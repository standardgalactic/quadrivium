more information  - www.cambridge.org/9781107012820


QUANTUM SOCIAL SCIENCE
Written by world experts in the foundations of quantum mechanics and its appli-
cations to social science, this book shows how elementary quantum mechanical
principles can be applied to decision making paradoxes in psychology, and used in
modeling information in Ô¨Ånance and economics.
The book starts with a thorough overview of some of the salient differences
between classical, statistical, and quantum mechanics. It presents arguments on why
quantum mechanics can be applied outside of physics and deÔ¨Ånes quantum social
science. The issue of the existence of quantum probabilistic effects in psychology,
economics, and Ô¨Ånance is addressed and basic questions and answers are provided.
Aimed at researchers in economics and psychology, as well as physics, basic
mathematical preliminaries and elementary concepts from quantum mechanics are
deÔ¨Åned in a self-contained way.
emmanuel haven is a Professor at the School of Management, University of
Leicester, UK. He has published numerous articles in a variety of Ô¨Åelds, such as
operations research, economics, and Ô¨Ånance.
andrei khrennikov is a Professor of Applied Mathematics at Linnaeus
University, Sweden, and Director of the International Centre for Mathematical
Modelling in Physics, Engineering, Economics and Cognitive Science.


QUANTUM SOCIAL SCIENCE
EMMANUEL HAVEN
University of Leicester
AND
ANDREI KHRENNIKOV
Linnaeus University

cambridge university press
Cambridge, New York, Melbourne, Madrid, Cape Town,
Singapore, SÀúao Paulo, Delhi, Mexico City
Cambridge University Press
The Edinburgh Building, Cambridge CB2 8RU, UK
Published in the United States of America by Cambridge University Press, New York
www.cambridge.org
Information on this title: www.cambridge.org/9781107012820
C‚ÉùE. Haven and A. Khrennikov 2013
This publication is in copyright. Subject to statutory exception
and to the provisions of relevant collective licensing agreements,
no reproduction of any part may take place without the written
permission of Cambridge University Press.
First published 2013
Printed and bound in the United Kingdom by the MPG Books Group
A catalogue record for this publication is available from the British Library
Library of Congress Cataloguing in Publication data
Haven, Emmanuel, 1965‚Äì
Quantum social science / Emmanuel Haven and Andrei Yu. Khrennikov.
p.
cm.
Includes bibliographical references and index.
ISBN 978-1-107-01282-0 (hbk.)
1. Social sciences ‚Äì Mathematical models.
2. Quantum theory.
I. Khrennikov, A. IU. (Andrei IUr‚Äôevich), 1958‚Äì
II. Title.
H61.25.H38
2012
300.1‚Ä≤53012 ‚Äì dc23
2012027126
ISBN 978-1-107-01282-0 Hardback
Cambridge University Press has no responsibility for the persistence or
accuracy of URLs for external or third-party internet websites referred to
in this publication, and does not guarantee that any content on such
websites is, or will remain, accurate or appropriate.

To our lovely Wives ‚Äì Irina and Sophie
To our lovely Children ‚Äì Anton, Nath, and Sam


Contents
Foreword
page xiii
Preface
xvii
Acknowledgements
xix
List of symbols
xxi
I
Physics concepts in social science? A discussion
1
Classical, statistical, and quantum mechanics: all in one
3
1.1
Newtonian mechanics
3
1.2
References
6
1.3
The Hamiltonian formalism
7
1.4
Statistical mechanics and the Liouville equation
9
1.5
The classical kingdom . . .
11
1.6
References
12
1.7
Classical Ô¨Åelds
12
1.8
Reference
14
1.9
The Born‚ÄìSommerfeld quantization
14
1.10 Reference
17
1.11 Theory of quantum waves
17
1.12 References
18
1.13 Heisenberg‚Äôs symbolic calculus
18
1.14 Heisenbergian symbolism in physics: a version of symbolism
in art
23
1.15 References
24
1.16 Completeness of quantum mechanics and a possibility to
apply quantum mechanics outside of physics
24
1.17 References
28
1.18 Brownian motion
28
1.19 References
31
vii

viii
Contents
1.20 The Schr¬®odinger equation
31
1.21 References
35
1.22 Do not be afraid of no-go theorems!
35
1.23 References
36
2
Econophysics: statistical physics and social science
37
2.1
Science and social science: econophysics?
37
2.2
References
40
2.3
The physics-based ‚ÄúFokker‚ÄìPlanck‚Äù PDE in economics
40
2.4
References
41
2.5
Potential and kinetic energy in social science
41
2.6
References
42
2.7
The backward Kolmogorov PDE in Ô¨Ånance
43
2.8
References
48
2.9
What a weird world! Martingales and fake probabilities
49
2.10 References
52
2.11 Whetting the quantum appetite
52
2.12 References
53
3
Quantum social science: a non-mathematical motivation
54
3.1
What is quantum social science?
54
3.2
Key Ô¨Åndings from quantum social science
62
3.3
References
64
II
Mathematics and physics preliminaries
4
Vector calculus and other mathematical preliminaries
71
4.1
Linear spaces
71
4.2
References
72
4.3
State space: Hilbert space
72
4.4
References
73
4.5
Operators
73
4.6
References
75
4.7
Dirac brakets and bras and kets
75
4.8
References
76
4.9
Eigenvalues/eigenfunction
77
4.10 References
77
4.11 Hermiticity
77
4.12 References
78
4.13 Projection operators
78
4.14 Probability density functions
79
4.15 References
79

Contents
ix
4.16 ODEs and PDEs
79
4.17 References
80
4.18 Basics of stochastic mathematics, Brownian motion,
non-arbitrage condition, ItÀÜo‚Äôs Lemma
80
4.19 References
82
5
Basic elements of quantum mechanics
84
5.1
Mathematical formalism of quantum mechanics: brief
introduction
84
5.2
References
89
5.3
Double slit experiment: rationale for the existence of
probability waves
90
5.4
References
92
5.5
Quantum mechanical postulates
92
5.6
References
94
5.7
States and state functions
95
5.8
References
95
5.9
Wave packets ‚Äì constructive and destructive interference
96
5.10 References
96
5.11 Heisenberg‚Äôs uncertainty principle
96
5.12 References
97
5.13 The time-dependent and time-independent Schr¬®odinger PDE
97
5.14 References
98
5.15 Classical limit ideas: Ehrenfest‚Äôs approach and the
correspondence principle
98
5.16 References
100
6
Basic elements of Bohmian mechanics
102
6.1
Short introduction to Bohmian mechanics
102
6.2
References
103
6.3
Mathematical formalism
103
6.4
References
105
6.5
Non-locality
106
6.6
References
107
6.7
Criticisms of Bohmian mechanics
107
6.8
References
108
III
Quantum probabilistic effects in psychology: basic questions
and answers
7
A brief overview
113
7.1
Decision making in social science: general overview
113

x
Contents
7.2
References
116
7.3
Modeling risk: some basic approaches
117
7.4
References
120
7.5
Possible remedies to the paradox: a brief discussion
120
7.6
References
122
7.7
The role of the law of total probability (LTP): a brief overview
122
7.8
Reference
123
8
Interference effects in psychology ‚Äì an introduction
124
8.1
Classical decision making and the Bayesian approach
124
8.2
References
125
8.3
Non-classical decision making: violation of the LTP (law of
total probability) and the quantum Bayesian approach
125
8.4
Contextual probabilistic formalization
128
8.5
Interference effects in social science: decision making based
on LTP with interference terms
132
8.6
Savage sure-thing principle
132
8.7
Behavioral games: Prisoner‚Äôs Dilemma
134
8.8
Violation of rationality in the experiments of ShaÔ¨År and
Tversky
135
8.9
Prisoner‚Äôs dilemma-type experiment: ShaÔ¨År and Tversky
136
8.10 Violation of double stochasticity for matrices of
transition probabilities
137
8.11 Prisoner‚Äôs dilemma-type experiment: Croson
138
8.12 Gambling experiment ‚Äì 1: Tversky and ShaÔ¨År
139
8.13 Gambling experiment ‚Äì 2: Tversky and ShaÔ¨År
141
8.14 The Hawaii vacation experiment
141
8.15 Non-classicality of statistical data: non-zero coefÔ¨Åcients of
interference
142
8.16 The constructive wave function approach and Ô¨Åt to data from
the experiments of ShaÔ¨År and Tversky
144
8.17 Other experiments
145
8.18 References
152
9
A quantum-like model of decision making
155
9.1
Introduction
155
9.2
Two-player game and rational behavior
155
9.3
Construction of a mental state
156
9.4
A process of decision making
158
9.5
Example: decision making in PD
161
Appendix 1: Channels and liftings
162

Contents
xi
Appendix 2: Quantum Markov chain description of data from
experiments in cognitive psychology
163
9.6
References
170
IV
Other quantum probabilistic effects in economics, Ô¨Ånance, and
brain sciences
10
Financial/economic theory in crisis
173
10.1 Relevance of the concepts of efÔ¨Åciency and non-arbitrage: a
brief discussion
173
10.2 References
176
10.3 George Soros‚Äô interpretation of the crisis and the use of
classical quantum physics in Ô¨Ånance
177
10.4 References
181
10.5 The need for an information modeling device in
economics and Ô¨Ånance
182
10.6 Reference
183
11
Bohmian mechanics in Ô¨Ånance and economics
184
11.1 The pilot wave function and its uses outside of quantum
mechanics
184
11.2 References
185
12
The Bohm‚ÄìVigier model and path simulation
186
12.1 The Bohm‚ÄìVigier model in Ô¨Ånance
186
12.2 References
187
12.3 The Newton‚ÄìBohm equation: path simulation
187
12.4 Reference
191
13
Other applications to economic/Ô¨Ånancial theory
192
13.1 The (non-)Hermiticity of Ô¨Ånance-based operators?
192
13.2 References
196
13.3 Implications of the non-Hermiticity of a Black‚ÄìScholes
Hamiltonian operator on the use of the classical limit
arguments
197
13.4 References
198
13.5 Implications of the non-Hermiticity of a Black‚ÄìScholes
Hamiltonian operator on the stochastic equivalent of
Hamilton‚ÄìJacobi equations
198
13.6 Interpretations of the wave function: a brief discussion
198
13.7 The wave function and non-observed state prices
200
13.8 Price and superposition of values
204

xii
Contents
13.9
References
207
13.10 Arbitrage and negative probabilities
207
13.11 References
210
13.12 The Li‚ÄìZhang and WKB approach
211
13.13 References
214
13.14 The wave function as a Radon‚ÄìNikodym derivative
214
13.15 References
220
13.16 Universal Brownian motion: deÔ¨Ånition and discussion
220
13.17 References
222
13.18 Universal Brownian motion and option pricing
222
13.19 References
226
13.20 Wave functions in drift-dependent option pricing
226
13.21 References
227
13.22 Generalizations of ItÀÜo stochastics: path integration and other
tools
227
13.23 References
228
13.24 q-calculus and Ô¨Ånance
228
13.25 References
235
14
Neurophysiological sources of quantum-like processing in the brain
237
14.1
Introduction
237
14.2
Why could the brain use the quantum-like representation of
information which is based on classical electromagnetic
waves?
239
14.3
Prequantum classical statistical Ô¨Åeld theory: non-composite
systems
242
14.4
Cognitive model: two regimes of brain‚Äôs functioning
246
14.5
Classical regime: time representation
250
14.6
Classical signal processing of mental images
252
14.7
Quantum-like processing of mental images
255
14.8
Composite systems
259
14.9
References
261
15
Conclusion
263
Glossary of mathematics, physics, and economics/Ô¨Ånance terms
265
Index
274

Foreword
This new book by Emmanuel Haven and Andrei Khrennikov argues that informa-
tion processing in social systems can to a degree be formalized with the mathe-
matical apparatus of quantum mechanics. This is a novel approach. Understanding
decision making is a central objective of economics and Ô¨Ånance and the quantum
like approach proposed here, is used as a tool to enrich the formalism of such deci-
sion making. Emmanuel and Andrei argue for instance that probability interference
can be used to explain the violation of the law of total probability in well known
paradoxes like the Ellsberg decision making paradox.
Emmanuel and Andrei‚Äôs book forms one of the very Ô¨Årst contributions in a very
novel area of research. I hope this book can open the road for many new books to
come. More new results are needed, especially in the area of decision making.
H. Eugene Stanley
William FairÔ¨Åeld Warren Distinguished Professor;
Professor of Physics; Professor of Chemistry;
Professor of Biomedical Engineering;
Professor of Physiology (School of Medicine)
Director, Center for Polymer Studies,
Department of Physics, Boston University
By chance a few days before Andrei Khrennikov and Emmanuel Haven asked me
to write this Foreword to their new book Quantum Social Science, I was brows-
ing the collected works of Wolfgang Pauli, Writings on Physics and Philosophy,
eds. Charles P. Enz and Karl von Meyenn, Springer (1994). I was just coming off
a busy semester, including teaching a rather advanced course on harmonic anal-
ysis and quantum physics. To those erstwhile Ph.D. students in mathematics and
physics, I had found myself counseling them with utterances such as ‚Äúlook, all
physicists need to think semi-classically or even classically,‚Äù or ‚Äúyou have to do
something, you cannot just say it is all random motion,‚Äù or ‚ÄúHeisenberg didn‚Äôt
really understand mathematics, but his intuition was sufÔ¨Åcient to guide him.‚Äù
xiii

xiv
Foreword
Therefore I was very pleased to see Haven and Khrennikov also going to some
of Pauli‚Äôs thoughts in their Preface. Pauli, one of the greatest thinkers on quan-
tum mechanics, was often preoccupied with the interaction of experiment with
observer, and in analogy with the interaction of the conscious with the unconscious.
Pauli‚Äôs advocacy of the coupling of objective quantum physics to the subjective,
e.g. psychic, was patterned upon Bohr‚Äôs fundamental notion of complementar-
ity. Two mutually contradictory concepts, e.g. those of particle and wave, may
co-exist.
Indeed, quantum mechanics has forced upon us a new reality, possessing many
co-existing dualities. One has the Schr¬®odinger picture of differential equations
describing all the chemical elements upon which the universe depends, and the
Heisenberg picture stressing more the probabilistic nature of scattering interactions.
The two pictures were more or less reconciled by Born in 1926, with his concept of
probability wave. I have reviewed the Born probability interpretation of quantum
mechanics from its inception to the present in K. Gustafson, The Born Rule, AIP
Proceedings 962 (2007) pp. 98‚Äì107. I detailed in that review how often the great
pioneers of quantum theory had to resort to reasonings of classical physics. So one
should not think that quantum mechanics is all ‚Äú hocus-pocus.‚Äù Quantum mechanics
is grounded in reality.
On the other hand, it is quite important to stress that the Born interpretation
places the physics into an abstract conÔ¨Åguration space, and not in real 3d space.
As a consequence, from then on one must rely on the mathematics. Quantum
mechanics has generated some very powerful mathematics. Ideally, this then
should be coupled with new quantum-like thinking that one will not Ô¨Ånd in
classical physics. It is the authors‚Äô intention in the present book to apply these
powerful new mathematical tools and the evolving new non-classical quantum
intuition to social science, behavioral economics, decision theory, and Ô¨Ånancial
engineering.
Both authors already have considerable experience in this endeavor. Andrei
Khrennikov is the founder of the celebrated series of annual quantum physics
conferences held in V¬®axj¬®o Sweden for the last dozen years. At those conferences
Emmanuel Haven from the economics side has joined with Khrennikov in recent
years to organize special sessions on the subject matter of this book. Khrennikov
has previously put forth his thinking in two books, Information Dynamics in Cog-
nitive, Psychological and Anomalous Phenomena, Kluwer (2004), and Ubiquitous
Quantum Structure: From Psychology to Finance, Springer (2010). Haven brings
to the present book more expertise in economics and Ô¨Ånance.
Overall, one could describe their basic approach as that of embedding situations
from the social or economic sciences into a quantum mechanical context and then
using the methods of the latter to obtain new insights and results for the former.

Foreword
xv
Such approach presumes of the reader a substantial knowledge of both contexts,
that of quantum mechanics, and that of the particular social Ô¨Åeld of application.
That is asking a lot.
I chose to address this issue, that of more needed interdisciplinary competence in
education, science, and the general public, in my recent autobiography The Crossing
of Heaven: Memoirs of a Mathematician, Springer (2012). I have come to the
conclusion that we must invoke and enforce a new term, that of Multidisciplinarity.
Interdisciplinarity is a weak word. It implies that one is less than one hundred
percent committed to each of the two Ô¨Åelds. Or that one is slightly weak in one‚Äôs
own Ô¨Åeld and leaning on an expert from the other Ô¨Åeld, who is probably a bit weak
also in his Ô¨Åeld. I have worked successfully in several Ô¨Åelds of science and I can
assure you that you should plan on becoming an expert also in ‚Äúthe other Ô¨Åeld,‚Äù
and that will take you, say, at least Ô¨Åve years before you have a chance of becoming
competitive there.
Thus a collateral message of this foreword is that of advancing the concept and
indeed the cause of creating more multidisciplinarity in our future mathematicians,
physicists, social scientists, and, in a more general sense, throughout the educated
public. A tall order! But great opportunities will open up to those who are strong
enough.
This book by Haven and Khrennikov is a move in that direction, a pioneering
effort.
Karl Gustafson
Professor Of Mathematics
University of Colorado at Boulder


Preface
The current level of specialization of knowledge in a variety of Ô¨Åelds of inquiry
may make it quite challenging for a researcher to be at the same time a ‚Äúdeveloper‚Äù
and a ‚Äútester‚Äù of a theory. Although a theory can exist without a necessary clear
and obvious practical end goal, the ultimate test of the validity of a theory (whether
it is situated in the exact or social sciences) will always be how measurement can
‚ÄúconÔ¨Årm‚Äù or dislodge a theory.
This book is largely dedicated to the development of a theory. We will be the
very Ô¨Årst to accept the accusation that the duo ‚Äútheory-test‚Äù is widely absent in this
work, and we believe it necessary to make this statement at the very beginning.
This book is about a very counter-intuitive development. We want to use a
physics machinery which is meant to explain sub-atomic behavior, in a setting
which is at the near opposite end of the size spectrum, i.e. the world as we know
and live it through our senses. We may know about the sub-atomic world, but we
do not have human experience of the sub-atomic world. Do we have credible and
provable stories which can explain how the sub-atomic engages into the mechanics
of the statistical macro-world? Probably not. Why do we bother then about being
so exotic? The interested reader will want us to provide for a satisfactory answer
to this obvious question, and we want to leave it up to him or her to decide
whether we have begun, via the medium of this book, to convince that the level of
‚Äúexoticality‚Äù (and ‚Äúyes‚Äù how exotic is that word?) is sensibly less than anticipated.
We can possibly give a glimmer of ‚Äúhope,‚Äù even at this early stage. Consider
the words of one of the towering giants of physics of the twentieth century ‚Äì
Wolfgang Pauli. In an unpublished essay by Pauli, entitled ‚ÄúModern examples
of ‚Äòbackground physics‚Äô,‚Äù which is reproduced in Meier‚àó(pp. 179‚Äì196), we can
read Pauli‚Äôs words (Meier* (p. 185)): ‚ÄúComplementarity in physics . . . has a very
close analogy with the terms ‚Äòconscious‚Äô and ‚Äòunconscious‚Äô in psychology in
* Meier C. A. (2001). Atom and Archetype: The Pauli/Jung Letters, 1932‚Äì1958. Princeton University Press.
xvii

xviii
Preface
that any ‚Äòobservation‚Äô of unconscious contents entails fundamentally indeÔ¨Ånable
repercussions of the conscious on these very contents.‚Äù The words of Pauli are
important. They show there is promise for a connection between ‚Äúconcepts‚Äù of
utmost importance in two very different sciences: complementarity in quantum
physics and ‚Äúcomplementarity‚Äù between consciousness and unconsciousness in
psychology.
In this book, we intend to give the reader a Ô¨Çavor of an intellectual development
which has taken shape over several years via the usual media many academics
use: conference presentations and academic articles. The theory presented here is
nowhere complete but we strongly believe that it merits presentation in book form.
The models presented in this book can be called ‚Äúquantum-like.‚Äù They do not
have a direct relation to quantum physics. We emphasize that in our approach,
the quantum-like behavior of human beings is not a consequence of quantum
physical processes in the brain. Our basic premise is that information processing
by complex social systems can be described by the mathematical apparatus of
quantum mechanics. We present quantum-like models for the Ô¨Ånancial market,
behavioral economics, and decision making.
Connecting exact science with social science is not an easy endeavor. What
reveals to be most difÔ¨Åcult is to dispel an intuition that somehow there should exist
a natural bridge between physics and the modeling of social systems. This is a very
delicate issue. As we have seen above it is possible to think of ‚Äúcomplementarity‚Äù
as a concept which could bridge physics and psychology. However, in some speciÔ¨Åc
areas of social systems, the ‚Äúphysics equivalent‚Äù of the obtained results may have
very little meaning.
It is our sincere hope that with this book we can convince the brave reader that
the intuition of the authors is not merely naive, but instead informative. Hence,
may we suggest that ‚Äúreading on‚Äù is the command of the moment? Let the neurons
Ô¨Åre!

Acknowledgements
Luigi Accardi and A. Khrennikov and M. Ohya (2009). Quantum Markov model for
data from ShaÔ¨År-Tversky experiments in cognitive psychology. Open Systems
& Information Dynamics, 16(4), 378‚Äì383. This material is reproduced with
permission of World ScientiÔ¨Åc Publishing Co Pte Ltd.
Masanari Asano and M. Ohya and A. Khrennikov (2011). Quantum-like model
for decision making process in two players game. Foundations of Physics,
41, 538‚Äì548. Foundations of Physics by Springer New York LLC. Repro-
duced with permission of Springer New York LLC in the format reuse in a
book/textbook via Copyright Clearance Center.
Masanari Asano and M. Ohya and Y. Tanaka and I. Basieva and A. Khrennikov
(2011). Quantum like model of brain‚Äôs functioning: decision making from
decoherence. Journal of Theoretical Biology, 281, 63‚Äì64. Journal of Theoret-
ical Biology by Academic Press. Reproduced with permission of Academic
Press in the format reuse in a book/textbook via Copyright Clearance Center.
Sheldon Goldstein (2010). Bohmian mechanics and quantum information. Foun-
dations of Physics, 40, 335‚Äì355.
C‚ÉùSpringer Science+Business Media,
LLC 2009. Quotes reproduced with kind permission from Springer
Science+Business Media: Foundations of Physics.
Emmanuel Haven (2005). Analytical solutions to the backward Kolmogorov PDE
via an adiabatic approximation to the Schrodinger PDE. Journal of Mathe-
matical Analysis and Applications, 311, 442‚Äì443. C‚Éù2005. Reprinted with
Permission from Elsevier Inc.
Emmanuel Haven (2008). Private information and the ‚Äúinformation function‚Äù: a
survey of possible uses. Theory and Decision, 64, 200‚Äì201. C‚ÉùSpringer 2007.
Reprinted with kind permission from Springer Science+Business Media.
Emmanuel Haven (2008). The variation of Ô¨Ånancial arbitrage via the use of an
information wave function. International Journal of Theoretical Physics, 47,
xix

xx
Acknowledgements
196‚Äì199. C‚ÉùSpringer Science+Business Media, LLC 2007. Reprinted with
kind permission from Springer Science+Business Media, LLC 2007.
Emmanuel Haven (2010). The Blackwell and Dubins theorem and R¬¥enyi‚Äôs amount
of information measure: some applications. Acta Applicandae Mathematicae,
109, 751‚Äì757. C‚ÉùSpringer Science+Business Media B.V. 2008. Reprinted
with kind permission from Springer Science+Business Media B.V. 2008.
Emmanuel Haven (2011). ItÀÜo‚Äôs lemma with quantum calculus: some implica-
tions. Foundations of Physics, 41, 3, 530‚Äì536. C‚ÉùSpringer Science+Business
Media,
LLC
2010.
Reprinted
with
kind
permission
from
Springer
Science+Business Media.
Peter Holland (2000). The Quantum Theory of Motion: An Account of the de
Broglie‚ÄìBohm Causal Interpretation of Quantum Mechanics. C‚ÉùCambridge
University Press 1995. Reproduced with permission.
Hiromu Ishio and E. Haven (2009). Information in asset pricing: a wave function
approach. Annalen der Physik, 18, 1, 40‚Äì42.
C‚Éù2009 Wiley-VCH Verlag
GmbH & Co. KGaA, Weinheim. Reprinted with kind permission from J.
Wiley.
Max Jammer (1974). The Philosophy of Quantum Mechanics. New York: J. Wiley.
This material is reproduced with permission of John Wiley & Sons, Inc.
Andrei Khrennikov (2010). Ubiquitous Quantum Structure: From Psychology to
Finance, Prisoner‚Äôs Dilemma. C‚ÉùSpringer-Verlag, Berlin, Heidelberg 2010.
Reprinted with kind permission from Springer Science+Business Media.
Andrei Khrennikov (2011). Quantum-like model of processing of information in
the brain based on classical electromagnetic Ô¨Åeld. Biosystems, 105, 251‚Äì259.
Biosystems by Elsevier Science. Reproduced with permission of Elsevier
Science.
C. A. Meier (2001). Atom and Archetype: The Pauli/Jung Letters, 1932‚Äì1958.
C‚ÉùPrinceton University Press 2001. Reprinted with permission.
Michael A. Morrison (1990). Understanding Quantum Physics: A User‚Äôs Manual.
Volume 1. 1st edition. C‚Éù1990. Reprinted by permission of Pearson Education
Inc., Upper Saddle River, NJ.
Salih Neftci (2000). An Introduction to the Mathematics of Financial Derivatives,
pp. 346‚Äì358. C‚ÉùElsevier 2000.
Hal R. Varian (1992). Microeconomic Analysis. 3rd edition. C‚Éù1992, 1984, 1978
W. W. Norton and Company, Inc. Used by Permission of W. W. Norton and
Company Inc.

List of symbols
Some mathematics symbols used in the book
r R: space of real numbers
r C: space of complex numbers
r œÅ(., .): probability density function (2 dimensional)
r œÅ(t, ., .): time-dependent probability density function
r L2(R3): space of square integrable complex valued functions œà : R3 ‚ÜíC
r H = L2(R3): complex Hilbert space with a scalar product
r l.i.m: limit in the mean square sense
r P = (, F, P ): P is a probability space and points œâ of  (which is a non-
empty set) are said to be elementary events. F is a so-called œÉ-algebra and P is
a probability measure
r m.s.: mean square
r Œ¥(x ‚àíx0): Dirac Œ¥-‚Äúfunction‚Äù
r Pb|a: matrix of transition probabilities
r dqf (x): q differential of a function f (x)
r dhf (x): h differential of a function f (x)
Some physics symbols used in the book
r m: mass
r a: acceleration
r f : force acting on particle
r V : real potential function
r œÜ, S: phase of a wave function
r ŒΩ: frequency
r t: time
r ‚àáV : gradient of the real potential function
xxi

xxii
List of symbols
r p: momentum
r q: position
r H(.,.): Hamiltonian function
r {f, g}: Poisson bracket of two functions f and g on an N particle phase space
r {f1, f2}: Poisson bracket for a pair of classical observables f1, f2
r œÜ(t, x, y, z, ): Ô¨Åeld state at instant t of vector with coordinates x, y and z
r E(t, x, y, z, ): electrical Ô¨Åeld at instant t of vector with coordinates x, y and z
r B(t, x, y, z, ): magnetic Ô¨Åeld at instant t of vector with coordinates x, y and z
r h: Planck‚Äôs constant
r ¬Øh: rationalized Planck constant
r 
Eij = Ei ‚àíEj: discrete portion of energy
r L: angular momentum of an electron
r I: intensity of the electromagnetic Ô¨Åeld
r A = (aij): Hermitian matrix
r 
H: Hermitian matrix representing the energy observable (quantum Hamiltonian)
r ÀÜq: position operator
r ÀÜp: momentum operator
r œÉx: standard deviation of position
r œÉp: standard deviations of momentum
r 
qj: Laplace operator
r œà(t, q): probability amplitude on time, t, and position, q
r : phase space of hidden states
r |œà‚ü©: element of the Hilbert space H : a ket vector
r ‚ü®œÜ|: element of the dual space H ‚àó, the space of linear continuous functionals on
H: a bra vector
r ‚ü®œà1|wœà2‚ü©: Dirac braket, where œà‚àó
1 denotes the complex conjugate of œà1 and w
acts on the state function œà2.
r k: wave number
r A(k): amplitude function of wave number k
r ‚ü®p‚ü©: average momentum
r Q: quantum potential
r P(.|C): conditional probability dependent on the context, C
r D+: mean forward derivative
r D‚àí: mean backward derivative
Some economics/Ô¨Ånance symbols used in the book
r œÉ: volatility
r Œ± (œÉ): drift function of volatility
r Œ≤ (œÉ): diffusion function of volatility

List of symbols
xxiii
r dX, dz, dW: Wiener process
r ‚àí‚Üí
q = (q1, q2 . . . qn): n-dimensional price vector
r mj: number of shares of stock j
r Tj(t): market capitalization of trader j at time t
r V (q1, . . . , qn): interactions between traders as well as interactions from other
macro-economic factors
r : portfolio value
r F: Ô¨Ånancial option price
r S: stock price
r 
 = ‚àÇF
‚àÇS : delta of the option
r fu; fd : intrinsic values of the option when the price of the asset is respectively
going up and down
r E(r): expected return
r Œ¥: discrete change in the value of the portfolio, 
r Œº: expected return
r dF: inÔ¨Ånitesimal change in F (the option price)
r rf : risk free rate of interest
r œÜ(S, t): part of the premium invested in the stock, S
r ST : asset price at the expiration of the option contract
r S0: asset price at the inception of the option contract
r P(., .|., .): conditional probability distribution
r E[ST |It]: conditional expectation of a stock price at time T > t, given the
information you have at time t
r E(eYtŒª): moment generating function, Œª is some arbitrary parameter, and Yt
follows a probability density function (pdf) with mean Œºt and œÉ 2t
r E 
P [., .]: expectation with respect to a risk neutral probability measure 
P
r EP [., .]: expectation with respect to a probability measure P
r Ct: option call value at time t
r Pt: option put value at time t
r ‚àí‚Üí
 = (1, 2, . . . , K): K-dimensional state price vector
r ‚àí‚Üí
D1, . . . , ‚àí‚Üí
DK: security price vector at time t1, if the market is, respectively, in
state 1, . . . , K
r Œª: Lagrangian multiplier
r E(u(W)): expected utility of wealth, W
r ‚âª: preference relation
r ‚™∞: weak preference relation
r Œ≤i: CAPM - Beta of asset i


Part I
Physics concepts in social science? A discussion


1
Classical, statistical, and quantum mechanics: all in one
This chapter provides for a very short course on classical (Newtonian as well
as statistical) mechanics and quantum mechanics. Readers who have not been
trained in physics will be able to gain basic knowledge of the main physical
theories developed during the last 400 years, with the inclusion of some of the
interpretational problems of these theories.
1.1 Newtonian mechanics
We discuss one of Newton‚Äôs laws, namely Newton‚Äôs second law: ‚Äúthe product of
mass and acceleration is equal to the force‚Äù or in mathematical symbols:
ma = f.
(1.1)
We state that m is the mass of a particle, a is its acceleration, and f is the force
acting on the particle.
Newton also introduced the notion of a continuous (inÔ¨Ånitely divisible) physical
space which was used to describe the dynamics of a particle. Here we can also men-
tion the contribution of Leibniz. However, the rigorous mathematical formalization
of the real continuum was done much later, at the end of the nineteenth century.
Physical space was represented by the mathematical model R3, the Cartesian prod-
uct space R √ó R √ó R of three real lines. In this mathematical model, Newton‚Äôs
second law can be formalized in the following way. Let us introduce the following
notations. Let q = (x, y, z), be a three-dimensional vector, where x, y, z are the
particle‚Äôs coordinates:
v = dq
dt =
dx
dt , dy
dt , dz
dt

(1.2)
3

4
Classical, statistical, and quantum mechanics: all in one
is the vector of velocity, and, Ô¨Ånally:
a = dv
dt =
d2x
dt2 , d2y
dt2 , d2z
dt2

(1.3)
is the vector of acceleration. The dynamics of a particle, t ‚Üíq(t) (its trajectory in
physical space), is described by the ordinary differential equation:
md2q(t)
dt2
= f (t, q(t)).
(1.4)
To Ô¨Ånd the particle‚Äôs dynamics, we also have to know the initial conditions:
q(t0) = q0, v(t0) = dq
dt (t0) = v0,
(1.5)
where q0 and v0 are respectively the particle‚Äôs position and velocity at the initial
instant of time t0.
An important class of forces is given by the so-called ‚Äúconservative forces.‚Äù
We start with the one-dimensional model, a particle on the line: there is only one
coordinate x. We state that a force f (x) is called conservative if there exists a real
valued function V (x) (which is called the potential) such that:
f (x) = ‚àídV
dx .
(1.6)
The potential V (x) represents the potential energy of a particle (see for instance the
next chapter for the use of such potential in a social science setting). To illustrate
this notion, consider a basic example which also plays an important role in quantum
mechanics. The harmonic oscillator is a well-known object in classical mechanics.
The restoring force f which is proportional to the displacement of a particle from
its equilibrium position is:
f (x) = ‚àíkx,
(1.7)
where k is a positive constant. This is a conservative force with the potential
V (x) = kx2/2. This is the equation of the standard parabola indicating the fact that
the potential energy has its minimum at the point x = 0. Newton‚Äôs second law for
the system is:
md2x
dt2 = ‚àíkx.
(1.8)
Solving this ordinary differential equation, we Ô¨Ånd that the motion is described by
the function:
x(t) = A cos (2œÄŒΩt + œÜ) ,
(1.9)

1.1 Newtonian mechanics
5
where:
ŒΩ = 1
2œÄ

k
m = 1
T .
(1.10)
Remark that ŒΩ indicates the frequency expressed as the number of cycles per time
unit. Clearly, as is intuitive, the force constant k and the mass m inÔ¨Çuence this
frequency. The position x(t) depends on this frequency ŒΩ but also on the amplitude
A and phase œÜ. They can be found from the system of equations:
A cos œÜ = x0, A sin œÜ = ‚àív0/2œÄŒΩ.
(1.11)
In the case of a particle in the three-dimensional case, the force f is a vector
f = (fx, fy, fz). It is called conservative if there exists a (real) potential V (q), q =
(x, y, z), such that fx = ‚àí‚àÇV
‚àÇx , fy = ‚àí‚àÇV
‚àÇy , fz = ‚àí‚àÇV
‚àÇz . We also recall the notion of
the gradient of a function V. This is a vector composed of its partial derivatives
and it is denoted as ‚àáV. Hence, a conservative force can be represented as the
‚Äúnegative gradient‚Äù of the potential:
f = ‚àí‚àáV.
(1.12)
Although in this book we try to minimize mathematical details as much as
possible, we need to point out the theorem of the existence and uniqueness of the
solution of the equation (1.4) with the initial conditions (1.5). Such a problem, i.e.
an equation with initial conditions, is called the Cauchy problem. This is one of
the basic mathematical problems of classical mechanics. The simplest version of
the aforementioned theorem is that if the force is described by a smooth function
f, i.e. differentiable and with continuous derivative, and the derivative is bounded,
i.e. there exists a constant c > 0 such that, for every q ‚ààR3, |f ‚Ä≤(q)| ‚â§c, then, for
any pair (q0, v0), a unique solution of the Cauchy problem exists (1.4), (1.5). This
mathematical theorem was the main source of the causal deterministic viewpoint
to classical mechanics: if we know the position and velocity of a particle at t = t0,
then we can Ô¨Ånd them at any instant of time t > t0 : q = q(t), v = v(t) = dq(t)
dt .
Consider the following quote by Laplace [1]:
We ought to regard the present state of the universe as the effect of its antecedent state and
as the cause of the state that is to follow. An intelligence knowing all the forces acting in
nature at a given instant, as well as the momentary positions of all things in the universe,
would be able to comprehend in one single formula the motions of the largest bodies

6
Classical, statistical, and quantum mechanics: all in one
as well as the lightest atoms in the world; provided that its intellect were sufÔ¨Åciently
powerful to subject all data to analysis; to it nothing would be uncertain, the future as well
as the past would be present to its eyes.
Later interpretations of quantum mechanics also leave the theoretical possibility
of such a super intellect contested.
This is a good example of how pure mathematics generates fundamental philo-
sophic principles. As it often happens in science, it is not easy to change philosophic
principles which have been established on the basis of some special mathematical
results and models. During Laplace‚Äôs lifetime, the theory of differential equations
had not yet been well developed. Nowadays, it is well known that the Cauchy
problem (1.4), (1.5) may have a non-unique solution even for continuous forces.
If f is smooth, then the solution is unique only locally, i.e. for a small neighbor-
hood of the point (t0, x0). However, globally it can be non-unique. Hence, modern
mathematics does not imply determinism even in classical mechanics (see [2] for
usage of this argument in classical non-deterministic biological dynamics). We
also remark that if the dynamics of a particle is even deterministic, but unstable,
then a small disturbance of initial conditions, can change crucially the trajectory
of such a particle. In such a case, although the principle of determinism is formally
valid, it has no usage in real practice, since it is impossible to determine initial
conditions with inÔ¨Ånite precision. This argument against the uncontrollable usage
of the principle of determinism in classical mechanics was presented by Blohinzev
[3] in his comparison of classical and quantum mechanics. In conclusion, we can
see from the above that Laplace‚Äôs causal determinism is indeed a mere prejudice.
Besides Laplace‚Äôs prejudice, we can also mention the Kantian prejudice which
says that physical space has to be identiÔ¨Åed with its Euclidean model [4]. This
prejudice was based on two-thousand years of Euclidean geometry. The Ô¨Årst blow
to the Kantian views of physical space was given by Lobachevsky. However,
the genius of Einstein was needed to establish modern views of the geometry of
physical space.
The above discussion raises a reasonable recommendation: the reader may want
to veer close to mathematics and instead steer away from general physical, meta-
physical, and philosophic principles.
1.2 References
[1] See http://plato.stanford.edu/entries/determinism-causal and the reference contained
therein, cited as: Laplace, P. S. (1820). Essai philosophique sur les probabilit¬¥es forming
the introduction to his Th¬¥eorie analytique des probabilit¬¥es, Paris: V. Courcier repr.
Truscott, F. W. and Emory, F. L. (1951). A Philosophical Essay on Probabilities.
Dover, New York.

1.3 The Hamiltonian formalism
7
[2] Conte, E., Federici, A., Khrennikov, A., and Zbilut, J. P. (2004). Is determinism the
basic rule in dynamics of biological matter? Proceedings of Quantum Theory: Recon-
sideration of Foundations. Series in Mathematical Modelling in Physics, Engineering
and Cognitive Science, 10, 639‚Äì678, V¬®axj¬®o University Press, Sweden.
[3] Blochinzev, D. I. (1976). Elementary Quantum Mechanics. Nauka, Moscow
(in Russian).
[4] Kant, I. (2008). The Critique of Pure Reason. Penguin Classics, London.
1.3 The Hamiltonian formalism
To proceed from classical to quantum mechanics, one typically uses the Hamilto-
nian formalism for the description of the motion of classical particles. As usual, let
us introduce the momentum p = mv of a particle and consider phase space with
coordinates (q, p), where q is position. Points of the phase space are interpreted
as states of classical particles. We state again that, by Newton‚Äôs second law, to
determine the trajectory of a particle it is necessary to know both initial position
q0 and the velocity v0. In particular, knowledge of only position is not sufÔ¨Åcient.
Therefore, it is natural to deÔ¨Åne the particle‚Äôs state as the pair (q, v). By scaling the
velocity by the particle‚Äôs mass, we introduce its momentum, p, and equivalently
we represent the particle‚Äôs state as a pair (q, p).
We remark that the momentum‚Äôs deÔ¨Ånition can be expressed in the form of an
ordinary differential equation:
dq
dt = p
m.
(1.13)
Hence, Newton‚Äôs second law, (1.4), can be written as:
dp
dt = ‚àídV
dq .
(1.14)
Let us introduce the following function on the phase space:
H(q, p) = p2
2m + V (q).
(1.15)
H(., .) is called the Hamiltonian function. This is the total energy of a particle
which moves under the action of the force induced by the potential V and the
kinetic energy p2
2m. The system of equations (1.13), (1.14) can be written as:
dq
dt = ‚àÇH
‚àÇp , dp
dt = ‚àí‚àÇH
‚àÇq .
(1.16)
This is the system of Hamiltonian equations. It is easy to prove that the energy is
preserved in the process of motion:
H(q(t), p(t)) = H(q(t0), p(t0)).
(1.17)

8
Classical, statistical, and quantum mechanics: all in one
To prove this important fact (the law of energy conservation), it is sufÔ¨Åcient to use
the basic rule for the differentiation of a composition of functions and then to apply
this rule to the system of Hamiltonian equations.
By using the Hamiltonian formalism, we can formulate a feature of classical
mechanics, which can be called locality. Let us consider a system consisting of N
particles with the three-dimensional coordinates qj = (xj, yj, zj), j = 1, . . . , N
and corresponding momenta pj. The Hamiltonian function of a system of N
particles with masses mj moving in the potential V (q1, . . . , qN) has the form:
H(q, p) =
N

j=1
p2
j
2mj
+ V (q),
(1.18)
where q = (q1, . . . , qN), p = (p1, . . . , pN). The above Hamiltonian gives the total
energy of this system composed of N particles. The system of Hamiltonian equa-
tions describing the dynamics of this composite system can be written as:
dqj
dt = ‚àÇH(q, p)
‚àÇpj
, dpj
dt = ‚àí‚àÇH(q, p)
‚àÇqj
, j = 1, . . . , N.
(1.19)
Within the potential V, the interaction between different particles is described
by terms containing coordinates of a few particles. We can consider the interaction
between particles by writing for instance terms of the form qi . . . qN (various
products of different coordinates). But let us consider now a potential which does
not contain interaction terms, V (q) = V1(q1) + ¬∑ ¬∑ ¬∑ + VN(qN). The corresponding
system of Hamiltonian equations is:
dqj
dt = pj
mj
, dpj
dt = ‚àí‚àÇVj
‚àÇqj
, j = 1, . . . , N.
(1.20)
This is a system of N-independent equations.
Hence, an important principle emerges from our discussion so far: Hamiltonian
mechanics is local, i.e. in the absence of interaction between particles, such parti-
cles move independently of each other.
We remark that non-local motion, as is the case with for instance Bohmian
mechanics (see Chapter 6), has the following (paradoxical from the viewpoint of
our classical intuition) feature. In the absence of interaction, even for V ‚â°0, the
dynamics of different particles are dependent on each other. Changing the state of
one particle (qj, pj) induces changing the states (qi, pi), i Ã∏= j, of other particles.
In the classical world, we have never seen such a behavior of physical systems.
Let us introduce a mathematical tool which has a key role in the Hamiltonian
formalism. The Poisson bracket of two functions on the N-particle phase space,

1.4 Statistical mechanics and the Liouville equation
9
f (q, p), g(q, p), is deÔ¨Åned as:
{f, g} =
N

j=1
‚àÇf (q, p)
‚àÇqj
‚àÇg(q, p)
‚àÇpj
‚àí‚àÇf (q, p)
‚àÇpj
‚àÇg(q, p)
‚àÇqj

.
(1.21)
As an example, consider functions f (q, p) = qj, g(q, p) = pj. Then:
{qj, pj} = 1, {qj, pk} = 0, j Ã∏= k.
(1.22)
{qj, qk} = 0, {pj, pk} = 0.
(1.23)
By using the Poisson bracket, we rewrite the system of Hamiltonian equations
as:
dqj
dt = {qj, H}, dpj
dt = {pj, H}.
(1.24)
This form of the Hamiltonian dynamics will be used to proceed from classical
Hamiltonian mechanics to quantum mechanics.
1.4 Statistical mechanics and the Liouville equation
In studying the dynamics of an ensemble of a huge number, say N particles, the
presence of the system of Hamiltonian equations plays merely a methodologi-
cal role. From as early as the nineteenth century until the 1960s, it was simply
impossible to solve this system for large N and non-trivial potentials. Nowadays
in principle one can solve it numerically and obtain millions of trajectories in the
phase space. However, it is not clear how one can use or visualize the results of
such computations. Already in the nineteenth century it was proposed that instead
of studying the trajectories of individual particles, it would be better to consider
the probability to Ô¨Ånd a particle in some domain, say W, of the phase space. Such
an approach meant in effect a move away from the deterministic description of
mechanics to a statistical description. Hence, the name statistical mechanics was
coined to denote this particular area of study.
Let us consider the phase space of the system of N particles, R2N, with points
(q, p), where q = (q1, . . . , qN), p = (p1, . . . , pN). What is the probability den-
sity function which indicates the probability to Ô¨Ånd the Ô¨Årst particle at point q1
with momentum p1, the second particle at point q2 with momentum p2, . . . ,
the Nth particle at qN with momentum pN? Since momenta are mass scalings
of velocities, the question can be reformulated as: ‚ÄúWhat is the probability den-
sity function of the Ô¨Årst particle at point q1 with velocity v1, the second parti-
cle at point q2 with velocity v2, . . . , the Nth particle at qN with velocity vN?‚Äù
We state that mathematically a probability density is a function œÅ(q, p) which is

10
Classical, statistical, and quantum mechanics: all in one
non-negative and normalized by 1:

R2N œÅ(q, p)dqdp = 1.
(1.25)
The probability to Ô¨Ånd a particles at a point (q, p) from the domain W of the
phase space is calculated with the aid of the probability density function:
P((q, p) ‚ààW) =

W
œÅ(q, p)dqdp.
(1.26)
A fundamental problem now consists to describe the dynamics of the
(time-dependent) probability density, t ‚ÜíœÅ(t, q, p). Fortunately, the Liouville
equation gives us the answer:
‚àÇœÅ(t,q,p)
‚àÇt
= {H(q, p), œÅ(t, q, p)},
(1.27)
œÅ(t0, q, p) = œÅ0(q, p).
(1.28)
Here, we remark:
{H, œÅ} =
N

j=1
‚àÇH
‚àÇqj
‚àÇœÅ
‚àÇpj
‚àí‚àÇH
‚àÇpj
‚àÇœÅ
‚àÇqj

.
(1.29)
Hence, if the initial probability density function is known, then (by solving the
Liouville equation) we can Ô¨Ånd the density at any instant of time. We remark that
the usage of the probabilistic description of an ensemble of N particles does not
contradict the existence of the deterministic Hamiltonian dynamics.
We do not provide the formal derivation of the Liouville equation. Instead
of this, we present physical arguments which lie behind this equation. Consider
the probability density function on a trajectory (q(t), p(t)) in the phase space
œÅ(t, q(t), p(t)). We calculate its total derivative with respect to time:
dœÅ
dt = ‚àÇœÅ
‚àÇt +
N

j=1
	 ‚àÇœÅ
‚àÇqj
dqj
dt + ‚àÇœÅ
‚àÇpj
dpj
dt

.
(1.30)
We now use the system of Hamiltonian equations (1.19) (this describes the trajec-
tory in the phase space) to express the time derivatives of coordinates and momenta
and obtain:
dœÅ
dt = ‚àÇœÅ
‚àÇt +
N

j=1
 ‚àÇœÅ
‚àÇqj
‚àÇH(q, p)
‚àÇpj
‚àí‚àÇœÅ
‚àÇpj
‚àÇH(q, p)
‚àÇqj

.
Then the Liouville equation is equivalent to the following statement: the distribution
function is constant along any trajectory in phase space, i.e. dœÅ
dt = 0.

1.5 The classical kingdom
11
1.5 The classical kingdom . . .
At the end of the nineteenth century, it was widely believed that all physical pro-
cesses can (at least in principle) be described with the aid of classical statistical
mechanics.1 The two fundamental principles of classical mechanics, namely deter-
minism and locality, had never been doubted. No experimental data were available
to disprove whether these principles actually existed.
The elaboration of a very consistent picture of natural phenomena was emerging.
Here are some examples. A previous state determines coming states. A change of a
state could happen only through the action of some force. For a composite system
consisting of a few particles and where interaction is absent, a change of the state of
any particle could not change the states of other particles. Such philosophical views
of natural phenomena are known under the term of local realism. Here ‚Äúrealism‚Äù
denotes the realism of states of physical systems, i.e. their positions and momenta.
Their dynamics are described by transitions from one state to another.
Let us speculate on a physical world in which local realism is violated. Start
with a world in which the principle of locality is violated, but the principle of
determinism holds true (‚Äúnon-local realism‚Äù). Consider two cars moving, e.g. in
Moscow and New York. The motion of each car is deterministic. Each car has a
well-deÔ¨Åned position in space and a velocity. However, if we were to consider there
exists action at a distance, then if, say, the car in Moscow stops near a trafÔ¨Åc light,
the car in New York may feel the effect of this stop instantaneously! Note that
instantaneously means at least faster than the speed of transmission (at the speed
of light) of a signal between Moscow and New York.2 If indeed such instantaneous
action were possible, then a state formed by the Moscow car stopping could affect
the state of the New York car.
Consider now a local world in which the principle of determinism is violated,
i.e. the previous state of a system does not determine uniquely successive states. A
car moving in Moscow can appear with some probability in any place of the world.
In all cases, the initial position and velocity of this car are the same. Hence, the
initial state does not determine the car‚Äôs dynamics.
We remark that physical determinism inÔ¨Çuenced some social doctrines. For
example, the philosophical basis of Marxism‚ÄìLeninism is known under the name
of ‚Äúhistorical materialism.‚Äù This says that one social system will inevitably change
1 When Max Planck Ô¨Ånished highschool, he applied to university to study physics. A professor interviewing
applicants explained to young Max that it was totally meaningless to start an education in physics. The professor
was sure nothing more could be studied in physics. All was now known! Young people would only destroy their
lives by starting careers in physics. Max was very talented in music and the professor recommended him to start
a career in music. See [1].
2 The optic Ô¨Åber signal speed can be close to the speed of light. Therefore, in the case of Ô¨Ånancial transactions
for instance, transmission speeds can attain close to speed of light transmission.

12
Classical, statistical, and quantum mechanics: all in one
another, capitalism ‚Üísocialism ‚Üícommunism. Even Sigmund Freud‚Äôs psy-
chological determinism was created under the inÔ¨Çuence of classical mechanics.
In [2], we can read about Freud‚Äôs psychoanalysis: ‚ÄúWhat is attractive about the
theory, even to the layman, is that it seems to offer us long sought-after and much-
needed causal explanations for conditions which have been a source of a great deal
of human misery. The thesis that neuroses are caused by unconscious conÔ¨Çicts
buried deep in the unconscious mind in the form of repressed libidinal energy
would appear to offer us, at last, an insight in the causal mechanism underlying
these abnormal psychological conditions as they are expressed in human behav-
ior, and further show us how they are related to the psychology of the ‚Äònormal‚Äô
person‚Äù (see also [3]). Furthermore, [3] mentions that ‚ÄúIn psychology, those, like
Freud, who believe in psychic determination in psychiatry, assume that all men-
tal events have causes. Freud believed that the existence of unconscious forces
proved psychic determinism to be a fact of mental life . . . he regarded psycho-
analysis as a science based on causal-deterministic assumptions.‚Äù See [4] [5] for
an attempt to combine Freudian psychological determinism and free will through
the Bohmian quantum model. See also Chapter 6 for the Bohmian mechanics
model.
1.6 References
[1] See
http://backreaction.blogspot.com/2011/12/advent-calender-9-prof-jollys-advice.
html, and the reference contained therein: Planck, M. (1933). Wege zur physikalis-
chen Erkenntnis (S. Hirzel), p. 128.
[2] Internet Encyclopedia of Philosophy. University of Tennessee. See http://www.iep.
utm.edu/freud/ (under b. The coherence of the theory).
[3] The Encyclopedia69 Dictionary. Please see at: http://www.encyclopedia69.com/
eng/d/determinism/determinism.htm.
[4] Khrennikov, A. (2002). Classical and Quantum Mental Models and Freud‚Äôs Theory
of Unconscious Mind. Series in Mathematical Modelling in Physics, Engineering and
Cognitive Sciences. V¬®axj¬®o University Press, Sweden.
[5] Khrennikov A. (2004). Information Dynamics in Cognitive, Psychological, Social, and
Anomalous Phenomena. Series: Fundamental Theories of Physics. Kluwer, Dordrecht.
1.7 Classical Ô¨Åelds
The completion of the theory of classical mechanics of particles was performed
via the introduction of the notion of the classical mechanics of Ô¨Åelds, i.e. classical
Ô¨Åeld theory ‚Äì the local deterministic theory of the electromagnetic Ô¨Åeld. The Ô¨Åeld‚Äôs
state (at the instant of time t) is given by the vector:
œÜ(t, x, y, z)) = (E(t, x, y, z), B(t, x, y, z)),
(1.31)

1.7 Classical Ô¨Åelds
13
where:
E(t, x, y, z) = (E1(t, x, y, z), E2(t, x, y, z), E3(t, x, y, z))
(1.32)
and:
B(t, x, y, z) = (B1(t, x, y, z), B2(t, x, y, z), B3(t, x, y, z))
(1.33)
are electric and magnetic Ô¨Åelds, respectively. The dynamics of the electromagnetic
Ô¨Åeld also can be described by the Cauchy problem (i.e., a dynamical equation
combined with initial conditions):
‚àÇœÜ(t, x, y, z)
‚àÇt
= L(œÜ(t, x, y, z)), œÜ(t0, x, y, z) = œÜ0(t, x, y, z),
(1.34)
where L is a differential operator of the Ô¨Årst order with partial derivatives with
respect to coordinates. At the moment, its form is not important. This operator was
found by Maxwell. We remark that the system of Maxwell equation (1.34) can be
written as a Hamiltonian system with respect to Ô¨Åeld components [1]. The electric
component plays a role of position, q(t, x, y, z) ‚â°E(t, x, y, z), and the magnetic
component plays a role of momentum, p(t, x, y, z) ‚â°B(t, x, y, z). What is the
phase space of this Ô¨Åeld system? The energy of the electromagnetic Ô¨Åeld (at the
Ô¨Åxed instant of time) is given by the integral:
E(E, B) =

R3(E2(x, y, z) + B2(x, y, z))dxdydz.
(1.35)
Since this integral is Ô¨Ånite, the Ô¨Åeld‚Äôs position q(x, y, z) = E(x, y, z) and the
Ô¨Åeld‚Äôs momentum p(x, y, z) = B(x, y, z) have to be square integrable (integrals
of squared functions are less than inÔ¨Ånity). By using mathematical analogy, we can
see E2 relates to a real potential ‚Äì B2 relates to kinetic energy ‚Äì in the non-Ô¨Åeld
setting. Denote the space of square integrable functions by L2. Thus, the Ô¨Åeld‚Äôs
phase space is the Cartesian product of two L2-spaces: L2 √ó L2.
The electric and magnetic components can be combined in a single complex
valued Ô¨Åeld œÜ = E + iB. This is well known (in classical signal theory) as the
Riemann‚ÄìSilberstein representation of the classical electromagnetic Ô¨Åeld. This rep-
resentation induces the complex structure on the phase space, œÜ = q + ip, where
all functions depend on spatial coordinates.3 This is equivalent to the consideration
of the space H of square integrable complex valued functions:
H =

œÜ :

|œÜ(x, y, z)|2dxdydz < ‚àû

.
(1.36)
3 This complex representation of the classical electromagnetic Ô¨Åeld was in usage before the creation of quantum
mechanics. Nowadays, little attention is paid to this historical fact. The fathers of quantum mechanics, including
Schr¬®odinger, were well aware of the Riemann‚ÄìSilberstein representation. Originally, the complex wave function
was invented merely as an analogue of the complex (classical) electromagnetic Ô¨Åeld.

14
Classical, statistical, and quantum mechanics: all in one
1.8 Reference
[1] Khrennikov, A. (2008). Quantum-like model for classical random electromagnetic
Ô¨Åeld. Journal of Modern Optics, 55, 2257‚Äì2267.
1.9 The Born‚ÄìSommerfeld quantization
Contrary to what could be expected, the Ô¨Årst steps towards edifying quantum
mechanics were not revolutionary at all! We note that those Ô¨Årst steps were not
at all accompanied by a fundamental change in the philosophical foundations of
science. The story started with a graph representing experimental data, and it
contained a spike, which from the viewpoint of classical mechanics was quite
difÔ¨Åcult to explain. The experimental graph turned out to be about black body
radiation and it was Max Planck who found that the spike could be explained in
a classical statistical mechanics framework, but it required one novel assumption:
radiation is emitted not continuously, but by discrete portions. Purely formally
the energy space was decomposed into cells. The size of a cell depends on the
frequency ŒΩ of the oscillations of the electromagnetic Ô¨Åeld. Max Planck postulated
that dependence on the frequency is linear and the coefÔ¨Åcient does not depend on
the frequency:

EŒΩ = hŒΩ.
(1.37)
This coefÔ¨Åcient of proportionality was later called Planck‚Äôs constant. Since the fre-
quency has dimension l/time, the Planck constant is expressed in units of ‚Äúenergy √ó
time.‚Äù This is the dimension of the classical physical variable called action. This
constant was measured with very good precision:
h ‚âà6.6260693(11) √ó 10‚àí34 J √ó sec.
(1.38)
The decomposition of the energy space into small cells and the summation over
cells is similar to the standard procedure of forming Riemann sums.4 To calculate
the Riemann integral, the size of cells has to go to zero. However, Planck did not
make this last step and wrote the answer using cells of a Ô¨Ånite size (proportional to
h). We note that in quantum folklore, one can Ô¨Ånd a story that Max Planck obtained
the correct answer, because he simply did not know that in order to calculate
Riemann‚Äôs integral one has to consider that the limit of the cell‚Äôs size goes to zero.
We remark that the tool of discretization of the energy space was not as novel
as it is typically presented in textbooks on quantum mechanics. It was actually
rather standard in classical statistical mechanics! In particular, Boltzmann used
4 These sums are used in the construction of the Riemann integral.

1.9 The Born‚ÄìSommerfeld quantization
15
discretization œµ, 2œµ, . . . , nœµ, . . . , where œµ was a ‚Äúminimal quant‚Äù of energy. This
is maybe the reason why the work of Planck was very welcome in the classical
statistical community: nobody considered the introduction of a parameter of energy
discretization as an attack against classical statistical mechanics!
The discretization parameter h ceased to be merely a parameter only after
Einstein‚Äôs work [1] (1905). In his work, Einstein claimed that 
EŒΩ = hŒΩ is not
just a minimal portion of energy which can be transmitted for the frequency ŒΩ,
but that even in the absence of interaction of the electromagnetic Ô¨Åeld and matter,
the Ô¨Åeld is ‚Äúquantized,‚Äù i.e. it is split into a collection of quanta of lights. Later
these quanta were called photons. Thus, in opposition to classical Ô¨Åeld theory, the
electromagnetic Ô¨Åeld has to be decomposed into an ensemble of photons, i.e. it has
corpuscular features.5
The next step towards quantum theory was performed on the basis of Bohr‚Äôs
quantization condition. We want to explicitly state that in classical Hamiltonian
mechanics, the energy is preserved on each trajectory (see (1.17)). Suppose now
that there exist constraints (of an unknown nature) which forbid some motions
and some trajectories, and that the system can move only via a discrete set of
trajectories. Denote those possible trajectories (consistent with the constraints) by:
Œ≥1, . . . , Œ≥n, . . .
(1.39)
Since the energy is constant on each of them, we obtain a discrete set of possible
energies:
E1 = E(Œ≥1), E2 = E(Œ≥2), . . . , En = E(Œ≥n), . . .
(1.40)
This idea was explored by Niels Bohr in his model of the atom. It was known from
experiments that atoms can emit and absorb energy only by quantized portions.
Bohr proposed a model describing this feature of atoms. In this model, the electron
is a classical-like particle which moves around the nucleus. However, in such a
motion a purely classical charged particle would continuously emit radiation and
lose energy. Finally, it would fall onto the nucleus. This was one of the main
unsolved problems of classical electrodynamics. Bohr postulated that an electron
can move only on a discrete set of orbits (1.39) and hence its energy can take
only a discrete series of values (1.40). Since an electron can only jump from
one orbit to another, the atom can emit (absorb) only discrete portions of energy

Eij = Ei ‚àíEj. To match experimental data, Bohr postulated that the frequency
5 There is a piece of irony in this story. Although Albert Einstein introduced quanta of light and hence in this way
he made the Ô¨Årst step towards modern quantum theory, later (in the 1920s) he gave up and until the end of his
life he worked to create a classical Ô¨Åeld theory which would describe quantum phenomena.

16
Classical, statistical, and quantum mechanics: all in one
ŒΩ of emitted (absorbed) electromagnetic radiation is determined by Planck‚Äôs law:

Eij = Ei ‚àíEj = hŒΩ.
(1.41)
Since these frequencies were known from experiment, he could Ô¨Ånd energy spacing
in the atom. Bohr was also able to ‚Äúderive‚Äù energy spacing even theoretically and he
obtained a key result which indicates that the angular momentum L of an electron
is to be an integer multiple of ¬Øh
L = n h
2œÄ = n¬Øh,
(1.42)
where n = 1, 2, 3, . . . is the quantum number, and ¬Øh = h/2œÄ.
Bohr‚Äôs quantization condition (1.42) determining the electron‚Äôs orbits in the
atom was generalized to the famous Bohr‚ÄìSommerfeld quantization rule (which
also had been postulated):

Œ≥n
pdq = hn,
(1.43)
where Œ≥n is the permitted orbit corresponding to a natural number n. In the original
Bohr model, only circular orbits were permitted; in the Bohr‚ÄìSommerfeld model
orbits can be elliptic.
Thus, the Ô¨Årst step towards quantum theory was the recognition that some phys-
ical quantities, Ô¨Årst of all energy, which were considered as continuous in classical
mechanics, are fundamentally discrete. Discreteness by itself is less fascinating.
However, the concept is fascinating, and even mystical, when it is combined with
the wave features of the systems under consideration (see below). Photons are
mystical not because they have corpuscular features,6 but because these features
are combined with wave behavior. As was shown in the famous experiment on the
interference of quantum light (see Chapter 5, Section 5.3), photons did not lose
their wave features. They interfere as usual waves. ‚ÄúQuantumness‚Äù was exhibited
by the detection procedure. As a consequence of the discreteness of energy in
experiments on quantum interference, one registers not intensities of signals and
interference of these intensities, but rather clicks of detectors which are ‚Äúeating‚Äù
discrete portions of energy. The probability density of the number of clicks presents
the interference picture similar to the ordinary wave interference.
6 Already Newton invented corpuscles of light.

1.11 Theory of quantum waves
17
1.10 Reference
[1] Einstein, A. (1905). ¬®Uber einen die Erzeugung und Verwandlung des Lichtes betref-
fenden heuristischen Gesichtspunkt. Annalen der Physik, 4, 17, 132‚Äì148.
1.11 Theory of quantum waves
The next step of great importance was performed by Louis de Broglie who assigned
the wave length to any quantum particle.7 Thus, not only a photon has a wave length
(and hence a frequency),8 but even an electron or a neutron, i.e. a massive particle.
Later, it was shown experimentally that de Broglie‚Äôs conjecture was correct and
even massive micro-systems can demonstrate non-trivial interference. As in the
case of photons, this is interference of the number of discrete counts of detectors,
i.e. interference encoded in the probability density.
The natural question arises, e.g. [1], how big (in size and mass) can systems be to
exhibit wave properties, e.g. interference? The theoretical formulation of quantum
mechanics cannot provide the deÔ¨Ånite answer to this question. Bohr emphasized
that the laws of quantum mechanics are valid only at scales related to the funda-
mental quant of action ‚Äì the Planck constant. He had in high esteem the role of
the correspondence principle, which established the coupling between classical
and quantum mechanics. This principle is discussed in detail in Chapter 5, Section
5.15. This principle (which, in fact, was and still remains very vaguely formu-
lated) says that if h ‚Üí0, i.e. the Planck constant is negligibly small compared
with the action scale (time√óenergy) of systems under consideration, then quan-
tum features (such as interference) disappear and classical mechanics becomes
applicable. However, Bohr‚Äôs correspondence principle has never been really justi-
Ô¨Åed. Although an advanced mathematical formalism related to this principle was
developed, e.g. [2], its physical meaning is still the subject of many discussions.
Therefore, it should not come as a surprise to witness the fact that high-level
researchers in quantum mechanics have claimed that wave features can be exhib-
ited by macroscopic massive bodies. For instance, Nobel prize winner A. Leggett
expects the creation of Schr¬®odinger‚Äôs cat-like states ‚Äì i.e. macroscopic superposi-
tions. This came after a discussion held following a talk from one of the authors
of this book.9 A. Zeilinger performed famous experiments on the interference of
7 de Broglie interpreted ‚Äúquantum waves‚Äù as physical waves. Later he elaborated the double solution theory by
which quantum particles appeared as singularities in quantum waves. The former were driven by the latter. De
Broglie‚Äôs double solution theory was the Ô¨Årst step towards modern pilot wave theory and Bohmian mechanics.
This is a theory which combines corpuscular and wave features of quantum systems in a realistic manner. See
also Chapter 6 where we discuss the basics of Bohmian mechanics.
8 This was not surprising.
9 This refers to the talk given by A. Khrennikov on May 3, 2004, at the Beckman Institute of the University of
Illinois, Urbana Champain.

18
Classical, statistical, and quantum mechanics: all in one
macro-molecules [3]. Recently, De Martini created macroscopic photonic clouds
in states of superposition and, moreover, he created entangled macroscopic clouds
of photons [4]. However, all these studies are far from fully clarifying! Indeed,
they suffer from interpretational problems. We need to indicate that superposition
is also a fundamental feature of classical macroscopic waves. Thus, superposition
by itself is not a unique feature of quantum mechanics. We note that the super-
position attains a quantum character when it is combined with the discreteness of
measurement results. Interference of continuous quantities, such as intensities of
classical radio signals, cannot be considered as a quantum feature. However, the
interference of discrete clicks of detectors is really a quantum phenomenon. To
check the property of ‚Äúquantum superpositions‚Äù is a difÔ¨Åcult problem. For exam-
ple, in experiments of De Martini [4] discreteness is created by hand, through
threshold type measurements of the intensity of the electromagnetic Ô¨Åeld: if I > œµ
the result is +1, if I < œµ it is ‚Äì1. However, as was shown by Adenier and one of the
authors of this book [5], such ‚Äúthreshold generated‚Äù combination of discreteness
and interference can be obtained even for classical electromagnetic signals.
Finally, quantum theory obtained a solid mathematical base via Schr¬®odinger‚Äôs
dynamical equation (see also Section 1.20 and Chapter 5). In a similar way as de
Broglie, Schr¬®odinger considered waves which were associated with micro-systems
as real physical waves. He derived an evolutionary equation for the wave associated
with a massive particle, e.g. a non-relativistic electron, moving under the action of
an arbitrary potential V (q).
1.12 References
[1] Khrennikov, A. (2009). Contextual Approach to Quantum Formalism. Springer Verlag,
Berlin, Heidelberg.
[2] Khrennikov, A. (1999). Superanalysis. Kluwer, Dordrecht.
[3] Zeilinger, A. (2010). Dance of the Photons: From Einstein to Quantum Teleportation.
Macmillan; Farrar, Straus & Giroux, New York.
[4] De Martini, F., Sciarrino, F., and Vitelli, Ch. (2008). Schr¬®odinger cat: entanglement
test in a micro-macroscopic system. Physical Review Letters, 100, 253601.
[5] Adenier, G. and Khrennikov, A. (2007). Is the fair sampling assumption supported by
EPR experiments? Journal of Physics B: Atomic, Molecular and Optical Physics, 40,
131‚Äì141.
1.13 Heisenberg‚Äôs symbolic calculus
Somewhat before Schr¬®odinger‚Äôs work, Heisenberg started a new trend in physical
science which can be called symbolism. He made a mathematical observation which

1.13 Heisenberg‚Äôs symbolic calculus
19
was trivial by its very mathematical nature, but it turned out to play a fundamental
role in the further development of quantum theory.
Consider the notion of the Hermitian matrix A = (aij): its elements satisfy
the condition aij = ¬Øaij, where, for a complex number a = a1 + ia2, ¬Øa = a1 ‚àíia2
denotes its conjugate. Heisenberg identiÔ¨Åed discrete values of physical observables
with eigenvalues of Hermitian matrices. In Heisenberg‚Äôs approach, all physical
observables have to be represented by Hermitian matrices.
As is well known from linear algebra,10 any Hermitian matrix of Ô¨Ånite size,
n √ó n, can be diagonalized in the basis consisting of eigenvectors corresponding
to its eigenvalues (eigenvalues are real numbers and eigenvectors are orthogo-
nal). However, matrices in quantum theory are of inÔ¨Ånite size. We shall explain
later in the book why one cannot proceed with matrices of Ô¨Ånite size. In such
a case, some Hermitian matrices cannot be diagonalized. Besides eigenvalues,
their spectra can contain a non-discrete part. It can even happen that there are no
eigenvalues at all, and then such spectra are called continuous. This mathemat-
ical formalism matches the physical situation: some physical observables, such
as the particle‚Äôs position and momentum, are still continuous (as it is in classical
mechanics).
1.13.1 Canonical commutation relations
Heisenberg performed a formal translation of classical Hamiltonian mechanics
(in which observables were given by functions on the phase space) into a new
type of mechanics (quantum mechanics), in which observables are represented by
Hermitian matrices. He correctly noted the crucial role the Poisson brackets could
play in classical formalism. They are deÔ¨Åned for any pair of classical observables,
f1, f2. We remark that Poisson brackets are antisymmetric {f1, f2} = ‚àí{f2, f1}.
A natural operation on the set of Hermitian matrices corresponding to Poisson
brackets is the commutator of two matrices:
[A1, A2] = A1A2 ‚àíA2A1,
(1.44)
deÔ¨Åned with the aid of standard matrix multiplication. Note that the commutator is
anti-symmetric as well. The transformation of the usual multiplication of functions
into matrix multiplication was the great contribution of Heisenberg towards the
creation of quantum formalism. Starting with the classical position and momentum
observables qj, pk (coordinates on the phase space) and the equalities for their
Poisson brackets, see (1.22), (1.23), he postulated that corresponding quantum
observables denoted by ÀÜqj, ÀÜpk (hats are used to distinguish classical and quantum
10 Please see Chapter 4 where various linear algebra concepts are dealt with in more detail.

20
Classical, statistical, and quantum mechanics: all in one
observables, functions and matrices) have to satisfy the following commutation
relations:
[ÀÜqj, ÀÜpj] = ihI, [ÀÜqj, ÀÜpk] = 0, j Ã∏= k;
(1.45)
[ÀÜqj, ÀÜqk] = 0, [ ÀÜpj, ÀÜpk] = 0,
(1.46)
where I is the unit matrix. These commutation relations were called the canonical
commutation relations. The appearance of i in the non-trivial commutator is not
surprising. One cannot simply borrow the relation (1.22) and put the unit matrix
I, instead of the constant function f ‚â°1, on the phase space. Take two Hermitian
matrices A1 and A2 and form their commutator B = [A1, A2]. The latter is a skew-
Hermitian, i.e. its elements satisfy the condition bij = ‚àí¬Øbji. However, the unit
matrix is simply Hermitian; by multiplying it by i, we obtain a skew-Hermitian
matrix iI. The Planck constant h in (1.45) plays a role of scaling factor (the scale
of energy for micro-systems under consideration). One can say that Heisenberg
introduced a non-commutative phase space.
1.13.2 Schr¬®odinger‚Äôs representation
Later Schr¬®odinger found a concrete representation for the quantum observables of
position and momentum, and nowadays authors of textbooks typically simply start
with this (Schr¬®odinger) representation. However, this may give the impression that
Schr¬®odinger‚Äôs concrete choice of the operators of position and momentum ÀÜqj, ÀÜpj
played a primary role in the derivation of the canonical commutation relations.
This was not the case. As was pointed out, Heisenberg really started with classical
Poisson brackets on the phase space variables. As was mentioned in Section 1.11,
Schr¬®odinger considered the wave function of a quantum system as a real physical
wave. Therefore, we work in the space L2(R3) of square integrable complex valued
functions œà : R3 ‚ÜíC, i.e.:

R3 |œà(q)|2dq < ‚àû.
(1.47)
For a shorter notation, one can set H = L2(R3). This is a complex Hilbert space
with the scalar product:
‚ü®œà1, œà2‚ü©(‚â°‚ü®œà1|œà2‚ü©) =

R3 œà1(q)œà2(q)dq.
(1.48)
We note that the Hilbert space is deÔ¨Åned in Chapter 4, Section 4.3. Contrary
to Heisenberg, Schr¬®odinger worked with operators (and not matrices), i.e. he
considered a more general framework. For simplicity, we consider here the

1.13 Heisenberg‚Äôs symbolic calculus
21
one-dimensional case, i.e. of a particle moving on the real line. Here H = L2(R).
He introduced the operators of position and momentum:
ÀÜqœà(q) = qœà(q), ÀÜpœà(q) = ‚àíi¬Øh‚àÇœà(q)
‚àÇq
.
(1.49)
The result of the action of the position operator on the square integrable function
œà(q) (vector in H) leads to another function, q ‚Üíqœà(q). In the same way, the
momentum operator ÀÜp transforms œà(q) into its derivative, up to the constant factor
‚àíi¬Øh. Formally, we can write:
ÀÜq = q, ÀÜp = ‚àíi¬Øh ‚àÇ
‚àÇq .
(1.50)
We remark that H was considered by Schr¬®odinger as the space of classical Ô¨Åelds.
See also Section 1.7 and especially (1.36). Thus, originally the appearance of the
complex Hilbert space to represent operators of position and momentum was just
the operator reformulation of the theory of classical Ô¨Åelds and signals. Of course,
this is correct only with respect to views relative to Schr¬®odinger, but not at all
relative to Heisenberg or Bohr.
1.13.3 Heisenberg‚Äôs dynamics
Finally, Heisenberg put operators satisfying the canonical commutation relations
in the system of the Hamiltonian equation (1.24), instead of the classical phase
space variables. In this way, he derived the basic equations of quantum dynamics:
d ÀÜqj
dt = i
h[ÀÜqj, 
H], d ÀÜpj
dt
= i
h[ ÀÜpj, 
H],
(1.51)
where 
H is a Hermitian matrix representing the energy observable. It is called
the quantum Hamiltonian. Thus, classical and quantum dynamics have the same
form, cf. (1.24) and (1.51). However, the variables have different physical mean-
ings and mathematical representations. In (1.24), the ‚Äúposition‚Äù and ‚Äúmomentum‚Äù
are real valued functions; in particular they commute. In (1.51), the ‚Äúposition‚Äù
and ‚Äúmomentum‚Äù are Hermitian operators (which can be represented by inÔ¨Ånite
Hermitian matrices); they satisfy the canonical commutation relations. In classical
mechanics, the position and momentum are interpreted as objective properties of
systems. In quantum mechanics, these are observables which cannot be considered
as objective properties of quantum systems.

22
Classical, statistical, and quantum mechanics: all in one
1.13.4 Quantization procedure
How can one Ô¨Ånd such a Hamiltonian? Consider the classical Hamilton function
of the form (see also Section 1.3):
H(q, p) = p2
2m + V (q),
(1.52)
where V is a polynomial function, e.g. V (q) = kq2 and k is a real constant. Then
one can construct the corresponding Hermitian matrix, i.e the quantum observable,
by formally putting matrices ÀÜq and ÀÜp in the classical Hamiltonian function, instead
of classical variables. For the aforementioned potential, we obtain:

H = 1
2m ÀÜp2 + k ÀÜq2.
(1.53)
If the potential is not a polynomial, then the mathematics are more complicated.
The operator theory and Schr¬®odinger‚Äôs representation of the canonical commutation
relations have to be used, see Section 1.13.1. The main problem arises for classical
observables, functions on the phase space, which contain products of position and
momentum variables, e.g. f (q, p) = qp. In principle, we can form a family of
matrix expressions corresponding to this function, ÀÜf = Œ± ÀÜq ÀÜp + Œ≤ ÀÜp ÀÜq, where Œ±, Œ≤
are real numbers, Œ± + Œ≤ = 1. However, we obtain the Hermitian matrix only for
Œ± = Œ≤ = 1/2, ÀÜf = (ÀÜq ÀÜp + ÀÜp ÀÜq)/2. This rule is known as the Weyl quantization.11
If one uses the Schr¬®odinger‚Äôs representation of the canonical commutation rela-
tions, i.e. (1.50), the quantum Hamiltonian, (1.52), can be written as:

H = ‚àí¬Øh2
2m
‚àÇ2
‚àÇq2 + V (q),
where V (q) is the operator of multiplication by the function V (q) in the space
of square integrable functions, namely œà(q) ‚ÜíV (q)œà(q). Thus, in Schr¬®odinger‚Äôs
representation all Hamiltonians are simply partial differential operators.
In general, quantization has the meaning of a transition from functions on the
phase space, f (q, p), to Hermitian matrices or more generally operators, by using
operators of position and momentum, instead of corresponding classical variables.
It is important to stress that there is no ‚Äúreasonable explanation‚Äù for such a formal
procedure which is required when transiting from classical physical quantities to
quantum physical quantities. However, it works well.
We remark that one of the problems in the application of quantum formalism to
social sciences (such as economics, Ô¨Ånance, psychology, and cognitive science) is
that, roughly speaking, we do not have classical (such as Newtonian or Hamiltonian)
11 Let f (q, p) = q2p. Find the corresponding matrix representation.

1.14 Heisenbergian symbolism in physics
23
mechanics. In other words, we do not have classical quantities which we can
automatically quantize. Therefore, the majority of quantum-like quantities used in
the aforementioned domains of science are phenomenological. They are invented
by analogy with quantum theory. Hence, and we need to emphasize this, we do
not start with a classical model and then quantize it, but we directly mimic the
quantum approach. This forms one of the important problems of the quantum-like
approach. One possible solution of this problem consists in using phenomenological
Hamiltonians.
1.14 Heisenbergian symbolism in physics: a version of symbolism in art
Heisenberg‚Äôs approach to micro-phenomena was really symbolic (operational).
Heisenberg was not able to present physical reasons (in the classical meaning)
for the introduction of matrices, instead of functions on the phase space. His
calculus was useful to encode observed energy levels in the spectra of Hermitian
matrices, but nothing more.12 Nevertheless, this symbolic approach has been very
fruitful and it played a key role. The history of the creation of quantum mechanics
is an interesting subject for some social scientists. The main positive impact of
Heisenberg‚Äôs symbolic approach was the novelty in the description of physical
phenomena. In fact, this was not a detailed and realistic description as in classical
physics, but instead a fuzzy (operational) description of results of measurements.
We should also mention Bohr‚Äôs contribution who emphasized the role of the so-
called experimental context. For him, it was meaningless to speak about an object
outside of the concrete measurement context. The main negative impact was the
aggressive anti-classical attitude. From the very beginning, Heisenberg claimed that
his symbolic (operational) description of experimental data for micro-systems could
not be derived on the basis of a Ô¨Åner classical-like model of micro-reality. Moreover,
he and Bohr strongly advertised the viewpoint Mach held that it is meaningless
even to try to create such models, since such an activity belongs to the domain of
metaphysics and not real physics.13 One could say that Heisenberg and Bohr were
not correct, since a number of ‚Äúprequantum‚Äù (classical-like) models reproducing
results of quantum experiments have been created, for example Bohmian mechanics
(see Chapter 6) and stochastic electrodynamics. However, it is clear that Heisenberg
and Bohr would not agree with such a statement, as for them ‚Äúprequantum models‚Äù
are metaphysical.
The behavior and writings of Heisenberg and especially Bohr remind us very
much of the manifestos of symbolism and futurism. Please see [1] [2].
12 We note that to Ô¨Ånd theoretically these levels, one has to use Schr¬®odinger‚Äôs approach.
13 This is a good place to recall that Mach intensively attacked Boltzmann by claiming that, since molecules
are not observable (as was the case at that time), they are metaphysical creatures and hence they have to be
excluded from real physical theory. Mach‚Äôs attacks against Boltzmann‚Äôs realism may have played a role in
Boltzmann‚Äôs tragic death.

24
Classical, statistical, and quantum mechanics: all in one
We also mention works of Plotnitsky [3] [4] who analyzed similarities between
‚Äúromanticism‚Äù in literature and ‚Äúromanticism‚Äù in Heisenberg‚Äôs and Bohr‚Äôs writing
see also Khrennikov [5] [6]. Plotnitsky also gave talks on Beckett and quantum
mechanics and on Blake and quantum epistemology. For example, he recently pre-
sented his views at an interdisciplinary workshop (philosophy, Ô¨Ånance, psychology,
quantum physics) at the University of Leicester, UK, November 2011.
1.15 References
[1] Balakian, A. (1967). The Symbolist Movement: A Critical Appraisal. Random House,
New York.
[2] Martin, M. W. (1978). Futurist Art and Theory. Hacker Art Books, New York.
[3] Plotnitsky, A. (1995). All shapes of light: the quantum mechanical Shelley. In Shelley:
Poet and Legislator of the World. Eds. Curran, S. and Bennett, B., Johns Hopkins
University Press, Baltimore, USA.
[4] Plotnitsky, A. (2004). In principle observable: Werner Heisenberg‚Äôs discovery of quan-
tum mechanics and romantic imagination. Parallax, 10, N3, 20‚Äì35.
[5] Khrennikov, A. Yu. (2002). V¬®axj¬®o Interpretation of Quantum Mechanics. Please see:
http://arxiv.org/abs/quant-ph/0202107 and also http://arxiv.org/abs/quant-ph/0401072,
Cornell University.
[6] Khrennikov, A. Yu. (2002). On foundations of quantum theory. In Quantum Theory:
Reconsideration of Foundations. Ed. Khrennikov, A. Series in Mathematical Mod-
elling, 2, 163‚Äì196, V¬®axj¬®o University Press, V¬®axj¬®o, Sweden.
1.16 Completeness of quantum mechanics and a possibility to apply
quantum mechanics outside of physics
Heisenberg was the Ô¨Årst who claimed that a Ô¨Åner description of micro-phenomena
than that given by the matrix representation of physical observables is in principle
impossible. His claim was supported by Bohr who later elaborated the principle of
completeness of quantum mechanics. The main Heisenberg argument was based
on the uncertainty relation:

x
p ‚â•h,
(1.54)
which is related to the Ô¨Årst equality in the canonical commutation relations (1.45).
Heisenberg was sure that, because of the uncertainty relation, the precise position
and momentum cannot be jointly assigned to a quantum system, e.g. to an electron.
Therefore, it is impossible to create a Ô¨Åner description of quantum phenomena,
e.g. based on the classical phase space description.

1.16 Completeness of quantum mechanics
25
Later this interpretation of Heisenberg‚Äôs uncertainty relation was criticized by
Margenau [1] and Ballentine [2]. To understand their point, we remark that Heisen-
berg established the expression (1.54) as the minimum amount of unavoidable
momentum disturbance caused by any position measurement. However, he did not
give a precise deÔ¨Ånition for the uncertainties 
x and 
p. It was Kennard in 1927
who Ô¨Årst proved the modern inequality:
œÉxœÉp ‚â•¬Øh
2,
(1.55)
where ¬Øh = h/2œÄ, and œÉx, œÉp are the standard deviations of position and momen-
tum, respectively. The crucial point is that the standard deviations are statistical
quantities. They can be deÔ¨Åned only through measurements of either position or
momentum for huge ensembles of particles. Therefore the Heisenberg uncertainty
relation (1.55) has nothing to do with the joint determination of position and
momentum for a single particle. This is a statistical (dispersion) relation applica-
ble to an ensemble of systems and describing the interrelation between standard
deviations of positions and momenta of systems in such an ensemble. However,
at the beginning of the twentieth century, the Margenau‚ÄìBallentine argument was
not yet known. Unfortunately, this argument against the ‚Äúnaive interpretation‚Äù of
Heisenberg‚Äôs uncertainty relation is until today practically unknown, and, if it is
known, it is simply discarded in the modern quantum community. By the ‚Äúnaive
interpretation‚Äù we understand this to be a rather common viewpoint to Heisenberg‚Äôs
uncertainty relation: it is impossible to assign to a quantum system both position
and momentum, since, by (1.54), increasing the precision of determining the posi-
tion should automatically decrease the precision of determining the momentum and
vice versa. A closely related interpretation is that it is impossible to perform a joint
measurement of position and momentum with arbitrary high precision. Neither of
these interpretations could be justiÔ¨Åed by (1.54), because in reality one does not
operate with (1.54) (whose meaning is rather unclear), but with (1.55). The latter
has nothing to do with position and momentum of an individual particle. Therefore,
in spite of (1.54), we have Bohmian mechanics (see Chapter 6) in which position
and momentum of a quantum particle are well deÔ¨Åned.
Niels Bohr inspired by Heisenberg‚Äôs discovery concluded that quantum mechan-
ics is complete. Even the grandchildren of our grandchildren will not be able to
Ô¨Ånd a Ô¨Åner description of micro-phenomena . . . At the time of Bohr‚Äôs writing, the
‚ÄúÔ¨Åner description‚Äù had the meaning ‚Äúspace time description.‚Äù Later the ortho-
dox ‚ÄúCopenhagenists‚Äù14 generalized this principle of impossibility to any kind of
14 The word ‚ÄúCopenhagenists‚Äù comes from the Bohr‚ÄìHeisenberg Copenhagen interpretation of quantum mechan-
ics. By this interpretation, the wave function of a quantum system provides the most complete description of
its state, i.e. no Ô¨Åner description could be created.

26
Classical, statistical, and quantum mechanics: all in one
additional variables which might improve the quantum description. Nowadays,
such variables are known under the name hidden variables. When this term was
coined, the idea was that position and momentum were known. What was hidden
was only the pair of those variables, i.e. a point of the phase space. The complete-
ness of quantum mechanics implies that determinism cannot be recovered through
a Ô¨Åner description. Thus, instead of the symbolic dynamics of Hermitian matrices,
a more detailed dynamics, e.g. in space time, cannot be constructed.
We state again that one has to distinguish determinism as a general philosophic
principle from its applications to real phenomena. As was remarked, even in clas-
sical mechanics determinism can be violated by dynamics with some (continuous)
forces f (q). Moreover, the initial conditions (position and velocity) cannot be
determined with inÔ¨Ånite precision. If the dynamics are unstable, a small pertur-
bation can change the trajectory crucially. In this case, the principle of deter-
minism has merely a theoretical value.15 For an ensemble consisting of a huge
number of particles, in practice we can operate only with probabilities and the
dynamics will be given by the Liouville equation. The fact of the existence of the
underlying Hamiltonian mechanics has merely a metaphysical value: positions and
momenta can be really assigned to individual particles and these quantities can be
imagined as evolving in space independently of our measurements. By the Bohr‚Äì
Heisenberg approach, it is sufÔ¨Åcient to operate only with probabilities for results of
measurements.
A reader may be curious and ask the following question: ‚ÄúWhy do we need all
these philosophic considerations on the completeness of quantum mechanics?‚Äù The
main problem is that we want to use quantum mathematics without having to share
the views of Bohr and Heisenberg, i.e. the so-called Copenhagen interpretation
of quantum mechanics. Our position is that we consider Heisenberg‚Äôs discovery
as merely a discovery of a new mathematical formalism describing results of
measurements for systems characterized by a high sensitivity to external inÔ¨Çuences.
The reader can hopefully understand our dilemma: we want to use the total power
of the quantum operational (symbolic) approach and at the same time we do not
want to give up realism. The latter is very important for us. The very subject of this
book is tied to this position we adopt. We plan to apply quantum mathematics to
social and cognitive phenomena. We cannot forget (even if we wished) that these
phenomena are based on classical physical processors of information, the brains
(individual and collective).
15 We remark that classical mechanical determinism is rigidly coupled to the mathematical model of space-time,
namely to the real continuum. The states of classical systems are given by pairs of real numbers (or by pairs of
real vectors). The inÔ¨Ånite divisibility of this space plays an important role, cf. with p-adic spaces which have
been recently used in theoretical physics [3].

1.16 Completeness of quantum mechanics
27
We are well aware of attempts to create models of a so-called quantum brain (see
also Chapter 14). In such models, quantum processes at the micro-level induce our
mental activity, see e.g. Penrose and Hameroff [4] [5]. However, we do not want to
couple our modeling to this very special model of the brain‚Äôs activity. In particular,
we do not want to give up the neuronal paradigm of neurophysiology and cognitive
science. Neurons are classical processors of electrical signals. Therefore, we try
to convince the reader that the arguments of Bohr and Heisenberg about the com-
pleteness of quantum mechanics were not fully justiÔ¨Åed. The structure of quantum
mathematics does not exclude a possibility of a peaceful coexistence, of e.g. clas-
sical signal processing of information in the brain (performed by neurons) and the
quantum probabilistic description of the results of (self-)measurements performed
by the brain! Please see again Chapter 14 for more details. A similar viewpoint
was presented by de Barros and Suppes [6]: classical oscillatory processes in the
brain can in principle induce information processing which has to be described by
the mathematical formalism of quantum mechanics. We can also mention Nelson‚Äôs
stochastic quantum mechanics [7] in which quantum probabilistic behavior can
be reduced to classical randomness. See also Chapter 13 for more details on this
approach.
When considering a quantum-like model of the functioning of the brain pro-
posed in [8], the brain processes concrete mental images by using a classical
representation of information. However, abstract mental images, such as concepts,
are processed on the basis of the quantum-like representation of information. A
physical mechanism of creation of the quantum-like representation of classical
signals is presented. Quantum-like images are encoded by covariance matrices
of classical signals. In the quantum terminology, these are density matrices. Thus
concepts are represented by density matrices (which are in fact classical covariance
matrices). The same model can be applied to ‚Äúcollective brains‚Äù and thus social
systems.
Thus, we do not merely reject the Bohr‚ÄìHeisenberg thesis about completeness
of quantum mechanics. We explore the incompleteness of the quantum (and more
general quantum-like) description. Our main claim is that such a description is
useful precisely in situations in which the complete information is not available
or even if it is available it is impossible to process it in the complete setting.16 A
cognitive system must make a cut-off in the information space. But such a cut-off
has to be done in a consistent way. This can be done by using quantum information
theory. In our approach, the latter is simply a version of classical information theory
adjusted for the processing of incomplete information.
16 For example, a cognitive (social) system does not have time or computational resources to analyse the complete
data about a problem.

28
Classical, statistical, and quantum mechanics: all in one
For applications to social systems, it is important to know that such systems can
process information in a quantum-like way just as it occurs in macroscopic classical
systems. Thus, instead of all the quantum mysteries, we have ‚Äúonly‚Äù special formal
schemes of processing of incomplete information. Our main thesis is that social
systems developed the ability to use such quantum-like scheme of information
processing and decision making.
1.17 References
[1] Margenau, H. (1950). The Nature of Physical Reality. McGraw-Hill, New York.
[2] Ballentine, L. E. (1989). Quantum Mechanics. Prentice Hall, Englewood Cliffs, NJ.
[3] Khrennikov, A. Yu. (1997). Non-Archimedean analysis: Quantum Paradoxes, Dynam-
ical Systems and Biological Models. Kluwer, Dordrecht.
[4] Penrose, R. (1994). Shadows of the Mind. Oxford University Press.
[5] Hameroff, S. (1994). Quantum coherence in microtubules: a neural basis for emergent
consciousness? Journal of Consciousness Studies, 1, 91‚Äì118.
[6] de Barros, J. A. and Suppes, P. (2009). Quantum mechanics, interference, and the brain.
Journal of Mathematical Psychology, 53, 306‚Äì313.
[7] Nelson, E. (1985). Quantum Fluctuations. Princeton University Press, NJ.
[8] Khrennikov, A. Yu. (2010). On the physical basis of the theory of ‚Äúmental waves.‚Äù
Neuroquantology, 8, 4 (Suppl. 1), S71‚ÄìS80.
1.18 Brownian motion
The creation of a mathematical model of so-called ‚ÄúBrownian motion‚Äù was a
crucial step towards the probabilistic description of physical reality. Maybe we can
claim it was not less important than the creation of the quantum formalism?17 We
would like to compare the probabilistic dynamics of the Brownian motion (also
known as the Smoluchowski equation) with the probabilistic dynamics of quantum
particles (given by the Schr¬®odinger equation). The consideration of the probabilistic
dynamics given by the Smoluchowski equation and not by the Liouville equation
has an important philosophic impact. By creating a mathematical model of the
Brownian motion, physicists understood that the Hamiltonian phase space model
cannot be directly applied to this (classical) phenomenon. The basic problem is
that in general the velocity of a Brownian particle is not well deÔ¨Åned; its trajectory,
although continuous, is not differentiable. Therefore, instead of the probability
density œÅ(q, p) deÔ¨Åned on the phase space, one has to use the probability density
of spatial coordinates œÅ(q).
The q-space is often called conÔ¨Åguration space.
17 In this chapter we are interested in physics, but it has to be remarked that the Ô¨Årst mathematical construction
of the corresponding stochastic process was done in Ô¨Ånance; in the doctoral thesis of Louis Bachelier [1] in
1900, see also Section 2.1.

1.18 Brownian motion
29
In phase space mechanics, it is always possible to obtain the conÔ¨Åguration space
density from the phase space:
œÅ(t, q) =

œÅ(t, q, p)dp.
(1.56)
The Liouville dynamics on the phase space induce the dynamics of the probability
density on the conÔ¨Åguration space.
Suppose now that q(t) is continuous, but not differentiable. Then the velocity
(and, hence, the momentum) is not well deÔ¨Åned. Nevertheless, the density on the
conÔ¨Åguration space is used to Ô¨Ånd the probability that the particle‚Äôs coordinate q
belongs to a domain V of the conÔ¨Åguration space:
P(q(t) ‚ààV ) =

V
œÅ(t, q)dq.
(1.57)
The problem of the derivation of the corresponding dynamical equation for œÅ(t, q)
now arises.
The simplest probabilistic dynamics of this type correspond to the Brownian
motion. In a few words, we can say that a particle moves in a linear fashion
colliding with a molecule which changes the direction of motion, and again the
particle resumes a same linear based movement. Note that at the points of collision
the velocity is not well deÔ¨Åned. Einstein and Smoluchowski found the form of this
probability density to be of the Gaussian form:
œÅ(t, q) =
1
‚àö
2œÄt
e‚àíq2/2t,
(1.58)
and then by calculating its derivatives they found that this function satisÔ¨Åes the
partial differential equation:
‚àÇœÅ(t, q)
‚àÇt
= 1
2
‚àÇ2œÅ(t, q)
‚àÇq2
.
(1.59)
This partial differential equation formally (i.e. from a mathematics point of view)
coincides with the Fokker‚ÄìPlanck partial differential equation. See Chapter 2.
However, physically they are different: the Smoluchowski‚Äôs equation describes the
probability density of position and the Fokker‚ÄìPlanck‚Äôs equation is the equation for
the probability density of velocity. Equation (1.59) describes the dynamics of the
probability density on the conÔ¨Åguration space. If one knows the initial probability
density œÅ(t0, q) = œÅ0(q), it is possible to Ô¨Ånd the density at any instant of time
t > t0.
However, the knowledge of the initial position q(t0) = q0 of a particle does
provide a possibility to determine uniquely its state q(t), t > t0. The dynamics
depend on a chance parameter, say œâ, q ‚â°q(t, œâ). Formally, if œâ was known in

30
Classical, statistical, and quantum mechanics: all in one
advance, it would be possible to recover determinism along the trajectory t ‚Üí
q(t, œâ). However, œâ is never known. For example, for a Brownian particle, œâ
includes the knowledge of all possible collisions which will occur for this particle!
Hence, the principle of determinism has no practical value for classical stochastic
processes.
One natural way to recover determinism is to use a coarser description of
reality, namely to deÔ¨Åne states of particles not as points of the conÔ¨Åguration
space, but as probability densities on this space. The dynamics (1.58) emerg-
ing from such an approach are deterministic. We shall speculate that some-
thing similar was done in quantum mechanics. However, this ‚Äúrecovery of deter-
minism‚Äù for the Brownian motion has an unexpected consequence and that is
‚Äúnon-locality‚Äù of this model! This is a rather unexpected statement: non-locality
of classical dynamics! To illustrate this viewpoint, we proceed to the multi-
dimensional case.
In the multi-dimensional case, the Cauchy problem18 for Smoluchowski‚Äôs equa-
tion has the form:
‚àÇœÅ(t,q1,...,qN)
‚àÇt
= 1
2
N
j=1 
qjœÅ(t, q1, . . . , qN),
(1.60)
œÅ(t0, q1, . . . , qN) = œÅ0(q1, . . . , qN),
(1.61)
where Laplace operators 
qj are deÔ¨Åned as:

qjœÅ = ‚àÇ2œÅ
‚àÇx2
j
+ ‚àÇ2œÅ
‚àÇy2
j
+ ‚àÇ2œÅ
‚àÇz2
j
,
and qj = (xj, yj, zj), j = 1, . . . , N. If the initial density is factorizable:
œÅ0(q1, . . . , qN) = œÅ01(q1) . . . œÅ0N(qN),
(1.62)
i.e. at the initial instant of time t = t0 particles are independent, then the solution
of equation (1.60) can be found in the form:
œÅ(t, q1, . . . , qN) = œÅ1(t, q1) . . . œÅN(t, qN),
(1.63)
with:
œÅj(t0, qj) = œÅ0j(qj), j = 1, . . . , N.
(1.64)
18 We state again that this is a dynamical equation with initial conditions.

1.20 The Schr¬®odinger equation
31
Thus, the Cauchy problem (1.60), (1.61) can be separated into a system of inde-
pendent problems:
‚àÇœÅj(t, qj)
‚àÇt
= 1
2
qjœÅj(t, qj),
(1.65)
œÅj(t0, qj) = œÅ0(qj).
(1.66)
Such a dynamics can be called local: the dynamics of the state (in the sense of
the probability density) of the jth particle has no inÔ¨Çuence on the dynamics of
the ith particle, i Ã∏= j. We state again that equation (1.60) describes the motion of
non-interacting Brownian particles.
However, if the initial density is not factorizable, i.e. at t = t0 particles are not
independent, they will be correlated (e.g. as the result of the common preparation
procedure), and then we cannot use the ansatz (1.63) and split the Cauchy problem
for Smoluchowski‚Äôs equation, see (1.60), (1.61).
Thus, in the very classical situation, the Brownian motion, the determinism
(realism) may be incompatible with locality. An attempt to recover the former
through the usage of a coarser mathematical description, via the interpretation of
a probability density as a state of a system, may lead to the impossibility to treat
independently the dynamics of N non-interacting Brownian particles.
We remark that little attention is paid to this trivial mathematical fact: initial
correlations can have an impact on further dynamics. We have presented here this
‚Äúdeterminism‚Äìlocality‚Äù analysis of the Brownian motion to keep closer to typical
discussions of quantum foundations. We shall see that the quantum situation will
remind us very much of our presentation of the ‚Äúdeterminism‚Äìlocality‚Äù problem in
the classical theory of random processes, see [2] (in Russian) for more detail.
1.19 References
[1] Bachelier, L. (1900). Th¬¥eorie de la Sp¬¥eculation. Annales scientiÔ¨Åques de l‚ÄôEcole Nor-
male Sup¬¥erieure, 21‚Äì86.
[2] Khrennikov, A. (2008). Introduction to Quantum Information Theory. Nauka, Fizmatlit,
Moscow (in Russian).
1.20 The Schr¬®odinger equation
It is clear that the dynamics of a quantum particle cannot be simpler than the
dynamics of a Brownian particle: a quantum particle collides not only with other
particles, but also with Ô¨Åelds. Moreover, it is evident that the picture of the vacuum
as the totally empty space does not match physical reality: the random background

32
Classical, statistical, and quantum mechanics: all in one
is present everywhere.19 Therefore, one could not expect that it would be possi-
ble to construct the phase space dynamics of the Hamiltonian type for quantum
particles. The dynamics of œÅ(t, q) were needed. In principle, we might refer to
Heisenberg‚Äôs uncertainty relation with the original Heisenberg interpretation: posi-
tion and momentum cannot be jointly determined. However, we prefer to use purely
classical arguments.
Roughly speaking, in quantum mechanics the following ansatz was used:
œÅ(t, q) = œà2(t, q).
(1.67)
So, it was proposed to search for a ‚Äúdensity amplitude‚Äù œà(t, q) (wave function)
and not directly for a density. At the beginning (in the pioneering studies of
Schr¬®odinger), this amplitude was real. Later it was proposed to extend this ansatz
and consider complex amplitudes, i.e. to look for a density which is represented as:
œÅ(t, q) = |œà(t, q)|2,
(1.68)
where œà(t, q) takes values in the Ô¨Åeld of complex numbers C. The correct equation
for this probability amplitude is the famous Schr¬®odinger equation. We write it
directly for an N-particle system:
i¬Øh‚àÇœà(t, q1, . . . , qN)
‚àÇt
= ‚àí
N

j=1
¬Øh2
2mj

qjœà(t, q1, . . . , qN)
+ V (q1, . . . , qN)œà(t, q1, . . . , qN),
(1.69)
œà(t0, q1, . . . , qN) = œà0(q1, . . . , qN),
(1.70)
where mj is the mass of the jth particle and V is a potential. In the modern presen-
tation of quantum mechanics, this dynamical equation is simply postulated. There
are no reasonably justiÔ¨Åed derivations of Schr¬®odinger‚Äôs equation in conventional
quantum theory. The original Schr¬®odinger derivation was heuristic and it had little
to do with modern quantum theory. When quantum theory was being developed,
Schr¬®odinger considered the œà-function (at least for a single particle) as a real
physical Ô¨Åeld.20
19 Although Copenhagenists (see Section 1.16) had never accepted Planck‚Äôs viewpoint of the spontaneous emis-
sion of light by atoms, in modern quantum theory, especially quantum Ô¨Åeld theory, the vacuum is also considered
as a highly complex structure which can produce experimentally observable effects, e.g. the Casimir effect.
Although formally classical Ô¨Åeld and quantum viewpoints of the vacuum are totally different, the resulting
picture of the vacuum as the actively acting environment is practically the same.
20 Feynman claimed that he derived Schr¬®odinger‚Äôs equation by using the formalism of the path integral, e.g.
[1]. However, since he treated the path integral formally, merely as a symbol, his ‚Äúderivation‚Äù cannot be
considered as rigorous. In a series of papers of one of the authors [2]‚Äì[4], it was shown that by representing
the œà-function in the form œà(t, q) = Q(t, q) + iP (t, q), where Q and P are the real and imaginary parts
of œà, Schr¬®odinger‚Äôs equation can be written as a system of Hamiltonian equations with respect to the Ô¨Åeld
variables Q and P. Thus, the Schr¬®odinger equation is a special case of the Hamiltonian dynamics for the Ô¨Åeld

1.20 The Schr¬®odinger equation
33
If one assumes that quantum mechanics is complete, i.e. the state of a quantum
system is given by the wave function œà (and any Ô¨Åner description is forbidden),
then the theory is deterministic: the knowledge of the initial condition, (1.70),
provides the knowledge of the wave function at any instant of time. Under natural
conditions, the Cauchy problem (1.69), (1.70) has the unique solution. Of course,
the price to be paid for obtaining such determinism is to allow for the probabilistic
nature of a quantum state. In the same way as for the Brownian motion, we are also
equally aversive by the fundamental non-locality of quantum dynamics.
Let us now present the quantum analogue of the consideration which was pre-
sented for the Smoluchowski equation for a system of classical particles.
Suppose that there are no mutual interactions between different particles, i.e.:
V (q1, . . . , qN) = V1(q1) + ¬∑ ¬∑ ¬∑ + VN(qN).
(1.71)
If the initial wave function is factorizable:
œà0(q1, . . . , qN) = œà01(q1) . . . œà0N(qN),
(1.72)
then the solution of equation (1.69) can be found in the form:
œà(t, q1, . . . , qN) = œà1(t, q1) . . . œàN(t, qN),
(1.73)
with:
œàj(t0, qj) = œà0j(qj), j = 1, . . . , N.
(1.74)
Thus the Cauchy problem (1.69), (1.70) can be separated into a system of indepen-
dent problems:
i¬Øh‚àÇœàj(t, qj)
‚àÇt
= ‚àí¬Øh2
2mj

qjœàj(t, qj) + Vj(qj)œàj(t, qj),
(1.75)
œàj(t0, qj) = œà0(qj).
(1.76)
Such dynamics are local: the dynamics of the state (in the sense of the probability
amplitude) of the jth particle has no inÔ¨Çuence on the dynamics of the state of the
ith particle, i Ã∏= j.
We remark that the factorization of the wave function implies factorization of
the probability density, and hence independence of different particles. However,
phase space (we remark that such phase space is inÔ¨Ånitely dimensional). We state again that the system of
Maxwell equations for the classical electromagnetic Ô¨Åeld can also be represented as the Hamiltonian system
with respect to the Ô¨Åeld variables. Therefore, Schr¬®odinger‚Äôs equation can be considered as the generalization of
the Maxwell equation for the case of massive particles. However, such an interpretation is incompatible with
the conventional interpretation of the wave function.

34
Classical, statistical, and quantum mechanics: all in one
the analogy between classical Brownian motion and the dynamics of a system of
quantum particles is not complete. The factorizability of the density, i.e. the prob-
abilistic independence of particles, does not imply factorization of the probability
amplitude. For example, take:
œà0(q1, q2) = eiqpœà01(q1)œà02(q2).
(1.77)
Then:
œÅ0(q1, q2) = |œà0(q1, q2)|2 = |œà01(q1)|2|œà02(q2)|2 = œÅ01(q1)œÅ02(q1).
(1.78)
For such an initial œà-function, we are not able to split the Cauchy problem (1.69),
(1.70) into the system of independent problems (1.75), (1.76). Thus, classical
probabilistic independence of initial conditions does not provide independence of
dynamics. This is the essence of quantum non-locality. Within the conventional
(Copenhagen) approach, this observation is difÔ¨Åcult to comprehend. Pilot wave
theory was one of the Ô¨Årst theories which took this observation seriously (Bohmian
mechanics is an improvement of the de Broglie‚Äôs double solution model). See also
Chapter 6 for more details on Bohmian mechanics. This theory was one of the Ô¨Årst
attempts to go beyond quantum mechanics and create a Ô¨Åner (in fact, space time)
description of the micro-phenomena.
The so-called prequantum classical statistical Ô¨Åeld theory (PCSFT) is a promis-
ing new approach which may go beyond quantum physics [3]. In this model,
quantum non-locality has been reduced to classical correlations in the background
Ô¨Åeld.
Our analysis of quantum non-locality differs from conventional considerations.
In the conventional presentation, quantum non-locality is a consequence of quantum
entanglement, i.e. the existence of wave functions of the form:
œà(q1, q2) = œà1(q1)œà2(q2) + œà2(q1)œà1(q2),
(1.79)
where œà1 Ã∏= œà2. From a (mathematical) point of view, it is impossible to factorize
the wave function of the composite system S = (S1, S2), where S1 and S2 are two
systems. Factorization can be written as:
œà(q1, q2) = œà1(q1)œà2(q2).
(1.80)
Typically, one may not always pay attention to the following trivial mathematical
fact. If the corresponding probability density is not factorizable:
œÅ(q1, q2) Ã∏= œÅ1(q1)œÅ2(q2),
(1.81)
i.e.:
|œà(q1, q2)|2 Ã∏= |œà1(q1)|2|œà2(q2)|2.
(1.82)

1.22 Do not be afraid of no-go theorems!
35
The impossibility to split the Cauchy problem for the Schr¬®odinger equation has the
purely classical probabilistic explanation: initial correlations will affect the future
dynamics. Thus, the correlation of phases (and not the coordinates) is the essence
of quantum entanglement.
Thus, the quantum multi-particle correlations have a lot in common with multi-
particle correlations of classical particles (see [5] for a deep analogy between
quantum entanglement and correlation of classical Brownian motions). However,
quantum correlations cannot be totally reduced to the classical. Besides the cor-
relations of particle coordinates, the correlations of phases, encoded in the wave
function (complex probability amplitude), play an important role.
1.21 References
[1] Feynman, R. and Hibbs, A. (1965). Quantum Mechanics and Path Integrals. McGraw-
Hill, New York.
[2] Khrennikov, A. (2006). Prequantum classical statistical Ô¨Åeld theory: complex rep-
resentation, Hamilton‚ÄìSchr¬®odinger equation, and interpretation of stationary states.
Foundations of Physics Letters, 19, 299‚Äì319.
[3] Khrennikov, A. (2005). A pre-quantum classical statistical model with inÔ¨Ånite-
dimensional phase space. Journal of Physics A: Mathematical and General, 38, 9051‚Äì
9073.
[4] Khrennikov, A. (2009). Entanglement‚Äôs dynamics from classical stochastic process.
Europhysics Letters, 88, 40005.1‚Äì6.
[5] Allahverdyan, A., Khrennikov, A., and Nieuwenhuizen, Th. M. (2005). Brownian
entanglement. Physical Review A, 71, 032102-1‚Äì032102-14.
1.22 Do not be afraid of no-go theorems!
The so-called ‚Äúno-go theorems‚Äù (see von Neumann [1] [2], Bell [3], and Kochen-
Specker [4]) are often considered as a barrier on the way towards applications
of quantum formalism, outside physics. Since the mathematical statements made
about the completeness of quantum mechanics are taken as mathematical proofs,
there is an impossibility to combine quantum formalism and realism. The majority
of scientists are sure that quantum phenomena cannot be emergent from some
classical phenomena. As was already emphasized, such a scientiÔ¨Åc ideology is not
acceptable by the authors of this book. Therefore, we have to present arguments
against the common interpretation of no-go theorems. A detailed analysis of no-go
ideology was performed in [1]. No-go theorems are statements about the impossi-
bility to construct ‚Äúprequantum models‚Äù reproducing the probabilistic predictions
of quantum mechanics and operating with classical probabilities. The main point
is that physics cannot tell us anything about the features of such models and their
coupling with the quantum model. How can one hope to prove that something does

36
Classical, statistical, and quantum mechanics: all in one
not exist without any knowledge (or at least not much) about this ‚Äúsomething‚Äù?
Therefore, each author of a no-go theorem, in fact, formulates a list of features
of a ‚Äúprequantum model‚Äù and its correspondence with the quantum model. Then
the author proves that his list of assumptions is in contradiction with quantum for-
malism. Hence, instead of the standard conclusion that the classical probabilistic
description is incompatible with the quantum description, we can say that the list
of assumptions underlying a no-go theorem is not properly formulated. Therefore,
the contradiction with quantum formalism is not surprising. We remark that the
situation is made more complicated by the vague formulations of no-go theorems.
The authors of these theorems, e.g. von Neumann and Bohr, use some ‚Äúhidden
assumptions‚Äù which play an important role in ‚Äúderivations‚Äù (see [1] for an analysis
of hidden assumptions in Bell‚Äôs theorem). We cannot say it better than Bell [3]
himself: ‚Äúlong may Louis de Broglie continue to inspire those who suspect that
what is proved, by impossibility proofs, is lack of imagination.‚Äù21
Hence, we recommend to researchers applying quantum formalism outside quan-
tum physics: do not be afraid of no-go theorems! However, one has to use the
lessons of the no-go activity. It seems that no-go statements work against classi-
cal mechanics of particles, but not against classical wave models. We claim that
classical waves and oscillatory processes can produce quantum (or more general
quantum-like) representations of information, see [4], and Chapter 14.
1.23 References
[1] von Neumann, J. (1932). Mathematische Grundlagen der Quantenmechanik. Springer
Verlag, Berlin.
[2] von Neumann, J. (1955). Mathematical Foundations of Quantum Mechanics. Princeton
University Press, New Jersey.
[3] Bell, J. (1987). Speakable and Unspeakable in Quantum Mechanics. Cambridge Uni-
versity Press.
[4] Kochen, S. and Specker, E. (1967). The problem of hidden variables in quantum
mechanical systems. Journal of Mathematics and Mechanics, 17, 59‚Äì87.
21 We recall that de Broglie also advertised the viewpoint that one has not yet found a proper prequantum model.

2
Econophysics: statistical physics and social science
2.1 Science and social science: econophysics?
Economics and Ô¨Ånance have for long used concepts drawn from the exact sciences.
Famous economists such as Vilfredo Pareto, Nobel Prize winners Paul Samuelson
and Maurice Allais, and many others, all used concepts from the exact sciences in
order to aid them in modeling economic phenomena.
As we mentioned already in a footnote in Section 1.18 of Chapter 1, Louis
Bachelier [1] submitted in 1900 a doctoral thesis in mathematics on the use of
a Brownian motion (of the arithmetic type) as a general descriptor of an asset
price process. Paul Samuelson [2] proposed, 60 years later, to use the geometric
Brownian motion so as to allow for the fact that asset prices cannot be negative. This
Brownian motion becomes then a major ingredient in the famous Black‚ÄìScholes
option pricing theory [3].
The famous American mathematician, John von Neumann1 (with economist O.
Morgenstern), wrote the basics of game theory. Their book [4], entitled Theory of
Games and Economic Behavior, which Ô¨Årst appeared in 1947, is the ‚Äúclassic‚Äù of
any game theorist‚Äôs library.
Important contributions to theoretical economics were also proposed by Gerard
Debreu [5], a Nobel Prize winner in economics (and a mathematician by training),
on the development of the so-called core of the economy.
Leonard Savage [6], a famous statistician, developed the Savage expected util-
ity2 model (1954), where subjective probabilities are used in the calculation of
expected utility. Robert Aumann [7], also a mathematician by training and a recent
economics Nobel Prize laureate, developed the so-called Anscombe‚ÄìAumann
approach (1963), where expected utility is measured with a mixture of subjec-
tive and objective probabilities.
1 See for instance reference to von Neumann in Section 1.22 of Chapter 1 in the context of no-go theorems.
2 We refer the interested reader to Chapter 7, where we expand more on the meaning of utility functions.
37

38
Econophysics: statistical physics and social science
The Savage expected utility model mentioned above was found to have inconsis-
tencies in its axiomatic content. As an example, the Ellsberg paradox [8], which we
also discuss in much more detail in Chapter 8, indicates that the famous sure-thing
principle, a key assumption of the Savage model, can be refuted on experimen-
tal grounds. The theoretical economics community has attempted to answer the
shortcomings laid bare by the Ellsberg paradox.
In light of this very brief overview, how can we understand the birth of the
so-called ‚Äúeconophysics‚Äù movement? What does ‚Äúeconophysics‚Äù stand for?
From a symptomatic perspective, the econophysics community is mainly com-
posed of physicists (but we can also count some social scientists in that community)
who are interested in explicitly using physics techniques and concepts in the social
sciences. Econophysics does not only target economics or Ô¨Ånance. One can Ô¨Ånd
applications of physics concepts in sociology and even religious studies. We note
that the econophysics movement is not characterized by social scientists attempting
to apply social science concepts in physics.
It is very much debatable how the econophysics movement came into being. The
book by Nikolae Georgescu-Roegen [9], a Harvard economist, could possibly be
seen as a starting point for the movement. Bertrand Roehner [10] in a survey paper
on the econophysics movement, indicates that the term ‚Äúeconophysics‚Äù was coined
for the very Ô¨Årst time in a talk delivered by Eugene Stanley at a statistical physics
meeting held in August 1995 in Xiamen (China). In effect, Eugene Stanley may
well be called the founding father of the movement. As editor-in-chief of the journal
Physica A, numerous articles on the topic of econophysics have been published in
that journal. Rosario Mantegna and Stanley [11] published a successful handbook
on some of the basics of econophysics as early as 1999. Thomas Lux and Marchesi
[12], succeeded in publishing an economics article in the famous journal Nature
in 1999. In 2006, economist Xavier Gabaix joint with Eugene Stanley (and others)
[13] published a highly cited econophysics article in the top-notch economics
journal, Quarterly Journal of Economics.
Can we now come to a clearer deÔ¨Ånition of what econophysics is? Not really!
Most of the literature in econophysics will be characterized by the use of mainly
statistical physics techniques to social science areas of application. A frequently
used concept in econophysics is the so-called power law. A lot of important econo-
physics work has indeed attempted to Ô¨Ånd the existence of such power laws in
economic data. Please consult for instance Mantegna and Stanley [11]. We will
show some other examples of simple econophysics applications later in this chapter.
Maybe we can try to deÔ¨Åne the econophysics movement by what it is not.
Econophysics does not seem to be concerned with applying quantum physical
concepts to social science problems. It is in that sense that econophysics is distinct
from what we would dare to call ‚Äúquantum social science.‚Äù For a much more
extensive discussion, please see Chapter 3, Section 3.1.

2.1 Science and social science
39
As the reader may have noticed, this book is thus not about econophysics. Instead
this book is very much pre-occupied with attempting to convince the reader that
simple quantum mechanical concepts can be employed to good use in a variety
of social science settings. In Chapter 3, we will be focussing on explaining, in
substantial detail, what so-called ‚Äúquantum social science‚Äù is all about. Part III
of the book will examine quantum probabilistic effects in psychology, while
Part IV will consider quantum probabilistic effects in economics, Ô¨Ånance, and
brain sciences. The classical stochastic model of a Ô¨Ånancial process presented in
this chapter (see Sections 2.3 and 2.7) plays an important role in the transition to
quantum models, which we propose in Part IV of this book (notably Chapters 11,
12, and 13).
From the outset, we need to mention that one of the main problems which
emerge when considering applications of the quantum formalism to the social
sciences (particularly in Ô¨Ånance and economics) is that we cannot perform the
so-called ‚Äúquantization procedure,‚Äù i.e. the transition from classical to quantum-
like quantities, by simply using operators instead of classical Ô¨Ånancial variables.
Surprisingly, the problem is not in the formalism of the transition (i.e. quantization)
by itself, but in the absence of a Ô¨Ånancial analogue of classical statistical mechanics,
cf. Chapter 1. To proceed to quantum-like Ô¨Ånancial modeling we need to operate
with classical quantities such as Ô¨Ånancial energy, momentum, and so on. As was
pointed out already, current Ô¨Ånancial mathematics does not provide us with such
quantities. Nevertheless, some analogs and motivations can be extracted from
classical Ô¨Ånance. One of the crucial points when considering the coupling of
classical and quantum Ô¨Ånance is the usage of the basic classical Ô¨Ånancial model
which refers to the fundamental equation of classical statistical mechanics, i.e. the
Fokker‚ÄìPlanck equation.3 Therefore, we present below in brief detail applications
of this equation in classical Ô¨Ånance. From these considerations, we also get the
motivation to introduce Ô¨Ånancial analogs of potential, energy, and momentum ‚Äì
see Section 2.5.
As we already indicated above, the theory of classical stochastic processes is
actively used in Sections 2.3 and 2.7. We have tried to present the fundamentals of
classical stochastic Ô¨Ånance in a simple and brief way. Nevertheless, readers who
have never used stochastic calculus may encounter resistance to proceed easily
through these sections. In principle, these sections can be omitted (at least during
a Ô¨Årst reading). We remark that a brief introduction to the theory of classical
stochastic processes is presented in Chapter 4, Section 4.18.
In the next section, we consider a simple economics application of the for-
ward Kolmogorov partial differential equation, also known as the ‚ÄúFokker‚ÄìPlanck‚Äù
3 Mathematically, the Fokker‚ÄìPlanck equation coincides with the Smoluchowski equation, see Chapter 1,
Section 1.18 (on the probabilistic description of the trajectories of Brownian motion).

40
Econophysics: statistical physics and social science
partial differential equation. In the next section (Section 2.5), we brieÔ¨Çy discuss
potential and kinetic energy equivalents in economics. In Section 2.7, we show an
example of a very famous backward Kolmogorov partial differential equation: the
Black‚ÄìScholes partial differential equation. The Black‚ÄìScholes model aids in pric-
ing Ô¨Ånancial derivative products. In the penultimate Section 2.9, we give a Ô¨Çavor of
the wonderfully ‚Äúweird‚Äù world of Ô¨Ånance, where fake probabilities are high up the
agenda to solving asset pricing problems. We Ô¨Ånish the chapter with a very short
section, which has the sole aim to ‚Äúwhet the appetite‚Äù on how quantum mechanics
can be connected to basic option pricing. No quantum mechanics knowledge is
required at this stage.
2.2 References
[1] Bachelier, L. (1900). Th¬¥eorie de la sp¬¥eculation. Annales scientiÔ¨Åques de l‚ÄôEcole
Normale Sup¬¥erieure, 21‚Äì86.
[2] Samuelson, P. (1965). Proof that properly anticipated prices Ô¨Çuctuate randomly. Indus-
trial Management Review, 4, 41‚Äì50.
[3] Black, F. and Scholes, M. (1973). The pricing of options and corporate liabilities.
Journal of Political Economy, 81, 637‚Äì659.
[4] von Neumann, J. and Morgenstern, O. (1947). Theory of Games and Economic
Behavior. Princeton University Press, New Jersey.
[5] Debreu, G. (1959). Theory of Value: An Axiomatic Analysis of Economic Equilibrium.
Yale University Press, New Haven, CT.
[6] Savage, L. J. (1954). The Foundations of Statistics. J. Wiley, New York.
[7] Anscombe, F. and Aumann, R. (1963). A deÔ¨Ånition of subjective probability. Annals
of Mathematical Statistics, 34, 199‚Äì205.
[8] Ellsberg, D. (1961). Risk, ambiguity and Savage axioms. Quarterly Journal of Eco-
nomics, 75, 643‚Äì669.
[9] Georgescu-Roegen, N. (1999). The Entropy Law and the Economic Process. Harvard
University Press, Cambridge, MA.
[10] Roehner, B. (2010). Fifteen years of econophysics: worries, hopes and prospects.
Please see at: http://arxiv.org/abs/1004.3229, Cornell University.
[11] Mantegna, R. and Stanley, H. E. (1999). An Introduction to Econophysics: Correla-
tions and Complexity in Finance. Cambridge University Press.
[12] Lux, Th. and Marchesi, M. (1999). Scaling and criticality in a stochastic multi-agent
model of a Ô¨Ånancial market. Nature, 397, 498‚Äì500.
[13] Gabaix, X., Gopikrishnan, P., Plerou, V., and Stanley, H. E. (2006). The trades of
large institutional investors in illiquid markets explain many patterns in the extreme
behavior of returns and trading volume. Quarterly Journal of Economics, 121, 2,
461‚Äì504.
2.3 The physics-based ‚ÄúFokker‚ÄìPlanck‚Äù PDE in economics
We have already discussed the Fokker‚ÄìPlanck partial differential equation (PDE) as
describing the time evolution of a probability density function of velocity. We have
already mentioned this equation in Section 1.18 (please see under equation (1.59)).

2.5 Potential and kinetic energy in social science
41
Many textbooks in physics will deal with the background and construction of the
Fokker‚ÄìPlanck PDE. One area where such an equation can be used to beneÔ¨Åcial
effect is in the estimation of stochastic volatility. The concept of volatility has wide
bearing in Ô¨Ånancial asset pricing. Following Hull [1] (p. 206), the volatility of the
price of an asset is a measure of the uncertainty about the returns of a stock. It is
universally deÔ¨Åned as the standard deviation of the return of an asset (a stock for
instance). If stock prices are assumed to be lognormally distributed,4 then we can
say that the percentage changes in the stock price are normally distributed. The
Ô¨Ånance community often uses the concept of ‚Äúvolatility‚Äù and this is the square root
of the variance of the return of an asset. Recall that Brownian motion has already
been discussed in Section 1.18 of Chapter 1. We can imagine that the volatility
of the price of an asset moves over time following a Brownian motion. Hence,
suppose we have the stochastic differential equation for volatility, œÉ, to be:
dœÉ = Œ± (œÉ) dt + Œ≤ (œÉ) dz,
(2.1)
where dœÉ denotes the inÔ¨Ånitesimal change in the value of volatility, œÉ; Œ± (œÉ) is some
drift function of volatility; dt denotes the inÔ¨Ånitesimal change in time; Œ≤ (œÉ) is some
diffusion function of volatility; dz is a Wiener process. Imagine, following Wilmott
[2] (p. 319) that from empirical data you can estimate: dœÉ = Œ± (œÉ) dt + vœÉ Œªdz;
with v = 0.88 and Œª = 1.05. One can estimate Œ± (œÉ) using the Fokker‚ÄìPlanck
PDE approach, by using ‚àÇf
‚àÇt ‚àí1
2
‚àÇ2f
‚àÇœÉ 2 Œ≤2 + ‚àÇf
‚àÇœÉ (Œ±) = 0. As per Wilmott [2] (p. 320),
impose time independency and assume that we know the steady-state distribution
of f : f‚àû. One can write 1
2
‚àÇ2f‚àû
‚àÇœÉ 2 Œ≤2 = ‚àÇf‚àû
‚àÇœÉ (Œ±) and integrating once (towards œÉ),
Wilmott [2] (p. 320) obtains Œ±f‚àû= 1
2
‚àÇf‚àû
‚àÇœÉ Œ≤2 from which Œ± =
1
2f‚àû
‚àÇf‚àû
‚àÇœÉ Œ≤2 and where
the constant is assumed zero. Hence, if one knows f‚àû, one can Ô¨Ånd the drift,
Œ±(œÉ). We note that Wilmott [2] (p. 320), indicates that f‚àûcould be a lognormal
probability density function (pdf) on volatility.
2.4 References
[1] Hull, J. (2006). Options, Futures and Other Derivatives. 6th edition. Prentice Hall.
[2] Wilmott, P. (1998). Derivatives: The Theory and Practice of Financial Engineering.
J. Wiley, New York.
2.5 Potential and kinetic energy in social science
We may wonder how potential and kinetic energy connect to economics? Khren-
nikov [1] [2] and Choustova [3] [4] [5] [6] have shown that many concepts in basic
physics can have a social science equivalent (including potential energy).
4 Please note that other distributions can certainly be assumed too! The 2008 Ô¨Ånancial crisis showed us that
so-called fat-tailed distributions would be much more appropriate.

42
Econophysics: statistical physics and social science
The model presented in this section can be considered as a ‚Äúclassical mechani-
cal model‚Äù for Ô¨Ånance. In principle, it can be used as the basis for what we could
call ‚ÄúÔ¨Ånancial quantization,‚Äù i.e. a transition from the functional to the operator
representation of Ô¨Ånancial variables. The main problem is that at this level of the
‚Äúclassical mechanical model‚Äù of the Ô¨Ånancial market we do not know which ‚Äúpre-
cise‚Äù Ô¨Ånancial Hamiltonian function describes the Ô¨Ånancial analogue of energy. In
effect, we thus ‚Äúplay‚Äù around with Hamiltonian functions borrowed from (classical)
mechanics. Quantization will lead to the use of quantum Ô¨Ånancial Hamiltonians.
Let us follow closely, in the development below, Khrennikov [7] (pp. 155‚Äì157).
Consider the most simple concept: the phase space. Assume there exists a con-
Ô¨Åguration space Q = Rn of price vectors ‚àí‚Üí
q = (q1, q2, . . . , qn), where qj is the
price of the share of the jth corporation. The dynamics of prices can then be
described by a trajectory ‚àí‚Üí
q (t) = (q1(t), q2(t), . . . , qn(t)) in Q. One can deÔ¨Åne
Œ¥qj(t) = qj(t + 
t) ‚àíqj(t) which symbolizes a discrete price change. A contin-
uous price change vj(t) =
.
qj(t) = lim
t‚Üí0
qj(t+
t)‚àíqj(t)

t
can then be deÔ¨Åned. Note
that one can consider time scales such as 
t, 2
t, . . .
There exists a phase space Q √ó V , where V ‚â°Rn and ‚àí‚Üí
v = (v1, v2, . . . , vn) ‚àà
V. A state (q, v) is called a classical state.
The analogue of physical mass can also be introduced, i.e. the number of shares of
stock j: mj. The market capitalization of trader j (Ô¨Årm j) is then Tj(t) = mjqj(t).
Total energy is the sum of kinetic and potential energy. Kinetic energy
is deÔ¨Åned in physics as
1
2
n
j=1 mjv2
j and the interpretation with the former
economics-based analogies is now immediate. Potential energy is denoted as
usual V (q1, . . . , qn). It describes interactions between traders as well as inter-
actions from other factors, such as macro-economic factors. What is its functional
form? An example of a simple Ô¨Ånancial potential would be (qi ‚àíqj)2. Classical
price dynamics are then deÔ¨Åned by a price momentum pj = mjvj. We then have
mj

lim
t‚Üí0
vj(t+
t)‚àívj(t)

t

= ‚àí‚àÇV
‚àÇqj
and here we Ô¨Ånd the well-known Newtonian
equation.
The development above can also be found in other work. Any of the refer-
ences mentioned above will give a similar treatment (i.e. Khrennikov, [1] [2] and
Choustova [3] [4] [5] [6]).
2.6 References
[1] Khrennikov, A. (2004). Information Dynamics in Cognitive, Psychological and
Anomalous Phenomena. Series Fundamental Theories of Physics, vol. 138. Kluwer,
Dordrecht.
[2] Khrennikov, A. Yu. (1999). Classical and quantum mechanics on information spaces
with applications to cognitive, psychological, social and anomalous phenomena. Foun-
dations of Physics, 29, 1065‚Äì1098.

2.7 The backward Kolmogorov PDE in Ô¨Ånance
43
[3] Choustova, O. (2004). Bohmian mechanics for Ô¨Ånancial processes. Journal of Modern
Optics, 51, 6/7, 1111.
[4] Choustova, O. (2006). Quantum Bohmian model for Ô¨Ånancial market. Physica A, 374,
304‚Äì314.
[5] Choustova, O. (2007). Quantum modeling of nonlinear dynamics of prices of shares:
Bohmian approach. Theoretical and Mathematical Physics, 152, 7, 1213‚Äì1222.
[6] Choustova, O. (2007). Quantum Bohmian model for Ô¨Ånancial market. Department of
Mathematics and System Engineering, International Center for Mathematical Model-
ing, V¬®axj¬®o University, Sweden.
[7] Khrennikov, A. (2010). Ubiquitous Quantum Structure: From Psychology to Finance.
Springer Verlag, Berlin.
2.7 The backward Kolmogorov PDE in Ô¨Ånance
2.7.1 What is an option?
One of the most famous statistical physics equations in Ô¨Ånance is the so-called
Black‚ÄìScholes PDE. This PDE, when solved, yields the price of a so-called
‚Äúoption‚Äù contract. There do exist two basic option contracts: the call option and the
put option.
In Bailey [1] (p. 439), a call option is deÔ¨Åned as:
DeÔ¨Ånition 1 A security that gives its owner the right, but not the obligation, to
purchase a speciÔ¨Åed asset for a speciÔ¨Åed price, known as the exercise price or the
strike price.
In Bailey (p. 439), the put option is deÔ¨Åned as:
DeÔ¨Ånition 2 A security that gives its owner the right, but not the obligation, to
sell a speciÔ¨Åed asset for a speciÔ¨Åed price, known as the exercise price or the strike
price.
When you go ‚Äúlong‚Äù on an option, you pay a premium (this is the option price).
The writer of the option has the so-called ‚Äúshort‚Äù position.
2.7.2 The Black‚ÄìScholes portfolio and preferences for risk
The typical Black‚ÄìScholes PDE derivation is as follows. The interested reader may
want to consult Black and Scholes [2]. Assume a collection (also called a portfolio)
of two assets: a stock and an option. The portfolio value can be called, . It can be
written as follows:
 = ‚àíF + ‚àÇF
‚àÇS S,
(2.2)

44
Econophysics: statistical physics and social science
where F is the Ô¨Ånancial option price and S is the stock price. We remark that the
Ô¨Ånancial option price is the price of a call or a put option (please see DeÔ¨Ånitions
1 and 2 above). This option price is typically a function of two variables: time
and the value of the underlying asset. Option pricing can be applied to a myriad
of underlying assets, such as bonds, stocks, and other options. In the derivation
we provide here, we will assume that the stock (or also ‚Äúshare‚Äù) is the underlying
asset. The practical signiÔ¨Åcance of the option price is that it is the price of the
option contract. This price is also known under the name of ‚Äúpremium.‚Äù As an
example, if we were to think of a put contract as an insurance contract against a
certain contingency, then the put price, F, would be nothing else than the price of
the insurance contract.
We note the quite abstract form of this postulated portfolio: the minus sign which
precedes the Ô¨Ånancial option F indicates we must sell an option. The + ‚àÇF
‚àÇS indicates
the quantity we need to buy of the underlying asset, S. Often the question is raised
how the inventors of the option pricing formula got the ‚Äúintuition‚Äù to propose such
an abstract portfolio formula. We may want to take a step back now. Consider the
so-called binomial option pricing model. The binomial option pricing model can
be shown to converge to the Black‚ÄìScholes option pricing model. The key paper is
by Cox et al. [3]. In the binomial option pricing model, the portfolio used is quite
similar to the portfolio presented in the above equation (2.2). As any text book on
option pricing will show, the Ô¨Ånding of a quantity 
 (which is similar ‚Äì albeit not
the same! ‚Äì to the partial derivative of F towards S) makes that the portfolio in the
binomial option pricing model has the same value, no matter whether the price of
the underlying asset S goes up or down. Following Hull [4] (p. 243), the portfolios
in the binomial option pricing model can be written as S.u.
 ‚àífu = S.d.
 ‚àífd,
where S.u is the price of the underlying asset when it goes ‚Äúup,‚Äù while S.d is the
price of the underlying asset when it goes down; fu and fd are the so-called intrinsic
values of the option when the price of the asset is going up or down, respectively.
Following the above two deÔ¨Ånitions (DeÔ¨Ånitions 1 and 2), the intrinsic value of
an option, when it is a (long) call (DeÔ¨Ånition 1), would be max{S.u ‚àíX, 0} when
considering S.u, where X is the strike price. Using DeÔ¨Ånition 2, we would have
as intrinsic value for a (long) put, max{X ‚àíS.d, 0} when considering S.d. From
the imposed equality, S.u.
 ‚àífu = S.d.
 ‚àífd, one can Ô¨Ånd 
 =
fu‚àífd
S.u‚àíS.d . This

 is essential as it allows the use of the so-called ‚Äúrisk free rate of interest‚Äù as a
return parameter on the portfolio. Such a rate of return is in Ô¨Ånancial economics
a highly desirable variable, since it is independent of preferences for risk. But
the novice reader may now wonder about those two new terms: ‚Äúrisk free rate of
interest‚Äù and ‚Äúpreferences for risk.‚Äù The risk free rate of interest is an interest rate
which is relevant for assets which do not bear any risk. As an example, bonds
issued by a government would in theory need to yield a risk free rate of interest

2.7 The backward Kolmogorov PDE in Ô¨Ånance
45
if those bonds are guaranteed to be repaid no matter the Ô¨Ånancial circumstance.
The concept of ‚Äúpreference for risk‚Äù is quite easy to understand. As individual
investors, we all have different levels of tolerance towards risk. Some investors are
much more sensitive towards the perceived risk position of a certain asset, while
others do perceive the level of risk as quite acceptable.
Although it is very intuitive to understand that we have levels of tolerance for
risk vis-`a-vis a certain Ô¨Ånancial asset, it is quite a much more daunting task to
formulate, in a rigorous way, such levels of tolerance for risk. Economists, have for
long used the tool of utility functions to ‚ÄúreÔ¨Çect‚Äù our attitude towards risk (more
on this function in Chapter 7).
As an example, we could for instance think of projecting various scenarios of
asset returns in the future. Typically, we assume the existence of states of nature
(a state of nature such as ‚Äúan expanding economy‚Äù or also a state of nature such as
‚Äúa collapsing economy‚Äù). If we were to attach probabilities to the likelihood of such
states occurring and if we had some idea what return each asset would carry in each
of the different states of nature, then we could calculate the mean and the variance
of the returns of each asset across the different states of nature. Assets could then
be classiÔ¨Åed according to their risk/return proÔ¨Åle. However, this is not fault free.
The probabilities of states and estimated levels of returns are mostly subjective
assessments. Furthermore, one can easily be confronted with the situation where
asset A has a higher expected return than asset B, but asset A‚Äôs volatility is also
higher compared to asset B‚Äôs volatility. As Danthine and Donaldson [5] (p. 23)
remark: ‚Äúwhat decrease in expected return is a [decision maker] willing to accept for
a 1% decrease in standard deviation of returns?‚Äù Answering this question requires
the notion of risk tolerance.
Clearly, if we can dispense with the use of any considerations towards the
formulation of attitudes towards risk, then we have in some sense a much more
tractable theory. The very objective of the portfolio as formulated in equation (2.2)
above (and we gave some background information as to how we can see a similar
portfolio in the binomial option pricing formula) is thus to form a portfolio which
allows for the application of the use of the risk free rate of return for a judicious
choice of the 
. Indeed, if equation (2.2) were to be rewritten as ‚àíF + 
‚Ä≤S,
where we used 
‚Ä≤ to distinguish it clearly from the 
 in the binomial option
pricing model, then if we replace 
‚Ä≤ = ‚àÇF
‚àÇS in the derivation of the Black‚ÄìScholes
model (please see below ‚Äì especially equation (2.8)), then we can obtain a risk
free portfolio. The attentive reader will of course have spotted that the relation
between 
‚Ä≤ and 
 is mathematically not that remote. For more on the background
of choice under (un)certainty and the various models of expected utility, please see
Chapter 7, Sections 7.1 and 7.3.

46
Econophysics: statistical physics and social science
2.7.3 A Taylor expansion in a stochastic environment?
The discrete change in the value of the above Black‚ÄìScholes portfolio (equation
(2.2)), which we denote as Œ¥, is:
Œ¥ = ‚àíŒ¥F + ‚àÇF
‚àÇS Œ¥S.
(2.3)
It is an assumption that the stock price process follows a geometric Brownian
motion (see Samuelson [6]):
dS = ŒºSdt + œÉSdz,
(2.4)
where Œº is the expected return; œÉ is volatility of the stock price S; dz is a Wiener
process; t is time. Remark that the expected return, Œº, includes preferences for risk.
It is precisely one of the great achievements of the Black‚ÄìScholes model that, by
virtue of its portfolio construction, this expected return is fully absent from the Ô¨Ånal
partial differential equation (i.e. the Black‚ÄìScholes partial differential equation),
which is (2.12). Assume one wants to know how to write the inÔ¨Ånitesimal change
in F (the option price (put or call)), denoted as dF, when the derivative F is a
function of the stock price and time.
We cover in some detail in Chapter 4, Section 4.18.4 the so-called ItÀÜo Lemma
[7], which we will use now. Employing the ItÀÜo Lemma in the context presented
here involves the use of equations (2.5) and (2.6) below. As per Hull [4] (p. 291),
the ItÀÜo Lemma indicates that:
dF =
	‚àÇF
‚àÇS ŒºS + ‚àÇF
‚àÇt + 1
2
‚àÇ2F
‚àÇS2 œÉ 2S2

dt +
	‚àÇF
‚àÇS

œÉSdz,
(2.5)
and we can put this into a discrete format as follows:
Œ¥F =
	‚àÇF
‚àÇS ŒºS + ‚àÇF
‚àÇt + 1
2
‚àÇ2F
‚àÇS2 œÉ 2S2

Œ¥t +
	‚àÇF
‚àÇS

œÉSŒ¥z.
(2.6)
INTERMEZZO. The reader will have noticed our ‚Äúcasual‚Äù switching from con-
tinuous to discrete changes. Such a change is not to be taken lightly. In a stochas-
tic sense, does it make sense to write that E(X‚Ä≤(t)) = E

l.i.mŒµ‚Üí0
x(t+Œµ)‚àíx(t)
Œµ

=
limŒµ‚Üí0 E
 x(t+Œµ)‚àíx(t)
Œµ

, where l.i.m is the limit in the mean square sense (and this
is a very different notion from the ordinary limit deÔ¨Ånition)? We will assume stan-
dard Hilbert spaces L1 ‚â°L1 (, F, P) and L2 ‚â°L2 (, F, P), which are deÔ¨Åned
as L1 = {Y : E [|Y|]} < ‚àû} and L2 
Y : E

Y 2
< ‚àû}. Note that L2 ‚äÇL1. Here
is an interesting proof. The proof was provided by Alexander [8].
Proof. We can write:
E(X‚Ä≤(t)) ‚àíE( x(t+Œµ)‚àíx(t)
Œµ
)
 =
E(X‚Ä≤(t)) ‚àí( x(t+Œµ)‚àíx(t)
Œµ
))
.
Square both sides and use Jensen‚Äôs inequality then we obtain:

2.7 The backward Kolmogorov PDE in Ô¨Ånance
47
1. 0 ‚â§
E(X‚Ä≤(t)) ‚àíE( x(t+Œµ)‚àíx(t)
Œµ
)
2 =
E(X‚Ä≤(t)) ‚àí( x(t+Œµ)‚àíx(t)
Œµ
))
2
2.
E(X‚Ä≤(t)) ‚àí( x(t+Œµ)‚àíx(t)
Œµ
))
2 ‚â§E

(X‚Ä≤(t) ‚àí( x(t+Œµ)‚àíx(t)
Œµ
))2
(which is Jensen‚Äôs
inequality)
Now we know that limŒµ‚Üí0 E
 x(t+Œµ)‚àíx(t)
Œµ
‚àíX‚Ä≤(t)
2
= 0 since this is the
deÔ¨Ånition of l.i.m. Therefore, we can write (using 1 and 2 and the deÔ¨Ånition of
l.i.m):
0 ‚â§limŒµ‚Üí0
E(X‚Ä≤(t)) ‚àíE( x(t+Œµ)‚àíx(t)
Œµ
)
2 =
E(X‚Ä≤(t)) ‚àí( x(t+Œµ)‚àíx(t)
Œµ
))
2 ‚â§
limŒµ‚Üí0 E

(X‚Ä≤(t) ‚àí( x(t+Œµ)‚àíx(t)
Œµ
))2
= 0
and
therefore
limŒµ‚Üí0
E(X‚Ä≤(t))‚àí
E( x(t+Œµ)‚àíx(t)
Œµ
)
2 = 0
which
of
course
implies
that
limŒµ‚Üí0
E(X‚Ä≤(t))‚àí
E( x(t+Œµ)‚àíx(t)
Œµ
)
 = 0
and
which
therefore
proves
that
E(X‚Ä≤(t)) =
limŒµ‚Üí0 E
 x(t+Œµ)‚àíx(t)
Œµ

.
‚ñ†
After this brief intermezzo, let us put the geometric Brownian motion in discrete
format:
Œ¥S = ŒºSŒ¥t + œÉSŒ¥z.
(2.7)
As per Hull [4] (p. 291), if we substitute the Œ¥F equation (see above) and the Œ¥S
equation (see above) into Œ¥ = ‚àíŒ¥F + ‚àÇF
‚àÇS Œ¥S, then we get:
Œ¥ = ‚àí
		‚àÇF
‚àÇS ŒºS + ‚àÇF
‚àÇt + 1
2
‚àÇ2F
‚àÇS2 œÉ 2S2

Œ¥t +
	‚àÇF
‚àÇS

œÉSŒ¥z

+ ‚àÇF
‚àÇS (ŒºSŒ¥t + œÉSŒ¥z) .
(2.8)
You will observe that the discrete change in the value of the portfolio will be
written as:
Œ¥ =
	
‚àí‚àÇF
‚àÇt ‚àí1
2
‚àÇ2F
‚àÇS2 œÉ 2S2

Œ¥t.
(2.9)
A crucial argument (see also Hull [4] (p. 292)) now consists in claiming that
since we do not have the Wiener process we can say that the return of the portfolio
( Œ¥
 ) per unit of time 1
Œ¥t is equal (under no arbitrage) to the risk free rate of interest:
Œ¥

1
Œ¥t = rf ,
(2.10)
where rf is the risk free rate. Now remark that this risklessness of the portfolio is
only valid for a brief instant of time.
Finally, all that now needs to be done is to substitute Œ¥ and  into the above
equations, to get:
	
‚àí‚àÇF
‚àÇt ‚àí1
2
‚àÇ2F
‚àÇS2 œÉ 2S2

Œ¥t = rf
	
‚àíF + ‚àÇF
‚àÇS S

Œ¥t.
(2.11)

48
Econophysics: statistical physics and social science
Cancel both Œ¥t on the left-hand side and the right-hand side of the equation and
you obtain the Black‚ÄìScholes equation (i.e. the partial differential equation):
‚àÇF
‚àÇt + rf S ‚àÇF
‚àÇS + 1
2œÉ 2S2 ‚àÇ2F
‚àÇS2 = rf F.
(2.12)
The Black‚ÄìScholes PDE is a famous example of a so-called backward Kol-
mogorov PDE. There is a lot of literature on this. The backward Kolmogorov PDE
can be written as (see Wilmott [9] (p. 144)) ‚àÇP
‚àÇt + 1
2B(y, t) ‚àÇ2P
‚àÇy2 + A(y, t) ‚àÇP
‚àÇy = 0,
where P is a pdf; B(y, t) is some diffusion function; A(y, t) is some drift function;
y is some position variable; t is time.
It is easy to show that the Black‚ÄìScholes PDE is a backward Kolmogorov PDE.
Following Wilmott [9] (pp. 147‚Äì148), using the format above and substituting
for B(y, t) = B(S, t) = œÉ 2S2 and A(S, t) = ŒºS: ‚àÇP
‚àÇt + 1
2œÉ 2S2 ‚àÇ2P
‚àÇy2 + ŒºS ‚àÇP
‚àÇS = 0.
Imposing P(S, t) = (exp(rf (T ‚àít))F(S, t) and taking the necessary derivatives,
one gets:
r
‚àÇP
‚àÇt = (exp(rf (T ‚àít))F(S, t)‚Ä≤
t = ‚àírf erf (T ‚àít)F(S, t) + ‚àÇF(S,t)
‚àÇt
erf (T ‚àít),
r
‚àÇP
‚àÇS = erf (T ‚àít) ‚àÇF
‚àÇS ,
r
‚àÇ2P
‚àÇS2 = er(T ‚àít) ‚àÇ2F
‚àÇS2 .
Substituting all this into ‚àÇP
‚àÇt + 1
2œÉ 2S2 ‚àÇ2P
‚àÇS2 + ŒºS ‚àÇP
‚àÇS = 0 and dividing by erf (T ‚àít),
one obtains: ‚àírf F + ‚àÇF
‚àÇt + 1
2œÉ 2S2 ‚àÇ2F
‚àÇS2 + ŒºS ‚àÇF
‚àÇS = 0.
Bouchaud [10], Bouchaud and Potters [11], Bouchaud and Sornette [12],
Schweizer [13], and Sch¬®al [14] provide for an alternative and very elegant
way of deriving the option price. We expand on this approach in Chapter 13,
Section 13.20.
2.8 References
[1] Bailey, R. (2005). The Economics of Financial Markets. Cambridge University Press.
[2] Black, F. and Scholes, M. (1973). The pricing of options and corporate liabilities.
Journal of Political Economy, 81, 637‚Äì659.
[3] Cox, J., Ross, S., and Rubinstein, M. (1979). Option pricing: a simpliÔ¨Åed approach.
Journal of Financial Economics, 7, 229‚Äì263.
[4] Hull, J. (2006). Options, Futures and Other Derivatives. 6th edition. Prentice Hall.
[5] Danthine, J. P. and Donaldson, J. B. (2005). Intermediate Financial Theory. Academic
Press Advanced Finance Series.
[6] Samuelson, P. A. (1965b). Rational theory of warrant pricing. Industrial Management
Review, 6, 13‚Äì39.
[7] √òksendal, B. (1992). Stochastic Differential Equations. Springer Verlag, Berlin.
[8] Alexander, D. (2003). Private communication.
[9] Wilmott, P. (1998). Derivatives: The Theory and Practice of Financial Engineering.
J. Wiley.

2.9 Martingales and fake probabilities
49
[10] Bouchaud, J. P. (2002). An introduction to statistical Ô¨Ånance. Physica A, 313, 238‚Äì
251.
[11] Bouchaud, J. P. and Potters, M. (2000). Theory of Financial Risks. Cambridge Uni-
versity Press.
[12] Bouchaud, J. P. and Sornette, D. (1994). The Black‚ÄìScholes option pricing problem
in mathematical Ô¨Ånance: generalization and extensions for a large class of stochastic
processes. Journal de Physique I, 4, 863‚Äì881.
[13] Schweizer, M. (1994b). Approximating random variables by stochastic integrals.
Annals of Probability, 22, 1536‚Äì1575.
[14] Sch¬®al, M. (1994). On quadratic cost criteria for option hedging. Mathematics of
Operations Research, 19, 121‚Äì131.
2.9 What a weird world! Martingales and fake probabilities
How can one solve this backward Kolmogorov PDE? One approach is to use mar-
tingales to solve such PDE. Martingales are a well-known mathematical instrument
in Ô¨Ånance. A heuristic (and in this case incomplete view) of the martingale is very
simple: the conditional expectation of say a stock price at time T > t, given the
information you have at time t : It is E[ST |It] = St, for all t < T . For an excellent
introductory book on this topic, see Neftci [1]. More advanced material can be
found in the excellent text by √òksendal [2].
One possible approach to solving the backward Kolmogorov PDE (Black‚Äì
Scholes PDE) is provided for in Neftci [1]. We now closely follow Neftci [1]
and we summarize5 below the development6 contained in Neftci [1] (pp. 346‚Äì
358). Consider a stock price St = S0 exp (Yt) and let Yt be following a normal
pdf with mean Œºt and variance œÉ 2t. The moment generating function, deÔ¨Åned as
E(eYtŒª), where Œª is some arbitrary parameter can be found as being (assume that
Yt follows a pdf with mean Œºt and œÉ 2t):
E(eYtŒª) = exp
	
ŒªŒºt + 1
2œÉ 2tŒª2

.
(2.13)
The Ô¨Årst moment can then be found as dE(eYt Œª)
dŒª
= tŒº when this derivative is
evaluated at Œª = 0. We can write the change in Yt as 
Yt and this then follows
N(Œº(t ‚àís), œÉ 2(t ‚àís)). The moment generating function is now:
E(e
YtŒª) = exp
	
ŒªŒº(t ‚àís) + 1
2œÉ 2(t ‚àís)Œª2

.
(2.14)
Therefore, E(e
Yt) = exp(Œº(t ‚àís) + 1
2œÉ 2(t ‚àís)), where we set Œª = 1. One can
write, E

St
Su |Su, u < t

= E[exp(
Yt)|Su]. Please note that the notation says we
5 The summary is based on work from Neftci, S., An Introduction to the Mathematics of Financial Derivatives,
pp. 346‚Äì358, Elsevier (2000).
6 Up to Section 2.10.

50
Econophysics: statistical physics and social science
obtain the expectation of the division of St over Su for Ô¨Åxed u such that u < t.
We can write, E [St|Su, u < t] = Su exp(Œº(t ‚àíu) + 1
2œÉ 2(t ‚àíu)), and where Su is
treated as non-random at time u (and hence can be taken out of the expectation
operator).
We would like to introduce a new probability measure 
P, which will help us to
transfer St, which is not a martingale, into an St, which will be a martingale, and
that up to a deterministic process. This approach describes a mean shift induced
with the presence of the risk free (and constant) rate of interest.
Hence, let us now write the following, E 
P [(exp(‚àírf t)St|Su, u < t] =
exp(‚àírf u)Su, which in words says that the expectation of the discounted value
of a risky asset can be discounted with the risk free rate (rf ), as long as we use
the probability measure 
P. This is very useful from a Ô¨Ånance perspective! The
risk free rate of interest is not linked to preferences for risk. Hence, from a natural
science perspective, the risk free rate of interest can almost be considered as a
(time-dependent . . . ) constant. We have already alluded to the usefulness of the
risk free rate of interest (and its importance) in Section 2.7.2 above.
The key issue in the above development is to Ô¨Ånd an expression for 
P. Associate
that new probability to a normal density with mean œÅt, and the same variance as
before œÉ 2t. But what is œÅ? Sure we can write, in analogy with EP [St|Su, u < t],
that E 
P [St|Su, u < t] = Su exp(œÅ(t ‚àíu) + 1
2œÉ 2(t ‚àíu)). But that does not bring
us much further.
We can augment the above expression, E 
P [St|Su, u < t], a little more by
considering a discount factor and we could write E 
P 
e‚àírf (t‚àíu)St|Su, u < t

=
Sue‚àírf (t‚àíu) exp(œÅ(t ‚àíu) + 1
2œÉ 2(t ‚àíu)). To say something sensible about the
at-present undeÔ¨Åned

P, one could think of imposing that the expecta-
tion E 
P 
e‚àírf (t‚àíu)St|Su, u < t

obeys the martingale. This would then mean
that E 
P 
e‚àírf (t‚àíu)St|Su, u < t

= Su. This is reasonable since this is equiv-
alent to saying that E 
P 
e‚àírf tSt|Su, u < t

= e‚àírf uSu. Therefore, impose on
Sue‚àírf (t‚àíu) exp(œÅ(t ‚àíu) + 1
2œÉ 2(t ‚àíu)) so that it is equal to Su.
Therefore, one needs that e‚àírf (t‚àíu) exp(œÅ(t ‚àíu) + 1
2œÉ 2(t ‚àíu)) = e0. One can
easily see this now by just writing e(( 1
2 œÉ 2‚àírf)(t‚àíu))+œÅ(t‚àíu) = e0 and this is only
the case when œÅ = rf ‚àí1
2œÉ 2. Thus, the probability 
P associated with the normal
density N(œÅt, œÉ 2t) can now be made more precise (by using the martingale condi-
tion) N(œÅt, œÉ 2t) = N

rf ‚àí1
2œÉ 2
t, œÉ 2t

.
What one can see clearly is that the transition from P to 
P has shifted the
mean. This leads to a very nice analogy. If the payoffs in a lottery dice game are
to be changed, how could one proceed? The mean of the value of that lottery can
be altered by changing the payoffs you get from each dice outcome. However,
the mean value of the lottery can also be altered by changing the probabilities

2.9 Martingales and fake probabilities
51
associated to each dice outcome! This is indeed a seriously weird solution: if the
dice is a fair dice, then we know what the objective probabilities are of each dice‚Äôs
outcome: 1/6. Thus, in analogy with the dice example, you can think of the change
from P to 
P as a change of probability, from the real probability P to some ‚Äúfake‚Äù
probability 
P!
If one writes that the call value at time t = 0:
C0 = E 
P 
e‚àírf T max [ST ‚àíX, 0]

,
(2.15)
where X is the strike price (i.e. the price at which we can exercise the option) and
ST is the terminal stock price, then the main query consists in asking how to work
out the expectation E 
P ?
We have now an answer. By imposing the martingale, one could Ô¨Ånd that the fake
probability 
P can be associated with N(œÅt, œÉ 2t), with œÅ = rf ‚àí1
2œÉ 2. Let us use
the integral to calculate the expectation. We remind ourselves that the probabilities
we want to use in this expected value calculation must be drawn from N(œÅt, œÉ 2t).
We write:
C0 =
 ‚àû
‚àí‚àû
e‚àírf T max[ST ‚àíX, 0]
1
‚àö
2œÄœÉ 2T
e‚àí
1
2œÉ2T (YT ‚àí(rf ‚àí1
2 œÉ 2)T )2dYT .
(2.16)
We are interested in the ‚Äúideas‚Äù behind this integral. We have the following
important parts:
r
1
‚àö
2œÄœÉ 2T e‚àí
1
2œÉ2T (YT ‚àí(rf ‚àí1
2 œÉ 2)T )2: this is the functional form of the Normal density
associated with N(œÅt, œÉ 2t), with œÅ = rf ‚àí1
2œÉ 2.
r (YT ‚àí(rf ‚àí1
2œÉ 2)T )2: notice the presence of the mean here, (r ‚àí1
2œÉ 2).
r dYT : notice that we clearly integrate towards YT here.
We can get rid of the max-operator by imposing ST = S0eYT ‚â•X and this can
be rewritten as:
YT ‚â•ln
	 X
S0

:
 ‚àû
ln

X
S0
 e‚àírf T 
S0eYT ‚àíX

1
‚àö
2œÄœÉ 2T
e‚àí
1
2œÉ2T (YT ‚àí(rf ‚àí1
2 œÉ 2)T )2dYT .
(2.17)
This integral can then be split into two parts:
r S0
 ‚àû
ln

X
S0
 e‚àírf T eYT
1
‚àö
2œÄœÉ 2T e‚àí
1
2œÉ2T (YT ‚àí(rf ‚àí1
2 œÉ 2)T )2dYT = Part A
r ‚àíXe‚àírf T  ‚àû
ln

X
S0

1
‚àö
2œÄœÉ 2T e‚àí
1
2œÉ2T (YT ‚àí(rf ‚àí1
2 œÉ 2)T )2dYT = Part B.
A handy way of solving Part B is to set Z =
YT ‚àí(rf ‚àí1
2 œÉ 2)T
œÉ
‚àö
T
, which allows one
to write ‚àíXe‚àírf T  ‚àû
ln
	
X
S0

‚àí(rf ‚àí1
2 œÉ2)T
œÉ
‚àö
T
1
‚àö
2œÄ e‚àí1
2 (Z)2dZ. Remark here, integration now

52
Econophysics: statistical physics and social science
happens towards Z. In the lower bound, one reads ln

X
S0

. One can rewrite this as
ln

X
S0

= ln
 S0
X
‚àí1 = ‚àíln
 S0
X

. The lower bound of the integral can be rewritten
as
ln

X
S0

‚àí(rf ‚àí1
2 œÉ 2)T
œÉ
‚àö
T
=
‚àíln
 S0
X

‚àí(rf ‚àí1
2 œÉ 2)T
œÉ
‚àö
T
= ‚àí
ln
 S0
X

+(rf ‚àí1
2 œÉ 2)T
œÉ
‚àö
T
= ‚àíd2. Because of
symmetry of the normal density, ‚àíXe‚àírf T  d2
‚àí‚àû
1
‚àö
2œÄ e‚àí1
2 (Z)2dZ = ‚àíXe‚àírf T N(d2).
This latter part is ‚Äúone-half‚Äù of the Black‚ÄìScholes solution.
Part A can be solved likewise, with a little more trickery, to obtain
S0
 d2
‚àí‚àû
1
‚àö
2œÄ e
‚àí1
2

Z+œÉ
‚àö
T
2
dZ;
Z =
YT ‚àí(rf ‚àí1
2 œÉ 2)T
œÉ
‚àö
T
.
Introduce
H = Z + œÉ
‚àö
T :
S0
 d2+œÉ
‚àö
T
‚àí‚àû
1
‚àö
2œÄ e‚àí1
2 (H)2dH = SN(d1), where d1 = d2 + œÉ
‚àö
T . The full Black‚Äì
Scholes solution for a European call is now available, taken from parts A
and B.
The development above which thus deals with a solution technique to solving
the Black‚ÄìScholes PDE can also be found in other sources. Books on the topic of
partial differential equations will often carry solution techniques for certain types
of PDEs. As we already remarked in Section 2.1 above, the Black‚ÄìScholes PDE is
a backward Kolmogorov PDE.
2.10 References
[1] Neftci, S. (2000). An Introduction to the Mathematics of Financial Derivatives.
Academic Press.
[2] √òksendal, B. (1992). Stochastic Differential Equations. Springer Verlag, Berlin.
2.11 Whetting the quantum appetite
Li and Zhang [1] show in an interesting paper how option pricing can also be
modeled via the use of the most fundamental quantum mechanics partial differ-
ential equation: the Schr¬®odinger PDE. Without going into any depth (please see
Chapter 13 for a more detailed treatment of this approach), the authors show
[2] (p. 2) that the necessary transformations to achieve such a pricing approach
are that the call function (which is a function of the stock price and time),
Call(S, t) = ‚àöœÉ(S)g(x, t), where g(x, t) is the quantum mechanical wave func-
tion (which we will discuss in much more detail in the next chapter), and œÉ(S) is
some volatility function of the asset price S. Furthermore, the authors also show
in the same paper (p. 2) that x(S) = Œ¥

1
œÉ(S)dS, with Œ¥ = +/ ‚àí1. The authors
then show that one can use the Schr¬®odinger PDE to solve for g(x, t). Interesting
potential functions are considered in a fully Ô¨Ånancial environment. The concept of

2.11 Whetting the quantum appetite
53
the potential function has already been discussed in Sections 1.1, 1.3, 1.13.4, 1.20
in Chapter 1 and 2.5 in this chapter.
Haven [3] shows that when using the so-called WKB approximation method,
the Schr¬®odinger PDE can be used to obtain the option price. We will discuss the
WKB and the Li and Zhang approaches in more depth in Chapter 13.
In summary, we have covered some simple examples which show how elemen-
tary physics equations such as the Fokker‚ÄìPlanck PDE and the backward Kol-
mogorov PDE can be successfully used in economics. This chapter has introduced
the reader to the concept of mean changes via the use of a fake probability. This
approach is beneÔ¨Åcial, from a Ô¨Ånance perspective, as the risk free rate of interest
can then be employed. Such interest rates can be seen as the near equivalent of a
natural science constant.
2.12 References
[1] Li, Y. and Zhang, J. E. (2004). Option pricing with Weyl‚ÄìTitschmarsh theory. Quanti-
tative Finance, 4, 457‚Äì464.
[2] Zhang, J. E. and Li, Y. (2010). New analytical option pricing models with Weyl‚Äì
Titschmarsh theory. Quantitative Finance, DOI: 10. 1080/14697688.2010.503659.
[3] Haven, E. (2005). Analytical solutions to the backward Kolmogorov PDE via an
adiabatic approximation to the Schr¬®odinger PDE. Journal of Mathematical Analysis
and Applications, 311, 439‚Äì444.

3
Quantum social science: a non-mathematical motivation
3.1 What is quantum social science?
After a short discursion into the Ô¨Åeld of ‚Äúeconophysics‚Äù we now arrive at a much
more exotic stop. However, readers who have perused Chapter 1, will possibly be
less astonished to Ô¨Ånd that instead of making reference to social science within
a statistical mechanics environment, we now make reference to social science as
it could be embedded in a quantum mechanical context. Or is ‚Äúquantum social
science‚Äù denoting something altogether different? The term is certainly fraught
with a huge potential for misinterpretation. A common, but maybe not so erro-
neous, interpretation of the term often made by newcomers to this ‚ÄúÔ¨Åeld‚Äù can
be expressed via the following question: ‚Äúis quantum social science about re-
formulating social science with quantum mechanical tools?‚Äù Such a question
brings us closer to the goal of attempting to explain quantum social science, but
right here and now, i.e. at this very point in this book, we have the opportunity
to make a serious attempt to be really precise on what is meant with this new
term.
Therefore, let us from the outset indicate what it is not. Quantum social science
is not about reformulating social science on a quantum size scale. The macroscopic
world does not operate at the Planck scale. On prima facie, this obvious statement
does not need any further explanation. However, if the human experience is centered
around consciousness and the functioning of the brain, then we are much less sure
to claim there is a total absence of quantum processes. Roger Penrose has proposed
the idea that the brain can operate according to quantum mechanics. The key
references to note are by Penrose [1] and Penrose [2]. Roger Penrose and Stuart
Hameroff [3] edited in May of 2011 a special issue of the Journal of Cosmology
on consciousness and the universe. The special issue contains numerous articles on
the topic of the relationship between quantum physics and consciousness. See also
Hameroff and Penrose [4] and Hagan et al. [5]. We are unsure whether to subscribe
54

3.1 What is quantum social science?
55
to those points of view in our book. We will have more to say about this topic in
Chapter 14.
Besides the brain and consciousness, anything else which is part of the human
experience certainly does not operate on a scale comparable to the Planck scale.
Clearly, we certainly use the word ‚Äúquantum‚Äù in quantum social science. Here is
our attempt to be precise in what we mean. We even encapsulate it in a deÔ¨Ånition.
DeÔ¨Ånition 3 Quantum social science has as goal to investigate problems within the
wide remit of the social sciences ‚Äì be it economics, Ô¨Ånance, psychology, sociology,
or other domains of inquiry ‚Äì with the help of formal models and concepts used in
quantum physics.
Formal models from quantum physics are many and plentiful. Chapter 1 gave us
already a rich Ô¨Çavor. Chapter 6 will give an example of a formal model, Bohmian
mechanics, which can be used to some extent within a social science setting. An
example of the use of a formal concept from quantum mechanics in a social science
setting can be the idea of employing probability interference in psychology. This
is a concept which we will cover in Chapters 5 and 8.
Two immediate questions emerge: (i) How can we argue for the use of con-
cepts and models from quantum physics in such a macroscopic setting? (ii) What
problems have been solved? We hope Chapters 1 and 2 have already given some
idea of the usefulness to consider why concepts from physics (for instance sta-
tistical physics) have found inroads in social science. It is impossible to make
an assessment of the achievements of ‚Äúeconophysics‚Äù contributions to social sci-
ence, but there is little doubt that we can make the argument that physics and to
a wider extent, engineering concepts, have penetrated many Ô¨Ånance models. We
think speciÔ¨Åcally of derivative pricing models. The proprietary Ô¨Ånance models
developed by research departments of international investment houses rely very
heavily on concepts developed in the physical sciences. A simple example is the
intensive use of Monte-Carlo simulation in Ô¨Ånance. This simulation technique, to
the best of our knowledge, was popularized in Ô¨Ånance via the great efforts of an
outstanding Ô¨Ånance academic (with a physics training), Phelim Boyle [6]. See also
Ma [7] for more on Ô¨Ånancial asset pricing.
The attentive reader has spotted that we still have not answered the Ô¨Årst and sec-
ond immediate questions we mentioned above: Why quantum physical concepts in
social science? The econophysics movement which is roughly about 12 years old
may have seen the emergence of a parallel movement, i.e. the one we attempted
to describe in the above deÔ¨Ånition. It is difÔ¨Åcult to pinpoint what the precise
research papers were which jump-started the quantum social science movement.
However, some trust can be put in the assertion that the Foundations of Physics
paper by Andrei Khrennikov, which appeared in 1999 [8], may have had a very

56
Quantum social science: a non-mathematical motivation
important impact on the new movement. We believe that the central objective of
that paper and subsequent work (for instance the 2004 Kluwer book by Andrei
Khrennikov [9]) was essentially asking the question: How can we model informa-
tion to a reasonable standard in a social science setting? We do not want the reader
to jump to fortuitous conclusions! Quantum social science is not only about mod-
eling information in social science. We believe it is an important component but by
no means the only component. Surely, there do exist important models in the social
sciences, most notably in economics, where information can form an active part of
for instance a pricing model. However, there is surely room for more novelty in this
area. Let us consider the last sentence of the abstract of Sheldon Goldstein‚Äôs paper
which appeared in Foundations of Physics [10] (p. 335): ‚ÄúI would like to explore
the hypothesis that the idea that information plays a special role in physics natu-
rally emerges in a Bohmian universe.‚Äù1 Goldstein answers the question regarding
the role of the central object (although by no means the unique characteristic) of
quantum mechanics: the wave function. This is indeed an important question, also
for our purposes, since there is a close connection, we believe, between the wave
function and information. Before delving a little deeper between the connection of
the wave function and information, we feel it to be quite appropriate to mention
that Anton Zeilinger elaborated a purely informational interpretation of quantum
mechanics. See Bouwmeester and Zeilinger [11] (Chapter 1). His theory is neither
about particles nor is it about waves. It is about information as a fundamental,
irreducible objective entity. Although Zeilinger may have never spoken about such
a possibility, the reader may conclude that in Zeilinger‚Äôs interpretation quantum
theory can be applied everywhere where information plays a fundamental and
active role. We also would like to mention the contributions of Christopher Fuchs
[12] [13] who recently presented a novel viewpoint to quantum probabilities (and
hence entropy and information). He interpreted quantum probability as subjective
probability: it represents the experimenters‚Äô subjective expectations of the results
of experiments. The Fuchsian interpretation of the quantum wave function is still
questioned by a majority of physicists. On the other hand, in social science this
interpretation can be fruitfully used.
We can possibly have a sense of discomfort which maybe generated by the
thought that ‚Äúthe wave function does not have to be quantum mechanical to establish
a link with information.‚Äù This is indeed correct. However, to our knowledge, there
is a speciÔ¨Åc model in quantum mechanics (which we Ô¨Årst discuss in Chapter 6
and then in Chapters 11 and following) which provides for a usable model (in a
social science setting) of linking information with the quantum mechanical wave
1 Bohmian mechanics is covered in Chapter 6.

3.1 What is quantum social science?
57
function. Goldstein proposes that the quantum mechanical wave function is a
puzzling object. He proposes several questions that can be asked as to its existence
(see [10] (p. 336)):
r ‚ÄúDoes it merely represent information or does it describe an observer-
independent reality?‚Äù
r ‚ÄúIf it is objective, does it represent a concrete material sort of reality, or does it
somehow have an entirely different and perhaps novel nature?‚Äù
To come back to the point we made about the non-unique characteristic the
wave function carries in quantum physics, we hint back to Goldstein‚Äôs paper [10]
where he queries that the wave function is (p. 336) (i) everything, (ii) something, or
(iii) nothing. For our purposes, we need to exclude (iii). But as Goldstein also
indicates, the second option is the one which leaves room for the use of so-called
‚Äúhidden‚Äù variables. The motivation for hidden variables can be traced back ‚Äì even
before quantum mechanics existed. Jammer [14] (p. 259) argues that Hertz had
a theory of ‚Äúverborgene Koordinaten,‚Äù which actually informed so-called hidden
motions and masses. Jammer [14] presents two deÔ¨Ånitions of hidden variables. The
Ô¨Årst deÔ¨Ånition we cover much later in the book, in Chapter 13. Let us consider his
second deÔ¨Ånition (p. 262). We leave out the more technical parts (i.e. parts (3) and
(4) of that deÔ¨Ånition, which in essence refer to the existence of probability densi-
ties): ‚Äú(1) each individual quantum system described by the . . . state function œà is
characterized by additional hidden states labeled by a parameter Œª; the totality of
all hidden states is the phase space  of hidden states; œà and Œª determine the result
of measuring any observable on the system. (2) Each state function œà is associated
with a probability measure œÅœà () on  such that if  is a measurable subset of 
then œÅœà () is the probability that the state, deÔ¨Åned by œà and Œª, lies in .‚Äù What is
of interest here (having thus only cited aspects (1) and (2) of this deÔ¨Ånition) is that
Œª are called hidden variables. As Jammer [14] also remarks (p. 262), if Œª‚Äôs value is
known for an individual system in state œà, then, with certainty, one can predict the
result of any measurement on it. A very telling (and early) interpretation of hidden
variables was in fact given by no less than Born. Jammer [14] cites him as follows
(pp. 263‚Äì264): ‚ÄúThe classical theory introduces the microscopic coordinates which
determine the individual processes, only to eliminate them because of ignorance by
averaging over their values; whereas the new theory gets the same results without
introducing them at all. Of course it not forbidden to believe in the existence of these
coordinates; but they will only be of physical signiÔ¨Åcance when methods have been
devised for their experimental observation‚Äù (see Born [15]). Of course, as Jammer
also reports, hidden variables became much more of a ‚Äúno-no‚Äù once the work of
von Neumann seemed to establish the impossibility of hidden variables. The main

58
Quantum social science: a non-mathematical motivation
argument2 (see Jammer [14] (p. 270)) for the refutation of hidden variables is the
argument that if hidden variables were acceptable, then no dispersive ensembles
could be homogeneous. But von Neumann‚Äôs proof shows that every ensemble is
dispersive and no ensemble can be homogeneous. However, homogeneous ensem-
bles do exist. This then refutes the existence of hidden variables. To put it in words
which can be understandable for the non-physicist, Jammer writes [14] (pp. 270‚Äì
271): ‚ÄúIf experiments force us to base the formalism of quantum mechanics on
postulates as formulated above,3 any conception of hidden variables, designed to
embed, even only conceptually, the theory into a deterministic scheme is incon-
sistent with these postulates.‚Äù History also shows us that it was David Bohm who
actually called into being again the possible existence of hidden variables. It is very
interesting to note that Bohm indeed did write in his 1951 book [16] that hidden
variables were an impossibility. However, the two key papers by Bohm, supporting
hidden variables appeared very quickly after the book [17] [18]. We will have to
say much more about the Bohmian approach in Chapter 6 of this book. Later work
by Jauch and Piron will however show again that quantum mechanics would not be
able to be interpreted with hidden variables. See Jammer [14] (pp. 300‚Äì302) and
Jauch and Piron [19], but also Kochen and Specker [20]. We note that Bohm and
Bub [21] refuted the Jauch and Piron proof.
This very short description on the evolution of hidden variables could absolutely
not be complete without mention of the most important contribution of Bell [22]
[23]. Bell‚Äôs theorem states that [14] (p. 306): ‚Äúa local hidden variable theory can
not reproduce all statistical predictions of quantum mechanics.‚Äù
We need to emphasize that we presented here in detail the conventional viewpoint
on hidden variables. Roughly speaking, those variables cannot be introduced in a
consistent way (at least locally). However, as it was stressed in Section 1.22, the
aforementioned argument against hidden variables cannot be considered as the
Ô¨Ånal word! In spite of all the no-go theorems, some form of a local hidden variable
theory might be invented in the future. We refer the reader to the citation of Bell
on the views of de Broglie in Section 1.22.
Goldstein also queries [10] (p. 337) what information the wave function repre-
sents. He mentions (p. 337) that if the wave function is about information, then ‚Äúit
is presumably concerned directly either with mental events or, more likely, with
the behavior of macroscopic variables.‚Äù But Goldstein also raises the query that
(p. 337) ‚Äúthe very form of the Hamiltonian and wave function strongly points to
a microscopic level of description.‚Äù We have already hinted to the notion of a
Hamiltonian in Chapter 1. The Hamiltonian in a quantum mechanical setting is
2 A sketch of von Neumann‚Äôs proof is provided for on pp. 267‚Äì270 in Jammer [14].
3 Those are postulates P.I‚ÄìP.IV in Jammer [14] (pp. 267‚Äì268).

3.1 What is quantum social science?
59
operator derived and in that sense is very different from the classical mechanics-
based Hamiltonian. There is also evidence from important work performed by Belal
Baaquie [24] that the Hamiltonians which are usable in for instance an interest rate
modeling environment exhibit traits which, from a physics point of view (quantum
mechanical or classical mechanical), are very difÔ¨Åcult to interpret.
Let us come back to the wave function. We mentioned in Section 1.11 that de
Broglie interpreted quantum waves as physical waves. Any undergraduate student
in a physical sciences curriculum will know that there is a very famous relationship,
proposed by no less than Louis de Broglie many many years ago, between a wave
property (i.e. the wave number4) and the momentum of a particle. This is important
to keep in mind, especially in light of our earlier statement that wave functions are
not a unique characteristic of quantum mechanics. As we will see more in detail in
Chapter 6, the wave function can be embedded in a physics model such that it very
clearly affects the behavior of a particle (see [10] (p. 348, Section 6)). We believe it
is in that sense that the wave function takes on the role of information. The simple
algebraic detail of this statement will be shown in Chapter 6, and the transposition
of that important idea within a social science setting was Ô¨Årst proposed by Andrei
Khrennikov (see [8] and [9]).
Hence, so far we seem to come to the hesitating conclusion that quantum social
science seems to have something to do with (i) wave functions, (ii) information
connected to such wave functions, and (iii) a very peculiar model which seems to
connect particles, wave functions, and information. We used the word ‚Äúhesitating‚Äù
as indeed quantum social science as a new Ô¨Åeld does not revolve around solely
those vague (we hope it all gets clearer in Chapter 6) references.
Therefore, let us propose three other facets which may possibly also be included
in this new Ô¨Åeld, quantum social science. The list is clearly non-exhaustive. We will
Ô¨Årst discuss the functional approach by Volovich. A second facet will brieÔ¨Çy treat
the issue of consciousness and quantum mechanics. The third facet will consider a
‚Äúbridge‚Äù model between classical and quantum mechanics.
Volovich, in a Foundations of Physics paper [25], argues that a trajectory in
the Newtonian approach does not have physical real meaning since it embeds the
use of real numbers, while our observations require the use of rational numbers.
He proposes in that paper a so-called functional approach, where the Liouville
equation, which we have already discussed in Section 1.4, is now the starting
point. The functional approach is applied to both classical and quantum mechan-
ics. Interestingly, Volovich shows that with the functional approach the densities
of the distribution functions (for a Gaussian wave packet (see also Chapter 5 for
the idea of such packet)) are the same as the densities used in classical mechanics,
4 See Chapter 5, section 5.9, where we discuss the wave number.

60
Quantum social science: a non-mathematical motivation
as long as a condition is met that equates the Planck constant with the product
of two distribution parameters (this is equation (17) in that paper). We remark
in Chapter 13, where we will discuss the so-called universal Brownian motion,
that the treatment of the stochastic equivalent of so-called Hamilton‚ÄìJacobi equa-
tions will involve the setting of equalities between the Planck constant and other
parameters.
Another possible facet of quantum social science deals with the treatment of
consciousness and quantum physics. We already alluded to the work of Roger
Penrose. But we also believe that this is the correct place in the book to discuss in
some detail the approach Carl Jung, founder of analytical psychology, followed by
attempting to connect psychology with exact science, in particular quantum physics.
Wolfraim [26] describes how Pauli, one of the most eminent quantum physicists
of the twentieth century, was in contact with Jung for many years to discuss how
quantum mechanics could possibly be connected to psychology. This led to the
publication of a book, jointly authored by Jung, Pauli, and Hull [27] in 1955 entitled
The Interpretation of Nature and the Psyche. Wolfraim [26] writes that ‚ÄúBecause
mathematics reÔ¨Çects the order of the Unus Mundus, it solves the profound mystery
of how it is that mathematics, which is a phenomenon of the mind, should prove so
remarkably effective in representing phenomena occurring in the physical world.‚Äù
The meaning of ‚ÄúUnus Mundus‚Äù seems to be what Wolfraim [26] describes as the
‚Äúdeeper levels of the collective unconscious.‚Äù There may be here some connection
with one of the proposals Edward Nelson [28] once made about the nature of the
so-called ‚Äúformalism‚Äù approach to mathematics. Says Nelson [28] (p. 7) ‚Äúwhat is
real in mathematics is the notation, not an imagined denotation.‚Äù This would then,
as we argued in Haven [29], rule out the existence of so-called ‚Äúmodels‚Äù in this
approach to mathematics. We based our argument on the proposal Verhulst [30]
(p. 33) made that ‚ÄúA model . . . is a metaphor with something added, it has not only
qualitative but also quantitative aspects which adds to the precision of description.‚Äù
If there are metaphors which, we could propose, are equivalent to the denotations;
if indeed mathematics is a representation of the mind which at the same time is
also superbly effective in describing natural phenomena, then it must be that there
should be very little ‚Äúhuman construct‚Äù in mathematics. In other words, one could
for instance subscribe to the formalism approach Nelson proposes.
An important point is the possible fact that we may not be able to, as Wolfraim
says [26], ‚Äúdirectly perceive an objective world but only experience a mental repre-
sentation of it constructed from the brain‚Äôs interpretation of incoming sense-data.‚Äù
Of course, if there exists an accurate representation of the external world, it must
be, as per Wolfraim [26], that the images ‚Äúmust be governed by the same environ-
mental constraints and functional properties that we normally attribute to physical
objects, such as spatial depth, motion and rotation as well as environmental forces

3.1 What is quantum social science?
61
such as gravity as well.‚Äù This statement is closely linked to what Wolfraim [26]
calls the ‚ÄúEnvironmental Invariants Hypothesis.‚Äù This hypothesis comes from the
work of Shepard [31] and it is worth noting what this hypothesis stands for. As
Wolfraim [26] says: ‚ÄúThe Environmental Invariants Hypothesis claims that gov-
erning principles inherent in the laws of physics, such as spatiality, momentum,
gravity, friction and centripetal force etc., found in the physical environment, are
also actively present in the mental imagery comprising our perception of an expe-
riential world. That is, our mental representation of the physical world is regulated
by the very same governing principles that apply to the physical environment.‚Äù
Shepard [31] says the following (p. 1318): ‚ÄúAnalogously in psychology, a law that
is invariant across perceptual dimensions, modalities, individuals, and species may
be attainable only by formulating that law with respect to the appropriate abstract
psychological space.‚Äù
Baaquie and Martin [32] describe the psyche of an individual as (p. 11) ‚Äúbeing
represented by a state vector, denoted as |P‚ü©whose elements are all possible states
of an individual‚Äôs psyche.‚Äù Ideas can be expressed also as state vectors and if they
are independent from each other, Baaquie and Martin [32] then indicate that we
can write (in general) (see p. 12): ‚ü®Idea 1|Idea 2‚ü©= 0. The fact that the product of
those ideas is zero embeds the notion of orthogonality. As is also remarked in their
paper, ideas can be seen as superposition of (non-)independent basic ideas. As an
example, watching television may be done with a level of attention which is affected
by the mixing up of other ideas, i.e. one may be thinking of the kids playing in
the garden while watching the television. Thus, as in Baaquie and Martin [32] (see
again p. 12, but also p. 13), the individual‚Äôs psyche is smeared out amongst many
different states (some dependent, some independent) and they write (equations (5)
and (6), p. 13): |a‚ü©= c1|Idea 1‚ü©+ c2|Idea 2‚ü©+ c3|Idea 3‚ü©+ . . . cN|Idea N‚ü©, where
ci are complex numbers and it is the square modulus |ci|2 which can be seen as
the weight or probability of each of the ideas in the superposed thought |a‚ü©. When
the state is normalizable we have that N
i=1 |ci|2 = 1 and the state space which
consists of normalizable states is called a Hilbert space. See also Chapter 5 for
more deÔ¨Ånitions on this topic.
Baaquie and Martin [32] (p. 16), remark that ‚Äú when the mind is observed either
externally or by itself, the density matrix undergoes decoherence . . . (and one can
write): œÅ = N
i=1 |ci|2 |Idea i‚ü©‚ü®Idea i|.‚Äù Free will is an important concept in all of
human decision making. The way that Baaquie and Martin [32] (p. 16) deÔ¨Åne free
will is interesting: it ‚Äúoperates in the freedom of choosing to actualize a particular
state.‚Äù
The stance Baaquie and Martin [32] (see p. 19) take towards the classiÔ¨Åcation
of the human psyche is an interesting one. The paper discusses in detail how a
Fermion and Boson Ô¨Åeld can be used to express the state of the human psyche.

62
Quantum social science: a non-mathematical motivation
Baaquie and Martin [32] also provide for a beautiful idea: the deÔ¨Ånition of
self-consciousness is seen as the rate of change of consciousness (see p. 27).
They introduce a time variable which has the peculiarity that it can be seen as the
psychological time of an individual. Baaquie has used this interpretation of time in
some of his other work. Equation (17) (p. 27) deÔ¨Ånes the time-dependent change
of the creation operator as ‚àÇa‚Ä≤(x,t)
‚àÇts
= ‚àÇt
‚àÇts
‚àÇa‚Ä≤
‚àÇt , and it is remarked that the operator ‚àÇa‚Ä≤
‚àÇt
and the operator a‚Ä≤ do not commute. As Baaquie and Martin [32] (p. 27) remark, it
is not allowed that one is at the same time in the state of consciousness AND in the
state of self-consciousness. The absence of precise measurement on position and
momentum we will also argue for in later chapters, notably Chapter 13.
Baaquie and Martin [32] also propose the idea (p. 36) that one can probe an
electron at different scales and this scale-dependent probing thus gives different
results in terms of energy measurements. They propose that this scale dependency
can also be applied to the Ô¨Åeld of the human psyche.
Let us consider (very brieÔ¨Çy) the third facet to quantum social science: a ‚Äúbridge‚Äù
model between classical and quantum mechanics. This model proposed by Aerts
and Durt appeared Ô¨Årst in Foundations of Physics [33]. The authors propose a
sphere model where three major situations are distinguished: (i) a situation where
the Ô¨Çuctuations on the experimental apparatus is maximal; (ii) a situation where
the Ô¨Çuctuations on the experimental apparatus is zero; and (iii) an intermediate
situation. The Ô¨Çuctuations have nothing to do with measurement error due to the
apparatus. Different types of probabilities (Kolmogorovian or not Kolmogorovian)
are found in the three models.
Another bridge model, which we will discuss in much more detail in
Chapter 13, is the model which considers the stochastic equivalent of the Hamilton‚Äì
Jacobi equations.
Are we any further in our elucidation of what quantum social science now is? The
aware reader can sense that this is a very multifaceted movement, but it resolutely
uses a quantum mechanical tool kit. But why? We hope to convince the reader
that the use of this quantum mechanical toolkit has given interesting insights into
a variety of areas of the social sciences. We thus turn in the next sub-section to
highlight some of the past and current achievements.
3.2 Key Ô¨Åndings from quantum social science
The title of this section is somewhat ambitious. We will attempt to provide a brief
overview of some of the key Ô¨Åndings. Clearly, we cannot provide much detail on
any of those key Ô¨Åndings as much more detail will follow in later chapters. It is our
intention to give an appetite-inducing Ô¨Çavor of some of the achievements to date
in the Ô¨Åeld.

3.2 Key Ô¨Åndings from quantum social science
63
Quantum social science has been working on multiple problems, which we can
divide into the following groups:
r Ô¨Ånancial asset pricing,
r decision making,
r quantum game theory,
r new social science concepts.
A reference, which treats all of the above groups in detail, is by Khrennikov
[34].
In the area of Ô¨Ånancial asset pricing, research in quantum social science may
have started as early as 1998, with a paper by Segal and Segal [35] on a reformu-
lation of the Black‚ÄìScholes option pricing equation within a quantum mechanical
context. Related work on the topic of such speciÔ¨Åc embedding was also performed
by Accardi and Boukas [36]. But there was also much earlier work by Hudson
and Parthasarathy [37] who brought out a paper on the formulation of a quan-
tum version of the ItÀÜo formula. Belal Baaquie‚Äôs work on using a non-stochastic
approach towards Ô¨Ånancial derivative pricing can be found in his 2005 book [38].
But Baaquie went beyond a mere reformulation of derivative pricing. He extended
his analysis, intensively using path integration,5 to other areas of Ô¨Ånance, notably
to interest rate modeling [24]. He also provided for a world primer on using the
Wilson expansion in Ô¨Ånance. Baaquie also is currently developing very interesting
Hamiltonians, which for the most part are quite devoid of any physics-based inter-
pretation. This also shows quite clearly that a simple ‚Äúimport‚Äù of physics principles
into social science may well be much less evident than previously anticipated.
Brandenburger, a celebrated economist, together with Yanofsky [40] produced
a paper where a classiÔ¨Åcation scheme is proposed, which aids in better under-
standing the hidden variable theory interpretation of quantum physics. Bohmian
mechanics and its applications to economics and Ô¨Ånance, as we have already
mentioned at the beginning of this chapter (and in other chapters), was Ô¨Årst intro-
duced by Khrennikov [8] [9]. See also Choustova [41] and Haven [42]. In Haven
[43], the Wentzel‚ÄìKramers‚ÄìBrillouin approximation in option pricing theory is
considered.
In the area of decision making and psychology, we can mention the early work
of Belal Baaquie [44] on how quantum Ô¨Åeld theory can be used to model con-
sciousness.6 See also Deutsch [45]. We also mention the work of Khrennikov [46]
[47] on the pilot wave (Bohmian-like) model of dynamical processing of con-
scious and unconscious information by the brain. Here the classical conÔ¨Åguration
5 Path integration was developed by Feynman, and following Vardarajan [39] it can be seen as an equivalent
model to the von Neumann approach when wanting to construct probability models to explain complementarity.
6 We also mentioned some of the related work in the Ô¨Årst section of this chapter. See [32].

64
Quantum social science: a non-mathematical motivation
space is given, not by the real continuum, but by Ô¨Åelds of p-adic numbers (dis-
crete hierarchic trees). Brandenburger and La Mura [48] investigate how decision
makers when given access to quantum signals can improve their decision making.
For instance, memory limitations can be overcome via the setting up of so-called
quantum signals.
Busemeyer et al. [49] and Busemeyer and Wang [50] have shown that the
Ellsberg paradox (a decision making paradox well known in psychology and eco-
nomics) can be explained with the help of probability interference. See also Khren-
nikov and Haven [51]. The interference concept will be explained in Chapter 5 and
it will be shown how to apply it to decision making in Chapter 8 (see for this Asano
et al. [52]; Asano et al. [53]; Accardi et al. [54]).
Danilov and Lambert-Mogiliansky [55] develop non-expected utility with the
help of quantum mechanical concepts. Finally, La Mura [56] shows how quantum
mechanical concepts can solve (amongst others) the Rabin paradox. The use of
experiments to uncover quantum mechanical behavior at the level of decision
making are discussed in Conte et al. [57] and in Khrennikov [59][58]. See also
Bordley and Kadane [60].
In regards to quantum game theory, inÔ¨Çuential work is by Eisert et al. [61],
Brandenburger [62], and La Mura [63]. Quantum games do allow for another
consideration of equilibriae when qubits are considered. Broekaert et al. [64]
generalize the famous liar paradox with the aid of quantum mechanics.
Finally, new social science concepts have been contributed mainly in the area
of devising a relevant social science-based uncertainty principle. Martin Shubik
[65], as early as 1999, did mention that ‚Äúmodern Ô¨Ånance . . . has not yet provided
us with either the appropriate concepts or measures for the bounds on the minimal
overall uncertainty that have to be present in an economy.‚Äù Baaquie [38] discusses a
pragmatic approach to a social-science-based-version of the Heisenberg uncertainty
principle. See also Bordley [66].
3.3 References
[1] Penrose, R. (1989). The Emperor‚Äôs New Mind: Concerning Computers, Minds and
the Laws of Physics. Oxford University Press.
[2] Penrose, R. (1994). Shadows of the Mind: A Search for the Missing Science of
Consciousness. Oxford University Press.
[3] Penrose, R. and Hameroff, S. (2011). Editors of the Special Issue: Consciousness and
the universe. Journal of Cosmology, 14.
[4] Hameroff, S. and Penrose, R. (1996). Orchestrated reduction of quantum coherence
in brain microtubules: a model for consciousness? In Toward a Science of Conscious-
ness: The First Tucson Discussions and Debates. Eds. Hameroff, S., Kaszniak, A.,
and Scott, A., MIT Press, pp. 507‚Äì540.

3.2 Key Ô¨Åndings from quantum social science
65
[5] Hagan, S., Hameroff, S., and Tuszynski, J. (2002). Quantum computation in
brain microtubules? Decoherence and biological feasibility. Physical Review E, 65,
061901.
[6] Boyle, P. (1977). Options: a Monte Carlo approach. Journal of Financial Economics,
4, 4, 323‚Äì338.
[7] Ma, C. (2010). Advanced Asset Pricing Theory. Imperial College Press.
[8] Khrennikov, A. Yu. (1999). Classical and quantum mechanics on information spaces
with applications to cognitive, psychological, social and anomalous phenomena.
Foundations of Physics, 29, 1065‚Äì1098.
[9] Khrennikov, A. Yu. (2004). Information dynamics in cognitive, psychological and
anomalous phenomena. Series in the Fundamental Theories of Physics. Kluwer,
Dordrecht.
[10] Goldstein, S. (2009). Bohmian mechanics and quantum information. Foundations of
Physics, 40, 335‚Äì355.
[11] Bouwmeester, D. and Zeilinger, A. (2010). The physics of quantum information: basic
concepts. In The Physics of Quantum Information. Eds. Bouwmeester, D., Ekert, A.,
and Zeilinger, A., Springer Verlag, Berlin.
[12] Fuchs, C. A. (2002). Quantum mechanics as quantum information (and only a lit-
tle more). In Quantum Theory: Reconsideration of Foundations. Ed. Khrennikov,
A. Yu. Series Mathematical Modelling, 2, V¬®axj¬®o University Press, V¬®axj¬®o, Sweden,
pp. 463‚Äì543.
[13] Fuchs, C. A. (2007). Delirium quantum (or, where I will take quantum mechanics
if it will let me). In Foundations of Probability and Physics-3. Eds. Adenier, G.,
Fuchs, C., and Khrennikov, A. Yu., American Institute of Physics, Conference Series
Proceedings, 889, Melville, NY, pp. 438‚Äì462.
[14] Jammer, M. (1974). The Philosophy of Quantum Mechanics. J. Wiley, New York.
[15] Born, M. (1927). Physical aspects of quantum mechanics. Nature, 119, 354‚Äì357
(reprint).
[16] Bohm, D. (1959). Quantum Theory. Prentice Hall.
[17] Bohm, D. (1952a). A suggested interpretation of the quantum theory in terms of
hidden variables. Physical Review, 85, 166‚Äì179.
[18] Bohm, D. (1952b). A suggested interpretation of the quantum theory in terms of
hidden variables. Physical Review, 85, 180‚Äì193.
[19] Jauch, J. M. and Piron, C. (1963). Can hidden variables be excluded in quantum
mechanics? Helvetica Physica Acta, 36, 827‚Äì837.
[20] Kochen, S. and Specker, E. P. (1967). The problem of hidden variables in quantum
mechanics. Journal of Mathematics and Mechanics, 17, 59‚Äì87.
[21] Bohm, D. and Bub, J. (1966). A refutation of the proof by Jauch and Piron that hidden
variables can be excluded in quantum mechanics. Review of Modern Physics, 38,
470‚Äì475.
[22] Bell, J. S. (1964). On the Problem of Hidden Variables in Quantum Mechanics.
Preprint, SLAC-PUB-44, Stanford University.
[23] Bell, J. S. (1966). On the problem of hidden variables in quantum mechanics. Reviews
of Modern Physics, 38, 447‚Äì452.
[24] Baaquie, B. (2009). Interest rates in quantum Ô¨Ånance: the Wilson expansion and
Hamiltonian. Physical Review E, 80, 046119.
[25] Volovich, I. V. (2011). Randomness in classical mechanics and quantum mechanics.
Foundations of Physics, 41, 3, 516‚Äì528.
[26] Wolfraim, D. H. (2010). The Unity of Psyche and World. www.psybernet.co.nz/
Ô¨Åles/The-Unity-of-Psyche-and-World.txt.

66
Quantum social science: a non-mathematical motivation
[27] Jung, C., Pauli, W., and Hull, R. (1955). The Interpretation of Nature and the Psyche.
Routledge & Kegan Paul.
[28] Nelson, E. (2010). Confessions of an Apostate Mathematician. http://www.math.
princeton.edu/Àúnelson/papers.html.
[29] Haven, E. (2010). Metaphors and interdisciplinary research. In Proceedings of the
First CHESS Interdisciplinary Conference. Eds. Rangacharyulu, C. and Haven, E.,
University of Saskatchewan (Canada), WorldscientiÔ¨Åc Press, Singapore.
[30] Verhulst, F. (1999). The Validation of Metaphors. In Validation of Simulation. Eds. van
Dijkum, C., DeTombe, D., and van Kuijk, E., SISWO Publication 403, Amsterdam,
pp. 30‚Äì45.
[31] Shepard, R. N. (1987). Towards a universal law of generalization for psychological
science. Science, 237, 4820, 1317‚Äì1323.
[32] Baaquie, B. and Martin, F. (2005). Quantum psyche: quantum Ô¨Åeld theory of the
human psyche. NeuroQuantology, 1, 7‚Äì42.
[33] Aerts, D. and Durt, T. (1994). Quantum, classical and intermediate: an illustrative
example. Foundations of Physics, 24, 1353‚Äì1369.
[34] Khrennikov, A. (2010). Ubiquitous Quantum Structure: From Psychology to Finance.
Springer Verlag.
[35] Segal, W. and Segal, I. E. (1998). The Black‚ÄìScholes pricing formula in the quantum
context. Proceedings of the National Academy of Sciences of the USA, 95, 4072‚Äì4075.
[36] Accardi, L. and Boukas, A. (2007). The quantum Black‚ÄìScholes equation. Global
Journal of Pure and Applied Mathematic, 2, 2, 155‚Äì170.
[37] Hudson, R. L. and Parthasarathy, K. R. (1984). Quantum Ito‚Äôs formula and stochastic
evolutions. Communications in Mathematical Physics, 93, 301‚Äì323.
[38] Baaquie, B. (2005). Quantum Finance. Cambridge University Press.
[39] Varadarajan, V. S. (2008). The quantum dice. Talk given at U.C.L.A., Slides 1-20.
[40] Brandenburger, A. and Yanofsky, N. (2007). A classiÔ¨Åcation of hidden-variable prop-
erties. Journal of Physics A: Mathematical and Theoretical, 41, 425302.
[41] Choustova, O. (2006). Quantum Bohmian model for Ô¨Ånancial markets. Physica A,
374, 304‚Äì314.
[42] Haven, E. (2005). Pilot-wave theory and Ô¨Ånancial option pricing. International Jour-
nal of Theoretical Physics, 44, 1957‚Äì1962.
[43] Haven, E. (2005). Analytical solutions to the backward Kolmogorov PDE via an
adiabatic approximation to the Schr¬®odinger PDE. Journal of Mathematical Analysis
and Applications, 311, 439‚Äì444.
[44] Baaquie, B. (1987). Quantum Ô¨Åeld theory as model of consciousness. Unpublished.
[45] Deutsch, D. (1999). Quantum theory of probability and decisions. Proceedings of the
Royal Society London A, 455, 3129‚Äì3137.
[46] Khrennikov, A. (1999). p-adic information spaces, inÔ¨Ånitely small probabilities and
anomalous phenomena. Journal of ScientiÔ¨Åc Exploration, 4, 13, 665‚Äì680.
[47] Khrennikov, A. (2000). Classical and quantum mechanics on p-adic trees of ideas.
BioSystems, 56, 95‚Äì120.
[48] Brandenburger, A. and La Mura, P. (2011). Quantum Decision Theory. Please see:
http://arxiv.org/abs/1107.023, Cornell University.
[49] Busemeyer, J., Wang, Z., and Townsend, J. T. (2006). Quantum dynamics of human
decision making. Journal of Mathematical Psychology, 50, 3, 220‚Äì241.
[50] Busemeyer, J. and Wang, Z. (2007). Quantum information processing explanation for
interactions between inferences and decisions. In AAAI Spring Symposium on Quan-
tum Interaction (Stanford University). Eds. Bruza, P., Lawless, W., van Rijsbergen,
K., and Sofge, D., AAAI Press, pp. 91‚Äì97.

3.2 Key Ô¨Åndings from quantum social science
67
[51] Khrennikov, A. Yu. and Haven, E. (2009). Quantum mechanics and violations of the
sure-thing principle: the use of probability interference and other concepts. Journal
of Mathematical Psychology, 53, 378‚Äì388.
[52] Asano, M., Ohya, M., Tanaka, Y., Basieva, I., and Khrennikov, A. (2011). Quantum-
like model of brain‚Äôs functioning: decision making from decoherence. Journal of
Theoretical Biology, 281, 56‚Äì64.
[53] Asano, M., Ohya, M., and Khrennikov, A. (2011). Quantum-like model for decision
making process in two players game ‚Äì a non-Kolmogorovian model. Foundations of
Physics, 41, 538‚Äì548.
[54] Accardi, L., Khrennikov, A., and Ohya, M. (2009). Quantum Markov model for
data from ShaÔ¨År‚ÄìTversky experiments in cognitive psychology. Open Systems and
Information Dynamics, 16, 371‚Äì385.
[55] Danilov, V. I. and Lambert-Mogiliansky, A. (2007). Non-classical expected util-
ity theory with application to type indeterminacy. Preprint Paris-Jourdan Sciences
Economiques.
[56] La Mura, P. (2006). Projective expected utility. Mimeo. Leipzig Graduate School of
Management.
[57] Conte, E., Todarello, O., Federici, A., Vitiello, F., Lopane, M., Khrennikov, A., and
Zbilut, J. (2007). Some remarks on an experiment suggesting quantum-like behavior
of cognitive entities and formulation of an abstract quantum mechanical formalism to
describe cognitive entity and its dynamics. Chaos Solitons Fractals, 31, 1076‚Äì1088.
[58] Khrennikov, A. Yu. (2004). On quantum-like probabilistic structure of mental infor-
mation. Open Systems and Information Dynamics, 11, 267‚Äì275.
[59] Khrennikov, A. Yu. (2003). Quantum-like formalism for cognitive measurements.
Biosystems, 70, 211‚Äì233.
[60] Bordley, R. F. and Kadane, J. (1999). Experiment dependent priors in psychology and
physics. Theory and Decision, 47, 213‚Äì227.
[61] Eisert, J., Wilkens, M., and Lewenstein, M. (1999). Quantum games and quantum
strategies. Physical Review Letters, 83, 3077‚Äì3080.
[62] Brandenburger, A. (2010). The relationship between quantum and classical correlation
in games. Games and Economic Behavior, 69, 175‚Äì183.
[63] La Mura, P. (2005). Correlated equilibria of classical strategic games with quantum
signals. International Journal of Quantum Information, 3, 183‚Äì188.
[64] Broekaert, J., Aerts, D., and D‚ÄôHooghe, B. (2006). The generalized liar paradox: a
quantum model and interpretation. Foundations of Science, 11, 4, 399‚Äì418.
[65] Shubik, M. (1999). Quantum economics, uncertainty and the optimal grid size. Eco-
nomics Letters, 64, 3, 277‚Äì278.
[66] Bordley, R. F. (1998). Quantum mechanical and human violations of compound prob-
ability principles: toward a generalized Heisenberg uncertainty principle. Operations
Research, 46, 923‚Äì926.


Part II
Mathematics and physics preliminaries


4
Vector calculus and other mathematical preliminaries
4.1 Linear spaces
In essence vector spaces are quite simple mathematical objects. We can distinguish
between so called ‚Äòreal vector spaces‚Äô and the maybe less used ‚Äòcomplex vector
spaces‚Äô. The former uses real numbers, while the latter uses complex numbers. For
the novice reader, many textbooks will give a deÔ¨Ånition of such a space and they
very often will go into more detail (such as on covering the notion of subspaces;
product of spaces and span). Hubbard and Hubbard [1]; Kreyszig [2] and Ha [3]
are good examples.
The real vector space V is characterized by i) commutativity in addition and
hence for two vectors a, b ‚ààV : a + b = b + a; ii) associativity in addition and
hence for vectors a, b, c ‚ààV : (a + b) + c = a + (b + c); iii) the existence of a
vector 0 ‚ààV such that: a + 0 = a; iv) for each vector a ‚ààV there exists an additive
inverse, ‚àía : (‚àía) + a = 0. Moreover, for real scalars Œ±, Œ≤ ‚ààR and vectors a, b ‚àà
V , the following simple laws need to be satisÔ¨Åed: i) 1a = a; ii) (Œ± + Œ≤) a =
Œ±a + Œ≤a (distributivity towards scalars); iii) Œ± (a + b) = Œ±a + Œ±b (distributivity
towards vectors): iv) Œ± (Œ≤a) = (Œ±Œ≤) a (associativity). The complex vector space is
obtained by just swapping the real scalars for complex scalars.
An important concept which is very often deÔ¨Åned in relation to vector spaces
is the concept of a basis of a vector space. The deÔ¨Ånition is quite immediate.
A vector space V is n-dimensional if its basis contains n linearly independent
vectors. n vectors are linearly independent when vectors b1, b2, . . . bn ‚ààV and n
real scalars: Œ±1, Œ±2, . . . Œ±n ‚ààR: Œ±1b1 + Œ±2b2 . . . . . Œ±nbn = 0 (with 0 ‚ààV ) such that
Œ±1 = Œ±2 . . . = Œ±n = 0 (with 0 ‚ààR). The set of n linearly independent vectors is
called a basis of dimension n.
71

72
Vector calculus and other mathematical preliminaries
4.2 References
[1] Hubbard, J. H. and Hubbard, B. B. (2002). Vector Calculus, Linear Algebra and
Differential Forms: A UniÔ¨Åed Approach. 2nd edition. Prentice Hall.
[2] Kreyszig, E. (1999). Advanced Engineering Mathematics. J. Wiley.
[3] Ha, D. M. (2006). Functional Analysis. Volume 1. Matrix Editions, New York.
4.3 State space: Hilbert space
We denote the Ô¨Åelds of real and complex numbers by the symbol C and R,
respectively; for a complex number z = u + iv, u, v ‚ààR, ¬Øz denotes its conju-
gate: ¬Øz = u ‚àíiv; |z| = ‚àöz¬Øz =
‚àö
u2 + v2.
The basic mathematical structure of quantum mechanics is a complex Hilbert
space, H: a linear space over complex numbers (i.e. it is possible to form linear
combinations of vectors with complex coefÔ¨Åcients) endowed with a scalar product.
The latter is a form of mapping a pair of vectors œà1, œà2 ‚ààH into a complex number
‚ü®œà1, œà2‚ü©. It has the following properties:
r ‚ü®œà, œà‚ü©‚â•0 (positive ‚àídeÔ¨Åniteness);
r ‚ü®œà, œà‚ü©= 0 if and only if œà = 0 (non-degeneration);
r ‚ü®œà1, œà2‚ü©= ‚ü®œà2, œà1‚ü©(conjugate symmetry);
r ‚ü®œà, Œ±œà1 + Œ≤œà2‚ü©= Œ±‚ü®œà, œà1‚ü©+ Œ≤‚ü®œà, œà2‚ü©, Œ±, Œ≤ ‚ààC, œàk, œà ‚ààH
(linearity with respect to the second argument).
As a consequence, we obtain that:
r ‚ü®Œ±œà1 + Œ≤œà2, œà‚ü©= ¬ØŒ±‚ü®œà1, œà‚ü©+ ¬ØŒ≤‚ü®œà2, œà‚ü©.
We remark that in the physical literature, the scalar product is linear with respect
to the second argument, as in this book. In the mathematical literature, it is linear
with respect to the Ô¨Årst argument.
The theory is especially simple in the Ô¨Ånite-dimensional case (which is typically
considered in quantum information theory). Here H = Cn is the Cartesian product
of n-copies of the set of complex numbers C. Hence, a pure state:
œà = (z1, . . . , zn),
(4.1)
where:
‚à•œà‚à•2 = |z1|2 + ¬∑ ¬∑ ¬∑ + |zn|2 = 1.
(4.2)
We remarked above that a Hilbert space is a linear space. As per Messiah
[1] (p. 164), this means that for two square integrable functions 1 and 2, the

4.5 Operators
73
linear combination Œ±1 + Œ≤2, where Œ± and Œ≤ are complex numbers, are also
square integrable functions. A square integrable function  is a function such that
 ||2 dx converges. Still following Messiah [1] (pp. 164‚Äì166), the existence of
linearity and the existence of a scalar product are two important characteristics
of a Hilbert space. However, the completeness, which is a property of square
integrable functions, is the hallmark property which really makes a space a Hilbert
space. The completeness property requires Cauchy convergence of any sequence
of square integrable functions towards a square integrable function (AND vice
versa!). This then means that any square integrable function can be seen as the
limit of a Cauchy converging sequence.
We note that deÔ¨Ånitions of the Hilbert space can be found in many books.
The interested reader may want to peruse Aleksandrov et al. [2] (pp. 234‚Äì237).
Messiah [1] (pp. 164‚Äì166), discusses the linearity and completeness of a Hilbert
space. From a more function analytical point of view, Hilbert spaces can also be
deÔ¨Åned as so-called inner product spaces, but with some important conditions. See
Ha [3] (p. 292) and (p. 296) for, respectively, the deÔ¨Ånition of an inner product
space and the induced normed space. The relationship between a Hilbert space and
an induced normed space is deÔ¨Åned in Ha [3] (p. 300). We note that Gustafson and
Sigal [4] (p. 6) also give a good overview of the deÔ¨Ånition of a Hilbert space.
4.4 References
[1] Messiah, A. (1961). Quantum Mechanics. Volume 1. North-Holland.
[2] Aleksandrov, A. D., Kolmogorov, A. N., and Lavrent‚Äôev, M. A. (1984). Mathematics:
Its Content, Methods and Meaning. Volume 3. The MIT Press, MA.
[3] Ha, D. M. (2006). Functional Analysis. Volume 1. Matrix Editions. New York.
[4] Gustafson, S. J. and Sigal, I. M. (2006). Mathematical Concepts of Quantum Mechan-
ics. Springer Verlag, Berlin.
4.5 Operators
We have already hinted at the existence of operators in Chapter 1 (see for instance
Section 1.13 on Heisenberg‚Äôs symbolic calculus). In fact, a formal deÔ¨Ånition of a
position and momentum operator is given in equation (1.50). For the beneÔ¨Åt of the
reader, we expand a little more on operators and related concepts in this section.
An operator in its most basic form can just be seen as an operation which changes
one function f (x) into another function g(x). See for instance Fong [1] for more
on the real basics of operators or also Haken and Wolf [2].
An essential characteristic of the algebra of linear operators is the non-
commutativity of the product of two operators. Linear operators w and v can
be deÔ¨Åned as: (i) wŒ±œà = Œ±wœà and (ii) w [Œ±œà1 + Œ≤œà2] = Œ±wœà1 + Œ≤wœà2, where
Œ± and Œ≤ are arbitrary complex constants.

74
Vector calculus and other mathematical preliminaries
Clearly, if w is an operator and v is another operator, then the expression
vwf (x), wherev acts on wf (x), may not at all be equal to the expression generated
by wvf (x), where w acts on vf (x). Please see for instance Messiah [3] for more
details. Bowman [4] indicates (pp. 53‚Äì54) that the ‚Äúfundamental entity (in quantum
physics) is the quantum state‚Äù and it is the behavior of such a state which is key.
Measurements of quantum states are performed via the route of operators. Operators
when applied on a quantum state will change that quantum state unless the operator
is the identity operator.
According to Morrison [5] (p. 160), it were the mathematics luminaries Leibniz
and Lagrange who founded the so-called operator method and Boole was one
of the protagonists of the so-called formal theory of operators when applied to
quantum mechanics. An operator, w, is deÔ¨Åned relative to a function in the following
straightforward way:1 g(x) = wf (x). Here is a simple example of an operator
w: take the derivative of the function f (x) : wf (x) = df (x)
dx . Operators carry the
distributive property towards addition and substraction. Furthermore, the product
of two operators yields a third operator. Recall the deÔ¨Ånition of position and
momentum operators introduced in equation (1.50). Those two operators do not
commute. It is simple to show why this is the case. Consider a function f (x). Show
that qpf (x) Ã∏= pqf (x). One just needs to write the deÔ¨Ånition of the momentum
operator, p = ‚àíi¬Øh ‚àÇ
‚àÇq , and apply it to: pqf (x) = ‚àíi¬Øh ‚àÇ
‚àÇq (qf (x)). This is clearly not
the same as: q(‚àíi¬Øh ‚àÇ
‚àÇq (f (x))), as one takes the derivative of a product on the right-
hand side of the non-equality but no such product exists on the left-hand side of
the non-equality. In fact, it also is straightforward to show that qpf (x) ‚àípqf (x)
is equal to i¬Øhf (x) and this can be slightly rewritten as qp ‚àípq = i¬Øh1, where1 is
the identity operator. This equality, which is the Heisenberg uncertainty relation,
was already introduced in Chapter 1, equation (1.54).
Hermitian operators are covered below (under ‚ÄúHermiticity‚Äù). Projection oper-
ators can be introduced via the concept of bras and kets (please see below under
‚ÄúDirac brakets and bras and kets‚Äù and for a deÔ¨Ånition see the entry below on
projection operators).
Identity operators, as mentioned above, leave unchanged a quantum state.
The ‚Äúunitary operators‚Äù can be deÔ¨Åned via the notion of an adjoint operator.
Please see below again under ‚ÄúDirac brakets and bras and kets.‚Äù
An operator w is bounded if ‚à•w‚à•= sup{‚ààH:‚à•‚à•=1} ‚à•wœà‚à•< ‚àû. We need
to stress that the basic operators of quantum mechanics such as position and
momentum and the majority of Hamiltonians are not bounded. Nevertheless,
bounded operators play an important role in quantum mechanics, especially in
1 We denote operators, as in Chapter 1, with a cap.

4.7 Dirac brakets and bras and kets
75
quantum information theory. Please see also the section on projection operators
(Section 4.13).
Jackson [6] is a further good source for a discussion on operators.
4.6 References
[1] Fong, P. (2005). Elementary Quantum Mechanics. World ScientiÔ¨Åc.
[2] Haken, H. and Wolf, H. C. (1984). Atomic and Quantum Physics. Springer Verlag,
Berlin.
[3] Messiah, A. (1961). Quantum Mechanics. Volume 1. North-Holland.
[4] Bowman, G. (2008). Essential Quantum Mechanics. Oxford University Press.
[5] Morrison, Michael A. (1990). Understanding Quantum Physics: A User‚Äôs Manual.
Volume 1. 1st edition. Pearson Education, Upper Saddle River, NJ.
[6] Jackson, J. D. (1961). Mathematics for Quantum Mechanics. W. A. Benjamin.
4.7 Dirac brakets and bras and kets
We now turn to Dirac‚Äôs symbolism.2 We recall the notions of ket and bra vectors.
Elements of the Hilbert space H are called ket vectors and they are denoted as
|œà‚ü©. Elements of the dual space H ‚àó, the space of linear continuous functionals on
H, are called bra vectors. They are denoted as ‚ü®œÜ|. Basically, the symbol ‚ü®œÜ|œà‚ü©
has the meaning of the action of the functional ‚ü®œÜ| to the vector |œà‚ü©. However,
since the dual space H ‚àóis isomorphic to H, we can always identify a bra vector
with the corresponding ket vector. After such identiÔ¨Åcation, the pairing ‚ü®œÜ|œà‚ü©has
the properties of a scalar product. Thus, for two vectors œÜ, œà ‚ààH or in the Dirac
notation two ket vectors |œÜ‚ü©, |œà‚ü©:
‚ü®œÜ, œà‚ü©= ‚ü®|œÜ‚ü©, |œà‚ü©‚ü©= ‚ü®œÜ|œà‚ü©.
(4.3)
Hence, we can rewrite properties of the scalar product by using Dirac‚Äôs
symbolism:
r ‚ü®œà|œà‚ü©‚â•0 (positive ‚àídeÔ¨Åniteness);
r ‚ü®œà|œà‚ü©= 0 if and only if œà = 0 (non-degeneration);
r ‚ü®œà1|œà2‚ü©= ‚ü®œà2|œà1‚ü©(conjugate symmetry);
r ‚ü®œà|Œ±œà1 + Œ≤œà2‚ü©= Œ±‚ü®œà|œà1‚ü©+ Œ≤‚ü®œà|œà2‚ü©, Œ±, Œ≤ ‚ààC, œàk, œà ‚ààH
(linearity with respect to the second argument).
As a consequence, we obtain that:
r ‚ü®Œ±œà1 + Œ≤œà2|œà‚ü©= ¬ØŒ±‚ü®œà1|œà‚ü©+ ¬ØŒ≤‚ü®œà2|œà‚ü©.
Let us now consider how operators function within Dirac brakets. Following
Morrison [1] (p. 444) (equation 10.17), a Dirac braket can be deÔ¨Åned as ‚ü®œà1|wœà2‚ü©‚â°
2 This is a formalism which is basic in quantum information theory.

76
Vector calculus and other mathematical preliminaries

œà‚àó
1 (wœà2)dv, where œà‚àó
1 denotes the complex conjugate3 of œà1. The operator
w acts on the state function œà2. Note that ‚ü®œà1|wœà2‚ü©is also written sometimes
as ‚ü®œà1|w|œà2‚ü©. We can write that the operator w acts on a state as w|œà‚ü©. Now
consider again ‚ü®œà1|wœà2‚ü©, and this means the operator w acts on the state |œà‚ü©,
i.e. on the ‚Äúket.‚Äù But there is no action on the bra, when using ‚ü®œà1|wœà2‚ü©. It is
the adjoint operator which operates on the bra. Bowman [2] (p. 56) deÔ¨Ånes the
adjoint operator as an operator which acts on a bra, producing a new bra which
then corresponds to a ket formed by another operator. If w is an operator, then,
if w+ is the adjoint operator, one can write w|œà‚ü©= |œÜ‚ü©‚Üê‚Üí‚ü®œà|w+ = ‚ü®œÜ|. This
means the action of the operator w on the ket state |œà‚ü©produces a new ket state
|œÜ‚ü©. This ket state corresponds to the bra state ‚ü®œÜ| obtained by the action of the
operator w+ on the bra state ‚ü®œà|. Please note that operators are deÔ¨Åned on the
Hilbert space. The state function is then an element of the Hilbert space. See
for instance Gustafson and Sigal [3]. The Hilbert space is further considered in
Section 5.1.
The unitary operator is deÔ¨Åned as follows. If the inverse of an operator w,
denoted as w‚àí1, is equal to the adjoint operator w+, then w is a unitary operator.
The inverse operator is such that ww‚àí1 = w‚àí1w = identity operator. It is important
to stress that the basic property of a unitary operator is that it preserves the scalar
product (and hence the norm).
The essential component in unitary transformations is the unitary operator. Fol-
lowing Bransden and Joachain [4] (p. 216), ‚Äúthe application of a unitary operator
to every wave function is called a unitary transformation.‚Äù Messiah [5] (p. 292)
indicates that ‚Äúthe product of two unitary transformations is a unitary transforma-
tion.‚Äù A transformation is so-called ‚ÄúinÔ¨Ånitesimal‚Äù if the operator U deÔ¨Åning the
unitary transformation can be written as (this is equation VII.94 in Messiah [5]
(p. 292)) U = I + iŒµF, where F is a Hermitian operator (Hermitian operators are
covered below, under ‚ÄúHermiticity‚Äù), I is the identity operator, i ‚ààC, and Œµ is an
inÔ¨Ånitesimal real quantity.
If one writes the following Dirac braket ‚ü®œà1|wœà1‚ü©‚â°

œà‚àó
1 (wœà1)dv, then this
yields the expectation value. One can also write ‚ü®wœà1|œà2‚ü©‚â°

(w‚àóœà‚àó
1 )œà2dv. Note
the effect of the operator now on the state function œà‚àó
1 .
4.8 References
[1] Morrison, Michael, A. (1990). Understanding Quantum Physics: A User‚Äôs Manual.
Volume 1. 1st Edition. Pearson Education, Upper Saddle River, NJ.
[2] Bowman, G. (2008). Essential Quantum Mechanics. Oxford University Press.
3 The notion of conjugate was Ô¨Årst introduced in Chapter 1, Section 1.13. See also Section 4.3.

4.11 Hermiticity
77
[3] Gustafson, S. J. and Sigal, I. M. (2006). Mathematical Concepts of Quantum Mechan-
ics. Springer Verlag, Berlin.
[4] Bransden, B. H. and Joachain, C. J. (2000). Quantum Mechanics. Prentice Hall.
[5] Messiah, A. (1961). Quantum Mechanics. Volume 1. North-Holland.
4.9 Eigenvalues/eigenfunction
Eigenvalues were already brieÔ¨Çy mentioned in Chapter 1. We give a little more
detail here. In Chapter 5, we use the concept again when we give some detail on the
time-(in)dependent Schr¬®odinger equation. The eigenvalue equation for an operator
w, with eigenfunction fl and eigenvalue l, is given by wfl = lfl. For the deÔ¨Ånition
of an operator, please see above. The eigenvalues of the operator can be discrete
valued, and/or continuous valued. When the function fl is replaced by a quantum
mechanical wave function, œà, the eigenvalue equation is then often re-named as an
eigenstate equation, wœà = lœà, and œà can be seen as an eigenstate. Haken and Wolf
[1] (p. 130) indicate that ‚Äúeigenvalues are identical with the observed values.‚Äù To
put it somewhat more precisely, postulate 4 (see also below, Section 5.5, for more
of a discussion on postulates in quantum mechanics) in Bransden and Joachain [2]
(p. 199) indicates that the ‚Äúonly result of a precise measurement of the dynamical
variable . . . is one of the eigenvalues . . . of the linear operator associated with (the
dynamical variable).‚Äù
4.10 References
[1] Haken, H. and Wolf, H. C. (1984). Atomic and Quantum Physics. Springer Verlag,
Berlin.
[2] Bransden, B. H. and Joachain, C. J. (2000). Quantum Mechanics. Prentice Hall.
4.11 Hermiticity
One of the key postulates of quantum mechanics (postulate 3, please see
Section 5.5 in Chapter 5) mentions that observables are represented by operators.
However, there is an essential condition which needs fulÔ¨Ålling if such is the case,
and this is the characteristic that all operators must satisfy Hermiticity.4 Although
the term seems quite exotic, the meaning of it is quite straightforward. An
operator, w, will be called Hermitian if ‚ü®wœà1|œà2‚ü©= ‚ü®œà1|wœà2‚ü©. The Hamiltonian,5

H, in quantum mechanics must be Hermitian, i.e.
 
Hœà1|œà2

=

œà1| 
Hœà2

. The
momentum and position operators are also Hermitian. Please see for instance
Fermi [1] (p. 33) for some other examples of Hermitian operators. An important
4 A Hermitian matrix has been Ô¨Årst deÔ¨Åned in Chapter 1, Section 1.13. Hermiticity is also further discussed in
Section 4.11.
5 The Hamiltonian formalism was extensively introduced in Chapter 1, Section 1.13.

78
Vector calculus and other mathematical preliminaries
property of Hermitian operators is that their eigenvalues must be real (i.e.
measurable). Another important property is that the product of two Hermitian
operators will be Hermitian if and only if the two operators commute. Clearly,
this means that the product of the position and the momentum operators
cannot be Hermitian. Hermitian operators are a subset of the space of linear
operators.
Baaquie [2] [3] shows that in Ô¨Ånance the Hamiltonian which corresponds to
the famous Black‚ÄìScholes partial differential equation6 is not Hermitian. Baaquie
indicates that this non-Hermiticity is traceable to the necessary requirement of
the martingale condition (please see Chapter 2 for a brief discussion of what a
martingale is).
We Ô¨Ånalize this section with the remark that the existence of arbitrage (please
see below for the so-called non-arbitrage theorem) should then imply the existence
of Hermiticity. What does this mean? What conclusions can we derive from such
an observation? What does it mean that probability is not conserved in a non-
arbitrage-based Ô¨Ånancial context (i.e. when there is no Hermiticity)?
4.12 References
[1] Fermi, E. (1961). Notes on Quantum Mechanics. University of Chicago Press.
[2] Baaquie, B. (2005). Quantum Finance. Cambridge University Press.
[3] Baaquie, B. (2008). Quantum mechanics and option pricing. In Quantum interaction.
Eds. Bruza, P., Lawless W., van Rijsbergen, K., Sofge, D. A., Coecke, B., and Clark,
S. Proceedings of the Second Quantum Interaction Symposium (Oxford University).
College Publications, London, pp. 49‚Äì53.
4.13 Projection operators
We can deÔ¨Åne a projection operator via the two properties: idempotency and Her-
miticity (please see entry above on Hermiticity). An operator w is idempotent
if w2 = w. When the operator is both idempotent and Hermitian, the operator
is a projection operator. We can express any vector œà in the Hilbert space in
terms of two orthogonal vectors œÜ and Œ∏ by means of a projection operator. Write
œà = œÜ + Œ∏ and œÜ = wœà and Œ∏ = (I ‚àíw) œà, where I is the unit (or identity)
operator. One can write that ‚ü®œÜ|Œ∏‚ü©= ‚ü®wœà| (I ‚àíw) œà‚ü©and because of Hermitic-
ity of w, one can write that ‚ü®wœà| (I ‚àíw) œà‚ü©=

œà|w ‚àíw2|œà

and this is equal
to zero since, via idempotence, w2 = w. Note that I ‚àíw is also a projection
operator.
6 This equation was covered in Chapter 2.

4.16 ODEs and PDEs
79
4.14 Probability density functions
Following Ross [1] (p. 7), a random variable X will be a ‚Äúfunction that assigns a
real value to each outcome of the sample space, S (which is the set of all possible
outcomes).‚Äù By the Kolmogorov axiomatics [2], the Kolmogorov probability space
is a triple P = (, F, P ). Points œâ of  (which is a non-empty set) are said to be
elementary events. F is a so called œÉ-algebra and P is a probability measure.
Following Brze¬¥zniak and Zastawniak [3] (pp. 1‚Äì2), a œÉ-algebra F on the non-
empty set  is a family of subsets of  such that: (i) the empty set and the set
 belong to F; (ii) if A belongs to F, then so will the complement \A; (iii) if
A1, A2, . . . is a sequence of sets in F, then A1 ‚à™A2 . . . also belongs to F. Remark,
thus, that elements of F are events. If F is a œÉ-algebra on , then a probability
measure P will be a function P : F ‚Üí[0, 1] such that (i) P() = 1 and ii) if
A1, A2, . . . are pairwise disjoint (i.e. Ai ‚à©Aj = ‚àÖ(i Ã∏= j)) and belong to F then
P(A1 ‚à™A2 . . .) = P(A1) + P(A2) + . . . .
The random variable is called ‚Äúcontinuous‚Äù if there exists a function f (x)
which is called the probability density function such that

A f (x) dx denotes the
probability of the random variable X to be in the set A. Following Hubbard and
Hubbard [4] (p. 417) for a function to be a density of a probability function it must
satisfy two essential conditions: (i) f (.) ‚â•0 and (ii)

Rk f (x) dkx = 1. The one-
dimensional probability density function for the so-called ‚Äúnormal distribution‚Äù
with mean x and standard deviation œÉ is given by: f (x, œÉ) =
1
œÉ
‚àö
2œÄ e‚àí(x‚àíŒº)2/2œÉ 2.
4.15 References
[1] Ross, S. (1996). Stochastic Processes. J. Wiley.
[2] Kolmogorov, A. N. (1933). Grundbegriffe der Wahrscheinlichkeitsrechnung. Springer
Verlag, Berlin; English translation (1956): Kolmogorov, A. N. Foundations of Proba-
bility Theory. Chelsea Publishing Company, New York.
[3] Brze¬¥zniak, Z. and Zastawniak, T. (1999). Basic Stochastic Processes. Springer Verlag,
Berlin.
[4] Hubbard, J. H. and Hubbard, B. B. (2002). Vector Calculus, Linear Algebra and
Differential Forms: A UniÔ¨Åed Approach. 2nd edition. Prentice Hall.
4.16 ODEs and PDEs
The basic distinction between an ordinary differential equation (ODE) and a partial
differential equation (PDE) is that the former uses ordinary derivatives, while the
latter uses partial derivatives. This distinction is then based on whether a function
does depend on one independent variable or depends on more than one independent
variable, respectively. An example of an ODE is equation (1.4) in Chapter 1. An
example of a PDE is equation (1.59) in Chapter 1. The Schr¬®odinger equation is a

80
Vector calculus and other mathematical preliminaries
partial differential equation, since, even in its simplest form, the wave function is a
function of position and time variables. We also say that the Schr¬®odinger equation
is a partial differential equation of second order. The order is nothing else other than
the highest derivative which appears in the equation. Hence, in the Schr¬®odinger
PDE, the derivative with highest order is the second derivative, which happens
to be the second derivative towards position. Following Boyce and Di Prima [1]
(p. 5), one needs to also distinguish differential equations on whether they are linear
or non-linear. Consider the ODE F(x, y, y‚Ä≤ . . . y(n)) = 0; where y are functions of
x, and y‚Ä≤ indicates the Ô¨Årst ordinary derivative towards x; similarly for y(n), which
indicates the nth derivative towards x. An ODE will be linear if F is a linear
function of the variables y, y‚Ä≤ . . . y(n). All basic equations of quantum mechanics
are linear. The Schr¬®odinger equation is a linear PDE of second order.
The PDE or ODE will be non-linear in the alternative case; i.e. when F
is a non-linear function of the variables y, y‚Ä≤ . . . y(n). As an example, consider
y‚Ä≤‚Ä≤‚Ä≤ + 2 exp(x)y‚Ä≤‚Ä≤ + yy‚Ä≤ = x4, which is a third-order non-linear ODE, because of
the presence of yy‚Ä≤. Kreyszig [2] (pp. 64‚Äì65) deÔ¨Ånes a linear second-order differ-
ential equation as y‚Ä≤‚Ä≤ + p(x)y‚Ä≤ + q(x)y = r(x). The equation is linear in y and its
derivatives, y‚Ä≤ and y‚Ä≤‚Ä≤. p(x), q(x), and r(x) can be any given functions of x. If the
differential equation cannot be written in this form, then it is non-linear. Consider-
ing the example f (x)y‚Ä≤‚Ä≤ + p(x)y‚Ä≤ + q(x)y = r(x), then this a linear second-order
differential equation since we can write it as7 y‚Ä≤‚Ä≤ + p(x)
f (x)y‚Ä≤ + q(x)
f (x)y = r(x)
f (x). Consider
in the linear second-order differential equation that r(x) = 0, then this differential
equation is homogeneous. Otherwise, it is called non-homogeneous.
4.17 References
[1] Boyce, W. E. and Di Prima, R. C. (1992). Elementary Differential Equations and
Boundary Value Problems. J. Wiley.
[2] Kreyszig, E. (1999). Advanced Engineering Mathematics. J. Wiley.
4.18 Basics of stochastic mathematics, Brownian motion,
non-arbitrage condition, ItÀÜo‚Äôs Lemma
4.18.1 Basics of stochastic mathematics
Here are some deÔ¨Ånitions and claims which may highlight some of the basics of
stochastic mathematics.
DeÔ¨Ånition 4 (Hwei [1] (p. 209)) A random process X(t) is continuous in the mean
square (m.s.) if limŒµ‚Üí0 E

[X(t + Œµ) ‚àíX(t)]2
= 0.
7 We assume f (x) Ã∏= 0.

4.18 Basics of stochastic mathematics
81
DeÔ¨Ånition 5 (Hwei [1] (p. 172)) The random process X(t) is a Wiener process when
it is characterized by the following properties: 1. X(t) has stationary-independent
increments; 2. the increment X(t) ‚àíX(s), with t > s, must be normally distributed;
3. E(X(t)) = 0; 4. X(0) = 0.
DeÔ¨Ånition 6 (Hwei [1] (p. 209)) A random process X(t) is having an m.s. deriva-
tive X‚Ä≤(t) if l.i.mŒµ‚Üí0
X(t+Œµ)‚àíX(t)
Œµ
= X‚Ä≤(t). We denote with l.i.m the limit in the mean
square sense, limŒµ‚Üí0 E
 X(t+Œµ)‚àíX(t)
Œµ
‚àíX‚Ä≤(t)
2
= 0.
Claim 7 (Hwei [1] (p. 220)) If X(t) is m.s. continuous, then the mean is continuous.
Proof. Consider the Var[X(t + Œµ) ‚àíX(t)] = E

[X(t + Œµ) ‚àíX(t)]2
‚àí{E [X
(t + Œµ) ‚àíX(t)]}2 ‚â•0 and therefore E

[X(t + Œµ) ‚àíX(t)]2
‚â•{E [X(t + Œµ)‚àí
X(t)]}2 = [ŒºX(t + Œµ) ‚àíŒºX(t)]2. By the assumed mean square continuity of X(t)
we have that limŒµ‚Üí0 E

[X(t + Œµ) ‚àíX(t)]2
= 0 and hence limŒµ‚Üí0 [ŒºX(t + Œµ)‚àí
ŒºX(t)] = 0.
‚ñ†
Claim 8 (Hwei [1] (p. 220)) An m.s. continuous random process is continuous in
probability.
Proof. Use
Chebychev‚Äôs
inequality
P {|X(t + h) ‚àíX(t)| ‚â•Œµ} ‚â§
E[|X(t+h)‚àíX(t)|2]
Œµ2
. If h goes to zero, then
E[|X(t+h)‚àíX(t)|2]
Œµ2
must go to zero.
Therefore, P {|X(t + h) ‚àíX(t)| > Œµ} must go to zero as h goes to zero.
‚ñ†
Claim 9 (Hwei [1] (p. 222)) A Wiener process has no m.s. derivative.
Proof. We know that X(t) has mean square derivative X‚Ä≤(t) so E(X‚Ä≤(t)X‚Ä≤(s)) =
‚àÇ2E(X(t)X(s))
‚àÇt‚àÇs
. Now for a Wiener process, we know that E(X(t)X(s)) = œÉ 2 min (t, s).
Therefore, ‚àÇE(X(t)X(s))
‚àÇs
= œÉ 2 if s < t and zero if s > t. Thus, we have some step
function f (t ‚àís) which is equal to unity if s < t and zero for s > t. Clearly,
this step function is not continuous at s = t. Hence, ‚àÇ2E(X(t)X(s))
‚àÇt‚àÇs
will not exist
at s = t.
‚ñ†
4.18.2 Brownian motion
A discrete time version of arithmetic Brownian motion is Œ¥x = aŒ¥t + bœµ(Œ¥t)1/2,
where œµ follows a normal density with mean zero and variance of unity. The
mean of Œ¥x is aŒ¥t, and the standard deviation is: b(Œ¥t)1/2. One can generalize
the above discrete time version of Brownian motion by writing Œ¥x = a(x, t)Œ¥t +
b(x, t)œµ(Œ¥t)1/2. In continuous time, we can rewrite this equation as a stochastic
differential equation dx = a(x, t)dt + b(x, t)dW, where dW is a Wiener process.
An example of a geometric Brownian motion would be dx = axdt + bxdW.

82
Vector calculus and other mathematical preliminaries
4.18.3 Non-arbitrage theorem
The discrete state space non-arbitrage theorem (as opposed to the continuous state
space non-arbitrage theorem (see Kabanov and Stricker [2]) is a crucial theorem in
asset pricing theory. See for instance the paper by Harrison and Kreps [3] for the
original ideas. The formulation of the non-arbitrage theorem by Etheridge [4] is fol-
lowed here closely. We repeat deÔ¨Ånition 15.1 in Etheridge [4] (p. 11) but with some-
what different notation. Assume there are N tradable assets (some assets may be
risky and some not) and their prices, at time t0 are given by ‚àí‚Üí
p0=

p1
0, p2
0, . . . , pN
0

.
Assume there exists a K (where K indicates the K states of the world) dimen-
sional state price vector ‚àí‚Üí
 = (1, 2, . . . , K) which is strictly positive in all
coordinates. Consider the following model
‚éõ
‚éú‚éú‚éú‚éù
p1
0
p2
0...
pN
0
‚éû
‚éü‚éü‚éü‚é†= 1
‚éõ
‚éú‚éú‚éú‚éù
D11
D21
...
DN1
‚éû
‚éü‚éü‚éü‚é†+ 2
‚éõ
‚éú‚éú‚éú‚éù
D12
D22
...
DN2
‚éû
‚éü‚éü‚éü‚é†+ ¬∑ ¬∑ ¬∑ + K
‚éõ
‚éú‚éú‚éú‚éù
D1K
D2K
...
DNK
‚éû
‚éü‚éü‚éü‚é†,
where each N-dimensional vector ‚àí‚Üí
D1, . . . ‚àí‚Üí
DK is the security price vector at time
t1, if the market is, respectively, in state 1, . . . , K. Following theorem 1.5.2 in
Etheridge [4] (p. 11), ‚ÄúFor the market model described (here) there is no arbitrage
if and only if there is a state price vector.‚Äù The proof of this theorem can be found
in DufÔ¨Åe [5].
4.18.4 ItÀÜo‚Äôs Lemma
Following √òksendal [6], ItÀÜo‚Äôs Lemma can be expressed in integral form or in differ-
ential notation. Equation (4.1.6) (p. 44) in √òksendal [6] deÔ¨Ånes Xt as a stochastic
integral: dXt = udt + vdBt, where Bt is a one-dimensional Brownian motion, u
and v are respectively drift and diffusion factors, and t is time. Theorem (4.1.2)
(p. 44) in √òksendal [6], says that if a g(t, x) is twice continuously differentiable
on the product space [0, ‚àû[√óR, then Yt = g(t, Xt) is also a stochastic integral and
ItÀÜo‚Äôs Lemma indicates that:
dYt = ‚àÇg
‚àÇt (t, Xt)dt + ‚àÇg
‚àÇx (t, Xt)dXt + 1
2
‚àÇ2g
‚àÇx2 (t, Xt)(dXt)2.
(4.4)
4.19 References
[1] Hwei, P. H. (1997). Probability, Random Variables and Random Processes. Schaum‚Äôs
Outline Series. McGraw-Hill.

4.18 Basics of stochastic mathematics
83
[2] Kabanov, Yu. and Stricker, C. (2005). Remarks on the True No-arbitrage Property.
S¬¥eminaire de Probabilit¬¥es XXXVIII. Lecture Notes in Mathematics, 1857, 186‚Äì194.
Springer Verlag, Berlin.
[3] Harrison, J. M. and Kreps, D. M. (1979). Martingales and arbitrage in multiperiod
securities markets. Journal of Economic Theory, 20, 381‚Äì408.
[4] Etheridge, A. (2002). A Course in Financial Calculus. Cambridge University Press.
[5] DufÔ¨Åe, D. (1996). Dynamic Asset Pricing Theory. Princeton University Press, NJ.
[6] √òksendal, B. (1998). Stochastic Differential Equations. Springer Verlag, Berlin.

5
Basic elements of quantum mechanics
5.1 Mathematical formalism of quantum mechanics: brief introduction
In this chapter, we present basic notions of quantum mechanics, and we emphasize
‚Äúquantum mathematics.‚Äù To posit that the mathematical formalism of quantum
mechanics can be used outside of quantum physics (as in sociology, economics,
or Ô¨Ånance) may be of interest. If one can steer away from merely positing and
veer instead into convincing the reader that such a position is tenable, then some
achievement has been booked. But the price to pay is that the formalism of quantum
mechanics needs to be uncovered: how else can one judge whether what we posit
is senseful? Thus, a reader can either (i) formally accept our viewpoint about the
quantum-like paradigm (see Khrennikov [1]), or (ii) ask for a detailed analysis of
the quantum foundations which would justify this paradigm. In the Ô¨Årst case, it
may well be sufÔ¨Åcient to skip this chapter (but we should suggest to attempt to
include Chapter 3). In the second case, we invite especially those readers who are
concerned about the fact that the formal usage of the mathematical formalism of
quantum mechanics may transfer major problems of quantum foundations to social
science, economics, and Ô¨Ånance, to read the present chapter carefully.
Quantum mechanics formally describes states of systems, observables and the
dynamics of states and observables. We explained in Chapter 4 the notion of Hilbert
space.
Consider complex vectors (here describing pure states of a quantum system),
i.e. œà ‚ààH (H being a Hilbert space) such that:
‚à•œà‚à•2 = ‚ü®œà|œà‚ü©= 1.
(5.1)
The normalization (by one) of the above vectors is of capital importance to engender
the notion of the probability of a pure state. We note that Hermitian operators are
used to denote observables (such as the position observable).
84

5.1 Mathematical formalism of quantum mechanics
85
In an orthonormal basis {ej}, observables are given by Hermitian matrices A =
(aij); here:
¬Øaij = aji.
(5.2)
Remark that by using the usual scalar product notation we write the matrix
elements as ‚ü®ei, Aej‚ü©, but we can also employ ‚ü®ei|A|ej‚ü©to denote matrix elements
in the notation proposed by Dirac.
The squared absolute values of the coordinates of a state vector are interpreted
as probabilities (Born‚Äôs interpretation). As we have remarked in Asano et al. [2]
(p. 63): ‚ÄúOne can say that the quantum formalism provides a geometric rep-
resentation of probabilities which is based on the Euclidean distance.‚Äù In the
Ô¨Ånite-dimensional case, it is especially easy (from the mathematical viewpoint) to
formulate quantum postulates describing measurements of observables. Let A be
a Hermitian matrix representing a quantum observable. Consider its eigenvalues
Œ±j and eigenvectors ej : Aej = Œ±jej. It is postulated that only values Œ±j can be
observed in measurements of the quantum observable represented by A. Quantum
theory cannot predict which concrete value Œ±j0 will be obtained. It predicts only
the probabilities Pœà(A = Œ±j) to obtain values Œ±j for A measurements for systems
prepared in the pure state œà. For further simpliÔ¨Åcation, let us consider the case of
the non-degenerate spectrum1 Œ±i Ã∏= Œ±j, i Ã∏= j. In this case, any pure state œà can be
expanded with respect to the orthonormal basis consisting of eigenvectors of A:
œà =

j
cjej,
(5.3)
where 
j |cj|2 = 1. It is postulated that:
Pœà(A = Œ±j) = |cj|2 = |‚ü®ej|œà‚ü©|2.
(5.4)
This is the basic rule for establishing the coupling between quantum theory and
experiment. Denote by nj the number of measurements of A in which the result
A = Œ±j was obtained, and denote the total length of the series of measurements by
N. Finally, set Œºj(N) = nj
N , the frequency of observation of the value Œ±j. Then by
the frequency interpretation of probability:
|‚ü®ej|œà‚ü©|2 = lim
N‚Üí‚àûŒºj(N).
(5.5)
The rule (5.4) is a discrete version of Born‚Äôs rule: the probability to Ô¨Ånd a particle
at the point x of physical space is given by the square of the absolute value of the
œà-function (complex probability amplitude):
Pœà(x) = |œà(x)|2.
(5.6)
1 In the Ô¨Ånite-dimensional case, the spectrum coincides with the set of eigenvalues.

86
Basic elements of quantum mechanics
By using Born‚Äôs rule, it is easy to derive the quantum representation of the average
of the quantum observable given by A. For any classical random variable Œæ taking
values Œæj with probabilities pj, its average is deÔ¨Åned as:
‚ü®Œæ‚ü©‚â°EŒæ =

j
Œæjpj.
(5.7)
Any quantum observable can be considered as a classical random variable taking
values Œ±j with the probabilities pj = Pœà(A = Œ±j). Hence:
‚ü®A‚ü©œà =

j
Œ±jpj.
(5.8)
The reader may be surprised by the above statement. However, this is really the
case: any single quantum observable is described by classical probability theory.
Problems with classicality arise if two or more quantum observables represented
by non-commutative operators are considered.
Sometimes it is important to know, besides the possible results of quantum
measurements and corresponding probabilities, the post-measurement states. It
was postulated by von Neumann that if the result A = Œ±j has been obtained, then,
immediately2 after this, the system can be found in the state ej. Thus, the state
œà has been projected onto the eigenvector ej corresponding to the result of the
measurement. We note that this opposes Born‚Äôs rule, and von Neumann‚Äôs projection
postulate is still a subject of debate.
Now consider an observable given by a Hermitian matrix with degenerate spec-
trum (still in the Ô¨Ånite-dimensional case), i.e. the dimension of the subspace Lj
consisting of eigenvectors corresponding to Œ±j can be larger than 1. Denote by œÄLj
the orthogonal projector onto the subspace Lj. Then it is postulated that:
Pœà(A = Œ±j) = ‚à•œÄLjœà‚à•2.
(5.9)
If Lj has dimension 1, then (5.9) is reduced to (5.4). What can one say about
the post-measurement state? In any textbook, one can Ô¨Ånd the statement that the
post-measurement state is:
œàŒ±j =
œÄLjœà
‚à•œÄLjœà‚ü©‚à•,
(5.10)
with the projection of the original state œà on the subspace Lj which is normalized
by 1 (to get again a pure state). However, von Neumann was sure that the case of
a degenerate spectrum was more complicated and it cannot be treated in the same
way as the case of a non-degenerate spectrum. He pointed out that the degeneration
2 ‚ÄúImmediately‚Äù indeed is somewhat fuzzy . . .

5.1 Mathematical formalism of quantum mechanics
87
of spectrum implies that in general post-measurement states are not pure states,
but instead so-called mixed states [3] (see [4] for an analysis of the consequences
of von Neumann‚Äôs viewpoint). The latter are described not by normalized vectors,
but density matrices (we shall deÔ¨Åne them below ‚Äì please see equation (5.16)).
Although the rule (5.10) was used at the very beginning of quantum mechanics,
e.g. in the famous paper of Einstein et al. [5], this rule was presented in the form of
a postulate only in the 1950s by L¬®uders. Therefore, experts in quantum foundations
refer to (5.10) as L¬®uders‚Äô projection postulate. Sometimes it is called the ‚Äúvon
Neumann‚ÄìL¬®uders postulate‚Äù or simply the ‚Äúprojection postulate‚Äù or even the ‚Äúvon
Neumann projection postulate.‚Äù
In the inÔ¨Ånite-dimensional case, the formulation of measurement postulates is
based on more complicated mathematics. Roughly speaking, the main difÔ¨Åculty is
the presence of generalized eigenvectors, i.e. eigenvectors which do not belong to
the Hilbert space H, the space of quantum states. For example, for the position
operator, Dirac‚Äôs Œ¥-function ex0(x) = Œ¥(x ‚àíx0) is the eigenfunction corresponding
to the eigenvalue x0. This function does not belong to the L2-space, the space of
square summable (or integrable) functions ‚Äì the state space of quantum mechan-
ics. The same happens for the momentum observable. Neither does the complex
exponent ep0(x) = eip0x/h belong to the L2-space. However, this is a generalized
eigenfunction of the position operator corresponding to the eigenvalue p0. The
formalism of generalized eigenvectors was used by Paul Dirac who created the Ô¨Årst
mathematical formalism of quantum mechanics. Von Neumann [3] used another
approach, which came to be known as the theory of orthogonal projection mea-
sures. We recall, as was mentioned before already, that in quantum information
one often operates in a Ô¨Ånite-dimensional Hilbert space. However, real quantum
physics is inÔ¨Ånite dimensional.
If a quantum observable is represented by a Hermitian operator whose eigen-
vectors {ej} belong to the Hilbert space H and form the basis in this space,
then all aforementioned postulates can be immediately generalized to the inÔ¨Ånite-
dimensional case. In this book, we shall not delve deeper into the operator mathe-
matics of quantum mechanics. The reader can always proceed by keeping in mind
the Ô¨Ånite-dimensional situation.
In this part of section 5.1 we reproduce (pp. 63‚Äì64)3 the paper by Asano et al.
[2]. The dynamics of a pure state are described by the Schr¬®odinger differential
equation:
i dœà
dt (t) = Hœà(t), œà(0) = œà0,
(5.11)
3 Masanari Asano and Masanori Ohya and Yishiharu Tanaka and Irina Basieva and Andrei Khrennikov (2011).
Quantum like model of brain‚Äôs functioning: decision making from decoherence. Journal of Theoretical Biology,
281, 63‚Äì64.

88
Basic elements of quantum mechanics
where the operator H is the generator of evolution, also called the ‚ÄúHamiltonian,‚Äù
the operator of energy. We remark that Schr¬®odinger dynamics are deterministic.
By Ô¨Åxing the initial state, we can Ô¨Ånd the state of a quantum system at any instant
of time. The fundamental problem of the foundations of quantum mechanics is
that this state does not determine the values of observables. Measurements induce
randomness.
We remark that each pure state œà determines a Hermitian operator, the projector
onto this state; œÅ ‚â°|œà‚ü©‚ü®œà| (the last symbol is simply the Dirac notation), œÅœÜ =
‚ü®œÜ|œà‚ü©œà. We recall the basic properties of œÅœà:
(a) it is positively deÔ¨Åned, i.e. ‚ü®œÜ|œÅ|œÜ‚ü©‚â•0 for any œÜ;
(b) it is Hermitian;
(c) its trace (the sum of diagonal elements) equals to one.
The Schr¬®odinger dynamics for pure states (vectors) can be rewritten as the
dynamics for corresponding operators:
i dœÅ
dt (t) = [H, œÅ(t)], œÅ(0) = œÅ0,
(5.12)
where [H, œÅ] = HœÅ ‚àíœÅH is the commutator of operators.
Consider now a statistical mixture (in the classical sense) of a few projection
operators œÅi corresponding to pure states œài with weights pi ‚â•0,  pi = 1:
œÅ = p1œÅ1 + ¬∑ ¬∑ ¬∑ + pnœÅn.
(5.13)
Each operator of this form satisÔ¨Åes conditions (a)‚Äì(c) and vice versa. Denote the
class of all operators with properties (a)‚Äì(c) by the symbol D(H). This is the
space of states of quantum systems. Its elements (called density operators) can
be interpreted as statistical mixtures of pure states. In general, a density operator
can be represented in many ways. There is one special expansion corresponding
to eigenvectors of œÅ. The density operator corresponding to a pure state can be
characterized in the following way: in the basis of eigenvectors, its matrix has only
one non-zero element (equal to one), i.e. up to a permutation of eigenvectors:
œÅ =
	1
0
0
0

,
(5.14)
where the blocks of zeros have the corresponding sizes. However, this takes place
only in the basis of eigenvectors.
Consider,4 for example, the two-dimensional Hilbert space H and Ô¨Åx some
orthonormal basis in this space, {e1, e2}; take a pure state:
œà = xe1 + ye2,
(5.15)
4 This part of the text until and including equation 5.16 is not part of the Asano et al. [2] article.

5.1 Mathematical formalism of quantum mechanics
89
where |x|2 + |y|2 = 1. The density matrix œÅ corresponding to this pure state has
the form:
œÅ =
	|x|2
x ¬Øy
¬Øxy
|y|2

.
(5.16)
The dynamics of a quantum state are described by the equation (5.12). This dynam-
ical model can be used only in the absence of interaction of a quantum system with
an environment, a bath. If such interaction is essential (so a system cannot be
considered as isolated), the dynamics (5.12) have to be modiÔ¨Åed and additional
terms have to be included. The basic postulate of quantum theory is that the state
dynamics are linear. Therefore, the modiÔ¨Åed dynamics have the form:
i dœÅ
dt (t) = [H, œÅ(t)] + L(œÅ), œÅ(0) = œÅ0,
(5.17)
where L is a linear operator. This operator has to be chosen in such a way that
starting with œÅ0 ‚ààD(H), we shall obtain a trajectory t ‚ÜíœÅ(t) in D(H). The cor-
responding conditions for linear systems were formulated by Gorini, Kossakowski,
Sudarshan, and Lindblad, see, e.g., [7] for details.
Consider a mixed state œÅ and a quantum observable A. The average of A in this
state is given by the formula (see e.g. von Neumann [3]):
‚ü®A‚ü©œÅ = TrœÅA,
(5.18)
where Tr denotes the operator trace. This formula can be derived on the basis of
Born‚Äôs rule and the probabilistic interpretation of the classical statistical mixture
(5.17).
5.2 References
[1] Khrennikov, A. (2009). Contextual Approach to Quantum Formalism. Springer Verlag,
Berlin, Heidelberg, New York.
[2] Asano, M., Ohya, M., Tanaka, Y., Basieva, I., and Khrennikov, A. (2011). Quantum-
like model of brain‚Äôs functioning: decision making from decoherence. Journal of
Theoretical Biology, 281, 56‚Äì64.
[3] Von Neumann, J. (1955). Mathematical Foundations of Quantum Mechanics. Princeton
University Press, NJ.
[4] Khrennikov, A. (2009). Bell‚Äôs inequality, Einstein, Podolsky, Rosen arguments and von
Neumann‚Äôs projection postulate. Laser Physics, 19, 346‚Äì356.
[5] Einstein, A., Podolsky, B., and Rosen, N. (1935). Can quantum-mechanical description
of physical reality be considered complete? Physical Review, 47, 777.
[6] Dirac, P. A. M. (1995). The Principles of Quantum Mechanics. Clarendon Press,
Oxford.
[7] Ingarden, R. S., Kossakowski, A., and Ohya, M. (1997). Information Dynamics and
Open Systems: Classical and Quantum Approach. Kluwer, Dordrecht.

90
Basic elements of quantum mechanics
5.3 Double slit experiment: rationale for the existence of probability waves
Varadarajan [1] (slide 11) mentions that ‚Äúthe double slit experiment suggests that
the logic of quantum theory is not classical, i.e. is not a Boolean algebra, because of
the complementarity principle.‚Äù There are many variant descriptions of the double
slit experiment. Let us introduce the setting of the experiment with a description
given by Varadarajan. Citing Varadarajan [1] (slide 8): ‚ÄúElectrons from a source,
all with the same energy, pass through two slits on a screen and fall on a plate.
We place a counter at a variable point x on the plate and record the arrival of the
electrons. If the source is a weak one, we will be able to count the electrons one
by one as they arrive.‚Äù Using the same notation as in Varadarajan [1] (slide 8),
denote by Ai(x) the event that slit i (= 1, 2) is open. Denote A(x) as the event
when both slits are open. From a classical point of view, one could then claim that
A(x) = A1(x) ‚à™A2(x) and the probability of the event A(x) to occur would then be
(assuming mutually exclusive events) p(A(x)) = p(A1(x)) + p(A2(x)). However,
the experimental evidence, does show that this is not the case. How can that now
be explained? The standard explanation revolves very often around the concept of
so-called ‚Äúwave‚Äìparticle‚Äù duality.
Let us re-set the d¬¥ecor of the experiment in a slightly different way. We want to
transit Ô¨Årst from a classical mechanical situation to a quantum mechanical situation.
Consider the description below (see Khrennikov [2], Khrennikov [3], Khrennikov
and Haven [4]). We follow closely Haven [5] (pp. 43‚Äì45) (up to Section 5.4).
Imagine an experimenter Ô¨Åring a gun containing very tiny plastic pellets onto
a screen, similar as in the Varadarajan description, which has two equally spaced
slits. We imagine there is a detector screen, behind the screen containing the slits,
upon which the pellets land. Assume there exists a detector which can count the
pellets landings in the various locations on the detector screen. Denote the top
and bottom slits as respectively slits 1 and 2. We then have the following three
scenarios:
r slit 1 is open and slit 2 is closed,
r slit 1 is closed and slit 2 is open,
r slit 1 is open and slit 2 is open.
We imagine that the diameter of the pellets is substantially smaller than the
slits‚Äô width. When carrying out the experiment, the following (expected) result
occurs. In scenario 1, pellets start accumulating behind slit 1. Some pellets also
land close to slit 2, and go even further as they are deÔ¨Çected on the edges of slit 1. In
scenario 2, pellets accumulate behind slit 2 and some pellets land close to slit 1 and
even further. When both slits are open we have an accumulation behind both slits
and some scattering also.

5.3 Double slit experiment
91
The key issue now consists in remarking that if one were to convert the pellets
into electrons, the result of the experiment would be altogether seriously different.
Essentially, with electrons, an interference pattern will form. Electrons will Ô¨Årst
behave like particles and with the onset of time, they will start behaving like waves.
This in essence, exempliÔ¨Åes, the idea of wave‚Äìparticle duality. The most striking
(and frankly very much counter-intuitive) event is the fact that there is interference
between an electron and itself. This result is substantially different from what we
would expect if the electrons had been plastic pellets. Those results laid the basis
for the formal development of quantum mechanics.
The probabilistic description of the electrons landing on the detector screen is
different from the probabilistic description of plastic pellets landing on the detector
screen. In fact, the difference in description is so resolutely different that a new
notion was born: ‚Äúprobability interference.‚Äù In a nutshell, the observed interference
in the double slit experiment when electrons are Ô¨Åred almost requires that we must
superpose probability distributions. Note the use of the word ‚Äúalmost.‚Äù As is well
know, such functions cannot be superposed.
Let us denote with p1(x) the probability that the electron arrives at position x
when slit 1 is open. Similarly, for p2(x). We can now query what the expression
would be when both slits 1 and 2 are open. Would it be p12(x) = p1(x) + p2(x)?
This probability formula would reÔ¨Çect the situation when both slits are open but
when we use plastic pellets rather than electrons. Hence, this formulation is not
reÔ¨Çecting the interference pattern experimenters found when they used electrons.
As we have indicated above, it is not possible to capture interference by superpos-
ing probability distributions. The mathematical machinery needed for the superpo-
sition of probability waves (or probability amplitudes) is well explained in Morrison
[6] (pp. 55‚Äì56) and we follow it here closely. But before getting into the mechanics
of this machinery, let us quickly remind ourselves about the notion of ‚Äúconjugate‚Äù
of a complex number, which we covered in Chapter 1, Section 1.13. We also dis-
cussed it brieÔ¨Çy in Chapter 4, Section 4.3. The wave function is essential in the
determination of the probability density function on the position. The pdf, denoted
as |œà1(x)|2, is obtained by writing that |œà1(x)|2 is the product of the wave function
with its complex conjugate, œà‚àó. The wave function when written in terms of phase
and amplitude can be expressed, for when slit 1 is open, as |œà1(x)| exp(iS1(x)),
where S1(x) is the phase of the wave and |œà1(x)| is the amplitude of the wave
function; |œà2(x)|, for when slit 2 is open, can be expressed in the same way. The
transition of going from the probability amplitude to the pdf is via the procedure
of the complex conjugate. The complex conjugate of |œà1(x)| exp(iS1(x)) is simply
|œà1(x)| exp(‚àíiS1(x)). Similarly, for when slit 2 is open.
At this stage, we have not yet indicated how we arrive at probability inter-
ference. We follow now closely Morrison [6] (pp. 55‚Äì56). We need one more

92
Basic elements of quantum mechanics
ingredient: superposition of the probability amplitudes. This can be deÔ¨Åned as
œà12(x) = œà1(x) + œà2(x), where œà12(x) is the superposed state. If we write that
p12(x) ‚àù|œà1(x) + œà2(x)|2, then substituting |œài(x)| exp(iSi(x)) into that expres-
sion, one obtains:
p12(x) = |œà1(x)|2 + |œà2(x)|2 + 2 |œà1(x)| |œà2(x)| cos (S1 ‚àíS2) .
(5.19)
A complex number z (see Chapter 4, Section 4.3) can be denoted as z = x + iy,
where x is the real part and y is the imaginary part; z can also be written as z =
r exp(iŒ∏), where r =
"
x2 + y2. r is often denoted as |z|. The angle Œ∏ = tan‚àí1  y
x

,
where y = r sin Œ∏ and x = r cos Œ∏. In analogy with the wave function, we also say
that |z| is the amplitude and Œ∏ is the phase.
Equation (5.19), is the probability formula, which now includes the probability
interference term 2 |œà1(x)| |œà2(x)| cos (S1 ‚àíS2). When this term is not zero, it
renders the probability in a quantum context to be either sub- or super-additive.
5.4 References
[1] Varadarajan, V. S. (2008). The quantum dice. Talk given at U.C.L.A. Slides 1‚Äì20.
[2] Khrennikov, A. (1999). Interpretations of Probability. VSP International Science Pub-
lishers, Utrecht, Tokyo.
[3] Khrennikov, A. (2009). Interpretations of Probability. 2nd edition. De Gruyter,
Berlin.
[4] Khrennikov, A. and Haven, E. (2009). Quantum mechanics and violations of the sure-
thing principle: the use of probability interference and other concepts. Journal of
Mathematical Psychology, 53, 5, 378‚Äì388.
[5] Haven, E. (2008). Elementary quantum mechanical principles and social science: is
there a connection? Romanian Journal of Economic Forecasting, 9, 1, 41‚Äì58.
[6] Morrison, Michael, A. (1990). Understanding Quantum Physics: A User‚Äôs Manual.
Volume 1. 1st edition. Pearson Education, Upper Saddle River, NJ.
5.5 Quantum mechanical postulates
Aerts and Aerts [1] remark (p. 27) that there does not exist ‚Äúa uniquely accepted
set of axioms for quantum theory.‚Äù The authors go on to show some examples of
approaches used in quantum physics. They mention [1] (pp. 27‚Äì28) the Bohmian
mechanics approach (see Chapter 6); the Feynman path integral5 approach (which
we have already mentioned in Chapter 1 and Chapter 3; the Birkhoff‚Äìvon Neumann
approach [3]; and the convexity of states approach [4]. They propose that any theory
would have to contain at least three parts which link theory to experiment. They
are as follows (p. 28):
5 Holland [2] (p. 268) views the Feynman approach as a way to obtain ‚Äúquantum action from the set of all classical
actions.‚Äù

5.5 Quantum mechanical postulates
93
1. ‚Äúthere exists a set 
S of possible states for a system S‚Äù;
2. from experiments one can infer a set of observable quantities, OS, and to ‚Äúeach
observable there corresponds a set of discrete or continuous outcomes, XA‚Äù;
3. a map P exists which is as follows: ‚ÄúP : 
S √óOS √ó XA ‚Üí[0, 1] and

xi‚ààXA P = 1.‚Äù
As Aerts and Aerts [1] (p. 28) remark, for a classical deterministic system, one
deÔ¨Ånes P : 
S √óOS √ó XA ‚Üí{0, 1} and 
xi‚ààXA P = 1.
The objective of this section does not consist of discussing an axiomatic struc-
ture of quantum mechanics. Many books exist on this topic and it is certainly not
the objective of this present book to engage in this very complex topic. The title of
this section in fact hints at the existence of postulates. Indeed, there are some basic
postulates which are closely allied to the three parts presented above. In Chapter 1
and in other parts of this book, we mention the word ‚Äúpostulate‚Äù several times.
For instance, in Chapter 1, we discussed (amongst others) the Bohr postu-
late about electrons taking on discrete energy values; the Bohr‚ÄìSommerfeld
quantization rule; and the Heisenberg postulate (this chapter) that operators on
position and momentum should satisfy a peculiar commutation relation (the
Heisenberg uncertainty principle). We also mentioned (amongst others) the von
Neumann projection postulate (or also the von Neumann‚ÄìL¬®uders postulate). In
Chapter 8, we will discuss Kolmogorov‚Äôs postulate of being able to embed
‚Äúcontext‚Äù in probability space. See also Kahneman [5] for a very interesting
interpretation of ‚Äúcontext.‚Äù In Chapter 14, where we discuss the possibility of
a quantum-like brain; we also will mention several postulates.
Morrison [6] distinguishes four postulates in quantum mechanics. Other authors
may bring forward slightly different postulates. For instance, Bransden and
Joachain [7] (pp. 194‚Äì205) propose six postulates. Omn`es [8] (pp. 467‚Äì477) pro-
poses the following rules:
Rule 1 (p. 467). ‚ÄúThe theory of an individual isolated physical system is entirely
formulated in terms of a speciÔ¨Åc Hilbert space and a speciÔ¨Åc algebra of
operators, together with the mathematical notions associated with them.‚Äù
We remark that some of those mathematical notions were covered in
Chapter 4.
Rule 2 (p. 468) ‚ÄúThe vectors œà in the Hilbert space evolve in time according to
the Schr¬®odinger equation.‚Äù
Rule 3 (p. 468) ‚ÄúA physical system S can be said to consist of two non-interacting
systems6 S‚Ä≤ and S‚Ä≤‚Ä≤.‚Äù
6 Omn`es does give more mathematical detail on how the Hilbert space of S relates to the two Hilbert spaces of
S‚Ä≤ and S‚Ä≤‚Ä≤. We do not mention this here. Please consult, pp. 468‚Äì469 in Omn`es [8].

94
Basic elements of quantum mechanics
Rule 4 (p. 476) ‚ÄúEvery description of a physical system should be expressed in
terms of properties belonging to a common consistent logic. A valid rea-
soning relating these properties should consist of implications holding in
that logic.‚Äù
Following Morrison [6], the four postulates he distinguishes are:
Postulate 1 (p. 58). ‚ÄúEvery physically-realizable state of a system is described in
quantum mechanics by a state function œà that contains all accessible
physical information about the system in that state.‚Äù
This postulate has been discussed before. See also Bransden and Joachain [7]
(p. 194).
Postulate 2 (p. 70). ‚ÄúIf a system is in a quantum state represented by a wave
function œà, then Pdv = |œà|2 dv is the probability that in a position
measurement at time t the particle will be detected in the inÔ¨Ånitesimal
volume element dv.‚Äù
We have discussed this postulate already in Section 5.1 of this chapter. See
equation (5.6).
Postulate 3 (p. 158). ‚ÄúIn quantum mechanics, every observable is represented
by an operator that is used to obtain physical information about the
observable from state functions.‚Äù
Postulate 4 (p. 186). ‚ÄúThe time development of the state functions of an iso-
lated quantum system is governed by the time-dependent Schr¬®odinger
equation . . . ‚Äù
We have already mentioned this fourth postulate in Chapter 1, where we
described it around equations (1.69) and (1.70).
Relative to postulate 3, we note that in the conventional axiomatics of quan-
tum mechanics, observables are represented by Hermitian operators. However, in
applications to economics and Ô¨Ånance we can ignore this restriction and proceed in
the generalized quantum mechanical framework, i.e. by operating with observables
represented by non-Hermitian operators, e.g. Hamiltonians, see Chapter 13.
5.6 References
[1] Aerts, S. and Aerts, D. (2008). When can a data set be described by quantum theory?
Proceedings of the Second Quantum Interaction Symposium. (Oxford University),
pp. 27‚Äì33.
[2] Holland, P. (2000). The Quantum Theory Of Motion: An Account of the de Broglie‚Äì
Bohm Causal Interpretation of Quantum Mechanics. Cambridge University Press.

5.7 States and state functions
95
[3] Birkhoff, G. and von Neumann, J. (1936). The logic of quantum mechanics. Annals of
Mathematics, 37, 823‚Äì843.
[4] Mielniek, B. (1974). Generalized quantum mechanics. Communications in Mathemat-
ical Physics, 37, 3, 221‚Äì256.
[5] Kahneman, D. (2003). Maps of bounded rationality: psychology for behavioral eco-
nomics. American Economic Review, 93, 1449‚Äì1475.
[6] Morrison, Michael, A. (1990). Understanding Quantum Physics: A User‚Äôs Manual.
Volume 1. 1st edition. Pearson Education, Upper Saddle River, NJ.
[7] Bransden, B. H. and Joachain, C. J. (2000). Quantum Mechanics. Prentice Hall.
[8] Omn`es, R. (1994). The Interpretation of Quantum Mechanics. Princeton Series in
Physics. Princeton University Press.
5.7 States and state functions
Postulate 1 above gives us a good idea about the meaning of a state. As per Morrison
[1] (p. 58), note the word ‚Äúaccessible‚Äù in that postulate, which shows that in quantum
mechanics we can never know with precision either position or momentum. This
inherent imprecision is fully connected to the Heisenberg uncertainty principle
which we also discuss below. Omn`es [2] (p. 118) indicates that ‚Äúa state of a system
is well deÔ¨Åned when one can assign a deÔ¨Ånite probability to every conceivable
property.‚Äù
Note also that position and time are independent quantities in quantum mechan-
ics and that is because classical quantum mechanics does not allow for paths. The
state function, before complex conjugation is applied, is indicative of the prob-
ability wave or the probability amplitude. Note also that only normalizable state
functions can serve as representing quantum states. We also distinguish between so
called ‚Äústationary‚Äù and ‚Äúnon-stationary‚Äù states. In the case where we have a conser-
vative system, i.e. with a real potential which is time-independent, stationary states
will exist. When the wave function is not separable, then we must obtain a non-
stationary state. A stationary state is an example of a so-called eigenstate. Following
Bowman [3] (p. 146), consider the Hamiltonian operator of the Schr¬®odinger equa-
tion which is Hermitian. An eigenstate of this Hamiltonian is time invariant. For a
simple overview between the difference of a classical and a quantum description
of a state of a system, see Eisberg and Resnick [4], pp. 409‚Äì410.
An important distinction is to be made between so-called ‚Äúpure‚Äù states and
‚Äúmixed‚Äù states. Following Bransden and Joachain [5] (p. 641), when a system is
described by a single wave function then it is called a pure state. In the case of
a mixed state, a statistical mixture of wave functions is needed. Mixed states are
represented by density operators (in the Ô¨Ånite-dimensional case, density matrices),
see Section 5.1.
5.8 References
[1] Morrison, Michael, A. (1990). Understanding Quantum Physics: A User‚Äôs Manual.
Volume 1. 1st edition. Pearson Education, Upper Saddle River, NJ.

96
Basic elements of quantum mechanics
[2] Omn`es, R. (1994). The Interpretation of Quantum Mechanics. Princeton Series in
Physics. Princeton University Press.
[3] Bowman, G. (2008). Essential Quantum Mechanics. Oxford University Press.
[4] Eisberg, R. and Resnick, R. (1985). Quantum Physics of Atoms, Molecules, Solids,
Nuclei and Particles, J. Wiley.
[5] Bransden, B. and Joachain, C. (2000). Quantum Mechanics. Prentice Hall.
5.9 Wave packets ‚Äì constructive and destructive interference
Wave packets can be expressed in the form of:
œà(x, t) =
1
‚àö
2œÄ
 ‚àû
‚àí‚àû
A(k) exp(i(kx ‚àíœât))dk,
(5.20)
where k is a wave number, A(k) is the amplitude function, t is time, x is position,
and œâ is the angular frequency. This expression shows, as per Morrison [1] (p. 109)
that ‚Äúthere is a superposition of an inÔ¨Ånite number of plane wave functions with
inÔ¨Ånitesimally differing wave numbers k.‚Äù Note that there are inÔ¨Ånite number of
regions of constructive interference which are combined with an inÔ¨Ånite number of
regions of destructive interference. See Morrison [1] (p. 108). The above expression
is an example of Fourier integration. Kreyszig [2] (p. 570), deÔ¨Ånes a Fourier
transform of a function f as:

f (w) =
1
‚àö
2œÄ
 ‚àû
‚àí‚àû
f (x) exp(‚àíiwx)dx,
(5.21)
where i is a complex number. Note that f (x): (i) needs to be piecewise continuous
on every Ô¨Ånite interval and (ii) f (x) is absolutely integrable on the X-axis. Kreyszig
[2] (p. 570) deÔ¨Ånes the Fourier integral as:
f (x) =
1
‚àö
2œÄ
 ‚àû
‚àí‚àû

f (w) exp(iwx)dw.
(5.22)
Remark that the wave number k can be written via the de Broglie relation as k = p
¬Øh ,
where p is momentum.
5.10 References
[1] Morrison, Michael, A. (1990). Understanding Quantum Physics: A User‚Äôs Manual.
Volume 1. 1st edition. Pearson Education Inc., Upper Saddle River, NJ.
[2] Kreyszig, E. (1999). Advanced Engineering Mathematics. J. Wiley.
5.11 Heisenberg‚Äôs uncertainty principle
This equality was already introduced in Chapter 1, equation (1.54), and also in
the section on ‚ÄúOperators‚Äù in Chapter 4. The original discussion can be found

5.13 Time-dependent/time-independent Schr¬®odinger PDE
97
in Heisenberg [1]. The relation expresses the fact that there is no full precision
on measuring either position or momentum. If one measures the position with
a high precision, the trade off will be that there will be more uncertainty on
the measurement of momentum and vice versa. ‚ÄúSimultaneous eigenfunctions of
(position and momentum operators) cannot (have) a physically realizable quantum
state‚Äù (see Morrison [2] (p. 490)). The principle does not say anything about the
imprecision of the measurement apparatus. Instead, the principle does indicate there
exists a intrinsic uncertainty at the quantum scale. In its easy form, the relation
can be expressed as 
x
p ‚â•¬Øh
2. For a Gaussian wave packet, the relation is said
to be minimal and becomes 
x
p = ¬Øh
2. The Heisenberg uncertainty principle can
be proven with the use of the Schwartz inequality. See equation 6.7.13 in Holland
[3] (p. 257). Finally, the Heisenberg uncertainty principle is a special case of the
so-called generalized uncertainty principle.
5.12 References
[1] Heisenberg, W. (1927). ¬®Uber den anschaulichen Inhalt der quantentheoretischen Kine-
matik und Mechanik. Zeitschrift f¬®ur Physik, 43, 172‚Äì198.
[2] Morrison, Michael, A. (1990). Understanding Quantum Physics: A User‚Äôs Manual.
Volume 1. 1st edition. Pearson Education, Upper Saddle River, NJ.
[3] Holland, P. (2000). The Quantum Theory of Motion: An Account of the de Broglie‚Äì
Bohm Causal Interpretation of Quantum Mechanics. Cambridge University Press.
5.13 The time-dependent and time-independent Schr¬®odinger PDE
Equation (1.69) in Chapter 1, Section 1.20, formulated the time-dependent
Schr¬®odinger PDE for an N-particle system. This is the most general version of
that PDE. The time-independent Schr¬®odinger PDE obviously does not contain the
time parameter and is substantially easier to solve. The separation of variables as
a solution technique is well known, and it implies that one can write the time-
dependent wave function as a product of two other functions (x, t) = œà(x).Œ±(t).
This approach will require a time-independent real potential function and thus will
imply the use of a conservative system.
The time-independent Schr¬®odinger PDE for a 1-particle system can be written
in shorthand as 
H = E, where E is the particle‚Äôs energy. If we recall our
brief entry on the meaning of eigenvalues and eigenfunctions in Chapter 4, then
the above 1-particle time-independent Schr¬®odinger equation can be seen to very
much resemble what we entered in Section 4.9, wœà = lœà. Clearly, w is now the
Hamiltonian operator. The wave function, , is the eigenfunction and the energy,
E, is now the eigenvalue. Section 4.11 in Chapter 4 also discussed Hermiticity. We
know the Hamiltonian operator is Hermitian and hence this implies that E is real.
See also Morrison [1] (p. 464) for a more extensive discussion.

98
Basic elements of quantum mechanics
Messiah [2] (p. 61) points out that the choice of the wave function (i.e. the
Schr¬®odinger equation) is restricted to certain ‚Äúa priori conditions‚Äù such as the
(i) linearity and homogeneity of the equation, and (ii) the PDE must be ‚ÄúÔ¨Årst order
with respect to time.‚Äù The latter condition is then linked to the fact that the wave
function once known at an instant of time t will determine the function at later
times.
The Schr¬®odinger equation exhibits some interesting properties. Auletta et al.
[3] (pp. 107‚Äì110) mention some of those properties for the cases when position
variables are one- and three-dimensional. Here are some regularity properties which
are interesting. The wave function , [3] (p. 107), ‚Äúhas to be single valued and
continuous.‚Äù As per Auletta, Fortunato, and Parisi [3] (p. 107) there ‚Äúcan not be two
different probability amplitudes for the same position‚Äù and continuity is necessary
since the Schr¬®odinger equation requires differentiability. When the real potential
were to be inÔ¨Ånite in some regions, then continuity of the wave function is still
needed (see (ii) in [3] (p. 108)). However, its Ô¨Årst derivatives may not be continuous.
Finally, another interesting regularity property says that whatever the dimension,
‚Äúthe wave function of the ground state never vanishes‚Äù [3] (p. 108).
5.14 References
[1] Morrison, Michael, A. (1990). Understanding Quantum Physics: A User‚Äôs Manual.
Volume 1. 1st edition. Pearson Education, Upper Saddle River, NJ.
[2] Messiah, A. (1961). Quantum Mechanics. Volume I. North-Holland.
[3] Auletta, G., Fortunato, M., and Parisi, G. (2009). Quantum Mechanics. Cambridge
University Press.
5.15 Classical limit ideas: Ehrenfest‚Äôs approach and the
correspondence principle
Morrison [1] (p. 169) reports that the correspondence principle proclaims that in
the so-called ‚Äúclassical limit‚Äù quantum mechanical laws must become Newtonian
laws. Clearly, the correspondence principle must establish a relationship between
an operator (on position and momentum) and the classical equivalent of the opera-
tor. The obtaining of the classical limit can sometimes be deÔ¨Åned with the argument
that one wants to see what occurs when ¬Øh ‚Üí0 and this means really (following
Morrison [1] (p. 170)) that in the classical limit ‚Äúthe quantum effects are immea-
surably small.‚Äù Holland [2] (p. 219) refers to a proposal by Berry [3] who says
that the smallness of ¬Øh ‚Äúhas no absolute meaning because its value depends on the
system of units.‚Äù The uncertainty principle can apply to macroscopic particles, but
as Morrison [1] (p. 171) indicates the meaning of that uncertainty principle is the

5.15 Classical limit ideas
99
same, i.e. there is no limit on the precision of measurement at the macroscopic
scale. Here is a precise way to express the correspondence principle: Morrison [1]
(p. 172): ‚Äúthe classical function Q(t) is the expectation value of the operator 
Q with
respect to the wave function œà(x, t) that represents the state.‚Äù Thus, the average
momentum, ‚ü®p‚ü©= m d‚ü®x‚ü©
dt becomes p = m dx
dt in the classical limit. This forms the
Ô¨Årst part of Ehrenfest‚Äôs theorem; similarly, for the average position. Ehrenfest [4]
proposed the following relationship (this is the second part of Ehrenfest‚Äôs theorem)
d‚ü®p‚ü©(t)
dt
=

‚àí‚àÇV
‚àÇx

(see also Morrison [1] (p. 520)), which indeed gives the quantum
mechanical equivalent of Newton‚Äôs second law. We follow closely Morrison [1]
(pp. 521‚Äì522) (equations 11.105‚Äì11.112) for a sketch of the proof of this theo-
rem. The key ingredient needed is the formulation for the time development of
the expectation of a Hermitian operator d‚ü®Q(t)‚ü©
dt
=
#
‚àÇ
Q
‚àÇt
$
+ 1
¬Øh

i
 
H, 
Q

, where 
Q is
an arbitrary Hermitian operator and 
H is the Hermitian Hamiltonian operator. To
obtain the position equivalent in the classical limit, one replaces the arbitrary Her-
mitian operator 
Q by a position operator. We can write d‚ü®x‚ü©(t)
dt
= 1
m ‚ü®p‚ü©(t), where use
was made of the fact that the commutator relation for position is
 
H,x

= ‚àíi¬Øh
m p. To
obtain the momentum equivalent in the classical limit, one follows the same strategy
using now the commutator relation for momentum
 
H, p

= i¬Øh ‚àÇV
‚àÇx1, where V is the
real potential and1 is the identity operator. The result is then d‚ü®p‚ü©(t)
dt
= ‚àí
 ‚àÇV
‚àÇx

. And
from the latter one can Ô¨Ånd immediately that m d2‚ü®x‚ü©(t)
dt2
= ‚ü®F(x, t)‚ü©. The right-hand
side can in effect be written as ‚àí
 ‚àû
‚àí‚àûœà‚àó(x, t)
 ‚àÇV (x,t)
‚àÇx

œà(x, t)dx (Morrison [1]
(p. 522) (equation 11.112)), and note the minus sign which appears because of the
fact that force is the negative derivative of the real potential towards position. In the
classical limit,
 ‚àû
‚àí‚àûœà‚àó(x, t)F(x, t)œà(x, t)dx can be written as F (‚ü®x‚ü©(t)). Thus,
in the classical limit the time evolution of ‚ü®x‚ü©and ‚ü®p‚ü©appears as in Newtonian
mechanics.
As is remarked in Holland [2] (p. 255), ‚Äúthe mean quantum (and classical)
motion will coincide rigorously with that of a classical particle when the following
condition is satisÔ¨Åed: ‚ü®F(x)‚ü©= F(‚ü®x‚ü©)‚Äù (see Messiah [5] (p. 217), as quoted in
Holland [2]). Holland [2] (p. 255) remarks that this equality is obeyed for polyno-
mial potentials up to and including second degree.
We note that within a Bohmian mechanics context (please see the next chapter
for the basics of Bohmian mechanics), Holland [2] (p. 224) makes the argument
that the ‚Äúquantum dynamics will coincide with, or approach, the classical dynamics
when the quantum force (the negative gradient of the quantum potential) and power
become negligible in comparison with the classical force and power.‚Äù7 It can be
shown that if the quantum potential tends to zero and this is inserted into the
7 Please see the next chapter for a discussion on the emergence of the quantum potential.

100
Basic elements of quantum mechanics
quantum Hamilton‚ÄìJacobi and continuity equations (which are equations (6.14)
and (6.15) in the next chapter), one obtains the classical Hamilton‚ÄìJacobi and
continuity equations. Thus when the quantum potential tends to zero, one can
argue this as a correspondence principle (see Holland [2] (p. 226)).
There exists another well-known approach to the classical-quantum duality
world and that is the Wentzel [6], Kramers [7], Brillouin [8] approach or the
so-called WKB approach. Holland [2] (pp. 231‚Äì234) shows convincingly that this
is not necessarily a foolproof method to argue for a classical limit. As per Holland
[2] (p. 232), when the real potential ‚Äúis a slowly varying function of (position)
x and (the energy difference) E ‚àíV is not too small,‚Äù8 one can Ô¨Ånd a ‚Äúclassical
wave function‚Äù (see Holland [2] (p. 232 (6.4.9)) and the quantum potential using
the amplitude from that wave function can then be generated. Please note the inter-
pretation of this wave function is not obvious. We come back to the WKB method
in Chapter 13 of this book.
We Ô¨Ånish this sub-section with some of the words out of the ‚Äúcaveat lector‚Äù
section of the paper by de Gosson and Hiley [10]. De Gosson and Hiley cite
(p. 1418 in their paper) the work of Mackey [11] (p. 106) who mentions that
‚Äúquantum mechanics is not just an algorithm for attaching a self-adjoint operator
to every classical Hamiltonian, because such a programme would overlook many
facts: Ô¨Årst quantum mechanics rules out a large number of conceivable Hamiltoni-
ans, and secondly there are features of quantum mechanics (such as spin) which
do not manifest themselves in the classical limit.‚Äù
5.16 References
[1] Morrison, Michael, A. (1990). Understanding Quantum Physics: A User‚Äôs Manual.
Volume 1. 1st edition. Pearson Education, Upper Saddle River, NJ.
[2] Holland, P. (2000). The Quantum Theory of Motion: An Account of the de Broglie‚Äì
Bohm Causal Interpretation of Quantum Mechanics. Cambridge University Press.
[3] Berry, M. (1991). Some quantum-to-classical asymptotics. In Chaos and Quantum
Physics. Proceedings of the Les Houches Summer School (1989). Eds. M. Giannoni,
A. Voros, and J. Zinn-Justin. North-Holland, pp. 251‚Äì303.
[4] Ehrenfest, P. (1927). Bemerkung ¬®uber die angen¬®aherte G¬®ultigkeit der Klassischen
Mechanik innerhalb der Quantenmechanik. Zeitschrift f¬®ur Physik, 45, 455‚Äì457.
[5] Messiah, A. (1961). Quantum Mechanics. Volume 1. North-Holland.
[6] Wentzel, G. (1926). Eine Verallgemeinerung der Quantenbedingungen f¬®ur die Zwecke
der Wellenmechanik. Zeitschrift f¬®ur Physik, 38, 518‚Äì529.
[7] Kramers, H. (1926). Wellenmechanik und halbzahlige Quantisierung. Zeitschrift f¬®ur
Physik, 39, 828‚Äì840.
[8] Brillouin, L. (1926). La m¬¥ecanique ondulatoire de Schr¬®odinger: une m¬¥ethode g¬¥en¬¥erale
de r¬¥esolution par approximations successives. Comptes Rendus, 183, 24‚Äì26.
8 Please see also Bohm [9] for more detail.

5.15 Classical limit ideas
101
[9] Bohm, D. (1951). Quantum Theory. Prentice Hall.
[10] de Gosson, M. A. and Hiley, B. (2011). Imprints of the quantum world in classical
mechanics. Foundations of Physics, 41, 1415‚Äì1436.
[11] Mackey, G. W. (1998). The relationship between classical and quantum mechanics.
Contemporary Mathematics, 214. American Mathematical Society.

6
Basic elements of Bohmian mechanics
6.1 Short introduction to Bohmian mechanics
Sheldon Goldstein in a Foundations of Physics paper [1] indicates (p. 341):
‚ÄúSince macroscopic objects are normally regarded as built out of microscopic
constituents . . . there can be no problem of macroscopic reality per se in Bohmian
mechanics.‚Äù Goldstein in the same paper remarks (p. 342) that this |œà|2 has ‚Äúa
status very much the same as that of a thermodynamic equilibrium.‚Äù
Basil Hiley the closest collaborator of David Bohm, says the following (Hiley
[2] (p. 2)): ‚ÄúWhat Bohm (1952a; 1952b) did was to show how to retain a description
of all the usual properties of a classical world and yet remain completely within the
quantum formalism.‚Äù The Bohm (1952) [3] [4] references in that quote refer to the
original work of Bohm in which he sets out the basics of the Bohmian mechanics.
As we will see later in the next section of this chapter, the appearance of an
‚Äúadditional term‚Äù in the Hamilton‚ÄìJacobi equation, is the hallmark of Bohmian
mechanics and it is very often termed the ‚Äúquantum potential.‚Äù Hiley [2] (p. 2)
remarks that since the Bohmian momentum is a well-deÔ¨Åned1 function of position
and time, an ensemble of trajectories can be found when the quantum potential is
non-zero. A unique, classical path is found when the quantum potential is zero.
From the outset, we hope the reader can savor the beauty of this simple but very
powerful result. Bohmian mechanics indeed shows this very gentle transition from
quantum mechanics to classical mechanics via the value of the quantum potential.
A perhaps less gentle transition can be found when considering the Ehrenfest limit
theorem, which is the theorem we covered in Section 5.15 of Chapter 5.
A very important characteristic of Bohmian mechanics is that paths do have
simultaneous determined position and momentum, i.e. we can legitimately talk
about the existence of paths. But as Hiley remarks [2] ‚Äúeven though as observers
1 For those who want to know (but please see the sections below in this chapter), it is the gradient of the phase of
the polar version of the wave function which is the momentum.
102

6.3 Mathematical formalism
103
(we) do not know the value of one of these variables.‚Äù The quantum poten-
tial‚Äôs signiÔ¨Åcance from a physics point of view seems to indicate the (Hiley [2]
(p. 3)) ‚Äúquantum potential had simply ‚Äòlocked together‚Äô the particles described by
entangled states.‚Äù
6.2 References
[1] Goldstein, S. (2009). Bohmian mechanics and quantum information. Foundations of
Physics, 40, 335‚Äì355.
[2] Hiley, B. (2008). Quantum reality unveiled through process and the implicate order.
Proceedings of the Second Quantum Interaction Symposium. University of Oxford,
pp. 1‚Äì10.
[3] Bohm, D. (1952a). A suggested interpretation of the quantum theory in terms of hidden
variables. Physical Review, 85, 166‚Äì179.
[4] Bohm, D. (1952b). A suggested interpretation of the quantum theory in terms of hidden
variables. Physical Review, 85, 180‚Äì193.
6.3 Mathematical formalism
The mathematical formalism involved in deriving the core arguments of the
Bohmian mechanical set up is quite easy. Holland [1] (pp. 68‚Äì69 and p. 134)
provides for some of the essential steps. See also Bohm and Hiley ([2] (pp. 28‚Äì29))
and Auletta, Fortunato, and Parisi [3]. For the development below (equations (6.1)
until (6.16)), we follow Choustova [4] (pp. 9‚Äì12) (equations (2.3)‚Äì(2.11)).
The wave function in polar form is considered:
œà(q, t) = R(q, t)ei S(q,t)
h ,
(6.1)
where R(q, t) = |œà(q, t)| ; S(q, t)/h is the argument of the complex number
œà(q, t). This polar form is put into the Schr¬®odinger equation:
ih‚àÇœà
‚àÇt = ‚àíh2
2m
‚àÇ2œà
‚àÇq2 + V (q, t)œà(q, t).
(6.2)
Begin with the left-hand side of the Schr¬®odinger equation:
ih‚àÇœà
‚àÇt = ih
	‚àÇR
‚àÇt ei S
h + R i
h
‚àÇS
‚àÇt ei S
h

(6.3)
= ih‚àÇR
‚àÇt ei S
h ‚àíR‚àÇS
‚àÇt ei S
h .
(6.4)
Consider now the right-hand side of the Schr¬®odinger equation. Write out Ô¨Årst
‚àÇœà
‚àÇq :
‚àÇR
‚àÇq ei S
h + R i
h
‚àÇS
‚àÇq ei S
h .
(6.5)

104
Basic elements of Bohmian mechanics
Now write out ‚àÇ2œà
‚àÇq2 :
‚àÇ2R
‚àÇq2 ei S
h + i
h
‚àÇR
‚àÇq
‚àÇS
‚àÇq ei S
h + ‚àÇR
‚àÇq
i
h
‚àÇS
‚àÇq ei S
h + R i
h
‚àÇ2S
‚àÇq2 ei S
h ‚àíR
h2
	‚àÇS
‚àÇq

2
ei S
h ,
(6.6)
which can then be simpliÔ¨Åed to:
‚àÇ2R
‚àÇq2 ei S
h + 2i
h
‚àÇR
‚àÇq
‚àÇS
‚àÇq ei S
h + R i
h
‚àÇ2S
‚àÇq2 ei S
h ‚àíR
h2
	‚àÇS
‚àÇq

2
ei S
h .
(6.7)
Substitute all this into the Schr¬®odinger equation: ih ‚àÇœà
‚àÇt = ‚àíh2
2m
‚àÇ2œà
‚àÇq2 + V (q, t) √ó
œà(q, t).
One obtains:
ih‚àÇR
‚àÇt ei S
h ‚àíR‚àÇS
‚àÇt ei S
h = ‚àíh2
2m
‚é°
‚é£
‚àÇ2R
‚àÇq2 ei S
h + 2i
h
‚àÇR
‚àÇq
‚àÇS
‚àÇq ei S
h +
R i
h
‚àÇ2S
‚àÇq2 ei S
h ‚àíR
h2

‚àÇS
‚àÇq
2
ei S
h
‚é§
‚é¶+ V œà.
Multiply the above with e‚àíi S
h , so as to get:
ih‚àÇR
‚àÇt ‚àíR‚àÇS
‚àÇt = ‚àíh2
2m
‚é°
‚é£
‚àÇ2R
‚àÇq2 + 2i
h
‚àÇR
‚àÇq
‚àÇS
‚àÇq +
R i
h
‚àÇ2S
‚àÇq2 ‚àíR
h2

‚àÇS
‚àÇq
2
‚é§
‚é¶+ V R,
where V R = V œàe‚àíi S
h = V R ei S
h e‚àíi S
h .
The real and imaginary parts can now be separated:
First the imaginary part:
‚àÇR
‚àÇt = ‚àíh2
2m
1
ih
)2i
h
‚àÇR
‚àÇq
‚àÇS
‚àÇq + R i
h
‚àÇ2S
‚àÇq2
*
.
(6.8)
This can be simpliÔ¨Åed into:
‚àÇR
‚àÇt = ‚àí1
2m
)
2‚àÇR
‚àÇq
‚àÇS
‚àÇq + R‚àÇ2S
‚àÇq2
*
.
(6.9)
For the real part:
‚àíR‚àÇS
‚àÇt = ‚àíh2
2m
+
‚àÇ2R
‚àÇq2 ‚àíR
h2
	‚àÇS
‚àÇq

2,
+ V R.
(6.10)
Multiply now (6.9) (left-hand side and right-hand side) by 2R, so as to get:
2R‚àÇR
‚àÇt = ‚àí1
2m
)
2R2‚àÇR
‚àÇq
‚àÇS
‚àÇq + 2RR‚àÇ2S
‚àÇq2
*
.
(6.11)

6.3 Mathematical formalism
105
The left-hand side of (6.11) can also be written as:
2R‚àÇR
‚àÇt = ‚àÇR2
‚àÇt .
(6.12)
Remark also that 2R ‚àÇR
‚àÇq
‚àÇS
‚àÇq + RR ‚àÇ2S
‚àÇq2 (which is in the right-hand side of (6.11))
can also be written as:
2R‚àÇR
‚àÇq
‚àÇS
‚àÇq + RR‚àÇ2S
‚àÇq2 = ‚àÇ
‚àÇq
	
R2 ‚àÇS
‚àÇq

.
(6.13)
Thus, (6.11) can now be rewritten as:
‚àÇR2
‚àÇt
+ 1
m
‚àÇ
‚àÇq
	
R2 ‚àÇS
‚àÇq

= 0.
(6.14)
Equation (6.14) is also known under the name of the ‚Äúcontinuity equation.‚Äù We
can see this equation expresses the evolution of a probability distribution, since
R2 = |œà|2.
We can simplify (6.10) a little (divided by ‚àíR):
‚àÇS
‚àÇt + 1
2m
	‚àÇS
‚àÇq

2
+
	
V ‚àí
h2
2mR
‚àÇ2R
‚àÇq2

= 0.
(6.15)
Equation (6.15) is important for our purposes. If h2
2m << 1 and let
h2
2mR
‚àÇ2R
‚àÇq2 be
negligibly small, then (6.15) is a Hamilton‚ÄìJacobi equation. Bohm [5] interprets
the above equation by claiming that ‚àíh2
2mR
‚àÇ2R
‚àÇq2 is a so-called quantum potential.
The Newton‚ÄìBohm equation is:
md2q(t)
dt2
= ‚àí‚àÇV (q, t)
‚àÇq
‚àí‚àÇQ(q, t)
‚àÇq
(6.16)
and Q(q, t) depends on the wave function and the wave function evolves according
to the Schr¬®odinger equation.
The initial conditions are q(t0) = q0 and q‚Ä≤(t0) = q‚Ä≤
0 (momentum).
6.4 References
[1] Holland, P. (2000). The Quantum Theory of Motion: An Account of the de Broglie‚Äì
Bohm Causal Interpretation of Quantum Mechanics. Cambridge University Press.
[2] Bohm, D. and Hiley, B. J. (1993). The Undivided Universe: An Ontological Interpre-
tation of Quantum Theory. Routledge.
[3] Auletta, G., Fortunato, M., and Parisi, G. (2009). Quantum Mechanics. Cambridge
University Press.

106
Basic elements of Bohmian mechanics
[4] Choustova, O. (2007). Quantum Bohmian model for Ô¨Ånancial market. Department of
Mathematics and System Engineering, International Center for Mathematical Model-
ing, V¬®axj¬®o University, Sweden.
[5] Bohm, D. (1952). A suggested interpretation of the quantum theory in terms of ‚Äúhidden‚Äù
variables, Parts I and II. Physical Review, 85, 166‚Äì193.
6.5 Non-locality
Non-locality is a topic which has been explained at multiple points in Chapter 1. An
essential issue which relates intrinsically to the concept of non-locality is the fact
that in a classical mechanics setting forces do ‚Äúfall off with interparticle distance‚Äù
(Holland [1] (p. 282)). And Holland [1] (p. 282), continues ‚Äúthe contribution to the
total force acting on the ith particle coming from the quantum potential . . . does not
necessarily fall off with distance.‚Äù The most telling formulation of non-locality can
probably be found back in the use of the Newton‚ÄìBohm law, which was equation
(6.16) above, and which for a one body system is simply:
m.a = ‚àí‚àá(V + Q) ,
(6.17)
where m is mass, a is acceleration, V is the real potential, and Q is the quantum
potential.
As per Holland [1] (p. 282), for a ‚Äúmany body system in the limit of large
separations‚Äù one obtains:
miai = ‚àí[‚àáiQ(q1, q2, . . . , qn) + ‚àáiVi(qi)]qj=qj(t),
(6.18)
where i is the ith particle (this is equation 7.1.12; Holland [1] (p. 282)). Holland
([1] (p. 282)) would see three characteristics as typical of what he calls a ‚Äúnon-local
connection‚Äù:
r ‚Äúdependence of each particle orbit on all the others‚Äù;
r ‚Äúresponse of the whole to localized disturbances‚Äù;
r ‚Äúthe extension of actions to large interparticle distances.‚Äù
Holland ([1] (p. 290)) reports that the ‚Äúcondition for non-locality is . . . non-
factorizability‚Äù of the wave function. The factorizability of, say, a two body
system-based wave function would be œà(x1, x2) = œàA(x1)œàB(x2) (Holland [1]
(p. 287, equation (7.2.1)). Particle 1 is associated with œàA and satisÔ¨Åes its own
Schr¬®odinger equation. Similarly, particle 2 is associated with œàB and also satisÔ¨Åes
its own Schr¬®odinger equation. Holland writes [1] (p. 288) ‚Äúfactorizability implies
physical independence.‚Äù Bohm and Hiley [2] (p. 61) compare the factorization to
the existence of independent pools of information.

6.7 Criticisms of Bohmian mechanics
107
As Holland indicates ([1] (p. 462)), it can be that ‚Äúquantum mechanics is both
incomplete and non-local.‚Äù If the wave function is interpreted as a probability
amplitude and not as a kind of a physical wave (the ensemble interpretation of
wave function ‚Äì Einstein, Margenau, Ballentine, see Chapter 1), then ‚Äúquantum
non-locality‚Äù is not surprising at all. The same property can be assigned with
the Smoluchowski equation for a few Brownian particles, see again Chapter 1.
Hence, the non-locality of Bohmian mechanics is so intriguing only because the
wave function is assigned with an individual (may be composite) system (the
pilot wave), but not an ensemble of such systems. We urge the reader also to
consult again our discussion on non-locality in Chapter 1, Section 1.20, just under
equation (1.78).
Now consider again equation (6.18) and one can indeed see that the non-locality
is intimately connected to the existence of the quantum potential. Please also refer
to Bohm and Hiley [2] (pp. 134‚Äì159), who provide for a full chapter on the topic
of non-locality.
6.6 References
[1] Holland, P. (2000). The Quantum Theory of Motion: An Account of the de Broglie‚Äì
Bohm Causal Interpretation of Quantum Mechanics. Cambridge University Press.
[2] Bohm, D. and Hiley, B. J. (1993). The Undivided Universe: An Ontological Interpre-
tation of Quantum Theory. Routledge.
6.7 Criticisms of Bohmian mechanics
In Chapter 3, we already mentioned that Bohm in effect revived hidden vari-
ables. Historically speaking, we should mention that one of the very early crit-
ics of Bohmian mechanics was also a very unexpected critic: Louis de Broglie.
Recall that we mentioned in Chapters 1 and 3 that de Broglie interpreted quantum
waves as physical waves. Jammer [1] (p. 287) indicates that originally de Broglie
rejected Bohm‚Äôs work, but later on he came to accept it more. Jammer [1] (p. 289)
cites Takabayasi [2], who said that ‚Äúthe proposed hidden variables would become
physically signiÔ¨Åcant only through a modiÔ¨Åcation of the Schr¬®odinger equation or
law of motion, a modiÔ¨Åcation which is ‚ÄòartiÔ¨Åcial and improbable.‚Äô ‚Äù Holland [3]
(pp. 25‚Äì26) sums up very well the usual objections which are voiced against
Bohmian mechanics. We mention some of them here (Holland [3] (p. 25)):
1. ‚Äúyou can not prove the trajectories are there‚Äù;
2. ‚Äúit predicts nothing new‚Äù;
3. ‚Äúit attempts to return to classical physics‚Äù;
4. ‚Äúthe price to be paid is nonlocality.‚Äù

108
Basic elements of Bohmian mechanics
Critique ‚Äò1‚Äô, as Holland remarks [3] (p. 25), is indeed partially true since
the Heisenberg uncertainty principle holds. But indeed, as Holland also fur-
ther indicates, this in itself is not sufÔ¨Åcient proof that no trajectories can exist.
Critique ‚Äò2‚Äô can be replied to as follows. Holland [3] indicates (pp. 184‚Äì185),
that ‚ÄúIn the quantum theory of motion we can make more detailed statements
about the behavior of individual elements in the ensemble than are contained in
the distribution function, of the type possible in classical mechanics.‚Äù Holland‚Äôs
[3] (p. 25) main argument in reply to the third objection is that there exists a
‚Äú‚Äòstate‚Äô of a mechanical system that lies beyond the material points‚Äù and there-
fore this makes that Bohmian mechanics is not just a straight return to classical
physics.
A critique which is sometimes put forward against the use of Bohmian mechanics
in a macroscopic system is that there would seem to be no action of the particle on
the wave. The ‚Äúone-way‚Äù direction, i.e. of the wave function guiding the particle
(but no opposite inÔ¨Çuence), may have a connection to the fact that equation (6.16),
m d2q(t)
dt2
= ‚àí‚àÇV (q,t)
‚àÇq
‚àí‚àÇQ(q,t)
‚àÇq
, is the particle equation of motion. However, we hasten
to add that we must tread very carefully here. It is essential to remark that in fact
‚Äúone can deduce the wave function from the trajectories‚Äù (Holland [4]). Please see
Holland [5] and Holland [6] for recent results.
Finally, as to the last point of critique (i.e. non-locality), one can safely claim
that, following Holland [3] (p. 25), non-locality is indeed ‚Äúan intrinsic feature of the
de Broglie‚ÄìBohm theory.‚Äù However, non-locality, although may be not a desirable
physical property, seems to be found in physics approaches other than Bohmian
mechanics. For instance, Bohm and Hiley [7] (p. 144) mention that Aspect et al.
[8] [9] [10] provided for an ‚Äúexperimental proof that, if there are hidden variables,
they must be non-local.‚Äù
6.8 References
[1] Jammer, M. (1974). The Philosophy of Quantum Mechanics. J. Wiley, New York.
[2] Takabayasi, T. (1952). On the formulation of quantum mechanics associated with
classical pictures. Progress of Theoretical Physics, 8, 143‚Äì182.
[3] Holland, P. (2000). The Quantum Theory of Motion: An Account of the de Broglie‚Äì
Bohm Causal Interpretation of Quantum Mechanics. Cambridge University Press.
[4] Holland, P. (2012). Private communication with one of the authors of this book.
[5] Holland, P. (2005). Computing the wavefunction from trajectories: particle and
wave pictures in quantum mechanics and their relation. Annals of Physics, 315,
505‚Äì531.
[6] Holland, P. (2006). Quantum back-reaction and the particle law of motion. Journal
of Physics A: Mathematical and General, 39, 559‚Äì564.
[7] Bohm, D. and Hiley, B. J. (1993). The Undivided Universe: An Ontological Interpre-
tation of Quantum Theory. Routledge.

6.7 Criticisms of Bohmian mechanics
109
[8] Aspect, A., Grangier, P., and Roger, G. (1981). Experimental tests of realistic local
theories via Bell‚Äôs theorem. Physical Review Letters, 47, 460‚Äì463.
[9] Aspect, A., Grangier, P., and Roger, G. (1982). Experimental realization of Einstein‚Äì
Podolsky‚ÄìRosen‚ÄìBohm gedankenexperiment: a new violation of Bell‚Äôs inequalities.
Physical Review Letters, 49, 2, 91‚Äì94.
[10] Aspect, A., Dalibard, J., and Roger, G. (1982). Experimental test of Bell‚Äôs inequalities
using time-varying analyzers. Physical Review Letters, 42, 1804‚Äì1807.


Part III
Quantum probabilistic effects in psychology:
basic questions and answers


7
A brief overview
7.1 Decision making in social science: general overview
Decision-making models are central in economics and psychology. Finding appro-
priate models which can approach human decision-making behavior is, as expected,
a very challenging task. Economics has for a long time embraced models which are
based on a particular axiomatic skeleton. The axioms are thought to be ‚Äúreasonable‚Äù
approximations of general decision situations.
A central starting point in preference modeling in economics consists in proving
that there exists an equivalence between the preference relation of an object x over
an object y, denoted as x ‚âªy, if and only if there exists a utility function u(.),
which maps a set of objects into R, such that u(x) > u(y). This is not an easy
task. However, for a Ô¨Ånite set of objects X (to which x and y belong), as any good
micro-economic theory textbook will show, the equivalence is quite easy to show.
It is substantially more difÔ¨Åcult to show when the set X is countable inÔ¨Ånite or
uncountable. As David Kreps [1] indicates (p. 24), for an uncountable X there
may exist a preference relation ‚âª, but this does not mean that there exists a utility
function u(.)! The lexicographic preference relation is an example.
The utility function has many practical uses in social science. Here we mention
two very basic uses:
1. In economics, the utility function plays an essential role in the derivation of a
demand function. The classical approach to deriving such a demand function
consists in maximizing a function subject to an equality constraint. In economics,
this is known as the ‚Äúmethod of Lagrange.‚Äù Ingersoll [2] (p. 8) describes the
method in a nutshell: to maximize a function f subject to an (equality) con-
straint g(x) = a, the so-called Lagrangian is L(x, Œª) ‚â°f (x) ‚àíŒª(g(x) ‚àía)),
where Œª is the Lagrangian multiplier. At this point, it needs to be mentioned
that the word ‚ÄúLagrangian‚Äù does have a different meaning in physics. Following
Baaquie [3] (p. 78), a ‚ÄúLagrangian . . . is the fundamental mathematical structure
113

114
A brief overview
in the path-integral formulation of quantum mechanics.‚Äù1 The use of the (eco-
nomics version) of the Lagrangian can be seen in the following simple example.
Any good undergraduate textbook in economics will discuss how a consumer
maximizes a utility function subject to the budget he or she is constrained by.
The basic formulation is then max u(‚àí‚Üíc ) constrained by the budget equation
‚àí‚Üí
p .‚àí‚Üíc = I, where ‚àí‚Üí
p is a 1 √ó n price vector and ‚àí‚Üíc is a n √ó 1 vector of quan-
tities of goods which are part of the consumption bundle of the consumer, I
is the budget Ô¨Ågure, and u(.) is a utility function. The Lagrangian is imme-
diate, L = u(‚àí‚Üíc ) ‚àíŒª(‚àí‚Üí
p ‚àí‚Üíc ‚àíI), where Œª is the Lagrangian multiplier. One
can obtain from this equation that the level of satisfaction will be maximized
where the so-called ‚Äúmarginal rate of substitution‚Äù is equal to the slope of the
budget curve. The interested reader may query whether, besides equality con-
strained optimization, there is room in economics for optimization procedures
with inequality constraints. The answer is afÔ¨Årmative, and the ‚ÄúKuhn‚ÄìTucker‚Äù
conditions (Kuhn and Tucker [4]) are invoked in that respect. The so-called
‚ÄúsufÔ¨Åciency theorem‚Äù by Kuhn and Tucker provides for conditions to obtain a
maximum/minimum. For an excellent discussion, see Chiang [5] (Chapter 21,
Section 2 (p. 722); Section 4 (p. 738 and following) and especially Section 5
(p. 744)).
2. The utility function plays also an essential role as an input in risk aversion. The
concavity and/or convexity of the utility function expresses risk aversion/risk
loving behavior of a decision maker. Let us make the simple assumption that we
derive utility from using wealth. We can then compare the expected utility of
consuming wealth, denoted as E(u(w)), with the utility derived from expected
wealth, u(E(w)). Let us imagine a gamble with two outcomes, for instance. The
u(E(w)) corresponds then to the utility received from obtaining a sure outcome,
while E(u(w)) then corresponds to the utility of gambling (that is to accept
the lottery). Hence, it is intuitive that, if u(E(w)) > E(u(w)), the individual is
risk averse. If the opposite equality occurs, E(u(w)) > u(E(w)), the individual
is a risk lover. Equality occurs if the individual is indifferent to risk. Those
relationships are also tied to the concavity, convexity, and linearity, respectively
of the utility function. Please see also below for the next section where we
propose other risk aversion measures.
Let us revisit the relationship between the preference over objects (whatever
those are) and the corresponding relationship expressed via the mathematical
inequality over levels of utility (as given by the utility function). The following
1 Professor Baaquie Ô¨Çagged up this issue of the meaning of the Lagrangian whilst he was staying for his sabbatical
at the University of Leicester.

7.1 Decision making in social science
115
sequence of ‚Äúevents‚Äù is important. Kreps [1] (p. 31) says it succinctly as follows:2
‚Äúwe‚Äôll make assumptions about the mathematical structure of the objects in the set
X ‚Äì we will want x ‚ààX somehow to represent uncertain prospects. And by impos-
ing further conditions on ‚âªhaving to do with the mathematical structure of X, we
will try to specialize the form of the function u.‚Äù The central question which is now
being asked is this: (Kreps [1] (p. 31)): ‚Äúwhat corresponding forms of functions
u will we seek?‚Äù We are now getting back to the three grand groups of expected
utility models already mentioned in Chapter 2. The workhorse of most economics
models is the von Neumann‚ÄìMorgenstern model [6], where the probabilities used
to calculate the expected utility are ‚Äúobjective.‚Äù When ‚Äúsubjective‚Äù probabilities
are used, then the Savage model [7] will be very relevant. In case of a mixture
of objective and subjective probability, the Anscombe‚ÄìAumann [8] model is used.
The famous decision-making paradoxes (such as Allais and Ellsberg‚Äôs paradox)
relate to the axiomatic underpinnings of those models. The next chapter will study
in detail the violation of the sure-thing principle (an important axiom in the Savage
expected utility model).
The classical expected utility models in economics, we mentioned above, have
now been ‚Äúsuperseded‚Äù by augmented models. An excellent survey paper is by
Machina [9].
Finally, new decision modeling movements have appeared on the international
research scene. We note for instance the work of Colin Camerer at Caltech.
Camerer‚Äôs approach is directly inspired from brain science and it attempts to
mimic human decision making in an as close way as possible. This new movement
is also known under the name of ‚ÄúNeuroeconomics‚Äù [10], which may be seen as a
subÔ¨Åeld of a larger more general discipline known under the name of ‚Äúbehavioral
economics.‚Äù
The relationship between a preference relation and the utility function is tightly
connected with probably the most fundamental ‚Äúbuilding‚Äù3 block of economics:
‚Äúeconomic rationality.‚Äù We follow Danthine and Donaldson [11] (p. 25) to sum-
marize the key assumptions:
1. Economic participants (or investors, or economic agents) have a complete pref-
erence relation (i.e. agents always can express a preference over objects (inci-
dentally they can be indifferent between objects too)).
2. Using the same notation we introduced at the beginning of this chapter, a
preference relation satisÔ¨Åes transitivity: ‚àÄx, y, z ‚ààX : if x ‚™∞y and y ‚™∞z, then
x ‚™∞z.
2 Please note that X is the set of objects. The mapping: X ‚ÜíR, expresses the levels of utility (as given by the
utility function).
3 Or should we say ‚Äústumbling‚Äù block?

116
A brief overview
3. Preference relations are stable over time.
4. A preference relation ‚™∞on X is continuous, that is for any sequence of pairs
{xn, yn}‚àû
n=1 with xn ‚™∞yn; for all n, we have x = limn‚Üí‚àûxn and y = limn‚Üí‚àûyn;
we have x ‚™∞y. The continuity assumption says that consumer preferences
cannot exhibit jumps.
As Danthine and Donaldson [11] (p. 25) remark, the above four key assumptions
guarantee (please see the beginning of this chapter) that if x ‚âªy, if and only if
there exists a utility function u(.), which maps a set of objects into R, such that
u(x) > u(y).
The above was a brief discussion of choice under certainty. When uncertainty is
built into the utility spectrum another assumption route is to be taken. The choice
then becomes a choice over lotteries. We follow Varian [12] (pp. 172‚Äì174). Varian
makes the important distinction between two properties: (i) the existence of a
utility function and (ii) the property that a utility function is (Varian [12] (p. 174))
‚Äúadditively separable over the outcomes and linear in the probabilities.‚Äù We do not
go into detail on the necessary assumptions to guarantee the existence of a utility
function (in the uncertainty environment). It is quite telling though to consider the
axioms needed to guarantee the second property we mentioned above. We follow
Varian [12] (p. 174):4
1. ‚Äúlotteries with indifferent prices are indifferent‚Äù;
2. ‚Äúthere is some best lottery. . . and some worst lottery . . . ‚Äù;
3. ‚Äúif one lottery between the best prize and the worst prize is preferred to another
it must be because it gives higher probability of getting the best prize.‚Äù
With those axioms, a utility function with the second property will exist. The
proof can be found in Varian [12] (pp. 174‚Äì175).
The three chapters in this part of the book will analyze human decision making
in a still different way. The objective here consists in trying to uncover, via the
use of quantum physics concepts, whether human decision making can be better
explained by such concepts.
7.2 References
[1] Kreps, D. (1988). Notes on the Theory of Choice. Westview Press, CO.
[2] Ingersoll, J. E. (1987). Theory of Financial Decision Making. Rowman & LittleField.
[3] Baaquie, B. (2004). Quantum Finance. Cambridge University Press.
[4] Kuhn, H. W. and Tucker, A. W. (1951). Nonlinear programming. In Proceedings
of the Second Berkeley Symposium on Mathematical Statistics and Probability. Ed.
Neyman, J. University of California Press, Berkeley, CA, pp. 481‚Äì491.
4 We omit the continuity axiom in our discussion.

7.3 Modeling risk
117
[5] Chiang, A. C. (1984). Fundamental Methods of Mathematical Economics. McGraw-
Hill.
[6] von Neumann, J. and Morgenstern, O. (1947). Theory of Games and Economic
Behavior. Princeton University Press.
[7] Savage, L. J. (1954). The Foundations of Statistics. J. Wiley, New York.
[8] Anscombe, F. and Aumann, R. (1963). A deÔ¨Ånition of subjective probability. Annals
of Mathematical Statistics, 34, 199‚Äì205.
[9] Machina, M. (1987). Choice under uncertainty: problems solved and unsolved. Jour-
nal of Economic Perspectives, 1, 121‚Äì154.
[10] Camerer, C., Loewenstein, G., and Prelec, D. (2005). Neuroeconomics: how neuro-
science can inform economics. Journal of Economic Literature, 43, 9‚Äì64.
[11] Danthine, J. P. and Donaldson, J. B. (2005). Intermediate Financial Theory. Academic
Press Advanced Finance Series.
[12] Varian, H. (1992). Microeconomic Analysis. 3rd edition. Norton.
7.3 Modeling risk: some basic approaches
As is well known in the micro-economics literature, the so-called ‚ÄúSt. Petersburg‚Äù
paradox is often invoked, as per Blavatskyy [1] (p. 677) to argue against ‚Äúexpected
value and in favour of expected utility.‚Äù The key paper on this paradox is by
Samuelson [2] (also cited in Blavatskyy [1]). The paradox is quite easy to explain.
We follow Samuelson [2] (p. 25): ‚ÄúPeter offers to let Paul toss a fair coin an
indeÔ¨Ånite number of times, paying him 2 ducats5 if heads Ô¨Årst come up at the Ô¨Årst
toss, 4 ducats if its Ô¨Årst comes up at the second toss . . . 2i ducats for heads Ô¨Årst
coming up at the tth toss . . . and so forth ad inÔ¨Ånitum. Hence, if Paul has linear
utility, he could be made to pay for the ‚Äòfair price of playing the game‚Äô the value of
the mathematical expectation of the gains: E(2i) = 1
22 + 1
44 + ¬∑ ¬∑ ¬∑ 2k
2k + ¬∑ ¬∑ ¬∑ = ‚àû.‚Äù
It is quite straightforward to argue that if a utility functional were to be introduced
which is concave (i.e. with second derivative weakly negative), the inÔ¨Ånite expec-
tation problem could be converted into a Ô¨Ånite expectation (using then expected
utility). The last bracketed words are important, because they rejoin exactly the
point made by Blavatskyy [1] that this paradox is often invoked to defend expected
utility (as opposed to expected value).
We remarked already in the beginning of this chapter that utility functions can
be characterized by degrees of convexity and/or concavity. A linear utility function
is both concave and convex.
The concavity of the expected utility function indicates risk aversion. But as a
measure of risk aversion it is a little incomplete since it would be scale dependent.
An appropriate measure which counters scale dependency, is the so-called ‚ÄúArrow‚Äì
Pratt measure of risk aversion.‚Äù Textbooks devoted to the basics of micro-economic
5 This is a currency unit.

118
A brief overview
theory will deÔ¨Åne this measure. We follow here Varian [3] (p. 178):
ARA(w) = ‚àíu‚Ä≤‚Ä≤(w)
u‚Ä≤(w) ,
(7.1)
where u‚Ä≤‚Ä≤ is the second derivative of the utility function towards wealth, w; and u‚Ä≤
denotes the Ô¨Årst derivative of the utility function towards wealth.
Let us consider an agent with utility function u(w) and another agent with utility
function v(w). The agent with utility function u(w) is more risk averse than the
agent with utility function v(w) when ‚àíu‚Ä≤‚Ä≤(w)
u‚Ä≤(w) > ‚àív‚Ä≤‚Ä≤(w)
v‚Ä≤(w) for all levels of wealth.
Using the ARA measure we can then also calculate whether ARA is increasing
(IARA), decreasing (DARA), or constant (CARA).
As Varian [3] (p. 181) indicates ARA is a measure of local risk aversion. Two
well-known measures which are appropriate for a context of so-called global risk
aversion, are: (i) a measure which relates to the composition of two functions and
(ii) a measure which involves a ‚Äúwillingness to pay approach.‚Äù We mention those
here and we follow again Varian ([3] (p. 181)).6 As mentioned already above, a
natural way to measure degrees of risk aversion follows from imposing degrees
of concavity on the utility function. Hence, agent 1‚Äôs utility function, u, is ‚Äúmore
concave‚Äù than agent 2‚Äôs utility function, v, when u(w) = h(v(w)) where h(.) is
an increasing/strictly concave function. Finally, there is another possible measure.
As per Varian ([3] (p. 181)), denote7 a(Œµ) as the maximum amount of wealth8 an
agent would be willing to give up so as to avoid the risk, Œµ. Such risk is typically
deÔ¨Åned in a very basic way: a random variable with mean zero. One can write
that u(w ‚àía(Œµ)) = E(u(w + Œµ)). The utility for diminished wealth (the left-hand
side of this simple equation) is equal to the expected utility of getting into the
gamble. This indeed a very intuitive statement, and it follows that agent 1 with
utility function u(w) is more risk averse than agent 2 with utility function v(w)
when au(Œµ) > av(Œµ) (and this must hold for any wealth level).
It is instructive to consider the following theorem which establishes the equiv-
alence between the three measures we mentioned above. We adapt the proof from
Varian ([3] (pp. 182‚Äì183)). Ingersoll [4] (pp. 40‚Äì41) gives also a proof.
Theorem 10 If u(w) and v(w) are two differentiable, increasing and concave
expected utility functions then: ‚àíu‚Ä≤‚Ä≤(w)
u‚Ä≤(w) > ‚àív‚Ä≤‚Ä≤(w)
v‚Ä≤(w) ‚áîu(w) = h(v(w)) ‚áîau(Œµ) >
av(Œµ), where h(.) and Œµ are deÔ¨Åned as above.
Proof. (1). ‚àíu‚Ä≤‚Ä≤(w)
u‚Ä≤(w) > ‚àív‚Ä≤‚Ä≤(w)
v‚Ä≤(w) ‚áíu(w) = h(v(w)). We do not do this. (2) u(w) =
h(v(w)) ‚áíau(Œµ) > av(Œµ). u(w ‚àía(Œµ)) = E(u(w + Œµ)) and by the given we can
6 For a similar discussion, see also Ingersoll [4] (pp. 37‚Äì40).
7 We alter somewhat notation.
8 We assume such quantity could exist.

7.3 Modeling risk
119
also see that u(w ‚àía(Œµ)) = Eh(v(w + Œµ)). By Jensen‚Äôs inequality, which says
that for a random variable x and f (.) a strictly concave function of x, Ef (x) <
f (Ex). So we can say that Eh(v(w + Œµ)) < h(Ev(w + Œµ)) and we know that
h(Ev(w + Œµ)) = h(v(w ‚àíav(Œµ)) and h(v(w ‚àíav(Œµ)) is equal to u(w ‚àíav(Œµ)), and
therefore we can say that u(w ‚àíau(Œµ)) < u(w ‚àíav(Œµ)) and thus it must then be
true that au(Œµ) > av(Œµ). (3) That au(Œµ) > av(Œµ) ‚áí‚àíu‚Ä≤‚Ä≤(w)
u‚Ä≤(w) > ‚àív‚Ä≤‚Ä≤(w)
v‚Ä≤(w) can also be
proven.
‚ñ†
A useful comparative static result is as follows. We follow again Varian ([3]
(p. 184)). Consider two assets, one risky and one is risk free, and invest an amount
a in the risky asset. Assume there exists an endowment of wealth of level w. Hence,
w ‚àía is the amount invested in the riskless asset. Second period wealth, w‚àó, can
be written as: a(1 + r) + (w ‚àía)(1 + rf ), where rf is the risk free interest rate.
To simplify, set9 rf = 0. A key question is then: What is the expected utility from
investing a units of currency? One writes Eu(w + ar) = v(a). The Ô¨Årst derivative
(towards a) is Eu‚Ä≤(w + ar)r and the second derivative (towards a) is Eu‚Ä≤‚Ä≤(w +
ar)r2. With an assumed existence of risk aversion, there is the requirement that the
second derivative is negative. Set the Ô¨Årst-order condition as Eu‚Ä≤(w + ar)r = 0.
How does the amount of money invested, a, vary with changes in wealth, w?
Denote a(w) as the optimal level a function of w. Differentiating the Ô¨Årst-order
condition with respect to w yields Eu‚Ä≤‚Ä≤(w + a(w)r)r(1 + a‚Ä≤(w)r) = 0, from where
one Ô¨Ånds that a‚Ä≤(w) = ‚àíEu‚Ä≤‚Ä≤(w+ar)r
Eu‚Ä≤‚Ä≤(w+ar)r2 . In order to know what the sign behavior is of
a‚Ä≤(w), the following claim is made. We adapt the claim below from Varian [3]
(p. 185).
Note: Increasing ARA means: if wealth increases, ARA increases; decreasing
ARA: if wealth increases, ARA decreases.
Claim 11 Eu‚Ä≤‚Ä≤(w + ar)r is positive, negative, or zero as ARA is decreasing,
increasing, or constant.
Proof. It needs to be shown that DARA (decreasing absolute risk aversion) implies
that Eu‚Ä≤‚Ä≤(w + ar)r > 0. If r > 0, then ARA(w + ar) = ‚àíu‚Ä≤‚Ä≤(w+ar)
u‚Ä≤(w+ar) < ARA(w) and
this can be rewritten as u‚Ä≤‚Ä≤(w + ar) > ‚àíARA(w)u‚Ä≤(w + ar), and since r > 0
we can write that u‚Ä≤‚Ä≤(w + ar)r > ‚àíARA(w)u‚Ä≤(w + ar)r. Now let us consider
the case of r < 0. Writing that u‚Ä≤‚Ä≤(w + ar) > ‚àíARA(w)u‚Ä≤(w + ar) and con-
sidering decreasing ARA (i.e. if wealth increases, ARA decreases) we have
that u‚Ä≤‚Ä≤(w + ar) < ‚àíARA(w)u‚Ä≤(w + ar), and since r < 0, we must have that
u‚Ä≤‚Ä≤(w + ar)r > ‚àíARA(w)u‚Ä≤(w + ar)r. Whether r < 0 or r > 0, we get the same
result. Taking expectations over u‚Ä≤‚Ä≤(w + ar)r > ‚àíARA(w)u‚Ä≤(w + ar)r yields
9 This is in fact not an unreasonable assumption in the current Ô¨Ånancial context where interest rates on current
deposits (in some countries) carry virtually zero nominal interest rates (and possibly negative real interest rates).

120
A brief overview
Eu‚Ä≤‚Ä≤(w + ar)r > ‚àíARA(w)Eu‚Ä≤(w + ar)r and we know that Eu‚Ä≤(w + ar)r = 0
by the Ô¨Årst-order condition. Hence, Eu‚Ä≤‚Ä≤(w + ar)r > 0.
‚ñ†
Thus, when the investment in the risky asset, is increasing, risk aversion must be
decreasing. If you reduce the investment in the risky asset, then you get increasing
risk aversion.
7.4 References
[1] Blavatskyy, P. R. (2005). Back to the St. Petersburg paradox. Management Science, 51,
4, 677‚Äì678.
[2] Samuelson, P. (1977). St. Petersburg paradoxes: defanged, dissected, and historically
described. Journal of Economic Literature, 15, 24‚Äì55.
[3] Varian, H. (1992). Microeconomic Analysis. 3rd edition. Norton.
[4] Ingersoll, J. E. (1987). Theory of Financial Decision Making. Rowman & LittleField.
7.5 Possible remedies to the paradox: a brief discussion
In Chapter 2, we have already mentioned the existence of paradoxes in decision
making, most notably the Ellsberg paradox [1]. This paradox is discussed in detail
in Chapter 8, Section 8.6. Please note the paradox is treated in condensed form but
with excellent detail in Kreps [2]. We do not include the details of this paradox at
this point in the book.
However, let us provide for some needed background in order to ‚Äúset the tone‚Äù
of the gravity of this problem for economics. To underscore this ‚Äúgravity,‚Äù let
us consider Schoemaker [3] who at the beginning of his Journal of Economic
Literature article noted (p. 529) that: ‚ÄúIt is no exaggeration to consider expected
utility theory the major paradigm in decision making since the Second World War.‚Äù
It is really in the light of this quote that one can gauge the impact a paradox such
as Ellsberg‚Äôs can have. After all, it affects the expected utility paradigm.
Segal [4] provides for an excellent discussion of the Ellsberg paradox, and for
a proposal and summary of other approaches, to deal with that paradox within
the context of the utility structure well known in economics. Please see also
Section 1 in this chapter. Segal [4] remarks (p. 194) there are two important issues
which relate to the Ellsberg paradox (as presented by Ellsberg himself): (i) the sep-
aration of risk and uncertainty and (ii) the fact that the so called sure-thing principle
(please see again Chapter 8, Section 8.6) cannot be held up at all times as a valid
axiom by actual decision makers. The second point needs emphasizing, since if
indeed the axiomatic structure underlying the Savage model showed this defect, the
model as such was becoming substantially weaker. As we have brieÔ¨Çy discussed in
Chapter 2, the Savage model is one of the pillar models of expected utility in

7.5 Possible remedies to the paradox
121
economics. Hence, the economic theory community (as well as the academics
in applied economics research) were quite keen to see answers to this problem.
Indeed, leading economists have contributed to this important debate.
Segal also indicates [4] (p. 194) that Ellsberg never empirically veriÔ¨Åed his
proposed paradox.10 But much research subsequently did (please see Segal [4]
(p. 194) for some of the relevant references).
Let us now brieÔ¨Çy consider some of the proposals which were put forward. Segal
[4] distinguishes two groups of proposals: (i) the use of so-called non-additive prob-
abilities or (ii) the use of the additive probability approach (which is the objective
of Segal‚Äôs paper). In this book, we will (very) brieÔ¨Çy review one non-additive prob-
ability approach. We use the same references Segal proposes. Schmeidler [6] (p.
572) remarks: ‚Äúnon-additive‚Äù probability is an objective probability and such type
of ‚Äúprobability(ies) have been in use in physics for a long time.‚Äù In this chapter, we
provided for a brief discussion on the use of objective and subjective probabilities.
But let us continue brieÔ¨Çy with Schmeidler [6] (p. 572) who remarks that ‚Äúobjec-
tive probability is considered here as a physical concept like . . . momentum.‚Äù
Schmeidler [6] (pp. 572‚Äì573) argues that a die can for instance be made as
‚Äúperfect‚Äù as possible, i.e. by controlling for a uniform density of the material
used in the manufacturing of the cube etc. By controlling for such physical aspects,
the objective probability of obtaining one of the faces of the die, is indeed 1/6. On
the contrary, the subjective probability of an event, according to Schmeidler [6]
(p. 573), can be seen ‚Äúas the number used in calculating the expectation . . . of a
random variable.‚Äù And Schmeidler immediately adds that ‚ÄúThis deÔ¨Ånition includes
objective or physical probabilities as a special case where there is no doubt as to
which number is to be used.‚Äù
Let us now consider one non-additive probability approach. Fishburn, one of
the most noted decision theorists of our times, proposes in his paper (Fishburn [7]
(p. 1052)), six axioms, two of which are of importance to guarantee the existence
of subjective probability.11 A straightforward discussion of each of the six axioms
is provided for in Fishburn [7], pp. 1052‚Äì1053. His axioms imply useful properties,
and most notably one axiom implies a property (‚Äústatewise dominance‚Äù) (Fishburn
[7] (p. 1053)) which is a special case of Savage‚Äôs sure-thing principle. Theorem 1
in Fishburn [7] (pp. 1053‚Äì1054) indicates that his set of axioms do hold if and only
if there exists a unique so-called skew-symmetric bilinear functional, œÅ, so that for
gambles f and g, gamble g is preferred to gamble f if and only if œÅ(f, g) > 0. As
Segal [4] remarks (p. 194), the preferences in the Fishburn model are not assumed
transitive, but theorem 3 in Fishburn [7] (p. 1057) allows for such transitivity, but
10 Wu et al. [5] (p. 404) do mention that some data appeared in Ellsberg‚Äôs doctoral thesis at Harvard.
11 Remark that the Savage model uses subjective probability (see also Chapter 2).

122
A brief overview
as Segal [4] (p. 195) further points out, the skew-symmetric bilinear functional will
not explain the Ellsberg paradox. We note that in Segal‚Äôs [4] model (the additive
probability approach) transitivity is satisÔ¨Åed.
7.6 References
[1] Ellsberg, D. (1961). Risk, ambiguity and Savage axioms. Quarterly Journal of Eco-
nomics, 75, 643‚Äì669.
[2] Kreps, D. (1988). Notes on the Theory of Choice. Westview Press, CO.
[3] Schoemaker, P. J. H. (1982). The expected utility model: its variants, purposes, evidence
and limitations. Journal of Economic Literature, 20, 529‚Äì563.
[4] Segal, U. (1987). The Ellsberg paradox and risk aversion: an anticipated utility
approach. International Economic Review, 28, 1, 175‚Äì202.
[5] Wu, G., Zhang, J., and Gonzalez, R. (2004). Decision Under Risk. In The Blackwell
Handbook of Judgment and Decision Making. Eds. Koehler, D. and Harvey, N. Oxford
University Press.
[6] Schmeidler, D. (1989). Subjective probability and expected utility without additivity.
Econometrica, 57, 3, 571‚Äì587.
[7] Fishburn, P. (1983). Ellsberg revisited: a new look at comparative probability. The
Annals of Statistics, 11, 1047‚Äì1059.
7.7 The role of the law of total probability (LTP): a brief overview
One of the basic laws of classical probability theory is the law of total probability
(LTP). This law is a basic theorem drawn from classical Kolmogorovian probability
theory. It is a consequence of the additivity of probability and Bayes‚Äô formula for
conditional probabilities. We remark that Bayes‚Äô formula is a deÔ¨Ånition in the
classical Kolmogorov model. The conditional probability P(B|A) is deÔ¨Åned by
using the probability P(B ‚à©A) of the intersection of events A and B (their joint
occurrence):
P(B|A) = P(B ‚à©A)
P(A)
; P(A) > 0.
(7.2)
We recall the deÔ¨Ånition of Kolmogorov probability space. By the Kolmogorov
axiomatics [1], the probability space is a triple:
P = (, F, P).
(7.3)
Elementary events are denoted by œâ (those events belong to ); elements of F
are events, P is probability. We emphasize that Bayes‚Äô formula is not a theorem,
it cannot be derived. Kolmogorov wrote that in his model, Bayes‚Äô formula is a
deÔ¨Ånition of conditional probability.
We formulate the LTP in the form as it is used in decision making. Consider
two dichotomous random variables a = ¬±1, b = ¬±1. The b-variable describes

7.7 The role of the LTP
123
decisions. So, we can make the decision b = +1, ‚Äúyes,‚Äù or b = ‚àí1, ‚Äúno.‚Äù The
a-variable describes possible conditions preceding the decision making. For exam-
ple, a = +1: ‚Äúthe climate will change towards warming,‚Äù a = ‚àí1; the negation.
An example for the b-variable: ‚Äúone buys a property near the sea,‚Äù b = ‚àí1; the
negation, b = +1.
LTP The prior probability to obtain the result, e.g. b = +1 for the random variable
b is equal to the prior expected value of the posterior probability of b = +1 under
conditions a = +1 and a = ‚àí1:
P(b = j) = P(a = +1)P(b = j|a = +1) + P(a = ‚àí1)P(b = j|a = ‚àí1), (7.4)
where j = +1 or j = ‚àí1.
The LTP gives a possibility to predict the probabilities for the b-variable on
the basis of conditional probabilities and the a-probabilities. The main idea behind
applications of the LTP is to split, in general, a complex condition, say C, preceding
the decision making, into a family of (disjoint) conditions, in our case Ca
+ =
a = +1 and Ca
‚àí= a = ‚àí1, which are less complex. One can then estimate in
some way (subjectively or on the basis of available statistical data) the probabilities
under these simple conditions P(b = ¬±|a = ¬±1) and the probabilities P(a = ¬±1)
of the realization of conditions Ca
¬±. On the basis of these data, the LTP provides
the value of the probability P(b = j) for j = ¬±1. If, e.g., P(b = +1) is larger than
P(b = ‚àí1), it is reasonable to make the decision b = +1, for instance say ‚Äúyes.‚Äù
Typically, decision making is based on two thresholds for probabilities (chosen
depending on a problem): 0 ‚â§Œµ‚àí‚â§Œµ+ ‚â§1. If the probability P(b = +1) ‚â•Œµ+,
the decision b = +1 should be made. If the probability P(b = +1) ‚â§Œµ‚àí, i.e.
P(b = ‚àí1) ‚â•1 ‚àíŒµ‚àí, the decision b = ‚àí1 should be made. If Œµ‚àí< P(b = +1) <
Œµ+, then additional analysis should be performed.
7.8 Reference
[1] Kolmogorov, A. N. (1933). Grundbegriffe der Wahrscheinlichkeitsrechnung. Springer
Verlag, Berlin. English translation (1956). Foundations of the Probability Theory.
Chelsea Publishing, New York.

8
Interference effects in psychology ‚Äì an introduction
8.1 Classical decision making and the Bayesian approach
In the former chapter (Chapter 7, Section 7.7), we deÔ¨Åned the Bayes probability
rule for two events A and B. The Bayesian approach has very important practical
applications. The title of this section of the chapter suggests the Bayesian approach
seems to have a close connection with classical decision making. This is clearly
true, but it does say little on which areas of decision making this approach has high
impact. In Ô¨Ånancial applications but also in the area of risk and insurance, does
this theory have high levels of use. Robert [1] is an excellent source for a detailed
description. We give here a slightly (but only slightly) more involved deÔ¨Ånition of
the Bayesian approach. We follow here Shevchenko [2]. Denote, as in Shevchenko
[2] (p. 43)1 the density function for a random vector X of data, given a vector of
parameters Y, as FX|Y. The joint density FX,Y of the data and parameters is given
by:
FX,Y = Y|X.FX,
(8.1)
where Y|X is the density of parameters given that the data are taking a speciÔ¨Åc
value (the posterior density), FX is the marginal density of X. Bayes‚Äô theorem is
very close to the above equation, and it says that the posterior density, Y|X, can
be calculated as:
Y|X = 1
FX
FX|YY,
(8.2)
where Y is the density of parameters. As is indicated in Shevchenko [2] (p. 44), the
density Y|X is characterized by combining prior knowledge (Y) with information
derived from the data, given thus by FX|Y. Shevchenko [2] (pp. 119‚Äì120) also
distinguishes two main approaches on how to estimate the parameters of the prior
1 We have the adapted the notation.
124

8.3 Non-classical decision making
125
distribution. In the so-called ‚Äúpure Bayesian approach,‚Äù the prior is subjectively
speciÔ¨Åed (for instance using opinion), while in the so-called ‚Äúempirical Bayesian
approach,‚Äù data are used for speciÔ¨Åcation. Practical aspects of such speciÔ¨Åcations
are given also in Shevchenko [2] (see for instance pp. 119‚Äì121). We do not expand
on this here.
Schmeidler [3] makes the following very interesting statement (p. 571): ‚ÄúThere
are two . . . rules for assigning prior probabilities to events in case of uncertainty.
The Ô¨Årst says that symmetric information with respect to the occurrence of events
results in equal probabilities. The second says that if the space is partitioned into
k symmetric (i.e. equiprobable) events, then the probability of each event is 1/k.‚Äù
Schmeidler indicates he does not agree with the second rule. Let us cite him again
(Schmeidler [3] (p. 571)): ‚ÄúThe probability attached to an uncertain event does
not reÔ¨Çect the heuristic amount of information that led to the assignment of that
probability. For example when the information on the occurrence of two events
is symmetric they are assigned equal prior probabilities. If the events are com-
plementary the probabilities will be 1/2, independently of whether the symmetric
information is meager or abundant.‚Äù This comment clearly puts an important qual-
iÔ¨Åer on the speciÔ¨Åcation of the prior (for instance in the case of the pure Bayesian
approach which we mentioned above).
With this added information in mind, we are now ready to consider Bayesian
decision making in a very different context: non-classical decision making.
8.2 References
[1] Robert, C. P. (2001). The Bayesian Choice. Springer Verlag, Berlin.
[2] Shevchenko, P. V. (2011). Modelling Operational Risk Using Bayesian Inference.
Springer Verlag, Berlin.
[3] Schmeidler, D. (1989). Subjective probability and expected utility without additivity.
Econometrica, 57, 3, 571‚Äì587.
8.3 Non-classical decision making: violation of the LTP (law of total
probability) and the quantum Bayesian approach
The departure point for our quantum journey is the understanding that the LTP, in
spite of its matching with our ‚Äúnatural probabilistic expectations,‚Äù is really just a
mathematical theorem. It was proven on the basis of a special mathematical model
for probability, i.e. the Kolmogorov probability model, see Kolmogorov [1]. The
cornerstone of Kolmogorov‚Äôs approach is the postulation of a possibility to embed
complex conditions (contexts) preceding the decision making into one probability
space. This postulated (!) embedding provides a possibility to apply to contexts a

126
Interference effects in psychology ‚Äì an introduction
set-theoretical algebra, known as Boolean algebra. Hence, operations of intersec-
tion, union, and complement can all be used. The Ô¨Årst operation (intersection) is the
subject of our main interest, since it plays the fundamental role in Bayes‚Äô formula,
which we recall is a deÔ¨Ånition of conditional probability in the Kolmogorov model.2
Suppose now that Kolmogorov‚Äôs embedding postulate has a restricted domain
of application.3 We note this is not surprising at all. All mathematical models are
restricted only to special classes of natural or social phenomena. Thus, the Boolean
algebra cannot be freely applied to any given collection of contexts (i.e. complexes
of conditions preceding the decision making). We are especially interested in the
situation where the operation of intersection cannot be used. In this case, Bayes‚Äô
formula for conditional probabilities has no meaning. It then follows that the LTP
cannot be derived in the absence of Bayes‚Äô formula. Hence, the natural law of
classical probability, the LTP, can be violated! Is this surprising? In fact, it is not
more surprising than, for instance, the appearance of non-Euclidean geometries,
e.g. Lobachevsky‚Äôs geometry in physics. In parallel to the fact that the Euclidean
geometric model has its limits of application, the Kolmogorov probabilistic model
has its own limits too.
In particular, the LTP is violated in quantum physics, in the double-slit experi-
ment. Please see Chapter 5, Section 3 of this book for details on this experiment.
In this chapter, we consider this experiment again, but now in a way which
is proper for comparing the LTP and decision making. The b-observable (see
Chapter 7 (Section 7)) gives us the position of the photon on the registration screen.
To remain within the objective of connecting with decision making, one can con-
sider the problem of predicting the position of a photon‚Äôs registration, that is to pre-
dict the probability that the photon hits a selected domain on the registration screen.
To make the b-variable discrete, we split the registration screen into two domains
say B+ and B‚àíand, if a photon produces the black dot in B+, we set b = +1. We
can similarly deÔ¨Åne the result b = ‚àí1.
The a-variable (see Chapter 7, Section 7) describes the slit which is used by a
particle, say a = +1 the upper slit and a = ‚àí1 the lower slit. For simplicity, we
2 This is a good place to make a general remark about the role of mathematical models in science. To analyze a
natural or social phenomenon, one should always be aware about the mathematical details of the model which
one wants to use. In the absence of such knowledge, one may risk interpreting features of the mathematical
model as fundamental features of Nature or society. In applying various laws of probability, some researchers
will not take note of the precise mathematical description of those laws. As an example, it is not uncommon to
notice that some researchers working on applications of probability and statistics in various domains of science
maybe sometimes quite ignorant about the Kolmogorov axiomatics of modern (classical) probability theory.
As a showcase to this observation, this phenomenon occurs quite often in quantum physics, including quantum
information theory.
3 The main problem is that this is a hidden postulate. It does not Ô¨Ågure in the list of Kolmogorov‚Äôs axioms
(see [1]). Therefore, even if one does read the book ([1]), one may risk not paying attention to this extremely
important (hidden) postulate.

8.3 Non-classical decision making
127
set P(a = +1) = P(a = ‚àí1) = 1/2, so the source is placed symmetrically with
respect to the slits. Consider three different experimental contexts:
C : both slits are open. We can Ô¨Ånd P(b = +1) and P(b = ‚àí1) from the exper-
iment as the frequencies of photons hitting the domains B+ and B‚àí, respec-
tively.
Ca
+ : only one slit, labeled a = +1, is open. We can Ô¨Ånd P(b = j|a = +1),
j = ¬±1, the frequencies of photon hitting B+ and B‚àí, respectively.
Ca
‚àí: only one slit, labeled a = ‚àí1, is open. We can Ô¨Ånd P(b = j|a = ‚àí1),
j = ¬±1, the frequencies of photon hitting B+ and B‚àí, respectively.
If we put together these frequency probabilities, which were collected in the
three real experiments, then we observe that the LTP is violated, e.g. Khrennikov
[2]. The classical LTP cannot be used to predict, e.g., the probability P(b = +1)
that the photon hits B+ under the context C (both slits are open) or on the basis of
probabilities P(b = j|a = ¬±1), that the photon hits B+ under contexts Ca
¬± (only
one respective slit is open). We remark that here the probabilities P(b = j|a =
¬±1) are statistical empirical probabilities obtained in corresponding experiments.
We have performed experiments under contexts Ca
¬±, and we have collected the
corresponding data. We now want to predict the probabilities for a new experiment
(under the context C), but we do not perform that experiment. We can see that the
classical LTP prediction strategy does not work.
An important question is this: Can the LTP be violated outside quantum physics?
Why not! What is the crucial probability issue of the previous analysis of the two
slit experiment? Three experimental contexts C, Ca
¬± cannot be embedded in the
same space , since one cannot apply to the real physical situation the Boolean
algebra. It is impossible (physically) to make an ‚Äúintersection‚Äù of, e.g., contexts
C and Ca
+, and to create a context C ‚à©Ca
+. In philosophic terms, this story is
about the principle of complementarity. If we specify the slit, e.g. context Ca
+, we
specify particle features of a quantum system. This destroys the context C describ-
ing the wave features (interference of two waves propagating through two open
slits). In quantum physics, the principle of complementarity is often coupled to
wave‚Äìparticle duality. We remark that Niels Bohr never mentioned wave‚Äìparticle
duality. The principle of complementarity was formulated as a general principle
for the existence of incompatible (complementary) experimental contexts. From
a later point of view, it is not so surprising to observe that the principle of com-
plementarity may Ô¨Ånd applications not only in physics, but even in social science.
We mention that Bohr borrowed this principle from psychology. Our presentation
can be considered as the comeback of the principle of complementarity to psy-
chology and cognitive science. However, we come well equipped with quantum
mathematics.

128
Interference effects in psychology ‚Äì an introduction
8.4 Contextual probabilistic formalization
We now mathematically formalize the above considerations. Consider a context
C (a complex of conditions: for instance physical, social, Ô¨Ånancial) and two
dichotomous observables a and b. We may call a and b random variables, but
we should remember that these are not random variables in the sense of the con-
ventional Kolmogorov model, i.e. we do not suppose that they can be realized as
(measurable) functions, a, b :  ‚Üí{¬±1}. These variables under context C have
probabilities P(a = +1|C), P(a = ‚àí1|C), P(b = +1|C), P(b = ‚àí1|C); here, e.g.,
P(a = +1|C) is the probability that a = +1 under context (condition) C. We will
attempt to escape Ô¨Åxing the interpretation of the probabilities. They can be statis-
tical probabilities obtained via frequencies of results of measurements as well as
subjective probabilities, i.e. probabilities of a priori assignments for the values of
a and b.
In contrast to the LTP formulation of Chapter 7, Section 7 (see equation (7.4)), we
shall proceed by carefully controlling the contextual dependence of probabilities.
We emphasize that context-conditioning is quite different from the standard (as it
pertains to the Kolmogorov model) event-conditioning. The reason for this is not
only limited to the fact that event-conditioning is based on the Bayes‚Äô formula and
Boolean algebra. A context C need not (although can in some cases) be associated
with any event. For example, we can speak about different social contexts, e.g. the
context of the present Ô¨Ånancial crisis. Thus, in general, a context is a complex of
conditions. In some special situations, the context can be identiÔ¨Åed with an event.
An important class of such event contexts is given by selection contexts which
correspond to conditioning upon values of some variable. Take a variable, say a,
which takes two values a = ¬±1. Consider two contexts: Ca
+, the condition that a
takes the value a = +1, and Ca
‚àí, the condition that a takes the value a = ‚àí1.
For example, a is a question asked to a group (ensemble) of people. Here contexts
Ca
¬± have the ensemble representation: the Ca
+ is characterized by the ensemble of
people who replied ‚Äúyes‚Äù and Ca
‚àíis characterized by the ensemble of those people
who replied ‚Äúno.‚Äù The original ensemble of people used for this experiment can
be considered as the ensemble representation of some context, say C4. Since all
contexts in this consideration can be represented by ensembles, it may induce the
illusion that this experiment can be described with a unique Kolmogorov space.
This is not true. It is natural to choose the C-ensemble (the original group of people)
as the set . This set was encountered in Chapter 7 (Section 7) as being part of
the triple which deÔ¨Åned the probability space (equation (7.3)). Then, of course,
4 This context is determined by conditions under which the original group was created; for example, age,
education, and so on.

8.4 Contextual probabilistic formalization
129
the Ca
¬±-ensembles can be considered as subsets, say A¬±, of . However, such an
embedding cannot be used for a proper description of the experiment. In general,
by giving the deÔ¨Ånite answer to the a-question people change their mental states.
People in Ca
¬±-groups (sets A¬±) cannot be identiÔ¨Åed with themselves in the original
C-group (set ).
Consider now another variable b. Under selection contexts Ca
¬±, we can per-
form the b-measurement and obtain the corresponding conditional probabilities
(contextual probabilities):
P(b = +1|Ca
+), P(b = ‚àí1|Ca
+), P(b = +1|Ca
‚àí), P(b = ‚àí1|Ca
‚àí).
To make the notation closer to the standard one, we set:
P(b = +1|Ca
+) ‚â°P(b = +1|a = +1), P(b = ‚àí1|Ca
+) ‚â°P(b = ‚àí1|a = +1),
P(b = +1|Ca
‚àí) ‚â°P(b = +1|a = ‚àí1), P(b = +1|Ca
‚àí) ‚â°P(b = ‚àí1|a = ‚àí1).
In the above presentation, we considered measurements of the b-variables. Thus,
the statistical interpretation of probabilities was in use. As was mentioned before,
there are no reasons why one needs to stick to one Ô¨Åxed interpretation. For instance,
we also can appeal to subjective probability. Thus, for example, P(b = +1|Ca
+) can
be interpreted (depending on the problem) as a priori subjective probability that b
takes the value b = +1 under the condition that a has taken the value a = +1.
If the LTP does not hold true (as a consequence of multi-contextuality with
complementary contexts), then the left-hand side of equation (7.4) in Section 7.7
is not equal to the right-hand side. We call this difference the interference term by
analogy with quantum mechanics in which the LTP is violated, inducing a so-called
interference term. In contextual notation, the interference terms are given by:
Œ¥(b = +1|C) = P(b = +1|C)‚àí‚àíP(a = +1|C)P(b = +1|a = +1)
‚àíP(a = ‚àí1|C)P(b = +1|a = ‚àí1),
(8.3)
Œ¥(b = ‚àí1|C) = P(b = ‚àí1|C)‚àí‚àíP(a = ‚àí1|C)P(b = ‚àí1|a = +1)
‚àíP(a = ‚àí1|C)P(b = ‚àí1|a = ‚àí1).
(8.4)
This deÔ¨Ånition can be rewritten as the LTP which is perturbed by the interference
terms:
P(b = ¬±1|C) = P(a = +1|C)P(b = ¬±1|a = +1)
+ P(a = ‚àí1|C)P(b = ¬±1|a = ‚àí1) + Œ¥¬±,
(8.5)

130
Interference effects in psychology ‚Äì an introduction
where Œ¥¬± = Œ¥¬±(C). By analogy with quantum physics, see Khrennikov [3] for
details, we select the normalization:
Œª¬± = Œ¥¬±/2
"
¬±,
(8.6)
where:
¬± ‚â°¬±(C) = P(a = +1|C)P(b = ¬±1|a = +1)P(a = ‚àí1|C)
√ó P(b = ¬±1|a = ‚àí1)
(8.7)
Thus, the LTP with interference terms (8.5) can be written as:
P(b = ¬±|C) = P(a = +1|C)P(b = ¬±|a = +1)
+ P(a = ‚àí1|C)P(b = ¬±|a = ‚àí1) + 2Œª¬±
"
¬±.
(8.8)
If the absolute values of the normalized interference term Œªq is less than 1 (for
some q = ¬±1), we can Ô¨Ånd an angle Œ∏q such that:
Œªq = cos Œ∏q.
(8.9)
In the opposite case, we use the representation:
Œªq = œµ cosh Œ∏q, œµ = ¬±1.
(8.10)
Here Œ∏q = Œ∏(q|C). The ‚Äúprobabilistic phase‚Äù Œ∏q depends on the context C. If (8.9)
holds for both q = ¬±, then this case yields trigonometric interference. If (8.10)
holds for both q = ¬±, then this case yields hyperbolic interference. Otherwise, we
get mixed hyper-trigonometric interference.
In the trigonometric case, we have the following LTP with the interference term:
P(b = ¬±|C) = P(a = +1|C)P(b = ¬±|a = +1)
+ P(a = ‚àí1|C)P(b = ¬±|a = ‚àí1) + 2 cos Œ∏¬±
"
¬±.
(8.11)
This sort of interference between probabilities can be easily derived in the standard
formalism of complex Hilbert spaces used in quantum mechanics. However, we
emphasize that we did not start with this formalism. We did not start directly
with the assumption that the state of the brain is described by the complex vector
normalized by 1. Of course, one might proceed by starting with this assumption.
But in such an approach one misses the motivation to appeal to the mathematical
formalism of quantum mechanics. Why did the brain select such a representation
of information? Typically to justify postulating the Hilbert space for encoding of
the brain‚Äôs states, people appeal to the quantum brain, i.e. the brain as the real
quantum physical system. See, for instance, Roger Penrose [4] [5] and Stuart
Hameroff [6] [7].

8.4 Contextual probabilistic formalization
131
There are strong objections to claim there exists a ‚Äúphysical quantum brain.‚Äù
Therefore, we would not like to be rigidly coupled to this model which induces the
interference of probabilities and violation of the LTP in a standard quantum way.
We motivate the use of the mathematical formalism of quantum physics by
its natural appearance from the contextual probabilistic model for representation
of information.5 We shall see later on that our very general contextual approach
induces the same LTP with an interference term just as in quantum physics. More-
over, the formalism of quantum physics based on the representation of probabilities
by complex probability amplitudes, on the vector representation of probabilistic
data in complex Hilbert space (Khrennikov [3]) also emerges. Thus, the brain
could design such a representation by attempting to Ô¨Ånd the simplest form of the
processing of contextual probabilistic data, i.e. a linear representation.
But the situation is more complicated. Besides the trigonometric interference of
probabilities, well known in quantum physics, the contextual formalism induced a
new kind of interference, namely hyperbolic interference:
P(b = ¬±|C) = P(a = +1|C)P(b = ¬±|a = +1)
+ P(a = ‚àí1|C)P(b = ¬±|a = ‚àí1) ¬± 2 cosh Œ∏¬±
‚àö
.
(8.12)
Such a deviation from the classical LTP has a natural explanation. We recall
that the interference terms Œª¬± provide the magnitudes of deviations from the
classical LTP (with corresponding normalizations by products of probabilities).
Trigonometric interference is the exhibition of rather small deviations (normalized
by probabilities), so |Œª¬±| ‚â§1. Hyperbolic interference is the exhibition of larger
deviations, such that |Œª¬±| ‚â•1. Of course, in our contextual model there are no
reasons to assume that deviations should be bounded by 1. We mention that this
may be a sign that quantum observables were selected in a ‚Äúspecial‚Äù way, inducing
only the trigonometric interference. One may expect that social systems can exhibit
even stronger non-classicality than the quantum systems. It may well be that the
human being is more non-classical than the electron.
It is interesting to remark that starting with the LTP with the hyperbolic inter-
ference term we can develop a formalism based on generalized Hilbert spaces over
algebras of so-called hyperbolic numbers, which is very similar to the standard
quantum formalism in complex Hilbert space. We recall that complex numbers
have the form z = x + iy; x, y ‚ààR, and i2 = ‚àí1. Hyperbolic numbers have the
5 We shall see that, in fact, the canonical Dirac‚Äìvon Neumann formalism based on the representation of observables
by self-adjoint operators in complex Hilbert space is too restrictive to match the general contextual probabilistic
model. Its generalization based on the so-called lifting of the density matrix should be used to describe
probabilistic data from, for example, psychology. Please see Appendix 1 in the next chapter of this part of the
book.

132
Interference effects in psychology ‚Äì an introduction
form z = x + jy; x, y ‚ààR, and j 2 = +1. In contrast to complex numbers, the
system of hyperbolic numbers is not a Ô¨Åeld, but only an algebra. This means that the
operations of addition, subtraction, and multiplication are well deÔ¨Åned. However,
the division is not. Nevertheless, even in the absence of division it is possible to
proceed quite far (Khrennikov [3]).
8.5 Interference effects in social science: decision making based on
LTP with interference terms
Our basic hypothesis is that cognitive systems (including collective social systems)
can make decisions by using the LTP with non-trivial interference terms. To conÔ¨Årm
this hypothesis, we should Ô¨Ånd experimental evidence in psychology and cognitive
and social science. One should either design and perform experiments which will
demonstrate the violation of the LTP or Ô¨Ånd this violation in the existing data.
We remark that the violation of the LTP supports the hypothesis of the complex
vector representation of the information by cognitive systems. We remark that as in
quantum physics via the interference of probabilities, the violation of the classical
LTP is the only possible test for the existence of a kind of wave representation
in the brain. As well as in quantum physics, in neurophysiology it is impossible
(at least at this present time) to observe directly ‚Äúmental complex amplitudes.‚Äù
We hope that our research on the violation of the LTP in the process of decision
making will stimulate neurophysiologists to look for vector (wave) representations
and quantum (quantum-like) information processing in the brain.
Recently Jerome Busemeyer paid attention to some famous experiments in
cognitive psychology (the ShaÔ¨År‚ÄìTversky [8] and Tversky‚ÄìShaÔ¨År [9], experiments)
which could explain violation of the LTP. Those experiments are related to the so-
called ‚Äúsure-thing principle‚Äù and the so-called disjunction effect (see also Rapoport
[10], Hofstadter [11] [12], and Croson [13]).
8.6 Savage sure-thing principle
As we mentioned in the introduction to Chapter 7, expected utility is the tool used
in traditional economics to model uncertainty. Two classical decision (expected
utility) theory paradoxes are the Allais and Ellsberg paradoxes.
In this chapter, we deal extensively with the Ellsberg paradox (see the
Section 8.12 in this chapter on the Tversky and ShaÔ¨År experiments). The Allais para-
dox (which is not treated in this book) really attacks von Neumann‚ÄìMorgenstern
expected utility. This paradox violates the so-called substitution axiom. As we have

8.6 Savage sure-thing principle
133
mentioned before, the von Neumann‚ÄìMorgenstern model is a model of objective
probability (i.e. with probabilities which are given from outside ‚Äì i.e. exogenously).
The Ellsberg paradox refers to the Savage model and in particular to a violation
of the sure-thing principle, an essential axiom in this expected utility theory. Prob-
ability in the Savage model is determined by the economic agent. Hence, in this
model subjective probability is used in the calculation of expected utility.
The sure-thing principle is quite easy to understand. Consider two sets of gam-
bles. Each set contains two gambles: G1 and G2 for set 1, G3 and G4 for set 2.
Imagine now that the participants in the experiment need to express a preference:
(i) in a Ô¨Årst time, do they prefer G1 over G2 (or vice versa) and (ii) in a second time,
do they prefer G3 over G4 (or vice versa). We can assume that participants in the
experiment are informed of the payoffs of all the gambles. We assume each gamble
has three states of nature: sn1, sn2, and sn3. The crux of the sure-thing principle
resides now in paying close attention to the fact that the payoffs of gambles in
set 1, G1 and G2 for state sn3, are identical. Similarly, the payoffs of gambles in
set 2, G3 and G4 for state sn3, are also identical.
The sure-thing principle is now easy to understand: the preference of the partic-
ipants in the experiment over G1 and G2 and G3 and G4 are not inÔ¨Çuenced by the
identical outcomes given state sn3.
In Busemeyer et al. [14], it is pointed out that ShaÔ¨År and Tversky [8] have
uncovered that participants in experiments such as the one described above, do
exhibit many violations of the sure-thing principle (STP).
We can formulate the STP in another possible way (Savage [15]). Following
Khrennikov [16] (p. 93), if you prefer prospect b+, to prospect b‚àí, if a possible
future event A happens (a = +1), and you still prefer prospect b+ if the future
event A does not happen (a = ‚àí1), then you should prefer prospect b+, despite
having no knowledge of whether or not event A will happen.
Savage‚Äôs illustration refers to a person who is undecided as to whether to buy a
property shortly before a presidential election. Says Savage, ‚ÄúSeeing that he would
buy in either event, he decides that he should buy, even though he does not know
which event will obtain‚Äù (Savage [15] (p. 21)). The crucial point is that the decision
maker is assumed to be rational. Thus, the STP was used as one of the foundations
of rational decision making and rationality in general. It plays an important role in
economics in the framework of Savage‚Äôs expected utility theory.
Savage‚Äôs STP is a simple consequence of the LTP. Consider a Kolmogorov prob-
ability space (, F, P). Suppose that the uncertainty context C and contexts Ca
¬±
can be embedded in the same probability space, i.e. the situation can be described
by using set-algebra (Boolean algebra). Moreover suppose that C is represented by
. The contexts Ca
¬± are represented by subsets A¬± of  and A‚àí=  \ A+. We
hope that the reader will forgive us for the introduction of new symbols A¬±. We

134
Interference effects in psychology ‚Äì an introduction
want to distinguish sharply between contexts and their set-theoretical images (if
they exist). Suppose now that, for example, for b = +1, both conditional probabil-
ities P(b = +1|Ca
+) and P(b = +1|Ca
‚àí) are equal to 1. We can express contextual
probabilities in the set-theoretic framework:
P(b = +1|C) ‚â°P(b = +1), P(b = ¬±1|Ca
¬±) = P(b = ¬±1|A¬±).
(8.13)
We obtain:
P(b = +1) = P(b = +1|A+ ‚à™A‚àí) = P(A+) + P(A‚àí) = 1.
(8.14)
Probability P(b = +1) can be considered as a conditional probability with respect
to the disjunction of events A+ and A‚àí, i.e.:
P(b = +1|A+ ‚à™A‚àí).
As we remark in Khrennikov [16] (p. 94) the ‚Äúviolation of (8.14) (is a nonclassical
probabilistic effect)6 induced by the creation of disjunction . . . the inÔ¨Çuence of
disjunction (to the decision b = +1) cannot be reduced to separate out inÔ¨Çuences
of its counterparts. In cognitive psychology this situation is called the disjunction
effect.‚Äù
8.7 Behavioral games: Prisoner‚Äôs Dilemma
The prisoner‚Äôs dilemma is a very famous example in basic game theory. Many
references exist as to this game. See, for instance, Howard [17] or also Nowak
et al. [18]. It can be formulated in the following simple way. Two individuals
(denote them as ‚ÄòSA‚Äô and ‚ÄòSB‚Äô) are suspected of committing a crime. The police,
wanting to press charges must be able to ascertain who of the two individuals is
the culprit. As is customary, they isolate both suspects. They can either confess or
deny the crime. The situation is summarized below:
Suspect A(SA)
PA
PA
Suspect B (SB)
Confess
Deny
PB
Confess
4 years; 4 years
1 year; 8 years
PB
Deny
8 years; 1 year
2 years; 2 years
From the table, one can see that the suspects can do well by both denying.
However, the players can do better if one of them confesses (i.e. betrays the other
suspect). In that case, the suspect who confesses only gets one year, while the denier
gets eight years. If both of them confess, then they are worse off when compared
to when both of them were denying. This is obvious. The problem in the prisoner‚Äôs
6 See the paper by ShaÔ¨År and Tversky [8].

8.8 Violation of rationality in the experiments of ShaÔ¨År and Tversky
135
dilemma thus returns to the issue that since one suspect does not know what the
other suspect will do, no best action can be taken. How should the prisoners act?
Rational prisoners, i.e. prisoners who proceed on the basis of the Savage STP,
should always (both) select the strategy to betray, i.e. to cooperate with police.
8.8 Violation of rationality in the experiments of ShaÔ¨År and Tversky
8.8.1 Contexts involved in the Prisoner‚Äôs Dilemma (PD)
This sub-sub-section reproduces7 part of Section 7.4.1 in Khrennikov [16]
(pp. 101‚Äì102).
The following mental contexts are involved in the PD:
r Context C, representing the situation when a player has no idea about the planned
action of the other player, the ‚Äúuncertainty context.‚Äù
r Context Ca
+, representing the situation when the B-player supposes that A will
stay silent (‚Äúcooperate‚Äù), and
r Context Ca
‚àí, when B supposes that A will betray (‚Äúcompete‚Äù).
Such a version of the PD experiment was performed by Croson [13].
Another version of the PD experiment (which is also realistic) was performed
by ShaÔ¨År and Tversky [8]. In their experiments, the B-player was informed about
the real actions of the A-player.8
We can also consider similar contexts Cb
¬±. We deÔ¨Åne dichotomous variables
a and b corresponding to actions of players A and B: a = +1 if A chooses to
cooperate and a = ‚àí1 if A chooses to compete; the b values are deÔ¨Åned in the
same way.
A priori the law of total probability might be violated for the PD, since player
B is not able to combine contexts. If those contexts were represented by subsets
of the so-called space of ‚Äúelementary events,‚Äù as is done in classical probability
theory, then player B would be able to consider the conjunction of the contexts
C and, e.g., Ca
+. Therefore, player B could operate in the context C ‚àßCa
+ (which
would be represented by the set C ‚à©Ca
+). But the very situation of the PD is such
that one cannot expect contexts C and CA
¬± to be peacefully combined. If player B
obtains information about the planned action of player A (or even if he just decides
that A will play in a deÔ¨Ånite way, e.g. the context Ca
+ will be realized), then the
context C is simply destroyed. It could not be combined with Ca
+.
We can introduce the following contextual probabilities:
7 Andrei Khrennikov (2010). Prisoners Dilemma. Ubiquitous Quantum Structure: From Psychology to Finance.
Springer-Verlag, Berlin, Heidelberg, pp. 101‚Äì102.
8 It actually is a little bit more complicated. Please see the fuller description of their experiment below.

136
Interference effects in psychology ‚Äì an introduction
r P(b = ¬±1|C): probabilities for actions of B under the complex of mental con-
ditions C.
r p+¬± ‚â°P(b = ¬±1|Ca
+) and p‚àí¬± ‚â°P(b = ¬±1|Ca
‚àí): probabilities for actions of
B under the complexes of mental conditions Ca
+ and Ca
‚àí, respectively.
r P(a = ¬±1|C): prior probabilities that B assigns for actions of A under the
complex of mental conditions C.
As we pointed out, there is no prior reason for the LTP to be true in this situation.
Recently, Busemeyer et al. [14]; [19]‚Äì[21] have shown that the LTP can be violated
by statistical data collected by ShaÔ¨År and Tversky [8] many years ago.
8.9 Prisoner‚Äôs dilemma-type experiment: ShaÔ¨År and Tversky
This sub-section reproduces9 part of Section 7.4.1 in Khrennikov [16] (pp. 102‚Äì
103).
ShaÔ¨År and Tversky [8] performed the following PD-type experiment. Participants
were told that they would play a two-person PD against another participant. In fact,
contrary to what they had been told, participants played against a pre-programmed
strategy. All participants were told that they had been randomly assigned to a
bonus group, which meant that they would occasionally be given information
about the other player‚Äôs already chosen move before they had to choose their own.
Throughout the experiment, each participant saw three versions of each PD: one
in which the other player‚Äôs move was unknown, one in which the other player had
cooperated, and one in which the other player had defected.
In the ShaÔ¨År‚ÄìTversky [8] PD experiment: we have,
r P(b = ‚àí1|C) = 0.63 and hence P(b = +1|C) = 0.37;
r p‚àí‚àí= 0.97, p‚àí+ = 0.03; p+‚àí= 0.84, p++ = 0.16.
As usually in probability theory, it is convenient to introduce the matrix of
transition probabilities:
Pb|a =
	0.16
0.84
0.03
0.97

.
We point out that this matrix is stochastic (as it should be). But it is clear that the
matrix obtained by ShaÔ¨År and Tversky is not double stochastic!
9 Andrei Khrennikov (2010). Prisoners Dilemma. Ubiquitous Quantum Structure: From Psychology to Finance.
Springer-Verlag, Berlin, Heidelberg, pp. 102‚Äì103.

8.10 Violation of double stochasticity for matrices of transition probabilities
137
8.10 Violation of double stochasticity for matrices of
transition probabilities
In probability and combinatorics, a double stochastic matrix is a square matrix of
non-negative real numbers, with the peculiar property that each of its columns add
up to 1 and each of its rows add up to 1. When only the columns of non-negative
real numbers (of the square matrix) add up to 1, then one obtains a left stochastic
matrix. When only the rows of non-negative real numbers (of the square matrix)
add up to 1, then one obtains a right stochastic matrix. Hence, a double stochastic
matrix must be both left stochastic and right stochastic.
We emphasize that, since:
P(b = +1|Ca
+) + P(b = ‚àí1|Ca
+) = 1, P(b = +1|C+‚àía) + P(b = ‚àí1|Ca
‚àí) = 1,
or in our notation:
p++ + p+‚àí= 1, p‚àí+ + p‚àí‚àí= 1,
the matrix Pb|a is always a right stochastic matrix.
If Pb|a was produced by quantum observables represented by symmetric opera-
tors a and b (in the two-dimensional complex space), it should be double stochastic,
since in such a case, e.g.:
p++ = |‚ü®+a|+b‚ü©|2 = |‚ü®+b|+a‚ü©|2,
where |¬±a‚ü©and |¬±b‚ü©are normalized by 1, eigenvectors of operators a and b are
deÔ¨Åned respectively:
a|¬±a‚ü©= ¬±|¬±a‚ü©, b|¬±b‚ü©= ¬±|¬±b‚ü©.
To derive double stochasticity, we apply the Parseval equality.
We point out again that matrices of transition probabilities constructed from
experimental data in cognitive psychology are not double stochastic. We now follow
Khrennikov [22] (p. 186). On the other hand, matrices of transition probabilities that
should be generated by conventional quantum mechanics in the two-dimensional
Hilbert space are always double stochastic.
We can present two possible explanations of this ‚Äúnon-double stochasticity
paradox‚Äù:
(a) The statistics of these experiments are neither classical nor quantum (i.e.,
neither the Kolmogorov measure-theoretic model nor the conventional quantum
model with self-adjoint operators could describe these statistics).
(b) Observables corresponding to real and possible actions are not complete. From
the viewpoint of quantum mechanics, this means that they should be represented

138
Interference effects in psychology ‚Äì an introduction
not in the two-dimensional (mental qubit) Hilbert space, but in a Hilbert space
of a higher dimension.
8.11 Prisoner‚Äôs dilemma-type experiment: Croson
This sub-section reproduces10 part of section 7.4.1 in Khrennikov [16] (pp. 103‚Äì
104).
Croson [13] performed a similar experiment with one important difference.
Unlike the original ShaÔ¨År‚ÄìTversky experiment, participants were now not informed
that they belonged to a ‚Äúbonus group.‚Äù They were also not informed they would
occasionally get information about actions of their co-players (in advance). Partic-
ipants were proposed ‚Äì in a subset of games ‚Äì to guess the actions of co-players.
Hence, the PD game in this version became a game with elicited rather than con-
trolled beliefs. In such a PD experiment, Croson obtained the following data:
P(b = ‚àí1|C) = 0.225 and hence P(b = +1|C) = 0.775; so the cooperation
rate was essentially higher than in the original ShaÔ¨År‚ÄìTversky experiment:
p‚àí‚àí= 0.68, p‚àí+ = 0.32; p+‚àí= 0.17, p++ = 0.83.
Hence, the matrix of transition probabilities is:
Pb|a =
	0.83
0.17
0.32
0.68

.
We see an essential deviation from the original ShaÔ¨År‚ÄìTversky experiment. It is
especially interesting that both experiments were based on the same payoff matrix:
	75, 75
25, 85
85, 25
30, 30

.
Croson‚Äôs experiment is very important in our mental contextual model. A mental
context can be changed not only by a ‚Äúreal change of the world,‚Äù but even by the
brain‚Äôs self-measurement. Even by imagining something, the brain changes its state
of mind, i.e. its mental context.
In Croson [13], an asymmetric version of the PD was performed. Here the payoff
matrix had the form:
	85, 65
35, 75
95, 15
40, 20

.
Here:
P(b = ‚àí1|C) = 0.375 and hence P(b = +1|C) = 0.625,
10 Ibid., pp. 103‚Äì104.

8.12 Gambling experiment ‚Äì 1: Tversky and ShaÔ¨År
139
so the cooperation rate was essentially higher than in the original ShaÔ¨År‚ÄìTversky
experiment:
p‚àí‚àí= 0.65, p‚àí+ = 0.35; p+‚àí= 0.47, p++ = 0.53.
Hence, the matrix of b|a-contextual probabilities is:
Pb|a =
	0.53
0.47
0.35
0.65

.
8.12 Gambling experiment ‚Äì 1: Tversky and ShaÔ¨År
The experiment that Tversky and ShaÔ¨År [9] proposed to test the disjunction effect
is well described in Busemeyer [20]. We follow this description here. Experiment
participants have an equal chance to win $200 or lose $100. The key issue consists
in remarking that the gamble is played in sequence: play1 and play2. Play1 is
required. Play2 is optional. The experimenters then considered three conditions.
In condition (i) experiment participants were told they won play1, but in condition
(ii) they were told they lost play1. In condition (iii) nothing was told to participants
in the experiment as to the outcome of play1. As we have indicated before in
this chapter (Section 8.6), the adding in of a sure outcome should not inÔ¨Çuence
the preferences. Recall the four gambles, G1, G2, G3, and G4 we discussed in
Section 8.6. Preferences of G1 over G2 and G3 over G4 should not be inÔ¨Çuenced
by the identical outcomes in state sn3. In a similar way, can we claim the same
outcome with the set-up in the Tversky and ShaÔ¨År experiment: if you prefer to
gamble in play2, given that you know you lost in play1, and you prefer to gamble
in play2, given that you know you won in play1, then it should not matter that you
do not know the outcome in play1 in order to prefer to gamble in play2.
Consider still another way to look at the experiment. We follow here Khrennikov
and Haven [23] (p. 380), where we show a very common form of presenting the
paradox. Consider the following experiment. We have an urn with 30 red balls and
60 other balls (blue and green). We do not know the exact proportion of green and
blue balls. We consider four gambles and we ask experiment participants to express
a preference between gambles 1 and 2 and between gambles 3 and 4. The gamble‚Äôs
payoffs are as follows:
1. Gamble 1 (G1): you receive 1 unit of currency (uoc) if you draw a red ball.
2. Gamble 2 (G2): you receive 1 unit of currency (uoc) if you draw a blue ball.
3. Gamble 3 (G3): you receive 1 unit of currency (uoc) if you draw a red or green
ball.
4. Gamble 4 (G4): you receive 1 unit of currency (uoc) if you draw a blue or green
ball.

140
Interference effects in psychology ‚Äì an introduction
Most of the experiment participants (and this result has occurred in repeated
experiments) will prefer G1 over G2, G1 ‚âªG2. The intuition for such preference
can be explained by the fact that one knows the odds of winning in G1 (i.e. 1/3
probability) but in G2 one is unsure about the odds. Participants in this experiment
also indicated that G4 ‚âªG3. Here again, one knows the odds of winning in G4 are
2/3. However, one is unsure about the odds in G3. Hence, the odds are ambiguous
in G2 and G3.
This paradox clearly violates the sure-thing principle. This can be easily shown
(see Khrennikov and Haven [24] (p. 7)) if we use the following table to summarize
the payoffs (in units of currency):
Red
Blue
Green
G1
1
0
0
G2
0
1
0
G3
1
0
1
G4
0
1
1
The constant payoffs in set 1 (G1 and G2) and in set 2 (G3 and G4) should not
inÔ¨Çuence the preferences. Hence, if G1 ‚âªG2, then, using the sure-thing principle,
it should be G3 ‚âªG4. As indicated already above, experiment participant will
very often indicate G3 ‚â∫G4.
Let us now cast the Ellsberg paradox in notation which can be used for our
purposes. Here, a gambling device, e.g. roulette plays the role of A. B is a
real player, his actions are b = +1 to play the second game, and b = ‚àí1 not
to play the second game. The context C corresponds here to the situation when
the result of the Ô¨Årst play is unknown to B. The contexts CA
¬± correspond to
the situations when B is informed of the results a = ¬±1 of the Ô¨Årst play in the
gamble.
Tversky‚ÄìShaÔ¨År gambling experiment, the version with the same group of
students.
We reproduce11 here part of section 7.4.2. in Khrennikov [16] (p. 104).
The data given here derive from the experiment which was performed for the
same group of students, but under different contexts CA
+ (win context), CA
‚àí(lost-
context), C (uncertainty context). Please note that there was a ten day pause between
successive experiments. From Tversky and ShaÔ¨År [9] we have:
P(b = +1|C) = 0.36 and hence P(b = ‚àí1|C) = 0.64;
p‚àí+ = 0.59, p‚àí‚àí= 0.41; p++ = 0.69, p+‚àí= 0.31.
11 Andrei Khrennikov (2010). Gambling experiment. Ubiquitous Quantum Structure: From Psychology to
Finance. Springer-Verlag, Berlin, Heidelberg, p. 104.

8.14 The Hawaii vacation experiment
141
We get the following matrix of transition probabilities:
Pb|a =
	0.69
0.31
0.59
0.41

.
This matrix of transition probabilities is not double stochastic either, compare with
previously considered PD-type experiments.
8.13 Gambling experiment ‚Äì 2: Tversky and ShaÔ¨År
We reproduce12 here part of section 7.4.2. in Khrennikov [16] (pp. 104‚Äì105).
In the same paper, Tversky and ShaÔ¨År [9] modiÔ¨Åed the gambling experi-
ment. Three different populations, one for each context, were involved in the
b-measurement (between subject design). The data are:
P(b = +1|C) = 0.38 and hence P(b = ‚àí1|C) = 0.62;
p‚àí+ = 0.57, p‚àí‚àí= 0.43; p++ = 0.69, p+‚àí= 0.31.
We get the following matrix of transition probabilities:
P =
	0.69
0.31
0.57
0.43

.
8.14 The Hawaii vacation experiment
We reproduce13 here Section 7.4.3 and part of Section 7.5 in Khrennikov [16]
(p. 105).
Tversky and ShaÔ¨År [9] considered the following psychological test demonstrat-
ing the disjunction effect. They showed that signiÔ¨Åcantly more students report that
they would purchase a non-refundable Hawaii vacation if they knew that they had
passed or failed an important exam as opposed to the case when they did not know
the outcome of the exam.
The latter context is denoted by C and the ‚Äúpassed‚Äù context by Ca
+ and ‚Äúfailed‚Äù
context by Ca
‚àí.
Here the results are:
P(b = +1|C) = 0.32 and hence P(b = ‚àí1|C) = 0.68;
p++ = 0.54, p‚àí+ = 0.57; p+‚àí= 0.46, p‚àí‚àí= 0.43; and
Pb|a =
	0.54
0.46
0.57
0.43

.
It is again not a double stochastic matrix.
12 Ibid. pp. 104‚Äì105.
13 Andrei Khrennikov (2010). Exam‚Äôs result and Hawaii experiment + reason Based Choice and Its Quantum
Like Interpretation. Ubiquitous Quantum Structure: From Psychology to Finance. Springer-Verlag, Berlin,
Heidelberg, p. 105.

142
Interference effects in psychology ‚Äì an introduction
Tversky and ShaÔ¨År [9] claimed that the disjunction effect is caused by a decision
process of reason-based choice. Participants, instead of considering the conse-
quences of their decisions, focus on reasons to choose one thing versus another.
Let us go back to the Hawaii experiment. If the exam were passed, there would
be a good reason to go to Hawaii ‚Äì to celebrate. If the exam were failed, there
would also be a good reason to go to Hawaii ‚Äì to console oneself. However, before
knowing the outcome of the exam, there is no reason to go to Hawaii. Hence,
participants choose not to go. This dependence on reasons for choice leads to
violation of the STP.
Bagassi and Macchi [25] show that the disjunction effect does not depend on
the presence of uncertainty (pass or fail the exam), but on the introduction into the
text-problem of a non-relevant goal (‚Äúpaying to know‚Äù).
In PD-type games, the information (real as well as obtained by imagination)
on plans of the A-player induces reasons (for the B-player) that are absent in the
absence of this information.
8.15 Non-classicality of statistical data: non-zero coefÔ¨Åcients
of interference
The presented experimental data demonstrate the violation of the LTP:
(1a) Tversky‚ÄìShaÔ¨År gambling experiment: version 1 (with the same group of
students) (Section 8.12). We reproduce14 here part of Section 7.6 in Khrennikov [16]
(p. 106). Here a-probabilities are equal: they were produced simply by a random
generator imitating the Ô¨Årst play of the gamble. Simple arithmetic calculations give:
Œ¥+ = ‚àí0.28, Œª+ = ‚àí0.44;
Œ¥‚àí= 0.28, Œª‚àí= 0.79.
The coefÔ¨Åcients of interference are non-zero! Thus, the probabilistic data are non-
classical. These coefÔ¨Åcients are bounded by 1. Thus, a non-classical version of the
LTP (with trigonometric interference) holds true. Here, the probabilistic phases
are:
Œ∏+ = 2.03, Œ∏‚àí= 0.66.
(1b)
Tversky‚ÄìShaÔ¨År
gambling
experiment:
between
subject
design
(Section 8.13). We reproduce15 here part of Section 7.6 in Khrennikov [16]
14 Andrei Khrennikov (2010). CoefÔ¨Åcients of interference and quantum like representation. Ubiquitous Quantum
Structure: From Psychology to Finance. Springer-Verlag, Berlin, Heidelberg, p. 106.
15 Ibid.

8.15 Non-classicality of statistical data
143
(p. 106). Here also, the a-probabilities are equal. We Ô¨Ånd:
Œ¥+ = ‚àí0.25, Œª+ = ‚àí0.4, Œ∏+ = 1.98;
Œ¥‚àí= 0.25, Œª‚àí= 0.69, Œ∏‚àí= 0.81.
Thus (as one can expect), the uncertainty context C is again non-classical; it is
trigonometric.
(2) ShaÔ¨År‚ÄìTversky PD experiment. We reproduce16 here part of Section 7.6 in
Khrennikov [16] (p. 107). In this PD experiment (Section 8.9) the B-player was
given the information that the A-player had chosen to cooperate and to compete
an equal number of times. Thus, here the a-probabilities are also equal. Here
Œª‚àí= ‚àí0.31 and hence the phase is Œ∏‚àí= 1.89. However, Œª+ = 3.98. Thus, the
interference level is very high. It exceeds the possible range of the conventional
trigonometric interference. This is the case of hyperbolic interference! Here the
hyperbolic phase Œ∏+ = arccosh (3.98) = 2.06.
This is the Ô¨Årst example of hyperbolic (in fact, hyper-trigonometric) inter-
ference! It shows that students are even more non-classical than electrons and
photons!
(3) Tversky‚ÄìShaÔ¨År Hawaii experiment (Section 8.14). We reproduce 17 here part
of Section 7.6 in Khrennikov [16] (p. 107). Here the a-probabilities are equal as
well. We have:
Œ¥+ = 0.17, Œª+ = 0.3, Œ∏+ = 1.3;
Œ¥‚àí= ‚àí0.17, Œª‚àí= ‚àí0.37, Œ∏‚àí= 2.
In summary, in all of the presented experiments, the LTP is violated. This means
thus that the probabilistic behavior of players is non-classical. However, contrary
to Savage, we would not call such a behavior solely irrational: it is irrational, but
non-classical, behavior.
Remark (On the equality of a-probabilities) In all experiments considered above,
besides Croson‚Äôs experiment18 the a-probabilities are assumed to be equal. In fact, it
is a rather natural assumption for decision making in the absence of information on
possible actions of the A-player to put equal probabilities for the player‚Äôs possible
actions.
16 Ibid., p. 107.
17 Ibid.
18 We were not able to get the a-probabilities for this experiment. We communicated with the author and she
promised to send us data. But, Ô¨Ånally, we did not get the data. The experiment was done a long time ago and at
that time the a-probabilities were not important: Croson (as well as Tversky and ShaÔ¨År) were interested only
in transition probabilities, since only these probabilities were used in their discussions on irrational decision
making. Hence, the a-probabilities were not included in the paper [13].

144
Interference effects in psychology ‚Äì an introduction
8.16 The constructive wave function approach and Ô¨Åt to data from the
experiments of ShaÔ¨År and Tversky
The Law of Total Probability (LTP) with the trigonometric interference term pro-
vides for a possibility to represent probabilities by complex probability amplitudes:
i.e. on the basis of probabilistic data, one can reconstruct a probabilistic amplitude.
Roughly speaking, if the cognitive systems really function on the basis of the com-
plex vector representation of information, then such a representation can be recon-
structed. This encapsulates the core of the constructive wave function approach. A
detailed (quite advanced mathematical) presentation of this approach can be found
(in the very general case, i.e. without coupling to cognition) in Khrennikov [3].
For the purpose of this section, let us make a short and simple presentation. We
use the elementary formula for complex numbers (which can be checked by direct
calculation):
D = A + B + 2
‚àö
AB cos Œ∏ = |
‚àö
A + eiŒ∏‚àö
B|2,
for real numbers A, B > 0, Œ∏ ‚àà[0, 2œÄ]. By using the LTP with the trigonometric
interference term, we can represent the probability P(b = Œ≤|C), Œ≤ = ¬±1, as the
square of the complex amplitude (Born‚Äôs rule):
P(b = Œ≤|C) = |œàC(Œ≤)|2 .
(8.15)
Here:
œà(Œ≤) ‚â°œàC(Œ≤) =
"
P(a = +1|C)P(b = Œ≤|a = +1)
+ eiŒ∏C(Œ≤)"
P(a = ‚àí1|C)P(b = Œ≤|a = ‚àí1).
(8.16)
The formula (8.16) gives the quantum representation algorithm. For any trigono-
metric context C by starting with the probabilistic data:
P(b = ¬±1|C), P(a = ¬±1|C), P(b = ¬±1|a = ¬±1)
this algorithm produces the complex amplitude œàC, which we can call the ‚Äúmental
wave function,‚Äù i.e. the quantum informational state of the brain.
Let us now reconstruct ‚Äúmental wave functions‚Äù (Asano et al. [26]) for experi-
ments on the disjunction effect:
(1a) Tversky‚ÄìShaÔ¨År gambling experiment, version 1 (Section 8.12):
œà(+) ‚âà0.59 + e2.03i 0.54;
œà(‚àí) ‚âà0.39 + e0.79i 0.45.
(8.17)
(1b) Tversky‚ÄìShaÔ¨År gambling experiment, version 2, between subject design
(Section 8.13):
œà(+) ‚âà0.59 + e1.98i 0.53;
œà(‚àí) ‚âà0.39 + e0.81i 0.46.
(8.18)

8.17 Other experiments
145
As one can expect, the two complex vectors (8.17) and (8.18) do not differ too
much.
We postpone the presentation of the ShaÔ¨År‚ÄìTversky PD experiment, since it
exhibited hyperbolic interference. We go directly to the Hawaii experiment:
(3) Tversky‚ÄìShaÔ¨År Hawaii experiment (Section 8.14):
œà(+) ‚âà0.59 + e1.98i 0.53;
œà(‚àí) ‚âà0.39 + e0.81i 0.46.
(8.19)
The LTP with trigonometric interference induces the representation of data
by complex amplitudes and the LTP with hyperbolic interference induces the
representation of data by hyperbolic amplitudes, see Khrennikov [3] for details.
In this book, we do not want to depart from the complex Hilbert space model
of cognitive processing of information. We just mention that the ShaÔ¨År‚ÄìTversky
PD experiment provides for a sign that cognitive systems exhibit more complex
information behavior than physical quantum systems. The complex Hilbert space
model is too restrictive for their description. Thus, other non-classical models,
including models based on Hilbert space should be explored.
We remark that even for interference coefÔ¨Åcients which are bounded by 1 (in the
case of trigonometric interference), the experiments in cognitive psychology which
were presented in previous sections can be considered as a sign that the canonical
(Dirac‚Äìvon Neumann) quantum formalism does not work. The matrices of transi-
tion probabilities are not double stochastic. This seems to be a general feature of
mental observables. Up to now, we have not found statistical data which produce
double stochastic matrices. A natural generalization of the canonical (Dirac‚Äìvon
Neumann) quantum formalism is given by the quantum Markov chain model,
developed by Accardi et al. [27].
We move the presentation of the quantum Markov chain description of data from
the experiments in cognitive psychology (with the trigonometric interference) to
Appendix 2 of the next chapter, because the model is quite complex mathematically.
It is based on a quite complicated construction of quantum information theory,
also known under the name of ‚Äúlifting‚Äù (see Appendix 1 of the next chapter). As a
numerical example, we will construct19 in the next chapter a quantum Markov chain
representation of the data from the ShaÔ¨År‚ÄìTversky PD experiment (see Appendix 2
in the next chapter).
8.17 Other experiments
In this section, we propose a practical experiment to measure the level of prob-
ability interference. See for instance Khrennikov [28]. Within this section, until
19 This is joint work of one of the authors with L. Accardi and M. Ohya [29].

146
Interference effects in psychology ‚Äì an introduction
Section 8.17.3, we follow entirely (with very slight modiÔ¨Åcations) Khrennikov and
Haven [24] (pp. 17‚Äì24).20 See also Haven [30] for a brief summary.
Assume there exists two mutually exclusive features A and B. Each feature
has a dual outcome, ‚Äú0‚Äù or ‚Äú1.‚Äù The outcome ‚Äú0‚Äù in features A and B is denoted
as respectively a1 and b1. Similarly, the outcome ‚Äú1‚Äù in features A and B can
be denoted as respectively a2 and b2. There exists an ensemble of experiment
participants,  who have the same mental state. The ensemble probability is
denoted as pa
j and is deÔ¨Åned as:
pa
j =
number of results aj
total number of elements in  .
(8.20)
Similarly for pb
j. A new ensemble  needs to be prepared to perform the
measurement pb
j.
Ensembles, a
i and b
i ; i = 1, 2 need then to be prepared and they have states
corresponding to the values of A = aj and B = bj; j = 1, 2. The following prob-
ability is then deÔ¨Åned:
pa|b
ij
= number of results aj for the ensemble b
i
total number of elements in b
i
.
(8.21)
Likewise for pb|a
ij . From classical probability theory, total probability is deÔ¨Åned
as:
pa
j = pb
1pa|b
1j + pb
2pa|b
2j ; j = 1, 2.
(8.22)
A similar deÔ¨Ånition can be made for pb
j.
In the presence of probability interference, one obtains (see also the section on
contextual probability formalization in the beginning of this chapter):
pa
j = pb
1pa|b
1j + pb
2pa|b
2j + 2
-
pb
1pb
2pa|b
1j pa|b
2j cos Œ∏j; j = 1, 2,
(8.23)
where cos Œ∏j is deÔ¨Åned as:
cos Œ∏j =
pa
j ‚àípb
1pa|b
1j + pb
2pa|b
2j
2
-
pb
1pb
2pa|b
1j pa|b
2j
.
(8.24)
If the cos Œ∏j is non-zero, then this would be indicative of the existence of the
quantum-like behavior of cognitive systems. A similar deÔ¨Ånition can be made for
pb
j.
20 This is Section 9.1 until Section 9.4 in that paper.

8.17 Other experiments
147
8.17.1 Description and discussion of a proposed experiment
What is the conjecture we want to test? We note that the test description which we
will explain below does not contain the minute details of the experimental set up.
We only provide for a fairly general discussion of how we could possibly test our
conjecture.
In basic terms the experiment deals with having experiment participants rec-
ognize a list of songs from a pre-determined list of songs. The tempo of each of
the songs is distorted by either lengthening or shortening the tempo. We use the
deÔ¨Ånition of tempo as in Levitin and Cook [31] (p. 927): ‚Äúthe amount of time it
takes a given note or the average number of beats occurring in a given interval of
time, usually beats per minute.‚Äù Kuhn [32] (p. 270) deÔ¨Ånes, beat tempo, in a very
similar way as: ‚Äúthe rate of speed of a composition.‚Äù
The time of listening exposure the test participants are allowed so as to recognize
each of the songs varies. The time of exposure is lengthened when the tempo is
increased. However, the time of exposure is shortened when the tempo of songs is
decreased. The rationale for this time variation is discussed below.
The experiment participants are divided into several groups. We Ô¨Årst want to
discuss the ‚Äúnormed‚Äù group. Levitin and Cook [31] in an experiment on tempo
recognition asked experiment participants to sing tunes of songs they themselves
had picked from a list of available songs. They examined how well the participants
could mimic the tempo of each of the chosen songs. In their experimental set up,
they formed a group of experiment participants (250 students) who would Ô¨Åll in
questionnaires which would allow, what Levitin and Cook [31] called, ‚Äúnorming.‚Äù
This questionnaire, in the words of Levitin and Cook [31] (p. 929), asked them (the
test participants) ‚Äúto indicate songs that ‚Äòthey knew well and could hear playing
in their heads‚Äô.‚Äù If we were to set up such an experiment ourselves, then we
would categorize experiment participants in the ‚Äúnormed‚Äù group, to do exactly
that: indicate songs they know well. We would then also need to determine a set of
songs which we can term as being ‚Äúbest known.‚Äù However, we may want to make
sure we use songs from different music categories. In a study by Collier and Collier
[33], the authors examine tempo differences in different types of music (like jazz
and other types). The authors Ô¨Ånd that the tempo differences are quite tied to the
music genre in question. Furthermore, Attneave and Olson [34] indicate that the
size of a music interval is dependent on the level of frequency of the music.
In the Levitin and Cook [31] study, the 250 students we mentioned above, were
all taken from a psychology 101 course (i.e. an introductory level Psychology
course). Those students were given the questionnaire and from their answers the
experimenters chose 58 CDs. Our experiment proposal would not really follow the
Levitin and Cook [31] study closely, since we instead would ask participants to

148
Interference effects in psychology ‚Äì an introduction
recognize songs we played randomly from a list we selected from the choice of
songs the ‚Äúnormed‚Äù group puts forward. In our experimental set up, the experiment
participants have to recognize songs we play for them when tempo and time of
exposure is varied. In the Levitin and Cook [31] study, participants are asked to
sing or hum a song for a time the participant selects him/herself and the obtained
tempo is then compared with the copyrighted song‚Äôs tempo.
Besides the normed group, we would in our envisioned experiment, have two
other groups of experiment participants. We note that none of the members of the
‚Äúnormed‚Äù group would participate in the experiment itself.21 We have therefore
two other groups. Group 1 whose participants are subjected to song excerpts where
tempo decreases are randomly injected into each song. The time of listening expo-
sure for each song is short. Participants in group 2 will be subjected to song excerpts
where tempo increases are randomly injected into each song. The time of the lis-
tening exposure for each song is longer than in each of the songs used in group 1.
The rationale for the variation of the exposure time comes from a study by Kuhn
[32],22 where it was found that test participants were better able to detect tempo
decreases rather than tempo increases. Kuhn [32] (p. 271) indicates that a study
by Farnsworth [35] showed that the ‚Äúlistener is most likely to change affective
terms with which he describes a piece of music whenever its tempo is appreciably
slowed or hastened.‚Äù 23 Kuhn [32] in his experiment set-up, where he solely used
professional musicians, showed that the beat tempos which had been decreased
were identiÔ¨Åed faster (in a statistically signiÔ¨Åcant way) than beat tempos which
had been increased. Kuhn [32] indicates those results also had been obtained,
independently, in a study by Drake [36]. In more general terms, the work by Drake
and Botte [37] addressed a fairly similar problem. They had subjects listen to two
identical sequences (except for their tempo difference). One sequence had a higher
tempo than the other. The subjects were asked to indicate which sequence was faster.
We note that the tempo experiments by Kuhn [32] did not make use of music.
However, the Kuhn [38] study does provide for this. In this study, mention is made
of the work by Geringer and Madsen [39], which actually Ô¨Ånds, in the context
of orchestral music, that tempo increases were more easily identiÔ¨Åed than tempo
decreases.
The Kuhn [38] study provides for a rich context in which one can appreciate
how tempo changes can be affected by extraneous variables such as melody activity
and audible steady beats. The study Ô¨Ånds that when melody activity and audible
steady beat were kept constant, the experiment participants (the participants were
21 This is probably wishful thinking. Running the experiment with a sufÔ¨Åciently large pool of students may well
be very challenging.
22 Also reported in the Levitin and Cook [31] paper (p. 931).
23 Kuhn‚Äôs [32] study also discusses rhythm besides beat. We omit it here.

8.17 Other experiments
149
students at an elementary school with a very strong music programme) could
distinguish well between slow and fast tempo. However, experiment results in this
study showed that melody activity clearly affected tempo perception, but there was
much less certainty as to how tempo recognition is affected when audible beat was
considered. It needs to be stressed that, according to Kuhn [38], there exists a sizable
literature which documents that there is ambiguity in tempo perception. Kuhn [38]
cites work by (amongst others) Madsen et al. [40] and Wang and Salzberg [41].
One way out, as suggested in Kuhn [38], is then maybe to only use musicians as
experiment participants in groups 1 and 2 (besides the normed group participants).
Khrennikov and Haven [42] have described an experiment where we can test
for the same type of variables (time and degree of deformation) by using instead a
database of pictures.
In our potential experiment, two features of the song recognition would be
compared:
1. time of processing of the songs,
2. the ability to recognize a song, S0, by analyzing a deformation S of it.
We denote the time of processing of the song with the variable t. The ability
to recognize the song with tempo deformations, which are either increasing or
decreasing, is denoted with the variable a.
The conjecture we want to test is:
Conjecture 12 t and a are complementary.
Preparation
The state preparation of the experiment can be described as follows. The experimen-
tal context (state) C is given by a sequence of songs, S1, . . . , Sm. The experiment
participants form a group G and each of the participants are exposed to all the songs
(from the distilled list of songs taken from the normed group) excerpts they will
hear. The context allows thus the experiment participants to learn the songs (some of
the songs they surely will know, but some they may not know as well (or not at all)).
In the Levitin and Cook [31] study, 46 students were selected for the tempo
recognition experiment. After learning has taken place, the group G is randomly
divided into two equal subgroups G1 and, G2.
First experiment: song tempo decreases and short exposure time
A Ô¨Årst experiment would be performed with experiment participants from group
G1. As was done in Levitin and Cook [31], test participants are to be seated in a
so-called sound attenuation booth. Each of the participants is then subjected to a
battery of songs (selected from our ‚Äúbest‚Äù songs (from the normed group)) played

150
Interference effects in psychology ‚Äì an introduction
sequentially. Each of the songs is played for the same amount of time. In this
Ô¨Årst experiment, the tempo of each of the songs is decreased and the exposure
time (to listen to the song) is kept uniformly short.24 Experiment participants must
choose from the full list of songs which the they are listening to. Songs in the
full list are indicated (alphabetically) by the name of the singer or composer. Next
to the authors‚Äô name is the title of the song and the record company owning the
copyright of the song. We also note that experiment participants need to pick the
song from the list within a uniformly prescribed time interval. This is a possible
issue of contention. Kuhn [32] reports that professional musicians need less time to
respond to a tempo change and they also make less mistakes than non-professional
musicians. A study related to this issue is Kuhn‚Äôs [43] paper which reports that, on
a longitudinal basis, test participants (from all walks of life), when asked to keep
a constant tempo, seem to instead increase tempo. Our study would not be able to
contain only test participants who are musicians. Hence, setting the response time
too short could thus create a negative bias.
The low tempo songs S‚Ä≤
1, . . . , S‚Ä≤
m are deformations of the original songs
S1, . . . , Sm. The tempo change could be Ô¨Åne tuned in the way Madsen and Graham
[44] (see also Kuhn [32]) have proposed. Those authors propose a modulation rate
(of tempo) of one beat per minute change every second.
Experiment participants in group G1 are subjected to listening to S‚Ä≤
1, . . . , S‚Ä≤
m
and also to listening to a few other songs which have not been part of the training
sample. We denote this set of songs as: SG1. The width of the time window, w, is a
parameter of the experiment.
The task the experiment participants have to fulÔ¨Åll is to indicate whether they
either recognize or not the songs SG1 as modiÔ¨Åcations of the songs S1, . . . , Sm. We
can make this experiment a little more sophisticated by using the procedure Levitt
[45] used. See alsoDrake andBotte [37]where the Levitt[45]approachis described.
Levitt [45] would decrease the tempo difference between two subsequent sequences
by 1%, if the subjects gave two correct answers (to the two prior sequences). In
some sense, the tempo decrease compensates for the shorter period which is given.
We could also make it increasingly harder for test participants by instead increasing
the tempo for every correct answer.
Let œâ be an experiment participant from group G1 performing this task. We set
t(œâ) = 1 if œâ was able to give the correct answers for x% of the songs in SG1; and
t(œâ) = 0 in the opposite case.
We now Ô¨Ånd probabilities P(t = 1|C) and P(t = 0|C) through counting num-
bers of experiment participants who gave answers t = 1 and t = 0, respectively.
24 The ‚Äúshortness‚Äù of the exposure time is obviously a calibration issue. Please see below for some beginning
discussion on this topic.

8.17 Other experiments
151
We denote respective subgroups of experiment participants by G1(t = 1) and
G1(t = 0), respectively. The Ô¨Årst subgroup consists of experiment participants
who have the ability to perform song recognition (with tempo decrease) ‚Äúquickly‚Äù
and the second subgroup consists of experiment participants who do not possess
that feature.
Second experiment: song tempo increase and long exposure time
The second experiment is performed with experiment participants from the group
G2 as well as the subgroups G1(t = 0) and G1(t = 1) of the Ô¨Årst subgroup G1.
The song deformations now are based on song tempo increases, which, as per
the experiment of Kuhn [32], are deformations which are harder to recognize. We
denote those deformations as S‚Ä≤‚Ä≤
1, . . . , S‚Ä≤‚Ä≤
m of the initial songs S1, . . . , Sm. As in the
Ô¨Årst experiment, ‚Äúunknown‚Äù songs will be added to the group of songs. We denote
the set of essentially deformed songs (with the ‚Äúunknown‚Äù songs) SG2.
The task the experiment participants have to fulÔ¨Åll is identical to the task
described in experiment 1: Can the participants recognize the songs in SG2 as
modiÔ¨Åcations of the initial songs S1, . . . , Sm?
The time window in experiment 2 is now longer than in experiment 1. The width
of the time window, w, is a parameter of the experiment.
Let œâ be an experiment participant performing this task. We set a(œâ) = 1 if œâ
was able to give the correct answers for x% of images in the series. And a(œâ) = 0
in the opposite case.
We now Ô¨Ånd probabilities P(a = 1|C) and P(a = 0|C) through counting num-
bers of experiment participants in the group G2 who gave answers a = 1 and
a = 0, respectively. We denote respective subgroups of experiment participants by
G2(a = 1) and G2(a = 0), respectively. The Ô¨Årst subgroup consists of experiment
participants who have the ability to perform song recognition (with tempo increase)
quickly and the second subgroup consists of experiment participants who do not
possess that feature. Because of the tempo increase, we note that the emphasis in
experiment 2 is on the carefulness of recognizing the deformation of a song.
Here again, we could use the Levitt [45] approach. We can increase (or decrease)
by 1% the tempo between subsequent songs if the test participant has given two
correct answers.
8.17.2 Sub- (super-) additivity
Using the above experiment, we Ô¨Ånd probabilities P(a = Œ≤|t = Œ±); Œ±, Œ≤ = 0, 1,
by counting the number of people in the group G1(t = Œ±) who gave the answer
a = Œ≤. After this, we calculate the coefÔ¨Åcient Œª and we Ô¨Ånd the angle Œ∏ which
gives us the measure of complementarity of variables t and a. If Œª > 1, we would

152
Interference effects in psychology ‚Äì an introduction
Ô¨Ånd experimental evidence of probabilistic behavior which is neither quantum nor
classical. We could also consider Œª(w) and even make Œª dependent on both w and
the degree of deformation. This degree of deformation could be expressed by using
the tempo measure deÔ¨Åned by Levitin and Cook [31].
8.17.3 The potential issue of the complementarity of t and a
Can the above conjecture we posed at the beginning of this section make sense
from a quantum mechanical point of view? As is well known, there does not exist
a quantum operator on time at all! It is not possible to Ô¨Ånd an uncertainty principle
of the type 
t.
a = hcogn/2, where hcogn is an analogue of the Planck constant.
This relates to the issue of operators having discrete spectra. See Khrennikov and
Haven [42]. Discussions on analogues of Planck constants in Ô¨Ånancial contexts
and other non-quantum physical contexts have been provided for in Choustova
[46][47], Khrennikov [48] and Haven [49].
The very objective of our experiment is just to overcome those problems of
measurement and hence to be able to test for complementarity on the t and a
variables.
In summary, in this chapter we have considered several experiments which
indicate a clear violation of the Law of Total Probability. The various versions of
the prisoner‚Äôs dilemma and the Tversky‚ÄìShaÔ¨År gambling experiment, as well as
the Hawaii problem, all exhibit this violation. Hence, we can say that probabilistic
behavior in those cases is non-classical.
8.18 References
[1] Kolmogorov, A. N. (1933). Grundbegriffe der Wahrscheinlichkeitsrechnung. Springer
Verlag, Berlin. English translation: (1956). Foundations of the Probability Theory.
Chelsea Publishing Company, New York.
[2] Khrennikov, A. (2009). Interpretations of Probability. De Gruyter, Berlin.
[3] Khrennikov, A. (2009). Contextual Approach to Quantum Formalism. Springer
Verlag, Berlin.
[4] Penrose, R. (1989). The Emperor‚Äôs New Mind. Oxford University Press.
[5] Penrose, R. (1994). Shadows of the Mind. Oxford University Press.
[6] Hameroff, S. (1994). Quantum coherence in microtubules: a neural basis for emergent
consciousness? Journal of Consciousness Studies, 1, 91‚Äì118.
[7] Hameroff, S. (1994). Quantum computing in brain microtubules? The Penrose‚Äì
Hameroff ‚ÄúOrch Or‚Äù model of consciousness. Philosophical Transactions of the
Royal Society, London A 1-28.
[8] ShaÔ¨År, E. and Tversky, A. (1992). Thinking through uncertainty: nonconsequential
reasoning and choice. Cognitive Psychology, 24, 449‚Äì474.
[9] Tversky, A. and ShaÔ¨År, E. (1992). The disjunction effect in choice under uncertainty.
Psychological Science, 3, 305‚Äì309.

8.17 Other experiments
153
[10] Rapoport, A. (1988). Experiments with n-person social traps 1: prisoner‚Äôs dilemma,
weak prisoner‚Äôs dilemma, volunteer‚Äôs dilemma, and largest number. Journal of Con-
Ô¨Çict Resolution, 32, 457‚Äì472.
[11] Hofstadter, D. R. (1985). Metamagical Themes: Questing for the Essence of Mind
and Pattern. Basic Books, New York.
[12] Hofstadter, D. R. (1983). The calculus of cooperation is tested through a lottery.
ScientiÔ¨Åc American, June, 14‚Äì18.
[13] Croson, R. (1999). The disjunction effect and reasoning-based choice in games.
Organizational Behavior and Human Decision Processes, 80, 118‚Äì133.
[14] Busemeyer, J. B., Wang, Z., and Townsend, J. T. (2006). Quantum dynamics of
human decision making. Journal of Mathematical Psychology, 50, 220‚Äì241.
[15] Savage, L. J. (1954). The Foundations of Statistics. J. Wiley, New York.
[16] Khrennikov, A. (2010). Ubiquitous Quantum Structure: From Psychology to Finance.
Springer Verlag, Berlin.
[17] Howard, J. V. (1988). Cooperation in the prisoner‚Äôs dilemma. Theory and Decision,
24, 203‚Äì213.
[18] Nowak, M., May, R., and Sigmund, K. (1995). The arithmetics of mutual help.
ScientiÔ¨Åc American, 272, 76‚Äì81.
[19] Busemeyer, J. B. and Wang, Z. (2007). Quantum information processing explanation
for interactions between inferences and decisions. In Quantum Interaction. Eds.
Bruza, P. D., Lawless, W., van Rijsbergen, K., Sofge, D. A., AAAI Spring Symposium
(Stanford University). Technical Report SS-07-08; 91-97. AAAI Press. Menlo Park.
[20] Busemeyer, J. R., Matthews, M., and Wang, Z. (2006). A Quantum Information
Processing Explanation of Disjunction Effects. In The 28th Annual Conference of the
Cognitive Science Society and the 5th International Conference of Cognitive Science.
Eds. Sun, R. and Myake, N. Erlbaum, New Jersey, pp. 131‚Äì135.
[21] Busemeyer, J. R., Santuy, E., and Lambert-Mogiliansky, A. (2008). Comparison of
Markov and quantum models of decision making. In Quantum Interaction: Proceed-
ings of the Second Quantum Interaction Symposium. (Eds.) Bruza, P., Lawless, W.,
van Rijsbergen, K., Sofge, D. A., Coecke, B., Clark, S. Oxford University, College
Publications, London.
[22] Khrennikov, A. Yu (2009). Quantum like model of cognitive decision making and
information processing. Biosystems, 95, 179‚Äì187.
[23] Khrennikov, A. and Haven, E. (2009). Quantum mechanics and violations of the
sure-thing principle: the use of probability interference and other concepts. Journal
of Mathematical Psychology, 53, 5, 378‚Äì388.
[24] Khrennikov, A. and Haven, E. (2007). The importance of probability interfer-
ence in social science: rationale and experiment. Cornell University Library,
http://arxiv.org/pdf/0709.2802.pdf.
[25] Bagassi, M. and Macchi, L. (2007). The ‚Äúvanishing‚Äù of the disjunction effect by
sensible procrastination. Mind and Society, 6, 41‚Äì52.
[26] Asano, M., Khrennikov, A., and Ohya, M. (2011). Quantum-like model for decision
making process in two players game: a non-Kolmogorovian model. Foundations of
Physics, 41, 3, 538‚Äì548.
[27] Accardi, L., Ohya, M., and Watanabe, N. (1997). Dynamical entropy through quantum
Markov chains. Open Systems and Information Dynamics, 4, 1, 71‚Äì87.
[28] Khrennikov, A. (2002). On the cognitive experiments to test quantum-like behav-
ior of mind. Reports from V¬®axj¬®o University: Mathematics, Natural Sciences and
Technology, Nr. 7.
[29] Accardi, L., Khrennikov, A., and Ohya, M. (2009). Quantum Markov model for
data from ShaÔ¨År‚ÄìTversky experiments in cognitive psychology. Open Systems and
Information Dynamics, 16, 371‚Äì385.

154
Interference effects in psychology ‚Äì an introduction
[30] Haven, E. (2008). Bohmian mechanics in the mechanics of option pricing. In Quantum
Interaction: Proceedings of the Second Quantum Interaction Symposium. (Eds.)
Bruza, P., Lawless, W., van Rijsbergen, K., Sofge, D. A., Coecke, B., Clark, S.
Oxford University, College Publications, London.
[31] Levitin, D. and Cook, P. R. (1996). Memory for musical tempo: additional evidence
that auditory memory is absolute. Perception and Psychophysics, 58, 927‚Äì935.
[32] Kuhn, T. L. (1974). Discrimination of modulated beat tempo by professional musi-
cians. Journal of Research in Music Education, 22, 270‚Äì277.
[33] Collier, G. and Collier, J. L. (1994). An exploration of the use of tempo in jazz. Music
Perception, 11, 3, 219‚Äì242.
[34] Attneave, F. and Olson, R. K. (1971). Pitch as a medium: a new approach to psycho-
logical scaling. The American Journal of Psychology, 84, 147‚Äì166.
[35] Farnsworth, P. R. (1969). The Social Psychology of Music. Iowa State University
Press, Iowa.
[36] Drake, A. H. (1968). An experimental study of selected variables in the performance
of musical durational notation. Journal of Research in Music Education, 16, 329‚Äì338.
[37] Drake, C. and Botte, M. C. (1993). Tempo sensitivity in auditory sequences: evidence
for a multiple look model. Perception and Psychophysics, 54, 3, 277‚Äì286.
[38] Kuhn, T. L. and Booth, G. D. (1988). The effect of melodic activity, tempo change,
and audible beat on tempo perception of elementary school students. Journal of
Research in Music Education, 36, 140‚Äì155.
[39] Geringer, J. and Madsen, C. M. (1984). Pitch and tempo discrimination in recorded
orchestral music among musicians and nonmusicians. Journal of Research in Music
Education, 32, 195‚Äì204.
[40] Madsen, C. K., Duke, R. A., and Geringer, J. M. (1986). The effect of speed alterations
on tempo note selection. Journal of Research in Music Education, 34, 101‚Äì110.
[41] Wang, C. C. and Salzberg, R. S. (1984). Discrimination of modulated music tempo
by strong students. Journal of Research in Music Education, 32, 123‚Äì131.
[42] Khrennikov, A. and Haven, E. (2006). Does probability interference exist in social
science? In Foundations of Probability and Physics ‚Äì 4. Eds. Adenier, G., Khrennikov,
A., Fuchs, C. AIP Conference Proceedings, 899, 299‚Äì309.
[43] Kuhn, T. L. (1975). Effect of notational values, age, and example length on tempo
performance accuracy. Journal of Research in Music Education, 23, 3, 203‚Äì210.
[44] Madsen, C. K. and Graham, R. (1970). The effect of integrated schools on perfor-
mance of selected music tasks of black and white students. Music Educator‚Äôs National
Conference, Chicago, Illinois, USA.
[45] Levitt, H. (1971). Transformed up-down methods in psychoacoustics. Journal of the
Acoustical Society of America, 49, 467‚Äì477.
[46] Choustova, O. (2006). Quantum Bohmian model for Ô¨Ånancial markets. Physica A,
374, 304‚Äì314.
[47] Choustova, O. (2007). Toward quantum-like modelling of Ô¨Ånancial processes. Journal
of Physics: Conference Series, 70 (38pp).
[48] Khrennikov, A. (2004). Information Dynamics in Cognitive, Psychological and
Anomalous Phenomena. Series Fundamental Theories of Physics, v. 138. Kluwer,
Dordrecht.
[49] Haven, E. (2005). Pilot-wave theory and Ô¨Ånancial option pricing. International Jour-
nal of Theoretical Physics, 44, 11, 1957‚Äì1962.

9
A quantum-like model of decision making
9.1 Introduction
In the previous chapter, we presented experimental data from cognitive psychology
which can be considered as a strong argument in favor of the complex (or more
general) Hilbert space representation of information by cognitive systems and the
use of the quantum information scheme in information processing. We have seen
that the classical Law of Total Probability (LTP) is violated. The interference of
probabilities induces a possibility to ‚Äúreconstruct a mental wave function.‚Äù An
important lesson we can learn from this is that the standard Dirac‚Äìvon Neumann
approach based on self-adjoint operators is too restrictive to describe known data
from cognitive psychology. More general quantum models should be used. Please
see also Appendix 2, this chapter.
In this chapter, we proceed under the assumption (which we consider as suf-
Ô¨Åciently conÔ¨Årmed experimentally) that in order to make decisions, cognitive
systems operate with ‚Äúmental wave functions.‚Äù We describe the scheme of such
decision making1 based on the lifting formalism, see Appendix 1, this chapter.
Since this book is oriented towards non-experts in quantum information theory,
we try to avoid the use of the lifting concept as long as is tolerable. In principle, the
reader can proceed without using the lifting concept. However, the formulation in
terms of lifting is mathematically elegant and it provides a possibility for further
generalizations of the model.
9.2 Two-player game and rational behavior
In this chapter (including Appendix 1) we reproduce2 (with only slight modiÔ¨Å-
cations) the paper by Asano et al. [1]. We explain in more detail a two-player
1 This is joint work of one of the authors with Asano and Ohya [1].
2 Masanari Asano and Masanori Ohya and Andrei Khrennikov (2011). Quantum-like model for decision making
process in two players game. Foundations of Physics, 41, 538‚Äì548.
155

156
A quantum-like model of decision making
Table 9.1. Pay-off table of a two-player game.
0 and 1 denote the actions player A or B chooses.
Cij(x, y) denotes the consequences of the game,
and x, y = a, b, c, d represent the values of the
pay-off. For example, in the dilemma game, the
relation of c > a > d > b is assumed.
A B
0
1
0
C00(a, a)
C01(b, c)
1
C10(c, b)
C11(d, d)
game and the rational behavior that is conventionally discussed in game theory.
Two players A and B have two alternatives for actions denoted by 0 and 1. These
players are under the same condition on their pay-offs as seen in the pay-off table,
Table 9.1, where Cij(x, y) denotes the consequences of the game, and x, y = a,
b, c, d represent values of the pay-off.
We here explain the rational behavior of a player in the setting of the so-called
‚Äúdilemma game.‚Äù The dilemma game has the inequalities c > a > d > b on the
values of the pay-offs. In the game, a player who chooses action 1 can avoid
the possibility of the minimum pay-off of d at least. Furthermore, the player can
gain the maximal pay-off of c if the other player chooses 0. To choose action 1
is reasonable for a player who wants to maximize his own pay-off. Game theory
considers that a rational player chooses 1 without any concern for the action of
the other player. The consequence of the game is always C11 if both players are
rational.3
9.3 Construction of a mental state
In the above game, in principle a player has no idea about another player‚Äôs action.
We assume this uncertainty creates some psychological inÔ¨Çuence on the decision
making of each player, i.e. it yields irrational choices. The decision making in our
model is mathematically described in the form of a quantum state called a ‚Äúmental
state.‚Äù In this section, we discuss the deÔ¨Ånition and construction of such a mental
state.
3 Note that, in this case, the sum of pay-offs in C11 is less than the one in the consequence C00, where both players
perform the irrational choice of 0. This is an interesting property of the dilemma game.

9.3 Construction of a mental state
157
9.3.1 A prediction state
We consider two players, named A and B. Player B only has to predict A‚Äôs choice
before deciding his own action. Here, we assume that player B predicts player A
will choose action 0 with probability p. Action 1 is then chosen with probability
1 ‚àíp. This does not mean that player B ‚Äújudges‚Äù player A‚Äôs action to be 0 (or 1).
Player B should consider the possibility of A‚Äôs actions simultaneously. We represent
such a situation by using the quantum state œÉ = |œÜ‚ü©‚ü®œÜ|:
|œÜ‚ü©= Œ± |0A‚ü©+ Œ≤ |1A‚ü©‚ààH = C2,
(9.1)
where |Œ±|2 = p, |Œ≤|2 = 1 ‚àíp and the orthogonal basis of |0A‚ü©and |1A‚ü©indicates
the alternatives of A. We call this state a prediction state.
9.3.2 An alternative state
When player B decides his action is 0, he thinks the consequence of the game will
be C00 or C10. In a sense, he chooses a consequence described in the superposition
of C00 and C10 as:
Œ± |C00‚ü©+ Œ≤ |C10‚ü©.
Now, when we put |C00‚ü©= |0A‚ü©‚äó|0B‚ü©and |C10‚ü©= |1A‚ü©‚äó|0B‚ü©, where |0B‚ü©and
|1B‚ü©are an orthogonal basis in K = C2, the state vector:
|0‚ü©= Œ± |C00‚ü©+ Œ≤ |C10‚ü©
= |œÜ‚ü©‚äó|0B‚ü©.
(9.2)
In a similar way, this gives another vector as:
|1‚ü©= Œ± |C01‚ü©+ Œ≤ |C11‚ü©
= |œÜ‚ü©‚äó|1B‚ü©.
(9.3)
We call the states of |0‚ü©‚ü®1|, alternative states.
9.3.3 A mental state
In the process of decision making, the player imagines the four consequences, and
he decides his own action in a probabilistic way. We describe such a situation by
using the following quantum state on H ‚äóK;
Œ∏ = |œà‚ü©‚ü®œà| , |œà‚ü©= x |0‚ü©+ y |1‚ü©.
(9.4)
This description indicates that the player chooses 0 with probability Œª = |x|2 and
1 with probability Œº = 1 ‚àíŒª = |y|2.

158
A quantum-like model of decision making
9.4 A process of decision making
In this section, we discuss a process of decision making that consists of three stages:
prediction, comparison, and decision.
9.4.1 Making an initial mental state
The decision making starts from the prediction of the other player‚Äôs choice. Before
the prediction, the player‚Äôs mental state is given by:
œÅ0 = |Œæ‚ü©‚ü®Œæ| , |Œæ‚ü©= x0 |0B‚ü©+ y0 |1B‚ü©‚ààK,
(9.5)
where |x0| = |y0| =
1
‚àö
2. With the use of this œÅ0 and the prediction state œÉ (in
Section 9.3.1), we deÔ¨Åne the initial mental state Œ∏I = |œàI‚ü©‚ü®œàI|:
Œ∏I = œÉ ‚äóœÅ0.
9.4.2 A comparison of consequences
The essential part of the decision making process is comparing the consequences
of the game. The coefÔ¨Åcients x, y of the mental state |œà‚ü©= x |0‚ü©+ y |1‚ü©
become changed by the comparison. We assume its dynamics obeys the following
differential equations, and approach a state of equilibrium:
dŒª
dt = ‚àíkŒª + ÀúkŒº
dŒº
dt = ‚àíÀúkŒº + kŒª,
(9.6)
where Œª = |x|2 and Œº = |y|2. These equations are similar to a chemical equilibra-
tion in a reaction system written as:
0
k
‚áå
Àúk
1,
(9.7)
where k (Àúk) ‚ààR means a rate of reaction from 0 to 1 (or from 1 to 0). Using
k and Àúk, we deÔ¨Åne the mental state in equilibrium:
Œ∏E = |œàE‚ü©‚ü®œàE| , |œàE‚ü©= xE |œÜ0‚ü©+ yE |œÜ1‚ü©,
|xE| =
.
Àúk
k + Àúk, |yE| =
.
k
k + Àúk.
(9.8)

9.4 A process of decision making
159
The probabilities ŒªE = |xE|2 and ŒºE = |yE|2 satisfy dŒª
dt = dŒº
dt = 0 in the above
differential equations. Here note that this equilibrium state Œ∏E is described as
Œ∏E = œÉ ‚äóœÅE. We call œÅE a mental state after comparison.
The reaction rate Àúk or k is related with the degree of the player‚Äôs tendency to
choose either 0 or 1. To discuss these parameters in a simple way, we consider
the case where the prediction state vector is |œÜ‚ü©= |0‚ü©, i.e. Œ± = 1 and Œ≤ = 0 in
equation (9.1). In this case, the alternative state vectors in equations (9.2) and (9.3)
are |œÜ0‚ü©= |C00‚ü©and |œÜ1‚ü©= |C01‚ü©. Therefore, the equilibrium state |E‚ü©is decided
in the reaction system of:
C00
k
‚áå
Àúk
C01,
(9.9)
and the value of Àúk
k indicates a degree of the worth of C00 relative to C01 for the
player. On the contrary, if |œÜ‚ü©= |1‚ü©, k and Àúk decide |E‚ü©in the comparison of:
C10
k
‚áå
Àúk
C11.
(9.10)
Here we denote k and Àúk of the above two comparisons with indices ki, Àúki (i = 1, 2).
In general, the alternative vectors are given by:
|œÜ0‚ü©= Œ± |C00‚ü©+ Œ≤ |C10‚ü©, |œÜ1‚ü©= Œ± |C01‚ü©+ Œ≤ |C11‚ü©.
In this quantum mechanical representation, besides the two comparisons of
(k1, Àúk1) and (k2, Àúk2), the player is allowed to make the following comparisons:
C00
k3
‚áå
Àúk3
C11 , C10
k4
‚áå
Àúk4
C01.
(9.11)
Generally, the rates of (k, Àúk) in equation (9.7) are decided by these (k1, Àúk1),
(k2, Àúk2), (k3, Àúk3), and (k4, Àúk4). If the four comparisons are made independently,
we can write the rates of k and Àúk of equation (9.7) as a classical expectation value
given by:
k = |Œ±|4k1 + |Œ≤|4k2 + |Œ±|2|Œ≤|2k3 + |Œ±|2|Œ≤|2k4,
Àúk = |Œ±|4 Àúk1 + |Œ≤|4 Àúk2 + |Œ±|2|Œ≤|2 Àúk3 + |Œ±|2|Œ≤|2 Àúk4.
(9.12)
However,
we
consider
that
the
four
comparisons
of
equations
(9.9),
(9.10), and (9.11) are not made probabilistically in such classical means. In the
mental state, these comparisons are made with the effect of inÔ¨Çuencing each other,

160
A quantum-like model of decision making
in a sense simultaneously. We give k and Àúk in the following forms:
k = |s|2, Àúk = |Àús|2 (s, Àús ‚ààC),
t = |Œ±|2k
1
2
1 + |Œ≤|2k
1
2
2 + Œ±‚àóŒ≤k
1
2
3 + Œ±Œ≤‚àók
1
2
4 ,
Àút = |Œ±|2 Àúk
1
2
1 + |Œ≤|2 Àúk
1
2
2 + Œ±Œ≤‚àóÀúk
1
2
3 + Œ±‚àóŒ≤ Àúk
1
2
4 .
(9.13)
The values of k and Àúk in this deÔ¨Ånition are different from that in the classical
form of equation (9.12). The differences come from the effect of quantum interfer-
ence. In our quantum mechanical model, those inÔ¨Çuences come from simultaneous
comparisons.
Here, we introduce a quantum channel ‚àómapping from the prediction state œÉ
to the mental state œÅE:
‚àó: S(H) ‚àí‚ÜíS(K),
‚àóœÉ = œÅE.
Since the comparison of consequences is made on a compound system in H ‚äóK,
the channel ‚àóis deÔ¨Åned with using a lifting E‚àó: S(H) ‚àí‚ÜíS(H ‚äóK). This lifting
is deÔ¨Åned by:
E‚àóœÉ =
T œÉ ‚äóœÅT ‚àó
tr(T œÉ ‚äóœÅT ‚àó),
where:
T =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éù
0
0
Àúk
1
2
1
Àúk
1
2
3
0
0
Àúk
1
2
4
Àúk
1
2
2
k
1
2
1
k
1
2
4
0
0
k
1
2
3
k
1
2
2
0
0
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚é†
.
(9.14)
In general, the state E‚àóœÉ is a quantum entangled state in H ‚äóK. Note that t and Àút
of equation (9.13) is rewritten as:
t = ‚ü®œÜ1| T |œÜ0‚ü©, Àút = ‚ü®œÜ0| T |œÜ1‚ü©,
(9.15)
and it is easily checked that the equilibrium state Œ∏E is described in the form of:
Œ∏E =
ME‚àóœÉM‚àó
tr(ME‚àóœÉM‚àó),
where M is a projection deÔ¨Åned by M = œÉ ‚äóI. From Œ∏E = œÉ ‚äóœÅE, we obtain:
‚àóœÉ = trH
	 ME‚àóœÉM‚àó
tr(ME‚àóœÉM‚àó)

.

9.5 Example: decision making in PD
161
9.4.3 Decision of action
After the comparison, the player decides his own action. We assume the decision
corresponds to a quantum measurement of the state |0B‚ü©‚ü®0B| or |1B‚ü©‚ü®1B| to the
mental state œÅE. Therefore, his decision is made probabilistically in general. The
probabilities of decisions 0 and 1 are given by:
ŒªE = tr(|0B‚ü©‚ü®0B| œÅE |0B‚ü©‚ü®0B|),
ŒºE = tr(|1B‚ü©‚ü®1B| œÅE |1B‚ü©‚ü®1B|).
(9.16)
9.5 Example: decision making in PD
In this section, we apply our model to the Prisoner‚Äôs Dilemma (PD) game. We
show the model makes irrational choices in this example.
In our model, the characteristics of the game are reÔ¨Çected in the contents of the
operator T of equation (9.14). In other words, the pay-offs of the game as seen
in the Table 9.1 can be factors which decide the values of ki and Àúki. We give the
operator T for the example of the PD game, in the following form:
T =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éù
0
0
0
Àúk
1
2
3
0
0
0
0
k
1
2
1
k
1
2
4
0
0
0
k
1
2
2
0
0
‚éû
‚éü‚éü‚éü‚éü‚éü‚é†
.
In this form, we assume k3 = 0 and Àúk1 = Àúk2 = Àúk4 = 0, because the pay-off d for the
consequence C10 is smaller than those of the other consequences and the pay-off
a for C00 is smaller than c for C01 but larger than d for C11. This setting of the
parameters provides the probability:
ŒªE =
|Œ±|2|Œ≤|2 Àúk3
|Œ±|2|Œ≤|2 Àúk3 +
|Œ±|2k
1
2
1 + |Œ≤|2k
1
2
2 + Œ±Œ≤‚àók
1
2
4

2 ,
ŒºE =
|Œ±|2k
1
2
1 + |Œ≤|2k
1
2
2 + Œ±Œ≤‚àók
1
2
4

2
|Œ±|2|Œ≤|2 Àúk3 +
|Œ±|2k
1
2
1 + |Œ≤|2k
1
2
2 + Œ±Œ≤‚àók
1
2
4

2 .
(9.17)
As mentioned in Section 9.2, a rational player always chooses his action 1, i.e.
ŒºE = 1. The player in our model becomes rational in two special cases; the case
of Àúk3 = 0 and the case of Œ± = 0 or Œ≤ = 0. Since the parameters of Œ± and Œ≤ decide
the player‚Äôs prediction for the other player‚Äôs choice, the case of Œ± = 0 or Œ≤ = 0

162
A quantum-like model of decision making
is unnatural to the principle of the game, which says that the player is uncertain
about the other player‚Äôs choice. It may correspond to a special situation where the
player obtains some information and can judge another player‚Äôs choice before his
own choice.
Appendix 1: Channels and liftings
In quantum information theory [2], a ‚Äúmap‚Äù is important for describing an infor-
mation transmission such as a measurement process or a signal transmission.
This map is called a channel ‚àó: S(A)  ‚ÜíS(B). Here S(A) (S(B)) are state
spaces of C‚àó-algebras A (B). For example, a set of all bounded linear operators
B(H) on Hilbert space H realizes a C‚àó-algebra A. If a channel ‚àóis afÔ¨Åne, i.e.
‚àó(
n ŒªnœÅn) = 
n Œªn‚àó(œÅn), ‚àÄœÅn ‚ààS(A), ‚àÄŒªn ‚àà[0, 1],  Œªn = 1, it is called a
linear channel. A completely positive (CP) channel is a linear channel ‚àósuch that
its dual  : B  ‚ÜíA (i.e. tr(‚àó(œÅ)A) = tr(œÅ(A)) for any A ‚ààA) satisÔ¨Åes:
n

i,j=1
A‚àó
i (B‚àó
i Bj)Aj ‚â•0,
for any {Aj} ‚äÇA, {Bj} ‚äÇB and n ‚ààN.
Liftings are a class of channels from S(A) to S(A ‚äóB):
E‚àó: S(A)  ‚ÜíS(A ‚äóB).
(9.18)
The following liftings are often used in physics:
1. Linear lifting: A linear lifting is afÔ¨Åne and its dual is a completely positive
map.
2. Pure lifting: A pure lifting maps pure states into pure states.
3. Non-demolition lifting: A lifting is a non-demolition lifting for a state œÅ ‚ààS(A)
if œÅ is invariant for any A ‚ààA in the sense of:
(E‚àóœÅ)(A ‚äó1) = œÅ(A).
Here, œÅ(A) ‚â°tr(œÅA), A ‚ààA.
4. Compound state lifting: A compound state lifting is a non-linear and non-
demolition lifting such that for a density matrix œÅ = 
k ŒªkEk, Ek ‚ààS(A):
E‚àó(œÅ) =

k
ŒªkEk ‚äó‚àóEk.
5. Transition lifting: A transition expectation is a completely positive linear map
given by E : A ‚äóB  ‚ÜíA, and it satisÔ¨Åes:
E(1 ‚äó1) = 1.

Appendix 2: Quantum Markov chain description
163
Transition expectations play a crucial role in the construction of quantum
Markov chains and they appear in the framework of measurement theory. The
dual of a transition expectation is an example of a lifting.
6. Isometric lifting: A lifting is a channel from a subsystem to a compound
system, and it is useful for describing open system dynamics. Let us consider
the following situation. A system interacts with another (environment) system,
and a correlated state is generated in a compound system. We assume that the
system is independent from another system before the interaction and initial
states of the two systems are given by œÅ ‚ààS(A) and œÉ ‚ààS(B). The compound
system after the interaction is represented by E‚àóœÅ ‚ààS(A ‚äóB) in general. Now
let the lifting E‚àóbe an isometric lifting deÔ¨Åned as:
E‚àóœÅ = VœÅV ‚àó,
where the operator V : HA  ‚ÜíHA ‚äóHB satisÔ¨Åes V ‚àóV = 1HA. Then for an
observable B ‚ààB(B), the expectation value trAE‚àóœÅ(B) is written as:
trAE‚àóœÅ(B) = trA(œÅV ‚àó(1 ‚äóB)V ) = trA(œÅE(1 ‚äóB)) = œÅ(E(1 ‚äóB)).
Here, we introduce the map E(1 ‚äóB) = V ‚àó(1 ‚äóB)V . This map is a transition
expectation and its dual is the isometric E‚àó. We can easily check trAE‚àóœÅ(I) = 1.
When the E‚àórepresents a time evolution; E‚àóœÅ = UœÅ ‚äóœÉU ‚àó(U is a unitary
operator), the corresponding transition expectation is written by:
E(1 ‚äóB) = trB(U(1 ‚äóœÉ)U ‚àó(1 ‚äóB)).
If B is written as B = 
k ŒªkPk with projections {Pk}:
trAE‚àóœÅ(B) =

k
ŒªktrAE‚àóœÅ(Pk) =

k
ŒªkœÅ(E(1 ‚äóPk)) ‚â°

k
Œªk‚àó
kœÅ(Pk).
In this form, values of ‚àó
kœÅ(Pk) mean probabilities p(Œªk), and E(1 ‚äóPk)
mean a POVM (a positive operator valued measure) Qk that satisÔ¨Åes Qk ‚â•0,

k Qk = I.
Appendix 2: Quantum Markov chain description of data from experiments
in cognitive psychology
In this section we construct a quantum-like representation of the experimental
statistical data from the Tversky‚ÄìShaÔ¨År PD experiment, please see Section 8.9
of Chapter 8. In this appendix we reproduce (pp. 378‚Äì383)4 (with only slight
4 Luigi Accardi and Andrei Khrennikov and Masaniori Ohya (2009). Quantum Markov model for data from
ShaÔ¨År-Tversky experiments in cognitive psychology. Open Systems & Information Dynamics, 16(4), 378‚Äì383.

164
A quantum-like model of decision making
modiÔ¨Åcations) the paper by Accardi et al. [3]. To describe these data, we have to use
a more general quantum probabilistic model than the standard Dirac‚Äìvon Neumann
model based on Hermitian operators in a complex Hilbert space and the deÔ¨Ånition of
probabilities through projections of eigenvalues of operators (Born‚Äôs rule). We want
to emphasize that the aforementioned data have such a complex internal structure
that it is impossible to Ô¨Ånd two Hermitian operators with non-degenerate spectra
which act in the Hilbert space of the dimension matching the dimension of the
game, namely the two-dimensional space. This is a consequence of a simple fact:
the matrix of transition probabilities is not double stochastic. We shall use so-called
quantum Markov chains, a non-commutative generalization of ordinary Markov
chains. Please see Accardi et al. [3].
This section is based on advanced mathematics. Therefore, this section is not rec-
ommended for readers who have no experience of research in quantum probability
and quantum information theory. Experts from psychology, behavioral economics,
Ô¨Ånance, and decision making can learn that statistical data from games exhibit-
ing irrational behavior can have a very complex non-commutative structure, more
complex than the structure of statistical data from basic experiments on quantum
foundations, e.g. the two slit experiment.
The quantum Markov model presented in this section was created by Accardi
et al. [3].
Given a classical Markov transition matrix (pij) with state space {1, . . . , d}
(d ‚ààN), a natural way to associate to it a conditional density amplitude is to
deÔ¨Åne:
K =

i,j
‚àöpijeii ‚äóejj ‚ààMd ‚äóMd,
where Md denotes the d √ó d complex matrices, (ei) an orthonormal basis of Cd,
(eij) the associated system of matrix units (eijehk = Œ¥j,heik), and ‚àöpij are arbi-
trary (usually complex) square roots of pij. Any conditional density amplitude
determines a (special) linear lifting (see Appendix 1):
E‚àó: S(Md) ‚ÜíS(Md ‚äóMd)
from density matrices on Md to density matrices on Md ‚äóMd or, dually, a transition
expectation, i.e. a completely positive, identity preserving linear map:
E : Md ‚ÜíMd ‚äóMd
deÔ¨Åned by:
E(x) = Tr2(K‚àóxK),
x ‚ààMd ‚äóMd,
(9.19)
where Tr2 denotes the partial trace over the second factor (Tr2(a ‚äób) := Tr(b)a ‚àà
Md) and Tr denotes the non-normalized trace on Md. More explicitly, if X, Y ‚ààMd,

Appendix 2: Quantum Markov chain description
165
one has:
E(X ‚äóY) = Tr2(K‚àó(X ‚äóY)K) =

i,j

h,k
‚àöpij
‚àó‚àöphkTr(eijXehk ‚äóejiYekk)
=

i,j

h,k
‚àöpij
‚àó‚àöphkeiiXehkŒ¥jkTr(Yejj);
therefore, using the identities:
ejjYejj = ‚ü®ej, Yej‚ü©ejj,
eiieŒ±Œ≤ehh = Œ¥ixŒ¥Œ≤heih,
eiiXehh = ‚ü®ei, Xeh‚ü©eih,
one obtains:
E(X ‚äóY) =

i,j,h
‚àöpij
‚àó‚àöphj‚ü®ei, Xeh‚ü©eih‚ü®ej, Yej‚ü©.
(9.20)
Notice that, if X, Y ‚ààMd are diagonal in the (ei)-basis, then this formula reduces
to the usual formula for the conditional expectation in classical probability:
E(X ‚äóY) =

i,j
pijXiieiiYjj =

i
‚éõ
‚éùXii

j
pijYjj
‚éû
‚é†eii = XP(Y).
Given any density matrix in Md:
œÅ0 =

Œ±‚Ä≤,Œ≥ ‚Ä≤
œÅŒ±‚Ä≤,Œ≥ ‚Ä≤eŒ±‚Ä≤,Œ≥ ‚Ä≤,
the pair {œÅ0, E} uniquely determines the joint n-point correlations:
œï (a0 ‚äóa1 ‚äó. . . an) := Tr (œÅ0E(a0 ‚äóE(a1 ‚äóE(a2 ‚äó. . . E(an ‚äó1) . . . )) ,
where a0, a1, a2, . . . , an ‚ààMd. We are interested in a time horizon with two time
points: initial and Ô¨Ånal. The corresponding joint probabilities are in this case:
TrœÅ0E(a ‚äóE(b ‚äó1)).
Using (9.20), we obtain:
E(b ‚äó1) =

i,j,h
‚àöpij
‚àó‚àöphj.‚ü®ei, beh‚ü©eih.

166
A quantum-like model of decision making
Therefore:
E(a‚äóE(b‚äó1)) =

i,j,h
‚àöpij
‚àó‚àöphj‚ü®ei, beh‚ü©E(a ‚äóeih)
=

i,j,h
‚àöpij
‚àó‚àöphj‚ü®ei, beh‚ü©

Œ±,Œ≤,Œ≥
‚àöpŒ±Œ≤
‚àó‚àöpŒ≥Œ≤‚ü®eŒ±, aeŒ≥ ‚ü©eŒ±Œ≥ ‚ü®eŒ≤, eiheŒ≤‚ü©
=

i,j,Œ±,Œ≥
‚àöpij
‚àó‚àöpij‚ü®ei, bei‚ü©‚ü®eŒ±, aeŒ≥ ‚ü©eŒ±Œ≥
‚àöpŒ±i
‚àó‚àöpŒ≥ i.
By using the right stochasticity of the matrix of transition probabilities, 
j pij = 1
(here pij = P(b = j|a = i)), we obtain:
TrœÅ0E(a ‚äóE(b ‚äó1)) =

i,Œ±,Œ≥,Œ±‚Ä≤,Œ≥ ‚Ä≤
‚ü®ei, bej‚ü©‚ü®eŒ±, aeŒ≥ ‚ü©‚àöpŒ±i
‚àó‚àöpŒ≥ iœÅŒ±‚Ä≤Œ≥ ‚Ä≤TreŒ±‚Ä≤Œ≥ ‚Ä≤eŒ±Œ≥
and, using the identity:
TreŒ±‚Ä≤Œ≥ ‚Ä≤eŒ±Œ≥ = Œ¥Œ≥ ‚Ä≤Œ±Œ¥Œ±‚Ä≤Œ≥
and the notations:
‚ü®ei, bei‚ü©=: bii, ‚ü®eŒ±, aeŒ≥ ‚ü©=: aŒ±Œ≥
one Ô¨Ånally obtains:
TrœÅ0E(a ‚äóE(b ‚äó1)) =

i,Œ±,Œ≥
‚ü®ei, bei‚ü©‚ü®eŒ±, aeŒ≥ ‚ü©‚àöpŒ±i
‚àó‚àöpŒ≥ iœÅŒ≥ Œ±
=

i,Œ±Œ≥
biiaŒ±Œ≥
‚àöpŒ±i
‚àó‚àöpŒ≥ iœÅŒ≥ Œ±
=

Œ±,Œ≥
œÅŒ≥ Œ±aŒ±Œ≥
/
i
bii
‚àöpŒ±i
‚àó‚àöpŒ±i
0
=

Œ±,Œ≥
œÅŒ±Œ≥ aŒ±Œ≥ L(b)Œ±Œ≥ .
If the observables a, b have the form:
a = |+a‚ü©‚ü®+a| ‚àí|‚àía‚ü©‚ü®‚àía, |b = |+b‚ü©‚ü®+b| ‚àí|‚àíb‚ü©‚ü®‚àíb|,
the marginal probabilities for a are obtained by putting b = +1, i.e.:
Tr (œÅ0E(|+a‚ü©‚ü®+a| ‚äó1)) =

i,j,h
‚àöpij
‚àó‚àöphj‚ü®ei, +a‚ü©‚ü®+a, eh‚ü©œÅhi
=

h,i
œÅhi‚ü®ei, +a‚ü©‚ü®+a, eh‚ü©

j
‚àöpij
‚àó‚àöphj,

Appendix 2: Quantum Markov chain description
167
where we used the identity:
TrœÅeih =

Œ±,Œ≥
œÅŒ±,Œ≥ TreŒ±Œ≥ eih =

Œ±,Œ≥
œÅŒ±Œ≥ Œ¥Œ±iŒ¥Œ±h = œÅhi.
Now we specialize to the case d = 2, so that œÅ0 has the form:
œÅ11 = p, œÅ22 = 1 ‚àíp, œÅ12 = œÅ21 = z,
for some p ‚àà[0, 1] and z ‚ààC. This gives the equation:
p|‚ü®e1, +a‚ü©|2 + (1 ‚àíp)|‚ü®e2, +a‚ü©|2 + 4Re (z‚ü®e1, +a‚ü©‚ü®+a, e2‚ü©) Re
‚àöp12
‚àó‚àöp21

= P(a = +1|C).
A similar calculation for the marginal probabilities for b gives the equation:
TrœÅ0E(1 ‚äóE(|+b‚ü©‚ü®+b|)) =

Œ±
œÅŒ±Œ±

i
|‚ü®a1, ei‚ü©|2pŒ±i = P(b = +1|C).
Expanding the eigenvectors of b and a in the e-basis, we obtain, for some pa, pb ‚àà
[0, 1]:

i
pp1i|‚ü®+b, ei‚ü©|2 +

i
(1 ‚àíp)p2i|‚ü®+b, ei‚ü©|2 = P(b = +1 = |C)
|+a‚ü©=: ‚àöpae1 +
"
1 ‚àípae2,
|+b‚ü©=: ‚àöpbe1 +
"
1 ‚àípbe2,
and therefore the above equations become:
ppa + (1 ‚àíp)(1 ‚àípa) + 4Re

z‚àöpa
"
1 ‚àípa
‚àó
Re
‚àöp12
‚àó‚àöp12

= P (a = +1|C),
pp11pb + pp12(1 ‚àípb) + (1 ‚àíp)p12pb + (1 ‚àíp)p22(1 ‚àípb)
= P (b = +1|C).
Looking for a solution with z = 0 leads to the simpliÔ¨Åed system:
ppa ‚àí(1 ‚àíp)pa + (1 ‚àíp) = (2p ‚àí1)pa + (1 ‚àíp) = P(a = +1|C),
p(p11 ‚àíp12)pb + pp12 + (1 ‚àíp)pb(p12 ‚àíp22) + (1 ‚àíp)p22 = P(b = +1|C).
Recalling that the empirical values, found by Tversky and ShaÔ¨År for the PD-type
experiment (please see Section 8.9 in Chapter 8), are:
P(a = +1|C) = 1
2, P (b = +1|C) = 0.63,

168
A quantum-like model of decision making
the Ô¨Årst equation becomes equivalent to:
(2p ‚àí1)pa + (1 ‚àíp) = 1
2,
which gives, independently of p:
pa =
	
p ‚àí1
2

1
2p ‚àí1 = 1
2.
This result is not really surprising, since here the A-player is a computer which
produces wins and losses with equal probabilities. It is natural for the B-player
(who is really a player) to simply incorporate these probabilities in the quantum-
like representation of the A-strategy. This representation is given by vectors |¬±a‚ü©.
Thus, the simplest representation:
|+a‚ü©= (e1 + e2)/
‚àö
2,
the second vector can be chosen as any normalized vector which is orthogonal
to:
|‚àía‚ü©= (e1 ‚àíe2)/
‚àö
2.
Of course, mathematically the situation is essentially more general. The vector
representation of the state of A can involve complex phases:
|+a‚ü©= (e1 + eiŒ∏Ae2)/
‚àö
2, |‚àía‚ü©= (e1 ‚àíeiŒ∏Ae2)/
‚àö
2.
In a more complicated gamble, such that the A player is not a computer, the B player
may really use the additional degree of freedom, namely the phase to represent the
A-strategy. However, in the present gambling experiment it seems that B can be
Ô¨Åne with purely real eigenvectors.
The second equation becomes equivalent to:
pb(p(p11 ‚àíp12) + (1 ‚àíp)(p21 ‚àíp22)) + pp12 + (1 ‚àíp)p22 = 0.63
‚áîpb(p(0.16 ‚àí0.84) + (1 ‚àíp)(0.03 ‚àí0.97)) +p0.84 + (1 ‚àíp)0.97=0.63
‚áî‚àípbp0.68 ‚àípb(1 ‚àíp)0.94 + p0.84 + (1 ‚àíp)0.97 = 0.63
‚áîp(0.84 ‚àípb0.68) + (1 ‚àíp)(0.97 ‚àípb0.94) = 0.63
‚áîp = 0.63 ‚àí(0.97 ‚àípb0.94)
0.84 ‚àípb0.68
.

Appendix 2: Quantum Markov chain description
169
Thus any pb ‚àà(0.1) such that:
0 < 0.63 ‚àí(0.97 ‚àípb0.94)
0.84 ‚àípb0.68
< 1
will give a unique p.
The two inequalities are equivalent to:
0 < 0.63 ‚àí0.97 + pb0.94
0.63 ‚àí0.97 + pb0.94 < 0.84 ‚àípb0.68.
The Ô¨Årst is equivalent to:
0.34 < pb0.94 ‚áî34
94 < pb.
The second is equivalent to:
pb(0.94 + 0.68) < 0.84 + 0.34 ‚áîpA1.62 < 1.28 ‚áîpb < 118
162.
Since:
34
94 ‚âà0.36 < 118
162 ‚âà0.73
any pb in the (non-empty) interval [ 34
94, 118
162] will give a solution.
If pb = 34
94, then p = 0. Thus, in the density matrix œÅ11 = 0 and œÅ22 = 1, non-
diagonal elements are equal to zero. The pure state œÅ = e2 ‚äóe2 is a ‚Äúpure state of
mind.‚Äù In the same way, in the case pb = 118
162 we get œÅ = e1 ‚äóe1. We point out the
crucial difference of the quantum Markov model from the conventional Dirac‚Äìvon
Neumann model based on Born‚Äôs rule, where:
P(b = +1|C) = PœÅ(b = +1) = TrœÅ(|+b‚ü©‚ü®+b|)
and:
P(a = +1|C) = PœÅ(a = +1) = TrœÅ(|+a‚ü©‚ü®+a|).
In the brain of the B-player, vectors |+a‚ü©and |+b‚ü©are created. One can
speculate that they provide a kind of ‚Äúinternal mental representation‚Äù of the
context C. However, this internal representation does not determine completely
the real probabilities of answers. The latter arise in the process of interaction of
the internal mental representation with previous experience, which is encoded in
probabilities pij, and, Ô¨Ånally, in the lifting operator E‚àó, which is determined by
the operator K. Of course, it is just a Ô¨Årst reÔ¨Çection to interpret moving from the
conventional quantum model to the quantum Markov model: interference of the
internal mental representation of context C with representations of contexts corre-
sponding to Ô¨Åxed strategies, say Cb
¬± = (b = ¬±1) and Ca
¬± = (a = ¬±1). The latter

170
A quantum-like model of decision making
strategies are based on previous experience. We hope that psychologists may sug-
gest more justiÔ¨Åed motivations of the shift from the conventional quantum model to
the quantum Markov model. We would not be surprised if possible psychological
interpretations would be different from our interpretation.
9.6 References
[1] Asano, M., Ohya, M., and Khrennikov, A. (2011). Quantum-like model for decision
making process in two players game. Foundations of Physics, 41, 3, 538‚Äì548.
[2] Ingarden, R. S., Kossakowski, A., and Ohya, M. (1997). Information Dynamics and
Open Systems: Classical and Quantum Approach. Kluwer, Dordrecht, Holland.
[3] Accardi, L., Khrennikov, A., and Ohya, M. (2009). Quantum Markov model for data
from ShaÔ¨År-Tversky experiments in cognitive psychology. Open Systems and Infor-
mation Dynamics, 16, 371‚Äì385.

Part IV
Other quantum probabilistic effects in economics,
Ô¨Ånance, and brain sciences


10
Financial/economic theory in crisis
In this chapter and Chapters 11, 12, and 13, we will discuss quantum-like models
with Ô¨Ånancial applications in mind. The very last chapter of this book will analyze
the sources of quantum-like processing in the brain.
The concept of non-arbitrage, as we have indicated before (see Section 4.18.3) is
of key importance in Ô¨Ånancial models. We reiterate its importance in this chapter.
We also brieÔ¨Çy mention a popular Ô¨Ånance model. In the coming chapters, the
wave function will sometimes have an information interpretation. Therefore we
also discuss the informational aspects of the classical Ô¨Ånancial theory (see Section
10.1). This chapter is meant to introduce the reader to some of the key achievements
in Ô¨Ånancial theory. By doing so, we hope to convince the reader, in later chapters,
that some of those very achievements can possibly be reformulated with the help
of the wave function approach. Section 10.3 in this chapter will give a Ô¨Çavor of
how Fourier integration can possibly be used to model George Soros‚Äô concept of
reÔ¨Çexivity.
10.1 Relevance of the concepts of efÔ¨Åciency and non-arbitrage:
a brief discussion
With the 2008 Ô¨Ånancial crisis, the concept of efÔ¨Åciency may have been seriously
questioned. Indeed the Ô¨Ånancial market in September 2008 did take a tremendous
hit and the ensuing price movements would not be consistent with a so-called
efÔ¨Åcient market.
For now, let us concentrate on what is efÔ¨Åciency. Ma [1] (p. 4) deÔ¨Ånes efÔ¨Åcient
portfolios as: ‚Äúportfolios that are efÔ¨Åcient in the sense that no other portfolios are
available to reduce further the portfolio risk.‚Äù Here is an interesting corollary out
of Ma [1] (Corollary 1.3 (p. 41)): ‚ÄúSuppose the market is efÔ¨Åcient with respect to
F. For all G ‚äÜF and for any arbitrary trading strategies œÜ based on information
structure G, the value of the investment must coincide with the market price of
173

174
Financial/economic theory in crisis
the trading strategy.‚Äù This is an important statement. The set of information G is
a subset of the set of information F. This means that G contains less information
than F.
As Ma [1] (Chapter 1)) indicates, the efÔ¨Åciency deÔ¨Ånitions are due originally
to Fama [2]. Any textbook in basic Ô¨Ånance, will deÔ¨Åne the following types of
efÔ¨Åciency:
r strong form efÔ¨Åciency: prices reÔ¨Çect all available information;
r semi-strong form efÔ¨Åciency: prices reÔ¨Çect all publicly available information;
r weak form efÔ¨Åciency: prices reÔ¨Çect all historic prices of the traded securities.
Strong form efÔ¨Åciency is elegantly formulated in Ma [1] (p. 52) as follows:
‚ÄúIn particular, no individual investor can make excess returns with his possessed
information set Fi that is no more informative than the pooling information
set ‚à©i‚ààIFi.‚Äù
At this point, we would like to make two possibly important points. In what
follows, we would like to discuss (a) information manipulation, and (b) give an
example of where private information may not give any proÔ¨Åt advantage.
Let us tackle (a). Ma [1] (p. 43)) indicates that the manipulation of infor-
mation can take on the forms of, what he calls: (i) ‚Äúinformation leakage‚Äù and
(ii) ‚Äúuncertainty creation.‚Äù These are two very interesting notions which do emu-
late very much realistic behavior. Ma [1] (p. 43) deÔ¨Ånes information leakage as:
‚Äúsituations where agents wish to reveal truthfully their private possessed infor-
mation to others.‚Äù Uncertainty creation is then deÔ¨Åned as per Ma [1] (p. 43) as
agents wishing to create ‚Äúuncertainty in the rest of the economy.‚Äù The latter type
of information creation is straightforward: create information which is dubious (or
even false) so it can serve your investment strategy.
Now let us tackle (b). We reproduce1 here Haven‚Äôs [3] section 12 of that paper.
In Tirole [4] a market is considered with I (i = 1, . . . , I) risk averse or risk neutral
traders. The traders exchange an asset on a price p and the (random) value of that
asset is p. The trader buys x units of the asset and if p is revealed, his gain will be
given by:
Gi = (p ‚àíp)xi.
(10.1)
A set E ‚äÇR is then deÔ¨Åned containing all the potential values of p. Each trader has
a private signal si, which belongs to the set of signals Si. The cross product of all
1 Emmanuel Haven (2007). Private information and the ‚Äúinformation function.‚Äù Theory and Decision, 64, 2‚Äì3,
2008, pp. 200‚Äì201.
2 This is the section ‚ÄúPrivate information and the information function‚Äù with as subsection ‚ÄúPrivate information
as deÔ¨Åned by Tirole.‚Äù

10.1 Concepts of efÔ¨Åciency and non-arbitrage
175
those sets Si forms a set S. The vector of all signals is denoted by s = (. . . , si, . . .).
The set  is then deÔ¨Åned as:  ‚â°E √ó S. It is then assumed that the traders have
a common prior ŒΩ on . Each trader is assumed to take out a quantity xi so as
to maximize his conditional expected gain. The rational expectations equilibrium
is deÔ¨Åned to be a forecast function , which in the words of Tirole [4] (p. 1166)
‚Äúassociates with each set of signals s a price p = (s) and the set of trades
xi(p, si, S(p)) for each agent i, relative to information si and s ‚ààS(p) ‚â°‚àí1(p),
such that xi(p, si, S(p))‚Äù will maximize the expected conditional gain, which we
denote as in the excellent paper by Scheinkman and Xiong [5], as:
E(Gi|p, si) ‚â°

Gdi
,p,si,
(10.2)
where .
. is a conditional distribution. The conditional distribution is induced by the
forecast function, the observed price and the signal si. This explains the notation
Scheinkman and Xiong [5] use on this conditional distribution. Furthermore, the
market will clear for each s ‚ààS. The no-trade theorem then says that in a rational
expectations equilibrium (see Scheinkman and Xiong [5], p. 227): E(Gi|p, si) =
0. This will thus be true if all agents are rational and have the same prior ŒΩ. Thus
private information has no impact whatsoever on the conditional expected gains
if the agents are behaving under the conditions of what Scheinkman and Xiong
[5] call the standard rational expectations model. Thus, when those conditions are
violated the conditional expected gain could be non-negative.
This section of the book also has as goal to re-iterate the concept of non-arbitrage.
In Chapter 4, Section 4.18.3 we provided for a formulation of the non-arbitrage
theorem following Etheridge [6]. It is not difÔ¨Åcult to show that if one of the prices
in the price vector (at time3 t = 0) is set to unity, and the security prices of that
one asset under the various states of nature (at time t = 1) are set equal to unity
with the addition of a return equal to the risk free rate of interest, then one can
deÔ¨Åne a set of probabilities (risk neutral probabilities) by which we can discount a
risky asset at the risk free rate. Neftci [7] shows this very nicely in his book (see
pp. 19‚Äì20). This is a very useful result in Ô¨Ånance, since risky assets would require
the use of preferences for risk which are notoriously difÔ¨Åcult to estimate.4 The
use of the risk free rate does not ask for such preferences, and, in effect, there is
wide agreement by market participants on the level of a risk free rate of interest
in an economy (for instance it could be the prime rate set by the central bank of a
country). As long as we do not worry about the meaning of the probability, then
such discounting is warranted.
3 When we formulated the non-arbitrage theorem in Chapter 4, Section 4.18.3, we denoted t = 0, as t0 and t = 1,
as t1.
4 But see below for our brief discussion of the CAPM model.

176
Financial/economic theory in crisis
Beginning undergraduate students studying for Ô¨Ånance degrees will all know
about the so-called ‚ÄúCAPM‚Äù model, or also the ‚ÄúCapital Asset Pricing Model,‚Äù
which in effect does give an estimate of the return of an asset (whether risky or
risk free). Following Luenberger [8] (p. 173), this model was developed mainly by
Sharpe [9], Lintner [10], and Mossin [11]. The CAPM model has been extended in
many ways.
The model is in fact quite easy to grasp. One needs essentially two main ingre-
dients: (i) the so-called Œ≤ of an asset and (ii) the concept of a market portfolio. The
market portfolio can be thought of as proxied by for instance an index portfolio
such as the Dow Jones 30. One can deÔ¨Åne the so-called Beta for a security i, Œ≤i,
as Œ≤i = cov(ri,rm)
œÉ 2m
, where ri is the return of asset i and rm is the return of the market
portfolio and cov(ri, rm) is the covariance of the return of asset i and the return of
the market portfolio m. The variance of the return of the market portfolio is denoted
as œÉ 2
m. If asset i is the risk free asset (with return the risk free rate of return, rf ), then
cov(rf , rm) = 0 and therefore Œ≤f = cov(rf ,rm)
œÉ 2m
= 0. Remark that if i is the market
portfolio (with return rm), then cov(rm, rm) = œÉ 2
m and hence Œ≤m = œÉ 2
m
œÉ 2m = 1. In a non-
expected form, the so-called CAPM can be written as ri = rf + Œ≤i(rm ‚àírf ) + œµi,
where œµi is the error term.
The CAPM can also be written as a pricing formula. As per Luenberger [8]
(p. 187), one obtains then P =
E(Q)
rf +Œ≤i(E(rm)‚àírf )+1, where P is the price (now) of an
asset with expected selling price Q. The appropriate discount rate is thus rf +
Œ≤i(E(rm) ‚àírf ).
10.2 References
[1] Ma, C. (2010). Advanced Asset Pricing Theory. Imperial College Press.
[2] Fama, E. (1970). EfÔ¨Åcient capital markets: a review of theory and empirical work.
Journal of Finance, 25, 2, 383‚Äì417.
[3] Haven, E. (2008). Private information and the ‚Äúinformation function.‚Äù Theory and
Decision, 64, 2‚Äì3, 193‚Äì228.
[4] Tirole, J. (1982). On the possibility of speculation under rational expectations. Econo-
metrica, 50, 1163‚Äì1181.
[5] Scheinkman, J. and Xiong, W. (2004). Heterogeneous Beliefs, Speculation and Trad-
ing in Financial Markets. Paris‚ÄìPrinceton Lectures on Mathematical Finance. Lec-
ture Notes in Mathematics 1847, Springer Verlag, Berlin.
[6] Etheridge, A. (2002). A Course in Financial Calculus. Cambridge University Press.
[7] Neftci, S. (2000). An Introduction to the Mathematics of Financial Derivatives.
Academic Press.
[8] Luenberger, D. (1998). Investment Science. Oxford University Press.
[9] Sharpe, W. (1964). Capital asset prices: a theory of market equilibrium under condi-
tions of risk. Journal of Finance, 19, 425‚Äì442.

10.3 George Soros‚Äô interpretation of the crisis
177
[10] Lintner, J. (1965). The valuation of risk assets and the selection of risky investment
in stock portfolios and capital budgets. Review of Economics and Statistics, 47,
13‚Äì37.
[11] Mossin, J. (1966). Equilibrium in a capital asset market. Econometrica, 34, 4,
768‚Äì783.
10.3 George Soros‚Äô interpretation of the crisis and the use of classical
quantum physics in Ô¨Ånance
Any beginning undergraduate student in economics will know about one of the
basic principles of economics, the so-called ‚Äúinvisible hand.‚Äù The principle is
deceptively simple and roughly says that each economic agent, even though he
or she acts in his or her own self-interest, will, in so doing, also help the other.
Paul Samuelson, the Nobel prize winner in economics mentions in his well-known
textbook (with Nordhaus) [1] that the ‚Äúinvisible hand‚Äù is a doctrine. As Samuelson
notes in this book, the ‚Äúinvisible hand‚Äù is a concept which can be sourced back
from Adam Smith‚Äôs [2] The Wealth of Nations. Quoting Samuelson [1] (p. 46), ‚Äúthe
invisible hand doctrine is a concept for explaining why the outcome of a market
mechanism looks so orderly . . . We know that the market sometimes lets us down,
that there are ‚Äòmarket failures‚Äô.‚Äù Samuelson mentions that externalities are one case
of such a market failure.
Nozick [3] remarks, the ‚Äúinvisible hand‚Äù approach can be explained via the
theory of rational choice behavior amongst agents and he also indicates that this
does not necessarily imply that one needs to invoke the principle of expected utility
maximization. Nozick refers to his book [4], where variants of expected utility are
used instead.
The economic literature has provided interesting explanations of the workings
of the invisible hand. One quite condensed way of explaining its mechanics, in an
albeit quite abstract setting, is by Schelling [5]. We do not expand on it here. We
note that, already in 1978, it was remarked by Ullmann-Margalit [6] (p. 278) that
the invisible hand approach could be viewed as ‚Äúthe counterpart, within the social
domain, of the biological-evolutionary explanations within the domain of living
organisms.‚Äù
From an econophysics (statistical mechanics) point of view, the ‚Äúinvisible hand‚Äù
could be seen as a ‚Äúdevice‚Äù by which a complex system can be stabilized to an
equilibrium state. However, we must emphasize that one needs to be very careful
with the extension of physics-based theories to social systems.
It could be claimed that in the command economies of the past, the rational
choice of individuals was assumed by the state. In effect, command economies
‚Äúmodeled‚Äù an aggregate version of the rational choice of individuals, while in free

178
Financial/economic theory in crisis
market economies the rational choice was squarely lying at the individual level. The
‚Äúinvisible hand‚Äù really operates at an individual level rather than at an aggregate
level. Clearly, the debate on the (optimal) weight of state regulation in economic
activity is an interminable one, and this book has no pretence at all to be a forum
for such a discussion.
A question however, which now has come to the foreground, is whether the
absence (or presence) of Ô¨Ånancial regulation could not in fact (in part) explain
the events of the 2008 Ô¨Ånancial crisis. If we interpret this crisis as having been
caused by the emergence of a degree of ignorance about how to price speciÔ¨Åc
Ô¨Ånancial assets, then we may want to indeed connect the doctrine of the invisible
hand to that crisis. One could for instance argue that the idea of efÔ¨Åciency, which
we covered in Section 10.1 of this chapter, is connected to the invisible hand.
In effect, assume very little relevant information is incorporated in prices. The
very presence of ‚Äúprice-less assets‚Äù would disallow the proper functioning of the
rational choice of individuals. After all, how could one exercise a rational choice
on goods, when their prices would not be reÔ¨Çective of the worth of those goods?
As a consequence, we would observe very random price behavior and decision
making. In effect, no economic decision maker would be able to decide whether to
(rationally) buy or sell. Such an economic state of affairs would indeed invalidate
the proper functioning of the invisible hand principle altogether. We remark that the
2008 crisis did exhibit instances where assets seemed to be very much mispriced
in some cases, merely because of the consequence of the absence of knowledge on
how to price the asset in the Ô¨Årst place. We may wonder whether it was precisely
the absence of state intervention which made the existence of such ‚Äúprice-less‚Äù
assets possible.
As one can appreciate, such a very difÔ¨Åcult problem cannot be solved in the
space of a book (and certainly not this one!). The interested reader may want to
visit the editorials by the Nobel prize winner (economics), Paul Krugman in the
New York Times to get an idea of how difÔ¨Åcult the debate is on arguing the pros and
cons of state intervention in an economy (in this case the US economy), which to
some extent seems to be at a critical cross-road of its existence.
In social systems, as any economist well knows, it is impossible to perform a
pure experimental test (such as in physics) by selecting a speciÔ¨Åc experimental
context. The absence of such a setting does indeed make it extremely difÔ¨Åcult to
ascertain the degree of potency of having the ‚Äúinvisible hand‚Äù function in a society
with for instance a mildly interventionist government.
One could argue that the focus needed for the ‚Äúmanaging‚Äù of the ‚Äúinvisible
hand‚Äù principle in a Ô¨Ånancial context is in effect very different from when the same
principle is to be looked after in, say, an industrial production setting. Clearly, the
theory of industrial organization (for instance see the work of Jean Tirole [7]),

10.3 George Soros‚Äô interpretation of the crisis
179
which devotes a lot of intellectual effort to modeling the economics of industrial
production and organization, is different in its mathematical expression, from a
theory of Ô¨Ånancial management, which can account for, say, extreme events. The
stress would need to be put on the word ‚Äúextreme.‚Äù The attacks against Ô¨Ånan-
cial models are very often oblivious about mentioning this important qualiÔ¨Åer. It
needs to be emphasized that a branch of applied probability has developed very
sophisticated models on how to measure extreme events. Whether those models
have been sufÔ¨Åciently incorporated into Ô¨Ånancial models remains to some degree
an open question. However, to claim that no such theories exist (mathematical or
Ô¨Ånancial mathematical) is an incorrect statement. Please see, for instance, the work
by Embrechts [8] and Delbaen [9].
George Soros, the multi-billionaire investor, has for many years proposed an
alternative theory to efÔ¨Åciency. The key concept which emerges from Soros‚Äôs theory
is the principle of ‚ÄúreÔ¨Çexivity.‚Äù See for instance [10]. The connection between
reÔ¨Çexivity and the wave function has been discussed in Khrennikov [11] [12] [13]
and Choustova [14] [15] [16].
Soros [17] argues that, in his theory of reÔ¨Çexivity, the economic agent‚Äôs thinking,
has two functions: (i) ‚Äúto understand reality, that is the cognitive function‚Äù and (ii)
‚Äúto make an impact on the situation . . . (the) manipulative, function.‚Äù Clearly, the
second role, we believe, has already been alluded to when we discussed efÔ¨Åciency
in Section 10.1 of this chapter. Recall the idea of so-called ‚Äúinformation manip-
ulation‚Äù we discussed above. We mentioned that such manipulation can take on
the form of information leakage and (ii) uncertainty creation. We recall that Ma
[18] (p. 43) deÔ¨Ånes information leakage as: ‚Äúsituations where agents wish to reveal
truthfully their private possessed information to . . . others.‚Äù Uncertainty creation is
then deÔ¨Åned as per Ma [18] (p. 43) as agents wishing to create ‚Äúuncertainty in the
rest of the economy.‚Äù
Soros [17] proposes that if both the cognitive function (understanding the mar-
ket) and the manipulative function ‚Äúwork independently of each other they produce
determinate results.‚Äù However, if both functions, in the words of Soros [17], do
‚Äúoperate simultaneously (then) they interfere with each other.‚Äù It is this inter-
ference that Soros calls ‚ÄúreÔ¨Çexivity.‚Äù Soros [17] indicates that ‚ÄúreÔ¨Çexivity intro-
duces an element of unquantiÔ¨Åable uncertainty into both the participants‚Äô under-
standing and the actual course of events.‚Äù The interested reader may sense the
notion of an uncertainty principle in some macroscopic environment. We already
mentioned such principle in Chapter 3, Section 3.2. But we also note the word
‚Äúinterference‚Äù which from a simple analogy point of view makes us possibly think
about probability interference. This concept was covered in Chapter 5.
We may wonder whether we can connect this approach with the meaning of a
wave function in a Bohmian mechanical environment? Chapters 11, 12, and 13

180
Financial/economic theory in crisis
will discuss more the economic role of the Bohmian wave function. In Chapter 13
we will introduce a so-called ‚Äúinformation risk parameter.‚Äù The Wiener process
there will be mimicking the source of information risk. We can also argue that the
constructive and destructive interference, which are essential in the build up of the
wave function via the Fourier integration (see Chapter 5, Section 5.9), could be
an echo of the simultaneous interfering of what Soros calls the manipulative and
cognitive functions.
We can make the following argument. We can consider cognitive and manipu-
lative functions as variables of the model under consideration. If these observables
interfere (and experimentally this fact is expressed in the violation of the formula
of total probability), then we can apply the quantum-like approach to modeling
Soros‚Äô theory of reÔ¨Çexivity, and describe the state of the market by the quantum
mechanical wave function. In simple quantum mechanical terms, if normalized
plane wave functions do interfere, via constructive and destructive interference
(i.e. cognitive and manipulative functions), then they build up a quantum mechan-
ical wave function. This resultant wave function, we will propose, can be used
as a carrier of a degree of erroneous information. The rationale for doing so, as
we will see in Chapter 13, may possibly be traced back to the idea Bohm and
Hiley [19] proposed of ‚Äúactive information.‚Äù This active information is narrowly
connected to the existence of the wave function. Furthermore, the use of Fourier
series and integrals in this context, also naturally leads to the uncertainty principle
of momentum and position. Hence, the idea of reÔ¨Çexivity in effect would then be
closely connected to the Fourier integration apparatus (and thus the uncertainty
principle). Furthermore, recalling the deÔ¨Ånition of the wave function in Chapter 5,
Section 5.9, we can see that the role of the amplitude function of the wave
number is of central importance in giving shape to the emerging wave func-
tion. The absence of reÔ¨Çexivity in this proposed framework would then clearly
imply the absence of the Fourier integration apparatus of the wave function con-
struction. The wave number can be best interpreted in the light of the famous
de Broglie relation p = ¬Øhk: p is momentum and ¬Øh is the rationalized Planck
constant.
Let us quote Soros on his idea on how interference produces effects in the
Ô¨Ånancial markets. Says Soros [17]: ‚ÄúThis two-way connection works as a feedback
loop. The feedback is either positive or negative. Positive feedback reinforces both
the prevailing trend and the prevailing bias ‚Äì and leads to a mispricing of Ô¨Ånancial
assets. Negative feedback corrects the bias.‚Äù With our proposed connection of
bringing reÔ¨Çexivity into the realm of wave function construction, we could identify
the existence of a negative feedback with the appearance of an amplitude function
which is very wide, producing via Fourier integration, a very tight wave function. If
that wave function is dependent on the position parameter, which is price, then the

10.3 George Soros‚Äô interpretation of the crisis
181
density function derived from that wave function will be tight, and the probability
of mispricing would be very much limited. Positive feedback effects would provoke
the opposite effect: the amplitude function on the wave number would be very tight
and, via Fourier integration, this would create a very wide wave function. If again,
this wave function is dependent on price, the probability of mispricing would indeed
be much less limited. Remark also the case where reÔ¨Çexivity is absent, i.e. when the
manipulative and cognitive functions do not interfere with each other, no such wave
function construction exists at all. In other words, the Fourier integration apparatus
(and the ancillary uncertainty principle) in that case completely disappears. In fact
this absence of reÔ¨Çexivity could possibly be connected to the existence of no-
arbitrage, where it can be shown that the absence of arbitrage leads to a break down
of the Fourier integration machinery we propose here. The existence of arbitrage
would then allow for the existence of an amplitude function and the appearance of
the Fourier integration machinery.
We Ô¨Ånish this section with an observation on feedback loops. Feedback loops
are well known in classical dynamics (and neural networks). Hence, the reader may
wonder why the authors of this book advertise the usage of quantum formalism
to describe such market dynamics. As was pointed out, one of the reasons is the
presence of interference effects which cannot be described by classical dynamics.
However, for Soros the crucial consequence of the reÔ¨Çexivity theory is that, contrary
to models which are based on the formalism of classical statistical mechanics, his
theory does not imply that a stabilization to equilibrium must occur. Following
Soros, as we mentioned above, the Ô¨Ånancial market can be unstable. Such dynamical
behavior can be well explained by the fact that any solution of the Schr¬®odinger
equation (which is different from the stationary solution) will Ô¨Çuctuate forever
without approaching the equilibrium state. We remark that stationarity of solutions
means that there are no such dynamics at all. In the modeling of the market,
the only possibility for the realization of such a stationary state is the state of
stagnation.
10.4 References
[1] Samuelson, P. and Nordhaus, W. D. (1985). Economics. McGraw-Hill.
[2] Smith, A. (1776). An Inquiry into the Nature and Causes of the Wealth of Nations.
5th edition. Methuen and Co. Ltd (publication date 1904).
[3] Nozick, R. (1994). Invisible-hand explanations. American Economic Review, 84, 2,
314‚Äì318.
[4] Nozick, R. (1993). The Nature of Rationality. Princeton University Press, NJ.
[5] Schelling, T. C. (1969). Models of segregation. American Economic Review, 59,
488‚Äì493.
[6] Ullmann-Margalit, E. (1978). Invisible-hand explanations. Synthese, 39, 2, 263‚Äì291.

182
Financial/economic theory in crisis
[7] Tirole, J. (1992). Theory of Industrial Organization. MIT Press.
[8] Embrechts, P., Lindskog, F., and McNeil, A. (2003). Modelling dependence with cop-
ulas and applications to risk management. In Handbook of Heavy Tailed Distributions
in Finance. Ed. Rachev, S. T. Handbooks in Finance (Book 1), Elsevier.
[9] Artzner, P., Delbaen, F., Eber, J.M., and Heath, D. (1999). Coherent measures of risk.
Mathematical Finance, 9, 3, 203‚Äì228.
[10] Soros, G. (1987). The Alchemy of Finance. Reading the Mind of the Market. J. Wiley,
New York.
[11] Khrennikov, A. (2010). Ubiquitous Quantum Structure: From Psychology to Finance.
Springer Verlag, Berlin.
[12] Khrennikov, A. (2004). Information Dynamics in Cognitive, Psychological and
Anomalous Phenomena. Series Fundamental Theories of Physics. v. 138. Kluwer,
Dordrecht.
[13] Khrennikov, A. Yu. (1999). Classical and quantum mechanics on information spaces
with applications to cognitive, psychological, social and anomalous phenomena.
Foundations of Physics, 29, 1065‚Äì1098.
[14] Choustova, O. (2004). Bohmian mechanics for Ô¨Ånancial processes. Journal of Modern
Optics, 51, 6/7, 1111.
[15] Choustova, O. (2006). Quantum Bohmian model for Ô¨Ånancial market. Physica A, 374,
304‚Äì314.
[16] Choustova, O. (2007). Quantum modeling of nonlinear dynamics of prices of shares:
Bohmian approach. Theoretical and Mathematical Physics, 152, 7, 1213‚Äì1222.
[17] Soros, G. (2011). Why I agree with (some of) Friedrich Hayek. Interviews and
Speeches. GeorgeSoros.com: the ofÔ¨Åcial website of George Soros (April 28, 2011).
[18] Ma, C. (2010). Advanced Asset Pricing Theory. Imperial College Press.
[19] Bohm, D. and Hiley, B. (1998). Non-locality and locality in the stochastic interpreta-
tion of quantum mechanics. Physics Reports, 172, 93‚Äì122.
10.5 The need for an information modeling device in
economics and Ô¨Ånance
The former section gave us a Ô¨Çavor on how wave functions could be used to
model Soros‚Äô idea of reÔ¨Çexivity. The interference of wave functions can be tightly
connected to the existence of reÔ¨Çexivity. The positive and negative feedback loops
may be connected to respectively tight and wide amplitude functions. The same
amplitude function could also be proposed to be connected to the prior distribution
(via Bayes rule). Bayes rule was brieÔ¨Çy discussed in Chapter 8, Section 8.1.
The concept of information has a long history in the sciences. Information theory
has proposed many useful measures, such as (of course) entropy and ‚Äúinformation
gain‚Äù formulas, which aid in precisely assessing the quantity of information in
systems. However, it remains very challenging to devise measures which can
determine the content of information.
Haken [1] (p. 55), gives an interesting example on how one can maximize
information. He considers symbols like dashes or dots. The probability of Ô¨Ånding
such a dash or a dot, in a total population (N) of N1 and N2 dashes and dots,

10.5 An information modeling device
183
he deÔ¨Ånes simply to be pj = Nj
N ; j = 1, 2. The measure for the information per
symbol is then (Haken [1] (p. 55)): i = ‚àíK 
j pj ln pj, where K is a constant and
j = 1, 2. This measure can then be maximized subject to the fact probabilities add
up to unity. Haken [1] (p. 57) also shows that by rewriting i = ‚àíK 
j pj ln pj as:
i = ‚àí
j pjfj (with fj = ‚àíK ln pj), fj can be interpreted (Haken [1] (p. 57))
‚Äúas the information content of the symbol (dash or dot for instance).‚Äù
Haken shows that ‚Äúinformation‚Äù and ‚Äúinformation gain‚Äù can be precisely mea-
sured in, for instance, self-organizing systems. It is unclear whether economic
systems can in fact be seen as self-organizing systems.
10.6 Reference
[1] Haken, H. (1988). Information and Self-Organization: A Macroscopic Approach to
Complex Systems. Springer Verlag, Berlin.

11
Bohmian mechanics in Ô¨Ånance and economics
11.1 The pilot wave function and its uses outside of quantum mechanics
Let us recall our discussion on Bohmian mechanics in Chapter 6. The idea of
using Bohmian mechanics outside of quantum mechanics is not new anymore.
Khrennikov [1] provides for an overview on how this model can contribute in
precise terms to areas such as economics and Ô¨Ånance.1 Historically, the work by
Bohm and Hiley [2] and also Hiley and Pylkk¬®anen [3] brought forward the idea that
the pilot wave function could be seen as a wave function containing information.
In Khrennikov [4], Choustova [5], and Haven [6], the idea of using pilot wave
theory to Ô¨Ånance was investigated. Khrennikov [1] (p. 160) remarks that ‚Äúthe force
induced by the pilot wave Ô¨Åeld does not depend on the amplitude of the wave.‚Äù
He cites the argument made by Bohm and Hiley [2] that because of this property
the pilot wave is an information wave.
The various interpretations (with applications) of the wave function will be
covered in detail in Chapter 13.
Here are some of the key features which can be of use in an Ô¨Ånancial/economics
setting. When the wave function is not factorized, then a change in the price of a
stock i will affect the prices of stocks, j, with j Ã∏= i. See Khrennikov [1] (p. 161).
The Bohmian theory, as we remarked already in Chapters 1 and 6, is non-local. The
amplitudes of wave functions are inconsequential on the force emanating from the
pilot wave (recall the existence of a quantum potential which is an essential part of
pilot wave theory ‚Äì see Chapter 6).
An interesting discussion can be engaged on the notion of what we would
like to call a ‚Äúpricing rule.‚Äù We will brieÔ¨Çy refer back to this notion in the next
chapter. Recall the deÔ¨Ånition of the quantum potential from Chapter 6, which we
could derive from equation (6.15), Q(q) = ‚àíh2
2mR
‚àÇ2R
‚àÇq2 . In Khrennikov [1], several
1 Chapter 9 in that book (pp. 151‚Äì170) provides for a discussion.
184

11.1 The pilot wave function and its uses outside of quantum mechanics
185
examples are given on how such a quantum potential can be used in an economics
context. We reiterate two examples given there. The Ô¨Årst example (Khrennikov [1]
(pp. 162‚Äì163) (Example 9.1)) concerns the simple case of a constant amplitude,
R. The force derived from the quantum potential, ‚àí‚àÇQ
‚àÇq , is then, in this case, zero.
Thus, the size of the amplitude in this case is totally inconsequential. Consider
a second example (see Khrennikov [1] (p. 163) (Example 10.3)) with amplitude
R(q) = c(q4 + b), c, b > 0. The force, ‚àí‚àÇQ
‚àÇq , yields
bq‚àíq5
(q4+b)
2 and setting d =
4‚àö
b,
then, as the price moves from q = 0 to q = d, there is no negative force in increasing
the price from the level 0 to the level d. Beyond level d, the situation is reversed.
The forces portrayed through those two simple examples show clearly that an
argument can be made that such quantities could be interpreted as some ‚Äúpricing
rule.‚Äù Such rules could indeed be very sophisticated, depending on the functional
form of the quantum potential.
11.2 References
[1] Khrennikov, A. (2009). Ubiquitous Quantum Structure: From Psychology to Finance.
Springer Verlag, Berlin.
[2] Bohm, D. and Hiley, B. (1993). The Undivided Universe: An Ontological Interpretation
of Quantum Mechanics. Routledge.
[3] Hiley, B. and Pylkk¬®anen, P. (1997). Active information and cognitive science ‚Äì a reply
to Kiesepp¬®a. In Brain, Mind and Physics. Eds. Pylkk¬®anen, P., Pyllk¬®o, P., and Hautam¬®aki,
A. IOS Press, Amsterdam, pp. 123‚Äì145.
[4] Khrennikov, A. (2004). Information Dynamics in Cognitive, Psychological and Anoma-
lous Phenomena. Series Fundamental Theories of Physics, v. 138. Kluwer, Dordrecht.
[5] Choustova, O. (2009). Application of Bohmian mechanics to the dynamics of prices
of shares: stochastic model of Bohm‚ÄìVigier from properties to price trajectories.
International Journal of Theoretical Physics, 47, 252‚Äì260.
[6] Haven, E. (2006). Pilot-wave theory and Ô¨Ånancial option pricing. International Journal
of Theoretical Physics, 44, 11, 1957‚Äì1962.

12
The Bohm‚ÄìVigier model and path simulation
12.1 The Bohm‚ÄìVigier model in Ô¨Ånance
Bohm and Hiley [1] (p. 194) (equation (9.29)) indicate that according to Bohm and
Vigier the velocity of a particle could be given by1 v = ‚àáS
m + Œæ, where ‚àáS is the
gradient of the phase of the wave function towards position, m is mass, and Œæ is
a random contribution with mean zero. Bohm and Hiley‚Äôs interpretation (p. 195)
of the term ‚àáS
m is seen as the ‚Äúaverage velocity of the particle.‚Äù Bohm and Hiley
[1] (p. 195) argue that if the average velocity is so deÔ¨Åned and the wave function
is expressed via the polar form œà = R.eiS (this was equation (6.1) in Chapter 6),
‚Äúthen Schr¬®odinger‚Äôs equation implies that‚Äù:
dv
dt = ‚àí‚àá(V + Q),
(12.1)
where
the
gradient
(towards
position)
is
taken
on
both
the
real
and
quantum potentials.
Now recall the portfolio we considered in the Black‚ÄìScholes option pricing
model. In Chapter 2, equation (2.10), it was indicated that the return per unit of
time of the portfolio should be equal (in case of no arbitrage) to the risk free rate
of interest d

1
dt = r, where  is the Black‚ÄìScholes portfolio (a collection of a
stock and an option). We can make the argument that the above Bohm‚ÄìVigier
model could be used in this option pricing context in the following way. As in
Haven [2] (p. 334), we write in analogy with v = ‚àáS
m + Œæ that d
dt = ‚àáS() + œâ,
and the information function is now deÔ¨Åned as œà () = R () exp(iS()) and
S () = r2
2 and œâ = x ‚àáS()
r
, where x is a time-independent arbitrage return.
We may of course wonder why one would want to write the above? In
Chapter 3, we hinted at the necessary existence of non-arbitrage in the deriva-
tion of the Black‚ÄìScholes model. In effect, the left-hand side and right-hand
1 We omit subscripts i.
186

12.3 The Newton‚ÄìBohm equation
187
side of d

1
dt = r can only be equal in the absence of arbitrage. Hence, writing
d
dt = ‚àáS() + œâ, with the phase and the stochastic term as deÔ¨Åned above, indi-
cates allowance is made for the existence of arbitrage. Thus, in that context one
can now propose d

1
dt > r or d

1
dt < r. This leads us into an already established
theory, developed mainly by Ilinski [3], Otto [4], Fedotov, Panayides [5], and
Panayides [6]. See also Haven [7].
The Ilinski [3] and Otto [4] approaches specify that the return on the Black‚Äì
Scholes portfolio, , is: d = rdt + xdt. See, for instance, equation (43)
in Ilinski [3] (p. 237). The ‚Äúx‚Äù can follow a speciÔ¨Åc random process like the
Ornstein‚ÄìUhlenbeck process, and this process is deÔ¨Åned as in Ilinski [3] (p. 240)
(equation 49):
dx
dt = ‚àíŒªx(t) + Œ∑(t),
(12.2)
where Œ∑(t) is white noise and Œª is a relaxation parameter.
12.2 References
[1] Bohm, D. and Hiley, B. (1993). The Undivided Universe: An Ontological Interpretation
of Quantum Mechanics. Routledge.
[2] Haven, E. (2005). Bohmian mechanics in a macroscopic quantum system. In Quantum
Theory: Reconsideration of Foundations ‚Äì 3. Eds. Adenier, G., Khrennikov, A., and
Nieuwenhuizen, T. American Institute of Physics Conference Proceedings, New York.
[3] Ilinski, K. (2001). Physics of Finance: Gauge Modelling in Non-Equilibrium Pricing.
J. Wiley.
[4] Otto, M. (1999). Stochastic relaxational dynamics applied to Ô¨Ånance: towards non-
equilibrium option pricing theory. European Physical Journal B, 14, 383‚Äì394.
[5] Fedotov, S. and Panayides, S. (2005). Stochastic arbitrage returns and its implications
for option pricing. Physica A, 345, 207‚Äì217.
[6] Panayides, S. (2005). Derivative pricing and hedging for incomplete markets: stochastic
arbitrage and adaptive procedure for stochastic volatility. Ph.D. Thesis. The School of
Mathematics, University of Manchester.
[7] Haven, E. (2008). Elementary quantum mechanical principles and social science: is
there a connection. Romanian Journal of Economic Forecasting, 9, 1, 41‚Äì58.
12.3 The Newton‚ÄìBohm equation: path simulation
The Newton‚ÄìBohm equation was described in equation (6.16), see Chapter 6, Sec-
tion 6.3. We recall this PDE as being m.a = m d2q(t)
dt2
= ‚àí‚àÇV (q,t)
‚àÇq
‚àí‚àÇQ(q,t)
‚àÇq
, where
V is the real potential function and Q is the quantum potential function. The hall-
mark of Bohmian mechanics is the quantum potential, which depends on the wave
function‚Äôs amplitude. The wave function does evolve according to the Schr¬®odinger
partial differential equation.

188
The Bohm‚ÄìVigier model and path simulation
Real data
View Save Help
507
220.00
133.50
0
Figure 12.1. Real trajectory I, generated on the basis of price data (source:
Khrennikov and Kotovich [1])
Real data
View Save Help
254
0
198.50
157.50
Figure 12.2. Real trajectory II, generated on the basis of price data (source:
Khrennikov and Kotovich [1])
An important issue which needs to be tackled is to inquire whether real price
trajectories can be simulated by the Bohmian model. The simulations below
(Figures 12.1‚Äì12.6) are using as real potential a free particle in a box. The
Schr¬®odinger PDE is solved (using the above real potential function) and then
the quantum potential is found. Simulation can then be started. An important issue
which remains open is to know what initial condition wave function one needs to
choose for the Schr¬®odinger equation. The simulated Newton‚ÄìBohm paths do very
much depend on the choice of this initial condition.

12.3 The Newton‚ÄìBohm equation
189
Real data
View Save Help
502
0
41.80
79.00
Figure 12.3. Real trajectory III, generated on the basis of price data (source:
Khrennikov and Kotovich [1])
Result
View
Save
Help
1501
1
‚Äì17.36
87.07
Figure 12.4. A Newton‚ÄìBohm trajectory (source: Khrennikov and Kotovich [1])
The Ô¨Ågures above show path simulations based on real data (Figures 12.1‚Äì12.3).
The Newton‚ÄìBohm paths are shown in Figures 12.4‚Äì12.6.
The Y axis in Figures 12.4, 12.5, and 12.6 represent values which are the
logarithm of the values on the Y axis from Figures 12.1, 12.2, and 12.3. As
indicated already above, the results of the simulation are highly conditional on
the initial condition ‚Äì wave function. A problem which presents itself here is how
to interpret the dynamics of expectations (of say market participants), which are
encapsulated at the level of the wave function. This is a problem we can also Ô¨Ånd

190
The Bohm‚ÄìVigier model and path simulation
Result
View Save Help
1501
1
30.32
‚Äì42.73
Figure 12.5. Another Newton‚ÄìBohm trajectory (source: Khrennikov and
Kotovich [1])
Result
View
Save
Help
1501
1
‚Äì22.41
4.78
Figure 12.6. Another Newton‚ÄìBohm trajectory (source: Khrennikov and Kotovich [1])
back in economics. Do we know how to encapsulate the mood of a representative
agent in a utility function? If we were to try to mimic price paths with a stochastic
approach, should we not need to worry about the expected rate of interest to use
(which reÔ¨Çects preferences for risk (of the representative agent))? We may wonder
whether a pricing rule (tied to the quantum potential) cannot be guessed via certain
speciÔ¨Åc historical price moments. As an example, the behavioral Ô¨Ånance literature
has come forward with several pricing effects. The pricing rule is in effect nothing
else than the force derived from the quantum potential. This is in effect the last

12.3 The Newton‚ÄìBohm equation
191
term in equation (6.16) (see Chapter 6). We must therefore pay particular attention
to the amplitude function of the wave function. One very important feature of the
model would then be to encapsulate in the choice of the amplitude function the
possibility that a noticeable event in the market may be coming forward. One could
possibly measure such upcoming event via the change in level of the LIBOR rate
(London Interbank Offer Rate).
12.4 Reference
[1] Khrennikov, A. Yu. and Kotovich, N. (2010). Private communication. December 30,
2010.

13
Other applications to economic/Ô¨Ånancial theory
This chapter attempts to delve deeper into the question on how quantum mechanical
techniques can be brought closer into the realm of economics and Ô¨Ånance.
13.1 The (non-)Hermiticity of Ô¨Ånance-based operators?
Hermiticity of operators was discussed in Chapter 4 of the book. We again take up
this very important concept in the context of Ô¨Ånancial asset pricing. It is a classical
result from quantum mechanics that the existence of Hermiticity of the Hamiltonian
operator is intimately linked with the notion of conservation of probability. The
existence of Hermiticity is also known to be closely linked to the concept of spatial
localization. Please see below.
Baaquie [1] makes the important argument that the Black‚ÄìScholes Hamiltonian
is non-Hermitian and this condition provides for the need to satisfy the martingale
condition. Please recall that the martingale property was covered in Chapter 2,
Section 2.9. It is also important to mention that Luigi Accardi has indicated1 that
it is white noise which may be the cause of non-Hermiticity in a Ô¨Ånance context.
One can argue that within an economics/Ô¨Ånance context, the equivalent of the
state function, using Baaquie [1] [2], can be the option price function. A similar
interpretation can also be found in the paper by Li and Zhang [3] (see also Haven
[4]). Please note that the work of Li and Zhang is covered in Section 13.12 of this
chapter. We would like to note that by interpreting the wave function as the call/put
price, we depart from the conventional probabilistic interpretation of the wave func-
tion (the Born interpretation), and we move instead towards Schr¬®odinger‚Äôs original
interpretation of the wave function as a real physical Ô¨Åeld. Schr¬®odinger considered
the wave function as the density of the electron charge (see Khrennikov [5]). In
1 One of the authors recalls that Professor Accardi made this remark at the Fifth Foundations of Probability and
Physics conference, which was held at Linnaeus University (Sweden), August 25‚Äì27, 2008.
192

13.1 (Non-)Hermiticity of Ô¨Ånance-based operators?
193
particular, in his approach the wave function was not normalized. Moreover, at the
beginning he considered only real valued wave functions. Hence, the analogy with
the call/put price interpretation of the wave function in Ô¨Ånance is evident. Recently
Schr¬®odinger‚Äôs interpretation of the wave function was justiÔ¨Åed in the framework
of so-called prequantum classical statistical Ô¨Åeld theory (see Khrennikov [6]). The
main departure from Schr¬®odinger‚Äôs approach (as well as from Khrennikov [6]) are
the non-unitary dynamics of such a wave function of the Ô¨Åeld type.
The underlying asset of the option pricing function (please see also Chapter 2,
Section 2.7.1 for the deÔ¨Ånition of an option) could be the equivalent of the inde-
pendent variable entering the state function. Since asset prices can not be negative,
there is a restriction on the space where we can Ô¨Ånd (Ô¨Ånancial) particles.
However, can we necessarily argue for spatial localization? The concept of
‚Äúprobability conservation‚Äù tells us that the probability of Ô¨Ånding a particle anywhere
in space is time independent. To show that probability conservation is intimately
related to the Hermiticity of the Hamiltonian operator, one actually needs to activate
the condition of spatial localization. This condition is simple and says that the wave
function œà(x, t) ‚Üí0 when |x| ‚Üí‚àû. Clearly, if we consider the Ô¨Ånance equivalent
of œà(x, t), i.e. the option pricing function where the underlying is an asset price,
then we know asset prices never go to inÔ¨Ånity. But assume for theoretical sake
that they do. Consider the martingale property E(St+1|Ft) = St. This is intimately
linked to the existence of non-arbitrage, since we can write under this condition
that
1
1+r EP (St+1) = St, i.e. the risky asset can be discounted at the risk free rate of
interest, r, under the risk neutral probability measure, P.
Bj¬®ork [7] (p. 9) indicates that a probability measure P is called a martingale
measure if the condition S0 = EP (S1)
1+r
is satisÔ¨Åed. Bj¬®ork [7] (p. 10) also shows that
there does not exist arbitrage if and only if there exists a martingale measure P.
Let us for easiness of purpose say that r = 0, and hence we can then write
EP (St+1) = St. When there is arbitrage, the best we can write is EP(St+1) =
St(1 + r + premium), and, therefore, EP (St+1) > St in the case where the premium
is positive, and EP (St+1) < St in the case where the premium is negative.2 Assume
now that the strike price of a call option is Ô¨Ånite, which is a very reasonable
assumption. If St were to go to inÔ¨Ånity, and assuming there is a positive premium,
then EP(St+1) would certainly go to inÔ¨Ånity and therefore the equivalent condition
in Ô¨Ånance terms of œà(x, t) ‚Üí0 when |x| ‚Üí‚àûwould certainly not be met, since
the call price would even ‚Äúbe more‚Äù3 inÔ¨Ånite since St ‚ÜíSt+1 ‚Üí‚àû. Thus the
call price C(St+1, t) ‚Üõ0. If the premium is negative, we would have possibly the
reverse: St may tend to inÔ¨Ånity, but, since St+1 < St, we could argue that St+1
is ‚Äúnow less‚Äù4 tending to inÔ¨Ånity. But if it is less tending to inÔ¨Ånity, it may be
2 Remark that the premium is asset speciÔ¨Åc, i.e. the level of the premium refers to the speciÔ¨Åc asset in question.
3 We agree this is indeed very imprecise language.
4 Again, the language we use is imprecise.

194
Other applications to economic/Ô¨Ånancial theory
Ô¨Ånite. Hence, although the call price C(St, t) ‚Üí‚àû, one could possibly argue that
C(St+1, t) < ‚àûsince St+1 can be Ô¨Ånite. If the stock price were to indeed coincide
with the Ô¨Ånite strike price, then C(St+1, t) = 0. Remark that no option contract
exists with inÔ¨Ånite strike prices.
In the proposition below, we use the Ô¨Åeld interpretation of the wave function,
i.e. as a classical (real valued) Ô¨Åeld.5 Here is the argument in a more formal format.
Proposition 13 Assume the state function œà(x, t) becomes now C(A, t), where
A is the price of an asset and C is the price of a call option. A necessary and
sufÔ¨Åcient condition for the Black‚ÄìScholes option price Hamiltonian operator to be
Hermitian is that an appropriate super-martingale on A exists.
Proof. The non-arbitrage condition yields that: EP (A(t+1))
1+r
= A(t), where r is the
risk free rate (a constant) and P is the risk neutral probability measure. Hence, we
can write this expression as a martingale (see Chapter 2, Section 2.9 for a deÔ¨Åni-
tion):6 EP(A(t + 1)) = A(t). Assume for easiness of purpose that r = 0. Assume a
martingale does not exist, i.e. we obtain EP (A(t + 1)) = A(t)(1 + risk premium).
Hence, we can only write the expectation as either a so-called super-martingale
EP (A(t + 1)) < A(t) or a so-called sub-martingale EP (A(t + 1)) > A(t). If A(t)
tends to the inÔ¨Ånite, then, in the case of a sub-martingale, A(t + 1) will be even
larger. Therefore, from a call option point of view, the intrinsic value yielded
by A(t + 1) will be even farther removed from the strike price (and thus far-
ther removed from zero). Under a martingale, if A(t) is tending to inÔ¨Ånity with
a non-zero call price, then A(t + 1) will equally yield a non-zero call price.
A necessary (but not sufÔ¨Åcient) condition for the call price to tend to zero
is to impose a super-martingale on A(t). If A(t) tends to inÔ¨Ånity, then under
the super-martingale, A(t + 1) < ‚àûwill be Ô¨Ånite. However, we need to fur-
ther impose that A(t + 1) must tend to the Ô¨Ånite strike price. In that case,
only the call price will tend to zero. Hence, if there exists a super-martingale
and for an appropriate choice of A(t + 1), one can obtain spatial localiza-
tion. Assuming that such spatial localization exists, using the usual state func-
tions7 and following (Morrison [9] (p. 202)), one can write
d
dt p([‚àí‚àû, ‚àû]) =
‚àíi
¬Øh
‚àû

‚àí‚àû

œà‚àó(x, t) 
Hœà(x, t) ‚àíœà(x, t)
 
Hœà(x, t)
‚àó
dx and since the Hamiltonian
operator
can
be
split
into
a
real
potential
energy
operator
(which
5 For a nice introduction on the topic of the quantization of Ô¨Åelds, please see Bethe [8].
6 We have taken off, for easiness of notation, the conditionality of the expectation on the information set at
time t.
7 Adjustments would have to be made if the conversion from state function to option price is made, like re-
mapping the fact that the product ‚àíi
¬Øh will not appear in the option pricing setting. However, this does not alter
the argument of the proof.

13.1 (Non-)Hermiticity of Ô¨Ånance-based operators?
195
is
the
real
potential)
and
a
kinetic
energy
operator,
one
can
write:
d
dt p([‚àí‚àû, ‚àû]) = ‚àíi
¬Øh
‚àû

‚àí‚àû

œà‚àó(x, t)T œà(x, t) ‚àíœà(x, t)
T œà(x, t)
‚àó
dx, where T
is
the
kinetic
energy
operator
which
is
equal
to
‚àí¬Øh2
2m
‚àÇ2
‚àÇx2 .
The
above
expression
d
dt p([‚àí‚àû, ‚àû])
can
then
be
shown
to
be
equal
to
(Mor-
rison
[9]
(p.
203)):
‚àíi¬Øh
2m

œà‚àó(x, t) ‚àÇ
‚àÇx œà(x, t) ‚àíœà(x, t) ‚àÇ
‚àÇx œà(x, t)‚àó‚àí‚àû
‚àû
and
this expression is zero because spatial localization now exists.
Hence,
i
¬Øh
‚àû

‚àí‚àû

œà‚àó(x, t) 
Hœà(x, t) ‚àíœà(x, t)
 
Hœà(x, t)
‚àó
dx = 0 and therefore we can
recuperate the deÔ¨Ånition for the Hermiticity of a Hamiltonian operator:
‚àû

‚àí‚àû
œà‚àó(x, t) 
Hœà(x, t)dx =
‚àû

‚àí‚àû
œà(x, t)
 
Hœà(x, t)
‚àódx.
‚ñ†
We remark the very speciÔ¨Åc conditions needed to argue for the existence of
Hermiticity of the Black‚ÄìScholes Hamiltonian operator. Here are the conditions
again:
1. We assume that an equivalent analogue of the state function is the option call
function (please see above Proposition 13).
2. We require a super-martingale on the underlying asset.
3. Because of 2, we must assume the existence of arbitrage on the underlying asset.
4. The underlying asset‚Äôs price must tend to the strike price.
Conditions 2 and 3 are conditions which tend to conÔ¨Årm that Hermiticity and
the existence of arbitrage may have to co-exist. Condition 4, clearly imposes a
constraint, which Ô¨Ånancially is possible. Asset prices can deÔ¨Ånitely converge to a
strike price in reality. However, there are many instances where that is not the case.
Proposition 14 Assume the state function œà(x, t) becomes now P(A, t), where A
is the price of an asset and P is the price of a put option, then the Black‚ÄìScholes
option price Hamiltonian operator is Hermitian.
Proof. The proof follows almost entirely the proof of Proposition 13 above. When
A ‚Üí‚àû, then P(A, t) = 0 by deÔ¨Ånition of the intrinsic value of the put option
and the fact that the strike price is always Ô¨Ånite. Using the usual state functions,8
there exists spatial localization. Following (Morrison [9] (p. 202)) one can write:
8 Adjustments would have to be made if the conversion from state function to option price is made, like re-
mapping the fact that the product ‚àíi
¬Øh will not appear in the option pricing setting. However, this does not alter
the argument of the proof.

196
Other applications to economic/Ô¨Ånancial theory
d
dt p([‚àí‚àû, ‚àû]) = ‚àíi
¬Øh
‚àû

‚àí‚àû
{œà‚àó(x, t) 
Hœà(x, t) ‚àíœà(x, t)
 
Hœà(x, t)
‚àó}dx and since
the Hamiltonian operator can be split into a real potential energy operator (which is
the real potential) and the kinetic energy operator, one can write: d
dt p([‚àí‚àû, ‚àû]) =
‚àíi
¬Øh
‚àû

‚àí‚àû
{œà‚àó(x, t)T œà(x, t) ‚àíœà(x, t)
T œà(x, t)
‚àó}dx, where T is the kinetic energy
operator which is equal to: ‚àí¬Øh2
2m
‚àÇ2
‚àÇx2 . The above expression
d
dt p([‚àí‚àû, ‚àû]) can
then be shown to be equal to (Morrison [9] (p. 203)): ‚àíi¬Øh
2m[œà‚àó(x, t) ‚àÇ
‚àÇx œà(x, t) ‚àí
œà(x, t) ‚àÇ
‚àÇx œà(x, t)‚àó]‚àí‚àû
‚àû
and this expression is zero because spatial localization
exists. Hence,
i
¬Øh
‚àû

‚àí‚àû
{œà‚àó(x, t) 
Hœà(x, t) ‚àíœà(x, t)
 
Hœà(x, t)
‚àó}dx = 0 and there-
fore we can recuperate the deÔ¨Ånition for the Hermiticity of a Hamiltonian operator:
‚àû

‚àí‚àû
œà‚àó(x, t) 
Hœà(x, t)dx =
 ‚àû
‚àí‚àûœà(x, t)
 
Hœà(x, t)
‚àódx.
‚ñ†
If we compare proposition 14 with proposition 13, we can immediately observe
a high degree of asymmetry. Here are the conditions:
1. We assume that an equivalent analogue of the state function is the option put
function (please see above Proposition 13).
2. The existence of arbitrage or non-arbitrage is irrelevant.
Thus in the case of the put, the existence of Hermiticity is un-connected with
the existence of arbitrage or non-arbitrage. Hence, spatial localization is always
veriÔ¨Åed in that case.
13.2 References
[1] Baaquie, B. (2008). Quantum mechanics and option pricing. In Quantum Interaction.
Eds. Bruza, P., Lawless, W., van Rijsbergen, K., Sofge, D. A., Coecke, B., and Clark,
S. Proceedings of the Second Quantum Interaction Symposium (Oxford University),
College Publications, pp. 49‚Äì53.
[2] Baaquie, B. (2005). Quantum Finance. Cambridge University Press.
[3] Li, Y. and Zhang, J. E. (2004). Option pricing with Weyl‚ÄìTitschmarsh theory. Quanti-
tative Finance, 4, 457‚Äì464.
[4] Haven, E. (2005). Analytical solutions to the backward Kolmogorov PDE via an
adiabatic approximation to the Schr¬®odinger PDE. Journal of Mathematical Analysis
and Applications, 311, 439‚Äì444.
[5] Khrennikov, A. (2009). Contextual Approach to Quantum Formalism. Springer Verlag,
New York.

13.3 Implications of the non-Hermiticity
197
[6] Khrennikov, A. (2010). Quantum correlations and dynamics from classical random
Ô¨Åelds valued in complex Hilbert spaces. Journal of Mathematical Physics, 51, art-
number 082106.
[7] Bj¬®ork, T. (1998). Arbitrage Theory in Continuous Time. Oxford University Press.
[8] Bethe, H. (1964). Intermediate Quantum Mechanics. W. A. Benjamin Inc.
[9] Morrison, Michael, A. (1990). Understanding Quantum Physics: A User‚Äôs Manual.
Volume 1. 1st edition. Pearson Education, Upper Saddle River, NJ.
13.3 Implications of the non-Hermiticity of a Black‚ÄìScholes Hamiltonian
operator on the use of the classical limit arguments
The non-Hermiticity of the Black‚ÄìScholes Hamiltonian operator will also have an
immediate implication on the classical limit arguments of Chapter 5, Section 5.15.
Here is a straightforward proposition.
Proposition 15 If the Black‚ÄìScholes Hamiltonian operator is not Hermitian, then
the Ehrenfest theorem cannot hold and the classical limit can not be obtained.
Proof. The proof of this proposition is quite straightforward. From Ehren-
fest‚Äôs theorem, one Ô¨Ånds that
d‚ü®p‚ü©(t)
dt
= ‚àí
 ‚àÇV
‚àÇx

and
d‚ü®x‚ü©(t)
dt
= ‚ü®p‚ü©
m
(see Holland
[1], p. 111). The key result to prove Ehrenfest‚Äôs theorem, i.e. the time evolu-
tion of the expectation value of an arbitrary operator, Q, which is:
d
dt ‚ü®Q(t)‚ü©=
#
‚àÇ
Q
‚àÇt
$
+ 1
¬Øh

i
 
H, 
Q

does not hold since it can be shown that
 
Hœà|
Qœà

can-
not be written as:

œà| 
H 
Qœà

. In that case, following Morrison [2] (p. 516)
d
dt ‚ü®Q(t)‚ü©‚àí
#
‚àÇ
Q
‚àÇt
$
= i
¬Øh
 
Hœà|
Qœà

‚àí

œà|
Q 
Hœà

and since
 
Hœà|
Qœà

Ã∏=

œà| 
H 
Qœà

,
one cannot rewrite i
¬Øh
 
Hœà|
Qœà

‚àí

œà|
Q 
Hœà

as i
¬Øh

œà| 
H 
Qœà

‚àí

œà|
Q 
Hœà

. We
note that i
¬Øh

œà| 
H 
Qœà

‚àí

œà|
Q 
Hœà

= 1
¬Øh

i
 
H, 
Q

. To obtain the second result
of the Ehrenfest theorem: d‚ü®x‚ü©(t)
dt
= ‚ü®p‚ü©
m , one would need to use (Morrison [2] (p.
517)): d
dt ‚ü®Q(t)‚ü©=
#
‚àÇ
Q
‚àÇt
$
+ 1
¬Øh

i
 
H, 
Q

, and substitute for 
Q the position operator.
However, d
dt ‚ü®Q(t)‚ü©=
#
‚àÇ
Q
‚àÇt
$
+ 1
¬Øh

i
 
H, 
Q

cannot be used because of the absence
of Hermiticity. A similar argument can be made for the Ô¨Årst result of the Ehrenfest
theorem: d‚ü®p‚ü©(t)
dt
= ‚àí
 ‚àÇV
‚àÇx

.
‚ñ†
Corollary 16 If the state function œà(x, t) now becomes P(A, t), where A is the
price of an asset and P is the price of a put option, then the Ehrenfest theorem
does hold and the classical limit can be obtained.
Proof. Immediate. See Propositions 14 and 15.
‚ñ†
Corollary 17 If the state function œà(x, t) now becomes C(A, t), where A is the
price of an asset and C is the price of a call option and if there exists an appropriate

198
Other applications to economic/Ô¨Ånancial theory
super-martingale on A, then the Ehrenfest theorem does hold and the classical limit
can be obtained.
Proof. Immediate. See Propositions 13 and 15.
‚ñ†
13.4 References
[1] Holland, P. (2000). The Quantum Theory of Motion: An Account of the de Broglie‚Äì
Bohm Causal Interpretation of Quantum Mechanics. Cambridge University Press.
[2] Morrison, Michael, A. (1990). Understanding Quantum Physics: A User‚Äôs Manual.
Volume 1. 1st edition. Pearson Education, Upper Saddle River, NJ.
13.5 Implications of the non-Hermiticity of a Black‚ÄìScholes Hamiltonian
operator on the stochastic equivalent of Hamilton‚ÄìJacobi equations
When we considered the mathematical formalism of the Bohmian mechanical set
up in Chapter 6, Section 6.3, we obtained equation (6.14), which was termed there
the ‚Äúcontinuity equation.‚Äù This leads to the next proposition:
Proposition 18 If the Black‚ÄìScholes Hamiltonian operator is not Hermitian, then
the Bohmian continuity equation may not hold.
Proof. This is immediate. The continuity equation was: ‚àÇR2
‚àÇt + 1
m
‚àÇ
‚àÇq

R2 ‚àÇS
‚àÇq

= 0
and when conservation of probability is not obtained, then clearly ‚àÇR2
‚àÇt Ã∏= 0.
‚ñ†
Clearly, using Propositions 13 and 14 can reverse this result.
In summary, when options would only be puts, the classical limit and the
Bohmian continuity equation would all be veriÔ¨Åed. When call options were to
be used, those results only obtain under the conditions of proposition 13.
13.6 Interpretations of the wave function: a brief discussion
In Chapter 10, Section 10.3, we proposed some possible uses of the wave function
within the setting of Soros‚Äô idea of reÔ¨Çexivity. The idea of connecting this interesting
concept to the use of one of the most elementary tools of quantum mechanics,
i.e. Fourier integration (and series), was quite straightforward. We also considered
brieÔ¨Çy the so-called ‚Äúactive information‚Äù interpretation of the Bohmian mechanics-
based wave function in Chapter 10.
We can consider seven possible (economics based/Ô¨Ånance based) interpretations
of the wave function.
1. the use of a basic quantum mechanical (like) wave function which represents
the expectations of traders in a Ô¨Ånancial market (Chapter 10, Section 10.3);

13.6 Interpretations of the wave function
199
2. the use of a basic quantum mechanical (like) wave function which is the resultant
of wave packet construction: the Soros interpretation of reÔ¨Çexivity (Chapter 10,
Section 10.3);
3. the use of a basic quantum mechanical (like) wave function as an input in the
Radon‚ÄìNikodym derivative (this chapter, Section 13.14);
4. the use of a basic quantum mechanical (like) wave function as an analogue of
the put and call functions (this chapter, Section 13.1); and as an analogue of the
value of an asset (this chapter, Section 13.8);
5. the Bohmian mechanics-based pilot wave function as a carrier of so-called
‚Äúactive information‚Äù: pilot waves as carriers of erroneous information (this
chapter, Section 13.18);
6. the Bohmian mechanics-based pilot wave function as a carrier of so-called
‚Äúactive information‚Äù: pilot wave in a drift dependent option (this chapter,
Section 13.20);
7. the Bohmian mechanics-based pilot wave function as a carrier of so called
‚Äúactive information‚Äù: pilot wave in the non-arbitrage theorem (this chapter,
Section 13.7).
It is important to remark that the above interpretations can in fact be embedded
within a more general possible framework. Depending on the role we decide the
wave function should take in the macroscopic environment, we implicitly make
an assumption as to what formal role is ascribed to this very wave function. It is
clear that the array of formal models one can choose from is constraining if we
want to deÔ¨Åne a wave function role (in a macroscopic environment) which has a
quantum mechanical characteristic. In other words, if we want to step resolutely
outside of quantum physics, we could consider wave functions as they are deÔ¨Åned
in, for instance, classical physics wave dynamics.
A question we may ask is whether there exist other possible interpretations
of the wave function within an economics/Ô¨Ånance-based setting? In other words,
compared to, for instance, the analogue interpretation of the wave function as either
a call or put option pricing function, does there exist another type of analogue? One
important issue to note is the following. As Baaquie [1] remarked (p. 51), the wave
function in quantum mechanics is not observable, while the put and call option
pricing functions are observable. The observability of the option price is, as we
know, artiÔ¨Åcially rendered; i.e. such an observation is made by man. The observ-
ability does not derive from a natural phenomenon. Clearly, the same argument can
be invoked for asset prices, which are not options. The social science literature has
been enriched with important research, which attempts to document how in fact the
option market was generated via the development of the Black‚ÄìScholes formula
mentioned in Chapter, Section 2.7. In other words, the phenomenon of an option
pricing market may have been generated by the uncovering of the Black‚ÄìScholes

200
Other applications to economic/Ô¨Ånancial theory
formula. This is in some sense a reverse phenomenon of what we are used to in the
natural sciences: a phenomenon is observed and a theory is built to explain the phe-
nomenon. MacKenzie and Millo [2] seem to indicate that the opposite happened in
option pricing: a theory is built and the phenomenon is generated from the theory.
To some extent such an event is also noticeable in other areas of social science,
but this so-called ‚Äúreverse theorizing‚Äù is certainly most clear in the option pricing
theory side of the social sciences, since it is after all the Black‚ÄìScholes formula
which triggered a trillion dollar market. Hence, in some sense we can thus question
to some slight degree the so-called ‚Äúobservability‚Äù of option prices.
13.7 The wave function and non-observed state prices
If we want to stay resolutely within a non-observed framework, then we can
possibly hint at the use of the so-called state prices, which are used in the theory
of non-arbitrage. This theory, within a discrete state space environment, has been
treated in different places in this book (for instance see Chapter 4, Section 4.18).
We follow here an approach which can connect the wave function in, again, a
Bohmian mechanics framework.
Recall the formulation of the non-arbitrage theorem in Chapter 4, Section 4.18.3.
We now reproduce9 the paper by Haven [3] (Sections 4 and 5 (pp. 196‚Äì199)).
Remark that q indicates the position of the particle (for instance the price of an
asset)
The existence of arbitrage is for a large part based upon the existence of infor-
mation. Hence, changes in information will alter arbitrage opportunities. We can
thus imagine a benchmark situation where we start out under no arbitrage with
a particular state of information, reÔ¨Çected by a particular functional form of the
information wave function. Our goal, in the proposition below, is then to show
that if the state of information changes (this can for instance be reÔ¨Çected by a
change in the functional form of the wave function) arbitrage can occur. Before we
consider our proposition, let us consider again the non-arbitrage theorem (please
see Chapter 4, Section 4.18.3). We recall that if there exists a K-dimensional state
price vector ‚àí‚Üí
 = (1, 2, 3, . . . , K), which solved the system of equations of
that theorem, there will be no arbitrage (and vice versa). An associated probability
vector ‚àí‚àí‚Üí
prob =

1
0 , 2
0 , 3
0 , . . . , K
0

can be deÔ¨Åned, where each coordinate is a
probability. We have also that 0 = exp(‚àírT ), where r is the risk free rate of return
and T is time. We must stress that we assume that the probability values making
up the probability vector ‚àí‚àí‚Üí
prob can be drawn from ‚à•‚à•2 =

R |œà(q)|2 dM(q).
9 Emmanuel Haven (2008). The variation of Ô¨Ånancial arbitrage via the use of an information wave function.
International Journal of Theoretical Physics, 47, pp. 196‚Äì199.

13.7 Wave function and non-observed state prices
201
Proposition 19 Let there exist an N-dimensional asset price vector ‚àí‚Üí
p0 and a
K-dimensional state price vector ‚àí‚Üí
 . Let there exist a K-dimensional probability
vector ‚àí‚àí‚àí‚Üí
prob =

1
0 , 2
0 , 3
0 , . . . , K
0

. Let N = K and let 0 = exp(‚àírT ) be
Ô¨Åxed. Let there be an information wave function (q) and a measure M on R.
Let each of the probabilities in ‚àí‚àí‚àí‚Üí
prob be drawn from ‚à•‚à•2 =

R |œà(q)|2 dM(q)
for each of the respective set of lower and upper bound values of the integral.
Let the state prices which are in ‚àí‚àí‚Üí
prob guarantee no arbitrage. Consider now an
information wave function Œ≥ (q) which has a different functional form from œà(q)
in the following way: (i) we assume that Œ≥ (q) cannot be the dual wave function
of œà(q);10 (ii) for the same measure M on R and for the same respective set of
lower and upper bound values of the integral we used for

R |œà(q)|2 dM(q), we
write

R |Œ≥ (q)|2 dM(q) such that the functions |Œ≥ (q)|2 and |œà(q)|2 can be allowed
to intersect on different intervals of their domain (of course the functions may
not intersect at all) but under the constraint that at least one probability drawn
from ‚à•Œ≥ ‚à•2 =

R |Œ≥ (q)|2 dM(q) must be different from the probabilities drawn from

R |œà(q)|2 dM(q). Under those conditions, will the change in the information wave
function from œà(q) to Œ≥ (q) trigger arbitrage.
Proof. Since N = K, there will be a unique state price vector ‚àí‚Üí
 =
(1, 2, . . . , K) solving the system of equations set out by the non-arbitrage
theorem. Hence, the probabilities in ‚àí‚àí‚àí‚Üí
prob =

1
0 , 2
0 , 3
0 , . . . , K
0

, where 0 =
exp(‚àírT ) is Ô¨Åxed, are also unique. Those probabilities are drawn from ‚à•œà‚à•2 =

R |œà(q)|2 dM(q), for each of the respective set of lower and upper bound values
of the integral. Now let us consider an information wave function of a different
functional form, Œ≥ (q). This information wave function cannot be the dual of the
information wave function œà(q). As pointed out by one of the referees of the paper,
the space of the information wave functions (with the Hermitian inner product) is
a Hilbert space. As the referee points out, ‚ÄúHence (by the Riesz Lemma), the dual
and bidual spaces are conjugate isomorphic, respectively isometrically isomorphic
to the Hilbert space.‚Äù In that case, the result will not hold. Keeping this in mind,
we do allow both |œà(q)|2 and |Œ≥ (q)|2 to overlap on different intervals (of course,
the functions may not overlap at all) in their domain. However, the overlap is per-
missible up to the point where we require, for the same respective set of lower and
upper bound values of the integrals, that at least one probability value generated
by ‚à•Œ≥ ‚à•2 =

R |Œ≥ (q)|2 dM(q) must be different from any of the probability values
generated by ‚à•œà‚à•2 =

R |œà(q)|2 dM(q). Without this restriction, the two different
functions could possibly overlap on intervals of their domain in such a way to gen-
erate (for the same lower and upper bound values of the integrals) exactly the same
10 Thanks to one of the referees for pointing out this important restriction.

202
Other applications to economic/Ô¨Ånancial theory
probabilities. We are now sure that the different functional form of the information
wave function will induce at least one different probability. Therefore, the emerging
probability vector ‚àí‚àí‚àí‚Üí
‚àó‚àó‚àó
prob =

‚àó‚àó‚àó
1
0 , ‚àó‚àó‚àó
2
0 , ‚àó‚àó‚àó
3
0 , . . . , ‚àó‚àó‚àó
K
0

, which has now probabili-
ties uniquely drawn from ‚à•Œ≥ ‚à•2 =

R |Œ≥ (q)|2 dM(q) will contain at least one state
price in ‚àí‚àí‚Üí
‚àó‚àó‚àó= (‚àó‚àó‚àó
1 , ‚àó‚àó‚àó
2 , . . . , ‚àó‚àó‚àó
K ) such that ‚àí‚àí‚Üí
‚àó‚àó‚àóÃ∏= ‚àí‚Üí
 . Hence, there must
be arbitrage.
‚ñ†
We make the following three remarks.
1. It is feasible to trigger arbitrage by only changing the upper and lower bound
values of the integral and keeping the functional form of the wave function
unchanged. In this sense, can q be interpreted as the price of information. Since
arbitrage is dependent on information, a change in the price of information
could trigger arbitrage. We can think of the price of information as the price
of proprietary information for instance. A change in the functional form of the
information wave function would then indicate a change in the information
about the price of information.
2. If we allow a change can occur in the risk free interest rate, r, so that 0 is not
Ô¨Åxed anymore, then the change in the functional form of the information wave
function from œà(q) to Œ≥ (q) could induce a change from the risk free rate of
return r to another rate of return, say R, which is non-risk free. The difference
between R ‚àír could be denoted as a risk premium (or a risk discount) if,
respectively, the difference is positive or negative. Alternatively, we could also
change T , although that would have little economic meaning. Clearly, in both
cases the state prices will also need to change since the probabilities need to
continue to add up to unity.
3. Our proposition will not necessarily hold for the case where N > K since in this
case we may obtain more than one set of state price vectors guaranteeing non-
arbitrage. Hence, for a different functional form Œ≥ (q) it could still be possible
we Ô¨Ånd state prices guaranteeing non-arbitrage.
Using the conditions contained in the above proposition, we observe that
in the case when N = K a change in the information wave function from
œà(q) to Œ≥ (q) will change the state price vector ‚àí‚Üí
 = (1, 2, . . . , K) to
‚àí‚àí‚Üí
‚àó‚àó‚àó= (‚àó‚àó‚àó
1 , ‚àó‚àó‚àó
2 , . . . , ‚àó‚àó‚àó
K ) such that ‚àí‚àí‚Üí
‚àó‚àó‚àóÃ∏= ‚àí‚Üí
 . We need at least one state
price in ‚àí‚àí‚Üí
‚àó‚àó‚àówhich is different from the state prices in ‚àí‚Üí
 . We know that the Ô¨Årst
state price, 1, multiplies all the prices contained in the N-dimensional asset price
vector corresponding to state 1. We continue doing this for all K states. Neftci [4]
(pp. 19‚Äì20) provides for an interesting interpretation of the state prices and likens
them to prices used in an insurance policy. As an example, consider the price of
asset 2 at time 0, which we denote as p2
0. An investor could be willing to pay 1

13.7 Wave function and non-observed state prices
203
units for an ‚Äúinsurance policy‚Äù that offers D21 units of currency if state 1 (at time
1) is to occur (but the insurance pays nothing if any other state than state 1 occurs).
The investor could be willing to pay 2 units plus 1 units for an ‚Äúinsurance
policy‚Äù that offers D22 units of currency if state 2 (at time 1) is to occur and D21
units of currency if state 1 (at time 1) is to occur (but the insurance pays nothing if
any other state than states 1 and 2 occur). If the investor wants to insure that he gets
a payoff no matter what state occurs, then he will be willing to pay an ‚Äúinsurance
policy‚Äù of 1 + 2 + ¬∑ ¬∑ ¬∑ + K.
In order to connect our theory with Bohmian mechanics, we would need to intro-
duce the idea of a continuous state space. We would then, in light of the above, have
a continuum of ‚Äúinsurance policy‚Äù prices. In a Bohmian mechanics environment,
we would have a continuum of information prices, q, and the information wave
functions would change following the Schr¬®odinger partial differential equation. So
the information about the information prices changes as well as the information
prices themselves. Those changes will then affect the ‚Äúinsurance policy‚Äù prices.
So we could in physics terms, imagine there exists a smooth information price
trajectory which is traced out by the Newton‚ÄìBohm equation (which we already
covered as equation (6.16), in Chapter 6.
md2q(t)
dt2
= ‚àí‚àÇV (q)
‚àÇq
‚àí‚àÇQ(q)
‚àÇq
,
(13.1)
subject to the initial conditions that q(t = 0) = q0 and q‚Ä≤(t = 0) = q
‚Ä≤
0 , where q0
is the information price at t = 0 and q
‚Ä≤
0 is momentum at t = 0. We note that m is
mass and d2q(t)
dt2
is acceleration, ‚àí‚àÇV (q)
‚àÇq
is the partial derivative of the real potential
towards the information price, and ‚àí‚àÇQ(q)
‚àÇq
is the partial derivative of the quantum
potential towards the information price. We note that m, the real potential V , and
the quantum potential Q have already been interpreted economically in the work
by Khrennikov [5] [6] [7], Choustova [8], and Haven [9] [10] [11]. In Bohmian
mechanics, since the quantum potential, Q, depends on the wave function (via
the amplitude function of the wave function), we can say the wave function steers
the particle. Thus, in the context we have now described, the information about the
price of information (i.e. the information wave function) steers the information
prices. Moreover, it seems reasonable to claim that the smooth information price
trajectory on the prices of information would also trigger a trajectory of ‚Äúinsurance
policy‚Äù prices. In summary, we have obtained, via the use of the information wave
function, a natural device by which we can induce either arbitrage or form a risk
premium (or risk discount). Those two Ô¨Ånancial phenomena are essential in asset
pricing and hence we can begin to see the importance of the information wave
function in an asset pricing context.

204
Other applications to economic/Ô¨Ånancial theory
13.8 Price and superposition of values
The above approach looked at a wave function and non-observed state prices. Are
there other approaches where non-observed quantities can be rationalized with
the help of a wave function? Recall the approach we discussed in Chapter 3,
Section 3.1, where Baaquie and Martin [12] (p. 11) describe the psyche of an
individual ‚Äúas being represented by a state vector, denoted as |P > ‚Äù which is an
element of a state space (linear vector space). We could think of the price state
of an asset as the superposition of values of the asset. The value of the asset
would be a subjective (unobserved measure), while the price state is an observed
measure. Those values of assets could be formed from pools of investors who react
to information of the market in a variety of ways. However, we must emphasize that
the value is unobserved. Thus, the idea would be that the value would be equivalent
to the ‚Äúanti-chamber‚Äù stage (or maybe ‚Äúgestation‚Äù stage) before investors decide to
buy or sell an asset at a given (observed) price. The same machinery from Baaquie
and Martin [12] can now be used. Values may be orthogonal to each other:11 <Value
Traders Group 1|Value Traders Group 2 >= 0. In words, traders in group 1 do not
share any common belief as to the value of the asset with traders of group 2. This
could be the case if we think of so-called ‚Äúfundamental traders‚Äù (as Group 1 traders)
versus ‚Äúnoise traders‚Äù (as Group 2 traders). In analogy with Baaquie and Martin‚Äôs
approach [12] (p. 12) of deÔ¨Åning the individual‚Äôs psyche as a superposition of idea
states, we can deÔ¨Åne the price state of an asset as the superposition of different
states, which have emerged from the different groups of traders who participate in
the buying and selling process. We could then write that the price state of an asset
A = |A‚ü©= c1|V G1‚ü©+ c2|V G2‚ü©+ c3|V G3‚ü©+ ¬∑ ¬∑ ¬∑ + cN|V GN‚ü©. As before, the
squared modulus of the complex number ci can be interpreted as the probability
of each of the values in |A‚ü©. Remark also that V G1, V G2, . . . , V GN indicate
the values given to the asset from the traders in the N different trading groups.
‚ÄúFree will‚Äù (as in Baaquie and Martin [12] (p. 16)) can again be invoked here.
But this ‚Äúfree will‚Äù now has very much a Ô¨Ånancial ‚ÄúÔ¨Çavour.‚Äù The choice of states,
in the asset price state formation process is decided by whom? The answer may
well be that, depending on the inÔ¨Çuence various trading groups have, this choice
will be auto-determined via the weights of those groups. There is then also the
scale dependency which we discussed in Chapter 3, Section 3.1. Such dependency
would refer back to the ‚Äúcontext‚Äù of the price state. The context could be the type
of market to which the price state refers to. Maybe the state price is connected to
a very local stock market exchange. This could be the case if the asset is a very
country speciÔ¨Åc asset (i.e. for a product which is not sold outside of the country
11 In Baaquie and Martin [12] , ideas were orthogonal to each other (see p. 12 in that paper).

13.8 Price and superposition of values
205
but produced by a very large company which can be stock exchange traded). The
state price‚Äôs context could be connected to a much larger stock market (i.e. it could
be traded virtually simultaneously (assuming comparable time zones) on many
different stock market exchanges). This could be the case of banking stocks which
trade globally. The information exchange level is indeed very different from one
context to the other.
An important issue which needs mentioning is the existence of incompatible
observables. In this case, we could mention that one observable variable is ‚Äúprice‚Äù
and the ‚Äútime change of price‚Äù would be the other observable variable. Both
variables cannot be simultaneously observed. See for instance Baaquie [13]. Traders
are the ‚Äúobservers‚Äù as they cause the price change because of the act of selling and
buying. We can also come up with other possibilities. Assume for instance that the
Ô¨Ånancial market could be seen as divided by ‚Äúgreed-driven‚Äù traders (i.e. traders
who are interested solely in making money) and ‚Äúfear-driven traders‚Äù (traders
who are primordially driven by safeguarding invested capital). Assume there is
heavy volatility in the Ô¨Ånancial markets with a deÔ¨Ånite short to medium outlook
that markets will end up in a downward spiral. The practice of so-called ‚Äúshort
selling‚Äù consists in a broker selling shares at a price, p, on behalf of an investor.
It is important to stress that the broker borrows the shares from another investor.
Assuming the price of the asset drops, the investor will buy the shares at the price
p1 < p and will make a per share proÔ¨Åt (before transaction costs) of p ‚àíp1. In
case the price rises after the selling, the short seller makes no money. The act
of short selling can very much trigger a massive sell off on shares, since it can
trigger price drops. This is the main reason why in very volatile markets, with
serious downward pressure, short selling can be prohibited by governments.12
Consider now the ‚Äúfear-driven‚Äù trader. In a heavily volatile market with strong
downward pressure, the trader may sell and this may cause further price drops if
there exist many ‚Äúfear-driven‚Äù traders. The ‚Äúgreed-driven‚Äù traders may sell too,
and will opt for the speciÔ¨Åc trading route which we described above, i.e. short
selling. This can only accelerate price drops, if sufÔ¨Åcient ‚Äúgreed-driven‚Äù traders
exist. The two incompatible variables (observables) here could be (i) the price
velocity, i.e. the price momentum, and (ii) the price acceleration. If a market were
to only exist with ‚Äúfear-driven‚Äù traders, then one could make possibly the argument
the acceleration in price drops would be constant. But if ‚Äúgreed-driven‚Äù traders are
added to the market, this acceleration could become random. If both traders were
to be present in the market, then we could make the argument that both observables
(price momentum and price acceleration) are not simultaneously observable. Of
course, one could also make the argument that even with the sole presence of
12 During the 2008 crisis, short selling was for a period of time banned by government order in certain countries.

206
Other applications to economic/Ô¨Ånancial theory
either ‚Äúfear-driven‚Äù or ‚Äúgreed-driven‚Äù traders, there could be randomness on the
momentum of price and the acceleration of price. Thus, here are possibly two
different incompatible observables: price momentum and price acceleration, as
opposed to price momentum and price position.
Before concluding, we would also like to mention that there may well be an
interesting link between the simultaneous observability of variables and the concept
of arbitrage we have discussed before. We could propose that the existence of non-
arbitrage on an asset is equivalently translatable as the existence of simultaneous
observation (of all possible traders) of this asset‚Äôs price over all the world Ô¨Ånancial
trading places.13 Such a type of observation is in reality not feasible, as it would
require transmission of information at speeds which are well beyond the optic
Ô¨Åbre transmission speeds. But if one were to think of this ‚Äúequivalence‚Äù as being
theoretically feasible, then the argument may well invite another possible idea
which may merit mentioning. It seems to be the case that the occurrence of arbitrage,
via its connection to the existence of a martingale, may indeed have ties to the non-
existence of the Hermiticity of an operator. We discussed this in Section 13.1
of this chapter. Hermiticity, we realize is not the sole deÔ¨Åning characteristic of
quantum mechanics, but it is still a very important aspect. The non-simultaneity
of observation of variables is also in itself not a deÔ¨Åning characteristic of quantum
mechanics. However, again, it is an important characteristic since non-simultaneous
observation can be linked back to so-called incompatible observables. Such link
back has a historical connotation which can be traced to Bohr. See Khrennikov
[14] (p. 48). Here again, only simultaneous observation on an asset‚Äôs price over
all stock exchanges would guarantee the existence of non-arbitrage. We may have
therefore a nascent feeling that the existence of arbitrage may be connected to
non-simultaneous observation or the existence of Hermiticity.
We have so far considered some possible interpretations of the quantum-like
wave function in an economics and Ô¨Ånance context. More ideas on how such a
wave function may tie into economics and Ô¨Ånance will be provided in the next
sections of this chapter. Up to this point in the book, we considered the wave
function as representing the expectations of Ô¨Ånancial traders in a market or also as
being the result of the wave packet construction (via the Fourier integral). Soros‚Äô
idea of reÔ¨Çexivity would Ô¨Åt in quite well in such a construction. We also considered
the wave function as a put or call function and we also looked into the possibility
of using the wave function in the context of superposing values and non-observed
state prices.
We can argue that the applications of the quantum formalism to economics,
Ô¨Ånance, and behavioral science can be considered as a theoretical experiment on
the fundamentals of quantum mechanics. The fundamental principles of quantum
13 For ease of purpose, we assume that transaction costs and currency costs could be instantaneously determined.

13.10 Arbitrage and negative probabilities
207
mechanics can be modiÔ¨Åed to match new domains of applications. Such an activity
induces a variety of novel quantum-like models. In effect, it can be considered as the
testing of the coupling between different quantum postulates and the possibilities
of their modiÔ¨Åcation.
13.9 References
[1] Baaquie, B. (2008). Quantum mechanics and option pricing. In Quantum Interaction.
Eds. Bruza, P., Lawless, W., van Rijsbergen, K., Sofge, D. A., Coecke, B., and Clark,
S. Proceedings of the Second Quantum Interaction Symposium (Oxford University).
College Publications, pp. 49‚Äì53.
[2] MacKenzie, D. and Millo, Y. (2005). Negotiating a market, performing a theory:
the historical sociology of a Ô¨Ånancial derivatives exchange. American Journal of
Sociology, 109, 107‚Äì145.
[3] Haven, E. (2008). The variation of Ô¨Ånancial arbitrage via the use of an information
wave function. International Journal of Theoretical Physics, 47, 193‚Äì199.
[4] Neftci, S. (2000). An Introduction to the Mathematics of Financial Derivatives. Aca-
demic Press, New York.
[5] Khrennikov, A. Yu. (1999). Classical and quantum mechanics on information spaces
with applications to cognitive, psychological, social and anomalous phenomena.
Foundations of Physics, 29, 1065‚Äì1098.
[6] Khrennikov, A. Yu. (2004). Information Dynamics in Cognitive, Psychological and
Anomalous Phenomena. Series in the Fundamental Theories of Physics. Kluwer,
Dordrecht.
[7] Khrennikov, A. Yu. (1999). Interpretations of Probability. VSP International Publish-
ers, Utrecht.
[8] Choustova, O. (2006). Quantum Bohmian model for Ô¨Ånancial markets. Physica A,
374, 304‚Äì314.
[9] Haven, E. (2005). Pilot-wave theory and Ô¨Ånancial option pricing. International Jour-
nal of Theoretical Physics, 44, 1957‚Äì1962.
[10] Haven, E. (2005). Analytical solutions to the backward Kolmogorov PDE via an
adiabatic approximation to the Schr¬®odinger PDE. Journal of Mathematical Analysis
and Application, 311, 439‚Äì444.
[11] Haven, E. (2008). Private information and the ‚Äúinformation function‚Äù: a survey of
possible uses. Theory and Decision, 64, 193‚Äì228.
[12] Baaquie, B. and Martin, F. (2005). Quantum psyche: quantum Ô¨Åeld theory of the
human psyche. NeuroQuantology, 1, 7‚Äì42.
[13] Baaquie, B. (2005). Quantum Finance. Cambridge University Press.
[14] Khrennikov, A. (2010). Ubiquitous Quantum Structure: From Psychology to Finance.
Springer Verlag.
13.10 Arbitrage and negative probabilities
Feynman [1] introduced the idea of using negative probabilities in the context of
the Young double slit experiment (see Chapter 5, Section 5.3). Scully et al. [2]
indicate that Feynman used the concept of negative probability (quasiprobability
(Wigner-like) distributions) to explain why a particle goes through both holes in the
Young double slit experiment (see Chapter 5, Section 5.3). Burgin [3] quotes Dirac

208
Other applications to economic/Ô¨Ånancial theory
[4] who said that ‚ÄúNegative energies and probabilities should not be considered
as nonsense. They are well-deÔ¨Åned concepts mathematically, like a negative of
money.‚Äù For more background on probability concepts in quantum mechanics,
see Khrennikov [5] and also Suppes [6]. The book by Espen Haug [7], provides
for an excellent overview of some of the work of the top academics in Ô¨Ånance
and probability. There are two relevant chapters: (i) a chapter entitled ‚ÄúAndrei
Khrennikov on negative probabilities‚Äù (Haug [7], pp. 315‚Äì322) and (ii) a chapter
entitled ‚ÄúWhy so negative about negative probabilities‚Äù (Haug [7] (pp. 323‚Äì333)).
We urge the reader to peruse those two chapters so as to get well acquainted with
the notion of negative probability.
In social science, negative probabilities are a taboo subject. It may be ‚Äúpsy-
chologically‚Äù more convenient to use the term ‚Äúnegative weights‚Äù instead.14 One
of the authors of this book (Khrennikov) published one of his Ô¨Årst papers on
negative probability (jointly with O. G. Smolyanov under the recommendation
of Professor Kolmogorov) in Doklady of the Academy of Sciences of the USSR.
Khrennikov also shows the connection between negative probabilities and so-called
p-adic probability theory [8] [9]. See Khrennikov [5] for more detail, but see
also Khrennikov [10] for an application of p-adic probability theory to quantum
physics, to describe negative probability distributions. In the area of social sci-
ence, p-adic probability theory sheds new light on the St. Petersburg paradox. See
Khrennikov [11].
Let us consider the binomial option pricing model which we mentioned in
Chapter 2, Section 2.7. We consider a simple example from Haug [7] (p. 325),
which provides for a simple extension on the basic model.
Example 20 Consider the following example. The asset price, S, is $100. The
time to maturity, T , is 6 months: T = 0.5. The volatility of the asset is: œÉ =
2% and the risk free rate of interest is 12%. Assume six time steps and hence

t =
1
12 = 0.08. Assume that the up proportion is given by the formulation u =
eœÉ
‚àö

t = e0.02(‚àö0.08) = 1. 006, and similarly for the down proportion d = e‚àíœÉ
‚àö

t =
e‚àí0.02(‚àö0.08) = 0.994 2. The risk neutral probability can then be calculated as p1 =
e0.12(0.08)‚àí0.9942
1.006‚àí0.9942
= 1.309. The complement probability then becomes p2 = 1 ‚àíp1 =
1 ‚àí1.309 = ‚àí0.309. Note that to make the probability negative we must impose
that œÉ <
r
‚àö

t
 = 0.02 < 0.12
‚àö
0.08 = 0.03 (see Haug [7] (p. 325)). The value
of the asset price in the up state is given by pSu = 1.309(100(1.006)) = 131.69
and the value of the asset price in the down state is given by ‚àí0.309(100(0.9942)) =
‚àí30.721.
14 Thanks to Karl Gustafson for bringing up this argument.

13.10 Arbitrage and negative probabilities
209
Clearly, the negative price in the above example is outside the sample space. As
Haug [7] (p. 326) proposes: why therefore not call it the ‚Äúhidden state‚Äù of the stock
price? Furthermore, since risk neutral probabilities do not measure anything, we
may wonder why negative probabilities would be so extraneous in this context.
An alternative formulation is as follows. Consider the risk neutral probability
which one obtains out of the binomial option pricing model. If we opt for so-called
non-continuous compounding, then the risk neutral probability can be written
as p = 1+r‚àíd
u‚àíd . The relationship between arbitrage and the existence of negative
probabilities can be shown to occur immediately if we consider the statement by
Bj¬®ork [12] (p. 8), which says that there does not exist arbitrage if and only if
d ‚â§1 + r ‚â§u. The proof of this theorem is instructive. We slightly adapt it from
Bj¬®ork [12] (p. 8).
r (I) =‚áí: d ‚â§1 + r ‚â§u implies no arbitrage. This part of the proof shows the
contrapositive of (I): if there is arbitrage, then d ‚â§1 + r ‚â§u does not hold.
Assume a portfolio h = (x, y), where x is the number of bonds in the portfolio
and y is the number of units of stock in the portfolio. Assume there exists a
stochastic variable Z which takes on either (i) the value u with probability pu
or (ii) the value d with probability pd. Consider the value of a portfolio at time
t = 0, V h
0 = x + ys, where s is the stock price. DeÔ¨Åne the value of the portfolio
at time t = 1, V h
1 = x(1 + r) + ysZ. There will be arbitrage if V h
0 = 0 and
V h
1 > 0 (i.e. you get ‚Äúsomething (V h
1 > 0) for nothing (V h
0 = 0)‚Äù). Let V h
0 = 0;
this means x = ‚àíys. Substituting this into V h
1 = ‚àíys(1 + r) + ysZ. If Z = u,
V h
1 = ys [u ‚àí(1 + r)]. If Z = d, V h
1 = ys [d ‚àí(1 + r)] . Assuming that y > 0,
then h is an arbitrage strategy if and only if u > 1 + r and d > 1 + r, which
violates the proposition. For the case y < 0, using the same procedure, one
obtains u < 1 + r and d < 1 + r, which again violates the proposition.
r (II) ‚áê=:no arbitrage implies d ‚â§1 + r ‚â§u. This part of the proof shows the
contrapositive of (II): if d ‚â§1 + r ‚â§u does not hold, then there is arbitrage.
Assume s(1 + r) > su, then surely s(1 + r) > sd, and then you invest always
in the bond as opposed to the stock. Therefore, let h = (s, ‚àí1) (i.e. you sell
stock (negative sign) and buy bonds). Then V h
0 = x + ys = s ‚àís = 0. Recall
V h
1 = x(1 + r) + ysZ and substituting h = (s, ‚àí1), one obtains: V h
1 = s(1 +
r) ‚àísZ > 0 by the assumption we made. Therefore, there exists arbitrage.
In Jammer [13] (p. 256) ‚ÄúDeÔ¨Ånition I‚Äù of a hidden variable is as follows: ‚ÄúIn a
given theory T about certain physical systems S certain variables v describe the
states of S; in a theory T ‚Ä≤ about S certain variables v‚Ä≤ (which may be dynamical
quantities or other hypothetical entities) which are not experimentally detectable
within the framework of T describe the states of S; if the values of v. . . can be
obtained by some averaging operation over the values of v‚Ä≤, (then) v‚Ä≤ are called

210
Other applications to economic/Ô¨Ånancial theory
hidden variables with respect to T .‚Äù If we apply Jammer‚Äôs statement to the non-
arbitrage context, then we can say:
r The ‚Äústate prices‚Äù used in the calculation of risk neutral probabilities (see this
chapter,15 Section 13.7 or see also Chapter 4, Section 4.18.3) are unobserv-
able. Call those v‚Ä≤. The risk free rate of interest, R, is observable. An asset
with price A(t) at time t can be carried forward in the future A(t)(1 + R) =
1
0 A1(t + 1) + 2
0 A2(t + 1), where i
0 is part of the probability vector
‚Üí
 which
was deÔ¨Åned before16 and i describe the states of nature; Ai are the prices in
the future, depending on the state of nature occurring. Call this R, thus v.
r In some sense, we can obtain v by ‚Äúsome averaging‚Äù17 operation over the values
v‚Ä≤: 1 + R =
1
0 A1(t+1)+ 2
0 A2(t+1)
A(t)
.
Before moving to the next section of this chapter, let us reiterate some key issues
which may have arisen so far. When considering quantum mechanical applications
to social science, one needs to keep carefully in mind that one is not importing
quantum physics, as a physical theory, into social science. Khrennikov in the preface
of his book (Khrennikov [14]) stresses this quite clearly. Recall the discussion we
had on the non-Hermiticity of a very important Hamiltonian, i.e. the Black‚ÄìScholes
Hamiltonian. This discussion shows us that doing otherwise, i.e. pretending that
there is some trace of quantum mechanics in the macroscopic world, can be a
very difÔ¨Åcult position to take. Any quantum system implies the use of Hermitian
operators.
So caution is of importance here. The message remains: we use quantum mechan-
ical principles in social science to potentially better explain certain phenomena in
that macroscopic setting. This does not mean that anything quantum mechanical is
as such manifest in the macroscopic world.
13.11 References
[1] Feynman, R. (1987). Negative probabilities in quantum mechanics. In Quantum Impli-
cations. Eds. Hiley, B. and Peat, F. Routledge & Kegan Paul.
[2] Scully, M. O., Walther, H., and Schleich, W. (1994). Feynman‚Äôs approach to negative
probability in quantum mechanics. Physical Review A, 49, 3, 1562‚Äì1566.
[3] Burgin, M. (2012). Interpretations of negative probabilities. Cornell University
Library, http://arxiv.org/ftp/arxiv/papers/1008/1008.1287.pdf
[4] Dirac, P. A. M. (1942). The physical interpretation of quantum mechanics. Proceed-
ings of the Royal Society London (A180), 1‚Äì39.
15 Just above Proposition 19.
16 See this chapter, Section 13.7 or see also Chapter 4, Section 4.18.3.
17 Indeed ‚Äúsome‚Äù averaging operation. . . : i.e. the weighted average is divided by some price A(t) . . .

13.12 The Li‚ÄìZhang and WKB approach
211
[5] Khrennikov, A. Yu. (2009). Interpretations of Probability. 2nd edition. De Gruyter,
Berlin.
[6] Suppes, P. (1961). Probability concepts in quantum mechanics. Philosophy of Science,
28, 4, 378‚Äì389.
[7] Haug, E. (2007). Derivatives: Models on Models. J. Wiley.
[8] Khrennikov, A. Yu. (1992). p-adic probability and statistics. Doklady Akademii Nauk
(Proceedings of the Russian Academy of Sciences), ser. Math., 322, 1075‚Äì1079.
[9] Khrennikov, A. Yu. (1993). Discrete Qp-valued probabilities. Doklady Akademii
Nauk (Proceedings of the Russian Academy of Sciences), ser. Math., 333, 162‚Äì164.
[10] Khrennikov, A. Yu. (1997). Non-Archimedean Analysis: Quantum Paradoxes,
Dynamical Systems and Biological Models. Kluwer, Dordrecht.
[11] Khrennikov, A. Yu. (1994). p-adic Valued Distributions in Mathematical Physics.
Kluwer, Dordrecht.
[12] Bj¬®ork, T. (1998). Arbitrage Theory in Continuous Time. Oxford University Press.
[13] Jammer, M. (1974). The Philosophy of Quantum Mechanics. J. Wiley.
[14] Khrennikov, A. (2010). Ubiquitous Quantum Structure: From Psychology to Finance.
Springer Verlag, Berlin.
13.12 The Li‚ÄìZhang and WKB approach
At the end of Chapter 2 (Section 2.11), we mentioned some of the work by Li
and Zhang, which maps option pricing functions into wave functions. We also
mentioned related work, using the WKB method. In this section of this chapter, we
provide for some details on those two approaches.
Two papers by Li and Zhang argue for the use of the so-called Weyl‚ÄìTitchmarsh
theory in option pricing. They are Ô¨Årst the 2004 paper by Li and Zhang [1] and
second an update paper by Zhang and Li [2], which appeared in 2012.
In Li and Zhang [1], it is shown that option pricing can be modeled via the use
of the Schr¬®odinger PDE.
In a nutshell, Li and Zhang [1] (p. 459), show that the necessary transformations
to achieve such a pricing approach are that the call function (which is a function
of the stock price, S, and time, t); C(S, t) = ‚àöœÉ(S)g(x, t), where g(x, t) is the
quantum mechanical wave function and œÉ(S) is some volatility function of the
asset price, S. Furthermore, they also set: x(S) = Œ¥

1
œÉ(S)dS, with Œ¥ = +/ ‚àí1.
Equation (7) in Li and Zhang [1] (p. 459) shows that a heat equation on a
call option can be written as ‚àÇC
‚àÇt ‚àíœÉ 2(S) ‚àÇ2C
‚àÇS2 = 0 with initial condition C(S, 0) =
max(S ‚àíK, 0), where K is the strike price. The authors show that equation (7)
can be written as a Schr¬®odinger PDE: ‚àÇg
‚àÇt = ‚àÇ2g
‚àÇx2 ‚àíq(x)g, with g(x, t)|t=0 = g0(x)
(they indicate that g0(x) is deÔ¨Åned from C(S, 0)).
A beautiful interpretation is obtained of a potential function: the function q(x)
is the potential function deÔ¨Åned as 1
4
 dœÉ(S)
dS
2 ‚àí1
2œÉ(S)

d2œÉ(S)
dœÉ(S)2

. See Li and Zhang

212
Other applications to economic/Ô¨Ånancial theory
[1] (p. 459). The authors also mention that when q(x) is a quadratic function of x,
one can then transform the above Schr¬®odinger PDE into a standard heat equation.
The practical utility of the Li and Zhang approach is important. For instance, in
their paper they provide for a sophisticated volatility function of the form œÉ(S) =
S

œÉ 2 + œµ2

ln S
S0
2
, with œµ > 0 a small parameter and œÉ > 0 and S0 > 0 (see Li
and Zhang [1] (p. 461)). Using the transformation x(S) = Œ¥

1
œÉ(S)dS, they then
Ô¨Ånd in this speciÔ¨Åc case that x = 1
œµ sinh‚àí1 œµ
œÉ ln S
S0 with S = S0 exp
 œÉ
œµ

sinh œµx

.
The potential function q(x) = 1
4l(S) + 1
4œµ2 ‚àí3
4
œÉ 2œµ2
4l(S), and l(S) = œÉ 2 cosh2 œµx. The
authors indicate that if œµ ‚Üí0, then q(x) ‚ÜíœÉ 2
4 . A solution is found for g(x, t) in
the paper.
Another volatility function, the so-called exponentially decreasing volatility of
the form œÉ(S) = exp(‚àíS) is also treated. A solution for g(x, t) is also presented
for this case. See Li and Zhang [1] (p. 462).
Table 1 in Li and Zhang [1] (p. 463), provides for a very interesting overview of
potential functions for which solutions for g(x, t) exist.
An update on the 2004 paper is provided for in Zhang and Li [2]. In that paper
other interesting potential functions are considered (with associated solutions).
A different approach can be proposed by using the so-called WKB technique in
option pricing. We follow here closely, Haven [3]. The so-called WKB approxima-
tion, by Bender and Orszag [4], yields a solution, œà(x), to the time-independent
Schr¬®odinger equation.
For that approximation to be senseful, it must satisfy:
¬Øhm
 dR
dx

"
(2m(E ‚àíR))3 ‚â™1,
(13.2)
where R is the potential function (Bohm [5]).18 Note that m is mass, E is total
energy, and ¬Øh is the rationalized Planck constant. See Haven [3] (pp. 440‚Äì441).
In Haven [3], we also mention that when using Bohm [5], the solution for œà(x)
using the WKB approximation:
œà(x) = œë(x)e

i
 x
x0
‚àö2m(E‚àíR) dx
¬Øh

+ Œ∏(x)e

‚àíi
 x
x0
‚àö2m(E‚àíR) dx
¬Øh

,
(13.3)
where œë(x) =
A
4‚àöE‚àíR(x) and Œ∏(x) =
B
4‚àöE‚àíR(x) and A and B are constants. Those
coefÔ¨Åcient A and B can be determined via an initial value problem.
As we have seen in Chapter 2, the Black‚ÄìScholes PDE is a so-called backward
Kolmogorov PDE. The backward Kolmogorov PDE is of the form ‚àÇp
‚àÇt + b(y,t)2
2
‚àÇ2p
‚àÇy2 +
18 Although this book is authored by David Bohm, the book does NOT discuss ‚ÄúBohmian mechanics,‚Äù as
deÔ¨Åned in Chapter 6. Hence, the application considered in this section of the book (Section 13.12) does
not have a connection with Bohmian mechanics.

13.12 The Li‚ÄìZhang and WKB approach
213
a(y, t) ‚àÇp
‚àÇy = 0. Clearly, depending on the functional forms of b(y, t) and a(y, t),
the solution approaches (and solutions) will vary substantially. Note that p is a
probability density function. As in Haven [3] (p. 441), if we let a(y, t) and b(y, t)
be time independent functions and let a(y, t) be a constant function, then the
claims we make in that paper (Haven [3] (Claim 2 (p. 441)) is that the essential
transformation needed for using the WKB approximation in solving the backward
Kolmogorov PDE are: (a) x = g(b(y)) and (b) œà(x) = f (p(y, t)). When we apply
those transformations to the Black‚ÄìScholes PDE, we need to set: (a) x = g(œÉ(S))
and (b) œà(x) = f (p(S, t)). Furthermore, we need a semigroup operator, d, which
relates p(S, t) with the option price V (S, t) : V (S, t) = dp(S, t). In this Ô¨Ånance
problem, ¬Øh2
2m = 1.
As expressed in criterion 6 in Haven [3] (p. 442), the WKB approximation is
appropriate when, after using E = p2
¬Øh2 , the inequality ¬Øh3
2
 dR
dx

‚â™
"
(p2 ‚àí¬Øh2R)3 is
respected.
We now reproduce19 the paper by Haven [3] (latter part of p. 442 and p. 443).
Bender and Orszag [4] provide for an initial value problem where,
if they set œà(x) = 0 for x = 0 and
dœà(x)
dx |x=0 = 1, they obtain as WKB
solution:
œà(x) = œÇ(S) sinh
+‚àö
2m
i¬Øh
 S
0
"
E ‚àíR(t)dt
,
,
(13.4)
with œÇ(S) =
i¬Øh
‚àö
2m
1
4‚àöE‚àíR(0) 4‚àöE‚àíR(S). Note also that t is NOT time, but just the inte-
gration variable.
Let us apply Bender and Orszag‚Äôs initial value problem to our Ô¨Ånancial problem.
A key issue to note is that when using œà(x) = f (p(y, t)), we must make sure
that the conditions œà(0) = 0 and dœà(x)
dx |x=0 = 1 do make Ô¨Ånancial sense. Let us set
y = S and let us deÔ¨Åne, as in the paper by Li and Zhang [1], x(S) =

1
œÉ(S)dS (this
takes care of deÔ¨Åning g(.)).20 Assume we know what d is and let us have for a
given t that V (S, t) = œà(x)‚àöœÉ(S) (this takes care of deÔ¨Åning f (.)). As in Li and
Zhang [1], we propose a quite interesting (i.e. close to reality) volatility function
œÉ(S) = S

œÉ 2 + œµ2

ln S
S0
2
, where the volatility œÉ > 0 and S0 > 0 and œµ is small.
Following, Li and Zhang [1], one can then write x = 1
œµ sinh‚àí1 œµ
œÉ ln S
S0 . To apply the
WKB initial value problem conditions, we need:
19 Emmanuel Haven (2005). Analytical solutions to the backward Kolmogorov PDE via an adiabatic approx-
imation to the Schr¬®odinger PDE. Journal of Mathematical Analysis and Applications, 311, 442‚Äì443.
20 This is Example 7 in Haven [3] (p. 443).

214
Other applications to economic/Ô¨Ånancial theory
1. to see whether the Bohm condition to use WKB can be satisÔ¨Åed: ¬Øh3
2
 dR
dx

‚â™
"
(p2 ‚àí¬Øh2R)3. In effect, R(x) = 1
4œÉ 2 cosh2 œµx + 1
4œµ2 ‚àí3
4
œÉ 2œµ2
œÉ 2 cosh2 œµx and it is
immediate for œµ very small dR
dx ‚Üí0.
2. x = 0 ‚áîS = S0 and in the WKB equation (13.3), after setting x0 = 0, we
get: œà(0) =
A+B
4‚àöE‚àíR(0) =
A+B
4‚àö
E‚àí1
4 œÉ 2+ 1
2 œµ2 = V (S=S0,t)
‚àöœÉ(S0)
= 0. This is deÔ¨Ånitely possi-
ble, from a Ô¨Ånancial point of view, if S0 ‚â™K and hence A = ‚àíB.
3. Given A = ‚àíB, we have that C = dœà(x)
dx |x=0 = (A ‚àíB) 4‚àöE ‚àíR(0)
‚àö
2m
i¬Øh and let
C = 1 so we get: A =
i¬Øh
2
‚àö
2m 4‚àö
E‚àí1
4 œÉ 2+ 1
2 œµ2 and we can now use equation (13.4)
since dœà(x)
dx |x=0 =
d
‚éõ
‚éú‚éú‚éù
V (S,t)
1
2
2
3S
.
œÉ2+œµ2
	
ln S
S0

2
‚éû
‚éü‚éü‚é†
d

1
œµ sinh‚àí1 œµ
œÉ ln S
S0
 |S=S0 = 1 is Ô¨Ånancially feasible.
Therefore, using the relationship between œà(x) and V (S, t) and using the oper-
ator d we will have found an analytical solution to the option pricing backward
Kolmogorov PDE.
13.13 References
[1] Li, Y. and Zhang, J. E. (2004). Option pricing with Weyl‚ÄìTitchmarsh theory. Quanti-
tative Finance, 4, 4, 457‚Äì464.
[2] Zhang, J. E. and Li, Y. (2012). New analytical option pricing models with Weyl‚Äì
Titchmarsh theory. Quantitative Finance, 12, 7, 1003‚Äì1010.
[3] Haven, E. (2005). Analytical solutions to the backward Kolmogorov PDE via an
adiabatic approximation to the Schr¬®odinger PDE. Journal of Mathematical Analysis
and Applications, 311, 439‚Äì444.
[4] Bender, D. and Orszag, S. (1978). Advanced Mathematical Methods for Scientists and
Engineers. McGraw Hill.
[5] Bohm, D. (1951). Quantum Theory. Prentice-Hall.
13.14 The wave function as a Radon‚ÄìNikodym derivative
We can augment our understanding of the wave function in an asset pricing context
by considering some of the results which deal with the measurement of the quantity
of information. In this section we reproduce21 (with only slight modiÔ¨Åcations22) the
paper by Haven [1] (sections 6 until 9 (pp. 751‚Äì755)). To measure the quantity of
21 Emmanuel Haven (2010). The Blackwell and Dubins theorem and R¬¥enyi‚Äôs amount of information measure:
some applications. Acta Applicandae Mathematicae, 109, 3, 751‚Äì755.
22 Mainly condition 27 and the brief discussion preceding that condition provides for the modiÔ¨Åcation.

13.14 The wave function as a Radon‚ÄìNikodym derivative
215
information in the information wave function, we can use a speciÔ¨Åc theorem which
we will highlight below. Before we state the main theorem from the Blackwell and
Dubins paper [2], we need to deÔ¨Åne a so-called predictive probability.
DeÔ¨Ånition 21 (Blackwell and Dubins [2] (p. 882). Predictive probabil-
ity. Let Bi be a œÉ-Ô¨Åeld of subsets of the set Xi, i = 1, 2 . . . Let (X, B) =
(X1 √ó X2 √ó . . . √ó B1 √ó B2 √ó . . . ). Let (X, B, P ) be a probability space and let
Pn be the marginal distribution of (X1 √ó X2 √ó . . . √ó Xn, B1 √ó B2 √ó . . . √ó Bn);
i.e., Pn(A) = P(A √ó Xn+1 √ó . . .) for all A ‚ààB1 √ó B2 √ó . . . √ó Bn. The predictive
probability P is deÔ¨Åned if, for every n ‚â•1, there exists a conditional probability P n
for the future Xn+1 √ó . . . given the past X1, . . . , Xn. That is, if there exists a func-
tion P n(x1, . . . , xn)(C) where (x1, . . . , xn) ranges over X1 √ó X2 √ó . . . √ó Xn and
C ranges over Bn+1 √ó . . . with the usual three properties: (i) P n(x1, . . . , xn)(C)
is B1 √ó B2 √ó . . . √ó Bn measurable for Ô¨Åxed C; (ii) a probability distribu-
tion on (Xn+1 √ó . . . Bn+1 √ó . . .) for Ô¨Åxed (x1, . . . , xn); and (iii) for bounded
B-measurable
œÜ
we
have
that

œÜdP =

[œÜ(x1, . . . , xn, xn+1, . . .)
dP n(xn+1, . . . |x1, . . . , xn)] .dPn(x1, . . . , xn) holds.
DeÔ¨Ånition 22 (Blackwell and Dubins [2] (p. 883)). Distance between distribu-
tions. For any two probabilities Œº1 and Œº2 on the same œÉ‚àíÔ¨Åeld F, the distance
œÅ (Œº1, Œº2) is the least upper bound over D ‚ààF of |Œº1(D) ‚àíŒº2(D)| .
Theorem 23 (Blackwell and Dubins [2] (p. 883)). Let P be a predictive probability
on (X, B) and let Q be absolutely continuous with respect to P. Then for each
conditional distribution P n of the future given the past with respect to P, there
exists a conditional distribution Qn of the future given the past with respect to Q
such that the distance between P n(x1, . . . , xn) and Qn(x1, . . . , xn) converges to
zero as n ‚Üí‚àû.
As is proposed in Nakata [3] (p. 13), we can make the distributions conditional in
such a way that we have P {.|x1, x2, . . . , xt} and Q {.|x1, x2, . . . , xt} so that when
time t ‚Üí‚àûone can say that both distributions agree Q‚Äìa.s. (almost surely). From
an information point of view, the meaning of the theorem indicates that a merging
of opinions (amongst agents) occurs if we assume that there exist two agents who
have as probability measures P and Q. See Nakata [3] (pp. 1, 28, 13). In this sense,
as is well argued in Nakata [3] (p. 13), one can assume mutual absolute continuity
so that both distributions agree Q‚àía.s. and P‚àía.s. Therefore (Nakata [3] (p.
13)), a special case of this mutual absolute continuity is then that P = Q. One
possible interpretation of this equality is that agents in an economy have attained
a state where all asymmetric information has been removed. See again Nakata [3]
(p. 29, 55).

216
Other applications to economic/Ô¨Ånancial theory
The Radon‚ÄìNikodym derivative is a widely used concept in stochastic mathe-
matics and it has applications in many areas, including Ô¨Ånancial theory where it
is used in the theory of Ô¨Ånancial option pricing. Primbs [4] provides for a dense
and excellent background to the measure theoretic issues lying on the back of the
Radon‚ÄìNikodym derivative. To deÔ¨Åne the Radon‚ÄìNikodym derivative, we need
the following ingredients: (1) a set ; (2) a set F which is a collection of subsets
of  (and a œÉ-algebra); (3) two measures, Œº and œÖ; (4) absolute continuity of one
measure with respect to the other measure; and (5) the so-called Radon‚ÄìNikodym
theorem. Let us Ô¨Årst deÔ¨Åne absolute continuity. The deÔ¨Ånition is by Primbs [4].
DeÔ¨Ånition 24 Absolute continuity. Let Œº and œÖ be two measures on the measurable
space (, F), then œÖ is absolutely continuous with respect to Œº if, for any set A,
Œº(A) = 0 ‚áíœÖ(A) = 0.
The Radon‚ÄìNikodym theorem is as follows. We follow again Primbs [4].
Theorem 25 Radon‚ÄìNikodym theorem. If œÖ is absolutely continuous with respect
to Œº, then œÖ(A) =

A gdŒº.
The Radon‚ÄìNikodym derivative is then deÔ¨Åned as follows. We follow again
Primbs [4].
DeÔ¨Ånition 26 Radon‚ÄìNikodym derivative. The function g is known as the Radon‚Äì
Nikodym derivative and denoted as g = dœÖ
dŒº.
In the condition 27, which follows below, we mention there exists a represen-
tative agent and a ‚ÄúspeciÔ¨Åc‚Äù agent. The representative agent can be thought of as
being representative of a trading group. Examples of such trading groups could be
‚Äúfundamental traders‚Äù or also ‚Äúnoise traders.‚Äù Fundamental traders can be seen as
traders who have speciÔ¨Åc Ô¨Ånancial information such as market depth (and other
measures), which they can objectively use in making a trading decision. Noise
traders can be seen as traders who act upon information (which more often than not
could be wholly spurious information). We assume that both types of agents have
knowledge of a measure, which in effect can be a probability density function. We
assume this probability density function can refer to, for instance, rates of return
of a stock or also the price of a stock. We note that in the condition below the wave
function œà(q) is deÔ¨Åned as œà(q) ‚â°R(q) exp((iA(q)), where q is position, R(q) is
the amplitude function, A(q) is the phase, and h is the Planck constant.
Condition 27 |œà(q)|2 as a Radon‚ÄìNikodym derivative. Assume there exists a
representative agent ‚Äú1‚Äù and a speciÔ¨Åc agent ‚Äú2‚Äù who is not part of the represen-
tative‚Äôs agent trading group. The representative agent ‚Äú1‚Äù has a measure œÖ (i.e.
a probability density function) on the return or the price of an asset. The speciÔ¨Åc

13.14 The wave function as a Radon‚ÄìNikodym derivative
217
agent ‚Äú2‚Äù has a measure Œº (i.e. a probability density function) on the return or the
price of an asset. Consider a Hilbert state space of quantum states L2 with respect
to œÖ. Assume that Œº is absolutely continuous with respect23 to œÖ. We assume that
the Radon‚ÄìNikodym derivative dŒº
dœÖ = |œà(q)|2, where œà(q) is the information wave
function of the representative agent ‚Äú1‚Äù.
We remark that |œà(q)|2 as a probability density function is deÔ¨Åned with respect
to the measure œÖ. We could imagine there exist other œà(q) functions which refer
to the speciÔ¨Åc information of other representative agents.
We are now ready to deÔ¨Åne the R¬¥enyi measure of quantity of information as
follows.
DeÔ¨Ånition 28 R¬¥enyi‚Äôs quantity of information measure [5] (pp. 553‚Äì554). Con-
sider P as the unconditional distribution of a random variable and consider Q as
the conditional distribution of the same random variable (obtained from observing
an event E). Let Q be absolutely continuous with respect to P. The amount of infor-
mation I (Q|P) , concerning the random variable obtained from observing E is
given by I (Q|P) =

 log h dQ, where h = dQ
dP is the Radon‚ÄìNikodym derivative
of Q with respect to P.
DeÔ¨Ånition 29 R¬¥enyi‚Äôs information measure [5] and |œà(q)|2. Given the above con-
dition that |œà(q)|2 is a Radon‚ÄìNikodym derivative, we can apply R¬¥enyi‚Äôs quantity
of information measure directly on the information wave function and write that,
using the same variables as in the above condition, I (Œº|œÖ) =

 log |œà(q)|2 dŒº.
We can thus say that |œà(q)|2 has in fact a double interpretation: (i) changing
|œà(q)|2 will affect the probability value and (ii) changing |œà(q)|2 will affect the
quantity of information. We thus see here that |œà(q)|2 has a true information-
theoretic interpretation.
We now want to discuss a little more how R¬¥enyi‚Äôs information measure can be
connected to the Blackwell and Dubins theorem. Let us Ô¨Årst consider the special
case of mutual absolute continuity. In this case, |œà(q)|2 = 1 and, therefore, R¬¥enyi‚Äôs
measure yields zero. In the context of the Blackwell and Dubins theorem, we can
interpret this result somewhat better. In the context of the special case of mutual
absolute continuity, the zero information quantity measure would indicate that all
asymmetric information has been removed. This case occurred because, under the
economic interpretation of the Blackwell and Dubins theorem, Nakata [3] (p. 28)
indicates that there is a merging of opinions. This convergence of measures is
obtained because of communication. Communication removes asymmetric infor-
mation and the highest level of absence of asymmetric information is reached when
23 Compared to the deÔ¨Ånition of absolute continuity, we reverse the measures.

218
Other applications to economic/Ô¨Ånancial theory
I (Œº|œÖ) = 0. In quantum physical terms, we can think of the case |œà(q)|2 = 1 as
the ground state (i.e. the state with minimal total energy). It is not unreasonable
to argue that the representative agent ‚Äú1‚Äù can possibly make gainful use of his
information, transmitted via œà(q), if indeed his information is running counter to
the information possessed by the speciÔ¨Åc agent ‚Äú2.‚Äù The information wave function
would then, in quantum physical terms, have a state with higher than minimal total
energy.
Clearly, by slightly modifying the Blackwell and Dubins theorem, we can induce
a quantity of information measure which is non-zero. Clearly, if t ‚Üõ‚àû, then, using
Nakata‚Äôs [3] (p. 13) interpretation, we cannot possibly have convergence of mea-
sures. Therefore, it is impossible that P {.|x1, x2, . . . , xt} = Q {.|x1, x2, . . . , xt}
using the above terminology. Therefore, it is immediate that, using R¬¥enyi‚Äôs infor-
mation measure, we have that: I (Q|P) =

 log dQ
dP dQ Ã∏= 0.
DeÔ¨Ånition 30 Ambiguity of information. Let œà(q) = œà1(q)œà2(q), then there is
ambiguity of information.
In this equality, the wave function is factorized into an independent product. As
per Bohm and Hiley [6] (p. 61), this could indicate that there exist ‚Äúindependent
pools of information.‚Äù However, the position variable, q, is the same. Hence, this
sort of product could indicate ambiguity of information: we have two sources of
information on the same position variable. The obvious conditions for this equality
to hold is that R(q) = R1(q)R2(q) and A(q) = A1(q) + A2(q).
Proposition 31 R¬¥enyi‚Äôs information measure [5] and ambiguity of information.
Given our condition that |œà(q)|2 is a Radon‚ÄìNikodym derivative and that œà(q) =
œà1(q)œà2(q), we can apply R¬¥enyi‚Äôs information measure directly on the information
wave function and write that, using the same variables as in the above condition ,
I (Œº|œÖ) =

 log |œà|2 dŒº =

 log |œà1|2 dŒº +

 log |œà2|2 dŒº.
Proof. Obvious.
We
can
write
|œà|2 = |œà1 ‚àóœà2|2 =
R1eiA1 ‚àóR2eiA22 =
R1R2ei(A1+A2)2 = R2
1R2
2. But R2
1R2
2 is nothing else other than |œà1|2 |œà2|2 . We
note that we have omitted Planck‚Äôs constant.
‚ñ†
DeÔ¨Ånition 32 Multi-sourced information. Let œà(q1, q2) = œà1(q1)œà2(q2), then
there is multi-sourced information.
Here we have again a factorization into an independent product. Note that each
information wave function refers now to a different position variable. We have two
sources of information on different position variables. Here the requirements for the

13.14 The wave function as a Radon‚ÄìNikodym derivative
219
equality to hold are again obvious: A (q1, q2) = A1(q1) + A2(q2) and R(q1, q2) =
R1(q1)R2(q2).
We now consider postulate 9 in R¬¥enyi‚Äôs 1961 article [5]. This proposition is
valid for discrete distributions and is formulated as follows.
Proposition 33 Postulate 9 in R¬¥enyi [5] (p. 555). Consider I(Q1|P1) and I(Q2|P2)
and let P = P1 ‚àóP2 and Q = Q1 ‚àóQ2, where ‚Äú‚àó‚Äù denoted direct product. Let the
correspondence between the elements of P and Q be induced by the correspondence
between the elements of P1 and Q1 and those of P2 and Q2. Then we can write
that I(Q|P) =I(Q1|P1)+ I(Q2|P2).
It is interesting to see how this postulate would look if we were to use an
information wave function as the basis of the Radon‚ÄìNikodym derivative. Assume
that we draw from positive rational numbers rather than positive real numbers, so
we can keep the correspondence. Therefore, we can use the integral representation
for the quantity of information.
We have the following proposition:
Proposition 34 R¬¥enyi‚Äôs postulate 9 [5] and the information wave function. If
we use |œà1 ‚àóœà2|2, |œà1|2, |œà2|2 as Radon‚ÄìNikodym derivatives in respectively
R¬¥enyi‚Äôs quantity of information measures I(Q|P), I(Q1|P1), I(Q2|P2), then

 log dQ1‚àóQ2
dP1‚àóP2 dQ1 ‚àóQ2 Ã∏=

 log dQ1
dP1 dQ1 +

 log dQ2
dP2 dQ2.
Proof. We observe that
dQ1‚àóQ2
dP1‚àóP2
can be written as the information func-
tion as follows:
dQ1‚àóQ2
dP1‚àóP2 = |œà1 ‚àóœà2|2 . The right-hand side can be written
as:
R1eiA1 ‚àóR2eiA22 =
R1R2ei(A1+A2)2 = R2
1R2
2. But R2
1R2
2 is nothing else
other than |œà1|2 |œà2|2. Therefore, we can write

 log dQ1‚àóQ2
dP1‚àóP2 dQ1 ‚àóQ2 =

 log dQ1
dP1
dQ2
dP2 dQ1 ‚àóQ2 =

 log |œà1|2 dQ1 ‚àóQ2 +

 log |œà2|2 dQ1 ‚àóQ2. From
this, we can clearly see I(Q|P) Ã∏= I(Q1|P1)+ I(Q2|P2).
‚ñ†
Proposition 35 R¬¥enyi‚Äôs postulate 9 [5] and ambiguity of information. If
we have ambiguity of information, then I(Q|P) =

 log |œà|2 dQ1 ‚àóQ2 Ã∏=

 log dQ1
dP1 dQ1 +

 log dQ2
dP2 dQ2.
Proof. Obvious. Clearly, since |œà1 ‚àóœà2|2 = |œà1|2 |œà2|2, we can only write

 log |œà|2 dQ1 ‚àóQ2 =

 log |œà1|2 dQ1 ‚àóQ2 +

 log |œà2|2 dQ1 ‚àóQ2.
‚ñ†
Proposition 36 R¬¥enyi‚Äôs postulate 9 [5] and multi-sourced information. If
we have multi-sourced information, then I(Q|P) =

 log |œà|2 dQ1 ‚àóQ2 Ã∏=

 log dQ1
dP1 dQ1 +

 log dQ2
dP2 dQ2.

220
Other applications to economic/Ô¨Ånancial theory
Proof. Obvious. Since œà(q1, q2) = œà1(q1)œà2(q2), the left-hand side of the non-
equality is integrating a two-dimensional function under dQ1 ‚àóQ2, while the right-
hand side is integrating a one-dimensional function again towards dQ1 ‚àóQ2.
‚ñ†
In conclusion, we have connected the information wave function with the concept
of a Radon‚ÄìNikodym derivative. We have then tried to show how this derivative
could be used in R¬¥enyi‚Äôs quantity of information measure [5]. We also brieÔ¨Çy
alluded to how the derivative could be interpreted in the context of the Blackwell
and Dubins theorem [2]. We also introduced the possible notions of ambiguity of
information and multi-sourced information. Finally, we considered R¬¥enyi‚Äôs postu-
late 9 [5] for the case when we considered an information wave function as the
basis of the Radon‚ÄìNikodym derivative.
13.15 References
[1] Haven, E. (2010). The Blackwell and Dubins theorem and R¬¥enyi‚Äôs amount of informa-
tion measure: some applications. Acta Applicandae Mathematicae, 109, 3, 743‚Äì757.
[2] Blackwell, D. and Dubins, L. (1962). Merging of opinions with increasing information.
Annals of Mathematical Statistics, 33, 882‚Äì886.
[3] Nakata, H. (2000). On the Dynamics of Endogenous Correlations of Beliefs. Ph.D.
Thesis; Stanford University.
[4] Primbs, J. (2006). Measure Theory in a Lecture. http://www.stanford.edu/Àújaprimbs/
MeasureTheory5.ppt. Cited September 28, 2006.
[5] R¬¥enyi, A. (1961). On Measures of Entropy and Information. In Neyman, J. (ed.)
Proceedings of the Fourth Berkeley Symposium on Mathematical Statistics and Prob-
ability, California.
[6] Bohm, D. and Hiley, B. (2005). The Undivided Universe: An Ontological Interpretation
of Quantum Theory. Routledge.
13.16 Universal Brownian motion: deÔ¨Ånition and discussion
13.16.1 Basic steps
The hypothesis of Universal Brownian motion was proposed by Edward Nelson.
The key references for this important work can be found in Nelson [1] [2] [3]. Paul
and Baschnagel [4] provide for an interesting overview of the essential steps in this
hypothesis. Elbaz [5] also gives a good account of Nelson‚Äôs stochastic mechanics.
Recall the Brownian motion (see Chapter 4, Section 4.18.2): dx(t) = b(x, t)dt +
œÉdW(t), where dW(t) is Wiener process. Nelson [1] (p. 1080) deÔ¨Ånes a mean
forward derivative:
Dx(t) = lim

t‚Üí0 E
)x(t + 
t) ‚àíx(t)

t
*
.
(13.5)

13.16 Universal Brownian motion
221
The mean backward derivative is then (Nelson [1] (p. 1080)):
D‚àóx(t) = lim

t‚Üí0 E
)x(t) ‚àíx(t ‚àí
t)

t
*
.
(13.6)
One can write, using the above Brownian motion, what Nelson calls [1]
(p. 1081) ‚Äúmean forward velocity‚Äù as:
Dx(t) = b(x, t).
(13.7)
Similarly (mean backward velocity):
D‚àóx(t) = b‚àó(x, t).
(13.8)
Nelson [1] (p. 1081) then deÔ¨Ånes a current velocity as:
v(x, t) = 1
2 (b(x, t) + b‚àó(x, t)).
(13.9)
As Paul and Baschnagel [4] remark (p. 84) for Newtonian motion, the mean
forward and mean backward derivative will be equal, i.e. D‚àóx(t) = Dx(t) and
hence v(x, t) = D‚àóx(t) = Dx(t) = b‚àó(x, t) = b(x, t).
The osmotic velocity is deÔ¨Åned as (see Paul and Baschnagel [4] remark (p. 84)):
u(x, t) = 1
2 (D ‚àíD‚àó) x(t).
(13.10)
Recall the Fokker‚ÄìPlanck PDE we mentioned in Chapter 2, Section 2.3. Paul
and Baschnagel [4] (p. 84) show (see also Nelson [1] (p. 1081)) that by using the
Fokker‚ÄìPlanck PDE (using the Brownian motion above), one Ô¨Ånds that:
u(x, t) = œÉ 2
2 ‚àáln p(x, t) = œÉ 2
2 1/p(x, t)‚àÇp
‚àÇx ,
(13.11)
where p is a probability density function.
13.16.2 The Universal Brownian motion
Consider the drift in the Brownian motion dx(t) = b(x, t)dt + œÉdW(t). Paul and
Baschnagel [4] (p. 86) indicate (see also Nelson [1] (p. 1083)) that, when using the
polar form of the quantum mechanical wave function, one obtains:
b(x, t) = ¬Øh
m‚àáln R + 1
m‚àáS,
(13.12)
where R is the amplitude function, S is the phase, m is mass, and ¬Øh is the rationalized
Planck constant. Substituting the above equation in to dx(t) = b(x, t)dt + œÉdW(t)

222
Other applications to economic/Ô¨Ånancial theory
yields:
dx(t) =
	 1
m‚àáS + ¬Øh
2m
‚àá|œà|2
|œà|2

dt + dW(t).
(13.13)
We assume here also that the Wiener process has the constraints dW = 0 and
(dW)2 = ¬Øh
mdt. Bacciagaluppi [6] also formulated a stochastic differential equation
like the one above. We note that Bohm and Hiley [7] indicate that ‚àá|œà|2
|œà|2 is osmotic
velocity.
Wallstrom [8] is also an interesting source for more detail on the link between
the Schr¬®odinger equation and stochastic mechanics.
13.17 References
[1] Nelson, E. (1966). Derivation of the Schr¬®odinger equation from Newtonian mechanics.
Physical Review, 150, 1079‚Äì1085.
[2] Nelson, E. (1967). Dynamical Theories of Brownian Motion. Princeton University
Press, NJ.
[3] Nelson, E. (2005). The Mystery of Stochastic Mechanics. http://www.math.princeton.
edu/Àúnelson/papers/talk.pdf.
[4] Paul, W. and Baschnagel, J. (2000). Stochastic Processes: From Physics to Finance.
Springer Verlag, Berlin.
[5] Elbaz, E. (2006). The Quantum Theory of Particle, Fields, and Cosmology. Springer
Verlag, Berlin.
[6] Bacciagaluppi, G. (1999). Nelsonian mechanics revisited. Foundations of Physics Let-
ters, 12, 1‚Äì16.
[7] Bohm, D. and Hiley, B. (1998). Non-locality and locality in the stochastic interpretation
of quantum mechanics. Physics Reports, 172, 93‚Äì122.
[8] Wallstrom, T. C. (1989). On the derivation of the Schr¬®odinger equation from stochastic
mechanics. Foundations of Physics Letters, 2, 2, 113‚Äì126.
13.18 Universal Brownian motion and option pricing
13.18.1 Pricing of information risk
In Chapter 6, Section 6.3, equations (6.14) and (6.15) were the two key equations
which emerged from putting in the polar form of the quantum mechanical wave
function into the Schr¬®odinger equation. In Ishio and Haven [1], it is argued that there
is a connection between Bohmian mechanics and the Nelson approach. However, in
Ishio and Haven [1] it is also argued that the stochastic model does not necessarily
imply Bohmian mechanics.
Recall our discussion in Chapter 2, Section 2.7, where we set up the basics
of Black‚ÄìScholes option pricing. The famous Black‚ÄìScholes partial differential

13.18 Universal Brownian motion and option pricing
223
equation was equation (2.12). We recall the equation again:
‚àÇF
‚àÇt + œÉ 2S2
2
‚àÇ2F
‚àÇS2 + rS ‚àÇF
‚àÇS = rF,
(13.14)
where F is the option price, t is time, œÉ is the volatility, S is the stock price (not to
be confused with the phase S of (13.13)!), r is the risk free rate of interest.
In Ishio and Haven [1], we propose to deÔ¨Åne a so-called ‚Äúinformation risk param-
eter.‚Äù We argued there that information carried a degree of erroneous information
and the parameter we propose would measure this type of information. In that same
paper, we proposed two Brownian motions, one which is (13.13) (but adapted to
become a Brownian motion on the return, Œº) and the other stochastic differential
equation which is the Brownian motion we used in the original Black‚ÄìScholes set
up, i.e. equation (2.4) (in Chapter 2, Section 2.7.3), i.e. dS = ŒºSdt + œÉSdW. In
Ishio and Haven [1] (p. 40), the stochastic differential equation on Œº is introduced
as:
dŒº =
/
‚àáPh(Œº) + 1
2
‚àá
œà12
œà12
0
dt + dW1,
(13.15)
where ‚àáPh(Œº) is the gradient of the phase of the wave function, œà1, Œº is the asset
(or stock) return, and dW1 is a Wiener process. As in Wilmott [2], a correlation is
assumed to exist between dW1 and the Wiener process dW, which is part of the
(geometric) Brownian motion of the asset (or stock) price. Ishio and Haven [1]
follow Wilmott‚Äôs [2] (pp. 299‚Äì302) set up, but use equation (13.15) instead of the
stochastic differential equation on volatility.
We reproduce24 the paper by Ishio and Haven [1] (Section 4 (pp. 40‚Äì42)).
We now follow Wilmott‚Äôs approach [2] (p. 300). Consider the option price F
to be a function of the drift Œº, the stock price S, and time t: F(Œº, S, t). The
inÔ¨Ånitesimal change in the option price dF can be expanded as follows:
dF = ‚àÇF
‚àÇS dS + ‚àÇF
‚àÇŒº dŒº + ‚àÇF
‚àÇt dt + 1
2
‚àÇ2F
‚àÇS2 (dS)2 + 1
2
‚àÇ2F
‚àÇŒº2 (dŒº)2 + ‚àÇ2F
‚àÇŒº‚àÇS dSdŒº.
(13.16)
In contrast to the Black‚ÄìScholes portfolio, which was  = ‚àíF + ‚àÇF
‚àÇS S, where
F(S, t)is the optionprice,the portfoliowe have nowis somewhatdifferent(Wilmott
[2]):
 = F ‚àí
S ‚àí
1F1.
(13.17)
24 Ishio, H. and Haven, E. (2009). Information in asset pricing: a wave function approach. Annalen der Physik,
18, 1, 40‚Äì42.

224
Other applications to economic/Ô¨Ånancial theory
We remark that F and F1 are two different option prices. In full analogy with
Wilmott [2], the two option prices F and F1 are needed in this set up since one
needs to hedge against two sources of randomness: (i) stock price randomness (as
in Black‚ÄìScholes) (as expressed by the geometric Brownian motion on the stock
price) and now also (ii) information risk randomness (as expressed by (13.15)).
We are ultimately interested in Ô¨Ånding the functional form of F, which can be
found by solving the PDE in (13.24) below. The variables 
 and 
1 indicate,
respectively, the quantities of stock and options which are needed to make sure (as
in Black‚ÄìScholes) that the portfolio change per unit of time is risk free. At this
stage of the derivation, the quantities 
 and 
1 are open. However, as we will see
following from (13.20) below, those two quantities will be fully determined.
As is the case in the Black‚ÄìScholes derivation, the inÔ¨Ånitesimal change in the
value of the portfolio given by (13.17) can be written as:
d = dF ‚àí
dS ‚àí
1dF1,
(13.18)
where dF (and dF1) is given by (13.16).25 Remark that dS is given by the geometric
Brownian motion on stock.
Substituting those expressions in (13.18) above, one obtains:
d =
	‚àÇF
‚àÇS ‚àí
1
‚àÇF1
‚àÇS ‚àí

dS +
	‚àÇF
‚àÇŒº ‚àí
1
‚àÇF1
‚àÇŒº

dŒº
+
	‚àÇF
‚àÇt + 1
2œÉ 2S2 ‚àÇ2F
‚àÇS2 + œÅœÉS ‚àÇ2F
‚àÇS‚àÇŒº + 1
2
‚àÇ2F
‚àÇŒº2

dt
‚àí
1
	‚àÇF1
‚àÇt + 1
2œÉ 2S2 ‚àÇ2F1
‚àÇS2 + œÅœÉS ‚àÇ2F1
‚àÇS‚àÇŒº + 1
2
‚àÇ2F1
‚àÇŒº2

dt. (13.19)
In the Black‚ÄìScholes set up, we had one source of risk given by the unique Wiener
process, dW. Now, we have two sources of risk, dW (the dS term of (13.19)) and
dW1 (the dŒº term of (13.19)), which are the Wiener processes corresponding
respectively to the geometric Brownian motion on stock and (13.15). To eliminate
those two sources of risk, one now sets:
	‚àÇF
‚àÇS ‚àí
1
‚àÇF1
‚àÇS ‚àí

=
	‚àÇF
‚àÇŒº ‚àí
1
‚àÇF1
‚àÇŒº

= 0.
(13.20)
Clearly, from (13.20) we Ô¨Ånd immediately that 
 and 
1 are now deÔ¨Åned:

1 = ‚àÇF
‚àÇŒº
4‚àÇF1
‚àÇŒº
(13.21)
25 We note that to obtain dF1, F is to be replaced by F1 in (13.16).

13.18 Universal Brownian motion and option pricing
225
and

 = ‚àÇF
‚àÇS ‚àí
	‚àÇF
‚àÇŒº /‚àÇF1
‚àÇŒº

 ‚àÇF1
‚àÇS .
(13.22)
At this stage of the derivation, one can invoke the same important arguments
which were used in the Black‚ÄìScholes derivation (see Chapter 2, Section 2.7.3):
(i) the sources of risk (dW and dW1) are eliminated by imposing (13.20), and
(ii) we assume there is no arbitrage. Given (i) and (ii) we can write again that
d = rdt. Thus:
d =
	‚àÇF
‚àÇt + 1
2œÉ 2S2 ‚àÇ2F
‚àÇS2 + œÅœÉS ‚àÇ2F
‚àÇS‚àÇŒº + 1
2
‚àÇ2F
‚àÇŒº2

dt
‚àí
1
	‚àÇF1
‚àÇt + 1
2œÉ 2S2 ‚àÇ2F1
‚àÇS2 + œÅœÉS ‚àÇ2F1
‚àÇS‚àÇŒº + 1
2
‚àÇ2F1
‚àÇŒº2

dt
= r(F ‚àí
S ‚àí
1F1)dt = rdt.
(13.23)
Then the Ô¨Ånal PDE becomes [2] (p. 301):
‚àÇF
‚àÇt + 1
2œÉ 2S2 ‚àÇ2F
‚àÇS2 + œÅœÉS ‚àÇ2F
‚àÇS‚àÇŒº + 1
2
‚àÇ2F
‚àÇŒº2 + rS ‚àÇF
‚àÇS
+
/
‚àáPh(Œº) + 1
2
‚àá
œà12
œà12
‚àíŒª
0
‚àÇF
‚àÇŒº
= rF,
(13.24)
where we could claim that Œª is the market price of information risk. In Wilmott
[2] (p. 301), this Œª, within the stochastic volatility model, is called the market
price of volatility risk. We now claim that dW1 is a source of information risk.
We remark that the phase Ph and amplitude
œà1 of the wave function, which
appear in the above PDE, will have a functional form which will have been deter-
mined within the Bohmian mechanics setting. As was pointed out at the beginning
of this section, those functional forms carry over only in one direction: from
Bohmian mechanics to the Universal Brownian motion, but not in the opposite
direction.
We write, for the case of information risk, in complete analogy with Wilmott [2]
(p. 302):
d ‚àírdt = ‚àÇF
‚àÇŒº (Œªdt + dW1).
(13.25)
The right-hand side of the above equation should vanish in Black‚ÄìScholes because
of d = rdt.

226
Other applications to economic/Ô¨Ånancial theory
13.19 References
[1] Ishio, H. and Haven, E. (2009). Information in asset pricing: a wave function approach.
Annalen der Physik, 18, 1, 33‚Äì44.
[2] Wilmott, P. (1999). Derivatives: The Theory and Practice of Financial Engineering.
J. Wiley, Chichester.
13.20 Wave functions in drift-dependent option pricing
In Chapter 2, Section 2.7.3, we brieÔ¨Çy mentioned an alternative way of deriving
the option pricing formula by Bouchaud [1], Bouchaud and Potters [2], Bouchaud
and Sornette [3], Schweizer [4], and Sch¬®al [5]. Bouchaud [1] (p. 241) writes
the so-called ‚Äúglobal wealth balance‚Äù as 
W = cerT ‚àímax(x(T ) ‚àíxs, 0) +

i œÜ(xi, ti) exp(r(T ‚àíti)) [xi+1 ‚àíxi ‚àírxiœÑ], with c the price of a call, x(T ) the
underlying asset price at maturity time T , xs the exercise price, r the interest rate,
œÜ(xi, ti) (as per Bouchaud [1] (p. 241)) ‚Äúthe trading strategy, i.e. the number of
stocks per option in the portfolio of the option writer,‚Äùxi = x(ti) the underlying
asset price, and œÑ is what Bouchaud [1] (p. 241) terms the ‚Äúelementary time inter-
val.‚Äù
The Ô¨Årst two terms are self explanatory in the above equation. The price of the
contract (c) is what the writer of the contract receives and is used to buy bonds
with interest r. The term with the summation indicates what Bouchaud [1] (p. 241)
calls ‚Äúthe proÔ¨Åt or loss . . . incurred due to the trading strategy œÜ.‚Äù
When imposing the condition E(
W) = 0 and a so called ‚Äúrisk minimization
condition‚Äù26 (see Bouchaud and Sornette [3], Schweizer [4], and Sch¬®al [5]); the
call value is then found to be:
 ‚àû
xs (x‚Ä≤ ‚àíxs)P (x‚Ä≤, T |x0, 0)dx‚Ä≤, with P a conditional
probability.
Tan [6] introduces the following condition:
E
	
œÜ(x, t)dx
dt dt

= Œºx0
 T
0
 ‚àû
0
œÜ‚àó(x, t)P(xi, t; Œº|x0, 0)dxdt,
(13.26)
where now P(xi, t; Œº|x0, 0), is in the words of Tan [6] (p. 114) ‚Äúthe
biased
(Œº-dependent)
distribution
of
the
stock.‚Äù
Note
that
œÜ‚àó(x, t) =
 ‚àû
xs (x(T ) ‚àíxs) ‚àÇP
‚àÇx dx(T ). Tan [6] then shows (p. 116) that, when using (13.26),
the call option price can be rewritten in the following form:
cnew = cBlack ‚àíŒºx0T
œÉ 2x2
0
‚àû

n=3
an
(n ‚àí1)!
‚àÇn‚àí3P(xs, T |x0, 0)
‚àÇxn‚àí3
0
,
(13.27)
26 This condition is essentially requiring that the Ô¨Årst partial derivative of 
W towards œÜ is zero.

13.22 Generalizations of ItÀÜo stochastics
227
where an = 0 for all n ‚â•3 when the Gaussian probability density is used. Hence,
in that case one recuperates cBlack, which is the Black‚ÄìScholes option price.
Equation (13.27) is a highly interesting result. In Haven [7], we substitute the
drift term we imposed in equation (13.15) (see Section 13.18 of this chapter)
into the above correction term to the Black‚ÄìScholes call price. This term then
reads as:
‚àí

‚àáPh + 1
2
‚àá|œà|2
|œà|2

S0T
œÉ 2S2
0
‚àû

n=3
an
(n ‚àí1)!
‚àÇn‚àí3P(X, T |S0, 0)
‚àÇSn‚àí3
0
.
(13.28)
13.21 References
[1] Bouchaud, J. P. (2002). An introduction to statistical Ô¨Ånance. Physica A, 313, 238‚Äì251.
[2] Bouchaud, J. P. and Potters, M. (2000). Theory of Financial Risks. Cambridge Univer-
sity Press.
[3] Bouchaud, J. P. and Sornette, D. (1994). The Black‚ÄìScholes option pricing problem
in mathematical Ô¨Ånance: generalization and extensions for a large class of stochastic
processes. Journal de Physique I, 4, 863‚Äì881.
[4] Schweizer, M. (1994b). Approximating random variables by stochastic integrals.
Annals of Probability, 22, 1536‚Äì1575.
[5] Sch¬®al, M. (1994). On quadratic cost criteria for option hedging. Mathematics of Oper-
ations Research, 19, 121‚Äì131.
[6] Tan, A. (2005). Long memory stochastic volatility and a risk minimisation approach
for derivative pricing and hedging. Doctoral Thesis, School of Mathematics, Faculty
of Engineering and Physical Sciences, University of Manchester (UK).
[7] Haven, E. (2009). The use of the information wave function in a drift dependent option
price: a simple example. Foundations of Probability and Physics, 5, Sweden, 1101,
74‚Äì77. American Institute of Physics Conference Proceedings.
13.22 Generalizations of ItÀÜo stochastics: path integration and other tools
Path integration was developed by Feynman. It has very wide applications in
science, but has only trickled-in, in very narrow ways, into social science (mostly
in mathematical Ô¨Ånance).
Baaquie [1] in a recent paper which appeared in Physical Review E proposes
the use of quantum Ô¨Åelds in the establishment of a theory of forward rates. Any
advanced undergraduate and graduate student in Ô¨Ånance will have heard of the
so-called HJM theory [2] of forward interest rates which was developed by Heath,
Jarrow, and Morton. In the context of LIBOR markets, the Baaquie approach gener-
alizes white noise, a characteristic of stochastics, to what Baaquie [1] (p. 046119-4)
calls a ‚Äútwo dimensional quantum Ô¨Åeld.‚Äù The key formulation is given by equation
(9) in Baaquie‚Äôs paper [1] (p. 046119-4): ‚àÇf (x,t)
‚àÇt
= Œº(x, t) + v(t, x)A(t, x), where
f (t, x) is the LIBOR forward interest rate on position x and time t, v(t, x) is the

228
Other applications to economic/Ô¨Ånancial theory
volatility, and A(t, x) is the two-dimensional quantum Ô¨Åeld. In Baaquie
[1] (p. 046119-4), f (t, x) is built up as f (t, x) = f (t0, x) +
 t
t0 Œº(t, x)dt +
 t
t0 v(t, x)A(t, x)dt and the quantum Ô¨Åeld dynamics are given by what Baaquie
[1] (p. 046119-5) calls a ‚Äústiff Lagrangian.‚Äù The so-called Wilson expansion [3] in
that paper is central because it allows for considering the product of non-Gaussian
quantum Ô¨Åelds. Furthermore, this very same expansion for Gaussian quantum Ô¨Åelds
also provides for a generalization of ItÀÜo calculus.
13.23 References
[1] Baaquie, B. (2009). Interest rates in quantum Ô¨Ånance: the Wilson expansion. Physical
Review E, 80, 046119.
[2] Heath, D., Jarrow, R., and Morton, A. (1992). Bond pricing and the term structure of
interest rates: a new methodology for contingent claims valuation. Econometrica, 60,
1, 77‚Äì105.
[3] Wilson, K. G. (1969). Non-Lagrangian models in current algebra. Physical Review,
179, 1499‚Äì1512.
13.24 q-calculus and Ô¨Ånance
q-calculus is also known under the name of ‚Äúquantum calculus.‚Äù Key references
to this type of calculus can be found in Kac and Cheung [1] and Andrews [2] [3].
The Heisenberg uncertainty principle is to be slightly adapted when such calculus
is used. We would also like to show how this type of calculus can be connected to
some elementary Ô¨Ånancial principles. We apply it here to option pricing. We now
reproduce27 the paper by Haven [4] (Sections 2‚Äì4 (pp. 530‚Äì536)).
13.24.1 q-derivatives, Hilger delta time derivatives and links between them
For deÔ¨Ånitions 37, 38, 39, and 40, below,28 we follow Kac and Cheung [1]. We
also use their notation.
DeÔ¨Ånition 37 For an arbitrary function f (x), the q-differential is dqf (x) =
f (qx) ‚àíf (x).
DeÔ¨Ånition 38 For an arbitrary function f (x), the h-differential is dhf (x) =
f (x + h) ‚àíf (x).
27 Haven, E. (2010). ItÀÜo‚Äôs Lemma with quantum calculus: some implications, Foundations of Physics, 41, 3,
530‚Äì536.
28 The deÔ¨Ånitions in this section are also given in Haven [5] except for deÔ¨Ånitions 42, 43, 44, and 45, and
Theorem 46.

13.24 q-calculus and Ô¨Ånance
229
The relationship between q-calculus and h-calculus follows via either q = eh or
q = eih, where i ‚ààC. We also have the following deÔ¨Ånitions.
DeÔ¨Ånition 39 The q-derivative of a function f (x) is Dqf (x) = dqf (x)
dq(x) = f (qx)‚àíf (x)
qx‚àíx
.
DeÔ¨Ånition 40 The h-derivative of a function f (x) is Dhf (x) = dhf (x)
dh(x) =
f (x+h)‚àíf (x)
(x+h)‚àíx
.
Note that limq‚Üí1 Dqf (x) = limh‚Üí0 Dhf (x) = df (x)
dx .
What is the q-derivative of a function f (x) = xn? Since Dqf (x) = xn(qn‚àí1)
x(q‚àí1) and
qn‚àí1
q‚àí1 = qn‚àí1 + ¬∑ ¬∑ ¬∑ + 1 = [n] (n ‚ààZ+
0 ) as in Kac and Cheung [1].
The so-called Hilger delta time derivative follows the calculus of Hilger [6] [7].
See also Bohner and Peterson [8] [9] and Davis et al. [10] for excellent sources.
In order to deÔ¨Åne this derivative, we need to provide for some background Ô¨Årst.
Please see for instance Hilger [7] or also Bohner and Peterson [8]. In DeÔ¨Ånitions
41, 42, 43, 44, and 45, and Theorem 46 below, we follow Bohner and Peterson [8].
Let us Ô¨Årst deÔ¨Åne the most basic object: a time scale T.
DeÔ¨Ånition 41 A time scale T is an arbitrary non-empty closed subset of R.
As Bohner and Peterson [8] indicate, the sets ]0, 1[, Q, R\Q, and C do contradict
DeÔ¨Ånition 41 and hence are not time scales.
DeÔ¨Ånition 42 For t ‚ààT, the forward jump operator Œ∑ : T ‚ÜíT is deÔ¨Åned as
Œ∑(t) ‚â°inf {s ‚ààT : s > t} .
DeÔ¨Ånition 43 For t ‚ààT, the backward jump operator Œª : T ‚ÜíT is deÔ¨Åned as
Œª(t) ‚â°sup {s ‚ààT : s < t} .
DeÔ¨Ånition44 The graininess function Œ∏ : T ‚Üí[0, ‚àû[is deÔ¨Ånedas Œ∏(t) ‚â°Œ∑(t) ‚àít.
DeÔ¨Ånition 45 If t < sup T and Œ∑(t) = t, then t is right dense. If t > inf T and
Œª(t) = t, then t is left dense.
Still following Bohner and Peterson [8], t is said to be right-scattered, when
Œ∑(t) > t. When Œª(t) < t, then t is said to be left-scattered. We have the usual
derivative when T = R. As an example, the usual time derivative, limt‚Üís
f (t)‚àíf (s)
t‚àís
is obtained when T = R. When T = Z, one uses the forward difference operator
f (t + 1) ‚àíf (t). When T = R, then for all t ‚ààT, Œ∏(t) = 0. When T = Z, then for
all t ‚ààT, Œ∏(t) = 1.
An interesting question is now: ‚ÄúHow can one deÔ¨Åne a ‚Äòderivative‚Äô when T
is arbitrary?‚Äù Theorem 1.16 in Bohner and Peterson [8] provides for an answer.
Before we proceed to enumerate part of that theorem, we need the deÔ¨Ånition of TŒ∫.
If sup T < ‚àû, then TŒ∫ = T \ ]Œª(sup T), sup T]. If sup T = ‚àû, then TŒ∫ = T.

230
Other applications to economic/Ô¨Ånancial theory
Theorem 46 Bohner and Peterson [8] (p. 13). Assume the function f : T ‚ÜíR and
let t ‚ààTŒ∫. If f is continuous at t and t is right-scattered, then f is differentiable
at t with f 
(t) = f (Œ∑(t))‚àíf (t)
Œ∑(t)‚àít
, where for t ‚ààT, Œ∑(t) ‚â°inf {s ‚ààT : s > t}.
We call f 
(t) the Hilger delta time derivative. The link between Dqf (x) and
f 
(t) is quite straightforward: if one sets Œ∑(t) = qt in f 
(t), then a q-derivative
in t is obtained. We need the graininess Œ∏(t) = Œ∑(t) ‚àít = qt ‚àít > 0 for t to be
right-scattered. For T = Z, we know TŒ∫ = T. We require that qt ‚àít = 1, where
q = 1
t + 1. For the case when T = R, we have TŒ∫ = T and Œ∏(t) = Œ∑(t) ‚àít =
qt ‚àít = 0. Therefore, q = 1 in that case.
13.24.2 How can we formulate ItÀÜo‚Äôs Lemma with q-derivatives?
ItÀÜo‚Äôs Lemma [11] is a crucial mathematical result, which allows for the effective
use of stochastic calculus in Ô¨Ånancial derivative (or also option) pricing. The title of
this sub-section suggests investigating whether q-derivatives could be used in ItÀÜo‚Äôs
Lemma. Hence, we need to have a closer look at the proof of ItÀÜo‚Äôs Lemma to check
the feasibility of this query. We follow √òksendal‚Äôs [12] treatment of the proof (in
one dimension) of ItÀÜo‚Äôs Lemma. ItÀÜo‚Äôs Lemma can be expressed in integral form or in
differential notation. Assume that Xt is a stochastic integral29 dXt = udt + vdBt,
where Bt is a one-dimensional Brownian motion, u and v are respectively drift
and diffusion factors, and t is time. Let a function g(t, x) be twice continuously
differentiable on the product space [0, ‚àû[√óR, then g(t, Xt) is also a stochastic
integral and ItÀÜo‚Äôs Lemma indicates that:30
g(t, Xt) ‚àíg(0, X0) =
 t
0
	‚àÇg
‚àÇs + u‚àÇg
‚àÇx + 1
2v2 ‚àÇ2g
‚àÇx2

ds +
 t
0
v ‚àÇg
‚àÇx dBs. (13.29)
It can be assumed, as is indicated in √òksendal [12], that g, ‚àÇg
‚àÇt , ‚àÇg
‚àÇx , and ‚àÇ2g
‚àÇx2
are bounded. But the Lemma can also be proven without this restriction. See, for
instance, Brze¬¥zniak and Zastawniak [13].
While still following √òksendal [12], Taylor‚Äôs theorem now reads as:
g(t, Xt) ‚àíg(0, X0) =

j
‚àÇg
‚àÇt 
tj +

j
‚àÇg
‚àÇx 
Xj + 1
2

j
‚àÇ2g
‚àÇt2


tj
2
+

j
‚àÇ2g
‚àÇt‚àÇx


tj
 

Xj

+ 1
2

j
‚àÇ2g
‚àÇx2


Xj
2 +

j
Rj,
(13.30)
29 Please see Theorem 4.2, p. 33 in √òksendal [12].
30 Please see Theorem 4.5, p. 35 in √òksendal [12].

13.24 q-calculus and Ô¨Ånance
231
where 
tj = tj+1 ‚àítj; 
Xj = Xtj+1 ‚àíXtj and Rj = o

tj
2 +

Xj
2
, ‚àÄj.
The partial derivatives are evaluated at

tj, Xtj

.
√òksendal [12] proposes, so as to prove ItÀÜo‚Äôs Lemma, that the following evalua-
tions are made. Each term in (13.30) is evaluated as follows:
(a) If 
tj ‚Üí0, then 
j
‚àÇg
‚àÇt 
tj ‚Üí
 t
0
‚àÇg
‚àÇs (s, Xs)ds.
(b) If 
tj ‚Üí0, then 
j
‚àÇg
‚àÇx 
Xj ‚Üí
 t
0
‚àÇg
‚àÇx (s, Xs)dXs.
This means the two Ô¨Årst-order terms will remain in the Taylor expansion. How-
ever, the situation is different for some of the second-order terms.
(c) If 
tj ‚Üí0, then in 
j
‚àÇ2g
‚àÇx2 (
Xj)2 = 
j
‚àÇ2g
‚àÇx2 u2
j(
tj)2 + 2 
j
‚àÇ2g
‚àÇx2 ujvj(
tj)
√ó (
Bj) + 
j
‚àÇ2g
‚àÇx2 v2
j(
Bj)2 the Ô¨Årst two terms are zero. As an exam-
ple, √òksendal [12], shows, the limit 
tj ‚Üí0 in the mean square sense
of 
j
‚àÇ2g
‚àÇx2 ujvj √ó (
tj)(
Bj), is lim
tj‚Üí0 E
+	 
j
‚àÇ2g
‚àÇx2 ujvj(
tj)(
Bj)

2,
=
lim
tj‚Üí0

j
E
)
‚àÇ2g
‚àÇx2 ujvj
2
(
tj)3
*
= 0.
The situation is different with the last term in (c). In effect, √òksendal [12] shows
that 
j
‚àÇ2g
‚àÇx2 v2
j


Bj
2, when 
tj ‚Üí0, tends to
 t
0
‚àÇ2g
‚àÇx2 v2ds.
(d) The other terms in (13.30), 
j
‚àÇ2g
‚àÇt‚àÇx


tj
 

Xj

and
1
2

j
‚àÇ2g
‚àÇt2


tj
2, can
equally be shown to vanish.
(e) The remainder term 
j
R2
j can also be shown to tend to zero, when 
tj ‚Üí0.
To stay faithful to the title of this section, we now query how (a), (b), (c), (d),
and (e) behave if we consider q-derivatives. A key remark can be as follows. Let
us denote q-derivatives as ‚àÇq.
‚àÇq.. If we consider (a), then we can write:
lim

tj‚Üí0

j
‚àÇqg
‚àÇqt 
tj Ã∏= ‚àÇqg
‚àÇqt
lim

tj‚Üí0

j

tj.
(13.31)
This non-equality will appear for the following reason.31 Let us use the
q-derivative deÔ¨Ånition on time f 
(t) = f (Œ∑(t))‚àíf (t)
Œ∑(t)‚àít
, where for t ‚ààT, Œ∑(t) ‚â°
31 Of course, lim
tj ‚Üí0

j
‚àÇg
‚àÇt 
tj = ‚àÇg
‚àÇt lim
tj ‚Üí0

j

tj.

232
Other applications to economic/Ô¨Ånancial theory
inf {s ‚ààT : s > t} and let us set Œ∑(t) = qt. Set qt = t2 and t = t1 and t1 < t2 (there-
fore q > 0, which is Ô¨Åne when we assume that q = exp(h)). Let 
tj = t2 ‚àít1.
Thus, lim
tj‚Üí0

j
‚àÇqg
‚àÇqt 
tj = lim
tj‚Üí0

j
g(t2)‚àíg(t1)
t2‚àít1

tj, but lim
tj‚Üí0
g(t2)‚àíg(t1)
t2‚àít1
=
‚àÇg
‚àÇt Ã∏= ‚àÇqg
‚àÇqt . This then means that, if we apply the delta time limit as in (a) on a
q-derivative on time, we plainly cannot keep the q-derivative on time. The q-
derivative converts itself to a regular derivative. So we cannot keep the q-derivative
on time in (a). We must use an ordinary time derivative. This argument does not
repeat itself for (b), where the delta time limit is applied to a position derivative.
Hence, we can write in (b) that lim
tj‚Üí0

j
‚àÇqg
‚àÇqx 
Xj ‚Üí
 t
0
‚àÇqg
‚àÇqx (s, Xs)dXs. The
same argument goes for (c). In (d) and (e), we must again be prudent to use regular
derivatives and no q-derivatives.
In non-summation form, we can write (13.30), with the blend of ordinary deriva-
tives on time and the q-derivatives on position, simply as follows:

g = ‚àÇqg
‚àÇqX
Xj + ‚àÇg
‚àÇt 
tj + 1
2
‚àÇ2
qg
‚àÇqX2


X2
j

+ 1
2
‚àÇ2g
‚àÇt2


tj
2
+ ‚àÇ2g
‚àÇX‚àÇt (
tj)(
Xj) + Rj.
(13.32)
If we consider 
Xj = uj
tj + vj
Bj, then using (a), (b), (c), (d), and (e) from
above, we can write:

qg = ‚àÇqg
‚àÇqX

uj
tj + vj
Bj

+ ‚àÇg
‚àÇt (
tj) + 1
2
‚àÇ2
qg
‚àÇqX2 v2
j
tj.
(13.33)
Note the mixed use of derivatives in this expansion.
13.24.3 Financial interpretation of q
In Haven [5], we provide for an option pricing application using the ItÀÜo‚Äôs Lemma
with mixed q-derivatives.32 We summarize this application as follows. Before we
do so, let us consider an example.
Example 47 Consider a small generalization of dXt = udt + vdBt which
is dX = u(X, t)dt + v(X, t)dB. Consider a stock price, S. Let X = S and
u(X, t) = ŒºS, where Œº is a rate of return on the stock. Let v(X, t) = œÉS,
where œÉ is a constant stock price volatility. Let g(S) = Sn. We want to express
32 Haven [5] does not show why we can only have mixed derivatives in Ito‚Äôs Lemma. We attempt to show this
in this section.

13.24 q-calculus and Ô¨Ånance
233
dg(S) = dSn when we use q-derivatives. We use therefore (13.33) in dif-
ferential form. We obtain dSn =

dqg(S)
dq(S) ŒºS + 1
2
d2
qg(S)
dq(S)2 œÉ 2S2
dt + dqg(S)
dq(S) œÉSdB =

[n]ŒºSn + 1
2[n][n ‚àí1]œÉ 2Sn
dt + [n]œÉSndB.
This takes on a quite complicated form if we replace [n]. We get: dSn =

(1 + q + .. qn‚àí1)ŒºSn + 1
2(1 + q + .. qn‚àí1)(1 + q + ..qn‚àí2)œÉ 2Sn
dt + (1 + q+
..qn‚àí1)œÉSndB.
A Ô¨Ånancial option is a contract entitling the buyer of such contract to either have
the right to buy or sell an asset (from the seller of that contract) at a certain price at
a certain date in the future. The value at maturity of a ‚Äúcall‚Äù option is max{S ‚àíK,
0}, where K indicates the price at which the holder of a call option has the right to
buy the underlying asset (a stock with price S in this case). The ‚Äúput‚Äù option has
as intrinsic value: max{K ‚àíS, 0}. K indicates the price at which the holder of a
put option has the right to sell the underlying asset (a stock with price S in this
case). See Wilmott [14]. See also Baaquie [15]. Black‚ÄìScholes [16] option pricing
theory yields a partial differential equation, which when solved yields the value of
a (European) call and put contract.
As in Haven [5], we consider an option with intrinsic value, max{S2 ‚àíK, 0} for
the call and max{K ‚àíS2, 0} for the put.33 Consider, as in example 47, g(S) = Sn,
but now for n = 2. The expression, with q-derivatives, for dS2 is then dS2 =

[2]ŒºS2 + 1
2[2]œÉ 2S2
dt + [2]œÉS2dB. The inÔ¨Ånitesimal change of the value of the
option price function, df (S2, t) can be shown to be equal to:
df (S2, t) = ‚àÇqf
‚àÇqS2
		
[2]ŒºS2 + 1
2[2]œÉ 2S2

dt + [2]œÉS2dB

+ ‚àÇf
‚àÇt dt + 1
2
‚àÇ2
qf
‚àÇqS22 [2]2œÉ 2S4dt.
(13.34)
Note that we made use of (dB)2 = dt. The above equation (13.34) simply uses
the result (13.33). The traditional Black‚ÄìScholes [16] set up deÔ¨Ånes the value of a
portfolio  which consists of the buying and selling of two positions: an option and
‚àÇf
‚àÇS units of a stock. In analogy with the Black‚ÄìScholes [16] set up, the inÔ¨Ånitesimal
change in the value of this portfolio, d, is deÔ¨Åned as d = ‚àídf + ‚àÇqf
‚àÇqS2 dS2.
Substituting (13.34) and the expression for dS2 in d, one obtains:
d
dt = ‚àí‚àÇf
‚àÇt ‚àí1
2
‚àÇ2
qf
‚àÇqS22 [1 + q]2œÉ 2S4.
(13.35)
Note that we replaced [2] = 1 + q, using the notation of Kac and Cheung [1].
33 McDonald [18] provides for a discussion, albeit without reference to q-derivatives, on claims other than S.

234
Other applications to economic/Ô¨Ånancial theory
13.24.4 Non-use of the macroscopic q-derivative version of the Heisenberg
uncertainty principle
A main argument consists now in debating whether equation (13.35) is reasonable
when q-derivatives are used. We make a different argument from Haven [5]. We
note that the term
‚àÇ2
qf
‚àÇqS22 is indicative of the so-called ‚Äúhedging error,‚Äù or also the
‚Äúgamma‚Äù of the option. This term is thus nothing else other than a measure of the
curvature of the option pricing function, f . This measure of the hedging error is
becoming more imprecise when using q Ã∏= 1, since no limits are being used. But
what interpretation could we give to the imprecision of the curvature measurement?
What does this mean? We could claim that the value of q indicates uncertainty as to
the precision of f to measure the option price. Under the use of ‚àÇ2f
‚àÇS22 , we effectively
advance that the curvature of the option pricing function is precisely measurable.
Under the use of
‚àÇ2
qf
‚àÇqS22 , we effectively advance that the measurement of the curvature
is not precisely measurable, and this could be equivalently translated into saying
that there is uncertainty as to the precision of the option pricing function, f . This
could lead to non-uniqueness of option prices.
On prima facie, this imprecision in measurement of f , given by the parameter
q, could also be possibly quantiÔ¨Åed in some sort of macroscopic Heisenberg uncer-
tainty principle. The q-derivative version of the Heisenberg uncertainty principle,
at the quantum level, can be written as:
P.Q ‚àíq.Q.P = ‚àíi.¬Øh,
(13.36)
where P and Q are respectively the position and momentum operators. See Baez
[17]. See also Haven [5], where we discuss the q-derivatives version of the macro-
scopic Heisenberg uncertainty principle in different terms. At the macroscopic level
(with no operators thus), we could write:

f.
dqf
dqt ‚àíq.
dqf
dqt .
f = ‚àík,
(13.37)
where 
f is the uncertainty on the measurement of the option price f and 
 dqf
dqt
measures the uncertainty on the momentum of the option price. The parameter
k > 0 would be some macroscopic ‚Äúequivalent‚Äù of the Planck constant. We note
that a macroscopic version of the Heisenberg uncertainty principle (albeit not in q-
derivative form) is discussed, in a stock price context, by Baaquie [15]. For related
work, see also Segal and Segal [19] and Accardi and Boukas [20].
We can claim that for q = 1 (in (13.37)), we indeed would have no macroscopic
uncertainty principle: there would be no imprecision as to the measurement of
the option pricing function (or the option price momentum for that matter). This

13.24 q-calculus and Ô¨Ånance
235
conclusion could tie in with the argument we made above that for q = 1 there
would be no uncertainty as to the imprecision of the option pricing function.
It is important to observe that from the above development, we found that we
could not use q-derivatives on time in the context of the application of ItÀÜo‚Äôs Lemma.
Clearly, in (13.37) we must use such derivative, dqf
dqt . Therefore, we can logically
conclude that in the q = exp(k) world, the uncertainty argument we tied to the
existence of
‚àÇ2
qf
‚àÇqS22 is still valid, but the non-commutativity, as captured by (13.37),
would not hold. The speciÔ¨Åc use of q-derivatives in ItÀÜo‚Äôs Lemma prohibits us from
doing this.
In conclusion, if we assume there should exist a macroscopic uncertainty relation
which exhibits non-commutativity at the level of option pricing, then is the q-
derivative world the correct generalization for Ô¨Ånancial option pricing? Would we
have to work instead with a Langevin-based approach on option pricing, where the
dt ‚Üí0 is not an issue?
13.25 References
[1] Kac, V. and Cheung, P. (2002). Quantum Calculus. Springer Verlag.
[2] Andrews, G. E., Askey, R., and Roy, R. (1999). Special Functions. Cambridge Uni-
versity Press.
[3] Andrews, G. E. (1986). q-Series: Their Development and Application in Analysis,
Number Theory, Combinatorics, Physics and Computer Algebra. In CBMS Regional
Conference Lecture Series in Mathematics, 66, American Mathematical Society.
[4] Haven, E. (2010). ItÀÜo‚Äôs Lemma with quantum calculus: some implications. Founda-
tions of Physics, 41, 3, 529‚Äì537.
[5] Haven, E. (2009). Quantum calculus (q-calculus) and option pricing: a brief intro-
duction. In Quantum Interaction. Eds. Bruza, P., Sofge, D., Lawless, W., and van Rijs-
bergen, K., Lecture Notes in ArtiÔ¨Åcial Intelligence (LNAI), 5494, 308‚Äì314, Springer-
Verlag.
[6] Hilger, S. (1988). Ein Ma√ükettenkalk¬®ul mit Anwendung auf Zentrumsmannig-
faltigkeiten. Ph.D. thesis, Universit¬®at W¬®urzburg (Germany).
[7] Hilger, S. (1990). Analysis on measure chains ‚Äì a uniÔ¨Åed approach to continuous and
discrete calculus. Results in Mathematics, 18, 18‚Äì56.
[8] Bohner, M. and Peterson, A. (2001). Dynamic Equations on Time Scales: An Intro-
duction with Applications. Birkh¬®auser Verlag.
[9] Bohner, M. and Peterson, A. (2003). Advances in Dynamic Equations on Time Scales.
Birkh¬®auser, Basel.
[10] Davis, J. M., Gravagne, I. A., Jackson, B. J., Marks II, R. J., and Ramos, A. A. (2007).
The Laplace transform on time scales revisited. Journal of Mathematical Analysis
and Applications, 332, 1291‚Äì1307.
[11] ItÀÜo, K. (1951). On stochastic differential equations. Memoirs of the American Math-
ematical Society, 4, 1‚Äì51.
[12] √òksendal, B. (1992). Stochastic Differential Equations. Springer Verlag.
[13] Brze¬¥zniak, Z. and Zastawniak, T. (1999). Basic Stochastic Processes. Springer Verlag.
[14] Wilmott, P. (1999). Derivatives: The Theory and Practice of Financial Engineering.
J. Wiley.

236
Other applications to economic/Ô¨Ånancial theory
[15] Baaquie, B. (2004). Quantum Finance. Cambridge University Press.
[16] Black, F. and Scholes, M. (1973). The pricing of options and corporate liabilities.
Journal of Political Economy, 81, 637‚Äì654.
[17] Baez, J. (2003). This week‚Äôs Ô¨Ånds in mathematical physics (Week 183).
http://math.ucr.edu/home/baez/week183.html.
[18] McDonald, R. L. (2003). Derivatives Markets. Addison-Wesley.
[19] Segal, W. and Segal, I. E. (1998). The Black‚ÄìScholes pricing formula in the quantum
context. Proceedings of the National Academy of Sciences of the USA, 95, 4072‚Äì4075.
[20] Accardi, L. and Boukas, A. (2007). The quantum Black‚ÄìScholes equation. Global
Journal of Pure and Applied Mathematics, 2, 155‚Äì170.

14
The neurophysiological sources of quantum-like
processing in the brain
14.1 Introduction
In previous chapters, we discussed the conjecture of quantum-like (QL) process-
ing of information in the brain. See, for instance, Chapter 1 (Section 1.16) and
Chapter 3 (Section 3.1). In general, such processing need not be based on the
physical quantum brain (see, for instance, Hameroff [1] [2] and Penrose [3] [4]),
which is the quantum physical carrier of information. As we remarked in Khren-
nikov [5], the brain created the QL representation (QLR) of information in Hilbert
space. Such representation uses quantum information rules in decision making.
The existence of such QLR was (at least preliminary) conÔ¨Årmed by experimental
data from cognitive psychology (please see Chapter 8). The violation of the law of
total probability in these experiments is an important sign of the non-classicality
of data. In the constructive wave function approach (see Section 8.16 of Chapter
8), such data can be represented by complex amplitudes. We also presented the QL
model of decision making in Chapter 9.
In this chapter we reproduce1 (with only slight modiÔ¨Åcations) the paper by
Khrennikov [6]. The next natural step is to try to Ô¨Ånd possible physical realizations
of the QLR in the brain. One of the possibilities is to appeal to the quantum physics
of the microprocesses in the brain ‚Äì the quantum brain. However, quite surprisingly,
it is possible to proceed within the classical Ô¨Åeld framework, i.e. to create a classical
wave model producing the QLR.
Neurophysiologically, our model is based on a variety of time scales in the brain.
Each pair of scales ‚Äì a Ô¨Åne scale (the background Ô¨Çuctuations of the electromagnetic
Ô¨Åeld) and a rough scale (the mental image scale) ‚Äì induces the QL representation.
The background Ô¨Åeld plays the crucial role in the creation of ‚Äúsuperstrong QL
correlations‚Äù in the brain.
1 Andrei Khrennikov (2011). Quantum-like model of processing of information in the brain based on classical
electromagnetic Ô¨Åeld. Biosystems, 105, 251‚Äì259.
237

238
Neurophysiological sources of quantum-like processing in the brain
We propose a classical (!) wave model, which reproduces probabilistic effects
of quantum information theory. Why do we appeal to classical electromagnetic
Ô¨Åelds in the brain and not to quantum phenomena? In neurophysiological and
cognitive studies, we see numerous classical electromagnetic waves in the brain.
Our conjecture is that these waves are carriers of mental information which are
processed in the framework of quantum information theory.
In the quantum community, there is a general opinion that quantum effects
cannot be described by classical wave models. Even those who agree that the clas-
sical and quantum interferences are similar will emphasize the role of quantum
entanglement and its irreducibility to classical correlations (but recall Einstein‚Äì
Podolsky‚ÄìRosen). It is well known that entanglement is crucial in quantum infor-
mation theory. Although some authors emphasize the role of quantum parallelism
in quantum computing, i.e. superposition and interference, experts know well that
without entanglement the quantum computer is not able to beat the classical digital
computer.
Recently, one of the authors of this book proposed a classical wave model
which reproduces all the probabilistic predictions of quantum mechanics, including
correlations of entangled systems. This model was called prequantum classical
statistical Ô¨Åeld theory (PCSFT) [7]‚Äì[9] and see paper [10] for the recent model for
composite systems. It seems that, in spite of the mentioned common opinion, the
classical wave description of quantum phenomena is still possible.
In this chapter, we apply PCSFT to model the QL processing of information in
the brain on the basis of classical electromagnetic Ô¨Åelds. This model is based on
the presence of various time scales in the brain. Roughly speaking, as mentioned
already above, each pair of time scales (Ô¨Åne2, rough3) can be used for the creation
of the QLR in the brain. The background Ô¨Åeld (background rhythms in the brain),
which is an important part of our model, plays the crucial role in the creation
of ‚Äúsuperstrong QL correlations‚Äù in the brain. These mental correlations are non-
local due to the background Ô¨Åeld. These correlations might provide a solution to
the so-called binding problem.
Each of such pairs of time scales (Ô¨Åne, rough) induces the QLR of information.
As a consequence of the variety of time scales in the brain, we get a variety of
QL representations serving various mental functions. This QL model of the brain‚Äôs
functioning was originated in Khrennikov [11]. The main improvement of the ‚Äúold
model‚Äù is due to a new possibility achieved recently by the PCSFT: to represent
the quantum correlations for entangled systems as the correlations of the classical
random Ô¨Åeld, i.e. the prequantum Ô¨Åeld. This recent development also enlightened
the role of the background Ô¨Åeld, i.e. the vacuum Ô¨Çuctuations. We now transfer
2 Fine: the background Ô¨Çuctuation of the electromagnetic (classical) Ô¨Åeld in the brain.
3 Rough: the mental image scale.

14.2 Quantum-like representation of information
239
this mathematical construction designed for quantum physics to the area of brain
sciences. Of course, in some sense it is a slightly naive model, since we do not
know the ‚ÄúQL code‚Äù used by the brain, i.e. the correspondence between images
and probability distributions of random electromagnetic Ô¨Åelds in the brain.
We speculate that decision making through the non-classical law of total prob-
ability (LTP) is based on a wave representation of information in the brain. The
brain is full of classical electromagnetic radiation. It could be that the brain is able
to create the QLR of information via classical electromagnetic signals, cf. Fichtner
et al. [12].
It is well known that classical waves produce superposition and, hence, violate
the LTP. However, quantum information processing is based not only on superpo-
sition, but also on ENTANGLEMENT. It is the source of superstrong non-local
correlations. Correlations are really superstrong (violations of Bell‚Äôs inequality).
Can entanglement be produced by classical signals? Can quantum information
processing be reproduced by using classical waves? Surprisingly, the answer is
positive.
The crucial element of our classical wave model in explaining the function-
ing of the brain is the presence of the random background Ô¨Åeld. In physics, this
background Ô¨Åeld consists of the Ô¨Çuctuations of the vacuum. However, in the cog-
nitive model this Ô¨Åeld consists of the background Ô¨Çuctuations of the brain. Such a
random background increases essentially the correlations between different men-
tal functions and it generates the non-local presentation of information. As was
already remarked, we might couple this non-local representation of information to
the binding problem:
‚ÄúHow is the unity of conscious perception brought about by the distributed
activities of the central nervous system?‚Äù
14.2 Why could the brain use the quantum-like representation of
information which is based on classical electromagnetic waves?
As we have emphasized already, profound neurophysiological studies have demon-
strated that the brain deÔ¨Ånitely processes information by using classical electro-
magnetic signals. We would like to apply the results of these studies and propose
a classical signal model of the functioning brain. However, we do not plan to just
solely explore the standard classical signal theory. We speculate that information
processing in the brain should be described by the mathematical formalism of
quantum mechanics and that classical electromagnetic waves are used by the brain
to create the QLR.
‚ÄúWhy is the brain not satisÔ¨Åed with classical signal processing?‚Äù
‚ÄúWhat are the advantages of the QL processing of information (even with a
classical Ô¨Åeld)?‚Äù

240
Neurophysiological sources of quantum-like processing in the brain
14.2.1 The incomplete processing of information
If we speculate (as we do in this chapter) that in physics quantum probabilistic
behavior can be expressed through classical random waves, then we deÔ¨Ånitely
reject Bohr‚Äôs thesis on the completeness of quantum mechanics (QM). Please note
that this ‚ÄúEinsteinian‚Äù attitude is characteristic only for this chapter. In previous
chapters, we were able to proceed even with the orthodox Copenhagen interpreta-
tion. Here we have to assume that the QM formalism provides only an approximate
description of processes in the micro-world. The main difference between quantum
processing of information and classical processing is that the quantum approach
provides for a possibility to ignore consistently a part of information, i.e. to make a
consistent cutoff on information (which is described by the mathematical formalism
of QM).
The operation through incomplete information processing is very proÔ¨Åtable for
cognitive systems. An important part of cognition is the extraction of a part of
information from huge information Ô¨Çows coming to the brain. By operating in the
QL framework, for example, on the basis of the wave representation, the brain gets
a possibility to work harmonically with incomplete information. This is one of the
sources of creation of QL processing in the brain.
By ignoring a part of information, the brain is able to create abstract mental
images, ideas, concepts, categories. Another advantage is the incredible increase in
the speed of computations. Here we speak about computations based on classical
electromagnetic signals, but performed on the basis of quantum formalism.
14.2.2 Background noise: how can the worst enemy become the best friend?
By the PCSFT, the standard QM formalism provides a possibility to extract signals
(in fact, their averages) from the noisy background. QM can be interpreted as a kind
of renormalization theory which is applicable to signals with irreducible noise. In
quantum physics, this is the noise of vacuum Ô¨Çuctuations, the background Ô¨Åeld. It
seems that this noise is a fundamental feature of space. One cannot hope to isolate
a signal from these Ô¨Çuctuations. The only possibility is to take them into account
in a consistent way.
Let us now project this situation to the functioning of the brain. The brain
is a complex electric system. Its functioning deÔ¨Ånitely induces noise. The more
complex brains are, the more noisy they are. The higher the brain activity, the
noisier it is. Of course, in the process of evolution, cognitive systems might try to
reduce the impact of the background noise in the brain. However, it is clear that
it would be a very complicated task: it seems impossible to isolate signals in the
brain from the background Ô¨Çuctuations (induced by a huge number of neurons).

14.2 Quantum-like representation of information
241
We speculate that the brain has chosen another way to evolve, namely to elaborate
a procedure to extract mental images from signals of the noisy background. Hence,
the brain proceeds with the noise, but it has a procedure (which is consistent for
different signals) for extracting images. By using the PCSFT, the processing of
information on the basis of the QLR provides for such a possibility.
Moreover, in physics (by the PCSFT) the background Ô¨Åeld is a source of super-
strong non-local correlations between entangled systems. Those are ‚Äúentangled
classical waves‚Äù in the PCSFT framework. By projecting this situation to the brain
functioning, we see that the brain can obtain a great advantage from the presence of
background Ô¨Çuctuations. They produce entanglement between processes in differ-
ent (including spatially separated) domains of the brain, between different mental
functions.
14.2.3 The joint processing of an abstract image and its concrete realizations
By the PCSFT, a random electromagnetic Ô¨Åeld is represented in the QL way by
its covariance operator (=‚Äúdensity operator‚Äù). In the cognitive model, the QL
representation corresponds to abstract mental images. Thus, they are given by
covariance operators. To process such QL images, the brain is not interested in the
complex structure of random Ô¨Çuctuations of classical signals. The brain operates
with images encoded by operators ‚Äì covariance operators (matrices) of classical
random signals. However, in this process the brain might need to proceed from the
abstract image to its concrete realization. For example, the brain can operate with
abstract notions, e.g. house and tree, but it can switch to the concrete house and
the concrete tree. In the processing of the Ô¨Årst type (the QL processing), the brain
operates with operators Dhouse and Dtree and in the processing of the second type
(the classical processing) the brain has to switch to the classical signals encoding
this house and this tree.
We remark that two different realizations of the random signal with the Ô¨Åxed
covariance operator can differ essentially, i.e. they really can encode two dif-
ferent houses. Take a coin. Consider a series of tossings, e.g. a few thousand:
x = (x1, x2, . . . , xn), where xj = 0, 1 are labels of coin‚Äôs sides. After this tossing
is Ô¨Ånished, start a new series: y = (y1, y2, . . . , yn). Although both sequences are
samples of the same random law, they can differ essentially bit-wise. Thus, we can
encode ‚Äúhouse‚Äù (as the abstract notion) by the probability law of this coin, but two
concrete houses are encoded by sequences x and y.
If the brain works in the QL (abstract) regime, it recognizes only encoding of
the corresponding probability laws. If it works in the classical regime, it has to
use essentially more processing resources, since it operates not with the codes of
probabilistic laws, but with the real data streams.

242
Neurophysiological sources of quantum-like processing in the brain
In the QL model induced by PCSFT, we consider only Gaussian random Ô¨Åelds
with zero averages (symmetric rhythms). Such random Ô¨Åelds are uniquely deter-
mined by covariance operators. The former remark on encoding by using the coin
and its tossings can be modiÔ¨Åed in the following way. We have a Gaussian random
generator producing vector data. Each vector (realization) has dimension m. Start-
ing with some input given by the vector x0 the generator produces the stream of
vectors x encoding the concrete house. Starting with another input x‚Ä≤
0, the gener-
ator produces another stream of random data y encoding another concrete house.
The concept of house is represented by the covariance operator D = Dhouse of this
random generator, the density operator in the QL formalism.
14.3 Prequantum classical statistical Ô¨Åeld theory: non-composite systems
Quantum mechanics (QM) is a statistical theory. It cannot tell us anything about an
individual quantum system, e.g. an electron or photon. It predicts only probabilities
for results of measurements of ensembles of quantum systems. Classical statistical
mechanics (CSM) does the same. Why are QM and CSM based on different
probability models?
In CSM, averages are given by integrals with respect to probability measures
and in QM they are given by traces. In CSM, we have:
‚ü®f ‚ü©Œº =

M
f (œÜ)dŒº(œÜ),
(14.1)
where M is the state space. In probabilistic terms, there is a random vector œÜ(œâ)
given, which is taking values in M. Then ‚ü®f ‚ü©œÜ = Ef (œÜ(œâ)) = ‚ü®f ‚ü©Œº. In QM, the
average is given by the operator trace-formula:
‚ü®
A‚ü©œÅ = TrœÅA.
(14.2)
This formal mathematical difference induces a prejudice on the fundamental dif-
ference between classical and quantum worlds. Our aim is to show that, in spite of
common opinion, quantum averages can be easily represented as classical averages
and, moreover, even correlations between entangled systems can be expressed as
classical correlations (with respect to Ô¨Çuctuations of classical random Ô¨Åelds).
14.3.1 Einstein‚Äôs dreams:
Albert Einstein did not believe in irreducible randomness, i.e. the completeness of
QM. He dreamed of a better, so to say ‚Äúprequantum,‚Äù model [13]:
(1) Dream 1. A mathematical model reducing quantum randomness to classical
randomness.

14.3 Prequantum classical statistical Ô¨Åeld theory
243
(2) Dream 2. Renaissance of the causal description.
(3) Dream 3. Instead of particles, classical Ô¨Åelds will provide the complete descrip-
tion of reality: the reality of Ô¨Åelds (Einstein and Infeld [13] (p. 257)):
‚ÄúBut the division into matter and Ô¨Åeld is, after the recognition of the equivalence of mass
and energy, something artiÔ¨Åcial and not clearly deÔ¨Åned. Could we not reject the concept
of matter and build a pure Ô¨Åeld physics? What impresses our senses as matter is really a
great concentration of energy into a comparatively small space. We could regard matter as
the regions in space where the Ô¨Åeld is extremely strong. In this way a new philosophical
background could be created.‚Äù
The real trouble with the prequantum wave model (in the spirit of early
Schr¬®odinger) is not the various no-go theorems4 (e.g., the Bell inequality [14]),
but the problem which had already been recognized by Schr¬®odinger. In fact, he
gave up with his wave quantum mechanics because of this problem: A composite
quantum system cannot be described by waves on physical space! Two electrons
are described by the wave function on R6 and not by two waves on R3.
Einstein also recognized this problem (Einstein and Infeld [13] (p. 305)):
‚ÄúFor one elementary particle, electron or photon, we have probability waves in a three-
dimensional continuum, characterizing the statistical behavior of the system if the exper-
iments are often repeated. But what about the case of not one but two interacting parti-
cles, for instance, two electrons, electron and photon, or electron and nucleus? We can-
not treat them separately and describe each of them through a probability wave in three
dimensions . . . ‚Äù
14.3.2 Quantum system = classical random Ô¨Åeld
Einstein‚Äôs Dreams 1 and 3 came true in PCSFT (but not Dream 2!), which is a
version of CSM in which Ô¨Åelds play the role of particles.5 In particular, composite
systems can be described by vector random Ô¨Åelds, i.e. by the Cartesian product
of state spaces of subsystems and not the tensor product. The basic postulate of
PCSFT can be formulated in the following way:
A quantum particle is the symbolic representation of a ‚Äúprequantum‚Äù classical
Ô¨Åeld Ô¨Çuctuating on the time scale which is essentially Ô¨Åner than the time scale of
measurements.
In the prequantum state space M = L2(R3), states are Ô¨Åelds œÜ : R3 ‚ÜíR; ‚Äúelec-
tronic Ô¨Åeld,‚Äù ‚Äúneutronic Ô¨Åeld,‚Äù ‚Äúphotonic Ô¨Åeld‚Äù ‚Äì classical electromagnetic Ô¨Åeld.
4 See Chapter 1, Section 1.22 for more on no-go theorems
5 It seems surprising that, although Dream 1 came true, Dream 2 did not. The situation differs essentially
from CSM where dynamics of probability distributions given by the Liouville equation can be reduced
to the deterministic Hamiltonian dynamics. The main difference is due to the presence of the background
Ô¨Çuctuations ‚Äì irreducible noise.

244
Neurophysiological sources of quantum-like processing in the brain
An ensemble of ‚Äúquantum particles‚Äù is represented by an ensemble of classical
Ô¨Åelds. The probability measure Œº on M = L2(R3), or the random Ô¨Åeld œÜ(x, œâ)
is taking values in M = L2(R3). For each Ô¨Åxed value of the random parameter
œâ = œâ0, x ‚ÜíœÜ(x, œâ0) is a classical Ô¨Åeld on physical space.
14.3.3 Density operator = covariance operator
Each measure (or random Ô¨Åeld) has the covariance operator, say D. It describes
correlations between various degrees of freedom. The map œÅ  ‚ÜíD = œÅ is one-to-
one between density operators and the covariance operators of the corresponding
prequantum random Ô¨Åelds, in the case of non-composite quantum systems. In the
case of composite systems, this correspondence is very tricky.
Thus, each quantum state (an element of the QM formalism) is represented
by the classical random Ô¨Åeld in PCSFT. The covariance operator of this Ô¨Åeld is
determined by the density operator. We also postulate that the prequantum random
Ô¨Åeld has zero mean value. These two conditions determine uniquely Gaussian
random Ô¨Åelds. We restrict our model to such Ô¨Åelds. Thus, by PCSFT, quantum
systems are Gaussian random Ô¨Åelds.
Finally, we recall that the covariance operator D of a random Ô¨Åeld œÜ is deÔ¨Åned
by its bilinear form (u, v ‚ààH):
‚ü®Du, v‚ü©= E‚ü©œÜ, u‚ü®‚ü®v, œÜ‚ü©= E
	
O
œÜ(x, œâ)u(x)dx

 	
O
v(x)œÜ(x, œâ)dx

(14.3)
or by using the probability distribution Œº of the random Ô¨Åeld:
‚ü®Du, v‚ü©=

H
	
O
œÜ(x)u(x)dx

 	
O
v(x)œÜ(x)dx

dŒº(œÜ).
(14.4)
14.3.4 Quantum observable = quadratic form
The map 
A ‚ÜífA(œÜ) = (
AœÜ, œÜ) establishes a one-to-one correspondence between
quantum observables (self-adjoint operators) and classical physical variables
(quadratic functionals of the prequantum Ô¨Åeld).
It is easy to prove that the following equality holds:
EfA(œÜ(œâ)) =

M
fA(œÜ)dŒº(œÜ) = TrœÅA.
(14.5)
In particular, for a pure quantum state œà, consider the Gaussian measure with zero
mean value and the covariance operator œÅ = œà ‚äóœà (the orthogonal projector on

14.3 Prequantum classical statistical Ô¨Åeld theory
245
the vector œà), then

M
fA(œÜ)dŒº(œÜ) = (
Aœà, œà).
This mathematical formula coupling the integral of a quadratic form and the cor-
responding trace is well known in measure theory. Our main contribution is the
coupling of this mathematical formula with quantum physics.
This is the end of the story for quantum non-composite systems, e.g. a single
electron or photon [7] [9].
14.3.5 Beyond QM
In fact, PCSFT not only reproduces quantum averages, but it also provides a
possibility to go beyond QM. Suppose that not all prequantum physical variables
are given by QUADRATIC forms. Consider a more general model, such as all
the smooth functionals f (œÜ) of classical Ô¨Åelds. We only have the illusion of the
representation of all quantum observables by self-adjoint operators.
The map
f  ‚Üí
A = f ‚Ä≤‚Ä≤(0)/2
(14.6)
projects smooth functionals of the prequantum Ô¨Åeld (physical variables in PCSFT)
on self-adjoint operators (quantum observables). Then quantum and classical (pre-
quantum) averages do not coincide precisely, but only approximately:

M
fA(œÜ)dŒº(œÜ) = TrœÅ 
A + O(œÑ/T ),
(14.7)
where T is the time scale of measurements and œÑ is the time scale of Ô¨Çuctuations
of the prequantum Ô¨Åeld. The main problem is that PCSFT does not provide a
quantitative estimate of the time scale of Ô¨Çuctuations of the prequantum Ô¨Åeld. If
this scale is too Ô¨Åne, e.g. the Planck scale, then QM is ‚Äútoo good an approximation
of PCSFT,‚Äù i.e. it would be really impossible to distinguish them experimentally.
However, even a possibility to represent QM as the classical wave mechanics
can have important theoretical and practical applications. In the present chapter,
we shall use the mathematical formalism of PCSFT to model the functioning of
the brain. Although even in this case the choice of the scale of Ô¨Çuctuations is a
complicated problem, we know that it is not extremely Ô¨Åne. Hence, the model can
be experimentally veriÔ¨Åed (in contrast to Roger Penrose, we are not looking for
cognition at the Planck scale!).

246
Neurophysiological sources of quantum-like processing in the brain
14.4 Cognitive model: two regimes of brain‚Äôs functioning
We now turn to considerations which were exhibited in Section 14.2.3 and proceed
on the basis of the short presentation of PCSFT given in Section 14.3. We Ô¨Årst
consider a one Ô¨Åxed mental function of the brain, say F, which is physically
concentrated in some spatial domain O ‚äÇR3 of the brain. We shall then come to
the model of QL cooperation of a few mental functions (‚Äúentanglement of mental
functions‚Äù) after presentation of the PCSFT for composite systems, Section 14.8.
Classical regime
By getting an input œÜ0 (from an environment or another mental function), the
mental function F produces a random signal œÜ(x, œâ), a classical electromagnetic
Ô¨Åeld resulting from neuronal activity.6 It is a random signal depending on the
chance parameter œâ. For each œâ0, this electromagnetic Ô¨Åeld, x ‚ÜíœÜ(x, œâ0), is
distributed on the domain O.
We use the complex representation for the electromagnetic Ô¨Åeld, the Riemann‚Äì
Silberstein representation:
œÜ(x) = E(x) + iB(x),
where E(x) = (E1(x), E2(x), E3(x)) and B(x) = (B1(x), B2(x), B3(x)) are the
electric and magnetic components, respectively.
In our model, each concrete mental image is associated with a random signal.
Its mental features, ‚Äúqualia,‚Äù are given by functionals of this signal. In the simplest
case, these are quadratic forms of the signal.
The main problem is to create the classical signal code, i.e. to establish a
correspondence between random signals and mental images as well as between Ô¨Åeld
functionals and qualia of images. We speculate that at least some Ô¨Åeld functionals
represent emotions related to the mental image (which is represented by the classical
electromagnetic signal). Consider a number of emotions, say E1, . . . , Ek, related to
some image, say MIœÜ (associated with the signal œÜ). Then, the mental function F
physically operates with the corresponding Ô¨Åeld functionals. In the simplest case,
these are quadratic functionals and they can be represented by integral kernels:
fEj(œÜ) =

O√óO
Kj(x, y)œÜ(x)œÜ(y)dxdy.
(14.8)
6 Thus, we consider the ensemble of neurons which are located in O. By our model the brain is not so much
interested in the ‚Äúprivate life‚Äù of the individual neurons, i.e. the frequency of spikes and so on, it is only interested
in the electromagnetic Ô¨Åeld induced by the activity of these neurons.

14.4 Cognitive model
247
However, in the classical regime non-quadratic functionals are also in use, e.g.:
f (œÜ) = fE(œÜ) +

O√óO√óO
K(x, y, z)œÜ(x)œÜ(y)œÜ(z)dxdydz,
where fE is the functional of the form (14.8).
Remark 1. (Spatial distribution of qualia) By considering integral functionals
of the classical electromagnetic Ô¨Åeld, we suppose that the F-function performs
integration of a signal over its domain of spatial concentration. Thus, we consider
only spatially concentrated mental functions. If a mental function F is concentrated
in a domain O = ‚à™kOk, where the Ok are located in the brain far away from each
other, then we represent F as a collection of ‚Äúelementary mental functions‚Äù Fk
concentrated in domains Ok. Some qualia of F are associated with elementary
functions Fk. However, there are also exist global qualia which are obtained by
the summation of local ones (so integration on each Ok and then collection and
summation in a ‚Äúspecial center‚Äù).
Since signals are random, Ô¨Åeld functionals are Ô¨Çuctuating quantities ‚Äì random
variables ŒæœÜ(œâ) = f (œÜ(œâ)). It is clear that the brain cannot operate with such
unstable mental entities. Thus, it has to produce averages of emotions and operate
with them. It will be especially clear in the time-representation of random signals,
see Section 14.5. Let Œº be the probability distribution of a random signal œÜ. Then
emotions are quantiÔ¨Åed by averages:
‚ü®fEj‚ü©=

H
fEj(œÜ)dŒº(œÜ),
(14.9)
where H = L2(O). In our model, not only emotions but all qualia are quantiÔ¨Åed
by averages.
It is clear that quantiÔ¨Åcation of each qualia consumes the brain‚Äôs resources.
Therefore, only a special class of qualia (in particular, emotions) is associated with
each mental image. How the mental function F selects them is the open question!
The crucial point is that in principle any two emotions E1 and E2 or other qualia
can be associated with the image MIœÜ and quantiÔ¨Åed. This total compatibility of
emotions and qualia in general may induce some problems. For example, it is not
always proÔ¨Åtable for survival to combine some emotions. We shall see that the
situation is totally different in the QL processing of information.
Functionals of classical electromagnetic signals represent not only emotions,
but even other qualia of the image MIœÜ. For example, in the PCSFT we have the
energy variable (representing the intensity of a signal):
fI(œÜ) =

O
|œÜ(x)|2dx =

O
(E2(x) + B2(x))dx.
(14.10)

248
Neurophysiological sources of quantum-like processing in the brain
We relate this functional to the intensity of feeling of the image MIœÜ. This intensity
is quantiÔ¨Åed as:
‚ü®fI‚ü©=

H
fI(œÜ)dŒº(œÜ) =

H
	
O
|œÜ(x)|2dx

dŒº(œÜ),
(14.11)
=

H
	
O
(E2(x) + B2(x))dx

dŒº(œÜ).
In QM, the position observable is given by the multiplication operator:
xœÜ(x) = xœÜ(x)
and in the PCSFT it is represented by the Ô¨Åeld functional:
fx(œÜ) = (xœÜ, œÜ) =

O
x|œÜ(x)|2dx =

O
x(E2(x) + B2(x))dx.
(14.12)
What quale can be coupled to this functional?
Already here, on the level of classical mental processing, mathematics led us
to the notion of conjugate qualia of a mental image. For example, consider the
momentum functional in the PCSFT:
fp(œÜ) = (pœÜ, œÜ) =

R3 p| ÀúœÜ(p)|2dp,
(14.13)
where ÀúœÜ(p) is the Fourier transform of the signal œÜ(x). What is a cognitive inter-
pretation of conjugation between qualia given by functionals fx and fp?
It seems that in the classical regime the brain can process conjugate qualia
simultaneously. In the case of ‚Äúposition and momentum‚Äù functionals, this means
simultaneous processing in the spatial and frequency representations.
Classical mental coding: How does the brain associate the mental image
MIœÜ with a classical signal œÜ? In our model, this is done through calculation
of its covariance operator D = D(œÜ). This association, mental image ‚Äì covariance
operator, is especially natural in the time representation of random signals, see
Section 14.5.
Quantum-like regime
We are now interested in the QLR (quantum-like representation) of information.
In the QLR, the brain operates with density operators which represent not only
concrete mental images (coming from the classical regime of mental processing),
but also abstract concepts (of different levels of abstraction, see Section 14.7 for
details) which do not correspond to classically produced images.
In the QLR, the brain‚Äôs state space is a space of density operators D(H), H =
L2(O). In principle, each density operator can be used as a QL state of the brain.

14.4 Cognitive model
249
However, it is natural to assume that each mental function F operates in its own
subspace DF(H) of D(H).
In standard QM a system has not only the state, but also the ‚Äúproperties‚Äù or
(depending on the interpretation) there are deÔ¨Åned observables on this system (in
this state) ‚Äì e.g. the energy observable, the coordinate observable, and so on. In
QM, they are represented by self-adjoint operators.
To simplify the mathematics, we shall consider only bounded (continuous)
operators. Denote the space of all bounded self-adjoint operators by the symbol
Ls(H). For a given quantum state œÅ ‚ààD(H) and observable 
A ‚ààLs(H), the QM
formalism gives the average of this observable in this state, see (14.2).
We encode qualia of a QL cognitive image MIœÅ (which is encoded by a density
operator œÅ) by self-adjoint operators. Thus, qualia of a mental image (in the QLR
of information) are described by the space Ls(H). They are quantiÔ¨Åed by their
averages, via (14.2).
Contrary to classical processing, in the QLR the brain cannot quantify all qualia
simultaneously. There exist incompatible qualia; in particular, incompatible emo-
tions. The QL brain can select different representations of the mental image MIœÅ
and different collections of compatible qualia of the image. The QL brain escapes
the simultaneous use of e.g. some emotions (‚Äúincompatible emotions‚Äù). In this way
the QLR-processing differs essentially from classical processing. We can specu-
late that in the process of evolution, the brain created (on the basis of experience)
commutative algebras corresponding to compatible qualia.
Coupling between classical and quantum-like representations
The crucial point of the QLR of information is that this ‚Äúoperator-thinking‚Äù is
naturally coupled with the processing of classical electromagnetic signals. On the
level of mental images, we have:
(aMI). From the classical regime to QL: a classical signal œÜ induces the mental
image MIœÜ given by its covariance operator D = D(œÜ) and it is transferred to the
QLR through normalization by the trace D ‚ÜíœÅ = D/TrD. Thus, there is a map
from classical mental images to QL mental images MIœÜ ‚ÜíMIœÅ.
(bMI). From QL to classical: a QL mental image MIœÅ can be represented by
a classical (Gaussian) signal œÜ = œÜœÅ with the covariance operator œÅ, i.e. by the
image MIœÜ.
On the level of qualia we have:
(aQU). From the classical regime to QL: each functional of classical Ô¨Åeld, f (œÜ),
is represented by its second derivative ‚Äì self-adjoint operator, see (14.6).
(bQU). From QL to classical: each quantum qualia (given by a self-adjoint
operator) is represented by its quadratic form.

250
Neurophysiological sources of quantum-like processing in the brain
Since (aQU) is not one-to-one, i.e. since a huge class of different classical
qualia given by various functionals of the electromagnetic Ô¨Åeld (all functionals
with the same second derivative) is mapped into the same self-adjoint operator,
the QLR makes the mental picture less rich than it was in the classical repre-
sentation. The same can be said about (aMI). Various classical signals, concrete
mental images, can have the same covariance operator. Please note that we do
not claim that input signals are obligatory Gaussian, so there is no one-to-one
correspondence.
Take a classical mental image MIœÜ. It is represented by the covariance operator
D = D(œÜ). Of course, it can be mapped to a QL image MIœÅ, see aMI. Values of
all QL qualia can be obtained by scaling from values of corresponding classical
qualia, since, for any operator 
A ‚ààLs(H):
‚ü®
A‚ü©œÅ = TrœÅ 
A =
1
TrDTrD 
A
=
1
TrD

H
fA(œÜ)dŒº(œÜ) =
1
TrD‚ü®fA‚ü©œÜ,
where Œº is the probability distribution of the signal. We remark that:
TrD =

H
	
O
|œÜ(x)|2dx

dŒº(œÜ) = ‚ü®fI‚ü©
is the intensity of the signal, or in the cognitive model the intensity of feeling
of the mental image MIœÜ. Thus, QL qualia are normalized by the intensity of
feeling:
‚ü®
A‚ü©œÅ =

H fA(œÜ)dŒº(œÜ)

H

O |œÜ(x)|2dx

dŒº(œÜ).
The QL processing of all mental images is performed on the same level of
intensity of feeling, so it is ‚Äúcalm thinking.‚Äù We remark once again that some
classical qualia do not have a quantum counterpart.
14.5 Classical regime: time representation
As usual in signal theory, we can switch from the ensemble representation for
averages to the time representation (under the standard assumption of ergodicity).
Thus, instead of a random Ô¨Åeld œÜ(x, œâ), which is distributed with some probability
distribution dŒº(œÜ) on H, we consider a time-dependent signal:
œÜ(s) ‚â°œÜ(s, x),

14.5 Classical regime
251
where
x ‚ààO, s ‚àà[0, +‚àû).
Then,
for
each
functional
f (œÜ)
such
that

H |f (œÜ)|dŒº(œÜ) < ‚àû, we have (by ergodicity):
‚ü®f ‚ü©Œº ‚â°

H
f (œÜ)dŒº(œÜ) = lim
T ‚Üí‚àû
1
T
 T
0
f (œÜ(s))ds ‚â°‚ü®f ‚ü©œÜ.
(14.14)
Consider two time scales: œÑ is a Ô¨Åne scale and T >> œÑ is a rough time scale. In
QM the latter is the scale of measurements and œÑ is the scale of Ô¨Çuctuations of the
prequantum Ô¨Åeld.7 In cognitive science, we use the following interpretation of time
scales: T is the scale of the QLR and œÑ is the scale of the real physical processing
of the electromagnetic signal in the brain. Thus
‚ü®f ‚ü©œÜ ‚âà1
T
 T
0
f (œÜ(s))ds,
(14.15)
where s denotes the time variable at the œÑ-scale. We call the T -scale the mental
time scale. We can also speak about psychological time. The T -scale is the scale of
creation of mental images by the brain. The œÑ-scale is the physical processing scale
or premental time scale. Theoretical and experimental studies in neurophysiology
provide the following estimate of relative magnitudes of these time scales. If we
select œÑ = 1 mls., then T ‚âà80 mls.
For each signal œÜ(s, x), x ‚ààO, the brain can Ô¨Ånd its qualia, e.g. the strength of
feeling of this image:
‚ü®f ‚ü©Œº ‚âà1
T
 T
0
	
O
(E2(s, x) + B2(s, x))dx

ds.
(14.16)
In particular, emotions (special qualia) are given by such functionals, e.g.,
fanger, fsadness . . . Our formal mathematical model cannot provide the form of con-
crete emotion functionals. We hope that in the future it will be described as the
result of neurophysiological and cognitive studies.
In the time representation, the covariance operator (its bilinear form) of the
signal œÜ(s, x) is given by
(Du, v) = lim
T ‚Üí‚àû
1
T
 T
0
	
O
u(x)œÜ(s, x)dx

O
œÜ(s, x)v(x)dx

ds,
‚âà1
T
 T
0
	
O
u(x)œÜ(s, x)dx

O
œÜ(s, x)v(x)dx

ds,
(14.17)
where u(x), v(x) are two ‚Äútest signals,‚Äùu, v ‚ààL2(O).
7 The PCSFT does not predict the magnitude of the scale of prequantum Ô¨Åeld Ô¨Çuctuations. One may speculate
(motivated in particular by cosmology and string theory), cf. G. ‚Äòt Hooft [15] [16] and T. Elze [17]), that it
has to be the Planck scale œÑP ‚âà10‚àí44 s. If it were really the case, then prequantum Ô¨Çuctuations have only a
theoretical value: they will never be approached experimentally. However, in Khrennikov [18] we discussed a
possibility that the prequantum scale may have a larger magnitude and, hence, Ô¨Çuctuations will be sooner or
later approached experimentally.

252
Neurophysiological sources of quantum-like processing in the brain
14.6 Classical signal processing of mental images
This section contains a detailed presentation of the classical processing of infor-
mation, see Section 14.4. We proceed in the time representation of random signals.
CSP1. Electromagnetic Ô¨Åeld basis of mental images. Inputs from external
and internal worlds induce electromagnetic signals in the brain. Each signal has a
variety of qualia, in particular emotions associated with the signal œÜ(s, x). Qualia
are realized by various functionals, œÜ  ‚Üíf (œÜ), of the signal. They are quantiÔ¨Åed
by averages of these functionals, f  ‚Üí‚ü®f ‚ü©œÜ, see (14.14) and (14.16). In principle,
all possible qualia (e.g., emotions) can be jointly associated with œÜ(s, x).
The physical dynamics of a signal is in general non-linear and very complicated.
It depends essentially on the context of the signal processing:
œÜ(s, x) = œÜ(s0, x) +
 s
s0
dŒ±
	
O
K(x, y, Œ±; œÜ(Œ±, y); œÜ(s0, y))dy

,
(14.18)
where the kernel K depends on (i) the spatial variables x, y ‚ààO (the distribution
of the signal in the brain), (ii) the time variable Œ±, (iii) the previous dynamics of
the signal œÜ(Œ±, y), Œ± ‚àà[s0, s), and (iv) the signal at s = s0, the input. We remark
that the dynamics œÜ(s, x) depend on input not only additively, i.e. as the initial
state which then will evolve in accordance with some integral equation, but even
the kernel of the equation depends non-trivially on the input. Thus, the dynamics
are different for different inputs.
CSP2. Calculation of correlations, creation of mental images. For each signal
œÜ(s, x), the brain calculates the corresponding covariance operator D ‚â°D(œÜ), see
(14.17). The completion of this process, i.e. calculation of D, is associated with the
creation of the mental image, MIœÜ, induced by the signal, œÜ. Thus, on the cognitive
level, the brain is not interested in the dynamics of the physical signal (14.18). It is
only interested in the dynamics of the covariance operator
t  ‚ÜíD(t).
(14.19)
We remark that the dynamics (14.18) and (14.19) have different time scales. The
Ô¨Årst one is performed on the physical time scale and the second one on the mental
time scale. Thus, it is very important that the ‚Äúphysical brain‚Äù and the ‚Äúcognitive
brain‚Äù work on two different time scales: the scale of physical signal ‚Äì œÑ, and the
scale of the QLR ‚Äì T. The interval of time T >> œÑ, so its size justiÔ¨Åes the ergodic
interplay between ensemble and time representations of random signals.
CSP3. Memory of correlations. The density operator D is recorded in the brain.
The PCSFT basis of the model in combination with the ergodic argument makes
the following model of memory very attractive.

14.6 Classical signal processing
253
The operator D determines uniquely the Gaussian probability distribution ŒºD
(with zero mean value). The brain records this probability distribution. How can it
do this? We speculate that, to encode ŒºD, the brain uses the statistical distribution
by assigning statistical weights to elements of some ensemble . What are elements
of ? They might be neurons or even distributions of chemical components in the
brain. We emphasize once again that such a model of memory for probabilistic laws
is based on the ergodicity of processes in the brain: from a signal œÜ(s) ‚â°œÜ(s, x) (the
time representation) to its covariance, and from the covariance to the probability
distribution on an ensemble.8
CSP4. Recollection of images. Recollection is the process of activation of a
special mental image. We keep to the model of statistical (ensemble) representa-
tion of the probability distribution encoding the image, see CSP3. We obtain the
following procedure of recollection.
Suppose that a mental image MIœÜ was recoded in the memory, œÜ  ‚ÜíD =
D(œÜ)  ‚ÜíŒº = ŒºD.
The process of recollection proceeds as follows. Starting with the probability
distribution Œº, the brain computes the covariance operator D of this probability
distribution by using the ensemble averaging, see (14.3), (14.4).
On the basis of this covariance operator, it produces a signal œÜrecall(s, x), x ‚ààO,
a trajectory of the corresponding Gaussian process.
In this situation, the brain does not reproduce the original signal œÜ(s, x), see
CSP1. The graphs of œÜ(s, x) and œÜrecall(s, x) can differ essentially point wise. More-
over, the original signal œÜ(s, x) need not be Gaussian at all. However, correlations
inside both signals approximately coincide and, hence, their qualia:
‚ü®f ‚ü©œÜ = lim
T ‚Üí‚àû
1
T
 T
0
f (œÜ(s))ds ‚âàlim
T ‚Üí‚àû
1
T
 T
0
f (œÜrecall(s))ds = ‚ü®f ‚ü©œÜrecall.
We also remark that even two different recollections œÜ1
recall(s, x) and œÜ2
recall(s, x)
of the same image can be very different as physical signals ‚Äì two different realiza-
tions of the same Gaussian process. However, their qualia coincide:
‚ü®f ‚ü©ŒºD = lim
T ‚Üí‚àû
1
T
 T
0
f (œÜ1
recall(s))ds = lim
T ‚Üí‚àû
1
T
 T
0
f (œÜ2
recall(s))ds.
(14.20)
To be more precise, we say that they coincide approximately, since in reality the
brain does not calculate the limit for T ‚Üí‚àû, but it uses the Ô¨Ånite T. Thus:
‚ü®f ‚ü©ŒºD ‚âà1
T
 T
0
f (œÜ1
recall(s))ds ‚âà1
T
 T
0
f (œÜ2
recall(s))ds.
(14.21)
8 The choice of a Gaussian probability law can be debated. But at least mathematically it works well, because of
the one-to-one correspondence between covariance matrices and Gaussian probability distributions (with zero
mean values).

254
Neurophysiological sources of quantum-like processing in the brain
CSP5. Recognition of images. Suppose now that some mental image was saved
in the memory: starting with the input signal œÜ(s, x) and through its covariance
operator D(œÜ). As an example, consider the Moscow Kremlin. I revisit Moscow
once again and I look at the Kremlin. This visual input induces a signal q(s, x). Its
covariance operator D(q) is produced, see CSP2. It is compared with covariance
operators in the memory to match with the operator D(œÜ). Note that the model under
considerationdoes notdescribe the mechanismofthis comparingprocess. However,
see CSP5n (Section 14.6.1). Finally, matching of the operators, D(œÜ) ‚âàD(q), is
approached. This activates in the memory the statistical probability distribution
ŒºD(œÜ) in the form of a Gaussian signal œÜrecall(s, x). Its triggers the feeling of
recognition of the image, which was encoded by D(œÜ).
14.6.1 Classical signal processing of mental images:
Ô¨Ånite-dimensional approximations
In principle, the brain can calculate the complete covariance operator (14.17),
especially if it works as an analogous computational device. However, it consumes
a lot of computational resources. We might speculate that the brain selects a Ô¨Ånite
number of test functions. It is always possible to assume that they are orthogonal
in L2(O):
u1(x), . . . , un(x).
(14.22)
Instead of the complete covariance operator D = D(œÜ), the brain calculates its
cutoff, the covariance n √ó n matrix Dn = Dn(œÜ). Thus, instead of an inÔ¨Ånite
dimensional L2-space, the brain works (for a given mental function) in a Ô¨Åxed
Ô¨Ånite dimensional subspace Hn. We modify CSP1‚ÄìCSP5. The Ô¨Årst step CPS1 is
not changed. We have:
CSP2n. The signal œÜ(s, x) induces the mental image MIœÜ;n encoded by the
covariance matrix Dn.
CSP3n. The MIœÜ;n is recorded in the memory through the probability distribution
ŒºDn on the Ô¨Ånite-dimensional Hilbert space Hn.
CSP4n. On the basis of Dn, the brain produces a signal œÜrecall(t) in Hn. Its
activation is a recollection of the memory on MIœÜ;n.
CSP5n. The memory contains the image MIœÜ;n in the form of the matrix Dn(œÜ).
The new signal produces MIq;n with the covariance matrix Dn(q). These matrices
must be compared. Since a lot revolves around covariance matrices, so n √ó n
matrices, it is natural to expect a comparing algorithm which compares cutoffs of
these n √ó n covariance matrices. First, the matrix is of dimension two, then three,
and so on. Thus, Ô¨Årst the D2(q) is compared with 2 √ó 2 matrices obtained through
the projection of mental images on H2 until the cluster of matrices with the left-up

14.7 Quantum-like processing of mental images
255
block D2(q)(= D2(œÜ)) is found. Then inside this cluster the brain is looking for
the sub-cluster with the left-up block D3(q)(= D3(œÜ)) and so on.
How does the brain select the subspace Hn with the basis (14.22)?
The most natural way is to assume that it just selects a band of frequencies. It is
also natural that different mental functions may use different bands, i.e. different
Hilbert spaces. For mental functions F and G, two Hilbert spaces HF and HG are
used.
14.7 Quantum-like processing of mental images
We still proceed with the functioning of one Ô¨Åxed mental function, say F.
QLP1. Density operator code. At some stage in its growth, a cognitive sys-
tem creates a sufÔ¨Åciently extended database of classical mental images. They are
encoded by covariance operators which are transferred in density operators by
normalization, see (aMI), Section 14.4. Thus, the brain created a collection of QL
mental states borrowed from the classical processing, œÅ ‚ààDdata(H) which is a
subspace of D(H). At this stage the brain can be Ô¨Åne by working inside D(H), i.e.,
even without contact with the physical and mental environment.
QLP2. Unitary thinking. The processing of information inside D(H) is the
process of QL thinking. Starting with the operator œÅ0 the brain induces the evolution
œÅ(s) of the mental QL state. The simplest dynamics correspond to the process of
thinking in the absence of inputs from the environment (which includes the body).
It is given by the von Neumann equation:
i dœÅ(t)
dt
= [ 
H, œÅ(t)], œÅ(0) = œÅ0,
(14.23)
where 
H : H ‚ÜíH is the ‚Äúmental Hamiltonian‚Äù (given by a self-adjoint operator).
It describes the functioning of the mental function F under consideration.
In the simplest case, the Hamiltonian 
H is completely determined by the mental
function F, so 
H ‚â°
HF. However, even more complex dynamics seem to be
reasonable ‚Äì with 
H which also depends on the initial state œÅ0 : 
H ‚â°
HF,œÅ0 (cf.
with the QL model of decision making, Chapter 9).
We remark that by starting with e.g. the QL version of a concrete image, i.e.,
œÅ0 ‚ààDdata(H), the QL dynamics can go away from this subspace of D(H). New
‚Äúreally QL‚Äù images are created. They can be visualized through the production of
corresponding classical signals, see (bMI), Section 14.4.
We emphasize that the QL dynamics of mental images is performed on the T -
scale which is rough compared with the œÑ-scale of physical processing of signals
in the brain. Each instant of time t of the T -scale is the (large) interval T of the
s-time.

256
Neurophysiological sources of quantum-like processing in the brain
It may be more illustrative to consider the discrete dynamics, the mental time t
is considered as the discrete parameter: tn = nT. Then
iœÅ(tn+1) = T [ 
H, œÅ(tn)], œÅ(0) = œÅ0.
(14.24)
QLP3. Dynamics of QL qualia. In QL processing qualia are reduced to
quadratic functionals of premental (physical) signals. These functionals are rep-
resented by their QL counterparts ‚Äì corresponding self-adjoint operators. The
evolution of QL qualia is described by the Heisenberg equation:
‚àíi d 
A(t)
dt
= [ 
H, 
A], 
A(0) = 
A0,
(14.25)
or in the discrete representation of the mental time:
i 
A(tn) = T [ 
H, 
A(tn)], 
A(0) = 
A0.
(14.26)
The qualia (encoded by 
A) of a mental image MIœÅ (encoded by the density operator
œÅ) is quantiÔ¨Åed by its average, given by the quantum formula (14.2).
Of course, the transition from the class of classical qualia (given by arbitrary
functionals of signals) to QL mental features corresponding to only quadratic func-
tionals simpliÔ¨Åes the mental representation of an image. However, this reduction
can be justiÔ¨Åed by (14.7) in the framework of the QLR (14.6) of classical functionals
of signals.
QLP4. Thinking via operator algebra. This is the crucial point. In QL think-
ing, the brain switches from the classical physical signal processing, i.e. non-linear
equations of the type (14.18) to the linear processing of mental images represented
by density operators (14.26). The representation of qualia is also essentially sim-
pliÔ¨Åed and it can be done in the linear operator form. Our conjecture is that the
brain is really able to realize such linear operator processing of mental entities.
This type of processing is especially proÔ¨Åtable for ‚Äúabstract thinking,‚Äù i.e. thinking
which has a high degree of independence from inputs.
How does the brain realize the QL (operator) processing on the physical level?
We do not know yet. However, we hope that our model may stimulate neurophys-
iologists to look for the corresponding neuronal representation of QL processing.
We can present the following scheme of mental operator processing.
Since the brain has no other computational resources different from neural elec-
tric activity, it seems reasonable to assume that the QL mental dynamics ((14.26),
(14.29)) also has to be performed through this activity. The production of density
operators can be done similarly to the production of covariance operators in the
classical regime. The only difference is that the brain wants to escape the com-
plicated non-linear evolution (14.18). We consider the following stochastic linear

14.7 Quantum-like processing of mental images
257
dynamics in Hilbert space H (of classical electromagnetic Ô¨Åelds):
‚àÇœÜ
‚àÇt (t, x, œâ) = 
HœÜ(t, x, œâ), œÜ(t0, x, œâ) = œÜ0(x, œâ),
(14.27)
where the random variable œÜ0(x, œâ) is the Gaussian Ô¨Åeld with zero mean value
and the covariance operator œÅ0. Hence, ‚ü®œÅ0u, v‚ü©= E‚ü®œÜ0, u‚ü©‚ü®v, œÜ0‚ü©, u, v ‚ààH. The
solution of the Cauchy problem (14.27) is the random Ô¨Åeld:
œÜ(t, x, œâ) = UtœÜ0(x, œâ),
(14.28)
where ut = e‚àíit 
H is the standard for QM one parametric group of unitary oper-
ators. The covariance operator œÅ(t) ‚â°œÅœÜ(t) can be easily found: ‚ü®œÅ(t)u, v‚ü©=
E‚ü®UtœÜ0, u‚ü©‚ü®v, UtœÜ0‚ü©= E‚ü®œÜ0, U ‚àó
t u‚ü©‚ü®U ‚àó
t v, œÜ0‚ü©= ‚ü®œÅ(t)U ‚àó
t u, U ‚àó
t v‚ü©. Thus:
œÅ(t) = UtœÅ0U ‚àó
t .
This operator valued function œÅ(t) satisÔ¨Åes the von Neumann equation (14.29).
Thus, the von Neumann evolution of the mental state can be induced by the linear
dynamics with random initial condition (14.27). As was mentioned, the crucial
point is that those dynamics are much simpler than the ‚Äúclassical signal dynamics‚Äù
(14.18).
Finally, we have the following model of physical realization of the evolution
(14.29). In fact, the brain produces the Gaussian random signal by realizing on the
neuronal level the linear Schr¬®odinger type evolution. At each moment of mental
time t by calculating its covariance operator, the brain creates the mental image
given by the covariance density operator œÅ(t).
In quantum information theory it is well known that in general, i.e. in the
presence of interaction with the environment, the von Neumann equation should
be modiÔ¨Åed to the Gorini‚ÄìKossakowski‚ÄìSudarshan‚ÄìLindblad equation:
i dœÅ(t)
dt
= L(œÅ(t)), œÅ(0) = œÅ0,
(14.29)
where L : L(H) ‚ÜíL(H) is a linear map with special properties. All previous
considerations can be easily generalized to such mental dynamics.
QLP5. Concepts. Consider a subspace L of H and the orthogonal projector œÄ ‚â°
œÄHL : H ‚ÜíL. It induces the map œÄ : D(H) ‚ÜíD(L),
œÅL ‚â°œÄ(œÅ) =
œÄœÅœÄ
TrœÄœÅœÄ .
Mental images corresponding to elements of D(L) can be considered as abstractions
of mental images corresponding to elements of D(H). We call them L concepts or
simply concepts. Take some œÅL ‚ààD(L). The mental image MIœÅL can be interpreted

258
Neurophysiological sources of quantum-like processing in the brain
as an abstract concept induced by the cluster of mental images:
WœÅL = {œÅ ‚ààD(H) : œÄ(œÅ) = œÅL}.
Each concept is based on common correlations of a cluster of mental images. It is
especially interesting to consider the case dim L = m, and m is quite small. These
are very abstract concepts which contain only the basic common correlations in a
huge cluster of mental images. It is extremely proÔ¨Åtable for the brain to think on
the conceptual level, especially to operate in a Ô¨Ånite-dimensional L. The operator
unitary dynamics (14.29) is reduced to the matrix dynamics. Conceptually, the
Hamiltonian is given by a symmetric m √ó m matrix. For small m, the dynamics of
such a type are very simple and processing is very rapid.
For example, consider the QLR for the concept ‚Äúhouse.‚Äù In the classical regime,
the brain created a collection of images of concrete houses MI1, . . . , MIk. They
were classically encoded by covariance operators D1, . . . , Dk. These operators
contain some common correlations. In the matrix representation, they have a com-
mon block. For simplicity, suppose that this block is of the diagonal type. Consider
a subspace L of H related to this block. Then this block can be represented as a
self-adjoint and positive operator DL in L. We have:
DL = œÄDjœÄ, j = 1, 2, . . . , k,
where œÄ : H ‚ÜíL is the orthogonal projector. Its QL image is given by
QL = DL/TrDL =
œÄDjœÄ
TrœÄDjœÄ =
œÄ(Dj/TrDj)œÄ
TrœÄ(Dj/TrDj)œÄ =
œÄœÅjœÄ
TrœÄœÅjœÄ = œÅL.
Here œÅj are QL representations of the covariance operators Dj. The density operator
œÅL gives the abstract concept of house.
We now describe the process of creation of a concept of a higher level of
abstractness from a cluster of concepts. Consider a subspace Z of L. The brain can
create new concepts belonging to D(Z) starting with clusters of L concepts. Of
course, it can proceed directly starting with mental images from D(H). However,
such step-by-step increasing of the level of abstraction is very natural.
QLP6. Neuronal location of the QL processor. From the general viewpoint there
are no reasons to assume that the QLR is realized in the same physical domain, i.e.
there is the same ensemble of neurons, as in classical processing. It may be that there
is a special domain OQL which is used for dynamics (14.29). Our model induced
an interesting problem of experimental neurophysiology, i.e. to Ô¨Ånd domains of
the brain coupled to the QLR. If the hypothesis that the dynamics (14.29) of
mental images is based on the physical dynamics (14.27) is correct, then domains
of the QLR can be identiÔ¨Åed by the presence of Gaussian stochastic dynamics.

14.8 Composite systems
259
Unfortunately, at the present level of measurements it is impossible to measure
directly the electromagnetic Ô¨Åeld inside the brain (at least to make measurements
in a sufÔ¨Åciently dense set of points). However, even the measurement technology
based on EEG provides a possibility of reconstruction of the Ô¨Åeld inside the brain
by using the methods of the inverse problem.
QLP7. Quantum-like consciousness. We may speculate that consciousness can
be associated with QL processing in the brain. The von Neumann equation (or more
generally the Gorini‚ÄìKossakowski‚ÄìSudarshan‚ÄìLindblad equation) represents the
‚Äúcontinuous Ô¨Çow of consciousness.‚Äù The feeling of continuity is generated through
the averaging of physical signals with respect to the mental time scale, i.e. the
representation of mental images by covariance density operators. In fact, on the
physical time scale the dynamics are discrete, see (14.26).
QLP8. Correspondence between classical and quantum qualia. Consider a clas-
sical quale given by a functional f (œÜ). The corresponding quantum quale is given
by the self-adjoint operator, the second derivative of f (œÜ) at the point œÜ = 0. In
general, the behavior of the functional f (œÜ) differs essentially from the behavior of
its quadratic part. However, on the level of averages the difference is not so large:
in the limit œÑ/T ‚Üí0 they coincide, see (14.7).
14.8 Composite systems
We turn again to physics. As remarked in Khrennikov [19] (pp. 2‚Äì3), in CSM, a
composite system S = (S1, S2) is mathematically described by the Cartesian prod-
uct of state spaces of its parts S1 and S2. In QM, it is described by the tensor
product. The majority of researchers working in quantum foundations and, espe-
cially quantum information theory, consider this difference in the mathematical
representation as crucial. In particular, the entanglement which is a consequence of
the tensor space representation is considered as a totally non-classical phenomenon.
However, we recall that Einstein considered the EPR-states as exhibitions of classi-
cal correlations due to the common preparation. The PCSFT will realize Einstein‚Äôs
dream on entanglement.
Let S = (S1, S2), where Si has the state space Hi ‚Äì complex Hilbert space.
Then, by the CSM, the state space of S is H1 √ó H2. By extending the PCSFT
to composite systems, we should describe ensembles of composite systems by
probability distributions on this Cartesian product, or by a random Ô¨Åeld œÜ(x, œâ) =
(œÜ1(x, œâ), œÜ1(x, œâ)) ‚ààH1 √ó H2.
In our approach, each quantum system is described by its own random Ô¨Åeld: Si
by œÜi(x, œâ), i = 1, 2. However, these Ô¨Åelds are CORRELATED ‚Äì in a completely
classical sense. Correlation at the initial instant of time s = s0 propagates in time

260
Neurophysiological sources of quantum-like processing in the brain
in complete accordance with the laws of QM. There is no action at a distance. We
have purely classical dynamics of two stochastic processes which were correlated
at the beginning. In fact, the situation is more complex: there is also the common
random background, i.e. vacuum Ô¨Çuctuations. We shall come back to this question
in future research.
14.8.1 Operator realization of wave function
Consider now the QM model. Take a pure state case  ‚ààH1 ‚äóH2. Can one
peacefully connect the QM and the PCSFT formalisms? Yes! But  should be
interpreted in a completely different way than in conventional QM.
The main mathematical point is:  is not a vector! It is an operator! It is,
in fact, the non-diagonal block of the covariance operator of the corresponding
prequantum random Ô¨Åeld: œÜ(x, œâ) ‚ààH1 √ó H2. The wave function (x, y) of a
composite system determines the integral operator:
œÜ(x) =

(x, y)œÜ(y)dy.
We keep now to the Ô¨Ånite-dimensional case. Any vector  ‚ààH1 ‚äóH2 can be
represented in the form  = m
j=1 œàj ‚äóœáj, œàj ‚ààH1, œáj ‚ààH2, and it determines
a linear operator from H2 to H1
œÜ =
m

j=1
(œÜ, œáj)œàj, œÜ ‚ààH2.
(14.30)
Its adjoint operator ‚àóacts from H1 to H2 : ‚àóœà = m
j=1(œà, œàj)œáj, œà ‚ààH1.
Of course, ‚àó: H1 ‚ÜíH1 and ‚àó : H2 ‚ÜíH2 and these operators are self-
adjoint and positively deÔ¨Åned. Consider the density operator corresponding to a
pure quantum state, œÅ =  ‚äó. Then, the operators of the partial traces œÅ(1) ‚â°
TrH2œÅ = ‚àóand œÅ(2) ‚â°TrH1œÅ = ‚àó.
14.8.2 Basic equality
Let  ‚ààH1 ‚äóH2 be normalized by 1. Then, for any pair of linear bounded opera-
tors 
Aj : Hj ‚ÜíHj, j = 1, 2, we have:
Tr 
A2‚àó
A1 = ‚ü®
A1 ‚äó
A2‚ü© ‚â°(
A1 ‚äó
A2, ).
(14.31)
This is a mathematical theorem (Khrennikov [10]). It will play a fundamental role
in further considerations.

14.8 Composite systems
261
14.8.3 Coupling of classical and quantum correlations
In the PCSFT a composite system S = (S1, S2) is mathematically represented by
the random Ô¨Åeld œÜ(œâ) = (œÜ1(œâ), œÜ2(œâ)) ‚ààH1 √ó H2. Its covariance operator D has
the block structure
D =
	D11
D12
D21
D22

,
where Dii : Hi ‚ÜíHi, Dij : Hj ‚ÜíHi. The covariance operator is self-adjoint.
Hence, D‚àó
ii = Dii, and D‚àó
12 = D21.
Here by the deÔ¨Ånition: (Dijuj, vi) = E(uj, œÜj(œâ))(vi, œÜi(œâ)), ui ‚ààHi, vj ‚àà
Hj. For any Gaussian random vector œÜ(œâ) = (œÜ1(œâ), œÜ2(œâ)) having zero aver-
age and any pair of operators 
Ai ‚ààLs(Hi), i = 1, 2, the following equal-
ity takes place: ‚ü®fA1, fA2‚ü©œÜ ‚â°EfA1(œÜ1(œâ))fA2(œÜ2(œâ)) = (TrD11 
A1)(TrD22 
A2) +
TrD12 
A2D21 
A1. We remark that TrDii 
Ai = EfAi(œÜi(œâ)), i = 1, 2. Thus, we have
fA1fA2 = EfA1EfA2 + TrD12 
A2D21 
A1. Consider a Gaussian vector random Ô¨Åeld
such that D12 = :
E(fA1 ‚àíEfA1)(fA2 ‚àíEfA2) = (
A1 ‚äó
A2, ) ‚â°‚ü®
A1 ‚äó
A2‚ü©,
(14.32)
or, for the covariance of two classical random vectors fA1, fA2, we have:
cov (fA1, fA2) = ‚ü®
A1 ‚äó
A2‚ü©.
14.9 References
[1] Hameroff, S. (1994). Quantum coherence in microtubules: a neural basis for emergent
consciousness? Journal of Consiousness Studies, 1, 91‚Äì118.
[2] Hameroff, S. (1994). Quantum computing in brain microtubules? The Penrose‚Äì
Hameroff Orch Or model of consciousness. Philosophical Transactions of the Royal
Society; London A 1-28.
[3] Penrose, R. (1989). The Emperor‚Äôs New Mind. Oxford University Press.
[4] Penrose, R. (1994). Shadows of the Mind. Oxford University Press.
[5] Khrennikov, A. Yu (2010). On the physical basis of the theory of ‚Äúmental waves.‚Äù
Neuroquantology, 8, 4 (Supp. 1), S71‚ÄìS80.
[6] Khrennikov, A. Yu (2011). Quantum-like model of processing of information in the
brain based on classical electromagnetic Ô¨Åeld. Biosystems 105, 250‚Äì262.
[7] Khrennikov, A. Yu. (2005). Prequantum classical statistical model with inÔ¨Ånite dimen-
sional phase-space. Journal of Physics A: Mathematical and General, 38, 9051‚Äì9073.
[8] Khrennikov, A. Yu. (2005). Generalizations of quantum mechanics induced by
classical statistical Ô¨Åeld theory. Foundations of Physics Letters, 18, 637‚Äì650.
[9] Khrennikov, A. Yu. (2007). Nonlinear Schr¬®odinger equations from prequantum
classical statistical Ô¨Åeld theory. Physics Letters A, 357, 171‚Äì176.
[10] Khrennikov, A. Yu. (2009). Entanglement‚Äôs dynamics from classical stochastic
process. Europhysics Letters, 88, 40005.

262
Neurophysiological sources of quantum-like processing in the brain
[11] Khrennikov, A. Yu. (2008). The quantum-like brain on the cognitive and subcognitive
time scales. Journal of Consciousness Studies, 15, 39‚Äì77.
[12] Fichtner, K. H., Fichtner, L., Freudenberg, W., and Ohya, M. (2008). On a quantum
model of the recognition process. In Quantum Probability and White Noise Analysis.
Eds. Accardi, L., Freudenberg, W., and Ohya, M.; 21, 64‚Äì84; World ScientiÔ¨Åc.
[13] Einstein, A. and Infeld, L. (1961). Evolution of Physics: The Growth of Ideas from
Early Concepts to Relativity and Quanta. Simon & Schuster.
[14] Khrennikov, A. Yu. (2009). Contextual Approach to Quantum Formalism. Springer
Verlag, Berlin.
[15] ‚Äòt Hooft, G. (2002). Determinism beneath quantum mechanics. Conference
Proceedings ‚ÄúQuo Vadis Quantum Mechanics‚Äù; Philadelphia (see also http://arxiv.
org/abs/quant-ph/0212095; Cornell University.
[16] ‚Äôt Hooft, G. (2007). The free-will postulate in quantum mechanics. Please see
http://arxiv.org/abs/quant-ph/0701097; Cornell University.
[17] Elze, T. (2008). The attractor and the quantum states. Please see http://arxiv.
org/abs/0806.3408; Cornell University.
[18] Khrennikov, A. Yu. (2008). Quantum randomness as a result of random Ô¨Çuctuations
at the Planck time scale? International Journal of Theoretical Physics, 47, 114‚Äì124.
[19] Khrennikov, A. Yu. (2011). A classical Ô¨Åeld theory comeback? The classical Ô¨Åeld
viewpoint on triparticle entanglement. Physica Scripta, T143, 014013 (6pp).

15
Conclusion
This book had as its main objective to discuss how (quantum) physics concepts
could be used in a relevant way in the modeling of a variety of economics/Ô¨Ånance
and psychology-based processes.
For those readers who have come to read this conclusion, without skipping its
‚Äúbackbone,‚Äù we would like to say ‚Äúthank you‚Äù for keeping with us until the end.
The possible claim, which says that social science driven dynamics would need
analyzing with techniques from the natural sciences, may well have been tempered
with this book. Although quantum physics as a theory of prediction is one of the
most successful theories humankind ever devised, it is not unreasonable to suggest
that the number of foundational interpretations of quantum physics is sizable.
Consider now the following natural question: ‚ÄúHow can a theory with such a
wide diversity of foundational interpretations serve to inform and elucidate a non-
cognate area of research (like economics or psychology)?‚Äù Indeed, we should want
to stand upright and write, without hesitation, the words ‚Äúnon-cognate.‚Äù
No theory in social science can come close to the predictive power of quantum
physics. However, very few social science theories are ‚Äúplagued‚Äù by foundational
issues of such depth as quantum physics. As an example, consider the issue of why
quantum physical wave functions do have to be complex valued. Do physicists
have a satisfactory answer to this very basic question? A theory of such predictive
power has a partial differential equation, the Schr¬®odinger equation, which cannot be
rigorously derived. However, in economics and Ô¨Ånance we strive to build theoretical
ediÔ¨Åces with the utmost respect for rigor.
Consider the recent Ô¨Ånancial crisis. Are we comfortable to propose that physics
should now lend a helping hand to the social sciences? This is indeed an extremely
difÔ¨Åcult question. There are good examples of theories in Ô¨Ånance which can be
reformulated in (quantum) physics-based terms. Option pricing is one such theory.
In economics, expected utility and the violation of the sure-thing principle can
be explained with the concept of probability interference. However, it is unclear
263

264
Conclusion
whether those novel viewpoints have added to our understanding of the pricing or
decision making processes expressed in the above two examples.
We hope that this book has given more clues to aid in our understanding of how
certain foundational aspects in the theories of Ô¨Ånance, economics, and psychology
can be re-interpreted. We may have opened up new avenues for research but it
is still far too early to ascertain whether this bears any promise. However, there
may be ‚Äúrays of light‚Äù on the horizon. As an example, we can observe that several
important research funding agencies have now provided Ô¨Ånancial aid to projects
which involve the use of quantum physical techniques in psychology, Ô¨Ånance, and
economics. This is a healthy positive step forward and we can only hope that this
continued support can muster sufÔ¨Åcient enthusiasm and wit around the world so
that true breakthroughs can be expected in the near future. We may soon be in dire
need for those.

Glossary of mathematics, physics, and
economics/Ô¨Ånance terms
Some mathematics based deÔ¨Ånitions (in alphabetical order)
r Bayes‚Äô formula: the conditional probability P(B|A) is deÔ¨Åned by using the prob-
ability P(B ‚à©A) of the intersection of events A and B (their joint occurrence):
P(B|A) = P(B‚à©A)
P(A) ; P(A) > 0.
r Bra vector: elements of the dual space H ‚àó, the space of linear continuous func-
tionals on H, are called bra vectors. They are denoted as ‚ü®œÜ| (see also ‚ÄúKet
vector‚Äù below).
r Complex numbers: z = x + iy; x, y ‚ààR and i2 = ‚àí1.
r Dirac braket: it can be deÔ¨Åned as ‚ü®œà1|wœà2‚ü©‚â°

œà‚àó
1 (wœà2)dv, where œà‚àó
1 denotes
the complex conjugate of the state function œà1, and the operator w acts on the
state function œà2.
r Eigenstate equation ‚Äì see ‚ÄúEigenvalue equation‚Äù below: when the function fl is
replaced by a quantum mechanical wave function, œà, the eigenvalue equation is
often re-named as an eigenstate equation: wœà = lœà, and œà can be seen as an
eigenstate.
r Eigenvalue equation: this equation for an operator w, with eigenfunction fl and
eigenvalue l, is given by wfl = lfl (see ‚Äúeigenstate equation‚Äù above).
r Fourier integral of a function f : f (x) =
1
‚àö
2œÄ
 ‚àû
‚àí‚àû
f (w) exp(iwx)dw, where i is
a complex number (see ‚ÄúFourier transform‚Äù below).
r Fourier transform of a function f : 
f (w) =
1
‚àö
2œÄ
 ‚àû
‚àí‚àûf (x) exp(‚àíiwx)dx, where
i is a complex number. Note that f (x) (i) needs to be piecewise continuous on
every Ô¨Ånite interval and (ii) f (x) is absolutely integrable on the X-axis.
r h-derivative of a function f : Dhf (x) = dhf (x)
dh(x) = f (x+h)‚àíf (x)
(x+h)‚àíx
.
r h-differential of a function f : dhf (x) = f (x + h) ‚àíf (x).
r Hermitian Hamiltonian: the Hamiltonian, 
H, is Hermitian when
 
Hœà1|œà2

=

œà1| 
Hœà2

, where ‚ü®.|.‚ü©is a Dirac braket.
265

266
Glossary of mathematics, physics, and economics/Ô¨Ånance terms
r Hilbert space: see Chapter 4: Vector calculus and other mathematical prelimi-
naries.
r InÔ¨Ånitesimal transformation: see entry ‚ÄúDirac brakets and bras and kets‚Äù in
Chapter 4: Vector calculus and other mathematical preliminaries.
r Hyperbolic numbers: z = x + jy; x, y ‚ààR, and j 2 = +1.
r Kantian prejudice: physical space has to be identiÔ¨Åed with its Euclidean model
(later modiÔ¨Åed by Lobachevsky and Einstein) ‚Äì see also ‚ÄúLaplace‚Äôs prejudice‚Äù
in Chapter 1: Classical, statistical, and quantum mechanics: all in one.
r Ket vector: elements of the Hilbert space H are called ket vectors and they are
denoted as |œà‚ü©(see also ‚Äúbra vector‚Äù above).
r Linear space: see Chapter 4: Vector calculus and other mathematical
preliminaries.
r Operator: an operator, w, is deÔ¨Åned relative to a function f (x) in the following
way: g(x) = wf (x).
r Operator (adjoint): see entry ‚ÄúDirac brakets and bras and kets‚Äù in the Chapter 4:
Vector calculus and other mathematical preliminaries.
r Operator (bounded): an operator w is bounded if: ‚à•w‚à•= sup{‚ààH:‚à•‚à•=1}
‚à•wœà‚à•< ‚àû.
r Operator (Hermitian): an operator, w, is Hermitian if ‚ü®wœà1|œà2‚ü©= ‚ü®œà1|wœà2‚ü©,
where ‚ü®.|.‚ü©is a Dirac braket.
r Operator (idempotent): an operator w is idempotent if w2 = w.
r Operator (identity): such an operator leaves a quantum state unchanged. As an
example, in the Heisenberg uncertainty principle, one can write the identity
operator qp ‚àípq = i¬Øh1, where1 is the identity operator.
r Operator (inverse): an inverse operator is such that ww‚àí1 = w‚àí1w = identity
operator.
r Operator (linear): i) wŒ±œà = Œ±wœà and ii) w [Œ±œà1 + Œ≤œà2] = Œ±wœà1 + Œ≤wœà2,
where Œ± and Œ≤ are arbitrary complex constants, and w and v are operators. See
also entry ‚ÄúOperators‚Äù in Chapter 4: Vector calculus and other mathematical
preliminaries.
r Operator (momentum): p = ‚àíi¬Øh ‚àÇ
‚àÇq , where q is position, i is a complex number,
and ¬Øh is the rationalized Planck constant.
r Operator (non-commutative): consider a function f (x), operators q, p do not
commute if qpf (x) Ã∏= pqf (x).
r Operator (projection): an operator which is idempotent and Hermitian.
r Operator
(unitary):
see
entry
‚ÄúDirac
brakets
and
bras
and
kets‚Äù
in
Chapter 4: Vector calculus and other mathematical preliminaries.
r Ordinary differential equation (ODE): F(x, y, y‚Ä≤ . . . y(n)) = 0, where y are func-
tions of x and y‚Ä≤ indicates the Ô¨Årst ordinary derivative towards x; similarly for
y(n), which indicates the nth derivative towards x.

Glossary of mathematics, physics, and economics/Ô¨Ånance terms
267
r Ordinary differential equation (ODE) (linear): An ODE will be linear if F is a
linear function of the variables y, y‚Ä≤ . . . y(n).
r q-derivative of a function f : Dqf (x) = dqf (x)
dq(x) = f (qx)‚àíf (x)
qx‚àíx
.
r q-differential of a function f : dqf (x) = f (qx) ‚àíf (x).
r Stochastic matrix (double): a square matrix of non-negative real numbers, where
each row and each column sums to 1.
r Stochastic matrix (right): a square matrix where each of its rows consists of
non-negative real numbers, with each row summing to 1.
r Stochastic matrix (left): a square matrix whose columns consist of non-negative
real numbers whose sum is 1.
r Unitary transformation: see entry ‚ÄúDirac brakets and bras and kets‚Äù in Chapter 4:
Vector calculus and other mathematical preliminaries.
Some physics-based deÔ¨Ånitions (in alphabetical order)
r Bohr‚Äôs postulate: an electron can move only on a discrete set of orbits and hence
its energy can take only a discrete series of values.
r Bohr‚ÄìHeisenberg Copenhagen interpretation of quantum mechanics: this inter-
pretation says that the wave function of a quantum system provides the
most complete description of its state, i.e. no Ô¨Åner description could be
created.
r Born‚Äôs rule (discrete version): the probability to Ô¨Ånd a particle at the point x of
physical space is given by the square of the absolute value of the œà-function
(complex probability amplitude).
r de Broglie relation: p = ¬Øhk; p is momentum and ¬Øh is the rationalized Planck
constant; k is the wave number.
r Conditioning (context): conditioning which is not only based on the Bayes‚Äô
formula and Boolean algebra, since a context C need not (although can in some
cases) be associated with any event.
r Conditioning (event): conditioning which is based on the Bayes‚Äô formula and
Boolean algebra.
r Conservative force: f (x) = ‚àídV
dx , where f is force, V is the real potential, x is
position.
r Context: a context C is a complex of conditions: for instance physical, social,
Ô¨Ånancial.
r Continuity equation: ‚àÇR2
‚àÇt + 1
m
‚àÇ
‚àÇq

R2 ‚àÇS
‚àÇq

= 0, where R is the amplitude of the
wave function, S is the phase of the wave function, m is mass, q is position, t is
time.
r Correspondence principle: the principle which establishes a coupling between
classical and quantum mechanics.

268
Glossary of mathematics, physics, and economics/Ô¨Ånance terms
r Double slit experiment: the basic experiment in quantum mechanics which indi-
cates wave-particle duality.
r Energy preservation in the process of motion: H(q(t), p(t)) = H(q(t0), p(t0)),
where H is the Hamiltonian function (please see below for ‚ÄúHamiltonian func-
tion‚Äù).
r Factorizability of the density: the probabilistic independence of particles (this
does not imply factorization of the probability amplitude).
r Hamiltonian function: H(q, p) = p2
2m + V (q), where p is momentum, m is mass,
V (.) is the real potential, p2
2m is kinetic energy, q is position.
r Hamilton‚ÄìJacobi equation: consider the equation
‚àÇS
‚àÇt +
1
2m

‚àÇS
‚àÇq
2
+ (V ‚àí
h2
2mR
‚àÇ2R
‚àÇq2

= 0, where S is the phase of the wave function, t is time, m is mass, q
is position, h is the Planck constant, V is the real potential, R is the amplitude
function. When
h2
2m << 1 and let
h2
2mR
‚àÇ2R
‚àÇq2 be negligibly small, then the above
equation is a Hamilton‚ÄìJacobi equation.
r Heisenberg‚Äôs postulate: operators on position and momentum should satisfy a
peculiar commutation relation (the Heisenberg uncertainty principle).
r Heisenberg uncertainty relation (Ô¨Årst proven by Kennard (1927) ‚Äì see
Chapter 1: Classical, statistical, and quantum mechanics: all in one): œÉxœÉp ‚â•¬Øh
2,
where ¬Øh = h/2œÄ, and œÉx, œÉp are the standard deviations of respectively position
and momentum.
r Information: i = ‚àí
j
pj ln pj, where pj is a probability distribution of states
and the index j can describe a feature of a system (or a particle for instance).
r Information gain: K = 
j pj ln pj
p
‚Ä≤
j , where pj and p‚Ä≤
j are different probability
distributions (see also ‚ÄúInformation‚Äù above).
r Maps (quantum information theory): a map is important for describing an infor-
mation transmission such as a measurement process or a signal transmission.
r Mean
forward
derivative
of
a
function
f :
D+f (x, t) = lim
t‚Üí0
E

f (x(t+
t),t+
t)‚àíf (x(t),t)

t

, where t is time.
r Mean
backward
derivative
of
a
function
f :
D‚àíf (x, t) = lim
t‚Üí0
E

f (x(t),t)‚àíf (x(t‚àí
t),t‚àí
t)

t

, where t is time.
r Mixed state: such a state is obtained when a statistical mixture of wave functions
is used.
r Newton‚Äôs second law: m.a = f , m is mass, a is acceleration, f is force.
r Newton‚ÄìBohm equation: m d2q(t)
dt2
= ‚àí‚àÇV (q,t)
‚àÇq
‚àí‚àÇQ(q,t)
‚àÇq
, where m is mass, q is
position, V is the real potential, and Q is the quantum potential. Q(q, t) depends
on the wave function, and the wave function evolves according to the Schr¬®odinger
equation. The initial conditions are q(t0) = q0 and q‚Ä≤(t0) = q‚Ä≤
0 (momentum).

Glossary of mathematics, physics, and economics/Ô¨Ånance terms
269
r No-go theorems: theorems about the impossibility to construct ‚Äúprequantum
models‚Äù reproducing the probabilistic predictions of quantum mechanics and
operating with classical probabilities.
r Non-local realism: a condition of the world where determinism holds true. There
is instantaneous action (with transmission speed faster than speed of light) at a
distance.
r Non-stationary states: when the wave function is not separable, then we must
obtain a non-stationary state.
r Operators
on
position
and
momentum
(respectively):
ÀÜqœà(q) = qœà(q),
ÀÜpœà(q) = ‚àíi¬Øh ‚àÇœà(q)
‚àÇq , where œà(q) is a square integrable function, i is a complex
number.
r Planck constant: h ‚âà6.6260693(11) √ó 10‚àí34 J √ó sec.
r Polar form of wave function: œà(q, t) = R(q, t)ei S(q,t)
h , where R(q, t) = |œà(q, t)|,
S(q, t)/h is the phase of the wave function (divided by the Planck constant), q
is position, t is time.
r Prequantum approach: approach by which classical-like models reproduce
results of quantum experiments have been created.
r Prequantum classical statistical Ô¨Åeld theory (PCSFT): in this model quantum
non-locality has been reduced to classical correlations in the background Ô¨Åeld
(please see below for ‚Äúquantum non-locality‚Äù).
r Probability interference term: 2 |œà1(x)| |œà2(x)| cos (S1 ‚àíS2), where Si(x) is the
phase of the wave function i and |œài(x)| is the amplitude of the wave function i.
r Pure state: when a system is described by a single wave function then it is called
a pure state.
r Quantization: a transition from functions on the phase space, f (q, p), to Her-
mitian matrices or more generally operators, by using operators of position and
momentum, instead of corresponding classical variables.
r Quantum entanglement: the existence of wave functions of the form œà(q1, q2) =
œà1(q1)œà2(q2) + œà2(q1)œà1(q2). The correlation of phases (and not the coordi-
nates) is the essence of quantum entanglement.
r Quantum-like approach: the approach by which we do not start with a classical
model and then quantize it, but we directly mimic the quantum approach.
r Quantum non-locality: a consequence of quantum entanglement (please see
above for ‚Äúquantum entanglement‚Äù).
r Quantum potential: ‚àíh2
2mR
‚àÇ2R
‚àÇq2 , where R is the amplitude of the wave function, m
is mass and q is position, h is the Planck constant.
r Quantum state representation: only normalizable state functions can represent
a quantum state. The state function, before complex conjugation is applied, is
indicative of the probability wave or the probability amplitude.
r Rationalized Planck constant: ¬Øh = h/2œÄ.

270
Glossary of mathematics, physics, and economics/Ô¨Ånance terms
r Schr¬®odinger partial differential equation (time dependent ‚Äì for one particle sys-
tem): i¬Øh ‚àÇœà(q,t)
‚àÇt
= ‚àí¬Øh2
2m
‚àÇ2œà(q,t)
‚àÇq2
+ V (q, t)œà(q, t), where i is a complex number, ¬Øh
is the rationalized Planck constant, œà is the wave function, m is mass, V is the
real potential, q is position, and t is time.
r Stationary states (existence): in the case we have a conservative system, i.e. with
a real potential which is time independent, stationary states will exist.
r Wave packet construction: œà(x, t) =
1
‚àö
2œÄ
 ‚àû
‚àí‚àûA(k) exp(i(kx ‚àíœât))dk, where k
is a wave number, A(k) is the amplitude function, t is time, x is position, and œâ
is the angular frequency.
Some economics/Ô¨Ånance and psychology-based deÔ¨Ånitions
(in alphabetical order)
r Absolute risk aversion (ARA): ARA= ‚àíu‚Ä≤‚Ä≤(W)
u‚Ä≤(W) ; where u‚Ä≤‚Ä≤(W) indicates the
second derivative of the utility function towards wealth (and similarly for the
Ô¨Årst derivative).
r Absolute risk aversion (increasing): if wealth increases ARA increases (often
denoted as IARA).
r Absolute risk aversion (decreasing): if wealth increases ARA decreases (often
denoted as DARA).
r Anscombe‚ÄìAumann expected utility model: a mixture of objective and subjective
probabilities are used in the calculation of expected utility.
r Arbitrage (no-): the absence of making a riskless proÔ¨Åt. Example: if two deposit
accounts, A and B, are equally default free (ceteris paribus), then if the interest
rate on deposit account A is higher than on the deposit account B, an arbitrage
proÔ¨Åt situation occurs; the excess interest rate between accounts A and B reÔ¨Çects
no additional risk.
r Binomial option pricing: a model which aids in setting the non-arbitrage price
of a Ô¨Ånancial option (see ‚ÄúBlack‚ÄìScholes option pricing model‚Äù below).
r Black‚ÄìScholes partial differential equation: ‚àÇF
‚àÇt + rf S ‚àÇF
‚àÇS + 1
2œÉ 2S2 ‚àÇ2F
‚àÇS2 = rf F,
where F is the option contract and ‚àÇF
‚àÇS is the ‚Äúdelta‚Äù of the option, rf is the risk
free rate of interest, œÉ is the volatility of the price of the underlying asset S, t is
time.
r Black‚ÄìScholes option pricing: solutions to the Black‚ÄìScholes partial differential
equation (with the proper end conditions (please see ‚ÄúBlack‚ÄìScholes partial
differential equation‚Äù above)) provide for the pricing equations of the Black‚Äì
Scholes model.
r Black‚ÄìScholes portfolio:  = ‚àíF + ‚àÇF
‚àÇS S, where , F is the option contract
and ‚àÇF
‚àÇS is the ‚Äúdelta‚Äù of the option, S is the price of the underlying asset.
r Brownian motion on the price of an asset: a stochastic differential equation
dS = Œ± (S) dt + Œ≤ (S) dX, where dS denotes the inÔ¨Ånitesimal change in the

Glossary of mathematics, physics, and economics/Ô¨Ånance terms
271
asset price S, Œ± (S) is some drift function of the asset price, dt denotes the
inÔ¨Ånitesimal change in time, Œ≤ (S) is some diffusion function of the asset price,
dX is a Wiener process.
r Call option (plain vanilla): a security that gives its owner the right, but not
the obligation, to purchase a speciÔ¨Åed asset for a speciÔ¨Åed price, known as the
exercise price or the strike price.
r Capital asset pricing model (CAPM): the return of asset i, ri, is written as
ri = rf + Œ≤i(rm ‚àírf ) + œµi, where œµi is the error term, Œ≤i is the CAPM beta (see
below for ‚ÄúCAPM ‚Äì Œ≤i‚Äù), rf is the risk free rate of interest (please see below for
‚Äúrisk free rate of interest‚Äù), rm is the rate of return on the market portfolio (see
below for ‚Äúmarket portfolio‚Äù).
r CAPM ‚Äì Œ≤i: for a security i, Œ≤i, is deÔ¨Åned as Œ≤i = cov(ri,rm)
œÉ 2m
, where ri is the
return of asset i and rm is the return of the market portfolio and cov(ri, rm) is the
covariance of the return of asset i and the return of the market portfolio, m (see
also ‚Äúmarket portfolio‚Äù below).
r EfÔ¨Åciency: efÔ¨Åciency expresses what type of information (for instance public
information) prices reÔ¨Çect.
r Equivalence between preference relation and utility function: there exists an
equivalence between the preference relation of an object x over an object y,
denoted as x ‚âªy, if and only if there exists a utility function u(.), which maps a
set of objects into R, such that u(x) > u(y).
r Ellsberg paradox: this paradox indicates that the ‚Äúsure-thing principle,‚Äù a key
assumption of the Savage model can be refuted on experimental grounds.
r Incompatible observables (economics/Ô¨Ånance interpretation): non-simultaneous
observables. As an example, one observable variable is ‚Äúprice‚Äù and the ‚Äútime
change of price‚Äù would be the other observable variable. Both variables cannot
be simultaneously observed.
r Information price trajectory: a Newton‚ÄìBohm path (see above ‚ÄúNewton‚ÄìBohm
equation‚Äù) of non-observed prices which affect non-observed risk neutral prob-
abilities (see below ‚ÄúRisk neutral probabilities‚Äù) in the non-arbitrage theorem.
r Information (quantum-like representation): in the quantum-like representation
of information, the brain operates with density operators which represent not
only concrete mental images (coming from the classical regime of mental pro-
cessing), but also abstract concepts (of different levels of abstraction which do
not correspond to classically produced images).
r Kinetic energy in economics: 1
2
n
j=1 mjv2
j, where mj is the number of shares
of stock j and vj(t) = Àôqj(t) = lim
t‚Üí0
qj(t+
t)‚àíqj(t)

t
, where t is time and qj is
the price of asset j.
r Market capitalization: Tj(t) = mjqj(t): market capitalization of trader j at time
t, where mj is the number of stock of asset j, and qj is the price of asset j.

272
Glossary of mathematics, physics, and economics/Ô¨Ånance terms
r Market portfolio: a theoretical portfolio used in the capital asset pricing model.
A close proxy of such portfolio can be an index portfolio like the Dow Jones 30
portfolio.
r Martingale of a stock price: the conditional expectation of a stock price, ST
at time T > t, given the information at time t : It, is E[ST |It] = St (note: the
mathematical deÔ¨Ånition is more involved than this heuristic deÔ¨Ånition).
r Phase space of prices: a product space Q √ó V ; where V ‚â°Rn and ‚àí‚Üí
v =
(v1, v2, . . . , vn) ‚ààV, vj(t) = Àôqj(t) = lim
t‚Üí0
qj(t+
t)‚àíqj(t)

t
; t is time and ‚àí‚Üí
q =
(q1, q2, . . . , qn) ‚ààQ, where qj is the price of the share of the jth corporation.
r Potential energy in economics: describes the interactions between traders as well
as interactions from other factors such as macro-economic factors.
r Pricing rule: ‚àí‚àÇQ
‚àÇq , where Q is the quantum potential (adopted for a Ô¨Ånancial
environment) and q is price.
r Psychological time scale (T -scale): the T -scale is called the mental time scale or
psychological time scale. The T -scale is the scale of creation of mental images
by the brain.
r Put option (plain vanilla): a security that gives its owner the right, but not the
obligation, to sell a speciÔ¨Åed asset for a speciÔ¨Åed price, known as the exercise
price or the strike price.
r Qualia: in prequantum classical statistical Ô¨Åeld theory, each concrete mental
image is associated with a random signal. Its mental features, ‚Äú qualia,‚Äù are given
by functionals of this signal. In the simplest case, these are quadratic forms of
the signal.
r Quantum-like wave function (economics/Ô¨Ånance interpretation): as an input in
the Radon‚ÄìNikodym derivative (see Chapter 13).
r Quantum-like wave function (economics/Ô¨Ånance interpretation): as an analogue
of the put and call functions (see Chapter 13).
r Quantum-like pilot wave function (economics/Ô¨Ånance interpretation): pilot
waves as carriers of erroneous information (see Chapter 13).
r Quantum-like pilot wave function (economics/Ô¨Ånance interpretation): pilot wave
in a drift-dependent option (see Chapter 13).
r Risk averting: u(E(W)) > E(u(W)), i.e. if the utility of expected wealth is larger
than the expectation of the utility of wealth, then the individual is risk averse.
r Risk averting (degree of): if agent 1 is more risk averse than agent 2, then agent‚Äôs
1 utility function is ‚Äúmore concave‚Äù than agent‚Äôs 2 utility function; we get for
agent‚Äôs 1 utility function that u(w) = h(v(w)) where h(.) is an increasing/strictly
concave function.
r Risk free rate of interest: the rate of interest on an asset which carries no risk at
all. Example: a deposit account upon which no default can occur should carry a
risk free rate of return.

Glossary of mathematics, physics, and economics/Ô¨Ånance terms
273
r Risk loving: u(E(W)) < E(u(W)), i.e. if the utility of expected wealth is smaller
than the expectation of the utility of wealth, then the individual is risk loving.
r Risk neutral probability: a probability measure which allows a risky asset to be
discounted at the risk free rate of interest.
r Savage expected utility model: subjective probabilities are used in the calculation
of expected utility.
r Short selling: a broker sells shares at a price, p, on behalf of an investor. The
broker borrows the shares from another investor. Assuming the price of the asset
drops, the investor will buy the shares at the price p1 < p and will make a per
share proÔ¨Åt (before transaction costs) of p ‚àíp1.
r von Neumann‚ÄìMorgenstern expected utility model: objective probabilities are
used in the calculation of expected utility.

Index
absolute continuity, 215‚Äì217
Absolute risk aversion, 119
Absolute risk aversion (CARA, DARA, IARA), 118
Accardi, 63, 64, 74, 145, 164, 192, 234
active information, 180, 198‚Äì199
Adenier, 18
Aerts, 62, 92‚Äì93
Allais (paradox), 37, 115, 132
ambiguity, 218‚Äì220
amplitude, 5, 32‚Äì35, 85, 91, 96, 144, 164, 180‚Äì181,
182, 191, 221, 237
Anscombe‚ÄìAumann, 37, 115
arbitrage, 47, 78, 173‚Äì175, 186‚Äì187, 193‚Äì196, 200,
200‚Äì203, 206, 209‚Äì210, 225
Arrow‚ÄìPratt, 117
Asano, 64
Aumann, 37
axioms (economics), 113, 116,121
Baaquie, 59‚Äì64, 78, 113, 192, 199, 205, 227‚Äì228,
233‚Äì234
Bacciagaluppi, 222
Bachelier, 37
background Ô¨Åeld, 34, 237‚Äì241
backward Kolmogorov equation, 40‚Äì49, 212‚Äì214
Baez, 234
Ballentine, 25, 107
Baschnagel, 220‚Äì221
basis, 19, 220‚Äì221, 71, 85‚Äì88, 157, 164‚Äì167
Bayes‚Äô Formula, 122, 128
Bayesian approach, 124‚Äì125
behavioural economics, xiv, xviii, 115, 164
Bell (inequality), 35‚Äì36, 58, 239, 243
Bender, 212‚Äì213
Berry, 98
Beta of a security, 176
binding problem, 238‚Äì239
binomial option pricing, 44‚Äì45, 208‚Äì209
Bj¬®ork, 209
Black‚ÄìScholes Hamiltonian, 192, 195, 197‚Äì198, 210
Black‚ÄìScholes partial differential equation, 40, 46, 78
Black‚ÄìScholes portfolio, 43‚Äì46, 186‚Äì187, 223
Blackwell, 215‚Äì220
Bohm, 58, 102‚Äì105, 106‚Äì108, 180, 184, 186,
212‚Äì214, 218, 222
Bohm‚ÄìVigier model, 186
Bohmian mechanics, 8, 12, 23, 25, 34, 55, 63, 92, 99,
102‚Äì108, 184, 187, 199, 200, 203, 222, 225
Bohmian momentum, 102
Bohner, 229‚Äì230
Bohr, xiv, 15‚Äì36, 93, 127, 206, 240
Bohr‚Äôs quantization condition, 15, 16
Boolean algebra, 90, 126‚Äì133
Bordley, 64
Born, xiv, 57, 85‚Äì89, 144, 164, 169, 192
Boson Ô¨Åeld, 61
Bouchaud, 48, 226
Boukas, 63, 234
Bowman, 63, 74, 76, 95
Boyle, 55
bra, 74, 75‚Äì76
brakets, 74, 75
Brandenburger, 63, 64
Broekaert, 63, 64
Brownian motion, 28‚Äì35, 37, 41, 46, 81‚Äì82, 220,
223‚Äì224, 230
Brownian motion (discrete version), 47, 81
Brze¬¥zniak, 79, 230
Bub, 58
Busemeyer, 64, 132, 133, 136, 139
call, 43‚Äì46, 51‚Äì52, 115, 117, 192‚Äì198, 199, 206, 211,
226, 227, 233
Camerer, 115
canonical commutation relations, 20‚Äì24
Capital Asset Pricing Model (CAPM), 176
Cauchy problem, 5‚Äì13, 30‚Äì35, 257
Cauchy convergence, 73
causal deterministic viewpoint, 5
Cheung, 228‚Äì233
Choustova, 42, 63, 103, 152, 179, 184, 203
classical averages, 242
274

Index
275
classical limit, 98‚Äì100, 197‚Äì198
classical statistical mechanics (CSM), 11‚Äì15, 39, 181,
242
cognitive function, 179‚Äì181
communication, 217
complementarity, xiv‚Äìxviii, 90, 127, 151, 152
completeness, 24‚Äì27, 35, 73, 240‚Äì242
completeness (preferences), 115
complex amplitudes, 32, 132, 145
complex conjugate, 76, 91
complex Hilbert space, 20‚Äì21, 72, 130‚Äì131, 145, 164,
259
concave utility function, 117‚Äì119
conÔ¨Åguration space, xiv, 28‚Äì30, 42
conjugate symmetry, 72, 75
consciousness, xviii, 54‚Äì63, 259
constructive interference, 96
constructive wave function approach, 144, 237
continuity equation, 100, 105, 198
Conte, 64
context, 23, 93, 114, 125, 126‚Äì134, 140‚Äì144, 146, 169
context (in prisoner‚Äôs dilemma), 135‚Äì138
contextual probability, 140‚Äì144, 146
convex utility function, 114, 169, 117
Copenhagen interpretation, 26, 240
Copenhaganists, 25
correlations, 31, 34, 35, 165, 237, 238, 239, 241, 242,
244, 253, 258, 259
correspondence principle, 17, 98‚Äì100
Cox, 44
crisis (Ô¨Ånancial), 128, 173, 178, 263
Croson, 132, 135, 138, 143
Danilov, 64
Danthine, 45, 115‚Äì116
de Barros, 27
Debreu, 37
de Broglie, 17, 18, 34, 36, 58, 59, 96, 107, 108, 180
decision maker, 45, 64, 114, 120, 133, 178
degenerate spectrum, 85, 86
de Gosson, 100
Delbaen, 179
demand function, 113
de Martini, 18
density matrix, 61, 89, 162, 165, 169
destructive interference, 96, 180
Deutsch, 63
dilemma game, 156
Dirac‚Äìvon Neumann, 145, 155, 164, 169
Dirac symbolism, 75
disjunction effect, 132, 134, 139, 141‚Äì144
Donaldson, 45, 115‚Äì116
double slit experiment, 90‚Äì91, 207
double stochastic matrix, 137, 141
Dow Jones, 176
drift, 41, 48, 82, 199, 221, 223, 227, 230
dual space, 75, 201‚Äì203
Dubins, 215‚Äì220
DufÔ¨Åe, 82
Durt, 62
dynamic of prices, 42
econophysics, 38‚Äì39, 54‚Äì55, 177
efÔ¨Åciency, 173‚Äì179
Ehrenfest (theorem), 99, 102, 197‚Äì198
eigenfunctions, 97
eigenvalues, 19, 77, 85, 97, 164
Einstein, 6, 15, 29, 87, 107, 238, 240, 242‚Äì243, 259
Eisert, 64, 238
electromagnetic Ô¨Åelds (brain), 64, 238, 239, 257
electromagnetic waves, 238, 239
Ellsberg paradox, 38, 64, 115, 120‚Äì122, 132‚Äì140
Embrechts, 179
ensemble, 9‚Äì10, 15, 25‚Äì26, 58, 102, 107, 108, 128,
129, 146, 242, 244, 250, 252‚Äì259
entangled classical waves, 241
entangled states, 103
entanglement, 34, 35, 238, 239, 241, 246, 259
entropy, 56, 182
Environmental Invariants Hypothesis, 61
ergodicity, 250‚Äì251, 253
Etheridge, 82, 175
event, 12, 58, 79, 90, 121, 122, 124‚Äì135, 217
expected utility theorem, 37‚Äì38, 45, 64, 114, 115,
117, 118‚Äì120, 132‚Äì133, 177, 263
factorizable (density), 30‚Äì34
Fama, 174
Fedotov, 187
feedback loops, 181‚Äì182
Fermi, 77
Fermion Ô¨Åeld, 61
Feynman, 92, 207, 227
Ô¨Åeld functionals, 246
Fishburn, 121
Fokker‚ÄìPlanck equation, 29, 39, 40‚Äì41, 53, 221
formalism approach, 60
forward interest rates, 227
Fourier integral, 96, 206
Fourier transform, 96, 248
free will, 12, 61, 204
Freud, 12
Fuchs, 56
Fuchsian interpretation, 56
fundamental traders, 204, 216
Gabaix, 38
Gamma, 234
Gaussian form, 29
Gaussian random Ô¨Åelds, 242, 244
Gaussian wave packet, 59, 97
generalized eigenvectors, 87
Georgescu‚ÄìRoegen, 38
Goldstein, 56‚Äì58, 102
Gorini‚ÄìKossakowski‚ÄìSudarshan‚ÄìLindblad equation,
257, 259

276
Index
graininess function, 229
Gustafson, xiv, xv
Ha, 73
Haken, 73, 77, 182‚Äì183
Hameroff, 27, 54, 130, 237
Hamiltonian, 7, 8, 9, 10, 13, 15, 19, 21, 22, 26, 28, 32,
42, 58, 59, 63, 74, 77, 78, 88, 94, 95, 100, 210, 255,
258
Hamiltonian (mental), 255
Hamiltonian function, 7, 8, 22, 42
Hamilton‚ÄìJacobi equation, 60, 62, 102, 105
Hamiltonian operator, 95, 97, 99, 192, 193, 194‚Äì198
Harrison, 82
Haug, 208, 208
Haven, 53, 63, 139, 203
Hawaii vacation experiment, 141
Heath‚ÄìJarrow‚ÄìMorton (HJM) theory, 227
hedging error, 234
Heisenberg, xiii, 18, 19‚Äì32, 93, 97
Heisenberg (equation), 256
Heisenberg uncertainty, 25, 74, 64, 93, 95, 97, 108,
228, 234
Hermitian matrix, 19, 20, 21, 22, 85, 86
Hermitian operators, 21, 74, 76, 77‚Äì78, 84, 94, 164,
210
Hermiticity, 74, 76, 77‚Äì78, 97, 192‚Äì197, 206, 210
hidden variables, 26, 57, 58, 63, 107, 108, 209,
210
Hiley, 100, 102, 103, 106‚Äì108, 180, 184, 186, 218,
222
Hilger, 229‚Äì230
Holland, 97, 98, 99, 100, 103, 106, 107, 108, 197
Hubbard, 71, 79
Hudson, 63
Hull, 41, 44, 46, 47
hyperbolic numbers, 131, 132
Ilinski, 187
incompatible observables, 205, 206
incomplete, 27, 28, 107, 240
information (ambiguity), 218‚Äì220
information (asymmetric), 215, 217
information (degree of erroneous), 180, 199, 223
information (multi-sourced), 218, 219, 220
information (pools of), 106, 218
information (wave of), 184, 200, 215, 217‚Äì220
information gain, 182, 183
information leakage, 174, 179
information manipulation, 174, 179
information prices, 203
information price trajectory, 203
information risk, 180, 223, 224, 225
interference (hyperbolic), 130, 131, 143, 145
interference (trigonometric), 130, 131, 142, 143‚Äì145
interference term, 92, 129‚Äì132, 144
internal mental representation, 169
invisible hand, 177, 178
Ishio, 222, 223
ItÀÜo‚Äôs Lemma, 46, 82, 230‚Äì235
Jammer, 57‚Äì58, 107, 209, 210
Jauch, 58
Jensen inequality, 46, 47, 119
joint density, 124
Jung, 60
Kac, 228‚Äì233
Kadane, 64
Kant, 6
Kennard, 25
ket, 74, 75‚Äì76
Khrennikov, 41‚Äì42, 55, 56, 59, 63, 64, 84, 90, 127,
130, 132‚Äì152, 179, 184‚Äì185, 192‚Äì193, 203‚Äì206,
208, 210, 260
kinetic energy, 7, 13, 40, 41‚Äì42, 195‚Äì196
Kochen, 35, 58
Kolmogorov axiomatics, 79, 122
Kolmogorov probability model, 125
Kreps, 82, 113, 115, 120
Kreyszig, 80, 96
Krugman, 178
Lagrangian multiplier, 113‚Äì114
Lambert‚ÄìMogilianski, 64
La Mura, 64
Laplace, 5‚Äì6, 30
law of total probability, 122, 135, 144, 152, 155, 237,
239
Leggett, 17
Li, 52, 53, 192, 211‚Äì213
LIBOR, 191, 227
lifting, 145, 155, 160, 162‚Äì169
limit in the mean square sense, 46, 81
linear space, 71, 72
Liouville, 10, 26, 28, 29, 59
lognormal, 41
lotteries, 116
Luenberger, 176
Lux, 38
Ma, 55, 174, 179
Mach, 23
Machina, 115
Mackenzie, 200
Mackey, 100
macroscopic, 17, 18, 28, 54, 55, 58, 98, 99, 102, 108,
179, 199, 210, 234, 235
manipulative function, 179, 180
Mantegna, 38
Marchesi, 38
Margenau, 25, 107
marginal distribution, 215
marginal rate of substitution, 114
market capitalization, 42
Markov chain model, 145

Index
277
Martin, 61‚Äì62, 204
martingale, 49‚Äì51, 78, 192, 193‚Äì198, 206
mean backward derivative, 221
mean forward derivative, 220
mental contextual model, 138
mental qubit, 138
mental state, 129, 146, 156‚Äì161, 246, 255, 257
mental wave function, 144, 155
Messiah, 72, 73, 74, 76, 98, 99
metaphor, 60
Millo, 200
Mixed states, 87, 95
moment generating function, 49
momentum, 7, 9, 13, 16, 19, 20, 42, 59, 61, 62, 73,
105, 121, 132, 180, 203, 205, 206, 234, 248
Monte Carlo simulation, 55
Morgenstern, 37, 115, 132, 133
Morrison, 74, 75, 91, 93, 94, 95, 96, 97, 98, 99, 194,
195, 196, 197
m.s. continuity, 81
m.s. derivative, 81
Nakata, 215, 217, 218
Neftci, 49, 175, 202
negative probability, 207, 208
Nelson, 27, 60, 220, 221, 222
neuroeconomics, 115
Newton‚ÄìBohm equation, 105, 187, 203
Newton‚ÄìBohm paths, 188, 189
Newtonian mechanics, 99
no-go theorems, 35‚Äì36, 58, 243
noise traders, 204, 216
non-arbitrage theorem, 78, 82, 175, 199, 200
non-classical decision making, 125
non-commutative phase space, 20
non-commutativity, 235
non-local(ity), 30, 33, 34, 106, 107, 108
normal density, 50, 51, 52, 81
normalized interference term, 130
no-trade theorem, 175
Nozick, 177
objective probability, 121, 133
√òksendal, 49, 82, 230, 231
operator (backward jump), 229
operator (bounded), 74, 260
operator (covariance), 241, 242, 244, 248, 249, 250,
251, 252, 253, 254, 255, 256, 257, 258, 260, 261
operator (creation), 62
operator (density), 88, 95, 241, 242, 244, 248, 249,
252, 255, 256, 257, 258, 259, 260
operator (forward jump), 229
operator (idempotent), 78
operator (identity), 74, 76, 78, 99
operator (integral), 260
operator (projection), 74, 75, 78, 88
operator (self-adjoint), 100, 137, 155, 244, 245, 249,
250, 255, 256, 259
operator (trace), 89, 242, 260
operator (unitary), 74, 76, 163, 257
option, 37, 40, 43, 44‚Äì53, 63, 186, 192‚Äì200, 211, 212,
213, 214, 216, 222‚Äì235, 263
ordinary differential equation, 4, 7, 79
Ornstein‚ÄìUhlenbeck process, 187
Orszag, 212‚Äì213
Otto, 187
p-adic numbers, 64, 208
Panayides, 187
Parseval inequality, 137
Parthasarathy, 63
partial differential equation, 29, 39, 40, 46, 48, 52, 79,
80, 187, 203, 233, 263
path integration, 63, 227
path simulation, 189
Paul, 19, 220‚Äì221
Pauli, xiv, xvii, xviii, 60
Penrose, 27, 54, 60, 130, 237, 245
phase space, 7‚Äì32, 42, 57
physical quantum brain, 131, 237
pilot wave, 34, 63, 107, 184, 199
Piron, 58
Planck, 14‚Äì20, 54, 55, 60, 152, 180, 212, 216, 218,
221, 234, 245
Plotnitsky, 24
Podolsky, 238
Poisson brackets, 19, 20
portfolio (riskless), 43‚Äì47, 44, 173, 45, 176, 186, 209,
224, 226, 233
position, 4‚Äì13, 19, 20‚Äì32, 48, 62, 73, 80, 84, 91, 94,
95, 96, 97, 98‚Äì100, 102, 126, 180, 186, 197, 200,
206, 215, 216, 218, 227, 232, 234, 248
posterior density, 124
posterior probability, 123
postulates, 58, 77, 85, 87, 93, 94, 207
potential, 4‚Äì18, 22, 32, 39, 40, 41‚Äì42, 52, 53, 95, 97,
103, 105‚Äì107, 184‚Äì203, 211‚Äì212
Potters, 48, 226
prediction state, 157‚Äì160
predictive probability, 215
preference relation, 113, 115, 116
premium, 43, 44, 193‚Äì203
prequantum (classical statistical Ô¨Åeld theory
(PCSFT)), 34, 193, 238
prequantum models, 23, 35
prequantum state space, 243
prequantum wave model, 243
price, 37, 41‚Äì53, 82, 114, 117, 173, 174‚Äì234
pricing rule, 184, 185, 190
prior probability, 123, 125, 136
prisoner‚Äôs dilemma, 135
private information, 174, 175
probabilistic phase, 130, 142
probability amplitude, 32‚Äì35, 85, 91, 92, 95, 98, 107,
131, 144
probability conservation, 193

278
Index
probability density function, 9‚Äì10, 40‚Äì41, 79, 91, 213,
216, 217, 221
probability interference, 55, 64, 91, 145, 146, 179, 263
probability space, 79, 93, 122, 125, 128, 133, 215
probability waves, 243
psychology, xvii, xviii, 12, 22, 24, 39, 55, 60, 61, 63,
113, 127‚Äì147, 155‚Äì164, 237, 263‚Äì264
pure state, 72, 84‚Äì95, 162, 169, 260
put, 43‚Äì46, 192‚Äì198, 199, 206, 233
Pylkk¬®anen, 184
q-differential, 228
quale, 248, 259
qualia (classical), 250, 256, 259
qualia (conjugate), 248
qualia (global), 247
qualia (incompatible), 249
qualia (quantum), 249, 259
qualia (QL), 250, 256
qualia (spatial distribution), 247
qualia (total compatibility), 247
quantum averages, 242, 245
quantum (q-)calculus, 228
quantum channel, 160
quantum correlation, 35, 238
quantum game theory, 63, 64
quantum information theory, 27, 72, 75, 145, 155,
162, 164, 238, 257, 259
quantum like (QL), xiv, xviii, 23, 27, 28, 36, 39, 84,
93, 132, 146, 163, 173, 180, 206, 207, 237, 248
quantum Markov chain, 163, 164
quantum Markov model, 164, 169, 170
quantum observable, 19, 20, 22, 85, 86‚Äì89, 131, 137,
244, 245
quantum probability, 56, 164
quantum randomness, 242
quantum social science, 38, 39, 54, 55‚Äì63
quantum state, 74, 87, 95, 217
quantum waves, 59, 107
qubit, 64
Rabin paradox, 64
Radon‚ÄìNikodym derivative, 199, 216, 217, 218, 219,
220
Radon‚ÄìNikodym theorem, 216
Rapoport, 132
rational, 115, 133, 135, 143, 156, 175, 177, 178
reÔ¨Çexivity, 173, 179, 180, 181, 182, 198, 199, 206
R¬¥enyi (quantity of information), 217, 219, 220
representative agent, 190, 216, 217, 218
Riemann‚Äôs integral, 14
Riemann‚ÄìSilberstein representation, 13, 246
risk (attitude towards), 45
risk free rate, 44‚Äì53, 175, 176, 186, 193‚Äì223
risk neutral probability measure, 193, 194
Roehner, 38
Rosen, 238
Ross, 79
Samuelson, 37, 46, 117, 177
Savage, 37, 38, 115, 120, 120, 133, 135, 143
Savage sure-thing principle, 38, 115, 120, 121,
132‚Äì140, 263
Scheinkman, 175
Schmeidler, 121, 125
Schoemaker, 120
Sch¬®al, 48, 226
Schweizer, 48, 226
Segal, 63, 120, 121, 122, 234
selection context, 128, 226, 129
self-consciousness, 62
self organizing system, 183
ShaÔ¨År, 132, 163, 167
Shepard, 61
Shevchenko, 124, 125
short selling, 205
Shubik, 64
Smoluchowski, 28, 29, 30, 31, 33, 107
Sornette, 48, 226
Soros, 173, 179, 180, 181, 182, 198, 199, 206
spatial localization, 192, 193, 194‚Äì196
Specker, 35, 58
square-integrable, 13, 20, 21, 22, 59, 72, 73
Stanley, 38
state functions, 94, 95, 194, 195
stationary independent increments, 81
St. Petersburg paradox, 117
subjective probability, 56, 115, 121, 129, 133
Suppes, 27, 208
superposed state, 92
symbolism, 18, 23
Tan, 226
tensor product, 243, 259
time (psychological), 62, 251
time scale, 42, 229, 237, 238, 243, 245
time scale (mental), 251, 252, 259
time scale (premental), 251
Tirole, 174, 175, 178
transition expectation, 162, 163, 164
transition probabilities (matrix of), 136,138, 141, 164,
166
transitivity, 115, 121
Tversky, 132, 133, 135, 134, 136‚Äì167
Ullmann‚ÄìMargalit, 177
uncertainty creation, 174, 179
unitary transformation, 76
utility function, 45, 113, 114, 115, 116, 117, 118, 190
vacuum Ô¨Åeld, 31, 238, 239, 240, 260
value of an asset, 199
Varadarajan, 90
Varian, 116, 118, 119
Verhulst, 60
Vigier, 186
violation of the law of total probability, 152, 237

Index
279
volatility, 41, 45, 46, 52, 205, 208, 211, 212, 213, 223,
225, 228, 232
Volovich, 59
von Neumann (equation), 255, 257, 259
von Neumann projection postulate, 87, 93
Wang, 64
wave number, 59, 96, 180, 181
wave‚Äìparticle duality, 90, 91, 127
wealth balance, 226
Wentzel‚ÄìKramers‚ÄìBrillouin (WKB), 53, 100, 211,
212, 213, 214
Weyl quantization, 22
Wiener process, 41‚Äì47, 81, 180, 220, 222, 223, 224
Wigner, 207
Wilmott, 41, 48, 223, 224, 225, 233
Wilson expansion, 63, 228
Wolfraim, 60, 61
Xiong, 175
Yanofsky, 63, 64
Zastawniak, 79, 230
Zeilinger, 17, 56
Zhang, 52, 53, 192, 211‚Äì213


