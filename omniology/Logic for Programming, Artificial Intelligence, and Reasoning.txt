Lecture Notes in Artificial Intelligence
3452
Edited by J. G. Carbonell and J. Siekmann
Subseries of Lecture Notes in Computer Science

Franz Baader Andrei Voronkov (Eds.)
LogicforProgramming,
Artiﬁcial Intelligence,
and Reasoning
11th International Conference, LPAR 2004
Montevideo, Uruguay, March 14-18, 2005
Proceedings
1 3

Series Editors
Jaime G. Carbonell, Carnegie Mellon University, Pittsburgh, PA, USA
Jörg Siekmann, University of Saarland, Saarbrücken, Germany
Volume Editors
Franz Baader
TU Dresden
Theoretical Computer Science
01062 Dresden, Germany
E-mail: baader@tcs.inf.tu-dresden.de
Andrei Voronkov
University of Manchester
Department of Computer Science
Oxford Rd, Manchester M13 9PL, UK
E-mail: voronkov@cs.man.ac.uk
Library of Congress Control Number: 2005921519
CR Subject Classiﬁcation (1998): I.2.3, I.2, F.4.1, F.3, D.2.4, D.1.6
ISSN 0302-9743
ISBN 3-540-25236-3 Springer Berlin Heidelberg New York
This work is subject to copyright. All rights are reserved, whether the whole or part of the material is
concerned, speciﬁcally the rights of translation, reprinting, re-use of illustrations, recitation, broadcasting,
reproduction on microﬁlms or in any other way, and storage in data banks. Duplication of this publication
or parts thereof is permitted only under the provisions of the German Copyright Law of September 9, 1965,
in its current version, and permission for use must always be obtained from Springer. Violations are liable
to prosecution under the German Copyright Law.
Springer is a part of Springer Science+Business Media
springeronline.com
© Springer-Verlag Berlin Heidelberg 2005
Printed in Germany
Typesetting: Camera-ready by author, data conversion by Markus Richter, Heidelberg
Printed on acid-free paper
SPIN: 11403487
06/3142
5 4 3 2 1 0

Preface
This volume contains the papers presented at the 11th International Conference
on Logic for Programming, Artiﬁcial Intelligence, and Reasoning (LPAR), held
from March 14 to 18, 2005, in Montevideo, Uruguay, together with the 5th In-
ternational Workshop on the Implementation of Logics (organized by Stephan
Schulz and Boris Konev) and the Workshop on Analytic Proof Systems (orga-
nized by Matthias Baaz).
The call for papers attracted 77 paper submissions, each of which was re-
viewed by at least three expert reviewers. The ﬁnal decisions on the papers were
taken during an electronic Program Committee meeting held on the Internet.
The Internet-based submission, reviewing, and discussion software EasyChair,
provided by the second PC co-chair, supported each stage of the reviewing pro-
cess. But the most important work was, of course, done by the 34 PC members
and their external reviewers, who provided high-quality reviews. After intense
discussions to resolve conﬂicts among the reviewers, the Program Committee
decided to accept 33 papers.
The conference program also included 4 invited talks, by J¨urgen Giesl, Alex-
ander Leitsch, Helmut Seidl, and Igor Walukiewicz, which are documented by
short or extended abstracts in these proceedings. In addition, Mart´ın Abadi
held a tutorial on Reasoning About Security Protocols, and Ian Horrocks on
Description Logic Reasoning.
Apart from the authors, invited speakers, tutorialists, Program Committee
members, and external reviewers, we would like to thank the other people and
organizations that made this LPAR a success: the Local Arrangements Chair,
Alberto Pardo, and all the other people involved in the local organization; the
Chair for Automata Theory at TU Dresden, the Kurt G¨odel Society, and the
European Union (in the Information Society Technologies programme of the
European Commission, Future and Emerging Technologies under the IST-2001-
33123 CoLogNET project), which provided partial funding for our invited speak-
ers; and the Centro Latinoamericano de Estudios en Informatica (CLEI), which
provided scholarships for several Latin American participants of the conference.
January 2005
Franz Baader
Andrei Voronkov

Conference Organization
Program Chairs
Franz Baader (Technische Universit¨at Dresden, Germany)
Andrei Voronkov (University of Manchester, UK)
Program Committee
Matthias Baaz (Technische Universit¨at Wien)
David Basin (ETH Zurich)
Philippe Besnard (CNRS, Toulouse)
Thomas Eiter (Technische Universit¨at Wien)
Javier Esparza (Universit¨at Stuttgart)
Marcelo Finger (Universidade de Sao Paulo )
Rajeev Gore (Australian National University)
Georg Gottlob (Technische Universit¨at Wien)
Erich Gr¨adel (RWTH Aachen)
Martin Grohe (Humboldt Universit¨at Berlin)
Miki Hermann (Ecole Polytechnique)
Deepak Kapur (University of New Mexico)
H´el`ene Kirchner (LORIA)
Dexter Kozen (Cornell University)
Orna Kupferman (Hebrew University)
Dietrich Kuske (Technische Universit¨at Dresden)
Maurizio Lenzerini (Universit`a di Roma)
Leonid Libkin (University of Toronto)
Christopher Lynch (Clarkson University)
Dale Miller (INRIA)
Ilkka Niemel¨a (Helsinki University of Technology)
Tobias Nipkow (Technische Universit¨at M¨unchen)
Luke Ong (Oxford University)
Alberto Pardo (Universidad de la Republica, Montevideo)
David Pym (University of Bath)
Wolfgang Reif (Universit¨at Augsburg)
Ulrike Sattler (Technische Universit¨at Dresden)
Wolfgang Thomas (RWTH Aachen)
Cesare Tinelli (University of Iowa)
Ralf Treinen (ENS Cachan)
Toby Walsh (University College Cork)
Frank Wolter (University of Liverpool)

Organization
VII
Local Organization
Alberto Pardo (Universidad de la Republica, Montevideo)
External Reviewers
Marcelo Arenas
Simon Baeumler
Steﬀen van Bakel
Philippe Balbiani
Michael Balser
Pablo Barcelo
Clark Barrett
Peter Baumgartner
Stefan Berghofer
Dietmar Berwanger
Gustavo Betarte
Ana Bove
Sabine Broda
Kai Bruennler
Marco Cadoli
Amine Chaieb
Agata Ciabattoni
Veronique Cortier
Jeremy Dawson
St´ephanie Delaune
Francesco M. Donini
Francesco Donini
Gilles Dowek
Roy Dyckhoﬀ
Marcelo Falappa
Maribel Fernandez
Michael Fink
Jean Goubault-Larrecq
Holger Grandy
Tim Griﬃn
Dominik Haneberg
Keijo Heljanko
Duncan Hull
Ullrich Hustadt
Steﬀen H¨olldobler
Giovambattista Ianni
Tomi Janhunen
Lukasz Kaiser
Tom Kelsey
Felix Klaedtke
Boris Konev
Oliver Kutz
Gerhard Lakemeyer
Thomas Linke
Markus Lohrey
Dominique Longin
Carlos Luna
Carsten Lutz
Michael Maher
Marc Meister
Stephan Merz
George Metcalfe
Thomas Meyer
Aart Middeldorp
Cesar Munoz
Ralf M¨oller
Linh Anh Nguyen
Robert Nieuwenhuis
Hans de Nivelle
Michael Norrish
Emilia Oikarinen
Albert Oliveras
Frank Ortmeier
Maurice Pagnucco
Nicolas Peltier
Norbert Preining
Silvio Ranise
Horst Reichel
Antoine Reilles
Mark Reynolds
Andrea Schalk
Torsten Schaub
Tobias Scheﬀer
Roman Schindlauer
Manfred Schmidt-Schauss
Jonathan Schmitt
Philippe Schnoebelen
Nicole Schweikardt
Paula Severi
Luis Sierra

VIII
Organization
Gregor Snelting
Viorica Sofronie-Stokkermans
Kurt Stenzel
Georg Struth
Tommi Syrj¨anen
Alwen Tiu
Hans Tompits
Laurent Vigneron
Mateu Villaret
Pascal Weil
Martin Wildmoser
Burkhart Wolﬀ
Stefan Woltran
Hantao Zhang
Conferences Preceding LPAR-11
RCLP 1990, Irkutsk, Soviet Union
RCLP 1991, Leningrad, Soviet Union, aboard the ship “Michail Lomonosov”
LPAR 1992, St. Petersburg, Russia, aboard the ship “Michail Lomonosov”
LPAR 1993, St. Petersburg, Russia
LPAR 1994, Kiev, Ukraine, aboard the ship “Marshal Koshevoi”
LPAR 1999, Tbilisi, Republic of Georgia
LPAR 2000, R´eunion Island, France
LPAR 2001, Havana, Cuba
LPAR 2002, Tbilisi, Republic of Georgia
LPAR 2003, Almaty, Kazakhstan

Table of Contents
CERES in Many-Valued Logics
Matthias Baaz and Alexander Leitsch . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
A Decomposition Rule for Decision Procedures by Resolution-Based
Calculi
Ullrich Hustadt, Boris Motik, and Ulrike Sattler
. . . . . . . . . . . . . . . . . .
21
Abstract DPLL and Abstract DPLL Modulo Theories
Robert Nieuwenhuis, Albert Oliveras, and Cesare Tinelli
. . . . . . . . . . .
36
Combining Lists with Non-stably Inﬁnite Theories
Pascal Fontaine, Silvio Ranise, and Calogero G. Zarba . . . . . . . . . . . . .
51
Abstract Model Generation for Preprocessing Clause Sets
Miyuki Koshimura, Mayumi Umeda, and Ryuzo Hasegawa . . . . . . . . . .
67
Flat and One-Variable Clauses: Complexity of Verifying
Cryptographic Protocols with Single Blind Copying
Helmut Seidl and Kumar Neeraj Verma . . . . . . . . . . . . . . . . . . . . . . . . . .
79
Applications of General Exact Satisﬁability in Propositional Logic
Modelling
Vilhelm Dahll¨of . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
95
BCiC: A System for Code Authenticationand Veriﬁcation
Nathan Whitehead and Mart´ın Abadi
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
110
Ordered Resolution with Selection for H(@)
Carlos Areces and Daniel Gor´ın . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
125
On a Semantic Subsumption Test
Jerzy Marcinkowski, Jan Otop, and Grzegorz Stelmaszek
. . . . . . . . . . .
142
Suitable Graphs for Answer Set Programming
Thomas Linke and Vladimir Sarsakov
. . . . . . . . . . . . . . . . . . . . . . . . . . .
154
Weighted Answer Sets and Applications in Intelligence Analysis
Davy Van Nieuwenborgh, Stijn Heymans, and Dirk Vermeir
. . . . . . . .
169
How to Fix It: Using Fixpoints in Diﬀerent Contexts
Igor Walukiewicz . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
184
Reasoning About Systems with Transition Fairness
Benjamin Aminof, Thomas Ball, and Orna Kupferman
. . . . . . . . . . . .
194

X
Table of Contents
Entanglement – A Measure for the Complexity of Directed Graphs
with Applications to Logic and Games
Dietmar Berwanger and Erich Gr¨adel
. . . . . . . . . . . . . . . . . . . . . . . . . . .
209
How the Location of ∗Inﬂuences Complexity in Kleene Algebra
with Tests
Chris Hardin
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
224
The Equational Theory of ⟨N, 0, 1, +, ×, ↑⟩Is Decidable, but Not
Finitely Axiomatisable
Roberto Di Cosmo and Thomas Dufour
. . . . . . . . . . . . . . . . . . . . . . . . . .
240
A Trichotomy in the Complexity of Propositional Circumscription
Gustav Nordh . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
257
Exploiting Fixable, Removable, and Implied Values in Constraint
Satisfaction Problems
Lucas Bordeaux, Marco Cadoli, and Toni Mancini . . . . . . . . . . . . . . . . .
270
Evaluating QBFs via Symbolic Skolemization
Marco Benedetti
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
285
The Dependency Pair Framework: Combining Techniques for
Automated Termination Proofs
J¨urgen Giesl, Ren´e Thiemann, and Peter Schneider-Kamp
. . . . . . . . .
301
Automated Termination Analysis for Incompletely Deﬁned Programs
Christoph Walther and Stephan Schweitzer
. . . . . . . . . . . . . . . . . . . . . . .
332
Automatic Certiﬁcation of Heap Consumption
Lennart Beringer, Martin Hofmann, Alberto Momigliano, and
Olha Shkaravska
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
347
A Formalization of Oﬀ-Line Guessing for Security Protocol Analysis
Paul Hankes Drielsma, Sebastian M¨odersheim, and Luca Vigan`o . . . .
363
Abstraction-Carrying Code
Elvira Albert, Germ´an Puebla, and Manuel Hermenegildo
. . . . . . . . . .
380
A Veriﬁcation Environment for Sequential Imperative Programs in
Isabelle/HOL
Norbert Schirmer
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
398
Can a Higher-Order and a First-Order Theorem Prover Cooperate?
Christoph Benzm¨uller, Volker Sorge, Mateja Jamnik, and
Manfred Kerber . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
415
A Generic Framework for Interprocedural Analyses of Numerical
Properties
Markus M¨uller-Olm and Helmut Seidl
. . . . . . . . . . . . . . . . . . . . . . . . . . .
432

Table of Contents
XI
Second-Order Matching via Explicit Substitutions
Fl´avio L.C. de Moura, Fairouz Kamareddine, and
Mauricio Ayala-Rinc´on
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
433
Knowledge-Based Synthesis of Distributed Systems Using Event
Structures
Mark Bickford, Robert C. Constable, Joseph Y. Halpern, and
Sabina Petride . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
449
The Inverse Method for the Logic of Bunched Implications
Kevin Donnelly, Tyler Gibson, Neel Krishnaswami, Stephen Magill,
and Sungwoo Park
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
466
Cut-Elimination: Experiments with CERES
Matthias Baaz, Stefan Hetzl, Alexander Leitsch, Clemens Richter,
and Hendrik Spohr
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
481
Uniform Rules and Dialogue Games for Fuzzy Logics
Agata Ciabattoni, Christian G. Ferm¨uller, and George Metcalfe
. . . . .
496
Nonmonotonic Description Logic Programs: Implementation and
Experiments
Thomas Eiter, Giovambattista Ianni, Roman Schindlauer, and
Hans Tompits
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
511
Implementing Eﬃcient Resource Management for Linear Logic
Programming
Pablo L´opez and JeﬀPolakow
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
528
Layered Clausal Resolution in the Multi-modal Logic of Beliefs and
Goals
Jamshid Bagherzadeh and S. Arun-Kumar
. . . . . . . . . . . . . . . . . . . . . . .
544
Author Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
561

CERES in Many-Valued Logics⋆
Matthias Baaz1 and Alexander Leitsch2
1 Institut f¨ur Computermathematik (E-118),
TU-Vienna, Wiedner Hauptstraße 8-10,
1040 Vienna, Austria
baaz@logic.at
2 Institut f¨ur Computersprachen (E-185),
TU-Vienna, Favoritenstraße 9,
1040 Vienna, Austria
leitsch@logic.at
Abstract. CERES is a method for cut-elimination in classical logic
which is based on resolution. In this paper we extend CERES to CERES-
m, a resolution-based method of cut-elimination in Gentzen calculi for
arbitrary ﬁnitely-valued logics. Like in the classical case the core of the
method is the construction of a resolution proof in ﬁnitely-valued log-
ics. Compared to Gentzen-type cut-elimination methods the advantage
of CERES-m is a twofold one: 1. it is easier to deﬁne and 2. it is compu-
tationally superior and thus more appropriate for implementations and
experiments.
1
Introduction
The core of classical cut-elimination methods in the style of Gentzen [8] consists
of the permutation of inferences and of the reduction of cuts to cuts on the
immediate subformulas of the cut formula. If we switch from two- valued to
many-valued logic, the reduction steps become intrinsically tedious and opaque
[3] in contrast to the extension of CERES to the many-valued case, which is
straightforward.
We introduce CERES-m for correct (possible partial) calculi for m-valued
ﬁrst order logics based on m-valued connectives, distributive quantiﬁers [7] and
arbitrary atomic initial sequents closed under substitution. We do not touch
the completeness issue of these calculi, instead we derive clause terms from the
proof representing the formulas which are ancestor formulas of the cut formulas;
the evaluation of these clause terms guarantees the existence of a resolution
refutation as core of a proof with atomic cuts only. This resolution refutation
is extended to a proof of the original end-sequent by adjoining cut-free parts
of the original proof. Therefore, it is suﬃcient to refute the suitably assembled
components of the initial sequents using a m-valued theorem prover [2].
⋆supported by the Austrian Science Fund (FWF) proj. no P16264-N05
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 1–20, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

2
M. Baaz and A. Leitsch
2
Deﬁnitions and Notation
Deﬁnition 1 (language). The alphabet Σ consists of an inﬁnite supply of vari-
ables, of inﬁnite sets of n-ary function symbols and predicate symbols er σ con-
tains a set W of truth symbols denoting the truth values of the logic, a ﬁnite
number of connectives ◦1, . . . , ◦m of arity n1, . . . , nm, and a ﬁnite number of
quantiﬁers Q1, . . . , Qk.
Deﬁnition 2 (formula). An atomic formula is an expression of the form
P(t1, . . . , tn) where P is an n-ary predicate symbol in Σ and t1, . . . , tn are terms
over Σ. Atomic formulas are formulas.
If ◦is an n-ary connective and A1, . . . , An are formulas then ◦(A1, . . . , An)
is a formula.
If Q is quantiﬁer in Σ and x is a variable then (Qx)A is a formula.
Deﬁnition 3 (signed formula). Let w ∈W and A be a formula. Then w: A
is called a signed formula.
Deﬁnition 4 (sequent). A sequent is a ﬁnite sequence of signed formulas. The
number of signed formulas occurring in a sequent S is called the length of S and
is denoted by l(S). ˆS is called the unsigned version of S if every signed formula
w: A in S is replaced by A. The length of unsigned versions is deﬁned in the
same way. A sequent S is called atomic if ˆS is a sequence of atomic formulas.
Remark 1. Note that the classical sequent (∀x)P(x) ⊢Q(a) can be written as
f: (∀x)P(x), t: Q(a).
m-valued sequents are sometimes written as m-sided sequents. We refrain
from this notation, because it denotes a preferred order of truth values, which
even in the two-valued case might induce unjustiﬁed conclusions.
Deﬁnition 5 (axiom set). A set A of atomic sequents is called an axiom set
if A is closed under substitution.
The calculus we are deﬁning below is capable of formalizing any ﬁnitely
valued logic. Concerning the quantiﬁers we assume them to be of distributive
type [7]. Distribution quantiﬁers are functions from the non-empty sets of truth-
values to the set of truth values, where the domain represents the situation in
the structure, i.e. the truth values actually taken.
Deﬁnition 6. Let A(x) be a formula with free variable x. The distribution
Distr(A(x)) of A(x) is the set of all truth values in W to which A(x) evalu-
ates (for arbitrary assignments of domain elements to x).
Deﬁnition 7. Let q be a mapping 2W →W. In interpreting the formula
(Qx)A(x) via q we ﬁrst compute Distr(A(x)) and then q(Distr(A(x))), which is
the truth value of (Qx)A(x) under the interpretation.

CERES in Many-Valued Logics
3
In the calculus deﬁned below the distinction between quantiﬁer introductions
with (strong) and without eigenvariable conditions (weak) are vital.
Deﬁnition 8. A strong quantiﬁer is a triple (V, w, w′) (for V ⊆W) s.t.
(Qx)A(x) evaluates to w if Distr(A(x)) ⊆V and to w′ otherwise. A weak quan-
tiﬁer is a triple (u, w, w′) s.t. (Qx)A(x) evaluates to w if u ∈Distr(A(x)), and
to w′ otherwise.
Remark 2. Strong and weak quantiﬁers are dual w.r.t. to set complementation.
In fact to any strong quantiﬁer there corresponds a weak one and vice versa. Like
in classical logic we may speak about weak and strong occurrences of quantiﬁers
in sequents and formulas.
Note that strong and weak quantiﬁers deﬁne merely a subclass of distribution
quantiﬁers. Nevertheless the following property holds:
Proposition 1. Any distributive quantiﬁer can be expressed by strong and weak
quantiﬁers and many valued associative, commutative and idempotent connec-
tives (which are variants of conjunction and disjunction).
Deﬁnition 9 (LM-type calculi). We deﬁne an LM-type calculus K. The ini-
tial sequents are (arbitrary) atomic sequents of an axiom set A. In the rules of
K we always mark the auxiliary formulas (i.e. the formulas in the premiss(es)
used for the inference) and the principal (i.e. the inferred) formula using dif-
ferent marking symbols. Thus, in our deﬁnition, classical ∧-introduction to the
right takes the form
Γ, t: A+
Γ, t: B+
Γ, t: A ∧B∗
If Π ⊢Γ, ∆is a sequent then Π ⊢Γ, ∆+ indicates that all signed formulas in
∆are auxiliary formulas of the deﬁned inference. Γ ⊢∆, w: A∗indicates that
A: w∗is the principal formula (i.e. the inferred formula) of the inference.
Auxiliary formulas and the principal formula of an inference are always sup-
posed to be rightmost. Therefore we usually avoid markings as the status of the
formulas is clear from the notation.
logical rules:
Let ◦be an n-nary connective.For any w ∈W we have an introduction rule
◦: w of the form
Γ, ∆+
1
...
Γ, ∆+
m
Γ, w: ◦(π( ˆ
∆1, . . . , ˆ
∆m, ˆ
∆))∗◦: w
where l(∆1, . . . , ∆m, ∆) = n (the ∆i are sequences of signed formulas which are
all auxiliary signed formulas of the inference) and π(S) denotes a permutation
of a sequent S.
Note that, for simplicity, we chose the additive version of all logical intro-
duction rules.

4
M. Baaz and A. Leitsch
In the introduction rules for quantiﬁers we distinguish strong and weak intro-
duction rules. Any strong quantiﬁer rule Q: w (for a strong quantiﬁer (V, w, w′))
is of the form
Γ, u1: A(α)+, . . . , um: A(α)+
Γ, w: (Qx)A(x)∗
Q: w
where α is an eigenvariable not occurring in Γ, and V = {u1, . . . , um}.
Any weak quantiﬁer rule (for a weak quantiﬁer (u, w, w′)) is of the form
Γ, u: A(t)+
Γ, w: (Qx)A(x)∗Q: w
where t is a term containing no variables which are bound in A(x). We say that
t is eliminated by Q: w.
We need deﬁne a special n-ary connective for every strong quantiﬁer in order
to carry out skolemization. Indeed if we skip the introduction of a strong quan-
tiﬁer the m (possibly m > 1) auxiliary formulas must be contracted into a single
one after the removal of the strong quantiﬁer (see deﬁnition of skolemization
below). Thus for every rule
Γ, u1: A(α1)+, . . . , um: A(αm)+
Γ, w: (Qx)A(x)∗
Q: w
we deﬁne a propositional rule
Γ, u1: A(t)+, . . . , um: A(t)+
Γ, w: A(t)∗
cQ: w
This new operator cQ can be eliminated by the de-skolemization procedure after-
wards.
structural rules:
The structural rule of weakening is deﬁned like in LK (but we need only one
weakening rule and may add more then one formula).
Γ
Γ, ∆w
for sequents Γ and ∆.
To put the auxiliary formulas on the right positions we need permutation
rules of the form
F1, . . . , Fn
Fπ(1), . . . , Fπ(n)
π
where π is a permutation of {1, . . . , n} and the Fi are signed formulas .

CERES in Many-Valued Logics
5
Instead of the usual contraction rules we deﬁne an n-contraction rule for any
n ≥2 and F1 = . . . = Fn = F:
Γ, F1, . . . , Fn
Γ, F
c : n
In contrast to LK we do not have a single cut rule, but instead rules cutww′
for any w, w′ ∈W with w ̸= w′. Any such rule is of the form
Γ, w: A
Γ ′, w′: A
Γ, Γ ′
cutww′
Deﬁnition 10 (proof). A proof of a sequent S from an axiom set A is a
directed labelled tree. The root is labelled by S, the leaves are labelled by elements
of A. The edges are deﬁned according to the inference rules (in an n-ary rule
the children of a node are labelled by the antecedents, the parent node is labelled
by the consequent). Let N be a node in the proof φ then we write φ.N for the
corresponding subproof ending in N. For the number of nodes in φ we write ∥φ∥.
Deﬁnition 11. Let K be an LM-type calculus. We deﬁne P[K] as the set of all
K-proofs. Pi[K] is the subset of P[K] consisting of all proofs with cut-complexity
≤i (P0[K] is the set of proofs with at most atomic cuts). P∅[K] is the subset of
all cut-free proofs.
Example 1. We deﬁne W = {0, u, 1} and the connectives as in the 3-valued
Kleene logic, but introduce a new quantiﬁer D (“D” for determined) which gives
true iﬀall truth values are in {0, 1}. We only deﬁne the rules for ∨and for D,
as no other operators occur in the proof below.
0: A, 1: A
0: B, 1: B
1: A, 1: B
1: A ∨B
∨: 1
u: A, u: B
u: A ∨B ∨: u
0: A, 0: B
0: A ∨B ∨: 0
0: A(α), 1: A(α)
1: (Dx)A(x)
D: 1
u: A(t)
0: (Dx)A(x) D: 0
where α is an eigenvariable and t is a term containig no variables bound in
A(x). Note that D: 1 is a strong, and D: 0 a weak quantiﬁer introduction. The
formula u: (Dx)A(x) can only be introduced via weakening.
For the notation of proofs we frequently abbreviate sequences of structural rules
bei ∗; thus π∗+ ∨: u means that ∨: u is performed and permutations before
and/or afterwards. This makes the proofs more legible and allows to focus on
the logically relevant inferences. As in the deﬁnition of LM-type calculi we mark
the auxiliary formulas of logical inferences and cut by +, the principle ones by
∗.

6
M. Baaz and A. Leitsch
Let φ be the following proof
φ1
φ2
0: (Dx)((P(x) ∨Q(x)) ∨R(x)), 1: (Dx)P(x) cut
where φ1 =
(ψ′)
0: P(α) ∨Q(α), u: P(α) ∨Q(α), 1: P(α) ∨Q(α)
0: P(α) ∨Q(α), u: P(α) ∨Q(α), u: R(α)∗, 1: P(α) ∨Q(α) π∗+ w
0: A(α) ∨Q(α), u: (P(α) ∨Q(α)) ∨R(α)+∗, 1: P(α) ∨Q(α)
∨: u
0: (Dx)((P(x) ∨Q(x)) ∨R(x))∗, 0: P(α) ∨Q(α)+, 1: P(α) ∨Q(α)+ π∗+ D: 0
0: (Dx)((P(x) ∨Q(x)) ∨R(x)), 1: (Dx)(P(x) ∨Q(x))∗
D: 1
and φ2 =
0: P(β), u: P(β), 1: P(β)
0: P(β), 1: P(β), u: P(β)+, u: Q(β)∗+ π∗+ w
0: P(β), u: P(β) ∨Q(β)∗+, 1: P(β)
π∗+ ∨: u
0: (Dx)(P(x) ∨Q(x))∗, 0: P(β)+, 1: P(β)+ π∗+ D: 0
0: (Dx)(P(x) ∨Q(x)), 1: (Dx)P(x)∗
D: 1
we have to deﬁne ψ′ as our axiom set must be atomic. We set
ψ′ = ψ(A, B){A ←P(α), A ←Q(α)}
and deﬁne
ψ(A, B) =
S, 0: A, 1: A
S, 0: B, 1: B
S, 1: A, 1: B
0: A, u: A, u: B, 1: A ∨B
∨: 1
T, 0: A, 1: A
T, 0: B, 1: B
T, 1: A, 1: B
0: B, u: A, u: B, 1: A ∨B
0: A ∨B, u: A, u: B, 1: A ∨B
∨: 0
0: A ∨B, u: A ∨B, 1: A ∨B
π∗+ ∨: u
For S = 0: A, u: A, u: B and T = 0: B, u: A, u: B. It is easy to see that the
end sequent is valid as the axioms contain 0: A, u: A, 1: A and 0: B, u: B, 1: B as
subsequents.
Deﬁnition 12 (W-clause). A W-clause is an atomic sequent (where W is the
set of truth symbols). The empty sequent is called empty clause and is denoted
by 2 .
Let S be an W-clause. S’ is called a renamed variant of S if S′ = Sη for a
variable permutation η.
Deﬁnition 13 (W-resolution). We deﬁne a resolution calculus RW which
only depends on the set W (but not on the logical rules of K). RW operates
on W-clauses; its rules are:

CERES in Many-Valued Logics
7
1. resww′ for all w, w′ ∈W and w ̸= w′,
2. w-factoring for w ∈W,
3. permutations.
Let S: Γ, w: A and S′: Γ ′, w′: A′ (where w ̸= w′) be two W-clauses and
S′′: Γ ′′, w′: A′′ be a variant of S′ s.t. S and S′ are variable disjoint. Assume that
{A, B′} are uniﬁable by a most general uniﬁer σ. Then the rule resww′ on S, S′
generates a resolvent R for
R = Γσ, Γ ′′σ.
Let S: Γ, w: A1, . . . , w: Am be a clause and σ be a most general uniﬁer of
{A1, . . . , Am}. Then the clause
S′: Γσ, w: A1σ
is called a w-factor of S.
A W-resolution proof of a clause S from a set of clauses S is a directed labelled
tree s.t. the root is labelled by S and the leaves are labelled by elements of S. The
edges correspond the applications of w-factoring (unary), permutation (unary)
and resww′ (binary).
It is proved in [1] that W-resolution is complete. For the LM-type calculus
we only require soundness w.r.t. the underlying logic. So from now on we assume
that K is sound.
Note that we did not deﬁne clauses as sets of signed literals; therefore we need the
permutation rule in order to “prepare” the clauses for resolution and factoring.
Deﬁnition 14 (ground projection). Let γ be a W-resolution proof and
{x1, . . . , xn} be the variables occurring in the indexed clauses of γ. Then, for all
ground terms t1, . . . , tn, γ{x1 ←t1, . . . , x1 ←tn} is called a ground projection
of γ.
Remark 3. Ground projections of resolution proofs are ordinary proofs in K;
indeed factoring becomes n-contraction and resolution becomes cut.
Deﬁnition 15 (ancestor relation). Let
S1: Γ, ∆+
1
...
Sm: Γ, ∆+
m
S: Γ, w: A∗
x
be a an inference in a proof φ; let µ be the occurrence of the principal signed
formula w: A in S and νij be the occurrence of the j-th auxiliary formula in Si.
Then all νij are ancestors of µ.
The ancestor relation in φ is deﬁned as the reﬂexive and transitive closure of
the above relation.
By S(N, Ω) ( ¯S(N, Ω)) we denote the subsequent of S at the node N of φ
consisting of all formulas which are (not) ancestors of a formula occurrence in
Ω.

8
M. Baaz and A. Leitsch
Example 2. Let ψ(A, B) as in Example 1:
S, 0: A, 1: A
S, 0: B, 1: B
S, 1: A, 1: B
0: A†, u: A, u: B, 1: A ∨B
∨: 1
T, 0: A, 1: A
T, 0: B, 1: B
T, 1: A, 1: B
0: B†, u: A, u: B, 1: A ∨B
0: A ∨B†, u: A, u: B, 1: A ∨B
∨: 0
0: A ∨B†, u: A ∨B, 1: A ∨B
π∗+ ∨: u
Let N0 be the root of ψ(A, B) and µ be the occurrence of the ﬁrst formula
(0: A ∨B) in N. The formula occurrences which are ancestors of µ are labelled
with †. The marking is not visible in S and T where the ancestors occur. In the
antecedent N1, N2 of the binary inference ∨: 0 we have S(N1, {µ}) = 0: A and
S(N2, {µ}) = 0: B.
3
Skolemization
As CERES-m (like CERES [6] and [5]) augments a ground resolution proof with
cut-free parts of the original proof related only to the end-sequent, eigenvariable
conditions in these proof parts might be violated. To get rid of this problem,
the endsequent of the proof and the formulas, which are ancestors of the end-
sequent have to be skolemized, i.e eigenvariables have to be replaced by suit-
able Skolem terms. To obtain a skolemization of the end-sequent, we have to
represent (analyze) distributive quantiﬁers in terms of strong quantiﬁers (cover-
ing exclusively eigenvariables) and weak quantiﬁers (covering exclusively terms).
This was the main motivation for the choice of our deﬁnition of quantiﬁers in
Deﬁnition 9. The strong quantiﬁers are replaced by Skolem functions depending
on the weakly quantiﬁed variables determined by the scope. Note that distribu-
tive quantiﬁers are in general mixed, i.e. they are neither weak nor strong, even
in the two-valued case.
3.1
Skolemization of Proofs
Deﬁnition 16 (skolemization). Let ∆: Γ, w: A be a sequent and (Qx)B be a
subformula of A at the position λ where Qx is a maximal strong quantiﬁer in
w: A. Let y1, . . . , ym be free variables occurring in (Qx)B, then we deﬁne
sk(∆) = Γ, w: A[B{x →f(y1, . . . , ym)}]λ
where f is a function symbol not occurring in ∆.
If w: A contains no strong quantiﬁer then we deﬁne sk(∆) = ∆.
A sequent S is in Skolem form if there exists no permutation S′ of S s.t.
sk(S′) ̸= S′. S′ is called a Skolem form of S if S′ is in Skolem form and can be
obtained from S by permutations and the operator sk.
The skolemization of proofs can be deﬁned in a way quite similar to the
classical case (see [4]).

CERES in Many-Valued Logics
9
Deﬁnition 17 (skolemization of K-proofs). Let K be an LM-type calculus.
We deﬁne a transformation of proofs which maps a proof φ of S from A into a
proof sk(φ) of S′ from A′ where S′ is the Skolem form of S and A′ is an instance
of A.
Locate an uppermost logical inference which introduces a signed formula w: A
which is not an ancestor of a cut and contains a strong quantiﬁer.
(a) The formula is introduced by a strong quantiﬁer inference:
ψ[α]
S′: Γ, u1: A(α)+, . . . , um: A(α)+
S: Γ, w: (Qx)A(x)∗
Q: w
in φ and N ′, N be the nodes in φ labelled by S′, S. Let P be the path from the root
to N ′, locate all weak quantiﬁer inferences ξi (i=1,. . . ,n) on P and all terms ti
eliminated by ξi. Then we delete the inference node N and replace the derivation
ψ of N ′ by
ψ[f(t1, . . . , tn)]
S′: Γ, u1: A(f(t1, . . . , tn))+, . . . , um: A(f(t1, . . . , tn))+
S0: Γ, w: A(f(t1, . . . , tn))∗
cQ : w
where f is a function symbol not occurring in φ and cQ is the connective corre-
sponding to Q. The sequents on P are adapted according to the inferences on P.
(b) The formula is inferred by a propositional inference or by weakening (within
the principal formula w: A) then we replace w: A by the Skolem form of w: A
where the Skolem function symbol does not occur in φ.
Let φ′ be the proof after such a skolemization step. We iterate the procedure
until no occurrence of a strong quantiﬁer is an ancestor of an occurrence in the
end sequent. The resulting proof is called sk(φ). Note that sk(φ) is a proof from
the same axiom set A as A is closed under substitution.
Deﬁnition 18. A proof φ is called skolemized if sk(φ) = φ.
Note that skolemized proofs may contain strong quantiﬁers, but these are
ancestors of cut, in the end-sequent there are none.
Example 3. Let φ be the proof from Example 1:
φ1
φ2
0: (Dx)((P(x) ∨Q(x)) ∨R(x)), 1: (Dx)P(x) cut
where φ1 =
(ψ′)
0: P(α) ∨Q(α), u: P(α) ∨Q(α), 1: P(α) ∨Q(α)
0: P(α) ∨Q(α), u: P(α) ∨Q(α), u: R(α)∗, 1: P(α) ∨Q(α) π∗+ w
0: A(α) ∨Q(α), u: (P(α) ∨Q(α)) ∨R(α)+∗, 1: P(α) ∨Q(α)
∨: u
0: (Dx)((P(x) ∨Q(x)) ∨R(x))∗, 0: P(α) ∨Q(α)+, 1: P(α) ∨Q(α)+ π∗+ D: 0
0: (Dx)((P(x) ∨Q(x)) ∨R(x)), 1: (Dx)(P(x) ∨Q(x))∗
D: 1

10
M. Baaz and A. Leitsch
and φ2 =
0: P(β), u: P(β), 1: P(β)
0: P(β), 1: P(β), u: P(β)+, u: Q(β)∗+ π∗+ w
0: P(β), u: P(β) ∨Q(β)∗+, 1: P(β)
π∗+ ∨: u
0: (Dx)(P(x) ∨Q(x))∗, 0: P(β)+, 1: P(β)+ π∗+ D: 0
0: (Dx)(P(x) ∨Q(x)), 1: (Dx)P(x)∗
D: 1
The proof is not skolemized as the endsequent contains a strong quantiﬁer
occurrence in the formula 1: (Dx)P(x). This formula comes from the proof φ2.
Thus we must skolemize φ2 and adapt the end sequent of φ. It is easy to verify
that sk(φ2) =
0: P(c), u: P(c), 1: P(c)
0: P(c), 1: P(c), u: P(c)+, u: Q(c)∗+ π∗+ w
0: P(c), u: P(c) ∨Q(c)∗+, 1: P(c)
π∗+ ∨: u
0: (Dx)(P(x) ∨Q(x))∗, 0: P(c)+, 1: P(c)+ π∗+ D: 0
0: (Dx)(P(x) ∨Q(x)), 1: P(c)∗
cD−1
Then sk(φ) =
φ1
sk(φ2)
0: (Dx)((P(x) ∨Q(x)) ∨R(x)), 1: P(c) cut
Note that φ1 cannot be skolemized as the strong quantiﬁers in φ1 are ances-
tors of the cut in φ.
3.2
De-Skolemization of Proofs
Skolem functions can be replaced by the original structure of (strong and weak)
quantiﬁers by the following straightforward algorithm at most exponential in the
maximal size of the original proof and of the CERES-m proof of the Skolemized
end sequent: Order the Skolem terms (terms, whose outermost function symbol
is a Skolem function) by inclusion.The size of the proof resulting from CERES-m
together with the number of inferences in the original proof limits the number
of relevant Skolem terms. Always replace a maximal Skolem term by a fresh
variable, and determine the formula F in the proof, for which the correspond-
ing strong quantiﬁer should be introduced. In re-introducing the quantiﬁer we
eliminate the newly introduced connectives cQ. As the eigenvariable condition
might be violated at the lowest possible position, where the quantiﬁer can be
introduced (because e.g. the quantiﬁed formula has to become part of a larger
formula by an inference) suppress all inferences on F such that F occurs as side
formula besides the original end-sequent. Then perform all inferences on F. This
at most triples the size of the proof (a copy of the proof together with suitable
contractions might be necessary).

CERES in Many-Valued Logics
11
3.3
Re-introduction of Distributive Quantiﬁers
The distributive quantiﬁers are by now represented by a combination of strong
quantiﬁers, weak quantiﬁers and connectives. A simple permutation of inferences
in the proof leads to the immediate derivation in several steps of the representa-
tion of the distributive quantiﬁer from the premises of the distributive quantiﬁer
inference. The replacement of the representation by the distributive quantiﬁer is
then simple.
4
CERES-m
As in the classical case (see [5] and [6]) we restrict cut-elimination to skolemized
proofs. After cut-elimination the obtained proof can be re-skolemized, i.e. it can
be transformed into a derivation of the original (unskolemized) end-sequent.
Deﬁnition 19. Let K be an LM-type calculus. We deﬁne SK[K] be the set of
all skolemized proofs in K. SK∅[K] is the set of all cut-free proofs in SK[K]
and, for all i ≥0, SKi[K] is the subset of SK[K] containing all proofs with
cut-formulas of formula complexity ≤i.
Our goal is to transform a derivation in SK[K] into a derivation in SK0[K]
(i.e. we reduce all cuts to atomic ones). The ﬁrst step in the corresponding
procedure consists in the deﬁnition of a clause term corresponding to the sub-
derivations of an K-proof ending in a cut. In particular we focus on derivations
of the cut formulas themselves, i.e. on the derivation of formulas having no
successors in the end-sequent. Below we will see that this analysis of proofs,
ﬁrst introduced in [5], is quite general and can easily be generalized to LM-type
calculi.
Deﬁnition 20 (clause term). The signature of clause terms consists of that
of W-clauses and the operators ⊕n and ⊗n for n ≥2.
– (Finite) sets of W-clauses are clause terms.
– If X1, . . . , Xn are clause terms then ⊕n(X1, . . . , Xn) is a clause term.
– If X1, . . . , Xn are clause terms then ⊗n(X1, . . . , Xn) is a clause term.
Clause terms denote sets of W-clauses; the following deﬁnition gives the
precise semantics.
Deﬁnition 21. We deﬁne a mapping | | from clause terms to sets of W-clauses
in the following way:
|S| = C for sets of W-clauses S,
| ⊕n (X1, . . . , Xn)| =
n

i=1
|Xi|,
| ⊗n (X1, . . . , Xn)| = merge(|X1|, . . . , |Xn|),

12
M. Baaz and A. Leitsch
where
merge(S1, . . . , Sn) = {S1 . . . Sn | S1 ∈S1, . . . Sn ∈Sn}.
We deﬁne clause terms to be equivalent if the corresponding sets of clauses are
equal, i.e. X ∼Y iﬀ|X| = |Y |.
Deﬁnition 22 (characteristic term). Let K be an LM-type calculus, φ be a
proof of S and let Ωbe the set of all occurrences of cut formulas in φ. We deﬁne
the characteristic (clause) term Θ(φ) inductively:
Let N be the occurrence of an initial sequent S′ in φ. Then Θ(φ)/N = {S(N, Ω)}
(see Deﬁnition 15).
Let us assume that the clause terms Θ(φ)/N are already constructed for all nodes
N in φ with depth(N) ≤k. Now let N be a node with depth(ν) = k + 1. We
distinguish the following cases:
(a) N is the consequent of M, i.e. a unary rule applied to M gives N. Here we
simply deﬁne
Θ(ϕ)/N = Θ(ϕ)/M.
(b) N is the consequent of M1, . . . , Mn, for n ≥2, i.e. an n-ary rule x applied
to M1, . . . , Mn gives N.
(b1) The auxiliary formulas of x are ancestors of Ω, i.e. the formulas occur
in S(Mi, Ω) for all i = 1, . . . , n. Then
Θ(φ)/N = ⊕n(Θ(ϕ)/M1, . . . , Θ(ϕ)/Mn).
(b2) The auxiliary formulas of x are not ancestors of Ω. In this case we
deﬁne
Θ(φ)/N = ⊗n(Θ(ϕ)/M1, . . . , Θ(ϕ)/Mn).
Note that, in an n-ary inference, either all auxiliary formulas are ancestors of
Ωor none of them.
Finally the characteristic term Θ(φ) of φ is deﬁned as Θ(φ)/N0 where N0 is
the root node of φ.
Deﬁnition 23 (characteristic clause set). Let φ be proof in an LM-type
calculus K and Θ(φ) be the characteristic term of φ. Then CL(φ), deﬁned as
CL(φ) = |Θ(φ)|, is called the characteristic clause set of φ.
Remark 4. If φ is a cut-free proof then there are no occurrences of cut formulas
in φ and CL(φ) = {2}.

CERES in Many-Valued Logics
13
Example 4. Let φ′ be the skolemized proof deﬁned in Example 3. It is easy to
verify that the characteristic clause set CL(φ′) is
{u: P(c),
0: P(α), 0: P(α), 1: P(α)
0: P(α), 0: Q(α), 1: Q(α)
0: P(α), 1: P(α), 1: Q(α)
0: Q(α), 0: P(α), 1: P(α)
0: Q(α), 0: Q(α), 1: Q(α)
0: Q(α), 1: P(α), 1: Q(α)}.
The set CL(φ′) can be refuted via W-resolution for W = {0, u, 1}. A W-
resolution refutation is (0f stands for 0-factoring) γ =
0: P(α), 0: P(α), 1: P(α)
u: P(c)
0: P(c), 0: P(c)
res1u
0: P(c)
0f
u: P(c)
2
res0u
A ground projection of γ (even the only one) is γ′ = γ{α ←c} =
0: P(c), 0: P(c), 1: P(c)
u: P(c)
0: P(c), 0: P(c)
cut1u
0: P(c)
c
u: P(c)
2
cut0u
Obviously γ′ is a proof in K.
In Example 4 we have seen that the characteristic clause set of a proof is
refutable by W-resolution. This is a general principle and the most signiﬁcant
property of cut-elimination by resolution.
Deﬁnition 24. From now on we write Ωfor the set of all occurrences of cut-
formulas in φ. So, for any node N in φ S(N, Ω) is the subsequent of S containing
the ancestors of a cut. ¯S(N, Ω) denotes the subsequent of S containing all non-
ancestors of a cut.
Remark 5. Note that for any sequent S occurring at a node N of φ, S is a
permutation variant of S(N, Ω), ¯S(N, Ω).
Theorem 1. Let φ be a proof in an LM-calculus K. Then there exists a W-
resolution refutation of CL(φ).
Proof. According to Deﬁnition 22 we have to show that
(∗) for all nodes N in φ there exists a proof of S(N, Ω) from SN,

14
M. Baaz and A. Leitsch
where SN is deﬁned as |Θ(φ)/N| (i.e. the set of clauses corresponding to N, see
Deﬁnition 22). If N0 is the root node of φ labelled by S then, clearly, no ancestor
of a cut exists in S and so S(N0, Ω) = 2. But by deﬁnition SN0 = CL(φ). So
we obtain a proof of 2 from CL(φ) in K. By the completeness of W-resolution
there exists a W-resolution refutation of CL(φ).
It remains to prove (∗):
Let N be a leaf node in φ. Then by deﬁnition of CL(φ) SN = {S(N, Ω)}. So
S(N, Ω) itself is the required proof of S(N, Ω) from SN.
(IH):
Now assume inductively that for all nodes N of depth ≤n in φ there exists a
proof ψN of S(N, Ω) from SN.
So let N be a node of depth n + 1 in φ. We distinguish the following cases:
(a) N is the consequent of M, i.e. N is the result of a unary inference in φ. That
means φ.N =
φ.M
S(N) x
By (IH) there exists a proof ψM of S(M, Ω) from SM. By Deﬁnition 22
SN = SM. If the auxiliary formula of the last inference is in S(M, Ω) we
deﬁne ψN =
ψM
S′
x
Obviously S′ is just S(N, Ω).
If the auxiliary formula of the last inference in φ.N is not in S(M, Ω) we
simply drop the inference and deﬁne ψN = ψ.M. As the ancestors of cut did
not change ψN is just a proof of S(N, Ω) from SN.
(b) N is the consequent of an n-ary inference for n ≥2, i.e. φ.N =
φ.M1
. . .
φ.Mn
S(N)
x
By (IH) there exist proofs ψMi of S(Mi, Ω) from SMi.
(b1) The auxiliary formulas of the last inference in φ.N are in S(Mi, Ω), i.e.
the inference yields an ancestor of a cut. Then, by Deﬁnition 22
SN = SM1 ∪. . . ∪SMn.
Then clearly the proof ψN:
ψM1
. . .
ψMn
S′
x
is a proof of S′ from SN and S′ = S(N, Ω).

CERES in Many-Valued Logics
15
(b2) The auxiliary formulas of the last inference in φ.N are not in S(Mi, Ω),
i.e. the principal formula of the inference is not an ancestor of a cut.
Then, by Deﬁnition 22
SN = merge(SM1, . . . , SMn).
We write Si for SMi and ψi for ψMi, Γi for S(Mi, Ω) and deﬁne
Di = merge(S1, . . . , Si),
∆i = Γ1, . . . , Γi,
for i = 1, . . . , n. Our aim is to deﬁne a proof ψN of S(N, Ω) from SN
where SN = Dn.
We proceed inductively and deﬁne proofs χi of ∆i from Di. Note that
for i = n we obtain a proof χn of S(M1, Ω), . . . , S(Mn, Ω) from SN, and
S(N, Ω) = S(M1, Ω), . . . , S(Mn, Ω). This is just what we want.
For i = 1 we deﬁne χ1 = ψ1.
Assume that i < n and we already have a proof χi of ∆i from Di. For
every D ∈Si+1 we deﬁne a proof χi[D]:
Replace all axioms C in χi by the derivation
C, D
D, C π
and simulate χi on the extended axioms (the clause D remains passive).
The result is a proof χ′[D] of the sequent
D, . . . , D, ∆i.
Note that the propagation of D through the proof is possible as no
eigenvariable conditions can be violated, as we assume the original proof
to be regular (if not then we may transform the ψi into proofs with
mutually disjoint sets of eigenvariables) . Then we deﬁne χi[D] as
χ′[D]
∆i, D c∗+ π
Next we replace every axiom D in the derivation ψi+1 by the proof χi[D]
and (again) simulate ψi+1 on the end-sequents of the χi[D] where the
∆i remain passive. Again we can be sure that no eigenvariable condition
is violated and we obtain a proof ρ of
∆i, . . . , ∆i, Γi+1.
from the clause set merge(Di, Si+1) which is Di+1. Finally we deﬁne
χi+1 =
ρ
∆i, Γi+1 π∗+ c∗
Indeed, χi+1 is a proof of ∆i+1 from Di+1.
3

16
M. Baaz and A. Leitsch
Like in the classical case ([6]) we deﬁne projections of the proof φ relative to
clauses C in CL(φ). The basic idea is the following: we drop all inferences which
infer ancestors of a cut formula; the result is a cut-free proof of the end sequent
extended by the clause C. Of course we do not obtain cut-elimination itself, but
instead a cut free proof of the end sequent extended by a clause. These cut-free
proofs are eventually inserted into a resolution proof, which eventually gives a
proof with atomic cuts only.
Lemma 1. Let φ be a deduction in SK[K] of a sequent S. Let C be a clause
in CL(φ). Then there exists a deduction φ[C] of C, S s.t. φ[C] is cut-free (in
particular φ(C) ∈SK∅[K]) and ∥φ[C]∥≤2 ∗∥φ∥.
Proof. Let SN be |Θ(φ)/N| (like in the proof of Theorem 1). We prove that
(⋆) for every node N in φ and for every C ∈SN there exists a proof T(φ, N, C)
of C, ¯S(N, Ω) s.t.
∥T(φ, N, C)∥≤2∥φ.N∥.
Indeed, it is suﬃcient to prove (⋆): for the root node N0 we have S = ¯S(N0, Ω)
(no signed formula of the end sequent is an ancestor of Ω), φ.N0 = φ and
CL(φ) = SN0; so at the end we just deﬁne φ[C] = T(φ, N0, C) for every C ∈
CL(φ).
We prove ⋆by induction on the depth of a node N in φ.
(IB) N is a leaf in φ.
Then, by deﬁnition of SN we have S = {S(N, Ω)} and C: S(N, Ω) is the only
clause in SN. Let Γ = ¯S(N, Ω). Then S(N) (the sequent labelling the node N)
is a permutation variant of C, Γ and we deﬁne T(φ, N, C) =
S(N)
C, Γ
π
If no permutation is necessary we just deﬁne T(φ, N, C) = S(N). In both cases
∥T(φ, N, C)∥≤2 = 2∥φ.N∥.
(IH) Assume (⋆) holds for all nodes of depth ≤k.
Let N be a node of depth k + 1. We distinguish the following cases:
(1) N is inferred from M via a unary inference x. By Deﬁnition of the clause
term we have SN = SM. So any clause in SN is already in SM.
(1a) The auxiliary formula of x is an ancestor of Ω. Then clearly ¯S(N, Ω) =
¯S(M, Ω) and we deﬁne T(φ, N, C) = T(φ, M, C). Clearly
∥T(φ, N, C)∥= ∥T(φ, M, C)∥≤(IH) 2∥φ.M∥< 2∥φ.N∥.

CERES in Many-Valued Logics
17
(1b) The auxiliary formula of x is not an ancestor of Ω. Let Γ = ¯S(M, Ω), Γ ′ =
¯S(N, Ω); thus the auxiliary formula of x is in Γ. By (IH) there exists a
proof ψ: T(φ, M, C) of C, Γ and ∥ψ∥≤2∥φ.M∥. We deﬁne T(φ, N, C) =
(ψ)
C, Γ
C, Γ ′ x
Note that x cannot be a strong quantiﬁer inference as the proof φ is
skolemized and there are no strong quantiﬁers in the end sequent. Thus
T(φ, N, C) is well-deﬁned. Moreover
∥T(φ, N, C)∥= ∥T(φ, M, C)∥+ 1 ≤(IH) 2∥φ.M∥+ 1 < 2∥φ.N∥.
(2) N is inferred from M1, . . . , Mn via the inference x for n ≥2. By (IH) there
are proofs T(φ, Mi, Ci) for i = 1, . . . , n and Ci ∈SMi. Let ¯S(Mi, Ω) = Γi
and ¯S(N, Ω) = Γ ′
1, . . . , Γ ′
n. We abbreviate T(φ, Mi, Ci) by ψi.
(2a) The auxiliary formulas of x are in Γ1, . . . , Γn. Let C be a clause in SN.
Then, by deﬁnition of the characteristic clause set, C = C1, . . . , Cn for
Ci ∈SMi (SN is deﬁned by merge). We deﬁne T(φ, N, C) as
(ψ1)
C1, Γ1
. . .
(ψn)
Cn, Γn
C1, . . . , Cn, Γ ′
1, . . . , Γ ′
n
x
By deﬁnition of ∥∥we have
∥φ.N∥= 1 +
n

i=1
∥φ.Mi∥,
∥ψi∥≤2∥φ.Mi∥by (IH)
Therefore
∥T(φ, N, C)∥= 1 +
n

i=1
∥ψi∥≤1 + 2
n

i=1
∥φ.Mi∥< 2∥φ.N∥.
(2b) The auxiliary formulas of x are not in Γ1, . . . , Γn. Let C by a clause
in SN. Then x operates on ancestors of cuts and SN = n
i=1 SMi, thus
C ∈SMi for some i ∈{1, . . . , n}. Moreover Γ ′
i = Γi for i = 1, . . . , n. We
deﬁne T(φ, N, C) as
(ψi)
C, Γi
C, Γi, Γ1, . . . , Γi−1, Γi+1, . . . , Γn
w
C, Γ1, . . . , Γn
π
Then
∥T(φ, N, C)∥≤∥ψi∥+ 2 < 2∥φ.N∥.

18
M. Baaz and A. Leitsch
This concludes the induction proof.
3
Example 5. Let φ′ be the proof from Example 3. We have computed the set
CL(φ′) in example 4. We select the clause C: 0: P(α), 0: P(α), 1: P(α) and com-
pute the projection φ′[C]:
0: P(α), u: P(α), u: Q(α), 0: P(α), 1: P(α)
0: P(α), 0: P(α), 1: P(α), u: P(α), u: Q(α) π
0: P(α), 0: P(α), 1: P(α), u: P(α) ∨Q(α)
∨: u
0: P(α), 0: P(α), 1: P(α), u: P(α) ∨Q(α), u: R(α) w
0: P(α), 0: P(α), 1: P(α), u: (P(α) ∨Q(α)) ∨R(α) ∨: u
0: P(α), 0: P(α), 1: P(α), 0: (Dx)((P(x) ∨Q(x)) ∨R(x)) D: 0
0: P(α), 0: P(α), 1: P(α), 0: (Dx)((P(x) ∨Q(x)) ∨R(x)), 1: P(c) w
Let φ be a proof of S s.t. φ ∈SK[K] and let γ be a W-resolution refutation
of CL(φ). We deﬁne a ground projection γ′ of γ which is a K-proof of 2 from
instances of CL(φ). This proof γ′ can be transformed into a proof γ′[φ] of S from
the axiom set A s.t. γ′[φ] ∈SK0[K] (γ′[φ] is a proof with atomic cuts). Indeed,
γ′ is the skeleton of the proof of S with atomic cuts and the real core of the end
result; γ′[φ] can be considered as an application of γ′ to (the projections of) φ.
Theorem 2. Let φ be a proof of S from A in SK[K] and let γ′ be a ground
projection of a W-refutation of CL(φ). Then there exists a proof γ′[φ] of S with
γ′[φ] ∈SK0[K] and
∥γ′[φ]∥≤∥γ′∥(2 ∗∥φ∥+ l(S) + 2).
Proof. We construct γ′[φ]:
(1) Replace every axiom C in γ′ by the projection φ[C]. Then instead of C we
obtain the proof φ[C] of C, S. For every occurrence of an axiom C in γ we
obtain a proof of length ≤2 ∗∥φ∥(by Lemma 1).
(2) Apply the permutation rule to all end sequents of the φ[C] and infer S, C.
The result is a proof ψ[C] with ∥ψ[C]∥≤2 ∗∥φ∥+ 1.
(3) Simulate γ′ on the extended sequents S, C, where the left part S remains
passive (note that, according to our deﬁnition, inferences take place on the
right). The result is a proof χ of a sequent S, . . . , S from A s.t.
∥χ∥≤∥γ′∥∗(2 ∗∥φ∥+ 1) + ∥γ∥.
Note that χ is indeed a K-proof as all inferences in γ′ are also inferences of
K.
(4) Apply one permutation and contractions to the end sequent of χ for obtaining
the end sequent S. The resulting proof is γ′[φ], the proof we are searching for.
As the number of occurrences of S in the end sequent is ≤∥γ′∥the additional
number of inferences is ≤1+l(S)∗∥γ′∥. By putting things together we obtain
∥γ′[φ]∥≤∥γ′∥(2 ∗∥φ∥+ l(S) + 2).
3

CERES in Many-Valued Logics
19
Looking at the estimation in Theorem 2 we see that the main source of
complexity is the length of the W-resolution proof γ′. Indeed, γ (and thus γ′)
can be considered as the characteristic part of γ′[φ] representing the essence of
cut-elimination. To sum up the procedure CERES-m for cut-elimination in any
LM-type logic K cab be deﬁned as:
Deﬁnition 25 (CERES-m).
input :φ ∈P[K].
construct a Skolem form φ′ of φ.
compute CL(φ′).
construct a W-refutation γ of CL(φ′).
compute a ground projection γ′ of γ.
compute γ′[φ′] (γ′[φ′] ∈SK0[K]).
reskolemize γ′[φ′] to φ′′ (φ′′ ∈P0[K]).
Example 6. The proof φ from Example 1 has been skolemized to a proof φ′ in
Example 3. In Example 4 we have computed the characteristic clause set CL(φ′)
and gave a refutation γ of CL(φ′) and a ground projection γ′: γ{α ←c}. Recall
γ′:
0: P(c), 0: P(c), 1: P(c)
u: P(c)
0: P(c), 0: P(c)
cut1u
0: P(c)
c
u: P(c)
2
cut0u
and the instances C′
1 = u: P(c) and C′
2 = 0: P(c), 0: P(c), 1: P(c) of two signed
clauses in CL(φ′) which deﬁned the axioms of γ′. We obtain γ′[φ′] by substituting
the axioms C′
1, C′
2 by the projections φ[C′
1], φ[C′
2] (φ[C′
2] is an instance of the
projection computed in Example 5). The end sequent of φ′ is
S: 0: (Dx)((P(x) ∨Q(x)) ∨R(x)), 1: P(c)
So we obtain γ′[φ′] =
(φ′[C′
2])
0: P(c), 0: P(c), 1: P(c), S
S, 0: P(c), 0: P(c), 1: P(c) π
(φ[C′
1])
u: P(c), S
S, u: P(c) π
S, S, 0: P(c), 0: P(c)
cut1u
S, S, 0: P(c)
c
(φ[C′
1])
u: P(c), S
S, u: P(c) π
S, S, S
cut0u
S
c∗
5
Conclusion
Besides establishing a feasible cut-elimination method for many-valued ﬁrst order
logics the main aim of this paper is to demonstrate the stability of CERES

20
M. Baaz and A. Leitsch
w.r.t. cut elimination problems beyond classical ﬁrst order logic. The authors
are convinced, that this stability of CERES will it enable to incorporate intrinsic
non-classical logics such as intuitionistic logic and possibly to extend CERES to
the second order case, where inductive methods of cut-elimination fail by G¨odel’s
Second Incompleteness Theorem.
References
1. M. Baaz, C. Ferm¨uller:
Resolution-Based Theorem Proving for Many-Valued
Logics, Journal of Symbolic Computation, 19(4), pp. 353-391, 1995.
2. M. Baaz, C. Ferm¨uller, G. Salzer: Automated Deduction for Many-Valued Logics,
in: Handbook of Automated Reasoning 2, eds. J. A. Robinson, A. Voronkov,
Elsevier and MIT Press, pp. 1356-1402, 2001.
3. M. Baaz, C. Ferm¨uller, R. Zach: Elimination of Cuts in First-order Finite-valued
Logics, J. Inform. Process. Cybernet. (EIK), 29(6) , pp. 333-355, 1994.
4. M. Baaz, A. Leitsch: Cut normal forms and proof complexity, Annals of Pure
and Applied Logic, 97, pp. 127-177, 1999.
5. M. Baaz, A. Leitsch: Cut-Elimination and Redundancy-Elimination by Resolu-
tion, Journal of Symbolic Computation, 29, pp. 149-176, 2000.
6. M. Baaz, A. Leitsch: Towards a Clausal Analysis of Cut-Elimination, Journal of
Symbolic Computation, to appear.
7. W. A. Carnielli:
Systematization of Finite Many-Valued Logics through the
Method of Tableaux, Journal of Symbolic Logic, 52(2), pp. 473-493, 1987.
8. G. Gentzen: Untersuchungen ¨uber das logische Schließen, Mathematische Zeit-
schrift 39, pp. 405–431, 1934–1935.

A Decomposition Rule for Decision Procedures
by Resolution-Based Calculi
Ullrich Hustadt1, Boris Motik2, and Ulrike Sattler3
1 Department of Computer Science, University of Liverpool
Liverpool, UK
U.Hustadt@csc.liv.ac.uk
2 FZI Research Center for Information Technologies at the University of Karlsruhe
Karlsruhe, Germany
motik@fzi.de
3 Department of Computer Science, University of Manchester
Manchester, UK
sattler@cs.man.ac.uk
Abstract. Resolution-based calculi are among the most widely used
calculi for theorem proving in ﬁrst-order logic. Numerous reﬁnements of
resolution are nowadays available, such as e.g. basic superposition, a cal-
culus highly optimized for theorem proving with equality. However, even
such an advanced calculus does not restrict inferences enough to obtain
decision procedures for complex logics, such as SHIQ. In this paper,
we present a new decomposition inference rule, which can be combined
with any resolution-based calculus compatible with the standard notion
of redundancy. We combine decomposition with basic superposition to
obtain three new decision procedures: (i) for the description logic SHIQ,
(ii) for the description logic ALCHIQb, and (iii) for answering conjunc-
tive queries over SHIQ knowledge bases. The ﬁrst two procedures are
worst-case optimal and, based on the vast experience in building eﬃcient
theorem provers, we expect them to be suitable for practical usage.
1
Introduction
Resolution-based calculi are nowadays among the most widely used calculi for
theorem proving in ﬁrst-order logic. The reasons for that are twofold. On the
theoretical side, the initial resolution calculus was signiﬁcantly reﬁned to obtain
various eﬃcient calculi without losing soundness or completeness (e.g. [2,15]).
On the practical side, implementation techniques for eﬃcient theorem provers
have been devised and applied in practice (an overview is given in [21]).
Because of its popularity, resolution is often used as a framework for deciding
various fragments of ﬁrst-order logic. The fundamental principles for deciding a
ﬁrst-order fragment L by resolution are known from [12]. First, one selects a
sound and complete resolution calculus C. Next, one identiﬁes the set of clauses
NL such that for a ﬁnite signature, NL is ﬁnite and each formula ϕ ∈L, when
translated into clauses, produces clauses from NL. Finally, one demonstrates
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 21–35, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

22
U. Hustadt, B. Motik, and U. Sattler
closure of NL under C, namely, that applying an inference of C to clauses from
NL produces a clause in NL. This is suﬃcient to obtain a refutation decision
procedure for L since, in the worst case, C will derive all clauses of NL. An
overview of decision procedures derived by these principles is given in [8].
The calculus C should be chosen to restrict inferences as much as possible
without losing completeness. Namely, an unoptimized calculus usually performs
unnecessary inferences which hinder closure of NL under C. Consider the decision
procedure for SHIQ−description logic we presented in [11]. This logic provides
so-called number restrictions, which are translated into ﬁrst-order logic using
counting quantiﬁers. We translate counting quantiﬁers into (in)equalities, and
decide SHIQ−by saturation under basic superposition [3,14]. The prominent
feature of basic superposition is the basicness restriction, by which superposi-
tion into terms introduced by uniﬁcation can be omitted without compromising
completeness. This restriction is crucial to obtain closure under inferences.
Interestingly, this approach does not yield a decision procedure for the slightly
more expressive DL SHIQ [9] (SHIQ−allows number restrictions only on roles
without subroles). Namely, basic superposition alone is not restrictive enough to
limit the term depth in conclusions. Therefore, we present decomposition, a new
inference rule which can be used to transform certain conclusions. We show that
decomposition is sound and complete when combined with basic superposition,
which is interesting because of a non-standard approach to lifting used in basic
superposition; however, the rule can be combined with any saturation calculus
compatible with the standard notion of redundancy [2].
Decomposition indeed solves the motivating problem since it allows us to
establish the closure under inferences for SHIQ, and even yields an optimal de-
cision procedure4. Furthermore, decomposition proves to be versatile and useful
for other decidable fragments of ﬁrst-order logic: we extend the basic superposi-
tion algorithm to handle ALCHIQb, a description logic providing safe Boolean
role expressions. As for SHIQ, this algorithm is optimal. Finally, we derive a de-
cision procedure for answering conjunctive queries over SHIQ knowledge bases.
Based on the vast experience in building eﬃcient theorem provers, we believe
that these algorithms are suitable for practice.
All results in this paper have been summarized in a technical report [10].
2
Preliminaries
Description Logics. Given a set of role names NR, a SHIQ role is either some
R ∈NR or an inverse role R−for some R ∈NR. A SHIQ RBox KBR is
a ﬁnite set of role inclusion axioms R ⊑S and transitivity axioms Trans(R),
for R and S SHIQ roles. As usual, for R ∈NR, we set Inv(R) = R−and
Inv(R−) = R, and we assume that, if R ⊑S ∈KBR (Trans(R) ∈KBR), then
Inv(R) ⊑Inv(S) ∈KBR (Trans(Inv(R)) ∈KBR) as well. A role R is simple if for
each role S ⊑∗R, Trans(S) /∈KBR (⊑∗is the reﬂexive-transitive closure of ⊑).
4 Optimal under the assumption that numbers in number restrictions are coded in
unary.

A Decomposition Rule for Decision Procedures by Resolution-Based Calculi
23
Given a set of concept names NC, SHIQ concepts are inductively deﬁned as
follows: each A ∈NC is a SHIQ concept and, if C is a SHIQ concept, R a role,
S a simple role, and n an integer, then ¬C, C1 ⊓C2, ∀R.C, and ≤n S.C are also
SHIQ concepts. As usual, we use C1 ⊔C2, ∃R.C, ≥n S.C as abbreviations for
¬(¬C1 ⊓¬C2), ¬∀R.¬C, and ¬(≤(n −1) S.C). A TBox KBT is a ﬁnite set of
concept inclusion axioms C ⊑D. An ABox KBA is a ﬁnite set of axioms C(a),
R(a, b), and (in)equalities a ≈b and a ̸≈b. A SHIQ knowledge base KB is a
triple (KBR, KBT , KBA). The semantics of KB is given by translating it into
ﬁrst-order logic by the operator π from Table 1. The main inference problem is
checking KB satisﬁability, i.e. determining if a ﬁrst-order model of π(KB) exists.
The logic SHIQ−is obtained from SHIQ by restricting roles in number
restrictions ≤n S.C and ≥n S.C to very simple roles; a role S is very simple in
KBR if there is no role S′ with S′ ⊑S ∈KBR. The restriction ALCHIQ of
SHIQ is obtained by disallowing transitivity axioms Trans(R) in RBoxes.
Considering complexity, we must decide how to measure the size of concepts
and knowledge bases. Here, we simply use their length, and assume unary coding
of numbers, i.e. |≤n R.C| = n + 1 + |C|.
Basic Superposition. We assume the standard notions of ﬁrst-order clauses with
equality: all existential quantiﬁers have been eliminated using Skolemization;
all remaining variables are universally quantiﬁed; we only consider the equality
predicate, i.e. all non-equational literals A are encoded as A ≈⊤in a multi-
sorted setting; and we treat ≈as having built-in symmetry. Moreover, we assume
the reader to be familiar with standard resolution [2].
Basic superposition [3,14] is an optimized version of superposition which
prohibits superposition into terms introduced by uniﬁcation in previously per-
formed inferences. Its inferences rules are formalized by distinguishing two parts
of a clause: (i) the skeleton clause C and (ii) the substitution σ representing
the cumulative eﬀects of all uniﬁcations. Such a representation of a clause Cσ is
called a closure, and is written as C·σ. A closure can conveniently be represented
by marking the terms in Cσ occurring at variable positions of C with [ ]. Any
position at or beneath a marked position is called a substitution position.
The calculus requires two parameters. The ﬁrst is an admissible ordering
on terms ≻, i.e. a reduction ordering total on ground terms. If ≻is total on
non-ground terms (as is the case in this paper), it can be extended to literals
by associating, with each literal L = s ◦t, ◦∈{≈, ̸≈}, a complexity measure
cL = (max(s, t), pL, min(s, t)), where pL is 1 if ◦is ≈, and 0 otherwise. Now
L1 ≻L2 iﬀcL1 ≻cL2, where cLi are compared lexicographically, with 1 ≻0.
The second parameter of the calculus is a selection function which selects an
arbitrary set of negative literals in each clause.
The basic superposition calculus is a refutation procedure. If a set of closures
N is saturated up to redundancy (meaning that all inferences from premises in N
are redundant in N), then N is unsatisﬁable if and only if it contains the empty
closure. A literal L · σ is (strictly) maximal w.r.t. a closure C · σ if no L′ ∈C
exists, such that L′σ ≻Lσ (L′σ ⪰Lσ). A literal L · σ is (strictly) eligible for
superposition in (C ∨L)·σ if there are no selected literals in (C ∨L)·σ and L·σ

24
U. Hustadt, B. Motik, and U. Sattler
Table 1. Semantics of SHIQ by Mapping to FOL
Concepts to FOL:
πy(A, X) = A(X)
πy(C ⊓D, X) = πy(C, X) ∧πy(D, X)
πy(¬C, X) = ¬πy(C, X)
πy(∀R.C, X) = ∀y : R(X, y) →πx(C, y)
πy(≤n S.C, X) = ∀y1, . . . , yn+1 : V S(X, yi) ∧V πx(C, yi) →W yi ≈yj
Axioms to FOL:
π(C ⊑D) = ∀x : πy(C, x) →πy(D, x)
π(R ⊑S) = ∀x, y : R(x, y) →S(x, y)
π(Trans(R)) = ∀x, y, z : R(x, y) ∧R(y, z) →R(x, z)
KB to FOL:
π(R) = ∀x, y : R(x, y) ↔R−(y, x)
π(KBR) = V
α∈KBR π(α) ∧V
R∈NR π(R)
π(KBT ) = V
α∈KBT π(α)
π(KBA) = V
C(a)∈KBA πy(C, a) ∧V
R(a,b)∈KBA R(a, b)∧
V
a≈b∈KBA a ≈b ∧V
a̸≈b∈KBA a ̸≈b
π(KB) = π(KBR) ∧π(KBT ) ∧π(KBA)
X is a meta variable and is substituted by the actual variable.
πx is deﬁned as πy by substituting x(i) for all y(i), respectively, and πy for πx.
Table 2. Inference Rules of the BS Calculus
Positive superposition:
(C ∨s ≈t) · ρ
(D ∨w ≈v) · ρ
(C ∨D ∨w[t]p ≈v) · θ
(i)
σ = MGU(sρ, wρ|p) and θ = ρσ,
(ii) tθ  sθ and vθ  wθ,
(iii) (s ≈t) · θ is strictly eligible for superposition,
(iv) (w ≈v) · θ is strictly eligible for superposition,
(v)
sθ ≈tθ  wθ ≈vθ,
(vi) w|p is not a variable.
Negative superposition:
(C ∨s ≈t) · ρ
(D ∨w ̸≈v) · ρ
(C ∨D ∨w[t]p ̸≈v) · θ
(i)
σ = MGU(sρ, wρ|p) and θ = ρσ,
(ii) tθ  sθ and vθ  wθ,
(iii) (s ≈t) · θ is strictly eligible for superposition,
(iv) (w ̸≈v) · θ is eligible for resolution,
(v)
w|p is not a variable.
Reﬂexivity resolution:
(C ∨s ̸≈t) · ρ
C · θ
(i) σ = MGU(sρ, tρ) and θ = ρσ,
(ii) (s ̸≈t) · θ is eligible for resolution.
Equality factoring:
(C ∨s ≈t ∨s′ ≈t′) · ρ
(C ∨t ̸≈t′ ∨s′ ≈t′) · θ
(i)
σ = MGU(sρ, s′ρ) and θ = ρσ,
(ii) tθ  sθ and t′θ  s′θ,
(iii) (s ≈t) · θ is eligible for superposition.
Ordered Hyperresolution:
E1 . . . En
E
(C1 ∨. . . ∨Cn ∨D) · θ
(i)
Ei are of the form (Ci ∨Ai) · ρ, for 1 ≤i ≤n,
(ii) E is of the form (D ∨¬B1 ∨. . . ∨¬Bn) · ρ,
(iii) σ is the most general substitution such that
Aiθ = Biθ for 1 ≤i ≤n, and θ = ρσ,
(iv) Ai · θ is strictly eligible for superposition,
(v)
¬Bi·θ are selected, or nothing is selected, i = 1
and ¬B1 · θ is maximal w.r.t. D · θ.
is (strictly) maximal w.r.t. C · σ; L · σ is eligible for resolution in (C ∨L) · σ if it
is selected in (C ∨L) · σ or there are no selected literals in (C ∨L) · σ and L · σ
is maximal w.r.t. C · σ. We denote basic superposition with BS and present its
inference rules in Table 2. The ordered hyperresolution rule is a macro inference,
combining negative superposition and reﬂexivity resolution. The closure E is
called the main premise, and the closures Ei are called the side premises. An
overview of the completeness proof and compatible redundancy elimination rules
are given in [10].

A Decomposition Rule for Decision Procedures by Resolution-Based Calculi
25
3
Motivation
To motivate the need for decomposition, we give an overview of our procedure for
deciding satisﬁability of a SHIQ−knowledge base KB using BS from [11] and
highlight the problems related to deciding full SHIQ. We assume that KB has
an extensionally reduced ABox, where all concepts occurring in ABox assertions
are atomic. This is without loss of generality, since each axiom C(a), where C
is complex, can be replaced with axioms AC(a) and AC ⊑C, for AC a new
concept; this transformation is obviously polynomial.
3.1
Deciding SHIQ−by BS
Eliminating Transitivity. A minor problem in deciding satisﬁability of KB are
the transitivity axioms, which, in their clausal form, do not contain so-called
covering literals (i.e. literals containing all variables of a clause). Such clauses
are known to be diﬃcult to handle, so we preprocess KB into an equisatisﬁable
ALCHIQ−knowledge base Ω(KB). Roughly speaking, we replace each transi-
tivity axiom Trans(S) with axioms ∀R.C ⊑∀S.(∀S.C), for each R with S ⊑∗R
and C a concept occurring in KB. This transformation is polynomial.
Preprocessing. We next translate Ω(KB) into a ﬁrst-order formula π(KB) ac-
cording to Table 1. Assuming unary coding of numbers, π(KB) can be computed
in polynomial time. To transform π(KB) into a set of closures Ξ(KB), we apply
the well-known structural transformation [16]. Roughly speaking, the structural
transformation introduces a new name for each non-atomic subformula of π(KB).
It is well-known that π(KB) and Ξ(KB) are equisatisﬁable, and that Ξ(KB)
can be computed in polynomial time.
For any KB, all closures from Ξ(KB) are of types from Table 3; we call them
ALCHIQ−-closures. We use the following notation: for a term t, with P(t) we
denote a disjunction of the form (¬)P1(t) ∨. . . ∨(¬)Pn(t), and with P(f(x))
we denote a disjunction of the form P1(f1(x)) ∨. . . ∨Pm(fm(x)) (notice that
this allows each Pi(fi(x)) to contain positive and negative literals). With ⟨t⟩we
denote that the term t may, but need not be marked. In all closure types, some of
the disjuncts may be empty. Furthermore, for each function symbol f occurring
in Ξ(KB), there is exactly one closure of type 3 containing f(x) unmarked; this
closure is called the Rf-generator, the disjunction Pf(x) is called the f-support,
and R is called the designated role for f and is denoted as role(f).
Parameters for BS. We use BSDL to denote the BS calculus parameterized as
follows. We use a standard lexicographic path ordering [7,1] (LPO) for comparing
terms. LPOs are based on a precedence >P over function, constant, and predicate
symbols. If the precedence is total, LPO is admissible for basic superposition.
To decide ALCHIQ−, we can use any precedence such that f >P c >P p >P ⊤,
for any function symbol f, constant c, and predicate symbol p. We select all
negative binary literals in a closure. On ALCHIQ−-closures BSDL compares
only terms with at most one variable, and LPOs are total for such terms. Hence,
literals in ALCHIQ−-closures can be compared as explained in Section 2.

26
U. Hustadt, B. Motik, and U. Sattler
Table 3. Types of ALCHIQ−-closures
1 ¬R(x, y) ∨Inv(R)(y, x)
2 ¬R(x, y) ∨S(x, y)
3 Pf(x) ∨R(x, ⟨f(x)⟩)
4 Pf(x) ∨R([f(x)] , x)
5 P1(x) ∨P2(⟨f(x)⟩) ∨W ⟨fi(x)⟩≈/̸≈⟨fj(x)⟩
6 P1(x) ∨P2([g(x)]) ∨P3(⟨f([g(x)])⟩) ∨W ⟨ti⟩≈/̸≈⟨tj⟩
where ti and tj are either of the form f([g(x)]) or of the form x
7 P1(x) ∨W ¬R(x, yi) ∨P2(y) ∨W yi ≈yj
8 R(⟨a⟩, ⟨b⟩) ∨P(⟨t⟩) ∨W ⟨ti⟩≈/̸≈⟨tj⟩
where t, ti and tj are either some constant b or a functional term fi([a])
Conditions:
(i): In any term f(t), the inner term t occurs marked.
(ii): In all positive equality literals with at least one function symbol,
both sides are marked.
(iii): Any closure containing a term f(t) contains Pf(t) as well.
(iv): In a literal [fi(t)] ≈[fj(t)], role(fi) = role(fj).
(v): In a literal [f(g(x))] ≈x, role(f) = Inv(role(g)).
(vi): For each [fi(a)] ≈[b] a witness closure of the form R(⟨a⟩, ⟨b⟩) ∨D exists,
with role(fi) = R, D does not contain functional terms or negative
binary literals, and is contained in this closure.
Closure of ALCHIQ−-closures under Inferences. The following lemma is central
to our work, since it implies, together with a bound on the number of ALCHIQ−-
closures, termination of BSDL. The proof is by examining all inferences of BSDL
for all possible types of ALCHIQ−-closures.
Lemma 1. Let Ξ(KB) = N0, . . . , Ni ∪{C} be a BSDL-derivation, where C is
the conclusion derived from premises in Ni. Then C is either an ALCHIQ−-
closure or it is redundant in Ni.
Termination and Complexity Analysis. Let |KB| denote the size of KB with
numbers coded in unary. It is straightforward to see that, given a knowledge base
KB, the size of a set of non-redundant ALCHIQ−-closures over the vocabulary
from Ξ(KB) is exponentially bounded in |KB|: let r be the number of role
names, a the number of atomic concept names, c the number of constants, f
the number of Skolem function symbols occurring in Ξ(KB), and v the maximal
number of variables in a closure. Obviously, r, a, and c are linear in |KB| and,
for unary coding of numbers, f and v are also linear in |KB|. Thus we have at
most (f + 1)2(v + c) terms of depth at most 2, which, together with the possible
marking, yields at most t = 2(f + 1)2(v + c) terms in a closure. This yields
at most at + rt2 atoms, which, together with the equality literals, and allowing
each atom to occur negatively, gives at most ℓ= 2(at + (r + 1)t2) literals in
a closure. Each closure can contain an arbitrary subset of these literals, so the
total number of closures is bounded by 2ℓ. Thus we obtain an exponential bound
on the size of the set of closures that BSDL can derive. Each inference step can

A Decomposition Rule for Decision Procedures by Resolution-Based Calculi
27
be carried out in exponential time, so, since BSDL is a sound and complete
refutation procedure [3], we have the following result:
Theorem 1 ([11]). For an ALCHIQ−knowledge base KB, saturating Ξ(KB)
by BSDL with eager application of redundancy elimination rules decides satisﬁa-
bility of KB and runs in time exponential in |KB|, for unary coding of numbers.
3.2
Removing the Restriction to Very Simple Roles
For a SHIQ knowledge base KB containing number restrictions on roles which
are not very simple, the saturation of Ξ(KB) may contain closures whose struc-
ture corresponds to Table 3, but for which conditions (iii) – (vi) do not hold; we
call such closures ALCHIQ-closures. Let KB be the knowledge base containing
axioms (1) – (9):
R ⊑T ⇒¬R(x, y) ∨T(x, y)
(1)
S ⊑T ⇒¬S(x, y) ∨T(x, y)
(2)
C ⊑∃R.⊤⇒¬C(x) ∨R(x, f(x))
(3)
⊤⊑∃S−.⊤⇒S−(x, g(x))
(4)
⊤⊑≤1 T ⇒¬T(x, y1) ∨¬T(x, y2) ∨y1 ≈y2 (5)
∃S.⊤⊑D ⇒¬S(x, y) ∨D(x)
(6)
∃R.⊤⊑¬D ⇒¬R(x, y) ∨¬D(x)
(7)
⊤⊑C ⇒C(x)
(8)
¬S−(x, y) ∨S(y, x)
(9)
S([g(x)] , x)
(10)
¬C(x) ∨T(x, [f(x)])
(11)
T([g(x)] , x)
(12)
¬C([g(x)]) ∨[f(g(x))] ≈x
(13)
¬C([g(x)]) ∨R([g(x)] , x)
(14)
D([g(x)])
(15)
¬D([g(x)]) ∨¬C([g(x)])
(16)
¬C([g(x)])
(17)
□
(18)
Consider a saturation of Ξ(KB) by BSDL producing closures (10) – (13). For
(13), Condition (v) is not satisﬁed: role(f) = R ̸= Inv(role(g)) = Inv(S−) = S.
This is because in (5), a number restriction was stated on a role that is not very
simple. Now (13) can be superposed into (3), resulting in (14), which is obviously
not an ALCHIQ-closure.
If KB were an ALCHIQ−knowledge base, Condition (v) would hold, so we
would be able to assume that a closure R([g(x)] , x) exists. This closure would
subsume (14), so we would simply throw (14) away and continue saturation.
Since Condition (v) does not hold, a subsuming closure does not exist, so
in order not to lose completeness, we must keep (14) and perform further in-
ferences with it. This might cause termination problems: in general, (14) might
be resolved with some closure of type 6 of the form C([g(h(x))]), producing a
closure of the form R([g(h(x))] , [h(x)]). The term depth in the binary literal is
now two, and it may be used to derive closures with ever deeper terms. Thus,
the set of derivable closures becomes inﬁnite, and we cannot conclude that the
saturation necessarily terminates.
A careful analysis reveals that various reﬁnements of the ordering and the
selection function will not help. Furthermore, the inference deriving (14) is nec-
essary. Namely, KB is unsatisﬁable, and the empty closure is derived through
steps (15) – (18), which require (14).

28
U. Hustadt, B. Motik, and U. Sattler
4
Transformation by Decomposition
To solve the problems outlined in Subsection 3.2, we introduce decomposition, a
transformation that can be applied to the conclusions of some BS inferences. It
is a general technique not limited to description logics. In the following, for x a
vector of distinct variables x1, . . . , xn, and t a vector of (not necessarily distinct)
terms t1, . . . , tn, let {x →t} denote the substitution {x1 →t1, . . . , xn →tn},
and let Q([t]) denote Q([t1] , . . . , [tn]).
Deﬁnition 1. Let C · ρ be a closure and N a set of closures. A decomposition
of C · ρ w.r.t. N is a pair of closures C1 · ρ ∨Q([t]) and C2 · θ ∨¬Q(x) where
t is a vector of n terms, x is a vector of n distinct variables, n ≥0, satisfying
these conditions: ( i) C = C1 ∪C2, ( ii) ρ = θ{x →t}, ( iii) x is exactly the
set of free variables of C2θ, and ( iv) if C2 · θ ∨¬Q′(x) ∈N, then Q = Q′,
otherwise Q is a new predicate not occurring in N. The closure C2 · θ is called
the ﬁxed part, the closure C1 ·ρ is called the variable part and the predicate Q is
called the deﬁnition predicate. An application of decomposition is often written
as C · ρ ⇝C1 · ρ ∨Q([t]), C2 · θ ∨¬Q(x).
Let ξ be a BS inference with a most general uniﬁer σ on a literal Lm ·η from
a main premise Dm · η and with a side premise Ds · η. The conclusion of ξ is
eligible for decomposition if, for each ground substitution τ such that ξτ satisﬁes
the constraints of BS, we have ¬Q(t)τ ≺Lmηστ. With BS+ we denote the BS
calculus where decomposition can be applied to conclusions of eligible inferences.
The deﬁnition of eligibility is deﬁned to cover the most general case. In the
following, we use a simpler test: ξ is eligible for decomposition if ¬Q(t) ≺Lmησ,
or a literal L ∈Ds exists such that ¬Q(t) ≺Lησ. The latter is a suﬃcient
approximation, since Lηστ ≺Lmηστ for each τ as in Deﬁnition 1.
E.g., consider superposition from [f(g(x))] ≈[h(g(x))] into C(x)∨R(x, f(x))
resulting in D = C([g(x)]) ∨R([g(x)] , [h(g(x))]). The conclusion is not an
ALCHIQ-closure, so keeping it might lead to non-termination. D can be de-
composed into C([g(x)]) ∨QR,f([g(x)]) and ¬QR,f(x) ∨R(x, [h(x)]), which are
both ALCHIQ-closures. The inference is eligible for decomposition if we ensure
that ¬QR,f(g(x)) ≺R(g(x), h(g(x))) (e.g. by using R >P QR,f in LPO).
The soundness and completeness proofs for BS+ are given in [10]; here we
present the intuition behind these results. As shown by Lemma 2, decomposition
is sound: it merely introduces a new name for C2 · θ. Any model of C · ρ can
be extended to a model of C1 · ρ ∨Q([t]) and C2 · θ ∨¬Q(x) by adjusting the
interpretation of Q.
Lemma 2. Let N0, . . . , Ni be a BS+-derivation, and let I0 be a model of N0.
Then for i > 1, Ni has a model Ii such that, if the inference deriving Ni from
Ni−1 involves a decomposition step as speciﬁed in Deﬁnition 1 introducing a
new predicate Q, then Ii = Ii−1 ∪{Q(s) | s is a vector of ground terms such that
C2θ{x →s} is true in Ii−1}; otherwise Ii = Ii−1.
The notion of variable irreducibility is a central concept in the completeness
proof of basic superposition. Roughly speaking, a closure C · ρτ is a variable

A Decomposition Rule for Decision Procedures by Resolution-Based Calculi
29
irreducible ground instance of C·ρ w.r.t. a ground and convergent rewrite system
R if substitution positions in C·ρτ are not reducible by rewrite rules in R. We use
this to prove completeness, by showing that decomposition is compatible with
the usual notion of redundancy for BS [3,14], as shown by Lemma 3. We do so
in two steps. First, the eligibility criterion ensures that (*) ground instances of
C1 · ρ ∨Q([t]) and C2 · θ ∨¬Q(x) are smaller than the corresponding ground
instances of Dm · η. Second, (**) for each variable irreducible ground instance
C · ρτ of C · ρ, there are variable irreducible ground instances E1 and E2 of
C1 · ρ ∨Q([t]) and C2 · θ ∨¬Q(x), respectively, such that {E1, E2} |= C · ρτ.
Property (**) holds since the terms t are extracted from the substitution part of
C·ρ. Eﬀectively, (**) means that decomposition does not lose “relevant” variable
irreducible ground instances of C·ρ which are used in the proof. Actually, closures
C1 ·ρ∨Q([t]) and C2 ·θ∨¬Q(x) can have “excessive” variable irreducible ground
instances without a counterpart ground instance of C · ρ. However, this is not a
problem, since decomposition is sound.
Lemma 3. Let ξ be a BS inference applied to premises from a closure set N
resulting in a closure C ·ρ. If C ·ρ can be decomposed into closures C1 ·ρ∨Q([t])
and C2 · θ ∨¬Q(x) which are both redundant in N, then the inference ξ is
redundant in N.
Soundness and compatibility with the notion of redundancy imply that BS+
is a sound and complete calculus, as shown by Theorem 2. Note that, to obtain
the saturated set N, we can use any fair saturation strategy [2]. Furthermore, the
decomposition rule can be applied an inﬁnite number of times in a saturation,
and it is even allowed to introduce an inﬁnite number of deﬁnition predicates.
In the latter case, we just need to ensure that the term ordering is well-founded.
Theorem 2. For N0 a set of closures of the form C·{}, let N be a set of closures
obtained by saturating N0 under BS+. Then N0 is satisﬁable if and only if N
does not contain the empty closure.
For a resolution calculus C other than BS, Lemma 2 applies as well. Further-
more, if C is compatible with the standard notion of redundancy [2], Lemma 3
holds as well: (*) holds for C identically, and (**) is needed only for BS, due to a
non-standard lifting strategy. Hence, decomposition can be combined with any
such calculus.
Related Work. In [17] and [6] a similar rule for splitting without backtracking
was considered, and in [18] a similar separation rule was introduced to decide
ﬂuted logic. Decomposition allows replacing complex terms with simpler ones,
so it is diﬀerent from splitting (which does not allow component clauses to con-
tain common variables) or separation (which links component clauses only by
literals without functional terms). Furthermore, by the eligibility criterion we
make decomposition compatible with the standard notion of redundancy. Thus,
decomposition becomes a full-ﬂedged inference rule and can be applied an in-
ﬁnite number of times in a saturation. Finally, combining decomposition with
basic superposition is not trivial, due to a non-standard approach to lifting.

30
U. Hustadt, B. Motik, and U. Sattler
5
Applications of Decomposition
To show the usefulness of decomposition, in this section, we use it to extend the
algorithm from Section 3 to obtain three new decision procedures.
5.1
Deciding ALCHIQ
Deﬁnition 2. BS+
DL is the modiﬁcation of the BSDL calculus where conclusions
are decomposed, whenever possible, as follows, for an arbitrary term t:
D · ρ ∨R([t] , [f(t)]) ⇝
D · ρ ∨QR,f([t])
¬QR,f(x) ∨R(x, [f(x)])
D · ρ ∨R([f(t)] , [t]) ⇝
D · ρ ∨QInv(R),f([t])
¬QInv(R),f(x) ∨R([f(x)] , x)
and where the precedence of the LPO is f >P c >P p >P QS,f >P ⊤, for any
function symbol f, constant symbol c, non-deﬁnition predicate p and deﬁnition
predicate QS,f.
For a (possibly inverse) role S and a function symbol f, the predicate QS,f
is unique. Since R([f(x)] , x) and Inv(R)(x, [f(x)]) are logically equivalent by the
operator π, it is safe to use QInv(R),f as the deﬁnition predicate for R([f(x)] , x).
Inferences of BSDL, when applied to ALCHIQ-closures, derive an ALCHIQ-
closure even if conditions (iii) – (vi) are not enforced. The only exception is the
superposition from a closure of type 5 or 6 into a closure of type 3, but such
closures are decomposed by BS+
DL into two ALCHIQ-closures; the inference
is eligible for decomposition since ¬QR,f(t) ≺R(t, g(t)) (which is the maximal
literal of the closure of type 3 after uniﬁcation). Furthermore, QS,f is unique for a
pair of S and f, so the number of deﬁnition predicates is polynomially bounded.
This allows us to derive an exponential bound on the number of ALCHIQ-
closures as in Theorem 1 and thus to obtain a decision procedure.
Theorem 3. For an ALCHIQ knowledge base KB, saturation of Ξ(KB) by
BS+
DL decides satisﬁability of KB, and runs in time exponential in |KB|.
5.2
Safe Role Expressions
A prominent limitation of ALCHIQ is the rather restricted form of role expres-
sions that may occur in a knowledge base. This can be overcome by allowing for
safe Boolean role expressions in TBox and ABox axioms. The resulting logic is
called ALCHIQb, and can be viewed as the “union” of ALCHIQ and ALCIQb
[20]. Using safe expressions, it is possible to state negative or disjunctive knowl-
edge regarding roles. Roughly speaking, safe role expressions are built using
union, disjunction, and relativized negation of roles. This allows for statements
such as ∀x, y : isParentOf (x, y) →isMotherOf (x, y)∨isFatherOf (x, y), but does
not allow for “fully negated” statements such as: ∀x, y : ¬isMotherOf (x, y) →
isFatherOf (x, y). The safety restriction is needed for the algorithm to remain in
ExpTime; namely, it is known that reasoning with non-safe role expressions is
NExpTime-complete [13].

A Decomposition Rule for Decision Procedures by Resolution-Based Calculi
31
Deﬁnition 3. A role expression is a ﬁnite expression built over the set of roles
using the connectives ⊔, ⊓and ¬ in the usual way. A role expression E is safe if
each conjunction of the disjunctive normal form of E contains at least one non-
negated atom. The description logic ALCHIQb is obtained from ALCHIQ by
allowing concepts ∃E.C, ∀E.C, ≥n E.C and ≤n E.C, inclusion axioms E ⊑F
and ABox axioms E(a, b), where E is a safe role expression, and F is any role
expression. The semantics of ALCHIQb is obtained by extending the operator
π from Table 1 in the obvious way.
We assume w.l.o.g. that all concepts in KB contain only atomic roles, since
one can always replace a role expression with a new atomic role and add a
corresponding role inclusion axiom. Hence, the only diﬀerence to the case of
ALCHIQ logic is that KB contains axioms of the form E ⊑F, where E is
a safe role expression. Such an axiom is equivalent to the ﬁrst-order formula
ϕ = ∀x, y : π(¬E ⊔F). Assume that E is in disjunctive normal form; since it is
safe, ¬E is equivalent to a conjunction of disjuncts, where each disjunct contains
at least one negated atom. Hence, translation of ϕ into ﬁrst-order logic produces
closures of the form Γ = ¬R1(x, y) ∨. . . ∨¬Rn(x, y) ∨S1(x, y) ∨. . . ∨Sm(x, y),
where n ≥1, m ≥0. Computing the disjunctive normal form might introduce an
exponential blow-up, so to compute Ξ(KB) we use structural transformation,
which runs in polynomial time, but also produces only closures of type Γ.
Next, we consider saturation of Ξ(KB) using BS+
DL, and deﬁne ALCHIQb-
closures to be of the form as speciﬁed in Table 3 where closures of type 2 are
replaced with closures of the form Γ above. Since in BS+
DL all negative binary
literals are selected and a closure of type 3 always contains at least one negative
binary literal, it can participate only in a hyperresolution inference with closures
of type 3 or 4. Due to the occurs-check in uniﬁcation, side premises are either
all of type 3 or all of type 4. Hyperresolvents can have two forms, which are
decomposed, whenever possible, as follows, for S(s, t) = S1(s, t) ∨. . . ∨Sm(s, t):
P(x) ∨S(x, [f(x)]) ⇝
¬QSi,f(x) ∨Si(x, [f(x)]) for 1 ≤i ≤m
P(x) ∨QS1,f(x) ∨. . . ∨QSm,f(x)
P(x) ∨S([f(x)] , x) ⇝¬QInv(Si),f(x) ∨Si([f(x)] , x) for 1 ≤i ≤m
P(x) ∨QInv(S1),f(x) ∨. . . ∨QInv(Sm),f(x)
Again, we decompose a non-ALCHIQb-closure into several ALCHIQb-closures.
Hence, we may establish the bound on the size of the closure set as in Subsec-
tion 5.1, to obtain the following result:
Theorem 4. For an ALCHIQb knowledge base KB, saturation of Ξ(KB) by
BS+
DL decides satisﬁability of KB in time exponential in |KB|.
5.3
Conjunctive Queries over SHIQ Knowledge Bases
Conjunctive queries [5] are a standard formalism for relational queries. Here, we
present an algorithm for answering conjunctive queries over a SHIQ knowledge
base KB. To eliminate transitivity axioms, we encode KB into an equisatisﬁable

32
U. Hustadt, B. Motik, and U. Sattler
ALCHIQ knowledge base Ω(KB) [11]. Unfortunately, this transformation does
not preserve entailment of ground non-simple roles. Hence, in the following we
prohibit the use of non-simple roles in conjunctive queries (such roles can still
be used in KB), and focus on ALCHIQ.
Deﬁnition 4. Let KB be an ALCHIQ knowledge base, and let x1, . . . , xn and
y1, . . . , ym be sets of distinguished and non-distinguished variables, written as
x and y, respectively. A conjunctive query over KB, denoted as Q(x, y), is
a conjunction of DL-atoms of the form (¬)A(s) or R(s, t), where s and t are
individuals from KB or distinguished or non-distinguished variables. The basic
inferences for conjunctive queries are:
– Query answering. An answer of a query Q(x, y) w.r.t. KB is an assignment
θ of individuals to distinguished variables, such that π(KB) |= ∃y : Q(xθ, y).
– Query containment. A query Q2(x, y2) is contained in a query Q1(x, y1)
w.r.t. KB if π(KB) |= ∀x : [∃y2 : Q2(x, y2) →∃y1 : Q1(x, y1)].
Query containment is reducible to query answering by well-known transfor-
mations of ﬁrst-order formulae: Q2(x, y1) is contained in Q1(x, y2) w.r.t. KB
if and only if a is an answer to Q1(x, y1) over KB ∪{Q2(a, b)}, where a and
b are vectors of new distinct individuals, not occurring in Q1(x, y1), Q2(x, y2)
and KB. Therefore, in the rest we only consider query answering.
Let KB be an ALCHIQ knowledge base. Obviously, for a conjunctive query
Q(x, y), the assignment θ such that θx = a, is an answer of the query w.r.t. KB
if and only if the set of closures Γ ′ = Ξ(KB)∪{¬Q(a, y)} is unsatisﬁable, where
¬Q(a, y) is the closure obtained by negating each conjunct of Q(a, y).
A conjunctive query Q(a, y) is weakly connected if its literals cannot be de-
composed into two subsets not sharing common variables. W.l.o.g. we assume
that Q(a, y) is weakly connected: if Q(a, y) can be split into n weakly con-
nected mutually variable-disjoint subqueries Q1(a1, y1), . . . , Qn(an, yn), then
π(KB) |= 
1≤i≤n ∃yi : Qi(ai, yi) if and only if π(KB) |= ∃yi : Qi(ai, yi) for
all 1 ≤i ≤n. The subqueries Qi(ai, yi) can be computed in polynomial time, so
this assumption does not increase the complexity of reasoning.
A slight problem arises if ¬Q(a, y) contains unmarked constants: assuming
that ai ∈ai and a′
i ∈a′
i for i ∈{1, 2}, a superposition of a1 ≈a′
1 ∨a2 ≈a′
2 into
¬Q1(a1, y1) and ¬Q2(a2, y2) may produce a closure ¬Q1(a′
1, y1)∨¬Q2(a′
2, y2).
Such an inference produces a conclusion with more variables than each of its
premises, thus leading to non-termination. To prevent this, we apply the struc-
tural transformation to ¬Q(a, y) and replace Γ ′ with Γ, where for each a ∈a,
Oa is a new predicate unique for a, xa is a new variable unique for a, and xa is
the vector of variables obtained from a by replacing each a ∈a with xa:
Γ = Ξ(KB) ∪{¬Q(xa, y) ∨

a∈a
¬Oa(xa)} ∪

a∈a
{Oa(a)}
The sets Γ ′ and Γ are obviously equisatisﬁable. In the rest we write ¬Oa(xa)
for 
a∈a ¬Oa(xa). We now deﬁne the calculus for deciding satisﬁability of Γ:

A Decomposition Rule for Decision Procedures by Resolution-Based Calculi
33
Deﬁnition 5. BS+
CQ is the extension of the BS+
DL calculus, where the selection
function is as follows: if a closure C contains a literal ¬Oa(xa), then all such
literals are selected; otherwise, all negative binary literals are selected. The prece-
dence for LPO is f >P c >P p >P Oa >P QR,f >P pa,b >P ⊤. In addition
to decomposition inferences from Deﬁnition 2, the following decompositions are
performed whenever possible, where the ti are of the form fi,1(. . . fi,m(x) . . .):
(¬)A1([t1]) ∨. . . ∨(¬)An([tn]) ⇝
Q(¬)A1,t1(x) ∨. . . ∨Q(¬)An,tn(x)
¬Q(¬)Ai,ti(x) ∨(¬)Ai([ti]), 1 ≤i ≤n
C · ρ ∨Oa(⟨b⟩)
⇝
C · ρ ∨pa,b
¬pa,b ∨Oa(b)
Deﬁnition 6. The class of CQ-closures w.r.t. a conjunctive query Q(a, y) over
an ALCHIQ knowledge base KB is the generalization of closures from Table 3
obtained as follows:
– Conditions ( iii) – ( vi) are dropped.
– Closure types 5 and 6 are replaced with a new type 5′, which contains all
closures C satisfying each of the following conditions:
1. C contains only equality, unary or propositional literals.
2. C contains only one variable x.
3. The depth of a term in C is bounded by the number of literals of Q(a, y).
4. If C contains a term of the form f(t), then all terms of the same depth in
C are of the form g(t), and all terms of smaller depth are (not necessarily
proper) subterms of t.
5. Only the outmost position of a term in C can be unmarked, i.e. each
functional term is either of the form [f(t)] or of the form f([t]).
6. Equality and inequality literals in C can have the form [f(t)] ◦[g(t)] or
[f(g(t))] ◦[t] for ◦∈{≈, ̸≈}.
– Closure type 8 is modiﬁed to allow unary and (in)equality literals to contain
unary terms whose depth is bounded by the number of literals in Q(a, y); only
outermost positions in a term can be unmarked; all (in)equality literals are
of the form [f(a)]◦[b], [f(t)]◦[g(t)], [f(g(t))]◦[t] or ⟨a⟩◦⟨b⟩, for ◦∈{≈, ̸≈}
and t a ground term; and a closure can contain propositional literals (¬)pa,b.
– A new query closure type contains closures of the form ¬Q([a] , y)∨p, where
Q([a] , y) is weakly connected, it contains at least one binary literal and p is
a possibly empty disjunction of propositional literals p = (¬)pa,b.
– A new initial closure type contains closures of the form ¬Oa(xa)∨¬Q(xa, y).
We show the closure of CQ-closures under BS+
CQ in [10]. Roughly speaking,
since all literals ¬Oa(xa) are selected, the only possible inference for an initial
closure is hyperresolution with ¬pa,b∨Oa(b) or Oa(a), generating a query closure
with marked terms. Propositional symbols pa,b are used to decompose closures
resulting from superposition into Oa(b); since such literals are smallest in any
closure, they cannot participate in inferences with a closure of type 5′.
Consider an inference with a closure ¬Q([a] , y) ∨p such that Q([a] , y) is
weakly connected. Since all constants are marked, superposition into such a

34
U. Hustadt, B. Motik, and U. Sattler
closure is not possible. The only possible inference is hyperresolution with side
premises of type 3, 4 and 8 with a uniﬁer σ. If Q([a] , y) contains a constant
or if some side premise is ground, then Q([a] , y)σ is ground because Q([a] , y)
is weakly connected. Otherwise, since the query closure is weakly connected,
the hyperresolution produces a closure of the form (¬)Ai([ti]) with ti of the
form fi,1(. . . fi,m(x) . . .). This closure does not satisfy condition 4 of CQ-closures,
so it is decomposed into several closures of type 5′; eligibility is ensured since
¬Q(¬)Ai,ti(x) ≺(¬)Ai(ti), and (¬)Ai(ti) originates from some side premise Ejσ.
All side premises contain at most one functional term of depth one, so the depth
of functional terms in the conclusion is bounded by the length of the maximal
path in Q([a] , y), which is bounded by |Q(a, y)|.
To build a term of the form f1(. . . fm(x) . . .), one selects a subset of at most
|Q(a, y)| function symbols; the number of such subsets is exponential in |Q(a, y)|.
This gives an exponential bound on the closure length, and a doubly exponential
bound on the number of CQ-closures, leading to the following result:
Theorem 5. For a conjunctive query Q(a, y) over an ALCHIQ knowledge base
KB, saturation of Γ by BS+
CQ decides satisﬁability of Γ in time doubly exponen-
tial in |KB| + |Q(a, y)|.
Related Work. Answering conjunctive queries over the related description logic
SHf was considered in [19]. In this approach, transitive roles can be used in
the queries, but SHf does not provide inverse roles. Conjunctive queries were
also considered in [4]. To the best of our knowledge, this is the ﬁrst work that
considers answering conjunctive queries over description logic knowledge bases
in the framework of resolution.
6
Conclusion
We have proposed decomposition, a general inference rule applicable to any res-
olution calculus compatible with the standard notion of redundancy. This rule
transforms certain conclusions of the calculus at hand, and thus can be used to
turn a resolution calculus into a decision procedure.
For three decidable fragments of ﬁrst-order logic, we present three decision
procedures obtained by combining basic superposition with decomposition, and
by choosing an appropriate term ordering and selection function. More precisely,
we obtain two new decision procedures for checking satisﬁability of SHIQ and
ALCHIQb knowledge bases, and a procedure for answering conjunctive queries
over SHIQ knowledge bases. The ﬁrst two procedures are worst-case optimal,
and we expect them to be suitable for implementation due to the vast experience
in building saturation theorem provers. An implementation of these algorithms
is under way, and we hope to soon be able to conﬁrm our expectations.
In addition, we plan to extend the algorithm for ALCHIQb to support ar-
bitrary role expressions, and to ﬁnd a way to handle transitivity directly within
our calculus, to avoid the reduction and to allow transitive roles in queries.

A Decomposition Rule for Decision Procedures by Resolution-Based Calculi
35
References
1. F. Baader and T. Nipkow. Term Rewriting and All That. Cambridge University
Press, 1998.
2. L. Bachmair and H. Ganzinger. Resolution Theorem Proving. In A. Robinson and
A. Voronkov, editors, Handbook of Automated Reasoning, pages 19–99. Elsevier
Science, 2001.
3. L. Bachmair, H. Ganzinger, C. Lynch, and W. Snyder.
Basic Paramodulation.
Information and Computation, 121(2):172–192, 1995.
4. D. Calvanese, G. De Giacomo, and M. Lenzerini. On the Decidability of Query
Containment under Constraints. In Proc. PODS 1998, pages 149–158. ACM Press,
1998.
5. A. K. Chandra and P. M. Merlin. Optimal implementation of conjunctive queries
in relational data bases. In Proc. STOC 1977, pages 77–90. ACM Press, 1977.
6. H. de Nivelle. Splitting through new proposition symbols. In Proc. LPAR 2001,
volume 2250 of LNAI, pages 172–185. Springer, 2001.
7. N. Dershowitz and D.A. Plaisted. Rewriting. In A. Robinson and A. Voronkov,
editors, Handbook of Automated Reasoning, pages 535–610. Elsevier Science, 2001.
8. C. Ferm¨uller, A. Leitsch, U. Hustadt, and T. Tammet. Resolution Decision Pro-
cedures. In A. Robinson and A. Voronkov, editors, Handbook of Automated Rea-
soning, pages 1791–1849. Elsevier Science, 2001.
9. I. Horrocks, U. Sattler, and S. Tobies. Practical Reasoning for Very Expressive
Description Logics. Logic Journal of the IGPL, 8(3):239–263, 2000.
10. U. Hustadt, B. Motik, and U. Sattler. Reasoning for Description Logics around
SHIQ in a Resolution Framework. Technical Report 3-8-04/04, FZI, Germany,
2004. http://www.fzi.de/wim/publikationen.php?id=1172.
11. U. Hustadt, B. Motik, and U. Sattler. Reducing SHIQ−Description Logic to
Disjunctive Datalog Programs. In Proc. KR 2004, pages 152–162. AAAI Press,
2004.
12. W. H. Joyner Jr. Resolution Strategies as Decision Procedures. J. ACM, 23(3):398–
417, 1976.
13. C. Lutz and U. Sattler. The Complexity of Reasoning with Boolean Modal Logics.
In Advances in Modal Logics, volume 3. CSLI Publications, Stanford, 2001.
14. R. Nieuwenhuis and A. Rubio.
Theorem Proving with Ordering and Equality
Constrained Clauses. J. Logic and Computation, 19(4):312–351, 1995.
15. R. Nieuwenhuis and A. Rubio.
Paramodulation-Based Theorem Proving.
In
A. Robinson and A. Voronkov, editors, Handbook of Automated Reasoning, pages
371–443. Elsevier Science, 2001.
16. D. A. Plaisted and S. Greenbaum. A Structure-preserving Clause Form Transfor-
mation. J. Symbolic Logic and Computation, 2(3):293–304, 1986.
17. A. Riazanov and A. Voronkov. Splitting Without Backtracking. In Proc. IJCAI
2001, pages 611–617. Morgan Kaufmann, 2001.
18. R. A. Schmidt and U. Hustadt. A Resolution Decision Procedure for Fluted Logic.
In D. McAllester, editor, Proc. CADE 2000, pages 433–448. Springer, 2000.
19. S. Tessaris. Questions and answers: reasoning and querying in Description Logic.
PhD thesis, University of Manchester, UK, 2001.
20. S. Tobies. Complexity Results and Practical Algorithms for Logics in Knowledge
Representation. PhD thesis, RWTH Aachen, Germany, 2001.
21. C. Weidenbach. Combining Superposition, Sorts and Splitting. In A. Robinson
and A. Voronkov, editors, Handbook of Automated Reasoning, pages 1965–2013.
Elsevier Science, 2001.

Abstract DPLL and
Abstract DPLL Modulo Theories
Robert Nieuwenhuis1⋆, Albert Oliveras1⋆, and Cesare Tinelli2⋆⋆
1 Technical University of Catalonia, Barcelona
www.lsi.upc.es/~{roberto|oliveras}
2 Dept. of Computer Science, The University of Iowa, www.cs.uiowa.edu/~tinelli
Abstract. We introduce Abstract DPLL, a general and simple abstract r
ule-based formulation of the Davis-Putnam-Logemann-Loveland (DPLL)
procedure. Its properties, such as soundness, completeness or termina-
tion, immediately carry over to the modern DPLL implementations with
features such as non-chronological backtracking or clause learning. This
allows one to formally reason about practical DPLL algorithms in a
simple way. In the second part of this paper we extend the framework
to Abstract DPLL modulo theories. This allows us to express—and for-
mally reason about—state-of-the-art concrete DPLL-based techniques
for satisﬁability modulo background theories, such as the diﬀerent lazy
approaches, or our DPLL(T) framework.
1
Introduction
Most state-of-the-art SAT solvers [MMZ+01,GN02] today are based on dif-
ferent variations of the Davis-Putnam-Logemann-Loveland (DPLL) procedure
[DP60,DLL62], a procedure for deciding the satisﬁability of propositional for-
mulas in conjunctive normal form.
Starting essentially with the pioneering work on the GRASP [MSS99] and
SATO [Zha97] systems, the spectacular improvements in the performance of
DPLL-based SAT solvers achieved in the last years are due to i) better imple-
mentation techniques, such as, e.g., the 2-watched literal approach for unit propa-
gation, and ii) several conceptual enhancements on the original DPLL procedure
aimed at reducing the amount of explored search space such as non-chronological
backtracking, conﬂict-driven lemma learning, and restarts.
Because of their success, both the DPLL procedure and its enhancements
have been recently adapted to satisﬁability problems in more expressive logics
than propositional logic. In particular, they have been used to build eﬃcient
solvers for the satisﬁability of (certain classes of) ground ﬁrst-order formulas with
respect to theories such as the theory of equality, of the integer/real numbers,
or of arrays [ACG00,ABC+02,BDS02,dMR02,FJOS03,GHN+04].
⋆Partially supported by Spanish Min. of Educ. and Science by the LogicTools project
(TIN2004-03382, both these authors), and FPU grant AP2002-3533 (Oliveras).
⋆⋆Partially supported by Grant No. 237422 from the National Science Foundation.
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 36–50, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

Abstract DPLL and Abstract DPLL Modulo Theories
37
Altogether, it has become non-trivial to reason formally about the properties
of such enhanced DPLL procedures and their extensions to satisﬁability modulo
theories (SMT). However, so far there have been no attempts to do so in the
literature, to our knowledge at least, except for a work by Tinelli [Tin02] (one
of these authors). That work describes DPLL and DPLL modulo theories at
an abstract, formal level by means of a sequent-style logical calculus. This cal-
culus consists of a few deterministic derivation rules, modelling the constraint
propagation mechanism of the DPLL procedure, and one branching rule, mod-
elling the non-deterministic guessing step of DPLL. Because of the branching
rule the calculus produces derivation trees. As a consequence, it can explictly
model neither backtracking (chronological or not) nor lemma learning—they are
metalogical features for the calculus. Also, the calculus implicitly assumes the
procedure to keep track of the current truth values of all clauses, which is not
the case in practical implementations.
In this paper we address these limitations of Tinelli’s calculus by modelling
the DPLL procedure and its SMT extensions as transitions systems. While still
as declarative in nature as the calculus in [Tin02], our transition systems can
explicitly model various features of state-of-the-art DPLL-based solvers, thus
bridging the gap between abstract calculi for DPLL and actual implementations.
In Section 2, using transition systems deﬁned by means of conditional tran-
sition rules, we introduce general and simple abstract formulations of several
variants of propositional DPLL, and discuss their soundness, completeness, and
termination. These properties immediately carry over to modern DPLL imple-
mentations with features such as non-chronological backtracking and learning. In
fact, we also explain and formalize what is done by the diﬀerent implementations.
For example, we explain how diﬀerent systems implement our backjumping rule,
how devices such as implication graphs are just one possibility for computing
new lemmas, and how standard backtracking is a special case of the backjumping
rule.
We also provide a general and simple termination argument for DPLL pro-
cedures that does not depend on an exhaustive enumeration of all truth assign-
ments; instead, it cleanly expresses that a search state becomes more advanced if
an additional unit is deduced, the higher up in the search tree the better—which
is the very essence of the idea of backjumping.
Our transition systems allow one to formally reason about practical DPLL
implementations in a simple way, which to our knowledge had not been done
before. In Section 3 we extend the framework to Abstract DPLL modulo theories.
This allows us to express—and formally reason about—most state-of-the-art
DPLL-based techniques for satisﬁability modulo background theories, such as
various so-called lazy approaches [ACG00,ABC+02,BDS02,dMR02,FJOS03] and
our own DPLL(T) framework [GHN+04].

38
R. Nieuwenhuis, A. Oliveras, and C. Tinelli
2
The Abstract DPLL Procedure
The DPLL procedure works by trying to build incrementally a satisfying truth
assignment for a given propositional formula F in conjunctive normal form. At
each step, the current assignment M for F is augmented either by a process of
boolean constraint propagation, which deduces deterministically from M and F
the truth value of additional variables of F, or by a non-deterministic guess, or
decision, on the truth value of one of the remaining undeﬁned variables.
Modern implementations of DPLL use eﬃcient constraint propagation algo-
rithms, and sophisticated backtracking mechanisms for recovering from wrong
decisions. We provide here a general abstract framework for describing both
constraint propagation and backtracking in DPLL-based systems.
In this section we deal with propositional logic. Atoms are propositional
symbols from a ﬁnite set P. If p ∈P, then p is a positive literal and ¬p is a
negative literal. The negation of a literal l, written ¬l, denotes ¬p if l is p, and
p if l is ¬p. A clause is a set of literals and a cnf (formula) is a set of clauses.
A (partial truth) assignment M is a set of literals such that {p, ¬p} ⊆M for no
p. A literal l is true in M if l ∈M, is false in M if ¬l ∈M, and is undeﬁned
otherwise. M is total if no literal of P is undeﬁned in M. A clause C is true in
M if C ∩M ̸= ∅, is false in M, denoted M |= ¬C, if all its literals are false in M,
and is undeﬁned otherwise. A cnf F is true in M (or satisﬁed by M), denoted
M |= F, if all its clauses are true in M. In that case, M is called a model of F.
If F has no models then it is unsatisﬁable. We write F |= C (F |= F ′) if the
clause C (cnf F ′) is true in all models of F. If F |= F ′ and F ′ |= F, we say that
F and F ′ are logically equivalent. We denote by C ∨l the clause D such that
l ∈D and C = D \ {l}.
2.1
The Basic DPLL Procedure
Here, a DPLL procedure will be modeled by a transition system: a set of states
together with a relation, called the transition relation, over these states. States
will be denoted by (possibly subscripted) S. We write S =⇒S′ to mean that
the pair (S, S′) is in the transition relation, and then say that S′ is reachable
from S in one transition step. We denote by =⇒∗the reﬂexive-transitive closure
of =⇒. We write S =⇒! S′ if S =⇒∗S′ and S′ is a ﬁnal state, i.e., if S′ =⇒S′′
for no S′′.
A state is either fail or a pair M || F, where F is a ﬁnite set of clauses and
M is a sequence of annotated literals. We will denote the empty sequence of
literals by ∅, unit sequences by their only literal, and the concatenation of two
sequences by simple juxtaposition. We will not go into a complete formalization
of annotated literals; it suﬃces to know that some literals l will be annotated
as being decision literals; this fact will be denoted here by writing ld (roughly,
decision literals are the ones that have been added to M by the Decide rule given
below). Most of the time the sequence M will be simply seen as a set of literals,
denoting an assignment, i.e., ignoring both the annotations and the fact that M
is a sequence and not a set.

Abstract DPLL and Abstract DPLL Modulo Theories
39
In what follows, the transition relation will be deﬁned by means of (condi-
tional) transition rules. If F is a cnf formula and C is a clause, we will sometimes
write F, C in the second component of a state as a shorthand for F ∪{C}.
Deﬁnition 1. The Basic DPLL system consists of the following transition rules:
UnitPropagate :
M || F, C ∨l =⇒M l || F, C ∨l if

M |= ¬C
l is undeﬁned in M
Decide :
M || F
=⇒M ld || F
if
 l or ¬l occurs in a clause of F
l is undeﬁned in M
Fail :
M || F, C
=⇒fail
if

M |= ¬C
M contains no decision literals
Backjump :
M ld N || F
=⇒M l′ || F
if







there is some clause C ∨l′ s.t.:
F |= C ∨l′ and M |= ¬C
l′ is undeﬁned in M
l′ or ¬l′ occurs in a clause of F
Below we will show that the transition relation terminates when starting from
∅|| F, that is, there exist no inﬁnite sequences of the form ∅|| F =⇒S1 =⇒. . . ,
and we will deﬁne a Basic DPLL procedure to be any procedure taking an input
cnf F and computing a sequence ∅|| F =⇒! S.
Of course, actual DPLL implementations may use the above rules in more
restrictive ways, using particular application strategies. For example, many sys-
tems will eagerly apply UnitPropagate, but this is not necessary; in fact, below we
will show that any strategy is adequate: the ﬁnal state produced by the strategy
will be either fail, when F is unsatisﬁable, or else a state of the form M || F ′
where M is a model of F. This result holds even if UnitPropagate is not applied
at all. Similarly, most implementations will try to minimize the number of ap-
plications of Decide. Others may apply it only with literals l belonging to some
clause that is not yet true in M (in that case the procedure can also terminate
if M is a non-total model).
Example 2. In the following sequence of transitions, to improve readability we
have denoted atoms by natural numbers, negation by overlining, and written
decision literals in bold:
∅|| 1∨3, 1∨4∨5∨2, 1∨2
=⇒
(Decide)
3 || 1∨3, 1∨4∨5∨2, 1∨2
=⇒
(UnitPropagate)
3 1 || 1∨3, 1∨4∨5∨2, 1∨2
=⇒
(UnitPropagate)
3 1 2 || 1∨3, 1∨4∨5∨2, 1∨2
=⇒
(Decide)
3 1 2 4 || 1∨3, 1∨4∨5∨2, 1∨2
=⇒
(UnitPropagate)
3 1 2 4 5 || 1∨3, 1∨4∨5∨2, 1∨2
Final state: model found.
⊓⊔

40
R. Nieuwenhuis, A. Oliveras, and C. Tinelli
Concerning the rules Fail and Backjump, we will show below that if in some
state M || F there is a conﬂict, i.e., a clause of F that is false in M, it is
always the case that either Fail applies (if there are no decision literals in M)
or Backjump applies (if there is at least one decision literal in M). In fact, in
most implementations Backjump is only applied when such a conﬂict arises, this
is why it is usually called conﬂict-driven backjumping. Note that M can be seen
as a sequence M0 l1 M1 . . . lk Mk, where the li are all the decision literals in M.
As in actual DPLL implementations, such a state is said to be in decision level
k, and the literals of each li Mi are said to belong to decision level i.
Example 3. Another example of application of the Basic DPLL rules is:
∅|| 1∨2, 3∨4, 5∨6, 6∨5∨2
=⇒
(Decide)
1 || 1∨2, 3∨4, 5∨6, 6∨5∨2
=⇒
(UnitPropagate)
1 2 || 1∨2, 3∨4, 5∨6, 6∨5∨2
=⇒
(Decide)
1 2 3 || 1∨2, 3∨4, 5∨6, 6∨5∨2
=⇒
(UnitPropagate)
1 2 3 4 || 1∨2, 3∨4, 5∨6, 6∨5∨2
=⇒
(Decide)
1 2 3 4 5 || 1∨2, 3∨4, 5∨6, 6∨5∨2
=⇒
(UnitPropagate)
1 2 3 4 5 6 || 1∨2, 3∨4, 5∨6, 6∨5∨2
=⇒
(Backjump)
1 2 5 || 1∨2, 3∨4, 5∨6, 6∨5∨2
Indeed, before the application of Backjump there was a conﬂict: the clause 6∨5∨2
is false in 1 2 3 4 5 6. We have backjumped from decision level 3 to decision
level 1, whereas standard backtracking would reverse only the last decision, and
return to 1 2 3 4 5 (decision level 2). The Backjump rule applies here because
we can take 1∨5 playing the role of the backjump clause C ∨l′ in the deﬁnition
of the rule. In fact, one can always take a disjunction of negated decision literals
for this (see the proof of Lemma 6). But in practice one can usually ﬁnd better
backjump clauses by conﬂict analysis, that is, by analyzing the so called conﬂict
graph (see, e.g., [MSS99] for details).
⊓⊔
The Backjump rule makes progress in the search by returning to a strictly
lower decision level, but with the additional information given by the literal l′
that is added to it. In most DPLL implementations the backjump clause C ∨l′
is added to the clause set as a learned clause (conﬂict-driven clause learning).
However, in this Basic system the second component of each state (the clause
set) remains unchanged; this will change in Subsection 2.3 when the learning rule
is added. In fact, for some readers it may be surprising that backjumping can be
done without clause learning. Such a distinction gives the system more ﬂexibility,
allowing it to model, for example, the original DPLL procedure [DLL62].
2.2
Correctness of Basic DPLL
In what follows, (possibly subscripted) F and M will always denote ﬁnite clause
sets and annotated literal sequences, respectively.

Abstract DPLL and Abstract DPLL Modulo Theories
41
Lemma 4. If ∅|| F =⇒∗M || F then the following hold.
1. All the atoms in M are atoms of F.
2. M contains no literal more than once and is indeed an assignment, i.e., it
contains no pair of literals of the form p and ¬p.
3. If M is of the form M0 l1 M1 . . . ln Mn, where l1, . . . , ln are all the decision
literals of M, then F ∪{l1, . . . , li} |= Mi for all i in 0 . . . n.
Theorem 5 (Termination). There exist no inﬁnite sequences of the form
∅|| F =⇒S1 =⇒. . .
Proof. We deﬁne a well-founded strict partial ordering ≻on states, and show
that each rule application M || F =⇒M ′ || F ′ is decreasing with respect to this
ordering, i.e., M || F ≻M ′ || F ′.
Let M be of the form M0 l1 M1 . . . lp Mp, where l1, . . . , lp are all the decision
literals of M. Similarly, let M ′ be M ′
0 l′
1 M ′
1 . . . l′
p′ M ′
p′.
Let N be the number of distinct atoms (propositional variables) in F. It is not
diﬃcult to show that p, p′ and the length of M and M ′ are always smaller than
or equal to N. Deﬁne m(M) to be N −length(M), that is, m(M) is the number
of literals “missing” in M for M to be total. Now deﬁne: M || F ≻M ′ || F ′ if
(i) there is some i with 0 ≤i ≤p, p′ such that
m(M0) = m(M ′
0),
. . .
m(Mi−1) = m(M ′
i−1),
m(Mi) > m(M ′
i) or
(ii) m(M0) = m(M ′
0),
. . .
m(Mp) = m(M ′
p)
and
m(M) > m(M ′).
Comparing the number of missing literals in sequences is clearly a strict ordering
(i.e., it is an irreﬂexive and transitive relation) and it is also well-founded, and
hence this also holds for its lexicographic extension on tuples of sequences of
bounded length. It is easy to see that all Basic DPLL rule applications are
decreasing with respect to ≻if fail is added as an additional minimal element.
The rules UnitPropagate and Backjump decrease by case (i) of the deﬁnition and
Decide decreases by case (ii).
⊓⊔
In the previous termination proof one can observe that DPLL search pro-
gresses (that is, it makes progress w.r.t. ≻) by adding a literal to the current
decision level (by UnitPropagate), by adding an additional decision level (Decide)
or, which is especially interesting, by what the Backjump rule does, i.e., adding
an additional literal to a previous decision level, even if all the work done in later
decision levels is “thrown away”.
Note that it is not trivial to check whether a state is ﬁnal, because of the
Backjump rule. But in practice Backjump is applied only if there is a conﬂict.
If in a state M || F there is no conﬂict, and UnitPropagate and Decide are not
applicable either (i.e., there are no undeﬁned literals in M), then one can of
course stop because M is a model of F.
Lemma 6. Assume that ∅|| F =⇒∗M || F and that M |= ¬D for some clause
D in F. Then either Fail or Backjump applies to M || F.

42
R. Nieuwenhuis, A. Oliveras, and C. Tinelli
Proof. If there is no decision literal in M, it is immediate that Fail applies.
Otherwise, M is of the form M0 l1 M1 . . . ln Mn for some n > 0, where
l1, . . . , ln are all the decision literals of M. Since M |= ¬D, we have, due to
Lemma 4-3, that F ∪{l1, . . . , ln} |= ¬D. Now consider any i in 1 . . . n such that
F ∪{l1, . . . , li} |= ¬D, and j in 0 . . . i−1 such that F ∪{l1, . . . , lj, li} |= ¬D. We
will show that then backjumping to decision level j is possible.
Let C be the clause ¬l1∨. . .∨¬lj, and note that M is of the form M ′ lj+1 N.
Then Backjump applies to M || F as: M ′ lj+1 N || F =⇒M ′ ¬li || F because
for the clause C ∨¬li all three conditions of the Backjump rule hold. In fact:
(i) F |= C ∨¬li because F ∪{l1, . . . , lj, li} |= ¬D implies, being D a clause
in F, that F |= ¬l1 ∨. . . ∨¬lj ∨¬li. We also obviously have that M ′ |= ¬C.
(ii) ¬li is undeﬁned in M ′ (by Lemma 4-2) and
(iii) either li or ¬li occurs in a clause of F (by Lemma 4-1).
⊓⊔
It is interesting to observe that the smaller the j in the previous proof the
better, because one can backjump “higher up”. Note also that, if we take i to
be n and j to be n −1, the Backjump rule models standard backtracking.
Lemma 7. If ∅|| F =⇒! M || F, then M |= F.
Deﬁnition 8. A Basic DPLL procedure is any procedure taking an input cnf F
and computing a sequence ∅|| F =⇒! S.
Now, we can prove that our Basic DPLL system, and hence any Basic DPLL
procedure, provides a decision procedure for the satisﬁability of cnf formulas.
Theorem 9. The Basic DPLL system provides a decision procedure for the sat-
isﬁability of cnf formulas F, that is:
1. ∅|| F =⇒! fail if, and only if, F is unsatisﬁable.
2. ∅|| F =⇒! M || F if, and only if, F is satisﬁable.
3. If ∅|| F =⇒! M || F then M is a model of F.
Proof. For the left-to-right implication of property 1: if ∅|| F =⇒! fail then
there is some state M || F such that ∅|| F =⇒∗M || F =⇒fail, there is no
decision literal in M and M |= ¬C for some clause C in F. By the case i = 0
of Lemma 4-3 we have that F |= M, and so F |= ¬C. However, since C is a
clause in F it follows that F is unsatisﬁable. For the right-to-left implication of
property 1, if ∅|| F ̸=⇒! fail, then by Theorem 5 there must be a state M || F
such that ∅|| F =⇒! M || F. Then F is satisﬁable by Lemma 7.
For property 2, if ∅|| F =⇒! M || F then F is satisﬁable by Lemma 7.
Conversely, if ∅|| F ̸=⇒! M || F, then by Theorem 5 again, ∅|| F =⇒! fail and
hence F is unsatisﬁable by property 1. Property 3 is again Lemma 7.
⊓⊔
The previous theorem does not just prove the desirable properties for a con-
crete DPLL procedure; rather, it proves the correctness of any procedure ap-
plying these steps, with any strategy. For example, the designer of a practical

Abstract DPLL and Abstract DPLL Modulo Theories
43
DPLL implementation is free to choose her own heuristic for selecting the next
decision literal in Decide, or choose the priorities between the diﬀerent rules.
Note that we may have ∅|| F =⇒! M || F and also ∅|| F =⇒! M ′ || F, for
diﬀerent M and M ′.3 Then, the formula F is satisﬁable and both M and M ′
are models of F.
2.3
DPLL with Clause Learning
Deﬁnition 10. The DPLL system with learning consists of the four transition
rules of the Basic DPLL system, plus the following two additional rules:
Learn :
M || F
=⇒M || F, C if

all atoms of C occur in F
F |= C
Forget :
M || F, C =⇒M || F
if

F |= C
In these two rules, the clause C is said to be learned and forgotten, respectively.
In the following, we denote by =⇒L the transition relation deﬁned by the DPLL
system with learning.
Example 11. (Example 3 continued). When applying Backjump, many actual
DPLL implementations learn the backjump clause:
. . .
. . .
1 2 3 4 || 1∨2, 3∨4, 5∨6, 6∨5∨2
=⇒L
(Decide)
1 2 3 4 5 || 1∨2, 3∨4, 5∨6, 6∨5∨2
=⇒L
(UnitPropagate)
1 2 3 4 5 6 || 1∨2, 3∨4, 5∨6, 6∨5∨2
=⇒L
(Backjump)
1 2 5 || 1∨2, 3∨4, 5∨6, 6∨5∨2
=⇒L
(Learn)
1 2 5 || 1∨2, 3∨4, 5∨6, 6∨5∨2, 1∨5
When backjumping to decision level j, the backjump clause C∨l′ (in the example
1∨5) is always such that, if it had existed the last time the procedure was at
level j, the literal l′ could have been added by UnitPropagate. Learning such
clauses hence avoids repeated work by preventing decisions such as 5, if, after
more backjumping, one reaches again a state similar to this decision level j
(where “similar” roughly means that it could produce the same conﬂict). Indeed,
reaching such similar states frequently happens in industrial problems having
some regular structure. The use of Forget is to free memory by removing a clause
C, once a search region presenting such similar states has been abandoned. In
practice this is usually done if the activity of C (i.e., the number of times C
causes some conﬂict or some unit propagation) has become low [MMZ+01].
⊓⊔
The results given in the previous subsection for Basic DPLL smoothly extend
to DPLL with learning, and again the starting point is the following.
3 Conﬂuence, in the sense of, e.g., rewrite systems is not needed here.

44
R. Nieuwenhuis, A. Oliveras, and C. Tinelli
Lemma 12. If ∅|| F =⇒∗
L M || F ′ then the following hold.
1. All the atoms in M and all the atoms in F ′ are atoms of F.
2. M contains no literal more than once and is indeed an assignment, i.e., it
contains no pair of literals of the form p and ¬p.
3. F ′ is logically equivalent to F.
4. If M is of the form M0 l1 M1 . . . ln Mn, where l1, . . . , ln are all the decision
literals of M, then F ∪{l1, . . . , li} |= Mi for all i = 0 . . . n.
Proof. It is easy to see that property 3 holds. Using this fact, the other properties
can be proven similarly to the proof of Lemma 4.
Theorem 13 (Termination of =⇒L). There exist no inﬁnite sequences of the
form ∅|| F =⇒L S1 =⇒L . . . if no clause C is learned inﬁnitely many times
along a sequence.
Proof. The ordering used in Theorem 5 can also be applied here, since, by
Lemma 12, atoms appearing in any state are atoms of F. Therefore an inﬁ-
nite sequence of the form ∅|| F =⇒L S1 =⇒L . . . cannot contain any inﬁnite
subsequence of contiguous =⇒steps, and must hence contain inﬁnitely many
Learn or Forget steps, which is not possible since there are only ﬁnitely many
diﬀerent clauses with atoms in F, and no clause C is learned inﬁnitely many
times along the sequence.
⊓⊔
Note that the condition that no clause C is learned inﬁnitely many times is in
fact a necessary and suﬃcient condition for termination. This condition is easily
enforced by applying at least one rule of the Basic DPLL system between two
successive applications of Learn. Since states do not increase with respect to the
ordering used in Theorem 5 when Learn is applied, any strict alternation between
Learn and Basic DPLL rules must be ﬁnite as well. As with the basic DPLL
system, we have the following deﬁnition and theorem (with identical proof).
Deﬁnition 14. A DPLL procedure with learning is any procedure taking an
input cnf F and computing a sequence ∅|| F =⇒∗
L S where S is a ﬁnal state with
respect to the Basic DPLL system.
Theorem 15. The DPLL system with learning provides a decision procedure
for the satisﬁability of cnf formulas F, that is:
1. ∅|| F =⇒!
L fail if, and only if, F is unsatisﬁable.
2. ∅|| F =⇒∗
L M || F ′, where M || F ′ is a ﬁnal state with respect to the Basic
DPLL system, if, and only if, F is satisﬁable.
3. If ∅|| F =⇒∗
L M || F ′, where M || F ′ is a ﬁnal state with respect to the Basic
DPLL system, then M is a model of F.

Abstract DPLL and Abstract DPLL Modulo Theories
45
3
Abstract DPLL Modulo Theories
This section deals with procedures for Satisﬁability Modulo Theories (SMT),
that is, procedures for deciding the satisﬁability of ground4 cnf formulas in the
context of a background theory T. Typical theories considered in this context
are EUF (equality with uninterpreted function symbols), linear arithmetic (over
the integers and over the reals), some theories of arrays and of other data struc-
tures such as lists, ﬁnite sets, and so on. For each of these theories there exist
eﬃcient procedures (in practice) that decide the satisﬁability, in the theory, of
conjunctions of ground literals. To decide eﬃciently the satisﬁability of ground
cnf formulas, many people have recently worked on combining these decision
procedures with DPLL based SAT engines. In this section we show that many
of the existing combinations can be described and discussed within the Abstract
DPLL framework.
In the rest of the paper we consider ﬁrst-order logic without equality—of
which the purely propositional case we have seen until now is a particular
instance. We adopt the standard notions of ﬁrst-order structure, satisfaction,
entailment, etc., extended with the following. A theory is a satisﬁable set of
closed ﬁrst-order formulas. A formula F is (un)satisﬁable in a theory T, or T-
(in)consistent, if there is a (no) model of T that satisﬁes F, that is, if T ∪F is
(un)satisﬁable. If F and G are formulas, F entails G in T, written F |=T G, if
T |= ¬F ∨G. If F |=T G and G |=T F, we say that F and G are T-equivalent.
We extend the notion of (partial truth) assignment M from Section 2 to a set
of ground ﬁrst-order literals in the obvious way. We say that M is a T-model of
a ground formula F if M, seen as the conjuction of its literals, is T-consistent
and M |=T F.
In the following we will use T to denote a background theory T such that
the satisﬁability in T of conjunctions of ground literals is decidable. To decide
the satisﬁability of ground cnf formulas we consider again the DPLL systems
introduced in the previous section—with arbitrary ground atoms now used in
place of propositional symbols—and add new rules for dealing with T. However,
in the side conditions of the rules presented in the previous section, entailment
between formulas is now replaced by entailment in T between formulas. That is,
the condition F |= C in Learn and Forget is now F |=T C, the Backjump rule is
M ld N || F =⇒M l′ || F if







there is some clause C ∨l′ s.t.:
F |=T C ∨l′ and M |= ¬C
l′ is undeﬁned in M
l′ or ¬l′ occurs in a clause of F
and Decide, Fail and UnitPropagate remain unchanged. We point out that the
rules of the previous section can now be seen as a particular instance of the new
ones if we consider T to be the empty theory.
4 By ground we mean containing no variables—although possibly containing constants
not in T.

46
R. Nieuwenhuis, A. Oliveras, and C. Tinelli
3.1
A Simple Example: The Classical Very Lazy Approach
One way for dealing with SMT is what has been called the lazy approach
[dMR02,ABC+02,BDS02,FJOS03]. This approach initially considers each atom
occurring in a formula F to be checked for satisﬁability simply as a proposi-
tional symbol, and sends the formula to a SAT solver. If the SAT solver returns
a propositional model of F that is T-inconsistent, a ground clause, a lemma,
precluding that model is added to F and the SAT solver is started again. This
process is repeated until the SAT solver ﬁnds a T-consistent model or returns
unsatisﬁable. The main advantage of such a lazy approach is its ﬂexibility, since
it can easily combine any SAT solver with any decision procedure for conjunc-
tions of theory literals, as long as the decision procedure is able to generate such
lemmas.
The addition of these lemmas can be modelled by the following rule, which
we will call Very Lazy Theory Learning:
M l M1 || F =⇒∅|| F, ¬l1∨. . .∨¬ln∨¬l if



M l M1 |= F
{l1, . . . , ln} ⊆M
l1 ∧. . . ∧ln |=T ¬l
Combining this rule with the four Basic DPLL rules, or with the six rules
of DPLL with learning, the resulting Very Lazy DPLL system terminates if
no clause is learned inﬁnitely many times, since only ﬁnitely many such new
clauses (built over input literals) exist. For this condition to be fulﬁlled, ap-
plying at least one rule of the Basic DPLL system between any two Learn ap-
plications does not suﬃce. It suﬃces if, in addition, no clause generated with
Very Lazy Theory Learning is ever forgotten. The system is also easily proved cor-
rect as it is done in the following subsection, by observing that M, seen as the
conjunction of its literals, is T-consistent for every state M || F that is ﬁnal with
respect to Basic DPLL and Very Lazy Theory Learning. However, in what follows
we will focus on other more interesting—and in practice better—lazy techniques,
based on tighter integrations between DPLL and theory solvers.
3.2
Less Lazy Approaches
It is clear that, as soon as a DPLL procedure reaches a state M || F with a
(possibly non-total) T-inconsistent M, the corresponding lemma can already be
added. Furthermore, it is also not necessary to restart from scratch once the
lemma has been added. These ideas can be modelled by the following rule.
Deﬁnition 16. The Lazy Theory Learning rule is the following:
M l M1 || F =⇒M l M1 || F, ¬l1∨. . .∨¬ln∨¬l if



{l1, . . . , ln} ⊆M
l1 ∧. . . ∧ln |=T ¬l
¬l1∨. . .∨¬ln∨¬l /∈F
The Lazy Theory DPLL system consists of this rule and the six rules of DPLL
with learning. In the following, we denote by =⇒LT the transition relation deﬁned
by the Lazy Theory DPLL system.

Abstract DPLL and Abstract DPLL Modulo Theories
47
Note that the lemma ¬l1 ∨. . . ∨¬ln ∨¬l added by an application of the
Lazy Theory Learning rule is, by construction, always false in M l, making ei-
ther Fail or Backjump applicable to the resulting state. In practice, one of these
two rules is always applied immediately after Lazy Theory Learning. This makes
the third test in the rule—introduced here to ensure termination—unnecessary.
This DPLL system is still called lazy because it does not consider any theory
information until a T-inconsistent partial interpretation M l has been reached.
As we will see, this is the essential diﬀerence between these lazy approaches and
the DPLL(T) approach that is described in Subsection 3.3 below.
All the results below are proved as in the previous section. However, the
following key lemma is needed to show that for any state of the form M || F that
is ﬁnal with respect to Basic DPLL and Lazy Theory Learning, M is T-consistent
and M |=T F.
Lemma 17. Let ∅|| F0 =⇒∗
LT M || F. If M is T-inconsistent then the rule
Lazy Theory Learning applies to M || F.
Theorem 18 (Termination of =⇒LT ). There exists no inﬁnite sequence of
the form ∅|| F =⇒LT S1 =⇒LT . . . if no clause C is learned by Learn or
Lazy Theory Learning inﬁnitely many times along a sequence.
Deﬁnition 19. A Lazy Theory DPLL procedure for T is any procedure taking
an input cnf F and computing a sequence ∅|| F =⇒∗
LT S where S is a ﬁnal state
with respect to the Basic DPLL system and Lazy Theory Learning.
Theorem 20. The Lazy Theory DPLL system provides a decision procedure for
the satisﬁability in T of cnf formulas F, that is:
1. ∅|| F =⇒!
LT fail if, and only if, F is unsatisﬁable in T.
2. ∅|| F =⇒∗
LT M || F ′, where M || F ′ is a ﬁnal state wrt the Basic DPLL
system and Lazy Theory Learning, if, and only if, F is satisﬁable in T.
3. If ∅|| F =⇒∗
LT M || F ′, where M || F ′ is a ﬁnal state wrt the Basic DPLL
system and Lazy Theory Learning, then M is a T-model of F.
Systems such as CVC Lite [BB04] are concrete implementations of Lazy
Theory DPLL. Usually, in such implementations the Lazy Theory Learning rule
is applied eagerly, that is, with an empty M1, as soon as the current partial in-
terpretation becomes T-inconsistent. Therefore, the soundness and completeness
of the approach followed by CVC Lite is a particular instance of the previous
theorem.
3.3
The DPLL(T) Approach with Eager Theory Propagation
The Lazy Theory DPLL systems we have seen are lazy in the sense that they use
theory information only after a theory-inconsistent partial assignment has been
generated. In this subsection we describe the DPLL(T) approach [GHN+04] with

48
R. Nieuwenhuis, A. Oliveras, and C. Tinelli
eager theory propagation, which allows the use of theory information as soon as
possible. This new information reduces the search space by discovering the truth
value of literals otherwise considered to be unassigned. Moreover, it does this
without sacriﬁcing modularity or ﬂexibility: combining arbitrary theory decision
procedures for conjunctions of literals with a DPLL system is as simple as for
the lazy approaches such as that of CVC Lite. The key idea behind DPLL(T) is
the following rule:
Deﬁnition 21. The Theory Propagate rule is the following:
M || F =⇒M l || F if



M |=T l
l or ¬l occurs in a clause of F
l is undeﬁned in M
The DPLL(T) system with eager theory propagation consists of this rule and
the six rules of DPLL with learning. We denote by =⇒Edpll(T) the transition
relation deﬁned by the DPLL(T) system with eager theory propagation where
Theory Propagate has priority over all the other rules.
All results as in the previous sections apply here, including termination under
the usual assumption (since Theory Propagate also decreases with respect to the
ordering ≻used in Theorem 5). The only additional ingredient needed is the
following lemma.
Lemma 22. If ∅|| F0 =⇒∗
Edpll(T) M || F then M is T-consistent.
Proof. This property is true initially, and all rules preserve it, by the fact that
M |=T l if, and only if, M ∪{¬l} is T-inconsistent: the rules only add literals to
M that are undeﬁned in M, and Theory Propagate adds all literals l of F that
are theory consequences of M, before any literal ¬l making it T-inconsistent can
be added to M by any of the other rules.
⊓⊔
Deﬁnition 23. A DPLL(T) procedure with Eager Theory Propagation for T is
any procedure taking an input cnf F and computing a sequence ∅|| F =⇒∗
Edpll(T)
S where S is a ﬁnal state wrt Theory Propagate and the Basic DPLL system.
Theorem 24. The DPLL system with eager theory propagation provides a de-
cision procedure for the satisﬁability in T of cnf formulas F, that is:
1. ∅|| F =⇒!
Edpll(T) fail if, and only if, F is unsatisﬁable in T.
2. ∅|| F =⇒∗
Edpll(T) M || F ′, where M || F ′ is a ﬁnal state wrt the Basic DPLL
system and Theory Propagate, if, and only if, F is satisﬁable in T.
3. If ∅|| F =⇒∗
Edpll(T) M || F ′, where M || F ′ is a ﬁnal state wrt the Basic
DPLL system and Theory Propagate, then M is a T-model of F.
In practice, the DPLL(T) approach can be implemented, very much in the
spirit of the CLP(X) scheme in constraint logic programming, by building a com-
ponent DPLL(X) common to all theories, and instantiating it with solvers for dif-
ferent theories T to obtain diﬀerent DPLL(T) procedures. At each state M || F,
the theory solver only sees the part M and communicates to the DPLL(X) en-
gine any input literals entailed by M in the given theory. More details on an
architecture for concrete DPLL(T) systems can be found in [GHN+04].

Abstract DPLL and Abstract DPLL Modulo Theories
49
3.4
The DPLL(T) Approach with Non-exhaustive Propagation
For some theories eager Theory Propagate is expensive in an actual implemen-
tation. For example, in our experience with EUF, this is the case for detecting
input literals entailed by disequations. However, using the information coming
from the “cheap enough” applications of Theory Propagate is extremely useful
for pruning the search space. Therefore one would like to have a combination of
Theory Propagate, for the cheaper cases, and Lazy Theory Learning, for covering
the incompletenesses of Theory Propagate making the equivalent of Lemma 22
hold. This is actually what is done in the DPLL(T) implementation of [GHN+04].
Deﬁnition 25. The DPLL(T) system with non-exhaustive theory propagation
consists of the Lazy Theory Learning and Theory Propagate rules and the six rules
of DPLL with learning. We denote by =⇒NEdpll(T) the transition relation deﬁned
by the DPLL(T) system with eager theory propagation.
Deﬁnition 26. A DPLL(T) procedure with Non-Exhaustive Theory Propaga-
tion for T is any procedure taking an input cnf F and computing a sequence
∅|| F =⇒∗
NEdpll(T) S where S is a ﬁnal state with respect to the Basic DPLL
system and Lazy Theory Learning.
A necessary and suﬃcient condition for ensuring the termination of the pre-
vious system is again that no clause can be learned by Lazy Theory Learning
or Learn inﬁnitely many times. In practice, this can be achieved by the same
strategy presented in Subsection 3.2. Hence, we have:
Theorem 27. The DPLL system with non-exhaustive theory propagation pro-
vides a decision procedure for the satisﬁability in T of cnf formulas F, that is:
1. ∅|| F =⇒!
NEdpll(T) fail if, and only if, F is unsatisﬁable in T.
2. ∅|| F =⇒∗
NEdpll(T) M || F ′, where M || F ′ is a ﬁnal state wrt Basic DPLL
and Lazy Theory Learning, if, and only if, F is satisﬁable in T.
3. If ∅|| F =⇒∗
NEdpll(T) M || F ′, where M || F ′ is a ﬁnal state wrt Basic DPLL
and Lazy Theory Learning, then M is a T-model of F.
4
Conclusions
We have presented a declarative formal framework for modeling DPLL-based
solvers for propositional satisﬁability or for satisﬁability modulo theories. We
have shown that the essence of these solvers can be described simply and ab-
stractly in terms of rule-based transition systems over states consisting of a truth
assignment and a clause set.
The declarative and formal nature of our transition systems makes it easier to
prove properties such as soundness, completeness or termination of DPLL-style
algorithms. Furthermore, it facilitates their comparison as their diﬀerences can

50
R. Nieuwenhuis, A. Oliveras, and C. Tinelli
be more easily seen as diﬀerences in the set of their transition rules or in their
rule application strategy.
The approach we presented is as ﬂexible and declarative as the one followed
in [Tin02], which ﬁrst formulated basic DPLL and DPLL modulo theories ab-
stractly, as sequent-style calculi. But it considerably improves on that work
because it allows one to model more features of modern DPLL-based engines
directly within the framework. This contrasts with the calculi in [Tin02] where
features as backjumping and learning can be discussed only at the control level,
in terms of proof procedures for the calculi.
References
ABC+02.
G. Audemard, P. Bertoli, A. Cimatti, A. Kornilowicz, and R. Sebastiani.
A SAT based approach for solving formulas over boolean and linear math-
ematical propositions. In CADE-18, LNCS 2392, pages 195–210, 2002.
ACG00.
Alessandro Armando, Claudio Castellini, and Enrico Giunchiglia. SAT-
based procedures for temporal reasoning. In Procs. 5th European Confer-
ence on Planning, LNCS 1809, pages 97–108, 2000.
BB04.
Clark W. Barrett and Sergey Berezin. CVC lite: A new implementation
of the cooperating validity checker. Category B. In Procs. 16th Int. Conf.
Computer Aided Veriﬁcation (CAV), LNCS 3114, pages 515–518, 2004.
BDS02.
Clark Barrett, David Dill, and Aaron Stump.
Checking satisﬁability of
ﬁrst-order formulas by incremental translation into sat.
In Procs. 14th
Intl. Conf. on Computer Aided Veriﬁcation (CAV), LNCS 2404, 2002.
DLL62.
Martin Davis, George Logemann, and Donald Loveland. A machine pro-
gram for theorem-proving. Comm. of the ACM, 5(7):394–397, 1962.
dMR02.
Leonardo de Moura and Harald Rueß. Lemmas on demand for satisﬁabil-
ity solvers. In Procs. 5th Int. Symp. on the Theory and Applications of
Satisﬁability Testing, SAT’02, pages 244–251, 2002.
DP60.
Martin Davis and Hilary Putnam. A computing procedure for quantiﬁca-
tion theory. Journal of the ACM, 7:201–215, 1960.
FJOS03.
C. Flanagan, R. Joshi, X. Ou, and J. B. Saxe. Theorem proving using lazy
proof explanation. In Procs. 15th Int. Conf. on Computer Aided Veriﬁca-
tion (CAV), LNCS 2725, 2003.
GHN+04.
H. Ganzinger, G. Hagen, R. Nieuwenhuis, A. Oliveras, and C. Tinelli.
DPLL(T): Fast decision procedures. In Procs. 16th Int. Conf. Computer
Aided Veriﬁcation (CAV), LNCS 3114, pages 175–188, 2004.
GN02.
E. Goldberg and Y. Novikov. BerkMin: A fast and robust SAT-solver. In
Design, Automation, and Test in Europe (DATE ’02), pages 142–149, 2002.
MMZ+01.
M. Moskewicz, Conor. Madigan, Y. Zhao, L. Zhang, and S. Malik. Chaﬀ:
Engineering an Eﬃcient SAT Solver.
In Proc. 38th Design Automation
Conference (DAC’01), 2001.
MSS99.
Joao Marques-Silva and Karem A. Sakallah. GRASP: A search algorithm
for propositional satisﬁability. IEEE Trans. Comput., 48(5):506–521.
Tin02.
Cesare Tinelli. A DPLL-based calculus for ground satisﬁability modulo
theories. In Procs. 8th European Conf. on Logics in Artiﬁcial Intelligence,
LNAI 2424, pages 308–319, 2002.
Zha97.
Hantao Zhang.
SATO: An eﬃcient propositional prover.
In CADE-14,
LNCS 1249, pages 272–275, 1997.

Combining Lists with
Non-stably Inﬁnite Theories
Pascal Fontaine, Silvio Ranise, and Calogero G. Zarba
LORIA and INRIA-Lorraine
Abstract. In program veriﬁcation one has often to reason about lists
over elements of a given nature. Thus, it becomes important to be able
to combine the theory of lists with a generic theory T modeling the
elements. This combination can be achieved using the Nelson-Oppen
method only if T is stably inﬁnite.
The goal of this paper is to relax the stable-inﬁniteness requirement.
More speciﬁcally, we provide a new method that is able to combine the
theory of lists with any theory T of the elements, regardless of whether
T is stably inﬁnite or not. The crux of our combination method is to
guess an arrangement over a set of variables that is larger than the one
considered by Nelson and Oppen.
Furthermore, our results entail that it is also possible to combine T with
the more general theory of lists with a length function.
1
Introduction
In program veriﬁcation one has often to decide the validity or satisﬁability of
logical formulae involving lists over elements of a given nature. For instance,
these formulae may involve lists of integers or lists of booleans.
One way to reason about lists over elements of a given nature is to use the
Nelson-Oppen method [12] in order to modularly combine a decision procedure
for a theory modeling lists with a decision procedure for a theory modeling the
elements. This solution requires that the theory of the elements be stably inﬁnite.
Unfortunately, this requirement is not satisﬁed by many interesting theories such
as, for instance, the theory of booleans and the theory of integers modulo n.
In this paper, we show how to relax the stable inﬁniteness require-
ment. More speciﬁcally, let Tlist be the two-sorted theory of lists involving a sort
elem for elements, a sort list for ﬂat lists of elements, plus the symbols nil, car,
cdr, and cons. For instance, a valid formula in Tlist is
x ≈cdr(cons(a, nil)) →x ̸≈cons(b, y) .
We consider the theory Tlen that extends Tlist with a sort int for the integers, the
symbols 0, 1, +, −, < for reasoning over the integers, and a function symbol
length whose sort is list →int. For instance, a valid formula in Tlen is
x ̸≈cdr(cons(a, nil)) →length(x) > 0 .
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 51–66, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

52
P. Fontaine, S. Ranise, and C.G. Zarba
We then provide a combination method that is able to combine Tlen with any
theory Telem modeling the elements, regardless of whether Telem is stably inﬁnite
or not.
The core ideas of our combination method are:
– modifying the Nelson-Oppen method in such a way to guess an arrangement
over an extended set of free constants, and not just the shared ones.
– appropriately computing a certain minimal cardinality k0, so that we can
ensure that the domain of the elements must have at least k0 elements.
1.1
Related Work
The importance of reasoning about lists is corroborated by the numerous ﬂavors
of theories of lists [1,3,4,13,14,18] present in literature, as well as by the increasing
number of tools [6,7,11,15,16,19] containing some capabilities for reasoning about
lists.
The idea of guessing an arrangement over a larger sets of free constants was
already used by Zarba in order to combine the theory of sets [24] and the theory of
multisets [22] with any arbitrary theory T of the elements, regardless of whether
T is stably inﬁnite or not. This idea was also used by Fontaine and Gribomont [8]
in order to combine the theory of arrays with any other non-necessarily stably
inﬁnite theory T.
The idea of computing minimal cardinalities was used by Zarba [23] in order
to combine the theory of ﬁnite sets with a non-necessarily stably inﬁnite theory
T of the elements, in the presence of the cardinality operator. This idea was also
exploited by Tinelli and Zarba [20], who provided a method for combining any
shiny theory S with any non-necessarily stably inﬁnite theory T. Examples of
shiny theories include the theory of equality, the theories of partial and total
orders, and the theories of lattices with maximum and minimum.
2
Many-Sorted Logic
2.1
Syntax
We ﬁx the following inﬁnite sets: a set sorts of sorts, a set con of constant
symbols, a set fun of functions symbols, and a set pred of predicate symbols.
We also ﬁx an inﬁnite set of variable symbols for every sort in sorts.
A signature Σ is a tuple ⟨S, C, F, P⟩where S ⊆sorts, C ⊆con, F ⊆fun,
P ⊆pred, all the symbols in C have sorts in S, and all the symbols in F, P
have sorts constructed using the sorts in S. If Σ = ⟨S, C, F, P⟩is a signature,
we sometimes write ΣS for S, ΣC for C, ΣF for F, and ΣP for P.
If Σ1 = ⟨S1, C1, F1, P1⟩and Σ2 = ⟨S2, C2, F2, P2⟩are signatures, we write
Σ1 ⊆Σ2 when S1 ⊆S2, C1 ⊆C2, F1 ⊆F2, and P1 ⊆P2. If Σ1 = ⟨S1, C1, F1, P1⟩
and Σ2 = ⟨S2, C2, F2, P2⟩are signatures, their union is the signature Σ1 ∪Σ2 =
⟨S1 ∪S2, C1 ∪C2, F1 ∪F2, P1 ∪P2⟩.

Combining Lists with Non-stably Inﬁnite Theories
53
Given a signature Σ and a set of variables, we assume the standard notions
of Σ-term, Σ-atom, Σ-literal, Σ-formula. If ϕ is either a term or a formula, we
denote by varsσ(ϕ) the set of variables of sort σ occurring in ϕ.
In the rest of this paper we identify a conjunction of formulae ϕ1 ∧· · · ∧ϕn
with the set {ϕ1, . . . , ϕn}. In addition, we abbreviate literals of the form ¬(s ≈t)
with s ̸≈t.
2.2
Semantics
Deﬁnition 1. If Σ is a signature, a Σ-interpretation A over a set of variables
V is a map which interprets:1
– each sort σ ∈ΣS as a non-empty domain Aσ;
– each variable x ∈V of sort σ as an element xA ∈Aσ;
– each constant symbol c ∈ΣC of sort σ as an element cA ∈Aσ;
– each function symbol f ∈ΣF of sort σ1 × · · · × σn →τ as a function
f A : Aσ1 × · · · × Aσn →Aτ;
– each predicate symbol p ∈ΣP of sort σ1 × · · · × σn as a subset P A of
Aσ1 × · · · × Aσn.
□
A Σ-formula is satisﬁable if it evaluates to true under some Σ-interpretation.
Let A be an Σ-interpretation over the set of variables V , and let Σ′ ⊆Σ and
V ′ ⊆V . We denote by AΣ′,V ′ the interpretation obtained from A by restricting
it to interpret only the symbols in Σ′ and variables in V ′. For convenience, AΣ′
also denotes AΣ′,V .
A Σ-structure is a Σ-interpretation over an empty set of variables.
2.3
Theories
Following Ganzinger [9], we deﬁne theories as sets of structures rather than as
sets of formulas. More formally:
Deﬁnition 2. A Σ-theory is a pair ⟨Σ, A⟩where Σ is a signature and A is a
set of Σ-structures.
□
Deﬁnition 3. Let T be a Σ-theory, and let Σ ⊆Ω. An Ω-interpretation A is
a T-interpretation if AΣ,∅∈T.
□
A formula is T-satisﬁable if it evaluates to true under some T-interpretation.
Given a Σ-theory T, the ground satisﬁability problem of T is the problem of
deciding, for each ground Σ-formula ϕ, whether or not ϕ is T-satisﬁable.
Deﬁnition 4. Let Σ be a signature, let S ⊆ΣS be a nonempty set of sorts, and
let T be a Σ-theory. We say that T is stably infinite with respect to S if every
ground Σ-formula ϕ is T-satisﬁable if and only if there exists a T-interpretation
satisfying ϕ such that Aσ is inﬁnite, for each sort σ ∈S.
□
1 Unless otherwise speciﬁed, we use the convention that calligraphic letters denote in-
terpretations, and that the corresponding Roman letters, appropriately subscripted,
denote the domains of the interpretations.

54
P. Fontaine, S. Ranise, and C.G. Zarba
Deﬁnition 5 (Combination of theories). Let Ti = ⟨Σi, Ai⟩be a theory, for
i = 1, 2. The combination of T1 and T2 is the theory comb(T1, T2) = ⟨Σ, A⟩
where Σ = Σ1 ∪Σ2 and A = {A | AΣ1 ∈A1 and AΣ2 ∈A2}.
□
2.4
The Theory of Integers
Let us ﬁx a signature Σint containing a sort int for the integers, plus the constant
symbols 0 and 1 of sort int, the function symbols + and −of sort int×int →int,
and the predicate symbol <, of sort int × int.
Deﬁnition 6. The standard int-structure is the Σint-structure A speciﬁed
by letting Aint = Z and interpreting the symbols 0, 1, +, −, < according to their
intuitive meaning over Z.
□
Deﬁnition 7. The theory of integers is the pair Tint = ⟨Σint, {A}⟩, where
A is the standard int-structure.
□
The ground satisﬁability problem of Tint can be decided by using methods
based on integer automata [21], the omega test [2,17], or appropriate extensions
of the Fourier-Motzkin method [10].
2.5
Lists
Let A be a non-empty set, and assume that the special object ⊥does not belong
to A.2 A list x over A of length n is a map x : N →A ∪{⊥} such that x(i) ∈A,
for i < n, and x(i) = ⊥, for i ≥n. We write |x| = n to indicate that the length
of the list x is n. We denote by A∗the set of lists over A.
We denote by nil the empty list, that is, nil(i) = ⊥, for each i ∈N. We denote
by car and cons the partial functions deﬁned as follows: given a list x ̸= nil, we
let car(x) = x(0), whereas cdr(x) is the unique list y such that y(n) = x(n + 1),
for each n ∈N.
Given an element e ∈A and a list x in A∗, we denote by cons(e, x) the list
y such that y(0) = e, and y(n + 1) = x(n), for each n ∈N.
2.6
The Theory of Lists
We ﬁx a signature Σlist containing a sort elem for elements and a sort list for lists
of elements, plus the constant symbol ⊥elem of sort elem, the constant symbols
nil and ⊥list of sort list, the function symbols car of sort list →elem, the function
symbol cdr of sort list →list, and the function symbol cons of sort elem × list →
list.
Deﬁnition 8. A standard list-structure A is a Σlist-structure satisfying the
following conditions:
2 Using this special object ⊥to deﬁne lists is not fundamental but it is convenient for
the following.

Combining Lists with Non-stably Inﬁnite Theories
55
– ⊥/∈Aelem;
– Alist = (Aelem)∗;
– nilA = nil;
– carA(nil) = (⊥elem)A;
– cdrA(nil) = (⊥list)A;
– carA(x) = car(x), for each x ∈Alist such that x ̸= nil;
– cdrA(x) = cdr(x), for each x ∈Alist such that x ̸= nil;
– consA(e, x) = cons(e, x), for each e ∈Aelem and x ∈Alist.
□
Note that although car and cdr are partial functions, standard list-structures
interpret the symbols car and cdr as total functions. In particular, all standard
list-structures ensure that the constants ⊥elem and ⊥list have the same interpre-
tations of the terms car(nil) and cdr(nil), respectively. However ⊥elem and ⊥list
may be interpreted by any element and list in the respective domain. There are
thus many standard list-structures.
Deﬁnition 9. The theory of lists is the pair Tlist = ⟨Σlist, A⟩, where A is
the set of all standard list-structures.
□
As a by product of the results of this paper, we will see that the ground
satisﬁability problem of Tlist can be decided by appropriately adapting Oppen’s
decision procedure for a one-sorted theory of lists without nil [14].
2.7
The Theory of Lists with a Length Function
We ﬁx a signature Σlen containing all the symbols in Σint and Σlist, plus the
function symbol length of sort list →int.
Deﬁnition 10. A standard len-structure A is a Σlen-structure satisfying
the following conditions:
– AΣint is the standard int-structure;
– AΣlist is a standard list-structure;
– lengthA(x) = |x|, for each x ∈Alist.
□
Deﬁnition 11. The theory of lists with a length function is the pair
Tlen = ⟨Σlen, A⟩, where A is the set of all standard len-structures.
□
The ground satisﬁability problem of Tlen can be decided by appropriately
adapting a decision procedure for a two-sorted theory of recursively deﬁned data
structures with integer constraints [25].
3
The Combination Method
Let Σelem be a signature such that ΣS = {elem}, and let Telem be any Σelem-
theory, not necessarily stably inﬁnite with respect to the sort elem. Assume
that the ground satisﬁability problem of Telem is decidable. We now describe a

56
P. Fontaine, S. Ranise, and C.G. Zarba
fail
Integer
phase
Element
phase
fail
Decomposition
phase
succeed
fail
List
phase
Fig. 1. The phases of our combination method
combination-based decision procedure for the ground satisﬁability problem of
T = comb(Telem, Tlen).
In our combination method we use as black boxes a decision procedure for
the ground satisﬁability problem of Telem and a decision procedure for the ground
satisﬁability problem of Tint. We also use—albeit not strictly as a black box—
Oppen’s decision procedure for recursively deﬁned data structures.
Without loss of generality, we restrict ourselves to conjunctions Γ of literals
in separate form: Γ = Γelem ∪Γint ∪Γlist ∪Γlength where:
(a) Γelem contains only Σelem-literals;
(b) Γint contains only Σint-literals;
(c) Γlist contains only ﬂat Σlist-literals of the form
x ≈y ,
x ̸≈y ,
x ≈nil ,
e ≈⊥elem ,
x ≈⊥list ,
x ≈cons(e, y) ,
where e1, e2, e are elem-variables and x, y are list-variables;
(d) Γlength contains only literals of the form u ≈length(x) where u is an int-
variable and x is a list-variable;
(e) for each list-variable x ∈varslist(Γ), either x ≈nil or x ̸≈nil is in Γlist.
Notice that, given a set of literals in T, it is easy to build an equisatisﬁable
separation verifying (a),(b),(d) the usual way [12] by introducing fresh variables.
However to furthermore ensure (c) and (e), and in particular to eliminate all
occurences of car and cdr, it is necessary to include disjunctions to the set of
literals. For eﬃciency concerns, this transformation is done at the formula level;
it is described in Section 5.
Our combination method consists of the four phases depicted in Figure 1,
and described below.
3.1
Decomposition Phase
Let Γ = Γelem∪Γint∪Γlist∪Γlength be a conjunction of literals in separate form. Also
let Velem = varselem(Γlist) ∪{⊥elem} and Vlist = varslist(Γ). In the decomposition
phase we non-deterministically guess an equivalence relation ∼elem of Velem, and
we construct the following set of literals:
αelem = {e1 ≈e2 | e1 ∼elem e2} ∪{e1 ̸≈e2 | e1, ≁elem e2} .

Combining Lists with Non-stably Inﬁnite Theories
57
Note that our decomposition phase diﬀers from the one of Nelson-Oppen
method. In fact, in the Nelson-Oppen method one guesses an equivalence relation
over the smaller set of variables varselem(Γelem) ∩varselem(Γlist). We need to use
the larger set Velem because we do not have any stable inﬁniteness assumption
over the theory Telem of the elements.
3.2
List Phase
In the list phase we essentially employ Oppen’s decision procedure for recursively
deﬁned data structures. By not using Oppen’s procedure just as a black box, we
will later be able to use the information constructed in this phase in the later
phases of our method. (Cf. Section 5.)
More in detail, in the list phase we construct the least equivalence relation
∼list of Vlist satisfying the following conditions:
(a) if x ≈y is in Γlist then x ∼list y;
(b) if x1 ≈cons(e1, y1) and x2 ≈cons(e2, y2) are in Γlist, and e1 ∼elem e2 and
y1 ∼list y2 then x1 ∼list x2;
(c) if x1 ≈cons(e1, y1) and x2 ≈cons(e2, y2) are in Γlist, and x1 ∼list x2 then
e1 ∼elem e2 and y1 ∼list y2.
Furthermore, we construct the relation ≺list of Vlist deﬁned by letting x ≺list y
if and only if there are list-variables x′, y′ ∈Vlist and an elem-variable e ∈Velem
such that x ∼list x′, y ∼list y′, and the literal y′ ≈cons(e, x′) is in Γlist.
We end our method by outputting fail if at least one of the following con-
ditions does not hold:
(C1) If x ∼list y then the literal x ̸≈y is not in Γlist;
(C2) There are no two literals x ≈nil and y ≈cons(e, z) in Γlist for which
x ∼list y;
(C3) The relation ≺list is well-founded.
If instead all conditions (C1)–(C3) hold, we proceed to the next phase.
3.3
Integer Phase
In this phase we extract integer constraints from the conjunctions Γlist and Γlength,
as well as from the equivalence relation ∼list constructed in the list phase.
More in detail, we generate a fresh int-variable ux, for each list-variable x in
Vlist, and we construct the following set of literals
αint = {ux ≈0 | x ≈nil is in Γlist} ∪
{ux > 0 | x ̸≈nil is in Γlist} ∪
{ux = uy + 1 | x ≈cons(e, y) is in Γlist} ∪
{u ≈ux | u ≈length(x) is in Γlength} ∪
{ux ≈uy | x ∼list y} .
Then, we check whether Γint ∪αint is Tint-satisﬁable. If this is not the case, we
end our method by outputting fail; otherwise we proceed to the next phase.

58
P. Fontaine, S. Ranise, and C.G. Zarba
3.4
Element Phase
We will prove later that when we reach this point we can already conclude that
αelem∪Γlist∪Γint∪Γlength is Tlen-satisﬁable.3 Therefore, we can eﬀectively compute
the minimal integer k0 for which there exists a Tlen-interpretation A satisfying
αelem ∪Γlist ∪Γint ∪Γlength such that k0 = |Aelem|.4
Let {|elem| ≥k0} denotes the set of disequalities {ei ̸≈ej | 1 ≤i < j ≤k0},
where the ei are fresh elem-variables. The last step of the element phase consists
of checking whether Γelem ∪αelem ∪{|elem| ≥k0} is Telem-satisﬁable. If this is not
the case, we end the method by outputting fail; otherwise we happily output
succeed.
4
Correctness
In this section we prove that our combination method is correct. Clearly, our
method is terminating. The following proposition shows that our method is also
partially correct.
Proposition 12. Let Telem be a Σelem-theory such that ΣS = {elem}, let T =
comb(Telem, Tlen), and let Γ = Γelem∪Γint∪Γlist∪Γlength be a conjunction of literals
in separate form. Then the following are equivalent:
1. Γ is T-satisﬁable.
2. There exists an equivalence relation ∼elem of varselem(Γlist)∪{⊥elem} for which
our method outputs succeed.
□
Proof. Remember that Velem = varselem(Γlist) ∪{⊥elem} and Vlist = varslist(Γ).
(1 ⇒2). Let M be a T-interpretation satisfying Γ. We deﬁne an equivalence
relation ∼elem over Velem by letting
e1 ∼elem e2 ⇐⇒eM
1
= eM
2 ,
for each e1, e2 ∈Velem .
We claim that if we guess ∼elem as deﬁned above, then our method outputs
succeed. To see this, let ∼list be the equivalence relation constructed in the list
phase, and let ≡list be the equivalence relation of Vlist deﬁned as follows:
x ≡list y ⇐⇒xM = yM ,
for each x, y ∈Vlist .
By construction ≡list satisﬁes conditions (a)–(c) in the list phase. Therefore,
we have ∼list ⊆≡list, that is:
x ∼list y =⇒x ≡list y ,
for each x, y ∈Vlist .
3 A Tlen-interpretation satisfying αelem ∪Γlist ∪Γint ∪Γlength is denoted by C in the second
part of the proof of Proposition 12.
4 One way of computing k0 is to use [25] to check, for increasing k, whether there exists
a Tlen-interpretation A satisfying αelem ∪Γlist ∪Γint ∪Γlength such that |Aelem| = k.

Combining Lists with Non-stably Inﬁnite Theories
59
By using the fact that ∼list ⊆≡list, one can verify that ∼list satisﬁes all
conditions (C1)–(C3) of the list phase. Therefore, our method does not output
fail when executing the list phase.
Next, we claim that our method also does not output fail when executing
the integer phase. To justify the claim, we need to show that Γint ∪αint is Tint-
satisﬁable. Indeed, by again using the fact that ∼list ⊆≡list, it is possible to verify
that a Tint-interpretation satisfying Γint ∪αint can be obtained by extending M
to the variables ux by letting
uM
x
= |xM| ,
for each list-variable x ∈Vlist .
It remains to show that our method outputs succeed when executing the
element phase. To see this, let k0 be the minimal integer computed in the element
phase. By construction, M satisﬁes Γelem ∪αelem. Moreover, since M satisﬁes
αelem ∪Γlist ∪Γint ∪Γlength, it must have at least k0 elements. It follows that M
is a Telem-interpretation satisfying Γelem ∪αelem ∪{|elem| ≥k0}.
(2 ⇒1). Let ∼elem be an equivalence relation of Velem for which our method
outputs succeed. Denote by ∼list and ≺list the relations of Vlist constructed in the
list phase, and denote by k0 the minimal integer computed in the element phase.
Next, note that there exists an interpretation A satisfying Γelem∪αelem∪{|elem| ≥
k0} and a Tint-interpretation B satisfying Γint ∪αint.
Using A and B, we deﬁne a Tlen-interpretation C satisfying αelem ∪Γint ∪Γlist ∪
Γlength by ﬁrst letting Celem = Aelem ∪X, where X is any inﬁnite set disjoint from
Aelem. We also let:
eC = eA,
for all e ∈varselem(Γ) ,
uC = uB,
for all u ∈varsint(Γ) .
In order to deﬁne C over the list-variables in Vlist, we ﬁx an injective function
h : (Vlist / ∼list) →X. Note that h exists because Vlist is ﬁnite and X is inﬁnite.
Next, we proceed by induction on the well-founded relation ≺list. Thus, let
x ∈Vlist. Then:
– In the base case, we let xC be the unique list of length uB
x containing only
the element h([x]∼list). In other words, xC(i) = h([x]∼list) for i < uB
x, and
xC(i) = ⊥for i ≥uB
x.
– In the inductive case, ﬁx a list-variable y such that x ≺list y. Then there
exists variables x′, y′, e such that x ∼list x′, y ∼list y′, and the literal x′ ≈
cons(e, y′) is in Γlist. We let xC = cons(eC, (y′)C).
Note that C is well-deﬁned over the list-variables. Furthermore, by construc-
tion C is a Tlen-interpretation satisfying αelem ∪Γint ∪Γlist ∪Γlength.
It follows that there exists a Tlen-interpretation D satisfying αelem ∪Γint ∪
Γlist ∪Γlength and such that |Delem| = k0. But then, we can use D and A to obtain

60
P. Fontaine, S. Ranise, and C.G. Zarba
1: ϕ := preprocess(ϕ)
2: ϕa ←abs(ϕ)
3: while ϕa ̸= false do
4:
Γ a ←pick assign(ϕa)
5:
Γ ←prop2fol(Γ a)
6:
(ρ, π) ←check sat(Γ)
7:
if ρ = fail then
8:
ϕa ←ϕa ∧¬fol2prop(π)
9:
else
10:
return succeed
11:
end if
12: end while
Fig. 2. haRVey’s main loop
a T-interpretation M satisfying Γ by letting Melem = Aelem and
eM = eA,
for all e ∈ΣC
elem ∪varselem(Γ) ,
f M = f A,
for all f ∈ΣF
elem ,
pM = pA,
for all p ∈ΣP
elem ,
uM = uD,
for all u ∈varsint(Γ) .
In order to deﬁne M over the list-variables, ﬁx an injective function g : Delem →
Aelem. For convenience, also let g(⊥) = ⊥. Note that g exists because |Delem| =
k0 ≤|Aelem|. We let:
xM(i) = g(xD(i)) ,
for all x ∈varslist(Γ) and i ∈N .
By construction, M is a T-interpretation satisfying Γ.
■
From Proposition 12 and the fact that our combination method is terminat-
ing, we obtain the following decidability result.
Theorem 13 (Decidability). Let Telem be a Σelem-theory such that the ground
satisﬁability problem is decidable. Then the ground satisﬁability problem of the
theory comb(Telem, Tlen) is decidable.
□
5
Using the Combination Method
In this Section, we describe how to lift the proposed combination method to
eﬃciently (at least in practice) handle arbitrary Boolean combinations of ground
literals. The method is a reﬁnement of the main loop of haRVey [6] (cf. Figure 2),
a prover based on a combination of Boolean solving and satisﬁability checking
modulo theories. The idea is to obtain a propositional abstraction ϕa of a formula
ϕ (cf. abs) and to enumerate all the propositional assignments (cf. pick assign).

Combining Lists with Non-stably Inﬁnite Theories
61
If an assignment, reﬁned to a conjunction of ﬁrst-order literals (cf. prop2fol),
is found satisﬁable modulo the background theory (cf. check sat returns with
ρ = fail), then we are entitled to conclude the satisﬁability of ϕ. Otherwise, a
new assignment is considered. For eﬃciency, it is crucial to reduce the number
of invocations to check sat. To this end, it is required that check sat returns
a conﬂict set π (which is a subset of the input set of literals) so that all the
propositional assignments sharing that set can be eliminated in one shot.5
We now give some details of the implementation of the functionalities in
Figure 2 which are peculiar to using the combination method in Section 3. In
particular, we describe how to satisfy the requirements necessary for the method
to work correctly (see beginning of Section 3) and, most importantly, we explain
how to compute the ∼list and ≺list of Section 3.2.
Function preprocess. A ﬂat atom is an atom of the form p(c1, . . . , cn), c ≈
f(c1, ..., cm), c1 ≈c2 or c1 ≈d, where p is n-ary predicate symbol (n ≥0), f is
an m-ary function symbol (m > 0), ci is an element of par, and d is a constant.
A ﬂat literal is either a ﬂat atom or the negation of a ﬂat atom of one of the
two forms ¬p(c1, . . . , cn) or c1 ̸≈c2. A formula is said to be ﬂattened if all its
literals are ﬂat. It is easy to get an equisatisﬁable ﬂattened formula from any
ground formula by introducing fresh variables to name subterms.
The preprocessing step also removes all occurrences of car and cdr in the
formula using the following equivalences
e ≈car(x)
≡
(x ≈nil ∧e ≈⊥elem) ∨(x ̸≈nil ∧(∃list y)(x ≈cons(e, y)))
x ≈cdr(y)
≡
(y ≈nil ∧x ≈⊥list) ∨(y ̸≈nil ∧(∃elem e)(y ≈cons(e, x)))
For instance, ϕ[a ≈car(x)] is equisatisﬁable to ϕ[a ≈e] ∧e ≈car(x). In this last
formula, the atom e ≈car(x) has always positive polarity. In a later step, it can
be replaced by (x ≈nil ∧e ≈⊥elem) ∨(x ̸≈nil ∧(∃list y)(x ≈cons(e, y)))
and since the polarity is positive, the existential quantiﬁer can be Skolemized by
simply introducing a fresh variable. Exhaustively applying this transformation
gives a new ground formula, without car and cdr.
Finally, and still by introducing fresh variables, functions cons and length are
made to appear only in unit clauses of the form cons(e, x) ≈y or length(x) ≈u.
For instance formula ϕ[cons(e, x) ̸≈y] is replaced by ϕ[y′ ̸≈y] ∧y′ ≈cons(e, x).
Function pick assign. The function pick assign is implemented by the Boolean
solver and returns a propositional assignment satisfying ϕa. It is easy to tune
the solver to make pick assign return a propositional assignment Γ a such that
prop2fol(Γ a) contains the literals representing the fact that each list variable is
equal to nil or not.
5 Best results are obtained in practice when this set is chosen to be minimal: an
unsatisﬁable set such that each subset is satisﬁable.

62
P. Fontaine, S. Ranise, and C.G. Zarba
Function check sat. First of all, we notice that, thanks to preprocess, the func-
tion pick assign returns a set Γ of literals which can be put in separate form
satisfying conditions (a)–(e) at the beginning of Section 3 by simply partitioning
the literals.
Our combination method uses decision procedures for the quantiﬁer-free frag-
ment of arithmetic and for the theory of acyclic lists. While we use a decision
procedure for the ﬁrst theory as a black box, we require the decision procedure
for the theory of acyclic lists to be able to return ∼list and ≺list. For this reason,
we detail below how to do this.
Reasoning About Acyclic Lists
We introduce a graph structure encapsulating all constraints on the Tlist-models
of a set of equalities of the form x ≈y, e ≈e′, x ≈cons(e, y), where x, y are
list-variables, and e, e′ are elem-variables. In fact, this structure is implicitly
computed by the algorithm described in [14]. We here make it explicit, and
explain how to extract relations ∼list and ≺list from it. The structure may also
be used in order to guide the guessing in Section 3.1.
From now on, if not otherwise speciﬁed, nil is treated as any other variable.
An equality x ≈nil can thus be seen as an equality between two diﬀerent list
variables. Given ﬁnite sets of list and element variables, a list-graph is a tuple
⟨Vlist, Velem, slist, selem⟩with
– Vlist (Velem) is a partition of list (resp. element) variables. It is the set of list
(resp. element) nodes. Variables in a node are labels for that node;
– slist (selem) is a function from Vlist to subsets of Vlist (resp. Velem). Given a list
node u, slist(u) (selem(u)) is the set of list (resp. element) successors of u.
A Tlist-interpretation A agrees with a list-graph if the following conditions are
met:
– if x and y label the same node then A |= x ≈y, where x and y are both
element variables or both list variables;
– if y labels the list successor of x then A |= ∃e x ≈cons(e, y);
– if e labels the element successor of x then A |= ∃y x ≈cons(e, y).
Assume L is a Tlist-satisﬁable set of equalities of the form x ≈y, e ≈e′, x ≈
cons(e, y). Then there is a list-graph G such that, for every Tlist-interpretation
A, A agrees with G if and only if A is a model of L. Indeed, the following graph
veriﬁes this property:
– x and y label the same node if and only if L |=list x ≈y,6 where x and y are
both element variables or both list variables;
– y labels the list successor of x if and only if L |=list ∃e x ≈cons(e, y);
– e labels the element successor of x if and only if L |=list ∃y x ≈cons(e, y).
6 |=list denotes logical consequence in the theory of lists. That is L |=list x ≈y if every
Tlist-model of L is a model of x ≈y.

Combining Lists with Non-stably Inﬁnite Theories
63
z, u
e3
e1
e2, e4
x
y
t
Fig. 3. example of canonical list-graph
This graph is unique. It is such that, for each v ∈Vlist, slist(v) and selem(v) are
either a singleton or the empty set. In other words, every list node has at most
one list successor, and one element successor. In fact, it can be showed that
every node has two or zero successor, since the cdr and car functions are not
explicitly used in the set of equalities. If nil labels a list-node, then this node has
no list successors. It is acyclic in the sense that slist is acyclic. Finally, for each
u, v ∈Vlist, if slist(u) = slist(v), slist(u) ̸= ∅, selem(u) = selem(v), and selem(u) ̸= ∅,
then u = v. In other words, two diﬀerent list nodes must not have the same list
and element successors.
This graph will thus be called the canonical list-graph for a set of equalities.
For instance, the canonical list-graph for the set of equalities
y ≈cons(e1, x), x ≈cons(e2, z), x ≈cons(e4, u), t ≈cons(e3, x)
is given in Figure 3.
Given the canonical list-graph for a set of equalities, we have that x ∼list y is
true if and only if x and y both label the same list node and ≺list is the transitive
closure of the list successor relation.
Computing Canonical list-Graphs
To compute the canonical graph for a set of equalities, three transformations on
list-graphs are necessary:
– a congruence step replaces two lists nodes u and v such that slist(u) = slist(v)
and selem(u) = selem(v) by a unique node u ∪v.7 The new node inherits all
successors of the nodes it replaces. All list nodes which had u or v as list
successor are made to have u ∪v as list successor.
– a list uniﬁcation step (Unify-cdr) replaces two list successors u and v of one
node t by a unique node u ∪v. The new node inherits all successors of the
nodes it replaces. All list nodes which had u or v as list successor are made
to have u ∪v as list successor.
– an element uniﬁcation step (Unify-car) replaces two element successors u
and v of one node t by a unique node u ∪v. All list nodes which had u or v
as element successor are made to have u ∪v as list successor.
7 Remember u and v are disjoint sets of list variables.

64
P. Fontaine, S. Ranise, and C.G. Zarba
Congruence:
L
L′
−→
L ∪L′
Unify-cdr:
L
L′
−→
L ∪L′
Unify-car:
L
L′
−→
L ∪L′
Fig. 4. Transformation steps
These transformations are depicted in Figure 4.
Let L be a set of equalities of the form x ≈y, e ≈e′, x ≈cons(e, y). To build
the canonical graph for this set, the ﬁrst operation is to compute the reﬂexive,
symmetric and transitive closure of all equalities between variables in the set
L. Second, for every equality cons(e, x) ≈y, the nodes labeled by x and e are
made list and element successors of the node labeled by y. Third, the graph
is uniﬁed, beginning with nodes without parent, ﬁnishing with those without
successor, using uniﬁcation steps (beginning with all element uniﬁcation steps).
Last, the congruence rule is applied, from the nodes without successors, to the
nodes without parents. In presence of nil, a postprocessing ensures that the node
it labels has no successor.
If the graph happens to be cyclic, or if nil happens to have a successor, the
procedure fails. In that case the initial set of equalities is unsatisﬁable. A careful
implementation of this procedure is linear in time [14].
The obtained graph (after a ﬁnite number of transformation steps) is indeed
the canonical graph: every Tlist-interpretation A agreeing with a graph G also
agrees with the graph obtained from G by a transformation step. That ensures
that every model of L agrees with the ﬁnal graph. To show that every Tlist-
interpretation agreeing with the graph is also a model for L, it suﬃces to show
that every equality of L is trivially satisﬁed by any interpretation agreeing with
the graph.
There is a Tlist-interpretation agreeing with a canonical list-graph, such that
every node is assigned to a diﬀerent element or list. As a consequence, satisﬁa-
bility checking of a set of literals in Tlist can be simply implemented by building
the canonical list-graph for all equalities in the set, and check afterward if no
inequality has both members labeling the same node.

Combining Lists with Non-stably Inﬁnite Theories
65
Two ﬁnal remarks are in order. First, the list-graph may be build before
guessing an arrangement of the element variables, and may be used to guide
this guessing. Indeed it is not necessary to consider an αelem implying that two
variables labeling the same node in the list-graph are diﬀerent. Second, for the
algorithm in Figure 2 to be eﬃcient, it is required also that check sat returns
a small (minimal, if possible) conﬂict set π out of the input set of literals. For
instance, the decision procedure for acyclic lists should produce small unsatisﬁ-
able subsets of the input set of literals, or be able to give the equations necessary
to deduce a given equality from a satisﬁable set. We believe this is possible by
adapting the method developed for congruence closure in [5].
6
Conclusion
We presented a combination method that is able to combine a many-sorted
theory Tlen modeling lists of elements in the presence of the length operator with
a theory Telem modeling the elements.
Our method works regardless of whether the theory of the elements is stably
inﬁnite or not. We were able to relax the stable inﬁniteness requirement by
employing the following basic ideas:
– guess an arrangement larger than the one computed by Nelson and Oppen;
– compute a certain minimal cardinality k0, so that we can ensure that the
domain of the elements must have at least k0 elements.
Future works include implementing the proposed method in haRVey, and in
particular, study heuristics to make it more eﬃcient, and investigate extending
the procedure for acyclic lists to compute minimal conﬂict sets. On the theo-
retical side, it remains to determine the exact complexity of the algorithm, and
examine the proposed combination when some sorts (elem, list, int) are equal.
Acknowledgments
We are grateful to Christophe Ringeissen for insightful discussions on the prob-
lem of combining non-stably inﬁnite theories. We would also like to thank the
reviewers for their comments.
References
1. A. Armando, S. Ranise, and M. Rusinowitch. A rewriting approach to satisﬁability
procedures. Information and Computation, 183(2):140–164, 2003.
2. S. Berezin, V. Ganesh, and D. L. Dill. An Online Proof-Producing Decision Pro-
cedure for Mixed-Integer Linear Arithmetic. In Proceedings of TACAS’03, volume
2619 of LNCS, Warshaw, Poland, April 2003.
3. N. S. Bjørner. Integrating Decision Procedures for Temporal Veriﬁcation. PhD
thesis, Stanford University, 1998.

66
P. Fontaine, S. Ranise, and C.G. Zarba
4. R. S. Boyer and J. S. Moore. A Computational Logic. ACM Monograph SERIES,
1979.
5. L. de Moura, H. Rueß, and N. Shankar. Justifying equality. In PDPAR, 2004.
6. D. D´eharbe and S. Ranise.
Light-Weight Theorem Proving for Debugging and
Verifying Units of Code.
In Proc. of the International Conference on Software
Engineering and Formal Methods (SEFM03). IEEE Computer Society Press, 2003.
7. J.-C. Filliˆatre, S. Owre, H. Rueß, and N. Shankar. ICS: integrated canonizer and
solver. In G. Berry, H. Comon, and A. Finkel, editors, Computer Aided Veriﬁcation
(CAV), volume 2102 of LNCS, pages 246–249. Springer-Verlag, 2001.
8. P. Fontaine and P. Gribomont.
Combining non-stably inﬁnite, non-ﬁrst order
theories. In S. Ranise and C. Tinelli, editors, Pragmatics of Decision Procedures
in Automated Reasoning, 2004.
9. H. Ganzinger.
Shostak light.
In A. Voronkov, editor, Automated Deduction –
CADE-18, volume 2392 of LNCS, pages 332–346. Springer, 2002.
10. D. Kapur and X. Nie. Reasoning about Numbers in Tecton. In Proc. 8th Inl.
Symp. Methodologies for Intelligent Systems, pages 57–70, 1994.
11. T. F. Melham. Automating Recursive Type Deﬁnitions in Higher Order Logic.
In Current Trends in Hardware Veriﬁcation and Theorem Proving, LNCS, pages
341–386. Sprigner-Verlag, 1989.
12. G. Nelson and D. C. Oppen. Simpliﬁcations by cooperating decision procedures.
ACM Trans. on Programming Languages and Systems, 1(2):245–257, Oct. 1979.
13. G. Nelson and D. C. Oppen. Fast decision procedures based on congruence closure.
Journal of the Association for Computing Machinery, 27(2):356–364, 1980.
14. D. C. Oppen. Reasoning about recursively deﬁned data structures. Journal of the
ACM, 27(3):403–411, 1980.
15. S. Owre and N. Shankar. Abstract Datatypes in PVS. Technical Report CSL-93-
9R, SRI International, 1997.
16. L. C. Paulson. A ﬁxedpoint approach to implementing (co)inductive deﬁnitions. In
A. Bundy, editor, Automated Deduction — CADE-12, LNAI 814, pages 148–161.
Springer, 1994. 12th international conference.
17. W. Pugh. The omega test: a fast integer programming algorithm for dependence
analysis. Supercomputing, pages 4–13, 1991.
18. R. E. Shostak. Deciding combination of theories. Journal of the Association for
Computing Machinery, 31(1):1–12, 1984.
19. A. Stump, C. W. Barrett, and D. L. Dill. CVC: a cooperating validity checker.
In E. Brinksma and K. G. Larsen, editors, Computer Aided Veriﬁcation (CAV),
volume 2404 of LNCS, pages 500–504. Springer, 2002.
20. C. Tinelli and C. G. Zarba. Combining non-stably inﬁnite theories. Journal of
Automated Reasoning, 2004. To appear.
21. P. Wolper and B. Boigelot. On the construction of automata from linear arithmetic
constraints. In S. Graf and M. I. Schwartzbach, editors, TACAS, volume 1785 of
LNCS, pages 1–19, Berlin, Mar. 2000. Springer-Verlag.
22. C. G. Zarba. Combining multisets with integers. In A. Voronkov, editor, Automated
Deduction – CADE-18, volume 2392 of LNCS, pages 363–376. Springer, 2002.
23. C. G. Zarba. Combining sets with integers. In A. Armando, editor, Frontiers of
Combining Systems, volume 2309 of LNCS, pages 103–116. Springer, 2002.
24. C. G. Zarba. Combining sets with elements. In N. Dershowitz, editor, Veriﬁcation:
Theory and Practice, volume 2772 of LNCS, pages 762–782. Springer, 2004.
25. T. Zhang, H. B. Sipma, and Z. Manna. Decision procedures for recursive data
structures with integer constraints. In D. A. Basin and M. Rusinowitch, editors,
Automated Reasoning, volume 3097 of LNCS, pages 152–167. Springer, 2004.

Abstract Model Generation for Preprocessing
Clause Sets
Miyuki Koshimura, Mayumi Umeda, and Ryuzo Hasegawa
Kyushu University, 6-1 Kasuga-koen, Kasuga, Fukuoka, 816-8580 Japan
{koshi,umeda,hasegawa}@ar.is.kyushu-u.ac.jp
Abstract. Abstract model generation refers to model generation for
abstract clause sets in which arguments of atoms are ignored. We give
two abstract clause sets which are obtained from normal clause sets. One
is for checking satisﬁability of the original normal clause set. Another is
used for eliminating unnecessary clauses from the original one. These
abstract clause sets are propositional, i.e. decidable. Thus, we can use
them for preprocessing the original one.
1
Introduction
The use of abstraction seems to be helpful in many subﬁelds of artiﬁcial intelli-
gence [10,7,4,3,2]. The most common use of abstraction in theorem proving has
been to abstract the problem, to prove its abstracted version, and then to use
the structure of the resulting proof as guides in searching for the original prob-
lem. This assumes that the structure of the abstract proof is similar to that of
the original problem. The most common approach is to integrate the abstract
proving into the deduction process by specifying clause selection functions that
imitate the abstract proof. On the other hand, there is another approach which
uses the abstract proving as a preprocessing step in the (ground) prover [8].
The beneﬁt of preprocessing a set S of clauses can be large. In the extreme
S may be solved in the preprocessing stage. In this paper, we use model gener-
ation [6,5] as a procedure for preprocessing S rather than proving S. We apply
model generation to abstractions of S. We present two types of abstraction;
c-abstraction and d-abstraction. In these abstractions, we abstract away all ar-
guments from atoms. Thus, abstract clause sets are propositional.
S is satisﬁable if its d-abstraction is satisﬁable. In this case, we determine its
satisﬁability without proving S itself. If a clause in S contains an atom whose
abstraction is not in the model of c-abstraction of S, the clause is unnecessary
for checking unsatisﬁability. Thus, the clause can be eliminated.
This c-abstraction based elimination is a kind of simpliﬁcation which sim-
pliﬁes a set of clauses. Its eﬀect is parallel to that of a simpliﬁcation operation
eliminating pure literals [15]. However, their strength is not comparable. That
is, the former can eliminate more clauses than the latter does in some cases, and
vice versa. We evaluate eﬀects of abstract model generation for preprocessing
with all CNF problems in the TPTP problem library.
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 67–78, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

68
M. Koshimura, M. Umeda, and R. Hasegawa
2
Model Generation
Throughout this paper, a clause ¬A1 ∨. . .∨¬Am ∨B1 ∨. . .∨Bn is represented
in implicational form: A1 ∧. . . ∧Am →B1 ∨. . . ∨Bn where Ai (1 ≤i ≤m) and
Bj (1 ≤j ≤n) are atoms; the left hand side of “→” is said to be the antecedent;
and the right hand side of “→” the consequent.
A clause is said to be positive if its antecedent is true (m = 0), and negative
if its consequent is false (n = 0); otherwise it is mixed (m ̸= 0, n ̸= 0). A
clause is said to be violated under a set M of ground atoms if with some ground
substitution σ the following condition holds: ∀i(1 ≤i ≤m)Aiσ ∈M ∧∀j(1 ≤
j ≤n)Bjσ ̸∈M.
A model generation proof procedure is sketched in Fig. 1. The procedure MG
takes a partial interpretation Mc (model candidate) and a set of clauses S to be
proven, and builds a (sub)proof-tree of S.
A leaf labeled with ⊤tells us that a model of S has been found as a current
model candidate. If every leaf of the constructed proof-tree is labeled with ⊥, S
is unsatisﬁable; otherwise S is satisﬁable. In the latter case, at least one leaf is
labeled with ⊤or at least one branch grows inﬁnitely.
procedure MGTP(S) : P; /* Input(S):Clause set, Output(P):Proof-tree of S */
return(MG(∅, S));
procedure MG(Mc, S) : P;/* Input(Mc): Model candidate */
1. (Model rejection) If a negative clause (A1 ∧. . . ∧Am →false) ∈S is
violated under Mc with a ground substitution σ, return⟨⊥⟩
2. (Model extension) If a positive or mixed clause (A1 ∧. . . ∧Am →B1 ∨
. . . ∨Bn) ∈S is violated under Mc with a ground substitution σ,
return ⟨
B1σ
P1
Biσ
Pi
Bnσ
Pn
⟩
where Pi = MG(Mc ∪{Biσ}, S) (1 ≤i ≤n).
3. (Model ﬁnding) If neither 1 nor 2 is applicable, return ⟨⊤⟩;
Fig. 1. Model generation procedure
3
Abstract Clauses
An abstract atom of P(t1, . . . , tn) is an atom P. That is, the abstract atom ab-
stracts away its arguments. Henceforth, we will use capital letters A, B, A1, B1, ...
as denoting normal atoms, and small letters a, b, a1, b1, . . . as denoting abstract
atoms corresponding to the capital letters.

Abstract Model Generation for Preprocessing Clause Sets
69
A d-abstract clause of A1∧. . .∧Am →B1∨. . .∨Bn is a clause a1∧. . .∧am →
b1 ∨. . . ∨bn. A set of d-abstract clauses obtained from a normal clause set S by
replacing normal clauses with d-abstract ones is denoted by d abs(S).
Theorem 1. Let S be a set of clauses. If d abs(S) is satisﬁable, then S is sat-
isﬁable.
d abs(S) is a set of propositional clauses, so, checking its satisﬁability is
decidable, while checking satisﬁability of S is generally undecidable1.
Example 1 (D-abstraction). Let S = {p(x) ∧q(x) ∧s(y) →false, p(x) ∧r(x) →
s(f(x)), q(x) →r(x) ∨s(f(x)), p(x) →q(x) ∨r(y), true →p(a)}, then
d abs(S) = {p ∧q ∧s →false, p ∧r →s, q →r ∨s, p →q ∨r, true →p}.
d abs(S) has a model {p, r, s} and thus is satisﬁable. Therefore, we conclude
S is satisﬁable.
C-abstract clauses of A1∧. . .∧Am →B1∨. . .∨Bn are n clauses a1∧. . .∧am →
b1, a1 ∧. . . ∧am →b2, · · · , and a1 ∧. . . ∧am →bn. Note that there is no c-
abstract clause for a negative clause A1 ∧. . . ∧Am →false.
A set of c-abstract clauses obtained from a normal clause set S by replacing
normal clauses with c-abstract ones is denoted by c abs(S). Note that negative
clauses are eliminated in c abs(S) and all clauses in c abs(S) are Horn clauses.
Therefore, we obtain a unique model of c abs(S) with the model generation
procedure.
A clause A1 ∧. . . ∧Am →B1 ∨. . . ∨Bn is relevant to a set A of abstract
atoms if ∀i(1 ≤i ≤m)(ai ∈A), otherwise, irrelevant. If a clause C(∈S) is used
for model extension or rejection in the model generation procedure on S, C is
relevant to the model of c abs(S). Thus, we obtain the following lemma.
Lemma 1. Let S be a set of clauses, P be a proof tree of S, M be a model of
c abs(S), and C = A1 ∧. . .∧Am →B1 ∨. . .∨Bn ∈S be a clause used for model
extension or rejection in P. Then, ∀i(1 ≤i ≤m)ai ∈M where ai is the abstract
atom of Ai(1 ≤i ≤m). That is, C is relevant to M.
Proof. Let Ck = Ak
1 ∧. . .∧Ak
m →Bk
1 ∨. . .∨Bk
n ∈S be a clause used for the k-th
model extension or rejection in P. We can easily show the following property by
induction on k: ∀i(1 ≤i ≤m)ak
i ∈M ∧∀j(1 ≤j ≤n)bk
j ∈M where ak
i is the
abstract atom of Ak
i (1 ≤i ≤m) and bk
j is the abstract atom of Bk
j (1 ≤j ≤n).
This property implies the lemma.
⊓⊔
The lemma says that if a clause C(∈S) is irrelevant to the model of c abs(S),
then C is never used for model extensions or rejections in the model generation
procedure on S. Therefore, we ignore irrelevant clauses when we apply the model
generation procedure on S.
1 d abs(S) is exactly the same as the propositional abstraction proposed by Plaisted [7]
and thus folklore. But, it is still interesting to see experimental data on all satisﬁable
problems from the TPTP library.

70
M. Koshimura, M. Umeda, and R. Hasegawa
Theorem 2. If the model generation determines that a set S of clauses is un-
satisﬁable, then it also determines that S\IR(S) is unsatisﬁable, where IR(S) =
{C|C is irrelevant to M} and M is a model of c abs(S).
The model generation is a sound and complete proof procedure [1], therefore,
we obtain the corollary.
Corollary 1. Let S be a set of clauses. Then, S is unsatisﬁable iﬀS \ IR(S) is
unsatisﬁable.
By proving S \ IR(S) instead of S, we can diminish its execution cost if
IR(S) ̸= ∅. If S \IR(S) = ∅, we conclude that S is satisﬁable. When IR(S) = ∅,
we may decrease the number of clauses in S by applying the same consideration
on the set CON(S) = {B1 ∧. . . ∧Bn →A1 ∨. . . ∨Am | (A1 ∧. . . ∧Am →
B1∨. . .∨Bn) ∈S} which is obtained from the contrapositive set of S by reversing
every literal polarity. Thus, we obtain a process which eliminates unnecessary
clauses in S:
(1) Let S be a set of clauses.
(2) i = 0, S0 = S.
(3) Si+1 = Si \ IR(Si), i = i + 1.
(4) If i = 1 or Si ̸= Si−1, then Si = CON(Si) and goto (3).
(5) If i is an even number, then Si = CON(Si).
We stop the process when it reaches a ﬁxpoint gotten as Si = Si−1. Then,
we try to prove the ﬁnal Si instead of S.
Example 2 (C-abstraction). Let S(= S0) be a set of 6 clauses from C1 to C6:
C1 : r(x) →false
C2 : v(x) →r(x)
C3 : s(x) →r(x)
C4 : q(x) →s(x) ∨u(x)
C5 : p(x) →q(x)
C6 : true →p(a)
Then, c-abstraction c abs(S0) is a set of the following clauses:
C21 : v →r
C31 : s →r
C41 : q →s
C42 : q →u
C51 : p →q
C61 : true →p
We obtain the model {p, q, u, s, r} of c abs(S0) with model generation. The
clause C2 is irrelevant to this model and thus eliminated. So, S1 = {C1, C3, C4,
C5, C6}, then S1 = CON(S1) = {C1C, C3C, C4C, C5C, C6C} where
C1C : true →r(x)
C3C : r(x) →s(x)
C4C : s(x) ∧u(x) →q(x)
C5C : q(x) →p(x)
C6C : p(a) →false
Next, we obtain the model {r, s} of c abs(S1). Therefore, C4C, C5C, and C6C
are irrelevant to this model and thus eliminated. So, S2 = {C1C, C3C}, then
S2 = CON(S2) = {C1, C3}. We continue this process until no clause is elimi-
nated. Finally, S3 becomes an empty set. Thus, we conclude S is satisﬁable.

Abstract Model Generation for Preprocessing Clause Sets
71
4
Experimental Results
The method is implemented on top of a constraint logic programming system B-
Prolog [17]. We use all 5522 CNF problems in the TPTP problem library version
2.7.0 [13,14]. We remove equality axioms using the tptp2X utility (distributed
with TPTP) with option “-t rm_equality:rsftp” from each problem if any.
The problems were run on a DELL computer (Mobile Intel Pentium III 650MHz
CPU, 512MB memory, Linux 2.6.0).
If a problem S contains equality which is represented using the equal/2
predicate in TPTP, we simply add a positive unit clause “true →equal” to
d abs(S) and c abs(S) before preprocessing. In other words, we assume that all
individuals are equal in d-abstraction and the equal/2 predicate is relevant in
c-abstraction.
4.1
D-Abstraction: Checking Satisﬁability
In 766 satisﬁable ﬁrst-order problems, 223 problems are determined as satisﬁable
with their d-abstract clause sets, within one second for each. Table 1 (a) shows
the number of problems solved by d-abstraction for each problem domain in
TPTP. The ﬁrst column shows domain names, and the second column shows the
number of problems solved and the number of satisﬁable ﬁrst-order problems in
that domain. For example, there are 17 satisﬁable ﬁrst-order problems in the
BOO domain. Among them, 4 problems are solved by d-abstraction. 45 % of
223 problems are in the SYN category and 19 % are in the NLP category. Table
1 (b) shows similar information for every problem rating2. The eﬀectiveness of
d-abstraction seems to be independent of the problem domains and ratings.
4.2
C-Abstraction: Eliminating Unnecessary Clauses
In 5522 CNF problems, 725 problems are reduced by c-abstraction based elimi-
nation. For the ALG, COM, FLD, GRA, HEN, HWC, KRS, LDA, RNG, ROB,
SWC, and TOP categories, no problem is reduced. The average preprocessing
time is 3.75 seconds for 725 problems. More than 90% problems are reduced
within one second for each, while 35 problems need more than ten seconds for
reducing. All these 35 problems are in the SYN category and consist of more
than 1000 clauses.
Table 2 (a) shows the numbers of problems reduced with c-abstraction for
each problem domain. For example, there are 83 CNF problems in the HWV
category. 31 problems of them are reduced. For the NLP and SYN categories,
more than half of the problems are reduced.
2 In the TPTP distribution, each problem ﬁle consists of a header part and a body
part. The header part contains information about problem. The rating ﬁled is in the
header part. The rating gives the diﬃculty of the problem. It is a real number in the
range 0.0 to 1.0, where 0.0 means that the problem is easy and 1.0 means that the
problem is hard.

72
M. Koshimura, M. Umeda, and R. Hasegawa
Table 1. Numbers of problems solved by d-abstraction
(a) Domain
ALG
0/2
ANA
2/2
BOO 4/17
CAT 6/10
COL
0/6
COM
0/0
FLD
0/0
GEO 0/17
GRA
0/0
GRP 12/75
HAL
0/0
HEN
3/3
HWC
2/2
HWV
6/8
KRS
2/8
LAT
8/22
LCL
10/44
LDA
0/0
MGT
2/11
MSC
1/2
NLP 42/236
NUM
4/7
PLA
2/2
PUZ
2/20
RNG
5/10
ROB
2/5
SET
4/12
SWC
0/1
SWV
3/9
SYN 100/216
TOP
1/19
(b) Rating
0.00 91/232
0.14
41/79
0.17
4/33
0.29
18/25
0.33
3/109
0.43
15/18
0.50
0/41
0.57
19/56
0.67
0/80
0.71 18/29
0.83
0/1
0.86 14/51
1.00
0/12
Table 2. Numbers of problems reduced by c-abstraction
(a) Domain
ALG
0/15
ANA
4/21
BOO
1/133
CAT
2/62
COL 13/193
COM
0/8
FLD
0/279
GEO
6/253
GRA
0/1
GRP 17/791
HAL
0/0
HEN
0/67
HWC
0/6
HWV
31/83
KRS
0/17
LAT
1/104
LCL
4/527
LDA
0/23
MGT
3/78
MSC
2/13
NLP 156/258
NUM
5/315
PLA
2/32
PUZ
6/82
RNG
0/104
ROB
0/38
SET
5/706
SWC
0/423
SWV
5/21
SYN 462/839
TOP
0/24
(b) Ratio(%)
0-9
87
10-19
6
20-29
32
30-39
17
40-49 108
50-59
19
60-69
55
70-79 118
80-89 167
90-99 116
Table 2 (b) shows the ratio of remaining clauses to the original ones. For
example, the ﬁrst row indicates that there are 87 problems less than 10 % clauses
of which are remaining after reduction. There are 57 problems which are reduced
to the empty sets. All such problems are determined as satisﬁable without proof.
In order to measure the c-abstraction eﬀect, we solved all 725 problems, by
using three provers with a time limit of 600 seconds: DCTP 1.31 [12], Vampire
7.0 [9], and E 0.82 [11]3. These provers attended the CADE ATP system com-
petition CASC-J2[16]. Vampire 7.0 won the ﬁrst place in the MIX and FOF
divisions, DCTP 1.31 won the third place in the EPR division, and E 0.82 won
the third place in the MIX division.
Table 3 (a) shows summaries of c-abstraction eﬀects on these three provers.
The “before” column shows statistics for the original clause sets, while the “after”
column shows statistics for their reduced clause sets. The last row shows the
average cpu time in seconds. The parenthetic number in the “after” column
shows the cpu time including preprocessing. Table 3 (b) shows a detailed version
of (a). We succeed in enhancing performance of the three provers: The numbers
of problems solved are increased from 642 to 647 for DCTP, from 626 to 642 for
Vampire, and from 650 to 661 for E.
3 DCTP runs with options “-negpref -complexity -fullrewrite -alternate -resisol”.
Vampire runs with options “–mode casc-j2 -p oﬀ-t 600”.
E runs with options “-s –print-statistics -xAuto -tAuto –memory-limit=384 –tptp-
in”.

Abstract Model Generation for Preprocessing Clause Sets
73
Table 3. Eﬀect of c-abstraction
(a) Summary
DCTP 1.31
Vampire 7.0
E 0.82
ALL
before
after
before
after
before
after
Attempted
725
Solved
642
647
626
642
650
661
Av. Time(s)
6.15 5.10(9.28)
11.69 7.68(8.80)
5.48 11.64(15.73)
(b) Category summary
Domain
DCTP 1.31
Vampire 7.0
E 0.82
(Attempted) before
after
before
after
before
after
ANA
0
1
1
1
1
1
(4)
-
0.0(0.08)
15.53
15.28(15.36)
46.61 36.98(37.06)
BOO
1
1
1
1
1
1
(1)
0.0
0.0(0.07) 150.09
0.46(0.53)
22.66
0.50(0.57)
CAT
1
1
0
0
0
0
(2)
0.0
0.0(0.08)
-
-
-
-
COL
4
4
4
4
0
0
(13)
12.69
6.61(6.73) 159.39 159.22(159.33)
-
-
GEO
1
1
1
1
1
1
(6)
0.0
0.0(0.07)
0.73
0.11(0.18)
0.86
0.48(0.55)
GRP
17
17
7
8
9
11
(17)
1.05
1.05(1.12)
3.45
3.11(3.19)
1.62
1.35(1.43)
HWV
22
25
28
28
30
29
(31)
1.50
0.08(0.17)
12.76
4.67(4.77)
2.04 10.50(10.59)
LAT
1
1
0
0
0
0
(1)
0.01
0.01(0.09)
-
-
-
-
LCL
4
4
1
4
0
4
(4)
0.00
0.00(0.08) 235.93
0.37(0.45)
-
0.85(0.93)
MGT
3
3
3
3
3
3
(3)
0.03
0.03(0.11)
11.30
11.39(11.47)
0.51
0.52(0.60)
MSC
2
2
2
2
2
2
(2)
0.01
0.0(0.07)
0.41
0.27(0.34)
0.49
0.52(0.59)
NLP
126
126
140
140
146
146
(156)
0.05
0.04(0.14)
9.96
8.56(8.66)
3.19 33.17(33.27)
NUM
5
5
2
5
2
5
(5)
0.0
0.0(0.08)
0.12
0.33(0.40)
0.49
0.60(0.67)
PLA
2
2
2
2
2
2
(2)
0.01
0.0(0.08)
0.13
0.12(0.20)
0.49
0.48(0.56)
PUZ
6
6
5
6
6
6
(6)
0.03
0.03(0.11)
0.13
0.27(0.35)
0.51
0.51(0.59)
SET
4
4
4
4
3
4
(5)
0.09
0.05(0.13)
79.62
18.24(18.31)
0.49 82.65(82.73)
SWV
5
5
4
5
4
5
(5)
0.01
0.0(0.08)
84.62
0.31(0.39)
0.62
0.57(0.65)
SYN
438
439
421
428
440
441
(462)
8.76 7.39(13.52)
9.05
6.57(8.20)
6.69
4.87(10.95)

74
M. Koshimura, M. Umeda, and R. Hasegawa
There is a series of 10 satisﬁable problems in the NLP domain which have a
negative eﬀect on E. The average proving times for these problems are increased
by 440 seconds after c-abstraction. This is a major cause why the average run
time of E is increased from 5.48 seconds to 11.68 seconds.
C-abstraction eﬀects on Vampire and E seem to be stronger than that on
DCTP. This is due to the fact that there exist problems which have no positive
clause or no negative clause. These problems are obviously satisﬁable. But, for
such problems, Vampire and E sometimes consume a lot of cpu time (or reach a
time limit) while DCTP immediately stops. There are 18 such cases for Vampire
and 11 cases for E. These problems become empty sets by c-abstraction, so it is
easy to determine them as satisﬁable4
Table 4. Positive and negative eﬀects of c-abstraction
Problem
Time
No. of clauses
DCTP 1.31
Vampire 7.0
E 0.82
(secs) original reduced before after
before after
before after
ANA006-1
0.08
14
5
T.O.
0.00
T.O.
T.O.
T.O.
T.O.
BOO008-1
0.07
21
1
0.00
0.00 150.09
0.46
22.66
0.50
COL092-2
0.12
195
183
24.66
12.96
T.O.
T.O.
T.O.
T.O.
HWV009-1
0.10
92
66
T.O.
0.10
0.54
0.20
0.56
0.57
HWV031-1
0.10
93
67
T.O.
T.O.
T.O.
T.O.
35.22 283.71
NLP037-1
0.08
66
12
0.02
0.00
65.30
0.10
0.51
0.50
NLP186-1
0.11
108
99
T.O.
T.O.
0.25
0.26
34.69 538.11
NUM288-1
0.07
12
0
0.0
0.0
T.O.
0.44
T.O.
0.85
SET787-1
0.08
14
12
0.34
0.21
71.12
71.55
T.O. 329.16
SWV017-1
0.09
37
5
0.01
0.00 215.64
0.44
0.55
0.51
SYN597-1
0.08
28
23
5.36
5.37
30.91 209.20
3.47
T.O.
SYN599-1
0.08
29
25
89.48
89.57 209.29 162.53
42.30
5.07
SYN610-1
0.08
30
26
T.O.
T.O.
15.18 209.38
5.17
2.87
SYN624-1
0.07
35
26
0.25
0.25
4.80
61.30 111.65
0.68
SYN708-1
0.09
83
61
T.O.
T.O.
36.04 124.57
72.27
60.82
SYN742-1
0.08
31
0
0.04
0.00 169.80
0.10
0.67
0.49
SYN813-1
1.69
504
378
34.41
T.O.
13.59
9.19
10.71
2.96
SYN818-1
104.59
2621
1397 258.68
87.32
T.O.
T.O.
59.65
18.31
SYN821-1
27.53
1716
712
56.24 122.71
T.O.
26.52
T.O.
5.42
SYN822-1
33.15
1768
1138
65.15
34.17
T.O.
59.11
T.O.
71.08
SYN897-1
0.86
122
97
T.O.
4.85
2.26
1.87
1.35
1.11
SYN912-1
2.72
1780
247
61.90
0.62
T.O.
T.O.
T.O.
T.O.
Table 4 shows problems which exhibit positive or negative eﬀect of c-abstraction
on the 3 provers. The second column shows cpu times for preprocessing in sec-
onds, the third the number of original clauses, and the fourth the number of
4 Vampire regards an empty clause set as an error of the input and aborts. We treat
such a case as a normal proof which tells that the set is satisﬁable.

Abstract Model Generation for Preprocessing Clause Sets
75
clauses remaining after preprocessing. The last 6 columns show proving time of
the 3 provers. The “before” column shows the time for the original clause sets,
while the “after” column shows the time for their reduced clause sets. “T.O.”
indicates that the problem is not solved in 600 seconds.
We succeeded in enhancing the provers’ performance for several problems. For
example on SYN912-1, DCTP’s proving times is decreased from 61.90 seconds
to 0.62 seconds after 2.72 seconds preprocessing which decreases the number of
clauses from 1780 to 247. Vampire and E can prove SYN822-1 in 59.11 and 71.08
seconds respectively after preprocessing, while they cannot prove it within 600
seconds before preprocessing.
On the other hand, there are some problems which show negative eﬀects of c-
abstraction. For example on NLP186-1, E’s proving time is increased from 34.69
seconds to 538.11 seconds. DCTP can not prove SYN813-1 within 600 seconds
after preprocessing, while it can prove the same problem in 34.41 seconds before
preprocessing. There is another type of problem which show both positive and
negative eﬀects. For example, SYN624-1 shows a negative eﬀect on Vampire and
a positive eﬀect on E: Vampire’s proving times is increased from 4.80 seconds to
61.30 seconds while E’s proving time is decreased from 111.65 seconds to 0.68
seconds.
There are some satisﬁable problems which are reduced to empty sets of
clauses in DCTP’s preprocessing phase after c-abstraction based clause elimi-
nation. In these problems, 48 problems are not reduced to empty sets without c-
abstraction. This indicates that c-abstraction based clause elimination enhances
the eﬀects of other preprocessing operations.
4.3
C-Abstraction Based Elimination and Pure Literal Elimination
A pure literal is a literal in a clause that cannot be resolved against any literal in
any clause. Clauses that contain pure literals can be eliminated, because such a
clause cannot contribute a resolution proof. Pure literal elimination has a similar
eﬀect to c-abstraction’s because c-abstraction based preprocessing eliminates
clauses which contain literals irrelevant to model generation.
Pure literal elimination is sometimes stronger and sometimes weaker than c-
abstraction based elimination. The strength comes from a uniﬁcation operation
which is necessary to the former but unnecessary to the latter. On the other
hand, weakness comes from (model generation) inferences which are necessary
to the latter but unnecessary to the former.
In 5522 CNF problem, 562 problems are reduced by pure literal elimination.
This indicates that c-abstraction is applicable to more problems than pure literal
elimination. The average elimination time is 4.49 seconds for 562 problems. More
than 85% of the problems are reduced within one second for each, while 38
problems needs more than ten seconds for reducing. Pure literal elimination
takes more time than c-abstraction does on average. This is caused by the task
of uniﬁcation.
Table 5 (a) shows the numbers of problems reduced by pure literal elimination
for every problem domain. Table 5 (b) shows the ratio of remaining clauses to

76
M. Koshimura, M. Umeda, and R. Hasegawa
Table 5. Pure literal elimination
(a) Domain
ALG
0/15
ANA
3/21
BOO
0/133
CAT
1/62
COL 13/193
COM
2/8
FLD
0/279
GEO
6/253
GRA
0/1
GRP 13/791
HAL
0/0
HEN
0/67
HWC
0/6
HWV
6/83
KRS
0/17
LAT
0/104
LCL
0/527
LDA
0/23
MGT
4/78
MSC
0/13
NLP 142/258
NUM
0/315
PLA
1/32
PUZ
11/82
RNG
0/104
ROB
0/38
SET
2/706
SWC
0/423
SWV
0/21
SYN 358/839
TOP
0/24
(b) Ratio(%)
0-9
18
10-19
4
20-29
3
30-39
5
40-49
2
50-59
13
60-69
27
70-79
43
80-89
98
90-99 350
(c) Eﬀect
DCTP 1.31
Vampire 7.0
E 0.82
ALL
before
after
before
after
before
after
Attempted
562
Solved
509
510
485
485
507
509
Av. Time(s)
6.98 6.77(11.63)
7.10 6.70(8.25)
4.82 13.37(18.15)
the original ones. There are 350 problems which are in the ratio from 90% to
99%. This is 3 times as many as those of c-abstraction (cf. Table 2). We may
say that the clause elimination eﬀect of c-abstraction is generally stronger than
that of pure literal elimination.
Table 5 (c) shows the summaries of pure literal elimination eﬀects on the
provers. A little eﬀect can be seen on the performance of the provers. Indeed,
there is no change in terms of problems solved within 600 seconds after prepro-
cessing for Vampire. The inﬂuence of pure literal elimination upon the perfor-
mance of these provers is weaker than that of c-abstraction.
There are 752 problems which are reduced by c-abstraction based elimina-
tion or pure literal elimination. They can be classiﬁed into 4 groups by the set
inclusion relation as follows: (1) A is a proper subset of B, (2) A equals B, (3)
A is a proper superset of B, and (4) there is no set inclusion relation between A
and B, where A is a problem (i.e. a set of clauses) reduced by c-abstraction base
elimination and B is a problem reduced by pure literal elimination. There are
333 problems in the ﬁrst group, 182 in the second, 62 in the third, and 175 in the
fourth. This indicates that pure literal elimination is diﬀerent from c-abstraction.
And it seems reasonable to suppose that the latter gains the ascendancy over
the former with respect to clause elimination.
By the way, it is possible to apply pure literal elimination after c-abstraction.
Our experiment shows that only simple problems are further reduced by pure
literal elimination after c-abstraction. Thus, pure literal elimination after c-
abstraction has no inﬂuence upon the performance of DCTP, Vampire, and E.

Abstract Model Generation for Preprocessing Clause Sets
77
4.4
C-Abstraction Combined with D-Abstraction
Among 725 problems reduced by c-abstraction, there are 87 problems which are
determined as satisﬁable by d-abstraction. We don’t need to prove these prob-
lems anymore. Is is natural to combine c-abstraction with d-abstraction. Table
6 shows the summary of c-abstraction eﬀects on the remaining 638 problems.
The parenthetic number in the “after” column shows the cpu time including
c-abstraction and d-abstraction.
Table 6. Eﬀect of C-abstraction on problems passed through d-abstraction
DCTP 1.31
Vampire 7.0
E 0.82
ALL
before
after
before
after
before
after
Attempted
638
Solved
556
560
565
567
585
583
Av. Time(s)
7.06 5.86(10.83)
8.86 8.71(10.09)
5.97 13.10(17.87)
There is a positive eﬀect on DCTP. The number of problems solved is in-
creased from 556 to 560 and the average cpu time is decreased from 7.06 seconds
to 5.86 seconds. For Vampire, c-abstraction barely has a positive eﬀect. The
number of problems solved is increased from 565 to 567, but the average cpu
time is almost unchaged. Unfortunately, there is a negative eﬀect on E. The
number of problems solved is decreased from 585 to 583 and the average cpu
time is increased from 5.97 seconds to 13.10 seconds.
5
Conclusion
Preprocessing a set of clauses has a great impact on the success of a subsequent
automated reasoning system. We have introduced two abstractions of the given
clause set for preprocessing it. Experimental results show that these abstrac-
tions are eﬀective for several problems. 29% of satisﬁable ﬁrst-order problems
in TPTP are determined as satisﬁable with their d-abstract clause sets. 13% of
CNF problems in TPTP are reduced with d-abstraction.
C-abstraction sometimes has positive eﬀects and sometimes negative eﬀects
on state-of-the-art theorem provers: DCTP, Vampire, and E. As a whole, without
d-abstraction, these provers proﬁt from c-abstraction. On the other hand for
the problems passed through d-abstraction, DCTP and Vampire proﬁt from
c-abstraction, but E does not. This situation may be improved if we ﬁnd a
combination of the provers’ options that ﬁt for c-abstraction. Furthermore, the
combination of the proposed method and other preprocessing operations can
enhance their abilities.

78
M. Koshimura, M. Umeda, and R. Hasegawa
Acknowledgement
This research was partially supported by Grant-in-Aid for Scientiﬁc Research
(No. A-15200002) from the Ministry of Education, Culture, Sports, Science and
Technology of Japan.
References
1. Fran¸cois Bry and Adnan Yahya.
Positive Unit Hyperresolution Tableaux and
Their Application to Minimal Model Generation. Journal of Automated Reasoning,
25:35–82, 2000.
2. Marc Fuchs and Dirk Fuchs. Abstraction-Based Relevancy Testing for Model Elim-
ination. In Harald Ganzinger, editor, CADE-16, volume 1632 of LNAI, pages 344–
358. Springer, July 1999.
3. Fausto Giunchiglia and Toby Walsh. A theory of abstraction. Artiﬁcial Intelligence,
57:323–389, 1992.
4. Craig A. Knoblock, Josh D. Tenenberg, and Qiang Yang. Characterizing Abstrac-
tion Hierarchies for Planing. In Proceedings of the Ninth National Conference on
Artiﬁcial Intelligence, pages 692–697. AAAI Press, 1991.
5. Miyuki Koshimura and Ryuzo Hasegawa.
Proof Simpliﬁcation for Model Gen-
eration and Its Applications.
In Michel Parigot and Andrei Voronkov, editors,
LPAR2000, volume 1955 of LNAI, pages 96–113. Springer, November 2000.
6. Rainer Manthey and Fran¸cois Bry. SATCHMO: a theorem prover implemented
in Prolog. In E. Lusk and R. Overbeek, editors, CADE-9, volume 310 of LNCS,
pages 415–434. Springer, May 1988.
7. David A. Plaisted.
Theorem Proving with Abstraction.
Artiﬁcial Intelligence,
16:47–108, 1981.
8. David A. Plaisted and Adnan Yahya. A relevance restriction strategy for automated
deduction. Artiﬁcial Intelligence, 144:59–93, 2003.
9. Alexandre Riazanov and Andrei Voronkov.
The design and implementation of
VAMPIRE. AI Communications, 15(2):91–110, 2002.
10. Earl D. Sacerdoti. Planning in a Hierarchy of Abstraction Spaces. Artiﬁcial Intel-
ligence, 5:115–135, 1974.
11. Stephan Schulz. E - a brainiac theorem prover. AI Communications, 15(2):111–126,
2002.
12. Gernot Stenz. DCTP 1.2 - System Abstract. In Uwe Egly and Christian G. Fern-
muller, editors, TABLEAUX-2002, volume 2381 of LNAI, pages 335–340. Springer,
2002.
13. G. Sutcliﬀe and C.B. Suttner. The TPTP Problem Library: CNF Release v1.2.1.
Journal of Automated Reasoning, 21(2):177–203, 1998.
14. G. Sutcliﬀe and C.B. Suttner. The TPTP Problem Library for Automated Theo-
rem Proving. http://www.cs.miami.edu/~tptp/, 2004.
15. GeoﬀSutcliﬀe and Stuart Melville. The Practice of Clausiﬁcation in Automatic
Theorem Proving. South African Computer Journal, 18:57–68, 1996.
16. GeoﬀSutcliﬀe and Christian Suttner. The CADE ATP System Competition. In
David Basin and Micha¨el Rusinowitch, editors, IJCAR 2004, volume 3097 of LNAI,
pages 490–491. Springer, July 2004.
17. Neng-Fa Zhou. B-Prolog User’s Manual (Version 6.6). http://www.probp.com,
2004.

Flat and One-Variable Clauses: Complexity of Verifying
Cryptographic Protocols with Single Blind Copying
Helmut Seidl and Kumar Neeraj Verma
Institut f¨ur Informatik, TU M¨unchen, Germany
{seidl,verma}@in.tum.de
Abstract. Cryptographic protocols with single blind copying were deﬁned and
modeled by Comon and Cortier using the new class C of ﬁrst order clauses,
which extends the Skolem class. They showed its satisﬁability problem to be in
3-DEXPTIME. We improve this result by showing that satisﬁability for this class
is NEXPTIME-complete, using new resolution techniques. We show satisﬁability
to be DEXPTIME-complete if clauses are Horn, which is what is required for
modeling cryptographic protocols. While translation to Horn clauses only gives a
DEXPTIME upper bound for the secrecy problem for these protocols, we further
show that this secrecy problem is actually DEXPTIME-complete.
1
Introduction
Several researchers have pursued modeling of cryptographic protocols using ﬁrst order
clauses [3,6,15] and related formalisms like tree automata and set constraints[5,11,12].
While protocol insecurity is NP-complete in case of a bounded number of sessions [14],
this is helpful only for detecting some attacks. For certifying protocols, the number of
sessions cannot be bounded, although we may use other safe abstractions. The approach
using ﬁrst order clauses is particularly useful for this class of problems. A common safe
abstraction is to allow a bounded number of nonces, i.e. random numbers, to be used in
inﬁnitely many sessions. Security however still remains undecidable [5]. Hence further
restrictions are necessary to obtain decidability.
Inthisdirection,ComonandCortier[6,8]proposedthenotionofprotocolswithsingle
blind copying. Intuitively this restriction means that agents are allowed to copy at most
one piece of data blindly in any protocol step, a restriction satisﬁed by most protocols
in the literature. Comon and Cortier modeled the secrecy problem for these protocols
using the new class C of ﬁrst order clauses, which extends the Skolem class, and showed
satisﬁability for C to be decidable [6] in 3-DEXPTIME [8]. The NEXPTIME lower
bound is easy. We show in this paper that satisﬁability of this class is in NEXPTIME, thus
NEXPTIME-complete. If clauses are restricted to be Horn, which sufﬁces for modeling
of cryptographic protocols, we show that satisﬁability is DEXPTIME-complete (again
the lower bound is easy). While translation to clauses only gives a DEXPTIME upper
bound for the secrecy problem for this class of protocols, we further show that the secrecy
problem for these protocols is also DEXPTIME-complete.
For proving our upper bounds, we introduce several variants of standard ordered
resolution with selection and splitting [2]. Notably we consider resolution as consisting
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 79–94, 2005.
c⃝Springer-Verlag Berlin Heidelberg 2005

80
H. Seidl and K.N. Verma
of instantiation of clauses, and of generation of propositional implications. This is in the
style of Ganzinger and Korovin [10], but we enhance this approach, and generate in-
teresting implications to obtain optimal complexity. More precisely, while the approach
of Ganzinger and Korovin [10] has a single phase of instantiation followed by proposi-
tional satisﬁability checking, we generate certain interesting propositional implications,
instantiate them, and iterate the process. We further show how this technique can be em-
ployed also in presence of rules for replacement of literals in clauses, which obey some
ordering constraints. To deal with the notion of single blind copying we show how terms
containing a single variable can be decomposed into simple terms whose uniﬁers are of
very simple forms. As byproducts, we obtain optimal complexity for several subclasses
of C, involving so called ﬂat and one-variable clauses.
Outline: We start in Section 2 by recalling basic notions about ﬁrst order logic and
resolution reﬁnements. In Section 3 we introduce cryptographic protocols with sin-
gle blind copying, discuss their modeling using the class C of ﬁrst order clauses, and
show that their secrecy problem is DEXPTIME-hard. To decide the class C we start
with the subclass of one-variable clauses in Section 4 and show its satisﬁability to be
DEXPTIME-complete. Satisﬁability of the fragment of C involving ﬂat clauses is shown
to NEXPTIME-complete in Section 5. In Section 6, the techniques from the two cases
are combined with further ideas to show that satisﬁability for C is NEXPTIME-complete.
In Section 7 we adapt this proof to show that satisﬁability for the Horn fragment of C is
DEXPTIME-complete.
2
Resolution
We recall standard notions from ﬁrst order logic. Fix a signature Σ of function symbols
each with a given arity, and containing at least one zero-ary symbol. Let r be the maximal
arity of function symbols in Σ. Fix a set X = {x1, x2, x3, . . .} of variables. Note that
x1, x2, . . . (in bold face) are the actual elements of X, where as x, y, z, x1, y1, . . . are
used to represent arbitrary elements of X. The set TΣ(X) of terms built from Σ and X
is deﬁned as usual. TΣ is the set of ground terms, i.e. those not containing any variables.
Atoms A are of the form P(t1, . . . , tn) where P is an n-ary predicate and ti’s are terms.
Literals L are either positive literals +A (or simply A) or negative literals −A, where
A is an atom. −(−A) is another notation for A. ± denotes + or −and ∓denotes the
opposite sign (and similarly for notations ±′, ∓′, . . .). A clause is a ﬁnite set of literals.
A negative clause is one which contains only negative literals. If M is any term, literal or
clause then the set fv(M) of variables occurring in them is deﬁned as usual. If C1 and C2
are clauses then C1∨C2 denotes C1∪C2. C∨{L} is written as C∨L (In this notation, we
allow the possibility of L ∈C). If C1, . . . , Cn are clauses such that fv(Ci)∩fv(Cj) = ∅
for i ̸
= j, and if Ci is non-empty for i ≥2, then the clause C1 ∨. . . ∨Cn is also
written as C1 ⊔. . . ⊔Cn to emphasize this property. Ground literals and clauses are
ones not containing variables. A term, literal or clause is trivial if it contains no function
symbols. A substitution is a function σ : X →TΣ(X). Ground substitutions map
every variable to a ground term. We write σ = {x1 
→t1, . . . , xn 
→tn} to say that
xiσ = ti for 1 ≤i ≤n and xσ = x for x /∈{x1, . . . , xn}. If M is a term, literal,
clause, substitution or set of such objects, then the effect Mσ of applying σ to M is

Flat and One-Variable Clauses: Complexity of Verifying Cryptographic Protocols
81
deﬁned as usual. Renamings are bijections σ : X →X. If M is a term, literal, clause
or substitution, then a renaming of M is of the form Mσ for some renaming σ, and an
instance of M is of the form Mσ for some substitution σ. If M and N are terms or
literals then a uniﬁer of M and N is a substitution σ such that Mσ = Nσ. If such a
uniﬁer exists then there is also a most general uniﬁer (mgu), i.e. a uniﬁer σ such that
for every uniﬁer σ′ of M and N, there is some σ′′ such that σ′ = σσ′′. Most general
uniﬁers are unique upto renaming: if σ1 and σ2 are two mgus of M and N then σ1 is
a renaming of σ2. Hence we may use the notation mgu(M, N) to denote one of them.
We write M[x1, . . . , xn] to say that fv(M) ⊆{x1, . . . , xn}. If t1, . . . , tn are terms
then M[t1, . . . , tn] denotes M{x1 
→t1, . . . , xn 
→tn}. If N is a set of terms them
M[N] = {M[t1, . . . , tn] | t1, . . . , tn ∈N}. If M is a set of terms, atoms, literals or
clauses them M[N] = 
m∈M m[N]. A Herbrand interpretation H is a set of ground
atoms. A clause C is satisﬁed in H if for every ground substitution σ, either A ∈H
for some A ∈Cσ, or A /∈H for some −A ∈Cσ. A set S of clauses is satisﬁed in H
if every clause of S is satisﬁed in H. If such a H exists then S is satisﬁable, and H is
a Herbrand model of S. A Horn clause is one containing at most one positive literal.
If a set of Horn clauses is satisﬁable then it has a least Herbrand model wrt the subset
ordering.
Resolution and its reﬁnements are well known methods for testing satisﬁability of
clauses. Given a strict partial order < on atoms, a literal ±A is maximal in a clause
C if there is no literal ±′B ∈C with A < B. Binary ordered resolution and ordered
factorization wrt ordering < are deﬁned by the following two rules respectively:
C1 ∨A
−B ∨C2
C1σ ∨C2σ
C1 ∨±A ∨±B
C1σ ∨Aσ
where σ = mgu(A, B) in both rules, A and B are maximal in the left and right premises
respectively of the ﬁrst rule, and A and B are both maximal in the premise of the second
rule. We rename the premises of the ﬁrst rule before resolution so that they don’t share
variables. The ordering < is stable if: whenever A1 < A2 then A1σ < A2σ for all
substitutions σ. We write S ⇒< S ∪{C} to say that C is obtained by one application of
the binary ordered resolution or binary factorization rule on clauses in S (the subscript
denotes the ordering used).
Another resolution rule is splitting. This can be described using tableaux. A tableau
is of the form S1 | . . . | Sn, where n ≥0 and each Si, called a branch of the tableau, is
a set of clauses (the | operator is associative and commutative). A tableau is satisﬁable
if at least one of its branches is satisﬁable. The tableau is called closed if each Si
contains the empty clause, denoted 2. The splitting step on tableaux is deﬁned by the
rule: T | S →spl T | (S \ {C1 ⊔C2}) ∪{C1} | (S \ {C1 ⊔C2}) ∪{C2} whenever
C1 ⊔C2 ∈S and C1 and C2 are non-empty. C1 and C2 are called components of the
clause C1 ⊔C2 being split. It is well known that splitting preserves satisﬁability of
tableaux. We may choose to apply splitting eagerly, or lazily or in some other fashion.
Hence we deﬁne a splitting strategy to be a function f such that T →spl f(T ) for all
tableaux T . The relation ⇒< is extended to tableaux as expected. Ordered resolution
with splitting strategy is then deﬁned by the following rule: T1 ⇒<,f f(T2) if T1 ⇒< T2.
This provides us with a well known sound and complete method for testing satisﬁability.

82
H. Seidl and K.N. Verma
For any binary relation R, R∗will denote the reﬂexive transitive closure of R, and R+
will denote the transitive closure of R.
Lemma 1 ([2]). For any set S of clauses, for any stable ordering <, and for any splitting
strategy f, S is unsatisﬁable iff S ⇒∗
<,f T for some closed T .
If all predicates are zero-ary then the resulting clauses are propositional clauses.
In this case we write S ⊨p T to say that every Herbrand model of S is a Herbrand
model of T. This notation will also be used when S and T are sets of ﬁrst order clauses,
by treating every (ground or non-ground) atom as a zero-ary predicate. For example
{P(a), −P(a)} ⊨p 2 but {P(x), −P(a)} ⊭p 2. S ⊨p {C} is also written as S ⊨p C.
If S ⊨p C then clearly Sσ ⊨p Cσ for all substitution σ.
3
Cryptographic Protocols
We assume that Σ contains the binary functions { } and ⟨, ⟩denoting encryption and
pairing. Messages are terms of TΣ(X). A state is of the form S(M1, . . . , Mn) where
S with arity n is from a ﬁnite set of control points and Mi are messages. It denotes
an agent at control point S with messages Mi in its memory. An initialization state
is a state not containing variables. A protocol rule is of the form S1(M1, . . . , Mm) :
recv(M) →S2(N1, . . . , Nn) : send(N). Here Mi, Nj are messages, and M and N are
each either a message, or a dummy symbol ? indicating nothing is received (resp. sent).
For secrecy analysis we can replace ? by some public message, i.e. one which is known to
everyone including the adversary. The rule says that an agent in state S1(M1, . . . , Mm)
can receive message M, send a message N, and then move to state S2(N1, . . . , Nn),
thus also modifying the messages in its memory. A protocol is a ﬁnite set of initialization
states and protocol rules. This model is in the style of [9] and [5]. The assumption of
single blind copying then says that each protocol rule contains at most one variable
(which may occur anywhere any number of times in that rule). For example, the public-
key Needham-Schroeder protocol below
A →B : {A, NA}KB
B →A : {NA, NB}KB
A →B : {NB}KB
is written in our notation as follows. For every pair of agents A and B in our system
(ﬁnitely many of them sufﬁce for ﬁnding all attacks against secrecy [7,6]) we have two
noncesN 1
AB andN 2
AB tobeusedinsessionswhereAplaystheinitiator’sroleandB plays
the responder’s role. We have initialization states Init0(A, N 1
AB) and Resp0(B, N 2
AB)
for all agents A and B. Corresponding to the three lines in the protocol we have rules
for all agents A and B:
Init0(A, N 1
AB):recv(?)
→
Init1(A, N 1
AB):send({⟨A, N 1
AB⟩}KB)
Resp0(B, N 2
AB):recv({⟨A, x⟩}KB)
→Resp1(B, x, N 2
AB):send({⟨x, N 2
AB⟩}KA)
Init1(A, N 1
AB):recv({⟨N 1
AB, x⟩}KA)→Init2(A, N 1
AB, x):send({x}KB)
Resp1(B, x, N 2
AB):recv({N 2
AB}KB)
→Resp2(B, x, N 2
AB):send(?)
Any initialization state can be created any number of times and any protocol rule
can be executed any number of times. The adversary has full control over the net-
work: all messages received by agents are actually sent by the adversary and all mes-

Flat and One-Variable Clauses: Complexity of Verifying Cryptographic Protocols
83
sages sent by agents are actually received by the adversary. The adversary can ob-
tain new messages from messages he knows, e.g. by performing encryption and de-
cryption. To model this using Horn clauses, we create a unary predicate reach to
model reachable states, and a unary predicate known to model messages known to
the adversary. The initialization state S(M1, . . . , Mn) is then modeled by the clause
reach(S(M1, . . . , Mn)), where S is a new function symbol we create. The protocol rule
S1(M1, . . . , Mm) : recv(M) →S2(N1, . . . , Nn) : send(N) is modeled by the clauses
known(N) ∨−reach(S1(M1, . . . , Mm)) ∨−known(M) and reach(S2(N1, . . . , Nn))
∨−reach(S1(M1, . . . , Mm)) ∨−known(M). Under the assumption of single blind
copying it is clear that all these clauses are one-variable clauses, i.e. clauses con-
taining at most one variable. We need further clauses to express adversary capabil-
ities. The clauses known({x1}x2) ∨−known(x1) ∨−known(x2) and known(x1) ∨
−known({x1}x2) ∨−known(x2) express the encryption and decryption abilities of the
adversary. We have similar clauses for his pairing and unpairing abilities, as well as
clauses known(f(x1, . . . , xn)) ∨−known(x1) ∨. . . ∨−known(xn) for any function f
that the adversary knows to apply. All these are clearly ﬂat clauses, i.e. clauses of the form
C = k
i=1 ±iPi(fi(xi
1, . . . , xi
ni))∨l
j=1 ±jQj(xj), where {xi
1, . . . , xi
ni} = fv(C) for
1 ≤i ≤k. Asymmetric keys, i.e. keys K such that message {M}K can only be de-
crypted with the inverse key K−1, are also easily dealt with using ﬂat and one-variable
clauses. The adversary’s knowledge of other data c like agent’s names, public keys, etc
are expressed by clauses known(c). Then the least Herbrand model of this set of clauses
describes exactly the reachable states and the messages known to the adversary. Then
to check whether some message M remains secret, we add the clause −known(M) and
check whether the resulting set is satisﬁable.
A set of clauses is in the class V1 if each of its members is a one-variable clause. A
set of clauses is in the class F if each of its members is a ﬂat clause. More generally we
have the class C proposed by Comon and Cortier [6,8]: a set of clauses S is in the class
C if for each C ∈S one of the following conditions is satisﬁed:
– C is a one-variable clause
– C = k
i=1 ±iPi(ui[fi(xi
1, . . . , xi
ni)]) ∨l
j=1 ±jQj(xj), where for 1 ≤i ≤k we
have {xi
1, . . . , xi
ni} = fv(C) and ui contains at most one variable.
If all clauses are Horn then we have the corresponding classes V1Horn, FHorn and
CHorn. Clearly the classes V1 (resp. V1Horn) and F (resp. FHorn) are included in the
class C (resp. CHorn) since the ui’s above can be trivial. Conversely any clause set in C
can be considered as containing just ﬂat and one-variable clauses. This is because we can
replace a clause C ∨±P(u[f(x1, . . . , xn)]) by the clause C ∨±Pu(f(x1, . . . , xn)) and
add clauses −Pu(x) ∨P(u[x]) and Pu(x) ∨−P(u[x]) where Pu is a fresh predicate.
This transformation takes polynomial time and preserves satisﬁability of the clause set.
Hence now we need to deal with just ﬂat and one-variable clauses. In the rest of the
paper we derive optimal complexity results for all these classes.
Still this only gives us an upper bound for the secrecy problem of protocols since
the clauses could be more general than necessary. It turns out, however, that this is not
the case. In order to show this we rely on a reduction of the reachability problem for
alternating pushdown systems (APDS). In form of Horn clauses, an APDS is a ﬁnite set of
clauses of the form (i) P(a) where a is a zero-ary symbol, (ii) P(s[x])∨−Q(t[x]) where

84
H. Seidl and K.N. Verma
s and t involve only unary function symbols, and (iii) P(x) ∨−P1(x) ∨−P2(x). Given
such an APDS S, a ground atom P(t) is reachable if P(t) is in the least Herbrand model
of S, i.e. if S ∪{−P(t)} is unsatisﬁable. Reachability in APDS is DEXPTIME-hard [4].
We encode this problem into secrecy of protocols, as in [9]. Let K be a (symmetric) key
not known to the adversary. Encode atoms P(t) as messages {⟨P, t⟩}K, by treating P
as some data. Create an initialization state S (no message is stored in the state). Clause
(i) is translated as S : recv(?) →S : send({⟨P, a⟩}K). Clause (ii) is translated as
S : recv({⟨Q, t[x]⟩}K) →S : send({⟨P, s[x]⟩}K). Clause (iii) is translated as S : recv
(⟨{⟨P1, x⟩}K, {⟨P2, x⟩}K⟩) →S : send({⟨P, x⟩}K). The intuition is that the adversary
cannot decrypt messages encrypted with K. He also cannot encrypt messages with K.
He can only forward messages which are encrypted with K. However he has the ability
to pair messages. This is utilized in the translation of clause (iii). Then a message {M}K
is known to the adversary iff M is of the form ⟨P, t⟩and P(t) is reachable in the APDS.
Theorem 1. Secrecy problem for cryptographic protocols with single blind copying,
with bounded number of nonces but unbounded number of sessions is DEXPTIME-hard,
even if no message is allowed to be stored at any control point.
4
One Variable Clauses: Decomposition of Terms
We ﬁrst show that satisﬁability for the classes V1 and V1Horn is DEXPTIME-complete.
Note that although we consider only unary predicates, this is no restriction in the case
of one-variable clauses, since we can encode atoms P(t1, . . . , tn) as P ′(fn(t1 . . . , tn))
for fresh P ′ and fn for every P of arity n. As shown in [6,8], ordered resolution on
one-variable clauses, for a suitable ordering, leads to a linear bound on the height of
terms produced. This does not sufﬁce for obtaining a DEXPTIME upper bound and
we need to examine the forms of uniﬁers produced during resolution. We consider
terms containing at most one variable (call them one-variable terms) to be compositions
of simpler terms. A non-ground one-variable term t[x] is called reduced if it is not
of the form u[v[x]] for any non-ground non-trivial one-variable terms u[x] and v[x].
The term f(g(x), h(g(x))) for example is not reduced because it can be written as
f(x, h(x))[g(x)]. The term f ′(x, g(x), a) is reduced. Unifying it with the reduced term
f ′(h(y), g(h(a)), y) produces ground uniﬁer {x 
→h(y)[a], y 
→a} and both h(y) and
a are strict subterms of the given terms. Indeed we ﬁnd:
Lemma 2. Let s[x] and t[y] be reduced, non-ground and non-trivial terms where x ̸
= y
and s[x] ̸
= t[x]. If s and t have a uniﬁer σ then xσ, yσ ∈U[V ] where U is the set of
non-ground (possibly trivial) strict subterms of s and t, and V is the set of ground strict
subterms of s and t.
In case both terms (even if not reduced) have the same variable we have the following
easy result:
Lemma 3. Let σ be a uniﬁer of two non-trivial, non-ground and distinct one-variable
terms s[x] and t[x]. Then xσ is a ground strict subterm of s or of t.

Flat and One-Variable Clauses: Complexity of Verifying Cryptographic Protocols
85
In the following one-variable clauses are simpliﬁed to involve only reduced terms.
Lemma 4. Any non-ground one-variable term t[x] can be uniquely written as t[x] =
t1[t2[. . . [tn[x]] . . .]] where n ≥0 and each ti[x] is non-trivial, non-ground and reduced.
This decomposition can be computed in time polynomial in the size of t.
Above and elsewhere, if n = 0 then t1[t2[. . . [tn[x]] . . .]] denotes x. Now if a clause
set contains a clause C = C′ ∨±P(t[x]), with t[x] being non-ground, if t[x] =
t1[. . . [tn[x]] . . .] where each ti is non-trivial and reduced, then we create fresh predicates
Pt1 . . . ti for 1 ≤i ≤p −1 and replace C by the clause C′ ∨±Pt1 . . . tn−1(tn[x]).
Also we add clauses Pt1 . . . ti(ti+1[x]) ∨−Pt1 . . . ti+1(x) and −Pt1 . . . ti(ti+1[x]) ∨
Pt1 . . . ti+1(x) for 0 ≤i ≤n −2 to our clause set. Note that the predicates Pt1 . . . ti
are considered invariant under renaming of terms tj. For i = 0, Pt1 . . . ti is same as
P. Our transformation preserves satisﬁability of the clause set. By Lemma 4 this takes
polynomial time and eventually all non-ground literals in clauses are of the form ±P(t)
with reduced t. Next if the clause set is of the form S∪{C1∪C2}, where C1 is non-empty
and has only ground literals, and C2 is non-empty and has only non-ground literals, then
we do splitting to produce S ∪{C1} | S ∪{C2}. This process produces at most expo-
nentially many branches each of which has polynomial size. Now it sufﬁces to decide
satisﬁability of each branch in DEXPTIME. Hence now we assume that each clause is
either:
(Ca) a ground clause, or
(Cb) a clause containing exactly one variable, each of whose literals is of the form
±P(t[x]) where t is non-ground and reduced.
Consider a set S of clauses of type Ca and Cb. We show how to decide satisﬁability of
the set S. Wlog we assume that all clauses in S of type Cb contain the variable x1. Let
Ng be the set of non-ground terms t[x1] occurring as arguments in literals in S. Let Ngs
be the set of non-ground subterms t[x1] of terms in Ng. We assume that Ng and Ngs
always contain the trivial term x1, otherwise we add this term to both sets. Let G be
the set of ground subterms of terms occurring as arguments in literals in S. The sizes
of Ng, Ngs and G are polynomial. Let S† be the set of clauses of type Ca and Cb which
only contain literals of the form ±P(t) for some t ∈Ng ∪Ng[Ngs[G]] (observe that
G ⊆Ngs[G] ⊆Ng[Ngs[G]]). The size of S† is at most exponential.
For resolution we use ordering ≺: P(s) ≺Q(t) iff s is a strict subterm of t. We
call ≺the subterm ordering without causing confusion. This is clearly stable. This is the
ordering that we are going to use throughout this paper. In particular this means that if
a clause contains literals ±P(x) and ±′Q(t) where t is non-trivial and contains x, then
we cannot choose the literal ±P(x) to resolve upon in this clause. Because of the simple
form of uniﬁers of reduced terms we have:
Lemma 5. Binary ordered resolution and ordered factorization, wrt the subterm order-
ing, on clauses in S† produces clauses which are again in S† (upto renaming).
Hence to decide satisﬁability of S ⊆S†, we keep generating new clauses of S†
by doing ordered binary resolution and ordered factorization wrt the subterm ordering
till no new clause can be generated, and then check whether the empty clause has been
produced. Also recall that APDS consist of Horn one-variable clauses. Hence:
Theorem 2. Satisﬁability for the classes V1 and V1Horn is DEXPTIME-complete.

86
H. Seidl and K.N. Verma
5
Flat Clauses: Resolution Modulo Propositional Reasoning
NextweshowhowtodecidetheclassF ofﬂatclausesinNEXPTIME.Thisiswellknown
when the maximal arity r is a constant, or when all non-trivial literals in a clause have
the same sequence (instead of the same set) of variables. But we are not aware of a proof
of NEXPTIME upper bound in the general case. We show how to obtain NEXPTIME
upper bound in the general case, by doing resolution modulo propositional reasoning.
While this constitutes an interesting result of its own, the techniques allow us to deal
with the full class C efﬁciently. Also this shows that the generality of the class C does
not cost more in terms of complexity. An ϵ-block is a one-variable clause which contains
only trivial literals. A complex clause C is a ﬂat clause k
i=1 ±iPi(fi(xi
1, . . . , xi
ni)) ∨
l
j=1 ±jQj(xj) in which k ≥1. A ﬂat clause is either a complex clause, or an ϵ-clause
which is deﬁned to be a disjunction of ϵ-blocks, i.e. to be of the form C1[x1]⊔. . .⊔Cn[xn]
where each Ci is an ϵ-block. ϵ-clauses are difﬁcult to deal with, hence we split them to
produce ϵ-blocks. Hence deﬁne ϵ-splitting as the restriction of the splitting rule in which
one of the components is an ϵ-block.
Recall that r is the maximal arity of symbols in Σ. Any complex clause C can be
renamed to make it good i.e. such that fv(C) ⊆Xr = {x1, . . . , xr}. An ϵ-block C
can be renamed to make it good i.e. of the form C[xr+1]. The choice of xr+1 is not
crucial. Now notice that ordered resolution between complex clauses and ϵ-blocks only
produces ﬂat clauses, which can then be split to be left with only complex and ϵ-blocks.
E.g. Resolution between P1(x1) ∨−P2(x2) ∨P3(f(x1, x2)) ∨−P4(g(x2, x1)) and
P4(g(x1, x1))∨−P5(h(x1))∨P6(x1) produces P1(x1)∨−P2(x1)∨P3(f(x1, x1))∨
−P5(h(x1)) ∨P6(x1). Resolution between P2(xr+1) and −P2(f(x1, x2)) ∨P3(x1) ∨
P4(x2) produces P3(x1) ∨P4(x2) which can then be split. The point is that we always
choose a non-trivial literal from a clause for resolution, if there is one. As there are ﬁnitely
many complex clauses and ϵ-blocks this gives us a decision procedure. Note however
that the number of complex clauses is doubly exponential. This is because we allow
clauses of the form P1(f1(x1, x1, x2)) ∨P2(f2(x2, x1)) ∨P3(f3(x2, x1, x2)) ∨..., i.e.
the nontrivial terms contain arbitrary number of repetitions of variables in arbitrary order.
The number of such variable sequences of r variables is exponentially many, hence the
number of clauses is doubly exponential. Letting the maximal arity r to be a constant,
or forcing all non-trivial literals in a clause to have the same variable sequence would
have produced only exponentially many clauses. In presence of splitting, this would
have given us the well-known NEXPTIME upper bound, which is also optimal. But we
are not aware of a proof of NEXPTIME upper bound in the general case. To obtain
NEXPTIME upper bound in the general case we introduce the technique of resolution
modulo propositional reasoning.
For a clause C, deﬁne the set of its projections as π(C) = C[Xr]. Essentially projec-
tion involves making certain variables in a clause equal. As we saw, resolution between
two complex clauses amounts to propositional resolution between their projections. De-
ﬁne the set U = {f(x1, . . . , xn) | f ∈Σ and each xi ∈Xr} of size exponential in
r. Resolution between ϵ-block C1 and a good complex clause C2 amounts to proposi-
tional resolution of a clause from C[U] with C2. Also note that propositional resolution
followed by further projection is equivalent to projection followed by propositional res-

Flat and One-Variable Clauses: Complexity of Verifying Cryptographic Protocols
87
olution. Each complex clause has exponentially many projections. This suggests that
we can compute beforehand the exponentially many projections of complex clauses
and exponentially many instantiations of ϵ-blocks. All new complex clauses generated
by propositional resolution are ignored. But after several such propositional resolution
steps, we may get an ϵ-clause, which should then be split and instantiated and used
for obtaining further propositional resolvents. In other words we only compute such
propositionally implied ϵ-clauses, do splitting and instantiation and iterate the process.
This generates all resolvents upto propositional implication. The difference from the
approach of Ganzinger and Korovin [10] is that they have a single phase of instantiation
followed by propositional satisﬁability checking. In contrast, we compute certain inter-
esting propositional implications which are further instantiated, and iterate the process.
We now formalize our approach.
For a set S of clauses, let comp(S) be the set of complex clauses in S, eps(S) be
the set of ϵ-blocks in S, π(S) = 
C∈S π(C) and I(S) = S ∪π(comp(S))∪eps(S)[U].
For sets S and T of complex clauses and ϵ-blocks, write S ⊑T to mean that:
– if C is a complex clause in S then I(T) ⊨p π(C), and
– every ϵ-block in S can be renamed as some C[xr+1] ∈T.
For tableaux T1 and T2 involving only complex clauses and ϵ-blocks we write T1 ⊑T2
if T1 can be written as S1 | . . . | Sn and T2 can be written as T1 | . . . | Tn (note same
n) such that Si ⊑Ti for 1 ≤i ≤n. Intuitively T2 is a succinct representation of T1.
Deﬁne the splitting strategy f as the one which repeatedly applies ϵ-splitting on a tableau
as long as possible. The relation ⇒≺,f provides us a sound and complete method for
testing unsatisﬁability. We deﬁne the alternative procedure for testing unsatisﬁability
by using succinct representations of tableaux. We deﬁne ▶by the rule: T | S ▶T |
S ∪{C1[xr+1]} | . . . | S ∪{Ck[xr+1]} whenever I(S) ⊨p C = C1[xi1]⊔. . .⊔Ck[xik],
C is an ϵ-clause, and 1 ≤i1, . . . , ik ≤r. Then ▶simulates ⇒≺,f:
Lemma 6. If S is a set of complex clauses and ϵ-blocks, S ⊑T and S ⇒≺,f T , then
all clauses occurring in T are complex clauses or ϵ-blocks and T ▶∗T ′ for some T ′
such that T ⊑T ′.
Hence we have completeness of ▶:
Lemma 7. If a set S of good complex clauses and ϵ-blocks is unsatisﬁable then S ▶∗T
for some closed T .
Proof. By Lemma 1, S ⇒∗
≺,f S1 | . . . | Sn such that each Si ∋2. Since all complex
clauses and ϵ-blocks in S are good, we have S ⊑S. Hence by Lemma 6, we have some
T1, . . . , Tn such that S ▶∗T1 | . . . | Tn and Si ⊑Ti for 1 ≤i ≤n. Since 2 ∈Si and
2 is an ϵ-block, hence 2 ∈Ti for 1 ≤i ≤n.
⊓⊔
Call a set S of good complex clauses and ϵ-blocks saturated if the following condition
is satisﬁed: if I(S) ⊨p B1[xi1] ⊔. . . ⊔Bk[xik] with 1 ≤i1, . . . , ik ≤r, each Bi being
an ϵ-block, then there is some 1 ≤j ≤k such that Bj[xr+1] ∈S.
Lemma 8. If S is a satisﬁable set of good complex clauses and ϵ-blocks then S ▶∗T | T
for some T and some saturated set T of good complex clauses and ϵ-blocks, such that
2 /∈T.

88
H. Seidl and K.N. Verma
Proof. We construct a sequence S = S0 ⊆S1 ⊆S2 ⊆. . . of good complex clauses
and ϵ-blocks such that Si is satisﬁable and Si ▶∗Si+1 | Ti for some Ti for each i.
S = S0 is satisﬁable by assumption. Now assume we have already deﬁned S0, . . . , Si
and T0, . . . , Ti−1. Let Cl = Bl
1[xil
1] ⊔. . . ⊔Bl
k[xil
kl ] for 1 ≤l ≤N be all the possible
ϵ-clauses such that I(Si) ⊨p Cl, 1 ≤il
1, . . . , il
kl ≤r. Since Si is satisﬁable, Si ∪{Cl |
1 ≤l ≤N} is satisﬁable. Since xil
1, . . . , xil
kl are mutually distinct for 1 ≤l ≤N,
there are 1 ≤jl ≤kl for 1 ≤l ≤N such that Si ∪{Bl
jl[xil
jl ] | 1 ≤l ≤N} is
satisﬁable. Let Si+1 = Si ∪{Bl
jl[xr+1] | 1 ≤l ≤N}. Si+1 is satisﬁable. Also it is
clear that Si ▶∗Si+1 | Ti for some Ti. If Si+1 = Si then Si is saturated, otherwise Si+1
has strictly more ϵ-blocks. As there are only ﬁnitely many good ϵ-blocks, eventually we
will end up with a saturated set T in this way. Since T is satisﬁable, 2 /∈T. From
construction it is clear that there is some T such that S ▶∗T | T.
⊓⊔
Theorem 3. Satisﬁability for the class F is NEXPTIME-complete.
Proof. The lower bound comes from reduction of satisﬁability of positive set constraints
whichisNEXPTIME-complete[1].FortheupperboundletS beaﬁnitesetofﬂatclauses.
Repeatedly apply ϵ-splitting to obtain f(S) = S1 | . . . | Sm. S is satisﬁable iff some
Si is satisﬁable. The number m of branches in f(S) is at most exponential. Also each
branch has size linear in the size of S. We non-deterministically choose some Si and
check its satisﬁability in NEXPTIME.
Hence wlog we may assume that the given set S has only complex clauses and ϵ-
blocks. Wlog all clauses in S are good. We non-deterministically choose a certain number
of good ϵ-blocks B1[xr+1], . . . , BN[xr+1] and check that T = S1 ∪{B1[xr+1], . . . ,
BN[xr+1]} is saturated and 2 /∈T. By Lemma 8, if S is satisﬁable then clearly there is
such a set T. Conversely if there is such a set T, then whenever T ▶∗T , we will have
T = T | T ′ for some T ′. Hence we can never have T ▶∗T where T is closed. Then
by Lemma 7 we conclude that T is satisﬁable. Hence S ⊆T is also satisﬁable.
Guessing the set T requires non-deterministically choosing from among exponen-
tially many ϵ-blocks. To check that T is saturated, for every ϵ-clause C = B1[xi1] ⊔
. . .⊔Bk[xik], with 1 ≤i1, . . . , ik ≤r, and Bj[xr+1] /∈T for 1 ≤j ≤k, we check that
I(T) ⊭p C, i.e. I(T)∪¬C is propositionally satisﬁable (where ¬(L1 ∨. . .∨Ln) denotes
{−L1, . . . , −Ln}). This can be checked in NEXPTIME since propositional satisﬁability
can be checked in NPTIME. We need to do such checks for at most exponentially many
possible values of C.
⊓⊔
6
Combination: Ordered Literal Replacement
Combining ﬂat and one-variable clauses creates additional difﬁculties. First observe
that resolving a one variable clause C1 ∨±P(f(s1[x], . . . , sn[x])) with a complex
clause ∓P(f(x1, . . . , xn)) ∨C2 produces a one-variable clause. If si[x] = sj[x] for all
xi = xj, and if C2 contains a literal P(xi) then the resolvent contains a literal P(si[x]).
The problem now is that even if f(s1[x], . . . , sn[x]) is reduced, si[x] may not be reduced.
E.g. f(g(h(x)), x) is reduced but g(h(x)) is not reduced. Like in Section 4 we may think
of replacing this literal by simpler literals involving fresh predicates. Firstly we have to

Flat and One-Variable Clauses: Complexity of Verifying Cryptographic Protocols
89
ensure that in this process we would not generate inﬁnitely many predicates. Secondly
it is not clear that mixing ordered resolution steps with replacement of literals is still
complete. Correctness is easy to show since the new clause is in some sense equivalent to
the old deleted clause. However deletion of clauses arbitrarily can violate completeness
of the resolution procedure. The key factor which preserves completeness is that we
replace literals by smaller literals wrt the given ordering <.
Formally a replacement rule is of the form A1 →A2 where A1 and A2 are (not
necessarily ground) atoms. The clause set associated with this rule is {A1∨−A2, −A1∨
A2}. Intuitively such a replacement rule says that A1 and A2 are equivalent. The clause
set cl(R) associated with a set R of replacement rules is the union of the clause sets
associated with the individual replacement rules in R. Given a stable ordering < on
atoms, a replacement rule A1 →A2 is ordered iff A2 < A1. We deﬁne the relation
→R as: S →R (S \ {±A1σ ∨C}) ∪{±A2σ ∨C} whenever S is a set of clauses,
±A1σ ∨C ∈S, A1 →A2 ∈R and σ is some substitution. Hence we replace literals
in a clause by smaller literals. The relation is extended to tableaux as usual. This is
reminiscent of the well-studied case of resolution with some equational theory on terms.
There, however, the ordering < used for resolution is compatible with the equational
theory and one essentially works with the equivalence classes of terms and atoms. This
is not the case here.
Next note that in the above resolution example, even if f(s1[x], . . . , sn[x]) is non-
ground, some si may be ground. Hence the resolvent may have ground as well as non-
ground literals. We avoided this in Section 4 by initial preprocessing. Now we may
think of splitting these resolvents during the resolution procedure. This however will be
difﬁcult to simulate using the alternative resolution procedure on succinct representations
of tableaux because we will generate doubly exponentially many one-variable clauses.
To avoid this we use a variant of splitting called splitting-with-naming [13]. Instead of
creating two branches after splitting, this rule puts both components into the same set,
but with tags to simulate branches produced by ordinary splitting. Fix a ﬁnite set P of
predicate symbols. P-clauses are clauses whose predicates are all from P. Introduce fresh
zero-ary predicates C for P-clauses C modulo renaming, i.e. C1 = C2 iff C1σ = C2
for some renaming σ. Literals ±C for P-clauses C are splitting literals. The splitting-
with-naming rule is deﬁned as: S →nspl (S \ {C1 ⊔C2}) ∪{C1 ∨−C2, C2 ∨C2}
where C1 ⊔C2 ∈S, C2 is non-empty and has only non-splitting literals, and C1 has at
least one non-splitting literal. Intuitively C2 represents the negation of C2. We will use
both splitting and splitting-with-naming according to some predeﬁned strategy. Hence
for a ﬁnite set Q of splitting atoms, deﬁne Q-splitting as the restriction of the splitting-
with-naming rule where the splitting atom produced is restricted to be from Q. Call this
restricted relation as →Q−nspl. This is extended to tableaux as usual. Now once we have
generated the clauses C1 ∨−C2 and C2 ∨C2 we would like to keep resolving on the
second part of the second clause till we are left with the clause C2 (possibly with other
positive splitting literals) which would then be resolved with the ﬁrst clause to produce
C1 (possibly with other positive splitting literals) and only then the literals in C1 would
be resolved upon. Such a strategy cannot be ensured by ordered resolution, hence we
introduce a new rule. An ordering < over non-splitting atoms is extended to the ordering
<s by letting q <s A whenever q is a splitting atom and A is a non-splitting atom,

90
H. Seidl and K.N. Verma
and A <s B whenever A, B are non-splitting atoms and A < B. We deﬁne modiﬁed
ordered binary resolution by the following rule:
C1 ∨A
−B ∨C2
C1σ ∨C2σ
where σ = mgu(A, B) and the following conditions are satisﬁed:
(1) C1 has no negative splitting literal, and A is maximal in C1.
(2) (a) either B ∈Q, or
(b) C2 has no negative splitting literal, and B is maximal in C2.
As usual we rename the premises before resolution so that they don’t share variables.
This rule says that we must select a negative splitting literal to resolve upon in any
clause, provided the clause has at least one such literal. If no such literal is present in the
clause, then the ordering <s enforces that a positive splitting literal will not be selected
as long as the clause has some non-splitting literal. We write S ⇛<s S ∪{C} to say
that C is obtained by one application of the modiﬁed binary ordered resolution or the
(unmodiﬁed) ordered factorization rule on clauses in S. This is extended to tableaux as
usual. A Q-splitting-replacement strategy is a function f such that T (→Q−nspl ∪→spl
∪→R)∗f(T ) for any tableaux T . Hence we allow both normal splitting and Q-splitting.
Modiﬁed ordered resolution with Q-splitting-replacement strategy f is deﬁned by the
relation: S ⇛<s,f,R f(T) whenever S ⇛<s T. This is extended to tableaux as usual.
The above modiﬁed ordered binary resolution rule can be considered as an instance
of ordered resolution with selection [2], which is known to be sound and complete
even with splitting and its variants. Our manner of extending < to <s is essential for
completeness. We now show that soundness and completeness hold even under arbitrary
ordered replacement strategies. It is not clear if such rules have been studied elsewhere.
Wlog we forbid the useless case of replacement rules containing splitting symbols. The
relation < is enumerable if the set of all ground atoms can be enumerated as A1, A2, . . .
such that if Ai < Aj then i < j. The subterm ordering is enumerable.
Theorem 4. Modiﬁed ordered resolution, wrt a stable and enumerable ordering, with
Q-splitting and ordered literal replacement is sound and complete for any strategy. I.e.
for any set S of P-clauses, for any strict stable and enumerable partial order < on atoms,
for any set R of ordered replacement rules, for any ﬁnite set Q of splitting atoms, and
for any Q-splitting-replacement strategy f, S ∪cl(R) is unsatisﬁable iff S ⇛∗
<s,f,R T
for some closed T .
For the rest of this section ﬁx a set S of one-variable P-clauses and complex P-clauses
whose satisﬁability we need to decide. Let Ng be the set of non-ground terms occurring
as arguments in literals in the one-variable clauses of S. We rename all terms in Ng to
contain only the variable xr+1. Wlog assume xr+1 ∈Ng. Let Ngs be the set of non-
ground subterms of terms in Ng, and Ngr = {s[xr+1] | s is non-ground and reduced,
and for some t, s[t] ∈Ngs}. Deﬁne Ngrr = {s1[. . . [sm] . . .] | s1[. . . [sn] . . .] ∈Ngs,
m ≤n, and each si is non-trivial and reduced}. Deﬁne the set of predicates Q = {Ps |
P ∈P, s ∈Ngrr}. Note that P ⊆Q. Deﬁne the set of replacement rules R =
{Ps1 . . . sm−1(sm[xr+1]) →Ps1 . . . sm([xr+1]) | Ps1 . . . sm ∈Q}. They are clearly
ordered wrt ≺. Let G be the set of ground subterms of terms occurring as arguments in
literals in S. For the rest of this section the set of splitting atoms that we are going to use is

Flat and One-Variable Clauses: Complexity of Verifying Cryptographic Protocols
91
Q0 = {±P(t) | P ∈P, t ∈G}. Their purpose is to remove ground literals from a non-
ground clause. All sets deﬁned above have polynomial size. We also need the set Ngr1 =
{xr+1}∪{f(s1, . . . , sn) | ∃g(t1, . . . , tm) ∈Ngr·{s1, . . . , sn} = {t1, . . . , tm}} which
has exponential size. These terms are produced by resolution of non-ground one-variable
clauses with complex clauses, and are also reduced. In the ground case we have the set
G1 = {f(s1, . . . , sn) | ∃g(t1, . . . , tm) ∈G | {s1, . . . , sn} = {t1, . . . , tm}} of expo-
nential size. For a set P′ of predicates and a set U of terms, the set P′[U] of atoms is
deﬁned as usual. For a set V of atoms the set −V and ±V of literals is deﬁned as usual.
The following types of clauses will be required during resolution:
C1 clauses C ∨D, where C is an ϵ-block with predicates from Q, and D ⊆±Q0.
C2 clauses C ∨D where C is a one-variable clause with literals from ±Q(Ngr1), C
has at least one non-trivial literal, and D ⊆±Q0.
C3 clausesC∨D whereC isanon-emptyclausewithliteralsfrom±Q(Ngr1[Ngrr[G1]]),
and D ⊆±Q0.
C4 clauses C ∨D where C = k
i=1 ±iPi(fi(xi
1, . . . , xi
ni)) ∨l
j=1 ±jQj(xj) is a
complex clause with each Pi ∈Q, each Qj ∈P and D ⊆±Q0
We have already argued why we need splitting literals in the above clauses, and why
we need Ngr1 instead of Ngr in type C2. In type C3 we have Ngrr in place of the set Ngs
that we had in Section 4, to take care of interactions between one-variable clauses and
complex clauses. In type C4 the trivial literals involve predicates only from P (and not
Q). This is what ensures that we need only ﬁnitely many fresh predicates (those from
Q \ P) because these are the literals that are involved in replacements when this clause
is resolved with a one-variable clause. The Q0-splitting steps that we use in this section
consist of replacing a tableau T | S by the tableau T | (S \{C ∨L})∪{C ∨−L, L∨L},
where C is non-ground, L ∈±P(G) and C ∨L ∈S. The replacement steps we are
going to use are of the following kind:
(1) replacing clause C1[x] = C ∨±P(t1[. . . [tn[s[x]]] . . .]) by clause C2[x] = C ∨
±Pt1 . . . tn(s[x])} where P ∈P, s[xr+1] ∈Ngr is non-trivial, and t1[. . . [tn] . . .] ∈
Ngrr. We have {C1[xr+1]} ∪cl(R)[Ngrr] ⊨p C2[xr+1].
(2) replacing ground clause C1 = C ∨±P(t1[. . . [tn[g]] . . .]) by clause C2 = C ∨
±Pt1 . . . tn[g]} where P ∈P, g ∈Ngrr[G1] and t1[. . . [tn] . . .] ∈Ngrr. This replace-
ment is done only when t1[. . . [tn[g]] . . .] ∈Ngrr[Ngrr[G1]] \ Ngr1[Ngrr[G1]]. We have
{C1} ∪cl(R)[Ngrr[Ngrr[G1]]] ⊨p C2.
Deﬁne the Q0-splitting-replacement strategy f as one which repeatedly applies ﬁrst
ϵ-splitting, then the above Q0-splitting steps, then the above two replacement steps till
no further change is possible. Then ⇛≺s,f,R gives us a sound and complete method for
testing unsatisﬁability.
As in Section 5 we now deﬁne a succinct representation of tableaux and an alternative
resolution procedure for them. As we said, a literal L ∈Q0 represents −L. Hence for
a clause C we deﬁne C as the clause obtained by replacing every ±L by the literal
∓L. This is extended to sets of clauses as usual. As before U = {f(x1, . . . , xn) | f ∈
Σ, and each xi ∈Xr}. The functions eps and comp of Section 5 are now extended to
return ϵ-blocks and complex clauses respectively, possibly in disjunction with splitting
literals. For a set S of clauses, deﬁne ov(S) as the set of clauses of type C2 in S. The
function π is as before. We need to deﬁne which kinds of instantiations are to be used

92
H. Seidl and K.N. Verma
to generate propositional implications. For a clause C, deﬁne I1(C) = {C} ∪C[U] ∪
C[U[Ngrr∪Ngrr[Ngrr[G1]]]]∪C[Ngr1]∪C[Ngr1[Ngrr[G1]]]. These are the instantiations
necessary for ϵ-blocks. Deﬁne I2(C) = {C}∪C[Ngrr[G1]]. These are necessary for one-
variable clauses. Deﬁne I3(C) = {C}. Ground clauses require no instantiation. Deﬁne
I4(C) = π(C) ∪C[Ngrr ∪[Ngrr[Ngrr[G1]]]]. These are necessary for complex clauses.
For a set S of clauses, deﬁne Ii(S) = 
C∈S Ii(C). For a set S of clauses of type C1-C4
deﬁne I(S) = S∪I1(eps(S))∪I2(ov(S))∪I4(comp(S))∪cl(R)[Ngrr∪Ngrr[Ngrr[G1]]].
Note that instantiations of clauses in cl(R) are necessary for the replacement rules, as
argued above. For a set T of clauses deﬁne the following properties:
(P1T ) C satisﬁes property P1T iff C[xr+1] ∈T.
(P2T ) C satisﬁes property P2T iff I(T) ⊨p I2(C[xr+1]).
(P3T ) C satisﬁes property P3T iff I(T) ⊨p I3(C).
(P4T ) C satisﬁes property P4T iff I(T) ⊨p I4(C).
For sets of clauses S and T, deﬁne S ⊑T to mean that every C ∈S is of type
Ci and satisﬁes property PiT for some 1 ≤i ≤4. This is extended to tableaux as
usual. The alternative resolution procedure for testing unsatisﬁability by using succinct
representations of tableaux is now deﬁned by the rule: T | S ▶T | S∪{C1[xr+1]⊔D} |
S ∪{C2[xr+1]} | . . . | S ∪{Ck[xr+1]} whenever I(S) ⊨p C1[xi1]⊔. . .⊔Ck[xik]⊔D,
each Ci is an ϵ-block, 1 ≤i1, . . . , ik ≤r and D ⊆±Q0. The simulation property now
states:
Lemma 9. If S ⊑T and S ⇛≺s,f,R T then T ▶∗T ′ for some T ′ such that T ⊑T ′.
Hence as for ﬂat clauses we obtain:
Theorem 5. Satisﬁability for the class C is NEXPTIME-complete.
7
The Horn Case
We show that in the Horn case, the upper bound can be improved to DEXPTIME.
The essential idea is that propositional satisﬁability of Horn clauses is in PTIME in-
stead of NPTIME. But now we need to eliminate the use of tableaux altogether. To
this end, we replace the ϵ-splitting rule of Section 6 by splitting-with-naming. Ac-
cordingly we deﬁne the set of splitting atoms as Q = Q0 ∪Q1 where Q1 = {C |
C is a non-empty negative ϵ−block with predicates from P}. We know that binary res-
olution and factorization on Horn clauses produces Horn clauses. Replacements on
Horn clauses using the rules from R produces Horn clauses. Q1-splitting on Horn
clauses produces Horn clauses. E.g. clause P(x1) ∨−Q(x1) ∨−R(x2) produces
P(x1)∨−Q(x1)∨−−R(x2) and −R(x2)∨−R(x2). Q0-splitting on P(f(x))∨−Q(a)
produces P(f(x1)) ∨−−Q(a) and −Q(a) ∨−Q(a) which are Horn. However Q0-
splitting on C = −P(f(x1)) ∨Q(a) produces C1 = −P(f(x1)) ∨−Q(a) and C2 =
Q(a) ∨Q(a). C2 is not Horn. However C1 = C and C2 = −Q(a) ∨Q(a) are Horn. Fi-
nally, as Q1 has exponentially many atoms, we must restrict their occurrences in clauses.
Accordingly, for 1 ≤i ≤4, deﬁne clauses of type Ci’ to be of the form C∨E where C is
of type Ci, E ⊆±Q1, C ∨E is Horn and E has at most r negative literals (C is deﬁned
as before, hence it leaves atoms from Q1 unchanged). Now the Q-splitting-replacement

Flat and One-Variable Clauses: Complexity of Verifying Cryptographic Protocols
93
strategy f ﬁrst applies Q1-splitting as long as possible, then applies Q0-splitting as long
as possible and then applies the replacement steps of Section 6 as long as possible. Suc-
cinct representations are now deﬁned as: S ⊑T iff for each C ∈S, C is of type Ci’
and satisﬁes PiT for some 1 ≤i ≤4. The abstract resolution procedure is deﬁned as:
T ▶T ∪{B1[xr+1]∨−q2∨. . .∨−qk⊔D⊔E}∪{qi∨Bi[xr+1] | 2 ≤i ≤k} whenever
I(T) ⊨p C, C = B1[xi1] ⊔. . . ⊔Bk[xik] ⊔D ⊔E, C is Horn, 1 ≤i1, . . . , ik ≤r,
B1 is an ϵ-block, Bi is a negative ϵ-block and qi = Bi for 2 ≤i ≤k, D ⊆±Q0 and
E ⊆±Q1 such that if k = 1 then E has at most r negative literals, and if k > 1 then E
has no negative literal.
Lemma 10. If S ⊑T and S ⇛≺s,f,R S′ then T ▶∗T ′ for some T ′ such that S′ ⊑T ′.
Now for deciding satisﬁability of a set of ﬂat and one-variable clauses we proceed
as in the non-Horn case. But now instead of non-deterministically adding clauses, we
compute a sequence S = S0 ▶S1 ▶S2 . . . starting from the given set S, till no more
clauses can be added, and then check whether 2 has been generated. The length of this
sequence is at most exponential. Computing Si+1 from Si requires at most exponential
time because the number of possibilities for C in the deﬁnition of ▶above is exponential.
(Note that this idea of Q1-splitting would not have helped in the non-Horn case because
we cannot bound the number of positive splitting literals in a clause in the non-Horn
case, whereas Horn clauses by deﬁnition have at most one positive literal). Also note
that APDS can be encoded using ﬂat Horn clauses. Hence:
Theorem 6. Satisﬁability for the classes CHorn and FHorn is DEXPTIME-complete.
Together with Theorem 1, this gives us optimal complexity for protocol veriﬁcation:
Theorem 7. Secrecy of cryptographic protocols with single blind copying, with bounded
number of nonces but unbounded number of sessions is DEXPTIME-complete.
8
Conclusion
We proved DEXPTIME-hardness of secrecy for cryptographic protocols with single
blind copying, and improved the upper bound from 3-DEXPTIME to DEXPTIME. We
improved the 3-DEXPTIME upper bound for satisﬁability for the class C to NEXP-
TIME in the general case and DEXPTIME in the Horn case, which match known lower
bounds. For this we invented new resolution techniques like ordered resolution with
splitting modulo propositional reasoning, ordered literal replacements and decomposi-
tions of one-variable terms. As byproducts we obtained optimum complexity for several
fragments of C involving ﬂat and one-variable clauses. Security for several other decid-
able classes of protocols with unbounded number of sessions and bounded number of
nonces is in DEXPTIME, suggesting that DEXPTIME is a reasonable complexity class
for this class of protocols.

94
H. Seidl and K.N. Verma
References
1. A. Aiken, D. Kozen, M. Vardi, and E. Wimmers. The complexity of set constraints. In CSL’93,
pages 1–17. Springer-Verlag LNCS 832, 1993.
2. L. Bachmair and H. Ganzinger. Resolution theorem proving. In Handbook of Automated
Reasoning, volume I, chapter 2, pages 19–99. North-Holland, 2001.
3. B. Blanchet. An efﬁcient cryptographic protocol veriﬁer based on Prolog rules. In CSFW’01,
pages 82–96. IEEE Computer Society Press, 2001.
4. A. K. Chandra, D. C. Kozen, and L. J. Stockmeyer. Alternation. Journal of the ACM, 28(1),
1981.
5. H. Comon and V. Cortier. Tree automata with one memory, set constraints and cryptographic
protocols. Theoretical Computer Science, 2004. To appear.
6. H. Comon-Lundh and V. Cortier. New decidability results for fragments of ﬁrst-order logic
andapplicationtocryptographicprotocols. InRTA’03,pages148–164.Springer-VerlagLNCS
2706, 2003.
7. H. Comon-Lundh and V. Cortier. Security properties: Two agents are sufﬁcient. In ESOP’03,
pages 99–113. Springer-Verlag LNCS 2618, 2003.
8. V. Cortier. V´eriﬁcation Automatique des Protocoles Cryptographiques. PhD thesis, ENS
Cachan, France, 2003.
9. N. A. Durgin, P. Lincoln, J. Mitchell, and A. Scedrov. Undecidability of bounded security
protocols. In FMSP’99, Trento, Italy, 1999.
10. H. Ganzinger and K. Korovin. New directions in instantiation-based theorem proving. In
LICS’01, pages 55–64. IEEE Computer Society Press, 2003.
11. J. Goubault-Larrecq, M. Roger, and K. N. Verma. Abstraction and resolution modulo AC:
How to verify Difﬁe-Hellman-like protocols automatically. Journal of Logic and Algebraic
Programming, 2004. To Appear. Available as Research Report LSV-04-7, LSV, ENS Cachan.
12. D. Monniaux. Abstracting cryptographic protocols with tree automata. In SAS’99, pages
149–163. Springer-Verlag LNCS 1694, 1999.
13. A. Riazanov and A. Voronkov. Splitting without backtracking. In IJCAI’01, pages 611–617,
2001.
14. M. Rusinowitch and M. Turuani. Protocol insecurity with ﬁnite number of sessions is NP-
complete. In CSFW’01. IEEE Computer Society Press, 2001.
15. C. Weidenbach. Towards an automatic analysis of security protocols. In CADE’99, pages
378–382. Springer-Verlag LNAI 1632, 1999.

Applications of
General Exact Satisﬁability in
Propositional Logic Modelling
Vilhelm Dahll¨of⋆
Dept. of Computer and Information Science
Link¨oping University
SE-581 83 Link¨oping, Sweden
vilda@ida.liu.se
Abstract. There is a trend to study extended variants of propositional
logic which have explicit means to represent cardinality constraints. That
is accomplished using so-called c-atoms. We show that c-atoms can be
eﬃciently reduced to a general form of Exact Satisﬁability. The general
xisat problem is to ﬁnd an assignment for a CNF such that exactly i
literals are true in each clause for any i ≥1. We show that this prob-
lem is solvable in time O(1.4143n) (where n is the number of variables)
regardless of i if we allow exponential space. For polynomial space, we
present an algorithm solving xisat for all i strictly better than the triv-
ial O(2n) bound. For i = 2, i = 3 and i = 4 we obtain upper time
bounds in O(1.5157n), O(1.6202n) and O(1.6844n), respectively. We also
present a dedicated x2sat algorithm running in polynomial space and
time O(1.4511n).
1
Introduction
Propositional logic can be used to model and compute a plethora of problems.
Typically one constructs a theory such that its models encode solutions to the
problem of interest. Recently there has been a dramatic improvement in the
performance of programs for ﬁnding models, see e.g. [15,18,10]. However, most
of these programs are sat-solvers, restricting their input to instances of the
satisﬁability problem. That raises at least two issues:
1. It forces the formulation of unnecessarily large theories even for quite simple
constraints.
2. To exactly solve sat one must deploy exponential-time algorithms where
no other base than 2 is known. While several ways trying to work around
this have been proposed such as incomplete solvers using randomized and/or
heuristic methods, fact remains that sat has a very diﬃcult structure.
⋆The research is supported by CUGS – National Graduate School in Computer Sci-
ence, Sweden.
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 95–109, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

96
V. Dahll¨of
As for the ﬁrst issue, several extensions to the basic language have been pro-
posed such as equality, pseudo boolean constraints and c-atoms, see e.g. [13,5,1].
We will return to the c-atoms later.
The second issue makes it clear that it would be desirable to ﬁnd another less
hard problem capable of expressing interesting theories. Such a problem would
by necessity be NP-hard. However, it might have a structure allowing faster
algorithms than sat. In this paper we will focus on one such candidate.
One well-studied variant of sat is Exact Satisfiability, x1sat (sometimes
denoted just xsat), which asks for an assignment such that exactly one literal
is true in every clause. It is NP-complete, even when restricted to clauses of
maximum length 3 (a problem called x13sat or one-in-three sat), see [9]. It
is closely related to problems such as Exact Hitting Set and has sometimes
been treated in connection with these, see [7]. Exact algorithms for x1sat and
x13sat have been presented by several authors [6,8,11,16,4,3]. The so-far best
algorithms by Byskov et al. [3] have running times in O(1.1003n) (for x13sat)
and O(1.1748n) (for x1sat). Note that x13sat in earlier papers usually was
denoted X3SAT.
A natural extension of x1sat is the problem xisat, asking if a formula allows
an assignment to the variables such that exactly i literals are true in each clause.
In the context of propositional logic modelling, xisat is of interest when it comes
to means to represent cardinality constraints. Such extensions have been studied
by e.g. [14,5,2,19]. They accomplish the extension using so-called cardinality
atoms (although the author of [19] does not use the name, he does use the
concept). A cardinality atom is an expression k{a1, . . . , an}m, where a1, . . . , an
are boolean variables and the expression is true iﬀat least k and no more than
m of the ai’s are true. One way to handle the cardinality atoms is by compiling
(reducing) them into ordinary sat clauses and then using sat-solvers. Liu and
Truszczy´nski [14] describe two possible reductions. First a method that does not
introduce any new variables but increases the number of clauses exponentially.
They dismiss this technique: “This approach . . . is practical only if k and m are
small (do not exceed, say 2). Otherwise the size . . . quickly gets too large for sat
solvers to be eﬀective.” They also present a second method that does not have
this problem. However, the reduction more than doubles the number of variables.
Rather than compiling the c-atoms away, Liu and Truszczy´nski investigates the
possibility of keeping them and then applying an incomplete search method. In
eﬀect, they deal with a formula having diﬀerent kinds of clauses (ordinary sat
clauses as well as diﬀerent kinds of c-atoms).
Note that an xisat clause (a1 ∨a2 . . . an) is not just a special case of the
c-atom h{a1, a2 . . . an}i. If we add the new variable b into the xisat clause,
then ﬁnding a model for the modiﬁed clause (b ∨a1 ∨a2 . . . an) is tantamount to
ﬁnding a satisfying assignment for the c-atom i−1{a1, a2 . . . an}i. Repeating the
procedure, we obtain a transformation that is more eﬃcient than transforming
to sat, as this reduction introduces i −h new variables. Also, we see that xisat
well captures interesting properties of c-atoms. We hope that the algorithms and

General Exact Satisﬁability
97
tools presented here will facilitate a better utilization of the c-atoms in practice
as well as enhancing our theoretical understanding of these constraints.
This paper will show that xisat is solvable in time O(1.4143n), where n
is the number of variables, if a space consumption in O(1.1893n) is allowed.
This method is an application of a general algorithm for a special class of NP-
complete problems described by Schroeppel and Shamir [17]. While of theoretical
interest, showing that the running time does not necessarily depend upon i, the
use of exponential space is of course highly undesirable. For practical use, in the
context of c-atoms, we present a branch-and-bound algorithm with polynomial
space requirements that obtains a running time considerably better than the
trivial O(2n) bound.
In the following presentation we ﬁrst give some preliminaries and deﬁnitions.
Section 3 presents some features of the language xisat. Then follows Section 4
which presents and analyzes exact algorithms for deciding xisat in polynomial
space. Section 5 shows how to deal with xisat using exponential space. Con-
clusions and a brief discussion about our results and possible future research
directions are given in Section 6.
2
Preliminaries
A propositional variable (or variable for short) has either the value true or false.
A literal is a variable p or its negation ¯p. The literal p is true iﬀthe corresponding
variable p has the value true and ¯p is true iﬀthe corresponding variable p has
the value false. A clause is a number of literals connected by logical or (∨). The
length of a clause x, denoted |x|, is the number of literals in it. We will sometimes
need a sub-clause notation in this way: (a∨b∨C), such that C = c0 ∨. . .∨cn is a
disjunction of one or more literals. In the following, literals will be indicated by
lower-case letters and sub-clauses by upper-case letters. A formula is a sequence
of clauses connected by logical and (∧). Var(F) for a formula F denotes the set
of variables of F. The degree of c, denoted δ(c), is the number of clauses that
contain either c or ¯c. If δ(c) = 1 we call c a singleton. If δ(c) ≥3 we say that c
is heavy.
Substitution of a by δ in the formula F is denoted F(a/δ); the notation
F(a/δ; b/γ) indicates repeated substitution: F(a/δ)(b/γ) (ﬁrst a is replaced and
then b). We will assume that the substitution operation also takes care of some
trivial simpliﬁcations such as replacing the occurence of a ∨¯a in a clause with
true. F(B/false), where B is a disjunction of literals, means that every literal
of B is replaced by false. For a given disjunction of literals B = a ∨b ∨¯c . . ., ¯B
is the inversion of B, i.e., ¯B = ¯a ∨¯b ∨c . . ..
F = (a ∨b ∨c) ∧(¯a ∨b ∨d) ∧(¯c ∨d)
M = {a, b, ¯c, d}
Fig. 1. An instance F of x2sat and a model M of F

98
V. Dahll¨of
The Exact i Satisﬁability Problem (xisat) for a formula is to ﬁnd an assign-
ment to the variables such that exactly i literals are true in each clause. Such
an assignment is known as a model. Given a formula F, an assignment to the
variables is inconsistent if any clause has no true literal (it is unsatisﬁed) or
more than i true literals (it is over-satisﬁed). Figure 1 shows a formula in x2sat
and a model for it. The languages x1sat, x2sat, x3sat etc. are referred to as
sublanguages of xisat. Note that xisat is not the language L = {F | such that
there is a truth assignment for F making the same number of literals true in
every clause}, but rather, L = ∞
i=1 xisat.
In the branch-and-bound algorithm for xisat to be presented later, the recur-
sive decomposition will create various kinds of constraints represented as clauses,
that is, when setting the variables of a clause, other clauses will be aﬀected. For
instance, the clause (a ∨b ∨c ∨d)x2sat, which requires two true literals to be
satisﬁed, will become (a ∨b ∨c)x1sat if d is set to true. When there are dif-
ferent types of clauses in a formula, we say that it is mixed. Depending on how
many true literals a clause needs to be satisﬁed we will use notations such as
(a ∨b ∨c ∨d)x2sat and the like.
For terms such as NP-completeness etc., the reader is referred to [9]. The
notation p1 ≤p
m p2 means that there exists a polynomial transformation from
the problem p1 to the problem p2.
When analyzing the running time of the algorithms, we will encounter re-
currences of the form T(n) ≤k
i=1 T(n −ri) + poly(n). They satisfy T(n) ∈
O(τ(r1, . . . , rk)n) where τ(r1, . . . , rk) is the largest, real-valued root of the func-
tion
f(x) = 1 −
k

i=1
x−ri
(1)
see [12]. Since this bound does not depend on the polynomial factor poly(n),
we ignore all polynomial-time calculations. Let R = k
i=1 ri and then note
that due to the nature of the function f(x) = 1 −k
i=1 x−ri, the smallest
possible real-valued root (and hence the best running time) will appear when
each ri is as close to R/k as possible, i.e., when the decrease of size of the
instance is balanced through the branches. Say for instance that R = 4, k = 2.
Then τ(1, 3) = τ(3, 1) ≈1.4656 and τ(2, 2) ≈1.4142. We will refer to this as
the balanced branching eﬀect. We will use the shorthand notation τ(rk . . .) for
τ(r, r . . . r
  
k
, . . .), e.g., τ(52, 33) for τ(5, 5, 3, 3, 3).
3
Properties of the xisat Problem
The xisat problem is obviously NP-complete since x1sat ≤p
m xisat: any oc-
currence of the literal a is replaced by i occurences. The reduction gives a hint
that xisat might be harder to solve for higher i, which indeed seems to be the

General Exact Satisﬁability
99
case for polynomial space algorithms. Surprisingly, this does not hold for the
exponential space algorithm to be presented.
One property of xisat that will prove useful in the following algorithms is
given in this lemma:
Lemma 1. A formula F, where each variable occurs at most twice, can be re-
duced in polynomial time to a formula F ′, such that F ′ ∈x1sat iﬀF ∈xisat,
the number of variables is increased only by a polynomial amount and each vari-
able in F ′ occurs at most twice.
Proof. For clarity of presentation we consider a special case, namely the clause
x = (a ∨b ∨c ∨d)x2sat which we want to transfer into x1sat clauses. As any
pair of the literals may be both false, both true or one true and one false
in any combination, they cannot appear in the same x1sat clause. A possible
solution is this reduction from x:
(¯a ∨k ∨l)x1sat
(k ∨m ∨o ∨q)x1sat
(¯b ∨m ∨n)x1sat (l ∨n ∨p ∨r)x1sat
(¯c ∨o ∨p)x1sat
( ¯d ∨q ∨r)x1sat
It is straightforward to verify that this construction works and is extendible to
other exact constraints and clause lengths.
The following is needed in the main algorithm for xisat:
Corollary 1. For a formula F where each variable occurs at most twice, it is
polynomial time decidable whether F ∈xisat.
The corollary follows from Lemma 1 and the fact that for a formula F where
each variable occurs at most twice, one can apply polynomial-time matching
techniques to see whether there is an x1sat model. These techniques were ﬁrst
described by Porschen et al. in [16] in the context of x13sat. They can easily be
extended to general x1sat formulae, see e.g. [4].
In [7] Drori and Peleg introduced the name canonization for all the various
polynomial time pruning rules that can be applied to an instance of x1sat. For
example, a clause (a ∨b)x1sat ∈F implies that one of a and b, but not both,
must be true, and so F can be replaced by F(a/¯b). Some of these rules extend
to xisat, other not. We here present the ones used in this paper. It is straight-
forward to see that they can be performed in polynomial time and that they do
not change the xisat satisﬁability when applied to a formula F.
1. Pick an xisat clause with i + k singletons. Remove k singletons.
2. Pick a clause (a ∨b)x1sat, remove it and let F := F(a/¯b)
3. Pick an xisat clause A such that |A| = i. Remove it and let F := F(aj/true)
for all literals aj of A.
4. Pick two clauses (a∨b∨A)x1sat and (¯a∨b∨B)x1sat and let F := F(b/false)
5. For two xisat clauses (A) and (A ∨B) let F := F(B/false)

100
V. Dahll¨of
6. If there are two clauses x = (A ∨B)x2sat and y = (A ∨¯B)x2sat, such that
|B| mod 2 = 1 or |B| > 4, then let F := {∅}
7. If there are two clauses x = (A ∨b ∨c)x2sat and y = (A ∨¯b ∨¯c)x2sat, then
let F := F(b/¯c)
8. For two xisat clauses (a ∨A) and (A ∨b), let F := F(a/b)
9. If there are two clauses (a ∨A ∨b)x2sat and (¯a ∨A ∨c)x2sat, then let
F := F(b/¯c)
10. If there are two clauses (a ∨b ∨A ∨c)x2sat and (¯a ∨¯b ∨A ∨d)x2sat, then
let F := F(c/ ¯d)
11. If there are two clauses (a∨b∨c∨d∨e∨A)x2sat and (¯a∨¯b∨¯c∨¯d∨¯e∨B)x2sat,
then let F := {∅}
12. If there are two clauses (a ∨b ∨c ∨d ∨A)x2sat and (¯a ∨¯b ∨¯c ∨¯d ∨B)x2sat,
then let F := F(A/false; B/false)
13. If there are two clauses (a ∨b ∨c ∨A)x2sat and (¯a ∨¯b ∨¯c ∨B)x2sat, then
let F := F(A/false; B/false)
Clause Length x1sat
x2sat
x3sat
x4sat
1 *
*
*
*
2 *
*
*
*
3 3n/3 < 1.45n
3n/3 < 1.45n
*
*
4 4n/4 < 1.42n
6n/4 < 1.57n
4n/4 < 1.42n
*
5 5n/5 < 1.38n
10n/5 < 1.59n 10n/5 < 1.59n
5n/5 < 1.38n
6 6n/6 < 1.35n
15n/6 < 1.58n 20n/6 < 1.65n
15n/6 < 1.58n
7 7n/7 < 1.33n
21n/7 < 1.55n 35n/7 < 1.67n
35n/7 < 1.67n
8 8n/8 < 1.30n
28n/8 < 1.52n 56n/8 < 1.66n
70n/8 < 1.71n
9 9n/9 < 1.28n
36n/9 < 1.49n 84n/9 < 1.64n
126n/9 < 1.72n
10 10n/10 < 1.26n 45n/10 < 1.47n 120n/10 < 1.62n 210n/10 < 1.71n
Fig. 2. Running times for Di should it always encounter the same kind of clause; ‘*’
indicates polynomial time
4
Polynomial Space Exact Algorithms for xisat
The basic idea behind all known poly-space algorithms for x1sat has been DPLL
branching. One way to deal with xisat is to generalize the approach so that for
a certain clause y, we test all
|y|
i
	
assignments to the variables of y making i
literals true. That makes
|y|
i
	
recursive calls, in each of which |y| variables are
removed – when i literals are true, the rest have to be false and so |y| variables
are set. Of course the length of y is crucial for the running time. Short clauses (in
comparison with i) are good w.r.t. the running time. However, as opposed to the
ordinary sat-problem, long clauses are also good. In Fig. 2 is an overview of the
ﬁrst sublanguages of xisat and the ﬁrst clause lengths. Each entry is calculated

General Exact Satisﬁability
101
as
|y|
i
	n/|y|. Note that for a ﬁxed i, this table is polynomial time computable (as-
suming that the longest clause length is a polynomial in i). Hence, we can easily
ﬁnd a clause which is the best choice, i.e., gives the fastest running time. We call
such a clause preferable. As the formula changes during the recursive decompo-
sition of generalized DPLL branching diﬀerent clauses will become preferable.
The following algorithm elaborates on this idea. For clarity of presentation we
assume that a variable occurs in each clause at most once. (Laxation of this
would not introduce any new worst case, however, it would introduce some un-
interesting technicalities.) We also assume that in the substitution, if a (partial)
assignment is made such that any clause becomes over-satisﬁed or too short to
ever be satisﬁed, then the unsatisﬁable formula F = {∅} is returned. The pur-
pose of Line 2 is to limit the number of singletons in the following lines. It works
by forcing a certain percentage of the variables to be heavy. The choice of 3/5 is
rather arbitrary – it works well for the ﬁrst sublanguages. As will become clear
in the time complexity analysis it is reasonable to believe that for higher i a
larger constant will give a better trade-oﬀ. Note that when F is small enough
Line 2 is applicable and so the recursion ends. Line 1 will limit the number of
singletons in a preferable clause when the clause is long. The beneﬁt of this will
be clear in the time complexity analysis.
Algorithm Di(F)
1. If there is an xisat clause with i + k singletons then remove k of those
singletons;
2. If 3/5 or less of the variables are heavy then cycle through all possible assign-
ments to these variables. For each such partial assignment to the variables,
transform the instance to an x1sat instance, using the reduction of Lemma
1, then use the matching techniques by Porschen et al. to decide whether
there is a model. Answer ‘Yes’ if such a model is found and ‘No’ otherwise;
3. Pick a preferable clause y with as few singletons as possible and make
|y|
i
	
recursive calls, each call having the form Di(F(a1/true; a2/true . . .
ai/true; ai+1/false . . .)).
Theorem 1. Di(F) decides whether F ∈xisat
Proof. Line 1 is a canonical rule. Line 2 is correct by Lemma 1 and the correctness
of the matching techniques. Line 3 is correct since all models for F must have i
literals true in y.
We now examine Di w.r.t. to time complexity. Let TDi indicate the running
time of Di(F).
Theorem 2. For every ﬁxed i, TDi is in
O

max

max
m≤n
i≤m
m
i
1/m
, 1.5157
n
⊂o(2n)

102
V. Dahll¨of
Proof. Line 1 takes polynomial time to execute. As for line 2, we can safely
disregard the polynomial time work spent on matching. Hence the interesting
thing is the size of the recursion tree, which is 23n/5 ≈1.5157n. Similarly for line
3, we disregard the polynomial work done. The recursion tree of Di(F) has size
at most
m
i
	n/m and so the big-Oh expression is justiﬁed.
To justify the o(2n) inclusion, ﬁrst note that
m
i
	n/m = 2log2 (
m
i )
n/m
=
2
n
m log2 (
m
i ). Then, remember that
m
i
	
is the number of subsets of size i whose el-
ements are picked from a set of size m. As the powerset has size 2m,
m
i
	
is always
smaller than that. Hence it follows that log2
m
i
	
< m and so 2
n
m log2 (
m
i ) < 2n.
It is interesting to note that already the above rough analysis shows that
the running time is better than any known DPLL-style algorithm for sat. This
indicates the practical usefulness of xisat in the context of c-atoms – xisat
seems to have a more benign structure than sat. We now try to reﬁne the
analysis to achieve a tighter upper time bound. Unfortunately, in order to do
that we need to know the worst clause length for every sublanguage. Looking
again at Fig. 2 one could think that the worst clause length is 2i + 1. However,
that is not always the case. Extending the table, one sees that the pattern is
changed for x12sat where the worst clause length is 26. It is still an open problem
where to ﬁnd the worst clause length for a given sublanguage. However, for the
ﬁrst sublanguages we can perform a better analysis:
Theorem 3. For x2sat, x3sat and x4sat TDi is in O(1.5157n), O(1.6214n)
and O(1.6848n), respectively.
Proof. Starting with x2sat, we need to take a closer look at Line 3.
Once Line 3 has been applied, the formula is likely to have become mixed, and
so in the general case, y might be a clause requiring one or two true literals. If y
requires one true literal we have a worst clause length of 3, where 3 branches are
made, in each of which 3 variables are removed. If the algorithm always did this
branching, we would have a branching tree of size O(1.4423n). If y requires two
true literals, we will have a worst case when |y| = 5. If Di always had to branch
upon such a y, we would have a running time in O
5
2
	n/5
⊂O(1.5849n).
However, note that due to the previous cases and the fact that y has the smallest
possible number of singletons, at most one variable of y is a singleton. (Line 1
is not strong enough to impose this, but Line 2 ensures that there are clauses
with at least 4 heavy variables.) That means that in each of the 10 calls, other
clauses will be aﬀected. As y was most preferable, all clauses must have length
5, and of the 10 calls at most one call will not set a literal true in another clause
(only one combination of the non-singletons will not set a literal true). Hence, for
the worst case, in 9 of the recursive calls the algorithm will in the immediately
following step encounter an x1sat clause of length 4 and in one recursive call
encounter an x2sat clause of length 4. This means that we will have an upper
time bound O(cn) where c = τ(96, 99·4) ≈1.5149. In this case, Line 2 will decide
the overall running time of the algorithm.

General Exact Satisﬁability
103
Looking at Fig. 2, let us examine the other clause lengths that are possible
worst-case candidates.
1. Clause length 4: In this case there will be at most one singleton in the clause
picked and so we get c = τ(75·3, 73) ≈1.5113.
2. Clause length 6: As 2·6
5 = 2.4 there may be two singletons in the clause we
picked. Hence we get c = τ(1114·5, 112·10) ≈1.5055.
3. Clause length 7: As 2·7
5 = 2.8 there may be two singletons in the clause we
picked. Hence we get c = τ(1319·6, 132·15) ≈1.4657.
4. Clause length 8: 2·8
5
= 3.2 but Line 2 prevents the possibility of three sin-
gletons. Hence we get c = τ(1526·7, 152·21) ≈1.4345.
When it comes to x3sat and x4sat the analysis is almost identical. Here c
will be τ(1333·15, 132·20) and τ(17123·56, 173·70), respectively.
The use of canonization has proved fruitful in the construction of algorithms
for x1sat, and so one could hope that the use of more canonical rules would im-
prove Di further (in terms of proven upper time bounds). However, the problem
is that while canonization helps improve many cases such as overlaps between
clauses, many singletons and few occurrences of high degreed variables, yet the
worst case of the algorithm still remains, namely: all clauses have the worst pos-
sible length, no pair of clauses share more than one variable and there are many
heavy variables. For x2sat the author has constructed an algorithm that obtains
a better upper time than Di. The algorithm D2(F) carefully chooses variables
to branch on, uses canonization, and arrives at the bad case described. Then the
algorithm picks a clause that has two heavy variables a and b. It makes three re-
cursive calls, D2(F(a/true; b/true)), D2(F(a/¯b)) and D2(F(a/false; b/false)).
By a careful case analysis of how D2 behaves in the three calls, an interesting
time bound can be established. When this case is no longer applicable, it can
be shown that there are suﬃciently few heavy variables left and the cycling and
matching technique can be used.
Algorithm D2(F)
0. Canonize F and if |V ar(F)| < 10 then perform an exhaustive search to ﬁnd
a model
1. Pick a clause (a∨b∨A)x1sat or a clause (¯a∨¯b∨¯c)x2sat; return D2(F(a/¯b))
or D2(F(a/false; b/false))
2. Pick a clause(a∨b∨c∨d)x2sat; returnD2(F(a/¯b; c/ ¯d)) or D2(F(a/b; c/d; b/ ¯d))
3. Pick two clauses (a ∨b ∨c ∨A)x2sat and (¯a ∨¯b ∨c ∨B)x2sat such that
V ar(A) ∩V ar(B) = ∅; return D2(F(c/true; a/¯b)) or D2(F(c/false))
4. Pick two clauses (a ∨b ∨c ∨A)x2sat and (¯a ∨b ∨c ∨B)x2sat; return
D2(F(b/¯c; a/true)) or D2(F(b/¯c; a/false)) or D2(F(b/false; c/false))
5. Pick two clauses (a∨b∨A)x2sat and (¯a∨b∨B)x2sat; return D2(F(a/true;
b/true)) or D2(F(a/false; b/true)) or D2(F(b/false))
6. Pick two clauses x = (A∨B)x2sat and y = (A∨C)x2sat such that |A| ≥2;
return D2(F ∪(A)x2sat) or D2(F ∪(A)x1sat) or D2(F(A/false)).

104
V. Dahll¨of
7. Pick a clause x = (a ∨b ∨A)x2sat such that a and b are heavy; return
D2(F(a/true; b/true)) or D2(F(a/¯b) or D2(F(a/false; b/false).
8. Cycle through all possible assignments to the heavy variables. For each such
partial assignment to the variables, transform the instance to an x1sat in-
stance, using the reduction of Lemma 1, then use the matching techniques
by Porschen et al. to decide whether there is a model. Answer ‘Yes’ if such
a model is found and ‘No’ otherwise.
The following theorem establishes the correctness of D2:
Theorem 4. D2(F) will correctly decide whether F has an x2sat model.
Proof. We look at the cases of D2:
0. Correct by assumption.
1. If the clause is an x1sat clause both a and b cannot be true, so the two
cases 1) one of a and b is true; 2) both are false, cover all possibilities.
If the clause is (¯a ∨¯b ∨¯c)x2sat, we have seen that this clause in eﬀect is
identical to (a ∨b ∨c)x1sat and so this is also correct.
2. The two cases cover all possibilities: either it holds that one of a and b and
one of c and d are true, or it holds that both a and b are true and the other
two false or vice versa.
3. When c = true it holds that a ̸= b
4. Both of b and c cannot be true, and so all possible cases are covered.
5. One of b = true and b = false holds. In the ﬁrst case one of a = true and
a = false holds.
6. Two, one or zero variables of A are true.
7. The second branch covers the two possibilities a = true, b = false and
a = false, b = true.
8. Correct by Lemma 1 and the correctness of the matching techniques.
The time complexity analysis consists of a number of case and sub-case anal-
yses. Typically the analysis of a case m will establish an upper time bound Uα
“for this case” which should be interpreted: if throughout the whole execution
of the algorithm, α is the only case applicable, then Uα is an upper bound of
the execution time. Hence one can easily see that an overall upper time bound
for the algorithm is the maximum Uj established for all cases j.
Theorem 5. Algorithm D2 runs in time O(1.4511n)
Proof. We examine each of the cases:
0. Runs in polynomial time.
1. We look at the possible subcases:
(a) We picked a clause (a ∨b ∨c ∨d)x1sat: In the ﬁrst branch, the call
D2(F(a/¯b)) will make the substitution operation apply the following
steps: the clause will become (¯b ∨b ∨c ∨d)x1sat which will become
(true ∨c ∨d)x1sat which will remove the clause and replace c and d by

General Exact Satisﬁability
105
false and hence 3 variables are removed. The second branch will result
in the following steps: (false ∨false ∨c ∨d)x1sat, (c ∨d)x1sat. The
clause (c∨d) will then be immediately taken care of by the canonization
step following. Hence, this case runs in O(τ(3, 3)n) ⊆O(1.2600n) time.
(b) We picked a clause (a∨b∨c)x1sat: In the ﬁrst branch, when a is replaced
by ¯b, the other literal will be put to false by the substitution operation,
so two variables are removed. In the other branch, when a = b = false,
the clause (c)x1sat is created and so, three variables are removed in this
branch. Hence, this case runs in time O(τ(3, 2)n) ⊆O(1.3248n).
(c) We picked an x1sat clause longer than 4. The worst case is when the
clause has length 5. This case runs in O(τ(4, 2)n) ⊆O(1.2721n) time.
(d) We picked a clause (¯a∨¯b∨¯c)x2sat. This case runs in time O(τ(3, 2)n) ⊆
O(1.2721n).
2. We have a running time for this case in O(τ(2, 3)n) ⊆O(1.2600n).
3. As the formula has been canonized, |A ∪B| ≥3 and so in the ﬁrst branch
at least 5 variables are removed (c is true and b ∨¯b equals true and so
the literals of A and B are set to false). Hence we have a running time in
O(τ(5, 1)n) ⊆O(1.3248n) time.
4. This case runs in O(τ(4, 4, 2)n) ⊆O(1.4143n) time.
5. This case runs in O(τ(5, 5, 1)n) ⊆O(1.4511n) time.
6. Doing a naive analysis like in previous cases, looking only at the direct
eﬀects we would obtain very bad ﬁgures. For example, assume |x| = |y| = 5
and |A| = 2, we would reason that in the ﬁrst branch 2+3+3 variables are
removed, in the second 1 variable and in the third 2 variables, giving an
upper bound in O(τ(8, 1, 2)n) ⊆O(1.6408n). However, if one broadens the
perspective to the branchings that will be done immediately afterwards, we
end up with better time bounds. In our example, the ﬁrst branch we cannot
say more about, and so we stay with 8 variables removed. In the second
branch, however, we will have the two clauses (B)x1sat and (C)x1sat.
Following their way downward the recursion tree we see that eﬀectively, there
will be four branches and the number of variables removed are 7,6,6 and 5,
respectively (the one variable removed by the explicit creation of (A)x1sat
included). We may continue and reason similarly about the third branch,
however, the ﬁgures we obtained are good enough: O(τ(8; 7, 6, 6, 5; 2)n ⊆
O(1.4401n). Note that the sign ‘;’ is used to help the reader see how the
expansion is done. We now look at the remaining cases:
(a) For |A| = 2, we have already described the worst case, because if any of
B and C are longer than 3 we will be able to remove more variables.
(b) For |A| = 3; if |B| = |C| = 2 we note that the second branch can
be expanded to two branches due to the explicit creation of (A)x1sat
and so we get a running time in O(τ(4; 5, 4; 3)) ⊆O(1.4253n). If |B| =
2, |C| = 3 we note that the second branch can be expanded to four
branches and we get a running time in O(τ(5; 5, 6, 6, 7; 3)n ⊆O(1.4276n).
If |B| = |C| = 3 we may expand each of the three branches, the ﬁrst
to two branches, the second to eight branches and the third to two,
thereby obtaining a running time in O(τ(9, 8; 8, 8, 7, 7, 7, 6, 9, 8; 8, 7)n ⊆

106
V. Dahll¨of
O(1.3993n). When we look back in the complexity analysis we see that
the worst case possible for any x1sat clause or any x2sat clause shorter
than 5 is that in one branch 2 variables are removed and in the other 3.
As this was the case for all extra branchings when |B| = |C| = 3 we are
now done with the subcase of |A| = 3.
(c) For |A| = 4, we note that due to the canonical rules |x|+|y| > 10, and so
the ﬁrst subcase to consider is |B| = 1, |C| = 2. As a matter of fact, we
will have only two branches, because in the third branch the formula will
immediately be found unsatisﬁable by the canonization. Hence this case
runs in O(τ(3, 2)n ⊆O(1.3248n) time. If |B| = |C| = 2 a naive analysis
show that we have a running time in O(τ(4, 2, 4)n ⊆O(1.4143n). For
|B| = |C| = 2 we also have the bound O(τ(4, 2, 4)n ⊆O(1.4143n). For
|B| = 2, |C| = 3 we get the bound O(τ(5; 4, 4; 4)) ⊆O(1.3888n). If
|B| = |C| = 2 we get a running time in O(τ(6; 3, 3; 4)) ⊆O(1.4459n) and
this is clearly the worst case for |A| = 4.
(d) For |A| = 5, if |B| = 1, |C| = 2, we get a running time in O(τ(3, 2, 5))n ⊆
O(1.4300n). |B| = |C| = 2 gives a bound O(τ(4, 2, 5)n) ⊆O(1.3803n). If
|B| = 2, |C| = 3 we get a running time in O(τ(5, 1, 5))n ⊆O(1.4511n).
For |B| > 2, |C| = 3 we have a bound O(τ(6; 4, 2; 5)n) ⊆O(1.4352n) (the
second branch is expanded by making use of (A)x1sat). The other cases
are better than this last one. We also see that for |A| > 5 we will have
no case worse than the ones already analyzed.
7. We know that there are x2sat clauses a ∈y, a ∈y′, b ∈z and b ∈z′ which,
by the earlier cases, are all diﬀerent from x, do not share any other variables
than a and b and are at least 5 in length. That means that there is a subset
of the formula looking like this (˙a indicates a or ¯a):
y = (˙a ∨c ∨c′ ∨C)x2sat
y′ = (˙a ∨d ∨d′ ∨D)x2sat
x = (a ∨b ∨a′ ∨a′′ ∨A)x2sat
z = (˙b ∨e ∨e′ ∨E)x2sat
z′ = (˙b ∨f ∨f ′ ∨F)x2sat
We will examine the cases depending on |x|, using the same expanded view
as in the previous case:
(a) If |x| = 5 then there are ﬁve variants depending on the actual look of ˙a
and ˙b – none of the dotted variables is negated, one is negated, etc.
None of the dotted is negated: this case runs in O(τ(21, 194, 176, 154, 13;
3, 4; 4, 5))n ⊆O(1.4413n) time. The ﬁrst branch can be extended into 16
branches, taking care of the four x1sat clauses created by a = b = true.
The ﬁrst ﬁgure, 21, is 5 (obtained from x) +4 + 4 + 4 + 4 (obtained from
the other four clauses). Note that due to the balanced branching eﬀect,
the worst case will be when |y| = |y′| = |z| = |z′| = 6.
One of the dotted is negated: this case runs in O(τ(17, 153, 133, 11; 3, 4;
8, 6, 9, 7)n) ⊆O(1.4138n) time.
Two of the dotted are negated: this case runs in O(τ(13, 11, 11, 9; 3, 4;
12, 10, 10, 8, 13, 11, 11, 9)n) ⊆O(1.4001n) time.

General Exact Satisﬁability
107
Three of the dotted are negated: this case runs in O(τ(9, 7; 3, 4; 16, 143,
123, 10, 17, 153, 133, 11)n) ⊆O(1.3934n) time.
All of the dotted are negated: this case runs in O(τ(5; 3, 4; 20, 184, 166,
144, 12, 21, 194, 176, 154, 13)n) ⊆O(1.3920n) time.
(b) For |x| = 6 we can of course make the same subcase analysis as above,
however, by now we have seen that due to the balanced branching eﬀect,
we only need to look at the case when no dotted is negated. This case has
a running time in O(τ(22, 20, 203, 186, 164, 14; 4, 4; 4, 5))n ⊆O(1.4396n).
(c) For |x| = 7, in the third branch, when a = b = false, there will be a
x2sat clause of length 5 created. We will not expand that branch and so
we get a running time in O(τ(23, 214, 196, 174, 15; 5, 3; 2))n ⊆O(1.4400n)
time. Clearly, there is no need to examine the cases when |x| > 7 – they
will all be better than this one.
8. As all clauses have at least length 5 and contains at most one heavy variable,
the ratio —heavy variables— to |V ar(F)| is at most 2/12. 21/6 ≈1.1225 and
the so-for worst case runs in O(1.4511n). Hence we see that this case will
not be the worst case.
5
Solving xisat in Exponential Space
From the above algorithms and properties presented, it seems reasonable that
the running time of an algorithm for deciding xisat should always depend heav-
ily upon the actual i. However, that is not always the case. In the early 1980’s,
Shroeppel and Shamir found a way to solve a class of NP-complete problems in
time O(2n/2) ⊂O(1.4143n) and space O(2n/4) ⊂O(1.1893n). There has been
a recent interest in this kind of algorithms, for instance [20]. There are two
conditions a problem must satisfy in order for the algorithm of Shroeppel and
Shamir to be applicable: ﬁrst, that given a solution (or rather an assignment
in the solution space), the problem instances satisﬁed by the solution must be
enumerable in polynomial time and space, and second, that a problem instance
can be split in a way such that the split operation enjoys certain algebraic prop-
erties. One could think that the enumerability requirement makes the algorithm
unapplicable to problems involving Boolean formulae (given an assignment one
can construct an inﬁnite set of formulae for which that is a model). However,
we may consider the formula ﬁxed and so the requirement boils down to simple
evaluation. In the context of xisat, a possible implementation of their algorithm
looks like this: The xisat instance is described by a list of variables and a list of
numbers indicating for each clause how many true literals it needs to be satisﬁed,
i.e., i. Now split the variable list in four parts and for each part, tabulate all
possible assignments to the variables, and for each assignment make a list indi-
cating for each clause how many literals became true. We now have four tables
and want to scan them to see if there a four lists which can be piece-wise added
so that the list (i, i, i . . .) is obtained. If these four lists are found the formula has
an xisat model. We will not go into details on how the search is done. Instead,
we will restate the main theorem of Shroeppel and Shamir and then prove that
the split-operation described for xisat makes the theorem applicable.

108
V. Dahll¨of
Theorem 6. (Shamir and Shroeppel) If a set of problems is polynomially
enumerable and has a monotonic composition operator, then its instances of size
n can be solved in time T = O(2n/2) and space S = O(2n/4).
In the above described representation of xisat the requirement of polynomi-
ally enumerability is satisﬁed as, for a ﬁxed formula, simple evaluation reveals
whether an assignment satisﬁes the formula. A composition operator ⊕is mono-
tonic iﬀ
1. for all problem instances P ′ and P ′′, |P ′ ⊕P ′′| = |P ′| + |P ′′|
2. for any two solutions x′ to P ′ and x′′ to P ′′ there is a simple concatenation
x′x′′ which is a solution to P ′ ⊕P ′′.
3. for every solution x to P any any represenation of x as x′x′′, there are
problems P ′ and P ′′ such that x′ solves P ′, x′′ solves P ′′ and P = P ′ ⊕P ′′.
4. P ′ ⊕P ′′ can be computed in polynomial time (of the lengths of P ′ and P ′′).
In our case, ⊕is the concatenation of the variable lists of P ′ and P ′′ and the
piece-wise addition of the list of numbers. Clearly it is monotonic.
6
Discussion and Conclusions
We have shown that c-atoms can be eﬃciently reduced to an NP-complete prob-
lem called xisat which is novel to this paper. xisat has a nice structure allowing
the construction of algorithms faster than the trivial O(2n) bound. It is likely
that exact model checkers that are to deal with c-atoms would beneﬁt from
working with formulae consisting of both sat clauses as well as xisat clauses.
When it comes to further improved algorithms, there are several possible
directions. In the past, the algorithms for x1sat have beneﬁtted greatly from
new canonical rules. For instance the special resolution rule which has been
so successfully applied in [3]. Unfortunately, that very rule does not extend to
other sublanguages of xisat. However, there are probably other rules that will
prove useful. Better tools for analyzing the run time complexity of the extended
DPLL-style algorithms presented in this paper would also be helpful.
Due to the low upper time bounds for x1sat (“low” for an NP-complete
problem), no randomized algorithms have been proposed, to the best of our
knowledge. However, such algorithms should be of interest for the general xisat
problem if deployed in incomplete model checkers.
7
Acknowledgements
We thank Magnus Wahlstr¨om and Peter Jonsson for proofreading and valuable
comments.

General Exact Satisﬁability
109
References
1. F. Aloul, A. Ramani, I. Markov, and K. Sakallah. Pbs: a backtrack-search pseudo-
boolean solver and optimizer. In Proc. 5th Int. Symp. Theory and Applications of
Satisﬁability (SAT2002), pages 346–353, 2002.
2. B. Benhamou, L. Sais, and P. Siegel.
Two proof procedures for a cardinality
based language in propositional calculus. In 1th Annual Symposium on Theoretical
Aspects of Computer Science (STACS1994), volume 775, pages 71–82, 1994.
3. J. M. Byskov, B. A. Madsen, and B. Skjernaa. New algorithms for exact satisﬁa-
bility. Theoretical Computer Science, 2004. To appear.
4. V. Dahll¨of, P. Jonsson, and R. Beigel. Algorithms for four variants of the exact
satisﬁability problem. Theoretical Computer Science, 320(2–3):373–394, 2004.
5. M. Dransﬁeld, L. Liu, V. Marek, and M. Truszczy´nski. Satisﬁability and computing
van der Waerden numbers. The Electronic Journal of Combinatorics, 2004.
6. L. Drori and D. Peleg. Faster exact solutions for some NP-hard problems. In Proc.
7th Annual European Symposium on Algorithms (ESA1999), pages 450–461, 1999.
7. L. Drori and D. Peleg.
Faster solutions for exact hitting set and exact SAT.
Technical report, Belfer Institute of Mathematics and Computer Science, 1999.
8. L. Drori and D. Peleg. Faster solutions for some NP-hard problems. Theoretical
Computer Science, 287:473–499, 2002.
9. M. Garey and D. Johnson. Computers and Intractability: A Guide to the Theory
of NP-Completeness. Freeman, New York, 1979.
10. E. Goldberg and Y. Novikov.
Berkmin: a fast and robust sat-solver.
In Proc.
Design, Automation and Test in Europe Conference and Exposition (DATE 2002),
pages 142–149, 2002.
11. E. Hirsch and A. Kulikov. A 2n/6.15-time algorithm for X3SAT.
12. O. Kullmann. New methods for 3-SAT decision and worst-case analysis. Theoretical
Computer Science, 223:1–72, 1999.
13. C. M. Li.
Integrating equivalency reasoning into Davis-Putnam procedure.
In
Proc. 17th Nat. Conf. AI (AAAI2000), pages 291–296, 2000.
14. L. Liu and M. Truszczy´nski. Local-search techniques for propositional logic ex-
tended with cardinality constraints. In Proceedings of the 9th International Con-
ference on Principles and Practice of Constraint Programming – CP 2003, pages
495–509, 2003.
15. Matthew, Moskewicz, C. Madigan, Y. Zhao, L. Zhang, and S. Malik. Chaﬀ: En-
gineering an eﬃcient SAT solver. In Proc. 38th Design Automation Conference
(DAC2001), pages 530–535, 2001.
16. S. Porschen, B. Randerath, and E. Speckenmeyer. X3SAT is decidable in time
O(2n/5). In Proc. 5th Int. Symp. on Theory and Appl. of SAT, pages 231–235,
2002.
17. R. Schroeppel and A. Shamir. A T = O(2n/2), S = O(2n/4) algorithm for certain
NP-complete problems. SIAM Journal on Computing, 1981.
18. J. M. Silva and K. Sakallah. Graps: A search algorithm for propositional satisﬁa-
bility. IEEE Trans. Computers, 48(5):506–521, 1999.
19. P. Simons. Extending and Implementing the Stable Model Semantics. PhD thesis,
Helsinki University of Technology, 2000.
20. R. Williams.
A new algorithm for optimal constraint satisfaction and its im-
plications.
In Proc 31st Int. Colloq. Automata Languages and Programming
(ICALP2004), pages 1227–1237, 2004.

BCiC: A System for Code Authentication
and Veriﬁcation
Nathan Whitehead and Mart´ın Abadi
Department of Computer Science
University of California, Santa Cruz
{nwhitehe,abadi}@cs.ucsc.edu
Abstract. We present BCiC, a system for verifying and authenticating code that
combines language-based proof methods with public-key digital signatures. BCiC
aims to augment the rigor of formal proofs about intrinsic properties of code by
relying on authentication and trust relations. BCiC integrates the Binder security
language with the Calculus of (Co)Inductive Constructions (CiC). In this respect, it
is a descendant of our previous logic BLF, which was based on LF rather than CiC.
This paper focuses on the architecture and implementation of BCiC. In addition
to a logical inference engine, the design most notably includes a network com-
munication module for the efﬁcient exchange of logical facts between hosts, and
a cryptography module for generating and checking signatures. The implementa-
tion cooperates with the Open Veriﬁer, a state-of-the-art system for proof-carrying
code with modular checkers.
1
Introduction
Modern software comes from a multitude of sources, and it often comes in pieces.
Some applications dynamically link to libraries, some are extended with applets or
plug-in modules, and others can be automatically updated. In every case, policies and
mechanisms for establishing trust in new code are essential. When the new code is signed
with a public-key digital signature, trust in the code may be based on trust in its signer.
More generally, trust in the code may result from authenticating the source of the code.
However, such trust has limits: many signers are unknown or only partly known to the
consumers of code, and even reputable signers make mistakes. Therefore, evaluating the
code itself and its properties is also important. It can yield fundamental safety guarantees,
as in Java bytecode veriﬁcation [17], and it need not burden code consumers with proofs
of code properties, as research on proof-carrying code (PCC) [18] demonstrates. (With
PCC, code comes accompanied by safety proofs, and consumers need only check, not
generate, the proofs.) Nevertheless, formal speciﬁcation and analysis of code remain
difﬁcult and often incomplete, particularly when we go beyond basic memory-safety
guarantees.
In this paper we present an approach and a system for establishing trust in code that
combine signatures and proofs. We deﬁne a policy language that allows references to
signed assertions and supports reasoning about trust in the signers. The policy language
can also express theorems about code properties, and supports reasoning about the cor-
rectness of proofs of the theorems. The ﬁnal decision to run code, and what privileges
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 110–124, 2005.
c⃝Springer-Verlag Berlin Heidelberg 2005

BCiC: A System for Code Authentication and Veriﬁcation
111
to give to the code, may require both signatures from trusted parties and direct proofs
of code safety. For instance, it may require a partial proof of safety with trusted, signed
assertions as hypotheses.
Speciﬁcally, we introduce BCiC, a system for verifying and authenticating code that
combines language-based proof methods with public-key digital signatures. BCiC aims
to augment the rigor of formal proofs about intrinsic properties of code by relying on
authentication and trust relations. BCiC integrates the Binder security language [10] with
the Calculus of (Co)Inductive Constructions (CiC) [8]. In this respect, it is a descendant
of our previous logic BLF [22], which was based on LF [13] rather than CiC. Here we
go beyond our work on BLF by designing and building a concrete system. In addition to
a logical inference engine, the design most notably includes a network communication
module for the efﬁcient exchange of logical facts between hosts, and a cryptography
module for generating and checking signatures. The implementation cooperates with
the Open Veriﬁer [6], a state-of-the-art system for proof-carrying code with modular
checkers.
After considering previous and related work in Section 2, we give a short example in
Section 3 and present a high-level overview of our system in Section 4. In Section 5 we
deﬁne the syntax and logical meaning of policies, and describe the implementation of
the logical inference engine. In Section 6 we present two important components of the
system in more detail, the cryptography module and the network module. In Section 7
we describe the integration of BCiC with the Open Veriﬁer. We conclude with some
comments on future work in Section 8.
2
Related Work and Background
Many existing systems combine reason and authority in some way. Checking the validity
of an X.509 certiﬁcate involves a combination of trusting principals and reasoning about
the transitivity of certiﬁcation. Environments that execute network code often combine
static typechecks of the code with signature checks [17,11,15]. These systems can verify
only ﬁxed, simple properties of the code. PCC allows more interesting properties to be
checked, but existing work on PCC [18,1,3,19] assumes that properties and proof rules
areﬁxedaheadoftimebetweenthecodeproducerandthecodeconsumer;theyalsodonot
support signatures in their reasoning. Our previous paper [22] contains further discussion
of related work, in particular of research on proof-carrying authentication [2,4,16]. For
the sake of brevity we do not reproduce that material here; it is somewhat less relevant
for the present paper.
BLF is a logic for authorizing code that combines reason and authority [22]. The logic
in our new system is similar to BLF but, instead of combining Binder [10] and LF [13],
it combines Binder and CiC, the Calculus of (Co)Inductive Constructions [8], used in
the Coq tool [21, 5]. We switched to CiC in order to allow the use of Coq for theorem
proving. We have found that inductive deﬁnitions for data structures yield signiﬁcant
advantages in proofs. The Coq environment also allows a high degree of organization
and automation, and is thus friendly to large-scale theorem proving efforts. Our formal
description in Section 5 is an updated version of our previous presentation, adapted to
the new choice of logical framework.

112
N. Whitehead and M. Abadi
Although the change in logical framework is signiﬁcant, the primary difference
between our current and previous work is that BCiC has a deﬁnite system architecture
and a concrete realization whereas BLF does not. Previously we implemented BLF in
an abstract way. All computation was contained in one machine and the interactions
between hosts were simulated. Public-key digital signatures were considered abstract
terms; no actual cryptographic algorithms were used. Similarly, logical formulas were
manipulated abstractly. In our present work the implementation is concrete. Signatures
and logical formulas have concrete representations as binary bit strings in a standardized
format. Hosts communicate with one another over the Internet in order to share data,
following the formal semantics of the import and export functions in Section 5. We
have also connected our system with an actual PCC framework, the Open Veriﬁer, as
described in Section 7.
The implementation of our communication structure, in which pairs of hosts syn-
chronize and exchange new information, is inspired by work on replicated databases and
database synchronization [9,14]. In our case, the database which is being synchronized
is a set of logical statements.
3
An Example
This section motivates and introduces some components of the system through an ex-
ample.
Suppose that Alice is a user who requires that every program she executes nei-
ther access memory incorrectly nor use too many resources. There may be a relatively
straightforward way to prove memory safety for the programs of interest, but not one for
characterizing resource usage. Moreover, excessive resource usage may not be viewed as
very harmful when there is someone to blame and perhaps bill. Accordingly, Alice may
want proofs for memory safety but may trust Bob on resource usage. Alice constructs a
policy that includes:
use R in
forallobj P:program
mayrun(P) :- sat(safe P), economical(P)
economical(P) :- Bob says economical(P)
end
The ﬁrst line indicates that R applies, as an environment. This environment is a set of
constructors and proof rules that deﬁne the syntax of programs and the rules employed
for proving memory safety. It is speciﬁc to a particular programming language and proof
methodology. For instance, R may contain the following snippet, which deﬁnes standard
constructs for memory access:
mem : Type
sel : mem -> val -> val
upd : mem -> val -> val -> mem
The second line of the policy (forallobj P:program) is a universal quantiﬁcation
over all programs P. The ﬁrst clause indicates that Alice believes that she may execute a

BCiC: A System for Code Authentication and Veriﬁcation
113
program P if there is a proof that P is memory safe and she thinks that P is economical.
The second clause reﬂects Alice’s trust in Bob. In more complex examples, other clauses
may provide other ways of establishing economical(P). The operator says, from
Binder, represents assertions by principals. The sat construct is a special logic predicate
that holds when there is a CiC proof of its argument. The other predicates (mayrun and
economical) are user-deﬁned predicates.
In turn, Bob trusts Charlie to write only economical programs, and has in his policy:
use R in
forallobj P:program
economical(P) :- Charlie says mine(P)
end
where mine is another user-deﬁned predicate.
Suppose further that Charlie supplies a program P0 that Alice wishes to execute.
Charlie produces a CiC proof, Pf, of memory safety of the program. Charlie publishes
his proof by asserting proof(Pf), speciﬁcally by typing the command bcicclient
assert proof(Pf). The predicate proof does not have any built-in logical mean-
ing; it simply serves for introducing the proof Pf. Similarly, Charlie asserts mine(P0).
Alice, Bob, and Charlie all run BCiC servers in the background. When the servers
are set up, they are given the address of an existing server. From that point, they syn-
chronize and receive a list of all other known servers. Once connected, they occasionally
choose other servers with which to synchronize. After sufﬁcient synchronization, Alice
can deduce economical(P0) and Charlie says proof(Pf). After the logic
inference engine checks the proof Pf, Alice obtains sat(safe P0). Now when Alice
queries mayrun(P0), she receives the answer “yes” and is prepared to run P0.
4
Overview
Although our system must implement the logic presented in the next section in order to
support reasoning about signatures and proofs (like the reasoning in the example), the
system is much more than a bare implementation of the logic. In such a bare implementa-
tion, for instance, signed statements may simply be logical expressions—appropriate for
initial experimentation but not much else. In order to be useful, signed statements must
have concrete, secure digital representations. Thus, in our system, signatures employ
cryptography; they are unforgeable and tamper-evident. Furthermore, our system deals
with communication over an insecure network. The network module should minimize
the need for manual user intervention for synchronization.
The implementation has several parts:
– The parser understands the syntax of the logic and can translate between textual
and abstract syntax tree representations.
– The logic interpreter performs deductions in the logic from a set of given statements
to produce a larger (but still ﬁnite) set of deduced statements.
– The cryptography module implements the necessary cryptographic operations, such
as generating and checking signatures.

114
N. Whitehead and M. Abadi
– The network module can communicate statements over the network.
– The user interface accepts textual input from the user and determines which action
should be taken. The user interface is a simple command-line utility that communi-
cates with an existing daemon over a secure local socket.
– The supervisor is in charge of coordinating the global behavior of the program.
It loads existing databases of statements, decides when to communicate on the
network, sign statements, draw inferences, and accept input from the user.
– The policy gives rules for deciding when code should be executed, who to trust
initially about what, and so forth.
– The database holds all known true facts from any source.
Figure 1 shows the organization of these components in the system. Boxes represent
code modules, circles represent data. The ﬁgure also shows the Open Veriﬁer; this part
is explained in Section 7.
	
	


	

	
	



	





 !
"	"
#
$

	$

%!	"
	
	"$
	"
&"
	
'
$
"

$
(
)"
Fig. 1. System components

BCiC: A System for Code Authentication and Veriﬁcation
115
5
BCiC’s Policy Language
This section presents the syntax and semantics of our policy language in a somewhat
abbreviated fashion. Details can be found in the appendix. The interested reader is also
encouraged to refer to corresponding descriptions for BLF [22] for additional explana-
tions. What we describe here, however, should sufﬁce for understanding the rest of this
paper.
5.1
Formal Presentation of the Language
The policy language has both a user syntax (deﬁned in Figure 2 of the appendix) and
an internal syntax (in Figure 4). The user syntax allows proof rules to be stated in
environments of the form use R in ... end. On the other hand, the internal syntax
records proof rules at every point where they are employed, as extra parameters rather
than with use. A simple annotation function translates from the user syntax into the
internal syntax(Figure3). Rulesets (typesignatures) aretypedaccordingtotheidentiﬁers
that they deﬁne. In this respect, BCiC is more constrained than BLF. Therefore, when
one quantiﬁes over rulesets, only rulesets with the proper deﬁnitions are considered.
The logical meaning of policies is given by proof rules (in Figure 5). These proof rules
rely on the CiC typing relation (written ⊢CiC). They also rely on conversions to normal
form, as calculated by Coq. In other respects, the proof rules are a fairly ordinary logical
system for standard logical constructs. We formulate them as sequent deductions [12].
The import function is used for determining the logical meaning of signed statements
received over the network. It is a partial function that takes a key and a formula and
returns a new formula. Our method for importing statements follows Binder. An atomic
formula A signed with a key U is imported as U says A. It is also possible to export
and import some (but not all) non-atomic formulas. A clause can be imported from U
only if the head of the clause is not already quoted with says. If the original clause
is H :- B, then the imported clause will be U says H :- B′ where B′ is the original
body with every formula F without a says preﬁx replaced with U says F. In terms
of g-formulas and d-formulas as used in the formal syntax, a g-formula G without a
says preﬁx is translated to U says G. A g-formula of the form V says G remains
unchanged in translation. A d-formula D without says gets translated to U says D,
while d-formulas of the form V says D are untranslatable.
5.2
The Logic Interpreter
Thelogicmoduleisresponsibleformanagingthefactdatabaseandrespondingtoqueries.
Initially the fact database contains only the facts in the local policy. After synchronizing
with other hosts and exchanging signed statements, the fact database will grow. The main
job of the logic interpreter is ﬁnding all possible logical deductions within the database
and adding them to the database.
This method of answering queries is bottom-up evaluation. The bottom-up approach
has the advantage that it is simple and clearly exhaustive. In contrast, the termination of
top-down inference for Datalog (and therefore for Binder) requires tabling, which can
give rise to subtle issues [20,7]. Moreover, bottom-up evaluation immediately offers a

116
N. Whitehead and M. Abadi
convenient memoizing capability. Although bottom-up evaluation can require more time
and space than top-down evaluation, we believe that bottom-up evaluation is practical
for our application.
The basic operation of the logic interpreter is as for BLF except for term normal-
ization. The interpreter repeatedly examines the database and systematically attempts to
apply every term to every other term. If the application succeeds, then the new result is
normalized and added to the database and the process repeats. Normalization is done in
a module that applies the rules for CiC using code borrowed from Coq.
Although the logic interpreter always terminates on pure Datalog policies, it need not
terminate on policies that make a non-trivial use of CiC. Inﬁnite loops may happen when
applying one dependent type to another results in a more complicated type. Fortunately,
we have not seen this behavior in practice. Moreover, it should be possible to deﬁne a
syntactic restriction that guarantees termination. We have such a restriction in BLF, and
believe that we know how to port it to BCiC if it proves necessary.
6
Other System Modules
This section describes the cryptography module and the network module in more detail.
6.1
The Cryptography Module
The cryptography module is based on Xavier Leroy’s library for OCaml, cryptokit,
a library that provides cryptographic primitives. We use these primitives for generating
keys, for signing, and for verifying signatures. We rely on RSA signatures with a key
length of 1024 bits, and we apply SHA-1 hashing before signing. Each signed logical
statement is accompanied by public-key information about the signer. Verifying that
Alice signs statement X leads to an entry in the fact database, with the formula Alice
says X. We serialize and deserialize statements using the Marshal standard library
functions of OCaml.
When keys are not managed securely, the integrity of every signature is suspect.
Therefore, following standard practices, we store secret keys in encrypted form, keyed
to the hash of a passphrase supplied by the user. We use AES encryption and SHA-1
hashes for storing secret RSA keys.
6.2
The Network Module
The network module is only in charge of communicating signed statements between
hosts, not determining their logical meaning. When new statements become available,
the logic inference module must decide how they are to be interpreted. When the logic
inference algorithm adds new unquoted conclusions (that is, formulas without says)
to the database, the cryptography module creates new signatures and stores them in the
database, and the network module communicates them to other hosts.
Network communication is done using TCP/IP connections on a speciﬁc port. Users
may leave a Unix daemon running at all times waiting for connections, if they wish. When
two BCiC nodes connect, they follow a protocol to decide which statements are known

BCiC: A System for Code Authentication and Veriﬁcation
117
to one and not the other. These statements are then transmitted over the connection.
Connections can be scheduled to occur automatically with randomly chosen partners
at regular intervals, or can be requested manually by users. Full-time servers may run
the daemon and automatically communicate with one another, while individual client
machines may rather connect to the nearest server sporadically at a user’s request.
The most interesting aspect of the network module is the algorithm for coordinating
updates. When nodes connect, they must decide who has new statements that need
to be transmitted. Simply transmitting all the statements at every connection would
be tremendously inefﬁcient. A slightly more realistic possibility is a naive protocol in
which each node hashes every statement in its database and communicates the entire set
of hashes to the other node. Then it is easy for each node to decide which statements it
must send. If n is the total number of statements known by both sides, then the naive
protocol takes O(n) steps per synchronization.
The naive protocol is likely not to be efﬁcient enough in the long run. The size of the
fact databases will steadily increase over time, if nothing else because expiration and
revocation are rare (and they are not even modeled explicitly in the logic, although the
implementation deals with them). More speciﬁcally, we may estimate the performance
of the naive protocol as follows. A large library may be composed of several hundred
functions. The library provider may wish to declare some functions correct by assertion
and to verify other, simpler functions. One way to do this is for the library provider to
sign assertions for each of the functions separately. As new versions of library functions
become available, new statements will be generated. A fairly typical Linux operating
system in our lab currently uses 652 libraries and 2777 applications. If every library
requires 100 statements and releases 10 major versions a year, with each version con-
taining 10 function updates, and every application releases 10 new versions a year, then
the database will initially contain 67977 statements and will increase by 92970 state-
ments each year. After two years the naive protocol will be exchanging 5 Mb at each
connection. Even if one reduces the number of statements at the expense of statement
size by signing one large conjunction that contains statements for all the functions in a
library release, the protocol will still be exchanging 2.7 Mb at each connection after two
years.
There are many possible solutions to the synchronization problem. It is not too hard
to imagine methods that record timestamps or remember which facts have already been
communicated to other servers. We chose to implement a recursive divide-and-conquer
protocol that does not require any extra storage outside the databases themselves. It is
asymptotically efﬁcient for small updates between large databases.
Our approach requires that every statement in every database be hashed and stored
sorted by hash value. Our protocol synchronizes ranges of hash values between two
databases. To synchronize two entire databases, the protocol is performed over the entire
range of possible hash values. To synchronize all hash values between L and H, ﬁrst
both participants extract all hash values in their databases between L and H. Each list is
encoded and hashed, then exchanged between the participants. A special token is used
to represent the hash of the empty list. If the hash values agree, then both databases are
already synchronized and the protocol terminates. If one hash is nonempty and one is
empty, then the protocol terminates and the participant with the nonempty list knows

118
N. Whitehead and M. Abadi
they must transfer the contents of the list. If both hashes are nonempty and differ, then
the range of hash values is split into two equal subranges, L to M and M to H. The
protocol is then applied recursively on these two subranges. (We could also use more
than two subranges, of course.) If n is the total number of statements known by both
sides, and m is the maximum number of statements known by one side that are not
known by the other, then an update takes O(m log n) steps.
Transmitting one large batch of data is often much faster than performing several
rounds of communication to determine which parts of the data should be sent. By com-
municating the number of statements that were hashed at each exchange, the implemen-
tation can switch to the naive protocol when the number falls beneath a threshold. In
experiments we found the optimal threshold to be approximately 1200 children for con-
nections between computers in our lab and a laptop off campus. The network module of
BCiC uses the naive protocol on databases of size 1200 or smaller, and uses the recursive
protocol on larger databases.
7
Integrating BCiC with the Open Veriﬁer
The Open Veriﬁer [6] supports verifying untrusted code using modular veriﬁers. Pro-
grams are expressed in a low-level assembly language with formally speciﬁed semantics.
Code producers may provide veriﬁcation modules for creating proofs of code safety on
demand, rather than actual proofs. Figure 1 illustrates the workings of the Open Veriﬁer.
The code, veriﬁer extension module, and metadata on the right are untrusted and provided
by the code producer. The trusted components on the left (the ﬁxpoint module, post-
condition generator, and checker) communicate with the untrusted veriﬁer extension in
order to generate a conjunction of invariants with proofs.
In this section we explain how BCiC can be connected to the Open Veriﬁer. We focus
on what we have implemented: a scheme in which the Open Veriﬁer can call BCiC. We
also discuss, more brieﬂy, a scheme in which BCiC can call the Open Veriﬁer.
7.1
The Open Veriﬁer Calling BCiC
Supplementing the Open Veriﬁer with BCiC makes veriﬁcation with plug-in veriﬁers
even more ﬂexible. Instead of requiring that veriﬁers be able to prove code safety abso-
lutely, we allow the veriﬁers to use assumptions that are trusted because they have been
asserted by trusted authorities. This arrangement might be necessary for difﬁcult safety
properties. It also allows a veriﬁer to prove something different than required if there is
a trusted assumption that says that the property proved implies the required property. In
particular, the veriﬁer may do a “proof by typechecking”: it may typecheck a program,
and a trusted assumption may declare that typechecked programs are safe.
In the normal operation of the Open Veriﬁer, the ﬁxpoint module collects invariants
that must be veriﬁed. First the ﬁxpoint module supplies an initial invariant to the post-
condition generator. The strongest post-condition is calculated and then passed to the
untrusted veriﬁer extension, which responds with weaker invariants and proofs that they
are indeed weaker. These proofs are checked using Coq by the checker module. The
weaker invariants are collected in the ﬁxpoint module, which continues to calculate a

BCiC: A System for Code Authentication and Veriﬁcation
119
ﬁxpoint of invariants by possibly sending more invariants back to the post-condition
generator.
The connection between BCiC and the Open Veriﬁer affects the communication
between the post-condition generator, the untrusted veriﬁer extension, and the checker.
We have integrated BCiC so that when the Open Veriﬁer decides that it needs justiﬁcation
for a weaker invariant, instead of the Open Veriﬁer asking the extension directly, BCiC
ﬁrst checks its database of facts. If the statement already appears in the database, then
the extension is never queried and the Open Veriﬁer continues as if the justiﬁcation
were received. If the statement is not in the database, then the extension is asked for the
justiﬁcation as usual.
This scheme allows the BCiC database to short-circuit the interactive proof protocol
at any point. Untrusted code can be asserted to be safe without any proof. In this case
there must be an entry in the BCiC database that corresponds to the ﬁrst query that
the Open Veriﬁer provides to the extension. In particular, this scheme handles “proofs
by typechecking”. When the extension can verify that the code typechecks but cannot
justify the soundness of the typechecking rules, the soundness lemmas can appear in the
BCiC database.
7.2
BCiC Calling the Open Veriﬁer
Currently the Open Veriﬁer is limited to verifying a single, generic memory-safety
property. This focus is reasonable in light of current veriﬁcation techniques, but allowing
signatures opens the door to handling other properties. BCiC can support reasoning about
those properties, calling the Open Veriﬁer when appropriate.
For this purpose, we envision a mechanism whereby the conclusions of the Open
Veriﬁer can be used as new facts in the BCiC database. More speciﬁcally, the conclusions
of the Open Veriﬁer are represented as logical facts in BCiC, with a new predicate
verified. We are currently reﬁning our design and implementation of this scheme,
and a mechanism for running programs subject to BCiC policies.
8
Conclusion
In this paper we describe BCiC, a system for reasoning about code that can combine
proofs of code properties and assertions from trusted authorities. We present the un-
derlying logic, show the architecture of the system itself, and describe our method of
integration with the Open Veriﬁer. Going from an abstract logic to an actual system
requires a fair amount of work and a number of signiﬁcant design choices. Although our
system is still experimental, we believe that it shows one possible avenue for progress
in code authentication and veriﬁcation.
So far we have used BCiC for experimenting with small programs created to exercise
various features of theorem provers. Perhaps the most important remaining work is to
apply BCiC to large, useful programs. Clearly BCiC can handle those programs—at least
in uninteresting ways—since it subsumes technologies that scale well (typechecking,
public-key digital signatures). Going further, it would also be interesting to deploy the
system in an environment where many users may place different amounts of trust in

120
N. Whitehead and M. Abadi
many programs. This deployment would allow more experimentation with policies and
would test the effectiveness of the network protocol.
Acknowledgments
Thanks to George Necula for helpful discussions and allowing us access to the source
code of the Open Veriﬁer. Thanks to Katia Hayati and Bogdan Warinschi for providing
feedback on early drafts of this paper. This work was supported in part by the National
Science Foundation under Grants CCR-0204162 and CCR-0208800.
References
1. Andrew W. Appel. Foundational proof-carrying code. In Proceedings of the 16th Annual
Symposium on Logic in Computer Science, pages 247–258, June 2001.
2. Andrew W. Appel and Edward W. Felten. Proof-carrying authentication. In Proceedings of the
5th ACM Conference on Computer and Communications Security, pages 52–62, November
1999.
3. Andrew W. Appel and Amy P. Felty. A semantic model of types and machine instructions for
proof-carrying code. In Proceedings of the 27th Annual ACM SIGPLAN-SIGACT Symposium
on Principles of Programming Languages, pages 243–253, January 2000.
4. Lujo Bauer, Michael A. Schneider, and Edward W. Felten. A general and ﬂexible access-
control system for the Web. In Proceedings of the 11th USENIX Security Symposium 2002,
pages 93–108, 2002.
5. Yves Bertot and Pierre Cast´eran. Interactive Theorem Proving and Program Development.
Springer, 2004.
6. Bor-Yuh Evan Chang, Adam Chlipala, George C. Necula, and Robert R. Schneck. The Open
Veriﬁer framework for foundational veriﬁers. In Proceedings of the 2005 ACM SIGPLAN
International Workshop on Types in Language Design and Implementation (TLDI), pages
1–12, 2005.
7. W. Chen and D. S. Warren. Tabled evaluation with delaying for general logic programs.
Journal of the ACM, 43(1):20–74, January 1996.
8. Thierry Coquand and G´erard Huet. The calculus of constructions. Information and Compu-
tation, 76(2/3):95–120, 1988.
9. A. Demers, D. Greene, C. Hauser, W. Irish, J. Larson, S. Shenker, H. Sturgis, D. Swinehart,
and D. Terry. Epidemic algorithms for replicated database maintenance. In Proceedings of
the Sixth Symposium on Principles of Distributed Computing, pages 1–12, August 1987.
10. John DeTreville. Binder, a logic-based security language. In Proceedings of the 2002 IEEE
Symposium on Security and Privacy, pages 105–113, May 2002.
11. ECMA. Standard ECMA-335: Common Language Infrastructure, December 2001. Available
on-line at: http://msdn.microsoft.com/net/ecma/.
12. Jean-Yves Girard, Paul Taylor, and Yves Lafont. Proofs and Types. Cambridge University
Press, 1990. http://nick.dcs.qmul.ac.uk/ pt/stable/Proofs+Types.html.
13. Robert Harper, Furio Honsell, and Gordon Plotkin. A framework for deﬁning logics. Journal
of the ACM, 40(1):143–184, 1993.
14. JoAnne Holliday, Robert C. Steinke, Divyakant Agrawal, and Amr El Abbadi. Epidemic
algorithms for replicated databases. IEEE Transactions on Knowledge Data Engineering,
15(5):1218–1238, 2003.

BCiC: A System for Code Authentication and Veriﬁcation
121
15. Sebastian Lange, Brian LaMacchia, Matthew Lyons, Rudi Martin, Brian Pratt, and Greg
Singleton. .NET Framework Security. Addison Wesley, 2002.
16. Eunyoung Lee and Andrew W. Appel. Policy-enforced linking of untrusted components. In
Proceedings of the 11th ACM SIGSOFT Symposium on Foundations of Software Engineering,
pages 371–374, September 2003.
17. T. Lindholm and F. Yellin. The JavaTM Virtual Machine Speciﬁcation. Addison Wesley,
1997.
18. George C. Necula. Proof-carrying code. In Proceedings of the 24th ACM SIGPLAN-SIGACT
Symposium on Principles of Programming Languages (POPL’97), pages 106–119, 1997.
19. George C. Necula and Robert R. Schneck. A sound framework for untrusted veriﬁcation-
condition generators.
In Proceedings of the 18th Annual IEEE Symposium on Logic in
Computer Science, pages 248–260, July 2003.
20. P. Rao, K. Sagonas, T. Swift, D. S. Warren, and J. Freire. XSB: A system for efﬁciently
computing well-founded semantics. In Proceedings of the 4th International Conference on
LogicProgrammingandNonmonotonicReasoning, volume1265ofLectureNotes inArtiﬁcial
Intelligence, pages 430–440, Berlin, July 1997. Springer.
21. The Coq Development Team. The Coq proof assistant. http://coq.inria.fr/.
22. Nathan Whitehead, Mart´ın Abadi, and George Necula. By reason and authority: A system
for authorization of proof-carrying code. In Proceedings of the 17th IEEE Computer Security
Foundations Workshop, pages 236–250, June 2004.
Appendix
This appendix contains Figures 2 through 5. These ﬁgures provide details of the formal
syntax and semantics of BCiC. Some additional background and informal explanations
can be found with the formal presentation of BLF [22].

122
N. Whitehead and M. Abadi
⟨var, rsvar, termvar, cicvar⟩::= ⟨identiﬁer⟩
⟨policy⟩::= [ ⟨dform⟩. ]+
⟨predicate⟩::= ⟨identiﬁer⟩
⟨principal⟩::= ⟨key⟩| ⟨var⟩
⟨argument⟩::= ⟨identiﬁer⟩| ⟨key⟩| ⟨var⟩| ⟨expr⟩
| ⟨ruleset⟩
⟨ruleset⟩::= ⟨rsvar⟩| ⟨actualruleset⟩| ⟨rsvar⟩; ⟨ruleset⟩
⟨actualruleset⟩::= ruleset( [ ⟨identiﬁer⟩: ⟨lfterm⟩. ]∗)
⟨expr⟩::= ⟨termvar⟩| ⟨cicvar⟩| type | set | prop | ⟨expr⟩⟨expr⟩
| ⟨expr⟩→⟨expr⟩| {⟨cicvar⟩: ⟨expr⟩} ⟨expr⟩
| [⟨cicvar⟩: ⟨expr⟩] ⟨expr⟩
⟨gform⟩::= ⟨atomic⟩| ⟨gform⟩, ⟨gform⟩| ⟨gform⟩; ⟨gform⟩
| exists ⟨var⟩⟨gform⟩
| existrules ⟨rsvar⟩: ⟨rulesettype⟩⟨gform⟩
| existsobj ⟨termvar⟩: ⟨expr⟩⟨gform⟩
| use ⟨ruleset⟩in ⟨gform⟩end
⟨dform⟩::= ⟨atomic⟩| ⟨dform⟩, ⟨dform⟩
| ⟨dform⟩:- ⟨gform⟩| forall ⟨var⟩⟨dform⟩
| forallrules ⟨rsvar⟩: ⟨rulesettype⟩⟨dform⟩
| forallobj ⟨termvar⟩: ⟨expr⟩⟨dform⟩
| use ⟨ruleset⟩in ⟨dform⟩end
⟨atomic⟩::= [ ⟨principal⟩says ] sat(⟨expr⟩)
|
[ ⟨principal⟩says ] believe(⟨expr⟩)
|
[ ⟨principal⟩says ] ⟨predicate⟩
( [ ⟨argument⟩[ , ⟨argument⟩]∗] )
⟨rulesettype⟩::= [ ⟨identiﬁer⟩[ , ⟨identiﬁer⟩]∗]
Fig. 2. Syntax

BCiC: A System for Code Authentication and Veriﬁcation
123
[A, B]R = [A]R, [B]R
[A; B]R = [A]R; [B]R
[D :- G]R = [D]R :- [G]R
[forall x D]R = forall x [D]R
[exists x G]R = exists x [G]R
[forallrules r : T D]R = forallrules r : T [D]R
[existrules r : T G]R = existrules r : T [G]R
[forallobj x : T D]R = forallobj′ R x : T [D]R
[existsobj x : T G]R = existsobj′ R x : T [G]R
[use R′ in A end]R = [A]R;R′
[P says X]R = P says [X]R
[sat(T)]R = sat′(R, T)
[believe(T)]R = believe′(R, T)
[P(α1, α2, . . . , αn)]R = P(α1, α2, . . . , αn)
Fig. 3. Annotation function
⟨gform⟩::= ⟨atomic⟩| ⟨gform⟩, ⟨gform⟩| ⟨gform⟩; ⟨gform⟩
| exists ⟨var⟩⟨gform⟩
| existrules ⟨rsvar⟩: ⟨rulesettype⟩⟨gform⟩
| existsobj′ ⟨ruleset⟩⟨termvar⟩: ⟨expr⟩⟨gform⟩
⟨dform⟩::= ⟨atomic⟩| ⟨dform⟩, ⟨dform⟩
| ⟨dform⟩:- ⟨gform⟩| forall ⟨var⟩⟨dform⟩
| forallrules ⟨rsvar⟩: ⟨rulesettype⟩⟨dform⟩
| forallobj′ ⟨ruleset⟩⟨termvar⟩: ⟨expr⟩⟨dform⟩
⟨atomic⟩::= [ ⟨principal⟩says ] sat′(⟨ruleset⟩, ⟨expr⟩)
|
[ ⟨principal⟩says ] believe′(⟨ruleset⟩, ⟨expr⟩)
|
[ ⟨principal⟩says ] ⟨predicate⟩
( [ ⟨argument⟩[ , ⟨argument⟩]∗] )
...
Fig. 4. Internal syntax

124
N. Whitehead and M. Abadi
A, Γ ⇒∆, A
A is atomic
φ(Γ) ⇒∆
Γ ⇒∆
Γ ⇒φ(∆)
Γ ⇒∆
φ is a permutation
Γ ⇒∆
Γ, D ⇒∆
Γ ⇒∆
Γ ⇒∆, G
Γ, D, D ⇒∆
Γ, D ⇒∆
Γ ⇒∆, G, G
Γ ⇒∆, G
D1, D2, Γ ⇒∆
(D1, D2), Γ ⇒∆
Γ ⇒∆, G1
Γ ⇒∆, G2
Γ ⇒∆, (G1, G2)
Γ ⇒∆, G
D, Γ ⇒∆
D :- G, Γ ⇒∆
Γ ⇒∆, G1, G2
Γ ⇒∆, (G1; G2)
D[A/x], forall x D, Γ ⇒∆
forall x D, Γ ⇒∆
Γ ⇒∆, exists x G, G[A/x]
Γ ⇒∆, exists x G
D[O/x], forallobj′ R x : T D, Γ ⇒∆
R ⊢CiC O : T
forallobj′ R x : T D, Γ ⇒∆
Γ ⇒∆, existsobj′ R x : T G, G[O/x]
R ⊢CiC O : T
Γ ⇒∆, existsobj′ R x : T . G
D[R/r], forallrules r D, Γ ⇒∆
forallrules r D, Γ ⇒∆
Γ ⇒∆, existrules r G, G[R/r]
Γ ⇒∆, existrules r G
R ⊢CiC O : T
Γ ⇒∆, sat′(R, T)
Γ ⇒∆, sat′(R, {x : T}B)
R ⊢CiC O : T
Γ ⇒∆, sat′(R, B[O/x])
Γ ⇒∆, believe′(R, T), sat′(R, T)
Γ ⇒∆, believe′(R, T)
Γ ⇒∆, believe′(R, {x : T}B)
R ⊢CiC O : T
Γ ⇒∆, believe′(R, B[O/x])
Γ ⇒∆, sat′(R, {x : T}B)
Γ ⇒∆, sat′(R, T)
x does not occur in B
Γ ⇒∆, sat′(R, B)
Γ ⇒∆, believe′(R, {x : T}B)
Γ ⇒∆, believe′(R, T)
x does not occur in B
Γ ⇒∆, believe′(R, B)
Γ ⇒∆, sat′(R, T ′)
T and T ′ have the same normal form in ruleset R
Γ ⇒∆, sat′(R, T)
Γ ⇒∆, believe′(R, T ′)
T and T ′ have the same normal form in ruleset R
Γ ⇒∆, believe′(R, T)
Fig. 5. Proof rules

Ordered Resolution with Selection for H(@)
Carlos Areces1 and Daniel Gor´ın2
1 LORIA - INRIA Lorraine
areces@loria.fr
2 Universidad de Buenos Aires
dgorin@dc.uba.ar
Abstract. The hybrid logic H(@) is obtained by adding nominals and
the satisfaction operator @ to the basic modal logic. The resulting logic
gains expressive power without increasing the complexity of the satisﬁ-
ability problem, which remains within PSpace. A resolution calculus for
H(@) was introduced in [5], but it did not provide strategies for ordered
resolution and selection functions. Additionally, the problem of termina-
tion was left open.
In this paper we address both issues. We ﬁrst deﬁne proper notions
of admissible orderings and selection functions and prove the refutational
completeness of the obtained ordered resolution calculus using a stan-
dard “candidate model” construction [10]. Next, we reﬁne some of the
nominal-handling rules and show that the resulting calculus is sound,
complete and can only generate a ﬁnite number of clauses, establishing
termination. Finally, the theoretical results were tested empirically by
implementing the new strategies into HyLoRes [6,18], an experimental
prototype for the original calculus described in [5]. Both versions of the
prover were compared and we discuss some preliminary results.
1
Introduction
Modal logics are languages which oﬀer relatively high expressive power, but
which, unlike full classical ﬁrst-order logic, have a decidable satisﬁability prob-
lem [12] (deciding satisﬁability for the basic modal logic is PSpace-complete).
Traditional modal logics, though, suﬀer from some important expressive limita-
tions: 1) they can’t make explicit reference to concrete elements of the domain,
and 2) they can’t express equality between elements. Hybrid logics [11] are a
family of extensions of classical modal logics that aim to solve these limitations
by the introduction of nominals and special modal operators.
Intuitively, a nominal is a name for an element of a model even though, from
a syntactic point of view, it behaves like a proposition symbol and can be used
wherever the latter is acceptable. For instance, if i and j are nominals, and p is
a proposition symbol, we can write formulas such as i ∧p ∧⟨r⟩(p ∧[r]j). In this
paper we will consider only the basic hybrid logic H(@), i.e., the extension of
the basic modal logic with nominals and the satisfaction operator @, that allows
the evaluation of a formula at a speciﬁc element of the model.
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 125–141, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

126
C. Areces and D. Gor´ın
Formally, the set of formulas of H(@) is deﬁned with respect to a signature
S = ⟨PROP, NOM, REL⟩, where PROP = {p, q, r, . . .} (the proposition symbols),
NOM = {i, j, k, . . .} (the nominals), and REL = {r1, r2, r3, . . .} (the relation
symbols) are inﬁnite, enumerable, pairwise disjoint sets. ATOM = PROP∪NOM
is the set of atomic symbols. Given a signature S the set of H(@)-formulas over
S is deﬁned as:
H(@) ::= a | ¬ϕ | ϕ ∧ϕ′ | ⟨r⟩ϕ | @nϕ
where a ∈ATOM, n ∈NOM, r ∈REL and ϕ, ϕ′ ∈H(@). The remaining standard
operators (∨, →, [r], etc.) are deﬁned in the usual way.
Deﬁnition 1 (validity). A hybrid model is a structure M = ⟨W, {rM | r ∈
REL}, V ⟩where W is a non-empty set (the domain of the model, whose elements
are called states), rM ⊆W ×W is a binary relation for each r ∈REL, V (p) ⊆W
for each p ∈PROP, and V (n) = {w} for some w ∈W when n ∈NOM.
Given a hybrid model M = ⟨W, {rM | r ∈REL}, V ⟩and an element w ∈W,
the satisﬁability relation M, w |= ϕ (read “model M satisﬁes the formula ϕ at
state w”) is deﬁned as follows:
M, w |= a iﬀw ∈V (a), a ∈ATOM
M, w |= ¬ϕ iﬀM, w ̸|= ϕ
M, w |= ϕ1 ∧ϕ2 iﬀM, w |= ϕ1 and M, w |= ϕ2
M, w |= ⟨r⟩ϕ iﬀexists w′ ∈W such that rM(w, w′) and M, w′ |= ϕ
M, w |= @nϕ iﬀM, w′ |= ϕ, with w′ ∈V (n).
The logic H(@) introduces, through nominals and @, a weak notion of equality
reasoning. For example, the formulas
@ii
(reﬂexivity),
@ij ↔@ji
(symmetry),
(@ij ∧@jk) →@ik (transitivity), and
@ij →(ϕ ↔ϕ(i/j)) (substitution by identicals)
are tautologies of H(@). This notion is not present in the basic modal logic
and it can be shown that H(@) is strictly more expressive [2]. Nevertheless, its
satisﬁability problem remains within PSpace [3].
The most successful automated theorem proving implementations for modal
logics are based on the tableau method and much of their outstanding perfor-
mance is due to the heavy use of several heuristics and reﬁnements [8]. However,
a number of these heuristics don’t work or become rather involved when the
underlying logic allows some form of equality. When nominals are added, the
performance of the tableaux-based theorem provers is severely aﬀected. In this
scenario, it makes sense to investigate other kinds of algorithms. In particular, we
will discuss resolution, the most successful automated theorem proving method
for ﬁrst-order logic with equality [10,9].
In [5] a resolution based calculus for H(@) is proposed. The formulation of
the calculus that we will present takes formulas in negation normal form, i.e.,

Ordered Resolution with Selection for H(@)
127
the negation operator can only be applied to atoms1. As a consequence, both ∨
and [ ] become primitive symbols. Let S = ⟨PROP, NOM, REL⟩be a signature,
we deﬁne the set HNNF(@) as follows:
H
NNF(@) ::= a | ¬a | ϕ ∨ϕ′ | ϕ ∧ϕ′ | ⟨r⟩ϕ | [r]ϕ | @iϕ
where a ∈ATOM, r ∈REL, i ∈NOM and ϕ, ϕ′ ∈HNNF(@). We will call formulas
of the form @iϕ, @-formulas. We will consider, from now on, only formulas of
HNNF(@), unless the contrary is stated.
Like the resolution calculus for ﬁrst-order logic, the hybrid resolution calculus
works on sets of clauses. A clause, in this context, is a set of arbitrary HNNF(@)
@-formulas. A clause represents the disjunction of its formulas, but there’s no
additional restriction regarding the form of the formulas (i.e., they do not need
to be literals). It is worth noting that to allow only @-formulas in a clause is not
an expressivity limitation in terms of satisﬁability: a formula ϕ is satisﬁable if
and only if for an arbitrary nominal i not occurring in ϕ, @iϕ is satisﬁable.
Given a formula ϕ ∈HNNF(@), we deﬁne ClSet(ϕ) = {{@iϕ}}, for i an arbi-
trary nominal not occurring in ϕ. We can now deﬁne ClSet∗(ϕ) — the saturated
set of clauses for ϕ — as the smallest set that includes ClSet(ϕ) and is saturated
under the rules of the resolution calculus R[HNNF(@)] given in Figure 1, where
i, j ∈NOM and p ∈PROP.
(∧) Cl ∪{@i(ϕ1 ∧ϕ2)}
Cl ∪{@iϕ1}
Cl ∪{@iϕ2}
(∨) Cl ∪{@i(ϕ1 ∨ϕ2)}
Cl ∪{@iϕ1, @iϕ2}
(RES) Cl1 ∪{@ip}
Cl2 ∪{@i¬p}
Cl1 ∪Cl2
([r]) Cl1 ∪{@i[r]ϕ}
Cl2 ∪{@i⟨r⟩j}
Cl1 ∪Cl2 ∪{@jϕ}
(⟨r⟩) Cl ∪{@i⟨r⟩ϕ}
Cl ∪{@i⟨r⟩j}
Cl ∪{@jϕ}
for a new j ∈NOM
(@) Cl ∪{@i@jϕ}
Cl ∪{@jϕ}
(SYM) Cl ∪{@ij}
Cl ∪{@ji}
(REF) Cl ∪{@i¬i}
Cl
(PAR) Cl1 ∪{@ij}
Cl2 ∪{ϕ(j)}
Cl1 ∪Cl2 ∪{ϕ(j/i)}
Fig. 1. The Resolution Calculus R[HNNF(@)]
We can group these rules according to their role. The (∧), (∨) and (@) rules
handle formula simpliﬁcation. The (⟨r⟩) rule does a mild skolemization, assigning
a new name (through a new nominal) to an element of the model which was
1 The restriction to formulas in negation normal form simpliﬁes the deﬁnition of ad-
missible orderings and selections functions, but it also have eﬀects on the calculus
as we can see in Figure 1 where the (RES) rule applies only to literals.

128
C. Areces and D. Gor´ın
existentially quantiﬁed (through a diamond). The (RES) rule works like the
resolution rule for ﬁrst-order logic, while the ([r]) rule encodes a non-trivial
uniﬁcation plus a resolution step. Finally, the (SYM), (REF) and (PAR) rules
are the standard set of rules for equality handling in (function free) ﬁrst-order
logic resolution [9].
The construction of ClSet∗(ϕ) is a correct and complete algorithm to decide
satisﬁability for HNNF(@) (and hence for H(@)): ϕ is unsatisﬁable if and only if
the empty clause {} is an element of ClSet∗(ϕ) [5]. However, ClSet∗(ϕ) might be
an inﬁnite set because each application of the ⟨r⟩-rule introduces a new nominal.
Thus, there are formulas whose satisﬁability this algorithm can’t decide in a ﬁnite
number of steps. In Section 4 we show how to turn this calculus into a decision
method for H(@).
A standard technique to regulate the generation of clauses in resolution for
ﬁrst-order logic is called ordered resolution with selection functions [10]. The
general idea is to establish certain conditions under which it is safe to chose
a literal from each clause such that rules are to be applied to a clause only
to eliminate its chosen literal. The ordered resolution calculus with selection
functions is refutationally complete for ﬁrst-order logic when an ordering ≻with
certain properties is used (see [10] for further details). In the following sections
we develop similar strategies for R[HNNF(@)].
2
Ordered Hybrid Resolution with Selection Functions
In the context of resolution systems, an ordering between formulas is called
admissible when it can be used in a calculus of ordered resolution, preserving
refutational completeness. In this section we propose an ordered resolution cal-
culus for HNNF(@).
The following deﬁnitions are standard (see, e.g. [13]). A binary relation ≻is
called an ordering if it is transitive and irreﬂexive; if, additionally, for any two
distinct elements x and y one of x ≻y or y ≻x holds, ≻is said to be total.
An ordering ≻is called well-founded when there is no inﬁnite chain x1 ≻x2 ≻
x3 . . .. Let ≻be an ordering between formulas, and let’s indicate with ϕ[ψ]p a
formula ϕ where ψ appears at position p. We say that ≻has the subformula
property if ϕ[ψ]p ≻ψ whenever ϕ[ψ]p ̸= ψ, and that it is a rewrite ordering
when ϕ[ψ1]p ≻ϕ[ψ2]p iﬀψ1 ≻ψ2. A well-founded rewrite ordering is called
a reduction ordering, and if it also has the subformula property, it is called a
simpliﬁcation ordering. We will use the same symbol to denote both an ordering
on formulas and its standard extension to clauses.
We can now deﬁne the notion of admissible ordering for resolution on HNNF(@).
Deﬁnition 2 (admissible ordering). An ordering ≻over HNNF(@) is admis-
sible if it is a total simpliﬁcation ordering satisfying the following conditions for
all ϕ, ψ ∈HNNF(@) and all i, j ∈NOM:
A1) ϕ ≻i for all ϕ ̸∈NOM
A2) if ϕ ≻ψ, then @iϕ ≻@jψ

Ordered Resolution with Selection for H(@)
129
A3) if ⟨r⟩i is a proper subformula of ϕ, then ϕ ≻⟨r⟩j
A4) [r]i ≻⟨r⟩j.
Condition A1 states that nominals must be smaller than formulas other than
nominals, condition A2 requires the operator @ not to aﬀect the ordering among
formulas, condition A3 introduces a very weak notion of structural complexity,
while condition A4 prioritizes [ ] over ⟨⟩.
It is easy to show that the conditions in Deﬁnition 2 are not too restrictive,
and that there actually exists orderings satisfying them. A standard method
for building simpliﬁcation orderings is by using the lexicographic path orderings
(≻lpo), (see [13] for a deﬁnition), which is deﬁned given a set of operators O
and an ordering > on O (the precedence), over the set of well formed terms
T(O). When the ordering > is well-founded (and total), then ≻lpo is a (total)
simpliﬁcation ordering.
In this context, since we will deﬁne an ordering based on lpo, it will be
convenient to treat @, ⟨⟩and [ ] as binary operators: @(·, ·) : HNNF(@)×NOM →
HNNF(@)2, ⟨⟩(·, ·) : REL × HNNF(@) →HNNF(@) and [ ](·, ·) : REL × HNNF(@) →
HNNF(@) but we will keep the notation @nϕ, ⟨r⟩ϕ and [r]ϕ.
We give the following constructive deﬁnition of an admissible ordering based
on lpo over the set O = PROP∪NOM∪REL∪{¬, ∧, ∨, @, ⟨⟩, [ ]} with the obvious
arities (note that HNNF(@) ⊂T(O)).
Deﬁnition 3. Given a hybrid signature S = ⟨{pi | i ∈IN}, {ni | i ∈IN}, {ri |
i ∈IN}⟩, let O be the set S ∪{¬, ∧, ∨, @, [ ], ⟨⟩}, and deﬁne the precedence
relation > ⊆O × O as the transitive closure of the set
{(@, ¬), (¬, ∧), (∧, ∨), (∨, [ ]), ([ ], ⟨⟩)} ∪
{(⟨⟩, ri), (ri, pj), (pj, nk) | i, j, k ∈IN} ∪
{(ri, rj), (pi, pj), (ni, nj) | i > j}.
By deﬁnition, > is total, irreﬂexive and well-founded. Let ≻lpo be the lpo over
HNNF(@) that uses > as precedence. It follows that ≻lpo must be a total simpli-
ﬁcation ordering. Finally, deﬁne ≻h as
ϕ ≻h ψ iﬀ

size(ϕ) > size(ψ), or
size(ϕ) = size(ψ) and ϕ ≻lpo ψ
where size(ϕ) is the number of operators in ϕ.
Proposition 1. ≻h is an admissible ordering.
Observe that no admissible ordering can be deﬁned using lpo alone. It suﬃces
to note that there’s no way to guarantee ⟨r′⟩⟨r⟩i ≻lpo ⟨r⟩j when r ≻lpo r′ and
j ≻lpo i, which violates A3. Unless stated otherwise, from now on we will use ≻
to refer to some arbitrary but ﬁxed admissible ordering.
2 The order of the parameters of this operator has been chosen to simplify Deﬁnition 3
and the proof of Proposition 1.

130
C. Areces and D. Gor´ın
(∧) Cl ∪{@i(ϕ1 ∧ϕ2)}
Cl ∪{@iϕ1}
Cl ∪{@iϕ2}
(∨) Cl ∪{@i(ϕ1 ∨ϕ2)}
Cl ∪{@iϕ1, @iϕ2}
(RES) Cl1 ∪{@ip}
Cl2 ∪{@i¬p}
Cl1 ∪Cl2
([r]) Cl1 ∪{@i[r]ϕ}
Cl2 ∪{@i⟨r⟩j}
Cl1 ∪Cl2 ∪{@jϕ}
(⟨r⟩) Cl ∪{@i⟨r⟩ϕ}
Cl ∪{@i⟨r⟩j}
Cl ∪{@jϕ}
for a new j ∈NOM
and ϕ ̸∈NOM
(@) Cl ∪{@i@jϕ}
Cl ∪{@jϕ}
(REF) Cl ∪{@i¬i}
Cl
(SYM) Cl ∪{@ji}
Cl ∪{@ij}
if i ≻j
(PAR) Cl1 ∪{@ji}
Cl2 ∪{ϕ(j)}
Cl1 ∪Cl2 ∪{ϕ(j/i)}
if j ≻i and
ϕ(j) ≻@ji
Restrictions: Assume an admissible ordering ≻and a selection function S.
In the following, ϕ and ψ are the formulas explicitly displayed in the rules.
The main premise of each rule is the rightmost, the other premise (in rules
with two premises) is the side premise.
– If C = C′ ∪{ϕ} is the main premise, then either S(C) = {ϕ} or, S(C) = ∅
and {ϕ} ≻C′.
– If D = D′ ∪{ψ} is the side premise, then {ψ} ≻D′ and S(D) = ∅.
Fig. 2. The Resolution Calculus ROS[HNNF(@)]
Finally, in resolution for ﬁrst-order logic, a selection function may chose only
negative literals from a clause. As we work with clauses which can contain arbi-
trary @-formulas from HNNF(@) we deﬁne “negative literals” as the complement
of the set PLIT of positive literals, where PLIT ::= @ij | @ip | @i⟨r⟩j, for
i, j ∈NOM, p ∈PROP and r ∈REL.
Deﬁnition 4 (selection function). A function S from clauses to clauses is a
selection function if and only if, for every clause C we have S(C) ⊆C, |S(C)| ≤
1 and S(C) ∩PLIT = ∅.
We are now ready to formulate the strategy of ordered resolution with selection
functions for HNNF(@). Figure 2 contains the rules of the calculus.
The rules of ROS[HNNF(@)] diﬀer from the ones in Figure 1 only in the ad-
dition of some restrictions, both local (in the (⟨r⟩), (SYM) and (PAR) rules)
and global. Notice that, as an eﬀect of the global restrictions, there is only one
formula in each clause that may be involved in an inference. We will call this
formula the distinguished formula of the clause.
3
Refutational Completeness of R
OS[H
NNF(@)]
The standard proof of refutational completeness for ﬁrst-order logic resolution
is via the generation of potential Herbrand models [10]. In this section we start

Ordered Resolution with Selection for H(@)
131
by showing that an appropriate notion of Herbrand model can be deﬁned for
hybrid languages containing nominals and @.
The following result was established in [20] for CPDL a version of PDL
(Propositional Dynamic Logic [17]) extended with hybrid operators, but it holds
for any hybrid logics containing nominals and @. For N a hybrid model, let
diag(N), the diagram of N, be the set diag(N) = {ϕ | ϕ ∈PLIT and N |=
ϕ} ∪{¬ϕ | ϕ ∈PLIT and N ̸|= ϕ}, and call a model named if each state of its
domain satisﬁes at least one nominal.
Theorem 1 (Scott’s Isomorphism Theorem). Let M and N be two count-
able, named hybrid models. Then M and N are isomorphic iﬀM |= diag(N).
Based on Theorem 1 we can deﬁne hybrid Herbrand models as follows:
Deﬁnition 5 (Herbrand model). Let S = ⟨PROP, NOM, REL⟩be a hybrid
signature. A hybrid Herbrand model for H(@) over S is any set I ⊆PLIT.
We identify a Herbrand model with a set of positive literals. This set will uniquely
deﬁne certain hybrid model.
Deﬁnition 6. Given a hybrid Herbrand model I, let ∼I be the minimum equiv-
alence relation over NOM that extends the set {(i, j) | @ij ∈I}. We now deﬁne
the hybrid model uniquely determined by I as ⟨W I, {rI | r ∈REL}, V I⟩where
W I
= NOM/∼I
rI
= {([j], [k]) | @j⟨r⟩k ∈I}
V I(p) = {[j] | @jp ∈I}, p ∈PROP
V I(i) = {[i]}, i ∈NOM.
where NOM/∼I is the set consisting of equivalence classes of ∼I, and [i] is the
equivalence class assigned to i by ∼I.
From now on, we will not distinguish between a hybrid Herbrand model I and
its associated model. We will say, for instance, that a formula @iϕ is true in I
whenever it is satisﬁed by its associated model (as we are always referring to
@-formulas no explicit point of evaluation is needed).
The following theorem (easily proved using Theorem 1) shows that we can
work with Herbrand models instead of arbitrary models.
Theorem 2. Given Γ, a set of @-formulas of H(@) over a signature S =
⟨PROP, NOM, REL⟩, Γ has a hybrid model if and only if it has a hybrid Her-
brand model over the signature S′ = ⟨PROP, NOM ∪NOM′, REL⟩, where NOM′
is a numerable set disjoint from NOM.
We are now ready to prove the refutational completeness of ROS[HNNF(@)]. The
idea is to build a candidate Herbrand model from an arbitrary (and potentially
inﬁnite) set of clauses, such that if the least clause of the set is not true under this
model, then the calculus must allow the derivation of a new clause which will also

132
C. Areces and D. Gor´ın
fail to be true in the model. By deﬁnition, the empty clause is the smallest clause
in any admissible ordering, and it can be shown that admissible orderings ensure
that any consequent of a rule is smaller than the main premise. We will, thus,
prove that the process leads to either the construction of a Herbrand model for
the initial formula (i.e., the initial formula was satisﬁable), or to the inclusion of
the empty clause in the saturated set (i.e., the initial formula was unsatisﬁable).
The deﬁnition of a candidate model given below is more complex than the one
in [10]. This is because the latter was used for ﬁrst-order logic without equality,
while in H(@) we have to deal with equalities of the form @ij.
Deﬁnition 7 (σI). Given a hybrid Herbrand interpretation I, we deﬁne the
following substitution of nominals by nominals:
σI = {i →j | i ∼I j ∧(∀k)(k ∼I j →k ⪰j)}.
σI substitutes each nominal with the least nominal of its class, which is taken
as the class representative.
Deﬁnition 8. We deﬁne the set of simple formulas of HNNF(@) over S as:
SIMP ::= @ij (with i ≻j) | @ip | @i¬a | @i⟨r⟩j | @i[r]ϕ
where i, j ∈NOM, p ∈PROP, a ∈ATOM, r ∈REL and ϕ ∈HNNF(@).
Let N be a ﬁxed set of clauses. The following three deﬁnitions must be taken as
a unit. They are presented separately for clarity but are mutually recursive.
Deﬁnition 9 (IC). Let C be a clause (not necessarily in N), we name IC the
hybrid Herbrand interpretation given by 
C≻D εD.
Deﬁnition 10 (reduced form). Let C be a clause and ϕ its maximal formula.
If ϕ ∈SIMP and either a) ϕ ∈PLIT and ϕ = ϕσIC, or b) ϕ = @i[r]ψ and
i = iσIC; then we say that both ϕ and C are in reduced form.
Deﬁnition 11 (εC). Let C be a clause (not necessarily in N). If it simultane-
ously holds that: a) C ∈N, b) C is in reduced form, c) The maximal formula in
C is in PLIT, d) C is false under IC, and e) S(C) = ∅; then εC = {ϕ}, where ϕ
is the maximal formula in C; otherwise, εC is the empty set.
We say that C produces ϕ if εC = {ϕ} and call it a productive clause. IC is the
partial interpretation of N below C. Only those clauses whose maximal formula
ϕ is a positive literal and have no selected formulas may be productive.
Deﬁnition 12 (candidate model). IN, a candidate model for N, is deﬁned
as 
C∈N εC.
If a clause C is false under I, we say that C is a counterexample of I. Analyzing all
the rules of the calculus and considering separately those distinguished formulas
that are not in reduced form, the following result can be proved.

Ordered Resolution with Selection for H(@)
133
Proposition 2. Let N be a set of clauses and C ∈N be the minimum coun-
terexample of IN, with respect to an admissible ordering ≻. If C ̸= {}, then there
exists an inference using one of the rules of the calculus such that:
1. C is the main premise
2. the side premise (when present) is productive
3. all the consequents are smaller, with respect to ≻, than C and at least one
of them is a counterexample of IN.
Proof. Using Deﬁnition 2 we can easily check that every consequent in the cal-
culus is smaller than the main premise of its inference. The hard part of the
proof is to verify that a proper side premise (when required) exists.
Let ϕ be the distinguished formula of C. If ϕ ̸∈SIMP, C is trivially the
premise of some unary rule and the proposition holds. Now, suppose ϕ ∈SIMP
is not in reduced form; this means that some clause D produces @ij for an i
occurring in ϕ. It is easy to check that, in this case, (PAR) can be applied on
D and C. Finally, if ϕ is in reduced form, it must be of the form @i¬a (for
a ∈ATOM) or @i[r]ψ. The ﬁrst case is handled either by the (REF) or the
(RES) rules, and the proof is analogous to the standard one for ﬁrst-order logic.
The latter case deserves more attention. The non-trivial part of the proof is
to see that a clause in N must produce some @i⟨r⟩j such that @jψ is false in
IN; but this follows from the fact that C is a counterexample in reduced form
and that, for any k, l ∈NOM, if @kl ∈IN, then l = kσIN .
Refutational completeness can be easily established from Proposition 2.
Theorem 3. ROS[HNNF(@)] is refutationally complete.
4
Termination of the Calculus
In this section we show how the calculus ROS[HNNF(@)] can be turned into a
decision procedure for satisﬁability. We will introduce the necessary changes to
ensure that for any formula ϕ ∈H(@), ClSet∗(ϕ) is a ﬁnite set. If this condition
holds, implementing an algorithm that computes ClSet∗(ϕ) in ﬁnite time (e.g.,
the “given clause algorithm” [23]) is straightforward.
The calculus R[HNNF(@)] of Figure 1 can trivially generate an inﬁnite sat-
urated set of clauses as the (⟨r⟩) rule can be applied on formulas of the form
@i⟨r⟩j for j ∈NOM.3 ROS[HNNF(@)] avoids this behavior, but an inﬁnite number
of nominals can still be introduced by interaction between the ([r]), (⟨r⟩) and
(PAR) rules. As no other symbols but nominals are introduced during resolu-
tion, and given that formulas in consequent clauses are never larger (in number
of operators) than those in the antecedent, if we can control the generation of
nominals we will obtain termination.
3 Actually, just repetitive application of the (⟨r⟩) rule to the same clause can lead to
the generation of an inﬁnite set, but this can be easily avoided by ensuring that the
rule is applied only once to each ⟨r⟩-formula in a clause.

134
C. Areces and D. Gor´ın
There are essentially two ways in which an inﬁnite number of nominals can
be introduced by the rules of ROS[HNNF(@)]:
Type 1. A formula of the form @i⟨r⟩ϕ introduces a new nominal which, in turn,
contributes to the derivation of a new clause containing @i⟨r⟩ϕ. All new
nominals are immediate successors of i and they are actually representing
the same state in the model, but the calculus cannot detect it.
Type 2. There is a formula ϕ and an inﬁnite sequence of distinct nominals
n0, n1, n2, . . . such that, for all i ∈IN, some @ni⟨r⟩ϕi in the saturated set in-
troduces, by way of the (⟨r⟩) rule, the nominal ni+1. The calculus is exploring
a cycle in the model, and cannot detect when to stop the search.
For concrete examples, try the rules of ROS[HNNF(@)] over the formulas @i([r](i∧
(q∨⟨r⟩p))∧⟨r⟩p) and @i([r](i∧⟨r⟩p)∧⟨r⟩p) using any admissible ordering where
i is the least nominal.
As we see, to obtain termination we need to impose some control on the way
new nominals are generated by the (⟨r⟩) rule, and on how chains of nominal
successors are treated. Solving problems of Type 1 is relatively easy. The next
proposition provides the key to the solution.
Proposition 3. Let ϕ, ψ ∈HNNF(@) be such that ϕ[@i⟨r⟩ψ]p, and let j ∈NOM
not occur in ϕ. Then, ϕ is satisﬁable iﬀϕ[@i⟨r⟩ψ/(@i⟨r⟩j ∧@jψ)] is satisﬁable.
Notice that the proposition involves simultaneous replacement of all subformulas
@i⟨r⟩ψ in ϕ by (@i⟨r⟩j ∧@jψ). The (⟨r⟩) rule instead, uses a new nominal in
each application, even when applied to the same formula @i⟨r⟩ψ.
The solution to problems of Type 1 then is to deﬁne a function nom assigning
a unique nominal to each formula @i⟨r⟩ψ and redeﬁne the (⟨r⟩) rule with the
help of nom. Solving problems of Type 2 is more involved, and it is here where
the (PAR) rule plays an important role. We will see that we can use, also here,
the function nom to our advantage.
Let’s start by properly deﬁning this function. We ﬁrst diﬀerentiate between
nominals which appear in the input formula and nominals generated by appli-
cation of the (⟨r⟩) rule. Let NOMi (the set of initial nominals) and NOMc (the
set of computation nominals) be inﬁnite sets such that NOMi ∩NOMc = {} and
NOMi ∪NOMc = NOM.
We additionally assume, without loss of generality, that NOMc = 
k∈IN N k
c ,
where the sets N k
c are inﬁnite, pairwise disjoint and well-ordered by ≻. And we
impose the additional, mild condition on ≻requiring s ≻t whenever s ∈NOMj
c,
t ∈NOMk
c and j > k. These conditions will simplify the deﬁnition of nom and
the proof of termination. From now on we assume that NOMc and ≻comply
with these requirements.
Now, let HNNF
i
(@) be the subset of HNNF(@) where only nominals in NOMi
occur and deﬁne
H
NNF
@⋄(@) = {@i⟨r⟩ϕ | i ∈NOM, r ∈REL, ϕ ∈H
NNF
i
(@), ϕ ̸∈NOM},
the set of those @-formulas of HNNF(@) that can be the distinguished formula of
a premise of the (⟨r⟩) rule.

Ordered Resolution with Selection for H(@)
135
(∧) Cl ∪{@i(ϕ1 ∧ϕ2)}
Cl ∪{@iϕ1}
Cl ∪{@iϕ2}
(∨) Cl ∪{@i(ϕ1 ∨ϕ2)}
Cl ∪{@iϕ1, @iϕ2}
(RES) Cl1 ∪{@ip}
Cl2 ∪{@i¬p}
Cl1 ∪Cl2
([r]) Cl1 ∪{@i[r]ϕ}
Cl2 ∪{@i⟨r⟩s}
Cl1 ∪Cl2 ∪{@jϕ}
(⟨r⟩′) Cl ∪{@i⟨r⟩ϕ}
Cl ∪{@i⟨r⟩j}
Cl ∪{@jϕ}
ϕ ̸∈NOM and
j = nom≻(@i⟨r⟩ϕ)
(@) Cl ∪{@i@jϕ}
Cl ∪{@jϕ}
(REF) Cl ∪{@i¬i}
Cl
(SYM) Cl ∪{@ji}
Cl ∪{@ij}
if i ≻j
(PAR’)
Cl1 ∪{@ji}
Cl2 ∪{ϕ(j)}
Cl1 ∪Cl2 ∪{ϕ(j/i)}
if j ≻i, ϕ(j) ≻@ji, and whenever
ϕ(j) = @k⟨r⟩l, then l ∈NOMi, or
i ∈NOMi and l = j
(PAR-@⋄) Cl1 ∪{@ji}
Cl2 ∪{@j⟨r⟩k}
Cl1 ∪Cl2 ∪{@i⟨r⟩l}
Cl1 ∪Cl2 ∪{@kl}
if j ≻i and k ∈NOMc, and for
some ϕ, k = nom≻(@jϕ), and
l = nom≻(@iϕ)
Restrictions: Assume an admissible ordering ≻, a proper nom≻function and a
selection function S. In the following, ϕ and ψ are the formulas explicitly displayed
in the rules. The main premise of each rule is the rightmost, the other premise (in
rules with two premises) is the side premise.
– If C = C′ ∪{ϕ} is the main premise, then either S(C) = {ϕ} or, S(C) = ∅
and {ϕ} ≻C′.
– If D = D′ ∪{ψ} is the side premise, then {ψ} ≻D′ and S(D) = ∅.
Fig. 3. The Resolution Calculus ROS
T [HNNF(@)]
Deﬁnition 13 (nom≻). Given ≻an admissible ordering, let nom≻: HNNF
@⋄(@)
→NOMc be any function such that
1. nom≻is injective,
2. i ≻j iﬀnom≻(@i⟨r⟩ϕ) ≻nom≻(@j⟨r⟩ϕ), for any i, j ∈NOMc, and
3. for all j ∈NOMi
c there exists a formula @k⟨r⟩ϕ such that j = nom≻(@k⟨r⟩ϕ)
and, either i = 0 and k ∈NOMi, or else k ∈NOMi−1
c
Condition 1) is required for soundness: we can use the same nominal for each
@i⟨r⟩ϕ formula, but no two diﬀerent formulas in HNNF
@⋄(@) should use the same
nominal. Condition 2) is needed to guarantee refutational completeness. Finally,
condition 3) avoids cycles (like in i = nom≻(@i⟨r⟩ψ)) and, more important, it
is required in order to obtain a terminating calculus.
It can be easily shown that Deﬁnition 13 is not too restrictive; i.e., that it
can be satisﬁed by a concrete function. For example, let nϕ be a new nominal
for each formula ϕ ∈HNNF
@⋄(@) and make nϕ = nom≻(ϕ).

136
C. Areces and D. Gor´ın
Figure 3 shows the calculus ROS
T [HNNF(@)] for which we will establish refuta-
tional completeness and termination. Notice that the (⟨r⟩) rule has been replaced
by (⟨r⟩′) which uses the nom≻function to always assign the same nominal to a
formula in HNNF
@⋄. The (PAR) rule has been replaced by two rules: (PAR’) and
(PAR-@⋄). (PAR’) is just a restriction of (PAR) which does not handle certain
formulas of the form @i⟨r⟩j. Such formulas are treated in a special way by the
(PAR-@⋄) rule. The (PAR-@⋄) rule deserves some explanation. The intuition
behind this rule is the following: if j and i denote the same state in the model
(as indicated by the distinguished formula @ji in the side premise) then, by
Proposition 3, k and l can be taken to be equal too. However, by Deﬁnition 13,
k ≻l and, thus, l should be preferred over k.
We now proceed to discuss soundness, refutational completeness and termi-
nation of ROS
T [HNNF(@)], starting with soundness:
Theorem 4. If ϕ ∈HNNF
i
(@) is satisﬁable, then ClSet∗(ϕ) (closed by the rules
of ROS
T [HNNF(@)]) is satisﬁable.
Proof. The proof is based on the fact that, for any ≻and nom≻, given a model for
ϕ, we can build another model for ϕ but such that certain criteria of compatibility
with nom≻also holds. In essence, for M to be “compatible” with nom≻the
following conditions should hold:
– if M |= @i⟨r⟩ψ and j = nom≻(@i⟨r⟩ψ), then M |= @i⟨r⟩j, and M |= @jψ,
– if k = nom≻(@i⟨r⟩ψ), l = nom≻(@j⟨r⟩ψ) and M |= @ij, then M |= @kl.
In order to prove completeness, one should note that, by Deﬁnition 13, the
consequents of the (PAR-@⋄) rule are always smaller than the main premise.
Using this fact, the proof of Theorem 2 is easily adapted (handling the (⟨r⟩′)
rule is straightforward).
Theorem 5. ROS
T [HNNF(@)] is refutationally complete.
We ﬁnally turn to the problem of proving that ROS
T [HNNF(@)] doesn’t generate
inﬁnite saturated sets. We are ready to exactly formulate conditions under which
the problems of Type 1 and 2 we discussed above cannot occur. Let NOM(Γ)
be the set of all nominals occurring in Γ, we want to establish that for all
ϕ ∈HNNF
@⋄(@):
1. every set NOMi
c ∩NOM(ClSet∗(ϕ)) is ﬁnite, for all i ∈IN, and
2. the set {i | i ∈IN and NOMi
c ∩NOM(ClSet∗(ϕ)) ̸= {}} is ﬁnite.
In the next proposition we show that these two conditions can be guaranteed.
Proposition 4. Let ϕ ∈HNNF
i
(@), then the set of nominals in ClSet∗(ϕ) com-
puted using the rules in ROS
T [HNNF(@)] is ﬁnite.
Proof. For any i ∈NOM, the function level(i) is deﬁned as 0 if i ∈NOMi or the
only n ≥1 such that i ∈NOMn−1
c
otherwise. Now, given @iϕ ∈HNNF
i
(@) deﬁne
d′(@iϕ) = level(i) + d(ϕ) where d(ϕ) is the modal depth of ϕ. The proof of the
proposition directly follows from these properties:

Ordered Resolution with Selection for H(@)
137
1. For every clause {@i⟨r⟩j} ∪C ∈ClSet∗(ϕ), either level(j) = 0 or level(j) =
level(i) + 1.
2. For all formula ψ occurring in ClSet∗(ϕ), if some i ∈NOMc occurs in ψ, then
ψ is of the form: @iψ′, @j⟨r⟩i, or @ji (i does not occur in ψ′ and i ̸= j).
3. If ψ occurs in some clause in ClSet∗(ϕ), then d′(ψ) ≤d(ϕ) and, moreover, if
ψ = @ij, then level(j) ≤d(ϕ). Therefore, for all formula ψ, if i is a nominal
occurring in a formula in ClSet∗(ψ), then level(i) ≤d(ψ).
4. For all nominal i, the number of distinct formulas of the form @i⟨r⟩ψ (ψ ̸∈
NOM) occurring in ClSet∗(ϕ) is ﬁnite.
5. For all k ∈IN, the set NOMk
c ∩NOM(ClSet∗(ϕ)) is ﬁnite.
Termination of ROS
T [HNNF(@)] is a direct corollary of the above proposition.
Theorem 6. ROS
T [HNNF(@)] is a decision procedure for the problem of satisﬁa-
bility of H(@).
5
Implementation and Testing
HyLoRes 1.0 is an automated theorem prover for the logic H(@, ↓)4 (but we
will only use it for formulas of H(@)) written in Haskell, of approximately 5000
lines of code, based on the resolution calculus proposed in [5]. It must be noted
that this is not a tool aiming to compete with state-of-the-art theorem provers.
Automated provers such as SPASS [1], Vampire [22], RACER [16] or *SAT [15]
include an important number of heuristics and optimizations with which they
achieve an outstanding performance. HyLoRes implements a relatively small set
of optimizations and it is still mainly a proof of concept implementation.
We have developed a new version (2.0) of HyLoRes that uses the rules of the
ROS
T [HNNF(@)] calculus presented in Figure 3. Several tests were run to compare
the performance of versions 1.0 and 2.0. In this section we comment on some of
the results obtained.
Nowadays, the standard test suite for basic modal logic satisﬁability is the
“random 3CNF2m” [21], an adaptation of the random 3CNF for propositional
logic [19]. This type of test generates batches of random formulas subject to
certain restriction parameters (e.g., number of propositional variables, modal
depth, maximum number of clauses, etc.).
The standard deﬁnition of random 3CNF2m generates formulas that are
strictly modal (i.e., without neither nominals nor the @ operator). An extension,
called random h3CNF2m and implemented as the generator hGen, is described
in [7] that suits the needs of theorem provers for hybrid logics. hGen generates
formulas for sublanguages of H(@, A, ↓) (H(@) extended with the ↓binder and
the universal modality A).
The parameters involved in the generation of test batches were: number of
propositional variables (V ), number of nominals (N), maximum modal depth
(D) and number of clauses (L). After ﬁxing the values for V , N and D, a batch
4 H(@, ↓) is H(@) extended with the ↓binder, see [4] for details.

138
C. Areces and D. Gor´ın
of 100 formulas of H(@) was generated for each value of L in a given range.
They were then used as input for both theorem provers, with a timeout value
of 40 seconds per formula. To plot the results, the median of the execution time
and of the number of clauses generated were taken.
First Test. We compared the performance of both versions of the prover using
simple formulas (V = 2, N = 3, D = 1). Figure 4 shows four graphs: the
satisﬁability/unsatisﬁability curves together with percentage of timeouts in the
ﬁrst line, and the comparison of space and time resources used in the second.
In all cases, the x-axis represent number of clauses produced by the random
generator (notice that, the bigger the number of clauses generated the bigger
the probability of the clause set to be unsatisﬁable). In the ﬁrst line, the y-axis
shows the percentage of cases of satisﬁability, unsatisﬁability, and timeouts. In
the second line, the y-axis is a logscale and shows median of the number of clauses
generated in the left graph, and median of the execution time (in seconds) in
the right graph.
The performance of HyLoRes 2.0 was clearly better than that of its prede-
cessor. Figure 4 shows that HyLoRes 1.0 couldn’t solve an important fraction
of the simpler problems, while HyLoRes 2.0 solved them all. It is interesting to
observe that HyLoRes 1.0 had the larger number of timeouts in the region where
most of the formulas are satisﬁable, while HyLoRes 2.0 is beneﬁting here from
the restrictions on ordering and selection functions which accelerate saturation.
It is noticeable that in this test the initialization time of HyLoRes 2.0 is higher
than the time needed to solve the problem itself.
 0
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 2
 4
 6
 8
 10
 12
 14
 16
 18
 20
 22
 24
Satisfiable/unsatisfiable portion
L
Hybrid CNF test, V=2, N=3, D=1, L=1..24
hylores 1.0 sat
hylores 1.0 unsat
hylores 1.0 timeout
 0
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 2
 4
 6
 8
 10
 12
 14
 16
 18
 20
 22
 24
Satisfiable/unsatisfiable portion
L
Hybrid CNF test, V=2, N=3, D=1, L=1..24
hylores 2.0 sat
hylores 2.0 unsat
hylores 2.0 timeout
 1
 10
 100
 1000
 0
 2
 4
 6
 8
 10
 12
 14
 16
 18
 20
 22
 24
Median clauses generated
L
Hybrid CNF test, V=2, N=3, D=1, L=1..24
hylores 1.0
hylores 2.0
 0.01
 0.1
 1
 10
 100
 0
 2
 4
 6
 8
 10
 12
 14
 16
 18
 20
 22
 24
Median execution time (secs)
L
Hybrid CNF test, V=2, N=3, D=1, L=1..24
hylores 1.0
hylores 2.0
Fig. 4. h3CNF2m and HyLoRes 1.0 and 2.0 – Simple formulas

Ordered Resolution with Selection for H(@)
139
Second Test. As one can clearly see in Figure 4, a large number of time-
outs negatively aﬀects the representativeness of the plot (see how the satisﬁabil-
ity/unsatisﬁability percentage curves diﬀer between the two graphs in the ﬁrst
line of the ﬁgure). When the modal depth of the formulas is augmented, the
number of cases that HyLoRes 1.0 can solve in a reasonable time becomes too
small to be relevant. Hence the more diﬃcult tests were run only over diﬀerent
conﬁgurations of HyLoRes 2.0.
Figure 5 shows the results for formulas where only the strictly modal complex-
ity was increased: V = 8, N = 3 and D = 7. We only show now the distribution
of satisﬁability, unsatisﬁability and timeouts in the left graph and the cpu usage
on the right graph. In this case, the number of timeouts in the harder zone is
below 15%, however, the mean answer time is still below one second.
This test suggests again that the strategies of order and selection function
are eﬀective (see how times in the satisﬁability section are better than the ones
in the unsatisﬁable region).
 0
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 0
 2
 4
 6
 8
 10
 12
 14
 16
Satisfiable/unsatisfiable portion
L
Hybrid CNF test, V=8, N=3, D=7, L=1..15
hylores 2.0 sat
hylores 2.0 unsat
hylores 2.0 timeout
 0.01
 0.1
 1
 10
 0
 2
 4
 6
 8
 10
 12
 14
Median execution time (secs)
L
Hybrid CNF test, V=8, N=3, D=7, L=1..15
hylores 2.0
Fig. 5. h3CNF2m and HyLoRes 2.0 – Complex formulas, small number of nominals
Third Test. Finally, Figure 6 shows the results obtained with formulas with an
increased number of nominals and a low modal depth: V = 6, N = 7, D = 2. A
larger number of nominals means a more frequent application of paramodulation
rules. This is why HyLoRes 2.0 has a larger number of timeouts here, while the
median execution time in the harder zone is over 10 seconds.
This test indicate that heuristics to control paramodulation (for example
those described in [9]) should be implemented in HyLoRes, as the naive paramod-
ulation used at the moment is too expensive. It is important to observe, though,
that the formulas used in the test shown in Figure 6 have twice the modal depth,
three times the number of propositional variables and more than twice the num-
ber of nominals than those of Figure 4, which HyLoRes 1.0 could barely handle.
6
Conclusions and Future Work
We presented in this paper a sound, complete and terminating strategy of resolu-
tion with order and selection functions for the hybrid language H(@). The paper
shows in addition that standard resolution techniques and notions (e.g., the can-

140
C. Areces and D. Gor´ın
 0
 0.1
 0.2
 0.3
 0.4
 0.5
 0.6
 0.7
 0.8
 0.9
 1
 0
 2
 4
 6
 8
 10
 12
 14
 16
 18
 20
 22
Satisfiable/unsatisfiable portion
L
Hybrid CNF test, V=6, N=7, D=2, L=1..23
hylores 2.0 sat
hylores 2.0 unsat
hylores 2.0 timeout
 0.01
 0.1
 1
 10
 100
 0
 2
 4
 6
 8
 10
 12
 14
 16
 18
 20
 22
Median execution time (secs)
L
Hybrid CNF test, V=6, N=7, D=2, L=1..23
hylores 2.0
Fig. 6. h3CNF2m and HyLoRes 2.0 – Medium formulas, larger number of nominals
didate model construction, the notion of admissible orderings, the deﬁnition of
Herbrand models, etc.) which are crucial part of the actual work on resolution
for classical logics can be adapted to the framework of modal logics when the
hybrid operators (nominals and @) are present. Moreover, the strategy has been
implemented in the HyLoRes prover and the preliminary tests show signiﬁcant
improvements.
We have not yet investigated the complexity of our resolution strategy. We
conjecture that it is ExpTime-hard (and hence not optimal). Further reﬁnements
of the ordering and selection functions used, possibly together with the imple-
mentation of stronger resolution strategies (e.g, hyper resolution) might reduce
the complexity to the optimal bound of PSpace (see, [14]), but these are topics
for future research. More generally, further work on how to choose suitable pa-
rameters (which orderings and selection functions are most eﬀective for a certain
input) and the implementation of optimizations, heuristics and simpliﬁcations
by rewriting remain to be done to enhance the usability of HyLoRes.
Suitable generalizations of the standard notions of redundancy [10] (e.g.,
backwards and forwards subsumption) should also be developed in detail. Hy-
LoRes already implements of some basic ideas, but both theory and practice as
it applies to resolution for modal-like languages, should be further developed.
We are also interested in investigated fragments of H(@) for which resolu-
tion might have a specially good behavior (e.g., ﬁnd a suitable notion of Horn
formulas) on the one hand, and on the other in developing extensions the ac-
tual framework to languages more expressive than H(@) (e.g., considering the
addition of the ↓binder and the universal modality A).
References
1. B. Afshordel, U. Brahm, C. Cohrs, T. Engel, E. Keen, C. Theobald, D. Topi´c,
and C. Weidenbach.
System description: SPASS Version 1.0.0.
In Automated
deduction—CADE-16 (Trento, 1999), pages 187–201, Berlin, 1999. Springer.
2. C. Areces. Logic Engineering. The Case of Description and Hybrid Logics. PhD
thesis, Institute for Logic, Language and Computation, University of Amsterdam,
Amsterdam, The Netherlands, October 2000.

Ordered Resolution with Selection for H(@)
141
3. C. Areces, P. Blackburn, and M. Marx.
A road-map on complexity for hybrid
logics. In Proc. of the 8th Annual Conference of the EACSL, pages 307–321, 1999.
4. C. Areces, P. Blackburn, and M. Marx. Hybrid logics: Characterization, interpo-
lation and complexity. Journal of Symbolic Logic, 66(3):977–1010, 2001.
5. C. Areces, H. de Nivelle, and M. de Rijke. Resolution in modal, description and
hybrid logic. Journal of Logic and Computation, 11(5):717–736, 2001.
6. C. Areces and J. Heguiabehere. HyLoRes: A hybrid logic prover based on direct
resolution. In Advances in Modal Logic, Toulouse, France, 2002.
7. C. Areces and J. Heguiabehere.
hGen: A random CNF formula generator for
Hybrid Languages. In Proc. of Methods for Modalities 3, Nancy, France, 2003.
8. F. Baader, D. Calvanese, D. McGuinness, D. Nardi, and P. Patel-Schneider, edi-
tors. The Description Logic Handbook: Theory, Implementation, and Applications.
Cambridge University Press, 2003.
9. L. Bachmair and H. Ganzinger. Equational reasoning in saturation-based theorem
proving. In Automated deduction—a basis for applications, Vol. I, pages 353–397.
Kluwer, Dordrecht, 1998.
10. L. Bachmair and H. Ganzinger. Resolution theorem proving. In J. Robinson and
A. Voronkov, editors, Handbook of Automated Reasoning, volume 1, chapter 2,
pages 19–99. Elsevier, 2001.
11. P. Blackburn. Representation, reasoning, and relational structures: a hybrid logic
manifesto. Logic Journal of the IGPL, 8(3):339–365, 2000.
12. P. Blackburn, M. de Rijke, and Y. Venema. Modal Logic. Cambridge University
Press, 2002.
13. N. Dershowitz and J. Jouannaud. Rewrite systems. In J. van Leeuwen, editor,
Handbook of Theoretical Computer Science. Volume B: Formal Models and Semat-
ics (B), pages 243–320. Elsevier and MIT Press, 1990.
14. L. Georgieva, U. Hustadt, and R. Schmidt.
Computational space eﬃciency
and minimal model generation for guarded formulae.
In R. Nieuwenhuis and
A. Voronkov, editors, Proc. of the 8th LPAR 2001, number 2250 in LNAI, pages
85–99, 2001.
15. E. Giunchiglia, A. Tacchella, and F. Giunchiglia. SAT-based decision procedures
for classical modal logics. Journal of Automated Reasoning, 28(2):143–171, 2002.
16. V. Haarslev and R. M¨oller. RACER system description. In IJCAR 2001, number
2083 in LNAI, Siena, 2001.
17. D. Harel. Dynamic logic. In D. Gabbay and F. Guenthner, editors, Handbook of
Philosophical Logic. Vol. II, volume 165 of Synthese Library, pages 497–604. D.
Reidel Publishing Co., Dordrecht, 1984.
18. HyLoRes’ Home Page. http://www.loria.fr/~areces/HyLoRes/, 2004.
19. D. Mitchell, B. Sleman, and H. Levesque. Hard and easy distributions of SAT
problems. In Proc. of the 10th National Conference on Artiﬁcial Intelligence, pages
459–465, 1992.
20. S. Passy and T. Tinchev. An essay in combinatory dynamic logic. Information
and Computation, 93(2):263–332, 1991.
21. P. Patel-Schneider and R. Sebastiani. A new general method to generate random
modal formulae for testing decision procedures. Journal of Artiﬁcial Intelligence
Research, 18:351–389, May 2003.
22. A. Riazanov and A. Voronkov. The design and implementation of VAMPIRE. AI
Communications, 15(2):91–110, 2002. Special issue on CASC.
23. A. Voronkov. Algorithms, datastructures, and other issues in eﬃcient automated
deduction. In IJCAR 2001, number 2083 in LNAI, pages 13–28, Siena, 2001.

On a Semantic Subsumption Test
Jerzy Marcinkowski, Jan Otop, and Grzegorz Stelmaszek
Institute of Computer Science, University of Wroclaw,
Przesmyckiego 20, 51151 Wroclaw, Poland
Abstract. We observe, that subsumption of clauses (in the language of
ﬁrst order logic), so far understood as a syntactic notion, can also be
deﬁned by semantical means. Subsumption is NP-complete and testing
subsumption takes roughly half of the running time of a typical ﬁrst
order resolution-based theorem prover. We also give some experimen-
tal evidence, that replacing syntactic indexing for subsumption by our
semantic Monte Carlo technique can, in some situations, signiﬁcantly
decrease the cost of subsumption testing.
Finally, we provide some evidence that a similar semantic idea can be
probably successfully used for testing for AC matching, which is another
NP-complete problem whose millions of instances are being solved by
theorem provers.
1
Introduction
On the level of abstraction appropriate for this paper, a clausual ﬁrst order
resolution/paramodulation based theorem prover can be viewed as an imple-
mentation of the following algorithm.
There are two sets of clauses, A (as available) and SOS (as set of support).
A is initially empty. SOS is initially the set of clauses we want to ﬁnd a contra-
diction in.
While SOS is nonempty, and while the empty clause has not been proved:
a. select a clause D ∈SOS and move it to A,
b. resolve (using the available inference rules) D with all possible partners from
A,
c. for any clause C inferred in the previous step, check if it is not subsumed by
some clause already in A ∪SOS. If there is no clause subsuming C then add C
to SOS,
d. demodulate C using existing demodulators,
e. check for backward subsumption: delete each clause in A ∪SOS which is
subsumed by C.
See subsection 3.1 for the preliminaries about subsumption.
Our main interest in this paper is the subsumption testing step c.1. It takes
around half of the running time of a typical theorem prover. This is not sur-
prising, since millions of pairs of clauses need to be tested for subsumption in a
1 Although, also step e. will be brieﬂy addressed in Section 2.
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 142–153, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

On a Semantic Subsumption Test
143
single run, and since deciding, for two given clauses, whether one of them sub-
sumes another is NP-hard. Complicated data structures have been developed
to support subsumption tests, including discrimination trees [C93], [G86], with
their most advanced version, called code trees [V95], implemented in Vampire
[V] (see [SRV01] for a survey of term indexing). Since subsumption is a syntactic
notion, it is the syntax of the clauses which is indexed in the trees.
In this paper we show some evidence, that in some cases, a simple semantical
indexing technique can possibly prove more eﬃcient in this context, than the
known complicated syntactic data structures.
2
Semantic Redundancy Detection – First Idea
In our approach, as the ﬁrst step of the run of the theorem prover, we ﬁx some
ﬁnite number p (in our implementation this number is between 20 and 64) of
small randomly drawn structures M1, M2 . . . Mp over the signature of interest.
Then, for each newborn clause C we compute what we call proﬁle of C: the tuple
of numbers P(C) = ⟨i1, i2, . . . ip⟩, where ij is the truth value of C in Mj (this is
not a mistake, as we are going to explain in Section 3 the truth values ij can
indeed be numbers from the set {1, 2, 3} rather than bits). We index clauses in
SOS and in A with respect to their proﬁles.
For two proﬁles P1 = ⟨i1, i2, . . . ip⟩and P2⟨l1, l2, . . . lp⟩we say that P1 domi-
nates P2 if for each j it holds that ij ≥lj.
Now, our idea is shamefully simple: if C1 subsumes C2 then PC2 dominates
PC1, whatever the structures M1, M2 . . . Mp are. So, if for some proﬁle P in the
index, and for some newborn clause C, proﬁle PC does not dominate P then we
get the negative answer we wanted to get: we can be sure that no clause with
index entry P can subsume C.
Testing domination is very fast. A proﬁle is remembered as 64 bits (if ij are
numbers from the set {0, 1, 2} then we store them using unary encoding, which
takes 2 bits per number, so we can aﬀord at most 32 proﬁles then). Testing
whether one proﬁle dominates another takes just two machine instructions.
If we are lucky, then we can test negative for subsumption hundreds of clauses
for the cost of two machine instructions. If we are not lucky, then the proﬁle PC
dominates P and we get the positive answer that some of the clauses with index
P may subsume C. We need to perform a full syntactic subsumption test then,
for C and each clause C′ in A ∪SOS such that P = P(C′).
As for each indexing technique, the performance of our method depends on
two factors. The ﬁrst of them is the computational overhead, the second is the
selectivity of the index, or, in other words, the fraction of negative instances
returned as false positives.
The computational overhead is mainly the cost of computing the proﬁles. It
is, of course, linear with respect to the number p - the length of the proﬁles, and
proportional to the size of the models to the power of the number of variables
in the clauses. This rough calculation led us to the implementation decision of

144
J. Marcinkowski, J. Otop, and G. Stelmaszek
having relatively many (up to 64 of them, as we said) small (consisting of 4, or
even of 2 elements) models.
What concerns selectivity, we built our ﬁrst hopes on a (clearly oversimplify-
ing) assumption that the truth values of clauses in models would be distributed
uniformly and independently. Then (assuming that we use 64 proﬁles), if there
are just two truth values, zero and one, the probability of a false positive, which
is the probability that a random proﬁle P1 of length 64 dominates P2, should be
(3/4)64 which is around 10−9.
The more truth values the better. The probability of a false positive would
go down to only (2/3)64, which is about 10−12 if we had three truth values2.
Of course the real distribution is not that beautiful. One could also fear that
our harsh restrictions on the size of the models must result with bad selectivity.
But the results are anyway quite optimistic: In Section 3.3 and 3.4 we show that
for a very natural example proﬁles built of 64 models of size four, or even size
two give very good selectivity. In Section 4, where our main experimental results
are presented, we show that an index using a proﬁle of 64 models of size two
performs, on inputs consisting of long clauses, better than discrimination trees.
It could appear from what we wrote so far, that what our index can detect
is non-implication of clauses rather than non-subsumption. This could mean
that we will get a false positive result each time when C implies D but does
not subsume it. As we however explain in the next section this problem can be
avoided by using a logic in which implication3 coincides with subsumption.
2.1
Backward Subsumption
One of the options in a run of a typical theorem prover is another redundancy
test: detecting backward subsumption. Whereas (forward) subsumption test pre-
vents us from adding to SOS a clause that is less general than (i.e. subsumed
by) a clause already present in A ∪SOS, backward subsumption test removes
from SOS the clauses which are subsumed by a newly added clause C. It is not
a default option of theorem provers, since the number of removed redundant
clauses is usually too small compared to the time that the procedure takes. In
our method the main overhead is computing the proﬁles. This means that we
can have backward subsumption almost for free.
3
On a Semantics of Subsumption
3.1
Subsumption: Preliminaries
Let Σ be a ﬁrst order signature (which means that it consists of some constants,
function symbols and relation symbols), and let V be a countable set of variables.
We denote as TV (Σ) the set of all terms over Σ with variables from V .
2 But with 32 models and three truth values it would be about 10−6. Surprisingly we
will go back to this point in the end of Section 4.3.
3 The word implication
always means semantic implication
in this paper. Do not
confuse it with syntactic notion of derivability.

On a Semantic Subsumption Test
145
A clause is a universal closure of a disjunction of literals over Σ. We often
think of a clause as of the ﬁnite set of its literals, so that we can for example use
the notation C ⊆D for clauses C and D.
We say that C subsumes D if there exists a substitution σ such that σ(C) ⊆D.
Subsumption is a way of saying that one clause is ”more general” than another
but it should not be confused with implication:
Example. Consider a clause C1 step = {¬P(x), P(f(x))} and a clause C2 steps =
{¬P(x), P(f(f(x)))}. It is easy to see that C1 step implies C2 steps but does not
subsume it.
So subsumption does not follow from implication. The opposite is trivially
true, but despite its triviality we will state and prove the result here. This is
because we will need to refer to its proof later and because we want to ﬁx
notations:
Deﬁnition 1. Let M be a relational structure over Σ and let τ be a valuation
of variables in M, i.e. a function from V to M (to keep the notations simple
we do not distinguish between the structure M and its universe). By ¯τ we mean
the canonical extension of τ to objects like terms, atomic formulas and literals
(so, if L is a literal then ¯τ(L) is a truth value). Let C be a clause. Deﬁne the
truth value of C in M, (denoted as TV (C, M)) as: minτ:V →M maxL∈C
¯τ(L)
We say that C (ﬁnitely) implies D if for any (ﬁnite) structure M it holds that
TV (C, M) ≤TV (D, M).
Notice that our deﬁnition, although maybe written in a slightly bizarre way,
is just the standard one. The minimum (taken over the set of possible valuations)
is exactly universal quantiﬁcation, while the maximum over values of literals is
disjunction (of course we assume that false is 0 and thus is smaller than true
which equals 1).
Observation 1 If C subsumes D then C implies D.
Proof. Assume C subsumes D. This means that there exists a substitution σ
such that σ(C) ⊆D. We need to show that for any valuation τD there exists a
valuation τC such that maxC∈C ¯τC(C) ≤maxD∈D ¯τD(D). Take τC = τDσ. Then
maxC∈C ¯τC(C) = maxD∈σ(C) ¯τD(D) ≤maxD∈D ¯τD(D).
3.2
Multi-valued Logics
By a multi-valued logic we mean here any pair L = ⟨L, ¬⟩, where L is a totally
ordered set of truth values and ¬ : L →L is a function. Notice that the standard
notion of relational structure can be generalized to multi-valued logics: the only
diﬀerence is that the interpretation of relational symbol of arity k is a function
from M k to L now, not from M k to {0, 1} as usually (M is the universe of the
relational structure). Also Deﬁnition 1 can be applied in the context of multi-
valued logics. It turns out that Observation 1 survives the generalization:

146
J. Marcinkowski, J. Otop, and G. Stelmaszek
Observation 2 If C subsumes D then C implies clause D in each multivalued
logic L.
Proof. Reread the proof of Observation 1.
3.3
Main Observation
Consider the following Strange Four-Valued Logic (S4VL). The elements of L are
XT (so extremely true that even its negation remains extremely true: ¬XT=XT),
T (simply true: ¬T=F), F (simply false ¬F=T) and XF (so extremely false
that even its negation remains extremely false: ¬XF=XF). The total order is
XT > T > F > XF. It turns out that implication in S4VL does not coincide
with standard implication. Consider the clauses from the example from Section
3.1. We take M = {0, 1, 2, 3} and interpret the function symbols as f(0) = 1,
f(1) = 2, f(2) = f(3) = 3. As the interpretation of P we take P(0) = T, P(2) =
F, P(1) = P(3) = XT. Then TV (C1 step, M) = T but TV (C2 steps, M) = F, so
C1 step does not imply C2 steps in S4VL. This is not just a coincidence, as we are
going to show now:
Observation 3 (A semantics of subsumption) Subsumption of clauses is
ﬁnite implication in S4VL.
Notice, that since ﬁnite implication in any logic follows from implication in
the same logic, by Observation 2 we get that subsumption of clauses coincides
with implication in S4VL.
Proof. Let D be any clause. We will construct a ﬁnite relational structure MD,
with relational symbols interpreted as functions to {XT,T,F,XF}, such that
TV (C, MD) > TV (D, MD) for each clause C such that C does not subsume D .
The construction will be a generalization of the example from the beginning of
this subsection. Let d be a natural number greater than the depth of the deepest
term in D. For two terms t, s ∈TV (Σ) let R be the equivalence relation such
that sRt if and only if t and s are equal up to depth d. We deﬁne the universe
of MD to be the set of all equivalence classes of R. Notice that the equivalence
classes of terms not deeper than d are singletons, so we can identify such terms
with their classes. The interpretation of functions from Σ in MD is deﬁned in
the canonical way. What remains to be deﬁned are the functions which are the
interpretations of the relation symbols from Σ. Let P(¯t) be an atomic formula.
We consider four cases:
(i) P(¯t) ∈D and (¬P(¯t)) ∈D. Then interpret P(¯t) as XF.
(ii) P(¯t) ∈D but (¬P(¯t)) ̸∈D. Then interpret P(¯t) as F.
(iii) P(¯t) ̸∈D but (¬P(¯t)) ∈D. Then interpret P(¯t) as T.
(iv) P(¯t) ̸∈D and (¬P(¯t)) ̸∈D. Then interpret P(¯t) as XT.
Let now τid be identity. Then minτ:V →MD maxL∈D ¯τ(L) ≤maxL∈D ¯τid(L) ≤
F. On the other hand, if C does not subsume D, then for any valuation τ there

On a Semantic Subsumption Test
147
exists a literal L ∈C such that ¯τ(C) ̸∈D. This implies that ¯τ(C) ≥T . So
minτ:V →MD maxL∈D ¯τ(L) ≥T.
Since in practice we never test for subsumption clauses containing both a
literal and its negation (they are easily detected and deleted as tautologies), XF
is unnecessary, and we just need 3 truth values for a logic in which implication of
clauses coincides with subsumption4. If the interpretation of P is assumed to be a
function with three truth values, then there are 44∗34 four-element models for the
signature {P, f} of our running example5. Among them, there are 2220 (which is
10.7%) such structures M that TV (C1 step, M) > TV (C2 steps, M). This means
that the probability that for a random sequence M1, M2 . . . M64 of four-element
models PC1 step will dominate PC2 steps (and our semantic subsumption test will
return a false positive) is 0.89364 < 0.001.
Notice that S4VL is by no means the unique logic for which Observation 3
holds true. For example a logic with the same set of truth values as S4VL, and
the same negation, but with the ordering T > XT > XF > F would work as
well.
3.4
Size of the Models
Unlike the set of truth values, the structure MD, witnessing no-subsumption
cannot be kept small. In our proof it is exponential in the size of D. It is quite
unlikely that it could always be polynomial: this would mean that subsumption
is in co-NP, and thus that NP=co-NP. It appears however that for most of the
practical situations there are many structures which witness no-subsumption
and which are of size much smaller than the upper bound following from the
proof of Observation 3.
Exercise. The size of the structure MC2 steps, constructed as in the proof of Ob-
servation 3 is four. Show that among the 36 two-element models for the signature
{P, f} and logic S4VL, there are 4 structures M such that TV (C1 step, M) >
TV (C2 steps, M). The signature is too small here to allow proﬁles of length 64,
but the frequency of ”good” models is almost the same here as among the four
elements models.
4
Implementation
We implemented our semantic subsumption test in the Otter theorem prover
[OT]. The reason for this choice was that we found Otter sources relatively easy
to understand, and thus to make changes in6. We realize that it is not the fastest
theorem prover available, and that being able to improve Otter is not really a
4 Let us leave the truth value XF to the politicians. They know how to make good
use of it.
5 We count ordered structures here.
6 We are grateful to the authors of Otter for their copyright policy, which made our
work possible.

148
J. Marcinkowski, J. Otop, and G. Stelmaszek
good reason to be proud. But on the other hand, like Otter itself, our techniques
also still leave a lot of room for improvement.
Compared to the original Otter we deleted the discrimination tree based
subsumption test7, and replaced it by a semantic test. We took care not to
change anything else in the prover, so the proof search itself remains unchanged.
In principle our versions should be able to prove the same theorems in the same
way as Otter does, although not necessarily in the same time limit.
We tested four parameter choices for out implementation. The parameters
are: the number of models in a proﬁle, the size of the models, the number of
possible truth values in the interpretations of the predicates, and the way in
which negation is handled (see Table 1).
For each of the versions, we wanted the proﬁle to be no longer than 64 bits,
which means that the number of models multiplied by [the number of possible
truth values minus one] could not be greater than 64.
Table 1. Our versions of Otter
Number
Size
Number
Interpretation
of models of models of truth values of negation
2/2 semantic Otter 64
2
2
identity
2/3 semantic Otter 32
2
3
S4VL
3/3 semantic Otter 32
3
3
identity
4/4 semantic Otter 20
4
4
identity
Concerning negation, let us remind ourselves that Observation 2 holds for any
interpretation of negation. In three of our four versions we interpreted negation
as the identity, in one version it was interpreted according to the rules of the
logic S4VL.
We also ran some tests with a version of 2/2 semantic Otter with the classical
interpretation of negation. It appears to be a little bit worse than 2/2 semantic
Otter, but the tests were too few to be conclusive.
4.1
Indexing the Proﬁles
As we said in Section 2, our main idea is that the clauses are indexed by their
proﬁles. In our interpretation we decided to index also the proﬁles themselves.
We use a tree of (maximal) depth 16 and (maximal) arity 16, where the
children of a node i1i2 . . . i4k (nodes represent preﬁxes of proﬁles) are all the
7 Because of unit deletion we could not however completely get rid of discrimination
trees.

On a Semantic Subsumption Test
149
nodes of the form i1i2 . . . i4ki4k+1 . . . i4k+4, where ij ∈{0, 1}. But of course we
do not create a node unless there is a clause with a corresponding proﬁle.
Now, for a given new clause C we want to select all the proﬁles P from the
index, such that P(C) = j1j1 . . . j64 dominates P. In order to do so, being in the
node i1i2 . . . i4k enter all its existing children of the form i1i2 . . . i4ki4k+1 . . . i4k+4
such that j4k+1 . . . j4k+4 dominates i4k+1 . . . i4k+4.
4.2
Computing the Proﬁles
The most expensive operation in our approach is computing the proﬁle of a
new clause. This means computing its truth value in the given structures. Pes-
simistically it can take time proportional to the number of possible valuations
of variables, which is kn where n is the number of variables in the variables in
the clause and k is the size of the structure. Since the clauses that we encounter
can easily have more than 10 variables, the cost seems almost unaﬀordable. In
our implementation we used a semi-naive algorithm which, in practical cases,
reduces the number of valuations that need to be considered. It takes advantage
of the fact that the variables rarely are “non-local” for the same subterms: to
compute the set of possible values of the term g(t1(x1, . . . x5, z), t2(y1, . . . y5, z))
in a structure consisting of 4 elements we do not need to consider 411 valuations.
It is enough to compute the set of possible values of t1(x1, . . . x5, z) as a function
of z, and the set of possible values of t2(y1, . . . y5, z) as a function of z , which
requires only 46 valuations. The last number can usually be reduced again, if we
repeat the trick inside t1 and t2.
There are at least 2 possible ways in which we think we could be looking for
a real optimization here:
1. So far we treat terms as trees. We think we could beneﬁt a lot from
exploiting their DAG structure.
2. Each new clause C is a result of applying an inference rule to some clauses
C1 and C2, whose proﬁles were computed before. The structure of C is to some
extent similar to the structures of C1 and C2. Maybe we could gain something
by remembering the partial results of the computations of P(C1) and P(C2).
4.3
Results of the Tests
We ran Otter and 2/2 semantic Otter against the whole TPTP library We se-
lected our Reference Set, as the set of the 345 theorems which satisfy the two
conditions:
-at least one of the two programs proves it within 300 seconds, with a memory
limit of 515 megabytes,
-at least one of the two programs needs more than 5 seconds to prove it.
Then we ran the remaining 3 versions of semantic Otter on the Reference
Set. The results of the tests can be found in Tables 2-5.
As one could expect, the results are quite encouraging for problems with
long clauses, and very poor for short clauses. What we found surprising is the

150
J. Marcinkowski, J. Otop, and G. Stelmaszek
Table 2. Otter vs. 2/2 semantic Otter (by maximal number of literals in the input
clauses, run on the Reference Set)
Maximal
Theorems
Theorems
Theorems
Theorems
Theorems
number of not proved by for which
for which
for which
not proved
literals in
2/2 semantic
Otter was
they perform Otter was
by Otter
the input
Otter
> 30% faster equally
> 30% slower
clauses
4 or less
77
165
4
11
5
5
3
14
1
4
1
6
0
0
0
2
1
7
0
1
0
5
1
8
0
0
0
6
11
9
1
0
0
0
1
10 to 19
0
1
0
10
6
FOF
0
0
0
3
5
sharpness of the threshold: semantic Otter rarely beats the original version for
the instances with a clause with the maximal number of literals in the input
equal to 5 or less, and hardly ever gets beaten for the instances with a clause
with 6 or more literals. This means that a hybrid Otter, reading the input ﬁrst
and then, on the basis of the length of the clauses deciding if it should use the
semantic tests or rather stick to the traditional way, would easily outplay all the
versions of the prover.
What we did not expect was also that 2/2 semantic Otter would be the best
of the semantic versions. The results in Table 4 could be altered by the fact
that the deﬁnition of the Reference Set itself depended on the behavior of 2/2
semantic Otter. But the results in Table 5 constitute a hard piece of evidence:
2/2 semantic Otter is faster than its brothers. And, with its two truth values, it
cannot even see the diﬀerence between non-implication and non-subsumption.
We are not sure where the reasons of this superiority are. Clearly, computing
the proﬁles should be twice cheaper in in 2/3 semantic Otter than in 2/2. So the
selectivity of the 2/2 version must be better than of 2/3. Could it have anything
to do with the rough calculations in footnote 2 (Section 2)?

On a Semantic Subsumption Test
151
Table 3. Otter vs. 2/2 semantic Otter (by TPTP domain, not all domains included,
run on the Reference Set)
Theorems
Theorems
Theorems
Theorems
Theorems
TPTP
not proved by for which
for which
for which
not proved
domain 2/2 semantic
Otter was
they perform Otter was
by Otter
Otter
> 30% faster equally
> 30% slower
BOO
3
16
0
0
1
GRP
24
65
4
7
5
LCL
45
52
0
0
0
SYN
3
14
0
1
0
CAT
0
0
0
6
1
GEO
0
0
0
8
19
HWV
0
0
0
9
1
MGT
0
0
0
3
1
5
Future Work
Develop better algorithms for computing the proﬁles, and for indexing. Tune
the parameters (including the way negation is treated). Implement the thing in
Vampire.
6
Related Idea: AC Matching and Uniﬁcation
For a structure M and a term t ∈TV (Σ) deﬁne V ar(t, M) as {¯τ(v) : τ : V →
M}, that is the set of possible values of t in M. Suppose t is an instance of s.
Then for each structure M it holds that V ar(t, M) ⊆V ar(s, M). If t and s are
uniﬁable then, for each structure M, it holds that V ar(t, M) ∩V ar(s, M) ̸= ∅.
This leads to the idea of a semantic matching/uniﬁcation test. This does not
make much sense in the case of matching and uniﬁcation in the free term algebra
- they are easy to compute anyway. But the above observation holds true also
for the AC case. AC matching, like subsumption, is NP-complete and it turns
out that it is AC matching that takes most of the running time of EQP [EQP],
a cousin of Otter built to prove theorems in ﬁrst-order equational logic.
We built a naive implementation of the above idea in EQP. Terms were pro-
ﬁled by 32 random models, each of them of size 4 (the interpretations of the
AC symbol were drawn to be AC functions). For the evaluation of V ar(t, M)
we used the algorithm from Section 4.2. Of course we did not remove the orig-
inal matching procedure from EQP. But each time EQP wants to execute this

152
J. Marcinkowski, J. Otop, and G. Stelmaszek
Table 4. Theorems not proved by diﬀerent versions of otter (by the maximal number
of literals in the input clauses, run on the Reference Set)
Maximal number Theorems
Theorems
Theorems
Theorems
Theorems
of literals
not proved by not proved by not proved by not proved by not proved
in the input
2/2 semantic
2/3 semantic
3/3 semantic
4/4 semantic
by Otter
clauses
Otter
Otter
Otter
Otter
4 or less
77
101
93
105
5
5
3
8
6
8
1
6
0
1
0
0
1
7
0
1
0
0
1
8
0
6
2
6
11
9
1
1
1
1
1
10 to 19
0
7
2
2
6
FOF
0
2
2
2
5
Table 5. 2/2 semantic Otter vs. other semantic versions (on theorems from Reference
Set proved by both compared versions)
Version
Theorems
Theorems
of Otter
on which
on which
2/2 semantic Otter 2/2 semantic Otter
is faster
is slower
2/3 semantic Otter 169
12
3/3 semantic Otter 121
2
4/4 semantic Otter 187
4

On a Semantic Subsumption Test
153
procedure for some terms s and t we ﬁrst check if for each of our models Mi it
holds that V ar(t, Mi) ⊆V ar(s, Mi). If this is not the case we can be sure the
terms do not match. Otherwise we proceed with the original EQP matching.
Our program was tested on Lemma 1 and Lemma 2 from the proof of the
famous Robbins Conjecture [MC97]. The results we got are quite encouraging
(see Table 6).
Table 6. EQP vs. semantic EQP on the lemmas of Robbins Conjecture
EQP
semantic EQP
Lemma 1 - total time
72.67 sec
36.74 sec
Lemma 1 - matching time 56.13 sec
20.49 sec
Lemma 2 - total time
25477.20 sec 11405.72 sec
Lemma 2 - matching time 21030.06 sec 6812.41 sec
References
C93.
J. Christian; Flat terms, discrimination nets, and fast term rewriting; Journal
of Automated Reasoning 10(1), 95-113 (1993)
EQP.
EQP Equational Prover; http://www-unix.mcs.anl.gov/AR/eqp/
G86.
S. Greenbaum; Input transformations and resolution implementation tech-
niques for theorem proving in ﬁrst order logic, PhD thesis, Univ. of Illinois, at
Urbana Champaign, (1986)
MC97.
W. McCune, “Solution of the Robbins Problem”, Journal of Automated Rea-
soning 19(3), 263–276 (1997)
OT.
Otter: An Automated Deduction System;
http://www-unix.mcs.anl.gov/AR/otter/
TPTP. The TPTP (Thousands of Problems for Theorem Provers) Problem Library
for Automated Theorem Proving by GeoﬀSutcliﬀe and Christian Suttner;
http://www.cs.miami.edu/~tptp/
SRV01. R. Sekar, I.V. Ramakrishnan, A. Voronkov; Term Indexing; in Handbook of
Automated Reasoning, A. Robinson and A. Voronkov eds, Elsevier/MIT Press,
2001
V95.
A. Voronkov; The anatomy of vampire: implementing bottom-up procedures
with code trees; Journal of Automated Reasoning 15(2), 237–265 (1995)
V.
http://www.cs.man.ac.uk/~riazanoa/Vampire/ and
http://www.prover.info/

Suitable Graphs for Answer Set Programming
Thomas Linke and Vladimir Sarsakov
Institut f¨ur Informatik, Universit¨at Potsdam
linke@cs.uni-potsdam.de
Abstract. Often graphs are used to investigate properties of logic pro-
grams. In general, diﬀerent graphs represent diﬀerent kinds of informa-
tion of the underlying programs. Sometimes this information is not suﬃ-
cient for solving a certain problem. In this paper we deﬁne graphs which
are suitable for computing answer sets of logic programs. Intuitively, a
graph associated to a logic program is suitable for answer set semantics if
its structure is suﬃcient to compute the answer sets of the corresponding
program. We identify diﬀerent classes of graphs to be suitable for diﬀer-
ent classes of programs. We also give ﬁrst experimental results showing
the impact of the used graph type to one particular graph based algo-
rithm for answer set computation.
1
Introduction
Many diﬀerent types of graphs are associated with a given logic program in or-
der to investigate its properties or to compute its answer sets. Among them we
ﬁnd dependency graphs (DGs) [3], (deﬁned on atoms), rule graphs (RGs) [9]
(deﬁned on rules for reduced negative normal programs) and more recently ex-
tended dependency graphs (EDG) [6,8] (deﬁned on labeled atoms), as well as
rule dependency graphs (RDGs) [12,16] (deﬁned on rules of normal programs). In
general, diﬀerent graphs represent diﬀerent dependencies among rules or atoms
(literals) of a given program. Sometimes this information is not suﬃcient for
solving a certain problem. In this paper we are interested in the question which
graphs are suitable for computing answer sets of logic programs. Intuitively, a
class of graphs is suitable for answer set semantics of a class of programs if the
structure of a graph is suﬃcient to compute the answer sets of the corresponding
program. For an example, let us take a look at the dependency graphs of the
following two programs together with its answer sets:
P1 =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
x ←not a, not x.
x ←not b.
a ←not b.
b ←not a.
⎫
⎪
⎪
⎬
⎪
⎪
⎭
P2 =
⎧
⎨
⎩
x ←not a, not b, not x.
a ←not b.
b ←not a.
⎫
⎬
⎭
AS(P1) = {{a, x}}
AS(P2) = {{a}, {b}}.
The dependency graph [3] of a program is deﬁned on its atoms s.t. there is a
positive (negative) edge from p to q if p appears positively (negatively) in the
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 154–168, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

Suitable Graphs for Answer Set Programming
155
body of a rule with head q. According to this deﬁnition both programs P1 and P2
have the same DG which is shown in Figure 1. On the other hand, programs P1
b
a
x
−
−
−
−
Fig. 1. The dependency graph of programs P1 and P2
and P2 have diﬀerent answer sets AS(P1) and AS(P2). This semantic diﬀerence
between the two programs cannot be detected from the structure of the corre-
sponding dependency graph, since it does not contain information on the rules of
the two programs. Hence classical dependency graphs are not suitable for answer
set computation of negative programs (programs without positive body atoms).
For dealing with this problem diﬀerent alternative graph representations for logic
programs have been proposed [9,6,18,13,16]. However, considering normal logic
programs with multiple positive atoms in the bodies of rules, same problems as
the above arise in the aforementioned approaches. In this case, rule graphs for
example are not able to represent information indicating which node (rule) is
responsible for deriving which positive body atom of another rule (see RDG of
programs P4 and P5 in Figure 4). Therefore the approaches in [9,6] rely on a
translation of normal programs into negative ones before using there respective
graph representation for characterizing answer sets, whereas [13,18] utilizes some
kind of additional meta-information not present in the graph structure. In fact,
so far this kind of meta-information was also used in the noMoRe system [1] to
deal with arbitrary normal programs.
This paper deals with this problem. In fact, diﬀerent types of graphs are
deﬁned and their suitability for answer set computation of some syntactically
restricted subclasses of nested logic programs [15] is investigated. The main
idea of our approach is to allow diﬀerent kinds of nodes in a graph, in order
to incorporate more information of the underlying logic program, than e.g. the
classical dependency graph does (see above example and Figure 1). This avoids
the use of negative programs or meta-information. In fact, a program consists
of bodies, rules and heads, which all may appear as nodes in a corresponding
graph. The ﬁrst central contribution of this work is the identiﬁcation of so-
called body-head-graphs as the most compact graph representation for all classes
of programs under consideration. We formalize the concept of suitability and
prove that body-head-graphs are suitable for answer set computation of nor-
mal nested logic programs (nNLPs), a syntactically restricted subclass of nested
logic programs. To the best of our knowledge, this is the ﬁrst time that graphs
corresponding to those programs are introduced and utilized to characterize and
compute their answer sets. Hence we generalize results from [9,6,18,13,16]. Addi-
tionally, we obtain suitable graphs for normal logic programs (nLP), normal logic

156
T. Linke and V. Sarsakov
programs with at most one positive body atom (nLP1) and negative programs
(nLP0).
Furthermore, we have implemented our approach in the noMoRe system. This
ensures fair experimental results when comparing the diﬀerent graph represen-
tations. Our ﬁrst experimental results indicate that body-head-graphs are better
suited for computing answer sets than the other discussed graph representations,
as they lead to the most eﬃcient graph-based computation of answer sets.
The paper is organized as follows. In the next section basic concepts for logic
programming and directed graphs are introduced. Section 3 deﬁnes diﬀerent
new graphs associated with logic programs. Then, in Section 4, a special non-
standard graph coloring for a general class of labeled directed graphs is deﬁned
without any references to programs. In Section 5 suitability of graphs for answer
sets programming is deﬁned by relating the aforementioned graph colorings for
the graphs given in Section 3 to the answer sets of the corresponding programs.
Experimental results comparing the diﬀerent graphs are presented in Section 6
and Section 7 concludes the paper.
2
Background
In this paper we consider a proper subclass of propositional nested logic pro-
grams [14]. Nested logic programs generalize logic programs by allowing bodies
and heads of rules to contain arbitrary nested expressions. Let L be a proposi-
tional language. Then an expression is formed from propositional atoms from L
using the operators
,
;
not
standing for conjunction, disjunction and default negation, respectively. Literals
are expressions of the form p (positive literals) or not p (negative literals), where
p is some propositional atom. A rule r has the form
h1, . . . , hk ←B1; . . . ; Bn
(1)
where h1, . . . , hk are atoms and B1, . . . , Bn are conjunctions of literals or ⊤
(true) or ⊥(false). A rule r is called a fact if n = 1 and B1 = ⊤; r is called
normal if k = 1 and n = 1. If rule r contains no default negation not then it is
called a basic rule; a program is basic if it contains only basic rules. A normal
nested logic program (nNLP) is a ﬁnite set of rules of the form (1). A normal logic
program (nLP) is a ﬁnite set of normal rules. Furthermore, we consider the class
of normal programs with at most one positive body literal (nLP1) and the class of
negative programs (nLP0), which do not have any positive body literals. Notice
that nLP0 ⊂nLP1 ⊂nLP ⊂nNLP. For a rule r we deﬁne the head and the body
of r as Head(r) = {h1, . . . , hk} and Body(r) = {B1, . . . , Bn}, respectively. For a
set of rules P we deﬁne Head(P) = ∪r∈P Head(r) and Body(P) = ∪r∈P Body(r).
If B ∈Body(P) s.t. B = (p1, . . . , pl, not s1, . . . , not sm) then B+ = {p1, . . . , pl}
and B−= {s1, . . . , sm} denote the positive and negative part of B, respectively.
If B = ⊤then we set B+ = B−= ∅. If B = ⊥then we set B+ = B−= ⊥.
Furthermore, let Atm(P) denote the set of all atoms occurring in program P.

Suitable Graphs for Answer Set Programming
157
Answer sets were ﬁrst deﬁned in [15] for general nested programs. Here we
adapt the deﬁnition of stable models [11] (answer sets for normal programs) to
normal nested logic programs. A set of atoms X is closed under a basic program
P iﬀfor any r ∈P, Head(r) ⊆X whenever there is a B ∈Body(r) s.t. B+ ⊆X.
The smallest set of atoms which is closed under a basic program P is denoted by
Cn(P). The reduct, P X, of a program P relative to a set X of atoms is deﬁned
in two steps. First, let B ∈Body(P) and let X be some set of atoms. Then the
reduct BX of B relative to X is deﬁned as
BX =

B+ if B−∩X = ∅
⊥
otherwise.
For a rule of the form (1) we deﬁne rX = h1, . . . , hk ←BX
1 ; . . . ; BX
n . Second, for
a normal nested program P we deﬁne P X = {rX | r ∈P and Body(rX) ̸= {⊥}}.
Then P X is a basic program. We say that a set X of atoms is an answer set of a
program P iﬀCn(P X)=X. For normal logic programs this deﬁnition coincides
with the deﬁnition of stable models [14]. The set of all answer sets of program
P is denoted by AS(P).
Now let P be a normal nested logic program and let X be a set of atoms.
Rule r ∈P is captured wrt X iﬀfor each B ∈Body(r) we have B+ ∪B−⊆X.
Program P is captured iﬀall of its rules are captured wrt Head(P). Observe
that each logic program P can be transformed to some captured program P ′
s.t. AS(P) = AS(P ′). Hence, without loss of generality, we restrict ourselves to
captured programs.
A directed graph (or digraph) G is a pair G = (V, E) such that V is a ﬁnite
set (nodes) and E ⊆V × V is a set (arcs). For a digraph G = (V, E) and
a vertex v ∈V , we deﬁne the sets of all predecessors and successors of v as
Pred(v) = {u | (u, v) ∈E} and Succ(v) = {u | (v, u) ∈E}, respectively. A
digraph G′ = (V ′, E′) is a subgraph of G = (V, E) iﬀV ′ ⊆V and E′ ⊆E. A
path from v to v′ in G = (V, E) is a sequence Pvv′ = (v1, . . . , vn) of nodes of
G s.t. n > 1, v = v1, v′ = vn and (vi, vi+1) ∈E for each 1 ≤i < n. A graph
G = (V, E) is acyclic iﬀfor each node v there is no path from v to v.
3
Graphs for Logic Programs
This section deﬁnes diﬀerent graphs corresponding to logic programs. We need
the following general concept of labeled digraphs.
Deﬁnition 1. Let V and L and E ⊆V × V be ﬁnite sets. A quadruple G =
(V, E, l, L) is a labeled digraph iﬀthe following two conditions hold:
1. (V, E) is a digraph and
2. l : E →L is a function (labeling function).
Labeld digraph G = (V, E, l, L) is acyclic iﬀdigraph (V, E) is acyclic. Let G =
(V, E, l, L) be a labeled digraph s.t. L = {l1, . . . , ln}. Then we denote G by
(V, El1, . . . , Eln) where Ek = {(u, v) | (u, v) ∈E, l((u, v)) = k} for each k ∈L.

158
T. Linke and V. Sarsakov
Let G+,∗,−denote the class of labeled digraphs with label set L = {+, ∗, −}.
G = (V, E+, E∗, E−) is a subgraph of G′ = (V ′, E′
+, E′
∗, E′
−) iﬀV ⊆V ′ and
Ei ⊆E′
i for each i ∈{+, ∗, −}.
The arcs in G ∈G+,∗,−are called i-arcs for each i ∈L. For a graph G ∈G+,∗,−
and a node v of G deﬁne the i-predecessors and i-successors of v for each i ∈L
as follows:
Predi
G(v) = {v′ | (v′, v) ∈Ei} for i ∈{+, ∗, −}
Succi
G(v) = {v′ | (v, v′) ∈Ei} for i ∈{+, ∗, −}.
As mentioned in Section 1, a program consists of bodies, rules and heads
(atoms). Based on this observation we deﬁne diﬀerent dependency graphs asso-
ciated with a program P.
Deﬁnition 2. Let P be a logic program.
The BH-graph (body-head-graph) BHP = (Body(P)∪Head(P), E+, E∗, E−) of
P is a directed graph with labeled arcs
E+ = {(B, h) | r ∈P, B ∈Body(r), h ∈Head(r)}
E∗= {(h, B) | B ∈Body(P), h ∈Head(P), h ∈B+}
E−= {(h, B) | B ∈Body(P), h ∈Head(P), h ∈B−}.
The RH-graph (rule-head-graph) RHP = (P ∪Head(P), E+, E∗, E−) of P is a
directed graph with labeled arcs
E+ = {(r, h) | r ∈P, h ∈Head(r)}
E∗= {(h, r) | r ∈P, h ∈Head(P), h ∈B+, B ∈Body(r)}
E−= {(h, r) | r ∈P, h ∈Head(P), h ∈B−, B ∈Body(r)}.
The BR-graph (body-rule-graph) BRP = (Body(P) ∪P, E+, ∅, E−) of P is a
directed graph with labeled arcs
E+ = {(B, r) | r ∈P, B ∈Body(r)}∪
{(r, B) | r ∈P, B ∈Body(P), Head(r) ∩B+ ̸= ∅}
E−= {(r, B) | r ∈P, B ∈Body(P), Head(r) ∩B−̸= ∅}.
Observe that all graphs in Deﬁnition 2 have two diﬀerent kinds of nodes such
as rules and heads for rule-head-graphs, bodies and rules for body-rule-graphs
and bodies and heads for body-head-graphs. Oppositely many graphs found in
the literature have a single kind of nodes such as the atoms or the rules of a
given program. The introduction of two diﬀerent kinds of nodes enables us to put
more information into a graph corresponding to a logic program. For the same
purpose a similar technique based on indexed copies of nodes of the classical DG
was proposed in [6].
Take a look at the RH-graph of the following two normal nested programs:
P2 =
⎧
⎨
⎩
x ←not a, not b, not x.
a ←not b.
b ←not a.
⎫
⎬
⎭
P3 =
⎧
⎨
⎩
x ←(not a, notx); (not b).
a ←not b.
b ←not a.
⎫
⎬
⎭
AS(P2) = {{a}, {b}}
AS(P3) = {{a, x}}.

Suitable Graphs for Answer Set Programming
159
Assume the rules of both programs are named r1, r2 and r3, respectively. Then
P2 and P3 have the same RH-graph shown in Figure 2. Since both programs
process diﬀerent answer sets the RH-graph should not be suitable for nNLP.
However, the clearly diﬀerent BH-graphs of P2 and P3 are shown in Figure 31.
a
r2
r3
b
r1
x
0|1
0|1
1|0
1|0
0|0
0|0
−
−
+
+
+
−
−
−
Fig. 2. RH-graph of programs P2 and P3
b
Ba
Ba,x
Bb
a
x
0
0
1
1
1
0
+
+
+
−
−
+
−
−
b
Ba
Bb
a
Ba,b,x
x
1|0
0|1
0|0
1|0
0|1
0|0
−
−
+
+
+
−
−
−
Fig. 3. BH-graphs of programs P2 (left) and P3 (right)
For completeness we also investigate three types of graphs where the nodes
are the bodies, rules and heads, respectively.
Deﬁnition 3. Let P be a logic program.
The B-graph (body-graph) BP = (Body(P), E+, ∅, E−) of P is a directed
graph with labeled arcs
E+ = {(B′, B) | r′ ∈P, B′ ∈Body(r′), Head(r′) ∩B+ ̸= ∅}
E−= {(B′, B) | r′ ∈P, B′ ∈Body(r′), Head(r′) ∩B−̸= ∅}.
The R-graph (rule-graph) RP = (P, E+, ∅, E−) of P is a directed graph with
labeled arcs
E+ = {(r′, r) | Head(r′) ∩B+ ̸= ∅, B ∈Body(r)}
E−= {(r′, r) | Head(r′) ∩B−̸= ∅, B ∈Body(r)}.
1 Observe that all graphs in the ﬁgures are depicted together with its a-colorings,
which are deﬁned in Section 3 and further investigated in Section 4.

160
T. Linke and V. Sarsakov
The H-graph (head-graph) HP = (Head(P), E+, ∅, E−) of P is a directed
graph with labeled arcs
E+ = {(h′, h) | r ∈P, h ∈Head(r), h′ ∈B+ for B ∈Body(r)}
E−= {(h′, h) | r ∈P, h ∈Head(r), h′ ∈B−for B ∈Body(r)}.
Observe, that for normal programs RP and HP coincide with the rule depen-
dency graph (RDG) and the classical dependency graph (DG), respectively. How-
ever, in this paper we use a diﬀerent arc labeling to obtain a uniform graph repre-
sentation framework. That is, 1-arcs and 0-arcs of RDGs are renamed to −-arcs
and +-arcs, respectively. Figure 4 shows the R-graph (RDG) of the following
two programs:
P4 =
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
r1 : a ←not b.
r2 : b ←not a.
r3 : c ←a.
r4 : d ←b.
r5 : x ←c, d.
r6 : x ←not x.
⎫
⎪
⎪
⎪
⎪
⎪
⎪
⎬
⎪
⎪
⎪
⎪
⎪
⎪
⎭
P5 =
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
r1 : a ←not b.
r2 : b ←not a.
r3 : c ←a.
r4 : c ←b.
r5 : x ←c.
r6 : x ←not x.
⎫
⎪
⎪
⎪
⎪
⎪
⎪
⎬
⎪
⎪
⎪
⎪
⎪
⎪
⎭
AS(P4) = ∅
AS(P5) = {{a, c, x}, {b, c, x}}.
r1
r2
r3
r4
r5
r6
0|1
0|1
1|1
1|0
1|0
0|0
−
−
−
+
+
+
+
Fig. 4. R-graph of programs P4 and P5
According to Deﬁnition 3, in the R-graph of both programs P4 and P5, rules r3
and r4 are both +-predecessors of r5. Hence R-graphs are not able to represent
the information indicating which of the positive body atoms is responsible for
which +-predecessor of node r5. Therefore, following our intuition, R-graphs
should not be suitable for normal programs, as both programs P4 and P5 have
the same R-graph but diﬀerent answer sets. On the other hand, the RH-graphs
of P4 and P5 are diﬀerent, because in the ﬁrst case (P4) r5 has ∗-predecessors
c and d, whereas in the second case (P5) r5 has the single ∗-predecessor c. The
same holds for the BH-graph of both programs. So far we have seen that the
graphs deﬁned in this section are able to represent diﬀerent information about
logic programs.
Finally, we deﬁne diﬀerent mappings associating the graphs from Deﬁni-
tions 2 and 3 to a given program.
Deﬁnition 4. For each Γ
∈{BH, RH, BR, R, B, H} deﬁne mapping Γ
:
nNLP →G+,∗,−as P →ΓP .

Suitable Graphs for Answer Set Programming
161
4
Graphs and A-Colorings
In this section, we deﬁne a special kind of labeled digraphs, without any reference
to logic programs. For those graphs we deﬁne non-standard 2-colorings (with two
colors), which reﬂect activation and deactivation of the nodes of a given graph.
Hence, these colorings are called a-colorings.
The intuition behind the following deﬁnition is to give a graph-based char-
acterization of the Cn-operator for all graphs presented in the last section.
Deﬁnition 5. Let G, Gv ∈G+,∗,−be labeled digraphs s.t. G = (V, E+, E∗, E−),
Gv = (V v, Ev
+, Ev
∗, ∅) and Gv is a subgraph of G s.t. v ∈V v.
Then Gv is a proof graph for v in G iﬀGv is acyclic and for each v′ ∈V v
the following two conditions hold:
1. {(v′′, v′) | v′′ ∈Pred∗
G(v′)} ⊆Ev
∗
2. if Pred+
G(v′) ̸= ∅then {(v′′, v′) | v′′ ∈Pred+
G(v′)} ∩Ev
+ ̸= ∅.
According to this deﬁnition a proof graph Gv for v in G is acyclic and does not
contain any −-arcs. That is, proof graphs do not consider negative body atoms
while ensuring recursive supportedness for single nodes (e.g. rules, atoms). In
this way, proof graphs form a graph-theoretical counterpart of Cn(P X) where
negative body atoms are not considered by taking the reduct P X instead of
the initial program P. Furthermore, for a node v′ in a proof graph Gv all ∗-
predecessors and all arcs from them to v′ in G are also arcs in Gv; and if there
exist +-predecessors of v′ in G then at least one of them together with its
+-arc to v′ is also in Gv. The intuition behind this deﬁnition is to separate
two diﬀerent (recursive) activation modes of nodes depending on its ∗- or +-
predecessors, respectively. The idea is that, a node can be activated if all of its
∗-predecessors are active and it can be activated if some of its +-predecessors are
active, provided that there are some +-predecessors. Observe, that for all graphs
deﬁned in Section 3, every node has either ∗-predecessors or +-predecessors (or
none of them), but not both. On the other hand, −-arcs represent negative
dependencies (blockage) between nodes and a node may have −-predecessors or
not, no matter which other predecessors it has.
For example, a body B in a BH-graph may be activated if all of its ∗-
predecessors (heads) are active, which means if all positive atoms in B are true
then B may also be true depending only on its negative atoms. On the other
hand a head h in a BH-graph is activated if one of its +-predecessors (bodies)
is active, which means h is true if there exists some applicable rule r s.t. B ∈
Body(r) and h ∈Head(r)2.
The concept of a proof graph is closely related to the one of a maximal sup-
port graph for R-graphs (RDGs) [12]. There are two diﬀerences. First, proof
graphs are more general since they are deﬁned for all graphs presented in Sec-
tion 3, whereas maximal support graphs are only deﬁned for rule graphs (RDGs).
Second, when restricting our attention to rule-graphs (RDGs) a maximal support
graph is the “union” of all proof graphs for all of its nodes (rules).
2 Heads do not have −-predecessors.

162
T. Linke and V. Sarsakov
A coloring of a graph G = (V, E+, E∗, E−) is a mapping C : V →{1, 0}. We
deﬁne C1 = {v | C(v) = 1} and C0 = {v | C(v) = 0}. If a node is colored with 1
this node is activated and if it is colored 0 it is deactivated. A total coloring C
is identiﬁed with (C1, C0) and the pair (G, C) is called a colored graph. Let CG
denote the set of all colorings of G.
Deﬁnition 6. Let C be a total coloring of G = (V, E+, E∗, E−) and let v ∈V
be a node.
Then v is blocked wrt (G, C) iﬀthere exists v′ ∈Pred−(v) s.t. v′ ∈C1.
Furthermore, v is grounded wrt (G, C) iﬀthere exists a proof graph Gv for
v in G s.t. V v \ {v} ⊆C1.
With these concepts at hand, we deﬁne a-colorings as follows:
Deﬁnition 7. Let G ∈G+,∗,−be a labeled digraph s.t. G = (V, E+, E∗, E−) and
let C be a total coloring of G. Then C is an a-coloring of G iﬀfor each v ∈V
we have
v ∈C1 iﬀv is grounded and not blocked wrt (G, C).
Let ACol(G) denote the set of all a-colorings of G. As examples, in Figures 2, 3
and 4 we also have depicted the a-colorings of all shown graphs. If there are two a-
colorings they are given right and left of |, respectively. Examples how to compute
a-colorings of R-graphs (RDGs) in terms of diﬀerent operators can be found
in [12]3. Furthermore, the noMoRe system can also be used for a step-by-step
visualization of the computation of a-colorings for BH-, RH- and R-graphs [5].
This nicely demonstrates the diﬀerent behavior of these graphs during answer
set computation.
5
Suitability
In this section, we further clarify our intuition of suitable graphs for answer
set programming (ASP). The idea is to relate a-colorings of graphs, which are
deﬁned independently of logic programs (see Section 3), to answer sets of the
corresponding programs. If it is possible to establish a tractable one to one
correspondence between the answer sets of the programs (of a given class) and the
a-colorings of the corresponding graphs then the class of those graphs is suitable
for the class of programs. Let G be a class of graphs and deﬁne CG = 	
G∈G CG,
the collection of all coloring of graphs in G.
Deﬁnition 8. Let P be a class of logic programs and let Γ : P →G+,∗,−be a
mapping.
Then Γ is suitable for P iﬀthere exists a partial, polynomial time mapping
ϕ : P × CG+,∗,−→2L s.t. for each P ∈P we have
1. if C ∈ACol(ΓP ) then ϕ(P, C) ∈AS(P)
3 In [12] a-colorings are called admissible colorings, since they are deﬁned by referring
to the generating rules of answer sets.

Suitable Graphs for Answer Set Programming
163
2. if X ∈AS(P) then there is a unique C ∈ACol(ΓP ) s.t. ϕ(P, C) = X.
This deﬁnition requires an one to one correspondence between a-colorings and
answer sets. Notice that it is important that mapping ϕ is computable in poly-
nomial time, because otherwise we would always get a trivial ϕ by directly
computing the answer sets of P without referring to the a-colorings of ΓP . By
forcing ϕ to be polynomial, the answer set has to be easily extractable from a
given a-coloring of a corresponding graph.
We have the following main results:
Theorem 1. Let BH, RH, BR, R, B and H the mappings from Deﬁnition 4.
Then we have the following results:
1. BH is suitable for nNLP.
2. RH is suitable for nLP.
3. BR, R and B are suitable for nLP1/nLP0.
4. RH is not suitable for nNLP.
5. BR, R and B are not suitable for nLP.
6. H is not suitable for nLP0.
In fact, examples P3, P4 and P1 serve as counterexamples to show the negative
results 4., 5. (only for R-graphs) and 6. in Theorem 1, respectively. On the other
hand, the a-colorings of the BH-graphs of P2 and P3 in Figure 3 correspond to
the respective answer set of both programs.
Next we investigate how exactly answer sets and a-colorings are related wrt
the diﬀerent graphs from Section 3. Let P be a program and let X ⊆Atm(P) be
a set of atoms. We deﬁne the set of generating bodies and the set of generating
rules of P wrt X as
GB(P, X)={B ∈Body(P) | B+ ⊆X and B−∩X =∅} and
GR(P, X) ={r ∈P | there is some B ∈Body(r) s.t. B ∈GB(P, X)},
respectively. Furthermore, for a subset S ⊆P ∪Body(P) ∪Head(P) we deﬁne
Hs(S) = S ∩Head(P), Bs(S) = S ∩Body(P) and Rs(S) = S ∩P.
Theorem 2. Let P be a logic program, let Γ ∈{BH, RH, BR, B, R, H}, let
ΓP = (V, E+, E∗, E−) be the Γ-graph of P and let C be a total coloring of ΓP .
Then we have the following equivalences:
1. If P ∈nNLP then C ∈ACol(BHP ) s.t. X = Hs(C1) iﬀ
X ∈AS(P) s.t. C1 = GB(P, X) ∪X.
2. If P ∈nLP then C ∈ACol(RHP ) s.t. X = Hs(C1) iﬀ
X ∈AS(P) s.t. C1 = GR(P, X) ∪X.
3. If P ∈nLP1 then C ∈ACol(BRP ) s.t. X = Head(Rs(C1)) iﬀ
X ∈AS(P) s.t. C1 = GB(P, X) ∪GR(P, X).
4. If P ∈nLP1 then C ∈ACol(RP ) s.t. X = Head(C1) iﬀ
X ∈AS(P) s.t. C1 = GR(P, X).
5. If P ∈nLP1 then C ∈ACol(BP ) s.t. X = Head({r ∈P | Body(r) ∩C1 ̸=∅})
iﬀX ∈AS(P) s.t. C1 = GB(P, X).

164
T. Linke and V. Sarsakov
This theorem demonstrates how an answer set can be eﬀectively extracted from
an a-coloring of a graph, provided that the graph is suitable for the underlying
program class.
6
Empirical Results
Our main goal on the empirical part of this work was to do some fair exper-
iments comparing diﬀerent graphs within an uniform implementation. Hence,
for experimental results, we have implemented computation of a-colorings for
BH-, RH- and R-graphs in noMoRe [1]4. This ensures, that all the results of our
experiments are fully comparable, since all parts of the implementation except
the underlying graph structure (which includes most of the source code as well
as used algorithms for graph coloring), are the same for all tests. In fact, our
new implementation generalizes the basic graph coloring procedure of noMoRe,
which is formally discussed in [13], to BH- and RH-graphs.
As benchmarks we present Hamiltonian cycle (HAM) problems for two rea-
sons. First, in [20] it is pointed out that HAM problems may be the “golden
standard” of ASP benchmarking, since the problem description is not tight.
That is, HAM problems cannot be solved by using a standard SAT solver on the
program completion of a given program (which is possible for most of the current
ASP problems). Second, our HAM encoding leads to programs in nLP1 and thus
provides us with a hard problem which can also be tested with R-graphs.
In Tables 1 and 2 we have summarized some results for HAM problems for
complete graphs (all answer sets) and so-called clumpy graphs (one answer set),
respectively. Table 1 gives the number of choices, nodes and edges as well as the
time needed for computing all a-colorings of BH-, RH- and R-graphs for the
HAM problem of complete graphs with n nodes. Table 2 gives the same results
for computing one a-coloring of those graphs for the HAM problem for clumpy
graphs with n clumps.
Observe that, although the HAM problem for complete graphs is trivial for
humans, it is diﬃcult for ASP solvers, especially if we want to compute multiple
answer sets, since it reﬂects the system behavior on backtracking. Clumpy graphs
were introduced in [20] as hard instances of HAM problems, since they are
directed graphs with less uniform distributed edges (so called “clumps”), such
that the existence of some (but few) Hamiltonian cycles is guaranteed (see [20]
for details). Our results show (i) that BH-graphs provide the most compact
graph representation for logic programs and (ii) that this compactness pays
oﬀin the size of the graph, in the number of choices and in the time needed.
Similar eﬀects can also be observed for other problem classes such as planning
and coloring problems. The new version of noMoRe including test cases is available
at http://www.cs.uni-potsdam.de/˜linke/nomore.
4 For results comparing a new C++ Version of noMoRe using BH-graphs with state-
of-the-art ASP systems like smodels and dlv see [19,4].

Suitable Graphs for Answer Set Programming
165
Table 1. Results for computing all answer sets of HAM problems on complete graphs
with n nodes
HAM n =
7
8
9
graph
BH
RH
R
BH
RH
R
BH
RH
R
choices
1853 2676 2676 14776 21259 21259
132343 190240 190240
nodes
108
150
93
139
195
122
174
246
155
edges
279
279
1548 366
366
2394
465
465
3504
time
3.12s 6.03s 7.46s 59.73s 117.6s 138.38s 325s
683s
916s
Table 2. Results for computing one answer set of HAM problems on clumpy graphs
with n clumps. For each n average values of ﬁve diﬀerent instances are given
clumps n =
4
5
6
graph
BH
RH
R
BH
RH
R
BH
RH
R
choices
35
41
60.8 73.6
86
180
8119
8567
21972
nodes
178.4 238
141
293.6 397
237
464.2 632
380
edges
423
423
1209 711
711
2300 1140
1140
3253
time
0.07s 0.12s 0.14s 0.31s 6.87s 0.96s 41.63s 67.74s 196.8s
7
Related Work and Discussion
Graphs associated with logic programs are used to detect structural properties
of programs, such as stratiﬁcation [2], existence of answer sets [10,6], or charac-
terization of answer set semantics and well-founded semantics [9,6,16,18]. The
usage of rule-oriented dependency graphs is common to [9,6,16,13]. In fact, the
coloration of such graphs for characterizing answer sets was independently de-
veloped in [6] and [16] and further investigated in [13]. However, as the two
normal logic programs P2 and P3 demonstrate, rule (dependency) graphs are
not suitable for computing answer sets of normal logic programs.
Therefore, the approaches in [9,6] rely on translations of normal programs
into negative ones before using their respective dependency graphs for character-
izing answer sets. In the noMoRe system [1] and its underlying theory [18,13,17]
some kind of additional (meta-)information not present in the rule graph
structure is necessary for deciding which positive body atoms of a rule like
a ←b1, . . . , bn are already suppported by other rules.
The main contribution of this work is the formal introduction of suitabil-
ity for existing and newly introduced graphs associated with logic programs, to
characterize situations where no additional information except the graph struc-
ture is needed. In fact, we have generalized a-colorings as given in [16,18] to all
graphs introduced in this paper. Especially body-head-graphs, which are shown
to be suitable for normal (nested) logic programs, handle multiple positive body
atoms in normal programs in an elegant and correct way and thus avoid the above
mentioned meta-information. Since none of the aforementioned graph-based ap-

166
T. Linke and V. Sarsakov
proaches deals with normal nested logic programs our work generalizes all those
approaches5. Furthermore, BH-graphs also handle disjunctions of conjunctions
of literals as bodies correctly. To the best of our knowledge, this is the ﬁrst time
that graphs corresponding to normal nested programs are introduced and used
for characterizing and computing answer sets. As a byproduct the application of
transformations utilized in [17] in order to replace all rules with same head and
all rules with same body by just one nested normal rule, respectively, comes for
free when using BH-graphs. That is, for all considered program classes body-
head-graphs give a much more compact representation than the other mentioned
graphs. This also turns out in the eﬃciency of their implementation compared
with the other graph representations (see Section 6) and the observation that
the ratio of the number of distinct bodies over the number of rules is alway
less than one. Hence BH-graphs should be the preferred graph representation
of logic programs.
Also [7] compares diﬀerent graph representations, but our approach is diﬀer-
ent in two important aspects. First, we deal with a syntactically richer class of
programs and second, our concept of suitability relies on graph colorings whereas
the one in [7] is deﬁned directly wrt answer sets and uses atom renaming.
Finally, one may ask whether we do not have investigated rule-body-head-
graphs in this context. The reason is that distinguishing rules and bodies does not
give much more information on the underlying logic program. This is reﬂected in
Theorem 1, where it is shown that BH-graphs are suﬃcient to deal with normal
nested programs; another argument is that BR-graphs are even not suitable for
normal logic programs and thus they are not able to represent more information
than R- or B-graphs on its own.
Acknowledgements
The authors were partially supported by the German Science Foundation (DFG)
under grant FOR 375/1 and SCHA 550/6, TP C and the Information Society
Technologies program of the European Commission, Future and Emerging Tech-
nologies under the IST-2001-37004 WASP project.
References
1. C. Anger, K. Konczak, and T. Linke. NoMoRe: A system for non-monotonic rea-
soning under answer set semantics. In W. Faber T. Eiter and M. Truszczy´nski,
editors, Proceedings of the 6th International Conference on Logic Programming and
Nonmonotonic Reasoning (LPNMR’01), pages 406–410. Springer, 2001.
2. K. Apt, H. Blair, and A. Walker. Towards a theory of declarative knowledge. In
J. Minker, editor, Foundations of Deductive Databases and Logic Programming,
chapter 2, pages 89–148. Morgan Kaufmann Publishers, 1987.
5 Observe, that normal nested logic programs are also utilized in [21] for translating
nested programs into extended ones.

Suitable Graphs for Answer Set Programming
167
3. K. R. Apt and R. N. Bol. Logic programming and negation: A survey. Journal of
Logic Programming, 19/20:9–71, 1994.
4. Asparagus. http://asparagus.cs.uni-potsdam.de.
5. A. B¨osel, T. Linke, and T. Schaub. Proﬁling answer set programming: The visu-
alization component of the noMoRe system. In J. J. Alferes and J. Leite, editors,
Logics in Artiﬁcial Intelligence (JELIA04), volume 3229 of Lecture Notes in Com-
puter Science, pages 702–705. Springer, 2004.
6. G. Brignoli, S. Costantini, O. D’Antona, and A. Provetti.
Characterizing and
computing stable models of logic programs: the non-stratiﬁed case. In C. Baral
and H. Mohanty, editors, Proc. of Conference on Information Technology, pages
197–201, Bhubaneswar, India, December 1999. AAAI Press.
7. S. Costantini. Comparing diﬀerent graph representations of logic programs under
the answer set semantics.
In T. C. Son and A. Provetti, editors, Proc. of the
AAAI Spring 2001 Symposium on: Answer Set Programming, Towards Eﬃcient
and Scalable Knowledge Representation and Reasoning, Stanford, CA, USA, 2001.
AAAI Press.
8. S. Costantini, O. D’Antona, and A. Provetti. On the equivalence and range of
applicability of graph-based representations of logic programs. Information Pro-
cessing Letters, 84(5):241–249, 2002.
9. Y. Dimopoulos and A. Torres. Graph theoretical structures in logic programs and
default theories. Theoretical Computer Science, 170:209–244, 1996.
10. F. Fages. Consistency of clark’s completion and the existence of stable models.
Journal of Methods of Logic in Computer Science, 1:51–60, 1994.
11. M. Gelfond and V. Lifschitz. The stable model semantics for logic programming.
In Proceedings of the International Conference on Logic Programming, pages 1070–
1080. The MIT Press, 1988.
12. K. Konczak, T. Linke, and T. Schaub. Graphs and colorings for answer set pro-
gramming: Abridged report. In V. Lifschitz and I. Niemel¨a, editors, Proceedings of
the Seventh International Conference on Logic Programming and Nonmonotonic
Reasoning (LPNMR’04), volume 2923 of Lecture Notes in Computer Science, pages
127 – 140. Springer-Verlag Heidelberg, 2003.
13. K. Konczak, T. Linke, and T. Schaub. Graphs and colorings for answer set pro-
gramming: Abridged report. In V. Lifschitz and I. Niemel¨a, editors, Proceedings of
the Seventh International Conference on Logic Programming and Nonmonotonic
Reasoning (LPNMR’04), volume 2923 of Lecture Notes in Artiﬁcial Intelligence,
pages 127–140. Springer Verlag, 2004.
14. V. Lifschitz. Answer set planning. In Proceedings of the 1999 International Con-
ference on Logic Programming, pages 23–37. MIT Press, 1999.
15. V. Lifschitz, L. Tang, and H. Turner. Nested expressions in logic programs. Annals
of Mathematics and Artiﬁcial Intelligence, 25(3-4):369–389, 1999.
16. T. Linke. Graph theoretical characterization and computation of answer sets. In
B. Nebel, editor, Proceedings of the International Joint Conference on Artiﬁcial
Intelligence, pages 641–645. Morgan Kaufmann Publishers, 2001.
17. T. Linke. Using nested logic programs for answer set programming. In M. De Voss
and A. Provetti, editors, Answer Set Programming: Advances in Theory and Im-
plementation (ASP03), volume 78, pages 181–194. CEUR Workshop Proceedings,
2003.
18. T. Linke, C. Anger, and K. Konczak. More on nomore. In S. Flesca, S. Greco,
N. Leone, and G. Ianni, editors, Proceedings of the Eighth European on Logics
in Artiﬁcial Intelligence (JELIA’02), volume 2424 of Lecture Notes in Artiﬁcial
Intelligence, pages 468–480. Springer Verlag, 2002.

168
T. Linke and V. Sarsakov
19. http://www.cs.uni-potsdam.de/nomore.
20. J. Ward and J. S. Schlipf. Answer set programming with clause learning. In V. Lif-
schitz and I. Niemel¨a, editors, Proceedings of the Seventh International Conference
on Logic Programming and Nonmonotonic Reasoning (LPNMR’04), volume 2923
of Lecture Notes in Computer Science, pages 302 – 313. Springer-Verlag Heidelberg,
2003.
21. J. You, L. Yuan, and M. Zhange. On the equivalence between answer sets and
models of completion for nested logic programs. In Proc. IJCAI03, page to appear,
2003.

Weighted Answer Sets and Applications in Intelligence
Analysis
Davy Van Nieuwenborgh⋆, Stijn Heymans, and Dirk Vermeir⋆⋆
Dept. of Computer Science
Vrije Universiteit Brussel, VUB
Pleinlaan 2, B1050 Brussels, Belgium
{dvnieuwe,sheymans,dvermeir}@vub.ac.be
Abstract. The extended answer set semantics for simple logic programs, i.e.
programs with only classical negation, allows for the defeat of rules to resolve
contradictions. In addition, a partial order relation on the program’s rules can be
used to deduce a preference relation on its extended answer sets. In this paper,
we propose a “quantitative” preference relation that associates a weight with each
rule in a program. Intuitively, these weights deﬁne the “cost” of defeating a rule.
An extended answer set is preferred if it minimizes the sum of the weights of
its defeated rules. We characterize the expressiveness of the resulting semantics
and show that it can capture negation as failure. Moreover the semantics can be
conveniently extended to sequences of weight preferences, without increasing the
expressiveness. We illustrate an application of the approach by showing how it can
elegantly express subgraph isomorphic approximation problems, a concept often
used in intelligence analysis to ﬁnd speciﬁc regions of interest in a large graph of
observed activities.
1
Introduction
Over the last decade a lot of research has been done on declarative programming using
the answer set semantics [10,2,16], a generalization of the stable model semantics [8].
In answer set programming, one uses a logic program to modularly describe the require-
ments that must be fulﬁlled by the solutions to a particular problem, i.e. the answer
sets of the program correspond to the intended solutions of the problem. One of the
possible problems in answer set programming is the absence of any solutions in case of
inconsistent programs. To remedy this, the authors proposed [14] the extended answer
set semantics which allows for the defeat of problematic rules. E.g., the rules a ←, b ←
and ¬a ←b are clearly inconsistent and have no classical answer sets, while both {a, b}
and {¬a, b} will be recognized as extended answer sets. Intuitively, ¬a ←b is defeated
by a ←in {a, b}, while ¬a ←b defeats a ←in {¬a, b}.
Within the context of inconsistent programs, it is natural to have some kind of
preference relation that is used to prefer certain extended answer sets above others.
⋆Supported by the FWO
⋆⋆This work was partially funded by the Information Society Technologies programme of the
European Commission, Future and Emerging Technologies under the IST-2001-37004 WASP
project
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 169–183, 2005.
c⃝Springer-Verlag Berlin Heidelberg 2005

170
D. Van Nieuwenborgh, S. Heymans, and D. Vermeir
In [14], a “qualitative” preference semantics is proposed, using a preference relation on
rules, to induce a partial ordering on the extended answer sets of a program.
As an alternative, this paper considers a “quantitative” preference relation for the
extended answer set semantics on simple programs, i.e. programs containing only classi-
cal negation. We assign each rule in a program a (nonnegative) weight, representing the
cost associated with defeating the rule. Solutions for these weighted programs, called
weighted answer sets, are those extended answer sets that minimize the sum of the
weights of defeated rules.
The resulting semantics turns out to be more expressive than classical answer set
programming, even in the absence of negation as failure. We demonstrate that e.g. the
membership problem is complete for the second level of the deterministic class of the
polynomial hierarchy, i.e. ∆P
2 -complete. Furthermore, we show how negation as failure
can be added to the formalism without increasing the complexity.
In some situations more than one actor is involved in the process of ﬁnding a solution
to a particular problem. Quite often we have a sequence of decision makers, where each
one sorts out the best solutions according to her preferences among the solutions that
are preferred by the previous one in the sequence. Intuitively, the solutions that are still
preferred by the last decision maker in the sequence are the ones that are acceptable by
all parties. E.g., in a job selection procedure, the secretary will only keep the applicants
that passed all the tests. Secondly, the head of the department will prefer people that
have better marks on their math tests, and among those, the management of the ﬁrm will
select those with a better psychological proﬁle.
Such hierarchies of individual weight preferences are supported by weight sequence
programs, where each rule in a program is equipped with a sequence ⟨wi⟩i=1,...,n of
weights corresponding to the cost each decision maker associates with defeating this
rule (wi has a higher priority than wi+1). Semantically, weighted answer sets for such
programs will be obtained from ﬁrst ﬁnding the weighted answer sets w.r.t. the weights
of the ﬁrst decision maker, i.e. the weights w1, and among those ﬁnding the ones that
are minimal w.r.t. the weights of the second decision maker, i.e. the weights w2, etc.
Regarding the complexity, it turns out that such sequences of weights do not result in
any additional expressiveness of the formalism, nevertheless allowing to express certain
problems more intuitively.
The proposed semantics has applications in several areas where quantitative prefer-
ences are useful. E.g., in the area of subgraph isomorphism algorithms [12] it is useful,
in case of absence of an exact match of the pattern graph in the larger graph, to search for
subgraph isomorphic approximations (SIA for short) of the larger graph that are minimal
in some sense, i.e. searching for a “minimal” set of items to add to the larger graph such
that the pattern occurs in it. We show how the solutions of such SIA problems corre-
spond with the weighted answer sets of a weighted program that can be constructed out
of the given instance graphs. Applications of SIA can be found in the area of intelligence
analysis [9,4], where it is common to search for a pattern of interest in a large attributed
relational graph [9] (ARG for short). An ARG is a normal graph where nodes and edges
can carry additional attributes e.g. denoting relationships. In intelligence analysis, ARGs
are used to model observed activity in the world under consideration. We show how the

Weighted Answer Sets and Applications in Intelligence Analysis
171
translation of the SIA problem for graphs into weighted programs can be intuitively
adapted to the setting of ARGs, thus providing a useful tool for intelligence analysis.
The remainder of this paper is organized as follows: Section 2 introduces weighted
programs and the corresponding weighted answer set semantics, together with a char-
acterization of the expressiveness. Additionally, we show how negation as failure can
be added without increasing the complexity. Section 3 formalizes weight sequence pro-
grams and we show that these systems do not have additional expressiveness in compar-
ison to normal weighted programs. In Section 4, we introduce the problem of subgraph
isomorphic approximations in graph theory and show how weighted programs can be
conveniently used to compute them. Section 5 discusses a generalization of subgraph iso-
morphic approximations in the area of attributed relational graphs. Finally, we conclude
in Section 6. Due to space restrictions, proofs have been omitted.1
2
Weighted Programs
We use the following basic deﬁnitions and notation. A literal is an atom a or a negated
atom ¬a. For a set of literals X, ¬X denotes {¬a | a ∈X} where ¬¬a = a. X is
consistent if X ∩¬X = ∅. An interpretation I is a consistent set of literals. A simple
rule r is of the form a ←β with {a} ∪β a ﬁnite set of literals2. The rule r is satisﬁed
by I, denoted I |= r, if a ∈I whenever β ⊆I, i.e. if r is applicable (β ⊆I), then it
must be applied (a ∈I).
A countable set of simple rules is called a simple logic program (SLP). The Herbrand
base BP of a SLP P contains all atoms appearing in P. For a SLP P and an interpretation
I we say that a rule a ←β ∈P is defeated w.r.t. I iff there exists an applied competing
rule ¬a ←β′ ∈P. Furthermore, we use PI ⊆P to denote the reduct of P w.r.t. I, i.e.
PI = {r ∈P | I |= r}, the set of rules satisﬁed by I.
An interpretation I is called a model of a SLP P if PI = P, i.e. I satisﬁes all rules
in P. If there is no model J of P such that J ⊂I, I is a minimal model or answer set
of P. An extended answer set for P is any interpretation I such that I is an answer set
of PI and each unsatisﬁed rule in P \PI is defeated.
Example 1. Consider the following SLP P about diabetes.
hypoglycemia ←
diabetes ←
sugar ←hypoglycemia
¬sugar ←diabetes
cola light ←¬sugar
cola ←sugar
Clearly, while this program has no traditional answer sets, it has, however, two ex-
tended answer sets I = {diabetes, hypoglycemia, sugar, cola} and J = {diabetes,
hypoglycemia, ¬sugar, cola light}.
The extended answer sets of a program are not always equally preferred. E.g., in
the above example, when low on sugar (hypoglycemia), one would prefer drinking
cola, rather than taking no sugar at all (¬sugar). So, defeating the rule sugar ←
hypoglycemia is “worse” than defeating the rule ¬sugar ←diabetes. Therefore, we
1 They are available in http://tinf2.vub.ac.be/˜dvnieuwe/graphasptech.ps
2 As usual, we assume that programs have already been grounded.

172
D. Van Nieuwenborgh, S. Heymans, and D. Vermeir
equip the rules in simple programs with a weight representing the “penalty” involved
when defeating the rule. Naturally, extended answer sets that minimize the total penalty
of a program are to be preferred over others.
Deﬁnition 1. A simple weight rule is a rule r of the form a ←β⟨w⟩, where {a} ∪β
is a ﬁnite set of literals and w is an associated weight value, i.e. a non-negative integer.
We use w(r) to denote the weight of r. A countable set of such simple weight rules is a
simple weight program (SWP). The extended answer sets of a SWP P coincide with the
extended answer sets of the SLP P ′ obtained from P by removing the weights from the
rules.
The program from Example 1 can be extended to a SWP containing a larger “penalty”
weight for the hypoglycemia rules, i.e. the program:
hypoglycemia ←⟨0⟩
diabetes ←⟨0⟩
sugar ←hypoglycemia⟨1⟩
¬sugar ←diabetes⟨0⟩cola light ←¬sugar⟨0⟩
cola ←sugar⟨0⟩
This program still has I and J as its extended answer sets, but intuitively I is better
than J as it satisﬁes the rule with weight 1 while J does not, which we formalize in the
following deﬁnition.
Deﬁnition 2. The penalty of an extended answer set S w.r.t. a SWP P, is deﬁned by
ΦP (S) = 
r∈P\PS w(r), i.e. the sum of the weights of all defeated rules in P w.r.t. S.
For two extended answer sets S1 and S2 of P, we deﬁne S1 ⪯S2 iff ΦP (S1) ≤
ΦP (S2). A weighted answer set of P is an extended answer set of P that is minimal
w.r.t. ≺(a ≺b iff a ⪯b and not b ⪯a) among the set of all extended answer sets of P.
A weighted answer set S of P with ΦP (S) = 0 is called a proper weighted answer set.
Intuitively, weighted answer sets are those solutions that minimize the penalties
incurred by defeating rules. For the weighted version of the program from Example 1
one obtains that ΦP (I) = 0 and ΦP (J) = 1 such that I ≺J, which corresponds with
our intuition.
While the previous example uses only two different weight values, the following
example shows that one can use the proposed semantics to represent complex relations
between defeated rules.
Example 2. Consider a company that wants to hire an employee. To get hired, you have
to do some tests and based on these results the company decides.
math ←⟨0⟩
lang ←⟨0⟩
psych ←⟨0⟩
prac ←⟨0⟩
phys ←⟨0⟩
¬math ←⟨0⟩
¬lang ←⟨0⟩
¬psych ←⟨0⟩
¬prac ←⟨0⟩
¬phys ←⟨0⟩
hire ←⟨3⟩
¬hire ←¬math⟨1⟩
¬hire ←¬lang⟨1⟩
¬hire ←¬psych⟨3⟩
¬hire ←¬prac⟨2⟩
¬hire ←¬phys⟨4⟩
Intuitively, the rules with weight 0, i.e. no penalty involved when defeated, represent
the choice between passing or not passing a certain test. Furthermore, the last ﬁve rules
encode which penalty is involved when a person fails a certain test, but still gets hired.
E.g., not passing the practical test is the same as failing both math and language. On

Weighted Answer Sets and Applications in Intelligence Analysis
173
the other hand, not passing the physical is considered unacceptable while failing the
psychological test will be tolerated only if it is the only failed test. Finally, the rule
hire ←⟨3⟩expresses the company’s policy: defeating this rule is cheaper from the
moment the penalty gets higher than 3.
Some of the program’s extended answer sets are M1 = {math, lang, psych, prac,
phys, hire}, M2 = {¬math, ¬lang, psych, prac, phys, hire}, M3 = {math, lang,
psych, ¬prac, phys, hire}, M4
= {¬math, lang, psych, ¬prac, phys, hire} and
M5 = {¬math, lang, psych, ¬prac, phys, ¬hire}.
Computing the penalties for these extended answer sets results in ΦP (M1) = 0,
ΦP (M2) = ΦP (M3) = 2 and ΦP (M4) = ΦP (M5) = 3. These values imply the
following order among the given extended answer sets: M1 ≺{M2, M3} ≺{M4, M5}.
It can be checked, that M1 is the only (proper) weighted answer set of P. While M2 has
a penalty of 2 by defeating two rules with weight 1, M3 only defeats a single rule, but
with weight 2, yielding that M2 and M3 are incomparable, and thus equally preferred.
Similarly, M4 and M5 only differ in the hire atom and are incomparable with each other,
both having a penalty of 3.
Combining simple programs with weights turns out to be rather expressive.
Theorem 1. Let P be a SWP and let l be a literal. Deciding whether there exists a
weighted answer set M of P containing l is ∆P
2 -complete.
The above result illustrates that the weighted answer set semantics is more powerful
than the classical answer set semantics for (non-disjunctive) programs containing also
negation as failure. Below, we provide a simple translation for such programs to SWPs.
In addition, we show that extending SWPs with negation as failure does not increase
their expressiveness.
In this context, an extended literal is a literal or a naf-literal of the form not l where
l is a literal. The latter form denotes negation as failure. For a set of extended literals
X, we use X−to denote the set of ordinary literals underlying the naf-literals in X, i.e.
X−= {l | not l ∈X}. For a set of ordinary literals Y , we use not Y to denote the set
not Y = {not y | y ∈Y }. An extended literal l is true w.r.t. an interpretation I, denoted
I |= l, if l ∈I in case l is ordinary, or a ̸∈I if l = not a for some ordinary literal a. As
usual, I |= X for some set of (extended) literals l iff ∀l ∈X · I |= l.
An extended rule is a rule of the form a ←β where a is a literal and β is a ﬁnite set
of extended literals. An extended rule r = a ←β is satisﬁed by I, denoted I |= r, if
a ∈I whenever I |= β, i.e. if r is applicable (I |= β), then it must be applied (a ∈I).
A countable set of extended rules is called an extended logic program (ELP). When an
ELP P does not contain classical negation, we call P a seminegative logic program. We
adopt from SLP the notion of the reduct PI w.r.t. an interpretation I and the notion of
defeating of rules.
For an extended logic program P and an interpretation I we deﬁne the GL-reduct[8]
for P w.r.t. I, denoted P I, as the program consisting of those rules a ←(β\not β−)
where a ←β is in P and I |= not β−. Now, all rules in P I are free from negation
as failure, i.e. P I is a simple program. An interpretation I is then an answer set of P
iff I is an answer set of the GL-reduct P I. Again, an extended answer set for P is any
interpretation I that is an answer set of PI and that defeats each rule in P \PI.

174
D. Van Nieuwenborgh, S. Heymans, and D. Vermeir
Theorem 2. Let P be a seminegative program. The weighted version of P is deﬁned by
N(P) = P ′ ∪Pn, where P ′ = {a ←β′⟨1⟩| a ←β ∈P} with β′ obtained from β by
replacing each naf-literal not p with ¬p, and Pn = {¬a ←⟨0⟩| a ∈BP }. Then, M is
an answer set of P iff M ∪¬(BP \M) is a proper weighted answer set of N(P).
Intuitively, the rules in Pn introduce negation as failure using classical negation by
allowing their defeat “for free”, while defeating rules in P ′, corresponding to the original
rules in P, is penalized.
Example 3. Consider the seminegative program P = {a ←not b, b ←not a}. The
weighted version N(P) consists of the rules {¬a ←⟨0⟩, ¬b ←⟨0⟩, a ←¬b⟨1⟩, b ←
¬a⟨1⟩}. This program has two proper weighted answer sets, i.e. I = {a, ¬b} and
J = {¬a, b}, corresponding with the answer sets {a} and {b} of P.
Simple weighted programs can be extended with negation as failure, i.e. extended
weighted programs (EWP), without increasing the expressiveness of the formalism. The
latter is conﬁrmed by the next theorem which reduces an EWP to an equivalent SWP. For
this reduction, we deﬁne a mapping ψ translating original naf-literals by: ψ(not a) = an
and ψ(not ¬a) = a¬
n, where for each atom a ∈BP , an and a¬
n are fresh atoms. We use
ψ(X), X a set of naf-literals, to denote {ψ(x) | x ∈X}.
Theorem 3. Let P be a ﬁnite EWP. The SWP version of P, denoted S(P), is deﬁned
by S(P) = Pn ∪P ′ ∪Pc, where Pn = {ψ(not l) ←⟨0⟩| l ∈BP ∪¬BP }, P ′ =
{a ←β′⟨w⟩| a ←β⟨w⟩∈P} where β′ is obtained from β by replacing not β−
with ψ(not β−), and Pc = {¬ψ(not l) ←l⟨Υ⟩| l ∈BP ∪¬BP } where Υ = 1 +

r∈P w(r).
Then, M is a weighted answer set of P iff there exists a weighted answer M ′ of
S(P) such that (a) ΦS(P )(M ′) < Υ; and (b) M = M ′ ∩(BP ∪¬BP ).
Intuitively, the rules in Pn introduce negation as failure for all literals in the Herbrand
base. As defeating negation as failure should be free, the rules all get a weight of 0. In
P ′ we adapt the original program with the corresponding weights by replacing the
naf-literals by their new representation. The rules in Pc ensure the consistency of any
solution by allowing the new representations of naf-literals to be defeated. To enforce
the satisfaction of these rules, we give them a weight that is higher than any possible
combination of weights in the original program, i.e. the sum of all weights plus 1. As
a result, S(P) will only yield weighted answer sets with high penalties, i.e. defeating
some of the rules in Pc, iff the original program itself has no solutions, making condition
(a) in Theorem 3 necessary.
E.g., the single rule program Q = {a ←not a⟨0⟩} has no weighted answer sets. Its
translation S(Q) = {an ←⟨0⟩, a¬
n ←⟨0⟩, ¬an ←a⟨1⟩, ¬a¬
n ←¬a⟨1⟩, a ←an⟨0⟩}
has only one weighted answer set I = {an, a¬
n, a} for which the penalty is ΦQ(I) =
1, yielding a value not strictly smaller than 1, corresponding to the non-existence of
weighted answer sets for the original program.
Combining Theorem 3 with Theorem 1 yields that EWPs have the same complexity
as SWPs, i.e. ∆P
2 -complete.

Weighted Answer Sets and Applications in Intelligence Analysis
175
3
Weight Sequences
In [13] an intuitive semantics is presented for sequences of individual complex qualitative
preferences. The idea is to apply each individual preference in the sequence in turn
and to let it sort out the preferred answer sets left over by the previous preferences
in the sequence. It is shown in [13] that this semantics is quite expressive as it can
handle arbitrary complete problems of the polynomial hierarchy. More speciﬁcally, for
a sequence of n preference relations, the semantics is ΣP
n+1-complete.
It is natural to wonder if a similar semantics for sequences of individual weights will
also yield a complexity blow-up depending on the length of the sequence. It turns out
that this is not the case as sequences of weights remain ∆P
2 -complete.
Deﬁnition 3. An n-weight sequence rule is a rule r of the form a ←β⟨wi⟩i=1,...,n,
where {a} ∪β is a ﬁnite set of literals and ⟨wi⟩i=1,...,n is a sequence of n associated
weight values, i.e. a sequence of non-negative integers. We use wi(r) to denote the weight
wi of r. A countable set of n-weight sequence rules is an n-weight sequence program
(nWSP). The extended answer sets of an nWSP P coincide with the extended answer
sets of the SLP P ′ obtained from P by removing the weight sequences from the rules.
The penalty of an extended answer set S w.r.t. the weights i (1 ≤i ≤n) and an
nWSP P, is deﬁned by Φi
P (S) = 
r∈P\PS wi(r), i.e. the sum of the weights wi of all
defeated rules in P w.r.t. S. Each of the penalties Φi
P induces a preference relation ≺i
between the extended answer sets, as in Deﬁnition 2.
We deﬁne the preference of extended answer sets up to a certain weight level by
induction.
Deﬁnition 4. Let P be a nWSP. An extended answer set S is preferable up to weight
level ≺i, 1 ≤i ≤n, iff
– i = 1 and S is minimal w.r.t. ≺1, or
– i > 1, S is preferable up to ≺i−1, and there is no T, preferable up to ≺i−1, such
that T ≺i S.
An extended answer set S of P is a weighted answer set iff it is preferable up to ≺n.
Example 4. Consider the problem of two people having to decide what to eat for dinner.
After checking the available ingredients, the cook preparing the dinner decides to let his
wife propose some possible combinations from which he will choose the ﬁnal one. As his
wife is rather hungry, she decides to choose the meal which is quickest to make, the reason
for which she assigns weights corresponding with times needed to make a particular part
of the meal. On the other hand, her husband is tired and wants to make a meal that is
easy to prepare, yielding weights representing the difﬁculty to make a particular part of
the meal. Further, they agree on some constraints that each meal should satisfy, e.g. with
french fries they take mayonnaise, etc. The 2WSP corresponding with this problem is
shown below.
Note that the rule ¬v ←v⟨200, 200⟩enforces the satisfaction of the common con-
straints, as it implies that every solution not making one of the rules with v in the head
applicable, is better than any solution making one of those rules applicable.

176
D. Van Nieuwenborgh, S. Heymans, and D. Vermeir
french fries ←⟨0, 0⟩
rice ←⟨0, 0⟩
steak ←⟨0, 0⟩
¬french fries ←⟨15, 1⟩
¬rice ←⟨5, 1⟩
¬steak ←⟨10, 1⟩
stew ←⟨0, 0⟩
meat ball ←⟨0, 0⟩
mayonnaise ←⟨0, 0⟩
¬stew ←⟨75, 3⟩
¬meat ball ←⟨20, 2⟩
¬mayonnaise ←⟨10, 5⟩
tomato sauce ←⟨0, 0⟩
¬tomato sauce ←⟨10, 2⟩
v ←¬french fries, ¬rice⟨0, 0⟩
v ←¬steak, ¬meat ball, ¬stew⟨0, 0⟩
v ←steak, ¬french fries⟨0, 0⟩
v ←rice, meat ball, ¬tomato sauce⟨0, 0⟩
v ←french fries, ¬mayonnaise⟨0, 0⟩
¬v ←v⟨200, 200⟩
For the extended answer sets3 S1 = {french fries, steak, mayonnaise} and S2 =
{rice, meat ball, tomato sauce} one can check that Φ1
P (S1) = Φ1
P (S2) = 35 and no
other extended answer sets exists with a smaller penalty for Φ1
P , yielding that both S1 and
S2 arepreferableuptoweight level ≺1. Ontheother hand, Φ2
P (S1) = 7andΦ2
P (S2) = 5,
making S2 preferable up to weight level ≺2, yielding that S2 is the weighted answer set
for this problem.
Finally, rearranging the weight sequence yields, in general, different solutions. E.g.,
if the cook ﬁrst decides which meals he wants to make and afterwards his wife can
choose a particular one, it can be checked that S3 = {rice, stew} will be the weighted
answer set of the problem.
In the following theorem we show that an n-weight sequence program can be trans-
formed into a simple weight program such that the weighted answer sets of the former
coincide with the weighted answer sets of the latter.
Theorem 4. Let P be an nWSP and let P ′ be the SWP deﬁned by
P ′ = {a ←β⟨wi × 10ξi⟩| a ←β⟨wi⟩i=1,...,n} ,
where ξn = 0 and ξi = 
j∈[i+1...n]

length

r∈P wj(r)

otherwise, with length(x)
the number of digits in x, e.g. length(2611) = 4.
Then, S is a weighted answer set of P iff S is a weighted answer set of P ′.
Reconsider the rule ¬stew ←⟨75, 3⟩from Example 4. In the SWP version of
this program, the rule would yield the rules ¬stew ←⟨3⟩and ¬stew ←⟨75000⟩, as

r∈P w2(r) = 215, yielding that length(215) = 3 and 75 × 103 = 75000.
The above transformation can be performed in polynomial time, yielding the fol-
lowing complexity result for n-weighted sequence programs.
Corollary 1. Let P be an nWSP. Deciding whether there exists a weighted answer set
S of P containing l is ∆P
2 -complete.
This result implies that, unlike for sequences of qualitative preferences [13], introducing
sequences of weights does not yield an increase of expressiveness. Nevertheless, these
sequences allow for a more intuitive expression of certain problems.
3 To keep the size of the extended answer sets small, we only provide the positive literals.

Weighted Answer Sets and Applications in Intelligence Analysis
177
4
Approximate Subgraph Isomorphisms
While approximate subgraph isomorphisms are similar to ﬁnding largest common sub-
trees [1], the formalisation we introduce in this section is, to the best of our knowledge,
new.
A graph is a tuple G = ⟨N, E⟩, where N is a ﬁnite set of nodes, and E ⊆N ×N is a
set of tuples representing the edges in the graph. We assume that graphs are directed; an
undirected edge from n to m can still be represented by having both ⟨m, n⟩and ⟨n, m⟩
in E.
Two graphs G1 = ⟨N1, E1⟩and G2 = ⟨N2, E2⟩are said to be isomorphic, denoted
G1 ∼= G2, if there exists a bijection f : N1 →N2 such that f(E1) = E2, where f(E1)
denotes {⟨f(t), f(h)⟩| ⟨t, h⟩∈E}. On the other hand, G2 is called a subgraph of G1,
denoted G2 ⪯G1, iff N2 ⊆N1 and E2 ⊆E1. Furthermore, G2 is called subgraph
isomorphic to G1, denoted G2 ≾G1, if there exists a subgraph G3 ⪯G1 such that
G2 ∼= G3.
Subgraph isomorphism itself is sometimes too strong a notion for certain appli-
cations. E.g., when a graph G2 = ⟨N2, E2⟩is not subgraph isomorphic to a graph
G1 = ⟨N1, E1⟩, it may be interesting to know what is “missing” in G1 for G2 to be
subgraph isomorphic to it. In this context, a graph G3 = ⟨N3, E3⟩is called an ex-
tension of G1 w.r.t. G2 just when G1 ⪯G3 and N3 = N1 when |N1| ≥|N2| or
N3 = N1 ∪{xi | 1 ≤i ≤|N2| −|N1|} otherwise, where the xi are new nodes not
occurring in N1. The latter construction of N3 is necessary to handle the cases in which
the graph to search for is bigger than the graph to search in. A graph G3 is a subgraph
isomorphic approximation of G1 w.r.t. G2 iff G3 is an extension of G1 w.r.t. G2 and
G2 ≾G3. We use G2 ≾G1 G3 to denote that G2 is approximately subgraph isomorphic
to G3 w.r.t. G1, i.e. G3 is a subgraph isomorphic approximation of G1 w.r.t. G2. The set
of all subgraph isomorphic approximations of G1 w.r.t. G2 is denoted by AG1(G2).
Obviously, not every subgraph isomorphic approximation G3 ∈AG1(G2) is equally
interesting. E.g., the fully connected graph ⟨N3, N3 ×N3⟩is, clearly, always a subgraph
isomorphic approximation and thus in AG1(G2). However, in most cases there will
exist smaller extensions of G1 in AG1(G2). Therefore, we are particularly interested in
elements from AG1(G2) that have a minimal, in some sense, difference with the original
graph G1. Here we use ∆G1(G3) to denote the unidirectional edge difference between
G1 and G3, i.e. ∆G1(G3) = E3\E1.
Two minimality criteria, which are widely used in areas like diagnostic reasoning
[5,6,15], are cardinal minimality and subset minimality. In the former case, we select
those elements from AG1(G2) that are minimal w.r.t. cardinality among the elements
in AG1(G2). Formally, a graph G3 ∈AG1(G2) is said to be a subgraph isomorphic
c-approximation iff there does not exist a graph G4 ∈AG1(G2) such that |∆G1(G4)| <
|∆G1(G3)|. The set of all c-approximations is denoted by Ac
G1(G2).
Example 5. Consider the three undirected graphs G1, G2 and G3 represented in Figure 1.
Clearly, G1 is subgraph isomorphic to G2, i.e. G1 ≾G2, but not to G3. However,
adding a single (bidirectional) edge between e.g. m and r in G3, i.e. G4 = ⟨N3, E3 ∪
{⟨m, r⟩, ⟨r, m⟩}⟩, results in a subgraph isomorphic approximation of G3 w.r.t. G1, i.e.
G1 ≾G3 G4. Obviously, G4 is cardinal minimal yielding that G4 ∈Ac
G3(G1).

178
D. Van Nieuwenborgh, S. Heymans, and D. Vermeir
a
b
c
d
m
n
o
p
q
r
s
t
u
v
w
l
h
j
G1
G2
G3
e
i
g
k
f
Fig. 1. The graphs G1, G2 and G3 of Example 5
Subsetminimalisomorphicapproximationscanbedeﬁnedinasimilarway.However,
in contrast with diagnostic reasoning, subset minimality is less intuitive in this setting.
E.g. adding the edges ⟨p, o⟩, ⟨o, w⟩, ⟨w, v⟩and ⟨v, p⟩(and their reverses) to G3 in
Example 5 yields a subset minimal isomorphic approximation w.r.t. G1. However, if
we see G3 as an activity graph and G1 as a pattern of interest, as is often done by
intelligence agencies for detecting possible threats [4], the previously mentioned subset
minimal approximation is not very useful as it forces the agency to check 4 possible
relations between currently unrelated things. On the other hand, the approximations in
Ac
G3(G1) are of much more value as they all yield one missing link to complete the
pattern, implying that the agency can quickly conﬁrm these solutions (see also the next
section).
Obviously, when a graph is subgraph isomorphic to another one, the latter is the only
c-approximation of itself.
Theorem 5. Let G1 and G2 be graphs such that G2 ≾G1. Then, Ac
G1(G2) = {G1}.
Using the weighted answer set semantics, we have the means to effectively compute
the c-approximations of a given graph G1 w.r.t. a graph G2. In what follows, we will
sometimes use non-grounded rules for clarity, but grounding is performed as usual.
Intuitively,weintroducetheedgesofG1 asfactsoftheformedge(x, y) ←⟨0⟩,where
⟨x, y⟩∈E1. For each possible edge ⟨x, y⟩̸∈E1, with x, y ∈N1, we give a choice to
either include it or not in an approximation by introducing the facts edge(x, y) ←⟨0⟩
and ¬edge(x, y) ←⟨1⟩. The penalty involved in the latter fact is to ensure that the
computed approximations are cardinal minimal, i.e. not inserting an edge (defeating the
former rule) can be done freely, but inserting an edge (defeating the latter rule) has to
be minimized. In case |N1| < |N2| we also add edges to the |N2| −|N1| new nodes.
To match G2 with the possible approximations, we need to introduce for each node
n ∈N2 a unique new variable name N. Searching for a match of G2 in the approximation
is done by the single rule match ←β⟨0⟩, where β = {edge(X, Y ) | ⟨x, y⟩∈E2} ∪
{X ̸= Y | ⟨x, y⟩∈E2∧x ̸= y}. Finally, we add the single rule match ←not match⟨0⟩
which forces any solution to contain a match (note that this rule cannot be defeated).
Deﬁnition 5. Let G1 = ⟨N1, E1⟩and G2 = ⟨N2, E2⟩be graphs. The program com-
puting the c-approximations of G1 w.r.t. G2, denoted LG1(G2), is deﬁned by the rules:
– {edge(x, y) ←⟨0⟩| ⟨x, y⟩∈E1} ;
– {edge(x, y) ←⟨0⟩; ¬edge(x, y) ←⟨1⟩| x, y ∈N1 ∪{xi | (|N1| < |N2|) ∧(1 ≤
i ≤|N2| −|N1|)} ∧⟨x, y⟩̸∈E1} ;

Weighted Answer Sets and Applications in Intelligence Analysis
179
– {match ←β⟨0⟩}, where β = {edge(X, Y ) | ⟨x, y⟩∈E2} ∪{X ̸= Y | ⟨x, y⟩∈
E2 ∧x ̸= y} ; and
– {match ←not match⟨0⟩} .
If we reconsider the graphs G1 and G3 from Example 5, the program LG3(G1)
contains, besides the numerous edge/2 facts, the rule
match ←edge(A,B), edge(B,D), edge(D,C), edge(C, A), edge(B, A), edge(D, B)
edge(C, D), edge(A, C), A ̸= B, B ̸= D, D ̸= C, C ̸= A .
One of the possible weighted answer sets of LG3(G1) is e.g. S = {edge(x, y) |
⟨x, y⟩∈E3} ∪{edge(m, r), edge(r, m)} ∪({¬edge(x, y) | x, y ∈N3 ∧⟨x, y⟩̸∈
E3}\{edge(m, r), edge(r, m)}). Clearly, S corresponds with the extension G4 from
Example 5, which is a cardinal minimal approximation of G3 w.r.t. G1. This behavior
is conﬁrmed by the following theorem.
Theorem 6. Let G1 = ⟨N1, E1⟩and G2 = ⟨N2, E2⟩be graphs. Then, G3 = ⟨N3, E3⟩
∈Ac
G1(G2) iff M = {edge(x, y) | ⟨x, y⟩∈E3}∪{¬edge(x, y) | x, y ∈N3 ∧⟨x, y⟩̸∈
E3} ∪{match} is a weighted answer set of LG1(G2).
In the current approach no distinction is made between the edges that can be added to
a graph to obtain an approximation. However, one can imagine situations in which adding
one edge is more “difﬁcult” than adding another, i.e. the cost of adding an edge may
vary. E.g., for an intelligence agency, it may be easier to check a relationship between
people in the home country, than between people in foreign countries, but checking 4
internal relationships may be as hard as checking 1 external relationship, resulting in a
cost of 4 for edges between externals and a cost of 1 for edges between internals. Such
costs represent a quantitative preference relation between edge additions.
In this case, optimal solutions are approximations that minimize the sum of all costs
associated with the added edges in the approximation. It is not difﬁcult to see that this
kind of minimization can easily be computed by an adapted version of the program in
Deﬁnition 5: just replace the weights 1 with the cost associated for adding the edge to
an approximation. Clearly, Theorem 6 remains valid in this extension.
Similarly, we could think of an agency where possible threats are ﬁrst selected,
by some ﬁeld agent, depending on the effort needed to check certain relationships.
Afterwards, the supervisor will apply, on the proposed investigations of his ﬁeld agent,
another kind of quantitative preferences, e.g. using information from other departments.
In case there are still a number of possible solutions left over after the supervisor, even
a third individual, e.g. the director, could apply his preferences on these possibilities.
Again, it is not difﬁcult to see that this problem can be elegantly modeled by an adapted
version of the program in Deﬁnition 5, this time using the n-weight sequence programs
introduced in Section 3. Also in this extension, an adapted version of Theorem 6 remains
valid.
5
An Application in Intelligence Analysis
Attributed relational graphs (ARGs), an extension of the abstract directed graphs deﬁned
in the previous section, are often used in e.g. intelligence analysis to understand complex,

180
D. Van Nieuwenborgh, S. Heymans, and D. Vermeir
and often uncertain, situations. The nodes in such ARGs are used to describe objects in
the observed world, e.g. persons, organizations, ..., while the edges are used to represent
relationships between the nodes, e.g. interaction, ownership, trust, ... .
In addition, ARG nodes and edges may have additional attributes that describe the
details of the speciﬁc objects or relationships: e.g. the name of a person, the kind of
chemical, the type of conversation. An example of such an ARG, based on an example
Person
observe
observe
Factory
reside
reside
Person
rent
buy
Truck
House
Chemicals
Fig. 2.
The
pattern
graph [4]
House,21 West St
Car, Honda
House, 34 East St
Person, Tom
Person, Richard
Person, Harry
Factory,Acme Inc.
House, 123 Main St
Person, Ted
Person, Bill
Chemicals,Gasoline
Chemicals,HCl
Person, Ben
Car, Bentley
Person, Jennifer
Conversation,Phone call
Conversation, Phone call
Conversation, Letter
Person, Alice
buy
buy
reside
reside
rent
observe
reside
reside
work
observe
work
friends
drives
drives
drives
married
Truck, Liquids
Fig. 3. The observed activity graph [4]
from [4], can be found in Figure 3. Here, a person named Bill has rented a truck for
carrying liquids and that same person resides in a house at 123 Main street together with
a person called Ted. Furthermore, Ted has been observing a factory called Acme Inc.
and he also bought large quantities of the chemical HCl.
Intelligence analysts normally deﬁne small abstract patterns which are believed to be
indications of possible threats. An example of such a pattern, based on the same example
from [4], can be found in Figure 2. Intuitively, it states that two persons residing at the
same place and both observing the same factory can be dangerous if one person buys
some chemical, while the other rents a truck.
Having both an ARG of observed activity and a pattern, the analysts need tools for
ﬁnding speciﬁc regions in the ARG that “closely” match the deﬁned threat pattern. Sub-
graph isomorphic approximations turn out to be valuable tools to accomplish this task
[4]. The framework and results we developed in Section 4 can be intuitively adapted to
the setting of ARGs, where the transformation into a weighted program allows an analyst
to compute subgraph isomorphic approximations that are minimal in some quantitative
sense. In situations where investigating missing additional relationships is equally hard,
the analyst can use the cardinal minimal approximations. On the other hand, if inves-
tigating some relationship has a higher cost than investigating others, an analyst could
rely upon the extension of the framework of Section 4, i.e. deﬁning a cost with each
relationship (edge) that can be added to have a subgraph isomorphic approximation and
only keeping the approximations that minimize the sum of the costs. Similarly, it could
be the case that the analist is not the only one in charge of making the ﬁnal decision or
that he has multiple equivalent possibilities. In such situations, it can be useful to apply
the quantitative preferences of some other people, e.g. a supervisor or the director, to

Weighted Answer Sets and Applications in Intelligence Analysis
181
reﬁne the number of solutions, so obtaining the most preferred solution. By using the
second extension of the framework of Section 4, also this kind of reasoning with ARGs
can be solved, i.e. by using weight sequence programs.
Instead of formally adapting the framework and the results, we illustrate the adapta-
tion, and its usefulness, using the example on intelligence analysis: we will translate the
ARG and pattern of Figures 3 and 2 into a weighted program and show that the solutions
of the program correspond with the regions of threat in the ARG w.r.t. the given pattern.
First we translate, for convenience, the nodes of the ARG to node-predicates. E.g. a
person named Bill forces the fact node(person, bill) ←⟨0⟩into the program, while the
factory Acme Inc. is responsible for the fact node(factory, acme inc) ←⟨0⟩. In total,
we have 17 of such facts in our weighted program.
Next, we have to describe the relationships between the nodes using extended ver-
sions of the edge/2-predicates used in the previous section. E.g. Ted residing at the house
in 123 Main street gives rise to the fact
edge(person, ted, reside, house, 123 main street) ←⟨0⟩,
while the conversation between Jennifer and Bill can be described by the fact
edge(person, bill, conversation, phone, person, jennifer) ←⟨0⟩.
Note that the different edge-facts can have different arities, which is not a problem as long
as the arities, and the ordering of the arguments, are the same for the same relationship.
E.g. edge-facts representing the conversation relationship always have six arguments:
the ﬁrst two correspond to a node, the third has to be “conversation”, the fourth the type
of conversation and the last two again correspond to a node.
Also note that ARGs are directed graphs, but certain relations are bidirectional, e.g.
friends and married. For these relationships we have to explicitly add both directions
using the edge-facts: e.g. both edge(person, richard, friend, person, tom) ←⟨0⟩and
edge(person, tom, friend, person, richard) ←⟨0⟩have to be present in the weighted
program. One could argue that a conversation through phone is also bidirectional, but
we use a directed edge here to represent who initiated the call.
The pattern in Figure 2 can be translated into the following rule, where names starting
with an uppercase letter correspond to a variable:
match ←edge(person, NamePerson1, observe, factory, NameFactory),
edge(person, NamePerson2, observe, factory, NameFactory),
edge(person, NamePerson1, reside, house, AddressHouse),
edge(person, NamePerson2, reside, house, AddressHouse),
edge(person, NamePerson1, rent, truck, KindOfTruck),
edge(person, NamePerson2, buy, chemicals, KindOfChemical)⟨0⟩
The above pattern matching rule also matches situations where only one person
observes a factory and does both the renting of the truck and the buying of the chemicals.
If one wants to have explicitly two different persons, we need to add the condition
NamePerson1 ̸= NamePerson2 to the rule.
Finally, we have to add rules for the edges that can eventually be added to our ac-
tivity graph to obtain a subgraph isomorphic approximation. These edges will directly

182
D. Van Nieuwenborgh, S. Heymans, and D. Vermeir
point out the region of interest in the activity graph as the minimization assures that
only edges are added where necessary, i.e. on those places in the activity graph where
the pattern (almost) matches. While we introduced all possible edges in the simula-
tion of Section 4, doing the same in the context of ARGs may not be the best way to
go. Indeed, ARGs can have multiple edges between the same nodes but with different
attributes, which are not always useful to deﬁne between certain types of nodes. E.g.
edge(chemical, hcl, buys, chemical, gasoline) ←⟨0⟩is theoretically possible, but use-
less in real life. Therefore, one should avoid the introduction of meaningless edges in
the program, possibly by adding extra semantical constraints, e.g. typing the attributes
in ARGS. Some examples of choices of edges to add are:
edge(person, bill, observe, factory, acme inc) ←⟨0⟩
¬ edge(person, bill, observe, factory, acme inc) ←⟨v⟩
edge(person, bill, buy, chemical, hcl) ←⟨0⟩
¬ edge(person, bill, buy, chemical, hcl) ←⟨w⟩
edge(person, alice, conversation, phone, person, ted) ←⟨0⟩
¬ edge(person, alice, conversation, phone, person, ted) ←⟨z⟩
In the above rules for possible edges to add, the rules with a positive occurrences of
the edge-predicate always have a weight of 0, as not adding an edge, i.e. defeating the
rule, can be done for free. On the other hand, the negative occurrences have a weight
corresponding to the cost associated with adding the edge. In case we use cardinal
minimality, the costs (e.g. v, w and z) will all be 1, while in case of total cost minimality
we could deﬁne v = 4, w = 2 and z = 1 yielding that it is twice as hard to check if
someone observed a factory than checking if he bought some chemical, which in turn is
twice as hard than checking if he made a phone call.
For simplicity, we only consider cardinal minimality (and no sequences) in what
follows, i.e. we take all the weights of the rules with negative occurrence of an edge-
predicate to be 1. If we consider the weighted program obtained in the way we described
above, we will have two weighted answer sets S and T. Both will contain all the edges
from the original activity graph together with the fact match. Additionally, S will con-
tain the fact edge(person, bill, observe, factory, acme inc) together with all negated
versions of the other edge-predicates we added to the program Similarly, T will con-
tain the fact edge(person, ted, rent, truck, liquids) together with all negated versions,
except the one occurring positively. Clearly, both S and T correspond with the only
cardinal minimal subgraph isomorphic approximations of the problem.
As said before, we can add the condition NamePerson1 ̸= NamePerson2 to the
pattern rule in our program if we explicitly want two different persons. When we consider
the weighted program obtained in that way, S will be the single weighted answer set
of the program, corresponding to the single subgraph isomorphic approximation of the
problem.
6
Conclusions and Directions for Further Research
We presented a simple and intuitive quantitative preferential semantics based on the
extended answer set semantics, characterized its expressiveness and illustrated its use-
fulness using an application in the area of intelligence analysis. Possible topics for further

Weighted Answer Sets and Applications in Intelligence Analysis
183
research include the efﬁcient implementation of the semantics, e.g. using existing answer
set solvers such as dlv [7] or smodels [11]. Furthermore, the relationships between the
present proposal and other weighted semantics such as weak constraints [3] need to be
investigated.
References
1. Tatsuya Akutsu and Magn´us M. Halld´orsson. On the approximation of largest common
subtrees and largest common point sets. Theoretical Comp. Science, 233(1-2):33–50, 2000.
2. Chitta Baral. Knowledge Representation, Reasoning and Declarative Problem Solving. Cam-
bridge Press, 2003.
3. Francesco Buccafurri, Nicola Leone, and Pasquale Rullo. Strong and weak constraints in dis-
junctive datalog. In Proceedings of the 4th International Conference on Logic Programming
(LPNMR ’97), pages 2–17, 1997.
4. Thayne Coffman, Seth Greenblatt, and Sherry Marcus. Graph-based technologies for intel-
ligence analysis. Communications of the ACM, 47(3):45–47, 2004.
5. L. Console and P. Torasso. A spectrum of logical deﬁnitions of model-based diagnosis.
Computational Intelligence, 7(3):133–141, 1991.
6. Thomas Eiter, Wolfgang Faber, Nicola Leone, and Gerald Pfeifer. The diagnosis frontend of
the dlv system. AI Communications, 12(1-2):99–111, 1999.
7. Thomas Eiter, Wolfgang Faber, Nicola Leone, and Gerald Pfeifer. Declarative problem-
solving using the dlv system. Logic-Based Artiﬁcial Intelligence, pages 79–103, 2000.
8. Michael Gelfond and Vladimir Lifschitz. The stable model semantics for logic programming.
In Logic Programming, Proceedings of the Fifth International Conference and Symposium,
pages 1070–1080. MIT Press, 1988.
9. R.J. Heuer. Psychology of intelligence analysis. Center for the Study of Intelligence, Central
Intelligence Agency, 2001.
10. Vladimir Lifschitz. Answer set programming and plan generation. Journal of Artiﬁcial
Intelligence, 138(1-2):39–54, 2002.
11. Syrj¨anen T. and Niemel¨a I. The smodels system. In Proceedings of the 6th International
Conference on Logic Programming and Nonmonotonic Reasoning, volume 2173 of Lecture
Notes in Computer Science, pages 434–438, Vienna, Austria, September 2001. Springer.
12. J.R. Ullman. An algorithm for subgraph isomorphism. J. of the ACM, 23(1):31–42, 1976.
13. Davy Van Nieuwenborgh, Stijn Heymans, and Dirk Vermeir. On programs with linearly
ordered multiple preferences. In Proc. of 20th Intl. Conference on Logic Programming (ICLP
2004), volume 3132 of Lecture Notes in Computer Science, pages 180–194. Springer, 2004.
14. Davy Van Nieuwenborgh and Dirk Vermeir. Preferred answer sets for ordered logic programs.
In European Conference on Logics in Artiﬁcial Intelligence, JELIA 2002, volume 2424 of
Lecture Notes in Artiﬁcial Intelligence, pages 432–443, 2002.
15. Davy Van Nieuwenborgh and Dirk Vermeir. Ordered diagnosis. In Proceedings of the 10th
International Conference on Logic for Programming, Artiﬁcial Intelligence, and Reasoning
(LPAR2003), volume 2850 of LNAI, pages 244–258. Springer, 2003.
16. Marina De Vos and Dirk Vermeir. Logic programming agents playing games. In Research and
Development in Intelligent Systems XIX (ES2002), BCS Conference Series, pages 323–336.
Springer-Verlag, 2002.

How to Fix It:
Using Fixpoints in Diﬀerent Contexts⋆
Igor Walukiewicz
LaBRI, Universit´e Bordeaux-1
351, Cours de la Lib´eration
F-33 405, Talence cedex, France
Abstract. In this note we discuss the expressive power of µ-calculi. We
concentrate on those that are extensions of propositional modal logics
with a ﬁxpoint operator. The objective is to try to match the expressive
power of monadic second-order logic. We consider diﬀerent kinds of mod-
els: from trees and transition systems up to traces and timed systems.
1
Introduction
Regular languages are a very interesting class because they have many closure
properties and many equivalent characterizations. Just to give an example, reg-
ular languages of ﬁnite words are characterized by ﬁnite automata and also
by monadic second-order logic (MSOL). The logical characterization testiﬁes
the nice closure properties of the class. The automata characterization permits,
among others, the development of an important set of tools used in veriﬁcation.
Regular languages can also be characterized by the µ-calculus. It is a logical char-
acterization, but its good algorithmic properties bring it close to the automata
characterization. Indeed, the connections between the µ-calculus and alternating
automata are so strong that one can almost say that they are the same modulo
the vocabulary used to describe them.
It is easy to interpret MSOL over diﬀerent domains: trees, traces, graphs,
real-time sequences. This way we obtain immediately an expressibility yardstick
in all these diﬀerent settings. We can then hope to adapt other characteriza-
tions of regular languages to other domains so that they match expressiveness
of MSOL. If successful one gets a similar set of powerful tools as the one for
regular languages of ﬁnite words.
The goal of this note is to put together three attempts [6,11,7] to match the
power of MSOL over three diﬀerent domains. The presented characterizations
will be either in terms of ﬁxpoint logic or in terms of alternating automata.
We will begin with the equivalence of the µ-calculus and MSOL on inﬁnite
binary trees. We will show how this equivalence generalizes nicely to all transition
systems. Next, we will proceed to trace models that are the simplest among so
called non-interleaving models for concurrency. Unlike words, which are linear
⋆Work supported by the ACI S´ecurit´e Informatique VERSYDIS.
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 184–193, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

How to Fix It: Using Fixpoints in Diﬀerent Contexts
185
orders on events, traces are partial orders on events. The intuition is that if
two events are not ordered then they have happened concurrently. Once again,
after deﬁning a µ-calculus appropriately we are able to get the equivalence with
MSOL and automata over traces. Finally, we will discuss the real-time setting.
The situation here is more delicate because both the standard automata model
as well as MSOL are undecidable. We will present a recent result which gives a
decidable ﬁxpoint calculus but with yet unknown expressive power.
2
The µ-Calculus over Transition Systems
In this section we recall the deﬁnition of the µ-calculus and discuss the expressive
power of the logic over trees and transitions systems. The µ-calculus is an ex-
tension of the modal logic K with ﬁxpoint operators. This addition gives a logic
with very interesting expressive power. While modal logic K is less expressive
than ﬁrst-order logic, the µ-calculus expresses a good fragment of the properties
deﬁnable in monadic second-order logic.
Formulas of the µ-calculus over the sets Prop = {p1, p2, . . .} of propositional
constants, Act = {a, b, . . . } of actions, and Var = {X, Y, . . .} of variables, are
deﬁned by the following grammar:
F := Prop | ¬Prop | Var | F ∨F | F ∧F |
⟨Act⟩F | [Act]F | µVar.F |νVar.F
Note that we allow negations only before propositional constants. This is not a
problem as we will be interested in sentences, i.e., formulas where all variables
are bound by µ or ν. Negation of a sentence is deﬁned by de Morgan laws and
the duality between the least and the greatest ﬁxed points (cf. [3,10]). In the
following α, β, . . . will denote formulas of the logic.
Formulas are interpreted in transition systems which are tuples of the form
M = ⟨S, {Ra}a∈Act, ρ⟩, where: S is a nonempty set of states, Ra ⊆S × S is
a binary relation interpreting the action a, and ρ : Prop →P(S) is a function
assigning to each propositional constant a set of states where this constant holds.
For a given transition system M and an assignment V : Var →P(S), the
set of states in which a formula ϕ is true, denoted ∥ϕ ∥M
V , is deﬁned inductively
as follows:
∥p ∥M
V = ρ(p)
∥¬p ∥M
V = S −ρ(p)
∥X ∥M
V =V (X)
∥⟨a⟩α ∥M
V ={s : ∃s′.Ra(s, s′) ∧s′ ∈∥α ∥M
V }
∥µX.α(X) ∥M
V =

{S′ ⊆S : ∥α ∥M
V [S′/X] ⊆S′}
∥νX.α(X) ∥M
V =

{S′ ⊆S : S′ ⊆∥α ∥M
V [S′/X]}
We have omitted here the obvious clauses for boolean operators and for [a]α
formula. We will omit V in the notation if α is a sentence and will sometimes
write M, s ⊨α instead of s ∈∥α ∥M.

186
I. Walukiewicz
The question we are interested in is what kind of properties are expressible in
the logic. For this we introduce the notion of a pointed transition system which
is a pair (M, s) consisting of a transition system and its state. A µ-calculus
sentence deﬁnes a class of pointed transition systems (M, s) such that M, s ⊨α.
To answer the question about the expressive power we will ﬁrst consider a
restricted class of graphs, namely deterministic trees. For this class we get a
perfect match with other well known formalism: monadic second-order logic.
Monadic second-order logic (MSOL) is an extension of ﬁrst-order logic with
quantiﬁcation over sets of elements. The signature of the logic consists of one
binary relation Ra for each a ∈Act and a monadic relation Pp for each p ∈Prop.
Let Var 1 = {x, y, . . . } and Var 2 = {X, Y, . . . } be the sets ﬁrst and second order
variables, respectively. The syntax of MSOL is given by the usual rules for the
ﬁrst-order logic together with the following:
– if X ∈Var 2, y ∈Var 1 and α is a formula then X(y) and ∃X.α are formulas.
Given a transition system M = ⟨S, {Ra}a∈Act, ρ⟩, the semantic of a formula is
deﬁned as in the ﬁrst-order logic. Because we have both ﬁrst and second-order
variables, the valuation V should assign to a variable either an element or a set
of elements respectively. The two new constructs are interpreted by:
– M, V ⊨X(y) iﬀV (y) ∈V (X),
– M, V ⊨∃X.α iﬀthere is S′ ⊆S such that M, V [S′/X] ⊨α.
A pointed transition system (M, s) can be considered as a transition system
with one more proposition Pstart that is true only in s. With this convention we
can talk about a class of pointed transition systems deﬁned by a MSOL formula.
A deterministic tree is a transition system whose underlying edge labeled
graph is a tree and such that for each node and for each relation Ra there is
at most one outgoing transition on Ra from the node. Such a tree can be also
considered as a pointed transition system where the chosen state is the root of
the tree. Observe that for every deterministic tree M and a state s the truth
of a µ-calculus formula in s depends only on the subtree rooted in s. Thus for
deﬁnability it does not make much sense to consider pointed structures with
other distinguished states than the root.
Theorem 1 ([8]). A set of deterministic trees is deﬁnable by a MSOL sentence
iﬀit is deﬁnable by a µ-calculus sentence.
The restriction to deterministic trees is necessary because over graphs MSOL
can say much more than the µ-calculus about structural properties of graphs.
It can say for example that there is a cycle in a transition system; this explains
why we need to restrict to trees. It can also say that the number successors of a
node is bigger than some threshold; this explains the condition of determinism.
Consider a standard deﬁnition of bisimulation between pointed transition
systems (where it is required that bisimilar states should satisfy the same propo-
sitions). The two structural properties mentioned above are not invariant under

How to Fix It: Using Fixpoints in Diﬀerent Contexts
187
bisimulation while all µ-calculus deﬁnable properties are. Given this, the fol-
lowing theorem says that over transition systems the µ-calculus has the best
possible expressive power.
Deﬁnition 1. A property is invariant under bisimulation iﬀfor arbitrary two
pointed transition systems either both have the property, or both do not have it.
Theorem 2 ([6]). A property of transition systems is deﬁnable in the µ-calculus
iﬀit is deﬁnable in MSOL and it is invariant under bisimulation.
3
Traces
A trace is a partial order with some particular properties. It can be used to
represent an execution of the system where we do not want to put some artiﬁcial
order on actions that appear concurrently. A trace can be represented by a
transition system so it makes sense to talk about monadic second-order logic
and the µ-calculus properties of traces. Due to the particularity of the setting
it is not reasonable to consider bisimulation invariant properties of traces. Thus
the theorem from the previous section looses its appeal. We will see that the
µ-calculus is weaker than MSOL over traces. One can obtain the equivalence by
giving to the µ-calculus access to some information about the concurrency in
the system.
A trace alphabet is a pair (Σ, D) where Σ is a ﬁnite set of actions and D ⊆
Σ × Σ is a reﬂexive and symmetric dependence relation.
A Σ-labeled graph is ⟨S, R, λ⟩where S is the set of vertices, R deﬁnes the
edges and λ : S →Σ is a labeling function.
Deﬁnition 2. A trace or a dependence graph over a trace alphabet (Σ, D) is
a Σ-labeled graph ⟨E, R, λ⟩satisfying the following conditions:
(T1)
∀e, e′ ∈E. (λ(e), λ(e′)) ∈D ⇔(R(e, e′) ∨R(e′, e) ∨e = e′).
(T2)
the transitive closure R∗of R is a partial order and
{e′ : R∗(e′, e)} is ﬁnite for every e.
The nodes of a dependence graph are called events. An a-event is an event e ∈E
which is labeled by a, i.e., λ(e) = a. We say that e is before e′ iﬀR∗(e, e′) holds.
In this case we also say that e′ is after e.
The ﬁrst condition of the deﬁnition of dependence graphs says that the events
are related only if they are labeled by dependent letters. The second says that
there cannot be neither circular dependencies nor inﬁnite descending chains. So
the past of each event (i.e. the set of events that appear before it) is ﬁnite. The
traces we consider here are sometimes called real traces [5]. From the deﬁnition
it follows that they are either ﬁnite or countably inﬁnite.
Deﬁnition 3. A transition system representation of a trace G = ⟨E, R, λ⟩is a
transition system M(G) = ⟨E, RH, ρ⟩over the set of propositions {Pa : a ∈Σ}
where (i) the function ρ is deﬁned by ρ(Pa) = {e : λ(e) = a}; and (ii) RH is
the smallest relation needed to determine R, i.e., R∗
H = R∗and if RH(e, e′) then
there is no e′′ diﬀerent from e and e′ such that RH(e, e′′) and RH(e′′, e′) hold.

188
I. Walukiewicz
The dependence graph representation has too many transitions to be interesting
for the logic as the µ-calculus. Working with this representation would be similar
to considering transitive closure of relations and not relations themselves. The
transition system representation we have deﬁned uses Hasse diagram of the trace
(which exists and is unique in this setting). To be consistent with the deﬁnitions
from the previous section we also need to change the labeling function. In traces
this function assigns a label to each node, in transition systems it assigns a set
of nodes to each label. Observe that a representation of a trace is a transition
system with a singleton action alphabet.
Thanks to the above deﬁnition we can use formalisms of transition systems to
talk about traces. In particular we will talk about µ-calculus or MSOL deﬁnable
sets of traces considered as pointed transition systems. In principle there can
be more than one minimal element in a trace and this can pose a problem with
deﬁnition of a pointed transition system. Because of this we assume a relatively
harmless proviso that every trace has the least event. Thus a transition system
M(G) can be considered as pointed transition system (M(G), e) where e is the
least event of G.
It turns out that the class of MSOL deﬁnable trace languages have very
similar characterizations as in the case of inﬁnite words. The following theorem
summarizing many results on traces can be found in [4].
Theorem 3. Fix a given trace alphabet. For a set L of traces the following are
equivalent:
– L is deﬁnable by a MSOL formula.
– L is deﬁnable by a c-regular expression.
– L is recognizable by an asynchronous automaton.
– The set of linearizations of traces in L is a recognizable language of ﬁnite
and inﬁnite words.
We will not need asynchronous automata or c-regular expressions, so we
will not deﬁne them here. If linearizations are concerned, let us just say that
a linearization of a trace is an inﬁnite word which corresponds to some linear
order of type ω extending the partial order of the trace.
We next show that the µ-calculus over traces cannot even express some ﬁrst-
order deﬁnable properties. This example motivates the search for extensions of
the µ-calculus that can capture the power of MSOL over traces.
Proposition 1. No µ-calculus sentence can distinguish between the transition
system representations of the two traces presented in Figure 1. In the left graph
the dots stand for the sequence (dc)ω and in the right graph for (cd)ω. In this
example the trace alphabet ({⊥, a, b, c, d}, D) where D is the smallest symmetric
and reﬂexive relation containing the pairs {(a, c), (b, d), (c, d)}∪{⊥}×{a, b, c, d}.

How to Fix It: Using Fixpoints in Diﬀerent Contexts
189
⊥
a
b
c
d
d
c
⊥
a
b
c
d
c
d
Fig. 1. Indistinguishable traces
Proof.
The two pointed transition systems are bisimilar. Proposition follows
from the fact that no µ-calculus formula can distinguish between two bisimilar
pointed transition systems.
2
The two traces from the proposition are distinguishable by a ﬁrst-order for-
mula because in the left trace ﬁrst d comes before ﬁrst c and it is the opposite
in the right trace.
The above example implies that one needs to add something to the µ-calculus
in order to be able to say more about the structure of a trace. One of the possible
extensions is that with concurrency information.
Deﬁnition 4. Let M(G) = ⟨E, R, ρ⟩be a transition system representation of
a trace G. Relation co ⊆E × E, called the concurrency relation, is deﬁned by:
co(e, e′) iﬀneither R∗(e, e′) nor R∗(e′, e) hold.
Deﬁnition 5. Let M(G) = ⟨E, R, ρ⟩be a transition system representation of
a trace G. We deﬁne an enriched representation Mco(G) = ⟨E, R, ρco⟩by
adding new propositions coa for a ∈Act and setting ρco(coa) = {e : ∃e′ ∈
λ(pa). co(e, e′)}. (Naturally ρ and ρco coincide on all other propositions.)
Intuitively a coa proposition holds in an event if there is a concurrent event
labeled by a. This way a µ-calculus formula can get some information about what
happens in parallel to the current event. Observe that co relation is deﬁnable in
MSOL. The following theorem says that Mco representations are reach enough
to get the equivalence between the µ-calculus and MSOL.
Theorem 4 ([11]). For every MSOL formula ϕ there is a µ-calculus formula
αϕ such that for every trace G M(G) ⊨ϕ iﬀMco(G) ⊨αϕ.
4
Real-Time Languages
By a timed word over Σ we mean a ﬁnite sequence
w = (a1, t1)(a2, t2) . . . (an, tn)

190
I. Walukiewicz
of pairs from Σ ×R+. Each ti describes the amount of time that passed between
reading ai−1 and ai, i.e., a1 was read at time t1, a2 was read at time t1+t2, and
so on. Note that we consider only ﬁnite timed words.
The presence of a dense domain makes a big diﬀerence and adoption of the
tools described in previous sections proceeds with some diﬃculties. The standard
automata model for real-time setting [1] is not closed under complement. First-
order logic with monadic predicates and +1 relation is undecidable over real line.
So it the MSOL theory of the real line (without +1 predicate) [9]. These negative
results indicate that some extra care is need to obtain decidable formalisms with
good expressive power.
Actually, it is quite diﬃcult to get a formalism with a reasonable expressive
power and closed under boolean operations. One such formalism is event-clock
automata [2]. These are a special variant of timed automata where the reset
operation on clocks is restricted. Here, we would like to present a diﬀerent ap-
proach. It is well known that the µ-calculus over transition systems is equivalent
to alternating automata and that there are very direct translations between the
two formalism. Thus we would like to ﬁnd an alternating automata model for
timed-words. The ﬁrst attempt would be to generalize the standard notion of
timed automata [1] by introducing alternation. This is bound to fail as the uni-
versality problem for timed automata is undecidable and, in consequence, we
would get a model with undecidable emptiness problem.
A solution is to restrict to automata with one clock [7]. With one clock alter-
nating automata can still recognize languages not recognizable by nondetermin-
istic automata with many clocks and moreover they have decidable emptiness
problem. Below we deﬁne alternating timed automata in full generality and then
state the results for the one-clock version.
For a given ﬁnite set C of clock variables (or clocks in short), consider the set
Φ(C) of clock constraints σ deﬁned by
σ
::=
x < c | x ≤c | σ1 ∧σ2 | ¬σ,
where c stands for an arbitrary nonnegative integer constant, and x ∈C. For
instance, note that tt (always true), or x = c, can be deﬁned as abbreviations.
Each constraint σ denotes a subset [σ] of (R+)C, in a natural way, where R+
stands for the set of nonnegative reals.
Transition relation of a timed automaton [1] is usually deﬁned by a ﬁnite set
of rules δ of the form
δ ⊆Q × Σ × Φ(C) × Q × P(C),
where Q is a set of locations (control states) and Σ is an input alphabet. A rule
⟨q, a, σ, q′, r⟩∈δ means, roughly, that when in a location q, if the next input
letter is a and the constraint σ is satisﬁed by the current valuation of clock
variables then the next location can be q′ and the clocks in r should be reset
to 0. Our deﬁnition below uses an easy observation, that the relation δ can be
suitably rearranged into a ﬁnite partial function
Q × Σ × Φ(C)
·→P(Q × P(C)).

How to Fix It: Using Fixpoints in Diﬀerent Contexts
191
The deﬁnition below comes naturally when one thinks of an element of the
codomain as a disjunction of a ﬁnite number of pairs (q, r). Let B+(X) denote
the set of all positive boolean formulas over the set X of propositions, i.e., the
set generated by:
φ
::=
X | φ1 ∧φ2 | φ1 ∨φ2.
Deﬁnition 6 (Alternating timed automaton). An alternating timed au-
tomaton is a tuple A = (Q, q0, Σ, C, F, δ) where: Q is a ﬁnite set of loca-
tions, Σ is a ﬁnite input alphabet, C is a ﬁnite set of clock variables, and
δ : Q×Σ ×Φ(C)
·→B+(Q×P(C)) is a ﬁnite partial function. Moreover q0 ∈Q is
an initial state and F ⊆Q is a set of accepting states. We also put an additional
restriction:
(Partition) For every q and a, the set {[σ] : δ(q, a, σ) is deﬁned} gives a (ﬁnite)
partition of (R+)C.
The (Partition) condition does not limit the expressive power of automata. We
impose it because it permits to give a nice symmetric semantic for the au-
tomata as explained below. We will often write rules of the automaton in a
form: q, a, σ 
→b.
To deﬁne an execution of an automaton, we will need two operations on
valuations v ∈(R+)C. A valuation v+t, for t ∈R+, is obtained from v by
augmenting value of each clock by t. A valuation v[r := 0], for r ⊆C, is obtained
by reseting values of all clocks in r to zero.
In order to deﬁne acceptance, for an alternating timed automaton A and a
timed word w = (a1, t1)(a2, t2) . . . (an, tn), we deﬁne the acceptance game GA,w
between two players Adam and Eve. Intuitively, the objective of Eve is to accept
w, while the aim of Adam is the opposite. A play starts at the initial conﬁguration
(q0, v0), where v0 : C →R+ is a valuation assigning 0 to each clock variable.
It consists of n phases. The (k+1)-th phase starts in (qk, vk), ends in some
conﬁguration (qk+1, vk+1) and proceeds as follows. Let v := vk + tk+1. Let σ be
the unique constraint such that v satisﬁes σ and b = δ(qk, ak+1, σ) is deﬁned.
Now, the outcome of the phase is determined by the formula b. There are three
cases:
– b = b1 ∧b2: Adam chooses one of subformulas b1, b2 and the play continues
with b replaced by the chosen subformula;
– b = b1 ∨b2: dually, Eve chooses one of subformulas;
– b = (q, r) ∈Q × P(C): the phase ends with the result (qk+1, vk+1) :=
(q, v[r := 0]). A new phase is starting from this conﬁguration if k+1 < n.
The winner is Eve if qn is accepting (qn ∈F), otherwise Adam wins.
Deﬁnition 7 (Acceptance). The automaton A accepts w iﬀEve has a win-
ning strategy in the game GA,w. By L(A) we denote the language of all timed
words w accepted by A.

192
I. Walukiewicz
To show the power of alternation we give an example of an automaton for a
language not recognizable by standard (i.e. nondeterministic) timed automata
(cf. [1]).
Example 1. Consider a language consisting of timed words w over a singleton
alphabet {a} that contain no pair of letters such that one of them is precisely
one time unit later than the other. The alternating automaton for this language
has three states q0, q1, q2. State q0 is initial. The automaton has a single clock x
and the following transition rules:
q0, a, tt 
→(q0, ∅) ∧(q1, {x})
q1, a, x=1 
→(q2, ∅)
q1, a, x̸=1 
→(q1, ∅)
q2, a, tt 
→(q2, ∅)
States q0 and q1 are accepting. Clearly, Adam has a strategy to reach q2 iﬀthe
word is not in the language, i.e., some letter is one time unit after some other.
As one expects, we have the following:
Proposition 2. The class of languages accepted by alternating timed automata
is eﬀectively closed under all boolean operations: union, intersection and com-
plementation. These operations to do not increase the number of clocks of the
automaton.
The closure under conjunction and disjunction is straightforward since we
permit positive boolean expressions as values of the transition function. Due
to the condition (Partition) the automaton for the complement is obtained by
exchanging conjunctions with disjunctions in all transitions and exchanging ac-
cepting states with non-accepting states.
An alternating timed automaton A is called purely existential if no conjunc-
tion appears in the transition rues δ. It is obvious that every purely-existential
automaton is a standard nondeterministic timed automaton. The converse re-
quires a proof because of the (Partition) condition.
Proposition 3. Every standard nondeterministic automaton is equivalent to a
purely-existential automaton.
The automaton from Example 1 uses only one clock. This shows that one
clock alternating automata can recognize some languages not recognizable by
nondeterministic automata with many clocks. The converse is also true. It is
enough to consider the language consisting of the words containing an appear-
ance of a letter b at times t1, t2, for some 0<t1<t2<1, and such that there is no b
at time between t1 and t2 while there is precisely one b between t1+1 and t2+1.
Theorem 5 ([7]). The emptiness problem is decidable for one-clock alternating
timed automata.
Thanks to this theorem we have a decidable formalism of timed-words that
is closed under boolean operations. One can think of developing a variant of the

How to Fix It: Using Fixpoints in Diﬀerent Contexts
193
µ-calculus which would correspond to these automata. It should not be too diﬃ-
cult given that the translation between alternating automata and the µ-calculus
works in many other settings. The main obstacles in this line of development are
rather negative complexity results. The complexity of the emptiness problem for
one-clock alternating automata is not primitively recursive [7]. Moreover, if we
consider inﬁnite words and alternating B¨uchi timed automata with one clock
then the problem becomes undecidable.
References
1. R. Alur and D.L. Dill. A theory of timed automata. Theoretical Computer Science,
126:183–235, 1994.
2. R. Alur, L. Fix, and T. Henzinger. Event-clock automata: A determinizable class
of timed automata. Theoretical Computer Science, 204, 1997.
3. Andre´e Arnold and Damian Niwi˜nski. The Rudiments of the Mu-Calculus, volume
146 of Studies in Logic. North-Holand, 2001.
4. Werner Ebinger. Logical deﬁnability of trace languages. In Volker Diekert and
Grzegorz Rozenberg, editors, The Book of Traces, pages 382–390. World Scientiﬁc,
1995.
5. Paul Gastin and Antoine Petit. Infninite traces. In V. Diekert and G. Rozenberg,
editors, The Book of Traces. World Scientiﬁc, 1995.
6. David Janin and Igor Walukiewicz. On the expressive completeness of the propo-
sitional mu-calculus with respect to monadic second order logic. In CONCUR’96,
volume 1119 of Lecture Notes in Computer Science, pages 263–277, 1996.
7. Slawomir Lasota and Igor Walukiewicz. Alternating timed automata. In FOS-
SACS’05, Lecture Notes in Computer Science, 2005. To appear.
8. Damian Niwi´nski. Fixed points vs. inﬁnite generation. In LICS ’88, pages 402–409,
1988.
9. Saharon Shelah. The monadic second order theory of order. Annals of Mathematics,
102:379–419, 1975.
10. Colin Stirling. Modal and Temporal Properties of Processes. Texts in Computer
Science. Springer, 2001.
11. Igor Walukiewicz. Local logics for traces. Journal of Automata, Languages and
Combinatorics, 7(2):259–290, 2002.

Reasoning About Systems with Transition Fairness
Benjamin Aminof1, Thomas Ball2, and Orna Kupferman1
1 Hebrew University, School of Engineering and Computer Science, Jerusalem 91904, Israel
{benj,orna}@cs.huji.ac.il
2 Microsoft Research, One Microsoft way, Redmond, WA 98052, USA
tball@microsoft.com
Abstract. Formal veriﬁcation methods model systems by Kripke structures. In
order to model live behaviors of systems, Kripke structures are augmented with
fairness conditions. Such conditions partition the computations of the systems
into fair computations, with respect to which veriﬁcation proceeds, and unfair
computations, which are ignored. Reasoning about Kripke structures augmented
with fairness is typically harder than reasoning about non-fair Kripke structures.
We consider the transition fairness condition, where a computation π is fair iff
each transition that is enabled in π inﬁnitely often is also taken in π inﬁnitely
often. Transition fairness is a natural and useful fairness condition. We show that
reasoning about Kripke structures augmented with transition fairness is not harder
than reasoning about non-fair Kripke structures. We demonstrate it for fair CTL
and LTL model checking, and the problem of calculating the dominators and
postdominators.
1
Introduction
In formal veriﬁcation, we check that a system is correct with respect to a desired behavior
by checking that a mathematical model of the system satisﬁes a formal speciﬁcation of
the behavior. In model checking, we model the system by a Kripke structure, whose
states correspond to conﬁgurations of the system, and we specify the desired behavior
by means of a temporal-logic formula. The model-checking problem is then to decide,
given a Kripke structure K and a temporal-logic formula ψ, whether K satisﬁes ψ
[CE81,QS81]. Symbolic methods, abstraction, compositional methods, and many more
heuristics have made model checking a successful veriﬁcation methodology, used in
industrial design of both hardware and software [CGP99].
Kripke structures describe only the safe behaviors of systems. In order to model
live behaviors, we have to augment Kripke structures with fairness conditions. Such
conditions partition the set of inﬁnite paths of a Kripke structure K (and thus also the set
of inﬁnite computations of the system that K models) into fair and unfair computations
[Fra86,MP92]. For example, when the Kripke structure models a concurrent system, we
may wish to restrict attention only to computations in which the scheduler enables each
process to proceed inﬁnitely many times.
The model-checking problem can be adjusted to the fair setting: in the linear-time
approach, speciﬁcations describe the desired behavior of all the computations of the
system, and thus refer to the language induced by the Kripke structure. Then, fair model
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 194–208, 2005.
c⃝Springer-Verlag Berlin Heidelberg 2005

Reasoning About Systems with Transition Fairness
195
checking amounts to verifying that all the fair computations satisfy the desired behavior.
In the branching-time approach, speciﬁcations may contain the path quantiﬁers A (for all
paths) and E (exists a path) and thus refer to the tree obtained by unwinding the Kripke
structure. Then, in fair model checking, path quantiﬁcation ranges over fair paths only
[CES86]. The transition to the fair setting involves a computational price. The exact
complexity of the fair model-checking problem depends on the speciﬁcation formalism
and the speciﬁc fairness condition that is used.
We consider the fairness condition in which a computation π is fair iff each transition
that is enabled in π inﬁnitely often is also taken in π inﬁnitely often. That is, for every
transition ⟨w, w′⟩in the Kripke structure, if the path π visits the state w inﬁnitely many
times,thenπ shouldalsohaveinﬁnitelymanyvisitstow thatareimmediatelyfollowedby
a visit to w′. We refer to this type of fairness as transition fairness. The transition fairness
condition is related to the classical strong-fairness condition [MP92] (Streett fairness)3,
and is a very natural one in reasoning about concurrent systems [LPS81,KPSZ02].
In order to see why transition fairness is so natural and useful, let us consider the
possible sources for nondeterminism in a Kripke structure. We distinguish between
external and internal nondeterminism [Hoa85]. External nondeterminism is caused by
the interaction of the system with its environment, and the fact that different inputs are
expected in each state of the system. Then, transition fairness requires that in every
state of the interaction that is visited inﬁnitely often, the environment provides each
input inﬁnitely often. Internal nondeterminism is caused by abstraction. In the case of
a concurrent composition between processes, we usually abstract the scheduler. Then,
transition fairness restricts attention to a scheduling policy in which for each process,
if a process is enabled in a state inﬁnitely often, then it is also scheduled to proceed
inﬁnitely often. In case we abstract other factors of the system, like information that is
irrelevant for the speciﬁcation, transition fairness is less natural and restricts attention
to computations that are fair with respect to the abstracted information. For an extensive
study of transition fairness, further motivation for it, and related deﬁnitions of fairness,
see [QS83].
Reasoning about systems augmented with the strong-fairness condition is not easy,
and is related to the emptiness problem for nondeterministic Streett automata. While the
latter problem is PTIME-complete [EL87,KV98a], no linear solutions are known, for
both the enumerative and symbolic approaches. The best enumerative algorithm makes
use of a lock-step search, used in dynamic graph algorithms, and is at most quadratic in
the size of the automaton [HT96]. The best symbolic algorithm is based on the improved
algorithm for detecting strongly connected components and requires O(n(k + log n))
symbolic steps, for an automaton of size n and a strong-fairness condition with k pairs
3 The Streett fairness condition consists of a set of pairs ⟨Li, Ui⟩, with Li and Ui being a subset
of the state space. A path π is fair if for all pairs, if the set Li is visited inﬁnitely often, then
so is Ui. By having a pair ⟨{w}, {w′}⟩for each transition ⟨w, w′⟩in the Kripke structure, we
can encode transition fairness with the Streett fairness condition (a technical issue is the fact
w′ may be reached via a different transition. This can be easily solved by adding an internal
state to each transition). In Section 2.2 we discuss other related fairness conditions.

196
B. Aminof, T. Ball, and O. Kupferman
[KPR98,BGS00]4. The complexity of model checking a speciﬁcation ϕ with respect to
a Kripke structure K augmented with a strong-fairness condition with k pairs is then
the complexity of checking emptiness for an automaton of size |K|2|ϕ|, in the case of
LTL5, and |ϕ| repeated checks for an automaton of size |K|, in the case of CTL.
We study the problem of reasoning about systems augmented with the transition
fairness condition, and show that this special case of the strong-fairness condition is
considerably simpler. We consider the CTL and LTL model-checking problems, as well
as the related problem of ﬁnding dominators and postdominators [C+91] in directed
graphs.
For model checking, we show that fair CTL model checking can be reduced to
non-fair CTL model checking. To do so, we introduce a function f with the following
properties. Given a CTL formula ϕ, the function f maps ϕ to another CTL formula
f(ϕ) such that for every Kripke structure K and state w in it, w satisﬁes ϕ fairly iff w
satisﬁes f(ϕ) non-fairly. The size of f(ϕ) is linear in the size of ϕ. The complexity of
the algorithm that follows then coincides with the one for non-fair CTL model checking.
Since the function f is simple, it is easy to implement it on top of both enumerative
and symbolic CTL model-checking tools. We note that another reduction of fair model
checking to unfair model checking by a transformation of the speciﬁcation is described
in [QS83]. The logic studied there contains operators corresponding to CTL’s EF (“po-
tential reachability”) and AF (“inevitable reachability”) and the transformation results
in formulas that are not CTL formulas.
In order to handle LTL model checking, we introduce a function g that maps LTL
formulas θ of some speciﬁc forms to a CTL formula g(θ) such that a fair Kripke structure
K hasapaththatfairlysatisﬁesθ iffK fairlysatisﬁesg(θ),whichinturncanbereducedto
checking whether K satisﬁes f(g(θ)). The forms of θ we handle are these that correspond
to the B¨uchi, Rabin, and Streett acceptance conditions for automata on inﬁnite words. In
the automata-theoretic approach to LTL model checking [VW94], we translate an LTL
formula ψ into an automaton A¬ψ that accepts exactly all the computations that violate
ψ. Model checking is then reduced to checking the emptiness of the product of K with
A¬ψ. When K is augmented with a fairness condition, checking the emptiness of the
product of K with A¬ψ corresponds to checking whether the product contains a path
whose projection on the states of K is fair, and which satisﬁes a formula θ induced by the
acceptance condition of A¬ψ, and is therefore of one of the forms above. Our algorithm
can therefore handle many LTL model-checking instances. On the other hand, we show
that taking the product of K with A¬ψ does not preserve transition fairness, thus our
algorithm does not handle all LTL model-checking instances.
The problem of ﬁnding the postdominators (or, dually, the dominators) of a given
state in the Kripke structure has application in the area of program analysis and compiler
optimizations [C+91]. In this application area, the control-ﬂow graph of a program is the
Kripke structure, where states correspond to basic blocks in the program and transitions
correspond to control-ﬂow transitions between basic blocks in the program. Domina-
4 We note that while it is possible to detect SCC also in linearly many symbolic steps [GPP03],
it is not known whether the technique there can be applied for an efﬁcient nonemptiness check
of Streett automata.
5 See [LH00] for the case the system is modeled by a petri net.

Reasoning About Systems with Transition Fairness
197
tors form the basis of an intermediate representation known as static single assignment
form [C+91], widely used in optimizing compilers. Computation of postdominators is
required for the computation of control dependences in the program dependence graph
[FOW87], a data structure used for the automatic parallelization of programs as well as
program slicing.
For a state w of a Kripke structure, the set of postdominators of w, denoted pd(w),
is the set of states s such that all paths from w eventually reach s. Dually, the set of
dominators of w, denoted dom(w), is the set of states s such that all paths to w pass
through s. The deﬁnition of pd(w) and its applications are of interest mainly in Kripke
structures augmented with fairness. Indeed, it makes sense to require s to be reachable
only along fair paths, in particular, paths that eventually reach a halting or an error
state, or paths that are fair with respect to our transition fairness condition. That is,
the deﬁnition of pd(w) as used in compiler optimizations generally assumes that loops
eventually terminate.
It is easy to show that if x postdominates w and x ̸= w then pd(x) ⊂pd(w).
This means that the postdomination relation can be represented as a tree, where x is the
parent of w in the tree iff pd(w) = {w} ∪pd(x) (in this case, x is called the “immediate
postdominator” of w). There are several efﬁcient algorithms for calculating dominator
and postdominator trees [LT79,BKAW98]. Once the tree has been computed, the set
pd(x) can be enumerated in time proportional to |pd(x)|, for all states x. However, the
above techniques maintain an explicit representation of the Kripke structure as a directed
graph and explicitly represent the postdominator tree. We use the technique we developed
for fair CTL model checking in order to describe a symbolic algorithm that efﬁciently
computes an ROBDD of pairs ⟨w, s⟩such that s ∈pd(w). Such a representation is
useful because in the application domain of program analysis it often is necessary to
enumerate pd(w) for many w without knowing in advance which w will be queried.
Due to lack of space, this version does not contain all the proofs. For the full version,
see [ABK04].
2
Preliminaries
2.1
Temporal Logics
We describe the desired behavior of systems by temporal-logic formulas. The logic LTL
is a linear temporal logic. Formulas of LTL describe computations and are constructed
from a set AP of atomic propositions using the usual Boolean operators and the temporal
operators X (“next”) and U (“until”). Formally, given a set AP, an LTL formula is one
of the following:
– true, false, or p, for p ∈AP.
– ¬ψ1, ψ1 ∨ψ2, Xψ1, or ψ1Uψ2, where ψ1 and ψ2 are LTL formulas.
We also use the abbreviations ∧, →, and ↔, interpreted in the usual way, Fψ = trueUψ
(“eventually”), Gψ = ¬F¬ψ (“always”), and ψ1Wψ2 = ψ1Uψ2∨Gψ1 (“weak until”).
The logic CTL is a branching temporal logic. In CTL, we precede each temporal
operator by a path quantiﬁer, either E (“for some path”) or A (“for all paths”). Thus, a
CTL formula is either:

198
B. Aminof, T. Ball, and O. Kupferman
– true, false, or p, for p ∈AP.
– ¬ϕ1 or ϕ1 ∨ϕ2, where ϕ1 and ϕ2 are CTL formulas.
– EXϕ1 or AXϕ1, where ϕ1 is a CTL formula.
– Eϕ1Uϕ2 or Aϕ1Uϕ2, where ϕ1 and ϕ2 are CTL formulas.
Note that the G and F abbreviations used in LTL can be used also in CTL, i.e.,
AFϕ1 = AtrueUϕ1, and so can the W abbreviation. Thus, while Eϕ1Wϕ2 =
E(ϕ1Uϕ2 ∨Gϕ1) is not a CTL formula, it is equivalent to the CTL formula Eϕ1Uϕ2 ∨
EGϕ1. Similarly, Aϕ1Wϕ2 is equivalent to the CTL formula ¬E(¬ϕ2)U(¬ϕ1 ∧¬ϕ2).
Accordingly, we refer to EW and AW as legal CTL modalities. The size |ϕ| of an LTL
or a CTL formula ϕ is the number of its subformulas. Note that ϕ can be represented by
a DAG with |ϕ| vertices.
We deﬁne the semantics of temporal-logic formulas with respect to Kripke structures,
with which we model systems. A Kripke structure K = ⟨AP, W, R, W0, L⟩consists of
a set AP of atomic propositions, a set W of states, a set W0 ⊆W of initial states, a
transition relation R ⊆W ×W that is total in its ﬁrst element (i.e., for each w ∈W there
exists at least one w′ with R(w, w′)), and a labeling function L : W →2AP , which maps
each state to the set of atomic propositions true in this state. When R(w, w′), we say that
w′ is a successor of w. A path in K represents a computation of the system modeled
by the Kripke structure and is a (possibly ﬁnite) sequence of states π = w0, w1, . . .,
such that for all i ≥0, we have R(wi, wi+1). The path π is initial if w0 ∈W0. We use
πi to denote the sufﬁx wi, wi+1, . . . of π, and we use π[i] to denote the i’th state in π.
The set of states that π visits is denoted by visit(π), and the set of states that π visits
inﬁnitely often is denoted by inf(π). Formally, visit(π) = {w : w = wj for some j},
and inf(π) = {w : w = wj for inﬁnitely many j}. Note that inf(π) ⊆visit(π).
Recall that LTL is a linear temporal logic, thus its formulas are interpreted over paths
of the Kripke structure. We use K, π |= ψ to indicate that the LTL formula ψ holds along
the path π of K. On the other hand, CTL is a branching temporal logic and its formulas
are interpreted over states of the Kripke structure. We use K, w |= ϕ to indicate that the
CTL formula ϕ holds in the state w of K. When K is clear from the context, we simply
write π |= ψ or w |= ϕ. For the deﬁnition of the relation |= see [Eme90]. We say that a
Kripke structure K satisﬁes an LTL formula ψ, denoted K |= ψ, if all the initial paths
of K satisfy ψ. Likewise, K satisﬁes a CTL formula ϕ, denoted K |= ϕ, if all the initial
states of K satisfy ϕ.
AKripkestructureK = ⟨AP, W, R, W0, L⟩inducesadirectedgraphGK = ⟨W, R⟩.
Notations and deﬁnitions from graph theory are then applied to Kripke structures in a
straightforward way. A state w is reachable from a state v iff there is a ﬁnite (possibly
empty) path w0, w1, . . . , wn such that v = w0 and w = wn and for every 0 ≤i < n, we
have R(wi, wi+1). A strongly connected component (SCC, for short) is a subset C of
W such that every state in C is reachable from every other state in C, via states in C. A
maximal strongly connected component (MSCC, for short) is an SCC C that is maximal
in the sense that we cannot add states to it and still have an SCC. Note that the MSCCs
partition W.
Given two MSCC’s C and C′ we say that C ≤C′ if there are states v ∈C′ and
w ∈C such that w is reachable from v. The relation ≤deﬁned above constitutes a
partial ordering of the set of MSCCs of K. A MSCC C is called a bottom MSCC if for

Reasoning About Systems with Transition Fairness
199
every MSCC C′, we have that either C and C′ are not comparable or C ≤C′. Note that
all the bottom MSCCs in a Kripke structure are not trivial (i.e., they contain at least one
edge) since R is total in its ﬁrst element.
It is not hard to see that for every state v ∈W there is at least one bottom MSCC C
such that for every state w ∈C, we have that w is reachable from v. Observe that since
there are no trivial bottom MSCCs we can assume that every w above is reachable from
v using a non-empty path.
2.2
Fairness
A fairness condition on a Kripke structure K partitions the paths of K into fair and
unfair paths. The B¨uchi, Rabin, and Streett acceptance conditions for word automata
(for a survey on word automata see [Tho90]) can also be viewed as fairness conditions on
Kripke structures. For example, a path π of K is fair with respect to a B¨uchi condition
α ⊆W iff π visits states in α inﬁnitely often. In this paper we consider transition
fairness, deﬁned as follows:
– A path π is fair with respect to the transition fairness condition iff all the transitions
that are enabled along π inﬁnitely often are also taken along π inﬁnitely often.
Formally, a transition ⟨v, w⟩∈R is enabled in position i along π, if π[i] = v. It is
taken, if in addition π[i+ 1] = w. Thus, equivalently, a path π is fair with respect to
the transition fairness condition iff for all v ∈W, if v ∈inf(π) and R(v, w) then
π[i] = v and π[i + 1] = w for inﬁnitely many i’s.
A fair Kripke structure K = ⟨K, α⟩consists of a Kripke structure K and a fairness
condition α for K (note that in the case of transition fairness, there is no need to specify
a speciﬁc α, thus α is some ﬂag indicating the type of fairness). The semantics of LTL
and CTL is adjusted to fair Kripke structures by letting path quantiﬁcation range over
fair paths only. For example, an LTL formula ψ is fairly satisﬁed in K, denoted K |=F ψ,
if all the fair initial paths of K satisfy ψ. For CTL, we use K, w |=F ϕ to indicate that
a CTL formula ϕ is fairly satisﬁed in the state w of the fair Kripke structure K, and use
K |=F ϕ to indicate that ϕ is fairly satisﬁed in all the initial states of K. For details, see
[CGP99].
Note that the transition fairness condition is related to the successor fairness condi-
tion, where a path π is fair iff all the successors of a state in π that is visited inﬁnitely
often are also visited inﬁnitely often. That is, π is fair iff for all v ∈W, if v ∈inf(π)
and R(v, w) then w ∈inf(π). Successor fairness is a special case of the Streett fairness
condition, and, like transition fairness, is used in order to ignore paths that get stuck
in a MSCC that is not a bottom MSCC (for an application in the probabilistic setting
see [Var85]). Transition fairness is stronger than successor fairness in the sense that for
every Kripke structure K, if a path π of K is fair with respect to the transition fair-
ness condition, then π is also fair with respect to the successor fairness condition. The
opposite is not necessarily true, as π may satisfy the successor fairness condition and
not satisfy the transition fairness condition. However, it is not hard to see that given a
Kripke structure with a successor fairness condition one can obtain, by inserting a new
state in the middle of every transition, a corresponding Kripke structure for which each

200
B. Aminof, T. Ball, and O. Kupferman
transition-fair path induces a corresponding successor-fair path in the original structure.
The “stretching” effect the new states have on the paths can be easily overcome). Our
results are thus also valid for the successor fairness condition.
In the rest of this paper we study the model-checking problem and the problem
of ﬁnding dominators and postdominators for Kripke structures augmented with the
transition fairness condition. For simplicity, we will only use the terms “fair path” or
“fair Kripke structure”, without repeating the type of fairness.
2.3
Observations on Fair Paths
Recall that if a fair path π visits a state v inﬁnitely often, then it also visits all the
successors of v inﬁnitely often. Such a fair behavior cascades from every successor to its
own successors. As we formally state below, this guarantees that a fair path eventually
gets trapped in some bottom MSCC, where it traverses all the states of the MSCC
inﬁnitely often. Formally, we have the following:
Lemma 1. Let K = ⟨K, α⟩, with K = ⟨AP, W, R, W0, L⟩, be a fair Kripke structure.
If π is a fair path in K then there exists a bottom MSCC C in K, and an index i, such
that inf(π) = visit(πi) = C.
Lemma 2. Let K = ⟨K, α⟩, with K = ⟨AP, W, R, W0, L⟩, be a fair Kripke structure.
Every (possibly empty) ﬁnite path w0, w1, . . . , wk in K can be extended to an inﬁnite
fair path w0, w1, . . . , wk, . . .
3
Fair Model Checking
In this section we reduce fair model checking to non-fair CTL model checking, and
analyze the complexity of the algorithm that follows. We start with CTL, and then
proceed to fragments of LTL.
3.1
Fair CTL Model Checking
Our fair CTL model-checking algorithm is based on a function f that maps each CTL
formula ϕ to another CTL formula f(ϕ) such that for every fair Kripke structure K =
⟨K, α⟩and state w in it, we have that K, w satisﬁes ϕ fairly iff K, w satisﬁes f(ϕ)
non-fairly. The function f is independent of K and the size of f(ϕ) is linear in the size
of ϕ (recall that we assume a DAG representation of CTL formulas. Thus, a sub-formula
that appears more than once is represented by a single node, and is evaluated only once).
Formally, we have the following:
Theorem 1. There is a function f : CTL formulas →CTL formulas such that for every
CTL formula ϕ, the following hold.
(1) |f(ϕ)| = O(|ϕ|).
(2) For every fair Kripke structure K = ⟨K, α⟩, with K = ⟨AP, W, R, W0, L⟩, and
state w ∈W, we have K, w |=F ϕ iff K, w |= f(ϕ).

Reasoning About Systems with Transition Fairness
201
Proof: We deﬁne f by induction on the structure of ϕ as follows.
– f(true) = true and f(false) = false.
– f(p) = p for p ∈AP.
– f(¬ϕ1) = ¬f(ϕ1).
– f(ϕ1 ∨ϕ2) = f(ϕ1) ∨f(ϕ2).
– f(EXϕ1) = EXf(ϕ1).
– f(AXϕ1) = AXf(ϕ1).
– f(Eϕ1Uϕ2) = Ef(ϕ1)Uf(ϕ2).
– f(Aϕ1Uϕ2) = A(f(ϕ1) ∧EFf(ϕ2))Wf(ϕ2).
It is easy to see that |f(ϕ)| = O(|ϕ|). We prove Claim (2) in detail. The proof
proceeds by an induction on the structure of ϕ. The induction base, where ϕ = true,
ϕ = false, or ϕ = p, for p ∈AP is trivial. For the induction step, assume that Claim (2)
holds for ϕ1 and ϕ2. That is, for every fair Kripke structure K, and every state w ∈W,
we have that K, w |=F ϕ1 iff K, w |= f(ϕ1), and similarly for ϕ2.
The cases where ϕ is of the form ¬ϕ1, ϕ1 ∨ϕ2, EXϕ1, AXϕ1, or Eϕ1Uϕ2 are
relatively easy, and are described in [ABK04]. Intuitively, the cases EXϕ1, AXϕ1, and
Eϕ1Uϕ2 all follow from the fact that their truth value is established by a ﬁnite preﬁx of
a path which by Lemma 2 can always be extended to a fair path. Here we consider the
more interesting case, where ϕ = Aϕ1Uϕ2.
As an intuition, consider the special case where ϕ = AFp. Note that f(AFp) =
A(EFp)Wp. Thus, we have to prove that all the fair paths that start at some state w
eventually reach a state labeled p iff all (possibly unfair) paths that start at w either
eventually reach p or always visit states from which a state labeled p is reachable. The
‘if’ direction is true since, by Lemma 1, every fair path has a tail for which all reachable
states are actually visited. The ‘only if’ direction is true since, by Lemma 2, every state
is the initial state of some fair path.
Assume ﬁrst that K, w |=F Aϕ1Uϕ2. Consider a (possibly unfair) path π starting
at w. We show that either (case 1) there is k ≥0 such that π[k] |= f(ϕ2) and all
0 ≤i < k are such that π[i] |= f(ϕ1) ∧EFf(ϕ2), or (case 2) all i ≥0 are such that
π[i] |= f(ϕ1) ∧EFf(ϕ2). It follows that K, w |= A(f(ϕ1) ∧EFf(ϕ2))Wf(ϕ2).
We distinguish between two cases, which actually correspond to the two cases above.
If there is a state along π that fairly satisﬁes ϕ2, we prove that case 1 above holds: let
k ≥0 be the minimal index for which π[k] |=F ϕ2. By Lemma 2, the path π[0], . . . , π[k]
can be extended to a fair path. Since K, w |=F Aϕ1Uϕ2, our choice of k guarantees
that π[k] |=F ϕ2 and π[i] |=F ϕ1 for all 0 ≤i < k. By the induction hypothesis,
π[k] |= f(ϕ2) and π[i] |= f(ϕ1) for all 0 ≤i < k. Moreover, since π[k] |= f(ϕ2), then
for all 0 ≤i < k, we have that π[i] |= EFf(ϕ2). Thus, case 1 holds for π.
In the other case, that is, if no state along π fairly satisﬁes ϕ2, we prove that case
2 above holds. Consider an index i ≥0. By Lemma 2, the path π[0], . . . , π[i] can be
extended to a fair path πi. Since K, w |=F Aϕ1Uϕ2, there is an index k such that
πi[k] |=F ϕ2 and πi[j] |=F ϕ1 for all 0 ≤j < k. Since π[j] ̸|=F ϕ2 for all j ≤i,
it must be that k > i. By the induction hypothesis, πi[j] |= f(ϕ1) for all 0 ≤j < k.
Moreover, since πi[k] |= f(ϕ2), then for all 0 ≤j < k, we have that πi[j] |= EFf(ϕ2).
Recall that k > i. Thus, in particular, πi[i] = π[i] |= f(ϕ1) ∧EFf(ϕ2), and case 2
holds for π.

202
B. Aminof, T. Ball, and O. Kupferman
Assume now that K, w |= A(f(ϕ1) ∧EFf(ϕ2))Wf(ϕ2). Let π be a fair path that
starts at w. We ﬁrst prove that there must be an index k ≥0 such that K, π[k] |= f(ϕ2).
since π is fair, By Lemma 1, there is a bottom MSCC C ⊆K, and an index i, such that
visit(πi) = C. Assume by way of contradiction that no k as above exists. Then for all
j ≥0, we have that K, π[j] |= (f(ϕ1) ∧EFf(ϕ2)). Since C is at the bottom, all states
reachable from states in C are also in C. Hence, as π[i] ∈C and K, π[i] |= EFf(ϕ2),
there is a state v ∈C such that v |= f(ϕ2). Since, however, C = visit(πi), there must
be k ≥0 such that v = π[k], and we reach a contradiction. So, let k be the minimal index
for which K, π[k] |= f(ϕ2). Then, by assumption, K, π[i] |= f(ϕ1) for all 0 ≤i ≤k.
Thus, by the induction hypothesis, K, π |= ϕ1Uϕ2, and we are done.
For the sake of completeness, we state here the result of applying the function f on
abbreviated CTL operators.
– f(EFϕ1) = EFf(ϕ1).
– f(AFϕ1) = A(EFf(ϕ1))Wf(ϕ1).
– f(EGϕ1) = Ef(ϕ1)UAGf(ϕ1).
– f(AGϕ1) = AGf(ϕ1).
– f(Eϕ1Wϕ2) = Ef(ϕ1)U(f(ϕ2) ∨AGf(ϕ1)).
– f(Aϕ1Wϕ2) = Af(ϕ1)Wf(ϕ2).
Since f involves a linear blow-up and reduces fair CTL model checking to non-fair
CTL model checking, the improved complexity for fair CTL model checking follows
from the known complexity of the non-fair case [CES86,BCM+92]:
Corollary 1. The fair CTL model-checking problem K |= ϕ for K augmented with
transition fairness can be solved in time linear in |K| and |ϕ|, or using at most |K||ϕ|
symbolic steps.
Interestingly, the function f maps universal CTL (ACTL, for short) formulas (that
is, formulas that do not use the existential path quantiﬁer, and whose satisfaction is
preserved under simulation [GL94]) to CTL formulas that do use the existential path
quantiﬁer. As we now show, the use of the existential path quantiﬁer is essential. We
prove it already for the ACTL formula AFp.
Theorem 2. There is no ACTL formula ϕ such that for all fair Kripke structures K =
⟨K, α⟩, we have K |=F AFp iff K |= ϕ.
Proof: Consider the two Kripke structures K and K′ appearing in Figure 1 below. Note
that K′ is obtained from K by eliminating the state w2 and the transitions to and from
it. Since a path that consistently avoids w2 in K is not fair, K |=F AFp. On the other
hand, since the single path of K′ is fair and never reaches a state labeled p, we have
that K′ ̸|= AFp. Accordingly, the formula ϕ we seek should be such that K |= ϕ and
K′ ̸|= ϕ. Since, however, K′ is simulated by K, and satisfaction of ACTL formulas is
preserved under simulation [GL94], no such ϕ exists.
In Section 5 we discuss the theoretical aspects of Theorem 2, and its relation to the
open problem about the expressive power of the linear fragments of CTL and ACTL.

Reasoning About Systems with Transition Fairness
203
q
q
w0
w1
q
q
w0
w1
p
w2
K :
K′ :
Fig. 1. While K simulates K′, only K fairly satisﬁes AFp
3.2
Beyond CTL
The correctness of the function f follows from the observations on fair paths studied
in Section 2.3. In this section we use these observations in the context of LTL model
checking. We show that for many common LTL formulas, fair model checking can be
reduced to fair CTL model checking, which in turn can be reduced to non-fair CTL
model checking6. The LTL formulas we consider are those that specify acceptance by
B¨uchi, Rabin, and Streett automata. Formally, we have the following.
Theorem 3. Let l1, u1, l2, u2, . . . , lk, uk be atomic propositions, for some k ≥1. Con-
sider the following three forms of LTL formulas:
1. (B¨uchi) θ = GFl1.
2. (Rabin) θ = 
1≤i≤k(GFli ∧FGui).
3. (Streett) θ = 
1≤i≤k(GFui ∨FGli).
There is a partial mapping g : LTL formulas →CTL formulas such that for every LTL
formula θ of one of the three forms above, the following hold.
(1) |g(θ)| = O(|θ|).
(2) For every fair Kripke structure K = ⟨K, α⟩, with K = ⟨AP, W, R, W0, L⟩, and
every state w ∈W, there is a fair path π in K, starting at w, such that K, π |= θ iff
K, w |=F g(θ).
Proof: We deﬁne g as follows.
1. g(GFl1) = EGEFl1.
2. g(
1≤i≤k(GFli ∧FGui)) = EF(
1≤i≤k(AGEFli ∧AGui)).
3. g(
1≤i≤k(GFui ∨FGli)) = EF(
1≤i≤k(AGEFui ∨AGli)).
It is easy to see that |g(θ)| = O(|θ|). The proof of the correctness of g is given in
[ABK04].
One immediate application of Theorem 3 is fair LTL model checking of formulas
of the form ¬θ, for θ of one of the three forms above (note that Theorem 3 follows
the existential approach, where one looks for a path that violates the property). A more
6 We note that, unlike other reductions of LTL to CTL model checking [KV98b,BRS99], our
method here makes use of the fact that the LTL formulas should hold only in the fair paths of
the Kripke structure.

204
B. Aminof, T. Ball, and O. Kupferman
ambitious application is to use the function g in order to fairly model check all LTL
formulas: let ψ be an LTL formula. In the automata-theoretic approach to LTL model
checking [VW94], we check whether all the paths of a Kripke structure K satisfy ψ by
checking whether the product of K with an automaton A¬ψ that accepts all the words
that violate ψ does not contain a bad path — a path whose projection on the states of
A¬ψ is an accepting run of A¬ψ. Indeed, the projection of such a path on the states of
K is a path of K that is accepted by A¬ψ, and thus violates ψ. The search for a bad
path is reduced to checking whether there is a path in the product that satisﬁes an LTL
formula θ induced by the acceptance condition of A¬ψ. Thus, assuming A¬ψ is a B¨uchi,
Rabin, or Streett automaton, θ is of one of the forms handled in Theorem 3. When the
Kripke structure K is augmented with a fairness condition, ψ is violated iff the product
contains a path whose projection on the states of A¬ψ is an accepting run of A¬ψ, and
whose projection on the states of K is a fair path of K. A detection of such a path can
be done as described above by augmenting the product with a fairness condition. Then,
the path that satisﬁes θ should be a fair path. To conclude, fair LTL model checking can
be reduced to checking whether the product of K and A¬ψ has a fair path that satisﬁes
an LTL formula of a speciﬁc form.
Unfortunately, the fact that K is augmented with the transition fairness condition
does not imply that fair paths in the product correspond to fair paths in K, and vice versa.
Technically, the product of K with A¬ψ may have non-fair paths whose projection on
the states of K is a fair path of K. Below we show that the problem exists already
for deterministic B¨uchi automata, implying that determinization, or a restriction to the
B¨uchi acceptance condition do not solve this problem. (See [ABK04] for the proof.)
Theorem 4. There is a fair Kripke structure K = ⟨K, α⟩and a deterministic B¨uchi
automaton A with a set F of accepting states such that there exists a fair path in K that
is accepted by A, yet the product of K and A has no fair path that visits inﬁnitely many
states whose projection on the states of A is in F.
Reducing fair LTL model checking to fair CTL model checking, we are able to use
Corollary 1, and obtain similar complexity results for LTL:
Corollary 2. The fair LTL model-checking problem K |=F ¬θ for K augmented with
transition fairness and θ of one of the forms handled in Theorem 3 can be solved in time
linear in |K| and |θ|, or using at most |K||θ| symbolic steps. Moreover, if ψ is an LTL
formula and K |=F ψ iff the product of K with A¬ψ fairly satisﬁes ¬θ, then the LTL
model-checking problem K |=F ψ can be solved in time linear in |K| and A¬ψ, or using
at most |K||A¬ψ| symbolic steps.
We note that the automaton A¬ψ may be exponential in |ψ| [VW94]. Moreover,
sometimes we can achieve the desired property of the product having the transition fair-
ness condition by applying to A¬ψ transformations that blow-up its state space further.
Nevertheless, since K is typically much larger than ψ and the exponential blow up, as
well as additional blow ups, do rarely appear in practice, the technique still pays off, as
the algorithm that follows is linear in |K|, rather than quadratic in |K|, if one keeps the
fairness condition (recall that the traditional algorithm for fair LTL model checking is
quadratic in |K|).

Reasoning About Systems with Transition Fairness
205
4
Computation of Postdominators and Dominators
In this section we use the technique developed in Section 3 in order to describe an
efﬁcient and symbolic algorithm for calculating the dominators and post-dominators of
states in a Kripke structure augmented with transition fairness.
For a state w of a Kripke structure K, the set of postdominators of w, denoted
pd(w), is the set of states s such that all paths from w eventually reach s. Dually, the set
of dominators of w, denoted dom(w), is the set of states s such that all paths to w pass
through s. Let Krev be the Kripke structure derived from K by reversing the direction
of transitions. That is, Krev is identical to K, only that its transition relation Rrev is
such that for all states w and w′, we have that Rrev(w, w′) iff R(w′, w). It is not hard
hard to see that dom(w) is the set of states s such that all paths from w eventually reach
s in Krev. Thus, a state s is in pd(w) in K iff s is in dom(w) in Krev. We study here
the computation of postdominators. By the above, our results can be applied also for the
computation of dominators.
As discussed in Section 1, the calculation of pd(w) is not an easy problem. On the
other hand, it is not hard to calculate, given s, all the states w for which s ∈pd(w).
Indeed, w has to (fairly) satisfy AFs. Let pd−1(s) be the set of all states w such that
s is in pd(w). That is, pd−1(s) = {w : s ∈pd(w)}. The deﬁnition of pd−1 still
leaves open the problem of calculating pd effectively. In many applications, however,
the goal is to calculate all pairs ⟨s, w⟩such that s ∈pd(w). Then, the fact that we
consider pd−1 is not a disadvantage. Indeed, instead of calculating pd(w) for all w, we
can calculate pd−1(s) for all s). On the other hand, such an approach requires linearly
many calculations of pd−1 – one calculation for each s ∈W. So, even if calculation
of pd−1 is reduced to a single fair CTL model-checking query, and even when such a
query is reduced, as described in Section 3, to a non-fair model-checking query, and is
calculated symbolically, we have to apply it linearly many times. The whole procedure
is therefore not truly symbolic7.
We describe a truly symbolic algorithm for this task. Consider a Kripke structure
K = ⟨AP, W, R, W0, L⟩. Let PD = {⟨s, w⟩: s ∈pd(w)}, and let x1, . . . , xn be n
variables used for encoding the state space of K. We assume that K is given symbolically.
In particular, we are given an ROBDD fR over x1, . . . , .xn, x′
1, . . . , x′
n that describes
the transition relation R. We generate an ROBDD fpd over x1, . . . , .xn, x′
1, . . . , x′
n such
that fpd(x1, . . . , .xn, x′
1, . . . , x′
n) = true iff the states s and w encoded by x1, . . . , .xn
and x′
1, . . . , x′
n, respectively, are such that ⟨s, w⟩∈PD.
To explain our algorithm, we ﬁrst describe it for a Kripke structure K with no
fairness. Then, PD = {⟨s, w⟩: w |= AFs}. Consider the operator (on a set P ⊆
W × W) PairAX(P) = {⟨v, w⟩: for all successors u of w, we have⟨v, u⟩∈P}.
Thus, for each pair ⟨v, w⟩in P, the operator PairAX(P) applies the AX operator
(universal preimage) to w, leaving v unchanged. Note that PairAX can be implemented
symbolically: given an ROBDD for P and the ROBDD fR, the construction of an
ROBDD for PairAX(P) is similar to the construction of an ROBDD for AX(S),
given an ROBDD for a set S of states [BCM+92]. Now, let P0 = {⟨w, w⟩: w ∈W},
and Pi+1 = Pi ∪PairAX(Pi), for all i ≥0. Intuitively, Pi contains all pairs ⟨s, w⟩
7 For a similar challenge, in the context of coverage in model checking, see [CKV01].

206
B. Aminof, T. Ball, and O. Kupferman
such that all the paths from w reach s within at most i transitions. It follows that the
ﬁxed-point of the above sequence is the set PD. In other words, we can describe PD by
means of the ﬁxed-point expression µy.P0 ∨PairAX(y), and calculate it symbolically.
When K is augmented by a transition fairness condition, PD = {⟨s, w⟩: w |=F
AFs}. Equivalently, by Theorem 1, PD = {⟨s, w⟩: w |= A(EFs)Ws}. Recall that
Aϕ1Wϕ2 = ¬E(¬ϕ2)U(¬ϕ1∧¬ϕ2).Accordingly,A(EFs)Ws = ¬E(¬s)U(AG¬s).
Consider the operator PairEX(P) = {⟨v, w⟩: there is a successor u of w for
which⟨v, u⟩∈P}. Like PairAX, the operator PairEX is “the pair version” of the op-
erator EX, and it can be implemented symbolically. Finally, let P0 = {⟨w, s⟩: w ̸= s}.
Using P0, PairAX, and PairEX, we can describe the set PD by means of the (al-
ternation free) ﬁxed-point expression ¬µy.νz.(P0 ∧AXz) ∨(P0 ∧PairEX(y)), and
calculate it symbolically.
We note that, in the context of postdominators and dominators, K is often augmented
with a fairness condition that restricts attention to paths that visit some designated states.
In particular, in pd(w) we care for paths that start at w and eventually reach a halting or
error states, and in dom(w) we care for paths that start at some initial state and eventually
reach w. Our idea above applies also in these cases. Then, instead of using the technique
in Section 3, removal of fairness is easier. To see this, consider the problem of calculating
pd−1(s) in a Kripke structure in which the fairness condition restricts attention to paths
that eventually visit a state labeled end. Note that then, w |=F AFs iff w |= ϕ, for the
CTL⋆formula ϕ = A(Fend →Fs). As proved in [EH86], ϕ has an equivalent CTL
formula, and PD can be calculated using the operator PairAX.
5
Discussion
We studied reasoning about systems augmented with the transition fairness condition.
We showed that while fairness usually makes reasoning harder, this is not the case for
transition fairness.
The key to our results is the ability to translate a speciﬁcation ϕ to a CTL formula
ϕ′ of size linear in the size of ϕ such that ϕ is satisﬁed fairly iff ϕ′ is satisﬁed non-fairly.
The formula ϕ′ may contain the existential path quantiﬁer E, even if ϕ imposes only
universal requirements (that is, ϕ is in LTL or ACTL). For example, if ϕ = AFp, then
ϕ′ = A(EFp)Wp, and we showed that the use of the existential path quantiﬁer in ϕ′ is
required – no ϕ′ in ACTL can do the job. These observations are of interest with respect
to the relative expressive power of the linear fragments of CTL and ACTL. Consider an
LTL formula ψ. Assume that ψ has an equivalent CTL formula. Can we then guarantee
that ψ also has an equivalent ACTL formula? This seems very likely, as ψ imposes
only linear, and hence universal, requirements. The question, however, is open, and the
characterization in [Mai00], of LTL ∩ACTL, may not apply for LTL ∩CTL. The fact
that the existential path quantiﬁer is essential in the domain of the function f implies
that, in the context of transition fairness, the answer to the question is negative: there
are formulas in LTL ∩ACTL that have a non-fair equivalence in CTL, but no non-fair
equivalence in ACTL.
Another issue that is still open is extending the technique described in Section 3.2
to full LTL. As explained there, a straightforward application of the automata-theoretic

Reasoning About Systems with Transition Fairness
207
approach does not work, as the transition fairness condition of the Kripke structure
induces a different type of fairness condition in the product. We are searching for prop-
erties of the speciﬁcation automaton, possibly properties relating the Kripke structure
and the speciﬁcation automaton, with which the technique can be applied in all LTL
model-checking instances. We note that even when the transition to an automaton with
such a property involves an additional exponential blow-up, the technique pays off, as
it reduces the LTL model-checking task to an evaluation of a single ﬁxed-point on the
product, rather than a nested ﬁxed-point, in the case a reduction to CTL model checking
is impossible.
References
ABK04.
B. Aminof, T. Ball, and O. Kupferman. Reasoning about systems with transition
fairness. Technical Report MSR-TR-2004-89, September 2004.
BCM+92. J.R. Burch, E.M. Clarke, K.L. McMillan, D.L. Dill, and L.J. Hwang. Symbolic model
checking: 1020 states and beyond. I&C, 98(2):142–170, June 1992.
BGS00.
R. Bloem, H.N. Gabow, and F. Somenzi. An algorithm for strongly connected com-
ponent analysis in n log n symbolic steps. In Formal Methods in Computer Aided
Design, LNCS 1954, pages 37–54, 2000.
BKAW98. A.L. Buchsbaum, H. Kaplan, A.Rogers, and J.R. Westbrook. A new, simpler linear-
time dominators algorithm. ACM TOPLAS., 20(6):1265–1296, 1998.
BRS99.
R. Bloem, K. Ravi, and F. Somenzi. Efﬁcient decision procedures for model checking
of linear time logic properties. In Proc. 11th CAV, LNCS 1633, pages 222-235, 1999.
CE81.
E.M. Clarke and E.A. Emerson. Design and synthesis of synchronization skeletons
using branching time temporal logic. In Proc. Workshop on Logic of Programs, LNCS
131, pages 52–71, 1981.
CES86.
E.M. Clarke, E.A. Emerson, and A.P. Sistla. Automatic veriﬁcation of ﬁnite-state
concurrent systems using temporal logic speciﬁcations. ACM Transactions on Pro-
gramming Languages and Systems, 8(2):244–263, January 1986.
C+91.
Ron Cytron, Jeanne Ferrante, Barry K. Rosen, Mark N. Wegman, and F. Kenneth
Zadeck. Efﬁciently computing static single assignment form and the control depen-
dence graph. ACM Trans. Program. Lang. Syst., 13(4):451–490, 1991.
CGP99.
E.M. Clarke, O. Grumberg, and D. Peled. Model Checking. MIT Press, 1999.
CKV01.
H. Chockler, O. Kupferman, and M.Y. Vardi. Coverage metrics for temporal logic
model checking. In 7th TACAS, LNCS 2031, pages 528 – 542, 2001.
EH86.
E.A. Emerson and J.Y. Halpern. ‘Sometimes’ and ‘not never’ revisited: on branching
versus linear time. Journal of the ACM, 33(1):151–178, 1986.
EL87.
E.A. Emerson and C.-L. Lei. Modalities for model checking: branching time logic
strikes back. Science of Computer Programming, 8:275–306, 1987.
Eme90.
E.A. Emerson. Temporal and modal logic. In J. Van Leeuwen, editor, Handbook of
Theoretical Computer Science, volume B, chapter 16, pages 997–1072. Elsevier, MIT
Press, 1990.
FOW87.
J. Ferrante, K. Ottenstein, and J. Warren. The program dependence graph and its use
in optimization. ACM Trans. Program. Lang. Syst., 9(3):319–349, 1987.
Fra86.
N. Francez. Fairness. Springer-Verlag, New York, 1986.
GL94.
O. Grumberg and D.E. Long. Model checking and modular veriﬁcation. ACM Trans.
on Programming Languages and Systems, 16(3):843–871, 1994.

208
B. Aminof, T. Ball, and O. Kupferman
GPP03.
R. Gentilini, C. Piazza, and A. Policriti. Computing strongly connected components
in a linear number of symbolic steps. In 14th ACM-SIAM Symposium on Discrete
Algorithms, pages 573–582, Baltimore, Maryland, 2003.
Hoa85.
C.A.R. Hoare. Communicating Sequential Processes. Prentice-Hall, 1985.
HT96.
M. Henzinger and J.A. Telle. Faster algorithms for the nonemptiness of Streett au-
tomata and for communication protocol pruning. In Proc. 5th Scandinavian Workshop
on Algorithm Theory, LNCS 1097, pages 10–20, 1996.
KG96.
O. Kupferman and O. Grumberg. Buy one, get one free!!! Journal of Logic and
Computation, 6(4):523–539, 1996.
KPR98.
Y. Kesten, A. Pnueli, and L. Raviv. Algorithmic veriﬁcation of linear temporal logic
speciﬁcations. In Proc. 25th ICALP, LNCS 1443, pages 1–16, 1998.
KPSZ02.
Y. Kesten, A. Pnueli, E. Shahar, and L. Zuck. Network invariant in action. In Proc.
13th CONCUR, LNCS 2421, pages 101–115, 2002.
KV98a.
O. Kupferman and M.Y. Vardi. Veriﬁcation of fair transition systems. Chicago Journal
of Theoretical Computer Science, 1998(2), March 1998.
KV98b.
O. Kupferman and M.Y. Vardi. Relating linear and branching model checking. In
Proc PROCOMET, pages 304 - 326, Chapman & Hall, 1998.
LH00.
Timo Latvala and Keijo Heljanko. Coping with strong fairness. Fundamenta Infor-
maticae, 43(1–4):175–193, 2000.
LPS81.
D. Lehman, A. Pnueli, and J. Stavi. Impartiality, justice, and fairness – the ethics of
concurrent termination. In Proc. 8th ICALP, LNCS 115, pages 264–277, 1981.
LT79.
T. Lengauer and R.E. Tarjan. A fast algorithm for ﬁnding dominators in a ﬂowgraph.
ACM Trans. Prog. Lang. and Sys., 1(1):121–141, 1979.
Mai00.
M. Maidl.
Using Model Checking for System Veriﬁcation.
PhD thesis, Ludwig-
Maximilians-Universit¨at M¨unchen, 2000.
MP92.
Z. Manna and A. Pnueli. The Temporal Logic of Reactive and Concurrent Systems:
Speciﬁcation. Springer-Verlag, Berlin, January 1992.
QS81.
J.P. Queille and J. Sifakis. Speciﬁcation and veriﬁcation of concurrent systems in
Cesar. In Proc. 5th International Symp. on Programming, LNCS 137, pages 337–351,
1981.
QS83.
J.P. Queille and J. Sifakis. Fairness and related properties in transition systems - A
temporal logic to deal with fairness. In Acta Informatica 19:195-220, 1983.
Tho90.
W.Thomas. Automataoninﬁniteobjects. HandbookofTheoreticalComputerScience,
pages 165–191, 1990.
Var85.
M.Y. Vardi. Automatic veriﬁcation of probabilistic concurrent ﬁnite-state programs.
In Proc. 26th FOCS, pages 327–338, October 1985.
VW94.
M.Y. Vardi and P. Wolper. Reasoning about inﬁnite computations. Information and
Computation, 115(1):1–37, November 1994.

Entanglement – A Measure for the Complexity
of Directed Graphs with Applications
to Logic and Games⋆
Dietmar Berwanger and Erich Gr¨adel
Mathematische Grundlagen der Informatik, RWTH Aachen
Abstract. We propose a new parameter for the complexity of ﬁnite
directed graphs which measures to what extent the cycles of the graph
are intertwined. This measure, called entanglement, is deﬁned by way of
a game that is somewhat similar in spirit to the robber and cops games
used to describe tree width, directed tree width, and hypertree width.
Nevertheless, on many classes of graphs, there are signiﬁcant diﬀerences
between entanglement and the various incarnations of tree width.
Entanglement is intimately connected to the computational and descrip-
tive complexity of the modal µ-calculus. On the one hand, the number of
ﬁxed point variables needed to describe a ﬁnite graph up to bisimulation
is captured by its entanglement. This plays a crucial role in the proof
that the variable hierarchy of the µ-calculus is strict.
In addition to this, we prove that parity games of bounded entangle-
ment can be solved in polynomial time. Speciﬁcally, we establish that
the complexity of solving a parity game can be parametrised in terms of
the minimal entanglement of a subgame induced by a winning strategy.
1
Entanglement: How to Catch a Thief
Let G = (V, E) be a ﬁnite directed graph. The entanglement of G, denoted
ent(G), measures to what extent the cycles of G are entangled. We deﬁne the
entanglement by way of a game, played by a thief against k detectives on G
according to the following rules. Initially the thief selects an arbitrary position
v0 of G and the detectives are outside the graph. In any move the detectives
may either stay where they are, or place one of them on the current position v
of the thief. The thief, in turn, has to move to a successor w ∈vE that is not
occupied by a detective. If no such position exists, the thief is caught and the
detectives have won. Note that the thief sees the move of the detectives before
she decides on her own move, and that she has to leave her current position no
matter whether the detectives stay where they are or not. The entanglement of G
is the minimal number k ∈N such that k detectives have a strategy to catch the
thief on G.
⋆This research has been partially supported by the European Community Research
Training Network “Games and Automata for Synthesis and Validation” (games)
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 209–223, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

210
D. Berwanger and E. Gr¨adel
The entanglement is an interesting measure on directed graphs. To deal with
undirected graphs, we view undirected edges {u, v} as pairs (u, v) and (v, u) of
directed edges. In the following a graph is always meant to be directed.
To get a feeling for this measure we collect a few simple observations con-
cerning the entanglement of certain familiar graphs. The proofs are simple and
left to the reader.
Proposition 1. Let G be any ﬁnite directed graph.
(1) ent(G) = 0 if, and only if, G is acyclic.
(2) If G is the graph of a unary function, then ent(G) = 1.
(3) If G an undirected tree, then ent(G) ≤2.
(4) If G is the fully connected directed graph with n nodes, then ent(G) = n.
Let Cn denote the directed cycle with n nodes. Given two graphs G = (V, E)
and G′ = (V ′, E′) their asynchronous product is the graph G × G′ = (V × V ′, F)
where F = {(uu′, vv′) : [(u, v) ∈E ∧u′ = v′] ∨[u = v ∧(u′v′) ∈E′]}.
Note, that Tmn := Cm × Cn is the (m × n)-torus or, to put it diﬀerently, the
graph obtained from the directed (m + 1) × (n + 1)-grid by identifying the left
and right border and the upper and lower border.
Proposition 2. (1) For every n, ent(Tnn) = n.
(2) For every m ̸= n, ent(Tmn) = min(m, n) + 1.
Proof. On Tnn, n detectives can catch the thief by placing themselves on a
diagonal, thus blocking every row and every column of the torus. On the other
side, it is obvious that the thief can escape against n −1 detectives.
On Tmn with m < n, m detectives are needed to block every row, and an
additional detective forces the thief to leave any row after at most n moves, so
that she ﬁnally must run into a detective. Again, it is obvious that the thief
escapes if there are less than m + 1 detectives.
⊓⊔
The following proposition characterises the graphs with entanglement one.
Proposition 3. The entanglement of a directed graph is one, if and only if, the
graph is not acyclic, and in every strongly connected component, there is a node
whose removal makes the component acyclic.
Proof. On any graph with this property, one detective catches the thief by plac-
ing himself on the critical node in the current strongly connected component
when the thief passes there. The thief will have to return to this node or leave
the current component. Eventually she will be caught in a terminal component.
Conversely if there is a strongly connected component without such a critical
node, then the thief may always proceed from her current position towards an
unguarded cycle and thus escape forever.
⊓⊔
Corollary 1. For k = 0 and k = 1, the problem whether a given graph has
entanglement k is Nlogspace-complete.

Entanglement – A Measure for the Complexity of Directed Graphs
211
To compute upper bounds on the entanglement of certain interesting graphs,
we can use the following suﬃcient criterion for the existence of a winning strategy
for k detectives. For any k ∈N, let [k] := {0, . . . , k −1}.
Lemma 1. Let G = (V, E) be a ﬁnite directed graph such that, for some k ∈N,
there exists a partial labelling i : V →[k] under which every strongly connected
subgraph C ⊆G contains a vertex v whose label is unique in C, that is, i(v) ̸= i(w)
for all w ∈C. Then ent(G) ≤k.
Proof. We may interpret the labelling i as a memoryless strategy for the detec-
tives, indicating at every position v occurring in a play, that detective i(v) shall
be posted there, or that no detective shall move if i(v) is undeﬁned. Towards
a contradiction, suppose that although the detectives move according to strat-
egy i, the thief can escape, that is, she succeeds to form an inﬁnite path without
meeting any detective. Let C be the set of positions visited inﬁnitely often by
this path. Clearly, C induces in G a strongly connected subgraph. Let v ∈C be a
node whose label i(v) is unique in C. According to the strategy described by i,
detective i(v) remains at v once the play has stabilised in C. But since the thief
visits every position in C inﬁnitely often, she is caught at v.
⊓⊔
Proposition 4. For every n, the undirected (n × n)-grid has entanglement at
most 3n.
Proof. Consider the labelling i : [n] × [n] →[3n] obtained by ﬁrst assigning
the values 0, . . . , n to the horizontal median of the grid, i.e., i(⌊n
2 ⌋, j) := j for
all j ∈[n]. For the two
n
2 × n grids obtained when removing the positions
already labelled, we proceed independently and assign the values n, . . . , n+ n
2 to
their vertical medians, and so on, in step k applying the procedure to the still
unlabelled domain consisting of 2k many
n
2k × n
2k disconnected grids. It is easy to
verify that the labelling obtained this way satisﬁes the criterion of Lemma 1.
⊓⊔
2
Entanglement Versus Tree Width
The deﬁnition of entanglement is reminiscent of robber and cops games intro-
duced by Seymour and Thomas in [10] for characterising tree width, and John-
son, Robertson, Seymour, and Thomas [6] for directed tree width. However,
entanglement is a quite diﬀerent, and for some purposes more accurate, measure
than tree width and directed tree width.
This becomes apparent on trees with back-edges which also play an important
role in our analysis of the variable hierarchy of the modal µ-calculus. It is easy to
see that the directed tree width of any tree with back-edges is one. However, we
will see that the entanglement of trees with back-edges can be arbitrarily large.
We now discuss the relationship between (undirected) tree width and entan-
glement. First, we observe that acyclic graphs (that have entanglement 0) can
of course have arbitrary tree width. On the other hand we prove that the entan-
glement of a graph can be bounded by its tree width times the logarithm of its
size.

212
D. Berwanger and E. Gr¨adel
Proposition 5. For any ﬁnite undirected graph G of tree width k, we have that
ent(G) ≤(k + 1) · log |G|.
Proof. By deﬁnition, every graph G = (V, E) of tree width k can be decomposed
as a tree T labelled with subsets of at most k + 1 elements of V , called blocks,
such that (1) every edge {u, v} ∈E is included in some block and (2) for any
element v ∈V the set of blocks containing v is connected.
In every subtree S of such a decomposition tree, there exists a node s, we may
call it the centre of S, which balances S in the sense that the subtree rooted at s
and its complement carry almost the same number of vertices (diﬀerences up to k
are admissible). Consider now the following memoryless detective strategy. First,
all vertices in the centre s of the decomposition tree receive indices 0, . . . , k. Then,
we repeat the process independently for the two subtrees (i.e., the one rooted in s
and its complement) and assign to the vertices in their respective centres indices
from k+1, . . . , 2k+2. The process ends when all vertices of G are labelled. In this
way, at most (k + 1) log |V | detective indices are assigned. Since the blocks of a
tree decomposition separate the graph, every strongly connected subgraph of G
will contain at least one unique label. This shows that the constructed labelling
indeed represents a memoryless strategy for at most (k+1) log |V | detectives.
⊓⊔
However, bounded tree width does not imply bounded entanglement.
Proposition 6. There exist graphs with tree width two that have arbitrarily
large entanglement.
Proof. Let T ↓
k be the full binary tree of depth k with edges oriented downwards,
and let T ↑
k be the same tree with edges oriented upwards. Every node v↓∈T ↓
k
has a double v↑∈T ↑
k , and vice versa. The graph G(2, k) is constructed by taking
the union T ↓
k ∪T ↑
k , adding edges from each leaf to its double (in both directions),
and adding the edges (u↑, v↓) for each edge (u↑, v↑) of T ↑
k . It is easy to see that
G(2, k) has tree width 2.
We claim that ent(G(2, k)) > k. To prove this we describe a strategy by
which the thief escapes against k detectives. We call a path in G(2, k) free if all
nodes on the path and all their doubles are unguarded by the detectives. We say
that a node is blocked if both the node and its double are guarded. The thief
moves according to the following strategy: at a leaf w↑, she selects an ancestor
u↓of w↓from which there is a free path to a leaf v↓. She goes to v↓by moving
upwards through T ↑
k , stepping over to u↓and moving downwards through T ↓
k .
Finally she steps over to v↑.
With this strategy, the thief is never below a blocked node. A leaf has (in-
cluding itself) k + 1 ancestors in T ↓
k , so there is always an ancestor with a free
path to a leaf. Thus, the thief can maintain this strategy and escape forever.
⊓⊔
3
Trees with Back-Edges and Partial Unravellings
Let T = (V, E) be a directed tree. We write ⪯E for the associated partial order
on T . Note that ⪯E is just the reﬂexive transitive closure of E.

Entanglement – A Measure for the Complexity of Directed Graphs
213
Deﬁnition 1. A directed graph T = (V, F) is a tree with back-edges if there is
a partition F = E ∪B of the edges into tree-edges and back-edges such that
(V, E) is indeed a directed tree, and whenever (u, v) ∈B, then v ⪯E u.
The following observation shows that, up to the choice of the root, the de-
composition into tree-edges and back-edges is unique.
Lemma 2. Let T = (V, F) be a tree with back-edges and v ∈V . Then there
exists at most one decomposition F = E ∪B into tree-edges and back-edges such
that (V, E) is a tree with root v.
Deﬁnition 2. Let T = (V, F) be a tree with back-edges, with decomposition
F = E ∪B into tree-edges and back-edges. The feedback of a node v of T is the
number of ancestors of v that are reachable by a back-edge from a descendant
of v. The feedback of T , denoted fb(T) is the maximal feedback of nodes on G.
More formally,
fb(T) = max
v∈V |{u ∈V : ∃w(u ⪯E v ⪯E w ∧(w, u) ∈B)}|.
We call a back edge (w, u), and likewise its target u, active at a node v in T , if
u ⪯E v ⪯E w.
Note that the feedback of T may depend on how the edges are decomposed
into tree-edges and back-edges, i.e. on the choice of the root. Consider, for in-
stance the following graph C+
3 (the cycle C3 with an additional self-loop on one
of its nodes). Clearly, for every choice of the root, C+
3 is a tree with two back-
edges. If the node with the self-loop is taken as the root, then the feedback is 1,
otherwise it is 2.
Lemma 3. Let T = (V, E, B) be a tree with back-edges of feedback k. Then there
exists a partial labelling i : V 
→{0, . . . , k −1} assigning to every target u of a
back edge an index i(u) in such a way that no two nodes u, u′ that are active at
the same node v have the same index.
Proof. The values of this labelling are set while traversing the tree in breadth-
ﬁrst order. Notice that every node u with an incoming back-edge is active at
itself. As T has feedback k, there can be at most k −1 other nodes active at u.
All of these are ancestors of u, hence their index is already deﬁned. There is
at least one index which we can assign to u so that no conﬂict with the other
currently active nodes arises.
Lemma 4. The entanglement of a tree with back-edges is at most its feedback:
ent(T ) ≤fb(T ).
Proof. Suppose that fb(T ) = k. By Lemma 3 there is a labelling i of the targets
of the back-edges in T by numbers 0, . . . , k −1 assigning diﬀerent values to any
two nodes u, u′ that are active at the same node v. This labelling induces the
following strategy for the k detectives: at every node v reached by the thief, send

214
D. Berwanger and E. Gr¨adel
detective number i(v) to that position or, if the value is undeﬁned, do nothing.
By induction over the stages of the play, we can now show that this strategy
maintains the following invariant: at every node v occurring in a play on T ,
all active nodes u ̸= v are occupied and, if the current node is itself active, a
detective is on the way. To see this, let us trace the evolution of the set Z ⊆T
of nodes occupied by a detective. In the beginning of the play, Z is empty. A
node v can be included into Z if it is visited by the thief and active with regard
to itself. At this point, our strategy appoints detective i(v) to move to v. Since,
by construction of the labelling, the designated detective i(v) must come from
a currently inactive position and, hence, all currently active positions except v
remain in Z. But if every node which becomes active is added to Z and no active
node is ever given up, the thief can never move along a back edge, so that after
a ﬁnite number of steps she reaches a leaf of the tree and loses. But this means
that we have a winning strategy for k detectives, hence ent(T ) ≤k.
⊓⊔
Note however, that the entanglement of a tree with back-edges can be much
smaller than its feedback. A simple example are paths with back-edges: let Pn =
({0, . . . , n −1}, En, Bn) be the path with n nodes and all possible back-edges,
i.e., En = {(i, i+1) : i < n−1} and Bn = {(i, j) : i ≥j}. Obviously, fb(Pn) = n,
but two detectives suﬃce to catch the thief on Pn.
It is well-known that every graph G can be unravelled from any node v to a
tree TG,v whose nodes are the paths in G from v. Clearly TG,v is inﬁnite unless G
is ﬁnite and no cycle in G is reachable from v. A ﬁnite unravelling of a (ﬁnite)
graph G is deﬁned in a similar way, but rather than an inﬁnite tree, it produces a
ﬁnite tree with back-edges. To construct a ﬁnite unravelling we proceed as in the
usual unravelling process with the following modiﬁcation: whenever we have a
path v0v1 . . . vn in G with corresponding node v = v0v1 . . . vn in the unravelling,
and a successor w of vn that coincides with vi (for any i ≤n), then we may,
instead of creating the new node vw (with a tree-edge from v to vw) put a back-
edge from v to its ancestor v0 . . . vi. Clearly this process is nondeterministic. In
this way, any ﬁnite graph can be unravelled, in many diﬀerent ways, to a ﬁnite
tree with back-edges.
Observe that diﬀerent ﬁnite unravellings of a graph may have diﬀerent feed-
back and diﬀerent entanglement. Clearly the entanglement of a graph is bounded
by the entanglement of its ﬁnite unravellings. Indeed a winning strategy for k de-
tectives on a ﬁnite unravelling of G immediately translates to a winning strategy
on G.
Proposition 7. The entanglement of a graph is the minimal feedback (and the
minimal entanglement) of its ﬁnite unravellings:
ent(G) = min{fb(T ) : T is a ﬁnite unravelling of G}
= min{ent(T ) : T is a ﬁnite unravelling of G}.
Proof. For any ﬁnite unravelling T of a graph G, we have ent(G) ≤ent(T ) ≤
fb(T ). It remains to show that for any graph G there exists some ﬁnite unravel-
ling T with fb(T ) ≤ent(G).

Entanglement – A Measure for the Complexity of Directed Graphs
215
To prove this, we view winning strategies for the detectives as descriptions of
ﬁnite unravellings. A strategy for k detectives tells us, for any ﬁnite path πv of
the thief whether a detective should be posted at the current node v, and if so,
which one. Such a strategy can be represented by a partial function g mapping
ﬁnite paths in G to {0, . . . , k −1}. On the other hand, during the process of
unravelling a graph to a (ﬁnite) tree with back edges, we need to decide, for
every successor v of the current node, whether to create a new copy of v or
to return to a previously visited one, if any is available. To put this notion
on a formal ground, we deﬁne an unravelling function for a rooted graph G, v0
as a partial function ρ between ﬁnite paths from v0 through G, mapping any
path v0, . . . , vr−1, vr in its domain to a strict preﬁx v0, v1, · · · , vj−1 such that
vj−1 = vr. Such a function gives rise to an unravelling of G in the following way:
we start at the root and follow ﬁnite paths through G. Whenever the current
path π can be prolonged by a position v and the value of ρ at πv is undeﬁned, a
fresh copy of v corresponding to πw is created as a successor of π. In particular,
this always happens if v was not yet visited. Otherwise, if ρ(π v) is deﬁned, then
the current path π is bent back to its preﬁx ρ(π) which also corresponds to
a copy of v. Formally, the unravelling of G driven by ρ is the tree with back
edges T deﬁned as follows:
– the domain of T is the smallest set T which contains v0 and for each path
π ∈T, it also contains all prolongations πv in G at which ρ is undeﬁned;
– the tree-edge partition is
ET := { (v0, . . . , vr−1, v0, . . . , vr−1, vr) ∈T × T | (vr−1, vr) ∈EG };
– for all paths π := v0, . . . , vr−1 ∈T where ρ(πv) is deﬁned, the back-relation
BT contains the pair (π, ρ(πv)) if (vr−1, v) ∈EG.
We are now ready to prove that every winning strategy g for the k detectives
on G, v0 corresponds to an unravelling function ρ for G, v0 that controls a ﬁnite
unravelling with feedback k.
Note that the strategy g gives rise to a k-tuple (g0, . . . , gk−1) of functions
mapping every initial segment π of a possible play according to g to a k-tuple
( g0(π), . . . , gk−1(π) ) where each gi(π) is a preﬁx of π recording the state of the
play (i.e., the current path of the thief) at the last move of detective i.
Now, for every path π and possible prolongation by v, we check whether,
after playing π, there is any detective posted at v. If this is the case, i.e, when,
for some i, the end node of gi(π) is v, we set ρ(π v) := πi. Otherwise we leave the
value of ρ undeﬁned at π, v. It is not hard to check that, if g is a winning strategy
for the detectives, the associated unravelling is ﬁnite and has feedback k.
⊓⊔
4
Descriptive Complexity
The modal µ-calculus Lµ introduced by Kozen [8] is a highly expressive formal-
ism which extends basic modal logic with monadic variables and binds them to
extremal ﬁxed points of deﬁnable operators.

216
D. Berwanger and E. Gr¨adel
Syntax. For a set act of actions, a set prop of atomic propositions, and a set
var of monadic variables, the formulae of Lµ are deﬁned by the grammar
ϕ ::= false | true | p | ¬p | X | ϕ ∨ϕ | ϕ ∧ϕ | ⟨a⟩ϕ | [a]ϕ | µX.ϕ | νX.ϕ
where p ∈prop, a ∈act, and X ∈var. An Lµ-formula in which no universal
modality [a]ϕ occurs is called existential.
The number of variables occurring in a formula provides a relevant measure
of its conceptual complexity. For any k ∈N, the k-variable fragment Lµ[k] of the
µ-calculus is the set of formulae ψ ∈Lµ that contain at most k distinct variables.
Semantics.
Formulae of Lµ are interpreted on transition systems, or Kripke
structures. Formally, a transition system K =

V, (Ea)a∈act, (Vp)p∈prop

is a
coloured graph with edges labelled by action and vertices labelled by atomic
propositions. Given a sentence ψ and a structure K with state v, we write K, v |=
ψ to denote that ψ holds in K at state v. The set of states v ∈K such that
K, v |= ψ is denoted by [[ψ]]K.
Here, we only deﬁne [[ψ]]K for ﬁxed-point formulae ψ. Towards this, note that
a formula ψ(X) with a monadic variable X deﬁnes on every transition structure
K (providing interpretations for all free variables other than X occurring in
ψ) an operator ψK : P(K) →P(K) assigning to every set X ⊆K the set
ψK(X) := [[ψ]]K,X = {v ∈K : (K, X), v |= ψ}. As X occurs only positively
in ψ, the operator ψK is monotone for every K, and therefore, by a well-known
theorem due to Knaster and Tarski, has a least ﬁxed point lfp(ψK) and a greatest
ﬁxed point gfp(ψK). Now we put
[[µX.ψ]]K := lfp(ψK) and [[νX.ψ]]K := gfp(ψK).
As a modal logic, the µ-calculus distinguishes between transitions structures
only up to behavioural equivalence, captured by the notion of bisimulation.
Deﬁnition 3. A bisimulation between two transition structures K and K′ is
a simulation Z from K to K′ so that the inverse relation Z−1 is a simulation
from K′ to K. Two transition structures K, u and K′, u′ are bisimilar, denoted
K, u ∼K′, u′, if there is a bisimulation Z between them, with (u, u′) ∈Z.
An important model-theoretic feature of modal logics is the tree model prop-
erty meaning that every satisﬁable formula is satisﬁable in a tree. This is a
straightforward consequence of bisimulation invariance, since K, u is bisimilar to
its inﬁnite unravelling, i.e., a tree whose nodes correspond to the ﬁnite paths
in K, u. Every such path π inherits the atomic propositions of its last node v;
for every node w reachable from v in K via an a transition, π is connected to
its prolongation by w via an a-transition. Notice that in terms of our notion of
unravelling deﬁned in the proof of Proposition 7, the inﬁnite unravelling of a
system is just the unravelling driven by a function deﬁned nowhere.
The entanglement of a transition system K =

V, (Ea)a∈act, (Vp)p∈prop

is
the entanglement of the underlying graph (V, E) where E = 
a∈act Ea. We now
show that every transition structure of entanglement k can be described, up to
bisimulation, in the µ-calculus using only k ﬁxed-point variables.

Entanglement – A Measure for the Complexity of Directed Graphs
217
Proposition 8.
Let K be a ﬁnite transition system with ent(K) = k. For any
node v of K, there is a formula ψv ∈Lµ[k] such that
K′, v′ |= ψv ⇔K′, v′ ∼K, v.
Proof. According to Proposition 7, the system K can be unravelled from any
node v0 to a ﬁnite tree T with back-edges, with root v0 and feedback k. Clearly
T , v0 ∼K, v0. Hence, it is suﬃcient to prove the proposition for T , v0. For every
action a ∈act, the transitions in T are partitioned into tree-edges and back-
edges Ea ·∪Ba.
Let i : T 
→{0, . . . , k −1} be the partial labelling of T deﬁned in Lemma 3.
At hand with this labelling, we construct a sequence of formulae (ψv)v∈T over
ﬁxed-point variables X0, . . . , Xk−1 while traversing the nodes of T in reverse
breadth-ﬁrst order.
The atomic type of any node v is described by the formula
αv :=

p∈prop
v∈Vp
p ∧

p∈prop
v̸∈Vp
¬p.
To describe the relationship of v with its successors, let
ϕv := αv ∧

a∈act


(v,w)∈Ea
⟨a⟩ψw ∧

(v,w)∈Ba
⟨a⟩Xi(w)
∧[a]


(v,w)∈Ea
ψw ∨

(v,w)∈Ba
Xi(w)
 
.
If v has an incoming back-edge, we set ψv := νXi(v) . ϕv, if this is not the case
we set ψv := ϕv. Note that since we proceed from the leaves of T to the root,
this process is well-deﬁned, and that in ψv the variables Xi(u) occur free, for any
node u ̸= v that is active at v. In particular the formula ψv0, corresponding to
the root of T , is closed.
It remains to prove that K′, v′ |= ψv0 ⇔K′, v′ ∼T , v0. We ﬁrst show that
T , v0 |= ψv0, and hence K′, v′ |= ψv0 for any K′, v′ ∼T , v0. To see this we prove
that Veriﬁer has a winning strategy for the associated model checking game.
Note that, since ψv0 has only greatest ﬁxed points, any inﬁnite play of the
model checking game is won by Veriﬁer. It thus suﬃces to show that from any
position of form (v, ϕv), Veriﬁer has a strategy to make sure that the play pro-
ceeds to a next position of form (w, ϕw), unless Falsiﬁer moves to position (v, αv)
and then loses in the next move. But by the construction of the formula, it is
obvious that Veriﬁer can play so that any position at which she has to move has
one of the following three types:
(1) (v, ⟨a⟩ψw), where (v, w) ∈Ea. In this case, Veriﬁer moves to position (w, ψw).
(2) (v, ⟨a⟩Xi(w)), where (v, w) ∈Ba. In this case Veriﬁer moves to (w, Xi(w)).
(3) (w, 
(v,w)∈Ea ψw ∨
(v,w)∈Ba Xi(w)) where w ∈vEa∪vBa. In this case, Veri-
ﬁer selects the appropriate disjunct and moves to either (w, ψw) or (w, Xi(w)).

218
D. Berwanger and E. Gr¨adel
In all cases the play will proceed to (w, ϕw). Hence, Falsiﬁer can force a play to
be ﬁnite only by moving to a position (v, αv). Otherwise the resulting play is
inﬁnite and thus also won by Veriﬁer.
For the converse, suppose that K′, v′ ̸∼T , v0. Since T is ﬁnite, the non-
bisimilarity it witnessed by a ﬁnite stage. That is, there is a basic modal formula
separating K′, v′ from T , v0, and Falsiﬁer can force the model checking game for
ψv0 on K′, v′ in ﬁnitely many moves to a position of form (w′, αw) such that w
and w′ have distinct atomic types. This proves that K′, v′ ̸|= ψv0.
⊓⊔
As the entanglement of a transition system regards only the underlying graph,
one can easily ﬁnd examples of high entanglement that can be described with
very few variables. For instance, in a transition structure over a strongly con-
nected ﬁnite graph with no atomic propositions and only a single action a, all
states are bisimilar, and can be described by νX.(⟨a⟩X ∧[a]X), regardless of
the entanglement of the underlying graph. Nevertheless, the following theorem
establishes a strong relationship between the notion of entanglement and the
descriptive complexity of Lµ.
Theorem 4 ([2]). Every strongly connected graph of entanglement k can be la-
belled in such a way that no µ-calculus formula with less than k variables can
describe the resulting transition structure, up to simulation.
This theorem, which generalises a result of [3], provides the witnesses for the
expressive strictness of the µ-calculus variable hierarchy proved in [4].
5
Computational Complexity
An intriguing open problem related to the µ-calculus regards the computational
complexity of its evaluation problem: Given a formula ψ and a ﬁnite transition
structure K, v, decide whether ψ holds in K, v. Equivalently, this problem can
be phrased in terms of parity games, the natural evaluation games for Lµ [11].
Parity games are path-forming games played between two players on labelled
graphs G = (V, V0, E, Ω) equipped with a priority labelling Ω: V →N. All plays
start from a given initial node v0. At every node v ∈V0, the ﬁrst player, called
Player 0, can move to a successor w ∈vE; at positions v ∈V1 := V \ V0, his
opponent Player 1 moves. Once a player gets stuck, he loses. If the play goes on
inﬁnitely, the winner is determined by looking at the sequence Ω(v0), Ω(v1), . . .
of priorities seen during the play. In case the least priority appearing inﬁnitely
often in this sequence is even, Player 0 wins the play, otherwise Player 1 wins.
A memoryless strategy for Player i in a parity game G is a function σ that
indicates a successor σ(v) ∈vE for every position v ∈Vi. A strategy for a player
is winning, if he wins every play starting in which he moves according to this
strategy. The Memoryless Determinacy Theorem of Emerson and Jutla states
that parity games are always determined with memoryless strategies.
Theorem 5 (Memoryless Determinacy, [5]). In any parity game, one of the
players has a memoryless winning strategy.

Entanglement – A Measure for the Complexity of Directed Graphs
219
Any memoryless strategy σ induces a subgraph Gσ of the original game graph.
If σ is a winning strategy for a player, he wins every play on Gσ. Since these
subgames are small objects and it can be checked eﬃciently whether a player
wins every play on a given graph, the winner of a ﬁnite parity game can be
determined in NP ∩co-NP. In general, the best known deterministic algorithms
to decide the winner of a parity game have running times that are polynomial
with respect to the size of the game graph, but exponential with respect to
the number of diﬀerent priorities occurring in the game [7]. However, for game
graphs of bounded tree width, Obdrzalek has showed in [9], that the problem
can be solved in polynomial time with respect to the the size of the graph,
independently of the number of priorities.
In the remainder of this paper we will show that the entanglement of a parity
game graph is a pivotal parameter for its computational complexity. To maintain
the relationship between games and algorithms conceptually close, we base our
analysis on alternating machines (for a comprehensive introduction, see e.g. [1]).
5.1
Alternating Cycle Detection
Many algorithmic issues in graph theory are related to the problem of cycle de-
tection, typically, to determine whether a given graph contains a cycle satisfying
certain properties. When alternation comes into play, that is, when we consider
paths formed interactively, the questions become particularly interesting but of-
ten rather complex, too. In this framework, we will study the entanglement of
a graph as a measure of how much memory is needed to determine whether a
path formed on-the-ﬂy enters a cycle.
As a basis for later development, let us ﬁrst consider a procedure for deciding
whether k detectives are suﬃcient to capture the thief on a given graph. The
following algorithm represents a straightforward implementation of the game as
an alternating algorithm, where the role of the thief is played by the existential
player while the detectives are controlled by the universal player.
procedure Entanglement(G, v0, k)
input graph G = (V, E), initial position v0, candidate k ≤|V |
// accept iﬀent(G, v0) ≤k
v := v0, (di)i∈[k] := ⊥;
// current position of thief and detectives
do
existentially guess i ∈[k] ∪{pass}
// appoint detective i or pass
if i ̸= pass then di := v
// guard current node
if vE \ {di : i ∈[k]} = ∅then accept
else universally choose v ∈vE;
repeat
Since this algorithm requires space only to store the current positions of the
thief and the k detectives, it runs in alternating space O((k + 1) log |V |) which
corresponds to deterministic polynomial time.
Lemma 5. The problem of deciding, for a ﬁxed parameter k, whether a given
graph G has ent(G) ≤k can be solved in polynomial time.

220
D. Berwanger and E. Gr¨adel
Notice that if we regard k as part of the input, the algorithm gives an
Exptime upper bound for deciding the entanglement of a graph.
5.2
Parity Games
Similar to the thief and detective game, the dynamics of a parity game consists
in forming a path through a graph. However, while in the former game the de-
tectives can inﬂuence the forming process only indirectly, by obstructing ways
of return, in a parity game both players determine directly how the path is pro-
longed in their turn. Besides this dynamic aspect, also the objectives of players
are quite diﬀerent at a ﬁrst sight. While the detectives aim at turning the play
back to a guarded position, each player of a parity game tries to achieve that
the least priority seen inﬁnitely often on the path is of a certain parity.
The key insight which brings the two games to a common ground is the
Memoryless Determinacy Theorem for parity games: whichever player has a
winning strategy in a given game G = (V, V0, E, Ω), also has a memoryless one.
This means, that either player may commit, for each reachable position v ∈V
which he controls, to precisely one successor σ(v) ∈vE and henceforth follow
this commitment in every play of G without risking any chance to win. It follows
that, whenever a play returns to a previously visited position v, the winner can
be established by looking at the least priority seen since the ﬁrst occurrence of v.
Therefore can view parity games on ﬁnite game graphs as path forming games
of ﬁnite duration where the objective is to reach a cycle with minimal priority
of a certain parity.
We obtain an immediate method to determine the winner of a parity game by
simulating the players’ moves while maintaining the history of visited positions
in order to detect whether a cycle has been reached. To store the full history, an
implementation of this method requires space O(|V | log |V |) in the worst case;
since the procedure uses alternation to simulate the single game moves, this
situates us in Aspace(O(|V | log |V |)), or Dtime(|V |O(|V |)).
What makes this approach highly impractical is its extensive representation
of the play’s history. In fact, the power of alternation is limited to the formation
of the path, while the history is surveyed in a deterministic way. We can signiﬁ-
cantly improve this by interleaving thief and detective games with parity games
in such a way that the formation of cycles in history is surveyed interactively.
Intuitively, we may think of a parity game as an aﬀair between three agents,
Player 0 and 1, and a referee who wishes to establish which of the two indeed
wins the game. In our initial approach, the referee memorises the entire history
of the game. But as we have seen, the occurrence of a cycle in a path-forming
game on G can be detected by storing at most ent(G) many positions. Hence, if
we could provide the referee with the power of suﬃciently many detectives, this
would reduce the space requirement. The crux of the matter is how to ﬁt such a
three-player setting into the two-player model of alternating computation.
Our proposal to overcome this diﬃculty is to let one of the players act as a
referee who challenges the other player in the parity game, but in the same time

Entanglement – A Measure for the Complexity of Directed Graphs
221
controls the detectives in an overlying thief and detective game which regards
the interactively formed path as if it would be formed by the thief alone.
Formally, this leads to a new game. For a game graph G = (V, V0, E, Ω),
a player i ∈{0, 1}, and a number k, the superdetective game G[i, k] is played
between the Superdetective controlling k detectives and the positions of Vi, and
the Challenger in hold of the positions in V1−i. Starting from an initial position
position v0, in any move the Superdetective may place one of the k detectives
on the current position v, or leave them in place. If the current position v be-
longs to V1−i, Challenger has to move to some position w ∈vE, otherwise the
Superdetective moves. (If a player gets stuck, he immediately loses.) The play
ends if a position w occupied by a detective is reached and the Superdetective
wins if, and only if, the least priority seen since the detective was placed there
is even, for i = 0 respectively odd, for i = 1.
The following lemma states that parity games can be reduced to Superde-
tective games with an appropriate number of detectives.
Lemma 6. (1) If Player i has a winning strategy for the parity game G, then
the Superdetective wins the superdetective game G[i, k] with k = ent(G).
(2) If for some k ∈N, the Superdetective wins the game G[i, k], then Player i
has a winning strategy for the parity game G.
Proof. Let σ be a memoryless winning strategy of Player i for the game G and
let Gσ be the subgame of G induced by this strategy. Then, the least priority
seen on any cycle of Gσ is favourable to Player i. This remains true for any cycle
formed in G[i, k] where Player i acting as a Superdetective follows the same
strategy σ. On the other hand, obviously ent(Gσ) ≤ent(G) = k, which means
that the Superdetective also has a strategy to place the k detectives so that
every path through Gσ will ﬁnally meet a guarded position v and hence form a
cycle, witnessing that he wins. This proves (1).
For (2) assume that Player 1 −i has a memoryless winning strategy τ in
the parity game G. But then he could follow this strategy when acting as a
Challenger in the G[i, k], so that the play would actually remain in Gτ where no
cycle is favourable to Player i. Hence, regardless of the number of detectives, the
Superdetective cannot win G[i, k].
⊓⊔
Note that computing the winner of a superdetective game G[i, k] requires
alternating space (2k + 1) log |V |. Indeed, one just plays the game recording the
current position of the thief, and the current position of each detective along
with the minimal priority that has been seen since he was last posted.
procedure Superdetective(G, v0, j, k)
input parity game G = (V, V0, E, Ω), initial position v0 ∈V , player j, k detectives
// accept iﬀSuperdetective has a winning strategy in G[j, k] with k detectives
v := v0
// current position
(di)i∈[k] := ⊥
// positions guarded by detectives
(hi)i∈[k] := ⊥
// most signiﬁcant priorities

222
D. Berwanger and E. Gr¨adel
repeat
if j = 0 then
existentially guess i ∈[k] ∪{pass}
// appoint detective i or pass
else
universally choose i ∈[k] ∪{pass}
// other player’s detective
if i ̸= pass then
di := v; hi := Ω(v)
// guard current node
v := Move(G, v)
// simulate a game step
forall i ∈[k] do
// update history
hi := min(hi, Ω(v))
repeat
until ( v = di for some i )
// cycle detected
if (j = 0 and hi is even) or (j = 1 and hi is odd) then accept
else reject
We are now ready to prove that parity games of bounded entanglement can be
solved in polynomial time. In fact, we establish a more speciﬁc result, taking into
account the minimal entanglement of subgames induced by a winning strategy.
Theorem 6. The winner of a parity game G = (V, V0, E, Ω) can be determined
in Aspace(O(k log |V |)), where k is the minimum entanglement of a subgame
Gσ induced by a memoryless winning strategy σ in G.
⊓⊔
Proof. We ﬁrst describe the procedure informally, by way of a game. Given
a parity game G = (V, V0, E, Ω) and an initial position v0, each player i se-
lects a number ki and claims that he has a winning strategy from v0 such that
ent(Gσ) ≤ki. The smaller of the two numbers k0, k1 is then chosen to verify that
Superdetective wins the game G[i, ki]. If this is the case the procedure accepts
the claim of Player i, otherwise Player (1 −i) is declared the winner.
Here is a more formal description of the procedure:
procedure SolveParity(G, v)
input parity game G = (V, V0, E, Ω), initial position v ∈V
// accept iﬀPlayer 0 wins the game
existentially guess k0 ≤|V |
universally choose k1 ≤|V |
if k0 ≤k1 then
if Superdetective(G, v, 0, k0) then accept
else reject
else
if Superdetective(G, v, 1, k1) then reject
else accept
We claim that Player 0 has a winning strategy in a parity game G, v if, and
only if, the alternating procedure ParitySolve(G, v) accepts.
To see this, assume that Player 0 has a memoryless winning strategy σ from v.
Then, the guess k0 := ent(Gσ) leads to acceptance. Indeed, for k1 ≥k0, Player 0
wins the superdetective game G[0, k0] by using the strategy σ as a parity player
together with the detective strategy for Gσ. On the other hand, for k1 < k0, the

Entanglement – A Measure for the Complexity of Directed Graphs
223
procedure accepts as well, since Player 1 cannot win the superdetective game
G[1, k1] without having a winning strategy for the parity game. The converse
follows by symmetric arguments exchanging the roles of the two players.
⊓⊔
Corollary 2. Parity games of bounded entanglement can be solved in polynomial
time.
References
[1] J. L. Balcazar, J. Diaz, and J. Gabarro, Structural complexity 2, Springer-
Verlag, 1988.
[2] D. Berwanger, Games and Logical Expressiveness, Ph. D. Thesis, RWTH Aachen
(2005).
[3] D. Berwanger, E. Gr¨adel, and G. Lenzi, On the variable hierarchy of the
modal mu-calculus, in Computer Science Logic, CSL 2002, J. Bradﬁeld, ed.,
vol. 2471 of LNCS, Springer-Verlag, 2002, pp. 352–366.
[4] D. Berwanger and G. Lenzi, The variable hierarchy of the µ-calculus is strict,
in STACS 2005, Proceedings of the 22nd Symposium on Theoretical Aspects of
Computer Science, LNCS, Springer-Verlag, 2005.
[5] A. Emerson and C. Jutla, Tree automata, mu-calculus and determinacy, in
Proc. 32nd IEEE Symp. on Foundations of Computer Science, 1991, pp. 368–377.
[6] T. Johnson, N. Robertson, P. D. Seymour, and R. Thomas, Directed tree-
width, J. Comb. Theory Ser. B, 82 (2001), pp. 138–154.
[7] M. Jurdzi´nski, Small progress measures for solving parity games, in STACS 2000,
17th Annual Symposium on Theoretical Aspects of Computer Science, Proceed-
ings, vol. 1770 of Lecture Notes in Computer Science, Springer, 2000, pp. 290–301.
[8] D. Kozen, Results on the propositional µ-calculus, Theoretical Computer Science,
27 (1983), pp. 333–354.
[9] J. Obdrzalek, Fast mu-calculus model checking when tree-width is bounded, in
CAV’03, vol. 2725 of LNCS, Springer-Verlag, 2003, pp. 80–92.
[10] P. D. Seymour and R. Thomas, Graph searching and a min-max theorem for
tree-width, J. Comb. Theory Ser. B, 58 (1993), pp. 22–33.
[11] C. Stirling, Bisimulation, modal logic and model checking games, Logic Journal
of the IGPL, 7 (1999), pp. 103–124.

How the Location of ∗Inﬂuences Complexity in
Kleene Algebra with Tests
Chris Hardin
Department of Mathematics
Cornell University
Ithaca, New York 14853-4201, USA
hardin@math.cornell.edu
Abstract. The universal Horn theory of relational Kleene algebra with
tests is of practical interest, particularly for program semantics, where
Horn formulas can be used to verify correctness of programs or compiler
optimizations. Unfortunately, this theory is known to be Π1
1-complete.
However, many formulas arising in practice fall into fragments of the
theory that are of lower complexity. In this paper, we see that the location
of occurrences of the Kleene asterate operator * within a formula has a
great impact on complexity. Using syntactic criteria based on the location
of *, we give a fragment of the theory that is Σ0
1-complete, and a slightly
larger fragment that is Π0
2-complete. We show that the same results hold
over *-continuous Kleene algebras with tests. The techniques exhibit a
relationship between ﬁrst-order logic and the Horn theories of relational
and *-continuous Kleene algebra, even though the theories are not ﬁrst-
order axiomatizable.
1
Introduction
The universal Horn theories of ∗-continuous and relational Kleene algebras (with
tests) are of great interest, particularly for program semantics. Unfortunately,
these Horn theories are are Π1
1-complete [8,5], making them diﬃcult to work
with in full generality. However, under various restrictions on the formulas, the
complexity is often much lower. For example, when the hypotheses are restricted
to the form s = 0, the theory (in both cases) is PSPACE-complete [2,3,10,6].
See [8,6] for further examples. In this paper, we investigate how the location of
∗in a Horn formula aﬀects complexity.
For the rest of the introduction, we ﬁnd it convenient to be non-rigorous and
use many terms without deﬁning them, in the hopes of quickly and abstractly
sketching the material that will be presented and some intuition behind it. The
rest of the paper is more self-contained—barely even requiring the introduction,
although it does assume a familiarity with ﬁrst-order logic—and more responsible
about proof.
The ∗-continuity axiom, stated succinctly as xy∗z = supn∈ω xynz, can equiv-
alently be expressed by
xynz ≤xy∗z
(for each n ∈ω)
(1)
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 224–239, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

How the Location of ∗Inﬂuences Complexity in Kleene Algebra with Tests
225
and the inﬁnitary Horn formula

n∈ω
xynz ≤w →xy∗z ≤w .
(2)
Informally, (1), by bounding xy∗z from below, describes the bigness of y∗, while
(2), by bounding xy∗z from above, describes the smallness of y∗. The bigness
condition (1) is ﬁrst-order, while the smallness condition (2) is not. By appro-
priately restricting where ∗may appear in a Horn formula, we can make the
validity of the Horn formula (over ∗-continuous Kleene algebras) depend only
on the bigness of ∗, while the smallness is irrelevant; ﬁrst-order logic will then
be adequate for determining the validity of such formulas, which will pull the
complexity down to Σ0
1 (“There exists a proof. . . ”). Speciﬁcally, the restriction
will be that in the hypotheses, ∗may only appear on the left-hand side of in-
equalities si ≤ti, and in the conclusion, ∗may only appear on the right hand
side of an inequality s ≤t; such formulas are called simple.
Since everything but (2) in the deﬁnition of ∗-continuous Kleene algebra
is ﬁrst-order, while the Horn theory is Π1
1-complete, it must be the smallness
condition (2) that admits Π1
1-hardness. How does this happen? Here are two
intuitions, closely related to each other:
1. First-order logical consequence comes down to the well-foundedness of ﬁnitely
branching trees, which (with suitable eﬀectiveness conditions on the trees)
is Σ0
1. (One can think of these trees as proof trees; one can also think of
these trees as systematic attempts to construct a counterexample, in which
inﬁnite paths yield counterexamples, while well-foundedness constitutes a
proof. The distinction is only superﬁcial.)
We could extend ﬁrst-order logic to incorporate (2) by adding the inﬁnitary
inference rule
xynz ≤w
(for each n ∈ω)
xy∗z ≤w
.
However, our proof trees will no longer be ﬁnitely branching, and the problem
of well-foundedness of (recursive) inﬁnitely branching trees is Π1
1-complete.
Loosely, what has happened here is that well-foundedness can no longer be
expressed as “There exists n such that there are no nodes of depth n,” which
was adequate for ﬁnitely branching trees; instead, well-foundedness must now
be expressed as “All paths eventually hit a leaf node,” and quantifying over
paths is second-order.
2. Given a set A of ﬁrst-order formulas (in the language of Kleene algebra), let
Th(A) = {ϕ | A |= ϕ}. This is a closure operator in the standard sense:
A ⊆Th(A), Th(Th(A)) = Th(A), A ⊆B ⇒Th(A) ⊆Th(B); A is closed if
A = Th(A). There are two ways to build Th(A) from A: from below, and
from above. To build Th(A) from below, we start with A, and iterate the
process of throwing in axioms and applying inference rules; after countably
many iterations, we will have Th(A), and this lets us express ϕ ∈Th(A)
with the Σ0
1 formula “There exists a stage in this iterative process at which
ϕ appears.” To build Th(A) from above, we take the intersection of all closed

226
C. Hardin
sets containing A;1 this lets us express ϕ ∈Th(A) by “For all closed sets C
containing A, ϕ ∈C,” which is Π1
1.
Suppose that we extend our notion of logical consequence to incorporate
(2), and let Th′ denote closure under this notion. We can build Th′(A) from
below and above as before, but when building from below, we must iterate
transﬁnitely (since we will have an inﬁnitary inference rule for (2)); in par-
ticular, we cannot express ϕ ∈Th′(A) with a Σ0
1 formula. We must resort
to the Π1
1 deﬁnition involving intersections of closed sets.
In both instances, incorporating (2) results in a loss of compactness, breaking
whatever Σ0
1 deﬁnition of logical consequence we had.
If we only incorporate (2) in a restricted way, we can end up with a complexity
between Σ0
1 and Π1
1. A semisimple Horn formula will be like a simple Horn
formula, except that ∗may appear anywhere in the conclusion. The validity of
such formulas will rely on (2), but only slightly, in that (2) is only used to convert
a semisimple Horn formula into an inﬁnite conjuction of simple Horn formulas;
the question of validity of such conjunctions is Π0
2.
These will be our main results: when we restrict to simple Horn formu-
las, the Horn theories of ∗-continuous and relational Kleene algebras are Σ0
1-
complete; when we restrict to semisimple Horn formulas, the Horn theories are
Π0
2-complete.
2
Preliminaries
2.1
Kleene Algebra
Deﬁnition 1. An idempotent semiring is a structure (S, +, ·, 0, 1) satisfying
x + x = x
(idempotence)
1 · x = x · 1 = x
x + 0 = x
x · (y · z) = (x · y) · z
x + y = y + x
x · (y + z) = x · y + x · z
x + (y + z) = (x + y) + z
(y + z) · x = y · x + z · x
0 · x = x · 0 = 0
(In other words, (S, +, 0) is an upper semilattice with bottom element 0, (S, ·, 1)
is a monoid, 0 is an annihilator for ·, and · distributes over + on the right and
left.) We let IS denote the class of all idempotent semirings.
We often drop ·, writing xy for x · y. The upper semilattice structure induces
a natural partial order on any idempotent semiring: x ≤y ⇔x + y = y.
+ and · enjoy the following form of monotonicity: if x ≤x′ and y ≤y′, then
x + y ≤x′ + y′, and xy ≤x′y′. (For +, this is trivial. For ·, suppose x ≤x′ and
y ≤y′. Then x + x′ = x′, so we have xy + x′y = (x + x′)y = x′y, so xy ≤x′y.
We similarly have x′y ≤x′y′, so xy ≤x′y′.)
1 This might seem circular because our deﬁnition of closed was in terms of Th, but
it is easy to show that a set is closed iﬀit contains all axioms and is closed under
applications of inference rules.

How the Location of ∗Inﬂuences Complexity in Kleene Algebra with Tests
227
The names of the several classes of algebras we consider will serve as conve-
nient abbreviations for the type of algebra they contain. For example, “Every IS
extends. . . ” would mean “Every idempotent semiring extends. . . ”. We use the
notation Ax(IS) to denote the idempotent semiring axioms.
Deﬁnition 2. A Kleene algebra is a structure (K, +, ·,∗, 0, 1) such that
(K, +, ·, 0, 1) forms an idempotent semiring, and which satisﬁes
1 + xx∗≤x∗
(3)
1 + x∗x ≤x∗
(4)
p + qx ≤x →q∗p ≤x
(5)
p + xq ≤x →pq∗≤x
(6)
(The order of precedence among the operators is ∗> · > +, so that p + qr∗=
p + (q · (r∗)).) We let KA denote the class of all Kleene algebras.
Given a set Σ of constant symbols, let RExpΣ be the set of Kleene algebra
terms over Σ. We call the elements of RExpΣ regular expressions, and the el-
ements of Σ atomic program symbols. An interpretation is a homomorphism
I : RExpΣ →K, where K is a Kleene algebra. I is determined uniquely by its
values on Σ.
Equation (3) implies that q∗p is a solution to the inequality p + qx ≤x,
and (5) implies that it is the least solution; (4) and (6) say that pq∗is the least
solution to p + xq ≤x.
We use |= to denote ordinary Tarskian satisfaction. However, since we have
constant symbols from Σ not in the signatures of the underlying algebras, we
will pair each algebra with an interpretation when speaking about satisfaction.
For example, given a Kleene algebra K, interpretation I : RExpΣ →K, and
formula ϕ whose atomic program symbols are among Σ, we will write K, I |= ϕ
to indicate that K satisﬁes ϕ when the symbols in Σ are evaluated according
to I. K |= ϕ means that K, I |= ϕ for every interpretation I : RExpΣ →K. We
also use |= in two other standard ways: for a class C of algebras, C |= ϕ means
that K |= ϕ for each K ∈C; for a set Φ of formulas, Φ |= ϕ means that K |= ϕ
for each algebra K satisfying every formula in Φ.
Deﬁnition 3. For an arbitrary monoid M, its powerset 2M forms a Kleene
algebra as follows.
0 = ∅
1 = {1M}
(where 1M is the identity element of M)
A + B = A ∪B
A · B = {xy | x ∈A, y ∈B}
A∗=

k∈ω
Ak

228
C. Hardin
We let REG M denote the smallest subalgebra of 2M containing the singletons
{x}, x ∈M. (The elements of REG M are the regular subsets of M.) 2M and
its subalgebras are known as language algebras.
Of particular interest is the case M = Σ∗, the monoid of all strings over
alphabet Σ, under concatenation (the empty string is the identity). We deﬁne
the canonical interpretation R : RExpΣ →REG Σ∗by letting R(p) = {p} (and
extending R homomorphically to the rest of RExpΣ).
Relational Kleene algebras are also of interest.
Deﬁnition 4. For an arbitrary set X, the set 2X×X of all binary relations on
X forms a Kleene algebra R(X) as follows.
0 = ∅
1 = ιX = {(x, x) | x ∈X}
R + S = R ∪S
R · S = R ◦S
(the relational composition of R with S)
R∗=

k∈ω
Rk
(the reﬂexive transitive closure of R)
A Kleene algebra K is relational if it is a subalgebra of R(X) for some X; X
is called the base of K. We let RKA denote the class of all relational Kleene
algebras.
The deﬁnitions of ∗in 2M and R(X) exemplify the most common intuition
about the meaning of ∗, which is that y∗= supn∈ω yn, or informally, y∗=
1 + y + y2 + · · · . (More generally, if we require that multiplication distributes
over this supremum, we have xy∗z = x1z + xyz + xy2z + · · · = supn∈ω xynz.)
However, this property of ∗does not follow from the KA ∗-axioms, and must be
postulated separately.
Deﬁnition 5. A Kleene algebra K is ∗-continuous if it satisﬁes
xy∗z = sup
k∈ω
xykz
for all x, y, z ∈K. We let KA∗denote the class of all ∗-continuous Kleene
algebras.
As in the introduction, this is equivalent to the bigness condition (1) and the
smallness condition (2). Because ﬁrst-order logic cannot be extended to accom-
modate formulas such as (2) without breaking compactness, it is not surprising
that compactness is well suited for violating ∗-continuity, as shown by the proof
of the following proposition.
Proposition 6. There is a Kleene algebra that is not ∗-continuous.
Proof. Let Φ = Ax(KA) ∪{1 < x, 1 + a < x, 1 + a + a2 < x, . . .} ∪{x < a∗}.
Φ is ﬁnitely satisﬁable, so it is satisﬁable. Any model of Φ is a Kleene algebra,
and x will witness that a∗is not the least upper bound for {an | n ∈ω}.
⊓⊔

How the Location of ∗Inﬂuences Complexity in Kleene Algebra with Tests
229
The following lemma is a useful generalization of ∗-continuity.
Lemma 7. Suppose K ∈KA∗, I : RExpΣ →K is an interpretation, and t ∈
RExpΣ. Then
I(t) =
sup
σ∈R(t)
I(σ) .
Proof. By induction on structure of t. For details, see [9, Lemma 7.1, pp. 246–
248].
⊓⊔
Since relational composition distributes over arbitrary union, it is immediate
from the deﬁnition of ∗in R(X) that relational Kleene algebras are ∗-continuous,
so RKA ⊆KA∗.
Lemma 8. For any monoid M, 2M and its subalgebras are isomorphic to rela-
tional Kleene algebras. In particular, REG M is isomorphic to a relational Kleene
algebra.
Proof. Deﬁne ϕ : 2M →R(M) by
ϕ(A) = {(x, xy) | x ∈M, y ∈A} .
It is straightforward to show that ϕ is an injective homomorphism. So, 2M (or
any subalgebra of 2M) is isomorphic to its image under ϕ.
⊓⊔
Deﬁnition 9. A universal Horn formula is a formula of the form
s1 = t1 ∧· · · ∧st = tk →s = t ,
where si, ti, s, t are terms in the appropriate language. The set of universal Horn
formulas valid over a class C of algebras is the universal Horn theory of C,
which we denote by HC.
Note that, because any inequality x ≤y is in fact an equation x + y = y,
inequalities are allowed in Horn formulas.
Despite the lack of quantiﬁers in our presentation, universal Horn formulas
are in fact universal statements, at least when speaking of their validity. (For
example, K |= p ≤1 →p2 = p ⇐⇒K |= ∀x(x ≤1 →x2 = x).) The missing
quantiﬁer is hiding in our deﬁnition of K |= ϕ. We will often drop the word
“universal”.
Horn formulas are very important in universal algebra—second only to equa-
tions, as formulas go—but take on particular importance in Kleene algebra: the
hypotheses of a Horn formula are used to capture (or partially capture) the
intended semantics of the atomic program symbols when reasoning about pro-
grams. (For example, if p is intended to mean “let x := 1” and q is intended to
mean “let y := 1”, we might wish to reason under hypotheses such as pq = qp,
p2 = p, and q2 = q.)
Proposition 10. HKA ⊊HKA∗⊊HRKA

230
C. Hardin
Despite the above proposition, there are many special cases in which these
Horn theories coincide. The following lemma, which will be useful for other
reasons, is one such example.
Lemma 11. Suppose M = Σ∗/E is a ﬁnitely presented monoid (where Σ is the
set of generators, and E = {σ1 = τ1, . . . , σn = τn} is a set of equations, with
σi, τi ∈Σ∗). Let J : Σ∗→M be the interpretation mapping each element of Σ∗
to its equivalence class in M. The following are equivalent for any σ, τ ∈Σ∗.
(i) M, J |= σ = τ
(ii) E →σ = τ is valid in all monoids.
(iii) KA |= E →σ = τ
(iv) KA∗|= E →σ = τ
(v) RKA |= E →σ = τ
(vi) KA |= E →σ ≤τ
(vii) KA∗|= E →σ ≤τ
(viii) RKA |= E →σ ≤τ
Lemma 12. HRKA, HKA∗, and HKA, restricted to formulas containing only
monoid equations (that is, equations whose terms are built from atomic program
symbols, 1, and ·), are each Σ0
1-complete.
Proof. The word problem for ﬁnitely presented monoids, known to be
Σ0
1-complete, is exactly the same as determining the validity (over all monoids)
of Horn formulas consisting of monoid equations. By Lemma 11, this is equiva-
lent to determining the validity of such Horn formulas in KA, KA∗, or RKA.
⊓⊔
2.2
Kleene Algebra with Tests
Deﬁnition 13. A
Kleene
algebra
with
tests
is
a
two-sorted
structure
(K, B, +, ·,∗,
, 0, 1),
where
(K, +, ·,∗, 0, 1)
is
a
Kleene
algebra,
and
(B, +, ·,
, 0, 1) is a Boolean subalgebra. The elements of B are called tests. We
let KAT denote the class of all Kleene algebras with tests; we let KAT∗denote
the subclass of all ∗-continuous Kleene algebras with tests.
Now, instead of just having atomic program symbols, we must also have sym-
bols to use for tests. For a ﬁnite set P of atomic program symbols and a ﬁnite set
B of atomic test symbols, RExpP,B is the set of KAT terms over P and B; negation
can only be applied to Boolean terms, which are terms built from 0,1,+,·, , and
atomic test symbols. An interpretation I : RExpP,B →K must map each atomic
test to a test in K (and it follows by induction that it will map all Boolean terms
to tests).
R(X) forms a Kleene algebra with tests by keeping the previously deﬁned
Kleene algebra structure, and letting B = {r ∈R(X) | r ≤1}, b = ιX −b. A
Kleene algebra with tests K is relational if it is a subalgebraof R(X) for some
X. We let RKAT denote the class of all relational Kleene algebras with tests.

How the Location of ∗Inﬂuences Complexity in Kleene Algebra with Tests
231
Every Kleene algebra induces a Kleene algebra with tests by letting B =
{0, 1}, the two-element Boolean algebra; conversely, every Kleene algebra with
tests induces a Kleene algebra by taking its reduct to the signature of Kleene alge-
bra (i.e., taking its image under the map (K, B, +, ·,∗,
, 0, 1) 
→(K, +, ·,∗, 0, 1)).
With this in mind, it is easy to see that for any formula ϕ in the language
of Kleene algebra, KAT |= ϕ ⇔KA |= ϕ, KAT∗|= ϕ ⇔KA∗|= ϕ, and
RKAT |= ϕ ⇔RKA |= ϕ.
Deﬁnition 14. Let AtomsB denote the atoms of the free Boolean algebra on
generators B, which we can treat as elements of RExpP,B in a canonical way by
ordering B and writing elements of AtomsB as conjunctions in which exactly one
of b and b appears for each b ∈B, in order. For example, if B = {a, b}, then
AtomsB = {ab, ab, ab, ab}. We use letters α, β, γ, δ to denote elements of AtomsB.
A guarded string over P and B is an element of RExpP,B of the form
α0p1α1 · · · pkαk ,
where k ≥0, αi ∈AtomsB, pi ∈P. Let GSP,B (or simply GS) denote the set of
all guarded strings on P and B.
We deﬁne a partial binary operation ⋄on GS by
ασβ ⋄γτδ =

ασβτδ
if β = γ;
undeﬁned
otherwise.
The powerset 2GS of GS forms a Kleene algebra with tests as follows. The
tests are the subsets of AtomsB, and
0 = ∅
1 = AtomsB
A + B = A ∪B
A · B = {σ ⋄τ
| σ ∈A, τ ∈B, and σ ⋄τ is deﬁned}
A∗=

k∈ω
Ak
A = AtomsB −A
The canonical interpretation G : RExpP,B →2GS is deﬁned by
G(p) = {αpβ | α, β ∈AtomsB}
for p ∈P ,
G(b) = {α | α ≤b}2
for b ∈B ,
extended homomorphically. Let REG GS denote the elements of 2GS which are
G(s) for some s ∈RExpP,B.
2 The partial order here is the natural partial order on the free Boolean algebra on
generators B. In this case, α ≤b iﬀb appears positively in α.

232
C. Hardin
REG GS is also called the guarded string model, and is the free KAT on
generators P, B in the sense that G(s) = G(t) iﬀKAT |= s = t [10]. The guarded
string model can be treated in more generality as a special case of a trace model
[6], which we do not deﬁne here.
Lemma 15. Let K ∈KAT∗, I : RExpP,B →K an interpretation, and p, q, r ∈
RExpP,B. Then
I(pqr) =
sup
σ∈G(q)
I(pσr) .
In particular, I(q) = supσ∈G(q) I(σ).
Proof. See [10].
⊓⊔
2.3
Complete Idempotent Semirings
A ∗-continuous Kleene algebra can be thought of as an idempotent semiring
where certain suprema are guaranteed to exist (supn qn = q∗), with multiplica-
tion distributing over these suprema (pq∗r = supn pqnr). If we strengthen this
to require arbitrary suprema to exist, with multiplication distributing over these
arbitrary suprema, we get the notion of complete idempotent semiring.3
The algebras we consider in this section will all have a Boolean subalgebra
(that is, they will be “with tests”), but all the results still hold without tests.
Deﬁnition 16. An idempotent semiring with tests is a two-sorted structure
(S, B, +, ·,
, 0, 1),
where
(S, +, ·, 0, 1)
is
an
idempotent
semiring,
and
(B, +, ·,
, 0, 1) is a Boolean subalgebra. The elements of B are called tests.
We let IST denote the class of all idempotent semirings with tests.
For a ﬁnite set P of atomic programs and a ﬁnite set B of atomic tests,
RExp0
P,B is the set of IST terms over P and B, i.e., the ∗-free terms in RExpP,B.
An S ∈IST is complete if the partial order on S induced by + is complete4
(We do not require the supremum of an arbitrary set of tests to be a test.)
RExp0
P,B is the set of IST terms over P and B; this coincides with the ∗-free
terms of RExpP,B, and we have RExp0
P,B ⊆RExpP,B.
A complete IST forms a ∗-continuous Kleene algebra with tests by deﬁning
x∗= supn∈ω xn.
Lemma 17. Given a monoid (S, ·, 1) with a complete partial order ≤such that
· distributes over arbitrary suprema, S forms a complete idempotent semiring by
deﬁning 0 = sup ∅and x + y = sup{x, y}. If S has a Boolean subalgebra (with
0, 1, +, · coinciding with the operations on S), then S forms a complete IST.
3 Complete idempotent semirings are often referred to as S-algebras [4].
4 Here, a partial order (P, ≤) is complete if every subset of P has a supremum, as in
[1]. In particular, we require ∅and P to have suprema; this is in contrast to other
existing notions of complete partial order.

How the Location of ∗Inﬂuences Complexity in Kleene Algebra with Tests
233
Proof. Trivial, except perhaps for the requirement that 0 is an annihilator for ·,
which follows from distributivity and the deﬁnition of 0:
0 · x = (sup ∅) · x = sup(∅· x) = sup ∅= 0 .
x · 0 = 0 is similar.
⊓⊔
Theorem 18. Every IST extends to a complete IST.
Proof. We use ideal completion, where an ideal I is a nonempty subset of the
semiring which is closed downward and closed under +. The details are given in
a full version of this paper.
(Note that if a given S ∈IST happens to be a Kleene algebra, this construc-
tion will not typically respect ∗. However, if S is a ∗-continuous Kleene algebra,
one can strengthen the notion of ideal to require pq∗r ∈I whenever pqnr ∈I
for all n, and using ideal completion with this notion of ideal will preserve ∗. For
details of this see [7].)
⊓⊔
Corollary 19. HKAT, HKAT∗, and HIST, restricted to ∗-free formulas, coin-
cide.
Proof. KAT∗⊆KAT ⊆IST, so any Horn formula valid over IST is valid over
KAT and KAT∗. If a Horn formula is valid over KAT∗, then it must be valid over
IST, since every IST extends to a complete IST, which is a ∗-continuous Kleene
algebra, and validity of Horn formulas is preserved in subalgebras.
⊓⊔
3
Simple and Semisimple Horn Formulas
Deﬁnition 20. A Horn formula ϕ of KAT is semisimple if it is of the form
s1 ≤t1 ∧· · · ∧sn ≤tn →s ≤t
where t1, . . . , tn are ∗-free (i.e., have no occurrence of ∗). We say that ϕ is simple
if, in addition, s is ∗-free.
The coercion of a Horn formula E →s ≤t is the formula E ∧p ≤s ∧t ≤
p′ →p ≤p′ where p and p′ are fresh atomic program symbols. E →s ≤t is
coerced if s and t are atomic program symbols (in particular, the coercion of a
formula is coerced).
Lemma 21. A Horn formula E →s ≤t is valid over any particular K ∈KAT
iﬀits coercion is. (If the formula is ∗-free, then validity is also preserved in any
IST.)
Note that the coercion of any simple Horn formula is simple, so when working
with simple Horn formulas, we will often assume without loss of generality that
they are coerced.

234
C. Hardin
Note that there are many Horn formulas which are not simple, but are equiv-
alent to simple formulas or conjunctions thereof. For example, p ≤1 →p2 = p
is not simple, but is equivalent to
(p ≤1 →p2 ≤p) ∧(p ≤1 →p ≤p2) .
A more subtle example is q∗= 1 →q ≤1. If we expand q∗= 1 to q∗≤1 ∧1 ≤q∗,
we still do not have a simple formula; however, the latter hypothesis is a KA
tautology, so it can be dropped, leaving us with the simple formula
q∗≤1 →q ≤1 .
Our goal is the following four theorems.
Theorem 22. HKAT∗, restricted to simple Horn formulas, is Σ0
1-complete.
Theorem 23. HRKAT, restricted to simple Horn formulas, is Σ0
1-complete.
Theorem 24. HKAT∗, restricted to semisimple Horn formulas, is Π0
2-complete.
Theorem 25. HRKAT, restricted to semisimple Horn formulas, is Π0
2-complete.
(In each case, the lower bound will not require tests, so the results also apply
to HKA∗and HRKA.)
In [8] and [5], the reduction used to show that HKA∗and HRKA are Π1
1-
complete uses formulas that are equivalent to simple formulas except for a single
occurrence of ∗on the right-hand side of one hypothesis. (Furthermore, they
have no occurrence of 0, 1, or +, and only the one occurrence of ∗.) Semisimple
formulas are as general as possible without allowing ∗on the right-hand side of
a hypothesis, which in turn allows for Π1
1-completeness, so if we wish to ﬁnd any
larger fragments of HKA∗or HRKA that are not Π1
1-complete, the criteria will
have to be more discriminating than simply where ∗occurs.
3.1
Simple and Semisimple Formulas in KAT∗
In KAT, ﬁrst-order logic can handle ∗well, because its axiomatization is ﬁrst
order. The ∗-continuity axiom (xy∗z = supn∈ω xynz) is not ﬁrst order, though,
and the fact that HKAT∗is Π1
1-complete shows that there is no hope of ﬁnding a
ﬁrst-order substitute. As we will see in this section, the notion of simple formula
captures the portion of HKAT∗that ﬁrst-order logic can (indirectly) handle
anyway.
The ∗-continuity axiom, when the deﬁnition of supremum is unravelled, be-
comes
xy∗z ≤w ⇔

n∈ω
xynz ≤w ,
or, using Lemma 15 (and abusing notation),
s ≤t ⇔

σ∈G(s)
σ ≤t .

How the Location of ∗Inﬂuences Complexity in Kleene Algebra with Tests
235
Our basic tactic will be to replace any hypothesis s ≤t, where t is ∗-free, with
the inﬁnite set of ∗-free hypotheses σ ≤t, σ ∈G(s), which ﬁrst-order logic can
better digest.
Fix a simple Horn formula ϕ of the form
s1 ≤t1 ∧· · · ∧sn ≤tn →s ≤t ,
and assume without loss of generality that ϕ is coerced, so that s1, . . . , sn are
the only terms that may contain ∗. Let
Γϕ = {σ ≤ti | σ ∈G(si), 1 ≤i ≤n} .
Lemma 26. For ϕ as above, the following are equivalent.
(i) KAT |= ϕ
(ii) KAT∗|= ϕ
(iii) Ax(IST) ∪Γϕ |= s ≤t
(Ax(IST) denotes the IST axioms.)
Proof. (i)⇒(ii) is immediate, since KAT∗⊆KAT.
Suppose (ii) holds. Let S ∈IST, and let I : RExp0
P,B →S be any inter-
pretation such that S, I |= Γϕ; we must show S, I |= s ≤t. By Theorem 18,
S extends to a complete semiring S′. I extends uniquely to an interpretation
I′ : RExpP,B →S′. For any σ ∈G(si), 1 ≤i ≤n, we have I′(σ) = I(σ) ≤I(ti) =
I′(ti), so by Lemma 15, I′(si) = supσ∈G(si) I′(σ) ≤I′(ti). So, since S′, I′ |= ϕ
by assumption, and we have just shown that S′, I′ satisﬁes each hypothesis of ϕ,
we must have S′, I′ |= s ≤t. Then I(s) = I′(s) ≤I′(t) = I(t), so S, I |= s ≤t,
giving us (iii).
Now suppose (iii) holds. Take any K ∈KAT and interpretation I : RExpP,B →
K. Suppose I(si) ≤I(ti) for 1 ≤i ≤n. Then for any σ ∈G(si), 1 ≤i ≤n, we
have I(σ) ≤I(si) ≤I(ti), so K, I |= Γϕ. We also have K, I |= Ax(IST), so by
(iii), K, I |= s ≤t. Therefore, K, I |= ϕ, giving us (i).
⊓⊔
Proof (of Theorem 22). The upper bound follows from Lemma 26, since the
Horn theory of KAT is Σ0
1. (The entire theory of KAT is Σ0
1 since it is ﬁnitely
axiomatized.)
The lower bound is by Lemma 12. (Although Horn formulas consisting of
monoid equations are not technically simple, each hypothesis can be replaced by
a pair of inequalities, and Lemma 11 shows that we can, in this case, replace the
conclusion with an inequality.)
⊓⊔
Proof (of Theorem 24). Essentially, ∗-continuity lets us treat a semisimple for-
mula E →s ≤t as the inﬁnite conjunction 
σ∈G(s) E →σ ≤t. The details are
given in a full version of this paper.
⊓⊔
Theorem 27. Let s1 ≤t1 ∧· · · ∧sn ≤tn →s ≤t be any simple Horn formula.
The following are equivalent.
(i) KAT∗|= s1 ≤t1 ∧· · · ∧sn ≤tn →s ≤t

236
C. Hardin
(ii) There exist ﬁnite sets T ⊆G(t) and Si ⊆G(si), 1 ≤i ≤n, such that
KAT∗|= (ΣS1) ≤t1 ∧· · · ∧(ΣSn) ≤tn →s ≤(ΣT) .
(iii) There exist ﬁnite sets T ⊆G(t) and Si ⊆G(si), 1 ≤i ≤n, such that
IST |= (ΣS1) ≤t1 ∧· · · ∧(ΣSn) ≤tn →s ≤(ΣT) .
(Here, ΣS denotes the sum of the elements of S.)
3.2
Simple and Semisimple Formulas in RKAT
The ideas of Section 3.1 also work for relational algebras, but we must use ﬁrst-
order logic diﬀerently.
Fix ﬁnite P = {p1, . . . , pm}, B = {b1, . . . , bℓ}. Let LP,B be the ﬁrst-order
language with binary predicate symbols P1, . . . , Pm, B1, . . . , Bℓ(in addition to
equality) and no function or constant symbols. Let β be the formula
ℓ
i=1
∀x, y[Bi(x, y) →x = y] ,
which will ensure that interpretations of the Bi make suitable Boolean elements
in a relational algebra, by making them subsets of the identity relation.
For any LP,B-structure A modeling β (or simply, “for any A |= β”), |A|
will denote the universe of A, while P A
1 , . . . , P A
m, BA
1 , . . . , BA
ℓ
will denote the
interpretations of P1, . . . , Pm, B1, . . . , Bℓin A, and we deﬁne the interpretation
IA : RExpP,B →R(|A|) by IA(pi) = P A
i , IA(bi) = BA
i .
For each t ∈RExp0
P,B, we deﬁne the formula θt(x, y) of LP,B by induction on
t as follows.
θ0(x, y) ⇔false
θt(x, y) ⇔x = y ∧¬θt(x, y)
θ1(x, y) ⇔x = y
θs+t(x, y) ⇔θs(x, y) ∨θt(x, y)
θpi(x, y) ⇔Pi(x, y)
θst(x, y) ⇔∃z[θs(x, z) ∧θt(z, y)]
θbi(x, y) ⇔Bi(x, y)
(Given a formula ϕ(x, y), when we write ϕ(x, z), the usual convention applies:
if the variable z already occurs in ϕ(x, y), it is renamed as necessary before
substituting z for y to get ϕ(x, z), to avoid variable capture.)
Lemma 28. Take any A |= β. Then for all a, a′ ∈|A| and t ∈RExp0
P,B,
(a, a′) ∈IA(t) ⇔A |= θt(a, a′) .
Proof. Straightforward induction on t.
⊓⊔
Now, for any inequality s ≤t for s, t ∈RExp0
P,B, we deﬁne the sentence θs≤t
by
θs≤t ⇔∀x, y[θs(x, y) →θt(x, y)] .

How the Location of ∗Inﬂuences Complexity in Kleene Algebra with Tests
237
Lemma 29. Take any A |= β. Then for all s, t ∈RExp0
P,B,
R(|A|), IA |= s ≤t ⇔A |= θs≤t .
As we did in Section 3.1, ﬁx a simple Horn formula ϕ of the form
s1 ≤t1 ∧· · · ∧sn ≤tn →s ≤t ,
assuming without loss of generality that s and t are ∗-free, and let Γϕ = {σ ≤
ti | σ ∈G(si), 1 ≤i ≤n}. Let
Γϕ = {θu≤v | u ≤v appears in Γϕ} .
Lemma 30. The following are equivalent.
(i) RKAT |= ϕ
(ii) {β} ∪Γϕ |= θs≤t
Proof. Suppose (i) holds. Suppose A |= {β} ∪Γϕ. Then by Lemma 29,
R(|A|), IA |= u ≤v for all u ≤v appearing in Γϕ; that is, R(|A|), IA |=
σ ≤ti for all σ ∈G(si), 1 ≤i ≤n. R(|A|) is ∗-continuous, so by Lemma 15,
R(|A|), IA |= si ≤ti, 1 ≤i ≤n. So, applying (i), R(|A|), IA |= s ≤t. Applying
Lemma 29 again, we have A |= θs≤t, giving us (ii).
Now suppose (ii) holds. Take any K ∈RKAT. Let X be the base of K.
Suppose I : RExpP,B →K is an interpretation such that K, I |= si ≤tn,
1 ≤i ≤n. Deﬁne the LP,B-structure A by |A| = X, P A
i
= I(pi), BA
i
= I(bi).
Then I = IA, so from K, I |= si ≤ti, 1 ≤i ≤n, we get R(|A|), IA |= si ≤ti,
1 ≤i ≤n. It follows that R(|A|), IA |= σ ≤ti for all σ ∈G(si), 1 ≤i ≤n; that
is, R(|A|), IA |= Γϕ. Thus, by Lemma 29, A |= Γϕ. Since each I(bi) is a subset
of the identity relation, we have A |= β. So, applying (ii), A |= θs≤t. Applying
Lemma 29 again, we have R(|A|), IA |= s ≤t. This gives us K, I |= s ≤t (since
I = IA). We now have (i), as desired.
⊓⊔
Proof (of Theorem 23). The upper bound comes from Lemma 30, since the
predicate {β}∪Γϕ |= θs≤t is Σ1
0 in ϕ. (The set {β}∪Γϕ is uniformly computable
in ϕ, so we can eﬀectively enumerate its logical consequences.) The lower bound
comes from Lemma 12.
⊓⊔
Lemma 31. Let E be a ﬁnite set of monoid equations over Σ. Then for any
s ∈RExpΣ and τ ∈Σ∗, the following are equivalent.
(i) KA∗|= E →s ≤τ
(ii) RKA |= E →s ≤τ
Proof (of Theorem 25). The upper bound is by the same argument as in the
proof of Theorem 24. The lower bound, also as in the proof of Theorem 24, is
from the reduction in [8]; we can use the same reduction because the formulas
in the reduction are of the form that Lemma 31 applies to.
⊓⊔

238
C. Hardin
Theorem 32. Let s1 ≤t1 ∧· · · ∧sn ≤tn →s ≤t be any simple Horn formula.
The following are equivalent.
(i) RKAT |= s1 ≤t1 ∧· · · ∧sn ≤tn →s ≤t
(ii) There exist ﬁnite sets T ⊆G(t) and Si ⊆G(si), 1 ≤i ≤n, such that
RKAT |= (ΣS1) ≤t1 ∧· · · ∧(ΣSn) ≤tn →s ≤(ΣT) .
(iii) There exist ﬁnite sets T ⊆G(t) and Si ⊆G(si), 1 ≤i ≤n, such that
β |= θ(ΣS1)≤t1 ∧· · · ∧θ(ΣSn)≤tn →θs≤(ΣT ) .
Proof. Similar to Theorem 27.
⊓⊔
4
Bigness and Smallness of ∗
In the introduction, we stated that the validity of simple Horn formulas depends
only on the bigness of ∗. We now make that precise.
Deﬁnition 33. A ∗-algebra is an algebra over the signature of KAT satisfying
the IST axioms (in other words, the result of dropping the ∗axioms from KAT).
A big-∗-algebra is a ∗-algebra satisfying the bigness condition (1) from the in-
troduction. A small-∗-algebra is a ∗-algebra satisfying the smallness condition
(2). We let BIG∗and SMALL∗denote the classes of big-∗- and small-∗-algebras,
respectively.
Clearly, BIG∗∩SMALL∗= KAT∗. We also have KAT ⊆BIG∗, KAT ̸⊆SMALL∗.
Theorem 34. For any simple Horn formula ϕ, the following are equivalent.
(i) KAT∗|= ϕ
(ii) BIG∗|= ϕ
(iii) KAT |= ϕ
If we reverse the inequalities in the deﬁnition of simple formula, we get for-
mulas whose validity (in KAT∗) depends only on the smallness of ∗.
Deﬁnition 35. A Horn formula ϕ of KAT is cosimple if it is of the form
s1 ≤t1 ∧· · · ∧sn ≤tn →s ≤t
where s1, . . . , sn and t are ∗-free.
Theorem 36. For any cosimple Horn formula ϕ, the following are equivalent.
(i) KAT∗|= ϕ
(ii) SMALL∗|= ϕ
(Note the absence of the case KAT |= ϕ.)

How the Location of ∗Inﬂuences Complexity in Kleene Algebra with Tests
239
Acknowledgments
I am grateful to Dexter Kozen for his comments on various drafts of this article.
References
1. Stanley Burris and H. P. Sankappanavar. A Course in Universal Algebra. Springer-
Verlag, New York, 1981. (Also available online:
http://www.thoralf.uwaterloo.ca/htdocs/ualg.html)
2. Ernie Cohen. Hypotheses in Kleene Algebra. Unpublished.
3. Ernie Cohen, Dexter Kozen, and Frederick Smith. The complexity of Kleene alge-
bra with tests. Technical Report 96-1598, Computer Science Department, Cornell
University, July 1996.
4. J. H. Conway. Regular Algebra and Finite Machines. Chapman and Hall, London,
1971.
5. Chris Hardin and Dexter Kozen. On the Complexity of the Horn Theory of REL.
Technical Report 2003-1896, Computer Science Department, Cornell University,
May 2003.
6. Chris Hardin and Dexter Kozen.
On the Elimination of Hypotheses in Kleene
Algebra with Tests. Technical Report 2002-1879, Computer Science Department,
Cornell University, October 2002.
7. Dexter Kozen. On Kleene algebras and closed semirings. In Rovan, editor, Proc.
Math. Found. Comput. Sci., volume 452 of Lect. Notes in Comput. Sci., pages
26–47. Springer, 1990.
8. Dexter Kozen. On the Complexity of Reasoning in Kleene Algebra. Information
and Computation 179, 152-162, 2002.
9. Dexter Kozen. The Design and Analysis of Algorithms. Springer-Verlag, New York,
1991.
10. Dexter Kozen and Frederick Smith. Kleene algebra with tests: completeness and
decidability. Proc. 10th Int. Workshop on Computer Science Logic (CSL’96), ed.
D. van Dalen and M. Bezem, Utrecht, The Netherlands, Springer-Verlag Lecture
Notes in Computer Science Volume 1258, September 1996, 244–259.

The Equational Theory of ⟨N, 0, 1, +, ×, ↑⟩Is
Decidable, but Not Finitely Axiomatisable
Roberto Di Cosmo and Thomas Dufour
PPS Laboratory (http://www.pps.jussieu.fr)
Université Paris 7
France
{dicosmo,dufour}@pps.jussieu.fr
Abstract. In 1969, Tarski asked whether the arithmetic identities taught in high
school are complete for showing all arithmetic equations valid for the natural
numbers. We know the answer to this question for various subsystems obtained by
restricting in different ways the language of arithmetic expressions, yet, up to now
we knew nothing of the original system that Tarski considered when he started all
this research, namely the theory of integers under sum, product, exponentiation
with two constants for zero and one.
This paper closes this long standing open problem, by providing an elementary
proof, relying on previous work of R. Gureviˇc, of the fact that Tarski’s original
system is decidable, yet not ﬁnitely aximatisable.
We also show some consequences of this result for the theory of isomorphisms
of types.
1
Introduction
Over forty years ago, Tarski asked whether the arithmetic identities taught in high
school are complete for showing all arithmetic equations valid for the natural num-
bers. The answer to this question has occupied many prestigious mathematicians over
half a century, that gave the answer for various subsystems, the most intriguing one
being the one involving a constant for the number one and the operations of product
and exponentiation, for which a complete equational theory exists and also character-
izes isomorphism in the typed lambda calculus and in Cartesian Closed Categories,
thus exposing interesting connections between number theory, category theory, lambda
calculus and type theory.
Yet, up to now we knew nothing of the original system that Tarski considered when
he started all this research, namely the equational theory of natural numbers under sum,
product, exponentiation and with the two constants for zero and one.
We provide here an elementary proof, relying on previous work of R. Gureviˇc, of
the fact that the equational theory of the arithmetical system with constants 0 and 1 is
decidable, but not ﬁnitely axiomatisable. By “elementary”, we do not mean “simple”,
but we do want to stress the fact that we proceed by a set of transformations of deriva-
tions and formal systems that are well in the tradition of logic and theoretical computer
science.
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 240–256, 2005.
c⃝Springer-Verlag Berlin Heidelberg 2005

The Equational Theory of ⟨N, 0, 1, +, ×, ↑⟩Is Decidable
241
As a ﬁrst consequence of this result, we can conclude that the theory of isomor-
phisms of types for bicartesian closed categories is undecidable, a question left open in
[BDCF02].
The paper is organized as follows: subsection 1.1 gives a rather comprehensive
overview of Tarski’s High School Algebra Problem, and subsection 1.2 pinpoints its
interest in computer science; section 2 provides a few basic deﬁnitions and notations;
section 3 provides a proof that the equational theory of ⟨N, 0, 1, +, ×, ↑⟩can be reduced
to the equational theory of ⟨N, 1, +, ×, ↑⟩, modulo the equations and the conditional
equation involving zero that we are taught in high school (ﬁgure 2), which in turn gives
a decision procedure for the system; section 4 shows that the theory of ⟨N, 0, 1, +, ×, ↑⟩
is not ﬁnitely axiomatisable, and section 5 concludes.
1.1
Tarski’s High School Algebra Problem
In 1969, Tarski [DT69] asked if the equational theory E of the usual arithmetic iden-
tities of ﬁgure 1 that are taught in high school are complete for the standard model
⟨N, 1, +, ×, ↑⟩of positive natural numbers; i.e. , if they are enough to prove all the
arithmetic identities (he considered zero fundamental too, but, probably due to the pres-
ence of one conditional equation, he left for further investigation the case of the other
equations of ﬁgure 2, that we are also taught in high school).
(E1) 1 × x = x (E2) x × y = y × x (E3) (x × y) × z = x × (y × z)
(E4) x1 = x
(E5) 1x = 1
(E6) xy×z = (xy)z
(E7) (x × y)z = xz × yz
(E8) x + y = y + x
(E9) (x + y) + z = x + (y + z)
(E10) x × (y + z) = x × y + x × z
(E11) x(y+z) = xy × xz
Fig. 1. Equations without zero
(Z1) 0 × x = 0 (Z2) 0 + x = x
(Z3) x0 = 1
(Z4) 0x = 0
(x > 0)
Fig. 2. Equations and conditional equation for zero
He conjectured that they were1, but was not able to prove the result. Martin [Mar72]
showed that the identity (E6) is complete for the standard model ⟨N, ↑⟩of positive nat-
1 Actually, he conjectured something stronger, namely that E is complete for ⟨N, Ack(n, _, _)⟩,
the natural numbers equipped with a family of generalised binary operators Ack(n, _, _) that

242
R. Di Cosmo and T. Dufour
ural numbers with exponentiation, and that the identities (E2), (E3), (E6), and (E7) are
complete for the standard model ⟨N, ×, ↑⟩of positive natural numbers with multiplica-
tion and exponentiation. Further, he exhibited the identity
(xu + xu)v × (yv + yv)u = (xv + xv)u × (yu + yu)v
that in the language without the constant 1 is not provable in E. 2 The question was
not completely settled by this counterexample, because it is was only a counterexample
in the language without a constant for 1, that Tarski clearly considered necessary in
his paper, as well as the constant for 0, even if he did not explicitly mention it in his
conjecture. In the presence of a constant 1, the following new equations come into play,
and allow us to easily prove Martin’s equality.
1a = a
a1 = a
1a = 1
This problem attracted the interest of many other mathematicians, like Leon Henkin,
who focused on the equalities valid in ⟨N, 0, +⟩, and showed the completeness of the
usual known axioms (commutativity, associativity of the sum and the zero axiom), and
gives a very nice presentation of the topic in [Hen77].
Wilkie [Wil81] was the ﬁrst to establish Tarski’s conjecture in the negative. Indeed,
by a proof-theoretic analysis, he showed that the identity
(Ax + Bx)y × (Cy + Dy)x = (Ay + By)x × (Cx + Dx)y
where A = 1 + x , B = 1 + x + x2 , C = 1 + x3 , D = 1 + x2 + x4 is not provable
in E.
Gureviˇc later gave an argument by an ad hoc counter-model [Gur85] and, more
importantly, showed that there is no ﬁnite axiomatisation for the valid equations in the
standard model ⟨N, 1, +, ×, ↑⟩of positive natural numbers with one, multiplication,
exponentiation, and addition [Gur90]. He did this by producing an inﬁnite family of
equations such that for every sound ﬁnite set of axioms one of the equations can be
shown not to follow. Gureviˇc’s identities, which generalize Wilkie’s identities, are the
following

Ax + Bn
x2x
×

Cn
2x + Dn
2xx
=

A2x + Bn
2xx
×

Cn
x + Dn
x2x
where
A = 1 + x
Bn = 1 + x + · · · + xn−1 = n−1
i=0 xi
Cn = 1 + xn
Dn = 1 + x2 + · · · + x2(n−1) = n−1
i=0 x2i
n ≥3
is odd
extend the usual sum +, product × and exponentiation ↑operators. In Tarski’s deﬁnition,
Ack(0, _, _) is the sum, Ack(1, _, _) is multiplication, Ack(2, _, _) is exponentiation (for the
other cases see for example [Rog88]).
2 He also showed that there are no nontrivial equations for ⟨N, Ack(n, _, _)⟩if n > 2.

The Equational Theory of ⟨N, 0, 1, +, ×, ↑⟩Is Decidable
243
Nonetheless, equality in all these structures, even if not ﬁnitely axiomatisable, was
shown to be decidable [Mac81,Gur85].3
As often happens in number theory, these last results use far more complex tools
than simple arithmetic reasoning, as in the case of [HR84], where Nevanlinna theory is
used to identify a subclass of numerical expressions for which the usual axioms for +,
×, ↑and 1 are complete.
1.2
Connections with Type Isomorphisms and Applications in Library Search
Two types A and B in a given language are called isomorphic if there exist conversion
functions f : A →B and g : B →A which are mutual inverses [DC95].
From a practical perspective, type isomorphisms are used as a basis for library
search tools of various kind, and one is interested in knowing whether type isomor-
phisms in the presence of sums are ﬁnitely axiomatisable, and whether an efﬁcient
decision procedure exists, to incorporate it in library search tools like those described
in [Rit90,DC95].
There is a connection between the characterization of type isomorphisms in typed
lambda calculi and Tarski’s high school algebra problem: for types built out of type
constructors chosen amongst the unit, product, and arrow, two types are isomorphic if
and only if their associated arithmetic expressions (obtained by interpreting the unit
by the number one, product by multiplication, and arrow by exponentiation) are equal
in the standard model of natural numbers. In this case, type isomorphism (and numer-
ical equality) is ﬁnitely axiomatisable and decidable; hence so is the equational the-
ory of isomorphisms in cartesian closed categories. Zibin, Gil and Considine [ZGC03]
provide very efﬁcient O(n log n) decision procedures for this system. In the same
vein, Soloviev [Sol93], gave a complete axiomatisation of isomorphisms in symmet-
ric monoidal closed categories, and Dosen and Petric [DP97] provided the arithmetic
structure that exactly corresponds to these isomorphisms.
Balat, Fiore and the ﬁrst author investigated the question as to whether such cor-
respondence was limited to the case of the well-behaved unit, product, and arrow type
constructors and, in particular, if it could be extended to more problematic types in-
volving the empty type and the sum type constructor [BDCF02,BDCF04], with the
following fundamental result:
Gureviˇc’s identities are indeed type isomorphisms, and one can then show that
the theory of type isomorphisms in the presence of the product, arrow, and sum
type constructors, and the unit type is not ﬁnitely axiomatisable.
Since nothing was known for arithmetic equality in the presence of zero, one could
not conclude the non ﬁnite axiomatisability of type isomorphisms in the presence of
the empty type: it could be the case that, with the zero added, the Gureviˇc’s identities
collapse into a ﬁnite set of equations.
3 For the interested reader, here is how the decision procedure works: from the size of the equa-
tion that has to be veriﬁed, it is possible to derive an upper bound; if the two sides coincide for
all values of the variables up to this upper bound, then they coincide everywhere.

244
R. Di Cosmo and T. Dufour
Worse than that: even if every isomorphism does produce a numerical equality4,
when the zero constant is added, there is a numerical equality which is not an iso-
morphism, hence type isomorphism and arithmetic equality no longer coincide in the
presence of zero.
With the results of this paper, we can conclude that the family of Gureviˇc’s identities
does not collapse in the presence of zero, and hence, even with the empty set, type
isomorphisms are not ﬁnitely axiomatisable.
2
Deﬁnitions and Notations
Deﬁnition 1. The terms in ⟨N, 0, 1, +, ×, ↑⟩are t ::= x | 0 | 1 | t + t | t × t | tt, and
the terms in ⟨N, 1, +, ×, ↑⟩are ¯t ::= x | 1 | ¯t + ¯t | ¯t × ¯t | ¯t¯t, where x is a metavariable
denoting a countably inﬁnite set of variables V = {x, y, z, . . . }. We will use the letters
t, s, u, . . . for the terms of ⟨N, 0, 1, +, ×, ↑⟩.
Deﬁnition 2. Let t be a term of ⟨N, 0, 1, +, ×, ↑⟩, we write Var(t) for the set of its
variables.
Deﬁnition 3 (Context). A context – written Γ, ∆, . . . – is a formula of the proposi-
tional logic with the operators ¬, ∨, ∧, in which the atomic formulas are the “x = 0”,
for x ∈V. We also include ⊤(true), and ⊥(false).
Deﬁnition 4 (Exhaustive context). Given A, B ⊂V two ﬁnite sets, we let [A, B] be
the following context:
[A, B] =

x∈A
x = 0 ∧

x∈B\A
¬x = 0
A context Γ will be said to be exhaustive for t (a term) if there exist two ﬁnite sets
A and B ⊃Var(t) such that Γ is equivalent – as a logical proposition – to [A, B].
Deﬁnition 5 (Syntactically positive terms). A term t in ⟨N, 0, 1, +, ×, ↑⟩is said to
be syntactically positive in context Γ when Γ is exhaustive for t and ∀x ∈Var(t),
Γ ⇒¬x = 0.
Deﬁnition 6. Let ϕ be a valuation (ϕ : V →N). We write tϕ the interpretation of t
relative to this valuation.
Deﬁnition 7. Let Γ be a context and ϕ a valuation, we write Γϕ the logical value
deﬁned as follows:
x = 0ϕ =
⊤if ϕ(x) = 0
⊥if ϕ(x) ̸
= 0
Γ ∧∆ϕ = Γϕ ∧∆ϕ,
Γ ∨∆ϕ = Γϕ ∨∆ϕ,
¬Γϕ = ¬Γϕ.
A valuation ϕ will be said to satisfy a context Γ if Γϕ = ⊤.
4 A type isomorphism can be turned into a bijection of ﬁnite sets, and hence into an equation
between cardinalities, expressed using the arithmetic languages; hence all isomorphisms are
arithmetical equalities.

The Equational Theory of ⟨N, 0, 1, +, ×, ↑⟩Is Decidable
245
3
⟨N, 0, 1, +, ×, ↑⟩as an Extension of ⟨N, 1, +, ×, ↑⟩
Introduction In this section we create a formal system (called ZP) that produces “con-
ditional equations” of terms in ⟨N, 0, 1, +, ×, ↑⟩. That system starts with the equalities
in ⟨N, 1, +, ×, ↑⟩and builds on them. The semantics of this system will be proved to
relate to equality in ⟨N, 0, 1, +, ×, ↑⟩in a fashion that allows us to deduce, ﬁrst the
relationship between equality in ⟨N, 0, 1, +, ×, ↑⟩and in ⟨N, 1, +, ×, ↑⟩, second that
equality in ⟨N, 0, 1, +, ×, ↑⟩is decidable.
Deﬁnition 8 (The ZP formal system). We deﬁne a formal system, which we will call
ZP. It contains two statements: “Γ ⊢t .= s” and “Γ ⊢t positive”, which are inferred
as described in ﬁgure 3.
Remark Informally, these statements mean: “If Γ holds, then t and s are equal (respectively: t
is positive)”. Proving this is actually the point of proposition 2.
Proposition 1. Let t be a term, and Γ a context which is exhaustive for t. There are a
term t′ and a derivation that proves Γ ⊢t .= t′, where one of the following conditions
holds:
1. t′ = 0
2. t′ is syntactically positive in context Γ.
PROOF: The proof is essentially a reduction by induction on t and can be seen in ap-
pendix A.1.
⊓⊔
Lemma 1 Let t be a term which is syntactically positive term in context Γ. There exists
a derivation of the statement Γ ⊢t positive.
PROOF: With the fact that being syntactically positive extends to sub-terms, plus rules
N0, N1, N3-N5, we have an obvious proof by structural induction.
⊓⊔
Proposition 2 (Semantics of the statements of ZP). The following statements hold:
Γ ⊢t .= s ⇔∀ϕ satisfying Γ tϕ = sϕ
(1)
Γ ⊢t positive ⇔∀ϕ satisfying Γ tϕ ̸
= 0
(2)
PROOF: The left-to-right implications in (1) and (2) will be proved simultaneously by
structural induction on the derivation of the statement. This is shown in appendix A.2.
In order to prove the right-to-left implication in (1), we will begin by stating that it
is enough to prove it under the following stronger hypotheses:
For all A ⊂B = Var(t + s),
∀ψ satisfying [A, B] tψ = sψ ⇒[A, B] ⊢t .= s
This is supported by the four quite simple facts about contexts and valuations that
can be found in appendix A.3.

246
R. Di Cosmo and T. Dufour
E0 Γ ⊢t .= s
If condition (†) holds
(†) : t and s are syntactically positive in context Γ, and t = s in ⟨N, 1, +, ×, ↑⟩5.
E1 x = 0 ⊢x .= 0
E2 ⊤⊢t + 0 .= t
E2’ ⊤⊢0 + t .= t
E3 ⊤⊢t × 0 .= 0
E3’ ⊤⊢0 × t .= 0
E4 ⊤⊢t0 .= 1
E5 Γ ⊢t positive
Γ ⊢0t .= 0
E6
Γ ⊢t .= s
∆⊢t .= s
If ∆⇒Γ
E7 Γ ⊢t .= s
∆⊢t .= s
Γ ∨∆⊢t .= s
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
N0 ¬x = 0 ⊢x positive
N1 ⊤⊢1 positive
N2 Γ ⊢t positive
Γ ⊢t .= s
Γ ⊢s positive
N3
Γ ⊢t positive
Γ ⊢t + s positive
N4 Γ ⊢t positive
Γ ⊢s positive
Γ ⊢t × s positive
N5 Γ ⊢t positive
Γ ⊢s positive
Γ ⊢ts positive
N6
Γ ⊢t positive
∆⊢t positive
If ∆⇒Γ
N7 Γ ⊢t positive
∆⊢t positive
Γ ∨∆⊢t positive
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
REFL ⊤⊢t .= t
SYM Γ ⊢t .= s
Γ ⊢s .= t
TRANS Γ ⊢t .= s
Γ ⊢s .= u
Γ ⊢t .= u
CONT
Γ ⊢t .= s
Γ ⊢C[t] .= C[s]
C[·] denotes a context with only one placeholder6
Fig. 3. Rules of inference of the statements “Γ ⊢t .= s” and “Γ ⊢t positive” (ZP)
Let us now prove this restricted property:[A, B] is exhaustive for t and s so propo-
sition 1 stipulates that there exist some terms t′ and s′, which are both 0 or syntactically
5 Since t and s are syntactically positive, they contain no 0, so it is meaningful to ask whether
they are equal as terms of ⟨N, 1, +, ×, ↑⟩.
6 Here “context” has its usual meaning with terms of a ﬁrst-order language. Such a context is a
term of the language with an extra 0-ary symbol [·] called placeholder, which can be seen as a

The Equational Theory of ⟨N, 0, 1, +, ×, ↑⟩Is Decidable
247
positive in context [A, B], such that [A, B] ⊢t .= t′ and [A, B] ⊢s .= s′. Then let
ψ be a valuation that satisﬁes [A, B], we have tψ = t′ψ and sψ = s′ψ, so
t′ψ = s′ψ.
With what we proved earlier in this proposition (namely the left-to-right implica-
tions), we can state that either:
– t′ = 0 and s′ = 0, and [A, B] ⊢t′ .= s′ is derived with REFL, or
– t′ and s′ are both syntactically positive. Let ϕ be a valuation with values in N\{0},
there exists a valuation ψ satisfying [A, B] such that t′ψ = t′ϕ, and s′ψ =
s′ϕ7. Hence t′ is equal to s′ in ⟨N, 1, +, ×, ↑⟩, and we have a derivation of
[A, B] ⊢t′ .= s′ with rule E0.
Finally, to prove the right-to-left implication in (2), let us notice that it also sufﬁces,
reasoning like we just did, to prove this when Γ is exhaustive for t. In that case, propo-
sition 1 implies that there is a term t′ such that Γ ⊢t .= t′ and t′ is syntactically positive
in context Γ 8, so lemma 1 gives us a derivation of Γ ⊢t′ positive, and with rule N2 a
derivation of Γ ⊢t positive.
⊓⊔
Corollary 2 Equality in ⟨N, 0, 1, +, ×, ↑⟩is decidable.
PROOF: It is a known fact that equality in ⟨N, 1, +, ×, ↑⟩is decidable.
Let t and s be two terms of ⟨N, 0, 1, +, ×, ↑⟩. Let also C be the following set of
contexts:
C = {[X, Var(t + s)] | X ⊆Var(t + s)}
We contend that ⊤⊢t .= s if and only if ∀Γ ∈C Γ ⊢t .= s. This is a direct
consequence of proposition 2.
By using proposition 1, we get two new terms t′ and s′ such that Γ ⊢t .= s is
equivalent to Γ ⊢t′ .= s′. Since these new terms are either 0 or syntactically posi-
tive in context Γ, the new equality is either obviously true or false, or an equality in
⟨N, 1, +, ×, ↑⟩. We have reduced deciding an equality in ⟨N, 0, 1, +, ×, ↑⟩to deciding
a ﬁnite number of equalities in ⟨N, 1, +, ×, ↑⟩, therefore equality in ⟨N, 0, 1, +, ×, ↑⟩is
decidable.
⊓⊔
Conclusion Eventually, we have displayed a formal system whose derivations prove
the equalities of ⟨N, 0, 1, +, ×, ↑⟩, which are represented by the statement ⊤⊢t .= s.
This statement calls upon equality in ⟨N, 1, +, ×, ↑⟩plus rules depicting the equations:
t + 0 = t, t × 0 = 0, t0 = 1 and 0t = 0 if t ̸
= 0.
special variable, and C[t] stands for C[t/[·]] (usual substitution). For example if C = x + [·]
and t = x1+x, C[t] = x + x1+x.
7 This is due to the fact that the variables in A can no longer occur in t′ or s′, since these terms
are syntactically positive in context[A, B].
8 Obviously t′ cannot be 0, because of (1).

248
R. Di Cosmo and T. Dufour
4
Axioms of Equality in ⟨N, 0, 1, +, ×, ↑⟩
Introduction Throughout this section (until just before theorem 7, actually) we will
make the assumption that equality in ⟨N, 0, 1, +, ×, ↑⟩has a ﬁnite system of axioms,
our goal being to prove the contrary.
We ﬁrst need to modify the formal system ZP, replacing the equality imported from
⟨N, 1, +, ×, ↑⟩(which appeared in rule E0) with a ﬁnite set of axioms. We call ZPax this
new system, which is equivalent to ZP under our ﬁnite axioms hypothesis.
We will then use our previous results, along with a few new notations, to prove that
the axioms of equality in ⟨N, 0, 1, +, ×, ↑⟩, once reasonably “projected” to ⟨N, 1, +, ×,
↑⟩, form a ﬁnite system of axioms for equality in ⟨N, 1, +, ×, ↑⟩, which is known to be
impossible.
In order to realize this projection, we will evolve the system ZPax gradually, so that
the derivations in ZPax will come to be transformed (also gradually) into derivations in
⟨N, 1, +, ×, ↑⟩.
Deﬁnition 9 (The ZPax formal system). The formal system we call ZPax includes the
same rules as ZP, except that:
– A ﬁnite set of axioms A1, . . . , An is added. These axioms are:
Ai ⊤⊢li .= ri
– Rule E0 is withdrawn.
Deﬁnition 10 (Partial evaluation in a given context). Given a context Γ, we deﬁne a
partial function Γ(t) for the terms t for which Γ is exhaustive.
It is deﬁned by structural induction on the term t, as shown in ﬁgure 4.
Proposition 3. Let Γ be a context and t a term such that Γ(t) is deﬁned. We contend
the following properties hold:
1. Γ(t) is either 0, or a syntactically positive term (in context Γ);
2. If t is syntactically positive in context Γ then Γ(t) = t;
3. If Γ(t) ̸
= 0 then Γ ⊢t positive can be derived in ZP;
4. Γ ⊢Γ(t) .= t can be derived in ZP without E0;
5. The converse of 3. holds.
PROOF:
1. This is trivially proved by structural induction.
2. Idem, recalling that being syntactically positive extends to sub-terms.
3. If Γ(t) ̸
= 0 then Γ(t) is syntactically positive in context Γ, so that the statement
Γ ⊢t positive can be derived thanks to lemma 1.
4. This goes by structural induction on t. Let us examine further a single case.
Suppose that t = s + u, with Γ(s) ̸
= 0 and Γ(u) = 0. By induction there is a
derivation D of Γ ⊢Γ(s) .= s, and a derivation D′ of Γ ⊢0 .= u.
We build the following derivation:

The Equational Theory of ⟨N, 0, 1, +, ×, ↑⟩Is Decidable
249
Γ(0) = 0
Γ(1) = 1
Γ(x) =
 0 if Γ ⇒x = 0
x if Γ ⇒¬x = 0
Γ(t + s) =
⎧
⎨
⎩
Γ(t)
if Γ(s) = 0
Γ(s)
if Γ(t) = 0
Γ(t) + Γ(s) otherwise
Γ(t × s) =
 0
if Γ(t) = 0 or Γ(s) = 0
Γ(t) × Γ(s) otherwise
Γ(ts) =
⎧
⎨
⎩
1
if Γ(s) = 0
0
if Γ(t) = 0 and Γ(s) ̸= 0
Γ(t)Γ (s) otherwise
Fig. 4. Partial evaulation of terms in a context Γ
(D)
(D′)
Γ ⊢Γ(s) .= s
Γ ⊢0 .= u
Γ ⊢Γ(s) + 0 .= s + 0
Γ ⊢s + 0 .= s + u
Γ ⊢Γ(s) + 0 .= s + u
Γ ⊢Γ(s) .= s + u
The last step is actually a contraction of E2 and TRANS, written so for improved
readability. Since Γ(t) = Γ(s), this is the derivation we wanted. Other cases are
similarly treated (let us notice, although, that when t = su with Γ(s) = 0 and
Γ(u) ̸
= 0, we need to summon point 3. to get a derivation of Γ ⊢u positive).
5. This is a consequence of point 4. and proposition 2.
⊓⊔
Remark This shows that partial evaluation is actually an implementation of the existential result
in proposition 1.
Deﬁnition 11 (The ZP +
ax formal system). The formal system called ZP +
ax is the system
ZPax to which we add the following new axioms A+
1 , . . . , A+
n :
A+
i
ΓAi ⊢ΓAi(li) .= ΓAi(ri)
where ΓAi = [∅, Var(li + ri)]
Remark The “axioms” A+
i can actually be derived in the system ZPax, as proposition 3
implies that ΓAi ⊢ΓAi(li) .= li can be derived in ZPax (mutatis mutandis ri).
Deﬁnition 12 (Local equality statements). The statement Γ ⊢t .= s is said to be
local if Γ is exhaustive for t + s.
Deﬁnition 13. We deﬁne two particular sets of rules:
G0 = {E1, E2, E2’, E3, E3’, E4, REFL}
G = G0 ∪{A1, . . . , An}

250
R. Di Cosmo and T. Dufour
Deﬁnition 14 (“L” property). A derivation D in ZPax will be said to have the property
“L” (or to be an L-derivation), if the following properties hold:
L1 The conclusion of D is ∆⊢t .= s, and this statement is local.
L2 Any statement Γ ⊢t′ .= s′ occurring in D has one of the following qualities:
– Γ = ⊤or Γ = (x = 0) and this statement follows immediately a rule in G, or
– Γ = ∆(as in L1), and this statement is local.
L3 No rule E7 occurs in D.
L4 Rule E6 only occurs in D where it follows immediately a rule R ∈G.
Conditions L2 to L4 are lifted for any part of the derivation “above” an occurrence of
rule E5.
Remark The caution of this last sentence is justiﬁed by the possibility of equality statements
to appear above an E5, because of rule N2. Practically, in the following proofs by structural
induction on derivations, we will never use induction hypotheses when said derivation ends with
an E5.
Deﬁnition 15 (“EL” property). Let G′ = G0 ∪{A+
1 , . . . , A+
n }. A derivation in ZP +
ax
will be said to have the property “EL” (or to be an EL-derivation) if it has the proper-
ties L1 to L4, where G is replaced with G′ in L2 and L4, and the following two extra
properties :
EL1 No original axiom Ai occurs in D.
EL2 For any statement Γ ⊢t .= s in D such that Γ(t) and Γ(s) are deﬁned, Γ(t) = t
and Γ(s) = s.
We now contend that certain derivations (namely those made in contexts where all
variables are positive) can be transformed into L-derivations, and then into EL-deriva-
tions, which is the topic of the three next lemmas.
The ﬁrst of this three lemmas is a plain technicality pertaining to L-derivations.
Lemma 3 Let D be an L-derivation of ∆⊢t .= s. Let also A and B be two ﬁnite sets
of variables that do not occur in ∆. There exists an L-derivation of ∆∧[A, B] ⊢t .= s.
PROOF: This is actually quite obvious. All that is needed is to replace ∆with ∆∧
[A, B] everywhere9. It will also be necessary to insert an N6 between the premise and
conclusion of any E5. Also, in the (supposedly rare) situation where ∆= ⊤, it will be
necessary to insert an E6 after any rule R ∈G.
⊓⊔
Lemma 4 Let D be a derivation of Γ ⊢t .= s in ZPax and ∆a context that is exhaus-
tive for t and s, and such that ∆⇒Γ holds.
There exists a context ∆′ = [∅, A] (where the variables in A do not occur in ∆)
and an L-derivation of ∆∧∆′ ⊢t .= s.
9 Again, this need not apply to any part of the derivation above an E5.

The Equational Theory of ⟨N, 0, 1, +, ×, ↑⟩Is Decidable
251
Remark Since no hypothesis but ﬁniteness is made about A we can safely ignore the case
∆= ⊤, thanks to lemma 3.
PROOF: We proceed by structural induction on D, and distinguish cases according to
the last rule used in this derivation. See appendix A.4.
⊓⊔
Lemma 5 If [∅, Var(t + s)] ⊢t .= s can be derived in ZPax, and if no 0 appears in
either t or s, there exists a ﬁnite set of variables A (whose elements do not occur in
t + s) and an EL-derivation of ∆′ ⊢∆′(t) .= ∆′(s) in ZP +
ax, where ∆′ = [∅, Var(t +
s)] ∧[∅, A].
PROOF: Proposition 4 yields us an L-derivation, call it D, of the statement ∆′ ⊢t .= s.
The EL-derivation will be built by structural induction from D. Again we distinguish
cases according to the last rule used in D, keeping in mind some structural properties
about L-derivations. This is done in appendix A.5.
⊓⊔
We will now introduce a last evolution of our formal system before actually going
to equality in ⟨N, 1, +, ×, ↑⟩.
Deﬁnition 16 (The Pax formal system). Pax is a sub-system of ZP +
ax which includes
the following rules :
– the axioms A+
1 , . . . , A+
n ,
– REFL, SYM, TRANS, CONT,
– E6.
Remarque Clearly any statement which can be derived in Pax can also be derived in
ZPax.
Corollary 6 With the same hypotheses and notations as in lemma 5, there is a deriva-
tion of [∅, Var(t + s)] ∧[∅, A] ⊢t .= s in Pax. Moreover, no 0 occurs in the terms of
this derivation at all.
PROOF: Clearly the EL-derivation granted by lemma 5 is actually a derivation in Pax.
The terms of its conclusion have no zeros, and we will prove that if a rule in an EL-de-
rivation has no 0 in its conclusion, it can have none in its premise(s).
A+
i , REFL Those rules have no premises.
SYM, CONT, E6 The terms in the premise are the same as (or subterms of) those in
the conclusion.
TRANS A new term can appear in the premise, but since it is partially evaluated it is
either syntactically positive or 0. But since it is derived to be equal to the terms of
the conclusion, and since these are syntactically positive, the “new” term must also
be syntactically positive.
⊓⊔
Theorem 7. The equational therory of ⟨N, 0, 1, +, ×, ↑⟩cannot derive from a ﬁnite set
of axioms.

252
R. Di Cosmo and T. Dufour
PROOF: As we said before, we reason ad absurdum. Let us then assume that such a
ﬁnite set of axioms {Ai}i∈{1,...,n} exists.
Let us also consider Th the equational theory of ⟨N, 1, +, ×, ↑⟩with the axioms
{A+
i }i∈{1,...,n} (as deﬁned previously). Since these axioms are true in ZPax (which is
by hypothesis equivalent to ZP), they are true in ⟨N, 1, +, ×, ↑⟩(see proposition 2). So
Th only proves equalities that are true in ⟨N, 1, +, ×, ↑⟩.
Let now t and s be two terms that are equal in ⟨N, 1, +, ×, ↑⟩. They support the
hypotheses of lemma 5, since [∅, Var(t + s)] ⊢t .= s can be derived in ZP (using E0),
thus in ZPax.
Corollary 6 then yields a derivation of ∆⊢t .= s in Pax, which contains no 0 in its
terms.
If contexts are removed from this derivation, the E6 rules can be stripped as well
(they become empty transitions), and we get a derivation in a formal system with
{A+
i }i∈{1,...,n} as axioms, and the usual transitivity, symmetry, reﬂexivity and context
rules, which is equivalent to Th
Therefore any equality in ⟨N, 1, +, ×, ↑⟩can be derived in Th. Since it is known
that equality in ⟨N, 1, +, ×, ↑⟩cannot derive from any ﬁnite set of axioms, we have a
contradiction.
⊓⊔
5
Conclusions
We have proved that ⟨N, 0, 1, +, ×, ↑⟩has a decidable, but not ﬁnitely axiomatisable,
equational theory, and clearly shown that the only difference between ⟨N, 0, 1, +, ×, ↑⟩
and ⟨N, 1, +, ×, ↑⟩is given by the system Z in ﬁgure 2.
As a consequence, the family of Gureviˇc’s equalities does not collapse, and we also
obtain the following additional result
Theorem 8. The theory of type isomorphisms in Bi-Cartesian Closed Categories is not
ﬁnitely axiomatisable
that closes the long standing open problem of the ﬁnite axiomatisability of type isomor-
phisms for the lambda calculus with sums and the empty types [DC95].
By using the decidability result for ⟨N, 0, 1, +, ×, ↑⟩and the fact that all isomor-
phisms are equalities, we can reject all non-isomorphisms that are also non-arithmetical
identities, but, due to the fact that some arithmetic identities are not isomorphisms of
BiCCCs, it is left open whether such isomorphisms are indeed decidable.
Acknowledgements The ﬁrst author would like to thank Claude Kirchner, Vincent Balat
and Christophe Calves for interesting discussions on these subjects.
References
BDCF02. Vincent Balat, Roberto Di Cosmo, and Marcelo Fiore. Remarks on isomorphisms in
typed lambda calculi with empty and sum type. In LICS. IEEE, July 2002.

The Equational Theory of ⟨N, 0, 1, +, ×, ↑⟩Is Decidable
253
BDCF04. Vincent Balat, Roberto Di Cosmo, and Marcelo Fiore. Extensional normalisation and
type-directed partial evaluation for typed lamda calculus with sums. In 31st Ann. ACM
Symp. on Principles of Programming Languages (POPL), pages 64–76. ACM, 2004.
DC95.
Roberto Di Cosmo. Isomorphisms of types: from λ-calculus to information retrieval
and language design. Birkhauser, 1995.
DP97.
Kosta Dosen and Zoran Petric. Isomorphic objects in symmetric monoidal closed
categories. Mathematical Structures in Computer Science, 7(6):639–662, 1997.
DT69.
J. Doner and Alfred Tarski. An extended arithmetic of ordinal numbers. Fundamenta
Mathematica, 65:95–127, 1969.
Gur85.
R. Gureviˇc. Equational theory of positive numbers with exponentiation. Proceedings
of the American Mathematical Society, 94(1):135–141, 1985.
Gur90.
R. Gureviˇc. Equational theory of positive numbers with exponentiation is not ﬁnitely
axiomatizable. Annals of Pure and Applied Logic, 49:1–30, 1990.
Hen77.
Leon Henkin. The logic of equality. American Mathematical Monthly, 84:597–612,
October 1977.
HR84.
C. W. Henson and L. A. Rubel. Some applications of Nevanlinna theory to mathemat-
ical logic: Identities of exponential functions. Trans. Am. Math. Soc., 282(1):1–32,
March 1984.
Mac81.
A. Macintyre. The laws of exponentiation. In C. Berline, K. McAloon, and J.-P.
Ressayre, editors, Model Theory and Arithmetic, volume 890 of Lecture Notes in
Mathematics, pages 185–197. Springer-Verlag, 1981.
Mar72.
Charles F. Martin. Axiomatic bases for equational theories of natural numbers. Notices
of the Am. Math. Soc., 19(7):778, 1972.
Rit90.
Mikael Rittri. Searching program libraries by type and proving compiler correctness
by bisimulation. PhD thesis, University of Göteborg, Göteborg, Sweden, 1990.
Rog88.
Hartley Rogers, Jr. Theory of Recursive Functions and Effective Computability. The
MIT Press, Cambridge, Massachusetts; London, England, second edition, 1988.
Sol93.
Sergei V. Soloviev. A complete axiom system for isomorphism of types in closed
categories. In A. Voronkov, editor, Logic Programming and Automated Reasoning,
4th International Conference, volume 698 of Lecture Notes in Artiﬁcial Intelligence
(subseries of LNCS), pages 360–371, St. Petersburg, Russia, 1993. Springer-Verlag.
Wil81.
A. J. Wilkie. On exponentiation — A solution to Tarski’s high school algebra problem.
Math. Inst. Oxford University (preprint), 1981.
ZGC03.
Yoav Zibin, Joseph (Yossi) Gil, and Jeffrey Considine. Efﬁcient algorithms for iso-
morphisms of simple types. In Proceedings of the 30th ACM SIGPLAN-SIGACT sym-
posium on Principles of programming languages, pages 160–171. ACM Press, 2003.
A
Appendix
A.1
Proof of Proposition 1
Let H(t) = #0(t) + 2 × 
x/Γ ⇒x=0 #x(t), where #s(t) is the number of times s
occurs in t. We proceed by induction in lexicographical order on (S(t), H(t)) where
S(t) is the size of t10.
If H(t) = 0 or t = 0, taking t′ = t is OK.
Otherwise, i.e. if t ̸
= 0 and H(t) > 0, t matches one of the following patterns:
10 This is the size in the usual meaning: the number of nodes in the syntax tree of t.

254
R. Di Cosmo and T. Dufour
1. C[0 × s] or C[s × 0],
2. C[0 + s] or C[s + 0],
3. C[s0],
4. C[x] where Γ ⇒x = 0,
5. C[0s] where s is syntactically positive.
(C[·] denotes a context with only one placeholder.)
1. The induction hypothesis yields a derivation D of Γ ⊢C[0] .= t′ where t′ is 0 or
syntactically positive, hence the following derivation:
⊤⊢s × 0 .= 0
Γ ⊢s × 0 .= 0
(D)
Γ ⊢t .= C[0]
Γ ⊢C[0] .= t′
Γ ⊢t .= t′
We proceed similarly when t = C[0 × s], using the rule E3’ instead of E3.
2. The induction hypothesis again yields a derivation D of Γ ⊢C[s] .= t′ where t′ is
0 or syntactically positive, and we build the following derivation.
⊤⊢s + 0 .= s
Γ ⊢s + 0 .= s
(D)
Γ ⊢t .= C[s]
Γ ⊢C[s] .= t′
Γ ⊢t .= t′
We proceed similarly when t = C[0 + s], using the rule E2’ instead of E2.
3. By induction there is a derivation D of Γ ⊢C[1] .= t′ with a suitable t′, and we
derive:
⊤⊢s0 .= 1
Γ ⊢s0 .= 1
(D)
Γ ⊢t .= C[1]
Γ ⊢C[1] .= t′
Γ ⊢t .= t′
4. By induction there is a derivation D of Γ ⊢C[0] .= t′ with a suitable t′, and we
derive:
x = 0 ⊢x .= 0
Γ ⊢x .= 0
(D)
Γ ⊢t .= C[0]
Γ ⊢C[0] .= t′
Γ ⊢t .= t′
5. By induction there is a derivation D of Γ ⊢C[0] .= t′ with a suitable t′, and we
derive:
(D′)
Γ ⊢s positive
Γ ⊢0s .= 0
(D)
Γ ⊢t .= C[0]
Γ ⊢C[0] .= t′
Γ ⊢t .= t′
Here, we will need the lemma 1 pertaining to the relationship between the “Γ ⊢
t positive” statement and being syntactically positive, in order to provide the deriva-
tion D′.

The Equational Theory of ⟨N, 0, 1, +, ×, ↑⟩Is Decidable
255
A.2
Proof of Proposition 2 (1)
Depending on the last rule used in this derivation, we have:
REFL, E1 to E4 These are trivial cases.
SYM, TRANS, CONT, E5 These are also obvious, using the induction hypothesis.
E0 Thanks to the (†) condition, ∀ϕ such that ∀x ϕ(x) ̸
= 0, tϕ = sϕ.
Let ψ be a valuation satisfying Γ; since t and s are syntactically positive in context
Γ, necessarily ∀x ∈Var(t + s) ψ(x) ̸
= 0, and there exists a valuation ϕ as above
such that tϕ = tψ, and sϕ = sψ. Thus tψ = sψ holds.
E6 By induction : ∀ϕ satisfying Γ, tϕ = sϕ. Since ∆⇒Γ it is clear that any
valuation ϕ satisfying ∆also satisﬁes Γ, hence ∀ϕ satisfying ∆, tϕ = sϕ.
E7 As well as with E6, any valuation ϕ satisfying Γ ∨∆satisﬁes either Γ or ∆.
N0 and N1 Are also trivial cases.
N2 to N5 The induction hypothesis obviously allows to conclude.
N6 This case is treated like E6.
N7 Like E7.
A.3
Proof of Proposition 2 (2)
We let Γ be such that ∀ϕ satisfying Γ, tϕ = sϕ.
Fact 1 Γ has a logically equivalent form that is written
([A1, B] ∧∆1) ∨· · · ∨([An, B] ∧∆n)
where
– B = Var(t + s),
– ∀i Ai ⊂B,
– ∀i ∆i is a ∧-formula in which no variable in Var(t + s) appears.
To draft a proof, let us say that one needs to put Γ in a normal disjunctive form, call it Γ ′,
which is in turn equivalent to Γ ′ ∧
x∈Var(t+s)(x = 0 ∨¬x = 0). What remains to be done is
distributing this expression, taking out the antilogic conjunctive clauses, and grouping the atoms
in each clause.
Fact 2 ∀ψ satisfying [Ai, B], there is a ϕ satisfying [Ai, B] ∧∆i (thus satisfying Γ),
such that tψ = tϕ, and sψ = sϕ.
All that is needed is to “change the values of ψ so that it satisﬁes ∆i”, which can assuredly
be done without modifying the value of ψ(x) for any x ∈Var(t + s).
Fact 3 (∀ϕ satisfying Γ tϕ = sϕ) ⇒∀i (∀ψ satisfying [Ai, B] tψ = sψ)
This is obvious thanks to fact 2.
Fact 4 (∀i [Ai, B] ⊢t .= s) ⇒Γ ⊢t .= s.
One needs only use rules E6 (to bring in the ∆is) and E7.

256
R. Di Cosmo and T. Dufour
A.4
Proof of Lemma 4
R ∈G Follow with an E6, with ∆as new context.
E5 Insert an N6 with ∆as new context between the premise and conclusion of this E5.
E6 D has the following form :
(D′)
Γ ′ ⊢t .= s
Γ ⊢t .= s
where Γ ⇒Γ ′. Thus ∆⇒Γ ′ and the induction hypothesis applies to the deriva-
tion of Γ ′ ⊢t .= s, yielding the wanted L-derivation.
E7 D has the following form :
(D′)
(D′′)
Γ ′ ⊢t .= s
Γ ′′ ⊢t .= s
Γ ′ ∨Γ ′′ ⊢t .= s
Since ∆is exhaustive for t and s, it is a ∧-formula and either ∆⇒Γ ′ or ∆⇒Γ ′′
holds. If for example , ∆⇒Γ ′ holds, the induction hypothesis can be applied to
the derivation of Γ ′ ⊢t .= s, yielding the wanted L-derivation.
SYM, CONT Trivial.
TRANS By induction hypothesis we have L-derivations of ∆∧∆0 ⊢t .= s and
∆∧∆1 ⊢s .= u. By letting ∆′ = ∆0 ∧∆1, and summoning lemma 3 we get
L-derivations of ∆∧∆′ ⊢t .= s and ∆∧∆′ ⊢s .= u. All that is left is to apply
TRANS again.
A.5
Proof of Lemma 5
Ai followed by E6 Use A+
i , then E6.
R ∈G0 followed by E6 For any rule in G0, when its conclusion is written Γ ⊢l .= r
we have ∆′ ⇒Γ (see L2, L4), and ∆′(l) = ∆′(r) (checking this is easy). The
EL-derivation we want is a suitable use of REFL followed by E6.
E5 Idem.
SYM Immediate induction step.
CONT In this case, the L-derivation (D) looks like this:
(D′)
∆′ ⊢t .= s
∆′ ⊢C[t] .= C[s]
By induction we have an EL-derivation of ∆′ ⊢∆′(t) .= ∆′(s), and one of two
things happens:
– Either ∆′(t) = ∆′(s) = 0, and ∆′(C[t]) = ∆′(C[s]) – both are ∆′(C[0]),
which can be derived by REFL + E6.
– Or ∆′(t) and ∆′(s) are syntactically positive in context ∆′, and ∆′(C[t]) =
∆′(C[·])[∆′(t)] (mutatis mutandis s). So we just have to apply CONT again,
with context ∆′(C[·]), to get the desired EL-derivation.
TRANS As SYM, relying on L2 to summon the induction hypothesis.
Properties L1 to L4 are clearly preserved, EL0 clearly holds, and EL1 as well since
Γ(Γ(t)) = Γ(t) whenever Γ(t) is deﬁned.

A Trichotomy in the Complexity of
Propositional Circumscription
Gustav Nordh⋆
Department of Computer and Information Science
Link¨opings Universitet
S-581 83 Link¨oping, Sweden
gusno@ida.liu.se
Abstract. Circumscription is one of the most important and well stud-
ied formalisms in the realm of nonmonotonic reasoning. The inference
problem for propositional circumscription has been extensively studied
from the viewpoint of computational complexity. We prove that there
exists a trichotomy for the complexity of the inference problem in propo-
sitional variable circumscription. More speciﬁcally we prove that every
restricted case of the problem is either ΠP
2 -complete, coNP-complete, or
in P.
1
Introduction
Circumscription, introduced by McCarthy [13], is perhaps the most well devel-
oped and extensively studied formalism in nonmonotonic reasoning. The key
intuition behind circumscription is that by focusing on minimal models of for-
mulas we achieve some degree of common sense, because minimal models have
as few ”exceptions” as possible.
Propositional circumscription is the basic case of circumscription in which
satisfying truth assignments of propositional formulas are partially ordered ac-
cording to the coordinatewise partial order ≤on Boolean vectors, which extends
the order 0 ≤1 on {0, 1}. In propositional variable circumscription only a cer-
tain subset of the variables in formulas are subject to minimization, others must
maintain a ﬁxed value or are subject to no restrictions at all. Given a proposi-
tional formula T and a partition of the variables in T into three (possibly empty)
disjoint subsets (P; Z; Q) where P is the set of variables we want to minimize,
Z is the set of variables allowed to vary and Q is the set of variables that must
maintain a ﬁxed value, we deﬁne the partial order on satisfying models as fol-
lows. Let α, β be two models of T, then α ≤(P ;Z) β if α and β assign the same
value to the variables in Q and for every variable p in P, α(p) ≤β(p) (moreover
if there exists a variable p in P such that α(p) ̸= β(p), we write α <(P ;Z) β). A
minimal model of a formula T is a satisfying model α such that there exists no
satisfying model β where β <(P ;Z) α.
⋆Supported by the National Graduate School in Computer Science (CUGS), Sweden.
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 257–269, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

258
G. Nordh
We will from now on call the restricted form of propositional circumscription
where all variables are subject to minimization (that is Q = Z = ∅) for basic
circumscription, and the more general propositional variable circumscription for
propositional circumscription.
Every logical formalism gives rise to the fundamental problem of inference. In
the case of propositional circumscription the inference problem can be formulated
as follows.
– Inference: Given two propositional Boolean formulas T and T ′ and a par-
tition of the variables in T into three disjoint (possibly empty) subsets
(P; Z; Q), is T ′ true in every minimal model of T.
The formulas T and T ′ are assumed to be given in conjunctive normal form. It is
easy to realize that the inference problem is equivalent (under polynomial-time
conjunctive reductions) to the case where T ′ is a single clause, since T ′ can be
inferred from T under propositional circumscription if and only if each clause
of T ′ can be so inferred. Moreover we follow the approach in [10,11,14] where
the clauses of T are allowed to be arbitrary logical relations (sometimes called
generalized clauses). This approach was ﬁrst used by Schaefer to classify the
complexity of the satisﬁability problem in propositional logic and is sometimes
referred to as Schaefer’s framework [18].
Circumscription in propositional logic is very well studied from the com-
putational complexity perspective [2,4,7,8,10,11,14]. The inference problem for
propositional circumscription has been proved to be ΠP
2 -complete [8]. This re-
sult displays a dramatic increase in the computational complexity compared to
the case of ordinary propositional logic, where the inference problem is coNP-
complete [3]. This negative result raise the problem of identifying restricted cases
in which the inference problem for propositional circumscription have computa-
tional complexity lower than the general case.
The most natural way to study such restrictions is to study restrictions on
the formulas representing knowledge bases, denoted T in above. This is also the
approach followed in most of the previous research in the area. Hence in the case
of restrictions of the inference problem, we only restrict the formula T while T ′
are subject to no restrictions. The ultimate goal of this line of research is to
determine the complexity of every restricted special case of the problem. The
ﬁrst result of this type was proved by Schaefer [18], who succeeded in obtaining
a complete classiﬁcation of the satisﬁability problem in propositional logic. He
proved that every special case of the satisﬁability problem in propositional logic
either is tractable or NP-complete (note that this implies that the inference
problem in propositional logic is either tractable or coNP-complete). Recall the
result due to Ladner [12] that if P ̸= NP, then there exist decision problems in NP
that are neither tractable nor NP-complete. Hence the existence of dichotomy
theorems like Schaefer’s can not be taken for granted.
Some partial results are known for the complexity of the inference problem.
More speciﬁcally, both in the general case and in the case where Q = Z = ∅, it
has been proved that every special case of the problem is either ΠP
2 -complete or
lies in coNP [10,14].

A Trichotomy in the Complexity of Propositional Circumscription
259
Until now we have lacked a clear picture of the complexity of the inference
problem in propositional circumscription, i.e., no complete classiﬁcation of spe-
cial cases of the problem with a complexity in coNP as coNP-complete or in P
is known. Some cases are known to be coNP-complete, but to the best of our
knowledge only one case of the inference problem (where Q and Z need not be
empty) is known to be in P [2].
We prove that there exists a trichotomy theorem for the complexity of the
inference problem, i.e., for every special case of the problem it is either in P,
coNP-complete, or ΠP
2 -complete. Moreover we discover two new tractable cases.
These results are obtained by the use of techniques from universal algebra. These
techniques were ﬁrst applied to the propositional circumscription problem in [14]
where dichotomies for the model checking and inference problem for proposi-
tional circumscription in 3-valued logic were proved.
Although basic circumscription (where Q = Z = ∅) is a restricted case
of the problem we study, our trichotomy does not imply a trichotomy for basic
circumscription. This is because our hardness results do not in general carry over
to the restricted case where Q = Z = ∅. Hence the existence of a trichotomy for
the inference problem in basic propositional circumscription is still open.
The paper is organized as follows. In Section 2 we give the necessary back-
ground on Constraint Satisfaction Problems (CSPs) and the algebraic techniques
that we will use throughout this paper. In Section 3 we prove our trichotomy
theorem for the complexity of circumscription in propositional logic and ﬁnally
in Section 4 we give some conclusions.
2
Preliminaries
In this section we introduce the notation and basic results on CSPs and the
algebraic techniques that we will use in the rest of this paper.
2.1
Constraint Satisfaction Problems
The set of all n-tuples of elements from {0, 1} is denoted by {0, 1}n. Any subset
of {0, 1}n is called an n-ary relation on {0, 1}. The set of all ﬁnitary relations
over {0, 1} is denoted by BR.
Deﬁnition 1. A constraint language over {0, 1} is an arbitrary set Γ ⊆BR.
Constraint languages are the way in which we specify restrictions on our prob-
lems. For example in the case of the inference problem for propositional circum-
scription over the constraint language Γ, we demand that all the relations in the
knowledge base are present in Γ.
Deﬁnition 2. The Boolean constraint satisfaction problem (or the generalized
satisﬁability problem as Schaefer called it) over the constraint language Γ ⊆BR,
denoted Csp(Γ), is deﬁned to be the decision problem with instance (V, C), where
– V is a set of variables, and

260
G. Nordh
– C is a set of constraints {C1, . . . , Cq}, in which each constraint Ci is a pair
(si, ϱi) with si a list of variables of length mi, called the constraint scope, and
ϱi an mi-ary relation over the set {0, 1}, belonging to Γ, called the constraint
relation.
The question is whether there exists a solution to (V, C), that is, a function from
V to {0, 1} such that, for each constraint in C, the image of the constraint scope
is a member of the constraint relation.
Example 1. Let NAE be the following ternary relation on {0, 1}:
NAE = {0, 1}3 \ {(0, 0, 0), (1, 1, 1)}.
It is easy to see that the well known NP-complete problem Not-All-Equal
3-Sat can be expressed as Csp({NAE}).
Next we consider operations on {0, 1}. Any operation on {0, 1} can be ex-
tended in a standard way to an operation on tuples over {0, 1}, as follows.
Deﬁnition 3. Let f be a k-ary operation on {0, 1} and let R be an n-ary re-
lation over {0, 1}. For any collection of k tuples, t1, t2, . . . , tk ∈R, the n-tuple
f(t1, t2, . . . , tk) is deﬁned as follows: f(t1, t2, . . . , tk) = (f(t1[1], t2[1], . . . , tk[1]),
f(t1[2], t2[2], . . . , tk[2]), . . . , f(t1[n], t2[n], . . . , tk[n])), where tj[i] is the i-th com-
ponent in tuple tj.
A technique that has shown to be useful in determining the computational
complexity of Csp(Γ) is that of investigating whether Γ is closed under certain
families of operations [9].
Deﬁnition 4. Let ϱi ∈Γ. If f is an operation such that for all t1, t2, . . . , tk ∈ϱi
f(t1, t2, . . . , tk) ∈ϱi, then ϱi is closed under f. If all constraint relations in Γ
are closed under f then Γ is closed under f. An operation f such that Γ is
closed under f is called a polymorphism of Γ. The set of all polymorphisms of
Γ is denoted Pol(Γ). Given a set of operations F, the set of all relations that is
closed under all the operations in F is denoted Inv(F).
Deﬁnition 5. For any set Γ ⊆BR the set ⟨Γ⟩consists of all relations that can
be expressed using relations from Γ ∪{=} (= is the equality relation on {0, 1}),
conjunction, and existential quantiﬁcation.
Intuitively, constraints using relations from ⟨Γ⟩are exactly those which can
be simulated by constraints using relations from Γ. The sets of relations of
the form ⟨Γ⟩are referred to as relational clones, or co-clones. An alternative
characterization of relational clones is given in the following theorem.
Theorem 1 ([17]). For every set Γ ⊆BR, ⟨Γ⟩= Inv(Pol(Γ)).
The ﬁrst dichotomy theorem for a broad class of decision problems was
Schaefer’s dichotomy theorem for the complexity of the satisﬁability problem
in propositional logic [18]. Schaefer’s result has later been given a much shorter
and simpliﬁed proof using the algebraic techniques that we will later apply to
the inference problem for propositional circumscription. Schaefer’s result can be
formulated in algebraic terms as follows.

A Trichotomy in the Complexity of Propositional Circumscription
261
Theorem 2 ([9]). Let Γ ⊆BR be a constraint language. Csp(Γ) is NP-complete
if Pol(Γ) only contains essentially unary operations, and tractable otherwise.
Note that an operation f is essentially unary if and only if f(d1, . . . , dn) = g(di)
for some non constant unary operation g, and any d1, . . . , dn ∈{0, 1}.
As we will see later, constraint languages containing the relations {(0)} and
{(1)} will be of particular importance to us.
Deﬁnition 6. Given a constraint language Γ, the idempotent constraint lan-
guage corresponding to Γ is Γ ∪{{(0)}, {(1)}} which is denoted by Γ id.
2.2
Propositional Circumscription
In this section we make some formal deﬁnitions and recall some of the results
from [14]. Note that the focus of [14] is on propositional circumscription in many-
valued logics, and as a consequence the clause to be inferred is allowed to be
a general constraint. Since we only consider circumscription in Boolean logic in
this paper, this generalization is no longer necessary and in order to comply with
the deﬁnitions of the problem in [2,10] we require that the clause to be inferred
is an ordinary clause. The results from [14] still holds.
First we introduce the minimal constraint inference problem. It should be
clear that this problem is equivalent to the inference problem for propositional
circumscription.
Deﬁnition 7. The minimal constraint inference problem over the constraint
language Γ ⊆BR, denoted Min-Inf-Csp(Γ), is deﬁned to be the decision prob-
lem with instance (V, P, Z, Q, C, ψ), where (P; Z; Q) is a partition of V into
disjoint (possibly empty) subsets and
– V is a set of variables,
– P represents the variables to minimize,
– Z represents the variables that vary,
– Q represents the variables that are ﬁxed,
– C is a set of constraints {C1, . . . , Cq} in which each constraint Ci is a pair
(si, ϱi) with si a list of variables of length mi, called the constraint scope, and
ϱi an mi-ary relation over the set {0, 1}, belonging to Γ, called the constraint
relation, and
– ψ is a clause such that the set of variables in ψ is a subset of V .
The question is whether each minimal model α of (V, P, Z, Q, C) is also a
model of ψ.
The size of a problem instance of Min-Inf-Csp(Γ) is the length of the encoding
of all tuples in all the constraints in C.
We deﬁne formally what we mean when we say that a certain special case of
a problem is tractable or complete for certain complexity class.

262
G. Nordh
Deﬁnition 8. The problem Min-Inf-Csp(Γ) is called tractable if for any ﬁ-
nite Γ ′ ⊆Γ the problem Min-Inf-Csp(Γ ′) is solvable in polynomial time. The
problem Min-Inf-Csp(Γ) is called C-complete (for a complexity class C) if Min-
Inf-Csp(Γ ′) is C-hard for a certain ﬁnite Γ ′ ⊆Γ, and Min-Inf-Csp(Γ) ∈C.
The following theorem forms the basis of the algebraic approach to determine
the complexity of the inference problem for circumscription in propositional
logic. It states that when investigating the complexity of Min-Inf-Csp(Γ) it is
suﬃcient to consider constraint languages that are relational clones.
Theorem 3 ([14]). Min-Inf-Csp(Γ) is in P (coNP-complete, ΠP
2 -complete) if
and only if Min-Inf-Csp(⟨Γ⟩) is in P (coNP-complete, ΠP
2 -complete).
Proof. Since Γ ⊆⟨Γ⟩, any instance of Min-Inf-Csp(Γ) is also an instance
of Min-Inf-Csp(⟨Γ⟩). So Min-Inf-Csp(⟨Γ⟩) is at least as hard as Min-Inf-
Csp(Γ).
To prove the converse, i.e., that Min-Inf-Csp(Γ) is at least as hard as Min-
Inf-Csp(⟨Γ⟩), take a ﬁnite set Γ0 ⊆⟨Γ⟩and an instance S = (V, P, Z, Q, C, ψ) of
Min-Inf-Csp(Γ0). We transform S into an equivalent instance S′ = (V ′, P ′, Z′,
Q′, C′, ψ′) of Min-Inf-Csp(Γ1), where Γ1 is a ﬁnite subset of Γ.
For every constraint C = ((v1, . . . , vm), ϱ) in S, ϱ can be represented on the
form ϱ(v1, . . . , vm) =
∃vm+1, . . . , ∃vnϱ1(v11, . . . , v1n1) ∧. . . ∧ϱk(vk1, . . . , vknk)
where ϱ1, . . . , ϱk ∈Γ ∪{=}, vm+1, . . . , vn are new variables not previously
present in S, and v11, . . . , v1n1,v21, . . . , vknk ∈{v1, . . . , vn}. Replace the con-
straint C with the constraints ((v11, . . . , v1n1), ϱ1), . . . , ((vk1, . . . , vknk), ϱk). Add
vm+1, . . . , vn to V and Z. If we repeat the same reduction for every constraint
in C it results in an equivalent instance S′′ = (V ′′, P, Z′′, Q, C′′, ψ) of Min-Inf-
Csp(Γ1 ∪{=}).
For each equality constraint ((vi, vj), =) in S′′ we do the following:
– If both vi and vj are in P (Z′′, Q) we remove vi from P (Z′′, Q) and V ′′,
replace all occurrences of vi in C′′ and ψ by vj.
– If vj is in Q and vi is in P we remove vi from P and V ′′, replace all occur-
rences of vi in C′′ and ψ by vj. The case where vj is in P and vi is in Q is
handled in the same way.
– The case that remains is when one of vi and vj is in Z′′, assume without
loss of generality that vi is in Z′′. We remove vi from Z′′ and V ′′, replace all
occurrences of vi in C′′ and ψ by vj.
Finally remove ((vi, vj), =) from C′′.
The resulting instance S′ = (V ′, P ′, Z′, Q′, C′, ψ′) of Min-Inf-Csp(Γ1) is
equivalent to S and has been obtained in polynomial time. Hence Min-Inf-
Csp(Γ) is in P (coNP-complete, ΠP
2 -complete) if and only if Min-Inf-Csp(⟨Γ⟩)
is in P (coNP-complete, ΠP
2 -complete).
⊓⊔

A Trichotomy in the Complexity of Propositional Circumscription
263
The following theorem reduces the set of constraint languages that need to
be considered even further.
Theorem 4 ([14]). Min-Inf-Csp(Γ) is in P (coNP-complete, ΠP
2 -complete) if
and only if Min-Inf-Csp(Γ id) is in P (coNP-complete, ΠP
2 -complete).
Proof. Since Γ ⊆Γ id), any instance of Min-Inf-Csp(Γ) is an instance of Min-
Inf-Csp(Γ id). So Min-Inf-Csp(Γ id) is at least as hard as Min-Inf-Csp(Γ).
To prove the converse, i.e., that Min-Inf-Csp(Γ) is at least as hard as Min-
Inf-Csp(Γ id), take a ﬁnite set Γ0 ⊆Γ id) and an instance S = (V, P, Z, Q, D, ≤
, C, ψ) of Min-Inf-Csp(Γ0). We transform S into an equivalent instance S′ =
(V ′, P ′, Z′, Q′, D, ≤, C′, ψ′) of Min-Inf-Csp(Γ1), where Γ1 is a ﬁnite subset of
Γ.
For all variables x occurring in a constraint in S of the type ((x), (0)) or
((x), (1)) we do as follows. Remove x from P and Z, add x to Q and remove the
constraint. Update ψ as follows. If x occurs in the form ((x), (0)), then add x to
the clause ψ. If x occurs in the form ((x), (1)), then add ¬x to ψ.
The idea behind the reduction is as follows. If ((x), (0)) is a constraint in
C, we remove it and modify ψ to make sure that every minimal model α of
C \ {((x), (0))} such that α(x) = 1, is a model of ψ, and in the case where
α(x) = 0 we make sure that α is a model of the modiﬁed ψ if and only if α was a
model of the original ψ. The case where ((x), (1)) is a constraint in C is handled
in the same way. It should be clear that S and S′ are equivalent.
⊓⊔
We conclude this section by stating the dichotomy for the complexity of the
inference problem in propositional circumscription that was proved in [14].
Theorem 5 ([14]). Let Γ ⊆BR be a constraint language. Min-Inf-Csp(Γ) is
ΠP
2 -complete if Pol(Γ id) only contains essentially unary operations, and it is in
coNP otherwise.
3
Trichotomy Theorem for the Inference Problem
In this section we prove our trichotomy theorem for the complexity of the infer-
ence problem in propositional circumscription. In the light of Theorem 5, what
remains to be proved is that every problem Min-Inf-Csp(Γ) in coNP is either
coNP-hard or in P. Some important cases like Horn clauses [2] and aﬃne clauses
[7] are already known to be coNP-complete. But to the best of our knowledge the
only case known to be in P is when the knowledge base only consists of clauses
containing at most one positive and negative literal (i.e., clauses that are both
Horn and dual-Horn) [2]. Our main results is the discovery of two new tractable
classes of knowledge bases (width-2 aﬃne and clauses only containing negative
literals) and a proof that for all other classes of knowledge bases the problem is
coNP-hard.
We prove this by further exploiting the results obtained in [14], e.g., Theorem
3 that states that to determine the complexity of Min-Inf-Csp(Γ) it is suﬃcient
to consider constraint languages that are relational clones.

264
G. Nordh
Emil Post [16] classiﬁed all Boolean clones/relational clones and proved that
they form a lattice under set inclusion. Our proofs rely heavily on Post’s lattice
of Boolean clones/relational clones. An excellent introduction to Post’s classiﬁ-
cation of Boolean clones can be found in the recent survey article [1], for a more
complete account, see [15,17].
See Figure 1 for the lattice of Boolean relational clones. Note that the names
for the relational clones in Figure 1 do not agree with Post’s names. Post also
considered other classes of Boolean functions/relations, so called iterative classes,
and this leads to some confusion and inconsistencies if we would use Post’s
names. The terminology used in Figure 1 was developed by Klaus Wagner in an
attempt to construct a consistent scheme of names for clones/relational clones,
and was subsequently used in [1].
Now we introduce some relational clones that will be of particular importance
to us.
– Relational Clone IR2: For a ∈{0, 1}, a Boolean function f is called
a-reproducing if f(a, . . . , a) = a. The clones Ra contain all a-reproducing
Boolean functions. The clone R2 contains all functions that are both 0-
reproducing and 1-reproducing. Hence Inv(R2) = IR2 is the relational
clone consisting of all relations closed under all functions that are both 0-
reproducing and 1-reproducing. Note that functions satisfying f(a, . . . , a) =
a for all a in its domain are usually called idempotent.
– Relational Clone ID1: ID1 is the relational clone consisting of all relations
closed under the aﬃne operation f(x, y, z) = x ⊕y ⊕z and the ternary
majority operation g(x, y, z) = xy ∨yz ∨xz. It is proved in [5] (Lemma
4.11) that any relation in ID1 can be represented as a linear equation on at
most two variables over the two element ﬁeld GF(2). Constraint languages
Γ ⊆ID1 are usually called width-2 aﬃne in the literature.
– Relational Clone IS1: S1 is the clone consisting of all 1-separating func-
tions (see [1] for the deﬁnition of 1-separating functions). It is proved in [6]
(Lemma 39) that Inv(S1) = IS1 is the relational clone consisting only of re-
lations of the form {0, 1}n \(1, 1, . . . , 1). That is, IS1 consists of all relations
corresponding to clauses where all literals are negative. Note that [6] uses
Post’s original names for the Boolean clones and that S1 is F ∞
8
in Post’s
notation.
As we have seen in Theorem 4 relational clones of the form ⟨Γ id⟩are of
particular importance to us (remember that Min-Inf-Csp(Γ) is of the same
complexity as Min-Inf-Csp(Γ id)). We call relational clones of this form for
idempotent relational clones. It can be deduced that a relational clone Γ is
idempotent if and only if IR2 ⊆Γ. Hence we have the following lemma.
Lemma 1. Let Γ1 be a Boolean relational clone and Γ2 the relational clone that
is the least upper bound of IR2 and Γ1 in Post’s lattice of relational clones. Then
the following holds, Min-Inf-Csp(Γ1) is in P (coNP-complete, ΠP
2 -complete) if
and only if Min-Inf-Csp(Γ2) is in P (coNP-complete, ΠP
2 -complete).

A Trichotomy in the Complexity of Propositional Circumscription
265
IR0
IR1
IBF
IR2
IM
IM0
IM1
IM2
IS2
1
IS3
1
IS1
IS2
12
IS3
12
IS12
IS2
11
IS3
11
IS11
IS2
10
IS3
10
IS10
IS2
0
IS3
0
IS0
IS2
02
IS3
02
IS02
IS2
01
IS3
01
IS01
IS2
00
IS3
00
IS00
ID2
ID
ID1
IL2
IL
IL0
IL1
IL3
IE2
IE
IE0
IE1
IV2
IV
IV1
IV0
II0
II1
IN2
II
BR
IN
IBF
IR0
IR1
IR2
IM
IM0
IM1
IM2
IS2
1
IS3
1
IS1
IS2
12
IS3
12
IS12
IS2
11
IS3
11
IS11
IS2
10
IS3
10
IS10
IS2
0
IS3
0
IS0
IS2
02
IS3
02
IS02
IS2
01
IS3
01
IS01
IS2
00
IS3
00
IS00
ID
ID1
ID2
IL
IL0
IL1
IL2
IL3
IE
IE0
IE1
IE2
IV
IV1
IV0
IV2
IN2
IN
II
II0
II1
BR
Fig. 1. Lattice (under set inclusion) of all Boolean relational clones (co-clones) and
their complexity for the inference problem in propositional circumscription. White
means in P, light grey means coNP-complete, and dark grey means ΠP
2 -complete

266
G. Nordh
Proof. Remember that IR2 is the relational clone consisting of all relations that
are closed under all functions that are both 0-reproducing and 1-reproducing.
Thus, {{(0)}, {(1)}} ⊆IR2. If F is a set of Boolean functions containing a non a-
reproducing function f, then {{(0)}, {(1)}} ⊈Inv(F). Hence, given a relational
clone Γ, then {{(0)}, {(1)}} ⊆Γ if and only if IR2 ⊆Γ.
Thus it follows that the least upper bound of IR2 and Γ1 in the lattice of
relational clones is ⟨Γ id
1 ⟩= Γ2. Now by Theorem 4 we get that Min-Inf-Csp(Γ1)
is in P (coNP-complete, ΠP
2 -complete) if and only if Min-Inf-Csp(Γ2) is in P
(coNP-complete, ΠP
2 -complete).
⊓⊔
Next we prove our two new tractable cases of Min-Inf-Csp(Γ). First out is
the width-2 aﬃne case.
Lemma 2. Min-Inf-Csp(ID1) is in P.
Proof. Remember that the set of constraints that can be expressed by ID1 can
be represented as a system of linear equations over GF(2) where each equation
contains at most two variables. Hence each constraint is equivalent to an equation
of the following form, x = c, x = y or x = −y, where c = 0 or 1.
Now consider an instance S = (V, P, Z, Q, C, ψ) of Min-Inf-Csp(Γ), where
Γ ⊆ID1. We begin by reducing S = (V, P, Z, Q, C, ψ) into an equivalent instance
S′ = (V ′, P ′, Z′, Q′, C′, ψ′) such that C′ has some special properties. Note that
by the symmetry of equations the cases where the roles of x and y are reversed
are handled in the same way.
– For all equations of the form x = c we do as follows. If x = 1 (x = 0) is an
equation in C and x (¬x) is a literal in ψ, then every minimal model of C
is also a model of ψ and we are done. Otherwise, replace all occurrences of
x in C by 1 (0). Remove x from V , P, Z, Q, and remove ¬x (x) from ψ.
Finally remove x = c from C.
– For all equations of the form x = y (x = −y) where x ∈Q and y is present in
another equation we do as follows. Replace all occurrences of y in all other
equations and ψ by x (−x) and remove y from V , P, Z, and Q. Finally
remove x = y (x = −y) from C.
– For all equations of the form x = y (x = −y) where y ∈Z and y is present in
another equation we do as follows. Replace all occurrences of y in all other
equations and ψ by x (−x) and remove y from Z and V . Finally remove
x = y (x = −y) from C.
– For all equations of the form x = y (x = −y) where x ∈P, y ∈P, and y is
present in another equation we do as follows. Replace all occurrences of y in
all other equations and ψ by x (−x) and remove y from P and V . Finally
remove x = y (x = −y) from C.
We repeat the above process until no more equations can be removed. It can be
realized that in the resulting system of equations C′, no variable in Z′ occurs in
more than one equation, no variable in Q′ occurs in an equation together with
a variable that occurs in another equation. Moreover, no variable in P ′ occurs

A Trichotomy in the Complexity of Propositional Circumscription
267
in an equation together with a variable from P ′ ∪Z′ that occurs in another
equation.
Now, if ψ′ is a tautology, then of course ψ′ is true in every minimal model
of C′, and we are done. So we assume that ψ′ is not a tautology. Since ψ′ is
a clause it is easy to ﬁnd the (single) assignment of the variables (in ψ′) that
does not satisfy ψ′. Note that since C′ is aﬃne it is easy to decide whether a
partial solution can be extended to a total solution, and it is clear that ψ′ can be
inferred from C′ under circumscription if and only if this assignment cannot be
extended to a minimal solution to C′. So the question that remains is whether
this partial solution (that can be extended to a total solution) can be extended
to a minimal solution to C′ or not.
Consider the equations of the form x = y or x = −y where neither x nor y
is in Q and x is present in ψ′. Then an assignment to x can be extended to a
minimal solution to C′ if and only if
– x is assigned to 0 in all equations x = y where x ∈P ′ and y ∈P ′ ∪Z′ and
all equations x = −y where x ∈P ′ and y ∈Z′, and
– x is assigned to 0 (1) in all equations x = y (x = −y) where x ∈Z′ and
y ∈P ′.
⊓⊔
Now on to the case of clauses where all literals are negative.
Lemma 3. Min-Inf-Csp(IS1) is in P.
Proof. We recall that IS1 consists of all relations corresponding to clauses where
all literals are negative. That is, relations of the form {0, 1}n \ (1, 1, . . . , 1).
Now consider an instance S = (V, P, Z, Q, C, ψ) of Min-Inf-Csp(Γ), where
Γ ⊆IS1. The cases where ψ is a tautology is trivial, so we assume that ψ is not
a tautology. Since ψ is a clause it is easy to ﬁnd the (single) assignment of the
variables that does not satisfy ψ. It is clear that ψ can be inferred from C under
circumscription if and only if this assignment cannot be extended to a minimal
solution to C. Note that since C consists of Horn clauses (with only negative
literals) it is easy to decide whether a partial solution can be extended to a total
solution, and it should be clear that such a partial solution can be extended to a
minimal solution if and only if all variables in P that are assigned by this partial
solution are assigned the value 0. Hence Min-Inf-Csp(IS1) is in P.
⊓⊔
Next we give the complexity of Min-Inf-Csp(Γ) for 8 particular relational
clones.
Theorem 6. Min-Inf-Csp(Γ) is coNP-complete when: 1. Γ = IS2
11; 2. Γ =
IS2
0; 3. Γ = IL; 4. Γ = IV ; or 5. Γ = IE. Min-Inf-Csp(Γ) is in P when: 6.
Γ = IS12; 7. Γ = ID1; or 8. Γ = IM2.
Proof.
1. The least upper bound of IS2
11 and IR2 is IS2
10. IS2
10 contains all
Horn clauses with at most 2 variables and it is proved in [2] that Min-Inf-
Csp(IS2
10) is coNP-complete, hence by Lemma 1 it follows that Min-Inf-
Csp(IS2
11) is coNP-complete.

268
G. Nordh
2. IS2
0 contains clauses of the form (x∨y), that is clauses only consisting of two
positive literals. It is proved in [2] that Min-Inf-Csp(IS2
0) is coNP-complete.
3. The least upper bound of IL and IR2 is IL2, the set of aﬃne clauses. It is
proved in [7] that Min-Inf-Csp(IL2) is coNP-complete, hence by Lemma 1
it follows that Min-Inf-Csp(IL) is coNP-complete.
4. The least upper bound of IV and IR2 is IV2, the set of dual-Horn clauses. By
Case 2. and Lemma 1 it follows that Min-Inf-Csp(IV ) is coNP-complete.
5. The least upper bound of IE and IR2 is IE2, the set of Horn clauses. By
Case 1. and Lemma 1 it follows that Min-Inf-Csp(IE) is coNP-complete.
6. It is proved in Lemma 3 that Min-Inf-Csp(IS1) is in P. The least upper
bound of IS1 and IR2 is IS12, hence by Lemma 1 it follows that Min-Inf-
Csp(IS12) is in P.
7. This is proved in Lemma 2.
8. IM2 consists of all clauses that are both Horn and dual Horn. It is proved
in [2] that Min-Inf-Csp(IM2) is in P.
⊓⊔
The previous theorem together with the structure of Post’s lattice of rela-
tional clones and the results proved in [14] yields a trichotomy for the complexity
of Min-Inf-Csp(Γ). The results are summarized in terms of the relational clones
in Figure 1. A perhaps more intelligible summary is given in the conclusions be-
low.
4
Conclusions
Only one tractable case of the inference problem for propositional circumscrip-
tion (where Q and Z need not to be empty) is known, namely when the knowl-
edge base only consists of clauses that are both Horn and dual-Horn [2]. We
have found two new tractable classes of knowledge bases (width-2 aﬃne clauses,
and Horn clauses only containing negative literals) for the inference problem
in propositional circumscription. We have proved that the inference problem is
coNP-hard for all other classes of knowledge bases. This together with the re-
sults in [14] gives us the following trichotomy for the complexity of the inference
problem in propositional circumscription:
– P: Horn and dual-Horn, width-2 aﬃne, negative Horn;
– coNP-complete: Horn, dual-Horn, aﬃne, bijunctive, (and not Horn and
dual-Horn, width-2 aﬃne, or negative Horn);
– ΠP
2 -complete: All that are not Horn, dual-Horn, aﬃne, or bijunctive.
In closing we note that the problem of establishing a trichotomy (as con-
jectured in [10]) for the complexity of the inference problem for propositional
circumscription in the restricted case where all variables must be minimized
(Q = Z = ∅) is still open.

A Trichotomy in the Complexity of Propositional Circumscription
269
Acknowledgments
The author thanks Steﬀen Reith for providing the visualization of Post’s lattice
in Figure 1.
References
1. E. B¨ohler, N. Creignou, S. Reith, and H. Vollmer. Playing with boolean blocks, part
I: Post’s lattice with applications to complexity theory. ACM SIGACT-Newsletter,
34(4):38–52, 2003.
2. M. Cadoli and M. Lenzerini. The complexity of closed world reasoning and cir-
cumscription. Journal of Computer and System Sciences, pages 255–301, 1994.
3. S. Cook. The complexity of theorem proving procedures. In Proceedings of the 3rd
ACM Symposium on Theory of Computing, pages 151–158, 1971.
4. S. Coste-Marquis and P. Marquis. Complexity results for propositional closed world
reasoning and circumscription from tractable knoledge bases. In Proceedings of the
16th International Joint Conference on Artiﬁcial Intelligence, pages 24–29, 1999.
5. N. Creignou, S. Khanna, and M. Sudan.
Complexity classiﬁcations of boolean
constraint satisfaction problems. SIAM, Philadelphia, 2001.
6. V. Dalmau. Computational Complexity of Problems over Generalized Formulas.
PhD thesis, Department LSI, Universitat Polit`ecnica de Catalanya, Barcelona,
2000.
7. A. Durand and M. Hermann.
The inference problem for propositional circum-
scription of aﬃne formulas is coNP-complete. In Proceedings of the 20th Annual
Symposium on Theoretical Aspects of Computer Science, pages 451–462, 2003.
8. T. Eiter and G. Gottlob. Propositional circumscription and extended closed-world
reasoning are ΠP
2 -complete. Theoretical Computer Science, 114:231–245, 1993.
9. P. Jeavons, D. Cohen, and M. Gyssens. Closure properties of constraints. Journal
of the ACM, 44:527–548, 1997.
10. L. Kirousis and P. Kolaitis. A dichotomy in the complexity of propositional cir-
cumscription. In Proceedings of the 16th Annual IEEE Symposium on Logic in
Computer Science, pages 71–80, 2001.
11. L. Kirousis and P. Kolaitis. The complexity of minimal satisﬁability problems.
Information and Computation, 187(1):20–39, 2003.
12. R. Ladner. On the structure of polynomial time reducibility. Journal of the ACM,
22:155–171, 1975.
13. J. McCarthy.
Circumscription - a form of nonmonotonic reasoning.
Artiﬁcial
Intelligence, 13:27–39, 1980.
14. G. Nordh and P. Jonsson. An algebraic approach to the complexity of propositional
circumscription. In Proceedings of the 19th Annual IEEE Symposium on Logic in
Computer Science, pages 367–376, 2004.
15. N. Pippenger. Theories of Computability. Cambridge University Press, Cambridge,
1997.
16. E. Post. The two-valued iterative systems of mathematical logic. Annals of Math-
ematical Studies, 5:1–122, 1941.
17. R. P¨oschel and L. Kaluznin. Funktionen- und Relationenalgebren. DVW, Berlin,
1979.
18. T.J. Schaefer. The complexity of satisﬁability problems. In Proceedings of the 10th
ACM Symposium on Theory of Computing, pages 216–226, 1978.

Exploiting Fixable, Removable, and Implied
Values in Constraint Satisfaction Problems
Lucas Bordeaux, Marco Cadoli, and Toni Mancini
Dipartimento di Informatica e Sistemistica
Universit`a di Roma “La Sapienza”
Via Salaria 113, I-00198 Roma, Italy
{bordeaux|cadoli|tmancini}@dis.uniroma1.it
Abstract. Complete algorithms for constraint solving typically exploit
properties like (in)consistency or interchangeability, which they detect
by means of incomplete yet eﬀective algorithms and use to reduce the
search space. In this paper, we study a wide range of properties which in-
cludes most of the ones used by existing CSP algorithms as well as some
which have not yet been considered in the literature, and we investigate
their use in CSP solving. We clarify the relationships between these no-
tions and characterise the complexity of the problem of checking them.
Following the CSP approach, we then determine a number of relaxations
(for instance local versions) which provide suﬃcient conditions whose
detection is tractable. This work is a ﬁrst step towards a comprehensive
framework for CSP properties, and it also shows that new notions still
remain to be exploited.
1
Introduction
Many Constraint Satisfaction Problems (CSPs) which arise in the modelling
of real-life problems exhibit “structural” properties that distinguish them from
random instances. Detecting such properties has been widely recognised to be an
eﬀective way for improving the solving process. To this end, several of them have
already been identiﬁed, and diﬀerent techniques have been developed in order
to exploit them, with the goal of reducing the search space to be explored. Good
examples are value substitutability and interchangeability [11], more general
forms of symmetries [6,12], and functional dependencies among variables [18,1].
Unfortunately, checking whether such properties hold, is (or is thought to be)
often computationally hard. As an example, let us consider interchangeability.
Value a is said to be interchangeable with value b for variable x if every solution
which assigns a to x remains a solution if x is changed to b, and vice versa [11].
The problem of checking interchangeability is coNP-complete (cf. Proposition 2).
Analogously, detecting some other forms of symmetry reduces to the graph auto-
morphism problem [5] (for which there are no polynomial time algorithms, even
if there is evidence that it is not NP-complete [16]).
To this end, in order to allow general algorithms to exploit such properties
eﬃciently, diﬀerent approaches can be followed. First of all, syntactic restrictions
on the constraint languages can be enforced, in order to allow for the eﬃcient
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 270–284, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

Exploiting Fixable, Removable, and Implied Values in CSP
271
veriﬁcation of the properties of interest. Alternatively, “local” versions of such
properties can be deﬁned, that can be used to infer their global counterparts,
and such that they can be veriﬁed in polynomial time. As an instance of this
“local reasoning” approach, instead of checking whether a value is fully inter-
changeable for a variable, Freuder [11] proposes to check whether that value is
neighbourhood, or k-interchangeable. This task involves considering only subsets
of the constraints of bounded size, and hence can be performed in polynomial
time. Neighbourhood and k-interchangeability are suﬃcient (but not necessary)
conditions for full interchangeability, and have been proven to be highly eﬀec-
tive in practice (cf., e.g., [4,3]). Moreover, in some cases, the existence of some
properties can also derive from intrinsic characteristics of the problem, or even
from an explicit promise [9], cf. forthcoming Example 1.
In this paper we give a formal characterisation of several properties of CSPs
which can be exploited in order to save search. Some of them are well-known,
while some others are, to the best of our knowledge, original. All the presented
deﬁnitions are then collected in a uniﬁed framework, and hierarchically classiﬁed
in order to highlight the semantical connections that hold among them. After-
wards, we present a formal discussion of their computational properties, and
show how some of them can be practically exploited by the solving engine in
order to save search.
In general, all these properties can be detected either statically, during a
preprocessing stage of the input CSP (cf. e.g., [2]), dynamically, during search
(since they may arise at any time), or explicitly “promised” by an external entity.
Example 1 (Factoring [17,23]). This problem is a simpliﬁed version of one of the
most important problems in public-key cryptography. Given a (large) positive
integer Z, which is known to be the product of two prime numbers (diﬀerent
from 1), it amounts to ﬁnd its factors X and Y .
An intuitive formulation of this problem as a CSP, in order to deal with
arbitrarily large numbers, amounts to encode the combinatorial circuit of integer
multiplication, and is as follows: assuming the input integer Z having n digits
(in base b) z1, . . . , zn, we consider 2n variables x1, . . . , xn and y1, . . . , yn one for
each digit (in base b) of the two factors, X and Y (with x1 and y1 being the
least signiﬁcant ones). The domain for all these variables is [0, b −1]. In order to
maintain information about the carries, n + 1 additional variables c1, . . . , cn+1
must be considered, with domain [0..(b −1)2n/b].
As for the constraints (cf. Fig. 1 for the intuition), they are the following:
1. Constraints on factors:
(a) Factors must be diﬀerent from 1, or, equivalently, X ̸= Z and Y ̸= Z
must hold;
(b) For every digit i ∈[1, n]: zi = ci + 
j,k∈[1,n]:j+k=i+1(xj ∗yk mod b);
2. Constraints on carries:
(a) Carry on the least signiﬁcant digit is 0: c1 = 0;
(b) Carries on other digits: ∀i ∈[2, n + 1], ci = ci−1 + 
j,k∈[1,n]:j+k=i
xj∗yk
b
;
(c) Carry on the most signiﬁcant digit is 0: cn+1 = 0;
⊓⊔

272
L. Bordeaux, M. Cadoli, and T. Mancini
7
8
7 ∗
7
9
7 =
0 6 13 18 12
4
0
49 56 49
63 72 63 −
49 56 49 −−
6
2
7
2
3
9
x3
x2
x1 ∗
y3
y2
y1 =
c7
c6
c5
c4
c3
c2
c1
x3y1 x2y1 x1y1
x3y2 x2y2 x1y2
−
x3y3 x2y3 x1y3
−
−
z6
z5
z4
z3
z2
z1
Fig. 1. Factoring instance 627239, n = 6, b = 10
It is worth noting that, when a guess on the two factors X and Y (i.e., on vari-
ables x1, . . . , xn and y1, . . . , yn) has been made, values for variables c1, . . . , cn+1
are completely determined, since they follow from the semantics of the multipli-
cation. Functional dependencies arise very often, e.g.,, in all problems for which
an intermediate state has to be maintained, and their detection and exploitation
has been recognized to be of great importance from an eﬃciency point of view,
since it can lead to signiﬁcant reductions of the search space (cf., e.g., [13,1,2]).
The presence of functional dependencies among variables of a CSP highlights
an interesting problem, i.e., that of computing the values of dependent variables
when a choice of the deﬁning ones has been made. It is worth noting that this
problem, always present as a subproblem of a CSP with dependencies, has ex-
actly one solution. Hence, the knowledge of such a promise can be useful to
the solver. It is worth noting that there are also problems which intrinsically
exhibit promises. This is the case of, e.g., Factoring, where we additionally add
the symmetry-breaking constraint forcing x1, . . . , xn to be lexicographically less
than or equal to y1, . . . , yn. This new formulation is guaranteed to have exactly
one solution.
In what follows, we investigate the relations that hold among diﬀerent concepts.
In particular, we reconsider the notions of inconsistency, substitutability and
interchangeability, and propose the concepts of ﬁxable, removable, and implied
value for a given variable, and those of determined, dependent, and irrelevant
variable. These properties make it possible to transform a problem into a simpler
one. Depending on the case, this transformation is guaranteed to preserve all
solutions of the problem, or to preserve at least one if one exists.
In order to give the intuition of some of the properties we are going to deﬁne,
let us reconsider the Factoring problem.
Example 2 (Factoring, Example 1 continued). Let us consider an instance such
that Z is given in binary notation (i.e., b = 2) and with the least signiﬁcant
digit, z1 = 1. This implies that the last digit of both factors X and Y must be 1.
Hence, we can say that value 1 is implied for variables x1 and y1, and that 0 is
removable for them and, more precisely inconsistent. Moreover, for this problem,
which, if the symmetry is broken, has a unique solution, we also know that all
variables x1, . . . , xn and y1, . . . , yn are determined (cf. forthcoming Deﬁnition 1),
regardless of the instance, and because of the functional dependence already
discussed in Example 1, we have that variables encoding carries, i.e., ci (i ∈
[1, n]), are dependent on {x1, . . . xn, y1, . . . , yn}.
⊓⊔

Exploiting Fixable, Removable, and Implied Values in CSP
273
Unfortunately, solving problem instances with unique solutions is likely to remain
intractable (cf., e.g., [22]). But this does not exclude, of course, the possibility
to ﬁnd good heuristics for instances with such a promise, or to look for other
properties that are implied by the existence of unique solutions, that can be
exploited in order to improve the search process. In particular, determined and
implied values play an important role in this and other classes of problems. As
the previous example shows, such problems arise frequently in practice, either as
subproblems of other CSPs, as in presence of functional dependencies, or because
of intrinsic characteristics of the problem at hand. In general, if a problem has
a unique solution, all variables have a determined value.
Another central role is played by the removability property, that characterises
precisely the case when a value can be safely removed from the domain of a
variable, while preserving satisﬁability. This property is of course weaker than
inconsistency, (since some solutions may be lost), but can be safely used in place
of it when we are interested in ﬁnding only a solution of the input CSP, if one
exists, and not all of them.
Unfortunately, detecting the proposed properties is computationally hard in
general. In particular, we show that these tasks are all coNP-complete. This
holds also for Freuder’s substitutability and interchangeability (this result is, to
the best of our knowledge, original). Hence, in order to be able to practically
make the relevant checks during preprocessing and search, we show how some
of the proposed properties can be veriﬁed eﬃciently along two lines: by impos-
ing restrictions on the constraint language, and by exploiting locality, i.e., by
checking them for single constraints.
The outline of the paper is as follows: after recalling some preliminaries, in
Section 2 we formally deﬁne all the properties we are interested in, and discuss
the semantical connections that hold among them. Then, in Section 3 we present
the intractability results of checking such properties. Hence, in Section 4 we show
some tractability results, investigating the two aforementioned approaches in
order to be able to eﬃciently make the required reasoning: imposing restrictions
on the constraint languages, and exploring locality. Finally, in Section 5 we draw
conclusions and address future work.
2
A Hierarchy of Properties
2.1
Preliminaries
Let D be a ﬁnite set of size at least 2. A V -tuple t, where V represents a ﬁnite
set of variables, is a mapping which associates a value tx ∈D to every x ∈V .
A V -relation is a set of V -tuples. A Constraint Satisfaction Problem (CSP) is a
triple ⟨X, D, C⟩where:
– X is a ﬁnite set of variables,
– D associates to every variable x ∈V a domain Dx ⊆D and
– C is a ﬁnite set of constraints, each of which is a V -relation for some V ⊆X.

274
L. Bordeaux, M. Cadoli, and T. Mancini
Given a V -tuple t and a subset U ⊆V of its variables, we denote by t|U
the restriction of t to U, which has the same value as t on the variables of U
and is undeﬁned elsewhere. The explicit assignment of the value of a V -tuple
t on a variable x ∈V to value a is written t[x := a]. The relational operators
of selection, projection and complement will be useful: given a V -relation c, a
subset U of V and a value a ∈Dx, we denote by σx=a(c) (resp. σx̸
=a(c)) the
V -relation which contains the tuples of c whose value on x is a (resp. is diﬀerent
from a), by πU(c) the set of restrictions to U of tuples of c (i.e., the set of
U-tuples {t | ∃t′ ∈c (t = t′|U)}) and by c the set of V -tuples {t | t ̸∈c}.
An X-tuple t satisﬁes a V -relation c ∈C if t|V ∈c. We denote by Sol(c) the
set of X-tuples which satisfy c. The set 
c∈C Sol(c) of X-tuples which satisfy
all the constraints is called the solution space, and denoted Sol(C). The set of
X-tuples t such that tx ∈Dx for all variables x is called the search space and
noted SD, or simply S if the domain is implicit from the context. Note that
σx=a(S) denotes the search space obtained by ﬁxing Dx to {a} if a ∈Dx and is
empty otherwise. For the sake of simplicity, the sets X and C will be considered
as globally deﬁned and shall therefore be omitted from the parameters of most
deﬁnitions; only the search space will be explicitly mentioned.
2.2
Deﬁnitions
Deﬁnition 1. The following properties are deﬁned for a search space S, vari-
ables x and y, values a and b, and for a set of variables V :
ﬁxable(S, x, a) ≡
∀t ∈S (t ∈Sol(C) →t[x := a] ∈Sol(C))
substitutable(S, x, a, b) ≡
∀t ∈S

tx = a ∧t ∈Sol(C) →
t[x := b] ∈Sol(C)

interchangeable(S, x, a, b) ≡
substitutable(S, x, a, b)∧
substitutable(S, x, b, a)
removable(S, x, a) ≡
∀t ∈S

tx = a ∧t ∈Sol(C) →
∃b ̸= a (t[x := b] ∈Sol(C))

inconsistent(S, x, a) ≡
∀t ∈S
t ∈Sol(C) →tx ̸= a)
implied(S, x, a) ≡
∀t ∈S
t ∈Sol(C) →tx = a)
determined(S, x) ≡
∀t ∈S

t ∈Sol(C) →
∀b ̸= tx (t[x := b] ̸∈Sol(C))

dependent(S, V, y) ≡
∀t, t′ ∈S
⎛
⎝
⎛
⎝
t ∈Sol(C)∧
t′ ∈Sol(C)∧
∀x ∈V (tx = t′
x)
⎞
⎠→ty = t′
y
⎞
⎠
irrelevant(S, x) ≡
∀t ∈S

t ∈Sol(C) →
∀a ∈Dx (t[x := a] ∈Sol(C))


Exploiting Fixable, Removable, and Implied Values in CSP
275
In the few cases where an ambiguity arises on the considered set of con-
straints, we will indicate it using subscript (e.g., irrelevantC(S, x)). Note that
all the deﬁnitions but the last three ones are value-oriented, in that they are
properties of particular values of the domain. On the contrary, dependency, ir-
relevance and determinacy are variable-oriented properties which do not directly
express results on particular values of the domains but have important relations
with the value-oriented notions.
The notion of consistency was proposed in [21,19] and is one of the best-
studied notions in CSP. Substitutability and interchangeability were introduced
in [11]. Implied values, which are known as backbones in the literature, were
seemingly ﬁrst explicitly studied in [20]. To the best of our knowledge, the no-
tion of removable and ﬁxable values have on the contrary not been considered.
Determined, irrelevant and dependent variables have been studied in a number
of contexts but we are aware of little work concerning their application in the
context of CSP. The following example illustrates some of the properties.
Example 3. Consider a CSP modeling the colouring problem for the graph below.
Let c1 . . . c4 denote the variables involved, and Σ denote the search space in
which all four variables have domain {R, G, B}. We have:
2
1
3
4
– ﬁxable(Σ,c1,R),
– substitutable(Σ,c1,R,G),
– interchangeable(Σ,c1,R,G),
– removable(Σ,c1,G),
– irrelevant(Σ,c1).
Example 4. Consider a CSP over boolean variables a, b, and c, whose constraints
are written below. Denoting as Ξ the search space in which all variables range
over {true, false}. We have:
a
∧
a →b
∧
(c ∨d) ↔e
– inconsistent(Ξ,b,false),
– implied(Ξ,b,true),
– determined(Ξ,b),
– dependent(Ξ,{c, d},e).
2.3
Semantical Relations
The notions presented in Deﬁnition 1 are semantically connected, and we clarify
here the main relationships that exist between them.
Proposition 1. The relations shown in Figure 2 hold between the properties
deﬁned in Deﬁnition 1.
Proof. (sketch)
dependence-determinacy: we have dependent(S, {x1, . . . , xi}, y) iﬀany solu-
tion t has a value on y which is given by a function f of the values it assigns
to x1 . . . xi, iﬀin any search space σx1=a1...xi=ai(S) (where all these vari-
ables receive a ﬁxed value), all solutions assign the same value f(a1, . . . , an)
to y.

276
L. Bordeaux, M. Cadoli, and T. Mancini
inconsistent(S, x, a) →
∀b ∈Dx substitutable(S, x, a, b)
implied(S, x, a) ↔
∀b ∈Dx \ {a} inconsistent(S, x, b)
dependent(S, {x1 . . . xi}, y) ↔
∀a1 ∈Dx1 . . . ai ∈Dxi determined(σx1=a1...xi=ai(S), y)
irrelevant(S, x) ↔
∀a ∈Dx ﬁxable(S, x, a)
determined(S, x) ↔
∃b ∈Dx implied(S, x, b)
implied(S, x, b) →
ﬁxable(S, x, b)
removable(S, x, a) ←
∃b ∈Dx \ {a} substitutable(S, x, a, b)
inconsistent(S, x, a) →
removable(S, x, a)
ﬁxable(S, x, b) ↔
∀a ∈Dx substitutable(S, x, a, b)
irrelevance
dependence
determinacy
implication
ﬁxability
inconsistency
substitutability
removability
Fig. 2. Relations between the properties
irrelevance-ﬁxability: t ∈Sol(C) →∀a ∈Dx(t[x := a] ∈Sol(C)) rewrites to
∀a ∈Dx(t ∈Sol(C) →t[x := a] ∈Sol(C)).
determinacy-implication: if we have implied(S, x, b) for some b, then for any
t and any a ̸= b we have t[x := a] ̸∈Sol(C). If we have determined(S, x)
and t ∈Sol(C), then implied(S, x, tx) (no t′ with t′
x ̸= tx is in Sol(C)).
implication-ﬁxability: implied(S, x, b) means that every t ∈Sol(C) has tx =
b. Hence for every t ∈Sol(C), we have t[x := b] = t ∈Sol(C).
implication-inconsistency: implied(S, x, a) holds iﬀ∀t (tx ̸= a →t ̸∈Sol(C)),
i.e., iﬀ∀t ∀b ∈Dx \ {a} (tx = b →t ̸∈Sol(C)). This rewrites to ∀b ∈
Dx \ {a} inconsistent(S, x, b).
ﬁxability-substitutability: Let Dx = {a1, .., ad}. We have 
i∈1..d substitu-
table(S, x, ai, b) iﬀ∀t ((tx = a1 ∨· · · ∨tx = ad) ∧t ∈Sol(C) →t[x := b] ∈
Sol(C)), which rewrites to ﬁxable(S, x, v).
inconsistency-substitutability: suppose we have inconsistent(S, x, a). No so-
lution t with tx = a exists, hence the implication tx = a ∧t ∈Sol(C) →. . .
is always valid.
inconsistency-removability: same argument as for inconsistency-substitut-
ability.
substitutability-removability: suppose we have substitutable(S, x, a, b) for
some value b. This can be written ∃b ∀t (tx = a ∧t ∈Sol(C) →t[x := b] ∈
Sol(C)), which implies that ∀t ∃b(tx = a∧t ∈Sol(C) →t[x := b] ∈Sol(C)).
The latter rewrites to ∀t (tx = a ∧t ∈Sol(C) →∃b t[x := b] ∈Sol(C)).

Exploiting Fixable, Removable, and Implied Values in CSP
277
Note also that determined values are strongly related to problems with a
unique solution: if a problem has a unique solution, then all its variables have
an implied value (cf. Example 1).
2.4
Exploiting Properties in Constraint Solving
An important reason why the aforementioned properties are interesting is that,
when detected, they allow us to reduce the search space by removing values.
Two key notions here are inconsistency and removability:
– Suppressing a value a from the domain of a variable x preserves all solutions
(i.e., σx̸
=a(S) ∩Sol(C) = S ∩Sol(C)) iﬀa is inconsistent for variable x.
– Suppressing a value a from the domain of variable x preserves the satisﬁa-
bility of the problem (i.e., σx̸
=a(S) ∩Sol(C) = ∅↔S ∩Sol(C) = ∅) iﬀ
value a is removable from the domain of x.
– Instantiating a value a from the domain of variable x preserves the satisﬁ-
ability of the problem (i.e., σx=a(S) ∩Sol(C) = ∅↔S ∩Sol(C) = ∅) if
value a is ﬁxable for x.
The removability property is therefore weaker than the inconsistency one,
and this shows an interesting beneﬁt: in cases where we do not want to ﬁnd all
solutions of a problem but we simply want to ﬁnd one, removability is the ideal
property to use.
Some of these deﬁnitions can be used to construct solution-preserving map-
pings, i.e., mappings which transform solutions into solutions.
Deﬁnition 2 (solution-preserving transformation). A solution-preserving
transformation is a total mapping τ from S to S such that
∀t ∈S (t ∈Sol(C) →τ(t) ∈Sol(C))
To understand the connection between solution-preserving transformations
and the aforementioned properties, consider the following mappings:
τ1(t) = t[x := a]
τ2(t) =

t[x := b]
if tx = a
t
otherwise
τ3(t) =
⎧
⎪
⎨
⎪
⎩
t[x := b]
if tx = a
t[x := a]
if tx = b
t
otherwise
Checking whether value a is ﬁxable for variable x, whether value a is substi-
tutable to value b for variable x, and whether values a and b are interchangeable
for value x amounts to checking whether mappings τ1, τ2 and τ3 (respectively)
are solution-preserving.
3
Intractability Results
In this section, we show that the problem of checking whether properties deﬁned
in Deﬁnition 1 hold is intractable. From now on, we assume that the input is

278
L. Bordeaux, M. Cadoli, and T. Mancini
given as a set of constraints C over a set of variables X. We also assume that
the problem of checking whether t ∈Sol(C) is polynomial in the size of the
representation of the input. Additionally, we assume that the size of D is ﬁxed.
Such properties hold for propositional logic and for CSPs, in the sense of [8].
We note that the problem of checking each property of Deﬁnition 1 is in coNP,
because it can be done by guessing all tuples in S in non-deterministic polynomial
time, and making the relevant tests in polynomial time (as for interchangeability,
we note that the logical and of two properties in coNP is still in coNP). In the
rest of this section, proofs are therefore restricted to the coNP-hardness part.
Proposition 2 (coNP-completeness of properties of Deﬁnition 1).Given
a CSP, the following tasks are coNP-complete:
– Checking whether value a is ﬁxable, removable, inconsistent, implied, deter-
mined for variable x;
– Checking whether value a is substitutable to, or interchangeable with b for
variable x;
– Checking whether variable y is dependent on variables in V ;
– Checking whether variable x is irrelevant.
Proof. For the sake of simplicity, we give the proofs for ﬁxability and substi-
tutability. The other proofs can be given in a similar way, by using also Proposi-
tion 1. To prove that checking ﬁxability and substitutability are hard for coNP, we
reduce a coNP-complete problem, i.e., that of checking that an arbitrary CSP is
unsatisﬁable, to ﬁxability and substitutability. In particular, the proofs hold even
if the domains are binary, in which case the CSP can be written as a propositional
formula, e.g., in CNF.
Fixability. Let us consider an arbitrary propositional formula φ in CNF, over
variables X, and a variable x ̸∈X. Let ψ be deﬁned as φ ∧¬x. We have that ψ
is unsatisﬁable if and only if φ is unsatisﬁable.
We now show that φ is unsatisﬁable if and only if value true is ﬁxable for x
in formula ψ. Let us ﬁrst assume that φ is unsatisﬁable. It follows that true is
ﬁxable for x in ψ, because ψ has no models.
As for the other direction, by Deﬁnition 1, if true is ﬁxable for x in ψ, then,
every model of ψ remains a model if x is assigned to true. However, since, by
construction, models of ψ never assign true to x, it follows that true is ﬁxable
for x in ψ only if no solutions to ψ exist, hence, only if φ is unsatisﬁable.
Substitutability. Let us consider an arbitrary propositional formula φ in CNF,
over variables X, and a variable x ̸∈X. Let ψ be the deﬁned as φ ∧x. We have
that ψ is unsatisﬁable if and only if φ is unsatisﬁable.
We now show that φ is unsatisﬁable if and only if value true is substitutable
to false for x in ψ. Let us ﬁrst assume that φ is unsatisﬁable. It follows that true
is substitutable to false for x in ψ, because ψ has no models.
As for the other direction, by Deﬁnition 1, if true is substitutable to false for
x in ψ, then, every model of ψ with x assigned to true remains a model if x is
assigned to false. However, since, by construction, models of ψ never assign false

Exploiting Fixable, Removable, and Implied Values in CSP
279
to x, it follows that true is substitutable to false for x in ψ only if no solutions
to φ exist.
It is worth noting that the intractability of checking the above properties
hold also for binary CSPs (i.e., CSPs in which all constraints relate at most two
variables). As an example, the following result holds.
Corollary 1 (coNP-completeness of ﬁxability for binary constraints).
Given a CSP with only binary constraints, checking whether a value a is ﬁxable
for a variable x is coNP-complete.
Proof. Let Φ = ⟨X, D, C⟩be a binary CSP. Consider an arbitrary variable y ̸∈X
and let a and b be arbitrary values. Let Ψ denote the CSP ⟨X′, D′, C′⟩with
X′ = X ∪{y}, D′
x = Dx forall x ∈X, D′
y = {a, b}, and C′ = C ∪{y ̸= a}.
Ψ is binary and, by using the same arguments of the proof of Proposition 2, it
follows that Φ is unsatisﬁable if and only if value a for variable y is ﬁxable for Ψ.
From the observation that a CSP encoding of the graph 3-colourability problem
can be made using only binary constraints, the thesis follows, since checking
unsatisﬁability of this problem (which is coNP-hard) can be reduced into checking
ﬁxability in a binary CSP.
4
Tractability Results
Since detecting any of the properties we are interested in in the paper is a
computationally hard problem, a natural question is to determine special cases
where this can be done eﬃciently. We investigate two approaches: we exhibit
syntactical restrictions which make the problem tractable, and we study local
relaxations of these deﬁnitions which are polynomial-time checkable, and which
therefore provide incomplete algorithms for detecting the property.
4.1
Tractability for Restricted Constraint Languages
A number of syntactical restrictions to the constraint satisfaction problem are
known which make it tractable. For instance, in the case of boolean constraints,
i.e., propositional formulae, the satisﬁability problem becomes tractable if the in-
stance is expressed using only Horn clauses, only dual Horn clauses (i.e., clauses
with at most one negative literal), only clauses of size at most 2, or only aﬃne
constraints (i.e., constraints built using XOR) [24]. It is natural to wonder if
all the properties identiﬁed in Deﬁnition 1 are also easy to determine for these
classes of formulae. This is indeed the case for most of them, and we give a more
general condition under which tractable classes for the consistency property are
also tractable for other properties of our framework. We note that a recent paper
[15] gives a complete characterization of tractable cases for a related property.
We say that a language is closed under instantiation (resp. under comple-
mentation) if whenever a constraint c is expressible in the language, the relation
πX\{x}(σx=a(c)) (resp. the complementation c) is also representable by a con-
junction of constraints of this language. For instance, taking a Horn clause, a

280
L. Bordeaux, M. Cadoli, and T. Mancini
dual Horn clause, a 2CNF clause or an aﬃne constraint, we can express the
relation obtained by instantiating a variable to a value or by complementing the
constraint as a conjunction of constraints of the same type.
Proposition 3. If the satisﬁability problem for the language is tractable and if
the language is closed under complementation and instantiation, then checking
any property among ﬁxability, substitutability, interchangeability, inconsistency,
determinacy or irrelevance is tractable.
Proof. We start by the substitutability property and note that value a is substi-
tutable by b for variable x if
πX\{x}(σx=a(Sol(C)))
⊆
πX\{x}(σx=b(Sol(C)))
This inclusion holds iﬀtx = a∧t ∈Sol(C) →t[x := b] ∈Sol(C). This inclusion
is false, i.e., we do not have substitutability if the set
πX\{x}(σx=a(Sol(C)))
∩
πX\{x}(σx=b(Sol(C)))
(1)
is non empty. Since σx=a(Sol(C)) = σx=a(
c∈C Sol(c)) = 
c∈C(σx=a(Sol(c))),
we have:
πX\{x}(σx=b(Sol(C))) = πX\{x}

c∈C(σx=b(Sol(c)))
Although the projection of an intersection of relations is not equal to the inter-
section of their projections in general, the latter rewrites to:

c∈C
πX\{x}(σx=b(Sol(c)))
This is due to the fact that we select on x before eliminating it by projection.
We only prove the inclusion which does not hold in general: suppose we have
t ∈
c∈C πX\{x}(σx=b(Sol(c))). This means that ∀c ∈C, there exists a tuple
tc such that tc|X\{x} = t and tc ∈σx=b(Sol(c)). It follows that tc
x = b and
that we have indeed a unique t with tx = b and tc|X\{x} = t which is such that
∀c ∈C (t ∈σx=b(Sol(c))), i.e., t ∈πX\{x}(
c∈C(σx=b(Sol(c)))).
Equation (1) is therefore equivalent to:
πX\{x}(σx=a(Sol(c)))
∩

c∈C
πX\{x}(σx=b(Sol(c)))
A solution exists (and we therefore do not have substitutability) if one of the sets
πX\{x}(σx=a(Sol(c)))
∩
πX\{x}(σx=b(Sol(c)))
obtained for every c ∈C has a solution. If the language is closed under instanti-
ation and complement, we can express the new constraint πX\{x}(σx=a(Sol(c)))
as a constraint c′ of the language. Each of the sets has a solution iﬀthe CSP
⟨X, D, {σx=a(c) | c ∈C} ∪{c′}⟩is satisﬁable. We have reduced the substitutabil-
ity testing problem to solving m instances of a constraint satisfaction problem
whose constraints are all in the original language, which is tractable.

Exploiting Fixable, Removable, and Implied Values in CSP
281
The result for the ﬁxability, interchangeability and irrelevance properties fol-
lows directly. Consistency of value a for variable x can directly be expressed as
the satisﬁability of πX\{x}(σx=a(Sol(C))), which can be expressed in the language
since we assume closure under instantiation, and the proofs for the implication
and determinacy properties follow from this result.
A slightly diﬀerent closure property is needed for the removability of value a
for variable x since it is expressed as πX\{x}(Sol(C)) ⊆πX\{x}(σx̸
=a(Sol(C))).
Nevertheless, since on boolean domains a value v is removable if v is sub-
stitutable by ¬v, and from the remarks on the closure properties of Schaefer’s
classes, and the previous proposition, we obtain that:
Corollary 2. Testing ﬁxability, substitutability, interchangeability, inconsis-
tency, determinacy, irrelevance and removability is tractable for a boolean CSP
where constraints are either Horn clauses, dual Horn clauses, clauses of size at
most two or aﬃne constraints.
4.2
Tractability Through Locality
An important class of incomplete criteria to determine in polynomial time
whether a complex property holds are those based on local reasoning. This
approach has proved extremely successful for consistency [19] and interchange-
ability [11] properties. We propose in this section a systematic investigation of
whether a local approach can be used for value-based properties.
Verifying a property P(C) of a set of constraints C locally means that we
verify the property on a well-chosen number of sub-problems. We must ensure
that this approach is sound for the considered property:
Deﬁnition 3 (soundness of local reasoning). We say that local reasoning
on a property P is sound if, for all subsets of constraints C1 ⊆C, . . . , Ck ⊆C
such that 
i∈1..k Ci = C, we have

i∈1..k P(Ci)
→P(C)
Note that if a property P satisﬁes this requirement, its negation satisﬁes a
stronger soundness property:

i∈1..k ¬P(Ci)
→¬P(C). A typical choice of
granularity is to simply consider that each Ci contains one of the constraints of
C as is done, for instance, for arc-consistency. On the other extreme, if we take a
unique C1 = C, we have a global checking. Between these two extremes, a wide
range of intermediate levels can be deﬁned [10,11].
Reasoning locally is typically tractable if we focus on a moderate number
of subsets of C, and under the condition that we can bound the complexity
of reasoning on each of these subsets. A typical assumption in CSP is that we
can bound the arity of the constraints, and that every constraint is for instance
binary. In this case, the cost of determining any property of the constraint is
polynomial (here again we are indeed polynomial in the domain size, we therefore
assume that the input is represented in a way polynomial in the domain size, for

282
L. Bordeaux, M. Cadoli, and T. Mancini
instance with the domains listed explicitly); and if we choose to reason locally
by considering each constraint separately, or by taking groups of constraints of
bounded size, then local checking is tractable.
Proposition 4. Local reasoning is sound for the properties of substitutability,
interchangeability, ﬁxability, inconsistency and implication.
Proof. The result is well-known for consistency [19], substitutability and inter-
changeability [11]. Fixability of variable x to value b can be expressed as
∀a ̸= b (substitutableC(S, x, a, b))
Therefore, if we have 
i∈1..k ﬁxableCi(S, x, b) (which is equivalent to 
i

a̸
=b
substitutableCi (S, x, a, b) and to 
a̸
=b

i substitutableCi (S, x, a, b)), then we
have 
a̸
=b substitutableC(S, x, a, b), which means ﬁxableC(S, x, b). The impli-
cation property satisﬁes the following, stronger property (which implies that local
reasoning is sound):

i∈1...m impliedCi (S, x, a)
→
impliedC(S, x, a)
In eﬀect, if a value a is implied for variable x in any Ci, then all tuples t with
tx ̸= a violate the constraints of Ci and do a fortiori not belong to Sol(C).
There is only one property, namely removability, for which the local approach
is unfortunately not sound:
Proposition 5. Local reasoning is not sound for the removability property.
Proof. Take C = C1∧C2, where C1 is deﬁned as x ≤y and C2 as x ≥y. Suppose
the domain has values {1, 2, 3}. Value 2 for x is removable from both constraints
considered independently since, in both cases, we can change the value of any
solution which assigns 2 to x to another value. Still, value 2 is not removable
from their conjunction.
Note that removing values which are shown to be removable only locally can
even make a satisﬁable problem unsatisﬁable: if furthermore we add the con-
straints C3, deﬁned as x ̸= 1 and C4, deﬁned as x ̸= 3, then value 2 for x is
removable in each constraint, while the only (global) solution actually has value
2 on x.
This proposition raises an interesting issue: does there exist new (i.e., other
than the special cases of substitutable and inconsistent values) properties for
which local reasoning is sound and which imply removability?
We end this section by noting that the local version of the ﬁxability property
is indeed a generalisation for arbitrary domains of the pure literal rule [7] which
is well-known in the case of boolean constraints in conjunctive normal form. The
pure literal rule exploits the cases where no constraint (clause) of the problem has
a positive (resp. negative) occurrence of some variable x. In this case, assigning
value 0 (resp. 1) to x preserves the satisﬁability of the problem: if a solution t
with tx = 1 exists, then t[x := 0] will also be a solution since no clause constrains
x to have value 1. It is clear that the pure literal rule is a rule to detect ﬁxability
based on a reasoning local to each clause (a variable x is ﬁxable to, say, 1 in a
clause iﬀthis clause does not contain the literal ¬x, and the pure literal rule
checks that this condition holds for every constraint).

Exploiting Fixable, Removable, and Implied Values in CSP
283
5
Conclusions and Perspectives
In this paper we focused on structural properties of CSPs that can be exploited
by the solver in order to simplify search. Starting from the well-known notions of
inconsistency and substitutability, we propose removability as a property which
subsumes both of them, as well as several new others, e.g., ﬁxability, which are
particularly interesting if we want to ﬁnd just a solution of the input CSP, and
not to compute all of them. By classifying these properties in a uniﬁed hierarchy,
we investigated the semantical connections among them, and provided a ﬁrst step
towards a comprehensive framework. Note that our central deﬁnitions are value-
based and that more general deﬁnitions inspired from the tuple-based notion of
substitutability proposed in [14] could be considered in future work.
Then, we tackled the questions related to their automated detection and of
their exploitation by the solving engine for simplifying problems. In particular,
we showed how detecting all the proposed properties is generally intractable,
but, for many of them, it becomes polynomial-time in two cases: by restricting
the constraint languages, and by exploiting locality. Moreover, we discussed how
in some cases such properties may arise from explicit promises made by users.
This is the case of problems with properties such as functional dependencies and
unique solutions.
Two of the perspectives raised by our work concern the new properties which
have emerged from it. We have identiﬁed the removability property as an ideal
characterisation of the values which can be removed while preserving satisﬁabil-
ity. Unfortunately, negative results (coNP-completeness of the detection of this
property and impossibility of local reasoning) make it impossible to directly use
the removability property in practice. This justiﬁes the use of weaker notions (like
inconsistency or substitutability) which imply the removability property, yet can
be checked by tractable means (of course at the price of losing completeness).
An interesting problem is to determine new cases where removability-checking is
tractable. Lastly, the beneﬁts of ﬁxability have long been known in the boolean
case, since this property has been used in the form of the pure literal rule in
many SAT solvers. Its generalisation to CSPs has not yet been considered, and
will be the subject of future work. Another issue we intend to explore is the ap-
plication of the properties of Deﬁnition 1 to problems not in NP, e.g., to model
checking of formulae of temporal logic or quantiﬁed boolean formulae.
Acknowledgements. Work partially supported by project ASTRO funded by
the Italian Ministry for Research under the FIRB framework (funds for basic
research), and by a COFIN/PRIN project. We thank the reviewers for their
careful reading which helped us improving the paper.
References
1. M. Cadoli and T. Mancini. Exploiting functional dependencies in declarative prob-
lem speciﬁcations. In 9th Euro. Conf. on Logic in Artiﬁcial Intelligence (JELIA),
pages 628–640. Springer, 2004.
2. M. Cadoli and T. Mancini. Using a theorem prover for reasoning on constraint
problems. In 3rd Int. CP Workshop on Modelling and Reformulating CSPs, 2004.

284
L. Bordeaux, M. Cadoli, and T. Mancini
3. B. Choueiry, A. Lal, and E. C. Freuder. Interchangeability and dynamic bundling
for non-binary ﬁnite CSPs. In Int. Workshop on Constraint Solving and Constraint
Logic Programming (CSCLP), page To appear. Springer, 2004.
4. B. Choueiry and G. Noubir. On the computation of local interchangeability in dis-
crete constraint satisfaction problems. In Nat. (US) Conf. on Artiﬁcial Intelligence
(AAAI), pages 326–333. AAAI, 1998.
5. J. M. Crawford. A theoretical analysis of reasoning by symmetry in ﬁrst-order
logic (extended abstract). In AAAI Workshop on Tractable Reasoning, 1992.
6. J. M. Crawford, M. L. Ginsberg, E. M. Luks, and A. Roy. Symmetry-breaking
predicates for search problems. In Int. Conf. on Principles of Knowledge Repre-
sentation and Reasoning (KR), pages 148–159. Morgan Kaufmann, 1996.
7. M. Davis and H. Putnam. A computing procedure for quantiﬁcation theory. J. of
the ACM, 7(3):201–215, 1960.
8. R. Dechter. Constraint networks (survey). In Encyclopedia of Artiﬁcial Intelligence,
2nd edition, pages 276–285. 1992.
9. S. Even, A. Selman, and Y. Yacobi. The complexity of promise problems with
applications to public-key cryptography. Information and Control, 61(2):159–173,
1984.
10. E. C. Freuder.
Synthesizing constraint expressions.
Comm. of the ACM,
21(11):958–966, 1978.
11. E. C. Freuder. Eliminating interchangeable values in constraint satisfaction prob-
lems. In Nat. (US) Conf. on Artiﬁcial Intelligence (AAAI), pages 227–233. AAAI
Press, 1991.
12. I. P. Gent and B. M. Smith. Symmetry breaking in constraint programming. In
Euro. Conf. on Artiﬁcial Intelligence (ECAI), pages 599–603. IOS Press, 2000.
13. E. Giunchiglia, A. Massarotto, and R. Sebastiani. Act, and the rest will follow: Ex-
ploiting determinism in planning as satisﬁability. In Nat. (US) Conf. on Artiﬁcial
Intelligence (AAAI), pages 948–953. AAAI, 1998.
14. P. Jeavons, D. A. Cohen, and M. C. Cooper. A substitution operation for con-
straints. In Int. Conf. on Principles and Practice of Constraint Programming (CP),
pages 1–9. Springer, 1994.
15. P. Jonsson and A. Krokhin. Recognizing frozen variables in constraint satisfaction
problems. Theoretical Computer Science (TCS), 329(1-3):93–113, 2004.
16. J. K¨obler, U. Sch¨oning, and J. Tor´an. The graph isomorphism problem: its com-
putational complexity. Birkhauser, 1993.
17. A. Lenstra and H. W. Lenstra. Algorithms in number theory. In J. van Leeuwen,
editor, The Handbook of Theoretical Computer Science, vol. 1: Algorithms and
Complexity. MIT Press, 1990.
18. C. M. Li. Integrating equivalency reasoning into Davis-Putnam procedure. In Nat.
(US) Conf. on Artiﬁcial Intelligence (AAAI), pages 291–296. AAAI press, 2000.
19. A.K. Mackworth.
Consistency in networks of relations.
Artiﬁcial Intelligence,
8:99–118, 1977.
20. R. Monasson, R. Zecchina, S. Kirkpatrick, B. Selman, and L. Troyansky. Deter-
mining computational complexity from characteristic ‘phase transitions’. Nature,
400:133–137, 1999.
21. U. Montanari. Networks of constraints: Fundamental properties and applications
to picture processing. Information Science, 7(2):85–132, 1974.
22. Ch. H. Papadimitriou. Computational Complexity. Addison Wesley, 1994.
23. T. Pyh¨al¨a.
Factoring benchmarks for SAT solvers.
Technical report, Helsinki
university of technology, 2004.
24. T. J. Schaefer. The complexity of satisﬁability problems. In ACM Symp. on Theory
of Computing (STOC), pages 216–226. ACM, 1978.

Evaluating QBFs via Symbolic Skolemization
Marco Benedetti§
Istituto per la Ricerca Scientiﬁca e Tecnologica (IRST)
Via Sommarive 18, 38055 Povo, Trento, Italy
benedetti@itc.it
Abstract. We describe a novel decision procedure for Quantiﬁed Boolean For-
mulas (QBFs) which aims to unleash the hidden potential of quantiﬁed reasoning
in applications. The Skolem theorem acts like a glue holding several ingredients
together: BDD-based representations for boolean functions, search-based QBF
decision procedure, and compilation-to-SAT techniques, among the others. To
leverage all these techniques at once we show how to evaluate QBFs by symboli-
cally reasoning on a compact representation for the propositional expansion of the
skolemized problem. We also report about a ﬁrst implementation of the procedure,
which yields very interesting experimental results.
1
Introduction
Unquestionably, the most effective tools for solving a large class of industrial-scale prob-
lems (such as computer-aided design of integrated circuits [19], Planning [17], Model
Checking for dynamic systems [5], Scheduling, Operations Research, and Cryptogra-
phy, to name a few) are SAT solvers, which are search-based reasoning engines designed
to decide the existence of models for propositional instances (PROP).
One step ahead of PROP, we encounter the more expressive language of quantiﬁed
boolean formulas (QBFs), which adds the valuable possibility to quantify (universally or
existentially) over the truth value of variables. Many of the problems mentioned above
feature a far more handily QBF formulation, which is also (possibly) exponentially more
succinct than the propositional one. For sure, by sticking to PROP we avoid worsening
the decision complexity from NP to PSPACE. But, we also loose the expressive power
of quantiﬁcation, which not only provide a natural way to state relevant facts or rules,
but could also be exploited during the solving process. At least in principle.
What really matters to applications is the capability of a reasoning engine to solve
those problems that arise in practice. Hence, we ask: Is the balance between the above
pros and cons favorable to QBF? Do quantiﬁed decision procedures add substantial value
to the reasoning capabilities of purely propositional SAT solvers? The answer is: not yet.
QBF is a promising formalism, but substantial improvements in decision procedures are
expected before its potential can be unleashed to applications [1, 21, 4].
The observations above motivates this paper, in which we describe a new solving
paradigm that captures the added value of quantiﬁed reasoning. A twofold novelty is
introduced. On the one hand, we reinterpret the Skolem theorem to reassess quanti-
ﬁed reasoning as a quantiﬁer-free, propositional reasoning over a purposely designed
§ This work was supported by PAT (Provincia Autonoma di Trento, Italy), grant n. 3248/2003.
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 285–300, 2005.
c⃝Springer-Verlag Berlin Heidelberg 2005

286
M. Benedetti
symbolic representation. We show how this allows to mix (1) the inference power of
quantiﬁed reasoning, (2) the strength of many well known SAT techniques, and (3) the
classical search-based decision procedures for QBF. On the other hand, several powerful
techniques for automated reasoning are arranged within a coherent framework in a way
that is advantageous and instrumental in realizing the just mentioned approach.
The essential component of our construction traces back to the Twenties (the Skolem
theorem [31]). Following the timeline, we capitalize on the seminal contributions to
propositional theorem proving from the Sixties (DPLL algorithms [9, 10]). Then, a
compact formalism from the Eighties to reason on boolean functions [6] is employed.
Effective quantiﬁed reasoning comes from the Nineties [7, 18]. In the same years, tech-
niques to translate real-world problems into SAT arised [17, 19, 5] which are adapted to
our case. Finally, symbolic representations for propositional problems gained attention
in the last few years [8, 25, 28], and are largely useful here. These techniques are ex-
ercised together thank to a symbolic representation for the propositional expansion of
skolemized QBF instances, also resorting to SAT-based reasoning when it pays back.
Intherestofthispaperweintroducesomepreliminaries(Section2),presentsymbolic
skolemization (Section 3), discuss symbolic reasoning strategies (Section 4), analyze
experimental results (Section 5), and give our concluding remarks (Section 6).
2
Preliminaries
We consider quantiﬁed boolean formulas in prenex conjunctive normal form1, such as
f = ∀a∃b∀c∃d. (¬a ∨c ∨d) ∧(¬b ∨¬d) ∧(a ∨b ∨¬d) ∧(¬a ∨b)
(1)
where “∀a∃b∀c∃d" is called preﬁx and is followed by a conjunctive normal form (CNF)
matrix, i.e. a propositional formula made up by conjuncting clauses, each clause being
a disjunction of literals (a variable or a negated variable). More in general, we consider
formulas Q1V1Q2V2 . . . QnVn. M where Qi ∈{∀, ∃}, Qi ̸= Qi+1, and the matrix M
has variables var(M) = ∪n
i=1Vi (Vi ∩Vj = ∅for i ̸= j). Variables v ∈Vi are said
to be existentially (universally) quantiﬁed if Qi = ∃(Qi = ∀). The set of existentially
(universally) quantiﬁed variables in a QBF f is denoted by var∃(f) (var∀(f)). The
universal depth δ(v) of an existential variable v ∈Vi is the number of universal variables
dominating v: δ(v) = 
Qj=∀,j<i |Vj|. For clauses, it is δ(Γ) = maxv∈var∃(Γ )δ(v).
We use lowercase (uppercase) roman letters for propositional variables (clauses),
and greek letters for values in the boolean space B = {0, 1} and vectors in Bn. For
example: Ψ = ⟨ψ1, . . . , ψn⟩∈I ⊆Bn. The complement of I ⊆Bn is denoted by I.
Double negation on literals is disallowed: ¬¬l is rewritten as l. We use exclusive-or
to build literals out of variables: ϕ⊗v means v when ϕ = 0, and ¬v when ϕ = 1. Given
a literal l = ϕ ⊗v, we pose var(l) = v. An assignment is a consistent set of literals
(i.e. a set S such that ∄l ∈S| ¬l ∈S). We denote by C ∗l the result of applying the
assignment {l} to the clause C. C is unchanged if var(l) ̸∈var(C), is subsumed if
l ∈C, and resolves to C \ {¬l} if ¬l ∈C. This notion is extended to sets of clauses
and literals: f ∗A is the formula resulting from applying A to each clause in f.
1 This choice causes no loss of generality and is shared by all the available encodings of real-world
problems [15]. However, it might be responsible for an increase in proof complexity.

Evaluating QBFs via Symbolic Skolemization
287
Finally, forall reduction is a model preserving transformation for QBFs that consists
in removing from each clause C all the universal literals π⊗v ∈C with v ∈Vi such
that var∃(C) ∩Vj = ∅for every j > i. We always consider forall-reduced formulas.
3
Symbolic Propositional Skolemization for QBFs
We leverage the Skolem theorem to map any QBF instance onto a satisﬁability equiv-
alent SAT instance featuring a very compact symbolic representation. We interleave the
development of the general method with the presentation of a running example.
3.1
Propositional Skolemization
The Skolem theorem [31] shows how to transform any given First Order Logic (FOL)
statement f into a skolemized formula Sk(f) that has two properties: (1) Sk(f) contains
no existential quantiﬁer, and (2) Sk(f) is satisﬁable iff f is satisﬁable (see [12] for a
survey). Existential quantiﬁers are eliminated by replacing the variables they bind with
Skolem functions whose deﬁnition domains are appositely chosen to preserve satisﬁa-
bility. We empoly an outer form of skolemization [26], in which the function introduced
for e ∈var∃(f) depends on all the universal variables that have e in their scope (for
prenex formulas: all the universal variables to the left of e in the preﬁx).
Functions have no direct representation in PROP, but their deﬁnability can be
captured at the expense of a possibly exponential blowup in the size of the instance.
We adopt a three-step propositional skolemization for a QBF instance f.
1. Translation of f into a satisﬁability equivalent FOL instance FOL(f).
2. Application of the Skolem theorem to FOL(f) to obtain a (satisﬁability preserving)
FOL instance Sk(FOL(f)) with no existential quantiﬁer.
3. Translation of Sk(FOL(f)) into an equivalent SAT instance Prop(Sk(FOL(f))).
The ﬁrst step is a slight rephrase of the problem, but it allows us to plainly capture the
intuition behind propositional skolemization. Skolem funtions leverage the existence of
two semantics levels in FOL, namely the level of predicates and the level of terms.
Skolem functions are terms that are substituted for other terms (the existential variables)
as arguments of predicates. QBF and PROP lack the formal mechanisms necessary to
cope with those two levels. They just feature the predicate level, though this is obfuscated
by their variable-oriented syntax. To uncover such level, we introduce a FOL unary
predicate p deﬁned over the boolean space B, and interpreted as p(1) = TRUE,
p(0) = FALSE, and restrict the domain of interpretation of every variable to be
the boolean space as well. This immediately allows us to rewrite every QBF as a
satisﬁability equivalent FOL formula. For example, by rewriting the QBF (1) we obtain
f ′ = FOL(f) = ∀a∃b∀c∃d. (¬p(a) ∨p(c) ∨p(d)) ∧(¬p(b) ∨¬p(d))
∧(p(a) ∨p(b) ∨¬p(d)) ∧(¬p(a) ∨p(b))
In the second step we eliminate existential quantiﬁers by substituting to each existential
variable v a Skolem function sv depending on the proper subset of dominating universal
quantiﬁers. We obtain a satisﬁability-equivalent purely universal formula.
Sk(f ′) = ∀a∀c. (¬p(a) ∨p(c) ∨p(sd(a, c))) ∧(¬p(sb(a)) ∨¬p(sd(a, c)))
∧(p(a) ∨p(sb(a)) ∨¬p(sd(a, c))) ∧(¬p(a) ∨p(sb(a)))
(2)

288
M. Benedetti
From a FOL point of view, existential quantiﬁers are simply disappeared. The dute we
pay for this simpliﬁcation is the loss of logical equivalence. From a higher-level point
of view, we can predicate over the interpretation of terms and explicitly state what the
Skolem theorem implicitly says when it reduces the satisﬁability of FOL(f) to the
satisﬁability of Sk(FOL(f)), i.e. that each inner existential FOL quantiﬁcation over
v has been substituted by an outer higher-order existential quantiﬁcation over sv (over
the existence of a proper interpretation for the Skolem terms). Informally:
∀a∃b∀c∃d. f(a, b, c, d)
SAT
⇐⇒
[∃sb∃sd]∀a∀c. f(a, sb(a), c, sd(a, c))
In the third step (translation to PROP), the actual work is done. It amounts to ﬂat-
ten the two semantics levels introduced above onto one single propositional level.
This transformation is made easy by the constructive property that for every formula
Sk(FOL(f)) with f ∈QBF both the predicate-level and the term-level interpretations
map boolean spaces onto boolean values. We join their deﬁnition spaces and interpreta-
tionfunctions,andgiveaninductivetranslationprocedurefromSk(FOL(f))toPROP.
The only non-trivial piece of work consists of building a CNF propositional repre-
sentation for every (possibly negated) Skolem term. As a constructive consequence of
steps 1-2, every Skolem function s(a1, a2, . . . , an) we manage is a relation over Bn+1
that maps Bn onto B. Each one is completely speciﬁed by 2n boolean parameters giving
the truth value of the function on each point of its domain, so 22n different Skolem n-ary
functions exist. Let us denote by sΨ the boolean parameter that represents the truth value
of a boolean n-ary function s evaluated in Ψ = ⟨ψi, ψ2, . . . , ψn⟩∈Bn. We directly
obtain a CNF propositional version for s(a1, a2, . . . , an) as follows:
Prop(ϕ⊗s(a1, . . . , an)) .=

Ψ∈Bn
(ϕ⊗sΨ) ∨¬(ψ1⊗a1) ∨¬(ψ2⊗a2) ∨· · · ∨¬(ψn⊗an)
For example, the Skolem terms ¬sb(a) and sd(a, c) are translated as Prop(¬sb(a)) =
(¬sb
0 ∨a)∧(¬sb
1 ∨¬a), and Prop(sd(a, c)) = (sd
11 ∨¬a∨¬c)∧(sd
10 ∨¬a∨c)∧(sd
01 ∨
a ∨¬c) ∧(sd
00 ∨a ∨c). So, Prop(sd(a, c)) may be seen as a function mapping a point
⟨α, γ⟩∈B2 onto the proper value sd
αγ = sd(α, γ), and the same for Prop(¬sb(a)).
The next step extends the translation from terms to predicates. Let us ﬁrst consider
a clause containing only one existentially quantiﬁed variable e with polarity ϕ:
∀u1∀u2 · · · ∀un∃e. (π1⊗ui1) ∨(π2⊗ui2) ∨· · · ∨(πr⊗uir) ∨(ϕ⊗e)
where u1, u2, . . . , un are all the universal variables dominating e, while a subset ui1, ui2,
. . . , uir, r ≤n of such variables appears in the clause with polarities π1, π2, . . . , πr.
By substituting for e the expansion Prop(ϕ ⊗s(u1, . . . , un)) of the Skolem function
s : Bn →B deﬁned by the 2n parameters {s0...00, s0...01, · · · , s1...11}, we obtain:
∃s0...00∃s0...01 · · · ∃s1...11
∀u1∀u2 · · · ∀un
(π1⊗ui1) ∨(π2⊗ui2) ∨· · · ∨(πr⊗uir)∨
∨

Ψ∈Bn(ϕ⊗sΨ) ∨¬(ψ1⊗u1) ∨· · · ∨¬(ψn⊗un)

As a consequence of the semantics ﬂattening we have performed, the “meta" existential
quantiﬁer over an n-ary Skolem function has been transformed into a set of 2n outer
existential quantiﬁers. In the worst case, we have to distribute the disjunction over all
the clauses in the last term, thus obtaining 2n clauses. Fortunately, some (many) of those

Evaluating QBFs via Symbolic Skolemization
289
clauses are trivially satisﬁed by complementary literals. In particular, whenever ψij = πj
for at least one j ∈{1, . . . , r}, the clause is satisﬁed, so that we get only 2n−r = 2δ(e)−r
clauses. Moreover, skolemized clauses no longer contain existential variables dominated
by universal variables, hence all the universal literals are forall reducible. As a result of
these two properties, we obtain the set of unit clauses:
∃s0...00∃s0...01 · · · ∃s1...11.

Ψ∈I
ϕ⊗sΨ,
where I = {Ψ ∈Bn|∀j.ψij ̸
= πj}
In the general case we have clauses containing m existential variables {e1, e2, . . . , em}
with δ(e1) ≤δ(e2) ≤. . . ≤δ(em) and polarities ϕ1, . . . , ϕm, where each ei is domi-
nated by a set ∪i
j=0Uj of universal variables. Each clause also contains a possibly empty
subset of universal literals {πk⊗uk, k = ij−1 + 1, . . . , ij} ⊆Uj for each j = 1, . . . , m,
with i0 = 0. The general shape for the clause is
∀U1∃e1 · · · ∀Um∃em.
(π1⊗ui1) ∨· · · ∨(πj1⊗uij1 ) ∨(ϕ1⊗e1) ∨
(πj1+1⊗uij1+1) ∨· · · ∨(πj2⊗uij2 ) ∨(ϕ2⊗e2) ∨
...
(πjm−1+1⊗uijm−1+1) ∨· · · ∨(πjm⊗uijm ) ∨(ϕm⊗em)
(3)
By (a) propositionally skolemizing all the existential variables in such clause, and (b)
applying forall reduction to all the variables in ∪m
j=0Uj, we obtain:
∃S1 · · · ∃Sm.

Ψ ∈Bδm
∀j.ψij ̸
= πj
(ϕ1⊗s(1)
Ψ|δ1 ) ∨(ϕ2⊗s(2)
Ψ|δ2 ) ∨· · · ∨(ϕm⊗s(m)
Ψ|δm )
(4)
where Ψ|k denotes the k-bit long preﬁx of Ψ, δi = δ(ei), the boolean parameter s(i)
Ψ ′
represents the truth value over Ψ ′ = Ψ|δi ∈Bδi of the Skolem function s(i) introduced
for ei, and Si = {s(i)
Ψ | Ψ ∈Bδi}. The abstraction operator “|” generalizes to sets as
I|k .= {⟨ψ1 . . . , ψk⟩|∃⟨ψ1, . . . , ψk, . . . , ψn⟩∈I} with I ⊆Bn and k ≤n.
We denote by PropSk(·) the function that applied to a generic QBF clause rep-
resented by Expression (3) yields the result of our three-step translation, i.e. the set of
clauses represented by Expression (4). The cardinality of this clause set is 2δ(em)−jm.
To translate an entire formula, we observe that Skolem terms are introduced once
per variable. So, the propositional skolemization of any formula is obtained by joining
together the skolem clauses obtained out of each QBF clause, always re-using the same
parameters on the same existential variable. The overall procedure deﬁnes a satisﬁability-
preserving mapping PropSk : QBF −→PROP between the original QBF space and
a purely propositional space. For a QBF f with var∃(f) = {e1, . . . , em}, the PROP
instance is deﬁned over the set of fresh variables {s(i)
Ψ , i = 1, . . . , m, Ψ ∈Bδ(ei)}.
As an example, by propositionally skolemizing (1) we obtain
∃sb
0∃sb
1∃sd
00∃sd
01∃sd
10∃sd
11. (sd
01) ∧(¬sb
0∨¬sd
00) ∧(¬sb
0∨¬sd
01) ∧(¬sb
1∨¬sd
10)
∧(¬sb
1∨¬sd
11) ∧(sb
1∨¬sd
10) ∧(sb
1∨¬sd
11) ∧(sb
0)
(5)
If (and only if) we ﬁnd a model for (5) we are entitled to conclude that (2) is satisﬁable,
so that (1) evaluates to TRUE. Not only we are ensured that a proper interpretation for
the Skolem functions sb and sd do exist to satisfy the formula, but we have explicitily
computed such an interpretation. Every model for (5) gives us the desired truth value of
acceptable skolem functions over each point of their domains.

290
M. Benedetti
3.2
Symbolic Representation
The term “symbolic representation" has a broad AI-related sense, but it has been used
with a much more speciﬁc meaning in the realm of model checking (MC). According
to MC’s usage of the word, a symbolic representation is one that allows to shift from
explicit MC techniques—where each state of a system to be checked is individually
represented and manipulated—to symbolic MC approaches—where data structures are
employed that allow to compactly and implicitly represent (possibly huge) sets of states,
and also to reason about them as a whole. We adopt MC’s viewpoint here, as we are
interested in symbolically representing and manipulating sets of clauses.
This interest originates in the observation that PropSk(f) may be exponentially
larger than f. Without some powerful tool for compactely representing and managing
propositional skolemizations, not only it may be unfeasible to solve the resulting SAT
instances, but they might not even ﬁt into the memory of any real machine.
Related approaches exist in the literature (see Section 6), but we have to manage
a very special case here, and we want to proﬁt from its structure. In particular, we are
only interested in representing clause-sets coming from propositional skolemization of
QBF formulas, with a representation that is closed under the operations we deﬁne in
the next section. Our representation employes one single symbolic clause to compactly
represent the whole clause set described by the Expression (4) w.r.t. the QBF clause C
described in Expression (3). We need to memorize three pieces of information:
1. The list Γ = [ϕ1⊗e1, . . . , ϕm⊗em] of existential literals in the originating clause.
2. The set of indexes I = {Ψ ∈Bδ(em) | ∀j.ψij ̸= πj}.
3. The list [δ(e1), . . . , δ(em)] of the universal depths of each existential literal.
The information in Item 3 is not related to a single clause. Rather, it is an attribute of
the formula as a whole that only depends on the preﬁx, and that needs to be represented
once per formula. By contrast, the couple ⟨Γ, I⟩actually deﬁnes a symbolic clause
Symb(C) which we compactly denote by writing ΓI. The Symb(·) transformation
is readily extended to QBF instances as Symb : QBF −→PROPSY MB, where
PROPSY MB denotes the space of symbolic propositional instances. It is
Symb(∀U1∃e1 · · · ∀Um∃em.M) .= ∃[e1]δ1 · · · ∃[em]δm.

C∈M
Symb(C)
(6)
where ∃[e1]δ1 · · · ∃[em]δm is a symbolic preﬁx mentioning a symbolic variable [ei]δi for
each original existential variable ei at universal depth δi = δ(ei).
For example, the symbolic representation of the QBF formula (1) is:
F = ∃[b]1∃[d]2. [d]{10} ∧[¬b, ¬d]{00,01,10,11} ∧[b, ¬d]{00,01} ∧[b]{1}
(7)
Each symbolic clause is made up of symbolic literals, that we represent as symbolic unit
clauses. For example, the clause [b, ¬d]{00,01}, under the preﬁx ∃[b]1∃[d]2, is made up
by the symbolic literals [b]{0} and [¬d]{00,01}. A symbolic literal [ϕ⊗e]I belongs to a
symbolic clause ΓJ , written [ϕ⊗e]I ∈ΓJ , when ϕ⊗e ∈Γ and I ⊆J |δ(e). As opposite
to symbolic objects, the standard propositional elements are called ground objects. For
example, the ground literals ¬d00 and ¬d01 belong to the symbolic literal [¬d]{00,01},
while the ground clauses b0 ∨¬d01 and b0 ∨¬d00 belongs to [b, ¬d]{00,01}.

Evaluating QBFs via Symbolic Skolemization
291
Symbolic formulas have both a symbolic size and a ground size. The symbolic size
of F is the number of symbolic clauses (or literals) in the formula. The ground size
is the number of clauses (or literals) in Prop(F). So, the symbolic size (number of
clauses) for a symbolic formula F is |F|symb = 
ΓI∈F |Γ|, while its ground size is
|F|ground = 
ΓI∈F |I|. For example, the formula (7) has symbolic size equal to 4 and
ground size equal to 8. The ground size is always greater than the symbolic size, as each
symbolic clause represents at least one ground clause.
Symbolic formulas exhibit three appealing properties: (1) they preserve the satisﬁ-
ability of the originating QBF instance, (2) they are compactly representable, and (3)
they can be efﬁciently manipulated to perform deductions. We here consider the ﬁrst
two properties, and delay the discussion on the third one until the next section.
Semantics for Symbolic Formulas. We deﬁne an evaluation mechanism for symbolic
formulas based on the standard evaluation of their propositional expansion. According
to Expression (4), we can re-gain the ground meaning of ΓI = [ϕ1⊗e1, . . . , ϕm⊗em]I
under the relevant preﬁx P = ∃[e1]δ1 · · · ∃[em]δm through a function Prop deﬁned as
Prop(P, ΓI) .=

Ψ∈I
ϕ1⊗s(1)
Ψ|δ1 ∨. . . ∨ϕm⊗s(m)
Ψ|δm
(8)
This function is extended to a symbolic formula F with matrix M and preﬁx P by posing
Prop(F) .= 
ΓI∈M Prop(P, ΓI). In particular, a consistent set of symbolic literals
{[e1]I1, . . . , [ek]Ik} is a model for F = P. M = Symb(f), f ∈QBF iff the ground
assignment ∪j=1,...,kProp(P, [ej]Ij) is a model for Prop(Symb(f)). By construction,
it is Prop(Symb(f)) = PropSk(f), hence the QBF f evaluates to TRUE iff Symb(f)
is satisﬁable. For example, the Prop function applied to (7) yields (5).
Compact Representation. The (possible) exponential blowup in every symbolic clause
ΓI has been purposely conﬁned to the cardinality of I. We pursue compactness for its
symbolic representation, notwithstanding its ground size, by employing a second layer of
abstraction, consisting in the compact representation of I by means of reduced ordered
binary decision diagrams (BDDs) deﬁned over the set of variables var∀(f).
[c,¬e]
b
0
1
d
0
1
b
a
[e]
According to the semantics of BDDs, an entire set I = {Ψ ∈
Bδ(em) | ∀j.ψij ̸= πj} is represented by a single linear-sized BDD
(in m) requiring one internal node for each universal variable in the
originating clause. The whole symbolic representation has a linear
size w.r.t. the number of literals in the originating QBF clause. The
picture aside depicts our representation of the skolemized version of
∀a∀b∃c∀d∃e. (b∨c∨¬e)∧(¬a∨¬b∨d∨e). As an additional source
of compactness, we notice that BDDs are semantically canonical rep-
resentations, so they share at least all the representations for QBF
clauses with the same universal literals. As we produce only one sym-
bolic clause out of each QBF clause, the representation of Symb(f)
enlarges at most linearly with |f|. However, this only holds for the ini-
tial representation. The symbolic size may increase as a consequence
of the symbolic inferences described in the next section.

292
M. Benedetti
4
Reasoning on Propositional Skolemizations
The evaluation of the original QBF instance has been restated as a satisﬁability test on
the symbolically represented existential instance Symb(f). The peculiar structure of
Symb(f) allows to attack the SAT problem from three different perspectives, each one
featuring speciﬁc strengths. We describe such methods in the subsequent three sections.
Far from being mutually exclusive, those three strategies can be used in a synergic way,
so that each one contributes at its best towards the common goal (see Section 4.3).
4.1
Ground Reasoning
The original QBF f can be evaluated by explicitly constructing Prop(Symb(f)) and
solving it via state-of-the-art SAT solvers (they are very efﬁcient on QBF-derived in-
stances). We resort to this option only when the ground instance is affordable2, which
is not the case for many real-world problems. Yet, the reduced problems generated as
described in Section 4.2, 4.3 are eventually small enough to be solved this way.
Altought theorically straightforward, the computation of Prop(Symb(f)) deserves
a lot of attention on the practical side, due to the (possibly) large number of (possibly)
huge SAT instances generated out of each QBF formula. Groundization is made up of
two steps: (1) generation of the ground space and (2) generation of the ground clauses.
The latter step is executed according to Expression (8). The former constructs a mapping
between the structured namespace of symbolic literals and a ﬂat, SAT-solver friendly
namespace for ground literals. It amounts to associate a unique positive integer to each
ground variable that belongs to at least one clause in the current symbolic formula (and to
them only). To prevent the SAT solver from suffering unnecessarily large data structures,
the set of variable codes generated for the formula as a whole should be composed of
all and only the integers in the interval [1, n], for some sufﬁciently large n. In essence,
we need a partial, efﬁciently invertible function Vmap : D∃× D∀→[1, n] where
D∃= var∃(f), D∀= B|var∀(f)|, and n just sufﬁces to allow bijection.
4.2
Symbolic Reasoning
We deﬁne some symbolic inference rules over PROPSY MB to directly manipulate
Symb(f) while preserving the satisﬁability of Prop(Symb(f)). As opposed to ground
reasoning, the emphasis is on designing symbolic versions of the standard inference rules
that work without expanding symbolic objects to ground objects. In essence, it is a matter
of deﬁning how the basic steps (subsumption, resolution, assignment, substitution) can
be performed at a purely symbolic level on sets of ground clauses at once.
Complete refutation strategies—such as those based on SL, linear, or directional
resolution—could be employed in principle. However, efﬁcient and easy-to-implement
forms of incomplete reasoning exist that capture many inferences relevant to QBF-
derived instances. Even if the rules adopted are not refutationally complete, the compu-
tation of their deductive closure normalizes the instance. So, a satisﬁability-equivalent,
symbolic output formula with a (much) smaller ground size than the original one is
generated, and other complete methods can safely work on such simpliﬁed version.
2 By affordable we mean that the instance can be decided without running out of memory.
AffordabilitythusdependsontheSATengineemployedandontheavailableamountofmemory.

Evaluating QBFs via Symbolic Skolemization
293
The central step towards symbolic reasoning amounts to extend the star operator. For-
merly absent empty clause-sets Γ∅may result, which are eliminated from the formula.
ΓI ∗[l]J =
⎧
⎨
⎩
ΓI∩J
when l ∈Γ
ΓI∩J ∧Γ ′
(I∩J )|δ(Γ ′) with Γ ′ = Γ \ {¬l}, when ¬l ∈Γ
ΓI
otherwise
(9)
The efﬁciency of symbolic reasoning thus stems from the structured nature of the rep-
resentation, which takes universal reasoning apart form existential reasoning. BDD op-
erations conveniently deal with the former, list-based representations with the latter.
We now exemplify four (incomplete) symbolic rules that are highly effective on
average and can be implemented rather efﬁciently. In particular, notice that it is easy to
symbolically extract both pure literals and unit clauses. Let us consider the formula
∃a∀b∃c∀de∃fgh∀i∃l. (¬c∨a) ∧(¬a∨¬g) ∧(¬e ∨h) ∧(c ∨¬e ∨g∨¬h)
∧(¬b∨d∨¬f∨l) ∧(¬e∨f∨g) ∧(i∨¬c∨¬h∨d∨¬l)
(10)
and its symbolic matrix M (under the preﬁx ∃[a]0∃[c]1∃[f]3∃[g]3∃[h]3∃[l]4):
[¬c, a]{0,1} ∧[¬a, ¬g]{0,1}3 ∧[h]{001,011,101,111} ∧[c, g, ¬h]{001,011,101,111}∧
[¬f, l]{1000,1001,1010,1011} ∧[g, f]{001,011,101,111} ∧[¬c, ¬h, ¬l]{0000,1000,0010,1010}
The simplest rule is the symbolic unit clause propagation (SUCP). It builds on top
of the observation that each symbolic unit clause [γ]I in the formula represents a set
{γi|i ∈I} of ground literals. All of them need to be assigned to avoid contradictions.
These assignments are performed all-at-once by the star operator. The only unit clause
in our symbolic formula is [h]{001,011,101,111}. By assigning this literal we obtain
[¬c, a]{0,1} ∧[¬a, ¬g]{0,1}3 ∧[c, g]{001,011,101,111} ∧[¬f, l]{1000,1001,1010,1011}
∧[g, f]{001,011,101,111} ∧[¬c, ¬l]{0000,1000} ∧[¬c, ¬h, ¬l]{0010,1010}
The next rule we apply is the symbolic pure literal elimination (SPLE). It does what we
would expect from the standard rule, but performs its job in a purely symbolic manner, by
(a)constructingacompletesymbolicrepresentationofthesetofeverypuregroundliteral,
and (b) applying the resulting symbolic literals to the formula. The pure literals on v are
[v]I+\(I+∩I−) and [¬v]I−\(I+∩I−), where I+ = ∪[v]I∈MI and I−= ∪[¬v]I∈MI.
The pure literals in our example are [f]{001,011,111}, [¬f]{100}, [¬g]{000,010,100,110},
[¬h]{000,100}, [l]{1001,1011}, and [¬l]{0000,0010}, so we obtain
[¬c, a]{0,1} ∧[¬a, ¬g]{001,011,101,111} ∧[c, g]{001,011,101,111}
∧[¬f, l]{1010} ∧[g, f]{101} ∧[¬c, ¬l]{1010}
The next two rules only consider the subset of binary symbolic clauses, employing a
graph-based approach similar to the one used to simplify standard propositional instances
with many binary clauses [2]. We build a symbolic implication graph (SIG), which has
two nodes labeled by [a]δ(a) and [¬a]δ(a) for each existential variable a in the original
QBF, and a couple of arcs [¬a]δ(a)
I
−→[b]δ(b) and [¬b]δ(b)
I
−→[a]δ(a) for each binary
symbolicclause[a, b]I.So,unlikestandardimplicationgraphs,SIGsfeaturelabeledarcs.
The arcs originating from [a, b]I are labeled by I. Each symbolic arc a
I
−→b represents
a set of ground arcs {aΨ|δ(a) −→bΨ|δ(b), Ψ ∈I} in the corresponding ground graph.
The two rules we apply are as follows.

294
M. Benedetti
1. Symbolic Hyper Binary Resolution (SHBR). It enumerates all the resolution chains
of symbolic binary clauses (via a depth-ﬁrst, non-redundant traversal of the SIG),
looking for failed literals, i.e. for literals [a]I such that each ¬aΨ ∈[¬a]I can
be derived (via a ﬁnite number of resolution steps only involving binary clauses)
as a consequence of the hypothesis aΨ. Each ground literal in [a]I generates a
contradiction, so we force the opposite symbolic assignment, shifting our attention
onto F ∗[¬a]I. A literal [a]I is failed if we encounter the following (portion of a)
resolution path: [a]
I1
→[a1]
I2
→[a2] · · ·
In
→¬[a], with I = (∩j=1,...,nIj)|δ(a) ̸= ∅.
2. Symbolic Equivalence Reasoning (SER). It aims at identifying symbolic equiva-
lences [a]
I↔[b], meaning that for all Ψ ∈I, aΨ|δ(a) ↔bΨ|δ(b) is a consequence of
Prop(F). It is easy to rewrite the substitution rule to apply all such equivalences
at once, producing at most two symbolic clauses out of each clause involved in. To
reduce the ground size of the formula we substitute [a] for [b] if δ(a) ≤δ(b), and
vice-versa. SER is performed by extracting all the strongly connected components
(SCCs) from the SIG, temporarily discarding arc labels. Then, for each SCC we
enumerate all its non-intersecting loops [a]
I1
→[a1]
I2
→[a2] · · ·
In
→[a] (let us suppose
without loose of generality that δ(a) ≤δ(ai), i = 1, . . . , n −1), and apply the
substitutions [a]
I↔[ai], i = 1, . . . , n −1, with I = (∩j=1,...,nIj)|δ(a).
In our example, all the remaining symbolic clauses are binary. Notice that for the class
of QBF instances with at most two existential literals per clause, the symbolic binary
rules inherit completeness from their standard counterpart.
In the ﬁgure aside a fragment of the sample SIG is
depicted. By SER we obtain [c]
I↔[¬g] with I
=
{{001, 011, 101, 111}}δ(c) < δ(g), hence: [a, ¬c]{0,1} ∧
[¬a, c]{0,1} ∧[¬f, l]{1010} ∧[¬c, f]{101} ∧[¬c, ¬l]{1010}.
Then, the failed literal [c]{1} can be deduced from [c]
{101}
−→
[f]
{1010}
−→[l]
{1010}
−→[¬c], so [a, ¬c]{0}∧[¬a, c]{0}∧[¬a]{1}
[c]1
[a]0
[¬g]3
{0,1}
{001,011,
101,111}
{001,011,
101,111}
∧[¬f, l]{1010} remains. By assigning the pure literal [l]1010 and the unit clause [¬a]{1}
we have [a, ¬c]{0} ∧[¬a, c]{0}, hence the empty formula by SER on [c]
{0}
↔[a].
Applied until ﬁxpoint, the above set of rules R = {SUCP,SPLE,SHBR,SER} deﬁnes
a satisﬁability preserving trasformation NormR:PROPSY MB →PROPSY MB.
4.3
Branching Reasoning
In addition to symbolic and SAT reasoning, our representation ﬁts well into search-based
branching decision procedures. As far as QBFs are concerned, branching procedures
extend the DPLL-approach [9] to the quantiﬁed case [7]. They look for models following
theleft-to-rightorderofthevariablesinthepreﬁxduringadepth-ﬁrstvisitofthesemantic
evaluation tree of the formula. Existential variables generate or nodes that disjunctively
split the branch, universal quantiﬁers are associated to and nodes that split branches
conjunctively. Each node n is labeled by the cofactored matrix M ∗∆where ∆is the
assignment on the path to n, while the root is labeled by the original matrix M.

Evaluating QBFs via Symbolic Skolemization
295
A model, if one exists, is a subtree with all the
leaves labeled by ⊤, extracted by choosing only
one child for each existential node, and both chil-
dren for conjunctive nodes. For example, the for-
mula ∃a∀b∃c.(a∨b∨c)∧(b∨¬c)∧(a∨¬b∨¬c)∧
(¬a ∨b) is decided to be false by visiting the tree
reported aside and failing to extract any model.
Inspired by the above strategy, we build an evalu-
ation procedure that mixes ground, symbolic, and
branching reasoning. We just need to deﬁne the
following projection operator.
(a㱹b㱹c)(b㱹¬c)(a㱹¬b㱹¬c)(¬a㱹b)
a=T
a=F
(b㱹¬c)(b)
(¬c)
(c)(¬c)
b=T
b=F
b=T
b=F
c=T
c=T
c=F
c=F
T
T
T
T
T
T
(b㱹c)(b㱹¬c)(¬b㱹¬c)
ΓI↓α
.= ΓI′ with α ∈B and I′ = {⟨ψ2, . . . , ψδ(Γ )⟩|⟨α, ψ2, . . . , ψδ(Γ )⟩∈I}
Projection is used for universal branching and is readily extended to formulas:
(∃[e1]δ1 · · · ∃[em]δm.M)↓α= ∃[e1]δ1−1 · · · ∃[em]δm−1.(M↓α)
(11)
where M↓α= ∧ΓI∈MΓI↓α. Existential branching is done according to Expression (9).
The resulting decision procedure is reported below.
As far as splitting over existential variables is concerned, the purely existential nature
of Prop(F) makes the whole procedure more similar to search-based SAT solvers than
to QBF decision procedures. By contrast, when the split is performed over universal
variables, something conceptually different happens: the instance is partitioned into two
completely disjoint existential sub-instances, according to (11).
The two base-cases do not deal with trivial sub-formulas. Well in advance, either
symbolic reasoning (whenever the current sub-instance falls within its deductive power)
orgroundreasoningactaspowerfullook-aheadtools.Theusualenhancementstobranch-
ing procedures (backjumping, learning, heuristics, etc.) also apply.
Function symbEval(symbolic formula F)
begin
F ′ ←NormR(F);
if F′ = ∅then
return TRUE;
else if ⊥∈F ′ then
return FALSE;
else
if (|F′|ground is affordable) then
return SAT(prop(F ′));
else
Let F ′ be ∃[e1]δ1 · · · ∃[em]δm. M ;
if (δ1 > 0) then
return symbEval (∃[e1]δ1−1 · · · ∃[em]δm−1. M↓0) and
symbEval (∃[e1]δ1−1 · · · ∃[em]δm−1. M↓1);
else
return symbEval (∃[e2]δ2 · · · ∃[em]δm. M ∗[e1]) or
symbEval (∃[e2]δ2 · · · ∃[em]δm. M ∗[¬e1]);
end

296
M. Benedetti
5
Implementation and Experimentation
We present a ﬁrst implementation of our decision procedure and a preliminary experi-
mental evaluation. The interested reader may ﬁnd further details and a wider experimen-
tation in [3]. The resulting solver—called sKizzo—is a 60k-line piece of object-oriented
C code managing ROBDDs through the CUDD package [32], version 2.4.0, and per-
forming SAT solving using zChaff [24], version 2004.5.13.
We focus on a subset of the non-random families of instances collected in the
QBFLIB’s archive [15]. Among the others, we consider (1) Rintanen’s benhmarks [29],
the ﬁrst and best-known collection of QBF problems, made up of 47 instances divided
into 5 families, obtained by encoding planning problems, (2) Ayari’s benchmarks [1],
made up of 72 instances divided into 5 families, obtained from real-world veriﬁcation
Table 1. The effect of symbolic reasoning over the size of instances
Symbolic size (clauses)
Ground size (clauses)
Instance
Before
After
Diff.
Before
After
Diff.
Symb. time
Adder2-2-c
234
193
-18%
1.0 · 106
5.4 · 105
-46.0%
100%
Adder2-6-s
3,315
2,236
-33%
1.8 · 1012
1.0 · 106
-99.9%
23%
Adder2-8-s
6,060
4,070
-33%
1.0 · 1016
2.2 · 107
-99.9%
14%
BLOCKS3i.5.4
2,640
2,814
+7%
4.0 · 104
3.0 · 104
-25.0%
100%
BLOCKS3ii.5.2
1,886
2,095
+11%
2.9 · 104
2.1 · 104
-28.0%
100%
BLOCKS3iii.5
1,226
1,614
+32%
1.9 · 104
1.3 · 104
-32.0%
100%
CHAIN12v.13
486
0
-100%
1.8 · 106
0
-100.0%
100%
CHAIN17v.18
861
0
-100%
1.1 · 108
0
-100.0%
100%
CHAIN23v.24
1,443
0
-100%
1.2 · 1010
0
-100.0%
100%
cnt08
1,237
0
-100%
6.1 · 104
0
-100.0%
100%
cnt08re
1,309
1,240
-5%
6.5 · 104
1.1 · 104
-83.0%
<1%
cnt12
2,505
0
-100%
1.3 · 106
0
-100.0%
100%
cnt12re
2,733
2,820
+3%
1.5 · 106
2.6 · 105
-83.0%
<1%
ﬂipﬂop-9-c
74,066
71,691
-3%
9.4 · 1012
9.2 · 1012
-2.0%
100%
ﬂipﬂop-10-c
128,245 124,844
-3%
1.3 · 1014
1.3 · 1014
-1.0%
100%
ﬂipﬂop-11-c
210,674 205,995
-2%
1.7 · 1015
1.7 · 1015
-1.0%
100%
impl04
32
0
-100%
1.4 · 102
0
-100%
100%
impl12
96
0
-100%
3.7 · 104
0
-100%
100%
impl20
160
0
-100%
9.4 · 106
0
-100%
100%
k-branch-n-9
12,923
20,608
+59%
2.1 · 1018
1.6 · 1018 -23.8%
3%
k-branch-p-13
28,676
78,006 +172%
3.7 · 1024
2.9 · 1024 -21.6%
100%
k-d4-n-16
5,133
5,535
+8%
4.2 · 1022
2.4 · 1022 -42.9%
2%
k-d4-p-16
2,959
5,044
+70%
4.7 · 1017
3.1 · 1017 -34.0%
100%
mutex-4-s
362
0
-100%
1.9 · 107
0
-100%
100%
mutex-8-s
834
367
-56%
2.9 · 1012
3.5 · 104
-99.9%
70%
TOILET10.1.iv.20
3,466
3,326
-4%
2.1 · 104
7.4 · 103
-64.8%
55%
TOILET16.1.iv.32 10,495
8,175
-22%
5.6 · 104
8.6 · 103
-84.6%
72%
toilet-a-08-01.11
3,109
1,069
-66%
6.0 · 104
2.7 · 104
-55.0%
3%
toilet-c-10-01.14
1,974
1,874
-5%
7.5 · 103
4.0 · 103
-46.6%
1%
toilet-g-20-01.2
460
0
-100%
1.1 · 103
0
-100.0%
100%
tree-exa2-40
51
1
-100%
5.6 · 1014
1
-100%
100%
tree-exa10-30
58
0
-100%
58
0
-100%
100%

Evaluating QBFs via Symbolic Skolemization
297
Ayari’s benchmarks
Biere’s benchmarks
 0
 5
 10
 15
 20
 25
 30
 35
 40
 0.1
 1
 10
 100
 1000
Number of solved instances
Running Time (sec)
sKizzo
quantor
semprop
yquaffle
qube
 0
 10
 20
 30
 40
 50
 0.1
 1
 10
 100
 1000
Running Time (sec)
sKizzo
quantor
yquaffle
semprop
qube
Fig. 1. Comparison with other solvers over two groups of families
problems on circuits and protocol descriptions (these instances are quite challenging
for modern solvers, and some of them have never been solved), and (3) Biere’s bench-
marks [4], made up of 64 instances divided into 4 families, where the n-th instance in
each family refers to model checking problem on a n-bit counter. The veriﬁcation is
easy for BDD-based symbolic MC and very difﬁcult for SAT-based bounded MC, as
it captures the worst-case scenario in which the number of steps necessary to falsify
the property equals the diameter of the system. QBF reasoning has been shown not to
outperform SAT-based reasoning (Bounded Model Checking) on these benchmarks.
Table 1 measures the relative importance of symbolic reasoning w.r.t. all the other
reasoning strategies. It puts side by side the symbolic/ground size of a few instances
before and after NormR is applied for the ﬁrst time. The last column gives the amount
of time spent in (the ﬁrst application of) symbolic reasoning. When this percentage is
equal to 100%, the instance is just symbolically solved. As expected, the ground size
of instances is always reduced, whilst the symbolic size of some of them is increased
as an effect of symbolic reasoning. The reduction ratio for the ground size is quite
family-dependent, though not sensibly instance-depending. Most of the simpler families
are completely solved by symbolic reasoning. Conversely, for more complex instances
symbolic reasoning does not sufﬁces. Quite often, the number of ground clauses before
symbolic reasoning is intractable (state-of-the-art solvers can afford millions clauses,
not billions). Some of them stays unaffordable even after NormR, but many undergo a
strong reduction of the ground size. Several problems exist that—thought not strongly
reduced during the ﬁrst call to NormR—are hardly simpliﬁed during the recursive calls
(not shown in the table). The overall effect of symbolic reasoning is quite incisive.
Figure 1 compares sKizzo with publically available state-of-the-art solvers, among
which we ﬁnd the three top-rated solvers according to most of the results presented
in [20] (see also Section 6). The number of solved instances in two groups of families
is plotted against the (non-cumulative) time taken to solve such instances. The overall

298
M. Benedetti
performance is quite impressive, especially if we take into consideration that sKizzo is
just a ﬁrst non-optimized implementation.
6
Related Work and Discussion
Most QBF solvers leverage revised versions of search-based techniques developed in
the SAT framework, ranging from the extension of resolution-based reasoning [18]
to the employment of lookback techniques [23], encountering along the way a key
contribution by Cadoli, Giovanardi and Schaerf [7] in which the original extension of
DPLL to QBF is presented. Up to a certain point, these extensions have been successful.
In the solver evaluation reported in [21], all the competitive solvers (such as QSAT [30],
QSOLVE [11], QUAFFLE [34], QuBE [15], SEMPROP [22]) are search-based.
A few alternative algorithms for QBF are emerging [20]. Some of them reverse
the order in which quantiﬁers are considered (such as Quantor [4]), others employ some
compact representation for the problem (such as ZQSAT [14] and QMRES/QBDD [28]).
Manyrestatetheverygoalofthesolver:itisnolongeramatterofsearchingforasolution,
rather an attempt to directly solve the instance (this distinction traces back to [9, 10]).
Resolution-based solving techniques have also received renewed attention, especially
when used in conjunction with compressed representation for clauses [8, 13, 25]. In the
SAT framework, these so-called symbolic approaches show a certain strength on speciﬁc
classes of instances, but seem to be not competitive in general [27]. In the QBF scenario,
both the idea of compressed/symbolic representations, and the shift from searching to
solving are more promising [28, 4, 14].
The foundational work of Skolem [31] has had the widest possible application. We
here just cite a recent work by Jackson [16]. Forms of reasoning about binary sub-
formulas are regarded as an effective pre-processing step in the propositional frame-
work [2]. The interest in binary decision diagrams as a tool for manipulating boolean
functions traces back to the seminal work by Bryant [6]. Their usage in SAT/QBF sat-
isﬁability algorithms have been explored at least in [33, 8, 25, 13, 27, 28, 14].
Several features distinguish our approach from previous ones. For example, it: (1)
largely abstracts over variable ordering and number of alternations in the preﬁx; (2)
explicitly leverages skolemization; (3) proﬁts from the peculiar structure of QBF-derived
instancestosymbolicallyrepresentthem;(4)advantageouslyintegratessearch-basedand
solving decision strategies in QBF reasoning; (5) repeatedly engages a SAT solver as an
oracle; (6) employs a hybrid PROP/QBF branching style. For further differences and an
in-depth comparison, see [3].
7
Conclusions and Future Work
Our work is motivated by the outstanding potential of QBF in applications. Advances in
decision procedures for this formalism are ardently expected, and quantiﬁed reasoners
worhty of inheriting the amazing success of SAT solvers are a looming possibility.
In this respect, we ﬁrstly succeed to efﬁciently retain both the expressive power of
quantiﬁcation and the strength of the purely propositional reasoning. Our preliminary
experimental evaluation yields remarkable results. Large room for improvements exist as

Evaluating QBFs via Symbolic Skolemization
299
(1) our implementation is just a ﬁrst, non-optimized prototype, and (2) several effective
QBF and SAT reasoning techniques (q-resolution, subsumption control, backjumping,
etc.) have been left out of the ﬁrst implementation to focus on the main topic.
To further investigate our guideline, we are (1) strengthening the symbolic machinery
by adding new rules, (2) conceiving a symbolic model veriﬁer, and (3) designing the
integration with an industrial-scale model checker.
Acknowledgements
I thank Gigina Aiello and Paolo Traverso for supporting my research efforts, and Sara
Bernardini for the many days she has spent on listening to my early ideas on symbolic
skolemization. I’m grateful to Marco Cadoli for discussing this work with me. Finally,
Amedeo Cesta deserves a special thought for his indefatigable encouragement.
References
1. A. Ayari and D. Basin. Bounded Model Construction for Monadic Second-order Logics. In
Proc. of CAV’00, 2000.
2. F. Bacchus and J. Winter. Effective Preprocessing with Hyper-Resolution and Equality Re-
duction. In Proc. of SAT’03, 2003.
3. M. Benedetti. sKizzo: a QBF Decision Procedure based on Propositional Skolemization and
Symbolic Reasoning, Tech.Rep. 04-11-03, ITC-irst, available at
sra.itc.it/people/benedetti/sKizzo, 2004.
4. A. Biere. Resolve and Expand. In Proc. of SAT’04, pages 238–246, 2004.
5. A. Biere, A. Cimatti, E. M. Clarke, M. Fujita, and Y. Zhu. Symbolic Model Checking without
BDDs. In Proc. of Design Automation Conference, volume 1579, pages 193–207, 1999.
6. R. E. Bryant. Graph-based algorithms for Boolean function manipulation. IEEE Transaction
on Computing, C-35(8):677–691, 1986.
7. Marco Cadoli, Andrea Giovanardi, and Marco Schaerf. An algorithm to evaluate quanti-
ﬁed boolean formulae. In Proceedings of the ﬁfteenth national/tenth conference on Artiﬁcial
intelligence/Innovative applications of artiﬁcial intelligence, pages 262–267. American As-
sociation for Artiﬁcial Intelligence, 1998.
8. P. Chatalic and L. Simon. Multi-Resolution on compressed sets of clauses. In Proceedings of
the Twelfth International Conference on Tools with Artiﬁcial Intelligence (ICTAI’00), 2000.
9. M. Davis, G. Logemann, and D. Loveland. A machine program for theorem proving. Journal
of the ACM, 5:394–397, 1962.
10. M. Davis and H. Putnam. A computing procedure for quantiﬁcation theory. Journal of the
ACM, 7, 1960.
11. R.Feldmann,B.Monien,andS.Schamberger. ADistributedAlgorithmtoEvaluateQuantiﬁed
Boolean Formulas. In Proceedings of the AAAI National Conference on Artiﬁcial Intelligence,
pages 285–290, 2000.
12. M. Fitting. First-Order Logic and Automated Theorem Proving. Springer Verlag, 1996.
13. J. Franco, M. Kouril, J. Schlipf, J. Ward, S. Weaver, M. Dransﬁeld, and W. Vanﬂeet. SBSAT:
a state-based, BDD-based satisﬁability solver. In Proceedings of SAT’03, 2003.
14. M. GhasemZadeh, V. Klotz, and C. Meinel.
ZQSAT: A QSAT Solver based on Zero-
suppressed Binary Decision Diagrams, available at http://www.informatik.uni-
trier.de/TI/bdd-research/zqsat/zqsat.html, 2004.

300
M. Benedetti
15. E. Giunchiglia, M. Narizzano, and A. Tacchella. QuBE: A system for deciding Quantiﬁed
Boolean Formulas Satisﬁability. In Proc. of the International Joint Conference on Automated
Reasoning (IJCAR’2001), 2001.
16. Daniel Jackson. Automating ﬁrst-order relational logic. In Proceedings of the 8th ACM
SIGSOFT international symposium on Foundations of software engineering, pages 130–139.
ACM Press, 2000.
17. H. Kautz and B. Selman. Planning as satisﬁability. In Proc. of ECAI 1992, pages 359–363.
18. H. Kleine-Buning, M. Karpinski, and A. Flogel. Resolution for quantiﬁed Boolean formulas.
Information and Computation, 117(1):12–18, 1995.
19. T. Larrabee. Test pattern generation using boolean satisﬁability. In IEEE Transaction on
Computer-aided Design, pages 4–15, 1992.
20. D. Le Berre, M. Narizzano, L. Simon, and A. Tacchella. Second QBF solvers evaluation,
avaliable on-line at www.qbflib.org, 2004.
21. D. Le Berre, L. Simon, and A. Tacchella. Challenges in the QBF arena: the SAT’03 evaluation
of QBF solvers, avaliable on-line at www.qbflib.org, 2003.
22. R. Letz. Advances in Decision Procedures for Quantiﬁed Boolean Formulas. In Proceedings
of the First International Workshop on Quantiﬁed Boolean Formulae (QBF’01), pages 55–64,
2001.
23. R. Letz. Lemma and model caching in decision procedures for quantiﬁed boolean formulas. In
Proc. of the Int. Conf. on Automated Reasoning with Analytic Tableaux and Related Methods,
pages 160–175. Springer-Verlag, 2002.
24. M. W. Moskewicz, C. F. Madigan, Y. Zhao, L. Zhang, and S. Malik. Chaff: Engineering an
Efﬁcient SAT Solver. In proceedings of the 38th Design Automation Conference, 2001.
25. D. B. Motter and I. L. Markov. A compressed, breadth-ﬁrst search for satisﬁability. LNCS,
2409:29–42, 2002.
26. A. Nonnengart and C. Weidenbach.
Computing Small Clause Normal Forms.
In Alan
Robinson and Andrei Voronkov, editors, Handbook of Automated Reasoning, chapter 6, pages
335 – 367. Elsevier, Amsterdam, Netherlands, 2001.
27. G. Pan and M.Y. Vardi. Search vs. Symbolic Techniques in Satisﬁability Solving. In Pro-
ceedings of SAT 2004, 2004.
28. G. Pan and M.Y. Vardi. Symbolic Decision Procedures for QBF. In Proceedings of the Tenth
International Conference on Principles and Practice of Constraint Programming (CP04),
2004.
29. J. Rintanen. Construction Conditional Plans by a Theorem-prover. Journal of A. I. Research,
pages 323–352, 1999.
30. J. Rintanen. Partial implicit unfolding in the davis-putnam procedure for quantiﬁed boolean
formulae. In Proceedings of the International Conference on Logic for Programming, Artiﬁ-
cial Intelligence and Reasoning (LPAR’01), 2001.
31. T. Skolem. Logico-combinatorial investigations in the satisﬁability or provability of mathe-
matical propositions: a simpliﬁed proof of a theorem by L. L¨owenheim and generalizations
of the theorem. In From Frege to G¨odel. A Source Book in Mathematical Logic, 1879-1931,
pages 252–263. Harvard University Press, Cambridge, 1967 (1920).
32. Fabio Somenzi. Colorado University Binary Decision Diagrams,
vlsi.colorado.edu/ fabio/CUDD, 1995.
33. T. E. Uribe and M. E. Stickel. Ordered binary decision diagrams and the Davis-Putnam proce-
dure. In J. P. Jouannaud, editor, 1st International Conference on Constraints in Computational
Logics, volume 845, pages 34–49, 1994.
34. L. Zhang and S. Malik. Towards Symmetric Treatment of Conﬂicts And Satisfaction in
Quantiﬁed Boolean Satisﬁability Solver. In Proc. of CP’02, 2002.

The Dependency Pair Framework: Combining
Techniques for Automated Termination Proofs
J¨urgen Giesl, Ren´e Thiemann, and Peter Schneider-Kamp
LuFG Informatik II, RWTH Aachen, Ahornstr. 55, 52074 Aachen, Germany
{giesl|thiemann|psk}@informatik.rwth-aachen.de
Abstract. The dependency pair approach is one of the most powerful
techniques for automated termination proofs of term rewrite systems. Up
to now, it was regarded as one of several possible methods to prove ter-
mination. In this paper, we show that dependency pairs can instead be
used as a general concept to integrate arbitrary techniques for termina-
tion analysis. In this way, the beneﬁts of diﬀerent techniques can be
combined and their modularity and power are increased signiﬁcantly. We
refer to this new concept as the “dependency pair framework” to distin-
guish it from the old “dependency pair approach”. Moreover, this frame-
work facilitates the development of new methods for termination analy-
sis. To demonstrate this, we present several new techniques within the
dependency pair framework which simplify termination problems consid-
erably. We implemented the dependency pair framework in our termina-
tion prover AProVE and evaluated it on large collections of examples.
1
Introduction
Termination of term rewrite systems (TRSs) has been studied for decades and
several methods were developed to prove termination of TRSs automatically
(one of the most powerful techniques is the dependency pair approach [1,6,7]).
Up to now, all these methods were seen as separate approaches on their own.
In contrast, this paper shows that dependency pairs are suitable as a general
framework to integrate arbitrary techniques for termination proofs. In this way,
the beneﬁts of all available methods can be combined and the classical depen-
dency pair approach is just a special case of this new dependency pair framework.
By combining termination techniques within the dependency pair framework (in-
stead of trying to apply them on a TRS directly, one after another), the ﬂexibility,
modularity, and power of these techniques are increased signiﬁcantly.
We introduce the dependency pair framework in Sect. 2. Here, each tech-
nique for termination proofs is seen as a dependency pair processor that trans-
forms a dependency pair problem into a set of new (and hopefully, simpler) ones.
Sect. 3 shows how to formulate the components of the classical dependency pair
approach as processors. This increases their applicability substantially and it
demonstrates that the dependency pair approach is indeed a special case of the
dependency pair framework. In Sect. 4 we introduce new processors which sim-
plify dependency pair problems signiﬁcantly and which are only possible due to
the new formulation of the dependency pair framework. This demonstrates that
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 301–331, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

302
J. Giesl, R. Thiemann, and P. Schneider-Kamp
the dependency pair framework is particularly well suitable as a basis for future
developments in automated termination proving. In Sect. 5 we discuss how to
integrate other (existing) methods for automated termination proofs into the
dependency pair framework by formulating them as processors as well.
Finally, to construct an automatic termination prover using the dependency
pair framework, a main problem is to develop strategies to decide which pro-
cessors should be applied to a given DP problem. Suitable heuristics and our
implementation in the termination prover AProVE are discussed in Sect. 6.
2
The Dependency Pair Framework
We extend the dependency pair approach to a framework for the combination of
arbitrary termination techniques. The reader is referred to [2] for the basics of
term rewriting and to [1,7] for further details on the dependency pair approach.
We restrict ourselves to ﬁnite signatures F and TRSs. T (F, V) denotes the
set of terms over F and the inﬁnite set of variables V. A TRS over F is a set of
rules l →r where l and r are from T (F, V), V(r) ⊆V(l), and l /∈V. To handle
diﬀerent evaluation strategies (like innermost or full rewriting) in a uniform way,
we introduce the new notion of Q-restricted rewriting. In Q-restricted rewriting,
one may only perform a rewrite step if the proper subterms of the redex are not
reducible w.r.t. Q (i.e., if they are Q-normal forms). This notion is particularly
useful when deﬁning techniques for innermost termination proofs later on.
Deﬁnition 1 (Q-restricted Rewriting). Let R and Q be TRSs. We deﬁne
the Q-restricted rewrite relation as s Q→R,p t iﬀp is a position of s, s|p = lσ for
some rule l →r ∈R and some substitution σ, t = s[rσ]p, and all proper subterms
of the redex s|p are in Q-normal form. Moreover, s Q→R t means that s Q→R,p t
for some position p. A TRS R is Q-terminating iﬀQ→R is well founded.1
Example 1. Consider R = {f(a) →f(a), a →b}. If Q contains the rule a →b,
then the step from f(a) to f(a) is no longer possible with Q→R since the proper
subterm a of the redex f(a) is not a Q-normal form. Thus, R is Q-terminating.
Q-restricted rewriting subsumes both innermost and ordinary rewriting. Or-
dinary rewriting is Q-restricted rewriting for Q = ∅and innermost rewriting is
Q-restricted rewriting with Q = R (→R = ∅→R and
i→R = R→R). The following
lemma shows that Q→R is “increasing” if R is “increasing” and Q is “decreasing”.
Lemma 1 (Monotonicity of Q→R). R′ ⊆R and Q′ ⊇Q implies Q′
→R′ ⊆Q→R.
Proof. Obvious.
⊓⊔
This lemma already indicates why Q-restricted rewriting is better suitable
for termination analysis than innermost rewriting. There exist several techniques
which can simplify termination proofs by removing rules from the TRS R. For
full rewriting and also for Q-restricted rewriting, removal of rules is always ad-
vantageous, since it can never introduce non-termination (termination of Q→R
1 Since the right-hand sides of Q’s rules are not needed to deﬁne Q-restricted rewriting,
Def. 1 could also be formulated if Q is a set of terms instead of rules.

The Dependency Pair Framework
303
implies termination of Q→R′ if R′ ⊆R). But for innermost rewriting, this is not
true. For instance, by removing the rule a →b from the innermost terminating
TRS R of Ex. 1, we result in a TRS R′ that is not innermost terminating (hence,
i→R′ ̸
⊆
i→R). Here, Q-restricted rewriting has the advantage that the rules Q
which restrict the set of possible redexes are separated from the rules R used for
rewriting and thus, R and Q can be changed independently.
Now we present a termination criterion for Q-restricted rewriting based on
dependency pairs. For a TRS R over F, the deﬁned symbols are D = {root(l) |
l →r ∈R} and the constructors are C = F \ D. For every f ∈D we extend the
signature F by a fresh tuple symbol f ♯, where f ♯has the same arity as f and we
often write F for f ♯. If t=g(t1, . . . , tm) with g∈D, we let t♯denote g♯(t1, . . . , tm).
Deﬁnition 2 (Dependency Pair). The set of dependency pairs for a TRS
R is DP(R) = {l♯→t♯| l →r ∈R, root(t) ∈D, t is a subterm of r}.2
Example 2. The following TRS computes subtraction and division, cf. [1, Ex. 2].
minus(x, 0) →x
(1)
minus(0, s(y)) →0
(2)
minus(s(x), s(y)) →minus(x, y)
(3)
div(0, s(y)) →0
(4)
div(s(x), s(y)) →s(div(minus(x, y), s(y)))
(5)
Here, the deﬁned symbols are minus and div and the symbols 0 and s are con-
structors. We obtain the following dependency pairs:
MINUS(s(x), s(y)) →MINUS(x, y) (6)
DIV(s(x), s(y)) →MINUS(x, y)
(7)
DIV(s(x), s(y)) →DIV(minus(x, y), s(y)) (8)
To verify Q-termination, we use the notion of chains. Intuitively, a depen-
dency pair corresponds to a function call and a chain represents a possible se-
quence of calls that can occur in a reduction. For termination, we try to prove
that there are no inﬁnite chains. We always assume that diﬀerent occurrences of
dependency pairs are variable disjoint and consider substitutions whose domains
may be inﬁnite. In the following deﬁnition, P is usually a set of dependency pairs.
Deﬁnition 3 (Chain). Let P, Q, R be TRSs. A (possibly inﬁnite) sequence of
pairs s1 →t1, s2 →t2, . . . from P is a (P, Q, R)-chain iﬀthere is a substitution
σ such that tiσ Q→∗
R si+1σ for all i and all siσ are in Q-normal form. A chain
is minimal iﬀthere is a σ as above where all tiσ are terminating w.r.t. Q→R.
Example 3. If Q ⊆R, then the TRS of Ex. 2 has the following chain which
consists of two occurrences of the dependency pair (8).
DIV(s(x1), s(y1)) →DIV(minus(x1, y1), s(y1)),
DIV(s(x2), s(y2)) →DIV(minus(x2, y2), s(y2))
The reason is that DIV(minus(x1, y1), s(y1))σ Q→∗
R DIV(s(x2), s(y2))σ holds for
some substitution σ (e.g., σ(x1) = s(0) and σ(x2) = σ(yi) = 0 for i ∈{1, 2})
such that all instantiated left-hand sides DIV(s(xi), s(yi))σ are in Q-normal form.
Moreover, the chain is minimal, since all instantiated right-hand sides of the
dependency pairs are terminating w.r.t. Q→R.
2 It even suﬃces only to regard dependency pairs where t is no proper subterm of l [4].

304
J. Giesl, R. Thiemann, and P. Schneider-Kamp
As mentioned above, termination corresponds to absence of inﬁnite chains.
Here, it suﬃces to consider minimal chains, since minimal non-terminating terms
(whose proper subterms are terminating) correspond to inﬁnite minimal chains.
The following termination criterion is immediately obtained from [1, Thm. 6].
Theorem 1 (Termination Criterion). These three properties are equivalent:
• R is Q-terminating
• there is no inﬁnite (DP(R), Q, R)-chain
• there is no inﬁnite minimal (DP(R), Q, R)-chain
With this criterion, we can now state the dependency pair framework. The ba-
sic idea of this framework is to examine a set of dependency pairs P together with
the TRSs Q and R and to prove absence of (minimal) inﬁnite (P, Q, R)-chains
instead of examining the relation Q→R directly. The advantages of this approach
will become clear in the sequel. For example, it will be possible to decompose
this so-called dependency pair problem into several independent sub-problems.
These problems can then be solved separately using diﬀerent techniques, which
leads to a very modular approach to termination proving.
More precisely, a dependency pair problem (“DP problem”, for short) consists
of three TRSs P, Q, and R (where initially, P = DP(R)) and a ﬂag f ∈{m, a}
which stands for “minimal” or “arbitrary”. Initially, we have f = m. Our goal
is to show that there is no inﬁnite minimal (P, Q, R)-chain if f = m and that
there is no inﬁnite (possibly non-minimal) (P, Q, R)-chain if f = a. If this is
possible, then we call the problem ﬁnite.
A DP problem (P, Q, R, f) that is not ﬁnite is called inﬁnite. But in ad-
dition, (P, Q, R, f) is already inﬁnite whenever R is not Q-terminating. So in
particular, the existence of any (possibly non-minimal) inﬁnite (P, Q, R)-chain
suﬃces to conclude that (P, Q, R, f) is inﬁnite, even if f = m. While the initial
DP problem (DP(R), Q, R, m) is either ﬁnite or inﬁnite, other DP problems
(P, Q, R, f) which can occur in termination proofs can be both ﬁnite and inﬁ-
nite. For example, the DP problem (P, Q, R, m) with P = {A →B}, Q = ∅
and R = {a →a, a →b, b →c} is ﬁnite since there is no inﬁnite minimal
(P, Q, R)-chain, but also inﬁnite since R is not (Q-)terminating.
Such DP problems do not cause diﬃculties. If one detects an inﬁnite problem
during a termination proof, one can always abort the proof, since termination
has been disproved (provided that all proof steps were “complete”, i.e., that they
preserved the termination behavior). If the problem is both ﬁnite and inﬁnite,
then even if one only considers it as being ﬁnite, the proof is still correct, since
then there exists another resulting DP problem which is inﬁnite and not ﬁnite.
The reason is that by Thm. 1, non-termination implies that there is an inﬁnite
(minimal) chain. Indeed, when proving termination of the TRS R above one also
obtains a DP problem with the inﬁnite minimal chain A →A, A →A, . . .
Termination techniques should now operate on DP problems instead of TRSs.
They should transform a DP problem into a new set of problems which then have
to be solved instead. Alternatively, they can also return the answer “no”. We
refer to such techniques as dependency pair processors (“DP processors”).

The Dependency Pair Framework
305
Deﬁnition 4 (DP Problems and Processors). A DP problem (P, Q, R, f)
consists of three TRSs P, Q, R and a ﬂag f ∈{m, a}. A DP problem (P, Q,
R, m) is ﬁnite iﬀthere is no inﬁnite minimal (P, Q, R)-chain and (P, Q, R, a)
is ﬁnite iﬀthere is no inﬁnite (P, Q, R)-chain. A DP problem (P, Q, R, f) is
inﬁnite iﬀit is not ﬁnite or if R is not Q-terminating.
A DP processor is a function Proc which takes a DP problem as input and
returns either a set of DP problems or the result “no”. A DP processor Proc is
sound if for all DP problems d, d is ﬁnite whenever Proc(d) is not “no” and all
DP problems in Proc(d) are ﬁnite. A DP processor Proc is complete if for all
DP problems d, d is inﬁnite whenever Proc(d) is “no” or when Proc(d) contains
an inﬁnite DP problem.
Thus, soundness is required in order to use a DP processor Proc to prove
termination (in particular, to conclude that d is ﬁnite if Proc(d) = ∅). Com-
pleteness is needed in order to use Proc to prove non-termination (in particular,
to conclude that d is inﬁnite if Proc(d) = no). Even if one is only interested in
proving termination, completeness is still advantageous, since it ensures that one
does not transform non-inﬁnite DP problems into inﬁnite ones (i.e., applying the
processor does not “harm”). The reason for the above non-symmetric deﬁnition
of “ﬁnite” and “inﬁnite” is that in this way there are more ﬁnite resp. inﬁnite DP
problems and therefore, it becomes easier to detect (in)ﬁniteness of a problem.3
The following corollary introduces the dependency pair framework (“DP
framework”, for short). The idea is to start with the initial DP problem where
P = DP(R) and f = m. Then this problem is transformed repeatedly by sound
DP processors. If the ﬁnal processors return empty sets of DP problems, then
termination is proved. If one of the processors returns “no” and all processors
used before were complete, then one has proved that the original TRS is not
terminating. The proof of Cor. 1 is immediate from Def. 4 and Thm. 1.
Corollary 1 (Dependency Pair Framework). Let R and Q be TRSs. We
construct a tree whose nodes are labelled with DP problems or “yes” or “no” and
whose root is labelled with (DP(R), Q, R, m). For every inner node labelled with
d, there is a sound DP processor Proc satisfying one of the following conditions:
• Proc(d) = no and the node has just one child, labelled with “no”
• Proc(d) = ∅and the node has just one child, labelled with “yes”
• Proc(d) ̸
= no, Proc(d) ̸
= ∅, and the children of the node are labelled with
the DP problems in Proc(d)
If all leaves of the tree are labelled with “yes”, then R is Q-terminating.
Otherwise, if there is a leaf labelled with “no” and if all processors used on the
path from the root to this leaf are complete, then R is not Q-terminating.
3 That a DP problem (P, Q, R, m) is already “ﬁnite” if there are no inﬁnite minimal
chains will be required for the soundness of many processors (cf. Thm. 3, Thm. 6,
Thm. 8, and Thm. 10) and that a DP problem is already “inﬁnite” if R is not Q-
terminating will be required for the completeness of most processors for dependency
pair transformations (cf. Ex. 11 in Sect. 3.3).

306
J. Giesl, R. Thiemann, and P. Schneider-Kamp
Example 4. If d0 is the initial problem (DP(R), Q, R, m), Proc0, Proc1, Proc2
are sound DP processors, and Proc0(d0) = {d1, d2}, Proc1(d1) = ∅, Proc2(d2) =
∅, then one could obtain the ﬁrst tree below and conclude termination.
d0


d1
d2
yes
yes
d0


d1


d2
d3
d4
d5
no
But if Proc1(d1) = {d3, d4, d5} and Proc2(d2) = no, one could get the second tree.
If both Proc0 and Proc2 are complete, then one could conclude non-termination.
In the remainder of the paper, we present several sound DP processors which
can be used for termination proofs within the DP framework. Of course, it is
desirable to ﬁnd DP processors which transform a DP problem (P, Q, R, f) into
a set of “simpler” problems and whose application can never “harm”. Therefore,
we are particularly interested in processors which decrease P and R and which
increase Q. As stated by Lemma 1, decreasing the set of rules R and increasing
Q leads to a more restricted rewrite relation and thus, it can never transform a
non-inﬁnite DP problem into an inﬁnite one. In other words, any DP processor
which removes rules from P and R and which adds rules to Q is complete.
Lemma 2 (Completeness of DP Processors). Let Proc be a DP processor
where for all DP problems (P, Q, R, f) and all (P′, Q′, R′, f ′)∈Proc((P, Q, R, f))
we have P′ ⊆P, R′ ⊆R, and Q′ ⊇Q. Then Proc is complete.
Proof. Let some (P′, Q′, R′, f ′) ∈Proc((P, Q, R, f)) be inﬁnite and suppose
that (P, Q, R, f) is not inﬁnite. Thus, R is Q-terminating and (P, Q, R, f) is
ﬁnite. Due to Q-termination of R, every (P, Q, R)-chain is minimal and thus,
there is no inﬁnite (P, Q, R)-chain, even if f = m.
Note that Q′-termination of R′ follows from Q-termination of R by Lemma 1.
So if (P′, Q′, R′, f ′) is inﬁnite, there must be an inﬁnite (P′, Q′, R′)-chain. But
then this is also an inﬁnite (P, Q, R)-chain which contradicts the observation
above. The reason is that tiσ Q′
→∗
R′ si+1σ implies tiσ Q→∗
R si+1σ by Lemma 1
and if siσ is a Q′-normal form then it is also a Q-normal form.
⊓⊔
3
DP Processors from the Dependency Pair Approach
In the classical dependency pair approach, ﬁniteness of a DP problem was shown
by ﬁrst modularizing the proof using the dependency graph (cf. Sect. 3.1.) Af-
terwards, a set of inequalities was generated and one tried to ﬁnd certain orders
satisfying these inequalities (cf. Sect. 3.2). Moreover, before constructing the de-
pendency graph, it was possible to transform dependency pairs (cf. Sect. 3.3). In
this section, we develop DP processors which perform these three tasks. Thus,
the whole dependency pair approach is now presented as a set of processors work-
ing on DP problems. Each step of the dependency pair approach is formulated
as a DP processor on its own. In this way, ﬂexibility is increased substantially:
now these DP processors may be applied repeatedly and in any order, whereas
their order of application was ﬁxed in the original dependency pair approach.

The Dependency Pair Framework
307
All processors in this section only modify the set of pairs P in a DP problem
(P, Q, R, f). Processors which also modify the sets Q and R will be discussed
in Sect. 4 and processors which also modify f will be shown in Sect. 5.
3.1
A DP Processor Based on the Dependency Graph
We now present a processor to decompose a DP problem into several separate
sub-problems. To this end, one tries to determine which pairs can follow each
other in chains by constructing a so-called dependency graph.
Deﬁnition 5 (Dependency Graph). Let (P, Q, R, f) be a DP problem. The
nodes of the (P, Q, R)-dependency graph are the pairs of P and there is an arc
from s →t to u →v iﬀs →t, u →v is a (P, Q, R)-chain.
Example 5. We regard the TRS for subtraction and division from Ex. 2 again.
Here we obtain the following (P, Q, R)-dependency graph for all Q ⊆R.
DIV(s(x), s(y)) →MINUS(x, y) (7)
DIV(s(x), s(y))→DIV(minus(x, y), s(y)) (8)
MINUS(s(x), s(y))→MINUS(x, y) (6)
Obviously, every inﬁnite chain corresponds to a cycle in the dependency
graph. Since this graph is in general not computable, for automation one con-
structs an estimated graph. To this end, one has to approximate whether two
pairs s →t, u →v form a (P, Q, R)-chain. In this case, one draws an arc from
s →t to u →v. As long as the approximation is sound (i.e., as long as it is
an over-approximation), the resulting graph contains the real dependency graph
and thus, every inﬁnite chain also corresponds to a cycle in the estimated graph.
In the classical dependency pair approach, several such approximations were
developed (e.g., [1,11]) and for example, all of them would be able to compute
the graph given in Ex. 5. However, instead of (P, Q, R)-chains, here one only
considered chains where Q = ∅(for full termination) or where Q = R (for in-
nermost termination). The latter were called “innermost chains”. By Lemma 1,
every (P, Q, R)-chain is also a (P, ∅, R)-chain (i.e., an ordinary chain in the
classical dependency pair approach) and if Q ⊇R, it is also an innermost chain.
Thus, all existing methods to (over-)approximate chains in the dependency pair
approach can also be used to approximate (P, Q, R)-chains for any Q. More-
over, if Q ⊇R, then all approximations for innermost chains can be applied as
well. Hence, one can still use the existing estimation techniques for (innermost)
dependency graphs in order to estimate (P, Q, R)-dependency graphs.
Now it is suﬃcient to prove absence of inﬁnite (minimal) chains for maximal
cycles (so-called strongly connected components, SCCs) of the dependency graph.
Here, a subset P′ of dependency pairs is called a cycle iﬀfor all pairs s →t and
u →v in P′, there is a path from s →t to u →v traversing only pairs from P′.
A cycle P′ is called an SCC if P′ is not a proper subset of any other cycle.

308
J. Giesl, R. Thiemann, and P. Schneider-Kamp
Theorem 2 (DP Processor Based on the Dependency Graph). The fol-
lowing DP Processor Proc is sound and complete. For a DP problem (P, Q, R, f)
Proc returns {(P1, Q, R, f), . . . , (Pn, Q, R, f)}, where P1, . . . , Pn are the SCCs
of the (estimated) (P, Q, R)-dependency graph.
Proof. Completeness follows from Lemma 2, since Pi ⊆P for all i. Proc is
sound since after a ﬁnite number of pairs in the beginning, any inﬁnite (minimal)
(P, Q, R)-chain only contains pairs from some SCC. Hence, there would also be
an inﬁnite (minimal) (Pi, Q, R)-chain for some Pi.
⊓⊔
Example 6. To prove Q-termination of the TRS R for subtraction and division
from Ex. 2, we start with the initial DP problem (P, Q, R, m), where P is the set
of dependency pairs {(6), (7), (8)}. As shown in Ex. 5, the SCCs of the depen-
dency graph consist of (6) and (8), respectively. Hence, the above DP processor
transforms the initial DP problem into the two new problems ({(6)}, Q, R, m)
and ({(8)}, Q, R, m). These two problems can now be solved independently. In
other words, we can now prove termination of minus and div separately.
In contrast to the classical dependency pair approach, now the dependency
graph can be (re-)computed at any time during the termination proof. This leads
to very modular proofs, since one may always decompose DP problems into sub-
problems which can be solved independently, e.g., by diﬀerent DP processors.
3.2
A DP Processor Based on Orders
Classical techniques for automated termination proofs try to ﬁnd a reduction or-
der ≻, i.e., an order which is well-founded, monotonic, and stable (closed under
contexts and substitutions), such that l ≻r holds for all rules l →r of the TRS.
In practice, one mainly uses simpliﬁcation orders, where a term is always greater
than its proper subterms [3,19]. Examples for such orders are the lexicographic or
recursive path order [3,14], the Knuth-Bendix order [15], and (most) polynomial
orders [17]. However, the power of this approach is limited, since termination of
many important TRSs cannot be proved with simpliﬁcation orders. For instance,
simpliﬁcation orders fail on the TRS of Ex. 2, since the left-hand side of Rule
(5) is embedded in its right-hand side if y is instantiated with s(x).
The dependency pair approach was introduced to overcome the limitations
of classical simpliﬁcation orders. For any TRS, it generates a set of inequality
constraints and if there exists a well-founded order satisfying the constraints,
then termination is proved. Hence, one can use existing techniques to search for
suitable orders and it turns out that in this way, classical simpliﬁcation orders
can prove termination of numerous TRSs where they would have failed otherwise.
We now formalize this idea in the context of the DP framework. To remove
pairs from P in a DP problem (P, Q, R, f), one can generate constraints which
should be satisﬁed by a reduction pair [16] (≿, ≻) where ≿is reﬂexive, transitive,
monotonic, and stable and ≻is a stable well-founded order compatible with ≿
(i.e., ≿◦≻⊆≻and ≻◦≿⊆≻). But ≻does not have to be monotonic. The
constraints require that at least one pair in P is strictly decreasing (w.r.t. ≻)
and all remaining pairs in P and all rules in R are weakly decreasing (w.r.t. ≿).

The Dependency Pair Framework
309
Requiring l ≿r for all rules l →r ∈R ensures that in chains s1 →t1, s2 →t2, . . .
with tiσ Q→∗
R si+1σ, we have tiσ ≿si+1σ. Hence, the existence of such a reduction
pair implies that there is no chain which contains the strictly decreasing pairs
of P inﬁnitely often. Thus, all of these pairs can be deleted from P.
If the Q-restricted rewrite relation is contained in the innermost rewrite
relation (i.e., if Q ⊇R), this approach can be improved. Now a weak decrease
l ≿r is not required for all rules but only for the usable rules. For any term t,
all function symbols occurring in t are “usable”. Moreover, if some symbol f is
usable and there is a rule f(. . .) →r in R whose right-hand side r contains a
symbol g, then g is usable as well. Let US(t, R) denote the set of usable symbols
and we deﬁne the usable rules U(t, R) as the set of those rules f(. . .) →. . . from
R where f ∈US(t, R). Analogously, for a TRS P, the usable symbols and rules
are deﬁned as US(P, R) = 
s→t∈P US(t, R) and U(P, R) = 
s→t∈P U(t, R).
Further reﬁnements to reduce the set of usable rules can be found in [8,12,21].
Example 7. Let R be the TRS of Ex. 2. For the problem ({MINUS(s(x), s(y))
→MINUS(x, y)}, Q, R, m) one would now have to ﬁnd a reduction pair (≿, ≻)
such that MINUS(s(x), s(y)) ≻MINUS(x, y) and l ≿r for all rules. But if one
only wants to prove innermost termination (or Q-termination for Q ⊇R), it
suﬃces to require l ≿r just for the usable rules. Since the only usable symbol
of the dependency pair’s right-hand side MINUS(x, y) is MINUS, there are no
usable rules. So for this DP problem, one only has to ﬁnd a stable well-founded
order ≻satisfying MINUS(s(x), s(y)) ≻MINUS(x, y). This can easily be done
with any of the existing classical reduction orders. Thus, the dependency pair
can be deleted and the resulting DP problem (∅, Q, R, m) is transformed into
the empty set by the dependency graph processor of Thm. 2.
In [21], we recently extended previous results of [8,23] and showed that if one
only has to prove absence of minimal chains (i.e., if f = m), then usable rules
can also be used for proving full instead of just innermost termination, provided
that ≿is Cε-compatible (i.e., c(x, y) ≿x and c(x, y) ≿y for a fresh function
symbol c). This holds for virtually all relations ≿generated automatically by
standard techniques. Then, to prove Q-termination (for arbitrary Q) it is enough
to require l ≿r just for the usable rules. In this way, the DP problem for minus
can be solved as in Ex. 7 for arbitrary Q.
To generate reduction pairs (≿, ≻) automatically, one often uses classical
(monotonic) simpliﬁcation orders. However, ≻does not have to be monotonic.
To beneﬁt from this possibility and to build non-monotonic orders from sim-
pliﬁcation orders, one may pre-process the constraints ﬁrst and delete certain
function symbols and arguments by an argument ﬁltering π [1]. For example,
if π1 eliminates the second argument of the function symbol minus, then for
any term t, π1(t) results from replacing all subterms minus(t1, t2) by minus(t1).
Moreover, one can also use argument ﬁlterings which collapse function symbols
to one of their arguments (i.e., one could also deﬁne an argument ﬁltering π2 with
π2(minus(t1, t2)) = t1). Now instead of a reduction pair (≿, ≻), one may use the
reduction pair (≿π, ≻π) with s ≿π t iﬀπ(s) ≿π(t) and s ≻π t iﬀπ(s) ≻π(t).
Techniques to search for argument ﬁlterings eﬃciently were developed in [8,11].

310
J. Giesl, R. Thiemann, and P. Schneider-Kamp
Example 8. Regard the other DP problem ({DIV(s(x), s(y)) →DIV(minus(x, y),
s(y))}, Q, R, m) resulting from the TRS R of Ex. 2. The usable rules of the term
DIV(minus(x, y), s(y)) are just the minus-rules. Thus, if we use Cε-compatible re-
lations ≿, it suﬃces to ﬁnd a reduction pair (≿, ≻) and an argument ﬁltering π
such that DIV(s(x), s(y)) ≻π DIV(minus(x, y), s(y)) and l ≿π r for all minus-rules.
If we apply the argument ﬁltering π1 above, the constraint from the de-
pendency pair becomes DIV(s(x), s(y)) ≻DIV(minus(x), s(y)) and if we use the
argument ﬁltering π2, it becomes DIV(s(x), s(y)) ≻DIV(x, s(y)). In both cases,
all resulting constraints can easily be satisﬁed (e.g., by the lexicographic path or-
der). Thus, the dependency pair can be deleted from this DP problem as well and
in this way, termination of the TRS in Ex. 2 can easily be shown automatically.
For any TRS P and any relation ≻, let P≻= {s →t ∈P | s ≻t}, i.e.,
P≻contains those rules of P which decrease w.r.t. ≻. Now we can deﬁne a DP
processor which deletes all pairs from P which are strictly decreasing w.r.t. a
reduction pair and an argument ﬁltering (i.e., all pairs of P≻π). The reason is
that they cannot occur inﬁnitely many times in a chain.
Theorem 3 (DP Processor Based on Reduction Pairs). Let (≿, ≻) be a
reduction pair and π be an argument ﬁltering. Then the following DP processor
Proc is sound and complete. For a DP problem (P, Q, R, f), Proc returns
• {(P \ P≻π, Q, R, f)}, if
– P≻π ∪P≿π = P and
– R≿π ⊇U(P, R) and
– Q ⊇R
or
R≿π = R
or
(≿is Cε-compatible and f = m)
• {(P, Q, R, f)}, otherwise
Proof. Completeness follows from Lemma 2. If ≿is Cε-compatible, soundness is
proved as in [21, Thm. 22]. (The extension from ordinary to Q-restricted rewrit-
ing is completely straightforward.) The case R≿π=R is the classical dependency
pair approach for termination and its soundness is proved in [7, Thm. 3.5] and [1,
Thm. 11]. Finally, for the case Q ⊇R recall that the Q-restricted rewrite relation
is contained in the innermost rewrite relation and thus, every (P, Q, R)-chain is
an innermost chain. Hence, then the soundness follows from the corresponding
result of [7, Thm. 5.6] for innermost termination.
⊓⊔
Whenever a processor modiﬁes a DP problem, it is usually advantageous to
apply the dependency graph processor of Thm. 2 afterwards. The reason is that
in this way one can split the DP problem into new subproblems and probably
also remove further rules of P. This is a generalization of a strategy which was
originally suggested within the classical dependency pair approach in [11]. Here,
SCCs of the dependency graph were re-computed whenever some dependency
pairs were strictly oriented and therefore removed. In the DP framework, this
would now correspond to a repeated alternating application of the processors in
Thm. 2 and in Thm. 3. However, by formalizing termination techniques as DP
processors, many additional strategies can now easily be formulated as well, cf.
Sect. 6.

The Dependency Pair Framework
311
3.3
DP Processors Based on Dependency Pair Transformations
As shown in [1,6,8], to increase the power of the dependency pair approach, a
dependency pair may be transformed by rewriting, narrowing, or instantiation.
We now adapt these transformations to the DP framework. Given a DP problem
(P, Q, R, f), they replace one of the pairs s →t in P by several new ones (i.e.,
the result is of the form (P′, Q, R, f)). In contrast to the previous processors,
we usually do not have P′ ⊆P, but P′ is obtained by replacing s →t with new
pairs resulting from rewriting, narrowing, or instantiating s →t.
Compared to the original versions of these transformations in the dependency
pair approach, they are now improved and modularized considerably. The reason
is that now these transformations can be applied at any time during the proof
and the conditions for their applicability only have to take the pairs and rules
in the current DP problem into account. In this way, these conditions are much
more often satisﬁed than in the original dependency pair approach, where such
transformations were only permitted in the very beginning.
In the dependency pair approach, there were two variants of the narrowing
and the instantiation transformation (for termination and for innermost termi-
nation, respectively), cf. [8]. The DP processors for narrowing and instantiation
are immediately obtained from the original transformations, by applying the
variants for termination if Q = ∅and by applying the variants for innermost
termination if Q ⊇R.4 The soundness and completeness results for these trans-
formations directly carry over from the classical dependency pair approach to
their versions in the DP framework: instantiation is sound and complete and
narrowing is sound. Completeness of narrowing holds as well in the termination
case (i.e., if Q = ∅), but not if Q ⊇R, cf. [1, Ex. 43]. The proofs for these
results are completely analogous to the ones in the dependency pair approach
(i.e., to [1, Thm. 27 and 42] for narrowing and to [6, Thm. 20] for instantiation).
While adapting narrowing and instantiation to the DP framework is straight-
forward, the adaption of the rewriting transformation is more problematic. In
the classical dependency pair approach, rewriting is only applicable for inner-
most termination proofs (i.e., if Q = R). The problem is that the original proofs
for its soundness and completeness [6, Thm. 14, 15, 18, 19] do not extend to the
case where Q ⊇R.5 However, such an extension is urgently required in the DP
framework, since in Sect. 4 we will introduce new powerful DP processors which
reduce the set of rules R in a DP problem. Thus, even if one starts with an inner-
most termination problem (P, Q, R, f) where Q = R, after application of some
4 Of course, when applying the transformations for Q ⊇R instead of “normal forms”
in [8] one always has to regard “Q-normal forms”.
5 In contrast to the narrowing and instantiation transformations which perform all
possible narrowings or instantiations, here one may replace s →t by any pair result-
ing from rewriting t. The soundness proof relies on the result that weak innermost
termination and non-overlappingness imply conﬂuence and termination [10] and the
completeness proof relies on the result that innermost termination implies normaliza-
tion. Obviously, these results do not extend to Q ⊇R, i.e., in general Q-termination
and non-overlappingness do not imply conﬂuence, termination, or normalization.

312
J. Giesl, R. Thiemann, and P. Schneider-Kamp
DP processors one might result in a problem (P′, Q′, R′, f ′) where Q′ ⊃R′. Now
it would be desirable if one could still apply the rewriting transformation (this
will be demonstrated in Ex. 14). Therefore, we now present a new proof to show
that the rewriting transformation is sound for any Q ⊇R in the DP framework.
Moreover, if for all subterms q below the position where the rewriting took place
we have U(q, Q) ⊆R, then it is also complete. So q’s usable rules w.r.t. Q also
have to be contained in R. In the special case of innermost termination where
Q = R, this completeness condition is always fulﬁlled (i.e., our results encompass
the completeness result for innermost termination from [6, Thm. 19]).6
For the proof, we need the following suﬃcient criterion for conﬂuence of the
Q-restricted rewrite relation. It states that if there are no critical pairs on the
root level, then we even have the diamond property (i.e., if t Q→R t1 and t Q→R t2,
then t1 = t2 or there exists a t′ such that t1
Q→R t′ and t2
Q→R t′).
Lemma 3 (Conﬂuence of Q→R). Let Q ⊇R and let R be non-overlaying (i.e.,
left-hand sides of diﬀerent R-rules do not unify after variable renaming). Then
Q→R has the diamond property and hence, it is conﬂuent.
Proof. Let t Q→R,p1 t1 and t Q→R,p2 t2. Since t|p1 and t|p2 are no R-normal forms
and thus no Q-normal forms (by Q ⊇R), p2 cannot be strictly above p1 and p1
cannot be strictly above p2. If p1 = p2, then t1 = t2, as we used the same rule in
both reductions since R is non-overlaying. Otherwise, p1 and p2 are not above
each other, and thus, t1 and t2 can obviously be joined in one step.
⊓⊔
Now we introduce the rewriting processor. It states that in a DP problem
(P, Q, R, f) with Q ⊇R, any s →t ∈P can be replaced by s →t′ if t rewrites
to t′ at some position p. The only applicability condition is that the usable rules
for the redex t|p must be non-overlapping (i.e., they must not have critical pairs).
Theorem 4 (Rewriting Processor). Let Proc be a processor which trans-
forms a DP problem (P ∪{s →t}, Q, R, f) either into {(P ∪{s →t′}, Q, R, f)}
or into {(P ∪{s →t}, Q, R, f)} again. In the ﬁrst case, the following two con-
ditions must be satisﬁed:
• t →R,p t′ and U(t|p, R) is non-overlapping
• Q ⊇R
Proc is sound, and it is complete if U(q, Q)⊆R for all proper subterms q of t|p.
Proof. Let t = t[lµ]p →R t[rµ]p = t′ for some l →r ∈R and a substitution µ.
We ﬁrst prove the soundness and only consider the case where f = m. The
case f = a is analogous. Let s →t, u →v be a minimal (P, Q, R)-chain. Thus,
tσ Q→∗
R uσ, both sσ and uσ are in Q-normal form, and tσ and vσ are terminating
w.r.t. Q→R. We want to show that t′σ Q→∗
R uσ and that t′σ is also terminating
w.r.t. Q→R. Then we can exchange all occurrences of s →t in chains by s →t′.
6 A similar completeness result also holds for narrowing: if Q ⊇R, then the narrowing
processor is still complete if for all narrowed subterms, the usable rules w.r.t. R are
non-overlapping and for all subterms q below those positions that were narrowed we
have U(q, Q) ⊆R. Again, the latter condition is always satisﬁed if Q = R. Thus,
this encompasses the completeness result of [6, Thm. 17] for innermost termination.

The Dependency Pair Framework
313
We consider the reduction tσ = tσ[lµσ]p
Q→∗
R uσ. As uσ is in Q-normal form
and as Q→R-reductions cannot take place above Q-redexes, w.l.o.g. we ﬁrst reduce
lµσ to some Q-normal form w. Thus, tσ = tσ[lµσ]p
Q→∗
R tσ[w]p
Q→∗
R uσ where
lµσ Q→∗
R w. Since σ instantiates all variables by normal forms w.r.t. Q ⊇R,
the only rules applicable to t|pσ = lµσ or its reducts are from U(t|p, R). For
readability, we abbreviate U(t|p, R) by U. Hence, lµσ Q→∗
U w. As w is a Q-normal
form, w.l.o.g. one ﬁrst reduces all terms xµσ with x ∈V(l) to Q-normal forms.
As U is non-overlapping and Q ⊇R ⊇U, by Lemma 3 these normal forms are
unique. Thus, lµσ Q→∗
U lδ Q→∗
U w for some Q-normal substitution δ (i.e., δ(x) is in
Q-normal form for all x ∈V) and for all x ∈V(l) we have xµσ Q→∗
U xδ. Note that
lδ is not yet a Q-normal form as l →r ∈R ⊆Q. Thus, we need at least one more
step to get from lδ to w. As δ is a Q-normal substitution, the reduction is above
δ and as U is non-overlapping, the only possible reduction is lδ Q→U rδ Q→∗
U w.
This ﬁnally proves t′σ = tσ[rµσ]p
Q→∗
R tσ[rδ]p
Q→∗
R tσ[w]p
Q→∗
R uσ.
Now minimality (i.e., termination of t′σ w.r.t. Q→R), can be proved in an
analogous way. As before, w.l.o.g. any inﬁnite Q→R-reduction of t′σ = tσ[rµσ]p
ﬁrst reduces all redexes in xµσ for x ∈V(r). These reductions either lead to
non-termination or they end in some Q→R-normal forms. Since x ∈V(r) ⊆V(l),
all xµ are contained in t|p. As σ instantiates variables by normal forms w.r.t.
Q ⊇R, again the only rules applicable to subterms of t|pσ (like xµσ) are from
U. As Q→U is conﬂuent by Lemma 3, the reduction must begin with rµσ Q→∗
R rδ.
Hence, whenever t′σ is non-terminating w.r.t. Q→R then so is tσ[rδ]p. But this
would contradict the termination of t w.r.t. Q→R as we know that t Q→∗
R tσ[rδ]p.
The completeness of the rewriting processor is obvious if R is not Q-termina-
ting. Otherwise, we show that if there is a reduction t′σ Q→∗
R uσ such that sσ
and uσ are in Q-normal form, then tσ
Q→∗
R uσ also holds. We use the same
way of reasoning as for the soundness proof. So if t′σ = tσ[rµσ]p
Q→∗
R uσ,
we may assume that we ﬁrst reduce rµσ to some Q-normal form w which is
again done with Q→U reductions. By the conﬂuence of Q→U (Lemma 3), we have
rµσ Q→∗
U rδ Q→∗
U w for some Q-normal substitution δ. In the same way as before
we obtain t′σ = tσ[rµσ]p
Q→∗
R tσ[rδ]p
Q→∗
R tσ[w]p
Q→∗
R uσ. It remains to show
that lµσ Q→R∗rδ, as this implies tσ = tσ[lµσ]p
Q→∗
R tσ[rδ]p
Q→∗
R tσ[w]p
Q→∗
R uσ.
We know that xµσ Q→∗
R xδ for all x ∈V(r), where xδ is in Q-normal form.
By Q ⊇R, xδ is in normal form w.r.t. Q→R, too. As R is Q-terminating, we
can extend δ such that xδ is a normal form of xµσ w.r.t. Q→R for every variable
x ∈V(l)\V(r). Then we have lµσ Q→R∗lδ. To prove the desired result lδ Q→R rδ,
we show that lδ does not contain Q-redexes as proper subterms.
First suppose that lδ contains a Q-redex at a position o of l where l|o /∈V.
If a rule l′ →r′ ∈Q can be applied to l|oδ at root position, then we have
l′ →r′ ∈U(l|o, Q) ⊆U(l|oµ, Q) ⊆R, by the prerequisite of the theorem. Since
root(l′) occurs in l|o and hence in l, we also have l′ →r′ ∈U(t|p, R). But then
l′ →r′ and l →r are two rules from U(t|p, R) which form a critical pair. This
contradicts the requirement that U(t|p, R) is non-overlapping.
Now we show that xδ cannot contain a Q-redex for x ∈V(l). Note that if xδ
is not a Q-normal form, it is also not a normal form w.r.t. Q→Q. Thus, there is a

314
J. Giesl, R. Thiemann, and P. Schneider-Kamp
term w′ such that xµσ Q→∗
Q xδ Q→Q w′. We now show that Q-reductions starting
from xµσ can only use rules from R. Then we also have xµσ Q→∗
R xδ Q→R w′.
But this contradicts the fact that xδ is in normal form w.r.t. Q→R.
Any Q-reduction starting from xµσ only uses rules from U(xµ, Q), since σ
is a Q-normal substitution. As xµ is a subterm of t|p, by the prerequisite of the
theorem we have U(xµ, Q) ⊆R. Thus, any Q-reduction starting from xµσ can
indeed only use rules from R.
⊓⊔
Example 9. We replace the minus-rule (3) of Ex. 2 by the following rules:
minus(s(x), s(y)) →minus(p(s(x)), p(s(y)))
(9)
minus(x, plus(y, z)) →minus(minus(x, y), z)
(10)
p(s(x)) →x
(11)
plus(0, y) →y
(12)
plus(s(x), y) →s(plus(x, y)) (13)
Now (innermost) termination cannot be shown by the previous processors (if
one uses reduction pairs based on (quasi-)simpliﬁcation orders in Thm. 3).7 The
reason is that the dependency pair MINUS(s(x), s(y)) →MINUS(p(s(x)), p(s(y)))
from Rule (9) is not strictly decreasing w.r.t. any classical reduction order.
However, by the rewrite processor, the right-hand side of this dependency
pair can be rewritten twice to obtain MINUS(s(x), s(y)) →MINUS(x, y). The
processor is applicable, since the only usable rule of the redexes p(s(x)) and
p(s(y)) is (11) which is non-overlapping (although the whole TRS is overlapping).
Afterwards, innermost termination can easily be shown. However, since rewriting
is only possible for Q ⊇R, this step is not permitted if one wants to prove
termination (where Q = ∅). Note that this TRSs does not belong to those classes
of TRSs where it is known that innermost termination implies termination. (A
well-known such class are locally conﬂuent overlay systems [10], but due to Rule
(10) this system is neither locally conﬂuent nor an overlay system.) In Sect. 4,
we will introduce new DP processors to simplify DP problems and it will turn
out that then the termination of this example is very easy to prove, cf. Ex. 14
and 15.8
The following examples show why straightforward extensions of the rewriting
processor would destroy soundness or completeness, respectively.
Example 10. Since non-overlayingness already implies conﬂuence of the Q-re-
stricted rewrite relation by Lemma 3, a natural question is whether the rewrite
7 Here, ≿is a quasi-simpliﬁcation order if s ≿t for all subterms t of s. However, a
proof with Thm. 3 using the very recently developed negative polynomial orders of
[13] would be possible. An example where negative polynomials fail as well is Ex. 16.
8 Alternatively, termination can also be proved using the narrowing transforma-
tion. Then the right-hand side MINUS(p(s(x)), p(s(y))) would be replaced by its
narrowings MINUS(x, p(s(y))) and MINUS(p(s(x)), y). However, narrowing is only
permitted for right-hand sides of dependency pairs which do not unify with left-
hand sides. Thus, narrowing would no longer be possible if one adds the rule
minus(p(x), y) →p(minus(x, y)), since MINUS(p(s(x)), p(s(y))) uniﬁes with the left-
hand side of the new dependency pair MINUS(p(x), y) →MINUS(x, y). In contrast,
the termination proof with the new DP processors in Ex. 14 and 15 would still work.

The Dependency Pair Framework
315
processor in Thm. 4 would already be sound if the usable rules U(t|p, R) are
just non-overlaying instead of non-overlapping. This is refuted by the following
counterexample. Let R = Q = {f(c) →d, f(h(x)) →a, h(b) →c, g(d, x) →
g(f(h(x)), x)}. Then R is not innermost terminating (i.e., not Q-terminating):
g(d, b)
i→R g(f(h(b)), b)
i→R g(f(c), b)
i→R g(d, b)
i→R . . .
The dependency graph has only one SCC {G(d, x) →G(f(h(x)), x)}. Since R
is non-overlaying and G(f(h(x)), x) →R G(a, x), rewriting would transform the
dependency pair of the SCC into the new pair G(d, x) →G(a, x). Now the de-
pendency graph processor would delete this pair, since it is obviously not on any
cycle of the (new) dependency graph. Thus, we could falsely “prove” termination.
The problem is that although the dependency pair was rewritten by a Q-
restricted step, it is no longer Q-restricted if one instantiates x with b. So to guar-
antee that any reduction from G(f(h(x)), x)σ to an instantiated left-hand side of
a dependency pair is also possible from G(a, x)σ, one needs non-overlappingness
and not just conﬂuence of U(t|p, R)’s Q-restricted rewrite relation.
Example 11. This processor shows why we deﬁned a DP problem (P, Q, R, f) to
be “inﬁnite” if it is not ﬁnite or if R is not Q-terminating, cf. Def. 4. The reason
is that if “inﬁnite” would be deﬁned as “not ﬁnite”, then the rewriting pro-
cessor would be incomplete, i.e., it could transform DP problems that are not
inﬁnite into problems with inﬁnite chains, even if Q = R. Let P = {F(x, x) →
F(b, g(a(x), x))} and Q = R = {g(x, y) →y, a(b) →a(b)}. Obviously, R is not
Q-terminating. But there is no inﬁnite (P, Q, R)-chain as F(b, g(a(x1), x1))σ Q→R∗
F(x2, x2)σ implies σ(x2) = b. Thus F(b, g(a(x2), x2))σ = F(b, g(a(b), b)) can only
be reduced by Q→R to itself, but it does not unify with F(x3, x3).
However, the rewriting processor could rewrite the right-hand side F(b,
g(a(x), x)) of the dependency pair to F(b, x). This results in P′ = {F(x, x) →
F(b, x)}. Now there is clearly an inﬁnite (minimal) (P′, Q, R)-chain.
Example 12. Finally, we also show that the condition U(q, Q) ⊆R for all proper
subterms q of t|p is required for completeness. We again let P = {F(x, x) →
F(b, g(a(x), x))}. Moreover, R = {g(x, y) →y} and Q = R ∪{a(b) →a(b)}.
Now R is Q-terminating. As in Ex. 11, there is no inﬁnite (P, Q, R)-chain. But
the rewriting processor would replace P by P′ = {F(x, x) →F(b, x)} and there is
again a minimal inﬁnite (P′, Q, R)-chain. Note however, that the redex g(a(x), x)
of the reduction has a proper subterm a(x) whose usable rules w.r.t. Q are not
contained in R. So the condition for completeness in Thm. 4 is violated.
4
New Dependency Pair Processors
Now we introduce new processors which improve the power of termination analy-
sis considerably. The techniques of the classical dependency pair approach from
Sect. 3 only modify the pairs P in a DP problem (P, Q, R, f). In contrast, we
now present techniques to decrease the underlying set of rules R (Sect. 4.1 and
4.2) or to increase the set Q that restricts possible redexes (Sect. 4.3).

316
J. Giesl, R. Thiemann, and P. Schneider-Kamp
4.1
DP Processors Based on Usable Rules
The ﬁrst processor shows that in a DP problem (P, Q, R, f) one can remove all
non-usable rules from R if Q ⊇R (i.e., if Q→R ⊆
i→R).
Example 13. After applying the dependency graph processor, the TRS R for
division from Ex. 2 results in the problems ({MINUS(s(x), s(y)) →MINUS(x, y)},
Q, R, m) and ({DIV(s(x), s(y)) →DIV(minus(x, y), s(y))}, Q, R, m), cf. Ex. 5.
When proving innermost termination (or if Q ⊇R), one can replace R by
the usable rules of MINUS(x, y) and DIV(minus(x, y), s(y)), respectively. So the
problems become ({MINUS(s(x), s(y))→MINUS(x, y)},Q, ∅, m) and ({DIV(s(x),
s(y)) →DIV(minus(x, y), s(y))}, Q, R′, m), where R′ are the minus-rules.
A similar restriction to the usable rules was already possible with the DP
processor based on reduction pairs in Thm. 3. However, with that processor
one immediately had to ﬁnd a reduction pair which orients the usable rules
U(P, R) and the pairs in P, and afterwards one remained with a DP problem
(P\P≻π, Q, R, f) which still contains the full set of rules R. In contrast, this new
processor requires no orientation with reduction pairs and it has the advantage
that subsequent DP processors can beneﬁt from the removal of non-usable rules.
Therefore whenever Q ⊇R, this processor should be applied ﬁrst.
Theorem 5 (DP Processor Based on Usable Rules). The following DP
processor Proc is sound and complete. For a DP problem (P, Q, R, f), Proc
returns { (P, Q, U(P, R), f) } if Q ⊇R and { (P, Q, R, f) } otherwise.
Proof. Completeness follows from Lemma 2. For soundness, let s1 →t1, s2 →
t2, . . . be an inﬁnite (P, Q, R)-chain. Thus there is a σ such that tiσ Q→∗
R si+1σ,
siσ is in Q-normal form, and if the chain is minimal then tiσ is terminating
w.r.t. Q→R for all i. By Lemma 1 then tiσ also terminates w.r.t. Q→U(P,R).
Since σ instantiates all variables by normal forms w.r.t. Q ⊇R, the only rules
applicable to tiσ or its reducts are from U(P, R). Hence, tiσ Q→∗
U(P,R) si+1σ. So
s1 →t1, s2 →t2, . . . is also an inﬁnite (minimal) (P, Q, U(P, R))-chain.
⊓⊔
Note that completeness of this processor is due to our new notions of “Q-
restricted rewriting” and of “(P, Q, R)-chains”, which use two diﬀerent TRSs
Q and R to restrict potential redexes and to determine possible rewrite steps,
respectively. In other words, this processor would be incomplete in the origi-
nal dependency pair approach, where one regarded innermost termination and
“innermost chains”. As an example let P = {F(a, x) →F(x, x)} and R =
{f(a, x) →f(x, x), a →b}. Now there is no inﬁnite innermost chain (i.e., no
inﬁnite (P, R, R)-chain), since the left-hand side of the dependency pair in P is
not in R-normal form. As there are no usable rules, this processor would replace
R by the empty set. In the DP framework, one would obtain the DP problem
(P, R, ∅, f) which still has no inﬁnite chain, but in the classical dependency
pair approach, the second component of this DP problem would be disregarded.
Since there is an inﬁnite (minimal) innermost chain of P’s dependency pair if
the underlying TRS is empty, then this processor would be incomplete.

The Dependency Pair Framework
317
A similar processor can also be deﬁned in the general case (for arbitrary Q).
Thus, this processor is also suitable for full (instead of just innermost) termina-
tion proofs. In contrast to Thm. 5, in order to apply this processor one has to
satisfy a set of constraints and one can only use it if one tries to prove absence
of minimal chains. On the other hand, this processor does not only delete non-
usable rules, but it also removes all rules from P and R that contain non-usable
symbols on their left-hand sides. To this end, for any TRS P and any subset F′ of
the signature we deﬁne P¬F′ as the set of those rules of P which contain symbols
on left-hand sides that are not in F′, i.e., P¬F′ = {s →t ∈P | s /∈T (F′, V)}.
As in Thm. 3, to apply this processor, all pairs in P and all their usable rules
have to be (weakly) decreasing. But in contrast to Thm. 3, none of the pairs in
P has to be strictly decreasing. On the other hand, now we require monotonicity
and Cε-compatibility of the order ≻and one may not use argument ﬁlterings.
Theorem 6 (DP Processor Based on Usable Rules and Reduction
Pairs). Let (≿, ≻) be a reduction pair where ≻is monotonic and Cε-compatible.
The following DP processor Proc is sound and complete. For a DP problem
(P, Q, R, f), Proc returns
• { (P \ P¬US(P,R), Q, U(P, R) \ R¬US(P,R), f) }, if
– P≿= P and
– R≿⊇U(P, R) and
– f = m
• { (P, Q, R, f) }, otherwise
Proof. Completeness follows by Lemma 2. For soundness, let s1 →t1, s2 →t2, . . .
be an inﬁnite minimal (P, Q, R)-chain. So there is a substitution σ and rules
{li,1 →ri,1, . . . , li,mi →ri,mi} ⊆R with mi ≥0 where tiσ = vi,0
Q→{li,1→ri,1}
vi,1
Q→{li,2→ri,2} . . . Q→{li,mi→ri,mi} vi,mi = si+1σ, siσ is in Q-normal form, and
the term tiσ is terminating w.r.t. Q→R for all i. We now show that this chain
ends in an inﬁnite minimal (P \ P¬US(P,R), Q, U(P, R) \ R¬US(P,R))-chain.
By [21, Lemma 16], there exists a mapping I : T (F, V) →T (F ∪{c}, V)
such that9 we have ti I(σ) = I(tiσ) = I(vi,0) →+
Cε∪(U(P,R)∩{li,1→ri,1}) I(vi,1)
→+
Cε∪(U(P,R)∩{li,2→ri,2}) . . . →+
Cε∪(U(P,R)∩{li,mi→ri,mi}) I(vi,mi) = I(si+1σ) →∗
Cε
si+1 I(σ). Here, “→Cε∪(U(P,R)∩{li,j→ri,j})” denotes a reduction with Cε ∪{li,j →
ri,j}, where the rule li,j →ri,j may only be used if it is contained in U(P, R).
Moreover, I(σ) is the substitution with I(σ) (x) = I(σ(x)) for all x ∈V.
As P ∪U(P, R)⊆≿and ≻is Cε-compatible, the reduction s1I(σ) →P t1I(σ)
→∗
Cε∪U(P,R) s2I(σ) →P t2I(σ) →∗
Cε∪U(P,R) . . . only has ﬁnitely many →Cε-steps.
So there is an n where for all i ≥n we have ti I(σ) = I(tiσ) = I(vi,0) →+
{li,1→ri,1}
I(vi,1) →+
{li,2→ri,2} . . . →+
{li,mi→ri,mi} I(vi,mi) = I(si+1σ) = si+1 I(σ).
9 As in the proof of Thm. 3, the lemma and the mapping I have to be adapted to
Q-restricted instead of full rewriting, which however is completely straightforward.

318
J. Giesl, R. Thiemann, and P. Schneider-Kamp
Due to the deﬁnition of I [21, Def. 14], for any term s ∈T (F, V) one proves by
structural induction that symbols from F \US(P, R) only occur below c-symbols
in I(s). So since si I(σ) = I(siσ) for i > n, symbols from F \ US(P, R) only
occur below c in si I(σ). As si does not contain c, we have si ∈T (US(P, R), V).
Thus, si →ti ∈P \ P¬US(P,R) for all i ≥n.
Inspection of the proof of [21, Lemma 16] reveals that the reductions from
I(tiσ) to I(si+1σ) never take place below any c-symbol. Hence by the observa-
tion above, in the redexes of this reduction, symbols from F \ US(P, R) only
occur below c-symbols. Thus the rules li,1 →ri,1, . . . , li,mi →ri,mi used for the
reductions are from U(P, R) \ R¬US(P,R).
Hence, even if one uses the original substitution σ instead of I(σ), all rules
li,j →ri,j used in the reduction from tiσ to si+1σ are from U(P, R)\R¬US(P,R).
Since these reductions were performed with Q-restricted rewriting, the tail sn+1
→tn+1, sn+2 →tn+2, . . . of the chain is an inﬁnite (P \ P¬US(P,R), Q, U(P, R) \
R¬US(P,R))-chain. The chain is also minimal: since all tiσ are terminating w.r.t.
Q→R, they are also terminating w.r.t. Q→U(P,R)\R¬US(P,R) by Lemma 1.
⊓⊔
Example 14. We regard the termination proof of the TRS R from Ex. 9, i.e.
minus(x, 0) →x
(1)
p(s(x)) →x
(11)
minus(0, s(y)) →0
(2)
plus(0, y) →y
(12)
minus(s(x), s(y)) →minus(p(s(x)), p(s(y)))
(9)
plus(s(x), y) →s(plus(x, y)) (13)
minus(x, plus(y, z)) →minus(minus(x, y), z)
(10)
together with the rules (4) and (5) for division. By the dependency graph pro-
cessor (Thm. 2) we get two DP problems corresponding to the termination of div
and plus (which can easily be solved) and the problem ({(14), (15), (16)}, ∅, R,
m) with the following dependency pairs:
MINUS(s(x), s(y)) →MINUS(p(s(x)), p(s(y)))
(14)
MINUS(x, plus(y, z)) →MINUS(minus(x, y), z)
(15)
MINUS(x, plus(y, z)) →MINUS(x, y)
(16)
As discussed in Ex. 9, this problem cannot be solved by the previous processors
if one uses reduction pairs based on (quasi-)simpliﬁcation orders.
We now show how the processor of Thm. 6 simpliﬁes this DP problem. An
eﬃcient approach to mechanize this processor is to use reduction pairs (≿, ≻)
based on linear polynomial interpretations Pol with coeﬃcients from {0, 1}. Due
to the monotonicity of ≻, for an n-ary function symbol f ∈F, we either have
Pol(f(t1, . . . , tn)) = Pol(t1)+. . .+Pol(tn) or Pol(f(t1, . . . , tn)) = Pol(t1)+. . .+
Pol(tn) + 1. Since there are just two possible interpretations for each function
symbol, the search space is small and our experiments show that with these
orders, the processor of Thm. 6 is already very successful.
Here, we use the polynomial interpretation Pol with Pol(f(t1, . . . , tn)) =
Pol(t1) + . . . + Pol(tn) for every function symbol f ∈F (i.e., Pol(f) = 0 for
constants f). With this reduction pair, the conditions of Thm. 6 are satisﬁed
whenever P and U(P, R) are non-duplicating. Therefore, we can now remove

The Dependency Pair Framework
319
the dependency pairs (15) and (16) and the rule (10) which contain the non-
usable symbol plus on their left-hand sides. Moreover, we can delete all non-
usable rules (i.e., all rules except the ones for p and minus). So the DP problem
({(14), (15), (16)}, ∅, R, m) is transformed to ({(14)}, ∅, {(1), (2), (9), (11)}, m).
The only deﬁned usable symbol in (14) is p. Hence, if we apply the processor
again with the same reduction pair as above, we can remove the non-usable
minus-rules. Thus, we obtain the DP problem ({(14)}, ∅, {(11)}, m). To solve
such DP problems, we will introduce another processor in the next section.
Obviously, the processor of Thm. 6 can also be applied for innermost ter-
mination proofs in the same way. Then we would obtain the resulting DP
problem ({(14)}, R, {(11)}, m) instead, i.e., then the second component would
be the original TRS. Note that since the processor of Thm. 6 removes rules
from the third component of the DP problem, the resulting problem is not a
real “innermost termination problem” anymore. In other words, now the sec-
ond component R is a proper superset of the third component {(11)}. Due
to our extension of the rewriting transformation to this case in Thm. 4, we
can still apply the rewriting processor and replace the dependency pair (14)
by MINUS(s(x), s(y)) →MINUS(x, y) as in Ex. 9. Afterwards, the proof can be
completed immediately. But if we would only have the classical rewrite transfor-
mation from the dependency pair approach, this step would not be possible.
4.2
A DP Processor Based on Removal of Rules
Now we introduce a processor to remove further rules from R. As in Thm. 3, for
a DP problem (P, Q, R, f), all rules in P and R are oriented with a reduction
pair (≿, ≻). The processor in Thm. 3 was used to remove pairs from P which
could be oriented with ≻. In contrast, the present processor removes rules from
both P and R if they can be oriented with ≻. On the other hand, here we are
again restricted to monotonic orders ≻and we may not use argument ﬁlterings.
Theorem 7 (DP Processor Based on Rule Removal). Let (≿, ≻) be a
reduction pair where ≻is monotonic. The following DP processor Proc is sound
and complete. For a DP problem (P, Q, R, f), Proc returns
• { (P \ P≻, Q, R \ R≻, f) }, if
– P≻∪P≿= P and
– R≻∪R≿= R
• { (P, Q, R, f) }, otherwise
Proof. Completeness follows by Lemma 2. For soundness, let s1 →t1, s2 →t2, . . .
be an inﬁnite (P, Q, R)-chain. So there is a σ with tiσ Q→∗
R si+1σ and if the chain
is minimal, then tiσ is terminating w.r.t. Q→R for all i.
As in the proof of [21, Thm. 23], one can show that in the reductions tiσ Q→R∗
si+1σ, R≻-rules are only applied for ﬁnitely many i and that si →ti ∈P≻only
holds for ﬁnitely many i as well. So si →ti ∈P \ P≻and tiσ Q→∗
R\R≻si+1σ for
all i ≥n for some n ∈IN. Moreover, if all tiσ are terminating w.r.t. Q→R, then
by Lemma 1 they are terminating w.r.t. Q→R\R≻as well. Thus, sn →tn, sn+1 →
tn+1, . . . is an inﬁnite (minimal) (P \ P≻, Q, R \ R≻)-chain.
⊓⊔

320
J. Giesl, R. Thiemann, and P. Schneider-Kamp
Example 15. We continue the termination proof of Ex. 14. To ﬁnish the proof, we
only have to solve the problem ({(14)}, ∅, {(11)}, m), i.e., ({MINUS(s(x), s(y))
→MINUS(p(s(x)), p(s(y)))}, ∅, {p(s(x)) →x}, m). With the DP processor of
Thm. 7 this can easily be done, whereas it is diﬃcult with the previous pro-
cessors. As with Thm. 6, for eﬃciency it is often enough to restrict oneself
to linear polynomial interpretations with coeﬃcients from {0, 1}. We use the
reduction pair based on the interpretation Pol with Pol(s(t)) = Pol(t) + 1
and Pol(f(t1, . . . , tn)) = Pol(t1) + . . . + Pol(tn) for every other symbol f ∈
F. In general, this reduction pair satisﬁes l ≿r whenever a rule l →r is
non-duplicating and the number of s-symbols in l is greater than or equal
to the number of s-symbols in r. By Thm. 7, those rules where l contains
more s-symbols than r can be removed. So in our example, the rule (11) (i.e.,
p(s(x)) →x) can be deleted. The resulting DP problem is ({MINUS(s(x), s(y)) →
MINUS(p(s(x)), p(s(y)))}, ∅, ∅, m).
Note that now p is not a deﬁned symbol anymore. Therefore, the dependency
pair MINUS(s(x), s(y)) →MINUS(p(s(x)), p(s(y))) is no longer on a cycle of the
dependency graph (since now terms starting with p cannot reduce to terms
starting with s anymore). This can be detected by all existing estimations of
dependency graphs (e.g., [1,11]). Hence by the the dependency graph processor
of Thm. 2, we obtain the empty set of DP problems, i.e., the termination proof
is completed. This demonstrates an advantage of the DP framework, since now
it is possible to apply techniques like the dependency graph repeatedly at any
point during the termination proof. In contrast, in the classical dependency pair
approach this technique was only applied at the beginning.
Note that similar to Thm. 5, in the classical dependency pair approach the
processor of Thm. 7 would not be complete for innermost termination. This is
shown by the example P = {F(a) →F(a)} and Q = R = {a →b}. There is no
inﬁnite innermost chain, but if one uses an order where a ≻b, one can replace R
by the empty set. Obviously, now one obtains an inﬁnite innermost chain (i.e.,
an inﬁnite (P, ∅, ∅, f)-chain), but there is no inﬁnite (P, R, ∅, f)-chain.
In [21, Thm. 23] we presented a ﬁrst method within the dependency pair
approach to remove rules of the TRS R that are not relevant for termination.
The processors in Thm. 6 and 7 are signiﬁcant improvements of this earlier
technique: there one could only eliminate strictly decreasing (usable) rules as
in Thm. 7, but it was impossible to remove non-usable rules and rules with
non-usable symbols in their left-hand sides as in Thm. 6. This removal of non-
usable rules is often crucial, since these rules often block the application of other
important processors, as will be shown in the next section (cf. Ex. 16).
4.3
A DP Processor to Switch to Innermost Termination
The following processor replaces a DP problem (P, Q, R, m) with Q ⊂R by
(P, R, R, m), i.e., under certain conditions it suﬃces to prove innermost instead
of full termination. Proving innermost termination is signiﬁcantly simpler: the
dependency graph is smaller (Sect. 3.1), there are less restrictions when applying
reduction pairs (Sect. 3.2), more dependency pair transformations are applicable
(Sect. 3.3), one may directly remove all non-usable rules (Sect. 4.1), etc.

The Dependency Pair Framework
321
So while the previous processors modiﬁed the ﬁrst and third components P
and R in a DP problem (P, Q, R, f), this processor modiﬁes the second compo-
nent Q. As shown in Lemma 2, while for P and R it is advantageous to remove
rules, for Q it is advantageous to add rules.
In the classical dependency pair approach, a switch from termination to in-
nermost termination was only possible if the whole TRS belongs to a class where
innermost termination implies termination. An example for such a class are lo-
cally conﬂuent overlay systems [10] or in particular, non-overlapping TRSs.
Instead, the following processor only requires local conﬂuence for the rules R
of the current DP problem. After applying the processors of Sect. 4.1 and 4.2, R
is usually just a small subset of the whole TRS. Moreover, R does not have to
be an overlay system. One only requires that R may not overlap with the pairs
in P. But the rules R themselves may have arbitrary critical pairs. This clearly
extends the known classes where innermost termination implies termination.
Theorem 8 (DP Processor for Modular Non-Overlap Check). The fol-
lowing processor is sound and complete. For a problem (P, Q, R, f), Proc returns
• {(P, R, R, f)}, if
– for all s →t ∈P, non-variable subterms of s do not unify with
left-hand sides of rules from R (after variable renaming) and
– Q→R is locally conﬂuent and
– Q ⊆R and
– f = m
• {(P, Q, R, f)}, otherwise
Proof. Completeness follows from Lemma 2. For soundness, we prove that under
the conditions of the ﬁrst case in Thm. 8, every minimal (P, Q, R)-chain s1 →
t1, s2 →t2, . . . also results in a minimal (P, R, R)-chain. There is a substitution
σ such that we have the following conditions for all i:
(a) tiσ Q→∗
R si+1σ
(b) siσ is in Q-normal form
(c) tiσ is terminating w.r.t. Q→R
By (a) and (c), σ(x) is terminating w.r.t. Q→R for all x ∈V(s2) ∪V(s3) ∪. . .
Since Q→R is locally conﬂuent, every σ(x) has a unique normal form σ(x)↓w.r.t.
Q→R by Newman’s lemma. Let σ′ be a substitution with σ′(x) = σ(x)↓for all
x ∈V(s2) ∪V(s3) ∪. . . and σ′(x) = σ(x) otherwise. For all i > 1 we obtain:
(i)
For all terms t we have tσ Q→∗
R tσ′.
(ii) If non-variable subterms of si do not unify with left-hand sides
of rules from R, then siσ′ is a normal form w.r.t. Q→R.
(iii) A term is an R-normal form iﬀit is a normal form w.r.t. Q→R.
The observations (i) and (ii) are obvious. For (iii), the “only if” direction follows
from Q→R ⊆→R (by Lemma 1). For the “if” direction, let t be a normal form

322
J. Giesl, R. Thiemann, and P. Schneider-Kamp
w.r.t. Q→R and assume that t contains R-redexes. Let t′ be an “innermost” R-
redex, i.e., all proper subterms of t′ are in R-normal form. Since Q ⊆R, they are
also in Q-normal form. But then t′ is also a redex w.r.t. Q→R. This contradicts
the assumption that t is a normal form w.r.t. Q→R.
Now we show that s2 →t2, s3 →t3, . . . is also a minimal (P, R, R)-chain. To
this end, we use the substitution σ′ instead of σ. For all i > 1 we have to prove:
(a′) tiσ′ R→∗
R si+1σ′
(b′) siσ′ is in normal form w.r.t. R
(c′) tiσ′ is terminating w.r.t. R→R
For (a′), note that tiσ Q→∗
R si+1σ Q→∗
R si+1σ′ by (a) and (i), where si+1σ′ is
a normal form w.r.t. Q→R by (ii). Moreover, since tiσ is terminating w.r.t. Q→R
and since Q→R is locally conﬂuent, si+1σ′ is the unique normal form of tiσ w.r.t.
Q→R by Newman’s lemma. Since tiσ Q→∗
R tiσ′ by (i), tiσ′ is terminating w.r.t.
Q→R by (c) and since R→R ⊆Q→R by Lemma 1, tiσ′ is also terminating w.r.t.
R→R. Let w be a normal form of tiσ′ w.r.t. R→R. As tiσ Q→∗
R w and as w is also
a normal form w.r.t. Q→R by (iii), w must be the unique normal form si+1σ′.
Hence, tiσ′ R→∗
R si+1σ′.
For (b′), siσ′ is a normal form w.r.t. Q→R by (ii). Thus, (iii) implies that it
is also a normal form w.r.t. R.
For (c′), we have tiσ Q→∗
R tiσ′ by (i). Thus, tiσ′ is terminating w.r.t. Q→R by
(c). Hence, tiσ′ is also terminating w.r.t. R→R since R→R ⊆Q→R by Lemma 1.
⊓⊔
To apply this processor to a DP problem (P, Q, R, m), one only has to check
that R does not overlap with P and one has to prove local conﬂuence of Q→R. In
practice, Thm. 8 is usually applied for Q = ∅(i.e., to switch from full to inner-
most termination). Then local conﬂuence is equivalent to joinability of critical
pairs and, for example, it suﬃces if R is non-overlapping. With such syntactic
suﬃcient conditions for its applicability, Thm. 8 can easily be automated.
Example 16. R results from replacing the plus-rules (12) and (13) in Ex. 14 by
plus(0, y) →y
(17)
plus(s(x), y) →s(plus(y, minus(s(x), s(0)))) (18)
and by adding the rule div(plus(x, y), z) →plus(div(x, z), div(y, z)).
To prove termination, now the dependency graph processor of Thm. 2 results
in three DP problems (corresponding to the termination of div, minus, and plus).
While the DP problems for div and minus can be solved as before, the DP problem
({(19)}, ∅, R, m) for plus cannot be handled with the existing processors if one
uses base orders based on (quasi-)simpliﬁcation orders or on (possibly negative)
polynomial interpretations. In contrast, innermost termination of the TRS is
easy to show. Here, (19) is the following dependency pair from Rule (18).
PLUS(s(x), y) →PLUS(y, minus(s(x), s(0)))
(19)
Since R is non-duplicating, we can apply the usable rule processor of Thm. 6
with the same polynomial interpretation as in Ex. 14 (i.e., Pol(f(t1, . . . , tn)) =
Pol(t1) + . . . + Pol(tn) for all f ∈F) and replace R by the usable rules, i.e., by

The Dependency Pair Framework
323
the p- and minus-rules. Moreover, Rule (10) can also be deleted, since it contains
the non-usable symbol plus on its left-hand side. Thus, the DP problem is trans-
formed into ({(19)}, ∅, {(1), (2), (9), (11)}, m). The TRS {(1), (2), (9), (11)} is
non-overlapping and thus, locally conﬂuent. Moreover, no non-variable subterm
of the left-hand side of (19) uniﬁes with a left-hand side of these rules after vari-
able renaming. Hence, we can apply the new DP processor of Thm. 8 to switch
to an innermost termination problem.10 To this end, we enlarge the second com-
ponent of the DP problem from the empty set to {(1), (2), (9), (11)}. So now we
have to solve the problem ({(19)}, {(1), (2), (9), (11)}, {(1), (2), (9), (11)}, m).
Note that the whole TRS R is overlapping and not locally conﬂuent. Thus,
it does not belong to a known class where innermost termination implies termi-
nation. Hence, this switch would not have been possible with existing results.
Since we now have an innermost termination problem, we may use the rewrit-
ing processor of Thm. 4 repeatedly to transform the pair (19) to PLUS(s(x), y)
→PLUS(y, x). Then the usable rule processor of Thm. 5 allows us to delete all
rules, since they are not usable anymore. Hence, we obtain the problem ({(19)},
∅, ∅, m). By Thm. 3, now it suﬃces to solve the constraint PLUS(s(x), y) ≻
PLUS(y, x) which is trivial by polynomial orders or recursive path orders.
By using Thm. 8 instead of removing rules as in Thm. 7, one also obtains
an alternative proof for the DP problem of minus. As seen in Ex. 14, after re-
moving all non-usable rules, one obtains the DP problem ({MINUS(s(x), s(y)) →
MINUS(p(s(s)), p(s(y)))}, ∅, {p(s(x)) →x}, m). Since the rule is locally conﬂu-
ent and does not overlap with the remaining dependency pair, now one can use
Thm. 8 to switch to the innermost case and easily solve the DP problem.
Ex. 15 already showed the advantages of re-computing the dependency graph
later during the termination proof. Now we have demonstrated that it can also
be beneﬁcial to use dependency pair transformations after some other processors
have been applied (like the usable rule processor of Thm. 6 and the processor for
the modular non-overlap check of Thm. 8). In contrast, in the classical depen-
dency pair approach, transformations could only be used in the very beginning of
a proof, but not after deleting rules, pairs, etc. This demonstrates an advantage
of the new modular DP framework.
Note that by Thm. 8, the observation that innermost termination implies
termination for locally conﬂuent overlay systems is obtained as a corollary. While
the original proof for this important result of Gramlich [10] is not at all trivial,
the proof of Thm. 8 is quite simple. While there already exists another easy
proof [18], in this way we get an alternative simple proof for this crucial result.
10 Deleting all non-usable rules with Thm. 6 is often needed to enable an application of
the modular non-overlap check from Thm. 8 afterwards. In this example, the non-
usable rules are not locally conﬂuent due to the new additional div-rule and there is
no other processor which can remove these rules (if one uses reduction pairs based
on (quasi-)simpliﬁcation orders). Therefore, if one would replace the new processor
of Thm. 6 with our previous related technique in [21, Thm. 23], then one cannot
switch to an innermost termination problem with Thm. 8 anymore and thus, the
termination proof would fail.

324
J. Giesl, R. Thiemann, and P. Schneider-Kamp
Corollary 2 (Thm. 3.23. in [10]). Let R be a locally conﬂuent overlay system.
If R is innermost terminating, then it is terminating.
Proof. R terminates if the DP problem (DP(R), ∅, R, m) is ﬁnite by Thm. 1.
For overlay systems, no non-variable subterms of left-hand sides from DP(R)
unify with variable-renamed left-hand sides from R. Thus by Thm. 8, it is suﬃ-
cient if the DP problem (DP(R), R, R, m) is ﬁnite. This follows from innermost
termination (i.e., R-termination) of R by Thm. 1.
⊓⊔
However, Thm. 8 improves Gramlich’s result signiﬁcantly. Even if R is not a
locally conﬂuent overlay system, by representing the termination task as a DP
problem, one may ﬁrst apply other processors to obtain sub-problems (P′, ∅, R′,
m) where R′ is indeed locally conﬂuent and does not overlap with P′. For these
sub-problems, one can now switch to the innermost case, whereas Gramlich’s
result would not be applicable. As demonstrated in Ex. 16, this switch can be
crucial for the termination proof.
5
DP Processors from Other Techniques
Now we show how to integrate existing termination techniques in the DP frame-
work. In this way, these techniques can beneﬁt from other DP processors which
were applied before. This increases their applicability and power considerably.
Deﬁnition 6 (Termination Technique). A termination technique TT maps
TRSs to TRSs such that termination of TT(R) implies termination of R.
Note that the above deﬁnition captures both transformational techniques
(which transform a TRS R into a new TRS R′ whose termination is suﬃcient
for termination of R) and traditional techniques which simply give a “yes” or
“no” answer when trying to prove termination. For those techniques, we would
deﬁne TT(R) = ∅if termination of R can be proved and TT(R) = R, otherwise.
Now at any point during the termination proof, instead of solving a DP
problem (P, Q, R, f) one can use a termination technique and verify termination
of TT(P ∪R). To this end, one should of course use the DP framework again.
Hence, we now deﬁne a processor to integrate arbitrary termination techniques.
Theorem 9 (DP Processor for Termination Techniques). Let TT be a
termination technique and let Proc be a DP processor with Proc((P, Q, R, f)) =
{(DP(R′), ∅, R′, m)} where TT(P ∪R) = R′. Then Proc is sound.
Proof. Obvious from Thm. 1.
⊓⊔
It is easy to show that if P’s rules have tuple symbols on their root posi-
tions,11 if Q = ∅, and if TT is “complete” (i.e., TT(P ∪R) terminates iﬀP ∪R
terminates), then the above processor is also complete.
11 More precisely, one requires root(s), root(t) ∈F ′ for all s →t ∈P and some F ′ ⊆F,
while F′-symbols do not occur anywhere else in P and they also do not occur in R.

The Dependency Pair Framework
325
Of course, if a termination technique TT is capable of handling Q-restricted
rewriting, then one could easily take this into account: Now TT would be applied
to pairs (Q, R) and return a pair (Q′, R′) such that Q′-termination of R′ is
suﬃcient for Q-termination of R. Hence, a DP problem (P, Q, R, f) may now
be transformed into (DP(R′), Q′, R′, m) where TT(Q, P ∪R) = (Q′, R′).
To improve the applicability of termination techniques, one may pre-process
a DP problem (P, Q, R, f) before. The reason is that there exist powerful termi-
nation techniques which can only be applied to subclasses of TRSs. For example,
the RFC matchbounds technique of [5] or the method of string reversal only op-
erate on string rewrite systems (SRSs), i.e., on TRSs where all occurring function
symbols have arity 1. To make such techniques applicable, one may perform a
pre-processing step which transforms a DP problem with non-unary symbols
into a problem on SRSs.
Note that the processors of the previous sections never change the ﬂag f when
transforming a DP problem (P, Q, R, f). Thus, when starting with the initial DP
problem (DP(R), Q, R, m), all resulting problems have the ﬂag f = m. However,
for the pre-processing mentioned above, we will also introduce processors which
modify the ﬂag by changing it to a. In other words, while for the original DP
problem it was suﬃcient to prove absence of minimal chains, for the problems
resulting from these processors one has to prove absence of all arbitrary chains.
Applying such processors usually has the disadvantage that afterwards, many
other processors are no longer applicable, since they only work on DP problems
with f = m, i.e., on problems where one only examines minimal chains. However,
if one re-builds the dependency pairs afterwards as in Thm. 9, then any DP
problem is changed back again into a problem with the ﬂag f = m. For this
reason, if one has obtained a DP problem with the ﬂag a, it can even be useful to
apply Thm. 9 with the “empty” termination technique where TT(P∪R) = P∪R,
since afterwards it is again suﬃcient to regard only minimal chains.
We now introduce two processors which are very useful as pre-processing
steps before applying termination techniques. The ﬁrst processor ProcU removes
all non-usable rules from a reduction pair (without checking any further condi-
tions as in Thm. 6). This corresponds to the usable rule processor of Thm. 5,
but in contrast to Thm. 5 the new processor is applicable for arbitrary Q, not
just for Q ⊇R. However, one now has to add Cε = {c(x, y) →x, c(x, y) →y}
to the usable rules. Moreover, we introduce a processor which allows us to ap-
ply argument ﬁlterings to the rules and pairs in a DP problem. Here, we deﬁne
π(R) = {π(l) →π(r) | l →r ∈R} for any TRS R.
Theorem 10 (Pre-Processing DP Processors). The following DP proces-
sors ProcU and Procπ are sound.
• For a DP problem (P, Q, R, f), ProcU returns
– { ( P, ∅, U(P, R) ∪Cε, a) }, if f = m
– {(P, Q, R, f)}, otherwise

326
J. Giesl, R. Thiemann, and P. Schneider-Kamp
• Let π be an argument ﬁltering. For a DP problem (P, Q, R, f), Procπ returns
– {(π(P), ∅, π(R), a)}, if π(P) and π(R) are TRSs
– {(P, Q, R, f)}, otherwise
Proof. ProcU is sound since every minimal (P, Q, R)-chain is a (not necessarily
minimal) (P, ∅, U(P, R) ∪Cε)-chain, cf. [21, Thm. 17].12
We now show soundness of Procπ: If s1 →t1, s2 →t2, . . . is an inﬁnite
(P, Q, R)-chain, then there is a substitution σ with tiσ→∗
R si+1σ for all i. Hence,
π(ti)σπ →∗
π(R) π(si+1)σπ for the substitution σπ with σπ(x) = π(σ(x)) for all x
∈V. So π(s1)→π(t1), π(s2)→π(t2), . . . is an inﬁnite (π(P), ∅, π(R))-chain.
⊓⊔
The following example shows that the processors are incomplete, even if Q = ∅.
Example 17. Let R = {f(a, b, x) →f(x, x, x)} [22]. R is terminating and thus,
the resulting DP problem ({F(a, b, x) →F(x, x, x)}, ∅, R, m) is not inﬁnite. How-
ever, by the processor ProcU we obtain the inﬁnite DP problem ({F(a, b, x) →
F(x, x, x)}, ∅, Cε, a), since now the instantiated right-hand side of the depen-
dency pair reduces to the instantiated left-hand side if x is substituted by c(a, b).
Incompleteness of Procπ is shown by ({F(a)→F(b)},∅,∅,f) which is not inﬁ-
nite, but the ﬁltering π(F(x))=F produces the inﬁnite problem ({F→F},∅,∅,a).
Now we demonstrate why the argument ﬁltering processor Procπ has to set
the ﬂag f to a, i.e., we show why one has to prove absence of arbitrary (pos-
sibly non-minimal) chains after the ﬁltering. For the processor ProcU it is cur-
rently open whether changing f to a is really needed for soundness. In other
words, it is not known whether a processor which transforms (P, Q, R, m) into
{ ( P, ∅, U(P, R) ∪Cε, m) } would be sound.
Example 18. An argument ﬁltering processor which replaces (P, Q, R, m) by
{(π(P), ∅, π(R), m)} is not sound, even if Q = ∅and if π does not modify the
function symbols of R: The DP problem (P, ∅, R, m) with P = {F(g(s(a))) →
F(g(s(a)))} and R = {g(a) →g(a)} has an inﬁnite minimal chain, but if one
ﬁlters P with π(s(x)) = x, then there is no inﬁnite minimal chain anymore. The
reason is that then the ﬁltered right-hand side F(g(a)) of the pair in π(P) is no
longer terminating w.r.t. R.
However, it is easy to show that if P’s rules have tuple symbols on their
root positions (as in Footnote 11) and if the ﬁltering π only modiﬁes these
tuple symbols, then one could deﬁne Procπ((P, Q, R, f)) = {(π(P), Q, R, f)}
if π(P) is a TRS. In other words, then both the TRS Q and the ﬂag f could
remain unchanged and the resulting processor Procπ would still be sound. (This
observation can also be extended to more general forms of P.)
The next example shows that replacing Q by ∅after the ﬁltering is needed
for the soundness of Procπ, even if π does not modify any symbols of Q.
12 The extension from ordinary to Q-restricted rewriting is again straightforward.

The Dependency Pair Framework
327
Example 19. Consider the problem (P, Q, R, m) with P = {F(x) →F(g(s(x)))},
Q = {g(g(x)) →x}, and R = ∅. Clearly, there is a (minimal) inﬁnite (P, Q, R)-
chain as F(x) →F(g(s(x))), F(g(s(x))) →F(g(s(g(s(x))))), . . . , are instantiations
of the pair in P which are in Q-normal form. However, if one uses the argument
ﬁltering with π(s(x)) = x, we would replace P by π(P) = {F(x) →F(g(x))}
whereas Q would remain unchanged. Now there is no inﬁnite (π(P), Q, R)-chain
anymore, since terms of the form F(g(g(. . .))) are not in Q-normal form.
As a larger last example, we now demonstrate the beneﬁts of Thm. 10 for the
integration of string reversal into the DP framework. As mentioned before, string
reversal is a transformational termination technique which is only applicable to
SRSs. The reversal t−1 of a term t with only unary symbols is obtained by
reversing the order of its function symbols (e.g., the reversal of f(g(h(x))) is
h(g(f(x)))). For a TRS R, its reversal is R−1 = {l−1 →r−1 | l →r ∈R}. It is
well known that an SRS R is terminating iﬀR−1 is terminating. Thus, we can
use the termination technique TT REV with TT REV (R) = R−1 if R is an SRS
and TT REV (R) = R, otherwise.
Example 20. The TRS R contains the following rules together with the plus-rules
(12) and (13) from Ex. 9. Here, mult(x, y, z) computes x ∗y + z.
times(x, y) →mult(x, y, 0)
(20)
mult(0, y, z) →z
(21)
mult(s(x), y, z) →mult(p(s(x)), y, plus(y, z))
(22)
times(plus(x, y), z) →plus(times(x, z), times(y, z)) (23)
p(s(0)) →0
(24)
p(s(s(x))) →s(p(s(x))) (25)
By the processor based on the dependency graph of Thm. 2, we obtain four DP
problems corresponding to the termination of p, plus, times, and mult. The ﬁrst
three are easy to handle, but the problem ({MULT(s(x), y, z) →MULT(p(s(x)),
y, plus(y, z))}, ∅, R, m) cannot be solved by the processors of the previous sec-
tions if one uses reduction pairs based on (quasi-)simpliﬁcation orders.
However, by applying the new processors of this section, we can transform
this DP problem into an SRS and apply the termination technique “string re-
versal”. Afterwards, it can easily be solved. We ﬁrst apply the processor ProcU
of Thm. 10 to remove the non-usable rules for times and mult which results in
({MULT(s(x), y, z)→MULT(p(s(x)), y, plus(y, z))}, ∅, {(12), (13), (24), (25)}∪Cε,
a). Next we eliminate the second and third argument of MULT by the argu-
ment ﬁltering processor Procπ of Thm. 10 and replace the dependency pair by
MULT(s(x)) →MULT(p(s(x))). Now the processor for removal of rules from
Thm. 7 is used with a polynomial interpretation where Pol(c(x, y)) = x + y + 1,
Pol(plus(x, y)) = 2 x + y + 1, Pol(p(x)) = x, and Pol(s(x)) = x + 1. Then the
rules (12), (13), and (24) are strictly decreasing and can be removed, i.e., we
result in ({MULT(s(x)) →MULT(p(s(x)))}, ∅, {p(s(s(x))) →s(p(s(x)))}, a).
Note that we have obtained a DP problem containing only symbols of arity 1.
Therefore, we can apply the termination technique TT REV and try to prove ter-
mination of the reversed TRS R′ = {s(MULT(x)) →s(p(MULT(x))), s(s(p(x)))
→s(p(s(x)))}. The resulting DP problem (DP(R′), ∅, R′, m) is easy to solve:

328
J. Giesl, R. Thiemann, and P. Schneider-Kamp
the dependency graph processor yields ({S(s(p(x))) →S(x)}, ∅, R′, m) and by
the usable rule processor we can delete all rules of R′ and also the remaining pair
S(s(p(x))) →S(x) which contains the non-usable symbol p on the left-hand side.
To summarize, the advantage of integrating termination techniques like string
reversal into the DP framework is that they can solve certain parts of the termi-
nation proof, whereas diﬀerent techniques are used for other parts (e.g., because
these parts do not correspond to an SRS). Moreover, as shown in the above
example, since one can modify DP problems by argument ﬁlterings, one can also
apply SRS-termination techniques for DP problems which originally contained
non-unary function symbols. So in general, the applicability, modularity, and
power of existing termination techniques is increased signiﬁcantly by the inte-
gration into the DP framework. While Thm. 9 shows how to integrate arbitrary
techniques, certain termination techniques may also be adapted in order to oper-
ate on DP problems directly instead of TRSs. Then instead of integrating them
with Thm. 9, they could be directly used as processors in the DP framework.
6
Strategies for the Dependency Pair Framework
The DP framework allows us to combine DP processors in a completely modular
and ﬂexible way. A system for termination proofs with the DP framework tries
to prove Q-termination of R for two TRSs Q and R. It starts with the initial
DP problem (DP(R), Q, R, m) and then constructs a tree as in Cor. 1. As long
as there is a DP problem d left, it chooses a DP processor Proc and computes
Proc(d). If Proc(d) = no, the proof is stopped. Then the system returns “no” if
Proc and all processors used on the path from the initial DP problem to d are
complete and otherwise it returns “maybe”. If Proc(d) ̸
= no, then d is replaced
by Proc(d) and the procedure continues. As soon as there are no DP problems
left anymore, the system returns “yes”. To avoid non-termination of the system,
it can also abort the proof after some time limit and return “maybe”. This algo-
rithm and a large number of DP processors (including those presented in this pa-
per) have been implemented in our automated termination tool AProVE [9] which
can be obtained from http://www-i2.informatik.rwth-aachen.de/AProVE.
To obtain a powerful system for termination proofs, a main challenge is to
develop strategies to decide which DP processor should be applied to a DP
problem d. A general heuristic is to apply fast processors ﬁrst and to use more
powerful slower processors later on in order to handle those problems which
cannot already be solved by fast processors. The strategy of AProVE is to select
the ﬁrst DP processor Proc from the following list which satisﬁes Proc(d) ̸
= {d}.
1. DP processor based on the dependency graph (Thm. 2)
2. DP processor based on usable rules (Thm. 5)
3. DP processor for modular non-overlap check (Thm. 8)
4. Narrowing, rewriting, and instantiation processors in “safe” cases [8] where
they “simplify” the DP problem (Thm. 4)
5. DP processor based on usable rules and reduction pairs (Thm. 6)

The Dependency Pair Framework
329
6. DP processor based on rule removal (Thm. 7)
7. DP processor based on red. pairs: linear polynomials over {0, 1} (Thm. 3)
8. DP processor for non-termination analysis13
9. Narrowing, rewriting, and instantiation (up to a certain limit) (Thm. 4)
10. DP processor based on red. pairs: linear polynomials over {0, 1, 2} (Thm. 3)
11. DP processor based on reduction pairs: lexicographic path orders (Thm. 3)
12. DP processor based on reduction pairs: non-linear polynomials (Thm. 3)
13. DP processor based on string reversal (Thm. 9)
Of course, one can also use diﬀerent strategies for diﬀerent forms of TRSs. For
example, if the underlying TRS is an SRS, AProVE uses a slightly diﬀerent
strategy, which also includes DP processors based on other techniques like RFC
matchbounds [5] and semantic labelling [24], cf. Sect. 5.
Due to the DP framework (with the above strategies), AProVE was the most
powerful system at the competition of termination tools at the 7th International
Workshop on Termination (WST ’04). Here, the tools were tested on 936 ex-
amples from the termination problem data base (TPDB) [20], a collection of
termination problems from several sources and diﬀerent areas of computer sci-
ence. This demonstrates that the DP framework is indeed very well suited for
automation and for application in practice.
7
Conclusion and Future Work
We introduced the dependency pair framework for termination proofs (Sect. 2)
which generalizes the classical dependency pair approach into a general basis
for automated termination proofs. We ﬁrst showed how to formulate the exist-
ing components of the dependency pair approach as DP processors within this
framework (Sect. 3). Now these components can be applied at any time during
the termination proof and their applicability conditions only concern the cur-
rent DP problem, not the whole TRSs. Afterwards, we developed several new
DP processors to simplify termination problems (Sect. 4) and we showed how
to integrate arbitrary existing termination techniques into the DP framework
(Sect. 5). For all processors, we also investigated their completeness which al-
lows us to use them also when proving non-termination. As demonstrated in
Sect. 6, this framework is indeed suitable for automation in practice. For future
work, we see two main directions of research:
While there already exist several powerful DP processors, these processors are
not yet suﬃcient to handle all termination problems occurring in practice. There-
fore, one important topic for further work is the improvement of the existing DP
processors and the development of new DP processors which are particularly
fast or particularly powerful for certain classes of DP problems.
13 A simple sound and complete DP processor Proc for non-termination analysis is the
following: Proc((P, Q, R, f)) = no if P contains a rule of the form s →s where s
is in Q-normal form. Otherwise, Proc((P, Q, R, f)) = (P, Q, R, f). Obviously, this
processor can be improved to detect more cases of non-termination.

330
J. Giesl, R. Thiemann, and P. Schneider-Kamp
The other important line of research is the development of new strategies to
decide which DP processor should be applied next on a particular DP problem.
We have presented such a strategy in Sect. 6, but depending on the area of
application, other strategies can be advantageous.
To summarize, in this paper we have shown that the combination of tech-
niques for termination proofs within the dependency pair framework leads to
a very modular, ﬂexible, and powerful approach. Therefore, we think that this
framework is particularly suitable as a basis for future research on automated
termination proving.
References
1. T. Arts and J. Giesl. Termination of term rewriting using dependency pairs. The-
oretical Computer Science, 236:133–178, 2000.
2. F. Baader and T. Nipkow. Term Rewriting and All That. Cambridge University
Press, 1998.
3. N. Dershowitz. Termination of rewriting. J. Symb. Computation, 3:69–116, 1987.
4. N. Dershowitz. Termination by abstraction. In Proc. ICLP ’04, LNCS 3132, pages
1–18, 2004.
5. A. Geser, D. Hofbauer, and J. Waldmann. Match-bounded string rewriting sys-
tems. In Proc. MFCS ’03, LNCS 2747, pages 449–459, 2003.
6. J. Giesl and T. Arts. Veriﬁcation of Erlang processes by dependency pairs. Appl.
Algebra in Engineering, Communication and Computing, 12(1,2):39–72, 2001.
7. J. Giesl, T. Arts, and E. Ohlebusch. Modular termination proofs for rewriting
using dependency pairs. Journal of Symbolic Computation, 34(1):21–58, 2002.
8. J. Giesl, R. Thiemann, P. Schneider-Kamp, and S. Falke. Improving dependency
pairs. In Proc. LPAR ’03, LNAI 2850, pages 165–179, 2003.
9. J. Giesl, R. Thiemann, P. Schneider-Kamp, and S. Falke. Automated termination
proofs with AProVE. In Proc. RTA ’04, LNCS 3091, pages 210–220, 2004.
10. B. Gramlich.
Abstract relations between restricted termination and conﬂuence
properties of rewrite systems. Fundamenta Informaticae, 24:3–23, 1995.
11. N. Hirokawa and A. Middeldorp. Automating the dependency pair method. In
Proc. CADE ’03, LNAI 2741, pages 32–46, 2003. Full version to appear in Infor-
mation and Computation.
12. N. Hirokawa and A. Middeldorp. Dependency pairs revisited. In Proc. RTA ’04,
LNCS 3091, pages 249–268, 2004.
13. N. Hirokawa and A. Middeldorp. Polynomial interpretations with negative coeﬃ-
cients. In Proc. AISC ’04, LNAI 3249, pages 185–198, 2004.
14. S. Kamin and J. J. L´evy.
Two generalizations of the recursive path ordering.
Unpublished Manuscript, University of Illinois, IL, USA, 1980.
15. D. Knuth and P. Bendix. Simple word problems in universal algebras. In J. Leech,
editor, Computational Problems in Abstract Algebra, pages 263–297, 1970.
16. K. Kusakari, M. Nakamura, and Y. Toyama. Argument ﬁltering transformation.
In Proc. PPDP ’99, LNCS 1702, pages 48–62, 1999.
17. D. Lankford. On proving term rewriting systems are Noetherian. Technical Report
MTP-3, Louisiana Technical University, Ruston, LA, USA, 1979.
18. Aart Middeldorp. A simple proof to a result of Bernhard Gramlich. Presented at
the 5th Japanese Term Rewriting Meeting, Tsukuba, 1994. Available from
http://informatik.uibk.ac.at/users/ami/research/papers/bg.pdf.

The Dependency Pair Framework
331
19. J. Steinbach. Simpliﬁcation orderings: History of results. Fundamenta Informati-
cae, 24:47–87, 1995.
20. Termination Problem Data Base (TPDB). Available from http://www.lri.fr/
~marche/wst2004-competition/tpdb.html.
21. R. Thiemann, J. Giesl, and P. Schneider-Kamp. Improved modular termination
proofs using dependency pairs. In Proc. IJCAR ’04, LNAI 3097, pages 75–90, 2004.
22. Y. Toyama. Counterexamples to the termination for the direct sum of term rewrit-
ing systems. Information Processing Letters, 25:141–143, 1987.
23. X. Urbain. Modular and incremental automated termination proofs. Journal of
Automated Reasoning, 32(4): 315–355, 2004.
24. H. Zantema. Termination of term rewriting by semantic labelling. Fundamenta
Informaticae, 24:89–105, 1995.

Automated Termination Analysis for
Incompletely Deﬁned Programs
Christoph Walther and Stephan Schweitzer
Fachgebiet Programmiermethodik
Technische Universit¨at Darmstadt
www.informatik.tu-darmstadt.de/pm/
{chr.walther,schweitz}@informatik.tu-darmstadt.de
Abstract. Incompletely deﬁned programs provide an elegant and easy
way to write and to reason about programs which may halt with a run
time error by throwing an exception or printing an error message, e.g.
when attempting to divide by zero. Due to the presence of stuck compu-
tations, which arise when calling incompletely deﬁned procedures with
invalid arguments, we cannot use the method of argument bounded al-
gorithms for proving termination by machine. We analyze the problem
and present a solution to improve this termination analysis method so
that it works for incompletely deﬁned programs as well. Our technique
of proving the termination of incompletely deﬁned programs maintains
performance as well as simplicity of the original method and proved suc-
cessful by an implementation in the veriﬁcation tool ✓eriFun.
1
Introduction
A central problem in the development of correct software is to verify that algo-
rithms terminate. A non-terminating algorithm results in looping computations,
hence machine resources are wasted if a given input is not in the domain of
the function computed by the algorithm. Also manpower is wasted with the
debugging of those algorithms, and the frustration caused by non-terminating
programs is a common experience of programmers and computer scientists.
Termination analysis is concerned with the synthesis and veriﬁcation of ter-
mination hypotheses, i.e. proof obligations the truth of which entail the termina-
tion of the algorithm under consideration. In this paper, we are concerned with
functional programs where several proposals exist for proving termination, e.g.
[1],[2],[3],[4],[5],[6],[7],[8],[9],[10].
In the ✓eriFun system [11],[12],[13], a semi-automated veriﬁer for functional
programs, the method of argument bounded algorithms [10] is used and proved
successful for verifying the termination of procedures by machine. Recently,
✓eriFun was upgraded to work for incompletely deﬁned programs as well [14].
Those programs compute partially determined functions, i.e. functions which
may yield (deﬁned but) “unknown” results for some of their input arguments.
However, unsound inferences will result if our termination proof procedure is
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 332–346, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

Automated Termination Analysis for Incompletely Deﬁned Programs
333
structure bool
<=
true, false
structure nat
<=
0, succ(pred:nat)
structure list
<=
empty, add(hd:nat,tl:list)
function minus(x,y:nat):nat <=
function remainder(x,y:nat):nat <=
if y=0
if y=0
then x
then * ∥0
else if x=0
else if y>x
then * ∥0
then x
else minus(pred(x),pred(y))
else remainder(minus(x,y),y)
fi
fi
fi
fi
Fig. 1. Data structures, incompletely and completely deﬁned procedures
applied to incompletely deﬁned procedures, because the method requires that
only totally determined functions are computed by the procedures of a program.
We therefore use domain procedures [14] to modify the method so that it can be
soundly applied to prove the termination of incompletely deﬁned programs too.
2
Completely Deﬁned Programs
Syntax We use a programming language in which data structures are deﬁned
in the spirit of (free) algebraic data types. A data structure s is deﬁned by
stipulating the constructors of the data structure as well as a selector for each
argument position of a constructor. The set of all constructor ground terms built
with the constructors of s then deﬁnes the elements of the data structure s.
For example, truth values are represented by the set T ({true, false}) =
{true, false} and the set of natural numbers is represented by the set T ({0, succ})
= {0 , succ(0), succ(succ(0)), . . .}, both given by data structures bool and nat of
Fig. 1.1 Likewise, the data structure list of Fig. 1 represents the set of linear lists
of natural numbers, with e.g. add(succ(0), add(0, empty)) ∈T ({0, succ, empty,
add}). The selectors act as inverses to their constructors, since e.g. hd(add(n, k))
= n and tl(add(n, k)) = k is demanded. Each deﬁnition of a data structure s
implicitly introduces an equality symbol =s : s × s →bool (where s ̸= bool) and
a function symbol if s : bool × s × s →s for conditionals.
A procedure, which operates on these data structures, is deﬁned by giving
the procedure name, say f, the formal parameters and the result type in the
procedure head. The procedure body is given as a ﬁrst-order term over the set
of formal parameters, the function symbols already introduced by some data
structures and other procedures plus the function symbol f to allow recursive
deﬁnitions, cf. Fig. 1 where “* ∥” in the procedure bodies should be ignored.
A ﬁnite list P of data structure and procedure deﬁnitions—always beginning
with the data structure deﬁnitions of bool and nat as given in Fig. 1—is called
1
T (Σ, V)s is the set of terms of type s, T (Σ)s = T (Σ, ∅)s, and CL(Σ, V) is the set
of clauses over a signature Σ for function symbols and a set V of variable symbols.

334
C. Walther and S. Schweitzer
a completely deﬁned functional program. Σ(P) is the set of all function symbols
introduced by the data structures and procedures of P, and Σ(P)c ⊂Σ(P) is
the set of all constructor function symbols given by the data structures of P.
Semantics and Termination Given a (completely deﬁned functional) pro-
gram P, an interpreter evalP for P evaluates terms of T (Σ(P)) to “values”,
i.e. terms of T (Σ(P)c). The interpreter computes calls f(t1, . . . , tn) of a proce-
dure function f(x1:s1, . . . , xn:sn):s <= Rf call-by-value, i.e. by replacing each
formal parameter xi in the procedure body Rf by the computation t′
i of the
actual parameter ti, and then continuing with the computation of the instan-
tiated procedure body obtained. The interpreter also respects the deﬁnitions
of the data structures by computing, for instance, false for 0=succ(t) and q
for pred(succ(t)), provided evalP (t) = q for some q ∈T (Σ(P)c). For selectors
sel : s →s′ applied to constructors cons to which they do not belong, so-
called witness terms ωsel [x] ∈T (Σ(P), {x})s′ with x ∈Vs are assigned in P to
sel, and we deﬁne evalP (sel(cons(q1, . . . , qn)) := evalP (ωsel[cons(q1, . . . , qn)]).
Hence e.g. evalP (tl(empty)) = empty and evalP (hd(empty)) = 0 if ωtl [x] := x
and ωhd [x] := 0 for the selectors of data structure list, cf. Fig. 1. By these
deﬁnitions, our programming language is provided with an eager semantics.
Since P may contain non-terminating procedures, evalP is a partial mapping
only, i.e. evalP : T (Σ(P)) →T (Σ(P)c), and we deﬁne [14]:
Deﬁnition 1.
(Termination) A procedure function f(x1:s1, . . . , xn:sn):s <=
. . . of a completely deﬁned program P terminates in P iﬀevalP (f(q1, . . . , qn))
∈T (Σ(P)c) for all qi ∈T (Σ(P)c)si. P terminates iﬀ(i) each procedure of P
terminates in P and (ii) evalP (ωsel[q]) ∈T (Σ(P)c) for each selector sel : s →s′
and for all q ∈T (Σ(P)c)s.
3
Incompletely Deﬁned Programs
Motivation Incompletely deﬁned programs provide an elegant and easy way
to specify and to verify statements about (recursive) partial functions with deci-
dable domain [14]. Incompletely deﬁned programs compute partially determined
functions, also called loosely speciﬁed or underspeciﬁed functions in the literature.
A total function is called partially determined iﬀthe result of a function
application is indetermined for some arguments, called stuck arguments. Par-
tial functions φ : M →N with domain domφ can be represented by partially
determined but total functions φ : M →N by stipulating φ(m) := φ(m) for each
m ∈domφ but demanding φ(m) ∈N for each m ∈M \ domφ only, being silent
about which n ∈N exactly is assigned to φ(m). The elements of M \ domφ are
the stuck arguments of φ, and φ(m) is indetermined iﬀm is a stuck argument.
Examples of partially determined functions are quotient and remainder with
stuck arguments of form (m, 0), list processing functions, like head, last and
minimum with the empty list as stuck argument, and so on. If domφ is decidable
and the completion φ of φ is recursive, φ can be computed by an incompletely

Automated Termination Analysis for Incompletely Deﬁned Programs
335
deﬁned procedure ℘φ so that properties of φ can be veriﬁed by reasoning about
℘φ , using some veriﬁer based on a logic of total functions.
An incompletely deﬁned program is obtained by giving an incomplete case
analysis in a procedure or using a speciﬁc symbol, say *, to denote an indeter-
mined result. Such programs can be implemented by causing a runtime error or
throwing an exception when called with a stuck argument, e.g. upon the attempt
to divide by zero. When focussing on functional programs—as we do here—the
interpreter of the programming language responds by returning a ground term
r /∈T (Σ(P)c) when called with a stuck argument, and we call such a result r a
stuck computation.
Syntax A data structure s is incompletely deﬁned by not stipulating witness
terms for the selectors of s. For deﬁning a procedure f incompletely, we allow the
use of a wildcard * to stipulate the result when calling f with a stuck argument.
E.g., procedure minus of Fig. 1 is incompletely deﬁned if “∥0” is ignored in the
procedure body, and the value of minus(n, m) is only determined if n ≥m. Also
procedure remainder of Fig. 1 is incompletely deﬁned when ignoring “∥0”, and
the value of remainder(n, m) is determined iﬀm ̸= 0.
Formally, we assume a constant symbol *s /∈Σ(P) for each data structure
s in a functional program P, and we demand upon the extension of P by a
new procedure function f(x1:s1, . . . , xn:sn):s <= Rf, that Rf ∈T (Σ(P) ∪
{f, *s} , {x1, . . . , xn}) be ∗-correct, i.e. Rf = * or * is only used as a (direct)
argument in the alternatives of an if -conditional.
Termination and Semantics For deﬁning the termination and in turn the
semantics of an incompletely deﬁned program P, the notion of a fair comple-
tion P ′ of P is needed [14]: P is the set of all fair completions of P, where
each P ′ ∈P is a completely deﬁned program containing each data structure
s which is given in P plus the witness terms for the selectors of s. P ′ also
contains a procedure function f(x1:s1, . . . , xn:sn):s <= R′
f for each procedure
function f(x1:s1, . . . , xn:sn):s <= Rf in P. The procedure body R′
f is ob-
tained from Rf by replacing each occurrence of * in Rf by some term from
T (Σ(P ′), {x1, . . . , xn}), where it does not matter whether diﬀerent occurrences
of * are replaced by the same or by diﬀerent terms. In addition, the fairness
requirement demands that the termination of procedure f in P ′ not be spoiled
just because procedure f is completed by a non-terminating result in a ∗-case or
a non-terminating witness term is assigned to a selector.
For example, a fair completion of a program containing the incompletely
deﬁned procedure minus of Fig. 1 may contain the completely deﬁned procedure
minus. Also the occurrence of * in procedure minus may be replaced by succ(y)
or 13 or minus(x, pred(y)) etc. in a fair completion P ′ of P. But we may not
replace * by minus(x, y) or by loop(y), where function loop(x:nat):nat <=
succ(loop(x)) is a procedure of P ′, as this violates the fairness requirement.
Deﬁnition 2.
(Termination) A procedure function f(x1:s1, . . . , xn:sn):s <=
Rf of an incompletely deﬁned program P terminates in P iﬀfor each P ′ ∈
P procedure function f(x1:s1, . . . , xn:sn):s <= R′
f of P ′ terminates in P ′. P
terminates iﬀeach procedure of P terminates in P.

336
C. Walther and S. Schweitzer
Deﬁnition 3.
(Standard Model MP , Theory ThP) Let P be an incompletely
deﬁned and terminating program. Then a standard model MP of P is a Σ(P)-
algebra MP = (T (Σ(P)c), φ) such that some P ′ ∈P exists with φf(q1, . . . , qn) =
evalP ′(f(q1, . . . , qn)) for all f ∈Σ(P)s1,...,sn,s and all qi ∈T (Σ(P)c)si. The
theory ThP of P is deﬁned as {ϕ ∈F(Σ(P), V) | MP ⊨ϕ for each standard
model MP of P}. A veriﬁcation system for P is sound iﬀϕ ∈ThP for each
ϕ ∈F(Σ(P), V) veriﬁed by the system.2
By Deﬁnition 3, incompletely deﬁned procedures (and selectors) are under-
stood as loose speciﬁcations of total functions. The standard models for incom-
pletely deﬁned (and terminating) programs diﬀer only in the interpretation of
functions applied to stuck arguments, but coincide for all other function appli-
cations. So ThP is incomplete, i.e. neither ϕ ∈ThP nor ¬ϕ ∈ThP for some
ϕ ∈F(Σ(P), V), whereas ThP is complete for completely deﬁned programs P.
Veriﬁcation When we formulate proof obligations of form “ϕ ∈ThP ” for in-
completely deﬁned programs P in the following, we assume the availability of
some “sound veriﬁcation system for P” to compute a proof for ϕ. We can do
so as (i) several veriﬁers for functional programs exist, see e.g. [15],[16],[17] for
references, and (ii) (most) logics used for the veriﬁcation of terminating and
completely deﬁned programs can be applied without profound modiﬁcations to
verify terminating but incompletely deﬁned programs as well, see [14].
Computation To implement our programming language, we also have to de-
ﬁne an interpreter evalP for incompletely deﬁned programs P. As the formal
deﬁnition of evalP does not matter here, we refer to [14] for details. For the
purpose of this paper, it is enough to know that for each t ∈T (Σ(P))
evalP (t) ∈T (Σ(P)c) ⇐⇒

evalP (t) = evalP ′(t) for each P ′ ∈P

.
(1)
4
Termination Analysis with Argument Bounded
Algorithms
Argument bounded algorithms are the key concept for the automated termina-
tion analysis proposed in [10]. The method has been implemented and proved
successful in veriﬁcation tools, [18],[19],[20],[21],[12], and provided the base for
further developments of termination analysis [22],[23],[24],[3],[4],[25],[26],[27],[9]
as well. Termination analysis with argument bounded algorithms is based on
the syntactic estimation ⩾Γ,C of terms, where selector and procedure calls are
estimated above by some argument(s) of the call.
A total and totally determined function φ : T (Σ(P)c)s1×. . .×T (Σ(P)c)sn →
T (Σ(P)c)sp is called p-bounded iﬀp ∈{1, . . . , n} and qp ⩾# φ(q1, . . . , qn) for all
qi ∈T (Σ(P)c)si.3 A function φ is called argument bounded iﬀit is p-bounded for
2
F(Σ, V) is the set of closed formulas over Σ and V.
3
># is the size order comparing constructor ground terms q ∈T (Σ(P)c)s by the
number #s(q) of reﬂexive s-constructors in q, and q ⩾# r abbreviates q ># r or
q =# r. A function symbol h : s1 × . . . × sn →s is reﬂexive iﬀs = si for some i.

Automated Termination Analysis for Incompletely Deﬁned Programs
337
function half(x:nat):nat <=
if x=0
then 0
else if pred(x)=0 then * else succ(half(pred(pred(x)))) fi
fi
function log(x:nat):nat <=
if x=0
then *
else if pred(x)=0
then 0
else if even(x) then succ(log(half(x))) else * fi
fi
fi
Fig. 2. Incompletely deﬁned procedures (cont.)
some p ∈{1, . . . , n}. Each p-bounded function φ is associated with a so-called
(total and totally determined) p-diﬀerence function δp
φ : T (Σ(P)c)s1 × . . . ×
T (Σ(P)c)sn →{true, false} which satisﬁes δp
φ(q1, . . . , qn) ⇔qp ># φ(q1, . . . , qn)
for all qi ∈T (Σ(P)c)si.
Given a family Γ = (Γp)p∈N of sets of p-bounded function symbols g ∈Σ(P)
which denote p-bounded functions φ, and the function symbols ∆p
g denoting their
p-diﬀerence functions δp
φ, inequalities can be proved by the estimation calculus
[10] (called E-calculus for short). The formulas of the E-calculus are called esti-
mation pairs ⟨∆, E⟩, where ∆∈CL(Σ(P), V), consisting mainly of atoms of form
∆p
g(. . .), and E is a ﬁnite set of expressions of form r ≽t with r, t ∈T (Σ(P), V)s.
The E-calculus is decidable and is sound in the sense that
(i) [∀x1:s1, . . . , xn:sn. C →r ⩾# t] ∈ThP , and
(ii) [∀x1:s1, . . . ,xn:sn. C →(∆↔r ># t)] ∈ThP
(2)
hold if ⊢Γ,C ⟨∆, r ≽t⟩, i.e. if ⟨∆, {r ≽t}⟩is a theorem of the E-calculus, where
C ∈CL(Σ(P), V) and xi ∈Vsi are the variables in C, r and t.
The E-calculus is used (i) to generate termination hypotheses for completely
deﬁned procedures, (ii) to test whether a (terminating and completely deﬁned)
procedure function g(x1:s1, . . . , xn:sn):sp <= Rg computes a p-bounded func-
tion φ, and (if so) (iii) to synthesize a p-diﬀerence procedure function ∆p
g(x1:s1,
. . . , xn:sn):bool <= R∆p
g which computes the p-diﬀerence function δp
φ for φ.
5
Incompletely Deﬁned Argument Bounded Procedures
Consider the completely deﬁned and 1-bounded procedure minus from Fig. 1,
and assume that the incompletely deﬁned procedure half of Fig. 2 is fairly
completed by stipulating half (1) := 0 or half (1) := 1. Then half is 1-bounded
too, and the following estimation proof can be obtained:
x ⩾Γ pred(x) ⩾Γ half(pred(x)) ⩾Γ minus(half(pred(x)),succ(y))
(3)

338
C. Walther and S. Schweitzer
Here ⩾Γ abbreviates ⩾Γ,∅, where ⩾Γ,C is the syntactic estimation relation
deﬁned by r ⩾Γ,C t iﬀ⊢Γ,C ⟨∆, r ≽t⟩for some ∆∈CL(Σ(P), V). However, in
an incompletely deﬁned program, where minus and half are given as in Figs.
1 and 2, the result of a function applied to a stuck argument is not deter-
mined. Therefore pred, half and minus fail to be argument bounded, hence an
estimation proof like (3) cannot be obtained. This problem does not exist for
completely deﬁned programs, as we may stipulate any result we like for a func-
tion applied to a “don’t-care” argument. Hence we may in particular use results
which do not spoil the 1-boundedness of the above functions, and may deﬁne
e.g. pred(0) := minus(0, n) := half (1) := 0.
Since the function computed by an incompletely deﬁned procedure fails to
be argument bounded for stuck arguments, the notion of argument boundedness
as given in [10] has to be generalized:
Deﬁnition 4. (p-Boundedness) Let P be an incompletely deﬁned program. Then
each reﬂexive selector of a data structure in P is 1-bounded. A procedure
function f(x1:s1, . . . , xn:sn):s <= Rf of P is p-bounded iﬀ
1. p ∈{1, . . . , n} with sp = s,
2. Σ(r) ∩{*, f} = ∅for some result term r in the procedure body Rf, and
3. xp ⩾⊕
Γ,Cr r for each result term r ̸= ∗appearing under clause Cr in Rf.4
Γ := 
p∈NΓp is the set of argument bounded function symbols in P, where each
Γp is the set of p-bounded function symbols in P. Γp is deﬁned as the smallest
subset of Σ(P) satisfying (i) rsel ∈Γ1 for each reﬂexive selector rsel of a data
structure in P and (ii) f ∈Γp for each p-bounded procedure f in P.
Requirement (3) of Deﬁnition 4 allows to ignore indetermined result terms
when testing for argument boundedness and is the only relevant modiﬁcation
of the original deﬁnition. Requirement (2) is only an optimization, as proce-
dures computing indetermined results only cannot contribute to the termination
analysis.
For example, all reﬂexive selectors of the data structures given in Fig. 1 as
well as the incompletely deﬁned procedures minus, remainder, half and log of
Figs. 1 and 2 now are 1-bounded, and remainder is 2-bounded too.
6
Domain Procedures
Having generalized the notion of argument boundedness by Deﬁnition 4, estima-
tion proofs now can be obtained for incompletely deﬁned programs too. However,
such an estimation proof may be unsound, because the functions involved fail to
be argument bounded for stuck arguments.
For instance, the estimation proof (3) is unsound, because a standard model
exists which assigns 1 to pred(0) and 2 to half (1) as well as to minus(0, 1).
Hence 0 ≱pred(0), 2 ≥1 ≱half (1) and 3 ≥2 ≥1 ≱minus(1, 2).
4
We write ⊢⊕
Γ,Cr ⟨. . .⟩to denote the existence of an estimation proof which already
may use the Argument Estimation rule (5) of Deﬁnition 5 for each recursive call
f(t1, . . . , tn) in r. See [10] for a justiﬁcation.

Automated Termination Analysis for Incompletely Deﬁned Programs
339
As a remedy, we have to exclude the applications of reﬂexive selectors and ar-
gument bounded procedures to stuck arguments in an estimation proof. To this
eﬀect, we use domain procedures which have been developed in [14] for reason-
ing about stuck computations explicitly: Domain procedures are given for non-
procedure function symbols ̸=“if ”by stipulating function ∇=(x:s, y:s):bool <=
true, function ∇seli(x:s):bool <= ?cons(x) and function ∇cons(x1:s1, . . . ,
xn:sn):bool <= true for the selectors seli and constructors cons of a data
structure deﬁnition structure s <= . . . , cons(sel1:s1, . . . , seln:sn), . . ., where
?cons(x) abbreviates x = cons(sel1(x), . . . , seln(x)). For a procedure function
f(x1:s1, . . . , xn:sn):s <= . . ., a domain procedure function ∇f(x1:s1, . . . ,
xn:sn):bool <= . . . can be uniformly synthesized.
As proved in [14], (i) each domain procedure ∇f terminates iﬀits “mother”
procedure f terminates, (ii) computes a totally determined function, and (iii)
equivalently characterizes whether the computation of a call of procedure f
results in a stuck computation, i.e. for all qi ∈T (Σ(P)c)si
evalP (f(q1, . . . , qn)) ∈T (Σ(P)c) iﬀevalP (∇f(q1, . . . , qn)) = true.
Since domain procedures are tail recursive and compute a truth value, the
optimization techniques developed in [10] for diﬀerence procedures apply to do-
main procedures as well: Having generated a domain procedure ∇f, the body
of ∇f is simpliﬁed in a ﬁrst optimization step, and then it is tried to eliminate
recursive calls in the simpliﬁed procedure body. Recursion elimination is par-
ticularly important, because proofs are more easily obtained if the procedures
“called” in a statement have no unnecessary recursive calls.
Example 1.
(i) function ∇minus(x,y:nat):nat <=
if y=0
then true
else if x=0 then false else ∇minus(pred(x),pred(y)) fi
fi
is computed as the optimized domain procedure for the incompletely deﬁned
procedure minus from Fig. 1, and we ﬁnd ∇minus(n, m) = true iﬀn ≥m.
(ii) function ∇remainder(x:nat, y:nat):bool <=
if y=0 then false else true fi
is computed as the optimized domain procedure for the incompletely deﬁned
procedure remainder from Fig. 1, and ∇remainder(n, m) = true iﬀm ̸= 0.
(iii) function ∇half(x:nat):nat <=
if x=0
then true
else if pred(x)=0 then false else ∇half(pred(pred(x))) fi
fi
is computed as the optimized domain procedure for procedure half from Fig. 2,
and we ﬁnd ∇half(n) = true iﬀn is even.

340
C. Walther and S. Schweitzer
(iv) function ∇log(x:nat):nat <=
if x=0
then false
else if pred(x)=0
then true
else if even(x) then ∇log(half(x)) else false fi
fi
fi
is computed as the optimized domain procedure for procedure log from Fig. 2,
and we ﬁnd ∇log(n) = true iﬀn = 2k for some k ∈N. □
To optimize domain procedure ∇remainder, recursion elimination is required,
where the generated recursion elimination formulas are trivial to verify. All do-
main procedures of Example 1 are optimal because all recursive calls which
survived recursion elimination are required.
From now on we assume that each incompletely deﬁned program P contains a
domain procedure function ∇f for each function symbol f ∈Σ(P) with f ̸= if
and f ̸= ∇g, where g is any function symbol in Σ(P).5
7
Estimation Proofs in Incompletely Deﬁned Programs
Domain procedures provide the necessary prerequisite to exclude the applications
of reﬂexive selectors and argument bounded procedures to stuck arguments in an
estimation proof. For example, to guarantee soundness of the estimation proof
(3) we only have to demand
∇pred(x) ∧∇half(pred(x)) ∧∇minus(half(pred(x)),succ(y)) .
(4)
Requirement (4) expresses x ̸= 0, x−1 is even and (x−1) /2 ≥1 + y, thus
excluding the unsound estimations from Section 6. In the general case, we scan
an estimation proof
t1 ⩾Γ,C t2 ⩾Γ,C . . . ⩾Γ,C tn−1 ⩾Γ,C tn
(5)
step by step and create a procedure call ∇f(r1, . . . , rm) for each estimation step
ti ⩾Γ,C ti+1 with ti+1 = f(r1, . . . , rm) and f ∈Γ, where 1 ≤i ≤n −1. These
procedure calls are collected in a set ∇∈CL(Σ(P), V), called the determination
clause of the estimation proof (5).
To this eﬀect, the estimation calculus from [10] is reﬁned:
Deﬁnition 5. (pE-Calculus) Let P be an incompletely deﬁned program, let Γ be
a family of argument bounded function symbols in P, and let C ∈CL(Σ(P), V),
called the context clause. Assume further that ircons, ircons1 and ircons2 are
(not necessarily diﬀerent) irreﬂexive constructors, and that rcons, rcons1, . . . ,
rconsn are (not necessarily diﬀerent) reﬂexive constructors of some data struc-
tures in P. Then the partial estimation calculus ( pE-calculus) is given by:
5
This means that we do not need domain procedures of domain procedures.

Automated Termination Analysis for Incompletely Deﬁned Programs
341
1. Language Estimation triples, i.e. expressions of form ⟨∇, ∆, E⟩where ∇, ∆
∈CL(Σ(P), V) and E ⊂{r ≽t | r, t ∈T (Σ(P), V)s} with |E| < ∞.
2. Inference Rules (Estimation Rules) 6
(1)
Identity
⟨∇, ∆, E ⊎{t ≽t}⟩
⟨∇, ∆, E⟩
(2)
Equivalence
⟨∇, ∆, E ⊎{r ≽t}⟩
⟨∇, ∆, E⟩
, if C ⊢?ircons2(r) and C ⊢?ircons1(t)
(3)
Strong Estimation
⟨∇, ∆, E ⊎{r ≽t}⟩
⟨∇, ∆∪{true} , E⟩, if C ⊢?rcons(r) and C ⊢?ircons(t)
(4)
Strong Embedding
⟨∇, ∆, E ⊎{r ≽t}⟩
⟨∇, ∆∪{true} , E ∪{SELk(r) ≽t}⟩, if



C ⊢?rcons(r), and
k is a reﬂexive argument
position of rcons
(5)
Argument Estimation
⟨∇, ∆, E ⊎{r ≽f (t1, . . . , tn)}⟩
⟨∇∪{∇f(t1, . . . , tn)} , ∆∪{∆p
f(t1, . . . , tn)}, E∪{r ≽tp}⟩, if f ∈Γp
(6)
Weak Embedding
⟨∇, ∆, E ⊎{r ≽t}⟩
⟨∇, ∆, E ∪h
i=1 {SELji(r) ≽SELji(t)}⟩
, if











C ⊢?rcons(r),
C ⊢?rcons(t), and
j1, . . . , jh are all
reﬂexive argument
positions of rcons,
(7)
Minimum
⟨∇, ∆, E ⊎{r ≽t}⟩
⟨∇, ∆∪k
i=1 {?rconsi(r)} , E⟩
, if



C ⊢?ircons(t), and
rcons1, . . . , rconsk are all
reﬂexive constructors of s
3. Deduction A deduction of ⟨∇n, ∆n, En⟩from ⟨∇1, ∆1, E1⟩is a ﬁnite se-
quence ⟨∇1, ∆1, E1⟩, . . . , ⟨∇n, ∆n, En⟩of estimation triples such that n ≥1
and ⟨∇i, ∆i, Ei⟩⇛Γ,C ⟨∇i+1, ∆i+1, Ei+1⟩, i.e. ⟨∇i+1, ∆i+1, Ei+1⟩results
from ⟨∇i, ∆i, Ei⟩by an application of some estimation rule for each i < n.
r ⩾Γ,C t abbreviates ⊢Γ,C ⟨∇, ∆, r ≽t⟩for some ∇, ∆∈CL(Σ(P), V),
where ⊢Γ,C
⟨∇, ∆, r ≽t⟩denotes the existence of an estimation proof
for r ≽t with determination clause ∇and diﬀerence equivalent ∆, given by
⊢Γ,C ⟨∇, ∆, r ≽t⟩⇐⇒⟨∅, ∅, {r ≽t}⟩⇛+
Γ,C ⟨∇, ∆, ∅⟩.
6
We write C ⊢?consi(r) iﬀ(i) r = consi(. . .) or (ii) ?consi(r) ∈C or (iii)
{¬?consj(r) | j ∈{1, . . . , n} \ {i}} ⊂C for a data structure s with constructors
cons1, . . . , consn. SELk(r) stands for rk if r = rcons(. . . , rk, . . .), and abbreviates
selk(r) otherwise.

342
C. Walther and S. Schweitzer
Theorem 1. (Soundness of the pE-calculus) Let P be an incompletely deﬁned
and terminating program, and let ⊢Γ,C ⟨∇, ∆, r ≽t⟩where x1, . . . , xn with xi ∈
Vsi are all variable symbols in C, r and t. Then
1. [∀x1:s1, . . . , xn:sn. ∇→(C →r ⩾# t)] ∈ThP , and
2. [∀x1:s1, . . . , xn:sn. ∇→(C →(∆↔r ># t))] ∈ThP .7
By Theorem 1, the soundness of a pE-deduction is relativized by the domain
clause ∇inferred. This means that the soundness statements of (2) in Section
4 hold for incompletely deﬁned programs only if each literal of ∇is true, i.e.
if the absence of stuck computations is guaranteed. E.g., we now may obtain the
pE-deduction ⟨∅, ∅, {x ≽minus(half(pred(x)), succ(y))}⟩⇛+
Γ ⟨

∇pred(x),
∇half(pred(x)), ∇minus(half(pred(x)), succ(y))},

∆1
minus(half(pred(x))
,succ(y)), ∆1
half(pred(x)), ∆1
pred(x)

, ∅⟩.
A proof procedure for the pE-calculus is easily obtained, because the set of
theorems of the pE-calculus is decidable:
Theorem 2. (Decidability of pE-deductions) Let P be an incompletely deﬁned
program, let E = {r ≽t | r, t ∈T (Σ(P), V)s}, and let M = {⟨∇, ∆, E⟩| ∇, ∆∈
CL(Σ(P), V) and E ⊂E with |E| < ∞}. Then
1. {⟨∇, ∆, {r ≽t}⟩∈M | ⊢Γ,C ⟨∇, ∆, r ≽t⟩} is decidable, and
2. r ⩾Γ,C t is decidable.
8
Synthesis of Diﬀerence Procedures
The pE-calculus is used similarly to the E-calculus in [10] to recognize p-bound-
edness of a procedure function f(x1:s1, . . . , xn:sn):s <= Rf and to synthesize
a p-diﬀerence procedure function ∆p
f(x1:s1, . . . , xn:sn):bool <= R∆p
f for pro-
cedure f. But we have to modify the synthesis process slightly to cope with the
∗-symbol which may occur in the procedure bodies Rf.
We deﬁne * as the result term of R∆p
f under a clause C whenever * appears
as the result term under this clause in Rf. Consequently, a p-diﬀerence procedure
∆p
f is incompletely deﬁned iﬀits “mother” procedure f is.
Deﬁnition 6. (p-Diﬀerence Procedures) Let P be an incompletely deﬁned pro-
gram. Then each reﬂexive selector sel ∈{sel1, . . . , seln} of a data structure
deﬁnition structure s <= . . . , cons(sel1:s1, . . . , seln:sn), . . . in P is associated
with the 1-diﬀerence procedure
function ∆1
sel(x:s):bool <= if ?cons(x) then true else ∗fi .
Each p-bounded procedure function f(x1:s1, . . . , xn:sn):s <= Rf of P is
associated with some p-diﬀerence procedure
function ∆p
f(x1:s1, . . . , xn:sn):bool <= R∆p
f
7
We refer to [28] for omitted proofs.

Automated Termination Analysis for Incompletely Deﬁned Programs
343
such that R∆p
f is obtained from Rf by keeping each result term r with r = ∗and
by replacing each result term r with r ̸= ∗which appears under some clause Cr
in Rf by OR (∆r), where ⊢⊕
Γ,Cr ⟨∇r, ∆r, xp ≽r⟩.8
Theorem 3. Let P be an incompletely deﬁned program, let f ∈Σ(P)s1,...,sn,s
be p-bounded, and let function ∆p
f denote a p-diﬀerence procedure of f. Then
for all qi ∈T (Σ(P)c)si and for all P ′ ∈P
1. evalP ′(f(q1, . . . , qn))∈T (Σ(P)c) ⇔evalP ′(∆p
f(q1, . . . , qn))∈{true, false},
2. evalP (∇f(q1, . . . , qn)) = true =⇒evalP (∆p
f(q1, . . . , qn)) ∈{true, false},
3. P terminates ⇒[∀x1:s1, . . . , xn:sn. ∇f(x1, . . . , xn) →xp ⩾# f(x1, . . . , xn)
∧(∆p
f(x1, . . . , xn) ↔xp ># f(x1, . . . , xn))] ∈ThP.
By Theorem 3(1), a diﬀerence procedure terminates iﬀits “mother” pro-
cedure terminates. By Theorem 3(2), ∇f (q1, . . . , qn) entails that computation
of ∆p
f(q1, . . . , qn) does not get stuck. We therefore abandon with generating a
domain procedure ∇∆p
f for a diﬀerence procedure ∆p
f but use the domain pro-
cedure ∇f of its “mother” procedure f instead. Finally by Theorem 3(3), a
p-bounded procedure f computes a p-bounded function and a p-diﬀerence pro-
cedure is sound, i.e. it represents an equivalent requirement for a procedure call
f(q1, . . . , qn) being strictly bounded above by its pth argument qp, provided the
computation of f(q1, . . . , qn) does not get stuck.
After their synthesis, the diﬀerence procedures are optimized by simpliﬁca-
tion and recursion elimination as deﬁned in [10].
Example 2.
(i) function ∆1
minus(x,y:nat):bool <=
if y=0 then false else if x=0 then * else true fi fi
is computed as the optimized 1-diﬀerence procedure for the incompletely deﬁned
procedure minus of Fig. 1. Hence ∆1
minus(n, m) = true iﬀm ̸= 0 ̸= n and
∆1
minus(n, m) = false iﬀm = 0.
(ii) function ∆1
remainder(x:nat, y:nat):bool <=
if y=0 then * else if y>x then false else true fi fi
is computed as the optimized 1-diﬀerence procedure for the incompletely deﬁned
procedure remainder of Fig. 1. Hence ∆1
remainder(n, m) = true iﬀn ≥m ̸= 0
and ∆1
remainder(n, m) = false iﬀn < m. Since remainder is 2-bounded too, we
also obtain the optimized 2-diﬀerence procedure
function ∆2
remainder(x:nat, y:nat):bool <=
if y=0 then * else true fi
and ∆2
remainder(n, m) = true iﬀm ̸= 0 and ∆2
remainder(n, m) ̸= false.
(iii) function ∆1
half(x:nat):bool <=
if x=0 then false else if pred(x)=0 then * else true fi fi
is computed as the optimized 1-diﬀerence procedure for procedure half of Fig.
2, hence ∆1
half(n) = true iﬀn ≥2 and ∆1
half(n) = false iﬀn = 0.
8
OR(C) denotes the disjunction of the elements in C represented by if -conditionals.

344
C. Walther and S. Schweitzer
(iv) function ∆1
log(x:nat):bool <=
if x=0
then *
else if pred(x)=0 then true
else if even(x) then true else * fi fi fi
is computed as the optimized 1-diﬀerence procedure for procedure log of Fig. 2,
and ∆1
log(n) = true iﬀn = 1 or n ̸= 0 is even and ∆1
log(n) ̸= false. □
9
Generating Termination Hypotheses
Using the pE-calculus of Deﬁnition 5, we adjust the synthesis of termination
hypotheses as deﬁned in [10] to work also for incompletely deﬁned procedures:
Deﬁnition 7. (Termination Hypotheses) Let function f(x1:s1, . . . , xn:sn):s
<= Rf be a procedure of an incompletely deﬁned program P, let f (t1, . . . , tn)
be a recursive call which appears under some clause C in Rf, and let ∅̸= P ⊂
{1, . . . , n} such that ⊢Γ,C ⟨∇i, ∆i, xi ≽ti⟩for each i ∈P. Then a termination
hypothesis τ P
f of procedure f is deﬁned as
τ P
f =

∀x1:s1, . . . , xn:sn. C →
i∈P (∇i) ∧
i∈P (∆i)

.
(6)
Theorem 4. Let P = P0 ⊕⟨function f(x1:s1, . . . , xn:sn):s <= Rf⟩be an in-
completely deﬁned program such that P0 terminates. Then procedure f terminates
in P if some non-empty P ⊂{1, . . . , n} exists such that τ P
f
∈ThP0 for each
termination hypothesis τ P
f .
Example 3.
(i) We compute τ {1}
minus = τ {2}
minus = [∀x, y:nat. y ̸= 0 ∧x ̸= 0 →
true ∧true] for the incompletely deﬁned procedure minus of Fig. 1.
(ii) We compute τ {2}
remainder = [∀x, y:nat. y ̸= 0 ∧y ≯x →false] and τ {1}
remainder =
[∀x, y:nat. y ̸= 0 ∧y ≯x →∇minus(x, y) ∧∆1
minus(x, y)] for the incompletely
deﬁned procedure remainder of Fig. 1.
(iii) We compute τ {1}
half = [∀x:nat. x ̸= 0 ∧pred(x) ̸= 0 →true ∧true] for
procedure half of Fig. 2.
(iv) We compute τ {1}
log = [∀x:nat. x ̸= 0 ∧pred(x) ̸= 0 ∧even(x) →∇half(x) ∧
∆1
half(x)] for procedure log of Fig. 2. □
10
Summary and Conclusion
Our termination proof procedure for incompletely deﬁned programs is imple-
mented in the ✓eriFun system in the following way:
Upon deﬁnition of a data structure s, the domain procedures ∇sel are gener-
ated for each selector sel of s, each reﬂexive selector sel′ of s is inserted into Γ1
and the 1-diﬀerence procedures ∆1
sel′ for sel′ are generated, cf. Sections 6 and 8.

Automated Termination Analysis for Incompletely Deﬁned Programs
345
Upon deﬁnition of a procedure f, the pE-calculus is called to compute the
termination hypotheses for procedure f, cf. Deﬁnition 7. Then the system tries
to verify all termination hypotheses and—if successful—computes the domain
procedure ∇f and optimizes it, cf. Section 6. Next the pE-calculus is called
again to test whether procedure f is p-bounded for some argument position p,
cf. Deﬁnition 4. For each such p passing the test, the system computes the p-
diﬀerence procedure ∆p
f and optimizes it, cf. Section 8. Finally, f is inserted
into Γp to be available for subsequent termination proofs, i.e. for proving the
termination of procedures g which use procedure f in recursive g-calls.
Argument bounded algorithms proved as a useful concept to verify the termi-
nation of functional procedures by machine, easing the burden of a system user
signiﬁcantly as termination functions need to be supplied less frequently when
deﬁning procedures. Incompletely deﬁned programs provide an elegant and easy
way to write and to reason about programs which may halt with a run time
error. Our proposal uniﬁes the beneﬁts of both approaches without sacriﬁcing
performance or simplicity, neither when proving termination nor when reasoning
about programs.
Our method of proving the termination of incompletely deﬁned programs au-
tomatically has proved successful in ✓eriFun [12],[13], a semi-automated veriﬁer
for functional programs. The ✓eriFun system is available from the web [11].
Acknowledgement We are grateful to Markus Aderhold and Andreas Schlosser
for useful comments as well as to J¨urgen Giesl for thorough and fruitful discus-
sions and for constructive criticism on a draft of this paper.
References
1. Boyer, R.S., Moore, J.S.: A Computational Logic. Acad. Press, NY (1979)
2. Giesl, J.: Termination Analysis for Functional Programs using Term Orderings.
In: Proc. of the 2nd Intern. Static Analysis Symposium (SAS-95). Volume 983 of
Lecture Notes in Artiﬁcal Intelligence., Glasgow, Springer (1995) 154–171
3. Giesl, J.: Termination of Nested and Mutually Recursive Algorithms. Journal of
Automated Reasoning 19 (1997) 1–29
4. Giesl, J., Walther, C., Brauburger, J.: Termination Analysis for Functional Pro-
grams. In Bibel, W., Schmitt, P., eds.: Automated Deduction - A Basis for Appli-
cations. Volume 3. Kluwer Acad. Publ., Dordrecht (1998) 135–164
5. Kamareddine, F., Monin, F.: An extension of an automated termination method
of recursive functions. Intern. J. of Found. of Comp. Sc. 13 (2002) 361–386
6. Manoury, P., Simonot, M.: Automatizing Termination Proofs of Recursively De-
ﬁned Functions. Theoretical Computer Science 135 (1994) 319–343
7. Monin, F., Simonot, M.: An Ordinal Measure based Procedure for Termination of
Functions. Theoretical Computer Science 254 (2001) 63–94
8. Nielson, F., Nielson, H.R.: Termination Analysis based on Operational Semantics.
Technical report, Aarhus University, Denmark (1995)
9. Sengler, C.: Termination of Algorithms over Non−Freely Generated Data Types.
In McRobbie, M.A., Slaney, J.K., eds.: Proc. of the 13th Inter. Conf. on Automated
Deduction (CADE-13). Volume 1104 of Lecture Notes in Artiﬁcal Intelligence., New
Brunswick, NJ, Springer (1996) 121–136

346
C. Walther and S. Schweitzer
10. Walther, C.: On Proving the Termination of Algorithms by Machine. Artiﬁcial
Intelligence 71 (1994) 101–157
11. http://www.verifun.de.
12. Walther, C., Schweitzer, S.: About ✓eriFun. In Baader, F., ed.: Proc. of the 19th
Inter. Conf. on Automated Deduction (CADE-19). Volume 2741 of Lecture Notes
in Artiﬁcal Intelligence., Miami Beach, Springer (2003) 322–327
13. Walther, C., Schweitzer, S.: Veriﬁcation in the Classroom. Journal of Automated
Reasoning - Special Issue on Automated Reasoning and Theorem Proving in Ed-
ucation 32 (2004) 35–73
14. Walther, C., Schweitzer, S.:
Reasoning about Incompletely Deﬁned Programs.
Technical Report VFR 04/02, Programmiermethodik, Technische Universit¨at
Darmstadt (2004)
15. Bundy, A.: The Automation of Proof by Mathematical Induction. In Robinson,
A., Voronkov, A., eds.: Handbook of Automated Reasoning. Volume I. Elsevier
(2001) 845–911
16. Comon, H.: Inductionless Induction. In Robinson, A., Voronkov, A., eds.: Handb.
of Autom. Reasoning. Volume I. Elsevier (2001) 913–962
17. Walther, C.: Mathematical Induction. In Gabbay, D., Hogger, C., Robinson, J.,
eds.: Handbook of Logic in Artiﬁcial Intelligence and Logic Programming. Vol-
ume 2. Oxford University Press, Oxford (1994) 127–228
18. Autexier, S., Hutter, D., Langenstein, B., Mantel, H., Rock, G., Schairer, A.,
Stephan, W., Vogt, R., Wolpers, A.: VSE: Formal Methods Meet Industrial Needs.
Intern. J. on Software Tools for Technology Transfer 3 (2000) 66–77
19. Autexier, S., Hutter, D., Mantel, H., Schairer, A.: inka 5.0 - A Logic Voyager.
In Ganzinger, H., ed.: Proc. 16th Inter. Conf. on Autom. Deduction (CADE-16).
Volume 1632 of Lect. Notes in Artif. Intell., Trento, Springer (1999) 207–211
20. Hutter, D., Langenstein, B., Sengler, C., Siekmann, J., Stephan, W., Wolpers, A.:
Veriﬁcation Support Environment (VSE). High Integrity Syst. 1 (1996) 523–530
21. Hutter, D., Sengler, C.: INKA: The Next Generation. In McRobbie, M., J.Slaney,
eds.: Proc. 13th Inter. Conf. on Autom. Deduction (CADE-13). Volume 1104 of
Lect. Notes in Artif. Intell., New Brunswick, Springer (1996) 288–292
22. Brauburger, J.: Automatic Termination Analysis for Partial Functions using Poly-
nomial Orderings. In: Proc. of the 4th Intern. Static Analysis Symposium (SAS-97).
Volume 1302 of Lect. Notes in Artif. Intell., Paris, Springer (1997) 330–344
23. Brauburger, J., Giesl, J.: Approximating the Domains of Functional and Impera-
tive Programs. Science of Computer Programming 35 (1999) 113–136
24. Giesl, J.: Automated Termination Proofs with Measure Functions. In: Proc. of
the 19th Annual German Conf. on Artiﬁcal Intelligence (KI-95). Volume 981 of
Lecture Notes in Artiﬁcal Intelligence., Bielefeld, Springer (1995) 149–160
25. Gow, J., Bundy, A., Green, I.:
Extensions to the Estimation Calculus.
In
Ganzinger, H., McAllester, D.A., Voronkov, A., eds.: Proc. of the 6th Inter. Conf.
on Logic Progr. and Autom. Reasoning (LPAR-6). Volume 1705 of Lect. Notes in
Artif. Intelligence., Tbilisi, Georgia, Springer (1999) 258–272
26. Hutter, D.: Using Rippling to Prove the Termination of Algorithms. Technical
Report RR 97-03, DFKI, Saarbr¨ucken (1997)
27. McAllester, D., Arkoudas, K.: Walther Recursion. In McRobbie, M.A., Slaney,
J.K., eds.: Proc. of the 13th Inter. Conf. on Autom. Deduction. Volume 1104 of
Lect. Notes in Artif. Intell., New Brunswick, NJ, Springer (1996) 643–657
28. Walther, C., Schweitzer, S.: Automated Termination Analysis for Incompletely De-
ﬁned Programs. Technical Report VFR 04/03, Programmiermethodik, Technische
Universit¨at Darmstadt (2004)

Automatic Certiﬁcation of Heap Consumption
Lennart Beringer1, Martin Hofmann2, Alberto Momigliano1, and Olha Shkaravska2
1 Laboratory for Foundations of Computer Science, The University of Edinburgh,
Mayﬁeld Road, Edinburgh EH9 3JZ; {lenb,amomigl1}@inf.ed.ac.uk
2 Institut f¨ur Informatik, Ludwig-Maximilians-Universit¨at M¨unchen, Oettingenstraße 67,
80538 M¨unchen; {mhofmann,shkaravska}@tcs.ifi.uni-muenchen.de
Abstract. We present a program logic for verifying the heap consumption of
low-level programs. The proof rules employ a uniform assertion format and have
been derived from a general purpose program logic [1]. In a proof-carrying code
scenario, the inference of invariants is delegated to the code provider, who em-
ploys a certifying compiler that generates a certiﬁcate from program annotations
and analysis. The granularity of the proof rules matches that of the linear type sys-
tem presented in [6], which enables us to perform veriﬁcation by replaying typing
derivations in a theorem prover, given the speciﬁcations of individual methods.
The resulting veriﬁcation conditions are of limited complexity, and are automati-
cally discharged. We also outline a proof system that relaxes the linearity restric-
tions and relates to the type system of usage aspects presented in [2].
1
Introduction
Validating the resource consumption of a program obtained from an unknown or un-
trustworthy code producer is an important task of any security architecture targeting
devices with limited resources. The Mobile Resource Guarantees (MRG) project [17]
is developing Proof-Carrying Code (PCC) technology [14] to endow mobile code with
certiﬁcates of bounded resource consumption that can be validated automatically. These
certiﬁcates are generated by a compiler which, in addition to translating high-level pro-
grams into machine code, derives formal proofs based on programmer annotations and
program analysis. The foundation of the validation process is a program logic that is
sufﬁciently powerful to formulate expressive certiﬁcates. As the logic and the certiﬁ-
cate checker are trusted components from the point of view of the program recipient,
soundness of the logic with respect to an operational model of the target architecture
is crucial, and should ideally be present in a machine-checkable form. In [1], we pre-
sented our general-purpose logic, including proofs of soundness and completeness, the
latter relative to the ambient logic HOL. The development is completely backed up
by an implementation in Isabelle/HOL, building upon, and extending, earlier work on
formalised program logics by Kleymann, Nipkow and others [8, 15]. In this paper, we
use this logic to justify more specialised logics for the resource heap consumption. We
develop proof rules that allow the code producer to certify the heap consumption of a
low-level program in such a way that the recipient can validate the memory behaviour
prior to execution. Judgements in these heap logics arise from the base logic by restrict-
ing assertions to syntactically uniform representations and formally deriving proof rules
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 347–362, 2005.
c⃝Springer-Verlag Berlin Heidelberg 2005

348
L. Beringer et al.
in the theorem prover. The assertion formats are motivated by, and closely related to,
typing judgements used in a certifying compiler for inferring the memory requirements
of programs at source level.
Our approach to deriving proof rules for restricted assertion formats from the base
logic achieves several goals: ﬁrstly, soundness of the heap logics with respect to the
operational model is obtained from the soundness of the base logic. Secondly, a method
for certiﬁcate generation is achieved: the type systems infers invariants (in our case:
method speciﬁcations) for the low-level code based on the strategy used for compiling
high-level programs. Thirdly, a strategy is obtained that allows the program recipient to
verify the validity of a proof automatically: the proof rules are set up in such a way that
methods can be proved in a largely syntax-directed way, with side conditions that are
of low complexity. The granularity of proof rules matches that of the type systems: se-
quences of low-level instructions that originate from a high-level language construct are
combined in a single proof rule. Thus, the consumer-side veriﬁcation can follow a val-
idation tactic that essentially replays typing judgements, where the compiler-generated
invariants eliminate the need to perform complex proof search.
In the main part of this paper, we outline this certiﬁcation strategy for an (afﬁnely)
linear assertion format that interprets the type system of Hofmann and Jost [6]. Contin-
uing our work on formalisation, the derivation of the proof system from the base logic
has been implemented in Isabelle/HOL, as has the veriﬁcation tactic at recipient side.
However, in order to demonstrate that our approach is more widely applicable, we also
outline an extension that considers assertions corresponding to the more powerful type
system of [2]. Here, the linearity requirements are relaxed by distinguishing between
three usage disciplines a program may obey with respect to a data structure. While the
formalisation of the corresponding proof system for derived assertions in a theorem
prover is under way, the syntax-directedness and the computational simplicity of the
side conditions again make an automatic veriﬁcation by the recipient appear feasible.
2
Components of the MRG Architecture
In this section we summarise MRG’s PCC architecture. We start by introducing our rep-
resentation of low-level code, the Grail language, and the program logic that forms the
foundation of the certiﬁcation. We then move to the high-level language, Camelot, and
discuss the compilation of programs into Grail, with particular emphasis on memory
management. Finally, we outline the static analysis of memory consumption that will
be the basis of the proof rules in the following section. For details, see [1, 4, 6, 12].
Syntax and Semantics of Grail The target of MRG’s compilation, and the language to
which certiﬁcates refer, is a restricted form of Java bytecode, Grail [4]. This language
retains the object and method structure of bytecode, but represents method bodies as
sets of mutually tail-recursive ﬁrst-order functions. The syntax comprises instructions
for object creation and manipulation, method invocation and primitive operations such
as integer arithmetic, as well as let-bindings to combine program fragments. The main
characteristic of Grail is its dual identity: its (impure) call-by-value functional seman-
tics coincides with an imperative interpretation of the expansion of Grail programs into

Automatic Certiﬁcation of Heap Consumption
349
the Java Virtual Machine Language, provided that some mild syntactic conditions are
met. In particular, we require that actual arguments in function calls coincide syntac-
tically with the formal parameters of the function deﬁnitions. In [4] we showed that
this discipline, together with Administrative-Normal-Form (ANF)-style normalisation
of let-expressions, allows function calls to be interpreted as immediate jump instruc-
tions, and admits the deﬁnition of a code transformation that is the exact reversal of the
expansion of Grail expressions into JVML. The formal syntax of expressions
e ∈expr ::= null | int i | var x | prim op x x | new C [ti := xi] | x.t | x.t:=x |
C.t | C.t:=x | let x=e in e | e ; e | if x then e else e | call f | C.M(a)
a ∈args ::= var x | null | i
is deﬁned over mutually disjoint sets of method names, class names, function names
(i.e. labels of basic blocks), (static) ﬁeld names and variables, ranged over by M, C, f,
t, and x, respectively. In the grammar, i ranges over integers and op denotes a primitive
operation of type V ⇒V ⇒V such as an arithmetic or a comparison operator. Here V
is the semantic category of values (ranged over by v), comprising integers, references r,
and the special symbol ⊥, which stands for the absence of a value. Heap references are
either null or of the form Ref l where l ∈L is a location.
Expressions represent basic blocks and are built from operators, constants, and pre-
viously computed values (names). They correspond to primitive sequences of bytecode
instructions which may, as a side effect, alter the heap. For example, x.t and x.t:=y
represent (non-static) ﬁeld access instructions, while C.t and C.t:=y denote their static
counterparts. The binding let x=e1 in e2 is used if the evaluation of e1 returns an
integer or reference value on top of the JVM stack while e1 ; e2 represents non-binding
composition, used for example if e1 is a ﬁeld update. Object creation includes the ini-
tialisation of the object ﬁelds according to the argument list. Function calls follow the
Grail calling convention (i.e. correspond to immediate jumps) and do not carry argu-
ments. The instruction C.M(a) represents static method invocation. While formal pa-
rameters of method invocations are variables, actual arguments can be variables, in-
teger constants or null. Although a formal type and class system may be imposed on
Grail programs, our program logic abstracts from these restrictions. We assume that all
method declarations employ distinct names for identifying inner basic blocks.
A program is represented by a table Ftable mapping each function identiﬁer to
an expression and a list of formal arguments, and a table Mtable associating method
parameters and the name of the initial basic block to class names and method identiﬁers.
The formal basis of the program logic is an operational semantics that is expressed as a
big-step evaluation relation E ⊢h,e ⇓h′,v. For expression e, such a judgement relates
an (initial) variable environment E ∈E and an initial heap h ∈H to a ﬁnal heap h′ ∈H
and the result value v ∈V . Heaps are ﬁnite maps from locations and ﬁeld names to
values, while environments are modelled as total maps from variable names to values.
The rules for deﬁning the operational semantics are omitted, but are available in [1].
The Core Program Logic In our program logic [1], judgements take the form G▷e : P
where e is a Grail expression, G a context used for storing veriﬁcation assumptions for
recursive methods and functions, and P an assertion. Deviating from both Hoare-style

350
L. Beringer et al.
and VDM-style logic [7], we combine pre- and post-conditions into single assertions:
P is a predicate (in the meta-logic HOL) over the semantic components, and relates the
initial and ﬁnal heaps, the initial environment, and the result value: P : E →H →H →
V →B, where B is the set of booleans. For example, the rule for program composition
G▷e1 : P1
G▷e2 : P2
G▷let x=e1 in e2 : λ E h h′ v. ∃h1 w. (P1 E hh1 w) ∧w ̸
= ⊥∧
(P2 (E⟨x := w⟩)h1 h′ v)
VLET
existentially abstracts the intermediate heap and models the binding of x to the result
of evaluating e1 by interpreting P2 in the extended environment E⟨x := w⟩. Satisfaction
of a speciﬁcation P by program e is denoted by |= e : P and asserts that E ⊢h,e ⇓h′,v
implies PE h h′ v. In [1] we proved the soundness and (relative) completeness of the
program logic with respect to this (partial) interpretation, i.e. the statement ∅▷e :
P ⇐⇒|= e : P. Associations between methods and their speciﬁcations are collected in a
method speciﬁcation table MST. In order to allow the usage of a proof rule for method
invocation that includes parameter adaptation, each method speciﬁcation additionally
also abstracts over a list of actual arguments.
Compilation of Camelot Programs The high-level language Camelot is a ﬁrst-order
functional language with ML-style polymorphism and algebraic datatypes [12]. The
following example code introduces a data type of integer lists and functions that imple-
ment the insertion sort algorithm.
type L = !Nil | Cons of int * L
let ins a l = match l with Nil -> Cons(a,Nil)
| Cons(x,t)@_ -> if a < x
then Cons(a,Cons(x,t))
else Cons(x, ins a t)
let sort l =
match l with Nil -> Nil
| Cons(a,t)@_ -> ins a (sort t)
The compiler translates a program into Grail following a whole-program compilation
approach with phases such as monomorphisation and let-normalisation. The resulting
code contains a class InsSort comprising one (static) method for each Camelot function.
For example, the code for insertion sort yields methods InsSort.ins and InsSort.sort
whose (slightly pretty-printed) Grail representations are shown next:
method InsSort.ins(int a, D l) = call f
f : let b=prim isNull l l in
if b then let l =null in D.make(a,l)
else let v3 =l.HD in let v2 =l.TL in D.free(l) ; let b=prim less a v3 in
if b then let l =D.make(v3,v2) in D.make(a,l)
else let l =InsSort.ins(a,v2) in D.make(v3,l)
method InsSort.sort(D l) = call g
g : let b=prim isNull l l in
if b then null
else let v3 =l.HD in let v2 =l.TL in D.free(l) ;
let l =InsSort.sort(v2) in InsSort.ins(v3,l)

Automatic Certiﬁcation of Heap Consumption
351
Furthermore, a class D is deﬁned that declares sufﬁciently many ﬁelds for representing
values of all declared types (in our case: HD and TL), plus some internal ﬁelds (TAG,
FLIST, NEXT). The latter are used for discriminating between the various datatype
constructors (TAG, only used for datatypes with more than one non-nullary construc-
tor), and for implementing a freelist, i.e. a (non-cyclic) list of D-objects whose initial
member is pointed to by the static ﬁeld FLIST, and whose elements are linked via ﬁeld
NEXT. The declaration of D also contains methods for performing the operations typ-
ical of a freelist: objects can be inserted into the freelist using the method free, while
the method make allocates a fresh object (method alloc) and initialises its application
ﬁelds according to its method parameters (method ﬁll). The code for these memory
management methods is shown next:
method D.free(D nd)
= let f =D.FLIST in nd.NEXT:=f ; D.FLIST:=nd
method D.alloc()
= let f =D.FLIST in let b=prim isNull f f in
if b then new D []
else let t = f.NEXT in D.FLIST:=t ; f
method D.ﬁll(D x,int v,D w) = x.HD:=v ; x.TL:=w ; x
method D.make(int v,D w)
= let x=D.alloc() in D.ﬁll(x,v,w)
Notice that of all methods, alloc is the only one that contains the instruction new. Fresh
memory can thus only be allocated through the memory management interface, and this
operation is only performed if the freelist is empty. This discipline is at the heart of our
veriﬁcation: the interpretation of assertions in the derived program logic ensures that all
requests from the freelist can be served without executing new.
Two further aspects of the compilation are worth mentioning, as they concern pro-
grammer annotations in the source program. In each datatype declaration, (at most) one
constructor (like Nil in our example code) can be equipped with the annotation !, thus
instructing the compiler to use a heap-free representation. The effect is visible in the
compiler output: conditionals corresponding to match statements w.r.t. this construc-
tor discriminate over the condition isNull instead of inspecting the content of the ﬁeld
TAG. The second programmer annotation, @_, indicates that the corresponding (branch
of the) pattern match may be implemented destructively, i.e. the memory cell inhabited
by the value against which the match is performed is returned to the freelist after the
components have been accessed. The compiler output reﬂects this by calling method
free after de-constructing the cons-cells in methods ins and sort. The compiler veriﬁes
that both annotations are used safely: a constructor annotated with ! must not have
arguments, and pattern matching using @_ is only admitted if the data structure may
indeed be destroyed, i.e. it is not used in the continuation of the program.
Inference of Heap Space Consumption In order to analyse the memory requirements
of functional programs, Hofmann and Jost [6] introduced a type system that solves the
following problem. Given a program e of type, say, bool list →bool list, calculate
a (linear) function f such that computing e(L) for some input list L will not require
more than f(|L|) additional heap cells, provided that a freelist is available for storing
temporarily unused cells. In the context of the Camelot compilation, the result of such
an analysis can be used to ensure that the evaluation of e(L) will not perform a call

352
L. Beringer et al.
to new, by wrapping the evaluation with code that allocates a freelist of the sufﬁcient
length f(|L|) prior to calling e.
The analysis of [6] is formulated using an extended notion of types such that differ-
ent portions of the input can contribute a different amount to memory consumption. For
each (non-heapfree) datatype constructor, a numeric annotation indicates the amount
of heap that is required for a single build operation using that constructor. For exam-
ple, L(5) indicates the type of an integer list where each occurrence of Cons requires
ﬁve free memory cells to be available – constructing the list, say, [97;634;42] thus
requires ﬁfteen additional cells to be available. Judgements in the type system are of
the form Γ,n ⊢e : T,m where T is the (extended) type of e with respect to the context Γ
(which maps free variables of e to extended types), while n and m represent constants
that describe memory requirements that are independent of the size of the data struc-
tures. The typing rules are deﬁned in such a way that m and the numeric annotations
in T are expressed relative to the size of the output data structure, while n and the an-
notations in Γ refer to the size of the input data structures. For example, evaluating a
program e with typing x : L(5), 4 ⊢e : L(2),7 in an environment where x is bound
to the list [97;634;42] requires no more than 4 + (5 ∗3) cells to be available in the
freelist, and leaves a freelist of length (at least) 7+2∗|M| where M is the output list.
We present next some of the typing rules, which are motivated by this understand-
ing. The rule for constructing a list node, CONS, requires the initial freelist to contain
at least as many elements as the ﬁnal freelist does, plus one cell for representing the
value itself, plus the additional k cells speciﬁed in the desired return type. In order to
construct lists with homogeneous memory behaviour, the type associated to the tail t in
the context must also be L(k).
n ≥1+k +m
Γ,h : int,t : L(k),n ⊢Cons(h,t) : L(k),m CONS
Γ,n ⊢e1 : A,m
Γ,h : int,t : L(k),n+1+k ⊢e2 : A,m
Γ,x : L(k),n ⊢match x with Nil ⇒e1| Cons(h,t)@ ⇒e2 : A,m DM
Γ,n ⊢e1 : A,m
Γ,h : int,t : L(k),n+k ⊢e2 : A,m
Γ,x : L(k),n ⊢match x with Nil ⇒e1| Cons(h,t) ⇒e2 : A,m M
Γ1,n ⊢e1 : A,k
Γ2,x : A,k ⊢e2 : B,m
Γ1,Γ2,n ⊢let x = e1 in e2 : B,m
LET
Γ,x : A1,y : A2,n ⊢e : A,m
Γ,z : A1 ⊕A2,n ⊢e[z/x,z/y] : A,m SHARE
The effect of a pattern match on the freelist depends on whether the match is performed
destructively or not. In both cases, the branch executed in the case of an empty list
has exactly the same memory behaviour as the composite expression. In the case of a
non-empty list, the freelist available for the continuation grows at least by the amount
k “stored in” the list node that is taken apart. In case of a destructive match, the cell in-
habited by this node becomes available as well, which explains the additional +1 in rule
DM that is not present in the rule for a non-destructive match, M. The rule for program
composition, LET, reﬂects the above-mentioned interpretation of typing judgements, in
particular the fact that the result type and the right-hand-side annotation m of a judge-
ment refer to the size of the result of the computation, as the typing of the composite

Automatic Certiﬁcation of Heap Consumption
353
statement may be obtained compositionally from the typing of the sub-terms, glued to-
gether by the freelist-constant k, and the type A, that occur in both hypothesis. Finally,
the rule SHARE allows us to split resources between different variables representing
the same data structure – operation ⊕recursively descends through the type structure
and adds the annotations in the leafs. As this contraction results in the data structure
being aliased, the soundness of this rule relies on the semantic condition of benign
sharing: whenever a cell l is returned to the freelist during a destructive pattern match,
the program continuation will not access l through any aliasing access path. Various
static approximations to this conditions can be considered. Of these, imposing a linear
typing discipline (i.e. considering the type system without rule SHARE, and interpreting
the context split in rule LET to be a disjoint partitioning) is rather restrictive, but only
moderately complex to implement, and is therefore chosen in the formal interpretation
of assertions in the next section. However, as many programs cannot be typed under
such a discipline, it is desirable to have alternative means at hand. The generalisation of
our assertion format in Sect. 6 is a step in that direction, as it corresponds to the more
permissive type system of usage aspects presented in [2].
The inference process for the type system consists of two stages. First, a skele-
ton type derivation is constructed where the numerical annotations n,k,m,... are in-
terpreted as (rational) variables, constrained by side conditions such as the one in rule
CONS. These side conditions are collected, and in a second step handed over to a linear
programming solver. Any feasible solution to the linear program corresponds to a pos-
sible typing derivation. This inference process has been implemented for the language
considered in [6] and for Camelot, and scales well even to programs where skeleton
derivations contain thousands of variables or constraints.
In the context of certiﬁcate generation, the solution inferred by the analysis (if ex-
isting) is presented as a signature that contains one (extended) typing for each Camelot
function. In the case of our example program, one such signature is
{ins : 1,int×L(0) →L(0),0, sort : 0,L(0) →L(0),0.}
For both functions, this signature asserts that the heap consumption does not depend on
the size of the input: ins consumes one heap cell, while sort executes in-place: the
cell that is required in the call to ins has previously been gained in the pattern match.
3
Format and Interpretation of Assertions
In this section we introduce a class of assertions that interpret judgements of the high-
level type system in the program logic. These assertions have a uniform syntactic form,
and their interpretation expands to a predicate over the semantic components (environ-
ment, pre-heap, post-heap and return value), as is required of speciﬁcations by the core
logic. This syntactic form,
U,n,Γ ▶T,m
comprises components similar to the type system:
n,m ∈N represent the numerical results from the analysis. In the interpretation these
numbers will relate to the initial and ﬁnal length of the freelist, respectively.

354
L. Beringer et al.
Γ is the typing context, a partial map from program variables to extended types.
U (a ﬁnite set of program variables) is used to enforce the linear typing discipline.
T indicates the type of an expression e that satisﬁes the assertion.
In this paper, we only consider the data type of integer list. In the grammar
T ∈T ::= 1 | I | L(k)
the constructors represent respectively the unit (void) type, the integer type, and the type
of lists where each occurrence of the Cons constructor is equipped with k ∈N additional
free heap cells and the Nil constructor does not reserve any space. In [3] we consider
additional types, for representing e.g. integer trees.
The interpretation of assertions, and the proof rules that will be presented in the
following section, are formulated in such a way that the set U is inferred during the
veriﬁcation condition generation, and coincides with the free variables of e. Thus, the
restricted context Γ⇂U amounts to the minimal context in which an expression e may be
typed.
Before giving the semantic deﬁnition of an assertion, we introduce some auxiliary
predicates. Given a value v of type T and a heap h, the predicate v,h |=T R,n computes
the region R inhabited by v, and the number n of free heap cells associated with it
according to the numerical annotations in T.
⊥,h |=1 ∅,0
REGU
i,h |=I ∅,0
REGI
LIST(n,r,R,h)
r,h |=L(k) R,k ∗n
REGL
In rule REGU, we abuse the earlier notation slightly and let the symbol ⊥also denote
the canonical value of type 1. In rule REGL, the list predicate LIST(n,r,R,h) is satisﬁed
if reference r in heap h points to a (cycle-free) linked list of length n, whose cells inhabit
exactly locations R.
LIST(0,null,∅,h) NIL
h(l).HD = i
h(l).TL = r
LIST(n,r,R,h)
LIST(n+1,Ref l,R⊎l,h)
CONS
The deﬁnition directly reﬂects the layout of data values implemented by the Camelot
compiler – the disjoint sum notation ⊎indicates the implicit side condition {l}∩R = ∅.
Next, we deﬁne a predicate Γ,U |=E
h R,n that computes the amount n of free heap
associated to the variables in Γ⇂U and the heap region R inhabited by the corresponding
data structures.
Γ,∅|=E
h ∅,0 HEAPE
E⟨x⟩,h |=Γ(x) R1,n
Γ,U |=E
h R2,m
Γ,U ⊎x |=E
h R1 ⊎R2,n+m
HEAPV
Rule HEAPV, in combination with the above deﬁnition of the datatype representation
predicates, enforces a strict separation both between and within data structures. We will
relax some of these separation conditions in Sect. 6.
A further auxiliary predicate, freelist(h,F,N), is deﬁned by FL(N,h⟨D.FLIST⟩,F,h)
and expresses the fact that in heap h, the static ﬁeld D.FLIST points to a (non-cyclic)
list of length N, where the cells collectively inhabit locations F and are linked via ﬁeld
NEXT. The predicate FL( , , , ) is deﬁned analogously to the predicate LIST( , , , ).

Automatic Certiﬁcation of Heap Consumption
355
Finally, the predicate footprint(R,h,h′) ≡∀l ∈dom h\R. h(l) = h′(l) bounds the set
of locations on which two heaps may differ.
The interpretation U,n,Γ ▶T,m is now deﬁned by
U,n,Γ ▶T,m ≡∀qF R.
⎛
⎜
⎜
⎝
∃N K. freelist(h,F,N) ∧
Γ,U |=E
h R,K ∧
R∩F = ∅∧
n+K +q ≤N
⎞
⎟
⎟
⎠−→
⎛
⎜
⎜
⎝
∃QSM H. v,h′ |=T Q,S ∧freelist(h′,H,M) ∧
Q∩H = ∅∧(Q∪H) ⊆(R∪F) ∧
footprint(F ∪R,h,h′) ∧
m+S+q ≤M ∧dom h = dom h′
⎞
⎟
⎟
⎠
where the free variables E, h, h′ and v are implicitly abstracted over. A judgement
G▷e : U,n,Γ ▶T,m thus asserts that, whenever
– the initial heap h contains a freelist of length N, inhabiting locations F,
– the region R inhabited by the data structures Γ⇂U is disjoint from F, and
– the length N of the freelist is at least the amount K of heap owned by Γ⇂U, plus the
additionally required size n and some constant q,
and the evaluation of e terminates, then there are M and S and regions Q and G s. t.
– the result v (according to the type T) inhabits region Q (in the ﬁnal heap h′ ) and
contributes S cells to the (ﬁnal) freelist,
– the ﬁnal heap contains a freelist of length M inhabiting region G,
– the result and the ﬁnal freelist do not overlap,
– both G and Q are contained in the initial freelist region F, extended by the locations
reachable (in the initial heap) by the variables in Γ⇂U,
– locations that are neither part of the freelist nor reachable from variables from Γ⇂U
remain unchanged, i.e. F ∪R is an approximation of the locations touched,
– the ﬁnal length M of the freelist is at least the amount S contributed by the result,
plus the analysis number m and the constant q, and
– no new objects have been allocated.
Thus, data structures represented by variables in Γ⇂U are potentially destroyed. Corre-
sponding locations may have been recycled during the evaluation of e, may have been
inserted into the freelist, or have become unreachable. In contrast, locations not reach-
able from variables in Γ⇂U remain unchanged.
4
Proof Rules
Having introduced the assertion format, we can derive proof rules for various Grail
phrases by unfolding the interpretation. The design of the proof rules was guided by the
aim of minimising the complexity of veriﬁcation conditions that arise from side con-
ditions, and to mirror the high-level typing rules. Indeed, the granularity of the proof
rules corresponds to that of the typing system: match statements and constructor appli-
cations are veriﬁed as single entities, i.e. only the soundness proof of the rules inspects
the constituent instructions of the corresponding methods.

356
L. Beringer et al.
We ﬁrst present the rules for basic syntactic constructs of Grail. There are no proof
rules for object creation and (virtual or static) ﬁeld access instructions, since these op-
erations are only performed inside the memory management methods. The rules for
function calls and method invocations are the rules of the base logic.
m ≤n
G▷null : ∅,n,Γ ▶L(k),m NULL
m ≤n
G▷int i : ∅,n,Γ ▶I,m INT
m ≤n
Γ(x) = T
G▷var x : {x},n,Γ ▶T,m VAR
{x,y} ⊆dom Γ
m ≤n
G▷prim op x y : {x,y},n,Γ ▶I,m PRIM
G▷e1 : U1,n,Γ ▶1,m
G▷e2 : U2,m,Γ ▶T,k
G▷e1 ; e2 : U1 ⊎U2,n,Γ ▶T,k
COMP
G▷e1 : U1,n,Γ ▶S,l
G▷e2 : U2,l,(Γ,x : S) ▶T,m
S ̸
= 1
G▷let x=e1 in e2 : U1 ⊎(U2 \{x}),n,Γ ▶T,m
LET
G▷e1 : U1,n,Γ ▶T,m
G▷e2 : U2,n,Γ ▶T,m
G▷if b then e1 else e2 : U1 ∪U2,n,Γ ▶T,m
IF
(G∪{(call f,P})▷Ftable f : P
G▷call f : P
CALL
(G∪{(C.M(a),P}) ▷
Mtable C M : λ E h h′ v. ∀E′. E = frame (params C M) a E′ −→PE′ h h′ v
G▷C.M(a) : P
INVS
Next, we present the rules for non-destructive and destructive match operations, and
for constructor Cons. Treating the freelist management operations atomically reﬂects
the fact that the states at intermediate program points of these composite statements
do not satisfy formulae of the restricted form – they contain dangling pointers and
incompletely built data structures. In rule DMATCH, the additional side condition x ̸
= t
is needed to avoid the insertion of t into the freelist by instruction D.free(x).
Γ(x) = L(k)
h /∈{x,t}
G▷e : U,n+k,(Γ,h : I,t : L(k)) ▶T,m
G▷let h=x.HD in let t =x.TL in e : (U \{h,t})⊎x,n,Γ ▶T,m MATCH
Γ(x) = L(k)
h /∈{x,t}
x ̸
= t
G▷e : U,n+k +1,(Γ,h : I,t : L(k)) ▶T,m
G▷let h=x.HD in let t =x.TL in D.free(x) ; e :
(U \{h,t})⊎x,n,Γ ▶T,m
DMATCH
Γ(y) = L(k)
Γ(x) = I
G▷D.make(x,y) : {x,y},m+k +1,Γ ▶L(k),m MAKE
Finally, we give some structural rules.We will comment on their role in veriﬁcation
condition generation in the next section.

Automatic Certiﬁcation of Heap Consumption
357
G▷e : U,n,Γ ▶T,m
n ≤n′
m′ ≤m
G▷e : U,n′,Γ ▶T,m′
RELAX
G▷e : V,n,Γ ▶T,m
V ⊆U
G▷e : U,n,Γ ▶T,m
GEN
G▷e : U,n,Γ ▶T,m
G▷e : U,n+k,Γ ▶T,m+k SHIFT
G▷e : U,n,Γ ▶T,m
∀x ∈U. ∆(x) = Γ(x)
G▷e : U,n,∆▶T,m
CTXT
Theorem 1. All proof rules presented in this section are derivable in HOL from the
core logic.
The proof rules enforce benign sharing in a way that corresponds to linearity in the type
system. The rules COMP and LET combine the U-sets using the disjoint union operator
⊎. From the point of view of surrounding code, linearity is also observed in the rules
MATCH and DMATCH, despite variable x occurring repeatedly in the program text.
5
Veriﬁcation
We now return to our example program, insertion sort, and outline the veriﬁcation pro-
cess. As was remarked earlier, compiling the Camelot code for insertion sort results in
two class declarations: the class D with ﬁelds for the representation of data types and
the (pre-veriﬁed) memory management methods, plus a class InsSort containing the
application methods ins and sort. In addition, the compiler generates a certiﬁcate that
contains the result of the program analysis in a form that can be automatically veriﬁed.
The certiﬁcate contains the method speciﬁcation table, the deﬁnition of a proof context
G, and calls to a predeﬁned Isabelle tactic. Before describing the global veriﬁcation
strategy, we ﬁrst outline how this tactic veriﬁes an individual method body.
For verifying that method body Mtable C M satisﬁes a speciﬁcation of the restricted
form, i.e. that G ▷Mtable C M : U,n,Γ ▶T,m holds, we have implemented an Is-
abelle tactic (≈150 lines of ML) that starts by applying the GEN rule, then applies
the syntax-directed and memory management proof rules discharging the side condi-
tions locally, and ﬁnally veriﬁes that the initial side condition of GEN, V ⊆U, holds
for the inferred set V. The tactic maintains a stack of open goals that ensures that only
ground conditions arise. Inspecting the proof rules shows that apart from numerical
comparisons, set inclusions, and context look-ups, no advanced simpliﬁcation nor de-
cision procedures are required. The tactic is applied with a speciﬁcation table MST that
contains entries representing the result of the type analysis. Assertions are formulated
from the perspective of the method body, i.e. the chosen variable names are the formal
parameters. Method invocations are veriﬁed using a variation of INVS that incorporates
the effect of rules SHIFT and CTXT, and a notion of variable renaming for assertions
that is needed to handle the passing from actual arguments to formal parameters. In our
example program, the speciﬁcation table contains two entries that correspond to
Ins Spec ≡{a,l},1,[a : I,l : L(0)] ▶L(0),0
Sort Spec ≡{l},0,[l : L(0)] ▶L(0),0

358
L. Beringer et al.
Note that we have made no effort to employ efﬁcient data structures and we rely on
naive representation of contexts and sets as provided by Isabelle/HOL. However, we
have implemented a technique that allows us to verify each function body only once,
based on compiler-generated merge point information. For some details see [3].
Global veriﬁcation is based on the rule
goodContext MST G
ﬁnite(G)
(C.M(a),MST M a) ∈G
∅▷C.M(b) : MST M b
VADAPTS
which derives ∅▷C.M(b) : B (notice the empty context), provided the existence of a
context G that fulﬁls property goodContext and contains an entry (C.M(a),A) where A
and B arise by instantiating the method speciﬁcation table entry for M with the method
arguments a and b, respectively. The generated certiﬁcate contains the deﬁnition of such
a context G, consisting of one entry (C.M(a),MST M a) for each method invocation
occurring in the program. In our example program, the context G is given by
G ≡

(InsSort.ins(a,v2), MST ins [a,v2]), (InsSort.ins(v3,l), MST ins [v3,l]),
(InsSort.sort(v2), MST sort [v2])

.
The deﬁnition of goodContext (see [1] for details) requires each such entry to satisfy
G▷Mtable C M : ϕ(MST M), where ϕ models the passing of method arguments to the
formal parameters. As the result of applying ϕ is of the form U,n,Γ ▶T,m, discharg-
ing the condition of the goodContext predicate may be performed by the tactic discussed
above. Our veriﬁcation script veriﬁes ﬁrst each method body individually, before com-
bining the resulting local correctness statements. We thus obtain correctness of the sort
method for arbitrary method arguments
Theorem 2. We have ∅▷InsSort.sort(x) : MST sort [x]
for arbitrary x using a strategy that veriﬁes each method body only once, despite the
existence of two entries for ins in G.
6
Usage Aspects
As we pointed out earlier, the interpretation of assertions U,n,Γ ▶T,n corresponds to
a linear type system at the Camelot level. Although guaranteeing benign sharing, this d
iscipline is overly restrictive, as may be illustrated by the expression Cons(length(x),
x), where x is used as an argument for length, but also in the surrounding code. Mo-
tivated by similar examples involving nontrivial sharing of heap cells, Aspinall and
Hofmann [2] introduced a less restrictive type system that distinguishes three different
usages a program can make of a variable. These aspects are ordered in increasing order
of permissiveness:
1. modifying use, e.g. l in sort l, or the destroyed parameter in in-place list append;
2. non-modifying use, but shared with result, e.g. the second argument in append;
3. non-modifying use, and not shared with result, e.g. l in length l.

Automatic Certiﬁcation of Heap Consumption
359
Based on aspects we can allow duplication of variables in certain cases while preserving
benign sharing. For instance the nonlinear expression let x =e1(y3) in e2(xi, y1)
will be allowed, where variables are annotated with their relative usage aspects. In the
remainder of this section, we outline an assertion format for the type system of [2],
suitably adapted to the setting of Camelot compilation. To increase readability we omit
numerical annotations as they have the same format and meaning as in the linear system.
Usage Aspects for the Source Language We deﬁne a notion of usage-aspect aware
contexts Γ in which variables are decorated with their usage aspects; for instance xi : A
if x : A is used with aspect i ∈{1, 2, 3}. If xi : A ∈Γ, we write Γ(x) = A and Γ[x] = i. The
“committed to i” context ∆i is the same as ∆, but each declaration x2 : A is replaced
with xi : A. If we have two contexts ∆1, ∆2 which only differ on usage aspects, we
deﬁne the context ∆= ∆1 ∧∆2, to have the same domain and typing, but such that
∆[x] = min(∆1[x], ∆2[x]). Some of the typing rules are:
Γ,xi : A ⊢e : B
j ≤i
Γ,x j : A ⊢e : B
LDROP
Γ ⊢e1 : B
Γ ⊢e2 : B
Γ,x3 : I ⊢if x then e1 else e2 : B
LIF
x2 : A ⊢x : A
LVAR
Γ,∆1 ⊢e1 : A
Θ,∆2, xi : A ⊢e2 : B
Φ(i)
Γi, Θ, ∆i
1 ∧∆2 ⊢let x=e1 in e2 : B
LLET
The LVAR rule has default aspect 2, although variables can be raised (not shown here)
if heap-free or weakened (LDROP) to a more destructive usage. The most complex rule
is LLET: ﬁrst, the context is split into parts according to variables speciﬁc to e1 (or e2),
that is Γ (or Θ), and common variables, possibly used with different aspects ∆1,∆2. A
variable whose region overlaps with the result of e1 (i.e. of a variable that is of aspect 2
in Γ, ∆1) inherits the aspect of x in e2 - this is why Γi and ∆i
1 appear in the succedent.
Additionally, for a variable occurring in both contexts, the resulting usage aspect should
not supersede its aspects in the two antecedents. The additional side condition Φ(i)
prevents any common variable from being modiﬁed in e1 or e2 before being referenced
in e2: namely, ∆1[z] = 1 is never allowed, ∆1[z] = 3 is always allowed, ∆1[z] = 2 is only
allowed, provided neither i = 1 nor ∆2[z] = 1. Further, we exclude ∆1[z] = ∆2[z] = 2.
For more details, please see [2].
Derived Assertions for Usage Aspects In preparation of the deﬁnition of derived asser-
tions, we extend the previous auxiliary judgements by a (boolean) separation ﬂag p; the
relation v,h |=L(A) R, p means that v points to a well formed list occupying a region R
in a heap h. If the separation ﬂag p is set to false then the regions occupied by elements
of the list are allowed to overlap (internal sharing). Otherwise, these regions must be
located in separated parts of the heap.
This deﬁnition is generalised to a relation over environments, heaps, contexts and
regions in the following way:
E⟨x⟩,h |=Γ(x) R1,true
Γ,U |=E
h,1 R2
Γ,U ⊎x |=E
h,1 R1 ⊎R2
E⟨x⟩,h |=Γ(x) R1,true
Γ,U |=E
h,2 R2,true
Γ,U ⊎x |=E
h,2 R1 ⊎R2,true
E⟨x⟩,h |=Γ(x) R1,false
Γ,U |=E
h,2 R2,false
Γ,U ⊎x |=E
h,2 R1 ∪R2,false
E⟨x⟩,h |=Γ(x) R1,false
Γ,U |=E
h,3 R2
Γ,U ⊎x |=E
h,3 R1 ∪R2

360
L. Beringer et al.
The interpretation of aspect-aware assertions mirrors the correctness theorem in [2],
extended with a freelist, but not including any reasoning about the freelist’s length:
U1,U2,U3,Γ ▶T ≡∀F R1 R2 R3
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
U1 ⊎U2 ⊎U3 ⊆dom Γ ∧
freelist(h,F) ∧
Γ,U1 |=E
h,1 R1 ∧
Γ,U2 |=E
h,2 R2,false ∧
Γ,U3 |=E
h,3 R3 ∧
R1 ∩(R2 ∪R3) = ∅∧
F ∩(R1 ∪R2 ∪R3) = ∅
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
−→
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
∃QH. v,h′ |=T Q,false ∧
freelist(h′,H) ∧Q∩H = ∅∧
footprint(F ∪R1,h,h′) ∧
Q ⊆(F ∪R1 ∪R2) ∧
H ⊆(F ∪R1) ∧
dom h = dom h′ ∧
Γ,U2 |=E
h,2 R2,true −→v,h′ |=T Q,true
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
A judgement G▷e : U1,U2,U3,Γ ▶T thus asserts that, whenever
– variables in Ui point in the initial heap h to sets of locations Ri according to their
type in Γ and usage aspect i, with internal sharing allowed when i ≥2,
– the heap regions associated with variables of aspect 1 do not overlap with heap
regions related to other aspects, i.e. R1 ∩(R2 ∪R3) = ∅,
– the initial heap contains a freelist inhabiting region F, which does not overlap with
any region pointed to by a variable in U1 ∪U2 ∪U3,
and the evaluation of e terminates, then there exist regions Q and H such that:
– in h′, result v according to type T inhabits region Q, possibly with internal sharing,
– the ﬁnal heap contains a freelist in region H, not overlapping with Q,
– data structures pointed to by variables outside U1 and F remain unchanged,
– the result region consists of locations from the initial freelist F, locations from R1
(corresponding to destroyed data substructures, whose space has been recycled)
and from R2, which may overlap with the result region Q,
– the ﬁnal freelist region consists of locations of the initial freelist and R1,
– no new objects are allocated,
– if region R2 does not contain any shared (sub)structures, then neither does Q.
For example, in-place list append admits a typing that corresponds to the assertion
▷append(l1,l2) : {l1},{l2}, /0,(l1 : L(A),l2 : L(A)) ▶L(A) where l1(l2) is the de-
stroyed (aliased) argument.
Proof Rules for Usage Aspects We now introduce some of the derived rules.
Γ(x) = T
G▷var x : ∅,{x},∅,Γ ▶T DUVAR
G▷e : U1,U2 ⊎x,U3,Γ ▶T
G▷e : U1 ⊎x,U2,U3,Γ ▶T DUDROP21
G▷e1 : U1,U2,U3,Γ ▶T
G▷e1 : U1,U2,U3,Γ ▶T
G▷if x then e1 else e2 : U1,U2,U3 ⊎x,(Γ,x : I) ▶T DUIF
G▷e1 : U11,U12,U13,Γ ▶S
x ∈U2i
G▷e2 : U21,U22,U23,(Γ,x : S) ▶T
Ψ(i)
G▷let x=e1 in e2 : U1,U2,U3,Γ ▶T
DULET

Automatic Certiﬁcation of Heap Consumption
361
These rules are direct counterparts of the typing rules. In particular, in the DULET rule
the real work is done by the side condition Ψ(i), which statically approximates benign
sharing. For instance, for i = 2 the side condition Ψ(2) specialises to the conjunction of
static assumptions U1 = U11 ∪U21, U2 = (U12 \U21) ∪(U22 \ {x}), U3 =
	
U13 \ (U21 ∪
U22)

∪
	
U23\(U11∪U12)

,U11∩(U21∪U22∪U23) = ∅,U12∩(U21∪U22∪U23) ⊆U23.
7
Conclusion and Related Work
In this paper, we have described a logic for derived assertions that allows the results
of [6]’s analysis to be veriﬁed in Grail’s bytecode logic. Although we have presented
the logic for a speciﬁc datatype, our approach applies to algebraic datatypes in general.
Because the MRG project aims to verify the consumption of a variety of resources,
we have employed a general purpose logic as the basis of our formalisation. Our work
is thus best compared to other work on mechanical or at least formal veriﬁcation of
pointer programs using variants of traditional (general purpose) Hoare logic. Histori-
cally, some of the ﬁrst formal veriﬁcation of pointer programs in [11] (and later [10])
used a model where the store is incorporated in the assertion logic. More recent is the
veriﬁcation of several algorithms, including list manipulating programs and the Schorr-
Waite graph-marking algorithm, by Bornat [5] using the Jape system. This approach
employs a Hoare logic for a while-language with components that are semantically
modelled as pointer-indexed arrays. Separation conditions are expressed as predicates
on (object) pointers. Mehta and Nipkow [13] employ the same semantic model of the
heap for reasoning about pointer programs in higher-order logics. This effort extends
earlier work by Nipkow et al. [15] on formalised proofs in HOL of soundness and (rel-
ative) completeness of program logics.
Proving heap-related properties has also been the topic of Separation Logic [16].
Indeed, the primitives of Separation Logic appear well suited to express the mutual
separation of data structures, and their separation from the freelist more succinctly. An
Isabelle/HOL implementation is presented in [18], although the author reports proofs
(typically in-place reversal) to be slightly more complicated than in [13]. Furthermore,
little support for automation is currently available, both for proof search and for gener-
ating invariants. Finally, properties such as heap preservation in our predicate footprint
are more intensional than is usually the case in (Hoare-style) Separation Logic. Differ-
ently from Hoare-style logics in general, the style of our logic allows us to relate pre
and post states without the use of auxiliary variables.
The contribution of the present paper is the translation of typing assertions to state-
ments in the base logic and the formulation of derived rules which allow for automatic
construction of proofs. We have indicated how the linearity restrictions may be over-
come by considering the more generous sharing and separation systems induced by
usage aspects. This could be pushed further toward Koneˇcn´y’s [9] system for layered
sharing. Comparing the veriﬁcation of the example programs with the veriﬁcation of
similar programs in the core bytecode logic demonstrates the general beneﬁt of a proof
system of derived assertions, concerning both the proof complexity and automation. In-
deed, while veriﬁcation in the bytecode logic appears to depend on the machinery of a
general purpose theorem prover and manual intervention, a logic of derived assertions

362
L. Beringer et al.
may be implementable in a stand alone prover with access to fairly straightforward
simpliﬁcation capabilities.
Acknowledgements This research was supported by the MRG project (IST-2001-
33149) which is funded by the EC under the FET proactive initiative on Global Com-
puting. We would like to thank all our colleagues and in particular David Aspinall for
this role in implementing the certiﬁcate generation tactic.
References
1. D. Aspinall, L. Beringer, M. Hofmann, H.-W. Loidl, and A. Momigliano. A program logic for
resource veriﬁcation. In K. Slind, A. Bunker, and G. C. Gopalakrishnan, editors, Proceedings
of TPHOLs’04, volume 3223 of LNCS, pages 34–49. Springer, Sept. 2004.
2. D. Aspinall and M. Hofmann. Another type system for in-place update. In D. L. M´etayer,
editor, Proceedings of ESOP’02, volume 2305 of LNCS, pages 36–52. Springer, Apr. 2002.
3. L. Beringer, M. Hofmann, A. Momigliano, and O. Shkaravska. Towards certiﬁcate genera-
tion for linear heap consumption. In Proceedings of LRPP’04, July 2004.
4. L. Beringer, K. MacKenzie, and I. Stark. Grail: a Functional Form for Imperative Mobile
Code. In Proceedings FGC’03, volume 85(1) of Electronic Notes in Theoretical Computer
Science. Elsevier, June 2003.
5. R. Bornat. Proving Pointer Programs in Hoare Logic. In R. Backhouse and J. Nuno Oliveira,
editors, Proceedings of MPC’00, volume 1837 of LNCS, pages 102–126, July 2000.
6. M. Hofmann and S. Jost. Static prediction of heap space usage for ﬁrst-order functional
programs. In Proceedings of POPL’03, pages 185–197. ACM Press, Jan. 2003.
7. C. Jones. Systematic Software Development Using VDM. Prentice Hall, 1990.
8. T. Kleymann.
Hoare Logic and VDM: Machine-Checked Soundness and Completeness
Proofs. PhD thesis, LFCS, University of Edinburgh, 1999.
9. M. Koneˇcn´y. Functional in-place update with layered datatype sharing. In M. Hofmann,
editor, Proceedings of TLCA’03, volume 2701 of LNCS, pages 195–210. Springer, June 2003.
10. K. R. M. Leino. Toward Reliable Modular Programs. PhD thesis, California Institute of
Technology, 1995. Available as Technical Report Caltech-CS-TR-95-03.
11. D. C. Luckham and N. Suzuki. Veriﬁcation of array, record, and pointer operations in Pascal.
ACM Transactions on Programming Languages and Systems, 1(2):226–244, Oct. 1979.
12. K. MacKenzie and N. Wolverson. Camelot and Grail: Resource-aware Functional Program-
ming on the JVM. In S. Gilmore, editor, Proceedings of TFP’03, pages 29–46. intellect,
2003.
13. F. Mehta and T. Nipkow. Proving pointer programs in higher-order logic. In F. Baader,
editor, Proceedings of CADE-19, volume 2741 of LNCS/LNAI, pages 121–135. Springer,
Aug. 2003.
14. G. C. Necula. Proof-carrying code. In Proceedings of POPL’97, pages 106–119. ACM Press,
1997.
15. T. Nipkow. Hoare Logics for Recursive Procedures and Unbounded Nondeterminism. In
J. Bradﬁeld, editor, Proceedings of CSL’02, volume 2471 of LNCS, pages 103–119, Sept.
2002.
16. J. Reynolds. Separation Logic: A Logic for Shared Mutable Data Structures. In Proceedings
of LICS’02. IEEE Computer Society, July 2002.
17. D. Sannella and M. Hofmann. Mobile Resource Guarantees. EU Project IST-2001-33149,
2002–2004. http://groups/inf.ed.ac.uk/mrg/.
18. T. Weber. Towards mechanized program veriﬁcation with separation logic. In J. Marcin-
kowski and A. Tarlecki, editors, Proceedings of CSL’04, volume 3210 of LNCS, pages 250–
264. Springer, Sept. 2004.

A Formalization of Oﬀ-Line Guessing for
Security Protocol Analysis⋆
Paul Hankes Drielsma, Sebastian M¨odersheim, and Luca Vigan`o
Information Security Group, ETH Zurich, CH-8092 Zurich, Switzerland
http://www.infsec.ethz.ch/~[drielsma|moedersheim|vigano]
Abstract. Guessing, or dictionary, attacks arise when an intruder ex-
ploits the fact that certain data like passwords may have low entropy,
i.e. stem from a small set of values. In the case of oﬀ-line guessing, in par-
ticular, the intruder may employ guessed values to analyze the messages
he has observed. Previous attempts at formalizing oﬀ-line guessing con-
sist of extending a Dolev-Yao-style intruder model with inference rules to
capture the additional capabilities of the intruder concerning guessable
messages. While it is easy to convince oneself that the proposed rules are
correct, in the sense that an intruder can actually perform such “guess-
ing steps”, it is diﬃcult to see whether such a system of inference rules
is complete in the sense that it captures all the kinds of attacks that we
would intuitively call “guessing attacks”. Moreover, the proposed sys-
tems are specialized to particular sets of cryptographic primitives and
intruder capabilities. As a consequence, these systems are helpful to dis-
cover some oﬀ-line guessing attacks but are not fully appropriate for
formalizing what oﬀ-line guessing precisely means and verifying that a
given protocol is not vulnerable to such guessing attacks.
In this paper, we give a formalization of oﬀ-line guessing by deﬁning a
deduction system that is uniform and general in that it is independent of
the overall protocol model and of the details of the considered intruder
model, i.e. cryptographic primitives, algebraic properties, and intruder
capabilities.
1
Introduction
Motivation. A serious vulnerability of security protocols lies in the simple fact
that users tend to choose poor passwords, that is, passwords that are easy to
remember and accordingly easy to guess (English words, for instance). This can
give rise to guessing (or dictionary) attacks in which an intruder is able to guess
a password or some other guessable data, and then somehow verify that his guess
is correct [15,19].
One usually distinguishes between on-line and oﬀ-line guessing. One speaks
of on-line guessing when the intruder employs guesses when interacting with
⋆This work was partially supported by the FET Open Project IST-2001-39252 and
the BBW Project 02.0431, “AVISPA: Automated Validation of Internet Security
Protocols and Applications”.
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 363–379, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

364
P. Hankes Drielsma, S. M¨odersheim, and L. Vigan`o
other agents, e.g. trying to log into a system using a guessed password. One
speaks of oﬀ-line guessing when the intruder (who is not necessarily passive)
employs guesses when analyzing observed messages, e.g. when trying to decrypt
a message that is encrypted with a guessable password.
A number of approaches have been proposed to perform formal protocol
analysis in the presence of on-line guessing, e.g. [9]. In this paper, we focus on
oﬀ-line guessing. Several protocols, like the ones of the EKE family [7,8], have
been devised in an attempt to provide resilience to oﬀ-line guessing attacks. The
idea behind these protocols is that, even if the intruder guesses the password
correctly, he has no means of verifying whether his guess is correct or not.
In order to prove formally that such a protocol is correct, or detect attacks
on it, it is necessary to have a precise deﬁnition of oﬀ-line guessing and of the
potential vulnerabilities of protocols to such guessing attacks. A number of ap-
proaches, e.g. [10,11,12,13,17], have been proposed to formally analyze protocols
under the assumption that the intruder can perform oﬀ-line guessing.
The motivation underlying our work is based on the observation that these
approaches suﬀer from two problems. First, all these diﬀerent approaches are
based on extending a Dolev-Yao-style intruder [14] with sets of inference rules
to capture the additional capabilities of the intruder in the context of guessable
messages. While it is usually easy to convince oneself that the proposed rules
are correct, in the sense that an intruder can actually perform such “guessing
steps”, it is diﬃcult to see whether such a system of inference rules is complete
in the sense that it captures all the kinds of attacks that we would intuitively
call “guessing attacks”. Second, the proposed deduction systems are specialized
to particular intruder capabilities and to particular sets of cryptographic primi-
tives and operators (and, in some cases, e.g. [12,17], they are even restricted to
considering single guesses).
As a consequence, these systems are helpful to discover some oﬀ-line guess-
ing attacks, but are not fully appropriate for formalizing what oﬀ-line guessing
precisely means and proving that a particular protocol is not vulnerable to such
guessing attacks.
Contributions. We propose, however, that there is a fairly simple intuition under-
lying oﬀ-line guessing, which captures a generic class of oﬀ-line guessing attacks
without restriction to a particular intruder model or a set of cryptographic op-
erations and their associated properties. In this paper, we overcome the above
problems by precisely formulating this intuition to give a formalization of oﬀ-
line guessing. More speciﬁcally, we deﬁne a deduction system that is uniform
and general in that it is independent of the details of the considered intruder
model, i.e. cryptographic primitives, algebraic properties, and intruder capabil-
ities. In particular, our formalization works at the level of messages and is thus
independent of the technical and conceptual details of the overall protocol model
(which could be formalized, for example, by multiset rewriting, strand spaces, or
process calculi). Moreover, our approach allows us to consider multiple guesses
simultaneously.

A Formalization of Oﬀ-Line Guessing for Security Protocol Analysis
365
Our formalization is based on the idea of explicitly representing the inter-
mediate states of the computation of oﬀ-line guessing attacks. We call these
intermediate computation states maps. Intuitively, a map is the result of the
intruder constructing a message from his knowledge and inserting, in place of an
unknown value, every value from the dictionary he uses to perform the attack;
it thus maps candidate values for guessable data to the concrete message that
would result in the respective cases.
Organization. In Section 2 we discuss the intuitions underlying our approach to
oﬀ-line guessing, and in Section 3 we give a deduction system that captures these
intuitions. As a concrete example, in Section 4 we consider Microsoft’s Chal-
lenge/Response Authentication Protocol, version 2 (MS-CHAPv2). We draw
conclusions and discuss related and future work in Section 5.
2
Context and Intuitions
The Dolev-Yao intruder model has proved to be an appropriate abstraction in the
formal analysis of security protocols, as it idealizes the behavior and properties
of cryptographic operations. However, when considering oﬀ-line guessing, this
model suﬀers from several problems — even though guessing has nothing to
do with “breaking” cryptography. In this section, we illustrate the intuitions
behind our formalization of oﬀ-line guessing. To that end, we ﬁrst describe the
shortcomings of the Dolev-Yao model, in particular with respect to guessing, and
then argue how it can be appropriately modiﬁed to faithfully model a “semi-ideal
world” in which cryptography is still perfect but passwords are guessable. This
will lead us to introducing the notion of maps, which explicitly represent the
intermediate computation steps of an intruder during oﬀ-line guessing.
2.1
Problems with the Standard Dolev-Yao Intruder Model
Most approaches to the formal analysis of security protocols abstract away from
the details of real cryptography and instead use a term-algebra of messages in the
style of the Dolev-Yao intruder model [14], where concrete data like agent names,
nonces, or keys are represented by constants, and cryptographic operations like
diﬀerent kinds of encryption are represented by function symbols. Inherent in
the models considered in such approaches are several (closely related) simplifying
assumptions:
– Cryptography is perfect, i.e. there is no way to decrypt messages without
knowing the proper key.
– Syntactically diﬀerent terms represent diﬀerent messages. This assumption
is often relaxed by deﬁning algebraic properties, e.g. (ab)c = (ac)b, which
induce an equivalence relation on the terms, and one then considers the
quotient algebra in which syntactically diﬀerent terms represent the same
value if and only if they are equivalent.

366
P. Hankes Drielsma, S. M¨odersheim, and L. Vigan`o
– It is not deﬁned what happens when someone attempts to decrypt an en-
crypted message using a wrong key, i.e. by explicitly modeling that in this
case one obtains a string of random bits.
– The intruder always implicitly knows the format or structure of messages
being exchanged in a protocol, even if he cannot decrypt them.
The Dolev-Yao intruder model, which incorporates these simplifying assump-
tions, has proved to be extremely successful in security protocol analysis. How-
ever, these assumptions also have many subtle implications. Firstly, when an
agent creates a “fresh” nonce, this is usually modeled by picking a fresh con-
stant symbol, which is then “by deﬁnition” diﬀerent from anything that was
seen before. One thus abstracts away the small chance that an agent acciden-
tally “generates” a nonce that was used before (maybe by a diﬀerent agent).
Secondly, the cryptographic operations behave like injective functions, for in-
stance {|m|}k ̸= {|m′|}k′ if k ̸= k′ or m ̸= m′. This abstracts away the small
probability that diﬀerent operations may lead to the same result, e.g. that en-
crypting diﬀerent plain-texts with the same key may produce the same bit-string.
This leads, for instance, to the unrealistic consequence that all hash-functions
are perfect, e.g. never produce the same hash-value for diﬀerent messages.
These assumptions have unrealistic and counter-intuitive consequences, but
still they often provide an appropriate abstraction level for analysis: “collisions”
like the ones described above usually cannot be systematically exploited by an
intruder, at least not if we assume a reasonable behavior of the cryptographic op-
erations. For example, it should be computationally diﬃcult (though, of course,
not impossible) to produce diﬀerent messages with the same hash-value. The
Dolev-Yao model can thus indeed be eﬀectively used to abstract away the possi-
bility that the intruder exploits properties of real cryptography. However, when
we consider guessing attacks, we can observe further clashes with the assump-
tions of the idealized Dolev-Yao model: the intruder may observe a message
that is encrypted with a password, and if this password is poorly chosen, it
may appear in a dictionary that the intruder possesses; so, roughly speaking, he
“knows” the password. However, if we assume that the password is simply part
of the intruder knowledge, then, according to the Dolev-Yao model, the intruder
can decrypt everything encrypted with that password. This is, however, not the
case in reality: although the intruder possesses a dictionary that contains the
password, he does not know which entry in the dictionary it is, and it might be
impossible to identify the right entry. In other words, not distinguishing between
guessable and known messages in the Dolev-Yao model is like assuming that the
intruder “always guesses correctly”.
2.2
Rule-Based Extensions of the Dolev-Yao Intruder Model
Despite all these diﬃculties, it is still attractive to use a model in the style
of Dolev and Yao in order to abstract from the details of real cryptography,
not only for “standard” protocol analysis but also when considering a guessing
intruder. In this way, several approaches, e.g. [10,12,13,17], propose extensions of

A Formalization of Oﬀ-Line Guessing for Security Protocol Analysis
367
a Dolev-Yao-style model for oﬀ-line guessing, where the guessable messages (i.e.
those that occur in the intruder’s dictionary) are not part of the initial intruder
knowledge, but oﬀ-line guessing is modeled by additional rules that describe the
intruder’s ability to make a guess and verify it. An example of such a rule is:
– If the intruder knows a message m and its symmetric encryption {|m|}pw
with a password pw, and pw is guessable,
– then he can verify his guess and thus obtain pw (and add it to his knowledge).
It is easy to convince oneself that such a rule is correct with respect to one’s
intuition: the intruder can generate, for every pw′ in his dictionary, the term
{|m|}pw′ and compare each result with the original message {|m|}pw. Assuming
that there are no collisions, there is only one entry in his dictionary, namely pw,
such that the constructed message is identical with the original one.
However, it is unclear how we can ever be sure that a given set of such rules
is complete, i.e. that all the ways to ﬁnd out messages by guessing are covered
by the rule set. To see how hard it is to ﬁnd a complete set of rules, consider the
following rule, which captures another aspect of guessing:
– If the intruder knows the symmetric encryption {|⟨m1, m2⟩|}pw with a guess-
able password pw of a composed message ⟨m1, m2⟩and he knows the ﬁrst
component m1,
– then he can obtain pw (and thus also m2).
This is the case because the intruder can attempt to decrypt the given message
with every entry in his dictionary as the decryption key, and — again abstracting
from collisions — only for one entry of the dictionary, the decrypted message
begins with m1, which he can check as he knows m1. This identiﬁes the right
entry pw in his dictionary and he obtains the second component m2.
2.3
An Explicit Model of Oﬀ-line Guessing
Obviously, one can ﬁnd many such rules, and even when one arrives at a set of
rules that seem to cover one’s intuition completely, it is unclear how to prove
their completeness, as there is no formal deﬁnition of the underlying concept that
should be captured by these rules. Also, when extending the model with new
cryptographic operators, e.g. exponentiation, one would have to appropriately
extend the set of rules for oﬀ-line guessing as well.
However, we propose that there is a simple intuition behind the two rules
above and similar ones, which is based on operations the intruder can perform on
every entry in his dictionary so that he can uniquely determine one particular
entry of the dictionary (which then represents the “correct” guess). Our idea
to formalize oﬀ-line guessing attacks is to formalize this intuition by making
explicit the intermediate states of such a computation, which we express via
maps. Roughly speaking, a map relates each entry of the dictionary (or n-tuples
thereof) to the outcome of a sequence of operations under this guess (or these
guesses).

368
P. Hankes Drielsma, S. M¨odersheim, and L. Vigan`o
v
{|m|}v
d1 {|m|}d1
d2 {|m|}d2
...
...
dn {|m|}dn
v1 v2 {|v2|}v1
d1 d1 {|d1|}d1
d1 d2 {|d2|}d1
...
...
...
dn dn {|dn|}dn
v
π1({|{|m1, m2|}pw|}v)
d1 π1({|{|m1, m2|}pw|}d1)
d2 π1({|{|m1, m2|}pw|}d2)
...
...
dn π1({|{|m1, m2|}pw|}dn)
Fig. 1. Three examples of maps
Fig. 1 shows three examples of maps, where the intruder’s dictionary contains
the entries {d1, . . . , dn}. The ﬁrst is the map for the example {|m|}pw covered
above, where pw appears in the dictionary, i.e. dc = pw for the “correct” entry c ∈
{1, . . . , n}: the intruder encrypts the known message m with each of the di. Only
one of the entries {|m|}di corresponds to the original message {|m|}pw, and this
entry reveals the correct password pw = dc. The second example demonstrates
that the concept of maps can be easily extended to multiple guesses: if the
intruder knows a term {|pw′|}pw which consists of a guessable message encrypted
with a guessable key-term, then the intruder can simply build every encryption
of an entry in his dictionary with an entry in his dictionary.
Before we turn to the third example displayed in Fig. 1, we need to consider in
more detail one of the simplifying assumptions mentioned above: what happens
when encrypted messages are decrypted with a wrong key.
2.4
Decryption with a Wrong Key
In a Dolev-Yao intruder model without guessing, it is not necessary to consider
what happens when decrypting messages with a wrong key; this is because the
intruder knows whether he knows a particular key. Under the perfect crypto-
graphy assumption, he will thus not even attempt to decrypt messages for which
he does not know the proper key. Also, we can assume that the intruder will
send to honest agents only messages that they can receive, i.e. messages that
are encrypted with the keys that the honest agents will use for decryption, since
the intruder will not gain anything from a situation where an agent reads some
random bits after decryption of incoming messages. When considering guesses,
however, it is important to model what happens if the intruder decrypts messages
with a wrong key, for instance because he might simply try out every entry of
his dictionary as the decryption key.
It has become standard in Dolev-Yao-style intruder models to have explicit
rules for decryption of messages, i.e. of the form
– If the intruder knows {|m|}k and k,
– then he can obtain m by decryption.
Since these rules require that the intruder knows the key k, they are not really
appropriate when considering guessed keys. Rather, we want to turn to the
original form of the Dolev-Yao model where the intruder can perform encryption

A Formalization of Oﬀ-Line Guessing for Security Protocol Analysis
369
and decryption operations using as keys any composition of messages he knows,
and we add algebraic equations which, for instance, express that symmetric
encryption and decryption with the same key cancel each other out, i.e.
{|{|m|}k|}k = m .
Note that, for the sake of simplicity, we have assumed here that symmetric
encryption and decryption are in fact the same procedure (as is, for instance,
the case for exclusive-or); this is not a restriction but may introduce unrealistic
attacks in general.
The reason why we turn to this more complicated model with cancellation
equations is that the term {|{|m|}k|}k′ is equal to the term m if and only if k = k′
(assuming that there are no other algebraic properties for the operation {| · |}·).
This is exactly what we want, as the intruder can now attempt the decryption
with several keys, which results in the original message m only in the case that
he used the right key. In all other cases, he obtains a term of the form {|{|m|}k|}k′,
which represents some random bits he obtained after decryption, but which he
is not a priori able to distinguish from the “real” message m.1
We can now return to the third example of Fig. 1, where the intruder tries to
ﬁnd out the guessable password pw of the message {|⟨m1, m2⟩|}pw where he knows
the message m1. Here, we denote with π1 and π2 the projections to the ﬁrst and
second component of a pair, i.e. we have the cancellation rules π1(⟨m1, m2⟩) =
m1 and π2(⟨m1, m2⟩) = m2. The intruder builds a map in two steps: ﬁrst he
encrypts the given message {|⟨m1, m2⟩|}pw with every entry of the dictionary,
and then he builds the projection to the ﬁrst component. Only for the correct
guess, i.e. the entry c with dc = pw, the resulting message has the property
π1({|{|⟨m1, m2⟩|}pw|}dc) = π1(⟨m1, m2⟩) = m1 ,
and thus there is exactly one entry in this map that equals m1, while all other
entries are “irreducible” terms in the sense that they are not equal to any simpler
term. Note that the intruder could not verify the correct entry the way we
showed, if he did not initially know the message m1 (and there is no other way
to verify the guess).
To summarize, we have so far described a model where the intruder can
compose maps by applying operations on every term in a dictionary and on
messages that he knows for sure, and compare the outcome of each entry in the
map with other messages he knows. Only in the case that there is a single entry
in the map that he can distinguish from the other ones is the guessing successful
in the sense that he can identify the correct value(s) of the guess(es). Observe
that this model is independent from the concrete set of operators and algebraic
equations considered (we have only used them for concrete examples) and we can
1 Note that in the case that symmetric encryption and decryption are the same algo-
rithm as in our example, the intruder might even construct the term {|{|{|m|}k|}k′|}k′
by re-encrypting the term with the same key he used for decryption and, modulo
the cancellation, obtain the term he started with, i.e. {|m|}k.

370
P. Hankes Drielsma, S. M¨odersheim, and L. Vigan`o
thus entirely avoid specifying a large set of rules to capture all circumstances in
which an intruder can guess certain messages. In fact, we have only two “rules”:
ﬁrstly, the intruder can arbitrarily compose messages and maps that he already
knows to form new maps, and secondly, he can check if there is a particular
entry in a map. In fact, as we will explain in the next section, we do not need to
distinguish between messages and maps any more, as we can regard any message
as a special case of a map with only one entry.
Before we introduce our formalization of oﬀ-line guessing, let us conclude
this section with some remarks. First, observe that the above discussion does
not contain any notion of the probability that a guessing attack is successful.
Furthermore, it does not depend on the size of the dictionary, and ignores the
case that a password might be guessable (in the sense that it stems from a small
set of values), but is not contained in the concrete dictionary of the intruder. The
reason why these technical details can be ignored is that one might consider a
protocol as vulnerable if there is the mere possibility to mount an attack. In fact,
although the vulnerability of a protocol to oﬀ-line guessing attacks can be mod-
eled by expressing explicitly the probability of the intruder guessing correctly,
in our model we are only concerned with expressing whether this vulnerability
exists or not. Hence, a protocol that is vulnerable to oﬀ-line guessing according
to our model might still be “safe” in practice if the users choose good passwords
that cannot be easily guessed so that the attack becomes infeasible. Finally, one
may wonder what consequences would arise if we consider an intruder with sev-
eral dictionaries (instead of just one). It is, however, not diﬃcult to see that this
cannot aﬀect our notion of a guessing attack as one could consider the union of
all such dictionaries as the intruder’s dictionary.
3
A Formal Model for Oﬀ-line Guessing
We now introduce our formalization of oﬀ-line guessing: we give a Dolev-Yao-
style deduction system that attempts to capture the intuitions behind oﬀ-line
guessing in a uniform and general way. As we remarked above, our formalization
works at the level of messages and is thus independent of the overall protocol
model and of the details of the considered intruder model, i.e. cryptographic
primitives, algebraic properties, and intruder capabilities. Moreover, it allows us
to consider multiple guesses simultaneously.
Deﬁnition 1. An intruder model I = (Σ, O, ≈, D) consists of a ﬁnite set Σ of
operators where Σ0 ⊆Σ is a set of constants (i.e. symbols of arity 0), a subset
O ⊆Σ of these operators, called the intruder-accessible operators, a congruence
relation ≈⊆T 2
Σ on terms (usually deﬁned through a set of equations), and a
ﬁnite dictionary D ⊆Σ0, where D∩O = ∅and d1 ̸≈d2 for any pair of constants
d1, d2 ∈D with d1 ̸= d2.2 Also, let V be a set of variables disjoint from symbols
in Σ.
2 For convenient modeling of fresh data, the signature Σ may contain inﬁnitely many
constants, as long as the dictionary D is ﬁnite, without aﬀecting the results presented
here. We assume, however, a ﬁnite signature for simplicity.

A Formalization of Oﬀ-Line Guessing for Security Protocol Analysis
371
We assume that the reader is familiar with standard concepts like terms and
substitutions (see, for instance, [3]). Given a substitution σ and a term t, we
denote the application of σ to t by writing tσ, the domain of σ by writing
dom(σ), and the variables of t by writing vars(t). In this paper, we consider only
substitutions of variables with guesses (i.e. elements of the dictionary D).
Example 1. As a running example, we will consider the intruder model
Ie = (Σe, Oe, ≈e, De) ,
where the signature Σe consists of a set of constants Σ0e and the following
operators: asymmetric encryption {·}·, the inverse key of an asymmetric key-pair
·−1, symmetric encryption {|·|}·, function application ·(·), and pairing ⟨·, ·⟩, as well
as the two corresponding projections π1(·) and π2(·). All operators besides Σ0e
and ·−1 are accessible to the intruder, i.e. Oe = Σe \ (Σ0e ∪{·−1}). Equivalence
on terms is equality in the quotient algebra TΣe/≈e for the following equations:
{{m}k}k−1 ≈e m ,
{|{|m|}k|}k ≈e m ,
(k−1)
−1 ≈e k ,
π1(⟨m1, m2⟩) ≈e m1 ,
π2(⟨m1, m2⟩) ≈e m2 .
The dictionary De consists of a set of constants De = {d1, . . . , dn}.
□
Our formalization is based on the notion of maps introduced in the previous
section, as illustrated in Fig. 1. As we remarked above, a map is the result of the
intruder constructing a message from his knowledge and inserting, in place of an
unknown value, every value from the dictionary he uses to perform the attack.
The main characteristic of a map is that it is uniform and complete, in the sense
that exactly the same sequence of operations is performed for the various values
of the guesses, and that all possible guesses in the dictionary are considered. In
order to formally deﬁne what we mean by “the same sequence of operations” of
a map, we introduce the notion of a pattern term:
Deﬁnition 2. Let I = (Σ, O, ≈, D) be an intruder model. A pattern term (or,
simply, pattern) P is simply an element of TΣ(V ). We say that a set M is a
map iﬀthere is a pattern term P such that
M = {(σ, Pσ) | dom(σ) = vars(P) ∧∀v ∈vars(P). vσ ∈D} .
Note that this formal deﬁnition represents exactly the way we described maps
informally in the previous section, namely as tables of guesses and the corre-
sponding outcomes. For instance, each of the three maps displayed in Fig. 1 is
represented by the term on top of the right-most column, i.e. {|m|}v, {|v2|}v1, and
π1({|{|⟨m1, m2⟩|}pw|}v), respectively.
Note also that it follows straightforwardly from the deﬁnition that there
is a bijection between maps and patterns, modulo equivalence of patterns and
renaming of variables. Hence, a map is uniquely represented by a pattern that is
parameterized over a set of data to be guessed, and the intruder’s computation

372
P. Hankes Drielsma, S. M¨odersheim, and L. Vigan`o
of the outcome of this pattern for every possible combination of candidate values
for the guesses.
Given this bijection, in the following we will identify maps and their corre-
sponding patterns. In particular, for a map M and the corresponding pattern
P, we will identify entries of M and substitutions of variables with guesses in
P, as well as look-up in M and the term resulting from the application of a
substitution of variables with guesses in P.
Maps are expressive constructs: we can view all messages as maps with just
one entry, represented by a ground term (so the only substitution possible is the
identity). Also, the dictionary itself is a map, which is represented by a variable
v. This expressiveness allows us to consider a formal model where the intruder
knowledge consists only of maps.
We now deﬁne an entailment relation over maps, which tells us when the in-
truder can derive a map from a set of maps. In particular, given that we identify
maps with corresponding patterns, we deﬁne the entailment over patterns for
simplicity. This entailment relation yields a deduction system. Given that “nor-
mal” messages are a special case of maps, we can see this system as an extension
of (a system for) the standard Dolev-Yao intruder. We therefore call this system
the guessing Dolev-Yao intruder and denote the relation by · ∈GDYI(·).
Deﬁnition 3. Let I = (Σ, O, ≈, D) be an intruder model. The entailment rela-
tion P ∈GDYI(P), which expresses that the set of patterns P entails the pattern
P, is the smallest relation closed under the following rules:
P ∈GDYI(P) AXP (for P ∈P) ,
v ∈GDYI(P) AXv (for v ∈V ) ,
P1 ∈GDYI(P)
· · ·
Pn ∈GDYI(P)
op(P1, . . . , Pn) ∈GDYI(P)
OP (for op ∈O with arity n) ,
P1 ∈GDYI(P)
P2 ∈GDYI(P)
vσ ∈GDYI(P)
VER ,
where the rule VER has the following side conditions:
– v ∈vars(P1) ∪vars(P2),
– Θ = {σ | dom(σ) = vars(P1) ∪vars(P2) ∧∀v ∈dom(σ). vσ ∈D},
– σ ∈Θ,
– P1σ ≈P2σ,
– ∀σ′ ∈Θ. diﬀerentP1,P2(σ, σ′) =⇒P1σ′ ̸≈P2σ′, where diﬀerentP1,P2(σ, σ′)
stands for: P1σ ̸≈P1σ′ ∨P2σ ̸≈P2σ′,
– ∀P ′ ∈TΣ(V ). P ′ ≈P1 =⇒vars(P ′) ⊇vars(P1) and
∀P ′ ∈TΣ(V ). P ′ ≈P2 =⇒vars(P ′) ⊇vars(P2).
The ﬁrst two axiomatic rules are straightforward: a set of patterns P entails
all patterns that are contained within it, and for any guessable value, a set
of patterns P entails a pattern representing an unveriﬁed guess of that value

A Formalization of Oﬀ-Line Guessing for Security Protocol Analysis
373
that has the whole of dictionary D as candidates. (Recall that we consider only
substitutions of variables with guesses in D.) The rule OP expresses how patterns
can be combined. Given n patterns entailed by P, the rule states that they can
be combined using an n-ary operator op ∈O yielding a pattern that is the
application of op on the constituent patterns.
As explained in the previous section, the standard Dolev-Yao intruder sys-
tem includes both synthesis rules for composing messages and analysis rules for
decomposing them; see, for example, [4,5,6]. Examples of the latter type are de-
cryption and the projection of a paired message into its two components. Using
the equational theory, however, one can express analysis steps of the intruder
as composition using decryption operators (and cancellation of encryption and
decryption with corresponding keys).
We now turn our attention to the veriﬁcation of guesses, rule VER. In gen-
eral, verifying a guess requires that the intruder can construct two maps that
correspond on exactly one entry (we discuss below how we formalize diﬀerent
substitutions, representing diﬀerent entries, modulo the algebraic properties).
Thus, there is one uniquely determined substitution of dictionary entries for the
variables in the two corresponding patterns which yields the same message. This
substitution corresponds to the correct guesses, and after verifying his guesses,
the intruder learns these correct values for the guesses in the classical sense.
Note that this simple deﬁnition avoids any notion of “diﬀerent ways to con-
struct the same message” as is often required in other formal approaches to
guessing. Rather, the deﬁnition implicitly prevents that the intruder can “cheat
himself”: suppose he tries to verify something by taking two copies of the same
map (which is not forbidden); then either the maps do not contain any vari-
ables (so there is nothing guessable to obtain) or the two maps correspond on
all substitutions.
To illustrate this further, let us consider the case where the intruder has
derived two patterns P1 and P2, and Θ is the set of all substitutions for the
variables of P1 and P2 with entries of the dictionary. If there is one substitution
σ ∈Θ on which the two patterns yield the same message, P1σ ≈P2σ, and
the patterns diﬀer for all diﬀerent substitutions, then the intruder has indeed
veriﬁed the correct value for any of the data that he has guessed in the two
patterns/maps. Thus, for any variable v ∈vars(P1)∪vars(P2) in the two patterns,
he can derive the correct value vσ.
Recall that we identify entries of a map and substitutions of variables with
guesses in the corresponding pattern. The notion of diﬀerent substitutions σ and
σ′ (in the sense that they represent diﬀerent entries) is not simply σ ̸= σ′ for
the following reason. A map may contain several diﬀerent entries that yield the
same value. Consider, for instance, an intruder model that extends our running
example Ie with an operator ⊕representing exclusive-or, which has, among
other properties, the property of being commutative. Assume further that the
intruder knows the message P1 = pw1 ⊕pw2 for two guessable but unknown
passwords pw1 and pw2. To ﬁnd out the passwords, the intruder constructs
the map P2 = v1 ⊕v2. The problem now is that for the two diﬀerent entries

374
P. Hankes Drielsma, S. M¨odersheim, and L. Vigan`o
σ = [v1 →pw1, v2 →pw2] and σ′ = [v1 →pw2, v2 →pw1] we have P2σ ≈P2σ′
due to the algebraic properties, and thus there are several entries on which the
two maps P1 and P2 correspond. Therefore, our notion of diﬀerent entries is
relative to two maps that we want to compare, and we thus consider those pairs
of substitutions σ and σ′ as being diﬀerent entries relative to the maps P1 and
P2 if they indeed make a diﬀerence in at least one of the maps, i.e. if P1σ ̸≈P1σ′
or if P2σ ̸≈P2σ′.
Finally, note that the last pair of side conditions of the rule VER ensures
that for the veriﬁcation the intruder uses only maps P1 and P2 that are not
equivalent to some map P ′ that comprises fewer variables. For instance, for our
example intruder model, the rule VER cannot be applied to the map {|{|m|}v|}v
as this map is equivalent by ≈e to the map m. In other words, this condition
expresses that we don’t consider maps with redundant variables, i.e. those on
which the outcome does not depend.
The formal model presented here only allows for derivations that are indeed
possible according to the intuition given in the previous section. On the other
hand, all operations the intruder could perform according to this intuition have
a counter-part in the formal model, since composition and decomposition of
messages with guesses is described by respective operations on maps/patterns,
and veriﬁcation of guesses is described by the comparison of maps/patterns.
But, of course, one can only informally justify that a formal model captures the
intuition underlying it.
Example 2. We illustrate with the examples from the previous section, using
our paradigmatic intruder model Ie = (Σe, Oe, ≈e, De). In the ﬁrst example, the
intruder knowledge consists of a set of patterns P that contains the messages
{|m|}pw and m, and pw ∈De is guessable. The intruder ﬁrst constructs the map
{|m|}v by encrypting m with every entry of the dictionary, and then compares it
with the original message {|m|}pw to verify his guess of pw. This comparison is
possible since there is exactly one entry in the dictionary that equals pw and no
other substitution for v that can make {|m|}pw and {|m|}v equal:
{|m|}pw ∈GDYIe(P) AXP
v ∈GDYIe(P) AXv
m ∈GDYIe(P) AXP
{|m|}v ∈GDYIe(P)
OP
pw ∈GDYIe(P)
VER
In the second example, the intruder knowledge P contains {|m2|}m1, but
neither m1 nor m2. Further, both m1 and m2 are guessable, i.e. m1, m2 ∈De.
The intruder ﬁrst encrypts every entry of the dictionary with every entry of
the dictionary to obtain the pattern {|v2|}v1, which he can then compare to
{|m2|}m1. Since again only the substitution with the correct guesses can make
the two terms equal, he obtains both m1 and m2 by this comparison. Simplifying
the presentation, we have joined the derivation of the two messages into one tree:

A Formalization of Oﬀ-Line Guessing for Security Protocol Analysis
375
1. A →S : A
2. S →A : Ns
3. A →S : Na, H(Pw, Na, Ns, A)
4. S →A : H(Pw, Na)
Fig. 2. The MS-CHAPv2 Protocol
{|m2|}m1 ∈GDYIe(P) AXP
v1 ∈GDYIe(P) AXv
v2 ∈GDYIe(P) AXv
{|v2|}v1 ∈GDYIe(P)
OP
m1, m2 ∈GDYIe(P)
VER
In the third example, the intruder knowledge P contains the messages m1 and
{|⟨m1, m2⟩|}pw, and pw is guessable. The intruder tries to decrypt this message
with every entry in his dictionary, obtaining the pattern {|{|⟨m1, m2⟩|}pw|}v, and
then builds the projection to the ﬁrst component for every entry, which yields
the pattern π1({|{|⟨m1, m2⟩|}pw|}v). He compares this pattern with the known
message m1 and only for the right guess v = pw the pattern yields this value,
so he obtains pw:
{|m2|}m1 ∈GDYIe(P) AXP
v1 ∈GDYIe(P) AXv
v2 ∈GDYIe(P) AXv
{|v2|}v1 ∈GDYIe(P)
OP
m1, m2 ∈GDYIe(P)
VER
□
4
A Concrete Example: The MS-CHAPv2 Protocol
As a concrete example, we consider an entire protocol, namely Microsoft’s Chal-
lenge/Response Authentication Protocol, version 2 (MS-CHAPv2 [21]). MS-
CHAPv2 is the authentication mechanism for the Point-to-Point Tunneling Pro-
tocol (PPTP [16]), which itself is used to secure PPP connections over TCP/IP.
It is well known that this protocol is vulnerable to oﬀ-line guessing attacks [20],
and we illustrate how one can easily detect this vulnerability using our approach.
Fig. 2 shows an abstracted version of the MS-CHAPv2 Protocol in the Alice&
Bob-style notation that is standard in the literature. Note that, for simplicity,
we refrain here from explicitly displaying the pairing operator and simply use
commas. The protocol should achieve mutual authentication between a client
A and server S based on an initially shared password Pw, which we of course
assume to be guessable.
As an illustrative case, let us consider the situation in which the intruder has
observed a single run of the protocol between two honest agents a (playing in

376
P. Hankes Drielsma, S. M¨odersheim, and L. Vigan`o
h(⟨pw, na⟩) ∈GDYIe(P) AXP
Π
h(⟨v, na⟩) ∈GDYIe(P)
pw ∈GDYIe(P)
VER
where Π is
h ∈GDYIe(P) AXP
v ∈GDYIe(P) AXv
na ∈GDYIe(P) AXP
⟨v, na⟩∈GDYIe(P)
OP
h(⟨v, na⟩) ∈GDYIe(P)
OP
Fig. 3. An example derivation using the deduction system of Section 3
the role A) and s (playing in the role S). Then the intruder has the following
knowledge (assuming that he knows the hash-function h):
P = {a, s, h, na, ns, h(pw, na, ns, a), h(pw, na)} .
Note that we have used lower-case letters to distinguish the concrete data of a
protocol run from the protocol variables. Fig. 3 shows that, from this knowledge,
the intruder can indeed derive pw, if it is guessable.
He simply generates a map for the hash-value of the message under all values
of his dictionary in place of pw, and compares the outcome with the observed
message. Note that a similar attack would have already been possible after ob-
serving only the ﬁrst three messages of the protocol, since the intruder can
similarly build the hash-value of message three under all guesses for the pass-
word. Note also that, as we remarked above, in our model we only investigate
whether a protocol is vulnerable to oﬀ-line guessing or not. Hence, if the users
choose good passwords that cannot be easily guessed, it might be infeasible to
exploit in practice the vulnerability of the MS-CHAPv2 Protocol that we have
just described.
To conclude the section, observe that all examples we have given in this paper
are examples of the intruder successfully attacking a protocol by oﬀ-line guessing.
However, even though we lack space to go into the details, we observe that we can
also use our formalization as the basis to prove the absence of vulnerabilities of a
protocol even under oﬀ-line guessing, both in model-checking approaches (where
we usually bound the number of sessions considered) or in theorem-proving ones
(where we can inductively show the correctness for all situations).
5
Related Work and Concluding Remarks
We have given a formalization of oﬀ-line guessing (in the context of the ide-
alized Dolev-Yao intruder model) which is based on the notion of using maps
to explicitly represent the intermediate computation steps of an intruder dur-
ing guessing. Our formalization is general and uniform in the sense that it is
independent of the overall protocol model and of the details of the considered

A Formalization of Oﬀ-Line Guessing for Security Protocol Analysis
377
intruder model, i.e. cryptographic primitives, algebraic properties, and intruder
capabilities. Moreover, it allows us to consider multiple guesses simultaneously.
Several other approaches have similarly considered extensions of the Dolev-
Yao model with additional intruder capabilities to model a notion of oﬀ-line
guessing, starting with the work of [17], which inspired [10,12] and was extended
in [18]. These ﬁrst approaches are somewhat limited (for instance [12,17] consider
only single guesses) and are thus helpful to ﬁnd protocol attacks, but are not
fully appropriate for providing a deﬁnition of oﬀ-line guessing and verifying that
a protocol is invulnerable to such guessing attacks.
The more advanced approach of [13] presents a theory of oﬀ-line guessing
that overcomes such limitations and also includes an analysis of its complexity
and a basis for an eﬃcient implementation using a symbolic intruder model.
Like previous approaches, it is, however, specialized to the standard Dolev-Yao
intruder under a free term algebra, and it is based on involved syntactic concepts
like normalized intruder derivations to ensure that the guessing extension is not
“too powerful” (in the sense that the intruder could derive almost everything
that is guessable). The approach of [11] is the closest to ours as it also employs
cancellation equations rather than explicit decryption rules. Moreover, like our
approach, it is not specialized to a particular intruder model, although it is based
on an explicit formalization of protocols using the applied pi calculus of [2] where
security properties are deﬁned using a notion of indistinguishability of processes.
In [1], the authors show that the intruder deduction problem in this formalism is
undecidable unless one imposes strong restrictions on the considered equational
theory, and we believe that similar properties hold also for our formalization. It
is however not easy, at least in our opinion, to estimate whether the approaches
of [11,13], as well as the previous ones, indeed faithfully formalize the notion
of oﬀ-line guessing, as it is not completely clear what notion they capture. In
essence, these works formally deﬁne derivation systems but give little intuition
about how their respective systems relate to a common-sense understanding of
oﬀ-line guessing.
We believe that one of the major contributions of our work is that it de-
scribes and formalizes such a common-sense intuition of oﬀ-line guessing in a
precise way and thus provides an appropriate bridge between the intuitions and
a formal model of them. A detailed investigation of our intuition led us to the
notion of maps on which our formalization is based. In fact, one might say that
maps provide a semantical basis for our rules as they make explicit the intermedi-
ate computations of an intruder during an oﬀ-line guessing attack. We therefore
believe that our formalization is not only uniform and more general, but also
conceptually simpler and easier to understand than previous approaches. Note,
however, that our approach is based on algebraic equations, and is thus more
diﬃcult to implement within a protocol analysis tool than the less expressive ap-
proaches. In this paper, we have placed the emphasis on the theoretical founda-
tions underlying our model of guessing, but we are currently working on how our
deduction system can be deployed in practice by integrating it into the symbolic
lazy intruder model that underlies our protocol model-checker OFMC [4,5,6].

378
P. Hankes Drielsma, S. M¨odersheim, and L. Vigan`o
We conclude by highlighting an open problem that our approach does not
address (and that is not mentioned in other works on oﬀ-line guessing): when
the intruder has veriﬁed a guess, for instance, of a password pw belonging to an
agent A, then the guessed value is added to his “classical” knowledge. He can
then use it, for example, to decrypt other messages. While this is exactly what
one might expect, a problem arises when another agent, say B, accidentally has
the same guessable password (in theory, there might be several such agents). In
this case, in verifying his guess of A’s password pw, the intruder has — quite
inadvertently — also learned B’s password. This problem arises if the intruder
did not initially know that there was any correlation between the two passwords.
This issue can easily be resolved in the case of passwords, as we can simply model
the passwords of diﬀerent agents by diﬀerent constants. However, it is not clear
how to proceed for other guessable data, like protocol key-words. This problem
is related with the question of how much the intruder knows about the format
of messages — and the relation of several constants in them. We leave a closer
investigation of these issues for future work.
Acknowledgments. We thank Penny Anderson and David Basin for many
inspiring discussions, and the anonymous referees for their helpful comments.
References
1. M. Abadi and V. Cortier. Deciding knowledge in security protocols under equa-
tional theories. In Proc. ICALP’04, LNCS 3142. Springer, 2004.
2. M. Abadi and C. Fournet. Mobile values, new names, and secure communication.
In Proc. POPL’01. ACM Press, 2004.
3. F. Baader and T. Nipkow. Term Rewriting and All That. Cambridge U. Pr., 1998.
4. D. Basin, S. M¨odersheim, and L. Vigan`o.
An On-The-Fly Model-Checker for
Security Protocol Analysis. In Proc. ESORICS’03, LNCS 2808. Springer, 2003.
5. D. Basin, S. M¨odersheim, and L. Vigan`o.
Constraint Diﬀerentiation: A New
Reduction Technique for Constraint-Based Analysis of Security Protocols.
In
Proc. CCS’03. ACM Press, 2003.
6. D. Basin, S. M¨odersheim, and L. Vigan`o. OFMC: A Symbolic Model-Checker for
Security Protocols. International Journal of Information Security. 2004.
7. M. Bellare, D. Pointcheval, and P. Rogaway. Authenticated key exchange secure
against dictionary attacks. In Proc. EUROCRYPT’00, LNCS 1807. Springer, 2000.
8. S. M. Bellovin and M. Merritt. Encrypted key exchange: Password-based protocols
secure against dictionary attacks.
In Proc. IEEE Symposium on Security and
Privacy 1992. IEEE Computer Society Press, 1992.
9. E. Bresson, O. Chevassut, and D. Pointcheval.
Security proofs for an eﬃcient
password-based key exchange. In Proc. CCS’03. ACM Press, 2003.
10. E. Cohen.
Proving cryptographic protocols safe from guessing attacks.
In
Proc. Foundations of Computer Security’02. 2002.
11. R. Corin, J. Doumen, and S. Etalle. Analysing password protocol security against
oﬀ-line dictionary attacks.
In Proc. WISP’04. Electronic Notes in Theoretical
Computer Science, 2004.

A Formalization of Oﬀ-Line Guessing for Security Protocol Analysis
379
12. R. Corin, S. Malladi, J. Alves-Foss, and S. Etalle. Guess what? Here is a new
tool that ﬁnds some new guessing attacks (extended abstract). In Proc. WITS’03.
Dip. Scienze dell’Informazione, Universit`a di Bologna, Italy, 2003.
13. S. Delaune and F. Jacquemard. A theory of guessing attacks and its complexity.
Research Report LSV-04-1, Lab. Speciﬁcation and Veriﬁcation, ENS de Cachan,
France, 2004.
14. D. Dolev and A. Yao. On the Security of Public-Key Protocols. IEEE Transactions
on Information Theory, 2(29), 1983.
15. L. Gong, T. M. A. Lomas, R. M. Needham, and J. H. Saltzer. Protecting poorly
chosen secrets from guessing attacks. IEEE Journal on Selected Areas in Commu-
nications, 11(5):648–656, 1993.
16. K. Hamzeh, G. Pall, W. Verthein, J. Taarud, W. Little, and G. Zorn. RFC 2637:
Point-to-Point Tunneling Protocol, July 1999. Status: Informational.
17. G. Lowe. Analysing Protocols Subject to Guessing Attacks. In Proc. WITS 2002.
18. G. Lowe. Analysing Protocols Subject to Guessing Attacks. Journal of Computer
Security, 12(1), 2004.
19. R. Morris and K. Thompson. Password security: A case history. Communications
of the ACM, 22(11):594, 1979.
20. B. Schneier, Mudge, and D. Wagner. Cryptanalysis of Microsoft’s PPTP authenti-
cation extensions (MS-CHAPv2). In Proc. CQRE’99, LNCS 1740, Springer, 1999.
21. G. Zorn.
RFC 2759: Microsoft PPP CHAP Extensions, Version 2, Jan. 2000.
Status: Informational.

Abstraction-Carrying Code
Elvira Albert1, Germ´an Puebla2, and Manuel Hermenegildo2,3
1 DSIP, Universidad Complutense Madrid
2 Facultad de Inform´atica, Technical University of Madrid
3 Depts. of Comp. Sci. and El. and Comp. Eng., U. of New Mexico
Abstract. Proof-Carrying Code (PCC) is a general approach to mo-
bile code safety in which programs are augmented with a certiﬁcate (or
proof). The practical uptake of PCC greatly depends on the existence
of a variety of enabling technologies which allow both to prove programs
correct and to replace a costly veriﬁcation process by an eﬃcient checking
procedure on the consumer side. In this work we propose Abstraction-
Carrying Code (ACC), a novel approach which uses abstract interpre-
tation as enabling technology. We argue that the large body of applica-
tions of abstract interpretation to program veriﬁcation is amenable to
the overall PCC scheme. In particular, we rely on an expressive class
of safety policies which can be deﬁned over diﬀerent abstract domains.
We use an abstraction (or abstract model) of the program computed by
standard static analyzers as a certiﬁcate. The validity of the abstrac-
tion on the consumer side is checked in a single-pass by a very eﬃcient
and specialized abstract-interpreter. We believe that ACC brings the
expressiveness, ﬂexibility and automation which is inherent in abstract
interpretation techniques to the area of mobile code safety. We have im-
plemented and benchmarked ACC within the Ciao system preprocessor.
The experimental results show that the checking phase is indeed faster
than the proof generation phase, and that the sizes of certiﬁcates are
reasonable.
1
Introduction
One of the most important challenges which computing research faces today
is the development of security techniques for verifying that the execution of a
program (possibly) supplied by an untrusted source is safe, i.e., it meets certain
properties according to a predeﬁned safety policy. Proof-Carrying Code (PCC)
[15] is an enabling technology for mobile code safety which proposes to asso-
ciate safety information in the form of a certiﬁcate to programs. The certiﬁcate
(or proof) is created at compile time, and packaged along with the untrusted
code. The consumer who receives or downloads the code+certiﬁcate package can
then run a checker which by a straightforward inspection of the code and the
certiﬁcate, can verify the validity of the certiﬁcate and thus compliance with
the safety policy. The key beneﬁt of this “certiﬁcate-based” approach to mobile
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 380–397, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

Abstraction-Carrying Code
381
code safety is that the consumer’s task is reduced from the level of proving to
the level of checking. Indeed the (proof) checker performs a task that should be
much simpler, eﬃcient, and automatic than generating the original certiﬁcate.
The practical uptake of PCC greatly depends on the existence of a variety
of enabling technologies which allow:
1. deﬁning expressive safety policies covering a wide range of properties,
2. solving the problem of how to automatically generate the certiﬁcates (i.e.,
automatically proving the programs correct), and
3. replacing a costly veriﬁcation process by an eﬃcient checking procedure on
the consumer side.
The main approaches applied up to now are based on theorem proving and type
analysis. For instance, in PCC the certiﬁcate is originally a proof in ﬁrst-order
logic of certain veriﬁcation conditions and the checking process involves ensuring
that the certiﬁcate is indeed a valid ﬁrst-order proof. In Typed Assembly Lan-
guages [13], the certiﬁcate is a type annotation of the assembly language program
and the checking process involves a form of type checking. Each of the diﬀerent
approaches possess their own set of stronger and weaker points. Depending on
the particular safety property and the available computing resources in the con-
sumer, some approaches are more suitable than others. In some cases the priority
is to reduce the size of the certiﬁcate as much as possible in order to ﬁt in small
devices or to cope with scarce network access (as in, e.g., Oracle-based PCC [17]
or Tactic-based PCC [1]), whereas in other cases the priority is to reduce the
checking time (as in, e.g., standard PCC [15] or lightweight bytecode veriﬁcation
[11]). As a result of all this, a successful certiﬁcate infrastructure should have a
wide set of enabling technologies available for the diﬀerent requirements.
In this work we propose Abstraction-Carrying Code (ACC), a novel approach
which uses abstract interpretation [5] as enabling technology to handle the above
practical (and diﬃcult) challenges. Abstract interpretation is now a well es-
tablished technique which has allowed the development of very sophisticated
global static program analyses that are at the same time automatic, provably
correct, and practical. The basic idea of abstract interpretation is to infer in-
formation on programs by interpreting (“running”) them using abstract values
rather than concrete ones, thus obtaining safe approximations of the behavior
of the program. The technique allows inferring much richer information than,
for example, traditional types. This includes data structure shape (with pointer
sharing), bounds on data structure sizes, and other operational variable instan-
tiation properties, as well as procedure-level properties such as determinacy,
termination, non-failure, and bounds on resource consumption (time or space
cost).
Our proposal, ACC, opens the door to the applicability of the above
domains as enabling technology for PCC. In particular, ACC has the following
three fundamental elements:
1. An expressive class of safety policies based on “abstract”—i.e. symbolic—
properties over diﬀerent abstract domains. Our framework is parametric
w.r.t. the abstract domain(s) of interest, which gives us generality and ex-
pressiveness.

382
E. Albert, G. Puebla, and M. Hermenegildo
2. A ﬁxpoint static analyzer is used to automatically infer an abstract model
(or simply abstraction) about the mobile code which can then be used to
prove that the code is safe w.r.t. the given policy in a straightforward way.
We identify the particular subset of the analysis results which is suﬃcient
for this purpose.
3. A simple, easy-to-trust (analysis) checker veriﬁes the validity of the infor-
mation on the mobile code. It is indeed a specialized abstract interpreter
whose key characteristic is that it does not need to iterate in order to reach
a ﬁxpoint (in contrast to standard analyzers).
While ACC is a general approach, for concreteness we develop herein an incarna-
tion of it in the context of (Constraint) Logic Programming, (C)LP, because this
paradigm oﬀers a good number of advantages, an important one being the matu-
rity and sophistication of the analysis tools available for it. Also for concreteness,
we build on the algorithms of (and report on an implementation on) CiaoPP [8],
the abstract interpretation-based preprocessor of the Ciao multi-paradigm (Con-
straint) Logic Programming system. CiaoPP uses modular, incremental abstract
interpretation as a fundamental tool to obtain information about programs. The
semantic approximations thus produced have been applied to perform high- and
low-level optimizations during program compilation, including transformations
such as multiple abstract specialization, parallelization, resource usage control,
and program veriﬁcation. We report on our extension of the framework to in-
corporate ACC and on how this instantiation of ACC already shows promising
results.
2
An Assertion Language to Specify the Safety Policy
The purpose of a safety policy is to specify precisely the conditions under which
the execution of a program is considered safe. We propose the use of (a subset of)
the high-level assertion language [18] available in CiaoPP to deﬁne an expressive
class of safety policies in the context of constraint logic programs.
2.1
Preliminaries and Notation
We assume familiarity with constraint logic programming [10] (CLP) and the
concepts of abstract interpretation [5] which underlie most analyses in CLP.
The remaining of this section introduces some notation and recalls preliminary
concepts on these topics.
Terms are constructed from variables (e.g., X), functors (e.g., f) and pred-
icates (e.g., p). We denote by {X1 →t1, . . . , Xn →tn} the substitution σ with
σ(Xi) = ti for all i = 1, . . . , n (with Xi ̸= Xj if i ̸= j) and σ(X) = X for any
other variable X, where ti are terms. A renaming is a substitution ρ for which
there exists the inverse ρ−1 such that ρρ−1 ≡ρ−1ρ ≡id. We say that a renaming
ρ is a renaming substitution of term t1 w.r.t. term t2 if t2 = ρ(t1).
A constraint is essentially a conjunction of expressions built from predeﬁned
predicates. An atom has the form p(t1, ..., tn) where p is a predicate symbol and

Abstraction-Carrying Code
383
the ti are terms. A literal is either an atom or a constraint. A goal is a ﬁnite
sequence of literals. A rule is of the form H:-B where H, the head, is an atom
and B, the body, is a possibly empty ﬁnite sequence of literals. A CLP program,
or program, is a ﬁnite set of rules.
Example 1. The main predicate, create streams/2, of the following CLP pro-
gram receives a list of numbers which correspond to certain ﬁle names, and
returns in the second argument the list of ﬁle handlers (streams) associated to
the (opened) ﬁles:
create_streams([],[]).
create_streams([N|NL],[F|FL]):-
number_codes(N,ChInN), app("/tmp/",ChInN,Fname),
safe_open(Fname,write,F), create_streams(NL,FL).
safe_open(Fname,Mode,Stream):-
atom_codes(File,Fname), open(File,Mode,Stream).
The call number codes(N,ChInN) receives the number N and returns in ChInN
the list of the ASCII codes of the characters comprising a representation of
N. Then, it uses the well-known list concatenation predicate app/3. The call
atom codes(File,Fname) receives in Fname a list of ASCII codes and returns
the atom File made up of the corresponding characters. Also, a call such as
open(File,Mode,Stream) opens the ﬁle named File and returns in Stream the
stream associated with the ﬁle. The argument Mode can have any of the values:
read, write, or append.4
A distinguishing feature of our approach is that a class of safety policies can be
deﬁned for the diﬀerent abstract domains available in the system. In particular,
safety properties are expressed as substitutions in the context of an abstract
domain (Dα) which is simpler than the selected concrete domain (D). An ab-
stract value is a ﬁnite representation of a, possibly inﬁnite, set of actual values
in the concrete domain. Our approach relies on the abstract interpretation the-
ory [5], where the set of all possible abstract semantic values which represents
Dα is usually a complete lattice or cpo which is ascending chain ﬁnite. How-
ever, for this study, abstract interpretation is restricted to complete lattices over
sets, both for the concrete ⟨2D, ⊆⟩and abstract ⟨Dα, ⊑⟩domains. Abstract val-
ues and sets of concrete values are related via a pair of monotonic mappings
⟨α, γ⟩: abstraction α : 2D →Dα, and concretization γ : Dα →2D, such that
∀x ∈2D : γ(α(x)) ⊇x
and
∀y ∈Dα : α(γ(y)) = y. In general ⊑is induced
by ⊆and α. Similarly, the operations of least upper bound (⊔) and greatest lower
bound (⊓) mimic those of 2D in a precise sense. In this framework an abstract
property is deﬁned as an abstract substitution which allows us to express prop-
erties, in terms of an abstract domain, that the execution of a program must
satisfy. The description domain we use in our examples is the following regular
type domain [6].
4 Predicates number codes/2, atom codes/2, and open/3 are ISO-standard Prolog
predicates, and thus they are available in CiaoPP.

384
E. Albert, G. Puebla, and M. Hermenegildo
Example 2 ( regular type domain). We refer to the regular type domain as eterms,
since it is the name it has in CiaoPP. Abstract substitutions in eterms [21],
over a set of variables V , assign a regular type to each variable in V . We use
in our examples term as the most general type (i.e., term ≡⊤corresponds
to all possible terms). We also allow parametric types such as list(T) which
denotes lists whose elements are all of type T. Type list is clearly equivalent
to list(term). Also, list(T) ⊑list ⊑term for any type T. The least general
substitution ⊥assigns the empty set of values to each variable.5
Apart from predeﬁned types, in the eterms domain, one can have user-deﬁned
regular types declared by means of Regular Unary Logic programs [7]. For in-
stance, in the context of mobile code, it is a safety issue whether the code tries
to access ﬁles which are not related to the application in the machine consuming
the code. A very simple safety policy can be to enforce that the mobile code
only accesses temporary ﬁles. In a UNIX system this can be controlled (under
some assumptions) by ensuring that the ﬁle resides in the directory /tmp/. The
following regular type safe name deﬁnes this notion of safety:6
:-
regtype
safe_name/1.
safe_name("/tmp/"||L) :- list(L,alphanum_code).
:-
regtype
alphanum_code/1.
alphanum_code(X):- member(X,"abcdefghijklmnopqrstuvwzyz").
alphanum_code(X):- member(X,"ABCDEFGHIJKLMNOPQRSTUVWXYZ").
alphanum_code(X):- member(X,"0123456789").
The abstract property made up of substitution {X→safe name} expresses that
X is bound to a string which starts by the preﬁx “/tmp/” followed by a list of
alpha-numerical characters. In the following, we write simply safe name(X) to
represent it.
2.2
The Safety Policy
Assertions are syntactic objects which allow expressing a wide variety of high-
level properties of (in our case CLP-) programs. Examples are assertions which
state information on entry points to a program module, assertions which de-
scribe properties of built-ins, assertions which provide some type declarations,
cost bounds, etc. The original assertion language [18] available in CiaoPP is com-
posed of several assertion schemes. Among them, we simply consider the two
following schemes for the purpose of this paper, which intuitively correspond to
the traditional pre- and postcondition on procedures.
5 Let us note that certain abstract domains assign a diﬀerent meaning to ⊥. In these
cases, a distinguished symbol (i.e., an extra ⊥) can always be added to represent
unreachable points.
6 The regtype declarations are used to deﬁne new regular types in CiaoPP.

Abstraction-Carrying Code
385
calls(B, {λ1
P re; . . . ; λn
P re}): They express properties which should hold in any
call to a given predicate similarly to the traditional precondition. B is a
predicate descriptor, i.e., it has a predicate symbol as main functor and all
arguments are distinct free variables, and λi
P re, i = 1, . . . , n, are abstract
properties about execution states. The resulting assertion should be inter-
preted as “in all activations of B at least one property λi
P re should hold in
the calling state.”
success(B, [λP re, ]λP ost): This assertion schema is used to describe a postcon-
dition which must hold on all success states for a given predicate. B is a
predicate descriptor, and λP re and λP ost are abstract properties about ex-
ecution states. λP re is optional and must be evaluated w.r.t. the store at
the calling state to the predicate while condition λP ost is evaluated at the
success state. If the optional λP re is present, then λP ost is only required to
hold in those success states which correspond to call states satisfying λP re.
Note that several success assertions with diﬀerent λP re may be given.
Therefore, abstract properties λP re and λP ost in assertions allow us to express
conditions, in terms of an abstract domain, that the execution of a program must
satisfy. Each condition is an abstract substitution corresponding to the variables
in some atom. In existing approaches, safety policies usually correspond to some
variants of type safety (which may also control the correct access of memory
or array bounds [16]). In our system, the (co-)existence of several domains al-
lows expressing a wider range of properties using the assertion language. They
include a wide class of safety policies based on modes, types, non-failure, ter-
mination, determinacy, non-suspension, non-ﬂoundering, cost bounds, and their
combinations.
In the CiaoPP preprocessor, the assertion language allows us to deﬁne the
safety policy for the run-time system in the presence of foreign functions, built-
ins, etc. In general, it is the task of the compiler designer to deﬁne the safety
policies associated to the predeﬁned system predicates. In addition to these
assertions, the user can optionally provide further assertions manually for user-
deﬁned predicates.
Example 3. The following assertion for predicate safe open:
calls(safe open(Fname, , ), {safe name(Fname)})
provides a simple way to guarantee that all calls to open are safe. It can be read as
“the calling conventions for predicate safe open require that the ﬁrst argument
be a safe name”. Meanwhile the following assertion for open is predeﬁned in our
system:
success(open(X,Y,Z), ⊤, {constant(X),io mode(Y),stream(Z)})
It requires, upon success, the ﬁrst variable to be of type constant, the second
a proper io mode and the last one of type stream.
In contrast to traditional approaches, assertions are not compulsory for every
predicate. Thus, the user can decide how much eﬀort to put into writing as-
sertions: the more of them there are, the more complete the partial correctness
of the program is described and more possibilities to detect problems. Indeed,

386
E. Albert, G. Puebla, and M. Hermenegildo
pre- and post-conditions are frequently provided by programmers since they are
often easy to write and very useful for generating program documentation. Nev-
ertheless, the analysis algorithm is able to obtain safe approximations of the
program behavior even if no assertions are given. This is not always the case in
other approaches such as classical program veriﬁcation, in which loop invariants
are actually required. Such invariants are hard to ﬁnd and existing automated
techniques are generally not suﬃcient to infer them, so that often they have to
be provided by hand.
3
Certifying Programs by Static Analysis
Fig. 1 presents an overview of ACC as performed in the CiaoPP system. This
section introduces the certiﬁcation process (sketched to the left of the ﬁgure)
carried out by the producer, i.e., the generation of a certiﬁcate to attest the
adherence of the program to the safety policy. The whole certiﬁcation method is
based on the following idea: an abstraction of the program computed by abstract
interpretation-based analyzers can play the role of certiﬁcate for attesting pro-
gram safety. Our certiﬁcation process is carried out in the following phases. We
start from an initial program P. Firstly, the Safety Policy is deﬁned by means of
a set of assertions AS in the context of an abstract domain Dα, as introduced in
Sect. 2, among a repertoire of Domains available in the system. Secondly, a stan-
dard Analyzer is run, which returns an abstraction of P’s execution in terms of
the abstract domain Dα. Let us note that the analyzer is domain–independent.
This allows plugging in diﬀerent abstract Domains provided suitable interfacing
functions are deﬁned. From the user point of view, it is suﬃcient to specify the
particular abstract domain desired during the generation of the safety assertions.
Then, a veriﬁcation condition generator, VCGen extracts, from the initial asser-
tions and the abstraction, a Veriﬁcation Condition (VC) which can be proved
only if the execution of the code does not violate the safety policy. If VC can
be proved (marked as OK in Fig. 1), then the certiﬁcate (i.e., the abstraction)
is sent together with the program P to the code consumer. Sections 3.1 and 3.2
give further details on the Abstraction and the VCGen process, respectively.
3.1
Using Analysis Results as Certiﬁcates
A key idea in our certiﬁcation process is that the certiﬁcate is automatically
generated by an abstract interpretation-based analyzer (or simply static ana-
lyzer). In particular, the goal dependent (a.k.a. goal oriented) analyzer of [9],
which is the one implemented in the CiaoPP system, plays the role of Analyzer.
This analysis algorithm (we simply write Analysis for short in the following)
receives as input, in addition to the program P and the abstract domain Dα, a
set of calling patterns CP. A calling pattern is a description of the calling modes
(or entries) into the program. For simplicity, we assume that P comes enhanced
with its entries CP. In particular, a set of calling patterns Q consists of a set
of pairs of the form ⟨A : CP⟩where A is a predicate descriptor and CP is an

Abstraction-Carrying Code
387
Domain
Domain
OK
OK
OK
Program
Checker
VCGen
VCGen
Abstraction
Analyzer
Safety Policy
Safety Policy
PRODUCER 
CONSUMER 
Fig. 1. Abstraction-Carrying Code in CiaoPP
abstract substitution (i.e., a condition of the run-time bindings) of A expressed
as CP ∈Dα. In principle, calling patterns are only required for exported pred-
icates. The analysis algorithm is able to generate them automatically for the
remaining internal predicates. Nevertheless, they can still be automatically gen-
erated by assuming ⊤(i.e., no initial data) for all exported predicates (although
the idea is to improve this information in the initial calling patterns).
In order to compute Analysis(P, Q, Dα), traditional (goal dependent) ab-
stract interpreters for (C)LP programs construct an and–or graph (or analysis
graph) which corresponds to (or approximates) the abstract semantics of the
program [2]. The graph has two sorts of nodes: or–nodes and and–nodes. Or–
nodes correspond to literals whilst and–nodes to rules. Both kinds of nodes are
interleaved in the graph and connected as follows. An or–node has arcs to those
and–nodes which correspond to the rules whose head uniﬁes with the literal
it represents. An and–node for a rule H :– B1, . . . , Bn has n arcs to the or–
nodes which corresponds to the literals Bi in the body of the rule. Due to space
limitations, and given that it is now well understood, we do not describe here
algorithm Analysis(P, Q, Dα) (details can be found in, e.g., [9]). Nevertheless,
the checking algorithm of Sect. 4 illustrates how an and–or graph is traversed.
The analysis graph computed by CiaoPP’s analyzer represents an abstract
model (or abstraction) of the program. It is represented by means of two data
structures in the output: the answer table and the arc dependency table. The
following deﬁnition introduces the notion of analysis table (similar deﬁnitions
can be found, e.g., in [2,9]). Informally, it says that its entries are of the form
⟨A : CP →AP⟩which should be interpreted as “the answer pattern for calls to
A satisfying precondition (or call substitution), CP, accomplishes postcondition
(or success substitution), AP.”
Deﬁnition 1 (AT – analysis answer table). Let P be a program. Let Q
be a set of calling patterns expressed in the abstract domain Dα. We deﬁne an
analysis answer table, AT, as the set of entries ⟨Aj : CPj →APj⟩, ∀j = 1..n

388
E. Albert, G. Puebla, and M. Hermenegildo
computed by Analysis(P, Q, Dα)[9] where, in each entry, Aj is an atom and CPj
and APj are, respectively, the abstract call and success substitutions.
Intuitively, the answer table contains the answer patterns for all literals in the
or–nodes of the graph while the arc dependency table keeps detailed information
about dependencies among or–nodes in the graph. A central idea in this work
is that, for certifying program safety, it suﬃces to send the information stored
in the analysis answer table. In contrast to the original generic algorithm [9], a
simple analysis checker can be designed for validating the answer table without
requiring the use of the arc dependency table at all (as we show in Sect. 4).
The theory of abstract interpretation guarantees that the answer table is a safe
approximation of the runtime behavior (see [2,9] for details).
Example 4. Take the
calling pattern ⟨create streams(X, Y), {list(X, num)}⟩,
which indicates that calls to create streams are performed with a list of num-
bers in the ﬁrst argument. The answer table computed by CiaoPP contains
(among others) these entries:
⟨create streams(A, B) : {list(A, num)} →{list(A, num), list(B, stream)}⟩
⟨safe open(A, B, C) : {sf(A), B = write} →{sf(A), B = write, stream(B)}⟩
The ﬁrst entry should be interpreted as: all calls to predicate create streams
provide as input a list of numbers in the ﬁrst argument and, upon success, they
yield lists of numbers and streams, respectively, in each of its two arguments. In
the second entry, it is interesting to note that CiaoPP creates the auxiliary type:
sf("/tmp/"||A):-list(A,numcodes).
to represent lists of numbers starting by the preﬁx "/tmp/". We use the notation
B = write to denote that the system generates a new type for B whose only
element is constant write.
In order to increase accuracy, analyzers are usually multivariant on calls (see, e.g.,
[9]). Indeed, though not visible in this example, CiaoPP incorporates a multivari-
ant analysis, i.e., more than one triple ⟨A : CP1 →AP1⟩,. . ., ⟨A : CPn →APn⟩
n > 1 with CPi ̸= APi for some i, j may be computed for the same predicate
descriptor A.
It is important to note that our approach would work directly in other pro-
gramming paradigms, such as imperative or functional programming (the latter
already covered in our current system), as long as a static analyzer/checker is
available. Note that the fundamental components of the approach (ﬁxpoint se-
mantics and abstract interpretation) have both been widely applied also in these
paradigms.
3.2
The Veriﬁcation Condition
In the next step, the veriﬁcation condition generator (VCGen in Fig. 1) extracts,
from the initial assertions and answer table, a Veriﬁcation Condition (VC) which
can be proved only if the execution of the code does not violate the safety policy.

Abstraction-Carrying Code
389
Deﬁnition 2 (VC – veriﬁcation condition). Let AT be an analysis answer
table computed for a program P and a set of calling patterns Q in the abstract
domain Dα. Let S be an assertion. Then, the veriﬁcation condition, V C(S, AT),
for S w.r.t. AT is deﬁned as follows:
V C(S, AT) ::=
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩

⟨A:CP →AP ⟩∈AT
(ρ(CP) ⊑λ1
P rec ∨. . . ∨ρ(CP) ⊑λn
P rec)
if S = calls(B, {λ1
P rec; . . . ; λn
P rec})

⟨A:CP →AP ⟩∈AT
ρ(CP) ⊓λP rec = ⊥∨ρ(AP) ⊑λP ost
if S = success(B, λP rec, λP ost)
where ρ is a variable renaming substitution of A w.r.t. B.
If AS is a ﬁnite set of assertions, then its veriﬁcation condition, V (AS, AT),
is the conjunction of the veriﬁcation conditions of the elements of AS.
Roughly speaking, the VC generated according to Def. 2 is a conjunction of
boolean expressions (possibly containing disjunctions) whose validity ensures the
consistency of a set of assertions w.r.t. the answer table computed by Analysis.
It distinguishes two diﬀerent cases depending on the kind of assertion. For calls
assertions, the VC requires that at least one precondition λi
P rec be a safe ap-
proximation of all existing abstract calling patterns for the atom B. In the case
of success assertions, there are two cases for them to hold. The ﬁrst one indi-
cates that the precondition is never satisﬁed and, thus, the assertion trivially
holds (and the postcondition does not need to be tested). The second corre-
sponds to the case in which the success substitutions computed by analysis for
the predicate are more particular than the one required by the assertion.
Example 5. Consider the entry for predicate safe open in the answer table of
Ex. 4 and the calls assertion of Ex. 3 for the same predicate. According to
Def. 2, the VC is: B = write, sf(X) ⊑safe name(X) whose validity can be easily
proved in our system since sf ⊑safe name. This allows CiaoPP to infer that
calls to open performed within this program satisfy the simple safety policy
discussed in Ex. 1. The complete example includes further assertions for the
diﬀerent predicates and its corresponding VCs. We do not include them here
due to space limitations.
Therefore, upon creating the answer table and generating the VC, the validity
of the whole boolean condition is checked by resolving each conjunct separately.
Note that each conjunct consists of comparisons of pairs of abstract substitu-
tions, which simply return either true or false but do not compute any substi-
tution. This validation may yield three diﬀerent possible status: i) the VC is
indeed checked and the AT is considered a valid abstraction (marked as OK),
ii) it is disproved, and thus the certiﬁcate is not valid and the code is deﬁnitely
not safe to run (we should obviously correct the program before continuing the
process); iii) it cannot be proved nor disproved. The latter case happens because
some properties are undecidable and the analyzer performs approximations in

390
E. Albert, G. Puebla, and M. Hermenegildo
order to always terminate. Therefore, it may not be able to infer precise enough
information to verify the conditions. The user can then provide a more reﬁned
description of initial calling patterns or choose a diﬀerent, ﬁner-grained, domain.
Although, it is not shown in the picture, in both the ii) and iii) cases, the certi-
ﬁcation process needs to be restarted until achieving a VC which meets i).
The following theorem states the soundness of the VC. Intuitively, it amounts
to saying that if the VC holds, then the execution of the program will preserve
all safety assertions. Following the notation of [15], we write ▷V C when V C is
valid.
Theorem 1 (Soundness of the Veriﬁcation Condition). Let AT be an
analysis answer table for a program P and a set of calling patterns Q in an
abstract domain Dα (as deﬁned in Def. 1). Let AS be a set of assertions. Let
V C(AS, AT) be the veriﬁcation condition for AS w.r.t. AT (generated as stated
in Def. 2). If ▷V C(AS, AT), then P satisﬁes all assertions in AS for all com-
putations described by Q.
This result derives from the fact that the static analysis algorithm of [9] computes
a safe approximation of the stores reached during computation.
4
Checking Safety in the Consumer
The checking process performed by the consumer is illustrated in the right hand
side of Fig. 1. Initially, the supplier sends the program P together with the
certiﬁcate to the consumer. To retain the safety guarantees, the consumer can
provide a new set of assertions which specify the Safety Policy required by this
particular consumer. It should be noted that ACC is very ﬂexible in that it allows
diﬀerent implementations on the way the safety policy is provided. Clearly, the
same assertions AS used by the producer can be sent to the consumer. But,
more interestingly, the consumer can decide to impose a weaker safety condition
which can still be proved with the submitted abstraction. Also, the imposed
safety condition can be stronger and it may not be proved if it is not implied by
the current abstraction (which means that the code would be rejected). From the
provided assertions, the consumer must generate again a trustworthy VC and
use the incoming certiﬁcate to eﬃciently check that the VC holds. Thus, in the
validation process, a code consumer not only checks the validity of the answer
table but it also (re-)generates a trustworthy VC. The re-generation of V C (and
its corresponding validation) is identical to the process already discussed in the
previous section. Therefore, this section describes only the former part of the
validation process, i.e., algorithm check.
Although global analysis is now routinely used as a practical tool, it is still un-
acceptable to run the whole Analysis to validate the certiﬁcate since it involves
considerable cost. One of the main reasons is that the analysis algorithm is an it-
erative process which often computes answers (repeatedly) for the same call due
to possible updates introduced by further computations. At each iteration, the

Abstraction-Carrying Code
391
algorithm has to manipulate rather complex data structures—which involve per-
forming updates, lookups, etc.—until the ﬁxpoint is reached. The whole valida-
tion process is centered around the following observation: the checking algorithm
can be deﬁned as a very simpliﬁed “one-pass” analyzer. The computation of the
Analysis algorithm can be understood as: Analysis = fixpoint(analysis step).
I.e., a process which repeatedly performs a traversal of the analysis graph (de-
noted by analysis step) until the computed information does not change. The
idea is that the simple, non-iterative, analysis step process can play the role
of abstract interpretation-based checker (or simply analysis checker). In other
words, check ≡analysis step. Intuitively, since the certiﬁcation process already
provides the ﬁxpoint result as certiﬁcate, an additional analysis pass over it can-
not change the result. Thus, as long as the answer table is valid, one single
execution of analysis step validates the certiﬁcate.
The next deﬁnition presents our abstract interpretation-based checking al-
gorithm. It receives as an additional input a Certiﬁcate (which is the analysis
ﬁxpoint). In a single traversal, it constructs a program analysis graph by using
the information in Certiﬁcate. The algorithm is devised as a graph traversal pro-
cedure which places entries in a local answer table, AT, as new nodes in the
program analysis graph are encountered. Thus, it handles two distinct answer
tables: the local AT + the incoming Certiﬁcate. The ﬁnal goal of the checking is
to reconstruct the analysis graph and compare the results with the information
stored in Certiﬁcate. As long as Certiﬁcate is valid, both results coincide and,
thus, the certiﬁcate is guaranteed to be valid w.r.t. the program.
Deﬁnition 3 (Analysis Checker). Let P be a normalized7 program and Q be
a set of calling patterns in the abstract domain Dα. Let Certiﬁcate be a safety
certiﬁcate as deﬁned in Def. 1. The validation of Certiﬁcate is performed by the
procedure check depicted in Figure 2. The algorithm uses a local answer table,
AT, to compute the results (initially it does not contain any entry). Procedure
check is deﬁned in terms of ﬁve abstract operations [9] on the description domain
Dα of interest:
– Arestrict(CP, V) performs the abstract restriction of a description CP to the
set of variables in the set V , denoted vars(V );
– Aextend(CP, V) extends the description CP to the variables in the set V ;
– Aadd(C, CP) performs the abstract operation of conjoining the actual con-
straint C with the description CP;
– Aconj(CP1, CP2) performs the abstract conjunction of two descriptions;
– Alub(CP1, CP2) performs the abstract disjunction of two descriptions.
Following the presentation of Analysis [9], we assume that the program
P and the answer table are global parameters throughout the algorithm. The
checking algorithm proceeds as follows. For each calling pattern in the set Q,
the procedure process node inspects all rules deﬁning the considered atom. For
7 For clarity of presentation, in the algorithm we assume that all rule heads are normal-
ized, i.e., H is of the form p(X1, ..., Xn) where X1, ..., Xn are distinct free variables.

392
E. Albert, G. Puebla, and M. Hermenegildo
check(Q, Certiﬁcate)
foreach A : CP ∈Q
process node(A : CP, Certiﬁcate)
return Valid
process node(A : CP, Certiﬁcate)
if (∃a renaming σ s.t. σ(A : CP →AP) in Certiﬁcate)
then add (A : CP →AP) to AT
else return Error
foreach rule Ak ←Bk,1, . . . , Bk,nk in P
W := vars(Ak, Bk,1, . . . , Bk,nk)
CPb :=Aextend(CP, vars(Bk,1, . . . , Bk,nk))
CPRb := Arestrict(CPb, Bk,1)
foreach Bk,i in the rule body i = 1, ..., nk
CPa := process arc(Bk,i : CPRb, CPb, W, Certiﬁcate)
if (i <> nk) then CPRa := Arestrict(CPa, var(Bk,i+1))
CPb := CPa
CPRb := CPRa
AP1 := Arestrict(CPa, vars(Ak))
AP2 := Alub(AP1, σ−1(AP))
if AP <> AP2 then return Error
process arc(Bk,i : CPRb, CPb, W, Certiﬁcate)
if Bk,i is a constraint then CPa := Aadd (Bk,i, CPb)
elseif (̸ ∃a renaming σ s.t. σ(Bk,i : CPRb →AP ′) in AT)
then process node (Bk,i : CPRb, Certiﬁcate)
AP1 := Aextend (ρ−1(AP), W) where ρ is a renaming s.t.
ρ(Bk,i : CPRb →AP) in AT
CPa := Aconj (CPb, AP1)
return CPa
Fig. 2. Abstract Interpretation-based Checking in CiaoPP
each rule, it performs a left-to-right traversal of the atoms in the rule body.
The processing of each atom Bk,i in the rule body is handled by process arc.
We refer by CPb to the description of the program point immediately before the
atom Bk,i and by CPa to the description after processing the atom. Initially,
the description CPb takes the value of the initial description CP for the calling
pattern A : CP (extended to all the variables in the rule).8 We use variables
CPRx to denote that description CPx has been restricted, with x ∈{a, b}. The
procedure process arc is aimed at computing the resulting description CPa after
processing a given atom Bk,i. It distinguishes two diﬀerent cases:
– Constraints are simply abstractly added to the current description.
8 Further insights on the operations on abstract substitutions (like extensions, restric-
tions, disjunctions etc.) can be found in [2].

Abstraction-Carrying Code
393
– If Bk,i is an atom, then it inspects whether it has been processed before:
• If the atom already has an entry in the answer table, we do not need to
recompute it. Indeed, this could risk the termination of the algorithm.
• Otherwise, we process it by executing procedure process node. On return,
and in the absence of errors, this processing will have placed an answer
for Bk,i in the answer table (and possibly for other related atoms as
well).
Either way, there will be an answer for the atom at this point. This answer
is conjoined8 with the description CPb from the program point immediately
before Bk,i in order to obtain the description for the program point after it.
The computed result is used to process the next literal in the rule when Bk,i
is not the last literal. Otherwise, the computed result constitutes indeed the
computed answer for the rule. The answer is combined8 with the corresponding
answer supplied by the certiﬁcation process in Certiﬁcate. If Certiﬁcate is valid,
the comparison should hold; otherwise the process prompts an error and the
program is not safe to run.
The following theorem ensures that algorithm check is able to validate safety
certiﬁcates which are stored in a valid analysis answer table.
Theorem 2 (partial correctness). Let P be a program, let Q be a set of
calling patterns in an abstract domain Dα. Let Certiﬁcate be a safety certiﬁcate
for P and Q as stated in Def. 1. Then, check(Q, Certiﬁcate) terminates and
validates Certiﬁcate in P.
The theorem can be demonstrated by showing that check is a simpliﬁed version of
Analysis [9] in two main aspects.
Regarding the eﬃciency, our point to justify
an eﬃcient behavior of check for validating an answer table is that it performs a
single graph traversal. Indeed, for a regular type domain, [4] demonstrates that
directional type-checking for logic programs is ﬁxed-parameter linear. The next
section reports experimental evidence of eﬃciency issues.
5
Experimental Results
In this section we show some experimental results aimed at studying two crucial
points for the practicality of our proposal: the checking time as compared to
the analysis time, and the size of certiﬁcates. We have implemented the checker
as a simpliﬁcation of the generic abstract interpretation system of CiaoPP. It
should be noted that this is an eﬃcient, highly optimized, state-of-the-art anal-
ysis system and which is part of a working compiler. Both the analysis and
checker are parametric w.r.t. the abstract domain. In these experiments they
both use the same implementation of the domain-dependent functions of the
sharing+freeness domain [14]. We have selected this domain because the infor-
mation it infers is very useful for reasoning about instantiation errors, which is a
crucial aspect for the safety of logic programs. The whole system is implemented
in Ciao 1.11#200 [3] with compilation to bytecode. All of our experiments have

394
E. Albert, G. Puebla, and M. Hermenegildo
Table 1. Checking Time and Certiﬁcate Size
Analysis
Checking
Speedup
Source Byte Code Certiﬁcate
Bench
PA
An
TA PC Ch TC A/C TA/TC Source ByteC B/S
Cert C/S
aiakl
2
87
89
2
71
72
1.2
1.2
1555
3805
2.4
3090
2.0
ann
22
452
474
18 254 272
1.8
1.7
12745
43884
3.4 24475
1.9
bid
4
56
60
4
35
38
1.6
1.6
4945
10376
2.1
5939
1.2
boyer
9
143
151
7
85
92
1.7
1.6
11010
32522
3.0 12300
1.1
browse
3
14
17
3
12
15
1.2
1.2
2589
8467
3.3
1661
0.6
deriv
2
86
88
1
19
20
4.6
4.4
957
4221
4.4
288
0.3
grammar
2
10
12
2
9
11
1.1
1.1
1598
3182
2.0
1259
0.8
hanoiapp
2
25
26
2
16
18
1.5
1.5
1172
2264
1.9
2325
2.0
mmatrix
1
13
14
1
10
11
1.3
1.3
557
1053
1.9
880
1.6
occur
2
16
18
2
10
12
1.7
1.6
1367
6903
5.0
1098
0.8
progeom
2
13
15
2
9
11
1.5
1.4
1619
3570
2.2
2148
1.3
read
9
792
801
8 488 497
1.6
1.6
11843
24619
2.1 25359
2.1
qplan
13 1411 1424
11 962 973
1.5
1.5
9983
33472
3.4 20509
2.1
qsortapp
1
20
21
1
12
14
1.6
1.5
664
1176
1.8
2355
3.5
query
5
11
15
4
9
12
1.2
1.3
2090
8833
4.2
531
0.3
rdtok
8
141
149
6
43
49
3.3
3.1
13704
15354
1.1
6533
0.5
serialize
2
40
42
2
17
19
2.3
2.2
987
3801
3.9
1779
1.8
warplan
8
173
181
7 108 115
1.6
1.6
5203
23971
4.6 15305
2.9
witt
16
196
212
14
72
86
2.7
2.5
17681
41760
2.4 19131
1.1
zebra
3
94
97
3
90
92
1.1
1.0
2284
5396
2.4
4058
1.8
Overall
1.63
1.61
1
2.66
1.44
been performed on a Pentium 4 at 2.4GHz and 512MB RAM running GNU
Linux RH9.0. The Linux kernel used is 2.4.25, customized with the hrtime patch
to provide improved precision and resolution in time measurements.
Execution times are given in milliseconds and measure runtime. They are
computed as the arithmetic mean of ﬁve runs. A relatively wide range of pro-
grams has been used as benchmarks. They are the same ones used in [9], where
they are described in some detail. For each benchmark, the columns for Analysis
are the following: PA is the time required by the preprocessing phase, in which
program clauses are processed and stored in the format required by the ana-
lyzer. The analysis time proper is shown in column An. The actual time needed
for analysis –the sum of these two times– is shown in column TA. Similarly, in
the case of checking, three columns are shown. The preprocessing phase, PC,
includes asserting the certiﬁcate in addition to asserting the program to be ana-
lyzed. As the ﬁgures show, the overhead required for asserting the certiﬁcate is
negligible. Column Ch is the time for executing the checking algorithm. Finally,
TC is the total time for checking. The columns under Speedup compare analysis
and checking times. As can be seen in columns A/C and TA/TC, the checking
algorithm is faster than the analysis algorithm in all cases. The actual speedup
ranges from almost none, as in the case of zebra, to over four times faster in the
case of deriv. The last row summarizes the results for the diﬀerent benchmarks

Abstraction-Carrying Code
395
using a weighted mean, which places more importance on those benchmarks
with relatively larger analysis times. We use as weight for each program its ac-
tual analysis time. We believe that this weighted mean is more informative than
the arithmetic mean, as, for example, doubling the speed in which a large and
complex program is analyzed (checked) is more relevant than achieving this for
small, simple programs. Overall, the speedup is 1.63 in just analysis time, or
1.61 if we also take into account the preprocessing time. We believe that the
achieved speedup is signiﬁcant taking into account that CiaoPP’s analyzer for
this domain is highly optimized and converges very eﬃciently. However, it is to
be expected that, for other domains and implementations, the relative gains will
be higher.
The second part of the table studies the size of the certiﬁcates, coded in
compact (fastread) format, for the diﬀerent benchmarks and compares it to the
size of the source code for the same program and to the size of the corresponding
bytecode. To make this comparison fair, we subtract 4180 bytes from the size of
the bytecode for each program: the size of the bytecode for an empty program
in this version of Ciao (minimal top-level drivers and exception handlers for any
executable). The results show the size of the certiﬁcate to be quite reasonable. It
ranges from 0.3 times the size of the source code (for deriv) to 3.5 (in the case of
qsortapp). Overall, it is 1.44 times the size of the source code. We consider this
acceptable since in general Prolog programs are quite compact (up to 10 times
more compact than equivalent imperative programs). In fact, the size of source
plus certiﬁcate is smaller (1+1.44) than that of the bytecode (2.66).
6
Discussion and Related Work
The main contribution of this work is to introduce, implement, and (preliminar-
ily) benchmark abstraction-carrying code (ACC) as a novel enabling technology
for PCC, which is based throughout on the use of abstract interpretation tech-
niques. We argue that ACC is highly ﬂexible due to the parametricity on the
abstract domain inherited from the analysis engines used in (C)LP. Our ap-
proach diﬀers from existing approaches to PCC in several aspects. In our case,
the certiﬁcate is computed automatically on the producer side by an abstract
interpretation-based analyzer and the certiﬁcate takes the form of a particu-
lar subset of the analysis results. The burden on the consumer side is reduced
by using a simple one-traversal checker, which is a very simpliﬁed and eﬃcient
abstract interpreter which does not need to compute a ﬁxpoint.
A type-level dataﬂow analysis of Java virtual machine bytecode is also the
basis of most existing veriﬁers [12,11], and some are loosely based on abstract
interpretation. These analyses allow proving that the program is correct w.r.t.
type-related correctness conditions. In [19] a proposal is presented to split the
type-based bytecode veriﬁcation of the KVM (an embedded variant of the JVM)
in two phases, where the producer ﬁrst computes the certiﬁcate by means of a
type-based dataﬂow analyzer and then the consumer simply checks that the
types provided in the code certiﬁcate are valid. As in our case, the second phase

396
E. Albert, G. Puebla, and M. Hermenegildo
can be done in a single, linear pass over the bytecode. However, these approaches
are designed limited to types, whereas our approach is inherently parametric and
thus supports a very rich set of domains, and combinations of several of them.
Let us note that the checker is part of the trusted computing base and, hence,
the code consumer has to trust also the domain operations. Other approaches
to PCC use logic-based veriﬁcation methods as enabling technology, an example
is [22] which formalises a simple assembly language with procedures and presents
a safety policy for arithmetic overﬂow in Isabelle/HOL.
The coexistence of
several abstract domains in our framework is somewhat related to the notion of
models to capture the security-relevant properties of code, as addressed in the
work on Model-Carrying Code (MCC) [20].
Another diﬀerence between our work and other related work is that the
instance that we have described is actually deﬁned at the source-level, whereas
in existing PCC frameworks the code supplier typically packages the certiﬁcate
with the object code rather than with the source code (both are untrusted).
Actually, both approaches are of interest from our point of view (and, in fact, our
approach can also be applied to bytecode). Open-source code is becoming much
more relevant these days (in fact, Ciao and CiaoPP are themselves GNU-licensed
and available in source code). As a result, it is now realistic to expect that a
relatively large amount of untrusted source code is available to the consumer. The
advantages of open-source with respect to safety are important since it allows
inspecting the code and applying powerful techniques for program analysis and
validation which allow inferring information which may be diﬃcult to observe
in low-level, compiled code.
Acknowledgments
This work was funded in part by the Information Society Technologies pro-
gramme of the European Commission, Future and Emerging Technologies under
the IST-2001-38059 ASAP project and by the Spanish Ministry of Science and
Education under the MCYT TIC 2002-0055 CUBICO project. Part of this work
was performed during a research stay of Elvira Albert and Germ´an Puebla at
UNM supported by respective grants from the Secretar´ıa de Estado de Edu-
caci´on y Universidades, Spanish Ministry of Science and Education. Manuel
Hermenegildo is also supported by the Prince of Asturias Chair in Information
Science and Technology at UNM.
References
1. D. Aspinall, S. Gilmore, M. Hofmann, D. Sannella, and I. Stark. Mobile resource
guarantees for smart devices. In G. Barthe, L. Burdy, M. Huisman, J.-L. Lanet,
and T. Muntean, editors, Proceedings of CASSIS’04, LNCS. Springer, 2004.
2. M. Bruynooghe. A Practical Framework for the Abstract Interpretation of Logic
Programs. Journal of Logic Programming, 10:91–124, 1991.

Abstraction-Carrying Code
397
3. F. Bueno, D. Cabeza, M. Carro, M. Hermenegildo, P. L´opez-Garc´ıa, and G. Puebla.
The Ciao System. Reference Manual (v1.10). May 2004. Technical University of
Madrid (UPM). Available at http://clip.dia.fi.upm.es/Software/Ciao.
4. W. Charatonik. Directional Type Checking for Logic Programs: Beyond Discrim-
inative Types. In Proc. of ESOP 2000, pages 72–87. LNCS 1782, 2000.
5. P. Cousot and R. Cousot. Abstract Interpretation: a Uniﬁed Lattice Model for
Static Analysis of Programs by Construction or Approximation of Fixpoints. In
Proc. of POPL’77, pages 238–252, 1977.
6. P.W. Dart and J. Zobel. A Regular Type Language for Logic Programs. In Types
in Logic Programming, pages 157–187. MIT Press, 1992.
7. T. Fr¨uwirth, E. Shapiro, M.Y. Vardi, and E. Yardeni. Logic programs as types for
logic programs. In Proc. LICS’91, pages 300–309, 1991.
8. M. Hermenegildo, G. Puebla, F. Bueno, and P. L´opez-Garc´ıa. Program Develop-
ment Using Abstract Interpretation (and The Ciao System Preprocessor). In Proc.
of SAS’03, pages 127–152. Springer LNCS 2694, 2003.
9. M. Hermenegildo, G. Puebla, K. Marriott, and P. Stuckey. Incremental Analysis
of Constraint Logic Programs. ACM TOPLAS, 22(2):187–223, March 2000.
10. J. Jaﬀar and M.J. Maher. Constraint Logic Programming: A Survey. Journal of
Logic Programming, 19/20:503–581, 1994.
11. Xavier Leroy. Java bytecode veriﬁcation: algorithms and formalizations. Journal
of Automated Reasoning, 30(3-4):235–269, 2003.
12. T. Lindholm and F. Yellin. The Java Virtual Machine Speciﬁcation. Addison-
Wesley, 1997.
13. G. Morrisett, D. Walker, K. Crary, and N. Glew. From system F to typed assembly
language. ACM TOPLAS, 21(3):527–568, 1999.
14. K. Muthukumar and M. Hermenegildo. Combined Determination of Sharing and
Freeness of Program Variables Through Abstract Interpretation. In 1991 Interna-
tional Conference on Logic Programming, pages 49–63. MIT Press, June 1991.
15. G. Necula.
Proof-Carrying Code.
In Proc. of POPL’97, pages 106–119. ACM
Press, 1997.
16. G. Necula and P. Lee. The Design and Implementation of a Certifying Compiler.
In Proc. of PLDI’98. ACM Press, 1998.
17. G.C. Necula and S.P. Rahul.
Oracle-based checking of untrusted software.
In
Proceedings of POPL’01, pages 142–154. ACM Press, 2001.
18. G. Puebla, F. Bueno, and M. Hermenegildo. An Assertion Language for Constraint
Logic Programs. In Analysis and Visualization Tools for Constraint Programming,
pages 23–61. Springer LNCS 1870, 2000.
19. K. Rose, E. Rose. Lightweight bytecode veriﬁcation. In OOPSALA Workshop on
Formal Underpinnings of Java, 1998.
20. R. Sekar, V.N. Venkatakrishnan, S. Basu, S. Bhatkar, and D. DuVarney. Model-
carrying code: A practical approach for safe execution of untrusted applications.
In Proc. of SOSP’03, pages 15–28. ACM, 2003.
21. C. Vaucheret and F. Bueno.
More precise yet eﬃcient type inference for logic
programs. In Proc. of SAS’02, pages 102–116. Springer LNCS 2477, 2002.
22. M. Wildmoser and T. Nipkow. Certifying Machine Code Safety: Shallow Versus
Deep Embedding. In TPHOLs, number 3223 in LNCS. Springer, 2004.

A Veriﬁcation Environment for Sequential
Imperative Programs in Isabelle/HOL⋆
Norbert Schirmer
Technische Universit¨at M¨unchen, Institut f¨ur Informatik
http://www4.in.tum.de/~schirmer
Abstract. We develop a general language model for sequential impera-
tive programs together with a Hoare logic. We instantiate the framework
with common programming language constructs and integrate it into Is-
abelle/HOL, to gain a usable and sound veriﬁcation environment.
1
Introduction
The main goal of this work is to develop a suitable programming language model
and proof calculus, to support program veriﬁcation in the interactive theorem
prover Isabelle/HOL. The model should be lightweight so that program veriﬁ-
cation can be carried out on the abstraction level of the programming language.
The design of a framework for program veriﬁcation in an expressive logic like
HOL is driven by two main goals. On the one hand we want to derive the proof
calculus in HOL, so that we can guarantee soundness of the calculus with respect
to the programming language semantics. On the other hand we want to apply
the proof calculus to verify programs.
The main contribution of this work is to present a programming language
model that operates on a polymorphic state space, but still can handle local
and global variables throughout procedure calls. By this we can achieve both
desired goals. We can once and for all develop a sound proof calculus as well
as later on tailor the state space to ﬁt to the current program veriﬁcation task.
Moreover the model is expressive enough to handle abrupt termination, side-
eﬀecting expressions, runtime faults and dynamic procedure calls. Finally we
instantiate the framework with a state space representation that allows us to
match programming language typing with logical typing. So type inference will
take care of basic type safety issues, which simpliﬁes the assertions and proof
obligations. Parts of the frame condition for procedure speciﬁcations can be
naturally expressed in this state space representation and can already be handled
during veriﬁcation condition generation.
⋆This work was partially funded by the German Federal Ministry of Education, Sci-
ence, Research and Technology (BMBF) in the framework of the Verisoft project
(http://www.verisoft.de) under grant 01 IS C38. The responsibility for this arti-
cle lies with the author.
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 398–414, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

A Veriﬁcation Environment for Sequential Imperative Programs
399
Related Work The tradition of embedding a programming language in HOL goes
back to the work of Gordon [12], where a while language with variables ranging
over natural numbers is introduced. A polymorphic state space was already used
by Wright et. al. [21] in their machnisation of reﬁnement concepts, by Harrison
in his formalisation of Dijkstra [5] and by Prensa to verify parallel programs
[18]. Still procedures were not present. Homeier [6] introduces procedures, but
the variables are again limited to numbers. Later on detailed semantics for Java
[16,7] and C [15] were embedded in a theorem prover. But veriﬁcation of even
simple programs suﬀers from the complex models.
The Why tool [4] implements a program logics for annotated functional pro-
grams (with references) and produces veriﬁcation conditions for an external the-
orem prover. It can handle uninterpreted parts of annotations that are only
meaningful to the external theorem prover. With this approach it is possible to
map imperative languages like C to the tool by representing the heap in refer-
ence variables. Although the Why tool and the work we present in this paper
both provide comparable veriﬁcation environments for imperative programs the
theoretical foundations to achieve this are quite diﬀerent: Filliˆatre builds up a
sophisticated type theory incorporating an eﬀect analysis on the input language,
whereas the framework of Hoare logics and the simple type system of HOL is
suﬃcient for our needs. Moreover our entire development, the calculus together
with its soundness and completeness proof, is carried out in Isabelle/HOL, in
contrast to the pen and paper proofs of Filliˆatre [3].
The rest of the paper is structured as follows. We start with a brief introduc-
tion to Isabelle/HOL in Section 2; in Section 3 we introduce the programming
language model and the Hoare logics; Section 4 describes the integration into
Isabelle and shows how we deal with various language constructs; Section 5
concludes.
2
Preliminary Notes on Isabelle/HOL
Isabelle is a generic logical framework which allows one to encode diﬀerent object
logics. In this article we are only concerned with Isabelle/HOL [14], an encoding
of higher order logic augmented with facilities for deﬁning data types, records,
inductive sets as well as primitive and total general recursive functions.
The syntax of Isabelle is reminiscent of ML, so we will not go into detail
here. There are the usual type constructors T 1 × T 2 for product and T 1 ⇒T 2
for function space. The syntax [[P; Q]] =⇒
R should be read as an inference
rule with the two premises P and Q and the conclusion R. Logically it is just
a shorthand for P =⇒Q =⇒R. There are actually two implications −→and
=⇒. The two mean the same thing except that −→is HOL’s ”real” implication,
whereas =⇒comes from Isabelle’s meta-logic and expresses inference rules. Thus
=⇒cannot appear inside a HOL formula. For the purpose of this paper the two
may be identiﬁed. Similarly, we use  for the universal quantiﬁer in the meta
logic.

400
N. Schirmer
To emulate partial functions the polymorphic option type is frequently used:
datatype ′a option = None | Some ′a. Here ′a is a type variable, None stands
for the undeﬁned value and Some x for a deﬁned value x. A partial function from
type T 1 to type T 2 can be modelled as T 1 ⇒(T 2 option). The domain of such
a partial function f is dom f.
There is also a destructor for the constructor Some, the function the::
′a
option ⇒′a. It is deﬁned by the sole equation the (Some x) = x and is total in
the sense that the None is a legal, but indeﬁnite value.
Appending two lists is written as xs @ ys and “consing” as x # xs.
3
Programming Language Model
3.1
Abstract Syntax
The basic model of the programming language is quite general. We want to be
able to represent a sequential imperative programming language with mutually
recursive procedures, local and global variables and heap. Abrupt termination
like break, continue, return or exceptions should also be expressible in the
model. Moreover we support a dynamic procedure call, which allows us to rep-
resent procedure pointers or dynamic method invocation.
We only ﬁx the statements of the programming language. Expressions are or-
dinary HOL-expressions, therefore they do not have any side eﬀects. Nevertheless
we want to be able to express faults during expression evaluation, like division by
0 or dereferencing a Null pointer. We introduce guards in the language, which
check for those runtime faults.
The state space of the programming language and also the representation of
procedure names is polymorphic. The canonical type variable for the state space
is ′s and for procedure names ′p. The programming language is deﬁned by a
datatype ( ′s, ′p) com with the following constructors:
Skip: Do nothing
Basic f : Basic commands like assignment; f is a state-update: ′s ⇒′s
Seq c1 c2: Sequential composition, also written as c1;c2
Cond b c1 c2: Conditional statement
Guard g c: Guarded command, also written as g →c
While b c: Loop
Call p: Static procedure call, p:: ′p
Throw: Initiate abrupt termination
Catch c1 c2: Handle abrupt termination of c1 with c2
DynCom c: Dynamic (state dependant) command: c:: ′s ⇒( ′s, ′p) com
The procedure call above is parameterless. In 4.4 we implement a call with
parameters: call init p return result.
The dynamic command DynCom allows to abstract a statement over the
state. It is fairy general, and we implement side-eﬀecting expressions (4.3) and

A Veriﬁcation Environment for Sequential Imperative Programs
401
real “dynamic” statements, like pointers to procedures or dynamic method in-
vocation with it. We model the latter with:
dynCall init p return result ≡DynCom (λs. call init (p s) return result)
3.2
State Space Representation
Although the semantics is deﬁned for polymorphic state spaces we introduce the
state space representation which we will use later on to give some illustrative
examples. We represent the state space as a record in Isabelle/HOL. This idea
goes back to Wenzel [23]. A simple state space with three variables B, N and M
can be modelled with the following record deﬁnition:
record vars = B::bool N ::int M ::int
Records of type vars have three ﬁelds, named B, N and M of type bool resp.
int. An example instance of such a record is (|B = True, N = 42, M = 3|). For
each ﬁeld there is a selector function of the same name, e.g. N (|B = True, N =
42, M = 3|) = 42. The update operation is functional. For example, v(|N := 0|)
is a record where component N is 0 and whose B and M component are copied
from v. Selections of updated components can be simpliﬁed automatically e.g.
N (r(|N := 43|)) = 43. The representation of the state space as record has the
advantage that the typing of variables can be expressed by means of typing in
the logic. Therefore basic type safety requirements are already ensured by type
inference.
3.3
Hoare Logics
We have deﬁned two Hoare logic judgements, for partial correctness of the gen-
eral form Γ,Θ⊢P c Q,A and Γ,Θ⊢t P c Q,A for total correctness. P is the
precondtion and Q and A are the postconditions for normal and abrupt termi-
nation. If we start in a state satisfying P, execution of command c will end up
in a state satisfying Q in case of normal termination and in a state satisfying A
in case of abrupt termination. Total correctness additionally guarantees termi-
nation of the program. Γ is the procedure environment, which maps procedure
names to their bodies, and Θ is a set of Hoare quadruples that we may assume.
Θ is used to handle recursive procedures as we will see later on. We have proven
soundness and completeness of the Hoare logics with respect to an operational
semantics [20]. But this paper will focus on the application of the logic.
The assertions P, Q and A are represented as set of states: ′s set. This means
we do not introduce a special assertion language, but can use ordinary HOL sets
to describe the states.
The Hoare logic is deﬁned inductively. The rules are syntax directed, and
most of them are deﬁned in a weakest precondition style. This makes it easy to
automate rule application in a veriﬁcation condition generator. Handling abrupt
termination is surprisingly simple. The postcondition for abrupt termination is
left unmodiﬁed by most of the rules. Only if we actually encounter a Throw it has

402
N. Schirmer
to be a consequence of the precondition. This means that the proof rules do not
complicate the veriﬁcation of programs where abrupt termination is not present.
The approach to split up the postcondition for normal and abrupt termination
is also followed by [4,8].
The rules for the basic language constructs are standard:
Γ,Θ⊢Q Skip Q,A
Γ,Θ⊢{s. f s ∈Q} Basic f Q,A
Γ,Θ⊢P c1 R,A
Γ,Θ⊢R c2 Q,A
Γ,Θ⊢P Seq c1 c2 Q,A
Γ,Θ⊢(P ∩b) c1 Q,A
Γ,Θ⊢(P ∩−b) c2 Q,A
Γ,Θ⊢P Cond b c1 c2 Q,A
Γ,Θ⊢P c Q,A
Γ,Θ⊢(g ∩P) Guard g c Q,A
Γ,Θ⊢(P ∩b) c P,A
Γ,Θ⊢P While b c (P ∩−b),A
The command Basic f applies the function f to the current state. An example of
a basic operation may be an assignment N = 2. This can be represented as Basic
(λs. s(|N :=2|)) in our language model. We can also represent ﬁeld assignment
or memory allocation as basic commands.
To model runtime faults that may occur during expression evaluation (like
division by zero), we use the guarded command. In order to prove a guarded
command we have to ensure that the guard holds.
The remaining rules will be described in the following section. Most of rules
for total correctness are structurally equivalent to their partial correctness coun-
terparts. We will only focus on those interesting rules with an impact on termi-
nation, namely loops and recursion. The basic idea is to justify termination by
a well-founded relation on the state-space.
4
Veriﬁcation Environment
Our main tool is a veriﬁcation condition generator that is implemented as tactic
called vcg. The Hoare logic rules are deﬁned in a weakest precondition style, so
that we can almost take them as they are. We derive variants of the Hoare rules
where all assertions in the conclusions are plain variables so that they are ap-
plicable to every context. We get the following format:
P ⊆WP . . .
Γ,Θ⊢P c Q,A. The . . .
may be recursive Hoare quadruples or side-conditions which somehow lead to the
weakest precondition WP. If we recursively apply rules of this format until the
program c is completely processed, then we have calculated the weakest precon-
dition WP and are left with the veriﬁcation condition P ⊆WP. The set inclusion
is then transformed to an implication. Finally we split the state records so that
the record representation will not show up in the resulting veriﬁcation condi-
tion. This leads to quite comprehensible proof obligations that closely resemble
the speciﬁcations. Moreover we supply some concrete syntax for programs. The
mapping to the abstract syntax should be obvious. As a shorthand an empty
set Θ can be omitted and writing a Hoare triple instead of the quadruples is an
abbreviation for an empty postcondition for abrupt termination.

A Veriﬁcation Environment for Sequential Imperative Programs
403
If we refer to components (variables) of the state-space of the program we
always mark these with ´(in assertions and also in the program itself). Assertions
are ordinary Isabelle/HOL sets. As we usually want to refer to the state-space in
the assertions, we provide special brackets {|. . .|} for them. Internally, an assertion
of the from {|´I ≤3|} gets expanded to {s. I s ≤3} in ordinary set comprehension
notation of Isabelle.
Although our assertions work semantically on the state-space, stepping
through veriﬁcation condition generation “feels” like the expected syntactic sub-
stitutions of traditional Hoare logic. This is achieved by simpliﬁcation of the
record updates in the assertions calculated by the Hoare rules.
lemma
Γ⊢{|´M = a ∧´N = b|} ´I := ´M ; ´M := ´N ; ´N := ´I {|´M = b ∧´N = a|}
apply vcg-step
1. Γ⊢{|´M = a ∧´N = b|} ´I := ´M ; ´M := ´N {|´M = b ∧´I = a|}
apply vcg-step
1. Γ⊢{|´M = a ∧´N = b|} ´I := ´M {|´N = b ∧´I = a|}
apply vcg-step
1. {|´M = a ∧´N = b|} ⊆{|´N = b ∧´M = a|}
apply vcg-step
1. M N . N = N ∧M = M
4.1
Loops
To verify a loop, the user annotates an invariant. For total correctness the user
also supplies the variant, which in our case is a well-founded relation on the state-
space, which decreases by evaluation of the loop body. Formally this is expressed
by ﬁrst ﬁxing the pre-state with the rsingleton set {τ}. In the postcondition for
normal termination of the loop body we end up in a state s and have to show
that this state is “smaller than” τ according to the relation: (s, τ) ∈r. Since
abrupt termination will exit the loop immediately we do not have to take any
care in this case.
wf r
∀τ. Γ,Θ⊢t ({τ} ∩P ∩b) c ({s. (s, τ) ∈r} ∩P),A
Γ,Θ⊢t P While b c (P ∩−b),A
We make use of the infrastructure for well-founded recursion that is already
present in Isabelle/HOL [14]. The following example calculates multiplication
by iterated addition. The distance of the loop variable M to a decreases in every
iteration. This is expressed by the measure function a −´M on the state-space.
lemma Γ⊢t {|´M = 0 ∧´S = 0|}
WHILE ´M ̸= a INV{|´S = ´M ∗b ∧´M ≤a|} VAR MEASURE a −´M
DO ´S := ´S + b; ´M := ´M + 1 OD
{|´S = a ∗b|}
apply vcg

404
N. Schirmer
1. M S. [[M = 0; S = 0]] =⇒S = M ∗b ∧M ≤a
2. M S. [[S = M ∗b; M ≤a; M ̸= a]]
=⇒a −(M + 1) < a −M ∧S + b = (M + 1) ∗b ∧M + 1 ≤a
3. M S. [[S = M ∗b; M ≤a; ¬ M ̸= a]] =⇒S = a ∗b
The veriﬁcation condition generator gives us three proof obligations, stemming
from the path from the precondition to the invariant, from the invariant together
with the loop condition through the loop body to the invariant, and ﬁnally from
the invariant together with the negated loop condition to the postcondition. The
variant annotation results in the proof obligation a −(M + 1) < a −M after
veriﬁcation condition generation.
4.2
Abrupt Termination
In case of a Throw the abrupt postcondition has to stem from the precondition.
The rule for Catch is dual to sequential composition. Only if the ﬁrst statement
terminates abruptly the second statement is executed. Thinking of exceptions
the ﬁrst statement forms the protected try part, whereas the second statement
is the exception handler. Thus the precondition R for the second statement is
the postcondition for abrupt termination of the ﬁrst statement.
Γ,Θ⊢A Throw Q,A
Γ,Θ⊢P c1 Q,R
Γ,Θ⊢R c2 Q,A
Γ,Θ⊢P Catch c1 c2 Q,A
We can implement breaking out of a loop by a THROW inside the loop body
and enclosing the loop into a TRY−CATCH block.
lemma Γ⊢{|´I ≤3|}
TRY WHILE True INV {|´I ≤10|}
DO IF ´I < 10 THEN ´I := ´I + 1 ELSE THROW FI OD
CATCH SKIP YRT
{|´I = 10|},{}
apply vcg
1. I . I ≤3 =⇒I ≤10
2. I . [[I ≤10; True]]
=⇒(I < 10 −→I + 1 ≤10) ∧(¬ I < 10 −→I = 10)
3. I . [[I ≤10; ¬ True]] =⇒I = 10
The ﬁrst subgoal stems from the path from the precondition to the invariant.
The second one from the loop body. We can assume the invariant and the loop
condition and have to show that the invariant is preserved when we execute the
THEN branch, and that the ELSE branch will imply the assertion for abrupt
termination, which will be {|´I = 10|} according to the rule for Catch and Skip.
The third subgoal expresses that normal termination of the while loop has to

A Veriﬁcation Environment for Sequential Imperative Programs
405
imply the postcondition. But the loop will never terminate normally and so the
third subgoal will trivially hold.
To model a continue we can use the same idea and put a TRY−CATCH
around the loop body. Or for return we can put the procedure body into a
TRY−CATCH. To distinguish the kind of abrupt termination we can add
a ghost variable Abr to the state-space and store this information before the
THROW. For example break can be translated to ´Abr := ′′Break ′′; THROW.
The matching CATCH will peek for this variable to decide whether it is re-
sponsible or not: IF ´Abr = ′′Break ′′ THEN SKIP ELSE THROW FI. This
idea can immediately be extended to exceptions. We just have to make sure to
use a global variable to store the kind of exception, so that it will properly pass
procedure boundaries.
4.3
Expressions with Side Eﬀects
Expressions in our language model are ordinary HOL expressions (functions over
the state-space) and though do not have side eﬀects. The trivial approach is to
reduce side-eﬀecting expressions to statements and expressions without side ef-
fects. A program transformation step introduces temporary variables to store the
result of subexpressions. For example we can get rid of the increment expres-
sion in r = m++ + n by ﬁrst saving the initial value of m in a temporary vari-
able: tmp = m; m = m + 1; r = tmp + n. But in our state-space model this
approach is somehow annoying since the temporary variables directly aﬀect the
shape of the state record. The essence of the temporary variables is to ﬁx the
value of an expression at a certain program state, so that we can later on refer
to this value. Since our dynamic command DynCom allows to abstract over the
state-space we already have the means to refer to certain program states. In
contrast to Oheimb [16] we do not have to invent a special kind of postcondi-
tion that explicitely depends on the result value of an expression. Similar to the
state monad in functional programming [22] we introduce the command bind e
c, which binds the value of expression e (of type ′s ⇒′v) at the current program
state and feeds it into the following command c (of type ′v ⇒( ′s, ′p) com): bind
e c ≡DynCom (λs. c (e s)). The Hoare rule for bind is the following:
P ⊆{s. s ∈P ′ s}
∀s. Γ,Θ⊢(P ′ s) c (e s) Q,A
Γ,Θ⊢P bind e c Q,A
The initial state is s. The intuitive reading of the rule is backwards in the style
of the weakest precondition calculation. The postcondition we want to reach is
Q or A. Since statement c depends on the initial state s via expression e, the
intermediate assertion P ′ depends on s, too. The actual precondition P describes
a subset of the states of P ′ s.
In the following example the notation e ≫m. c is syntax for bind e (λm.
c), whereas the second ≫is just a syntactic variant of sequential composition
to indicate the scope of the bound variable m.

406
N. Schirmer
lemma
Γ⊢{|True|} ´M ≫m. ´M := ´M + 1 ≫´R := m + ´N {|´R = ´M + ´N −1|}
apply vcg
1. M N . True =⇒M + N = M + 1 + N −1
M and N are the initial values of the variables. So in the postcondition ´R gets
substituted by M + N and ´M by M + 1.
4.4
Procedures
To introduce a new procedure we provide the command procedures.
procedures Fac (N |R) =
IF ´N = 0 THEN ´R := 1
ELSE ´R := CALL Fac(´N −1); ´R := ´N ∗´R FI
Fac-spec: ∀n. Γ⊢{|´N = n|} ´R := PROC Fac(´N ) {|´R = fac n|}
A procedure is given by its signature followed by its body and some named
speciﬁcations. The parameters in front of the pipe | are value parameters and
behind the pipe are result parameters. Value parameters model call by value
semantics. The value of a result parameter at the end of the procedure is passed
back to the caller. Most common programming languages do not have the concept
of a result parameter. But our language is a model for sequential programs rather
than a “real” programming language. We represent return e as an assignment
of e to the result variable. In order to capture the abrupt termination stemming
from a return we can use the techniques described in 4.2.
To call a procedure we write ´M := CALL Fac(´I ). This translates to the
internal form call init ′′Fac ′′ return result with the proper init, return and result
functions. Starting in an initial state s ﬁrst the init function is applied, in order
to pass the parameters. Then we execute the procedure body according to the
environment Γ. Upon normal termination of the body in a state t, we ﬁrst exit the
procedure according to the function return s t and then continue execution with
result s t. In case of an abrupt termination the ﬁnal state is given by return s t.
The function return passes back the global variables (and heap components) and
restores the local variables of the caller, and result additionally assigns results
to the scope of the caller. The return/result functions get both the initial state
s before the procedure call and the ﬁnal state t after execution of the body. If
the body terminates abruptly we only apply the return function, thus the global
state will be propagated to the caller but no result will be assigned. This is the
expected semantics of an exception. We use the dynamic command to capture
the states s and t in the deﬁnition of the procedure call with parameters:
call init p return result ≡
DynCom
(λs. TRY Basic init; Call p CATCH Basic (return s); THROW YRT;
DynCom (λt. Basic (return s); result s t))

A Veriﬁcation Environment for Sequential Imperative Programs
407
Back to our example ´M := CALL Fac(´I ). The init function copies the
actual parameter I to the formal parameter N : init s = s(|N := I s|). The return
function updates the global variables of the initial state with their values in the
ﬁnal state. The global variables are all grouped together in a single record ﬁeld:
return s t = s(|globals := globals t|). The result function is not just a state update
function like return, but yields a complete command, like the second argument
in the bind command. This allows us to use the same technique as described for
side-eﬀecting expressions to model nested procedure calls. In our example the
result statement is an assignment that copies the formal result parameter R to
M : result s t = Basic (λu. u(|M := R t|)). Here s is the initial state (before
parameter passing), t the ﬁnal state of the procedure body, and u the state after
the return from the procedure. In the example the initial state s is not used.
But if we assign the result of the procedure to a complex left expression and
implement a left to right evaluation strategy like in C we can consider s. For
example consider a pointer manipulating function call: p->next = rev(q). The
left value of p->next is the address where the result is assigned to. It is evaluated
before the procedure call, according to the left to right evaluation strategy. We
can refer to the initial state s to properly implement this semantics.
Procedure speciﬁcations are ordinary Hoare quadruples. We use the parame-
terless call for the speciﬁcation; ´R := PROC Fac(´N ) is syntactic sugar for Call
′′Fac ′′. This emphasises that the speciﬁcation describes the internal behaviour
of the procedure, whereas parameter passing corresponds to the procedure call.
The precondition of the factorial speciﬁcation ﬁxes the current value ´N to the
logical variable n. Universal quantiﬁcation of n enables us to adapt the speciﬁca-
tion to an actual parameter. Besides providing convenient syntax, the command
procedures also deﬁnes a constant for the procedure body (named Fac-body) and
creates two locales. The purpose of locales is to set up logical contexts to sup-
port modular reasoning [1]. One locale is named like the speciﬁcation, in our case
Fac-spec. This locale contains the procedure speciﬁcation. The second locale is
named Fac-impl and contains the assumption Γ ′′Fac ′′ = Some Fac-body, which
expresses that the procedure is deﬁned in the current environment. The purpose
of these locales is to give us easy means to setup the context in which we will
prove programs correct.
Procedure Call By including the locale Fac-spec, the following lemma assumes
that the speciﬁcation of the factorial holds. The vcg will use this speciﬁcation to
handle the procedure call. The lemma also illustrates locality of I.
lemma includes Fac-spec shows
Γ⊢{|´M = 3 ∧´I = 2|} ´R := CALL Fac (´M ) {|´R = 6 ∧´I = 2|}
apply vcg
1. I M . [[M = 3; I = 2]] =⇒fac M = 6 ∧I = 2
If the veriﬁcation condition generator encounters a procedure call, like Γ,Θ⊢P
call ini p ret res Q,A, it does not look inside the procedure body, but instead

408
N. Schirmer
uses a speciﬁcation ∀Z. Γ,Θ⊢(P ′ Z) Call p (Q ′ Z),(A ′ Z) of the procedure.
It adapts the speciﬁcation to the actual calling context by a variant of the
consequence rule, which also takes parameter and result passing into account. In
the factorial example n plays the role of the auxiliary variable Z. It transports
state information from the pre- to the postcondition. A detailed discussion of
consequence rules and auxiliary variables can be found in [9,13].
P ⊆{s. ∃Z. ini s ∈P ′ Z ∧(∀t∈Q ′ Z. ret s t ∈R s t) ∧(∀t∈A ′ Z. ret s t ∈A)}
∀s t. Γ,Θ⊢(R s t) res s t Q,A
∀Z. Γ,Θ⊢(P ′ Z) Call p (Q ′ Z),(A ′ Z)
Γ,Θ⊢P call ini p ret res Q,A
The idea of this rule is to adapt the speciﬁcation of Call p to call ini p ret res.
Figure 1 shows the sequence of intermediate states for normal termination. We
call ini p ret res
s
t
P ′ Z
∈
P
∈
Call p
Q ′ Z
−→
∈
ini s
∈
Q
res s t
−→
∈
ret s t
R s t
Fig. 1. Procedure call and speciﬁcation
start in state s for which the precondition P holds. To be able to make use of
the procedure speciﬁcation we have to ﬁnd a suitable instance of the auxiliary
variable Z so that the precondition of the speciﬁcation holds: ini s ∈P ′ Z.
Let t be the state immediately after execution of the procedure body, before
returning to the caller and passing results. We know from the speciﬁcation that
the postcondition will hold: t ∈Q ′ Z. From this we have to conclude that leaving
the procedure according to the function ret will lead to a state in R s t. From
this state execution of res s t ends up in a state in Q. For abrupt termination
the analogous idea applies, but without the intermediate assertion R s t, since
execution of res s t is skipped. Simplifying the record updates and selections of
the side-condition yields the natural proof obligation we have seen before.
The rule for dynamic procedure call is a slight generalisation of the static
procedure call. Since the selected procedure depends on the state, we have the
liberty to select a suitable speciﬁcation dependent on the state.
P ⊆{s. ∃Z. ini s ∈P ′ s Z ∧
(∀t ∈Q ′ s Z. ret s t ∈R s t) ∧(∀t ∈A ′ s Z. ret s t ∈A)}
∀s t. Γ,Θ⊢(R s t) res s t Q,A
∀s∈P. ∀Z. Γ,Θ⊢(P ′ s Z) Call (p s) (Q ′ s Z),(A ′ s Z)
Γ,Θ⊢P dynCall ini p ret res Q,A

A Veriﬁcation Environment for Sequential Imperative Programs
409
Procedure Implementation — Partial Correctness To verify the proce-
dure body we use the rule for recursive procedures. We extend the context with
the procedure speciﬁcation. In this extended context the speciﬁcation will hold
by the assumption rule. We then verify the procedure body by using vcg, which
will use the assumption to handle the recursive call.
lemma includes Fac-impl shows
∀n. Γ⊢{|´N = n|} ´R := PROC Fac(´N ) {|´R = fac n|}
apply (hoare-rule ProcRec1)
1. ∀n. Γ,(
n {({|´N = n|}, ´R := PROC Fac(´N ), {|´R = fac n|}, {})})
⊢{|´N = n|}
IF ´N = 0 THEN ´R := 1
ELSE CALL Fac(´N −1); ´R := ´N ∗´R FI
{|´R = fac n|}
apply vcg
1. N . (N = 0 −→1 = fac N ) ∧(N ̸= 0 −→N ∗fac (N −1) = fac N )
The rule ProcRec1 is a specialised version of the general rule for recursion,
tailored for one recursive procedure. The method hoare-rule applies a single rule
and solves canonical side-conditions. Moreover it expands the procedure body.
Let us now have a look at the general recursion rule. The Hoare logic can
deal with (mutually) recursive procedures. We prove that the procedure bod-
ies respect their speciﬁcation, under the assumption that recursive calls to the
procedures will meet their speciﬁcations. To model this assumption the context
Θ comes in. If a procedure speciﬁcation is in this context, we can immediately
derive this speciﬁcation within the Hoare logic.
(P, c, Q, A) ∈Θ
Γ,Θ⊢P c Q,A
To handle a set P of mutually recursive procedures we enrich the context by all
the procedure speciﬁcations, while we prove their bodies.
Θ ′ = Θ ∪(

p∈P

Z {(P p Z, Call p, Q p Z, A p Z)})
∀p∈P. ∀Z. Γ,Θ ′⊢(P p Z) the (Γ p) (Q p Z),(A p Z)
P ⊆dom Γ
∀p∈P. ∀Z. Γ,Θ⊢(P p Z) Call p (Q p Z),(A p Z)
Since we deal with the set P of procedures we also have to give the pre- and
postconditions for all these procedures. We use the functions P, Q and A, which
map procedure names to the desired entities. Z plays the role of an auxiliary (or
logical) variable. It usually ﬁxes (parts of) the pre state, so that we can refer
to it in the post state. In the Hoare rule for procedure speciﬁcations, which we
have described before, we had the freedom to pick a particular Z so that s ∈P
−→init s ∈P ′ Z holds. Since we have the freedom there, we now have to prove
the procedure bodies for all possible Z. Finally, with P ⊆dom Γ, we make sure
that the calculation will not get stuck.

410
N. Schirmer
Procedure Implementation — Total Correctness For total correctness the
user supplies a well-founded relation. For the factorial the input parameter N
decreases in the recursive call. This is expressed by the measure function λ(s,p).
sN. The relation can depend on both the state-space s and the procedure name
p. The latter is useful to handle mutual recursion. The preﬁx superscript in sN
is a shorthand for record selection N s and is used to refer to state components
of a named state.
lemma includes Fac-impl shows
∀n. Γ⊢t {|´N = n|} ´R := PROC Fac(´N ) {|´R = fac n|}
apply (hoare-rule ProcRec1 t [where r=measure (λ(s,p). sN )])
1. ∀τ n. Γ,(
n {({|´N = n|} ∩{|´N < τN|}, ´R := PROC Fac(´N ),
{|´R = fac n|}, {})})
⊢t ({τ} ∩{|´N = n|})
IF ´N = 0 THEN ´R := 1
ELSE CALL Fac(´N −1); ´R := ´N ∗´R FI
{|´R = fac n|}
We may only assume the speciﬁcation for “smaller” states {|´N < τN|}, where
state τ gets ﬁxed in the precondition.
apply vcg
1. N . (N = 0 −→1 = fac N ) ∧
(N ̸= 0 −→N −1 < N ∧N ∗fac (N −1) = fac N )
The measure function results in the proof obligation N −1 < N.
In contrast to partial correctness we only assume “smaller” recursive pro-
cedure calls correct while verifying the procedure bodies. Here “smaller” again
is in the sense of a well-founded relation r. We ﬁx the pre-state of the proce-
dure p with the singleton set {τ}. For every call to a procedure q in a state s
which is “smaller” than the initial call of p in state τ according to the relation
(((s,q),(τ,p)) ∈r), we can safely assume the speciﬁcation of q while verifying
the body of p.
Θ ′=λτ p. Θ ∪(
[
q∈P
[
Z {(P q Z ∩{s. ((s,q),τ,p) ∈r},Call q,Q q Z,A q Z)})
∀p∈P. ∀τ Z. Γ,Θ ′ τ p⊢t ({τ} ∩P p Z) the (Γ p) (Q p Z),(A p Z)
wf r
P ⊆dom Γ
∀p∈P. ∀Z. Γ,Θ⊢t (P p Z) Call p (Q p Z),(A p Z)
4.5
Heap
The heap can contain structured values like structs in C or records in Pascal.
Our model of the heap follows Burstall [2]. We have one heap variable f of type
ref ⇒value for each component f of type value of the struct. References ref
are isomorphic to the natural numbers and contain Null.

A Veriﬁcation Environment for Sequential Imperative Programs
411
A typical structure to represent a linked list in the heap is struct list
{int cont; list *next}. The structure contains two components, cont and
next. So we will also get two heap variables, cont of type ref ⇒int and next of
type ref ⇒ref in our state-space record:
record heap =
next::ref ⇒ref
cont::ref ⇒int
record state =
globals::heap
p::ref
q::ref
r::ref
We follow the approach of [10], and abstract the pointer structure in the heap
to HOL lists of references. Then we can specify further properties on the level
of HOL lists, rather than on the heap:
List x h [] = (x = Null)
List x h (p # ps) = (x = p ∧x ̸= Null ∧List (h x) h ps)
The list of references is obtained from the heap h by starting with the reference
x, following the references in h up to Null. With a generalised predicate that
describes a path in the heap, Mehta and Nipkow [11] show how this idea can
canonically be extended to cyclic lists.
We deﬁne in place list reversal. The list pointed to by p in the beginning is
Ps. In the end q points to the reversed list rev Ps. The notation r→f mimics
the ﬁeld selection syntax of C and is translated to ordinary function application
for ﬁeld lookup and function update for ﬁeld assignment.
procedures Rev(p|q) =
´q := Null;
WHILE ´p ̸= Null
DO ´r := ´p; ´p := ´p→´next; ´r→´next := ´q; ´q := ´r OD
Rev-spec:
∀σ Ps. Γ⊢{|σ. List ´p ´next Ps|} ´q := PROC Rev(´p)
{|List ´q ´next (rev Ps) ∧(∀p. p /∈set Ps −→(´next p = σnext p))|}
Rev-modiﬁes:
∀σ. Γ⊢{σ} ´q := PROC Rev(´p) {t. t may-only-modify-globals σ in [next]}
We give two speciﬁcations this time. The ﬁrst one captures the functional be-
haviour and additionally expresses that all parts of the next-heap not contained
in Ps, will stay the same (σ denotes the pre-state). Fixing a state is part of the
assertion syntax: {|σ. ...|} translates to {s. s=σ ...} and σnext to next σ. The
second speciﬁcation is a modiﬁes-clause that lists all the state components that
may be changed by the procedure. Therefore we know that the cont parts will
remain unchanged. Thus the main speciﬁcation can focus on the relevant parts of
the state-space. The assertion t may-only-modify-globals σ in [next] abbreviates
the following relation between the ﬁnal state t and the initial state σ: ∃next.
globals t = (globals σ)(|next:=next|). This modiﬁes-clause can be exploited dur-
ing veriﬁcation condition generation. We derive that we can reduce the result
function in the call to Rev, which copies the global components next and cont

412
N. Schirmer
back, to one that only copies next back. So cont will actually behave like a local
variable in the resulting proof obligation. This is an eﬀective way to express sep-
aration of diﬀerent pointer structures in the heap and can be handled completely
automatically during veriﬁcation condition generation. For example, reversing a
list will only modify the next-heap but not some left- and right-heaps of a tree
structure. Moreover the modiﬁes-clause itself can be veriﬁed automatically. The
following example illustrates the eﬀect of the modiﬁes-clause.
lemma includes Rev-spec + Rev-modiﬁes shows
Γ⊢{|´cont=c ∧List ´p ´next Ps|} ´p := CALL Rev(´p)
{|´cont=c ∧List ´p ´next (rev Ps)|}
apply vcg
1. next cont p. List p next Ps =⇒
∀nexta q.
List q nexta (rev Ps) ∧(∀p. p /∈set Ps −→nexta p = next p) −→
cont = cont ∧List q nexta (rev Ps)
The impact of the modiﬁes-clause shows up in the veriﬁcation condition. The
cont-heap results in the same variable before and after the procedure call (cont
= cont), whereas the next-heap is described by next in the beginning and by
nexta in the end. The speciﬁcation of Rev relates both next-heap states.
Memory Management To model allocation and deallocation we need some
bookkeeping of allocated references. This can be achieved by an auxiliary ghost
variable alloc in the state-space. A good candidate is a list of allocated references.
A list is per se ﬁnite, so that we can always get a new reference. By the length
of the list we can also handle space limitations. Allocation of memory means to
append a new reference to the allocation list. Deallocation of memory means to
remove a reference from the allocation list. To guard against dangling pointers
we can regard the allocation list: {|´p̸=Null ∧´p ∈set ´alloc|}→´p→´cont := 2.
The use of guards is a ﬂexible mechanism to adapt the model to the kind of
language we are looking at. If it is type safe like Java and there is no explicit
deallocation by the user, we can remove some guards. If the new instruction of
the programming language does not initialise the allocated memory we can add
another ghost variable to watch for initialised memory through guards.
5
Conclusion
We have presented a ﬂexible, sound and complete Hoare calculus for sequential
imperative programs with mutually recursive procedures and dynamic procedure
call. We have elaborated how to model various kinds of abrupt termination like
break, continue, return and exceptions, how to deal with side-eﬀecting expres-
sions, global variables, heap and memory management issues. The polymorphic

A Veriﬁcation Environment for Sequential Imperative Programs
413
state-space of the programming language allows us to choose the adequate repre-
sentation for the current veriﬁcation task. Depending on the context we can for
example decide, whether it is preferable to model certain variables as unbounded
integers in HOL or as bit-vectors, without changing the program representation
or logics. Guards make it possible to customise the runtime faults we are inter-
ested in. Using records as state-space representation gives us a natural way to
express typing of program variables and yields comprehensible veriﬁcation condi-
tions. Moreover in combination with the modiﬁes-clause we can lift separation of
heap components, which are directly expressible in the split heap model, to the
level of procedures, without having to introduce a new logic like separation logic
[19]. Crucial parts of the frame problem can then already be handled during
veriﬁcation condition generation. The calculus is developed, veriﬁed and inte-
grated in the theorem prover Isabelle and the resulting veriﬁcation environment
seamless ﬁts into the infrastructure of Isabelle/HOL.
This work is part of the Verisoft project, a long-term research project aiming
at the pervasive veriﬁcation of computer systems (hard- and software). We trans-
late a subset of C to the veriﬁcation environment and have started to verify parts
of an operating system, a compiler and an email client. We also verify the trans-
lation into the veriﬁcation environment. Moreover we validated the feasibility of
our approach by verifying algorithms for binary decision diagrams, involving a
high degree of side eﬀects due to sharing in the pointer structure [17]. Applying
the veriﬁcation condition generator to the annotated programs results in quite
sizable proof obligations. But since they closely resemble the control ﬂow the
connection to the input program is not lost. To prove them, we used the struc-
tured proof language of Isar [24] that allows us to focus and keep track of the
various diﬀerent aspects, so that we can conduct the proof in a sensible order.
Moreover it turned out that the Isar proofs are quite robust with regard to the
iterative adaptation of the invariants resulting from failed proof attempts. The
already established lines of reasoning remained stable, while adding new aspects
to, or strengthening parts of the invariant. Altogether we gained conﬁdence that
our approach is practically useful.
References
1. C. Ballarin.
Locales and locale expressions in Isabelle/Isar.
In S. Berardi,
M. Coppo, and F. Damiani, editors, Types for Proofs and Programs: International
Workshop, TYPES 2003, Torino, Italy, April 30–May 4, 2003, Selected Papers,
number 3085 in LNCS, pages 34–50. Springer, 2004.
2. R. Burstall. Some techniques for proving correctness of programs which alter data
structures. In B. Meltzer and D. Michie, editors, Machine Intelligence 7, pages
23–50. Edinburgh University Press, 1972.
3. J.-C. Filliˆatre. Veriﬁcation of Non-Functional Programs using Interpretations in
Type Theory. Journal of Functional Programming, 13(4):709–745, July 2003.
4. J.-C. Filliˆatre.
Why: a multi-language multi-prover veriﬁcation tool.
Research
Report 1366, LRI, Universit´e Paris Sud, March 2003.

414
N. Schirmer
5. J. Harrison. Formalizing Dijkstra. In J. Grundy and M. Newey, editors, Theo-
rem Proving in Higher Order Logics: 11th International Conference, TPHOLs’98,
volume 1497 of LNCS, pages 171–188, Canberra, Australia, 1998. Springer.
6. P. V. Homeier. Trustworthy Tools for Trustworthy Programs: A Mechanically Veri-
ﬁed Veriﬁcation Condition Generator for the Total Correctness of Procedures. PhD
thesis, Department of Computer Science, University of California, Los Angeles,
1995.
7. M. Huisman. Java program veriﬁcation in higher order logic with PVS and Isabelle.
PhD thesis, University of Nijmegen, 2000.
8. B. Jacobs. Weakest precondition reasoning for Java programs with JML annota-
tions. Journal of Logic and Algebraic Programming, 58:61–88, 2004.
9. T. Kleymann. Hoare Logic and auxiliary variables. Formal Aspects of Computing,
11(5):541–566, 1999.
10. F. Mehta and T. Nipkow.
Proving pointer programs in higher-order logic.
In
F. Baader, editor, Automated Deduction — CADE-19, volume 2741 of LNCS, pages
121–135. Springer, 2003.
11. F. Mehta and T. Nipkow. Proving pointer programs in higher-order logic. Infor-
mation and Computation, 2005. To appear.
12. M.J.C. Gordon. Mechanizing programming logics in higher-order logic. In G.M.
Birtwistle and P.A. Subrahmanyam, editors, Current Trends in Hardware Veriﬁca-
tion and Automatic Theorem Proving (Proceedings of the Workshop on Hardware
Veriﬁcation), pages 387–439, Banﬀ, Canada, 1988. Springer, Berlin.
13. T. Nipkow. Hoare logics in Isabelle/HOL. In H. Schwichtenberg and R. Stein-
br¨uggen, editors, Proof and System-Reliability, pages 341–367. Kluwer, 2002.
14. T. Nipkow, L. Paulson, and M. Wenzel. Isabelle/HOL — A Proof Assistant for
Higher-Order Logic, volume 2283 of LNCS. Springer, 2002.
15. M. Norrish. C formalised in HOL. PhD thesis, University of Cambridge, 1998.
16. D. v. Oheimb. Analyzing Java in Isabelle/HOL: Formalization, Type Safety and
Hoare Logic. PhD thesis, Technische Universit¨at M¨unchen, 2001.
17. V. Ortner. Veriﬁcation of BDD Algorithms. Master’s thesis, Technische Universit¨at
M¨unchen, 2004. http://www.veronika.langlotz.info/.
18. L. Prensa Nieto. Veriﬁcation of Parallel Programs with the Owicki-Gries and Rely-
Guarantee Methods in Isabelle/HOL. PhD thesis, Technische Universit¨at M¨unchen,
2002.
19. J. C. Reynolds. Separation logic: A logic for shared mutable data structures. In
Proc. 17th IEEE Symposium on Logic in Computer Science (LICS 2002), pages
55–74, 2002.
20. N. Schirmer. A Veriﬁcation Environment for Sequential Imperative Programs in
Isabelle/HOL. In G. Klein, editor, Proc. NICTA Workshop on OS Veriﬁcation
2004, 2004. ID: 0401005T-1, http://www4.in.tum.de/~schirmer.
21. J. von Wright, J. Hekanaho, P. Luostarinen, and T. L˚angbacka. Mechanizing some
advanced reﬁnement concepts. Formal Methods in System Design, 3:49–81, 1993.
22. P. Wadler. The essence of functional programming. In Proc. 19th ACM Symp.
Principles of Programming Languages, 1992.
23. M. Wenzel.
Miscellaneous Isabelle/Isar examples for higher order logic. Is-
abelle/Isar proof document, 2001.
24. M. Wenzel. Isabelle/Isar — A Versatile Environment for Human-Readable For-
mal Proof Documents. PhD thesis, Institut f¨ur Informatik, Technische Universit¨at
M¨unchen, 2002.
http://tumb1.biblio.tu-muenchen.de/publ/diss/in/2002/wenzel.html.

Can a Higher-Order and a First-Order Theorem
Prover Cooperate?⋆
Christoph Benzm¨uller1, Volker Sorge2, Mateja Jamnik3, and Manfred Kerber2
1 Fachbereich Informatik, Universit¨at des Saarlandes
66041 Saarbr¨ucken, Germany (www.ags.uni-sb.de/~chris)
2 School of Computer Science, The University of Birmingham
Birmingham B15 2TT, England, UK (www.cs.bham.ac.uk/~{vxs|mmk})
3 University of Cambridge Computer Laboratory
Cambridge CB3 0FD, England, UK (www.cl.cam.ac.uk/~mj201)
Abstract. State-of-the-art ﬁrst-order automated theorem proving sys-
tems have reached considerable strength over recent years. However, in
many areas of mathematics they are still a long way from reliably prov-
ing theorems that would be considered relatively simple by humans. For
example, when reasoning about sets, relations, or functions, ﬁrst-order
systems still exhibit serious weaknesses. While it has been shown in the
past that higher-order reasoning systems can solve problems of this kind
automatically, the complexity inherent in their calculi and their ineﬃ-
ciency in dealing with large numbers of clauses prevent these systems
from solving a whole range of problems.
We present a solution to this challenge by combining a higher-order and a
ﬁrst-order automated theorem prover, both based on the resolution prin-
ciple, in a ﬂexible and distributed environment. By this we can exploit
concise problem formulations without forgoing eﬃcient reasoning on ﬁrst-
order subproblems. We demonstrate the eﬀectiveness of our approach on
a set of problems still considered non-trivial for many ﬁrst-order theorem
provers.
1
Introduction
When dealing with problems containing higher-order concepts, such as sets, func-
tions, or relations, today’s state-of-the-art ﬁrst-order automated theorem provers
(ATPs) still exhibit weaknesses on problems considered relatively simple by hu-
mans (cf. [14]). One reason is that the problem formulations use an encoding
in a ﬁrst-order set theory, which makes it particularly challenging when trying
to prove theorems from ﬁrst principles, that is, basic axioms. Therefore, to aid
ATPs in ﬁnding proofs, problems are often enriched by hand-picked additional
lemmata, or axioms of the selected set theory are dropped leaving the theory
incomplete. This has recently motivated extensions of state-of-the-art ﬁrst-order
⋆This work was supported by EPSRC grant GR/M22031 and DFG-SFB 378 (ﬁrst
author), EU Marie-Curie-Fellowship HPMF-CT-2002-01701 (second author), and
EPSRC Advanced Research Fellowship GR/R76783 (third author).
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 415–431, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

416
C. Benzm¨uller et al.
calculi and systems, as for example presented in [14] for the Saturate system.
The extended Saturate system can solve some problems from the SET domain
in the TPTP [24] which Vampire [21] and E-Setheo’s [23] cannot solve.
While it has already been shown in [6,2] that many problems of this nature
can be easily proved from ﬁrst principles using a concise higher-order represen-
tation and the higher-order resolution ATP Leo, the combinatorial explosion
inherent in Leo’s calculus prevents the prover from solving a whole range of
possible problems with one universal strategy. Often higher-order problems re-
quire only relatively few but essential steps of higher-order reasoning, while the
overwhelming part of the reasoning is ﬁrst-order or even propositional level. This
suggests that Leo’s performance could be improved when combining it with a
ﬁrst-order ATP to search eﬃciently for a possible refutation in the subset of
those clauses that are essentially ﬁrst-order.
The advantages of such a combination — further discussed in Sec. 2 — are
not only that many problems can still be eﬃciently shown from ﬁrst principles
in a general purpose approach, but also that problems can be expressed in a
very concise way. For instance, we present 45 problems from the SET domain
of the TPTP-v3.0.1, together with their entire formalisation in less than two
pages in this paper, which is diﬃcult to achieve within a framework that does
not provide λ-abstraction. We use this problem set, which is an extension of the
problems considered in [14], in Sec. 4 to show the eﬀectiveness of our approach.
While many of the considered problems can be proved by Leo alone with some
strategy, the combination of Leo with the ﬁrst-order ATP Bliksem [11] is not
only able to show more problems, but also needs only a single strategy to solve
them. Several of our problems are considered very challenging by the ﬁrst-order
community and ﬁve of them (of which Leo can solve four) have a TPTP rating
of 1.00, saying that they cannot be solved by any TPTP prover to date.
Technically, the combination — described in more detail in Sec. 3 — has been
realised in the concurrent reasoning system Oants [22,8] which enables the co-
operation of hybrid reasoning systems to construct a common proof object. In
our past experiments, Oants has been successfully employed to check the valid-
ity of set equations using higher-order and ﬁrst-order ATPs, model generation,
and computer algebra [5]. While this already enabled a cooperation between
Leo and a ﬁrst-order ATP, the proposed solution could not be classiﬁed as a
general purpose approach. A major shortcoming was that all communication of
partial results had to be conducted via the common proof object, which was
very ineﬃcient for hard examples. Thus, the solved examples from set theory
were considered too trivial, albeit they were often similar to those still consid-
ered challenging in the TPTP in the ﬁrst-order context. In this paper we now
present a novel approach to the cooperation between Leo and Bliksem inside
Oants by decentralising communication. This leads not only to a higher overall
eﬃciency — Sec. 4 details our results — but also to a general purpose approach
based on a single strategy in Leo.

Can a Higher-Order and a First-Order Theorem Prover Cooperate?
417
2
Why Linking Higher-Order and First-Order?
Existing higher-order ATPs generally exhibit deﬁcits in eﬃciently reasoning with
ﬁrst-order problems for several reasons. Unlike in the case of ﬁrst-order provers,
for which sophisticated calculi and strategies, as well as advanced implementa-
tion techniques, such as term indexing [19], have been developed, fully mech-
anisable higher-order calculi are still at a comparably early stage of develop-
ment. Some problems are much harder in higher-order, for instance, uniﬁcation
is undecidable, strong constraining term- and literal-orderings are not available,
extensionality reasoning and set variable instantiation has to be addressed. Nev-
ertheless, for some mathematical problem domains, such as naive set theory, for
instance, automated higher-order reasoning performs very well.
We motivate the need for linking higher-order and ﬁrst-order ATPs with some
examples from Table 1. It contains a range of challenging problems taken from
the TPTP, against which we will evaluate our system in Sec. 4. The problems are
given by the identiﬁers used in the SET domain of the TPTP, and are formalised
in a variant of Church’s simply typed λ-calculus with preﬁx polymorphism. In
classical type theory terms and all their sub-terms are typed. Polymorphism
allows the introduction of type variables such that statements can be made for
all types. For instance, in problem SET014+4 the universally quantiﬁed variable
Xoα denotes a mapping from objects of type α to objects of type o. We use
Church’s notation oα, which stands for the functional type α →o. The reader is
referred to [1] for a more detailed introduction. In the remainder, o will denote
the type of truth values, and small Greek letters will denote arbitrary types.
Thus, Xoα (resp. its η-longform λyα Xy) is actually a characteristic function
denoting the set of elements of type α, for which the predicate associated with
X holds. As further notational convention, we use capital letter variables to
denote sets, functions, or relations, while lower case letters denote individuals.
Types are usually only given in the ﬁrst occurrence of a variable and omitted if
inferable from the context.
The problems in Table 1 employ deﬁned concepts that are speciﬁed in a
knowledge base of hierarchical theories that Leo has access to. All concepts
necessary for deﬁning our problems in Table 1 are given in Table 2. Concepts are
deﬁned in terms of λ-expressions and they may contain other, already speciﬁed
concepts. For presentation purposes, we use customary mathematical symbols
∪, ∩, etc., for some concepts like union, intersection, etc., and we also use inﬁx
notation. For instance, the deﬁnition of union on sets can be easily read in
its more common mathematical representation A ∪B := {x|x ∈A ∨x ∈B}.
Before proving a problem, Leo always expands — recursively, if necessary — all
occurring concepts. This straightforward expansion to ﬁrst principles is realised
by an automated preprocess in our current approach.
SET171+3 We ﬁrst discuss example SET171+3 to contrast our formalisation to
a standard ﬁrst-order one. After recursively expanding the input problem, that is,
completely reducing it to ﬁrst principles, Leo turns it into a negated unit clause.
Since this initial clause is not in normal form, Leo ﬁrst normalises it with explicit

418
C. Benzm¨uller et al.
Table 1. Problems from TPTP for the evaluation of Oants
SET
Problem Formalisation
014+4 ∀Xoα, Yoα, Aoα [[X ⊆A ∧Y ⊆A] ⇒(X ∪Y ) ⊆A]
017+1 ∀xα, yα, zα [UnOrderedPair(x, y) = UnOrderedPair(x, z) ⇒y = z]
066+1 ∀xα, yα [UnOrderedPair(x, y) = UnOrderedPair(y, x)
067+1 ∀xα, yα [UnOrderedPair(x, x) ⊆UnOrderedPair(x, y)]
076+1 ∀xα, yα ∀Zoα x ∈Z ∧y ∈Z ⇒UnOrderedPair(x, y) ⊆Z
086+1 ∀xα ∃yα [y ∈Singleton(x)]
096+1 ∀Xoα, yα [X ⊆Singleton(y) ⇒[X = ∅∨X = Singleton(y)]]
143+3 ∀Xoα, Yoα, Zoα [(X ∩Y ) ∩Z = X ∩(Y ∩Z)]
171+3 ∀Xoα, Yoα, Zoα [X ∪(Y ∩Z) = (X ∪Y ) ∩(X ∪Z)]
580+3 ∀Xoα, Yoα, uα [u ∈ExclUnion(X, Y ) ⇔[u ∈X ⇔u ̸∈Y ]]
601+3 ∀Xoα, Yoα, Zoα[(X ∩Y ) ∪((Y ∩Z) ∪(Z ∩X)) = (X ∪Y ) ∩((Y ∪Z) ∩(Z ∪X))]
606+3 ∀Xoα, Yoα [X\(X ∩Y ) = X\Y ]
607+3 ∀Xoα, Yoα [X ∪(Y \X) = X ∪Y ]
609+3 ∀Xoα, Yoα, Zoα [X\(Y \Z) = (X\Y ) ∪(X ∩Z)]
611+3 ∀Xoα, Yoα [X ∩Y = ∅⇔X\Y = X]
612+3 ∀Xoα, Yoα, Zoα [X\(Y ∪Z) = (X\Y ) ∩(X\Z)]
614+3 ∀Xoα, Yoα, Zoα [(X\Y )\Z = X\(Y ∪Z)]
615+3 ∀Xoα, Yoα, Zoα [(X ∪Y )\Z = (X\Z) ∪(Y \Z)]
623+3 ∀Xoα, Yoα, Zoα [ExclUnion(ExclUnion(X, Y ), Z) = ExclUnion(X, ExclUnion(Y, Z))]
624+3 ∀Xoα, Yoα, Zoα [Meets(X, (Y ∪Z)) ⇔[Meets(X, Y ) ∨Meets(X, Z)]]
630+3 ∀Xoα, Yoα [Misses(X ∩Y, ExclUnion(X, Y ))]
640+3 ∀Roβα, Qoβα [Subrel(R, Q) ⇒Subrel(R, (λuα ⊤) × (λvβ ⊤))]
646+3 ∀xα, yβ [Subrel(Pair(x, y), (λuα ⊤) × (λvβ ⊤)) ]
647+3 ∀Roβα, Xoα [(RDom(R) ⊆X) ⇒Subrel(R, X × RCodom(R))]
648+3 ∀Roβα, Yoβ [(RCodom(R) ⊆Y ) ⇒Subrel(R, RDom(R) × Y )]
649+3 ∀Roβα, Xoα, Yoβ [[RDom(R) ⊆X ∧RCodom(R) ⊆Y ] ⇒Subrel(R, X × Y )]
651+3 ∀Roβα [RDom(R) ⊆Aoα ⇒Subrel(R, A × (λuβ ⊤))]
657+3 ∀Roβα [F ield(R) ⊆((λuα ⊤) ∪(λvβ ⊤))]
669+3 ∀Roαα [Subrel(Id(λuα ⊤), R) ⇒[(λuα ⊤) ⊆RDom(R) ∧(λuα ⊤) = RCodom(R)]]
670+3 ∀Zoα, Roβα, XoαYoβ [IsRelOn(R, X, Y ) ⇒IsRelOn(RestrictRDom(R, Z), Z, Y )]
671+3 ∀Zoα, Roβα, Xoα, Yoβ [[IsRelOn(R, X, Y ) ∧X ⊆Z] ⇒RestrictRDom(R, Z) = R]
672+3 ∀Zoβ, Roβα, XoαYoβ [IsRelOn(R, X, Y ) ⇒IsRelOn(RestrictRCodom(R, Z), X, Z)]
673+3 ∀Zoβ, Roβα, Xoα, Yoβ [[IsRelOn(R, X, Y ) ∧Y ⊆Z] ⇒RestrictRCodom(R, Z) = R]
680+3 ∀Roβα, Xoα, Yoβ [IsRelOn(R, X, Y ) ⇒
[∀uα u ∈X ⇒[u ∈RDom(R) ⇔∃vβ v ∈Y ∧R(u, v)]]]
683+3 ∀Roβα, Xoα, Yoβ [IsRelOn(R, X, Y ) ⇒
[∀vβ v ∈Y ⇒[v ∈RCodom(R) ⇒∃uα u ∈X ∧u ∈RDom(R)]]]
684+3 ∀Poβα, Roγβ, xα, zγ [RelComp(P, R)xz ⇔∃yβ P xy ∧Ryz]
686+3 ∀Zoα, Roγβ, xα [x ∈InverseImageR(R, Z) ⇔∃yα Rxy ∧x ∈Z]
716+4 ∀Fβα, Gγβ [[Inj(F ) ∧Inj(G)] ⇒Inj(G ◦F )]
724+4 ∀Fβα, Gγβ, Hγβ [[F ◦G = F ◦H ∧Surj(F )] ⇒G = H]
741+4 ∀Fβα, Gγβ, Hαγ [[Inj((F ◦G) ◦H) ∧Surj((G ◦H) ◦F ) ∧Surj((H ◦F ) ◦G)] ⇒Bij(H)]
747+4 ∀Fβα, Gγβ, ◁1
oαα, ◁2
oββ, ◁3
oγγ [[IncreasingF(F, ◁1, ◁2) ∧DecreasingF(G, ◁2, ◁3)] ⇒
DecreasingF(F ◦G, ◁1, ◁3)]
752+4 ∀Xoα, Yoα, Fβα [ImageF(F, X ∪Y ) = ImageF(F, X) ∪ImageF(F, Y )]
753+4 ∀Xoα, Yoα, Fβα [ImageF(F, X ∩Y ) ⊆ImageF(F, X) ∩ImageF(F, Y )]
764+4 ∀Fβα [InverseImageF(F, ∅) = ∅]
770+4 ∀Roβα, Qoβα [[EquivRel(R) ∧EquivRel(Q)] ⇒
[EquivClasses(R) = EquivClasses(Q) ∨Disjoint(EquivClasses(R), EquivClasses(Q))]]
clause normalisation rules to reach some proper initial clauses. In our concrete
case, this normalisation process leads to the following unit clause consisting of a
(syntactically not solvable) uniﬁcation constraint (here Boα, Coα, Doα are Skolem
constants and Bx is obtained from expansion of x ∈B):
[(λxα Bx ∨(Cx ∧Dx)) =? (λxα (Bx ∨Cx) ∧(Bx ∨Dx))]
Note that negated primitive equations are generally automatically converted
by Leo into uniﬁcation constraints. This is why [(λxα Bx ∨(Cx ∧Dx)) =?

Can a Higher-Order and a First-Order Theorem Prover Cooperate?
419
Table 2. Deﬁned concepts occurring in problems from Table 1
Deﬁned Notions in Theory Typed Set
∈
:= λxα, Aoα [Ax]
∅:= [λxα ⊥]
⊆
:= λAoα, Boα [∀xα x ∈A ⇒x ∈B]
∪
:= λAoα, Boα [λxα x ∈A ∨x ∈B]
∩
:= λAoα, Boα [λxα x ∈A ∧x ∈B]
:= λAoα [λxα x /∈A]
\
:= λAoα, Boα [λxα x ∈A ∧x /∈B]
ExclUnion( , ) := λAoα, Boα [(A\B) ∪(B\A)]
Disjoint( , ) := λAoα, Boα [A ∩B = ∅]
Meets( , ) := λAoα, Boα [∃xα x ∈A ∧x ∈B]
Misses( , ) := λAoα, Boα [¬∃xα x ∈A ∧x ∈B]
Deﬁned Notions in Theory Relation
UnOrderedPair( , ) := λxα, yα [λuα u = x ∨u = y]
Singleton( ) := λxα [λuα u = x]
Pair( , ) := λxα, yβ [λuα, vβ u = x ∧v = y]
×
:= λAoα, Boβ [λuα, vβ u ∈A ∧v ∈B]
RDom( ) := λRoβα [λxα ∃yβ Rxy]
RCodom( ) := λRoβα [λyβ ∃xα Rxy]
Subrel( , ) := λRoβα, Qoβα [∀xα ∀yα Rxy ⇒Qxy]
Id( ) := λAoα [λxα, yα x ∈A ∧x = y]
F ield( ) := λRoβα [RDom(B) ∪RCodom(R)]
IsRelOn( , , ) := λRoβα, Aoα λBoβ [∀xα, yβ Rxy ⇒(x ∈A ∧x ∈B)]
RestrictRCodom( , ) := λRoβα, Aoα [λxα, yβ x ∈A ∧Rxy]
RelComp( , ) := λRoβα, Qoγβ [λxα, zγ ∃yβ Rxy ∧Ryz]
InverseImageR( , ) := λRoβα, Boβ [λxα ∃yβ y ∈B ∧Rxy]
Reflexive( ) := λRoβα [∀xα Rxx]
Symmetric( ) := λRoβα [∀xα ∀yα Rxy ⇒Ryx]
T ransitive( ) := λRoβα [∀xα ∀yα ∀zα Rxy ∧Ryz ⇒Rxz]
EquivRel( ) := λRoβα [Reflexive(R) ∧Symmetric(R) ∧T ransitive(R)]
EquivClasses( ) := λRoαα [λAoα ∃uα u ∈A ∧∀vα v ∈A ⇔Ruv]
Deﬁned Notions in Theory Function
Inj( ) := λFβα [∀xα, yβ F (x) = F (y) ⇒x = y]
Surj( ) := λFβα [∀yβ ∃xα y = F (x)]
Bij( ) := λFβα Surj(F ) ∧Inj(F )
ImageF( , ) := λFβα, Aoα [λyβ ∃xα x ∈A ∧y = F (x)]
InverseImageF( , ) := λFβα, Boβ [λxα ∃yβ y ∈B ∧y = F (x)]
◦
:= λFβα, Gγβ [λxα G(F (x))]
IncreasingF( , , ) := λFβα, ◁1
oαα, ◁2
oββ [∀xα, yα x ◁1 y ⇒F (x) ◁2 F (y)]
DecreasingF( , , ) := λFβα, ◁1
oαα, ◁2
oββ [∀xα, yα x ◁1 y ⇒F (y) ◁2 F (x)]
(λxα (Bx ∨Cx) ∧(Bx ∨Dx))] is generated, and not [(λxα Bx ∨(Cx ∧Dx)) =
(λxα (Bx∨Cx)∧(Bx∨Dx))]F . Observe, that we write [.]T and [.]F for positive
and negative literals, respectively. Leo then applies its goal directed functional
and Boolean extensionality rules which replace this uniﬁcation constraint by the
negative literal (where x is a Skolem constant):
[(Bx ∨(Cx ∧Dx)) ⇔((Bx ∨Cx) ∧(Bx ∨Dx))]F
This unit clause is again not normal; normalisation, factorisation and subsump-
tion yield the following set of clauses:
[Bx]F
[Bx]T ∨[Cx]T
[Bx]T ∨[Dx]T
[Cx]F ∨[Dx]F
This set is essentially of propositional logic character and trivially refutable. Leo
needs 0.56 seconds for solving the problem and generates a total of 36 clauses.
Let us consider now this same example SET171+3 in its ﬁrst-order formula-
tion from the TPTP (see Table 3). We can observe that the assumptions provide

420
C. Benzm¨uller et al.
Table 3. TPTP problem SET171+3 — distributivity of ∪over ∩
Assumptions: ∀B, C, x [x ∈(B ∪C) ⇔x ∈B ∨x ∈C]
(1)
∀B, C, x [x ∈(B ∩C) ⇔x ∈B ∧x ∈C]
(2)
∀B, C [B = C ⇔B ⊆C ∧C ⊆B]
(3)
∀B, C [B ∪C = C ∪B]
(4)
∀B, C [B ∩C = C ∩B]
(5)
∀B, C [B ⊆C ⇔∀x x ∈B ⇒x ∈C]
(6)
∀B, C [B = C ⇔∀x x ∈B ⇔x ∈C]
(7)
Proof Goal: ∀B, C, D [B ∪(C ∩D) = (B ∪C) ∩(B ∪D)]
(8)
only a partial axiomatisation of naive set theory. On the other hand, the speciﬁ-
cation introduces lemmata that are useful for solving the problem. In particular,
assumption (7) is trivially derivable from (3) with (6). Obviously, clausal normal-
isation of this ﬁrst-order problem description yields a much larger and more diﬃ-
cult set of clauses. Furthermore, deﬁnitions of concepts are not directly expanded
as in Leo. It is therefore not surprising that most ﬁrst-order ATPs still fail to
prove this problem. In fact, very few TPTP provers were successful in proving
SET171+3. Amongst them are Muscadet 2.4. [20], Vampire 7.0, and Satu-
rate. The natural deduction system Muscadet uses special inference rules for
sets and needs 0.2 seconds to prove this problem. Vampire needs 108 seconds.
The Saturate system [14] (which extends Vampire with Boolean extension-
ality rules that are a one-to-one correspondence to Leo’s rules for Extensional
Higher-Order Paramodulation [3]) can solve the problem in 2.9 seconds while
generating 159 clauses. The signiﬁcance of such comparisons is clearly limited
since diﬀerent systems are optimised to a diﬀerent degree. One noted diﬀerence
between the experiments with ﬁrst-order provers listed above, and the experi-
ments with Leo and Leo-Bliksem is that ﬁrst-order systems often use a case
tailored problem representation (e.g., by avoiding some base axioms of the ad-
dressed theory), while Leo and Leo-Bliksem have a harder task of dealing with
a general (not speciﬁcally tailored) representation.
For the experiments with Leo and the cooperation of Leo with the ﬁrst-order
theorem prover Bliksem, λ-abstraction as well as the extensionality treatment
inherent in Leo’s calculus [4] is used. This enables a theoretically4 Henkin-
complete proof system for set theory. In the above example SET171+3, Leo gen-
erally uses the application of functional extensionality to push extensional uniﬁ-
cation constraints down to base type level, and then eventually applies Boolean
extensionality to generate clauses from them. These are typically much simpler
and often even propositional-like or ﬁrst-order-like (FO-like, for short), that is,
they do not contain any ‘real’ higher-order subterms (such as a λ-abstraction or
4 For pragmatic reasons, such as eﬃciency, most of Leo’s tactics are incomplete. Leo’s
philosophy is to rely on a theoretically complete calculus, but to practically provide
a set of complimentary strategies so that these cover a broad range of theorems.

Can a Higher-Order and a First-Order Theorem Prover Cooperate?
421
embedded equations), and are therefore suitable for treatment by a ﬁrst-order
ATP or even a propositional logic decision procedure.
SET624+3 Sometimes, extensionality treatment is not required and the origi-
nally higher-order problem is immediately reduced to only FO-like clauses. For
example, after expanding the deﬁnitions, problem SET624+3 yields the following
clause (where Boα, Coα, Doα are again Skolem constants):
[(∃xα (Bx ∧(Cx ∨Dx)) ⇔((∃xα Bx ∧Cx) ∨(∃xα Bx ∧Dx))]F
Normalisation results in 26 FO-like clauses, which present a hard problem for
Leo: it needs approx. 35 seconds (see Sec. 4) to ﬁnd a refutation, whereas ﬁrst-
order ATPs only need a fraction of a second.
SET646+3 Sometimes, problems are immediately refuted after the initial clause
normalisation. For example, after deﬁnition expansion in problem SET646+3 we
get the following clause (where Boα, Coα, xα are again Skolem constants):
[Ax ⇒(∀yβ By ⇒(∀uα ∀vβ (u = x ∧v = y) ⇒((¬⊥) ∧(¬⊥))))]F
Normalisation in Leo immediately generates a basic refutation (i.e., a clause
[⊥]T ∨[⊥]T ) without even starting proof search.
SET611+3 The examples discussed so far all essentially apply extensionality
treatment and normalisation to the input problem in order to immediately gen-
erate a set of inconsistent FO-like clauses. Problem SET611+3 is more compli-
cated as it requires several reasoning steps in Leo before the initially consistent
set of available FO-like clauses grows into an inconsistent one. After deﬁnition
expansion, Leo is ﬁrst given the input clause:
[∀Aoα, Boα (λxα (Ax ∧Bx)) = (λxα ⊥)) ⇔(λxα (Ax ∧¬Bx)) = (λxα Ax)]F
which it normalises into:
[(λxα (Ax ∧Bx)) =? (λxα ⊥)] ∨[(λxα (Ax ∧¬Bx)) =? (λxα Ax)]
(9)
[(λxα (Ax ∧Bx)) = (λxα ⊥)]T ∨[(λxα (Ax ∧¬Bx)) = (λxα Ax)]T
(10)
As mentioned before, the uniﬁcation constraint (9) corresponds to:
[(λxα (Ax ∧Bx)) = (λxα ⊥)]F ∨[(λxα (Ax ∧¬Bx)) = (λxα Ax)]F
(11)
Leo has to apply to each of these clauses and to each of their literals appro-
priate extensionality rules. Thus, several rounds of Leo’s set-of-support-based
reasoning procedure are required, so that all necessary extensionality reasoning
steps are performed, and suﬃciently many FO-like clauses are generated which
can be refuted by Bliksem.
In summary, each of the examples discussed in this section exposes a motiva-
tion for our higher-order/ﬁrst-order cooperative approach to theorem proving.
In particular, they show that:

422
C. Benzm¨uller et al.
– Higher-order formulations allow for a concise problem representation which
often allows easier and faster proof search than ﬁrst-order formulations.
– Higher-order problems can often be reduced to a set of ﬁrst-order clauses
that can be more eﬃciently handled by a ﬁrst-order ATP.
– Some problems are trivially refutable after clause normalisation.
– Some problems require in-depth higher-order reasoning before a refutable
ﬁrst-order clause set can be extracted.
3
Higher-Order/First-Order Cooperation via Oants
The cooperation between higher-oder and ﬁrst-order reasoners, which we inves-
tigate in this paper, is realised in the concurrent hierarchical blackboard archi-
tecture Oants [7]. We ﬁrst describe in Sec. 3.1 the existing Oants architecture.
In order to overcome some of its problems, in particular eﬃciency problems, we
devised within Oants a new and improved cooperation method for the higher-
order ATP Leo and ﬁrst-order provers (in particular, Bliksem) – we describe
this in Sec. 3.2. We address the question of how to generate the necessary clauses
in Sec. 3.3, and discuss soundness and completeness of our implementation of
the higher-order/ﬁrst-order cooperation in Sec. 3.4.
3.1
Oants
Oants was originally conceived to support interactive theorem proving but was
later extended to a fully automated proving system [22,8]. Its basic idea is to
compose a central proof object by generating, in each proof situation, a ranked
list of potentially applicable inference steps. In this process, all inference rules,
such as calculus rules or tactics, are uniformly viewed with respect to three
sets: premises, conclusions, and additional parameters. The elements of these
three sets are called arguments of the inference rule and they usually depend
on each other. An inference rule is applicable if at least some of its arguments
can be instantiated with respect to the given proof context. The task of the
Oants architecture is now to determine the applicability of inference rules by
computing instantiations for their arguments.
The architecture consists of two layers. On the lower layer, possible instanti-
ations of the arguments of individual inference rules are computed. In particular,
each inference rule is associated with its own blackboard and concurrent pro-
cesses, one for each argument of the inference rule. The role of every process is
to compute possible instantiations for its designated argument of the inference
rule, and to record these on the blackboard. The computations are carried out
with respect to the given proof context and by exploiting information already
present on the blackboard, that is, argument instantiations computed by other
processes. On the upper layer, the information from the lower layer is used for
computing and heuristically ranking the inference rules that are applicable in
the current proof state. The most promising rule is then applied to the central

Can a Higher-Order and a First-Order Theorem Prover Cooperate?
423
proof object and the data on the blackboards is cleared for the next round of
computations.
Oants employs resource reasoning to guide search.5 This enables the con-
trolled integration (e.g., by specifying time-outs) of full-ﬂedged external rea-
soning systems such as automated theorem provers, computer algebra systems,
or model generators into the architecture. The use of the external systems is
modelled by inference rules, usually one for each system. Their corresponding
computations are encapsulated in one of the independent processes in the ar-
chitecture. For example, an inference rule modelling the application of an ATP
has its conclusion argument set to be an open goal. A process can then place
an open goal on the blackboard, where it is picked up by a process that applies
the prover to it. Any computed proof or partial-proof from the external system
is again written to the blackboard from where it is subsequently inserted into
the proof object when the inference rule is applied. While this setup enables
proof construction by a collaborative eﬀort of diverse reasoning systems, the co-
operation can only be achieved via the central proof object. This means that all
partial results have to be translated back and forth between the syntaxes of the
integrated systems and the language of the proof object. Since there are many
types of integrated systems, the language of the proof object — a higher-order
language even richer than Leo’s, together with a natural deduction calculus —
is expressive but also cumbersome. This leads not only to a large communication
overhead, but also means that complex proof objects have to be created (large
clause sets need to be transformed into large single formulae to represent them in
the proof object; the support for this in Oants to date is ineﬃcient), even if the
reasoning of all systems involved is clause-based. Consequently, the cooperation
between external systems is typically rather ineﬃcient [5].
3.2
Cooperation via a Single Inference Rule
In order to overcome the problem of the communication bottleneck described
above, we devised a new method for the cooperation between a higher-order
and a ﬁrst-order theorem prover within Oants. Rather than modelling each
theorem prover as a separate inference rule (and hence needing to translate
the communication via the language of the central proof object), we model the
cooperation between a higher-order (concretely, Leo) and a ﬁrst-order theorem
prover (in our case study Bliksem) in Oants as a single inference rule. The
cooperation between these two theorem provers is carried out directly and not via
the central proof object. This avoids translating clause sets into single formulae
and back. While in our previous approach the cooperation between Leo and
an FO-ATP was modelled at the upper layer of the Oants architecture, our
new approach presented in this paper models their cooperation by exploiting the
lower layer of the Oants blackboard architecture. This is not an ad hoc solution,
5 Oants provides facilities to deﬁne and modify the processes at run-time. But notice
that we do not use these advanced features in the case study presented in this paper.

424
C. Benzm¨uller et al.
but rather, it demonstrates Oants’s ﬂexibility in modelling the integration of
cooperative reasoning systems.
Concretely, the single inference rule modelling the cooperation between Leo
and a ﬁrst-order theorem prover needs four arguments to be applicable: (1) an
open proof goal, (2) a partial Leo proof, (3) a set of FO-like clauses in the
partial proof, (4) a ﬁrst-order refutation proof for the set of FO-like clauses.
Each of these arguments is computed, that is, its instantiation is found, by
an independent process. The ﬁrst process ﬁnds open goals in the central proof
object and posts them on the blackboard associated with the new rule. The
second process starts an instance of the Leo theorem prover for each new open
goal on the blackboard. Each Leo instance maintains its own set of FO-like
clauses. The third process monitors these clauses, and as soon as it detects a
change in this set, that is, if new FO-like clauses are added by Leo, it writes
the entire set of clauses to the blackboard. Once FO-like clauses are posted, the
fourth process ﬁrst translates each of the clauses directly into a corresponding
one in the format of the ﬁrst-order theorem prover, and then starts the ﬁrst-order
theorem prover on them. Note that writing FO-like clauses on the blackboard is
by far not as time consuming as generating higher-order proof objects. As soon
as either Leo or the ﬁrst-order prover ﬁnds a refutation, the second process
reports Leo’s proof or partial proof to the blackboard, that is, it instantiates
argument (2). Once all four arguments of our inference rule are instantiated, the
rule can be applied and the open proof goal can be closed in the central proof
object. That is, the open goal can be proved by the cooperation between Leo
and a ﬁrst-order theorem prover. When computing applicability of the inference
rule, the second and the fourth process concurrently spawn processes running
Leo or a ﬁrst-order prover on a diﬀerent set of FO-like clauses. Thus, when
actually applying the inference rule, all these instances of provers working on
the same open subgoal are stopped.
The cooperation can be carried out between any ﬁrst-order theorem prover
and Leo instantiated with any strategy, thus resulting in diﬀerent instantiations
of the inference rule discussed above. While several ﬁrst-order provers are inte-
grated in Oants and could be used, Bliksem was suﬃcient for the case study
reported in this paper (see Sec. 4). In most cases, more than one Bliksem pro-
cess was necessary. But as the problems were always concerned with only one
subgoal, only one Leo process had to be started.
Our approach to the cooperation between a higher-order and a ﬁrst-order
theorem prover has many advantages. The main one is that the communication
is restricted to the transmission of clauses, and thus it avoids intermediate trans-
lation into the language of the central proof object. This signiﬁcantly reduces
the communication overhead and makes eﬀective proving of more involved theo-
rems feasible. A disadvantage of this approach is that we cannot easily translate
and integrate the two proof objects produced by Leo and Bliksem into the
central proof object maintained by Oants, as is possible when applying only
one prover per open subgoal. Providing such translation remains future work.
The repercussions will be discussed in more detail in Sec. 3.4.

Can a Higher-Order and a First-Order Theorem Prover Cooperate?
425
3.3
Extracting FO-Like Clauses from Leo
Crucial to a successful cooperation between Leo and a ﬁrst-order ATP is obvi-
ously the generation of FO-like clauses. Leo always maintains a heap of FO-like
clauses. In the current Leo system this heap remains rather small since Leo’s
standard calculus intrinsically avoids primitive equality and instead provides
a rule that replaces occurrences of primitive equality with their corresponding
Leibniz deﬁnitions which are higher-order. The Leibniz principle deﬁnes equal-
ity as follows =oαα:= λxα λyα [∀Poα Px ⇒Py]. Leo also provides a rule which
replaces syntactically non-uniﬁable uniﬁcation constraints between terms of non-
Boolean base type by their respective representations that use Leibniz equality.
While the clauses resulting from these rules are still refutable in Leo, they are
not refutable by Bliksem without adding set theory axioms. We illustrate the
eﬀect by the following simple example, where aι, bι, and fιι are constants:
a = b ⇒f(a) = f(b)
Depending on whether we work with primitive equality or Leibniz equality this
problem is reduced to the clause sets in either (12) or (13) respectively (in the
latter Poι is a new free variable, and Qoι is a new Skolem constant):
[a = b]T
[f(a) =? f(b)]
(12)
[Pa]F ∨[Pb]T
[Q(f(a))]T
[Q(f(b))]F
(13)
While the former is obviously refutable in Bliksem, the latter is not. Leo, how-
ever, still ﬁnds a refutation for the latter and generates the crucial substitution
P ←λxα Q(f(x)) by higher-order pre-uniﬁcation.
To circumvent this problem, we adapted the relevant rules in Leo. Instead
of immediately constructing Leibniz representation of clauses, an intermediate
representation containing primitive equality is generated and dumped on the
heap of FO-like clauses. As a consequence, additional useful FO-like clauses are
accumulated and the heap can become quite large, in particular, since we do
not apply any subsumption to the set of FO-like clauses (this is generally done
more eﬃciently by a ﬁrst-order ATP anyway). Recent research has shown that
Leibniz equality is generally very bad for automating higher-order proof search.
Thus, future work in Leo includes providing support for full primitive equality
and avoiding Leibniz equations.
3.4
Soundness and Completeness of the Cooperation
Clearly, soundness and completeness properties depend on the corresponding
properties of the systems involved, in our case, of Leo and Bliksem.
Soundness: The general philosophy of Oants is to ensure the correctness of
proofs by the generation of explicit proof objects, which can be checked inde-
pendently from the proof generation. In particular, reasoning steps of ATPs have
to be translated into Oants’s natural deduction calculus via the Tramp proof

426
C. Benzm¨uller et al.
transformation system [17] to be machine-checkable. Since the cooperative proof
result of Leo-Bliksem cannot yet be directly inserted into the centralised proof
object, the generation of a machine-checkable proof object is not yet supported.
One possible solution is to insert Bliksem proofs into Leo proofs at the right
places. Then, the modiﬁed Leo proofs can be inserted into the centralised proof
object, and hence, explicit proof objects can be generated by Oants. In princi-
ple, there is no problem with this, however, it is not yet implemented.
While there are many advantages in guaranteeing correctness of proofs by
checking them, it is worth noting that the combination of Leo and Bliksem
is sound under the assumption that the two systems are sound. Namely, to
prove a theorem it is suﬃcient to show that a subset of clauses generated in
the proof is inconsistent. If Leo generates an inconsistent set of clauses, then
it does so correctly by assumption, be it a FO-like set or not. Assuming that
the translation from FO-like clauses to truly ﬁrst-order clauses preserves consis-
tency/inconsistency, then a set of clauses that is given to Bliksem is inconsistent
only if Leo generated an inconsistent set of clauses in the ﬁrst place. By the as-
sumption that Bliksem is sound follows that Bliksem will only generate the
empty clause when the original clause set was inconsistent.
Thus, soundness of our cooperative approach critically relies only on the
soundness of the selected transformational mapping from FO-like clauses to
proper ﬁrst-order clauses. We use the mapping from Tramp, which has been
previously shown to be sound and is based on [16]. Essentially, it injectively maps
expressions such as P(f(a)) to expressions such as @1
pred(P, @1
fun(f, a)), where
the @ are new ﬁrst-order operators describing function and predicate applica-
tion for particular types and arities. The injectivity of the mapping guarantees
soundness, since it allows each proof step to be mapped back from ﬁrst-order to
higher-order. Hence, our higher-order/ﬁrst-order cooperative approach between
Leo and Bliksem is sound.
Completeness: Completeness (in the sense of Henkin completeness) can in prin-
ciple be achieved in higher-order systems, but practically, the strategies used
are typically not complete for eﬃciency reasons. Let us assume that we use a
complete strategy in Leo. All that our procedure does is pass FO-like clauses
to Bliksem. Hence, no proofs can be lost in this process. That is, completeness
follows trivially from the completeness of Leo.
The more interesting question is whether particular cooperation strategies
will be complete as well. For instance, in Leo we may want to give higher
preference to real higher-order steps which guarantee the generation of ﬁrst-
order clauses.
4
Experiments and Results
We conducted several experiments to evaluate our hybrid reasoning approach.
In particular, we concentrated on problems given in Table 1. We investigated
several Leo strategies in order to compare Leo’s individual performance with
the performance of the Leo-Bliksem cooperation. Our example set diﬀers from

Can a Higher-Order and a First-Order Theorem Prover Cooperate?
427
the one in [14] in that it contains some additional problems, and it also omits
an entry for problem SET108+1. This problem addresses the universal class and
can therefore not be formalised in type theory in the same concise way as the
other examples, but only in a way very similar to the one given in TPTP.
Table 4 presents the results of our experiments. All timings given in the
table are in seconds. The ﬁrst column contains the TPTP identiﬁer of the prob-
lem. The second column relates some of the problems to their counterparts in the
Journal of Formalized Mathematics (JFM; see mizar.org/JFM) where they orig-
inally stem from. This eases the comparison with the results in [6,2], where the
problems from the JFM article Boolean Properties of Sets were already solved:
the problems are named with preﬁx ‘B:’. Preﬁx ‘RS1:’ stands for the JFM ar-
ticle Relations Deﬁned on Sets. The third column lists the TPTP (v3.0.1 as of
20 January 2005, see http://www.tptp.org) diﬃculty rating of the problem,
which indicates how hard the problem is for ﬁrst-order ATPs (diﬃculty rating
1.00 indicates that no TPTP prover can solve the problem).
The fourth, ﬁfth and sixth columns list whether Saturate, Muscadet
(v2.4) and E-Setheo (csp04), respectively, can (+) or cannot (–) solve a prob-
lem. The seventh column lists the timing results for Vampire (v7). The results
for Saturate are taken from [14] (a ‘?’ in Table 4 indicates that the result
was not listed in [14] and is thus unavailable). The results for Muscadet and
E-Setheo are taken from the on-line version of the solutions provided with the
TPTP. Since the listed results were obtained from diﬀerent experiments on dif-
ferent platforms, their run-time comparison would be unfair, and was thus not
carried out. The timings for Vampire, on the other hand, are based on private
communication with A. Voronkov and they were obtained on a computer with a
very similar speciﬁcation as we used for the Leo-Bliksem timings. Note, that
the results for Vampire and E-Setheo reported in [14] diﬀer for some of the
problems to the ones in TPTP. This is probably due to diﬀerent versions of the
systems tested, for instance, the TPTP uses Vampire version 7, while the results
reported in [14] are based on version 5. The results in columns four through to
seven show that some problems are still very hard for ﬁrst-order ATPs, as well
as for the special purpose theorem prover Muscadet. Column eight and nine
in Table 4 list the results for Leo alone and Leo-Bliksem, respectively. Each
of these two columns is further divided into sub-columns to allow for a detailed
comparison.
All our experiments (for the values of Leo and Leo-Bliksem) were con-
ducted on a 2.4 GHz Xenon machine with 1GB of memory and an overall time
limit of 100 seconds. For our experiments with Leo alone in column eight in
Table 4 we tested four diﬀerent strategies. Mainly, they diﬀer in their treat-
ment of equality and extensionality. This ranges from immediate expansion of
primitive equality with Leibniz equality and limited extensionality reasoning,
STANDARD (ST), to immediate expansion of primitive equality and moderate
extensionality reasoning, EXT, to delayed expansion of primitive equality and
moderate extensionality reasoning, EXT-INPUT (EI), and ﬁnally to delayed ex-
pansion of primitive equality and advanced recursive extensionality reasoning,

428
C. Benzm¨uller et al.
Table 4. Experimental data for the benchmark problems given in Table 1
TPTP-
Mizar
Diffi- Satu-
Mus
E-Se- Vamp-
LEO
LEO-Bliksem
Problem
Problem culty
rate
cadet
theo
ire 7
Strat. Cl.
Time Cl. Time FOcl FOtm GnCl
SET014+4
.67
+
+
+
.01
ST
41
.16
34 6.76
19
.01
7
SET017+1
.56
–
–
+
.03
EXT 3906 57.52 25 8.54
16
.01
74
SET066+1
1.00
?
–
–
–
–
–
–
26 6.80
20
10
56
SET067+1
.56
+
+
+
.04
ST
6
.02
13 .32
16
.01
12
SET076+1
.67
+
–
+
.00
–
–
–
10 .47
18
.01
35
SET086+1
.22
+
–
+
.04
ST
4
.01
4
.01
N/A N/A
N/A
SET096+1
.56
+
–
+
.03
–
–
–
27 7.99
14
.01
25
SET143+3 B:67
.67
+
+
+
68.71
EIR
37
.38
33 7.93
18
.01
19
SET171+3 B:71
.67
+
+
–
108.31 EIR
36
.56
25 4.75
19
.01
20
SET580+3 B:23
.44
+
+
+
14.71
EIR
25
.19
6
2.73
8
.01
13
SET601+3 B:72
.22
+
+
+
168.40 EIR
145
2.20
55 4.96
8
.01
13
SET606+3 B:77
.78
+
–
+
62.02
EIR
21
.33
17 10.8
15
.01
5
SET607+3 B:79
.67
+
+
+
65.57
EIR
22
.31
17 7.79
15
.01
6
SET609+3 B:81
.89
+
+
–
161.78 EIR
37
.60
26 6.50
19
10
17
SET611+3 B:84
.44
+
–
+
60.20
EIR
996
12.69 72 32.14 38
.01
101
SET612+3 B:85
.89
+
–
–
113.33 EIR
41
.54
18 3.95
6
.01
7
SET614+3 B:88
.67
+
+
–
157.88 EIR
38
.46
19 4.34
16
.01
17
SET615+3 B:89
.67
+
+
–
109.01 EIR
38
.57
17 3.59
6
.01
9
SET623+3 B:99
1.00
?
–
–
–
EXT 43
8.84
23 9.54
10
.01
14
SET624+3 B:100
.67
+
–
+
.04
ST
4942 34.71 54 9.61
46
.01
212
SET630+3 B:112
.44
+
–
+
60.39
EIR
11
.07
6
.08
8
10
4
SET640+3 RS1:2
.22
+
–
+
70.41
EIR
2
.01
2
.01
N/A N/A
N/A
SET646+3 RS1:8
.56
+
–
+
59.63
EIR
2
.01
2
.01
N/A N/A
N/A
SET647+3 RS1:9
.56
+
–
+
64.21
EIR
26
.15
13 .30
13
.01
15
SET648+3 RS1:10
.56
+
–
+
64.22
EIR
26
.15
14 .30
13
.01
16
SET649+3 RS1:11
.33
–
–
+
63.77
EIR
45
.30
29 5.49
12
.01
16
SET651+3 RS1:13
.44
–
–
+
63.88
EIR
20
.10
11 .16
10
10
11
SET657+3 RS1:19
.67
+
–
+
1.44
EIR
2
.01
2
.01
N/A N/A
N/A
SET669+3 RS1:19
.22
–
–
+
.34
EI
35
.22
35 .23
N/A N/A
N/A
SET670+3 RS1:33
1.00
?
–
–
–
EXT 15
.17
17 .36
16
.01
6
SET671+3 RS1:34
.78
–
–
+
218.02 EIR
78
.64
7
2.71
10
.01
14
SET672+3 RS1:35
1.00
?
–
–
–
EXT 27
.4
30 .70
21
.01
11
SET673+3 RS1:36
.78
–
–
+
47.86
EIR
78
.65
14 5.66
14
.01
16
SET680+3 RS1:47
.33
+
–
+
.07
ST
185
.88
29 4.61
18
.01
24
SET683+3 RS1:50
.22
+
–
+
.06
ST
46
.20
35 8.90
18
10
24
SET684+3 RS1:51
.78
–
–
+
.33
ST
275
2.45
46 5.95
26
.01
47
SET686+3 RS1:53
.56
–
–
+
.11
ST
274
2.36
46 5.37
26
.01
46
SET716+4
.89
+
+
–
–
ST
39
.45
18 3.81
18
.01
118
SET724+4
.89
+
+
–
–
EXT 154
2.75
18 7.21
15
10
23
SET741+4
1.00
?
–
–
–
–
–
–
–
–
–
–
–
SET747+4
.89
–
+
–
–
ST
34
.46
25 1.11
18
10
10
SET752+4
.89
?
+
–
–
–
–
–
50 6.60
48
.01
4363
SET753+4
.89
?
+
–
–
–
–
–
15 3.07
12
10
19
SET764+4
.56
+
+
+
.02
EI
9
.05
8
.04
N/A N/A
N/A
SET770+4
.89
+
+
–
–
–
–
–
–
–
–
–
–
EXT-INPUT-RECURSIVE (EIR). Column eight in Table 4 presents the fastest
strategy for a respective problem (Strat.), the number of clauses generated by
Leo (Cl.), and the total runtime (Time). While occasionally there were more
than one Leo strategy that could solve a problem, it should be noted that none
of the strategies was successful for all the problems solved by Leo.
In contrast to the experiments with Leo alone, we used only the EXT-INPUT
strategy for our experiments with the Leo-Bliksem cooperation. Column nine in
Table 4 presents the number of clauses generated by Leo (Cl.) together with the
time (Time), and in addition, the number of ﬁrst-order clauses sent to Bliksem
(FOcl), the time used by Bliksem (FOtm), and the number of clauses generated

Can a Higher-Order and a First-Order Theorem Prover Cooperate?
429
by Bliksem (GnCl). Note, that we give the data only for the ﬁrst instance that
Bliksem actually succeeded in solving the problem. This time also includes
the time needed to write and process input and output ﬁles over the network.
While Leo and instances of Bliksem were running in separate threads (each
run of Bliksem was given a 50 second time limit), the ﬁgures given in the
‘Time’ column reﬂect the overall time needed for a successful proof. That is,
it contains the time needed by all concurrent processes: Leo’s own process as
well as those processes administering the various instances of Bliksem. Since
all these processes ran on a single processor, there is potential to ameliorate the
overall runtimes by using real multiprocessing.
Note also, that the number of clauses in Leo’s search space is typically low
since subsumption is enabled. Subsumption, however, was not enabled for the
accumulation of FO-like clauses in Leo’s bag of FO-like clauses. This is why
there are usually more clauses in this bag (which is sent to Bliksem) than there
are available in Leo’s search space. Finally, observe that for some problems a
refutation was found after Leo’s clausal normalisation, and therefore Bliksem
was not applicable (N/A).
While Leo itself can solve a majority of the considered problems with some
strategy, the Leo-Bliksem cooperation can solve more problems and, moreover,
needs only a single Leo strategy. We can also observe that for many problems
that appear to be relatively hard for Leo alone (e.g., SET017+1, SET611+3,
SET624+3), the Leo-Bliksem cooperation solves them not only more quickly,
but also it sometimes reduces the problems to relatively small higher-order pre-
processing steps with subsequent easy ﬁrst-order proofs, as for instance, in the
case of SET017+1.
From a mathematical viewpoint the investigated problems are trivial and,
hence, they should ideally be reliably and very eﬃciently solvable within a
proof assistant. This has been achieved for the examples in Table 4 (except for
SET741+4 and SET770+4) by our hybrid approach. While some of the proof
attempts now require slightly more time than when using Leo alone with a spe-
cialised strategy, they are, in most cases, still faster than when proving with a
ﬁrst-order system.
5
Related Work and Conclusion
Related to our approach is the Techs system [12], which realises a coopera-
tion between a set of heterogeneous ﬁrst-order theorem provers. Similarly to our
approach, partial results in Techs are exchanged between the diﬀerent theo-
rem provers in form of clauses. The main diﬀerence to the work of Denzinger
et al. (and other related architectures like [13]) is that our system bridges be-
tween higher-order and ﬁrst-order automated theorem proving. Also, unlike in
Techs, we provide a declarative speciﬁcation framework for modelling exter-
nal systems as cooperating, concurrent processes that can be (re-)conﬁgured at
run-time. Related is also the work of Hurd [15] which realises a generic inter-
face between HOL and ﬁrst-order theorem provers. It is similar to the solution

430
C. Benzm¨uller et al.
previously achieved by Tramp [17] in Omega, which serves as a basis for the
sound integration of ATPs into Oants. Both approaches pass essentially ﬁrst-
order clauses to ﬁrst-order theorem provers and then translate their results back
into HOL resp. Omega. Some further related work on the cooperation of Is-
abelle with Vampire is presented in [18]. The main diﬀerence of our work to
the related systems is that while our system calls ﬁrst-order provers from within
higher-order proof search, this is not the case for [15,17,18].
One of the motivations for our work is to show that the cooperation of higher-
order and ﬁrst-order automated theorem provers can be very successful and ef-
fective. The results of our case study provide evidence for this: our non-optimised
system outperforms related work on state-of-the-art ﬁrst-order theorem provers
and their ad hoc extensions such as Saturate [14] on 45 mathematical problems
chosen from the TPTP SET category. Among them are four problems which
cannot be solved by any TPTP system to date. In contrast to the ﬁrst-order
situation, these problems can in fact be proved in our approach reliably from
ﬁrst principles, that is, without avoiding relevant base axioms of the underlying
set theory, and moreover, without the need to provide relevant lemmata and
deﬁnitions by hand.
The results of our case study motivate further research in the automation
of higher-order theorem proving and the experimentation with diﬀerent higher-
order to ﬁrst-order transformation mappings (such as the ones used by Hurd)
that support our hybrid reasoning approach. They also provide further evidence
for the usefulness of the Oants approach as described in [8,5] for ﬂexibly mod-
elling the cooperation of reasoning systems.
Our results also motivate the need for a higher-order extension of the TPTP
library in which alternative higher-order problem formalisations are linked with
their ﬁrst-order counterparts so that ﬁrst-order theorem provers could also be
evaluated against higher-order systems (and vice versa).
Future work is to investigate how far our approach scales up to more complex
problems and more advanced mathematical theories. In less trivial settings as
discussed in this paper, we will face the problem of selecting and adding relevant
lemmata to avoid immediate reduction to ﬁrst principles and to appropriately
instantiate set variables. Relevant related work for this setting is Bishop’s ap-
proach to selectively expand deﬁnitions as presented in [9] and Brown’s PhD
thesis on set comprehension in Church’s type theory [10].
Acknowledgements For advice and help we thank Chad Brown, Andreas
Meier, Andrei Voronkov, and Claus-Peter Wirth.
References
1. P. Andrews. An Introduction to mathematical logic and Type Theory: To Truth
through Proof. Number 27 in Applied Logic Series. Kluwer, 2002.
2. C. Benzm¨uller.
Equality and Extensionality in Higher-Order Theorem Proving.
PhD thesis, Universit¨at des Saarlandes, Germany, 1999.
3. C. Benzm¨uller.
Extensional higher-order paramodulation and RUE-resolution.
Proc. of CADE-16, LNAI 1632, p. 399–413. Springer, 1999.

Can a Higher-Order and a First-Order Theorem Prover Cooperate?
431
4. C. Benzm¨uller. Comparing approaches to resolution based higher-order theorem
proving. Synthese, 133(1-2):203–235, 2002.
5. C. Benzm¨uller, M. Jamnik, M. Kerber, and V. Sorge. Experiments with an Agent-
Oriented Reasoning System.Proc. of KI 2001, LNAI 2174, p.409--424. Springer, 2001.
6. C. Benzm¨uller and M. Kohlhase. LEO – a higher-order theorem prover. Proc. of
CADE-15, LNAI 1421. Springer, 1998.
7. C. Benzm¨uller and V. Sorge. A Blackboard Architecture for Guiding Interactive
Proofs. Proc. of AIMSA’98, LNAI 1480, p. 102–114. Springer, 1998.
8. C. Benzm¨uller and V. Sorge. Oants – An open approach at combining Interactive
and Automated Theorem Proving. Proc. of Calculemus-2000. AK Peters, 2001.
9. M. Bishop and P. Andrews. Selectively instantiating deﬁnitions. Proc. of CADE-
15, LNAI 1421. Springer, 1998.
10. C. E. Brown. Set Comprehension in Church’s Type Theory. PhD thesis, Dept. of
Mathematical Sciences, Carnegie Mellon University, USA, 2004.
11. H. de Nivelle. The Bliksem Theorem Prover, Version 1.12. Max-Planck-Institut,
Saarbr¨ucken, Germany, 1999.
http://www.mpi-sb.mpg.de/~bliksem/manual.ps.
12. J. Denzinger and D. Fuchs. Cooperation of Heterogeneous Provers. Proc. IJCAI-
16, p. 10–15. Morgan Kaufmann, 1999.
13. M. Fisher and A. Ireland. Multi-agent proof-planning. CADE-15 Workshop “Using
AI methods in Deduction”, 1998.
14. H. Ganzinger and J. Stuber. Superposition with equivalence reasoning and delayed
clause normal form transformation. Proc. of CADE-19, LNAI 2741. Springer, 2003.
15. J. Hurd. An LCF-style interface between HOL and ﬁrst-order logic. Automated
Deduction — CADE-18, LNAI 2392, p. 134–138. Springer, 2002.
16. M. Kerber. On the Representation of Mathematical Concepts and their Translation
into First Order Logic. PhD thesis, Universit¨at Kaiserslautern, Germany, 1992.
17. A. Meier. TRAMP: Transformation of Machine-Found Proofs into Natural Deduction
Proofs at the Assertion Level. Proc. of CADE-17, LNAI 1831. Springer, 2000.
18. J. Meng and L. C. Paulson. Experiments on supporting interactive proof using
resolution. Proc. of IJCAR 2004, LNCS 3097, p. 372–384. Springer, 2004.
19. R. Nieuwenhuis, Th. Hillenbrand, A. Riazanov, and A. Voronkov. On the evalua-
tion of indexing techniques for theorem proving. Proc. of IJCAR-01, LNAI 2083,
p. 257–271. Springer, 2001.
20. D. Pastre.
Muscadet2.3 : A knowledge-based theorem prover based on natural
deduction. Proc. of IJCAR-01, LNAI 2083, p. 685–689. Springer, 2001.
21. A. Riazanov and A. Voronkov. Vampire 1.1 (system description). Proc. of IJCAR-
01, LNAI 2083, p. 376–380. Springer, 2001.
22. V. Sorge. OANTS: A Blackboard Architecture for the Integration of Reasoning Tech-
niques into Proof Planning. PhD thesis, Universit¨at des Saarlandes, Germany, 2001.
23. G. Stenz and A. Wolf. E-SETHEO: An Automated3 Theorem Prover – System
Abstract. Proc. of the TABLEAUX’2000, LNAI 1847, p. 436–440. Springer, 2000.
24. G. Sutcliﬀe and C. Suttner. The TPTP Problem Library: CNF Release v1.2.1.
Journal of Automated Reasoning, 21(2):177–203, 1998.

A Generic Framework for Interprocedural
Analyses of Numerical Properties
Markus M¨uller-Olm1 and Helmut Seidl2
1 Universit¨at Dortmund, Fachbereich Informatik, LS 5
Baroper Str. 301, 44221 Dortmund, Germany
markus.mueller-olm@cs.uni-dortmund.de
2 TU M¨unchen, Institut f¨ur Informatik, I2
80333 M¨unchen, Germany
seidl@in.tum.de
Abstract. Relations among program variables like 1 + 3 · x1 + 5 · x2 ≡
0 [224] have been called linear congruence relations. Such a relation is
valid at a program point iﬀit is satisﬁed by all reaching program states.
Knowledge about non-trivial valid congruence relations is crucial for var-
ious aggressive program transformations. It can also form the backbone
of a program correctness proof.
In his seminal paper [1], Philippe Granger presents an intraprocedural
analysis which is able to infer linear congruence relations between integer
variables. For aﬃne programs, i.e., programs where all assignments are
aﬃne expressions and branching is non-deterministic, Granger’s analysis
is complete, i.e., infers all valid congruence relations between variables.
No upper bound, though, has been proven for Granger’s algorithm. Here,
we present a variation of Granger’s analysis which runs in polynomial
time. Moreover, we provide an interprocedural extension of this algo-
rithm. The polynomial algorithm as well as its interprocedural exten-
sion are obtained by means of multiple instances of a general framework
for constructing interprocedural analyses of numerical properties. This
framework can be used for diﬀerent numerical domains such as ﬁelds or
modular rings and thus also covers the interprocedural analyses of [2,3]
where valid aﬃne relations are inferred.
We also indicate how the base technique can be extended to deal with
equality guards in the interprocedural setting.
References
1. P. Granger. Static Analysis of Linear Congruence Equalities among Variables of
a Program. In Int. Joint Conf. on Theory and Practice of Software Development
(TAPSOFT), pages 169–192. LNCS 493, Springer-Verlag, 1991.
2. M. M¨uller-Olm and H. Seidl. Precise Interprocedural Analysis through Linear Alge-
bra. In 31st ACM Symp. on Principles of Programming Languages (POPL), pages
330–341, 2004.
3. M. M¨uller-Olm and H. Seidl. Analysis of Modular Arithmetic. In European Sym-
posium on Programming (ESOP). Springer Verlag, 2005. To appear.
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, p. 432, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

Second-Order Matching via Explicit
Substitutions⋆
Fl´avio L.C. de Moura⋆⋆1, Fairouz Kamareddine2, and
Mauricio Ayala-Rinc´on⋆⋆⋆1
1 Departamento de Matem´atica, Universidade de Bras´ılia, Bras´ılia D.F., Brasil.
flavio@mat.unb.br,ayala@mat.unb.br
2 School of Mathematical and Computer Sciences, Heriot-Watt University,
Edinburgh, Scotland. fairouz@macs.hw.ac.uk
Abstract. Matching is a basic operation extensively used in computa-
tion. Second-order matching, in particular, provides an adequate envi-
ronment for expressing program transformations and pattern recognition
for automated deduction. The past few years have established the ben-
eﬁt of using explicit substitutions for theorem proving and higher-order
uniﬁcation. In this paper, we will make use of explicit substitutions to
facilitate matching: we develop a second-order matching algorithm via
the λσ-style of explicit substitutions. We introduce a convenient nota-
tion for matching in the λσ-calculus. This notation keeps the matching
equations separated from the incremental graftings. We characterise an
important class of second-order matching problems which is essential to
prove termination of the algorithm. In addition, we illustrate how the
algorithm works through some examples.
Keywords: Higher-Order Uniﬁcation, Second-Order Matching, Explicit
Substitutions.
1
Introduction
Matching is an important mechanism extensively used in automated deduction
and programming languages. For instance, second-order matching has been used
in program transformation [HL78,Vis04] and theorem proving [dlTC87,dlTC88].
First-order matching, as well as ﬁrst-order uniﬁcation, is decidable and uni-
tary, i.e., when a uniﬁer exists it is unique in the sense that the most general
uniﬁer (mgu) exists [Rob65]. Second-order matching is still decidable [Hue76],
but the solutions are not necessarily unique and the notion of an mgu no longer
exists. In fact, the second-order matching problem1 λx.(X a) <<? λx.(c(b a)),
where a, b and c are constants and X is a meta-variable, has two solutions given
by X/λy.(c(b a)) and X/λy.(c(b y)) and, none of them is an instance of the
⋆Work supported by funds from CNPq(CT-INFO) 50.6598/04-7 and PRONEX.
⋆⋆Corresponding author. Supported by Brazilian CAPES Foundation.
⋆⋆⋆Partially supported by Brazilian CNPq Council.
1 The type information is omitted to simplify the presentation of the example.
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 433–448, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

434
F.L.C. de Moura, F. Kamareddine, and M. Ayala-Rinc´on
other, and hence there is no mgu. Third and fourth order matching are decid-
able [Dow94,Pad00], but for higher orders, it remains unknown (for almost thirty
years) whether this problem is decidable [Hue76]. In [Loa03], the undecidability
of ﬁfth-order β-matching is given, but the proof does not deal with the general
case that includes η-conversion.
In [DHK00], Dowek, Hardin and Kirchner gave a general method for higher-
order uniﬁcation for the λσ-calculus of explicit substitutions. In that paper they
prove that the uniﬁcation problem P has a solution in the simply typed λ-
calculus if and only if the translation of this problem in the language of the λσ-
calculus, written PF has a solution. However, this general uniﬁcation method,
which has been proved adaptable for other explicit substitutions calculi [ARK01],
does not decide second-order matching in the λσ-calculus as we show by a non-
terminating counter-example. In addition, [Bur89] shows that matching may be-
have diﬀerently from uniﬁcation depending on the considered equational theory
and, therefore it is of interest to study matching via explicit substitutions.
In this paper we develop a second-order matching algorithm that decides a
special subset of λσ-terms. The contributions of this work are as follows:
1. We characterise an important subset of second-order λσ-terms which the
general method of Dowek, Hardin and Kirchner can decide. This subset contains
all the λσ-terms that can appear in a second-order matching problem derived
from another matching problem originated in the simply typed λ-calculus.
2. Since the notation used by Dowek, Hardin and Kirchner is not adequate for
matching because it may introduce ﬂexible-ﬂexible equations whose right-hand
sides need to be instantiated, we present an adequate notation for dealing with
matching in the λσ-calculus. This notation keeps graftings (ﬁrst-order substitu-
tions) separated from the matching equations to be uniﬁed. This separation will
be important during the matching because no variable, which can be instanti-
ated, is included in the right-hand side of a matching equation and, therefore
each matching rule will necessarily generate another matching problem.
3. We present a second-order matching algorithm that decides the subset of
λσ-terms characterised in item 1.
Using the λσ-style of explicit substitutions has the well known advantage of
reducing higher-order uniﬁcation problems into equivalent ﬁrst-order equational
uniﬁcation problems, and in this way, the variable instantiation mechanism of
the λ-calculus is implemented by ﬁrst-order substitution (grafting). Advantages
of this HOU approach include, among others: being closer to implementations
which is inherent to explicit substitutions; avoidance of functional encoding of
scoping constraints by separating substitutions from reductions and substitu-
tions from uniﬁcation variables; conceiving HOU as equational uniﬁcation mod-
ulo βη-conversion, which allows for natural mixing of higher order speciﬁcations
with equational ones as explained in [DHK00]. Nevertheless, since higher-order
uniﬁcation is undecidable [Gol81], it is important to study decidable subprob-
lems over speciﬁc λ-terms as well as of its extensions, such as the λσ-calculus.
In this way, this work is worthwhile because the presented algorithm decides the
subset of second-order λσ-terms characterised in item 1.

Second-Order Matching via Explicit Substitutions
435
In the next section we give a brief presentation of the simply typed version
of the λ- and λσ-calculi. In section 3 we start with the characterisation of a
subset of λσ-terms. Afterwards, we deﬁne an adequate notation for dealing with
matching problems and then, we present a second-order matching algorithm for
the λσ-calculus. Finally, we conclude and give directions for future work.
2
Background
We start this section with a brief presentation of the simply typed λ- and λσ-
calculus and some basic deﬁnitions used throughout the paper. The notation
used in this presentation uses de Bruijn indexes [dB72] instead of variables with
names. This is because de Bruijn’s notation is more adequate for implementa-
tions of the λ-calculus since α-conversion is no longer needed.
We deﬁne types and simply typed λ-terms in de Bruijn notation as usual:
types
A ::= K | A →B, where K is an atomic type.
contexts Γ ::= nil | A.Γ
terms
a ::= n | X | (a a) | λA.a, where n ∈N = {1, 2, . . .}
and X ∈X, the set of meta-variables.
The set of λ-terms built with this grammar is usually denoted by ΛdB(X)
and the typing rules are as follows:
(var)
A.Γ ⊢1 : A
(var n)
Γ ⊢n : B
A.Γ ⊢n + 1 : B
(app) Γ ⊢a : A →B Γ ⊢b : A
Γ ⊢(a b) : B
(lambda)
A.Γ ⊢a : B
Γ ⊢λA.a : A →B
The type judgement Γ ⊢a : A can also be written as aΓ
A.
To each meta-variable X we associate a unique type A and a unique context
Γ. We assume that for each type there exists an inﬁnite set of meta-variables
with that type. We add the following typing rule for meta-variables:
(Metavar) Γ ⊢X : A,
where Γ is any context.
β- and η-contraction are deﬁned as usual and =βη denotes βη-conversion.
Deﬁnition 1 (Order of types and terms). The order of a term is the order
of its type and the order of a type A, written as |A|, is deﬁned by:
1. If A is atomic then |A| = 1;
2. If A = B →C then |A| = max{1 + |B|, |C|}.
Uniﬁcation problems deal with uniﬁcation equations which are deﬁned by:
Deﬁnition 2 (Uniﬁcation equation). A uniﬁcation equation is an equation
of the form a =? b where a and b are λ-terms of the same type which are well-
typed under the same context. The order of a uniﬁcation equation is the high-
est order of the meta-variables occurring in it. A uniﬁcation equation is called

436
F.L.C. de Moura, F. Kamareddine, and M. Ayala-Rinc´on
ﬂexible-ﬂexible or rigid-rigid if the left and right-hand sides of the equation are
both ﬂexible or rigid terms, respectively. If one term is rigid and the other is ﬂexi-
ble (independently of the order) the equation is called ﬂexible-rigid. A uniﬁcation
equation is called trivial if it has the form a =? a.
Example 1. Let Γ = A.A →A.A →B.B.nil and X and Y meta-variables such
that Γ ⊢X : A →A and Γ ⊢Y : (A →A) →B. The uniﬁcation equation
(3(2(X1))) =? 4 has order 2 (since X has order 2), while Y X =? 4 has order 3.
Deﬁnition 3 (Uniﬁer). A uniﬁer for a given uniﬁcation equation, say a =? b,
is a substitution σ such that aσ =βη bσ.
Deﬁnition 4 (Uniﬁcation problem). A uniﬁcation problem is a ﬁnite set of
uniﬁcation equations. The order of a uniﬁcation problem is given by the highest
order amongst its uniﬁcation equations. A solution of a uniﬁcation problem P
is a substitution which is a uniﬁer for all equations in P. In other words, a
solution for P is a substitution σ such that Pσ is the trivial uniﬁcation problem
(i.e., formed only by trivial equations).
Deﬁnition 5 (Matching equation2). A higher-order matching equation is an
equation of the form a <<? b, where a and b are λ-terms of the same type which
are well typed under the same context and, such that the right hand side does
not contain meta-variables.
Deﬁnition 6 (Matcher). A matcher for a given matching equation, say
a <<? b, is a substitution σ such that aσ =βη b.
This deﬁnition corresponds to the notion of “ﬁltering”, which becomes from
the assumption that the term to be matched have disjoint variable sets or they
can be renamed as usual in rewriting systems and pattern matching. The alter-
native notion of “semi-uniﬁcation” (∃σ, aσ =βη bσ =βη b) is not treated here
[Bur89].
Deﬁnition 7 (Matching problem). A higher-order matching problem is a
ﬁnite set of matching equations. The order of a matching problem is given by the
highest order of its meta-variables.
The λσ-calculus of explicit substitutions extends the λ-calculus with explicit
operators to simulate the substitution (meta-)operation of the λ-calculus.
The syntax of the typed λσ-calculus is given by
Types
A ::= K | A →B
Contexts
Γ ::= nil | A.Γ
Terms
a ::= 1 | X | (a b) | λA.a | a[s]
where X ∈X
Substitutions
s ::= id | ↑| a.s | s ◦s
The set of λσ-terms is written as Λλσ(X).
2 Adapted from [Dow01]

Second-Order Matching via Explicit Substitutions
437
The λσ-typing rules are given by:
(var)
A.Γ ⊢1 : A
(lambda)
A.Γ ⊢a : B
Γ ⊢λA.a : A →B
(app)
Γ ⊢a : A →B Γ ⊢b : A
Γ ⊢(a b) : B
(clos)
Γ ⊢s ▷Γ ′ Γ ′ ⊢a : A
Γ ⊢a[s] : A
(id)
Γ ⊢id ▷Γ
(shift)
A.Γ ⊢↑▷Γ
(cons)
Γ ⊢a : A Γ ⊢s ▷Γ ′
Γ ⊢a.s ▷A.Γ ′
(comp)
Γ ⊢s′′ ▷Γ ′′ Γ ′′ ⊢s′ ▷Γ ′
Γ ⊢s′ ◦s′′ ▷Γ ′
In addition, to each meta-variable X we associate a unique type TX and a
unique context ΓX. We assume that for each pair (Γ, A) there is an inﬁnite set
of meta-variables X such that ΓX = Γ and TX = A. We add the following type
rule for meta-variables:
(Metavar) ΓX ⊢X : TX
We use the λσ-rules and the uniﬁcation rules (named Dec-λ, Dec-App,
Dec-Fail, Exp-λ, Exp-App, Normalise and Replace) for the λσ-calculus as
presented in [DHK00].
3
Second-Order Matching via Explicit Substitutions
The language of the λσ-calculus is a non-trivial extension of the language of the
λ-calculus, and hence, the decidability of second-order matching arises naturally
in the λσ-calculus. An obvious step to solve second-order matching problems in
the λσ-calculus would be to adapt the higher-order procedure for the λσ-calculus
of [DHK00] to solve second-order matching problems. As we will see in the next
section, the procedure given in [DHK00] does not terminate for all second-order
matching problems in the λσ-calculus. Nevertheless, we characterise a sub-set of
λσ-terms for which we can decide second-order matching problems.
3.1
An Important Class of λσ-Terms
In this section we characterise an important class of λσ-terms, and in the next
section, we design a second-order matching algorithm that decides this class.
The necessity to deﬁne this class is due to the fact that the uniﬁcation method
[DHK00] does not terminate for all second-order matching problems written in
the λσ-style. Hence this method does not decide second-order matching in the
λσ-calculus. The counter-example is the following:
XA→A.Γ
A
[(λA.1A.Γ
A
)Γ
A→A.idΓ
Γ ]Γ
A =?
λσ bΓ
A
where b is a given closed term, i.e. a term without occurrences of meta-variables,
and Γ is a given context.
We can build the following derivation:
XA→A.Γ
A
[(λA.1A.Γ
A
)Γ
A→A.idΓ
Γ ]Γ
A =?
λσ bΓ
A →Exp−App

438
F.L.C. de Moura, F. Kamareddine, and M. Ayala-Rinc´on
XA→A.Γ
A
[(λA.1A.Γ
A
)Γ
A→A.idΓ
Γ ] =?
λσ bΓ
A ∧
XA→A.Γ
A
=?
λσ (1A→A.Γ
A→A
Y A→A.Γ
A
)A→A.Γ
A
→Replace
(1A→A.Γ
A→A
Y A→A.Γ
A
)A→A.Γ
A
[(λA.1A.Γ
A
)Γ
A→A.idΓ
Γ ] =?
λσ bΓ
A ∧
XA→A.Γ
A
=?
λσ (1A→A.Γ
A→A
Y A→A.Γ
A
)A→A.Γ
A
→Normalise
Y A→A.Γ
A
[(λA.1A.Γ
A
)Γ
A→A.idΓ
Γ ] =?
λσ bΓ
A ∧
XA→A.Γ
A
=?
λσ (1A→A.Γ
A→A
Y A→A.Γ
A
)A→A.Γ
A
At this point we can repeat the strategy Exp-App, Replace and Nor-
malise since the last problem generated (see the last two lines) is composed
by two ﬂexible-rigid equations, the ﬁrst of which is equivalent to the original
problem up to renaming of meta-variables.
The class of λσ-matching problems that we are going to characterise is
strongly based on second-order matching problems that are generated in the
simply typed λ-calculus. Let M be a matching problem in the simply typed λ-
calculus. In order to solve M in the λσ-calculus, we need ﬁrst to rewrite M in
the λσ-language. This translation is given by the following precooking function:
Deﬁnition 8 (Precooking [DHK00]). Let a ∈ΛdB(X) such that Γ ⊢a : A.
To every meta-variable X of type B in the term a, we associate the type B and
the context Γ in the λσ-calculus. The precooking of a from ΛdB(X) to the set
Λλσ(X) of λσ-terms is given by aF = F(a, 0), where F(a, n) is deﬁned by:
1. F((λB.a), n) = λB(F(a, n + 1)).
2. F(k, n) = 1[↑k−1].
3. F((a b), n) = (F(a, n) F(b, n)).
4. F(X, n) = X[↑n].
Notice that F(1, n) and F(X, 0) are resp. 1 and X since ↑0= id. The precook-
ing translation is a function that takes a term from the simply typed λ-calculus
and returns an equivalent term in the language of the simply typed λσ-calculus.
This translation is essential to avoid variable capture since the HOU procedure
in the λσ-calculus uses ﬁrst-order substitution (grafting).
There are two important points that should be emphasised during the pre-
cooking translation: ﬁrst, the unique context associated to each meta-variable
in the simply typed λ-calculus in de Bruijn notation is the same unique context
associated to the translated meta-variable in the λσ-calculus, i.e., if Γ ⊢X : A
then Γ ⊢XF : A; second, only meta-variables have their structure changed
(in order to avoid variable capture when performing graftings) which means
that λσ-terms without occurrences of meta-variables are always in the image of
the precooking translation. This last remark will be particularly important for
matching. Although the precooking translation replaces the de Bruijn index n by
its codiﬁcation 1[↑n−1], here, we avoid using this codiﬁcation for clarity. To give
a better intuition of what happens during the precooking translation, consider
a (general) simply typed λ-term a. Suppose that a contains a meta-variable X

Second-Order Matching via Explicit Substitutions
439
which is under the scope of n abstractors:
λA1 . . . λAn. · · · ( XA1.··· .An.∆
B
) · · ·
After the precooking translation we get:
λA1 . . . λAn. · · · ( X∆
B [(↑n)A1.··· .An.∆
∆
]A1.··· .An.∆
B
) · · ·
which is a shorthand for the simultaneous substitution:
λA1 . . . λAn. · · · ( X∆
B [(n + 1.n + 2. · · · )A1.··· .An.∆
∆
]A1.··· .An.∆
B
) · · ·
Since in λσ one uses grafting, the precooking translation is the correct way
to ‘protect’ the meta-variables and to avoid possible variable capture. The sub-
stitution ↑n applied to the meta-variable X, i.e., X[↑n] means, on one hand,
that every free de Bruijn index occurring in the term to be substituted by X
must be updated by n and, on the other hand, that the ﬁrst n terms of any
substitution applied to X[↑n] will be ignored. That is, X[↑n][s] will be reduced
to X[s>n], for any substitution s, where s>n represents the elements in the list
s which are in positions greater than n. This means that the redexes related to
the abstractors appearing in the initial problem cannot introduce terms in the
substitution list applied to meta-variables. Hence, terms to be included in this
list should be arguments of β-redexes generated by new abstractors which are
created only by the rule Exp-λ.
Deﬁnition 9 (Uniﬁcation Path/Matching Path). Let P be a uniﬁcation
(resp. matching) problem. We say that P ′ is in the uniﬁcation (resp. matching)
path of P if P →∗P ′, where the relation →∗means n ≥0 applications of any
uniﬁcation (resp. matching) rules.
The next proposition characterises second-order problems in the language of
the λσ-calculus that can be decided by the method given by [DHK00].
Proposition 1 (Characterisation of a special subclass of λσ-terms). Let
P Γ
A be a second-order uniﬁcation problem which is in the image of the precooking
translation. Then every ﬂexible term occurring in P ′Γ
A which is in the uniﬁcation
path of P Γ
A using the uniﬁcation rules of [DHK00], and of the form X[s], with
X of atomic type and s in σ-normal form, is such that every element in the list
s with functional type is a de Bruijn index.
Proof. The proof is by induction on the size of the derivation that generated the
term that contains X[s] as sub-term. Without loss of generality we may assume
that P Γ
A is in λσ-normal form (otherwise we can apply one step of Normalise).
We use IH for the induction hypothesis.
If the considered equation belongs to P Γ
A then by the deﬁnition of precooking,
the substitution s is of the form ↑n, for some n ≥0 and, hence the proposition
holds since every term in the substitution ↑n is a de Bruijn index.
Now suppose that the proposition holds for P ′Γ
A
which by hypothesis is in
the uniﬁcation path of P Γ
A . Let P ′′Γ
A
be such that P ′Γ
A
→r P ′′Γ
A
and r is any
uniﬁcation rule as given in [DHK00] except Dec-Fail since it does not generate
a new uniﬁcation problem. We have the following cases:

440
F.L.C. de Moura, F. Kamareddine, and M. Ayala-Rinc´on
– If r is Dec-λ or Replace then X[s] was already in P ′Γ
A since these rules do
not change the structure of substitutions. The proposition follows by IH.
– If r is Dec-App then either X[s] corresponds to one of the arguments ai of
n a1 . . . ap or the equation was already in P ′Γ
A . In both cases, s satisﬁes the
proposition by IH.
– If r is Exp-λ then either X[s] is a sub-term of the new equation or it was
already in P ′Γ
A . In the former case, the sole new meta-variable that is intro-
duced has the form Y , that should be seen as Y [id] and then the proposition
holds. In the latter case the proposition holds by IH.
– If r is Exp-App then either X[s] is a sub-term of one of the terms occur-
ring among the new equations or it was already in P ′Γ
A . In the former case,
all the new meta-variables H1, . . . , Hk have the form Hi[id] and then the
proposition holds. In the latter case the proposition holds by IH.
– If r is Normalise then there are two cases that we need to consider:
1. The application of Normalise is preceded by an application of Exp-λ:
In this case, the newly introduced λ’s will generate new β-redexes and
the steps are as follows. The selected equation before the application of
Exp-λ had a sub-term of the form:
X∆
B1→···→Bk→B[(↑n)A1.··· .An.∆
∆
]A1.··· .An.∆
B1→···→Bk→B
where B1,. . . , Bk and B are atomic types since X is second order.
After an application of Exp-λ followed by Replace we have:
(λB1 · · · λBk.Y B1.··· .Bk.∆
B
)∆
B[(↑n)A1.··· .An.∆
∆
]A1.··· .An.∆
B
The normalisation step consists in pushing the substitution inside the
new λ’s and then performing β-reductions. After pushing the substitu-
tion inside these new abstractors we have a sub-term of the form:
λB1 · · · λBk.Y B1.··· .Bk.∆
B
[1B1.··· .Bk.A1.··· .An.∆
B1
. · · · .kB1.··· .Bk.A1.··· .An.∆
Bk
.
(↑k+n)B1.··· .Bk.A1.··· .An.∆
∆
]B1.··· .Bk.A1.··· .An.∆
B
The β-reductions that can be performed now will replace arbitrary ele-
ments by the ﬁrst k de Bruijn indexes in the above substitution list, but
since all of these λ’s have atomic type the proposition holds. The other
terms in the substitution list remain unchanged.
2. Normalise was not preceded by an application of Exp-λ: Then, an ap-
plication of Normalise is a consequence of an application of Exp-App
since the rules Dec-λ, Dec-App, Dec-Fail and Replace, do not change
the structure of the current terms which, by IH are in normal form. Ap-
plications of Exp-App do not introduce new abstractions and hence the
rule Beta3 does not apply. Application of Abs introduces a new de Bruijn
index in the substitution list, and hence the proposition still holds. None
of the others λσ-rules introduce new terms in the substitution lists of
the current uniﬁcation problem and the proposition holds by IH.
□
3 See the λσ-rules in [DHK00] or [ACCL91]

Second-Order Matching via Explicit Substitutions
441
In other words, the substitution s in Proposition 1, has the form a1.· · ·.ap.↑n
(ap ̸= n), such that all the elements a1, . . . , ap are of atomic type, and the other
part of the substitution, i.e., ↑n which is a short hand for n + 1.n + 2. · · · , is
formed by an inﬁnite number of diﬀerent de Bruijn indexes and is the only part
which may have elements of functional type. This result is illustrated as:
X[ a1. · · · .ap.


 n + 1.n + 2. · · ·


 ]
atomic
at most
types
2nd-order types
In section 3.3 we present a second-order matching algorithm for λσ-problems
whose terms belong to the class characterised by Proposition 1. Although this
class forms a proper subset of all λσ-terms, this restriction is not important since
this class includes all λσ-terms that occur in a second-order matching problem
which is in the matching path of another matching problem that is in the image
of the precooking translation. Thus, this class includes all the terms that can be
generated by the uniﬁcation procedure from a second-order matching problem
originated in the simply typed λ-calculus (after the precooking translation).
3.2
The Uniﬁcation by Transformation Notation
Matching problems are characterised by the fact that terms in the right-hand
side of equations cannot be instantiated. Therefore, the ﬁrst diﬃculty to use the
general rules of [DHK00] is related to applications of the rule Exp-λ because
it introduces a ﬂexible-ﬂexible equation whose right-hand side needs to be in-
stantiated. As an example, let a <<?
λσ b be a second-order matching problem
such that the term a has an occurrence of the meta-variable X of type A →A.
An application of a rule like Exp-λ would generate a new problem of the form
a <?
λσb ∧X <<?
λσ λA.Y , and of course the meta-variable Y needs to be instanti-
ated. To solve this problem we use a notation based on the so called “uniﬁcation
by transformation” approach [Nip93]. According to this approach, a matching
problem will be represented by a pair of the form ⟨σ, M⟩, where σ is a grafting,
and M is a matching problem. The advantage of this notation is that we can
deﬁne matching rules that do not introduce terms that need to be instantiated in
the right-hand side of matching equations because graftings and matching equa-
tions are kept in diﬀerent places. For the above example, an application of a rule
with the same behaviour of Exp-λ should generate from the matching problem
⟨{}, a <<?
λσ b⟩the equivalent matching problem ⟨{X →λA.Y }, {a <<?
λσ b}⟩.
This notation is independent of the matching rules and, hence we can char-
acterise solved forms without knowing explicitly the matching rules.
Deﬁnition 10 (Solved form). A solved form is a pair of the form ⟨θ, M⟩,
where the ﬁrst element of the pair is a grafting and the second element is either
the empty set or a ﬁnite set of trivial matching equations, i.e., equations of the
form a <<?
λσ a.
Now we are ready to deﬁne the matching rules.

442
F.L.C. de Moura, F. Kamareddine, and M. Ayala-Rinc´on
3.3
The Second-Order Matching Algorithm
The second-order matching rules are given in Table 1. The rules Dec-m-λ, Dec-
m-App, Dec-m-Fail and Normalisem correspond respectively to Dec-λ, Dec-
App, Dec-Fail and Normalise of [DHK00] written in the uniﬁcation by trans-
formation notation. The rule Expm-λ is the matching version of Exp-λ. The
diﬀerence between them, in addition to the notation, is that Expm-λ always
replaces a meta-variable of functional type by an abstraction whose body is a
fresh meta-variable of atomic type and also applies the generated grafting to the
current matching problem. This sole step corresponds to several applications
of Exp-λ and Replace. Note that, if no replacement is done, the rule Exp-λ
can be applied ad inﬁnitum. To avoid such inﬁnite reductions, [DHK00] deﬁned
fair strategies. The deﬁnition of Expm-λ avoids the necessity of deﬁning any
strategy because the rules in Table 1 cannot be applied to a given second-order
matching problem forever. In fact, for a given equation each rule can be applied
only once. The rules Imit and Proj generate grafting for ﬂexible-rigid equations
when the head of the ﬂexible term is a meta-variable of atomic type. The main
diﬀerence between Imit and Proj is that the latter does not introduce fresh
meta-variables. In addition, while Proj may generate several diﬀerent graftings,
for Imit we have at most one grafting. Moreover, in the rule Imit, the head of
the term which replaces X is a de Bruijn index of at most third order. This is
because the newly introduced meta-variables have at most second-order.
To prove that the rules of Table 1 always terminate for second-order matching
problems whose terms belong to the class characterised by Proposition 1, we need
to deﬁne an adequate measure. We start by giving the length of a λσ-term:
Deﬁnition 11 (Length of a λσ-term). Let a ∈Λλσ(X). We inductively de-
ﬁne |a|, the length of a, by:
– if a = X or a = 1 then |a| = 1
– if a = (b c) then |a| = |b| + |c|
– if a = λ.b then |a| = 1 + |b|
– if a = b[s] then |a| = |b| + ||s||, where the size of a substitution s, written as
||s||, is inductively deﬁned as:
• if s =↑or s = id then ||s|| = 0
• if s = c.d then ||s|| = |c| + ||d||
• if s = u ◦v then ||s|| = ||u|| + ||v||
Deﬁnition 12. Let M = {a1 <<?
λσ b1, . . . , an <<?
λσ bn} be a matching problem.
Deﬁne µ(M) = (ξ, ξ′, ξ′′) in the following way:
• ξ = Σn
i=1|bi|
• ξ′ = the number of meta-variables occurring in M
• ξ′′ = the sum of the order of the type of all meta-variables occurring in M.
Now denote by < the usual lexicographic order over triples.

Second-Order Matching via Explicit Substitutions
443
Table 1. Second-Order Matching Rules
Decm-λ
⟨σ, P ∪{λA.a <<?
λσ λA.b}⟩
⟨σ, P ∪{a <<?
λσ b}⟩
Decm-App
⟨σ, P ∪{(n a1 . . . ap) <<?
λσ (n b1 . . . bp)}⟩
⟨σ, P ∪{a1 <<?
λσ b1, . . . , ap <<?
λσ bp}⟩
Decm-Fail
⟨σ, P ∪{(n a1 . . . ap) <<?
λσ (m b1 . . . bq)}⟩
Fail
, if m ̸= n.
Expm-λ
⟨σ, P⟩
∃Y : (A1. · · · .Ak.Γ ⊢Y : B), ⟨σ′, P{X →λA1 . . . λAk.Y }⟩
if (Γ ⊢X : A1 →· · · →Ak →B) ∈T Var(P), Y ̸∈T Var(P),
and X is not a solved variable.
where σ′ = σ{X →λA1 . . . λAk.Y }
Imit
⟨σ, P ∪{X[a1. · · · .ap. ↑n] <<?
λσ (m b1 . . . bq)}⟩
⟨σ′, Pσ′ ∪{(m−n+p H1 . . . Hq)[a1σ′. · · · .apσ′. ↑n] <<?
λσ (m b1 . . . bq)}⟩
if X has atomic type and m > n.
where σ′ = σ{X →(m−n+p H1 . . . Hq)}, H1, . . . , Hq are meta
variables with appropriate type and with contexts
ΓHi = ΓX(∀1 ≤i ≤q), and m-n+p is at most third order.
Proj
⟨σ, P ∪{X[a1. · · · .ap. ↑n] <<?
λσ (m b1 . . . bq)}⟩
⟨σ{X →j}, {P{X →j} ∪{aj{X →j} <<?
λσ (m b1 . . . bq)}⟩
if X has atomic type, and the j-th element (1 ≤j ≤p)
of the list a1. · · · .ap has the same type of X.
Normalisem
⟨σ, P ∪{a <<?
λσ b}⟩
⟨σ′, P ∪{a′ <<?
λσ b′}⟩if a or b is not in Eta-long form.
where a′ (resp. b′) is the Eta-long form of a (resp. b),
and σ′ is obtained from σ by normalising all its terms.
if a (resp. b) is not a solved variable and a (resp. b) otherwise.
Proposition 2. Applications of the rules of Table 1 to second-order matching
problems whose terms belong to the class characterised by Proposition 1 always
terminate.
Proof. It is enough to show that µ(M) decreases after the application of any of
the rules in Table 1. We write M →r M ′ to denote one step reduction by one
application of rule r. Application of Decm-λ decreases the size of both sides of
the selected equation (see deﬁnition 11), therefore µ(M ′) < µ(M). Application
of Decm-App replaces one equation by a ﬁnite number of new equations formed
by sub-terms of the previous problem, therefore ξ decreases and we have that
µ(M ′) < µ(M). Application of Decm-Fail always stops. Application of Expm-
λ replaces a meta-variable of functional type by a metavariable of atomic type,
therefore ξ′′ decreases and the ﬁrst two components of the current triple remain
unchanged, therefore µ(M ′) < µ(M). Application of Imit introduces q ≥0
fresh meta-variables to the new matching problem, where q is the number of
arguments of the head m of the rigid term in the current equation. If q = 0

444
F.L.C. de Moura, F. Kamareddine, and M. Ayala-Rinc´on
then no new meta-variable is introduced and, hence ξ′ decreases. Otherwise, the
new equation (m−n+p H1 . . . Hq)[a1σ′. · · · .apσ′. ↑n] <<?
λσ (m b1 . . . bq), which is
rigid-rigid must be followed by an application of Decm-App which decreases
µ(M). Application of Proj decreases ξ′ since it does not introduce new meta-
variables. Application of Normalisem cannot be applied successively because
the λσ-calculus is weakly terminating. In this case, even if it is not the case
that µ(M) < µ(M ′) and M ′ is not trivial, one of the other rules must apply.
Therefore the reduction terminates.
□
Since we are dealing with matching problems, we have that the image of
the graftings corresponding to solved forms are λσ-terms that are always in
the image of the precooking translation. In fact, note that the grafting of a
solvable matching problem is always of the form {X1 →a1, . . . , Xk →ak},
where a1, . . . , ak are closed λσ-terms, i.e., terms without any occurrences of
meta-variables. This fact is formalised by the following proposition:
Proposition 3. Every solved form of a second-order matching problem, ob-
tained by application of the rules in Table 1, is in the image of the precooking
translation.
Proof. Every closed term is in the image of the precooking translation since we
only need to rewrite the λσ-codiﬁcation of de Bruijn indexes, say 1[↑n] (n ≥0),
into the usual form n. Recall that, for clarity, in all the examples and even in
the rules, we write n instead of 1[↑n], although this is not the notation used
internally by the λσ-calculus.
□
According to Proposition 3, the solved forms are translated back to the simply
typed λ-calculus by rewriting the codiﬁcation of de Bruijn indexes used by the
λσ-calculus by the corresponding de Bruijn index in the λ-calculus. The whole
matching process can be represented by the following scheme:
M
Precooking  MF
Matching Algorithm
 M ′
F
Precooking−1 M ′
Example 2. Let M be the second-order matching problem given by the equation
Γ ⊢λA.(X 3) <<? λA.(2(43)) : A →B, whose context is given by Γ = A →
B.A.A →A.nil, where A and B are atomic types and Γ ⊢X : A →B. After the
precooking translation, we have λA.(X[↑] 3) <<?
λσ λA.(2(43)). The algorithm
generates the following reduction:

Second-Order Matching via Explicit Substitutions
445
⟨{}, {λA.(X[↑] 3) <<?
λσ λA.(2(4 3))}⟩
Decm-λ

⟨{}, {(X[↑] 3) <<?
λσ (2(4 3))}⟩
Expm-λ

⟨{X →λA.Y }, {((λA.Y )[↑] 3) <<?
λσ (2(4 3))}⟩
Normalisem

⟨{X →λA.Y }, {Y [3. ↑] <<?
λσ (2(4 3))}⟩
Imit

⟨{Y →(2H1), X →(λA.(2H1))}, {(2H1)[3. ↑] <<?
λσ (2(4 3))}⟩
Normalisem

⟨{Y →(2H1), X →(λA.(2H1))}, {H1[3. ↑] =?
λσ (4 3)}⟩
Imit

Proj







T
T ′
where T ′ is given by:
⟨{H1 →1, Y →(2 1), X →λA.(2 1)}, {3 <<?
λσ (4 3)}⟩
Decm−Fail

Fail
and T is given by:
⟨{H1 →(4H2), Y →(2(4H2)), X →λA.(2(4H2))},{(4H2)[3.↑]<<?
λσ (4 3)}⟩
Normalisem

⟨{H1 →(4H2), Y →(2(4H2)), X →λA.(2(4H2))},{(4H2[3.↑])<<?
λσ (4 3)}⟩
Decm-App

⟨{H1 →(4H2), Y →(2(4H2)), X →λA.(2(4H2))}, {H2[3. ↑] <<?
λσ 3}⟩
Imit

Proj








T ′′
T ′′′
where T ′′ and T ′′′ are, respectively, given by:

446
F.L.C. de Moura, F. Kamareddine, and M. Ayala-Rinc´on
⟨{H2 →3, H1 →(4 3), Y →(2(4 3)), X →λA.(2(4 3))}, {3 <<?
λσ 3}⟩
and
⟨{H2 →1, H1 →(4 1), Y →(2(4 1)), X →λA.(2(4 1))}, {3 <<?
λσ 3}⟩
To prove completeness and correctness of the matching rules of Table 1, we
need to consider only the rules Expm-λ, Imit and Proj because for all the other
rules the proof is the same as in [DHK00]. As usual, let us call Uλσ(M) the set
of all λσ-uniﬁers (or matchers) of M.
Proposition 4 (Correctness). Let S = {Expm-λ, Imit, Proj}. The rules in
S are correct, i.e., if M →r M ′ then Uλσ(M ′) ⊆Uλσ(M), where r ∈S.
Proof.
1. Expm-λ: Suppose that γ is a matcher of P{X →λA1 . . . λAk.Y }.
This means that the λσ-normal form of P{X →λA1 . . . λAk.Y }γ is the trivial
problem, i.e, γ ∈Uλσ(P{X →λA1 . . . λAk.Y }) and {X →λA1 . . . λAk.Y }γ ∈
Uλσ(P) which shows that Uλσ(P{X →λA1 . . . λAk.Y }) ⊆Uλσ(P).
2. Imit: Let γ be a matcher of Pσ′ ∪{(m−n+p H1 . . . Hq)[a1σ′.· · ·.apσ′.↑n]
<<?
λσ (m b1 . . . bq)}, where σ′ = σ{X →m −n + p H1 . . . Hq}. This means
that the λσ-normal form of
Pσ′γ ∪{(m−n+p H1 . . . Hq)[a1σ′.· · ·.apσ′. ↑n]γ <<?
λσ (m b1 . . . bq)}
is the trivial problem. Therefore, σ′γ ∈Uλσ(P ∪{X[a1. · · · .ap. ↑n] <<?
λσ
(m b1 . . . bq)}), and hence Uλσ(Pσ′ ∪{(m−n+p H1 . . . Hq)[a1σ′.· · ·.apσ′.↑n]
<<?
λσ (m b1 . . . bq)}) ⊆Uλσ(P ∪{X[a1. · · · .ap. ↑n] <<?
λσ (m b1 . . . bq)}).
3. Proj: Let γ be a matcher of P{X →j} ∪{aj{X →j} <<?
λσ (m b1 . . . bq)},
i.e., the λσ-normal form of P{X →j}γ ∪{aj{X →j}γ <<?
λσ (m b1 . . . bq)} is
the trivial problem. Hence, {X →j}γ is a matcher of P ∪{X[a1.· · ·.ap. ↑n
] <<?
λσ (m b1 . . . bq)}, i.e., {X →j}γ ∈Uλσ(P ∪{X[a1. · · · .ap. ↑n] <<?
λσ
(m b1 . . . bq)}), and since {X →j}γ ∈Uλσ(P{X →j}∪{aj <<?
λσ (m b1 . . . bq)}),
we have that Uλσ(P{X →j} ∪{aj <<?
λσ (m b1 . . . bq)}) ⊆
Uλσ(P ∪{X[a1. · · · .ap. ↑n] <<?
λσ (m b1 . . . bq)}).
□
Proposition 5 (Completeness). Let S = {Expm-λ, Imit, Proj}. The rules
in S are complete, i.e., if M →r M ′ then Uλσ(M) ⊆Uλσ(M ′), where r ∈S.
Proof.
1. Expm-λ: Let θ be a λσ-uniﬁer of ⟨σ, P⟩and X ∈T var(P) such that
Γ ⊢X : A1 →. . . →Ak →B. Thus Xθ = a : A1 →. . . →Ak →B and we
can assume that a is of the form λA1 . . . λAk.b with b : B. Deﬁne θ′ such that
for all Z ∈Dom(θ), θ′(Z) = θ(Z) and Y θ = b for a new variable Y ̸∈Dom(θ)
of type B. Then θ′ is a λσ-uniﬁer of ⟨{X →λA1 . . . λAk.Y }, P⟩. Consequently
θ is a λσ-uniﬁer of ∃(Y : A1. · · · .Ak.Γ ⊢B), ⟨{X →λA1 . . . λAk.Y }, P⟩.
2. Imit and Proj: Let γ be a matcher of P∪{X[a1. · · · .ap. ↑n] <<?
λσ m b1 . . . bq},
where X has atomic type and m > n. Let X →k c1 . . . cr ∈γ. Then, we
have P{X →k c1 . . . cr} ∪{(k c1 . . . cr)[a1. · · · .ap. ↑n] <<?
λσ m b1 . . . bq} →∗
λσ

Second-Order Matching via Explicit Substitutions
447
P{X →k c1 . . . cr} ∪{k[a1. · · · .ap. ↑n]c1[a1. · · · .ap. ↑n] . . . cr[a1. · · · .ap.↑n]
<<?
λσ m b1 . . . bq}.
Now we have two options: k ≤p or k > p. In the ﬁrst case, the previous prob-
lem reduces to P{X →k c1 . . . cr}∪{ak c1[a1. · · · .ap. ↑n] . . . cr[a1. · · · .ap.↑n]
<<?
λσ m b1 . . . bq} and γ is certainly a uniﬁer of it. If k > p then the problem re-
duces to P{X →k c1 . . . cr}∪{k−p+n c1[a1. · · · .ap. ↑n] . . . cr[a1. · · · .ap.↑n]
<<?
λσ m b1 . . . bq} and it has a solution if and only if k −p + n = m and thus
k = m−n+p at the condition that k > p ⇔m−n+p > p ⇔m > n, which
gives the condition asserted in the rule Imit.
□
4
Conclusions and Future Work
We presented a second-order matching algorithm that decides an important sub-
set of λσ-terms. This subset is important because it contains all the second-order
λσ-terms that can occur in a second-order matching problem which is originated
from a matching problem in the simply typed λ-calculus. The algorithm uses an
adequate notation for dealing with matching problems since it keeps graftings
and matching equations as diﬀerent entities. This separation is important to
avoid the possible introduction of ﬂexible terms that need to be instantiated in
the right-hand side of a matching equation.
The study of the possible adaptation of this method to other calculi of explicit
substitutions, such as the λse-calculus (for which HOU was already adapted
[ARK01]) and the suspension calculus, can be helpful to identify advantages
and disadvantages of these calculi in practical applications [AMK05]. Moreover,
this work can be extended for matching via explicit substitutions using a richer
type theory, such as dependent types [Ree03,Mu˜n01].
There exist diﬀerent deﬁnitions of matching in the literature such as “ﬁlter-
ing” and “semi-uniﬁcation”, and in certain cases, matching cannot be seen as
a sub-case of higher-order uniﬁcation[Bur89,Dow01]. As future work, we intend
to study how these deﬁnitions are related in a higher-order framework and, how
they interfere with explicit substitutions environments. In addition, another in-
teresting problem concerns to the existence of a second-order matching algorithm
that decides the whole λσ-calculus and not a sub-class of it, as well as possible
extensions of the current algorithm to matching problems of higher orders.
Acknowledgments. We would like to thank Claude Kirchner for the comments
that motivated this work and the referees for their suggestions and constructive
criticisms.
References
ACCL91. M. Abadi, L. Cardelli, P.-L. Curien, and J.-J. L´evy. Explicit Substitutions.
J. of Func. Programming, 1(4):375–416, 1991.
ARK01. M. Ayala-Rinc´on and F. Kamareddine. Uniﬁcation via the λse-Style of Ex-
plicit Substitution. The Logical J. of the IGPL, 9(4):489–523, 2001.

448
F.L.C. de Moura, F. Kamareddine, and M. Ayala-Rinc´on
AMK05. M. Ayala-Rinc´on, F.L.C. de Moura and F. Kamareddine. Comparing and
Implementing Calculi of Explicit Substitutions with Eta-Reduction. R. de
Queiroz, B. Poizat and S. Artemov Eds. To appear in Special Issue of Annals
of Pure and Applied Logic - WoLLIC 2002 selected papers, 2005.
Bur89.
H.J. Burckert. Matching - A Special Case of Uniﬁcation? Journal of Symbolic
Computation, 8:523–536, 1989.
dB72.
N.G. de Bruijn. Lambda-Calculus Notation with Nameless Dummies, a Tool
for Automatic Formula Manipulation, with Application to the Church-Rosser
Theorem. Indag. Mat., 34(5):381–392, 1972.
DHK00. G. Dowek, T. Hardin, and C. Kirchner. Higher-order uniﬁcation via explicit
substitutions. Information and Computation, 157:183–235, 2000.
dlTC87. T. B. de la Tour and R. Caferra. Proof analogy in interactive theorem prov-
ing: A method to express and use it via second order pattern matching. In
Proceedings of AAAI 87, pages 95–99. Morgan Kaufmann, 1987.
dlTC88. T. B. de la Tour and R. Caferra. A formal approach to some usually informal
techniques used in mathematical reasoning. In P. Gianni, editor, Proc. of the
Int. Symposium on Symbolic and Algebraic Computation, LNCS 358, pages
402–406. Springer Verlag, 1988.
Dow94.
G. Dowek. Third order matching is decidable. Annals of Pure and Applied
Logic, 69:135–155, 1994.
Dow01.
G. Dowek.
Higher-Order Uniﬁcation and Matching.
In A. Robinson and
A. Voronkov, editors, Handbook of Automated Reasoning, volume II, chap-
ter 16, pages 1009–1062. MIT press and Elsevier, 2001.
Gol81.
W. Goldfarb. The Undecidability of the Second-Order Uniﬁcation Problem.
TCS, 13(2):225–230, 1981.
HL78.
G. Huet and B. Lang. Proving and applying program transformations ex-
pressed with second order patterns. Acta Informatica, 11:31–55, 1978.
Hue76.
G. Huet. R´esolution d’´equations dans les langages d’ordre 1,2,. . . ,ω. PhD
thesis, University Paris-7, 1976.
Loa03.
R. Loader. Higher order β matching is undecidable. Logic Journal of the
IGPL, 11(1):51–68, 2003.
Mu˜n01.
C. Mu˜noz. Proof-term synthesis on dependent-type systems via explicit sub-
stitutions. Theoretical Computer Science, 266:407–440, 2001.
Nip93.
T. Nipkow. Functional uniﬁcation of higher-order patterns. In Proc. 8th IEEE
Symp. Logic in Computer Science, pages 64–74, 1993.
Pad00.
V. Padovani. Decidability of fourth-order matching. Mathematical Structures
in Computer Science, 10(3):361–372, 2000.
Ree03.
J. Reed. Extending higher-order uniﬁcation to support proof irrelevance. In
TPHOLs, pages 238–252. Springer Verlag, 2003.
Rob65.
J. A. Robinson. A Machine-oriented Logic Based on the Resolution Principle.
Journal of the ACM, 12(1):23–41, January 1965.
Vis04.
E. Visser. A survey of strategies in rule-based program transformation sys-
tems. Journal of Symbolic Computation, 2004. Accepted for publication.

Knowledge-Based Synthesis of Distributed
Systems Using Event Structures
Mark Bickford⋆, Robert C. Constable⋆⋆, and Joseph Y. Halpern⋆⋆⋆,
and Sabina Petride∗∗∗
Department of Computer Science
Cornell University
Ithaca, NY 14853
{markb,rc,halpern,petride}@cs.cornell.edu
Abstract. To produce a program guaranteed to satisfy a given spec-
iﬁcation one can synthesize it from a formal constructive proof that a
computation satisfying that speciﬁcation exists. This process is particu-
larly eﬀective if the speciﬁcations are written in a high-level language that
makes it easy for designers to specify their goals. We consider a high-level
speciﬁcation language that results from adding knowledge to a fragment
of Nuprl speciﬁcally tailored for specifying distributed protocols, called
event theory. We then show how high-level knowledge-based programs can
be synthesized from the knowledge-based speciﬁcations using a proof de-
velopment system such as Nuprl. Methods of Halpern and Zuck [15] then
apply to convert these knowledge-based protocols to ordinary protocols.
These methods can be expressed as heuristic transformation tactics in
Nuprl.
1
Introduction
Errors in software are extremely costly and disruptive. NIST (the National In-
stitute of Standards and Technology) estimates the cost of software errors to
the US economy at $59.5 billion per year. One approach to minimizing errors
is to synthesize programs from speciﬁcations. Synthesis methods have produced
highly reliable moderate-sized programs in cases where the computing task can
be precisely speciﬁed. One of the most elegant synthesis methods is the use of
so-called correct-by-construction program synthesis [4,9]. Here programs are con-
structed from proofs that the speciﬁcations are satisﬁable. That is, a constructive
proof that a speciﬁcation is satisﬁable gives a program that satisﬁes the speciﬁ-
cation. This method has been successfully used by several research groups and
⋆Supported in part by AF-AFOSR F49620-02-1-0170.
⋆⋆Supported in part by ONR N00014-02-1-0455 and NSF 0208535.
⋆⋆⋆Supported in part by NSF under grant CCR-0208535, by ONR under grant N00014-
02-1-0455, by the DoD Multidisciplinary University Research Initiative (MURI) pro-
gram administered by the ONR under grants N00014-01-1-0795 and N00014-04-1-
0725, and by AFOSR under grant F49620-02-1-0101.
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 449–465, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

450
M. Bickford et al.
companies to construct large complex sequential programs, but it has not yet
been used to create substantial realistic distributed programs.
The Cornell Nuprl proof development system was among the ﬁrst tools used
to create correct-by-construction functional and sequential programs [9]. Nuprl
has also been used extensively to optimize distributed protocols, and to specify
them in the language of I/O Automata [6]. Recent work by two of the authors [5]
has resulted in the deﬁnition of a fragment of the higher-order logic used by Nuprl
tailored to specifying distributed protocols, called event theory, and the extension
of Nuprl methods to synthesize distributed protocols from speciﬁcations written
in event theory [5]. Event logic is a speciﬁcation language closely related to
I/O automata. As has long been recognized [13], designers typically think of
speciﬁcations at a high level, which often involves knowledge-based statements.
For example, the goal of a program might be to guarantee that a certain process
knows certain information. It has been argued that a useful way of capturing
these high-level knowledge-based speciﬁcations is by using high-level knowledge-
based programs [13,14]. Knowledge-based programs are an attempt to capture
the intuition that what an agent does depends on what it knows. For example,
a knowledge-based program may say that process 1 should stop sending a bit to
process 2 once process 1 knows that process 2 knows the bit. Such knowledge-
based programs and speciﬁcations can be given precise semantics [13,14]. They
have already met with some degree of success, having been used both to help in
the design of new protocols and to clarify the understanding of existing protocols
[10,15,21].
In this paper, we add knowledge operators to event theory raising its level
of abstraction and show by example that knowledge-based programs can be
synthesized from constructive proofs that speciﬁcations in event theory with
knowledge operators are satisﬁable. Our example uses the sequence-transmission
problem, where a sender must transmit a sequence of bits to a receiver in such a
way that the receiver eventually knows arbitrarily long preﬁxes of the sequence.
Halpern and Zuck [15] provide two knowledge-based programs for the sequence-
transmission, prove them correct, and show that many standard programs for
the problem in the literature can be viewed as implementations of their high-
level knowledge-based program. Here we show that these two knowledge-based
programs can be synthesized from the speciﬁcations of the problem, expressed
in event theory augmented by knowledge. We can then translate the arguments
of Halpern and Zuck to Nuprl, to show that the knowledge-based programs can
be transformed to the standard programs in the literature.
Engelhardt, van den Meyden, and Moses [11,12] have also provided tech-
niques for synthesizing knowledge-based programs from knowledge-based speci-
ﬁcations, by successive reﬁnement. We see their work as complementary to ours.
Since our work is based on Nuprl, we are able to take advantage of the huge li-
brary of tactics provided by Nuprl to be able to generate proofs. The expressive
power of Nuprl also allows us to express all the high-level concepts of interest
(both epistemic and temporal) easily. Engelhardt, van den Meyden, and Moses

Knowledge-Based Synthesis of Distributed Systems Using Event Structures
451
do not have a theorem-proving engine for their language. However, they do pro-
vide useful reﬁnement rules that can easily be captured as tactics in Nuprl.
2
Synthesizing Programs from Constructive Proofs
2.1
Nuprl: A Brief Overview
Much current work on formal veriﬁcation using theorem proving, including Nuprl,
is based on type theory (see [8] for a recent overview). A type can be thought of
as a set with structure that facilitates its use as a data type in computation; this
structure also supports constructive reasoning. The set of types is closed under
constructors such as × and →, so that if A and B are types, so are A × B and
A →B, where, intuitively, A →B represents the computable functions from A
into B. Constructive type theory, upon which Nuprl is based, was developed to
provide a foundation for constructive mathematics. The key feature of construc-
tive mathematics is that “there exists” is interpreted as “we can construct (a
proof of)”. A consequence of this approach is that the law of excluded middle
does not hold.
Deﬁnition 1. A program in Nuprl is an object of some type Pgm. A program
semantics is a function S of type Pgm →Sem assigning to each program Pg of
type Pgm a meaning of type Sem. A speciﬁcation is a predicate X on Sem.
We take Pg |= X to be an abbreviation of X (S (Pg)), and Sat(X ) to be an
abbreviation for ∃Pg (Pg |= X ). Thus, the fact that a speciﬁcation is satisﬁable
is expressible in Nuprl. The key point for the purposes of this paper is that from
a constructive proof of Sat(X ), we can extract a program that satisﬁes X .
Constructive type logic is highly undecidable, so we cannot hope to construct
a proof completely automatically. However, experience has shown that, by having
a large library of lemmas and proof tactics, it is possible to “almost” automate
quite a few proofs, so that with a few hints from the programmer, correctness
can be proved. In any case, for an instance of this general constructive framework
to be useful in practice, the parameters Pgm, Sem, and S must be chosen so
that (a) programs are concrete enough to be compiled, and (b) speciﬁcations are
naturally expressed as predicates over Sem, and (c) there is a small set of rules
for producing proofs of satisﬁability.
To use this general framework for synthesis of distributed, asynchronous algo-
rithms, we choose the programs in Pgm to be distributed message automata. Mes-
sage automata are closely related to IO-Automata [17] and are roughly equivalent
to UNITY programs [7] (but with message-passing rather than shared-variable
communication). We describe distributed message automata in Section 2.3. As
we shall see, they satisfy criterion (a) above.
The semantics of a program is the system, or set of runs, consistent with
it. Typical speciﬁcations in the literature are predicates on runs. We can view
a speciﬁcation as a predicate on systems by saying that a system satisﬁes a
speciﬁcation exactly if all the runs in the system satisfy it. To satisfy criterion (b)

452
M. Bickford et al.
above, we choose a formal deﬁnition of runs that builds in the fundamental order
structure and provides the operators for appropriately abstract speciﬁcations. To
do this we formalize runs as structures that we call event structures, much in the
spirit of Lamport’s [16] model of events in distributed systems. Event structures
are explained in more detail in the next section.
2.2
Event Structures
Consider a set AG of processes or agents; associated with each agent in AG
is a set of local variables. Agent i’s local state at a point in time is deﬁned
as the values of its local variables at that time. There are no shared variables.
Information is communicated by message passing. Sending a message on some
link l is understood as enqueuing the message on l, while receiving corresponds
to dequeuing the message. Communication is asynchronous and point-to-point:
for each link l there is a unique agent source(l) that can send messages on l, and
a unique agent destination(l) that can receive message on l.
Following Lamport [16], changes in the local state of an agent are modeled as
events. Intuitively, when an event “happens”, an agent either receives a message
or chooses some values (perhaps nondeterministically). As a result of receiving
the message or the (nondeterministic) choice, the values of some of the agent’s
local variables change. Formally, events are elements of a type E. There is a
one-to-one function agent such that for any event e, agent(e) is the agent whose
local state changes during event e. The values of state variables before and after
e happens are described by binary functions when and after, typically written
using inﬁx notation: if agent(e) = i and x is one of i’s variables, then (x when e)
describes the value of x before e, and (x after e) describes its value after e.1 To
each event we associate a value and a kind. If the event happens as a result of a
receiving a message on some link l, then the event has kind rcv(l), and its value
is the corresponding message. Any other event has kind local(a), where a is the
label of the event, and its value is the set of values (nondeterministically) chosen
by the agent. The label of an event is just a syntactic identiﬁer that makes it
easier to do proofs and state conditions. Note that, unlike Lamport [16], we do
not have events of kind send. We model the sending of a message on a link l by
changing the value of the local variable that describes the message enqueued on
l. This variable can be changed during any event; that is, any event can involve
sending a message. This way of modeling events has proved to be convenient.
For each i ∈AG, the set of events e such that agent(e) = i is totally ordered.
Intuitively, this set of events is the agent i’s history. If ﬁrst(e) holds, then e is the
ﬁrst event in the history associated with agent(e); if not, then e has a predecessor
pred(e).
Every receive event e has a corresponding send event, denoted send(e); this
is the event where the message received at e was enqueued. Following Lamport
1 State variables are typed, but to simplify our discussion we suppress all type decla-
rations.

Knowledge-Based Synthesis of Distributed Systems Using Event Structures
453
[16], we can deﬁne a causal order on events as the transitive closure of the sender-
receiver and predecessor relations. Thus, →is the least relation on events such
that e →e′ if
– e′ is a receive event and e is the corresponding send event, or
– agent(e) = agent(e)′ and e precedes e′ in the total order associated with
agent(e), or
– for some event e′′ we have e →e′′ and e′′ →e′.
Intuitively, if e →e′, then e is guaranteed to happen before e′. We write e ≥e′
if e = e′ or e →e′.
Formally, an event structure consist of a collection of events satisfying some
natural properties: only ﬁnitely many messages can be sent when an event hap-
pens; the predecessor function is one to one; the causal order is well-founded;
pred(e) is associated with the same agent as e; if e has kind rcv(l), then the
agent associated with send(e) is source(l); and, ﬁnally, the local variables of
agent agent(e) do not change between pred(e) and e; that is, (x after pred(e)) =
(x when e). The type (set) of event structures is deﬁnable in Nuprl.
2.3
Distributed Message Automata
A message automaton is a nondeterministic state machine associated with some
agent i; it speciﬁes when i can take actions and which actions it can take. The
actions in programs are essentially events in event structures. We view a receive
action as being out of the control of the agent; all other actions have associated
preconditions. At each point in time i nondeterministically decides which actions
to perform, among those whose precondition is satisﬁed.
Message automata are built from a small set of basic clauses. With each basic
clause cl in an automaton we associate a formula φcl in the language of event
structures. The event structures consistent with cl are the ones satisfying φcl. If
we prove a speciﬁcation X is satisﬁable using a set {φcl | cl ∈C} of assumptions,
then the set C of the clauses used in the proof is a program satisfying X . This
is how we extract a program satisfying a speciﬁcation from a proof that the
speciﬁcation is satisﬁable.
A basic clause does one of the following:
1. deﬁnes the initial value of one state variable;
2. deﬁnes the eﬀect of one kind of event on one state variable;
3. deﬁnes the precondition for one kind of local event;
4. lists all the kinds of events that can change the value of one particular state
variable.
For convenience, we represent each of the basic clauses as a simple program
in a programming language. We give some examples here:
– A basic clause of the second type that says the message f(s, v) is sent by i
on link l when a local event e such that kind(e) = local(a) and value(e) = v

454
M. Bickford et al.
occurs and i’s local state is s, where f is some function (recall that, in our
framework, sending a message on link l amounts to changing the value of a
local variable that encodes messages enqueued on l) is represented by the
program
a(v) sends f (state, v) on l.2
– A basic clause of the third type that says that an event a with value v
and kind local(a) occurs only if precondition P holds is represented by the
program
a(v) only if P(state, v).
– The program representing an instance of the last clause that says that all
the events that result in sending a message on a link l are on the list L is
only events in L send on l.
The programs representing instances of the ﬁrst three clauses can be easily com-
piled into JAVA. The last clause is called a frame condition; it corresponds to a
promise not to add code.
A ﬁnite set C of basic clauses is feasible if there is an event structure (a
run) consistent with all the clauses in C (i.e., satisfying all the clauses φcl such
that cl ∈C). Every basic clause is feasible. A distributed message automaton
is a collection of message automata, one for each agent in the system. A frame
condition and an eﬀect clause may be incompatible; that is, they may not be
simultaneously satisﬁable. We can form more complicated programs from simpler
programs by composition. The composition A ⊕B of two programs A and B is
just the union of the clauses from A and B. The rules restrict composition of
message automata to automata whose clauses are pairwise compatible. The set
(type) of distributed message automata is the smallest set of feasible clauses
containing the four basic clauses and closed under ⊕. By adding the appropriate
constants and functions to Nuprl, we can ensure that each program is a term in
the language.
The semantics of a distributed message automaton is the set of event struc-
tures that are consistent with it. In terms of the language used in Section 2.1,
an event structure is a run, and a set of event structures is a system. As we show
in the full paper, the semantics can formally be deﬁned in Nuprl as a relation
Consistent(Pg, es) between a program (i.e., message automaton) Pg and event
structure es. The set of event structures consistent with Pg is denoted Sys(Pg).
The fact that Consistent is deﬁnable in Nuprl is critical: it means that we can
talk about whether an event structure is consistent with a program in Nuprl.
Recall that a speciﬁcation is a predicate on systems, i.e., on the meaning of
programs. Many speciﬁcations that arise in practice are of a special type called
run-based speciﬁcations [13]. A run-based speciﬁcation is given as a predicate on
runs (i.e., event structures). We can view a predicate P on runs as a predicate
2 Here the notation a(v) is just a compact way of saying that the value of an event of
kind local(a) is v, and does not refer to function application.

Knowledge-Based Synthesis of Distributed Systems Using Event Structures
455
on systems by taking P to hold of a system if it holds of every run of the system.
If P is a run-based speciﬁcation, then Pg |= P exactly if
∀es.(Consistent(Pg, es) ⇒P(es)) ∧∃es.Consistent(Pg, es).
Bickford and Constable [5] derived from the formal semantics of distributed
message automata a set of seven useful Nuprl axioms for proving the satisﬁabil-
ity of a run-based speciﬁcation There are four base axioms, one for each basic
clause, an additional axiom for the combination of precondition and initialization
clauses, a composition axiom, and a reﬁnement axiom. We now brieﬂy discuss
these axioms.
The reﬁnement axiom says that if P reﬁnes Q (that is, if P(es) implies Q(es)
for all event structures es) and A satisﬁes P, then A also satisﬁes Q:
A |= P ⇒∀es.(P(es) ⇒Q(es)) ⇒A |= Q.
The composition axiom says that if two programs A and B are compatible (that
is, their clauses are pairwise compatible), denoted A||B, then A ⊕B combines
the constraints of A and B:
(A |= P ∧B |= Q ∧A||B) ⇒A ⊕B |= P ∧Q.
The axiom for each basic clause cl is just the corresponding formula φcl. We
give two examples of the axioms here; see [5] for the others.
The axiom corresponding to the basic clause “agent i initializes x to 5” is
∀e@i.ﬁrst(e) ⇒(x when e) = 5, where ∀e@i.P is an abbreviation of the for-
mula ∀e.agent(e) = i ⇒P. For the axiom corresponding to the precondition
clause, let state(e) be the state associated with event e; that is, the values of all
the local variables in event e. Similarly, let state(after(e)) be the values of the
variables after e. (This, of course, is just state(e′) where e′ is the successor of
e in the history, if there is a successor.) The intended meaning of the precondi-
tion clause a(v) only if P(state, v) in a program for agent i is that, inﬁnitely
often, agent i checks whether there is a some value v such that P(state(e), v)
holds; if so then, inﬁnitely often, i chooses such a value v and an event of kind
local(a) and value v occurs. Moreover, an event of kind local(a) occurs only when
its value satisﬁes the precondition. Finally, the clause rules out ﬁnite event se-
quences where an event of kind local(a) could be performed after the last event,
but is not. The axiom φcl for this clause is the conjunction of two formulas. The
ﬁrst is
∀e@i[∃e′ ≥e(kind(e′) = local(a)) ∨∀v ′(¬P(state(after(e)), v ′))],
which says that either inﬁnitely often an event of kind local(a) occurs, or in-
ﬁnitely often P is false, or the sequence is ﬁnite and P is false after the last event.
The second conjunct gives the obvious safety condition, namely, that P is a pre-
condition for an event of kind local(a): ∀e@i.kind(e) = local(a) ⇒P(state(e),
val(e)).

456
M. Bickford et al.
2.4
Example
As an example of a parameterized speciﬁcation that we use later, consider the fol-
lowing predicate Fair(P, f , l) on event structures, where P is a precondition, f is
a partial function (deﬁned on states where P holds), and l is a link. Fair(P, f , l)
is a conjunction of a safety condition and a liveness condition. The safety con-
dition asserts that the value of every receive event on link l is given by f of
the state of the sender and that state satisﬁes the precondition P. The liveness
condition says that, inﬁnitely often, either a receive event on l occurs or else the
precondition P fails. In the speciﬁcation, we abbreviate P(state(e), val(e)) by
P@e; we similarly use f@e. The speciﬁcation is
Fair(P, f , l) ≡
∀e′.kind(e′) = rcv(l) ⇒P@send(e′) ∧val(e′) = f @send(e′)
∧∀e@source(l).∃e′ ≥e.kind(e′) = rcv(l) ∨∀v ′.¬(P(state(after(send(e′))), v ′).
This speciﬁcation is satisﬁed by the following program Fair-Pg(P, f , l) for
agent source(l), which combines three basic clauses:
a(v) only if P(state, v) ⊕a(v) sends f (state, v) on l ⊕
only events in {local(a)} send on l.
Lemma 1. Fair-Pg(P, f , l) satisﬁes the speciﬁcation Fair(P, f , l). Moreover,
this can be proved using the seven axioms.
3
Adding Knowledge to Nuprl
3.1
Consistent Cut Semantics for Knowledge
To reason about knowledge in event structures we use a standard ﬁrst-order
modal logic of knowledge and time. Assume that there are n processes. Consider
a ﬁrst-order logic of knowledge and time, where formulas are formed by starting
with a set Φ of functions symbols, predicate symbols, and constant symbols of
various arities. We form atomic predicates and terms as usual in ﬁrst-order logic,
and close under conjunction, negation, universal quantiﬁcation, the temporal
operator
, and the operators Ki, i = 1, . . . , n, one for each process i.
Typically semantics for knowledge are given with respect to a pair (r, m)
consisting of a run r and a time m, assumed to be the time on some external
global clock (that none of the processes necessarily knows about) [13]. In event
structures, there is no external notion of time. Fortunately, Panangaden and
Taylor [18] give a variant of the standard deﬁnition with respect to what they
call asynchronous runs, which are essentially identical to event structures. Thus,
we just apply their deﬁnition in our framework.
The truth of formulas is deﬁned relative to a triple (Sys, E, c), consisting of
a system Sys (i.e., a set of event structures), and event structure E in Sys, and
a consistent cut c of E, where a consistent cut c in E is a set of events in E closed

Knowledge-Based Synthesis of Distributed Systems Using Event Structures
457
under the causality relation. That is, if e′ is an event in c and e is an event in E
that precedes e′ (i.e., e →e′), then e must also be in c.
Deﬁne the equivalence relations ∼i, i = 1, . . . , n, on consistent cuts by taking
c ∼i c′ if i’s history is the same in c and c′. Intuitively, c ∼i c′ if process i cannot
tell c and c′ apart, given its information. Given two consistent cuts c and c′, we
say that c ⪯c′ if, for each process i, process i’s history in c is a preﬁx of process
i’s history in c′.
Given a nonempty set of objects D and a system Sys, an interpretation
function π associates to each cut c and symbol s in Φ its interpretation, denoted
π(c, s), which is a predicate or function on D of the right arity. To extend this
interpretation to terms, we start with a valuation V , which associates with each
variable an element of D. For each variable x, we deﬁne π(c, x) = V (x). We then
deﬁne π(c, f(t1, . . . , tk)) by induction on the structure of terms, taking
π(c, f(t1, . . . , tk)) = π(c, f)(π(c, t1), . . . , π(c, tk)).
Using V and π, we deﬁne what it means for a formula φ to be true at the con-
sistent cut c in event structure E in system Sys, denoted (Sys, E, c, π, V ) |= φ,
by induction on the structure of φ, in the usual way. For example
– (Sys, E, c, π, V ) |= Kiϕ iﬀ∀E′ ∈Sys, and c′ cut of E′ such that c′ ∼i c, we
have (Sys, E′, c′, π, V ) |= ϕ
– (Sys, E, c, π, V ) |=
ϕ iﬀfor all cuts c′ of E such that c ⪯c′, we have
(Sys, E, c′, π, V ) |= ϕ.
As usual, we take ♦φ to be an abbreviation of ¬
¬φ, so that ♦φ is true at
(E, c) if there is some cut c′ extending c where φ is true. Similarly we write ♦- ϕ
if there was a time in past when ϕ was true, or ϕ holds at cut c. The complete
deﬁnition of |= is given in the appendix.
The satisfaction relation |= can be expressed as a formula in Nuprl. More
precisely, there is a translation T (which we deﬁne in the appendix) such that
for all tuples (Sys, E, c), domains D, interpretations π, valuations V , and formu-
las ϕ, T(Sys, E, c, D, π, V ϕ) is true iﬀ(Sys, E, c, V, π) |= ϕ. There is a subtlety
though. First-order epistemic logic assumes the principle of excluded middle;
Nuprl is a constructive type theory that does not. To prove that T has the de-
sired properties, we need to assume the law of the excluded middle. We remark
that this assumption is necessary only for the purpose of this translation and
not for the proofs we present in Section 4.
3.2
Knowledge-Based Programs and Speciﬁcations
In this section, we show how we can extend the notions of program and speci-
ﬁcation presented in Section 2 to knowledge-based programs and speciﬁcations.
This allows us to employ the large body of tactics and libraries already devel-
oped in Nuprl to synthesize knowledge-based programs from knowledge-based
speciﬁcations.

458
M. Bickford et al.
We have identiﬁed programs with distributed message automata, where a
distributed message automaton is characterized by a set of clauses. We take a
knowledge-based message automaton to be a function that associates to each sys-
tem (i.e. set of event structures) a message automaton; intuitively, a knowledge-
based message automaton allows preconditions on actions to depend on the
knowledge of processes about the whole system. For the purposes of this pa-
per, we take knowledge-based programs (hereafter abbreviated kb programs) to
be knowledge-based message automata. Note that each standard program Pg
corresponds to the kb program that associates to each system the program Pg.
What should the semantics of a kb program be? As discussed in Section 2,
in the case of standard programs, a program semantics is a function S that
associates with every program Pg of type Pgm the system S(Pg) consisting
of all the runs consistent with Pg. As we have seen, the truth of a knowledge
test in a kb program depends on the whole system. Once we have a system,
we can determine the truth of the knowledge tests. A kb program then reduces
to a standard program. Thus, a kb program has type Pgmkb = Sem →Pgm.
Note that composing the semantic function S with a knowledge-based program
yields a function from systems to systems. A system Sys is said to represent a
kb program Pgkb if it is a ﬁxed point of this function: Sys represents the kb
program Pgkb if S(Pgkb Sys) = Sys. Following Fagin et al. [13,14], we take the
semantics of a kb program Pgkb to be the set of systems that represent Pgkb.
Deﬁnition 2. A kb program semantics S kb is a function of type Pgmkb →
P(Sem), where P(Sem) is the type whose elements are sets of systems.
As observed by Fagin et al. [13,14], it is possible to construct kb programs that
are represented by no systems, exactly one system, or more than one system.
It is also possible to construct suﬃcient conditions (which are often satisﬁed in
practice) that guarantee that a kb program is represented by exactly one system.
Note that, in particular, standard programs, when viewed as kb programs, are
represented by a unique system; indeed, S kb(Pg) = {S(Pg)}. Thus, we can view
S kb as extending S.
We next consider knowledge-based speciﬁcations (hereafter abbreviated kb
speciﬁcations). Recall that a (standard) speciﬁcation is a predicate on runs.
Following [13,14], we take a kb speciﬁcation to be a predicate on systems.
Deﬁnition 3. A kb speciﬁcation is an object of type Sem →P. A kb program
Pgkb satisﬁes a kb speciﬁcation X kb, written Pgkb |= X kb, if all the systems rep-
resenting Pgkb satisfy X and S kb(Pgkb) ̸= ∅; i.e., ∀Sys ∈S kb(Pgkb). X kb(Sys)∧
S kb(Pgkb) ̸= ∅.
3.3
Example
Recall that in Section 2 a speciﬁcation Fair(P, f , l) was deﬁned that requires
that, inﬁnitely often, either a precondition P fails at the state of the source of
some link or a message is received on the link; the message is constructed by
applying the function f at the source of the link. The speciﬁcation is satisﬁed

Knowledge-Based Synthesis of Distributed Systems Using Event Structures
459
by a standard program Fair-Pg(P, f , l). Fair(P, f , l) can be generalized to a
kb speciﬁcation Fair kb(Pkb, f kb, l) where, instead of using a precondition P and
function f , we use a kb predicate Pkb and a kb function f kb, both of which take
a system as an extra argument (in addition to the other arguments of P and f ).
Fair kb(Pkb, f kb, l) asserts that, in every run of the system, inﬁnitely often either
the kb precondition fails or a receive event with the value given by f kb occurs
on link l:
Fair kb(Pkb, f kb, l) ≡
∀e′.kind(e′) = rcv(l) ⇒Pkb@send(e′) ∧val(e′) = f kb@send(e′)
∧∀e@source(l).∃e′ ≥e.kind(e′) = rcv(l) ∨∀v ′.¬(Pkb(state(after(e′)), v ′)
Fair kb(Pkb, f kb, l) is satisﬁed by a kb program Fair-Pgkb(Pkb, f kb, l):
a(v) only if Pkb(state, v) ⊕
a(v) sends f kb(state, v) on l ⊕
only events in {local(a)} send on l
Fair-Pgkb(Pkb, f kb, l) associates to each system Sys the program
Fair-Pg(Pkb(Sys), f kb(Sys), l); in system Sys, a process following
Fair-Pgkb(Pkb, f kb, l) sends a message with value determined by f kb(Sys) exactly
when Pkb(Sys) is true.
Lemma 2. Fair-Pgkb(Pkb, f kb, l) satisﬁes the speciﬁcation Fair kb(Pkb, f kb, l).
4
The Sequence Transmission Problem
In this section, we illustrate how programs can be extracted from knowledge-
based speciﬁcations using the Nuprl system.We do the extraction in two stages.
In the ﬁrst stage, we use Nuprl to prove that the speciﬁcation is satisﬁable. The
proof proceeds by reﬁnement: at each step, a rule or tactic (i.e. sequence of rules
invoked under a single name) is applied, and new subgoals are generated; when
there are no more subgoals to be proved, the proof is complete. The proof is
automated, in the sense that subgoals are generated by the system upon tactic
invocation. From the proof, we can extract a knowledge-based program Pgkb
that satisﬁes the speciﬁcation. In the second stage, we ﬁnd standard programs
that implement Pgkb.
We illustrate this methodology by applying it to one of the problems that has
received considerable attention in the context of knowledge-based programming,
the sequence transmission problem (stp). The stp involves a sender S that has
an input tape with a (possibly inﬁnite) sequence X = X [0], X [1], . . . of bits, and
wants to transmit X to a receiver R; R must write this sequence on an output
tape Y . A solution to the problem must satisfy two conditions:
1. (safety): at all times, the sequence Y of bits written by R is a preﬁx of X ,
and
2. (liveness): every bit X [k] is eventually written by R on the output tape.

460
M. Bickford et al.
Halpern and Zuck [15] deﬁne two kb programs that solve this problem, and show
that a number of standard programs in the literature, like Stenning’s algorithm
[20], the alternating bit protocol [3], and Aho, Ullman and Yannakakis’s [1]
algorithms are all particular instances of these programs. Sanders [19] derives
a number of kb and standard programs for the same problem, with a focus on
the more practical aspects of program development. Our method uses ideas from
both of these earlier works.
If messages cannot be lost, duplicated, reordered, or corrupted, then S could
simply send the bits in X to R in order. However, we are interested in solutions
to the stp in contexts where communication is not reliable. Without some con-
straints, the stp is unsolvable; following [15], we assume (a) that all corruptions
are detectable and (b) a weak fairness condition: all messages sent inﬁnitely often
are eventually received.
The safety and liveness conditions above are run-based speciﬁcations. As
argued by Fagin et al. in [13], it is often better to think in terms of knowledge-
based speciﬁcations for this problem. The real goal of the stp is to get the
receiver to know the bits. Writing KR(X [i]) as an abbreviation for KR(X [i] = 0)
∨KR(X [i] = 1), we really want a knowledge-based condition of the form
ϕkb def
≡∀i ♦KR(X [i]).
One way to achieve this condition is by requiring that the receiver makes progress:
for each i, if for all j < i there was a time when R knew X [j], then eventually
R knows X [i].
Intuitively, the sender is responsible for R’s progress. But how can S ensure
that R learns the ith bit? For any ﬁnite number n, it is possible that a message
sent n times is not received. Fortunately, the fairness condition ensures that if
X [i] is sent an unbounded number of times, R will receive it. Thus, S can ensure
that R learns the ith bit if, inﬁnitely often, either S sends X [i] or S knows that
R knew X [i] at some time in the past. This is similar in spirit to the speciﬁcation
Fair kb(Pkb, f kb, l) described in Example 3.3. In this case, l is the communication
link from S to R, f kb encodes the least bit that S does not know that R knew
at some point in the past, i.e., the pair (i, X[i]) for the least index i such that
¬KS♦- KRX [i] holds. Pkb is instantiated with a test on S’s knowledge such that
whenever Pkb fails, ∀i ♦- KRX [i] holds. Thus, we take Pkb ≡∃i ¬KS(♦- KRX [i])
Note that, unless at some point S knows that R knows the whole sequence, Pkb
will be true. (Indeed, in many settings, we can just take Pkb to be the formula
true.) We abbreviate this speciﬁcation as Fair kb(Pkb
S , f kb
S , lSR).
How does the sender learn which bits the receiver knows? One possibility is
for S to receive from R a request to send X [i]. This can be taken by S to be a
signal that R knows all the preceding bits. R’s program for sending this request
to S can again be viewed as an instance of the speciﬁcation Fair kb(Pkb, f kb, l),
this time for l the communication link from R to S, and f kb returning the least
index i such that R never knew X [i]. We take Pkb to be ∃i¬♦- KRX[i] (again, in
many contexts, we can take it to be simply true) and abbreviate this speciﬁcation
as Fair kb(Pkb
R , f kb
R , lRS).

Knowledge-Based Synthesis of Distributed Systems Using Event Structures
461
Up to this point we have only used our intuition to guess a plausible re-
ﬁnement for our initial speciﬁcation ϕkb. We can now use the system to verify
this intuition. That is, we prove that the satisﬁability of ϕkb follows from the
satisﬁability of each of Fair kb(Pkb
R , f kb
R , lRS) and Fair kb(Pkb
S , f kb
S , lSR) separately:
Goal:
|= ϕkb
Subgoal 1: |= Fair kb(Pkb
R , f kb
R , lRS)
Subgoal 2: |= Fair kb(Pkb
S , f kb
S , lSR)
Subgoal 3: (|= Fair kb(Pkb
R , f kb
R , lRS)) ∧(|= Fair kb(Pkb
S , f kb
S , lSR)) ⇒(|= ϕkb)
The proof is carried out in Nuprl in two steps. Using Lemma 2, we can prove
that there exist kb programs, Fair-Pgkb(Pkb
R , f kb
R , lRS) and Fair-Pgkb(Pkb
S , f kb
S ,
lSR), respectively, that satisfy both fairness speciﬁcations; i.e.,
Fair-Pgkb(Pkb
R , f kb
R , lRS) |= Fair kb(Pkb
R , f kb
R , lRS)
Fair-Pgkb(Pkb
S , f kb
S , lSR) |= Fair kb(Pkb
S , f kb
S , lSR).
Finally we have to check that the combination of the two programs satisﬁes
the conjunction of the speciﬁcations satisﬁed by each program separately. This
means that we have to inspect the frame conditions for both programs, i.e.
the conditions that allow only R to send messages of the form i to S, and
only S to send pairs ⟨i, X [i]⟩to R. Since messages sent by the programs go on
separate links, the frame conditions are easily seen to be compatible with the
eﬀect clauses. Thus, we can prove
Fair-Pgkb(Pkb
R , f kb
R , lRS) ⊕Fair-Pgkb(Pkb
S , f kb
S , lSR) |= ϕkb.
Using the program notation of Fagin et al. [13], Fair-Pgkb(Pkb
S , f kb
S , lSR) con-
sists of the following collection of statements (one for each i):
if KS(♦- KRX[0] ∧. . . ∧♦- KRX[i −1]) ∧¬KS(♦- KRX[i])
then sendlSR(⟨i, X [i]⟩) else skip.
Similarly, Fair-Pgkb(Pkb
R , f kb
R , lRS) consists of the following collection of state-
ments:
if ♦- KRX[0] ∧. . . . . . ∧♦- KRX[i −1] ∧¬♦- KRX[i] then sendlRS(i) else skip.
Notice that whenever S sends a message ⟨i, X[i]⟩, i is the minimum index
for which ¬KS(♦- KRX[i]); similarly, R always sends the minimum i for which
¬♦- KRX[i]. We can make this explicit by letting S and R have local variables,
say i and j, to keep track of these minimum indices. The variables i and j are
initially set to 0; S increments i from the current value v to v + 1 whenever
he learns that ♦- KRX[v] holds, and similarly, R increments j from v to v + 1
whenever he learns X[v]. The knowledge test in the sender program can then
be rewritten as ¬KS(♦- KRX[v]), for v the current value of i, and the knowledge

462
M. Bickford et al.
test for the receiver becomes ¬♦- KRX[j]; thus the derived program is essentially
one of the knowledge-based programs considered by Halpern and Zuck [15].
This is not surprising, since our derivation followed much the same reasoning
as that of Halpern and Zuck. However, note that we did not ﬁrst give a kb
program and then verify that it satisﬁed the speciﬁcation. Rather, we derived
the kb programs for the sender and receiver from the proof that the speciﬁcation
was satisﬁable. And, while Nuprl required “hints” from us in terms of what to
prove, the key ingredients of the proof, namely, the speciﬁcation Fair(P, f , l) and
the proof that Fair-Pg(P, f , l) realizes it, were already in the system, having been
used in other contexts. Thus, this suggests that we may be able to apply similar
techniques to derive programs satisfying other speciﬁcations in communication
systems with only weak fairness guarantees.
This takes care of the ﬁrst stage of the synthesis process. We now want to ﬁnd
a standard program that implements the knowledge-based program. As discussed
by Halpern and Zuck [15], the exact standard program that we use depends on
the underlying assumptions about the communications systems. Here we sketch
an approach to ﬁnding the standard program.
The ﬁrst step is to identify the exact properties of knowledge that are needed
for the proof. We can inspect the proof and identify which properties of the
knowledge operators KS and KR seem to be used. We replace ♦- (KR(X [i] = v))
by an abstract predicate Q(X [i] = v) and KS(♦- KR(X [i] = v)) by P(X [i] = v).
As before, we abbreviate P(X [i] = 0) ∨P(X [i] = 1) as P(X [i]), and Q(X [i]) for
Q(X [i] = 0) ∨Q(X [i] = 1). We add as hypotheses all the identiﬁed properties,
now as properties of Q and P, and check whether the former proof still applies.
If not, we add whatever additional properties are needed. Note that we can use
Nuprl to automate these checks.
This approach enables us to prove that the speciﬁcation is satisﬁable in a
more general setting. The speciﬁcation is now written in terms of P and Q,
and denoted ˜ϕkb. Fair kb(Pkb
R , f kb
R , lRS) is replaced by Fair kb( ˜Q, ˜
fR, lRS) with
˜Q
def
≡∃i ¬Q(X [i]), and similarly, Fair kb(Pkb
S , f kb
S , lSR) becomes Fair kb(˜P, ˜fS, lSR)
with ˜P
def
≡∃i ¬P(X [i]). Whenever ˜Q and ˜P hold, ˜fR and ˜fS return the minimum
index i such that ¬Q(X [i]) and ¬P(X [i]), respectively.
The new theorem states that, under suitable hypotheses about P and Q,
˜ϕkb is satisﬁable since both Fair kb(˜Q, ˜fR, lRS) and Fair kb(˜P, ˜fS, lSR) are satis-
ﬁable. One hypothesis we require is that P and Q must be sound tests, that
is, P(X [k] = v) and Q(X [k] = v) both imply X [k] = v; this is clearly true of
knowledge predicates. We must also assume that after R receives a message of
the form ⟨i, v⟩, Q(X [i] = v) holds; similarly, after S receives some message i,
∀j < i P(X [j]) holds. The extracted program is
Fair-Pgkb(˜Q, ˜fR, lRS) ⊕Fair-Pgkb(˜P, ˜fS, lSR),
where Fair-Pgkb(˜P, ˜fS, lSR), written using Fagin et al. notation, consists of the
statements
if P(X[0]) ∧. . . P(X[i −1]) ∧¬P(X[i]) then sendlSR(⟨i, X[i]⟩) else skip;

Knowledge-Based Synthesis of Distributed Systems Using Event Structures
463
similarly, Fair-Pgkb(˜Q, ˜fR, lRS) consists of the statements
if Q(X[0]) ∧. . . Q(X[i −1]) ∧¬Q(X[i]) then sendlRS(i) else skip.
Clearly, this is a generalization of the ﬁrst kb-program for the stp. Furthermore,
it is clear that other predicates P and Q satisfy these hypotheses. For example,
suppose that S has a state variable iS such that P(X [0]) ∧. . . P(X [is −1])∧
¬P(X[iS]) holds at the current state of S; similarly, R has a state variable iR
such that Q(X [0]) ∧. . . ∧Q(X [iR −1]) ∧¬Q(X [iR]) holds. We can then sim-
ply deﬁne P′(X [k])
def
≡iS > k and Q′(X [k])
def
≡iR > k; the resulting program is
exactly Stenning’s [20] protocol.
The key point here is that by replacing the knowledge tests by weaker pred-
icates that imply them and do not explicitly mention knowledge, we can derive
standard programs that implement the knowledge-based program. We believe
that other standard implementations of the knowledge-based program can be
derived in a similar way, although we have not yet concluded the derivation. We
hope to report on this shortly. 3
References
1. A. V. Aho, J. D. Ullman, A. D. Wyner, and M. Yannakakis. Bounds on the size
and transmission rate of communication protocols. Computers and Mathematics
with Applications, 8(3):205–214, 1982. This is a later version of [2].
2. A. V. Aho, J. D. Ullman, and M. Yannakakis. Modeling communication protocols
by automata. In Proc. 20th IEEE Symp. on Foundations of Computer Science,
pages 267–273. 1979.
3. K. A. Bartlett, R. A. Scantlebury, and P. T. Wilkinson. A note on reliable full-
duplex transmission over half-duplex links. Communications of the ACM, 12:260–
261, 1969.
4. J. L. Bates and Robert L. Constable. Proofs as programs. ACM Transactions on
Programming Languages and Systems, 7(1):53–71, 1985.
5. Mark Bickford and Robert L. Constable.
A logic of events.
Technical Report
TR2003-1893, Cornell University, 2003.
6. Mark Bickford, Christoph Kreitz, Robbert van Renesse, and Xiaoming Liu. Proving
hybrid protocols correct. In Richard Boulton and Paul Jackson, editors, 14th Inter-
national Conference on Theorem Proving in Higher Order Logics, volume 2152 of
Lecture Notes in Computer Science, pages 105–120, Edinburgh, Scotland, Septem-
ber 2001. Springer-Verlag.
7. K. M. Chandy and J. Misra. Parallel Program Design: A Foundation. Addison-
Wesley, Reading, Mass., 1988.
8. Robert L. Constable. Na¨ıve computational type theory. In H. Schwichtenberg and
R. Steinbr¨uggen, editors, Proof and System-Reliability, Proceedings of International
Summer School Marktoberdorf, July 24 to August 5, 2001, volume 62 of NATO
Science Series III, pages 213–260, Amsterdam, 2002. Kluwer Academic Publishers.
3 Extracts from the event system library can be seen at
http://www.cs.cornell.edu/Info/People/sfa/Nuprl/EventSystems/.

464
M. Bickford et al.
9. Robert L. Constable et al. Implementing Mathematics with the Nuprl Proof Devel-
opment System. Prentice-Hall, NJ, 1986.
10. C. Dwork and Y. Moses. Knowledge and common knowledge in a Byzantine envi-
ronment: crash failures. Information and Computation, 88(2):156–186, 1990.
11. K. Engelhardt, R. van der Meyden, and Y. Moses. A program reﬁnement framework
supporting reasoning about knowledge and time. In J. Tiuryn, editor, Proc. Foun-
dations of Software Science and Computation Structures (FOSSACS 2000), pages
114–129. Springer-Verlag, Berlin/New York, 1998.
12. K. Engelhardt, R. van der Meyden, and Y. Moses.
A reﬁnement theory that
supports reasoning about knowledge and time for synchronous agents.
In
Proc. Int. Conf. on Logic for Programming, Artiﬁcial Intelligence, and Reason-
ing, pages 125–141. Springer-Verlag, Berlin/New York, 2001.
13. R. Fagin, J. Y. Halpern, Y. Moses, and M. Y. Vardi. Reasoning about Knowledge.
MIT Press, Cambridge, Mass., 1995.
14. R. Fagin, J. Y. Halpern, Y. Moses, and M. Y. Vardi. Knowledge-based programs.
Distributed Computing, 10(4):199–225, 1997.
15. J. Y. Halpern and L. D. Zuck. A little knowledge goes a long way: knowledge-based
derivations and correctness proofs for a family of protocols. Journal of the ACM,
39(3):449–478, 1992.
16. L. Lamport.
Time, clocks, and the ordering of events in a distributed system.
Communications of the ACM, 21(7):558–565, 1978.
17. Nancy Lynch and Mark Tuttle. An introduction to Input/Output automata. Cen-
trum voor Wiskunde en Informatica, 2(3):219–246, September 1989.
18. P. Panangaden and S. Taylor. Concurrent common knowledge: deﬁning agreement
for asynchronous systems. Distributed Computing, 6(2):73–93, 1992.
19. B. Sanders. A predicate transformer approach to knowledge and knowledge-based
protocols. In Proc. 10th ACM Symp. on Principles of Distributed Computing, pages
217–230, 1991. A revised report appears as ETH Informatik Technical Report 181,
1992.
20. M. V. Stenning. A data transfer protocol. Comput. Networks, 1:99–110, 1976.
21. F. Stulp and R. Verbrugge. A knowledge-based algorithm for the Internet protocol
(TCP). Bulletin of Economic Research, 54(1):69–94, 2002.
A
Translating |= into Nuprl
Using valuation V and interpretation π, the fact that formula φ is true at the con-
sistent cut c in event structure E in system Sys is denoted (Sys, E, c, π, V ) |= φ
and deﬁned by induction on the structure of φ as follows:
– if P is a predicate symbol in Φ of some arity k, and t1, . . . , tk are terms, then
(Sys, E, c, π, V ) |= P(t1, . . . , tk) iﬀπ(c, P)(π(c, t1), . . . , π(c, tk))
– (Sys, E, c, π, V ) |= ¬ϕ iﬀ(Sys, E, c, π, V ) ̸|= ϕ
– (Sys, E, c, π, V ) |= ϕ1∧ϕ2 iﬀ(Sys, E, c, π, V ) |= ϕ1 and (Sys, E, c, π, V ) |= ϕ2
– (Sys, E, c, π, V ) |= ∀x.ϕ iﬀ, for all d ∈D, (Sys, E, c, π, V [x/d]) |= ϕ, where
V [x/d] is the valuation that agrees with V on all variables except possible
x, and V [x/d](x) = d
– (Sys, E, c, π, V ) |= Kiϕ iﬀfor all E′ ∈Sys and cuts c′ of E′ such that c′ ∼i c,
(Sys, E′, c′, π, V ) |= ϕ

Knowledge-Based Synthesis of Distributed Systems Using Event Structures
465
– (Sys, E, c, π, V ) |=
ϕ iﬀfor all cuts c′ of E such that c ⪯c′, we have
(Sys, E, c′, π, V ) |= ϕ
– (Sys, E, c, π, V ) |= ♦ϕ iﬀthere exists a cut c′ of E such that c ⪯c′ and
(Sys, E, c′, π, V ) |= ϕ
– (Sys, E, c, π, V ) |= ♦- ϕ iﬀthere exists a cut c′ of E such that c′ ⪯c and
(Sys, E, c′, π, V ) |= ϕ.
We can now deﬁne the translation T by induction on the structure of formu-
las:
– if P is a predicate symbol in Φ of some arity k, and t1, . . . , tk are terms, then
T(Sys, E, c, D, π, V, P(t1, . . . , tk)) = π(c, P)(π(c, t1), . . . , π(c, tk)
– T(Sys, E, c, D, π, V, ¬ϕ) = ¬(T(Sys, E, c, D, π, V, ϕ))
– T(Sys, E, c, D, π, V, ϕ1 ∧ϕ2)) = (T(Sys, E, c, D, π, V, ϕ1))∧(T(Sys, E, c, D,
π, V, ϕ2))
– T(Sys, E, c, D, π, V, (∀x.ϕ)) = ∀x.(T(Sys, E, c, D, π, V, (ϕ(V x)))
– T(Sys, E, c, D, π, V, Kiϕ) = ∀E′.E′ ∈Sys ⇒∀c′.c′ ∼i c ⇒(T(Sys, E′, c′, D,
π, V, ϕ))
– T(Sys, E, c, D, π, V,
ϕ) = ∀c′.c ⪯c′ ⇒(T(Sys, E, c′, D, π, V, ϕ))
From this deﬁnition it follows that, assuming the principle of excluded middle,
T(Sys, E, c, D, π, V ϕ) is provable iﬀ(Sys, E, c, V, π) |= ϕ.
Proposition 1. Assuming the principle of excluded middle, for all tuples (Sys,
E, c), domains D, interpretations π, valuations V , and formulas ϕ, T(Sys, E, c,
D, π, V, ϕ) is provable iﬀ(Sys, E, c, V, π) |= ϕ.

The Inverse Method for the Logic of Bunched
Implications
Kevin Donnelly1, Tyler Gibson2, Neel Krishnaswami3, Stephen Magill3, and
Sungwoo Park3
1 Department of Computer Science, Boston University, 111 Cummington Street, Boston
MA 02215, USA,
kevind@bu.edu
2 Department of Philosophy, Carnegie Mellon University, 5000 Forbes Avenue,
Pittsburgh PA 15213, USA,
tylerg@andrew.cmu.edu
3 Computer Science Department, Carnegie Mellon University, 5000 Forbes Avenue,
Pittsburgh PA 15213, USA,
{neelk,smagill,gla}@cs.cmu.edu
Abstract. The inverse method, due to Maslov, is a forward theorem prov-
ing method for cut-free sequent calculi that relies on the subformula prop-
erty. The Logic of Bunched Implications (BI), due to Pym and O’Hearn,
is a logic which freely combines the familiar connectives of intuitionis-
tic logic with multiplicative linear conjunction and its adjoint implication.
We present the ﬁrst formulation of an inverse method for propositional
BI without units. We adapt the sequent calculus for BI into a forward
calculus. The soundness and completeness of the calculus are proved, and
a canonical form for bunches is given.
1
Introduction
1.1
The Logic of Bunched Implications
The study of substructural logics, beginning with linear logic [10], has shown
the usefulness of restricting the structural rules of weakening, contraction, com-
mutativity and associativity. These logics have shown promise in modeling a
variety of situations, including reasoning about computations. For example, us-
ing the resource interpretation of linear logic, we can reason about availability
and use of resources that cannot be regenerated. The example of linear logic
also shows the usefulness of making available controlled uses of the eliminated
structural rules (which in linear logic comes in the form of the ! and ? modali-
ties).
The Logic of Bunched Implications (BI) [13,15] comes from freely combin-
ing the additive conjunction of intuitionistic logic with the multiplicative con-
junction of linear logic. It is important to note that while the rules for introduc-
ing and eliminating multiplicatives are the same as those of linear logic, the
use-once resource semantics of the multiplicative connectives no longer holds
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 466–480, 2005.
c⃝Springer-Verlag Berlin Heidelberg 2005

The Inverse Method for the Logic of Bunched Implications
467
in BI because of the possibility of nested additives. In the presence of two con-
text forming operations, there naturally arises two different implications with
the following adjoint relationships.
A ∗B ⊢C ⇐⇒A ⊢B −∗C and A ∧B ⊢C ⇐⇒A ⊢B ⊃C
The free combination of these conjunctions and implications leads to a logic
with tree structured contexts, and a calculus in which the multiplicative con-
junction distributes over the additive conjunction, but the inverse, factoring
multiplicatives out of additives, does not hold. This leads to a lack of a struc-
tural canonical form, which presents a challenge to the standard formulation of
the inverse method.
1.2
The Inverse Method
The inverse method [7,14] is a saturation based theorem proving technique for
sequent calculi which is related to resolution [4]. First proposed by Maslov [12],
the inverse method starts from a collection of axioms in a database and works
forward by applying rules to the sequents in the database and adding the re-
sults of these rules back into the database until the goal sequent has been de-
rived.
Proof search in the inverse method is of a very different character than
tableau search, which must deal with disjunctive non-determinism in search-
ing backward through the proof tree. In the inverse method we are concerned
with conjunctive non-determinism, as we work forward our information grows
monotonically. So the main challenge of inverse method search is to derive as
few ‘redundant’ sequents as possible while still retaining completeness.The key
property that the inverse method uses to limit conjunctive non-determinism is
that in all inference rules, each of the formulas of the premises are subformulas
of some formula in the conclusion. This implies that even if we restrict ourselves
to only apply rules when the conclusion of the rule contains only subformulas
of the goal sequent, we will still have a complete search strategy. In addition,
this lets us disprove a theorem by exhausting this search space. This makes it
also important to restrict rules like weakening, which would otherwise always
be applicable in the forward direction. This is dealt with in the intuitionistic
inverse method by eliminating weakening and changing the completeness the-
orem [7], a similar ﬁx works for BI.
As an example of the inverse method in IL, consider the (intuitionistically
true) goal proposition ((p ⊃q) ∨(p ⊃r)) ⊃(p ⊃(q ∨r))). We begin by enu-
merating signed subformulas to ﬁnd possible initial sequents. The subformulas
are:
+ ((p ⊃q) ∨(p ⊃r)) ⊃(p ⊃(q ∨r)))
−p
−((p ⊃q) ∨(p ⊃r))
−q
+ (p ⊃(q ∨r)))
+ p
−(p ⊃q)
−r
−(p ⊃r)
+ q
+ (q ∨r)
+ r

468
K. Donnelly et al.
Each pair of a positive proposition p and its negative indicates a possible use of
the axiom p ⊢p in the proof of the goal. So we begin with a database including,
p ⊢p, q ⊢q and r ⊢r. We work forward from these axioms by applying rules
of the intuitionistic forward calculus whenever the conclusion contains only
the signed subformulas above. When we reach a sequent that can be weakened
to the goal sequent, we are done. Theorem proving proceeds as follows (some
sequents irrelevent to the ﬁnal proof are not shown):
1. p ⊢p
init
2. q ⊢q
init
3. r ⊢r
init
4. q ⊢q ∨r
∨R1 2
5. r ⊢q ∨r
∨R2 3
6. p ⊃q, p ⊢q
⊃L 2
7. p ⊃r, p ⊢r
⊃L 3
8. p ⊃q, p ⊢q ∨r
∨R1 6
9. p ⊃r, p ⊢q ∨r
∨R2 7
10. (p ⊃q) ∨(p ⊃r), p ⊢q ∨r
∨L 8 9
11. (p ⊃q) ∨(p ⊃r) ⊢p ⊃(q ∨r)
⊃R 10
12. ⊢((p ⊃q) ∨(p ⊃r)) ⊃(p ⊃(q ∨r))
⊃R 11
One distinct advantage of inverse method theorem proving in BI is that the
resource distribution problem for multiplicative connectives disappears in the
forward direction. If we read a rule like
Γ ⊢ϕ
∆⊢ψ
Γ, ∆⊢ϕ ∗ψ
∗R
in the reverse direction as in tableau proof-search, it is not obvious how to split
the resources in the context between Γ and ∆, so this must be calculated during
proof search. This can be handled in both linear logic and BI by using Boolean
constraint methods as in [11]. However, in the forward direction the distribu-
tion problem simply disappears.
Unfortunately reading the rules in the forward direction introduces a new
resource problem for the units. In particular, the for the rule
Γ(øa) ⊢ϕ
Γ(⊤) ⊢ϕ ⊤L
and similarly for IL, the rule is always applicable in the forward direction and
it is not clear how many times it must be used. The solution for the similar
problem in linear logic is given in [6]. It is not clear if a similar ﬁx would work
for BI, so we omit units from our inverse method.
In our paper we formulate a forward sequent calculus for propositional BI
without units, which is suitable for inverse method theorem proving. We prove
the soundness and completeness of our method relative to the sequent calculus
rules given in [15, Ch. 6]. We describe a canonical form for bunches suitable for

The Inverse Method for the Logic of Bunched Implications
469
use in an implementation, and describe our SML implementation of our inverse
method. The main contribution of our paper is in deﬁning for the ﬁrst time
an inverse method for BI. In particular, we overcome the lack of a structural
canonical form.
2
Propositional BI Without Units
In this section we present a sequent calculus for the propositional fragment
of BI without propositional units (⊥, I, and ⊤). We leave out the units because
their inclusion in the inverse method is quite involved, see [6] for the challenges
presented by units in the inverse method for linear logic. Similar issues apply
to units in BI.
Firstly, we have two types of connectives:
Additives
∧⊃∨
Multiplicatives
∗−∗
The additive connectives are the same as those of intuitionistic logic and the
multiplicatives come from intuitionistic linear logic. The contexts of BI, re-
ferred to as bunches, are trees where the leaves are formulas or empty bunches
and the inner nodes are multiplicative (,) or additive (;) context forming opera-
tions. Note that while we leave out the propositional constants for units (⊥, I,
and ⊤), contextual units (empty bunches) may still appear in bunches.
Bunches
Γ ::=
ϕ
propositional assumption
|
øm
multiplicative unit
|
Γ, Γ
multiplicative combination
|
øa
additive unit
|
Γ; Γ
additive combination
In the following we write Γ(∆) to mean a bunch in which ∆is a subbunch and
Γ(∆′) to mean the replacement of ∆by ∆′ in Γ(∆). The following equivalence
on bunches is used to convert between isomorphic bunches.
Deﬁnition 1 (Coherent Equivalence). ≡is the least equivalence relation on
bunches satisfying:
1. Commutative monoid equations for øa and ;
2. Commutative monoid equations for øm and ,
3. Congruence: if ∆≡∆′ then Γ(∆) ≡Γ(∆′)
In section 3.3 we give a canonical form for bunches which uses n-ary operations,
however all rules are given in terms of the simple binary formulation.
Judgments are of the form Γ ⊢ϕ where Γ is a bunch and ϕ is a formula. The
sequent calculus rules for propositional BI without units are given in Figure 1.
The cut-rule is admissible in this system [15, Ch. 6].

470
K. Donnelly et al.
Identity and Structure
Γ ⊢ϕ
Γ ′ ⊢ϕ (Γ ≡Γ ′) E
ϕ ⊢ϕ INIT
Γ(∆) ⊢ϕ
Γ(∆; ∆′) ⊢ϕ W
Γ(∆; ∆) ⊢ϕ
Γ(∆) ⊢ϕ
C
Additives
Γ ⊢ϕ
∆(∆′; ψ) ⊢χ
∆(∆′; Γ; ϕ ⊃ψ) ⊢χ ⊃L
Γ; ϕ ⊢ψ
Γ ⊢ϕ ⊃ψ ⊃R
Γ(ϕ; ψ) ⊢χ
Γ(ϕ ∧ψ) ⊢χ ∧L
Γ ⊢ϕ
∆⊢ψ
Γ; ∆⊢ϕ ∧ψ
∧R
Γ ⊢ϕi
Γ ⊢ϕ1 ∨ϕ2 (i = 1, 2) ∨Ri
Γ(ϕ) ⊢χ
Γ(ψ) ⊢χ
Γ(ϕ ∨ψ) ⊢χ
∨L
Multiplicatives
Γ(ϕ, ψ) ⊢χ
Γ(ϕ ∗ψ) ⊢χ ∗L
Γ ⊢ϕ
∆⊢ψ
Γ, ∆⊢ϕ ∗ψ
∗R
Γ ⊢ϕ
∆(∆′, ψ) ⊢χ
∆(∆′, Γ, ϕ −∗ψ) ⊢χ
−∗L
Γ, ϕ ⊢ψ
Γ ⊢ϕ −∗ψ −∗R
Fig. 1. Sequent calculus rules for core propositional BI
3
An Inverse Method for BI
3.1
The Calculus
Following the general method for producing a weakening-free forward calcu-
lus from a backward sequent calculus [7], we adapt the sequent calculus for
BI into a calculus suitable for the inverse method. The rules for our forward
sequent calculus for BI are as given in Figure 2.
We annotate the rules in the new system with superscript I to differentiate
them from the old rules, the judgment of our new system has the form Γ ⊢I ϕ.
The ﬁrst step in generating a forward sequent calculus is to eliminate the
weakening rule (or reformulate the rules so weakening is not built into them,
if there is no explicit weakening rule). Since our starting point is a sequent cal-
culus with an explicit weakening rule, we remove it. In order to state the com-
pleteness theorem for the weakening-free system we need the following.

The Inverse Method for the Logic of Bunched Implications
471
Identity and Structure
Γ(∆1; ∆2) ⊢I ϕ
(∆∈lubs⊑(∆1) (∆2)) ̸≡∆1; ∆2
Γ(∆) ⊢I ϕ
CI
Γ ⊢I ϕ
Γ ′ ⊢I ϕ
(Γ ≡Γ ′) EI
ϕ ⊢I ϕ INITI
Additives
Γ ⊢I ϕ
∆(∆′; ψ) ⊢I χ
∆(∆′; Γ; ϕ ⊃ψ) ⊢I χ
⊃LI
Γ; ϕ ⊢I ψ
Γ ⊢I ϕ ⊃ψ
⊃RI
1
Γ ⊢I ϕ
∆⊢I ψ
Γ; ∆⊢I ϕ ∧ψ
∧RI
Γ ⊢I ψ
Γ ⊢I ϕ ⊃ψ
⊃RI
2
Γ(ϕi) ⊢I χ
Γ(ϕ1 ∧ϕ2) ⊢I χ
(i = 1, 2) ∧LI
i
Γ ⊢I ϕi
Γ ⊢I ϕ1 ∨ϕ2
(i = 1, 2) ∨RI
i
Γ(ϕ) ⊢I χ
∆(ψ) ⊢I χ
Σ(p) ∈lubs⊑(Γ(p)) (∆(p))
Σ(ϕ ∨ψ) ⊢I χ
∨LI
for new parameter p, not apprearing in Γ, ∆or Σ
Multiplicatives
Γ(ϕ, ψ) ⊢I χ
Γ(ϕ ∗ψ) ⊢I χ ∗LI
Γ ⊢I ϕ
∆⊢I ψ
Γ, ∆⊢I ϕ ∗ψ
∗RI
Γ ⊢I ϕ
∆(∆′, ψ) ⊢I χ
∆(∆′, Γ, ϕ −∗ψ) ⊢I χ
−∗LI
Γ, ϕ ⊢I ψ
Γ ⊢I ϕ −∗ψ −∗RI
Fig. 2. Forward sequent calculus rules for core propositional BI
Deﬁnition 2 (Bunch Ordering). ⊑is the transitive, reﬂexive (with respect to ≡)
closure of Γ(∆) ⊑Γ(∆; ∆′)
Note that this is equivalent to saying ∆⊑∆′ iff there is some derivation of
∆′ ⊢ϕ from ∆⊢ϕ using only rules W or E.
We next have to examine each of the rules to make sure they are still com-
plete without weakening. One rule which obviously must be changed is ⊃R
because the original system with weakening can derive ϕ ⊢ψ ⊃ϕ only because
we ﬁrst weaken ψ into the context, then use the ⊃R rule. To ﬁx this we split
the rule in two: ⊃RI
1 which is the same as the old rule and ⊃RI
2 which builds
in the weakening step. We also split rule ∧L into ∧LI
1 and ∧LI
2 which build in
weakening, the weakening-free original rule ∧LI is then derivable from ∧LI
1 ,
∧LI
2 and CI.

472
K. Donnelly et al.
More interesting complications arise with rules C and ∨L. In the intuitionis-
tic inverse method we simply remove C and build contraction into the rules by
unioning the contexts that would otherwise be additively combined. It is ﬁne
to union together additively combined sequents in our BI inverse method, but
this does not remove the need for rule C. The problem is that we may be able
to use rule C only after weakening two additively joined subbunches to be the
same. An example is the derivation:
(ϕ, ψ); (ϕ, χ) ⊢η
(ϕ, (ψ; χ)); (ϕ, χ) ⊢η W
(ϕ, (ψ; χ)); (ϕ, (ψ; χ)) ⊢η W
ϕ, (ψ; χ) ⊢η
C
In fact we cannot eliminate rule C, because each pair of bunches does not have
a unique least upper bound with respect to ⊑. For example the bunches (ϕ, ψ)
and (ϕ, χ) have the minimal upper bounds ϕ, (ψ; χ) and (ϕ, ψ); (ϕ, χ) and nei-
ther can be obtained from the other using just weakening and equivalence.
However each pair of bunches does have a ﬁnite minimal upper bound set,
deﬁned as follows.
Deﬁnition 3 (Minimal upper bound set). S is a minimal upper bound set for ∆
and Γ iff the following hold:
∀Σ ∈S. ∆⊑Σ ∧Γ ⊑Σ, and
∀Σ. (∆⊑Σ ∧Γ ⊑Σ) ⇒(∃Σ′ ∈S. (Σ′ ⊑Σ))
We write lubs⊑(∆) (Γ) for the minimal set of upper bounds of ∆and Γ. We
write it in curried notation to avoid the confusion of overloading “,” to separate
arguments as well as multiplicatively join bunches. Given the minimal upper
bound set, we build weakening into the contraction rule (CI) by replacing two
additively joined bunches with a common upper bound.
Rule ∨L is affected in a similar way to rule C because the rule
Γ(ϕ) ⊢χ
Γ(ψ) ⊢χ
Γ(ϕ ∨ψ) ⊢χ
∨L
requires that a single bunch with two different formulas plugged in prove a
particular formula. However, in the inverse method we will generally have
∆(ϕ) ⊢χ and ∆′(ψ) ⊢χ in the database, and if ∆(ϕ) ⊑Γ(ϕ) and ∆′(ψ) ⊑Γ(ψ)
we want to be able to apply the rule. So we make a new ∨LI which uses the
minimal upper bound set to achieve this.
In order to state the new ∨LI we need to either extend the deﬁnition of
bunches to allow for parameters or we can just think of this parameter as a
new, unique atomic proposition. The reason that we need a parameter is easy
to see if we think of ∆(−) and ∆′(−) as two bunches with holes, and we want
to ﬁnd a common upper bound with only a single hole, Γ(−). The parameters
are just place holders for the holes.

The Inverse Method for the Logic of Bunched Implications
473
We ﬁrst prove the soundness of our calculus by a fairly straightforward in-
duction on the derivations.
Theorem 1 (Soundness). If Γ ⊢I ϕ then Γ ⊢ϕ.
Proof (By structural induction).
case : Derivation is
ϕ ⊢I ϕ INITI
We immediately have ϕ ⊢ϕ by rule INIT.
case : Last rule is
Γ ⊢I ϕ
∆(∆′; ψ) ⊢I χ
∆(∆′; Γ; ϕ ⊃ψ) ⊢I χ
⊃LI
By IH, have Γ ⊢ϕ and ∆(∆′; ψ) ⊢χ.
We can use rule ⊃L to get ∆(∆′; Γ; ϕ ⊃ψ) ⊢χ.
case : Last rule is
Γ; ϕ ⊢I ψ
Γ ⊢I ϕ ⊃ψ ⊃RI
1
By IH, have Γ; ϕ ⊢ψ.
By rule ⊃R, we have Γ ⊢ϕ ⊃ψ.
case : Last rule is
Γ ⊢I ψ
Γ ⊢I ϕ ⊃ψ ⊃RI
2
By IH, have Γ ⊢ψ.
by rule W, we have Γ; ϕ ⊢ψ.
by rule ⊃R, we have Γ ⊢ϕ ⊃ψ.
case : Last rule is
Γ(∆1; ∆2) ⊢I ϕ
(∆∈lubs⊑(∆1) (∆2)) ̸
≡∆1; ∆2
Γ(∆) ⊢I ϕ
CI
By IH, we have Γ(∆1; ∆2) ⊢ϕ
Since ∆1 ⊑∆we can derive Γ(∆; ∆2) ⊢ϕ
Similarly, we can derive Γ(∆; ∆) ⊢ϕ then use rule C to get Γ(∆) ⊢ϕ.
case : Last rule is
Γ(ϕ) ⊢I χ
∆(ψ) ⊢I χ
Σ(p) ∈lubs⊑(Γ(p)) (∆(p))
Σ(ϕ ∨ψ) ⊢I χ
∨LI
By IH, we have Γ(ϕ) ⊢χ and ∆(ψ) ⊢χ
Since we have ∆(p) ⊑Σ(p) and Γ(p) ⊑Σ(p) we know Σ(ϕ) ⊢χ and
Σ(ψ) ⊢χ so we can use rule ∨L to get Σ(ϕ ∨ψ) ⊢χ
case : Last rule is
Γ(ϕ1) ⊢I χ
Γ(ϕ1 ∧ϕ2) ⊢I χ ∧LI
1
By IH, we have Γ(ϕ1) ⊢χ.
We can use rule W to get Γ(ϕ1; ϕ2) ⊢χ then rule ∧L to get Γ(ϕ1 ∧ϕ2) ⊢χ

474
K. Donnelly et al.
We conclude the proof by observing that ∧L2 is parallel to ∧L1 and the rest of the
rules are identical to the corresponding backward sequent calculus rules (EI, ∗, and −∗
rules)
Because our completeness proof will say that if Γ ⊢ϕ then Γ ′ ⊢I ϕ such that
Γ ′ ⊑Γ, we need a lemma about bunches that weaken to a split bunch (i.e.
we need to be able to say something about the form of Γ when we know Γ ⊑
Σ(∆)).
Lemma 1 (Weakening Split). If Γ ⊑Σ(∆) then either Γ ⊑Σ(p) or else Γ ≡
Σ′(∆′) such that, Σ′(p) ⊑Σ(p) and ∆′ ⊑∆(where p is a new parameter).
Proof (By Structural induction).
We will do induction on the derivation of Σ(∆) ⊢ϕ from Γ ⊢ϕ. We may assume
WLOG that the ﬁrst rule is E. In the base case, Γ ≡Σ(∆) so the second case of the
lemma holds.
If the last rule is rule E, then for any Σ′(∆′) ≡Σ(∆) either case obviously carries
through.
If the last rule is rule W, then we must consider the location of the use of rule
W. The bunch weakened on (or removed, if we look at the reverse direction) must be
either entirely within Σ(p) and disjoint from ∆or else it must entirely contain ∆or
be entirely contained in ∆(this can easily be seen by considering the tree structure of
bunches). In the ﬁrst case, either case of the IH carries through. In the second case, the
entirety of ∆was simply weakened on and we could have just as easily weakened on p
in its place, so the ﬁrst case of the lemma holds. In the last case, the ﬁnal step looks like:
Σ(Σ′′(∆′′)) ⊢ϕ
Σ(∆) = Σ(Σ′′(∆′′; ∆′′′)) ⊢ϕ W
and since Σ′′(∆′′) ⊑∆, either case of the IH carries through.
Now we can prove the completeness of our calculus. We use a fairly straight-
forward structural induction on the derivation, the main complication is that
we have to distinguish cases for the possible forms of Γ ⊑Σ(∆) as given in the
previous lemma.
Theorem 2 (Completeness). If Γ ⊢ϕ then Γ ◦⊢I ϕ such that, Γ ◦⊑Γ.
Intuitively we think of Γ ◦as a bunch that we can weaken to get Γ (these are the
types of sequents our inverse method will prove).
Proof (By structural induction).

The Inverse Method for the Logic of Bunched Implications
475
case : Derivation is
ϕ ⊢ϕ INIT
We have immediately ϕ ⊢I ϕ INITI
.
case : Last rule is
Γ(∆) ⊢ϕ
Γ(∆; ∆′) ⊢ϕ W
By IH, have (Γ(∆))◦⊢I ϕ with (Γ(∆))◦⊑Γ(∆) and since ∆⊑∆; ∆′,
(Γ(∆))◦⊑Γ(∆; ∆′) as required.
case : Last rule is
Γ(∆; ∆) ⊢ϕ
Γ(∆) ⊢ϕ
C
By IH, we have (Γ(∆; ∆))◦⊢I ϕ
Either (Γ(∆; ∆))◦⊑Γ(p) or (Γ(∆; ∆))◦≡Γ ◦((∆; ∆)◦) with (∆; ∆)◦⊑
∆; ∆by previous lemma.
In the ﬁrst case, clearly if (Γ(∆; ∆))◦⊑Γ(p) then (Γ(∆; ∆))◦⊑Γ(∆), so
we are done.
In the second case, either (∆; ∆)◦⊑∆or (∆; ∆)◦≡∆1; ∆2 such that
∆i ⊑∆(i = 1, 2).
In the ﬁrst case we are done.
In the second case we have ∆i ⊑∆(i = 1, 2) so we have some Σ ∈lubs⊑(∆1)
(∆2) such that Σ ⊑∆, so we use rule CI to get Γ ◦(Σ) ⊢I ϕ.
case : Last rule is
Γ ⊢ϕ
∆⊢ϕ (∆≡Γ)E
Again, this is immediate from IH because ∆≡Γ.
case : Last rule is
Γ ⊢ϕ
∆(∆′; ψ) ⊢χ
∆(Γ; ∆′; ϕ ⊃ψ) ⊢χ ⊃L
By IH have Γ ◦⊢I ϕ and (∆(∆′; ψ))◦⊢I χ
Either (∆(∆′; ψ))◦⊑∆(p) or (∆(∆′; ψ))◦≡∆◦((∆′; ψ)◦) such that ∆◦(p)
⊑∆(p) and (∆′; ψ)◦⊑∆′; ψ.
In the ﬁrst case we are done.
In the second case, either (∆′; ψ)◦⊑∆′ or (∆′; ψ)◦≡∆′◦; ψ such that
∆′◦⊑∆′.
In the ﬁrst case we are done.
In the second case we can apply rule ⊃LI to get ∆◦(Γ ◦; ∆′◦; ϕ ⊃ψ) ⊢I χ.
case : Last rule is
Γ; ϕ ⊢ψ
Γ ⊢ϕ ⊃ψ ⊃R
By IH have (Γ; ϕ)◦⊢ψ.
Either (Γ; ϕ)◦≡Γ ◦⊑Γ or (Γ; ϕ)◦≡Γ ◦; ϕ such that Γ ◦⊑Γ.
In the ﬁrst case we use rule ⊃RI
2 and in the second ⊃RI
1 to get Γ ◦⊢I ϕ ⊃ψ
case : Last rule is
Γ(ϕ) ⊢χ
Γ(ψ) ⊢χ
Γ(ϕ ∨ψ) ⊢χ
∨L
By IH have (Γ(ϕ))◦⊢χ and (Γ(ψ))◦) ⊢χ.
Either (Γ(ϕ))◦⊑Γ(p) or (Γ(ϕ))◦≡Γ ◦
1 (ϕ) such that Γ ◦
1 (p) ⊑Γ(p).

476
K. Donnelly et al.
In the ﬁrst case we are done.
In the second case, either (Γ(ψ))◦⊑Γ(p) or (Γ(ψ))◦≡Γ ◦
2 (ψ) such that
Γ ◦
2 (p) ⊑Γ(p).
In the ﬁrst case we are done.
In the second case, since Γ ◦
i (p) ⊑Γ(p)(i = 1, 2), we have Σ◦(p) ∈lubs⊑
(Γ ◦
1 (p)) (Γ ◦
2 (p)) such that Σ◦(ϕ ∨ψ) ⊑Γ(ϕ ∨ψ). So we apply rule ∨LI and
we are done.
case : Last rule is
Γ(ϕ; ψ) ⊢χ
Γ(ϕ ∧ψ) ⊢χ ∧L
By IH, we have (Γ(ϕ; ψ))◦⊢I χ such that (Γ(ϕ; ψ))◦⊑Γ(ϕ; ψ).
By the lemma, either (Γ(ϕ; ψ))◦⊑Γ(p) or (Γ(ϕ; ψ))◦≡Γ ◦((ϕ; ψ)◦) with
Γ ◦(p) ⊑Γ(p) and (ϕ; ψ)◦⊑(ϕ; ψ).
In the ﬁrst case we are done.
In the second case we need to consider (ϕ; ψ)◦. It cannot be empty or we would
be in the ﬁrst case.
If (ϕ; ψ)◦≡ϕ then we use rule ∧LI
1 to get Γ ◦(ϕ ∧ψ) ⊢I χ.
If (ϕ; ψ)◦≡ψ then we use rule ∧LI
2 to get Γ ◦(ϕ ∧ψ) ⊢I χ.
If (ϕ; ψ)◦≡(ϕ; ψ) then we use rule ∧LI
1 to get Γ ◦(ϕ ∧ψ; ψ) ⊢I χ then rule
∧LI
2 to get Γ ◦(ϕ ∧ψ; ϕ ∧ψ) ⊢I χ then rule CI to get Γ ◦(ϕ ∧ψ) ⊢I χ.
note : The remaining cases are similar.
3.2
An Example
Inverse method theorem proving in BI proceeds in the same way as in intu-
itionistic logic. Consider the (true) goal sequent øm ⊢I (p ∗(q ∧r)) −∗((p ∧q) ∗
(p ∧r)). We start by enumerating the signed subformulas and identifying the
initial sequents.
+ (p ∗(q ∧r)) −∗((p ∧q) ∗(p ∧r))
+ (p ∧r)
- (p ∗(q ∧r))
- q
+ ((p ∧q) ∗(p ∧r))
- r
- (q ∧r)
+ p
- p
+ q
+ (p ∧q)
+ r
From this we can see that the initial sequents we need are p ⊢I p, q ⊢I q and
r ⊢I r. Theorem proving proceeds in rounds as follows (some unnecessary
sequents are omitted).

The Inverse Method for the Logic of Bunched Implications
477
1. p ⊢I p
init
2. q ⊢I q
init
3. r ⊢I r
init
4. p, q ⊢I p ∗q
∗RI 1 2
5. p, r ⊢I p ∗r
∗RI 1 3
6. q ∧r ⊢I q
∧LI
1 2
7. q ∧r ⊢I r
∧LI
2 3
8. (p, q); (p, r) ⊢I (p ∗q) ∧(p ∗r)
∧RI 4 5
9. p, (q ∧r) ⊢I p ∗q
∗RI 1 6
10. p, (q; r) ⊢I (p ∗q) ∧(p ∗r)
CI 8
11. p, (q ∧r) ⊢I (p ∗q) ∧(p ∗r)
∧LI 10
12. p ∗(q ∧r) ⊢I (p ∗q) ∧(p ∗r)
∗RI 11
13. øm, (p ∗(q ∧r)) ⊢I (p ∗q) ∧(p ∗r)
EI 12
14. øm ⊢I (p ∗(q ∧r)) −∗((p ∗q) ∧(p ∗r))
−∗RI 13
3.3
An ≡Canonical Form for Bunches
While there is no canonical form which equates bunches modulo ≡, weaken-
ing and contraction, there is a canonical form modulo ≡alone. Although this is
fairly obvious, we have not seen it published anywhere. In [2], Armel´ın gives
a similar canonical form which does not equate bunches modulo units as ours
does. Use of this canonical form during proof-search lets us drop rule EI alto-
gether.
It is helpful, both in guiding an actual implementation and in understand-
ing the structure of bunches, to have a canonical representative of [Γ]≡for any
bunch Γ. To do so we deﬁne the following grammar.
Bunches Γ ::= ϕ | Π | Σ
Multiplicative Bunches Π ::= ϕ | {Σ∗}m
Additive Bunches Σ ::= ϕ | {Π∗}a
where {A∗} denotes a multiset with elements from A.
We maintain the invariant that the multisets {A∗} are never singletons
(empty sets are ﬁne, they are the units). If a subbunch which is supposed to
be a multiset is a singleton, then we simply promote it in the tree and union it
on to its parent. It is easy to see that ϕ’s can always be promoted. Since the lev-
els of the tree alternate between {Σ∗}m and {Π∗}a, if e.g. {Σ∗}m = {Σ}m and
Σ ̸
= ϕ then Σ = {Π∗}a so we can union that into the context of which {Σ∗}m
was a member. We also maintain the invariant that a subbunch only appears
once in any additive context, so we treat {Π∗}a as a set rather than a multiset.
This gives us an ≡-canonical form. To see if two bunches are equivalent we
convert to canonical form by these steps: ﬁrst, ﬂatten binary connectives into
n-ary connectives (justiﬁed by associativity of , and ;), then forget about order-
ing by making them multiset operators (justiﬁed by commutativity of , and ;)
then eliminate singletons by propagating them upwards. This last step is justi-
ﬁed by the unit laws (we think of {Σ} as Σ, øm) which let us promote and the

478
K. Donnelly et al.
associativity and commutativity laws which let us fold in (union) multisets that
we promote. Lastly, we forget about the number of occurrences in the additive
levels of the tree (justiﬁed by contraction for additive conjunction).
3.4
Implementation
We have implemented our inverse method for propositional BI without units
in SML. We use the above canonical form for our bunches and generate proof-
terms which are checked at the end.
Proof-terms for BI are terms of the αλ-calculus [15]. We store proof-terms
with each derived sequent in the database, so when we ﬁnish with a positive
answer we have also a proof that the theorem is in fact true. We then check the
proof in a straightforward way. This gives us a certifying theorem prover. Since
the proof-checking code is much shorter and simpler than the proof-search
code, we can have much higher conﬁdence in a certiﬁed result than one that
lacks proof-terms and checking.
In order to accommodate proof-terms in the inverse method, it is helpful to
deﬁne a new intermediate proof-term let x = e1 in e2 which we convert
to [e1/x]e2 before type-checking. This is used in elimination rules so we do not
have to do proof substitution on-line.
At present, we only have a very simple prototype implementation without
any of the customary optimizations applied in the inverse method. Nonethe-
less, we have found it useful for validating our ideas. In the conclusion we
mention some planned improvements.
4
Related Work and Conclusions
Separation Logic [16] is a logic for reasoning about programs similar to Hoare
Logic. Instead of standard intuitionistic logic, Separation Logic uses the connec-
tives of BI, along with some other primitives, to express properties about data
structures with shared mutable state. Therefore, automated theorem provers
for BI are likely to eventually have practical uses in reasoning about programs.
In particular, it is quite tedious to write out proofs of each inference step in Sep-
aration Logic and a good theorem prover for BI could go a long way towards
automating the process of checking Separation Logic assertions.
There has been some work on a semantic tableau proof-search by Galmiche
and M´ery in BI [9,5] which has so far produced the BILL theorem prover for
propositional BI without ⊥, a later paper [8] extends this work to include ⊥.
Our work presents an alternative method for theorem proving in BI. We be-
lieve it is useful to investigate thoroughly both backward and forward search
procedures for BI as work in other logics has shown that these methods have
different properties and ﬁnd different theorems easily.
There is also work on the inverse method in intuitionistic logic [18] and lin-
ear logic [17] which have resulted in inverse method provers for full ﬁrst-order

The Inverse Method for the Logic of Bunched Implications
479
intuitionistic and linear logics. Most of the improved strategies and optimiza-
tions used in these works (some described in the previous section) would most
probably be applicable to inverse method theorem proving in BI.
Work by Armel´ın and Pym [3] develops a logic programming language,
BLP, based on the hereditary Harrop fragment of BI with additive predication.
Their work devlops a bottom-up proof search as its basis. By extending our
inverse method to this fragment, it should be possible to develop an alternative,
top-down basis for bunched logic programming.
In this paper, we have demonstrated that the inverse method is applicable
to the core of propositional BI. Standard efﬁciency improvements [7] and the
addition of units [6] should be relatively straightforward and lead to a theorem
prover for full propositional BI. Additionally, formulation of a full ﬁrst-order
focusing prover for BI is likely to be fruitful for a number of reasons. Firstly,
many investigations in proof-search, particularly an analysis of focusing [1] in
BI, may lead to deeper understandings of its proof theory. And secondly, efﬁ-
cient provers for BI will likely become practically useful for program analysis
as this is the logic that underlies Separation Logic.
5
Acknowledgments
We are grateful to Frank Pfenning for teaching us about the inverse method,
offering some insightful suggestions and providing helpful feedback, and also
to the anonymous reviewers for their comments.
References
1. Jean-Marc Andreoli. Logic programming with focusing proofs in linear logic. Journal
of Logic and Computation, 2(3):197–347, 1992.
2. Pablo Armel´ın. Logic programming with bunched logic. PhD thesis, University of Lon-
don, 2002.
3. Pablo A. Armel´ın and David J. Pym. Bunched logic programming. In IJCAR ’01:
Proceedings of the First International Joint Conference on Automated Reasoning, pages
289–304. Springer-Verlag, 2001.
4. L. Bachmair and H. Ganzinger. Resolution theorem proving. In A. Robinson and
A. Voronkov, editors, Handbook of Automated Reasoning, volume 1, chapter 2, pages
19–100. North Holland, 2001.
5. Frederic Beal, Daniel M´ery, and Didier Galmiche. Bill: A theorem prover for propo-
sitional bi logic.
6. Kaustuv Chaudhuri and Frank Pfenning.
Resource management for the inverse
method in linear logic. Carnegie Mellon University, Unpublished Maniscript, Jan-
uary 2003.
7. Anatoli Degtyarev and Andrei Voronkov. The inverse method. In A. Robinson and
A. Voronkov, editors, Handbook of Automated Reasoning, volume 1, pages 179–272.
Elsevier Science and MIT Press, 2001.
8. Didier Galmiche, Daniel M&#233;ry, and David J. Pym. Resource tableaux. In CSL
’02: Proceedings of the 16th International Workshop and 11th Annual Conference of the
EACSL on Computer Science Logic, pages 183–199. Springer-Verlag, 2002.

480
K. Donnelly et al.
9. Didier Galmiche and Daniel M´ery. Semantic labelled tableaux for propositional bi
(without bottom). Journal of Logic and Computation, 13(5), October 2003.
10. Jean-Yves Girard. Linear logic. Theoretical Computer Science, 50:1–102, 1987.
11. James Harland and David Pym. Resource-distribution via boolean constraints. ACM
Trans. Comput. Logic, 4(1):56–90, 2003.
12. S. Maslov. The inverse method of establishing deducibility in classical predicate
calculus. Soviet Mathematical Doklady, 5:1420–1424, 1964.
13. P.W. O’Hearn and D. J. Pym. The logic of bunched implications. Bulletin of Symbolic
Logic, 5(2):215–244, June 1999.
14. Frank Pfenning. The inverse method. Carnegie Mellon University, Lecture Notes,
Ch. 5, February 2004.
15. D.J. Pym. The Semantics and Proof Theory of the Logic of the Logic of Bunched Implications,
volume 26 of Applied Logic Series. Kluwer Academic Publishers, 2002. Errata and
Remarks maintained at:
http://www.cs.bath.ac.uk/˜pym/BI-monograph-errata.pdf.
16. John C. Reynolds. Separation logic: A logic for shared mutable data structures. In
Proceedings of the 17th Annual IEEE Symposium on Logic in Computer Science, pages
55–74. IEEE Computer Society, 2002.
17. T. Tammet. Proof strategies in linear logic. Journal of Automated Reasoning, 12(3):273–
304, 1994.
18. Tanel Tammet. A resolution theorem prover for intuitionistic logic. In M. A. McRob-
bie and J. K. Slaney, editors, Proceedings 13th Intl. Conf. on Automated Deduction,
CADE’96, New Brunswick, NJ, USA, 30 July – 3 Aug 1996, volume 1104, pages 2–16.
Springer-Verlag, Berlin, 1996.

Cut-Elimination: Experiments with CERES⋆
Matthias Baaz1, Stefan Hetzl2, Alexander Leitsch2, Clemens Richter2, and
Hendrik Spohr2
1 Institute of Discrete Mathematics and Geometry (E104),
Vienna University of Technology, Wiedner Hauptstraße 8-10,
1040 Vienna, Austria
baaz@logic.at
2 Institute of Computer Languages (E185),
Vienna University of Technology, Favoritenstraße 9,
1040 Vienna, Austria
{hetzl|leitsch|richter|spohr}@logic.at
Abstract. Cut-elimination is the most prominent form of proof trans-
formation in logic. The elimination of cuts in formal proofs corresponds
to the removal of intermediate statements (lemmas) in mathematical
proofs. The cut-elimination method CERES (cut-elimination by resolu-
tion) works by constructing a set of clauses from a proof with cuts. Any
resolution refutation of this set can then serve as a skeleton of a proof
with only atomic cuts.
In this paper we present a systematic experiment with the implemen-
tation of CERES on a proof of reasonable size and complexity. It turns
out that the proof with cuts can be transformed into two mathematically
diﬀerent proofs of the theorem. In particular, the application of positive
and negative hyperresolution yield diﬀerent mathematical arguments. As
an unexpected side-eﬀect the derived clauses of the resolution refutation
proved particularly interesting as they can be considered as meaningful
universal lemmas.
Though the proof under investigation is intuitively simple, the experi-
ment demonstrates that new (and relevant) mathematical information
on proofs can be obtained by computational methods. It can be con-
sidered as a ﬁrst step in the development of an experimental culture of
computer-aided proof analysis in mathematics.
1
Introduction
Proof analysis is a central mathematical activity which proved crucial to the
development of mathematics. Indeed many mathematical concepts such as the
notion of group or the notion of probability were introduced by analyzing existing
arguments. In some sense the analysis and synthesis of proofs form the very core
of mathematical progress[7,8].
Cut-elimination introduced by Gentzen [4] is the most prominent form of
proof transformation in logic and plays an important role in automatizing the
⋆supported by the Austrian Science Fund (project no. P16264-N05)
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 481–495, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

482
M. Baaz et al.
analysis of mathematical proofs. The removal of cuts corresponds to the elim-
ination of intermediate statements (lemmas) from proofs resulting in a proof
which is analytic in the sense, that all statements in the proof are subformulas
of the result. Therefore, the proof of a combinatorial statement is converted into
a purely combinatorial proof. Cut-elimination is therefore an essential tool for
the analysis of proofs, especially to make implicit parameters explicit. Cut free
derivations allow for
– the extraction of Herbrand disjunctions, which can be used to establish
bounds on existential quantiﬁers (e.g. Luckhardt’s analysis of the Theorem
of Roth [6]).
– the construction of interpolants, which allow for the replacement of implicit
deﬁnitions by explicit deﬁnitions according to Beth’s Theorem.
– the calculation of generalized variants of the end formula.
In a formal sense Girard’s analysis of van der Waerden’s proof [5] is the
application of cut-elimination to the proof of F¨urstenberg/Weiss with the “per-
spective” of obtaining van der Waerden’s proof. Indeed an application of a com-
plex proof transformation like cut-elimination by humans requires a goal ori-
ented strategy. In contrast, as we demonstrate in this paper, the application of
purely computational methods on existing proofs may produce new interesting
proofs. Note that cut-elimination is non-unique, i.e. there is no single cut-free
proof which represents the analytic version of a proof with lemmas. Indeed, it
is non-uniqueness which makes computational experiments with cut-elimination
interesting. The experiments can be considered as a source for a base of proofs
in formal format which provide diﬀerent mathematical and computational infor-
mation.
CERES [2] is a cut-elimination method that is based on resolution. The
method roughly works as follows: The structure of the proof containing cuts is
mapped to a clause term which evaluates to an unsatisﬁable set of clauses C (the
characteristic clause set). A resolution refutation of C, which is obtained using
a ﬁrst-order theorem prover, serves as a skeleton for the new proof which con-
tains only atomic cuts. In a ﬁnal step also these atomic cuts can be eliminated,
provided the (atomic) axioms are valid sequents; but this step is of minor math-
ematical interest only. In the system CERES3 this method of cut-elimination
has been implemented. The system is capable of dealing with formal proofs in
LK, among them also very large ones.
In this paper we present a systematic experiment with CERES on a proof
deﬁned in [9]. It turns out that the proof with cuts is transformed into two
mathematically diﬀerent proofs of the theorem. In particular, the application of
positive and negative hyperresolution yield diﬀerent mathematical arguments.
As the core of the method is resolution, which works on the characteristic clause
set, it is worthwhile to investigate also the resolution proof itself. In fact the
derived clauses of the proof can be considered as universal lemmas, which are
eventually instantiated in the procedure. As an unexpected side-eﬀect also these
3 available at http://www.logic.at/ceres/

Cut-Elimination: Experiments with CERES
483
lemmas proved particularly interesting in the experiment. Though the proof un-
der investigation is intuitively simple, the experiment demonstrates that new
(and relevant) mathematical information on proofs can be obtained by compu-
tational methods. It can be considered as a ﬁrst step in the development of an
experimental culture of computer-aided proof analysis in mathematics.
2
The System CERES
The system CERES is an implementation of the cut-elimination method CERES
which will be roughly explained below. Also a short description of the behavior
of the system will be given including some implementational details.
2.1
Short Description of the Method via an Example
The cut-elimination method by resolution (CERES) is demonstrated in this pa-
per by the following example. You can ﬁnd an in-depth explanation of the method
itself and the underlying LK in [3], [2] and on the CERES web page4.
To simplify the understanding of the method all the premises (the auxiliary
formulas of the inferences) are put in bold face, the conclusions are underlined
and the ancestors of cut-formulas are marked with an asterisk in the following
input proof.
Now, let ϕ be the proof
ϕl
ϕr
(∀x)(∀y)(P(x, y) ⊃Q(x, y)) ⊢(∃x)(∃y)(¬Q(x, y) ⊃¬P(x, y)) cut
where ϕl is
P (z, a)∗⊢P(z, a)
⊢¬P (z, a)∗, P(z, a)
¬ : r
⊢¬P(z, a) ∨Q(z, a)∗, P (z, a)
∨: r1
Q(z, a) ⊢Q(z, a)∗
Q(z, a) ⊢¬P(z, a) ∨Q(z, a)∗∨: r2
P (z, a) ⊃Q(z, a) ⊢¬P(z, a) ∨Q(z, a)∗
⊃: l
(∀y)(P (z, y) ⊃Q(z, y)) ⊢¬P(z, a) ∨Q(z, a)∗∀: l
(∀x)(∀y)(P(x, y) ⊃Q(x, y)) ⊢¬P (z, a) ∨Q(z, a)∗∀: l
(∀x)(∀y)(P(x, y) ⊃Q(x, y)) ⊢(∃y)(¬P (z, y) ∨Q(z, y))∗∃: r
(∀x)(∀y)(P(x, y) ⊃Q(x, y)) ⊢(∀x)(∃y)(¬P (x, y) ∨Q(x, y))∗∀: r
4 The documentation and an online version of the system CERES are available at
http://www.logic.at/ceres/.

484
M. Baaz et al.
and ϕr is
P(b, v) ⊢P (b, v)∗
¬P(b, v)∗, P (b, v) ⊢¬ : l
¬P (b, v)∗⊢¬P(b, v)
¬ : r
Q(b, v)∗⊢Q(b, v)
¬Q(b, v), Q(b, v)∗⊢¬ : l
¬Q(b, v), ¬P(b, v) ∨Q(b, v)∗⊢¬P (b, v)
∨: l′
¬P(b, v) ∨Q(b, v)∗⊢¬Q(b, v) ⊃¬P (b, v) ⊃: r
¬P(b, v) ∨Q(b, v)∗⊢(∃y)(¬Q(b, y) ⊃¬P (b, y)) ∃: r
¬P (b, v) ∨Q(b, v)∗⊢(∃x)(∃y)(¬Q(x, y) ⊃¬P(x, y)) ∃: r
(∃y)(¬P (b, y) ∨Q(b, y))∗⊢(∃x)(∃y)(¬Q(x, y) ⊃¬P(x, y)) ∃: l
(∀x)(∃y)(¬P (x, y) ∨Q(x, y))∗⊢(∃x)(∃y)(¬Q(x, y) ⊃¬P(x, y)) ∀: l
The extraction of the characteristic clause term happens top down starting
with those parts of the initial sequents that are marked as ancestors of cut for-
mulas which are now interpreted as sets. At every occurrence of a binary rule the
two clause terms resulting from the premises are connected by a binary operator.
Depending whether the auxiliary formulas of the inference were ancestors of cut
formulas or not the operator will either be ⊕or ⊗. All unary inference rules
have no inﬂuence on the clause term and hence it remains unchanged.
For the example this yields the following characteristic clause term
Θ(ϕ) = (({P(z, a) ⊢} ⊗{⊢Q(z, a)}) ⊕({⊢P(b, v)} ⊕{Q(b, v) ⊢}))
which characterizes those parts of the axiom sequents which have been used to
derive the cut formula (on both sides).
The operator ⊕of the clause term is interpreted as union and the operator
⊗as merge, i.e. the antecedens and consequent parts of diﬀerent sequents are
exchanged such that only one part is exchanged at once.
Hence by evaluation of Θ(ϕ) for the characteristic clause set |Θ(ϕ)| of ϕ we
obtain
|Θ(ϕ)| = {P(z, a) ⊢Q(z, a),
(C2)
⊢P(b, v),
(C1)
Q(b, v) ⊢}.
(C3)
The characteristic clause set of an LK derivation is always unsatisﬁable.
Therefore one can always ﬁnd a resolution refutation of the characteristic clause
set.

Cut-Elimination: Experiments with CERES
485
In particular, we deﬁne a resolution refutation δ of |Θ(ϕ)|:
Q(b, v) ⊢
⊢P(b, v)
P(z, a) ⊢Q(z, a)
⊢Q(b, a)
⊢
and a corresponding ground refutation γ of δ, i. e. γ = δσ:
Q(b, a) ⊢
⊢P(b, a)
P(b, a) ⊢Q(b, a)
⊢Q(b, a)
⊢
with the ground substitution σ = {v →a, z →b}.
Now we have to reduce ϕ to projections of the clauses used as initial clauses
in the resolution refutation of |Θ(ϕ)|. A projection of ϕ w.r.t. a clause in |Θ(ϕ)| is
deﬁned by skipping all inferences going into cuts, which leads to cut-free proof of
(a subsequent of) the end sequent extended by C. Projections may be understood
as projection schemes of the clauses in question modulo a corresponding ground
substitution.
Again, we start at the initial sequents (without those parts marked as ances-
tors of cut formulas and not necessary for the creation of the clause in question)
and apply all inference rules not operating on ancestors of cut formulas until all
such binary rules have been applied and at least one formula also occurring in
the end sequent has been composed.
The projection scheme of ϕ corresponding to the clause C1 is:
ϕ(C1) =
P(b, v) ⊢P(b, v)
⊢P(b, v), ¬P(b, v) ¬ : r
¬Q(b, v) ⊢P(b, v), ¬P(b, v) w : l
⊢¬Q(b, v) ⊃¬P(b, v), P(b, v) ⊃: r
⊢(∃y)(¬Q(b, y) ⊃¬P(b, y)), P(b, v) ∃: r
⊢(∃x)(∃y)(¬Q(x, y) ⊃¬P(x, y)), P(b, v) ∃: r
and let the ground projection χ1 = ϕ(C1)σ.
The projection scheme of ϕ corresponding to the clause C2 is:
ϕ(C2) =
P(z, a) ⊢P(z, a)
Q(z, a) ⊢Q(z, a)
P(z, a) ⊃Q(z, a), P(z, a) ⊢Q(z, a) ⊃: l
(∀y)(P(z, y) ⊃Q(z, y)), P(z, a) ⊢Q(z, a) ∀: l
(∀x)(∀y)(P(x, y) ⊃Q(x, y)), P(z, a) ⊢Q(z, a) ∀: l

486
M. Baaz et al.
and let the ground projection χ2 = ϕ(C2)σ.
The projection scheme of ϕ corresponding to the clause C3 is:
ϕ(C3) =
Q(b, v) ⊢Q(b, v)
¬Q(b, v)Q(b, v) ⊢¬ : l
¬Q(b, v)Q(b, v) ⊢¬P(b, v) w : r
Q(b, v) ⊢¬Q(b, v) ⊃¬P(b, v) ⊃: r
Q(b, v) ⊢(∃y)(¬Q(b, y) ⊃¬P(b, y)) ∃: r
Q(b, v) ⊢(∃x)(∃y)(¬Q(x, y) ⊃¬P(x, y)) ∃: r
and let the ground projection χ3 = ϕ(C3)σ.
Finally the ground projections can be composed to a cut-free proof of ϕ, i.e.
a proof of ϕ containing only atomic cuts, using its resolution refutation as a
skeleton.
(χ1)
⊢Y, P(b, a)
(χ2)
P(b, a), X ⊢Q(b, a)
X ⊢Y, Q(b, a)
cut
(χ3)
Q(b, a) ⊢Y
X ⊢Y
cut
where X = (∀x)(∀y)(P(x, y) ⊃Q(x, y)) and Y = (∃x)(∃y)(¬Q(x, y) ⊃¬P(x, y)).
2.2
Description of the Program
The cut-elimination program CERES is written in ANSI-C++5. There are two
main tasks. On the one hand to compute an unsatisﬁable set of clauses C char-
acterising the cut formulas. This is done by automatically extracting the char-
acteristic clause term and computation of the resulting characteristic clause set.
On the other hand to evaluate the resolution refutation gained from an exter-
nal theorem prover6 and to compute the necessary projection schemes which
are properly instantiated and concatenated using the resolution refutation as a
skeleton of the cut-free proof, i.e. a proof without non-atomic cuts.
The input format and the output format are following the proof style7 of
LATEX with some extensions, and are translatable by any LATEX compiler. This
feature allows an easier input of proofs and reading of the output. Nevertheless
new approaches are planned (see section 4 for details).
5 The C++ Programming Language following the International Standard 14882:1998
approved as an American National Standard (see http://www.ansi.org).
6 The current version of CERES uses the automated theorem prover Otter (see
http://www-unix.mcs.anl.gov/AR/otter/), but any refutational theorem prover
may be used.
7 see http://research.nii.ac.jp/~tatsuta/proof-sty.html

Cut-Elimination: Experiments with CERES
487
3
Experiments with Resolution Reﬁnements
The use of the resolution refutation of the characteristic clause set as a skeleton
for the cut-free proof makes it possible to change the mathematical character
of the resulting proof via diﬀerent resolution refutations, e.g. using diﬀerent
resolution reﬁnements. Within these refutations universal lemmas, i.e. clauses
containing variables representing universal formulas, appear which do neither
occur in the original proof nor in the cut-eliminated proofs, where they are
already instantiated.
Now we are doing exactly such an interesting experiment using an input
proof already analyzed and deﬁned as an LK-derivation in [9] with the program
CERES.
The proof deals with the following situation: We are given an inﬁnite tape
where each cell contains either ‘0’ or ‘1’. We prove that on this tape there are
two cells with the same value. The contents of a cell of the tape is denoted by
f, s is the sucessor function and mx,y is the maximum of x and y.
Within this section the following formula abbreviations are used:
M1 = (∀y)(∀x)x ≤mx,y
M2 = (∀y)(∀x)y ≤mx,y
S = (∀x)(∀y)(s(x) ≤y ⊃x < y)
T = (∀i)(∀x)(∀y)((f(x) = i ∧f(y) = i) ⊃f(x) = f(y))
A = (∀x)(f(x) = 0 ∨f(x) = 1)
P = (∃p)(∃q)(p < q ∧f(p) = f(q))
∞0 = (∀n)(∃k)(n ≤k ∧f(k) = 0)
∞1 = (∀m)(∃l)(m ≤l ∧f(l) = 1)
moreover 1 is an abbreviation for s(0).
Then, let the proof ϕ be deﬁned as follows.
ϕ =
(τ)
M1, M2, A ⊢∞0, ∞1
(ϵ1)
∞1, S, T ⊢P
M1, M2, S, T, A ⊢P, ∞0
cut
(ϵ0)
∞0, S, T ⊢P
M1, M2, S, T, A ⊢P
cut
For the subproofs of τ, ϵ0 and ϵ1 please see [9] and the appendix.
The characteristic clause term Θ(ϕ) extracted from ϕ is
Θ(ϕ) =((({⊢v ≤mu,v} ⊕({⊢u ≤mu,v} ⊕({⊢f(mu,v) = 0} ⊗{⊢f(mu,v) = 1})))
⊕(({s(u) ≤v ⊢} ⊗{⊢}) ⊗(({f(u) = 1 ⊢} ⊗{f(v) = 1 ⊢}) ⊗{⊢})))
⊕(({s(u) ≤v ⊢} ⊗{⊢}) ⊗(({f(u) = 0 ⊢} ⊗{f(v) = 0 ⊢}) ⊗{⊢})))

488
M. Baaz et al.
and the corresponding characteristic clause set |Θ(ϕ)| obtained from Θ(ϕ) is
|Θ(ϕ)| = { ⊢v ≤mu,v,
(C1)
⊢u ≤mu,v,
(C2)
⊢f(mu,v) = 0, f(mu,v) = 1,
(C3)
s(u) ≤v, f(u) = 1, f(v) = 1 ⊢,
(C4)
s(u) ≤v, f(u) = 0, f(v) = 0 ⊢}
(C5)
The projection schemes obtained from ϕ for the ﬁve clauses above are the
following:
ϕ(C1) =
v ≤mu,v ⊢v ≤mu,v
(∀x)v ≤mx,v ⊢v ≤mu,v ∀: l
(∀y)(∀x)y ≤mx,y ⊢v ≤mu,v ∀: l
ϕ(C2) =
u ≤mu,v ⊢u ≤mu,v
(∀x)x ≤mx,v ⊢u ≤mu,v ∀: l
(∀y)(∀x)x ≤mx,y ⊢u ≤mu,v ∀: l
ϕ(C3) =
f(mu,v) = 0 ⊢f(mu,v) = 0
f(mu,v) = 1 ⊢f(mu,v) = 1
f(mu,v) = 0 ∨f(mu,v) = 1 ⊢f(mu,v) = 0, f(mu,v) = 1
∨: l
(∀x)(f(x) = 0 ∨f(x) = 1) ⊢f(mu,v) = 0, f(mu,v) = 1 ∀: l
ϕ(C4) = ψ1
ϕ(C5) = ψ0
where ψj is deﬁned:
ψj =
s(u) ≤v ⊢s(u) ≤v
u < v ⊢u < v
s(u) ≤v ⊃u < v, s(u) ≤v ⊢u < v ⊃: l
(∀y)(s(u) ≤y ⊃u < y), s(u) ≤v ⊢u < v ∀: l
(∀x)(∀y)(s(x) ≤y ⊃x < y), s(u) ≤v ⊢u < v ∀: l
ψ′
j
S, s(u) ≤v, T, f(u) = j, f(v) = j ⊢u < v ∧f(u) = f(v) ∧: r
S, s(u) ≤v, T, f(u) = j, f(v) = j ⊢(∃q)(u < q ∧f(u) = f(q)) ∃: r
S, s(u) ≤v, T, f(u) = j, f(v) = j ⊢(∃p)(∃q)(p < q ∧f(p) = f(q)) ∃: r
ψ′
j =
f(u) = j ⊢f(u) = j
f(v) = j ⊢f(v) = j
f(u) = j, f(v) = j ⊢f(u) = j ∧f(v) = j
∧: r
f(u) = f(v) ⊢f(u) = f(v)
(f(u) = j ∧f(v) = j) ⊃f(u) = f(v), f(u) = j, f(v) = j ⊢f(u) = f(v)
⊃: l
(∀y)((f(u) = j ∧f(y) = j) ⊃f(u) = f(y)), f(u) = j, f(v) = j ⊢f(u) = f(v) ∀: l
(∀x)(∀y)((f(x) = j ∧f(y) = j) ⊃f(x) = f(y)), f(u) = j, f(v) = j ⊢f(u) = f(v) ∀: l
(∀i)(∀x)(∀y)((f(x) = i ∧f(y) = i) ⊃f(x) = f(y)), f(u) = j, f(v) = j ⊢f(u) = f(v) ∀: l

Cut-Elimination: Experiments with CERES
489
The resolution refutations yielding two mathematically diﬀerent proofs of ϕ
are demonstrated in the following two subsections. The resulting cut-free proofs
have been ommited because of their sizes.
3.1
Positive Hyperresolution
Derivation of C6:
(C4σ1)
s(u′) ≤v′, f(u′) = 1, f(v′) = 1 ⊢
(C2σ2)
⊢u ≤mu,w
f(u′) = 1, f(ms(u′),w) = 1 ⊢
σ3
(C3)
⊢f(mu,v) = 0, f(mu,v) = 1
f(ms(mu,v),w) = 1 ⊢f(mu,v) = 0



CX
σ4
CX
(C3σ5)
⊢f(mu′,v′) = 0, f(mu′,v′) = 1
⊢f(mu,v) = 0, f(ms(mu,v),w) = 0
σ6
(C6)
where σ1 = {u →u′, v →v′}, σ2 = {v →w}, σ3 = {u →s(u′), v′ →ms(u′),w},
σ4 = {u′ →mu,v}, σ5 = {u →u′, v →v′} and σ6 = {u′ →s(mu,v), v′ →w}.
For arbitrary u, v and w either the cell with index i = mu,v is labelled ‘0’ or
the cell with index mi+1,w.
Derivation of C7:
(C5σ7)
s(u′) ≤v′, f(u′) = 0, f(v′) = 0 ⊢
(C1σ8)
⊢v ≤mu′′,v
f(u′) = 0, f(mu′′,s(u′)) = 0 ⊢
σ9
(C6)
⊢f(mu,v) = 0, f(ms(mu,v),w) = 0
f(mu′′,s(ms(mu,v),w)) = 0 ⊢f(mu,v) = 0



CY
σ10
CY
(C6σ11)
⊢f(mu′,v′) = 0, f(ms(mu′,v′ ),w′) = 0
⊢f(mu,v) = 0, f(mu′,v′) = 0
σ12
⊢f(mu,v) = 0
σ13
(C7)
where σ7 = {u →u′, v →v′}, σ8 = {u →u′′}, σ9 = {v →s(u′), v′ →mu′′,s(u′)},
σ10 = {u′ →ms(mu,v),w}, σ11 = {u →u′, v →v′, w →w′}, σ12 = {u′′ →
s(mu′,v′), w′ →s(ms(mu,v),w)} and σ13 = {u′ →u, v′ →v}.

490
M. Baaz et al.
For arbitrary u and v the cell with index i = mu,v is labelled ‘0’.
(C5)
s(u) ≤v, f(u) = 0, f(v) = 0 ⊢
(C2σ14)
⊢u′ ≤mu′,v′
f(u) = 0, f(ms(u),v′) = 0 ⊢
σ15
(C7σ16)
⊢f(mu′,v) = 0
f(ms(mu′,v),v′) = 0 ⊢
σ17
(C7σ18)
⊢f(mu,v′′) = 0
⊢
σ19
where σ14 = {u →u′, v →v′}, σ15 = {u′ →s(u), v →ms(u),v′}, σ16 = {u →u′},
σ17 = {u →mu′,v}, σ18 = {v →v′′} and σ19 = {u →s(mu′,v), v′′ →v′}.
For arbitrary u and v where u < v at least one of the cells with index u or
v should be labelled ‘1’ but again for arbitrary u′ and v′ the cell with index
i = mu′,v′ is labelled ‘0’. Hence choosing one time u as u′ and one time v as v′
leads to a contradiction.
3.2
Negative Hyperresolution
Derivation of C′
6:
(C1σ1)
⊢v′ ≤mu,v′
(C4σ2)
s(v) ≤u′, f(v) = 1, f(u′) = 1 ⊢
f(v) = 1, f(mu,s(v)) = 1 ⊢
σ3
(C′
6)
where σ1 = {v →v′}, σ2 = {u →v, v →u′} and σ3 = {u′ →mu,s(v), v′ →s(v)}.
If a cell with index v is labelled ‘1’ then no cell with an index bigger than v is
labelled ‘1’.
Derivation of C′
7:
(C2σ4)
⊢u′ ≤mu′,v
(C5σ5)
s(u) ≤v′, f(u) = 0, f(v′) = 0 ⊢
f(u) = 0, f(ms(u),v) = 0 ⊢
σ6
(C′
7)
where σ4 = {u →u′}, σ5 = {v →v′} and σ6 = {u′ →s(u), v′ →ms(u),v}.
If a cell with index u is labelled ‘0’ then no cell with an index bigger than u is
labelled ‘0’.

Cut-Elimination: Experiments with CERES
491
Derivation of C′
8:
(C3σ7)
⊢f(mu′,v′) = 0, f(mu′,v′) = 1
(C′
7)
f(u) = 0, f(ms(u),v) = 0 ⊢
f(u) = 0 ⊢f(ms(u),v′) = 1



C′
X
σ8
C′
X
(C′
6σ9)
f(v) = 1, f(mu′,s(v)) = 1 ⊢
f(v) = 1, f(u) = 0 ⊢
σ10
(C′
8)
where σ7 = {u →u′, v →v′}, σ8 = {u′ →s(u), v →v′}, σ9 = {u →u′} and
σ10 = {u′ →s(u), v′ →s(v)}.
If a cell with index v is labelled ‘1’ then there is no cell with index u labelled
‘0’, i.e. all cells are either only labelled ‘0’ or only labelled ‘1’.
Derivation of C′
9:
(C3σ11)
⊢f(mu′,v′) = 0, f(mu′,v′) = 1
(C′
7)
f(u) = 0, f(ms(u),v) = 0 ⊢
f(u) = 0 ⊢f(ms(u),v) = 1



C′
Y
σ12
C′
Y
(C′
8σ13)
f(v′) = 1, f(u′) = 0 ⊢
f(u) = 0, f(u′) = 0 ⊢
σ14
f(u) = 0 ⊢
σ15
(C′
9)
where σ11 = {u →u′, v →v′}, σ12 = {v′ →v, u′ →s(u)}, σ13 = {u →u′, v →
v′}, σ14 = {v′ →ms(u),v} and σ15 = {u′ →u}.
No cell is labelled ‘0’.
Derivation of C′
10:
(C3σ16)
⊢f(mu′,v′) = 0, f(mu′,v′) = 1
(C′
8)
f(v) = 1, f(u) = 0 ⊢
f(v) = 1 ⊢f(mu′,v′) = 1



C′
Z
σ17
C′
Z
(C′
6σ18)
f(v′′) = 1, f(mu,s(v′′)) = 1 ⊢
f(v) = 1, f(v′′) = 1 ⊢
σ19
f(v) = 1 ⊢
σ20
(C′
10)

492
M. Baaz et al.
where σ16 = {u →u′, v →v′}, σ17 = {u →mu′,v′}, σ18 = {v →v′′},
σ19 = {u′ →u, v′ →s(v′′)} and σ20 = {v′′ →v}.
No cell is labelled ‘1’.
(C3)
⊢f(mu,v) = 0, f(mu,v) = 1
(C′
9σ21)
f(u′) = 0 ⊢
⊢f(mu,v) = 1
σ22
(C′
10σ23)
f(v′) = 1 ⊢
⊢
σ24
where σ21 = {u →u′}, σ22 = {u′ →mu,v}, σ23 = {v →v′} and σ24 = {v′ →
mu,v}.
The contradiction follows from the axiom that for arbitrary u and v the cell
with the index mu,v is either labelled with ‘0’ or with ‘1’ in combination with
the facts that no cell is labelled ‘0’ and no cell is labelled ‘1’.
4
Possible Extensions
We plan to develop the following extensions of CERES:
– Due to the central importance of equality in mathematical proofs an inves-
tigation of cut-elimination in proofs with equality is very important to the
application of cut-elimination. We intend to use the Gentzen calculus LK
with the paramodulation rule (we refer to [10]) and to extend CERES to
equality.
– As the cut-free proofs are often very large and diﬃcult to interpret, we
intend to provide the possibility to analyse certain characteristics of the cut-
free proof (which are simpler than the proof itself). An important example
are Herbrand sequents which may serve to extract bounds from proofs (see
e.g. [6]). We plan to develop algorithms for extracting Herbrand sequents
(also from proofs of nonprenex sequents as indicated in [1]) and for comput-
ing interpolants.
– A great challenge in the formal analysis of mathematical proofs lies in pro-
viding a suitable format for the input and output of proofs. We plan to
develop an intermediary proof language connecting the language of mathe-
matical proofs with LK. Furthermore we will implement a proof editor with
a graphical user interface that allows for convenient input and analysis of
the output of CERES.
– In the present version CERES eliminates all cuts at once. But - for the ap-
plication to real mathematical proofs - only interesting cuts (i.e. lemmas)
deserve to be eliminated, others should be integrated as additional axioms.

Cut-Elimination: Experiments with CERES
493
5
Conclusion
The computer experiments with CERES described in this paper lead to the
following main consequences:
– even in the simple proof under consideration numerous formal variants of cut
free proofs condense to relatively few mathematically distinguishable vari-
ants.
– On the other hand, the number of mathematically distinguishable variants
is greater than one. This demonstrates, that the non-conﬂuence of CERES
is not just a formality within LK.
– CERES does not eliminate the mathematical activity of cut-elimination, it
just supports it. In fact it is essential to interprete the resources and results
mathematically.
– New features of CERES, concerning the relation of resolution refutations of
the characteristic clause set and the proof projections, evolved in the course
of the computer experiments.
References
1. M. Baaz, A. Leitsch: On skolemization and proof complexity, Fundamenta Infor-
maticae, 20(4), pp. 353–379, 1994.
2. M. Baaz, A. Leitsch: Cut-Elimination and Redundancy-Elimination by Resolution,
Journal of Symbolic Computation, 29, pp. 149-176, 2000.
3. M. Baaz, A. Leitsch: Towards a Clausal Analysis of Cut-Elimination, Journal of
Symbolic Computation to appear.
4. G. Gentzen:
Untersuchungen ¨uber das logische Schließen,
Mathematische
Zeitschrift, 39, pp. 405–431, 1934–1935.
5. J.Y. Girard: Proof Theory and Logical Complexity, in Studies in Proof Theory,
Bibliopolis, Napoli, 1987.
6. H. Luckhardt: Herbrand-Analysen zweier Beweise des Satzes von Roth: polynomi-
ale Anzahlschranken. The Journal of Symbolic Logic, 54, pp. 234–263, 1989.
7. G. Polya: Mathematics and plausible reasoning, Volume I: Induction and Analogy
in Mathematics. Princeton University Press, Princeton, New Jersey, 1954.
8. G. Polya: Mathematics and plausible reasoning, Volume II: Patterns of Plausible
Inference. Princeton University Press, Princeton, New Jersey, 1954.
9. C. Urban: Classical Logic and Computation. Ph.D. Thesis, University of Cam-
bridge Computer Laboratory, 2000.
10. A. Degtyarev, A. Voronkov: Equality Reasoning in Sequent-Based Calculi, Hand-
book of Automated Reasoning, vol. I, ed. by A. Robinson and A. Voronkov, chapter
10, pp. 611-706, Elsevier Science, 2001.

494
M. Baaz et al.
APPENDIX
Input Proof
This is the proof8 used for the experiments in section 3. Again all the premises
(the auxiliary formulas of the inferences) are put in bold face, the conclusions
are underlined and the same formula abbreviations are used.
p =
(τ)
M1, M2, A ⊢∞0, ∞1
(ϵ1)
∞1, S, T ⊢P
M1, M2, S, T, A ⊢P, ∞0
cut
(ϵ0)
∞0, S, T ⊢P
M1, M2, S, T, A ⊢P
cut
τ =
v ≤mu,v ⊢v ≤mu,v
(∀x)v ≤mx,v ⊢v ≤mu,v ∀: l
(∀y)(∀x)y ≤mx,y ⊢v ≤mu,v ∀: l
u ≤mu,v ⊢u ≤mu,v
(∀x)x ≤mx,v ⊢u ≤mu,v ∀: l
(∀y)(∀x)x ≤mx,y ⊢u ≤mu,v ∀: l
(τ ′)
M1, A ⊢u ≤mu,v ∧f(mu,v) = 0, f(mu,v) = 1 ∧: r
M1, M2, A ⊢u ≤mu,v ∧f(mu,v) = 0, v ≤mu,v ∧f(mu,v) = 1
∧: r
M1, M2, A ⊢(∃k)(u ≤k ∧f(k) = 0), v ≤mu,v ∧f(mu,v) = 1 ∃: r
M1, M2, A ⊢(∃k)(u ≤k ∧f(k) = 0), (∃l)(v ≤l ∧f(l) = 1)
∃: r
M1, M2, A ⊢(∀n)(∃k)(n ≤k ∧f(k) = 0), (∃l)(v ≤l ∧f(l) = 1) ∀: r
M1, M2, A ⊢∞0, (∀m)(∃l)(m ≤l ∧f(l) = 1)
∀: r
τ ′ =
f(mu,v) = 0 ⊢f(mu,v) = 0
f(mu,v) = 1 ⊢f(mu,v) = 1
f(mu,v) = 0 ∨f(mu,v) = 1 ⊢f(mu,v) = 0, f(mu,v) = 1 ∨: l
(∀x)(f(x) = 0 ∨f(x) = 1) ⊢f(mu,v) = 0, f(mu,v) = 1
∀: l
ϵ0 =
(ϵ′
0)
0 ≤u ∧f(u) = 0, s(u) ≤v ∧f(v) = 0, S, T ⊢P
0 ≤u ∧f(u) = 0, (∃k)(s(u) ≤k ∧f(k) = 0), S, T ⊢P ∃: l
0 ≤u ∧f(u) = 0, (∀n)(∃k)(n ≤k ∧f(k) = 0), S, T ⊢P ∀: l
(∃k)(0 ≤k ∧f(k) = 0), (∀n)(∃k)(n ≤k ∧f(k) = 0), S, T ⊢P ∃: l
(∀n)(∃k)(n ≤k ∧f(k) = 0), (∀n)(∃k)(n ≤k ∧f(k) = 0), S, T ⊢P ∀: l
(∀n)(∃k)(n ≤k ∧f(k) = 0), S, T ⊢P
c : l
8 speciﬁed and analyzed by Urban[9]

Cut-Elimination: Experiments with CERES
495
ϵ1 =
(ϵ′
1)
1 ≤u ∧f(u) = 1, s(u) ≤v ∧f(v) = 1, S, T ⊢P
1 ≤u ∧f(u) = 1, (∃l)(s(u) ≤l ∧f(l) = 1), S, T ⊢P ∃: l
1 ≤u ∧f(u) = 1, (∀m)(∃l)(m ≤l ∧f(l) = 1), S, T ⊢P ∀: l
(∃l)(1 ≤l ∧f(l) = 1), (∀m)(∃l)(m ≤l ∧f(l) = 1), S, T ⊢P ∃: l
(∀m)(∃l)(m ≤l ∧f(l) = 1), (∀m)(∃l)(m ≤l ∧f(l) = 1), S, T ⊢P ∀: l
(∀m)(∃l)(m ≤l ∧f(l) = 1), S, T ⊢P
c : l
ϵ′
j =
s(u) ≤v ⊢s(u) ≤v
u < v ⊢u < v
s(u) ≤v, s(u) ≤v ⊃u < v ⊢u < v ⊃: l
s(u) ≤v, (∀y)(s(u) ≤y ⊃u < y) ⊢u < v ∀: l
s(u) ≤v, (∀x)(∀y)(s(x) ≤y ⊃x < y) ⊢u < v ∀: l
(ϵ′′
j )
f(u) = j, s(u) ≤v, f(v) = j, S, T ⊢u < v ∧f(u) = f(v) ∧: r
f(u) = j, s(u) ≤v ∧f(v) = j, S, T ⊢u < v ∧f(u) = f(v) ∧: l
j ≤u ∧f(u) = j, s(u) ≤v ∧f(v) = j, S, T ⊢u < v ∧f(u) = f(v) ∧: l
j ≤u ∧f(u) = j, s(u) ≤v ∧f(v) = j, S, T ⊢(∃q)(u < q ∧f(u) = f(q)) ∃: r
j ≤u ∧f(u) = j, s(u) ≤v ∧f(v) = j, S, T ⊢(∃p)(∃q)(p < q ∧f(p) = f(q)) ∃: r
ϵ′′
j =
f(u) = j ⊢f(u) = j
f(v) = j ⊢f(v) = j
f(u) = j, f(v) = j ⊢f(u) = j ∧f(v) = j
∧: r
f(u) = f(v) ⊢f(u) = f(v)
f(u) = j, f(v) = j, ((f(u) = j ∧f(v) = j) ⊃f(u) = f(v)) ⊢f(u) = f(v)
⊃: l
f(u) = j, f(v) = j, (∀y)((f(u) = j ∧f(y) = j) ⊃f(u) = f(y)) ⊢f(u) = f(v) ∀: l
f(u) = j, f(v) = j, (∀x)(∀y)((f(x) = j ∧f(y) = j) ⊃f(x) = f(y)) ⊢f(u) = f(v) ∀: l
f(u) = j, f(v) = j, (∀i)(∀x)(∀y)((f(x) = i ∧f(y) = i) ⊃f(x) = f(y)) ⊢f(u) = f(v)
∀: l

Uniform Rules and Dialogue Games for Fuzzy Logics⋆
Agata Ciabattoni, Christian G. Ferm¨uller, and George Metcalfe
Technische Universit¨at Wien, A-1040 Vienna, Austria
{agata,chrisf,metcalfe}@logic.at
Abstract. We provide uniform and invertible logical rules in a framework of re-
lational hypersequents for the three fundamental t-norm based fuzzy logics i.e.,
Łukasiewicz logic, G¨odel logic, and Product logic. Relational hypersequents gen-
eralize both hypersequents and sequents-of-relations. Such a framework can be
interpreted via a particular class of dialogue games combined with bets, where the
rules reﬂect possible moves in the game. The problem of determining the valid-
ity of atomic relational hypersequents is shown to be polynomial for each logic,
allowing us to develop Co-NP calculi. We also present calculi with very simple
initial relational hypersequents that vary only in the structural rules for the logics.
1
Introduction
Fuzzy logics based on t-norms and their residua are formal systems providing a foun-
dation for reasoning under vagueness. Following e.g., [10], conjunction and implication
are interpreted on the real unit interval [0, 1] by a continuous t-norm and its residuum,
respectively. The most important of these logics are Łukasiewicz logic Ł, G¨odel logic
G, and Product logic Π. These three are viewed as fundamental since all continuous
t-norms can be constructed from their respective t-norms.
A variety of proof methods have been proposed for Ł, G, and Π. In particular, calculi
for many fuzzy logics have been presented in a framework of hypersequents, a gener-
alization of Gentzen sequents to multisets of sequents (see e.g., [2]). A very attractive
calculus has been deﬁned for G in [2] by embedding Gentzen’s LJ for intuitionistic
logic into a hypersequent calculus without modifying the rules for connectives. Elegant
hypersequent calculi have also been deﬁned for Ł [16] and Π [14], but using different
rules for connectives. A further calculus for G, which unlike the respective hypersequent
calculus has invertible rules, has been introduced in a framework of sequents-of-relations
[5]. More proof search oriented calculi include a tableaux calculus for Ł [9], decomposi-
tion proof systems for G [3], and goal-directed systems for Ł [15] and G [13]. Finally, a
general approach is presented in [1] where a calculus for any logic based on a continuous
t-norm is obtained via reductions to suitable ﬁnite-valued logics.
In this paper we introduce a generalization of both hypersequents and sequents-
of-relations, that we call relational hypersequents. A relational hypersequent, or, for
short, r-hypersequent, is a multiset of two different types of sequents, where Gentzen’s
sequent arrow is replaced in one by < and in the other by ≤. Intuitively we may think
⋆Research supported by C. B¨uhler-Habilitations-Stipendium H191-N04, FWF Project Nr.
P16539-N04, and Marie Curie Fellowship 501043.
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 496–510, 2005.
c⃝Springer-Verlag Berlin Heidelberg 2005

Uniform Rules and Dialogue Games for Fuzzy Logics
497
of an r-hypersequent as a meta-level (classical) disjunction of negated and non-negated
sequents. Within this framework, we are able to give logical rules for Ł, G, and Π, that
are uniform i.e., identical for all three logics. Since these rules are also invertible, we thus
obtain uniform proof search procedures where the validity problem for r-hypersequents
in Ł, G, or Π can be reduced to the validity problem in the respective logic for r-
hypersequents containing only atomic formulas.1 Moreover, we show that this latter
problem is polynomial for each logic. Simple modiﬁcations then allow us to use these
rules to present Co-NP decision procedures for Ł, G, and Π, matching the complexity
class of the logics (see e.g., [10]). Furthermore, purely syntactic calculi with very simple
initial relational hypersequents are obtained by introducing structural rules reﬂecting the
characteristic properties of the particular logic.
We also present an interpretation of the uniform logical rules in terms of dialogue
games combined with bets, that stems from Giles’s game-theoretic characterization of
Ł in the seventies [7,8]. Giles deﬁned a Lorenzen-style game for which the existence of
winning strategies for a formula corresponds to the validity of that formula in Ł. Here
we reveal a deep connection between the search for winning strategies in Giles’s game
and the r-hypersequent rules for Ł, and extend this connection to G and Π.
2
t-Norm Based Fuzzy Logics
Continuous t-norms and their residua are deﬁned as follows:
Deﬁnition 1. A continuous t-norm is a continuous, commutative, associative, monoton-
ically increasing function ∗: [0, 1]2 →[0, 1] where 1 ∗x = x for all x ∈[0, 1]. The
residuum of ∗is a function ⇒∗: [0, 1]2 →[0, 1] where x ⇒∗y = max{z | x ∗z ≤y}.
The most important examples of continuous t-norms and their residua are:
t-Norm
Residuum
Łukasiewicz x ∗Ł y = max(0, x + y −1) x ⇒Ł y = min(1, 1 −x + y)
G¨odel
x ∗G y = min(x, y)
x ⇒G y =
1 if x ≤y
y otherwise
Product
x ∗Π y = x · y
x ⇒Π y =
1
if x ≤y
y/x otherwise
Any continuous t-norm is an ordinal sum construction of these three, see e.g., [10] for
details. Observe also that the functions min and max can be expressed in terms of ∗and
⇒∗, i.e., min(x, y) = x ∗(x ⇒∗y) and max(x, y) = min((x ⇒∗y) ⇒∗y, (y ⇒∗
x) ⇒∗x). Each continuous t-norm determines a propositional logic as follows:
Deﬁnition 2. For a continuous t-norm ∗with residuum ⇒∗, we deﬁne a logic L∗based
on a language with binary connectives →, ⊙, constant ⊥, and deﬁned connectives
¬A =def A →⊥, A∧B =def A⊙(A →B), A∨B =def ((A →B) →B)∧((B →
1 These may also be viewed as providing a uniform normal form for Ł, G, and Π.

498
A. Ciabattoni, C.G. Ferm¨uller, and G. Metcalfe
A) →A). A valuation for L∗is a function v assigning to each propositional variable a
truth value from the real unit interval [0, 1], uniquely extended to formulas by:
v(A ⊙B) = v(A) ∗v(B)
v(A →B) = v(A) ⇒∗v(B)
v(⊥) = 0
A formula A is valid in L∗, written |=L∗A, iff v(A) = 1 for all valuations v for L∗.
We call the logics L∗Ł, L∗G, and L∗Π, Łukasiewicz logic Ł, G¨odel logic G, and Product
logic Π, respectively.
3
Uniform Rules
We give uniform and invertible logical rules for Ł, G, and Π in a framework of relational
hypersequents, which are deﬁned as follows:
Deﬁnition 3. A relational hypersequent (r-hypersequent) is a ﬁnite multiset of the form:
G = Γ1 ◁1 ∆1 | . . . | Γn ◁n ∆n
where ◁i ∈{<, ≤} and Γi and ∆i are ﬁnite multisets of formulas for i = 1, . . . , n. G
is atomic if all formulas occurring in G are atomic. The size of G is the total number of
symbols occurring in formulas of G.
The use of multisets in this deﬁnition means that the multiplicity but not the order of
elements is important. Hence all set notation will refer to multisets, denoted by the
symbols Γ and ∆. Also, we take advantage of standard conventions such as allowing
Γ, A and Γ, ∆to stand for Γ ∪{A} and Γ ∪∆respectively, λΓ for Γ, . . . , Γ (λ times),
and the empty space for the empty multiset ∅. Note moreover, that the use of inequality
symbols < and ≤in the deﬁnition is purely syntactic (although of course also suggestive
of the intended meaning). Finally, we remark that a hypersequent (see e.g., [2]) may be
viewed as an r-hypersequent with just one relation symbol, while a sequent-of-relations
(see e.g., [5]) may be viewed as an r-hypersequent where all multisets contain exactly
one formula.
Below, we deﬁne validity for r-hypersequents in each of the three logics, informally
understanding | as a meta-level “or” and < and ≤as denoting inequalities between
combinations (different for each logic) of truth values of formulas. Note that here (and
throughout this paper) the symbols < and ≤have two uses: a syntactic one as part of an
r-hypersequent, and a semantic one as inequalities holding between two mathematical
expressions. We rely on context to make clear which use is intended.
Deﬁnition 4. An r-hypersequent G = Γ1 ◁1 ∆1 | . . . | Γn ◁n ∆n is valid for L ∈
{Ł, G, Π}, written |=L G, iff for all valuations v for L,
#v
LΓi ◁i #v
L∆i for some i, 1 ≤i ≤n,
where #v
L∅= 1 for L ∈{Ł, G, Π} and
#v
Ł(Γ) = 1+

A∈Γ
{v(A)−1}
#v
G(Γ) = minA∈Γ {v(A)}
#v
Π(Γ) =

A∈Γ
{v(A)}

Uniform Rules and Dialogue Games for Fuzzy Logics
499
Observe that for all formulas A, |=L ≤A iff |=L A for L ∈{Ł, G, Π}. Below we
present uniform logical rules in this framework, using G and H as metavariables to
denote (possibly empty) r-hypersequents called side r-hypersequents.
Deﬁnition 5. We deﬁne the following uniform logical rules for ◁∈{<, ≤}:
(→, ◁, l) G | Γ ◁∆| Γ, B ◁A, ∆
G | Γ ◁∆| B < A
G | Γ, A →B ◁∆
(→, ◁, r)
G | Γ ◁∆
G | Γ, A ◁B, ∆| A ≤B
G | Γ ◁A →B, ∆
(⊙, ◁, l) G | Γ, A, B ◁∆G | Γ, ⊥◁∆
G | Γ, A ⊙B ◁∆
(⊙, ◁, r) G | Γ ◁⊥, ∆| Γ ◁A, B, ∆
G | Γ ◁A ⊙B, ∆
Note that uniform rules for ∧and ∨are derivable using Deﬁnition 2. However we can
also give more streamlined versions, i.e., for ◁∈{<, ≤}:
(∧, ◁, l)
G | Γ, A ◁∆| Γ, B ◁∆
G | Γ, A ∧B ◁∆
(∧, ◁, r) G | Γ ◁A, ∆
G | Γ ◁B, ∆
G | Γ ◁A ∧B, ∆
(∨, ◁, l) G | Γ, A ◁∆
G | Γ, B ◁∆
G | Γ, A ∨B ◁∆
(∨, ◁, r)
G | Γ ◁A, ∆| Γ ◁B, ∆
G | Γ ◁A ∨B, ∆
Observe that the rules for →, ∧and ∨have the subformula property, i.e., all formulas
occurring in the premises of a rule occur as subformulas of formulas in the conclusion.
The rules for ⊙do not have this property, since ⊥appears in the premises and possibly
not the conclusion. Nevertheless, the right premise in (⊙, ◁, l), and Γ ◁⊥, ∆in the
premise of (⊙, ◁, r) may be removed with no loss of soundness for G and Π. Moreover,
since Ł can be based on a language without ⊙, non-uniform rules with the subformula
property can be given for all three logics.
Deﬁnition 6. A rule G1 ... Gn
G
is sound for a logic L if whenever |=L Gi for i = 1, . . . , n,
then |=L G, and invertible if whenever |=L G, then |=L Gi for i = 1, . . . , n.
Lemma 1. If G1 ... Gn
G
is sound (invertible) for L, then so is H|G1 ... H|Gn
H|G
.
Proof. Follows directly from Deﬁnition 4.
⊓⊔
Theorem 1. The uniform logical rules are sound and invertible for Ł, G, and Π.
Proof. We consider only the rules for →(the cases for ⊙being similar), using Lemma 1
to disregard side r-hypersequents. Let v be a valuation for Ł, G, or Π. If v(A) ≤v(B),
then v(A →B) = 1, and clearly for both (→, ◁, l) and (→, ◁, r), the premises hold iff
the conclusion holds. Now suppose that v(A) > v(B). We consider each rule in turn:
– (→, ◁, l). The right premise clearly holds. For Ł and Π, by simple arithmetic,
the conclusion holds iff the left premise holds. For G, v(A →B) = v(B)
and min(#v
G(Γ), v(B)) ◁min(v(A), #v
G(∆)) iff min(#v
G(Γ), v(B)) ◁v(A)
and min(#v
G(Γ), v(B)) ◁#v
G(∆). However, min(#v
G(Γ), v(B)) ◁v(A) since
v(A) > v(B), so we have that the left premise holds iff the conclusion holds.

500
A. Ciabattoni, C.G. Ferm¨uller, and G. Metcalfe
– (→, ◁, r). If the conclusion holds, then the left premise, and (by simple arithmetic)
the right premise hold. For Ł and Π, by simple arithmetic, the conclusion holds iff
the right premise holds. For G, if min(#v
G(Γ), v(A)) ◁min(v(B), #v
G(∆)) then
min(#v
G(Γ), v(A))◁v(B) holds, and, since v(A) > v(B), min(#v
G(Γ), v(A)) =
#v
G(Γ). Hence the right premise holds iff the conclusion holds.
⊓⊔
Example 1. The uniform logical rules may be applied upwards exhaustively to reduce
r-hypersequents to atomic r-hypersequents, e.g.,
p ≤q | p, q ≤p, q
p ≤q | q < p
(→,≤,l)
p, p →q ≤q
⊥≤q
(⊙,≤,l)
p ⊙(p →q) ≤q
Proposition 1. Applying the uniform logical rules upwards to r-hypersequents termi-
nates with atomic r-hypersequents.
Proof. We deﬁne the following measures and well-orderings:
c(q) = 1 for q atomic, c(A ⊙B) = c(A →B) = c(A) + c(B) + 1 for formulas A, B.
mc(Γ ◁∆) = {c(A) | A ∈Γ ∪∆} for multisets Γ, ∆, and ◁∈{<, ≤}.
mmc(G) = {mc(Γ ◁∆) | Γ ◁∆∈G} for an r-hypersequent G.
For multisets α, β of integers: α <m β iff (1) α ⊂β, or (2) α <m γ where γ =
(β −{j}) ∪{i, . . . , i}, and i < j.
For multisets φ, ψ of multisets of integers, φ <mm ψ iff (1) φ ⊂ψ, or (2) φ <mm χ
where χ = (ψ −{α}) ∪{β, . . . , β} and β <m α.
For each uniform logical rule G1 ... Gn
G
it is easy to check that mmc(Gi) <mm mmc(G)
for i = 1, . . . , n. Hence, since there is always a rule for any non-atomic formula, the
rules applied upwards terminate with atomic r-hypersequents.
⊓⊔
4
Evaluating Atomic Relational Hypersequents
Let us take stock of what we have achieved so far. By providing uniform rules for Ł,
G, and Π, that are sound and invertible, we are able to reduce the validity problem (i.e.,
checking the validity of a formula) in these logics to checking the validity of atomic
r-hypersequents. We might also view the atomic r-hypersequents thus obtained as a sort
of “uniform normal form” for these logics. This is a pleasant enough achievement in
itself but it is only really useful computationally if we can show that checking the validity
of atomic r-hypersequents is less complex than deciding the validity problem for each
logic. In fact, while it is well-known that the validity problem for all these logics is
Co-NP complete (see e.g., [10] for proofs and references), we show here that checking
validity for atomic r-hypersequents is in each case polynomial.
We begin with a useful translation of atomic r-hypersequents into a set of inequations,
where an atomic r-hypersequent is valid in a logic iff the associated set is inconsistent
over [0, 1].

Uniform Rules and Dialogue Games for Fuzzy Logics
501
Deﬁnition 7. For atomic G = Γ1 ◁1 ∆1 | . . . | Γn ◁n ∆n and L ∈{Ł, G, Π}:
SG = {◦LΓ1 ̸◁1 ◦L ∆1, . . . , ◦LΓn ̸◁n ◦L ∆n}
where ̸≤is > and ̸< is ≥, ◦L∅= 1, and
◦Ł(Γ) = 1 +

q∈Γ
{xq −1}
◦G (Γ) = minq∈Γ {xq}
◦Π (Γ) =

q∈Γ
{xq}
where xq is a real-valued variable for all propositional variables q, and x⊥= 0.
Lemma 2. For atomic G and L ∈{Ł, G, Π}, |=L G iff SG is inconsistent over [0, 1].
Proof. Immediate from Deﬁnition 4.
⊓⊔
For Ł we obtain the desired result using linear programming methods.
Theorem 2. Checking |=Ł G for an atomic r-hypersequent G is polynomial.
Proof. By Lemma 2, since linear programming is polynomial, see e.g., [17].
⊓⊔
To show that checking the validity of atomic r-hypersequents for G is polynomial, we
use a result of Jeavons et al. [11] concerning relations over a ﬁnite domain.
Deﬁnition 8. Let R be an n-ary relation over a domain D and ⊗: D2 →D be an ACI
operation, i.e., a binary idempotent, associative, and commutative operation. We say that
R is closed under ⊗if (t1, . . . tn), (t′
1, . . . t′
n) ∈R implies (t1 ⊗t′
1, . . . , tn ⊗t′
n) ∈R.
A set of relations S is closed under ⊗iff R is closed under ⊗for all R ∈S.
Theorem 3 ([11]). If a set of relations Γ over a ﬁnite domain D is closed under some
ACI operation, then its constraint satisfaction problem is solvable in polynomial time.
Theorem 4. Checking |=G G for an atomic r-hypersequent G is polynomial.
Proof. Let x1, . . . , xn be the distinct variables occurring in SG. It can be shown that SG
is inconsistent over [0, 1] iff SG is inconsistent over the set Dn = {0, 1
n, . . . , n−1
n , 1}.
Associatewitheach◦GΓ ̸◁◦G∆∈SG arelationR(x1, . . . , xn)suchthatR(a1, . . . , an)
for ai ∈Dn, i = 1, . . . , n, holds iff ◦GΓ ̸◁◦G ∆holds when xi is replaced by ai.
Moreover, if R(a1, . . . , an) and R(b1, . . . , bn) hold for ai, bi ∈Dn, i = 1, . . . , n, then
also R(min(a1, b1), . . . , min(an, bn)) holds. Hence the set of relations associated with
SG is closed under the ACI operation min : D2
n →Dn, and, by Theorem 3, its constraint
satisfaction problem is solvable in polynomial time. However, this problem is equivalent
to checking the inconsistency of SG which, by Lemma 2, is equivalent to checking the
validity of G.
⊓⊔
For Π we again use linear programming methods, dealing separately with the cases
where propositional variables are assigned the value 0.
Deﬁnition 9. Let G be an atomic r-hypersequent. An atomic formula q is:
– 0-zero-ok for G if Γ, q ≤∆∈G.

502
A. Ciabattoni, C.G. Ferm¨uller, and G. Metcalfe
– n-zero-ok for G if Γ, q < ∆∈G, and for all p ∈∆, p is m-zero-ok for G for some
m ∈N, m < n, where n = 1 + 
p∈∆min{k | p is k-zero-ok for G}.
– zero-ok for G if q is n-zero-ok for G for some n ∈N.
Lemma 3. Let H = G | Γ < ∆be an atomic r-hypersequent, and p ∈Γ ∪∆where p
is not zero-ok for H. If |=Π H, then |=Π G.
Proof. Note ﬁrst that if p ∈Γ is not zero-ok, then there must be q ∈∆such that q is not
zero-ok for H. Hence we can assume that p ∈∆. Suppose ̸|=Π G, i.e., there is a valuation
v for Π such that for all Γ ′ ◁∆′ ∈G, #v
ΠΓ ′ ̸◁#v
Π∆′. We deﬁne a valuation v′ such
that v′(q) = 0 if q is not zero-ok, v′(q) = v(q) otherwise. Clearly, #v′
ΠΓ ̸< #v′
Π∆= 0.
Consider Γ ′ ◁∆′ ∈G. If all q ∈Γ ′ are zero-ok, then #v′
ΠΓ ′ = #v
ΠΓ ′. If q ∈Γ ′ is
not zero-ok, then ◁is <, and for some not zero-ok q′ ∈∆′, v′(q′) = 0. In both cases
#v′
ΠΓ ′ ̸◁#v
Π∆′ ≥#v
Π∆′. Hence ̸|=Π H as required.
⊓⊔
Lemma 4. Let G be an atomic r-hypersequent where p is zero-ok for G. For all valua-
tions v for Π, if v(p) = 0, then #v
Π(Γ) ◁#v
Π(∆) for some Γ ◁∆∈G.
Proof. A simple induction on n where p is n-zero-ok.
⊓⊔
Theorem 5. Checking |=Π G for an atomic r-hypersequent G is polynomial.
Proof. It is straightforward to show that ﬁnding the zero-ok atomic formulas of G is
polynomial in the size of G. Moreover, by repeated applications of Lemma 3, |=Π G iff
|=Π G′ for some G′ ⊆G containing only zero-ok atomic formulas. If ⊥occurs in G′
(which can be checked in polynomial time) then by Lemma 4, G′ is valid. If ⊥does not
occur in G′, by Lemma 2, |=Π G′ iff SG′ is inconsistent over [0, 1] iff, by Lemma 4,
SG′ is inconsistent over (0, 1]. However this latter problem is isomorphic to a linear
programming problem over the positive reals, known to be polynomial.
⊓⊔
5
Co-NP Calculi
Despite having invertible rules and polynomially decidable atomic r-hypersequents, we
do not yet have Co-NP calculi for Ł, Π, and G, since the rules applied upwards may
increase the size of r-hypersequents exponentially. This problem is overcome by giving
rules that make use of new propositional variables.
Deﬁnition 10. We deﬁne the following revised logical rules for ◁∈{<, ≤}, where p
and q are propositional variables not occurring in the conclusions of the rules:
(→, ◁, l)′
G | Γ, q ◁∆| B < q, A
G | Γ, A →B ◁∆
(→, ◁, r)′ G | Γ ◁∆G | Γ, p ◁q, ∆| p ≤q | A < p | q < B
G | Γ ◁A →B, ∆
(⊙, ◁, l) G | Γ, A, B ◁∆G | Γ, ⊥◁∆
G | Γ, A ⊙B ◁∆
(⊙, ◁, r)′ G | Γ ◁q, ∆| q < A, B | q < ⊥
G | Γ ◁A ⊙B, ∆

Uniform Rules and Dialogue Games for Fuzzy Logics
503
Theorem 6. The revised logical rules are sound and invertible for Ł, G, and Π.
Proof. We consider just the rules for →(the cases for ⊙being similar), using Lemma 1
to disregard side r-hypersequents. Let L ∈{Ł, G, Π}.
– (→, ◁, l)′. For soundness, given a valuation v, we can assume (since q does not
occur in the conclusion) that v(q) = v(A →B). From v(B) ≥#v
L(q, A) we
get #v
L(Γ, A →B) ◁#v
L(∆) as required. For invertibility, given a valuation v, if
v(B) < #v
L(q, A) then we are done, otherwise we must have v(q) ≤v(A →B)
and hence, #v
L(Γ, q) ◁#v
L(∆) as required.
– (→, ◁, r)′. For soundness, consider a valuation v. If v(A) ≤v(B), then v(A →
B) = 1 and we are done by the ﬁrst premise. If v(A) > v(B), then we can assume
(since p and q do not occur in the conclusion) that v(p) = v(A) and v(q) = v(B).
Hence, #v
L(Γ, p) ◁#v
L(q, ∆) and, similarly to the case of (→, ◁, r) in Theorem 1,
#v
L(Γ) ◁#v
L(A →B, ∆) as required. For invertibility, the left premise is obvious,
for the right premise consider a valuation v. If v(A) < v(p), v(q) < v(B), or
v(p) ≤v(q), then we are done. Otherwise, #v
L(Γ, A) ◁#v
L(B, ∆) and, similarly to
the case of (→, ◁, r) in Theorem 1, #v
L(Γ, p) ◁#v
L(q, ∆) as required.
⊓⊔
Proposition 2. Applying the revised logical rules upwards to an r-hypersequent G ter-
minates with atomic r-hypersequents of size polynomial in the size of G.
Proof. Similar to the proof of Proposition 1, except that also each upward application
of a rule gives only a constant increase in the size of the r-hypersequent.
⊓⊔
Theorem 7. The revised logical rules provide Co-NP decision procedures for the va-
lidity problems for Ł, G, and Π.
Proof. To show that a formula is not valid we apply the revised logical rules upwards
exhaustively, making a non-deterministic choice of two branches where necessary. The
result follows from Proposition 2, and Theorems 2, 4, and 5.
⊓⊔
6
Structural Rules
The aim of this section is to use the uniform logical rules to give purely syntactic calculi
for Ł, G, and Π with very simple axioms and structural rules.
Deﬁnition 11. We deﬁne the following uniform axioms and structural rules:
(ID) A ≤A
(⊥) ⊥≤A
(Λ) ≤
(<) ⊥<
(EW)
G
G | Γ ◁∆
(EC) G | Γ ◁∆| Γ ◁∆
G | Γ ◁∆
(WL)
G | Γ ◁∆
G | Γ, A ◁∆
(S≤)
G | Γ1, Γ2 ≤∆1, ∆2
G | Γ1 ≤∆1 | Γ2 ≤∆2
(M) G | Γ1 ◁∆1
G | Γ2 ◁∆2
G | Γ1, Γ2 ◁∆1, ∆2
Lemma 5. The uniform axioms and rules are sound for Ł, G, and Π.

504
A. Ciabattoni, C.G. Ferm¨uller, and G. Metcalfe
Proof. Straightforward using Deﬁnition 4.
⊓⊔
We now deﬁne calculi for Ł, G, and Π by extending the core uniform axioms and rules
with further structural rules reﬂecting the characteristic properties of each logic.
Deﬁnition 12. rHŁ consists of the uniform axioms and rules together with:
(SŁ)
G | Γ1, Γ2 ≤∆1, ∆2
G | Γ1 ≤∆1 | Γ2 < ∆2
(W⊥)
G | Γ ≤∆
G | Γ, ⊥< ∆
Theorem 8. An r-hypersequent G is derivable in rHŁ iff |=Ł G.
Proof. For soundness it is enough and easy to show that (SŁ) and (W⊥) are sound. For
completeness we apply the invertible logical rules to G upwards to obtain valid atomic
r-hypersequents. For each atomic r-hypersequent H = Γ1 ◁1 ∆1 | . . . | Γn ◁n ∆n,
|=Ł H iff SH is inconsistent over [0, 1]. By linear programming methods [17], this holds
iff there exist λ, λ1, . . . , λn ∈N where either λ > 0, or λi > 0 and ◁i is ≤for some i,
1 ≤i ≤n, and:
λ⊥∪
n

i=1
λi∆i ⊆∗
n

i=1
λiΓi
where (1) ∆⊆∗Γ if ∆⊆Γ, and (2) ∆∪{A} ⊆∗Γ ∪{⊥} if ∆⊆∗Γ. If λ > 0, then
we choose any i such that ⊥∈Γi and apply (W⊥) upwards to get an r-hypersequent
H′ where SH′ meets the conditions of the second case. If λi > 0 and ◁i is ≤for some i,
1 ≤i ≤n,thenweapply(EW)and(EC)upwardstogetλi copiesofΓi◁i∆i.Applying
(SŁ) and (S≤) upwards we have that H is derivable if H′ = λ1Γ1, . . . , λnΓn ≤
λ1∆1, . . . , λn∆n is derivable. However, H′ is derivable by repeated applications of
(M), (WL), (ID), (⊥), and (Λ).
⊓⊔
Deﬁnition 13. rHG consists of the uniform rules and axioms together with:
(SG, ◁) G | Γ1, Γ2 ◁∆1
G | Γ1 ≤∆2
G | Γ1 ◁∆1 | Γ2 < ∆2
(CL) G | Γ, A, A ◁∆
G | Γ, A ◁∆
Lemma 6. The following rules are invertible for G, and derivable in rHG:
(M, ◁, l) G | Γ1 ◁∆| Γ2 ◁∆
G | Γ1, Γ2 ◁∆
(M, ◁, r) G | Γ ◁∆1
G | Γ ◁∆2
G | Γ ◁∆1, ∆2
Proof. It is straightforward to show that (M, ◁, l) and (M, ◁, r) are invertible for G.
They are derivable in rHG as follows, where we write (WL)∗and (CL)∗for multiple
applications of (WL) and (CL) respectively:
G | Γ1 ◁∆| Γ2 ◁∆
(W L)∗
G | Γ1, Γ2 ◁∆| Γ1, Γ2 ◁∆
(EC)
G | Γ1, Γ2 ◁∆
G | Γ ◁∆1
G | Γ ◁∆2
(M)
G | Γ, Γ ◁∆1, ∆2
(CL)∗
G | Γ ◁∆1, ∆2
⊓⊔
Theorem 9. An r-hypersequent G is derivable in rHG iff |=G G.

Uniform Rules and Dialogue Games for Fuzzy Logics
505
Proof. For soundness, it sufﬁces and is easy to show that (CL) and (SG, ◁) are sound
for G. For completeness, we ﬁrst apply the invertible logical rules to G upwards to
obtain valid atomic r-hypersequents. By Lemma 6, applying (M, ◁, l) and (M, ◁, r)
upwards, atomic r-hypersequents are derivable if valid r-hypersequents in which all
multisets contain at most one atomic formula are derivable. Such an r-hypersequent H
is valid iff the sequent-of-relations obtained by replacing the empty set by ⊤is valid,
and hence, using a result of [4] for sequents-of-relations, we get that H must have one of
the following forms, where ◁i ∈{<, ≤} for i = 1, . . . , n, and we allow C, C1, . . . , Cn
to stand for multisets containing at most one formula.
1. (cycles) G′ | C ≤C or G′ | C1 ◁1 C2 | . . . | Cn−1 ◁n−1 Cn | Cn ≤C1.
2. (1-chains) G′ | C ≤or G′ | C1 ≤C2 | C2 < C3 | . . . | Cn−1 < Cn | Cn <
3. (0-chains) G′ | ⊥≤C or G′ | ⊥< C1 | C1 < C2 | . . . | Cn−1 < Cn | Cn ≤C.
4. (0-1-chains) G′ | ⊥< or G′ | ⊥< C1 | C1 < C2 | . . . | Cn <.
It is straightforward to show that the above r-hypersequents are derivable in rHG.
⊓⊔
Deﬁnition 14. rHΠ consists of the uniform rules together with:
(SΠ) G | Γ1, Γ2 ≤∆1, ∆2
G | Γ3 ≤∆2
G | Γ1 ≤∆1 | Γ2 < ∆2 | Γ3 ≤∆3
(RCL) G | Γ, ⊥, ⊥◁∆
G | Γ, ⊥◁∆
Lemma 7. If G | Γ1, Γ2 ≤∆1, ∆2 is atomic and derivable in rHΠ and p is zero-ok
for all p ∈∆2, then G | Γ1 ≤∆1 | Γ2 < ∆2 is derivable in rHΠ.
Proof. We proceed by induction on n = 1 + 
p∈∆2 min{m | p is m-zero-ok for G}
For each p ∈∆2, we have two cases. If p is 0-zero-ok, then Γ ′, p ≤∆′ ∈G. If p is m-
zero-ok for some m > 0, then Γ ′, p < ∆′ ∈G where all q ∈∆′ are zero-ok. Repeatedly
applying (S≤) upwards in the former case, and the induction hypothesis in the latter, plus
repeated applications of (EC) and (EW) upwards, we get that G | Γ1 ≤∆1 | Γ2 < ∆2
is derivable if H = G | Γ1 ≤∆1 | Γ2 < ∆2 | Γ3 ≤∆3 is derivable where ∆2 ⊆Γ3.
Now applying (SΠ) upwards, since G | Γ3 ≤∆2 is derivable, we get that H is derivable
if G | Γ1, Γ2 ≤∆1, ∆2 is derivable.
⊓⊔
Theorem 10. An r-hypersequent G is derivable in rHΠ iff |=Π G.
Proof. It is easy to show that (RCL) is sound for Π. For (SΠ), if v is a valuation for Π
in which the conclusion does not hold, and #v
Π(Γ1) · #v
Π(Γ2) ≤#v
Π(∆1) · #v
Π(∆2),
then, since #v
Π(Γ1) > #v
Π(∆1) and #v
Π(Γ2) ≥#v
Π(∆2), we must have #v
Π(∆2) = 0.
Hence, since #v
Π(Γ3) > #v
Π(∆3) ≥0, the right premise cannot hold. For completeness,
we apply the invertible logical rules to G upwards to obtain valid atomic r-hypersequents.
By Lemma 3, for each valid atomic r-hypersequent H, |=Π H implies |=Π H′ for some
H′ ⊆H such that H′ contains only zero-ok atomic formulae. If H′ contains ⊥then it is
easy to prove that H′ is derivable as required. Otherwise SH′ is inconsistent over (0, 1]
and by linear programming methods there exist λ1, . . . , λn ∈N with λi > 0, where ◁i
is ≤for some i, 1 ≤i ≤n, and
n

i=1
λi∆i ⊆
n

i=1
λiΓi

506
A. Ciabattoni, C.G. Ferm¨uller, and G. Metcalfe
By (EC) applied upwards to obtain λi copies of Γi ◁i ∆i, then multiple applications of
Lemma 7 and (S≤), and (EW) applied upwards, H is derivable if λ1Γ1, . . . , λnΓn ≤
λ1∆1, . . . , λn∆n is derivable. But this r-hypersequent is derivable using (M), (WL),
(ID) and (Λ).
⊓⊔
It is important to note that for each logic there may be considerable redundancy in the
rules presented. For example, for Ł we can drop the right premise of (→, l) and maintain
soundness; we are then able to drop all rules and axioms referring to <. What we obtain
is essentially the hypersequent calculus presented in [16]. For Π our pruning leads to
a calculus that, unlike the sequent or hypersequent calculi of [14], has the subformula
property,albeitwithmorecomplicatedstructures.ForGsimpliﬁcationsleadtoacalculus
very similar to the sequent-of-relations calculus presented in [5].
7
Game Interpretation
In the 1970s [7,8] Robin Giles presented a characterization of Ł in terms of a dia-
logue game combined with bets. In this section we review (very brieﬂy) Giles’s game
and generalize it with the aim of revealing a deep connection between our uniform r-
hypersequent rules and the search for winning strategies in versions of the game for Ł,
Π, and G.2 Giles’s game consists of two largely independent building blocks:
1. Betting for positive results of experiments. There are two players — say, me and
you — who agree to pay 1$ to the opponent player for every false statement that they
assert.3 By [p1, . . . , pm∥q1, . . . , qn] we denote an elementary state in the game, where
I assert each of the qi in the multiset {q1, . . . , qn} of statements (atomic formulas), and
you assert each pi ∈{p1, . . . , pm}.
Each statement q refers to an experiment Eq with a binary (yes/no) result: q can be
read as ‘Eq yields a positive result’. The same experiment may yield different results
when repeated. However, for every run of the game, a certain risk value ⟨q⟩∗∈[0, 1]
is associated with q, denoting the probability that Eq yields a negative result. For the
special atomic formula ⊥(falsum) we deﬁne ⟨⊥⟩∗= 1. The risk associated with a
multiset {p1, . . . , pm} of atomic formulas is deﬁned as ⟨p1, . . . , pm⟩∗= m
i=1⟨pi⟩∗.
The risk ⟨⟩∗associated with ∅is deﬁned as 0. The risk associated with an elementary state
[p1, . . . , pm∥q1, . . . , qn] is calculated from my point of view. Therefore the condition
⟨p1, . . . , pm⟩∗≥⟨q1, . . . , qn⟩∗expresses that I do not expect any loss (but possibly
some gain) when betting as explained above.
2. A Lorenzen-style dialogue game for compound formulas. Giles follows Paul
Lorenzen (see e.g., [12]) in implicitly deﬁning the meaning of logical connectives by
reference to rules of a dialogue game that proceeds by systematically reducing arguments
about compound formulas to arguments about their subformulas.
2 Wealsogeneralizetheresultsof[6]thatrelateadialoguegameforGtothesequents-of-relations
calculus of [5].
3 For a detailed motivation and explanation of the game we refer to [8].

Uniform Rules and Dialogue Games for Fuzzy Logics
507
To assist a concise presentation, we will only consider implication (→), noting that
in Ł all other connectives can be deﬁned from →and ⊥. The central dialogue rule can
be stated as follows:
(R) If I assert A →B, then whenever you choose to attack this assertion by asserting A,
I have to assert also B. (And vice versa, i.e., for the roles of me and you switched.)
No special regulations on the succession of moves in the dialogue game are required.
However, each assertion is attacked at most once: this is reﬂected by the removal of
A →B from the multiset of all formulas asserted by a player during a run of the game,
as soon as the other player has either attacked by asserting A, or indicated that she will not
attack A →B at all. Observe that these stipulations ensure that every run of the dialogue
game ends in an elementary state [p1, . . . , pm∥q1, . . . , qn]. Given an assignment ⟨·⟩∗of
risk values to the pis and qis we say that I win the game if I do not expect any loss, i.e.,
if ⟨p1, . . . , pm⟩∗≥⟨q1, . . . , qn⟩∗.
As an almost trivial example consider the game with intial state [∥p →q]; i.e., I
initially assert p →q, for some atomic formulas p and q. In response, you can either
assert p in order to force me to assert q, or explicitly refuse to attack p →q. In the ﬁrst
case the game ends in the elementary state [p∥q]; in the second case it ends in [∥]. If an
assignment ⟨·⟩∗of risk values gives ⟨p⟩∗≥⟨q⟩∗, then I win the game, whatever move
you choose to make. In other words: I have a winning strategy associated with p →q
for assignments of risk values such that ⟨p⟩∗≥⟨q⟩∗.
Theorem 11 (R. Giles [7,8]). A formula A is valid in Ł iff for all assignments of risk
values to atomic formulas occurring in A, I have a winning strategy.
Giles proved the theorem without formalizing the concept of strategies. However, to
reveal the connection to analytic proof systems we need to deﬁne structures that register
possible choices for both players. These structures, called disjunctive strategies or, for
short, d-strategies, appear at a different level of abstraction to strategies. The latter are
only deﬁned with respect to given assignments of risk values (and may be different for
different assignments), whereas d-strategies abstract away from particular assignments.
Deﬁnition 15. A d-strategy (for me) is a tree whose nodes are disjunctions of states:
[A1
1, . . . , A1
m1∥B1
1, . . . , B1
n1]

. . .

[Ak
1, . . . , Ak
mk∥Bk
1, . . . , Bk
nk]
which fulﬁll the following conditions:
1. All leaf nodes of a d-strategy denote disjunctions of elementary states.
2. Internal nodes are partitioned into I-nodes and you-nodes.
3. Any I-node is of the form G  [A →B, Γ∥∆] and has exactly one successor node of
theformG  [Γ, B∥A, ∆]  [Γ∥∆],whereG denotesa(possiblyempty)disjunction
of states, and Γ, ∆denote (possibly empty) multisets of formulas.
4. For every state [Γ∥∆] of a you-node and every occurrence of A →B in ∆, the you-
node has a successor node of the form G  [Γ, A∥B, ∆] as well as a successor node
of the form G  [Γ∥∆]. Moreover, there is at least one occurrence of an implication
on the right hand side of some disjunct (i.e., state) of a you-node.4
4 If there is a total of n occurrences of compound formulas on the right hand sides of states in a
you-node, then it has 2n successor nodes, i.e., corresponding to 2n possible moves for you.

508
A. Ciabattoni, C.G. Ferm¨uller, and G. Metcalfe
We call a d-strategy winning (for me) if, for all leaf nodes ν and for all possible assign-
ments ⟨·⟩∗of risk values to atomic formulas, there is a disjunct [p1, . . . , pm∥q1, . . . , qn]
in ν, such that ⟨p1, . . . , pm⟩∗≥⟨q1, . . . , qn⟩∗.
In game theory a winning strategy (for me) is usually deﬁned as a function from all
possible states where I have a choice, into the set of my possible moves. Note that
winning strategies in the latter sense exist for all assignments of risk values if and only
if a winning d-strategy exists.
Strictly speaking we have only deﬁned d-strategies (and therefore, implicitly, also
strategies) with respect to some given regulation that, for each possible state, determines
who is to move next. Each consistent partition of internal nodes into I-nodes and you-
nodes corresponds to such a regulation. However, it has been (implicitly) proved by
Giles that the order of moves is irrelevant. Therefore no loss of generality is involved.
The deﬁning conditions for I-nodes and you-nodes not only correspond to possible
moves in the dialogue game, but also to the introduction rules for implication in the
hypersequent calculus for Ł deﬁned in [16]. In fact, every winning d-strategy corre-
sponds to a family of proofs in that hypersequent calculus. In order to establish a similar
relation between our uniform r-hypersequent rules and game based characterizations of
Ł, Π, and G, we start by observing that the phrase ‘betting for a positive result of (a
multiset of) experiments’ is ambiguous. As we have seen, Giles identiﬁed the combined
risk associated with such a bet with the sum of risks associated with the single experi-
ments. However, other ways of interpreting the combined risk are worth exploring. In
particular, we are interested in a second version of the game, where an elementary state
[p1, . . . , pm∥q1, . . . , qn] corresponds to my single bet that all experiments associated
with the qis (1 ≤i ≤n) show a positive result, against your single bet that all experi-
ments associated with the pis (1 ≤i ≤m) show a positive result. A third form of the
game arises if one decides to perform only one experiment for each of the two players,
where the relevant experiment is chosen by the opponent.
To achieve a direct correspondence between the three versions of the game and the
standard t-norm based semantics for Ł, Π, and G, respectively, we invert risk values
into probabilites of positive results of associated experiments. More formally, the value
of an atomic formula q is deﬁned as ⟨q⟩= 1 −⟨q⟩∗; in particular, ⟨⊥⟩= 0.
My expected gain in the elementary state [p1, . . . , pm∥q1, . . . , qn] in Giles’s game
for Ł is the sum of money that I expect you to have pay me minus the sum that I expect
to have to pay you. This amounts to m
i=1(1 −⟨pi⟩) −n
i=1(1 −⟨qi⟩) $. Therefore my
expected gain is greater or equal to zero if and only if the condition 1+m
i=1(⟨pi⟩−1) ≤
1 + n
i=1(⟨qi⟩−1) holds.
In the second version of the game, you have to pay me 1$ unless all experiments
associated with the pis test positively, and I have to pay you 1$ unless all experiments
associated with the qis test positively. My expected gain is therefore 1 −m
i=1⟨pi⟩−
(1 −n
i=1⟨qi⟩) $. The corresponding winning condition is m
i=1⟨pi⟩≤n
i=1⟨qi⟩.
To maximize the expected gain in the third version of the game I will choose a pi ∈
{p1, . . . , pm} where the probability of a positive result of the associated experiment is
least; and you will do the same for the qis that I have asserted. Therefore my expected
gain is (1−min1≤i≤m⟨pi⟩)−(1−min1≤i≤n⟨qi⟩) $. Hence the corresponding winning
condition is min1≤i≤m⟨pi⟩≤min1≤i≤n⟨qi⟩.

Uniform Rules and Dialogue Games for Fuzzy Logics
509
We thus arrive at the following deﬁnitions for the value of a multiset {p1, . . . , pn}
of atomic formulas, according to the three versions of the game:
⟨p1, . . . , pn⟩Ł = 1+
n

i=1
(⟨pi⟩−1) ⟨p1, . . . , pn⟩Π =
n

i=1
⟨pi⟩⟨p1, . . . , pn⟩G = min
1≤i≤n⟨pi⟩
For the empty multiset we deﬁne ⟨⟩Ł = ⟨⟩Π = ⟨⟩G = 1.
A disjunction of elementary states ν is now called winning according to logic L ∈{Ł,
Π, G} if for every assignment ⟨·⟩of values there is a state [p1, . . . , pm∥q1, . . . , qn] in ν
where ⟨p1, . . . , pm⟩L ≤⟨q1, . . . , qn⟩L.
It turns out that, in order to characterize Π and G, the dialogue game rule (R) has
to be augmented5 by the following additional rule:
(Q) If I have a strategy for winning the game starting in the state [A∥B], then I am not
allowed to attack your assertion of A →B. (And vice versa.)6
The trees of disjunctive states as presented in Deﬁnition 15 do not yet contain all the
information that is needed to formulate winning d-strategies for the new versions of the
game. To see what kind of information is missing, observe that rule (Q), at the meta-level,
corresponds to
– if v(A) ≤v(B), then I have to quit on your assertions of A →B, and you have to
quit on my assertions of A →B,
where v is the valuation extending the relevant assignment ⟨·⟩from atomic formulas
to arbitrary formulas. Incorporating this fact into the deﬁnition of d-strategies seems,
at ﬁrst glance, to require additional notation for conditions of the form ‘if A ≤B’.
However, we can use the fact that ‘if X then Y’ (at the classical meta-level) is equivalent
to ‘not X or Y’. Thus we remain within the notation for disjunctive states, as long as we
are willing to use also the strict inequality <, in order to be able to express ‘not A ≤B’
as ‘B < A’. Consequently, states [Γ∥∆] now come in two different forms: [Γ < ∆]
and [Γ ≤∆].
Taking into account these modiﬁcations, condition 3 of Deﬁnition 15 is replaced by
3’. Any I-node is of the form G  [A →B, Γ  ∆], where  is either ≤or ≤. It has
exactly two successor nodes: one of the form G  [Γ, B  A, ∆]  [Γ  ∆] and
one of the form G  [B < A]  [Γ  ∆].
Note that this new condition corresponds directly to the uniform logical rules (→, , l)
for r-hypersequents.
In Deﬁnition 15 conditions 3 and 4 are dual. In fact, the availabilty of both inequality
relationsallowsustoexpressthedualtoconjunctionsofdisjunctivestatesasconjunctions
of disjunctive states, by pushing negations inside and ﬁnally expressing ‘not Γ ≤∆’
as ‘∆< Γ’. After removing some redundancies, the result of this purely mechanical
dualization of condition 3’ results in a version 4’ that corresponds to rule (→, , r).
5 We could have used rule (Q) already in Giles’s original game. However, in contrast to the game
for Π and G, (Q) does not affect the existence of winning strategies for formulas valid in Ł.
6 Recall that the strategies mentioned in (Q) refer to a given assignment ⟨·⟩of values.

510
A. Ciabattoni, C.G. Ferm¨uller, and G. Metcalfe
Concluding Remark. We have presented invertible uniform logical rules for the funda-
mental t-norm based fuzzy logics Ł, G, and Π, that both provide the basis for Co-NP
decision procedures, and may be interpreted within a framework of dialogue games with
bets. However, these rules are also sound and invertible for a number of related logics.
This raises the interesting question as to which other logics can be characterized in an
analogous way. In particular we hope to ﬁnd a ﬁrst natural calculus for H´ajek’s Basic
logic BL [10], the logic characterizing all logics based on continuous t-norms.
References
1. S. Aguzzoli. Uniform description of calculi for all t-norm logics. In L. Henkin et al., editors,
Proceedings of 34th IEEE International Symposium on Multiple-Valued Logic (ISMVL’04),
pages 38–43, 2004.
2. A. Avron. Hypersequents, logical consequence and intermediate logics for concurrency.
Annals of Mathematics and Artiﬁcial Intelligence, 4(3–4):225–248, 1991.
3. A. Avron and B. Konikowska. Decomposition Proof Systems for G¨odel-Dummett Logics.
Studia Logica, 69(2):197–219, 2001.
4. M. Baaz, A. Ciabattoni, and C. Ferm¨uller. Cut-elimination in a sequents-of-relations calculus
for G¨odel logic. In International Symposium on Multiple Valued Logic (ISMVL’2001), pages
181–186. IEEE, 2001.
5. M. Baaz and C. Ferm¨uller. Analytic calculi for projective logics. In Proc. TABLEAUX ’99,
volume 1617 of LNAI, pages 36–50, 1999.
6. C. Ferm¨uller and N. Preining. A dialogue game for intuitionistic fuzzy logic based on com-
parison of degrees of truth. In Proceedings of InTech’03, 2003.
7. R. Giles. A non-classical logic for physics. Studia Logica, 4(33):399–417, 1974.
8. R. Giles. A non-classical logic for physics. In R. Wojcicki and G. Malinkowski, editors,
Selected Papers on Łukasiewicz Sentential Calculi, pages 13–51. Polish Academy of Sciences,
1977.
9. R. H¨ahnle. Automated Deduction in Multiple-Valued Logics. Oxford University Press, 1993.
10. P. H´ajek. Metamathematics of Fuzzy Logic. Kluwer, Dordrecht, 1998.
11. P. G. Jeavons, D. A. Cohen, and M. Gyssens. Closure properties of constraints. The Journal
of the ACM, 44:527–548, 1997.
12. P. Lorenzen. Logik und Agon. In Atti Congr. Internaz. di Filosoﬁa, pages 187–194. Sansoni,
1960.
13. G. Metcalfe, N. Olivetti, and D. Gabbay. Goal-directed calculi for G¨odel-Dummett logics.
In M. Baaz and J. A. Makowsky, editors, Proceedings of CSL 2003, volume 2803 of LNCS,
pages 413–426. Springer, 2003.
14. G. Metcalfe, N. Olivetti, and D. Gabbay. Analytic proof calculi for product logics. Archive
for Mathematical Logic, 43(7):859–889, 2004.
15. G. Metcalfe, N. Olivetti, and D. Gabbay. Goal-directed methods for Łukasiewicz logics. In
J. Marcinkowski and A. Tarlecki, editors, Proceedings of CSL 2004, volume 3210 of LNCS,
pages 85–99. Springer, 2004.
16. G. Metcalfe, N. Olivetti, and D. Gabbay. Sequent and hypersequent calculi for abelian and
Łukasiewicz logics. To appear in ACM TOCL, 2005.
17. A. Schrijver. Theory of Linear and Integer Programming. John Wiley and Sons, 1987.

Nonmonotonic Description Logic Programs:
Implementation and Experiments ⋆
Thomas Eiter, Giovambattista Ianni, Roman Schindlauer, and Hans Tompits
Institut f¨ur Informationssysteme, Technische Universit¨at Wien
Favoritenstraße 9-11, A-1040 Vienna, Austria
{eiter, ianni, roman, tompits}@kr.tuwien.ac.at
Abstract. The coupling of description logic reasoning systems with other rea-
soning formalisms (possibly over the Web) is becoming an important research
issue and calls for advanced methods and algorithms. Recently, several notions
of description logic programs have been introduced, combining rule-based se-
mantics with description logics. Among them are nonmonotonic description logic
programs (or dl-programs for short) which combine nonmonotonic logic pro-
grams with description logics under a generalized version of the answer-set and
the well-founded semantics, respectively, which are the predominant semantics
for nonmonotonic logic programs. In this paper, we consider some technical issues
regarding an efﬁcient implementation for both semantics, which has been realized
in a working prototype exploiting the two state-of-art tools DLV and RACER. A
major issue in this respect is efﬁcient interfacing between the two reasoning sys-
tems at hand, for which we devised special methods. Such methods may fruitfully
be used for the implementation of systems of similar nature. Reported experimen-
tation activities with our prototype show that the methods we have developed are
effective and are a key for highly optimized nonmonotonic dl-program engines.
1
Introduction
Descriptionlogicsarewell-knownformalismsfordescribingontologicalknowledge,and
play an important role for building the Semantic Web [3,4,9]. The latter is conceived as a
hierarchy of different layers, of which the Ontology Layer is currently the highest layer
of sufﬁcient maturity, as evidenced by the W3C recommended Web Ontology Language
(OWL) [21,13]. OWL has three increasingly expressive sublanguages, namely OWL Lite,
OWL DL, and OWL Full. As shown in [12], the logical underpinnings of the former two
is provided by the description logics SHIF(D) and SHOIN(D), respectively.
The further steps in the development of the Semantic Web are realizing the Rules,
Logic, and Proof Layers on top of the Ontology layer, which should offer sophisti-
cated representation and reasoning capabilities. This requests, in particular, the need to
integrate the Rules and the Ontology layer.
Towards this goal, several approaches for combining description logics with rule-
based languages have been proposed recently [5,16,17,1,6,7,22]. Among them are de-
scription logic programs, or dl-programs for short, presented in [6,7] as a novel method
⋆This work was partially supported by the Austrian Science Fund under grant P17212-N04, and
by the European Commission through the IST REWERSE Network of Excellence (IST-506779)
and the IST Working Group in Answer Set Programming (IST 2001-37004 WASP).
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 511–527, 2005.
c⃝Springer-Verlag Berlin Heidelberg 2005

512
T. Eiter et al.
to couple description logics with nonmonotonic logic programs. Roughly speaking, a
dl-program consists of a knowledge base L in a description logic and a ﬁnite set P of
generalized logic-program rules, called dl-rules. These are similar to usual rules in logic
programs with negation as failure, but they may also contain queries to L in their bodies.
Importantly, such queries also allow for specifying an input from P to L, and thus for
a bidirectional ﬂow of information between P and L. Consequently, dl-programs allow
for building rules on top of ontologies, but also, to some extent, building ontologies on
top of rules.
By virtue of their design, dl-programs fully support encapsulation and privacy of the
description logic knowledge base, in the sense that logic programming and description
logic inference are technically separated and only interfacing details need to be known.
The description-logic knowledge bases in dl-programs are theories in the description
logics SHIF(D) and SHOIN(D). However, the framework can be easily extended
to other description logics as well.
Two basic types of semantics have been deﬁned for dl-programs: in [6], a gener-
alization of the answer-set semantics [10] for ordinary logic programs is given, and
in [7], a generalization of the well-founded semantics [19,2]. In fact, two versions of the
answer-set semantics for dl-programs are introduced in [6], namely the weak answer-
set semantics and the strong answer-set semantics. Every strong answer set is also a
weak answer set, but not vice versa. The two notions differ in the way they deal with
nonmonotonic dl-queries. We recall that the answer-set semantics and the well-founded
semantics are the two predominant semantics for nonmonotonic logic programs.
In this paper, we consider technical issues regarding an efﬁcient implementation
of the answer-set and the well-founded semantics for dl-programs, which has been
realized in a working prototype exploiting the two state-of-the-art solvers DLV [15] and
RACER [11]. A major issue in this respect is an efﬁcient interfacing between the two
reasoning systems at hand, for which we devised special methods.
The main contributions of this paper can be summarized as follows:
– We give novel methods and algorithms for computing answer sets and the well-
founded semantics of dl-programs. Starting from a simple guess-and-check algo-
rithm for weak answer sets, we devise more efﬁcient techniques which prune the
number of guesses and reduce the effort for dl-query evaluation.
– As a ﬁrst improvement over the naive guess-and-check method, we discuss the case
of stratiﬁed dl-programs, which, as follows from one of our results, can be evaluated
without explicitly using or even knowing some stratiﬁcation, at the ground or non-
ground level, with a standard answer-set solver.
– We devise special optimization techniques in order to avoid redundant computa-
tions. To wit, we discuss a method to avoid multiple ground program generation,
as well as special methods to reduce the number of calls to the description logic
engine. The latter techniques involve, on the one hand, an exploitation of function
calls to the description logic reasoner using non-ground queries, and, on the other
hand, special caching data structures tailored for fast access to previous query calls.
Also, hierarchic structures of the dependency graph can be taken into account for
evaluating unstratiﬁed dl-programs.
– The well-founded semantics is computed through an iterative procedure in terms
of the greatest and the least ﬁxpoint of a monotonic operator. Techniques devised
for the answer-set semantics can be fruitfully applied here as well for improving

Nonmonotonic Description Logic Programs
513
the evaluation. Moreover, the computation of answer sets can be optimized with the
help of a prior computation of the well-founded semantics, by introducing suitable
constraints.
– We implemented the above algorithms and optimization techniques in a working
prototype, both for computing the answer-set semantics as well as the well-founded
semantics, and performed experiments on a suite of benchmark problems. Our ex-
perimental results show that the optimization techniques can drastically improve the
performance of dl-programs over incremental grades of optimization.
Note that most of our methods and results are at an abstract level, and thus may also
be exploited for implementing similar computational-logic systems based on coupling.
2
Background
In this section, we recall syntax and semantics of description logic programs, introduced
in [6,7]. In what follows, we assume a function-free ﬁrst-order vocabulary, Φ, with
nonempty ﬁnite sets of constant and predicate symbols, and a set X of variables. As
usual, a classical literal (or literal), l, is an atom a or a negated atom ¬a.
2.1
SHIF(D) and SHOIN (D)
Intuitively, description logics allow for expressing knowledge about concepts, roles, and
individuals in a (possibly extended) ﬁrst-order logic (with concepts and roles being unary
and binary predicates C(a) and R(a, b), respectively) using a special syntax. Since for
the purpose of this paper we mainly interface description logics through queries, we
omit deﬁnitions of SHIF(D) and SHOIN(D) at this point and refer to Appendix A
(or, alternatively, to [12,6]) for more details.
A (SHIF(D) resp. SHOIN(D)) description logic knowledge base L is a ﬁnite
set of axioms in the respective description logic. We denote logical consequence of an
axiom α from L, which is deﬁned as usual, by L |= α.
2.2
Description Logic Programs
Informally, a description logic program consists of a description logic knowledge base L
and a generalized normal program P which may contain queries to L. Roughly, in such
a query, it is asked whether a certain description logic axiom or its negation logically
follows from L or not. For details, we refer to [6,7].
Syntax. We ﬁrst deﬁne dl-queries and dl-atoms, which are used to access the description
logic knowledge base. A dl-query, Q(t), is either (a) a concept inclusion axiom C ⊑D
or its negation ¬(C ⊑D), or (b) of the form C(t) or ¬C(t), where C is a concept
and t is a term, or (c) of the form R(t1, t2) or ¬R(t1, t2), where R is a role and t1,
t2 are terms.1
1 Note that SHOIN(D) does not provide terminological role negation; we use the expression
¬(∃R.{b})(a) in order to add and query ¬R(a, b) for a speciﬁc pair of individuals.

514
T. Eiter et al.
A dl-atom has the form
DL[S1op1p1, . . . , Smopm pm; Q](t) ,
m ≥0,
(1)
where each Si is either a concept or a role, opi ∈{⊎, −∪, −∩}, pi is a unary resp. binary
predicate symbol, and Q(t) is a dl-query. We call p1, . . . , pm its input predicate symbols.
Intuitively,opi = ⊎(resp.,opi = −∪)increasesSi (resp.,¬Si)bytheextensionofpi,while
opi = −∩constrains Si to pi.
Example 21 The dl-atom DL[buying ⊎buy cand, buying ⊎contract; Discount](V )
queries for all individuals of the concept Discount after adding the extensions of both
buy cand and contract to the role buying.
A dl-rule, r, is an expression of the form,
a ←b1, . . . , bk, not bk+1, . . . , not bm , m ≥k ≥0 ,
(2)
where a is a literal and b1, . . . , bm are either literals or dl-atoms. The symbol “not”
stands for weak negation, also called negation as failure (NAF). We refer to a as the
head of r, denoted H(r), and to the part right of “←” as the body of r. Its positive
part is b1, . . . , bk, and its negative part is not bk+1, . . . , not bm. Furthermore, we deﬁne
B(r) = B+(r) ∪B−(r), where B+(r) = {b1, . . . , bk} and B−(r) = {bk+1, . . . , bm}.
A dl-rule is ordinary, if it contains no dl-atom. An ordinary program is a ﬁnite set
of ordinary rules. A description logic program, or dl-program, KB = (L, P), consists
of a description logic knowledge base L and a ﬁnite set of dl-rules P.
Semantics. We ﬁrst recapitulate the strong and weak answer-set semantics for dl-pro-
grams [6], and then the well-founded semantics for dl-programs [7]. They generalize
the familiar answer-set semantics [10] and well-founded semantics [19] for ordinary
programs, respectively, which are the predominant semantics for nonmonotonic logic
programs.
We need some auxiliary notions. In what follows, let KB = (L, P) be a dl-program.
TheHerbrandbaseof P, denotedHB P , is theset of all groundliterals withastandard
predicate symbol that occurs in P and constant symbols in Φ, where Φ is assumed to
contain (a subset of) the constant symbols from L. An interpretation I relative to P is a
consistent subset of HBP . Such an I is a model of l ∈HBP under L, denoted I |=L l, iff
l ∈I, and a model of a ground dl-atom a = DL[S1op1 p1, . . . , Smopmpm; Q](c) under
L, denoted I |=L a, iff L ∪m
i=1 Ai(I) |= Q(c), where
– Ai(I) = {Si(e) | pi(e) ∈I}, for opi = ⊎,
– Ai(I) = {¬Si(e) | pi(e) ∈I}, for opi = −∪, and
– Ai(I) = {¬Si(e) | pi(e) ∈I does not hold}, for opi = −∩.
I is a model of a ground dl-rule r iff I |=L H(r) whenever both I |=L l for all
l ∈B+(r) and I ̸|=L l for all l ∈B−(r). I is a model of a dl-program KB = (L, P), or I
satisﬁes KB, denoted I |= KB, iff I |=L r for all r in the grounding, grd(P), of P. We
say that KB is satisﬁable if it has some model, otherwise KB is unsatisﬁable.
A ground dl-atom a is monotonic relative to KB = (L, P), providing I |=L a implies
I′ |=L a, for I ⊆I′ ⊆HBP . A dl-program KB = (L, P) is positive, if (i) P is not-free
and (ii) every ground dl-atom occurring in grd(P) is monotonic relative to KB.

Nonmonotonic Description Logic Programs
515
Observe that while dl-atoms containing only ⊎and −∪are always monotonic, a dl-
atom containing −∩may fail to be monotonic, since an increasing set of pi(e) in P results
in a reduction of ¬Si(e) in L.
We are now in the position to deﬁne the answer-set semantics for dl-programs.
For any dl-program KB = (L, P), we denote by DLP the set of all ground dl-atoms
that occur in ground(P). We assume in the following that KB has an associated set
DL+
P ⊆DLP of ground dl-atoms which are known to be monotonic, and we denote by
DL?
P = DLP −DL+
P the set of all other dl-atoms. An input literal of a ∈DLP is a ground
literal with an input predicate of a and constant symbols in Φ.
Strong answer sets. The strong dl-transform of P relative to L and an interpreta-
tion I ⊆HBP , denoted sP I
L, is the set of all dl-rules obtained from its grounding
grd(P) with respect to Φ by (i) deleting every dl-rule r such that either I ̸|=L a for some
a ∈B+(r) ∩DL?
P , or I |=L l for some l ∈B−(r), and (ii) deleting from each remaining
dl-rule r all literals in B−(r) ∪(B+(r) ∩DL?
P ).
Notice that (L, sP I
L) is a positive dl-program, which, as shown in [6], has a least
model if it is satisﬁable. We call I ⊆HBP a strong answer set of KB iff it is the least
model of (L, sP I
L).
Weak answer sets. Weak answer sets are like strong answer sets if monotonicity of all
dl-atoms is unknown resp. ignored (i.e., technically, if DL?
P = DLP ). In the respective
weak dl-transform, wP I
L, of P relative to L and I ⊆HBP , all dl-atoms are removed
from grd(P). A weak answer set of KB, then, is an interpretation I ⊆HBP such that
I is the least model of the ordinary positive program wP I
L. Note that strong answer sets
of KB are weak answer sets of KB, but not vice versa in general.
For any not-free dl-program P, both the strong reduct as well as the weak reduct
coincide with the usual Gelfond-Lifschitz reduct [10], and thus the strong and weak
answer sets of KB = (L, P) coincide with the standard answer sets of P.
Well-founded Semantics (WFS). The WFS is deﬁned in [7] for dl-programs KB without
classical negation and where all dl-atoms are monotonic. The former is no real restriction
but the latter a technical necessity. In practice, most dl-atoms are monotonic.
The WFS in [7] generalizes the classical WFS [19] by suitably generalizing the
notion of an unfounded set as in [19] to the setting of dl-atoms as follows. Let, for
any set S of literals, ¬.S be the set of the opposite literals of S. A set U ⊆HBP is an
unfounded set of KB = (L, P) relative to a consistent set I of ground literals, if for every
a ∈U and every r ∈grd(P) with H(r) = a, either (i) ¬b ∈I ∪¬.U for some ordinary
atom b ∈B+(r), or (ii) b ∈I for some ordinary atom b ∈B−(r), or (iii) for some dl-atom
b ∈B+(r), S+̸|=Lb for every consistent set S of ground literals with I ∪¬.U ⊆S, or
(iv) I+|=Lb for some dl-atom b ∈B−(r).
Compared to [19], Conditions (iii) and (iv) are novel. The WFS is then deﬁned in [7]
like in [19] as the least ﬁxpoint of a monotonic operator WKB(I) (this is feasible since
the greatest unfounded set of I always exists); for computation purposes, an alternative
characterization, discussed in Section 3.6, is more advantageous.
If P does not contain any dl-atoms, then the well-founded semantics for KB =
(L, P) coincides with the well-founded semantics for P in the sense of [19].

516
T. Eiter et al.
Stratiﬁed Semantics. The notion of stratiﬁcation for dl-programs [6] is similar as for
ordinary programs. Roughly speaking, stratiﬁed dl-programs are composed of hierarchic
layers of positive dl-programs that are linked via default negation (for a formal deﬁnition,
we refer the reader to [6]). As discussed in [7], if KB = (L, P) is positive or stratiﬁed,
then it has a single strong answer set, which coincides with WFS(KB) ∩HBP .
Example 22 A computer shop obtains its hardware from several vendors. It uses a
knowledge base L1 (see Appendix B), which contains information about the product
range that is provided by each vendor (property provides) and about possible rebate
conditions (concept Discount, depending on property buying; here we assume that
buying two or more parts from the same seller causes a discount). To evaluate possible
combinations of purchases, the following program P1 is speciﬁed:
(1)
vendor(s1); vendor(s5); vendor(s9);
(2)
needed(cpu); needed(harddisk); needed(case);
(3)
contract(s9, case);
(4)
avoid(V ) ←vendor(V ), not rebate(V );
(5)
rebate(V ) ←vendor(V ), DL[buying ⊎buy cand, buying ⊎contract; Discount](V );
(6)
buy cand(V, P) ←vendor(V ), not avoid(V ), DL[provides](V, P), needed(P),
not exclude(P)
(7)
exclude(P) ←buy cand(V1, P), buy cand(V2, P), V1 ̸= V2;
(8)
exclude(P) ←contract(V, P), needed(P);
(9)
supplied(V, P) ←DL[buying ⊎buy cand, buying ⊎contract; buying](V, P),
needed(P).
Rules (1)–(3) state the considered vendors as well as the needed parts; for some parts,
a vendor may already be contracted as supplier. Rules (4)–(6) choose a possible vendor
(buy cand) for each needed part, taking into account that the selection might affect
the rebate condition (by feeding the possible vendor back to L1, where the discount
is determined). Rules (7) and (8) assure that each hardware part is bought only once,
considering that for some parts a supplier might already be chosen. Rule (9) eventually
summarizes all purchasing results. Evaluating this program under the strong answer-set
semantics yields the following answer sets (quoting only the relevant atoms):
{supplied(s9, case); supplied(s5, cpu); supplied(s5, harddisk); rebate(s5); . . . };
{supplied(s9, case); supplied(s9, harddisk); rebate(s9); . . . };
{supplied(s9, case); . . . }.
For more details, discussion, and examples, see [6,7].
3
Implementing dl-Programs
In this section, we consider methods for computing dl-programs by using an answer-set
solver on the one hand and a description logic (DL) engine on the other. We start with a
simple method, and then present progressively methods to increase the efﬁciency.

Nonmonotonic Description Logic Programs
517
3.1
Naive Computation of Weak Answer Sets
The computation of the weak answer sets of a given dl-program KB = (L, P) can
be encoded by ordinary logic programs under the answer-set semantics, following a
generate and test approach, as follows:
1. Let Pd be the ordinary logic program having each dl-atom a(t) occurring in P
replaced by the atom da(t) (we call this kind of atoms replacement atoms), where
da is a fresh predicate symbol.
2. Add to Pd from Step 1 for each replacement atom da(t) all rules
da(c) ←not ¬da(c)
and
¬da(c) ←not da(c)
(3)
such that a(c) is a ground instance of dl-atom a(t). Intuitively, the rules (3) “guess”
the truth values of the dl-atoms of P.2 Denote the resulting program by Pguess.
3. Compute the answer sets Ans = {M1, . . . , Mn} of Pguess.
4. For each answer set M ∈Ans of Pguess, test whether the original “guess” of the
value of da(c) is compliant with L. That is, for each dl-atom a of form (1), check
whether da(c) ∈M iff M |=L a, i.e., L ∪m
i=1 Ai(M) |= Q(c). If this condition
holds (and only if), then M ∩HBP is a weak answer set of P.
If only one answer set is desired, the algorithm may stop after the ﬁrst one is found.
While simple and elegant, this method becomes quickly infeasible. If the number
of ground dl-atoms grows, the number of candidate answer sets generated may become
very large, and Ans may occupy a lot of space. It is more efﬁcient to interleave Steps 3
and 4 and to test each candidate answer set Mi immediately upon its generation. Still, a
lot of effort may be spent for evaluating dl-atoms. Efﬁcient implementations try to prune
the number of guesses, and to reduce the effort for dl-atom evaluation.
3.2
Stratiﬁed dl-Programs
In case of a stratiﬁed dl-program KB = (L, P), the guessing of the outcome of dl-atoms
can be avoided entirely. In the presence of monotonic dl-atoms only, a simple method
for computing the (unique) strong answer set of KB is given by a ﬁxpoint iteration of
the operator ΛKB : 2HBP →2HBP , deﬁned by ΛKB(I) = M(Pd ∪DP (I)) ∩HBP ,
where:
– Pd is as in Step 1 of the naive computation above;
– DP (I) is the set of all facts da(c) ←such that I |=L a(c); and
– M(Pd ∪DP (I)) is the single answer set of Pd ∪DP (I); since Pd is stratiﬁed, this
answer set is guaranteed to exist and to be unique.
For the sequence of powers I0
KB = ∅, Ii+1
KB = Λi+1
KB (∅) = ΛKB(Ii
KB), i ≥0, we
then have:
Lemma 1. For each stratiﬁed KB, the sequence Ii
KB, i ≥0, converges, and its limit
I∞
KB coincides with the strong answer set of KB.
2 Note that, when using the system DLV, rules (3) can equivalently be replaced by the disjunctive
facts da(c) ∨¬da(c) ←.

518
T. Eiter et al.
Notice that ΛKB is neither monotonic nor anti-monotonic, and that the sequence
Ii
KB, i ≥0, is not a chain. The proof of convergence is along a stratiﬁcation.
In view of this lemma, we can evaluate a stratiﬁed dl-program very easily without
explicitly using or even knowing some stratiﬁcation, at the ground or non-ground level,
with a standard answer-set solver (which is used to compute M(Pd ∪DP (I)) and
multiple calls to a DL reasoner (for deciding I |=L a(c) when it is needed to add facts
da(c) to DP (I)), in a simple loop.
In fact, the above method is applicable beyond stratiﬁed dl-programs. Let us call
a program P dl-stratiﬁed, if in the usual dependency graph G of grd(Pd ∪DLI (P)),
where DLI (P) consists of all rules da(X) ←pi(Y), i ∈{1, . . . , m}, for each dl-atom
a of form (1) occurring in P, no replacement atom da(c) is reachable from a cycle
having negative arcs.
The class of dl-stratiﬁed dl-programs is still rich in the sense that it features nondeter-
minism for problem solving, where ontologies can be accessed in portions of the program
that computes information in a stratiﬁed layer (possibly through positive recursion, e.g.,
by taking transitive closure).
Let us call an answer-set solver deterministic, if it returns for any input program
P on each call always the same result; i.e., if multiple answer sets exist, a “canonical”
answer set can(P) will be output. Then the following holds:
Proposition 1. Given a deterministic answer-set solver, for each dl-stratiﬁed KB, the
sequence Ii
KB, i ≥0, (where can(Pd(I)) replaces M(Pd(I)) in ΛKB) converges, and
its limit I∞
KB is a strong answer set of KB.
Since in dl-stratiﬁed programs terminological knowledge is involved only in a strati-
ﬁed portion of the program, it can be dealt with a quick preprocessing (cf. Section 3.5) by
easy means. We thus can solve a very relevant class of unstratiﬁed dl-programs through
the above technique.
Intuitively, assuming the given program has a stratiﬁcation λ = {KB0, . . . , KBn}, a
disadvantage of this simple method is the effort spent for evaluating dl-atoms in higher
levels KBi of the stratiﬁcation in the early stages of the ﬁxpoint iteration, where the
input from lower levels has not converged yet. This effort can be saved by proceeding
along λ and computing ΛKB0, . . . , ΛKBn, for the associated strata KB0, . . . KBn, at
the cost of pre-computing λ. This may pay off in general, given that the entailment to
dl-atoms is costly.
Furthermore, it turns out that both the answer-set solver and the DL engine are
invoked repeatedly, so that it is very important to avoid redundant computations. Thus,
two more additional optimization techniques are fruitful, namely ground program re-
using, and dl-atom caching and intelligent evaluation, discussed next.
3.3
Avoiding Multiple Ground Program Generation
The above method relies on the evaluation of a collection of ordinary logic programs
Pd ∪D(Ij
KB) starting from I0
KB = ∅. The programs of this sequence are very similar:
indeed, for any Ij
KB and Ij′
KB, the programs Pd ∪D(Ij
KB) and Pd ∪D(Ij′
KB) differ only
in the set of facts da(c) such that Ij
KB |=L a(c) is different from Ij′
KB |=L a(c), and so,
their ground versions are very similar.

Nonmonotonic Description Logic Programs
519
Indeed, it is possible to compute and store grd(Pd) only once, and then, for any
interpretation I, compute M(grd(Pd) ∪D(I)) whenever necessary.
This method can be enhanced by considering that answer-set programming systems,
like DLV, allow to obtain signiﬁcantly smaller versions of ground programs, where only
meaningful rules are kept; in particular, such grounding systems compute only those
ground rules which can be grounded not with respect to the whole Herbrand base HBP
but with respect to a notion of “active" domain of the rules (for more technical details,
see [8]). Let ogrd(P) denote the optimized ground version of a program P. For space
reasons, we cannot describe this operator in detail, but we observe that, in general, for a
given I, ogrd(Pd ∪D(I)) ̸= ogrd(Pd) ∪ogrd(D(I)), whereas for the usual grounding
of Pd ∪D(I) with respect to Φ it holds that grd(Pd ∪D(I)) = grd(Pd) ∪grd(D(I)).
This latter property prevents, in principle, to have any beneﬁt in computing and
storing ogrd(Pd) instead of grd(Pd). Nonetheless, we can prove that there exists an
optimized version ogrd ∗(Pd) of grd(Pd), such that it holds that M(ogrd ∗(Pd)∪D(I)) =
M(grd(Pd)∪D(I)), for each I, and ogrd∗(Pd) ⊆grd(Pd). Details of this optimization
technique are somehow intricate, so we give only an intuition on how it is carried out
for not-free programs.
Given a rule r ∈Pd, we consider a replacement atom da(t) safe, if each variable
X ∈t appears at least once in some non-replacement atom in the body of r. The program
ogrd∗(Pd) is obtained as follows:
1. Build a program P ′
d from Pd by removing from every rule r ∈Pd each replacement
atom da(t). In case this atom is not safe, we add in the body of r a predicate dom(X)
for each variable X ∈t witnessing unsafety. Furthermore, we add to P ′
d a rule r′
with head da(t) and body consisting of the ordinary body atoms of r, plus an atom
dom(X) for each variable X ∈t.
2. Add to P ′
d a fact dom(a) ←for each a ∈HBP .
3. Let ¯D be the set {da(c) ←|da(c) ∈M(P ′
d)}.3
4. Deﬁne ogrd∗(Pd) = ogrd(Pd ∪¯D) −¯D.
Intuitively, in Step 1, we create an envelope for the least model of Pd ∪D(I) on the
original predicates, which then allows to limit the set of ground dl-atoms a(c), potentially
relevant for evaluating P, to those such that da(c) is true in the least model of P ′
d. For
programs with not, we can proceed similarly discarding in Step 1 all not literals.
3.4
Efﬁcient dl-Atom Evaluation and Caching
Since the calls to the DL reasoner are a bottleneck in the coupling of an ASP solver with
a DL engine, special methods need to be devised in order to save on the number of calls
to the DL engine. To this end, we use complementary techniques.
DL-Function Calls. One of the features of DL reasoners which may be fruitfully ex-
ploited for speed up are non-ground queries. RACER provides the possibility to retrieve
in a function call all instances of a concept C (resp., of a role R) that are provable in
the DL knowledge base. Given that the cost for accessing the DL reasoner is high, in
3 In order to prevent DLV from optimized unfolding cancelling out signiﬁcant rules, some other
specialized rules are added.

520
T. Eiter et al.
the case when several different ground instances a(c1), a(c2), . . . , a(ck) of the dl-atom
a(t) have be evaluated, it is a reasonable strategy to retrieve at once, using the apposite
function call feature from the DL reasoner, all instances of the concept C (resp., a role
R) in a(t) = DL[S1op1p1, . . . ; C](t). This allows to avoid issuing k separate calls for
the single ground atoms a(c1), . . . , a(ck).
If the retrieval set has presumably many more than k elements, we can ﬁlter it with
respect to c1, . . . , ck, by pushing these instances to a DL engine as follows. For the
query concept C, we add in L axioms to the effect that C′′ = C ⊓C′, where C′ and C′′
are fresh concept names, and axioms C′(c1), . . . , C′(ck); then we ask for all instances
of C′′. For roles, a similar yet more involved approximation method is introduced, given
that SHIF(D) and SHOIN(D) do not offer role intersection.
With the above techniques, the number of calls to the DL reasoner can be greatly
reduced. Another very useful technique to achieve this goal is caching.
DL-Caching. Whatever semantics is considered, a number of calls will be made to
the DL engine. Therefore, it is is very important to avoid an unnecessary ﬂow of data
between the two engines, and to save time when a redundant DL query has to be made.
In order to achieve these objectives, it is important to introduce some special caching
data structures tailored for fast access to previous query calls. Such a caching system
needs to deal with the case of Boolean as well as non-Boolean DL-calls.
For any dl-atom DL[λ; Q](t), where λ is a list S1op1p1, . . . , Snopnpn, and inter-
pretation I, let us denote by Iλ the projection of I on p1, . . . , pn.
Boolean DL-calls. In this case, an external call must be issued in order to verify whether
a given ground dl-atom b fulﬁlls I |=L b, where I is the current interpretation and L
is the DL knowledge base hosted by the DL engine. In this setting, the caching system
exploits properties of monotonic dl-atoms a = DL[λ; Q](c).
Given two interpretations I1 and I2 such that I1 ⊆I2, monotonicity of a implies
that (i) if I1 |=L a then I2 |=L a, and (ii) if I2 ̸|=L a then I1 ̸|=L a. This property
allows to set up a caching machinery where only the outcome for ground dl-atoms with
minimal/maximal input is stored.
Roughly speaking, for each monotonic ground dl-atom a we store a set cache(a)
of pairs ⟨Iλ, o⟩, where o ∈{true, undeﬁned}. If ⟨Iλ, true⟩∈cache(a), then we can
conclude that J |=L a for each J such that Iλ ⊆Jλ. Dually, if ⟨Iλ, undeﬁned⟩∈
cache(a), we can conclude that J ̸|=L a for each J such that Iλ ⊇Jλ.
We sketch the maintenance strategy for cache(a) in the following. The rationale is
to cache minimal (resp., maximal) input sets Iλ for which a is evaluated to true (resp.,
undeﬁned) in past external calls.
Suppose a ground dl-atom a = DL[λ; Q](c), an interpretation I, and a cache set
cache(a) are given. With a small abuse of notation, let I(a) be a function whose value is
true iff I |=L a and undeﬁned otherwise. In order to check whether I |=L a, cache(a)
is consulted and updated as follows:
1. Check whether cache(a) contains some ⟨J, o⟩such that J ⊆Iλ if o = true, or
J ⊇Iλ if o = undeﬁned. If such J exists, conclude that I(a) = o.
2. If no such J exists, then decide I |=L a through the external DL engine. If I |=L a,
then add ⟨Iλ, true⟩to cache(a), and remove from it each pair ⟨J, true⟩such that

Nonmonotonic Description Logic Programs
521
Iλ ⊂J. Otherwise (i.e., if I ̸|=L a) add ⟨Iλ, undeﬁned⟩to cache(a) and remove
from it each pair ⟨J, undeﬁned⟩such that Iλ ⊃J.
Some other implementational issues are worth mentioning. First of all, since the
subsumption test between sets of atoms is a critical task, some optimization is made in
order to improve cache look-up. For instance, an element count is stored for each atom
set, in order to prove early that I ̸⊆J whenever |I| > |J|. More intelligent strategies
could be envisaged in this respect. Furthermore, a standard least recently used (LRU)
algorithm has been introduced in order to keep a ﬁxed cache size.
Non-Boolean DL-calls. In most cases, a single non-ground query for retrieving all
instancesofaconceptorrolemightbeemployed.Cachingofsuchqueriesisalsopossible,
but cache look-up cannot take advantage of monotonicity as in the Boolean case. For
each non-ground dl-atom a = DL[λ; Q](c), a set cache(a) of pairs ⟨Iλ, a↓(Iλ)⟩is
maintained, where a↓(I) is the set of all ground instances a′ of a such that I |=L a′.
Whenever for some interpretation I, a↓(I) is needed, then cache(a) is looked up for
some pair ⟨J, a↓(J)⟩such that Iλ = J.
3.5
Unstratiﬁed dl-Programs
When looking at the corresponding dependency graph, it often occurs in practice that
answer-set programs are structured in three separate and hierarchic layers:
– a ﬁrst, stratiﬁed layer at the bottom which performs some preprocessing on the input
data;
– a second, strongly connected and unstratiﬁed layer, usually aimed at encoding some
nondeterministic choice, and, eventually,
– a third “checking” layer on top, where values computed through the other layers are
ﬁltered with respect to some constraint criteria.
Following this common setting, we conceived an evaluation strategy where each
component is evaluated sequentially and results are fed from one layer to another. This
way, the bottom layer is computed exploiting techniques from Subsection 3.2. General
techniques are strictly limited to situations in which this cannot be avoided, as in non-
stratiﬁed layers.
3.6
Implementing the Well-Founded Semantics
An implementation of WFS for KB by ﬁxpoint iteration of the deﬁning monotonic
operator WKB(I) as in [7] is not attractive, since a polynomial-time algorithm for com-
puting the greatest unfounded set of KB with respect to I, due to Condition (iii) of an
unfounded set, is not evident (even if deciding I |=L l is polynomial).
As shown in [7], the WFS for KB, denoted WFS(KB), is alternatively given by
WFS(KB) = lfp(γ2
KB) ∪{¬a | a ∈HBP −gfp(γ2
KB)},
where the operator γKB(I) assigns each interpretation I ⊆HBP the least model MKBI
of the strong reduct KBI = (L, sP I
L). Since γKB is anti-monotonic, γ2
KB is monotonic
and thus has a least and greatest ﬁxpoint, lfp(γ2
KB) and gfp(γ2
KB), respectively.

522
T. Eiter et al.
This way, WFS(KB) is computable through a ﬁxpoint iteration which computes
and outputs the greatest and the least ﬁxpoint of the γ2
KB operator, starting from ∅
resp. HBP (which may be represented by its complement). Since KBI is a positive
dl-program, machinery developed in Section 3.2 for computing MKBI is very helpful
in this respect. Caching also proves to be very fruitful.
3.7
Enhancing Answer-Set Generation with Well-Founded Semantics
Another interesting result from [7] allows to speed up the computation of the answer
sets of a given KB = (P, L) by means of a pre-evaluation of WFS(KB):
Theorem 31 Every strong answer set of a dl-program KB = (L, P) includes lfp(γ2
KB)
and no atom a ∈HBP −gfp(γ2
KB).
For computing answer sets, we can exploit the possibility to introduce constraints
to a DLV program [15]. Constraints allow to ﬁlter out models which do not fulﬁll
prescribed requirements. An intermediate ordinary program P ′ obtained from P can be
then enriched with the constraint ←not a for any atom a such that a ∈WFS(KB),
and with a constraint ←a for any atom a such that ¬a ∈WFS(KB). Notice that such
constraints may also be added only for a subset of WFS(KB) (e.g., the one obtained after
some steps in the least resp. greatest ﬁxpoint iteration of γ2
KB). This technique proves to
be useful for helping the answer-set programming solver to converge to solutions faster.
4
System Prototype
The architecture of our system prototype is depicted in Figure 1. The system comprises
six modules: the two external engines DLV and RACER, the latter embedded into a
caching module, a WFS module, an answer-set semantics module, as well as a prepro-
cessing and a postprocessing module. Each internal module is coded in the PHP scripting
language; the overhead is insigniﬁcant, provided that most of the computing power is
devoted to the execution of the two external reasoners.
Our prototypical implementation is capable of evaluating a dl-program in three dif-
ferent modes: (1) under answer-set semantics, (2) under WFS, and (3) under answer-set
semantics with preliminary computation of the WFS.
In Mode (1), the answer-set semantics is computed through a preprocessing step,
aimed at computing all those dl-atoms which do not depend from the program P itself.
Then, an ordinary program Pd is generated whose models M1, . . . , Mn are checked and
ﬁltered through several consistency checks performed by querying the RACER engine
in an interleaved fashion. The stratiﬁed bottom portion of Pd is evaluated iteratively as
in Subsection 3.2. Eventually, the system outputs a list of answer sets Mk1, . . . , Mkm.
In Mode (2), we compute the well-founded semantics of a program P by generating
a corresponding ordinary program Pd which is grounded using the grounding module of
the DLV system. This instantiation grd(Pd) is fed back to the well-founded semantics
module, where an iterative algorithm, calling the RACER engine several times, is carried
out in order to compute the well-founded semantics of P.
In Mode (3), the answer-set semantics is computed by taking advantage of the WFS
which is combined with Pd in order to get a better constrained program, as described in
Section 3.7.

Nonmonotonic Description Logic Programs
523
WFS
Module
WFS
Module
Post-proc.
Module
Post-proc.
Module
ASP
Module
ASP
Module
DLV
DLV
DLV
Pre-proc.
module
Pre-proc.
module
Caching
System
Racer
Caching
System
Racer
Caching
System
Racer
P
P’’ + M
P’ + M’
{M1 … Mn}
{Mk1 … Mkm}
M
{Mk1 … Mkm}
or M
ground(P’)
P’
M1 … Mn
P’’
DL Answer
DL query
DL query
DL Answer
Fig. 1. System architecture of the dl-program evaluation prototype
5
Experiments
As mentioned in the previous section, we decided to exploit the scripting language PHP.
Clearly, the speed and grade of optimization of PHP applications cannot be compared
to ones natively compiled in a high-level programming language; however, during the
development of our prototype, we realized that the major bottlenecks are the external rea-
soning applications. Thus, our benchmarks already show signiﬁcant results with respect
to different methods of integrating the external reasoners.
RACER’s restriction of not allowing reasoning with nominals in concept deﬁnitions
as well as its slow performance on large knowledge bases seriously limited the ability
of performing realistic assertional knowledge reasoning tests with existing ontologies
(e.g., the OWL wine ontology from [20]). For this reason, we decided to carry out the
benchmarks with abstract, but well-scalable graph examples in addition to the already
presented computer shop application.
The benchmarks were carried out on an AMD Athlon 1.2GHz CPU with 256MB
RAM. We used the ofﬁcial DLV version of May 23th, 2004, and RACER version 1.7.23.
Positive Programs. In order to assess our evaluation strategy for positive dl-programs,
we considered the computation of the transitive closure of a graph. We evaluated ﬁve
graphs (taken from [18]) of different size with two different dl-programs, KBLP =
(L2, P2) and KBONT = (L3, P3), where:
L2 = {arc(1, 2); arc(1, 4); . . .};
P2 = {tc(X, Y ) ←DL[arc ⊎tc; arc](X, Y ); tc(X, Y ) ←DL[arc](X, Z), tc(Z, Y )};
L3 = L2 ∪Trans(arc);
P3 = {tc(X, Y ) ←DL[arc](X, Y )}.
Here, Trans(arc) denotes the DL transitivity axiom. Figure 2 shows the results
against a logarithmic time scale. We display total evaluation times for KBONT and
KBLP as well as the respective time needed for querying the DL engine. The logarithmic
scale shows very clearly that although KBONT scales as good as KBLP, it is always
two orders of magnitude slower than KBLP. In both cases, a signiﬁcant percentage of
the overall execution time is spent by RACER calls.

524
T. Eiter et al.
0,01
0,1
1
10
100
1000
10000
20
71
236
755
2360
#arcs
time (seconds)
KBONT: RACER time
KBONT: total time
KBLP: RACER time
KBLP: total time
Fig. 2. Graph experiment benchmark results
The reason of feeding the extension of tc back to the DL knowledge base in L2 is
not obvious here at ﬁrst sight. However, we wanted to simulate a situation where the
terminological information enlarges the extension of the relation. We illustrate this with
the following dl-program KB = (L4, P4):
L4 = {∃R.{c} ⊑∃R−.{d}; R(a, b); R(b, c)};
P4 = {r(X, Y ) ←DL[R ⊎r; R](X, Y ); r(X, Y ) ←r(X, Z), r(Z, Y )}.
The task of this program is to compute the transitive closure of R. In contrast to the graph
example, here it is not possible to query the entire relation and compute the closure solely
by rules, since the given subsumption axiom creates new tuples from existing ones, which
makes it necessary to feed the inferred facts back to the DL reasoner. Unfortunately, we
were not able to conduct experiments with such a scenario because RACER is not able
to handle individuals in concept expressions.
Unstratiﬁed dl-Programs. Unstratiﬁed dl-programs have been assessed exploiting Ex-
ample 22. The data set at hand is constituted of about 20 individuals.
The computation of this example involves evaluating the least model of the stratiﬁed
part, then the answer-set validation of the entire program. Figure 3 shows the result for
three different evaluation scenarios.
In the ﬁrst setting, we switched off the DL engine caching module: the number of DL
calls is in this case very high, and stems from the fact that (almost) each query is preceded
by calls that clone and extend the knowledge base at hand with facts coming from the
logic program. Since RACER does not provide other ad-hoc features, this technique
proves to be effective in order to quickly augment and restore a given knowledge base.
In the second case, we switched caching on, and this saved a lot of calls to RACER.
The remaining computation time, apart from DLV and RACER external calls, is con-
sumed mainly by a loop that examines answer sets for validity with respect to the DL

Nonmonotonic Description Logic Programs
525
total time DLV time RACER time #cache hits #DL calls
cache off
23.83
0.82
13.65
0
11535
cache on
9.65
0.81
0.26
3786
179
cache on, WFS ﬁrst
6.57
1.02
4.50
152
137
cache on, lfp(γ2
KB) ﬁrst
5.82
0.61
0.11
2283
131
Fig. 3. Shop example results (time expressed in seconds)
knowledge base and also by initializing RACER. These two experiments involved the
validation of 1280 answer sets, generated by the guessing mechanism for unstratiﬁed
dl-atoms.
In the third setting, we did a pre-computation of the WFS of the program before the
answer-set generation. The pre-evaluation of this model limits the number of possible
answer sets to 24, which narrows the execution time mainly to DL-calls.
An interesting variation of this method is to calculate only the positive facts of
WFS(KB), i.e., lfp(γ2
KB). When this method is applied on the current example, some
time-consuming calls to RACER that are involved in computing gfp(γ2
KB) are avoided.
However, the overall time is only slightly less, since this subset of WFS(KB) reduces
the number of answer sets to be checked only to 768.
In this last experiment with the unstratiﬁed dl-program, we considered to compute
only a subset of the well-founded semantics prior to the answer-set generation. Although
this resulted in a reduced overall execution time, this might not apply to other programs.
As we pointed out, the advantage of having less calls to the DL reasoner by omitting
gfp(γ2
KB) is compensated by an increase of the answer sets that have to be checked for
compliance with L. This tradeoff very much depends on the size of the assertional facts
in the DL knowledge base as well as on the number of answer sets, i.e., on the speciﬁc
design of the program and its stratiﬁcation.
6
Conclusion
We have presented methods and algorithms for implementing nonmonotonic description
logic programs. The issue of efﬁcient interfacing between a description logic reasoner
and an answer-set solver has been solved by means of several methods which can be
fruitfully exploited for the implementation of systems of similar nature.
We assumed in most cases to deal with monotonic dl-atoms only. It is worth pointing
out that this conﬁnement beneﬁts of useful nonmonotonic features in this setting as well.
Our semantics provides a safe coupling between rule-based languages and description
logics, since decidability is preserved. Furthermore, extending our semantics for dealing
with many of the special features of answer-set programming systems (e.g., weak and
integrity constraints, or aggregates) is quite straightforward.
Experimental results proved that description logics systems would beneﬁt from this
kind of coupling, since relieving a reasoner like RACER from some reasoning tasks,
which such kind of systems are not aimed at, proved to be effective, also from a perfor-
mance perspective. It turned out also that our system heavily relies on both reasoning
systems, and would beneﬁt from any performance improvement on both sides.
Our experimental prototype implementation, using DLV [15] and RACER [11], is
available at
http://www.kr.tuwien.ac.at/staff/roman/semweblp/.

526
T. Eiter et al.
A
SHIF(D) and SHOIN (D) Syntax
We brieﬂy recall the elements of the description logics SHIF(D) and SHOIN(D),
starting with the latter. We assume a set D of elementary datatypes. Every d ∈D has a
set of data values, called the domain of d, denoted dom(d). We use dom(D) to denote

d∈D dom(d). A datatype is either an element of D or a subset of dom(D) (called
datatype oneOf). Let A, RA, RD, and I be nonempty ﬁnite and pairwise disjoint sets
of atomic concepts, abstract roles, datatype roles, and individuals, respectively. We use
R−
A to denote the set of all inverses R−of abstract roles R ∈RA.
A role is an element of RA ∪R−
A ∪RD. Concepts are inductively deﬁned as follows.
Every C ∈A is a concept, and if o1, o2, . . . ∈I, then {o1, o2, . . .} is a concept (called
oneOf). If C and D are concepts and R ∈RA ∪R−
A, then (C ⊓D), (C ⊔D), and ¬C are
concepts (called conjunction, disjunction, and negation, respectively), as well as ∃R.C,
∀R.C, ≥nR, and ≤nR (called exists, value, atleast, and atmost restriction, respectively)
foranintegern ≥0.Ifd ∈DandU ∈RD,then∃U.d,∀U.d,≥nU,and≤nU areconcepts
(called datatype exists, value, atleast, and atmost restriction, respectively) for an integer
n ≥0. We write ⊤and ⊥to abbreviate C ⊔¬C and C ⊓¬C, respectively, and we
eliminate parentheses as usual.
An axiom is of one of the following forms: (1) C ⊑D, where C and D are concepts
(concept inclusion); (2) R ⊑S, where either R, S ∈RA or R, S ∈RD (role inclusion);
(3) Trans(R), where R ∈RA (transitivity); (4) C(a), where C is a concept and a ∈I
(concept membership); (5) R(a, b) (resp., U(a, v)), where R ∈RA (resp., U ∈RD) and
a, b ∈I (resp., a ∈I and v ∈dom(D)) (role membership); and (6) a = b (resp., a ̸= b),
where a, b ∈I (equality (resp., inequality)).
A knowledge base L is a ﬁnite set of axioms. (For decidability, number restrictions
in L are restricted to simple R ∈RA [14]).
SHIF(D) is the restriction of SHOIN(D) which excludes the oneOf constructor
and limits the atleast and atmost constructors to 0 and 1.
For the semantics of SHIF(D) and SHOIN(D), we refer to [12] or [6].
B
Example Ontology L1
≥1 buying ⊑Shop; ⊤⊑∀buying.Part; ≥2 buying ⊑Discount;
Part(graphiccard); Part(memory); Part(fan);
Part(harddisk); Part(cdrom); Part(dvdrom);
Part(soundcard); Part(cpu); Part(wlan); Part(case);
provides(s1, case); provides(s1, cpu);
provides(s2, dvdrom);
provides(s3, cpu); provides(s3, fan); provides(s3, wlan);
provides(s4, case); provides(s4, cdrom); provides(s4, harddisk);
provides(s5, cpu); provides(s5, harddisk);
provides(s6, graphiccard); provides(s6, soundcard); provides(s6, harddisk);
provides(s7, graphiccard); provides(s7, memory);
provides(s8, wlan);
provides(s9, case); provides(s9, harddisk).

Nonmonotonic Description Logic Programs
527
References
1. G. Antoniou. Nonmonotonic Rule Systems on Top of Ontology Layers. In Proc. ISWC 2002,
volume 2342 of LNCS, pages 394–398, 2002.
2. C. Baral and V. S. Subrahmanian. Dualities Between Alternative Semantics for Logic Pro-
gramming and Nonmonotonic Reasoning. J. Automated Reasoning, 10(3):399–420, 1993.
3. T. Berners-Lee. Weaving the Web. Harper, San Francisco, CA, 1999.
4. T. Berners-Lee, J. Hendler, and O. Lassila.
The Semantic Web.
Scientiﬁc American,
284(5):34–43, 2001.
5. F. M. Donini, M. Lenzerini, D. Nardi, and A. Schaerf. AL-log: Integrating Datalog and
Description Logics. Journal of Intelligent Information Systems, 10(3):227–252, 1998.
6. T. Eiter, T. Lukasiewicz, R. Schindlauer, and H. Tompits. Combining Answer Set Program-
ming with Description Logics for the Semantic Web. In Proc. KR 2004, pages 141–151,
2004. Extended Report RR-1843-03-13, Institut f¨ur Informationssysteme, TU Wien, 2003.
7. T. Eiter, T. Lukasiewicz, R. Schindlauer, and H. Tompits. Well-founded Semantics for De-
scription Logic Programs in the Semantic Web. In Proc. RuleML 2004, number 3323 in
LNCS, pages 81–97. Springer, 2004.
8. W. Faber, N. Leone, C. Mateis, and G. Pfeifer. Using Database Optimization Techniques for
Nonmonotonic Reasoning. In Proc. DDLP-99, pages 135–139. Prolog Association of Japan,
September 1999.
9. D. Fensel, W. Wahlster, H. Lieberman, and J. Hendler, editors. Spinning the Semantic Web:
Bringing the World Wide Web to Its Full Potential. MIT Press, 2002.
10. M. Gelfond and V. Lifschitz. Classical Negation in Logic Programs and Deductive Databases.
New Generation Computing, 17:365–387, 1991.
11. V. Haarslev and R. M¨oller. RACER System Description. In Proc. IJCAR 2001, volume 2083
of LNCS, pages 701–705, 2001.
12. I. Horrocks and P. F. Patel-Schneider.
Reducing OWL Entailment to Description Logic
Satisﬁability. In Proc. ISWC 2003, volume 2870 of LNCS, pages 17–29, 2003.
13. I. Horrocks, P. F. Patel-Schneider, and F. van Harmelen. From SHIQ and RDF to OWL:
The Making of a Web Ontology Language. Journal of Web Semantics, 1(1):7–26, 2003.
14. I. Horrocks, U. Sattler, and S. Tobies. Practical Reasoning for Expressive Description Logics.
In Proc. LPAR 1999, volume 1705 of LNCS, pages 161–180, 1999.
15. N. Leone, G. Pfeifer, W. Faber, T. Eiter, G. Gottlob, S. Perri, and F. Scarcello. The DLV
System for Knowledge Representation and Reasoning. ACM Transactions on Computational
Logic, 2004. To appear.
16. A. Y. Levy and M.-C. Rousset. Combining Horn Rules and Description Logics in CARIN.
Artif. Intell., 104(1-2):165–209, 1998.
17. R. Rosati. Towards Expressive KR Systems Integrating Datalog and Description Logics:
Preliminary Report. In Proc. DL-99, pages 160–164, 1999.
18. M. Trick. Graph Coloring Instances, 1994.
http://mat.gsia.cmu.edu/COLOR/instances.html.
19. A. Van Gelder, K. A. Ross, and J. S. Schlipf. The Well-Founded Semantics for General Logic
Programs. Journal of the ACM, 38(3):620–650, 1991.
20. W3C. OWL Web Ontology Language Guide, 2003. W3C Proposed Recommendation 15 De-
cember 2003. http://www.w3.org/TR/2003/PR-owl-guide-20031215/.
21. W3C. OWL Web Ontology Language Overview, 2004. W3C Recommendation 10 February
2004. www.w3.org/TR/2004/REC-owl-features-20040210/.
22. K. Wang, D. Billington, J. Blee, and G. Antoniou. Combining Description Logic and De-
feasible Logic for the Semantic Web. In Proc. RuleML 2004, number 3323 in LNCS, pages
170–181. Springer, 2004.

Implementing Eﬃcient Resource Management
for Linear Logic Programming
Pablo L´opez1 and JeﬀPolakow2
1 Universidad de M´alaga
lopez@lcc.uma.es
2 National Institute of Advanced Industrial Science and Technology (AIST),
Research Center for Veriﬁcation and Semantics (CVS), CREST, Japan Science and
Technology Agency (JST)
j-polakow@aist.go.jp⋆
Abstract. The Tag-Frame system of resource management [1] reunited
two divergent threads of linear logic programming research by achieving
the eﬃcient proof search behaviour of abstract systems, such as [2], while
using a low-level tag-based approach, as in [3], suitable for specifying an
abstract machine. However, Tag-Frame relies on set operations which
are linear in the size of the sets, and is not as eﬃcient, in general, as
it could be. We present a new tag-based derivation system which relies
solely on low-level concepts to implement eﬃcient resource management,
where most linear time operations have been replaced by constant time
ones. Though motivated and informed by the Tag-Frame system, we
derive our system directly from, and prove its correctness with respect
to the system of Cervesato et al. [2]. An abstract machine based on
the new system has been implemented by Tamura and Banbara, and its
performance compared to their previous machine.
1
Introduction
In the early nineties, work by Andreoli [4], Harland and Pym [5], and Hodas and
Miller [6] showed that goal-directed, focussed proof search is complete for a frag-
ment of linear logic [7]. Although this result qualiﬁed linear logic as an abstract
logic programming language [8], the enormous amount of nondeterminism in
goal-directed proof search, due to the need to split resources (linear hypotheses)
between premises, rendered a naive implementation useless. Hodas and Miller [6]
also introduced the I/O system, which Hodas further reﬁned to the I/O⊤system
[9] to implement the ﬁrst feasible method of managing resources; this work gave
birth to Lolli, a linear logic programming language which conservatively extends
λProlog [10].
Subsequent work on improving the implementation of Lolli1 split into two
general categories: reﬁning resource management strategies to further remove
⋆Work carried out while a JSPS Fellow at Kobe University.
1 For this paper we only consider pure Lolli, i.e. no extra-logical operations.
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 528–543, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

Implementing Eﬃcient Resource Management for Linear Logic Programming
529
nondeterminism from proof search [2,11]; and investigating low-level implemen-
tation techniques suitable for extending the WAM [3,12,13]. The work on re-
source management largely succeeded in removing unnecessary nondetermin-
ism, at least that related to linearity, from proof search. However, the proposed
systems rely upon high-level operations such as context intersection and union
which are linear in the size of the contexts. On the other hand, the work on
compilation associates tags with each resource and then maintains linearity con-
straints by manipulating individual formula tags, rather than whole contexts.
This approach produced very fast implementations, as evidenced by the Lolli-
Cop theorem prover [14], but did not manage to capture the more ideal proof
search behavior of the abstract systems– in particular, these systems lack the
notion of strict resources and thus may diverge where the more abstract systems
will simply fail.
These divergent research paths were reunited with the Tag-Frame system
of Hodas et al. [1] which captures the behavior of the resource management
systems using the low-level techniques of compiled implementations. Speciﬁcally,
the system abstracts the linear context into a set of tags, each representing
some portion of the context. Linearity constraints are then enforced by carefully
keeping track of which tags may and must be consumed at any point in the
proof. However, as argued by Polakow in [15], the machinery for managing tags
presented in [1] both requires more work than necessary and obfuscates the proof
search algorithm.
This paper presents a new proof search system for Lolli which improves upon
the Tag-Frame system in eﬃciency. Although informed by our experience with
the Tag-Frame system, we derive our new system, which we call T F, directly
from RM3, the eﬃcient resource management system of Cervesato et al. [2].
The rest of this paper is organized as follows. Section 2 formally introduces
the formula language of Lolli. Section 3 reviews developments in resource man-
agement up to the Tag-Frame system. Section 4 presents an ineﬃcient, tag-based
version of RM3 which illustrates the main intuition behind T F and serves as
an intermediate system in our proof of correctness. Sections 5 reﬁnes our inter-
mediate system to a new, very eﬃcient system based on the intuition that tags
are pointers. Section 6 presents one further reﬁnement which results in T F, our
ﬁnal system. Section 7 presents LLP-TF, an abstract machine based on T F and
discusses its performance. Finally, section 8 oﬀers some conclusions and further
work.
2
Formulas and Residuation
We now formally introduce our formula language. Due to space limitations, we
limit ourselves to a fragment of Lolli suﬃcient to illustrate all the features of our
system; our system easily extends to the full formula language of Lolli including
quantiﬁers, and intuitionistic implication and bang. We divide our formulas into
goal formulas, G, which may appear as goals, and deﬁnite clause formulas, D,
which may appear as hypotheses. The grammars for goal and clause formulas

530
P. L´opez and J. Polakow
are as follows:
G
::=
A | D −◦G | G1 & G2 | ⊤| G1 ⊗G2 | 1
D
::=
A | G −◦D | ⊤
where A represents atomic predicates. Note that D is restricted to asynchronous
[4] formulas which allows goal-directed proof search to be complete.
In the usual presentation of sequent systems, there are right rules which act
on the goal formula, and left rules which act upon hypotheses. In goal-directed
proof search, we only use right rules when the goal is non-atomic. When solving
an atomic goal, we choose a hypothesis, whose head matches (uniﬁes with) our
goal, to focus on, i.e. to apply left rules generating new goals.
As shown by Cervesato [16], the new goals which will be generated by fo-
cussing on a hypothesis may be eagerly generated by residuating, or “logically
compiling,” the hypothesis into one new goal formula. We note that this basic
idea underlies the earlier notion of a backchaining rule present in the original
presentation of Lolli [6]. For our presentation, we opt to dispense with left rules
in favor of residuation.
We make use of the following judgement to residuate a clause formula, D,
whose head matches a given atom, A, into a goal formula, G:
D ≫A⧹G
The rules for residuation are as follows (where .= signiﬁes uniﬁcation.):
A′ .= A
A′ ≫A⧹1
D ≫A⧹G
G′ −◦D ≫A⧹G ⊗G′
(no rule for ⊤)
3
A Review of Resource Management
The chief source of nondeterminism in linear logic programming (after restrict-
ing to goal-directed, focussed proof search) arises from the need to distribute
resources among the premises of multiplicative rules. When designing Lolli, Ho-
das and Miller realized that resources may be lazily distributed during proof
search; when solving a goal with two premises, all currently available resources
can be given to the ﬁrst premise and those left-over can be further passed to the
second premise. The I/O system [6] follows this intuition and its sequents have
the form:
∆I⧹∆O =⇒G
where ∆I contains the input linear hypotheses while ∆O contains the output
linear hypotheses, G is the goal to be proved.
In the I/O system, the actual linear context consumed by the derivation
corresponds to ∆I −∆O. Thus we can write the ⊗rule as:
∆I⧹∆M =⇒G1
∆M⧹∆O =⇒G2
∆I⧹∆O =⇒G1 ⊗G2
⊗R

Implementing Eﬃcient Resource Management for Linear Logic Programming
531
∆⧹∆=⇒1 ⊤⊤
∆⧹∆=⇒0 1 1
(∆I ∪{D})⧹∆O =⇒0 G
D ̸∈∆O
∆I⧹∆O =⇒0 D −◦G
−◦0
(∆I ∪{D})⧹∆O =⇒1 G
∆I⧹(∆O −{D}) =⇒1 D −◦G −◦1
∆I⧹∆M =⇒v1 G1
∆M⧹∆O =⇒v2 G2
∆I⧹∆O =⇒v1∨v2 G1 ⊗G2
⊗
∆I⧹∆O =⇒0 G1
∆I⧹∆O =⇒0 G2
∆I⧹∆O =⇒0 G1 & G2
&00
∆I⧹∆O =⇒0 G1
∆I⧹(∆O ∪∆) =⇒1 G2
∆I⧹∆O =⇒0 G1 & G2
&01
∆I⧹(∆O ∪∆) =⇒1 G1
∆I⧹∆O =⇒0 G2
∆I⧹∆O =⇒0 G1 & G2
&10
∆I⧹∆O1 =⇒1 G1
∆I⧹∆O2 =⇒1 G2
∆I⧹(∆O1 ∩∆O2) =⇒v G1 & G2
&11
D ≫A⧹G
(∆I −{D})⧹∆O =⇒v G
∆I⧹∆O =⇒v A
Pick(D ∈∆I)
Fig. 1. The I/O⊤system
Linearity constraints are maintained by checking that the output context does
not contain a formula which must be consumed, i.e.:
(∆I ∪{D})⧹∆O =⇒G
D ̸
∈∆O
∆I⧹∆O =⇒D −◦G
−◦R
However, rather than remove the nondeterminism, the idea of lazy splitting only
pushes it into the ⊤(additive unit) rule which can, in this setting, consume an
arbitrary subset of the input:
∆I ⊇∆O
∆I⧹∆O =⇒⊤⊤R
3.1
The I/O⊤System
Hodas removed nondeterminism from the ⊤rule by creating the I/O⊤system
[9]. This system decorates sequents with a boolean ﬂag indicating whether a
⊤was encountered which could implicitly consume extra resources. Thus I/O⊤
sequents have the form:
∆I⧹∆O =⇒v G
where v is a boolean, the ⊤ﬂag, and everything else is the same as in I/O.
In the I/O⊤system, the ⊤rule becomes lazy; rather than consume any of its
input, it simply sets the ⊤ﬂag. When the ⊤ﬂag is set, linearity constraints may
be relaxed since any unconsumed resources could have been consumed by the ⊤.
Figure 1 presents the derivation rules for I/O⊤adapted to use residuation and
our syntax.
While the I/O⊤system removes much of the nondeterminism of resource
distribution, its direct implementation as a logic programming interpreter allows
needless backtracking due to the ineﬃcient treatment of & (additive conjuction).
Since both premises of & must consume exactly the same resources, giving the
same input context to both premises potentially creates useless choice points in
the derivation of the second premise.

532
P. L´opez and J. Polakow
Ξ; ∆\∆=⇒1 ⊤⊤RM3
∅; ∆\∆=⇒0 1 1RM3
Ξ ∪{D}; ∆I\∆O=⇒v G
Ξ; ∆I\∆O=⇒v D −◦G
−◦RM3
∅; Ξ∪∆I\∆M=⇒0 G1
Ξ∩∆M; ∆I ∩∆M\∆O=⇒v G2
Ξ; ∆I\∆O=⇒v G1 ⊗G2
⊗0RM3
∅; Ξ∪∆I\∆M=⇒1 G1
∅; ∆M\∆O=⇒v G2
Ξ; ∆I\∆I ∩∆O=⇒1 G1 ⊗G2
⊗1RM3
Ξ; ∆I\∆O=⇒0 G1
Ξ∪(∆I −∆O); ∅\∅=⇒v G2
Ξ; ∆I\∆O=⇒0 G1 & G2
&0RM3
Ξ; ∆I\∆M=⇒1 G1
Ξ∪(∆I −∆M); ∆M\∆O=⇒v G2
Ξ; ∆I\∆O=⇒v G1 & G2
&1RM3
D ≫A⧹G
Ξ; ∆I\∆O=⇒v G
Ξ∪{D}; ∆I\∆O=⇒v A
pick ΞRM3
D ≫A⧹G
Ξ; ∆I\∆O=⇒v G
Ξ; ∆I ∪{D}\∆O=⇒v A
pick ∆RM3
Fig. 2. The RM3 system
3.2
The RM3 System
The RM3 system of Cervesato et al. [2] extends I/O⊤with the ability to keep
track of exactly which resources must be consumed at any point in the proof.
RM3 is characterized by the following judgement
Ξ; ∆I\∆O=⇒v G
where: Ξ is a set of strict linear clause formulas; ∆I, ∆O are sets of lax linear
clause formulas, the input and output contexts respectively; v is the ⊤ﬂag; and
G is the goal formula being derived. All linear hypotheses, i.e. the contents of
Ξ, ∆I, ∆O, are implicitly uniquely labelled so that we can distinguish diﬀerent
occurrences of the same formula in a set. We assume new labels are tacitly
generated as formulas are added to Ξ. Figure 2 gives a version of the derivation
rules for RM3 slightly modiﬁed to use residuation.
The basic idea behind RM3 is that strict resources must be consumed while
lax resources may be consumed. Because we have a lazy ⊤R rule, resources can
either be explicitly consumed in the pick rules, or implicitly consumed in the
⊤R rule. Thus Ξ is required to be empty in the 1R rule which also sets the ⊤ﬂag
to 0. Furthermore, by adding new resources to Ξ in the −◦R rule, we guarantee
they will be consumed and have no need to check the output context regardless
of the ⊤ﬂag’s value. The formulation of the remaining rules serves to insure
accurate bookeeping of strict resources.
The RM3 system speciﬁes a proof search behavior which is very appropriate
for linear logic programming– at least for goal-directed, left-to-right proof search.
However, the context intersections in the ⊗rules, and context diﬀerences in
the & rules, render a direct implementation of the system extremely slow. A
more concrete, lower-level speciﬁcation is needed for eﬃcient implementation.
In sections 4 through 6 we successively reﬁne RM3 into such a system. However,
we ﬁrst discuss two earlier reﬁnements of RM3 which inform our work.

Implementing Eﬃcient Resource Management for Linear Logic Programming
533
3.3
Frames and Tag-Frames
Upon closer analysis, the strict formulas of RM3 can be seen to follow a stack-like
behavior. The Frame system, F, of L´opez and Pimentel [11], exposes and exploits
this behavior to improve upon RM3’s eﬃciency. In F, the linear contexts, ∆I
and ∆O, are actually stacks of strict contexts, called frames. This representation
alleviates the need for context intersection, in the ⊗rules, to disentangle strict
and lax resources.
Although signiﬁcantly more concrete, and eﬃcient, than RM3, the F system
remains too abstract for direct implementation as a logic programming language.
In addition to relying upon context-wide comparisons, i.e. context diﬀerence, the
system does not maintain the order of linear hypotheses. Such information is
necessary to implement the depth ﬁrst search operational semantics of Prolog-
style languages.
To improve the treatment of &, and maintain context order, Hodas et al.
created the T F system [1] which employs low-level implementation techniques
of [3] to capture the proof search behavior of F (and RM3). Speciﬁcally, T F
assigns tags to each resource and then keeps track of exactly which tags must be
consumed, i.e. are strict, in the current sub-proof. This requires new delete tags
to be generated in the & rules to identify resources consumed in the ﬁrst premise.
Consumption of a resource amounts to changing the resource’s tag, rather than
explicitly removing the formula from the linear context. The use of individual
formula tags allows strict resources to be identiﬁed while maintaining the order
of linear hypotheses.
Although the T F could be used as the basis of an abstract machine for Lolli,
it is not the ideal candidate. The system still relies upon set membership and set
union to manage linearity constraints and requires scanning the linear context2
in the 1 rule as well as scanning the list of available tags in the pick rule. These
operations are not only linear in time, but the machinery for managing tags is
heavier than need be; see [15] for an alternative formulation.
4
Naive Tag-Based System
We start our development of a low-level and eﬃcient resource management spec-
iﬁcation with a simple and ineﬃcient tag-based system which captures the same
proof search behavior of RM3. This system, T F, which maintains context or-
der, ensures that every strict input formula is marked as consumed in the output.
The system will use lists of tagged clause formulas to represent linear contexts.
We respectively use nil, :: and @ for the empty list, list constructor, and list
append function. We also assume each linear hypothesis is implicitly uniquely
labelled so that we may distinguish between diﬀerent occurrences of the same
formula. We assume that new labels are generated as the linear context expands.
2 This could be optimized to just scanning the strict frame if tags are implemented as
pointers to counters.

534
P. L´opez and J. Polakow
∆⧹(s, d, ∆)
s::π
d
−−−−−→1 ⊤
⊤T F
[∆]s = ∅
∆⧹∆
s::π
d
−−−−−→0 1
1T F
Ds :: ∆I ⧹Dd :: ∆O
s::π
d
−−−−−→v G
∆I⧹∆O
s::π
d
−−−−−→v D −◦G
−◦T F
∆I⧹∆M
t::s::π
d
−−−−−−→0 G1
∆M⧹∆O
s::π
d
−−−−−→v G2
∆I⧹∆O
s::π
d
−−−−−→v G1 ⊗G2
⊗0T F
(t not in conclusion)
∆I⧹∆M
t::s::π
d
−−−−−−→1 G1
∆M⧹∆O
t::s::π
d
−−−−−−→v G2
∆I⧹(s, d, ∆O)
s::π
d
−−−−−→1 G1 ⊗G2
⊗1T F
(t not in conclusion)
∆I⧹∆M
s::π
d′
−−−−−→0 G1
∆M⧹∆O
d′::nil
d
−−−−−−→v G2
∆I⧹∆O
s::π
d
−−−−−→0 G1 & G2
&0T F
(d′ not in conclusion)
∆I⧹∆M
s::π
d′
−−−−−→1 G1
∆M⧹∆O
d′::π
d
−−−−−→v G2
∆I⧹∆O
s::π
d
−−−−−→v G1 & G2
&1T F
(d′ not in conclusion)
D ≫A⧹G
∆L@(Dd :: ∆R)⧹∆O
s::π
d
−−−−−→v G
∆L@(Dt :: ∆R)⧹∆O
s::π
d
−−−−−→v A
pick∆T F
(t ∈s :: π)
Fig. 3. The T F system
We make use of the following two functions on lists of tagged formulas:
[nil]t
=
∅
[Dt :: ∆]t
=
{D} ∪[∆]t
[Ds :: ∆]t
=
[∆]t
(if s ̸
= t)
(s, t, nil)
=
nil
(s, t, (Ds :: ∆))
=
Dt :: (s, t, ∆)
(s, t, (Ds′ :: ∆))
=
Ds′ :: (s, t, ∆)
(if s ̸
= s′)
[∆]t returns the set of all formulas in ∆tagged with t. (s, t, ∆) explicitly
changes all occurrences in ∆of tag s to t.
T F sequents have the form
∆I⧹∆O
s::π
d
−−−−−→v G
where: ∆I, ∆O are lists containing tagged clause formulas, the input and output
contexts; s is the strict tag; π is a list of available tags; d is the delete tag; v
is the ⊤ﬂag; and G is the goal formula being derived. Note that list s :: π is
manipulated as a stack. The basic intuition is that input formulas tagged with
s are strict, those tagged with t ∈π are lax3, and those with other tags are not
available for consumption; furthermore, all formulas consumed in the derivation
will be tagged with d in the output. Figure 3 presents the derivation rules for
T F.
3 We overload ∈to mean list membership as well as set membership.

Implementing Eﬃcient Resource Management for Linear Logic Programming
535
4.1
Correctness of T F
We now prove T F sound and complete with respect to RM3. In the follow-
ing statements, we assume that all variables are universally quantiﬁed at the
outermost level, unless explicitly noted otherwise.
We make use of the following function:
∆nil
=
∅
∆t::π
=
[∆]t ∪∆π
∆π returns the set of all formulas in ∆whose tag is in π.
We begin with a lemma that relates the input and output contexts of a T F
provable sequent.
Lemma 1 (Properties of T F).
∆I⧹∆O
s::π
d
−−−−−→v G implies
1. [∆O]s = ∅
2. ∆Iπ ⊇∆Oπ
3. [∆O]d = [∆I]s ∪[∆I]d ∪(∆Iπ −∆Oπ)
whenever s ̸
= d, s ̸
∈π, d ̸
∈π and all tags in π are unique.
Proof. By induction on the structure of the given derivation.
Part 1 states that there are no strict resources in the output. Part 2 states
that the optional output is a subset of the optional input. Finally, part 3 states
what resources are marked as consumed in the output.
The proof of correctnes is divided into two parts, a soundness result and a
completeness result.
Theorem 1 (Soundness with respect to RM3).
∆I⧹∆O
s::π
d
−−−−−→v G implies
[∆I]s ; ∆Iπ \ ∆Oπ =⇒v G
whenever s ̸
= d, s ̸
∈π, d ̸
∈π and all tags in π are unique.
Proof. By induction on the structure of the given derivation, making use of
lemma 1.
Theorem 2 (Completeness with respect to RM3).
Ξ; ∆I\∆O=⇒v G and [∆′
I]s = Ξ and ∆′
Iπ = ∆I implies
∃∆′
O. ∆′
I⧹∆′
O
s::π
d
−−−−−→v G and ∆′
Oπ = ∆O
whenever s ̸
= d, s ̸
∈π, d ̸
∈π and all tags in π are unique.
Proof. By induction on the structure of the given derivation, making use of
lemma 1.

536
P. L´opez and J. Polakow
4.2
Tags as Counters
Exactly four rules of T F require (non-constant time) work to manage linearity
constraints. The 1 rule requires scanning the context for tag s. The ⊤rule
must traverse the context and explicitly change all the strict tags to delete
tags. Likewise, since s is not strict in either premise, the ⊗1 rule must explicitly
consume any resources tagged with s leftover from the derivations of its premises.
Finally, since consumed formulas remain in the context, the pick rule must check
that the chosen formula is available for consumption, i.e. that t occurs in s :: π.
By implementing tags as counters, we can turn the strictness check in the 1
rule to a constant time memory lookup operation. In such an implementation,
each tag would be a reference to a memory location containing the number of
formulas marked with that tag. The implementations of the −◦and pick rules,
as well as the (s, t, ∆) function, would manipulate the counters appropriately
to maintain the representation.
5
Indirect Tag-Based System
Suppose we have three tags, s, t and d, and a context ∆= Ds
1, Ds
2, Dt
3, Dd
4
which we want to change to ∆′ = Dd
1, Dd
2, Dt
3, Dd
4. Then, letting the tags be
memory addresses, we wish to make the following transformation:
d
1
s
2
t
1
Ds
1, Ds
2, Dt
3, Dd
4
−→
d
3
s
0
t
1
Dd
1, Dd
2, Dt
3, Dd
4
By building on the intuition that tags are memory locations, it is possible to
eﬀectively accomplish the preceding transformation in constant time by using
indirection and considering tags as memory locations which contain either a
natural number or another memory location:
d
1
s
2
t
1
Ds
1, Ds
2, Dt
3, Dd
4
−→
d
3
s
d
t
1
Ds
1, Ds
2, Dt
3, Dd
4
If we modify memory lookup to chase down alias chains, s and d will eﬀectively
represent the same tag.
In other words, we would like to maintain equivalence classes of tags. The
machinery we subsequently add to our derivation rules may be seen as the im-
plementation of a union-ﬁnd structure.
5.1
Memory and Partial Functions
In order to formalize and prove correct the previous ideas, we will model memory
as a partial function from a countably inﬁnite set of locations, L, to the disjoint

Implementing Eﬃcient Resource Management for Linear Logic Programming
537
union of all possible value types. For our purposes, we will only consider value
types to be natural numbers, N, locations, and pairs.
We understand a partial function, σ, from A to B to be a set of pairs, (x, y)
where x ∈A and y ∈B, for which there is at most one b ∈B for every a ∈A
such that (a, b) ∈σ. We use the following functional notations:
σ(a)
=

b
if ∃b. (a, b) ∈σ
undeﬁned
otherwise
σ[a := b]
=
(σ −(a, b′)) ∪(a, b)
if ∃b′. σ(a) = b′
σ ∪(a, b)
otherwise
σ ∖a
=

σ −(a, b′)
if ∃b′. σ(a) = b′
σ
otherwise
which correspond to memory lookup, memory modiﬁcation (and allocation), and
memory deallocation. Note that our presentation is purely declarative. σ[a := b]
does not change σ but rather stands for the modiﬁed partial function; thus
σ[a := σ(b)][b := σ(a)] = σ[b := σ(a)][a := σ(b)]
We make use of the following syntax to denote the domain and codomain of
a partial function from A to B:
dom(σ) = {a ∈A | ∃b ∈B. σ(a) = b}
cod(σ) = {b ∈B | ∃a ∈A.σ(a) = b}
5.2
Aliasing and Memory Lookup
For T F+, formula tags will be locations l ∈L. Intuitively, these locations are
memory addresses which store natural numbers. However, since we want to be
able to alias one tag to another, we will model memory as a partial function
Σ from L to N ⊎L where Σ(l) ∈L implies l is aliased to some other memory
location.
We use an explicit lookup judgement to ﬁnd the current alias of a given tag.
In order to improve overall eﬃciency, we will update the Σ function to point to
the current (i.e. last in the chain) alias whenever we have to lookup the value of
a location. Our lookup judgement has the following form
ΣI⧹ΣO |= l ⇝l′
where: Σx are partial functions of type L →N ⊎L; and l, l′ are elements of L.
The derivation rules for the judgement are as follows:
Σ(l) ∈N
Σ⧹Σ |= l ⇝l value
ΣI(l) ∈L
ΣI⧹ΣO |= ΣI(l) ⇝l′
ΣI⧹ΣO[l := l′] |= l ⇝l′
alias
We use the following notational conveniences, where l ∈L and n ∈N, for
common memory operations:
Σ[l + n]
=

Σ[l := n′ + n]
if ∃n′ ∈N. Σ(l) = n′
undeﬁned
otherwise
Σ[l −n]
=
Σ[l := n′ −n]
if ∃n′ ∈N. Σ(l) = n′ and n′ ≥n
undeﬁned
otherwise

538
P. L´opez and J. Polakow
Σ⧹Σ[s := d][d + Σ(s)] ; ∆⧹∆
s::π
d
−−−−−→1 ⊤
⊤T F+
Σ(s) = 0
Σ⧹Σ ; ∆⧹∆
s::π
d
−−−−−→0 1
1T F+
ΣI[s + 1]⧹ΣO ; Ds :: ∆I ⧹D :: ∆O
s::π
d
−−−−−→v G
ΣI⧹ΣO[d −1] ; ∆I⧹∆O
s::π
d
−−−−−→v D −◦G
−◦T F+
ΣI[l := 0]⧹ΣM ; ∆I⧹∆M
l::s::π
d
−−−−−−→0 G1
(ΣM ∖l)⧹ΣO ; ∆M⧹∆O
s::π
d
−−−−−→v G2
ΣI⧹ΣO ; ∆I⧹∆O
s::π
d
−−−−−→v G1 ⊗G2
⊗0T F+
where l not in conclusion
ΣI[l := 0]⧹ΣM ; ∆I⧹∆M
l::s::π
d
−−−−−−→1 G1
ΣM[l := 0]⧹ΣO ; ∆M⧹∆O
l::s::π
d
−−−−−−→v G2
ΣI⧹(ΣO[s := d][d + ΣO(s)] ∖l) ; ∆I⧹∆O
s::π
d
−−−−−→1 G1 ⊗G2
⊗1T F+
where l not in conclusion
ΣI[l := 0]⧹ΣM ; ∆I⧹∆M
s::π
l
−−−−−→0 G1
ΣM⧹ΣO ; ∆M⧹∆O
l::nil
d
−−−−−→v G2
ΣI⧹ΣO ; ∆I⧹∆O
s::π
d
−−−−−→0 G1 & G2
&0T F+
where l ̸∈(dom(ΣI) ∪cod(ΣI)) and [∆I]l = ∅
ΣI[l := 0]⧹ΣM ; ∆I⧹∆M
s::π
l
−−−−−→1 G1
ΣM⧹ΣO ; ∆M⧹∆O
l::π
d
−−−−−→v G2
ΣI⧹ΣO ; ∆I⧹∆O
s::π
d
−−−−−→v G1 & G2
&1T F+
where l ̸∈(dom(ΣI) ∪cod(ΣI)) and [∆I]l = ∅
ΣI⧹ΣM |= t ⇝l
D ≫A⧹G
ΣM[l −1][d + 1]⧹ΣO ; ∆L@(Dd :: ∆R)⧹∆O
s::π
d
−−−−−→v G
ΣI⧹ΣO ; ∆L@(Dt :: ∆R)⧹∆O
s::π
d
−−−−−→v A
pick ∆T F+
where l ∈s :: π
Fig. 4. The T F+ system
5.3
T F+ Sequents
T F+ sequents are of the form
ΣI⧹ΣO ; ∆I⧹∆O
s::π
d
−−−−−→v G
where: ΣI, ΣO are partial functions of type L →N ⊎L, representing the state of
memory before and after the derivation; and everything else remains unchanged
from T F, unique labelling included. It is assumed that s ̸
= d, s /∈π, and d /∈π
Figure 4 contains the derivation rules for T F+.
5.4
Correctness of T F+
We now prove T F+ correct with respect to T F. In all logical statements, all
variables are implicitly universally bound at the outermost level unless explicitly
stated otherwise. We introduce the following notation:
Σ(nil)
=
nil
Σ(Dt :: ∆)
=
Dl :: Σ(∆)
where
Σ⧹|= t ⇝l
to apply all aliases to a contex; and:
nil −nil
=
∅
(Dt :: ∆) −(Dt :: ∆′)
=
∆−∆′
(Dt :: ∆) −(Dt′ :: ∆′)
=
{t′} ∪(∆−∆′)
where
t ̸
= t′

Implementing Eﬃcient Resource Management for Linear Logic Programming
539
for the tag diﬀerence of two contexts. Additionally, #(S) denotes the cardinality
of a (multi)set S.
For a T F+ sequent to be provable, ΣI must map every tag to an appropriate
counter, possibly through a chain of aliases. We formalize this as follows:
Deﬁnition 1 (Well-Formedness).
ΣI⧹ΣO ; ∆I⧹∆O
s::π
d
−−−−−→v G
is well-formed iﬀ
1. ∀t ∈dom(ΣI).∃l ∈dom(ΣI). ΣI⧹|= t ⇝l and ΣI(l) = #([ΣI(∆I)]l)
2. ∀t ∈d :: s :: π. ΣI⧹|= t ⇝t
A derivation is well-formed iﬀevery sequent is well-formed. We now state
some fundamental properties of well-formed derivations.
Lemma 2 (Properties of T F+).
A well-formed derivation of ΣI⧹ΣO ; ∆I⧹∆O
s::π
d
−−−−−→v G
implies all of the
following:
1. ∀t ∈dom(ΣO).∃l ∈dom(ΣO). ΣO⧹|= t ⇝l and ΣO(l) = #([ΣO(∆O)]l)
2. [ΣO(∆O)]s = ∅
3. (ΣI(∆I) −ΣO(∆O)) ⊆{d}
Proof. By structural induction on the given derivation.
Part 1 states that well-formedness is preserved. Part 2 states that the output
contains no strict resources. Part 3 states that a tag in the input can only be
changed to denote consumption.
We are now in a position to prove T F+ correct. We break the proof into
soundness and completeness results.
Theorem 3 (Soundness with respect to T F).
A well-formed derivation ΣI⧹ΣO ; ∆I⧹∆O
s::π
d
−−−−−→v G
implies
ΣI(∆I)⧹ΣO(∆O)
s::π
d
−−−−−→v G
Proof. By structural induction on the given derivation, making use of lemma 2.
Theorem 4 (Completeness with respect to T F).
∆I⧹∆O
s::π
d
−−−−−→v G
implies
∃Σ′
O, ∆′
O. Σ′
O(∆′
O) = ∆O and Σ′
I⧹Σ′
O ; ∆′
I⧹∆′
O
s::π
d
−−−−−→v G
whenever
Σ′
I(∆′
I) = ∆I and
(∀t ∈dom(Σ′
I).∃l ∈dom(Σ′
I).Σ′
I⧹|= t ⇝l and Σ′
I(l) = #([Σ′
I(∆′
I)]l)) and
∀t ∈d :: s :: π. Σ′
I⧹|= t ⇝t
Proof. By induction on the structure of the given derivation making use of lemma
2. Note that given ∆I, s, π, d, it is always possible to construct Σ′
I and ∆′
I such
that the resulting T F+ sequent is well-formed.

540
P. L´opez and J. Polakow
Λ; Σ⧹Σ[s := d][d + Σ(s)] ; ∆⧹∆
s
d
−−−→1 ⊤
⊤T F
Σ(s) = 0
Λ; Σ⧹Σ ; ∆⧹∆
s
d
−−−→0 1
1T F
Λ; ΣI[s + 1]⧹ΣO ; Ds :: ∆I ⧹D :: ∆O
s
d
−−−→v G
Λ; ΣI⧹ΣO[d −1] ; ∆I⧹∆O
s
d
−−−→v D −◦G
−◦T F
Λ[l := Λ(s)]; ΣI[l := 0]⧹ΣM ; ∆I⧹∆M
l
d
−−−→0 G1
Λ; (ΣM ∖l)⧹ΣO ; ∆M⧹∆O
s
d
−−−→v G2
Λ; ΣI⧹ΣO ; ∆I⧹∆O
s
d
−−−→v G1 ⊗G2
⊗0T F
where l not in conclusion
Λ[l := Λ(s)]; ΣI[l := 0]⧹ΣM ; ∆I⧹∆M
l
d
−−−→1 G1
Λ[l := Λ(s)]; ΣM[l := 0]⧹ΣO ; ∆M⧹∆O
l
d
−−−→v G2
Λ; ΣI⧹(ΣO[s := d][d + ΣO(s)] ∖l) ; ∆I⧹∆O
s
d
−−−→1 G1 ⊗G2
⊗1T F
where l not in conclusion
Λ; ΣI[l := 0]⧹ΣM ; ∆I⧹∆M
s
l
−−−→0 G1
Λ[l := n]; ΣM⧹ΣO ; ∆M⧹∆O
l
d
−−−→v G2
Λ; ΣI⧹ΣO ; ∆I⧹∆O
s
d
−−−→0 G1 & G2
&0T F
where [∆I]l = ∅, l ̸∈dom(Λ) ∪dom(ΣI) ∪cod(ΣI), and n ̸∈cod(Λ)
Λ; ΣI[l := 0]⧹ΣM ; ∆I⧹∆M
s
l
−−−→1 G1
Λ[l := Λ(s)]; ΣM⧹ΣO ; ∆M⧹∆O
l
d
−−−→v G2
Λ; ΣI⧹ΣO ; ∆I⧹∆O
s
d
−−−→v G1 & G2
&1T F
where [∆I]l = ∅, l ̸∈dom(Λ) ∪dom(ΣI) ∪cod(ΣI), and n ̸∈cod(Λ)
ΣI⧹ΣM |= t ⇝l
D ≫A⧹G
Λ; ΣM[l −1][d + 1]⧹ΣO ; ∆L@(Dd :: ∆R)⧹∆O
s
d
−−−→v G
Λ; ΣI⧹ΣO ; ∆L@(Dt :: ∆R)⧹∆O
s
d
−−−→v A
pick ∆T F
where Λ(l) = Λ(s)
Fig. 5. The T F system
6
The T F System
Our ﬁnal reﬁnement concerns the role of π which serves only to denote available
tags. By carrying around a complete stack of available tags, we are forced to
search through that stack to determine if a given formula may be focussed upon.
We can abstract this stack, or more precisely membership in this stack, by as-
sociating an availability value with each tag and then ensuring that all available
tags have the same availability value, and all unavailable tags do not have that
value.
To carry out this idea, the T F associates with each tag (location) another
value which will be used to determine that tag’s availability. T F sequents are
of the form
Λ; ΣI⧹ΣO ; ∆I⧹∆O
s
d
−−−→v G
where: Λ is a partial function of type L →N which tracks each tag’s availability;
and everything else remains the same as in T F+ sequents. The extension of
T F+ rules to T F rules is based on the observation that the strict tag is
always available. Figure 5 contains the T F derivation rules. Note that the
second premise of the &0 rule assigns the new strict tag l a new availability
number, thus making l the only available tag; in contrast, the &1 rule assigns
l the same availability number as s, thus allowing all tags available in the ﬁrst
premise to also be in consumed the second premise.
The systems T F and T F+ are essentially isomorphic. The following theo-
rem states the logical equivalence of both proof systems.

Implementing Eﬃcient Resource Management for Linear Logic Programming
541
Theorem 5 (Equivalence of T F and T F+).
Λ; ΣI⧹ΣO ; ∆I⧹∆O
s
d
−−−→v G iﬀΣI⧹ΣO ; ∆I⧹∆O
s::π
d
−−−−−→v G
whenever s ∈dom(Λ) and ∀t ∈ΣI(∆I).t ∈dom(Λ) and (t ∈π iﬀΛ(t) = Λ(s))
Proof. By induction on the structure of the given derivation.
7
Implementation and Benchmarks
The ﬁrst and only published abstract machine for Lolli, LLP, comes from a low-
level tag-based resource management system [3,12]. While this approach yields
a fast implementation, as evidenced by its performance on LolliCop [14]– a lean
connection method theorem prover for Lolli– it fails to preserve the ideal proof
search behavior of the more abstract systems. The main design goal for T F
was to provide a basis for an eﬃcient low-level implementation while retaining
the ideal behavior of more abstract systems.
Tamura and Banbara have recently developed and implemented LLP-TF [17],
an abstract machine for Lolli directly based on T F. They have also executed
a series of benchmarks to compare the performance of LLP-TF to that of LLP.
The results of these experiments are summarized in Fig. 6. The with-test, which
LLP-TF LLP
with-test
time
0.006
0.506
speedup
84.33
1.00
LolliCoP
time
1.920
1.794
speedup
1.00
1.07
12-Queens time
5.110
3.372
speedup
1.00
1.51
Fig. 6. LLP-TF benchmarks (CPU time in seconds)
tests the performance of & (additive conjunction), shows that, as expected, LLP-
TF outperforms LLP for &-intensive tasks. The LolliCoP benchmark exhibits
similar performance in both systems, though LLP is slightly faster in general.
For the N-Queens program, LLP is still faster than LLP-TF.
The loss of eﬃciency in LLP-TF is attributed to the treatment of the multi-
plicative conjunction. Though the tensor rule is in fact constant time, it requires
the creation of a new tag and a check of the ⊤ﬂag, both of which are absent
in LLP. However, LLP checks linear constraints in the linear implication rule,
thus eager failure is not available and LLP is less complete than LLP-TF4. Ad-
ditionally, LLP relies on a linear time rule for the additive conjunction while
LLP-TF’s rule is constant time. As a result, it is possible to write programs that
are faster in LLP than in LLP-TF, and vice-versa.
4 LLP will sometimes diverge where LLP-TF will simply fail, but not the converse.

542
P. L´opez and J. Polakow
In order to improve the performance of LLP-TF, the code generation for
tensor goals G1 ⊗G2 must be optimized. Whenever G1, G2 or both are intu-
itionistic, optimized code can be generated to avoid the extra cost incurred by
the general case. In fact, the current implementation generates optimized code
for built-in predicates. For other predicates, static analysis using abstract inter-
pretation seems the most promising technique. It should be noted that this is a
compiler optimization independent of both the T F proof system and its ab-
stract machine. From that point of view, we believe that T F fulﬁlls its original
goal.
8
Conclusions and Further Work
We have presented T F, a new tag-based resource management system for linear
logic. This system is based on the intuition that tags are memory locations which
store a counter or a reference to another memory location. By using a memory
lookup scheme supporting indirections, most linear time operations of previous
proposals can be replaced by constant time operations without sacriﬁcing proof
search behavior. In particular, the scan of the linear context necessary in the 1
rule of T F[1], has been replaced by a constant-time memory lookup in T F.
The only non-constant time work for managing linearity constraints in the
T F system occurs in the pick rule which requires looking up the current alias of
a given tag. Since the lookup derivation short circuits the alias chains it follows,
only the ﬁrst attempt to lookup a given tag’s alias will require a non-constant
amount of work.
The implementation of LLP-TF, an abstract machine based on T F, shows
that the proof system is detailed enough to allow a direct, low-level implemen-
tation which preserves the ideal proof search behavior of more abstract sys-
tems. The performance benchmarks show that LLP-TF is competitive with LLP,
though some optimization work remains to be done. In particular, given the per-
vasive use of tensor in linear logic programming, it is essential to optimize the
code generation of tensor goals. We plan to extend the compiler with a static
analysis phase to detect intuitionistic predicates.
9
Acknowledgements
The authors are indebted to Professors Naoyuki Tamura and Mutsunori Banbara
of Kobe University for implementing an abstract machine based on T F and
measuring its performance.
References
1. Hodas, J., L´opez, P., Polakow, J., Stoilova, L., Pimentel, E.: A tag-frame system of
resource management for proof search in linear-logic programming. In Bradﬁeld,
J.C., ed.: CSL’02, Edinburgh, Scotland (2002) 167–182

Implementing Eﬃcient Resource Management for Linear Logic Programming
543
2. Cervesato, I., Hodas, J.S., Pfenning, F.: Eﬃcient resource management for linear
logic proof search. Theoretical Computer Science 232 (2000) 133–163
3. Hodas, J.S., Watkins, K., Tamura, N., Kang, K.S.: Eﬃcient implementation of a
linear logic programming language. In: JICSLP’98, IEEE Computer Society Press
(1998) 145–149
4. Andreoli, J.M.: Logic programming with focusing proofs in linear logic. Journal
of Logic and Computation 2 (1992) 297–347
5. Pym, D., Harland, J.: A uniform proof-theoretic investigation of linear logic pro-
gramming. Journal of Logic and Computation 4 (1994) 175–207
6. Hodas, J.S., Miller, D.: Logic programming in a fragment of intuitionistic linear
logic. Information and Computation 110 (1994) 327–365
7. Girard, J.Y.: Linear logic. Theoretical Computer Science 50 (1987) 1–102
8. Miller, D., Nadathur, G., Pfenning, F., Scedrov, A.: Uniform proofs as a foundation
for logic programming. Annals of Pure and Applied Logic 51 (1991) 125–157
9. Hodas, J.S.: Logic Programming in Intuitionistic Linear Logic: Theory, Design and
Implementation. PhD thesis, University of Pennsylvania, Department of Computer
and Information Science (1994)
10. Miller, D., Nadathur, G.: Higher-order logic programming. In Shapiro, E., ed.:
Proceedings of the Third International Logic Programming Conference, London
(1986) 448–462
11. L´opez, P., Pimentel, E.: Resource management in linear logic proof search revisited.
In Ganzinger, H., McAllester, D., Voronkov, A., eds.: LPAR’99, Tbilisi, Republic
of Georgia, Springer-Verlag LNAI 1705 (1999) 304–319
12. Banbara, M., Tamura, N.:
Compiling resources in a linear logic programming
language. In Sagonas, K., ed.: JICSLP’98 Post Conference Workshop on Imple-
mentation Technologies for Programming Languages based on Logic. (1998) 32–45
13. Tamura, N., Kaneda, Y.: Extension of wam for a linear-logic programming lan-
guage. In Ida, T., Ohori, A., Takeichi, M., eds.: Second Fuji International Workshop
on Functional and Logic Programming, World Scientiﬁc (1996) 33–50
14. Hodas, J.S., Tamura, N.: lolliCOP - a linear logic encoding of a lean connection-
method theorem prover for ﬁrst-order classical logic. In: IJCAR’01, Siena, Italy
(2001) 670–684
15. Polakow, J.: Linearity constraints as bounded intervals in linear logic programming.
In: Proceedings of LRPP’04, Turku, Finland (2004)
16. Cervesato, I.:
Proof-theoretic foundation of compilation in logic programming
languages. In Jaﬀar, J., ed.: JICSLP’98, Manchester, UK, MIT Press (1998) 115–
129
17. Tamura, N., Banbara, M.: Llp-tf: an abstract machine for lolli based on tag-frame-
fast. http://bach.istc.kobe-u.ac.jp/llp/tf.html (2004)

Layered Clausal Resolution in the
Multi-modal Logic of Beliefs and Goals
Jamshid Bagherzadeh⋆and S. Arun-Kumar ⋆⋆
Indian Institute of Technology Delhi, 110016, New Delhi, India
jamshid@cse.iitd.ernet.in, sak@cse.iitd.ernet.in
Abstract. In this paper a proof technique for reasoning about the multi-
modal logic of beliefs and goals is deﬁned based on resolution at diﬀerent
levels of a tree of clauses. We have considered belief and goal as normal
modal logic operators. The technique is inspired by that in [6,7] and
allows for a locality property to be satisﬁed. The main motivation for
this work arises not as much from theorem-proving as from the notion
of belief and goal revision under an assumption of consistency of the
beliefs and goals of an agent. We also present proofs of soundness and
completeness of the logic.
Keywords: multi-modal logic, multi-agent systems, resolution, proof
method, belief revision.
1
Introduction
Modal logics are widely used for diﬀerent purposes in computer science and
mathematics. This class of logics extends classical logic with two main oper-
ators, necessity (2) and possibility (3) [4]. The semantics of these logics are
usually deﬁned in terms of Kripke structures [15]. Modal logics are used in the
representation of knowledge, belief, goals and other mental attitudes of agents.
Agents usually have three aspects:
– Informational aspects like Knowledge and Beliefs. The modal logics of S5,
and KD45 are used usually for these aspects.
– Motivational aspects like Goals, Desires and Intentions. Modal logics of KD
are used commonly for these aspects.
– Dynamic or temporal aspects. Linear time or branching time temporal logics
are used for modeling these aspects.
In this paper we don’t consider the dynamic aspects of agents and we only assume
the informational and motivational issues. We use Belief, Goal and Intention for
informational and motivational aspects respectively.
In some of the recent literature on agents, the mental state of an agent (in
a system of many communicating agents each with incomplete knowledge of the
global state of the system) is usually represented by data structures representing
⋆Supported by the ministry of science, research and technology, I.R. Iran.
⋆⋆Partly supported by research grant F.26-1/2002-TS.V from MHRD, Govt. of India.
F. Baader and A. Voronkov (Eds.): LPAR 2004, LNAI 3452, pp. 544–559, 2005.
c
⃝Springer-Verlag Berlin Heidelberg 2005

Layered Clausal Resolution in the Multi-modal Logic of Beliefs and Goals
545
the beliefs, goals and intentions of the agents [21]. Two important issues arise in
the context of execution of agent programs:
1. How does the mental state of an agent get revised when a new input arrives?
2. How does one reason about the mental state of an agent assuming that it
has a ﬁnite base of beliefs, goals and intentions, even though their logical
consequences may be inﬁnite?
The two issues are closely linked since it is necessary to be able to reason about
the mental state to ensure that its revision does not create any logical inconsis-
tency. We will discuss these issues in this paper.
Assume Ψi is the mental state of agent i. Alchourron et.al. in [1] have pro-
posed some postulates for belief expansion, contraction and revision which are
well known as AGM postulates. The idea is to satisfy the AGM postulates when
a new belief φ is observed and intended to be added to the belief state of the
agent. For example one of the important issues in the revision is the consistency
issue, i.e. if Ψi is consistent before addition of φ, then it should remain consistent
after the addition also. This may result in the removal of some of the existing for-
mulas from Ψi which contradict φ. There are diﬀerent ways of deﬁning functions
for expansion, contraction and revision which satisfy AGM postulates (perhaps
not all) in the belief sets1. We are not going to deﬁne these methods in detail.
We assume each agent has a belief base and a goal base consisting of a set of
formulas. The structure of the formulas will be discussed in section 3. Although
not common, we assume AGM postulates should hold for the goal base too. The
consistency of the set of formulas is checked using the resolution method which
will be discussed later. For the sake of completeness we deﬁne a simple procedure
of revision (using expansion and contraction according to Levi [16]).
Function Revise(S, φ)
S is belief or goal base and φ is a new formula.
S= S ∪{φ};
expansion
return (Contraction(S));
contraction of ¬φ
End Revise.
Function Contraction(S)
S0 = S; i=0;
while (Si |= false) do
Find minimum Fi ⊆Si s.t. Fi |= false;
gi = γ(Fi) ;
gi is one of the formulas of Fi
Si+1 = Si −{gi};
remove gi from Si
i = i + 1;
end while;
return Si;
End Contraction.
1 A belief set is closed under logical consequence and so it is inﬁnite but belief base is
not closed under logical consequence and so it is ﬁnite

546
J. Bagherzadeh and S. Arun-Kumar
where γ is a function to select a formula from Fi (according to some crite-
ria). In the function Contraction, Fi is one of the minimal subsets of Si which
implies false. To ﬁnd Fi we start from the rule which has implied false and
by backtracking the route which has resulted in false, we may ﬁnd the subset
of formulas which have implied it. If there are more subsets of formulas which
imply false, they will be found in the next iterations.
Our contraction function is similar to kernel base contraction method. It has
been shown in the literature [13] that kernel base contraction method satisﬁes
the postulates of AGM (except recovery postulate for contraction2).
2
Beliefs and Goals
In this framework we consider n agents each of which has a belief base and a
goal base for representing his mental state. We assume the modal operators B
and G which stand for belief and goal respectively, satisfy the axioms of KD45
and KD.
A crucial question is that how we can corporate the intention modality in
such a framework since intentions are also an important part of any agent’s
mental state. Various authors [5,20,14] have given sound reasons that intention
should be treated as non-normal modal operator. Therefor we assume intention is
a derived operator in the spirit of [5], which may be deﬁned as Iiφ ≡Giφ∧Bi¬φ.
Suppose Ag = {1, . . . , n} is a set of agents, and Bi and Gi (Belief and Goal
respectively) for any i ∈Ag, are called the mental attitudes for agent i. Let
O = {B, G} be a set of symbols. Let V be the set (O × Ag)∗, i.e., the set of
ﬁnite strings of the form o1i1 . . . onin with ok ∈O and ik ∈Ag. We call any v ∈
V, a view. Intuitively, each view in V represents a possible nesting of mental
attitudes. We may imagine the information store as a collection of n trees, such
that the tree rooted at Agi consists of the information of agent i. Figure 1 shows
a schematic information store of the multi-agent system and particularly that
of agent i. Considering this structure, we assume any agent has a set of beliefs
called the belief base and a set of goals called the goal base. We assume
beliefs of an agent should be consistent. We also suppose the goals of an agent
are consistent (set of goals is a subset of desires which are themselves consistent).
These two sets are represented by ΨBi and ΨGi respectively. Each of these sets,
contains formulas of a multi-modal logic called BGn, which will be discussed
below. Each formula of BGn will be transformed to clauses, and clauses will be
stored in diﬀerent nodes (or views) of the tree. Then for reasoning about the
system we use resolution inside any view or between two adjacent views.
The remaining part of this paper is organized as follows. In section 3 we deﬁne
the syntax and semantics of the logic BGn. Section 4 discusses the normal form
NFBG and the transformation of BGn formulas to NFBG clauses with a small
example. Section 5 deﬁnes the resolution rules. Then we prove the soundness
2 If we want to remove p ∨q then we must remove p and q consequently, but after
re-addition of p ∨q it will imply neither p nor q.

Layered Clausal Resolution in the Multi-modal Logic of Beliefs and Goals
547
        
 
Bi
Ag1
....
....
Agn
ϵ
BiBk
Gi
...
...
...
...
...
...
...
GiBj
BiBj
BiGj
GiGi
Agi
ΨBi
ΨGi
Fig. 1. Information store as a tree, with nodes representing views
and completeness of the resolution system in section 6 and ﬁnally section 7 is
the conclusion.
3
Syntax and Semantics of BGn
As we said, any agent has two sets of BGn formulas representing its beliefs,
and goals. Formulas of BGn are constructed from a set P = {p, q, r, ...} of
atomic propositions, and the constants true and false. The language contains
the standard propositional connectives ¬, ∧, ∨, and unary modal connectives
Bi and Gi (i ∈Ag). Formally the set WFFBG of well-formed formulas of BGn,
is deﬁned as the smallest set such that
– any element of P is in WFFBG;
– true and false are in WFFBG;
– if F and G are in WFFBG then so are
¬F
, F ∨G
, F ∧G
, BiF
, GiF
where i ∈Ag.
We use another binary operator F ⇒G which is an abbreviation of ¬F ∨G. We
deﬁne some particular classes of formulas that will be useful later.
Deﬁnition 1. A literal l is either p or ¬p where p ∈P. A simple modal
literal is either Oil, or ¬Oil, where l is a literal, i ∈Ag and O ∈{B, G}. A
modal literal is a literal l or its negation ¬l and if F is a modal literal then
OiF and ¬OiF also are modal literals, where O ∈{B, G}.
Deﬁnition 2. A Model M is a structure M = ⟨S, L, S0, B1, ..., Bn, G1, ..., Gn⟩,
where S is a set of states ranged over by s and t and {} ̸= S0 ⊆S is a set of initial
states. L is a state labeling function, i.e., L : S →2P. Bi, for all i ∈Ag is the
agent belief accessibility relation over states, i.e., Bi ⊆S × S, where each Bi is
transitive (∀s, s′, s′′ ∈S : if (s, s′) ∈Bi and (s′, s′′) ∈Bi then (s, s′′) ∈Bi), serial
(∀s ∈S, ∃s′ ∈S s.t. (s, s′) ∈Bi), and euclidean (∀s, s′, s′′ ∈S, if (s, s′) ∈Bi
and (s, s′′) ∈Bi then (s′, s′′) ∈Bi). Finally Gi, for all i ∈Ag is the agent goal
accessibility relation over states, i.e., Gi ⊆S × S, where each Gi is serial.

548
J. Bagherzadeh and S. Arun-Kumar
In Fig. 2 the semantics of the language is deﬁned as the satisfaction relation |=
between the states of a model and BGn formulas by induction on the structure of
formulas. We note here that Bi satisﬁes the axioms of the modal logic KD45 and
(M, s) |= true
for any state s.
(M, s) |= p
iﬀp ∈L(s) (where p ∈P).
(M, s) |= ¬F
iﬀ(M, s) ̸|= F
(M, s) |= F ∧H
iﬀ(M, s) |= F and (M, s) |= H
(M, s) |= F ∨H
iﬀ(M, s) |= F or (M, s) |= H
(M, s) |= OiF
iﬀ∀t ∈S, if (s, t) ∈Oi then (M, t) |= F
Fig. 2. Semantics of BGn
Gi satisﬁes the axioms of the modal logic KD. These axioms for O ∈{B, G} are:
K: ⊢Oi(F ⇒H) ⇒(OiF ⇒OiH)
4: ⊢BiF ⇒BiBiF
D: ⊢OiF ⇒¬Oi¬F
5: ⊢¬BiF ⇒Bi¬BiF
4
A Normal Form for Formulas of BGn
We ﬁrst transform formulas of BGn to a normal form called NFBG. For this
purpose we introduce a symbol start such that (M, s0) |= start for any initial
state s0. Formulas in NFBG are of the general form

i vi : Ci
where vi ∈V is a view and Ci is a clause. Clauses are of the following form:
start ⇒r
a=1 la (an initial clause) ,
true ⇒r
a=1 mBia (a Bi clause)
true ⇒r
a=1 la
(a literal clause)
,
true ⇒r
a=1 mGia (a Gi clause)
Here la are literals, mBia are either literals or simple modal literals involving the
Bi modality, and mGia are either literals or simple modal literals involving the
Gi modality. For convenience the conjunction is dropped and we consider just
the set of clauses of the form vi : Ci.
4.1
Translation to Normal Form
Before the translation to normal form we replace formulas of the form BiBiF
and Bi¬BiF by BiF and ¬BiF respectively. The translation to normal form
requires a number of propositional variables x, y, . . . proportional to the number
of modal operators and propositional connectives in the formula. In this section
we deﬁne the process of translation of arbitrary BGn formulas to the set of
clauses in normal form. Consider a formula F of BGn. The translation will be

Layered Clausal Resolution in the Multi-modal Logic of Beliefs and Goals
549
done in two steps by applying transformations τ0 and τ1 as described below (f
is a new propositional variable).
τ0[F] −→( ϵ : start ⇒f ) ∧τ1[ ϵ : f ⇒F ].
(1)
ϵ denotes the initial view in the tree of clauses. Next, we deﬁne τ1 as follows,
assuming x is a proposition. If the main operator on the right side of the impli-
cation is either ∧or ¬ we remove it as follows.
τ1[v : x ⇒(F ∧H)] −→τ1[v : x ⇒F] ∧τ1[v : x ⇒H]
τ1[v : x ⇒¬(F ∧H)] −→τ1[v : x ⇒(¬F ∨¬H)]
τ1[v : x ⇒¬(F ∨H)] −→τ1[v : x ⇒¬F] ∧τ1[v : x ⇒¬H]
τ1[v : x ⇒¬¬F] −→τ1[v : x ⇒F].
Complex sub-formulas that appear within the scope of any modal operator, are
transformed as follows (where y is a new proposition, Oi ∈{Bi, Gi}, and F is
not a literal).
τ1[v : x ⇒OiF] −→τ1[v : x ⇒Oiy] ∧τ1[vOi : y ⇒F]
τ1[v : x ⇒¬OiF] −→τ1[v : x ⇒¬Oi¬y] ∧τ1[vOi : y ⇒¬F]
Next, we use renaming on formulas whose right hand side has disjunction as its
main operator but may not be in the correct form (y is a new proposition and
D is a disjunction of formulas which are not necessarily in the normal form).
τ1[v : x ⇒D ∨F] −→τ1[v : x ⇒D ∨y] ∧τ1[v : y ⇒F]
where F is neither a literal nor a simple modal literal, nor a disjunction of
literals and simple modal literals. (For example F could be a conjunction of
formulas)
τ1[v : x ⇒D ∨OiF] −→τ1[v : x ⇒D ∨y] ∧τ1[v : y ⇒OiF],
where D contains a disjunct of the form O′
j or ¬O′
j and O ̸= O′ or i ̸= j.
τ1[v : x ⇒D ∨¬OiF] −→τ1[v : x ⇒D ∨y] ∧τ1[v : y ⇒¬OiF],
where D contains a disjunct of the form O′
j or ¬O′
j and O ̸= O′ or i ̸= j.
τ1[v : x ⇒D ∨OiF] −→τ1[v : x ⇒D ∨Oiy] ∧τ1[vOi : y ⇒F],
where F is not a literal and D contains only the modality Oi.
τ1[v : x ⇒D ∨¬OiF] −→τ1[v : x ⇒D ∨¬Oi¬y] ∧τ1[vOi : y ⇒¬F],
where F is not a literal and D contains only the modality Oi.
According to the deﬁnition of NFBG, each modal clause may contain sim-
ple modal literals involving only one modal operator. Thus clause true ⇒
B1x∨y ∨¬B1z is allowed, but true ⇒B1x∨y ∨B2z and true ⇒B1x∨y ∨G1z
are not allowed, as they contain more than one modality. The above transforma-
tions will make sure that each modal clause contains only one modal operator
on the right hand side. Finally we transform the formulas whose right hand
side is a disjunction of literals or simple modal literals of the same type: (D
is a disjunction of literals and simple modal literals only involving one modal
operator.)
τ1[v : x ⇒D] −→v : true ⇒¬x ∨D

550
J. Bagherzadeh and S. Arun-Kumar
τ1[ϵ : f ⇒Bix1] ∧τ1[Bi : x1 ⇒p ∨¬Bj(q ∨¬t))]
ϵ : true ⇒¬f ∨Bix1
τ0[Bi(p ∨¬Bj(q ∨¬t))] = (ϵ : start ⇒f) ∧τ1[ϵ : f ⇒Bi(p ∨¬Bj(q ∨¬t))]
τ1[Bi : x1 ⇒p ∨¬Bj¬x2] ∧τ1[BiBj : x2 ⇒¬(q ∨¬t)]
Bi : true ⇒¬x1 ∨p ∨¬Bj¬x2
τ1[BiBj : x2 ⇒¬q ∧t]
τ1[BiBj : x2 ⇒¬q] ∧τ1[BiBj : x2 ⇒t]
BiBj : true ⇒¬x2 ∨¬q
BiBj : true ⇒¬x2 ∨t
Fig. 3. Transformation of F = Bi(p ∨¬Bj(q ∨¬t)) into normal form
After the above transformations we will have a set of clauses in NFBG normal
form. Figure 3 shows the diﬀerent steps in the transformation of the formula
F = Bi(p ∨¬Bj(q ∨¬t)) into normal form.
Proposition 1. τ0 transforms every ϕ ∈WFFBG into normal form in O(m+p)
steps with an extra O(m+p) new propositional variables, where m is the number
of modal operators and p is the number of propositional connectives.
5
Resolution for NFBG Normal Form Formulas
In this section we deﬁne the resolution rules for inferring a formula from the
information store. Assuming F and H are disjunctions of literals, the initial
rules are:
[IRES1]
ϵ : true ⇒(F ∨l)
ϵ : start ⇒(H ∨¬l)
ϵ : start ⇒(F ∨H)
[IRES2]
ϵ : start ⇒(F ∨l)
ϵ : start ⇒(H ∨¬l)
ϵ : start ⇒(F ∨H)
Next we deﬁne modal resolution rules which are used to resolve two simple modal
literals in the same view (MRES1, MRES2), or to resolve two clauses in adjacent
views (MRES3, MRES4).
[MRES1]
v : true ⇒D ∨m
v : true ⇒D′ ∨¬m
v : true ⇒D ∨D′
[MRES3]
v : true ⇒D ∨¬Oil
vOi : true ⇒D′ ∨l
v : true ⇒D ∨modOi(D′)
[MRES2]
v : true ⇒D ∨Oil
v : true ⇒D′ ∨Oi¬l
v : true ⇒D ∨D′
[MRES4]
v : true ⇒D ∨Oil
vOi : true ⇒D′ ∨¬l
v : true ⇒D ∨modOi(D′)

Layered Clausal Resolution in the Multi-modal Logic of Beliefs and Goals
551
where modOi(D′) is deﬁned below. In MRES1 and MRES2, D and D′ have the
same kind of modal operators, i.e. if D has a simple modal literal Oil then all
other simple modal literals of D and all simple modal literals of D′ must involve
Oi only. In MRES3 and MRES4 if D has belief modality operator, say Bi, then
D′ must not have any simple modal literals involving Oj such that Oj ̸= Bi, i.e.
all the simple modal literals of D and D′ must have Bi only, otherwise we may
obtain a resolvent containing a modal literal which has a nesting of two modal
operators like BiOjl′ which is not in the normal form. In this case, if D′ has
a simple modal literal Ojl′ (Oj ̸= Bi), it must be resolved with another clause
already. In MRES3 and MRES4 if Oi = Gi, then D′ must be a disjunction of
literals only, to avoid the problem of nested modal operators.
Deﬁnition 3. The function modOi(D), is deﬁned on the disjunction of literals
or simple modal literals as follows: (Oi ∈{Bi, Gi})
modOi(l) = ¬Oi¬l
, modBi(Bil) = Bil
modOi(F ∨H) = modOi(F) ∨modOi(H) , modBi(¬Bil) = ¬Bil
Note that modBi(Ojl) where Oj ̸= Bi and modGi(Ojl) are not deﬁned, as these
cases will not occur in the resolution process. Let us justify MRES3, assuming
Oi = Bi; the same argument holds for Gi. The ﬁrst clause v : true ⇒D ∨¬Bil
is from view v, and the second clause vBi : true ⇒D′ ∨l is from view vBi. In
resolution rule MRES3, the second clause can be written as vBi : ¬D′ ⇒l and
after distributing Bi it will be v : Bi(¬D′ ⇒l), which implies v : Bi¬D′ ⇒Bil.
As D′ is a disjunction of simple modal literals involving only Bi, i.e., D′ = m1 ∨
...∨mk then ¬D′ = ¬m1∧...∧¬mk, and so Bi¬D′ = Bi¬m1∧...∧Bi¬mk. Finally
we obtain the clause v : true ⇒¬Bi¬m1∨...∨¬Bi¬mk∨Bil. Now we can resolve
two clauses v : true ⇒D ∨¬Bil and v : true ⇒¬Bi¬m1 ∨...¬Bi¬mk ∨Bil,
which will yield a new clause v : true ⇒D ∨¬Bi¬m1 ∨...¬Bi¬mk. If mi
is a simple modal literal then according to a theorem of the logic KD45 [6]
which says ¬Bi¬Bi¬F ⇔Bi¬F, we can remove ¬Bi¬ from the simple modal
literals and if mi = l′ it will remain in the form ¬Bi¬l′. In the case of goals,
D′ is just a disjunction of literals, that is because we don’t have the equivalence
¬Gi¬Gi¬F ⇔Gi¬F in the logic KD.
Example. Suppose agent i has the belief base: Bi(¬p ∨Bjq), BiBj¬q. The
question is, whether Bi¬p is implied by the belief base. We add ¬Bi¬p to the
belief base and check if the resolution process results in the clause ϵ : start ⇒
false (see Fig. 4).
6
Soundness and Completeness
We will prove that the transformation into NFBG preserves satisﬁability. As-
sume M = ⟨S, L, S0, B1, . . . , Bn, G1, . . . , Gn⟩is a Kripke structure. We say s′ is
accessible from s via relation Oi if (s, s′) ∈Oi. Moreover if s′′ is accessible from
s′ via v′ and s′ is accessible from s via v, then s′′ is accessible from s via vv′
where vv′ is concatenation of v and v′. If state s is accessible from an initial state

552
J. Bagherzadeh and S. Arun-Kumar
6
MRES1
2
10
5
8
IRES1
MRES1
MRES3
MRES2
8. ϵ : true ⇒¬f ∨¬Bi¬p
5. ϵ : true ⇒¬f ∨Biy1
Bi(¬p ∨Bjq)
BiBj¬q
¬Bi¬p
3. Bi : true ⇒¬x1 ∨¬p ∨Bjq
2. ϵ : true ⇒¬f ∨Bix1
1. ϵ : start ⇒f
4. ϵ : start ⇒f
6. Bi : true ⇒¬y1 ∨Bj¬q
7. ϵ : start ⇒f
3
12. ϵ : true ⇒¬f
1
ϵ : start ⇒false
10. ϵ : true ⇒¬f ∨¬Bix1 ∨¬Biy1
11. ϵ : true ⇒¬f ∨¬Biy1
9. Bi : true ⇒¬x1 ∨¬p ∨¬y1
Resolution :
Clauses :
Fig. 4. Clausal form and resolution process of belief base of the example
s0 via v, we say s is at level v of the Kripke structure M. We say M, s |= v : F
iﬀfor any state s′ accessible from s via v, M, s′ |= F. The following proposition
shows that the transformation τ0 preserves satisﬁability and unsatisﬁability.
Proposition 2.
Assume M is a Kripke structure and s0 is an initial state,
1. (M, s0) |= τ1[v : x ⇒F] implies (M, s0) |= (v : x ⇒F).
2. (M, s0) |= τ0[F] implies (M, s0) |= F.
3. If there is a model M, such that (M, s0) |= ϵ : x ⇒F, then there is a model
M ′ s.t. (M ′, s′
0) |= τ1[ϵ : x ⇒F].
4. For any model M of F, there exists a model M0 of τ0[F].
From the above proposition we have:
Theorem 1. A BGn formula A is satisﬁable if and only if τ0[A] is satisﬁable.
Theorem 2 (Soundness). Let T be a set of NFBG clauses. Let the clause
set R be obtained from T by applying one of the resolution rules. Then T is
satisﬁable if and only if R is satisﬁable.
Sketch of the proof. We prove the above theorem by considering any rule and
assuming its premises are satisﬁable, then we prove its conclusion (or resolvent)
is also satisﬁable. For reverse direction, if T is unsatisﬁable then after adding
the new clause to obtain R, still R is unsatisﬁable.
⊓⊔
Theorem 3 (Termination). The resolution process (repeated applications of
the rules in section 5) in a set of NFBG clauses always terminates.
Sketch of the proof. As the resolution rules don’t create new views, so the reso-
lution process terminates after some steps, because there are a ﬁnite number of
propositions, views and modal operators.
⊓⊔
The completeness proof is based on the construction of a behavior graph [7,6].
We construct a graph of NFBG clauses which has belief and goal relations for any
agent i. We will show that the set of resolution rules presented here is complete,
and there is a refutation by resolution if the set of clauses is unsatisﬁable. Note

Layered Clausal Resolution in the Multi-modal Logic of Beliefs and Goals
553
that we use the word ’view’ when we refer to a subset of clauses (we say clauses
of view v) and we use the word ’level’ when we refer to some subset of states in
the graph (we say states of level v).
Deﬁnition 4. The depth of a modal literal F is the number of modal operators
applied to a literal. Depth of literal l or its negation ¬l is 0. Depth of OiF or
¬OiF is 1 + depth(F).
Deﬁnition 5. Given a set of NFBG clauses, the view v = Oi1 . . . Oik is called a
deepest view if there are clauses in view v, but no clause in view vOik+1 for any
O ∈{B, G} and i1, . . . , ik+1 ∈Ag.
It is possible to have more than one deepest view in a set of clauses.
Deﬁnition 6. Let C = v : true ⇒φ be a NFBG clause, we deﬁne lset(C) =
{l, ¬l | l is an atomic proposition in φ} and mset(C) = {m, ¬m | m is a simple
modal literal in φ}. If v is a view and C1, . . . , Cn are all of the clauses of the form
v : true ⇒φ then we deﬁne cl(v) = {C1, . . . , Cn} which is the set of clauses
contained in view v. Moreover we deﬁne lset(v) = lset(C1) ∪· · · ∪lset(Cn) and
mset(v) = mset(C1) ∪· · · ∪mset(Cn).
For example if C1 ≡Bj : true ⇒¬x∨Bip∨q and C2 ≡Bj : true ⇒y ∨Bkt∨p
then lset(C1) = {x, p, q, ¬x, ¬p, ¬q} and mset(C) = {Bip, ¬Bip}. If view Bj
contains only clauses C1 and C2, then lset(Bj) = {x, p, q, y, t, ¬x, ¬p, ¬q, ¬y, ¬t},
and mset(Bj) = {Bip, Bkt, ¬Bip, ¬Bkt}.
Graph Construction Assume as before Ag = {1, ..., n} is a set of agents and T
is a set of clauses. For any set S = {f1, . . . , fn} of modal literals (cf. Def. 1), i ∈
Ag and O ∈{B, G} Application of Oi to S is represented as Oi.S and deﬁned as
Oi.S = {Oif1, . . . , Oifn}. We start with the clauses in the deepest views. Assume
v = O1 . . . Ok is a deepest view. Let ∆k = lset(v) ∪mset(v). We take ∆k−1 =
lset(O1 . . . Ok−1) ∪mset(O1 . . . Ok−1) ∪Ok.∆k ∪{¬f | f ∈Ok.∆k}. Now we will
do the same process for obtaining elements of ∆k−2 (∆k−2 = lset(O1 . . . Ok−2) ∪
mset(O1 . . . Ok−2) ∪Ok−1.∆k−1 ∪{¬f | f ∈Ok−1.∆k−1}). We repeat the same
process till we get the set ∆0. We deﬁne ∆v = ∆0 ∪· · · ∪∆k.3 Now consider all
other deepest views v′ and do the same for v′ to obtain other sets ∆v′. Finally
we deﬁne ∆= 
v ∆v where v is a deepest view.
Deﬁnition 7. Let F and H be modal literals. We deﬁne the relation F ⇒H
as:
F ⇒F
, OiF ⇒OiH iﬀF ⇒H , OiF ⇒¬Oi¬H iﬀF ⇒H.
Moreover a pair of formulas is complementary if they are of one of the following
forms (assume F ⇒H): F and ¬F , OiF and ¬OiH , OiF and Oi¬H.
For example Bip and Bi¬p, GiGjp and Gi¬Gjp , BiGjBkp and ¬Bi¬Gj¬Bkp
are all complementary pairs.
Graph G = (S, B1, ...Bn, G1, ..., Gn) is constructed as follows. The set of
states S is constructed by considering all possible maximal subsets of ∆(which
3 Note that ∆v has modal literals of depth at most k + 1.

554
J. Bagherzadeh and S. Arun-Kumar
is deﬁned earlier as 
v ∆v) which are consistent. δ is a maximal consistent
subset of ∆if we can not add any more element from ∆to δ, otherwise it will
be inconsistent. δ is consistent if it doesn’t have a complementary pair.
Deﬁnition 8. For each maximal consistent subset δ of ∆, we will have a corre-
sponding state s ∈S and will say δ is the label of s, and we write label(s) = δ.
Let us consider a simple example. Consider only one clause Bj : true ⇒p. Then
∆includes {p, ¬p, Bjp, Bj¬p, ¬Bjp, ¬Bj¬p} and it has six maximal subsets:
S = { {p, Bjp, ¬Bj¬p}, {p, Bj¬p, ¬Bjp}, {p, ¬Bjp, ¬Bj¬p},
{¬p, Bjp, ¬Bj¬p}, {¬p, Bj¬p, ¬Bjp}, {¬p, ¬Bjp, ¬Bj¬p} }
(Note that there are exactly some clauses in the view ϵ but we haven’t considered
them in this example.) So far we have considered all the possible states of a
Kripke structure. We must check which states satisfy the clauses in diﬀerent
views. Let C = vOi : true ⇒F be a clause, where F = f1 ∨· · · ∨fn and each
fi is a modal literal.
1. We move all but one of the disjuncts of F to the left of ⇒in clause C.
Without loss of generality assume f1 remains in the right hand side. Thus:
C = vOi : ¬f2 ∧· · · ∧¬fn ⇒f1.
2. We apply Oi to the clause and we obtain C = v : Oi(¬f2 ∧· · · ∧¬fn ⇒f1)
3. Based on axiom K we have v : Oi(¬f2 ∧· · · ∧¬fn) ⇒Oif1
4. This in turn implies v : Oi¬f2 ∧· · · ∧Oi¬fn ⇒Oif1.
5. We again move formulas from left of ⇒to its right side,
v : true ⇒Oif1 ∨¬Oi¬f2 ∨· · · ∨¬Oi¬fn.
The clause of step 5 is called a pushed clause (we have pushed Oi into clause)
and it is a pushed clause in the view v. If Oi = Bi and fj = Bigj, with j ̸=
1, then from the equivalence ¬Bi¬Bif ⇔Bif of the logic KD45 we obtain
¬Bi¬Bigj = Bigj = fj (so ¬Bi¬fj = fj). But if fj = l is a literal, then it will
remain ¬Bi¬fj. Similarly for Bif1. The reader can see that if in step 1 we keep
fj, j ̸= 1, on the right side we obtain another pushed clause. In summary we
have the following deﬁnition.
Deﬁnition 9. Let C = vOi : true ⇒F be a clause of view vOi. We deﬁne
C→= {v : true ⇒F ′} to be a set of clauses obtained after pushing Oi to
clause C. F ′ is obtained from Oi and F using the above algorithm. If vOi is a
view such that S = cl(vOi) = {C1, . . . , Cn}, then S→= C→
1 ∪· · · ∪C→
n is the
set of pushed clauses (in the view v) after pushing Oi.
For example suppose C = vOk : true ⇒l. Then C→= {v : true ⇒Okl} has
only one element. If C = vOk : true ⇒l1 ∨l2. Then C→= {v : true ⇒Okl1 ∨
¬Ok¬l2, v : true ⇒¬Ok¬l1 ∨Okl2}. Consider C = vBi : true ⇒l1 ∨l2 ∨Bil3,
then C→= {v : true ⇒Bil1 ∨¬Bi¬l2 ∨Bil3, v : true ⇒¬Bi¬l1 ∨Bil2 ∨Bil3}.
Here v : true ⇒¬Bi¬l1 ∨¬Bi¬l2 ∨Bil3 is a pushed clause also, but we may
ignore it as it is implied by the ﬁrst and second clauses. As a ﬁnal example
suppose C = vGi : true ⇒l1 ∨Bil2, then C→= {v : true ⇒Gil1 ∨¬Gi¬Bil2,
v : true ⇒¬Gi¬l1 ∨GiBil2}.

Layered Clausal Resolution in the Multi-modal Logic of Beliefs and Goals
555
Deﬁnition 10. Let ωn = O1. . . On be a sequence of n modal operators (|ωn| = n).
Let vωn be a view with the set of clauses S = cl(vωn) then S→n = S→(. . . (S→))
where →is applied n times, is a set of pushed clauses of the form v : true ⇒φ.
This intuitively means all modal operators of ωn consecutively are pushed to
clauses of S. Generally if λv = {vω | vω is a view with a nonempty set of clauses}
is a set of all nonempty views which include subview v, then we deﬁne the entire
set of pushed clauses of v as pcl(v) = 
vω∈λv cl(vω)→|ω|. Intuitively pcl(v)
contains all pushed clauses which are in view v.
Now we go back to the graph and ﬁnd the states which satisfy clauses of view
v for any v. We assign v to state s ∈S if label(s) |= cl(v) ∧pcl(v), i.e. s can
be in level v (it is accessible from one of the initial states via relation v) of the
graph if it satisﬁes the clauses and pushed clauses of v. If state s is assigned
more than one level (for example s is assigned v and v′) then we make one copy
of s for each combination of these levels and we assign that combination to the
labeling of the corresponding copy of s. For example suppose s is assigned v and
v′, then we consider four copies of s as: s1, s2, s3, s4, which are assigned by {v},
{v′}, {v, v′}, and {} respectively. The reason for this will become clear in the
proof of theorem 4. For a sketch intuition behind this, assume s ∈S belongs to
levels v1 and v2. Assume there is a state t ∈S which belongs to level v1Bi but
is not a member of level v2Bi. As we will discuss below this means we can not
make a Bi transition from s to t as t is not in level v2Bi, although t is in level
v1Bi. For solving this problem we make various copies of s with diﬀerent levels
assigned to them. For example the copy of s which is assigned only by v1 has a
transition to t. Finally we deﬁne level(v) to be the set of all states assigned v as
level(v) = {s ∈S | s is assigned v}.
Deﬁnition 11. For any agent i and set of modal literals X, Oi set(X) =
{ F | OiF ∈X}.
Now the set S of states is ready. The initial states are {s ∈S | s ∈level(ϵ) and
label(s) |= f} where f is deﬁned in the transformation process. We will ﬁnd the
accessibility relations Bi and Gi for any agent i. In the behavior graph we show
each relation by edges between states labeled by the name of the relation. We
add an edge from s to s′ labeled by Bi iﬀthe three following conditions hold:
a. If V = {v1, . . . , vk} is the set of levels assigned to s, then V B = {v1Bi, . . . ,
vkBi} is the set of levels assigned to s′ s.t. if vBi is a view with an empty
set of clauses, then vBi is omitted from V B. Also vjBiBi = vjBi.
b. label(s′) |= Bi set(label(s)) which means if label(s) |= BiF then label(s′) |= F
for any F.
c. BiF ∈label(s) iﬀBiF ∈label(s′) and ¬BiF ∈label(s) iﬀ¬BiF ∈label(s′),
which means s and s′ have the same set of beliefs involving Bi. This rule
guarantees Bi to be euclidean and transitive.
To ﬁnd Gi relations for state s we will ﬁnd all states s′ which satisfy only
conditions a. and b. replacing Bi with Gi. Now we will delete those states which
can not be a state in any model. If v is a view with a nonempty set of clauses,

556
J. Bagherzadeh and S. Arun-Kumar
but level(v) is empty, i.e. ¬∃s ∈S : label(s) |= cl(v) ∧pcl(v), then the set of
clauses does not have any model. In this case we will delete all the states of
graph, and we say graph is empty. Otherwise for any v with a nonempty set of
clauses, level(v) ̸= ∅. Now the graph is constructed. We can show the relations
Bi are serial, transitive, and euclidean and the relations Gi are serial.
Proposition 3.
1. The relations Gi in the behavior graph are serial.
2. The relations Bi in the behavior graph are serial, transitive and euclidean.
We could also prove the following lemma to ensure consistency between adjacent
levels.
Lemma 1. Let T be a set of NFBG clauses, and G be the behavior graph
constructed by the above process. For any node s of the graph, if ¬Oif ∈label(s)
then there is a node s′, s.t. (s, s′) ∈Oi and ¬f ∈label(s′).
The Above lemma and proposition show that the constructed graph is a Kripke
structure for the set of clauses. But there is a point which must be cleared
here. In the construction process of the graph, for each state of the graph in
level v, we checked if it satisﬁes clauses of view v (cl(v)) and pushed clauses
of view v (pcl(v)). The following lemma shows it is not possible that the set of
original normal form clauses to be satisﬁable while the set of clauses obtained
after pushing the modalities is unsatisﬁable.
Lemma 2. Let T be a set of clauses including a clause C in view vOi. Let
R = T ∪C→be the set of clauses of T and the pushed clauses obtained from C.
T is satisﬁable if and only if R is satisﬁable.
This lemma shows that pushing modalities into clauses preserves satisﬁability.
Finally we can prove that, for an unsatisﬁable set of clauses, the constructed
graph is empty, and thus there is no model.
Theorem 4. The set of clauses T is unsatisﬁable iﬀits behavior graph G is
empty.
Now we can prove the completeness of the method. The resolution rules are
complete if they can detect the emptiness of the graph. The graph is empty if
some level v (with nonempty set of clauses in view v) is empty. A level v is empty
if the clauses and pushed clauses of view v imply false. In the following we will
prove that our resolution calculus is complete.
Before proving the next theorem we will deﬁne two new resolution rules and
later we will prove that they can be eliminated. Assume F and H are modal
literals then resolution rules MRESC1 and MRESC2 are deﬁned as:
[MRESC1]
v : true ⇒D ∨OiF
v : true ⇒D′ ∨OiH
v : true ⇒D ∨D′
[MRESC2]
v : true ⇒D ∨OiF
v : true ⇒D′ ∨¬OiH
v : true ⇒D ∨D′
where in MRESC1, F and H are complementary, and in MRESC2, F ⇒H

Layered Clausal Resolution in the Multi-modal Logic of Beliefs and Goals
557
Theorem 5 (Completeness). Let T be a set of clauses and their pushed
clauses. Then T is unsatisﬁable iﬀthere is a refutation by resolution rules IRES1,
IRES2, MRES1, MRES2, MRESC1 and MRESC2.
Next we will prove that rules MRESC1 and MRESC2 are not necessary.
Deﬁnition 12. If F, F1 and F2 are modal literals and Oi ∈{Bi, Gi} then Rev
is deﬁned as:
1. Rev(¬OiF) = ¬F
2. Rev(OiF) = F
3. Rev(Bil) = Bil
4. Rev(¬Bil) = ¬Bil
5. Rev(F1 ∨F2) = Rev(F1) ∨Rev(F2).
Relation Rev(F) is the reverse of pushing modal operators (C→) into clauses.
Any pushed clause P in view v has a corresponding original clause C in view
vω s.t. P is obtained by pushing modalities of ω into C. Relation Rev takes
P and computes C. Note that for modal literals Bil and ¬Bil there might be
two reverses (depending on the other disjunct). For example, if we have clause
v : BiBjp∨¬Biq then its reverse can be either vBi : Bjp∨¬Biq or vBi : Bjp∨¬q,
but the ﬁrst one is not possible as it has two diﬀerent modal operators and second
one is the correct reverse. Using the relation Rev, we can prove the following
lemma which completes the proof of completeness.
Lemma 3. If two clauses of view v can be resolved with resolution rules
MRESC1 and MRESC2, then their corresponding original clauses can be re-
solved with resolution rules MRES1, MRES2, MRES3 and MRES4.
7
Conclusion and Future Work
In this paper we have deﬁned a framework for belief and goal bases and a reso-
lution based proof method for reasoning about them. We have also proved the
soundness, termination and completeness of the method.
There do exist tableau based methods for various modal logics in the litera-
ture (notably [12,17,3]). For certain modal logics such as S4, S5 and T resolution
methods exist [8]. Our method closely follows that of [6,7]. However we have ad-
vanced their work to include an additional KD modality while dropping the
temporal operators.
Our motivation however is not just to provide a proof system but instead to
tackle the problem of revision of an information store organized hierarchically.
The main feature of our method is the “locality” property enjoyed by our rules.
We have shown that it is necessary to consider complementary pairs of clauses
only at the same or between adjacent levels. This we believe considerably sim-
pliﬁes the tasks of belief and goal revision in order to keep the information store
consistent on fresh inputs. Secondly, it is no longer necessary to translate the
formulas into classical logic as is recommended by some authors [18,22,19,9].
However, even though we have combined the logics of KD45 and KD, we have
not deﬁned any interactions between them as it gets complicated to manage
using resolution rules. This is a subject of future research.

558
J. Bagherzadeh and S. Arun-Kumar
The idea of hierarchical structure for information store is taken (in some
sense) from Benerecetti et.al. [2]. More details of hierarchical structures and the
proposed logic can be found in [11,10].
Acknowledgment We thank the anonymous referees for some very insightful
comments.
References
1. C. Alchourron, P. Gardenfors, and D. Makinson. On the logic of theory change:
Partial meet contraction and revision functions. The Journal of Symbolic Logic,
50(2):510–530, 1985.
2. M. Benerecetti, F. Giunchiglia, and L. Seraﬁni. Model checking multi-agent sys-
tems. Journal of Logic and Computation, 8(3):401–424, 1998.
3. B. Bennett, C. Dixon, M. Fisher, U. Hustadt, E. Franconi, I. Horrocks, and M. De
Rijke. Combinations of modal logics. Artif. Intell. Rev., 17(1):1–20, 2002.
4. Brian F. Chellas. Modal Logic: An Introduction. Cambridge University Press, 1980.
5. P. R. Cohen and H. J. Levesque. Intention is choice with commitment. Artiﬁcial
Intelligence, 42(2-3):213–261, 1990.
6. Clare Dixon, Michael Fisher, and Alexander Bolotov. Clausal resolution in a logic
of rational agency. Artif. Intell., 139(1):47–89, 2002.
7. M. Fisher, C. Dixon, and M. Peim. Clausal temporal resolution. ACM Trans.
Coput. Logic, 2(1):12–56, 2001.
8. M. Fitting. Proof methods for modal and intuitionistic logics. In volume 169 of
Synthese Library. D. Reidel, Dordrecht. 1983.
9. A. M. Frisch and R. B. Scherl.
A general framework for modal deduction.
In
proccedings of KR, pages 196–207. Morgan Kaufmann, 1991.
10. C. Ghidini and F. Giunchiglia. Local models semantics, or contextual reasoning =
locality+compatibility. Artiﬁcial Intelligence, 127(2):221–259, 2001.
11. F. Giunchiglia and L. Seraﬁni. Multilanguage hierarchical logics or: How we can
do without modal logics. Artiﬁcial Intelligence, 65(1):29–70, 1994.
12. R. Gore.
Tableau methods for modal and temporal logics.
In M. D’Agostino,
D. Gabbay, R. Haehnle, and J. Posegga, editors, Handbook of Tableau Methods,
pages 297–396. Kluwer Academic Publishers, 1999.
13. Sven Ove Hansson. A Textbook of Belief Dynamics. Kluwer Academic Press, 1999.
14. A. Herzig and D. Longin. A logic of intention with cooperation principles and with
assertive speech acts as communication primitives. In Proc. ﬁrst Int. joint Conf.
on Autonomous agents and multiagent systems, pages 920–927. ACM Press, 2002.
15. S. A. Kripke. Semantical considerations on modal logic. In A Colloquium on Modal
and Many-Valued Logics, Helsinki, 1962.
16. I. Levi. Subjunctive, dispositions and chances. Synthese, 34:423–455, 1977.
17. F. Massacci. Single step tableaux for modal logics. Journal of Automated Reason-
ing, 24(3):319–364, 2000.
18. Robert C. Moore. A formal theory of knowledge and action. In J. R. Hobbs and
R. C. Moore, editors, Formal Theories of the Commonsense World, pages 319–358,
Ablex, Norwood NJ, 1985.
19. H. J. Ohlbach. Semantics-based translation methods for modal logics. Journal of
Logic and Computation, 1(5):691746, 1991.

Layered Clausal Resolution in the Multi-modal Logic of Beliefs and Goals
559
20. M. D. Sadek.
A study in the logic of intention.
In B. Nebel, C. Rich, and
W. Swartout, editors, Proc. Third Int. Conf. on Principles of knowledge Repre-
sentation and Reasoning (KR’92), pages 462–473. Morgan Kaufmann Publisher,
1992.
21. Y. Shoham.
Agent-oriented programming.
Artiﬁcial Intelligence, 60(1):51–92,
March 1993.
22. R. M. Smullyan. A generalization of intuitionistic and modal logics. In H. Leblanc,
editor, Truth, Syntax and Modality, pages 274–293, Amsterdam, 1973.

Author Index
Abadi, Mart´ın, 110
Albert, Elvira, 380
Aminof, Benjamin, 194
Areces, Carlos, 125
Arun-Kumar, S., 544
Ayala-Rinc´on, Mauricio, 433
Baaz, Matthias, 1, 481
Bagherzadeh, Jamshid, 544
Ball, Thomas, 194
Benedetti, Marco, 285
Benzm¨uller, Christoph, 415
Beringer, Lennart, 347
Berwanger, Dietmar, 209
Bickford, Mark, 449
Bordeaux, Lucas, 270
Cadoli, Marco, 270
Ciabattoni, Agata, 496
Constable, Robert C., 449
Dahll¨of, Vilhelm, 95
de Moura, Fl´avio L.C., 433
Di Cosmo, Roberto, 240
Donnelly, Kevin, 466
Drielsma, Paul Hankes, 363
Dufour, Thomas, 240
Eiter, Thomas, 511
Ferm¨uller, Christian G., 496
Fontaine, Pascal, 51
Gibson, Tyler, 466
Giesl, J¨urgen, 301
Gor´ın, Daniel, 125
Gr¨adel, Erich, 209
Halpern, Joseph Y., 449
Hardin, Chris, 224
Hasegawa, Ryuzo, 67
Hermenegildo, Manuel, 380
Hetzl, Stefan, 481
Heymans, Stijn, 169
Hofmann, Martin, 347
Hustadt, Ullrich, 21
Ianni, Giovambattista, 511
Jamnik, Mateja, 415
Kamareddine, Fairouz, 433
Kerber, Manfred, 415
Koshimura, Miyuki, 67
Krishnaswami, Neel, 466
Kupferman, Orna, 194
L´opez, Pablo, 528
Leitsch, Alexander, 1, 481
Linke, Thomas, 154
M¨odersheim, Sebastian, 363
M¨uller-Olm, Markus, 432
Magill, Stephen, 466
Mancini, Toni, 270
Marcinkowski, Jerzy, 142
Metcalfe, George, 496
Momigliano, Alberto, 347
Motik, Boris, 21
Nieuwenhuis, Robert, 36
Nordh, Gustav, 257
Oliveras, Albert, 36
Otop, Jan, 142
Park, Sungwoo, 466
Petride, Sabina, 449
Polakow, Jeﬀ, 528
Puebla, Germ´an, 380
Ranise, Silvio, 51
Richter, Clemens, 481
Sarsakov, Vladimir, 154
Sattler, Ulrike, 21
Schindlauer, Roman, 511
Schirmer, Norbert, 398
Schneider-Kamp, Peter, 301
Schweitzer, Stephan, 332
Seidl, Helmut, 79, 432
Shkaravska, Olha, 347
Sorge, Volker, 415
Spohr, Hendrik, 481
Stelmaszek, Grzegorz, 142

562
Author Index
Thiemann, Ren´e, 301
Tinelli, Cesare, 36
Tompits, Hans, 511
Umeda, Mayumi, 67
Van Nieuwenborgh, Davy, 169
Verma, Kumar Neeraj, 79
Vermeir, Dirk, 169
Vigan`o, Luca, 363
Walther, Christoph, 332
Walukiewicz, Igor, 184
Whitehead, Nathan, 110
Zarba, Calogero G., 51

