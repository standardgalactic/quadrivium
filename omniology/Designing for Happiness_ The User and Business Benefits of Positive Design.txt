
O’Reilly Media, Inc. 
 
1/19/2017 
 
1 
Technology as a Happiness Project 
It’s 2025. You are living in a house. Yes, that house. The pristine, white and glass, ultra-
modern, sustainable, smart home of the future. Objects are minimally designed with a 
layer of intelligence embedded deep within, or maybe with a projected layer of 
augmented reality. As you wander from one behaviorally and emotionally optimized 
choice to the next, occasionally enlisting the help of a chatbot here or a robot companion 
there, you never wonder if you are happy. Your chip implant monitors your brain 
chemistry, in tandem with a mood bot to give you a happiness boost when needed. You 
know, quantifiably, that you are happy.  
 
In the future, we are all better people. We are happy. And all our technology is positive. 
Well, maybe it doesn’t look quite like this example above though. What does it mean to 
design for happiness? 
We design technologies to make life easier, to make tiresome chores go faster, to add 
value to people’s lives. We strive for seamless interactions. We obsess over the details. 
We believe we are making the world a better place.  
Chances are if you are working in technology, you are something of an optimist. Now 
more than ever before, we want to do good in the world. More than just a motto, we truly 
want to do no evil.   
Rightly so. Think about how much of our lives are mediated or augmented by something 
digital. From the basics of getting from point A to point B or asking your partner to pick 
up some milk at the store to giving long-ago friendships new relevance and teaching your 
kids to code, technology is irrevocably mixed up with our everyday existence.   
And yet, we struggle with being human in the digital age. We sleep poorly, we have 
trouble paying attention, we feel isolated despite being more connected than ever.   
How can we have such positive intentions and yet see negative outcomes? Why isn’t all 
this new digital technology making us any happier?  
 
1 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
Maybe we just need to take a break from technology. We can even design technologies 
that block our access to technology temporarily. But, the fact that we need to detox from 
our technology is more than a little depressing. It implies that technology, whether how 
it’s designed or how we use it or both, is toxic. It presumes that there is a real life out 
there, separate from our digital life.   
So, maybe we need to design technology to get out of the way. Not a bad idea. 
Considering that many of our apps seem to be designed to demand our attention, this 
could be a move in the right direction. Much better than staring into the phones in our 
hands for hours at a time.   
Or maybe we can humanize technology. Actually, we are quite good at that already. 
Creating a personality for a website, or a chatbot, or a smartphone, is something we 
already do. Even if we weren’t designing personalities for our technology, we know 
people attach to technology anyway. What we are still figuring out is how to use 
technology to humanize humans.   
The truth is we have never designed technology with well-being, broadly speaking, in 
mind. We’ve designed for ease, productivity, engagement, and delight. Each has proven 
inadequate to really fostering well-being. What if we re-frame how we design technology 
to intentionally focus on happiness with a capital H?   
Rather than continuing to let our lives be shaped by technology—which will happen 
anyway—let’s reverse it. Let’s think about the lives we want to lead and develop 
technology for that. In the past decade, happiness has emerged as a subject of serious 
scholarship and experimental study. By investigating the everyday behaviors and 
decisions people make, psychologists and behavioral economists have learned a lot about 
happiness.   
So far, that knowledge has been applied to urban design, to personal spending, to national 
economies, but it hasn’t been applied to technology. That’s what this book is about. By 
paying more attention to the growing body of knowledge about happiness, we can 
develop technologies that cultivate well-being.  
To understand where we need to go, first let’s look back a bit.     
A Very Brief History of Technology and 
Happiness 
People will live in houses so automatic that push-buttons will be replaced by fingertip 
and even voice controls. Some people today can push a button to close a window – 
another to start coffee in the kitchen. Tomorrow such chores will be done by the warmth 
of your fingertip, as elevators are summoned now in some of the newest office buildings – 
or by a mere whisper in the intercom phone. 
This description comes from a Popular Mechanics article circa 1950, but it could just as 
easily apply (except for the intercom reference) to current day. Even though we might not 
mention happiness directly, it’s implied. The message is simple. If we can create the right 
technology and apply it in the right way, we can achieve a happier existence.   
 
2 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
You might say, technology has really always been about happiness. Technology has 
promised us happiness of one kind or another since the mid twentieth century. What does 
happiness mean when it comes to technology?   
Automatic for the People 
A good place to start this brief and idiosyncratic history of technology and happiness is in 
the 1950s. Post World War II, more homes than ever had electricity. Some people had a 
bit more money to spend. And new technology was focused on making mundane 
household tasks easier.  
Disney’s House of the Future, circa 1957 
 
 
Figure 1-1 Anchor’s House of the Future, circa 2015 
 
3 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
 
Figure 1-2 Include legend here. 
Push-Button Manor and a bit later, RCA/Whirlpool’s Miracle Kitchen and the 
Monsanto/Disney Home of the Future envisioned a home where “the things that women 
don’t like to do are done automatically.” Okay, I cringe a little at that. We’ve branched 
out a bit, and now we ‘d say that technology should do the things many people don’t 
really like to do.  If we look at how we envision future homes, the notion that unpleasant 
tasks should be automated is still a big part of technology’s promise of happiness. 
At the heart of this idea is automation. Automation had already been making markets 
more efficient and productive. Farming technology made it possible for a small number 
of farmers to produce food for a lot of people. Automated assembly lines meant that 
fewer workers could create more consumer goods of higher quality. Making it personal 
seemed like the next step.  
The idea behind automation, whether for business or no, is the same—eliminating 
mundane, routinized, repetitive tasks. Smart home products, for instance, take care of 
things we might forget, like turning lights off and thermostats down when we leave. Your 
Roomba takes care of the vacuuming so you can live your life.    
Although we worry about what we’ll do when robots take on all the work, part of the 
thinking behind it is that it will bump up the humanity of the humans. We will be able to 
engage in more meaningful activities that require empathy, creativity, and critical 
thinking.   
Tech happiness is automating the mundane to maximize the meaningful. 
The Easy Button 
If we skip ahead to the age of the personal computer in the 1980s, technology’s promise 
of happiness shifts toward productivity. It’s not exactly automating, but instead making 
common tasks achievable with less effort. Communicating with colleagues, creating and 
sharing documents, and many other work-related chores that were time-consuming were 
streamlined.   
Like automation, the business goal is the same—productivity and efficiency. On a 
personal level, it’s competence. Pulling a reference book off a shelf seems misguided 
when it’s easier to search for just about anything online. On-demand services like Uber 
 
4 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
and Blue Apron continue to push forward this idea of the easy life. Convenient and 
frictionless, these services save people time.   
Ease, as a guiding principle, applies to technology itself. Just as we make 
interactions with the world around us easier, technology itself is scrutinized and perfected 
until it becomes as easy as possible to use. Usability is foundational to good design.  
Tech happiness is reducing friction between ourselves and the world around us.  
How Technology Makes Us More, or Sometimes Less Productive 
Happiness and Productivity Infographic 
Superpowers for Everyone 
Another happiness promise that has dominated the last decade of technology is 
supplementing human capability using technology. Technology has always been about 
what it enables people to achieve and that’s become ever more personal. Beyond 
automating mundane tasks and making interactions external to ourselves easy, 
technology aims for our bodies and minds.   
The smartphone supplements our intelligence through omnipresent Internet access and to 
supplement our memory with photos or social networks. Wearables already offer 
improved health, from monitoring chronic conditions to pushing ourselves to get fit. 
Smart environments promise to boost up abilities for self-care for people who may have 
once needed a caretaker.   
Technology certainly amplifies our abilities. Almost as a byproduct it extends our 
identity. Sure, the technology we buy and how we present it—whether it’s a macbook 
covered in stickers or an old-school flip phone— says something about us to the world. 
But it runs deeper than that. What we post, who we follow, how we comment becomes a 
marker for who we are. We can proactively create avatars or try out different personas. 
We also spawn multiple identities online inadvertently. Technology extends our notion of 
self.  
Tech happiness is helping people be better at what they do, and maybe at who they are. 
How Technology Contributes to Our Sense of Self 
Happiness and Self Infographic 
 
The Extended Self 
The concept of an extended self has been around for a while. We know that the 
self is not fixed. That’s what makes us human in a way. We evolve. And a lot of 
that evolving happens because of the people, the pets, and possessions we bring 
into our lives.   
 
5 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
More than 100 years ago, William James pointed out that people consider their 
possessions to be a part of their self. Mihalyi Csikszentmihalyi (in his pre-flow 
work) describes how we attach to products as we create meaning with them. 
Sherry Turkle describes how objects become evocative as a companion to our 
experience. Consumer behavior researchers, like Russell Belk, describe this 
attachment as self-extension. The material things we bring into our lives become 
a part of ourselves. And our favorite things connect, remind, and reveal 
ourselves to other people in our lives.   
So, let’s think about music. Imagine it’s back in the 90s, and we are hanging out 
at your house. I’m wearing a thrift shop shift dress and purple Converse high 
tops, by the way. I’d definitely scan your CD collection. Not only would this be 
a conversation starter, but it would also tell me something about you. In fact, 
certain CDs might be core to your identity. After all, you probably chose to 
display Nirvana and Beastie Boys and to hide Vanilla Ice.  
Today, maybe I’d look at a playlist instead but the idea remains. The music acts 
as a cue for me to form an impression about who you are. More than that, it is a 
way for you to define who you are in the moment, and as you go along.  
In some measure, we are what we own. Perhaps this is why Marie Kondo’s The 
Life Changing Magic of Tidying Up (2014) hit a nerve. As Kondo succinctly 
notes, “The question of what you want to own is actually the question of how 
you want to live your life.” It’s not as shallow as acquiring status symbols. 
Instead it helps us figure out where we fit in and who we want to be.  
Beyond the purchase of the latest iThing, where does technology fit into this 
idea of extended self? This idea of extended self seems like it’s about stuff. 
Technology is not so much about the object itself, right?  
Well, yes and no. We become incredibly attached to our smartphones even if we 
don’t think about it as an extension of self (yet). When studies report teens 
having anxiety about being separated from their phones or that we all touch our 
phones hundreds of times a day, it seems like we are addicts. When fMRI 
studies reveal that our phones light up the same centers in our brain as love, this 
seems a little foolish. The idea that our phone is an embodiment of who we are 
doesn’t come into the discussion. It’s viewed as something outside. That’s how 
we use it and that’s how we design it.  
In one of my own research studies, listening to over 100 people give me a tour 
of the phone, each little icon opens up a big world. As Jamal put it, “my phone is 
really about who I am in this moment, and who I was, and who I want to be, it’s 
not really about watching videos and looking up facts.” It’s not just re-
embodiment as an avatar, or a virtual possession in a game of Farmville. It’s an 
extension of who we are. I wonder if it isn’t a mistake to consider technology 
only as something outside ourselves at all.  
A fundamental tension between technology of any kind—whether a fitness 
tracker, or an app, or an AI assistant—is this line we tread between technology 
as me and not me. Is it my sassy sidekick or my deepest self? Is it a means to an 
end that exists somewhere offline (whatever that is) or is it a mode of self-
reflection? It’s both. This is fundamental when we design for big picture well-
being.  
 
6 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
Technology as Connective Tissue 
In the aughts, technology really started to underpin our relationships. Emailing was 
already part of everyday work life. Now texting becomes part of a day-to-day social 
interactions with friends and family. Social media brought people back into our everyday 
circles. Our Facebook conversations are a jumping off point for real conversations. 
Sharing small moments or big accomplishments adds a layer of nuance and depth to 
personal relationships. So much so that it’s hard to imagine relationships that aren’t 
supported by technology.  
At the same time, weak ties became more important. While research shows we only have 
a certain number of true friends (which I’ll interpret as close ties), we can and do bring 
people into our lives on a broader and perhaps not quite as close basis. Acquaintances 
we’ve met once or twice, people whose opinions we value, people who live nearby, 
groups of people who share our interests—all consequential strangers. These weak ties 
connect us not just to people, but to ideas and the world.  
Connection is at the heart of well-being, in study after study. Strong relationships 
contribute to healthy and happy lives. And technology is the glue holding those 
connections together. 
Tech happiness strengthens relationships and foster the kind of weak ties we take for 
granted in other contexts. 
The Best Intentions 
While it may not always be an explicit goal, technology promises happiness by 
automating unpleasant or mundane chores, making our lives easier, augmenting our 
abilities, and, more recently, by connecting us to other people. This may seem obvious. 
It’s why you and I got into this field in the first place. Technology’s big goal is to make 
the world a better place and a big part of this is making people happy in a deep way.  
Despite our best efforts, technology has not always or not even consistently had a 
positive effect. In academic research, studies abound on the negative effects of 
technology on ourselves and our relationships. In popular culture, our smartphones have 
become a nexus of cultural critique. Letting technology into our lives has had unintended 
negative consequences.    
Addicted and Conflicted 
As much as technology implicitly strives for well-being or actually contributes to well-
being, that isn’t always the result. When we aren’t busy tweeting, checking in, emailing, 
and ruining tons of pictures with crappy filters, we suspect we might be miserable. We 
are pretty sure technology is to blame.  
Research makes a convincing case. The damage caused to our bodies and minds by our 
time online is well-documented. While internet addiction is not included in the latest 
version of the Diagnostic and Statistical Manual of the American Psychiatric Association, 
study after study finds strong positive correlation between heavy smartphone use and 
anxiety, depression, and other symptoms of mental illness. Video games may have some 
cognitive benefits, but they can also increase social anxiety. Social media is chipping 
 
7 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
away at self-worth, especially for teens. Staring at our smartphones is damaging our 
spines and disrupting our sleep.   
Here’s just a sample of recent studies: 
• 
Excessive internet use predicts school burnout among teens 
• 
Social anxiety among internet addicts 
• 
Cognitive performance when iPhones are out of reach 
• 
Text neck as a result of chronic slouching over screens 
• 
Neuroimaging suggestive of behavioral addictions 
Academic studies focus on the negative effects of technology, and that tends to spiral into 
negative press. In the media, talk about technology can be a lot of gloom and doom. Say 
goodbye to your job, it’s going to be automated. Selfie obsession is the surest path to 
narcissism. Smartphones make us behave rudely to our friends. Your attention 
span…wait what?  
We don’t need to read about technology’s ill effects though. We feel it. Maybe we are not 
so great at estimating how many times we check our phones (it’s actually double what we 
think according to some research). But we know that we find ourselves spending too 
much time on YouTube and not enough time with our families. As a parent, I’ve had that 
moment of reckoning, actually many moments of reckoning, where my daughters call me 
out on my own tech infatuation. 
That out of control feeling frames our experience of technology. Technology in popular 
culture is about unhappiness, from everyday distraction to a deep pathological misery. 
Mostly, when we talk about our life with tech it’s in terms of addiction.   
The Negative Effects of Tech 
Infographic 
Internet Addiction? There’s an App for That 
[Friend pulls out phone] Ugh, I’m so addicted. 
[At dinner with a group] It’s funny how we are all so addicted. 
[In the middle of a conversation] It’s hard to pull myself away, I feel like I’m addicted. 
People used to joke, with a hint of pride, about their crackberries. Now we compulsively 
refresh our email, all the while longing to achieve inbox zero. We mean to spend a few 
minutes on Facebook and end up spending an hour. We are a little foggy from binge 
watching the latest Netflix series. Then there’s notifications.   
Addiction is the story we tell ourselves, and take for granted, about technology. As a 
researcher, I hear this more often than most people. It’s actually difficult to remember a 
research session where I haven’t heard people speak about technology as an unhealthy 
obsession. Internet addiction is a real condition, a matter of debate, and widely accepted 
universal state of mind.   
 
8 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
But what are we addicted to anyway? Is it the phone itself? Some studies make the case. 
We get pangs of anxiety when separated from our phones. 
Other studies suggest that we are less focused when our smartphone is nearby. Our brains 
flood with oxytocin when we hear our phones — we may literally love our iPhones. 
Even the sound triggers love and loss. The object, security. 
Or are we addicted to the content, interactions, the stuff of the app? It’s difficult to 
untangle the device from the app from the content. Entrepreneurs study addictive 
behavior, after all, to help create it. Product teams work hard to engage us, hijacking our 
time.  
Social media, in particular, has been declared addictive in studies and by experts. A 
friend likes your photo, another comments on your post. Maybe we are addicted to the 
approval we get?   
Perhaps we are simply addicted to distraction itself. Like gamblers who get in a 
“machine-zone”, we are caught up in the rhythm of a repeating process. An alternate 
reality flow state.  
Addiction might be a little strong, but it captures the gravitational pull we feel toward our 
tech and away from “real life”. Happiness research shows that the more we stray from the 
moment, the less happy we are. It doesn’t seem to matter much whether the task is 
enjoyable or not, just that we focus. Our experience of technology seems to take away 
that focus, or just shift it toward the wrong thing. 
Addiction, especially feeling out of control, is part of the inner narrative we whisper to 
ourselves and shout to each other about technology.  
 
Internet Addiction 
Internet addiction disorder (IAD) goes by many names. Problematic internet use 
(PIU), compulsive internet use (CIU), and even pathological internet use. 
Internet addiction is used loosely in pop culture to describe the negative feelings 
we have around technology, especially feeling out of control. After all, addiction 
is a compulsive behavior that interferes with relationships, work, and health. 
Compulsive behavior seems an integral part of our experience with the internet.   
At the same time, internet addiction is being studied as a real condition. Internet 
addiction is considered an impulse control disorder, characterized by many 
hours spent in non-work technology-related activities. While Internet Addiction 
Disorder is not officially recognized in the American Psychiatric Association’s 
Diagnostic and Statistical Manual of Mental Disorder V (DSM-V), other 
behavioral addictions are included. Gambling addiction, for example, is a recent 
addition. Internet Gaming Disorder is flagged for further study.  
It takes several decades of extensive research to make the cut. So far, there isn't 
enough systematic, longitudinal data about internet addiction. Scientists are 
actively studying the negative effects of internet use, though, particularly 
adolescents who seem to be most vulnerable. 
 
9 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
Pinning down a quantifiable, negative effect of internet use is tricky.  With 
gambling, you’re losing money and causing harm to yourself and loved ones. 
With internet use, the negative effects are less direct.  Whether internet addiction 
can be teased out from other behavioral addictions is a matter of debate. It may 
be that gamers game, shoppers shop, and gamblers gamble no matter the 
medium. Preoccupation with the internet, inability to control the amount of time 
spent online, withdrawal symptoms when not engaged seem like other 
behavioral addictions but could be a symptom of depression or anxiety, too.  
Substance and behavioral addictions do seem to trigger the same mesolimbic 
dopamine pathway in the brain. That means that behaviors like gambling 
activate the brain’s reward circuitry. While there hasn’t been much study of how 
internet use affects brain chemistry, behavioral design references the language 
of trigger and reward. Designers and developers are tasked with attracting and 
keeping as many customers as possible, often leveraging psychology, and 
derivatives of Skinner’s methods in particular, and neuroscience. 
Cause or symptom? Internet addiction may be classified as a condition or not. 
What we know for sure is that we feel an unhealthy pull toward technology. We 
often use technology in ways that don’t seem to make us happy. Addiction 
has become  part of the story we tell ourselves about our relationship with 
technology.  
To me, this seems like an opportunity to turn things around. Despite the rapid 
change, we are still in the early years of the internet. There’s still time to change 
the story. 
The Eat, Pray, Love Approach to Technology 
When it comes to technology, we greedily feast on the unlimited variety that technology 
brings. We watch just as much TV as ever, but now we are online for hours each day too. 
If Virtual Reality (VR) becomes mainstream, there’s no reason to expect that we won’t 
just add on more hours to our tech consumption. We can’t seem to stop ourselves.  
Then we feel guilty. It’s hard to go through a day without a nagging feeling that we are 
spending too much time online. We are reminded that rather than liberating us, maybe it’s 
holding us back.   
So the advice we hear is to take a break from technology. It seems to make sense on a 
visceral level. If you want to find the happiest people, that aren’t all from Scandinavia. 
You can look at the Amish. Depression rates are low, happiness ratings are high. Not 
much technology. The comparison is a little simplistic, of course. Even so, the imagined 
simplicity of a life without technology is appealing.   
Look to psychology and you find similar answers. The primary way to deal with a 
behavioral addiction is to remove the triggers. Cancel the credit cards, avoid casinos, 
steer clear of people who engage in these behaviors with you. 
So what does this mean when it comes to technology? Shut down your computer? Stay 
away from your phone? You can’t disconnect and function in the world. Work, classes, 
parenting, our day-to-day lives all rely on technology. Working in tech, I’ve found it 
especially difficult to stay away from tech.  
 
10 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
We could use technology to minimize all the technology, calming the symptoms of heavy 
internet use with more internet use. Apps like Cold Turkey can help us go cold turkey, at 
least for twenty minutes. Products like Vinaya’s Altruis manage notifications for the 
fashionable, and affluent, few. 
In the future, maybe technology won’t be all about screens, and that will solve the 
problem. After all, when technology gets out of our way, or at least out of our hands, we 
should be able to focus again. But all signs point to no. Whether no screens, or lots of 
really tiny screens, it’s likely that getting the phone out of our grasp will not solve 
everything. In truth, more technology is another part of what makes us unhappy.   
A detox suggests that technology, or at least the way we use technology, has become 
toxic. Even so, we don’t talk about rehab, or interventions. We are a bit stunned by the 
severity of Chinese internet addiction camps. We rarely hear of friends in therapy for 
issues of internet addiction. Instead, we detox, like we would after a treat-filled holiday 
season. We indulge, we cleanse, we hope to restore balance.   
While there is plenty of evidence that we are a little stressed from our technology, there is 
not really any evidence of a digital detox having short-term or long-term positive 
effect. So while I’ll encourage you not to be too involved in your Facebook comments 
(guilty) or to look up at your children rather than stare at your screen (guilty again), it 
won’t solve everything.  
Taking a detox isn’t likely to restore a state of well-being with technology, but so far it’s 
the only strategy for well-being when it comes to technology. 
The Relentless Pursuit of Next 
We hear a lot about the new life-changing features of the iPhone 7, or excited projections 
about which company will be the next Uber or Tinder or Medium, or even 10 hacks for 
extending our battery life. Products, features, cool designs, things to buy or sell—this is a 
big part of the technology story. Technology's story is the next new thing and how that 
new thing will make our lives happier.  
One of the key insights of happiness studies is that people have a very hard time being 
content with what they have, especially when they know that others have more. So when 
you buy the latest iThing, you do so knowing that in a few months there’s going to be a 
better, faster version. And that you’re going to be stuck with the old one. It’s as if 
disappointment were built in from the very beginning. We metabolize our tech purchases 
so rapidly, that the happiness last only a short time.   
The pursuit of next keeps us running on a hedonic treadmill, where each purchase 
promises happiness but ultimately disappoints. It also clogs our basements and landfills 
with layers of junk we regret. Our smartphone home screens fill up with candy-colored 
icons in much the same way. Focus on next rather than now encourages a perpetual 
restlessness.  
The rapid pace of technological change encourages us to focus on the next new thing, 
rather than enjoying what we have, which is a recipe for unhappiness. 
 
11 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
Dehumanizing Humans 
Oh, the irony. Just the thing we love about technology, that it makes us feel competent, 
can also be the thing that makes us miserable. Incorporating human skills into a 
machine—called “blackboxing” because it makes its inner workings invisible to the 
user—allows people to do more with investing less time and effort. With your phone, you 
can make a movie, buy a car, or track your vital signs. All things that used to require a lot 
of hard-won knowledge. So putting the expertise in the machine lowers the barriers to 
entry. A plus. If those technologies break or disappear, a negative.   
So, we depend more on our technologies than ever before, but we can do more than ever 
before. Collectively and individually, technology has made us smarter, more capable, and 
more productive. On the flip side, we might understand less about what we are doing. 
Think about how we use GPS. While I may still enjoy looking at a map and day dreaming 
a little, I rarely use a map to navigate. In truth, for all my complaints about GPS and there 
are many, I would have trouble relying only on a map to drive from well-known point A 
to unfamiliar point B.  
Blackboxing translates into a bigger fear, replacing people with machines. Artificial 
intelligence is starting to replace jobs, even “knowledge” jobs in multiple industries. 
Expert radiologists are routinely outperformed by pattern-recognition software. Many 
aspects of the legal profession or being automated by companies like Rocket Lawyer. 
Companies such as Narrative Science can replicate the work of human journalists.  
Research tells us that unemployment indeed has a harmful impact on well-being. The 
experience of unemployment hits people so hard that they don’t always feel as happy as 
before even after getting a new job. Having a purpose, using and refining skills, and 
feeling in control are crucial to happiness. 
Happiness research suggests that challenging ourselves and meaningful work are 
fundamental for well-being. Does more automating help us achieve a flow state by 
getting the boring stuff out of the way? Or does it take away work that helps us find 
meaning and purpose?   
Automating has its downsides, particularly if it takes away meaningful work.    
Social Distortion 
Didn’t I just put connection in the happiness category a few pages back? Just as 
technology contributes to our happiness, well, it can also contribute to our unhappiness. 
This is the case with our relationships too.  
Almost since social media came to be, it’s been studied for negative effects, among them 
social comparison, fear of missing out, and bullying or worse, much worse. I’ve 
interviewed teens, who delete more than they post, often dropping their accounts entirely 
due to bullying. I’ve witnessed bad behavior under the “protection” of anonymity. I’ve 
listened to stories of harassment that is becoming disturbingly commonplace. Policies 
have not caught up with practices, and design for well-being alone won’t solve this. 
But there’s also the mundane everyday misery of social comparison to consider. We’ve 
all felt this from time to time. One thing that’s clear from the latest happiness research is 
that social comparison makes us unhappy. And social media, with all the perfect 
 
12 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
vacations and beautiful babies and romantic gestures, can make social comparison a daily 
routine rather than an occasional rumination.  
Social media also can encourage thinking about others in terms of endorsements or 
obligations. Posts to like, comments to make, people to follow define relationships in a 
tightly circumscribed way. Between three-dot anxiety and the 11-like threshold, 
technology can reinforce the worst of our social fears.  
Social media can end up distorting and diminishing our relationships, as much as 
supporting them.    
How Technology Makes Us More, or Sometimes Less Connected 
Happiness and Relationships Infographic 
 
Fragmented Self 
Technology stretches our experience of identity. We saw how this can be a positive thing, 
allowing for experimentation and augmenting our abilities. Our experience of our online 
selves is often piecemeal too. Out of concern for our privacy, we adopt different personas 
in different contexts. We can control what we post and how we present our self to the 
world to some degree, even if it’s a little burdensome to have to think about this public 
doppelganger. 
Some aspects of our online self we can’t control so well. More and more of our 
experience is created by what we’ve done before—how we’ve browsed, what we clicked, 
who we’ve followed—and yet it doesn’t feel much like who we are. When the algorithm 
doesn’t quite sync up with who we are, it’s a problem. “It’s like another me made from 
clicks and likes. So, it’s half-formed and honestly pretty strange,” according to Matt, who 
spoke with me during a recent research study. So far, we don’t have a real way to 
understand this version of our selves or how to shape it to who we are becoming.   
Our sense of self is limited by a certain inflexibility in how we can engage with it online.    
Unintended Consequences 
Just as technology can make lives easier or simplify complex tasks, it can also have 
negative consequences. Let’s go back to the 1950s again. Think about air conditioners. 
Yes, they made certain areas of the United States more livable in the summer. But they 
also meant less time spent sitting in the shade of a porch participating in neighborhood 
life. Once more people adopted air conditioning, house designs no longer favored 
porches. So, the unintended consequence of air conditioning for private homes turned out 
to be more isolation rather than community.   
With any technology, sometimes the good intentions we begin with don’t play out once 
the technology is released into a complicated ecosystem. People adopt their own practices 
and generate their own meaning around technology. This doesn’t mean we shouldn’t aim 
higher. After all, there is some evidence that internet and computer-related technology is 
actually contributed positively to well-being.  
 
13 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
The Global State of Tech Happiness 
Well-being seems to be a central goal for technology, even though we don’t necessarily 
shout it out loud. Ideas about how technology makes us happy are implicit in the 
technology we create—whether because it makes life easier or it helps us to be more 
awesome and more connected. But does technology actually contribute to the good life?  
We don’t really know for sure. Until the last decade, economists measured well-being by 
proxy. Measuring wealth at a national level has served as a way to stand in for 
happiness. If we’re richer, the thinking goes, we have more options and so we must be 
better off. That hasn’t turned out to be true. The wealthiest countries are not always 
ranked as the happiest. For individuals, happiness levels off at a certain amount of 
income. Even so, we still might find it hard to believe that more money means greater 
happiness.  
 
Measuring Well-Being on a Large Scale 
Money isn’t everything. But for measuring national success, it has pretty much 
been the only thing (other than sports). Since World War II, the dollar value of a 
country’s economic output has been the measure of success.  
While it’s great for measuring short-term fluctuations, it’s limited in a lot of 
ways. For one, it still misses a lot of things that have economic impact. It 
measures commodities, but not capabilities. Tim O’Reilly (yes, the eponymous 
O’Reilly) drew that conclusion too when he applied Stuart Brand’s clothesline 
paradox to the tech economy. You put your clothes in the dryer and the energy 
used gets measured. You hang your clothes on the clothesline and it disappears 
from the economy. Open source software, for instance, creates a lot of value. It 
may be the foundation of apps, but that value is not captured directly.  
National leaders have been looking to other metrics for success. That’s when 
happiness started to come into the equation. In the early 1970s, economist 
Richard Easterlin pointed out that national happiness polls did not correlate with 
per capita income as expected. The Easterlin Paradox means that beyond a 
certain level, rises in income over time fail to increase happiness.    
Around the same time, Bhutan proposed Gross National Happiness (GNH) as a 
supplement to the GDP. The feeling was that the GDP was not a great proxy for 
a good life. Instead, looking at subjective well-being in tandem with health, 
education, good governance, conservation of the natural environment could be a 
counterpoint to economic growth. The United Nations’ Human Development 
Index followed suit in the 1990s. The Organization for Economic Co-operation 
and Development (OECD) has released a well-being index, Better Life 
Initiative, every year since 2011.   
 
14 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
How can you measure happiness anyway? Mostly, you ask. I know what 
you’re thinking. In the design world, we are suspicious of asking. People can’t 
always articulate what they are thinking or feeling. While that may be true when 
interacting with a prototype, there are lots of valid research methods that rely on 
people answering questions about themselves. Plus, it turns out you can use 
magnetic 
resonance 
imaging 
to 
measure 
cerebral 
blood 
flow, 
or 
electromyography to measure the activity of the “smile muscles” in the face but 
those measures are highly correlated with self-reports for happiness.  
Happiness itself seems a little squishy, but the approach to measuring it has 
become more and more sophisticated. First, both in the moment and reflective 
questions are combined to understand subjective well-being. The Cantrill Ladder 
is one standard question but the Oxford Happiness Inventory and the Panas 
Scale show the range of questions designed to capture happiness on emotional, 
behavioral, and cognitive levels.  
Second, happiness indexes take into account multiple measures, sometimes 
drawn from multiple sources. Think a dashboard of indicators rather than a 
single number. More than just a feeling, happiness with a capital H takes into 
account other contributors to well-being including community, environment, 
health, and a number of other factors (see table x). 
Using social media as an indicator of community well-being has been tried too. 
University of Vermont’s Hedonometer assigns a happiness score to certain 
words and then monitors about 10% of all posts to Twitter. While it’s an 
imperfect sample, it seems to correlate to many subjective well-being surveys 
and is more sensitive to changes over a given time period.   
Clearly, the GDP doesn’t account for many of the things that make life 
worthwhile. For now, there’s no single well-being or national happiness index 
though, no big number like the GDP to tie it all together. That makes it harder to 
track and adopt. And that’s why you might see different country rankings 
reported at different times of the year.   
For our purposes, designing technology for happiness, there aren’t a lot of 
directly applicable measures. Or, maybe it’s just difficult to tease them out. 
Community, could have an online component even when we think of local 
neighborhoods. While I have a strong sense of community in my small Hudson 
Valley NY town, it is strengthened and extended by Facebook parent 
communities, the local freecycle site, and even the school’s rather 
lacking “portal." 
Despite the complications, current approaches to measuring personal 
and collective values can be a good model for building well-being with 
technology. If we accept that what we measure ends up being what we cultivate, 
then it seems like a good way to start. I’ll talk about that in greater depth in 
chapter 4. 
Greater wealth is generally associated with greater access to technology, too. So, you 
would think that happiness and techiness might be somehow connected. Ask your teen 
daughter or your mother or almost anyone else if the latest iPhone will make them 
happier, and the answer will be a definite yes. Just as we tend to equate more wealth with 
greater happiness, we also tend to think that more technology can lead to more 
happiness.   
 
15 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
So far, there is not a lot of evidence to fall back on. Some global surveys like Gallup 
World Poll measure access to technology, in addition to happiness, healthcare, 
community, environment, and a number of issues related to overall well-being. In other 
studies, like the Organization for Economic Cooperation and Development (OECD) 
Better Life Index, it’s not yet measured separately at all. What we can do instead is to 
pull together a meta-analysis of global happiness measures and cross-reference it against 
other technology measures for countries.   
While happiness, or life satisfaction, or well-being, is measured with multiple indicators 
(more on that in the sidebar), let’s just keep it simple for now. Let’s use the self-reported 
answers to the Cantrill Ladder prompt, a standard question in well-being surveys: “Please 
imagine a ladder with steps numbered from zero at the bottom to 10 at the top. The top of 
the ladder represents the best possible life for you and the bottom of the ladder represents 
the worst possible life for you. On which step of the ladder would you say you personally 
feel you stand at this time?”   
I’ll take the answers to this question from the most recent World Happiness Report and 
cross reference that with a few measures of “techiness", like access to broadband and use 
of personal technology, reported in the International Telecommunications Union annual 
report, Measuring the Information Society.  
How Happiness Relates to Tech Access 
Happiness and Techiness Chart 
Looking at measures for global happiness and how they intersect with access to 
technology above, the correlation is clear. Other researchers, looking at the Gallup World 
Poll corroborate. Access to technology does have a positive relationship with 
happiness. Nations 
that 
are 
more 
technologically 
advanced, 
including 
greater broadband access and more citizens with devices in their homes, are happier.  
A rapid digital acceleration may also be linked to happiness. For many Latin American 
nations happiness and tech access have simultaneously been on the rise. The rapid 
increase in mobile adoption may be contributing to an overall sense of well-being. Where 
there was little access to technology before, an increase in access or possibly even a 
promise of access may be connected with an increase in reported happiness.   
Don’t go out and buy more devices and upgrade all your tech just yet though. Access to 
broadband and personal devices like smartphones contributes positively to happiness. As 
a basic utility, technology bumps up happiness. But it’s not clear whether more 
technology will create more happiness.  
Up to a certain point, which seems to be about $75K in the US, money contributes to 
happiness. Maybe because money covers those basic needs at the bottom of Maslow’s 
hierarchy like food, shelter, safety. Then happiness levels off. More money doesn’t mean 
more happiness. It may be that access to technology levels off at a certain point too. 
The way a country governs technology also may be tied to happiness. 
Scandinavian countries, among the happiest, tend to have a regulatory authority that 
protects consumer interests and encourages a competitive market. An approach to 
technology that is geared toward the collective well-being of a society may have an 
impact on personal well-being for individuals in that society.   
 
16 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
So, one way to increase well-being with technology is to improve access. Another is to 
cultivate trust and transparency in how technology is regulated. No small order.   
More than just a silicon and cables and code, when it comes to personal well-being, it is 
mostly about how technology becomes a part of our lives. Happiness is in the experience 
of technology. Technology enables communication, socialization, learning, growth. 
That’s something we assume to be true, and can guide us as we try to develop it further.  
Trending Toward Happiness 
Positive intentions aside, there’s some evidence that technology is actually aligned with 
our well-being. There’s also a lot of evidence that it is chipping away at our well-being. 
How do we create technologies that are more apt to cultivate well-being? It’s a tricky 
question. And it may mean a shift in the current focus on problem-solving. 
The Problem Problem 
Competence and autonomy, the hallmarks of our current vision of tech happiness, are at 
the core of all our methods. In truth, it’s a kind of mantra. “Design must solve problems,” 
we reaffirm. Design thinking, now wholeheartedly adopted by organizations of all kinds, 
is adopted as a problem-driven approach. Organizations tend to practice design thinking 
by starting at an undesirable situation and then imagining how to resolve it in an ideal 
future. Our customer journeys aspire to move people from pain to pleasure.   
Focusing on solving problems, what Evgeny Morozov calls “solutionism” when taken to 
extremes, does not always lead us to positive and worthwhile experiences. Making 
something difficult easier doesn’t always make us happy. Actually challenges often make 
us happy, whether we get in a flow state through satisfying work or helping us develop 
our own meaning from the experience. By removing all friction, we remove moments for 
personal growth, serendipity, and self-reflection. At scale, these may start skew our lives 
towards intolerance and impatience, a lack of resilience, and an inability to navigate 
change.  
Lately, we’ve started to confront a bigger question, too. Problem-solving for whom? A 
while back, this quote by Startup L. Jackson was making the rounds, "The Uberfication 
of everything is turning San Francisco into an assisted living community for the young.” 
Uncomfortably funny. All this problem solving may be designing growth out of everyday 
experiences and focus on problems that aren’t really that big after all. How will the new 
economy engage and support the least visible among us? How can we move from sharing 
economy to caring economy?  
Tap, Scroll, Repeat 
The problem-solving approach, in some contexts, introduces another complication. It can 
be directed at filling empty moments that might be a little uncomfortable or just boring. 
Texting for a minute feels better than standing in line. Listening to a podcast feels better 
than a walk in silence. So rather than a vitamin, we learn how to design a pain killer.  
Using B. F. Skinner’s model of trigger and variable reward, websites and apps encourage 
repeated use. In response to so much pressure to grow we measure success in clicks and 
 
17 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
page views. Design blogs do a great job of documenting techniques for making 
experiences frictionless and getting attention. Endless scroll, auto-play, default settings, 
and even menu choices increase engagement but maybe at the expense of personal well-
being. 
Now, we may be so good at this type of behavioral design that experiences are starting to 
elicit compulsive behavior. So much so that Nir Eyal, who popularized this model in his 
book Hooked, has cautioned technologists to consider the consequences.  We may be 
solving problems a little too well, as it happens. 
A Wellness-Based Approach 
We can maximize productivity. We know how to make technology easy to the point of 
disappearing into the background. We certainly know how to get people to click. But do 
we know how we can maximize well-being?  
The disconnect between positive intentions and not-always-positive outcomes is 
prompting new approaches to designing technology. Solve CoLab and Games for Change 
create technology that is more socially relevant and purposeful. Time Well Spent is a 
movement toward minimizing distraction caused by technology. Value by Design and 
Slow Design encourage an intentional focus on long-term meaning over short-term 
interaction.   
Convergence of Design Trends 
Positive Design Trends 
More and more people who work in technology are beginning to take well-being in to 
account. Sometimes directly. Certainly there are apps for physical health as well as plenty 
of options for psychological well-being. Apps, like Happify and Talkspace, employ a 
range of interventions drawing on cognitive behavioral therapy and positive psychology. 
Likewise, Headspace and the growing number of mindfulness apps encourage people to 
be reflective.   
But we need a new model — a wellness model. Psychology (and medicine, in general) 
has shifted focus from surviving to thriving in the past decade. Researchers have begun to 
study how flow, gratitude, and compassion can get people beyond a neutral state to well-
being. Here is groundwork for understanding how our relationship to technology can 
move beyond a neutral state.  
In designing technology, we still need to address pain points, but should devote more 
thought to the well-being of the whole person on the other side the screen. Not just 
as users of technology, but as individuals living complicated lives and striving toward 
better health, creative outlets, and fulfilling relationships. Not just having, or doing, or 
even feeling in the moment, but becoming. 
Designing for happiness, or Positive Design after positive psychology and the net 
positive effect it produces, is not restricted to material, short-lived pleasures but also to 
other elements of personal and collective well-being. So how do we design differently? 
So far, there is a lot of encouraging movement in the design world. In the following 
chapters, we will look at how to build on what we already do well to formulate a new 
model. 
 
18 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
Field Note: Tech Highs and Lows 
Because misery and addiction seemed to dominate our way of thinking about technology, 
I was determined to study what might make us happy about technology. One way I tried 
to understand this was by documenting highs and lows.  
Really, at first, I had maybe naively wanted people to submit their peak moments with 
technology. As it turns out though, it was difficult to get below the surface of likes and 
lolcats. Once people were asked to think about highs and lows, something shifted. Just as 
we know that a positive emotion like pride is connected with a negative emotion like 
shame, so it seemed that technology’s best moments were connected somehow with the 
worst. Maybe it’s like a vacation, where some of your worst moments might end up being 
your best memories.  
Over the course of a month, my research team had diverse group of 50 people—diverse 
in abilities and baseline happiness level as well as ethnically and geographically 
diverse—keep an online diary of highs and lows. Each person would submit a picture, a 
description, and answer some questions about the emotions associated with the moment 
and tell us why they felt that way. 
Some of those moments are what you might expect. A funny app with talking animals, an 
uplifting story, a picture of a grandbaby. More often, it went much deeper than that. 
Moments of stolen intimacy with a loved one, moments of meaningful connection, 
sharing mundane everyday details and small personal triumphs were universals. And 
there were unexpected moments too. Creativity felt in Snapchat crowns and Spotify 
playlists. Personal growth, ranging from Timehop to Duolingo, was clearly important.  
Examples of Peak Happy 
Diary snapshots of peaks 
While people did feel happy when they were entertained, people felt happiest when they 
were creative, connected, and challenged. Rather than passively consuming, these were 
moment of active participation. 
The Mix of Happy Emotions  
Chart of emotions 
The lows centered on ways that technology distorts what we feel to be real, particularly 
about our sense of self and our relationships. Like our positive moments, we also tagged 
the negative moments, breaking it out into the categories below. 
3 Ways Technology Makes Us Unhappy 
Abilities 
Relationships 
Time 
Tethered 
Comparative 
FOMO 
Stressed 
Obligated 
Distracted 
Automatic 
Performative 
Fragmented 
Incomplete 
Voyeuristic 
Shallow 
 
19 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
Diminished 
Obsessed 
Disconnected 
Rather than cultivating a deep participation in their own personal growth, a relationship, 
or whatever each might define as a good life, these lows left people feeling off-course. 
The more intense the participation, the more meaningful the experience. And the more 
people felt a sense of deep, and sometimes complicated, well-being.   
As researchers, designers, and developers, the implications of this research steers us 
toward a different approach to happiness. One that is not entirely frictionless or 
delightful, but that strives toward meaningful engagement in the long and short-term. In 
Chapter 3, we will return to this research as well as the latest academic thinking to 
consider what this means for design. 
Briefly 
• 
Happiness is an implicit goal of technology—it is assumed that part of the point 
of technology is to make our lives better—but our definition of what constitutes 
tech happiness continues to evolve.  
• 
Creating happiness with technology, so far, centers on making people feel more 
competent and connected. It is likely that the goals for how technology can play 
a role in happiness will broaden as our use of technology does. 
• 
While technology implicitly, and sometimes explicitly, aims to create the good 
life, those good intentions don’t always play out. The relationship we have with 
technology is conflicted. Whether or not Internet addiction is an official 
condition, we feel an unhealthy pull toward technology. This is becoming part of 
the inner narrative we have about tech use.  
• 
The tech community is beginning to acknowledge the broad and deep impact 
that technology has on people’s lives. Because technology is so deeply 
embedded in our lives, we can’t not have an impact on well-being. 
• 
For now, we do know that access to technology does have a quantifiable impact 
of collective and personal well-being. 
• 
Yet, we still don’t intentionally choose happiness as a goal for designing 
technology. Instead we design to solve problems, which is only part of the 
picture. Taking away negatives doesn’t always lead to big-picture happiness.  
• 
A convergence of methods in the design world, like Value by Design, Slow 
Design, and Positive Design, propose alternative models that take into account 
broader goals.  
Further  
• 
Read Clive Thompson’s Smarter Than You Think: How Technology is Changing 
Our Minds for the Better (2013), a nice counterpoint to Nicholas Carr’s The 
Shallows: What the Internet Is Doing to Our Brains (2011) 
• 
While Neil Postman’s point is about how television degrades us individually and 
collectively, Amusing Ourselves to Death: Public Discourse in the Age of Show 
Business (2005) it is often applied in the context of technology. I found Virginia 
 
20 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
 
21 
 
Heffernan’s Magic and Loss: The Internet as Art (2016) to be a refreshing take 
on the positive potential of technology. 
• 
For how design itself may be leading us to addiction, I enjoyed Natasha Dow 
Schull’s Addiction by Design: Machine Gambling in Las Vegas (2013).  
• 
Sherry Turkle’s Alone Together: Why We Expect More from Technology and 
Less from Each Other (2012) has few positive counterparts. Try danah boyd’s 
It’s Complicated: The Social Lives of Networked Teens (2013) for a view on 
how social media might contribute to well-being. 
 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
2 
The Emotional Side of Design 
Reporter: “One gets the sense that he [Hal] is capable of emotional responses. When I 
asked him about his abilities I sensed a sort of pride...”  
Crewman: “Well he acts like he has genuine emotions. Of course he’s programmed that 
way to make it easier for us to talk with him. But whether or not he has real feelings is 
something I don’t think anyone can truly answer.” 
2001: A Space Odyssey  
 
On the one hand, it might seem like technology is neutral, a means to an end. And yet the 
human-machine relationship is not purely rational, it’s emotional. People tend to treat 
computers as if they are real people. If you’ve ever talked back to your GPS or said 
goodnight to Siri, you know this feeling. You might think of your Roomba as a pet, or 
give a name to your laptop. 
Sometimes the feeling is not so explicit. Maybe we don’t assign a personality to our 
favorite app, but we certainly know how it makes us feel. With smartphones, it goes a 
step further. Studies show that we feel a close personal connection to their phone. We 
aren’t sure if the phone is a best friend, a saboteur, or an extension of ourselves. The 
emotional undercurrent to our relationship with technology is real. 
Marketers know that emotion can drive behavior. Apple’s emotional branding, whether 
promising 1000 songs in our pocket or encouraging us to Think Different, inspires close 
study. Google, Spotify, Skype have all tried emotional storytelling as a way to connect 
people to their brands.  
Even so, emotion is not in our comfort zone as we design technology. Teams try to 
uncover pragmatic opportunities to solve problems, without spending much time on 
emotions. We may map a journey from sad or bored to happy without diving in to too 
much detail. We try to make empathy part of our process, but tend to shy away from 
uncomfortable moments.  
In our assumption that making things frictionless is an unquestionable good, we smooth 
away the edges so that technology seems alluringly simple. We have an ethos of “clean” 
 
1 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
design. Even personalization fashions itself around a scrubbed caricature of an 
individual’s actions and preferences. Design practices tidy up the mess. And emotions are 
nothing if not messy. 
Emotion is not a problem to be solved. That doesn’t make it a good fit with current 
design processes. That said, we have adopted a certain approach to emotional design in 
the last decade. Emotional design is very much concerned with building positive emotion 
into the design and minimizing negative emotion. So, in a way, we are already attempting 
to design for happiness.  
In this chapter, we will look at our current approach to emotional design. And then turn to 
how the new emotion-sensing technology is nudging us toward a reconsideration of our 
approach and how we might create a richer approach to positive, and negative emotion.  
Design, with Feeling 
Humans make decisions as much on emotions as out of logic. That emotional mechanism 
for making split-second decisions is a firmly ingrained instinct. A flash of fear when we 
see a huge spider in the garage tells us to run away. Likewise, the delight from seeing our 
loved ones reinforces our bond, which has its own advantages for survival. Emotions 
guide perception and attention.  
Negative emotions can mean that people are frustrated enough not to complete what they 
started, too bored to stay engaged, or disappointed enough to switch brands altogether. 
Negative emotions narrow interactions, but positive emotions expand them.   
While negative affect, like stress, anxiety, and fear, narrows our focus to be alert to 
danger, positive affect broadens our response. We relax, we are more open to 
interruptions, we are more creative. Rather than narrowing in on a problem, in a positive 
state we are more likely to focus on the big picture.  
Positive emotions diffuse problems, but also can increase engagement in the moment—as 
a flow state or meaning making—and attachment in the long-term. Happy moments turn 
into happy memories, building a cycle of positive emotions. Happiness leads to mental-
well-being and is even tied to physical well-being. 
Positive emotion is one part of happiness models. Positive emotion can take place in the 
past as satisfaction, pride, contentment or serenity. It can be a part of the present as 
sensory pleasure or comfort. Positive emotion can be projected in the future, too as 
optimism, hope, confidence and trust.  
So let’s consider how we design for positive emotion. 
Hedonism and Eudaimonia 
In well-being research, two types of happy are debated. Is happiness more about 
hedonism, or the pursuit of pleasure while avoiding pain, or is it in Eudaimonia, 
personal development and meaning in life?  
A purely hedonistic approach to life would center on sex, eating Swiss 
chocolate, and enjoying custom cocktails with friends. The focus is on sensory 
pleasure and personal comfort.  
A purely eudaimonic approach would privilege developing personal talents, 
participating in community or charitable activities, acting on meaningful goals.  
 
2 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
Most contemporary happiness models balance both, leaning heavily toward 
eudaimonia.   
PERMA is a framework for well-being introduced by Martin Seligman in 2011. 
The P is positive emotion which can be pure pleasure or the result of 
Engagement, Relationships, Meaning, and Achievement.  
Ryff’s model of well-being is more eudaimonia than hedonism, with six 
components—self-acceptance, positive relations with others, autonomy, 
environmental mastery, purpose in life, and personal growth. But a core 
outcome seems to be positive emotion and psychological health.  
SDT, or Self-Determination Theory, introduced by Edward Deci and Richard 
Ryan is a theory of human motivation looking at how intrinsic and extrinsic 
factors influence behavior. The most powerful motivators support three 
universal needs for autonomy, competence, and relatedness. Again, heavily 
eudaimonic rather than hedonic.  
Our current approach to emotional design is weighted much more heavily 
toward hedonism. It’s turning out to be a short-coming, as technology becomes a 
part of everything we do. At some level our approach to designing technology, 
will have to strive for a balance of hedonism and eudaimonia. I like to think of it 
as spectrum of pleasure and purpose (more on that in Chapter 4) instead.   
How Good Design Makes Us Happy 
I’ve never been one to track, well, anything but especially not exercise. Not that I’m 
especially lazy, but I just couldn’t see myself wearing a black band on my wrist. Then I 
discovered the Misfit Shine—a mysterious button that came in lots of colors and could be 
worn as a bracelet a necklace or just tucked away entirely. I was sold.  
Never mind that it took some effort to set it up, or that it didn’t let me create notes that 
would have helped me to understand patterns, or that the accessories didn’t always seem 
to fit the device. There was something special about it for me, for a while anyway. 
How do we explain why we love certain technologies, and others don’t really take hold? 
No doubt that emotion forges attachments and shapes how we use technology, but we are 
only just starting to understand that emotional connection.  
The first framework for emotional design to really take hold in the community has been 
Don Norman’s. In Emotional Design, Norman shows how beautiful design leads people 
to believe that a product is a higher quality or value. Call it the aesthetic-usability effect.  
When people feel better about a product, the thinking goes that people will be 
predisposed to overlook negatives and to generate favorable inferences about things that 
are missing from the product itself. In other words, a positive response smooths over the 
rough edges in the experience. Folk wisdom tells us that maybe it will make people more 
loyal to the brand as well.  
At a basic level, this means the aesthetics are important. Universal principles of beauty, 
like the Golden Ratio, the Rule of Thirds, and principles of proximity, alignment, 
contrast, and repetition inform our innate sense of whether something is beautiful or not. 
Universal design elements, like saturated hues, harmonious sounds, smiling faces, 
symmetrical objects, rounded shapes, attractive people also contribute to positive affect. 
As we move from the design of mostly visual experiences to more sensory experience, 
this might also mean warmth, sweet tastes, or a soft touch.  
 
3 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
It’s more than that though, Norman posits that people’s emotional responses to design fall 
into three different components that correspond to the three levels of information 
processing in the brain—visceral, behavioral, and reflective. To be successful, design has 
to appeal to all three levels of human response.  
Visceral 
The visceral level is associated with the initial impact of a design. It’s almost like a 
reflex response. Norman argues that a visceral response to design is hardwired, and 
may apply even across cultures and people. The impulse to reject bitter tastes at first, 
or prefer highly saturated colors, or gravitate toward symmetry are all examples of 
visceral response. Although there are differences of degree, visceral is how you 
instinctively react. 
Behavioral 
The behavioral level is the total experience of engaging with an object—how it 
functions, how it feels to interact, how it responds. It’s what you do, with varying 
levels of intent. In other words, you may pick up an object or interact with an app . 
The behavioral level is influenced by visceral reactions, which are largely 
unconscious, but also by reflection.  
Reflective 
The reflective level is how you perceive the product, the representation of the 
product in your mind. Rather than an emotional response based on a gut reaction or 
an in-the-moment interaction, reflective response is evoked by the design’s symbolic 
meaning.  
While visceral and behavioral are in the moment. Reflective, as the name suggests, is 
about remembering the past and contemplating the future. 
Because all three work together, it’s possible to have a positive emotional experience 
with something that’s ugly, or doesn’t work well, or we don’t instinctively enjoy. The 
behavioral and reflective levels are sensitive to experience, training, and education that is 
characteristic of reflection. 
Emotional Design inspired the design community to consider emotion as part of the big 
picture. While there were a lot of great examples of emotional design, from teapots to 
cars, there wasn’t a lot of how to. Process and practice were to come next in the concept 
of delight.     
Delight’s Sweet Micro-Somethings 
When I started to talk about happiness to designers and developers, people tried to 
translate for me: “Oh happiness, don’t you mean delight?” Even the lovely folks at 
O’Reilly weren’t entirely sold. I mean, haven’t we already wrapped up happiness with a 
big pink bow? Do we really need another book on “delight”? 
When we think about making people happy with design, we think about delight. Peak 
happy, feel-good moments, intensely positive emotion. Happiness turns out to be a lot 
more than delight. But when we talk about design for emotion, it’s most often interpreted 
as delight. And delight has become a kind of holy grail in the design world.  
“Attractive things work better” as Don Norman pointed out. And we took this to heart. 
Aarron Walter’s work, Designing for Emotion, has had a far-reaching influence and is 
 
4 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
still incredibly appealing. We can make mass market-stock photo-template sites, or we 
can bring back the craft, he argues. Delightful details show craftsmanship and pride in the 
originality of the design. 
At almost the same time, Edie Adams and Trevor von Gorp also came out with a book, 
Design for Emotion, aiming to provide the how of emotional design. Both books map out 
a hierarchy that grafts Vitruvius’ maxim that the ideal building must be “sturdy, useful, 
and beautiful” onto Maslow’s hierarchy. A pleasurable experience is at the top of the 
hierarchy of user needs. 
Useful 
The product must answer a specific need. Useful is the reason for the product to 
exist.  
Usable 
The product must be functional, delivering the promised value to its intended users.   
Delightful 
The product demonstrates finesse, exceeding the expectations of users through well-
designed details.  
A Mountain Range of Delight 
Illustration of 3-5 pyramids for delight 
For better or worse, I think we are all reminded, too, of the food pyramid (well, as they 
used to teach it anyway—it has changed quite a bit). The nutritious food is at the bottom 
and the treats are at the top. You have to eat your broccoli before you get the chocolate. 
No matter recent research that says ice cream for breakfast actually gives you a mental 
boost. 
Delight often comes at the end of the design process, the cherry on top. Walters aptly 
compares a usable site to a meal that is just edible. It’s acceptable but hardly memorable. 
This resonates, because we’ve all had those experiences. In a rush, we are pressured to 
make do with creating those experiences too. 
Maslow’s Hierarchy 
Maybe we are all a bit tired of hearing about Maslow’s hierarchy. Even so, it’s 
the model that seems to make a lot of sense to a lot of people when it comes to 
happiness. According to Maslow’s theory, people are motivated first to fill basic 
needs before moving on the higher order needs like esteem or self-actualization. 
Usually, it’s presented as a pyramid in the following order, bottom to top.  
Physiological needs are fundamental to survival—food, water, sleep, air, and 
sex. 
Safety needs are next, important to survival but not critical. Personal security, 
stability, protection, law and order fit here.  
Love and belonging needs, the desire to give and receive love from family, 
friends and community, are the next level up the hierarchy. 
Esteem needs, or the need to respect yourself and be respected by others 
associated with social recognition and mastery are near the top. 
 
5 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
Self-actualization needs, shorthand for personal growth in many different 
forms, is at the top.   
The hierarchy suggests that basic needs should be met first before moving on to 
those at a higher level. Sonya Lyubomirsky’s research seems to substantiate this 
by showing that after we make a certain amount of income happiness levels off.  
But I wonder if this is not a bit too narrow. Even if without having basic needs 
met, people will still seek out love and esteem and self-actualization. There may 
not be a lot of time to devote to self-improvement, of course, but it doesn’t rule 
out all those higher forms of happiness. If you are poor, you still feel joy.  
When it comes to design, I think the pyramid model also has problems. Taking 
delight in poorly designed products is not unusual. And not all delightful details 
speak to well-being. It also makes emotion a nice-to-have rather than an 
essential component of the experience. 
The thinking goes that small delightful details, or the micro-interactions, can have a big 
impact. Lovingly obsessing over the details is an endearing trait ;-) of designers, after all. 
By creating something new and unexpected, customers spread the word and share 
delightful surprises.  
After a review of several hundred examples of delightful details, it’s not too much of a 
stretch to see that delight, while fleeting, is often attempting something bigger. Here are 
just a few of the themes.  
De-escalating 
A lot of delight seems to attempt to lighten the mood when you encounter an error. 
When you search for an emoji in Slack that doesn’t exist, you get the cry emoji 
instead. 404 messages are often the place for humor too. Whether it actually lightens 
the mood is another question, of course. 
Discovery 
You might be tempted to call this category pointless fun, but Snap has proven that 
discovering secret features motivates people to share what they figured out and feel 
just a bit clever about it. When MakerBot’s website that “prints” the hamburger icon 
when you close the menu or when Alexa answers “What’s your favorite color?” with 
“Infrared is super pretty” are other examples of “Easter eggs”. 
Care 
Some delightful details seem to have your back. These range from security, like 
when Chrome detects you are on an insecure connection, it won’t autofill credit card 
details, to preventing embarrassment, like when you are sending multiple 
messages to hosts on Airbnb and the last message is automatically copied with the 
name of the host automatically replaced, to work saving, like Gilt’s site auto 
completing your email based on common domains or Codeacademy offering to 
summarize a thread, to error prevention, like Spotify’s warning if you add a song to 
a playlist that you’ve already added.  
Personalization 
When Coursera recommends online courses related to a particular job or when 
Tumblr shows pictures similar to one you liked to the right side of the screen, these 
are thoughtful and personal touches.  
 
6 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
Sensory-rich 
The web and app-based experience is often sensory-poor, so delightful details can 
visually enrich the experience in addition to preventing mistakes. The clock icon on 
Mailchimp, for instance, changes based on when you have scheduled your campaign. 
TV listings on NBC’s Apple TV app move from daylight to night.  
Musixmatch, Lightening Up and Buttering Up 
 
 
Delight can serve a higher purpose by introducing moments of care or a hint of 
personalization, but its nature is transitory. Delightful details are very much a part of the 
experience we have while we interact, and that’s where it can go sometimes go wrong. 
The Downsides of Delight 
The problem comes when we think about starting at the bottom and working our way up. 
Delight comes at the end of the design process, the finishing touches. Emotion is 
prioritized last even though it may be what matters most of all. So emotion becomes a 
superficial layer, or is put off entirely in the rush to get a product to market.  
 
7 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
As delight is practiced, it can feel formulaic. Websites like Little Big Details 
(littlebigdetails.com) and books like Dan Saffer’s Micro-interactions give us plenty of 
examples to use as model for these small details with big impact. These collections may 
have started as inspirational but end up as a design shorthand barely sketching out 
emotional design out with snappy microcopy, novelty transitions, skeuomorphic page 
turns and the like.  
Delight tries hard to create happiness, maybe a little too hard sometimes. It can be kind of 
like that person telling you to cheer up and just smile, when you’re feeling down. Well-
intentioned, perhaps, but potentially annoying. Creating a design element, a naming 
scheme, or an interaction pattern that’s surprising and clever can get in the way too. The 
following common problems can work against the intent of a design. 
Obstructionist 
Whether unclear naming or distracting animation, too-clever details actually make it 
more difficult to actually engage with the product in a meaningful way.  
Paternalistic 
While we want products to show that they have our back, it’s all too easy to cross the 
line toward a “we know best” kind of tone. Product Hunt suggesting that you go to 
bed if you’ve been browsing for too long is an example of crossing this line. 
Infantalizing 
Sometimes a little childish humor is OK, but we don’t want to be treated like 
children. Compare Waze, which is meant to be for grownups, with Pokemon Go, a 
game for kids (and everyone else), and the former looks more childish than the latter  
Trivializing 
Once in a while, delightful details trivialize something that isn’t trivial at all. In one 
research project on retirement saving, one participant was taken aback by the 
cheerfully illustration telling him that he had enough saved for 42 days of retirement. 
He said flatly, “I don’t think this is exactly a YAY moment for me.”  
Waze, Fun or Infantalizing? 
 
8 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
 
Delight is associated with a certain style of humor that’s a bit cheeky. Humor is not quite 
so straightforward though. A lot of delightful details try to be funny, but can come across 
as unsympathetic or insulting. Or it may be funny when you are in a certain mood or you 
find yourself in lighthearted circumstances, but not at other times. Humor is not only 
subjective but it’s also contextual.  
iStockphoto’s Error Message, Horrifying or Delightful? 
 
The downsides of delight can be much more serious. In Design for Real Life, Sarah 
Wachter-Boettcher and Eric Meyer, note that tech companies are often willing to invest 
resources chasing delight over addressing real life pressure points. “Apple has no trouble 
dedicating its smart, highly paid staff to preloading Siri with pithy quips and jokes. That 
was a priority from day one. Five years later, Apple still hasn’t stress-tested Siri for its 
response to crisis.” 
 
9 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
So delight can disappoint, or worse. But even if it isn’t lacking or annoying, it will still 
lose its appeal over time. I remember the first time I noticed how each photo loaded with 
a colorful placeholder on Pinterest. At first, it was thrilling. Then, I just expected it to be 
the case. Now I see it on Google image search and other sites too, and I’m almost not 
aware of it. The thrill is gone. 
The sad truth is that delightful details lose their charm over time. Delight has a shelf life.  
Pinterest’s Color-Coordinated Page Load 
 
 
Delight gets a lot trickier the more diverse and the more global the audience. If you’re a 
smaller brand, you can often get away with using fun language that you might assume 
appeals to people like yourself. You’ve got a tribe and they get it. But as a brand becomes 
global, the approach tends to be more straightforward and conventional. It’s easier to 
localize. No one is excluded from the joke. 
Quip’s Humor Wouldn’t Work for Google Docs  
 
10 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
 
Delightful details seem to work best along the periphery of an experience. Happiness 
research tells us that we quickly adapt our expectations, so that we habituate to what once 
made us happy. We are less likely to tire of those aspects of an experience we see once—
setting up an account, when a new feature is introduced, when an action is completed for 
the first time.  So the first time we read clever copy, it’s more likely to seem fun. The 
next time, well, not so much. 
Hedonic Adaptation 
The truth is the thing that makes us so happy right now, will not make us happy 
in the same way in the future. So, the first time you tried avocado toast ;-) you 
probably loved it. Me too. The next time you still loved it, but you weren’t 
telling everyone how great it was. A month later, you still enjoy it, just not quite 
as much. If you ate it every day for six months straight, the love affair would be 
over. It might be a habit but that’s a different thing altogether.  
The concept of hedonic adaptation relies on a happiness set point. The best 
thinking on positive psychology tells us that people generally maintain a 
constant level of happiness despite events or environment. It’s described as a 
treadmill since we keep going to maintain a certain level of happiness. Others 
think of it as a thermostat, a Nest thermostat perhaps, that maintains a certain 
comfortable temperature. Whatever the metaphor, the idea is the same. If you 
win the lottery, you will get a bit of a happiness boost. Then you will habituate 
to the new circumstances and your happiness will level off.  
It may seem like a bummer to never keep it cranked up to 11, but, on the plus 
side, that kind of stable happiness is tied to resilience.  
The sad truth may be that delight is easy to miss for the untrained eye. As designers, we 
share an appreciation and a finely-tuned sensibility for delightful details. People who are 
using that product or app might not. I wonder, in the end, how much emotional impact 
they do have on experience.  It’s tricky to study on its own. Teasing out delightful details 
from the rest of the experience is a challenge. For instance, when I asked people to 
 
11 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
submit their peak moments, I didn’t see any examples that would fit our designerly 
notion of delight. On research projects, clients are often dismayed that no one comments 
on delightful details. “Look at it, look at this cute bunny telling you to download your 
contacts,” they ask.  
As designers and developers, the craftsmanship of delightful details is in itself delightful. 
These details may not be appreciated by a wider audience. Or perhaps delight is a bit like 
other acquired tastes, such as fine wine or opera. It takes a trained sensibility to truly 
enjoy.  
So while we hope for the best, we are making some assumptions. It’s not entirely clear 
what kind of emotional impact delightful details actually have. What is clear is that it puts 
a lot of burden on the design itself to produce happiness.  
When it comes to delight, we look to the design itself as the source of happiness. That 
may be asking too much. So far, we’ve been considering all these delightful details as 
stand-alones though. The bigger goal is often to bring all these details together into a 
coherent personality for the brand.  
Anthropomorphism and Attachment 
Designers often talk about humanizing technology, but it’s not always clear what that 
means. My hope is making technology that amplifies our humanity. What it typically 
translates to is something a little different—giving technology human qualities.  
Emotional design, as its practiced currently, starts with moments of delight. As these 
details start to come together, emotional design can evolve into a coherent personality. 
Tone of voice, visual cues, and micro-interactions come together as a relatable character. 
Most of the time, this manifests as a brand mascot.  
Human spokespeople can make products relatable, but they are more complicated. They 
have opinions, they age, they do other things besides represent a brand. Occasionally, 
they say or do things that are inappropriate or embarrassing or even illegal. I’m sure we 
can all think of a few examples without naming names. 
Mascots, or “spokescreatures”, work together with other aspects of the product or brand 
by conveying the benefit and connecting with the target audience in a way that human 
spokespeople may not. The Pillsbury doughboy, the GEICO gecko, and Mailchimp’s 
Freddie are all examples of successful brand mascots. So oddly, we often humanize 
technology with animals or other creatures rather than humans.  
Humanizing Brands with Non-Human Mascots 
 
12 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
 
On the visual web and through mobile apps, we get a sense of a brand’s personality 
through what we read and what we see. So, there’s a bit of distance between us and the 
brand mascot. We aren’t having conversations directly.  
It looks as if conversational design is poised to follow conventions of brand personality. 
But we may need to rethink our approach to emotional design when it comes to 
conversational interfaces. Do we want to have a conversation with a cute, illustrated cat? 
Maybe when it’s about the weather, well, depending how seriously we take our weather.  
Brand Mascots May Not Be the Best Conversationalists 
 
13 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
 
We’re surrounded by Artificial Intelligence (AI) assistants from Google, Amazon, and 
Microsoft that are quick with a joke but not good for much else. A scan of the 
temperature outside in an app (or just by stepping outside ☺) takes a few seconds, texting 
a bot can take a few minutes. And how do we feel about having a text chat with a bot? 
Conflicted, at best.  
It’s not all that fulfilling to chat with a perpetually cheerful brand mascot. It might be fun 
to read the Aflac duck’s tweets or to test Siri’s sassy comebacks, but there’s no give and 
take. Including media options, in the style of Weibo or Peach, might enrich a 
conversation with a fellow human but still doesn’t do much for a chat with a bot, even a 
bot with a sparkling personality. Maybe conversation-ish is a better term.  
With or without mascots, conversational interfaces still feel like talking at rather than 
with. A one-off question or command, like “what time is it?” or “set a timer” isn’t a 
conversation. In truth, it’s accomplishing the opposite of humanizing by prompting our 
conversations practices to adapt to a “command and wait” flow. We end up talking like a 
robot to talk with a robot.  
Maybe conversational design is bumping up against the limits of delight. Whether there 
are humans behind the screens as we see in apps like Operator (www.operator.com), or 
the conversation is an amalgam of AI, programmers, poets and Turkers as in the case of 
Amazon’s Alexa, what’s missing is not a brand personality but the real collaborative ebb 
and flow of human to human conversation.   
The delightful touches aren’t quite enough to cover what is ultimately a pastiche of 
conversation. When you are talking with a chatbot or a virtual reality avatar, you are 
talking to an aggregate of other humans but you’re not talking with a human. In the Most 
Human Human, poet and programmer Brian Christian, wonders if we may become tone 
 
14 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
deaf to the difference between and individual voice and the collective “conversational 
puree” of a chatbot voice. We haven’t yet, but we easily might.  
Even the barest hint of human might lead us to be attached. One of the earliest attempts to 
create a humanized bot was Joseph Weizenbaum’s ELIZA, designed at MIT in 1966. 
Weizenbaum based the program on Rogerian psychotherapy where therapists ask open 
questions by reframing what the patient says, kind of like we do when we are conducting 
a traditional user testing session actually. I’ve wondered if we could use something like 
ELIZA for usability testing, but that’s another conversation for another day. 
ELIZA scanned for keywords like “mother” (of course) or “anxious” to respond with an 
appropriate question. So a typical conversation would look like this: 
Human: Well, my boyfriend made me come here. 
ELIZA: Your boyfriend made you come here? 
Human: He says I'm depressed much of the time. 
ELIZA: I am sorry to hear you are depressed. 
Human: It's true. I'm unhappy. 
ELIZA: Do you think coming here will help you not to be unhappy? 
ELIZA’s shallow conversation depth was easy to detect but it charmed people anyway. 
People approached the bot as if it were real. This condition even has a name—the ELIZA 
Effect. When it comes to children and chatbots, you can see the effect readily take hold. 
Even  
Perhaps there is a better way to humanize the design? Human gesture, behavior, and 
emotion can still be a model without turning into a sassy know-it-all like Clippy or a silly 
avatar like Poncho.  
Emotional connection through subtle humanizing touches, without veering into brand 
mascot territory, is not without precedent. When Apple introduced the Macintosh in 
1984, its conversational attributes was a hallmark of the design. The original Macintosh 
even looked a bit human, with its screen placed high in a tall narrow base to look like a 
face and its disk drive a crooked smile.  
Human markers continue to be a characteristic of Apple’s design. Apple secured a patent 
for the Breathing Status LED indicator in 2003—the gently pulsing light that shows your 
laptop has moved to a standby state is designed to mimic human breathing rates during 
sleep. The iPhone’s passcode screen is characterized by another human gesture. If you 
incorrectly enter your passcode, your iPhone will shake from left to right, mimicking a 
negative head shake. 
Contemporary chatbots, like Alexa, are designed to create a warm feeling using not just 
speech patterns but social conventions. Alexa is referred to as a she, like a lot of other 
feminized virtual assistants. She can answer questions that are not functional. And voice 
rather than text, conjures up a sense of a sentient being. Xiaoice is a Mandarin language 
chatbot powered by Microsoft’s semantic analysis and a team of psychologists who 
designed her with and EQ, not just an IQ. Her memory and compassionate questions has 
endeared her to 40 million human conversation partners.  
Assigning a personality to our laptops or ATMs seems to come naturally to us if there is 
the slightest hint of humanity. The truth is we probably don’t need a human element at all 
to attach to our devices. Given how easy it is for us to anthropomorphize technology and 
other inanimate objects, it’s inevitable that we will emotionally attach and maybe even 
 
15 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
fall in love. As you are interacting, you are building a relationship. Clifford Nass studied 
our relationship with computers for years and concluded that we treat our tech as social 
actors. And how we treat them says as much about us, as it does about the machine 
intelligence. 
Kate Darling of MIT research shows a relationship between people’s tendency for 
empathy and the way they are willing to treat a robot. She had people play with the 
adorable baby dinosaur, Pleo, for a time. Then she asked people to suffocate it. Short 
story, most wouldn’t.  As a parent, I’m mindful of how my kids talk to Siri and Alexa. 
While there hasn’t been much research in this area yet, but let’s assume since kids are 
developing behavioral patterns that it’s something to watch.  
Humanizing design through anthropomorphic details aims for a warm, fuzzy feeling of 
attachment in addition to in-the-moment delight. But it doesn’t attempt to prompt 
particular behaviors based on emotions. Behavioral design, and its reliance of a cycle of 
emotion, is where emotional design has evolved in the past couple of years.  
Behavioral Design and the Cycle of Emotion 
Lately, engagement has become code for emotional design. In a way, the focus on 
engagement takes delight, and how we had been practicing emotional design, and turns it 
upside down. Without fully acknowledging it, we have started to design for negative 
emotions like boredom or anxiety or FOMO when we design for behavior change.  
Designing for engagement means choosing a point in the journey where people are 
emotionally vulnerable, and then “solving” it for just a while, once in a while, brings 
people back again and again driving engagement. When this is accomplished on a micro-
level, like when we use a social media app to fill moments of boredom, we become 
“hooked”.  
In his book, Hooked, Nir Eyal hypothesizes that by creating habits in this way will create 
a higher lifetime customer value, offer greater potential for growth, and let companies 
have more flexibility in pricing. A claim that resonates with tech companies—especially 
those that rely on ad revenue. 
As depressing as it is to think of yourself as one of Skinner’s pigeons or Pavlov’s dogs, 
once you’ve learned about it, you start to see variable rewards everywhere you look. 
When you glance at a notification on your phone, or pull to refresh you email, when you 
endlessly scroll Facebook or Twitter, you might or you might not find what you are 
seeking. When you do, you get a little burst of dopamine and you feel good. But then it 
wears off and you are on the hamster wheel, pardon the mixed metaphor, again.  
Design kills the pain temporarily, and then, if it’s successful, repeatedly. What seems to 
be happening though, is that designing to alleviate pain doesn’t alleviate pain. Instead it 
cultivates a cycle of negative emotion. The good feeling doesn’t last. The false sense of 
urgency creates a new source of stress. And the good feeling might even not be that good, 
after all. It creates an experience that feels addictive.  
While the model could be used to develop “healthy habits”, in practice it isn’t. It’s 
possible to use negative emotional triggers for positive outcomes, but the positive 
outcomes are typically measured as views, time scrolling or hovering, or other aspects of 
engagement that drive revenue. The current business model for engagement-driven, ad-
reliant experiences comes at the expense of positive personal outcomes.  
 
16 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
Of course, it doesn’t have to be that way. Principles from behavioral design can be used 
to support big-picture happiness. Fitness trackers, like Fitbit, are good examples of how 
principles from behavioral design can be used to create healthy habits. But so far, it’s 
literal, found mostly in health and meditation apps, and limited.  
This is where emotional design, delight, and gamification come together. Gamification 
can help motivate people to meet their goals. For me, that’s the simplest test actually. 
Does gamification help people to meet goals that they’ve set? Or is it nudging them to 
meet business goals at the expense of personal goals? If it’s the former, then it contributes 
to well-being. If it’s the latter, it doesn’t. 
Fitbit Motivates and Rewards 
 
 
Maybe the idea of habit itself is not quite right when it comes to happiness and 
technology, anyway. Alain de Botton writes about the deadening effects of habit. Habit 
can give shape to our lives but it can also lull us into a mindlessly gliding through our 
days. Some habits, like daily gratitude, may contribute to well-being but happiness is 
more often associated with learning, creativity, and meaning-making—activities that 
don’t necessarily have to do with habits. 
Prioritizing engagement with a product, and with a screen in particular, relies on cycling 
through negative emotion. While a behavioral approach shows a slightly more nuanced 
understanding of the connection between emotion and behavior, it lacks empathy. So 
maybe the next wave of emotion-sensing computing will bring us closer to emotionally 
intelligent design. 
 
17 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
When Your Internet Things Know How You 
Feel 
Apps and chatbots don’t know whether you are having a good day or a bad day, whether 
you are running up against a big deadline or are about to leave for a long weekend, 
whether you spent the last hour laughing with close friends or arguing with your spouse. 
While a digital assistant can tell you the weather or an app can remember music you like 
or a cute error message can make you smile, they don’t react to changes in your mood. 
They might be engaging or even delightful, but they lack emotional intelligence. 
We are used to making guesses about how people feel or what would make them happy. 
That’s changing. Emotions are already becoming a part of our everyday use of 
technology. Emotional responses like angry, sad and wow! are now integrated into our 
online emotional vocabulary as we start to use Facebook’s reactions. Some of us use 
emotion tracking apps, like Moodnotes (moodnotes.thriveport.com) not only to 
understand our emotions but to drive positive behavior change. 
Ustwo’s Making of Moodnotes Video Shows an Approach to  Design 
for Emotion Capture 
 
Emotion-sensing technology is moving from an experimental phase to a reality. The Feel 
(myfeel.co) wristband and the Moodmetric ring (moodmetric.com) use sensors that read 
galvanic skin response, pulse, and skin temperature to detect emotion in a limited 
way. EmoSpark (emoshapes.com) is a smart home device that creates an emotional 
profile based on a combination of word choice, vocal characteristics and facial 
recognition. This profile is used to deliver music, video and images according to your 
mood. 
Emotion-sensing technology, or affective computing, is able to pick up on facial 
expressions, tone of voice, body language, and other physical cues to infer emotional 
state. There are five main types of emotion-sensing technology: 
 
18 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
1. Text analysis notes frequency, arrangement, and sometimes context of words and 
maps that to an emotional category.   
2. Voice recognition identifies patterns in vocal pitch, rhythm, and intensity of the 
human voice. 
3. Facial recognition reads facial expression expressions relies on Paul Ekman’s five 
to seven universal emotions that are made obvious by facial expression.  
4. Biometrics track heart rate, blood pressure, gaze, skin temperature or other physical 
signs and translate into emotional categories. 
5. Self-report asks people how they feel in any number of ways, from a simple 
question to a rating of intensity to expressing emotion through a picture or a song. 
Self-report is not strictly speaking emotion-sensing, but still necessary because 
emotion is not just a physical signal but a cognitive appraisal.  
By gathering signals through cameras, microphones, skin sensors, eye tracking, and other 
means, emotional artificial intelligence can recognize signs of emotions and translate 
those signs to an emotion. That information can be used by a computer express emotion 
to humans, or even to use that emotional intelligence as part of its decision making. 
When all these elements come together, a machine can, I suppose, be considered to have 
emotion although still in a much different way than humans.  
Jibo (jibo.com), developed by Cynthia Breazeal (you may remember her robot Kismet 
mentioned in Don Norman’s book), is one of the first robots to “have” emotions in this 
way. Jibo recognizes physical cues in humans that are translated to emotions. It then uses 
this intelligence to respond with emotional sensitivity, like waiting for a minute to 
interrupt with a notification.  
As a close cousin to the brand mascot and its sassy chatbot descendants, Jibo’s clever 
repartee is extoled as a feature. It’s touted as part of the family, in the same way that the 
butler or nanny on a Disney Kids show is a part of the family. This may be why my 
youngest daughter is infatuated with Jibo, actually. Part amusing distraction, part 
temporary friend/parent substitute, mostly servant. It’s a friendly, but the relationship is 
transactional.  
This may be what affective computing will look like in the future, especially if we stay 
with our current practice of emotional design. A robot as companion or object of 
affection puts humans in a weird position. We already treat machines as people—whether 
they have a carefully crafted personality or not. How long will it take for people starting 
to treat other people as they treat their robots? We haven’t quite arrived at this point yet. 
Robots like Jibo, and chatbots, and perhaps someday virtual reality avatars situate the 
emotional intelligence outside of ourselves. The other direction emotional AI is taking is 
about supporting our emotional nature without necessarily creating a robot buddy.  
Let’s look at a few examples of how emotion-sensing technology is in this way. Leading 
banks like JP Morgan Chase and Bank of America are working with tech companies like 
Humanyze (humanyze.com) to monitor employees’ emotions and determine whether they 
are at risk for making a costly mistake. After all, stock traders are making split-second 
decisions that can involve millions of dollars. The idea is that the sensor-laden badge 
would help managers assist employees and highlight positive action.  
Likewise, call centers are using Cogito’s (cogitocorp.com) tone of voice analytics to 
detect early signs of frustration in caller’s speech and guide customer service agents to 
speak with greater empathy and confidence.  Managers are automatically alerted to calls 
 
19 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
in which a customer is having a poor experience and can use the system to identify 
actionable best practices and training exercises for customer service reps.  
Of course, emotional artificial intelligence used in the workplace could also be used to 
penalize employees. Or it could be used to encourage conformity to strict behavioral 
guidelines, more so than is already the case. At a time when some firms are considering 
replacing employees with artificial intelligence entirely, it occupies an uneasy place to be 
sure. 
Both remind me of a speculative design project by Lauren McCarthy at NYU, called US+ 
(http://lauren-mccarthy.com/us). By analyzing tone of voice, words, and facial 
expression, it offers prompts about how to respond to your friend, colleague, or loved one 
with more emotional intelligence. Crystal (crystalknows.com) is a real-life take on this 
idea. It scans text from your social media posts and matches that with a personality type. 
When you communicate with other people who’ve also taken the personality test and use 
Crystal, you are given hints at how to best word your email or post.  
Crystal’s Personality Profile May Be a Way Toward Empathy 
 
In the best circumstances, this kind of approach to emotional artificial intelligence could 
help us to better understand ourselves. Tuning in to our emotions, can help us to be more 
self-aware and develop strategies to improve our lives. But the idea that it might know us 
better than we know ourselves is unsettling. Crystal counters this by letting you have a 
role in shaping the outcome. You can answer a few questions Myers-Briggs style to add 
or adjust without gaming it.  
While this kind of software could help in tricky social situations, most of us bristle at the 
idea of machines training us to be more emotionally intelligent. And it doesn’t take much 
imagination to consider a future when human conversation is optimized for maximum 
impact on the one hand, and machine expertly manipulate that communication on the 
other.  
 
20 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
And yet emotional AI that helps reveal our emotions could really help people. Affective 
computing emerged from research to help people on the autism spectrum who have 
trouble recognizing emotion in themselves or others. One of Rosalind Picard’s early 
projects involved designing ways to detect emotion from a wristband and communicate 
stress to a parent or caregiver. Parents of kids with ADHD have been using emotion-
sensing tech to respond constructively to their children’s difficulties.   
Ellie (ict.usc.edu/prototypes/simsensei) an experimental virtual therapist, developed at 
the University of Southern California’s Institute for Creative Technologies, to treat 
people with depression and veterans with PTSD, analyzes emotional cues through facial 
expressions, gestures, and vocal patterns to respond appropriately. Patients admit to 
feeling less judged talking to Ellie, too. A virtual therapist may make therapy more 
widely available to people who need it.  
The next wave of emotion tech will likely focus on emotion regulation. Living with 
someone who has PTSD, this was my first exposure to emotion-sensing technology. 
Emotion-sensing wearables have helped in managing PTSD, warning family members 
before an intense episode. Mood regulation devices, like the Thync (thync.com), don’t 
actually detect emotion. Instead, it stimulates the nervous system to affect an emotional 
response like calm or energy. Eventually, the emotion-detection and emotion-regulation 
might work together to provide relief to people with anxiety, depression, or PTSD.  
Not all emotional artificial intelligence works by revealing our emotions to ourselves or 
to other humans. Some emotion-sensing technology conveys our emotions to devices to 
change how the devices behave. If you get car sick like me, then you might be happy 
about self-driving cars that could become more responsive to how we feel about their 
driving. BRAIQ (braiq.ai) teaches autonomous vehicles to read the comfort level of 
passengers and adjust accordingly. In-cabin sensors provide data about how passengers 
feel about the acceleration, braking, and steering and then uses that data to adjust the ride. 
The emotional artificial intelligence becomes a way to respond to how we are feeling, 
rather than telling us what we feel and how to act accordingly or trying to engage in 
snappy banter (well, at least, not as far as I can tell at writing).  
Toward Emotionally Intelligent Technology 
As emotional artificial intelligence evolves, it will convey and evoke emotions on four 
levels. It’s similar to how we think of emotional intelligence in people. Emotional 
intelligence is a person’s ability to identify emotions in both themselves and others to 
guide behavior. Emotional intelligence has four different qualities: 
1. Recognition of your own emotions. Self-awareness means the ability to identify what 
you are feeling and interpret what that means.  
2. Recognition of emotions of other people or in social contexts. This is where empathy 
lives, currently and rightly a guiding principle of design.  
3. Regulation of your own emotions. Self-management of emotions translates to self-
control, initiative, adaptability, resilience. 
4. Relationship management is how we regulate our emotional relationship with other 
people individually or in groups. Leadership, mentoring, influence, building bonds, 
teamwork and collaboration are hallmarks.  
The Components of Emotional Intelligence Translated for Design 
 
21 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
Grid of 4 emotional components 
How does this translate to emotion-sensing technology and emotion AI? Let’s explore the 
same four principles.  
Helps Us to Recognize Our Own Emotions  
The quantified-self movement started out as niche, with homegrown tools and meet-ups. 
Now, tracking our health, physical and mental, is becoming more common. Current 
research estimates that one in ten people own a fitness tracker of some kind. Add in 
smartwatches and that number may be higher. 
Because we want to know ourselves better, and design better lives for ourselves, tracking 
our emotions, especially stress triggers or peak moments, potentially adds another layer 
of understanding. Reflecting on our emotions may be a positive thing, allowing us to 
savor experiences or cultivate happiness. Of course, there are dangers too. Revealing and 
reflecting on negative emotions may cause anxiety or exacerbate mental illness. 
Helps Us to Understand Other’s Emotions 
Early work in affective computing focused on helping children with autism, people with 
post-traumatic stress disorder (PTSD), or people with epilepsy. It’s easy to see how 
parents of toddlers or people with aging parents could also benefit from emotion-sensing 
technology to facilitate communication, but it won’t be limited to specialized use. Just as 
we share our fitness milestones, or compare notes on strategies for our physical health, 
we are also likely to share our emotions using technology. Maybe we will share emotions 
with text messages, through our clothing (sensoree.com) – maybe even with butterflies. 
Microsoft’s Experimental Mood Wings Sensory Wristband 
 
Chubble (chubble.co)  is an example of an app that lets you share live moments with your 
friends and see their emotional reaction in real time. In other words, emotionally 
intelligent technology will let us share our emotions explicitly and in more subtle ways 
too. 
 
22 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
Emotionally intelligent technology will also have to know when not to share emotions, or 
simply prevent you from inadvertently sharing emotion. It will also have to know how to 
provide context and history. Even the best of intentions can go wrong. 
Consider Samaritans Radar, now shut down, which alerted you to signs of depression 
from friends’ social media feeds. It could easily miss context and history, in addition to 
leaving your friend vulnerable to people with bad intentions. 
Adapt Based on Our Emotions 
We have already noted that emotionally intelligent technology can make us aware of our 
own emotions and communicate those emotions to others. The next step is to offer 
recommendations based on those emotions. Personalization algorithms shape what you 
discover, where you focus attention, and even who you interact with online.  
When these algorithms work well, they can feel like a friend. At the same time, 
personalization doesn’t feel all that personal. Your personalization algorithm, however, 
has only one part of the equation – your behaviors. The likes, videos, photos, locations, 
tags, comments, recommendations and ratings shape your online experience. 
Personalization stays in the past. Humans are in motion toward the future. 
Rather than recommendations based on past purchases, like Amazon’s, or places you’ve 
been, like Foursquare’s recommendations, imagine recommendations based on 
aggregated data from emotion-sensing technology. The emotional state of many people 
could be matched up with your current state to result in something like: “People feeling 
energetic like you go to Soul Cycle at Union Square.” Rather than selecting a curated list 
called Confidence Boost, imagine instead that Spotify picks up on signals from your 
emotion-sensing wristband to develop a custom playlist for your mood. 
Although a little tongue in cheek, pplkpr (pplkpr.com) is an example of an emotionally 
intelligent recommendation tool. Pplkpr asks users questions about how they feel in an 
app and pairs it with physiological data collected through a wristband to tell you which 
friends and colleagues are better for your mental health. This speculative app is designed, 
in part, to call into question the ethics of emotions. For example, what do you do when 
your app tells you a close friend is bad for your health? 
Communicates with Us in a More Human Way 
When devices can understand emotions, they can adjust the way they communicate with 
us. Siri is fun to prank because she usually doesn’t get when we are joking. Imagine if 
she did. Emotionally intelligent robots will learn our emotions and show emotion in a 
rudimentary way. Pepper, an emotion-sensing robot companion, is not just popular with 
consumers but is being used by companies to provide customer support services. 
Likewise, virtual reality avatars  
Emotion-sensing technology has the potential to help us to understand our own emotions, 
express our emotions, and take actions on our emotions. A machine with emotional AI 
can also adapt to how we are feeling. In all these cases, the design acts more as support 
rather than a source of emotion or an evocative symbol that produces emotion on 
anticipation or reflection. Providing emotional support is a new dimension to emotional 
design.  
Mixed Feelings About Emotional Artificial Intelligence 
While affective computing has the potential to recognize, interpret, and simulate human 
emotion, it comes with some significant drawbacks. Born in the 1990s, emotion-sensing 
 
23 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
and emotional artificial intelligence haven’t really started to take off until recently. Even 
with Moore’s law, it still seems like there’s a long way to go—maybe not from a 
development perspective but from well-being perspective. And when we think about 
well-being and happiness, invariably the ethical complications are mixed up in it.  
The sensing part itself is limited. When we are having a conversation, whether actually 
talking on the phone or texting, we tend to be the most expressive. Otherwise, our 
expressions tend to be pretty neutral. We don’t typically display a lot of emotion on our 
faces when we are looking at our laptops or our phones.  So facial recognition might 
work well for movies or concerts or ads (most of the patents around facial coding are 
related to ads, I’m sad to say), but it’s relevance is limited when it comes to our current 
device use. Voice analysis might be great when we are having an animated conversation, 
human or chatbot, but that’s not all, or even most, of our interactions.  
Contrary to negative emotions, positive emotions are relatively undifferentiated: joy, 
amusement and serenity are not easily distinguished from one another in terms of facial 
expressions as they all result in a smile. Due to subtle differences between positive 
emotions, most commonly used sets of basic emotions include fewer positive emotions 
than negative emotions. So, emotion research in psychology has predominantly focused 
on negative emotions. The same might end up being true about emotion sensing. 
The logic behind emotion-sensing, like that of any algorithm, makes assumptions. 
Facial expressions are mapped to Ekman’s 5-7 emotions in the current systems.  So while 
we are moving beyond the happy face/sad face scores of the social listening past, 
emotion-sensing may not be as nuanced as we like.  
Current technology uses cookies, beacons, and tracking code, to make assumptions based 
on behaviors. Data behemoths like Google also scan emails and private chats for any 
information that might help personalize web experience, where personalize means 
serving targeted ads. All of these techniques are guided by a certain logic, and it’s always 
inherently limited.  
Measuring Emotion 
Emotion-sensing detects physical signals and translates those into emotions. In a 
way, this isn’t anything new. We do it all the time. The better we are at 
identifying and understand emotions in ourselves or in others, the more we seem 
emotionally intelligent. But it’s hard to be right based on physical cues all the 
time. That’s why we also ask people how they feel.  
And it’s not an exact science. When we gauge our own emotions, or someone 
else’s, we might tend to rely on a few emotion categories. Happy or sad, angry 
or loving. We could identify more nuanced emotions, but often we don’t. And 
depending on the culture we grew up in, we might not even have the words for 
what we feel. In English for example, there are much fewer words for positive 
emotions than negative. 
Most emotion-sensing technology chooses to go with 5-7 core emotions. 
Designers do too. 
FACS In 1978, Paul Ekman identified five universal emotions including fear, 
sadness, anger, disgust, and enjoyment by analyzing facial expression. His 
Facial Action Coding System (FACS) is the basis of most current facial coding 
software and has been widely used for lie detection. The movie, Inside Out, uses 
Ekmans’ model too. 
 
24 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
Plutchik’s Flower In 1980, Robert Plutchik introduced the concept of eight 
basic emotions, including joy, trust, fear, surprise, sadness, disgust, anger, and 
anticipation. His flower, or wheel, of emotions shows the interplay of those 
emotions and the varying levels of intensity.  
Parrott’s Emotion Classification In the book Emotions in Social Psychology 
(2001), W. Gerrod Parrott created a tree-like diagram of emotions and their 
relationships starting with six core emotions: sadness, joy, love, fear, surprise, 
and anger. Parrot’s work explores the positive side of negative emotions.   
Feeling Wheel In 2001, Gloria Wilcox created the feeling wheel as a way to 
move from less intense emotion to the core emotions of sad, mad, scared, joyful, 
powerful, and peaceful. I’ve been using the Feeling Wheel in research in the 
opposite way though, since people are conversant with core emotions.  
 
The Feeling Wheel as a Way to Map Emotional Granularity 
  
 
The intelligence is only as good as the data that trains it. Hopefully, the datasets used 
to teach the artificial intelligence are vast and diverse, so the system will end up less 
biased. But decisions about which emotions to include and detect are embedded into the 
system. Cultural differences in how emotions are expressed abound. Many emotions run 
deep, either invisible or individual. Since most emotion datasets are collected in a certain 
context or under specific conditions, that data will be inherently limited. Given the 
 
25 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
proprietary nature of most data already being collected about people, and we will have to 
take great care in making meaning from it all. 
It privileges in the moment, intense emotion over long-term states of being. Emotions 
are strongly felt, often accompanied by immediate and discernable physiological and 
behavioral changes. Emotion-sensing technology registers emotions pretty well.  
Mood is emotion in the long-term, a frame of mind that may not be easily detectable and 
doesn’t necessarily map to an action. It can start with an intense emotion and dissipate 
over time, or not. Attitude is an overarching approach that involves emotions, but is 
bigger than emotion. Emotion-sensing can’t detect these emotional states of being. I can 
imagine this technology making claims to connect the dots between emotional peaks, but 
it’s not that simple.   
It assumes actions neatly map to emotions. Emotion certainly can drive behavior. You 
love someone, so you touch their arm or give them a hug. It can also work the other way 
around. Behaviors can drive emotions. Actors and actresses who behave as if they care 
deeply about each other sometimes do actually fall in love. That’s why those 36 questions 
you can ask to fall in love, accompanied by looking deeply into each other’s eyes, often 
have just that effect.  
Emotions sometimes have no associated action. You are angry, but you are an adult so 
you take a breather and move on. Or action may be deferred. You may feel sad, but you 
have children to take care of and work to do. You’ll cry later, when you’re watching a 
movie or in the bath. The impulse behind emotion-sensing is to prompt people to some 
kind of action—usually buying stuff or engaging more often. That connection is too 
simplistic. 
It emphasizes body over mind.  In those early web 1.0 days, moving beyond our bodies 
toward a meeting of the minds was celebrated. When John Perry Barlow told us that the 
internet is a “civilization of the mind”, we were hopeful for a more humane and fair 
world. So bringing the body back into the picture might seem a little strange, or it might 
seem exhilarating. It’s certainly new. And technology loves new.  
Emotions have a physiological component, and emotion-sensing puts that back into the 
picture. It takes a physical signal and translates it into an emotion. We do that too. But we 
are not computers. We do that in an individual way based on our experiences, our 
memories, our context. Cognitive appraisal, the evaluation we make in the moment and 
over the long term, is a crucial part of emotions we feel, moods that linger, and attitudes 
that persist.  
It might be too granular. Facial coding and tone analysis can detect fleeting expressions 
that we may not consciously register or we might otherwise miss. Consistently recording 
physical signs of emotion means that our apps will be attuned to the signs of emotion in a 
way that we are not. There may come a time quite soon when our devices start 
to understand our emotions better than we do ourselves, which has its own drawbacks. It 
might also mean that too much weight is given to emotions that are not all that important. 
It might trivialize emotion. Emotion has already been trivialized with hearts and thumbs 
ups. Online, we are quick to demonstrate emotion. Positives are more easily detectable 
because we have actions embedded in the interface. Negatives will start to become more 
detectable through tone analysis of comments or customer service logs. Either way, it’s 
easy to imagine emotion-sensing that detects emotion and offers an immediate, or 
variable, reward based on simple set of algorithmic rules. Recently, IKEA played around 
with this notion by temporarily renaming products according to relationship problems.  
 
26 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
IKEA’s tongue-in-cheek approach to design for the emotion behind the 
product 
 
 
Rosalind Picard, the founder of affective computing, voiced the greatest fear of all. Once 
machines have emotional intelligence, will they replace humans? Picard emphasized that 
affective computing must be practiced only with “the utmost respect for human, their 
thoughts, feelings, and freedom.” 
Just having more technology to identify or interpret emotion doesn’t automatically create 
a more human experience, though. At the heart of emotional artificial intelligence lies a 
paradox. Emotion promises to bring greater empathy to bear on our experiences, and yet 
it will be used to guide and shape emotion.  
Facebook’s infamous 2012 study, “Experimental evidence of massive-scale emotional 
contagion through social networks,” secretly modified news feeds to include positive or 
negative content. The goal was to see whether it had any effect on behavior. It did.  If the 
goal is to change people’s actual behavior at scale, rewarding only the most profitable 
behaviors, it’s likely to be abused. Rather than rushing to commercialize emotion, the key 
will be calibrating what we expect technology to do. 
Will emotion-sensing technology lead to emotionally intelligent design? Probably not at 
first. Feelings are complicated, and hopeless entangled with identity and experience and 
context. Not to mention emotions mixed up with sensory perception and cognition and 
behaviors. Recognizing five canonical facial expressions is not going to magically make 
 
27 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
us more sensitive. But emotion-sensing technology, by giving us more information about 
emotion, may inspire us to reconsider emotional design. 
Designing for All the Feels 
This chapter reads like a critique of emotional design so far. It is. And it isn’t. Emotion is 
approached with pragmatism, if at all, in the tech world. It’s become a rather formulaic 
finishing touch. That needs to change. 
We are currently designing for a one positive emotion. But we could design for a broader 
range of positive emotions or rich experiences, that tap a complicated and satisfying mix 
of positive and negative emotions. We are trying to humanize our products by giving 
them a brand personality. But we could use a lighter hand using human qualities as a 
foundation rather than a façade.  
And lately we’ve fallen into a trap. By designing positive emotions as a way for people to 
repeatedly cycle through negative emotions, we are responsible for creating behaviors 
that undermine well-being.  
In tech terms, emotional design is due for a refresh. Emotion-sensing technology is 
nudging us to reconsider. If our devices are tuned in to our emotions, can we afford not to 
be? The latest thinking in happiness and well-being is a way forward.  
Positive Emotion is a Spectrum 
Surprise and delight are not the only positive emotions, but we tend to design for these 
intense variations. Positive emotions can vary in intensity, can linger over time, can vary 
with social context. So while we aim to facilitate a positive experience, we generally 
don’t consider nuances. Designing for desire is a fundamentally different challenge than 
designing for relaxation. Designing for compassion is different than designing for 
contentment. 
Not only is there a range of positive emotions, emotions vary in intensity. An emotion 
can be strongly felt before, during, or after an experience. Or can be low-level 
throughout. It can be a mood that colors an entire experience, or a force that intensifies.  
Positive emotion can be mixed up with negative emotions. Think about aspiration as a 
mix of inspiration and envy or awe as a mix of fear and love. Positive and negative 
emotions can be felt in great subtlety and complexity. Earlier this year, I discovered the 
Dictionary of Obscure Sorrows (dictionaryofobscuresorrows.com) where writer John 
Koenig attempts to name feelings you might not even have known but instantly 
recognize. All of this points to the need to expand our range. 
Positive Emotion is in the Body and in the Mind 
In the past decade, we’ve made some assumptions about how designs produce happiness, 
whether through delightful details or brand mascots or purely practical servicing of 
needs. Design researchers are mixing more methods than ever before to understand 
experience, ranging from ethnographic interviews to usability testing to analytics. We 
mix exploratory methods to explore unspoken needs with evaluative methods to assess 
the success of the design. But most design research considers emotion only tangentially.  
 
28 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
The focus is primarily on observed behavior, measurable actions, or reported thoughts. 
Gestures and facial expressions may be noted but it’s certainly not the type of data that is 
available through analytics. Biometrics are still not the norm in the research process 
because, until recently, it has been too expensive and time-consuming. Whether from 
qualitative research or quantitative sources, teams simply don’t have a lot of data about 
emotion readily available to inform design. 
If we design for positive emotion as an outcome, the next wave of design research will 
have to look at how people experience emotion, whether it’s something we feel 
physically, something we do, something we construct in our mind, or maybe something 
bigger entirely. Moving forward, we need to use a mix of methods to understand the 
multiple dimensions of human emotion.  
A New Mix of Research Methods 
Diagram of positive emotions and behaviors  
At present, we privilege behavioral. It’s easy to see why. Product design is about 
outcomes. So we’ve come to trust what people do, more than what they say. Steve Jobs 
famously stated that people can’t articulate their needs, after all. But when it comes to 
emotion, there are layers. What people do is connected to how they reflect on their own 
feelings, how they understand their feelings in a social context, and how they physically 
experience emotion. We need to understand all of it in a respectful way. 
Positive Emotion Shapes Positive Behavior 
Positive emotions have distinct and specific behavioral effects, according to the work of 
Barbara Frederickson. Joy encourages play and creativity, contentment leads us to savor, 
hope prompts openness to new information and motivates sustained effort in the face of a 
challenge.  
When it comes to products, digital or physical, positive emotion can have the same effect. 
Surprise draws a person’s attention, leading to increased recall and recognition. A 
product that inspires can lead to creative thought or a shift in perspective. A feeling of 
interest engages exploration in the product itself but also in the possibilities it promises.  
If we look at the design of physical spaces, this approach is not entirely new. The design 
of buildings, neighborhoods, and cities has a profound effect on health and happiness. 
Disney has been designing happiness into its parks for a reason. In Happy City, Charles 
Montgomery looks at how the designs of urban spaces can shape happiness, In places like 
Bogota, happiness is an explicit design goal. Public spaces, buses, city blocks can be 
designed to foster trust and build community.  
Mapping emotion to behavior is tricky though. The temptation is to simplify, especially 
for pragmatic types who work in tech under tight deadlines. So I’ll share a start, but it’s 
by no means prescriptive. And it relies on learning more about how people respond 
emotionally to design.  
A Start at Mapping Positive Emotions to Behaviors 
 
29 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
Diagram of positive emotions and behaviors  
Toward Emotionally Intelligent Design 
In the near future, emotion will be designed into the experience. For example, the text 
your mobile wallet sends to tell you that your impulse clothing purchase won’t make you 
happy will be designed. The screen on your refrigerator that cautions you to wait 20 
minutes before deciding to binge on ice cream after a stressful day will be designed. The 
visualization of your child’s emotion data during a school day, and suggested responses, 
will also be designed. So we will be called upon to design for a mess of human emotion 
and a range of positive outcomes. 
When we think about emotional design, we tend to think about the design itself directly 
influencing happiness. But, there’s a bit more to it than that. Designing with emotional 
intelligence means going bigger.  
Design can cultivate positive emotion in a few ways, as a source, as a symbol, or as 
support.  
Source 
The design itself is what makes someone happy.  
Symbol 
The design represents something or someone that brings happiness.   
Support 
The design supports thoughts, activities, and behaviors that help people live happily.  
Emotional intelligence gives us a way to draw from a rich emotional vocabulary to 
understand strengths and weakness, make space for reflection, and embrace change.    
Positive emotions, like joy, contentment, love, interest, amusement, and pride improve 
individual and collective well-being and physical health. Positive emotions build 
resiliency. Positive emotion can broaden our range. So, okay, positive emotion is 
important.  
Is happiness simply positive emotion(s) though? The last decade of research tells us that 
happiness is a complex than more than an emotion. In a way, positive emotion is the 
outcome. In the next chapter, we will look how our understanding of happiness has 
evolved to encompass multiple factors, not just positive emotion. 
Field Note: The Emotional Range of 
Happiness 
When I first tried to untangle what happiness really meant in relation to technology, I 
quickly realized that it was not going to be as easy as asking “how does this make you 
feel?” Feelings and technology, for most people, do not go together like peanut butter and 
jelly. Most people don’t want to think about their feelings when it comes to technology, 
and there’s not much vocabulary to describe that conflicted emotional relationship 
anyway.  
 
30 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
One of the first things I tried was running two identical studies—identical except for one 
question. I asked people about their favorite website or app. In one study, I asked 250 
people to tell me what emotion they associated with the experience. In the other, I gave 
250 people a list of positive emotions based on Pieter Desmet’s typology of positive 
emotion, which we can see below or visualized at the University of Delft’s website 
(studiolab.ide.tudelft.nl/manila/emotion_rainbow).  
Pieter Desmet’s Positive Emotion Typology  
 
From that study I learned a few things that were foundational to my later research. First, 
contrary to my expectations, people did not just use general words like happy to describe 
how they felt. That was a little surprising to me. I thought people would come up with 
fewer positive terms. Certainly, people did bundle up emotions like love, admiration, and 
respect into bigger concepts like connection, though. This leads me to the next big 
surprise. 
Although the study asked about emotion, people did not always answer with an emotion 
in the open-ended version of the study. Instead, concepts like “creative” or “smart” 
cropped up a lot. Not really emotions, more like capabilities. Thinking of favorites 
experiences as more than just a positive emotion or two aligns with the current thinking 
on happiness, so perhaps I shouldn’t have been so surprised. Happiness is a mix of 
positive emotion and other factors.  
Lastly, intense positive emotions barely registered. Surprise, delight, joy were not at all 
common. Maybe people were playing it cool. Maybe we didn’t catch people right in a 
peak moment. Memory can soften the impact, but it can intensify too. Whatever the case, 
it points to delight as an uncommon occurrence. And it means we need to expand our 
repertoire. 
 
31 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
Lists of Emotional Associations for Favorite Sites or Apps Compared  
Chart of emotions 
Briefly 
• 
We think about designing for emotion as a hierarchy and we climb our way up 
to emotion, almost as a reward. This is not really how emotion works when it 
comes to technology, at least not anymore.  
• 
Emotional design has become synonymous with one emotion—delight. It 
focuses primarily on happiness as pleasure, a hedonic model. But most models 
of happiness privilege eudaumonia—purpose and meaning— over pleasure. 
• 
Delight is in the small details, such as microcopy or fleeting animations. It has 
taken on a particular personality over the past few years, based on a few industry 
leaders. It is clever, cute, and often illustrated. 
• 
Emotional design also aims to humanizes design, typically by creating a brand 
mascot. It literally attempts to give the design human characteristics. Ironically, 
our attempts at humanizing a brand personality often end up as friendly animals. 
Or female assistants, circa 1950. Or Disney channel style butlers. A more subtle 
approach to adding human elements may have a more profound emotional 
impact.  
• 
Behavioral design draws on emotion. It typically starts with a negative 
emotion—like anxiety or boredom—striving to convert it to a positive. When 
measures of success are engagement, or the business model is ad-driven, this 
becomes a cycle of highs and lows that ends up undermining well-being. 
• 
New emotion-sensing technology promises to imbue our devices and apps with 
a broader range of emotional understanding. But emotion-sensing is reductive 
too, relying on less-than-subtle expression in text, voice, or facial expression 
which it simplifies to 5-10 core emotions. 
• 
We still don’t know how to really design for more emotions. So far, we have to 
make some broad assumptions about how emotions connect to thoughts, 
behaviors, and sensory perception. Even behavioral design is skimming the 
surface when it comes to mapping emotional reactions to behaviors or by 
connecting the dots between triggers and emotions.  
• 
Positive emotion is one core aspect of happiness, but there are many different 
positive emotions varying in intensity. Positive emotion is often related to 
negative emotions too. It’s complicated, and we should get comfortable with 
that. 
• 
Design for emotion can do more and be more by looking toward multifactor 
models rather than simply aiming to please. The science of happiness and 
emotional intelligence are better models. 
 
32 
 

O’Reilly Media, Inc. 
 
1/19/2017 
 
 
33 
 
Further  
• 
If you haven’t read Don Norman’s Emotional Design: Why We Love (or Hate) 
Everyday Things (2005) recently, go back and read it again. The last chapters on 
emotion and robots now seem even more relevant to me than on my first read. 
• 
Familiarize yourself with Aaron Walter’s Designing for Emotion (2011) and 
Trevor von Gorp and Edie Adam’s Design for Emotion (2012). Both solid 
jumping off points for the next phase of emotional design. 
• 
The Media Equation: How People Treats Computers, Television, and New 
Media Like People and Places (1996) by Clifford Nass is a seminal read, in the 
context of brand personality and especially relevant for conversational 
technology. 
• 
Affective Computing (1997) by Rosalind Picard is the primary text for emotion-
sensing technology, dense but worth the effort. 
• 
Emotions Revealed by Paul Ekman, or the more technical Emotion in the Human 
Face, documents the facial action coding system. It might sound familiar if you 
read Malcolm Gladwell’s Blink, too. Stamen’s Atlas of Emotions 
(www.paulekman.com/atlas-of-emotions) is a mesmerizing visualization of Paul 
Ekman’s work in collaboration with the Dalai Lama.  
• 
Daniel Goleman’s Emotional Intelligence (1996) is controversial but is a 
promising model for understanding emotion that can be applied to technology. 
• 
It’s easy to lose yourself in all the wonderful wisdom of Alain de Botton’s 
School of Life (www.theschooloflife.com), plus it’s a very approachable way to 
learn about emotional intelligence. 
• 
Watch Inside Out! 
 
 
 

