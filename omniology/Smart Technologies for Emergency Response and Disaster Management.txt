
Smart Technologies for 
Emergency Response and 
Disaster Management
Zhi Liu
Waseda University, Japan
Kaoru Ota
Muroran Institute of Technology, Japan
A volume in the Advances in Public Policy and 
Administration (APPA) Book Series 

Published in the United States of America by
IGI Global
Information Science Reference (an imprint of IGI Global)
701 E. Chocolate Avenue
Hershey PA, USA 17033
Tel: 717-533-8845
Fax:  717-533-8661 
E-mail: cust@igi-global.com
Web site: http://www.igi-global.com
Copyright © 2018 by IGI Global.  All rights reserved. No part of this publication may be reproduced, stored or distributed in 
any form or by any means, electronic or mechanical, including photocopying, without written permission from the publisher.
Product or company names used in this set are for identification purposes only. Inclusion of the names of the products or 
companies does not indicate a claim of ownership by IGI Global of the trademark or registered trademark.
	
	
	
Library of Congress Cataloging-in-Publication Data
British Cataloguing in Publication Data
A Cataloguing in Publication record for this book is available from the British Library.
All work contributed to this book is new, previously-unpublished material. The views expressed in this book are those of the 
authors, but not necessarily of the publisher.
For electronic access to this publication, please contact: eresources@igi-global.com.
Names: Liu, Zhi, 1986- editor. | Ota, Kaoru, 1984- editor.
Title: Smart technologies for emergency response and disaster management / 
   Zhi Liu and Kaoru Ota, editors.
Description: Hershey, PA : Information Science Reference, [2018]
Identifiers: LCCN 2017006791| ISBN 9781522525752 (hardcover) | ISBN 
   9781522525769 (ebook)
Subjects: LCSH: Emergency management--Technological innovations. | Emergency 
   management--Information technology.
Classification: LCC HV551.2 .S6185 2018 | DDC 363.340285--dc23 LC record available at https://lccn.loc.gov/2017006791
 
This book is published in the IGI Global book series Advances in Public Policy and Administration (APPA) (ISSN: 2475-
6644; eISSN: 2475-6652)

Advances in Public Policy and 
Administration (APPA) Book 
Series
Proper management of the public sphere is necessary in order to maintain order in modern society. Re-
search developments in the field of public policy and administration can assist in uncovering the latest 
tools, practices, and methodologies for governing societies around the world.
The Advances in Public Policy and Administration (APPA) Book Series aims to publish schol-
arly publications focused on topics pertaining to the governance of the public domain. APPA’s focus on 
timely topics relating to government, public funding, politics, public safety, policy, and law enforcement 
is particularly relevant to academicians, government officials, and upper-level students seeking the most 
up-to-date research in their field.
Mission
ISSN:2475-6644 
 EISSN:2475-6652
•	Government
•	Law enforcement
•	Political Economy
•	Politics
•	Public Administration
•	Public Funding
•	Public Policy
•	Resource Allocation
•	Urban Planning
Coverage
IGI Global is currently accepting manuscripts 
for publication within this series. To submit a pro-
posal for a volume in this series, please contact our 
Acquisition Editors at Acquisitions@igi-global.com 
or visit: http://www.igi-global.com/publish/.
The Advances in Public Policy and Administration  (APPA) Book Series (ISSN 2475-6644) is published by IGI Global, 701 E. Chocolate 
Avenue, Hershey, PA 17033-1240, USA, www.igi-global.com. This series is composed of titles available for purchase individually; each title 
is edited to be contextually exclusive from any other title within the series. For pricing and ordering information please visit http://www.igi-
global.com/book-series/advances-public-policy-administration/97862. Postmaster: Send all address changes to above address. Copyright © 
2018 IGI Global. All rights, including translation in other languages reserved by the publisher. No part of this series may be reproduced or 
used in any form or by any means – graphics, electronic, or mechanical, including photocopying, recording, taping, or information and retrieval 
systems – without written permission from the publisher, except for non commercial, educational use, including classroom teaching purposes. 
The views expressed in this series are those of the authors, but not necessarily of IGI Global.

Titles in this Series
For a list of additional titles in this series, please visit: www.igi-global.com/book-series
Ideological Messaging and the Role of Political Literature
Önder Çakırtaş (Bingol University, Turkey) 
Information Science Reference • copyright 2017 • 317pp • H/C (ISBN: 9781522523918) • US $175.00 (our price)
Therapeutic Jurisprudence and Overcoming Violence Against Women
Debarati Halder (Centre for Cyber Victim Counselling (CCVC), India & Unitedworld School of Law, India) and 
K. Jaishankar (Raksha Shakti University, India) 
Information Science Reference • copyright 2017 • 344pp • H/C (ISBN: 9781522524724) • US $230.00 (our price)
Public Sector Entrepreneurship and the Integration of Innovative Business Models
Mateusz Lewandowski (Jagiellonian University in Kraków, Poland) and Barbara Kożuch (Jagiellonian University 
in Kraków, Poland) 
Business Science Reference • copyright 2017 • 309pp • H/C (ISBN: 9781522522157) • US $190.00 (our price)
Handbook of Research on Citizen Engagement and Public Participation in the Era of New Media
Marco Adria (University of Alberta, Canada) and Yuping Mao (California State University Long Beach, USA) 
Information Science Reference • copyright 2017 • 503pp • H/C (ISBN: 9781522510819) • US $265.00 (our price)
Global Perspectives on Development Administration and Cultural Change
Gbenga Emmanuel Afolayan (Murdoch University, Australia) and Akeem Ayofe Akinwale (University of Lagos, 
Nigeria) 
Information Science Reference • copyright 2017 • 277pp • H/C (ISBN: 9781522506294) • US $170.00 (our price)
Handbook of Research on Managerial Solutions in Non-Profit Organizations
Vojko Potocan (University of Maribor, Slovenia) Mustafa C. Ünğan (Sakarya University, Turkey) and Zlatko 
Nedelko (University of Maribor, Slovenia) 
Information Science Reference • copyright 2017 • 609pp • H/C (ISBN: 9781522507314) • US $300.00 (our price)
Achieving Open Justice through Citizen Participation and Transparency
Carlos E. Jiménez-Gómez (Department of Justice of the Autonomous Government of Catalonia, Spain) and Mila 
Gascó-Hernández (Institute of Public Governance and Management, ESADE Business and Law School, Spain) 
Information Science Reference • copyright 2017 • 296pp • H/C (ISBN: 9781522507178) • US $190.00 (our price)
Emerging Strategies in Defense Acquisitions and Military Procurement
Kevin Burgess (Cranfield University, UK) and Peter Antill (Cranfield University, UK) 
Information Science Reference • copyright 2017 • 351pp • H/C (ISBN: 9781522505990) • US $205.00 (our price)
701 East Chocolate Avenue, Hershey, PA 17033, USA
Tel: 717-533-8845 x100 • Fax: 717-533-8661
E-Mail: cust@igi-global.com • www.igi-global.com

﻿
Table of Contents
﻿
Preface...................................................................................................................................................xii
Chapter 1
Smart Technologies for Emergency Response and Disaster Management: New Sensing 
Technologies or/and Devices for Emergency Response and Disaster Management................................ 1
Kavitha T, BNM Institute of Technology, India
Saraswathi S, SSN College of Engineering, India
Chapter 2
Reliable Communication Network for Emergency Response and Disaster Management in 
Underground Mines............................................................................................................................... 41
S. M. Kamruzzaman, Ryerson University, Canada
Xavier Fernando, Ryerson University, Canada
Muhammad Jaseemuddin, Ryerson University, Canada
Wisam Farjow, PBE Group, Canada
Chapter 3
WiFi Fingerprint Localization for Emergency Response: Harvesting Environmental Dynamics for 
a Rapid Setup......................................................................................................................................... 86
Yu Gu, Hefei University of Technology, China
Min Peng, Hefei University of Technology, China
Fuji Ren, University of Tokushima, Japan
Jie Li, Tsukuba Science City, Japan
Chapter 4
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation of MANET 
Communication Protocols in Disaster Scenarios................................................................................. 106
José Manuel García-Campos, University of Seville, Spain
Daniel Gutiérrez, University of Seville, Spain
Jesús Sánchez-García, University of Seville, Spain
Sergio Toral, University of Seville, Spain
Chapter 5
Processing Big Data for Emergency Management.............................................................................. 144
Rajendra Akerkar, Western Norway Research Institute, Norway

﻿
Chapter 6
Exploring Cloud-Based Distributed Disaster Management With Dynamic Multi-Agents Workflow 
System.................................................................................................................................................. 167
Mansura Habiba, AIUB, Bangladesh
Shamim Akhter, East West University, Bangladesh
Chapter 7
Data Storages in Wireless Sensor Networks to Deal With Disaster Management.............................. 196
Mehdi Gheisari, Guangzhou University, China
Mehdi Esnaashari, K. N. Toosi University of Technology, Iran
Chapter 8
Application of Game Theory for Network Recovery After Large-Scale Disasters............................. 223
Bo Gu, Kogakuin University, Japan
Osamu Mizuno, Kogakuin University, Japan
Chapter 9
Communication Process of Disaster Management: Shift From Web 2.0 to Web 3.0.......................... 243
Ashir Ahmed, Swinburne University of Technology, Australia
Chapter 10
Using Long Endurance Remotely Piloted Aircraft Systems to Support Humanitarian Logistic 
Operations: A Case Study of Cyclone Winston................................................................................... 264
Peter Tatham, Griffith University, Australia
Catherine M. Ball, Remote Research Ranges, Australia
Yong Wu, Griffith University, Australia
Pete Diplas, HK Logistics, Australia
Compilation of References................................................................................................................ 279
About the Contributors..................................................................................................................... 306
Index.................................................................................................................................................... 311

﻿
Detailed Table of Contents
﻿
Preface...................................................................................................................................................xii
Chapter 1
Smart Technologies for Emergency Response and Disaster Management: New Sensing 
Technologies or/and Devices for Emergency Response and Disaster Management................................ 1
Kavitha T, BNM Institute of Technology, India
Saraswathi S, SSN College of Engineering, India
Disasters are the convergence of hazards that strikes a vulnerable community which is insufficient to 
withstand with its adverse effects and impact. Completely avoiding natural or anthropogenic disaster is not 
possible but its impact can be minimized by generating timely warning. The real-time earth observation 
is very important for generating such early warning. The earth observation is improving through the 
advancement in remote sensing technologies. Sensing technology provides real time monitoring and 
risk assessment. It helps in fast communication of an event occurrence. Disaster detection in urban 
areas is greatly improved by using remote sensing techniques. This chapter discus various devices used 
for real time earth monitoring of disaster events like Flood, Tsunami, Tornadoes, Droughts, Extreme 
Temperatures, Avalanches and Landslide. These devices gather information by continuous monitoring 
in their deployed location. The sensor information thus gathered must be communicated and processed 
to extract the disaster information.
Chapter 2
Reliable Communication Network for Emergency Response and Disaster Management in 
Underground Mines............................................................................................................................... 41
S. M. Kamruzzaman, Ryerson University, Canada
Xavier Fernando, Ryerson University, Canada
Muhammad Jaseemuddin, Ryerson University, Canada
Wisam Farjow, PBE Group, Canada
Emergency response and disaster management in underground mines are very challenging due to the 
hostile nature. Environment monitoring in mines has been an obligatory requirement to ensure safe 
working conditions for miners. Reliable communication network is essential to quickly detect the 
underground condition especially in emergency situation and to conduct proper rescue operations. 
This chapter presents an overview of reliable communication network needed for emergency response 
and disaster management in underground mines. The chapter begins by introducing the most common 
accidents occurring in the mining, underground mine environment and channel properties. Subsequently, 
communications in underground mines, existing underground communication and tracking systems, and 

﻿
disaster forecasting & mine safety management are discussed. The chapter also covers post-disaster mine 
communications & tracking systems and optimized backbone networks for underground mines. Finally, 
the chapter concludes by reporting relevant research at Ryerson Communications Lab and pointing out 
some open issues and possible research directions.
Chapter 3
WiFi Fingerprint Localization for Emergency Response: Harvesting Environmental Dynamics for 
a Rapid Setup......................................................................................................................................... 86
Yu Gu, Hefei University of Technology, China
Min Peng, Hefei University of Technology, China
Fuji Ren, University of Tokushima, Japan
Jie Li, Tsukuba Science City, Japan
As a key enabler for diversified location-based services (LBSs) of pervasive computing, indoor WiFi 
fingerprint localization remains a hot topic for decades. For most of previous research, maintaining a 
stable Radio Frequency (RF) environment constitutes one implicit but basic assumption. However, there is 
little room for such assumption in real-world scenarios, especially for the emergency response. Therefore, 
we propose a novel solution (HED) for rapidly setting up an indoor localization system by harvesting 
from the bursting number of available wireless resources. Via extensive real-world experiments lasting 
for over 6 months, we show the superiority of our HED algorithm in terms of accuracy, complexity and 
stability over two state-of-the-art solutions that are also designed to resist the dynamics, i.e., FreeLoc and 
LCS (Longest Common Subsequences). Moreover, experimental results not only confirm the benefits 
brought by environmental dynamics, but also provide valuable investigations and hand-on experiences 
on the real-world localization system.
Chapter 4
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation of MANET 
Communication Protocols in Disaster Scenarios................................................................................. 106
José Manuel García-Campos, University of Seville, Spain
Daniel Gutiérrez, University of Seville, Spain
Jesús Sánchez-García, University of Seville, Spain
Sergio Toral, University of Seville, Spain
The need for a Mobile Ad-Hoc Network (MANET) in environments where there is a lack of communication 
infrastructure, such as disaster or emergency scenarios, is critical to save lives. MANETs can be used 
as an alternative network that solves the problem of communications. The selection of an appropriate 
MANET communication protocol is crucial for the good performance of the whole network. Due to 
the great variety of communication protocols available for MANETs such as routing and broadcasting 
protocols, the selection of the most suitable one for disaster scenarios is a relevant task. Routing 
protocols and broadcasting algorithms are normally evaluated and compared using simulation-based 
studies. However, conducting reliable and repeatable simulation studies is not a trivial task because 
many simulation parameters should be correctly configured. In this paper, we propose a methodology for 
conducting reliable simulations of MANET broadcasting algorithms in disaster scenarios. The proposed 
methodology is focused on the source nodes selection based on different metrics.

﻿
Chapter 5
Processing Big Data for Emergency Management.............................................................................. 144
Rajendra Akerkar, Western Norway Research Institute, Norway
Emergencies are typically complex problems with serious consequences that must be solved in a limited 
amount of time to reduce any possible damage. Big data analysis leads to more assured decision making 
and better decisions can mean greater operational efficiencies, cost reductions and reduced risk. In this 
chapter, we discuss some issues on tackling emergency situation from the perspective of big data processing 
and management, including our approach for processing social media content. Communications during 
emergencies are so plentiful that it is necessary to sift through enormous data points to find information 
that is most useful during a given event. The chapter also presents our ongoing IT-system that processes 
and analyses social media data to transform the excessive volume of low information content into small 
volume but rich content that is useful to emergency personnel.
Chapter 6
Exploring Cloud-Based Distributed Disaster Management With Dynamic Multi-Agents Workflow 
System.................................................................................................................................................. 167
Mansura Habiba, AIUB, Bangladesh
Shamim Akhter, East West University, Bangladesh
Natural disaster is one of the important topics in current researches. Disaster Management System (DMS) 
is a complex system and needs to perform a collection of tasks collaboratively along with the potentiality 
to change the configurations of the system dynamically. In the research era of workflow model, existing 
models mainly deal with temporal and static constrains. However they cannot be used to keep pace with 
an uncertainly dynamic system like disaster management. Considering all these significant DMS attributes 
we have designed a new dynamically configurable and changeable workflow model with the support of 
adaptive scheduling, for both successful and failed situations, and implemented in a distributed cloud 
system to maintain the rescue and reorganization activities of disaster situation. In order to simplify the 
system architecture, we have used Multi Agent System (MAS) for our design. The proposed system 
achieves a comparatively higher rate of successful job completion-higher rescheduling success rate and 
comparatively lower dropout rate.
Chapter 7
Data Storages in Wireless Sensor Networks to Deal With Disaster Management.............................. 196
Mehdi Gheisari, Guangzhou University, China
Mehdi Esnaashari, K. N. Toosi University of Technology, Iran
Sensor networks are dense wired or wireless networks used for collecting and disseminating environmental 
data. They have some limitations like energy that usually provide by battery and storages in order that we 
cannot save any generated data. The most energy consumer of sensors is transmitting. Sensor networks 
generate immense amount of data. They send collected data to the sink node for storage to response 
to users queries. Data storage has become an important issue in sensor networks as a large amount of 
collected data need to be archived for future information retrieval. The rapid development and deployment 
of sensor technology is intensifying the existing problem of too much data and not enough knowledge. 
Sensory data comes from multiple sensors of different modalities in distributed locations. In this chapter 
we investigate some major issues with respect to data storages of sensor networks that can be used for 
disaster management more efficiently.

﻿
Chapter 8
Application of Game Theory for Network Recovery After Large-Scale Disasters............................. 223
Bo Gu, Kogakuin University, Japan
Osamu Mizuno, Kogakuin University, Japan
In recent years, large-scale disasters took place frequently and always caused severe damages to the 
network infrastructures. Due to these damages, available network resources are usually not sufficient to 
meet the data transmission requirements of users after disasters. Moreover, users tend to behave selfishly 
by consuming as much network resources as possible. Incentive mechanisms are therefore essential for 
the users to voluntarily cooperate with each other and improve the system performance. In commercial 
networks, this can be efficiently achieved through pricing. Namely, by selecting an appropriate pricing 
policy, it is able to incentivize users to choose the service that best matches their data transmission 
demands. In this chapter, assuming that a time-dependent pricing scheme is imposed on network users, 
a Stackelberg leader-follower game is then formulated to study the joint utility optimization problem of 
the users in a disaster region subject to maximum delay and storage constrains. The equilibrium for the 
Stackelberg leader-follower game is also investigated.
Chapter 9
Communication Process of Disaster Management: Shift From Web 2.0 to Web 3.0.......................... 243
Ashir Ahmed, Swinburne University of Technology, Australia
The importance of effective and timely communication is critical in disaster management life cycle. 
With the proliferation of communication and web technologies, the challenge has now shifted from the 
availability of information to the efficient handling of the sheer amount of information available online. This 
has attracted researchers and practitioners to find ways which can facilitate individuals and organizations 
in their decision making while dealing with large amounts of online data. This chapter presents (1) the 
evolution of web technologies from Web 1.0 to Web 3.0, (2) the overview of communications tasks 
involved in disaster management, and (3) the literature survey on the pros and cons of Web 2.0 and Web 
3.0 in disaster management. By comparing the role of Web 2.0 with Web 3.0, the chapter also attempts 
to explore how the communication tasks of disaster management could be improved using Web 3.0. It is 
anticipated that the findings of this chapter will assist the decision makers to use Web 3.0 as a strategic 
tool for effective communication in disaster management.

﻿
Chapter 10
Using Long Endurance Remotely Piloted Aircraft Systems to Support Humanitarian Logistic 
Operations: A Case Study of Cyclone Winston................................................................................... 264
Peter Tatham, Griffith University, Australia
Catherine M. Ball, Remote Research Ranges, Australia
Yong Wu, Griffith University, Australia
Pete Diplas, HK Logistics, Australia
Whilst there has been some limited use of Remotely Piloted Aircraft Systems (RPAS) as part of the 
response to natural disasters, to date these have typically employed short range mini or micro systems. 
Using a case study of Cyclone Winston that struck Fiji in February 2016, this chapter demonstrates the 
potential for long endurance aircraft (LE-RPAS) to support the humanitarian logistic operations through 
the use of their high quality optics and communications capabilities. In doing so, it offers a high level 
route map for the development of the people, process and technology requirements that will be needed 
to underpin the future deployments of LE-RPAS in providing support to humanitarian activities.
Compilation of References................................................................................................................ 279
About the Contributors..................................................................................................................... 306
Index.................................................................................................................................................... 311

﻿
Preface
﻿
Disaster becomes an emerging and critical issues worldwide. Not matter the natural disaster (such as 
the earthquake and tsunami in Japan) or the social disaster (such as the stampede happened recently in 
multiple places during the festivals), great losses have been brought to our living society and environ-
ment. How to utilize the information and communication technology to help better manage the emer-
gency and disaster in terms of prevention, detection, assistance/recovery, and post-processing hence 
has great impacts. There is system implemented or being implemented for emergency response and 
disaster management in various countries (such as Thailand, Malaysia) and these systems do provide 
good performance, although there are room for improvement.
This book looks to discuss and address the difficulties, challenges and solution in Smart Technologies 
for Emergency Response and Disaster Management. The editors seek chapters that address different 
aspects of Smart Technologies for Emergency Response and Disaster Management, ranging from net-
work technology for emergency response and disaster management, big data for emergency response and 
disaster management to robotics emergency response and disaster management. Additionally, the book 
also explores the implementation issues when these technologies are adopted for emergency response 
and disaster management. For each aspect, future work is also discussed.
INSIDE THIS BOOK
In this regard, the first article discusses new sensing technologies and devices for various disasters like 
Flood, Tsunami, Tornadoes, Droughts, Extreme Temperatures, Avalanches and Landslides. The devices 
for flood detection is discussed, that would find the height of water, sudden increase in water level, amount 
of rain in an area. The tsunami detection devices monitor the sea waves, underground water pressure 
and sea level to predict the occurrence of tsunami. Tornadoes detection is possible by monitoring the 
wind. Drought detection devices monitor the air pressure and the amount of water in the reservoir. Wind 
temperature and humidity monitoring devices help in predicting the extreme temperature. In avalanche 
forecasting, avalanche activities like acoustic, infrasonic or seismic emissions are used as important 
parameter. These sensing devices help in gathering information on the installed location and helps in 
generating timely information and early warning of potential hazards.
The second chapter presents an overview of reliable communication network needed for emergency 
response and disaster management in underground mines. This chapter begins by introducing the most 
common accidents occurring in the mining, underground mine environment and channel properties. 
Subsequently, communications in underground mines, existing underground communication and tracking 
xii

Preface
systems, and disaster forecasting and mine safety management are discussed. This chapter also covers 
post-disaster mine communications and tracking systems and optimized backbone networks for under-
ground mines. Finally, this chapter concludes by reporting relevant research at Ryerson Communications 
Lab and pointing out some open issues and possible research directions.
Location constitutes one of the most critical contexts of the emergency response and disaster moni-
toring. The third chapter addresses the environmental dynamics caused by the blossom of wireless de-
vices in the indoor WiFi fingerprint localization. While previous research may consider them as threats 
hampering the localization efficiency, the authors argue that certain factor could be utilized for better 
performance via an empirical study. With the hand-on experiences, the authors propose HED, an order-
tolerance sequences matching algorithm to harvest from the environmental dynamics. The basic idea is 
to utilize all the wireless sources that can be detected while combating demerits such as AP disorders 
and signal variance. The HED in two real-world scenarios is implemented and extensive experiments are 
conducted lasting for over 6 months to verify its performance. By comparing it with other state-of-the-art 
algorithms (i.e., FreeLoc and LCS), the authors show its superiority terms of localization accuracy and 
performance stability while maintaining reasonable computational complexity. oreover, critical insights 
and valuable hand-on experiences have been obtained, which offer in-depth understandings about the 
impact of various environmental dynamics in the real-world applications.
The fourth chapter presents a methodology to obtain reliable simulation results in disaster scenarios 
for MANETs. Using this methodology, the performance metric means and the dispersion of the simula-
tion result are improved. This is based on different simulation aspects, for example with the measure-
ment period the results are lesser scattered, discrepancies in terms of number of hops and availability 
path are avoid using the source and destination node selection. The authors demonstrate the importance 
of the used methodology to obtain reliable measurements with a low number of simulations. The pro-
posed methodology is extended for the evaluation of MANET communication broadcasting protocols. 
This one is based on the topological properties of the scenario such as partition degree and separation 
in number of hops. This methodology is also validated in the scenario under test. The researchers also 
demonstrate the importance of these metrics in the simulation results. Using this approach, lesser disper-
sion is guaranteed. Finally, the authors have validated the proposed methodology in the scenario under 
test, by comparing well-known routing and broadcasting protocols.
Big data analysis leads to more assured decision making and better decisions can mean greater op-
erational efficiencies, cost reductions and reduced risk. In Chapter 5, the authors discuss some issues on 
tackling emergency situation from the perspective of big data processing and management, including the 
authors’ proposed approach for processing social media content. Communications during emergencies 
are so plentiful that it is necessary to sift through enormous data points to find information that is most 
useful during a given event. The chapter also presents the authors’ ongoing IT-system that processes 
and analyses social media data to transform the excessive volume of low information content into small 
volume but rich content that is useful to emergency personnel.
Disaster Management System (DMS) is a complex system and needs to perform a collection of tasks 
collaboratively along with the potentiality to change the configurations of the system dynamically. In 
the research era of workflow model, existing models mainly deal with temporal and static constrains. 
However they cannot be used to keep pace with an uncertain and dynamic system like disaster manage-
ment. Considering all these significant DMS attributes, the authors have designed a new dynamically 
configurable and changeable workflow model with the support of adaptive scheduling, for both suc-
xiii

Preface
cessful and failed situations, and implemented in a distributed cloud system to maintain the rescue and 
reorganization activities of disaster situation in Chapter 6. In order to simplify the system architecture, 
the authors have used Multi Agent System (MAS) for our design. The proposed system achieves a com-
paratively higher rate of successful job completion-higher rescheduling success rate and comparatively 
lower dropout rate.
Chapter 7 introduces and formalizes a new Hierarchical Sensor Data Storage that divide sensors into 
some clusters, the node in a cluster that collect sensor data; sensor data send their data in SWE form; 
named cluster head, then aggregate received sensor data, then send aggregated data into sink. Sink nodes 
collect data for further process like response more variety of queries, etc. The system details and the 
performances are shown.
Chapter 8 considered a delay tolerant network where messengers deliver data between disaster and 
normal regions. Pricing is used as an incentive mechanism to reward nodes in disaster regions to select 
the amount of data that best matches its demand. The authors first review the state of art of network 
pricing and then proposed a usage-based-time-dependent pricing scheme that fits well with the purpose. 
The authors then constructed a Stackelberg game to analyze the interactions between the nodes in a 
disaster region and the messenger aiming to maximize the joint utility of the nodes, and characterized 
the Nash equilibrium solution of the game.
Chapter 9 presents an evolution of web technologies from Web 1.0 to Web 3.0, the overview of com-
munications tasks involved in disaster management and the literature survey on the pros and cons of Web 
2.0 and Web 3.0 in disaster management. By comparing the role of Web 2.0 with Web 3.0, the chapter 
also attempts to explore how the communication tasks of disaster management could be improved by 
the use of Web 3.0. It is anticipated that the findings of this chapter will assist the key participants to 
use Web 3.0 as a strategic tool for effective communication in disaster management.
The last chapter considers the potential benefits and costs of the operation of long endurance RPAS 
(LE-RPAS) in support of the logistic response to natural disasters. This chapter first offers a brief over-
view of the generic humanitarian logistic (HL) challenge. It will then provide a summary of the literature 
relating to RPAS in an HL context before discussing the capabilities of a typical LE-RPAS. An overview 
of Cyclone Winston follows, after which the chapter will outline ways in which an LE-RPAS could have 
been used to mitigate the cyclone’s impact. The chapter will end with a discussion of the areas of further 
work that will be needed to underpin a broader use of LE-RPAS to support the HL response to a disaster.
CONCLUSION
Smart Technologies for Emergency Response and Disaster Management have drawn great interest from 
industry and academia. These research activities help us to better respond to the emergent events and to 
manage the disaster in an interdisciplinary and multidisciplinary manner with a comprehensive set of 
knowledge, skills, techniques and approaches. These led to satisfactory performances as can be observed 
in each chapter.
However, the current research about Smart Technologies for Emergency Response and Disaster 
Management is far from enough. There are still many open issues to be solved. We hope this can arise 
more interests from industry and academia to help seal this gap and make our lives better.
xiv

1
Copyright © 2018, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.
Chapter  1
DOI: 10.4018/978-1-5225-2575-2.ch001
ABSTRACT
Disasters are the convergence of hazards that strikes a vulnerable community which is insufficient to 
withstand with its adverse effects and impact. Completely avoiding natural or anthropogenic disaster is 
not possible but its impact can be minimized by generating timely warning. The real-time earth observa-
tion is very important for generating such early warning. The earth observation is improving through 
the advancement in remote sensing technologies. Sensing technology provides real time monitoring 
and risk assessment. It helps in fast communication of an event occurrence. Disaster detection in urban 
areas is greatly improved by using remote sensing techniques. This chapter discus various devices used 
for real time earth monitoring of disaster events like Flood, Tsunami, Tornadoes, Droughts, Extreme 
Temperatures, Avalanches and Landslide. These devices gather information by continuous monitoring 
in their deployed location. The sensor information thus gathered must be communicated and processed 
to extract the disaster information.
Smart Technologies for 
Emergency Response and 
Disaster Management:
New Sensing Technologies or/and 
Devices for Emergency Response 
and Disaster Management
Kavitha T
BNM Institute of Technology, India
Saraswathi S
SSN College of Engineering, India

2
Smart Technologies for Emergency Response and Disaster Management
﻿
INTRODUCTION
We cannot stop disasters but we can arm ourselves with knowledge.
Disasters are the convergence of hazards with vulnerabilities. Disasters occur as a result of a hazard 
that strikes a vulnerable community which is insufficient to withstand with its adverse effects and im-
pact. Typically, disasters are classifiable into two basic groups: natural and anthropogenic. Among the 
natural disasters are earthquakes, volcanoes, hurricanes, floods, and fires. Among the anthropogenic 
disasters are war, pollution, nuclear explosions, fires, hazardous materials exposures, explosions, and 
transportation accidents.
Countries around the world face threats from both natural and anthropogenic disasters causing 
enormous destruction which creates human sufferings and producing negative impacts on national 
economies. Though it is not possible to completely avoid the natural disasters, but the sufferings can 
be minimized by creating timely awareness of the likely disasters through warning system. Its impact 
can also be reduced by incorporating disasters management policies and realization through application 
of information technology tools and devices. The changing trends have opened up a large number of 
scientific and technological resources and skills to reduce disaster risk.
The effective response to a disaster includes timely information (Farzad, 2015) and early warning of 
potential hazards. Science and technology plays an increasingly vital role in providing a timely response 
to manage disasters. Countries are continually improving their disaster detection and early warning ca-
pabilities (Rivera, J.Y. 2016). For this a growing number of OECD countries have recently established 
programmes or incentives to develop and deploy information and communication technologies (ICTs), 
geographic information systems, Sensing technologies and devices.
When a disaster strikes, remote sensing is often the only way to view what is happening on the 
ground. Remote sensing is the science of acquiring information about an object or phenomenon without 
making physical contact with the object using sensing or multivariable sensing (Watanabe et al., 2010) 
devices and technology in which their output have been assumed to be correct. It is inherently useful for 
disaster management. The data derived using sensing devices like in wireless sensor network (Devasena 
& Sowmya 2015 and Rahman et al., 2016) are excellent in mapping the spatial distribution of disaster 
related data within a relatively short period of time. However decision made by incorrect measurement 
even leads to disaster. To overcome this problem advanced validation technique (Shen & Wang 2013) 
also needs to be incorporated.
The rest of the chapter is organized as follows: Section 2 and 3 provides information about Flood and 
Tsunami. Section 4 and 5 describes Tornadoes and Drought respectively. Section 6 discusses the Extreme 
temperatures and section 7 is about Avalanches. Finally, section 8 provides the Landslide.
FLOOD
Flood is an overflow of water from water bodies like river, lake, ocean that submerges lands that are 
not usually covered by water. Countries throughout the world suffer from several floods. These floods 
cause serious damages to Public property, Private property as well as life. While the countries prepare 
for flood it still cause’s damage. It is essential to have flood warning systems that would provide warn-
ing of locations under flood risk. The warning system must continuously monitor, record and collect the 

3
Smart Technologies for Emergency Response and Disaster Management
﻿
data about critical rainfall, stream level automatically as described by Sun.G. et al. (2015) and predict 
whether flood (Indira, Kabita & Chandrakant, 2015) is about to occur, how severe it will be (Horita et 
al., 2015) and the areas under flood danger. Flood can be detected or predicted using sensor. Various 
sensors are available to measure the water level raise, rainfall rate and water flow rate. The sensors to 
measure the water level (Sunkpho et al., 2011) are called float level sensors. Along with sensors, wireless 
technology can be integrated to provide the information about the water levels of dams, when to open 
the gate and to which limit. Anita et al. (2015) discussed about the wireless management and monitor-
ing systems for dams. Chen et al., (2014) developed a sensor web heterogeneous node meta-model for 
flood monitoring system. 
Float Level Sensors
Magnetic Float
The principle float level sensor (Odli et al.,2016) often involves the opening or closing of a switch. With 
magnetically actuated float sensors, switching occurs when a permanent magnet sealed inside a float 
rises or falls to the actuation level. It can be signalled with multiple liquid level point measurement. It 
can be designed smarter for both liquid level and flow level detection and monitoring. This kind of flow 
sensor can be used in reservoirs to monitor the water level raise as well as the outflow of water from the 
reservoirs, which would help in flood prediction. A typical magnetic float sensor is shown in figure 1.
Figure 1. Magnetic Float

4
Smart Technologies for Emergency Response and Disaster Management
﻿
Hydrostatic Pressure
Hydrostatic pressure level sensors, shown in figure 2., are submersible and externally mounted pressure 
sensors suitable for measuring the level of corrosive liquids in deep tanks or reservoirs. These sensors 
sense increasing pressure with depth to detect the level of water. In this senor large variations in tem-
perature cause changes in specific gravity that should be accounted for when the pressure is converted 
to level. These level sensors can be suspended from a cable to the bottom point that is to be measured.
Air Bubbler
An air bubbler system figure 3, uses a tube with an opening below the surface of the liquid level. A fixed 
flow of air is passed through the tube. Pressure in the tube is proportional to the depth of the liquid over 
the outlet of the tube. The only part of the sensor that contacts the liquid is a bubble tube. Since the point 
of measurement has no electrical components, the technique is a good choice for classified “Hazardous 
Areas”. The control portion of the system can be located safely away, with the pneumatic plumbing 
isolating the hazardous from the safe area. It is highly recommended for liquid level measurement ap-
plications where ultrasonic, float or microwave techniques have proved undependable. The system will 
require constant supply of air during measurement. The end of the tube should be above certain height 
to avoid sludge from clogging the tube.
Radar Level Sensors
Radar impulses are emitted by an antenna, reflected off the target water surface and received again by 
the radar system. This provides the most precise measurement data in water level applications requiring 
non-contact transmission. The radar level transmitter will accurately measure the water level in a real 
time basis. Continuously monitoring the water level and transmitting this information to emergency 
management organizations can go a long way to minimizing the catastrophic effect of high water or 
flooding. Having this information allows the water management personnel to take action that may include 
opening or closing flood gates, diverting water flow or just notification to the public of the impending 
high water danger. The water level detection system can also monitor low levels of water as the result 
of drought or other man-made activities. Figure 4 shows a radar level sensor.
Figure 2. Hydrostatic Pressure Sensor

5
Smart Technologies for Emergency Response and Disaster Management
﻿
Micro Sensor
Aerial vehicles, Figure 5, can be used to drop disposable micro sensors. These micro sensors are used 
to track the evolution of a flood in both urban and remote environments. The floating micro sensors 
are implemented as low-cost, system-on-package (SoP) platforms. Once dropped, they remain at fixed 
positions until they are dragged away by flood waters. Aerial vehicle is used to map the location of the 
transmitter-equipped microsensors, and a centralized ground station uses these location maps in conjunc-
tion with flood models to accurately report floods and forecast future flooding events.
Figure 3. Air Bubbler
Figure 4. Radar Level Sensors

6
Smart Technologies for Emergency Response and Disaster Management
﻿
Visual Sensing
Image-based automated monitoring of flood formation and analyses of water level fluctuation were pro-
posed in Lo et al.,(2015), which turn a passive monitoring camera into a visual sensor. It determines of 
flood formation based on image-processing techniques. The experimental results in this paper suggest that 
the visual sensing approach may be a reliable way for determining the water fluctuation and measuring 
its elevation and flood intrusion with respect to real-world coordinates. This method has the capability 
to monitor and analyze the flood status, and therefore, it can serve as an active flood warning system.
Ultrasonic and Infrared Sensors
Mousa et al.,(2016) have proposed a new sensing device that can simultaneously monitor urban flash 
floods and traffic congestion. This sensing device is based on the combination of ultrasonic range finding 
with remote temperature sensing, and can sense both phenomena with a high degree of accuracy, using a 
combination of L1-regularized reconstruction and artificial neural networks to process measurement data. 
This paper explains the implementation of these algorithms on a low-power wireless sensor platform, 
and illustrates that urban water levels can be reliably estimated with error less than 2 cm.
Rain Gauge
A rain gauge shown in Figurer 6 is also known as an udometer, pluviometer, or an ombrometer. It is a 
type of instrument used by meteorologists and hydrologists to gather and measure the amount of liquid 
precipitation over a set period of time. It is a tool that measures the average intensity of rainfall in a 
certain interval of time. The standard rain gauge consists of a funnel emptying into a graduated cylinder, 
which fits inside a larger container. If the rainwater overflows the graduated inner cylinder, the larger 
outer container will catch it. When measurements are taken, the height of the water in the small gradu-
ated cylinder is measured, and the excess overflow in the large container is carefully poured into another 
graduated cylinder and measured to give the total rainfall.
Figure 5. Aerial Vehicles that dispose microsensor

7
Smart Technologies for Emergency Response and Disaster Management
﻿
Satellites
Satellites data can also warn floods, and inform response and recovery efforts. Rain gauges provide a 
direct measurement of rainfall; however, the spatial density of rain gauge networks is typically far too 
coarse to capture the spatial variability of rainfall at small scales. Radar provides an indirect measurement 
of rainfall, but only for regions within a few hundred km of a radar unit - and even less in mountainous 
regions due to blockage of the beam. Estimates of rainfall from satellite data are less direct and less ac-
curate than either gauges or radar, but have the advantage of high spatial resolution and complete cover-
age over oceans, mountainous regions, and sparsely populated areas where other sources of rainfall data 
are not available. Since flash flood events often originate with heavy rainfall in sparsely instrumented 
areas that goes undetected, satellite-derived rainfall can be a critical tool for identifying hazards from 
smaller-scale rainfall and flood events. This triggers requests to satellites such as MODIS, figure 7, for 
high-resolution data over the area of interest. These are then immediately processed and forwarded to 
scientists and local interested partners.
Harris et al., (2007) indicated the current level of uncertainty in satellite rainfall warrants caution 
before institutionalizing its use in operational flood forecasting systems at the basin scale. It requires a 
ways to generalize error adjustment schemes for satellite data as a function of regime, season and location.
Figure 6. Rain gauge
Figure 7. MODIS satellite

8
Smart Technologies for Emergency Response and Disaster Management
﻿
TSUNAMI
Tsunami is a series of high water waves caused by the displacement of substantial volume of water, 
generally in an ocean or a large lake. Tsunami means “harbor wave”or seismic sea wave. High water 
waves are generated due to some potential like Earthquakes (Reymond et al., 1991) volcanic eruptions 
and other nuclear explosions, landslides, glacier calving, meteorite impacts and other disturbances above 
or below. The generated waves may even be of tens meters. Tsunami causes deadly destruction in entire 
ocean basins. The 2004 Indian Ocean tsunami was among the deadliest natural disasters in human history 
with at least 230,000 people killed or missing in 14 countries bordering the Indian Ocean. The increase 
in coastal development combined with potential sea level rise from climate change sets the stage for more 
frequent high-impact coastal inundation events in the future, and presents. Tsunami is a threat to life and 
property for coastal residents through coastal flooding. It is essential to install tsunami warning system 
(TWS) like sea level gauges and tide gauges to predict costal flood and tsunami. In addition Deep Ocean 
assessment on underwater potential events and water pressure will help to predict and issue tsunami 
warning. A prototype of a robust and low cost high frequency sea-level tsunami gauge (Farreras, Ortiz & 
Gonzalez 2007) which samples every minute and equipped with 24 hours real time transmission to the 
Internet, was developed. Statistics allow identification of low, medium and extreme hazard categories 
of arriving tsunamis. The early warning can prevent loss of life and damage to properties.
Tide gauge technology has advanced considerably over the last few decades and nowadays, many 
countries have adopted acoustic gauges or radar gauges as their standard means of sea-level measure-
ment. Tide gauges allow us to measure the movement of the sea surface and the level of sea level. Due 
to technological advances, there are now many different types of tide gauge. They provide essential 
information to the maritime industry about tidal fluctuations, they are relied upon for flood forecasting 
and they help scientists to understand important issues such as sea-level rise and climate change. The 
following are few instruments tide gauge to measure the tide.
Bubbler Gauges
To measure sea level accurately, scientists use bubbler pressure gauges, figure 8. These instruments 
measure the back pressure from blowing bubbles of air down a hole – the higher the pressure needed to 
blow the bubbles, the deeper the water. These consist of a metered flow of compressed gas (usually air), 
which is fed through a supply tube to an underwater cylinder located well below the lowest expected 
tidal level, so that it may experience the full tidal range. The cylinder is open at the bottom so that the 
gas acting upon the surface of the water may push it down until it reaches the level of a small copper 
outlet mounted on the cylinder wall, at which point excess gas escapes through the nozzle in the form of 
bubbles. The pressure in the gas supply tube is then equal to that exerted by the water column above the 
copper outlet, as well as the pressure that is due to the overlying atmosphere. It measures the sea-level 
height directly proportional to the pressure measured in the gas supply tube.
Bubbler systems are often installed in pairs, alongside a float gauge or underwater pressure transducer 
in order to provide an independent means of validating measurements and to ensure continuity of data in 
the event of equipment failures. A major advantage of the bubbler system is that very little of the equip-
ment is exposed to water because the quartz transducer that measures pressure in the bubbler system is 
located at the landward end of the supply line alongside the other supporting pneumatic and electronic 
equipment. This can be housed several hundred yards away from the pressure point. Consequently, these 

9
Smart Technologies for Emergency Response and Disaster Management
﻿
gauges are less frequently damaged and more easily repaired. Bubbler gauges are important for detecting 
tsunamis because they measure sea level at short intervals (1 minute).
Underwater Pressure Transducers
Some tide gauges consist of one or more pressure transducers, figure 9, fixed below the lowest expected 
tidal level. The transducer is contained in a watertight housing and has a measuring port that consists of 
a copper outlet connected to a quartz element via an oil-filled tube. An electrical signal of known fre-
quency is passed through the quartz crystal, but variations in the pressure of the overlying water column 
exert a strain on the element and cause the frequency of the transmitted signal to alter in proportion to 
the change in pressure. These changes in signal frequency can then be converted to physical units and 
stored by a data logger. Absolute pressure transducers measure the pressure of the overlying water col-
umn plus atmospheric pressure, a barometric pressure recorder at the surface record the pressure that is 
solely due to changes in sea-level height. Transducers are useful in hostile environments, for example 
those that are prone to harsh weather conditions and extreme wave action.
Radar Gauges
Radar gauges, figure 10, are relatively new but promising technology and due to their relatively low 
cost and ease of operation, they have been installed in a number of countries. They operate on a similar 
principle to acoustic gauges, using the emission and detection of a radar signal to deduce the height of 
the sea surface. Some transmit at a continuous frequency and use the phase shift between transmission 
Figure 8. Bubbler Gauge

10
Smart Technologies for Emergency Response and Disaster Management
﻿
and detection to determine the height of the sea surface, whilst others use the time-of-flight of a pulsed 
signal. The radar emission and detection unit is fixed to the lower surface of a supporting arm so that 
there are no obstructions to the path of the radar beam and it must be positioned well above the highest 
expected sea level in order to ensure the continuity of measurements and to prevent physical damage. 
In addition to their low cost, radar gauges are reliable. Radar transmission times are not sensitive to 
fluctuations in air temperature.
High-Frequency Radar
To offer sufficient warning time, Grilli et al.(2016) and Lipa et al., (2006) have proposed to implement 
early warning systems relying on high-frequency (HF) radar remote sensing, that can provide a dense 
Figure 9. Pressure Transducer
Figure 10. Radar gauge

11
Smart Technologies for Emergency Response and Disaster Management
﻿
spatial coverage as far offshore as 200–300 km (e.g., for Diginext Ltd.’s Stradivarius radar). Shore-based 
HF radars have been used to measure near shore currents by inverting the Doppler spectral shifts, these 
cause on ocean waves at the Bragg frequency. It can be used to detect tsunami-induced currents and issue 
a warning. The principle of the new algorithm is to compute correlations of HF radar signals measured/
simulated in many pairs of distant “cells” located along the same tsunami wave ray, shifted in time by 
the tsunami propagation time between these cell locations; both rays and travel time are easily obtained 
as a function of long wave phase speed and local bathymetry. It is expected that, in the presence of a 
tsunami current, correlations computed as a function of range and an additional time lag will show a 
narrow elevated peak near the zero time lag, whereas no pattern in correlation will be observed in the 
absence of a tsunami current; this is because surface waves and background current are uncorrelated 
between pair of cells, particularly when time-shifted by the long-wave propagation time. This change in 
correlation pattern can be used as a threshold for tsunami detection.
Acoustic Gauges
Acoustic tide gauges, figure 11, are now considered standard to measure tide. These gauges emit an 
acoustic signal towards the sea surface and measure the travel time of the reflected signal in order to 
deduce water level. However, since the direction of signal reflection is influenced by the slope of the 
sea surface, wave activity can inhibit the detection of the return signal and acoustic gauges are therefore 
often used in conjunction with a vertical acoustic sounding tube. Most of the instruments that ‘look’ 
at the seabed are acoustic (they use sound instead of light). This is because sound penetrates further 
through water than light. The choice of sound frequency matters because low-frequency sounds penetrate 
Figure 11. Acoustic tide gauges

12
Smart Technologies for Emergency Response and Disaster Management
﻿
further but higher frequencies give greater resolution. To measure at seabed depths, researchers might 
use frequencies down to 50kHz, but if there’s an area of particular interest, they might use 250–500kHz 
to look at detail on the seabed.
Deep-Ocean Tsunami Detection Buoys
Deep-ocean tsunami detection buoys, figure 12, are used to confirm the existence of tsunami generated 
by undersea earthquakes. These buoys observe and record changes in sea-level out in Deep Ocean. A 
typical tsunami buoy system comprises of two components, the pressure sensor anchored to the sea floor 
and the surface buoy. The sensor on the sea floor measures the change in height of the water column 
above by measuring associated changes in the water pressure. This water column height is communicated 
to the surface buoy by acoustic telemetry and then relayed via satellite. This enhances the capability for 
early detection and real time reporting of tsunami before they reach land. These systems are capable of 
measuring sea-level changes of less than a millimetre in the deep ocean.
Buoys can be used to measure the height, period and direction of waves. The buoy can even measure 
its own acceleration – this can tell scientists whether it is falling from the top of a high wave into a trough.
Tsunami buoys are connected to underwater pressure gauges, which can provide important water-
level information about possible tsunamis as they speed past. There is a network of tsunami buoys in 
tsunami-prone areas of the Pacific Ocean. The buoys play a crucial role in alerting the public about 
potential tsunami waves.
TORNADOES
Tornadoes are violent storms that strike as a powerful rotating mixture of wind and thunderstorm clouds, 
extending from the clouds to the ground in a funnel shape. A tornado is a violently rotating column 
of air that rotates while in contact with both the surface of the Earth and a cumulonimbus cloud or, in 
Figure 12. Deep-ocean tsunami detection buoys

13
Smart Technologies for Emergency Response and Disaster Management
﻿
rare cases, the base of a cumulus cloud. They are often referred to as twisters. Tornadoes come in many 
shapes and sizes, but they are typically in the form of a visible condensation funnel, whose narrow end 
touches the earth and is often encircled by a cloud of debris and dust. Most tornadoes have wind speeds 
less than 110 miles per hour (180 km/h), are about 250 feet (80 m) across, and travel a few miles (several 
kilometres) before dissipating.
Doppler Radar
Doppler radar, figure 13, can measure both precipitation and wind. It uses light and sound waves to 
determine wind direction, looking for intensifying rotation—a clue that a tornado is about to form. The 
radar emits a short pulse of energy, and if the pulse strike an object (raindrop, snowflake, bug, bird, 
etc), the radar waves are scattered in all directions. A small portion of that scattered energy is directed 
back toward the radar. This reflected signal is then received by the radar during its listening period. 
Computers analyze the strength of the returned radar waves, time it took to travel to the object and back, 
and frequency shift of the pulse. The frequency of the returning signal typically changes based upon the 
motion of the raindrops (or bugs, dust, etc.).
Doppler radar enables forecasters to create different types of images that allow them to track and 
forecast severe weather in real time. Researchers discovered that the tornado produced a unique Doppler 
radar velocity measurement called a tornadic vortex signature. They found that this signature formed 
within the storm’s rotating updraft (also known as a mesocyclone). Initially, the signature appeared at 
Figure 13. A Terminal Doppler Weather Radar (TDWR)

14
Smart Technologies for Emergency Response and Disaster Management
﻿
mid-altitudes in the updraft over 20 minutes before tornado touchdown—well before the tornado ap-
peared. As the storm grew and intensified, the signature lengthened, both upward toward storm’s top and 
downward toward the ground. The radar signature reached the ground at the same time as the tornado. 
It was strongest and extended throughout most of the storm’s depth when the tornado was strongest and 
disappeared as the tornado died. It excels in detecting severe weather events since it allows time for early 
notification of damaging winds, and it significantly increases tornado warning time, because tornadoes 
can be predicted before actually reaching the ground. Once suspicious thunderstorms have been identi-
fied, radar keeps a close watch for rotation deep inside them, and local weather spotters are alerted.
Hook Echo
A “hook echo” describes a pattern in radar reflectivity images that looks like a hook extending from 
the radar echo, usually in the right-rear part of the storm (relative to the motion of the storm). A hook is 
often associated with a mesocyclone and indicates favorable conditions for tornado formation.
Dual-Polarization Radar
Dual-polarization radar technology can detect the presence of random shaped and sized targets like 
leaves, insulation or other debris. This gives meteorologists a high degree of confidence that a damag-
ing tornado is on the ground, and is especially helpful at night when tornadoes are difficult to see with 
the human eye.
The standard Doppler radar transmits and receives information horizontally. With the dual-polar 
upgrade, meteorologists will be able to transmit and receive information in both horizontally and verti-
cally in the atmosphere. These upgrades will improve the accuracy and identification of precipitation 
types, precipitation estimates, and even be able to view tornadoes better.
Multi-Radar, Multi-Sensor (MRMS) System
Multi-Radar, Multi-Sensor (MRMS) System was developed to produce severe weather forecasts and 
warnings. The MRMS system provides improved decision-making capability. It is capable of quickly 
integrates data streams from multiple radars, satellites, surface observations, upper air observations, 
lightning reports, rain gauges and numerical weather prediction models to produce a suite of decision-
support products every two minutes. It provides better depictions of high-impact weather events such as 
heavy rain, snow, hail, tornadoes, and other threat. It help forecasters to quickly diagnose severe weather 
and issue more accurate and earlier forecasts and warnings.
DROUGHTS
Drought is defined as a deficiency of rainfall over an extended period – a season, a year or several years. 
Lack of rainfall leads to inadequate water supply for plants, animals and human beings. This inadequate 
water supply may lead to drought. A drought may result in other disasters like food insecurity, famine, 
malnutrition, epidemics and displacement of populations. It is sometimes possible to cope with one or two 

15
Smart Technologies for Emergency Response and Disaster Management
﻿
successive rain failures but the situation becomes an emergency if it extends. Drought many be caused 
due to not receiving rain or snow over a period of time or changes in water cycle and wind patterns.
Gravity Recovery and Climate Experiment- GRACE satellites
Launched in 2002, Gravity Recovery and Climate Experiment (GRACE) satellites, figure 14, measure 
variations in water stored at all levels above and within the land surface. Using terrestrial water storage 
observations derived from GRACE satellite data, integrated with other observations, using a sophisti-
cated numerical model of land surface water and energy processes scientists generate groundwater and 
soil moisture drought indicators.
The drought indicators describe current wet or dry conditions, expressed as a percentile showing 
the probability of occurrence within the period of record to the present, with lower meaning dryer than 
normal, and higher values meaning wetter than normal.
Drought monitoring - continuous observation of rainfall levels and comparisons with current usage 
levels can help prevent man-made drought. Careful monitoring of moisture levels can also help predict 
increased risk for wildfires and drought
High Pressure
The immediate cause of drought is the predominant sinking motion of air that results in compressional 
warming or high pressure, which inhibits cloud formation and results in lower relative humidity and 
less precipitation. Most climatic regions experience varying degrees of dominance by high pressure, 
often depending on the season. Prolonged droughts occur when large-scale anomalies in atmospheric 
circulation patterns persist for months or seasons (or longer). High quality temperature sensor that is 
specifically designed for soil temperature measurement in extreme environments is shown in figure 15. 
Figure 14. GRACE Satellite

16
Smart Technologies for Emergency Response and Disaster Management
﻿
It is designed to have a record-breaking lifetime with optimal stability. Employing a platinum sensor, at 
extreme temperatures a higher accuracy can be attained than with commonly used thermistors.
EXTREME TEMPERATURES
Extreme weather includes unexpectable, unusual, unpredictable severe or unseasonal weather. It is the 
weather at the extremes of the historical distribution. Often, extreme events are based on a location’s 
recorded weather history. “Heat waves” and “cold snaps” are deadly natural hazards.
Heat Waves
Heat waves are periods of abnormally high temperatures. A heat wave is a prolonged period of exces-
sively hot and sometimes also humid weather relative to normal climate patterns of a certain region. Heat 
waves are not visible as other forms of severe weather are, like hurricanes, tornadoes, and thunderstorms. 
Heat kills by pushing the human body beyond its limits. In extreme heat and high humidity, evaporation 
is slowed and the body must work extra hard to maintain a normal temperature.
Cold Waves
Cold waves, heavy snowfall and extreme cold can immobilize an entire region. A cold wave is a weather 
phenomenon that is distinguished by marked cooling of the air, or the invasion of very cold air, over 
a large area. A cold wave can be both a prolonged period of excessively cold weather and the sudden 
invasion of very cold air over a large area. Even areas that normally experience mild winters can be 
hit with a major snowstorm or extreme cold. Winter storms can result in flooding, storm surge, closed 
highways, blocked roads, downed power lines and hypothermia. It cause damage to agriculture, infra-
structure, property. A cold wave can cause death and injury to livestock and wildlife. Exposure to cold 
Figure 15. High Pressure Temperature Sensor

17
Smart Technologies for Emergency Response and Disaster Management
﻿
mandates greater caloric intake for all animals, including humans, and if a cold wave is accompanied 
by heavy and persistent snow, grazing animals may be unable to reach necessary food and water, and 
die of hypothermia or starvation.
Humidity Sensor
Humidity sensors or hygrometer, figure 16, detect changes in air temperature and measures moisture in 
the air. It measures and reports the relative humidity in the air. Relative humidity is the ratio of actual 
moisture in the air to the highest amount of moisture that can be held at that air temperature. The warmer 
the air temperature is, the more moisture it can hold. Humidity / dew sensors use capacitive measure-
ment, which relies on electrical capacitance. Electrical capacity is the ability of two nearby electrical 
conductors to create an electrical field between them. The sensor is composed of two metal plates and 
contains a non-conductive polymer film between them. This film collects moisture from the air, which 
causes the voltage between the two plates to change. These voltage changes are converted into digital 
readings showing the level of moisture in the air.
Temperature Sensor
A temperature sensor, figure 17, is an electronic device that gathers data concerning the temperature 
from a source and then converts it into a form that can be displayed and understood by a user or another 
device. A temperature sensor is often a resistance temperature detector or thermocouple that measures 
temperature through an electrical signal. A resistance temperature detector is a variable resistor that 
changes its electrical resistance in proportion to the changes in temperature in a repeatable, precise and 
nearly linear manner. A thermocouple is made from two dissimilar metals that generate electrical voltage 
in proportion to the changes in temperature. The passive infrared Extreme Temperature Sensor provides 
consistent, stable coverage where extreme heat, cold or humidity must be accommodated, and where 
there are wide fluctuations in temperature.
Figure 16. Humidity sensors

18
Smart Technologies for Emergency Response and Disaster Management
﻿
Pyranometer
The Pyranometer in figure 18 is a unique sensor designed to measure global solar radiation. A pyranometer 
is a type of actinometer that can measure solar irradiance in the desired location and solar radiation flux 
density. The solar radiation spectrum extends approximately between 300 and 2800 nm. The pyranometer 
only requires a flat spectral sensitivity to help cover this spectrum.
Weather Station
A weather station, figure 19, is a device that collects data related to the weather and environment using 
many different sensors. A weather station is installed either on land or sea, with instruments and equip-
ment for measuring atmospheric conditions to provide information for weather forecasts and to study 
the weather and climate. The measurements taken include temperature, barometric pressure, humidity, 
wind speed, wind direction, and precipitation amounts. Weather stations sensors may include a ther-
mometer to take temperature readings, a barometer to measure the pressure in the atmosphere, as well 
as other sensors to measure rain, wind, humidity and more. Weather stations range from simple analog 
technology to digital technology. Manual observations are taken at least once daily, while automated 
measurements are taken at least once an hour.
Figure 17. Temperature sensors
Figure 18. Pyranometer

19
Smart Technologies for Emergency Response and Disaster Management
﻿
Weather Radar
Weather radar, figure 20, also called weather surveillance radar (WSR) and Doppler weather radar, is 
a type of radar used to locate precipitation, calculate its motion, and estimate its type (rain, snow, hail 
etc.). Modern weather radars are mostly pulse-Doppler radars, capable of detecting the motion of rain 
droplets in addition to the intensity of the precipitation. Both types of data can be analyzed to determine 
the structure of storms and their potential to cause severe weather.
Satellite
The temperature of the atmosphere at various altitudes as well as sea and land surface temperatures 
can be inferred from satellite measurements. These measurements can be used to locate weather fronts, 
determine the strength of tropical cyclones, study urban heat islands and monitor the global climate. 
Wildfires, volcanos, and industrial hot spots can also be found via thermal imaging from weather satellites.
Figure 19. Weather Station
Figure 20. Weather Radar

20
Smart Technologies for Emergency Response and Disaster Management
﻿
Weather satellites, figure 21, do not measure temperature instead but measure radiances in various 
wavelength bands. Since 1978 microwave sounding units (MSUs) on National Oceanic and Atmospheric 
Administration polar orbiting satellites have measured the intensity of upwelling microwave radiation 
from atmospheric oxygen, which is related to the temperature of broad vertical layers of the atmosphere. 
Measurements of infrared radiation pertaining to sea surface temperature have been collected since 1967.
Freezing-Rain and Ice Detectors
Freezing-rain and ice detectors, figure 22, detect the presence of icing conditions so that appropriate 
actions can be taken to prevent damage to power and communication lines, to warn of road hazards, to 
keep ice off a plane’s wings, and to prevent ice from forming on turbine blades.
AVALANCHES
The ability to detect avalanches as they occur is essential for aggressive avalanche management in 
transportation corridors and is a fundamental ingredient of avalanche forecasting. Temporary protective 
measures against avalanches have grown enormously in importance over the past few years. Compared 
to permanent constructional mitigation measures, today controlled-release of avalanches in small por-
tions from the avalanche fracture zones are being introduced increasingly. Modern remote-controlled 
blasting installations allow triggering even during snowfall or in the night if necessary. Naturally, with 
this benefit, the requirements for detection systems that are independent of visibility for verification 
of successful blasting are also increasing. Furthermore, when avalanches are registered, alarms can be 
set off and transport routes blocked with traffic lights as well as general information collected about 
avalanche activity, which could give important indications for avalanche warning. Different avalanche 
detection systems are discussed as follows:
Figure 21. Weather Satellite

21
Smart Technologies for Emergency Response and Disaster Management
﻿
LARA – Long Range Avalanche Radar
It is systems for specific and exact monitoring of individual avalanche paths. The Doppler radar sends out 
electromagnetic waves, which are reflected by objects. The frequency of reflected radiation of moving 
objectives is different to the one sent out (Doppler Effect). This effect is being used for avalanche detec-
tion. The data is sent to a server for processing and visualizing. Run out distance and size of avalanche 
can be roughly determined. The radar can be installed in the valley or at the opposite side of the valley 
facing the avalanche path to be monitored. The radar and the electronic box are mounted on a mast, 
which might be held by a fundament or connected to a building as shown in Figure 23.
SARA – Short Range Avalange Radar
This system is for pure verification directly close to the blasting installation (SARA). The device shown 
in figure.24 can be installed optionally directly on the deployment box of the avalanche tower to moni-
tor the effective range of the avalanche tower within a range of 300 to 500 m. Power is supplied by the 
battery of the avalanche tower. The radar can only be operational for a short time, usually just during 
the operation of the avalanche tower. The Doppler radar sends out electromagnetic waves which are 
reflected by objects. The frequency of reflected radiation of moving objectives is different to the one 
sent out (Doppler Effect). This effect is being used for avalanche detection. The data is sent to a server 
for processing and visualizing. Run out distance and size of avalanche can be roughly determined.
Figure 22. Freezing-Rain and Ice Detectors

22
Smart Technologies for Emergency Response and Disaster Management
﻿
IDA – Infrasound Detection System
This IDA can be used for monitoring of larger areas form a central location. Avalanche produce infra-
sound waves below 20 Hz (not audible for humans), which are detectable for sensor over large distance. 
Three sensors installed in a triangle setup with a distance in between of approx. ca. 100 m and one sensor 
in the centre. This array is installed outside of the avalanche path and connected to a central computer 
where the data is transmitted to a server for the analysis. Snow coverage of the sensors filtered out higher 
frequent noise signals.
PETRA – People Tracking Radar
To monitor endangered areas in order to make sure no people are exposed to controlled released ava-
lanches if visibility is poor.
The Doppler radar sends out electromagnetic waves which are reflected by objectives. The frequency 
of reflected radiation of moving objects is different to the one sent out (Doppler Ebffect). This effect 
is being used for avalanche detection. The data is sent to a server for processing a visualizing. Run out 
distance and size of avalanche can be determined within an rough precision. The radar installation is 
installed so that the area to be monitored is within its visibility and range. It can be mounted at a mast 
or building. Usually an optical or thermal imaging camera shown in figure.25 is combined in order to 
be able to determine whether the radar detected a human or animal.
Figure 23. Long Range Avalanche Radar
Figure 24. Short Range Avalange Radar

23
Smart Technologies for Emergency Response and Disaster Management
﻿
Detecting Avalanches with Satellite Radar
Satellite imagery that can penetrate fog, darkness and storms to detect old and recent avalanche tracks 
has the potential to help improve avalanche forecasting across Europe. Avalanche researchers in Nor-
way are now looking into using satellite imagery as a tool to improve their ability to improve avalanche 
forecasting and warnings.
The satellite radar sends pulses of electromagnetic radiation to the ground. Part of this radiation is 
reflected and sent back to the radar. Generally, snow doesn’t reflect much of this radar signal back, but 
avalanches really light up on radar images. Satellite radar works independently of storms, fog, night or 
other conditions that would normally prevent the capturing of images from conventional satellite cameras.
Figure 25. People tracking Radar
Figure 26. Tracing of avalanche

24
Smart Technologies for Emergency Response and Disaster Management
﻿
The green line in figure.26 shows where researchers have traced the outline of the avalanche at the 
base of the slide. The image shows how the avalanche stands out against the contrast of the surrounding 
snowpack. The undisturbed snowpack reflects radar poorly so that it looks darker in the images. (Photo: 
Norut)
European Space Agency Satellites
The Norut researchers are now using the European Space Agency’s Sentinel-1A satellite to investigate 
avalanches in Norway. Eckerstorfer recently published a paper in Cold Regions Science and Technology 
that explains the approach using a different satellite owned by Canada.
The figure 27 show the same avalanche area as recorded by radar imagery and by a conventional 
camera out in the field. The conventional photographs confirm what the radar images suggest, which is 
that there was an actual avalanche. (Photo: Norut)
Avalanche Radar
The main parameters for detecting mass movements are the volume and the velocity. A well known 
technology to measure velocities is the RADAR-technology by measuring the Doppler shift of the used 
frequency. The RADAR cross-section of an object for a given wavelength is a function of the size, the 
material, the incident and the reflecting angle, etc. and it determines the measured scattered intensity. 
Therefore, the measured reflected intensity is a parameter which belongs to the cross section of the 
moving volume of the detected object.
The RADAR shown in figure.28 operates according to the principle of the coherent pulse Doppler 
RADAR. A high-frequency generator produces a signal in the X-band (f0=10.425 GHz). This signal is 
pulse modulated in a high-frequency switch, amplified to an output power of about 1 W and radiated 
from a parabolic Antenna to the detection area. The reflected beam from the area passes the parabolic 
Figure 27. Recorded avalanche area by radar

25
Smart Technologies for Emergency Response and Disaster Management
﻿
Antenna again and goes through the receiver. In the receiver the reflected signal is sampled and goes 
to the analog-digital converters. After words, a digital signal processor calculates the measured values 
from the signal, which then are edited and displayed on a user interface or go through an automatic 
alarm generating software.
CASE STUDY: AVALANCHE DETECTOR USING 
DISTRIBUTED ACOUSTIC FIBER OPTIC SENSING
Zermatt Avalanche Radar
Challenge
The only road that leads to Zermatt, one of Switzerlands most renowned resorts, home to about 6000 
people and reaching 2 Mio. yearly overnight stays, is threatened by the two infamous avalanche gullies 
Lüegelti and Schusslobina. While most tourists reach Zermatt by train, locals and goods traffic depend 
heavily on the cantonal road that connects Zermatt and Täsch, the next village down valley.
In good weather, avalanches in the two gullies are triggered artificially by helicopter blastings. For 
the past 30 years, trigger lines have been used to keep the road open during stretches of bad weather 
when flying is impossible, closing the road when an avalanche triggers one of the lines. This system, 
however, had its shortcomings: after every avalanche, it was inactive and the trigger lines needed to be 
replaced — a risky and costly job during winter. Furthermore, only avalanches that passed by the trigger 
lines were recorded.
Figure 28. Mudslide and debris flow with Radar-antenna, UMTS-antenna, housing and IP-camera

26
Smart Technologies for Emergency Response and Disaster Management
﻿
Solution
Since December 2015, a new system using radar technology has replaced the old trigger line system. 
In cooperation with Brig-based ForstIngPlus we installed some brand new technology: two avalanche 
radars with a range of 2000 m and a horizontal opening angle of 90° survey an area of more than 2 
km2. They react within seconds, and immediately close the cantonal road by means of traffic lights and 
barriers. To prevent further traffic from entering the section between Täsch and Zermatt, a fifth traffic 
light is activated in Täsch.
Local authorities receive prioritized SMS and calls (Swisscom eAlarm emergency), and live cameras 
installed along the road allow them to check on the situation immediately — even at night, as all cameras 
are equipped with infrared floodlights. If the avalanche has not reached the road, authorities can reopen 
it from their computers or smartphones within minutes.
This system is unique world-wide, combining the following technologies:
•	
Long range avalanche radars with wide opening angles (90°)
•	
Automatic road closure
•	
Reopening per command issued from computer or smartphone
The project has been supported by the Canton of Valais.
Radar Used to Detect Avalanches
With the recent heavy snow falls, the piste service has been busy releasing avalanches with explosives. 
This are delivered from helicopters and are designed to move unstable snow layers.
However, while use of explosives is still important, a new radar system as in figure 29 is an example 
of one of the impressive technologies introduced by the local Valais canton.
Figure 29. Avalanche radars

27
Smart Technologies for Emergency Response and Disaster Management
﻿
Road Can Be Closed Automatically
High above the entry to the town, at 1800m, a new avalanche warning system has been installed – the 
first of its kind in the world. It uses radar technology to monitor the start of avalanches up to a height 
of around 2400m.
The system has been described by its inventors at Geopravent as ‘similar to the system that is used to 
track speeding cars’. It is designed to detect an avalanche as soon as it begins as there is only a limited 
amount of time to close the road below.
If an avalanche is detected the road is immediately closed automatically as in figure 30. Once any 
threat has been evaluated, the road can be opened again direct from the avalanche safety office.
Eiger Glacier Monitoring
Challenge
Every year, roughly one million tourists take the cogwheel railway up to Jungfraujoch to admire the famed 
summits of Eiger, Mönch and Jungrau. In fall 2015, ETH’s Laboratory for Hydraulics, Hydrology and 
Glaciology detected crevasses appearing near the terminus of a hanging glacier above the Eigergletscher 
station of the Jungfrau railway, indicating that up to 80’000 m3 of ice might be approaching detachment. 
Model runs at the Swiss Snow and Avalanche Research Institute suggested that the Eigergletscher sta-
tion could be damaged if the entire volume of ice collapsed at once. Traditionally employed means of 
observation like cameras, total stations or GPS were not suitable for this monitoring task because the 
rely on good visibility, only offer point measurements, and, in some cases, require equipment to be 
installed within the danger zone.
Figure 30. The road is closed automatically.

28
Smart Technologies for Emergency Response and Disaster Management
﻿
Solution
Geopraevent has designed a warning and alarm systemd specifically optimized for the situation at the 
Eiger glacier.
As early warning system, a ground-based interferometric radar continuously measures glacier flow 
velocities over the entire glacier. These data are available in our online data-portal, permitting glaci-
ologists to predict ice avalanches and enabling responsible personell to take appropriate measures like 
closing a ski run.
For a safe operation of the cogwheel railway and the safety of a nearby construction site in case of an 
ice avalanche, the system also includes an alarm component. In addition to the radar interferometer, an 
avalanche radar monitors the glacier around the clock and in all weather. The system sounds an alarm 
on the construction site and stops the train if an avalanche of a certain size is detected. Given a warning 
time of 35 – 45 seconds, both the construction workers and the train can move to the safety of the tunnel 
if they are in the danger zone when the avalanche is detected.
Combining the interferometric and avalanche radars, in addition to several webcams as alarm and 
early warning systems offers maximum security and safe operation of the Jungfrau railway, letting a 
million tourists enjoy the beauty of glaciated mountains every year.
Avalanche Detection Gonda
After large snowfalls, authorities often rely on artificial avalanche triggering to ensure the safety of 
transportation routes and ski runs. Avalanche towers and blasting cableways offer distinct advantages: 
remote control triggering allows avalanche blasting to take place at any time of day or night as well as 
in bad weather. This way, avalanches can be triggered before large amounts of snow accumulate in the 
release area. But local authorities often face difficulties verifying the effects of the remote triggering. 
Did an avalanche actually detach, and how large was it? At night or in bad weather, visual control is 
often impossible, especially since avalanches are not intended to reach the valley bottom or the ski run. 
We have teamed up with our partners at Wyssen Avalanche Control, Alpug GmbH, and the offices for 
civil engineering and forest and natural hazards of the canton of Grisons, to test an avalanche detec-
tion system. Several artificial avalanche release systems are installed around the Piz Chapisun in the 
Lower Engadin Valley. In the vicinity, a range of different systems are in place to monitor events: Three 
geophones detect the avalanche releases. Additionally, a radar system with two antennas continuously 
monitors the avalanche path further down. At the valley bottom, infrasound sensors, installed by the 
WSL Institute for Snow and Avalanche Research SLF, measure the low frequency sound waves emitted 
by the avalanches. The artificial releases and all the systems measurements are subsequently displayed 
on an information platform accessible to everyone involved.
Online-visualization of the basting events and the related detections are shown in figure 31. The list 
on the left lets the user select artificial releases and detection events, showing where the resulting ava-
lanche was detected in the terrain, and which instrument detected it. Figure 32 shows the solar powered 
systems which are installed at about 2300 ma.s.l., from where both radar and webcam systems have a 
clear view of the release area and the main avalanche path. The radar systems in figure 33 can detect the 
avalanches in the release area and also distinguish the runout distances of the events.

29
Smart Technologies for Emergency Response and Disaster Management
﻿
Figure 31. Online-visualization of the basting events and the related detections.
Figure 32. The solar powered systems
Figure 33. The radar systems.

30
Smart Technologies for Emergency Response and Disaster Management
﻿
LANDSLIDE
A landslide, also known as a landslip, is a form of mass wasting that includes a wide range of ground 
movements, such as rock falls, deep failure of slopes, and shallow debris flows. Landslides are the major 
cause of loss of life, human settlements, agriculture, forestland, and lead to damage of communication 
routes. Landslides occur when the slope changes from a stable to an unstable condition. It occurs as 
gravitational forces exceed the strength of material in a slope. A change in the stability of a slope can 
be caused by a number of factors like ground water pressure, erosion, earthquakes, volcanic eruptions, 
human activities and etc which are acting together or alone.
Monitoring, forecasting and warning of landslides are the essential features for saving the lives and 
assets from devastation. There are three fundamental ways for monitoring the landslide viz, visual, 
surveying and instrumentation. Ground based visual inspection and sampling of these on regular basis 
may be one of the effective ways of monitoring the landslides. Surveying includes all type of physical 
measurements. Instrumentation may include installing equipment for periodic reading of the different 
monitoring sensors such as inclinometer, strain gauge, rain gauge, clinometers, extensometer, pore pres-
sure sensors etc.
The monitoring techniques also can be divided into two groups: i) geodetic technique, and ii) non-
geodetic technique. Geodetic techniques give global information on the behavior of the deformable 
landslide while the non-geodetic techniques give localized and locally disturbed information without 
any check. Landslide hazard map can be obtained by systematic data manipulation within a Geographi-
cal Information Systems (GIS) (Carrara, Guzzetti & Cardinali, (1999). is assumed to be more objective.
Wireless Sensor Network for Detection of Landslides
Wireless sensor networks are one of the most promising emerging technologies, providing the opportunity 
for real-time monitoring of geographical regions (remote and hostile) that are prone to disasters. The 
successful implementation of a landslide detection application requires handling massive amounts of 
data from the wireless sensor network, maintaining its accuracy and integrity after integration (Alamdar 
et al. 2016) and ensuring low-latency transmission of the sensed data with efficient utilization of energy.
Gui et al., (2011) proposed a landslide hazard monitoring based on Zigbee wireless sensor network 
technology, network structure and the nodes, embed wireless sensor node in remote monitoring and 
warning system, a base platform of local wireless sensor network is formed, and it combine monitoring 
information with planar network and transmit concentrated information through Beidou satellite terminal 
machine; as a result, this largely expands the transmission distance of monitoring data.
The most significant physical phenomena to be monitored for early warning of landslides are the 
changes in moisture content, pore pressure, rainfall, movement, and vibrations inside the earth. After 
careful study, the geophysical sensors needed for monitoring these phenomena were selected and used. 
These are Dielectric moisture sensors, Pore pressure piezometers, Strain gauges, Tiltmeters, Geophones, 
Rain gauges and Temperature sensors.
The many sensors for landslide monitoring were identified and buried underground to measure the 
pertinent geological and hydrological properties as discussed by Maneesha (2014). A Deep Earth Probe 
(DEP) in figure.34 was deployed with these many sensors as a stack in different locations. The ideal 
depth for the DEP to be deployed would be the same as the depth of the bedrock in that location.

31
Smart Technologies for Emergency Response and Disaster Management
﻿
One of the important requirements for any landslide detection system is the efficient delivery of data 
in a real-time manner. This objective requires seamless connectivity with minimum delay in the network. 
The architecture we have developed for satisfying the above requirements is shown in Figure.35. The 
complete architecture is developed by integrating different heterogeneous wireless networks such as, 
probe network, Field LAWN and Adaptive WAWN.
The probe network is developed to capture the prevailing geological and hydrological parameters in 
a landslide prone area. The wireless probes with the lower level nodes sample and collect the heteroge-
neous data from the DEP, and the data packets are transmitted to the middle level(cluster head) which 
aggregates the data and forwards it to the probe gateway (sink node) maintained at the deployment site. A 
Field LAWN (local area wireless network) is designed to transmit the data received at the probe gateway 
to the VSAT earth station at the Field Management Center (FMC), which are separated by approximately 
500 m. Adaptive WAWN (Wide Area Wireless Network), which consists of a satellite network, a GSM/
GPRS network, and a broadband network, is used to provide wide area connectivity.
Figure 34. Multisensor DEP.

32
Smart Technologies for Emergency Response and Disaster Management
﻿
The wireless sensor network (Mishra et al., 2011) follows a two-layer hierarchy: i) lower layer wire-
less sensor nodes which sample and collect the heterogeneous data from the sensor and the data packets 
are transmitted to the upper layer, ii) the upper layer collects the data and forwards it to the sink node 
(gateway) or base radio. Wireless senor nodes used are Zigbee compliant 2.4 GHz IRIS motes from 
Crossbow. The IRIS mote integrated with different digital sensors. The output of digital sensor is con-
nected with the es9200 interface board in case of Eko nodes. The IRIS motes can be programmed as 
nodes as well as base radio. Experiments with micro-electro mechanical system (MEMS) based Incli-
nometer with signal output 4-20 mA and linear range ± 5 has been carried out. MEMS inclinometer can 
measure incline and decline i.e. positive and negative slopes, respectively. The input to the inclinometer 
is given by Twin Transistor Power supply (18-24 VDC). The inclinometer is inclined at some angle and 
its position is fixed. The angle is measured by changing the inclination of the inclinometer. The angle 
is determined by observing the corresponding output of the inclinometer in nano-volt meter and com-
paring it with the calibration sheet as supplied by the test firm. The output of the MEMS inclinometer 
Figure 35. The probe network

33
Smart Technologies for Emergency Response and Disaster Management
﻿
is connected to the holes of the IRIS mote integrated with MDA100 sensor board to specified holes 
for different channel output (Adc2, Adc3, Adc4, Adc5, and Adc6). Data are transferred through Motes 
(nodes) forming mesh topology. The nearest mote to base radio transfers data to base radio. Finally data 
can be viewed through mote view software installed in the system. Thus by using the complete system, 
one can determine angular change of the slope of landslide site.
Land Slide Detection System Using Hidden Markova Model (Sarita et al., 2016)
This system is forecast the weather such as rainfall condition and conclude the displacement of the soil 
because of the rain and set this value as a threshold. If there is a displacement in the soil Landslide dis-
placement detection sensor using optical fiber in figure 36 will detect and check whether the soil grip 
has been loosed and crosses the threshold value and pre-predict the landslide occurrence. The sensors 
sense the data like moist, soil, displacement, pressure etc. from the environment and provide it to the 
field management center. This section does real time monitoring and data acquisition. This particular 
data is sent for further analysis to the land slide detection system. This system uses the hidden Markova 
model and k-means algorithm for calculating the appropriate time of landslide occurrence. This data is 
provided to the alert system and hence the alert signal is send to human.
Optical Fiber Sensor (Higuchi et al., n.a)
Optical fiber sensing, the OTDR (Optical Time Domain Reflectometry) method is used which measures 
the amount of loss of traveling light and identifies where the loss occurs in the optical fiber.. The sensor 
is a mechanical device in which part of an optical fiber bends in response to landslide displacement. 
Several sensors are installed along the optical fiber measurement line, and the OTDR detector (Figure 
37) detects the transmission loss of the light caused by bending of the optical fiber, at the locations of 
several sensors simultaneously. The landslide displacement is calculated from the change of transmis-
sion loss. Measurement is controlled automatically by a computer. As a result of measurement, tensile 
displacement was detected; this is similar to the tensile displacement of an adjacent extensometer, but 
an error of several mm is also observed.
Figure 36. Landslide displacement detection sensor using optical fiber

34
Smart Technologies for Emergency Response and Disaster Management
﻿
Landslide Detection Using Satellite Remote Sensing 
Imagery (Kwong-Fai et al., 2015)
Landslide detection using satellite remote sensing images has been widely studied. These type of studies 
involves either change detection or multi-spectral image classification methodologies. If there is only 
one set of satellite image, the change detection method has limited use. Collecting and analyzing train-
ing area data for image classification are costly and time consuming. So, this method therefore utilize 
only one SPOT satellite image data for estimating the normalized difference vegetation index (NDVI), 
and to segregate vegetated and non-vegetated. Slope factor and textural feature are then used to identify 
the landslide area.
Vegetation indices attempt to measure biomass or vegetative vigor quantitatively based on digital 
values. Band ratios are computed from two spectral bands. Ratio of near infrared and red bands is use-
ful in mapping vegetation and vegetation condition. The ratio is high for healthy vegetation, but low 
for stressed or unhealthy vegetation as well as non-vegetation areas. There are three essential causative 
factors of debris flow. One is high intensity rainfall. The second is abundance of rock or sand sources. 
The third is steep slope. Landslide or debris flow usually occurs in steep hillside. Results indicate that 
the accuracy of landslide detection using NDVI with slope factor and textural feature performs much 
better than using NDVI alone. This study successfully demonstrates the capability of using one set of 
remote sensing image to map landslide area in a large river basin.
Figure 37. Example of install of Optical fiber sensor

35
Smart Technologies for Emergency Response and Disaster Management
﻿
MEMS Tilting Sensors (Towhata. I. et al., 2015)
The rainfall criteria of slope failure tell the probability of disaster on a regional scale which is difficult to 
judge the risk of particular slopes. It is due to the rainfall intensity is spatially too variable to forecast and 
the early warning based on rainfall alone cannot take into account the effects of local geology, hydrology 
and topography that vary spatially as well. So, an alternative technology in which the slope displacement/
deformation is monitored and issues the early warning also when a new criterion is satisfied. The new 
MEMS-based sensor monitors the tilting angle of an instrument that is embedded at a very shallow depth 
and the record of the tilting angle corresponds to the lateral displacement at the slope surface. Thus, the 
rate of tilting angle that exceeds a new criterion value implies an imminent slope failure.
Digital Photogrammetry
González-Díez et al.,(2014) employs digital photogrammetric techniques, combined with global posi-
tioning system (GPS) measurements, to analyse landslide features depicted in aerial images taken by 
ad hoc and historical flights. This method designed and carried out of an ad hoc flight to take 1:5,000 
photographs to be used as a reference, using different aircraft devices to control the position and geom-
etry of the photograms. It measured the different ground control points (GCPs) using GPS techniques 
(Xiao & He 2013) to support the geomorphological and photogrammetric work. It digitised the refer-
ence and historical photograms in a photogrammetric scanner and the digital images and incorporated 
the GCPs into a digital photogrammetric workstation to generate the reference digital stereo models by 
aerotriangulation.
SUMMARY
Disaster management is very essential as it may cause heavy causalities and destroy the infrastructure. 
Disaster management is highly time sensitive and demand real time data for making critical decision 
during disaster. The advancement in sensing, information communication technology and geographic 
information systems improves performance in identifying the potential risk areas, vulnerabilities and 
potentially affected populations. The adverse effect of disaster can be reduced considerably and also able 
to reduce loss of life by installing the sensing devices in various locations. These devices collect data 
through continuously monitoring. These data when linked with information communication technology 
and spatial data, helps in early discovery and protection from disaster.
This chapter has discussed new sensing technologies and devices for various disasters like Flood, 
Tsunami, Tornadoes, Droughts, Extreme Temperatures, Avalanches and Landslides. We have discussed 
devices for flood detection that would find the height of water, sudden increase in water level, amount 
of rain in an area. The tsunami detection devices monitor the sea waves, underground water pressure 
and sea level to predict the occurrence of tsunami. Tornadoes detection is possible by monitoring the 
wind. Drought detection devices monitor the air pressure and the amount of water in the reservoir. Wind 
temperature and humidity monitoring devices help in predicting the extreme temperature. In avalanche 
forecasting, avalanche activities like acoustic, infrasonic or seismic emissions are used as important 
parameter. These sensing devices help in gathering information on the installed location and helps in 
generating timely information and early warning of potential hazards.

36
Smart Technologies for Emergency Response and Disaster Management
﻿
REFERENCES
Alamdar, F., Kalantari, M., & Rajabifard, A. (2015). An evaluation of integrating multisourced sensors 
for disaster management. International Journal of Digital Earth, 8(9), 727–749. doi:10.1080/1753894
7.2014.927537
Alamdar, F., Kalantari, M., & Rajabifard, A. (2016). Towards multi-agency sensor information integra-
tion for disaster management. Computers, Environment and Urban Systems, 56, 68–85. doi:10.1016/j.
compenvurbsys.2015.11.005
Anita, , Singh, R., Choudhury, S., & Singh, B. (2015). Wireless Disaster Monitoring and Management 
System for Dams. Procedia Computer Science., 48, 381–386. doi:10.1016/j.procs.2015.04.197
Beatty, P. (2014, May 5). Water Quality Sonde Detects Tsunami Signal Over 4,000 Miles Away. Retrieved 
from https://www.ysi.com/ysi-blog/water-blogged-blog/2014/05/water-quality-sonde-detects-tsunami-
signal-over-4-000-miles-away/
Bhosle, A. S., & Gavhane, L. M. (2016). Forest disaster management with wireless sensor network. 
Proc of International Conference on Electrical, Electronics, and Optimization Techniques (ICEEOT), 
287-289. doi:10.1109/ICEEOT.2016.7755194
Board, O. S., & National Research Council. (2011). Tsunami warning and preparedness: an assessment 
of the us tsunami program and the nation’s preparedness efforts. National Academies Press. Retrieved 
from http://www.nap.edu/read/12628/chapter/7#153/
Brief, C. (2015, Jan 16). Explainer: How do scientists measure global temperature? Retrieved from 
https://www.carbonbrief.org/explainer-how-do-scientists-measure-global-temperature
C-temp. (2012). Quality temperature sensing products. Retrieved from http://www.c-temp.com/
Carrara, A., Guzzetti, F., Cardinali, M., & Reichenbach, P. (1999). Use of GIS Technology in the Prediction 
and Monitoring of Landslide Hazard. Natural Hazards, 20(2/3), 117–135. doi:10.1023/A:1008097111310
Chen, D., Liu, Z., Wang, L., Dou, M., Chen, J., & Li, H. (2013). Natural Disaster Monitoring with Wire-
less Sensor Networks: A Case Study of Data-intensive Applications upon Low-Cost Scalable Systems. 
Mobile Networks and Applications, 18(5), 651–663. doi:10.1007/s11036-013-0456-9
Chen, N., Wang, K., Xiao, C., & Gong, J. (2014). A heterogeneous sensor web node meta-model for 
the management of a flood monitoring system. Environmental Modelling & Software, 54, 222–237. 
doi:10.1016/j.envsoft.2014.01.014
Coastal Environment Systems. (n.d.). Ice Stations. Retrieved from http://www.coastalenvironmental.
com/ice-stations.shtml
Commonwealth of Australia, Bureau of Meterology. (2017). Deep Ocean Tsunami Detection Buoys. 
Retrieved from http://www.bom.gov.au/tsunami/about/detection_buoys.shtml

37
Smart Technologies for Emergency Response and Disaster Management
﻿
Devasena, A., & Sowmya, B. (2015). Wireless Sensor Network in Disaster Management. Indian Journal 
of Science and Technology, 8(15). doi:10.17485/ijst/2015/v8i15/74191
EATON. (n.d.). Extreme Temperature Sensors. Retrieved from http://www.cooperindustries.com/content/
public/en/lighting/controls/products/occupancy_sensors/ext_temp.html
Exergen. (2014). Extreme Sensor Delivers Accurate Temperature Measurement in Severe Temperature, 
Weather, And Other Environmental Conditions. Retrieved from http://www.exergenglobal.com/index.
php/en/exergen-global/news/2-ukategorisert/131-press-release-extreme-sensor
Farreras, S., Ortiz, M., & Gonzalez, J. (2007). Steps Towards the Implementation of a Tsunami Detec-
tion, Warning, Mitigation and Preparedness Program for Southwestern Coastal Areas of Mexico. Pure 
and Applied Geophysics, 164(2-3), 605–616. doi:10.1007/s00024-006-0175-2
Future Electronics. (n.d.). Temperature Sensor. Retrieved from http://www.futureelectronics.com/en/
sensors/temperature.aspx
Ghosh, N. (2014, Dec 22). Tsunami early warning systems. Retrieved from http://www.thestar.com.my/
news/nation/2014/12/22/tsunami-early-warning-systems/
González-Díez, A., Fernández-Maroto, G., Doughty, M. W., Díaz de Terán, J. R., Bruschi, V., Cardenal, 
J., & Delgado, J. et al. (2014). Development of a methodological approach for the accurate measure-
ment of slope changes due to landslides, using digital photogrammetry. Landslides, 11(4), 615–628. 
doi:10.1007/s10346-013-0413-5
Grilli, S. T., Grosdidier, S., & Guérin, C. A. (2016). Tsunami Detection by High-Frequency Radar 
Beyond the Continental Shelf. Appl. Geophys., 173(12), 3895–3934. doi:10.1007/s00024-015-1193-8
Gui, Y., Tao, Z., Wang, C., & Xie, X. (2011). Study on remote monitoring system for landslide hazard 
based on wireless sensor network and its application. J Coal Sci Eng China., 17(4), 464–468. doi:10.1007/
s12404-011-0422-8
Harris, A., Rahman, S., Hossain, F., Yarborough, L., Bagtzoglou, A. C., & Easson, G. (2007). Satellite-
based flood modeling using TRMM-based rainfall products. Sensors (Basel, Switzerland), 7(12).
Higuchi, K., Fujisawa, K., Asai, K., Pasuto, A., & Marcato, G. (n.d.). Application of new landslide 
monitoring technique using optical fiber sensor at Takisaka landslide, Japan. Academic Press.
Horita, F. E. A., et al. (2015). Development of a spatial decision support system for flood risk management 
in Brazil that combines volunteered geographic information with wireless sensor networks. Computers 
& Geosciences, 80, 84–94.
HW group. (n.d.). GSM Thermometer. Retrieved from http://www.hw-group.com/products/HWg-Ares/
HWg-Ares_GSM_sensors_en.html
Indira, P., Kabita, S., & Chandrakant, M. (2015). Flood Prediction and Prevention through Wireless 
Sensor Networking (WSN): A Survey. International Journal of Computer Applications, 113(9).

38
Smart Technologies for Emergency Response and Disaster Management
﻿
JPL. (2017). Gravity recovery and Climatic experiment. Retrieved from http://www.jpl.nasa.gov/mis-
sions/gravity-recovery-and-climate-experiment-grace/
Lipa, B. J., Barrick, D. E., Bourg, J., & Nyden, B. B. (2006). HF radar detection of tsunamis. Journal 
of Oceanography, 62(5), 705–716. doi:10.1007/s10872-006-0088-9
Lo, K.-F. A., Yeh, H.-C., & Chen, S.-H. (2015). Landslide detection using satellite remote sensing im-
agery. International Journal of Development Research, 5(4), 4237–4241.
Lo, S.-W., Wu, J.-H., Lin, F.-P., & Hsu, C.-H. (2015). Visual sensing for urban flood monitoring. Sensors 
(Basel, Switzerland), 15(8), 20006–20029. doi:10.3390/s150820006 PMID:26287201
Luna. (2017). Sensors and Systems. Retrieved from http://lunainc.com/applied-research/applied-research-
technologies/sensors-systems-2/
Maritime Journal. (2009, Feb 1). Instant feedback from tsunami warning system. Retrieved from http://
www.maritimejournal.com/news101/onboard-systems/safety,-survival-and training/instant_feedback_
from_tsunami_warning_system/
MAU. (n.d.). Ice and Climate: Automatic Weather Stations on glaciers. Retrieved from http://www.
projects.science.uu.nl/iceclimate/aws/technical.php
Mishra, P. K., Shukla, S. K., Dutta, S., Chaulya, S. K., & Prasad, G. M. (2011). Detection of Landslide 
Using Wireless Sensor Networks. IEEE.
Mousa, M., Zhang, X., & Claudel, C. (2016). Flash Flood Detection in Urban Cities Using Ultrasonic 
and Infrared Sensors. IEEE Sensors Journal, 16(19), 7204–7216. doi:10.1109/JSEN.2016.2592359
National Institute of Ocean Technology. (n.d.). Ocean Observation Systems. Retrieved from https://
www.niot.res.in
NOAA National Server Stroms Laboratory. (n.d.). Nssl Research: Tornadoes. Retrieved from http://
www.nssl.noaa.gov/research/tornadoes/
NOAA National Server Stroms Laboratory. (n.d.). Tornado Detection. Retrieved from http://www.nssl.
noaa.gov/education/svrwx101/tornadoes/detection/
NOAA’s National Weather Service Flood Warning Systems Manual. (2012). U.S. Department of Com-
merce, National Oceanic and Atmospheric Administration National Weather Service.
ODIM. (2011, Jul 11). SeaCycler. Retrieved from http://www.brooke-ocean.com/seacycler.html
Odli, Izhar, Razak, Yusuf, Zakarya, Saad, & Nor. (2016). Development of portable water level sensor 
for flood management system. ARPN Journal of Engineering and Applied Sciences, 11.
Pyrheliometer. (n.d.). Retrieved from https://en.wikipedia.org/wiki/Pyrheliometer
Rahman, M., Rahman, S., Mansoor, S., Deep, V., & Aashkaar, M. (2016). Implementation of ICT and 
Wireless Sensor Networks for Earthquake Alert and Disaster Management in Earthquake Prone Areas. 
Procedia Computer Science., 85, 92–99. doi:10.1016/j.procs.2016.05.184

39
Smart Technologies for Emergency Response and Disaster Management
﻿
Ramesh, M. V. (2014). Design, development, and deployment of a wireless sensor network for detection 
of landslides. Ad Hoc Networks, 13, 2–18. doi:10.1016/j.adhoc.2012.09.002
Reymond, D., Hyvernaud, O., & Talandier, J. (1991). Automatic detection, location and quantification of 
earthquakes: Application to tsunami warning. J. Pageoph., 135(3), 361–382. doi:10.1007/BF00879470
Rivera, J.Y. (2016). Tools to operate and manage early warning systems for natural hazards monitoring 
in El Salvador. Open Geospatial Data, Softw. Stand., 1, 9. doi:10.1186/s40965-016-0010-3
Senix. (2016). Ultrasonic Sensors help provide Tsunami warning. Retrieved from. https://senix.com/
toughsonic-ultrasonic-sensor-sea-level-measurement/
SGS Weather. (2015). Weather Sensors. Retrieved from http://www.sgsweather.com/weather-sensors
Shen, Z., & Wang, Q. (2013). Data Validation and Validated Uncertainty Estimation of Multifunctional 
Self-Validating Sensors. IEEE Transactions on Instrumentation and Measurement, 62(7), 2082–2092. 
doi:10.1109/TIM.2013.2253912
Sonardyne. (n.d.). Tsunami Detection System. Retrieved from http://www.sonardyne.com/products/
monitoring-a-control/tsunami-detection-system.html/
Space Science and Engineering Center. (2010, Apr 28). What makes up a Wisconsin AWS? Retrieved 
from https://amrc.ssec.wisc.edu/news/2010-May-01.html
Sun, G., Hu, T., Yang, G., & Jia, J. (2015). Real-time and clock-shared rainfall monitoring with a wireless 
sensor network. Computers and Electronics in Agriculture, 119, 1–11. doi:10.1016/j.compag.2015.09.023
Sunkpho & Ootamakorn. (2011). Real-time flood monitoring and warning system. Sonklanakarin Journal 
of Science and Technology, 33(2).
Tompe, Gaikwad, Pawar, & Pahadiya. (2016). Land Slide Detection System. Imperial Journal of Inter-
disciplinary Research, 2(1).
Towhata, I. (2015). Monitoring of unstable slopes by MEMS tilting sensors and its application to early 
warning. IOP Conf. Series: Earth and Environmental Science. doi:10.1088/1755-1315/26/1/012049
Tsunami Early Warning System. (2010). Retrieved from http://www.khaolak.net/homemenu/tsunami.html
Watanabe, K., Ishigaki, T., & Higuchi, T. (2010). A Multivariable Detection Device Based on a Capacitive 
Microphone and Its Application to Security. IEEE Transactions on Instrumentation and Measurement, 
59(7), 1955–1963. doi:10.1109/TIM.2009.2030716
Water, G. (2015). Water level (Pressure) Instrumentation. Retrieved from http://www.globalw.com/
catalog_level.html
Waterlog. (n.d.). Non-Contact water level sensor. Retrieved from http://www.waterlog.com/products-
detail.php?Air-Water-Soil-Temperature-Sensor
Waterlog. (n.d.). Silicon Pyranometer Sensor. Retrieved from http://www.waterlog.com/productsdetail.
php?H-380-Relative-Humidity-Temperature-Probe-and-Radiation-Shield-22

40
Smart Technologies for Emergency Response and Disaster Management
﻿
Xiao, R., & He, X. (2013). Real-time landslide monitoring of Pubugou hydropower resettlement zone 
using continuous GPS. Natural Hazards, 69(3), 1647–1660. doi:10.1007/s11069-013-0768-x
Yang, I. T., Park, J. K., & Kim, D. M. (2007). Monitoring the symptoms of landslide using the non-prism 
total station. KSCE J Civ Eng., 11(6), 293–301. doi:10.1007/BF02885900
Zhang, W., & Liu, S. (2010). Applications of the Small Satellite Constellation for Environment and 
Disaster Monitoring and Forecasting. Int. J. Disaster Risk Sci., 1(2), 9–16.

41
Copyright © 2018, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.
Chapter  2
DOI: 10.4018/978-1-5225-2575-2.ch002
ABSTRACT
Emergency response and disaster management in underground mines are very challenging due to the 
hostile nature. Environment monitoring in mines has been an obligatory requirement to ensure safe 
working conditions for miners. Reliable communication network is essential to quickly detect the un-
derground condition especially in emergency situation and to conduct proper rescue operations. This 
chapter presents an overview of reliable communication network needed for emergency response and 
disaster management in underground mines. The chapter begins by introducing the most common ac-
cidents occurring in the mining, underground mine environment and channel properties. Subsequently, 
communications in underground mines, existing underground communication and tracking systems, and 
disaster forecasting & mine safety management are discussed. The chapter also covers post-disaster mine 
communications & tracking systems and optimized backbone networks for underground mines. Finally, 
the chapter concludes by reporting relevant research at Ryerson Communications Lab and pointing out 
some open issues and possible research directions.
Reliable Communication 
Network for Emergency 
Response and Disaster 
Management in 
Underground Mines
S. M. Kamruzzaman
Ryerson University, Canada
Xavier Fernando
Ryerson University, Canada
Muhammad Jaseemuddin
Ryerson University, Canada
Wisam Farjow
PBE Group, Canada

42
Reliable Communication Network for Emergency Response and Disaster Management
﻿
INTRODUCTION
Natural or man-made disasters are unpredictable and increasing in number nowadays throughout the 
world. Without warning, disaster can strike and affect people, living society and environment in many 
ways. An underground mine is an inherently hazardous workplace. Mine disasters have been a crucial 
issue among mine operators, safety and health personnel, and miners for decades (Brnich, 2010). Although 
catastrophic mine accidents, such as the Benxihu colliery mine disaster that killed 1,549 people and the 
Courrieres disaster in France that killed 1,099 people, understandably make the headlines, many smaller 
incidents remain unnoticed. For example, there were 69 fatalities and 11,800 injuries in US mines in 
2006-2007 alone. Every year several miners die due to fatal incidents. Even during normal operations, 
mining workers are five times more likely to be exposed to occupational hazards than the industrial aver-
age. In case of disaster in an underground mine, it is very difficult for emergency response and disaster 
management team to identify actual person trapped, their number, and exact location (Bandyopadhyay, 
2009). Therefore, identifying and locating of miners, explosives and critical exits are very important 
tasks for underground mine management in case of disaster as well as usual working conditions.
Most important factors of accidents in the mining industry are (i) Poisonous or explosives gases pres-
ent in the ground and (ii) Use of explosives (blasting operations) for rock breaking purpose. Followings 
are the most common accidents occurring in the mining industry (Dozolme, 2016):
•	
Methane and Consecutive Coal Dust Explosions: Methane is a highly explosive gas trapped 
within coal layers. Mechanical errors from improperly used or malfunctioning mining equipment 
(such as safety lamps or electrical equipment) or the use of improper explosives underground can 
trigger methane and initiate consecutive coal dust explosions. Methane and coal dust explosions 
have caused the largest mining disasters in history and frequently kill or trap underground miners.
•	
Blasting Related Accidents: Blasting consists in using explosives for rock breaking purpose. 
Proper, and improper, use of explosives could lead to dangerous situations such as: a) Fly-rocks: 
For the past two decades, most explosives-related injuries and fatalities in surface mines occurred 
when workers were struck by rock, either because they were too close to the blast or rock was 
thrown much farther than expected; b) Premature blast: The detonation of an explosive charge 
earlier than warranted. Premature explosion may be due to carelessness, accidental percussion, a 
faulty fuse, or degenerated explosives; c) Misfires: Misfire means the complete or partial failure of 
a blasting charge to explode as planned; d) Mine-induced seismicity: It is especially dangerous in 
underground mining areas, mine-induced seismicity also cause slope instability in surface mining, 
and is a major threat for all miners.
•	
Fire: The followings are the potential sources of fire in underground mines: a) Friction from de-
fective bearings, conveyor idlers, drums, wheels/axles; b) Seized brakes on vehicles; c) Internal 
combustion engines – exhaust systems, air inlets, hot surfaces; d) Spontaneous heating of coal in 
the waste or of broken coal in the roadside in high-risk seams; e) Sparks from cutting machin-
ery picks; e) Electrical and mechanical machinery and equipment; f) Electrical sparking and hot 
surfaces from electrical equipment and distribution systems; g) Short circuits and earth faults on 
electrical equipment and distribution systems; h) Natural sources, for example, electrostatic dis-
charges and lightning; i) Hot work – burning, welding, and grinding; j) Smokers’ materials, e.g. 
cigarettes, lighters and matches.

43
Reliable Communication Network for Emergency Response and Disaster Management
﻿
•	
Collapse: Mine collapse might be caused by the following factors: a) Use of explosives-The use 
of explosives might cause earthquake-like events that collapse mine workings, and traps miners; 
b) Timbering/Pillar failure: The role of pillars or timbers is obviously key in underground opera-
tions. The instability of pillars induced by stress or other unfavourable causes may lead to hor-
rendous cascading pillar failure mechanisms. Accident due to roof fall and collapse of side gallery 
is a regular occurrence in underground coal mines which causes death of huge number of miners.
•	
Toxic Contaminant: Considering that the atmosphere in the underground is limited and confined, 
the contaminants may include dust, aerosols, diesel fumes and particulates and fumes from blast-
ing, as well as gasses released from the rock strata. Ventilation is important to extract or dilute to 
a harmless level the toxic contaminants.
Therefore, the ability to locate miners and explosives before/after disasters is critical for fast rescue 
and lifesaving. This requires reliable underground communication networks and tracking facilities that 
will enable communication with the workers and their locations to be known at all times.
The recent MINER (Mine Improvement and New Emergency Response) Act of 2006 mandates 
tracking of all coal miners continuously; however technology has not matured after 10 years to address 
this (Nutter, 2007). Continuous communication and tracking networks will alleviate accident rates and 
accelerate emergency services by accurately locating miners, moving machinery, and explosives.
Most mines currently use some kind of radio frequency identification (RFID) tags and walkie-talkies 
for monitoring and locating workers and assets. However, the collected data is very undependable due to 
noisy, harsh, irregularly confined, and rough RF propagation environments. Video information suffers 
from low light and dusty conditions.
In the next few sections, we describe (i) typical underground mine environments, (ii) communication 
systems that are currently in place and in development to address the issues, their advantages and issues 
(iii) few research topics that happen at Ryerson Communication Lab in this direction.
CHALLENGES IN UNDERGROUND MINE COMMUNICATIONS
In underground mine, it is a very difficult task to establish a reliable communication due to the extreme 
environmental conditions. Until now, no single communication system exists which can solve all of the 
problems and difficulties encountered in underground mine communications. However, combining re-
search with previous experiences might help existing systems improve, if not completely solve all of the 
problems. In this section, we will discuss the characteristics of underground mines focusing to the com-
munications aspect and the underground channel properties that impact the underground communications.
Underground Mine Environment
The underground mining environment is remarkably different from the conditions present on the surface. 
Underground mines are structurally non-uniform. They contain many crosscuts, escape ways, first-aid 
stations and blockages. Most of the hallways have railroads on the ground. The walls are rough and the 
ground surface is uneven and may have small amount of accumulated water. Some parts of the wall and 
ceilings are strengthened with wooden grids and metal (Yarkan, 2007). As our focus is on the commu-

44
Reliable Communication Network for Emergency Response and Disaster Management
﻿
nication aspect inside the mines, hence the general conditions that are noteworthy in this regard can be 
stated as follows (Misra, 2009):
•	
Dynamic Topology Change: The walls of the mines may shift on a daily basis as a result of the 
cutting of the mineral faces.
•	
Unstable Nature of Geological Construction: A mineral face consists of collapse and safe zones. 
In the safe zones, there are hydraulic supporters to avoid collapses. In collapse zones, there are 
no supporters and can easily collapse either when the zone becomes larger or in the event of mine 
quakes resulting in structural changes (Bai, 2007).
•	
Limited Line-of-Sight (LOS): This arises from the presence of pillars and undulations following 
the mineral seam. These underground structures get carved and come into existence in the due 
course of the mineral extraction process.
•	
Low Loss Dielectric Medium: At certain frequencies, the mine tunnel acts a low-loss dielectric 
(Murphy, 1978) resulting in the degradation of the communication system.
•	
Ionized Air: The air gets ionized as a result of fires inside the mine. The self-ignition of coal 
seams results from an exothermic reaction of coal and oxygen. If the concentration of oxygen is 
more than 3% then the oxidation heat is released from the coal and gives way to fires (Xie, 1999).
•	
Humid and Warm Conditions: The relative humidity is greater than 90% and the temperature is 
around 28 degrees (Xie, 1999).
•	
Gaseous Environment: The main component of the gases that effuse with the extraction of coal 
from the coal seams is Methane. When the concentration of Methane exceeds a threshold value, 
it leads to gas blasts/coal-dust explosion (Bai, 2007). Hence, there is continuous ventilation to 
decrease the built-up of the gas. However, in case of a disaster, the power supply to the mines is 
often cut down leading to the compromise of the ventilation system.
Unfortunately, an underground mine provides an extremely difficult environment for applying tradi-
tional wireless communications and tracking solutions and requires intensive computational resources. 
The active areas of a mine consist of a labyrinth of tunnels imbedded in a tubular coal seam. Intersecting 
tunnels (crosscuts) are arranged in a grid fashion and often extend for kilometres in various directions. 
The tunnels rarely have line-of-sight distances along entries. Furthermore, the communications systems 
must be designed to maximize their survivability after a catastrophic event, such as an explosion or fire 
and must meet Mine Safety and Health Administration’s (MSHA) permissibility requirements (intrinsi-
cally safe).
Appropriate telecommunications play a unique role in emergency response and disaster management. 
In the severe environment and changing topology of a mine, reliable communication is a prime concern. 
A reliable underground communication network in mines will not only facilitate the day to day opera-
tions but will also help save many lives. This book chapter aims to present a reliable Information and 
Communication Technology (ICT) infrastructure with wireless sensors in mines to improve the situation 
in multiple frontiers (Srivastava, 2011). Such a system is enable the tracking of miners, explosives, and 
vehicles, which will significantly improve worker safety (Wang, 2010). It is also enable effective locat-
ing of trapped miners to assist rescue missions following disasters. In addition, ICT will help reduce the 
energy usage by facilitating a smart grid concept in mines. A smart grid can be implemented through 
sensing various parameters and will have the ability to run high-power operations such as ventilation, 

45
Reliable Communication Network for Emergency Response and Disaster Management
﻿
pumping, and transportation at optimal times and rates (Li, 2011; Zhou, 2011a). In essence, a sophisti-
cated ICT system will make the mines smarter, safer and more energy efficient.
However, there are significant challenges in developing reliable ICT solutions for mines. First, the 
communication network has to be developed from scratch, as many above-ground techniques do not 
work underground (Daoud, 2011; Farjow, 2015). Second, large mines are several hundred meters deep, 
consisting of interconnected irregular tunnels with open areas, pillars, and blockades. The surfaces of 
these tunnels are rough and absorb and scatter RF energy, making reliable wireless access difficult to 
achieve. Third, mine topologies change dynamically and can grow over 50 feet per day. All these make 
many existing wireless communication technologies useless, requiring new innovative technologies.
Most importantly, an underground communication network must have very low power consumption. 
Power consumption of the carry on sensors need to be significantly small to save battery life and have 
light weight and small size (Li, 2012). In addition, the power consumption of the backbone network must 
also be small in order to meet the rigorous safety requirements of mines (Chehri, 2011).
Underground Channel Properties
The wireless channel characteristics in mines are different from those in free space because of the harsh 
underground environment. This is due to physical phenomena such as severe signals’ reflections, scat-
terings and diffractions in the confined spaces of the underground mines. The major factors that impact 
communication with Electromagnetic (EM) waves in the underground mines can be summarized as 
follows (Misra, 2009; Akyildiz, 2006):
•	
Extreme Path Loss: Lower frequencies experience less attenuation than higher frequencies due 
to material absorption. The rate of attenuation would increase with the increase in humidity as 
well. The path loss increases as the square of the distance travelled by the wave.
•	
Reflection/Refraction: As mentioned earlier, the tunnel acts a low-loss dielectric at certain fre-
quencies and leads to a waveguide effect. Waves that impinges on a wall of the tunnel are partially 
refracted into the surrounding dielectric and partially reflected back into the waveguide resulting 
in signal losses. The reflected waves may result in a completely new pattern that may not be rec-
ognized as information by the receiver but as noise.
•	
Multipath Fading: The random addition of multiple propagation paths causes fluctuations in 
signal strength with position and frequency, and, if reflectors, transmitters or receivers are mov-
ing, also in time.
•	
Reduced Propagation Velocity: Waves propagating through a dielectric medium would experi-
ence a reduced propagation velocity compared to that of air. With the change in underground 
temperature, the dielectric property of the medium will change. Hence, an increase in undermine 
temperature would alter the dielectric properties and lead to increase in signal attenuation.
•	
Noise: The performance of the communication system is highly dependent on the EM noise in 
the environment. Clouds contain electrical charges that are evidenced as lightning stokes under 
stormy conditions. This flow of current gives rise to EM radio waves with sufficient intensity to 
interfere with radio communications. A good amount of noise ends up in the extremely low fre-
quencies (ELF), voice frequencies (VF) and very low frequencies (VLF) frequency band, which 
have a negative impact on the receivers. The noise caused by electric motors, power lines, appli-
ances etc. is in the frequency bands which are most suitable for underground communications.

46
Reliable Communication Network for Emergency Response and Disaster Management
﻿
•	
Realistic Waveguide Effect: In an ideal waveguide effect, the electromagnetic waves are confined 
and guided by the mine tunnel but in a realistic scenario, the reflective and absorption losses along 
the path result in the increase in signal attenuation.
Many researchers have investigated the characteristics of the underground mines wireless channels 
based on mine shapes and layouts. Few studies have characterized the wireless channels in the open areas 
of the mines by utilizing generic models, such as Ray-Tracing techniques. Other studies have analyzed 
the wireless channels in the tunnel areas (canonical areas) by utilizing the theories of the guided wave 
propagation model.
COMMUNICATIONS IN UNDERGROUND MINES
In mining operations, communication systems play vital roles in ensuring personnel safety, enhancing 
operational efficiency and process optimization. In this section, the evolution of wireless communica-
tions in underground mines is discussed in terms of technologies and applications. It is well known 
that the initial motivation for underground mine communications was to increase the safety of miners 
by implementing man-to-man communications. As underground mine communications have evolved, 
man-to-machine and machine-to-machine communications have been implemented to meet efficiency 
and productivity objectives (Forooshani, 2013; Kumar, 2013; Sicignano, 2013). In an underground 
mine, there are three possible mechanisms for communication signaling: through-the-earth (TTE) at 
extremely-low-frequency (ELF)/very-low-frequency (VLF)/low-frequency (LF) bands, through-the-wire 
(TTW) at medium-frequency (MF)/VHF/lower-UHF (e.g., leaky feeders) and through-the-air (TTA) at 
upper-UHF/super-high-frequency (SHF) (Schiffbauer, 2006).
Through-The-Earth Communications
Interest in wireless communications for underground mine dates back to the 1920’s when the earliest 
pioneers of radio were interested in the possibilities of TTE wireless transmission (Forooshani, 2013). 
N. Tesla suggested to use ELF signals, and the earth as a transmitting medium to send messages across 
the world in 1899 (Pittman, 1985). This continued until the late 1940’s when techniques such as carrier-
current radios and TTE signaling were commercially offered by the U.S. Bureau of Mines for ordinary 
communications and for emergency operations in mines (Large, 1973; Nutter, 1988; Delogne, 1991). 
TTE communications in mines use huge antennas to transfer ELF or VLF signals through solid rock 
from the surface into the underground mine. In late 1940’s, due to limitations such as low data rate and 
bulky mobile equipment, early studies of wireless communications in tunnels were terminated (Hill, 
1982; Durkin, 1984).
Recent mine regulations have renewed interest in TTE communications since it offers a wider coverage 
inside the mine compared to modern wireless systems (Jong, 2016). There are apparent advantages to 
modern wireless systems in underground tunnels and mines, but they could be quite vulnerable when a 
major disaster occurs. Disasters such as explosion, flooding, rock burst, or severe roof fall, may damage 
the relay system or block airways. TTE communications has been proven to be suitable for emergency 
communications because it accesses every part of the mine by propagating through the rock and requires 
no cabling between the surface and underground (Barkand, 2006). Two-way communication systems are 

47
Reliable Communication Network for Emergency Response and Disaster Management
﻿
preferred over one-way systems because in most emergency cases, it is essential for escaping or trapped 
miners to relay valuable information to the surface.
Until several fatal incidents occurred in 2006, the number of mining disasters had been following a 
decreasing trend. The MINER Act of 2006 requires that mine operators install wireless two way com-
munications and tracking systems that will connect surface rescuers to the underground workers (Bise, 
2006). Two commonly used wireless solutions for emergency cases are text messaging based on TTE 
and tracker tagging.
Personal-emergency-device (PED) is an emergency warning system based on TTE technology, which 
uses VLF/ULF signals to transmit text messages. Initially, this product had one-way communication 
capability, but recent versions are capable of two-way communication via text messaging.
Through-The-Wire Communications
In the early history of through-the-wire communications in tunnels and underground mines, implementa-
tion of communication systems was based on experimental observations without any theoretical insights 
or empirical modeling attempts (Forooshani, 2013; Jong, 2016). People working in underground mines 
found that low frequencies on the order of 10 MHz (cutoff frequency of fundamental modes of most 
tunnels) could cover distances of less than 30 m in an empty mine (Liénard, 2000). However, they also 
observed that conductors such as electrical cables, pipes and etc., running in most mines, enhance EM 
propagation with low attenuation, and therefore increase the range (Pittman, 1985). This fact was not 
immediately understood by experimenters, but it resulted in development of the monofilar technique 
at the end of the 1960’s. Monofilar system became an introduction for leaky feeder systems that were 
widely used thereafter.
In general, TTW signals can travel over coaxial, twisted pair, trolley, leaky feeder and fiber optics 
from the surface or inside the mine and reach the mobile equipment. Since one side of the system is 
wired and the other is wireless, it is also called a hybrid or semi-wireless system. During the 1950’s and 
1960’s, leaky feeder systems and other distributed antenna systems were developed in order to extend 
the coverage of VHF wireless communication systems to the relatively short underground transporta-
tion tunnels found in major urban centers for public safety (Martin, 1984). In the late 1960’s when the 
safety concerns prompted government regulators and safety boards in Europe and North America to 
encourage the mining industry to improve communications with underground workers by deploying 
wireless systems based upon VHF-FM portable radios and leaky feeder distribution systems (Delogne, 
1991). Leaky feeder is the most well-known TTW-based communication system in underground mines. 
The cable is called leaky’ as it has gaps or slots in its outer sheath, allowing signal to leak into or out 
of the cable along its entire length (Figure 1). Because of this leakage of signal, line amplifiers must 
Figure 1. Leaky feeder cable structure

48
Reliable Communication Network for Emergency Response and Disaster Management
﻿
be inserted at regular intervals, typically every 350 to 500 meters. Key disadvantages of leaky feeder 
system are difficult maintenance, fixed infrastructure, limited capacity and low coverage near the face, 
i.e., the region of the mine where ore is extracted (Delogne, 1991).
Through-The-Air Communications
TTA is another wireless system for communications in underground mines. It is capable of offering 
various applications such as two-way voice and data communications, tracking miners and equipment, 
remote control and sensing, video surveillance and etc. (Forooshani, 2013).
In the early 2000’s, advances in short-range digital communications to cover 100’s of meters moti-
vated the mining industry to consider WLAN off-the-shelf products to support short-range applications 
in underground. In the late 2000’s, the mining industry was attracted to low data rate technologies such 
as ZigBee, active-RFID (10’s of meters), passive RFID (about 1 meter) and high data rate systems, such 
as ultra-wide band (UWB) systems (Shaban, 2015; El-Nasr, 2015; Savic, 2016a) because they offer 
short-range, low power and positioning capabilities (Pfeil, 2015). These technologies can support vari-
ous applications such as dispatch and sensor networks. These applications can be implemented based 
on WLAN backbone. So far, WLAN mesh networks that are redundant, self-learning and self-healing 
seems to be the most reliable wireless systems. If any part of the network is destroyed, the remainder 
continues to function, and therefore it is especially desirable in a dynamic environment where link 
failures are frequent as in the mine galleries (Srinivasan, 2005). One of the attractive wireless applica-
tions is tracking, which can be implemented based on RFID technology using WLAN, fiber optics or 
leaky feeder backbone. This tracking system provides the ability of real-time monitoring the location 
of personnel, vehicles and equipment underground (Savic, 2016b). Mining equipment such as vehicles, 
containers, drills and other valuable mobile ore production equipment are constantly moving through 
large underground areas. Because the equipment does not necessarily follow a pre-defined track and is 
spread throughout the mine, it is difficult to locate particular assets that are needed in real-time (Chehri, 
2009; Frielos, 2007).
A typical RFID-based tracker system consists of: (i) active tags to identify personnel/vehicles/assets 
or store data and histories, (ii) tag readers to exchange information with the server and tags, (iii) antennas 
to connect tags and tag readers and provide triangulation information for location finding, (iv) a server 
computer system for control and monitoring, and (v) backbone system that can be fiber optics or leaky 
feeder to connect tag readers to the server.
Another important application of short-range wireless is remote control and sensing. Some of 
commonly deployed control applications of wireless communication are real-time remote equipment 
diagnostics, remote monitoring, remote programmable-logic-controller (PLC) programming, etc. As 
an example, a PLC in local control station can wirelessly communicate with the remote automation 
and sensor devices (such as pull cords, belt misalignments and tilt switches or motion sensors) along a 
conveyor in a mine site.
Before employing the aforementioned wireless technologies in underground mines, careful charac-
terization of the wireless propagation in terms of parameters such as path loss, delay spread and angular 
spread, etc. is required. This is because wireless propagation in tunnels and underground mines is sig-
nificantly different from conventional indoor and outdoor environments, and therefore existing channel 

49
Reliable Communication Network for Emergency Response and Disaster Management
﻿
models developed for conventional surface environments are not applicable. Consequently, it will be 
necessary to develop new channel models that capture the nature of the relevant impairments and their 
dependence on the new environment.
A good channel model is abstract, simple, and focuses on those aspects of the channel that affect 
the performance of a system of interest and ignore the rest. Over-engineering the communications links 
is needlessly expensive and under-engineering them leads to either insufficient reliability or capacity. 
Propagation and channel modeling facilitates efficient design and system deployment by answering ques-
tions such as what channel impairments do we need to mitigate? Or what are the optimum frequency, 
antenna placement/configuration and range (Forooshani, 2013)?
EXISTING UNDERGROUND COMMUNICATION SYSTEMS
Most of the existing underground communication systems are wired communication systems that de-
pend on a wire connection which conveys the information between two communication nodes. Public 
switched telephone network (PSTN) can be considered as an example of wired communication systems.
In underground mine communications, some of wired communication systems depend on a com-
mon communication wire to which each individual phone (or terminal, or node) is attached (Yarkan, 
2009). This sort of wired communication system is called ‘party line’ system. Main characteristic of 
this system is that the transmission of any node can be received by all other individual nodes because 
of the common line. A more complicated version of party line system is known as ‘private line,’ which 
includes a central switch to handle the private transmissions connecting only desired nodes to each other. 
Switching mechanisms of early private line systems were governed by an operator, whereas those of 
current systems are controlled and processed by computers. Based on the line systems explained above, 
the following wired communication systems are employed in underground mines (Misra, 2009). Some 
existing communication devices (Bandyopadhyay, 2010) along with their advantage and disadvantage 
are shown in Table 1 (Misra, 2010).
Table 1. Communication devices
Name
Type
Advantages
Disadvantages
Telephones
TTW
Easy operation
Vulnerable to damage from roof falls, mine fires, 
and explosions
Pager phones
TTW + TTA
Cheap; simple operation
One-way
Trolley phones
TTW
Fixed/mobile — can provide 
communication to all rail haulage 
vehicles
Limited coverage; constant vibration; warm, 
humid, and dusty conditions; interference from
Hoist phones
TTW
Simple operation
Limited to communication between the hoist cage 
and sur-face/underground
Walkie-talkie
TTA
Wireless communication; portable; 
two-way; can connect to nearby 
communication infrastructure (e.g., leaky 
feeder)
Generally poor range but may have good LOS 
performance

50
Reliable Communication Network for Emergency Response and Disaster Management
﻿
•	
Telephones: The basic operation of the underground mine phones is similar to that of the surface-
type phones. The Private Branch Exchange (PBX) inside the mine is responsible for the make/
break of the call and these telephones are interconnected by multiple pair cables. Circuit breakers 
and lightning arrestors are responsible for protecting the system from sudden energy surges by 
limiting the electrical energy to safe levels. These telephone systems are easy to use but are vul-
nerable to damage from roof falls, mine fires and explosions.
•	
Pager Phones: The pager phones are battery operated, party line telephones with provision for 
loudspeaker paging. It is cheap and simple but is noisy even in the usual transmission mode.
•	
Trolley Phones: Trolley phones can be fixed or mobile (carried on locomotives). The mobile units 
are subjected to constant vibration and suffer the temperature extremity along with humid and 
dusty conditions. The transmission lines pass across various mining machineries which result in 
degradation of the communication quality. The main advantage is that they provide communica-
tion to all the rail haulage vehicles using trolley cables but are limited in coverage.
•	
Hoist Phones: It is a communication facility between the persons in the hoist cage (used to raise 
and lower conveyances within the mine shaft) and the surface/underground wherein a phone line 
directly connects the cage to the mine communication system.
•	
Walkie Talkie: It is a portable, bi-directional radio transceiver which has the appearance of tele-
phone handset with an antennae. It is basically a half-duplex communication system wherein only 
one person can talk at a time. They provide a wireless communication system with a better cover-
age area but have to be used in conjunction with leaky feeder cables and line amplifiers for signal 
transmission across corners and bents.
UNDERGROUND MINE TRACKING SYSTEMS
The majority of tracking devices are based on RFID technique (Misra, 2009). It consists of RFID tags 
that is carried by the workers/machinery. As it passes the tag readers pre-positioned at fixed locations 
throughout the mine, they are able to recognize the object by the coded RF signal emitted. This information 
is sent to a central location for monitoring. However, the latest tracking systems are based on digital data 
networks which include TCP/IP, Ethernet, WiFi, Wireless Mesh Networks, VoIP, Cell phone technology.
There are many research agencies and manufacturers that have conducted extensive research on de-
veloping effective tracking systems for underground mines (Misra, 2010). A detailed list is available in 
the website of West Virginia Office of Miners’ Health Safety and Training1. The U.S. Bureau of Mines, 
CSIRO (Australia), CSIR (South Africa) are some of the noteworthy organizations in this regard. As 
per the US government regulations for mines, electrical communication devices have to be approved by 
the MSHA as permissible. Permissibility can be achieved through Explosion Proof (XP) and Intrinsi-
cally Safe (IS) designs. A list of MSHA approved communication and tracking devices can be found in 
their website2. Designing and developing such systems for underground mines should have certain de 
facto standards.
A survey of the commercially available underground mine communication and tracking systems 
available with the manufacturers and vendors in (Misra, 2009). However, an assessment of performance 
and limitations has not been described in (Misra, 2009) as the utilization of these products in mines is 
presently not known and the compiled information is from the respective company websites which fea-
ture mostly on the promised functionality. However, The National Institute for Occupational Safety and 

51
Reliable Communication Network for Emergency Response and Disaster Management
﻿
Health (NIOSH)3 presents a brief report on the test results for some of the communication and tracking 
devices mentioned in (Misra, 2009). The discussed underground mine tracking systems can be classified 
into the following types based on the tracking type:
•	
Zone/Proximity Based Systems: They are able to detect the presence of the object in a particular 
region. The RFID based systems belong to this category. Resolution depends on number of read-
ers installed in a surveillance area.
•	
Node Based Systems: A radio device capable of communicating with other nodes is carried by 
the miner. The location is determined by identifying the node with which the miner was able to 
communicate. Resolution depends on the number of nodes and the fidelity of the signal process-
ing technique.
As of December 31, 2007, MSHA has observed the testing or demonstration of 27 communications 
and/or tracking systems at various mine sites. The agency met with representatives from 61 communica-
tions and tracking system companies. To date, it has had discussions with various vendors regarding 162 
different proposals for development of mine communications and tracking systems. Since the beginning 
of 2006, the agency has issued 35 new or revised approvals for communications and tracking products. 
It is currently investigating 43 approval applications for communications and tracking technology.
Several companies agreed to speak with Coal Age about their products. All of them have communi-
cations and tracking systems that are either approved by MSHA or submitted for approval. Generally, 
they can be separated into two camps: leaky feeder and purely wireless.
Most of the wireless systems are based on the IEEE 802.11 (WiFi) or 802.15.4 (ZigBee) radio speci-
fication. Most operate at 2.4 gigahertz (GHZ). Wireless systems use access points or nodes to create 
a self-forming, self-healing ad-hoc mesh network for communications. The leaky feeder system uses 
a cable strung throughout the mine as an antenna. Most mines are familiar with very high frequency 
(VHF) systems that operate on the yellow stranded cable. New, more future-proof ultra-high frequency 
(UHF) systems are being developed. One of the more popular cables is Radio Frequency Systems’ (RFS) 
Radiaflex cable. Most of the tracking systems use a RFID tag and a set of tag readers to determine the 
location of a miner or a piece of equipment. A list of MSHA approved communications and tracking 
technologies are shown in Table 2.
Recently, KAIST, Hydraumatics Co., and Korea Coal Corporation have developed a mining robot and 
a tele-operation system to operate the robot from a safe remote place. In the literature (Huh, 2011), it is 
discussed the design of the robot mechanism and the sensing algorithms for localization and elevation 
mapping. After explosion in hazardous environment, rescue team faces several problems in rescue opera-
tion. Rescue team usually does not know the real position of the mine cavity under such circumstances. 
In a project work in China (Jianguo, 2010), a coal mine “detect and rescue robot” is proposed based on 
an embedded control system with ARM9 microprocessor. Based on the design of robot’s hardware, Linux 
operating system is ported as the platform of the software development. The robot has the advantages 
of scalability, flexibility, and low power consumption.
In a recent literature, a 3G wireless network video surveillance system is proposed for underground 
coal mines (Zhou, 2011b). This system uses 3G as latest multimedia communication network having 
smaller size, low cost, high stability, real-time monitoring for rescue operation, and development of 
management. Using video surveillance systems, ground operator can conduct real-time monitoring 
of the underground miners and other situations. This technology is not only used for visual records of 

52
Reliable Communication Network for Emergency Response and Disaster Management
﻿
underground worksite and security of production, but it also predicts the cause of accidents and takes 
preventive action. Though the practical implementation requires more improvements, the application 
of 3G based on wireless embedded network video surveillance system has future importance for safety 
in underground mines.
DISASTER FORECASTING AND MINE SAFETY MANAGEMENT
Every year disasters occur in coal mines causing death of miners, and loss of coal and property. Under-
ground pumps are often sited at remote locations, and their operation and maintenance is very difficult. 
Table 2. MSHA approved communications and tracking technologies

53
Reliable Communication Network for Emergency Response and Disaster Management
﻿
Online monitoring of pump operation and water level using sensors is highly essential for early detection 
of fault in the pump. A microprocessor-based multichannel intrinsically safe real-time environmental 
monitoring system has to be used for online continuous monitoring and providing early audiovisual 
warning signal to forecast different category of disasters using special sensors and techniques (Table 3) 
(Bandyopadhyay, 2010). The system will also provide online visual representation of trend of all moni-
tored parameters and give audiovisual warning signal when a particular parameter crosses respective 
threshold limit so that mine management can immediately take appropriate action.
Using computer database, all safety- and rescue-related data can be uploaded in the system for future 
use. Analysis of data can identify possible areas of weakness in mines safety system, and data can be 
used as a guideline for the decision making process to improve mine safety performance. Online moni-
toring of exhaust fan s peed and pressure development across fan has to be done using tachometer and 
air pressure sensors, respectively, for proper ventilation in underground coal mines.
Computerized system has to be developed to provide accident analysis, accident prone areas, probable 
remedies, emergency response plan, list of first aid, rescue trained personnel along with their address, 
telephone numbers, and place of duty during an emergency. Mobilization of manpower and resources can 
be done effectively to rescue the trapped miners without any delay. Sometimes during any mishap, there 
is misplacement of statute books, like manager’s diary, supervisor’s report, etc., but if these reports are 
filled in web then there is no chance of losing data/information. This information will help expediting 
the court of enquiry in case of accidents/or a disaster. A day-to-day action taken by safety managers can 
help in avoiding any casualty and if anything goes wrong then the logged data can help in rectifying the 
problem. It will also speed up actions in providing assistance and benefits to affected people. Computer-
ized attendance of miners can be easily done and can be used during emergency.
Wireless Sensor Network for Mine Safety Monitoring
Wireless Sensor networks (WSNs) is an emerging technology that has a wide range of potential applica-
tions including environment monitoring, military application, e-health application and smart industrial 
factories. The key challenge to realize WSNs in underground is the wireless communication in under-
ground environments (Tan, 2015). WSN allow information to be collected with more monitoring points, 
Table 3. Techniques for disaster forecasting in underground coal mines
SL
Category of Disaster
Parameters to be Monitored for Forecasting
Sensor/Technique
1
Explosion of 
flammable gas
Methane (CH4)
CH4 sensor
2
High concentration of toxic gas
Carbon monoxide (CO)
CO sensor
3
Mine fire due to self 
heating of coal
Temperature of coal strata
Temperature sensor
4
Roof fall
Movement of roof strata
Low-frequency acoustic sensor
5
Inundation
Demarcation of water-logged area, and 
maintaining safe distance between working area 
and water-logged or old working area
Updating and analysis of 
day-to-day survey data by ground-
penetrating radar (GPR)
6
Pump management
Running status of pump and early warning of 
increasing water level
Pump status sensor (ON/OFF mode) 
and water-level 
indicator

54
Reliable Communication Network for Emergency Response and Disaster Management
﻿
providing awareness into the environmental conditions that affect overall uptime, safety, or compliance in 
industrial environments and enabling agile and flexible monitoring and control systems (Dohare, 2015; 
Lin, 2015). ZigBee is a wireless network standard which was destined to sensor network applications, 
control and remote monitoring (Moridi, 2015). The ZigBee is a commercial standard which has been 
developed from IEEE 802.15.4.
When choosing deployment of WSN in underground mine, for mine safety monitoring, it should be 
necessary to make a compromise between conflicting requirements (Chehri, 2011; Ghaddar, 2016). First 
of all, the wireless sensor networks must use flexible, multihop networking that can follow several archi-
tectural topologies, to guarantee that network functions with maximum efficiency and reliability (Zhang, 
2014). The priority is to insure a robust global network with battery-operated nodes. Therefore, these 
types of networks are usually developed with the following goals in mind. On one hand, the nodes must 
be able to communicate with other nodes via a highly reliable radio module that is compatible with the 
communication protocol of the network, such as, IEEE 802.15.4 standard in our case. On the other hand, 
the network should be robust to monitor the required measurements, such as temperature for long time.
To improve the flexibility and reliability of the network, the multi-route topology, where each node 
is relayed to sink is the suitable choice. So, if a single node, the remitted data can automatically route 
through alternate paths. As shown in Figure 2, the sensor nodes deployed in the appropriate areas to col-
lect the environmental data (temperature, oxygen concentration, humidity) or to supervise continuously 
some parameters to detect possible anomalies like a fires, explosions (gas explosions, dust explosions, 
premature explosions of charges), toxic gases (Carbon monoxide, Methane), or even a roof failure. These 
collected data are transmitted to the sink node using multihop routing. After reception, the sink nodes 
Figure 2. Architecture for WSN in underground mines (Chehri, 2011)

55
Reliable Communication Network for Emergency Response and Disaster Management
﻿
combine its collected data and forward it to the gateway. Hence, the observer can query for information 
from the network (Wang, 2016). Based on this architecture, the underground mine remote monitoring 
becomes possible.
Routing of Emergency Data in a WSN for Mines
Emergency situations in mines result in loss of precious human lives. Recently two-tier network archi-
tecture, as shown in Figure 3, for the large-scale WSN deployed in mine galleries has been discussed 
in (Srinivasan, 2005). The first tier consists of clusters of sensor nodes (SN) scattered in a mine tunnel 
that gathers local information and transmit it to the sinks, which are the nodes in the mesh backbone. 
There is a single base station (BS) that collects the sensory data generated by the sensor nodes through 
the Mesh backbone. The Mesh backbone provides reliable paths as the backbone nodes are connected 
to constant power supply. It also provides redundant routes that are desirable in a harsh environment 
where link failures are frequent (Srinivasan, 2005). The lifetime of the Mesh backbone is much longer 
than the clusters of sensor nodes.
This research is focused on reliability, delay and energy constraints for routing in wireless sensor 
networks deployed inside underground mines, because reporting some emergency events, such as lack 
of oxygen in some parts of a mine, are loss and delay-sensitive (Jafarian, 2008). The WSN in mines 
carry two types of network traffic. Non-emergency regular traffic is the result of constant monitoring 
and measurements, and is not delay or reliability constrained. Emergency traffic occurs occasionally and 
can be the result of a sudden and drastic change in the mine environmental condition, or a safety alarm 
sent by one of the miners. This necessitates the routing of emergency traffic through highly reliable and 
minimum-delay paths to prevent disasters. Therefore, our goal is to design a routing system for WSN 
in mines that ensure reliable and timely delivery of emergency data while maximize the lifetime of the 
sensor network to avoid costly redeployment of sensor nodes. We assume the backbone Mesh network 
is capable of routing the emergency traffic with minimum loss and within acceptable time. Thus, in this 
work, our objective is to find the optimal paths for delivering both emergency and regular traffic from 
the source sensor node to a sink mesh node considering their respective constraints. In the following 
discussion by WSN we refer to a cluster of sensor nodes connected to the Mesh backbone.
Figure 3. Two-tier WSN architecture inside mines (Jafarian, 2008)

56
Reliable Communication Network for Emergency Response and Disaster Management
﻿
•	
MDML Routing: The objective of routing emergency data is to carry the information from the 
source to the sink with high reliability and minimum delay. The objective of routing regular pe-
riodic sensing data is to reduce the energy consumption and thus maximize the network lifetime. 
We call our proposed routing Minimum-Delay Maximum-Lifetime (MDML) routing.
We assume that sensor nodes are aware of their geographic locations. Two sensor nodes are called 
neighbors if they can directly communicate with each other; hence they are one hop away from each other. 
All sensor nodes are stationary, and randomly deployed. We assume that the energy consumed while there 
is no communication is negligible. Sensor nodes are assumed to be equipped with an omni-directional 
antenna. All the nodes on the backbone Mesh network are considered as the sink nodes for our wireless 
sensor network. All the sink nodes are stationary and homogeneous; packets generated at a sensor node 
can be delivered to any sink reachable through the path chosen by MDML routing. Srinivasan, Ndoh, 
and Kaluri proposed using 802.11 for communication between sensor nodes and gateways or sink nodes 
in (Srinivasan, 2005). We follow their proposed MAC for our sensor network.
•	
Routing of Emergency Traffic: Reporting some emergency events, such as lack of oxygen in 
some parts of a mine, are loss and delay-sensitive. Emergency situations arise occasionally; hence 
emergency traffic is more sporadic. Since emergency traffic can compromise on energy efficiency 
to minimize losses and delay, we define separate cost metric for emergency paths.
We propose the use of priority queue to separate emergency and regular traffic in a sensor node. The 
priority queue has a classifier, which checks the type of the incoming packet and sends it to the appropri-
ate queue. A single priority bit in the packet can be set or reset at the traffic source to mark the packet 
for emergency and regular data. The implementation of priority queue doesn’t consume extra energy 
as the high priority queue can be implemented as a single packet buffer and a simple scheduler can be 
implemented that transmit the packet from the high priority queue if the queue is not empty otherwise 
transmit a packet from the low priority queue. Since the emergency traffic is loss and delay constrained, 
we assign it high priority. As the emergency traffic is more sporadic and its volume is small, assigning 
it the highest priority is not expected to cause starvation or long delay for the regular traffic. When a 
sensor node transmits an emergency packet, it waits to receive the ACK from the recipient node. If no 
ACK is received, the sender assumes its next hop neighbor is malfunctioning and decides to broadcast 
the emergency packet to all its neighbors in order to deliver the emergency packet as quickly as possible. 
This causes extra traffic in the network but prevents loss of emergency packets.
The main objective for the delivery of emergency traffic is to find a highly reliable path that incurs 
minimum delay. Reliability can be increased by using redundant paths, lowering link losses, and avoiding 
black holes caused by dead nodes. Path redundancy is often achieved in WSN by the fact that multiple 
sensor nodes experience the same sensed situation and generate multiple streams of traffic. Paths with 
high retransmission counts can be avoided to mitigate the effect of losses. Sensor nodes randomly run 
out of battery power creating black holes in the path. It can be avoided by estimating path survivability 
through the remaining lifetime of all the sensor nodes along the path. Due to high error-rate in under-
ground mines, retransmissions also increase path delay. Since emergency traffic is generated rarely in 
the network and it has the highest priority in a sensor node’s queue, we can safely assume it experiences 
negligible queuing delay.

57
Reliable Communication Network for Emergency Response and Disaster Management
﻿
Considering above factors, we propose following path cost function for choosing emergency paths:
Pathcost
f hopcount linkquality residualenergy
= (
)
,
,
	
(1)
Since queuing delay is negligible, hop count is a good measure of delay in the network. We also con-
sider link quality to choose a more reliable link with low error rate and low probability of re-transmission, 
which also contributes to reducing the delay. We suggest using the Expected Transmission Count (ETX) 
as a measure for the link-quality. ETX predicts the number of transmissions (including retransmissions) 
on each link. In the absence of retransmissions it is equivalent to hop count, thus it also becomes a suit-
able metric to calculate the path delay. The third parameter is a function of the residual energy of the 
nodes along the emergency path, which is a measure of path survivability. Residual energy of a node 
can be used to compute its remaining lifetime.
We measure path survivability by computing the minimum lifetime of a node along the path. The 
expected lifetime E (T) of a node as a function of its residual energy Er can be computed using the for-
mula proposed in (Zhu, 2003) as follows:
E T
E
e
e
r
i
s
id
r
i id
t
( ) =
−
(
)
+
λ
λ
λ
0
0
	
(2)
Where λ is traffic rate in bps for both self-generating (λs) and outgoing (λi) traffic, and eid0 is energy 
consumed per bit with respect to reference distance d0.
We define f (Er) such that:
f E
if E T
if E T
r
(
) =
( ) ≥
∞
( ) <




1 
 
τ
τ 	
(3)
Where  τ  is the routing update period. Considering the above measures, we can re-write Eq. (1) in 
terms of the sum of link costs as follows:
pathcost
ETX
f E
p Emergency
l
l
r
−
=
(
)
(
)
∑

*
	
(4)
Where ETXl = ETXij is the ETX value of the link between nodes i and j, and Er is the residual energy 
of node i. In fact, the algorithm selects the least ETX cost path among all survivable paths for emergency 
traffic, which ensures high reliability and low delay in delivering emergency traffic.
•	
Routing of Regular Traffic: The sensor network is mostly busy with monitoring and reporting 
non-emergency events, which cause periodic generation of regular traffic. Thus delivering regular 
traffic is the major consumer of energy of the nodes. Therefore, the primary goal of routing for 
regular traffic is to select energy-efficient paths that can maximize the network lifetime. The harsh 

58
Reliable Communication Network for Emergency Response and Disaster Management
﻿
terrain and narrow passages in underground mines make redeployment of sensor nodes extremely 
difficult, which necessitates the network to survive for maximal time. Since emergency path selec-
tion can compromise on network lifetime, we define separate metric for regular traffic that may 
choose a different path.
Our goal is to maximize the overall lifetime of the network, which is equivalent to maximizing the 
time until the first loss of coverage. In fact, we aim to increase the lifetime of each node in order to 
increase the network lifetime.
We use the cost function used in reference (Chang, 2004), with a little modification to find the optimal 
path for regular traffic. Since we assume all sensor nodes start with equal initial energy, we excluded the 
initial energy and used absolute residual energy. Therefore our link cost function for regular traffic is:
linkcost
e
e
ij
Regular
ij
t
i
ij
r
j
−
=
+
.
.
•
• 	
(5)
Where linkcostij
Rehular
−
 is the cost of link (i, j) for transmitting regular traffic from node i to node j, 
eij
t  and eij
r  are the energy consumption for unit data transmission over the link, and Ei and E j are the 
residual energy of nodes i and j.
•	
MDML Routing Algorithm: The MDML routing employs Bellman-Ford shortest path algo-
rithm and the two link costs defined in Eqs. (4) and (5), to find the least cost paths from each sen-
sor node to the sink S. Each sensor node maintains a simple routing table to keep two next hops, 
one for each type of the traffic (emergency, and regular); and the cost to reach the destination. A 
sink (mesh node) periodically broadcasts Sink Announcement Packet (SAP) after every τ second. 
Since propagation of routing updates consume energy, our goal is to increase the route refresh pe-
riod. Every SAP contains the residual energy of the transmitter node, as well as the accumulated 
path cost for both emergency and regular traffic. The residual energy of the sink is a constant. We 
can include either timestamp or sequence number in a SAP, which is used both to refresh the rout-
ing table entries and to avoid the loop in SAP flooding. When a sensor node receives the SAP, it 
extracts the path cost and energy metrics, calculates the new path costs for both emergency and 
regular traffic based on the new information, compares the new cost with the one in the routing 
table, and decides whether to update its routing table or discard the SAP. The sensor node only up-
dates its routing table if it receives the most recent SAP, or it receives a SAP with lower cost path 
for either emergency or regular traffic. After updating its routing table, it broadcasts the received 
SAP to advertise the newly computed route to its neighbors. Otherwise it stops the SAP flooding 
and drops it.
•	
Simulation Setup: We evaluated the performance of MDML algorithm through simulation using 
J-Sim4, which provides complete protocol stack and features for simulating WSN. We simulated a 
single cluster of 40 sensor nodes randomly distributed in a 100x100 square meter area and a single 
sink located at the edge of the network. We generated six random topologies. Sensor nodes are 
equipped with omni-directional antennas with radio transmission range of 30 meters. Each sensor 
node starts with initial energy of 20 Joules. We assume negligible energy consumption when a 
sensor node is not communicating. We used J-Sim’s default power consumption model of 0.660 
J/s for transmission and 0.395 J/s for reception.

59
Reliable Communication Network for Emergency Response and Disaster Management
﻿
In J-Sim events are generated by target nodes. We created a mobile target node to generate regular 
packets every 2 seconds. It moves at the constant speed of 30 m/s in a random direction. We simulated a 
separate mobile target node to generate emergency packets that is about 5% of the total regular packets. 
It moves in a random direction at the constant speed of 10 m/s. All the sensor nodes and the sink are 
stationary. All the sensor nodes within radius of 20 meters of the target node receive the event packets.
We implemented a two-level priority queue with high priority assigned to emergency packets. The 
priority queue size is 40 packets. We simulated free space channel model for all wireless links and not 
the zonal model for underground mines (Ndoh, 2004). We used IEEE 802.11 MAC protocol in power 
saving mode (PSM) at 2 Mbps throughput. The simulation time, T, is 2000 seconds. We simulated six 
different topologies to determine the performance trend independent of the network topologies. When 
the performance significantly differs, we show results of different topologies.
•	
Performance Results: Here we discuss the performance of the MDML routing showing both the 
overall performance and the performance of emergency traffic. Our main performance indicators 
are network lifetime for overall performance, and loss ratio and end-to-end delay for the perfor-
mance of emergency traffic. We compared the results of MDML with our implementation of the 
maximum lifetime routing in (Chang, 2004) which we refer to as non-MDML routing.
We studied the impact of routing refresh (SAP) period τ on the network lifetime, protocol overhead, 
and quality of routes. Figure 4 shows that the protocol overhead decreases as we increase τ for different 
topologies. Same trend is observed for all the topologies. This is expected since sink broadcasts routing 
updates (SAP) less frequently by increasing τ, which decreases the total number of SAP advertised by 
each sensor node. After a sharp decrease the overhead saturates for values of τ higher than 400 seconds.
Figure 5 shows the impact of τ on the network lifetime. The network lifetime slightly improves by 
increasing τ, but then it slightly decreases for values of τ higher than 400 seconds. Sharp decrease in 
protocol overhead for smaller values of τ (as shown in Figure 4) slightly increases the network lifetime 
as it drains less energy of the sensor nodes. When protocol overhead saturates for large values of τ its 
Figure 4. Impact of τ on protocol overhead for different topologies (Jafarian, 2008)

60
Reliable Communication Network for Emergency Response and Disaster Management
﻿
impact on energy consumption becomes less pronounced. But, due to long cycle of route update some 
routes remain overused and the nodes on those routes run out of energy earlier causing network lifetime 
to decrease.
Finally, we studied the network lifetime performance of MDML vis-à-vis non-MDML, as shown 
in Figure 6. We simulated Maximum Lifetime Routing proposed as a Non-MDML routing. The Non-
MDML approach uses FIFO queue instead of the priority queue, and it does not differentiate between 
emergency and regular packets that is it uses the same routes for both types of traffic. The Non-MDML 
uses the same metric for both regular and emergency traffic that is the one we used for regular traffic 
in the MDML protocol.
The objective of MDML routing is to ensure reliable delivery of emergency traffic, which is translated 
into low loss and low delay performance indicators. First, we present the packet loss ratio for all six 
topologies in Figure 6. We used four regular stationary targets to generate regular traffic and set buffer 
size equal to 20 packets for priority queue. The route update time, τ is set to 400 seconds. The simula-
Figure 5. Impact of τ on network lifetime for different topologies (Jafarian, 2008)
Figure 6. Network lifetime vs. τ for MDML and Non-MDML (Jafarian, 2008)

61
Reliable Communication Network for Emergency Response and Disaster Management
﻿
tion ends when the first node runs out of energy. Simulation results for all six topologies confirmed that 
emergency traffic experiences no packet loss. This is mainly due to the high priority given to emergency 
traffic in the priority queue. The packet loss ratio for regular traffic varies from 1.5% to 4.9% in different 
topologies, as shown in Figure 7.
We evaluated the average end-to-end delay performance for regular and emergency traffic under 
both MDML and Non-MDML routing using same topologies and target generation rate. We can derive 
following two conclusions from the graphs shown in Figure 8. First, MDML improves the delay for 
emergency traffic, while the average delay for emergency traffic is sometimes higher than the average 
delay for regular traffic in case of Non-MDML routing. This happens because emergency traffic shares 
the same FIFO queue with regular traffic and higher rate of regular traffic causes situations where 
emergency packets lie behind regular packets in the queues. Second, MDML shows consistently lower 
delay for emergency traffic across all six topologies.
Figure 7. Packet loss ratio of regular traffic (Jafarian, 2008)
Figure 8. Ave. delay per packet, for MDML and Non-MDML (Jafarian, 2008)

62
Reliable Communication Network for Emergency Response and Disaster Management
﻿
POST-DISASTER MINE COMMUNICATIONS AND TRACKING SYSTEMS
Post disaster rescue work indicated a need for a reliable means of communications and quickly locating 
trapped miners in the underground mines. Typical communication systems infrastructures installed in 
underground mines are very susceptible to failures in the events of disasters. MINER Act 2006 promi-
nently identified the need for wireless post-disaster communications and electronic tracking systems. 
The Act requires each coal mine to submit an emergency response plan, which includes post-disaster 
communications and tracking, to the MSHA within three years of the enactment date. Post-disaster 
investigations indicated that reliable post-disaster communications may have saved many lives through 
improved escape and rescue procedures.
Three types of communications technologies have demonstrated potential for meeting the require-
ments envisioned by the MINER Act: enhanced leaky-feeder, wireless-mesh, and medium-frequency 
(MF) systems. Each system possesses unique advantages and disadvantages, and because underground 
coal mines vary considerably in size and layout, more than one type of system may be needed to meet 
the communications requirements for a given mine. The operation and application of each system are 
discussed hereinafter (Novak, 2010).
Enhanced Leaky-Feeder System
The leaky-feeder system has a long history of success in tunnel applications (Martin, 1984), and it has 
been used in some coal mines for routine communications since the 1980s. Its feeder cable acts as both 
a transmission link and a distributed antenna. The coaxial-type cable is designed to radiate, or leak, a 
portion of its transmission signal through holes in its surrounding metallic shield, as shown in Figure 9. 
Therefore, radio signals are permitted to enter and exit the cable, providing two-way communications 
along its entire length. The cable’s center conductor conveniently supplies a dc voltage to power the 
system’s in-line amplifiers.
While most existing leaky-feeder systems operate in the very high frequency band (30–300 MHz), 
the enhanced system operates around 450 MHz, within the UHF band (300–3000 MHz). This higher 
frequency allows wider bandwidths that, in turn, permit the transmission of more data at higher rates. In 
addition, UHF signals demonstrate better free-space propagation characteristics (through crosscuts and 
around the corners of coal pillars) (Emslie, 1975). As a tradeoff, the higher frequency requires a more 
expensive feeder cable and causes greater line attenuation and coupling losses.
•	
Basic Operation: UHF signals propagate very poorly in coal or its surrounding strata; thus, sig-
nal transmission is confined to mine openings (entries and crosscuts). Therefore, a leaky-feeder 
cable must be strung throughout a mine wherever access to communications is required. Figure 9 
shows the basic operation of the system. The head end of the feeder cable connects to a base sta-
tion located at a control center on the surface. A nonradiating coaxial cable typically connects the 
base station to the mine’s leaky feeder, which is installed along a mine entry, as shown in Figure 
9. The base station controls the flow of communications within the mine. Figure 9 shows Miner-1 
transmitting from a radio handset. An analog format with frequency modulation is presently used 
for voice communications, with separate transmit and receive frequencies to allow duplex com-

63
Reliable Communication Network for Emergency Response and Disaster Management
﻿
munications. For example, the signal from Miner-1’s handset is transmitted at 450 MHz. At this 
frequency, a signal is only amplified in the upstream direction toward the cable’s head end. A 
frequency-translation repeater, within the base station, receives the 450-MHz signal and retrans-
mits it back onto the leaky feeder at 475 MHz. In-line amplifiers along the feeder amplify this 
retransmitted signal only in a downstream direction away from the head end. Miner-2, along with 
any other miner on the same channel within proximity of the leaky feeder, will receive Miner-1’s 
transmission.
Sixteen channels are available on the enhanced leaky-feeder system. For routine communications, 
separate channels can be used for individual job functions, such as by maintenance and construction 
crews. Using separate channels reduces communications traffic and its associated bottlenecks. In the 
event of an emergency, however, the system is capable of paging all channels simultaneously.
•	
Survivability: The most important function of a mine communications system is to provide post-
disaster communications between mine workers and surface personnel. Therefore, a system’s sur-
vivability after a catastrophic event, such as an explosion, fire, major roof fall, and even water 
inundation, is critical. Any of these events can severely damage communications infrastructure; 
therefore, system redundancy and component hardening are necessary for attaining survivability.
The size and layout of an underground mine can vary considerably. A significant percentage of work-
ers are clustered in the working sections where coal is extracted, while others are scattered throughout 
Figure 9. Basic operation of the enhanced leaky-feeder system

64
Reliable Communication Network for Emergency Response and Disaster Management
﻿
the mine, performing safety examinations, construction, maintenance, and supply transportation. Thus, 
each mine must perform its own risk assessment to establish a design and layout to maximize coverage 
and survivability of its communications system if a catastrophic event occurs.
Component hardening can certainly improve the chances of a communications system surviving a 
major event. Nevertheless, it may not be practical to design components to withstand the destructive 
forces associated with a catastrophic event for all cases and locations in a mine. Redundant communica-
tions paths allow for a backup path to operate in the event the primary path fails. The key is to physically 
isolate the redundant path so that a catastrophic event will not damage or destroy both paths.
There are always portions of a mine where surface access cannot be utilized. In these situations, an 
independent redundant path, although not as effective, can be established in a parallel entry.
•	
Tracking System: The MINER Act also requires that each mine’s emergency response plan in-
clude a system that allows above-ground personnel to determine the current or immediately pre-
accident location of all underground personnel. The enhanced leaky-feeder system is incapable 
of providing this function alone. Instead, separate tracking hardware must be installed. RFID is a 
common tracking technique that can be employed for this application (Bhat, 2013; Mishra, 2014).
An RFID tracking system utilizes electronic readers and tags. Readers are typically installed at station-
ary locations throughout the mine, and each reader is encoded with a specific location identifier. A tag is 
usually a small transmitter, or transceiver, attached to a miner’s hard hat. Each tag transmits a unique code 
that identifies the miner wearing the tag. With some systems, a reader transmits an interrogation signal 
to request a response from any tag within its range. If a tag receives an interrogation signal, it transmits 
its identification code to the reader. With other systems, a tag intermittently transmits its information 
on a continual basis. In either case, the reader then transmits its location, along with the miner’s iden-
tification, to the surface control center via a leaky-feeder cable, twisted-pair cable, fiber-optic cable, or 
wireless relaying. A video monitor within the control center can then display the location of the miner 
on a mine map. This type of tracking is referred to as zone-based RFID because the miner’s recorded 
location is within a zone defined by the reader’s range and spacing. Thus, the resolution of the system 
depends on the number of readers for a given area. Some systems utilize a technique, received signal 
strength indicator (RSSI), to further improve resolution. If a miner is within the range of two adjacent 
tags, the reader compares the signal strength from each tag and estimates the miner’s location between 
the two points. By utilizing the changing signal strengths of the two tags, the system can also determine 
the miner’s direction of travel. However, the accuracy of such systems can be affected by various factors, 
such as coal-seam undulations and equipment obstructions.
A relatively new approach, reverse RFID, is being developed as an alternative. With this technique, 
the locations of the readers and tags are reversed, as implied by its name. Tags are installed at stationary 
locations throughout the mine, while each miner wears a reader on his/her belt. The tags are designed 
to periodically transmit their location codes. When a reader receives this information, it retransmits the 
tag location and the miner’s identification to the leaky feeder, which, in turn, transmits the information 
to the surface control center for processing.
A battery-powered tag, with an estimated ten-year life, is less expensive than a reader. Therefore, 
system resolution can be increased in a more cost-effective manner. Moreover, the system uses RSSI to 
further improve resolution.

65
Reliable Communication Network for Emergency Response and Disaster Management
﻿
Wireless-Mesh System
Wireless-mesh systems utilize discrete nodes to form a network for relaying communications signals, 
in a node-to-node fashion, throughout the mine or to the surface. Several types of node-based systems 
exist, including LAN and Wi-Fi. The type of system developed by the National Institute for Occupational 
Safety and Health (NIOSH) is referred to as an ad hoc partial-mesh system.
The terms partial mesh define a system in which any node can communicate with any other node 
within its range, as compared with a full-mesh system where all nodes are able to communicate with 
each other. Since a full-mesh system is impractical in mining applications, the term partial is usually 
dropped, and the system is simply referred to as a wireless-mesh system. Unlike the leaky-feeder sys-
tem, a digital format is used, and signals are not routed through a central base station. Furthermore, 
the system allows direct person-to-person communications. A simplified mesh arrangement is shown 
in Figure 10, with the nodes depicted as gray dots. Each node basically consists of a router, transceiver, 
antenna, and battery backup.
•	
Basic Operation: The NIOSH-developed wireless-mesh system operates within the UHF band at 
900 MHz. Research shows 900 MHz to be an optimum frequency for signal propagation in coal 
mines (Emslie, 1975), particularly around pillars. Straight-line communication distances can ex-
Figure 10. Wireless-mesh system

66
Reliable Communication Network for Emergency Response and Disaster Management
﻿
tend to 2500 ft through air, but a node spacing of 1000 ft may be more realistic to provide coverage 
overlap. The system detects when a radio handset is within the range of a node and automatically 
connects the radio to the network. Thus, the handsets of Miners-1 and 2 are connected to the net-
work, as shown in Figure 10, by access nodes 1 and 6, respectively. Figure 10 shows that multiple 
paths are available for transmitting the signal between the sender and the receiver, such as 1-2-4-
6 and 1-3-5-6, with each path requiring four hops (number of intermediate devices between the 
sender and the receiver). Prior to establishing communications, microprocessors within the nodes 
work in concert to determine the optimum path, via the backhaul nodes, between the sender and 
the receiver. A handset can also function as a node for extending coverage temporarily. It should 
be noted that each hop introduces a small time delay along the communications path; however, 
even with extremely large mines, this should not be an issue.
The NIOSH-based wireless-mesh system uses a modified Zigbee protocol to allow compressed voice 
communications, which are not supported by a true Zigbee protocol. The advantages of this approach 
include the following: 1) Ad hoc mesh capabilities maximize flexibility for extending and/or repairing 
networks; 2) low-bit-rate voice communications can extend the range between nodes and support future 
interoperability with low-bit-rate systems, such as through-the-earth and MF systems; and 3) an operat-
ing frequency of 900 MHz has excellent in-mine propagation characteristics.
•	
Survivability: Figure 10 shows a variety of communications paths between Miners-1 and 2. If a 
given node fails along an established communications route, the system reconfigures its path to 
circumvent the failed node and maintain uninterrupted communications. With sufficient coverage 
overlap between nodes, the mesh arrangement exhibits an inherent redundancy, which enhances 
reliability by helping to ensure that the system will operate when one or more of its components 
fail. A unique feature of the wireless-mesh system is its ability to connect with a leaky-feeder sys-
tem through a bridge node, thus permitting the formulation of a hybrid communications system.
•	
Tracking System: A significant advantage of the wireless-mesh system is its capability of func-
tioning as a tracking system. This tracking capability is integrated into the communications sys-
tem such that the nodes act as readers and the radio handsets act as tags. The system functions as 
the previously described RFID system. Similar to an RFID tag, each radio is assigned a unique 
identification code that is intermittently transmitted without the user’s need to key the handset. 
The system also uses RSSI to help improve tracking accuracy.
MF System
The MF system operates at 470 kHz, which is in the MF range of 300–3000 kHz. Unlike the leaky-feeder 
and wireless-mesh systems, the MF system is not intended for routine mine communications. Its primary 
role, instead, is to provide an alternative communications backup in the event of an emergency. Because 
of its low operating frequency and power limits, this system is capable of only localized propagation 
through air; however, more importantly, its signal couples to any nearby metallic structures and cables 
(Mishra, 2014). This parasitic coupling can result in communication distances in excess of 2 mi.
•	
Basic Operation: The MF system consists of a handheld microphone attached to a single-channel 
transceiver that is connected to a ferrite loop antenna. The transceiver modulates voice communi-

67
Reliable Communication Network for Emergency Response and Disaster Management
﻿
cations onto a 470-kHz carrier signal. Because of the significant magnetic component at this fre-
quency, the radiated signal couples to all conductive materials in the vicinity of its antenna, such 
as pre-existing phone lines, metallic lifelines, power cables, water pipes, and conveyor structures. 
Depending on the type of conductor, a signal can travel a few miles and still maintain enough 
strength to be picked up by another MF transceiver. The conductive medium acts as a distributed 
antenna along its entire length, similar to a leaky feeder.
•	
Survivability: Post-disaster investigations have shown that large-diameter power conductors of-
ten survive, and maintain their continuity, after a catastrophic event. Thus, MF systems could play 
an invaluable role in post-disaster escape and rescue procedures. In addition, redundant circuits of 
inexpensive twisted-pair conductors could be installed in a fashion similar to that of leaky feeders.
•	
Tracking Systems: The MF system is designed to be an emergency voice communications sys-
tem, and it has no tracking capabilities. In addition, since the present MF system is an analog 
system, it is incapable of being used for transmitting tracking data to the surface. However, as 
mentioned earlier, a digital system with this capability should be available in the near future.
OPTIMIZED BACKBONE NETWORKS FOR UNDERGROUND MINES
The backbone network is the main transmission line through which the information travels back and forth 
from the surface of the mine to different locations and branches all through the mine. These networks 
are typically connected to other secondary networks through special gateways or similar devices. The 
backbone network can be any kind of transmission line or the combination of a few selections such as 
fiber networks, coaxial transmission lines, Radiating Cable Network, etc.
The Radiating Cable Networks (RCN) is considered to be the most common type of backbone networks 
in underground mines. It is the mine’s main transmission line through which all the communication RF 
traffic travel between the surface and different areas in the mine. The RCN also acts as long piece of 
antenna that enables homogeneous RF coverage in all the areas where the RCN is installed in the mine. 
The RCN is also used as the power grid to power up all the active devices in the backbone network. The 
amplifiers, repeaters, wireless nodes and gateways are powered directly from the RCN. This communi-
cation network and power grid is required to be very robust to resist the harsh environmental conditions 
in the mine. Mine size is very dynamic as it grows constantly with the progress of excavations and the 
removal of the ore from the ground. Therefore, the RCN is required to grow with the mine itself. The 
mine’s backbone network is required to be very scalable and flexible to accommodate the growth and 
dynamic expansion of the mine layout. The flexibility and scalability requirement brings about an im-
portant challenge in the design of such networks in the mines. In this section, we are presenting new 
approaches and algorithms to optimize (Hassan, 2016) the operation of the RCN in the mines and to 
increase scalability and reliability.
System Scalability and Stability Problems
The environments of the mines are dynamic, mines expand on a daily basis as long as the ore is taken 
out. The backbone networks in mines are required to be adaptive and scalable to the mine’s expansion. 
Therefore, the daily expansions in these networks as more cables and branches are added to the systems 
require automatic and intelligent methods for loss compensations and expansions. Equalization circuits 

68
Reliable Communication Network for Emergency Response and Disaster Management
﻿
have been introduced to automatically compensate for the changes in the networks, such as the variations 
in the levels of RF signals. The quality of the radio communications may vary with the level variations 
in the signals traveling through the networks in the mine. In the case of RCN, variations in signal level 
can be caused by temperature variations, which change the longitudinal loss characteristics of the cable. 
The level variations can also be caused by external noise generated by machinery in the mines. Many 
equalization algorithms and schemes for the Automatic Gain and Slope Control (AGC/ASC) systems 
have been developed to overcome the problems of level variations and slope corrections in the backbone 
networks of the mines; however, these approaches have not offered fully reliable system performance. 
The most common approach in deploying AGC/ASC is by utilizing reference RF carriers normally 
referred to as “pilots.” These reference pilots propagate through the entire system and are used by each 
amplifier as a measuring tool to correct the gain and slope of the amplifier.
One of the major scalability problems in the existing systems is due to the stability of the AGC cir-
cuits. Most of the systems utilize AGC/ASC circuits based on closed loop gain topology. The AGC loop 
depicted in Figure 11 consists of a Variable Gain Amplifier (VGA), a peak detector, and a loop filter. 
The AGC loop is generally a nonlinear system, having a gain acquisition settling time that is dependent 
on the input signal level.
In general, the time to adjust the gain in response to an input amplitude change should remain con-
stant, independent of the input amplitude level and, hence, the gain setting of the amplifier. Achieving a 
constant gain settling time permits the AGC loop’s bandwidth to be maximized for fast signal acquisition 
while maintaining stability for all operating conditions. In actual practice, the AGC loop time constant 
of each amplifier differs, due to the tolerances in component values. Therefore, overshoot is evident in 
cascaded amplifier systems. The magnitude of the overshoots increases with the number of amplifiers in 
the system. This implies that the stability of the cascade decreases as the number of AGC/ASC amplifiers 
used increases. As a result, signal levels in the cascade exhibit random fluctuations. Transients that are 
to some degree repetitive cause periodic variations in levels that affect the stability of the entire system.
Another problem in most of the current RCNs is the misleading reference pilot level. From the sys-
tem point of view, reliance on the reference pilots by the equalization circuits creates major problems, 
especially for multi-branched large leaky cable systems. In these types of systems, multiple reference 
pilot generators must be installed at the system head-end and at the end of each branch in the system, 
as shown in Figure 12. At the points of the system branching where the pilot carriers from each branch 
Figure 11. Closed loop automatic gain control circuit

69
Reliable Communication Network for Emergency Response and Disaster Management
﻿
superimpose, the accuracy of detecting the reference pilots are affected by the superimposition of multiple 
pilots. This, of course, affects the operations of the equalization circuits in the subsequent amplifiers and 
it results in unstable system operations.
The signal level varies as it travels through the system. The variations in signal level can be caused 
by temperature variations or by external noise generated by mining machinery. Therefore it is important 
to employ equalization mechanisms to equalize the levels within the system and to ensure adequate 
system performance. Many equalization techniques have been developed to overcome the problems of 
level variations and slope corrections in the leaky feeder systems; however, these approaches have not 
yielded fully reliable and stable system performance. In general, the system equalization is achieved via 
the reliance on closed-loop control circuits to equalize the system gain. These approaches were associ-
ated with stability and level variation problems. Overshoot is evident in cascaded amplifier systems. 
The overshoot magnitude increases with the number of amplifiers in the system. This implies that the 
stability of the cascade decreases as the number of amplifiers in use increases.
Within the context of the Self-Organized Networks (SON), we are proposing optimized algorithms 
to provide scalable and reliable system operation for the RCN in the underground mines. Utilizing the 
proposed algorithm called, “Prediction-based Adaptive Equalization Algorithm (PAEA)”, the network 
can be self-configured to an optimized stability and scalable performance.
Prediction-Based Adaptive Equalization Algorithm (PAEA)
Within the overall scheme of the SON, an intelligent algorithm is developed to mitigate the problems of 
network stability and scalability in the RCN. The algorithm optimizes the performance of the system in 
two stages. The first stage, called Network Self Recognition (NSR), the network will discover its own 
parameters. Based on this learned knowledge the network will optimize the performance by adjusting 
the network configurations during the second stage of the algorithm which is called Network Self Con-
figuration (NSC).
Figure 12. Multiple references equalizations topology

70
Reliable Communication Network for Emergency Response and Disaster Management
﻿
To achieve higher network stability, the amplifiers in the mine’s RCN will be able to predict the 
losses in the network even before they happen. This prediction is based on some preliminary informa-
tion and parameters determined by the network during the NSR phase. The developed algorithm, called 
“Prediction-based Adaptive Equalization Algorithm (PAEA),” will then apply certain configuration 
parameters to the network during the NSC phase that result in an optimized system stability and maxi-
mized scalability of the network (Farjow, 2012a). The algorithm was applied to a typical RCN in the 
mine as shown in Figure 13. There are four distinct RF bands in the system. These bands are required 
to provide RF propagation paths for voice and data communications. Table 4 lists the four bands of the 
system and their frequency ranges. The upstream and downstream orientations of the system bands are 
shown in Figure 13. This type of RCN is normally known as the Cable Modem Termination System 
(CMTS). These types of networks are capable of providing analogue voice communication and high-
speed digital data Communications.
The algorithm utilizes three reference carriers, also called pilots, which are generated at the system 
Head-End. These pilots can be referred to as Low-Pilot, PL, Midpoint-Pilot, PM, and High-Pilot, PH. 
The frequencies of these pilots are selected to be within the downstream voice and data bands (i.e. m 
=1 and 3). The PL propagates within the downstream voice band. The PM propagates at the lower end 
of the downstream data band and the PH propagates at the upper end of the downstream data band. A 
graphical representation of these reference pilots is shown in Figure 14. The amplitude of these pilots can 
be set at the system head-end to reference power level, PL0, PM0, and PH0, for the Low Pilot, Midpoint 
Pilot and High Pilot, respectively.
Figure 13. RCN frequency bands layout
Table 4. System frequency plan
Band No.
Band Name
Frequency (MHz)
1
Upstream Data
5-42 MHz
2
Downstream Voice
155-158 MHz
3
Upstream Voice
172-175 MHz
4
Downstream Data
220-232 MHz

71
Reliable Communication Network for Emergency Response and Disaster Management
﻿
Network Self Recognition (NSR)
As a first stage and within the phase of NSR, the network collects the necessary information and parameters 
such as system losses in different sections of the RCN. The fact that we have reference pilots traveling 
across the network in only one direction on only a certain frequency that makes it difficult to know the 
channels’ characteristics and losses of the RCN for other frequency bands of the network. Therefore, the 
algorithm needs the intelligence to adaptively model the channel characteristics of the RCN in the other 
frequency bands of the network. Moreover, the System Loss, L, of each section (i.e. between two nodes) 
consists of two components. The first component is called the Cable Longitudinal Loss (CL), which is 
due to the loss of the leaky cable itself. The amount of this component is, in fact, a function of frequency 
and cable length. Frequency response to this type of loss constitutes a negative slope since the frequency 
terms in the high spectrum suffer higher losses than the lower frequency terms. The second component 
of the system loss is called the Insertion Loss (IL). This component is not frequency dependent, and it 
is caused mainly by the insertion loss of miscellaneous active and passive units installed on the system. 
The frequency response of these units is typically flat, where the attenuations are almost the same over 
the entire frequency spectrum. An example of these units is found in cable branch units (power dividers 
or splitters) and cable splice boxes for joining two sections of cables (Farjow, 2012b).
To determine the relative positions between two nodes, it is very important to differentiate between 
these two types of losses and to quantify their values in order to determine the nature of the losses between 
two nodes in the system. The system loss in each cable section, Ln,m, can be calculated by the following:
L
CL
x
f
IL
n m
n m
n
m
n
,
,
,
,
=
(
) +
	
(6)
where,
Ln m
, : The total loss in one section of the cable, n, at frequency band m,
CLn m
, : The longitudinal cable losses in one section. This loss is a function of cable length,xn , and the 
frequency, fm , for each frequency band. (Negative slope loss),
ILn : The total insertion loss of all passive units in section, n, of the system. (Flat repose loss),
Figure 14. Graphical representations of the reference pilots

72
Reliable Communication Network for Emergency Response and Disaster Management
﻿
n∶ The cable section index in the system,
m∶ The band index in the system.
During the NSR phase, the reference pilots, PL, PM, and PH, propagate through the RCN and losses 
occur as a result. As previously mentioned, the losses are of two components, namely, the cable longi-
tudinal loss and the insertion loss of units installed on the system. When these two carriers arrive at the 
first node (i.e. amplifier), the RF detector at the input stage detects (measure) the levels of these carriers. 
For the first amplifier in the system, (i.e. n = 1), the measured levels PL1, PM1, and PH1, will be stored 
in the amplifier’s microcontroller memory.
Thus far, the actual total system loss of the first cable section, n = 1, for the two downstream bands 
(m = 2 and m = 4) can be calculated. The system loss is essentially the difference in the pilots’ levels 
at the head-end and the measured levels of these pilots when they are detected (i.e. measured) at the 
amplifier’s input stage.
The system loss at PL frequency, fPL , is:
L
PL
PL
n
n
,
,
2
0
=
−
	
(7)
and the system loss at PH frequency, fPH , is:
L
PH
PH
n
n
,
.
4
0
=
−
	
(8)
So far, only the total system loss, L, of the first cable section has been measured in the two downstream 
bands of interest. The values of CLn  and ILn  are yet to be determined. Let’s rewrite Eq. (6) to define 
the total system loss for any cable section, n, in downstream bands m = 2 and m = 4.
L
CL
IL
n
n
n
,
,
,
2
2
=
+
	
(9)
L
CL
IL
n
n
n
,
,
.
4
4
=
+
	
(10)
It will be advantageous to define a relationship between the longitudinal losses of leaky cable at the 
downstream frequency bands, m = 2 and m = 4. This relationship helps in defining the loss of PL in 
terms of PH loss or vice versa. We can define the Downstream Cable Loss Ratio, RD , to be the ratio 
between the cable losses at PL frequency (which represent the cable loss at m = 2 and m = 4) to those 
at PH frequency, which represent the cable loss at m = 4:


@

@
,
,
,
R
CableLoss
f
CableLoss
f
CL
CL
D
PL
PH
n
n
=
=
2
4
	
(11)

73
Reliable Communication Network for Emergency Response and Disaster Management
﻿
therefore,
L
R CL
n
D
n
,
, .
2
4
=
	
(12)
In practice, cable loss ratios for different frequencies and types of cables can be obtained from the 
cable manufacturer and are also available in many reference manuals. A sweep test was conducted on 
one type of leaky cable commonly used in underground communication systems. The result of this test 
is shown in Figure 15.
Substituting Eq. (12) into (9) and rearranging the equation will arrive at:

,
,
,
L
R CL
IL
n
D
n
n
2
4
=
+
	
(13)
or,
.
,
,
IL
L
R CL
n
n
D
n
=
−
2
4 	
(14)
Substituting Eq. (14) into (10) and solving for CLn,4  results in:


,
,
,
,
,
,
,
L
CL
L
R CL
CL
R
L
n
n
n
D
n
n
D
n
4
4
2
4
4
2
1
=
+
−
−
(
) +
=
	
(15)
or,
.
,
,
,
CL
L
L
R
n
n
n
D
4
4
2
1
=
−
−
	
(16)
Figure 15. Leaky feeder cable longitudinal loss chart

74
Reliable Communication Network for Emergency Response and Disaster Management
﻿
ILn can be calculated by substituting Eq. (16) into Eq. (10) as follows:
IL
L
CL
n
n
n
=
−
,
, .
4
4 	
(17)
The insertion loss in cable section n,  
 
ILn is the same for all frequency bands. The Longitudinal loss 
CLn,2  of the cable section, n, in band m = 2, can be easily calculated by using the Downstream Cable 
Loss Ratio defined in Eq. (11). Therefore, at the end of the NSR stage, we could obtain the following 
parameters:
•	
System losses for only the band in the downstream direction where reference carriers are available,
•	
Cable sections lengths in the network,
•	
Passive devices losses in the network.
Networks Self Configuration (NSC)
The self-discovered network parameters during the NSR phase are used in this phase to provide system 
gain and slope equalizations. Thus far, both components of the system loss, the leaky cable longitudinal 
loss, CL, and insertion loss, IL, have been determined for the system bands m = 2 and m = 4. Therefore, 
the gains of these bands can be found and adjusted to compensate for the system losses incurred in system 
section, n, previous to the amplifier as follow:
G
L
n m
n m
,
, .
=
	
(18)
Since there are no reference carriers in the upstream directions, the algorithm will use the information 
provided during the NSR phase to model and then predict the required equalization parameters of the 
amplifiers in this direction. Eq. (6) can be used to define the system loss in the upstream bands, bands 
m = 1 and m = 3 respectively:

,
,
,
L
CL
IL
n
n
n
1
1
=
+
	
(19)
L
CL
IL
n
n
n
,
,
.
3
3
=
+
	
(20)
Recall that the insertion loss component,   was already determined during the calculations of the 
downstream system losses.
Let’s define some reference points in the upstream bands as shown in Table 5.
These points are used in calculating the predicted signal losses in these bands. A graphical represen-
tation of these reference points is shown in Figure 16.
Similar to the Downstream Cable Loss Ratio, RD , that defined a relationship between the two down-
stream bands, m = 2 and m = 4, more cable loss ratios are required to define relationships between the 
cable longitudinal loss at m = 2 and m = 1 and between m = 2 and m = 3 as follows:

75
Reliable Communication Network for Emergency Response and Disaster Management
﻿
Let RU 1 be the Cable Loss Radio between the cable losses at fPL  and the cable losses at f1


@

@
.
,
,
R
CableLoss
f
CableLoss
f
CL
CL
U
PL
n
n f
1
1
2
1
=
=
	
(21)
Let RU 2 be the Cable Loss Radio between the cable losses at fPL and the cable losses at f2 as in the 
following:


@

@
.
,
,
R
CableLoss
f
CableLoss
f
CL
CL
U
PL
n
n f
2
2
2
2
=
=
	
(22)
Let RU 3 be the Cable Loss Radio between the cable losses at fPL and the cable losses at f3 as in the 
following:
R
CL
CL
U
n
n f
3
3
3
=
,
,
.	
(23)
Table 5. Upstream Bands reference points-frequencies
Reference Points
Frequency (MHz)
f1
5.00
f2
42.00
f3
172.325
f1 represents the frequency of a reference point at lower end of the m = 1 band.
f2 represents the frequency of a reference point at upper end of the m = 1 band.
f3 represents the frequency of a reference point within the upstream m = 3 band.
Figure 16. Graphical representations for the reference points

76
Reliable Communication Network for Emergency Response and Disaster Management
﻿
We know that, CLn,1  = CLn f, .
2  Substituting for CLn,1  in Eq. (22), we obtain:

.
,
,
,
CL
CL
CL
R
n
n f
n
U
1
2
2
2
=
=
	
(24)
The total system losses in the upstream data band, Ln,1  can be calculated from Eq. (6)
L
CL
R
IL
n
n
U
n
,
,
.
1
2
2
=
+
	
(25)
Similarly, the total system loss in the upstream m = 3 band, Ln,3  can be found as following
L
CL
R
IL
n
n
U
n
,
,
.
3
2
3
=
+
	
(26)
At this point, all the components of the system loss have been determined for all the four bands in the 
system. Eq. (18) can be used to calculate the gains of the upstream amplifiers in the system. Next, the 
algorithm will provide Slope Equalization to the network. The slope control is required only for the data 
bands as these bands have broad bandwidths, 12 MHz for the downstream data band and 37 MHz for the 
upstream data band. The RF response of any cable section has the shape of a negative slope (Tilt). The 
longitudinal loss in the cable at higher frequencies is greater than the loss at lower frequencies. Figure 
17 shows the proposed system equalization block diagram.
To calculate the slope in the downstream data band, the system losses at the frequencies of PM fPM
(
) 
and PH fPH
(
)  need to be determined. The losses at fPH  were calculated in Eq. (8).
The losses at fPM  can be calculated as follows:
L
PM
PM
n PM
n
,
.
=
−
0
	
(27)
The slope in the downstream data band can be calculated as follows:
T
L
L
n
n PM
4
4
=
−
,
,
. 	
(28)
T4  is the slope in the data downstream band, m = 4. Next we need to calculate T1  the slope in the 
upstream data band, m = 1. To calculate this slope, the cable longitudinal losses CLn f, 1  and CLn f, 2  at the 
two reference points, f1 and f2 respectively are required.
From the Cable Loss Ratio equations RU 1  and RU 2 , the cable longitudinal loss at the lower end of 
band m =1 can be calculated as in the following:

77
Reliable Communication Network for Emergency Response and Disaster Management
﻿

.
,
,
CL
CL
R
n f
n
U
1
2
1
=
	
(29)
The cable longitudinal loss at the higher end of band m =1 was calculated in Eq. (25). Therefore, the 
slope, T1 , in the upstream data band can be calculated as follows:
T
CL
CL
n f
n f
1
2
1
=
−
,
, . 	
(30)
Thus far, the algorithm could calculate all the required equalization parameters.
RESEARCH ON UNDERGROUND MINE COMMUNICATIONS AT RYERSON
Ryerson Communications Lab has been conducting various research on underground mine communica-
tions through the funding from different industries as well as Natural Sciences and Engineering Research 
Council (NSERC) of Canada. Some of the research topics shown below:
•	
Developing Green Communication Networks in Underground Mines (NSERC CRD Project).
•	
Green, Hybrid Communication Network for Localization in Underground Mines (NSERC CRD 
Project).
•	
Wireless Sensing and Tracking in Harsh, Low-Light Underground Mines (NSERC CRD Project).
•	
Cross Layer Optimizations of Integrated Networks in Underground Mines (Ph.D. Thesis).
•	
Leaky Feeder System Optimizations in Underground Mines and Tunnels (M.A.Sc. Thesis).
•	
Optimization of Leaky Feeder Slot Spacing for Better Beam Forming in Mines and Tunnels.
Figure 17. System equalization block diagram

78
Reliable Communication Network for Emergency Response and Disaster Management
﻿
•	
Novel Wireless Channels Characterization Model for Underground Mines.
•	
Localization for Mobile Sensor Networks in Mines.
•	
Advanced Mine Monitoring System with Ventilation on Demand.
•	
Design of Wireless Sensor Network for Mine Safety Monitoring.
•	
A Novel Diagnostic System for Adding Reliability to Communication Networks in Underground 
Mines.
•	
Advanced Diagnostic System with Ventilation on Demand for Underground Mines.
•	
Advanced Safety Systems for Underground Mines.
•	
Collaborative Robots for Rescuing Underground Miners.
•	
Search and Rescue Unit for Trapped Miners.
RESEARCH DIRECTIONS
Tracking and monitoring of miners and mining equipment are basic needs in underground mines for 
emergency response and disaster management. A portable wireless system would be the best option for 
these purposes in mines because they offer the best resistance to damage from roofs falls, fires and ex-
plosions. The detecting system of underground mine worker enables in detecting the location of trapped 
mine worker based on the radio wave transmission through rock strata or coal debris. Use of the system 
would help in precisely locating the position of the mine worker trapped in case of roof fall/collapse of 
gallery side. This would help the rescue team or mine management to identify the coal chunk/coal debris 
to be displaced at the right time and right place. This would also help in saving valuable life of men 
working in underground mines. Besides, the system can be carried by miners and they do not require 
pre-existing infrastructure in terms of pre-installed antennas.
WSN can be a reasonable solution for monitoring and tracking in underground mines. Using WSNs, 
the objects can estimate their location by co-operating with nearby objects by sharing the sensor data 
in order to minimize the overall location error. With a moderate up gradation of the processor used in 
the sensor nodes, fast and efficient object tracking can be performed. In addition, it can be enhanced to 
monitor gas and dust concentration inside the mines and stability of underground structures with the 
addition of a few extra sensors. Hence the topic of sensor fusion can also be researched in order to derive 
a one-fit solution for mines. Seamless integration of the wireless solutions with the existing wired sys-
tems present in the mines and efficient sensor deployment schemes in a short period of time in order to 
respond to emergency situation are possible research directions. Wireless underground location systems 
using UWB and Software Defined Radios (SDR) are other promising research topic in order to counter 
the challenges posed by radio propagation in mines.
Moreover, introduction of RFID system in underground mines is a viable and cost-effective system 
for tracking. To overcome day-to-day problem faced by mine management, installation of wireless in-
formation and safety system is a vital need for mining industry. With the help of central processing unit 
at pit top, it will be possible to keep track of miners and machines moving in underground. It will also 
be possible to keep record of time when respective miner is going inside the mine and coming back. 
Implementation of system will also help mine management to keep record of attendance and to identify 
persons who are delaying to start his scheduled duty and/or coming back early. In case of disaster, system 
will help in identifying trapped miner along with their location and numbers, and this will improve safety 
of miners. Further, communication technology in mining is developing fast and various researches are 

79
Reliable Communication Network for Emergency Response and Disaster Management
﻿
continuing throughout the world for development of RFID-based communication and tracking system 
for underground mines.
Future enhancements and interoperability features will further improve post-disaster communication 
system availability in those applications where two or more system types have been incorporated into the 
overall system design. Some mines will be able to meet their communications needs with only one type 
of system, while other mines may require a combination of systems. The leaky-feeder and wireless-mesh 
systems are designed for routine, as well as emergency, communications. Leaky feeder-based communi-
cation system is suitable for establishing data, voice, and video communication in an underground mine. 
The wireless communication range around the leaky feeder cable is around 20–22 m in underground coal 
mine. To enhance the communication range in the required portion of an underground mine, a passive 
amplifier has to be coupled with the leaky feeder cable. The system provides an amplifier for increasing 
the radiation field strength of a radiating leaky cable and enhancing the low level of radiation in the leaky 
cable itself to avoid use of booster for amplifying the signal. With the passive amplifier the wireless 
communication range around the leaky feeder cable has increased up to 50 m. As such, it is anticipated 
that mines will experience benefits, other than safety, from the expanded capabilities of these systems.
The communication networks in underground mines can be a very complicated structure made of a 
number of elements that are required to interact. For comprehensive enhanced performance, the entire 
network needed to be optimized for improved reliability, scalability and efficient power utilization. The 
scalability and reliability challenges in the backbone component of the mine’s network were addressed 
and optimized for improved performance within the context of self-organized networks and reliable com-
munication in the mines. The “Prediction-based Adaptive Equalization Algorithm (PAEA)”, provided 
a new scheme in controlling the gain and the slope in the leaky cable system of underground mines was 
presented. PAEA could enhance the stability and scalability of the backbone networks in the mines. In 
particular the backbone network was optimized within the overall scheme of the Self-Organized Net-
work (SON) in two stages. These are the Network Self Recognition (NSR), where the network could 
discover its own parameters, and Network Self Configuration (NSC), where the network optimized its 
performance by adjusting the network parameters and configurations.
PAEA can be further improved by considering the approach of part-time equalization. Through this 
approach the equalization pilots can be scheduled in part-time bases. Therefore, the carriers of the refer-
ence pilots might not need to be present in the system all the time. Instead, the pilots will be available 
only when needed by the amplifier circuit. This will help to maximize the channel capacity of the system 
and to reduce the power consumption of the amplifiers when the equalization is not needed. Finally, 
with the advent of new technology, time is not far away when underground mines will have mobile com-
munication as common as today’s above ground communications.
CONCLUSION
The recent developments and evolution of different communication technology and network for emer-
gency response and disaster management in underground mines is presented in this chapter. Wireless 
mine communications technologies and associated tracking systems have been described. These systems 
represent dramatic improvements in post disaster communications, as compared with previous mine 
communications systems. Since each of different communication type comes with its own problems, 
it is extremely difficult to come up with a single system that can provide solutions to all of them si-

80
Reliable Communication Network for Emergency Response and Disaster Management
﻿
multaneously. Although many different communication systems for underground mines exist, wireless 
communication draws considerable attention compared to other communication systems.
Wireless communication offers solutions to some of the fundamental challenges of all tethered com-
munication systems such as easy maintenance, higher robustness against failures stemming from physical 
damages, and mobility. Recently, many wireless technologies and standards have been developed and 
employed in underground mines. This rapid development of technologies and standards leads research-
ers to face some challenges such as interoperability and seamless connectivity. Cognitive radio (CR) is 
an emerging technology which observe their environment and react upon the changes in it to achieve 
a designated goal in an intelligent way. The most striking feature of CRs is their ability to adapt to the 
changing environmental conditions. Mine communications require radio devices to work in different 
scenarios such as in-mine operations, ground and disaster communications. Since each of these scenarios 
takes place in different environments, CR can provide a good solution to all of them.
Requirement of most radio applications is the maximum user satisfaction. Power levels of both 
transmitters and receivers are one of the limitations of mine communication systems. For instance, CRs 
may help reduce the power consumption of the transmitter and receiver by intelligently adjusting their 
transmission parameters leading to a longer battery life for both sides without causing any user dissatis-
faction. In short, CR technology seems to be very promising for mine communication systems since it 
offers solutions to the adaptation and interoperability issues which are the fundamental limiting factors. 
Underground mine communication problems might not be resolved by solely looking from communica-
tions point of view. One should consider this problem from the perspective of other disciplines as well.
REFERENCES
Akyildiz, I. F., & Stuntebeck, E. P. (2006). Wireless underground sensor networks: Research challenges. 
Ad Hoc Networks, 4(6), 669–686. doi:10.1016/j.adhoc.2006.04.003
Bai, M., Zhao, X., Hou, Z. G., & Tan, M. (2007, April). A wireless sensor network used in coal mines. 
In 2007 IEEE International Conference on Networking, Sensing and Control (pp. 319-323). IEEE. 
doi:10.1109/ICNSC.2007.372798
Bandyopadhyay, L. K., Chaulya, S. K., & Mishra, P. K. (2010). Wireless communication in underground 
mines: RFID-based sensor networking. Springer Publishing Company. doi:10.1007/978-0-387-98165-9
Bandyopadhyay, L. K., Chaulya, S. K., Mishra, P. K., Choure, A., & Baveja, B. M. (2009). Wireless 
information and safety system for mines. Journal of Scientific and Industrial Research, 68(2), 107–117.
Barkand, T. D., Damiano, N. W., & Shumaker, W. A. (2006, October). Through-the-earth, two-way, mine 
emergency, voice communication systems. In Conference Record of the 2006 IEEE Industry Applications 
Conference Forty-First IAS Annual Meeting (vol. 2, pp. 955-958). IEEE. doi:10.1109/IAS.2006.256640
Bhat, A. S., Raghavendra, B., & Kumar, G. N. (2013). Enhanced passive RFID based disaster manage-
ment for coal miners. International Journal of Future Computer and Communication, 2(5), 476–480. 
doi:10.7763/IJFCC.2013.V2.209

81
Reliable Communication Network for Emergency Response and Disaster Management
﻿
Brnich, M. J., Kowalski-Trakofler, K. M., & Brune, J. (2010). Underground coal mine disasters 1900-
2010: Events, responses, and a look to the future. Extracting the Science: A Century of Mining Research, 
363-373.
Chang, J. H., & Tassiulas, L. (2004). Maximum lifetime routing in wireless sensor networks. IEEE/ACM 
Transactions on Networking, 12(4), 609–619. doi:10.1109/TNET.2004.833122
Chehri, A., Farjow, W., Mouftah, H. T., & Fernando, X. (2011, May). Design of wireless sensor network 
for mine safety monitoring. In 2011 24th Canadian Conference on Electrical and Computer Engineering 
(CCECE), (pp. 1532-1535). IEEE. doi:10.1109/CCECE.2011.6030722
Chehri, A., Fortier, P., & Tardif, P. M. (2009). UWB-based sensor networks for localization in mining 
environments. Ad Hoc Networks, 7(5), 987–1000. doi:10.1016/j.adhoc.2008.08.007
Daoud, M., Farjow, W., & Fernando, X. (2011, May). A novel diagnostic system for adding reliability 
to communication networks in underground mines. In Electrical and Computer Engineering (CCECE), 
2011 24th Canadian Conference on (pp. 1342-1346). IEEE. doi:10.1109/CCECE.2011.6030681
Delogne, P. (1991). EM propagation in tunnels. IEEE Transactions on Antennas and Propagation, 39(3), 
401–406. doi:10.1109/8.76340
Dohare, Y. S., Maity, T., Das, P. S., & Paul, P. S. (2015). Wireless communication and environment 
monitoring in underground coal mines–review. IETE Technical Review, 32(2), 140–150. doi:10.1080/
02564602.2014.995142
Dozolme, P. (2016, August). What are the most common mining accidents? Thousands of miners die 
from mining accidents each year. The Balance. Retrieved October 13, 2016, from https://www.thebal-
ance.com/most-common-accidents-occurring-in-the-mining-industry-2367335
Durkin, J. (1984). Apparent earth conductivity over coal mines as estimated from through-the-earth 
electromagnetic transmission tests. US Department of the Interior, Bureau of Mines.
El-Nasr, M. A., & Shaban, H. (2015). Low-Power and reliable communications for UWB-Based wireless 
monitoring sensor networks in underground mine tunnels. International Journal of Distributed Sensor 
Networks, 2015, 48.
Emslie, A., Lagace, R., & Strong, P. (1975, March). Theory of the propagation of UHF radio waves 
in coal mine tunnels. IEEE Transactions on Antennas and Propagation, 23(2), 192–205. doi:10.1109/
TAP.1975.1141041
Farjow, W. (2012a). Cross layer optimizations of integrated networks in underground mines (Doctoral 
Dissertation). Ryerson University, Canada.
Farjow, W., & Fernando, X. (2012b, September). System and method to control amplifier gain in a 
radiating line communication system. Canadian Patent, serial number 2789768.
Farjow, W., Raahemifar, K., & Fernando, X. (2015, October). Novel wireless channels characterization 
model for underground mines. Applied Mathematical Modelling, 39(19), 5997–6007. doi:10.1016/j.
apm.2015.01.043

82
Reliable Communication Network for Emergency Response and Disaster Management
﻿
Forooshani, A. E., Bashir, S., Michelson, D. G., & Noghanian, S. (2013). A survey of wireless communi-
cations and propagation modeling in underground mines. IEEE Communications Surveys and Tutorials, 
15(4), 1524–1545. doi:10.1109/SURV.2013.031413.00130
Frielos, D. (2007). Xstrata mines RFID’s benefits. RFID Journal.
Ghaddar, M., Nedil, M., Mabrouk, I. B., & Talbi, L. (2016). Multiple-input multiple-output beam-space 
for high-speed wireless communication in underground mine. IET Microwaves, Antennas & Propaga-
tion, 10(1), 8–15.
Grayson, L., Bumbico, A., Cohn, S., Donahue, A., Harvey, J., Kohler, J., & Webb, H. (2006). Improving 
mine safety technology and training: Establishing US global leadership. Mine Safety Technology and 
Training Commission, National Mining Association.
Hassan, N., Farjow, W. F., & Fernando, X. (2016). Optimization of leaky feeder slot spacing for better 
beam forming in mines and tunnels. International Journal of Communications, Network and System 
Sciences, 9(4), 77–89. doi:10.4236/ijcns.2016.94007
Hill, D., & Wait, J. (1982). Theoretical noise and propagation models for through-the-earth communi-
cation. US Bureau of Mines.
Huh, S., Lee, U., Shim, H., Park, J. B., & Noh, J. H. (2011, October). Development of an unmanned coal 
mining robot and a tele-operation system. In 2011 11th International Conference on Control, Automation 
and Systems (ICCAS) (pp. 31-35). IEEE.
Jafarian, M., & Jaseemuddin, M. (2008, May). Routing of emergency data in a wireless sensor net-
work for mines. In 2008 IEEE International Conference on Communications (pp. 2813-2818). IEEE. 
doi:10.1109/ICC.2008.530
Jianguo, Z., Junyao, G., Kejie, L., Wei, L., & Shengjun, B. (2010, July). Embedded control system design 
for coal mine detect and rescue robot. In 3rd IEEE International Conference on Computer Science and 
Information Technology (ICCSIT), 2010 (vol. 6, pp. 64-68). IEEE. doi:10.1109/ICCSIT.2010.5563599
Jong, E. C., Schafrik, S. J., Gilliland, E. S., & Weiss, C. J. (2016, April). A preliminary evaluations of 
a through-the-earth (TTE) communications system at an underground coal mine in eastern Kentucky. 
Mining Engineering, 68(4), 52–57. doi:10.19150/me.6548
Kumar, N., Panchariya, P. C., Srinath, K., & Prasad, P. B. (2013, September). Hybrid mine wide 
communication system for surveillance and safety of the miners in underground coal mines. In 2013 
International Conference on Advanced Electronic Systems (ICAES) (pp. 262-266). IEEE. doi:10.1109/
ICAES.2013.6659405
Large, D., Ball, L., & Farstad, A. (1973). Radio transmission to and from underground coal mines-
theory and measurement. IEEE Transactions on Communications, 21(3), 194–202. doi:10.1109/
TCOM.1973.1091650
Li, C., Song, S. H., Zhang, J., & Letaief, K. B. (2012, April). Maximizing energy efficiency in wireless 
networks with a minimum average throughput requirement. In 2012 IEEE Wireless Communications 
and Networking Conference (WCNC) (pp. 1130-1134). IEEE. doi:10.1109/WCNC.2012.6213945

83
Reliable Communication Network for Emergency Response and Disaster Management
﻿
Li, L. L., Yang, S. F., Wang, L. Y., & Gao, X. M. (2011, March). The greenhouse environment monitoring 
system based on wireless sensor network technology. In Cyber Technology in Automation, Control, and 
Intelligent Systems (CYBER), 2011 IEEE International Conference on (pp. 265-268). IEEE. doi:10.1109/
CYBER.2011.6011806
Liénard, M., & Degauque, P. (2000). Natural wave propagation in mine environments. IEEE Transac-
tions on Antennas and Propagation, 48(9), 1326–1339. doi:10.1109/8.898765
Lin, S. C., Akyildiz, I. F., Wang, P., & Sun, Z. (2015, July). Distributed cross-layer protocol design for 
magnetic induction communication in wireless underground sensor networks. IEEE Transactions on 
Wireless Communications, 14(7), 4006–4019. doi:10.1109/TWC.2015.2415812
Martin, D. J. (1984, May). Leaky-feeder radio communication: A historical review. In 34th IEEE Ve-
hicular Technology Conference (vol. 34, pp. 25-30). IEEE. doi:10.1109/VTC.1984.1623231
Mishra, P. K., Stewart, R. F., Bolic, M., & Yagoub, M. C. (2014). RFID in underground-mining service 
applications. IEEE Pervasive Computing / IEEE Computer Society [and] IEEE Communications Society, 
13(1), 72–79. doi:10.1109/MPRV.2014.14
Misra, P., Kanhere, S., Ostry, D., & Jha, S. (2010, April). Safety assurance and rescue communication 
systems in high-stress environments: A mining case study. IEEE Communications Magazine, 48(4), 
66–73. doi:10.1109/MCOM.2010.5439078
Misra, P., Ostry, D., & Jha, S. (2009). Underground mine communication and tracking systems: A survey. 
Tech. Rep. UNSW-CSE-TR-0910, Univ. New South Wales.
Moridi, M. A., Kawamura, Y., Sharifzadeh, M., Chanda, E. K., Wagner, M., Jang, H., & Okawa, H. 
(2015). Development of underground mine monitoring and communication system integrated ZigBee 
and GIS. International Journal of Mining Science and Technology, 25(5), 811–818. doi:10.1016/j.
ijmst.2015.07.017
Murphy, J. N., & Parkinson, H. E. (1978). Underground mine communications. Proceedings of the IEEE, 
66(1), 26–50. doi:10.1109/PROC.1978.10836
Ndoh, M., & Delisle, G. Y. (2004, September). Underground mines wireless propagation modeling. In 
Vehicular Technology Conference, 2004. VTC2004-Fall. 2004 IEEE 60th (Vol. 5, pp. 3584-3588). IEEE. 
doi:10.1109/VETECF.2004.1404732
Novak, T., Snyder, D. P., & Kohler, J. L. (2010). Postaccident mine communications and tracking sys-
tems. IEEE Transactions on Industry Applications, 46(2), 712–719. doi:10.1109/TIA.2010.2040059
Nutter, R. (2007, September). Underground coal mine communications and tracking status SAGO plus 
one year. In Industry Applications Conference, 2007. 42nd IAS Annual Meeting. Conference Record of 
the 2007 IEEE (pp. 2086-2089). New Orleans, LA: IEEE. doi:10.1109/07IAS.2007.315
Nutter, R. S., & Aldridge, M. D. (1988). Status of mine monitoring and communications. IEEE Transac-
tions on Industry Applications, 24(5), 820–826. doi:10.1109/28.8986

84
Reliable Communication Network for Emergency Response and Disaster Management
﻿
Pfeil, R., Pichler, M., Schuster, S., & Hammer, F. (2015). Robust acoustic positioning for safety ap-
plications in underground mining. IEEE Transactions on Instrumentation and Measurement, 64(11), 
2876–2888. doi:10.1109/TIM.2015.2433631
Pittman, W. E., Church, R. H., & McLendon, J. T. (1985). Through-the-earth electromagnetic trapped 
miner location systems: A review. US Department of Interior, Bureau of Mines.
Savic, V., Larsson, E. G., Ferrer-Coll, J., & Stenumgaard, P. (2016a, March). Kernel methods for accurate 
UWB-based ranging with reduced complexity. IEEE Transactions on Wireless Communications, 15(3), 
1783–1793. doi:10.1109/TWC.2015.2496584
Savic, V., Wymeersch, H., & Larsson, E. G. (2016b, February). Target tracking in confined environ-
ments with uncertain sensor positions. IEEE Transactions on Vehicular Technology, 65(2), 870–882. 
doi:10.1109/TVT.2015.2404132
Schiffbauer, W. H., & Brune, J. F. (2006). Coal mine communications. American Longwall Mag.
Shaban, H. A., & Abou El-Nasr, M. (2015). Near–optimal rake receivers for green UWB radio com-
munications in NLOS underground mine tunnels. Journal of Electromagnetic Waves and Applications, 
29(4), 448–464. doi:10.1080/09205071.2014.998775
Sicignano, D., Tardioli, D., Cabrero, S., & Villarroel, J. L. (2013). Real-time wireless multi-hop protocol in 
underground voice communication. Ad Hoc Networks, 11(4), 1484–1496. doi:10.1016/j.adhoc.2011.01.017
Srinivasan, K., Ndoh, M., & Kaluri, K. (2005, June). Advanced wireless networks for underground mine 
communications. In First International Workshop on Wireless Communications in Underground and 
Confined Areas (IWWCUCA), (pp. 51–54). IEEE.
Srivastava, D., & Ranjan, P. (2011, April). Towards greener & safer mines with wireless sensor net-
works. In 2011 IEEE Green Technologies Conference (IEEE-Green) (pp. 1-6). IEEE. doi:10.1109/
GREEN.2011.5754881
Tan, X., Sun, Z., & Akyildiz, I. F. (2015, August). Wireless underground sensor networks: MI-based 
communication systems for underground applications. IEEE Antennas and Propagation Magazine, 57(4), 
74–87. doi:10.1109/MAP.2015.2453917
Wang, J., Wu, Y., Yen, N., Guo, S., & Cheng, Z. (2016). Big data analytics for emergency communica-
tion networks: A survey. IEEE Communications Surveys and Tutorials, 18(3), 1758–1778. doi:10.1109/
COMST.2016.2540004
Wang, Y., Huang, L., & Yang, W. (2010). A novel real-time coal miner localization and tracking system 
based on self-organized sensor networks. EURASIP Journal on Wireless Communications and Network-
ing, (1): 1.
Xie, H., & Golosinski, T. S. (1999, August). Mining science and technology 1999: Proceedings of the 
‘99 international symposium. Taylor and Francis.
Yarkan, S., & Arslan, H. (2007, October). Statistical wireless channel propagation characteristics in 
underground mines at 900MHz. In MILCOM 2007-IEEE Military Communications Conference (pp. 
1-7). IEEE.

85
Reliable Communication Network for Emergency Response and Disaster Management
﻿
Yarkan, S., Guzelgoz, S., Arslan, H., & Murphy, R. R. (2009). Underground mine communications: A 
survey. IEEE Communications Surveys and Tutorials, 11(3), 125–142. doi:10.1109/SURV.2009.090309
Zhang, Y., Yang, W., Han, D., & Kim, Y. I. (2014). An integrated environment monitoring system for 
underground coal mines: Wireless sensor network subsystem with multi-parameter monitoring. Sensors 
(Basel, Switzerland), 14(7), 13149–13170. doi:10.3390/s140713149 PMID:25051037
Zhou, G., & Chen, Y. (2011a, August). The research of carbon dioxide gas monitoring platform based on 
the wireless sensor networks. In Artificial Intelligence, Management Science and Electronic Commerce 
(AIMSEC), 2011 2nd International Conference on (pp. 7402-7405). IEEE.
Zhou, W. (2011b, August). Design of video surveillance system based on 3G wireless network in 
underground coal mine. In 2011 International Conference on Uncertainty Reasoning and Knowledge 
Engineering (URKE), (vol. 1, pp. 248-250). IEEE. doi:10.1109/URKE.2011.6007809
Zhu, J., & Papavassiliou, S. (2003). On the energy-efficient organization and the lifetime of multi-hop 
sensor networks. IEEE Communications Letters, 7(11), 537–539. doi:10.1109/LCOMM.2003.820097
ENDNOTES
1	
West Virginia Office of Miners’ Health Safety and Training, “Emergency Communications & 
Tracking,” http://www.wvminesafety.org/comtraclibrary.htm
2	
https://www.msha.gov/
3	
http://www.cdc.gov/niosh/index.htm
4	
J-SIM simulator, http://www.j-sim.org/

86
Copyright © 2018, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.
Chapter  3
DOI: 10.4018/978-1-5225-2575-2.ch003
ABSTRACT
As a key enabler for diversified location-based services (LBSs) of pervasive computing, indoor WiFi 
fingerprint localization remains a hot topic for decades. For most of previous research, maintaining a 
stable Radio Frequency (RF) environment constitutes one implicit but basic assumption. However, there is 
little room for such assumption in real-world scenarios, especially for the emergency response. Therefore, 
we propose a novel solution (HED) for rapidly setting up an indoor localization system by harvesting 
from the bursting number of available wireless resources. Via extensive real-world experiments lasting 
for over 6 months, we show the superiority of our HED algorithm in terms of accuracy, complexity and 
stability over two state-of-the-art solutions that are also designed to resist the dynamics, i.e., FreeLoc 
and LCS (Longest Common Subsequences). Moreover, experimental results not only confirm the benefits 
brought by environmental dynamics, but also provide valuable investigations and hand-on experiences 
on the real-world localization system.
INTRODUCTION
Disasters can be classified into two categories, natural and man-made. Examples of the former include 
earthquakes (Suzuki et al., 2007), hurricanes (Subramanian et al., 2011), volcanic eruption (Tan et al., 
2010), etc; while terrorism attacks (Goldman, 2011) fall into the latter.
WiFi Fingerprint Localization 
for Emergency Response:
Harvesting Environmental 
Dynamics for a Rapid Setup
Yu Gu
Hefei University of Technology, China
Min Peng
Hefei University of Technology, China
Fuji Ren
University of Tokushima, Japan
Jie Li
Tsukuba Science City, Japan

87
WiFi Fingerprint Localization for Emergency Response
﻿
In both natural and man-made disasters, emergency response always plays an important role. To this 
end, location constitutes one of the most critical contexts of the emergency response and disaster moni-
toring (Makki et al., 2015). For instance, in various emergency applications such as medicare (Alemdar 
& Ersoy, 2010), and home surveillance (He et al., 2011} demands the location-awareness.
Therefore, in this chapter, we focus on the indoor localization issue in emergency to provide an ac-
curate localization system with fast setups, which is particularly important considering the time urgency 
in disasters.
Indoor localization remains a great challenge due to unique features such as the inoperative GPS, 
irregular signal propagation and environmental dynamics (Harle, 2013). During the last few decades, 
tremendous research efforts have been dedicated to addressing this localization issue. The information 
sources of these indoor localization techniques are diversified and mainly related to hardware devices, 
such as infrared (Lee et al., 2006), ultrasound (Hazas & Hopper, 2006), Bluetooth (Feldmann et al., 
2003), radio-frequency identification (RFID) (Saad & Nakad, 2011) and WLAN (Bunato & Battiti, 2005).
WLAN is the most promising network access solution for the indoor environment. Therefore, nowa-
days WiFi signal literately can be accessed from anywhere at any time, making it a perfect source for the 
continuous indoor localization. Thus WiFi fingerprint localization has gradually become the mainstream 
solution. In general, it consists of two phases: training and serving. In the training phase, it leverages 
existing wireless access points (APs) and uses off-the-shelf equipments to collect signals from different 
APs to form the training database, i.e., the location-related fingerprints. In the serving phase, when it 
receives from a user a query message including unknown fingerprints, it will launch the localization 
algorithm to obtain the matched record within the database and return the corresponding locations to 
the user (Li et al., 2014).
Therefore, a key assumption to the performance is the RF environmental similarity between the 
training phase and serving phase. That assumption is backed up by several landmark APs manually 
deployed in the controlled environment (Sun et al., 2005). To the best of our knowledge, it is an implicit 
but fundamental assumption for most of current solutions. Thus, it is understandable that environmental 
dynamics are treated as a threat for the traditional approaches.
However, there exist strong concerns about whether this assumption holds in reality, especially in 
emergency, since the landmark APs used in the training phase could be sabotaged in disasters. This chap-
ter provides a different angle of view on the indoor localization issue to handle such dilemma. Previous 
approaches may treat the environmental dynamics as a major threat hampering the system efficiency, 
and try to avoid such situation by using self-deployed APs to create a stable RF environment. We argue 
that certain environmental dynamic is not a curse but rather bless. However, before harvesting from the 
bursting number of available wireless resources, in-depth understandings on the dynamics are essentials. 
In this way, we could quickly establish an indoor localization system relying on what we have right now, 
not what we used to have.
To this end, we present an empirical study with extensive real-world experiments to investigate 
the impact of environmental dynamics on the overall localization performance. More specifically, we 
conduct a series of comparative experiments in both short-term (STS) and long-term (LTS) scenarios 
under different AP settings.
•	
AP Setting: What we used to have (Pre-Deployed APs) verse what we have right now (all sur-
rounding APs, All-AP in short hereinafter). For the AP setting, on one hand, we can deploy a 
limited number of APs inside the experimental site, whose layout needs to be optimized under the 

88
WiFi Fingerprint Localization for Emergency Response
﻿
space and LAN access restrictions. On the other hand, we can simply utilize all surrounding APs 
that can be detected inside the site.
•	
Scenario Setting: STS verse LTS. For STS, the time gap between the training and serving phase 
is too small for the RF environment to change significantly, e.g., hours or days. For LTS, the time 
gap between the training and serving phase is large, e.g., months or even years. Due to the time-
consuming and labor-intensive training phase, LTS is more suitable to evaluate the performance 
of a localization scheme in the real-world.
The pre-deployed AP setting is the commonly-used option. However, it suffers from several demerits 
such as high cost (extra APs) and labor-intensity (the AP layout needs to be optimized), compared to 
the All-AP setting. In the meantime, for the All-AP setting, it also has shortcomings like signal variance 
and device diversity (heterogeneous APs) issues.
Via extensive experiments, two key observations have been derived, namely,
•	
Environmental dynamics of LTS are much more serious than STS, mainly due to the coming-and-
going APs.
•	
Compared to pre-deployed APs, the All-AP setting may constitute a better choice in terms of ac-
curacy and cost. Therefore, it is a good option for the emergency response.
With these valuable hand-on experiences, we design HED to explore merits of environmental dy-
namics while combating the accompanying demerits such as AP disorders. To evaluate the proposed 
approach, we implement our algorithm, prototype the localization system and conduct extensive real-
world experiments under different combinations of settings.
By comparing with two state-of-the-art solutions, i.e., FreeLoc and LCS, we show the superiority of 
our HED algorithm in terms of stability, computation complexity and localization accuracy. Moreover, 
experimental results not only confirm the benefits brought by environmental dynamics, but also provide 
valuable investigations and hand-on experiences on the real-world application.
The rest of this chapter is organized as follows. In the next section, we present some preliminary results 
to clarify our motivations. Section 3 introduces the HED as well as its theoretical analysis. In Section 4 
we prototype our design and report the performance evaluation with extensive real-world experiments. 
Section 5 discusses some related work in details. Finally, we summarize the chapter in Section 6.
PRELIMINARIES RESULTS
In this part, we explain the details about our experimental settings of the empirical study and present 
some preliminary results that inspire us to conduct further research.
Experimental Settings
We select two sites in our campus to carry out the experiments, namely,
•	
[Conference Room, CR] Room 205 in our facility. Its floor plan is shown in Figure 1(a). The floor 
size is 7.2 m × 8 m.

89
WiFi Fingerprint Localization for Emergency Response
﻿
•	
[Exhibition Room, ER] Room 206 in our facility. Its floor plan is shown in Figure 1(b). The floor 
size is 10 m × 14 m.
We select 142 and 97 reference points for the CR and ER, respectively (small dots in Figure 1. The 
distance between two adjacent locations in CR and ER is 0.5 m and 1 m, respectively. In CR, we select 
every other 2 reference locations for testing in each round of experiments, while in ER every reference 
location has been used for testing.
At each location, we collect 100 RSSI (Received Signal Strength Indicator) values for both testing 
and training. We use Samsung tablet GT-N5110 as the test device. The Android system is selected due 
to its customization capabilities.
The sampling configuration is listed in Table 1. To investigate the impact of environmental dynamics 
on the performance as time passes by, we conducted three rounds and five rounds of samplings for CR 
and ER, respectively. For CR, the second and three samplings are 2 days and 6 months after the initial 
sampling. For ER, the second to fifth samplings are 3 days, 1 week, 4 weeks and 10 weeks after the 
initial sampling, respectively.
Figure 1. The floor plan of the experimental sites
Table 1. Sampling Configurations
CR
Sample #
Time
ER
Sample #
Time
1
Reference time
1
Reference time
2
2 days later
2
3 days later
3
6 month later
3
1 week later
4
4 weeks later
5
10 weeks later

90
WiFi Fingerprint Localization for Emergency Response
﻿
For CR, we use sample 2 as the testing data to simulate STS while using sample 3 as the testing data 
to simulate LTS. For ER, we also use sample 2 as the testing data to simulate STS while using sample 
5 as the testing data to simulate LTS.
Algorithms Studied
Here we introduce two very recent solutions that are closely related to ours. They are also specifically 
designed to deal with environment dynamics, i.e., FreeLoc and LCS.
•	
FreeLoc: FreeLoc (Yang et al., 2013) is a novel indoor localization method that requires no 
calibration among heterogeneous devices. It can tolerate environmental dynamics such as device 
diversity and signal variances, by utilizing relationship among RSS values from different APs.
•	
LCS: The LCS algorithm (Chen et al., 2014) utilizes the surrounding APs while combating the 
environmental dynamics like coming-and-going APs based the idea of longest common subse-
quences matching.
Result Analysis
We have implemented and tested the FreeLoc and LCS algorithms under different combinations of set-
tings. Since CR and ER exhibit similar phenomena, we use CR as an example and its results have been 
shown in Figure 2.
Figure 2(a) shows the four combinations of different settings for the FreeLoc algorithm. Its legend, 
i.e., STS/LTS 6-AP and STS/LTS All-AP, represents the performance of FreeLoc in STS/LTS with 6 
pre-deployed APs and All-AP, respectively. Figure 2(b) presents the results of the LCS algorithm in a 
similar form. While Figure 2(c) compares FreeLoc and LCS algorithms by selecting the best performance 
achieved under their own specific combination of settings.
For the FreeLoc algorithm, the impact of different AP settings on the performance is consistent in 
both STS and LTS: FreeLoc has a better performance with pre-deployed APs than All-AP. This is because 
FreeLoc depends on the signal stability of APs, and thus it is sensitive to the signal variations. Therefore, 
the pre-deployed APs have certain advantages over the uncontrolled APs from the surroundings.
Figure 2. Experimental Results of FreeLoc and LCS under Different Combinations

91
WiFi Fingerprint Localization for Emergency Response
﻿
On the other hand, the impact of the scenario setting on the performance is inconclusive. With pre-
deployed 6 APs, FreeLoc has very similar performance in both scenarios. This is because the pre-deployed 
6 APs create a stable signal environment in both scenarios, leading to the similar performance. However, 
with All-AP, FreeLoc performs better in STS than LTS. This is because a large number of uncontrolled 
APs naturally leads to an unstable signal environment, resulting in a degenerated performance. Note that 
we have detected over 70 APs in total during the experiments.
For the LCS algorithm, the most interesting investigation is the performance improvement (20 cm) 
of All-AP (1.98 m) over 6-AP (2.18 m) in STS, as shown in Figure 2(b). The phenomenon implies that it 
may be possible to rapidly establish an efficient indoor localization system using all the surrounding APs 
in STS such as emergency/temporal applications. We also notice that LCS has very stable performance 
under different combinations of settings.
Figure 2(c) presents the best performance of two algorithms under their each specific combination 
of settings. It is very interesting that though the combinations of the two algorithms are totally different, 
i.e., FreeLoc in LTS with 6 APs and LCS in STS with All-AP, the performance is quite close. The phe-
nomenon suggests that though the stability of different algorithms may differ significantly, the boundary 
of their performance is very close and difficult to be breached.
In summary, the preliminary results reveal the following investigations that inspire us to push the 
research one step further, namely,
•	
Using all the surrounding APs could be a better choice over pre-deployed APs under certain cir-
cumstances. However, the environmental dynamics need to be dealt with first.
•	
The impact of different settings on the localization accuracy could be diversified, leading to the 
unstable performance. Therefore, stability is also a critical metric to evaluate the algorithms.
To this end, we present HED, which explicitly deals with environmental dynamics to harvest from 
the increasing number of APs while maintaining stable performance crossing different combinations 
of the AP and scenario settings. It aims to breach the performance boundary appearing in the LCS and 
FreeLoc algorithms.
HED: ORDER-TOLERANCE SEQUENCES MATCHING ALGORITHM
In this section, we first introduce an overview of our localization algorithm, and then present the details 
as well as theoretical analysis.
Basic Idea
A well designed algorithm not only needs to be accurately mapping the fingerprints to locations, but also 
needs to be of high-scalability and low-complexity to facilitate its usage in real-world applications. With 
various fingerprint positioning algorithms listed above, we now use the new definition of the fingerprint 
distance to help design our HED algorithm. The basic methodology of HED is to effectively use all the 
surrounding signal sources, i.e., APs, for precision positioning. Also, HED is designed to have stable 
performance in both STS and LTS.

92
WiFi Fingerprint Localization for Emergency Response
﻿
Algorithm 1. Pseudocode for the HED Algorithm
Input: x
PID BSSID RSSI
k
K Y
y
y
k
k
j
=<
>
=
=
,
,
;
... ;
{ ,...,
,...}
1
1
 
Output: Location of the target device: ( ,
)
X Y  
Begin: 
          While TRUE do
                    SORT_RSSI(x ,Y );
                    For Eachyi  do
                              MEASURE_SIM(x y SIM x y
i
i
,
,
( ,
) );
                    DECIDE_LOCATION(SIM x Y
( ,
));
Function SORT_RSSI(x yj
,
 )
          Sort by RSSI; 
          Return (x yj
,
);
Function MEASURE_SIM(x y SIM x y
i
i
,
,
( ,
) )
          For Each BSSID in x  do
                    IF It is not inyi then
                              SIM x yi
( ,
)  remains;
                    IF p
q
==
 then
                              SIM x yi
( ,
)++;
IF |p-q|<THD  then
                              Calculate_the_fluctuation(x y p q
i
,
, ,
);
IF |p-q|>THD  then
          Break; 
Function Calculate_the_fluctuation(x y p q
i
,
, ,
)
          calculate the mean difference of RSSI for bothx yi
,
 ;
          IF |
|
RSSI
RSSI
RSSI
RSSI
a
a
q
p
x
yi
−
≤
−
|
|  then
                    SIM x yi
( ,
)++;
IF |
|>
RSSI
RSSI
RSSI
RSSI
a
a
q
p
x
yi
−
−
|
| then
                    Break; 
Function DECIDE_LOCATION(SIM x Y
( ,
))
Average the top-k references points with the highest SIM scores; 
Return the final location;
Algorithm Detail
Before presenting details, we introduce some basic data structures first,
•	
Unknown fingerprint x
PID BSSID RSSI
j
J
j
j
=<
>
=
,
,
,
...
1
 where PID BSSIDj
,
, and RSSI j  
stands for the unknown position, the jth AP, and the average RSSI of 100 readings of AP j from 
that position, respectively.

93
WiFi Fingerprint Localization for Emergency Response
﻿
•	
Training fingerprint datasetY
y
y
y
j
J
= { ,... ,...
}
1
, where yi  is a set of entries with the same PID, 
i.e.,PIDi . More specifically,yi
PID BSSID RSSI
i
j
i j
= {
,
,
}
,
. PID BSSID RSSI
i
j
i j
,
,
,  stand for 
the ith reference point, the jth AP, and the average RSSI of 100 readings of AP j from that position, 
respectively. At each referent point, we take 100 samples for each available APs and use the aver-
aged value as the RSSI.
•	
SIM x yi
( ,
) . In order to identify the potential location of the unknown fingerprint, i.e., PID in x, 
we define a variable SIM x yi
( ,
)  to evaluate the similarity between x  and yi .
•	
THD. It is a threshold to evaluate the order difference in x  and yi  for the same AP. It is an empiri-
cal value and set to 3 in our experiments.
Note that x  and yi  have the same internal structure since they both are RF fingerprints of some 
specific locations. Therefore, HED compares x  with each yi  and select those locations with the highest 
similarity scores. We average the references points with the top-k SIMs to estimate the unknown location 
PID.
The Pseuduocode of HED is shown in Algorithm 1. It mainly consists of three steps, namely,
Step 1: Sort x  by RSSI in descending order. For each yi , sort it by RSSI in descending order.
Step 2: Evaluate the similarity between x  and eachyi , i.e.,SIM x yi
( ,
) . Since environmental dynamics 
may affect the RSS readings, instead of using the absolute RSSI values directly, HED uses the 
relative values. In particular, HED uses the order number of a given AP in a sorted fingerprint to 
capture the inherent geographical relationship among different APs, regardless of dynamics such 
as coming-and-going APs, time-variances and device diversity.
In detail, each AP in the sorted x, has its own order number, i.e, p. If it doesn’t exist in yi , SIM re-
mains. Otherwise, it has another order number q inyi . For p and q, we have the following three cases,
Case 1: if p
q
==
,SIM x yi
( ,
)++;
Case 2: if|p-q|<THD , go to step 2.1;
Case 3: if |p-q|>THD , SIM(x,  yi ) remains;
Step 2.1: Assume that p
q
>
. For x, calculate the average RSSI of entries from order q to p to get 
RSSIa x . Do the same to yi to getRSSIa yi .
Case 1: if|
|
RSSI
RSSI
RSSI
RSSI
a
a
q
p
x
yi
−
≤
−
|
| SIM x yi
( ,
)++;
Case 2: if |
|>
RSSI
RSSI
RSSI
RSSI
a
a
q
p
x
yi
−
−
|
| SIM x yi
( ,
)  remains;
Step 3: At this step, we have all SIM x yi
( ,
) . The bigger this value is, the closer the two locations are. 
We select k reference points with the highest SIM values and use their average as the location for 
x.

94
WiFi Fingerprint Localization for Emergency Response
﻿
Algorithm Analysis
In this part, we present theoretical analysis on the HED dealing with different environmental factors, as 
well as its computational complexity.
Remark 1: HED can effectively deal with the phenomenon coming-and-going APs.
There exists two different cases for this phenomenon,
Case 1: A new AP emerges after the training phase. In this case, we only have p but no q, so the SIM 
remains the same.
Case 2: An old AP disappears after the training phase. In this case, we only have q but no p, and the 
SIM still remains the same.
Therefore, in both cases, the coming-and-going APs don’t affect the SIM value between x and yi , 
and thus have no impact on the determination of the unknown location.
Remark 2: HED can effectively deal with the RSSI variance of one particular AP caused by time, i.e., 
time-variance.
The RSS drift of one particular AP caused by time, as evaluated in (Yang et al., 2013, does exist. 
Therefore, HED in step 2 determines the similarity between the unknown fingerprint and the training 
fingerprint by the relative order instead of the absolute RSSI values. In that way, we are able to capture 
the inherent relationship between the physical location and the signal strength, by eliminating the nega-
tive effects of the time-variant RSSI values.
Remark 3: HED can effectively deal with the device diversity, i.e., different collecting devices.
The device diversity imposes a potential threat to the accurate localization. In general, there exists 
two cases,
Case 1: The collecting devices in the testing phase may be different, i.e., different users.
Case 2: The collecting devices in the training phase and testing phase are different.
For both cases, different devices may have different measurements of a given AP at the same loca-
tion, due to the hardware heterogeneity. However, that kind of differences is marginal, even with little 
impact on previous solutions using the absolute RSSI values such as FreeLoc.
Moreover, HED uses the relative order in a sorted RSSI sequence to determine the similarity between 
two fingerprints. It can naturally combat the RSSI drift caused by the device diversity. Such drift is 
general and almost the same for all APs.
Theorem 1: The computational complexity of HED is O mn
(
) where m is the number of APs in x and 
n is the number of reference points.

95
WiFi Fingerprint Localization for Emergency Response
﻿
Proof: To clarify the complexity of HED, we need to analyze the complexity for each step:
Step 1: Hash sort of x and yi :O m
(
) .
Step 2: Comparing x and yi  leads toO m
(
) . Considering that there are n reference points, the total 
complexity of Step 2 is O mn
(
)
Step 3: Sorting SIM(x,Y): O m
(
)
Therefore, step 2 dominates the computational complexity, leading to the overall O mn
(
)complexity 
for HED. As shown in Table 1, LCS share the same complexity with HED while FreeLoc has a much 
higher complexity, i.e.,O m n
(
)
2
.
PERFORMANCE EVALUATION
In this section, we present performance evaluation by comparing HED with FreeLoc and LCS under 
different combinations of settings. The experiments have been divided into two categories, i.e., STS and 
LTS, so as to emphasize the differences between scenarios. Moreover, we provide detailed analysis of 
the impact of environmental dynamics on the overall performance.
The experimental parameters and settings remain the same as in Section 2. The experiments have 
been conducted in both CR and ER. However, since CR and ER show very similar phenomena, we will 
use CR as an example to interpret the results, while highlighting the differences between them.
Evaluation Metrics
To fully evaluate the performance of HED, FreeLoc and LCS, we use the following three metrics,
•	
Accuracy: Defined as the average localization error in meters. It is the most commonly used 
metric.
•	
Complexity: Defined as the average running time in seconds of each algorithm.
•	
Stability: Defined as the Standard Deviation (SD) of four combinations of settings in terms of 
accuracy.
STS Experiments
In STS, it is unlikely that there exist significant changes of APs. Therefore, the slow-varying signal 
fluctuation of a single AP is a typical dynamic factor we need to deal with. The experimental results 
are presented in Figure 3.
For CR, Figure 3(a) denotes the localization accuracy of all three algorithms with pre-deployed 
6 APs, while Figure 3(b) shows the same content with all surrounding APs. Figure 3(c) records the 
performance comparison between pre-deployed APs and All-AP of these algorithms to understand the 
impact of AP settings.
The pre-deployed APs combining the STS create the most stable RF environment among all four 
combinations. Thus, it is not a surprise that all three algorithms have similar performance. As a result, 

96
WiFi Fingerprint Localization for Emergency Response
﻿
HED, LCS and FreeLoc have an average localization error of 1.91 m, 2.18 m and 2.03 m, respectively. 
HED has the best performance and FreeLoc performs the second. However, even the performance gap 
between the best (HED) and the worst (LCS) is only around 27 centimeters, corresponding to 12.4% 
differences. The phenomenon also backs up that pre-deployed APs in STS brings a stable environment, 
which could potential benefit the localization. It explains the reason that most of previous work has 
employed this kind of combination for the experiments.
On the other hand, if using all surrounding APs, even in STS the performance of three algorithms 
is diversified. HED, LCS and FreeLoc have an average localization error of 1.88 m, 1.98 m and 2.86 
m, respectively. HED still has the best performance in terms of accuracy, but this time LCS beats the 
FreeLoc by 30.6%. We notice that under this combination HED and LCS have very close performance. 
Actually, the difference is only around 5%.
The reason is straightforward: for STS, the impact of coming-and-going APs is limited, and thus RSS 
time variance constitutes the major dynamic factor. The worst case scenario is the signal fluctuations of 
adjacent APs that lead to the order changes. Both HED and LCS allow such changes to some extent, as 
we analyzed above. But FreeLoc is more sensitive to the RSS variance according to our previous analysis 
in Section 2. Therefore, it suffers the most serious performance degeneration.
Figure 3(c) confirms the benefits brought by more APs: the performance of HED and LCS has been 
improved by 3cm and 20cm from 6-AP to All-AP, respectively. It is also consistent with our previous 
analysis. In STS, the RF environment is stable; therefore more APs could potentially bring more benefits 
Figure 3. Experimental Results in STS

97
WiFi Fingerprint Localization for Emergency Response
﻿
in localization, especially for algorithms such as HED and LCS that take the relative AP order info into 
consideration.
For ER, experimental results present the same features as in CR except for one. As shown in Figure 
3(f), unlike Figure 3(c) where the LCS has better performance with All-AP, it performed better with 
pre-deployed 8 APs. This is because we only detect 78 APs in ER while there are 122 in CR. On the 
other hand, we also notice that even with a shrinked number of APs HED is still able to improve the 
performance using All-AP.
Another interesting investigation worth noting is that the performance gap among three algorithms 
is much more obvious in ER than CR, as shown in Figure 3(b) and Figure 3(e). In CR, the gap between 
HED and LCS is 5%, while in ER it becomes 31.9%, implying that the larger the room is, the better 
HED performs.
LTS Experiments
For CR, as shown in Table I, we use the sample 1 and 3 as the training and testing data. For ER, we use 
the sample 1 and 5 as the training and testing data. The results have been presented in Figure 4. Like 
STS, most of investigations are consistent for both rooms and thus we use CR to illustrate them.
In LTS, the RSS time variance is no longer a major threat, but the impact of coming-and-going APs 
becomes much more significant compared to STS. In STS, 76 APs have been detected in total while 47 
remain the same. While in LTS, we have detected 74 APs in total, among which only 35 remain during 
the experiments. The experimental results are presented in Figure 4 the same way as Figure 3.
We notice that Figure 4(a) shows the same trend as in Figure 3(a): all three algorithms present similar 
performance. More specifically, HED, LCS and FreeLoc have an average localization error of 2.03 m, 
2.23 m and 2.14 m, respectively. HED is the best. But the gap with the worst, which is still the LCS, is 
marginal (around 9%).
Moreover, Figure 4(b) shows the same features as in Figure 3(b). HED, LCS and FreeLoc have an 
average localization error of 2.19 m, 2.34 m and 3.33 m, respectively. HED is the best, and it outperforms 
LCS and FreeLoc by 6.4% and 36.1%, respectively.
We notice that though the scenario has been shifted from STS to LTS, both Figure 4(a) and Figure 
4(b) show similar features as in Figure 3(a) and Figure 3(b), implying that the impact of the AP setting 
on the accuracy outweighs the scenario setting.
However, Figure 4(c) exhibits some different phenomena. We notice that unlike Figure 3(c) where 
both HED and LCS perform better with All-AP, in LTS they actually perform worse with more APs. It 
confirms the impact of the scenario setting on the accuracy: in LTS, the AP changes become the dominat-
ing factor to affect the localization. Though both HED and LCS present countermeasures that explicitly 
deal with this issue, it still leads to the performance degeneration. However, these countermeasures are 
successful in slowing down the deterioration. Comparing with FreeLoc, whose performance decreases 
by 35.7%, HED and LCS only suffer 7.3% and 4.7% performance degeneration, respectively.
For ER, we also obtain similar results as in CR. Figure 4(d) confirms that using pre-deployed APs in 
STS bring the most stable RF environment that is essential for better performance. Also, all three algo-
rithms have similar performance as in CR, implying that under the stable environment the performance 
boundary limited by the fingerprint method has been approached.

98
WiFi Fingerprint Localization for Emergency Response
﻿
Figure 4(e) backs up our previous statements about HED. Firstly, it is a better choice over LCS and 
FreeLoc. Secondly, the performance gap between HED and LCS has been increased from CR to ER. In 
CR, it is only around 6.4%, while in ER it becomes 17.5%.
Stability Analysis
In this part, we study the stability of all three algorithms. As shown in Figure 5, in terms of accuracy, 
HED preserves performance that is very close in STS and LTS. In other words, like LCS, HED can be 
considered as a stable algorithm across all settings. As defined in the previous part, stability is used to 
evaluate the algorithm performance under different combinations of settings.
For CR, the SD of HED over four combinations is 0.1408. While the SDs of FreeLoc and LCS are 
0.6155 and 0.1506, as shown in Figure 2(a) and Figure 2(b).
For ER, the SDs of HED, LCS and FreeLoc are 0.1241, 0.3162 and 1.711, respectively.
Therefore, we can conclude that HED performs more stable than both FreeLoc and LCS across dif-
ferent settings.
Figure 4. Experimental Results in LTS

99
WiFi Fingerprint Localization for Emergency Response
﻿
Performance Analysis Over Time
Previous results confirmed that all three algorithms have performed similarly using pre-deployed APs 
regardless of the scenario setting. But they may present diversified performance under the All-AP setting. 
Therefore, in this part, we study how different algorithms perform with time under All-AP. Here we use 
ER as an example. As shown in Table 2, we have four samples whose time differences to the reference 
sample are 3 days, 1 week, 4 weeks and 10 weeks, respectively. Figure 6 concludes the localization 
results of all three algorithms.
It is not surprising that HED and LCS still have stable performance over time, considering that there 
exists no significant performance degradation even between the STS and LTS. On the other hand, Free-
Loc has not been built to handle the AP changing, thus its performance suffers significant variances.
But it is indeed a surprise that we have not observed the similar performance degeneration over time 
as in Chen et al. 2004. Actually, there is no such trend found in all three algorithms. To clarify this issue, 
we revisited the raw data and listed the AP variation over time in Table 2.
As the time goes by, the number of the same APs decreases from 59 to 48, corresponding to 18% 
difference. Therefore, we can conclude that as long as the AP change is limited, algorithms such as HED 
and LCS can tolerate such changes and maintain stable performance over time.
Figure 5. Performance evaluation of HED under different combinations
Figure 6. ER: Performance Analysis Over Time

100
WiFi Fingerprint Localization for Emergency Response
﻿
Discussions and Summary
Besides the interesting investigations obtained in previous part, our experimental results have also re-
vealed the following valuable insights, namely,
1. 	
In the STS such as emergency/temporal applications, using all surrounding APs could constitute 
a better option for the localization. Compared to the labor-intensive pre-deployed AP setting, it is 
more accurate, much easier to establish, and lower in cost.
2. 	
In the LTS such as LBSs in public areas, using pre-deployed APs could ensure a stable RF environ-
ment, leading to better performance.
3. 	
When implementing a real-world indoor localization application facing diversified environmental 
dynamics, it would be better to employ algorithms with high stability.
In summary, as shown in Table 3, HED shows its superiority over other two state-of-the-art algo-
rithms (FreeLoc and LCS) in terms of accuracy and stability, while maintaining a reasonable complexity. 
Thus, we can conclude that it constitutes a pervasive localization algorithm that is a suitable candidate 
for real-world applications.
Table 2. ER: AP Variation Through Time Compared to Sample 1
3 Days
1 Week
4 Weeks
10 Weeks
# of Same APs
59
56
52
48
# of Disappeared APs
19
17
21
31
# of New APs
29
22
25
29
Table 3. Performance comparison of CR and ER under different combinations
CR
Combinations
Error(m)
Time(s)
ER
Combinations
Error(m)
Time(s)
HED
STS All-AP
1.88
236
STS All-AP
2.54
223
LTS All-AP
2.19
222
LTS All-AP
2.83
216
STS 6-AP
1.91
100
STS 8-AP
2.64
123
LTS 6-AP
2.03
102
LTS 8-AP
2.61
117
LCS
STS All-AP
1.98
229
STS All-AP
3.73
244
LTS All-AP
2.34
215
LTS All-AP
3.43
235
STS 6-AP
2.18
96
STS 8-AP
3.13
117
LTS 6-AP
2.23
99
LTS 8-AP
3.03
114
FreeLoc
STS All-AP
2.86
650
STS All-AP
5.22
666
LTS All-AP
3.33
424
LTS All-AP
3.76
528
STS 6-AP
2.03
109
STS 8-AP
2.65
122
LTS 6-AP
2.14
111
LTS 8-AP
2.85
119

101
WiFi Fingerprint Localization for Emergency Response
﻿
RELATED WORKS
With the rapid development of IoT, the location-based service (LBS) (Bellavista et al., 2008) becomes 
an essential part for various pervasive applications to promote user experiences, such as google maps 
(Geller, 2007).
Over the years, tremendous research efforts have been devoted to this specific topic. On one hand, 
techniques of outdoor localization is well-developed since they benefit a lot from exiting mature posi-
tioning techniques such as GPS (Moore, 1999). On the other hand, indoor localization remains a great 
challenge due to unique features such as the inoperative GPS, irregular signal propagation and complex 
environments (Liu et al., 2007).
In general, current research on indoor localization can be roughly divided into two categories by their 
localization methods: model-based and fingerprint-based (Wu et al., 2013). The model-based approaches 
use sophisticated geometrical models to estimate the physical locations of target devices, while the 
fingerprint-based solutions explore data mining techniques to recover locations from the historical data.
The well-known log-distance path loss model (LDPL) can be used to estimate the propagation distance 
using RSS values (Lee et al., 2010). However, LDPL is only suitable for the free space propagation. To 
be of practical usage, modifications concerning real-world environments are demanded. For instance, 
Stoyanova et al. proposed a model, which takes free-space path loss, ground reflection path loss, RSS 
uncertainty and antenna pattern irregularity into consideration, specifically for wireless sensor networks 
(Stoyanova et al., 2009). Lim et al. designed a complex model for WLAN, considering factors such as 
RF multi-path fading, temperature and humidity variations, opening and closing of doors, furniture 
relocation, and human mobility (Lim et al., 2007). There is a recent trend to develop more sophisticated 
models for a better characterization of physical environments, e.g., the ray-tracing models (Ghobadi 
et al., 1998; Yang et al., 2011; Rizk et al., 1997), Bayesian hierarchical model (Madigan et al., 2005; 
Kleisouris & Martin, 2007), and Hidden Markov models (Morelli et al., 2007).
Though the model-based solutions inherit various advantages such as low cost on the site survey 
and training data, there is one major concern: the ever-changing indoor environment poses a heavy 
burden on both geometrical models and computing powers, leading to unstable performance, e.g., large 
localization errors.
The fingerprint-based approaches leverage site survey and data mining techniques to estimate loca-
tions from known reference data. The basic idea is to manually gather RF RSSI values (signals could 
be from WLAN (Wu et al., 2013), ZigBee (Fang et al., 2012), Bluetooth (Bekkelien et al., 2012), FM 
(Chen et al., 2012), etc.) as the signatures (fingerprints) at every location within the area of interest, 
i.e., site survey. The collected fingerprint form the training database stored in the server. When a user 
wants to know its current locations, it first samples the surrounding signatures and then sends the test 
data back to server, which will use data mining techniques to figure out possible locations with similar 
fingerprints. Examples include RADAR (Bahl & Padmanabhan, 2000), ActiveCampus (Griswold et al., 
2004}, UbiSpot (Schwartz et al., 2010), FIFS (Xiao et al., 2012), and SSD (Mahtab et al., 2013), etc.
However, most of previous research implicitly assumes the similarity of the RF environment between 
the training and testing phases to maintain high localization accuracy. Such assumption is usually achieved 
by a limited number of controllable APs, i.e., pre-deployed APs.
Though fair performance under such assumption can be obtained, whether this assumption is reason-
able still remains questionable, e.g., deploying multiple APs in one room. Moreover, much effort has 

102
WiFi Fingerprint Localization for Emergency Response
﻿
been devoted to optimizing the AP layout to improve the localization accuracy (Aomumpai et al., 2014; 
Hu et al., 2015).
Therefore, there is a very recent trend to explore the ambient APs, which are neither pre-deployed nor 
controllable, to rapidly set up a cost-efficient localization system, as a consequence of the blossoming 
of WLANs in our daily lives. FreeLoc, proposed by Yang et al., is such an effort. It deals with typical 
dynamics such as the signal variance and device diversity (Yang et al., 2013). However, another major 
factor, i.e., coming-and-going AP, has not been considered. Chen et al. filled in the blank and designed 
LCS to utilize the massive ambient APs (Chen et al., 2014) for the localization. LCS has been evaluated 
in the real-world experiments for over one year and its performance has been proved to be consistent over 
time. However, LCS missed the AP disorder issue, where the signal variance of some AP may cause the 
order change when sorting the APs by the RSSI value. It could lead to a mismatched fingerprint with 
degenerated performance.
Inspired by Yang et al., 2013 and Chen et al., 2014, our work pushes the research one-step further by 
exploring the ambient APs for a more accurate and stable localization solution. Compared to FreeLoc, 
our work has a different focus in terms of the environmental dynamics. Also, our work handles the AP 
disorder issue in a better way than LCS, as proved in the Section 3.
CONCLUSION
This chapter addresses the environmental dynamics caused by the blossom of wireless devices in the 
indoor WiFi fingerprint localization. While previous research may consider them as threats hampering 
the localization efficiency, we argue that certain factors could be utilized for better performance via an 
empirical study.
With the hand-on experiences, we propose HED, an order-tolerance sequences matching algorithm 
to harvest from the environmental dynamics. The basic idea is to utilize all the wireless sources that can 
be detected while combating demerits such as AP disorders and signal variance.
We have implemented HED in two real-world scenarios and conducted extensive experiments lasting 
for over 6 months to verify its performance. By comparing it with other state-of-the-art algorithms (i.e., 
FreeLoc and LCS), we show its superiority terms of localization accuracy and performance stability 
while maintaining reasonable computational complexity.
Moreover, critical insights and valuable hand-on experiences have been obtained, which offer in-
depth understandings about the impact of various environmental dynamics in the real-world applications.
REFERENCES
Alemdar, H., & Ersoy, C. (2010). Wireless sensor networks for healthcare: A survey. Computer Networks, 
54(15), 2688–2710. doi:10.1016/j.comnet.2010.05.003
Aomumpai, S., Kondee, K., Prommak, C., & Kaemarungsi, K. (2013). Optimal placement of reference 
nodes for wireless indoor positioning systems. IEEE 11th International Conference on ECTI-CON, 1–6.
Atzori, L., Iera, A., & Morabito, G. (2010). The internet of things: A survey. Computer Networks, 54(15), 
2787–2805. doi:10.1016/j.comnet.2010.05.010

103
WiFi Fingerprint Localization for Emergency Response
﻿
Atzori, L., Iera, A., Morabito, G., & Nitti, M. (2012). The social internet of things (siot)–when social 
networks meet the internet of things: Concept, architecture and network characterization. Computer 
Networks, 56(16), 3594–3608. doi:10.1016/j.comnet.2012.07.010
Bahl, P., & Padmanabhan, V. (2000). RADAR: An in-building RF-based user location and tracking 
system. IEEE INFOCOM 2000, 2, 775–784.
Bekkelien, A., Deriaz, M., & Marchand-Maillet, S. (2012). Bluetooth indoor positioning (Master’s 
thesis). University of Geneva.
Bellavista, P., Kupper, A., & Helal, S. (2008). Location-based services: Back to the future. IEEE Pervasive 
Computing / IEEE Computer Society [and] IEEE Communications Society, 7(2), 85–89. doi:10.1109/
MPRV.2008.34
Brunato, M., & Battiti, R. (2005). Statistical learning theory for location fingerprinting in wireless LANs. 
Computer Networks, 47(6), 825–845. doi:10.1016/j.comnet.2004.09.004
Chen, X., Kong, J., Guo, Y., & Chen, X. (2014). An empirical study of indoor localization algorithms 
with densely deployed APs. IEEE Global Communications Conference, 517–522. doi:10.1109/GLO-
COM.2014.7036860
Chen, Y., Lymberopoulos, D., Liu, J., & Priyantha, B. (2012). FM-based indoor localization. Proceed-
ings of the 10th ACM international conference on Mobile systems, applications, and services, 169–182.
Fang, S. H., Wang, C. H., Huang, T. Y., Yang, C. H., & Chen, Y. S. (2012). An enhanced ZigBee in-
door positioning system with an ensemble approach. IEEE Communications Letters, 16(4), 564–567. 
doi:10.1109/LCOMM.2012.022112.120131
Feldmann, S., Kyamakya, K., Zapater, A., & Lue, Z. (2003). An Indoor Bluetooth-Based Positioning 
System: Concept. Implementation and Experimental Evaluation. International Conference on Wireless 
Networks, 109–113.
Geller, T. (2007). Imaging the World: The State of Online Mapping. IEEE Computer Graphics and Ap-
plications, 27(2), 8–13. doi:10.1109/MCG.2007.39 PMID:17388197
Ghobadi, C., Shepherd, P., & Pennock, S.R. (1998). 2D ray-tracing model for indoor radio propagation 
at millimetre frequencies, and the study of diversity techniques. IEE Proceedings on Microwaves, Anten-
nas and Propagation, 145, 349–353.
Goldman, O. (2011). The globalization of terror attacks. Terrorism and Political Violence, 23(1), 31–59. 
doi:10.1080/09546553.2010.514776
Griswold, W., Shanahan, P., Brown, S., Boyer, R., Ratto, M., Shapiro, R., & Truong, T. (2004). Ac-
tiveCampus: Experiments in community-oriented ubiquitous computing. Computer, 37(10), 73–81. 
doi:10.1109/MC.2004.149
Harle, R. (2013). A survey of indoor inertial positioning systems for pedestrians. IEEE Communications 
Surveys and Tutorials, 15(3), 1281–1293. doi:10.1109/SURV.2012.121912.00075

104
WiFi Fingerprint Localization for Emergency Response
﻿
Hazas, M., & Hopper, A. (2006). A. Broadband ultrasonic location systems for improved indoor posi-
tioning. IEEE Transactions on Mobile Computing, 5(5), 536–547. doi:10.1109/TMC.2006.57
He, D., Ma, M., Zhang, Y., Chen, C., & Bu, J. (2011). A strong user authentication scheme with smart 
cards for wireless communications. Computer Communications, 34(3), 367–374. doi:10.1016/j.com-
com.2010.02.031
Hu, X., Shang, J., Gu, F., & Han, Q. (2015). Improving Wi-Fi Indoor Positioning via AP Sets Similar-
ity and Semi-Supervised Affinity Propagation Clustering. International Journal of Distributed Sensor 
Networks, 11(1), 109642. doi:10.1155/2015/109642
Kleisouris, K., & Martin, R. (2007). Parallel Algorithms for Bayesian Indoor Positioning Systems. IEEE 
International Conference on Parallel Processing, 15–15. doi:10.1109/ICPP.2007.64
Lee, J., Ryu, J., Lee, S. J., & Kwon, T. T. (2010). Improved modeling of IEEE 802.11 a PHY through 
fine-grained measurements. Computer Networks, 54(4), 641–657. doi:10.1016/j.comnet.2009.08.003
Lee, S., Ha, K. N., & Lee, K. C. (2006). A pyroelectric infrared sensor-based indoor location-aware sys-
tem for the smart home. IEEE Transactions on Consumer Electronics, 52(4), 1311–1317. doi:10.1109/
TCE.2006.273150
Li, H., Sun, L., Zhu, H., Lu, X., & Cheng, X. (2014). Achieving privacy preservation in WiFi fingerprint-
based localization. Proceedings of IEEE INFOCOM, 2337–2345. doi:10.1109/INFOCOM.2014.6848178
Lim, C. H., Wan, Y., Ng, B. P., & See, C. (2007). A real-time indoor WiFi localization system utilizing smart 
antennas. IEEE Transactions on Consumer Electronics, 53(2), 618–622. doi:10.1109/TCE.2007.381737
Liu, H., Darabi, H., Banerjee, P., & Liu, J. (2007). Survey of Wireless Indoor Positioning Techniques 
and Systems. IEEE Transactions on Systems, Man and Cybernetics. Part C, Applications and Reviews, 
37(6), 1067–1080. doi:10.1109/TSMCC.2007.905750
Madigan, D., Einahrawy, E., Martin, R., Ju, W. H., Krishnan, P., & Krishnakumar, A. S. (2005). Bayes-
ian indoor positioning systems. Proceedings - IEEE INFOCOM, 2, 1217–1227.
Mahtab Hossain, A., Jin, Y., Soh, W. S., & Van, H. N. (2013, January). SSD: A robust RF location 
fingerprint addressing mobile devices heterogeneity. IEEE Transactions on Mobile Computing, 12(1), 
65–77. doi:10.1109/TMC.2011.243
Makki, A., Siddig, A., Saad, M., & Bleakley, C. (2015). Survey of WiFi positioning using time-based 
techniques. Computer Networks, 88, 218–233. doi:10.1016/j.comnet.2015.06.015
Moore, P., & Crossley, P. (1999). GPS applications in power systems. I. Introduction to GPS. Power 
Engineering Journal, 13(1), 33–39. doi:10.1049/pe:19990110
Morelli, C., Nicoli, M., Rampa, V., & Spagnolini, U. (2007). Hidden Markov Models for Radio Local-
ization in Mixed LOS/NLOS Conditions. IEEE Transactions on Signal Processing, 55(4), 1525–1542. 
doi:10.1109/TSP.2006.889978

105
WiFi Fingerprint Localization for Emergency Response
﻿
Rizk, K., Wagen, J., & Gardiol, F. (1997). Two-dimensional ray-tracing modeling for propagation pre-
diction in microcellular environments. IEEE Transactions on Vehicular Technology, 46(2), 508–518. 
doi:10.1109/25.580789
Saad, S. S., & Nakad, Z. S. (2011). A standalone RFID indoor positioning system using passive tags. 
IEEE Transactions on Industrial Electronics, 58(5), 1961–1970. doi:10.1109/TIE.2010.2055774
Schwartz, T., Stahl, C., Muller, C., Dimitrov, V., & Ji, H. (2010). UbiSpot - A user trained always best 
positioned engine for mobile phones. In Ubiquitous Positioning Indoor Navigation and Location Based 
Service (pp. 1–8). UPINLBS.
Stoyanova, T., Kerasiotis, F., Prayati, A., & Papadopoulos, G. (2009). A Practical RF Propagation 
Model for Wireless Network Sensors (pp. 194–199). Sensor Technologies and Applications. doi:10.1109/
SENSORCOMM.2009.39
Subramanian, C., Lapilli, G., Kreit, F., Pinelli, J. P., & Kostanic, I. (2011). Experimental and computa-
tional performance analysis of a multi-sensor wireless network system for hurricane monitoring. Sensors 
& Transducers, 10, 206–244.
Sun, G., Chen, J., Guo, W., & Liu, K. (2005). Signal processing techniques in network-aided position-
ing: A survey of state-of-the-art positioning designs. IEEE Signal Processing Magazine, 22(4), 12–23. 
doi:10.1109/MSP.2005.1458273
Suzuki, M., Saruwatari, S., Kurata, N., & Morikawa, H. (2007). A high-density earthquake monitor-
ing system using wireless sensor networks. International Conference on Embedded Networked Sensor 
Systems, 373-374. doi:10.1145/1322263.1322301
Tan, R., Xing, G., Chen, J., Song, W. Z., & Huang, R. (2010). Quality-Driven Volcanic Earthquake 
Detection Using Wireless Sensor Networks. IEEE Real-Time Systems Symposium (pp.271-280). IEEE 
Computer Society. doi:10.1109/RTSS.2010.21
Wu, C., Yang, Z., Liu, Y., & Xi, W. (2013). WILL: Wireless Indoor Localization without Site Survey. 
IEEE Transactions on Parallel and Distributed Systems, 24(4), 839–848. doi:10.1109/TPDS.2012.179
Wu, K., Xiao, J., Yi, Y., Chen, D., Luo, X., & Ni, L. M. (2013). CSI-based indoor localization. IEEE 
Transactions on Parallel and Distributed Systems, 24(7), 1300–1309. doi:10.1109/TPDS.2012.214
Xiao, J., Wu, K., Yi, Y., & Ni, L. (2012). FIFS: Fine-Grained Indoor Fingerprinting System. In IEEE 
2012 21st International Conference on Computer Communications and Networks (ICCCN), 1–7.
Yang, M., Stavrou, S., & Brown, A. (2011). Hybrid ray-tracing model for radio wave propagation through 
periodic building structures. IET Microwaves Antennas Propagation, 5, 340–348.
Yang, S., Dessai, P., Verma, M., & Gerla, M. (2013). Freeloc: Calibration-free crowdsourced indoor 
localization. Proceedings of IEEE INFOCOM, 2481–2489.

106
Copyright © 2018, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.
Chapter  4
DOI: 10.4018/978-1-5225-2575-2.ch004
ABSTRACT
The need for a Mobile Ad-Hoc Network (MANET) in environments where there is a lack of communica-
tion infrastructure, such as disaster or emergency scenarios, is critical to save lives. MANETs can be 
used as an alternative network that solves the problem of communications. The selection of an appro-
priate MANET communication protocol is crucial for the good performance of the whole network. Due 
to the great variety of communication protocols available for MANETs such as routing and broadcast-
ing protocols, the selection of the most suitable one for disaster scenarios is a relevant task. Routing 
protocols and broadcasting algorithms are normally evaluated and compared using simulation-based 
studies. However, conducting reliable and repeatable simulation studies is not a trivial task because 
many simulation parameters should be correctly configured. In this paper, we propose a methodology for 
conducting reliable simulations of MANET broadcasting algorithms in disaster scenarios. The proposed 
methodology is focused on the source nodes selection based on different metrics.
A Simulation Methodology 
for Conducting Unbiased and 
Reliable Evaluation of MANET 
Communication Protocols 
in Disaster Scenarios
José Manuel García-Campos
University of Seville, Spain
Daniel Gutiérrez
University of Seville, Spain
Jesús Sánchez-García
University of Seville, Spain
Sergio Toral
University of Seville, Spain

107
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
INTRODUCTION
Communications in disaster scenarios are crucial, especially during the immediate hours after the disaster 
occurred, in order to coordinate the relief actions. Communications among victims and/or rescue teams 
can alleviate the possible disaster consequences and save lives. The coordination and organization of 
rescue teams may be crucial to reduce the damages of a natural or human made disaster, such as hur-
ricanes, heavy floods, tsunamis or terrorist attacks. However, fixed communication infrastructure like 
cellular networks, which is normally used by citizens with their smartphones, can be malfunctioning 
due to the disaster damages.
For this reason, Wireless Mobile Ad Hoc NETworks (MANETs) (Lakshmi & Ibe, 2012)(Reina, Toral, 
Barrero, Bessis & Asimakopoulou, 2013) can be an appealing alternative communication network to 
be used in disaster response scenarios (Reina, Toral, Barrero, Bessis & Asimakopoulou, 2011)(Reina, 
Toral, Barrero, Bessis & Asimakopoulou, 2012). A MANET is an autonomous, infrastructure-less, self-
configuring and self-healing system of mobile nodes connected to each other by wireless links (Jurdak, 
Lopes & Baldi, 2004). In MANETs, mobile nodes can communicate with each other directly whenever 
they are within the transmission range of each other or via intermediate nodes (Arfeen, Kazi, Memen 
& Hyder, 2007).
Routing protocols and broadcasting algorithms are the main communication mechanisms to establish 
communication among nodes in MANETs. On the one hand, routing protocols are an important research 
topic in MANETs. A routing protocol is used to exchange data packets between nodes in the network 
through a multi-hop communication path. In MANETs, each node learns about nearby nodes and how to 
reach them by discovery processes which are included in routing protocols. Such discovery mechanisms 
allow routing information to be exchanged among all mobile nodes (Zhang, Low & Ng, 2011). On the 
other hand, broadcasting algorithms are a one-to-all communication technique, where nodes disseminate 
the same information simultaneously to all their one hop neighbours. Both communication strategies 
are useful in disaster scenarios. Broadcasting algorithms can be used to spread out a warning message 
among the civil protection members participating in a rescue operation. Regarding routing protocols, 
they can be used by civil protection services to establish stable communication paths between first re-
sponders such as fire fighters and police officers. Both communication mechanisms have been actively 
investigated during the last two decades. As a result of this research, many routing and broadcasting 
protocols can be found in the literature. However, it has also been stated that there is a lack of rigorous 
evaluation studies of the proposed protocols.
The evaluation of MANET communication protocols (routing and broadcasting) by simulation is 
an important mechanism so far in wireless ad hoc networks. This is because real experimentation in 
multi-hop ad hoc networks is costly in terms of hardware requirements. A high number wireless devices 
is required, and as a consequence, there are only a few available testbeds in the world (Blywis, Günes, 
Juraschek, Hahm & Schmittberger, 2011)(Li & Zhu, 2013). For this reason, it is very important to ob-
tain reliable simulation results. This is even more important in critical scenarios like disaster scenarios, 
where there is the necessity of establishing reliable communications in real time. However, MANET 
simulations have suffered from lack of credibility in the last decades, mainly because of the bad simula-
tion practices followed by the research community (Trung, Benjapolakul & Duc, 2007)(Das, castañeda 
& Yan, 2000)(Pucha, das & Hu, 2007).

108
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
In general, disaster mobility models must simulate the movements of participants communicating in 
disaster scenarios. Consequently, they play an important role in determining the communication protocol 
performance since the establishment of wireless communications strongly depends on the mobility of 
nodes in the network. When creating a simulating scenario for further performance evaluation of com-
munication protocols, it is an important issue that the mobility of nodes reflects real mobility patterns 
of people under the target scenario. The used disaster area mobility models define realistically tactical 
movements of a rescue team.
This book chapter presents an evaluation methodology for conducting simulations of routing proto-
cols and broadcasting algorithms for the application of MANETs in disaster scenarios. The proposed 
methodology is based on the study of the topological properties of the considered scenarios, and the 
selection of several important simulation parameters. The main idea is to guarantee that the evaluation of 
communication protocols is fair and statically reliable, so the authors can figure out which communica-
tion protocols and under which circumstances are suitable for disaster scenarios. The main contributions 
of this book chapter are:
•	
An evaluation methodology for a fairly comparison of MANET communication protocols (routing 
and broadcasting) in disaster scenarios.
•	
The validation of the proposed evaluation methodology in a representative disaster scenario mo-
bility model for MANETs; and considering well-known communication protocols for routing and 
broadcasting algorithms.
The rest of this book chapter continues as follows, section 2 introduces the MANETs communication 
protocols. Section 3 presents the models available for disaster scenarios and the one used in this book 
chapter. Section 4 contains the proposed evaluation methodology, and section 5 includes the simulation 
results that validate the proposed methodology. Finally, this book chapter ends with some conclusions 
included in section 6.
INTRODUCTION TO COMMUNICATION PROTOCOLS FOR MANETs
MANETs have received significant attention over last few years due to its potential applications in a 
wide variety of situations such as battlefield, emergency relief, etc. A MANET is a special category 
of wireless communication networks, where the communication relies on the cooperation among the 
nodes following a wireless multi-hop strategy. Therefore, this kind of network does not rely on any fixed 
infrastructure, and behaves as a self-organizing and a self-managing network. As an evolution of MA-
NETs, other multi-hop networks have appeared in the last decades such as Vehicular Ad Hoc Networks 
(VANETs), Wireless Sensor Networks (WSN), Delay Tolerant Networks (DTNs), and more recently, 
Flying Ad Hoc Networks (FANETs). Although all of these multi-hop networks share some features, 
they have also many particular characteristics that make them different from a research point of view.
Regarding MANET communication protocols, routing and broadcasting algorithms are the main 
communication mechanisms. The following subsections focus on detailing the main properties of both 
communication mechanisms.

109
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
Routing Protocols
In general MANET routing protocols can be classified into two main categories: proactive and reactive 
routing protocols (Shenbagapriya & Kumar, 2014). In proactive routing protocols (Aggarwal, Ghandi 
& Chaubey, 2011), each node maintains routing information about every other node in the network. 
Every node obtains a view of the whole network topology by propagating update messages, namely 
hello packets in the majority of routing protocols, in regular periods of time. The major disadvantages 
of proactive routing protocols are, i) the large amount of data that every node is required to maintain 
and exchange, and ii) the slow route reconfiguration in case of failures. Conversely, in reactive routing 
protocols (Aggarwal, Ghandi & Chaubey, 2011), nodes do not maintain routing information about the 
complete network. Instead, they provide route creation on demand. That means that a path is created 
between two nodes, source and destination nodes, only whenever the source node has data to send to 
the destination node. In this book chapter, the most used reactive routing protocols such as AODV, LAR 
and DYMO are used and a brief description about the most common proactive routing protocols such as 
OLSR and DSDV is given. Figure 1 shows an example of the performance of a reactive routing protocol 
in MANETs. The source node (S in Figure 1) wants to communicate with the destination (D in Figure 1). 
Consequently, it starts a discovery process to find a route. The solid black arrows represent the discovery 
process flow. The intermediate nodes (1, 2, 3, 4, 5 in Figure 1) retransmit the request packet until reach-
ing the destination. After this discovery procedure, the destination confirms the route (dashed arrows).
Reactive Routing Protocols
•	
Ad Hoc On-Demand Distance Vector Protocol (AODV): In this protocol (Perkins, Royer & 
Das, 2003), nodes keep routing tables to store the next hop in the routing path towards the destina-
tion nodes. When a source node has a packet to send for a given destination node, it first checks 
whether there is an active route in its routing table. If so, the node uses such route to transmit 
packets to the destination. Otherwise, it initiates a route discovery procedure to find a new route by 
broadcasting a route request (RREQ) message to its neighbors (flooding). When an intermediate 
Figure 1. Routing protocol in MANETs

110
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
node receives a RREQ message, it checks if it is the destination of the request, and if so, it replies 
to the source node with a route response (RREP). By contrast, if it is an intermediate node, then it 
forwards the RREQ message, continuing with the flooding mechanism.
•	
Location-Aided Routing (LAR): This protocol (Ko & Vaidya, 2000) uses location information 
to improve the performance of routing protocols that rely on flooding such as the previously de-
scribed AODV. The key idea is to reduce the number of nodes to which the route request messages 
are propagated by using positioning information. LAR protocol uses an estimation of destination’s 
location to concentrate the flooding of packets to those regions which are closer to the destination 
node’s location. LAR assumes that each node knows its own location, but does not employ any 
special location service to obtain the location of other nodes. The destination location information 
obtained from a prior route discovery is used in a subsequent route discovery. For this reason, 
it defines two operation methods, i) expected zone and ii) request zone. The expected zone in a 
given time is the region in which a source node predicts that the destination node will be located. 
In request zone mode, a source node defines a request zone for the route request. A node forwards 
a route request only if it belongs to the request zone.
•	
Dynamic Mobile on-Demand (DYMO): This is an evolution of AODV routing protocol (Johnson, 
Maltz & Hu, 2004), and it was designed with the objective of simplifying it. The main improve-
ment of DYMO with respect to AODV is that when an intermediate node receives a RREQ mes-
sage it generates routes entries for each intermediate hop. Unlike DYMO, AODV only generates 
routes entries for destination nodes and their next hops.
Proactive Routing Protocols
•	
Destination-Sequenced Distance Vector (DSDV): In this protocol (Ramesh, Subbaiah, Rao & 
Raju, 2010), every node in the network maintains a routing table, which contains a list of all 
known destination nodes and the number of hops required to reach them. Each entry in the rout-
ing table is marked with a sequence number, which is assigned by the destination node. These 
sequence numbers are used to identify routes, thus avoiding formation of loops. These sequence 
numbers are modified when the topology of the network changes. For this reason, DSDV is not 
suitable for dynamic networks or networks in which the number of nodes is high.
•	
Optimized Link State Routing Protocols (OLSR): This protocol (Clausen & Jacquet, 2003) 
uses a link stability start algorithm, and it has the advantage of having routes immediately avail-
able when needed due to its proactive nature. OLSR is an optimization of classical link state 
protocols, tailored for MANET. OLSR minimizes the overhead from flooding by using only se-
lected nodes, applying a mechanism called multi-point relays (MPRs), which is used to efficiently 
retransmit control messages. This technique significantly reduces the number of retransmissions 
required to flood a message to all nodes in the network.
To summarize the features of the described MANET routing protocols, Table 1 shows their most im-
portant properties. Firstly, the categories which are not explained are defined:
•	
Routing Metric: They are cost values used by nodes to determine the best path to a destination 
node. Several factors help routing protocols to decide about the preferred or shortest path to a 
particular destination.

111
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
•	
Sequence Number: It acts as a route timestamp, ensuring freshness of the route.
•	
Loop Free: It is a mechanism to prevent routing loops due to inconsistent routing tables.
•	
Multiple Path: it is a routing technique that permits multiple alternative paths through a network.
•	
Frequency of Updates: it is related to the routing table updates.
•	
Transmission Mode: it means the way in which data is transmitted from one node to another one, 
it is also called data transmission mode or data communication mode.
Evaluation of Routing Protocols in Disaster Scenarios
Many routing protocols have been proposed for MANETs in the last two decades (Shenbagapriya & 
Kumar, 2014)(Kaur, Sahni & Bala, 2013). Regarding the evaluation of MANET routing protocols in 
disaster scenarios, in (Reina, Toral, Barrero, Bessis & Asimakopoulou, 2011) and (Reina, Toral, Bar-
rero, Bessis & Asimakopoulou, 2012) several popular well-known routing protocols for MANETs such 
as AODV, AOMDV, and DSR, were evaluated. The authors conclude that AODV routing protocol is 
the most suitable protocol for the disaster scenario considered. In (Raffelsberger & Hellwagner, 2012), 
the authors present the performance of AODV, DYMO, BATMAN, and OLSR routing protocols, in a 
specific emergency response scenario. This scenario represents the operation of a rescue team after an 
explosion in a chemical plant. The authors also conclude that AODV behavior is the best one in com-
parison with the other routing protocols considered. In (Quispe & Galan, 2014), the authors evaluate 
several MANET routing protocols such as AODV and DSDV. The main difference from the previous 
evaluation is that in (Quispe & Galan, 2014) the Waypoint mobility model is used instead of disaster 
area mobility model (Shawamborn, aschenbruck & Martini, 2010). In this case, the authors conclude 
that CBRP protocol outperforms its counterparts AODV and DSDV.
The methodology that the authors propose in this paper is a step forward in the evaluation of MANET 
routing protocols. The highest number of routing protocols available in NS-2 simulator (“ns”, 2016) 
are evaluated. More specifically, up to six different routing protocols are evaluated. Additionally, our 
evaluation includes both types of well-known routing protocols such as reactive and proactive routing 
protocols. Moreover, in this book chapter, the authors propose an evaluation methodology that allows 
the researchers to evaluate the routing protocols under controlled and fair conditions. Therefore, the 
simulation results obtained in this chapter are more reliable and fair from a statistic point of view.
Table 1. Features of selected MANET routing Protocols
AODV
DSR
LAR
DYMO
DSDV
OLSR
Routing category
Reactive
Reactive
Reactive
Reactive
Proactive
Proactive
Routing metric
Shortest path
Shortest path
Shortest path
Shortest path
Shortest path
Shortest path
Sequence number
Yes
Yes
Yes
Yes
Yes
Yes
Loop free
Yes
Yes
Yes
Yes
Yes
Yes
Multiple path
No
Yes
No
No
No
No
Frequency of 
updates
As needed
As needed
As needed
As needed
Periodically
Periodically
Transmission mode
Unicast 
/Broadcast
Unicast
Unicast 
/Broadcast
Unicast
Broadcast
Broadcast

112
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
Broadcasting Algorithms
Broadcasting is an important dissemination mechanism in wireless multi-hop networks like MANETs, 
VANETs, and WSNs (Reina, Toral, Johnson & Barrero, 2015). It is the operation used to transmit data 
in a one-to-all fashion, whenever a node broadcasts a message; all its neighbors receive it. Among the 
main applications of broadcasting are i) the discovery phase of routing protocols and ii) the dissemina-
tion of emergency messages in VANETs and disaster scenarios. In Figure 2 is depicted an example of 
the dissemination of broadcasting messages. The simplest broadcasting algorithm is the flooding, where 
a node (S in Figure 2) sends a packet to all its neighbor nodes in the network. The one-hop neighbors in 
turn retransmit to their neighbors and so on, until the message has been propagated to the whole network.
The goal of broadcasting approaches is to maximize the reachability in the network (Reina, Toral, 
Asimakopoulou, Barrero & Bessis, 2015), i.e., the amount of nodes in the network that receive a certain 
broadcasting message. Some applications and network protocols require that always all nodes in the 
network must receive a broadcast message; otherwise the protocol will not work properly. For instance, 
many routing protocols for wireless multi-hop networks assume that in the route discovery phase all 
nodes receive the route-request message. Although broadcasting is a simple operation, it has attracted 
the attention of the research community during the last two decades because there is not optimal solution 
employing only local information of nodes, i.e., the required overhead is high and and may not allow the 
scalability of this approach in networks with higher number of nodes.
Figure 2. Dissemination of messages

113
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
Broadcasting algorithms can be categorized as i) simple flooding, ii) probabilistic, iii) area-based 
methods, iv) counter-based methods, and v) neighbor knowledge schemes. Simple flooding is the sim-
plest broadcasting method in which each node retransmits an incoming packet once. Unfortunately, it is 
inefficient in terms of redundancy, resulting in the well-known broadcast storm problem. In probabilistic 
schemes, nodes rebroadcast the incoming packets with some probability. This forwarding probability 
can be calculated using numerous parameters such as density of nodes, distance between nodes, and the 
speed of nodes, among others. Area-based approaches require nodes to be equipped with a positioning 
system like the Global Positioning System (GPS) or they should implement a localization algorithm, for 
instance using the Received Signal Strength Indicator (RSSI), or other alternative measurement systems. 
Counter-based methods exploit the number of received copies of a given packet in order to estimate the 
density of nodes and to obtain feedback on the broadcasting process in the node’s neighborhood. The 
basic idea is that nodes do not need to retransmit if a certain number of neighbor nodes have already 
retransmitted a given packet. Finally, neighbor knowledge methods use topological information in order 
to select a set of neighbor nodes as potential forwarders.
Another basic classification of broadcasting approaches divides them into two main groups: i) deter-
ministic approaches, and ii) probabilistic approaches. In deterministic approaches a subset of all nodes in 
the network is selected as optimal forwarders, thus these nodes always forward an incoming packet. This 
type of broadcasting presents some shortcomings. First, under node mobility conditions, the algorithm 
used to select the optimal forwarders must determine the nodes belonging to this subset continuously. 
However, it can be difficult or costly in terms of data exchange depending on the dynamics of the network 
and the information required by the algorithm. Second, in networks with limited energy resources such 
as WSN, the subset of selected forwarder-nodes will deplete their energy quickly, resulting in network 
partitioning. Third, deterministic approaches are more prone to suffer from the presence of malfunctioning 
nodes and malicious nodes, e.g., in the case that a malicious node is selected as a forwarder. For these 
reasons, in this book chapter is only considered probabilistic broadcasting algorithms.
Well-Known Probabilistic Broadcasting Algorithms
•	
Flooding (Conti & Giordano, 2015): This is the simplest broadcasting method in which each 
node retransmits an incoming packet once. Unfortunately, it is inefficient in terms of redundancy, 
resulting in the well-known broadcast storm problem.
•	
GOSSIP (Haas, Halpern & Li, 2006): This is the simplest probabilistic approach. In this algo-
rithm, the nodes forward an incoming packet with a fixed probability p, and the probability of not 
forwarding the incoming packet is 1 – p.
•	
P-Persistence (Wisitponghan et al., 2007): In this algorithm the forwarding probability p is de-
termined linearly with the relative Euclidean distance between two nodes i and k according to the 
following expression:
p
d
r
d
r
ik
ik
=
≤
≤
,0
	
(1)
In (1), r represents the nodes’ radio transmission range and dij the Euclidean distance between nodes i and j.

114
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
•	
Polynomial (Busanelli, Ferrai & Gruppini, 2012): The main objective of the polynomial broad-
cast protocol is to reduce the number of retransmitted packets compared with the p-persistence 
algorithm. The forwarding probability is obtained as follows:
p
d
r
ik
g
= (
) 	
(2)
The main difference from the p-persistence protocol is the exponent g. The forwarding probability 
function can be tuned by g. In (Busanelli, ferrai & Gruppini, 2012) the authors evaluate the polynomial 
broadcast protocol with different values of g, such as 0, 1, 2, 5, 10, and 20. They concluded that for a 
low density network, g = 1 (p-persistence protocol) is the best option to ensure high reachability.
•	
Irresponsible Forwarding (Panichpapiboon & Ferrari, 2008): This algorithm combines the 
relative distance between two nodes i and k and also uses the density of the neighborhood to obtain 
the retransmission probability. The retransmission probability is given by the next equation:
p
F
r
d
xij
ik
c
=
−
−
(
(
))
1
1
	
(3)
The main idea is that the forwarding probability of a node should be proportional to the probability 
that there is not node in the distance of r-dik. It means that there is not a node located at a higher distance 
from the sender.
Evaluation of Broadcasting Algorithms in Disaster Scenarios
After carrying out an extensive literature study, the authors have not found any work that evaluates 
broadcasting algorithms in disaster scenarios. Most of the existing studies are focused on the evalua-
tion of routing protocols (Shenbagapriya & Kumar, 2014)(Kaur, Sahni & Bala, 2013)(Quispe & Galan, 
2014) in this kind of scenarios.
MODELLING DISASTER SCENARIOS
Modeling disaster scenarios for carrying out simulation studies is of paramount importance. Normally 
in MANET simulation studies, mobility models are used to define the movements of nodes during the 
simulation time. Notice that this fact impacts importantly in the communication among nodes. Therefore, 
the considered mobility model should reflect real conditions in order to conduct a reliable evaluation 
of MANETs.
Existing Mobility Models for Disaster Scenarios
Nowadays, modeling the behavior of people in catastrophe situations is one of the objectives of the 
disaster mobility models. However, disaster areas are scenarios where it is difficult to know in detail 

115
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
because the disaster actually changes significantly the previous structure of the area due to broken roads, 
collapsed buildings, etc. In (Pomportes, Tomasik & Vecque, 2010)(Pomportes, Tomasik & Vecque, 
2011), the authors proposed a new mobility model, namely Composite Mobility (CoM), to model the 
mobility of humans in these situations. This model is based on three different aspects: i) realistic hu-
man movements, ii) group mobility and iii) obstacle avoidance. To model the movements of the injured 
and rescue teams, they use other well-known mobility models like the Levy-Walk (Rhee, Shin, Hong, 
Lee & Chong, 2008). The main reason is that this mobility model is quite realistic for emulating human 
movements. In addition, to model the movements of the rescue team workers, CoM used the Point Group 
Mobility (PGM) model (Hong, Gerla, pei & Chiang, 1999). Finally and to solve the obstacle avoidance 
problems, a modification of Voroni diagrams is used (Jardosh, Belding-Royer, Almeroth & Suri, 1999).
In (Conceicao & Curado, 2013), the authors propose another mobility model for disaster scenarios 
which mimics the real movements in search operations. The behavior of rescue workers when perform-
ing search-for-victims operations is modeled. The people maintain short distance between them with 
the objective of discovering new victims and can communicate these discoveries between them. Due to 
this fact, the authors in (Conceicao & Curado, 2013) propose two different distance values to control the 
movement of victims. On the one hand MaxDistance, an injured person has to be separated to another one 
by a distance lesser than this value. On the other hand MinDistance, the distance between two victims 
must be higher than this value. When nodes are not within these restrictions, it is defined a force which 
moves them into an optimal location.
In these situations is also important to model the behavior of the rescue team, specially the first 
responders. In (Jardosh, Belding-Royer, Almeroth & Suri, 1999), it is presented CORPS (Cooperation, 
Organization and Responsiveness in Public Safety) which models the behavior of the first responders. It 
bases the movements on three different aspects: i) people are organized and follow tactical movements; 
ii) they cooperate with each other within a group and iii) they present responsiveness to events occur-
ring in the disaster area. Moreover, CORPS is based on three different components: the first responder 
model, the event model and the interaction model. Each person is labeled with a role and people with 
the same role compose a group. The event models capture physical events happening in time and space. 
Each first responder has a role and the first responders with the same role have similar attributes and 
cooperate on events. These events are classified into two types such as attention and caution events. In 
the former, injured victims need assistance from the first responders. On the other hand, caution events 
correspond to situations in which there are not people involved in the accident, for example, chemical 
spill and explosions. Finally to create the mobility model is necessary the interaction between the first 
responders and the events. This process is named interaction model. Each first responder sees the inci-
dent areas as the sum of attending and forbidden zones and bases his/her movements on these aspects. 
CORPS gives a high level of realism to the first responder movements. However the victim movements 
in the disaster scenario are not model by CORPS.
The Disaster Area Mobility Model
This model is the so-called Disaster Area mobility (“Bonnmotion”, 2016) model, which is included in 
the open source mobility generator BonnMotion (“Bonnmotion”, 2016). Notice that the Disaster Area 
mobility model defines tactical movements of a rescue team, but it does not take into consideration 
movements of victims in the disaster area. The Disaster Area mobility model is based on a method 
called separation of rooms (“Bonnmotion”, 2016). Using this method, the disaster scenario is divided 

116
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
into different areas. These tactical areas are: (i) incident site, (ii) casualties treatment area, (iii) transport 
zone, (iv) technical operational command zone and (v) hospital zone.
•	
Incident Area: It is the place where the disaster happened. In this area, people injured are waiting 
for being rescued and being transported to treatment areas.
•	
Casualty Treatment Area: There are two places in this area. First, the place where patients wait 
for their treatment, which is named patients waiting for treatment area. And the other one is called 
the casualties clearing station, where injured people are transported after receiving their first aids. 
In a casualty treatment area, nodes are waiting for being transported to a hospital.
•	
Transport Zone: It is the zone where ambulances and helicopters wait to take injured people and 
transport them to hospitals.
•	
Technical Operational Command Zone: It is the place where the rescue operations are com-
manded, normally inside the casualty treatment areas.
•	
Hospital Zone: the vehicles of the transport zone transport the patients to the hospital. Normally 
these zones are not in the disaster area, for this reason ambulances always leave and arrive of the 
network.
All the areas mentioned above are modelled as squares. In each of these squares, the nodes mobility 
is modelled with the Random Waypoint Mobility model. Each sub-area has entrance points; these are 
specific locations at the edge of each sub-area that are used by the first responders to move victims from 
one sub-area to another.
Figure 3 shows the movements followed by the members of a rescue team in a disaster scenario 
according to the disaster area mobility model. Each colored line in Figure 3 represents a different 
Figure 3. Disaster area movements

117
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
crewmember movement. Each area such as Incident Location (IL), Patient Waiting for Treatment Area 
(PWFT), Casualty Clearing Station (CCS), Technical operation area (TEL), and Ambulance Parking 
area (APP) are marked.
The Disaster Area mobility model has already been used to simulate the movements of crewmembers 
in real disaster scenarios such as the disaster in Germany in 2005 during the preparation of the World 
Youth Day 2005, the FIFA Soccer World Cup 2006 (Achenbruck, Gerhaps-Padilla, Gerharz, Frank & 
Martini, 2007), the disaster scenario based on a suspension railway crash that happened in Wurppertal in 
1999 (Aschenbruck, Frank, Maritni & Tölle, 2004), and the disaster scenario based on a fire in amuse-
ment park near Cologne in 2001 (Aschenbruck, Frank, Maritni & Tölle, 2004).
Disaster Area mobility model is one of the most used mobility models to evaluate communications 
protocols in disaster scenarios. For this reason, this model will be used in this book chapter. However, other 
mobility models are available and they could be used in future works to apply the proposed methodology.
Communications in the Disaster Area Mobility Model: Inter-
Communications vs Intra-Communications
Since crewmembers in the disaster area mobility model are grouped into different areas, two possible 
types of communications among them are considered such as i) inter-communications and ii) intra-
communication. The former type of communications is established between two nodes that are moving 
inside different zones or tactical areas. For instance, this kind of communications can be established 
between the transport zone and the hospital zone to coordinate the transport of an injured person (see 
Figure 4). On the other hand, intra-communications are established between two nodes that are located 
inside the same zone. For instance, two firefighters moving inside the incident location area. It is obvious 
Figure 4. Example of source movements for inter and intra communication

118
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
that path availability can be significantly different for inter-communications and intra-communications 
due to fact that the distances between the people inside the same area are much smaller than the distances 
between two different areas. Figure 4 depicts two examples of the movements of source nodes for the 
two types of communications described.
THE PROPOSED EVALUATION METHODOLOGY FOR EVALUATING 
COMMUNICATION PROTOCOLS IN DISASTER SCENARIOS
This section describes the proposed evaluation methodology. Before presenting the proposed methodology 
some previous efforts made on improving the evaluation of MANET communications are summarized. 
Then, the proposed methodology is divided into two subsections, one focused on routing protocols, and 
another for broadcasting algorithms.
Good Simulation Practices in MANET Simulation-Based Studies
With regard to the evaluation of MANET routing protocols by using simulation analyses, in many simu-
lation studies have been detected a set of bad practices followed by researchers (Hiranandani, Obraczka 
& Garcia-Luna-Aceves, 20004)(Kurkowski, Camp & Colagrosso, 2005). In (Hiranandani, Obraczka & 
Garcia-Luna-Aceves, 20004), the authors underline random selection of source-destination pairs in the 
traffic patterns, as one of the key problems for the evaluation of MANET routing protocols. But this is not 
only the main reason for obtaining non reliable simulation results. In (Kurkowski, Camp & Colagrosso, 
2005), the authors also describe several bad practices commonly used in simulation studies. They classify 
such bad practices into four categories, such as simulation setup, simulation execution, output analysis, 
and publishing problems. Simulation setup problems refer to the use of default variables in both the 
simulator and the routing protocols under test. In the simulation execution category are included those 
factors that affect the simulation runs, like the pseudorandom number generator and erroneous metric 
measurements. Output analysis refers to the statistical analysis carried out by researchers with the output 
traces of a given simulator. For instance, a common bad practice in this sense is that researchers do not 
add confident intervals in graphs. Publishing problems are related to the lack of discussion about the 
obtained simulation results. Furthermore in (Andel & Yasinsac, 2006), the authors also show a list of 
detected problems in simulation analyses. They include aspects such as the lack of statistical validity, the 
use of inappropriate radio models, and the lack of independent repeatability, among others. They also 
provide some recommendations to solve the detected problems such as the use of two-ray and shadow 
models as radio models in order to provide more realistic environments, and the number of required 
independent runs to ensure reliable simulation results, among others. Additionally, in (Vallati, Omwando 
& Mohapatra, 2013), the authors categorize the source of simulation result inaccuracies into two main 
groups. On the one hand, improper simulation practices due to mistakes made by the researchers at the 
time of simulations. On the other hand, simulation model inconsistences, which require modifications of 
the simulation model in order to fix such inconsistences. To validate simulation models and fix inaccura-
cies, the authors show a workflow in which they depict a sequence of good practices to be followed such 
as verifying the implementation model, validating its assumptions and then calibrating input parameters. 
This chapter takes into account many of the problems indicated in the previous works on the evaluation 

119
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
of routing protocols, and it also proposes an evaluation methodology to solve some of them. It includes 
a procedure to select source-destination pairs based on path availability, number of hops and number of 
reconnections between source and destination nodes.
Evaluation Methodology for MANET Routing Protocols in Disaster Scenarios
The idea is to extend the methodology proposed in (Garcia-Campos, sanchez-Garcia, Reina, Toral & 
Barrero, 2016) in disaster scenarios. In (Garcia-Campos, sanchez-Garcia, Reina, Toral & Barrero, 2016), 
the authors propose a methodology for VANET routing protocols. This methodology includes aspects 
such as i) measurement periods, which ensure the stability of some simulation aspects, ii) the selection 
of communication pairs based on the path availability, iii) the separation in terms of the number of hops 
between the source and destination nodes, and iv) the repetition of source and destination nodes. Also 
this technique proposes to fix the number of simulations and the mobility model and select the proper 
performance metrics. All these aspects aim to improve the reliability of routing protocols simulation results.
Communication Set Up
To evaluate the behavior of routing protocols it is necessary to ensure that relevant simulation aspects are 
properly configured to obtain reliable simulation results. The communication set up period is the time 
required to guarantee that the communication and mobility of nodes are not in a transient period. The 
objective is that the performance metrics must be measured in stable conditions. In (Garcia-Campos, 
sanchez-Garcia, Reina, Toral & Barrero, 2016), the authors proposed to use a warm up period to obtain 
reliable and non-dispersed simulation results. This idea is used in this work. For that, Figure 5 shows 
Figure 5. THR vs Warm Up Values

120
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
different values of Warm Up periods (from 0 to 100s). Then, the throughput metric (THR in Figure 5), 
which measures the number of application packets delivered during the simulation time. In this study, five 
different source and destination nodes are selected randomly and the distinction between intra and inter 
communications are not taken into account. Figure 5 shows as the Warm up value increases, the THR 
also increases. It is due to the fact that the number of source nodes that have started to transmit packets 
is higher. From 50s (see Figure 5 for more details) is observed that the THR values are the same. Related 
to the confidence intervals, they are vey similar and high because the source and destination pairs are 
selected randomly. From now on, 50s is considered as the Warm Up value for the scenario under test.
Communication Flow Selection
In most simulation-based studies of MANET routing protocols (Vallati, Omwando & Mohapatra, 2013), 
source and destination nodes are selected randomly among all nodes forming the network. Using such 
random selection, simulation results can vary for the following reasons. First, the authors cannot guar-
antee that all source-destination pairs have similar properties in terms of number of hops and path avail-
ability. All of the mentioned aspects impact on simulation results. The worst situation in terms of path 
availability would occur when it is impossible to establish a communication path between the source 
and destination nodes (Wang, Wang, Cui & Yang, 2015). Regarding the number of hops, the authors 
also should guarantee that on average the selected communication flows have a similar separation. If 
the maximum and the minimum number of hops necessary to reach destination nodes are not fixed, 
it could happen that the authors select pairs which do not need any hop to reach the destination nodes 
(direct communications). Notice that this situation is not desirable for evaluating routing protocols in 
multi-hop ad hoc network like MANETs. In general, routing protocols are intended for establishing a 
multi-hop communication path. Consequently, the authors need to guarantee that the minimum number 
of hops between the source and destination nodes is higher or equal than 2.
The selection mechanism (Garcia-Campos, sanchez-Garcia, Reina, Toral & Barrero, 2016) should 
guarantee that there are enough communication pairs that meet the restrictions in terms of path avail-
ability and number of hops. According to that the first step is to measure the availability path (APA) and 
select pairs according to the duration of their routing paths. The target APA should be chosen to ensure 
a minimum and acceptable number of communication pairs. After selecting the target APA value, the 
next step is to select pairs which are separated by the same or similar number of hops. The target hop 
value is selected as the maximum available value which ensures that there are enough pairs. In general, 
the number of hops between source and destination nodes should be higher than 1 in order to ensure a 
multi-hop path.
Table 2 THR vs Warm up values
Warm up Values 
(s)
0
25
50
75
100
THR (Kbps)
Mean
0.4461
0.4540
0.4620
0.4742
0.4742
Confidence interval
± 
0.0103
± 
0.0086
± 
0.090
± 
0.01028
± 
0.01029

121
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
Next, the authors show how to apply the proposed methodology in disaster scenarios (scenario under 
test). The procedure is as follows:
•	
First, the distribution of the APA and number of hops for all the possible communication pairs 
(source-destination) are obtained.
•	
Then, the researchers select the most representative values for both metrics.
•	
Finally, benchmarking the performance of AODV routing protocol (baseline routing protocol) to 
show the importance of both metrics in the performance of routing protocols.
APA Distribution
The first step is to measure the APA distribution in the scenario under test in order to fix the target APA. 
Since, two types of communications (inter and intra communications) have been considered. Conse-
quently, two possible APA distributions are obtained, one distribution for inter-communications and 
another for intra-communications. It is expectable to have low values of the APA distribution for inter-
communications, however there can be some of them with higher APA value. In the APA distribution 
for intra-communication case, it is expectable that the most pairs will have a high APA value. To show 
this situation in Figure 6 is depicted the APA distribution for intra and inter communications.
Most of APA values for Intercommunication case are zero (see Figure 6). It means that the commu-
nications between areas are not possible because these areas are widely separated. Related to the target 
APA, a high number of pairs is necessary to ensure. For that 0.4 is set as the target APA for the inter 
Figure 6. APA distribution for Inter and Intra communication

122
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
communication case. In the intra communication case, the target APA is set in 0.7. Obviously the value 
1.0 is the best one but this situation can correspond to destination nodes which are within the source 
transmission range node and the routing protocols are not necessary.
Hop Distribution
After selecting pairs based on the APA, the next step is to select pairs based on the distance in terms of 
number of hops. For that, the target hop is chosen to ensure pairs which are separated by the same or 
similar number of hops. In this step, intra-communication and inter-communication are also distinguished. 
In order to ensure a multi-hop path, the highest separation between source and destination nodes are used 
to select pairs. Similar to the previous APA distribution section, the authors also should ensure that there 
are enough source-destination pairs. Figure 7 shows the hop distribution for both cases.
The idea is to select a target hop value from the highest possible value that ensures a high number 
of available pairs. This value corresponds to 4 hops for both cases (see Figure 7). Figure 7 summarizes 
the proposed source destination node selection.
Figure 7. Hop distribution for Inter and Intra communication
Table 3. Source destination selection summary
Target APA
Target Hop
Intra Communication
0.4
4
Inter Communication
0.7
4

123
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
Number of Simulations
The motivation for this idea is to not devote more time than necessary to conduct simulations while 
ensuring good results in terms of mean and dispersion. For that reason, the number of simulations has 
to be selected to ensure a representative data sample without requiring a lot of simulation time. In con-
sequence, the balance between the number of simulations and computing time has to be reached. Figure 
8 shows the throughput results (THR) and the required computing time for different number of traffic 
seeds (number of simulations). For this study the authors use the same scenario than in previous studies 
(the scenario under test) and five different pairs are used, the selection of these pairs are based on the 
proposed methodology. Orange bars represent the selected pairs based on the used methodology and 
yellow bars represent the random selection (See Figure 8). Both, intra and inter communications are 
distinguished in Figure 8. In Figure 8 is showed that the results are lesser scattered in the case of applying 
the proposed methodology (vertical interval in Figure 8than in the case of not using this methodology 
(vertical green interval in Figure 8). For low number of simulations, the obtained simulation results are 
not scattered (see Figure 8 for more details). Comparing the results with high number of simulations 
the differences are smaller. Consequently, five simulations is the best number due to the fact that good 
results are obtained in terms of dispersion and the computing time is low as well.
Figure 8. THR vs Number of simulations

124
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
Benchmarking the Methodology with AODV, LAR and 
DYMO Routing Protocols in the Disaster Scenario
In this subsection the authors use AODV as standard routing protocol to benchmark the proposed meth-
odology. AODV is evaluated using the proposed APA metric and the number of hops. In this study, intra 
and inter communications are distinguished. The throughput and the NRL metrics (see subsection 5.1.1 
for a definition of performance metrics) are used.
To highlight the importance of the APA in the performance of the routing protocols, Figure 9 shows 
the throughput (THR in Figure 9) for different values of APA, for inter and intra communication cases 
(orange bars in Figure 9). Figure 9 also depicts the obtained results when the methodology is not used, 
Table 4. Statistics measures for THR vs number of simulations
Using the Methodology
Intra Communications
Nº Simulations
5
10
15
20
25
30
THR (Kbps)
Mean
0.6493
0.6454
0.6415
0.6394
0.6355
0.6353
Confidence interval
0.0203
0.0155
0.0132
0.0116
0.0111
0.0102
Computing time (s)
Inter Communications
THR (Kbps)
Mean
0.2437
0.2392
0.2296
0.2331
0.2325
0.2342
Confidence Interval
0.0156
0.0115
0.0113
0.0098
0.0088
0.0076
Computing time (s)
26.26
80.96
145.32
228.69
290.55
351.14
Not using the Methodology
Intra Communications
Nº Simulations
5
10
15
20
25
30
THR (Kbps)
Mean
0.3339
0.3373
0.3472
0.3414
0.3390
0.3397
Confidence interval
0.1565
0.1085
0.0880
0.0749
0.0660
0.0597
Computing time (s)
13.25
62.58
113.66
164.59
221.77
275.89
Inter Communications
THR (Kbps)
Mean
0.3915
0.3768
0.3720
0.3760
0.3698
0.3712
Confidence Interval
0.1490
0.1045
0.0842
0.0730
0.0650
0.0591
Computing time (s)
9.41
45.75
81.62
119.08
155.36
194.04

125
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
NUUM (Not using the used methodology), (yellow bar in Figure 9). For this analysis, the authors select 
APA values which ensure a minimum number of pairs (Figure 6). The authors also add another restriction 
in the selection of the pairs based on APA such as the fact that the communication pairs can not be repeated. 
Figure 9 shows that as the APA value increases the number of delivery packets also increases due to fact 
that the available path is higher. The tendencies in both cases are to increase as the APA value increases. 
Related to NUUM results, the researchers can see that the results are worst in terms of mean and also they 
are more scattered (blue interval in Figure 9). Table 5 contains more details about the obtained results.
Figure 9. Throughput vs APA
Table 5. THR vs APA values in the scenario under test
Intra Communication
APA value
0.6
0.8
1.0
NUUM
THR (Kbps)
Mean
0.4498
0.6113
0.8895
0.08172
Confidence interval
± 0.0092
± 0.0103
± 0.0039
± 0.0233
Inter Communication
APA value
0.4
0.6
0.8
1.0
NUUM
THR (Kbps)
Mean
0.3294
0.5333
0.7226
0.8540
0.1313
Confidence interval
± 0.0116
± 0.0134
± 0.0193
± 0.0059
± 0.2260

126
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
Second, the performance of AODV based on the number of hops is studied. Again, the THR (orange 
and yellow bars in Figure 10 respectively) and the NRL metrics (red points in Figure 10) are used. Figure 
10 depicts that as the number of hops increases the number of delivery packets decreases in both of cases. 
The reason is that the number of lost packets increases. Regarding the congestion, the NRL increases 
when the numbers of hops increases. This situation happens in both types of communications because 
the number of routing packets is higher. Related to NUUM results, for intra and inter communication 
cases. On the one hand, in the intra communication the THR mean is lower and more scattered (see 
vertical blue intervals in Figure 10) than when using the proposed methodology. The reason is that the 
selected pairs cannot be established or the links are broken many times. Related to the NRL, means and 
confidence intervals are depicted with red points and red vertical intervals, respectively. NRL is high 
in terms of mean value because the number of routing packets increases. However, the dispersion is 
low because the pairs are selected based on the proposed methodology. On the other hand, for the inter 
communications the THR mean is also lesser and more scattered because there are pairs which can never 
establish communications. Similarly, the obtained NRL mean is lesser than when using the proposed 
methodology. That means that there are some pairs which never establish communication between them, 
and in consequence, the number of routing packets is low. For more details see Table 6.
Evaluation Methodology for MANET Broadcasting Algorithms
Based on the idea proposed in (Garcia-Campos, sanchez-Garcia, Reina, Toral & Barrero, 2016), a 
modification is proposed to be applied in broadcasting communications. Broadcasting operation aims to 
maximize the reachability in the network. That is the number of nodes that can be reached from a given 
source node. To achieve this goal, it is very useful to be able to study and analyze the number of reach-
able nodes for each possible source node in a network. In simulation studies of MANET broadcasting 
algorithms, sources are selected randomly. It means that a set of sources nodes among all nodes in the 
Figure 10. Throughput and NRL vs Number of hops

127
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
network are selected to generate the broadcasting packets. Then, depending on the broadcasting algorithm, 
the nodes retransmit the packets throughout the network. The random selection can affect negatively 
the simulation results for different reasons. The main one corresponds to the scenario, where the source 
nodes could have very different number of reachable nodes from each other. It could be possible even 
the selection of source nodes that do not have any reachable node (isolated nodes).
Furthermore, there is another aspect that can affect the simulation results. It corresponds to the dis-
tance to the reachable nodes in terms of number of hops with respect to the source nodes. If the number 
of hops is high, there are more options to lose some packets than in the case when the number of hops 
is low. For instance, the packets can be lost in intermediate node buffers or due to collisions with other 
packets. Consequently, the simulation results can drastically vary for different source nodes. To solve this 
problem the authors propose to select the source nodes based on these two aspects that can be configured 
properly in the simulation set up.
Communication Set Up
As the authors proposed in (Garcia-Campos, sanchez-Garcia, Reina, Toral & Barrero, 2016), for broad-
casting studies it is also necessary to select some aspects related to the measurement period. That is, the 
time stamps when the performance metrics begin and finish measuring. To accomplish this objective, the 
authors propose to initiate the evaluation of the performance metrics after starting the first broadcasting 
process, and then finish the measurement period once the last process has finished. This technique avoids 
having packets that are not considered during the simulation. If the measurement period stops earlier, 
some packets cannot reach all reachable nodes because some of them need more time in intermediate 
node buffers.
Table 6. THR and NRL vs Hop values in the scenario under test
Intra Communication
Hop Value
1
2
3
4
NUUM
THR (Kbps)
Mean
0.8338
0.6666
0.6220
0.6111
0.0807
Confidence interval
± 0.0191
± 0.0084
± 0.0112
± 0.0085
± 0.0236
NRL
Mean
2.9772
8.9015
14.3905
24.0647
25.1483
Confidence interval
± 0.0550
± 0.1564
± 0.2434
± 0.5050
± 0.6523
Inter Communication
Hop Value
3
4
5
NUUM
THR (Kbps)
Mean
0.3288
0.3119
0.2991
0.1335
Confidence interval
± 0.0140
± 0.0125
± 0.0131
± 0.0346
NRL
Mean
33.8539
50.4297
77.5827
63.0468
Confidence interval
± 0.5895
± 1.1534
± 1.6087
± 1.9991

128
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
Number of Simulations
The number of simulations is another important aspect which has to take into account to conduct simu-
lation-based studies. However when this one increases, the computing time consumption also increases. 
For that, it is very important to find the balance between the number of simulations and the consumed 
time. Figure 11 depicts the Re metric (reachability, see subsection 5.1.1) using and not using the pro-
posed methodology, P.M., (orange and yellow bars respectively). The computing time (red and black 
points respectively) is also depicted. For this study, the scenario is the same that in previous sections 
(the scenario under test) and the sources are selected based on the proposed methodology and random 
selection. Related to Re, the results are better in terms of mean not using the P.M. However, they are 
also too scattered because there are some sources which have a high Re but there are other which have 
a low Re. For this reason the dispersion is also high (green vertical interval in Figure 11). However, 
focusing on the case in which the P.M. is used, the computing time is lower and the results are lesser 
scattered (blue vertical interval in Figure 11) due to the fact that these sources are selected based on the 
same properties. Consequently, using the P.M. reliable simulation results can be obtained with a low 
number of simulations (see Table 7). From now on, 5 sources are considered as the best option because 
the results are not scattered and the computing time necessary to obtain them is quite low.
Source Node Selection
The selection mechanism proposed in this section avoids the random selection of the sources among 
all available nodes in the network. The random source node selection can make the simulation results 
vary for the following reasons. First, the authors can not guarantee that all source nodes have similar 
properties in terms of number of hops and reachable nodes. Related to the number of reachable nodes, 
the worst case corresponds to source nodes which do not have any reachable node or source nodes can 
have different number of reachable nodes. Both situations affect negatively the simulation results. To 
solve this situation, a new metric is proposed, which helps us to select source nodes based on the number 
of reachable nodes. This metric is named partition degree (PD). The partition degree is defined as the 
ratio of nodes (percentage) that are reachable from the source node through a multi-hop path. Notice 
that this metric is similar to the APA metric defined for the routing protocols. However, in broadcasting 
operation there is not a destination node. Instead, the authors should analyze the number of nodes that 
can be reached from a given source node.
Figure 11. Re and Computing time vs Number of simulations

129
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
Another aspect that is taken into account is the distance in terms of number of hops between the 
source nodes and the rest of reachable nodes. If the separation is high, the probability of losing packets 
for some reason is higher than for small separations. This is known as the die out problem in broadcast-
ing operation. There are nodes that occupy central positions in the network so they have the rest of the 
nodes at a lower distance. Conversely, nodes located at the periphery of the network will have to pass 
their packets through a high number of intermediate nodes to reach the other extreme of the network. 
Therefore, it is clear that the position of the source node in the network is an important parameter to be 
considered for the source node selection.
A new metric is proposed, Average hop to reach the reachable nodes (AHRN), to take into consid-
eration the position of the selected source nodes in the network. This metric is measured as the average 
distance, in terms of number of hops, from each source node to all their reachable nodes. To measure 
this metric the authors consider that all nodes can be source nodes. Based on this concept, the number 
of hops from each source node to all reachable nodes is measured and finally the mean is calculated.
Based on these new metrics, PD and AHRN, a selection mechanism is proposed to select source nodes. 
This mechanism should guarantee that there are enough source nodes that meet the restrictions in terms 
of PD and AHRN. The first step is to measure the partition degree (for each node) and select the source 
nodes according to the PDs found in the network. The idea is that if all the sources are selected with the 
same or similar PDs, the dispersion of the results will much lower. Consequently, a lower number of 
simulations to obtain reliable results will be needed. It is important to point out that a target PD value 
has to be chosen to ensure a minimum number of source nodes. This means that the selected PD should 
be representative among all the PDs that can be found in the network topology. The same strategy is 
necessary to select the source nodes based on the average hops to reach the reachable nodes. That is to 
select a target AHRN that ensures a minimum number of source nodes. Next, the procedure follows to 
use the proposed methodology in disaster scenario (scenario under test) is shown:
Table 7. Statistics measures for THR vs number of simulations
With P.M.
Number of simulations
5
10
15
20
Re
Mean
0.2472
0.2468
0.2466
0.2467
Confidence Interval
0.0015
0.0015
0.0011
0.0095
Computing time (s)
100.25
177.36
254.16
331.58
Without P.M.
Re
Mean
0.1776
0.3095
0.3064
0.3283
Confidence Interval
0.1591
0.1068
0.0838
0.0661
Computing Time (s)
107.98
192.14
271.69
348.79

130
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
•	
First, the distribution of the PD and AHRN metrics for all the possible source nodes in the network 
is obtained.
•	
Then, the most representative values for both metrics are selected.
•	
Finally, showing the importance of both metrics in the performance of broadcasting algorithms.
Partition Degree Distribution
Firstly, the partition degree distribution is obtained in the scenario under test in order to select the target 
PD. For this study, intra and inter communications are not distinguished. Due to the big dimensions of the 
scenario, it is expectable that the most of possible sources will have a low PD value. According to Figure 
12, the maximum PD obtained is 0.55. This means that only 55% of nodes are reachable in the best case.
Figure 12 shows the most of the PD values are close to 0.5. This means that on average each node 
has around 50 reachable nodes. Therefore, a PD of 0.5 is a representative value of the PD of the net-
work. Nevertheless, there are some nodes which have a low number of reachable nodes. This situation 
corresponds to nodes which are more isolated. Related to the target PD, the authors have to ensure a 
high number of source nodes with this value and the highest one is interested because the authors want 
to reach the maximum number of nodes. For that, the target PD is fixed to 0.5. The number of source 
nodes for that value is around 45 (see Figure 12).
Average Hops to Reach the Reachable Nodes Distribution
After the selection of sources based on PD (PD=0.5), the next step in the proposed procedure is to select 
sources based on AHRN. Again, the AHRN distribution in the scenario under test (see Figure 13) is 
Figure 12. PD Distribution

131
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
necessary to obtain. Then, a representative target AHRN should be chosen to ensure that the reachable 
nodes are separated by the same number of nodes.
Figure 13 shows that 5 hops is a representative value that guarantees a suitable evaluation of the 
broadcasting algorithms. As a summary of the source node selection, Table 8 shows the representative 
values of the source node selection procedure.
Benchmarking the Methodology with Flooding Algorithm
In this subsection flooding is used as a baseline broadcasting algorithm to benchmark the proposed meth-
odology. This one is evaluated using the proposed metric, PD and AHRN, respectively. The Re metric 
is used to evaluate the proposed methodology. To show the importance of the PD, Figure 14 depicts 
Re for different values of PD. For this study, a representative PD values (see Figure 12) are selected. 
In Figure 14 is shown that as the PD value increases the number of packets that reach the destination 
is higher. Therefore, there are big differences in the performance of flooding algorithm depending on 
the PD selected. This situation is shown as follow. For instance, if two sources are selected randomly, 
their PDs could be 0.25 and 0.5 respectively (see see Figure 12). For these PD values the obtained Re 
metric values are 0.25 and 0.36 (see Table 9) approximately. The resulting Re mean for both values 
is 0.3 and the confidence interval is 0.3069. The obtained confidence interval is quite high. However, 
when applying the proposed methodology, it guarantees that the obtained Re values are closer to the PD 
value selected. This situation illustrates that different values of PD mean that the network conditions are 
Table 8. Source node selection summary
Target PD
Target AHRN
0.5
5
Figure 13. AHRN Distribution

132
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
different for each case. For that, it is important to evaluate the broadcasting algorithms under the same 
network conditions. Guarantying similar network conditions, results will be less disperse (Figure 14).
To demonstrate the importance of the source selection based on AHRN, in Figure 15 is depicted the 
obtained Re metric values for each value of number of hops. Figure 15 shows that the results are not 
scattered, it means that the selected sources have the same properties in terms of network conditions.
Let us illustrate with an example the importance of selecting the source nodes based on AHRN metric. 
If sources are selected randomly, they could have AHRN metric values equal to 3 and 5 respectively, 
consequently their Re values will be 0.25 and 0.46 approximately (see Table 10). The mean value will 
be 0.35. Related to the confidence interval, it will be 0.3527 which is high compared with the mean.
Figure 14. Re vs PD
Table 9. Re vs PD values in the scenario under test
PD value
0.25
0.4
0.5
Re
Mean
0.2479
0.3312
0.3576
Confidence interval
± 0.0003
± 0.0052
± 0.0044

133
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
VALIDATION OF THE PROPOSED METHODOLOGY: A COMPARISON 
OF COMMUNICATION PROTOCOLS IN DISASTER SCENARIOS
This section is focused on validating the proposed methodology using the disaster area mobility model 
and realistic conditions. The idea is to compare a high number of communication protocols (routing and 
broadcasting) in a disaster scenario. First, the simulation environment is detailed in order to conduct the 
simulation study. Then, some widely used routing and broadcasting algorithms for MANETs are evaluated.
Simulation Environment
For the evaluation, the authors use NS-2.34 (“ns”, 2016) under Debian Linux operating system. The NS-2 
is the most used simulation tool for replicating real life networking environments. To simulate disaster 
mobility, the authors use the disaster area mobility model included in Bonnmotion (“Bonnmotion”, 
2016). Table 11 summarizes the general simulation settings used. Regarding the propagation model, the 
Table 10. Re vs AHRN values in the scenario under test
Hop value
3
4
5
Re
Mean
0.2468
0.2479
0.4665
Confidence interval
± 0.0009
± 0.0005
± 0.0024
Figure 15. Re vs AHRN

134
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
two-ray ground (Fogue et al., 2012) reflection model is used because it gives more accurate prediction 
for long distances than the free space model.
Regarding the disaster scenario used for the validation and evaluation, the researchers use an imaginary 
simulation scenario which is composed of one incident location, one patient waiting for treatment area, 
two casualty clearing stations, one ambulance parking area, and one technical operation area. Table 12 
includes more details about the features of the technical areas. In Figure 3 is depicted the movements 
of each node.
Table 11. Simulation parameters
Parameter
Value
Simulation Time
300s
Warm up period
50s
Routing Protocols
AODV,DYMO, LAR
Broadcasting protocols
P-persistence, Irresponsible, Polynomial, 
Gossip and Flooding
Transmission range
500m
Number of Nodes
102
Transport protocol
UDP
Traffic Types
CBR
Maximum Packet in Queue
50
Packet Size (Application)
512 bytes (routing) 
1000 bytes (Broadcasting)
Packet routing Rate
1 packet/s
Number of broadcast packets
60 Packets
Area Size
4000*4000 m2
Mobility model
Disaster Area
Propagation model
Two-ray ground
Table 12. Features of the scenarios
Parameter
Values
Total number of nodes
102
Total area
4000 x 4000 m
Nº Incident sites (IL)
1, with 30 transport units (mobile nodes)
Nº Patient waiting for treatment areas (PWFTA)
1, with 8 transport units and 2 static nodes
Nº Casualties clearing areas (CCSn )
2, with 15 units transport each station
Nº Ambulances parking point (APP)
1, with 25 units transport, and 5 static nodes
Nº Technical operational command (TEL)
1, with 2 static nodes

135
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
Performance Metrics
Regarding the performance metrics used to compare the routing protocols, the selected performance 
metrics are:
•	
Throughput (THR): It is the sum of the data packets in the simulation period.
THR Kbps
DeliveredApplicationPackets
SimulationTime
(
) = ∑
	
(4)
•	
Average End-to-End Delay (E2E): It is defined as the time taken for a data packet to be transmit-
ted across an ad hoc network from the source to the destination node.
E E s
DelivedTime
TransmittedTime
NumberPacketsDelivere
2 ( )
(
)
=
−
∑
d
	
(5)
•	
Normalized Routing Load (NRL): It is the ratio of the total routing packets to the total delivered 
data packets.
NRL
RoutingPackets
DeliveredApplicationPackets
=
∑
∑
	
(6)
•	
Packet Delivery Fraction (PDF): It is the ratio of the number of packets delivered to the receiver, 
to the number of packets sent by the source.
PDF Kbps
DeliveredApplicationPackets
SentPackets
(
) = ∑
∑
	
(7)
Related to the performance metrics for the evaluation of broadcasting algorithms, the used ones are:
•	
Reachability (Re): The reachability is defined as the percentage of nodes in the network receiv-
ing a given broadcast packet. As a rule, a high reachability is a basic requirement for a broadcast 
scheme.
Re = Receivers
Nodes
	
(8)
•	
Number of Retransmission (NR): It is the number of the retransmitted packets.
•	
Broadcast efficiency (Be): It is defined as the ratio between the reachability (Be) and the number 
of retransmissions (NR).

136
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
Be
NR
= Re 	
(9)
Table 13 summarizes the desired values for each of the performance metrics for routing protocols 
and broadcasting algorithms.
Reliable Comparison of Routing Protocols in Disaster Scenarios
This part of our study is focused on presenting a fair and reliable comparison of MANET routing protocols 
in the disaster scenario under test. Boxplot graphs are used to depict these results and also the obtained 
mean is shown with green points. Also, the analysis is divided into intra and inter communications.
Intra Communications
Figure 16 shows the performance of used routing protocols for intra-communications. In general, the best 
results are achieved by AODV and LAR routing protocols. It can be easily seen that their mean values 
are better than those obtained by other routing protocols for the four metrics chosen for the evaluation. 
In terms of dispersion, AODV is less scattered than LAR. For this reason, AODV is selected as the best 
routing protocol for intra-communications. DYMO exhibits a high value of NRL that significantly af-
fects the rest of performance metrics.
Inter Communications
In general, the performance of routing protocols worsen for in inter communications (see Figure 17). The 
main reason is that the APA values that can be obtained are low for inter-communications. Notice that 
the maximum throughput obtained is about 0.4, which is obtained by LAR routing protocol. This value 
is significantly lower than the maximum value obtained by LAR protocol for intra-communications, 
which is about 0.65. In general, LAR presents the best results again.
Reliable Comparison of Broadcasting Algorithms in Disaster Scenarios
This subsection is focused on showing a comparison of probabilistic broadcasting algorithms in disaster 
scenarios using the proposed methodology. Probabilistic algorithms based on dissimilarity metrics and 
also well-known probabilistic broadcasting algorithms are compared.
Table 13. Desirable values for routing and broadcasting performance metrics
Routing performance metrics
THR
PDF
E2E
NRL
Desirable values
High
High
Low
Low
Broadcasting performance metrics
Re
NR
Be
Desirable values
High
Low
High

137
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
Figure 17. Used routing protocol simulation results. Inter Communications
Figure 16. Used routing protocol simulation results. Intra Communications

138
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
Comparison of Broadcasting Algorithms
The authors compare up to five different probabilistic broadcasting algorithms. P-persistence based on 
the Euclidean distance, flooding, Gossip based on fixed probabilities and p-persistence, polynomial and 
irresponsible based on dissimilarity metrics. The selection of the best dissimilarity metric is based on the 
study proposed in (Garcia-Campos, Sanchez-Garcia, Reina, Toral & Barrero, 2015). In this study, the 
Kulczynsky dissimilarity metric is selected as the best one among other dissimilarity metrics because 
it presents the best balance between Re and Be.
For this comparison, the used scenario is the same as in previous sections (the scenario under test), 
the sources are selected based on the proposed methodology.
Figure 18 shows the performance of the selected probabilistic broadcasting algorithms using Kulc-
zynsky dissimilarity metric, p-persistence based on the Euclidean distance, flooding and Gossip based on 
fixed probabilities. The best result in terms of Re is obtained by flooding and Gossip (p=0.8). However, 
the number of retransmitted packets is high. Consequently, the broadcast efficiency (Be in Figure 18) is 
low. If the authors want to reach many nodes and it is not important the congestion of the network, these 
broadcasting algorithms will be used. However, if a balance between Re and the number of retransmit-
ted packets is necessary, the authors should focus on the Be. Figure 18 shows the best obtained Be by 
Polynomial and Irresponsible broadcasting algorithms using Kulczynski dissimilarity metric.
Discussion of Simulation Results
This subsection aims to summarize the obtained simulation results in previous sections which were ob-
tained based on the methodologies described in this book chapter. For that, the researchers also divide 
Figure 18. Comparison of the broadcasting algorithms based on Kulczynsky dissimilarity metric

139
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
this one into two categories. On the one hand, among the routing simulation results, AODV presents 
the best behavior in terms of delivery packets, throughput metric, and end to end delay. However, LAR 
routing protocol achieves better results in terms of number of routing packets, NRL metric. It is due 
to the fact that LAR uses location information in its discovery phase. On the other hand, regarding the 
broadcasting algorithms, five different algorithms are compared and the best one depends on our inter-
est. If the objective is to reach the most number of reachable nodes, flooding has to be used but with 
this selection the number of retransmitted packets is too high. For that, the researchers have to focus on 
the Be metric. Consequently, p-persistence and irresponsible broadcasting algorithms present the best 
Be metric. Although some other previous studies have performed comparative studies of protocols for 
MANETs, this chapter goes one step further by applying a methodology to guarantee a fair comparison, 
reducing the influence of simulation conditions.
CONCLUSION
In this book chapter a methodology is proposed to obtain reliable simulation results in disaster scenarios 
for MANETs. Using this methodology, the performance metric means and the dispersion of the simula-
tion result are improved. This is based on different simulation aspects, for example with the measure-
ment period the results are lesser scattered, discrepancies in terms of number of hops and availability 
path are avoid using the source and destination node selection. The authors demonstrate the importance 
of the used methodology to obtain reliable measurements with a low number of simulations. The pro-
posed methodology is extended for the evaluation of MANET communication broadcasting protocols. 
This one is based on the topological properties of the scenario such as partition degree and separation 
in number of hops. This methodology is also validated in the scenario under test. The researchers also 
demonstrate the importance of these metrics in the simulation results. Using this approach, lesser disper-
sion is guaranteed. Finally, the authors have validated the proposed methodology in the scenario under 
test, by comparing well-known routing and broadcasting protocols.
FUTURE WORK AND OPEN ISSUES
After a thorough analysis of the obtained results with the proposed framework, there are still some un-
expected results yet. For instance, some obtained confidence intervals are still large. As future work, it 
is necessary to try to identify those factors which can cause the unexpected results. During our research 
work, the authors could identify that the congestion plays an important role in the simulation results. Of 
course, the congestion of the network will depend on the underlying application and it is not a configura-
tion parameter. However, to guarantee a fair comparison of communication protocols, the authors should 
guarantee that the same application is considered for the evaluation of each communication protocol. 
Several topology factors can also affect the congestion of the network. For instance, the local density 
of a node like the number of neighbours per node is not taken into account when the proposed selec-
tion of pairs based on the APA and number of hop metrics is applied. The point that the authors want 
to highlight is that there is clear difference between the connectivity of the network from a theoretical 
point of view, as the authors have analysed with the APA and number of hops separation, and the real 
connectivity of the network that is also a function of the congestion of the network.

140
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
Another future work which is proposed in this book chapter is to develop a graphical application 
tool, which permits to the user select the main aspect that impact the simulation results and obtain the 
candidate communication pairs. This application will focus on the selection of source and destination 
nodes. The restrictions, the path availability and the distance in terms of number of hops, will be fixed 
and our application will return the candidate pairs. This tool will be open source so researchers could 
test their new communication algorithms correctly. The graphical application should also consider the 
mobility conditions; therefore, the mobility model will be also an input to be considered.
As future work, it is necessary to try to identify those factors which can cause the unexpected results. 
During our research work, the researchers could identify that the congestion plays an important role in 
the simulation results. Of course, the congestion of the network will depend on the underlying applica-
tion and it is not a configuration parameter. However, to guarantee a fair comparison of communication 
protocols, the authors should guarantee that the same application is considered for the evaluation of each 
communication protocol. Several topology factors can also affect the congestion of the network. For in-
stance, the local density of a node like the number of neighbours per node is not taken into account when 
the proposed selection of pairs based on the APA and number of hop metrics is applied. The point that 
the researchers want to highlight is that there is clear difference between the connectivity of the network 
from a theoretical point of view, as the authors have analysed with the APA and number of hops separa-
tion, and the real connectivity of the network that is also a function of the congestion of the network.
The last future work is to apply the proposed framework to evaluate different proactive routing 
protocols and check the importance of using the proposed approach even when the routing tables are 
updated periodically
REFERENCES
Achenbruck, N., Gerhaps-Padilla, E., Gerharz, M., Frank, M., & Martini, P. (2007). Modelling Mobility 
in Disaster Area Scenarios. Paper presented at International Symposium on Modeling, Analysis and 
Simulation of Wireless and Mobile Systems, Chania, Create Island. doi:10.1145/1298126.1298131
Aggarwal, A., Gandhi, S., & Chaubey, N. (2011). Performance analysis of AODV, DSDV and DSR in 
MANETs. Int. J. Distrib. Parallel Syst., 2(6), 167–177. doi:10.5121/ijdps.2011.2615
Andel, T. R., & Yasinsac, A. (2006). On the Credibility of Manet Simulations. Computer, 37(7), 48–54. 
doi:10.1109/MC.2006.242
Arfeen, S. U., Kazi, A. W., Memon, J. M., & Hyder, S. I. (2007). Innovative Algorithms and Techniques 
in Automation, Industrial Electronics and Telecommunications. Performance Evaluation of MANET 
Routing Protocols Using Scenario Based Mobility Models. Innovative Algorithms and Techniques in 
Automation, Industrial Electronics and Telecommunication (pp. 419-424). Springer.
Aschenbruck, N., Frank, M., Martini, P., & Tölle, J. (2004). Human Mobility in MANET Disaster Area 
Simulation – A realistic Approach. Paper presented at IEEE International Conference on Local Computer 
Network, Tampa, FL doi:10.1109/LCN.2004.64
Blywis, B., Günes, M., Juraschek, F., Hahm, O., & Schmittberger, N. (2011). Properties and Topology 
of DES-Testbed (2nd ed.). Telematic and Computer System. Freie Universitát Berlin.

141
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
BonnMotion Developers. (2013). BonnMotion - A Mobility ScenarioGeneration and Analysis Tool. 
Available at http://bonnmotion.net.cs.uni-bonn.de/
Busanelli, S., Ferrari, G., & Gruppini, R. (2012). Recursive analytical performance evaluation of broad-
cast protocols with silencing: Application to VANETs. EURASIP Journal on Wireless Communications 
and Networking, 10, 1–21.
Clausen & Jacquet. (2003). Optimized Link State Routing Protocol (OLSR). IETF, RFC 3626.
Conceição, L., & Curado, M. (2013). Modelling Mobility Based on Human Behaviour in Disaster 
Areas. International Conference of Wired/Wireless Internet Communication, Saint-Petersburg, Russia. 
doi:10.1007/978-3-642-38401-1_5
Conti, M., & Giordano, S. (2015). Mobile Ad Hoc Networking: Milestones, Challenges, and New Re-
search Directions. IEEE Communications Magazine, 52(1), 85–96. doi:10.1109/MCOM.2014.6710069
Das, S. R., Castañeda, R., & Yan, J. (2000). Simulation-based performance evaluation of mobile ad hoc 
Networks. Mobile Networks and Applications, 5(3), 179–189. doi:10.1023/A:1019108612308
Fogue, M., Garrido, P., Martinez, F. J., Cano, J. C., Calafate, C. T., & Manzoni, P. (2012). A Realistic 
Simulation Framework for Vehicular Networks. Paper presented at International ICST Conference on 
Simulation Tools and Techniques, Desenzano del Garda, Italy. doi:10.4108/icst.simutools.2012.247682
García-Campos, J. M., Sánchez-García, J., Reina, D. G., Toral, S. L., & Barrero, F. (2015). Evaluation of 
Dissimilarity-based Probabilistic Broadcasting Algorithms in VANETs Urban Scenarios. Paper presented 
at International Conference on Developments in eSystems Engineering, Dubai, UAE.
García-Campos, J. M., Sánchez-García, J., Reina, D. G., Toral, S. L., & Barrero, F. (2016). An evalu-
ation methodology for reliable simulation based studies of routing protocols in VANETs. Simulation 
Modelling Practice and Theory, 66, 139–165. doi:10.1016/j.simpat.2016.04.002
Haas, Halpern, & Li. (2006). Gossip-Based Ad Hoc Routing. IEEE/ACM Transaction on Networking, 
14, 479-491.
Hiranandani, D., Obraczka, K., & García-Luna-Aceves, J. J. (2013). MANET protocol simulations con-
sidered harmful: The case for benchmarking. IEEE Wireless Communications, 20(4), 82–90. doi:10.1109/
MWC.2013.6590054
Hong, X., Gerla, M., Pei, G., & Chiang, C.-C. (1999). A group mobility model for ad hoc wireless net-
works. Paper presented at International workshop on Modeling, analysis and simulation of wireless and 
mobile systems, Seattle, WA. doi:10.1145/313237.313248
Jardosh, A., Belding-Royer, E., Almeroth, K., & Suri, S. (1999). Towards realistic mobility models for 
mobile ad hoc networks. Paper presented at International conference on Mobile computing and network-
ing, Seattle, WA.
Johnson, Maltz, & Hu. (2004). The Dynamic Source Routing Protocol for Mobile Ad Hoc Networks. 
IETF, RFC 4728.

142
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
Jurdak, R., Lopes, C. V., & Baldi, P. (2004). A survey, classification and comparative analysis of medium 
access control protocols for ad hoc networks. IEEE Communications Surveys and Tutorials, 6(1), 2–16. 
doi:10.1109/COMST.2004.5342231
Kaur, H., Sahni, V., & Bala, M. (2013). A Survey of Reactive, Proactive and Hybrid Routing Protocols 
in MANET: A Review. International Journal of Computer Science and Information Technologies, 4, 
498–500.
Ko, Y.-B., & Vaidya, N. (2000). Location-Aided Routing (LAR) in mobile ad hoc networks. Wireless 
Networks, 6(4), 307–321. doi:10.1023/A:1019106118419
Kurkowski, S., Camp, T., & Colagrosso, M. (2005). MANET Simulation Studies: The Incredibles. 
ACMs. Mobile Computing and Communications Review, 9(4), 50–61. doi:10.1145/1096166.1096174
Lakshmi, N. (2012). A joint network for disaster recovery and search and rescue operations. Computer 
Networks, 56(14), 3347–3373. doi:10.1016/j.comnet.2012.05.012
Li, M., & Zhu, H. (2013). Mobile Ad Hoc Networking. Experimental work on VANET in Mobile Ad Hoc 
Networking. Wiley.
Panichpapiboon, S., & Ferrari, G. (2008). Irresponsible forwarding. Paper presented at the 8th Interna-
tional Conference on ITS Telecommunications, Phuket, Thailand.
Perkins, Royer, & Das. (2003). Ad hoc On-Demand Distance Vector (AODV) Routing. IETF, RFC 3561.
Pomportes, S., Tomasik, J., & Vèque, V. (2010). Ad hoc network in a disaster area: A composite mobility 
model and its evaluation. Paper presented at International Conference on Advanced Technologies for 
Communications, Saigon, Vietnam. doi:10.1109/ATC.2010.5672729
Pomportes, S., Tomasik, J., & Vèque, V. (2011). A Composite Mobility Model for Ad Hoc Networks in 
Disaster Areas. Journal on Electronics and Communications, 1, 62–68.
Pucha, H., Das, S. M., & Hu, Y. C. (2007). The performance impact of traffic patterns on routing protocols 
in mobile ad hoc networks. Computer Networks, 51(12), 3595–3616. doi:10.1016/j.comnet.2007.02.009
Quispe, L. E., & Galan, L. M. (2014). Behavior of Ad Hoc routing protocols, analyzed for emergency and 
rescue scenarios, on a real urban area. Expert Systems with Applications, 41(5), 2565–2573. doi:10.1016/j.
eswa.2013.10.004
Raffelsberger, C., & Hellwagner, H. (2012). Evaluation of MANET Routing Protocols in a Realistic 
Emergency Response Scenario. Paper presented at the 10th International Workshop on Intelligent Solu-
tions in Embedded Systems, Pilsen, Czech Republic.
Ramesh, , Subbaiah, Koteswar Rao, & Janardhana Raju. (2010). Performance comparison and analysis of 
DSDV and AODV for MANET. International Journal on Computer Science and Engineering, 2, 183–188.
Reina, D. G., Toral, S. L., Asimakopoulou, E., Barrero, F., & Bessis, N. (2015). The role of congestion 
in probabilistic broadcasting for ubiquitous wireless multi-hop networks through mediation analysis. 
Pervasive and Mobile Computing, 24, 16–29. doi:10.1016/j.pmcj.2015.06.014

143
A Simulation Methodology for Conducting Unbiased and Reliable Evaluation
﻿
Reina, D. G., Toral, S. L., Barrero, F., Bessis, N., & Asimakopoulou, E. (2011). Evaluation of ad hoc 
networks in disaster scenarios. Paper presented at the third International Conference on Intelligent Net-
working and Collaborative Systems, Fukuoka, Japan. doi:10.1109/INCoS.2011.86
Reina, D. G., Toral, S. L., Barrero, F., Bessis, N., & Asimakopoulou, E. (2012). Modelling and assess-
ing ad hoc networks in disaster scenarios. Journal of Ambient Intelligence and Humanized Computing, 
4(5), 571–579. doi:10.1007/s12652-012-0113-3
Reina, D. G., Toral, S. L., Barrero, F., Bessis, N., & Asimakopoulou, E. (2013). The role of ad hoc net-
works in the internet of things. Internet of Things and Inter-cooperative Computational Technologies 
for Collective Intelligence, 460, 89–113. doi:10.1007/978-3-642-34952-2_4
Reina, D. G., Toral, S. L., Johnson, P., & Barrero, F. (2015). A survey on probabilistic broadcast schemes 
for wireless ad hoc networks. Ad Hoc Networks, 25, 263–282. doi:10.1016/j.adhoc.2014.10.001
Rhee, I., Shin, M., Hong, S., Lee, K., & Chong, S. (2008). On the Levy-Walk Nature of Human Mobil-
ity. Paper presented at IEEE Conference on Computer Communications, Phoenix, AZ. doi:10.1109/
INFOCOM.2008.145
Schwamborn, M., Aschenbruck, N., & Martini, P. (2010). A Realistic Trace-based Mobility Model for 
First Responder Scenarios. Proceedings of the 13th ACM International Conference on Modeling, Analysis 
and Simulation of Wireless and Mobile Systems. doi:10.1145/1868521.1868564
Shenbagapriya, R., & Kumar, N. (2014). A Survey on Proactive Routing Protocols in MANETs. Paper 
presented at the International Conference on Science Engineering and Management Research, Chennai, 
India. doi:10.1109/ICSEMR.2014.7043630
Trung, H., Benjapolakul, W., & Duc, P. (2007). Performance evaluation and comparison of different ad hoc 
routing protocols. Computer Communications, 30(11-12), 2478–2496. doi:10.1016/j.comcom.2007.04.007
Vallati, Omwando, & Mohapatra. (2013). Experimental Work Versus Simulation in the study of Mobile 
Ad Hoc Networks. Academic Press.
Vallati, C., Omwando, V., & Mohapatra, P. (2013). Mobile Ad Hoc Networking. In Experimental Work 
Versus Simulation in the study of Mobile Ad Hoc Networks (pp. 191-228). Wiley.
Wang, X., Wang, C., Cui, G., & Yang, Q. (2015). Practical Link Duration Prediction Model in 
Vehicular Ad Hoc Networks. International Journal of Distributed Sensor Networks, 11(3), 1–14. 
doi:10.1155/2015/216934
Wisitpongphan, N., Tonguz, O. K., Parikh, J. S., Mudalige, P., Bai, F., & Sadekar, V. (2007). Broadcast 
storm mitigation techniques in vehicular ad hoc networks. IEEE Wireless Communications., 14(6), 84–94. 
doi:10.1109/MWC.2007.4407231
Zhang, Y., Low, C. P., & Ng, J. M. (2011). Performance Evaluation of Routing Protocols on the Refer-
ence Region Group Mobility Model for MANET. Wireless Sensor Network, 3(03), 92–105. doi:10.4236/
wsn.2011.33010

144
Copyright © 2018, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.
Chapter  5
DOI: 10.4018/978-1-5225-2575-2.ch005
ABSTRACT
Emergencies are typically complex problems with serious consequences that must be solved in a limited 
amount of time to reduce any possible damage. Big data analysis leads to more assured decision making 
and better decisions can mean greater operational efficiencies, cost reductions and reduced risk. In this 
chapter, we discuss some issues on tackling emergency situation from the perspective of big data processing 
and management, including our approach for processing social media content. Communications during 
emergencies are so plentiful that it is necessary to sift through enormous data points to find information 
that is most useful during a given event. The chapter also presents our ongoing IT-system that processes 
and analyses social media data to transform the excessive volume of low information content into small 
volume but rich content that is useful to emergency personnel.
1. INTRODUCTION
During a disaster, life-saving decisions are often made based on the most current information of a situation 
and past experiences in similar circumstances. While that’s a tried-and-true approach, the availability of 
complex, computer-generated data streams is changing the ball game for emergency service providers. 
Hence effective management of emergencies and disasters is a global challenge in big data era. A sys-
tematic process with principal goal to minimize the negative impact or consequences of emergencies and 
disasters, thus protecting societal infrastructure, is called effective emergency and disaster management. 
It is imperative throughout the world to increase knowledge of emergency and disaster management, 
for the purpose improving responsiveness. All the above aims may be accelerated by big data analysis.
Big data may be characterized as having four dimensions: Data volume, measuring the amount of 
data available, with typical data sets occupying many terabytes. Data velocity is a measure of the rate 
of data creation, streaming and aggregation. Data variety is a measure of the richness of data repre-
sentation – text, images, videos etc. Data value, measures the usefulness of data in making decisions 
Processing Big Data for 
Emergency Management
Rajendra Akerkar
Western Norway Research Institute, Norway

145
Processing Big Data for Emergency Management
﻿
(Akerkar 2013a). Variability, which represents the number of changes in the structure of the data their 
interpretation, is a newly added characteristic.
The management of such big data is perhaps one of the key challenges to be addressed by informat-
ics. The wide variety of data acquisition sources available in times of emergency creates a need for data 
integration, aggregation and visualization. Such techniques assist emergency management officials to 
optimize the decision making procedure. During the outburst of an emergency, the authorities responsible 
must quickly make decisions. The quality of these decisions depends on the quality of the information 
available. A key factor in emergency response is situational awareness. An appropriate, accurate assess-
ment of the situation can empower decision-makers during an emergency to make convenient decisions, 
take suitable actions for the most affective emergency management.
This chapter is divided into six sections. Section 2 presents various kinds of applications of big data in 
emergency cycle. Essential smart technological research approaches are discussed in section 3. Various 
research issues, concerning with big data, are elaborated in section 4. Section 5 describes key challenges 
and steps for processing social media contents. This section is underlining our approach for emergency 
management utilizing social media data. The chapter concludes in section 6.
2. BIG DATA AND EMERGENCY CYCLE
Big data is the technological paradigm that enables useful analysis of vast quantities of data to be achieved 
in practice. Big data is the collection of scientific and engineering methods and tools for dealing with 
such volumes of data, and addresses not merely the storage but also access to and distribution, analysis, 
and useful presentation of results (such as visualisation of analysis of the data) for huge volumes of data. 
Big data is becoming a critical part of emergency communication. Emergency communication does not 
involve only intentional, explicit exchange of messages – for example first responders talking over a 
voice connection, or an announcement of a text message warning to citizens threatened by an approach-
ing natural disaster. To be more precise, emergency communication also involves the monitoring and 
understanding of the complete body of public, openly available communication – such as messages and 
content being publicly exchanged on social media. Thus, individuals may be reporting their condition 
to loved ones or making specific requests for help, but a complete analysis of all communications can 
reveal valuable information of general scope, such as a disease outbreak.1
Usually, emergency cycle consists of three phases. “Prevention” and “Preparedness” are conducted 
before an emergency occurs in order to eliminate or reduce the probability of an emergency and to build 
emergency management capacities. “Response” activities provide emergency assistance to save lives, 
preserve property and protect the environment during an emergency. “Recovery” is the process of return-
ing systems to normal levels after an emergency. Big data has been used in all phases of the emergency 
management cycle as shown in the following Table 1.
Open initiatives and new applications for big data constitute a genuine opportunity to provide deci-
sion makers with powerful new tools for tracking and predicting hazardous events, protecting vulnerable 
communities, understanding human factors and targeting where to optimize programs and policies. For 
several “data deficient” countries and communities accessing big data can increase credibility and value of 
meteorological forecasts and warnings. Turning big data sets – satellite images, in situ and mobile sensor 
observations, online user-generated content, environmental data archives, weather and water forecasts, 
and climate model results, etc. – into useful and actionable information and integrating this complex 

146
Processing Big Data for Emergency Management
﻿
information into decision support requires domain expertise, automated data retrieval, and analytical 
and computational techniques, and visualization, mapping and decision tools to unveil trends and patters 
within and between these very large environmental and socio-economic datasets. The significance of 
big data is growing and expected to close both information and timeliness gaps that limit capabilities to 
plan, mitigate, or adapt to environmental hazards and change. But various National Meteorological and 
Hydrological Services and other stakeholders have no means to analyze and utilize effectively the new 
big data load that is present today and will continue to grow rapidly in the future.
While there is a variety of big data available for each phase of the emergency cycle, understanding 
issues of scale, granularity, ambiguity, accessibility, representation, and privacy are all key in using big 
data information correctly and ethically. It is important to understand how to combine data from differ-
ent resolutions and temporal scales with various emergencies. However, when analysing urban flood 
risk, high resolution and 3-D imagery is significant to estimate elevation and urban cover to understand 
where water will flow and pool (Preston et al, 2011, National Academy of Sciences reports People and 
Pixels 1998, and Tools and methods for estimating populations at risk from natural disasters and complex 
humanitarian crises, 2007).
Other challenge is difficulty separating the signal from the noise. Selecting the proper algorithm and 
quantitative metrics to discover precisely robust trends is important, as is understanding that big data 
analysis a lot demonstrates correlation rather than causation. In the 2010 Haiti earthquake aftermath, 
social media data production was only weakly correlated with destruction; besides, emergency services 
faced challenges making SMS information actionable.
It is also well-known that existing big data is not free and public. While Facebook has an open API 
to access its data, access to Twitter’s data stream can be expensive. Gaining access to CDR data requires 
Table 1. Data types and various phases of emergency management cycle
Phase
Description
Data Type
Example Data Sets
Pre-emergency 
(Prevention and 
Preparedness)
Avoid an incident or intervene to stop an 
incident from occurring and encompass 
actions that involve a combination of 
planning, resources, training, exercising, and 
organizing to build, sustain, and improve 
operational capabilities. In this phase 
governments, organizations, and individuals 
develop plans to save lives and minimize 
emergency damage.
User-generated
Twitter (food emergency, earthquake), web 
traffic (Flu)
Sensor
Precipitation (PERSIAN, TRMM), 
evapotranspiration, soil moisture, 
temperature, vegetation density and 
water content (MODIS, LANDSAT), 
groundwater levels (GRACE)
During emergency 
(Response)
Include immediate actions to save lives, 
protect property and the environment, meet 
basic human needs, and preserve business 
operations.
User-generated
CDR, Flickr, Twitter
Sensor
Imagery(LANDSAT, MODIS, Geoeye) 
thermal (LANDSAT, MODIS), radar 
(RADARSAT-1, CARTOSAT), spatial 
video
Post-emergency 
(Mitigation, 
Recovery)
Design recovery programs to assist victims 
and their families, restore institutions to 
suitable economic growth and confidence, 
rebuild destroyed property, and reconstitute 
government operations and services affected 
by emergencies. Recovery activities continue 
until all systems return to normal or better.
User-generated
CDR, emergency call content, Facebook
sensor
Night-time Lights (NTL), Imagery, 
thermal, Radar, spatial video, Temporal 
Flood Inundation Mapping (GIEMS)
institutional, 
public
GCM (Global Climate Model), 
Transportation data (subway, bikeshare), 
census, Worldpop, Open Cities

147
Processing Big Data for Emergency Management
﻿
an agreement with each provider. Some business data is free to view but not download (Zillow, Trulia), 
and other data can be purchased (Experian Real Estate data, ESRI business analysis). Some satellite 
data is free (Landsat, MODIS, SRTM), and others for sale (LiDar data, GeoEye, etc.). Access to the re-
quired computing power to analyse data can be an issue, but cloud computing and open source software 
removes some of those barriers.
Furthermore, big data is emerging together with a number of downsides and risks that demand scru-
tiny. Both academics and practitioners have raised concerns about the representativeness of big data in 
emergency management. Some big data sources may be representative of particular segments of society, 
but may not be generalizable to society as a whole (Currion, 2010). For instance, social media data in 
the wake of Superstorm Sandy were more highly concentrated in less-impacted areas of New York City, 
rather than in neighbourhoods in south Queens. The platforms on which big data multiply streamline 
the production and spreading of untruths, too. While means for preventing this are strengthening, prac-
titioners should continue to be cautious about untrustworthy or unconfirmed information, a gradually 
more challenging task in the big data perspective.
Moreover, privacy and security issues have been a large concern in big data. While data sets that 
could identify individuals are frequently anonymized (e.g. call record data) even the best attempts to 
coarsen the data do not preclude individual identification in some cases. So, we should be aware of the 
sensitivity of anonymized big data sets.
Especially in times of crisis, clear, complete and quick information is needed. ‘Disasters are threatening 
and highly dynamic situations, marked by high levels of information need and low levels of informa-
tion availability (Shklovski, 2010). Research shows that advances in information and communication 
technologies enlarge the possibilities for people to seek, get and send information about their situation, 
feelings and capacities in critical situations. Similarly, the information technology is an essential factor 
for streamlined search and rescue actions during disasters, but also for sufficient preparation and recovery, 
stimulated and organised by the authorities.
Shelton et al. (2014) have investigated Twitter activity in the wake of Hurricane Sandy in order to 
demonstrate the complex relationship between the material world and its digital representations and 
further described that any analysis of user-generated geographic information must take into account the 
existence of more complex spatialities than the relatively simple spatial ontology implied by latitude 
and longitude coordinates.
The categorization is based on multiple resources and recognizes that big data can assist before, dur-
ing and after an emergency, often via a cyclical process, as indicated in Figure 1.
2.1 Pre-Emergency Phase
Big Data analysis can help significantly to the preparation of crisis management. Through the data 
analysis can be done recognizing the dangers and to provide a sound strategic approach by the respective 
managers of the crisis. Big Data analysis can also guide the proactive deployment of resources to fully 
cope with an impeding type of disaster.
Social media data can be used for making diagnoses of vulnerabilities in systems and infrastructures. 
Besides, some applications can facilitate the warning of citizens in the period before a threatening crisis 
occurs. For instance, surveys of the American Red Cross show that a large part of the population in 
the United States is interested in technologies, applications or simply receiving emails for emergency 
communication. Information about the location of food and water, shelter locations, road closures, the 

148
Processing Big Data for Emergency Management
﻿
location of medical services and about how to keep safe during emergencies are high rated by around 
a half of the questioned people. On the other hand, more than a half of the citizens who is using social 
media say they should post relevant information on their sites or applications during periods of crisis 
(Page et al, 2013).
Information derived from the analysis of Big Data can help to anticipate crises or at least reduce 
the risks that would arise from a disaster the major crisis effect. One example is in a big earthquake 
harm arises in telecommunication networks leading to interruption of communications, also has been 
observed a large number of blackouts. There exists a need to study this data for optimization of the civil 
infrastructure to avoid this crisis effects.
2.2 During Emergency
In emergency situations, big data can be used to provide situational awareness both to authorities and 
members of the public using information coming from scientists, private organisations and members 
of the public. This further demonstrates that members of the public are key stakeholders in the big data 
and emergency management ecosystem.
Big Data analysis in real time can identify which areas need the most urgent attention from the crisis 
administrators. With the use of the GIS and GPS systems, Big Data analysis can assist the right guidance 
to the public to avoid or move away from the hazardous situation. Furthermore analysis from prior crisis 
could help identify the most effective strategy for responding to future disasters.
Moreover disaster-affected communities today are increasingly likely to be ‘digital communities’ as 
well – that is, both generators and consumers of digital information. This is obvious from the massive 
amounts of data being generated by members of the public in emergency situations. However, as well as 
gathering information from members of the public via social media, this tool can also be used to push 
information and share information with members of the public to aid in response during an emergency. 
This is intensely important, as members of the public often act as first responders in emergency situa-
tions, well before aid or assistance is available. Many of the systems, including early warning systems, 
Figure 1. Emergency management cycle

149
Processing Big Data for Emergency Management
﻿
situational awareness systems and training systems also include systems for disseminating information to 
members of the public, or are particularly intended as collaborative information sharing platforms. Tak-
ing emergency mapping as a specific example, the system can be set up in a matter of hours, long before 
humanitarian or other organizations can arrive. As such, the information can be used to enable members 
of the public to meet one another’s needs in the gap between the incident and the official response.
Real-time big data analysis can substantially enhance various disaster response aspects. First, it can 
help emergency response personnel to identify areas that need the most urgent attention. This could be 
areas where there are several people or critical resources. It could also be areas where there may be trig-
gers for other hazards. Second, real-time monitoring and situation analysis can assist emergency response 
personnel in coordinating their actions to optimally handle a disaster situation. This also includes guid-
ance to the public in taking the best routes to move away from a disaster in order to prevent congestions 
or causing people to move by mistake to a more hazardous situation. Third, big data analysis from prior 
incidents can help identify the most effective response methods for various situations and enable the 
development and deployment of assistive infrastructures for effectively responding to future disasters.
2.3 Post-Emergency Phase
When the recovery activation will gradually start, the infrastructure would provide a big data source. The 
big data analysis is sharing useful information for recovery procedures about provision of relief supply, 
volunteer coordination and logistics during the crisis. The mechanisms and approaches for continuous 
adaptation to the change of demands with the limited resources should be a vital issue for the big data 
infrastructure.
3. PERTINENT RESEARCH ISSUES
In order to take advantage of big data analysis for efficient emergency management, the core infrastruc-
ture must offer exceptional quality of service (QoS). While the QoS requirements may differ for diverse 
emergency situations, we sketch some instances.
In view of the urgency of the response activities when dealing with emergencies, it is vital for the 
infrastructure to provide real-time performance. This includes real-time data analysis to precisely pre-
dict the impact of an imminent hazard as well as the effective means of responding to the emergency. 
It additionally involves real-time communication to ensure that accurate data are collected about the 
situation, such as the location of affected individuals, etc. Real-time communication is also desirable to 
safeguard that different emergency response teams can coordinate their actions in optimally responding 
to a disaster (Castillo, 2016).
With the seriousness of emergency response situations, it is crucial to guarantee that the service will 
be particularly reliable and accessible regardless of the adverse conditions during such circumstances, 
involving tangible damages, power outages, floods, etc. Consequently, the big data storage, analysis, 
and communication services must be able to operate regardless of adverse conditions. Computing and 
sensor resources can be deployed at various geographical locations and communication methods can be 
used to ensure uninterrupted access to the data.
It is also vital to ensure that the big data supporting infrastructure is sustainable with the evolving 
nature of emergencies and even emergency response tactics. It is also important to ensure that the service 

150
Processing Big Data for Emergency Management
﻿
meets high levels of security, such as privacy, confidentiality and assurance that the information used 
to direct the response to an emergency is proper and not distorted.
Mostly, when we consider the usage of infrastructures, its efficiency, reliability and dependability are 
key segments. In general, big sensing data are stored in the cloud (Fazio et al, 2015). Yet, in emergency 
situations, it might not be able to access to the cloud from emergency areas. Thus, it is vital to consider 
the efficiency and reliability for not only the cloud but also the sensing rims. We also need to consider 
failures of communication lines in designing and delivering mission-critical services,. Further, it is 
necessary to ensure that the data acquisition and analysis measures are greatly dependable regardless 
of the failures of various processing and communication units. Given the distributed nature, it can be 
difficult to identify which units have failed. Hence, the processing and communication infrastructure 
may need to be augmented with dependable on-line system health monitoring capabilities to enable 
the rapid identification of faulty components and the activation of redundant substitute units to ensure 
correct and apt accomplishment of the big data analysis under emergency situations. Assessment of the 
big data analysis algorithms is needed to determine the confidence in the correctness of the results of 
the analysis, including predictions and recommendations for optimal response and recovery actions. 
Simulation platforms can be used for evaluating and verifying new algorithms and procedures. Differ-
ent algorithms can be evaluated and compared by applying them to a set of benchmark scenarios and 
test-beds for which the correct results are known.
3.1. Security and Privacy
There are several significant challenges in information security such as information quality, spam fil-
tering. Crowd-sourcing is among the most effective methods for filtering spam. Nevertheless, due to 
innate delays crowdsource approach may not be precisely appropriate in emergency situations. In order 
to enhance the information quality level is to timestamp and location-stamp each message (e.g., enabling 
the locations feature allows Twitter to show your followers the location you are Tweeting from as part of 
your Tweet), thus allowing more complete authentication of the data beside its content and correlation 
with other information sources.
In particular, real-time mining of indirectly self-reported and surveillance information harvested from 
aggregates of Twitter and other social network feeds can offer useful data and insights about unfolding 
trends and emerging crowd behaviours at times of crises (Kamel Boulos et al, 2010). However, such 
(raw) data obtained from Social Web feeds often contain variable amounts of “noise”, misinformation 
and bias and will commonly require some filtering and verification by both machine-based algorithms 
and human experts before becoming reliable enough for use in decision-making tasks.
Continuous big data analysis for streaming data, such as output of sensors, results of crowdsourc-
ing, etc., must be enhanced with anomaly detection mechanisms to identify data that may be incorrect 
due to sensor failures, security attacks, etc. In this aspect the uncertainty quantification method must be 
constructed with integrated machine learning methods. Machine learning can also help in reducing the 
chaos in big data storage and analysis by replacing large amounts of data by precise equivalent infer-
ence rules. It will also speed up the analysis under emergency situations since the rules can be used to 
promptly perform the prediction analysis as well as to identify optimal response strategies.
Other issue is about sharing big data and information. Big data producers are mostly reluctant to 
share information. This problem needs to be tackled for the mission-critical real-time applications such 
as emergency response, since sensors are collecting such data automatically and appropriate decision 

151
Processing Big Data for Emergency Management
﻿
making can be achieved through automated integration and sharing, with proper security and privacy 
assurances. However, in this regard several legal issues need to be solved. For many kinds of emergencies 
(e.g., flood), there are reliable sources of information. Alas, there are also other kinds of emergencies 
for which we do not get trustworthy sources from dedicated sensors. Hence research in such direction 
should emphasis on how people perceive information in social media and how they contribute informa-
tion in social media.
3.2. Noise & Big Social Data
While traditional event detection approaches assume that all documents are relevant, Twitter data typi-
cally contains a vast amount of noise and not every tweet is related to an event2. The source of noise in 
open source information can be divided into intentional and unintentional. Intentional sources of noise 
and misinformation are generated by cyber-attacks designed for illegitimate financial returns or inten-
tional advantage in a conflict. Social media technologies can facilitate the spread of false information 
as well as the spread of counter information that attempts to correct the false information, but how to 
take advantage of these technologies to reduce the spread of misinformation and at the same time in-
crease the spread of useful information such as alerts and warnings is the major concern. The source of 
unintentional noise is a precipitously varying environment. Linking the information to a correct topic or 
region of space-time continuum is critical when the environment changes rapidly. Thus improving the 
quality of information in social media (i.e., filtering out the big noise in big data) is a huge challenge 
and it involves several prominent issues.
4. SMART TECHNOLOGIES AND BIG DATA
4.1. Crowdsourcing
When a large emergency occurs, it is an incredible challenge to fulfil the information needs of humani-
tarian responders. Specially, access to latest data on the physical layout of the affected area, the location 
of critical infrastructure and services is imperative. Likewise, to develop the situational awareness that 
is desirable to act, responders need information on a kind of assistance required (Stanton et al., 2001). 
Therefore, maps are of immense significance during crisis response (Meier, 2015).
Crowdsourcing connects unobtrusive and ubiquitous sensing technologies, advanced data manage-
ment and analytics and novel visualization methods, to create solutions that improve urban environment, 
human life quality, and city operation systems. Nowadays, no countries, no communities, and no person 
are immune to urban emergency events. It is important to detect, resistant, and analyse these real time 
urban emergency events to protect the security of urban residents (Zheng et al, 2016). The crowdsource 
systems can be useful in mass emergencies to allow people to gather information, report information, 
volunteer to help, ask for help, or to re-broadcast useful information. Citizens can use this information 
to determine whether they should follow an evacuation order while government agencies can use this 
information to determine the allocation of resources or to get an overall sense for the status of a region 
or city.

152
Processing Big Data for Emergency Management
﻿
For example, during the night of 8th to 9th of June 2014, the storm hit Antwerp after following a 
destructive path between Gent and Antwerp. Data from fire services was extracted and uploaded to 
google maps and images from social media were collected. Figure 2 presents a screenshot of flood data 
from emergency service.
Crisis mapping is the real-time collection, display and analysis of data during a crisis, usually a 
natural disaster or social/political conflict. Crisis mappers achieve big data analytics and data mapping 
in order to gather insights about what and where emergency events are occurring on a real-time basis.
Crowdsourcing of information gathering and the sharing of the analysed results by individuals are 
certainly dominant ways to get the real-time monitoring of the quickly changing situations influenced 
by lots of unforeseen events. However, gathering information from crowd is challenging. If the collec-
tion of data requires users’ interaction with the application, then we need to provide users with attrac-
tive incentives. Another point is how to deliver the information in a right way in an emergency. Some 
information may trigger a panic, which may cause further troubles. Nevertheless privacy protection 
is always a significant problem. However, in order to save as many lives as possible during a disaster, 
privacy protection policy may be dynamically changed during emergency by emergency services, or 
even by volunteers. The emergency system should also support the real-time dynamical changes of the 
policy and the sharing of such information.
4.2. Cyber-Physical-Social Systems (CPSS)
The last decade has seen human factors becoming gradually crucial in computing systems. Therefore, 
by integrating human factors as part of a system, a cyber-physical-social system (CPSS) encompasses 
not only cyberspace and physical world, but also human knowledge, mental capacity, and sociocultural 
Figure 2. Geographical spread data from fire services

153
Processing Big Data for Emergency Management
﻿
elements. Just as the Internet has transformed the way that people interact with information, CPSS will 
transform the way people interact with every computing system and create new revolutionary science, 
technical capabilities for better quality of life. Cyber-Physical-Social systems tightly integrate physical, 
cyber, and social worlds based on interactions between these worlds in real time. This area is a new re-
search and development field that requires further development of models, methodologies, and theories 
for efficient interaction between physical, cyber, and social worlds. Cyber-Physical-Social systems rely 
on communication, computation and control infrastructures commonly consisting of several levels for 
the three worlds with various resources as sensors, actuators, computational resources, services, humans, 
etc. (Zeng, 2016; Vardi, 2011; Sheth, 2013). Operation and configuration of CPSS require approaches for 
managing the variability at design time and the dynamics at runtime caused by a multitude of component 
types and changing application environments.
Building CPSS for non-emergency conditions is already difficult; yet, building CPSS for emergency 
management and emergency response is significantly more challenging. Two key important challenges 
are how to tackle the exponential and multidimensional complexity of their operating environments and 
how to meet the strict design requirements of CPSS that are necessary for such environments.
Moreover, understanding social theories is an important step toward building systems that interact 
smoothly with people. These theories are crucial in the design and development of physical-cyber-
social systems. For example, a system that interprets various social interactions can be used to capture 
images/videos. One of the key challenges in dealing with social systems is how to maintain the privacy 
of participants. Privacy becomes an essential component and it is crucial for wide adoption of physical-
cyber-social systems. This is partly due to the fine-grained information collected from sensors and its 
correlation with behaviour patterns that would reveal personal information which may be misused. For 
example, a smart-meter installation may result in revealing the occupancy of a house. Some of the key 
challenges when using social data or in general any data processed by physical-cyber-social computing 
are listed below.
•	
Social bots: there are attempts to simulate and flood the social data generated automatically by 
programs that try to emulate human behaviour. Such a source of information should be used care-
fully and separated from rest of the social data.
•	
’Twitter’ data is not always reliable (i.e. requires careful consideration): while social data is avail-
able in massive scale (e.g., around 500 million tweets a day), the data is often very noisy, informal, 
and unevenly distributed.
•	
Assessing the relevance of Twitter to a problem: not all studies can be done on Twitter data since 
the nature of data and the social behaviours have a great variance on Twitter.
•	
Sometimes there is an assumption that data is available at all times: theoretically, there is data 
available related to various events. However in reality, it may be very hard to find sensors and 
their observations on Twitter and the Web in general. Choosing the appropriate data source is an 
important challenge in the context of physical-cyber-social systems.
•	
Understanding the feedback mechanism: social scientists need to understand the feedback mecha-
nism that exists between the physical world and the social world interactions. This is a challenging 
and important task to gain insights into systems that involve the social component.
•	
Data biases are crucial: social scientists should consider data biases carefully with the availability 
of massive data from social networks such as Twitter.

154
Processing Big Data for Emergency Management
﻿
•	
Combining reactive vs. non-reactive data: reactive data are those collected by social scientists 
through surveys and questions. Non-reactive data are those collected by sensors on a continuous 
basis.
4.3. Service and Cloud Computing
Cloud computing – a long held dream of computing as a utility – is a promising way that shifts data and 
computational services from individual devices to distributed architectures. Cloud computing provides a 
convenient tool for crisis response teams to collaborate and share information no matter where the team 
members are located. Depending on the type of crisis, there may be differing security requirements for 
the information, and this can impact how the cloud computing is managed or whether additional secu-
rity measures should be in place. The big data produced during emergency (e.g., by sensors, and social 
media) have to be collected, integrated, and delivered to big data consumer applications to achieve their 
new functionality. In addition, emergency management research requires the integration of emergency 
data with many other big data sources including, but not limited to mapping, land survey, environmental, 
satellite imagery, population and part disaster datasets; as well as models for climate, geomorphology 
and hazard spread forecasting.
One of the benefits of cloud computing is that information and operations are hosted in well protected 
data centers. Leading cloud providers keep information on thousands of systems and in several locations. 
Redundancy, availability and reliability are hallmarks of cloud computing, so that users can access your 
information rapidly, no matter where they are located. For example, Amazon and Microsoft have data 
centers all over the world, with enormous processing power and storage.
Using an analogy with cloud computing and service computing, the big data infrastructure for disaster 
management is divided into three layers (Pu and Kitsuregawa, 2013). Development of an architecture 
for each layer of the big data infrastructure for emergency management should consider the distributed 
nature of the data, the heterogeneity in data sources formats (structured and non-structured), protocols 
and semantics, the need to meet real-time constraints despite its volume, and quality of data sources.
Disaster recovery is not a problem for cloud service providers but every organization that uses cloud 
(Chang, 2015). If data are irretrievably lost, this may have negative impacts on the organization affected 
such as financial loss and loss of time to reproduce or regain data.
(Armbrust et al. 2010) define technical challenges and the security issues to be resolved for cloud 
computing and also big data. One aspect is ownership and privacy of the data stored in the Cloud. Data 
in the cloud should have a clear ownership definition, and not be shared or accessed by users without 
authorization. Legal and data compliance fulfilling governments and regional/international laws need 
to be met.
(Chang, 2015) demonstrates a multi-purpose approach for disaster recovery, since the existing lit-
erature suggests only single approach has been adopted. Chang’s approach can meet the requirements 
for big data systems and services that can fulfil requirements for volume, velocity, variety, veracity and 
value, with all data restored and updated in four sites. This is particularly useful for service providers 
who manage cloud data centers.
Clouds are secure and yet adaptation of authenticity, encryption, and meeting security software 
regulation large concern about secure can be put aside. Besides, the cloud is not in one place; hence 
the risk of systems failures substantially decreases. In the case of cloud computing, recovery costs are 
substantially lower since only local computers used to access the Internet are at risk and user data and 

155
Processing Big Data for Emergency Management
﻿
cloud servers are protected far from the emergency site. In the case of an emergency striking a cloud 
computing data center, user data will not be lost since suppliers of cloud infrastructure replicate user 
data and cloud servers across multiple data centers.
5. PROCESSING SOCIAL MEDIA CONTENTS
In above sections we have discussed various issues related to big data processing during emergencies. In 
this section we will describe our approach to handling social media data. A key challenge when gather-
ing and analysing social media (SM) data is the diversity of different SM services and the presence of 
different data formats (e.g. a tweet in Twitter or a video in YouTube). Therefore, to allow processing of 
the heterogeneous SM information we need to standardize the exchange data format.
There are several approaches present that attempt to harmonize multiple SM services on a data level. 
Social media offers an opportunity to communicate the emergency situation to other citizens or to EMS 
even though mobile phone or emergency services may be encumbered. During the past few years, vari-
ous studies were performed focusing on various aspects of social media in emergency management 
underlining its unceasingly growing importance in this area. For example, to enhance the identification 
of relevant messages from social media that relies upon the relations between georeferenced social 
media messages as Volunteered Geographic Information and geographic features of flood phenomena 
as derived from authoritative data (sensor data, hydrological data and digital elevation models), (de 
Albuquerque et al, 2015) have proposed an approach to examine the micro-blogging text messages of 
the Twitter platform (tweets). Several other projects are developing and implementing systems, tools 
and algorithms performing social media analysis.
This section recaps prominent EU Framework and other project works using social media analysis in 
the context of emergency management. The following tables summarize the referenced research initia-
tives based on common aspects of the performed social media analysis. The categorization was done 
based on respective web sites (e.g., (project) description, screenshots etc.), which does not necessarily 
include or highlight the full functional range of the systems. Independent of the categorization, all of 
the mentioned research initiatives are fundamental for situational awareness in emergency management 
and for monitoring of social media activities.
Now, we illustrate our approach to emergency management IT-system, in the following Figure 3 and 
describe major modules of the system. The overall objective is a stronger connection between public 
and emergency services or authorities through social media (Akerkar et al, 2016). In the process, huge 
amounts of ubiquitous, user-generated content in social media is frequently generated and monitored for 
emergency related communication. Citizens post messages on social media: amongst those, messages 
somehow related to emergencies may be present. Once detected, content is gathered and transferred to 
the analytical phase, where it is pre-processed, analysed according to various data mining analytical ap-
proaches. The alerts are generated and then either transferred to routing component for reporting where 
it can be visualized and interpreted or moves to the communication management module. For instance, 
The Routing module distributes messages towards responsible emergency service (ES), which use their 
Command & Control systems or the ES interfaces provided by the system to consume the information. 
The alert distribution is performed checking continuously for new alerts. Authorities or emergency 
service personnel can communicate with the public.
Now we will present some key aspects of our IT-system.

156
Processing Big Data for Emergency Management
﻿
Table 2. Social media and emergency management project
Project Name
Project Objectives
Social Media /
Data Source
Approaches
Visualization components
Filtering 
mechanism
Possible Usefulness to our 
approach
Alert4All 3
Alert4All aimed at improving 
the effectiveness of alert and 
communication towards the 
population in crises management.
Twitter, blogs
Classification, 
Support Vector 
Machine classifier
map
Keyword, tags
Usage of results, especially on 
how citizens trust information 
from EMS through different 
communication channels.
COSMIC4
COSMIC project is identifying 
the most effective ways in which 
new technologies and applications 
are being used by citizens and 
governments.
YouTube, 
Twitter, 
Facebook
Classification
list, recommendations and 
best practices
Topic, 
information
Mapping the use of current 
technologies in crises and also 
mapping the use of emerging 
applications. Usage of findings on 
the potential roles and ethics for 
citizen participation in emergency 
response.
CrisComScore5
The project developed an audit 
instrument as a tool for ensuring 
effective crisis communication 
strategies and implementation.
News media
Text processing
Text messaging
Topic, nformation
The auditing instruments for 
effectiveness will be one possible 
measurement 
method in the analysis phase.
CRISMA6
The CRISMA project will develop 
a simulation-based decision 
support system, for modelling crisis 
management, improved action and 
preparedness.
Data from 
sensors
Priorisation, 
Optimisation of 
response, counter 
measures and 
preparedness
GIS based visualization, 
Real-time environmental 
data visualization
Information
The auditing of decisions in crisis 
management will be one possible 
measurement method in the 
analysis phase.
ESS7
The ESS project developed a 
common information management 
and communication platform 
for supporting the management 
and coordination of emergency 
operations.
Real-time sensor 
data (thermal, 
video etc.)
Spatial localization, 
Data fusion
Map, lists
Time, query
Analysis of state-of-the-art 
technologies for crisis discovery 
and management and application 
of existing data fusion methods 
for developing a data fusion and 
mediation system.
IDIRA8
IDIRA project is focusing on 
the interoperability of data and 
emergency procedures in response 
to large-scale disasters.
Geographic and 
attribute data, 
integration of 
sensor data
Text classification, 
map, lists
Geo-referenced 
Visualisation map
Topic, time, 
information
Methods and technical 
interoperability standards 
developed here will influence the 
integration aspects.
INDECT9
The project is developing threat 
detection tools and generation 
of data mining and information 
retrieval applications.
Weblogs, chats, 
news reports
Relationship 
mining, machine 
learning methods 
for behavioural 
profiling
Event model
Keyword, query
Consideration of methodologies 
and algorithms for data & event 
processing.
continued on following page

157
Processing Big Data for Emergency Management
﻿
Project Name
Project Objectives
Social Media /
Data Source
Approaches
Visualization components
Filtering 
mechanism
Possible Usefulness to our 
approach
iSAR+10
iSAR+ project delivered the 
guidelines that enable citizens using 
new online and mobile technologies 
to actively participate in response 
efforts, through the provision, 
sharing and retrieval of emergency 
information.
SMS, Twitter, 
Videos
Multivariete 
testing, Design of 
experiments
-
Tags, time, 
location
Its approach to the dynamics 
between citizens and EMS in 
crises, allowing the leverage of 
EMS’ levels of shared awareness 
and performance, benefiting from 
citizens’ published information.
REACT11
REACT has enhanced data by 
providing associated services that 
are able to semantically analyse and 
cluster environmental and crisis 
management information.
Data from callers 
and automatic 
systems
Semantic analysis
GIS based interface
Location, 
keyword, time, 
semantic
Usage of the OASIS CAP Protocol 
to allow interoperability between 
Emergency Services together with 
the TSO protocol for a common 
data ontology.
SocialSensor12
SocialSensor is developing a 
framework for enabling 
real-time multimedia indexing and 
search across multiple 
social media sources.
Facebook, 
Youtube, 
Flickr, Tumblr, 
Google+, 
Instagram
Clustering of 
geodata and visual 
descriptors
Map, timeline, lists
Sorting, zooming
Scalable mining and indexing 
approaches that taking into 
account the content and social 
context of social networks.
WeKnowIt13
The system built in this project 
was based on interviews performed 
considering emergency management 
practitioners.
Pictures, Videos, 
Text
Text processing, 
Clustering
Map, Timeline
Tag, Time
The results of the layer of social 
interaction and the massive user 
feedback layer will be considered 
as one of the inputs for metrics.
Crisees14
Crisees has developed a monitoring 
tool for social media streams.
Youtube, Twitter
Extension to 
Sentiment
Map, Lists
Time, Query
Extracting information from social 
media. Filtering information 
related to event. Visualising 
information on maps.
Disaster 2.015
Disaster 2.0 (D2.0) project has 
explored how EU governments can 
potentially use Web 2.0 applications 
and Semantic Technologies in 
disaster response.
Twitter, 
Facebook, 
Ushahidi
Semantic 
technologies
Map, List
Tag, location, 
keyword
Use of results in which public 
utilise web 2.0 and web 3.0 
technologies during disasters
Emergency 
Situation 
Awareness 
Platform16
The emergency situation awareness 
platform analysed tweets.
Twitter
Aggregation, 
Text clasification, 
Keywords
Map, Tag cloud, Timeline
Slices time, 
Traffic, Tag
The research results on text 
classification to identify the 
impact of the incidents identified.
continued on following page
Table 2. Continued

158
Processing Big Data for Emergency Management
﻿
Project Name
Project Objectives
Social Media /
Data Source
Approaches
Visualization components
Filtering 
mechanism
Possible Usefulness to our 
approach
SensePlace217
SensePlace2 developed a system for 
filtering Twitter messages.
Twitter
Named entity 
recognition
Map, timeline
Time, Tag cloud
Use of different search and 
filtering facilities to browse 
through a huge amount of tweets 
by considering the extracted 
information.
TEDAS18
TEDAS project developed an event 
detection system for Twitter.
Twitter
Classification & 
rules, spatial and 
temporal analysis
Map, Timeline
Location, 
Keyword, Time
Results to detect and 
analyze events by exploring rich 
information from social media
Tweak-the-
Tweet19,20
Tweak-the-tweet was a 
crowdsourcing platform. The key 
difference to other platforms is that 
this system ‘works with the existing 
social media infrastructure’.
Twitter
Trust grammar, 
parsing
Map, Timeline
Predefined 
hashtags
Parsing algorithm applied to 
extract information given in 
combination with hashtags. This 
extracted information useful to 
perform keyword-based filtering.
Twitcident21
Twitcident project developed a 
toolbox for filtering and analyzing 
information from Twitter streams 
during crisis situations such as fires, 
storms or other types of incidents.
Twitter
Classification, rules
Map
Keyword, facets
Results related to facet-search 
interfaces, i.e. on facets extracted 
in the previous steps, which helps 
the user to browse through the data 
to gain a better overview.
TwitterBeat22
The TwitterBeat analyzes huge 
amounts of textual data uncovering 
the sentiment.
Twitter
Sentiment on topic 
and location
Map
Zooming
Approaches on sentiment analysis 
can be used to identify the mood 
after a disaster, for e.g., for crime 
prevention.
Twitris23
Twitris project presents an 
opportunity to aggregate social 
media information. Twitris provides 
situational awareness by monitoring 
an event on Twitter at both micro 
and macro-levels.
Twitter, SMS
Event discriptors
Map, Tag clouds
Spatial temporal 
theme
Results on context based semantic 
integration of multiple Web 
resources and expose semantically 
enriched social data to the public 
domain.
Crisees24
Crisees has developed a monitoring 
tool for social media streams.
Youtube, Twitter
Extension to 
Sentiment
Map, Lists
Time, Query
Extracting information from social 
media. Filtering information 
related to event. Visualising 
information on maps.
Table 2. Continued

159
Processing Big Data for Emergency Management
﻿
5.1. Data Enrichment
Data enrichment refers to processes used to enhance, refine or otherwise improve raw data. Various 
studies indicate that extraction of relevant information is a major challenge (Chaudhuri 2012), (Abel 
2011). Different circumstances require different assessment methods (Reuter 2015), and different data 
or meta-data. We can distinguish between source-based and computation-based enriched data: source-
based data is either directly given by the raw data, or not provided, and therefore requires no further 
computation besides extraction. The actual source-based data varies among different social networks 
such as Facebook, Google+, Instagram, Twitter or YouTube and is challenged by different technical 
and business-oriented limitations (Castillo, 2016). Provided data includes date, time, sender, title, tags, 
keywords, comments, replies, answers, number of views, dislikes, retweets, shares, age, gender, loca-
tion, education, uploads, watches, total posts and real name. In addition to source-based enriched data, 
computation-based enriched data, which requires one or multiple steps of algorithmic computation, is 
vital. Whilst some of the computations can be done on the local server, others may require the invoca-
tion of remote APIs. Computationally obtained data includes language detection and sentiment analysis. 
The provision of enriched data is helpful due to the fact that situation assessment has been shown to 
be very subjective (Rizza et al, 2013). Thus, information needs depend on personal feelings, experi-
ence and the situation itself, wherever information is gathered and analysed, and information systems 
are implemented to support this task. However, there is a usual challenge on implementing systems to 
Figure 3. EmerGent IT-system

160
Processing Big Data for Emergency Management
﻿
allow both the automatic selection of relevant data and the potentials for end-users to adapt automation 
and enable tailorable quality assessment according to their requirements. Enriched data supports us to 
tackle this challenge.
5.3. Semantic Issues
Semantic technologies have the capability to help us cope better with social media data overload. Ap-
plying semantic technologies to represent information can provide exceptional means for effectively 
sharing and using data within different organizations. Using highly structured, self-descriptive pieces 
of information, interlinked with multiple data resources can help develop a unified and accurate un-
derstanding of an evolving scenario. This provides an excellent framework for developing applications 
and technologies that are highly generic, reproducible and extendible to different regions, conditions, 
and scenarios. In addition, the semantic descriptions of data can enable new forms of analyses on this 
data, such as checking for inconsistencies, verifying developments according to planned scenarios, or 
trying to discover interesting semantically meaningful patterns in data. Such analytics can be performed 
either in real-time as the scenario unfolds, e.g., through semantic stream processing and event detection 
techniques, or as an after-action analysis to learn from past events.
On-going research (Galton and Worboys, 2011), (Grolinger et al, 2011) has shown that the need of a 
common understanding of concepts within and across domains is important to avoid misunderstandings. 
However, that it is generally accepted to build an ontology from scratch, which does not tap the existing 
potential of relevant, domain-related knowledge bases. Thus ontologies are often implicitly tailored to 
a specific need. The ontology can be used to apply semantic analysis on gathered data from SM. This 
includes the application of further data mining methods to detect patters, incidents or unusual events as 
well as the detection of correlations. Another advantage of this approach is that emergency services are 
not essentially required to deal with tweets or posts and may work with domain-related information. To 
facilitate information exchange with external systems, domains it is necessary that new developments 
build upon existing standards also on conceptual level. Hence current information models like FOAF, 
SIOC or MOAC have been considered to construct an ontology that associates information from SM 
with domain knowledge. Thus one can reuse and extend existing information models in order to combine 
extracted emergency related content with social media data.
The IT-system is building a large elastic data store in the cloud. It will comprise semantic data stored 
as RDF for OWL. In order to handle data of enormous size we expect a requirement for parallel computa-
tion, subdividing information and execution between different machines that work in the same network. 
The main challenge to storing RDF objects in NoSQL databases is to find the right way to represent 
graph inside them. Different studies have tried to use HBase (based on Hadoop) as a NoSQL database 
coupled with a semantic data framework like Apache Jena (Khadilkar et al, 2012).
We will explore a mixture of NoSQL plus a purely semantic database. For data gathering, a NoSQL 
solution possibly based on MongoDB is able to fulfil requirements in terms of performance and scal-
ability. We are upholding in the semantic storage only the data that will be analysed (execute queries 
and apply data mining techniques), and creating a parallel storage for data that is already processed.

161
Processing Big Data for Emergency Management
﻿
5.4. Data Mining
Data mining research has effectively created numerous methods, tools, and algorithms for handling large 
amounts of data to solve real-world problems. Many standard DM techniques have been developed and 
successfully implemented across a range of applications (Akerkar and Lingras 2008). However, mining 
SM comes with a set of unique challenges which have been the focus of much research in recent years 
(Gimpel et al 2011), (Imran et al 2013), (Castillo 2016). Primary objectives of the data mining process 
are to efficiently manage large-scale data, extract actionable patterns, and obtain insightful knowledge. 
Because social media is widely used for various purposes, huge amounts of user-generated data exist 
and can be made available for data mining. Data mining of social media can expand our capability of 
understanding new phenomena due to the use of social media and improve business intelligence to provide 
better services and develop innovative opportunities. In data mining data is transferred into information 
that needs to be understood in a domain-specific context.
Standard natural language processing (NLP) tools usually fail when faced with the non-standard, 
untidy language frequently found in SM (Eisenstein 2013), (Liu et al 2012). Additionally, scalability 
issues are present with SM data. During an emergency the mining tools must be able to capably deal 
with increased volumes of data. By analysing the enriched data and using NLP techniques on any textual 
content, combination of mining techniques consolidates multiple SM messages into an information-rich 
event. However, all together we need a seemly methodology to model any event information.
5.5. Data Quality Issues
Data quality is one of strongest barriers when using citizen-generated content through social media in 
emergency management. Indeed, issues of reliability, quantification of performance, deception, focus of 
attention, and effective translation of reported observations/inferences arise when emergency managers 
start engaging their organisational mechanisms to respond to the disaster. Thus, with the empowerment 
of the general public and the abundance of information on SM, fostering data quality (DQ) is central 
for decision makers to achieve an effective and efficient outcome in the emergency response (Jensen 
2012). A challenging issue in this domain is to determine how to generate, score, update and represent 
data and information quality cues to support operators to reason under uncertainties and improve their 
understanding about an ongoing situation.
Our approach follows the general quality literature by viewing quality as the capability to ‘meet or 
exceed users’ requirements. Common examples of DQ dimensions are accuracy, completeness, consis-
tency, timeliness, interpretability, and availability. Over the last decade, many studies have confirmed 
Table 3. DQ diamensions
Intrinsic 
dimensions
Contextual 
Dimensions
Representational 
Dimensions
Accessibility 
Dimensions
Believability 
Accuracy 
Objectivity 
Reputation
Value-added 
Relevance 
Completeness 
Timeliness 
Appropriate amount 
of data
Interpretability 
Ease of 
understanding 
Representational 
Consistency 
Concise 
representation
Accessibility 
Access security

162
Processing Big Data for Emergency Management
﻿
that DQ is a multi-dimensional concept and its evaluation should consider different aspects. Despite the 
multidimensional nature of DQ, it is nevertheless a single phenomenon. DQ dimensions are inherently 
dependent on each other. For example, to get more accurate information, more time might be required. 
Accessibility and security are also dependent on each other.
In our research, we are analysing prominent frameworks and develop a DQ assessment technique 
and reconciliation concept for emergency information. This allows us to assign numerical or categorical 
values to DQ criteria for information and then subsequently select and prioritise information accordingly 
to the specific emergency situation. The assessment of the quality of the content in social media adds 
a significant layer of complexity over traditional DQ assessment frameworks. Challenges arise in tim-
ing issues and evaluating the trustworthiness, completeness and accuracy of the quality of content that 
has been created by users from different backgrounds, in different situations and for different domains.
5.6. Data Visualization for Emergency Decision Support
There are several kinds of visualization techniques25 for complex – or even SM datasets: simple lists, 
spatial and temporal representations or charts and graph-based visualizations. The high-level visualization 
applies very restrictive filters to keep the amount of data as small as possible. The low-level visualization 
provides a more detailed view on the data.
In our ongoing research project we are tackling aforesaid concerns, with the help of the proposed 
IT-system the connection between citizens and emergency Services will be enhanced.
6. CONCLUSION
In this paper we have outlined an outlook of processing and analysing big data streams before, during, 
and after emergencies. Tools that can be used by many emergency services will have significant broad 
impact in helping citizens as well as many emergency services and government agencies. Big data is a 
great global opportunity for emergency management. Big data has already demonstrated its usefulness 
for both dedicated sensor networks (e.g., earthquake detection during the earthquake) and multi-purpose 
sensor networks (e.g., social media such as Twitter). However, significant research challenges remain, 
particularly in the areas of Variety of data sources and Veracity of data content. We have also described 
our efforts in developing emergency management tool that uses social media to support the management 
of large scale emergencies. It includes the construction of a big online store of data which will be continu-
ously mined to provide emergency information and alerts. Thus, as we keep confronting emergencies, 
which have become more common during the last few years, emergency service providers can be more 
efficient in dissemination of warning messages or/and alerts, better manage citizen’s sentiment triggered 
by the disaster, earn trust of citizens, and enhance authorities and citizen cooperation during emergencies.
AKNOWLEDGMENT
The research has received funding from a grant of the European Union (7th Framework Programme No. 
608352).

163
Processing Big Data for Emergency Management
﻿
REFERENCES
Abel, F., Gao, Q., Houben, G., & Tao, K. (2011). Semantic enrichment of twitter posts for user profile 
construction on the social web. Lect. Notes Comput. Sci., 6643, 375–389. doi:10.1007/978-3-642-
21064-8_26
Akerkar, R. (2013a). Big Data Computing. Chapman and Hall/CRC. doi:10.1201/b16014
Akerkar, R. (2013b). Improving Data Quality on Big and High-Dimensional Data. Journal of Bioinfor-
matics and Intelligent Control, 2(1), 155-162.
Akerkar, R., Friberg, T., & Amelunxen, C. (2016). EmerGent Deliverable 3.5: User Requirements (Ver-
sion 2). Paderborn.
Akerkar, R., & Lingras, P. (2008). Building an Intelligent Web. Jones and Burtlett.
Appleby, L. (2013). Connecting the last mile: The role of communications in the great East Japan 
earthquake. London: Internews.
Armbrust, Fox, Griffith, Joseph, Katz, Konwinski, … Zaharia. (2010). A view of cloud computing. 
Communications of the ACM, 53(4), 50–58.
Becker, H., Naaman, M., & Gravano, L. (2009). Event identification in social media. Twelfth Interna-
tional Workshop on the Web and Databases.
Castillo, C. (2016). Big Crisis Data: Social Media in Disasters and Time-Critical Situations. Cambridge 
University Press. doi:10.1017/CBO9781316476840
Chang, V. (2015). Towards a Big Data system disaster recovery in a Private Cloud. Ad Hoc Networks, 
35, 65–82. doi:10.1016/j.adhoc.2015.07.012
Chaudhuri, S. (2012). What Next? A Half-Dozen Data Management Research Goals for Big Data and 
the Cloud. Proc. 31st Symp. Princ. Database Syst., 1–4.
Currion, P. (2010). “If all You Have is a Hammer” - How Useful is Humanitarian Crowdsourcing? 
Retrieved from http://www.crowdsourcing.org/document/if-all-you-have-is-a-hammer---how-useful-is-
humanitarian-crowdsourcing/3533
Eisenstein, J. (2013). What to do about bad language on the internet. Proceedings of NAACL-HLT 2013, 
359–369.
Fazio, M., Celesti, A., Puliafito, A., & Villari, M. (2015). Big Data Storage in the Cloud for Smart En-
vironment Monitoring, Procedia. Computer Science, 52, 500–506.
Galton, A., & Worboys, M. (2011). An ontology of information for emergency management. Int. Conf. 
Cris. Response Manag., 8, 1– 10.
Gimpel, K., Schneider, N., O’Connor, B., Das, D., Mills, D., Eisenstein, J., … Smith, N. (2011). Part-
of-speech tagging for Twitter: Annotation, features, and experiments. Proceedings of the 49th Annual 
Meeting of the Association for Computational Linguistics: Human Language Technologies: Short papers, 
2, 42–47.

164
Processing Big Data for Emergency Management
﻿
Grolinger, K., Brown, K., & Capretz, M. (2011). From Glossaries to Ontologies: Disaster Management 
Domain. Academic Press.
Ilrina, S., Burke, M., Kiesler, S., & Kraut, R. (2010). Technology adoption and use in the after-
math of Hurricane Katrina in New Orleans. The American Behavioral Scientist, 53(8), 1228–1246. 
doi:10.1177/0002764209356252
Imran, M., Elbassouni, S., Castillo, C., Diaz, F., & Meier, P. (2013). Extracting information nuggets from 
disaster-related messages in social media. Proceedings of the 10th international ISCRAM Conference.
Jensen, G. E. (2012). Key criteria for information quality in the use of online social media for emergency 
management in New Zealand. Victoria University of Wellington.
Kamel Boulos, M. N., Sanfilippo, A. P., Corley, C. D., & Wheeler, S. (2010). Social Web Mining and 
Exploitation for Serious Applications: Technosocial Predictive Analytics and Related Technologies for 
Public Health, Environmental and National Security Surveillance. Computer Methods and Programs in 
Biomedicine, 100(1), 16–23. doi:10.1016/j.cmpb.2010.02.007 PMID:20236725
Khadilkar, V., Kantarcioglu, M., Thuraisingham, B., & Castagna, P. (2012). Jena-HBase: A Distributed, 
Scalable and Efficient RDF Triple Store. 11th International Semantic Web Conference.
Liu, X., Zhou, M., Zhou, X., Fu, Z., & Wei, F. (2012). Joint inference of named entity recognition and 
normalization for tweets. Proceedings of the ACL.
Meier, P., & Munro, R. (2010). The unprecedented role of SMS in disaster response: Learning from 
Haiti. SAIS Review of International Affairs, 30(2), 91–103.
Musaev, De Wang, & Pu. (2014). LITMUS: Landslide Detection by Integrating Multiple Sources. In 
S.R. Hiltz, M.S. Pfaff, L. Plotnick, & P.C. Shih (Eds.), Proceedings of the 11th International ISCRAM 
Conference, (pp. 677-86). Academic Press.
Page, S., Freberg, K., Saling, K., & Model, E. M. C. V. (2013). A Comparison of Relevant, Timely Message 
Strategies for Emergency Events. Journal of Strategic Security, 6(2), 20–31. doi:10.5038/1944-0472.6.2.2
Porto de Albuquerque, J., Herfort, B., Brenning, A., & Zipf, A. (2015). A geographic approach for 
combining social media and authoritative data towards identifying useful information for disaster man-
agement. International Journal of Geographical Information Science, 29(4), 667–689. doi:10.1080/13
658816.2014.996567
Pu, C., & Kitsuregawa, M. (Eds.). (2013). JST/NSF Joint Workshop Report on Big Data and Disaster 
Management. Technical Report No. GIT-CERCS-13-09. Georgia Institute of Technology, CERCS.
Reuter, C., Ludwig, T., Ritzkatis, M., & Pipek, V. (2015). Social-QAS: Tailorable Quality Assessment 
Service for Social Media Content. Proceedings of the International Symposium on End-User Develop-
ment (IS-EUD). doi:10.1007/978-3-319-18425-8_11
Rizza, C., Pereira, Â., & Curvelo, P. (2013). Do-it-yourself Justice-Considerations of Social Media use 
in a Crisis Situation: The Case of the 2011 Vancouver Riots. Proceedings of the Information Systems 
for Crisis Response and Management (ISCRAM), 411–415.

165
Processing Big Data for Emergency Management
﻿
Sheth, A., Anantharam, P., & Henson, C. (2013). Physical-cyber-social computing: An early 21st century 
approach. IEEE Intelligent Systems, 28(1), 79–82. doi:10.1109/MIS.2013.20
Stanton, N. A., Chambers, P. R., & Piggott, J. (2001). Situational awareness and safety. Safety Science, 
39(3), 189–204. doi:10.1016/S0925-7535(01)00010-8
Vardi, M. (2011). Computing for Humans. Communications of the ACM, 54(12).
Xu, Z. (2016). Crowdsourcing based description of urban emergency events using social media big data. 
IEEE Trans. Cloud Comput. doi:10.1109/TCC.2016.2517638
Yin, J., Lampert, A., Cameron, M., Robinson, B., & Power, R. (2012). Using social media to enhance 
emergency situation awareness. Intell. Syst. IEEE, 27(6), 52–59. doi:10.1109/MIS.2012.6
Zeng, J., Yang, L. T., Man Lin, H. N., & Ma, J. (2016). A survey: Cyber-physical-social systems and their 
system-level design methodology. Future Generation Computer Systems. 10.1016/j.future.2016.06.034
KEY TERMS AND DEFINITIONS
Analytics: Using software-based algorithms and statistics to derive meaning from data.
Big Data: Big data refers to the new technologies and applications introduced to handle increasing 
Volumes of social data while enhancing data utilization capabilities such as Variety, Velocity, Variability, 
Veracity, and Value.
Emergency Management: The term “emergency management” is used to encompass all of the 
activities carried out by the federal state and local agencies that are referred to as EMS. These activities 
have the primary goal of managing hazards, risks, and emergencies of all types.
Data Analytics: The application of software to derive information or meaning from data. The end 
result might be a report, an indication of status, or an action taken automatically based on the informa-
tion received.
Scalability: The ability of a system or process to maintain acceptable performance levels as workload 
or scope increases.
Semi-Structured Data: Data that is not structured by a formal data model, but provides other means 
of describing the data and hierarchies.
Structured Data: Data that is organized by a predetermined structure.
ENDNOTES
1	
Hirschfeld, D. Twitter data accurately tracked Haiti cholera outbreak. Available from http://www.
nature.com/news/twitter-data-accurately-tracked-haiti-choleraoutbreak-1.9770.
2 	
Pear Analytics, “Twitter Study”, http://www.pearanalytics.com/wp-content/uploads/2012/12/
Twitter-Study-August-2009.pdf,
3 	
http://www.alert4all.eu/
4 	
http://www.cosmic-project.eu
5 	
https://www.jyu.fi/hum/laitokset/viesti/en/research/projects/eucrisiscommunication

166
Processing Big Data for Emergency Management
﻿
6 	
http://www.crismaproject.eu/
7 	
http://www.ess-project.eu/
8 	
http://www.idira.eu/
9 	
http://www.indect-project.eu/
10 	
http://isar.i112.eu/
11 	
http://www.react-ist.net
12 	
http://www.socialsensor.eu/
13 	
http://www.weknowit.eu/
14 	
http://www.dcs.gla.ac.uk/access/crisees
15 	
http://repository.disaster20.eu/frontpage
16 	
http://www.csiro.au/Outcomes/ICT-and-Services/emergency-situation-awareness.aspx
17 	
http://www.geovista.psu.edu/SensePlace2/
18 	
https://wiki.cites.illinois.edu/wiki/display/forward/Demo-TEDAS
19 	
http://epic.cs.colorado.edu/?page_id=11
20	
http://faculty.washington.edu/kstarbi/TtT_Hurricane_Map_byEvent.html
21 	
http://twitcident.com/
22 	
http://www.sgi.com/go/twitter/
23 	
http://twitris.knoesis.org
24 	
http://www.dcs.gla.ac.uk/access/crisees
25 	
http://www.interactiondesign.us/courses/2011_AD690/PDFs/Shneiderman_1996.pdf

167
Copyright © 2018, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.
Chapter  6
DOI: 10.4018/978-1-5225-2575-2.ch006
ABSTRACT
Natural disaster is one of the important topics in current researches. Disaster Management System (DMS) 
is a complex system and needs to perform a collection of tasks collaboratively along with the potentiality 
to change the configurations of the system dynamically. In the research era of workflow model, existing 
models mainly deal with temporal and static constrains. However they cannot be used to keep pace 
with an uncertainly dynamic system like disaster management. Considering all these significant DMS 
attributes we have designed a new dynamically configurable and changeable workflow model with the 
support of adaptive scheduling, for both successful and failed situations, and implemented in a distrib-
uted cloud system to maintain the rescue and reorganization activities of disaster situation. In order to 
simplify the system architecture, we have used Multi Agent System (MAS) for our design. The proposed 
system achieves a comparatively higher rate of successful job completion-higher rescheduling success 
rate and comparatively lower dropout rate.
INTRODUCTION
Natural disasters include hurricanes, floods, tornadoes, limnic eruptions, volcanic eruptions, earthquakes, 
tsunamis, and other geologic processes are becoming more common. They can cause loss of life, damage 
properties, destruction of buildings, spread of diseases etc. People also suffer the accessibility of health 
care and education, as well as food supplies and clean water. Disaster or emergency management is the 
Exploring Cloud-Based 
Distributed Disaster 
Management With Dynamic 
Multi-Agents Workflow System
Mansura Habiba
AIUB, Bangladesh
Shamim Akhter
East West University, Bangladesh

168
Exploring Cloud-Based Distributed Disaster Management
﻿
creation of plans through which communities reduce vulnerability to hazards and cope with disasters. 
Disaster management does not eliminate the threats; instead, it focuses on creating plans to decrease 
the effect of disasters (Web1, 2017) and (Thomas, 1991). Thus, Disaster management is a complex 
system and needs to perform a collection of tasks collaboratively along with the potentiality to change 
the configurations of the system dynamically.
In order to run an efficient Disaster Management System (DMS), it is necessary to maintain proper 
chain of commands and hierarchical decision making, so that any task performed by the system will 
be validated, and efficiently evaluated. In a word, DMS needs a dynamic decision making component. 
The main goal of decision making component is to provide an efficient sequence of decisions which 
are either independent or mutually dependent as well as feasible to execute using the heterogeneous 
resources and efficient enough to reduce the processing time and cost of the whole process. However, 
existing workflow models mainly deal with temporal and static constrains. However they cannot be used 
to keep pace with an uncertainly dynamic system like disaster management.
Workflow models and WfMS have been discussed in Buhler and Vidal, 2005; Eder and Gruber, 
2002; Lis and Korherr, 2006. However, they are not suitable for disaster management concepts because 
of their inability to use resource management, delegation functionalities and state modeling approaches. 
Furthermore, a number of current WfMS systems have lack of adaptation during execution. The WfMS 
for emergency plans has been presented in Shell & Braun, 2009, however their WfMS considered the 
emergency plans as workflows model and acted similar to business processes. This kind of workflow is 
useable during immediate action phase of disaster management life cycle. They did not consider resched-
uling mechanism for the failed/dropped tasks. Thus, the system behaves as static and pre-fixed domain.
Considering all these significant DMS attributes we have designed a new dynamically configurable 
and changeable workflow model with the support of adaptive scheduling, for both successful and failed 
situations, and implemented in a distributed cloud system to maintain the rescue and reorganization 
activities of disaster situation. If the communication channel can be widen and make faster, the coopera-
tion among several groups, effective resource sharing and collaborative decision making will enhance 
the performance of DMS to a great extent. Therefore, a collaborative model of workflow using multiple 
agent based system architecture has been proposed. In Jennings et al., 2001, multi agent systems are suc-
cessfully deployed in diverse applications for complex and dynamic environments. We believe it can be 
beneficial to apply the potential of multi agent systems research to minimize the effects of such disasters. 
DesInventar (Wattegama, 2007) is used to simulate the performance of the proposed workflow model 
and scheduling algorithms. The proposed system achieves a comparatively higher rate of successful job 
completion (65.07%)-higher rescheduling success rate (81%) and comparatively lower dropout rate (10%).
The rest of this chapter is organized as follows: section 2 gives the background of the work. Section 
3 introduces the MAS based workflow model and adaptive scheduling. Section 4 presents the cloud 
implementation of the proposed DMS. Section 6 proves the performance of the proposed DMS through 
simulated data with the state-of-the-art. Finally, section 6 concludes the work of this paper and outlines 
the future work.
BACKGROUND
Extreme environmental events, like tsunami, tropical storms, flooding, forest, fires, etc. can lead to wide-
spread disastrous effects on our society. The frequency of such incidents in the recent past has focused 

169
Exploring Cloud-Based Distributed Disaster Management
﻿
the urgency of developing technological solutions to mitigate the damaging effects of natural disasters 
(Mendona & Wallace, 2004).
Usually a DMS has several main components for different important and foundational activities such as
•	
Decision Making component
•	
Task Identification and Preparation Component
•	
Resource Management Component
•	
Operation Component
•	
Monitoring Component
•	
Planning Component
These entire components are very complex and inter dependent on each other. In traditional DMS, 
all activities within each component are performed manually and take long time which delays the actual 
emergency and recovery stage of disaster management life cycle. For example Figure 1 shows the activi-
ties within decision making component in case of the disaster management system established in Japan 
proposed by KAZUSA in (Kazusa, 2011).
It is clear from Figure 1, that the authority needs to perform manual investigation in order to identify 
the priority and damage due to natural disaster and all these activities need lot of time and analysis. For 
human being in current system even more time is required and the final result is also not free from error. 
Therefore, automated DMS is required.
Several ICT based solutions for mainly emergency alert have been proposed such as Common Alert-
ing Protocol (CAP) (Wattegama, 2007) and Tsunami Early Warning System in (Wattegama, 2007) and 
Figure 1. Decision making Activities in DMS in Japan

170
Exploring Cloud-Based Distributed Disaster Management
﻿
(NAZAROV, 2011). Some data analysis tool is also improving to facilitate the planning and recovery 
phase of disaster management system. Recently in Japan (Kazusa, 2011), (Wattegama, 2007), (NAZ-
AROV,2011), and (Web3, 2006), Taiwan (Chen et al., 2006), India (Web4, 2017) and some other countries 
have focused to use ICT for natural and manmade disaster system in different phases of disaster such as 
emergency warning, response, recovery as well as planning.
DesInventar (Wattegama, 2007) is a tool which uses systematic way to gather and store information 
about characteristics and effects of different types of disasters. The DesInventar system can also be used 
to simulate disasters and study their impact. DesInventar only facilitates the analysis of disaster-related 
information for applications in planning, risk mitigation and disaster recovery purposes. However, this 
tool cannot directly take part in planning and decision making during a disaster situation. It can only 
store data and provide us a heuristic metadata for analysis the situation.
Groove (acquired by Microsoft, (Wattegama, 2007)) is also used in disaster management to facilitate 
collaboration and communication among small groups. However, the main challenge of Disaster Man-
agement system (DMS) is the lack of communication (Jennings et al. 2001 and Lander et al. 1993). If 
the communication channel can be widen and faster, the cooperation among several groups, effective 
resource sharing and collaborative decision making will enhance the performance of DMS to a great extent.
(Lesser & Corkill, 1983) presents multi agent systems and they are successfully deployed in diverse 
applications for complex and dynamic environments. In addition, (Schurr et al., 2005) presents a large-
scale prototype, DEFACTO that focuses on illustrating the potentiality of future agent-based response to 
disasters. We, therefore, believe it can be beneficial to apply the potential of multi agent systems research 
to minimize the effects of such disasters.
(Shell & Braun, 2009) has identified four major problems of the traditional multi-page printed docu-
ment based disaster management system such as restricted situation overview due to the paper based 
structure of emergency plan. It is very difficult to get an overview of completed, running and pending 
measures and therewith overall development at a glance. The next problem identified by them in current 
DMS is the absence of resource management system. It is very important in a dynamic DMS to identify 
the set of resources, and that is needed to be provided prior to the starting of a task. However, there is no 
technical support for this mammoth task in traditional DMS. In this proposed model, we have introduced 
the resource management system for DMS. The third identified problem is the lack of flexibility. Unpre-
dictable events and fast changing environmental conditions are typical for disaster. Currently there is no 
suitable tool support for rescheduling activities in such uncertain system. The fourth identified problem 
is non-supportive for delegation. Currently fax and telephone are used for delegation, and sometime 
may not be available in a disaster prone location. However, no structure is prepared for the delegation 
and collaborative decision making in conventional DMS.
Moreover, (Shell & Braun, 2009) has presented a model for a workflow management system (WfMS) 
for supporting the modeling, execution and management of emergency plans of disasters. The main 
concept of their WfMS is the emergency plans and that can be modeled as workflows as they are similar 
to business processes. However, this WfMS is only useable during immediate action phase of disaster 
management life cycle, it does not have any scheduling algorithm, and it also does not described the 
aftermath of failed and paused tasks. Thus, the existing WfMS considered DMS as static and certain 
system. However, DMS is very unpredictable and dynamic system.
From the above discussion it has been cleared that the current DMS has lack of capability to adapt 
with dynamicity of disaster situation and needs automated collaborative system. Automated multi agents 

171
Exploring Cloud-Based Distributed Disaster Management
﻿
disaster management system can perform all data collection through satellite and wireless sensor net-
working (Wattegama, 2007), and can perform faster data analysis and better accuracy.
As a result proposed workflow model is so far a unique model which can take decision on unpredict-
able, dynamic and uncertain disaster situations and can schedule tasks with better resource management 
considering several constraints such as cost, priority, quality, time and number of resources at the same 
time. In addition proposed model is capable to provide a collaborative framework for better delegation.
There is no standard to define DMS life cycle. Different researches have defined disaster system in 
different ways (NAZAROV, 2011), (Web3, 2006) and (Sell & Braun, 2009). For designing the proposed 
workflow model, we consider four different stages of DMS life cycle. Figure 2 presents the four stages 
with their corresponding activities.
(Sell & Braun, 2009) has identified five basic requirements to design a workflow management sys-
tem (WfMS) for emergency plan during disaster management system such as resource management, 
representation of current state, adoption of WfMS prior as well as during execution. In addition, we 
introduce some additional requirements for the better WfMS performance on DMS. The additional 
requirements are as follows:
•	
Dynamic Configuration: only dynamically configurable WfMS can able to handle dynamic di-
saster situation.
Figure 2. Disaster Management Activities Life Cycle

172
Exploring Cloud-Based Distributed Disaster Management
﻿
•	
Instant Notification: DMS has strong inter-dependency among these components. As a result, 
the proposed WfMS collects information about every transition state of the WfMS and notify all 
related components of WfMS.
•	
Parallel Data Collection: One unique feature of the proposed WfMS model is to support im-
mediate post planning. For this purpose, Analyzer Ant (AA) collects data of each stage of DMS 
in parallel to each activities of task execution. All these data are accumulated and formatted for 
post-panning activities.
Thus, the proposed WfMS is designed to perform against the three aforementioned requirements, in 
addition to the five basic requirements identified in (Sell & Braun, 2009).
THE MAS BASED WORKFLOW MODEL
Workflow System Architecture
The proposed workflow is designed with four layered system architecture in order to depict the real 
time emergency disaster management scenario. The top layer contains the global resource manager. The 
second layer has the data storage with proper privacy (access permission). Then the third layer has the 
resource owner agents. Data collector and analyzer agents are reside in this layer. The last/bottom layer 
holds the resource pool. In Figure 3, the complete problem domain is divided into several local areas. In 
each local area, there is a resource owner agent (RA) - who owns the resource. RA is also in-charge to 
gather information about its corresponding resource pool, which contains all available resources in its 
locality. To monitor each local area there are several global resource Managers (RM) are available and 
they are on the topmost layer of the system.
Figure 3. Four Layered System Architecture

173
Exploring Cloud-Based Distributed Disaster Management
﻿
Different Agents in MAS Workflow
Following different types of agents are considered to perform different actions in the proposed workflow 
model. Each agent is dedicated to do particular activities and maintains a collaborative communication 
environment between them.
•	
Collector Agent (CA): Main role of this type agent is to collect data from image sensors, satel-
lites, file systems, inputs given by human in the workflow system. This agent is engaged in collect-
ing data and migrating data from data storages to different local authority agent.
•	
Analyzer Agent (AA): Mainly performs updating database and sharing data with neighbor agents. 
They also update status of three distinguished features, i.e. emergency, priority, finish or not.
•	
Notification Agent (NA): Notify human manager about the three statuses.
•	
Resource Manager Agent (RM): Is responsible for allocating resources among Laborer Agents.
•	
Resource Owner Agent (OA): Responsible for sharing resource among themselves.
•	
Security Agent (SA): In-charge of imposing security on global and local area.
•	
Task Executor Agent (TA): Initiates or pause task if necessary, and restore them while the sys-
tem needs any paused task to resume again.
•	
Collaborator Agent (LA): Is responsible for mainly dynamic decision making, such as dynamic 
priority change for any task. It decides the base factor for similarity mapping matrix and the type 
of failed task. The work load for different agents at different stages of disaster management life 
cycle can be depicted in Figure 4. In Figure 4, during planning phase CA, AA and NA have more 
works than other agents, and during recovery phase they have less works.
Figure 4. Work Load of Agents at Different Stages of DMS Life Cycle

174
Exploring Cloud-Based Distributed Disaster Management
﻿
The activities of different agent can be represented as following sequence diagram in Figure 5. CA 
initiates the workflow through collecting data from GIS, mobile devices, heuristic data from web portals 
like DesInventar and so on. In this mean time, LA prepares a collaborative information management 
infrastructure to share data with other government as well as international agencies such as Red Cross, 
NGOs and so on. AA starts his activities through analysis collected data. AA has to identify all kinds 
of damages and to identify the tasks as well. After that, based on the severity of damages tasks are 
prioritized and alter native tasks are also identified to reduce the risk. Along with tasks AA also identi-
fies risk in order to perform tasks. All analyzed data are shared with LA. In this regard, SA validates 
all data to prevent any malicious information. After all similar types of tasks are identified by AA, NA 
notifies RM. RM identifies all similar type of tasks for same location and allocates resources for each 
RA. RA notifies TA to start the execution. TA, RM and RA shares updated data with CA. Finally AA 
uses updated data from CA for further analysis.
PROPOSED DISASTER MANAGEMENT SYSTEM
As disaster management system is an uncertain system, some tasks may fail. All failed tasks will be 
listed to reschedule in our proposed workflow model. Figure 6 depicts the complete workflow model 
for a given scenario.
Workflow Data Model
The data model of the proposed WfMS is illustrated in Figure 7. This data model describes the internal 
data structure as well as internal dependencies and flow of data of proposed WfMS.
The main components of the data model are as follows:
•	
Workflow: This is the workflow for any stage of the DMS life cycle such as recovery, immediate 
action, planning or post planning. Each workflow consists of a set of Flow Connections and Jobs.
•	
FlowConnection: This is the data item which controls the flow of data among different items 
in the WfMS. This object specifies the communication flow of workflow. Each FlowConnection 
has an id and the two endpoints of connection which are two different jobs- toJob and fromJob. 
FlowConnection also has an actor attribute, which defines the responsible agent to delegate this 
flow to next job.
•	
ConnectionPoint: Each FlowConnection is connected to Job through a ConenctionPoint. The 
state attribute of ConnectionPoint decides whether the connection is alive or not.
•	
Connection: Contains all lists of incoming and outgoing connections at any particular stage 
(node) of the workflow. Each incoming or outgoing connection has type. Based on different deci-
sions, the FlowConnection can have different types. We consider four different types of connec-
tion XOR and AND. XOR decides the alternative path, AND defines parallel and simultaneous 
execution of different JobItem.
•	
Decisions: As one of the most unique features in the proposed WfMS that it can play role for fu-
ture projection. Hence, it has a feature to store heuristic metadata for future planning and analysis 
phase of DMS. Each Decision has successHeuristic, which indicates the rate of success for that 

175
Exploring Cloud-Based Distributed Disaster Management
﻿
Figure 5. Sequence Diagram for Agent’s Activities in Recovery and Emergency Phase

176
Exploring Cloud-Based Distributed Disaster Management
﻿
particular decision. Moreover, impactWeight measures the impact of the Decision of the data flow 
of the workflow. In addition, reason specifies the necessity of taking that decision.
•	
Actor: Using the Actor class, workflow model can determine the responsible agent who will ex-
ecute the JobItem or continue the FlowConnection. Actor can be any of the proposed agents such 
as CA, AA, TA, SA, RM, RA, NA and LA.
•	
Location: This class is used to determine the location of JobItem, Workflow or Job.
•	
Job: A Job is consisting of Location, Actor, State and JobItem. Actor defines the agent such as TA, 
AA, CA or RA etc. State defines the status of the Job. We have considered five states for any Job 
READY_FOR_SUB MISSION, SUBMITTED, RUNNING, DROPPED and RESCHEDULED. 
Each JobItem also can be any of these five states. Each location indicates the list of places where 
the job will be executed and planned. In this regard, phase indicates the corresponding stage of 
life cycle of DMS for the Job.
•	
JobItem: This object has location, name, priority, status progress and type.
•	
ResourcePool: This is the list of all active Resources available for all Jobs in the Workflow.
•	
Resource: Each resource is owned by a ResourceActor. Moreover, type attribute of resource dif-
ferentiates the resource whether it is for construction purpose, medical purpose, evacuation pur-
pose etc. We have defined that there can UNASSIGNED, REQUESTED, IDLE, and ACTIVE. 
Any fault or description of resource will be informed by the attributes description and remark. 
Cost will determine the corresponding cost for the resource.
•	
ResourceActor: This is a subclass of Actor. This can be either RM or RA. Each RM is associated 
with a list of RA. Furthermore, each RA has a number of resources. In case of resource assign, 
RM asks for resource status for those resources owned by all RA registered under him.
Workflow State Model
In order to depict the deployment states, the state model for each artifact is depicted as follows:
Figure 6. An Example Workflow of the Proposed DMS

177
Exploring Cloud-Based Distributed Disaster Management
﻿
Figure 7. Workflow Data Model for DMS

178
Exploring Cloud-Based Distributed Disaster Management
﻿
•	
Resource State: All assigned resources can be either IDLE or ACTIVE. If any resource has been 
requested by RM to corresponding owner RA, that resource will be in REQUESTED state and if 
RA has accepted that request, corresponding resource will be initially in idle state. However, as 
soon as RM delegates that resource to TA, the state of the resource will be changed to ACTIVE.
Figure 8 shows eight different states for resource in this WfMS. After creation and adding to the 
global ResourcePool, the initial state of each resource is UNASSIGNED. When a task requests for a 
resource, it goes to REQUESTED state. From REQUESTED state resource is scheduled for requesting 
task by determining estimated starting time (est) and estimated finishing time (eft). If the current time 
is less than est, the resource remains in WAITING state. However, if current time is equal to or greater 
than est and the resource is allocated to TA for execution, the corresponding state is changed to AS-
SIGNED. ASSIGNED resource can either be ACTIVE or IDLE. ACTIVE resource can be changed to 
RESCHEDULED state due to resource preemption. RESCHEDULED resources are again changed to 
SHCEDULED state for rescheduling. Furthermore, if the resource is released from any of the SHCED-
ULED, WAITING, ASSIGNED, ACTIVE, IDLE or RESCHEDULED state or the request is canceled 
from REQUESTED state, then the resource state is changed to UNASSIGNED.
•	
ResourcePool State: Figure 9 shows that the resource pool for any particular task remains in 
INITIATE state after creation. After listing all the available resource the ResourcePool goes to 
PREPARED state.
At this stage resources are scheduled by defining the estimated execution of starting and finishing 
times. Thus, the sequence of each resource is defined in this state. The state of ResourcePool is changed 
to SCHEDULED in this stage. However, resources are being added to ResourcePool, before execution 
all required resources must be present in the ResourcePool. When all required resources are available in 
Figure 8. State Model of Resource

179
Exploring Cloud-Based Distributed Disaster Management
﻿
the ResourcePool and all of them are scheduled, the corresponding state of ResourcePool is changed to 
COMPLETE_SCHEDULED. Before allocating to TA, ResourcePool remains in WAITING state and 
after allocation the state changes to ASSIGNED state. Due to the priority change, resources need to be 
rescheduled and the state of ResourcePool changes to RESCHEDULED. Later, again after scheduling 
ResourcePool, the state changes to SCHEDULED. However, if the task is dropped, the state changes 
to terminating from RESCHEDULED. In this regard, if it is required to add more resources from any 
state of SCHEDULED, COMPLETE_SCHEDULED, WAITING, ASSIGNED or RESCHEDULED, 
the state changes to PREAPARED.
•	
Job State: Initially each job remains at NOT_ACTIVATED state. After activation command 
from AA, the job is promoted to ACTIVATED state. In this state AA initiates Job analysis, and 
therefore, Job is transferred to ANALYSIS_INCOMPLETE state. This state deals to measure the 
Job related damages including life cycle phase analysis and severity analysis etc. Once all kinds of 
related analysis are completed, the state of Job is changed to ANALYSIS_COMPLETE. However, 
if from ACTIVATED state the collaborator agent LA cancels the Job, and returns back to NOT_
ACTIVATED state. Again from ANALYSIS_COMPLETE state, the next state is PREPARION_
INCOMPLETE. This state prepares the complete Job through prioritizing, developing similarity 
mapping matrix, finding out all dependency, allocating necessary resources, ordering the sequence 
of dependency by building DAG (Habiba and Akhter, 2012). Next state is PREPARATION_
COMPLETE. Here the Job is ready for execution; hence the related state is READY. Once the 
ready Job is submitted into the queue, the state changes to WAITING state. If the Job is dropped 
from READY or WAITING state, it is transferred to DROPPED state. Moreover, if the Job is failed 
from READY or WAITING state due to any external or internal parameter, corresponding state is 
changed to FAILED state. On the other hand, if any decision is made to skip the Job, the state will 
be SKIPPED. However, from WAITING state of the Job is tuned to RUNNING_INCOMPLETE 
Figure 9. State Diagram for ResourcePool State

180
Exploring Cloud-Based Distributed Disaster Management
﻿
state and after completing all JobItems for the Job, its state becomes RUNNNING_COMPLETE. 
Finally, Job at RUNNNING_COMPLETE state tends to SUCCEED state. In this regard, if the Job 
is failed or dropped or skipped, the state turns to FAILED or DROPPED or SKIPPED respective-
ly. In addition, if the Job is suspended for future rescheduling, the state will be in SUSPENDED_
INCOMPLETE state. At the end of the suspension of Job, the corresponding state is changed to 
SUSPENDED_COMPLETE. On the initiation of rescheduling of suspended Job, the consequent 
state is turned to RUNNING_INCOMPLETE. However, if rescheduling is not initiated, Job state 
will be either FAILED or DROPPED or SKIPPED according to the action. Figure 10 shows the 
states of Job in a UML diagram.
The Full Components of Proposed DMS
The proposed DMS (Figure 11) consists of six major components such as (1) Web Portal, (2) Role 
Manager, (3) Workflow Engine, (4) Workflow Scheduler, (5) Workflow Monitor and (6) Notification. 
This section is going to explain all these six components of the proposed DMS and their Navigation 
Design (Figure 12 and Figure 13).
•	
Web Portal: This is the user interface of the proposed DMS. All agents can access different pages 
of this web portal according to their roles. All tasks of the workflow management can be done 
through this portal. In addition, this web portal provides a Graphical User Interface (GUI) to help 
users to edit their corresponding workflows. Although tasks are prepared from collected data 
and assigned with number of required resources as well as priority by Workflow Engine (WE). 
However, as the DMS deals dynamicity and uncertainty thus the problem domain may require to 
Figure 10. Job State Diagram

181
Exploring Cloud-Based Distributed Disaster Management
﻿
Figure 11. Components of Proposed DMS
Figure 12. Web Portal Navigation Design

182
Exploring Cloud-Based Distributed Disaster Management
﻿
change the tasks definition manually. Particularly, in this situation web portal plays a vital role. 
Workflow is organized as Direct Acyclic Graph (DAG) and later DAG is converted to xml schema 
(Habiba and Akhter, 2012). Each workflow consists of a number of parameters such as Agent, 
FlowConnection, list of resources, environment parameters, performance, assigned resource sta-
tus, overall workflow status, task status and task.
•	
Role Manager: This module is responsible for managing all different agents in this proposed 
DMS. It has an Agent Role Manager (ARM) which is the in-charge of defining access permis-
sion for agents on different modules, sections and tasks of DMS. The next sub module is Task 
Distributor. As soon as a task is produced and defined by the Workflow Engine, Task Distributor 
distributes the task to appropriate Agent. Another sub module is added to monitor the activities of 
different agents and prepare their audit report.
•	
Workflow Engine: This is the core component of this proposed DMS. Workflow Engine (WE) 
consists four basic components for managing the four core features (resource, task, data and au-
dit activity) of DMS. Figure 14 depicts different modules and their sub modules of a WE. In the 
proposed DMS system, data management is also very important. DMS needs to ensure security 
and easy sharing of data among different authorities. In addition, one of the major challenges 
for DMS is to be sharable beyond the geographical boundary (among different countries, differ-
ent NGOs, different organizations etc.). Therefore, secure data management and easy sharable 
framework have been integrated with the proposed DMS. Another important component of WE is 
the Task. Four different sub modules include-Task Manager, Task Scheduler, Task Executor and 
Task Monitor are introduced to manage different tasks. According to our previous work (Habiba 
and Akhter, 2012), the proposed DMS is a multiple agent system (MAS). Therefore, agent plays 
an important as well as governing role in the proposed DMS. Role Manager distributes the roles 
among agents. All the agents’ activities are monitored by Agent Monitor module. The main func-
tionality of Agent Access module is to keep traces the allowable permissions for different agents. 
Finally all internal communications among different agents as well as among different modules 
Figure 13. Task Component Design

183
Exploring Cloud-Based Distributed Disaster Management
﻿
are managed by Agent Manager. In addition, resource is a key element of this proposed system. As 
performance and cost are two most important attributes of resources, therefore, two different sub 
modules Cost Monitor and Performance Monitor continuously monitor the cost and performance 
of the resources. Resource Monitor will investigate the status of resources such as idle, out of 
work, and running. All activities and actions – that are taken by the proposed system- are continu-
ously audited by the Audit WfMS.
•	
Workflow Monitor: Workflow monitor plays a vital role in the proposed DMS. All performance 
and status of currently running as well as previous workflows are generated by these components. 
Later all reports can be visualized through the web portal. All the performance parameters for 
workflow monitor are presented in Table 1.
•	
Workflow Scheduler: The MAS based workflow scheduling algorithm proposed in (Habiba and 
Akhter, 2012) has been deployed in the workflow scheduler of the proposed DMS. Once the 
Figure 14. Components of Workflow Engine
Table 1. Performance parameters for Workflow Monitor
Name
Description
Number of Succeed Task per workflow
Defines the success rate
Number of failed task per workflow
Defines the failure rate
Number of used resources
Define the resource business
Number of total assigned resource
Define the actual resource capacity
Resource Status
Define the resource availability

184
Exploring Cloud-Based Distributed Disaster Management
﻿
task is prepared and integrated to currently running workflow. Figure 15 depicts the structure of 
workflow scheduler. It has six main components. At first all tasks of current workflow prepared 
by WE are put into the Ready Queue. The priority of the tasks can be changed dynamically by 
on-time priority changer. After tasks are ordered according to their priority in Ready Queue, Main 
Scheduler runs the scheduling algorithms (Habiba and Akhter, 2012). All successful jobs are 
stored in Successful Task list along with their reports and failed tasks are stored in Failed Task list. 
Failed tasks are rescheduled by Re-Scheduler and sent back to Ready Queue.
•	
Notification: This is also an important component of the system. Notification module performs 
two different activities -one is to implement cloud to device messaging (C2DM) in order to broad-
cast notification to mass people.
Cloud Implementation
Cloud based environment has been chosen for proposed DMS implementation for the following reasons:
•	
Large amount of data can be computed easily and within short period of time.
•	
During natural disaster ICT infrastructure can be damaged, such as some servers of IEEE were 
damaged due to recent violent flood sandy (Web5 (2007)). However, as the data was stored in 
cloud, those have been replicated from back up.
•	
DMS computation and decision making process is too complex and need apparently large amount 
of time. However, distributed environment in cloud can make this situation easier. As a result deci-
sion making process is expedited.
•	
For data storage, cloud is superior to provide data security, data sharing, easier data movement, 
flexible data access and rights management. These mentioned features are very necessary for this 
proposed system.
•	
Cloud implementation helps in discovering different classes and characterizes resources.
Figure 15. Workflow Scheduler Structure

185
Exploring Cloud-Based Distributed Disaster Management
﻿
•	
Cloud will take care of data management with reliability, scalability as well as security (Web5, 
2007).
•	
Expert believe cloud computing will enhance DMS (Kronfeld, 2011), Yoshizaki, M. (2011).
The following section will describe the implementation of the proposed DMS in cloud based system. 
Figure 16 describes the three layers of cloud environment. On the platform layer (PaaS), main data stor-
age system resides.
Along with data storage in PaaS, all decisions are taken for several past as well as current disasters 
form various locations for different type of incidents. It is the preferred model over fully outsourced data 
processing and handling, presumably gaining support for having clear visibility, ownership and control 
over all the data. At the same time, system can quickly obtain the benefits of a fully-maintained software 
solution on a subscription basis. With PaaS system can get full control over data encryption and security. 
Therefore in this proposed system all DMS data are stored in PaaS layer. These historical data are used 
as heuristic data storage for further workflow scheduling. In addition in this layer, all records come as a 
result of continuous audit of roles performed by different agents, success and fail reports from different 
workflow, status and performance evaluation of different resources, and comparative analysis of differ-
ent types of tasks in different workflows for different regional places are stored.
The next layer (IaaS) is the most important layer. Amazon EC2 can be a suitable candidate as IaaS. 
The main components of this proposed DMS such as Workflow Engine (WE), Workflow Scheduler (WS), 
Monitor, Cloud web services as well as temporary data storages are put in this layer. The proposed web 
portal is established on SaaS layer.
•	
Cloud Service Implementation: GIS based emergency management system ArcGIS (2012) is 
implemented in cloud; however it uses GIS to keep trace of location. However DMS is a complex 
and uncertain system. Although location is a vital parameter of DMS, it also has some other criti-
Figure 16. Cloud Implementation for DMS

186
Exploring Cloud-Based Distributed Disaster Management
﻿
cal as well as effective parameters such as weather, resources and data. In this proposed cloud 
based system several RESTful cloud services have been designed and those are connected as core 
service and cloud data storages.
Figure 17 describes the cloud services in proposed DMS. User is capable to interact with the system 
through mobile devices, computers and/or web portal. In the cloud, we integrate seven different web 
services and those are connected to core computation service. Core computation service is dependent on 
cloud data storages for data.GIS Service is necessary for tracing location which is indirectly connected 
to Weather Service to provide weather of particular location. In case of warning or emergency response 
Emergency Response Service is used for sending notification to mass people or government authorize 
personnel as well as NGOs. Notification Service is used for internal notification for the DMS system. 
Resource Management Service as well as Resource Discovery Service deals with resource management 
for the proposed DMS. These two services help other services for taking decision- based on the resource 
availability. Data Record Service is used for recording data and monitoring overall performance.
•	
Cloud System Structure: User can interact with the system through web portal, mobile devices 
as well as PC. The core computational service (CCS) will collect data dynamically from different 
services as well as previously saved data in different cloud data storages. CCS is the most impor-
tant service, which is implemented in WE of the proposed DMS. CCS communicates with GIS 
service in order to poll location information. Similarly CCS gets weather and available resource 
related information from weather service and resource management service respectively. Finally, 
CCS also gets data from storages and prepares the workflow of tasks those are needed to be per-
Figure 17. Cloud Services for Proposed DMS

187
Exploring Cloud-Based Distributed Disaster Management
﻿
formed in four different stages of Disaster Management lifecycle (Schurr et al., 2005). Therefore, 
in the proposed DMS, CCS performs the role to define workflow of DMS within WE with the help 
of the other services and data storages. Once the workflow is prepared for the next most important 
component of the proposed DMS, WS schedules the workflow with the help of resource discovery 
service and resource management service. Therefore, all decision making tasks are performed in 
WE, and scheduling activities are performed in WS. Notification is responsible for messaging, 
alert, and notification within or other external system. As during natural disaster system internet 
connection or Wi-Fi connection could not be available. In such situation C2DM can be a suitable 
solution. Therefore in this proposed DMS, along with web portal C2DM based push notification 
service in mobile phone is implemented to send alert, notification or general information to the 
mass people. C2DM service is integrated with notification component of proposed the DMS.
SIMULATION RESULT
In order to evaluate the performance of the proposed workflow model as well as the DMS, an eclipse 
based simulation tool is implemented. In order to have authenticated data for disaster management system 
we have collected data from Natural Disasters Data Book 2006 An Analytical Overview March 2007 
(NDDB, 2017). Another source of data used in our simulation is Disaster Management system Sri Lanka 
(DMSS) (Web2, 2017). Data regarding disaster from 1974 to up-to-date have been taken.
Figure 18 shows the data console for web portal (Web2, 2017). Same queries are used to prepare case 
data from another data source in (NDDB, 2017). Ten (10) different cases based on different disasters 
Figure 18. Data Query Console in DMSS (Web2, 2017)

188
Exploring Cloud-Based Distributed Disaster Management
﻿
include flood, tsunami, epidemic etc in different regions of the country are selected. Table 2 shows differ-
ent query criteria those have been used to distinguish different cases. Primarily we have chosen disaster 
type, location, year and damage type as the main query criteria to populate the data for our simulation. 
Different types of damages for which we have collected data from two different data sources (Web2, 
2017) and (NDDB, 2006) are listed in Table 2.
All data cards used for criteria to find out data for different types of damages in all cases are enlisted 
in Table 2. For example case 1 was based on the data for tsunami in Sri Lanka from all regions of this 
country for year 1985. We considered total 150 different types of damages that may cause due to different 
types of disasters. In each case, we considered relevant damage types only. For our simulation purpose, 
the considered constraints are listed in Table 4.
Figure 19 shows a graphical representation of comparative performance for ten (10) different cases 
for DMS. Figure 19 also presents that the average successful rate for our proposed algorithm is about 
65.07%. More than 50% jobs are getting done on the first time. Among failed task on average 81% task 
can be rescheduled successfully. This is the most significant contribution of proposed algorithms. Figure 
19 also highlights that almost 10% tasks are being dropped and this rate is negligible.
Introducing MAS has improved the performance of this proposed work significantly. This helps to 
improve the decision taking and resource management. In all existing agent based DMS systems (Frank 
& Burghardt, 2007), (Ghauri et al., 2010), (Min-Yuan et al., 2013), they only consider agents for decision 
taking and assisting in simulating the system. However, in the proposed work agent has the responsibil-
ity for resource management, communication and performance analysis even in carrying all the tasks. 
These features improve the overall performance of this system. The time required for resource discovery 
is almost double for a Non-MAS environment than a MAS environment and highlights in Figure 20.
Another important contribution of this work is to play a vital role for decision making at different 
stages for the DMS. Table 5 shows the impact of changing of parameters; those are directly related to the 
decisions taken for planning. It shows that if the parameter changes so abruptly, such as almost 80%, the 
rearrange of all tasks and changes in decision get less success. However the success rate is above 50% 
except Emergency stage. Emergency stage is the most dynamic and most abrupt stage of the total DMS. 
Therefore, the performance of decision changing and readjustment is quite satisfactory.
Table 2. Query criteria for Ten Cases used in Simulation
DATA Source
Disaster Type
Location
Year
Case-1
DMSS
Tsunami
All Region
1974-1986
Case-2
DMSS
Flood
All Region
1990-2010
Case-3
DMSS
Epidemic
All Region
1990-2010
Case-4
DMSS
Flood + Epidemic
North and South coast
1990-2010
Case-5
DMSS
Forest Fire
North and South coast
1990-2010
Case-6
DMSS
Tornado
All Region
1990-2010
Case-7
DMSS
Strom
All Region
1990-2010
Case-8
NDDB
Earthquake
Asia Zone
NA
Case-9
NDDB
Cyclone + Flood
Asia Zone
NA
Case-10
NDDB
Tidal Wave
Asia Zone
NA

189
Exploring Cloud-Based Distributed Disaster Management
﻿
In a strong DMS, it is very necessary that the communication channel must be scalable and the mini-
mum waiting time for processing any notification message must be very short. This is another significant 
achievement of this work. This work proposed MAS in order to introduce different agent to distribute 
different roles among them. Virtually these agents work in different channel. Therefore the notifica-
tion agent has its own channel and message bus. Therefore, without interrupting the activities of other 
agents notification agent can perform it own responsibility of processing the messages. Each message is 
prioritized; therefore, highly prioritized messages are distinguished as soon as they arrive in the queue. 
Table 3. Damage type for which data have been calculated
DataCards Deaths Injured Missing Houses Destroyed Houses Damaged Victims Affected Relocated Evacuated Losses $USD Losses $Local 
Education centers Hospitals Damages in crops Ha. Lost Cattle Damages in roads Mts With Deaths With Injured With Missing With Houses 
Destroyed With Houses Affected With Victims With Affected With Relocated With Evacuated Education Health sector Agriculture Water 
supply Sewerage Industries Communications Transportation Power and Energy Relief With other sectors fichas.latitude fichas.longitude 
Formula No of Males Affected No of Females Affected No. of males dead No. Families Affected No. of females dead No. of males injured 
No. of females injured No. of families evacuated No. of IDP Camps No. of people in the camps No. of families in IDP Camps No. of families 
relocated Rainfall recorded (mm) loss in Rs for Houses No. of GN divisions affected No. of partially damaged shops No of affected wells/ 
tube wells Paddy land in hectors No of paddy farm families Loss in Rs for paddy Other farm lands in hectors No. of other farm families 
Loss in Rs for other farm No of livestock affected No of livestock families affected Relief cost Rs National Roads damaged(Length in km) 
No. of fully damaged shops Loss in Rs for livestock Poultry Cattle/ Buffaloes Figury loss in Rs national road damaged Provincial Roads 
damaged(Length in km) loss in Rs provincial road damaged loss in Rs for Shops/ Business premises No. of partially damaged gov. premises 
No. of fully damaged gov. premises No. of village affected loss in Rs for industries MC / UC / PS Roads damaged(Length in km) loss in Rs 
MC/UC/PS road damaged No. of bridges damaged No. of bridges destroyed loss in Rs bridge damaged / destroyed No. of Culverts damaged 
No. of culverts destroyed loss in Rs culverts damaged / destroyed Loss in Rs for Other sector/property Loss(Rs) by Animal Attack(property 
damaged) No of fishing Families Affected No of Multiday Boats Damaged No of multiday boats destroyed No of Out Board Motors 
Damaged No of out board motors destroyed No of Ton Boats Damaged No of ton boats destroyed No of FRP Boats Damaged Total loss in 
Rs road damaged Total loss in transportation (Rs) No of water supply connections damaged Quantity of water supplied from other sources 
(l) Loss in Rs for drinking water sources loss in Rs for government premises No. of tourist hotels damaged No. of tourist hotels destroyed 
No of Restaurants/ Guest houses damaged No of Restaurants/ Guest houses destroyed No of FRP boats destroyed No of Traditional Craft 
Damaged No of traditional craft destroyed No of Fishing Vessels Damaged Loss(Rs) of Fishing Vessels Unit of fishing gear damaged Unit 
of fishing gear destroyed Loss in fishing gear(Rs) No. of partially damaged RFPS No of tanks affected loss in Rs tank damaged No. of 
canals damaged Total length of canals damaged (Km) loss in canals damaged (Rs) Goat Loss in tourist sector(Rs) No. of damaged anicuts 
Loss in Rs for partially damaged elements Loss in Rs for fully damaged elements Loss in Rs for partially / fully damaged towers No. of 
telecommunication connections damaged No. of partially damaged transformer stations No. of partially damaged transformer stations 
Loss in Rs for fully/partially damaged transformer sta. Loss in Rs for fully/partially damaged HT power lines Loss in Rs for fully/partially 
damaged distribution lines Loss in Rs for fully / partially damaged pylons No. of power connections damaged No. of destroyed anicuts Loss 
in damaged / destroyed anicuts (Rs) Extensive/ Intensive District _ Year_No of events District _Month_No of events DS Division _Year_No 
of events DS Division _Month_No of events Other Lands (Ha) Wind Speed(kph) Loss in education Sectore (Rs) Loss in fisheries Sector 
(Rs) Loss in transport sector (Rs) Loss in Electricity(Rs) Loss in tele communication sector(Rs) No of Temporary Shelters Damaged No of 
Temporary Shelters Destroyed Relief for Property Damaged by Animal Attack Relief cost for property damage in Rs paddy and other crop 
land (Ha) Relief distribution for damaged and destroyed houses(Rs) Loss for paddy and other crop in Rs loss for livelihood (Rs) Loss in Rs 
for RFPS No of Damaged and Destroyed Houses
Table 4. Constraints for Simulation
Constraints
Number of Items
Number of Task
150
Number of Resource
350
Different Set of Dependency Matrix
10
Different set of Priority matrix
10
Different Set of Similarity Mapping Matrix
10
Case
10

190
Exploring Cloud-Based Distributed Disaster Management
﻿
Table 5. Change in Decision Due to the Change of Environmental Conditions
Change in Decision 
Parameter (%)
Planning (%)
Emergency (%)
Recovery (%)
Post Planning (%)
20
78
63
80
86
40
65
52
72
77
60
52.33
45
63
63
80
55
39
52
57
Figure 19. Performance Evaluation
Figure 20. Comparison of Time Required for Resource Discovery in MAS and Non-MAS Environment

191
Exploring Cloud-Based Distributed Disaster Management
﻿
Figure 21 shows waiting times of different prioritized messages. In this experiment we have differenti-
ated all messages in eight different messages according to the priority. The highest prioritized message 
is Alarm(R) type and lowest prioritized message is information. The highest prioritized messages are 
processed as soon as possible; therefore, the waiting time in queue is 0.003 sec while for information 
the waiting time is 0.56 sec.
CONCLUSION
In this paper, we design a workflow model with MAS and define a dynamic agent based adaptive sched-
uling algorithm. We also figure different alternative solutions in order to reschedule failed tasks. For 
rescheduling tasks, we consider different level of recover abilities as well as compensations. The main 
significant contribution of the proposed workflow model is adding different agents and defining their 
roles significantly. Another major contribution is to achieve a comparatively higher rate of successful 
job completion in dynamic workflow model. The proposed model provides higher rescheduling success 
rate and comparatively lower dropout rate, and maintains a suitable and potential flow of information 
among different sections of the complete system through notification agent. Therefore, taking dynamic 
decision becomes easier. Another important feature of the proposed workflow model is to analyze 
different stages, which eventually helps to detect any forthcoming threat as well as change that makes 
within decision phase. Currently, we are working on the implementation of the proposed MAS model 
and scheduling algorithm in real time system. Once this web portal is live, it will be capable to retrieve 
data from DesInventar or any other source and dynamically prepare the workflow model for any disas-
ter affected region as well as schedule all activities during DMS dynamically. Initially, that web portal 
Figure 21. Time Required for Message Processing (in sec)

192
Exploring Cloud-Based Distributed Disaster Management
﻿
will be integrated with DesInventar to get data. As soon as DesInventar will update with recent data 
and automatic notification will be sent to the web portal and web portal will retrieve recent data from 
DesInventar and analysis the present situation. Furthermore, to improve the solution we need to simulate 
several failure situations. Such module will improve in near future.
FUTURE RESEARCH DIRECTIONS
Disaster management system is getting tremendous attention in research and data analytics. So far in 
our existing research projects, we have designed the workflow model in MAS and defined a dynamic 
agent-based scheduling algorithm for it. The workflow algorithm has still some manual steps and be-
havior driven decisions. As for being manual and human control, these steps are still biased and prone 
to mistake. The constraint described in Table 4 currently takes manual input. However, a deep learning 
based decision-making mechanism can easily define the constraints from data analysis and using dif-
ferent machine learning algorithm. Discovery management can be implemented within Planning and 
Post-Planning stage. Further analysis and validation of different stages of disaster management system 
need to be added. In this paper, we have identified several activities in both stages. Deep learning can 
be used on these identified activates or tasks in order to improve their performances, the collaboration 
among the task of any stage is important. This would improve the performance and sustainability to an 
impressive extent.
Figure 22. Decision making component for DMS

193
Exploring Cloud-Based Distributed Disaster Management
﻿
Machine learning will help us to change any decision dynamically based on real-time data on the 
fly in our project. In future a collective intelligent ontology generation system with context awareness 
will be implemented in order to get adaptive with the environment. The primary research focus will be 
to design a collective intelligence based knowledge domain and decision making component (Figure 
22). This is the third dimension that can be implemented in future to improve the performance of our 
workflow model.
Therefore, we are currently thinking in three different dimensions for future improvement. One is to 
use data analytics and machine learning in order to reduce human interaction in our proposed workflow 
model and automate most of its functionalities. The second dimension is also use of deep or machine 
learning in order to dynamically make decisions or change sequence of task of the proposed scheduling 
algorithm, to make more suitable set of task in Planning and Post-planning stage based on the result of 
Big data analytics, improve coherence and collaboration among tasks at any stage and make more suc-
cessful result. The third dimension is to improve performance of the workflow using machine learning 
algorithm for dynamic decision making.
Need to add extended module for broadening the scope of the work to real-time operational, decision 
making, and strategic management. Cloud based augmented reality based damage detection and recovery 
system can improve the DMS performance. Data security and privacy is another concern for such kind 
of research. In addition, the proposed concepts of scheduling workflow in distributed computing envi-
ronment can be used in so many other areas of knowledge, for example, defining activities in scientist’s 
research, industrial production plan, business plan of organizations etc.
Country level agriculture management (Akhter, 2005 and Akhter et al., 2006) activity needs to set 
priorities to the agri-tasks and distribute agri-decisions to the farmers. Thus, the policy makers need to 
prioritize the new assigned agri-task or change the priorities of existing tasks, depending on the country 
level dynamic conditions. Adaptive workflow scheduling can help to take such decision automatically 
and distribute the available/preempted resources for the new prioritized task. Traffic Management System 
(TMS) (Rahman & Akhter, 2015a, 2015b, 2016a), (Akhter et al., 2016b) is another research dimension, 
where the task priorities with decision mappings are changing dynamically. Thus, uncertain situations 
can force TMS to change their overall activities. Implementing the cloud based MAS workflow man-
agement system with the TMS will help to make the accurate decision on certain accident or hazard 
environmental conditions.
REFERENCES
Akhter, M. (2005a). Implementing the SWAP-GA model in cluster computers. Asian Institute of Tech-
nology. MSc.Thesis no. CS-05-11.
Akhter, S., Jangjaimon, I., Chemin, Y., Uthayopas, P., & Honda, K. (2006). Development of a GRIDRPC 
tool for Satellite Images Parallel Data Assimilation in Agricultural Monitoring. International Journal 
of Geoinformatics, 2(3).
Akhter, S., Rahman, M. R., & Islam, A. (2016b). Neural Network (NN) Based Route Weight Compu-
tation for Bi-Directional Traffic Management System. International Journal of Applied Evolutionary 
Computation, 7(4).

194
Exploring Cloud-Based Distributed Disaster Management
﻿
An Analytical Overview. (2007). Asian Disaster Reduction Center.
ArcGIS. (2012). GIS Tool. Retrieved from https://www.arcgis.com/features/index.html
Buhler, P., & Vidal, J. M. (2005). Towards Adaptive Workflow Enactment Using Multiagent Systems 
(Vol. 6). Information Technology and Management Journal.
Chen, L., Wu, J., & Lai, M. (2006). The Evolution of Natural Disaster Management System in Taiwan. 
Journal of the Chinese Institute of Engineering, 29(4), 633–638. doi:10.1080/02533839.2006.9671159
Disaster Management in India. (2017). Government of India, Ministry of Home Affair.
Disaster Management System Sri Lanka. (2017). Retrieved from https://online.desinventar.org/
desinventar/#LKA-1250695608-srilanka_historic_inventory_of_disasters
Early Warning Sub-Committee of the Inter-Ministerial Committee on International Cooperation for 
Disaster Reduction. (2006). Government of Japan.
Eder, J., & Gruber, W. (2002). A Meta Model for Structured Workflows Supporting Workflow Transfor-
mations. Proceedings of the 6th East European Conference on Advances in Databases and Information 
Systems, 326-339. doi:10.1007/3-540-45710-0_26
Frank, F., & Burghardt, P. (2007). Agent-based systems for disaster management. Communications of 
the ACM, 50(3), 41–42. doi:10.1145/1226736.1226763
Ghauri, F. U. D., Rehman, S. U., Yasir, M., & Asghar, S. (2010). Multi agent based decision support 
system for prioritized emergency fire evacuation. Proceeding of 4th International Conference on New 
Trends in Information Science and Service Science (NISS).
Habiba, M., & Akhter, S. (2012). MAS workflow model and scheduling algorithm for disaster manage-
ment system. Proceedings of Conference: Cloud Computing Technologies, Applications and Management 
(ICCCTAM), 164 - 173. doi:10.1109/ICCCTAM.2012.6488092
Habiba, M., & Akhter, S. (2013). A Cloud Based Natural Disaster Management System. Lecture Notes 
in Computer Science, 7861, 152–161. doi:10.1007/978-3-642-38027-3_16
Jennings, N., Faratin, P., Parsons, A. R. L. S., Sierra, C., & Wooldridge, M. (2001). Automated nego-
tiation: Prospects, methods and challenges. International Journal of Group Decision and Negotiation, 
10(2), 199–215. doi:10.1023/A:1008746126376
Kazusa, S. (2011). Disaster Management of Japan. Retrieved from Kochi University of Technology: 
http://management.kochi-tech.ac.jp/PDF/IWPM/IWPM_Kazusa.pdf
Kronfeld, M.J. (2011, July 5). Expert believe Cloud Computing will enhance disaster management. 
GSN Magazine.
Lander & Lesser. (1993). Understanding the role of negotiation in distributed search among heteroge-
neous agents. Proceedings of the Thirteenth International Joint Conference on Artificial Intelligence 
(IJCAI-93), 438-444.

195
Exploring Cloud-Based Distributed Disaster Management
﻿
Lesser, V. R., & Corkill, D. D. (1983). The Distributed Vehicle Monitoring Testbed: A tool for investi-
gating distributed problem solving networks. AI Magazine, 4(3).
List, B., & Korherr, B. (2006). An evaluation of conceptual business process modeling languages. Pro-
ceedings of the 2006 ACM Symposium on Applied Computing, 1532-1539.
Mendona, D., & Wallace, W. A. (2004). Studying organizationally-situated improvisation in response 
to extreme events. International Journal of Mass Emergencies and Disasters, 22(2).
Min-Yuan, C., & Wu, Y. (2013). Multi-agent-based data exchange platform for bridge disaster prevention: 
A case study in Taiwan. Natural Hazards, 69(1), 311–326. doi:10.1007/s11069-013-0708-9
Nazarov, E. (2011). Emergency Response management in Japan. Final Research report, ASIAN Di-
saster Reduction Center, FY2011A Program. Retrieved from http://www.adrc.asia/aboutus/vrdata/
finalreport/2011A_AZE_Emin_FRR.pdf
NDDB. (2006). Natural Disasters Data Book 2006, An Analytical Overview March 2007. Asian Disaster 
Reduction Center.
Rahman, M. R., & Akhter, S. (2015a). Real Time Bi-directional Traffic Management Support System 
with GPS and WebSocket. Proc. of the 15th IEEE International Conference on Computer and Informa-
tion Technology CIT ‘15. doi:10.1109/CIT/IUCC/DASC/PICOM.2015.144
Rahman, M. R., & Akhter, S. (2015b). Bi-directional traffic management support system with decision 
tree based dynamic routing. Proc. of 10th International Conference for Internet Technology and Secured 
Transactions ICITST ‘15. doi:10.1109/ICITST.2015.7412080
Rahman, M. R., & Akhter, S. (2016a). BiDirectional Traffic Management with Multiple Data Feeds for 
Dynamic Route Computation and Prediction System. International Journal of Intelligent Computing 
Research, 7(2).
Schurr, N., Marecki, J., Lewis, J., Tambe, M., & Scerri, P. (2005). The defacto system: Coordinating 
human-agent teams for the future of disaster response. Multi-Agent Programming, 197-215.
Sell, C., & Braun, I. (2009). Using a Workflow management System to manage Emergency Plans. Pro-
ceedings of the 6th International ISCRAM Conference.
Thomas. (1991). Emergency Management: Principles and Practice for Local Government. Washington, 
DC: International City Management Association.
Wattegama, C. (2007). ICT for Disaster Management. Asia-Pacific Development Information programme, 
e-Primers for the Information Economy, Society and Polity, APCICT 2007. Retrieved from http://www.
unapcict.org/ecohub/resources/ict-for-disaster-management/at_download/attachment1
What is Emergency Management? (2017). Maine Emergency Management Agency Web Site. Retrieved 
from http://www.maine.gov/mema/ema/mema_ema_whatis.shtml
Yoshizaki, M. (2011). Disaster Management and Cloud Computing in Japan. Report from Ministry 
of International Affair and Communication. Retrieved from http://www.gbd-e.org/events/2011/assem-
bly2011/pdf/Mr.Masahiro_Yoshizaki.pdf

196
Copyright © 2018, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.
Chapter  7
DOI: 10.4018/978-1-5225-2575-2.ch007
ABSTRACT
Sensor networks are dense wired or wireless networks used for collecting and disseminating environmen-
tal data. They have some limitations like energy that usually provide by battery and storages in order 
that we cannot save any generated data. The most energy consumer of sensors is transmitting. Sensor 
networks generate immense amount of data. They send collected data to the sink node for storage to 
response to users queries. Data storage has become an important issue in sensor networks as a large 
amount of collected data need to be archived for future information retrieval. The rapid development and 
deployment of sensor technology is intensifying the existing problem of too much data and not enough 
knowledge. Sensory data comes from multiple sensors of different modalities in distributed locations. 
In this chapter we investigate some major issues with respect to data storages of sensor networks that 
can be used for disaster management more efficiently.
INTRODUCTION
One of the characteristics of the post-PC era is to push computation from desktops and data centres 
out into the physical world. The area that we find especially interesting is networked sensors. Already 
today networked sensors can be constructed using commercial components using only a fraction of a 
Watt in power on the scale of a few inches. Wireless sensor networks produce a large amount of data 
that needs to be processed, delivered, and assessed according to the application objectives. A sensor 
Data Storages in Wireless 
Sensor Networks to Deal 
With Disaster Management
Mehdi Gheisari
Guangzhou University, China
Mehdi Esnaashari
K. N. Toosi University of Technology, Iran

197
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
is a device that measures a physical quantity and converts it into a signal which can be read by an ob-
server or by an instrument. The rapid advancements in computing has enabled the development of low 
cost wireless sensor networks (WSNs), and making WSNs one of the most important research areas. 
These are wireless ad-hoc network that connect deeply embedded sensors, actuators, and processors. 
This combination of wireless and data networking will result in a new form of computational paradigm 
which is more communication centric than any other computer network seen before. In the past few 
years, much research effort has been put forth to instrument the physical world with a large number 
of networked sensor nodes that are collaborating while self-configuring. Wireless sensor networks are 
composed of tiny devices with limited computation and battery capacities. The role of Wireless sensor 
networks in modern technology is obvious; and this was the main idea for many researches in the last 
decade. Progresses in wireless communications and micro electromechanical systems (MEMS) led to 
the deployment of large-scale wireless sensor networks (WSN). In other words, it revolutionized the way 
we monitor and control environments of interest (B.Arpinar, 2006). WSNs were identified as one of the 
ten emerging technologies that will change the world in MIT Technology Review (K.Moessner,2009). 
A wide variety of attractive applications with the use of WSNs (P. K. Chrysanthis,2006) would come 
into reality, such as habitat monitoring, search and military industries, disaster relief, target tracking, 
precision agriculture and smart environments. The applications of these networks are becoming wider 
nowadays. Smart environments represent the next evolutionary development step in building, utilities, 
industrial, home, shipboard, transportation systems automation, disaster management, earthquakes and 
so on. Like any sentient organism, the smart environment relies first and foremost on sensory data from 
the real world. One of most prominent sensor network applications is disaster management with the 
aim of achieving improved management. As the use of wireless sensor networks expands, Millions of 
sensors around the sphere currently collect rushes of data about our world. Wireless sensor networks 
produce a huge quantity of data that needs to be processed, delivered, and measured according to the 
application objectives. WSNs create variant types of data like arrays and images. These data should be 
stored somewhere for variety of queries. The section exemplifies how the use of semantics can enhance 
data management in sensor networks. Semantics exploit underlying relationships between data captured 
by sensors [6-8]. Wireless sensor networks (WSNs) are becoming increasingly popular in many spheres 
of life. Application domains include monitoring of the environment (e.g. temperature, humidity, and 
seismic activity) as well as numerous other ecological, law enforcement, and military settings. Sensors 
have more limitations like memory, CPU and energy providers (Mehdi Gheisari,2012). Most sensors use 
battery as its energy provider. We usually scattered sensors in dangerous environments. Sensors produce 
vast data that should be stored for further usage like querying. We cannot store all produced data that 
comes from sensors because of their limitations. As a result, we should store them in an effective way. 
Wireless sensors are deployed in a growing number of applications where they perform a wide variety 
of tasks like pervasive computing, e.g., monitoring learning behavior of the children, senior care system, 
environment sensing, etc., generate a large amount of data continuously over a long period of time. Often, 
the large volumes of data have to be stored somewhere for future retrieval and analysis. A big challenge 
is how to store data efficiently for future information retrieval.

198
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
BACKGROUND
Relational Model
The relational model uses a collection of tables to represent both data and the relationships among them. 
Each table has multiple columns, and each column has a unique name.
Advantages of Relational Model
•	
The Relational Model has survived through the years, though there are those who are always try-
ing to construct a more efficient way, it has managed to come out the victor thus far. One reason 
may be due to the structure it is big enough to be worthy of optimizing.
•	
Allows for Data Independence. This helps to provide a sharp and clear boundary between the logi-
cal and physical aspects of database management.
•	
Simplicity. This provides a simpler structure than those that were being before it. A simple struc-
ture that is easy to communicate to users and programmers and a wide variety of users in an en-
terprise can interact with a simple model.
•	
A good theoretical background. This means that it provides a theoretical background for database 
management field.
Disadvantages of the Relational Model
•	
Do not support querying semantically:
•	
Relational models do not support querying semantically that is done usually with SQL language- 
in other word, it cannot response queries that considers concepts between data’s.
•	
Do not support inheritance properties between records
•	
Do not support owned attributes between records.
•	
Machines cannot interpret data’s, so it cannot inference from existing data
•	
In heterogeneous Sensor networks, nodes cannot share the knowledge between agents
•	
Most RDBMSs have more loads that we have require like transactions control, etc.
•	
In relational model we cannot define new complex data types like images or videos.
Extensible Mark-Up Language
XML stands for Extensible Mark-up Language (often miscapitalized as eXtensible Mark-up Language 
to justify the acronym).
XML is a set of rules for defining semantic tags that break a document into parts and identify the 
different parts of the document. It is a meta-mark-up language that defines a syntax in which other 
domain-specific mark-up languages can be written. Each XML application has its own semantics and 
vocabulary, but the application still uses XML syntax. This is much like human languages, each of which 
has its own vocabulary and grammar, while adhering to certain fundamental rules imposed by human 
anatomy and the structure of the brain. Each XML application has its own semantics and vocabulary, 

199
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
but the application still uses XML syntax. This is much like human languages, each of which has its own 
vocabulary and grammar, while adhering to certain fundamental rules imposed by human anatomy and 
the structure of the brain. Here is a small, complete XML document, which uses all of these constructs 
and concepts.
 <?xml version=”1.0” encoding=’UTF-8’?> 
 <painting> 
  <img src=”madonna.jpg” alt=’Foligno Madonna, by Raphael’/> 
  <caption>This is Raphael’s “Foligno” Madonna, painted in  
<date>1511</date>-<date>1512</date>.</caption> 
 </painting>
There are five elements in this example document: painting, img, caption, and both dates. The date 
elements are children of caption, which is a child of painting. img has two attributes, src and alt.
XML is the abbreviation of Extensible Markup Language.XML includes a set of rules for defining 
semantic tags that break a document into different parts and defines those different parts of the docu-
ment [6].
XML is a meta-markup language that defines a syntax in which other domain-specific markup 
languages can be written. Syntactically, XML documents look like HTML documents. A well-formed 
XML document—one that conforms to the XML syntax—contains exactly one element. Additionally, 
an arbitrary number of comments and processing instructions can be included.
XML introduces some languages to allow more semantic management of information than HTML. 
XML is about the description of data, with nothing said about its presentation.HTML combines some 
fundamental descriptive markup, plus a great deal of mark up that describes the presentation of the data
Advantages of XML:
◦◦
XML is an extremely flexible format for text-based data.
◦◦
Learning XML is simple
◦◦
Heterogeneous agents can communicate with each other easily. if we use XML for transmis-
sion, knowledge is sharable
◦◦
With XML format, the system is more scalable
Disadvantages of XML:
◦◦
XML only define syntax of document and we have know idea about semantic of data’s
◦◦
XML do not define relationships between element, it only define hierarchy of them
◦◦
Xml is good for text data but if we have more complicated data types it maybe not suitable
◦◦
We cannot define constraints between elements like cows only eat vegetables.
Semantic Web Technologies
The Semantic Web is a mesh of information linked up in such a way as to be easily processable by ma-
chines, on a global scale. You can think of it as being an efficient way of representing data on the World 
Wide Web, or as a globally linked database.
The Semantic Web was thought up by Tim Berners-Lee, inventor of the WWW, URIs, HTTP, and 
HTML. There is a dedicated team of people at the World Wide Web consortium (W3C) working to 

200
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
improve, extend and standardize the system, and many languages, publications, tools and so on have 
already been developed. However, Semantic Web technologies are still very much in their infancies, 
and although the future of the project in general appears to be bright, there seems to be little consensus 
about the likely direction and characteristics of the early Semantic Web. In other words, the Semantic 
Web is envisioned as an extension of the current web where, in addition to being human-readable us-
ing WWW browsers, documents are annotated with meta-information. This meta-information defines 
what the information (documents) is about in a machine processable way. The explicit representation of 
meta-information, accompanied by domain theories (i.e. ontologies), will enable a web that provides a 
qualitatively new level of service (C. A. Henson, 2009).
An ontology defines a common vocabulary for researchers who need to share information in a do-
main (T. Rapoch,2007). It includes machine-interpretable definitions of basic concepts in the domain 
and relations among them.
Why would someone want to develop ontology? Some of the reasons are:
•	
To share common understanding of the structure of information among people or software agents.
•	
To enable reuse of domain knowledge.
•	
To make domain assumptions explicit.
•	
To separate domain knowledge from the operational knowledge.
•	
To analyze domain knowledge.
Sharing common understanding of the structure of information among people or software agents are 
one of the more common goals in developing ontologies. For example, suppose several different Web 
sites contain medical information or provide medical e-commerce services. If these Web sites share 
and publish the same underlying ontology of the terms they all use, then computer agents can extract 
and aggregate information from these different sites. The agents can use this aggregated information to 
answer user queries or as input data to other applications.
Enabling reuse of domain knowledge was one of the driving forces behind recent surge in ontology 
research. For example, models for many different domains need to represent the notion of time. This 
representation includes the notions of time intervals, points in time, relative measures of time, and so 
on. If one group of researchers develops such an ontology in detail, others can simply reuse it for their 
domains. Additionally, if we need to build a large ontology, we can integrate several existing ontologies 
describing portions of the large domain. We can also reuse a general ontology, such as the UNSPSC 
ontology, and extend it to describe our domain of interest.
Making explicit domain assumptions underlying an implementation makes it possible to change 
these assumptions easily if our knowledge about the domain changes. Hard-coding assumptions about 
the world in programming-language code makes these assumptions not only hard to find and understand 
but also hard to change, in particular for someone without programming expertise. In addition, explicit 
specifications of domain knowledge are useful for new users who must learn what terms in the domain 
mean (ManojKu.Tiwari,2008).
Separating the domain knowledge from the operational knowledge is another common use of on-
tologies. We can describe a task of configuring a product from its components according to a required 
specification and implement a program that does this configuration independent of the products and 
components themselves. We can then develop an ontology of PC-components and characteristics and 

201
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
apply the algorithm to configure made-to-order PCs. We can also use the same algorithm to configure 
elevators if we “feed” an elevator component ontology to it.
Analyzing domain knowledge is possible once a declarative specification of the terms is available. 
Formal analysis of terms is extremely valuable when both attempting to reuse existing ontologies and 
extending them.
Often an ontology of the domain is not a goal in itself. Developing an ontology is akin to defining a 
set of data and their structure for other programs to use. Problem-solving methods, domain-independent 
applications, and software agents use ontologies and knowledge bases built from ontologies as data. For 
example, one may develop an ontology of desserts and foods and appropriate combinations of desserts 
with meals. This ontology can then be used as a basis for some applications in a suite of restaurant-
managing tools: One application could create dessert suggestions for the menu of the day or answer 
queries of waiters and customers. Another application could analyze an inventory list of desserts and 
suggest which dessert categories to expand and which particular deserts to purchase for upcoming. In 
other words, Ontologies are a key enabling technology for the Semantic Web. They interweave human 
understanding of symbols with their machine processability (Kochut, K.2005). The wireless sensor 
networks of the near future are envisioned to consist of hundreds to thousands of inexpensive wireless 
nodes, each with some computational power and sensing capability, operating in an unattended mode. 
Many sensor network applications that are related to pervasive computing, e.g., monitoring learning 
behaviour of the children, senior care system, environment sensing, etc., generate a large amount of 
data continuously over a long period of time. The way these data are storing by the sensor nodes is a 
fundamental issue. Nowadays, the role of wireless technology is of great significance in a variety of 
areas. This accomplishment mostly relies on new technological advancements in sensor networks. In 
other words, sensors interact with each other in some specific network. Each sensor generates data based 
on its functionality. The data should be stored effectively in order to response future user queries. For 
example, sensor networks that are used in military environments or forests can help collect environmental 
related values. These networks generally cover a large scope; Therefore as time goes by, the amount of 
gathered data is increasing noticeably. Here, one of the major challenges is how to maintain and retrieve 
the huge amount of collected data using lower energy consumption. Using an energy-efficient technique 
for storing sensor data can substantially prolong the lifetime of the network. A longer life time is a con-
sequence of acquiring the optimum energy-efficient storage mechanism. Responding to semantic web 
queries would lead to more beneficial achievements. By using semantic web technology, it could be 
possible to respond more conceptual queries that are closer to human languages.
The Semantic Web is envisioned as an extension of the current web where, in addition to being 
human-readable using WWW browsers, documents are annotated with meta-information. This meta-
information defines what the information (documents) is about in a machine process able way. The ex-
plicit representation of meta-information, accompanied by domain theories (i.e.ontologies), will enable 
a web that provides a qualitatively new level of service
Ontologies are a key enabling technology for the Semantic Web. They interweavehuman understand-
ing of symbols with their machine process ability. Semantic Web is an extension to the current Web in 
which the meaningful relationships between different resources are represented in well-defined formats 
rather than simple links (i.e. href links in HTML). These formats are defined so that they can be processed 
automatically by machines. Different standard formats are defined by the World Wide Web Consortium 
(W3C) for representing the semantic Web data. These include Extensible Markup Language (XML), 
Resource Description Framework (RDF), RDF Schema (RDF-S) and the Web Ontology Language (OWL).

202
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
The OGC has recently established the Sensor Web Enablement Group in order to address the problem 
of the lack of standardization for realizing a progressive Sensor Web by developing a suite of specifica-
tions related to sensors, sensor data models, and sensor web services.
Semantic Web Technologies
The Semantic Web is a mesh of information linked up in such a way as to be easily processable by ma-
chines, on a global scale. You can think of it as being an efficient way of representing data on the World 
Wide Web, or as a globally linked database.
The Semantic Web was thought up by Tim Berners-Lee, inventor of the WWW, URIs, HTTP, and 
HTML. There is a dedicated team of people at the World Wide Web consortium (W3C) working to 
improve, extend and standardize the system, and many languages, publications, tools and so on have 
already been developed. However, Semantic Web technologies are still very much in their infancies, 
and although the future of the project in general appears to be bright, there seems to be little consensus 
about the likely direction and characteristics of the early Semantic Web. In other words, the Semantic 
Web is envisioned as an extension of the current web where, in addition to being human-readable us-
ing WWW browsers, documents are annotated with meta-information. This meta-information defines 
what the information (documents) is about in a machine processable way. The explicit representation of 
meta-information, accompanied by domain theories (i.e. ontologies), will enable a web that provides a 
qualitatively new level of service (C. A. Henson, 2009).
An ontology defines a common vocabulary for researchers who need to share information in a do-
main (T. Rapoch,2007). It includes machine-interpretable definitions of basic concepts in the domain 
and relations among them.
Why would someone want to develop ontology? Some of the reasons are:
•	
To share common understanding of the structure of information among people or software agents.
•	
To enable reuse of domain knowledge.
•	
To make domain assumptions explicit.
•	
To separate domain knowledge from the operational knowledge.
•	
To analyze domain knowledge.
Sharing common understanding of the structure of information among people or software agents are 
one of the more common goals in developing ontologies. For example, suppose several different Web 
sites contain medical information or provide medical e-commerce services. If these Web sites share 
and publish the same underlying ontology of the terms they all use, then computer agents can extract 
and aggregate information from these different sites. The agents can use this aggregated information to 
answer user queries or as input data to other applications.
Enabling reuse of domain knowledge was one of the driving forces behind recent surge in ontology 
research. For example, models for many different domains need to represent the notion of time. This 
representation includes the notions of time intervals, points in time, relative measures of time, and so 
on. If one group of researchers develops such an ontology in detail, others can simply reuse it for their 
domains. Additionally, if we need to build a large ontology, we can integrate several existing ontologies 
describing portions of the large domain. We can also reuse a general ontology, such as the UNSPSC 
ontology, and extend it to describe our domain of interest.

203
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
Making explicit domain assumptions underlying an implementation makes it possible to change 
these assumptions easily if our knowledge about the domain changes. Hard-coding assumptions about 
the world in programming-language code makes these assumptions not only hard to find and understand 
but also hard to change, in particular for someone without programming expertise. In addition, explicit 
specifications of domain knowledge are useful for new users who must learn what terms in the domain 
mean (ManojKu.Tiwari,2008).
Separating the domain knowledge from the operational knowledge is another common use of on-
tologies. We can describe a task of configuring a product from its components according to a required 
specification and implement a program that does this configuration independent of the products and 
components themselves. We can then develop an ontology of PC-components and characteristics and 
apply the algorithm to configure made-to-order PCs. We can also use the same algorithm to configure 
elevators if we “feed” an elevator component ontology to it.
Analyzing domain knowledge is possible once a declarative specification of the terms is available. 
Formal analysis of terms is extremely valuable when both attempting to reuse existing ontologies and 
extending them.
Often an ontology of the domain is not a goal in itself. Developing an ontology is akin to defining a 
set of data and their structure for other programs to use. Problem-solving methods, domain-independent 
applications, and software agents use ontologies and knowledge bases built from ontologies as data. For 
example, one may develop an ontology of desserts and foods and appropriate combinations of desserts 
with meals. This ontology can then be used as a basis for some applications in a suite of restaurant-
managing tools: One application could create dessert suggestions for the menu of the day or answer 
queries of waiters and customers. Another application could analyze an inventory list of desserts and 
suggest which dessert categories to expand and which particular deserts to purchase for upcoming. In 
other words, Ontologies are a key enabling technology for the Semantic Web. They interweave human 
understanding of symbols with their machine processability (Kochut, K.2005). The wireless sensor 
networks of the near future are envisioned to consist of hundreds to thousands of inexpensive wireless 
nodes, each with some computational power and sensing capability, operating in an unattended mode. 
Many sensor network applications that are related to pervasive computing, e.g., monitoring learning 
behaviour of the children, senior care system, environment sensing, etc., generate a large amount of 
data continuously over a long period of time. The way these data are storing by the sensor nodes is a 
fundamental issue. Nowadays, the role of wireless technology is of great significance in a variety of 
areas. This accomplishment mostly relies on new technological advancements in sensor networks. In 
other words, sensors interact with each other in some specific network. Each sensor generates data based 
on its functionality. The data should be stored effectively in order to response future user queries. For 
example, sensor networks that are used in military environments or forests can help collect environmental 
related values. These networks generally cover a large scope; Therefore as time goes by, the amount of 
gathered data is increasing noticeably. Here, one of the major challenges is how to maintain and retrieve 
the huge amount of collected data using lower energy consumption. Using an energy-efficient technique 
for storing sensor data can substantially prolong the lifetime of the network. A longer life time is a con-
sequence of acquiring the optimum energy-efficient storage mechanism. Responding to semantic web 
queries would lead to more beneficial achievements. By using semantic web technology, it could be 
possible to respond more conceptual queries that are closer to human languages.

204
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
SWE
The main specifications defined by the group are as follows (Botts.M et al.,(28 Dec. 2007)):
•	
Observations & Measurements (O&M): Define standard models and XML Schema for encoding 
real-time and archived observations and measurements of sensor data.
•	
Sensor Model Language (SensorML): A standard model to describe sensor systems and pro-
cesses associated with sensor observations in an XML-based structure. The information provided 
by SensorML can be used for sensor discovery, describing sensor data, and specifying sensor 
observations.
•	
Transducer Model Language (TransducerML or TML): Provides a conceptual model to describe 
transducers and to support real-time data to/from sensor systems, sensors and actuators.
•	
Sensor Observations Service (SOS): A standard Web service interface for requesting, filtering, 
and retrieving observations and sensor system information.
The models provided by SWE define a standard framework to deal with sensor data in heterogeneous 
sensor network applications. Although XML provides a remarkable solution for heterogeneous data 
representation, there are significant limitations in semantic interoperability and describing the semantics 
and relationships between different data elements using XML representations (C. A. Henson, 2009) The 
Open Geospatial Consortium recently built the Sensor Web Enablement as a suite of specifications re-
lated to sensors, sensor data models, and sensor web services that would permit sensors to be accessible 
and controllable through the Web
The core language and service interface includes the following:
1. 	
Observations & Measurements (O&M): Standard models and XML Schema for encoding obser-
vations and measurements from a sensor, both archived and real-time. These are standard models 
and XML schema for encoding archived and real-time observations and measurements from a 
sensor.
2. 	
Sensor Model Language (Sensor ML): Standard models and XML Schema for describing sen-
sors systems; in other words, it provides information needed for discovery of sensors, location of 
sensor observations. These are standard models and XML schema for describing sensors systems 
and processes; they provide information needed for discovering sensors, locating sensor observa-
tions, processing low-level sensor observations, and listing task able properties.
3. 	
Transducer Model Language (Transducer ML): Standard models and XML Schema for sup-
porting real-time streaming of data to and from sensor systems. These are standard models and 
XML schema for describing transducers and supporting real-time streaming of data to and from 
sensor systems.
4. 	
Sensor Observations Service (SOS): Standard web service for requesting, filtering, and retriev-
ing observations and sensor system information. This is the intermediary between a client and an 
observation source or near real-time sensor channel. This is the standard Web service interface 
for requesting, filtering, and retrieving observations and sensor system information. It’s also the 
intermediary between a client and an observation repository or near real-time sensor channel.

205
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
The following example shows a timestamp encoded in O&M and semantically annotated with RDFa.
The timestamp’s semantic annotation describes an instance of time: Instant (here, time is the namespace 
for OWL-Time ontology):
<swe: component rdfa: about=“time_1”  
rdfa: instance of =”time: Instant”> 
<swe: Timerdfa: property=“xs: date-time”> 
2010-0308T05:00:00 
</swe: Time> 
</swe: component>
This example generates two RDF triples. The first, time_1 rdf: type time: Instant, describes time_1 as 
an instance of time: Instant (subject is time_1, predicate is rdf: type, object is time: Instant). The second, 
time_1 xs: date-time “2010-03-08T05:00:00,”describes a data-type property of time_1 specifying the 
time as a literal value (subject is time_1, predicate is xs: date-time, object is “2008-03-08T05:00:00”)
(D.Rauch, 2008). In other words:
The relational model uses a collection of tables to represent both data and the relationships among 
them. Each table has multiple columns, and each column has a unique name. The OGC recently established
Sensor Web Enablement (SWE) to attain situation awareness by developing a suite of specifications 
related to sensors[1], sensor data models, and sensor Web services that will enable sensors to be ac-
cessible and controllable via the Web. The core suite of language and service interface specifications 
includes the following:
RDFa (or Resource Description Framework - in - Attributes)
Many languages can be used for annotating sensor data, such as RDFa, XLink, and SAWSDL (Semantic 
Annotations for WSDL and XML Schema).
Here, we describe the use of RDFa, a W3C proposed standard (www.w3.org/2006/07/SWD/RDFa/) 
and a markup language that enables the layering of RDF information on any XHTML or XML document. 
RDFa is a set of extensions to XHTML. RDFa uses attributes from XHTML’s meta and link elements 
and generalizes them so that they are usable on all elements. This allows annotating XHTML markup 
with semantics RDFa provides a set of attributes that can represent semantic metadata within an XML 
language from which we can extract RDF triples using a simple mapping
LEACH (Low-Energy Adaptive Clustering Hierarchy)
LEACH is an Application Specific Protocol Architectures for Wireless Networks in other words an 
architecture for remote microsensor networks that combines the ideas of energy-efficient cluster-based 
routing and media access together with application-specific data aggregation to achieve good performance 
in terms of system lifetime, latency and application perceived quality. The combination of them is as 
followsThere are potential benefits in arranging sensors in hierarchical format. Now we have a glance at 
some benefits of aligning along with most well-known method which is named LEACH (Low-Energy 
Adaptive Clustering Hierarchy).

206
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
Arranging sensors in tree model format constitutes a type of hierarchical model. The following figure 
illustrates this point in a schematic view.
Hierarchical Alignment (clustering, see Figure 1 for an example) has a number of benefits, some of 
which are as follows:
1. 	
Scalability: When the sensors are clustered, cluster heads play the role of moderator of their mem-
bers. This architecture can be easily scaled by minor changes.
2. 	
Routing Table: Arranging the sensors in hierarchical form causes a significant reduction in the 
size of the routing tables of sensor nodes. Member nodes need to have only an entry for their cluster 
head and cluster heads need only an entry for the sink node.
3. 	
Lower Bandwidth Consumption: Using a hierarchical routing strategy (as is used in the cluster-
ing structure) leads to two-hop paths from each sensor node to the sink node. This would reduce 
the bandwidth of communication compared to the other case where each node has to send its own 
data towards the sink node using a multi-hop routing strategy.
4. 	
Balanced Consumption of Energy: Allowing the cluster head role to be changed from time to 
time from some sensor nodes to the other ones, the energy consumption of different sensor nodes 
in the network can be balanced.
LEACH is an Application Specific Protocol Architecture for wireless networks. In other words, that 
is an architecture for remote micro-sensor networks combining the ideas of energy-efficient cluster-
based routing and media access together with application-specific data aggregation to achieve better 
performance with the corresponding of system’s lifetime-the time that a sensor networks last and run 
out from working properly- latency and last but not least volume of transmitted data through network. 
In this research the LEACH algorithm is used to support our new proposed method.
Ontology
Ontologies are typically defined as an abstract model of a domain of interest with a formal semantics in 
the sense that they constitute a logical theory. These models are supposed to represent a shared concep-
tualization of a domain as they are assumed to reflect the agreement of a certain community or group 
of people. In the simplest case, ontologies consist of a set of concepts or classes, which are relevant for 
Figure 1. Hierarchical Alignment

207
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
the domain of interest, as well as a set of relations defined on these concepts. The general idea is that 
data and services are semantically described with respect to ontologies, which are formal specifications 
of a domain of interest, and can thus be shared and reused in a way such that the shared meaning speci-
fied by the ontology remains formally the same across different parties and applications. Ontologies 
are utilized by the semantic Web Applications to offer conceptualized representation of domains and 
to specify meaningful relationships between the resources. Ontologies provide a common and shared 
understanding of different domains.OWL is a language that is based on description logic and facilitates 
construction of ontologies for different domains. The OWL representation of data enables expression of 
semantics and meaningful relationships between resources and amongst different attributes of complex 
data(s.santini,2008).
The OWL data can be accessed by software agents for reasoning and inference purposes and to enable 
systems to derive additional knowledge from the represented data. There are common query languages 
such as SPARQL available for the OWL data, in other words the stored ontology can be accessed via 
SPARQL queries. There are also widely used software systems such as Jena and Sesame to deploy and 
manage the constructed ontologies(c.henson,2009).
XLINK
The XML Linking Language, or XLink, is an XML markup language used for creating hyperlinks in 
XML documents. XLink is a W3C specification that outlines methods of describing links between 
resources in XML documents, whether internal or external to the original document. XLink defines a 
set of attributes that may be added to elements of other XML namespaces. XLink provides two kinds 
of hyper linking for use in XML documents. Extended links are out of band hyperlinks that, in a link 
base document, can link resources over which the link editor has no control. Simple links offer similar 
functionality to HTML links, which are in band links.
RELATES WORKS
SSW
Sheth and Henson (T.Rapoch,2007) describe a framework that named semantic sensor Web (SSW) in 
which sensor data is annotated with semantic metadata to increase interoperability as well as provide 
contextual information essential for situational knowledge. In particular, this involves annotating sen-
sor data with Spatial, temporal, and thematic semantic metadata. The spatial meta-data provides sensor 
location and data information in terms of a geographical reference system, location reference, or named 
locations. The temporal meta-data refers to the time interval duration whose sensor data has been 
captured. Thematic meta-data provides descriptive information about the sensor node which can be 
derived by sensor data analysis, and utilizing tagging and textual descriptions (F. van Harmelen,,April 
2004).In SSW, sensor data is annotated with semantic metadata to increase interoperability as well as 
provide contextual information essential for situational knowledge. In particular, this involves annotat-
ing sensor data with Spatial, temporal, and thematic semantic metadata. The spatial meta-data provides 
sensor location and data information in terms of a geographical reference system, location reference, 

208
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
or named locations. The temporal meta-data refers to the time interval duration whose sensor data has 
been captured. Thematic meta-data provides descriptive information about the sensor node which can 
be derived by sensor data analysis, and utilizing tagging and textual descriptions. Sheth and Henson 
Describes a framework that named Semantic Sensor Web (SSW) in which the sensor data is annotated 
with semantic meta data to increase interoperability as well as providing contextual information essential 
for situational knowledge. In particular, this involves annotating sensor data with Spatial, temporal, and 
thematic semantic metadata. The spatial meta-data provides sensor location and data information in 
terms of a geographical reference system, location reference, or named locations. The temporal meta-
data refers to the time interval duration whose sensor data has been captured [2]. Thematic meta-data 
provides descriptive information about the sensor node which can be derived by sensor data analysis, and 
utilizing tagging and textual descriptions. The SSW approach presented leverages current standardization 
efforts of the Open Geospatial Consortium (OGC; www.opengeospatial.org) and Semantic Web Activity 
of the World Wide Web Consortium (W3C; www.w3.org/2001/sw/) to provide enhanced descriptions 
and meaning to sensor data. They’ll review relevant components. Also relevant but outside the scope of 
this article is the semantic community Sensor Standards Harmonization Working Group, which takes 
user perspective. It used RDFa language to annotate sensor data. Sample Semantic annotation of SWE 
is shown in the following code.
<swe:component rdfa:about=“time_1” 
rdfa:intanceof=“time:Instant”> 
<swe:Time rdfa:property=“xs:date-time”> 
2008-03-08T05:00:00 
</swe:Time> 
     </swe:component> 
     <swe:value name=“satellite-data“ rdfa:about=“Dayton” 
rdfa:instanceof=“geo:City”> 
0011000111001111 … 
</swe:value>
This example generates two RDF triples. The first, time_1 rdf:typetime:Instant, describes time_1 
as aninstance of time:Instant(subject istime_1, predicate is rdf:type, object istime:Instant). The second, 
time_1 xs:date-time “2008-03-08T05:00:00,”describes a data-type property oftime_1 specifying the time 
as a literalvalue (subject is time_1, predicateis xs:date-time, object is “2008-03-08T05:00:00”). Sheth 
and Hanson, discuss the idea of a semantic sensor Web framework to provide Enhanced meanings to 
sensor data and to create situation awareness for the sensor networks. The semantics of sensor nodes is 
described within space and time dimensions, and it also includes thematic data. The spatial meta-data 
provides sensor location and data information in terms of a geographical reference system, location 
reference, or named locations. The main assumption is that although the sensor’s location might be 
changing, its location can be determined relative to the moving object. The temporal meta-data refers to 
the time interval duration whose sensor data has been captured. Thematic meta-data provides descrip-
tive information about the sensor node which can be derived by sensor data analysis, and utilizing tag-
ging and textual descriptions. The sensor Web facilitates interoperable architecture for sensor networks 
and enables the application to process and interpret the contextual, observation and measurement data 
obtained from a sensor in a heterogeneous environment. The authors describe different scenarios for 

209
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
applying the semantic Web technologies and ontologies to the sensor networks. One of the main issues 
in the semantic sensor Web architecture is employing a unified data model which supports universal 
interoperability and semantic description for sensor data. The latter will enable construction of content 
and context aware sensor network applications.
SemSOS
Henson, P. K. Chrysanthis.(2006) provide a system that models the domain of sensors and sensor ob-
servations in a suite of ontologies, adding semantic annotations to the sensor data, using the ontology 
models to reason over sensor observations.
Henson provides a system that are modeling the domain of sensors and sensor observations in a suite 
of ontologies, adding semantic annotations to the sensor data, using the ontologymodels to reason over 
sensor observations. They have developed an encoding of the Observations and Measurements language 
in OWL. In the ontology, they have defined the previous relations, and more, in a form that may be 
queried and reasoned over effectively in order to derive actionable knowledge of the environment from 
sensor observations. Sheth and Henson Describes a frameworks that named semantic sensor Web (SSW) 
in which sensor data is annotated with semantic meta data to increase interoperability as well as provide 
contextual information essential for situational knowledge. In particular, this involves annotating sen-
sor data with Spatial, temporal, and thematic semantic metadata. The spatial meta-data provides sensor 
location and data information in terms of a geographical reference system, location reference, or named 
locations. The temporal meta-data refers to the time interval duration whose sensor data has been cap-
tured. Thematic meta-data provides descriptive information about the sensor node, which can be derived 
by sensor data analysis, and utilizing tagging and textual descriptions.It propose a new method that uses 
smarter data than raw sensor data and accomplish this by leveraging semantic technologies in order to 
provide and apply more meaningful representation of sensor data. More specifically, they are modeling 
the domain of sensors and sensor observations in a suite of ontologies, adding semantic annotations to 
the sensor data.in other words, it represent data in O&M-OWL form.
The following example shows a sample sensor data in the proposed approach:
om:windspeed_1 rdf:type w:WindSpeedObservation.
om:windspeed_1 om:samplingTime om:time_1.
om:windspeed_1 om:observationLocation om:location_1.
om:windspeed_1 om:result om:result_1.
om:result_1 om:value 37.
om:result_1 om:uom w:MPH.
This example shows winspeed_1 that is type of WindSpeedObservation defined in weather(w) ontology. 
Related SamplingTime is time_1 and its value is 37 MPH. Henson et al, describe a prototype applica-
tion for the sensor Web by using annotated video data. The dataset contains Youtube videos annotated 
with SensorML and XLINK models with reference to time ontology. The authors discuss how utilizing 
the semantic leads to retrieve videos by specifying temporal concepts such as “within”, “contains”, or 
“Overlaps” during a time interval query submission. The proposed application demonstrates the main 
benefits of adding semantics to the sensor network and sensor data. The authors use keyword tagging and 

210
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
meta-data description to provide references to temporal concepts and domain ontologies. An extension 
to this idea could be seen as providing a universal meta-data structure with a broader scope to accom-
modate various sensor data types(c.henson,2007).
Rest of Related Works
ES3n uses Semantic Web techniques to manage and query data collected from a mini dome Sensor Net-
work. Our tool supports complex queries on both continuous and archival data, by capturing important 
associations among data, collected and stored in a distributed dynamic ontology. It uses Semantic Web 
techniques to manage and query data, collected from a minidome Sensor Netwo
Russomanno discusses a broad sensor ontology which is called OntoSensor. OntoSensor primarily 
adapts parts of SensorML descriptions and uses extensions to the IEEE Suggested Upper Merged On-
tology (SUMO) to describe sensor information and capabilities. The ontology is developed to support 
sensor information system applications in dynamic sensor selection, reasoning and querying various 
types of sensor. OntoSensor relies on deep knowledge models and provides extensive information about 
different aspects of the sensor nodes and devices. The ontology is represented in OWL format and the 
authors have discussed the advantages of the proposed approach compared to SensorML and XML 
based solutions. The main enhancement is providing self-descriptive meta-data for the transducer ele-
ments and embedded semantics in the descriptions which could be utilized in various sensor discoveries 
and reasoning applications. Although OntoSensor illustrates a semantic approach to sensor description 
and provides an extensive knowledge model, there is no distinctive data description model to facilitate 
interoperable data representation for sensors observation and measurement data.
A universal sensor observation and measurement data model in collaboration with a sensor specifi-
cation model create semantic sensor network architecture. Semantic sensor network utilizes semantic 
Web technologies and reasoning mechanisms to interpret sensor data from physical devices performing 
observations and measurements. It would support building automated sensor information processing 
mechanisms to extract additional knowledge from real-time or archived sensor data. Ontology-based de-
scription of a service oriented sensor network is discussed in P.Barnaghi. The SWE and Geography Markup 
Language (GML) classes and properties in collaboration with SensorML, Suggested Upper Ontology 
(SUMO, In the meantime OntoSensors are used to develop ontology for sensor service description. The 
ontology consists of three main components ServiceProperty, LocationProperty, and PhysicalProperty.
ServiceProperty explains what a service does and properties in the other two components describe 
the contextual and physical characteristics of the sensor nodes in wireless sensor network architecture. 
The ontology is represented in OWL form and some initial consistency checking and query results are 
provided to evaluate the validity of the proposed solution. The system, however, does not specify how 
complex sensor data will be described and interpreted in a sensor network application.
The proposed framework concentrates on building sensor description ontology for sensor discovery 
and description of sensor meta-data in a heterogeneous environment. Although sensor device and ser-
vice description will contribute to build more autonomous sensor networks, providing an interoperable 
data description model would be also an essential requirement in architecture for semantically enabled 
sensor networks.
Henson et al describe a prototype application for the sensor Web by using annotated video data. 
The dataset contains YouTube videos annotated with SensorML and XLINK models with reference to 
time ontology. The authors discuss how utilizing the semantic leads to retrieve videos by specifying 

211
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
temporal concepts such as “within”, “contains”, or “overlaps” during a time interval query submission. 
The proposed application demonstrates the main benefits of adding semantics to the sensor network and 
sensor data. The authors use keyword tagging and meta-data description to provide references to tem-
poral concepts and domain ontologies. An extension to this idea could be seen as providing a universal 
meta-data structure with a broader scope to accommodate various sensor data types.
A universal sensor observation and measurement data model in collaboration with a sensor specifica-
tion model creates semantic sensor network architecture. Semantic sensor network will utilize semantic 
Web technologies and reasoning mechanisms to interpret sensor data from physical devices that perform 
observations and measurements. This will support building automated sensor information processing 
mechanisms to extract additional knowledge from real-time or archived sensor data.
Ontology-based description of a service oriented sensor network is discussed in p.Barnaghi. The 
SWE and Geography Markup Language (GML) classes and properties in collaboration with SensorML, 
Suggested Upper Ontology (SUMO) and OntoSensor are used to develop ontology for sensor service 
description. The ontology consists of three main components Service Property, Location Property, and 
Physical Property.
Service Property explains what a service does and properties in the other two components describe 
the contextual and physical characteristics of the sensor nodes in wireless sensor network architecture. 
The ontology is represented in OWL form and some initial consistency checking and query results are 
provided to evaluate the validity of the proposed solution. The system, however, does not specify how 
complex sensor data will be described and interpreted in a sensor network application.
The proposed framework concentrates on building sensor description ontology for sensor discovery 
and description of sensor meta-data in a heterogeneous environment. Although sensor device and ser-
vice description will contribute to build more autonomous sensor networks, providing an interoperable 
data description model would be also an essential requirement in architecture for semantically enabled 
sensor networks.
A high level design for a universal ontology which consists of extension plug-in ontologies, sensor 
data ontology and sensor hierarchy ontology is described in S.Meissner.The extension plug-in ontologies 
enable the developers to integrate domain specific ontologies into the main ontology. This describes the 
sensor network capabilities and provides relations between the domain concepts and the sensor func-
tionalities. The sensor hierarchy ontology is a knowledge model for the sensors and actuators and other 
physical devices in the network. It describes the features and capabilities of the elements and contains 
meta-data related to devices such as measurement range, accuracy and calibration. The sensor data 
ontology describes the dynamic observational data for transducers. The ontology model describes the 
contextual data with respect to the spatio-temporal attributes. However the illustrated model does not 
specify the details of sensor data specification and relationships between various types of complex sen-
sor data. The taxonomy provided for the sensor hierarchy ontology specifies a set of primary numerical 
attributes for common types of sensors. In a practical scenario, sensor data will include more complex 
data types and there will be a requirement for a universal structure to define the sensor data and emerg-
ing semantics(M.Gheisari,H.R.Kamalabadi,2011).
There are other systems that have been proposed for storing data:
Minos: Defines a generic, Java-based tool that allows for collecting and storing data collected in 
wireless sensor networks (A. Sheth and M. Perry,2008)

212
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
Sense and Sens’ability: Describe a sensor data ontology which is created according to the Sensor Web 
Enablement1 and SensorML data component model (A. Sobeih and Jennifer C. Hou(November 2003)). 
Section 4 describes evaluation of existing works and proposing a new method for better data storage.
EVALUATION OF EXISTING METHODS, A NEW ONE
A Comparison of Two Semantic Sensor Data 
Storages in Total Data Transmission
As we can see when we use ES3n, more data are transmitted through network in comparison to SSW. 
So the lifetime of the network decreases more (P. Baldi,2004).
In recent years, progresses in energy efficient design and wireless technologies have enabled various 
new applications for wireless devices. These applications span a wide range including real time streaming 
video and audio delivery, remote monitoring using networked micro sensors, personal medical monitoring 
and home networking of everyday appliances. While these applications require high performance network, 
they suffer from resource constraints that do not exist in traditional wired computing environments. In 
particular wireless spectrum is scarce limiting the bandwidth available to applications and making the 
channel error prone and since the nodes are often battery operated, there is limited available energy. 
If we can store sensors data more effectively, we have more effective and lifetime sensor networks. In 
this research, we compared two methods of sensor data modeling to find better one in some aspect like 
remaining energy and total data transmission. We should have a tradeoff in choosing sensor data storage 
method. For future work, we plan to explore a new mechanism to deal with link failures between sensors 
in the network. Sending data more semantically will also be another step. Another step is evaluating this 
method when sensors send their data in stream.
Figure 2. Compares SSW and ES3N. X axis shows number of sensors and Y is the volume of data packets 
transmitted through network in KB.

213
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
NSSSD: A New Semantic Hierarchical Storage for Sensor Dat
Our NSSSD (short for New Semantic Hierarchical Storage for Sensor Data) model is mainly obtained 
from LEACH model, where we combine the advantages of semantic web concepts with clustering. 
The results show superior performance for our new model. We call the new model as NSSSD, which is 
elaborated as follows.
To begin with, assume that in a military application, the sensors are spread across the entire envi-
ronment in order to support enemy recognition. These sensors collect various kinds of data, including 
temperature and movement updates, etc. By increasing the total sensor numbers, the amount of collected 
data in the long run are extremely enormous. Most sensors use battery for their energy production. Thus 
they have a significant limitation in energy. In other words, this resource is critical. In brief, a huge 
amount of sensor data along with the limitation of most sensors in computational power and especially 
lack of efficient, long-last and reliable energy suppliers, all these together necessitate the sensors to 
use battery as their energy supplier. Hence a minor improvement can cause a significant promotion in 
the life time, which is the time that elapses from network inception to death of the whole network. But 
the battery industry has faced difficulties in achieving this. So we suggest more efficient software ap-
proaches like more efficient algorithms in order to reduce energy consumption of the overall network. 
Our proposed method is concerning how we should store data so that we can respond to semantic queries 
effectively and efficiently in terms of energy consumption. For example, requisites are disseminated 
in semantic web based queries on behalf of users, which may be closer to human language, following 
with less energy consumption of the network. NSSSD is the combination of a hierarchical method with 
the help of LEACH where sensor nodes are arranged into some clusters with semantic web technology. 
Hierarchical method we are using resembles tree structures with 3 levels. Sink node is the root of the 
hierarchy; cluster heads are children of the sink node. All other sensor nodes are located as leaves of the 
tree. After arranging sensors, we need to schedule data transmissions in order to make sure the safety 
of the data transmission process is maintained. The proposed method consists of two phases, the set-up 
phase and the steady-state phase. During the set-up phase, the clustering hierarchy is formed. During 
the steady-state phase, data transmission is performed as follows: Sensor nodes send their data in XML 
format to their cluster heads. Then Cluster heads aggregate the received XML-format data and periodi-
cally, based on the specified scheduling, send the aggregated data to the sink node, the root of the whole 
tree. A difference between our method and the LEACH algorithm is that our method concentrates on 
how data should be stored to achieve better performance. Our method stores data semantically to support 
more diverse queries but LEACH concentrates on arranging sensors instead of considering the query 
answering situation of sensors. Further, our method has better performance in situations that we need to 
save more energy to achieve longer life time along with responding to various queries that resemble to 
real human languages instead of querying with very restricted query languages.
The LEACH algorithm is used for clustering concerned sensor networks. Cluster heads send data 
periodically towards the sink node every 2 time units. Simulations are executed for 10 time units. We 
have assumed that the sink node is fixed and has no mobility. The simulations are conducted through 
using j-sim simulator for network simulation and protégé 2000 software for semantic web technology. 
Simulated network dimension is a 100*100 array. Number of sensors in this dimension range is varied 
from 10 to 150 in a mesh topology. We also use CSMA protocol for our MAC layer that we can set in 
j-sim. To get more steady data we have run the algorithm for 200 times. Our evaluation uses remaining 

214
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
energy parameter in the simulations. The content of the data we used in simulations can be demonstrated 
by the following sample data in XML form (see Figure 3).
As Figure 3 shows, the first part of the data denotes air temperature parameter with a value of 35.1 
Celsius and second part denotes the wind speed with a value of 6.5 meters per second. In brief, with the 
help of semantic web technologies, we can respond to more kinds of queries. This is because we store 
more metadata about the main data.
In Figure 4, the amount of received data (in KB) in the sink node of the whole network with different 
number of nodes and different number of clusters is illustrated. In this figure, the horizontal axis shows 
an ordered pair, (X, Y), where X is the number of sensors in the network and Y shows the number of 
clusters that the sensor network is divided into. As shown from the figure, increasing the number of sen-
sors results in receiving fewer amounts of data at the sink node. One possible reason for this phenomenon 
is the effect of the data aggregation. We use data aggregator that sends data in array formats instead of 
sending each part of the original data.
It may be possible that data is lost. For example, in (150,3), because of inappropriate data aggregation, 
we observe much data loss. But our analysis shows that most data is successfully aggregated. It means 
that data aggregation plays a much more important role in reducing the volume of data.
Figure 3. The XML sample of simulation
Figure 4. Amount of data received at the sink node

215
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
In a nonhierarchical sensor network, an increase of the total number of sensors can cause more data 
transmission so the remaining energy rate of overall sensor network decreases overtly. In hierarchical 
networks; nodes have been arranged into some clusters; because of bounding sensors into its cluster head, 
rate of energy consumption is reduced. But NSSSD combines both advantages of clustering approach 
and the semantic web one. Using semantic web causes replying to more various queries. We should 
establish a trade-off between total amounts of received data that we want to handle with the number of 
clusters to choose which one is more appropriate. In comparison (10, 3) with (20, 3); number of sensors 
increases but the number of cluster heads is fixed to 3; the slope is decreasing. One possible reason is 
that cluster heads cannot assign a particular time to each sensor then intervention between sensors hap-
pened and some sensors could not win in this competition so their data was lost. But when we compare 
this with other collected data, we can conclude that there is more possibility that the aggregator plays 
a major role in this reduction of data. Also as we can see in figure 2, the number of cluster heads plays 
a key role in the total data transmitted through the network. Another important aspect of the proposed 
model is how to aggregate data in cluster heads. Better aggregation results in less data transmission so 
that we can achieve longer life time of the whole network.
Figure 5 shows remaining energy of the sensor nodes during the operation of the network for a scenario 
in which we have 10 sensor nodes and 1 cluster head. The remaining energy of the cluster head is shown 
in black. As can be seen from this figure, the energy level of the cluster head is reduced more rapidly than 
the energy level of the other sensor nodes in the network (for example the red line). Remaining energy 
of cluster head is 0.999982*104 joule after 2 time units. Energy consumption of cluster head nodes is 
Figure 5. Energy consumption of the network

216
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
more than other nodes in the network because the head nodes are also in charge of aggregation. But we 
have got more powerful features like more scalability, better management and less consumption of the 
bandwidth. The system can respond to a more variety of queries. We should opt between all suitable 
approaches for this critical factor.
Finally a comparison between our proposed mechanism and another well-known approach named 
SSW mechanism in terms of the total data transmission throughout the network is demonstrated in Figure 
6. The curve of differences between them is illustrated instead of showing each of them.
As it is obvious, variation is in exponential form so we can conclude that NSSSD shows better per-
formance. We should opt which method is more suitable for storing the data in sensor networks based 
on the specific applications. For example, when we have 100 sensors and 2 cluster heads, the difference 
between the model and SSW is 300152 KB, which means NSSSD stores the same copy of sensor data as 
in SSW but using less volume of storage. So our storage method can lead to better performance. Because 
we want to respond to more kinds of queries with less energy consumption, we should apply semantic 
models in our storage model. For enegy, we use a hierarchical method to reduce energy consumption. 
NSSSD stores the same sensor data more efficiently in less storage volume than other methods like SSW 
or SemSOS. One major reason behind this is that we use aggregation in cluster heads with the help of 
semantic web technologies.
Figure 7 provides a comparison between NSSSD, SSW and SemSOS in terms of the amount of data 
(in KB) received at the sink node. We can see from this figure, our proposed mechanism consumes 
significantly fewer amounts of storage for storing the same sensor data than the other two mechanisms. 
For instance, consider the case when we have 100 sensor nodes divided into 3 clusters. In this case, 
with SemSOS and SSW methods, the total amounts of data stored at the sink node are about 700 MB 
and 500 MB, respectively, whereas using the NSSSD method, this amount is reduced to about 200 MB 
of data. When we store data in plain-text format, aggregation dose not have any significant effect in 
reducing the size of data, but when the sensor data is stored and transmitted via XML format, there are 
efficient aggregators, such as VERT aggregator, which can help significantly reducing the amount of 
storage for the data.
In this part, a new semantic hierarchical sensor data storage is introduced and formalized. It divides 
sensors into different clusters and sends data semantically. Each member node sends its data in semantic 
form to its corresponding cluster head. Cluster heads then aggregate the received data and send it to the 
sink node. We have integrated the benefits of sending data semantically and arranging the data hierarchi-
Figure 6. Comparison of new storage and SSW

217
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
cally. We have shown that NSSSD supports responding to more diverse queries in a semantic way with 
the combination of arranging sensors in a hierarchical mode to gain the advantages. We are planning on 
extending this new-born method like sending data in a more semantical way.
Sensor Hierarchical Data Storage
In this section, we introduce new sensor data storage.
At first, we arrange sensor nodes into some clusters. A sensor node in a cluster plays the role of a 
cluster head, collect sensor data from sensors that rely on that cluster, then aggregate data and send them 
to the sink for future querying. Sensors send their data in XML form. In figure 8 we see a snapshot of 
network view.
The network in figure 8, is divided into two parts. Node B and C play the role of cluster head in the 
network. Node B and node C aggregate received data. Then they send them to sink node, which in this 
example is Node A. We have done our simulation using j-sim sensor network simulator and protégé 2000 
software. We also use LEACH algorithm that is a hierarchical protocol for clustering sensors.
In figure 9, we can see the amount of received data in different situations.
Horizontal axis shows an ordered pair; X, Y; X is the number of sensors in the sensor network and 
Y shows the number of clusters that the sensor network is divided into.
Figure 7. Amounts of received data for three methods (NSSSD, SSW, and SemSOS form) in KB
Figure 8. Network view

218
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
As we can see, usually increasing sensors in sensor network results in less amount of data received 
in the Sink node. One possible reason is the aggregation of data because less data is transmitted in the 
network. However, in (10, 3), when we have 10 sensors that are divided into 3 clusters; we have a trade-
off in total amount of received data and number of clusters.
Figure 10 shows the lifetime and remaining energy of the sensor network in variety of situations.
Figure 9. Amount of received data in sink node
Figure 10. Rate of remaining energy during times

219
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
As we can see, when a sensor plays the role of cluster head, the rate of energy consumption is in-
creased because it does more processing like data aggregation, etc. The rate of consumption depends 
on the amount of processing.
CONCLUSION AND FUTURE WORK
we introduced and formalized a new Hierarchical Sensor Data Storage that divides sensors into some 
clusters, the node in a cluster that collect sensor data; sensor data send their data in SWE form; named 
cluster head, then aggregate received sensor data, then send aggregated data into sink. Sink nodes collect 
data for further processes like response more variety of queries, etc. For future work, we plan to explore a 
more reliable mechanism. In other words, we explore a new mechanism to deal with link failures between 
sensors in the network. Sending data more semantically will be also another step with needs evaluation.
REFERENCES
Sheth, A., & Perry, M. (2008). Traveling the Semantic Web through Space, Time, and Theme. IEEE 
Internet Computing, 12(2), 81–86. doi:10.1109/MIC.2008.46
Sheth, A., Henson, C., & Sahoo, S. (2008, July-August). Semantic sensor web. IEEE Internet Comput-
ing, 12(4), 78–83. doi:10.1109/MIC.2008.87
Sobeih, A., & Hou. (2003). A Simulation Framework for Sensor Networks in J-Sim. Technical Report 
UIUCDCS-R-2003-2386.
Botts, M., et al. (2007). OGC Sensor Web Enablement: Overview and High Level Architecture (OGC 
07-165). Open Geospatial Consortium White Research.
Henson, Pschorr, Sheth, & Thirunarayan. (2009). SemSOS: Semantic Sensor Observation Service. IEEE 
Computer Society.
Henson, C., Sheth, A., Jain, P., & Rapoch, T. (2007). Video on the semantic sensor web. W3C Video on 
the Web Workshop. Retrieved from http://www.w3.org/2007/08/video/researchs.html
Singh, C. P., Vyas, O. P., & Tiwari. (2008). A Survey of Simulation in Sensor Networks. Proceeding of 
CIMCA 2008, IAWTIC 2008.
Antoniou & van Harmelen. (2004). A Semantic Web Primer (Cooperative Information Systems). The 
MIT Press.
Gheisari, Movassagh, Qin, Yong, Tao, Zhang, & Shen. (2016). NSSSD: A New Semantic Hierarchical 
Storage for Sensor Data. IEEE 20th International Conference on Computer Supported Cooperative Work 
in Design (CSCWD 2016), Nanchang, China.
Aly, M., Pruhs, K., & Chrysanthis, P. K. (2006). Kddcs: A load-balanced in-network data-centric storage 
scheme for sensor networks. Proceedings of CIKM, 317–326. doi:10.1145/1183614.1183662

220
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
Gheisari & Abadi. (2011). Evaluation of two known methods in energy parameter. 3rd National Confer-
ence on computer engineering and information technology.
Lewis, C. Xie, & Arpinar. (2006). Es3n: A Semantic Approach to Data Management in Sensor Networks. 
Semantic Sensor network workshop, the 5th International Semantic Web Conference ISWC 2006, Ath-
ens, GA.
Gheisari, Porkar, & Zadeh. (2012). A New semantic Sensor Data Storage. ICCSET 2012, Zurich, Swit-
zerland.
Barnaghi, P., Meissner, S., Presser, M., & Moessner, K. (2009). Sense and Sensability: Semantic Data 
Modelling for Sensor Networks. Proceedings of ICT-MobileSummit Conference RDF Schema (RDF-S). 
Retrieved from http://www.w3.org/TR/rdf-schema/
Resource Description Framework (RDF). (n.d.). Retrieved from http://www.w3.org/TR/rdfconcepts/
Sensor Observation Service. (n.d.). Retrieved from http://www.opengeospatial.org/standards/sos
SPARQL Query Language for RDF. (n.d.). Retrieved from http://www.w3.org/TR/rdf-sparqlquery/
Santini, S., & Rauch, D. (2008). Minos: A Generic Tool for Sensor Data Acquisition and Storage. 19th 
International Conference on Scientific and Statistical Database Management IEEE, W3C Semantic Web 
Activity. Retrieved from http://www.w3.org/2001/sw/
Heinzelman, W. (2000). Application-specific protocol architectures for wireless networks (Ph.D. dis-
sertation). Mass. Inst. Technol., Cambridge, MA. Retrieved from http://protege.stanford.edu/
Gheisari, M., & Bagheri, A. R. (2011). Evaluation two methods on sensor data storage in total data. 5th 
symposium on advanced technology.
Vincenzo, Jimenez-Peris, & Patino-Martinez, Soriente, & Valduriez. (2012). Streamcloud: An elastic 
and scalable data streaming system. IEEE Transactions on Parallel and Distributed Systems, 23(12), 
2351–2365.
Tatbul, Etintemel, & Zdonik. (2007). Staying Fit: Efficient Load Shedding Techniques for Distributed 
Stream Processing. Proc. Int’l Conf. Very Large Data Bases (VLDB), 159–170.
Vincenzo, Jimenez-Peris, Patino-Martinez, & Valduriez. (2010). Streamcloud: A large scale data stream-
ing system. IEEE 30th International Conference on Distributed Computing Systems (ICDCS), 126–137.
Gheisari. (2012). Design, Implementation, and Evaluation of SemHD: A New Semantic Hierarchical 
Sensor Data Storage. Indian J. Innovations Dev., 1(3).
Puthal Deepak, , Mishra, & Swain. (2015). Cloud Computing Features Issues and Challenges: A Big 
Picture. International Conference on Computational Intelligence & Networks (CINE), 116–123.
Trusted Platform Module, T. C. G. (TPM) Specification. (n.d.). Retrieved from https://www.trusted-
computinggroup.org/specs/tpm/
Nepal, S. J. Z. D. L., & Jang, J. (2011). A mobile and portable trusted computing platform. EURASIP 
Journal on Wireless Communications and Networking, 2011(1), 1–19. doi:10.1186/1687-1499-2011-75

221
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
Rajiv, R. (2014). Streaming big data processing in datacenter clouds. IEEE Cloud Computing, 1(1), 
78–83. doi:10.1109/MCC.2014.22
Changqing, Li, Qiu, Awada, & Li. (2012). Big data processing in cloud computing environments. 12th 
International Symposium on Pervasive Systems Algorithms and Networks, 17–23.
Liyang, Wang, & Meng. (2005). Real-time forest fire detection with wireless sensor networks. Proceed-
ings. 2005 International Conference on Wireless Communications Networking and Mobile Computing, 
2, 1214–1217.
Deepak, Nepal, Ranjan, & Chen. (2016). A dynamic prime number based efficient security mechanism 
for big sensing data streams. Journal of Computer and System Sciences.
Taejoon, P., & Shin, K. G. (2004). LiSP: A lightweight security protocol for wireless sensor networks. 
ACM Transactions on Embedded Computing Systems, 3(3), 634–660. doi:10.1145/1015047.1015056
Puthal, Nepal, Ranjan, & Chen. (2016). DLSeF: A Dynamic Key Length based Efficient Real-Time 
Security Verification Model for Big Data Stream. ACM Transactions on Embedded Computing Systems.
Hu Han, , & Wen,. (2014). Towards Scalable Systems for Big Data Analytics: A Technology Tutorial. 
IEEE Access, 2, 652–687. doi:10.1109/ACCESS.2014.2332453
Issam & Abdul-Nabi. (2012). On formula to compute primes and the nth prime. Applied Mathematical 
Science, 6(76), 3751–3757.
Campbell, DePoy, Dillinger, & Young. (2003). Sustainable security for infrastructure SCADA. Al-
buquerque, NM: Sandia National Laboratories. Retrieved from www.sandia.gov/scada/documents/
SustainableSecurity.pdf
Davidson Euan, M., & Stephen, D. J. (2006). Applying multi-agent system technology in practice: 
Automated management and analysis of SCADA and digital fault recorder data. Power Systems IEEE 
Transactions on, 21(2), 559–567. doi:10.1109/TPWRS.2006.873109
Ramesh Maneesha, V. (2009). Real-time wireless sensor network for landslide detection. Sensor Tech-
nologies and Applications 2009. SENSORCOMM’09. Third International Conference on (pp. 405–409). 
IEEE. doi:10.1109/SENSORCOMM.2009.67
Chun-Pin, T., & Chen, C.-W. (2012). Natural disaster management mechanisms for probabilistic earth-
quake loss. Natural Hazards, 60(3), 1055–1063. doi:10.1007/s11069-011-9889-2
Castillo-Effer, Quintela, Moreno, Jordan, & Westhoff. (2004). Wireless sensor networks for flash-flood 
alerting. In Devices Circuits and Systems 2004. Proceedings of the Fifth IEEE International Caracas 
Conference on (pp. 142–146). IEEE.
Nehme Rimma, , Lim, Bertino, & Rundensteiner. (2009). StreamShield: a stream-centric approach 
towards security and privacy in data stream environments. In Proceedings of the 2009 ACM SIGMOD 
International Conference on Management of data (pp. 1027–1030). ACM.
Sandhu Ravi, S. (1992). Lattice-based enforcement of chinese walls. Computers & Security, 11(8), 
753–763. doi:10.1016/0167-4048(92)90131-A

222
Data Storages in Wireless Sensor Networks to Deal With Disaster Management
﻿
STREAM: the stanford stream data manager (demonstration description). (2003). Proceedings of the 
2003 ACM SIGMOD international conference on Management of data, 665–665.
Martin, R. (1999). Snort: Lightweight Intrusion Detection for Networks. LISA, 99(1), 229–238.
Tsikoudis, N. A. P., & Markatos, E. P. (2016). LEoNIDS: A Low-latency and Energy-efficient Network-
level Intrusion Detection System. IEEE Transactions on Emerging Topics in Computing, 4(1), 142–155. 
doi:10.1109/TETC.2014.2369958
Gheisari & Abadi. (2011). Evaluation methods on sensor data storages in energy. CEIT2011.
Jurdak, Topes, & Baldi. (2004). A Framework for Modeling Sensor Networks. OOPSLA IVorhhop on 
Building Software for Pervasive Computing.
Berners-Lee, T., Hendler, J., & Lassila, O. (2001, May). The semantic web. Scientific American, 284(5), 
28–37. doi:10.1038/scientificamerican0501-34 PMID:11323639
GhadakSaz, Amini, Porkar, & Gheisari. (2012). A Design- Implement and Compare two proposed sen-
sor data’s storages Named SemHD and SSW. International Geoinformatics Research and Development 
Journal, 3(2).
Gheisari, Porkar, SharifZadeh, & Moghaddam. (2012). A New semantic Sensor Data Storage. ICCSET 
2012, Zurich, Switzerland,
Jafari & Gheisari. (2016). Automatic Text Summarization Using Fuzzy Inference. 22nd IEEE Interna-
tional Conference on Automation and Computing (ICAC 2016).
ENDNOTE
1	
SWE

223
Copyright © 2018, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.
Chapter  8
DOI: 10.4018/978-1-5225-2575-2.ch008
ABSTRACT
In recent years, large-scale disasters took place frequently and always caused severe damages to the 
network infrastructures. Due to these damages, available network resources are usually not sufficient to 
meet the data transmission requirements of users after disasters. Moreover, users tend to behave selfishly 
by consuming as much network resources as possible. Incentive mechanisms are therefore essential for 
the users to voluntarily cooperate with each other and improve the system performance. In commercial 
networks, this can be efficiently achieved through pricing. Namely, by selecting an appropriate pricing 
policy, it is able to incentivize users to choose the service that best matches their data transmission 
demands. In this chapter, assuming that a time-dependent pricing scheme is imposed on network users, 
a Stackelberg leader-follower game is then formulated to study the joint utility optimization problem of 
the users in a disaster region subject to maximum delay and storage constrains. The equilibrium for the 
Stackelberg leader-follower game is also investigated.
INTRODUCTION
As shown in Figure 1, Large-scale disasters such as earthquakes, tsunamis, hurricane-force winds, and 
floodwaters, always cause severe damage to devices or components that make up the network infrastruc-
ture. For instance, the Great Tohoku, Japan Earthquake and Tsunami in 2011 destroyed thousands of 
homes and network infrastructures including 1,900,000 telecommunication circuits and 29.000 cellular 
base station towers (Oskin, 2015). Disaster recovery, especially the Internet service recovery has been 
a critical issue and attracted significant attention from both academia and industry.
Application of Game Theory 
for Network Recovery After 
Large-Scale Disasters
Bo Gu
Kogakuin University, Japan
Osamu Mizuno
Kogakuin University, Japan

224
Application of Game Theory for Network Recovery After Large-Scale Disasters
﻿
After disasters, available network resources become extremely limited, while traffic demand on the 
other hand may increase since most users make voice calls to confirm the safety of their relatives or 
friends. NTT docomo, the predominant mobile phone operator in Japan, reported up to 50-60-fold in-
creases in voice calls being made after the Great Tohoku, Japan Earthquake and Tsunami in 2011 (MIC 
White paper, 2013). The limited network resource and surge in traffic demand lead to severe network 
congestion.
Vehicle-based Delay Tolerant Networks (DTN) have consequently emerged to address the network 
congestion problem after disasters. The Vehicle-based DTNs rely on messengers, which could be heli-
copters, unmanned aerial vehicles (UAVs), busses, or trains with data storage, to carry message bundles 
to or out of disaster-affected regions. Burgess, Gallagher, Jensen & Levine (2006) proposed an DTN 
routing protocol which is termed MaxProp. The authors considered the problem of determining which 
packets should be deleted when the storage of messenger is not enough. Harras & Almeroth (2006) pro-
posed several inter-regional messenger scheduling algorithms in DTN and evaluated the efficiency of 
these scheduling algorithms through simulations. Uddin, Nicol, Abdelzaher & Kravets, (2009) pointed 
out that DTN depends on the underlying mobility model of messengers, then thy proposed a mobility 
model for post-disaster scenarios, and extended the capabilities of a DTN simulator (ONE) to adapt 
to the mobility of messengers. Fajardo, Yasumoto, Shibata, Sun & Ito (2012) presented a DTN-based 
solution to aggregate disaster-related information from a disaster region. A filter was then constructed 
to drop duplicate message generated from users. Simulation results confirmed that this solution achieve 
a small delay in message delivery. Takahashi, Nishiyama & Kato (2013) studied the fairness issue in 
DTN. The authors evaluated the performance of existing routing algorithms in DTN through extensive 
simulations and show that none of the existing routing algorithms can achieve the fair message delivery.
In vehicle-based DTNs, the storage as well as the time duration that messengers exist in disaster-
affected regions could be limited. However, users always act without considering the system performance 
even during disasters. For example, network users may transmit nonurgent or even unnecessary data, 
Figure 1. Damage to network infrastructures due to large-scale disasters

225
Application of Game Theory for Network Recovery After Large-Scale Disasters
﻿
which increases the time for transmitting data to messengers, and hence result in a terrible delay to the 
other users with emergent data to be sent.
Incentive mechanisms are therefore essential for users to voluntarily cooperate with each other to im-
prove the network resource utilization. In commercial networks, this can be efficiently achieved through 
pricing. Namely, by selecting an appropriate pricing scheme, it is able to incentivize users to choose the 
service that best matches their data transmission demands.
The authors first review the state of art of network pricing and then introduce an appropriate pricing 
scheme that fits well with our purpose.
TRENDS IN PRICING FOR CONGESTION MANAGEMENT
Flat Rate
Flat rate refers to a tariff that is independent of the amount of traffic produced as well as of the Quality 
of Service (QoS) provided. Due to the characteristics of simplicity, flat-rate pricing schemes have been 
the dominating model for pricing in both wired and wireless networks for a long time. However, the flat 
rate does not differentiate between light users (e.g., e-mail, web browsing users) and heavy users (e.g., 
multimedia applications, cloud file synchronization users). It is criticized that light users subsidize other 
heavy users, which hence degrades the fairness of the overall system. Moreover, congestion costs cannot 
be recovered by using flat-rate pricing.
Usage-Based Pricing (UBP)
Under UBP, prices vary as a function of the amount of traffic that actually flows through a connection 
(Odlyzko, Arnaud, Stallman & Weinberg, 2012). Since May 2011, American ISPs T-Mobile and AT&T 
start data caps and charge additional fees to users as long as they go over the limits. UBP has been 
proved to be effective on limiting users’ monthly usage. However, UBP hardly works well for controlling 
peak-time congestion unless it changes its prices dynamically to reflect real-time congestion condition.
Time-Dependent Pricing (TDP)
TDP addresses the peak-time congestion problem by considering not only how much a user transmits 
data, but also when a user transmits data (Zhang, Wu, & Wang, 2014). TDP encourages users to shift 
their nonurgent traffic demand from peak time to off-peak time. Therefore, comparing with the flat-rate 
pricing and UBP, TDP has the potential to flatten time-of-the-day fluctuations in traffic demand, improv-
ing the overall bandwidth utilization and saving unnecessary investment expenses for service providers.
The concept of Smart Market is firstly proposed in (MacKie-Mason, & Varian, 1995), in which each 
user bids on the packet that is going to be transmitted. The bid reflects his/her willingness to pay towards 
transmitting the packet on network. The packet will be delivered if the bid exceeds the network’s marginal 
congestion cost. Although mart Market has its advantages in terms of allocating resources efficiently, 
some issues need to be further investigated, such as, accounting complexity, burden of decision making 
on users, etc.

226
Application of Game Theory for Network Recovery After Large-Scale Disasters
﻿
El-Sayed, Mukhopadhyay, Urrutia-Valdes, & Zhao (2011) proposed a novel off-peak charge discount 
service. During off-peak time, ISP offers a charge discount to users. The authors investigated three fac-
tors that affect the ISP’s revenue: (i) the size of off-peak window when the charge discount is offered; 
(ii) the average discount rate for shifting 1 MB traffic load from peak time to off-peak time; and (iii) the 
percentage of peak-time load shifted because of the price incentives.
Jiang, Parekh, & Walrand (2008) proposed an incentive-compatible TDP scheme where only a mo-
nopoly ISP exists. If the monopoly ISP has complete information on users’ preference over access time, 
the proposed TDP scheme results in social welfare maximization. Zhang, Gu, Yamori, Xu & Tanaka 
(2015) extended the monopoly case to an oligopoly case, and used a game theoretic approach to determine 
the optimal time-dependent prices. Competition among ISPs is hence taken into account.
In smart grid, time-of-use pricing (Mohsenian-Rad, & Leon-Garcia, 2010) offers different prices 
for peak, normal and off-peak time. The same concept is also adopted in communication networks, i.e., 
day-ahead pricing (Ha, Sen, Joe-Wong, Im, & Chiang, 2012). In DAP pricing model, prices could be 
different for different time slot and they remain flat within each time slot. Furthermore, prices are offered 
on a day-ahead basis. The first proof-of-concept prototype of DAP is named TUBE (Sen, Joe-Wong, 
Ha & Chiang, 2012, Sen, Joe-Wong, Ha, & Chiang, 2014), where time is divided into 48 slots, with 30 
minutes per slot. The authors analyzed the probability of users to shift their traffic demand from peak 
time to off-peak time, based on which, the traffic demand of each time slot as well as the optimal price 
for revenue maximization are calculated.
Application-Based Pricing (ABP)
In recent years, the rise of Over-the-Top (OTT) applications imposes a new challenge for network op-
erators to get recovery of their investments on network capacity. For example, OTT services such as 
WhatsAPP have clearly overtaken the traditional voice calls and SMS, which formed the major source of 
the revenue for the network operators. Recently, some operators are trying to seek new business models 
by involving the participation of contents providers aiming to overcome the effect of OTTs. ABP is 
emerging as a new pricing trend in many countries over the world.
•	
French ISP Orange charges Google for the traffic incurred by YouTube and other Google applica-
tions, which occupy nearly 50% of total traffic on the Orange network (Orange, 2016).
•	
Danish ISP TDC bundles its online music service “TDC play” into its data plans (Lunden, I., 
2010).
•	
American ISP Comcast does not count the usage of its video streaming service Xfinity towards 
users’ data caps (Xfinity, 2016).
ABP could be achieved via Deep Packet Inspection (DPI) technologies. Network management system 
equipped with the DPI technology examines the header of each packet as it passes through and charge 
different prices to different types of traffic. Nevertheless, ABP received widespread criticism since it 
may threaten network neutrality (Kraemer, Wiewiorra & Weinhardt, 2013).
A brief summary of the main advantages and disadvantages of fixed rate, UBP, TDP and ABP is 
presented in Table I.

227
Application of Game Theory for Network Recovery After Large-Scale Disasters
﻿
UTILITY FUNCTIONS
Utility functions are used to model network users’ preferences. These functions help to describe how 
sensitive users are to the Quality of Service (QoS) changes. In some sense, utility can be considered as 
the amount of money that a user is willing to pay for certain QoS guarantees (Gu, Zhang, Yamori, & 
Tanaka, 2012, Gu, Zhang, Yamori, & Tanaka, 2013a, Gu, Zhang, Yamori, & Tanaka, 2013b, Gu et al., 
2015a, Gu et al., 2015b).
Ideally, utility should be modelled as a function of actual QoS parameters, e.g., delay or packet losses. 
However, in real networks, it is impossible to predict such quality measures in advance, which closely 
depend on such as traffic models, scheduling disciplines and network topology. Thus, the amount of 
resources allocated is used to describe the utility function instead of using actual QoS parameters. As 
shown in Figure 2, traffic is classified into two categories according to their sensitivity towards the 
amount of resources allocated (e.g., bandwidth).
Elastic Traffic
Traditional data traffic such as e-mail are elastic in the sense that they incline to be tolerant of variations 
in delay, and can work with even minimal amounts of network resource. Therefore, their utility can be 
modeled as a logarithm function (which is increasing, strictly concave and differentiable) of the amount 
of resource allocated (Kerry, 1997).
Table 1. Characteristics of different pricing schemes
Flat rate
UBP
TDP
ABP
Easy to implement and little overhead for billing
yes
no
no
no
Able to recover congestion cost
no
yes
yes
yes
Able to alleviate peak-time congestion
no
no
yes
no
Threaten network neutrality
no
no
no
yes
Figure 2. Elastic traffic and inelastic traffic

228
Application of Game Theory for Network Recovery After Large-Scale Disasters
﻿
Inelastic Traffic
On the other hand, real-time applications (e.g., VoIP and streaming service) that employ constant bit 
rate coding are inelastic, since they require a fixed amount of bandwidth for adequate QoS. Therefore, 
their utility could be modeled as a sigmoid function of the amount of bandwidth allocated. Namely, the 
utility of real-time application users stays in an extremely low level when the bandwidth allocated is not 
enough to meet their QoS requirement.
Since real-time data transmission is difficult to achieve in disaster scenarios where data transmission 
relies on the messengers communicating between disaster and normal regions, the authors therefore 
focus on the elastic traffic.
PROBLEM FORMULATION
Figure 3 demonstrates an example of network topologies after disasters. A region is defined as an intra-
connected cluster of nodes (i.e., users with mobile devices). Regions are classified into two categories: 
disaster regions and normal regions. A disaster region could be a remote village which suffered from a 
disaster. The nodes inside the disaster region are physically isolated from the Internet. On the other hand, 
a normal region could be a rescue team or a village which does not or lightly suffered from the disaster. 
Regions are disconnected from each other and messengers are used to carry bundles of data between the 
regions. Messengers could be helicopters, unmanned aerial vehicles (UAVs), busses, or trains with data 
storage. Within each region, a node is selected as cluster header to collect data from other nodes. Mes-
sengers know the location of the cluster header exactly. When messengers arrive at the disaster region, 
Figure 3. Delay tolerant network with messengers

229
Application of Game Theory for Network Recovery After Large-Scale Disasters
﻿
they download the data from the cluster header and then carry the data to a normal region with Internet 
connection (Harras & Almeroth, 2006, Mizuno, Takashi, Yamamoto, & Asatani, 2013).
Without loss of generality, the authors consider a region which is composed of a set of nodes N. A 
node n ∈N  has a maximum amount of data vn t,
max  to be carried from a disaster region to a normal 
region, including urgent data, semi-urgent data and nonurgent data. In order to provide the right incen-
tives for each node to choose the optimal amount of data that best matches its demands during disaster, 
the authors consider a charging policy which is a combination of UBP and TDP. Specifically, the price 
charged to node n is a linear function of the amount of data to be sent by node n:
P
v
p
n t
n t
t
,
,
=
	
(1)
where the unit price pt is time-dependent and varies as a function of the overall traffic demand; and vn t,  
is the amount of data that node n actually sends in time t with an upper bound of vn t,
max .
The authors focus on uplink transmission (from disaster region to normal region) over a single 
messenger, while it is worth pointing out that the results obtained under this assumption can be easily 
extended to scenarios with parallel data delivery and multiple messengers.
As illustrated in the last section, the authors focus on the elastic traffic and use a logarithmic function 
of vn t,  to represent the utility in accordance with the law of diminishing marginal returns.
U
v
n t
n t
,
,
log
= θ
	
(2)
where  θ  is a scale factor and can be thought of as a parameter representing the priority of users’ willing-
ness to pay (WTP).
Game theory (Fudenberg & Tirole, 1991) is regarded as a powerful tool to modeling and analyzing 
the interactions between decision makers especially when conflicted interests exist. Recent years, game 
theory has been successfully used for a variety of purposes, such as congestion control, rate allocation, 
and utility optimization (Gu, Yamori, & Tanaka, 2012a, Gu, Yamori, Xu, & Tanaka, 2012b, Gu, Yamori, 
Xu, & Tanaka, 2013a, Gu, Yamori, Xu, & Tanaka, 2013b, Gu, Yamori, & Tanaka, 2014, Gu, Dong, 
Zhang, Liu, & Tanaka. 2017).
Specifically, Stackelberg leader-follower game (Fudenberg & Tirole, 1991) is a non-cooperative 
game, where a leader player selects its strategy firstly and then the followers response sequentially. 
Nash equilibrium (Fudenberg & Tirole, 1991) of the Stackelberg is a profile of strategies such that no 
player in the game can improve its payoff by unilaterally changing its own strategy. In other words, each 
player achieves best response to the others’ and the system achieves a stable status. Nash equilibrium of 
Stackelberg leader-follower game can be obtained through backward induction. Namely, given the best 
response of the followers, the leader can choose the optimal strategy to gain the highest payoff.
Since the messenger has the priority to decide its pricing strategy first, and based on which the nodes 
determine their volume of data to be sent, it is natural to employ Stackelberg game to model the interac-
tions between the messenger and nodes in a disaster region.
The Stackelberg game G(Player, Strategy, Payoff) is defined as follows.

230
Application of Game Theory for Network Recovery After Large-Scale Disasters
﻿
•	
Player: The messenger is the leader, and nodes in a disaster region are the follower.
•	
Strategy: For the messenger, the strategy is the selection of the price to be charged in time t, and 
for node n, the strategy is the selection of the amount of data vn t,  to be delivered.
•	
Payoff: The payoff for the messenger and each node are described as follows.
The payoff for node n is the net benefit which is denoted by g
v
p
n
n t
t
, ,
(
).
g
v
p
v
v
p
n
n t
t
n t
n t
t
,
,
,
,
log
(
) =
−
θ
	
(3)
over
v
v
n t
n t
,
,
≤
max 	
(4)
On the other hand, the payoff of the messenger is the joint utility of all nodes in the disaster region 
which is denoted by h p v
t
n t
,
,
(
).
h
p v
v
t
n t
N
n t

n
,
log
,
,
(
) =
∈∑θ
	
(5)
subject to
n N n t
v
x
d
∈
∑
≤
,
	
(6)
and
n N
n t
v
s
∈∑
≤
,
	
(7)
where x is the transmission rate for downloading data from the cluster header to the messenger, 
n N n t
v
x
∈
∑
,  
represents the time used for downloading all the data from the cluster header to the messenger, d is the 
maximum time duration that the messenger stays in the disaster region, and s is the maximum amount 
of storage that the messenger has. Equation (6) and (7) represent the delay constraint and storage con-
straint, respectively, in order to optimize the joint utility of all nodes. Equation (6) and (7) could be 
merged to Eq.(8) as follows:
n N
n t
v
C
∈∑
≤
,
	
(8)
where C
xd s
=
(
)
min
,
, which is identical to all the nodes.

231
Application of Game Theory for Network Recovery After Large-Scale Disasters
﻿
NASH EQUILIBRIUM SOLUTION
As shown in Figure 4, the messenger (leader) imposes a price per unit amount of data (cost) on the nodes 
(followers) to ensure that the delay and storage constraints could be satisfied. Then, each node updates 
its data delivery strategy (i.e., the amount of data to be sent) to maximize their individual payoff. Given 
the best response of each node, the messenger chooses the price that optimize the joint utility through 
backward induction. 
Definition 1. v
p
n t
t
,
*
*
,
(
) is a Nash Equilibrium if for any v
p
n t
t
, ,
(
) ,
g
v
p
g
v
p
n
n
n t
t
n
n t
t
,
*
*
,
*
,
,
,
(
) ≥
(
) ∀
	
(9)
and
h
p
v
h
p v
t
n t
t
n t


,
,
*
,
*
,
*
(
) ≥(
)	
(10)
Given the pricing strategy pt , node n maximizes its payoff by choosing the amount of data vn t,  to 
be sent. The authors first consider the payoff optimization problem of network users as follows:
Problem 1.
max
,
log
,
,
,
,
v
n
n t
t
n t
n t
t
n t
g
v
p
v
v
p
(
) =
−
θ
	
(11)
Figure 4. Stackelberg game

232
Application of Game Theory for Network Recovery After Large-Scale Disasters
﻿
subject to
v
v
n t
n t
,
,
≤
max 	
(12)
Taking the first differentiation of Eq.(11) and let it equals to 0
∂
(
)
∂
=
g
v
p
v
n
n t
t
n t
,
,
,
0 	
(13)
The best response of node n could be derived as follows:
v
p
v
n
n t
t
n t
,
*
,
min
,
,
=





∀
θ
max
	
(14)
On the other hand, the messenger then decides its pricing strategy by solving the following joint 
utility optimization problem.
Problem 2.
max
,
log
,
*
,
*
p
t
n t
N
n t
t
h p v
v


n
(
) =
∈∑
	
(15)
subject to
n∈∑
≤
N
n t
v
C
,
*
	
(16)
The corresponding Lagrangian form of Eq.(16) is
L v
v
v
C
n t
N
n t
N
n t

,
log
,
*
,
*
,
*
λ
λ
(
) = −
+
−






∈
∈
∑
∑
n
n
 	
(18)
where λ  is the Lagrangian multiplier.
It is observed that the objective function is a concave function over vn t,
* . The constraints are affine. 
Therefore, Problem 2 is a convex optimization problem. For a convex optimization problem, the optimal 
solution must satisfy the Karush-Kuhn-Tucker (KKT) conditions (Boyd & Vandenberghe, 2004).
The KKT conditions are given as follows:

233
Application of Game Theory for Network Recovery After Large-Scale Disasters
﻿
∂(
)
∂
=
∀
−





=
∈∑
L v
v
n
v
C
n t
n t
N
n t

,
,

,
*
,
*
,
*
λ
λ
λ
0
0
n

≥





0
	
(19)
Solving Eq.(19), it could be obtained that
v
C
N
n
n
*
,
=
∀

	
(20)
When 
max
v
p
n t
t
,
 > θ , ∀n , combining the best response of users shown in Eq.(17) and Eq.(20), the 
messenger can choose its optimal price as follows:
p
N
C
t
* =
θ
	
(21)
which indicates that the optimal price depends on the data delivery demand (i.e., N ) as well as the 
capacity of the messenger (i.e., C ).
Otherwise, the algorithm used to find the optimal price pt
*  are shown as follows:
Algorithm 1 Steps involved in finding the optimal price pt
* .
1: Inputs:
C, |N|, θ , 
,

vn t
max ,  ∀n
2: Initialize:
p
N
C
t ⇐
θ
3: for n=1 to |N| do
4: v
C
N
v
n t
n t
,
*
,
min
,
=






max
5: end for
6: while 
n∈∑
−
N
n t
v
C
,
*
>Threshold do
7: Consider a small perturbation ” p

234
Application of Game Theory for Network Recovery After Large-Scale Disasters
﻿
8: if 
n∈∑
>
N
n t
v
C
,
*
 then
9: p
p
p
t
t
⇐
+ ”
10: else
11: p
p
p
t
t
⇐
−”
12: end if
13: for n=1 to |N| do
14: v
C
N
v
n t
n t
,
*
,
min
,
=






max
15: end for
16: end while
17: p
p
t
t
* =
CONCLUSION
In this chapter, the authors considered a delay tolerant network where messengers deliver data between 
disaster and normal regions. Pricing is used as an incentive mechanism to reward nodes in disaster 
regions to select the amount of data that best matches its demand. The authors first review the state of 
art of network pricing and then proposed a usage-based-time-dependent pricing scheme that fits well 
with the purpose. The authors then constructed a Stackelberg game to analyze the interactions between 
the nodes in a disaster region and the messenger aiming to maximize the joint utility of the nodes, and 
characterized the Nash equilibrium solution of the game.
REFERENCES
Boyd, S., & Vandenberghe, L. (2004, March). Convex Optimization. Cambridge, UK: Cambridge Uni-
versity Press.
Burgess, J., Gallagher, B., Jensen, D., & Levine, B. N. (2006). MaxProp: Routing for Vehicle-Based 
Disruption-Tolerant Networks. Proceedings of INFOCOM, 2006, 1–11.
El-Sayed, M., Mukhopadhyay, A., Urrutia-Valdes, C., & Zhao, Z. J. (2011). Mobile data explosion: 
Monetizing the opportunity through dynamic policies and QoS pipes. Bell Labs Tech. J., 16(2), 79–99. 
doi:10.1002/bltj.20504
Fajardo, J. T. B., Yasumoto, K., Shibata, N., Sun, W., & Ito, M. (2012). DTN-based data aggregation for 
timely information collection in disaster areas. In Proceedings of 2012 IEEE 8th International Confer-
ence on Wireless and Mobile Computing, Networking and Communications (pp. 333-340). doi:10.1109/
WiMOB.2012.6379095
Fudenberg, D., & Tirole, J. (1991). Game Theory. Cambridge, MA: MIT Press.

235
Application of Game Theory for Network Recovery After Large-Scale Disasters
﻿
Gu, B., Dong, M., Zhang, C., Liu, Z., & Tanaka, Y. (2017, January). Real-Time Pricing for On-Demand 
Bandwidth Reservation in SDN-Enabled Networks. In Proceedings of 14th Annual IEEE Consumer 
Communications & Networking Conference.
Gu, B., Yamori, K., & Tanaka, Y. (2012a, February). Auction-based Resource Allocation for Wireless 
Local Area Networks in Metropolitan Areas. In Proceedings of 14th International Conference on Ad-
vanced Communication Technology (pp. 470-474).
Gu, B., Yamori, K., & Tanaka, Y. (2014, December). Integration of time-dependent pricing with transmis-
sion rate control for flattening out peak-time demand. In Proceedings of 2014 International Conference 
and Workshop on the Network of the Future (pp. 1-5). doi:10.1109/NOF.2014.7119765
Gu, B., Yamori, K., Xu, S., & Tanaka, Y. (2012b, April). A Game Theoretic Framework for Bandwidth 
Allocation and Pricing in Federated Wireless Networks. IEICE Transactions on Communications, E95-
B(4), 1109–1116. doi:10.1587/transcom.E95.B.1109
Gu, B., Yamori, K., Xu, S., & Tanaka, Y. (2013a, February). An Incentive-Compatible Load Distribu-
tion Approach for Wireless Local Area Networks with Usage-Based Pricing. IEICE Transactions on 
Communications, E96-B(2), 451–458. doi:10.1587/transcom.E96.B.451
Gu, B., Yamori, K., Xu, S., & Tanaka, Y. (2013b, July). Multi-Stage Non-Cooperative Game for Pricing 
and Connection Admission Control in Wireless Local Area Networks. IEICE Transactions on Commu-
nications, E96-B(7), 1986–1996. doi:10.1587/transcom.E96.B.1986
Gu, B., Zhang, C., Yamori, K., & Tanaka, Y. (2012, December). Utility-Based Load Distribution for QoS 
Provisioning and Utility Maximization in Wireless Random Access Networks. In Proceedings of 2nd 
International Conference on Computer Science and Network Technology (pp. 406-410). doi:10.1109/
ICCSNT.2012.6525965
Gu, B., Zhang, C., Yamori, K., & Tanaka, Y. (2013a, August). A Greedy Algorithm for Connection 
Admission Control in Wireless Random Access Networks. In Proceedings of 19th Asia-Pacific Confer-
ence on Communications. doi:10.1109/APCC.2013.6765989
Gu, B., Zhang, C., Yamori, K., & Tanaka, Y. (2013b, September). Distributed Connection Admission 
Control Integrated with Pricing for QoS Provisioning and Revenue Maximization in Wireless Random 
Access Networks. In Proceedings of 15th Asia-Pacific Network Operations and Management Symposium 
(pp. 1-5).
Gu, B., Zhang, C., Yamori, K., Zhou, Z., Liu, S., & Tanaka, Y. (2015a, August). Regulating Network 
Traffic by Exploiting the Price Elasticity of Demand in Wireless Random Access Networks. In Proceed-
ings of 10th Asia-Pacific Symposium on Information and Telecommunication Technologies (pp.1-3). 
doi:10.1109/APSITT.2015.7217129
Gu, B., Zhang, C., Yamori, K., Zhou, Z., Liu, S., & Tanaka, Y. (2015b, November). Facilitating Incentive-
Compatible Access Probability Selection in Wireless Random Access Networks. IEICE Transactions 
on Communications, E98-B(11), 2280–2290. doi:10.1587/transcom.E98.B.2280

236
Application of Game Theory for Network Recovery After Large-Scale Disasters
﻿
Ha, S., Sen, S., Joe-Wong, C., Im, Y., & Chiang, M. (2012). Tube: time-dependent pricing for mobile 
data. In Proceedings of the ACM SIGCOMM 2012 conference on Applications, technologies, architec-
tures, and protocols for computer communication (vol. 42, no. 4, pp. 247–258).
Harras, K. A., & Almeroth, K. C. (2006). Inter-regional messenger scheduling in delay tolerant mobile 
networks. In Proceedings of the 2006 International Symposium on on World of Wireless, Mobile and 
Multimedia Networks (pp. 93-102). doi:10.1109/WOWMOM.2006.53
Jiang, L., Parekh, S., & Walrand, J. (2008, April) Time-dependent network pricing and bandwidth trad-
ing. In Proceedings of IEEE/IFIP Netw. Oper. (pp. 193-200). doi:10.1109/NOMSW.2007.33
Kerry, F. (1997). Charging and rate control for elastic traffic. European Transactions on Telecommuni-
cations., 8(1), 33–37. doi:10.1002/ett.4460080106
Kraemer, J., Wiewiorra, L., & Weinhardt, C. (2013, October). Net neutrality: A progress report. In Pro-
ceedings of Telecommun. Policy (vol. 37, no. 9, pp. 794-813). doi:10.2139/ssrn.2344623
Lunden, I. (2010, January). Danish ISP TDC Preps IPO After Bundled-Music Success. Retrieved August 01, 
2016, from https://gigaom.com/2010/01/15/419-danish-isp-tdc-preps-ipo-after-bundled-music-success/
MacKie-Mason, J. K., & Varian, H. (1995). Pricing the Internet. Cambridge, MA: MIT Press.
MIC White Paper. (2013, November). 東日本大震災における情報通信の状況. Retrieved August 01, 
2016, from www.soumu.go.jp/johotsusintokei/whitepaper/ja/h23/pdf/n0010000.pdf
Mizuno, O., Takashi, A., Yamamoto, S., & Asatani, K. (2013). Sustainable operation technologies for 
the mitigation information network in urban area. In Proceedings of Humanitarian Technology Confer-
ence (pp. 255-260). doi:10.1109/R10-HTC.2013.6669051
Mohsenian-Rad, A. H., & Leon-Garcia, A. (2010, September). Optimal residential load control with 
price prediction in real-time electricity pricing environments. IEEE Transactions on Smart Grid., 1(2), 
120–133. doi:10.1109/TSG.2010.2055903
Odlyzko, A., Arnaud, B. S., Stallman, E., & Weinberg, M. (2012, May). Know your limits: Considering 
the role of data caps and usage based billing in internet access service. Retrieved August 01, 2016, from 
http://www.publicknowledge.org/files/UBP%20paper%20FINAL.pdf
Orange. (n.d.). Retrieved August 01, 2016, from http://www.orange.com/en/home
Oskin, B. (2015, May). Japan Earthquake & Tsunami of 2011: Facts and Information. Retrieved August 
01, 2016, from http://www.livescience.com/39110-japan-2011-earthquake-tsunami-facts.html
Sen, S., Joe-Wong, C., Ha, S., & Chiang, M. (2012, November). Incentivizing time-shifting of data: A 
survey of time-dependent pricing for internet access. IEEE Communications Magazine, 50(11), 91–99. 
doi:10.1109/MCOM.2012.6353688
Sen, S., Joe-Wong, C., Ha, S., & Chiang, M. (2014, June). A survey of broadband data pricing: Past 
proposals, current plans, and future trends. ACM Computing Surveys, 46(2).
Takahashi, A., Nishiyama, H., & Kato, N. (2013, January). Fairness Issue in Message Delivery in De-
lay- and Disruption-Tolerant Networks for Disaster Areas. In Proceedings of International Conference 
on Computing, Networking and Communications (pp. 890-894). doi:10.1109/ICCNC.2013.6504207

237
Application of Game Theory for Network Recovery After Large-Scale Disasters
﻿
Uddin, M. Y. S., Nicol, D. M., Abdelzaher, T. F., & Kravets, R. H. (2009). A post-disaster mobility 
model for delay tolerant networking. In Proceedings of Winter Simulation Conference (pp. 2785-2796). 
doi:10.1109/WSC.2009.5429249
Xfinity. (n.d.). XFINITY from Comcast. Retrieved August 01, 2016, from http://www.xfinity.com/
Zhang, C., Gu, B., Yamori, K., Xu, S., & Tanaka, Y. (2015, January). Oligopoly Competition in Time-
Dependent Pricing for Improving Revenue of Network Service Providers with Complete and Incomplete 
Information. IEICE Transactions on Communications, E98-B(01), 20–32. doi:10.1587/transcom.E98.B.20
Zhang, L., Wu, W., & Wang, D. (2014, April). Time dependent pricing in wireless data networks: 
Flat-rate vs. usage-based schemes. In Proceedings of the IEEE International Conference on Computer 
Communications 2014 (pp. 700–708). doi:10.1109/INFOCOM.2014.6847996
ADDITIONAL READING
Chen, Y., Gu, B., Yamori, K., & Tanaka, Y. (2014, March). Time-Dependent Pricing for Realizing Maxi-
mum Revenue of VOD Type IPTV Service Provider. In Proceedings of 2014 IEICE General Conference 
(No.BS-1-70, pp. S-131-S-132).
Gu, B. (2013, February). Studies on congestion control using pricing in wireless local area networks. 
(Unpublished doctoral dissertation). Waseda University, Tokyo, Japan.
Gu, B., Yamori, K., & Tanaka, Y. (2013, September). Game Modelling of Connection Admission Con-
trol for Random Access Networks. In Proceedings of 2013 IEICE Communications Society Conference 
(No.BS-7-22, pp. S-75-S-76).
Gu, B., Yamori, K., Xu, S., & Tanaka, Y. (2009, September). Wireless Network Access Market Using 
Threshold Price Double Auction Protocol. In Proceedings of 2009 IEICE Communications Society 
Conference (No.BS-10-21, pp. S-105-S-106).
Gu, B., Yamori, K., Xu, S., & Tanaka, Y. (2010, March). Y. Pricing of Wireless Access Network Using 
Second-Price Auction Protocol. In Proceedings of 2010 IEICE General Conference (No.BS-3-11, pp. 
S-44-S-45).
Gu, B., Yamori, K., Xu, S., & Tanaka, Y. (2010, September). Pricing of Wireless Local Access Network 
by Considering Compensation for Collisions. In Proceedings of 2010 IEICE Communications Society 
Conference (No.BS-7-8, pp. S-59-S-60).
Gu, B., Yamori, K., Xu, S., & Tanaka, Y. (2011, March). Admission Control Algorithms Integrated with 
Pricing for Revenue Optimization in Wireless Local Access Networks. In Proceedings of 2011 IEICE 
General Conference (No.BS-4-4, pp. S-15-S-16).
Gu, B., Yamori, K., Xu, S., & Tanaka, Y. (2011, September). QoS Management and Load Balancing in 
Wireless LANs. In Proceedings of 2011 IEICE Communications Society Conference (No.BS-6-1, pp. 
S-30-S-31).

238
Application of Game Theory for Network Recovery After Large-Scale Disasters
﻿
Gu, B., Yamori, K., Xu, S., & Tanaka, Y. (2012, March) Exploiting User Mobility for Load Balancing 
and Improving QoS in Wireless LANs. In Proceedings of IEICE Technical Report on Communication 
Quality (No. CQ2012-, Vol. 112, No. 10, pp. 13-18).
Gu, B., Yamori, K., Xu, S., & Tanaka, Y. (2012, March). A Price-based Scheme for QoS Management 
and Load Balancing in Wireless LANs. In Proceedings of 2012 IEICE General Conference (No.BS-3-
16, pp. S31-S-32).
Gu, B., Yamori, K., Xu, S., & Tanaka, Y. (2012, September). Analysis of Combined Connection Admis-
sion Control and Pricing in Wireless LANs. In Proceedings of 2012 IEICE Communications Society 
Conference (No.BS-5-26, pp. S-30-S-31).
Gu, B., Yamori, K., Xu, S., & Tanaka, Y. (2013, March). Stackelberg Game Modelling of Wireless Ac-
cess Point Selection by Mobile users. In Proceedings of 2013 IEICE General Conference (No.BS-1-1, 
pp. S-1-S-2).
Gu, B., Zhang, C., Liu, Z., Yamori, K., Mizuno, O., & Tanaka, Y. (2016, September). Pricing and Ser-
vice Differentiation in OpenFlow and SDN. In Proceedings of 2016 IEICE Communications Society 
Conference (No.BS-5-19, pp. S-88-S-89).
Gu, B., Zhang, C., Liu, Z., Yamori, K., & Tanaka, Y. (2015, September). Price-Based Access Probability 
Control for Slotted-Aloha Random Access MAC Protocols. In Proceedings of 2015 IEICE Communica-
tions Society Conference (No.BS-6-26, pp. S-65-S-66).
Gu, B., Zhang, C., Liu, Z., Yamori, K., & Tanaka, Y. (2016, March). Intelligent Bandwidth Consumption 
Scheduler Considering the Connectivity of Heterogeneous Wireless Networks and Users’ Preferences. 
In Proceedings of 2016 IEICE General Conference (No.BS-3-35, pp.S-78-S-79).
Gu, B., Zhang, C., Yamori, K., Liu, S., & Tanaka, Y. (2015, January). Time-Dependent Pricing for 
Mitigating Fluctuation of Data Traffic Demand. In Proceedings of IEICE Technical Report on Com-
munication Quality (No. CQ2014-91, Vol. 114, No. 404, pp. 31-34).
Gu, B., Zhang, C., Yamori, K., Liu, S., & Tanaka, Y. (2015, March). Effect of Time-Dependent Pricing 
on the Congestion Management Practices of ISPs. In Proceedings of 2015 IEICE General Conference 
(No.BS-3-54, pp. S-110-S-111).
Gu, B., Zhang, C., Yamori, K., & Tanaka, Y. (2014, March). Integration of Discounting Service with 
Admission Control for Flattening out Peak-Time Usage. In Proceedings of 2014 IEICE General Confer-
ence (No.BS-1-62, pp. S-115-S-116).
Gu, B., Zhang, C., Yamori, K., & Tanaka, Y. (2014, September). Incentive Engineering in Wireless 
Random Access Networks. In Proceedings of 2014 IEICE Communications Society Conference (No.
BS-6-9, pp. S-52-S-53).
Huo, Y., Yang, F., Brost, V., & Gu, B. (2013, June). LDR Image to DHR Image Mapping with Over-
exposure Preprocessing. IEICE Transactions on Fundamentals of Electronics, Communications and 
Computer Science, E96-A(6), 1185–1194. doi:10.1587/transfun.E96.A.1185

239
Application of Game Theory for Network Recovery After Large-Scale Disasters
﻿
Li, X., Gu, B., Yamori, K., & Tanaka, Y. (2014, March). Pricing and Revenue Management in Cloud 
Computing. In Proceedings of 2014 IEICE General Conference (No.BS-1-64, pp. S-119-S-120).
Li, X., Gu, B., Zhang, C., Yamori, K., & Tanaka, Y. (2014, September). Price Competition in a Duopoly 
IaaS Cloud Market. In Proceedings of 16th Asia-Pacific Network Operations and Management Sympo-
sium (pp. 17-19). doi:10.1109/APNOMS.2014.6996552
Li, X., Gu, B., Zhang, C., Yamori, K., & Tanaka, Y. (2014, September). Revenue Management in IaaS 
Cloud Computing with Reserved Pricing Scheme. In Proceedings of 2014 IEICE Communications So-
ciety Conference (No.BS-6-24, pp. S-82-S-83).
Li, X., Gu, B., Zhang, C., Yamori, K., & Tanaka, Y. (2015, March). Price and Time Guarantee for Cloud 
Service Delivery. In Proceedings of 2015 IEICE General Conference (No.BS-3-41, pp. S-86-S-87).
Li, X., Gu, B., Zhang, C., Yamori, K., & Tanaka, Y. (2015, July). Optimal Pricing for Revenue Maximi-
zation in Duopoly Cloud Computing (Poster Presentation). In Proceedings of IEICE Technical Report 
on Communication Quality (No. CQ2015-24, Vol. 115, No. 130, pp. 25-28).
Li, X., Gu, B., Zhang, C., Yamori, K., & Tanaka, Y. (2015, September). Pricing for Revenue Maximization 
in a Monopoly Cloud Market with Delay Sensitive Users. In Proceedings of 2015 IEICE Communica-
tions Society Conference (No.BS-6-13, pp. S-40-S-41).
Li, X., Gu, B., Zhang, C., Yamori, K., & Tanaka, Y. (2016, March). Optimal Pricing Strategy for Service 
Provisioning in the Monopoly Cloud Context with Heterogeneous Users. In Proceedings of 2016 IEICE 
General Conference (No.BS-3-16, pp. S-42-S-43).
Li, X., Gu, B., Zhang, C., Yamori, K., & Tanaka, Y. (2016, September). Joint Pricing and Load Balancing 
for Distributed Cloud Data Centres. In Proceedings of 2016 IEICE Communications Society Conference 
(No.BS-5-22, pp. S-94-S-95).
Liu, Z., Dong, M., Gu, B., Zhang, C., Ji, Y., & Tanaka, Y. (2015, August). Inter-Domain Popularity-aware 
Video Caching in Future Internet Architectures. In Proceedings of 11th EAI International Conference 
on Heterogeneous Networking for Quality, Reliability, Security and Robustness. doi:10.4108/eai.19-8-
2015.2260888
Liu, Z., Dong, M., Gu, B., Zhang, C., Ji, Y., & Tanaka, Y. (2016, February). Fast-start Video Delivery 
in Future Internet Architectures with Intra-domain Caching. ACM/Springer. Mobile Networks and Ap-
plications.
Liu, Z., Dong, M., Gu, B., Zhang, C., Ji, Y., & Tanaka, Y. (2016, October). Impact of Item Popularity 
and Chunk Popularity in CCN Caching Management. In Proceedings of 18th Asia-Pacific Network 
Operations and Management Symposium (pp. 1-6). doi:10.1109/APNOMS.2016.7737213
Liu, Z., Gu, B., Zhang, C., Ji, Y., & Tanaka, Y. (2016, March). Intra-Domain Video Caching in Content 
Centric Network with Normalized Popularity. In Proceedings of 2016 IEICE General Conference (No.
BS-3-4, pp. S-19-S-20).

240
Application of Game Theory for Network Recovery After Large-Scale Disasters
﻿
Liu, Z., Gu, B., Zhang, C., Wang, X., Ji, Y., & Tanaka, Y. (2015, September). Pricing in Pay-per-View 
Video System for Content Provider Profit Maximization. In Proceedings of 2015 IEICE Communica-
tions Society Conference (No.BS-6-4, pp. S-23-S-24).
Liu, Z., Gu, B., Zhog, L., Ji, Y., & Tanaka, Y. (2015, March). Multi-path Transmission for Picocell Edge 
Users in LTE-Advanced Heterogeneous Networks. In Proceedings of 2015 IEICE General Conference 
(No.BS-3-1, pp. S-10-S-11).
Liu, Z., Wang, X., Gu, B., Zhang, C., Ji, Y., & Tanaka, Y. (2016, September). Popularity-aware Caching 
in Content Centric Network Considering Video Drop Ratio. In Proceedings of 2016 IEICE Communica-
tions Society Conference (No.BS-5-16, pp. S-82-S-83).
Liu, Z., Zhang, C., Dong, M., Gu, B., Ji, Y. & Tanaka, Y. (2016, November). Markov-Decision-Process-
Assisted Consumer Scheduling in a Networked Smart Grid. IEEE Access. PP(99), 1-11.
Wang, D., Wang, X., & Gu, B. (2014, January). nterference Coordination Mechanisms for Device-to-
Device Multicast Uplink Underlaying Cellular Networks. IEICE Transactions on Communications, 
E97-B(01), 56–65. doi:10.1587/transcom.E97.B.56
Wang, H., Liu, S., Jiang, L., Liu, P., & Gu, B. (2017, January). Building a Policy Simulation Platform 
for Future Smart Grid in China. In Proceedings of 14th Annual IEEE Consumer Communications. 
Networking Conference.
Wang, Y., Gu, B., Liu, S., Liu, P., & Zhong, X. (2015, May). Stackelberg Game Modeling of Pricing for 
Mobile Virtual Network Operators. In Proceedings of 8th International Conference on Mobile Multimedia 
Communications (pp.105-109). doi:10.4108/icst.mobimedia.2015.259090
Wang, Y., Gu, B., Liu, S., Liu, P., & Zhong, X. (2015, November). Stackelberg Game Modeling of Pric-
ing for Mobile Virtual Network Operators. EAI Endorsed Transactions on Future Intelligent Educational 
Environments, 15(4), e1. doi:10.4108/fiee.1.2.e1
Werda, W., Gu, B., Yamori, K., & Tanaka, Y. (2015, March). Setting a Dynamic Pricing Strategy from 
User’s Viewpoint in Heterogeneous Networks. In Proceedings of 2015 IEICE General Conference (No.
BS-3-39, pp. S-82-S-83).
Werda, W., Gu, B., Yamori, K., & Tanaka, Y. (2015, September). Pricing Strategy in Macro-Femoto 
Heterogeneous Network. In Proceedings of 2015 IEICE Communications Society Conference (No.BS-
6-40, pp. S-92-S-93).
Werda, W., Gu, B., Yamori, K., & Tanaka, Y. (2016, January/February). Financial Benefit Analysis of 
Macro-Femto Network Structures Based on TCO Approach. In Proceedings of 18th International Con-
ference on Advanced Communication Technology (pp.). doi:10.1109/ICACT.2016.7423579
Werda, W., Gu, B., Yamori, K., & Tanaka, Y. (2016, October). Pricing and Revenue Optimization Strat-
egy in Macro-Femto Heterogeneous Networks. In Proceedings of 18th Asia-Pacific Network Operations 
and Management Symposium (pp. 1-6). doi:10.1109/APNOMS.2016.7737195

241
Application of Game Theory for Network Recovery After Large-Scale Disasters
﻿
Wu, L., Kastner, R., Gu, B., & Yu, D. (2013, April). Design of a Reconfigurable Acoustic Modem for 
Underwater Sensor Networks. IEICE Transactions on Fundamentals of Electronics, Communications 
and Computer Science, E96-A(4), 821–823. doi:10.1587/transfun.E96.A.821
Yu, B., Gu, B., Yamori, K., & Tanaka, Y. (2013, March). Relationship between User Mobility and 
Influential Factors in Wireless Data Communication Services. In Proceedings of 2013 IEICE General 
Conference (No.BS-1-41, pp. S-80-S-81).
Yu, B., Gu, B., Yamori, K., & Tanaka, Y. (2013, July). Modelling of Access Point Selection Based on 
Wireless QoS Demand. In Proceedings of 28th International Technical Conference on Circuits/Systems, 
Computers and Communications.
Yu, B., Gu, B., Yamori, K., & Tanaka, Y. (2013, September). Modelling of User’s Movement Decision 
Based on QoS Demand in Wireless Networks. In Proceedings of 2013 IEICE Communications Society 
Conference (No.BS-7-20, pp. S-71-S-72).
Yu, B., Gu, B., Yamori, K., & Tanaka, Y. (2014, March). A Multiobjective Approach for Improving 
Association Control in Wireless LANs. In Proceedings of 2014 IEICE General Conference, (No.BS-1-
31, pp. S-60-S-61).
Yu, B., Gu, B., Yamori, K., & Tanaka, Y. (2014, March). A Multiobjective Approach for Improving 
Association Control in Wireless LANs. In Proceedings of IEICE Technical Report on Communication 
Quality (No. CQ2013-106, Vol. 113, No. 471, pp. 101-106).
Zhang, C., Gu, B., Liu, Z., Yamori, K., & Tanaka, Y. (2015, March). Learning Automaton Based Algo-
rithm for Time-Dependent Pricing under Oligopoly Network Service Providers Market. In Proceedings 
of 2015 IEICE General Conference (No.BS-3-56, pp. S-114-S-115).
Zhang, C., Gu, B., Liu, Z., Yamori, K., & Tanaka, Y. (2015, August). Oligopoly Competition in Time-
Dependent Pricing for Improving Revenue of Network Service Providers Considering Different QoS 
Functions. In Proceedings of 17th Asia-Pacific Network Operations and Management Symposium (pp. 
273-278). doi:10.1109/APNOMS.2015.7275439
Zhang, C., Gu, B., Liu, Z., Yamori, K., & Tanaka, Y. (2015, September). Learning Automaton Based 
Algorithm for Time-Dependent Pricing under Oligopoly Network Service Providers Market. In Proceed-
ings of 2015 IEICE Communications Society Conference (No.BS-6-38, pp. S-88-S-89).
Zhang, C., Gu, B., Liu, Z., Yamori, K., & Tanaka, Y. (2016, March). Economic Analysis of Mobile Data 
Offloading Cooperation Market. In Proceedings of 2016 IEICE General Conference (No.BS-3-33, pp. 
S-74-S-75).
Zhang, C., Gu, B., Liu, Z., Yamori, K., & Tanaka, Y. (2016, September). Pricing for Monopolistic In-
ternet of Things Service Provider. In Proceedings of 2016 IEICE Communications Society Conference 
(No.BS-5-7, pp. S-64-S-65).
Zhang, C., Gu, B., Liu, Z., Yamori, K., & Tanaka, Y. (2016, October). A Reinforcement Learning Ap-
proach for Cost- and Energy-Aware Mobile Data Offloading. In Proceedings of 18th Asia-Pacific Network 
Operations and Management Symposium (pp. 1-6). doi:10.1109/APNOMS.2016.7737203

242
Application of Game Theory for Network Recovery After Large-Scale Disasters
﻿
Zhang, C., Gu, B., Liu, Z., Yamori, K., & Tanaka, Y. (2017, January). A Stackelberg Game Based Analysis 
for Interactions among Internet Service Provider, Content Provider, and Advertisers. In Proceedings of 
14th Annual IEEE Consumer Communications. Networking Conference.
Zhang, C., Gu, B., Yamori, K., & Tanaka, Y. (2014, March). Pricing Content Provider Considering Adver-
tisers’ Participation. In Proceedings of 2014 IEICE General Conference (No.BS-1-66, pp. S-123-S-124).
Zhang, C., Gu, B., Yamori, K., Xu, S., & Tanaka, Y. (2013, September). Time-Dependent Pricing for 
Revenue Maximization of Network Service Providers Considering Users Preference. In Proceedings of 
15th Asia-Pacific Network Operations and Management Symposium (pp. 1-6).
Zhang, C., Gu, B., Yamori, K., Xu, S., & Tanaka, Y. (2013, September). Price Competition between 
Content Provider and Internet Service Provider. In Proceedings of 2013 IEICE Communications Society 
Conference (No.BS-7-42, pp. S-113-S-114).
Zhang, C., Gu, B., Yamori, K., Xu, S., & Tanaka, Y. (2013, December). Duopoly competition in time-
dependent pricing for improving revenue of network service providers. IEICE Transactions on Com-
munications, E96-B(12), 2964–2975. doi:10.1587/transcom.E96.B.2964
Zhang, C., Gu, B., Yamori, K., Xu, S., & Tanaka, Y. (2014, September). Price Competition between 
Content Provider and Internet Service Provider. In Proceedings of 2014 IEICE Communications Society 
Conference (No.BS-6-4, pp. S-42-S-43).
Zhang, C., Gu, B., Yamori, K., Xu, S., & Tanaka, Y. (2015, May). A Novel Stackelberg-Bertrand Game 
Model for Pricing Content Provider. In Proceedings of 8th International Conference on Mobile Multi-
media Communications (pp. 128-132). doi:10.4108/icst.mobimedia.2015.259082
Zhang, C., Gu, B., Yamori, K., Xu, S., & Tanaka, Y. (2015, November). A Novel Stackelberg-Bertrand 
Game Model for Pricing Content Provider. EAI Endorsed Transactions on Collaborative Computing, 
15(4), e2.
Zhong, X., Liu, S., Gu, B., Zhou, Y., & Liu, P. (2015, June). PMV Based Power-Saving Control Method 
for Air-Conditioning System”, In Proceedings of 4th International Conference on Energy and Environ-
mental Protection.
Zhou, P., Gu, B., Yamori, K., & Tanaka, Y. (2015, September). User Oriented Demand-Side Manage-
ment in Smart Grid. In Proceedings of 2015 IEICE Communications Society Conference (No.BS-6-23, 
pp. S-59-S-60).
Zhou, Z., Dong, M., Chang, Z., & Gu, B. (2015, November). Combined Centralized and Distributed 
Resource Allocation for Green D2D Communications. In Proceedings of 4th IEEE/CIC International 
Conference on Communications in China. doi:10.1109/ICCChina.2015.7448680
Zhou, Z., Dong, M., Ota, K., Gu, B., & Sato, T. (2014, November). Stackelberg-Game based Distributed 
Energy-Aware Resource Allocation in Device-to-Device Communications. In Proceedings of 14th IEEE 
International Conference on Communication Systems (pp. 11-15). doi:10.1109/ICCS.2014.7024756

243
Copyright © 2018, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.
Chapter  9
DOI: 10.4018/978-1-5225-2575-2.ch009
ABSTRACT
The importance of effective and timely communication is critical in disaster management life cycle. With 
the proliferation of communication and web technologies, the challenge has now shifted from the avail-
ability of information to the efficient handling of the sheer amount of information available online. This 
has attracted researchers and practitioners to find ways which can facilitate individuals and organiza-
tions in their decision making while dealing with large amounts of online data. This chapter presents (1) 
the evolution of web technologies from Web 1.0 to Web 3.0, (2) the overview of communications tasks 
involved in disaster management, and (3) the literature survey on the pros and cons of Web 2.0 and Web 
3.0 in disaster management. By comparing the role of Web 2.0 with Web 3.0, the chapter also attempts 
to explore how the communication tasks of disaster management could be improved using Web 3.0. It is 
anticipated that the findings of this chapter will assist the decision makers to use Web 3.0 as a strategic 
tool for effective communication in disaster management.
INTRODUCTION
Web technologies especially the Web 2.0 (the terms generally used interchangeably with social media) 
became an integral part of billions of peoples’ lives around the world. Web 2.0, as a mode of a commu-
nication, has become the preferred communication channel when it comes to communicating with ease, 
effectiveness and with low cost. Web 2.0 enable the end users to set up their own websites and blogs, post 
videos, and fill the web with user-generated content. People with little Hyper Text Mark-up Language 
(HTML) experience could set up a decent website through third-party software. Like the individuals’ 
use, the organizations have also realized the value of Web 2.0 for activities like marketing, promotion, 
and outreach. There is a growing number of organizations using these technologies for connecting with 
their customers and building online communities. Over the last few years, it has been witnessed that not 
Communication Process of 
Disaster Management:
Shift From Web 2.0 to Web 3.0
Ashir Ahmed
Swinburne University of Technology, Australia

244
Communication Process of Disaster Management
﻿
only commercial organizations are considering Web 2.0 as an important communication channel to reach 
out to their existing and potential customers, the organizations working in disaster management have 
also opted for Web 2.0 applications to reach the masses before, during and after the crisis. The review 
of recent literature on disasters such as Haiti (Gao, Barbier, Goolsby, & Zeng, 2011), Chile earthquake 
(Ahmed & Sargent, 2014; Alexander, 2014) proved the critical role that Web 2.0 played during these 
crises. There are several examples when large volumes of data (in the form of blogs, posts, and messages) 
were created by the individuals and organizations within few moments of disaster strikes.
Study of recent events suggests that though the large volumes of data created on Web 2.0 are valu-
able, the excess of the data could easily turn into data overloading where potential recipients struggle to 
extract meaningful information from available sources of incoming data. According to Schwarz (2012), 
it is highly likely that the massive stream of user generated content contains pieces of highly relevant 
information that is not known to its potential recipients. To deal with the massive influx of data on Web 
2.0, the agent-based mechanism (referred as Web 3.0) was introduced a few years ago. The aim of Web 
3.0 is to replace humans with software agents for better collecting, harvesting, distributing and analyz-
ing the data available online (Workman, 2016). There are several articles that describe the architecture, 
use and the value of Web 3.0 and its importance in effective decision making (Gretzel, 2015; Nayar, 
2015; Rudman & Bruwer, 2016). However, to the extent of our knowledge, there is not much literature 
available that compares Web 3.0 with Web 2.0, particularly for disaster management. This chapter offers 
a conceptual, non-empirical review of the work done by Ahmed & Sargent (2014) and employs it as a 
theoretical underpinning to evaluate the significance of Web 3.0 for various communication tasks of 
disaster management. A systematic review of literature is also conducted to support the findings of this 
study. It is anticipated that the findings presented in this chapter would extend the existing understanding 
on the use of Web 3.0 in disaster management.
The chapter is structured into four sections. Section one highlights the key characteristics and the 
overview of various web technologies such as the Web 1.0, Web 2.0 and Web 3.0. Based on the recent 
work by Ahmed & Sargent (2014), section 2 presents the overview of communication process involved 
in disaster management. Section three summarizes the process and key findings of the literature review 
related the limitations of Web 2.0 in disaster management. Finally, the chapter is concluded with the 
summary of the role of Web 2.0 and Web 3.0 and the recommendations to consider Web 3.0 as a strategic 
communication channel in disaster management along with the future research directions.
EVOLUTION OF WEB TECHNOLOGIES
The first web page http://info.cern.ch/hypertext/WWW/TheProject.html was developed by Tim Berners-
Lee and launched on August 6, 1991. It was dedicated to information on the World Wide Web (WWW) 
project and ran on a NeXT computer at the European organization for Nuclear Research, CERN. The 
value of a web page was soon realized as a tool by which businesses can send their information to their 
existing and potential customers via the internet. Soon after its inception, web pages become a popular 
avenue to host organizational information online. Initially, an expert (referred as ‘Webmaster’) was 
responsible for creating static websites and uploading information that can be viewed by the end users 
(Lafuente, 2016). It was only the Webmaster who could edit the contents of the web page to reflect any 
update. The end users were only able to visit and access the existing information on the web pages but 
were not able to edit them. Primarily, these static web pages offered one-way communication (from 

245
Communication Process of Disaster Management
﻿
Webmaster to the end-user) where organizations (via Webmaster) aimed to push as much information as 
possible toward the end user. The role of Webmaster (information creator) was replaced by a ‘Moderator’ 
(communication facilitator) in a new strand; called Web 2.0. Web 2.0 emerged in 2006 that aimed to 
leverage two-way communication (dialog) on the internet. This new paradigm (at that time) transformed 
the static web into a dynamic web where end-users not only access the contents but they can also create, 
share and respond to the contents (Hiremath & Kenchakkanavar, 2016). The implementation of Web 2.0 
in the form of a dynamic web changed the dynamics of online communication giving more power and 
control to the end users where they are content consumer and content producer at the same time. Some 
of the Web 2.0 applications types are mentioned in Table 1.
Building on the premises of Web 2.0 and social media, the new emerging trend in the web paradigm 
is Web 3.0 - also referred as Semantic Web. While the Web 3.0 technologies are difficult to define 
precisely, the outline of emerging applications has become clear over the past few years. The key idea 
behind the Web 3.0 is the extrapolation of data in which the:
Action zone will be changed from the front-office to the back-office in which computers become capable 
of analyzing all data on the web – contents, links, and transactions between people and computers: the 
“semantic web” generation, where’s machines are talking to machines (Tim Berners-Lee, 1999).
Some of the most relevant technology concepts that will enhance Web 3.0 paradigm are:
Location Based Contents
The Web 3.0 has the ability to receive and to deliver information (contents) based on location data or/
and user’s context (client system). User’s context evolves metadata description regarding contents use 
or user’s profile. Location based contents help the user to receive more precise and relevant informa-
tion based on the particular location and hence reduces the complexity of accessing the relevant piece 
of information from immeasurable volumes of data available on the internet through meaning-making 
(Clough, 2010).
Geo-Referencing
Geo-reference refers the ability to have adaptive delivery systems focused and activated by the effect 
of location definitions (slightly different from content by location objectives – as described above). 
Combining Global Positioning System (GPS) and digital compass technologies can provide a basic func-
tionality for locating someone holding a device and computing their orientation and provide customized 
information within that environment.
Table 1. Types of Web 2.0 Applications
Wiki
BlogPod
Content sharing
RSS
Collaboration
Video streaming
Mashups
Online Forums
Portals
Blogging
Online Chatting
Social Networking

246
Communication Process of Disaster Management
﻿
Applied Semantics
At the Web 3.0 paradigm, semantics are undoubtedly the logic support for all end-user aware-context 
and content by location information ability. Applied semantics at Web 3.0 backstage having a knowledge 
base about the meaning of web sources’ contents stored in a machine-processable and interpretable way 
(Guarino, 1995).
Enhanced Security
Enhanced web security through a unified identification system (already started by application reference 
login). Besides, some biotechnology authentication systems are ready to be integrated throughout hard-
ware developments. Such biometrics (or biometric authentication) refers to the identification of humans 
by their characteristics or traits that may contribute to making Web 3.0 more secure. Table 2 summarizes 
the key characteristics of the Web 1.0, Web 2.0 and Web 3.0.
Further to the characteristics of various web technologies presented in table above, the Figure 1 
presents the key applications of the Web 1.0, Web 2.0 and Web 3.0 and their common usage.
COMMUNICATION PROCESS OF DISASTER MANAGEMENT
According to Weichselgartner (2001),
Disaster management is interchangeably used with a term emergency management. It involves plans, 
structures, and arrangements established to engage the normal endeavors of governments, voluntary and 
private agencies in a comprehensive and coordinated way to respond to the whole spectrum of emergency 
needs. Such activities are carried out in an urgent manner when there is an onset of disaster occurrence.
Research in the field of disaster management stresses the importance of timely, reliable and ac-
cessible information. Though, it might be unlikely to entirely prevent disasters (especially the natural 
disaster), the effective communication could minimize the impacts of disasters. There have been few 
studies that investigate the types of communication occurred during disaster management and how they 
could be leveraged using various communication technologies. For instance, Ahmed & Sargent (2014) 
proposed a framework that identified four key participants involved in the communication process such 
as (i) Disaster management agencies, (ii) Business organizations, (iii) Government organizations and 
(iv) general communities. Ahmed & Sargent (2014) examined the needs why these participants interact 
with each other (referred as communication tasks). The communication needs suggested by Ahmed & 
Sargent (2014) include ‘Coordination and Collaboration’, ‘Alerts and Warnings’, ‘Collaboration and 
Situational Awareness’, ‘Communication’, ‘Education’, ‘Moral / Emotional Support’, ‘Information Dis-
semination’, ‘Issue Warnings’, ‘Queries and Feedback’, ‘Communication with the Rest of the World’ 
and examined how these communication tasks can be facilitated using the Web 2.0/social media. In this 
study, the communication tasks mentioned above are used to contextualize the review of the literature on 
the pros and cons of the Web 2.0 and Web 3.0. A four-stage approach (methodology) used to conduct a 
systematic literature review is described before presenting the key findings emerged from the synthesis 
of the relevant literature.

247
Communication Process of Disaster Management
﻿
METHODOLOGY
Further to the above discussion, a systematic review of the literature was conducted to have a good un-
derstanding of the role of the Web 2.0, the challenges associated with its usage and how these challenges 
could possibly be dealt with the use of the Web 3.0. A four stage model suggested by Sylvester, Tate & 
Johnstone (2013) was employed to conduct the review of the literature. The overview of the literature 
review process is depicted in Figure 2 before discussing the details of each stage in the following sections.
Stage One: The Searching Stage
The first stage was to find the relevant articles. The initial search terms were intentionally selected 
to include a broader spectrum of results by combining three key themes such as ‘Disaster management’, 
‘Web 2.0’ and ‘Web 3.0’. Below is a list of terms used interchangeably along the key themes as mentioned 
above. For disaster management, the following terms are used as search criteria:
Table 2. Key characteristics of Web 1.0, Web 2.0 and the Web 3.0
Web 1.0
Web 2.0
Web 3.0
Tim Berners Lee
Tim O’Reilly
Time Berners Lee
1996
2006
2015
The web
The social web
The semantic web
The hypertext/CGI web (the basics)
The community web (for people: apps / 
sites connecting them
The semantic web (for machines
Pushed web, text/graphics
Two-way-web pages, Wikis, video, 
podcasts, shading. Personal publishing
Avtar representation, interoperable profits, multi- 
user virtual environment, integrated games, all 
media flows in and out of the virtual web.
Read-only web
Read and write
Read, write and execute the web
Information sharing
Interaction
Immersion
Ecosystem
Participation
Understanding itself
Connect information
Connect people
Connect knowledge
Web 1.0 was all about static content, 
one-way publishing of content 
without any real interaction between 
readers or publishers or each other.
Web 2.0 is more about two-way 
communication through social networking, 
blogging, wikis, tagging, user generated 
content and video.
Web 3.0 is curiously undefined. AI 
and the web learning what you 
want and delivering you a personalized web 
experience.
Personal websites
Blogs
Semantic Blogs: SemiBlog, 
Haystack, Semiblog, Structured 
Blogging
Content Management Systems, 
Wikipedia
Wikis, Wikipedia
Semantic Wikis: Semantic MediaWiki, 
SemperWiki, Platypus, dbpedia, Rhizome
AltaVista, Google
Google personalized, DumpFind, Hakia
Semantic Search: SWSE, Swoogle, 
Intellidimension
Message boards
Community portals
Semantic Forums and community 
portals: SIOC, OpenLink DataSpaces
Buddy Lists, Address book
Online social networks
Semantic Social Networks: FOAF, 
PeopleAggregator

248
Communication Process of Disaster Management
﻿
Figure 1. The evolution of Web technologies
Figure 2. Overview of Literature Review Process

249
Communication Process of Disaster Management
﻿
‘Disaster management’, ‘Disaster communication’, ‘Preparedness’, ‘Prevention’, ‘Recovery’, ‘Emergency 
management’, ‘Emergency communication’, ‘Crisis management’, ‘Crisis communication’, ‘Hazards’ 
For the Web 2.0, the following terms are used as search criterion:
‘Social media’, ‘Social network’, ‘blogs’, ‘Web 2.0’, ‘Facebook’, ‘Twitter’, SNA, ‘Social networking sites’, 
For the Web 3.0, the following terms are used as search criterion:
‘Semantic web’, ‘Web 3.0’, ‘The third generation web’, 
The search was enabled through various electronic databases, such as ProQuest, Science Direct, 
scholarly articles (Google Scholar), organizational whitepapers and the relevant electronic journals. 
Since a small number of research articles available on the Web 3.0 in disaster management context, the 
reputational value of the articles was originally not taken into account during the selection stage. The 
search has enabled to locate 330 items in total.
Stage Two: The Mapping Stage
During this stage, the original selection was narrowed down by limiting articles published in scholarly 
journals and readings that had a similar running theme. The selection of articles included the following 
recurring themes: ‘Web 2.0’, ‘Disaster management’, ‘Limitations of Web 2.0’ and ‘Web 3.0 in disaster 
management’. This enabled to narrow down the search results to 41 articles.
Stage Three: The Appraisal Stage
An in-depth reading of the narrowed down selection enabled the author to develop the understanding about 
limitations of the Web 2.0, and to elaborate the potential of the Web 3.0 in disaster management context.
Stage Four: The Synthesis Stage
During this stage, the author compiled all annotations and generated the conclusions through integrating, 
modifying and generalizing the weaknesses of the Web 2.0 in disaster management. The findings of all 
four stages were recorded into a single flowing document. The key findings of the ‘synthesis stage’ are 
presented below.
APPLICATION OF WEB 2.0 IN DISASTER MANAGEMENT
Findings from the Literature
In this section, the past literature related to the use of the Web 2.0 technologies was examined. The ap-
plication domain set for this purpose was the ‘disaster management’. Use of the Web 2.0 technology 
by means of social media applications largely entered into disaster management scene in the year 2005, 

250
Communication Process of Disaster Management
﻿
in response to crisis event: Hurricane Katrina, which was landed in Southeast Louisiana on August 29, 
2005, displacing more than 500,000 families and flooding 80% in New Orleans (Sutton, Palen, & Shk-
lovski, 2008). Literature documented social media usage in emergencies suggest that the applications 
such as blogs and online forums are more popular among victims and general public (Heverin & Zach, 
2010; Palen, Hiltz, & Liu, 2007; T. Schultz, 2000; Shklovski, Burke, Kiesler, & Kraut, 2010; Sinnappan, 
Farrell, & Stewart, 2010; Valentini & Romenti, 2011). These studies stress that the Web 2.0 applications 
provide a perfect place for citizens to virtually connect with other members in the society to exchange 
information and to cope with their losses. Moreover, it has been found that the Web 2.0 technologies not 
only used by citizens to coordinate disaster relief efforts by way of providing donations such as cloths, 
toys, and other items, but also helping to find missing persons and offering housing for victims and 
sufferers (Ortiz & Ostertag, 2014). After Hurricane Katrina, research in disaster management domain 
continued to explore the use of the Web 2.0 tools to investigate the variety of other hazards. For instance, 
by analyzing large amounts of retweets in Egyptian uprising context, researchers concluded that the most 
frequently retweeted message tend to be those with broad appeals, such as high-level news reports and 
message of solidarity with the community. However, there are several shreds of evidence from various 
crisis when members of the community filter the messages such as tweets before they actually retweet 
them to the other (Starbird & Palen, 2012). This reflects the role of the Web 2.0 technologies to generate 
collective intelligence where distributed people can solve complex problems by sharing important fil-
tered information among other members. It also implies that the Web 2.0 technologies have the potential 
to facilitate the collection of both implicit and explicit knowledge in order to create a knowledge base 
which can then be used by citizens and organizations alike (Vieweg, Hughes, Starbird, & Palen, 2010).
While the advent of the Web 2.0 technologies has played an important role in providing organizations 
and individuals with useful information regarding a crisis, it has also posed a greater risk of spreading 
unauthorized information relating to a particular situation and potentially damaging the image of people 
and operational aspect of organizational activities without having the consent to do so. For instance, 
Simon, Goldberg, Aharonson-Daniel, Leykin, and Adini (2014) report that during Westgate Mall crisis 
in Kenya, citizens shared sensitive information regarding the location of armed forces via Twitter ac-
counts with no control and with minimal official monitoring and censorship. Similarly, the overreliance 
of Web 2.0 technologies on other technologies such as electricity and the internet is considered a major 
concern with the widespread use of the Web 2.0 technologies in the crisis situations when the working 
conditions are not normal and access to the other technological infrastructure is inadequate. Depending 
on crisis circumstances, physical damage to or overloading of the communication network may prevent 
the use of the Web 2.0 applications. Kaigo (2012) noted that the access to several the Web 2.0 sites was 
severely disrupted during Great East Japan Earthquake because of the serious power outage for more 
than 48 hours whereas most of the mobile devices had battery lives lasting twelve hours or less depend-
ing on their use. The overreliance on the Web 2.0 as a sole source of information gathering could be 
problematic under prolonged power outages. Further to the above discussion, the review of the literature 
suggests that disasters or emergency situations usually amplify the levels of uncertainty among the public, 
which prompts them to engage in information seeking. Information seeking is a primary driver of the 
Web 2.0 usage during routine times and during disasters alike (Palen, Vieweg, & Anderson, 2010; Ra-
dianti, Hiltz, & Labaka, 2016). Research further indicates that, although the Web 2.0 allow for feedback 
and relationship building, oftentimes when disasters occur individuals might aim to search and collect 
information, not to discuss it or simply re-tweeting second-hand information (David, Ong, & Legara, 

251
Communication Process of Disaster Management
﻿
2016; Hughes & Palen, 2009; Takahashi, Tandoc, & Carmichael, 2015). Hughes & Palen (2009) study 
regarding Twitter use during mass convergence and emergency events found fewer person-specific 
reply tweets including greater inclusion of URLs in the hurricane and convention tweets as compared 
to the general tweets. This indicates that there is a risk of information overload, unreliable coverage of 
facts, second-hand content shared by the public when using some the Web 2.0 applications, as concerns 
have been raised about their reliability, accuracy, and authority. Aligned with the above line of argu-
ments, the open nature of the Web 2.0 presents significant challenges in terms of controlling intellectual 
property of the shared information. According to Yates & Paquetta (2011), the public may fear that the 
information available on the Web 2.0 could be misused through unauthorized access to their personal 
information during disasters. Liu, Jin, & Austin (2013) mentioned that most of the participants in their 
study expressed the fear of having comments taken out of context and dispersed in the Web 2.0 sphere; 
a finding attributed to privacy concerns (Liu et al., 2013). Due to privacy concerns, some users may be 
hesitant of using the Web 2.0 technologies and may not be interested in using these applications at all. 
Mendoza, Poblete, & Castillo (2010) explored the activity related to the 2010 earthquake in Chile and 
characterize popular Web 2.0 tool, that is, Twitter as one of the main communication tool among public 
about the disaster but in some instances there were reports of people questioning the accuracy and reli-
ability of the information item they are reading. This would provide signals for many users to determine 
how much to trust a certain information posted and shared on Web 2.0 during disasters (Mendoza et 
al., 2010). Similarly, Chew & Eysenbach (2010) explored 5,395 tweets which they randomly selected 
and analyzed found that majority of contents of tweets about disasters actually not original contents, 
but rather come from traditional media such as newspapers and other electronic media. Some informa-
tion produced by the public via Web 2.0 tools may lack credibility because it is unreliable, outdated or 
an inappropriate format. For instance, de Albuquerque, Herfort, Brebbing, & Zipf (2015) suggest that 
messages for improving situational awareness depend on more on the individuals’ uploaded photos than 
on its accompanying text when extracting information for improving situation awareness in crisis. The 
sheer abundance of information (especially the textual information) highlights a problem about structur-
ing, storage, and dissemination of vital and more importantly reliable information for decision making. 
Based on the above discussion, the key limitations of Web 2.0 are summarized as follows:
LIMITATIONS OF WEB 2.0
Inaccurate Information
Instances of inaccurate and false information may be an inherent problem, given the nature of the Web 
2.0 platforms and the number of people disseminating information. Studies have found that outdated, 
inaccurate, or false information has been disseminated via Web 2.0 forums during disasters. In some 
cases, the location of the hazard or threat was inaccurately reported (Oh, Agrawal, & Rao, 2013; Sweet-
ser, 2010). In the case of the March 2011 Japanese earthquake and tsunami, tweets for assistance were 
‘retweeted’ 27 times after the victims had been rescued (Acar & Muraki, 2011; Doan, Vo, & Collier, 
2011). Information that is false, inaccurate, or outdated could complicate situational awareness of an 
incident and consequently hinder or slow down the response efforts. Inaccurate information could also 
jeopardize the safety of first responders and the community. If the disaster management agencies were 

252
Communication Process of Disaster Management
﻿
to adopt Web 2.0 as a strategic tool for disaster response, it might also consider doing so within a com-
prehensive initiative that would include adopting methods and protocols that help officials interpret 
incoming information and help to eliminate or reduce misinformation.
Information Overloading
Currently, there are countless Web 2.0 outlets hosting a huge volume of information. Though in some 
cases, it is good to have more information, it could potentially create issues for the end users in order 
to find relevant information from tones of data available online (Bawden & Robinson, 2009). A broad 
range of Web 2.0 applications also creates the challenge for the organizations to prioritize their Web 2.0 
strategy to effectively reach out to the majority of their audiences (Fischer & Reuber, 2011).
Malicious Use of the Technology
Another concern relating to the use of Web 2.0 during disasters is the probability of intentional misuse of 
the technology when some individuals or organizations may provide inaccurate information to confuse, 
disrupt, or otherwise thwart disaster response efforts. Malicious use of Web 2.0 during the crisis could 
range from mischievous pranks by issuing calls for assistance to an area, or notifying officials of a false 
hazard or threat that requires a response to even facilitate the act of terrorism (Gupta, Lamba, Kumara-
guru, & Joshi, 2013). When using Web 2.0 applications for situational awareness and response efforts, 
officials, and first responders should be careful that the online information could be fake or misleading. 
Recently, there have been a number of instances where governments and the law enforcement agencies 
elected the use of civil or criminal sanctions against individuals and organizations that purposely pollute 
Web 2.0 with misleading information (Gupta et al., 2013; Sánchez Abril, Levin, & Del Riego, 2012).
Technological Limitations
Technological limitation in term of the dependability on other technologies such as electricity and ac-
cess to the internet is one of the key bottlenecks that hinders the use of Web 2.0 during crisis situations 
(Kaigo, 2012). In the case of Hurricane Irene, many residents experienced power outages lasting 48 
hours or longer after the crisis struck. Generally, the smartphones and tablets have battery lives lasting 
twelve hours or less depending on their use. In the case of the shortage of electric supply (a very com-
mon situation in most crisis), it becomes difficult to stay online as the interruption to the Internet access 
either caused by a disaster or cyberattack could disrupt the use of Web 2.0 applications. In short, Web 
2.0 has improved some aspects of emergency and disaster response, the overreliance on this technology 
as the sole source of information could be problematic under prolonged power outages and the inacces-
sibility of the Internet.
Difference in Personal Preferences
Generally, people enjoy many different communication platforms to interact with other till the point 
when it gets difficult to manage their contacts across various Web 2.0 outlets (Berthon, Pitt, Plangger, 
& Shapiro, 2012). A broad range of applications available at Web 2.0 sphere gives more choices to the 

253
Communication Process of Disaster Management
﻿
people to pick a particular application as their preferred mode of online communication. A variety of 
applications and lack of interoperateability poses serious challenges for disaster management agencies 
to manage all the applications with their limited resources (Latonero & Shklovski, 2011).
Administrative Cost Considerations
The process to calculate the total cost of ownership (TCO) required to launch and maintain Web 2.0 
based programs is complex. The number of personnel required to monitor multiple Web 2.0 avenues, 
verifying the accuracy of incoming information, responding to the personalized queries and questions, 
and redirecting the incoming messages in the right direction is also uncertain (Houston et al., 2015). 
In addition, the disaster management agencies may experience a large volume of queries and questions 
flowing in from the general public during a disaster. Responding to each message in a timely manner 
could be time-consuming and require more resources such as the personnel responding to the incoming 
questions (F. Schultz, Utz, & Göritz, 2011).
Privacy Issues
Privacy concerns exist around the collection, retention, and data mining of personal information by the 
disaster management agencies with respect to their use of Web 2.0. Specifically, the use of status alerts 
and the creation of personal pages to establish situational awareness may raise privacy concerns for some 
people. Moreover, in the case of feedback and polling, people have concerns on how, and for how long, 
information would be compiled, stored, and used (Kavanaugh et al., 2012). For example, would the law 
enforcement agencies compile records after a manmade disaster such as a terrorist attack to help investi-
gate certain individuals? In the USA, the E-Government Act of 2002 mandates that Federal agencies to 
assess the privacy impact of any substantially revised or new Information Technology System. In March 
2011, the Department of Homeland Security (DHS) issued a Privacy Impact Assessment (PIA) for the 
Use of Unidirectional Social Media Applications Communications and Outreach. The DHS PIA on the 
Use of Unidirectional Social Media Applications does not cover users sending content to the Depart-
ment, but describes the Personally Identifiable Information (PII) and the limited circumstances under 
which DHS will have access to PII, how it will use the PII? what PII is retained and shared? and how 
individuals can gain access to their PII? In 2010, DHS published a PIA on the Use of Social Networking 
Interactions and Applications (Communications /Outreach/Public Dialogue). Neither PIA covers other 
online activities such as monitoring initiatives, law enforcement and intelligence activities, and other 
similar operations (Bertot, Jaeger, & Hansen, 2012).
APPLICATION OF WEB 3.0 IN DISASTER MANAGEMENT:
Findings from the Literature
Web 3.0 is also known as the Semantic Web that not just display information but also understands the 
data in a meaningful way (Rudman & Bruwer, 2016). According to Rudman & Bruwer (2016), Web 3.0 
allows intelligence, personalization, interoperability, and virtualization. Once integrated into disaster 
management domain, Web 3.0’s success will rely on its ability to optimize data integration. Intelligent 

254
Communication Process of Disaster Management
﻿
search engines embedded in Web 3.0 will only find the relevant matched crisis or disaster-related keyword 
in the search versus irrelevant searches. In this way, Web 3.0 technology offers more opportunities for 
citizen reporting, community oriented computing, and collective intelligence and distributed problem 
solving and hence has a potential to reshape the perception about how members of the public could 
participate in emergency management. From an organizational point of view, a recent study conducted 
by Sarcevic et al. (2012), found that emergency management agencies broadcast messages in the hope 
that the message would be heard by a large number of people. Sarcevic et al. (2012) analyzed Twitter 
communications of 110 emergency medical response teams and organizations in the immediate aftermath 
of January 12, 2010, Haiti earthquake. In their analysis, they found that these agencies were anxious to 
assist and wanted to coordinate their rescue efforts with other agencies and the general public. However, 
the Twitter did not automatically provide necessary connections for proper coordination required by the 
agencies (Sarcevic et al., 2012). Furthermore, the study conducted by Plotnick & Hiltz Starr (2016) found 
that information overload is one of the most significant barriers to effective use of Web 2.0 technolo-
gies for communication purposes by county level by the US emergency managers, which in turn points 
the need for an alternative platform that filters large information sets which in turn facilitates different 
styles of engagement by different agency actors. Web 3.0 technologies have potential to understand the 
disaster management data and categorized these data sets in a hierarchical manner to link the data with 
similar characteristics, and retrieve crisis specific data effectively and efficiently for agencies, business 
organizations and general public (Rudman & Bruwer, 2016).
When emergency management agencies issue warnings about an upcoming crisis, their objective 
is to alert the public of an impending hazard, its likelihood, nature, and consequences, and to outline 
a protective action. Traditionally, this process entailed one to many communication methods, where 
information was issued by a single information source to many people using various communication 
tools and it will re-broadcast to multiple recipients by original receivers. However, in most of the cases, 
the contents of the original message need to be contextualized according to the potential recipients of 
the message. Web 3.0 offers features to personalize a piece of information according to the ‘Location’, 
‘Time’ and ‘Context’ of the recipient. The applications of these features enable the information provid-
ers to make their communication more effective and help them to get the expected outcome from their 
communication (Rudman & Bruwer, 2016).
By combining the human intelligence in the crowd and automatic approaches for enhancing the situ-
ational picture with Linked Open Data (LOD), Schwarz (2012) proposed a Web 3.0 process for more 
efficient information handling and better decision making in disaster management. In their proposed Web 
3.0 process (as shown in Figure 3 below), Schwarz (2012) identified three key steps such as ‘Informa-
tion Collection’, ‘Information Classification’ and ‘Information Enrichment’ and are described below:
Information Collection
In this step, information collected through two key sources (a) the ‘first-hand’ information from citizens 
witnessing an incident and (b) the ‘second-hand’ information collected and shared using various social 
media platforms. These two sources supposed to create a valuable information resource for disaster man-
agement. Channeling and collecting this stream of information was supposed to be done via specialized 
mobile applications and Web 2.0 platforms. Schwarz (2012) developed an application called ‘Incident 
Reporter’ that can be used by the citizens to send and share disaster-related information including images, 
audio, and textual description, that allow the submission as clearly related information objects in contrast 

255
Communication Process of Disaster Management
﻿
to existing social media platforms. Because of the ‘information collection’ process, information would 
be collected that could possibly be unstructured, unsorted and even redundant. Although this informa-
tion may not be in the right form to be used for decision making, it certainly provides a repository of 
relevant information that could further be processed and be used in decision making. Information from 
both sources would be collected and saved in a central storage, called, ‘Information Cockpit’.
Information Classification
Once the required information is collected in ‘Information Cockpit’ as a result of ‘Information Collection’ 
step (described above), the aim of ‘Information Classification’ step is to segregate the relevant informa-
tion from irrelevant information. The goal of this step is to reduce the incoming flood of information 
to a set of reports that is relevant to the information need of the decision maker using automatic and 
crowd-based classification. Before providing the information objects to a crowd for filtering, they are 
pre-classified in the automatic pre-classification step to simplify and speed up the classification process. 
In this case Linked Open Data was used. According to Schwarz (2012), the text information obtained 
from social networks and human observers is usually very short and may contain noise such a typing er-
rors, abbreviations and colloquial language. This makes it hard to classify the information automatically.
For instance, the decision maker may ask a question, ‘is there a fire in the city?’. In this scenario, 
the question may implicitly refer to Central Business District (CBD) that implicitly refers to Melbourne 
city, that is not explicitly mentioned and asked in the question. By looking at the geographical location 
of the decision maker asking the question about the fire in the city, the software agent would annotate 
the string ‘city’ with ‘CBD’ and with ‘Melbourne’. This augmentation process supported by a software 
agent would classify all the information related to the ‘fire in Melbourne’.
Information Enrichment
In this step, some other relevant information from Linked Open Datasets would be amalgamated along 
with the results of information classification step (as mentioned above). Keeping the same example (‘is 
there a fire in the city?’) into the considering, the results from Information classification step such as (‘is 
there a fire in the city?’, ‘is there is a fire in the CBD?’ and ‘is there a fire in the Melbourne?’) would 
be enriched with other relevant information such as the key building in the Melbourne, key roads, key 
events in the Melbourne and the impact of fire in the city on these sets of entities. The software agents 
use to classify and enrich the information on a particular context would provide more specific, relevant, 
timely and personalized information through the extension and explanation of the incident’s context that 
could make a huge impact on the decision-making process during disasters such as to plan response and 
rescue activities.
ROLE OF WEB 2.0 VS ROLE OF WEB 3.0
Coordination and Collaboration
One of the key obstacles of employing Web 2.0 as a strategic communication tool for coordination and 
collaboration is the administrative cost associated with the management of social media outlets. The 

256
Communication Process of Disaster Management
﻿
number of personnel required to monitor multiple Web 2.0 channels, verify the accuracy of incoming 
information, and respond to and redirect incoming messages could go beyond the resources available to 
disaster management agencies. The situation gets worse due to the incompatibility among various Web 
2.0 applications.
Web 3.0 promises to save significant resources required to manually search, select and analyze online 
information. The software agents replacing humans not only automate the process of extracting relevant 
information from large volumes of online data but also facilitate the personalization dissemination of 
information to the potential recipients.
Education
Educating people, equipping them with the relevant information and developing more resilient com-
munities can enhance their capacity to better deal with disasters. With the advent of communication 
technologies especially Web 2.0; we have seen people helping each other for disaster preparation and 
education trough crowdsourcing. Though educational information may be available online not many 
people actually use that information effectively and hence failed to take precautionary steps before the 
upcoming disaster. In general, the following are the four key reasons why people do not use educational 
material available on Web 2.0:
Figure 3. Web 3.0 process for Disaster Management

257
Communication Process of Disaster Management
﻿
1. 	
Time (T): Before the disaster, some people may think they would be able to prepare themselves at 
the ‘right time’ and hence ignore the relevant information in the pre-disaster phase. However, they 
might struggle to find enough time to find relevant information from a large amount of information 
presented on Web 2.0 when they need the information.
2. 	
Location (L): People might find it difficult to relate the information available on Web 2.0 because 
of the geographic differences and hence unable to use it effectively as a tool to better prepare them 
for an upcoming disaster.
3. 	
Context (C): Generally, there is a large amount of disaster information available on Web 2.0, 
however, it may lack in presenting the right context and enough background information required 
for people to act properly. People may find it difficult to draw the right meaning from ‘piece of 
information’ such as a tweet or Facebook post.
4. 	
Lack of Personalization (P): One of the characteristics of Web 2.0 is that the same information is 
available for everyone. Though it could be valuable in some situations, but in time-critical situations, 
people prefer specific information based on their personal preferences. Lack of personalization 
could result in the ineffectiveness of the available information.
Based on the discussion addressing the limitations of Web 2.0, it is evident that Time, Location, Con-
text and lack of Personalization (TLCP) could potentially hinder the effectiveness of Web 2.0 for disaster 
education and preparation. However, the underlying premises of Web 3.0 could potentially counter the 
issues related to TLCP. The ability for Web 3.0 to harvest, collect and analyses, personalized informa-
tion based on the time, location, and contextual preferences increases the likelihood of the availability 
of relevant information and its effective usage for disaster preparedness.
Information Dissemination and Communicating with The World
The lack of contextualization of information may complicate the process of decision making based solely 
on Web 2.0 data. It is important to note that from senders’ viewpoint, the dissemination of information 
on Web 2.0 is triggered and controlled by humans. These are humans who need to think, draft and dis-
seminate information without any agent based intervention. Similarly, from the receivers’ viewpoint, 
they must manually select, collect and analyze the information before they can use this information for 
decision-making.
In semantic Web 3.0, computer agents replace humans and may trigger, control and disseminate 
information based on sender’s preferences. This ensures that the important information is disseminated 
in a critical situation even without direct human’s intervention.
Alerts and Warnings
One of the key issues associated with the use of Web 2.0 as an official communication tool for alerts 
and warning is peoples’ lack of trust on the authentication and credibility of alerts and warnings issued 
on Web 2.0. there have been several incidents reported in the past where several Web 2.0 channels of 
emergency management agencies were either hacked by the people or incorrect alerts were issued for 
mischievous pranks.

258
Communication Process of Disaster Management
﻿
Web 3.0 offers more control and transparency of the online communication by enabling disaster 
management agencies to establish communication protocols to gauge the integrity and accuracy of 
information especially related to the source of alerts and warnings.
Collaboration and Situational Awareness
Situational awareness is the ability to identify, process, and comprehend critical elements of an incident or 
situation. Monitoring information flows could help establish ‘situational awareness’. Collecting real-time 
information as an incident unfolds can help officials determine where people are located, assess victim 
needs, and alert citizens and first responders to changing conditions and new threats. Various disaster 
management agencies could use the information to direct certain resources to reduce damages, loss of 
life, or both. One benefit of two-way communication facilitated by Web 2.0 is helping officials compile 
lists of the dead and injured, and contact information of victims’ friends and family members. Despite 
the fact that Web 2.0 make it easy for the individuals to provide situational awareness, the real bottle-
neck is at the filtering of large volumes of data based on the context, location, and situation. Collecting 
and analyzing large volumes of data under enormous time pressure could exceed the humans’ abilities.
Web 3.0 promise to offer agent based collecting and analyzing of information based on the contact, 
location and the situation allowing disaster management to freeing up their resources and better utilize 
them on the other rescue activities. In contrast to humans who may underperform or panic during the 
crisis, the use of software agents (replacing direct human intervention) ensures consistent performance 
during the crisis. These agents can automatically detect the location and other relevant details of a per-
son and update the disaster management agencies to get more accurate, timely and complete situational 
awareness.
Queries and Feedback
A large volume of incoming messages from the public is expected during a disaster. Responding to each 
message in a timely manner could be time-consuming and might require an increase in the number of 
employees working at disaster management agencies to respond to these messages. Monitoring, managing 
and ensuring the same information is communicated across various Web 2.0 channels is a tedious job. 
Several incidents have been reported in the literature suggesting the difficulties and delays associated 
with getting the feedback on individuals’ queries during a crisis. The situation is more complex when 
large volumes of queries and questions are directed to disaster management agencies requiring a more 
personalized and customized feedback for those queries.
The underlying principal of Web 3.0 (as a semantic web) promises to generate more customized and 
personalized information on individuals’ (receivers’) preferences without direct humans’ intervention. 
Web 3.0 not only save a considerable amount of resources required to generate, customize and transmit 
personalized information but also improve the response time for the reviewers to receive feedback on 
their queries.

259
Communication Process of Disaster Management
﻿
DISCUSSION
The above discussion summarizes the key communication tasks of disaster management and explains 
the role of Web 2.0 and Web 3.0. The findings of this study in line with the results emerged from the 
review of the literature on the role of web technologies in the effective online communication. This study 
agrees with the fact that the use of Web 2.0 has revolutionized the overall communication process and 
there are countless success stories where this technology has been used as an effective communication 
channel both in crisis and in normal situations. However, the key bottlenecks hindering the use of Web 
2.0 as a strategic communication channel during the crisis are the overflow of information and inability 
to process the large volumes of data to get enough understating of information required to make the right 
decisions in time-critical situations. The emergence of Web 3.0 promises greater value for participants 
involved in the communication process. The ability of Web 3.0 to harvest, collect and analyses, person-
alized information based on the time, location, and contextual preferences increases the likelihood of 
the availability of relevant information and its effective usage for disaster preparedness. It is anticipated 
that this study successfully presented a strong case advocating the use of Web 3.0 as a strategic tool to 
improve the effectiveness of communication process in disaster management.
CURRENT ISSUES AND FUTURE DIRECTION
Web 3.0 is not a separate or isolated technology, but rather a compilation of already existing principles 
amalgamated with new programs and scripts. Though the technology (web 3.0) might not yet be mature, 
but we have come a long way, and the current use of Web 3.0 offers increased collaboration between 
human and machines (software agents) and reduced the workload of data management and enable new, 
intuitive and personalized web service. Web 3.0 has the ability to integrate and structure data autono-
mously that will eventually increase the accuracy and availability of searching data repositories. The 
artificial intelligence embedded within Web 3.0 creates a personalized web experience which will amount 
to countless opportunities for improved decision making. However, it is worthy to consider the risks 
associated with the use of Web 3.0 that many include the unauthorized access to sensitive data, or data 
manipulation by unauthorized persons, new and more complicated electronic attacks, such as Structured 
Query Language (SQL) injections, malware, hyper-targeted spam, and internet ranking manipulation. 
The personalization of Web 3.0 content creates a situation where personal and sensitive data will be 
more widely available on the Web, thus creating an increased risk of identity theft and social phishing.
The chapter shows that it is crucial for organizations and the decision maker to understand the under-
lying infrastructure of Web 3.0 and the opportunities they present. Undoubtedly, Web 3.0 offers a great 
deal of assistance and improvement in the communication process of disaster management, it is vital to 
obtain a proper understanding of Web 3.0 technologies along with its strengths and weakness and the 
role it can play in the improvement of the communication process of disaster management.

260
Communication Process of Disaster Management
﻿
REFERENCES
Acar, A., & Muraki, Y. (2011). Twitter for crisis communication: Lessons learned from Japans tsunami di-
saster. International Journal of Web Based Communities, 7(3), 392–402. doi:10.1504/IJWBC.2011.041206
Ahmed, A., & Sargent, J. (2014). Analysis of post-crisis Twitter communication: a study of the Iquique, 
Chile earthquake. Academic Press.
Alexander, D. E. (2014). Social media in disaster risk reduction and crisis management. Science and 
Engineering Ethics, 20(3), 717–733. doi:10.1007/s11948-013-9502-z PMID:24306994
Bawden, D., & Robinson, L. (2009). The dark side of information: Overload, anxiety and other paradoxes 
and pathologies. Journal of Information Science, 35(2), 180–191. doi:10.1177/0165551508095781
Berthon, P. R., Pitt, L. F., Plangger, K., & Shapiro, D. (2012). Marketing meets Web 2.0, social media, 
and creative consumers: Implications for international marketing strategy. Business Horizons, 55(3), 
261–271. doi:10.1016/j.bushor.2012.01.007
Bertot, J. C., Jaeger, P. T., & Hansen, D. (2012). The impact of polices on government social media 
usage: Issues, challenges, and recommendations. Government Information Quarterly, 29(1), 30–40. 
doi:10.1016/j.giq.2011.04.004
Chew, C., & Eysenbach, G. (2010). Pandemics in the Age of Twitter: Content Analysis of Tweets during 
the 2009 H1N1 Outbreak. PLoS ONE, 5(11), e14118. doi:10.1371/journal.pone.0014118 PMID:21124761
David, C. C., Ong, J. C., & Legara, E. F. T. (2016). Tweeting Supertyphoon Haiyan: Evolving Func-
tions of Twitter during and after a Disaster Event. PLoS ONE, 11(3), e0150190. doi:10.1371/journal.
pone.0150190 PMID:27019425
de Albuquerque, J. P., Herfort, B., Brenning, A., & Zipf, A. (2015). A geographic approach for combin-
ing social media and authoritative data towards identifying useful information for disaster management. 
International Journal of Geographical Information Science, 29(4), 667–689. doi:10.1080/13658816.2
014.996567
Doan, S., Vo, B.-K. H., & Collier, N. (2011). An analysis of Twitter messages in the 2011 Tohoku Earth-
quake. Paper presented at the International Conference on Electronic Healthcare.
Fischer, E., & Reuber, A. R. (2011). Social interaction via new social media:(How) can interactions on 
Twitter affect effectual thinking and behavior? Journal of Business Venturing, 26(1), 1–18. doi:10.1016/j.
jbusvent.2010.09.002
Gretzel, U. (2015). 9 Web 2.0 and 3.0. Communication and Technology, 5, 181.
Gupta, A., Lamba, H., Kumaraguru, P., & Joshi, A. (2013). Faking sandy: characterizing and identify-
ing fake images on twitter during hurricane sandy. Proceedings of the 22nd international conference on 
World Wide Web. doi:10.1145/2487788.2488033
Heverin, T., & Zach, L. (2010). Microblogging for Crisis Communication: Examination of Twitter Use 
in Response to a 2009 Violent Crisis in the Seattle-Tacoma, Washington, Area. ISCRAM.

261
Communication Process of Disaster Management
﻿
Hiremath, B., & Kenchakkanavar, A. Y. (2016). An Alteration of the Web 1.0, Web 2.0 and Web 3.0: A 
Comparative Study. Imperial Journal of Interdisciplinary Research, 2(4).
Houston, J. B., Hawthorne, J., Perreault, M. F., Park, E. H., Goldstein Hode, M., Halliwell, M. R., & 
McElderry, J. A. et al. (2015). Social media and disasters: A functional framework for social media use in 
disaster planning, response, and research. Disasters, 39(1), 1–22. doi:10.1111/disa.12092 PMID:25243593
Hughes, A. L., & Palen, L. (2009). Twitter adoption and use in mass convergence and emergency events. 
International Journal of Emergency Management, 6(3-4), 248–260. doi:10.1504/IJEM.2009.031564
Kaigo, M. (2012). Social Media Usage During Disasters and Social Capital: Twitter and the Great East 
Japan Earthquake. Keio Communication Review, 34, 19–35.
Kavanaugh, A. L., Fox, E. A., Sheetz, S. D., Yang, S., Li, L. T., Shoemaker, D. J., & Xie, L. et al. (2012). 
Social media use by government: From the routine to the critical. Government Information Quarterly, 
29(4), 480–491. doi:10.1016/j.giq.2012.06.002
Lafuente, M. (2016). Getting looped in to the web: Characterizing learning processes and educational 
responses. Interactive Learning Environments, 1–13.
Latonero, M., & Shklovski, I. (2011). Emergency management, Twitter, and social media evangelism. 
International Journal of Information Systems for Crisis Response and Management, 3(4), 67–86.
Liu, B. F., Jin, Y., & Austin, L. L. (2013). The Tendency To Tell: Understanding Publics Communica-
tive Responses To Crisis Information Form and Source. Journal of Public Relations Research, 25(1), 
51–67. doi:10.1080/1062726X.2013.739101
Mendoza, M., Poblete, B., & Castillo, C. (2010). Twitter under crisis: can we trust what we RT? Paper 
presented at the First Workshop on Social Media Analytics, Washington, DC. doi:10.1145/1964858.1964869
Nayar, R. (2015). Role of Web 3.0 in Service Innovation. In The Handbook of Service Innovation (pp. 
253–280). Springer.
Oh, O., Agrawal, M., & Rao, H. R. (2013). Community intelligence and social media services: A rumor 
theoretic analysis of tweets during social crises. Management Information Systems Quarterly, 37(2), 
407–426.
Ortiz, D. G., & Ostertag, S. F. (2014). Katrina Bloggers and the Development of Collective Civic 
Action: The Web as a Virtual Mobilizing Structure. Sociological Perspectives, 57(1), 52–78. 
doi:10.1177/0731121413517558
Palen, L., Hiltz, S. R., & Liu, S. B. (2007). Online forums supporting grassroots participation in emergency 
preparedness and response. Communications of the ACM, 50(3), 54–58. doi:10.1145/1226736.1226766
Palen, L., Vieweg, S., & Anderson, K. M. (2010). Supporting Everyday Analysts in Safety- and Time-
Critical Situations. The Information Society, 27(1), 52–62. doi:10.1080/01972243.2011.534370
Plotnick, L., & Hiltz Starr, R. (2016). Barriers to Use of Social Media by Emergency Managers. Journal 
of Homeland Security and Emergency Management, 13, 247.

262
Communication Process of Disaster Management
﻿
Radianti, J., Hiltz, S. R., & Labaka, L. (2016). An Overview of Public Concerns During the Recovery 
Period after a Major Earthquake: Nepal Twitter Analysis. Paper presented at the 2016 49th Hawaii 
International Conference on System Sciences (HICSS).
Rudman, R., & Bruwer, R. (2016). Defining Web 3.0: Opportunities and challenges. The Electronic 
Library, 34(1), 132–154. doi:10.1108/EL-08-2014-0140
Sánchez Abril, P., Levin, A., & Del Riego, A. (2012). Blurred boundaries: Social media privacy and the 
twenty‐first‐century employee. American Business Law Journal, 49(1), 63–124. doi:10.1111/j.1744-
1714.2011.01127.x
Sarcevic, A., Palen, L., White, J., Starbird, K., Bagdouri, M., & Anderson, K. (2012). Beacons of hope 
in decentralized coordination: learning from on-the-ground medical twitterers during the 2010 Haiti 
earthquake. Paper presented at the ACM 2012 conference on Computer Supported Cooperative Work, 
Seattle, WA.
Schultz, F., Utz, S., & Göritz, A. (2011). Is the medium the message? Perceptions of and reactions to 
crisis communication via twitter, blogs and traditional media. Public Relations Review, 37(1), 20–27. 
doi:10.1016/j.pubrev.2010.12.001
Schultz, T. (2000). Mass media and the concept of interactivity: An exploratory study of online forums 
and reader email. Media Culture & Society, 22(2), 205–221. doi:10.1177/016344300022002005
Schwarz, A. (2012). How publics use social media to respond to blame games in crisis communication: 
The Love Parade tragedy in Duisburg 2010. Public Relations Review, 38(3), 430–437. doi:10.1016/j.
pubrev.2012.01.009
Shklovski, I., Burke, M., Kiesler, S., & Kraut, R. (2010). Technology Adoption and Use in the After-
math of Hurricane Katrina in New Orleans. The American Behavioral Scientist, 53(8), 1228–1246. 
doi:10.1177/0002764209356252
Simon, T., Goldberg, A., Aharonson-Daniel, L., Leykin, D., & Adini, B. (2014). Twitter in the Cross 
FireThe Use of Social Media in the Westgate Mall Terror Attack in Kenya. PLoS ONE, 9(8), e104136. 
doi:10.1371/journal.pone.0104136
Sinnappan, S., Farrell, C., & Stewart, E. (2010). Priceless tweets! A study on Twitter messages posted 
during crisis: Black Saturday. ACIS 2010 Proceedings, 39.
Starbird, K., & Palen, L. (2012). (How) will the revolution be retweeted?: information diffusion and the 
2011 Egyptian uprising. Proceedings of the acm 2012 conference on computer supported cooperative 
work. doi:10.1145/2145204.2145212
Sutton, J., Palen, L., & Shklovski, I. (2008). Backchannels on the front lines: Emergent uses of social 
media in the 2007 southern California wildfires. Proceedings of the 5th International ISCRAM Conference.
Sweetser, K. D. (2010). A losing strategy: The impact of nondisclosure in social media on relationships. 
Journal of Public Relations Research, 22(3), 288–312. doi:10.1080/10627261003614401
Sylvester, A., Tate, M., & Johnstone, D. (2013). Beyond synthesis: Re-presenting heterogeneous research 
literature. Behaviour & Information Technology, 32(12), 1199–1215. doi:10.1080/0144929X.2011.624633

263
Communication Process of Disaster Management
﻿
Takahashi, B., Tandoc, E. C. Jr, & Carmichael, C. (2015). Communicating on Twitter during a disaster: 
An analysis of tweets during Typhoon Haiyan in the Philippines. Computers in Human Behavior, 50, 
392–398. doi:10.1016/j.chb.2015.04.020
Valentini, C., & Romenti, S. (2011). Blogging about crises: The role of online conversations in fram-
ing Alitalias performance during its crisis. Journal of Communication Management, 15(4), 298–313. 
doi:10.1108/13632541111183398
Vieweg, S., Hughes, A. L., Starbird, K., & Palen, L. (2010). Microblogging during two natural hazards 
events: what twitter may contribute to situational awareness. Paper presented at the SIGCHI Conference 
on Human Factors in Computing Systems, Atlanta, GA. doi:10.1145/1753326.1753486
Weichselgartner, J. (2001). Disaster mitigation: The concept of vulnerability revisited. Disaster Pre-
vention and Management: An International Journal, 10(2), 85–95. doi:10.1108/09653560110388609
Workman, M. (2016). Using Symbols for Semantic Representations: A Pilot Study of Clinician Opinions 
of a Web 3.0 Medical Application. In Semantic Web (pp. 31–38). Springer.
Yates, D., & Paquette, S. (2011). Emergency knowledge management and social media technologies: A 
case study of the 2010 Haitian earthquake. International Journal of Information Management, 31(1), 
6–13. doi:10.1016/j.ijinfomgt.2010.10.001
KEY TERMS AND DEFINITIONS
Communication Process: The term ‘communication process’ is used to describe the transfer of mes-
sage from sender to receiver. The key components of communication process include sender, message, 
channel, receiver and feedback.
Disaster Management: The term ‘disaster management’ is used to describe the key phases of disaster 
management life cycle. Generally, disaster management life cycle comprises of four phases including 
mitigation, preparedness, response and recovery.
Literature Review: The term ‘literature review’ is used to describe, summarize, evaluate and clarify 
the literature related to a selected area of study. The findings of literature review process are generally 
presented in the form of a report.
Social Media: The term ‘social media’ is used to website websites and applications that enable users 
to create and share content or to participate in social networking. In nature, social media are the type of 
Web 2.0 applications.
Web 1.0: The term ‘Web 1.0’ is used to describe the first stage in the World Wide Web (WWW) 
which was entirely made up of static Web pages connected by hyperlinks.
Web 2.0: The term ‘Web 2.0’ is used to describe the dynamic web sites that emphasize user-generated 
content, usability, and interoperability.
Web 3.0: The term ‘Web 3.0’ is used to describe a semantic web that is the evolution of the web as 
an extension of Web 2.0. Web 3.0 allows connective intelligence; connecting data, concepts, applica-
tions and ultimately people.

264
Copyright © 2018, IGI Global. Copying or distributing in print or electronic forms without written permission of IGI Global is prohibited.
Chapter  10
DOI: 10.4018/978-1-5225-2575-2.ch010
ABSTRACT
Whilst there has been some limited use of Remotely Piloted Aircraft Systems (RPAS) as part of the re-
sponse to natural disasters, to date these have typically employed short range mini or micro systems. 
Using a case study of Cyclone Winston that struck Fiji in February 2016, this chapter demonstrates the 
potential for long endurance aircraft (LE-RPAS) to support the humanitarian logistic operations through 
the use of their high quality optics and communications capabilities. In doing so, it offers a high level 
route map for the development of the people, process and technology requirements that will be needed 
to underpin the future deployments of LE-RPAS in providing support to humanitarian activities.
INTRODUCTION
It has recently been estimated by the United States Federal Aviation Administration (FAA) that sales of 
Remotely Piloted Aircraft Systems (RPAS) will grow from their estimated 2016 annual US sales level of 
2.5 million an annual level of 7 million in 2020 (FAA, 2016). It is unsurprising, therefore, that their use 
in support of the response to disasters is already taking place and is likely to expand. This is underlined 
by a recent report discussing the use of RPAS in a humanitarian context in which the United Nations 
Office for the Coordination of Humanitarian Affairs commented that: “[the] move from speculation to 
Using Long Endurance Remotely 
Piloted Aircraft Systems 
to Support Humanitarian 
Logistic Operations:
A Case Study of Cyclone Winston
Peter Tatham
Griffith University, Australia
Catherine M. Ball
Remote Research Ranges, Australia
Yong Wu
Griffith University, Australia
Pete Diplas
HK Logistics, Australia

265
Using Long Endurance Remotely Piloted Aircraft Systems
﻿
reality raises challenging questions around … how best to integrate [RPAS] into humanitarian response.” 
(OCHA, 2014, p. 3).
However, to date, the use of such RPAS has mainly been limited to short range mini or micro variants 
such as those documented in a number of recently published case studies (UAViators, 2016). The aim of 
this chapter is, therefore, to consider the potential benefits and costs of the operation of long endurance 
RPAS (LE-RPAS) in support of the logistic response to natural disasters. In doing so, the events sur-
rounding Cyclone Winston that struck Fiji in February 2016 will be used as an exemplar to demonstrate 
both how an LE-RPAS might be employed as well as the steps that would be needed to operationalise 
this concept in a robust way.
In discussing this subject it is important to note that there are multiple words and/or acronyms that 
have been used to describe RPAS which include Unmanned Aerial Vehicles (UAVs), Unmanned Aerial 
Systems (UAS) and Drones. Within this chapter, however, the term Remotely Piloted Aircraft Systems 
(RPAS) will be used as this reflects the nomenclature adopted by the International Civil Aviation Organi-
sation (ICAO). In addition, the use of ‘RPAS’ to describe such systems helps avoid the potential negative 
connotations of the military use of UAVs/UAS/Drones which is clearly unhelpful when considering their 
operation in a humanitarian context. Furthermore, when referring to the aircraft (as distinct from the 
overall system), the acronym RPA (or RPAs) will be used.
To achieve the chapter’s aim, it will first offer a brief overview of the generic humanitarian logistic 
(HL) challenge. It will then offer a summary of the literature relating to RPAS in an HL context before 
discussing the capabilities of a typical LE-RPAS. An overview of Cyclone Winston follows, after which 
the chapter will outline the ways in which an LE-RPAS could have been used to mitigate the cyclone’s 
impact. The chapter will end with a discussion of the next steps that will be needed to underpin a broader 
use of LE-RPAS to support the HL response to a disaster.
THE HUMANITARIAN LOGISTIC CHALLENGE
In the same way as the commercial logistician, the challenge facing his or her humanitarian counterpart 
is that of matching supply with demand in an efficient and effective way. Thus, in the ‘for profit’ en-
vironment the demand side of the equation becomes clear from the action of a consumer purchasing a 
product in a shop or via the internet. However in the aftermath of a disaster those who have survived are 
focussed on staying alive and minimizing the impact of the event. As a result, the process of ascertaining 
their requirements – usually termed ‘needs assessment’ – frequently has to be undertaken by a 3rd party 
such as staff from a government agency or from a non-government organisation (NGO).
Furthermore, this process is often challenged by the failure of communications systems as well as 
the affected population’s demographics and, hence, individuals’ particular needs (Kovács & Tatham, 
2010). Thus determining the answer to the ‘4W question’ (Who Wants What Where) can be extremely 
complex, particularly recognising that the price of failure is not simply a matter of reduced profits. On 
the other side of the equation, the physical impact of the disaster frequently disrupts re-supply routes – 
for example through disrupted sea ports and airports, blocked roads, destroyed bridges etc, all of which 
reduce the speed and effectiveness of the response.

266
Using Long Endurance Remotely Piloted Aircraft Systems
﻿
THE CHARACTERISTICS OF AN LE-RPAS TO SUPPORT HL OPERATIONS
According to OCHA (2014), RPAs are becoming relatively commonplace with 270 companies in 57 
countries reported as manufacturing such aircraft – a figure that will, unquestionably, grow as indicated 
by the FAA data summarised in the introduction to this chapter. Such aircraft range start from very 
small platforms, often in a multi-rotor helicopter configuration similar to those that have recently gained 
significant publicity in the wake of trials by, amongst others, Amazon (Amazon, 2016) and Domino’s 
Pizzas (Gye, 2013). At the other end of the spectrum there are high performance fixed wing aeroplanes 
such as the USAF Global Hawk that is the size of a small executive jet and has a unit cost of >US$130M 
(GAO, 2013).
Given this potential range of offerings, and putting aside cost considerations that will be discussed later, 
the choice of platform will reflect its desired capabilities as well as the operational environment. With 
this in mind it is argued that the chosen LE-RPAS should meet a number of high level selection criteria:
•	
In light of the humanitarian context, it should not be covered by the International Traffic in Arms 
Regulations (ITAR) or be an otherwise restricted system.
•	
Ideally it should have sufficient endurance to allow it to operate continuously throughout the hours 
of daylight, i.e. for some 8-12 hours.
•	
Whilst not essential, a night-flying capability would be beneficial.
•	
It should have a relatively large payload capability which should include regular and infra-red 
still and video cameras, together with the ability to link with satellite networks as necessary both 
for command and control purposes and also to deliver the resultant data to the affected country’s 
National Disaster Management Organisation (NDMO) swiftly and efficiently.
As indicated earlier, these high level criteria would indicate a LE-RPAS that should be able to oper-
ate ‘beyond line of sight’ (BLOS). An exemplar of such a system is the Aerosonde Mk 4.7, the details 
of which are summarised in Table 1.
It should be noted that the Aerosonde RPA can be launched either by a catapult system or from the 
roof of a 4*4 vehicle that requires approximately 400m (440yds) of straight road (or runway) in order 
to reach the required speed of some 60kph (40mph). It lands either directly onto a grass area (again 
requiring 400m (440yds) to allow the RPAS to line up and then ‘skid’ to a halt), or via a mechanical 
‘catch net’ into which it flies and is then captured.
Table 1. Aerosonde Mk 4.7 – Key Performance Data (www.aerosonde.com)
Endurance: 8-18 hours (payload dependent)
Airspeed range: 80-125 kph (42-68 knots)
Cruising speed: 90-110 kph (50-60 knots)
Ceiling: 4,500m (14,750 ft)
Wingspan: 2.8m (9.4 ft)
Overall Length: 1.7m (5.7 ft)
Maximum gross take-off weight: 25kg (55lb)

267
Using Long Endurance Remotely Piloted Aircraft Systems
﻿
LITERATURE REVIEW
Unsurprisingly most of the literature related to RPAS operations is to be found in a military context – 
albeit, within this, there is occasional mention of the potential for the RPAS capabilities to be applied 
in a disaster response context (e.g. Wilson, 2009). With this in mind, the literature related to humanitar-
ian logistics was considered through an analysis of a number of recent summaries including: Kunz and 
Reiner (2012), Leiras et al. (2014), and Gizaw & Gümüş (2016).
This initial review was only able to identify one paper that specifically focussed on the use of RPAS 
in an HL context, namely Tatham (2009) in which the author argued that RPAS had the potential to 
be a cost-effective way of conducting post-disaster reconnaissance. This paper also identified a small 
number of instances (< 5) when (at the time of writing) an RPAS had actually been used to support 
disaster response.
However, in light of the general discussion of RPAS in the media as well as the specifics of a number 
of missions published by UAViators (2016), a further review was carried out based on the methodology 
of Kunz and Reiner (2012) and using the keyword and Boolean operator string:
(“Unmanned Aerial Vehicle” OR “UAV” OR “Unmanned Aerial System” OR “UAS” OR “Drone” 
OR “Remotely Piloted Aircraft System” OR “RPAS”) AND (“Disaster response” OR “Emergency Re-
sponse” OR “Humanitarian Logistics”)
The start point for the search timeframe (2005) was selected based on the first reported use of RPAS 
in a humanitarian context which took place in the aftermath of the Hurricane Katrina (Tatham, 2009), 
and final date was the end of the calendar year 2015. The raw number of papers returned from this search 
is shown in Table 2.
The abstracts of these papers were analysed and, notwithstanding the search string, 20 were found to 
be not relevant. Of the remaining 55, the key themes are summarised in Table 3.
Analysis
As will be seen from Table 3, the literature contains several discussions around the ethical operation of 
RPAS which is unsurprising given their genesis as military systems. There was also consideration of the 
implications of the restrictions on RPAS operations imposed by, in particular, the FAA – albeit these rules 
are under active consideration that aims to provide a balance between the concerns related to safety and 
privacy versus the potential benefits of RPAS operations both generally and in the aftermath of a disaster.
The next most populous category covers a number of papers which were of a highly technical nature 
discussing various sensors and ways in which their operation could be improved through, for example, 
the use of mathematical algorithms. Although clearly important, these contributions were considered to 
be out of scope for this chapter which is focussing on the potential generic benefits of RPAS in support 
of HL operations.
Table 2. Results of the database search
Science Direct
ABI/Inform 
Complete
Business Source 
Complete
Web of Science
Total
Publications
14
12
16
33
75

268
Using Long Endurance Remotely Piloted Aircraft Systems
﻿
More relevantly, a number of important areas emerged from the review including the use of RPAS 
for mapping, for the post-disaster evaluation of buildings, and for the transport of medical supplies, all 
of which will be discussed in greater detail in the section that follows.
In addition to the UAViators (2016) reports and also the contribution by Tatham (2009) outlined 
above, the review specifically uncovered three papers of particular relevance, namely: Czyzewski (2012), 
OCHA (2014), and American Red Cross (2015).
•	
Czyzewski (2012) discusses Project ResQU that was completed in 2014 and which was designed 
to investigate the potential for RPAS in disaster response in Queensland, Australia. Specifically, 
this project highlighted the need for updated regulations governing the use of RPAS in commer-
cial airspace and in this context it also investigated the use of emerging technologies to enable 
RPAS to sense and avoid other aircraft, and to land safely in emergencies thereby contributing to 
potential improvements to the air traffic control regime.
•	
The OCHA (2014) paper introduced earlier summarises the recent use of RPAS in a humanitarian 
context and argues that they will be able to enhance:
◦◦
Data collection via video/photo feeds, including map production.
◦◦
Public information and advocacy through a demonstration of the scale of a disaster’s dam-
age, the pace of recovery, and/ or by highlighting specific problems.
◦◦
Search missions both at a macro level and, through the use of micro RPAS, within buildings 
etc.
◦◦
The provision of medical support through the delivery of items such as medicines or vaccines.
Table 3. Analysis of the database search
Subject Area
No of 
Articles
Ethics/control of RPAS Operations
16
Technical operation of RPAS of Sensors
8
Use of micro/mini RPAS in disaster response
7
Development of ‘dextrous RPAS’ that incorporate manipulation devices
4
Use of drones for mapping
4
Use of macro RPAS in disaster response
3
Use of RPAS for post-disaster evaluation of buildings and structures
3
Use of RPAS in agriculture
2
Use of drones to transport medical supplies
2
Safety/Risk Management in RPAS operations
2
RPAS communications systems
1
Use of RPAS for detection of sand/dust storms
1
Use of RPAS for detection of fires
1
Use of ambulance drones
1
Total
55

269
Using Long Endurance Remotely Piloted Aircraft Systems
﻿
The OCHA (2014) report also underlined the relatively low cost of RPAS operations, the need for 
their swift deployment, and the importance of ensuring that operations are integrated into existing 
guidelines such as those from the International Search and Rescue Group (INSARAG). However this 
report also underlines many of the issues that surfaced in the literature review including the absence 
or restrictive nature of regulatory frameworks covering RPAS operations; ethical issues relating to the 
fact that the operators of, in particular, RPAS that can operate Beyond Line of Sight (BLOS) are also 
military contractors; and privacy issues that reflect the capability of RPAS to observe private property 
and capture sensitive personal information.
Importantly, the OCHA (2014) report recommends that RPAS operators should attempt to develop a 
mechanism that provides some form of ‘informed consent’ through, for example, ensuring that the roles, 
mission timings, areas to overflown etc. are cleared in advance with local authorities and publicised. 
As part of the development of a robust process, the report also supports the use of the draft Operational 
Guidelines (UAViators, 2016a) which are currently being considered by the disaster response communities.
The conclusions of the OCHA (2014) report are similar to those of a recent report by the American 
Red Cross (2015, p. 7) in which it is suggested that RPAS they have the potential to support the follow-
ing disaster response activities:
•	
Reconnaissance and Mapping.
•	
Structural Assessment.
•	
Temporary Infrastructure/Supply Delivery.
•	
Wildfire – Detection and Extinguishing.
•	
High-Rise Building Fire Response.
•	
Chemical, Biological, Radiological, Nuclear, or Explosive (CBRNE) Events.
•	
Search and Rescue Operations.
•	
Insurance Claims Response and Risk Assessment.
•	
Logistics Support.
In summary, and drawing on the above literature and also following informal discussions with manu-
facturers and experts, a BLOS LE-RPAS is perceived to have particular benefit for the humanitarian 
logistician in the provision of the following capabilities:
•	
Still/video photography/infra-red imagery to support the Needs Assessment process.
•	
The existence of a ‘find your phone’ functionality in which RPAS can determine the location of an 
operating cell phone and initiate a call to this phone from, for example, the NDMO as an extension 
of the Needs Assessment process.
•	
Acting as a temporary mobile communications system by flying in a geo-stationery orbit.
•	
Dropping a mobile communications device (such as a solar-powered satellite phone) into the af-
fected area to enable direct communications with the NDMO.
•	
Conducting low level surveillance of prospective logistic re-supply routes to ascertain if they have 
been compromised by, for example, landslips or broken bridges.
The next section of this chapter is designed to demonstrate how these five core capabilities could be 
operationalised using the example of Cyclone Winston as an exemplar.

270
Using Long Endurance Remotely Piloted Aircraft Systems
﻿
CYCLONE WINSTON: A CASE STUDY
An Overview of Cyclone Winston
Fiji is a nation of 2 major and over 110 smaller inhabited islands covering a total land area of 18,300 sq 
km (7,100 sq mi). Cyclone Winston first began to develop on 11th Feb 2016 between Vanuatu and Fiji 
and started to travel in a South Easterly direction before turning North East and passing between the 
Fiji’s Western islands (the Lao Group) and Tonga on 16th Feb. It then turned back westwards towards 
Fiji and grew in strength before crossing the northern islands in the Lau Group on 19th Feb and then 
passing between the two main (and most populated) islands of Vanua Levu and Viti Levu over the next 
24 hours. The wind strengths as Winston crossed the nation were recorded at 260-270 kph (140-145 kts) 
making this the most powerful cyclone to strike the country on record.
Unsurprisingly the resulting devastation was enormous, especially in those areas that received a ‘direct 
hit’ (see Figure 1). The impact of the cyclone resulted in a death toll of 42, and over 55,000 people (15% 
of the population) had to take shelter in evacuations centres and schools, with the damage to properties 
and infrastructure estimated to cost in excess of $1Bn.
A further complicating factor was that the cyclone damaged or destroyed much of the communications 
systems including the aerial on the island of Mago that served the Lau Group of islands. As a result, the 
OCHA Situation Reports Numbers 1 (21 Feb) to 9 (29 Feb) all indicated that: “Communications with 
many affected areas remain interrupted, hampering efforts to get a clear picture of needs on the ground” 
or similar words to that effect (see, for example, OCHA, 2016, p. 2).
Furthermore, and notwithstanding the presence of an RNZAF P3 Orion surveillance aircraft from 
Day 3 (22 Feb), it was reported that it was necessary to send assessment teams in order to understand 
the impact of the disaster to the most severely affected islands such as Koro (population 3,450) that was 
in the eye of the storm (OCHA, 2016a).
How Might the Response to Cyclone Winston Have Been 
Different If an LE-RPAS Had Been Available?
As discussed above, a core capability of an LE-RPAS such as the Aerosonde Mk4.7 is its capacity to 
undertake aerial surveillance over a long time period, typically some 10 hours using still photography or 
around 8 hours using a slightly heavier video camera. In this regard, whilst video footage has the benefit 
of real time data capture and subsequent transmission to the NDMO, its use constrains operations to some 
100km (60mi) from the operating base. On the other hand, the capabilities of the latest generation still 
cameras are such that after post-mission processing, they can provide the equivalent of a video camera 
output. The processing itself takes a similar time to that actual data capture – thus, for example, 5 hours 
of surveillance requires 5 hours of processing.
Either approach would provide the NDMO with a relatively swift overview of the impact of the 
disaster, thereby contributing significantly to the Needs Assessment process. Furthermore, the data 
collected by this process can be transmitted in parallel not only to the NDMO, but also to the equivalent 
organisations in those countries that are assisting the response (such as Australia and New Zealand in 
the case of Cyclone Winston), and to UN agencies and NGOs. This is a key benefit as it will assist all 
of the supporting governments and agencies in moving from a ‘guesstimated’ push-based response to 
one that is more closely driven by an improved understanding of the disaster’s impact (i.e. pull-based).

271
Using Long Endurance Remotely Piloted Aircraft Systems
﻿
The flight time for an Aerosonde LE-RPAS with a high definition still camera at a cruising speed of 
100kph (60mph) is some 10 hours, i.e. it has a range of 1,000km (600mi). As shown in Figure 1, this 
would enable a comprehensive overview of the impact of the disaster on the affected areas over a period 
of 3 days. In developing the mission profiles, the population locations on each island have been taken 
into account, and conservative estimates of distances and timings have been used. Notwithstanding the 
use of such conservative assumptions, it will be noted that in each case the transit time is 4-6 hours, 
leaving some 4-6 hours to conduct the oversight of the affected areas.
BROADER CONSIDERATIONS IN RELATION TO THE USE OF AN LE-RPAS
Whilst the use of an LE-RPAS to capture the post-disaster impact is unquestionably valuable, the benefits 
would be significantly improved were these results able to be compared with a pre-disaster baseline. 
To an extent this could be achieved in the typical 48 hour warning period between the clear indications 
that a cyclone is likely to strike a country or region and its actual onset. However, the development of a 
pre-planned surveillance programme that is focussed on areas of high risk has the potential to provide 
significantly more meaningful data.
Figure 1. Overview of Cyclone Winston and potential RPAS Needs Assessment routes

272
Using Long Endurance Remotely Piloted Aircraft Systems
﻿
In addition to such surveillance missions, the LE-RPAS is also able to provide an ad hoc mapping 
service in the event that suitable information is not readily available – as was the case in the aftermath 
of Typhoon Haiyan that struck the Philippines in 2013 (American Red Cross, 2015, p. 16), and also as 
reported in a number of the recent case studies (UAViators, 2016).
In relation to such operations it should also be noted that these are not necessarily constrained by the 
high wind speeds that occur in the vicinity of a cyclone. For example in November 2007, an Aerosonde 
RPAS flew for 7.5 hours monitoring the core of the 130kph (80mph) Hurricane Noel (NASA, 2007), 
thereby providing data to the US National Aeronautics and Space Administration (NASA) and the US 
National Oceanic and Atmospheric Administration (NOAA). Whilst it is recognised that the wind speeds 
in the heart of Cyclone Winston were significantly higher, but the Aerosonde could have safely operated 
in the lead up and aftermath of the event.
The second core capability that would have been invaluable in the response to Cyclone Winston is 
that of carrying and dropping a small payload (comfortably up to 5kg) such as a satellite phone and 
associated solar powered battery systems. This would have enabled the provision of a communications 
system with a direct link to the NDMO from the affected area and, thereby, provide a much improved 
understanding of the actual post-disaster needs of the population (i.e. the demand side of the equation). In 
a similar way, the use of a ‘find my phone’ capability can locate cell phones on the ground – and hence, 
by implication, where an individual or a group of people are situated. This can then be used to initiate 
a call to the cell phone from the NDMO thereby enhancing the all-important exchange of information 
between those affected and the responders
Thirdly, as explained above, one of the challenges in responding to Cyclone Winston was the loss of 
communications to the Lau Group of islands that had been badly affected. To overcome this, the RPAS 
can fly in a geo-stationary mode and thereby act as a temporary telecoms relay tower. In doing so, there 
is a clear potential that the LE-RPAS will be overwhelmed by the volume of calls, but this can be over-
come by limiting access to pre-determined phones such as those from local disaster management staff.
Finally, the ability of the RPAS to overfly a prospective logistic route helps the NDMO to ensure the 
viability of the proposed road by checking that it is not compromised by fallen trees, landslips or broken 
bridges etc. Whilst this capability cannot provide absolute surety that a route is usable – for example a 
bridge or culvert may appear sound, but actually be unable to take the weight of a truck – it neverthe-
less provides a first approximation, and thus has major benefit to the supply side of the equation saving 
valuable time and effort in reaching those in need.
Importantly, however, the above benefits of a prospective LE-RPAS focus on the technology side of 
the challenge. To this must be added a ‘whole-system’ perspective and the other two components of the 
people/processes/technology triangle will be discussed in detail in the next sections.
Overview of the Process Challenges
As discussed in OCHA (2014), there remains a gap in the ability of responding agencies to integrate 
the results of aerial observations and the associated data collection into needs and damage assessments, 
search and rescue, and other humanitarian functions. Overcoming this challenge is the subject of broad 
consideration within the sector including, for example, a recent contribution by Tatham and Spens 
(2016). This recommends that resolution of the coordination challenge facing humanitarian logistician 
be undertaken using a mechanism that parallels that used by the Urban Search and Rescue community. 
The International Search and Rescue Guidelines (INSARAG, 2015) provide an overarching model for 

273
Using Long Endurance Remotely Piloted Aircraft Systems
﻿
the integration of the work of multiple teams from multiple countries using a common process and ap-
proach. Importantly, this model is also being adopted by the World Health Organisation (WHO) under 
their Guidelines for Foreign Medical Teams (FMTs) (WHO, 2013).
Although at a relatively immature stage, the WHO guidelines on the composition of FMTs are de-
signed to help ensure that the levels of skills, equipment, etc. of such teams are appropriate to the event 
to which they are responding. In essence, both of these approaches (INSARAG and WHO) are aiming 
to ensure compatibility between the work of responding agencies. Furthermore, they provide the abil-
ity for an affected nation to reject the assistance of an individual or organisation that does not meet the 
guidelines/standards. Such an approach would appear to have significant benefit in the future operation 
of RPAS, however achieving this will take time. In the interim, as indicated earlier, OCHA (2014) rec-
ommends that all operations be conducted in line with the ‘Humanitarian UAV Code of Conduct and 
Guidelines’ (UAViators, 2016a).
In a separate, but related, contribution to the resolution of the inter-agency logistic coordination 
challenge, Tatham et al. (2016) recommend the adoption of a ‘Common Humanitarian Logistic Picture’ 
(CHLP) to which all agencies contribute and which can form the basis of integrated decision-making. 
Self-evidently, linking the RPAS output to the CHLP would be of considerable value in helping to ensure 
that response activities are appropriately prioritised and needs-based.
However, the current reality is that, although the data that are produced by RPAS are typically geo-
tagged or referenced in some manner, there are no metadata standards. The development of a robust 
metadata framework and its associated standards is, therefore, clearly is clearly an area that requires 
further consideration and development in order to ensure that the technical capabilities on the LE-RPAS 
are maximised. In terms of the processing of the RPAS data, most can be exported into standard soft-
ware for subsequent manipulation. However there is a clear risk that the data may overwhelm existing 
NDMO systems, and the implications of this must be borne in mind as part of any project to incorporate 
LE-RPAS into the disaster response mechanisms.
The final, and key, process-related challenge is that of ensuring that the appropriate permissions are 
in place that will allow the operation of LE-RPAS in the affected country with a minimum of delay. 
Given that international and national air traffic management and safety authorities are struggling to 
achieve the appropriate balance between such operations and the associated safety/privacy issues, this 
is clearly a critical area of development. In some cases it has been mitigated by informal processes such 
as the decision by the Mayor of Tacloban to authorise local RPAS flights in the aftermath of the 2014 
Typhoon Haiyan (OCHA, 2014, p.5). However, this is a poor substitute for the development of an agreed 
protocol that can be practised in advance of a disaster event and which will support, rather than impede, 
the RPAS operations.
Overview of the People-Related Challenges
On the assumption that the aircraft are operated by a reputable commercial company, it can reasonably 
be anticipated that the staff will have the necessary skills and expertise to conduct flying operations in 
a safe, effective and ethical manner, and in line with the relevant air traffic control/safety requirements 
of the relevant country. However, over and above this area, there are clear people-related challenges to 
be overcome that related to the population of the affected region and the integration, interpretation and 
analysis of the RPAS-generated data which will generate a range of training/education requirements.

274
Using Long Endurance Remotely Piloted Aircraft Systems
﻿
The first such requirement would be for an education programme that covers a range of subjects 
including the risks and safety implications of RPAS operations, the potential benefits, and ways in 
which local communities can engage and support such operations. As an example, if it is planned that 
the RPA will drop a satellite phone for use by those affected in a disaster, the appropriate protocols 
must be developed and practised in advance. These would include the operation of the phone as well 
as the ways in which meaningful information can be passed to the NDMO – for example by the use of 
a standardised question and answer system. Given that the availability of local disaster management 
staff may have been compromised by the disaster, this knowledge may need to be included as part of 
the satellite phone delivery package – perhaps in pictorial form in the event that the operator is unable 
to read or uses a different language.
Secondly, given that the capability and modus operandi of the NDMO in each country is likely to 
differ, it will be essential that the processes for capturing and integrating the RPAS data into the disas-
ter management systems are prepared and exercised in advance of any actual event. In particular, the 
interpretation of the RPAS data is a sophisticated skill set and this implies that an individual versed in 
the operation of a particular NDMO (and, indeed, with the appropriate language skills) may need to be 
engaged in order to ensure that the data is correctly interpreted and integrated with other sources of data.
Thirdly, and in the same way as for the local NDMO, it would be necessary to have staff available 
who are skilled in the interpretation of the RPAS data within the disaster management teams of support-
ing countries. On the one hand, such a task is likely to be of a lesser complexity than the local context 
discussed above as the systems would be more familiar and there should not be any significant language 
challenges. On the other hand, the potential lack of local knowledge and understanding of the affected 
country may require appropriate mitigation strategies.
LE-RPAS COST CONSIDERATIONS
Unfortunately, as noted by Mailey (2013), comparable costs between different aircraft modes are not 
easy to calculate given as there are numerous ways in which the costs/flight hour can be calculated and 
there is no standardised or accepted protocol. Furthermore, to the extent that open-source literature does 
exist (e.g. Economist, 2009; Economist, 2011; Boyle, 2012), the focus is usually comparisons between 
high end military systems versus manned military aircraft. Thus, rather than attempt a potentially flawed 
direct comparison between alternative modes of delivering the core capabilities outlined above, the fol-
lowing observations in relation to the potential use of an LE-RPAS are offered:
•	
Corcoran (2014) indicates that its capital cost in 2013 for an Aerosonde Mk4.7 was some 
US$100,000, to which must be added the cost of the camera which will depend on its type (eg 
video v still), with the latter costing around US$40-50,000. Thus, the overall capital cost of an 
LA-RPAS with a high definition still camera to be some US$100-150,000. This can be compared 
with that of a two-seat Raven light helicopter which has a capital cost of US$473,400 (Robinson 
(2016).
•	
The crew size of an Aerosonde consists of one pilot, one camera operator and a maintainer which 
is broadly similar to that of a small fixed or rotary wing aircraft and significantly less than needed 
for high specification military aircraft.

275
Using Long Endurance Remotely Piloted Aircraft Systems
﻿
•	
The fuel consumption of an LE-RPAS is extremely low. For example, in August 1998 an Aerosonde 
Mk 1 flew across the Atlantic, a distance of 3,270km (2,030mi) at an altitude of 1,680m (5,500ft) 
in just under 27 hours consuming some 7li (1.5gal) of fuel (Barnard, 1999). However, a broad or-
der consumption figure for the Mk 4.7 with a high definition still camera is understood to be some 
0.6 li/hour which equates to 0.6li/100 km at cruising speed. Thus, an indicative 10 hr mission time 
would use some 6li of unleaded fuel (i.e. costing around US$1-2/hour). By comparison, Robinson 
(2016) indicates that the two-seat Raven light helicopter consumes some US$75/hour in fuel. 
Thus, a 10 hour flight would cost around US$750 compared with US$15 for a similar RPAS flight.
In summary, therefore, it would the proposed use of an LE-RPAS has a significant financial benefit 
in terms of both capital and operating costs.
Summary and Areas of Further Research
The above analysis of the benefits and costs of the use of an LE-RPAS such as the Aerosonde demon-
strates its potential to support logistic operations through the use of the five core capabilities (video/
photography to support Needs Assessment; provision of temporary communications; ‘find your phone’, 
the ability to drop a satellite phone; and logistic route surveillance). It is far less costly to operate than 
fixed/rotary wing aircraft, can fly in very poor weather conditions, and can free up other assets (such 
as helicopters) for more appropriate activities. However, operationalising the use of such an LE-RPAS 
will, inevitably, require considerable investment. The following represents a proposed way forward that 
is designed to integrate the people, process and technology requirements.
Phase 1
Given the relatively novel nature of RPAS and, in particular, the need to integrate their operation into 
existing response systems, it is believed that the most appropriate way forward it so select a country (or 
countries) to act as ‘pathfinders’ in order to develop the proof of concept. The selection of the country 
is likely to reflect a combination of its likelihood of being impacted by a future disaster, the potential 
impact of such a disaster, the extent to which it is likely to be supportive of the use of RPAS and has the 
capability to be able to use the resultant information in a meaningful way, and the extent to which its 
geography and topology are conducive to the use of RPAS.
Phase 2
Relevant experts from the selected country together with those with RPAS skills in the various domains 
(operation of the RPA; data handling; air traffic control etc.) should collaborate work together to establish 
appropriate air traffic control protocols; capture base-line data to support subsequent impact analysis; 
develop the systems needed to integrate the data captured by the RPAS into the NDMO as a basis for 
efficient and effective decision-making.
Once these processes and protocols have been developed, it will then be necessary to carry out 
appropriate training and education at all levels (community->local government->NDMO and support-
ing country decision-makers) in order prepare for future RPAS operations. This should include actual 

276
Using Long Endurance Remotely Piloted Aircraft Systems
﻿
operations in order to evaluate and improve the above processes and then updating them as necessary 
to ensure that, in the event of a disaster, the end-to-end RPAS operations will be conducted in a safe, 
ethical, effective and efficient way.
SUMMARY
In summary, it is perceived that the use of an LE-RPAS has significant potential to support the logistic 
response to a disaster. However, a number of important hurdles remain before the concept can be opera-
tionalised, key amongst these are the development of an air traffic control regime that supports (rather 
than constrains) the RPAS use, and the mechanisms (both process and people-related) that translate the 
data from the RPAS into usable information to underpin timely and effective decision making.
REFERENCES
Amazon. (2016). Amazon Prime Air. Retrieved from: http://www.amazon.com/b?node=8037720011
American Red Cross. (2015). Drones for Disaster Response and Relief Operations. Retrieved from: https://
www.zurichna.com/en/search?q=Drones+for+Disaster+Response+and+Relief+Operations&page=2#
Microsystems, B. (1999). First Atlantic crossing by an unmanned aircraft. Available at: http://www.
barnardmicrosystems.com/UAV/milestones/atlantic_crossing_1.html
Boyle, A. (2012). The US and its UAVs: A Cost Benefit Analysis. American Security Project. Retrieved 
from http://www.americansecurityproject.org/the-us-and-its-uavs-a-cost-benefit-analysis/
Corcoran, M. (2014). Drone journalism: Newsgathering applications of Unmanned Aerial Vehicles 
(UAVs) in covering conflict, civil unrest and disaster. Retrieved from: http://www.flinders.edu.au/ehl/fms/
law_files/Drone%20Journalism%20During%20Conflict,%20Civil%20Unrest%20and%20Disasters%20
March%201%202014.pdf
Czyzewski, A. (2012). Project investigates potential of UAVs for disaster response. The Engineer. Re-
trieved from: http://www.theengineer.co.uk/project-investigates-potential-of-uavs-for-disaster-response/
The Economist. (2009, September). Attack of the drones. Economist, 3. Retrieved from http://www.
economist.com/node/14299496/print
The Economist. (2011, October). Flight of the drones. Economist, 8. Retrieved from http://www.econo-
mist.com/node/21531433/print
FAA (Federal Aviation Administration). (2016). FAA Aerospace Forecast: Fiscal Years 2016-2036. 
FAA. Retrieved from: http://www.faa.gov/data_research/aviation/aerospace_forecasts/media/FY2016-
36_FAA_Aerospace_Forecast.pdf
GAO (United States Government Accountability Office). (2013). Defense Acquisitions: Assessments of 
Selected Weapon Programs. GAO. Retrieved from: http://www.gao.gov/assets/660/653379.pdf

277
Using Long Endurance Remotely Piloted Aircraft Systems
﻿
Gizaw, B. T., & Gümüş, A. T. (2016). Humanitarian Relief Supply Chain Performance Evaluation: A 
Literature Review. International Journal of Marketing Studies, 8(2), 105. doi:10.5539/ijms.v8n2p105
Gye, H. (2013). Now that’s a special delivery: Domino’s builds DRONE to deliver pizzas by air and beat 
the traffic. Daily Mail. Retrieved from: http://www.dailymail.co.uk/news/article-2336324/Dominos-
builds-DRONE-deliver-pizzas-air-beat-traffic.html#ixzz44XJEkfMO
INSARAG. (2015). International Search and Rescue Guidelines. Retrieved from http://www.insarag.
org/en/methodology/guidelines.html
Tatham, P. H., & Kovács, G. (2010). The impact of gender on humanitarian logistics. International 
Journal of Mass Emergencies and Disasters, 28(2), 148–169.
Kunz, N., & Reiner, G. (2012). A meta-analysis of humanitarian logistics research. Journal of Humani-
tarian Logistics and Supply Chain Management, 2(2), 116–147. doi:10.1108/20426741211260723
Leiras, A., de Brito, I., Peres, E. Q., Bertazzo, T. R. R., & Yosthizaki, H. R. J. (2014). Literature review 
of humanitarian logistics research: Trends and challenges. Journal of Humanitarian Logistics and Sup-
ply Chain Management, 4(1), 95–130. doi:10.1108/JHLSCM-04-2012-0008
Mailey, C. (2013). Are UAS More Cost Effective that Manned Flights? AUVSI. Retrieved from www.
auvsi.org
NASA. (2007). NASA and NOAA Fly Unmanned Aircraft into Hurricane Noel. Retrieved from http://
www.nasa.gov/centers/wallops/news/story105.html
OCHA (Office for the Coordination of Humanitarian Affairs). (2014). Unmanned aerial vehicles in hu-
manitarian response. OCHA Policy and Studies Series, Occasional Paper No 10. Retrieved from: https://
docs.unocha.org/sites/dms/Documents/Unmanned%20Aerial%20Vehicles%20in%20Humanitarian%20
Response%20OCHA%20July%202014.pdf
OCHA (Office for the Coordination of Humanitarian Affairs). (2016). Fiji: Severe Tropical Cyclone 
Winston, Situation Report No. 9 (as of 29 February 2016). Retrieved from: http://reliefweb.int/sites/
reliefweb.int/files/resources/OCHA%20TC%20Winston%20Situation%20Report%209.pdf
OCHA (Office for the Coordination of Humanitarian Affairs). (2016a). Fiji: Severe Tropical Cyclone 
Winston, Situation Report N0. 2 (as of 22 February 2016). Retrieved from: http://reliefweb.int/report/
fiji/fiji-severe-tropical-cyclone-winston-situation-report-no-2-22-february-2016
Robinson. (2016). R42 Raven II 2016 Estimated Operating Costs. Retrieved from: http://robinsonheli.
com/price_lists_eocs/r44_2_eoc.pdf
Tatham, P. H. (2009). An Initial Investigation into the Suitability of the use of Unmanned Aerial Ve-
hicle Systems (UAVS) to Support the Emergency Assessment Process in Rapid Onset Humanitarian 
Disasters. International Journal of Risk Assessment and Management, 13(1), 60–78. doi:10.1504/
IJRAM.2009.026391
Tatham, P. H., & Spens, K. M. (2016). Cracking the humanitarian logistics coordination challenge: Les-
sons from the urban search and rescue community. Disasters: The Journal of Disaster Studies, Policy 
and Management, 40(2), 246–261.

278
Using Long Endurance Remotely Piloted Aircraft Systems
﻿
Tatham, P. H., Kovács, G., & Spens, K. M. (2016). The humanitarian common logistic operating pic-
ture: A solution to the inter-agency coordination challenge. Disasters: The Journal of Disaster Studies, 
Policy and Management.
UAViators. (2016). Case Studies: Mapping Drones in Humanitarian Contexts. Retrieved from http://
drones.fsd.ch/2016/03/17/case-studies-mapping-drones-in-humanitarian-contexts/
UAViators. (2016a). Humanitarian UAV Code of Conduct & Guidelines. Retrieved from: http://uavia-
tors.org/docs
WHO (World Health Organisation). (2013). Classification and minimum standards for foreign medi-
cal teams in sudden onset disasters. Retrieved from: http://www.who.int/hac/global_health_cluster/
fmt_guidelines_september2013.pdf
Wilson, J.R. (2009, July). Unmanned aerial vehicles get ready for prime time. Military and Aerospace, 
18-25.

﻿
Compilation of References
﻿
Abel, F., Gao, Q., Houben, G., & Tao, K. (2011). Semantic enrichment of twitter posts for user profile construction on 
the social web. Lect. Notes Comput. Sci., 6643, 375–389. doi:10.1007/978-3-642-21064-8_26
Acar, A., & Muraki, Y. (2011). Twitter for crisis communication: Lessons learned from Japans tsunami disaster. Inter-
national Journal of Web Based Communities, 7(3), 392–402. doi:10.1504/IJWBC.2011.041206
Achenbruck, N., Gerhaps-Padilla, E., Gerharz, M., Frank, M., & Martini, P. (2007). Modelling Mobility in Disaster Area 
Scenarios. Paper presented at International Symposium on Modeling, Analysis and Simulation of Wireless and Mobile 
Systems, Chania, Create Island. doi:10.1145/1298126.1298131
Aggarwal, A., Gandhi, S., & Chaubey, N. (2011). Performance analysis of AODV, DSDV and DSR in MANETs. Int. J. 
Distrib. Parallel Syst., 2(6), 167–177. doi:10.5121/ijdps.2011.2615
Ahmed, A., & Sargent, J. (2014). Analysis of post-crisis Twitter communication: a study of the Iquique, Chile earthquake. 
Academic Press.
Akerkar, R. (2013b). Improving Data Quality on Big and High-Dimensional Data. Journal of Bioinformatics and Intel-
ligent Control, 2(1), 155-162.
Akerkar, R., Friberg, T., & Amelunxen, C. (2016). EmerGent Deliverable 3.5: User Requirements (Version 2). Paderborn.
Akerkar, R. (2013a). Big Data Computing. Chapman and Hall/CRC. doi:10.1201/b16014
Akerkar, R., & Lingras, P. (2008). Building an Intelligent Web. Jones and Burtlett.
Akhter, M. (2005a). Implementing the SWAP-GA model in cluster computers. Asian Institute of Technology. MSc.Thesis 
no. CS-05-11.
Akhter, S., Jangjaimon, I., Chemin, Y., Uthayopas, P., & Honda, K. (2006). Development of a GRIDRPC tool for Satellite 
Images Parallel Data Assimilation in Agricultural Monitoring. International Journal of Geoinformatics, 2(3).
Akhter, S., Rahman, M. R., & Islam, A. (2016b). Neural Network (NN) Based Route Weight Computation for Bi-
Directional Traffic Management System. International Journal of Applied Evolutionary Computation, 7(4).
Akyildiz, I. F., & Stuntebeck, E. P. (2006). Wireless underground sensor networks: Research challenges. Ad Hoc Net-
works, 4(6), 669–686. doi:10.1016/j.adhoc.2006.04.003
Alamdar, F., Kalantari, M., & Rajabifard, A. (2015). An evaluation of integrating multisourced sensors for disaster 
management. International Journal of Digital Earth, 8(9), 727–749. doi:10.1080/17538947.2014.927537
Alamdar, F., Kalantari, M., & Rajabifard, A. (2016). Towards multi-agency sensor information integration for disaster 
management. Computers, Environment and Urban Systems, 56, 68–85. doi:10.1016/j.compenvurbsys.2015.11.005
279

Compilation of References
Alemdar, H., & Ersoy, C. (2010). Wireless sensor networks for healthcare: A survey. Computer Networks, 54(15), 
2688–2710. doi:10.1016/j.comnet.2010.05.003
Alexander, D. E. (2014). Social media in disaster risk reduction and crisis management. Science and Engineering Ethics, 
20(3), 717–733. doi:10.1007/s11948-013-9502-z PMID:24306994
Aly, M., Pruhs, K., & Chrysanthis, P. K. (2006). Kddcs: A load-balanced in-network data-centric storage scheme for 
sensor networks. Proceedings of CIKM, 317–326. doi:10.1145/1183614.1183662
Amazon. (2016). Amazon Prime Air. Retrieved from: http://www.amazon.com/b?node=8037720011
American Red Cross. (2015). Drones for Disaster Response and Relief Operations. Retrieved from: https://www.zurichna.
com/en/search?q=Drones+for+Disaster+Response+and+Relief+Operations&page=2#
An Analytical Overview. (2007). Asian Disaster Reduction Center.
Andel, T. R., & Yasinsac, A. (2006). On the Credibility of Manet Simulations. Computer, 37(7), 48–54. doi:10.1109/
MC.2006.242
Anita, , Singh, R., Choudhury, S., & Singh, B. (2015). Wireless Disaster Monitoring and Management System for Dams. 
Procedia Computer Science., 48, 381–386. doi:10.1016/j.procs.2015.04.197
Antoniou & van Harmelen. (2004). A Semantic Web Primer (Cooperative Information Systems). The MIT Press.
Aomumpai, S., Kondee, K., Prommak, C., & Kaemarungsi, K. (2013). Optimal placement of reference nodes for wireless 
indoor positioning systems. IEEE 11th International Conference on ECTI-CON, 1–6.
Appleby, L. (2013). Connecting the last mile: The role of communications in the great East Japan earthquake. London: 
Internews.
ArcGIS. (2012). GIS Tool. Retrieved from https://www.arcgis.com/features/index.html
Arfeen, S. U., Kazi, A. W., Memon, J. M., & Hyder, S. I. (2007). Innovative Algorithms and Techniques in Automation, 
Industrial Electronics and Telecommunications. Performance Evaluation of MANET Routing Protocols Using Scenario 
Based Mobility Models. Innovative Algorithms and Techniques in Automation, Industrial Electronics and Telecommu-
nication (pp. 419-424). Springer.
Armbrust, Fox, Griffith, Joseph, Katz, Konwinski, … Zaharia. (2010). A view of cloud computing. Communications 
of the ACM, 53(4), 50–58.
Aschenbruck, N., Frank, M., Martini, P., & Tölle, J. (2004). Human Mobility in MANET Disaster Area Simulation 
– A realistic Approach. Paper presented at IEEE International Conference on Local Computer Network, Tampa, FL 
doi:10.1109/LCN.2004.64
Atzori, L., Iera, A., & Morabito, G. (2010). The internet of things: A survey. Computer Networks, 54(15), 2787–2805. 
doi:10.1016/j.comnet.2010.05.010
Atzori, L., Iera, A., Morabito, G., & Nitti, M. (2012). The social internet of things (siot)–when social networks meet 
the internet of things: Concept, architecture and network characterization. Computer Networks, 56(16), 3594–3608. 
doi:10.1016/j.comnet.2012.07.010
Bahl, P., & Padmanabhan, V. (2000). RADAR: An in-building RF-based user location and tracking system. IEEE IN-
FOCOM 2000, 2, 775–784.
280

Compilation of References
Bai, M., Zhao, X., Hou, Z. G., & Tan, M. (2007, April). A wireless sensor network used in coal mines. In 2007 IEEE 
International Conference on Networking, Sensing and Control (pp. 319-323). IEEE. doi:10.1109/ICNSC.2007.372798
Bandyopadhyay, L. K., Chaulya, S. K., & Mishra, P. K. (2010). Wireless communication in underground mines: RFID-
based sensor networking. Springer Publishing Company. doi:10.1007/978-0-387-98165-9
Bandyopadhyay, L. K., Chaulya, S. K., Mishra, P. K., Choure, A., & Baveja, B. M. (2009). Wireless information and 
safety system for mines. Journal of Scientific and Industrial Research, 68(2), 107–117.
Barkand, T. D., Damiano, N. W., & Shumaker, W. A. (2006, October). Through-the-earth, two-way, mine emergency, 
voice communication systems. In Conference Record of the 2006 IEEE Industry Applications Conference Forty-First 
IAS Annual Meeting (vol. 2, pp. 955-958). IEEE. doi:10.1109/IAS.2006.256640
Barnaghi, P., Meissner, S., Presser, M., & Moessner, K. (2009). Sense and Sensability: Semantic Data Modelling for 
Sensor Networks. Proceedings of ICT-MobileSummit Conference RDF Schema (RDF-S). Retrieved from http://www.
w3.org/TR/rdf-schema/
Bawden, D., & Robinson, L. (2009). The dark side of information: Overload, anxiety and other paradoxes and patholo-
gies. Journal of Information Science, 35(2), 180–191. doi:10.1177/0165551508095781
Beatty, P. (2014, May 5). Water Quality Sonde Detects Tsunami Signal Over 4,000 Miles Away. Retrieved from https://
www.ysi.com/ysi-blog/water-blogged-blog/2014/05/water-quality-sonde-detects-tsunami-signal-over-4-000-miles-away/
Becker, H., Naaman, M., & Gravano, L. (2009). Event identification in social media. Twelfth International Workshop 
on the Web and Databases.
Bekkelien, A., Deriaz, M., & Marchand-Maillet, S. (2012). Bluetooth indoor positioning (Master’s thesis). University 
of Geneva.
Bellavista, P., Kupper, A., & Helal, S. (2008). Location-based services: Back to the future. IEEE Pervasive Computing 
/ IEEE Computer Society [and] IEEE Communications Society, 7(2), 85–89. doi:10.1109/MPRV.2008.34
Berners-Lee, T., Hendler, J., & Lassila, O. (2001, May). The semantic web. Scientific American, 284(5), 28–37. 
doi:10.1038/scientificamerican0501-34 PMID:11323639
Berthon, P. R., Pitt, L. F., Plangger, K., & Shapiro, D. (2012). Marketing meets Web 2.0, social media, and creative 
consumers: Implications for international marketing strategy. Business Horizons, 55(3), 261–271. doi:10.1016/j.
bushor.2012.01.007
Bertot, J. C., Jaeger, P. T., & Hansen, D. (2012). The impact of polices on government social media usage: Issues, chal-
lenges, and recommendations. Government Information Quarterly, 29(1), 30–40. doi:10.1016/j.giq.2011.04.004
Bhat, A. S., Raghavendra, B., & Kumar, G. N. (2013). Enhanced passive RFID based disaster management for coal min-
ers. International Journal of Future Computer and Communication, 2(5), 476–480. doi:10.7763/IJFCC.2013.V2.209
Bhosle, A. S., & Gavhane, L. M. (2016). Forest disaster management with wireless sensor network. Proc of Inter-
national Conference on Electrical, Electronics, and Optimization Techniques (ICEEOT), 287-289. doi:10.1109/
ICEEOT.2016.7755194
Blywis, B., Günes, M., Juraschek, F., Hahm, O., & Schmittberger, N. (2011). Properties and Topology of DES-Testbed 
(2nd ed.). Telematic and Computer System. Freie Universitát Berlin.
281

Compilation of References
Board, O. S., & National Research Council. (2011). Tsunami warning and preparedness: an assessment of the us tsu-
nami program and the nation’s preparedness efforts. National Academies Press. Retrieved from http://www.nap.edu/
read/12628/chapter/7#153/
BonnMotion Developers. (2013). BonnMotion - A Mobility ScenarioGeneration and Analysis Tool. Available at http://
bonnmotion.net.cs.uni-bonn.de/
Botts, M., et al. (2007). OGC Sensor Web Enablement: Overview and High Level Architecture (OGC 07-165). Open 
Geospatial Consortium White Research.
Boyd, S., & Vandenberghe, L. (2004, March). Convex Optimization. Cambridge, UK: Cambridge University Press.
Boyle, A. (2012). The US and its UAVs: A Cost Benefit Analysis. American Security Project. Retrieved from http://www.
americansecurityproject.org/the-us-and-its-uavs-a-cost-benefit-analysis/
Brief, C. (2015, Jan 16). Explainer: How do scientists measure global temperature? Retrieved from https://www.car-
bonbrief.org/explainer-how-do-scientists-measure-global-temperature
Brnich, M. J., Kowalski-Trakofler, K. M., & Brune, J. (2010). Underground coal mine disasters 1900-2010: Events, 
responses, and a look to the future. Extracting the Science: A Century of Mining Research, 363-373.
Brunato, M., & Battiti, R. (2005). Statistical learning theory for location fingerprinting in wireless LANs. Computer 
Networks, 47(6), 825–845. doi:10.1016/j.comnet.2004.09.004
Buhler, P., & Vidal, J. M. (2005). Towards Adaptive Workflow Enactment Using Multiagent Systems (Vol. 6). Information 
Technology and Management Journal.
Burgess, J., Gallagher, B., Jensen, D., & Levine, B. N. (2006). MaxProp: Routing for Vehicle-Based Disruption-Tolerant 
Networks. Proceedings of INFOCOM, 2006, 1–11.
Busanelli, S., Ferrari, G., & Gruppini, R. (2012). Recursive analytical performance evaluation of broadcast protocols 
with silencing: Application to VANETs. EURASIP Journal on Wireless Communications and Networking, 10, 1–21.
Campbell, DePoy, Dillinger, & Young. (2003). Sustainable security for infrastructure SCADA. Albuquerque, NM: Sandia 
National Laboratories. Retrieved from www.sandia.gov/scada/documents/SustainableSecurity.pdf
Carrara, A., Guzzetti, F., Cardinali, M., & Reichenbach, P. (1999). Use of GIS Technology in the Prediction and Moni-
toring of Landslide Hazard. Natural Hazards, 20(2/3), 117–135. doi:10.1023/A:1008097111310
Castillo, C. (2016). Big Crisis Data: Social Media in Disasters and Time-Critical Situations. Cambridge University 
Press. doi:10.1017/CBO9781316476840
Castillo-Effer, Quintela, Moreno, Jordan, & Westhoff. (2004). Wireless sensor networks for flash-flood alerting. In Devices 
Circuits and Systems 2004. Proceedings of the Fifth IEEE International Caracas Conference on (pp. 142–146). IEEE.
Chang, J. H., & Tassiulas, L. (2004). Maximum lifetime routing in wireless sensor networks. IEEE/ACM Transactions 
on Networking, 12(4), 609–619. doi:10.1109/TNET.2004.833122
Changqing, Li, Qiu, Awada, & Li. (2012). Big data processing in cloud computing environments. 12th International 
Symposium on Pervasive Systems Algorithms and Networks, 17–23.
Chang, V. (2015). Towards a Big Data system disaster recovery in a Private Cloud. Ad Hoc Networks, 35, 65–82. 
doi:10.1016/j.adhoc.2015.07.012
282

Compilation of References
Chaudhuri, S. (2012). What Next? A Half-Dozen Data Management Research Goals for Big Data and the Cloud. Proc. 
31st Symp. Princ. Database Syst., 1–4.
Chehri, A., Farjow, W., Mouftah, H. T., & Fernando, X. (2011, May). Design of wireless sensor network for mine safety 
monitoring. In 2011 24th Canadian Conference on Electrical and Computer Engineering (CCECE), (pp. 1532-1535). 
IEEE. doi:10.1109/CCECE.2011.6030722
Chehri, A., Fortier, P., & Tardif, P. M. (2009). UWB-based sensor networks for localization in mining environments. Ad 
Hoc Networks, 7(5), 987–1000. doi:10.1016/j.adhoc.2008.08.007
Chen, Y., Lymberopoulos, D., Liu, J., & Priyantha, B. (2012). FM-based indoor localization. Proceedings of the 10th 
ACM international conference on Mobile systems, applications, and services, 169–182.
Chen, D., Liu, Z., Wang, L., Dou, M., Chen, J., & Li, H. (2013). Natural Disaster Monitoring with Wireless Sensor 
Networks: A Case Study of Data-intensive Applications upon Low-Cost Scalable Systems. Mobile Networks and Ap-
plications, 18(5), 651–663. doi:10.1007/s11036-013-0456-9
Chen, L., Wu, J., & Lai, M. (2006). The Evolution of Natural Disaster Management System in Taiwan. Journal of the 
Chinese Institute of Engineering, 29(4), 633–638. doi:10.1080/02533839.2006.9671159
Chen, N., Wang, K., Xiao, C., & Gong, J. (2014). A heterogeneous sensor web node meta-model for the management 
of a flood monitoring system. Environmental Modelling & Software, 54, 222–237. doi:10.1016/j.envsoft.2014.01.014
Chen, X., Kong, J., Guo, Y., & Chen, X. (2014). An empirical study of indoor localization algorithms with densely 
deployed APs. IEEE Global Communications Conference, 517–522. doi:10.1109/GLOCOM.2014.7036860
Chew, C., & Eysenbach, G. (2010). Pandemics in the Age of Twitter: Content Analysis of Tweets during the 2009 H1N1 
Outbreak. PLoS ONE, 5(11), e14118. doi:10.1371/journal.pone.0014118 PMID:21124761
Chun-Pin, T., & Chen, C.-W. (2012). Natural disaster management mechanisms for probabilistic earthquake loss. Natural 
Hazards, 60(3), 1055–1063. doi:10.1007/s11069-011-9889-2
Clausen & Jacquet. (2003). Optimized Link State Routing Protocol (OLSR). IETF, RFC 3626.
Coastal Environment Systems. (n.d.). Ice Stations. Retrieved from http://www.coastalenvironmental.com/ice-stations.shtml
Commonwealth of Australia, Bureau of Meterology. (2017). Deep Ocean Tsunami Detection Buoys. Retrieved from 
http://www.bom.gov.au/tsunami/about/detection_buoys.shtml
Conceição, L., & Curado, M. (2013). Modelling Mobility Based on Human Behaviour in Disaster Areas. International 
Conference of Wired/Wireless Internet Communication, Saint-Petersburg, Russia. doi:10.1007/978-3-642-38401-1_5
Conti, M., & Giordano, S. (2015). Mobile Ad Hoc Networking: Milestones, Challenges, and New Research Directions. 
IEEE Communications Magazine, 52(1), 85–96. doi:10.1109/MCOM.2014.6710069
Corcoran, M. (2014). Drone journalism: Newsgathering applications of Unmanned Aerial Vehicles (UAVs) in covering 
conflict, civil unrest and disaster. Retrieved from: http://www.flinders.edu.au/ehl/fms/law_files/Drone%20Journalism%20
During%20Conflict,%20Civil%20Unrest%20and%20Disasters%20March%201%202014.pdf
C-temp. (2012). Quality temperature sensing products. Retrieved from http://www.c-temp.com/
Currion, P. (2010). “If all You Have is a Hammer” - How Useful is Humanitarian Crowdsourcing? Retrieved from http://
www.crowdsourcing.org/document/if-all-you-have-is-a-hammer---how-useful-is-humanitarian-crowdsourcing/3533
283

Compilation of References
Czyzewski, A. (2012). Project investigates potential of UAVs for disaster response. The Engineer. Retrieved from: http://
www.theengineer.co.uk/project-investigates-potential-of-uavs-for-disaster-response/
Daoud, M., Farjow, W., & Fernando, X. (2011, May). A novel diagnostic system for adding reliability to communication 
networks in underground mines. In Electrical and Computer Engineering (CCECE), 2011 24th Canadian Conference 
on (pp. 1342-1346). IEEE. doi:10.1109/CCECE.2011.6030681
Das, S. R., Castañeda, R., & Yan, J. (2000). Simulation-based performance evaluation of mobile ad hoc Networks. Mobile 
Networks and Applications, 5(3), 179–189. doi:10.1023/A:1019108612308
David, C. C., Ong, J. C., & Legara, E. F. T. (2016). Tweeting Supertyphoon Haiyan: Evolving Functions of Twitter 
during and after a Disaster Event. PLoS ONE, 11(3), e0150190. doi:10.1371/journal.pone.0150190 PMID:27019425
Davidson Euan, M., & Stephen, D. J. (2006). Applying multi-agent system technology in practice: Automated manage-
ment and analysis of SCADA and digital fault recorder data. Power Systems IEEE Transactions on, 21(2), 559–567. 
doi:10.1109/TPWRS.2006.873109
Deepak, Nepal, Ranjan, & Chen. (2016). A dynamic prime number based efficient security mechanism for big sensing 
data streams. Journal of Computer and System Sciences.
Delogne, P. (1991). EM propagation in tunnels. IEEE Transactions on Antennas and Propagation, 39(3), 401–406. 
doi:10.1109/8.76340
Devasena, A., & Sowmya, B. (2015). Wireless Sensor Network in Disaster Management. Indian Journal of Science and 
Technology, 8(15). doi:10.17485/ijst/2015/v8i15/74191
Disaster Management in India. (2017). Government of India, Ministry of Home Affair.
Disaster Management System Sri Lanka. (2017). Retrieved from https://online.desinventar.org/desinventar/#LKA-
1250695608-srilanka_historic_inventory_of_disasters
Doan, S., Vo, B.-K. H., & Collier, N. (2011). An analysis of Twitter messages in the 2011 Tohoku Earthquake. Paper 
presented at the International Conference on Electronic Healthcare.
Dohare, Y. S., Maity, T., Das, P. S., & Paul, P. S. (2015). Wireless communication and environment monitoring in un-
derground coal mines–review. IETE Technical Review, 32(2), 140–150. doi:10.1080/02564602.2014.995142
Dozolme, P. (2016, August). What are the most common mining accidents? Thousands of miners die from mining acci-
dents each year. The Balance. Retrieved October 13, 2016, from https://www.thebalance.com/most-common-accidents-
occurring-in-the-mining-industry-2367335
Durkin, J. (1984). Apparent earth conductivity over coal mines as estimated from through-the-earth electromagnetic 
transmission tests. US Department of the Interior, Bureau of Mines.
Early Warning Sub-Committee of the Inter-Ministerial Committee on International Cooperation for Disaster Reduction. 
(2006). Government of Japan.
EATON. (n.d.). Extreme Temperature Sensors. Retrieved from http://www.cooperindustries.com/content/public/en/
lighting/controls/products/occupancy_sensors/ext_temp.html
Eder, J., & Gruber, W. (2002). A Meta Model for Structured Workflows Supporting Workflow Transformations. Proceed-
ings of the 6th East European Conference on Advances in Databases and Information Systems, 326-339. doi:10.1007/3-
540-45710-0_26
Eisenstein, J. (2013). What to do about bad language on the internet. Proceedings of NAACL-HLT 2013, 359–369.
284

Compilation of References
El-Nasr, M. A., & Shaban, H. (2015). Low-Power and reliable communications for UWB-Based wireless monitoring 
sensor networks in underground mine tunnels. International Journal of Distributed Sensor Networks, 2015, 48.
El-Sayed, M., Mukhopadhyay, A., Urrutia-Valdes, C., & Zhao, Z. J. (2011). Mobile data explosion: Monetizing the op-
portunity through dynamic policies and QoS pipes. Bell Labs Tech. J., 16(2), 79–99. doi:10.1002/bltj.20504
Emslie, A., Lagace, R., & Strong, P. (1975, March). Theory of the propagation of UHF radio waves in coal mine tunnels. 
IEEE Transactions on Antennas and Propagation, 23(2), 192–205. doi:10.1109/TAP.1975.1141041
Exergen. (2014). Extreme Sensor Delivers Accurate Temperature Measurement in Severe Temperature, Weather, And 
Other Environmental Conditions. Retrieved from http://www.exergenglobal.com/index.php/en/exergen-global/news/2-
ukategorisert/131-press-release-extreme-sensor
FAA (Federal Aviation Administration). (2016). FAA Aerospace Forecast: Fiscal Years 2016-2036. FAA. Retrieved 
from: http://www.faa.gov/data_research/aviation/aerospace_forecasts/media/FY2016-36_FAA_Aerospace_Forecast.pdf
Fajardo, J. T. B., Yasumoto, K., Shibata, N., Sun, W., & Ito, M. (2012). DTN-based data aggregation for timely infor-
mation collection in disaster areas. In Proceedings of 2012 IEEE 8th International Conference on Wireless and Mobile 
Computing, Networking and Communications (pp. 333-340). doi:10.1109/WiMOB.2012.6379095
Fang, S. H., Wang, C. H., Huang, T. Y., Yang, C. H., & Chen, Y. S. (2012). An enhanced ZigBee indoor positioning system 
with an ensemble approach. IEEE Communications Letters, 16(4), 564–567. doi:10.1109/LCOMM.2012.022112.120131
Farjow, W. (2012a). Cross layer optimizations of integrated networks in underground mines (Doctoral Dissertation). 
Ryerson University, Canada.
Farjow, W., & Fernando, X. (2012b, September). System and method to control amplifier gain in a radiating line com-
munication system. Canadian Patent, serial number 2789768.
Farjow, W., Raahemifar, K., & Fernando, X. (2015, October). Novel wireless channels characterization model for under-
ground mines. Applied Mathematical Modelling, 39(19), 5997–6007. doi:10.1016/j.apm.2015.01.043
Farreras, S., Ortiz, M., & Gonzalez, J. (2007). Steps Towards the Implementation of a Tsunami Detection, Warning, 
Mitigation and Preparedness Program for Southwestern Coastal Areas of Mexico. Pure and Applied Geophysics, 164(2-
3), 605–616. doi:10.1007/s00024-006-0175-2
Fazio, M., Celesti, A., Puliafito, A., & Villari, M. (2015). Big Data Storage in the Cloud for Smart Environment Moni-
toring, Procedia. Computer Science, 52, 500–506.
Feldmann, S., Kyamakya, K., Zapater, A., & Lue, Z. (2003). An Indoor Bluetooth-Based Positioning System: Concept. 
Implementation and Experimental Evaluation. International Conference on Wireless Networks, 109–113.
Fischer, E., & Reuber, A. R. (2011). Social interaction via new social media:(How) can interactions on Twitter affect 
effectual thinking and behavior? Journal of Business Venturing, 26(1), 1–18. doi:10.1016/j.jbusvent.2010.09.002
Fogue, M., Garrido, P., Martinez, F. J., Cano, J. C., Calafate, C. T., & Manzoni, P. (2012). A Realistic Simulation Frame-
work for Vehicular Networks. Paper presented at International ICST Conference on Simulation Tools and Techniques, 
Desenzano del Garda, Italy. doi:10.4108/icst.simutools.2012.247682
Forooshani, A. E., Bashir, S., Michelson, D. G., & Noghanian, S. (2013). A survey of wireless communications and propa-
gation modeling in underground mines. IEEE Communications Surveys and Tutorials, 15(4), 1524–1545. doi:10.1109/
SURV.2013.031413.00130
285

Compilation of References
Frank, F., & Burghardt, P. (2007). Agent-based systems for disaster management. Communications of the ACM, 50(3), 
41–42. doi:10.1145/1226736.1226763
Frielos, D. (2007). Xstrata mines RFID’s benefits. RFID Journal.
Fudenberg, D., & Tirole, J. (1991). Game Theory. Cambridge, MA: MIT Press.
Future Electronics. (n.d.). Temperature Sensor. Retrieved from http://www.futureelectronics.com/en/sensors/temperature.
aspx
Galton, A., & Worboys, M. (2011). An ontology of information for emergency management. Int. Conf. Cris. Response 
Manag., 8, 1– 10.
GAO (United States Government Accountability Office). (2013). Defense Acquisitions: Assessments of Selected Weapon 
Programs. GAO. Retrieved from: http://www.gao.gov/assets/660/653379.pdf
García-Campos, J. M., Sánchez-García, J., Reina, D. G., Toral, S. L., & Barrero, F. (2015). Evaluation of Dissimilarity-
based Probabilistic Broadcasting Algorithms in VANETs Urban Scenarios. Paper presented at International Conference 
on Developments in eSystems Engineering, Dubai, UAE.
García-Campos, J. M., Sánchez-García, J., Reina, D. G., Toral, S. L., & Barrero, F. (2016). An evaluation methodology 
for reliable simulation based studies of routing protocols in VANETs. Simulation Modelling Practice and Theory, 66, 
139–165. doi:10.1016/j.simpat.2016.04.002
Geller, T. (2007). Imaging the World: The State of Online Mapping. IEEE Computer Graphics and Applications, 27(2), 
8–13. doi:10.1109/MCG.2007.39 PMID:17388197
GhadakSaz, Amini, Porkar, & Gheisari. (2012). A Design- Implement and Compare two proposed sensor data’s storages 
Named SemHD and SSW. International Geoinformatics Research and Development Journal, 3(2).
Ghaddar, M., Nedil, M., Mabrouk, I. B., & Talbi, L. (2016). Multiple-input multiple-output beam-space for high-speed 
wireless communication in underground mine. IET Microwaves, Antennas & Propagation, 10(1), 8–15.
Ghauri, F. U. D., Rehman, S. U., Yasir, M., & Asghar, S. (2010). Multi agent based decision support system for priori-
tized emergency fire evacuation. Proceeding of 4th International Conference on New Trends in Information Science and 
Service Science (NISS).
Gheisari & Abadi. (2011). Evaluation methods on sensor data storages in energy. CEIT2011.
Gheisari & Abadi. (2011). Evaluation of two known methods in energy parameter. 3rd National Conference on computer 
engineering and information technology.
Gheisari, Movassagh, Qin, Yong, Tao, Zhang, & Shen. (2016). NSSSD: A New Semantic Hierarchical Storage for Sen-
sor Data. IEEE 20th International Conference on Computer Supported Cooperative Work in Design (CSCWD 2016), 
Nanchang, China.
Gheisari, Porkar, & Zadeh. (2012). A New semantic Sensor Data Storage. ICCSET 2012, Zurich, Switzerland.
Gheisari, Porkar, SharifZadeh, & Moghaddam. (2012). A New semantic Sensor Data Storage. ICCSET 2012, Zurich, 
Switzerland,
Gheisari. (2012). Design, Implementation, and Evaluation of SemHD: A New Semantic Hierarchical Sensor Data Stor-
age. Indian J. Innovations Dev., 1(3).
286

Compilation of References
Gheisari, M., & Bagheri, A. R. (2011). Evaluation two methods on sensor data storage in total data. 5th symposium on 
advanced technology.
Ghobadi, C., Shepherd, P., & Pennock, S.R. (1998). 2D ray-tracing model for indoor radio propagation at millimetre 
frequencies, and the study of diversity techniques. IEE Proceedings on Microwaves, Antennas and Propagation, 145, 
349–353.
Ghosh, N. (2014, Dec 22). Tsunami early warning systems. Retrieved from http://www.thestar.com.my/news/na-
tion/2014/12/22/tsunami-early-warning-systems/
Gimpel, K., Schneider, N., O’Connor, B., Das, D., Mills, D., Eisenstein, J., … Smith, N. (2011). Part-of-speech tag-
ging for Twitter: Annotation, features, and experiments. Proceedings of the 49th Annual Meeting of the Association for 
Computational Linguistics: Human Language Technologies: Short papers, 2, 42–47.
Gizaw, B. T., & Gümüş, A. T. (2016). Humanitarian Relief Supply Chain Performance Evaluation: A Literature Review. 
International Journal of Marketing Studies, 8(2), 105. doi:10.5539/ijms.v8n2p105
Goldman, O. (2011). The globalization of terror attacks. Terrorism and Political Violence, 23(1), 31–59. doi:10.1080/
09546553.2010.514776
González-Díez, A., Fernández-Maroto, G., Doughty, M. W., Díaz de Terán, J. R., Bruschi, V., Cardenal, J., & Delgado, 
J. et al. (2014). Development of a methodological approach for the accurate measurement of slope changes due to land-
slides, using digital photogrammetry. Landslides, 11(4), 615–628. doi:10.1007/s10346-013-0413-5
Grayson, L., Bumbico, A., Cohn, S., Donahue, A., Harvey, J., Kohler, J., & Webb, H. (2006). Improving mine safety 
technology and training: Establishing US global leadership. Mine Safety Technology and Training Commission, Na-
tional Mining Association.
Gretzel, U. (2015). 9 Web 2.0 and 3.0. Communication and Technology, 5, 181.
Grilli, S. T., Grosdidier, S., & Guérin, C. A. (2016). Tsunami Detection by High-Frequency Radar Beyond the Continental 
Shelf. Appl. Geophys., 173(12), 3895–3934. doi:10.1007/s00024-015-1193-8
Griswold, W., Shanahan, P., Brown, S., Boyer, R., Ratto, M., Shapiro, R., & Truong, T. (2004). ActiveCampus: Experi-
ments in community-oriented ubiquitous computing. Computer, 37(10), 73–81. doi:10.1109/MC.2004.149
Grolinger, K., Brown, K., & Capretz, M. (2011). From Glossaries to Ontologies: Disaster Management Domain. Aca-
demic Press.
Gu, B., Dong, M., Zhang, C., Liu, Z., & Tanaka, Y. (2017, January). Real-Time Pricing for On-Demand Bandwidth 
Reservation in SDN-Enabled Networks. In Proceedings of 14th Annual IEEE Consumer Communications & Network-
ing Conference.
Gu, B., Yamori, K., & Tanaka, Y. (2012a, February). Auction-based Resource Allocation for Wireless Local Area Net-
works in Metropolitan Areas. In Proceedings of 14th International Conference on Advanced Communication Technology 
(pp. 470-474).
Gu, B., Yamori, K., & Tanaka, Y. (2014, December). Integration of time-dependent pricing with transmission rate control 
for flattening out peak-time demand. In Proceedings of 2014 International Conference and Workshop on the Network 
of the Future (pp. 1-5). doi:10.1109/NOF.2014.7119765
Gu, B., Yamori, K., Xu, S., & Tanaka, Y. (2012b, April). A Game Theoretic Framework for Bandwidth Allocation and 
Pricing in Federated Wireless Networks. IEICE Transactions on Communications, E95-B(4), 1109–1116. doi:10.1587/
transcom.E95.B.1109
287

Compilation of References
Gu, B., Yamori, K., Xu, S., & Tanaka, Y. (2013a, February). An Incentive-Compatible Load Distribution Approach for 
Wireless Local Area Networks with Usage-Based Pricing. IEICE Transactions on Communications, E96-B(2), 451–458. 
doi:10.1587/transcom.E96.B.451
Gu, B., Yamori, K., Xu, S., & Tanaka, Y. (2013b, July). Multi-Stage Non-Cooperative Game for Pricing and Connection 
Admission Control in Wireless Local Area Networks. IEICE Transactions on Communications, E96-B(7), 1986–1996. 
doi:10.1587/transcom.E96.B.1986
Gu, B., Zhang, C., Yamori, K., & Tanaka, Y. (2012, December). Utility-Based Load Distribution for QoS Provisioning 
and Utility Maximization in Wireless Random Access Networks. In Proceedings of 2nd International Conference on 
Computer Science and Network Technology (pp. 406-410). doi:10.1109/ICCSNT.2012.6525965
Gu, B., Zhang, C., Yamori, K., & Tanaka, Y. (2013a, August). A Greedy Algorithm for Connection Admission Control in 
Wireless Random Access Networks. In Proceedings of 19th Asia-Pacific Conference on Communications. doi:10.1109/
APCC.2013.6765989
Gu, B., Zhang, C., Yamori, K., & Tanaka, Y. (2013b, September). Distributed Connection Admission Control Integrated 
with Pricing for QoS Provisioning and Revenue Maximization in Wireless Random Access Networks. In Proceedings 
of 15th Asia-Pacific Network Operations and Management Symposium (pp. 1-5).
Gu, B., Zhang, C., Yamori, K., Zhou, Z., Liu, S., & Tanaka, Y. (2015a, August). Regulating Network Traffic by Exploiting 
the Price Elasticity of Demand in Wireless Random Access Networks. In Proceedings of 10th Asia-Pacific Symposium 
on Information and Telecommunication Technologies (pp.1-3). doi:10.1109/APSITT.2015.7217129
Gu, B., Zhang, C., Yamori, K., Zhou, Z., Liu, S., & Tanaka, Y. (2015b, November). Facilitating Incentive-Compatible 
Access Probability Selection in Wireless Random Access Networks. IEICE Transactions on Communications, E98-B(11), 
2280–2290. doi:10.1587/transcom.E98.B.2280
Gui, Y., Tao, Z., Wang, C., & Xie, X. (2011). Study on remote monitoring system for landslide hazard based on wireless 
sensor network and its application. J Coal Sci Eng China., 17(4), 464–468. doi:10.1007/s12404-011-0422-8
Gupta, A., Lamba, H., Kumaraguru, P., & Joshi, A. (2013). Faking sandy: characterizing and identifying fake im-
ages on twitter during hurricane sandy. Proceedings of the 22nd international conference on World Wide Web. 
doi:10.1145/2487788.2488033
Gye, H. (2013). Now that’s a special delivery: Domino’s builds DRONE to deliver pizzas by air and beat the traffic. 
Daily Mail. Retrieved from: http://www.dailymail.co.uk/news/article-2336324/Dominos-builds-DRONE-deliver-pizzas-
air-beat-traffic.html#ixzz44XJEkfMO
Haas, Halpern, & Li. (2006). Gossip-Based Ad Hoc Routing. IEEE/ACM Transaction on Networking, 14, 479-491.
Habiba, M., & Akhter, S. (2012). MAS workflow model and scheduling algorithm for disaster management system. 
Proceedings of Conference: Cloud Computing Technologies, Applications and Management (ICCCTAM), 164 - 173. 
doi:10.1109/ICCCTAM.2012.6488092
Habiba, M., & Akhter, S. (2013). A Cloud Based Natural Disaster Management System. Lecture Notes in Computer 
Science, 7861, 152–161. doi:10.1007/978-3-642-38027-3_16
Harle, R. (2013). A survey of indoor inertial positioning systems for pedestrians. IEEE Communications Surveys and 
Tutorials, 15(3), 1281–1293. doi:10.1109/SURV.2012.121912.00075
288

Compilation of References
Harras, K. A., & Almeroth, K. C. (2006). Inter-regional messenger scheduling in delay tolerant mobile networks. In 
Proceedings of the 2006 International Symposium on on World of Wireless, Mobile and Multimedia Networks (pp. 93-
102). doi:10.1109/WOWMOM.2006.53
Harris, A., Rahman, S., Hossain, F., Yarborough, L., Bagtzoglou, A. C., & Easson, G. (2007). Satellite-based flood 
modeling using TRMM-based rainfall products. Sensors (Basel, Switzerland), 7(12).
Ha, S., Sen, S., Joe-Wong, C., Im, Y., & Chiang, M. (2012). Tube: time-dependent pricing for mobile data. In Proceed-
ings of the ACM SIGCOMM 2012 conference on Applications, technologies, architectures, and protocols for computer 
communication (vol. 42, no. 4, pp. 247–258).
Hassan, N., Farjow, W. F., & Fernando, X. (2016). Optimization of leaky feeder slot spacing for better beam forming in 
mines and tunnels. International Journal of Communications, Network and System Sciences, 9(4), 77–89. doi:10.4236/
ijcns.2016.94007
Hazas, M., & Hopper, A. (2006). A. Broadband ultrasonic location systems for improved indoor positioning. IEEE 
Transactions on Mobile Computing, 5(5), 536–547. doi:10.1109/TMC.2006.57
He, D., Ma, M., Zhang, Y., Chen, C., & Bu, J. (2011). A strong user authentication scheme with smart cards for wireless 
communications. Computer Communications, 34(3), 367–374. doi:10.1016/j.comcom.2010.02.031
Heinzelman, W. (2000). Application-specific protocol architectures for wireless networks (Ph.D. dissertation). Mass. 
Inst. Technol., Cambridge, MA. Retrieved from http://protege.stanford.edu/
Henson, C., Sheth, A., Jain, P., & Rapoch, T. (2007). Video on the semantic sensor web. W3C Video on the Web Work-
shop. Retrieved from http://www.w3.org/2007/08/video/researchs.html
Henson, Pschorr, Sheth, & Thirunarayan. (2009). SemSOS: Semantic Sensor Observation Service. IEEE Computer Society.
Heverin, T., & Zach, L. (2010). Microblogging for Crisis Communication: Examination of Twitter Use in Response to 
a 2009 Violent Crisis in the Seattle-Tacoma, Washington, Area. ISCRAM.
Higuchi, K., Fujisawa, K., Asai, K., Pasuto, A., & Marcato, G. (n.d.). Application of new landslide monitoring technique 
using optical fiber sensor at Takisaka landslide, Japan. Academic Press.
Hill, D., & Wait, J. (1982). Theoretical noise and propagation models for through-the-earth communication. US Bureau 
of Mines.
Hiranandani, D., Obraczka, K., & García-Luna-Aceves, J. J. (2013). MANET protocol simulations considered harmful: 
The case for benchmarking. IEEE Wireless Communications, 20(4), 82–90. doi:10.1109/MWC.2013.6590054
Hiremath, B., & Kenchakkanavar, A. Y. (2016). An Alteration of the Web 1.0, Web 2.0 and Web 3.0: A Comparative 
Study. Imperial Journal of Interdisciplinary Research, 2(4).
Hong, X., Gerla, M., Pei, G., & Chiang, C.-C. (1999). A group mobility model for ad hoc wireless networks. Paper 
presented at International workshop on Modeling, analysis and simulation of wireless and mobile systems, Seattle, WA. 
doi:10.1145/313237.313248
Horita, F. E. A., et al. (2015). Development of a spatial decision support system for flood risk management in Brazil that 
combines volunteered geographic information with wireless sensor networks. Computers & Geosciences, 80, 84–94.
Houston, J. B., Hawthorne, J., Perreault, M. F., Park, E. H., Goldstein Hode, M., Halliwell, M. R., & McElderry, J. A. 
et al. (2015). Social media and disasters: A functional framework for social media use in disaster planning, response, 
and research. Disasters, 39(1), 1–22. doi:10.1111/disa.12092 PMID:25243593
289

Compilation of References
Hu Han, , & Wen, . (2014). Towards Scalable Systems for Big Data Analytics: A Technology Tutorial. IEEE Access, 2, 
652–687. doi:10.1109/ACCESS.2014.2332453
Hughes, A. L., & Palen, L. (2009). Twitter adoption and use in mass convergence and emergency events. International 
Journal of Emergency Management, 6(3-4), 248–260. doi:10.1504/IJEM.2009.031564
Huh, S., Lee, U., Shim, H., Park, J. B., & Noh, J. H. (2011, October). Development of an unmanned coal mining robot 
and a tele-operation system. In 2011 11th International Conference on Control, Automation and Systems (ICCAS) (pp. 
31-35). IEEE.
Hu, X., Shang, J., Gu, F., & Han, Q. (2015). Improving Wi-Fi Indoor Positioning via AP Sets Similarity and Semi-
Supervised Affinity Propagation Clustering. International Journal of Distributed Sensor Networks, 11(1), 109642. 
doi:10.1155/2015/109642
HW group. (n.d.). GSM Thermometer. Retrieved from http://www.hw-group.com/products/HWg-Ares/HWg-Ares_
GSM_sensors_en.html
Ilrina, S., Burke, M., Kiesler, S., & Kraut, R. (2010). Technology adoption and use in the aftermath of Hurricane Katrina 
in New Orleans. The American Behavioral Scientist, 53(8), 1228–1246. doi:10.1177/0002764209356252
Imran, M., Elbassouni, S., Castillo, C., Diaz, F., & Meier, P. (2013). Extracting information nuggets from disaster-related 
messages in social media. Proceedings of the 10th international ISCRAM Conference.
Indira, P., Kabita, S., & Chandrakant, M. (2015). Flood Prediction and Prevention through Wireless Sensor Networking 
(WSN): A Survey. International Journal of Computer Applications, 113(9).
INSARAG. (2015). International Search and Rescue Guidelines. Retrieved from http://www.insarag.org/en/methodol-
ogy/guidelines.html
Issam & Abdul-Nabi. (2012). On formula to compute primes and the nth prime. Applied Mathematical Science, 6(76), 
3751–3757.
Jafari & Gheisari. (2016). Automatic Text Summarization Using Fuzzy Inference. 22nd IEEE International Conference 
on Automation and Computing (ICAC 2016).
Jafarian, M., & Jaseemuddin, M. (2008, May). Routing of emergency data in a wireless sensor network for mines. In 
2008 IEEE International Conference on Communications (pp. 2813-2818). IEEE. doi:10.1109/ICC.2008.530
Jardosh, A., Belding-Royer, E., Almeroth, K., & Suri, S. (1999). Towards realistic mobility models for mobile ad hoc 
networks. Paper presented at International conference on Mobile computing and networking, Seattle, WA.
Jennings, N., Faratin, P., Parsons, A. R. L. S., Sierra, C., & Wooldridge, M. (2001). Automated negotiation: Prospects, methods 
and challenges. International Journal of Group Decision and Negotiation, 10(2), 199–215. doi:10.1023/A:1008746126376
Jensen, G. E. (2012). Key criteria for information quality in the use of online social media for emergency management 
in New Zealand. Victoria University of Wellington.
Jiang, L., Parekh, S., & Walrand, J. (2008, April) Time-dependent network pricing and bandwidth trading. In Proceed-
ings of IEEE/IFIP Netw. Oper. (pp. 193-200). doi:10.1109/NOMSW.2007.33
Jianguo, Z., Junyao, G., Kejie, L., Wei, L., & Shengjun, B. (2010, July). Embedded control system design for coal mine 
detect and rescue robot. In 3rd IEEE International Conference on Computer Science and Information Technology (ICC-
SIT), 2010 (vol. 6, pp. 64-68). IEEE. doi:10.1109/ICCSIT.2010.5563599
Johnson, Maltz, & Hu. (2004). The Dynamic Source Routing Protocol for Mobile Ad Hoc Networks. IETF, RFC 4728.
290

Compilation of References
Jong, E. C., Schafrik, S. J., Gilliland, E. S., & Weiss, C. J. (2016, April). A preliminary evaluations of a through-the-earth 
(TTE) communications system at an underground coal mine in eastern Kentucky. Mining Engineering, 68(4), 52–57. 
doi:10.19150/me.6548
JPL. (2017). Gravity recovery and Climatic experiment. Retrieved from http://www.jpl.nasa.gov/missions/gravity-
recovery-and-climate-experiment-grace/
Jurdak, Topes, & Baldi. (2004). A Framework for Modeling Sensor Networks. OOPSLA IVorhhop on Building Software 
for Pervasive Computing.
Jurdak, R., Lopes, C. V., & Baldi, P. (2004). A survey, classification and comparative analysis of medium access control 
protocols for ad hoc networks. IEEE Communications Surveys and Tutorials, 6(1), 2–16. doi:10.1109/COMST.2004.5342231
Kaigo, M. (2012). Social Media Usage During Disasters and Social Capital: Twitter and the Great East Japan Earthquake. 
Keio Communication Review, 34, 19–35.
Kamel Boulos, M. N., Sanfilippo, A. P., Corley, C. D., & Wheeler, S. (2010). Social Web Mining and Exploitation for 
Serious Applications: Technosocial Predictive Analytics and Related Technologies for Public Health, Environmental 
and National Security Surveillance. Computer Methods and Programs in Biomedicine, 100(1), 16–23. doi:10.1016/j.
cmpb.2010.02.007 PMID:20236725
Kaur, H., Sahni, V., & Bala, M. (2013). A Survey of Reactive, Proactive and Hybrid Routing Protocols in MANET: A 
Review. International Journal of Computer Science and Information Technologies, 4, 498–500.
Kavanaugh, A. L., Fox, E. A., Sheetz, S. D., Yang, S., Li, L. T., Shoemaker, D. J., & Xie, L. et al. (2012). Social media 
use by government: From the routine to the critical. Government Information Quarterly, 29(4), 480–491. doi:10.1016/j.
giq.2012.06.002
Kazusa, S. (2011). Disaster Management of Japan. Retrieved from Kochi University of Technology: http://management.
kochi-tech.ac.jp/PDF/IWPM/IWPM_Kazusa.pdf
Kerry, F. (1997). Charging and rate control for elastic traffic. European Transactions on Telecommunications., 8(1), 
33–37. doi:10.1002/ett.4460080106
Khadilkar, V., Kantarcioglu, M., Thuraisingham, B., & Castagna, P. (2012). Jena-HBase: A Distributed, Scalable and 
Efficient RDF Triple Store. 11th International Semantic Web Conference.
Kleisouris, K., & Martin, R. (2007). Parallel Algorithms for Bayesian Indoor Positioning Systems. IEEE International 
Conference on Parallel Processing, 15–15. doi:10.1109/ICPP.2007.64
Ko, Y.-B., & Vaidya, N. (2000). Location-Aided Routing (LAR) in mobile ad hoc networks. Wireless Networks, 6(4), 
307–321. doi:10.1023/A:1019106118419
Kraemer, J., Wiewiorra, L., & Weinhardt, C. (2013, October). Net neutrality: A progress report. In Proceedings of Tele-
commun. Policy (vol. 37, no. 9, pp. 794-813). doi:10.2139/ssrn.2344623
Kronfeld, M.J. (2011, July 5). Expert believe Cloud Computing will enhance disaster management. GSN Magazine.
Kumar, N., Panchariya, P. C., Srinath, K., & Prasad, P. B. (2013, September). Hybrid mine wide communication system 
for surveillance and safety of the miners in underground coal mines. In 2013 International Conference on Advanced 
Electronic Systems (ICAES) (pp. 262-266). IEEE. doi:10.1109/ICAES.2013.6659405
Kunz, N., & Reiner, G. (2012). A meta-analysis of humanitarian logistics research. Journal of Humanitarian Logistics 
and Supply Chain Management, 2(2), 116–147. doi:10.1108/20426741211260723
291

Compilation of References
Kurkowski, S., Camp, T., & Colagrosso, M. (2005). MANET Simulation Studies: The Incredibles. ACMs. Mobile 
Computing and Communications Review, 9(4), 50–61. doi:10.1145/1096166.1096174
Lafuente, M. (2016). Getting looped in to the web: Characterizing learning processes and educational responses. Inter-
active Learning Environments, 1–13.
Lakshmi, N. (2012). A joint network for disaster recovery and search and rescue operations. Computer Networks, 56(14), 
3347–3373. doi:10.1016/j.comnet.2012.05.012
Lander & Lesser. (1993). Understanding the role of negotiation in distributed search among heterogeneous agents. Pro-
ceedings of the Thirteenth International Joint Conference on Artificial Intelligence (IJCAI-93), 438-444.
Large, D., Ball, L., & Farstad, A. (1973). Radio transmission to and from underground coal mines-theory and measure-
ment. IEEE Transactions on Communications, 21(3), 194–202. doi:10.1109/TCOM.1973.1091650
Latonero, M., & Shklovski, I. (2011). Emergency management, Twitter, and social media evangelism. International 
Journal of Information Systems for Crisis Response and Management, 3(4), 67–86.
Lee, J., Ryu, J., Lee, S. J., & Kwon, T. T. (2010). Improved modeling of IEEE 802.11 a PHY through fine-grained 
measurements. Computer Networks, 54(4), 641–657. doi:10.1016/j.comnet.2009.08.003
Lee, S., Ha, K. N., & Lee, K. C. (2006). A pyroelectric infrared sensor-based indoor location-aware system for the smart 
home. IEEE Transactions on Consumer Electronics, 52(4), 1311–1317. doi:10.1109/TCE.2006.273150
Leiras, A., de Brito, I., Peres, E. Q., Bertazzo, T. R. R., & Yosthizaki, H. R. J. (2014). Literature review of humanitar-
ian logistics research: Trends and challenges. Journal of Humanitarian Logistics and Supply Chain Management, 4(1), 
95–130. doi:10.1108/JHLSCM-04-2012-0008
Lesser, V. R., & Corkill, D. D. (1983). The Distributed Vehicle Monitoring Testbed: A tool for investigating distributed 
problem solving networks. AI Magazine, 4(3).
Lewis, C. Xie, & Arpinar. (2006). Es3n: A Semantic Approach to Data Management in Sensor Networks. Semantic Sen-
sor network workshop, the 5th International Semantic Web Conference ISWC 2006, Athens, GA.
Li, C., Song, S. H., Zhang, J., & Letaief, K. B. (2012, April). Maximizing energy efficiency in wireless networks with 
a minimum average throughput requirement. In 2012 IEEE Wireless Communications and Networking Conference 
(WCNC) (pp. 1130-1134). IEEE. doi:10.1109/WCNC.2012.6213945
Li, L. L., Yang, S. F., Wang, L. Y., & Gao, X. M. (2011, March). The greenhouse environment monitoring system based 
on wireless sensor network technology. In Cyber Technology in Automation, Control, and Intelligent Systems (CYBER), 
2011 IEEE International Conference on (pp. 265-268). IEEE. doi:10.1109/CYBER.2011.6011806
Liénard, M., & Degauque, P. (2000). Natural wave propagation in mine environments. IEEE Transactions on Antennas 
and Propagation, 48(9), 1326–1339. doi:10.1109/8.898765
Li, H., Sun, L., Zhu, H., Lu, X., & Cheng, X. (2014). Achieving privacy preservation in WiFi fingerprint-based localiza-
tion. Proceedings of IEEE INFOCOM, 2337–2345. doi:10.1109/INFOCOM.2014.6848178
Li, M., & Zhu, H. (2013). Mobile Ad Hoc Networking. Experimental work on VANET in Mobile Ad Hoc Networking. Wiley.
Lim, C. H., Wan, Y., Ng, B. P., & See, C. (2007). A real-time indoor WiFi localization system utilizing smart antennas. 
IEEE Transactions on Consumer Electronics, 53(2), 618–622. doi:10.1109/TCE.2007.381737
292

Compilation of References
Lin, S. C., Akyildiz, I. F., Wang, P., & Sun, Z. (2015, July). Distributed cross-layer protocol design for magnetic induc-
tion communication in wireless underground sensor networks. IEEE Transactions on Wireless Communications, 14(7), 
4006–4019. doi:10.1109/TWC.2015.2415812
Lipa, B. J., Barrick, D. E., Bourg, J., & Nyden, B. B. (2006). HF radar detection of tsunamis. Journal of Oceanography, 
62(5), 705–716. doi:10.1007/s10872-006-0088-9
List, B., & Korherr, B. (2006). An evaluation of conceptual business process modeling languages. Proceedings of the 
2006 ACM Symposium on Applied Computing, 1532-1539.
Liu, B. F., Jin, Y., & Austin, L. L. (2013). The Tendency To Tell: Understanding Publics Communicative Responses 
To Crisis Information Form and Source. Journal of Public Relations Research, 25(1), 51–67. doi:10.1080/106272
6X.2013.739101
Liu, H., Darabi, H., Banerjee, P., & Liu, J. (2007). Survey of Wireless Indoor Positioning Techniques and Systems. IEEE 
Transactions on Systems, Man and Cybernetics. Part C, Applications and Reviews, 37(6), 1067–1080. doi:10.1109/
TSMCC.2007.905750
Liu, X., Zhou, M., Zhou, X., Fu, Z., & Wei, F. (2012). Joint inference of named entity recognition and normalization 
for tweets. Proceedings of the ACL.
Liyang, Wang, & Meng. (2005). Real-time forest fire detection with wireless sensor networks. Proceedings. 2005 Inter-
national Conference on Wireless Communications Networking and Mobile Computing, 2, 1214–1217.
Lo, K.-F. A., Yeh, H.-C., & Chen, S.-H. (2015). Landslide detection using satellite remote sensing imagery. International 
Journal of Development Research, 5(4), 4237–4241.
Lo, S.-W., Wu, J.-H., Lin, F.-P., & Hsu, C.-H. (2015). Visual sensing for urban flood monitoring. Sensors (Basel, Swit-
zerland), 15(8), 20006–20029. doi:10.3390/s150820006 PMID:26287201
Luna. (2017). Sensors and Systems. Retrieved from http://lunainc.com/applied-research/applied-research-technologies/
sensors-systems-2/
Lunden, I. (2010, January). Danish ISP TDC Preps IPO After Bundled-Music Success. Retrieved August 01, 2016, from 
https://gigaom.com/2010/01/15/419-danish-isp-tdc-preps-ipo-after-bundled-music-success/
MacKie-Mason, J. K., & Varian, H. (1995). Pricing the Internet. Cambridge, MA: MIT Press.
Madigan, D., Einahrawy, E., Martin, R., Ju, W. H., Krishnan, P., & Krishnakumar, A. S. (2005). Bayesian indoor posi-
tioning systems. Proceedings - IEEE INFOCOM, 2, 1217–1227.
Mahtab Hossain, A., Jin, Y., Soh, W. S., & Van, H. N. (2013, January). SSD: A robust RF location fingerprint address-
ing mobile devices heterogeneity. IEEE Transactions on Mobile Computing, 12(1), 65–77. doi:10.1109/TMC.2011.243
Mailey, C. (2013). Are UAS More Cost Effective that Manned Flights? AUVSI. Retrieved from www.auvsi.org
Makki, A., Siddig, A., Saad, M., & Bleakley, C. (2015). Survey of WiFi positioning using time-based techniques. Com-
puter Networks, 88, 218–233. doi:10.1016/j.comnet.2015.06.015
Maritime Journal. (2009, Feb 1). Instant feedback from tsunami warning system. Retrieved from http://www.maritime-
journal.com/news101/onboard-systems/safety,-survival-and training/instant_feedback_from_tsunami_warning_system/
Martin, R. (1999). Snort: Lightweight Intrusion Detection for Networks. LISA, 99(1), 229–238.
293

Compilation of References
Martin, D. J. (1984, May). Leaky-feeder radio communication: A historical review. In 34th IEEE Vehicular Technology 
Conference (vol. 34, pp. 25-30). IEEE. doi:10.1109/VTC.1984.1623231
MAU. (n.d.). Ice and Climate: Automatic Weather Stations on glaciers. Retrieved from http://www.projects.science.
uu.nl/iceclimate/aws/technical.php
Meier, P., & Munro, R. (2010). The unprecedented role of SMS in disaster response: Learning from Haiti. SAIS Review 
of International Affairs, 30(2), 91–103.
Mendona, D., & Wallace, W. A. (2004). Studying organizationally-situated improvisation in response to extreme events. 
International Journal of Mass Emergencies and Disasters, 22(2).
Mendoza, M., Poblete, B., & Castillo, C. (2010). Twitter under crisis: can we trust what we RT? Paper presented at the 
First Workshop on Social Media Analytics, Washington, DC. doi:10.1145/1964858.1964869
MIC White Paper. (2013, November). 東日本大震災における情報通信の状況. Retrieved August 01, 2016, from www.
soumu.go.jp/johotsusintokei/whitepaper/ja/h23/pdf/n0010000.pdf
Microsystems, B. (1999). First Atlantic crossing by an unmanned aircraft. Available at: http://www.barnardmicrosystems.
com/UAV/milestones/atlantic_crossing_1.html
Min-Yuan, C., & Wu, Y. (2013). Multi-agent-based data exchange platform for bridge disaster prevention: A case study 
in Taiwan. Natural Hazards, 69(1), 311–326. doi:10.1007/s11069-013-0708-9
Mishra, P. K., Shukla, S. K., Dutta, S., Chaulya, S. K., & Prasad, G. M. (2011). Detection of Landslide Using Wireless 
Sensor Networks. IEEE.
Mishra, P. K., Stewart, R. F., Bolic, M., & Yagoub, M. C. (2014). RFID in underground-mining service applications. 
IEEE Pervasive Computing / IEEE Computer Society [and] IEEE Communications Society, 13(1), 72–79. doi:10.1109/
MPRV.2014.14
Misra, P., Ostry, D., & Jha, S. (2009). Underground mine communication and tracking systems: A survey. Tech. Rep. 
UNSW-CSE-TR-0910, Univ. New South Wales.
Misra, P., Kanhere, S., Ostry, D., & Jha, S. (2010, April). Safety assurance and rescue communication systems in high-stress 
environments: A mining case study. IEEE Communications Magazine, 48(4), 66–73. doi:10.1109/MCOM.2010.5439078
Mizuno, O., Takashi, A., Yamamoto, S., & Asatani, K. (2013). Sustainable operation technologies for the mitigation 
information network in urban area. In Proceedings of Humanitarian Technology Conference (pp. 255-260). doi:10.1109/
R10-HTC.2013.6669051
Mohsenian-Rad, A. H., & Leon-Garcia, A. (2010, September). Optimal residential load control with price prediction in real-
time electricity pricing environments. IEEE Transactions on Smart Grid., 1(2), 120–133. doi:10.1109/TSG.2010.2055903
Moore, P., & Crossley, P. (1999). GPS applications in power systems. I. Introduction to GPS. Power Engineering Journal, 
13(1), 33–39. doi:10.1049/pe:19990110
Morelli, C., Nicoli, M., Rampa, V., & Spagnolini, U. (2007). Hidden Markov Models for Radio Localization in Mixed 
LOS/NLOS Conditions. IEEE Transactions on Signal Processing, 55(4), 1525–1542. doi:10.1109/TSP.2006.889978
Moridi, M. A., Kawamura, Y., Sharifzadeh, M., Chanda, E. K., Wagner, M., Jang, H., & Okawa, H. (2015). Develop-
ment of underground mine monitoring and communication system integrated ZigBee and GIS. International Journal of 
Mining Science and Technology, 25(5), 811–818. doi:10.1016/j.ijmst.2015.07.017
294

Compilation of References
Mousa, M., Zhang, X., & Claudel, C. (2016). Flash Flood Detection in Urban Cities Using Ultrasonic and Infrared Sen-
sors. IEEE Sensors Journal, 16(19), 7204–7216. doi:10.1109/JSEN.2016.2592359
Murphy, J. N., & Parkinson, H. E. (1978). Underground mine communications. Proceedings of the IEEE, 66(1), 26–50. 
doi:10.1109/PROC.1978.10836
Musaev, De Wang, & Pu. (2014). LITMUS: Landslide Detection by Integrating Multiple Sources. In S.R. Hiltz, M.S. Pfaff, 
L. Plotnick, & P.C. Shih (Eds.), Proceedings of the 11th International ISCRAM Conference, (pp. 677-86). Academic Press.
NASA. (2007). NASA and NOAA Fly Unmanned Aircraft into Hurricane Noel. Retrieved from http://www.nasa.gov/
centers/wallops/news/story105.html
National Institute of Ocean Technology. (n.d.). Ocean Observation Systems. Retrieved from https://www.niot.res.in
Nayar, R. (2015). Role of Web 3.0 in Service Innovation. In The Handbook of Service Innovation (pp. 253–280). Springer.
Nazarov, E. (2011). Emergency Response management in Japan. Final Research report, ASIAN Disaster Reduction 
Center, FY2011A Program. Retrieved from http://www.adrc.asia/aboutus/vrdata/finalreport/2011A_AZE_Emin_FRR.pdf
NDDB. (2006). Natural Disasters Data Book 2006, An Analytical Overview March 2007. Asian Disaster Reduction Center.
Ndoh, M., & Delisle, G. Y. (2004, September). Underground mines wireless propagation modeling. In Vehicular Technology 
Conference, 2004. VTC2004-Fall. 2004 IEEE 60th (Vol. 5, pp. 3584-3588). IEEE. doi:10.1109/VETECF.2004.1404732
Nehme Rimma, , Lim, Bertino, & Rundensteiner. (2009). StreamShield: a stream-centric approach towards security and 
privacy in data stream environments. In Proceedings of the 2009 ACM SIGMOD International Conference on Manage-
ment of data (pp. 1027–1030). ACM.
Nepal, S. J. Z. D. L., & Jang, J. (2011). A mobile and portable trusted computing platform. EURASIP Journal on Wire-
less Communications and Networking, 2011(1), 1–19. doi:10.1186/1687-1499-2011-75
NOAA National Server Stroms Laboratory. (n.d.). Nssl Research: Tornadoes. Retrieved from http://www.nssl.noaa.gov/
research/tornadoes/
NOAA National Server Stroms Laboratory. (n.d.). Tornado Detection. Retrieved from http://www.nssl.noaa.gov/educa-
tion/svrwx101/tornadoes/detection/
NOAA’s National Weather Service Flood Warning Systems Manual. (2012). U.S. Department of Commerce, National 
Oceanic and Atmospheric Administration National Weather Service.
Novak, T., Snyder, D. P., & Kohler, J. L. (2010). Postaccident mine communications and tracking systems. IEEE Trans-
actions on Industry Applications, 46(2), 712–719. doi:10.1109/TIA.2010.2040059
Nutter, R. (2007, September). Underground coal mine communications and tracking status SAGO plus one year. In In-
dustry Applications Conference, 2007. 42nd IAS Annual Meeting. Conference Record of the 2007 IEEE (pp. 2086-2089). 
New Orleans, LA: IEEE. doi:10.1109/07IAS.2007.315
Nutter, R. S., & Aldridge, M. D. (1988). Status of mine monitoring and communications. IEEE Transactions on Industry 
Applications, 24(5), 820–826. doi:10.1109/28.8986
OCHA (Office for the Coordination of Humanitarian Affairs). (2014). Unmanned aerial vehicles in humanitarian re-
sponse. OCHA Policy and Studies Series, Occasional Paper No 10. Retrieved from: https://docs.unocha.org/sites/dms/
Documents/Unmanned%20Aerial%20Vehicles%20in%20Humanitarian%20Response%20OCHA%20July%202014.pdf
295

Compilation of References
OCHA (Office for the Coordination of Humanitarian Affairs). (2016). Fiji: Severe Tropical Cyclone Winston, Situation 
Report No. 9 (as of 29 February 2016). Retrieved from: http://reliefweb.int/sites/reliefweb.int/files/resources/OCHA%20
TC%20Winston%20Situation%20Report%209.pdf
OCHA (Office for the Coordination of Humanitarian Affairs). (2016a). Fiji: Severe Tropical Cyclone Winston, Situation 
Report N0. 2 (as of 22 February 2016). Retrieved from: http://reliefweb.int/report/fiji/fiji-severe-tropical-cyclone-winston-
situation-report-no-2-22-february-2016
ODIM. (2011, Jul 11). SeaCycler. Retrieved from http://www.brooke-ocean.com/seacycler.html
Odli, Izhar, Razak, Yusuf, Zakarya, Saad, & Nor. (2016). Development of portable water level sensor for flood manage-
ment system. ARPN Journal of Engineering and Applied Sciences, 11.
Odlyzko, A., Arnaud, B. S., Stallman, E., & Weinberg, M. (2012, May). Know your limits: Considering the role of data 
caps and usage based billing in internet access service. Retrieved August 01, 2016, from http://www.publicknowledge.
org/files/UBP%20paper%20FINAL.pdf
Oh, O., Agrawal, M., & Rao, H. R. (2013). Community intelligence and social media services: A rumor theoretic analysis 
of tweets during social crises. Management Information Systems Quarterly, 37(2), 407–426.
Orange. (n.d.). Retrieved August 01, 2016, from http://www.orange.com/en/home
Ortiz, D. G., & Ostertag, S. F. (2014). Katrina Bloggers and the Development of Collective Civic Action: The Web as a 
Virtual Mobilizing Structure. Sociological Perspectives, 57(1), 52–78. doi:10.1177/0731121413517558
Oskin, B. (2015, May). Japan Earthquake & Tsunami of 2011: Facts and Information. Retrieved August 01, 2016, from 
http://www.livescience.com/39110-japan-2011-earthquake-tsunami-facts.html
Page, S., Freberg, K., Saling, K., & Model, E. M. C. V. (2013). A Comparison of Relevant, Timely Message Strategies 
for Emergency Events. Journal of Strategic Security, 6(2), 20–31. doi:10.5038/1944-0472.6.2.2
Palen, L., Hiltz, S. R., & Liu, S. B. (2007). Online forums supporting grassroots participation in emergency preparedness 
and response. Communications of the ACM, 50(3), 54–58. doi:10.1145/1226736.1226766
Palen, L., Vieweg, S., & Anderson, K. M. (2010). Supporting Everyday Analysts in Safety- and Time-Critical Situations. 
The Information Society, 27(1), 52–62. doi:10.1080/01972243.2011.534370
Panichpapiboon, S., & Ferrari, G. (2008). Irresponsible forwarding. Paper presented at the 8th International Conference 
on ITS Telecommunications, Phuket, Thailand.
Perkins, Royer, & Das. (2003). Ad hoc On-Demand Distance Vector (AODV) Routing. IETF, RFC 3561.
Pfeil, R., Pichler, M., Schuster, S., & Hammer, F. (2015). Robust acoustic positioning for safety applications in underground 
mining. IEEE Transactions on Instrumentation and Measurement, 64(11), 2876–2888. doi:10.1109/TIM.2015.2433631
Pittman, W. E., Church, R. H., & McLendon, J. T. (1985). Through-the-earth electromagnetic trapped miner location 
systems: A review. US Department of Interior, Bureau of Mines.
Plotnick, L., & Hiltz Starr, R. (2016). Barriers to Use of Social Media by Emergency Managers. Journal of Homeland 
Security and Emergency Management, 13, 247.
Pomportes, S., Tomasik, J., & Vèque, V. (2010). Ad hoc network in a disaster area: A composite mobility model and 
its evaluation. Paper presented at International Conference on Advanced Technologies for Communications, Saigon, 
Vietnam. doi:10.1109/ATC.2010.5672729
296

Compilation of References
Pomportes, S., Tomasik, J., & Vèque, V. (2011). A Composite Mobility Model for Ad Hoc Networks in Disaster Areas. 
Journal on Electronics and Communications, 1, 62–68.
Porto de Albuquerque, J., Herfort, B., Brenning, A., & Zipf, A. (2015). A geographic approach for combining social 
media and authoritative data towards identifying useful information for disaster management. International Journal of 
Geographical Information Science, 29(4), 667–689. doi:10.1080/13658816.2014.996567
Pu, C., & Kitsuregawa, M. (Eds.). (2013). JST/NSF Joint Workshop Report on Big Data and Disaster Management. 
Technical Report No. GIT-CERCS-13-09. Georgia Institute of Technology, CERCS.
Pucha, H., Das, S. M., & Hu, Y. C. (2007). The performance impact of traffic patterns on routing protocols in mobile 
ad hoc networks. Computer Networks, 51(12), 3595–3616. doi:10.1016/j.comnet.2007.02.009
Puthal Deepak, , Mishra, & Swain. (2015). Cloud Computing Features Issues and Challenges: A Big Picture. Interna-
tional Conference on Computational Intelligence & Networks (CINE), 116–123.
Puthal, Nepal, Ranjan, & Chen. (2016). DLSeF: A Dynamic Key Length based Efficient Real-Time Security Verification 
Model for Big Data Stream. ACM Transactions on Embedded Computing Systems.
Pyrheliometer. (n.d.). Retrieved from https://en.wikipedia.org/wiki/Pyrheliometer
Quispe, L. E., & Galan, L. M. (2014). Behavior of Ad Hoc routing protocols, analyzed for emergency and rescue scenarios, 
on a real urban area. Expert Systems with Applications, 41(5), 2565–2573. doi:10.1016/j.eswa.2013.10.004
Radianti, J., Hiltz, S. R., & Labaka, L. (2016). An Overview of Public Concerns During the Recovery Period after a 
Major Earthquake: Nepal Twitter Analysis. Paper presented at the 2016 49th Hawaii International Conference on System 
Sciences (HICSS).
Raffelsberger, C., & Hellwagner, H. (2012). Evaluation of MANET Routing Protocols in a Realistic Emergency Response 
Scenario. Paper presented at the 10th International Workshop on Intelligent Solutions in Embedded Systems, Pilsen, 
Czech Republic.
Rahman, M. R., & Akhter, S. (2015a). Real Time Bi-directional Traffic Management Support System with GPS and 
WebSocket. Proc. of the 15th IEEE International Conference on Computer and Information Technology CIT ‘15. 
doi:10.1109/CIT/IUCC/DASC/PICOM.2015.144
Rahman, M. R., & Akhter, S. (2015b). Bi-directional traffic management support system with decision tree based dy-
namic routing. Proc. of 10th International Conference for Internet Technology and Secured Transactions ICITST ‘15. 
doi:10.1109/ICITST.2015.7412080
Rahman, M. R., & Akhter, S. (2016a). BiDirectional Traffic Management with Multiple Data Feeds for Dynamic Route 
Computation and Prediction System. International Journal of Intelligent Computing Research, 7(2).
Rahman, M., Rahman, S., Mansoor, S., Deep, V., & Aashkaar, M. (2016). Implementation of ICT and Wireless Sensor 
Networks for Earthquake Alert and Disaster Management in Earthquake Prone Areas. Procedia Computer Science., 85, 
92–99. doi:10.1016/j.procs.2016.05.184
Rajiv, R. (2014). Streaming big data processing in datacenter clouds. IEEE Cloud Computing, 1(1), 78–83. doi:10.1109/
MCC.2014.22
Ramesh Maneesha, V. (2009). Real-time wireless sensor network for landslide detection. Sensor Technologies and 
Applications 2009. SENSORCOMM’09. Third International Conference on (pp. 405–409). IEEE. doi:10.1109/SEN-
SORCOMM.2009.67
297

Compilation of References
Ramesh, , Subbaiah, Koteswar Rao, & Janardhana Raju. (2010). Performance comparison and analysis of DSDV and 
AODV for MANET. International Journal on Computer Science and Engineering, 2, 183–188.
Ramesh, M. V. (2014). Design, development, and deployment of a wireless sensor network for detection of landslides. 
Ad Hoc Networks, 13, 2–18. doi:10.1016/j.adhoc.2012.09.002
Reina, D. G., Toral, S. L., Barrero, F., Bessis, N., & Asimakopoulou, E. (2011). Evaluation of ad hoc networks in disaster 
scenarios. Paper presented at the third International Conference on Intelligent Networking and Collaborative Systems, 
Fukuoka, Japan. doi:10.1109/INCoS.2011.86
Reina, D. G., Toral, S. L., Asimakopoulou, E., Barrero, F., & Bessis, N. (2015). The role of congestion in probabilistic 
broadcasting for ubiquitous wireless multi-hop networks through mediation analysis. Pervasive and Mobile Computing, 
24, 16–29. doi:10.1016/j.pmcj.2015.06.014
Reina, D. G., Toral, S. L., Barrero, F., Bessis, N., & Asimakopoulou, E. (2012). Modelling and assessing ad hoc net-
works in disaster scenarios. Journal of Ambient Intelligence and Humanized Computing, 4(5), 571–579. doi:10.1007/
s12652-012-0113-3
Reina, D. G., Toral, S. L., Barrero, F., Bessis, N., & Asimakopoulou, E. (2013). The role of ad hoc networks in the in-
ternet of things. Internet of Things and Inter-cooperative Computational Technologies for Collective Intelligence, 460, 
89–113. doi:10.1007/978-3-642-34952-2_4
Reina, D. G., Toral, S. L., Johnson, P., & Barrero, F. (2015). A survey on probabilistic broadcast schemes for wireless 
ad hoc networks. Ad Hoc Networks, 25, 263–282. doi:10.1016/j.adhoc.2014.10.001
Resource Description Framework (RDF). (n.d.). Retrieved from http://www.w3.org/TR/rdfconcepts/
Reuter, C., Ludwig, T., Ritzkatis, M., & Pipek, V. (2015). Social-QAS: Tailorable Quality Assessment Service for Social 
Media Content. Proceedings of the International Symposium on End-User Development (IS-EUD). doi:10.1007/978-
3-319-18425-8_11
Reymond, D., Hyvernaud, O., & Talandier, J. (1991). Automatic detection, location and quantification of earthquakes: 
Application to tsunami warning. J. Pageoph., 135(3), 361–382. doi:10.1007/BF00879470
Rhee, I., Shin, M., Hong, S., Lee, K., & Chong, S. (2008). On the Levy-Walk Nature of Human Mobility. Paper presented 
at IEEE Conference on Computer Communications, Phoenix, AZ. doi:10.1109/INFOCOM.2008.145
Rivera, J.Y. (2016). Tools to operate and manage early warning systems for natural hazards monitoring in El Salvador. 
Open Geospatial Data, Softw. Stand., 1, 9. doi:10.1186/s40965-016-0010-3
Rizk, K., Wagen, J., & Gardiol, F. (1997). Two-dimensional ray-tracing modeling for propagation prediction in microcel-
lular environments. IEEE Transactions on Vehicular Technology, 46(2), 508–518. doi:10.1109/25.580789
Rizza, C., Pereira, Â., & Curvelo, P. (2013). Do-it-yourself Justice-Considerations of Social Media use in a Crisis Situ-
ation: The Case of the 2011 Vancouver Riots. Proceedings of the Information Systems for Crisis Response and Manage-
ment (ISCRAM), 411–415.
Robinson. (2016). R42 Raven II 2016 Estimated Operating Costs. Retrieved from: http://robinsonheli.com/price_lists_eocs/
r44_2_eoc.pdf
Rudman, R., & Bruwer, R. (2016). Defining Web 3.0: Opportunities and challenges. The Electronic Library, 34(1), 
132–154. doi:10.1108/EL-08-2014-0140
298

Compilation of References
Saad, S. S., & Nakad, Z. S. (2011). A standalone RFID indoor positioning system using passive tags. IEEE Transactions 
on Industrial Electronics, 58(5), 1961–1970. doi:10.1109/TIE.2010.2055774
Sánchez Abril, P., Levin, A., & Del Riego, A. (2012). Blurred boundaries: Social media privacy and the twenty‐first‐
century employee. American Business Law Journal, 49(1), 63–124. doi:10.1111/j.1744-1714.2011.01127.x
Sandhu Ravi, S. (1992). Lattice-based enforcement of chinese walls. Computers & Security, 11(8), 753–763. 
doi:10.1016/0167-4048(92)90131-A
Santini, S., & Rauch, D. (2008). Minos: A Generic Tool for Sensor Data Acquisition and Storage. 19th International 
Conference on Scientific and Statistical Database Management IEEE, W3C Semantic Web Activity. Retrieved from 
http://www.w3.org/2001/sw/
Sarcevic, A., Palen, L., White, J., Starbird, K., Bagdouri, M., & Anderson, K. (2012). Beacons of hope in decentralized 
coordination: learning from on-the-ground medical twitterers during the 2010 Haiti earthquake. Paper presented at the 
ACM 2012 conference on Computer Supported Cooperative Work, Seattle, WA.
Savic, V., Larsson, E. G., Ferrer-Coll, J., & Stenumgaard, P. (2016a, March). Kernel methods for accurate UWB-based 
ranging with reduced complexity. IEEE Transactions on Wireless Communications, 15(3), 1783–1793. doi:10.1109/
TWC.2015.2496584
Savic, V., Wymeersch, H., & Larsson, E. G. (2016b, February). Target tracking in confined environments with uncertain 
sensor positions. IEEE Transactions on Vehicular Technology, 65(2), 870–882. doi:10.1109/TVT.2015.2404132
Schiffbauer, W. H., & Brune, J. F. (2006). Coal mine communications. American Longwall Mag.
Schultz, F., Utz, S., & Göritz, A. (2011). Is the medium the message? Perceptions of and reactions to crisis communica-
tion via twitter, blogs and traditional media. Public Relations Review, 37(1), 20–27. doi:10.1016/j.pubrev.2010.12.001
Schultz, T. (2000). Mass media and the concept of interactivity: An exploratory study of online forums and reader email. 
Media Culture & Society, 22(2), 205–221. doi:10.1177/016344300022002005
Schurr, N., Marecki, J., Lewis, J., Tambe, M., & Scerri, P. (2005). The defacto system: Coordinating human-agent teams 
for the future of disaster response. Multi-Agent Programming, 197-215.
Schwamborn, M., Aschenbruck, N., & Martini, P. (2010). A Realistic Trace-based Mobility Model for First Responder 
Scenarios. Proceedings of the 13th ACM International Conference on Modeling, Analysis and Simulation of Wireless 
and Mobile Systems. doi:10.1145/1868521.1868564
Schwartz, T., Stahl, C., Muller, C., Dimitrov, V., & Ji, H. (2010). UbiSpot - A user trained always best positioned engine 
for mobile phones. In Ubiquitous Positioning Indoor Navigation and Location Based Service (pp. 1–8). UPINLBS.
Schwarz, A. (2012). How publics use social media to respond to blame games in crisis communication: The Love Parade 
tragedy in Duisburg 2010. Public Relations Review, 38(3), 430–437. doi:10.1016/j.pubrev.2012.01.009
Sell, C., & Braun, I. (2009). Using a Workflow management System to manage Emergency Plans. Proceedings of the 
6th International ISCRAM Conference.
Senix. (2016). Ultrasonic Sensors help provide Tsunami warning. Retrieved from. https://senix.com/toughsonic-ultrasonic-
sensor-sea-level-measurement/
Sen, S., Joe-Wong, C., Ha, S., & Chiang, M. (2012, November). Incentivizing time-shifting of data: A survey of time-
dependent pricing for internet access. IEEE Communications Magazine, 50(11), 91–99. doi:10.1109/MCOM.2012.6353688
299

Compilation of References
Sen, S., Joe-Wong, C., Ha, S., & Chiang, M. (2014, June). A survey of broadband data pricing: Past proposals, current 
plans, and future trends. ACM Computing Surveys, 46(2).
Sensor Observation Service. (n.d.). Retrieved from http://www.opengeospatial.org/standards/sos
SGS Weather. (2015). Weather Sensors. Retrieved from http://www.sgsweather.com/weather-sensors
Shaban, H. A., & Abou El-Nasr, M. (2015). Near–optimal rake receivers for green UWB radio communications in NLOS 
underground mine tunnels. Journal of Electromagnetic Waves and Applications, 29(4), 448–464. doi:10.1080/092050
71.2014.998775
Shenbagapriya, R., & Kumar, N. (2014). A Survey on Proactive Routing Protocols in MANETs. Paper presented at 
the International Conference on Science Engineering and Management Research, Chennai, India. doi:10.1109/IC-
SEMR.2014.7043630
Shen, Z., & Wang, Q. (2013). Data Validation and Validated Uncertainty Estimation of Multifunctional Self-Validating 
Sensors. IEEE Transactions on Instrumentation and Measurement, 62(7), 2082–2092. doi:10.1109/TIM.2013.2253912
Sheth, A., Anantharam, P., & Henson, C. (2013). Physical-cyber-social computing: An early 21st century approach. 
IEEE Intelligent Systems, 28(1), 79–82. doi:10.1109/MIS.2013.20
Sheth, A., Henson, C., & Sahoo, S. (2008, July-August). Semantic sensor web. IEEE Internet Computing, 12(4), 78–83. 
doi:10.1109/MIC.2008.87
Sheth, A., & Perry, M. (2008). Traveling the Semantic Web through Space, Time, and Theme. IEEE Internet Computing, 
12(2), 81–86. doi:10.1109/MIC.2008.46
Sicignano, D., Tardioli, D., Cabrero, S., & Villarroel, J. L. (2013). Real-time wireless multi-hop protocol in underground 
voice communication. Ad Hoc Networks, 11(4), 1484–1496. doi:10.1016/j.adhoc.2011.01.017
Simon, T., Goldberg, A., Aharonson-Daniel, L., Leykin, D., & Adini, B. (2014). Twitter in the Cross FireThe Use of 
Social Media in the Westgate Mall Terror Attack in Kenya. PLoS ONE, 9(8), e104136. doi:10.1371/journal.pone.0104136
Singh, C. P., Vyas, O. P., & Tiwari. (2008). A Survey of Simulation in Sensor Networks. Proceeding of CIMCA 2008, 
IAWTIC 2008.
Sinnappan, S., Farrell, C., & Stewart, E. (2010). Priceless tweets! A study on Twitter messages posted during crisis: 
Black Saturday. ACIS 2010 Proceedings, 39.
Sobeih, A., & Hou. (2003). A Simulation Framework for Sensor Networks in J-Sim. Technical Report UIUCDCS-
R-2003-2386.
Sonardyne. (n.d.). Tsunami Detection System. Retrieved from http://www.sonardyne.com/products/monitoring-a-control/
tsunami-detection-system.html/
Space Science and Engineering Center. (2010, Apr 28). What makes up a Wisconsin AWS? Retrieved from https://amrc.
ssec.wisc.edu/news/2010-May-01.html
SPARQL Query Language for RDF. (n.d.). Retrieved from http://www.w3.org/TR/rdf-sparqlquery/
Srinivasan, K., Ndoh, M., & Kaluri, K. (2005, June). Advanced wireless networks for underground mine communica-
tions. In First International Workshop on Wireless Communications in Underground and Confined Areas (IWWCUCA), 
(pp. 51–54). IEEE.
300

Compilation of References
Srivastava, D., & Ranjan, P. (2011, April). Towards greener & safer mines with wireless sensor networks. In 2011 IEEE 
Green Technologies Conference (IEEE-Green) (pp. 1-6). IEEE. doi:10.1109/GREEN.2011.5754881
Stanton, N. A., Chambers, P. R., & Piggott, J. (2001). Situational awareness and safety. Safety Science, 39(3), 189–204. 
doi:10.1016/S0925-7535(01)00010-8
Starbird, K., & Palen, L. (2012). (How) will the revolution be retweeted?: information diffusion and the 2011 Egyptian 
uprising. Proceedings of the acm 2012 conference on computer supported cooperative work. doi:10.1145/2145204.2145212
Stoyanova, T., Kerasiotis, F., Prayati, A., & Papadopoulos, G. (2009). A Practical RF Propagation Model for Wireless 
Network Sensors (pp. 194–199). Sensor Technologies and Applications. doi:10.1109/SENSORCOMM.2009.39
STREAM: the stanford stream data manager (demonstration description). (2003). Proceedings of the 2003 ACM SIGMOD 
international conference on Management of data, 665–665.
Subramanian, C., Lapilli, G., Kreit, F., Pinelli, J. P., & Kostanic, I. (2011). Experimental and computational performance 
analysis of a multi-sensor wireless network system for hurricane monitoring. Sensors & Transducers, 10, 206–244.
Sun, G., Chen, J., Guo, W., & Liu, K. (2005). Signal processing techniques in network-aided positioning: A survey of 
state-of-the-art positioning designs. IEEE Signal Processing Magazine, 22(4), 12–23. doi:10.1109/MSP.2005.1458273
Sun, G., Hu, T., Yang, G., & Jia, J. (2015). Real-time and clock-shared rainfall monitoring with a wireless sensor network. 
Computers and Electronics in Agriculture, 119, 1–11. doi:10.1016/j.compag.2015.09.023
Sunkpho & Ootamakorn. (2011). Real-time flood monitoring and warning system. Sonklanakarin Journal of Science 
and Technology, 33(2).
Sutton, J., Palen, L., & Shklovski, I. (2008). Backchannels on the front lines: Emergent uses of social media in the 2007 
southern California wildfires. Proceedings of the 5th International ISCRAM Conference.
Suzuki, M., Saruwatari, S., Kurata, N., & Morikawa, H. (2007). A high-density earthquake monitoring system 
using wireless sensor networks. International Conference on Embedded Networked Sensor Systems, 373-374. 
doi:10.1145/1322263.1322301
Sweetser, K. D. (2010). A losing strategy: The impact of nondisclosure in social media on relationships. Journal of 
Public Relations Research, 22(3), 288–312. doi:10.1080/10627261003614401
Sylvester, A., Tate, M., & Johnstone, D. (2013). Beyond synthesis: Re-presenting heterogeneous research literature. 
Behaviour & Information Technology, 32(12), 1199–1215. doi:10.1080/0144929X.2011.624633
Taejoon, P., & Shin, K. G. (2004). LiSP: A lightweight security protocol for wireless sensor networks. ACM Transactions 
on Embedded Computing Systems, 3(3), 634–660. doi:10.1145/1015047.1015056
Takahashi, A., Nishiyama, H., & Kato, N. (2013, January). Fairness Issue in Message Delivery in Delay- and Disruption-
Tolerant Networks for Disaster Areas. In Proceedings of International Conference on Computing, Networking and Com-
munications (pp. 890-894). doi:10.1109/ICCNC.2013.6504207
Takahashi, B., Tandoc, E. C. Jr, & Carmichael, C. (2015). Communicating on Twitter during a disaster: An analysis of tweets 
during Typhoon Haiyan in the Philippines. Computers in Human Behavior, 50, 392–398. doi:10.1016/j.chb.2015.04.020
Tan, R., Xing, G., Chen, J., Song, W. Z., & Huang, R. (2010). Quality-Driven Volcanic Earthquake Detection Using 
Wireless Sensor Networks. IEEE Real-Time Systems Symposium (pp.271-280). IEEE Computer Society. doi:10.1109/
RTSS.2010.21
301

Compilation of References
Tan, X., Sun, Z., & Akyildiz, I. F. (2015, August). Wireless underground sensor networks: MI-based communication systems 
for underground applications. IEEE Antennas and Propagation Magazine, 57(4), 74–87. doi:10.1109/MAP.2015.2453917
Tatbul, Etintemel, & Zdonik. (2007). Staying Fit: Efficient Load Shedding Techniques for Distributed Stream Process-
ing. Proc. Int’l Conf. Very Large Data Bases (VLDB), 159–170.
Tatham, P. H. (2009). An Initial Investigation into the Suitability of the use of Unmanned Aerial Vehicle Systems (UAVS) 
to Support the Emergency Assessment Process in Rapid Onset Humanitarian Disasters. International Journal of Risk 
Assessment and Management, 13(1), 60–78. doi:10.1504/IJRAM.2009.026391
Tatham, P. H., & Kovács, G. (2010). The impact of gender on humanitarian logistics. International Journal of Mass 
Emergencies and Disasters, 28(2), 148–169.
Tatham, P. H., Kovács, G., & Spens, K. M. (2016). The humanitarian common logistic operating picture: A solution to 
the inter-agency coordination challenge. Disasters: The Journal of Disaster Studies, Policy and Management.
Tatham, P. H., & Spens, K. M. (2016). Cracking the humanitarian logistics coordination challenge: Lessons from the 
urban search and rescue community. Disasters: The Journal of Disaster Studies, Policy and Management, 40(2), 246–261.
The Economist. (2009, September). Attack of the drones. Economist, 3. Retrieved from http://www.economist.com/
node/14299496/print
The Economist. (2011, October). Flight of the drones. Economist, 8. Retrieved from http://www.economist.com/
node/21531433/print
Thomas. (1991). Emergency Management: Principles and Practice for Local Government. Washington, DC: International 
City Management Association.
Tompe, Gaikwad, Pawar, & Pahadiya. (2016). Land Slide Detection System. Imperial Journal of Interdisciplinary 
Research, 2(1).
Towhata, I. (2015). Monitoring of unstable slopes by MEMS tilting sensors and its application to early warning. IOP 
Conf. Series: Earth and Environmental Science. doi:10.1088/1755-1315/26/1/012049
Trung, H., Benjapolakul, W., & Duc, P. (2007). Performance evaluation and comparison of different ad hoc routing 
protocols. Computer Communications, 30(11-12), 2478–2496. doi:10.1016/j.comcom.2007.04.007
Trusted Platform Module, T. C. G. (TPM) Specification. (n.d.). Retrieved from https://www.trustedcomputinggroup.
org/specs/tpm/
Tsikoudis, N. A. P., & Markatos, E. P. (2016). LEoNIDS: A Low-latency and Energy-efficient Network-level Intrusion 
Detection System. IEEE Transactions on Emerging Topics in Computing, 4(1), 142–155. doi:10.1109/TETC.2014.2369958
Tsunami Early Warning System. (2010). Retrieved from http://www.khaolak.net/homemenu/tsunami.html
UAViators. (2016). Case Studies: Mapping Drones in Humanitarian Contexts. Retrieved from http://drones.fsd.
ch/2016/03/17/case-studies-mapping-drones-in-humanitarian-contexts/
UAViators. (2016a). Humanitarian UAV Code of Conduct & Guidelines. Retrieved from: http://uaviators.org/docs
Uddin, M. Y. S., Nicol, D. M., Abdelzaher, T. F., & Kravets, R. H. (2009). A post-disaster mobility model for delay 
tolerant networking. In Proceedings of Winter Simulation Conference (pp. 2785-2796). doi:10.1109/WSC.2009.5429249
Valentini, C., & Romenti, S. (2011). Blogging about crises: The role of online conversations in framing Alitalias per-
formance during its crisis. Journal of Communication Management, 15(4), 298–313. doi:10.1108/13632541111183398
302

Compilation of References
Vallati, C., Omwando, V., & Mohapatra, P. (2013). Mobile Ad Hoc Networking. In Experimental Work Versus Simula-
tion in the study of Mobile Ad Hoc Networks (pp. 191-228). Wiley.
Vallati, Omwando, & Mohapatra. (2013). Experimental Work Versus Simulation in the study of Mobile Ad Hoc Networks. 
Academic Press.
Vardi, M. (2011). Computing for Humans. Communications of the ACM, 54(12).
Vieweg, S., Hughes, A. L., Starbird, K., & Palen, L. (2010). Microblogging during two natural hazards events: what 
twitter may contribute to situational awareness. Paper presented at the SIGCHI Conference on Human Factors in Com-
puting Systems, Atlanta, GA. doi:10.1145/1753326.1753486
Vincenzo, Jimenez-Peris, Patino-Martinez, & Valduriez. (2010). Streamcloud: A large scale data streaming system. IEEE 
30th International Conference on Distributed Computing Systems (ICDCS), 126–137.
Vincenzo, Jimenez-Peris, & Patino-Martinez, Soriente, & Valduriez. (2012). Streamcloud: An elastic and scalable data 
streaming system. IEEE Transactions on Parallel and Distributed Systems, 23(12), 2351–2365.
Wang, J., Wu, Y., Yen, N., Guo, S., & Cheng, Z. (2016). Big data analytics for emergency communication networks: A 
survey. IEEE Communications Surveys and Tutorials, 18(3), 1758–1778. doi:10.1109/COMST.2016.2540004
Wang, X., Wang, C., Cui, G., & Yang, Q. (2015). Practical Link Duration Prediction Model in Vehicular Ad Hoc Net-
works. International Journal of Distributed Sensor Networks, 11(3), 1–14. doi:10.1155/2015/216934
Wang, Y., Huang, L., & Yang, W. (2010). A novel real-time coal miner localization and tracking system based on self-
organized sensor networks. EURASIP Journal on Wireless Communications and Networking, (1): 1.
Watanabe, K., Ishigaki, T., & Higuchi, T. (2010). A Multivariable Detection Device Based on a Capacitive Microphone 
and Its Application to Security. IEEE Transactions on Instrumentation and Measurement, 59(7), 1955–1963. doi:10.1109/
TIM.2009.2030716
Water, G. (2015). Water level (Pressure) Instrumentation. Retrieved from http://www.globalw.com/catalog_level.html
Waterlog. (n.d.). Non-Contact water level sensor. Retrieved from http://www.waterlog.com/productsdetail.php?Air-
Water-Soil-Temperature-Sensor
Waterlog. (n.d.). Silicon Pyranometer Sensor. Retrieved from http://www.waterlog.com/productsdetail.php?H-380-
Relative-Humidity-Temperature-Probe-and-Radiation-Shield-22
Wattegama, C. (2007). ICT for Disaster Management. Asia-Pacific Development Information programme, e-Primers for 
the Information Economy, Society and Polity, APCICT 2007. Retrieved from http://www.unapcict.org/ecohub/resources/
ict-for-disaster-management/at_download/attachment1
Weichselgartner, J. (2001). Disaster mitigation: The concept of vulnerability revisited. Disaster Prevention and Manage-
ment: An International Journal, 10(2), 85–95. doi:10.1108/09653560110388609
What is Emergency Management? (2017). Maine Emergency Management Agency Web Site. Retrieved from http://www.
maine.gov/mema/ema/mema_ema_whatis.shtml
WHO (World Health Organisation). (2013). Classification and minimum standards for foreign medical teams in sud-
den onset disasters. Retrieved from: http://www.who.int/hac/global_health_cluster/fmt_guidelines_september2013.pdf
Wilson, J.R. (2009, July). Unmanned aerial vehicles get ready for prime time. Military and Aerospace, 18-25.
303

Compilation of References
Wisitpongphan, N., Tonguz, O. K., Parikh, J. S., Mudalige, P., Bai, F., & Sadekar, V. (2007). Broadcast storm mitigation 
techniques in vehicular ad hoc networks. IEEE Wireless Communications., 14(6), 84–94. doi:10.1109/MWC.2007.4407231
Workman, M. (2016). Using Symbols for Semantic Representations: A Pilot Study of Clinician Opinions of a Web 3.0 
Medical Application. In Semantic Web (pp. 31–38). Springer.
Wu, C., Yang, Z., Liu, Y., & Xi, W. (2013). WILL: Wireless Indoor Localization without Site Survey. IEEE Transactions 
on Parallel and Distributed Systems, 24(4), 839–848. doi:10.1109/TPDS.2012.179
Wu, K., Xiao, J., Yi, Y., Chen, D., Luo, X., & Ni, L. M. (2013). CSI-based indoor localization. IEEE Transactions on 
Parallel and Distributed Systems, 24(7), 1300–1309. doi:10.1109/TPDS.2012.214
Xfinity. (n.d.). XFINITY from Comcast. Retrieved August 01, 2016, from http://www.xfinity.com/
Xiao, J., Wu, K., Yi, Y., & Ni, L. (2012). FIFS: Fine-Grained Indoor Fingerprinting System. In IEEE 2012 21st Inter-
national Conference on Computer Communications and Networks (ICCCN), 1–7.
Xiao, R., & He, X. (2013). Real-time landslide monitoring of Pubugou hydropower resettlement zone using continuous 
GPS. Natural Hazards, 69(3), 1647–1660. doi:10.1007/s11069-013-0768-x
Xie, H., & Golosinski, T. S. (1999, August). Mining science and technology 1999: Proceedings of the ‘99 international 
symposium. Taylor and Francis.
Xu, Z. (2016). Crowdsourcing based description of urban emergency events using social media big data. IEEE Trans. 
Cloud Comput. doi:10.1109/TCC.2016.2517638
Yang, I. T., Park, J. K., & Kim, D. M. (2007). Monitoring the symptoms of landslide using the non-prism total station. 
KSCE J Civ Eng., 11(6), 293–301. doi:10.1007/BF02885900
Yang, M., Stavrou, S., & Brown, A. (2011). Hybrid ray-tracing model for radio wave propagation through periodic 
building structures. IET Microwaves Antennas Propagation, 5, 340–348.
Yang, S., Dessai, P., Verma, M., & Gerla, M. (2013). Freeloc: Calibration-free crowdsourced indoor localization. Pro-
ceedings of IEEE INFOCOM, 2481–2489.
Yarkan, S., & Arslan, H. (2007, October). Statistical wireless channel propagation characteristics in underground mines 
at 900MHz. In MILCOM 2007-IEEE Military Communications Conference (pp. 1-7). IEEE.
Yarkan, S., Guzelgoz, S., Arslan, H., & Murphy, R. R. (2009). Underground mine communications: A survey. IEEE 
Communications Surveys and Tutorials, 11(3), 125–142. doi:10.1109/SURV.2009.090309
Yates, D., & Paquette, S. (2011). Emergency knowledge management and social media technologies: A case study of the 2010 
Haitian earthquake. International Journal of Information Management, 31(1), 6–13. doi:10.1016/j.ijinfomgt.2010.10.001
Yin, J., Lampert, A., Cameron, M., Robinson, B., & Power, R. (2012). Using social media to enhance emergency situ-
ation awareness. Intell. Syst. IEEE, 27(6), 52–59. doi:10.1109/MIS.2012.6
Yoshizaki, M. (2011). Disaster Management and Cloud Computing in Japan. Report from Ministry of International Affair 
and Communication. Retrieved from http://www.gbd-e.org/events/2011/assembly2011/pdf/Mr.Masahiro_Yoshizaki.pdf
Zeng, J., Yang, L. T., Man Lin, H. N., & Ma, J. (2016). A survey: Cyber-physical-social systems and their system-level 
design methodology. Future Generation Computer Systems. 10.1016/j.future.2016.06.034
304

Compilation of References
Zhang, C., Gu, B., Yamori, K., Xu, S., & Tanaka, Y. (2015, January). Oligopoly Competition in Time-Dependent Pricing 
for Improving Revenue of Network Service Providers with Complete and Incomplete Information. IEICE Transactions 
on Communications, E98-B(01), 20–32. doi:10.1587/transcom.E98.B.20
Zhang, L., Wu, W., & Wang, D. (2014, April). Time dependent pricing in wireless data networks: Flat-rate vs. usage-
based schemes. In Proceedings of the IEEE International Conference on Computer Communications 2014 (pp. 700–708). 
doi:10.1109/INFOCOM.2014.6847996
Zhang, W., & Liu, S. (2010). Applications of the Small Satellite Constellation for Environment and Disaster Monitoring 
and Forecasting. Int. J. Disaster Risk Sci., 1(2), 9–16.
Zhang, Y., Low, C. P., & Ng, J. M. (2011). Performance Evaluation of Routing Protocols on the Reference Region Group 
Mobility Model for MANET. Wireless Sensor Network, 3(03), 92–105. doi:10.4236/wsn.2011.33010
Zhang, Y., Yang, W., Han, D., & Kim, Y. I. (2014). An integrated environment monitoring system for underground 
coal mines: Wireless sensor network subsystem with multi-parameter monitoring. Sensors (Basel, Switzerland), 14(7), 
13149–13170. doi:10.3390/s140713149 PMID:25051037
Zhou, G., & Chen, Y. (2011a, August). The research of carbon dioxide gas monitoring platform based on the wireless 
sensor networks. In Artificial Intelligence, Management Science and Electronic Commerce (AIMSEC), 2011 2nd Inter-
national Conference on (pp. 7402-7405). IEEE.
Zhou, W. (2011b, August). Design of video surveillance system based on 3G wireless network in underground coal mine. 
In 2011 International Conference on Uncertainty Reasoning and Knowledge Engineering (URKE), (vol. 1, pp. 248-250). 
IEEE. doi:10.1109/URKE.2011.6007809
Zhu, J., & Papavassiliou, S. (2003). On the energy-efficient organization and the lifetime of multi-hop sensor networks. 
IEEE Communications Letters, 7(11), 537–539. doi:10.1109/LCOMM.2003.820097
305

﻿
About the Contributors
﻿
Ashir Ahmed is a Lecturer of information systems at Swinburne University of Technology, Aus-
tralia. He earned his PhD in information systems from Monash University. His research interests focus 
on the role of technologies such as IT and Web 2.0/Web 3.0 for creating positive social impact. Some 
of his research projects include the use of social media for suicide prevention, evaluating the role of 
community consultation for anti-radicalisation through e-education, and the framework for using web 
2.0 in disaster management. He has published his research findings in leading journals and conferences 
such as Pacific Asia Journal of the Association for Information Systems (PAJAIS), International Con-
ference on Information Systems (ICIS), European Conference on Information Systems (ECIS), Hawaii 
International Conference on System Sciences (HICSS), Pacific Asia Conference on Information Systems 
(PACIS) and IGI Global.
Rajendra Akerkar is a professor at Western Norway Research Institute, Norway. He is also a chair-
man of Technomathematics Research Foundation, India. He has authored 13 books and more than 120 
research articles. His current research focuses on intelligent information management, big data analytics 
and data science.
Shamim Akhter received his Ph.D. in 2009 from information processing department, Tokyo Insti-
tute of Technology, JAPAN. He completed B.S. and M.S. degrees in computer science from American 
International University-Bangladesh (AIUB), and Asian Institute of Technology (AIT), THAILAND 
respectively. He is now affiliated with department of computer science and engineering, East West 
University Bangladesh as assistant professor (he promoted to associate professor and will be effective 
soon). He served the department of computer science, American International University Bangladesh, 
as lecturer from 2001 - 2005, and as assistant professor 2005-2014. He also worked as assistant profes-
sor in Thompson Rivers University, Kamloops, CANADA for more than six (6) months. In addition, he 
worked as a research associate at RS and GIS FoS, Asian Institute of Technology, THAILAND, a JSPS 
postdoctoral research fellow at National Institute of Informatics (NII), JAPAN and a GCOE research as-
sistant at Tokyo Institute of Technology, JAPAN. He also served as the head of computer science graduate 
program at American International University Bangladesh for two years. He is the author of a book, and 
more than 50 articles. His research interests include applied intelligent system and information process-
ing; parallel and high-performance computing; and RS-GIS. He was a recipient of the “The Excellent 
Student of The Year, FY2008”, Global COE Program, Photonics Integration-Core Electronics (PICE), 
JAPAN. He mentored two (2) PhD, supervised around ten (10) MSc and more than 30 undergraduate 
dissertations. His students/co-authors awarded student travel grant for best student paper at ICONIP, 
306

About the Contributors
2006, Hong Kong, the best student presentation in National Convention of IPSJ, 2010 Siga, JAPAN, 
vice chancellor award for the best thesis in 2006, and 3rd position in Falling Walls Lab in Bangladesh, 
2016. He became a Member (M) of IEEE in 2006, a Senior Member (SM) in 2014. He is also a senior 
member of IPSJ and WASET.
Catherine Ball is an author, founder, and ethics advocate working across global projects where 
robotics and new technology meet environmental protection. She holds a BSc (Hons) in Environmental 
Protection and a PhD (Spatial Ecology, Descriptive and Predictive Statistics) from the University of 
Newcastle-upon-Tyne in the United Kingdom. Dr. Ball’s biggest passion is found working on projects 
that have a humanitarian aspect, ranging from the use of RPAS for emergency response, to recording 
cultural heritage, and agricultural assessments.
Peter Diplas is the Chief Executive Officer of Palladium’s Logistics business unit (formerly HK 
Logistics). He joined HKL in 2005 and became Chief Executive Officer in 2015. Peter holds the strategic 
management, leadership and operational guidance across HKL group operations. He is uniquely placed 
with both field and corporate experience gained over 20 years of progressive private, public sector and 
development aid practice. Before joining HKL, Peter held management roles with the Department of 
Defence for the Australian Government and Qantas Airways Limited.
Mehdi Esnaashari received the B.S., M.S., and PhD. degrees in Computer Engineering, all from 
the Amirkabir University of Technology in Iran, in 2002, 2005, and 2011 respectively. Currently, he is 
an assistant professor at Iran Telecommunications Research Center (ITRC), Tehran, Iran. His research 
interests include computer networks, learning systems and information retrieval.
Wisam Farjow has the position of Adjunct Professor in the Department of Electrical and Computer 
Engineering / Ryerson University in Toronto. Wisam is actively involved in researching advanced tech-
nologies and modern theories related to the underground mines and tunnels. His work has resulted in 
developing a number of novel algorithms and registered patents targeting safer mines and advanced com-
munication systems. Wisam has a Ph.D. degree in Electrical and Computer Engineering from Ryerson 
University in Toronto. He is a member of the Ontario Society of Professional Engineers (OSPE), the 
Institute of Electrical and Electronics Engineering (IEEE), Project Management Institute (PMI), and is 
a Registered Professional Engineer in the province of Ontario, Canada (PEO).
Xavier N. Fernando received the Ph.D. degree from the University of Calgary, Calgary, AB, Canada, 
in 2001. In 2001, he joined Ryerson University, Toronto, ON, Canada, where he is currently a Professor 
and directing Ryerson Communications Laboratory. He has authored or coauthored of 100 research ar-
ticles. He is also a coauthor of the IEEE COMSOC WEBOK Wireless Engineering Body of Knowledge 
and the sole author of the book Radio over Fiber for Wireless Communications: From Fundamentals 
to Advanced Topics (Wiley). He is the holder of two patents. Prof. Fernando is a member of the IEEE 
COMSOC Education Board Working Group on Wireless Communications and an IEEE Distinguished 
Lecturer. He has delivered invited lectures and tutorials worldwide. He is a Program Evaluator for 
ABET. He is the General Chair for the 2014 IEEE Canadian Conference on Electrical and Computer 
Engineering. He was a member of Ryerson Board of Governors during 2010–2011 and the Chair of the 
IEEE Toronto Section during 2012–2013. His work has won several awards and prizes, including the 
307

About the Contributors
IEEE Humanitarian Initiative Technology Workshop First Prize in 2014, IEEE Microwave Theory and 
Techniques Society Prize in 2010, Sarnoff Symposium Prize in 2009, Opto-Canada Best Poster Prize 
in 2003, and CCECE Best Paper Prize in 2001. He was a finalist for the Top 25 Immigrant Award of 
Canada in 2012.
José Manuel García-Campos was born in Seville, Spain, in 1989. He received the telecommunica-
tion engineering degree from the University of Seville, Seville, Spain, in 2014, where he is currently 
working toward the Ph.D. degree. His current research interests include routing protocols and mobility 
models for vehicular ad hoc networks. He attended to two international conferences and has written three 
papers for different journals which are under review.
Mehdi Gheisari got his bachelor and master degree from Islamic Azad University in Iran and his PhD 
from Guangzhou University in computer. His research interests are Deep learning, Big Data, and WSN.
Bo Gu received the B.E. degree from Tianjin University, Tianjin, China, in 2004, M.E. degree from 
Peking University, Beijing, China, in 2007, and Ph.D. degree from Waseda University, Tokyo, Japan, 
in 2013, respectively. From 2007 to 2011, he was a research engineer at Sony Digital Network Applica-
tions, Japan. In 2013, he joined the Department of Communications and Computer Engineering, Waseda 
University as an assistant professor. Since April 2016, he has been with the Department of Information 
and Communications Engineering, Kogakuin University. His current research interests include network 
economics, game theory, and network optimization. He received the best paper award in APNOMS 2016. 
He is a member of IEEE and IEICE.
Yu Gu received B.E and D.E. degree from the Special Classes for the Gifted Young (SCGY) and 
Department of Computer Science, University of Science and Technology of China in 2004 and 2010, 
respectively. From 2006.2 to 2006.8, he has been an intern in Wireless Network Group, Microsoft Re-
search Asia, Beijing, China. From 2007.12 to 2008.12, he has been with the Department of Computer 
Science, University of Tsukuba, Japan, where he was a visiting scholar. From 2010.11 to 2012.10, he 
has worked in the National Institute of Informatics (Japan) as a JSPS Research Fellow. Now he is a full-
time Professor and Huangshan Mountain Young Scholar in School of Computer and Information, Hefei 
University of Technology, China. He received the Excellent Paper Award from IEEE Scalcom 2009. His 
research interests include wireless communications, pervasive computing, and effective computing. He 
is a senior member of IEEE and a member of ACM.
Daniel Gutiérrez was born in Seville, Spain, in 1983. He received the B.E. degree in electronic en-
gineering and M.S. degree in electronics and telecommunications from the University of Seville, Seville, 
Spain, in 2009 and 2011 respectively. He obtained the Ph.D. degree in electronic engineering in 2015 
by the University of Seville, Seville. His current research interests include wireless networks such as ad 
hoc networks, delay tolerant networks and flying ad hoc networks.
308

About the Contributors
Muhammad Jaseemuddin received the B.E. degree from NED University of Engineering and Tech-
nology, Karachi, Pakistan, in 1989, the M.S. degree from The University of Texas at Arlington, Arlington, 
TX, USA, in 1991, and the Ph.D. degree from the University of Toronto, Toronto, ON, Canada, in 1997. 
He worked in the Advanced IP group and at the Wireless Technology Lab (WTL) at Nortel Networks. He 
worked on the wireless service delivery platform, Universal Mobile Telecommunications System Virtual 
Home Environment framework, and Open IP protocol suite. In WTL, he worked on quality of service, 
routing, and handover issues in mobile wireless IP access network. Since 2002, he has been Associate 
Professor at Ryerson University, Toronto. His research interests include investigating medium access 
control and routing for smart beamforming antennas and cooperative communications, the impact of 
mobility on routing and transport layers, mobile middleware and mobile cloud, heterogeneous wireless 
networks, and IP routing and traffic engineering.
S. M. Kamruzzaman received the B.Sc. Engineering degree from the Dhaka University of Engineering 
and Technology, Bangladesh, in 1997, the M. Sc. Engineering degree from the Bangladesh University 
of Engineering and Technology, in 2005, and the Ph.D. degree from the Hankuk University of Foreign 
Studies, South Korea, in 2012. He is a Postdoctoral Research Fellow with the Ryerson Communica-
tions Laboratory, Ryerson University, Toronto, ON, Canada. Prior to joining at the Ryerson University, 
he worked as an Assistant Professor in the College of Computer and Information Sciences at the King 
Saud University, Riyadh, Saudi Arabia from 2013 to 2015. He also worked at the International Islamic 
University Chittagong, the Manarat International University, and the University of Rajshahi from 1998 
to 2013. He has authored or coauthored of more than 50 research articles. Besides, he is serving as 
reviewer/TPC member in a number of journals/IEEE conferences, respectively. His research interests 
include medium access control, routing protocol, and radio resource management for ad-hoc, sensor, 
and cognitive radio networks; coexistence of heterogeneous networks, and cooperative communications.
Saraswathi S completed her Ph.D in the Faculty of Information and Communication Engineering, 
Anna University Chennai, India in the year 2015. She received her M.E. degree in Computer Science and 
Engineering from Manonmaniyam Sundaranar University, Thirunelveli India in the year 2005. B.E. in 
Computer Science and Engineering from Manonmaniyam Sundaranar University, Thirunelveli India in 
the year 1999. Presently she is working as an Associate Professor in NSSN College of Engineering. She 
has 12+ years of experience in teaching and research Engineering colleges. Her fields of interests are 
Network Security, Cryptography, information security, Disaster Management and etc. She has published 
10 papers in national/International conferences and 7 in International Journals.
Jesús Sánchez-García was born in Seville, Spain, in 1984. Since 2012, he holds a M.S. degree in 
telecommunications engineering from the University of Seville, Seville, Spain. From 2010 to 2013 he 
worked as an engineer in the R&D department of a privately owned engineering company. In 2014 he 
joined the University of Seville as a scientific personnel and he is currently pursuing his Ph.D in elec-
tronic engineering in the field of wireless ad hoc networks and its applications.
309

About the Contributors
Kavitha T completed her Ph.D in the Faculty of Information and Communication Engineering, Anna 
University Chennai, India in the year 2014. She received her M.E. degree in Systems Engineering and 
Operations Research from Anna University, Chennai India in the year 2006. B.E. in Electronics and Com-
munication Engineering from Bharathidasan University, India in the year 2000. Presently she is working 
as an Associate professor in BNM Institute of Technology, Visvesvaraya Technological University.. She 
has 16+ years of experience in teaching and research in Jerusalem College of Engineering. Her fields 
of interests are Wireless Networks, Wireless Sensor Network, information security, Disaster Manage-
ment and etc. She has published 20 papers in national/International conferences and 8 in International 
Journals. She is a life member of ISTE, 2011.
Peter Tatham, after 35 years as logistician in the (UK) Royal Navy, moved into academia in 2004 
before joining the faculty of Griffith University in July 2010 where he teaches and researches in humani-
tarian and commercial supply chain management. He is the Asian and Australasian Editor of the Journal 
of Humanitarian Logistics and Supply Chain Management, and a member of the Editorial Board of the 
International Journal of Physical Distribution and Logistics Management.
Sergio Toral was born in Rabat, Morocco, in 1972. He received the M.S. and Ph.D. degrees in elec-
trical and electronic engineering from the University of Seville, Spain, in 1995 and 1999, respectively. 
He is currently a full Professor with the Department of Electronic Engineering, US. His main research 
interests include ad hoc networks and their routing protocols, deployment of wireless sensor networks, 
real-time and distributed systems, intelligent transportation systems, and embedded operating systems.
Yong Wu is currently a Senior Lecturer at the Department of International Business and Asian 
Studies, Griffith University, Australia. He obtained his PhD from Nanyang Technological University, 
Singapore and his Master’s degree from Nanjing University of Aeronautics and Astronautics, China. He 
teaches in the area of logistics and supply chain management and his research interests include supply 
chain modelling and simulation, logistical operations research, and global optimization and computa-
tional intelligence for problems in logistics and supply chain management and other related areas. He is 
a member of the Institute for Operations Research and the Management Sciences (INFORMS).
310

  311
Index
A 
ad-hoc network 106, 197
aggregate 200, 202, 213, 215-217, 219, 224
Analytics 84, 144, 151-152, 160, 164-165, 192-193, 
221, 261
B 
Backbone networks 41, 67-68, 79
Bandwidth 68, 206, 212, 216, 225, 227-228, 235-
236, 238
Big Data 84, 144-152, 154-155, 162-165, 193, 221
broadcasting 106-109, 112-114, 118, 126-133, 135-
136, 138-139, 141-142
business processes 168, 170
C 
Channel properties 41, 43, 45
clean water 167
Cloud Computing 147, 154-155, 163, 167, 185, 194-
195, 220-221, 239
commercial components 196
Communication Process 243-244, 246, 259, 263
communication protocols 106-108, 118, 133, 139-
140, 258
Communication systems 43, 46-47, 49, 62, 73, 80, 
83-84, 242
Cyclone Winston 264-265, 269-272, 277
D 
Data Analytics 84, 152, 165, 192-193, 221
data mining 101, 155, 160-161, 253
data packets 31-32, 107, 135, 212
Data Streams 14, 144, 162, 221
Disaster 1-2, 35-38, 40-42, 44, 46, 52-53, 62, 78-80, 
87, 106-108, 111-112, 114-119, 121, 124, 129, 
133-134, 136, 139-145, 147-149, 152, 154, 
161-164, 166-169, 171-174, 184, 187-188, 
191-192, 194-197, 221, 223-224, 228-230, 234, 
236, 243-244, 246-247, 249-254, 256-261, 263, 
265-278
Disaster Management 1-2, 35-38, 41-42, 44, 78-80, 
144, 154, 164, 167-174, 187, 192, 194-197, 
221, 243-244, 246-247, 249-251, 253-254, 256, 
258-260, 263, 266, 272, 274
Disaster scenarios 106-108, 111-112, 114-115, 117-
119, 121, 133, 136, 139, 143, 228
Drones 264-265, 276, 278
DTN 223-224
E 
Emergency Management 4, 144-149, 153-156, 161-
165, 167, 185, 195, 243, 246, 249, 254, 257, 
261
Emergency response 1, 41-44, 53, 62, 64, 78-79, 
86-88, 111, 142, 145, 149-150, 153, 161, 186, 
195, 267
environmental dynamics 86-91, 93, 95, 100, 102
evaluation 36, 88, 95, 99, 103, 106-108, 111, 114, 
118-119, 126-127, 131, 133-136, 139-143, 162, 
185, 190, 195, 212-213, 219-220, 222, 268, 277
F 
Fiji 264-265, 270, 277
fingerprint WiFi Localization 86
food supplies 167
G 
geologic processes 167
geometrical models 101

312  
Index
H 
hardware devices 87
health care 167
human sufferings 2
I 
information sources 87, 150
L 
life cycle 168-171, 173-174, 176, 179, 243, 263
Literature Review 244, 246-248, 263, 267, 269, 277
M 
Management System 36, 38, 167-171, 174, 185, 
187, 192-195, 226
MANET communication 106-108, 139
MANETs 106-109, 111-112, 114, 120, 133, 139-
140, 143
man-made disasters 42, 87
Mine environment 41, 43
Mine safety management 41, 52
Monitoring Equipment and Disaster prediction 1
N 
Nash Equilibrium 223, 229, 231, 234
Natural disasters 2, 8, 146, 167, 169, 187, 195, 264-
265
networked sensors 196
nuclear explosions 2, 8
O 
off-the-shelf equipments 87
Optimization 36, 46, 77, 82, 110, 148, 223, 229, 
231-232, 234, 237, 240
P 
pervasive computing 83, 86, 103, 197, 201, 203, 222
physical world. 196
Post-disaster communications 62-63
post-PC era 196
Pricing 223, 225-227, 229, 231-232, 234-242
proposed workflow 168, 171-174, 187, 191, 193
R 
radio-frequency identification 87
real-world experiments 86-88, 102
Reliable communication network 41
Resource allocation 223, 235, 242
routing algorithms 106, 224
Routing protocols 106-112, 114, 118-122, 124, 128, 
135-136, 140-143
RPAS 264-269, 271-276
S 
Scalability 51, 67-70, 79, 112, 160-161, 165, 185, 
206, 216
Scheduling 167-168, 170, 179, 183-185, 187, 191-
194, 213, 224, 227, 236, 240
Semi-Structured Data 165
Sensing Devices 1-2, 35
Sensor 1-6, 12, 15-18, 22, 30, 32-39, 48, 53-59, 78, 
80-85, 101-102, 104-105, 108, 143-145, 149-
150, 155, 162, 171, 196-198, 201-222, 241
Social Media 144-148, 151-152, 154-156, 160-165, 
245-246, 249-250, 253-255, 260-263
Stackelberg 223, 229, 231, 234, 238, 240, 242
Structured Data 165
T 
technological resources 2
Tracking systems 41, 47, 50-51, 62, 67, 79, 83
U 
Unmanned Aerial Systems 264-265, 267, 277
Unmanned Aerial Vehicles 224, 228, 264-265, 267, 
273, 276-278
W 
Web 1.0 243-244, 246-247, 261, 263
Web 2.0 243-247, 249-250, 252-261, 263
Web 3.0 243-247, 249, 253-259, 261-263
web portal 180-183, 185-187, 191-192
Wireless networks 31, 82, 84, 103, 141-142, 196, 
205-206, 220, 225, 235, 238, 241
Workflow Model 167-168, 171-174, 176, 187, 191-
194

