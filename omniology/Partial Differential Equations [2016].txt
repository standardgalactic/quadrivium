168
International Series of Numerical Mathematics
Partial Differential 
Equations: 
Modeling, Analysis 
and Numerical 
Approximation
Herv√© Le Dret
Brigitte Lucquin


ISNM
International Series of Numerical Mathematics
Volume 168
Managing Editor
G. Leugering, Erlangen-N√ºrnberg, Germany
Associate Editors
Z. Chen, Beijing, China
R.H.W. Hoppe, Augsburg, Germany; Houston, USA
N. Kenmochi, Chiba, Japan
V. Starovoitov, Novosibirsk, Russia
Honorary Editor
K.-H. Hoffmann, M√ºnchen, Germany
More information about this series at www.birkhauser-science.com/series/4819

Herv√© Le Dret
‚Ä¢ Brigitte Lucquin
Partial Differential Equations:
Modeling, Analysis and
Numerical Approximation

Herv√© Le Dret
Laboratoire Jacques-Louis Lions
Universit√© Pierre et Marie Curie‚ÄîParis VI
Paris
France
Brigitte Lucquin
Laboratoire Jacques-Louis Lions
Universit√© Pierre et Marie Curie‚ÄîParis VI
Paris
France
ISSN 0373-3149
ISSN 2296-6072
(electronic)
International Series of Numerical Mathematics
ISBN 978-3-319-27065-4
ISBN 978-3-319-27067-8
(eBook)
DOI 10.1007/978-3-319-27067-8
Library of Congress Control Number: 2015955864
Mathematics Subject ClassiÔ¨Åcation (2010): 35J20, 35J25, 35K05, 35K20, 35L03, 35L05, 65M06,
65M08, 65M12, 65N30
Springer Cham Heidelberg New York Dordrecht London
¬© Springer International Publishing Switzerland 2016
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part
of the material is concerned, speciÔ¨Åcally the rights of translation, reprinting, reuse of illustrations,
recitation, broadcasting, reproduction on microÔ¨Ålms or in any other physical way, and transmission
or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar
methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this
publication does not imply, even in the absence of a speciÔ¨Åc statement, that such names are exempt from
the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this
book are believed to be true and accurate at the date of publication. Neither the publisher nor the
authors or the editors give a warranty, express or implied, with respect to the material contained herein or
for any errors or omissions that may have been made.
Printed on acid-free paper
Springer International Publishing AG Switzerland is part of Springer Science+Business Media
(www.birkhauser-science.com)

Preface
This book is devoted to the study of partial differential equation problems both from
the theoretical and numerical points of view. A partial differential equation (PDE) is
a relation between the partial derivatives of an unknown function u in several
variables to be satisÔ¨Åed by this function, for example ou
ot  ou
ox ¬º 0, where u is a
function in the two variables t and x. Partial differential equations constitute a major
Ô¨Åeld of study in contemporary mathematics. They also arise in other Ô¨Åelds of
mathematics, such as differential geometry or probability theory for example. In
addition, partial differential equations appear in a wide variety of contexts in many
applied Ô¨Åelds, not only in the traditional Ô¨Åelds of physics, mechanics and engi-
neering, but also more recently in chemistry, bioscience, medicine, meteorology,
climatology, Ô¨Ånance and so on.
In all of these applied Ô¨Åelds, numerical simulation is playing an increasingly
prominent role, because even though solutions to such PDE problems can be shown
to exist, there is in general no closed form solution. Therefore, quantitative infor-
mation about the solutions can only be obtained by means of numerical approxi-
mation methods. It is very important not to take numerical simulation results at face
value since they inherently present errors. In order to be able to do this, a com-
prehensive knowledge of all the steps involved is necessary, starting from modeling
to mathematical existence theorems, to numerical approximation methods. This is
one of the main purposes of this book.
A numerical approximation method is a procedure in which the original con-
tinuous unknowns are replaced by a Ô¨Ånite number of discrete, computable
approximate unknowns. It is thus important to be able to properly understand on the
one hand the properties of partial differential equations and, on the other hand, the
properties of the numerical methods that are used to deÔ¨Åne approximations of their
solutions and effectively compute such approximations. In particular, it is essential
to quantify the approximation by appropriately deÔ¨Åning the error between
approximate and continuous unknowns, and to show that this error goes to zero,
preferably at a known rate, in the continuous limit when the number of approxi-
mated unknowns goes to inÔ¨Ånity.
v

The goal of this book is to try and illustrate this program through a rather wide
spectrum of classical or not so classical examples. We thus present some modeling
aspects, develop the theoretical analysis of the partial differential equation problems
thus obtained for the three main classes of partial differential equations, and analyze
several numerical approximation methods adapted to each of these examples.
We have selected three broad families of numerical methods, Ô¨Ånite difference,
Ô¨Ånite element and Ô¨Ånite volumes methods. This is far from being exhaustive, but
these three families of methods are the most widely used and constitute the core
skills for anyone intending to work with numerical simulation of partial differential
equations. There are many other numerical methods that we have chosen not to
develop, in order to keep the size of the book within reasonable bounds.
Parts of the book are accessible to Bachelor students in mathematics or engi-
neering. However, most of the book is better suited to Master students in applied
mathematics or computational engineering. We put emphasis on mathematical
detail and rigor for the analysis of both continuous and discrete problems.
The book is structured globally according to the three major types of partial
differential equations: elliptic equations, parabolic equations and hyperbolic equa-
tions. We mainly consider linear equations, except for a few nonlinear examples.
Each one of the above three types of equations requires a speciÔ¨Åc set of mathe-
matical techniques for theoretical analysis, and a speciÔ¨Åc set of numerical methods,
i.e., speciÔ¨Åc discretization procedures and convergence analyses for approximation.
We follow a path of progressive difÔ¨Åculty in each case inasmuch as possible. We
begin with the most elementary approaches either theoretical or numerical, which
also happen to be the earliest ones from the historical viewpoint. We then continue
to more advanced topics that require a more sophisticated mathematical back-
ground, both from the theoretical and numerical points of view, and that are also
more recent than the previous ones. We also give along the way several numerical
illustrations of successes as well as failures of numerical methods, using free
software such as Scilab and FreeFem++.
The book is divided into ten chapters. Chapter 1 is devoted to mathematical
modeling. We give examples ranging from mechanics and physics to Ô¨Ånance.
Starting from concrete situations, we try to present the various steps leading to a
mathematical model involving partial differential equations to the extent possible.
In some cases, it is possible to start from Ô¨Årst principles and entirely derive the
equations and boundary conditions. In other, more complicated cases, we just give a
few indications concerning the modeling approach and sometimes a historical
account. For some of the examples considered, we also give a short elementary
mathematical study: existence, uniqueness, maximum principle.
In Chap. 2, we present the simplest possible and earliest numerical method, the
so-called Ô¨Ånite difference method. We Ô¨Årst use the example of a one-dimensional
elliptic problem, already introduced in Chap. 1, which is elementary enough not to
require sophisticated mathematical machinery. We then consider a few general-
izations:
one-dimensional
problems
with
other
boundary
conditions,
two-
dimensional problems, still on a rather elementary mathematical level.
vi
Preface

The Ô¨Årst two chapters are accessible at the Bachelor level. The remainder of the
book calls for a higher level of mathematics, with the possible exception of parts of
Chaps. 8 and 10. Chapter 3 is thus devised as a toolbox of more advanced math-
ematical analysis techniques that are required to study more general partial differ-
ential equations, especially in more than one dimension: a review of Hilbert space
theory, usual function spaces, properties of open sets in Rd, multidimensional
integration by parts, distributions, and Sobolev spaces. The results are standard and
we sometimes refer to classical references. We have however detailed some of the
proofs for those results that are not always easy to Ô¨Ånd in the literature. Readers
who are more interested in the numerical aspects can leaf through this chapter and
keep it for future reference. For the reader‚Äôs convenience, the chapter is concluded
by a summary of the most important results that are used in the sequel.
Chapter 4 is concerned with the variational formulation of multidimensional
elliptic boundary value problems, which is a very powerful way of rewriting certain
partial differential equation problems in an abstract Hilbertian setting, in order to
prove the existence and uniqueness of solutions. We provide many examples of
such problems. Most of these examples are problems of second order, i.e., the
maximum order of derivatives appearing in the partial differential equation is two,
with one fourth order example. We also consider a variety of boundary conditions.
The variational formulation also makes it possible to devise numerical approx-
imation methods in a very natural and uniÔ¨Åed fashion. We introduce such methods
in Chap. 5. The approximate problems are set in the same framework as the con-
tinuous problem. This framework also provides a fundamental error estimate.
Of particular interest to us is the Ô¨Ånite element method introduced and analyzed in
detail on simple one-dimensional examples.
In Chap. 6, we study the generalization of the Ô¨Ånite element method to
two-dimensional elliptic problems. We start by a detailed presentation of approx-
imation using rectangular Ô¨Ånite elements. We provide a convergence estimate in the
case of the Lagrange rectangular element of lowest possible degree and give
indications about convergence for higher degrees. We then introduce the concept of
barycentric coordinates and use them to describe Lagrange triangular Ô¨Ånite ele-
ments of degree up to three.
The elliptic problems considered so far correspond to the modeling of static or
equilibrium situations, with no time evolution. We then turn to evolution problems
in Chap. 7 with the theoretical study of the heat equation, which is the prototypical
parabolic equation: maximum principle, existence and uniqueness of regular
solutions, energy estimates, variational formulation and weak solutions. New
mathematical tools are needed, mainly Hilbert space-valued function spaces, which
we introduce as the need arises. We also mention and discuss the heat kernel in the
case of the heat equation in the whole space.
We next consider the numerical approximation of the heat equation in Chap. 8.
We focus on the Ô¨Ånite difference method, already seen for static problems in
Chap. 2. We consider several Ô¨Ånite difference schemes of various precision. The
convergence of such schemes rest on their consistency and stability. The analysis
Preface
vii

of these schemes is signiÔ¨Åcantly more complicated in the evolution case than in the
static case, due in particular to rather subtle stability issues, which we analyze in
detail and from several different viewpoints. We also mention other methods such
as the Ô¨Ånite difference-Ô¨Ånite element method, in which time is discretized using
Ô¨Ånite differences and space is discretized using Ô¨Ånite elements.
Chapter 9 is devoted to both theoretical and numerical analyses of another
classical evolution problem, the wave equation. This equation is the prototypical
hyperbolic equation of second order. We Ô¨Årst study the continuous problem and
prove the existence and uniqueness of regular solutions and then of weak solutions.
We next consider Ô¨Ånite difference schemes for the wave equation. The stability
issues are again signiÔ¨Åcantly subtler than in the case of the heat equation, and take
up most of the exposition concerning numerical methods.
Finally, we present the Ô¨Ånite volume method in Chap. 10, again on examples.
Finite volume methods are the most recent of the numerical methods covered in the
book. They are currently widely used in certain areas of applications such as
computational Ô¨Çuid dynamics. We start with the one-dimensional elliptic problem
of Chap. 2 with a description of the Ô¨Ånite volume discretization and a complete
convergence analysis. We then consider the one-dimensional transport equation,
which is the prototypical hyperbolic equation of Ô¨Årst order. This equation is solved
via the method of characteristics. We then introduce several linear Ô¨Ånite volume
schemes and study their properties of consistency, stability and convergence. We
also present the method on a few examples in the nonlinear case and for the
two-dimensional transport equation.
The contents of this book are signiÔ¨Åcantly expanded from a series of Ô¨Årst year
Master degree classes, taught by the authors at UPMC (Universit√© Pierre et Marie
Curie) in Paris, France, over several years. It is intended to be as self-contained as
possible. It consequently provides more than enough material for a one semester
Master class on the subject. The book can also serve as a wide spectrum monograph
for more advanced readers.
We are indebted to the students who have attended our classes and asked many
questions that contributed to making the text more readable. We would like to thank
our colleagues Muriel Boulakia, Edwige Godlewski, Sidi Mahmoud Kaber and
G√©rard Tronel, for carefully reading parts of the manuscript and making numerous
suggestions that improved it signiÔ¨Åcantly. We also thank the anonymous referees
for making several constructive comments.
Paris, France
Herv√© Le Dret
Brigitte Lucquin
viii
Preface

Contents
1
Mathematical Modeling and PDEs . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
The Elastic String. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.2
The Elastic Beam. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
10
1.3
The Elastic Membrane . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12
1.4
The Transport Equation. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
18
1.5
The Vibrating String Equation . . . . . . . . . . . . . . . . . . . . . . . .
22
1.6
The Wave Equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
26
1.7
The Heat Equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
27
1.8
The Schr√∂dinger Equation . . . . . . . . . . . . . . . . . . . . . . . . . . .
30
1.9
The Black and Scholes Equation . . . . . . . . . . . . . . . . . . . . . .
31
1.10
A Rough ClassiÔ¨Åcation of PDEs . . . . . . . . . . . . . . . . . . . . . .
33
1.11
What Comes Next . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
2
The Finite Difference Method for Elliptic Problems . . . . . . . . . . . .
35
2.1
Approximating Derivatives by Differential Quotients . . . . . . . .
35
2.2
Application to a One-Dimensional Model Problem . . . . . . . . . .
38
2.3
Convergence of the Finite Difference Method . . . . . . . . . . . . .
41
2.4
Neumann Boundary Conditions . . . . . . . . . . . . . . . . . . . . . . .
48
2.5
The Two-Dimensional Case. . . . . . . . . . . . . . . . . . . . . . . . . .
57
2.6
Concluding Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
67
3
A Review of Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
69
3.1
Basic Hilbert Space Theory . . . . . . . . . . . . . . . . . . . . . . . . . .
69
3.2
A Few Basic Function Spaces . . . . . . . . . . . . . . . . . . . . . . . .
72
3.3
Regularity of Open Subsets of Rd . . . . . . . . . . . . . . . . . . . . .
76
3.4
Partitions of Unity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
82
3.5
Integration by Parts in Dimension d and Applications. . . . . . . .
87
3.6
Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
90
3.7
Sobolev Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
99
ix

3.8
Properties of Sobolev Spaces in One Dimension . . . . . . . . . . . 105
3.9
Density of Smooth Functions and Trace in Dimension d . . . . . . 108
3.10
A Summary of Important Results . . . . . . . . . . . . . . . . . . . . . . 115
4
The Variational Formulation of Elliptic PDEs . . . . . . . . . . . . . . . . 117
4.1
Model Boundary Value Problems. . . . . . . . . . . . . . . . . . . . . . 117
4.2
Abstract Variational Problems . . . . . . . . . . . . . . . . . . . . . . . . 122
4.3
Application to the Model Problems, and More . . . . . . . . . . . . . 126
4.4
General Second Order Elliptic Problems . . . . . . . . . . . . . . . . . 136
4.5
Concluding Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
5
Variational Approximation Methods for Elliptic PDEs. . . . . . . . . . 145
5.1
The General Abstract Variational Approximation Scheme . . . . . 145
5.2
The Finite Element Method in Dimension One . . . . . . . . . . . . 149
5.3
Comparison with the Finite Difference Method . . . . . . . . . . . . 157
5.4
A Fourth Order Example. . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
5.5
Neumann and Fourier Conditions . . . . . . . . . . . . . . . . . . . . . . 165
6
The Finite Element Method in Dimension Two . . . . . . . . . . . . . . . 167
6.1
Meshes in 2d. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
6.2
Rectangular Q1 Finite Elements . . . . . . . . . . . . . . . . . . . . . . . 172
6.3
Convergence and Error Estimate for the Q1FEM . . . . . . . . . . . 177
6.4
Assembling the Matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183
6.5
General DeÔ¨Ånition of a Finite Element . . . . . . . . . . . . . . . . . . 189
6.6
Q2 and Q3 Finite Elements . . . . . . . . . . . . . . . . . . . . . . . . . . 191
6.7
Barycentric Coordinates . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
6.8
Triangular P1 Lagrange Elements . . . . . . . . . . . . . . . . . . . . . . 204
6.9
Triangular P2 Lagrange Elements . . . . . . . . . . . . . . . . . . . . . . 209
6.10
An Example of 2d-Computation. . . . . . . . . . . . . . . . . . . . . . . 215
7
The Heat Equation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 219
7.1
Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 219
7.2
The Maximum Principle for the Heat Equation . . . . . . . . . . . . 220
7.3
Construction of a Regular Solution. . . . . . . . . . . . . . . . . . . . . 222
7.4
Spaces of Hilbert Space-Valued Functions. . . . . . . . . . . . . . . . 230
7.5
Energy Estimates, Stability, Uniqueness . . . . . . . . . . . . . . . . . 234
7.6
Variational Formulation and Existence of Weak Solutions. . . . . 237
7.7
The Heat Equation on R . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245
8
The Finite Difference Method for the Heat Equation . . . . . . . . . . . 253
8.1
The Explicit Euler Three Point Finite Difference Scheme
for the Heat Equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253
8.2
The Implicit Euler and Leapfrog Schemes . . . . . . . . . . . . . . . . 259
8.3
General Finite Difference Schemes, Consistency, Stability,
Convergence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260
8.4
General Criteria for Stability . . . . . . . . . . . . . . . . . . . . . . . . . 269
8.5
Stability for One Time Step Schemes in the 2; h Norms . . . . . . 273
x
Contents

8.6
Stability via the Discrete Fourier Transform. . . . . . . . . . . . . . . 282
8.7
Stability via Fourier Series . . . . . . . . . . . . . . . . . . . . . . . . . . 286
8.8
Stability via the Continuous Fourier Transform . . . . . . . . . . . . 292
8.9
The Crank‚ÄìNicolson Scheme, Stability
via the Energy Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 296
8.10
Other Approximations of the Heat Equation . . . . . . . . . . . . . . 302
9
The Wave Equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 307
9.1
Regular Solutions of the Wave Equation . . . . . . . . . . . . . . . . . 307
9.2
Variational Formulation and Existence of Weak Solutions. . . . . 313
9.3
The Wave Equation on R . . . . . . . . . . . . . . . . . . . . . . . . . . . 317
9.4
Finite Difference Schemes for the Wave Equation . . . . . . . . . . 320
9.5
Stability via the Fourier Approach . . . . . . . . . . . . . . . . . . . . . 327
9.6
For a Few Schemes More . . . . . . . . . . . . . . . . . . . . . . . . . . . 341
9.7
Concluding Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344
10
The Finite Volume Method. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 345
10.1
The Elliptic Case in One Dimension. . . . . . . . . . . . . . . . . . . . 345
10.2
The Transport Equation in One Dimension . . . . . . . . . . . . . . . 351
10.3
Finite Volumes for the Transport Equation . . . . . . . . . . . . . . . 354
10.4
Explicit Three Point Schemes . . . . . . . . . . . . . . . . . . . . . . . . 361
10.5
Examples of Linear Schemes . . . . . . . . . . . . . . . . . . . . . . . . . 370
10.6
Generalizations to Discontinuous Data and Nonlinear
Problems. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 372
10.7
The Transport Equation in an Open Set
in Higher Dimensions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 375
10.8
Finite Volumes for the Transport Equation
in Two Dimensions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 377
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 383
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 387
Contents
xi

Chapter 1
Mathematical Modeling and PDEs
In this chapter, we consider several concrete situations stemming from various areas
of applications, the mathematical modeling of which involves partial differential
equation problems. We will not be rigorous mathematically speaking. There will be
quite a few rather brutal approximations, not always convincingly justiÔ¨Åed. This is
however the price to be paid if we want to be able to derive mathematical models that
aim to describe the complex phenomena we are dealing with in a way that remains
manageable. At a later stage, we will study some of these models with all required
mathematical rigor.
The simplest examples arise in mechanics. Let us start with the simplest example
of all.
1.1
The Elastic String
Let us Ô¨Årst consider the situation depicted in Fig.1.1.
What is an elastic string in real life? The term can refer to several different objects,
such as a stretched rubber band, the strings of a musical instrument made of nylon
or steel, or again a cabin lift cable. Up to a certain level of approximation, all these
objects are modeled in the same way. What they all have in common is a very small
aspect ratio: they are three-dimensional, however much thinner in two directions
than in the third one. Thus, the Ô¨Årst step toward a simple mathematical model is to
simply declare them to be one-dimensional at the onset. Points in a string will thus be
labeled by a single real-valued variable x belonging to a segment [0, L], embedded
in R2 or R3. Another implicit assumption used here is the assumption of continuum
mechanics. We assume that matter is a continuum which can be divided indeÔ¨Ånitely.
This is obviously untrue, but it is true enough at the macroscopic scale to be an
extremely effective modeling hypothesis.
¬© Springer International Publishing Switzerland 2016
H. Le Dret and B. Lucquin, Partial Differential Equations:
Modeling, Analysis and Numerical Approximation, International Series
of Numerical Mathematics 168, DOI 10.1007/978-3-319-27067-8_1
1

2
1
Mathematical Modeling and PDEs
0
L
x
u(x)
applied force
Fig. 1.1 An elastic string stretched between two points and pulled by some vertical force. The
point initially located at x moves by a vertical displacement u(x) to an equilibrium position
Fig. 1.2 Stretching a string with a wheel and a weight
x
y
T‚àí(x)
T+(y)
Fig. 1.3 A piece of string cut at x and y, then kept in equilibrium
We assume that the string is stretched with a tension T > 0. The tension is just
the force that is applied at both extremities 0 and L in order to make the string taut,
for instance by working the tuners of a guitar or by passing the string on a wheel and
suspending a weight at the end with the other end attached to a wall, see Fig.1.2.
In terms of physical units, the tension is measured in Newton (N). If the only force
acting on the string is the tension, then the string settles in an equilibrium position
which is none but the segment [0, L].
We now perform a thought experiment by cutting the string at two points of [0, L],
located at two arbitrary abscissae x and y with x < y. If the piece of string that has
just been cut is going to stay in the same place, it is quite clear that we need to apply
horizontal forces T‚àí(x) < 0 and T+(y) > 0 at the two newly created extremities, in
order to compensate for the disappearance of the rest of the string, see Fig.1.3.
As a matter of fact, T‚àí(x) is the force that was exerted by the [0, x] part of
the string on the segment [x, y] at point x before the string was cut, and T+(y) is
likewise the force formerly exerted by the [y, L] part of the string at point y. The
action-reaction principle immediately shows that we have T‚àí(x) = ‚àíT+(x). Let us
thus just set T (x) = T+(x).
Since the cut out piece of string stays in equilibrium and the only forces acting
on it are the above two tensions, Newton‚Äôs law of motion implies that the resultant

1.1 The Elastic String
3
force vanishes, that is to say that
T (y) ‚àíT (x) = 0.
Now this holds true for all x and y, therefore the tension T (x) inside the string
is constant. Taking x = 0 or x = L, we see that this constant is equal to T , the
string tension applied at the extremities. This is an important‚Äîeven if obvious‚Äî
result, because it holds true irrespective of the physical nature of the string. Whether
a string is made of rubber, nylon or steel, the tension inside is constant and equal to
the applied tension. This is quite remarkable.
From now on, we will work with planar deformations, that is to say, we assume that
the string lives in R2. Of course, a similar model can be derived in three dimensions.
Let us apply other forces to the string, for example its weight or the weight of an
object that is suspended to the string. For simplicity, we assume that this extra force
is perpendicular to the segment‚Äîwe will say that it is vertical whereas the segment
is considered to be horizontal‚Äîand described by a lineic density f . This means that
we are given a function f : [0, L] ‚ÜíR such that the vertical component of the force
applied to a portion [a, b] of the string is equal to the integral
 b
a f (x) dx. Such is the
case of the weight of the string. Assuming the string is homogeneous, then its weight
is represented by the function f (x) = ‚àíœÅg, where œÅ is the string mass per unit
length and g is the gravitational acceleration. If we suspend a weight P to a device
occupying a segment [Œ±, Œ≤] of the string, we may take f (x) = ‚àíP1[Œ±,Œ≤](x), where
1E denotes the characteristic function of a set E: 1E(x) = 1 if x ‚ààE, 1E(x) = 0
otherwise.
Due to the extra applied force, the string deforms and settles in a new, unknown
equilibrium position that we wish to determine. We assume that any point initially
situated at (x, 0) moves vertically and reaches an equilibrium position (x, u(x)), as
in Fig.1.1. This verticality hypothesis is again a modeling hypothesis. It is not strictly
speaking true. In reality, the point in question also settles a little bit to the left or to
the right of the vertical position. However, this hypothesis is reasonable when the
force is vertical and the displacement is small. In this case, it can be justiÔ¨Åed, and we
just admit it here, that the horizontal displacement is negligible in comparison with
the vertical displacement u(x). If the force was slanted, or the displacement large, it
would be an entirely different story.
The deformed string is at this point described by a parametric curve in R2, x ‚Üí
(x, u(x)) where u is an unknown function to be determined. We now make another
modeling hypothesis, which is that we are only interested in those situations where
the derivative u‚Ä≤(x) has small absolute value compared to 1. In this case, the length
element of the deformed string satisÔ¨Åes

1 + u‚Ä≤(x)2 ‚âà1 + 1
2u‚Ä≤(x)2 ‚âà1,

4
1
Mathematical Modeling and PDEs
Fig. 1.4 Cutting out a piece
of the deformed string
x
x+Œ¥ x
‚àíœÑ (x)
œÑ(x+Œ¥ x)
since if u‚Ä≤(x) is small, then u‚Ä≤(x)2 is negligible.1 We are thus dealing with situations
in which the string is approximately inextensional, i.e., there are basically no length
changes compared to the initial straight stretched string.
Let us pick up our thought experiment scissors again and cut the string between
abscissae x and x + Œ¥x, Œ¥x > 0. This time, the string is no longer straight. When we
think about the forces exerted by the rest of the string on the extremities of the part
that was cut, it appears reasonable that these forces should be tangent to the deformed
string at the cut points, see Fig.1.4. This is yet another modeling hypothesis, which
can be justiÔ¨Åed by a more reÔ¨Åned mechanical analysis.
The thought experimenter thus applies a tension force of the form ‚àíT (x)œÑ(x) at
point (x, u(x)), and a tension force T (x +Œ¥x)œÑ(x +Œ¥x) at point (x +Œ¥x, u(x +Œ¥x)),
where œÑ is the unit tangent vector
œÑ(x) =
1

1 + u‚Ä≤(x)2
 1
u‚Ä≤(x)

‚âà
 1
u‚Ä≤(x)

,
in order to keep the piece that was cut out in equilibrium. The above approximation
of the tangent vector is legitimate in view of our decision to neglect terms involving
u‚Ä≤(x)2 and other quantities of higher order.
We apply Newton‚Äôs law of motion again, which yields the vector equation
T (x + Œ¥x)œÑ(x + Œ¥x) ‚àíT (x)œÑ(x) +

0
 x+Œ¥x
x
f (s) ds

=
0
0

.
The horizontal component of the equation implies that T (x) = T is the same constant
as before. The vertical component then reads
T

u‚Ä≤(x + Œ¥x) ‚àíu‚Ä≤(x)

+
 x+Œ¥x
x
f (s) ds = 0,
using the above approximation for the tangent vector. Dividing everything by Œ¥x, we
obtain
1As a general rule, we neglect all terms of order strictly higher than one with respect to u‚Ä≤(x). This
leads to a simpliÔ¨Åed linearized model. A model that would take into account such higher order
terms would be by nature nonlinear, and thus a lot more difÔ¨Åcult to study from the point of view of
mathematics.

1.1 The Elastic String
5
‚àíT u‚Ä≤(x + Œ¥x) ‚àíu‚Ä≤(x)
Œ¥x
= 1
Œ¥x
 x+Œ¥x
x
f (s) ds.
Since one of our modeling hypotheses is that matter can be indeÔ¨Ånitely divided, the
above relation holds true for any value of Œ¥x, no matter how small. We thus let Œ¥x tend
to 0. The left-hand side is a differential quotient, the right-hand side is an average
over a small interval, and we thus obtain in the limit Œ¥x ‚Üí0,
‚àíT u‚Ä≤‚Ä≤(x) = f (x),
which can be rewritten as the Ô¨Årst equation of the following string problem:
‚éß
‚é®
‚é©
‚àíu‚Ä≤‚Ä≤(x) = 1
T f (x) for all x in ]0, L[,
u(0) = u(L) = 0.
(1.1)
The second line of (1.1) expresses the fact that the string is Ô¨Åxed at the endpoints x =
0 and L. These points never move and the displacement is zero there. This condition
is called a boundary condition. Problem (1.1) consists of a differential equation in
an open set (here an ordinary differential equation, since we are in dimension one),
together with a condition on the boundary of the open set. This type of problem is
called a boundary value problem, and we will see many more of them.
If we are somehow capable of solving this problem, then we will have determined
the deformed shape of the string under the action of the applied forces. Indeed,
it is easily checked by following the computations backward, that any solution of
problem (1.1) yields an equilibrium position for the string, at least within the range
of approximations that have been made.
Remark 1.1 In order to appease natural suspicions that it does not feel right to neglect
terms before differentiating them, we can note that

u‚Ä≤(x)

1 + u‚Ä≤(x)2
‚Ä≤
=
u‚Ä≤‚Ä≤(x)

1 + u‚Ä≤(x)2 +
u‚Ä≤(x)2u‚Ä≤‚Ä≤(x)
(1 + u‚Ä≤(x)2)3/2 ‚âàu‚Ä≤‚Ä≤(x),
therefore it was not so bad, a posteriori.
‚ñ°
Remark 1.2 Let us admit for the time being that problem (1.1) has a unique solution
for given f and T . If we consider the same string subjected to the same force, but
with different tensions, we see that the displacement is inversely proportional to the
tension: the tauter the string, the more rigid it behaves and conversely. This is in
agreement with daily life.
Let us emphasize again that the string model is independent of the physical nature
of the string, which can be counterintuitive. A rubber string and a steel string stretched
with the same tension have the same behavior insofar as the model is concerned.
Once the model is derived and solved, a natural question arises: how far apart is
the model solution from real life or how large is the modeling error? This is a difÔ¨Åcult

6
1
Mathematical Modeling and PDEs
question in all generality. However, a few rules of thumb can be useful. For instance,
if a given modeling hypothesis is clearly not satisÔ¨Åed by the model solution, then its
validity is dubious at best. For example, in the case of a string, if we Ô¨Ånd a solution
which is such that |u‚Ä≤(x)| is large for some values of x, in the sense that u‚Ä≤(x)2 can no
longer be neglected, then we know that a more precise model is needed. Of course,
this is still rather vague. An ideal situation would be one in which it was possible to
have an explicit quantitative estimate of the difference in the solutions of models of
various accuracy. Unfortunately, this is rarely possible.
‚ñ°
It is important to understand that, even though the string model derived here
involves an ordinary differential equation because we are in dimension one, a bound-
ary value problem such as problem (1.1) has strictly nothing to do with the Cauchy
problem for the same ordinary differential equation, either in terms of theory or in
terms of numerical approximation.
In particular, the numerical schemes used for the Cauchy problem, such as the
forward and backward Euler methods or the Runge-Kutta method (see for example
[8, 16, 23, 60, 64]), are of no use to compute approximations of the solution of
problem (1.1) (except in the shooting method, see below). Different, more adapted
numerical methods are needed, and we will discuss several of them later on.
To illustrate this, let us introduce a slightly generalized version of the string
problem. We thus consider the following boundary value problem:

‚àíu‚Ä≤‚Ä≤(x) + c(x)u(x) = f (x) in ]0, L[,
u(0) = A, u(L) = B,
(1.2)
where f and c are two given functions deÔ¨Åned on ]0, L[ and A, B are two given
constants. The function c has no speciÔ¨Åc mechanical interpretation in the context
of the elastic string. It just adds generality without costing any extra complexity.
The boundary condition in (1.2) is called a Dirichlet boundary condition. In general,
imposing a Dirichlet condition means ascribing given values to the unknown function
u on the boundary. In the case when A = B = 0, it is called a homogeneous Dirichlet
condition.
Let us now see some of the fundamental differences between a boundary value
problem and a seemingly similar Cauchy problem. The Cauchy problem consists in
replacing the boundary conditions in (1.2) by initial conditions of the form u(0) = Œ±,
u‚Ä≤(0) = Œ≤ and no condition at x = L. We know from the classical theory of ordinary
differential equations (see [16, 23, 60] for example) that this Cauchy problem has
one and only one solution if for example c and f are continuous. The boundary value
problem (1.2) may however not have any solution at all under the same hypotheses!
Let us take the following apparently innocuous example: L = 1, A = B = 0,
c(x) = ‚àíœÄ2 and f (x) = 1. We can treat the Ô¨Årst equation in (1.2) as a linear
ordinary differential equation of second order with constant coefÔ¨Åcients that admits
the general solution

1.1 The Elastic String
7
u(x) = Œª cos(œÄx) + Œº sin(œÄx) ‚àí1
œÄ2 ,
where Œª and Œº are two real parameters. If we write down the homogeneous Dirichlet
boundary conditions, we obtain two relations
Œª ‚àí1
œÄ2 = 0,
‚àíŒª ‚àí1
œÄ2 = 0,
which are impossible to satisfy simultaneously. Consequently, there is no solution to
this particular boundary value problem.
More generally, let us assume that the problem

‚àíu‚Ä≤‚Ä≤(x) ‚àíœÄ2u(x) = f (x) in ]0, 1[,
u(0) = u(1) = 0,
has a regular solution that is for example of class C2. We multiply the differential
equation by sin(œÄx), which yields
‚àíu‚Ä≤‚Ä≤(x) sin(œÄx) ‚àíœÄ2u(x) sin(œÄx) = f (x) sin(œÄx).
We now integrate this equality between 0 and 1. We obtain
‚àí
 1
0
u‚Ä≤‚Ä≤(x) sin(œÄx) dx ‚àíœÄ2
 1
0
u(x) sin(œÄx) dx =
 1
0
f (x) sin(œÄx) dx. (1.3)
Now, if we integrate the Ô¨Årst integral by parts twice, we see that
 1
0
u‚Ä≤‚Ä≤(x) sin(œÄx) dx = [u‚Ä≤(x) sin(œÄx)]1
0 ‚àíœÄ[u(x) cos(œÄx)]1
0 ‚àíœÄ2
 1
0
u(x) sin(œÄx) dx.
The Ô¨Årst two terms vanish because the sine function vanishes at x = 0 and x = 1 for
the Ô¨Årst one, and u vanishes at the same points for the second one by the homogeneous
Dirichlet condition. The remaining integral cancels out with the second integral in
Eq.(1.3). Finally, we Ô¨Ånd that if the problem has a solution u, then
 1
0
f (x) sin(œÄx) dx = 0,
which is therefore a necessary condition for existence. By contraposition, if f is such
that
 1
0 sin(œÄx) f (x) dx Ã∏= 0, for instance f = 1, then the problem cannot have any
regular solution.
Concerning uniqueness, we note that for f = 0, we have the inÔ¨Ånite family of
solutions u(x) = Œº sin(œÄx), Œº ‚ààR. Hence, there is no uniqueness either.
‚ñ°

8
1
Mathematical Modeling and PDEs
The above trick of multiplying the equation by certain well-chosen functions and
integrating the result by parts will be at the heart of the existence and uniqueness
theory using variational formulations, as well as the basis of such variational approx-
imation methods as the Ô¨Ånite element method that we will encounter later on.
We can already prove a uniqueness result. The problem in the previous example
is that the function c is negative (and take the speciÔ¨Åc value ‚àíœÄ2).
Theorem 1.1 If c is a continuous, nonnegative function, then problem (1.2) has at
most one solution of class C2([0, L]).
Proof Let u1 and u2 be two solutions of class C2([0, L]), and set w = u2 ‚àíu1. It is
easily checked that w solves the homogeneous boundary value problem:

‚àíw‚Ä≤‚Ä≤(x) + c(x)w(x) = 0 in ]0, L[,
w(0) = w(L) = 0.
(1.4)
We multiply the differential equation by w and integrate between 0 and L. This yields
‚àí
 L
0
w‚Ä≤‚Ä≤(x)w(x) dx +
 L
0
c(x)w(x)2 dx = 0.
Integrating the Ô¨Årst term by parts once, we obtain
 L
0
[w‚Ä≤(x)2 + c(x)w(x)2] dx = 0,
since [w‚Ä≤w]L
0 = 0, given the boundary conditions satisÔ¨Åed by w. The integrand is
a continuous function which is nonnegative due to the sign hypothesis for c. Its
integral is zero, hence it is identically zero. In particular, w‚Ä≤(x) = 0, which implies
w(x) = w(0) = 0 for all x, hence u1 = u2, which is the uniqueness result.
‚ñ°
Let us say a few words about the shooting method alluded to above, applied to
boundary value problem (1.2). The idea is to use the Cauchy problem for the same
ordinary differential equation, ‚àíu‚Ä≤‚Ä≤(x) + c(x)u(x) = f (x) on ]0, L[, with initial
values u(0) = A, u‚Ä≤(0) = Œª and to try and adjust the parameter Œª so as to reach the
target B for x = L, i.e., u(L) = B, see Fig.1.5.
This Cauchy problem has one and only one solution, which we denote by uŒª, and
we consider the shooting mapping S : R ‚ÜíR, S(Œª) = uŒª(L). The boundary value
problem (1.2) thus has a solution for all B if and only if the mapping S is onto. Let
us study this mapping.
Lemma 1.1 The mapping S is afÔ¨Åne.
Proof Let Œª ‚ààR. We claim that uŒª = Œªu1 + (1 ‚àíŒª)u0. Indeed, if we set v =
Œªu1 + (1 ‚àíŒª)u0, we see that v(0) = ŒªA + (1 ‚àíŒª)A = A, v‚Ä≤(0) = Œªu‚Ä≤
1(0)
+ (1 ‚àíŒª)u‚Ä≤
0(0) = Œª, and

1.1 The Elastic String
9
Fig. 1.5 The shooting
method
0
A
B
L
on target!
missed...
‚àív‚Ä≤‚Ä≤(x)+c(x)v(x) = Œª(‚àíu‚Ä≤‚Ä≤
1(x)+c(x)u1(x))+(1‚àíŒª)(‚àíu‚Ä≤‚Ä≤
0(x)+c(x)u0(x)) = f (x)
in ]0, L[, hence the claim by uniqueness of the Cauchy problem. The Lemma follows
then by taking x = L, which shows that S(Œª) = ŒªS(1) + (1 ‚àíŒª)S(0).
‚ñ°
Theorem 1.2 If c is a continuous, nonnegative function, then problem (1.2) has one
and only one solution of class C2([0, L]).
Proof The mapping S : R ‚ÜíR is afÔ¨Åne by Lemma1.1. Let us show that it is one-
to-one and onto when c ‚â•0. Since S(Œª) = (S(1) ‚àíS(0))Œª + S(0), it is enough to
show S(0) Ã∏= S(1). Let thus assume that S(0) = S(1). We set w = u1 ‚àíu0, which
is thus a solution of problem (1.4). By Theorem1.1, it follows that w = 0, therefore
1 = u‚Ä≤
1(0) = u‚Ä≤
0(0) = 0, contradiction.
‚ñ°
We have seen that existence and uniqueness fail in the particular case L = 1 and
c = ‚àíœÄ2 < 0.
The shooting method can also be used in a numerical context, and in the present
case, it is particularly simple. Indeed, since S is afÔ¨Åne, it is sufÔ¨Åcient to compute
its values for two different values of Œª to determine it entirely. This can be done
numerically using ordinary differential equation schemes such as the forward Euler
scheme or the fourth-order Runge-Kutta scheme for better precision.
The shooting method also applies to nonlinear boundary value problems in one
dimension. In this case, the mapping S is no longer afÔ¨Åne, and computing two of
its values would be the initialization step in the application of a bisection method or
a secant method, for example. Now of course, there is no analogue of the shooting
method in dimensions higher than one, which severely restricts its interest.
Such boundary value problems as (1.2) have an important property called the
maximum principle [35, 40]. As we will see shortly, the proof is banal in dimension
one. However, the maximum principle is a profound property in dimensions strictly
greater than one.

10
1
Mathematical Modeling and PDEs
Theorem 1.3 (Maximum Principle) Assume that c ‚â•0 and that problem (1.2) has
a solution u of class C2. If f ‚â•0 in ]0, L[, A ‚â•0 and B ‚â•0, then we have u ‚â•0
in [0, L].
Proof We argue by contradiction by assuming that there exists a point x0 such that
u(x0) < 0. Since u(0) = A ‚â•0 and u(L) = B ‚â•0, it follows that x0 ‚àà]0, L[. Now
u is continuous, therefore there is an interval [Œ±, Œ≤] such that x0 ‚àà[Œ±, Œ≤] ‚äÇ[0, L]
and u ‚â§0 on [Œ±, Œ≤]. We may assume that u(Œ±) = u(Œ≤) = 0 by the intermediate
value theorem.
On the interval [Œ±, Œ≤], c and f are positive and u is nonpositive, therefore
u‚Ä≤‚Ä≤(x) = c(x)u(x) ‚àíf (x) ‚â§0.
We deduce from this that the function u is concave on [Œ±, Œ≤].
Now as x0 ‚àà[Œ±, Œ≤], there exists Œª ‚àà[0, 1] such that x0 = ŒªŒ± + (1 ‚àíŒª)Œ≤.
Consequently, the concavity of u implies that
u(x0) ‚â•Œªu(Œ±) + (1 ‚àíŒª)u(Œ≤) = 0,
which is a contradiction.
‚ñ°
Remark 1.3 Under the form given above, it is a little hard to see where the maxi-
mum of the principle is. . . because it is hiding. Anyway, one way of understanding
Theorem1.3 is to see it as a monotonicity result. Indeed, the function that maps the
data triple ( f, A, B) to the solution u is monotone. Thus, in the case of the elastic
string, when A = B = 0 and f ‚â•0, in other words when we pull upwards on the
string, then u ‚â•0, which means that the string bends upwards too. So we see a very
natural physical interpretation of the maximum principle that is in agreement with
our intuition. This is also the reason why, in mathematics, the operator ‚àíu‚Ä≤‚Ä≤, or more
generally ‚àíŒîu = ‚àíd
i=1
‚àÇ2u
‚àÇx2
i in higher dimension d, is preferred to the operator
u‚Ä≤‚Ä≤, which has the opposite behavior.
‚ñ°
1.2
The Elastic Beam
Our second example is also an example taken from mechanics. However, the mathe-
matical modeling of this example is considerably more complicated than that of the
string, and we will not explain it here. We are again dealing with essentially one-
dimensional objects that are a lot more rigid than the previous ones, such as a metal
rod, a concrete pillar or a wooden beam. Such objects exhibit a strong resistance to
bending, as opposed to strings.
If we assume that our beam is clamped in a rigid wall at both ends, see Fig.1.6,
then the following boundary value problem is found for the vertical displacement u:

1.2 The Elastic Beam
11
Fig. 1.6 A beam clamped at
both ends

E I u(4)(x) = f (x) in ]0, L[,
u(0) = u‚Ä≤(0) = u(L) = u‚Ä≤(L) = 0,
where f is again the density of the applied vertical force, E > 0 is a coefÔ¨Åcient
which is characteristic of the material of the beam2 and I is a geometric coefÔ¨Åcient
depending on the shape of the cross-section of the beam.3 This is in striking contrast
with the string model in which the nature of the string material and the shape of the
cross-section of the string play no role whatsoever. Note also that there is no tension
in a beam.
The differential equation is a fourth order equation (u(4) denotes the fourth deriv-
ative of u), as opposed to a second order equation in the case of the string, and
accordingly, the Dirichlet boundary conditions involve both u and u‚Ä≤.
We can generalize the equation in the same spirit as before by considering the
boundary value problem

u(4)(x) ‚àí(a(x)u‚Ä≤(x))‚Ä≤ + c(x)u(x) = f (x) in ]0, L[,
u(0) = u‚Ä≤(0) = u(L) = u‚Ä≤(L) = 0,
(1.5)
where the given functions a and c still have no particular mechanical meaning.
We also have uniqueness of C4 solutions when a and c are nonnegative. Indeed, if
w = u2‚àíu1 is the difference between two solutions, multiplying by w the differential
equation satisÔ¨Åed by w, which is the Ô¨Årst equation in (1.5) with zero right-hand side,
and integrating by parts as many times as needed, we obtain
 L
0
[(w‚Ä≤‚Ä≤(x))2 + a(x)(w‚Ä≤(x))2 + c(x)w(x)2] dx = 0,
whence w‚Ä≤‚Ä≤(x) = 0. Consequently, w is an afÔ¨Åne function of the form w(x) = Œ±x +Œ≤.
Since it vanishes at both ends, we deduce that w = 0.
Remark 1.4 A word of warning: there is no maximum principle for such problems as
(1.5) in general. The maximum principle is a property of second order boundary value
problems that does not extend to fourth order problems. Physically, this means that
some mechanical systems modeled by a fourth order equation may exhibit the strange
behavior that when pulled downwards, part of such systems may move upwards. ‚ñ°
2The coefÔ¨Åcient E is called the Young modulus of the material. It is measured in units of pressure.
The higher the coefÔ¨Åcient, the more rigid the material.
3I is an inertia momentum of the cross-section.

12
1
Mathematical Modeling and PDEs
1.3
The Elastic Membrane
Let us now switch to actual PDEs in more than one dimension. The Ô¨Årst example
is still taken from mechanics. It is the two-dimensional version of the elastic string,
and it is called the elastic membrane. As we will see, many of the characteristics of
the elastic string carry over to the elastic membrane.
To get a feeling for what an elastic membrane is, think of plastic wrap suitable
for food contact that you can Ô¨Ånd in your favorite supermarket. Stretch the Ô¨Ålm up to
the sides of some container in order to seal it before you store it in the fridge. In the
beginning, the stretched part of the plastic Ô¨Ålm is planar. Then, as the temperature
of the air inside the container goes down, the inside air pressure diminishes. At the
same time, the atmospheric pressure inside the fridge remains more or less constant
(you are bound to open the door every once in a while). The pressure differential thus
created pushes on the Ô¨Ålm which bends inwards as a result. We wish to determine
the Ô¨Ånal shape of the Ô¨Ålm in three-dimensional space.
This kitchen example above is by far not the only one. There are many instances
of elastic membranes around: the skin of a drum, a biological cell membrane, the
sails of a boat, a party balloon, and so on.
To model this situation, let us be given an open set Œ© of R2, whose boundary ‚àÇŒ©
represents the edge of the container opening. Each point x of the closure ¬ØŒ© of Œ©
represents a material point of the membrane when it is stretched without any other
applied force. Again, we identify a small aspect ratio, three-dimensional object with
a two-dimensional object Ô¨Ålling ¬ØŒ©.
We now subject the membrane to a given force density, such as the above pressure
differential, which is orthogonal to its plane, and is represented by a given function
f : Œ© ‚ÜíR. This time, f is a surfacic force density and the resultant force applied
to a part œâ of Œ© is given by the integral

œâ f (x1, x2) dx1dx2.
As in the case of the elastic string, we make the reasonable albeit approxima-
tive hypothesis that point x is displaced by a quantity u(x) perpendicularly to the
membrane (vertically in Fig.1.7). The displacement u is thus now a function in two
variables u : ¬ØŒ© ‚ÜíR, and the shape of the membrane at equilibrium is a parametric
surface in R3 given by (x1, x2) ‚Üí(x1, x2, u(x1, x2)).
Sinceweassumethatthemembranestickstotheopeningofthecontainer,wegetat
once a homogeneous Dirichlet boundary condition to be satisÔ¨Åed by the displacement
u of the membrane
u(x) = 0 on ‚àÇŒ©.
(1.6)
This condition is the exact analogue in two dimensions of the Dirichlet boundary
condition for an elastic string that is attached at both of its ends.
We next need to obtain an equation that will determine the function u in Œ©, and
based on our previous one-dimensional experience, we can expect partial differential
equations to play the leading role here.
Figure1.7 represents the graph of the function u(x1, x2) = (1 ‚àíx2
1)(1 ‚àíx2
2) on
the square Œ© = ]‚àí1, 1[2, which is the solution of the as yet unwritten membrane

1.3 The Elastic Membrane
13
Fig. 1.7 An elastic
membrane stretched with
tension T = 1 on the square
]‚àí1, 1[2
problem (1.8) for the vertical force f (x1, x2) = 4 ‚àí2(x2
1 + x2
2) and homogeneous
Dirichlet boundary conditions.
The two vectors
a1 =
‚éõ
‚éù
1
0
‚àÇu
‚àÇx1 (x1, x2)
‚éû
‚é†and a2 =
‚éõ
‚éù
0
1
‚àÇu
‚àÇx2 (x1, x2)
‚éû
‚é†
form a basis of the tangent plane to the surface at point (x1, x2, u(x1, x2)).
As in the case of the elastic string, we will only consider situations in which
‚à•‚àáu‚à•=
 ‚àÇu
‚àÇx1
2 +
 ‚àÇu
‚àÇx2
2 is small (which is not exactly the case in Fig.1.7!). This
hypothesis leads us to neglect all quantities that are at least quadratic in the partial
derivatives of u. In particular, when we normalize the above tangent basis vectors,
we obtain the approximation
ai
‚à•ai‚à•=
1

1 +
 ‚àÇu
‚àÇxi
2 ai ‚âàai,
which is analogous to the approximate normalization of the tangent vector to the
deformed elastic string used earlier.
Let us now explain what the word tension means in the case of a membrane.
Because we are in a two-dimensional setting, the situation is a bit more complicated
than for the elastic string. The general principle remains however the same. Let us
consider a part A of the membrane and isolate this part as if it was cut out of the
membrane. Just like the cut piece of string before, what keeps the part A in place must
be forces exerted by the rest of the membrane. It seems reasonable to assume that
these forces are exerted exactly on the boundary ŒìA of A relative to the membrane,
since the membrane cannot act at a distance. Now the boundary in question is a
curve, so that the force in question must be given by a lineic density distributed on

14
1
Mathematical Modeling and PDEs
Fig. 1.8 MagniÔ¨Åed view of
a small square cut out of the
membrane. A few of the
normal vectors are drawn.
The force density exerted by
the rest of the membrane is
equal to T times these
vectors. We can see it pulling
to stretch the piece of
membrane
ŒìA, the resultant force being the integral of the density on ŒìA. This is general for all
two-dimensional continuum mechanics models.
In the case of an elastic membrane, as in the case of a string, we assume that the
above force density lies in the tangent plane to the deformed surface, and furthermore,
that it is normal to ŒìA in the tangent plane and pointing outwards, see Fig.1.8.
Actually, this assumption can be seen as the very deÔ¨Ånition of an elastic membrane.
The tension T > 0 is the norm of this force density‚Äîwe admit here for simplicity
that this norm is a constant, independent of the point4‚Äîit measures the tautness of
the membrane. The physical unit for T is the Newton per meter (N/m).
Let us thus take the scissors out again and cut a small square out of the membrane
around an arbitrary point (¬Øx, u(¬Øx)) with ¬Øx = (¬Øx1, ¬Øx2). More precisely, we consider
the square
C ¬Øx,Œ¥x = ]¬Øx1 ‚àíŒ¥x, ¬Øx1 + Œ¥x[√ó]¬Øx2 ‚àíŒ¥x, ¬Øx2 + Œ¥x[,
in R2, with Œ¥x > 0, and cut out its image by the mapping x ‚Üí(x, u(x)) in R3, see
Fig.1.8. We also make no distinction between the boundary of the image of C ¬Øx,Œ¥x
in R3 and its boundary as a subset of R2 in the computation of the integrals. This is
because ‚à•‚àáu‚à•is assumed to be small. We already made this approximation in the
case of the string, without mentioning it. . . The exact computations can of course be
performed in order to make sure that this approximation is really justiÔ¨Åed.
In order to compute the integral, we number the four sides of the square counter-
clockwise:Œ≥ 1
¬Øx,Œ¥x = ]¬Øx1‚àíŒ¥x, ¬Øx1+Œ¥x[√ó{¬Øx2‚àíŒ¥x},Œ≥ 2
¬Øx,Œ¥x = {¬Øx1+Œ¥x}√ó]¬Øx2‚àíŒ¥x, ¬Øx2+Œ¥x[,
and so on for Œ≥ 3
¬Øx,Œ¥x and Œ≥ 4
¬Øx,Œ¥x. According to the normal vectors depicted in Fig.1.8,
Newton‚Äôs law of motion for the vertical force component then reads
4This can of course be proved with a little more work.

1.3 The Elastic Membrane
15
T

Œ≥ 1
¬Øx,Œ¥x
‚àí[a2(x)]3 dŒ≥ +

Œ≥ 2
¬Øx,Œ¥x
[a1(x)]3 dŒ≥
+

Œ≥ 3
¬Øx,Œ¥x
[a2(x)]3 dŒ≥ +

Œ≥ 4
¬Øx,Œ¥x
‚àí[a1(x)]3 dŒ≥

+

C ¬Øx,Œ¥x
f (x) dx = 0,
(1.7)
where [z]3 denotes the vertical component of vector z. It is a simple exercise to
check that the horizontal components already satisfy Newton‚Äôs law. Let us write
each integral separately. We have

Œ≥ 1
¬Øx,Œ¥x
[a2(x)]3 dŒ≥ =
 ¬Øx1+Œ¥x
¬Øx1‚àíŒ¥x
‚àÇu
‚àÇx2
(x1, ¬Øx2 ‚àíŒ¥x) dx1,

Œ≥ 2
¬Øx,Œ¥x
[a1(x)]3 dŒ≥ =
 ¬Øx2+Œ¥x
¬Øx2‚àíŒ¥x
‚àÇu
‚àÇx1
(¬Øx1 + Œ¥x, x2) dx2,

Œ≥ 3
¬Øx,Œ¥x
[a2(x)]3 dŒ≥ =
 ¬Øx1+Œ¥x
¬Øx1‚àíŒ¥x
‚àÇu
‚àÇx2
(x1, ¬Øx2 + Œ¥x) dx1,

Œ≥ 4
¬Øx,Œ¥x
[a1(x)]3 dŒ≥ =
 ¬Øx2+Œ¥x
¬Øx2‚àíŒ¥x
‚àÇu
‚àÇx1
(¬Øx1 ‚àíŒ¥x, x2) dx2.
Formula (1.7) can thus be rewritten as
T
 ¬Øx1+Œ¥x
¬Øx1‚àíŒ¥x
 ‚àÇu
‚àÇx2
(x1, ¬Øx2 + Œ¥x) ‚àí‚àÇu
‚àÇx2
(x1, ¬Øx2 ‚àíŒ¥x)

dx1
+
 ¬Øx2+Œ¥x
¬Øx2‚àíŒ¥x
 ‚àÇu
‚àÇx1
(¬Øx1 + Œ¥x, x2) ‚àí‚àÇu
‚àÇx1
(¬Øx1 ‚àíŒ¥x, x2)

dx2

+

C ¬Øx,Œ¥x
f (x) dx = 0.
The situation is less transparent than in dimension one, but the idea is the same. We
divide everything by 4(Œ¥x)2. This yields
‚àíT 1
2Œ¥x
 ¬Øx1+Œ¥x
¬Øx1‚àíŒ¥x
‚àÇu
‚àÇx2 (x1, ¬Øx2 + Œ¥x) ‚àí‚àÇu
‚àÇx2 (x1, ¬Øx2 ‚àíŒ¥x)
2Œ¥x
dx1
+
 ¬Øx2+Œ¥x
¬Øx2‚àíŒ¥x
‚àÇu
‚àÇx1 (¬Øx1 + Œ¥x, x2) ‚àí‚àÇu
‚àÇx1 (¬Øx1 ‚àíŒ¥x, x2)
2Œ¥x
dx2

=
1
4(Œ¥x)2

C ¬Øx,Œ¥x
f (x) dx.

16
1
Mathematical Modeling and PDEs
Now the length of each of the segments on which differential quotients of the partial
derivatives ‚àÇu/‚àÇxi are integrated is exactly 2Œ¥x, and the area of the square is exactly
4(Œ¥x)2. We thus see that all the above quantities are averages over small segments
or squares, which is good in view of letting Œ¥x tend to 0 later.
Let us assume that u is of class C2. We can thus write the following Taylor-
Lagrange expansion at ¬Øx
‚àÇu
‚àÇx2
(x) = ‚àÇu
‚àÇx2
(¬Øx) +
‚àÇ2u
‚àÇx2‚àÇx1
(¬Øx)(x1 ‚àí¬Øx1) + ‚àÇ2u
‚àÇx2
2
(¬Øx)(x2 ‚àí¬Øx2) + r(x)
where r(x)/‚à•x ‚àí¬Øx‚à•‚Üí0 when ‚à•x ‚àí¬Øx‚à•‚Üí0. Therefore
‚àÇu
‚àÇx2 (x1, ¬Øx2 + Œ¥x) ‚àí‚àÇu
‚àÇx2 (x1, ¬Øx2 ‚àíŒ¥x)
2Œ¥x
= ‚àÇ2u
‚àÇx2
2
(¬Øx) + r1(x1, Œ¥x)
where r1(x1, Œ¥x) ‚Üí0 when |x1 ‚àí¬Øx1| ‚â§Œ¥x and Œ¥x ‚Üí0. Integrating with respect to
x1, we obtain
1
2Œ¥x
 ¬Øx1+Œ¥x
¬Øx1‚àíŒ¥x
‚àÇu
‚àÇx2 (x1, ¬Øx2 + Œ¥x) ‚àí‚àÇu
‚àÇx2 (x1, ¬Øx2 ‚àíŒ¥x)
2Œ¥x
dx1 = ‚àÇ2u
‚àÇx2
2
(¬Øx) + r2(Œ¥x)
where r2(Œ¥x) ‚Üí0 when Œ¥x ‚Üí0.
We treat the remaining integral on the boundary in the same fashion and we obtain
1
2Œ¥x
 ¬Øx2+Œ¥x
¬Øx2‚àíŒ¥x
‚àÇu
‚àÇx1 (¬Øx1 + Œ¥x, x2) ‚àí‚àÇu
‚àÇx1 (¬Øx1 ‚àíŒ¥x, x2)
2Œ¥x
dx2 ‚Üí‚àÇ2u
‚àÇx2
1
(¬Øx)
when Œ¥x ‚Üí0. Finally, assuming that f is continuous, we have
1
4(Œ¥x)2

C ¬Øx,Œ¥x
f (x) dx ‚Üíf (¬Øx) when Œ¥x ‚Üí0,
since the left-hand side is the average of f over the square.
We have thus obtained in the Œ¥x ‚Üí0 limit
‚àÄ¬Øx ‚ààŒ©,
‚àíŒîu(¬Øx) = 1
T f (¬Øx).
(1.8)
The differential operator Œî =
‚àÇ2
‚àÇx2
1 + ‚àÇ2
‚àÇx2
2 is called the Laplacian or Laplace operator.
Equation(1.8) is called the elastic membrane equation. It is a second order equation
since it only involves second derivatives, the order of a partial differential equation
being the highest order of derivatives that appear in the equation. The equation must
naturally be complemented by some boundary conditions, such as the homogeneous
Dirichlet condition (1.6).

1.3 The Elastic Membrane
17
The mechanical remarks made in the case of the elastic string also apply to the
elastic membrane and we will not repeat them.
More generally, the boundary value problem in any dimension, Œ© ‚äÇRd, d ‚â•1,

‚àíŒîu = f in Œ©,
u = 0 on ‚àÇŒ©,
(1.9)
with Œîu = d
i=1
‚àÇ2u
‚àÇx2
i , is called the Poisson equation. The Poisson equation shows
up in a surprising number of different areas of mathematics and its applications. For
example, for d = 3, if f represents the density of electrical charge present in Œ©
and the boundary of Œ© is covered by a perfectly conducting material, then ‚àíu is the
electric potential5 inside Œ©. The gradient of ‚àíu is the electric Ô¨Åeld. More generally,
the Poisson equation is central in all questions relating to the Newtonian potential,
e.g. in electromagnetism, in classical gravity.
There are many other interpretations. Thus, if f represents a density of heat
sources in Œ©, say the distribution of radiators in a room and how much heat they
give off, then u is the equilibrium temperature in Œ© when the walls of the room ‚àÇŒ©
are somehow kept at temperature 0‚ó¶. This is why the Poisson equation is sometimes
referred to as the diffusion equation, as it also models the diffusion of heat (and of
other things that may want to diffuse). We will return to the heat equation later on.
There is also a probabilistic interpretation of the Poisson equation, not unrelated
to the diffusion interpretation. For f = 2, u(x) is the expectation of the Ô¨Årst exit time
from Œ© of a standard Brownian motion starting from point x. Roughly speaking, a
particle moving randomly in Rd and starting from a point x in ¬ØŒ© will reach ‚àÇŒ© for
the Ô¨Årst time in an average time u(x).
Finally, when f = 0, the equation is known as the Laplace equation whose
solutions are the harmonic functions (it is clearly better to impose a nonzero boundary
condition to have u Ã∏= 0, or no condition at all). Harmonic functions are of course
extremely important in many areas.
The Poisson equation satisÔ¨Åes the maximum principle, see [20, 25, 61] among
others.
Theorem 1.4 (Maximum Principle) Let Œ© be a bounded open subset of Rd and
u ‚ààC2(Œ©) ‚à©C0( ¬ØŒ©) be a solution of the Poisson equation (1.9) with f ‚â•0 in Œ©.
Then we have u ‚â•0 in ¬ØŒ©.
This is again a monotonicity result. For instance, in Fig.1.7, the membrane is pulled
upward by the applied force, and consequently bends upwards.
Let us close this section by rapidly mentioning the plate equation. A plate is to
a membrane what a beam is to a string: sheet iron, concrete wall, wood plank. The
clamped plate problem reads
5The minus sign is due to the physical convention that goes contrary to the mathematical convention
in this case.

18
1
Mathematical Modeling and PDEs
‚éß
‚é®
‚é©
Œî2u = f in Œ©,
u = ‚àÇu
‚àÇn = 0 on ‚àÇŒ©,
(1.10)
where the operator Œî2 = Œî ‚ó¶Œî =
‚àÇ4
‚àÇx4
1 + 2
‚àÇ4
‚àÇx2
1‚àÇx2
2 +
‚àÇ4
‚àÇx4
2 is called the bilaplacian
and ‚àÇu
‚àÇn = ‚àáu ¬∑ n =
‚àÇu
‚àÇx1 n1 + ‚àÇu
‚àÇx2 n2 is the normal derivative of u on the boundary,
n denoting the unit exterior normal vector (we will go back to this later). This is a
fourth order boundary value problem. A real plate model also contains mechanical
constants which depend on the nature of the material as well as the thickness of the
plate.
All the problems considered up to now are stationary problems in which time
plays no role and only model equilibrium situations. Let us now talk about problems
where time intervenes, that is to say evolution problems.
1.4
The Transport Equation
Let us imagine a kind of gas composed of particles moving in an inÔ¨Ånite straight tube
T in R3 of the form R√óD, where D is a disk of unit area in the (x2, x3) plane. Instead
of tracking each particle individually, which would be impossible in practice due to
their huge number, we can describe the gas by using a function u : T √ó R+ ‚ÜíR+,
where u(x, t) measures the quantity of particles, or rather their density at point x
and instant t. This is called a kinetic description. The initial density of particles at
t = 0 is denoted by u0(x) = u(x, 0). We assume it to be given, it is called an initial
condition.
Let us count the total number of particles in a section [y, y + Œ¥y] √ó D of the
tube. We disregard the fact that this number should be an integer. In fact, we consider
cases in which this integer is so large as to appear like a continuous quantity at
the macroscopic scale. Think of the Avogadro number and the fact that quantities
of matter are actually measured in moles. By deÔ¨Ånition of a density, at time t, this
quantity is equal to Q(y, Œ¥y, t) =
 y+Œ¥y
y

D u(x, t) dx1dx2dx3. For simplicity, we
assume that the density u only depends on x1, and we will henceforth drop the
subscript 1, so that Q(y, Œ¥y, t) =
 y+Œ¥y
y
u(x, t) dx, since the area of D is 1.
Now the question is how does the gas evolve in time? We clearly need to make
hypotheses on the individual motions of particles in order to answer this question.
For maximum simplicity, we assume here that all the particles move at the same
constant speed ae1, where a ‚ààR, is given. If a > 0, they all move to the right on
Fig.1.9, if a < 0, they all move to the left, and if a = 0, they do not move at all.
Since all particles move as a group at speed ae1, all the particles that were in the
tube section situated between {y} √ó D and {y + Œ¥y} √ó D at time 0, are going to be
located between {y + at} √ó D and {y + Œ¥y + at} √ó D at time t, and no other particle
will be there at the same time. Therefore, we have a conservation law: for all y, Œ¥y
and t

1.4 The Transport Equation
19
Fig. 1.9 Particles in the tube
Q(y + at, Œ¥y, t) = Q(y, Œ¥y, 0).
(1.11)
Let us differentiate relation (1.11) with respect to t. We obtain
0 = d
dt Q(y + at, Œ¥y, t) = d
dt
 y+Œ¥y+at
y+at
u(x, t) dx

= a[u(y + Œ¥y + at, t) ‚àíu(y + at, t)] +
 y+Œ¥y+at
y+at
‚àÇu
‚àÇt (x, t) dx.
Here again we Ô¨Ånd a relation that begs to be divided by Œ¥y. So we oblige, then let Œ¥y
tend to 0 so that
‚àÇu
‚àÇt (y + at, t) + a ‚àÇu
‚àÇx (y + at, t) = 0.
Now y andt arearbitrary, thereforewecanperformthechangeof variables x = y+at
and obtain the following PDE problem:
‚éß
‚é®
‚é©
‚àÇu
‚àÇt (x, t) + a ‚àÇu
‚àÇx (x, t) = 0 for (x, t) ‚ààR √ó R+,
u(x, 0) = u0(x) for x ‚ààR.
The PDE above is the transport equation (at velocity a), together with an initial
condition. The conjunction of the two form an initial value problem. There is no
boundary condition here because the space variable x ranges over the whole of R.
The PDE itself is of Ô¨Årst order in time and space.
Let us now proceed to solve the transport equation. Since the particles all move at
the same velocity a, we can look at the variation of u on the trajectory of one particle
t ‚Üíx + at with x Ô¨Åxed. We thus compute the derivative
d
dt

u(x + at, t)

= a ‚àÇu
‚àÇx (x + at, t) + ‚àÇu
‚àÇt (x + at, t) = 0.

20
1
Mathematical Modeling and PDEs
Fig. 1.10 The
characteristics are the dashed
straight lines with slope 1/a.
If a = 0, they are vertical
and there is no propagation
In other words, u is constant on the trajectories. In particular,
u(x + at, t) = u(x, 0) = u0(x).
(1.12)
The curves t ‚Üí(x + at, t) in space-time R √ó R+‚Äîwhich are here straight lines‚Äî
are called the characteristics of the equation, and their use to solve the equation is
accordingly called the method of characteristics. They are often drawn in a space-
time diagram as shown on Fig.1.10.
To determine the value of u at a point (x, t) in space-time, it is enough to look at
the unique characteristic going through this point, take the point where it intersects
the t = 0 axis and take the value of u0 at that point, see Fig.1.10. This construction
simply amounts to rewriting formula (1.12) in the form
u(x, t) = u0(x ‚àíat),
(1.13)
which proves the uniqueness of the solution, due to an explicit formula!6
We have established the uniqueness of the solution, but have not yet established
its existence. Fortunately, we have an explicit formula, therefore we just need to
check that it actually is a solution. Let us compute the partial derivatives of u given
by formula (1.13), assuming u0 smooth enough. We have
‚àÇu
‚àÇx (x, t) = u‚Ä≤
0(x ‚àíat) and ‚àÇu
‚àÇt (x, t) = ‚àíau‚Ä≤
0(x ‚àíat),
where u‚Ä≤
0 is the ordinary derivative of u0. The PDE is thus clearly satisÔ¨Åed. Moreover,
theinitialconditionisalsotriviallysatisÔ¨Åedbysettingt = 0 informula (1.13).Hence,
we have found the unique solution.
It is apparent that u propagates or transports the initial data at constant speed a,
hence the name of the equation. This transport of the density is the macroscopic
manifestation of the individual microscopic behavior of the gas particles.
6Explicit solutions are very rare in PDE problems.

1.4 The Transport Equation
21
Fig. 1.11 Propagation of the
initial data u0
x
x0
u0
u(¬∑,t)
x0 +at
If it was possible to animate Fig.1.11 on paper, the solid curve would be seen to
glide to the right at a steady pace (a > 0 in the picture) without changing shape,
after having coincided with the dashed curve at t = 0.
The transport equation has higher dimensional versions, which are much more
complicated than the one-dimensional version. It can also be set in open sets of Rd
instead of on the whole of Rd, see Chap.10. In this case, boundary conditions must
be added in addition to the initial condition, which makes it an initial-boundary value
problem. The boundary value question is delicate depending on whether the transport
velocity, which is then a vector, points inwards or outwards of the open set. Let us
illustrate this on a simple one-dimensional example. To be speciÔ¨Åc, we suppose that
the constant speed a is strictly positive and we consider the problem
‚éß
‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é©
‚àÇu
‚àÇt (x, t) + a ‚àÇu
‚àÇx (x, t) = 0 for x ‚àà]0, 1[, t > 0,
u(x, 0) = u0(x) for x ‚àà[0, 1],
u(0, t) = g(t) for t > 0,
where g is a given Dirichlet boundary condition at x = 0 such that g(0) = u0(0)
and g‚Ä≤(0) = ‚àíau‚Ä≤
0(0). This problem has the explicit solution for t > 0
u(x, t) =

u0(x ‚àíat)
for at ‚â§x ‚â§1,
g(t ‚àíx
a )
for 0 ‚â§x ‚â§min(at, 1).
(1.14)
This means that the initial condition is transported along the characteristics in the
region at ‚â§x ‚â§1, t > 0, whereas it is the boundary condition at x = 0 that is
transported, still along the characteristics, in the region 0 ‚â§x ‚â§min(at, 1), see
Fig.1.12.
In particular, expression (1.14) imposes the value u(1, t) = u0(1 ‚àíat) for t < 1
a
and u(1, t) = g

t ‚àí1
a

for t ‚â•1
a at x = 1, so that it is not possible to ascribe a
Dirichlet boundary condition at point x = 1. Note that in the case a < 0, it would
be the other way around: a boundary condition would be expected at x = 1 and no
condition at x = 0. We will go back to the transport equation in higher dimension
in Chap.10.
We can also consider periodic boundary conditions u(0, t) = u(1, t) for all t. In
thatcase,weconsideraperiodicinitialdatau0,whichweextendtoRby1-periodicity.
Let us take a > 0. We can use the previous formulas for the solution for t < 1
a .
We have u(x, t) = u0(x ‚àíat) in the lower right triangle of Fig.1.12, that is to say

22
1
Mathematical Modeling and PDEs
Fig. 1.12 The transport
equation in [0, 1] with a > 0
x = at
x
t
u0(x)
g(t)
0
1
x > at
x < at
for at < x ‚â§1, 0 < t ‚â§1
a . Therefore, u(1, t) = u0(1 ‚àíat) for 0 < t ‚â§1
a . The
periodic condition u(0, t) = u(1, t) then gives a Dirichlet boundary data at x = 0
for 0 < t ‚â§1
a , more precisely g(t) = u0(1 ‚àíat). We thus obtain an expression for
u(x, t) in the region 0 ‚â§x ‚â§at, t ‚â§1
a
u(x, t) = g

t ‚àíx
a

= u0(x + 1 ‚àíat) = u0(x ‚àíat),
since u0 has been extended by 1-periodicity. For t = 1
a , we thus have u(x, 1
a ) =
u0(x ‚àí1) = u0(x), and we can continue by periodicity in time on [ 1
a , 2
a ] and so on.
Note that considering the transport problem on R with the extended initial data u0
directly gives the periodic solution u(x, t) = u0(x ‚àíat) by restriction to [0, 1]. How-
ever, the above argument establishes the uniqueness of the solution of the problem
with periodic boundary condition.
The transport equation is relevant in many areas, whenever a spatially distributed
quantity u0 is transported by a velocity Ô¨Åeld, think of a concentration of pollutants
carried away by the wind. A diffusion term of second order is often added, yielding
what are called convection-diffusion problems.
1.5
The Vibrating String Equation
Let us return to the elastic string in the context of dynamics. The displacement u of
the string is now a function of space x and time t. The analysis of applied forces is
exactly the same as in the static case, except that Newton‚Äôs law of motion says that
the resultant of the applied forces is equal to the time derivative of the momentum for
each piece that can be cut out of the whole string. There is no point in going through
all the detail again‚Äîit is actually a good exercise‚Äîand the result is

1.5 The Vibrating String Equation
23
T
‚àÇu
‚àÇx (x + Œ¥x, t) ‚àí‚àÇu
‚àÇx (x, t)

+
 x+Œ¥x
x
f (s, t) ds =
 x+Œ¥x
x
œÅ ‚àÇ2u
‚àÇt2 (s, t) ds,
where T is still the constant tension, œÅ is the mass of the string per unit length, which
we assume to be a constant independent of x, i.e., that the string is homogeneous,
and ‚àÇ2u
‚àÇt2 (x, t) is the acceleration of the string at point x and time t. Note that the
applied force f can now depend on time as well. Dividing by Œ¥x and letting Œ¥x tend
to 0, we obtain
T ‚àÇ2u
‚àÇx2 (x, t) + f (x, t) = œÅ ‚àÇ2u
‚àÇt2 (x, t),
which is best rewritten as
‚àÇ2u
‚àÇt2 (x, t) ‚àíc2 ‚àÇ2u
‚àÇx2 (x, t) = 1
œÅ f (x, t),
(1.15)
with c =

T
œÅ . This partial differential equation, which is also called the one-
dimensional wave equation, is attributed to Jean le Rond d‚ÄôAlembert. The constant
c is the propagation speed. We will see later that this equation propagates waves to
the right at speed c and to the left at speed ‚àíc. This is easily seen experimentally on
a long rope held by two persons. In fact, the vibrating string differential operator is
a composition of two transport operators
‚àÇ2
‚àÇt2 ‚àíc2 ‚àÇ2
‚àÇx2 =
 ‚àÇ
‚àÇt ‚àíc ‚àÇ
‚àÇx
 ‚àÇ
‚àÇt + c ‚àÇ
‚àÇx

=
 ‚àÇ
‚àÇt + c ‚àÇ
‚àÇx
 ‚àÇ
‚àÇt ‚àíc ‚àÇ
‚àÇx

,
hence the two propagation directions. Note that the propagation speed increases with
the tension and decreases with the mass of the string.
Equation(1.15) must be complemented by initial conditions that prescribe the
initial shape and initial velocity of the string (this is a problem of second order in
time)
u(x, 0) = u0(x), ‚àÇu
‚àÇt (x, 0) = u1(x) for all x ‚àà]0, L[,
(1.16)
and by boundary conditions, meaning here that the string is Ô¨Åxed at both endpoints
u(0, t) = u(L, t) = 0, for all t ‚ààR+.
(1.17)
It should be noted that if a regular solution is expected, then a certain compatibility
between initial data (1.16) and boundary conditions (1.17) must be imposed
u0(0) = u0(L) = 0 and u1(0) = u1(L) = 0,
otherwise a discontinuity in the displacement or velocity will arise at t = 0.

24
1
Mathematical Modeling and PDEs
We will return in Chap.9 to a more in-depth study of the wave equation. For the
time being, let us consider a particular case: harmonic vibrations (see [71, 74] for
example). We are looking for solutions to Eq.(1.15) with right-hand side f = 0 and
by separation of variables, i.e., solutions of the special form u(x, t) = œÜ(x)œà(t),
non identically zero and satisfying the boundary condition (1.17). Obviously, in the
case of harmonic vibrations, we cannot impose an arbitrary initial condition.
Let us rewrite the problem in this setting:

œÜ(x)œà‚Ä≤‚Ä≤(t) ‚àíc2œÜ‚Ä≤‚Ä≤(x)œà(t) = 0 for all x ‚àà]0, L[, t ‚ààR+,
œÜ(0)œà(t) = œÜ(L)œà(t) = 0, for all t ‚ààR+.
Naturally, if œà = 0 then u = 0, which is not a very interesting solution. We thus
assume that there exists t0 such that œà(t0) Ã∏= 0. It is therefore legal to divide by
œà(t0), so that
‚éß
‚é®
‚é©
‚àíœÜ‚Ä≤‚Ä≤(x) + œà‚Ä≤‚Ä≤(t0)
c2œà(t0)œÜ(x) = 0 for all x ‚àà]0, L[,
œÜ(0) = œÜ(L) = 0.
This a boundary value problem in the variable x of a kind we have already encoun-
tered, and we know that if œà‚Ä≤‚Ä≤(t0)
c2œà(t0) ‚â•0, then œÜ = 0 is the unique solution. This again
means that u = 0, which is deÔ¨Ånitely not interesting. Let us thus consider the case
when Œª = ‚àíœà‚Ä≤‚Ä≤(t0)
c2œà(t0) > 0 and see under which conditions there could exist a nonzero
solution.
Forgetting the boundary conditions for an instant, we recognize a second order
linear differential equation with constant coefÔ¨Åcients, the general solution of which
is of the form
œÜ(x) = A sin
‚àö
Œªx

+ B cos
‚àö
Œªx

.
The boundary condition œÜ(0) = 0 implies that B = 0. The boundary condition
œÜ(L) = 0 then either imposes A = 0, but then we are back to œÜ = 0, hence a trivial
solution u = 0, or sin(
‚àö
ŒªL) = 0, that is to say
‚àö
ŒªL = kœÄ for some k ‚ààZ,
or again
Œª = k2œÄ2
L2
and œÜ(x) = A sin
kœÄ
L x

,
where k is an integer. This gives a nontrivial solution, at last.
Without loss of generality, we take A = 1 and plug u(x, t) = sin
 kœÄ
L x

œà(t) back
into the original wave equation, which gives an equation for œà

1.5 The Vibrating String Equation
25
œà‚Ä≤‚Ä≤(t) + c2 k2œÄ2
L2 œà(t) = 0,
that we solve immediately
œà(t) = Œ± sin
ckœÄ
L t

+ Œ≤ cos
ckœÄ
L t

,
where Œ± and Œ≤ are arbitrary constants. Finally, we have found
u(x, t) =

Œ± sin
ckœÄ
L t

+ Œ≤ cos
ckœÄ
L t

sin
kœÄ
L x

,
and it is easily checked that all these functions solve the wave equation with the
homogeneous Dirichlet condition. We thus have found all the separated variable
solutions.
These solutions are harmonic vibrations of frequency ŒΩk = ck
2L =

T
œÅ
k
2L indexed
by the integer k. The lowest possible frequency is obtained for k = 1. It is called
the fundamental and is the note that is heard from that string. The following integers
correspond to the harmonics of this note: k = 2 double frequency, one octave above
the fundamental, k = 3, k = 4 two octaves above the fundamental, etc., see Fig.1.13.
Naturally, the actual vibration of an ideal musical string is never a separated variable
solution, but a superposition of harmonics. This superposition gives the note its
timbre. From the point of view of mathematics, this is a question of Fourier series,
but we will not pursue this angle here, see Chap.9, Theorem9.2.
To close this section, we deduce from the formula for the frequency that a longer
string will ring a lower note, hence the relative lengths of the necks of a guitar and
Fig. 1.13 Three successive
harmonics: functions œÜ for
k = 1, 2, 3
0,25
0,5
0,75
-1
-0,5
0,5
1

26
1
Mathematical Modeling and PDEs
a bass and the different notes played on the same string on the frets, that a heavier
string also rings a lower note, hence the mass differences between the strings of a
guitar or piano, and that a higher tension yields a higher note, which is how such
instruments are tuned.
1.6
The Wave Equation
This is the higher dimensional analogue of the vibrating string equation. If we con-
sider a vibrating membrane in dimension two, we easily obtain the problem
‚éß
‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é©
‚àÇ2u
‚àÇt2 (x, t) ‚àíc2Œîu(x, t) = f (x, t) in Œ© √ó R+,
u(x, t) = 0 on ‚àÇŒ© √ó R+,
u(x, 0) = u0(x), ‚àÇu
‚àÇt (x, 0) = u1(x) in Œ©,
with c =

T
œÅ , T is the tension and œÅ the membrane mass per unit area. Note that
compatibility conditions between the boundary and initial conditions must again be
imposed if we expect a regular solution.
The harmonic vibration problem consists in looking for a solution of the form
u(x, t) = eiŒªtœÜ(x) (we no longer need to pretend that we do not know what œà(t)
must be. . .), hence the problem
‚éß
‚é®
‚é©
‚àíŒîœÜ(x) = Œª2
c2 œÜ(x) in Œ©,
œÜ(x) = 0 on ‚àÇŒ©,
(1.18)
with œÜ Ã∏= 0.
Problem (1.18) is an eigenvalue problem for the linear operator ‚àíŒî, that is to
say an inÔ¨Ånite dimensional spectral problem. This was already the case in dimension
one, but there was no need for the whole apparatus of self-adjoint compact operator
spectral theory since everything could be done by hand.
What we need to know for now is that the eigenvalues, i.e., the possible values
for Œº = Œª2
c2 for which problem (1.18) admits a nonzero solution, form an inÔ¨Ånite
increasing sequence 0 < Œº1 < Œº2 ‚â§Œº3 ‚â§¬∑ ¬∑ ¬∑ , with Œºk ‚Üí+‚àûwhen k ‚Üí+‚àû,
which depends on the shape of Œ©, see for example [5, 26, 28]. The situation is thus a
lot more complex than in dimension one, where the shape of Œ© is just characterized
by its length L and we have an explicit formula for the eigenvalues. In particular, the
vibration frequencies Œªk
2œÄ = c
‚àöŒºk
2œÄ are no longer proportional to successive integers. If
the Ô¨Årst eigenvalue still gives the fundamental tone, the following harmonics are not
in rational proportion to each other, and the timbre of the sound is entirely different.

1.6 The Wave Equation
27
This explains why a drum produces a sound that has nothing in common with the
sound produced by a guitar. It is all a question of dimensionality of the source of
vibrations.
A classical problem that was only solved fairly recently was formulated as ‚ÄúCan
you hear the shape of a drum?‚Äù The meaning of the question was to know whether
the knowledge of the spectrum, that is to say of the entire sequence (Œºk)k‚ààN‚àó, made
it possible to determine Œ© up to a rigid motion. The answer is negative. There are
open sets in R2 of different shapes with exactly the same spectrum. Drums of these
different shapes would thus nonetheless sound exactly the same (up to the modeling
errors).
In higher dimensions, the wave equation is used to model the propagation of sound
waves in the air, the propagation of light waves in the void (the wave equation in this
case is deduced from Maxwell‚Äôs equations, the system of PDEs of electromagnetism).
Thereareallsortsofdifferentkindsofwaves,suchasseismicwavesoroceanicwaves,
the propagation of which is governed by equations that are more complex than the
wave equation.
1.7
The Heat Equation
The heat equation is yet another evolution equation, of a totally different nature from
the previous ones. For example, time is reversible in the wave equation: changing
t to ‚àít does not change the equation. The heat equation describes the evolution of
temperature. It thus has a connection with thermodynamics and time can only Ô¨Çow
from the past to the future. From the point of view of mathematics, changing t into
‚àít modiÔ¨Åes the equation and leads to problems with no solution in general.
The heat equation is as follows:
‚éß
‚é™‚é™‚é®
‚é™‚é™‚é©
‚àÇu
‚àÇt (x, t) ‚àíŒîu(x, t) = f (x, t) in Œ© √ó R+,
u(x, t) = 0 on ‚àÇŒ© √ó R+,
u(x, 0) = u0(x) in Œ©.
Here Œ© ‚äÇRd is an open set that represents a material body (for d = 1, 2 and 3) and
u(x, t) is its temperature at point x and time t. We have set all physical constants to
the value 1, as is customary in mathematics, which can in any case be achieved by a
change of units. The equation is of Ô¨Årst order in time and second order in space with
a boundary condition (of Dirichlet type here) and an initial condition. When f = 0,
the effect of the heat equation is to diffuse the initial condition.
The heat equation was discovered by Joseph Fourier, based on arguments of
exchange of heat between small particles. Let us rephrase in modern terms some of

28
1
Mathematical Modeling and PDEs
Fourier‚Äôs quite remarkable modeling arguments, published in his famous 1822, 639
pages long memoir, Th√©orie analytique de la chaleur7 [38].
Fourier starts by observing that two particles of the same substance at the same
temperature have no mutual effect on each other. However, if one of the particles
is hotter than the other, then there is a transfer of heat, which is a form of energy,
from the warmer to the cooler particle. He then states that the quantity of heat that
is transferred depends on the duration of the exchange, on the distance between the
two particles, which is assumed to be very small, on both temperatures and on the
nature of the substance.
Fourier goes on to assert that the exchange of heat is furthermore proportional
to the temperature difference, based on very precise experiments at the time. He
concludes that the amount of heat exchanged between particle m at temperature
u and particle m‚Ä≤ at temperature u‚Ä≤ during the period of time Œ¥t (small enough so
that there is no appreciable change of temperature during that time) is of the form
(u ‚àíu‚Ä≤)œï(Œ¥x)Œ¥t, where Œ¥x is the distance between the particles and œï is a rapidly
decreasing function that tends to 0 when Œ¥x ‚Üí+‚àû, with the intended meaning that
heat exchange between particles is localized in space. This function depends on the
nature of the substance. He says nothing else about it.
Fourier next considers an inÔ¨Ånite homogeneous medium contained between two
parallel planes A and B so that A is kept at constant temperature a and B at constant
temperature b. Assume that A = {x = 0} and B = {x = e} where e > 0 is
the distance between the two planes.8 Fourier claims to show that the equilibrium
temperature proÔ¨Åle in the medium is given by u = a + b‚àía
e x (it is reasonable that the
temperature should only depend on x). What he actually explains is that this proÔ¨Åle
is consistent with equilibrium, in the sense that the heat Ô¨Çux9 through all planes
C = {x = c} is independent of c. Hence, considering a slab of material contained
between two arbitrary planes C and C‚Ä≤, there is a perfect balance of incoming heat
on one plane and outgoing heat on the other plane, so that the temperature must stay
stationary.
His argument is as follows. Assume that the former temperature proÔ¨Åle is present
in the material, and consider two very close particles m and m‚Ä≤ situated on both sides
of C, say at x = c + Œ∂ and x = c ‚àíŒ∂, and two other very close particles n and n‚Ä≤
situated on both sides of C‚Ä≤ at x = c‚Ä≤ + Œ∂ and x = c‚Ä≤ ‚àíŒ∂, such that the distance d
between m and m‚Ä≤ is equal to the distance between n and n‚Ä≤. The exchanges of heat
between m and m‚Ä≤, and between n and n‚Ä≤, are then both equal to 2 b‚àía
e Œ∂œï(d)Œ¥t, and
independent of c and c‚Ä≤. Fourier argues that since the total heat Ô¨Çux going through
C (and C‚Ä≤) results from all possible conÔ¨Ågurations of such pairs of particles, it is
likewise independent of c (and c‚Ä≤).
Using the same kind of reasoning with two slabs of different thicknesses e and e‚Ä≤,
left temperatures a and a‚Ä≤ and right temperatures b and b‚Ä≤, Fourier determines that
7In which, not only is the heat equation derived and solved in special cases, but Fourier series are
invented, the heat kernel appears, etc.
8e stands for √©paisseur in French, i.e. thickness.
9The heat Ô¨Çux is the quantity of heat going through a unit area in the plane during a unit of time.

1.7 The Heat Equation
29
the corresponding heat Ô¨Çuxes F and F‚Ä≤ are such that
F
F‚Ä≤ =
a‚àíb
e
a‚Ä≤‚àíb‚Ä≤
e‚Ä≤
.
Calling K the heat Ô¨Çux necessary to have a slab of unit thickness support a unit
temperature difference, he thus obtains the following law, which is now called the
Fourier law,
F = K a ‚àíb
e
= ‚àíK du
dx .
The constant K is characteristic of the material, it is called its heat conductivity.
Fourier shows that the Ô¨Çux law actually holds for general, time-dependent temper-
ature repartitions, replacing the derivative du
dx with what we would call today the
gradient ‚àáu.
For simplicity, let us stay in the one-dimensional case, i.e., an inÔ¨Ånite medium
between two parallel planes, and derive the evolution equation in the manner of
Fourier. The temperature is thus an unknown function u of x and t.
Let C be the speciÔ¨Åc heat of the material, that is to say, the amount of heat needed
to heat up a unit of mass of the material from temperature 0 to temperature 1. Consider
a parallelepiped bounded by the planes x = x0 and x = x0 +Œ¥x, the section of which
has unit area. The total heat balance coming from the outside during a small period
of time Œ¥t is thus the Ô¨Çux on the left minus the Ô¨Çux on the right multiplied by the
duration
Q =

F(x, t) ‚àíF(x + Œ¥x, t)

Œ¥t = K
‚àÇu
‚àÇx (x0 + Œ¥x, t) ‚àí‚àÇu
‚àÇx (x0, t)

Œ¥t.
This heat input, which can be positive or negative, results in a change of temperature
u(x0, t + Œ¥t) ‚àíu(x0, t) =
Q
œÅŒ¥xC ,
where œÅ is the mass density of the material. Indeed, œÅŒ¥x is the mass of the paral-
lelepiped under consideration. Therefore, we obtain
u(x0, t + Œ¥t) ‚àíu(x0, t)
Œ¥t
= K
œÅC
‚àÇu
‚àÇx (x0 + Œ¥x, t) ‚àí‚àÇu
‚àÇx (x0, t)
Œ¥x
.
Letting Œ¥x and Œ¥t go to 0, we thus obtain the heat equation
‚àÇu
‚àÇt (x, t) = K
œÅC
‚àÇ2u
‚àÇx2 (x, t).

30
1
Mathematical Modeling and PDEs
Of course, the presence of an external heat source is easily taken into account in
the above balance of Ô¨Çuxes argument and results in a nonzero right-hand side in the
heat equation. In the case of a stationary heat distribution, ‚àÇu
‚àÇt = 0, we recover the
Poisson equation.
Other arguments used by Fourier are actually very close to the Ô¨Ånite difference
method that we will see later on. It is quite remarkable, and Fourier points it out
himself, that it is not necessary to know the ultimate nature of heat, which remained
mysterious at the time but which we now know to be the kinetic energy corresponding
to the random vibrations of molecules, and how it propagates precisely, in order to
be able to derive an extremely accurate macroscopic evolution equation.
1.8
The Schr√∂dinger Equation
The Schr√∂dinger equation is another evolution equation of an again totally different
nature. This time, u is a wave function in the sense of quantum mechanics. It is
complex-valued. The domain is the whole of R3. The equation reads10
i ‚àÇu
‚àÇt (x, t) + Œîu(x, t) = 0 in R3 √ó R+.
The Schr√∂dinger equation is the basic equation of quantum mechanics that governs
the evolution of the wave function of one particle in the absence of any potential,
that is in the void. Physical constants are missing (set to 1), such as Planck‚Äôs constant
‚Ñèand the mass of the particle. We need to add an initial condition u(x, 0) = u0(x)
on R3.
Since the square of the modulus of the wave function is interpreted as a presence
probability density, we need to impose

R3 |u(x, t)|2 dx = 1.
Actually, if the initial condition satisÔ¨Åes this normalization condition, then the solu-
tion satisÔ¨Åes it automatically at all times.
Even though the Schr√∂dinger equation presents a formal similarity with the heat
equation‚ÄîÔ¨Årst order in time, second order in space‚Äîthe presence of the imaginary
factor i gives it radically different properties. In particular, the Schr√∂dinger equation
propagates waves, also not at all in the same way as the wave equation, whereas the
heat equation does not propagate waves (heat waves notwithstanding!).
10Here i2 = ‚àí1.

1.8 The Schr√∂dinger Equation
31
LetusnotethatintheSchr√∂dingerequationforasystemof N particles,thevariable
x must belong to R3N, which becomes rapidly difÔ¨Åcult for practical purposes when
N is large. . .11
As a general rule, physics is a nearly inexhaustible source of partial differential
equations problems. Let us cite the Dirac equation, a Ô¨Årst order system of equations
and relativistic version of the Schr√∂dinger equation; Einstein‚Äôs equations of gen-
eral relativity, a system of nonlinear PDEs; the Boltzmann equation for the kinetic
description of gases, all the equations of Ô¨Çuid mechanics, Euler, Stokes, Navier-
Stokes, and so on, and so forth. We refer for example to [21, 22, 24, 34] for other
physical models leading to the study of PDEs.
1.9
The Black and Scholes Equation
Physics is not by far the only source of PDEs. PDEs are also playing an increasing
role in diverse areas, such as biology, chemistry, material science, meteorology,
climatology, road trafÔ¨Åc modeling, crowd movement modeling, economy, Ô¨Ånance,
among many others. Let us give a famous example in the latter area, the Black and
Scholes equation.
The question is to set the price of a call option. A call option is a contract between
a seller and a buyer, drawn at time t = 0. The contract gives the buyer the right to
buy an asset belonging to the seller, not right away but later and at a price K, the
strike, that is agreed on in advance. The contract has a price paid by the buyer to
the seller at t = 0, otherwise the seller would have no real reason to agree to it. For
the buyer, it is an insurance against future price Ô¨Çuctuations since the strike is Ô¨Åxed.
The price C must be computed in such a way that the game should be fair on
average, or at least seem to be fair. . . The possibility of option pricing hinges on a
modeling of the market and on a hypothesis called no arbitrage opportunity (no free
lunch) meaning that it is impossible to make sure gains without taking risks.
To make things a little more precise, the price of the asset at instant t is denoted St.
It is a continuous time stochastic process. In the case of an american call, the buyer
acquires the right to exercise the option, that is to say to buy the asset for the price
K, at any moment t ‚àà[0, T ], where T is an expiration date agreed on in advance.
The buyer is under no obligation to do so, and after time T , the option disappears.
Of course, the buyer has no interest in exercising the option at time t if St < K. In
this case, it is better to buy at the market price or not buy at all. On the other hand, the
buyer could also have invested the amount C at a Ô¨Åxed interest rate r without risk.
Therefore, a proÔ¨Åt would only be made by exercising the option if St > ertC + K,
which is the decision criterion. The buyer bets this situation will occur before time
T , in which case he or she buys the asset for a price K and sells it back immediately
on the market at price St, thus pocketing the difference St ‚àíK. The global balance
11Think Avogadro‚Äôs number.

32
1
Mathematical Modeling and PDEs
of the operation is either ‚àíC if the option is not exercised or st ‚àíK ‚àíC if it is
exercised.
The seller always gains C and loses St ‚àíK if the buyer exercises the option, in
the sense that he or she could have sold at time t at the market price to somebody
else. Therefore, the bet is that the buyer will not exercise the option. The seller must
also seek to cover losses in case the buyer exercises the option. The price C is meant
to compensate for such potential losses.
The option price C is naturally a function of the asset price, which is represented
by a variable x ‚ààR+, because a price is nonnegative. It is also useful to introduce
the price at instant t, that is to say, the price the option would have if it was bought at
instant t with the same strike K and expiry date T . The option price is thus a function
in two variables C(x, t) (let us emphasize again that the space variable x is actually
a price).
We want to determine C(x, 0) as a function of x in order to deÔ¨Åne the terms of the
contract, since at t = 0, the price of the asset S0 is known and the price of the option
is then C(S0, 0). The price of the option at t = T is obviously C(x, T ) = (x ‚àíK)+
sincetheoptionisexercisedat T onlyifthepriceoftheassetislargerthan K,andthere
is no time left to invest C(x, T ) at a Ô¨Åxed interest rate (the notation C+ = max(C, 0)
denotes the positive part of C).
At this point, stochastic modeling is needed in order to describe the evolution of
asset prices and to ensure a viable game, which we do not describe in detail. Anyway,
hypotheses are made concerning the St process. As recent world events have made
quite clear, such hypotheses are not always satisÔ¨Åed in real life, but let us proceed
anyway. At the end of this stochastic modeling phase, we end up with a deterministic
PDE for the function C(x, t) of the form
‚àÇC
‚àÇt (x, t) + 1
2œÉ 2x2 ‚àÇ2C
‚àÇx2 (x, t) + Œºx ‚àÇC
‚àÇx (x, t) ‚àírC(x, t) = 0 in R+ √ó [0, T ],
with the Ô¨Ånal condition
C(x, T ) = (x ‚àíK)+.
This is the Black and Scholes equation. It has a Ô¨Ånal condition and not an initial
condition because of modeling reasons, as we have seen, in fact the initial value is
the unknown quantity of interest. Another reason is that the principal part of the
differential operator is basically similar to a backward heat equation. We have seen
that the heat equation is incapable of going back in time. Therefore, a backward heat
equation needs a Ô¨Ånal condition in order to be well-posed. There is an additional
difÔ¨Åculty since the coefÔ¨Åcients of the space derivatives are functions of the space
variables that vanish for x = 0. There is thus a degeneracy at the boundary, so
whether or not boundary conditions are in order it is not so clear. The constant œÉ is
called the asset volatility, a measure of the more or less erratic behavior of the asset
price, and Œº is the trend, a sort of average growth rate.

1.9 The Black and Scholes Equation
33
These oddities of the Black and Scholes equation are mostly corrected by a simple
change of variable. Let us set u(y, œÑ) = C(ey, T ‚àíœÑ), then
‚àÇu
‚àÇœÑ ‚àí1
2œÉ 2 ‚àÇ2u
‚àÇy2 ‚àí

Œº ‚àí1
2œÉ 2‚àÇu
‚àÇy + ru = 0 in R √ó [0, T ],
with the initial (since time has been reversed) condition
u(y, 0) = (ey ‚àíK)+.
We are comfortably back with an ordinary heat equation with the right time direction,
whose effect is to diffuse the price, corrected by a transport term whose effect is to
make the price drift (in backward time) at speed ‚àí(Œº ‚àí1
2œÉ 2). The ru term is an
updating term with respect to the interest rate which can be eliminated by a further
change of variables.
To conclude, let us remark that the Black and Scholes equation for one asset
is a two-dimensional equation, one space dimension and one time dimension. The
analogous equation for a portfolio of N assets is in N + 1 dimensions, which is a
source of difÔ¨Åculty for numerical approximation even for N moderately large.
1.10
A Rough ClassiÔ¨Åcation of PDEs
We give a rather informal classiÔ¨Åcation of PDEs which is neither very precise, nor
exhaustive, but which has the advantage of giving a general idea of their properties.
Let us start with the Laplace operator Œî =
‚àÇ2
‚àÇx2
1 + ‚àÇ2
‚àÇx2
2 , and replace
‚àÇ
‚àÇxi by multi-
plication by a variable Œæi (which is more or less what the Fourier transform does).
The equation Œîu = f is thus replaced by an equation of the type ‚à•Œæ‚à•2 = g which
is the equation of a circle in R2, a special case of an ellipse. We say that the Pois-
son equation is elliptic. More generally, if we repeat the same operation on the
principal part d
i, j=1 ai j
‚àÇ2
‚àÇxi x j of a general second order linear operator, we obtain
d
i, j=1 ai jŒæiŒæ j = g. If this yields the equation of an ellipsoid in Rd, then we say that
the equation is elliptic. This is the case if the matrix (ai j) is positive deÔ¨Ånite.
The same game played on the heat equation, replacing ‚àÇ/‚àÇt by Œæ0, yields Œæ0‚àíŒæ 2
1 =
g, which is the equation of a parabola, or a paraboloid in higher dimension. We say
that the heat equation is parabolic.
Finally, in the case of the wave equation, we obtain Œæ 2
0 ‚àíŒæ 2
1 = g, the equation of
a hyperbola. We say that the wave equation is hyperbolic.
In the two-dimensional case, d = 2, the above classiÔ¨Åcation reduces to the dis-
criminant criterion, which is as follows. First we can always assume that a12 = a21
and let D = a2
12 ‚àía11a22. Then the equation is elliptic if and only if D < 0, it is
parabolic if and only if D = 0 and it is hyperbolic if and only if D > 0.

34
1
Mathematical Modeling and PDEs
It is possible to give more precise deÔ¨Ånitions [24], but this is not useful here. The
important idea is that an elliptic equation (resp. a parabolic equation, resp. a hyper-
bolic equation) has more or less the same properties as the Poisson equation (resp.
the heat equation, resp. the wave equation). The transport equation is considered to
be hyperbolic.
1.11
What Comes Next
Up to now, we have presented a few examples of diverse mathematical models that
involvepartial differential equations. Wehavealsoobtainedexistenceanduniqueness
results for the simplest of these models, in Sect.1.1. The rest of the book is devoted
to the mathematical analysis and numerical approximation of the three main types
of partial differential equations, elliptic, parabolic and hyperbolic.
General elliptic problems exempliÔ¨Åed by the elastic membrane equation are
treated in Chap.4 for their mathematical analysis and Chaps.5 and 6 for their numer-
ical approximation. Parabolic equations are the subject of Chaps.7 and 8 for the theo-
retical and numerical aspects respectively. Finally, we consider hyperbolic equations
in Chaps.9 and 10 from both points of view.
In the next chapter, Chap.2, we take the simplest possible elliptic problem, i.e.,
the elastic string problem (1.2). Since the mathematical analysis of this problem has
already been performed, we skip directly to its numerical approximation. We use
this example to present the Ô¨Ånite difference method. This is the earliest and simplest
numerical approximation method and it only requires elementary mathematical tools.
This method has drawbacks for more general elliptic problems, as we will see. We
will however return to the Ô¨Ånite difference method later when dealing with evolution
equations of parabolic or hyperbolic type.

Chapter 2
The Finite Difference Method for Elliptic
Problems
Even though it can be shown that the boundary value problems introduced in Chap.1
admit solutions, they do not admit explicit solutions as a general rule, i.e., solutions
that can be written in closed form. Therefore, in order to obtain quantitative infor-
mation on the solutions, it is necessary to deÔ¨Åne approximation procedures that are
effectively computable. We present in this chapter the simplest of all approxima-
tion methods, the Ô¨Ånite difference method. We apply the method to the numerical
approximation of a model problem, the Dirichlet problem for the Laplacian in one
space dimension. We then give some indications for the extension of the method to
Neumann boundary conditions and to two-dimensional problems.
2.1
Approximating Derivatives by Differential Quotients
The Ô¨Ånite difference method is based on an elementary concept which is directly
connected to the deÔ¨Ånition of differentiation of functions. The idea is simply to
approximate any derivative by a differential quotient. As opposed to more sophisti-
cated methods, such as the Ô¨Ånite element method that we will present later on, we
can directly treat the boundary value problem instead of a more abstract formula-
tion thereof, the variational formulation, see Chap.4. This explains the popularity
of the Ô¨Ånite difference method, in spite of its shortcomings in particular in higher
dimensions.
Let us explain the method in one dimension. Using the deÔ¨Ånition of the derivative
of a function u at point x ‚ààR, we can write
u‚Ä≤(x) = lim
h‚Üí0
u(x + h) ‚àíu(x)
h
,
¬© Springer International Publishing Switzerland 2016
H. Le Dret and B. Lucquin, Partial Differential Equations:
Modeling, Analysis and Numerical Approximation, International Series
of Numerical Mathematics 168, DOI 10.1007/978-3-319-27067-8_2
35

36
2
The Finite Difference Method for Elliptic Problems
and deduce that, when h Ã∏= 0 is small, the differential quotient [u(x + h) ‚àíu(x)]/h
should be a good approximation of the Ô¨Årst order derivative u‚Ä≤(x), in the sense that
the error induced by this approximation goes to 0 when h goes to 0. If the function
is regular (in a neighborhood of x), we can make a precise estimate of this error by
using a Taylor‚ÄìLagrange expansion. Namely, if u is C2 in a neighborhood of x, we
have
u(x + h) = u(x) + hu‚Ä≤(x) + h2
2 u‚Ä≤‚Ä≤(Œæ),
(2.1)
where Œæ lies between x and x + h. Therefore, taking h0 > 0 and setting C =
supy‚àà[x‚àíh0,x+h0] |u‚Ä≤‚Ä≤(y)|/2, we see that

u(x + h) ‚àíu(x)
h
‚àíu‚Ä≤(x)
 ‚â§C|h|,
for all h Ã∏= 0 such that |h| ‚â§h0, In other words, the error made by replacing the
derivative u‚Ä≤(x) by the differential quotient u(x+h)‚àíu(x)
h
is of the order of h. We say
that we have a consistent approximation of order one of u‚Ä≤ at point x. More generally,
we say that we have a consistent approximation of order p (p > 0) of u‚Ä≤(x) if there
exists a constant C, which does not depend on h, such that this error is bounded by
Chp.
Other consistent approximations are possible. For example, the differential quo-
tient [u(x) ‚àíu(x ‚àíh)]/h is also a consistent approximation of order one of u‚Ä≤(x).
One way of improving the accuracy is to center the approximation, by using the
points x + h and x ‚àíh to form the differential quotient u(x+h)‚àíu(x‚àíh)
2h
. In fact, if u is
C3 in a neighborhood of x, we can write
u(x + h) = u(x) + hu‚Ä≤(x) + h2
2 u‚Ä≤‚Ä≤(x) + h3
6 u(3)(Œæ +),
u(x ‚àíh) = u(x) ‚àíhu‚Ä≤(x) + h2
2 u‚Ä≤‚Ä≤(x) ‚àíh3
6 u(3)(Œæ ‚àí),
where Œæ + and Œæ ‚àíare located between x ‚àíh and x + h. Subtracting the two formulas
above and using the intermediate value theorem, we obtain
u(x + h) ‚àíu(x ‚àíh)
2h
= u‚Ä≤(x) + h2
6 u(3)(Œæ),
for some Œæ between x ‚àíh and x + h. We deduce the following estimate of the error:
For all h, 0 < |h| ‚â§h0, we have

u(x + h) ‚àíu(x ‚àíh)
2h
‚àíu‚Ä≤(x)
 ‚â§Ch2,

2.1 Approximating Derivatives by Differential Quotients
37
where
C = 1
6
sup
y‚àà[x‚àíh0,x+h0]
|u(3)(y)|.
We have then deÔ¨Åned a consistent approximation of order two of u‚Ä≤(x). Note that the
above error estimate is a priori not valid if u is less regular than C3.
The model problem (1.2) of Chap.1 or problem (2.4) below involve second deriva-
tives so that we also need to approximate second derivatives by differential quotients.
Lemma 2.1 Let us suppose that u is C4 on the interval [x ‚àíh0, x + h0] (h0 > 0).
Then there exists a constant C such that, for all h, 0 < |h| ‚â§h0, we have

u(x + h) ‚àí2u(x) + u(x ‚àíh)
h2
‚àíu‚Ä≤‚Ä≤(x)
 ‚â§Ch2.
(2.2)
In other words, the differential quotient u(x+h)‚àí2u(x)+u(x‚àíh)
h2
is a consistent approxi-
mation of order two of the second derivative of u at point x.
Proof The proof is again based on Taylor‚ÄìLagrange expansions. We have
u(x + h) = u(x) + hu‚Ä≤(x) + h2
2 u‚Ä≤‚Ä≤(x) + h3
6 u(3)(x) + h4
24u(4)(Œæ +),
u(x ‚àíh) = u(x) ‚àíhu‚Ä≤(x) + h2
2 u‚Ä≤‚Ä≤(x) ‚àíh3
6 u(3)(x) + h4
24u(4)(Œæ ‚àí),
where Œæ + and Œæ ‚àíare between x ‚àíh and x + h. Adding the two formulas above and
using the intermediate value theorem, we thus obtain
u(x + h) ‚àí2u(x) + u(x ‚àíh)
h2
= u‚Ä≤‚Ä≤(x) + h2
12u(4)(Œæ),
(2.3)
for some Œæ between x ‚àíh and x + h. It follows that estimate (2.2) holds with
C =
sup
y‚àà[x‚àíh0,x+h0]
|u(4)(y)|
12
,
for 0 < |h| ‚â§h0, which completes the proof.
‚ñ°
Remark 2.1 Let us remark that this error estimate also depends on the regularity of
u. For example, if u is only C3, the Taylor expansion cannot be carried out up to
fourth order, and gives an error estimate of order h. Conversely, any regularity higher
than C4 will not improve the accuracy, which remains of order h2. There is thus no
reason to use a higher order Taylor‚ÄìLagrange expansion, see Remark 8.1 of Chap.8.
‚ñ°

38
2
The Finite Difference Method for Elliptic Problems
Remark 2.2 We remark that
u(x + h) ‚àí2u(x) + u(x ‚àíh)
h2
= 1
h
u(x + h) ‚àíu(x)
h
‚àíu(x) ‚àíu(x ‚àíh)
h

= D+
h D‚àí
h u(x) = D‚àí
h D+
h u(x),
where the operators D+
h and D‚àí
h are deÔ¨Åned by
D+
h u(x) = u(x + h) ‚àíu(x)
h
,
D‚àí
h u(x) = u(x) ‚àíu(x ‚àíh)
h
.
These are precisely the operators, respectively called forward difference operator
and backward difference operator, of order one that we have already met for the
approximation of Ô¨Årst order derivatives.
‚ñ°
2.2
Application to a One-Dimensional Model Problem
We consider the model problem consisting in Ô¨Ånding u: [0, 1] ‚ÜíR such that

‚àíu‚Ä≤‚Ä≤(x) + c(x)u(x) = f (x),
x ‚àà]0, 1[,
u(0) = g0,
u(1) = g1,
(2.4)
where c and f are two given continuous functions, deÔ¨Åned on [0, 1], and g0 and g1
are given constants. We know that this problem has a unique solution if c ‚â•0, by the
shooting method, see Theorem 1.2 of Chap.1. We will thus take c ‚â•0 in the sequel.
In the particular case c = 0, u has the following expression
u(x) =
 1
0
G(x, y) f (y)dy + g0 + x(g1 ‚àíg0),
(2.5)
where G is the Green function, given by
G(x, y) = x(1 ‚àíy) if y ‚â•x,
G(x, y) = y(1 ‚àíx) if y ‚â§x.
In the general case (i.e., c Ã∏= 0), formula (2.5) still holds with a Green function which
is not explicitly known. The idea is thus to deÔ¨Åne an approximation of u.
More precisely, we are going to look for an approximation of u at speciÔ¨Åc points xi
of the interval [0, 1] in Ô¨Ånite number. These points are called discretization points or
gridpoints. For simplicity, weassumeherethat thesepoints areuniformlydistributed,
see Fig.2.1, i.e., of the form xi = ih, i ‚àà{0, . . . , N + 1}, where N is a given positive

2.2 Application to a One-Dimensional Model Problem
39
h
0 = x0
x1
xi‚àí1
xi
¬∑¬∑¬∑
xi+1
xN+1 = 1
¬∑¬∑¬∑
Fig. 2.1 A uniform 1d grid and grid points
integer and h = 1/(N + 1) is the grid space step, or grid step in short. Even though
the notation does not make it clear, we see that xi not only depends on i, but also on h
or equivalently on N. Note that 0 ‚â§h ‚â§1 and that h goes to 0 when the number
N + 2 of grid points goes to inÔ¨Ånity.
We have at the ends of the interval x0 = 0 and xN+1 = 1. The other grid points
xi, for i ‚àà{1, . . . , N}, are called internal points.
We would like to compute an approximated value ui of the unknown exact value
u(xi) at each point xi, with i ‚àà{1, . . . , N}. We naturally set at the ends u0 = g0
and uN+1 = g1, i.e., we enforce the exact boundary condition at the discrete level.
For the internal points, the idea is to start from the Ô¨Årst equation in system (2.4) ex-
pressed at point xi, and approximate u‚Ä≤‚Ä≤(xi) based on the central differential quotient of
Lemma 2.1.
The unknowns of the discrete problem are thus only u1, . . . , uN. Just like xi, we
remark that ui also depends on h or N. Let us denote by Uh the vector in RN with
components ui, for i ‚àà{1, . . . , N}.
Recall that c ‚ààC0([0, 1]) and f ‚ààC0([0, 1]). We start from problem (2.4).
We replace each exact value u(xi) at each grid point by the corresponding approx-
imated value ui, and the second order derivative u‚Ä≤‚Ä≤(xi) at each internal point xi,
i ‚àà{1, . . . , N}, of the grid by the central difference quotient ui+1‚àí2ui+ui‚àí1
h2
. We thus
get the following discrete system expressed solely in terms of the approximated
discrete values ui:
‚éß
‚é®
‚é©
‚àíui+1 ‚àí2ui + ui‚àí1
h2
+ c(xi)ui = f (xi),
i ‚àà{1, . . . , N},
u0 = g0,
uN+1 = g1.
(2.6)
At this point, it must be emphasized that there is no indication that ui ‚âàu(xi),
in any sense whatsoever. We say that we have discretized the problem by a Ô¨Ånite
difference method, using the three point central Ô¨Ånite difference scheme or simply
three point scheme.
The discrete problem has the following equivalent vector formulation:
AhUh = Fh,
(2.7)

40
2
The Finite Difference Method for Elliptic Problems
where Ah is the N √ó N matrix deÔ¨Åned by
Ah = A0
h +
‚éõ
‚éú‚éú‚éú‚éú‚éù
c(x1)
0
¬∑ ¬∑ ¬∑
0
0
c(x2) ...
...
...
...
...
0
0
¬∑ ¬∑ ¬∑
0 c(xN)
‚éû
‚éü‚éü‚éü‚éü‚é†
,
(2.8)
with
A0
h = 1
h2
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù
2 ‚àí1 0 ¬∑ ¬∑ ¬∑ 0
‚àí1 2 ‚àí1 ...
...
0
... ... ...
0
...
... ‚àí1 2 ‚àí1
0 ¬∑ ¬∑ ¬∑ 0 ‚àí1 2
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†
,
(2.9)
and
Fh =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éù
f (x1) + g0
h2
f (x2)
...
f (xN‚àí1)
f (xN) + g1
h2
‚éû
‚éü‚éü‚éü‚éü‚éü‚é†
.
(2.10)
In order to compute the discrete solution Uh, we thus have to solve the linear
system (2.7). The Ô¨Årst point to check is whether or not this system has a solution for
any right-hand side, in other words, whether or not the matrix Ah is invertible. This
is a consequence of the following proposition.
Proposition 2.1 The matrix Ah is symmetric. Furthermore, when c ‚â•0, it is positive
deÔ¨Ånite.
Proof The matrix Ah is clearly symmetric. Let us show it is positive deÔ¨Ånite when
c ‚â•0. Let V be a vector in RN with components vi, i ‚àà{1, . . . , N}. Let us compute
V TAhV . First, thanks to the assumption c ‚â•0, we get
V TAhV = V TA0
hV +
N

i=1
c(xi)v2
i ‚â•V TA0
hV.
It is thus sufÔ¨Åcient to show that A0
h is positive deÔ¨Ånite. A simple computation gives
h2 V TA0
hV = v2
1 + (v2 ‚àív1)2 + (v3 ‚àív2)2 + ¬∑ ¬∑ ¬∑ + (vN‚àí1 ‚àívN)2 + v2
N,
from which we deduce that V TA0
hV ‚â•0. Moreover, if V TA0
hV = 0, then each term in
the sum above has to be zero, which implies that 0=v1 =v2 ‚àív1 =¬∑ ¬∑ ¬∑=vN‚àí1 ‚àívN =
vN. Thus v1 = v2 = ¬∑ ¬∑ ¬∑ = vN = 0, i.e. V = 0, which completes the proof.
‚ñ°

2.2 Application to a One-Dimensional Model Problem
41
It is well-known that positive deÔ¨Ånite matrices are invertible, since AhV = 0
implies that V TAhV = 0, thus
Corollary 2.1 The discrete system (2.7) has one and only one solution Uh for any
N and Fh.
It follows that the Ô¨Ånite difference scheme (2.6) is well deÔ¨Åned. Note that the
matrix of the linear system (2.7) is sparse, i.e., it has many zero elements. More
precisely, Ah is a tridiagonal matrix in the sense that the only nonzero elements are
either on the diagonal or on the super- or sub-diagonal.
The next question concerns in which sense the discrete system solution Uh is
actually an approximation of the exact solution u of the boundary value problem (2.4).
The two quantities are of different nature since Uh is a vector in RN and u is a function
deÔ¨Åned on [0, 1]. The only reasonable way of comparing the two is to compare the
ith component ui of Uh with the value u(xi) of u at the corresponding grid point,
since this is what the Ô¨Ånite difference scheme is intended for. In particular we would
like to know if ui ‚àíu(xi) ‚Üí0 when the grid step h goes to zero and at which rate,
in a sense that is made precise in the next section.
2.3
Convergence of the Finite Difference Method
We study the convergence of the method in the case of the model problem (2.4). The
analysis below applies to more general situations.
In order to compare the discrete solution Uh ‚ààRN with the exact solution u,
we introduce the grid sampling operator and what is meant by convergence in this
context.
DeÔ¨Ånition 2.1 The grid sampling operator Sh : C0([0, 1]) ‚ÜíRN is deÔ¨Åned by
Sh(v) =
‚éõ
‚éú‚éú‚éú‚éù
v(x1)
v(x2)
...
v(xN)
‚éû
‚éü‚éü‚éü‚é†.
We say that the method (2.7) is convergent if
‚à•Uh ‚àíSh(u)‚à•‚àû‚Üí0 when h ‚Üí0.
Moreover, we say that the scheme is convergent of order p if there exists p > 0 and
a constant C which do not depend on h such that, for all h > 0 we have
‚à•Uh ‚àíSh(u)‚à•‚àû‚â§Chp.

42
2
The Finite Difference Method for Elliptic Problems
Remark 2.3 The norm ‚à•X‚à•‚àû= maxi‚àà{1,...,N} |Xi| is deÔ¨Åned on RN, and thus de-
pends on N. This speciÔ¨Åc choice is made for simplicity. We will see more gen-
eral choices of norms in Chap.8 in the study of the numerical approximation of
the heat equation. With the present choice of norm, convergence thus means that
maxi‚àà{1,...,N} |ui ‚àíu(xi)| ‚Üí0 when N ‚Üí+‚àû, which is quite natural. Remember
that h ‚Üí0 is equivalent to N ‚Üí+‚àûand that ui and xi also depend on N and h. ‚ñ°
In order to evaluate the error Uh ‚àíSh(u) of the method, we next introduce the
truncation error of the scheme (2.6) or equivalently (2.7).
DeÔ¨Ånition 2.2 The truncation error of the scheme AhUh = Fh is the vector in RN
denoted by Œµh(u) and deÔ¨Åned by
Œµh(u) = Ah(Sh(u)) ‚àíFh.
We say that the scheme is consistent if
lim
h‚Üí0 ‚à•Œµh(u)‚à•‚àû= 0.
Moreover, we say that the scheme is consistent of order p if there exists p > 0 and a
constant C which do not depend on h such that, for all h > 0 we have the following
error estimate
‚à•Œµh(u)‚à•‚àû‚â§Chp.
Remark 2.4 The truncation error is not to be confused with the error of the method
itself. The evaluation of the truncation error is however an important intermediate
step in the evaluation of the error estimate.
‚ñ°
Let us thus evaluate the truncation error of the scheme. We assume that u is C4
on [0, 1], which means that f is C2. Using formula (2.3), we obtain
Œµh(u) = ‚àíh2
12
‚éõ
‚éú‚éú‚éú‚éù
u(4)(Œæ1)
u(4)(Œæ2)
...
u(4)(ŒæN)
‚éû
‚éü‚éü‚éü‚é†,
where each point Œæi is such that Œæi ‚àà]xi‚àí1, xi+1[. We deduce that
‚à•Œµh(u)‚à•‚àû‚â§h2
12 max
y‚àà[0,1] |u(4)(y)|.
(2.11)
We have thus shown the
Proposition 2.2 Let us suppose that the solution u of problem (2.4) is C4 on [0, 1].
Then the scheme (2.6) is consistent of order two.

2.3 Convergence of the Finite Difference Method
43
Remark 2.5 We remark that, if the exact solution u is such that its derivative of order
4 is zero, then the truncation error Œµh(u) is zero, so that Ah(Uh ‚àíSh(u)) = 0. Since
the matrix Ah is invertible, it follows that Uh = Sh(u), which means that for any
i ‚àà{0, . . . , N + 1}, we have ui = u(xi). The discrete solution is thus equal to the
exact solution at each grid point (internal or not)! This is very speciÔ¨Åc to the case
when the exact solution u happens to be a polynomial function of degree at most 3,
see the proof of Proposition 2.5 where this property is used. Of course, in general
ui Ã∏= u(xi).
‚ñ°
Let us now compute the error of the method. By deÔ¨Ånition of the scheme on the
one hand, and of the truncation error on the other hand, we have
AhUh = Fh
and
AhSh(u) = Fh + Œµh(u).
Subtracting one from the other, we deduce that
Ah(Uh ‚àíSh(u)) = ‚àíŒµh(u).
Since Ah is invertible, this implies that the error is given by
Uh ‚àíSh(u) = ‚àí(Ah)‚àí1Œµh(u).
(2.12)
We thus have a decomposition of the error into two independent terms, the truncation
error Œµh(u) and the matrix term (Ah)‚àí1. We now proceed to show the following
convergence result:
Theorem 2.1 Let us suppose that c ‚â•0. If the solution u of problem (2.4) is C4 on
[0, 1], then the scheme (2.6) is convergent of order two. More precisely, we have
||Uh ‚àíSh(u)||‚àû‚â§h2
96 max
x‚àà[0,1] |u(4)(x)|.
(2.13)
In order to show this result, we need to brieÔ¨Çy introduce a few concepts, and in
particular the deÔ¨Ånition of matrix norms. In this chapter all matrices are real. We
refer for example to [6, 18, 53] for details.
Let ‚à•¬∑ ‚à•be a given norm on RN. For any N √ó N matrix A, we denote by |||A||| the
associated induced matrix norm or operator norm deÔ¨Åned by
|||A||| =
sup
X‚ààRN,XÃ∏=0
‚à•AX‚à•
‚à•X‚à•=
sup
X‚ààRN,‚à•X‚à•=1
‚à•AX‚à•=
sup
X‚ààRN,‚à•X‚à•‚â§1
‚à•AX‚à•.
The mapping ||| ¬∑ ||| satisÔ¨Åes the usual properties of norms, i.e.,
1. |||A||| ‚â•0 and |||A||| = 0 if and only if A = 0,
2. for all real Œª, |||ŒªA||| = |Œª| |||A|||,
3. the triangle inequality |||A + B||| ‚â§|||A||| + |||B|||, for all matrices A and B.

44
2
The Finite Difference Method for Elliptic Problems
It also satisÔ¨Åes the following additional property: For all matrices A and B, we have
|||AB||| ‚â§|||A||| |||B|||.
We say that a matrix norm is submultiplicative. Finally, by deÔ¨Ånition, we have for
all N √ó N matrices A and for all vectors X in RN,
‚à•AX‚à•‚â§|||A||| ‚à•X‚à•.
(2.14)
We note that |||I||| = 1 for any induced matrix norm. In this chapter, we only use the
‚à•¬∑ ‚à•‚àûnorm on RN. The induced matrix norm is given below.
Proposition 2.3 Let A be a N √ó N matrix with entries Ai j. We have
|||A|||‚àû=
max
i‚àà{1,...,N}
N

j=1
|Ai j|.
(2.15)
Proof Let us set M = maxi‚àà{1,...,N}
N
j=1 |Ai j|. Let X be an arbitrary vector in RN
with ‚à•X‚à•‚àû= 1. By deÔ¨Ånition of ‚à•¬∑ ‚à•‚àû, we have
‚à•AX‚à•‚àû=
max
i‚àà{1,...,N} |
N

j=1
Ai jX j| ‚â§
max
i‚àà{1,...,N}
N

j=1
|Ai j| |X j| ‚â§M,
because for any j ‚àà{1, . . . N}, |X j| ‚â§‚à•X‚à•‚àû= 1. We deduce that |||A|||‚àû‚â§M.
In order to show (2.15), it is thus sufÔ¨Åcient to Ô¨Ånd a vector X ‚ààRN, with
‚à•X‚à•‚àû= 1, such that ‚à•AX‚à•‚àû= M. By deÔ¨Ånition of M, there exists an index
i0 ‚àà{1, . . . , N} such that M = N
j=1 |Ai0 j|. Let us consider the vector X ‚ààRN
deÔ¨Åned by: X j = 1, if Ai0 j ‚â•0 and X j = ‚àí1 otherwise. We clearly have ‚à•X‚à•‚àû= 1
and (AX)i0 = N
j=1 Ai0 jX j = N
j=1 |Ai0 j| = M ‚â•0. This shows that |||A|||‚àû‚â•M,
which completes the proof.
‚ñ°
Let us now introduce another useful concept, inverse nonnegative matrices.
DeÔ¨Ånition 2.3 We say that a vector X ‚ààRN is nonnegative, and we write X ‚â•0, if
all its components Xi are nonnegative, and that a N √óN matrix A is nonnegative, and
we write A ‚â•0, if all its entries Ai j are nonnegative. A matrix A is said to be inverse
nonnegative or monotone if it is invertible and its inverse matrix is nonnegative.
We also note X ‚â§0 or A ‚â§0 whenever ‚àíX ‚â•0 or ‚àíA ‚â•0. We have the
following characterization of inverse nonnegative matrices:
Lemma 2.2 A matrix A is inverse nonnegative if and only if for all vectors X in RN,
we have
if AX ‚â•0 then X ‚â•0.
(2.16)

2.3 Convergence of the Finite Difference Method
45
Proof Let us suppose that A is inverse nonnegative. Let X be a vector in RN such
that AX ‚â•0. The matrix A‚àí1 is nonnegative, therefore the vector X = A‚àí1(AX) is
nonnegative by the usual formula for matrix-vector products.
Conversely, let A satisfy (2.16). We Ô¨Årst show that A is invertible. Let X be a
vector in RN such that AX = 0. In particular AX ‚â•0, so that, thanks to (2.16), we
have X ‚â•0. Likewise A(‚àíX) ‚â•0, so that ‚àíX ‚â•0. It follows that X = 0, which
shows that A is invertible. Let us next show that the matrix A‚àí1 is nonnegative. It
is sufÔ¨Åcient to show that each column of A is nonnegative. Let Ci be one of these
columns. By deÔ¨Ånition, Ci = A‚àí1Ei, where Ei is the ith vector of the canonical basis
of RN (i.e., all its components are zero, except the component of index i which is 1).
Since Ei ‚â•0 and ACi = Ei, we deduce from (2.16) that Ci ‚â•0, which completes
the proof.
‚ñ°
We now apply the above deÔ¨Ånitions and properties to the discrete problem (2.7).
Proposition 2.4 Let us suppose that c ‚â•0. The matrix Ah deÔ¨Åned by (2.8)‚Äì(2.9) is
inverse nonnegative.
Proof We use the above characterization of inverse nonnegative matrices. Let X be
a vector in RN such that AhX ‚â•0. Let us show that X ‚â•0. Let i0 be the smallest
index such that Xi0 ‚â§Xi, for all i ‚àà{1, . . . , N}. We will show that Xi0 ‚â•0, which
implies the result.
Let us Ô¨Årst consider the case when i0 = 1. The Ô¨Årst component of AhX is nonneg-
ative, therefore
[2 + h2c(x1)]X1 ‚àíX2 = (X1 ‚àíX2) + [1 + h2c(x1)]X1 ‚â•0.
As X1 ‚àíX2 ‚â§0 and 1+h2c(x1) ‚â•1 we deduce that X1 ‚â•0. The same proof applies
in the case i0 = N.
Let us now consider the case when i0 ‚àà{2, . . . , N ‚àí1}. Since (AhX)i0 ‚â•0, we
obtain
‚àíXi0‚àí1 +[2+h2c(xi0)]Xi0 ‚àíXi0+1 = (Xi0 ‚àíXi0‚àí1)+(Xi0 ‚àíXi0+1)+h2c(xi0)Xi0 ‚â•0,
(2.17)
with Xi0 ‚àíXi0‚àí1 ‚â§0 and Xi0 ‚àíXi0+1 ‚â§0 by deÔ¨Ånition of i0. If c(xi0) = 0, we get
Xi0 ‚àíXi0‚àí1 = Xi0 ‚àíXi0+1 = 0. In other words, i0 ‚àí1 is also an index where the
components of X achieve their minimum, which is a contradiction since i0 ‚àí1 < i0.
On the other hand, if c(xi0) > 0, then by (2.17), we see that Xi0 ‚â•0.
‚ñ°
Remark 2.6 The above proof shows that if we have AhUh = Fh with Fh ‚â•0, then
Uh ‚â•0. This is the discrete maximum principle, which is the discrete analogue of
the maximum principle of Theorem 1.3 of Chap.1.
‚ñ°
Remark 2.7 We note that the matrix Ah in addition to being inverse nonnegative
or monotone, is also such that its off-diagonal coefÔ¨Åcients are nonpositive. Such
matrices are called M-matrices. These matrices have applications in many Ô¨Åelds in

46
2
The Finite Difference Method for Elliptic Problems
addition to the discretization of differential operators, notably in probability theory
and economics among others, see [54, 79].
‚ñ°
We now are in a position to prove Theorem 2.1. Starting from (2.12) and using
formula (2.14), we deduce the following estimate:
‚à•Uh ‚àíSh(u)‚à•‚àû‚â§|||(Ah)‚àí1|||‚àû‚à•Œµh(u)‚à•‚àû.
We have already estimated the second term ‚à•Œµh(u)‚à•‚àû, see (2.11). We thus need an
estimate of the quantity |||(Ah)‚àí1|||‚àû, which is called a stability estimate.
Proposition 2.5 Let us suppose that c ‚â•0. We have the following estimate, for all
h =
1
N+1,
|||(Ah)‚àí1|||‚àû‚â§1
8.
(2.18)
Proof We Ô¨Årst remark that A‚àí1
h
‚àí(A0
h)‚àí1 = A‚àí1
h [A0
h ‚àíAh](A0
h)‚àí1. Since c ‚â•0, the
matrix A0
h ‚àíAh is diagonal with nonpositive entries. By Proposition 2.4, A‚àí1
h
‚â•0
and (A0
h)‚àí1 ‚â•0. Therefore A‚àí1
h
‚àí(A0
h)‚àí1 ‚â§0 by the usual formula for matrix
products. Since both A‚àí1
h
and (A0
h)‚àí1 are nonnegative, formula (2.15) then implies
that |||A‚àí1
h |||‚àû‚â§|||(A0
h)‚àí1|||‚àû. In order to get estimate (2.18), it is thus sufÔ¨Åcient to
show that
|||(A0
h)‚àí1|||‚àû‚â§1
8.
The matrix (A0
h)‚àí1 is nonnegative, therefore by formula (2.15)
|||(A0
h)‚àí1|||‚àû= ‚à•(A0
h)‚àí1E‚à•‚àû,
where E is the vector in RN all the components of which are equal to 1. We notice
that (A0
h)‚àí1E is precisely the discrete solution Uh of system (2.7) in the particular
case c = 0 and for Fh = E. In other words, it is the discrete solution associated with
the following boundary value problem:

‚àí¬Øu‚Ä≤‚Ä≤(x) = 1,
x ‚àà]0, 1[,
¬Øu(0) = 0,
¬Øu(1) = 0.
This problem clearly has the explicit solution ¬Øu(x) = x(1 ‚àíx)/2, a second degree
polynomial. Thanks to Remark 2.5, p. 43, we know that, in this particular case, the
discrete solution coincides with the exact solution at each grid point. We thus have
((A0
h)‚àí1E)i = ¬Øu(xi) = xi(1 ‚àíxi)/2. Consequently,
‚à•(A0
h)‚àí1E‚à•‚àû‚â§sup
x‚àà[0,1]
|¬Øu(x)| = ¬Øu
1
2

= 1
8,
which completes the proof.
‚ñ°

2.3 Convergence of the Finite Difference Method
47
Fig. 2.2 Plot of ¬Øu(x) = x(1‚àíx)
2
in solid line and Uh = (A0
h)‚àí1E for N = 10 with ‚ó¶marks
Remark 2.8 Note that the convergence proof relies on two fundamental properties:
consistency and stability. We will encounter a very similar idea in the study of
numerical approximations of the heat and wave equations in Chaps.8 and 9.
‚ñ°
We plot in Fig.2.2 the function u and the discrete solution Uh = (A0
h)‚àí1E in the
particular case used above in the stability estimate when the discrete solution happens
to coincide with the exact solution at the grid points.
Let us illustrate the preceding results with a numerical example. We take c(x) =
1000 sin(10œÄx)2 and f (x) = 1, and we compute the Ô¨Ånite difference approximations
of the corresponding boundary value problem for N = 19, 29, 49, 99, and 199, i.e.,
h = 0.05, 0.033, 0.02, 0.01, and 0.005, by solving the associated linear systems.
To compare the results, we plot in Fig.2.3 the computed discrete values ui against
xi for these Ô¨Åve cases on the same plot, with different marks for each value of N
and linear interpolations1 in between points. The solid curve with no marks is a
so-called ‚Äúreference‚Äù solution that is meant to represent the exact solution, but that
we actually also computed using Ô¨Ånite differences with N = 8000, since no explicit
formula seems to be available. The computation is performed with Scilab, a free,
general purpose scientiÔ¨Åc computing package (http://www.scilab.org/).
1This is for visualization purposes only. The Ô¨Ånite difference method does not compute a function
on [0, 1].

48
2
The Finite Difference Method for Elliptic Problems
0.0000
0.0005
0.0010
0.0015
0.0020
0.0025
0.0030
0.0035
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
Fig. 2.3 Convergence of the Ô¨Ånite difference method
2.4
Neumann Boundary Conditions
Let us brieÔ¨Çy describe the method in the case of Neumann boundary conditions at
both ends of the interval. The Neumann boundary conditions are different from the
Dirichlet conditions seen up to now. For a one-dimensional second order problem,
they concern the values of the Ô¨Årst derivative of the unknown function at the ends of
the interval, instead of the values of the function itself. In terms of modeling, in the
heat equation interpretation, they consist in imposing the heat Ô¨Çux at the boundary
instead of imposing the temperature.
We thus consider the problem: Find u: [0, 1] ‚ÜíR solution of

‚àíu‚Ä≤‚Ä≤(x) + c(x)u(x) = f (x),
x ‚àà]0, 1[,
u‚Ä≤(0) = g0,
u‚Ä≤(1) = g1,
(2.19)
where c and f are two given functions (c ‚ààC0([0, 1]) and f ‚ààC0([0, 1])), and g0
and g1 are two given constants. It is easy to prove by the shooting method that such a
function u exists if we suppose, for example, that there exists a constant c0 > 0 such
that c ‚â•c0 (see also the variational theory in Chap.4). More generally, if c ‚â•0 is not
identically 0, we have existence and uniqueness. On the other hand, if c = 0 there
is no uniqueness, hence no existence in general. Indeed, if a solution exists, then
we can add any arbitrary constant and still Ô¨Ånd another solution of problem (2.19).
This is one important difference with the Dirichlet problem (2.4) studied before. For
simplicity, we will assume a bound from below c ‚â•c0 > 0 from now on.
We now proceed to deÔ¨Åne a Ô¨Ånite difference approximation of this problem.
We use the same uniform grid in [0, 1] as before, i.e., with grid points xi = ih,
i ‚àà{0, . . . , N + 1}, where h =
1
N+1 and N is a given positive integer. There will be

2.4 Neumann Boundary Conditions
49
a discrete unknown ui attached to each grid point, including for i = 0 and i = N +1,
since the values of u at the ends of the interval are not prescribed by the continuous
problem as in the case of the Dirichlet problem.
For the internal grid points, i.e. points xi, with i ‚àà{1, . . . , N}, we will use the
same three point scheme as before to approximate the second order derivative at
this point. The problem is now to approximate the Neumann boundary condition,
since it cannot be satisÔ¨Åed exactly‚Äîcontrarily to the Dirichlet case. The condition
does not even make sense at the discrete level. There are several possibilities. The
simplest one consists in approximating the Ô¨Årst order derivative by one of the two
decentered difference schemes introduced in Remark 2.2. More precisely, we can
use the forward difference to approximate u‚Ä≤(0) and the backward difference to
approximate u‚Ä≤(1), i.e.,
u‚Ä≤(0) ‚âàD+
h u(0) = u(h) ‚àíu(0)
h
,
u‚Ä≤(1) ‚âàD‚àí
h u(1) = u(1) ‚àíu(1 ‚àíh)
h
.
This suggests the following approximation of the boundary conditions:
u0 ‚àíu1
h
= ‚àíg0,
uN+1 ‚àíuN
h
= g1.
The reason for the minus sign in the Ô¨Årst relation is that the Neumann boundary
condition at x = 0 is more naturally written as ‚àíu‚Ä≤(0) = ‚àíg0, in terms of integration
by parts and other considerations that we will see later. The discrete problem is thus
equivalent to the linear system
BhUh = Fh,
(2.20)
with
Bh = 1
h2
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù
h
‚àíh
0
...
...
0
‚àí1
2 + h2c(x1)
‚àí1
...
...
0
‚àí1
2 + h2c(x2) ‚àí1
...
...
0
...
...
...
...
0
...
...
‚àí1
2 + h2c(xN) ‚àí1
0
...
...
0
‚àíh
h
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†
,
where the unknown Uh is the vector in RN+2 of components ui, i ‚àà{0, . . . , N + 1}.
Note that Bh is an (N +2)√ó(N +2) matrix. The right-hand side of the linear system
is given by

50
2
The Finite Difference Method for Elliptic Problems
Fh =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éù
‚àíg0
f (x1)
...
f (xN)
g1
‚éû
‚éü‚éü‚éü‚éü‚éü‚é†
.
We Ô¨Årst remark that the matrix Bh is no longer symmetric due to the Ô¨Årst and last
lines. Before studying the convergence of the numerical method, let us make a few
comments on the case c = 0. In this case, it is easily seen that the kernel of Bh is the
one-dimensional space spanned by the vector (1, 1, . . . , 1)T, so that the matrix of the
linear system (2.20) is not invertible. Therefore the numerical method does not work
when c = 0, which is perfectly consistent with what happens at the continuous level.
We will see in Proposition 2.7 that when there exists a positive constant c0 such that
c ‚â•c0, the matrix Bh is invertible, hence the scheme is well deÔ¨Åned.
Let us now study the convergence of the method when c ‚â•c0 > 0, i.e., its
consistency (Proposition 2.6 below) and its stability (Proposition 2.7).
Proposition 2.6 Let us suppose that the solution u of problem (2.19) is C4 on [0, 1].
Then the scheme (2.20) is consistent of order one.
Proof Let Œµh(u) = BhSh(u) ‚àíFh be the truncation error, where Sh denotes here the
sampling operator on all the grid points, and is thus RN+2-valued. Using the Ô¨Årst
equation in (2.19) and (2.3), we get for any i ‚àà{1, . . . , N},
(Œµh(u))i = ‚àíu(xi+1) + 2u(xi) ‚àíu(xi‚àí1)
h2
+ c(xi)u(xi) ‚àíf (xi) = ‚àíh2
12u(4)(Œæi),
for some Œæi between xi‚àí1 and xi+1. For i = 0, using the left boundary condition in
(2.19) and (2.1), we obtain
(Œµh(u))0 = u(x0) ‚àíu(x1)
h
+ g0 = u(0) ‚àíu(h)
h
+ u‚Ä≤(0) = ‚àíh
2u‚Ä≤‚Ä≤(Œæ0),
for some Œæ0 between 0 and h. Similarly
(Œµh(u))N+1 = ‚àíu(xN) + u(xN+1)
h
‚àíg1 = u(1) ‚àíu(1 ‚àíh)
h
‚àíu‚Ä≤(1) = ‚àíh
2u‚Ä≤‚Ä≤(ŒæN+1),
for some ŒæN+1 between 1 ‚àíh and 1. Let us set
M = max
 1
12 max
y‚àà[0,1] |u(4)(y)|, 1
2 max
y‚àà[0,1] |u‚Ä≤‚Ä≤(y)|

.
Since h ‚â§1, we have h2 ‚â§h and therefore, for any i ‚àà{0, . . . , N + 1}, we see that
|(Œµh(u))i| ‚â§Mh. In other words,

2.4 Neumann Boundary Conditions
51
‚à•Œµh(u)‚à•‚àû‚â§Mh,
(2.21)
which shows that the scheme (2.20) is consistent of order one.
‚ñ°
Remark 2.9 Note that the terms coming from the approximation of the boundary
conditions are dominant with respect to the second derivative approximation in the
truncation error.
‚ñ°
We can show the following stability result.
Proposition 2.7 Let us suppose that there exists a constant c0 > 0 such that c ‚â•c0.
Then, the matrix Bh is inverse nonnegative, thus invertible and we have the following
estimate:
|||(Bh)‚àí1|||‚àû‚â§C,
(2.22)
where C is a constant which does not depend on h.
Proof We decompose the matrix as follows
Bh = B0
h +
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù
0
...
...
...
...
0
0 c(x1) ‚àíc0
0
...
...
0
...
...
c(x2) ‚àíc0
...
...
...
...
...
...
...
0
...
...
0 c(xN) ‚àíc0 0
0
...
...
...
...
0
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†
,
where
B0
h = 1
h2
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù
h
‚àíh
0
...
...
0
‚àí1 2 + c0h2 ‚àí1 ...
...
0
...
... ...
...
...
...
...
... ...
...
0
...
... ‚àí1 2 + c0h2 ‚àí1
0
...
...
0
‚àíh
h
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†
.
We Ô¨Årst show that Bh is inverse nonnegative using the characterization of inverse
nonnegative matrices given in Lemma 2.2. Let X be a vector in RN+2 such that
BhX ‚â•0. We have to show that X ‚â•0 and this is equivalent to showing that Xi0 ‚â•0,
where i0 is the smallest index such that Xi0 ‚â§Xi, for all i ‚àà{0, . . . , N + 1}. Let us
Ô¨Årst consider the case i0 = 0. As (BhX)0 ‚â•0, we have X0 ‚â•X1. On the other hand,
by deÔ¨Ånition of i0, we also have X0 ‚â§X1, so that X0 = X1. Now, as (BhX)1 ‚â•0, it
follows that
‚àíX0 + (2 + c(x1)h2)X1 ‚àíX2 = (X0 ‚àíX2) + c(x1)h2X0 ‚â•0.

52
2
The Finite Difference Method for Elliptic Problems
Now X0 ‚àíX2 ‚â§0 and c(x1) ‚â•c0 > 0, therefore X0 ‚â•0, which is the expected
result.
Let us now consider the case i0 ‚àà{1, . . . , N}. The condition (BhX)i0 ‚â•0 reads
‚àíXi0‚àí1 +(2+c(xi0)h2)Xi0 ‚àíXi0+1 = (Xi0 ‚àíXi0‚àí1)+(Xi0 ‚àíXi0+1)+c(xi0)h2Xi0 ‚â•0.
WehaveXi0‚àíXi0‚àí1 ‚â§0 andXi0‚àíXi0+1 ‚â§0,bydeÔ¨Ånitionofi0.Sincec(xi0) ‚â•c0 > 0,
this implies that Xi0 ‚â•0.
Finally, the case i0 = N + 1 cannot happen. Indeed, XN+1 ‚â•XN contradicts the
deÔ¨Ånition of i0. We have thus proven that Bh is inverse nonnegative. Since B0
h is a
particular case of Bh, B0
h is also inverse nonnegative.
Let us now prove estimate (2.22). We proceed as in Proposition 2.5. As before,
B‚àí1
h ‚àí(B0
h)‚àí1 = B‚àí1
h [B0
h‚àíBh](B0
h)‚àí1.Sincec ‚â•c0,thematrixB0
h‚àíBh isdiagonalwith
nonpositive entries and B‚àí1
h
‚â•0 and (B0
h)‚àí1 ‚â•0 as we have just seen. Consequently,
B‚àí1
h
‚àí(B0
h)‚àí1 ‚â§0. It follows that |||B‚àí1
h |||‚àû‚â§|||(B0
h)‚àí1|||‚àû.
In order to obtain estimate (2.22), it is thus sufÔ¨Åcient to show that
|||(B0
h)‚àí1|||‚àû= ‚à•(B0
h)‚àí1E‚à•‚àû‚â§C,
where C is a constant which does not depend on h and E the vector in RN+2 with
all components equal to 1. We notice that (B0
h)‚àí1E is precisely the discrete solution
Uh of system (2.20) in the particular case c = c0, f = 1 and ‚àíg0 = g1 = 1. In
other words, it is the discrete solution associated with the following boundary value
problem:

‚àí¬Øu‚Ä≤‚Ä≤(x) + c0¬Øu(x) = 1,
x ‚àà]0, 1[,
¬Øu‚Ä≤(0) = ‚àí1,
¬Øu‚Ä≤(1) = 1.
A simple computation shows that ¬Øu has the following expression:
¬Øu(x) =
1
‚àöc0
cosh
‚àöc0

x ‚àí1
2

sinh
 ‚àöc0
2

+ 1
c0
.
This function is of class C‚àû, hence C4. By deÔ¨Ånition of the truncation error Œµh(¬Øu) =
B0
hSh(¬Øu) ‚àíE, we have
(B0
h)‚àí1E = Sh(¬Øu) ‚àí(B0
h)‚àí1Œµh(¬Øu).
Consequently,
|||(B0
h)‚àí1|||‚àû= ‚à•(B0
h)‚àí1E‚à•‚àû‚â§‚à•Sh(¬Øu)‚à•‚àû+ |||(B0
h)‚àí1|||‚àû‚à•Œµh(¬Øu)‚à•‚àû.
Now ¬Øu is C4, hence by Proposition 2.6, ‚à•Œµh(¬Øu)‚à•‚àû‚â§Ch where C does not depend
on h. Therefore, for h sufÔ¨Åciently small, this quantity can be bounded from above by
1
2. It follows that

2.4 Neumann Boundary Conditions
53
|||(B0
h)‚àí1|||‚àû‚â§2‚à•Sh(¬Øu)‚à•‚àû‚â§2
 1
‚àöc0
coth
‚àöc0
2

+ 1
c0

,
due to the expression of ¬Øu. The values of h that are not sufÔ¨Åciently small in the above
sense are only Ô¨Ånite in number, thus this completes the proof.
‚ñ°
Note that the above estimate gets worse and worse as c0 ‚Üí0, which is con-
sistent with what happens when c0 = 0 and B0
h is no longer invertible. We deduce
from Proposition 2.6 (consistency) and Proposition 2.7 (stability) the following Ô¨Ånal
convergence result:
Corollary 2.2 Assume that there exists a constant c0 > 0 such that c ‚â•c0 and that
the solution u of problem (2.19) is C4 on [0, 1]. Then the scheme (2.20) is convergent
of order one. More precisely, we have
‚à•Uh ‚àíSh(u)‚à•‚àû‚â§Ch,
(2.23)
where C is a constant that does not depend on h.
Proof The proof is the same as for the Dirichlet case. We reproduce it for complete-
ness. By deÔ¨Ånition of the scheme and of the truncation error, we have
BhUh = Fh
and BhSh(u) = Fh + Œµh(u),
from which we deduce that
Bh(Uh ‚àíSh(u)) = ‚àíŒµh(u).
Since Bh is invertible, this implies that the error is given by
Uh ‚àíSh(u) = ‚àí(Bh)‚àí1Œµh(u),
so that we obtain
‚à•Uh ‚àíSh(u)‚à•‚àû‚â§|||(Bh)‚àí1|||‚àû‚à•Œµh(u)‚à•‚àû.
Estimate (2.23) then follows from (2.21) and (2.22).
‚ñ°
Remark 2.10 The Ô¨Ånal error estimate is only of order one, due to the decentered
scheme chosen for the approximation of the Neumann boundary condition and in
spite of the order two approximation of the second derivative inside the domain.
It could be thought that the order one error remains somehow concentrated near
the boundary and that the approximation is better inside. This is not the case. The
lower order approximation of the boundary condition ‚Äúpollutes‚Äù the discrete solution
everywhere, as we will see on a numerical example below.
‚ñ°
We can in fact improve the accuracy by choosing a central scheme for the approxima-
tion of the Neumann boundary condition, instead of the decentered approximations

54
2
The Finite Difference Method for Elliptic Problems
used before. In order to do that, we Ô¨Årst add two Ô¨Åctitious grid points x‚àí1 = ‚àíh
and xN+2 = 1 + h, which are outside the interval [0, 1], and we use the following
approximations of the Ô¨Årst derivative at both ends:
u‚Ä≤(0) ‚âàu(h) ‚àíu(‚àíh)
2h
,
u‚Ä≤(1) ‚âàu(1 + h) ‚àíu(1 ‚àíh)
2h
,
assuming u has been adequately extended outside of [0, 1], somehow.2 We also add
two Ô¨Åctitious discrete unknowns, denoted by u‚àí1 and uN+2. In order to have as
many unknowns as equations, we extend equation (2.19) up to the boundary of the
domain, i.e., we discretize it at each grid point xi, internal or not, which Ô¨Ånally gives
the scheme
‚éß
‚é™‚é®
‚é™‚é©
‚àíui+1 ‚àí2ui + ui‚àí1
h2
+ c(xi)ui = f (xi),
i ‚àà{0, . . . , N + 1},
u‚àí1 ‚àíu1
2h
= ‚àíg0,
uN+2 ‚àíuN
2h
= g1.
It can be shown that the truncation error of this new scheme is of order two.
In order to illustrate the compared performance of the previous schemes, we plot
the results of a few Scilab computations. We consider the case c(x) = 4, f (x) = 1
and ‚àíg0 = g1 = 1, for which we have an exact solution in closed form as seen before.
First we compute the results of the Ô¨Årst order scheme and plot them in Fig.2.4.
We plot the discrete solutions, again interpolated for easier visualization, for
N = 8, 12, 16, 20, and 24. Clearly, the convergence is fairly slow, and we can see
that the order 1 error is uniformly distributed over the whole domain, even though
it is only due to the approximation of the boundary conditions at the ends of the
interval, and the truncation error inside is of order 2.
Next, we plot the second order scheme for the same data (we do not plot the
Ô¨Åctitious values).
In this case, the marks for the discrete values are virtually on the graph of the
exact solution, thus indicating a much faster convergence. It should be noted that at
Ô¨Årst glance, the matrices of each method do not look that different from each other.
The results are nonetheless dramatically different, see Fig.2.5.
Fig. 2.4 First order scheme
with √ó marks. Exact solution
in solid line with no marks
2We skip the details.

2.4 Neumann Boundary Conditions
55
Fig. 2.5 Second order
scheme with √ó marks. Exact
solution in solid line with no
marks
Remark 2.11 Let us make a Ô¨Ånal remark concerning the resolution of the discrete
problem (2.20) in practice. This must be performed using a numerical method for
linear systems implemented in software. Of course, such numerical methods work in
Ô¨Çoating point arithmetic, hence are subject to round-off errors. This thus raises the
important question of controlling the effect of such errors on the computed solution.
Let us consider a N √ó N linear system AX = F where A is invertible. We wish
to measure the error Œ¥X produced on the solution X by an error Œ¥F on the right-
hand side F, i.e., A(X + Œ¥x) = F + Œ¥F. Subtracting the two equations, we obtain
AŒ¥X = Œ¥F, from which we deduce that ‚à•Œ¥X‚à•‚â§|||A‚àí1||| ‚à•Œ¥F‚à•(where ‚à•¬∑ ‚à•is a given
norm on RN and ||| ¬∑ ||| the associated matrix norm). On the other hand, we also have
‚à•F‚à•‚â§|||A||| ‚à•X‚à•, from which we deduce that
1
‚à•X‚à•‚â§
|||A|||
‚à•F‚à•when F Ã∏= 0 and thus
X Ã∏= 0. Multiplying the two estimates together yields
‚à•Œ¥X‚à•
‚à•X‚à•‚â§|||A||| |||A‚àí1||| ‚à•Œ¥F‚à•
‚à•F‚à•.
(2.24)
The number cond A = |||A||| |||A‚àí1||| is called the condition number of A (with respect
to the norm ‚à•¬∑ ‚à•) [6, 18, 53]. It is always larger than 1 since 1 = |||I||| ‚â§|||A||| |||A‚àí1|||
by submultiplicativity of an induced matrix norm. If it is roughly speaking small, we
say that the matrix is well-conditioned. On the contrary, if it is large compared to 1,
we say that the matrix is ill-conditioned. In the latter case, even a small relative error
on the right-hand side may induce a large relative error on the solution, which may
render the numerical computation meaningless. This is not the case if the matrix
is well-conditioned, on account of estimate (2.24). Of course, different numerical
methods have different abilities to handle ill-conditioned matrices. Some will fail on
some ill-conditioned matrices, whereas others will succeed on the same matrices.
The latter concept is not entirely well deÔ¨Åned.
Let us go back to the Ô¨Årst order scheme for the Neumann problem. We have written
it in a ‚Äúnatural‚Äù form that allows for consistency and stability to be established. There
are however inÔ¨Ånitely many other different matrix forms, with the same solutions
but different condition numbers.
In fact, we can for instance write this system in the following equivalent form:
B‚Ä≤
hUh = F‚Ä≤
h,
(2.25)

56
2
The Finite Difference Method for Elliptic Problems
with
B‚Ä≤
h = 1
h2
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù
1
‚àí1
0
...
...
0
‚àí1
2 + h2c(x1)
‚àí1
...
...
0
‚àí1
2 + h2c(x2) ‚àí1
...
...
0
...
...
...
...
0
...
...
‚àí1
2 + h2c(xN) ‚àí1
0
...
...
0
‚àí1
1
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†
,
and
F‚Ä≤
h =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éù
‚àíg0
h
f (x1)
...
f (xN)
g1
h
‚éû
‚éü‚éü‚éü‚éü‚éü‚é†
,
where both the Ô¨Årst and the last equations of system (2.20) have been divided by h.
Eventhoughthetwosystems(2.20)and (2.25)arestrictlyequivalentintermsoflinear
algebra, the new form (2.25) is not suitable for the computation of the truncation
error. It is however better suited for numerical resolution because the matrix B‚Ä≤
h has
a condition number that is smaller than that of matrix Bh.
We Ô¨Årst plot on Fig.2.6 the two condition numbers for the ‚à•¬∑‚à•‚àûnorm, as a function
of N in the case c(x) = 1. Next, Fig.2.7, we plot their ratio, still as a function of N. For
Fig. 2.6 Condition number of Bh top and B‚Ä≤
h bottom

2.4 Neumann Boundary Conditions
57
Fig. 2.7 Ratio cond Bh
cond B‚Ä≤
h
N large, both condition numbers are quite large, but there is a ratio of approximately 3
between the two, which is not spectacular, albeit appreciable. The general problem of
Ô¨Ånding a linear system equivalent to a given linear system but with a better condition
number is called preconditioning.
‚ñ°
2.5
The Two-Dimensional Case
The Ô¨Ånite difference method also applies to higher-dimensional elliptic problems,
with some limitations. We describe here the approximation of a simple two-
dimensional problem, and the generalization to three-dimensional and higher is easy
to imagine.
Let us thus consider the homogeneous Dirichlet problem in Œ© = ]0, 1[ √ó ]0, 1[

‚àíŒîu(x) = f (x) in Œ©,
u(x) = 0 on Œì,
(2.26)
where f is a given continuous function on ¬ØŒ© and Œì = ‚àÇŒ©. We will see in Chap.4
that this problem has a unique solution. In general, there is no closed form solution,
therefore our goal here is again to deÔ¨Åne a Ô¨Ånite difference approximation for it. For

58
2
The Finite Difference Method for Elliptic Problems
Fig. 2.8 A 2d grid
0.2
0.4
0.6
0.8
1
0.2
0.4
0.6
0.8
1
0
xi1,i2
h1
h2
that purpose, we start by placing a uniform grid in ¬ØŒ© as follows. Let us be given N1
and N2 two positive integers. We let h1 = 1/(N1 + 1) be the grid step in direction
x1 and h2 = 1/(N2 + 1) be the grid step in direction x2. The grid points will then be
xi1,i2 = (i1h1, i2h2) for i1 ‚àà{0, . . . , N1 + 1} and i2 ‚àà{0, . . . , N2 + 1}. The boundary
grid points correspond to i1 ‚àà{0, N1 + 1} or i2 ‚àà{0, N2 + 1}, and the internal grid
points to 1 ‚â§i1 ‚â§N1 and 1 ‚â§i2 ‚â§N2, see Fig.2.8.
Following the same idea as in the one-dimensional case, we want to compute an
approximation ui1,i2 of u(xi1,i2) for each i1 ‚àà{0, . . . , N1+1} and i2 ‚àà{0, . . . , N2+1}.
We naturally enforce the exact Dirichlet boundary condition on the boundary grid
points, i.e., we set ui1,i2 = 0 if i1 ‚àà{0, N1 + 1} or if i2 ‚àà{0, N2 + 1}.
We then need to approximate the Laplacian of u at internal grid points. Since
partial derivatives are nothing more than usual one-dimensional derivatives with
all the other variables frozen, we use the now familiar three point scheme for that
purpose. Namely, we approximate
‚àÇ2u
‚àÇx2
1
(x1, ¬∑) ‚âàu(x1 + h1, ¬∑) ‚àí2u(x1, ¬∑) + u(x1 ‚àíh1, ¬∑)
h2
1
and
‚àÇ2u
‚àÇx2
2
(¬∑, x2) ‚âàu(¬∑, x2 + h2) ‚àí2u(¬∑, x2) + u(¬∑, x2 ‚àíh2)
h2
2
.
Note that the variable x2 plays no role in the Ô¨Årst approximation and likewise for x1
in the second approximation. Taking into account that Œîu = ‚àÇ2u
‚àÇx2
1 + ‚àÇ2u
‚àÇx2
2 , this leads to
the following scheme:

2.5 The Two-Dimensional Case
59
Fig. 2.9 The Ô¨Åve point
stencil for the Laplacian
i2 ‚àí1
i2
i2 +1
i1
i1 ‚àí1
i1 +1
xi1,i2
xi1,i2+1
xi1,i2‚àí1
xi1+1,i2
xi1‚àí1,i2
‚éß
‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é©
‚àíui1+1,i2 ‚àí2ui1,i2 + ui1‚àí1,i2
h2
1
‚àíui1,i2+1 ‚àí2ui1,i2 + ui1,i2‚àí1
h2
2
= f (xi1,i2), for i1 ‚àà{1, . . . , N1}, i2 ‚àà{1, . . . , N2},
ui1,i2 = 0, for i1 ‚àà{0, N1 + 1} or i2 ‚àà{0, N2 + 1}.
This scheme is called the Ô¨Åve point scheme for the Laplacian. It is a central scheme.
Indeed, in order to evaluate the discrete approximation of Œîu at point xi1,i2, we use
the approximate values of u at the Ô¨Åve grid points centered around xi1,i2, namely the
point xi1,i2 itself and its four neighboring points xi1,i2‚àí1, xi1,i2+1, xi1‚àí1,i2 and xi1+1,i2.
These Ô¨Åve points constitute the stencil of the scheme, see Fig.2.9.
We need to reformulate the above scheme as a linear system. In order to do that,
we Ô¨Årst have to number the unknowns. For example, we can decide to number them
in the following way u1,1, ¬∑ ¬∑ ¬∑ , uN1,1, u1,2, ¬∑ ¬∑ ¬∑ , uN1,2, ¬∑ ¬∑ ¬∑ , uN1,1, ¬∑ ¬∑ ¬∑ , uN1,N2, i.e., line
by line. Other numberings are possible, for instance column by column.
With this choice of numbering, the scheme has the following equivalent vector
form
Ch1,h2Uh1,h2 = Fh1,h2,
(2.27)
where the N1N2√óN1N2 matrix Ch1,h2 has a block structure. More precisely, the matrix
Ch1,h2 is composed of N2
2 blocks, each one of size N1 √ó N1 and tridiagonal,

60
2
The Finite Difference Method for Elliptic Problems
Ch1,h2 =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù
A
‚àíb2I
0
...
...
...
0
‚àíb2I
A
‚àíb2I
...
...
0
‚àíb2I
A
‚àíb2I
...
...
...
...
...
...
...
...
...
...
...
‚àíb2I
A
‚àíb2I
0
...
...
‚àíb2I
A
‚àíb2I
0
...
...
...
0
‚àíb2I
A
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†
,
where A is the N1 √ó N1 matrix deÔ¨Åned by
A =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù
a
‚àíb1
0
...
...
0
‚àíb1
a
‚àíb1
...
...
0
...
...
...
...
...
...
...
...
...
...
0
...
... ‚àíb1
a
‚àíb1,
0
...
...
0
‚àíb1
a
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†
,
and I is the N1 √ó N1 identity matrix, where we have set
b1 = 1
h2
1
,
b2 = 1
h2
2
,
and
a = 2(b1 + b2)
for simplicity. Thus the matrix Ch1,h2 is block tridiagonal. There are no more than
Ô¨Åve nonzero elements on each line (or each column) in the matrix Ch1,h2. Moreover,
the matrix Ch1,h2 is symmetric.
The unknown Uh1,h2 and the right-hand side Fh1,h2 have the same block structure
given by
Uh1,h2 =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éù
U1
...
Ui2
...
UN2
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚é†
, where Ui2 =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éù
u1,i2
...
ui1,i2
...
uN1,i2
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚é†
‚ààRN1,

2.5 The Two-Dimensional Case
61
and
Fh1,h2 =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éù
F1
...
Fi2
...
FN2
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚é†
, where Fi2 =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éù
f (h1, i2h2)
...
f (i1h1, i2h2)
...
f (N1h1, i2h2)
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚é†
‚ààRN1.
We Ô¨Årst note that the method is well-posed.
Proposition 2.8 The matrix Ch1,h2 is positive deÔ¨Ånite, hence invertible.
Proof Same as in Proposition 2.1.
‚ñ°
Let us now study the convergence of the method. We start with the consistency. We
Ô¨Årst need to adapt the deÔ¨Ånition of the grid sampling operator to the present context.
Here,theoperatorhasvaluesinRN1N2 andissimplydeÔ¨ÅnedbySh1,h2(v)i1,i2 = v(xi1,i2),
for any v ‚ààC0( ¬ØŒ©).
Proposition 2.9 Let us suppose that the solution u of problem (2.26) is C4 on ¬ØŒ©.
Then the scheme (2.27) is consistent of order two.
Proof Let us denote by Œµh1,h2(u) = Ch1,h2Sh1,h2(u)‚àíFh1,h2 the truncation error. Using
the same numbering as before, it has the block structure
Œµh1,h2(u) =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éù
Œµh1,h2(u)1
...
Œµh1,h2(u)i2
...
Œµh1,h2(u)N2
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚é†
, where Œµh1,h2(u)i2 =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éù
Œµh1,h2(u)1,i2
...
Œµh1,h2(u)i1,i2
...
Œµh1,h2(u)N1,i2
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚é†
‚ààRN1.
We assume that u is C4 on ¬ØŒ©. We have
Œµh1,h2(u)i1,i2 = ‚àíu(xi1+1,i2) ‚àí2u(xi1,i2) + u(xi1‚àí1,i2)
h2
‚àíu(xi1,i2+1) ‚àí2u(xi1,i2) + u(xi1,i2‚àí1)
h2
‚àíf (xi1,i2).
We remark that in each differential quotient, one variable is Ô¨Åxed (either the Ô¨Årst one
or the second one), so that we can still use the Taylor‚ÄìLagrange expansion (2.3).
Thanks to the Ô¨Årst equation in (2.26), we then obtain
(Œµh1,h2(u))i1,i2 = ‚àí1
12

h2
1
‚àÇ4u
‚àÇx4
1
(Œæi1,i2, i2h2) + h2
2
‚àÇ4u
‚àÇx4
2
(i1h1, Œæ ‚Ä≤
i1,i2)

,
for some Œæi1,i2 ‚àà](i1 ‚àí1)h1, (i1 + 1)h1[ and Œæ ‚Ä≤
i1,i2 ‚àà](i2 ‚àí1)h2, (i2 + 1)h2[. Setting
h = max(h1, h2), we deduce that

62
2
The Finite Difference Method for Elliptic Problems
‚à•Œµh1,h2(u)‚à•‚àû‚â§Mh2,
where
M = 1
12

max
y‚àà¬ØŒ©
‚àÇ4u
‚àÇx4
1
(y)
 + max
y‚àà¬ØŒ©
‚àÇ4u
‚àÇx4
2
(y)


.
(2.28)
This shows that the scheme (2.27) is consistent of order two.
‚ñ°
Let us now study the stability of the method.
Proposition 2.10 We have the following estimate, for all h1, h2,
|||(Ch1,h2)‚àí1|||‚àû‚â§1
8.
(2.29)
Proof Let Œ©h1,h2 be the set of the indices of the grid points which are inside Œ©, Œìh1,h2
the set of the indices of the grid points which are on Œì and ¬ØŒ©h1,h2 = Œ©h1,h2 ‚à™Œìh1,h2 =
{0, . . . , N1 +1}√ó{0, . . . , N2 +1} the set of all grid indices. We consider the operator
D: R ¬ØŒ©h1,h2 ‚ÜíRŒ©h1,h2 deÔ¨Åned by
(DZ)i1,i2 = aZi1,i2 ‚àíb1(Zi1‚àí1,i2 + Zi1+1,i2) ‚àíb2(Zi1,i2‚àí1 + Zi1,i2+1).
The operator D is just the discrete Ô¨Åve point Laplacian without boundary conditions.
We Ô¨Årst establish a discrete maximum principle for D. More precisely, we claim that
if DZ ‚â§0, then
max
¬ØŒ©h1,h2
Zi1,i2 = max
Œìh1,h2
Zi1,i2.
(2.30)
Indeed, if the maximum in question is attained on Œìh1,h2, there is nothing to prove.
So let (m1, m2) ‚ààŒ©h1,h2 be an index such that Zm1,m2 ‚â•Zi1,i2, for all (i1, i2) ‚àà¬ØŒ©h1,h2.
Since (DZ)m1,m2 ‚â§0 and a = 2(b1 + b2), we have
aZm1,m2 ‚â§b1(Zm1+1,m2 + Zm1‚àí1,m2) + b2(Zm1,m2+1 + Zm1,m2‚àí1) ‚â§aZm1,m2.
Since b1 > 0 and b2 > 0, it follows that
Zm1,m2 = Zm1+1,m2 = Zm1‚àí1,m2 = Zm1,m2+1 = Zm1,m2‚àí1.
In other words, the maximum is also attained for the neighboring indices (m1+1, m2),
(m1 ‚àí1, m2), (m1, m2 + 1) and (m1, m2 ‚àí1). By an immediate induction, we have
Zm1,m2 = Zm1‚àí1,m2 = ¬∑ ¬∑ ¬∑ = Z0,m2. This means that the maximum is in fact attained
on Œìh1,h2 as well and we are done with the claim.
Let us now establish estimate (2.29). Let X be an arbitrary vector in RŒ©h1,h2 . We
deÔ¨Åne a vector X ‚ààR ¬ØŒ©h1,h2 by Xi1,i2 = Xi1,i2 for (i1, i2) ‚ààŒ©h1,h2 and Xi1,i2 = 0 for
(i1, i2) ‚ààŒìh1,h2. With this deÔ¨Ånition, we see that (DX)i1,i2 = (Ch1,h2X)i1,i2, for all
(i1, i2) ‚ààŒ©h1,h2.

2.5 The Two-Dimensional Case
63
Let now Y ‚ààR ¬ØŒ©h1,h2 be deÔ¨Åned by
Yi1,i2 = 1
4

i1 ‚àíN1 + 1
2
2
h2
1 +

i2 ‚àíN2 + 1
2
2
h2
2

.
By direct inspection, we see that (DY)i1,i2 = ‚àí1 for all (i1, i2) ‚ààŒ©h1,h2.
We next choose s = ¬±1 in such a way that
max
(i1,i2)‚ààŒ©h1,h2
|Xi1,i2| = |Xn1,n2| = sXn1,n2,
for some (n1, n2) ‚ààŒ©h1,h2. This way, we have
max
(i1,i2)‚ààŒ©h1,h2
|Xi1,i2| ‚â§
max
(i1,i2)‚ààŒ©h1,h2
(sXi1,i2).
Finally, let Z = sX + ‚à•Ch1,h2X‚à•‚àûY. We note that
‚à•Ch1,h2X‚à•‚àû=
max
(i1,i2)‚ààŒ©h1,h2
|(DX)i1,i2|.
Therefore, we have
(DZ)i1,i2 = s(DX)i1,i2 ‚àí‚à•Ch1,h2X‚à•‚àû‚â§0,
for all (i1, i2) ‚ààŒ©h1,h2. Applying estimate (2.30) to Z, we obtain
max
(i1,i2)‚ààŒ©h1,h2
(sXi1,i2) ‚â§
max
(i1,i2)‚ààŒ©h1,h2
Zi1,i2
‚â§
max
(i1,i2)‚ààŒìh1,h2
Zi1,i2
‚â§
max
(i1,i2)‚ààŒìh1,h2
(sXi1,i2) + ‚à•Ch1,h2X‚à•‚àû
8
,
since 0 ‚â§Yi1,i2 ‚â§1
8, for all (i1, i2) ‚àà¬ØŒ©h1,h2. Now Xi1,i2 = 0 on Œìh1,h2, therefore
‚à•X‚à•‚àû=
max
(i1,i2)‚ààŒ©h1,h2
|Xi1,i2| ‚â§‚à•Ch1,h2X‚à•‚àû
8
,
which completes the proof.
‚ñ°
Remark 2.12 The proof above shows, with only minor modiÔ¨Åcations, that the matrix
Ch1,h2 is inverse nonnegative.
The proof also shows that any Z such that DZ ‚â§0 and that attains its maximum
in Œ©h1,h2 is in fact constant.
As opposed to the one-dimensional case, we do not have a closed form formula
for the solution of ‚àíŒî¬Øu = 1 in Œ©, ¬Øu = 0 on Œì , at our disposal (¬Øu can however be

64
2
The Finite Difference Method for Elliptic Problems
expressed with Fourier series or approximated using Ô¨Ånite differences, see below),
hencenoclosedformexpressionforitsmaximumvalue.Thisexplainstheroundabout
way of introducing Y to play the same role, without boundary conditions.
As a consequence, the resulting stability estimate is not optimal, contrarily to the
one-dimensional case. Numerical evidence indicates that |||(Ch1,h2)‚àí1|||‚àû‚âà0.07356
pretty much independently of h1, h2 in the cases we computed.
‚ñ°
We deduce from Proposition 2.9 (consistency) and Proposition 2.10 (stability) the
Ô¨Ånal convergence result.
Corollary 2.3 Let us suppose that the solution u of problem (2.26) is C4 on ¬ØŒ©. Then
the scheme (2.27) is convergent of order two. More precisely, we have
‚à•Uh1,h2 ‚àíSh1,h2(u)‚à•‚àû‚â§M
8 h2,
(2.31)
where M is given by (2.28) and h = max(h1, h2).
Proof Exactly the same as in Corollary 2.2.
‚ñ°
Remark 2.13 On the surface, it looks like the one-dimensional error estimate (2.13)
and the two-dimensional error estimate (2.31) are basically the same. This is not
actually so. Indeed, an important consideration in numerical methods is that of their
cost. In effect, it is only possible to meaningfully compare two methods if they apply
to data of the same size.
For example, let us assume that Gaussian elimination, see [6, 53, 71], is used to
solve linear systems (we ignore the fact that more efÔ¨Åcient methods may exist that are
better adapted to these particular matrices). In the one dimensional case, this would
lead to a compute time T1d = O(N3) = O(h‚àí3), whereas in the two-dimensional
case, we would be looking at a compute time T2d = O(N6) = O(h‚àí6) since the
system to be solved is a N2 √ó N2 system.3 Thus the time required to achieve a given
error estimate in two dimensions is roughly the square of the time needed to achieve
the same error estimate in one dimension.
This is a general fact: Computations become exponentially costlier and costlier as
the dimension of the problem grows. This is called the curse of dimen-
sionality.
‚ñ°
Let us illustrate the previous considerations in Fig.2.10 with a plot of the Ô¨Ånite
difference solution of the Poisson problem ‚àíŒî¬Øu = 1 in Œ©, ¬Øu = 0 on Œì , in the unit
square. This plot can be visualized in 3D by squinting toward the middle of the page.
We have described the Ô¨Ånite difference method for the Poisson equation in the
unit square. It immediately generalizes to the case of a rectangle. The case of a more
general two-dimensional domain Œ© is more complicated.
3In practice, the cases considered here are all very small, and are solved almost instantaneously on
a personal computer, but the remark applies to more computationally challenging problems.

2.5 The Two-Dimensional Case
65
Fig. 2.10 Cross-eyed autostereogram for 3d visualization of the Ô¨Ånite difference solution for N = 21

66
2
The Finite Difference Method for Elliptic Problems
Fig. 2.11 The point qE is
outside Œ© and is replaced by
q‚Ä≤
E as part of the grid
Let us consider the following non homogeneous Dirichlet problem: Find
u: ¬ØŒ© ‚ÜíR solution of

‚àíŒîu(x) = f (x),
x ‚ààŒ©,
u(x) = g(x),
x ‚ààŒì,
where g is the given Dirichlet data on the boundary Œì of Œ©.
For simplicity, we assume that h1 = h2 = h and we consider the lattice hZ2 in
the plane. The straight lines parallel to the axes and going through lattice points are
called grid lines. In order to construct a Ô¨Ånite difference grid for the problem, we
Ô¨Årst retain the lattice points that belong to Œ©. The difÔ¨Åculty is that in order to impose
the Dirichlet boundary condition, we need points on the boundary, whereas lattice
points have no reason to fall on the boundary. To remedy this situation, the idea is
to replace the lattice points that are closest to Œ© outside of Œ© by the intersection of
grid lines with Œì . The Ô¨Ånite difference scheme must be modiÔ¨Åed accordingly in the
vicinity of such points.
To Ô¨Åx ideas, let us consider one possible conÔ¨Åguration in Fig.2.11. The grid point
q is such that its lattice neighbors qS, qW and qN are inside Œ©. We keep them in the
grid. On the contrary, the point qE is outside Œ© and closest to Œì . We replace it by
point q‚Ä≤
E of intersection of the grid line with Œì . Its distance to point q is h‚Ä≤ < h, as
can be seen on the Ô¨Ågure.
In the case of Fig.2.11, we now look for an approximation of Œîu(q) that uses
points q, qS, qW, qN and q‚Ä≤
E. We just have to modify the approximation of the second
order derivative with respect to variable x1 (for the other variable, we can use the
usual three point scheme using q, qS and qN which are inside Œ©). Let us explain how
this works. The trick consists in Ô¨Ånding three coefÔ¨Åcients Œ±, Œ≤ and Œ≥ such that

2.5 The Two-Dimensional Case
67
Œ±u(qW) + Œ≤u(q) + Œ≥ u(q‚Ä≤
E) = ‚àÇ2u
‚àÇx2
1
(q) + O(h).
Using as usual Taylor‚ÄìLagrange expansions of u(qW) and of u(q‚Ä≤
E) in a neighborhood
of q, we get the following system:
Œ± + Œ≤ + Œ≥ = 0,
‚àíŒ±h + Œ≥ h‚Ä≤ = 0,
Œ± h2
2 + Œ≥ h‚Ä≤2
2 = 1,
which admits a unique solution given by
Œ± =
2
h(h + h‚Ä≤),
Œ≤ = ‚àí2
hh‚Ä≤ ,
Œ≥ =
2
h‚Ä≤(h + h‚Ä≤).
We can check that the truncation error is only of order one due to the fact that h‚Ä≤ Ã∏= h,
hence a lesser quality of approximation compared with the rectangular case. Let us
remark that the matrix of the linear system we have to solve is no longer symmetric.
2.6
Concluding Remarks
To conclude, we see that the Ô¨Ånite difference method is not easily implemented in
arbitrary domains in dimensions higher than 1 or for different boundary conditions.
This is a serious limitation of the method for applications. It works well on domains
with simple geometry, for example domains which are unions of rectangles, with
Dirichlet boundary conditions. However, in the general case, i.e., for arbitrary do-
mains and other boundary conditions, the Ô¨Ånite element method that we will see in
two dimensions in Chap.6 will be generally preferred.
We will return to the Ô¨Ånite difference method in Chap.8 for the heat equation in
one dimension of space and Chap.9 for the wave equation also in one dimension of
space.
The Ô¨Ånite difference method for one-dimensional elliptic problems is mentioned
in many references. The reader is referred to [18, 46, 47, 64, 70, 75] for example, for
various extensions and points of view.

Chapter 3
A Review of Analysis
In order to go beyond the somewhat naive existence theory and Ô¨Ånite difference
method of approximation of elliptic boundary value problems seen in Chaps.1 and
2, we need to develop a more sophisticated point of view. This requires in turn some
elements of analysis pertaining to function spaces in several variables, starting with
some abstract Hilbert space theory. This is the main object of this chapter.
As already mentioned in the preface, this chapter can be read quickly at Ô¨Årst,
for readers who are not too interested in the mathematical details and constructions
therein. A summary of the important results needed for the subsequent chapters is
thus provided at the end of the chapter.
3.1
Basic Hilbert Space Theory
Let us quickly review basic Hilbert space theory from the abstract viewpoint. Let H
be a real Hilbert space, i.e., a real vector space endowed with a scalar product (¬∑|¬∑)H
and associated norm ‚à•¬∑ ‚à•H which is complete for this norm. The Cauchy‚ÄìSchwarz
inequality is really a hilbertian property.
Theorem 3.1 For all u, v ‚ààH, we have
|(u|v)H| ‚â§‚à•u‚à•H‚à•v‚à•H.
One of the most basic results in Hilbert space theory is the orthogonal projection
theorem, see [9, 14, 32, 51] for a proof.
Theorem 3.2 Let C be a non empty, convex, closed subset of H. For all x ‚ààH,
there exists a unique pC(x) ‚ààC such that
‚à•x ‚àípC(x)‚à•H = inf
y‚ààC ‚à•x ‚àíy‚à•H.
¬© Springer International Publishing Switzerland 2016
H. Le Dret and B. Lucquin, Partial Differential Equations:
Modeling, Analysis and Numerical Approximation, International Series
of Numerical Mathematics 168, DOI 10.1007/978-3-319-27067-8_3
69

70
3
A Review of Analysis
Fig. 3.1 The orthogonal
projection on a closed
convex subset C
x
y
pC(x)
C
The vector pC(x) is called the orthogonal projection of x onC. It is also characterized
by the inequality
‚àÄy ‚ààC,
(x ‚àípC(x)|y ‚àípC(x))H ‚â§0.
In addition, if the convex set is a closed vector subspace E of H, then pE is a
continuous linear mapping from H to E which is also characterized by the equality
‚àÄy ‚ààE,
(x ‚àípE(x)|y)H = 0.
The orthogonal projection of x on C is thus the element of C closest to x and the
angle between x ‚àípC(x) and y ‚àípC(x) is larger than œÄ
2 , see Fig.3.1. In particular, if
x ‚ààC, then pC(x) = x. An important consequence of the last characterization in the
case of a closed vector subspace E is that we can write H = E ‚äïE‚ä•with continuous
orthogonal projections on each factor. Indeed, we have x = pE(x) + (x ‚àípE(x))
with pE(x) ‚ààE by construction and x‚àípE(x) ‚ààE‚ä•by the second characterization.
Hence H = E + E‚ä•. To show that the sum is direct, it sufÔ¨Åces to note that E ‚à©E‚ä•=
{0} which is obvious since x ‚ààE ‚à©E‚ä•implies 0 = (x|x)H = ‚à•x‚à•2
H, see Fig.3.2.
Another important consequence is a characterization of dense subspaces.
Lemma 3.1 A vector subspace E of H is dense in H if and only if E‚ä•= {0}.
Proof For any vector subspace, it is always true that E‚ä•= ( ¬ØE)‚ä•. Let E be a dense
subspace, i.e., ¬ØE = H. Then, of course E‚ä•= H ‚ä•= {0}. Conversely, if E‚ä•= {0},
this implies that ( ¬ØE)‚ä•= {0} and since H = ( ¬ØE)‚ä•‚äï¬ØE, it follows that ¬ØE = H, and
E is dense in H.
‚ñ°
The Riesz theorem provides a canonical way of identifying a Hilbert space and
its dual.
Theorem 3.3 (Riesz) Let H be a Hilbert space and ‚Ñìan element of its dual H ‚Ä≤.
There exists a unique u ‚ààH such that

3.1 Basic Hilbert Space Theory
71
Fig. 3.2 The orthogonal
projection on a closed vector
subspace E
E
E‚ä•
x
pE(x)
pE‚ä•(x)
0
‚àÄv ‚ààH,
‚Ñì(v) = (u|v)H.
Moreover
‚à•‚Ñì‚à•H ‚Ä≤ = ‚à•u‚à•H
and the linear mapping œÉ : H ‚Ä≤ ‚ÜíH, ‚Ñì‚Üíu, is an isometry.
Proof For the uniqueness, assume u1 and u2 are two solutions, then for all v ‚ààH,
(v|u1 ‚àíu2)H = 0. This is true in particular for v = u1 ‚àíu2, hence u1 = u2.
If ‚Ñì= 0, then we set u = 0 to be the unique u in question. Let ‚ÑìÃ∏= 0. It is
thus a nonzero continuous linear form, hence its kernel ker ‚Ñìis a closed hyperplane
of H. Let us choose u0 ‚àà(ker ‚Ñì)‚ä•with ‚à•u0‚à•H = 1 (this is possible since ker ‚Ñìis
not dense). Since u0 /‚ààker ‚Ñì, we have ‚Ñì(u0) Ã∏= 0 and for all v ‚ààH, we can set
w = v ‚àí‚Ñì(v)
‚Ñì(u0)u0 so that
‚Ñì(w) = ‚Ñì

v ‚àí‚Ñì(v)
‚Ñì(u0)u0

= ‚Ñì(v) ‚àí‚Ñì(v)
‚Ñì(u0)‚Ñì(u0) = 0,
and w ‚ààker ‚Ñì. Now writing v =
‚Ñì(v)
‚Ñì(u0)u0 + w and setting u = ‚Ñì(u0)u0 ‚àà(ker ‚Ñì)‚ä•,
we obtain
(v|u)H =
 ‚Ñì(v)
‚Ñì(u0)u0
u

H + (w|u)H = ‚Ñì(v)(u0|u0)H = ‚Ñì(v),
hence the existence of u.

72
3
A Review of Analysis
The mapping œÉ is thus well deÔ¨Åned and obviously linear. Finally, for the isometry,
we have on the one hand
‚à•‚Ñì‚à•H ‚Ä≤ = sup
‚à•v‚à•H ‚â§1
|‚Ñì(v)| = sup
‚à•v‚à•H ‚â§1
|(v|u)H| ‚â§‚à•v‚à•H‚à•u‚à•H ‚â§‚à•u‚à•H,
by the Cauchy‚ÄìSchwarz inequality. On the other hand, equality trivially holds for
‚Ñì= 0, and for ‚ÑìÃ∏= 0, choosing v =
u
‚à•u‚à•H yields (v|u)H = ‚à•u‚à•H with ‚à•v‚à•H = 1,
hence the equality in this case too.
‚ñ°
Remark 3.1 The Riesz theorem shows that the dual of a Hilbert space is also a Hilbert
space for the scalar product (‚Ñì1|‚Ñì2)H ‚Ä≤ = (œÉ‚Ñì1|œÉ‚Ñì2)H which induces the dual norm.
Indeed it is not a priori obvious that the dual norm is hilbertian. It is often used to
identify H and H ‚Ä≤ via the isometry œÉ or œÉ ‚àí1. This identiÔ¨Åcation is not systematic
however. For example, when we have two Hilbert spaces H and V such that V ‚ÜíH
and V is dense in H, the usual identiÔ¨Åcation is to let
V ‚ÜíH = H ‚Ä≤ ‚ÜíV ‚Ä≤
using the Riesz theorem for H, which is called the pivot space, but not for V , see
[15, 28].
‚ñ°
We now turn to the study of more concrete function spaces.
3.2
A Few Basic Function Spaces
Let us rapidly review the most basic function spaces that we will need. All these
function spaces are real valued. In the sequel, Œ© denotes an open subset of Rd,
d ‚â•1. The canonical scalar product of two vectors x and y in Rd will be denoted
x ¬∑ y = d
i=1 xi yi, where xi (resp. yi) are the components of x (resp. y). The
associated Euclidean norm is ‚à•x‚à•= (x ¬∑ x)1/2. We use the multiindex notation for
partial derivatives. Let Œ± = (Œ±1, Œ±2, . . . , Œ±d) ‚ààNd be a multiindex. The integer
|Œ±| = d
i=1 Œ±i is called the length of Œ± and we set
‚àÇŒ±u =
‚àÇ|Œ±|u
‚àÇxŒ±1
1 ‚àÇxŒ±2
2 ¬∑ ¬∑ ¬∑ ‚àÇxŒ±d
d
,
whenever the function u is |Œ±|-times differentiable and the partial derivatives com-
mute. The space C0(Œ©) is the space of real-valued, continuous functions on Œ©, and
for all k ‚ààN, we deÔ¨Åne
Ck(Œ©) = {u;
for all Œ± ‚ààNd, |Œ±| ‚â§k, ‚àÇŒ±u ‚ààC0(Œ©)}

3.2 A Few Basic Function Spaces
73
to be the space of k-times continuously differentiable functions on Œ©. The space of
indeÔ¨Ånitely differentiable functions on Œ© is deÔ¨Åned by
C‚àû(Œ©) =

k‚ààN
Ck(Œ©).
We do not specify the natural topologies of these vector spaces as we will not need
them. Beware however that these natural topologies are not normed.
The support of a function u, supp u, is the complement of the largest open subset
of Œ© on which u vanishes. It is thus a closed subset of Œ©. A subset K of Œ© is compact
if and only if it is a closed, bounded subset that ‚Äúdoes not touch the boundary‚Äù in the
sense that d(K, ‚àÅRdŒ©) > 0. There is a ‚Äúsecurity strip‚Äù between K and ‚àÇŒ©. Functions
with compact support play an important role and deserve a notation of their own:
Ck
c (Œ©) = Dk(Œ©) = {u ‚ààCk(Œ©); supp u is compact}
and
C‚àû
c (Œ©) = D(Œ©) =

k‚ààN
Dk(Œ©).
Again, these vector spaces are endowed with natural topologies that we will not
describe. We will return to these spaces later when talking about distributions.
Let ¬ØŒ© be the closure of Œ© in Rd. The space C0( ¬ØŒ©) is the space of continuous
functions on ¬ØŒ©. If ¬ØŒ© is compact, that is to say, if Œ© is bounded, this space is normed
by
‚à•u‚à•C0( ¬ØŒ©) = sup
x‚àà¬ØŒ©
|u(x)| = max
x‚àà¬ØŒ© |u(x)|.
The convergence associated to this normed topology is just uniform convergence.
Likewise, we deÔ¨Åne Ck( ¬ØŒ©) to be the space of functions in Ck(Œ©), all the par-
tial derivatives of which up to order k have a continuous extension to ¬ØŒ©. Keep-
ing the same symbol for this extension, the natural norm of this space when Œ© is
bounded is
‚à•u‚à•Ck( ¬ØŒ©) = max
|Œ±|‚â§k ‚à•‚àÇŒ±u‚à•C0( ¬ØŒ©),
and the convergence of a sequence in this space is the uniform convergence of all
partial derivatives up to order k. All these spaces are Banach spaces, i.e., they are
complete for the metric deÔ¨Åned by their norm. We also deÔ¨Åne
C‚àû( ¬ØŒ©) =

k‚ààN
Ck( ¬ØŒ©),
a space which is endowed with a natural topology that is again not a normed space,
even when ¬ØŒ© is compact.

74
3
A Review of Analysis
For 0 < Œ≤ ‚â§1 and Œ© bounded, we deÔ¨Åne the spaces of H√∂lder functions
[35, 40] (Lipschitz for Œ≤ = 1) by
C0,Œ≤( ¬ØŒ©) =

u ‚ààC0( ¬ØŒ©); sup
x,y‚àà¬ØŒ©
xÃ∏=y
|u(x) ‚àíu(y)|
‚à•x ‚àíy‚à•Œ≤
< +‚àû

and
Ck,Œ≤( ¬ØŒ©) = {u ‚ààCk( ¬ØŒ©); ‚àÇŒ±u ‚ààC0,Œ≤( ¬ØŒ©) for all Œ± ‚ààNd, |Œ±| = k}.
When equipped with the norms
‚à•u‚à•Ck,Œ≤( ¬ØŒ©) = ‚à•u‚à•Ck( ¬ØŒ©) + max
|Œ±|=k

sup
x,y‚àà¬ØŒ©
xÃ∏=y
|‚àÇŒ±u(x) ‚àí‚àÇŒ±u(y)|
‚à•x ‚àíy‚à•Œ≤

,
these spaces also are Banach spaces. There are continuous injections
Ck,Œ≤( ¬ØŒ©) ‚ÜíCk,Œ≤‚Ä≤( ¬ØŒ©) ‚ÜíCk( ¬ØŒ©) ‚ÜíCk‚àí1,Œ≥ ( ¬ØŒ©)
which are compact for Œ≤‚Ä≤ < Œ≤ and Œ≥ < 1 by Ascoli‚Äôs theorem (the compactness of
the Ô¨Årst embedding requires some regularity on Œ©, see Sect.3.3). A linear mapping
f from a normed space E to a normed space F is continuous if and only if there
exists a constant C such that for all x ‚ààE, ‚à•f (x)‚à•F ‚â§C‚à•x‚à•E. In the continuous
injections above, f is just the identity, i.e., f (u) = u. A mapping is compact if it
transforms bounded sets into relatively compact sets.
The other major family of function spaces that will be useful to us is that of the
Lebesgue spaces (see for example [2, 15, 20, 51]),
L p(Œ©) =

u measurable;
	
Œ©
|u(x)|p dx < +‚àû

for 1 ‚â§p < +‚àûand
L‚àû(Œ©) =

u measurable; ess sup
Œ©
|u| < +‚àû

,
where
ess sup
Œ©
|u| = inf{M; |u| ‚â§M almost everywhere on Œ©}.
Now in these deÔ¨Ånitions, u is not strictly speaking a function, but an equivalence class
of functions that are equal almost everywhere with respect to the Lebesgue measure.
However, in practice and outside of very speciÔ¨Åc circumstances, it is harmless to

3.2 A Few Basic Function Spaces
75
think of u as just a function and not as an equivalence class. We just need to keep
this fact at the back of our mind, just in case.
When equipped with the norms
‚à•u‚à•L p(Œ©) =
	
Œ©
|u(x)|p dx
 1
p
for 1 ‚â§p < +‚àûand
‚à•u‚à•L‚àû(Œ©) = ess sup
Œ©
|u|,
the Lebesgue spaces are Banach spaces. For p = 2, the space L2(Œ©) is a Hilbert
space for the scalar product
(u|v)L2(Œ©) =
	
Œ©
u(x)v(x) dx,
see Sect.3.1 for general Hilbert space theory. H√∂lder‚Äôs inequality reads
	
Œ©
|u(x)v(x)| dx ‚â§
	
Œ©
|u(x)|p dx
 1
p 	
Œ©
|v(x)|p‚Ä≤ dx
 1
p‚Ä≤
when 1 < p, p‚Ä≤ < +‚àûare conjugate exponents, 1
p + 1
p‚Ä≤ = 1 and
	
Œ©
|u(x)v(x)| dx ‚â§(ess sup
Œ©
|u|)
	
Œ©
|v(x)| dx,
(the integrals do not need to be Ô¨Ånite). In particular, if u ‚ààL p(Œ©) and v ‚ààL p‚Ä≤(Œ©),
then uv ‚ààL1(Œ©) and

	
Œ©
u(x)v(x) dx
 ‚â§‚à•uv‚à•L1(Œ©) ‚â§‚à•u‚à•L p(Œ©)‚à•v‚à•L p‚Ä≤(Œ©).
For p = 2, we get the Cauchy‚ÄìSchwarz inequality, which is actually a Hilbert space
property as we have seen before,
|(u|v)L2(Œ©)| ‚â§‚à•u‚à•L2(Œ©)‚à•v‚à•L2(Œ©).
When Œ© is bounded, there are continuous injections Ck( ¬ØŒ©) ‚ÜíL p(Œ©) ‚Üí
Lq(Œ©) whenever q ‚â§p.1
1This is doubly false if Œ© is not bounded.

76
3
A Review of Analysis
The Lebesgue spaces admit local versions
L p
loc(Œ©) = {u; u|K ‚ààL p(K) for all compact K ‚äÇŒ©}.
These vector spaces have a natural topology which is not a normed topology.
Clearly, in view of H√∂lder‚Äôs inequality, we have L p
loc(Œ©) ‚äÇLq
loc(Œ©) whenever
q ‚â§p. In particular, the space L1
loc(Œ©) is the largest of all these spaces, and actually
the largest of all function spaces introduced up to now, which are all continuously
embedded in it.
The following result is of importance [2, 20, 51].
Proposition 3.1 Let u ‚ààL1
loc(Œ©) be such that

Œ© uœï dx = 0 for all œï ‚ààD(Œ©).
Then u = 0 almost everywhere.
Proof Note Ô¨Årst that since œï has support in a compact subset K of Œ©, so does the
product uœï. Since œï is bounded, it follows that uœï ‚ààL1(K) and the integral is
well-deÔ¨Åned.
Let x0 ‚ààŒ© and n be large enough so that B

x0, 1
n

‚äÇŒ©. It is possible to construct
a sequence œïk ‚ààD(Œ©) such that supp œïk ‚äÇB

x0, 1
n

and for all x ‚ààB

x0, 1
n

,
œïk(x) ‚Üí1 (we leave the proof as an exercise). Consequently, by the Lebesgue
dominated convergence theorem, we have
0 =
	
B(x0, 1
n)
uœïk dx ‚àí‚Üí
k‚Üí+‚àû
	
B(x0, 1
n)
u dx.
Hence, since
0 =
1
meas B

x0, 1
n

	
B(x0, 1
n)
u dx ‚àí‚Üí
n‚Üí+‚àûu(x0)
for almost all x0 by the Lebesgue points theorem, see [68], we obtain the result. ‚ñ°
Remark 3.2 Here we see at work the idea of testing a function u with a test-function
œï in order to obtain information on u. The general concept behind it is that of duality
and it will be used in much larger generality in the context of distributions and
variational formulations that we will see later on.
‚ñ°
3.3
Regularity of Open Subsets of Rd
The structure of the open subsets of Rd for the usual topology is very simple for
d = 1, since every open set is a union of an at most countable family of disjoint
open intervals. In particular, a one-dimensional connected open set is just an open
interval. The situation is more complicated in higher dimensions.
People tend to think of a connected open set of Rd as a potato-shaped object drawn
in R2. This geometrical intuition is basically correct as far as the open set itself is
concerned. It is misleading when the boundary of the open set is involved. In fact,

3.3 Regularity of Open Subsets of Rd
77
Fig. 3.3 An open set in R2 with a relatively wild boundary (imagine an inÔ¨Ånity of little spikes
pointing inward the disk)
Fig. 3.4 A zoom on the
complement of the
Mandelbrot set
the boundary of an open set in Rd, d > 1, can be more or less regular, more or less
smooth, as in Fig.3.3.
There is worse: the Mandelbrot set is compact, its complement is open with a very
convoluted boundary, see Fig.3.4.
It is even possible to construct open sets in R2 (or in Rd for any d for that matter),
the boundary of which has strictly positive Lebesgue measure, i.e., a strictly positive
area! PDE problems are posed in open subsets of Rd and we often need a certain
amount of regularity of the boundary of such open sets in order to deal with boundary
conditions.
There are several ways of quantifying the regularity of an open set boundary, or in
short the regularity of that open set. Let us give the deÔ¨Ånition that is the most adequate

78
3
A Review of Analysis
for our purposes here. Other deÔ¨Ånitions‚Äîequivalent or not‚Äîmay be encountered in
the literature [41, 44].
DeÔ¨Ånition 3.1 We say that a bounded open subset of Rd is Lipschitz (resp. of class
Ck,Œ≤) if its boundary ‚àÇŒ© can be covered by a Ô¨Ånite number of open hypercubes C j,
j = 1, . . . , m, each with an attached system of orthonormal Cartesian coordinates,
y j = (y j
1, y j
2, . . . , y j
d), in such a way that
C j = {y ‚ààRd; |y j
i | < a j for i = 1, . . . , d},
and there exists Lipschitz functions (resp. of class Ck,Œ≤) œï j : Rd‚àí1 ‚ÜíR such that
Œ© ‚à©C j = {y ‚ààC j; y j
d < œï j((y j)‚Ä≤)},
using the notation (y j)‚Ä≤ = (y j
1, y j
2, . . . , y j
d‚àí1) ‚ààRd‚àí1.
The meaning of DeÔ¨Ånition 3.1 is that locally in C j, Œ© consists of those points
located strictly below the graph of œï j, in other words, the hypograph of œï j, see
Figs.3.5 and 3.7. In particular, such an open set is situated on just one side of its
boundary, which consists of pieces of graphs, since
‚àÇŒ© ‚à©C j = {y ‚ààC j; y j
d = œï j((y j)‚Ä≤)}.
Remark 3.3 It is fairly clear that a bounded polygon is a Lipschitz open set in dimen-
sion 2. None of the wild examples of Figs.3.3 and 3.4 is of class C0,Œ≤.
Fig. 3.5 Covering the
boundary with hypercubes

3.3 Regularity of Open Subsets of Rd
79
Fig. 3.6 Simple, however
not Lipschitz
On the other hand, there are also perfectly nice open sets that are not Lipschitz
in the previous sense. We give an example in Fig.3.6, obtained by gluing together
two parallelepipeds one on top of the other, adding the open square of contact. It is
impossible to describe the resulting set as a hypograph at each vertex of that square.
The open set is nonetheless perfectly tame, it is a polyhedron.
‚ñ°
The boundary of a Lipschitz open set, and a fortiori that of an open set of class
Ck,Œ±, k ‚â•1, possesses a certain number of useful properties.
Proposition 3.2 Let Œ© be a Lipschitz open set. There exists a normal unit exterior
vector n, deÔ¨Åned almost everywhere on ‚àÇŒ©.
Normal means orthogonal to the boundary, exterior means that it points toward
the complement of Œ©. We will go back to the meaning of almost everywhere later.
Proof Let us work in C j and drop all j indices and exponents to simplify notation.
We will admit Rademacher‚Äôs theorem, a nontrivial result that says that a Lipschitz
function on Rd‚àí1 is differentiable in the classical sense, almost everywhere with
respect to the Lebesgue measure in Rd‚àí1, see [37].
Let y‚Ä≤ be a point of differentiability of œï. At this point, the differentiability implies
that the graph of œï has a tangent hyperplane generated by the d ‚àí1 vectors

80
3
A Review of Analysis
a1 =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éù
1
0
...
0
‚àÇ1œï(y‚Ä≤)
‚éû
‚éü‚éü‚éü‚éü‚éü‚é†
, a2 =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éù
0
1
...
0
‚àÇ2œï(y‚Ä≤)
‚éû
‚éü‚éü‚éü‚éü‚éü‚é†
, ¬∑ ¬∑ ¬∑ , ad‚àí1 =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éù
0
0
...
1
‚àÇd‚àí1œï(y‚Ä≤)
‚éû
‚éü‚éü‚éü‚éü‚éü‚é†
,
(for brevity we use here a slightly different notation for partial derivatives, ‚àÇiœï = ‚àÇœï
‚àÇyi ).
The orthogonal straight line is generated by the vector
N =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éù
‚àí‚àÇ1œï(y‚Ä≤)
‚àí‚àÇ2œï(y‚Ä≤)
...
‚àí‚àÇd‚àí1œï(y‚Ä≤)
1
‚éû
‚éü‚éü‚éü‚éü‚éü‚é†
.
which is clearly orthogonal to all ai. To conclude, we just need to normalize it and
notice that it points outwards due to the strictly positive last component and Œ© lying
under the graph,
n =
1

1 + ‚à•‚àáœï(y‚Ä≤)‚à•2
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éù
‚àí‚àÇ1œï(y‚Ä≤)
‚àí‚àÇ2œï(y‚Ä≤)
...
‚àí‚àÇd‚àí1œï(y‚Ä≤)
1
‚éû
‚éü‚éü‚éü‚éü‚éü‚é†
,
with ‚à•‚àáœï(y‚Ä≤)‚à•2 = d‚àí1
i=1 (‚àÇiœï(y‚Ä≤))2.
‚ñ°
Remark 3.4 It should be noted that the normal vector n is an object of purely geo-
metric nature that does not depend on the particular system of coordinates used to
compute it. In particular, if we take another admissible covering of the boundary, the
same formulas apply and compute the same vector in different coordinate systems.
This geometrically obvious remark can also be checked by direct computation in two
different coordinate systems, see Fig.3.7.
The ‚Äúalmost everywhere‚Äù is meant in the sense of the space Rd‚àí1 associated with
a local coordinate system. We give it an intrinsic meaning just below.
‚ñ°
If Œ© is a Lipschitz subset of Rd, there is a natural measure on ‚àÇŒ© that is inherited
in a sense from the Lebesgue measure in Rd, that we will call the boundary measure.
We will not go into all the detail but give a few ideas on how this measure can be
computed.
Let A ‚äÇ‚àÇŒ© be a Borel subset of ‚àÇŒ©. Since the open sets C j cover the boundary,
we can partition A with Borel sets A j ‚äÇC j. Let Œ† j be the orthogonal projection from
C j onto Rd‚àí1 according to the coordinate system associated with C j. The restriction
of the projection to the graph of œï j is a homeomorphism, therefore Œ† j(A j) is a Borel
subset of Rd‚àí1.

3.3 Regularity of Open Subsets of Rd
81
Fig. 3.7 Local aspect of the
boundary of a Lipschitz open
set and the normal unit
exterior vector
We set
Hd‚àí1(A j) =
	
Œ† j(A j)

1 + ‚à•‚àáœï j((y j)‚Ä≤)‚à•2 d(y j)‚Ä≤
and Hd‚àí1(A) =
m

j=1
Hd‚àí1(A j).
It can be checked, although it is quite tedious, that this formula does not depend
on the covering and coordinates chosen to compute it, and that it deÔ¨Ånes a Borel
measure on ‚àÇŒ©.
In the case when ‚àáœï j is constant, that is to say if the graph is portion of a hyper-
plane, it is also easy to check that the formula above gives the (d ‚àí1)-dimensional
Lebesgue measure on the hyperplane, using the same unit of length as in Rd. In this
sense, the boundary measure is inherited from Rd.
The notation Hd‚àí1 alludes to the (d‚àí1)-Hausdorff measure, a much more general
and complicated object that coincides here with our hand-crafted measure. Let us
develop an example.
In the example of Fig.3.8, Œ© is the unit square. We have Ô¨Ågured just one square
of the boundary covering, with the attached coordinate system. The part A of ‚àÇŒ©
included in it is drawn with a thicker line. It is clearly described by the function
œï(y1) = ‚àí|y1|, with y1 ‚àà]‚àí
3
2
‚àö
2,
3
2
‚àö
2[. We have œï‚Ä≤(y1) = 1 for y1 < 0 and
œï‚Ä≤(y1) = ‚àí1 for y1 > 0. Thus
H1(A) =
	
3
2
‚àö
2
‚àí
3
2
‚àö
2
‚àö
1 + 1 dy1 = 3,
which is equal to the length of the thicker line.

82
3
A Review of Analysis
Fig. 3.8 Boundary measure
example
‚àí1.5
‚àí1
‚àí0.5
0.5
1
1.5
2
2.5
3
‚àí1
‚àí0.5
0.5
1
1.5
2
2.5
0
y1
y2
More generally, for d = 2, the boundary of Œ© consists of curves and if these curves
are regular, we recognize the length of the parametric curve y1 ‚Üí(y1, œï(y1)). The
same interpretation holds for d = 3 with the area of a parametric surface.
It is now clear that the normal vector is deÔ¨Åned almost everywhere with respect to
the boundary measure. In addition, we can now deÔ¨Åne L p(‚àÇŒ©) spaces and compute
all sorts of integrals on the boundary, using this measure. In order to have a more
economical notation, we will write it dŒì in the integrals. Thus, if g is a function on
the boundary with support in C j, we have
	
‚àÇŒ©
g dŒì =
	
Œ† j(C j)
g(Œ†‚àí1
j (y‚Ä≤))

1 + ‚à•‚àáœï j((y j)‚Ä≤)‚à•2 d(y j)‚Ä≤.
The formula is extended to all functions without condition of support by a partition
of unity, see below.
3.4
Partitions of Unity
Partitions of unity [2] are a basic tool that is used in many contexts whenever the
need arises to localize a function. In what follows, Œ© will be a bounded open subset
of Rd with a Ô¨Ånite covering C j, j = 0, . . . , m, of its boundary ‚àÇŒ©.2
Let us Ô¨Årst state a few facts about convolution [15, 51]. Given two functions f
and g in L1(Rd), we deÔ¨Åne
2This particular assumption is only because this is the context in which we will use partitions of
unity here. It should be clear from the proof, that the result extends to more general covers.

3.4 Partitions of Unity
83
f ‚ãÜg(x) =
	
Rd f (x ‚àíy)g(y) dy.
The function f ‚ãÜg, which is called the convolution of f and g, is well deÔ¨Åned and
belongs to L1(Rd). If g is in addition of class C‚àûwith integrable derivatives, so is
f ‚ãÜg, with
‚àÇŒ±( f ‚ãÜg) = f ‚ãÜ‚àÇŒ±g
for all multiindices Œ±. If we take a function œÅ with support in the unit ball and integral
equal to 1 and let œÅn(x) = ndœÅ(nx), so that œÅn has support in the ball of radius 1
n
and integral also equal to 1, then we have
f ‚ãÜœÅn ‚Üíf in L p(Rd) when n ‚Üí+‚àû
as soon as f ‚ààL p(Rd), 1 ‚â§p < +‚àû[72]. If œÅ is in addition of class C‚àû, the
sequence œÅn is called a mollifying sequence or a sequence of molliÔ¨Åers [2]. Indeed,
the functions f ‚ãÜœÅn are C‚àûapproximates of f in the L p-norm.
Proposition 3.3 Let C0 be an open set such that ¬ØC0 ‚äÇŒ© and Œ© ‚äÇ‚à™m
j=0C j. There
exist m + 1 functions œà j : Rd ‚Üí[0, 1] of class C‚àûsuch that supp œà j ‚äÇ¬ØC j and
m
j=0 œà j = 1 in Œ©.
Proof Recall Ô¨Årst that for any closed set A, the function
x ‚Üíd(x, A) = inf
y‚ààA ‚à•x ‚àíy‚à•
is a continuous function from Rd into R+ that vanishes exactly on A.
We can choose Œ∑ > 0 small enough so that:
1. The sets CŒ∑
j = {x ‚ààC j; d(x, ‚àÇC j) > Œ∑} still form an open cover of Œ© in the
sense that Œ© ‚äÇ‚à™m
j=0CŒ∑
j .
2. We can take an open set CŒ∑
m+1 such that ¬ØCŒ∑
m+1 ‚äÇRd \ Œ© in order to cover the
whole of Rd = ‚à™m+1
j=0 CŒ∑
j , and such that d( ¬ØCŒ∑
m+1, ¬ØŒ©) > Œ∑).
This is possible by compactness of ¬ØŒ© but we omit the (tedious) details.
The functions
œàŒ∑
j (x) =
d(x, Rd \ CŒ∑
j )
m+1
k=0 d(x, Rd \ CŒ∑
k )
(3.1)
are continuous on Rd, indeed the denominator never vanishes because of the covering
property. They are [0, 1]-valued and œàŒ∑
j has support CŒ∑
j . Finally, it is clear that
m+1
j=0 œà j(x) = 1 on Rd, with œàŒ∑
m+1 identically zero on the set {x; d(x, ¬ØŒ©) ‚â§Œ∑}
which contains Œ©.
This family of functions has all the desired properties except that the functions
are not smooth. We thus use the convolution with a molliÔ¨Åer œÅŒ∑ with support in the
ball B(0, Œ∑). We have

84
3
A Review of Analysis
1 = 1 ‚ãÜœÅŒ∑ =
m+1

j=0
œàŒ∑
j

‚ãÜœÅŒ∑ =
m+1

j=0
(œàŒ∑
j ‚ãÜœÅŒ∑).
Each function œà j = œàŒ∑
j ‚ãÜœÅŒ∑ has support in C j for j = 0, . . . , m+1, with œàŒ∑
m+1‚ãÜœÅŒ∑ =
0 on Œ© (this is the reason why we shrank all open sets by Œ∑ in the beginning since
the convolution spreads supports by an amount Œ∑), and is of class C‚àû.
‚ñ°
Let us give an example in dimension 1, see Figs.3.9, 3.10, and 3.11, without
the Ô¨Ånal smoothing step. We take Œ© = ]0, 1[, C0 = ] 1
8, 7
8[, C1 = ]‚àí1
4, 1
4[, C2 =
] 3
4, 5
4[, C3 = ]‚àí1
8, 3
8[ and C4 = ]‚àí‚àû, 0[‚à™]1, +‚àû[. All functions can be computed
explicitly. Thus, denoting Œæ j(x) = d(x, R \ C j), we have
Œæ0(x) = min

x ‚àí1
8

+
,
7
8 ‚àíx

+

,
and so on.
We note that the set C3 is unnecessary to have a covering of Œ©. We just added
it to have a nicer picture. If we had not added it, the partition of unity would have
been piecewise afÔ¨Åne and it is a mistake to think the partitions of unity derived from
formula (3.1) are always piecewise afÔ¨Åne!
Let us also illustrate an example in dimension 2 (Figs.3.12, 3.13, 3.14, 3.15, and
3.16), Œ© is the unit disk covered by three squares of side 2.5, centered at 1, j and
j2 (identifying R2 and C) and rotated so as to form a covering of the boundary as
required. There is no C0, since the three squares already cover Œ©.
Corollary 3.1 Let Œ© be a bounded open set in Rd and u be a function on Œ©. Let
C j, j = 0, . . . , m, be an open cover as in Proposition 3.3. Then we can write
u = m
j=0 u j with supp u j ‚äÇC j and u j has the same smoothness or integrability
as u.
Fig. 3.9 The Ô¨Åve functions
Œæ j, j = 0, . . . , 4
-0,25
0
0,25
0,5
0,75
1
1,25
0,25
0,5
Fig. 3.10 Their sum, i.e.,
the denominator of (3.1),
which never vanishes
-0,25
0
0,25
0,5
0,75
1
1,25
0,25
0,5

3.4 Partitions of Unity
85
-0,5
-0,25
0
0,25
0,5
0,75
1
1,25
1,5
0,25
0,5
0,75
1
y
x
Fig. 3.11 The partition of unity œà j, j = 0, . . . , 4
Fig. 3.12 The four functions Œæ j
Fig. 3.13 Their sum
Proof We use the partition of unity œà j. Since 1 = m
j=0 œà j on Œ©, we can write
u = u √ó 1 = u
m

j=0
œà j =
m

j=0
uœà j
and set u j = uœà j. As supp œà j ‚äÇC j, it follows that u j vanishes outside of C j, and
since œà j is C‚àûand between 0 and 1, u j is as differentiable or as integrable as u
already is.
‚ñ°

86
3
A Review of Analysis
Fig. 3.14 The four functions œà j, drawn separately
Fig. 3.15 The whole
partition of unity

3.4 Partitions of Unity
87
Fig. 3.16 Checking that
œà1 + œà2 + œà3 = 1 on Œ©
It is in this sense that partitions of unity are used to localize a function u. Such a
function is decomposed into a sum of functions, each with support in a given open
set of a covering. It is often easier to work with the localized parts u j than with the
function u itself. A prime example is integration by parts in the next section.
3.5
Integration by Parts in Dimension d and Applications
Integration by parts in Rd is a basic formula, that is not often entirely proved. In
what follows, Œ© will be an at least Lipschitz open subset of Rd. The most crucial
integration by parts formula, from which all the others follow, is given in the next
Theorem.
Theorem 3.4 Let Œ© be a Lipschitz open set in Rd and u ‚ààC1( ¬ØŒ©). Then we have
	
Œ©
‚àÇu
‚àÇxi
dx =
	
‚àÇŒ©
uni dŒì,
(3.2)
where ni is the ith component of the normal unit exterior vector.
Proof We will only write the proof in dimension d = 2, which is not a real restriction
as the general case d ‚â•2 follows from exactly the same arguments, and only in the
case when Œ© is of class C1. This is a real restriction: there are additional technical
difÔ¨Åculties in the Lipschitz case due to only almost everywhere differentiability.
We start with the partition of unity associated with the given covering C j of the
boundary completed by an open set C0 to cover the interior. We have u = m
j=0 u j
with u j = uœà j, and each u j belongs to C1( ¬ØŒ©) and has support in ¬ØC j. Consequently,
since formula (3.2) is linear with respect to u, it is sufÔ¨Åcient to prove it for each u j.
Let us start with the case j = 0. In this case, u0 is compactly supported in Œ©
since ¬ØC0 ‚äÇŒ©. In particular, it vanishes on ‚àÇŒ©, so that

‚àÇŒ© u0ni dŒì = 0.

88
3
A Review of Analysis
We extend u0 by 0 to R2, thus yielding a C1(R2) function Àúu0. Since Œ© is bounded,
we choose a square that contains it, Œ© ‚äÇQ = ]‚àíM, M[2, for some M. Lettingi‚Ä≤ = 1
if i = 2, i‚Ä≤ = 2 if i = 1, we obtain
	
Œ©
‚àÇu0
‚àÇxi
dx =
	
Q
‚àÇÀúu0
‚àÇxi
dx =
	 M
‚àíM
	 M
‚àíM
‚àÇÀúu0
‚àÇxi
dxi

dxi‚Ä≤ =
	 M
‚àíM
[Àúu0]xi=M
xi=‚àíMdxi‚Ä≤ = 0,
by Fubini‚Äôs theorem and the fact that Àúu0 = 0 sur ‚àÇQ. Formula (3.2) is thus established
for u0.
The case j > 0 is a little more complicated. To simplify the notation, we omit all
j indices and exponents. We thus have a function u with support in ¬ØC. In particular,
u = 0 on ‚àÇC ‚à©¬ØŒ©. We have
Œ© ‚à©C = {y ‚ààC; y2 < œï(y1)},
see also Fig.3.7. We Ô¨Årst establish formula (3.2) in the (y1, y2) coordinate system
in which C = ]‚àía, a[2 for some a. We let ny,i, i = 1, 2, denote the components of
the normal vector in this coordinate system. There are two different computations
depending on the coordinate under consideration.
Case i = 1. We Ô¨Årst use Fubini‚Äôs theorem
	
Œ©
‚àÇu
‚àÇy1
dy =
	 a
‚àía
	 œï(y1)
‚àía
‚àÇu
‚àÇy1
(y1, y2) dy2

dy1,
see again Fig.3.7. Now it is well-known from elementary calculus that
d
dy1
	 œï(y1)
‚àía
u(y1, y2) dy2

=
	 œï(y1)
‚àía
‚àÇu
‚àÇy1
(y1, y2) dy2 + u(y1, œï(y1))œï‚Ä≤(y1),
(this is where the fact that œï is C1 intervenes and where it would be a little harder to
have œï only Lipschitz). Consequently,
	
Œ©
‚àÇu
‚àÇy1
dy =
	 a
‚àía
d
dy1
	 œï(y1)
‚àía
u(y1, y2) dy2

dy1 ‚àí
	 a
‚àía
u(y1, œï(y1))œï‚Ä≤(y1) dy1.
In the Ô¨Årst integral, we integrate a derivative, so that
	 a
‚àía
d
dy1
	 œï(y1)
‚àía
u(y1, y2) dy2

dy1
=
	 œï(a)
‚àía
u(a, y2) dy2 ‚àí
	 œï(‚àía)
‚àía
u(‚àía, y2) dy2 = 0,

3.5 Integration by Parts in Dimension d and Applications
89
since u = 0 on ‚àÇC. We thus see that
	
Œ©
‚àÇu
‚àÇy1
dy =
	 a
‚àía
u(y1, œï(y1))
‚àíœï‚Ä≤(y1)

1 + œï‚Ä≤(y1)2

1 + œï‚Ä≤(y1)2 dy1
=
	 a
‚àía
u(y1, œï(y1))ny,1(y1)

1 + œï‚Ä≤(y1)2 dy1
=
	
C‚à©‚àÇŒ©
uny,1 dŒì,
by the formulas established in Sect.3.3 for the normal vector components and the
boundary measure. Hence formula (3.2) in this case.
Case i = 2. We start again with Fubini‚Äôs theorem
	
Œ©
‚àÇu
‚àÇy2
dy =
	 a
‚àía
	 œï(y1)
‚àía
‚àÇu
‚àÇy2
(y1, y2) dy2

dy1
=
	 a
‚àía
u(y1, œï(y1)) dy1
=
	 a
‚àía
u(y1, œï(y1))
1

1 + œï‚Ä≤(y1)2

1 + œï‚Ä≤(y1)2 dy1
=
	
C‚à©‚àÇŒ©
uny,2 dŒì,
since u(y1, ‚àía) = 0. This proves the integration by parts formula in the (y1, y2)
system attached to the cube C covering a part of the boundary.
We need to go back to the original coordinate system (x1, x2). Let us write the
change of coordinates formulas
y1
y2

= R
x1 ‚àíc1
x2 ‚àíc2

or again
x1
x2

= RT
y1
y2

+
c1
c2

,
where R is an orthogonal matrix and (c1, c2) are the (x1, x2) coordinates of the center
of C. Similarly, if vx and vy denote the column-vectors of the components of the same
vector v ‚ààR2 in each of the coordinate systems, we have
vy = Rvx ‚áê‚áívx = RT vy.
This is true in particular for the normal vecteur n, nx = RT ny. Let us note ‚àáxu and
‚àáyu the components of the gradient of u in the two coordinate systems, we see by
the chain rule that
(‚àáxu)i = ‚àÇu
‚àÇxi
=
2

j=1
‚àÇu
‚àÇy j
‚àÇy j
‚àÇxi
=
2

j=1
R ji
‚àÇu
‚àÇy j
= (RT ‚àáyu)i,

90
3
A Review of Analysis
hence the result for the localized part of the function, by linearity of the integrals,
and then for the whole function again by linearity of the integrals.
‚ñ°
Once the basic formula is available, many other formulas are easily derived, that
bear various names in the literature. We give below a short selection of such formulas
that will be useful in the sequel. We do not specify the regularity of the functions
below, it is understood that they are sufÔ¨Åciently differentiable for all derivatives and
integrals to make sense.
Corollary 3.2 Let Œ© be a Lipschitz open set in Rd. We have
(i) Integration by parts strictly speaking
	
Œ©
‚àÇu
‚àÇxi
v dx = ‚àí
	
Œ©
u ‚àÇv
‚àÇxi
dx +
	
‚àÇŒ©
uvni dŒì,
(3.3)
(ii) Green‚Äôs formula
	
Œ©
(Œîu)v dx = ‚àí
	
Œ©
‚àáu ¬∑ ‚àáv dx +
	
‚àÇŒ©
‚àÇu
‚àÇn v dŒì,
(3.4)
where ‚àÇu
‚àÇn = ‚àáu ¬∑ n = d
i=1
‚àÇu
‚àÇxi ni denotes the normal derivative of u on ‚àÇŒ©.
(iii) A slightly more symmetrical version of Green‚Äôs formula
	
Œ©
(Œîu)v dx =
	
Œ©
u(Œîv) dx +
	
‚àÇŒ©
‚àÇu
‚àÇn v ‚àíu ‚àÇv
‚àÇn

dŒì,
(3.5)
(iv) Stokes formula
	
Œ©
div U dx =
	
‚àÇŒ©
U ¬∑ n dŒì,
(3.6)
where U : Œ© ‚ÜíRd is a vector Ô¨Åeld, its divergence is div U = d
i=1
‚àÇUi
‚àÇxi and
U ¬∑ n = d
i=1 Uini is the Ô¨Çux of the vector Ô¨Åeld through the boundary of Œ©.
Proof For (i), we apply the basic formula (3.2) to the product uv, and so on.
‚ñ°
3.6
Distributions
In this section, Œ© is an arbitrary open subset of Rd.
It turns out that functions that are differentiable in the classical sense are not
sufÔ¨Åcient to work with PDEs. A more general concept is needed, which is called
distributions [72, 73]. As we will see, distributions are a lot more general than
functions. They can always be differentiated indeÔ¨Ånitely, even when they correspond
to functions that are not differentiable in the classical sense, and their derivatives
are distributions. This is why distributional solutions to linear PDEs of arbitrary

3.6 Distributions
91
order make sense (with technical conditions on their coefÔ¨Åcients). We will also use
distributions to deÔ¨Åne an important class of function spaces for PDEs, the Sobolev
spaces.
Let us Ô¨Årst go back to the space D(Œ©) of indeÔ¨Ånitely differentiable functions with
compact support encountered in Sect.3.2. It is trivial, but crucial for the sequel, that
the space D(Œ©) is stable by differentiation of arbitrary order, i.e., if œï ‚ààD(Œ©) then
‚àÇŒ±œï ‚ààD(Œ©) for any multiindex Œ±.
The function œï(x) = e
1
‚à•x‚à•2‚àí1 for ‚à•x‚à•< 1, œï(x) = 0 otherwise, belongs to D(Rd).
It can be scaled to deÔ¨Åne a molliÔ¨Åer and thus construct inÔ¨Ånitely many functions in
D(Rd) by convolution. Let us notice that if Œ© contains the unit closed ball, then
the restriction of œï to Œ© belongs to D(Œ©). Conversely, it is quite clear that given a
function in D(Œ©) for any Œ©, by extending it by 0 to Rd \ Œ© we obtain a function in
D(Rd). In this sense, it can be said that a function of D(Œ©) vanishes on the boundary
of Œ©, even though it is a priori only deÔ¨Åned on Œ©.
As mentioned before, the vector space D(Œ©) has a natural topology that is a little
difÔ¨Åcult to understand (technically, it is an LF-space, a strict inductive limit of a
sequence of Fr√©chet spaces and it is not metrizable, see [13]) and it is not very useful
to master the details of this topology for the applications we have in mind. So we
will just skip it.
The convergence of a sequence in D(Œ©) for its natural topology is given by the
following proposition, which we admit, see [72, 73, 78, 80].
Proposition 3.4 A sequence œïn ‚ààD(Œ©) converges to œï ‚ààD(Œ©) in the sense of
D(Œ©) if and only if
(i) There exists a compact subset K of Œ© such that supp œïn ‚äÇK for all n.
(ii) For all Œ± ‚ààNd, ‚àÇŒ±œïn ‚Üí‚àÇŒ±œï uniformly.
It follows clearly from the above proposition that if œïn ‚Üíœï in the sense of D(Œ©),
then ‚àÇŒ±œïn ‚Üí‚àÇŒ±œï in the sense of D(Œ©) for all Œ± ‚ààNd. In addition, it is easy to see
that D(Œ©) ‚äÇL p(Œ©) for all p ‚àà[1, +‚àû] and that if œïn ‚Üíœï in the sense of D(Œ©),
then œïn ‚Üíœï in L p(Œ©).
When a real (or complex) vector space is equipped with a topology that makes its
vector space operations continuous, that is when it is a topological vector space, it
makes sense to look at the vector space of continuous linear forms, that is the space of
real (or complex) valued linear mappings that are continuous for the aforementioned
topology. This space is called the topological dual, or in short dual space.
DeÔ¨Ånition 3.2 The space of distributions on Œ©, D‚Ä≤(Œ©), is the dual of the space
D(Œ©).
We will indifferently use the notations T (œï) = ‚ü®T, œï‚ü©to denote the value of
a distribution T on a test-function œï and the duality pairing between the two. Of
course, since D‚Ä≤(Œ©) is a vector space, we can add distributions and multiply them
by a scalar in the obvious way.
Now, not knowing the topology of D(Œ©) makes it a little difÔ¨Åcult to decide which
linear forms on D(Œ©) are continuous and which are not. Fortunately, even though

92
3
A Review of Analysis
the topology in question is not metrizable, the usual sequential criterion happens to
still work in this particular case. We admit the following proposition, see [72, 73, 78,
80].
Proposition 3.5 A linear form T on D(Œ©) is a distribution if and only if we have
T (œïn) ‚Üí0 for all sequences œïn ‚ààD(Œ©) such that œïn ‚Üí0 in the sense of D(Œ©).
Remark 3.5 Let us note that the property T (œïn) ‚Üí0 for all sequences œïn ‚ààD(Œ©)
such that œïn ‚Üí0 immediately implies that T (œïn) ‚ÜíT (œï) for all sequences œïn such
that œïn ‚Üíœï in the sense of D(Œ©), by linearity, hence the sequential continuity of the
linear form T . The difÔ¨Åculty is that in a non metrizable topological space, sequential
continuity does not imply continuity in general, even though, in this particular case,
it does.
‚ñ°
Let us now see in which sense distributions generalize the usual notion of function.
Proposition 3.6 For all f ‚ààL1
loc(Œ©) there exists a distribution ƒ±( f ) on Œ© deÔ¨Åned
by the formula
‚ü®ƒ±( f ), œï‚ü©=
	
Œ©
f œï dx
for all œï ‚ààD(Œ©). The mapping ƒ± : L1
loc(Œ©) ‚ÜíD‚Ä≤(Œ©) is one-to-one.
Proof That the integral is well-deÔ¨Åned has already been seen. It clearly deÔ¨Ånes a
linear form on D(Œ©) by the linearity of the integral. What remains to be established
for ƒ±( f ) to be a distribution, is its continuity. Let us thus be given a sequence œïn ‚Üí0
in the sense of D(Œ©), and K the associated compact set. We have
|‚ü®ƒ±( f ), œïn‚ü©| =

	
Œ©
f œïn dx
 =

	
K
f œïn dx

‚â§
	
K
| f ||œïn| dx ‚â§max
K |œïn|
	
K
| f | dx ‚Üí0
since f|K ‚ààL1(K) and œïn tends to 0 uniformly on K.
Let us now show that the mapping ƒ± is one-to-one. Since it is clearly linear, it
sufÔ¨Åces to show that its kernel is reduced to the zero vector. Let f ‚ààker ƒ±, which
means that ƒ±( f ) is the zero linear form, or in other words that

Œ© f œï dx = 0 for
all œï in D(Œ©). By Proposition 3.1, it follows that we have f = 0, and the proof is
complete.
‚ñ°
Remark 3.6 The characterization of convergence in D(Œ©) of Proposition 3.4 is
implied by the topology of D(Œ©). In the proof of Proposition 3.6, we can see the
importance of having a Ô¨Åxed compact K containing all the supports. If it was not the
case, the Ô¨Ånal estimate would break down.
‚ñ°
Remark 3.7 The mapping ƒ± is not only one-to-one, it is also continuous (for the
topology of D‚Ä≤(Œ©) as topological dual of D(Œ©), which we also keep shrouded

3.6 Distributions
93
in mystery). The mapping ƒ± thus provides a faithful representation of one type of
objects, L1
loc functions, as objects of a completely different nature, distributions. It is
so faithful that in day-to-day practice, we say that an L1
loc function f is a distribution
and dispense with the notation ƒ± altogether, that is we just write ‚ü®f, œï‚ü©for the duality
bracket.
Conversely, when a distribution T belongs to the image of ƒ±, that is to say when
there exists f in L1
loc such that ‚ü®T, œï‚ü©=

Œ© f œï dx for all œï in D(Œ©), we just say
that T is a function and we write T = f . Beware however that most distributions
are not functions and that the notation

Œ© T œï dx is unacceptable for any distribution
that is not in the range of the mapping ƒ±.
Proposition 3.6 is all the more important as it shows that the elements of all the
function spaces introduced up to now actually are distributions, since L1
loc(Œ©) is the
largest of all such spaces.
‚ñ°
Proposition 3.6 gives us our Ô¨Årst examples of distributions. There are however
many others which are not functions. Let us describe a couple of them.
We choose a point a ‚ààŒ© and deÔ¨Åne
‚ü®Œ¥a, œï‚ü©= œï(a)
for all œï ‚ààD(Œ©). This is clearly a linear form on D(Œ©) and we just need to check
its continuity. Let us thus be given again a sequence œïn ‚Üí0 in the sense of D(Œ©).
In particular, there exists a compact subset K on which it converges uniformly to 0,
and out of which is identically 0. Therefore, the sequence converges uniformly on Œ©,
hence pointwise. Thus œïn(a) ‚Üí0 and we are done: Œ¥a ‚ààD‚Ä≤(Œ©). This distribution
is called the Dirac mass or Dirac distribution at point a. When a = 0, it is often
simply denoted Œ¥. The Dirac mass does not belong to the image of ƒ±, i.e., loosely
speaking, it is not a function.
Let us quickly show this in the case d = 1. Assume that there exists a function
f ‚ààL1
loc(R) such that, for all œï ‚ààD(R), we have
	
R
f (x)œï(x) dx = œï(0).
Letting g(x) = x f (x), we have g ‚ààL1
loc(R), and we see that for all œï ‚ààD(R),
	
R
g(x)œï(x) dx =
	
R
x f (x)œï(x) dx =
	
R
f (x)(xœï(x)) dx = 0
since x ‚Üíxœï(x) belongs to D(R) and vanishes at x = 0. This implies that g = 0
by Proposition 3.1, and therefore f = 0, which is a contradiction since Œ¥ Ã∏= 0.
Let us give a second example with Œ© = R. The function x ‚Üí1/x almost
everywhere is not in L1
loc(R) because it is not integrable in a neighborhood of 0.
Therefore, it cannot be identiÔ¨Åed with a distribution as in Proposition 3.6, which
is rather unfortunate for such a simple function and a concept claiming to widely

94
3
A Review of Analysis
generalize functions. The distribution deÔ¨Åned by

vp 1
x , œï

= lim
Œµ‚Üí0+
	 ‚àíŒµ
‚àí‚àû
œï(x)
x
dx +
	 +‚àû
Œµ
œï(x)
x
dx

is called the principal value of 1/x and replaces the function x ‚Üí1/x for all intents
and purposes (exercise: show that it is a distribution). It is however not a function.
We have hinted at a topology on the space of distributions. Here again, it is not
too important to know the details of this topology. The convergence of sequences is
more than enough and is surprisingly simple. We admit the following result, see [72,
73, 78, 80], which can actually be taken as a deÔ¨Ånition.
Proposition 3.7 A sequence Tn ‚ààD‚Ä≤(Œ©) converges to T ‚ààD‚Ä≤(Œ©) in the sense of
D‚Ä≤(Œ©) if and only if ‚ü®Tn, œï‚ü©‚Üí‚ü®T, œï‚ü©for all œï ‚ààD(Œ©).
Since distributions are linear forms on the space D(Œ©), we see that convergence
in the sense of distributions is actually nothing but simple or pointwise convergence
on D(Œ©). This makes it very easy to handle (and unfortunately, very easy to abuse.
Remember, it is not magic!).
This notion of convergence agrees with all previous notions deÔ¨Åned on smaller
function spaces. In particular, we have
Proposition 3.8 Let un ‚Üíu in L p(Œ©) for some p ‚àà[1, +‚àû]. Then un ‚Üíu in the
sense of D‚Ä≤(Œ©).
Proof For all œï ‚ààD(Œ©), we have
|‚ü®un, œï‚ü©‚àí‚ü®u, œï‚ü©| ‚â§
	
Œ©
|un ‚àíu||œï| dx ‚â§‚à•un ‚àíu‚à•L p(Œ©)‚à•œï‚à•L p‚Ä≤(Œ©) ‚Üí0
by H√∂lder‚Äôs inequality.
‚ñ°
We have said earlier that distributions can be differentiated indeÔ¨Ånitely, however
in a speciÔ¨Åc sense.
DeÔ¨Ånition 3.3 Let T be a distribution on Œ©. The formula
‚ü®S, œï‚ü©= ‚àí

T, ‚àÇœï
‚àÇxi

,
(3.7)
for all œï ‚ààD(Œ©), deÔ¨Ånes a distribution S, which is called the (distributional) partial
derivative of T with respect to xi and is denoted ‚àÇT
‚àÇxi .
Proof This deÔ¨Ånition needs a proof. Formula (3.7) clearly deÔ¨Ånes a linear form on
D(Œ©). Let us see that it is continuous. Let us be given a sequence œïn ‚Üí0 in D(Œ©).
It is apparent that ‚àÇœïn
‚àÇxi ‚Üí0 in D(Œ©). Indeed, the support condition is the same, since
the support of the partial derivative of a function is included in the support of this

3.6 Distributions
95
function, and the uniform convergence of all derivatives trivially holds true as all
derivatives of ‚àÇœïn
‚àÇxi are derivatives of œïn. Therefore,
‚ü®S, œïn‚ü©= ‚àí

T, ‚àÇœïn
‚àÇxi

‚Üí0
for all sequences œïn ‚Üí0 in D(Œ©).
‚ñ°
For example, the derivative of the Dirac mass Œ¥ in dimension one is the distribution
‚ü®Œ¥‚Ä≤, œï‚ü©= ‚àí‚ü®Œ¥, œï‚Ä≤‚ü©= ‚àíœï‚Ä≤(0),
for all œï ‚ààD(R).
The reason why it is reasonable to call this new distribution a partial derivative is
in the next proposition.
Proposition 3.9 Let u be a function in C1(Œ©). Then its distributional partial deriv-
atives coincide with its classical partial derivatives.
Proof Let œï ‚ààD(Œ©). The support K of uœï is bounded and we can include it in a
hypercube C. We deÔ¨Åne v on C by v(x) = u(x)œï(x) if x ‚ààK, v(x) = 0 otherwise.
It is easy to check that v ‚ààC1( ¬ØC) and v = 0 on ‚àÇC. Since C is a Lipschitz open set,
we can apply the integration by parts formula (3.3)3 and obtain
	
K
‚àÇv
‚àÇxi
dx =
	
C
‚àÇv
‚àÇxi
dx = 0.
Now, on K, we have ‚àÇv
‚àÇxi = u ‚àÇœï
‚àÇxi + ‚àÇu
‚àÇxi œï, so that
	
Œ©
‚àÇu
‚àÇxi
œï dx =
	
K
‚àÇu
‚àÇxi
œï dx = ‚àí
	
K
u ‚àÇœï
‚àÇxi
dx = ‚àí
	
Œ©
u ‚àÇœï
‚àÇxi
dx,
since all intervening integrands are zero outside of K, which completes the proof by
using Proposition 3.6.
‚ñ°
Remark 3.8 Be careful that the same result is false for functions that are only almost
everywhere differentiable. Let us show an example, which is also a showcase example
of how to compute a distributional derivative. Let H be the Heaviside function deÔ¨Åned
on R by H(x) = 0 for x ‚â§0, H(x) = 1 for x > 0. This function is classically
differentiable with zero derivative for x Ã∏= 0 and has a discontinuity of the Ô¨Årst
kind at x = 0. It is also in L‚àû(R), hence in L1
loc(R), hence a distribution. Let us
compute its distributional derivative. Take œï ‚ààD(R) and let R > 0 be such that
supp œï ‚äÇ[‚àíR, R]. We have
3Note that there is no regularity or boundedness hypothesis made on Œ© itself.

96
3
A Review of Analysis
‚ü®H ‚Ä≤, œï‚ü©= ‚àí‚ü®H, œï‚Ä≤‚ü©= ‚àí
	 R
0
œï‚Ä≤(s) ds = œï(0) ‚àíœï(R) = œï(0),
since œï and œï‚Ä≤ vanish for x ‚â•R. Therefore we see that
H ‚Ä≤ = Œ¥
even though the almost everywhere classical derivative of H is 0. This is an example
of a function that is not differentiable in the classical sense, but that is also a distrib-
ution, hence has a distributional derivative and this derivative is not a function. The
example also shows that H is a distributional primitive of the Dirac mass.
‚ñ°
Once a distribution is known to have partial derivatives of order one which are
again distributions, it is obvious that the same operation can be repeated indeÔ¨Ånitely
and we have, for any distribution T and any multiindex Œ±,
‚ü®‚àÇŒ±T, œï‚ü©= (‚àí1)|Œ±|‚ü®T, ‚àÇŒ±œï‚ü©
for all œï ‚ààD(Œ©), by induction on the length of Œ±.
Differentiation in the sense of distributions is continuous, which is violently false
in most function spaces. We just show here the sequential continuity, which is amply
sufÔ¨Åcient for the applications.
Proposition 3.10 Let Tn ‚ÜíT in the sense of D‚Ä≤(Œ©). Then, for all multiindices Œ±,
we have ‚àÇŒ±Tn ‚Üí‚àÇŒ±T in the sense of D‚Ä≤(Œ©).
Proof For all œï ‚ààD(Œ©), we have
‚ü®‚àÇŒ±Tn, œï‚ü©= (‚àí1)|Œ±|‚ü®Tn, ‚àÇŒ±œï‚ü©‚Üí(‚àí1)|Œ±|‚ü®T, ‚àÇŒ±œï‚ü©= ‚ü®‚àÇŒ±T, œï‚ü©,
hence the result.
‚ñ°
This continuity provides another reason why the partial derivative terminology is
adequate for distributions. Indeed, it can be shown that C‚àû(Œ©) functions are dense in
D‚Ä≤(Œ©). For any distribution T , there exists a sequence of indeÔ¨Ånitely differentiable
functions œàn that tends to T in the sense of distributions. Therefore, their distribu-
tional partial derivatives of arbitrary order, which coincide with their classical partial
derivatives, also converge in the sense of distributions. So the distributional partial
derivatives of a distribution appear as distributional limits of approximating classical
partial derivatives.
Many other operations usually performed on functions can be extended to distrib-
utions using the same transposition trick as for partial derivatives. Let us just mention
here the multiplication by a smooth function.
DeÔ¨Ånition 3.4 Let T be a distribution on Œ© and f ‚ààC‚àû(Œ©). The formula
‚ü®f T, œï‚ü©= ‚ü®T, f œï‚ü©,

3.6 Distributions
97
for all œï ‚ààD(Œ©), deÔ¨Ånes a distribution.
We leave the easy proof as an exercise. Of course, when T ‚ààL1
loc(Œ©), f T coin-
cides with the classical pointwise product and the mapping T ‚Üíf T is sequentially
continuous on D‚Ä≤(Œ©). Note that it is not possible to deÔ¨Åne such a product in all gen-
erality by a function that is less smooth than C‚àû. In particular, there is no product
of two distributions with the reasonable properties to be expected from a product‚Äîa
famous theorem by L. Schwartz that limits the usefulness of general distributions in
dealing with nonlinear PDEs.
The partial derivatives of a distribution multiplied by a smooth function follow
the classical Leibniz rule.
Proposition 3.11 Let T beadistributiononŒ© and f ‚ààC‚àû(Œ©).Forallmultiindices
Œ± such that |Œ±| = 1, we have
‚àÇŒ±( f T ) = f ‚àÇŒ±T + ‚àÇŒ±f T.
(3.8)
Proof We just use the deÔ¨Ånitions. For all œï ‚ààD(Œ©), we have
‚ü®‚àÇŒ±( f T ), œï‚ü©= ‚àí‚ü®f T, ‚àÇŒ±œï‚ü©= ‚àí‚ü®T, f ‚àÇŒ±œï‚ü©= ‚àí‚ü®T, ‚àÇŒ±( f œï)‚ü©+ ‚ü®T, ‚àÇŒ±f œï‚ü©
= ‚ü®‚àÇŒ±T, f œï‚ü©+ ‚ü®‚àÇŒ±f T, œï‚ü©= ‚ü®f ‚àÇŒ±T, œï‚ü©+ ‚ü®‚àÇŒ±f T, œï‚ü©
= ‚ü®f ‚àÇŒ±T + ‚àÇŒ±f T, œï‚ü©
by the Leibniz formula for smooth functions.
‚ñ°
We conclude this very brief review of distribution theory with the following result
[2, 51].
Proposition 3.12 Let Œ© be a connected open set of Rd and T a distribution on Œ©
such that ‚àÇT
‚àÇxi = 0 for i = 1, . . . , d. Then, there exists a constant c ‚ààR such that
T = c.
Proof We write the proof in the case Œ© = Rd. The general case follows by a localiza-
tion argument. First of all, we claim that if œï ‚ààD(Rd) is such that

Rd œï(x) dx = 0,
then there exists œïi ‚ààD(Rd), i = 1, . . . , d, such that
œï =
d

i=1
‚àÇœïi
‚àÇxi
.
(3.9)
The proof of the claim is by induction on the dimension d. For d = 1, the result
holds true by taking œï1(x1) =

 x1
‚àí‚àûœï(s) ds, which is clearly C‚àû. In addition, it is
compactly supported. Indeed, let a < b be such that supp œï ‚äÇ[a, b]. If x1 < a,
we have œï1(x1) = 0 obviously, since the integrand vanishes. If x1 > b, we have
0 =

 +‚àû
‚àí‚àûœï(s) ds = œï1(x1) +

 +‚àû
x1
œï(s) ds = œï1(x1) as well.
Assume now that decomposition (3.9) has been established for d ‚àí1. Let œï be
such that

Rd œï(x) dx = 0. We set œà(x‚Ä≤) =

 +‚àû
‚àí‚àûœï(x‚Ä≤, s) ds, so that œà ‚ààD(Rd‚àí1).
We have

98
3
A Review of Analysis
	
Rd‚àí1 œà(x‚Ä≤) dx‚Ä≤ =
	
Rd œï(x) dx = 0
by Fubini‚Äôs theorem.
Let now a < b be such that supp œï ‚äÇRd‚àí1√ó[a, b]. We pick a function Œ∏ ‚ààD(R)
such that supp Œ∏ ‚äÇ[a, b] and

 +‚àû
‚àí‚àûŒ∏(s) ds = 1. Then we let
œïd(x‚Ä≤, xd) =
	 xd
‚àí‚àû
œï(x‚Ä≤, s) ds ‚àíœà(x‚Ä≤)
	 xd
‚àí‚àû
Œ∏(s) ds.
It is also clear that œïd is C‚àû. Let us check that œïd is compactly supported. The
variables x‚Ä≤ pose no problem in this regard, so we just have to see what happens
with respect to the variable xd. For xd < a, again obviously œïd(x‚Ä≤, xd) = 0. For
xd > b, we have on the one hand

 xd
‚àí‚àûœï(x‚Ä≤, s) ds = œà(x‚Ä≤) and on the other hand

 xd
‚àí‚àûŒ∏(s) ds = 1, thus œïd(x‚Ä≤, xd) = 0. This shows that œïd ‚ààD(Rd). Now, by
deÔ¨Ånition,
‚àÇœïd
‚àÇxd
(x‚Ä≤, xd) = œï(x‚Ä≤, xd) ‚àíœà(x‚Ä≤)Œ∏(xd),
so that
œï(x‚Ä≤, xd) = œà(x‚Ä≤)Œ∏(xd) + ‚àÇœïd
‚àÇxd
(x‚Ä≤, xd).
The induction hypothesis applies to œà, thus proving claim (3.9).
Let us now consider a distribution T whose derivatives vanish. Let us pick a
function Œò ‚ààD(Rd) such that

Rd Œò(x) dx = 1 and for all œï ‚ààD(Rd), let us set
Œ¶(x) = œï(x) ‚àí
	
Rd œï(y) dy

Œò(x).
Clearly,

Rd Œ¶(x) dx = 0, so we can apply decomposition (3.9) to Œ¶ and write
œï ‚àí
	
Rd œï(y) dy

Œò =
d

i=1
‚àÇŒ¶i
‚àÇxi
,
so that
œï =
	
Rd œï(y) dy

Œò +
d

i=1
‚àÇŒ¶i
‚àÇxi
.

3.6 Distributions
99
It follows that
‚ü®T, œï‚ü©=
	
Rd œï(y) dy

‚ü®T, Œò‚ü©+
d

i=1

T, ‚àÇŒ¶i
‚àÇxi

=
	
Rd œï(y) dy

‚ü®T, Œò‚ü©‚àí
d

i=1
 ‚àÇT
‚àÇxi
, Œ¶i

=
	
Rd cœï(y) dy,
where we have set c = ‚ü®T, Œò‚ü©. This shows that T is identiÔ¨Åed with the L1
loc(Rd)
function y ‚Üíc, which happens to be a constant function.
‚ñ°
This proposition states that distributions behave the same as functions when their
gradient vanishes. There is nothing exotic added in this respect when generalizing
from functions to distributions. In particular, such a T is a function in the sense of
Proposition 3.6 which is equal to the constant c almost everywhere.
3.7
Sobolev Spaces
In this section, Œ© is an arbitrary open subset of Rd, unless otherwise speciÔ¨Åed. We
now introduce and brieÔ¨Çy study an important class of function spaces for PDEs, the
Sobolev spaces. As we have seen, every function in L p(Œ©) is actually a distribution,
therefore it has distributional partial derivatives. In general, these derivatives are not
functions, of course. There are however some functions whose distributional deriv-
ative also are functions, even though they may not be differentiable in the classical
sense. These are the functions we are going to be interested in.
DeÔ¨Ånition 3.5 Let m ‚ààN and p ‚àà[1, +‚àû]. We deÔ¨Åne the Sobolev space
W m,p(Œ©) = {u ‚ààL p(Œ©); ‚àÇŒ±u ‚ààL p(Œ©)
for all
Œ±
such that
|Œ±| ‚â§m}.
When p = 2, we use the notation W m,2(Œ©) = H m(Œ©).
Note the special case m = 0, where W 0,p(Œ©) = L p(Œ©) and H 0(Œ©) = L2(Œ©).
So the notation is hardly ever used for m = 0. In this book, we will mainly use the
H m(Œ©) spaces, with special emphasis on H 1(Œ©). The natural Sobolev norms are as
follows
‚à•u‚à•W m,p(Œ©) =
 
|Œ±|‚â§m
‚à•‚àÇŒ±u‚à•p
L p(Œ©)
 1
p

100
3
A Review of Analysis
for p < +‚àûand
‚à•u‚à•W m,‚àû(Œ©) = max
|Œ±|‚â§m ‚à•‚àÇŒ±u‚à•L‚àû(Œ©).
In particular, for p = 2, we have
‚à•u‚à•H m(Œ©) =
 
|Œ±|‚â§m
‚à•‚àÇŒ±u‚à•2
L2(Œ©)
 1
2 .
This latter norm is clearly a prehilbertian norm associated with the scalar product
(u|v)H m(Œ©) =

|Œ±|‚â§m
(‚àÇŒ±u|‚àÇŒ±u)L2(Œ©).
The notations ‚à•u‚à•m,p and ‚à•u‚à•m for the W m,p and H m norms are also encountered
in the literature if the context is clear.
Remark 3.9 It follows from the deÔ¨Ånition that W m+1,p(Œ©) ‚äÇW m,p(Œ©) for all m, p.
Moreover, if Œ© is bounded W m,p(Œ©) ‚äÇW m,q(Œ©) whenever q ‚â§p. Also if Œ© is
bounded, we have Cm( ¬ØŒ©) ‚äÇW m,p(Œ©). If Œ© is Lipschitz, we have in addition that
Cm( ¬ØŒ©) is dense in W m,p(Œ©) (we will prove it later on for m = 1, p = 2). We also
refer for example to [2, 25, 35, 40, 61] for other density results in W m,p(Œ©). Of
course, there are functions in W m,p(Œ©) that are not of class Cm. For example, the
function x ‚Üíx+ = max(x, 0) is in H 1(]‚àí1, 1[) since (x+)‚Ä≤ = H|]‚àí1,1[ in the sense
of D‚Ä≤ (exercise), but it is not differentiable in the classical sense at x = 0.
Similarly, there are functions in L p that are not in W 1,p, such as the Heaviside
function H whose derivative is Œ¥, which is not a function.
‚ñ°
Theorem 3.5 The spaces W m,p(Œ©) are Banach spaces. In particular, the spaces
H m(Œ©) are Hilbert spaces.
Proof We need to show that W m,p(Œ©) is complete for its norm. Let us thus be given
a Cauchy sequence (un)n‚ààN in W m,p(Œ©). In view of the deÔ¨Ånition of the norm, it
follows that for each multiindex Œ±, |Œ±| ‚â§m, the sequence of partial derivatives ‚àÇŒ±un
is a Cauchy sequence in L p(Œ©). We know that L p(Œ©) is complete, therefore there
exists gŒ± ‚ààL p(Œ©) such that ‚àÇŒ±un ‚ÜígŒ± in L p(Œ©). By Proposition 3.8, it follows
that ‚àÇŒ±un ‚ÜígŒ± in the sense of D‚Ä≤(Œ©). Now by Proposition 3.10, we also know
that ‚àÇŒ±un ‚Üí‚àÇŒ±u in the sense of D‚Ä≤(Œ©), where u = g(0,0,...,0) is the limit of the
sequence in L p(Œ©). Therefore ‚àÇŒ±u = gŒ± ‚ààL p(Œ©) since the space of distributions
is separated and thus a converging sequence can only have one limit. This shows that
u belongs to W m,p(Œ©) on the one hand, and that un ‚Üíu in W m,p(Œ©) since
‚à•un ‚àíu‚à•p
W m,p(Œ©) =

|Œ±|‚â§m
‚à•‚àÇŒ±un ‚àí‚àÇŒ±u‚à•p
L p(Œ©) =

|Œ±|‚â§m
‚à•‚àÇŒ±un ‚àígŒ±‚à•p
L p(Œ©) ‚Üí0,
for p < +‚àûand the same for p = +‚àû. Therefore W m,p(Œ©) is complete, and so is
the proof.
‚ñ°

3.7 Sobolev Spaces
101
From now on, we will mostly consider the case p = 2. Let us introduce an
important subset of H m(Œ©).
DeÔ¨Ånition 3.6 The closure of D(Œ©) in H m(Œ©) is denoted H m
0 (Œ©).
In other words, H m
0 (Œ©) consists exactly of those functions u of H m(Œ©) which
can be approximated in the sense of H m(Œ©) by indeÔ¨Ånitely differentiable func-
tions with compact support, i.e., such that there exists a sequence œïn ‚ààD(Œ©) with
‚à•œïn ‚àíu‚à•H m(Œ©) ‚Üí0. By deÔ¨Ånition, it is a closed vector subspace of H m(Œ©) and
thus a Hilbert space for the scalar product of H m(Œ©).
The following is a very important result. We introduce the semi-norm
|u|H m(Œ©) =
 
|Œ±|=m
‚à•‚àÇŒ±u‚à•2
L2(Œ©)
 1
2 .
This semi-norm just retains the partial derivatives of the highest order compared with
the norm.
Theorem 3.6 (Poincar√©‚Äôs inequality) Let Œ© be a bounded open subset of Rd. There
exists a constant C which only depends on Œ© such that for all u ‚ààH 1
0 (Œ©),
‚à•u‚à•L2(Œ©) ‚â§C|u|H 1(Œ©).
Proof Since Œ© is assumed to be bounded, it is included in a strip4 that we may
assume to be of the form
Œ© ‚äÇSa,b = {(x‚Ä≤, xd); x‚Ä≤ ‚ààRd‚àí1, a < xd < b}
for some a and b, without loss of generality, see Fig.3.17.
We argue by density. First let œï ‚ààD(Œ©). We extend it by 0 to the whole of Rd
and still call the extension œï. Let Œ±d = (0, 0, . . . , 0, 1) so that ‚àÇŒ±dœï =
‚àÇœï
‚àÇxd . Since
œï(x‚Ä≤, a) = 0 for all x‚Ä≤ ‚ààRd‚àí1 and œï is C1 with respect to xd, we can write
œï(x‚Ä≤, xd) =
	 xd
a
‚àÇŒ±dœï(x‚Ä≤, s) ds
for all (x‚Ä≤, xd). In particular, for a ‚â§xd ‚â§b, we obtain
œï(x‚Ä≤, xd)2 ‚â§(xd ‚àía)
	 xd
a

‚àÇŒ±dœï(x‚Ä≤, s)
2 ds ‚â§(b ‚àía)
	 b
a

‚àÇŒ±dœï(x‚Ä≤, s)
2 ds
by the Cauchy‚ÄìSchwarz inequality. We integrate the above inequality with respect
to x‚Ä≤
4It is enough for Poincar√©‚Äôs inequality to be valid that Œ© be included in such a strip although not
necessarily bounded.

102
3
A Review of Analysis
Fig. 3.17 The open set Œ©
included in a strip
b
a
x‚Ä≤
xd
	
Rd‚àí1 œï(x‚Ä≤, xd)2 dx‚Ä≤ ‚â§(b ‚àía)
	
Sa,b

‚àÇŒ±dœï(x)
2 dx
by Fubini‚Äôs theorem. Now, because the support of œï is included in Œ© ‚äÇSa,b, it
follows that
	
Sa,b

‚àÇŒ±dœï(x)
2 dx = ‚à•‚àÇŒ±dœï‚à•2
L2(Œ©).
We integrate again with respect to xd between a and b and obtain
‚à•œï‚à•2
L2(Œ©) ‚â§(b ‚àía)2‚à•‚àÇŒ±dœï‚à•2
L2(Œ©),
for the same reasons (Fubini and support of œï). Now by deÔ¨Ånition of the semi-norm,
it follows that
‚à•‚àÇŒ±dœï‚à•2
L2(Œ©) ‚â§

|Œ±|=1
‚à•‚àÇŒ±œï‚à•2
L2(Œ©) = |œï|2
H 1(Œ©),
hence Poincar√©‚Äôs inequality for a function œï ‚ààD(Œ©) with constant C = (b ‚àía).
We complete the proof by a density argument. Let u ‚ààH 1
0 (Œ©). By deÔ¨Ånition of
H 1
0 (Œ©) as the closure of D(Œ©) in H 1(Œ©), there exists a sequence œïn ‚ààD(Œ©) such
that œïn ‚Üíu in H 1(Œ©). Inspection of the deÔ¨Ånition of the H 1 norm reveals that this
is equivalent to œïn ‚Üíu in L2(Œ©) and ‚àÇŒ±œïn ‚Üí‚àÇŒ±u for all |Œ±| = 1 also in L2(Œ©).
Since all the L2 norms then converge, we obtain in the limit
‚à•u‚à•L2(Œ©) ‚â§(b ‚àía)|u|H 1(Œ©),
which is Poincar√©‚Äôs inequality on H 1
0 (Œ©).
‚ñ°
Remark 3.10 Poincar√©‚Äôs inequality shows that H 1
0 (Œ©) is a strict subspace of H 1(Œ©)
when Œ© is bounded. Indeed, the constant function u = 1 is in H 1(Œ©) but does

3.7 Sobolev Spaces
103
not satisfy the inequality, since all its partial derivatives vanish. It follows that it is
impossible to approximate a non zero constant by a sequence in D(Œ©) in the norm
of H 1(Œ©).
‚ñ°
From now on, we will use the gradient notation ‚àáu to denote the vector of all Ô¨Årst
order distributional partial derivatives of u. We already used the simpliÔ¨Åed notation
‚àÇi =
‚àÇ
‚àÇxi for individual Ô¨Årst order derivatives instead of the multiindex notation.
Similarly, we note ‚àÇi j =
‚àÇ2
‚àÇxi‚àÇx j for second order derivatives. When u ‚ààH 1(Œ©), then
we have ‚àáu ‚ààL2(Œ©; Rd). Poincar√©‚Äôs inequality has an important corollary.
Corollary 3.3 Let Œ© be a bounded subset of Rd. The H 1 semi-norm | ¬∑ |H 1(Œ©) is
a norm on H 1
0 (Œ©) that is equivalent to the H 1 norm. It is also a Hilbertian norm
associated with the scalar product
(u|v)H 1
0 (Œ©) =
	
Œ©
‚àáu ¬∑ ‚àáv dx.
Proof First of all, it is clear that |u|H 1(Œ©) ‚â§‚à•u‚à•H 1(Œ©) for all u ‚ààH 1(Œ©), hence
all u ‚ààH 1
0 (Œ©), since the norm squared is the semi-norm squared plus the L2 norm
squared.
The converse inequality follows from Poincar√©‚Äôs inequality. Indeed, for u ‚àà
H 1
0 (Œ©), we have ‚à•u‚à•L2(Œ©) ‚â§C|u|H 1(Œ©). Therefore
‚à•u‚à•H 1(Œ©) = (‚à•u‚à•2
L2(Œ©) + |u|2
H 1(Œ©))
1
2 ‚â§(C2 + 1)
1
2 |u|H 1(Œ©).
This shows both that the semi-norm is a norm on H 1
0 (Œ©) and that it is equivalent to
the full H 1 norm on H 1
0 (Œ©). This also shows that the bilinear form above is positive
deÔ¨Ånite, hence a scalar product.
‚ñ°
Remark 3.11 The fact that the two norms are equivalent implies that H 1
0 (Œ©) is also
complete for the semi-norm. Hence, it is also a Hilbert space for the scalar product
corresponding to the semi-norm. Beware however that this is a different Hilbert
structure from the one obtained by restricting the H 1 scalar product to H 1
0 . Indeed,
we now have two different notions of orthogonality, and (at least) two different ways
of identifying the dual of H 1
0 , see Theorem 3.3.
‚ñ°
Remark 3.12 The above results generalize to H m
0 (Œ©) on which the semi-norm
| ¬∑ |H m(Œ©) is equivalent to the full H m norm. They also generalize to the spaces
W m,p
0
(Œ©) deÔ¨Åned in a obvious way.
‚ñ°
Let us give yet another way of identifying the dual of H 1
0 (Œ©) as a subspace of the
space of distributions, see [2, 25, 35].
DeÔ¨Ånition 3.7 Let
H ‚àí1(Œ©) = {T ‚ààD‚Ä≤(Œ©); ‚àÉC, ‚àÄœï ‚ààD(Œ©), |‚ü®T, œï‚ü©| ‚â§C|œï|H 1(Œ©)},
(3.10)

104
3
A Review of Analysis
equipped with the norm
‚à•T ‚à•H ‚àí1(Œ©) = inf{C appearing in formula (3.10)} =
sup
œï‚ààD(Œ©)
œïÃ∏=0
|‚ü®T, œï‚ü©|
|œï|H 1(Œ©)
.
Then H ‚àí1(Œ©) is isometrically isomorphic to (H 1
0 (Œ©))‚Ä≤.
Proof Since D(Œ©) ‚äÇH 1
0 (Œ©) by deÔ¨Ånition, any linear form ‚Ñìon H 1
0 (Œ©) deÔ¨Ånes a
linear form on D(Œ©) by restriction. Moreover, if œïn ‚Üí0 in D(Œ©), we obviously
have œïn ‚Üí0 in H 1
0 (Œ©) as well. Hence, if ‚Ñìis continuous, that is ‚Ñì‚àà(H 1
0 (Œ©))‚Ä≤, its
restriction to D(Œ©) is a distribution T ‚ààD‚Ä≤(Œ©). This distribution clearly belongs
to H ‚àí1(Œ©).
Conversely, let us be given an element T of H ‚àí1(Œ©). By deÔ¨Ånition, it is a linear
form deÔ¨Åned on a dense subspace of H 1
0 (Œ©) and continuous with respect to the H 1
0 -
norm. Therefore, it extends to an element ‚Ñìof the dual space (H 1
0 (Œ©))‚Ä≤, with the
same norm.
‚ñ°
Remark 3.13 The identiÔ¨Åcation of the dual of H 1
0 (Œ©) with H ‚àí1(Œ©) is the one that
leads to the pivot space inclusions of Remark 3.1, V ‚ÜíH ‚ÜíV ‚Ä≤, in the case of
H = L2(Œ©) and V = H 1
0 (Œ©). Indeed, the scalar product used in the identiÔ¨Åcation of
the pivot space with its dual is equal to the duality bracket of an L2 function seen as
a distribution and a D test-function, when the second argument in the scalar product
is such a test-function, i.e., if œï ‚ààD(Œ©) and f ‚ààL2(Œ©), we have
‚ü®f, œï‚ü©=
	
Œ©
f œï dx.
The two scalar products that H 1
0 (Œ©) comes equipped with do not have this property.
Consequently, an identiÔ¨Åcation of H 1
0 (Œ©) with its dual using either one of the latter
scalar products, even though it is legitimate, does not use the same duality as the one
used to identify a function with a distribution.
‚ñ°
In order to explain the ‚àí1 exponent in the notation, we note the following.
Proposition 3.13 Let f ‚ààL2(Œ©),then‚àÇi f ‚ààH ‚àí1(Œ©)and‚ü®‚àÇi f, œï‚ü©= ‚àí

Œ© f ‚àÇiœï dx
for all œï ‚ààD(Œ©).
Proof By deÔ¨Ånition of distributional derivatives,
‚ü®‚àÇi f, œï‚ü©= ‚àí‚ü®f, ‚àÇiœï‚ü©= ‚àí
	
Œ©
f ‚àÇiœï dx,
since f is locally integrable. Thus
|‚ü®‚àÇi f, œï‚ü©| ‚â§‚à•f ‚à•L2(Œ©)‚à•‚àÇiœï‚à•L2(Œ©) ‚â§‚à•f ‚à•L2(Œ©)|œï|H 1
0 (Œ©),

3.7 Sobolev Spaces
105
by the Cauchy‚ÄìSchwarz inequality, hence ‚àÇi f ‚ààH ‚àí1(Œ©) with ‚à•‚àÇi f ‚à•H ‚àí1(Œ©) ‚â§
‚à•f ‚à•L2(Œ©).
‚ñ°
Remark 3.14 This shows that the operator ‚àÇi is linear continuous from L2(Œ©)
(= H 0(Œ©)) into H ‚àí1(Œ©), just as it is linear continuous from H 1(Œ©) into L2(Œ©).
Each time, the exponent in the notation gets decremented by 1 as one derivative
is lost.
‚ñ°
Remark 3.15 When Œ© is regular, a distribution in H ‚àí1(Œ©) whose Ô¨Årst order partial
derivatives are all in H ‚àí1(Œ©) is in fact a function in L2(Œ©). The latter result is known
as Lions‚Äôs lemma.
‚ñ°
The above bracket formula is also valid for all v ‚ààH 1
0 (Œ©), in the sense that
‚ü®‚àÇi f, v‚ü©H ‚àí1(Œ©),H 1
0 (Œ©) =
	
Œ©
f ‚àÇiv dx,
by density. In the same vein, we have
Corollary 3.4 The operator ‚àíŒî is linear continuous from H 1
0 (Œ©) into H ‚àí1(Œ©)
and for all u, v ‚ààH 1
0 (Œ©), we have
‚ü®‚àíŒîu, v‚ü©H ‚àí1(Œ©),H 1
0 (Œ©) =
	
Œ©
‚àáu ¬∑ ‚àáv dx.
The dual of H m
0 (Œ©) is likewise identiÔ¨Åed with a subspace H ‚àím(Œ©) of D‚Ä≤(Œ©).
3.8
Properties of Sobolev Spaces in One Dimension
The one-dimensional case is simple and useful to get acquainted with the properties
of Sobolev spaces in general. For simplicity, we mostly consider H 1(Œ©) where
Œ© = ]a, b[ is a bounded open interval of R. Let us admit a density result that we
will prove later in arbitrary dimension.
Proposition 3.14 The space C1([a, b]) is dense in H 1(]a, b[).
The density above is meant in the sense that the equivalence classes of elements
of C1([a, b]) are dense in H 1(]a, b[). We have already seen examples of functions
in dimension one that are H 1 but not C1. All one-dimensional H 1 functions however
are continuous, in the sense that each equivalence class contains one continuous
representative. There is even a more precise embedding.
Theorem 3.7 We have that H 1(]a, b[) ‚ÜíC0,1/2([a, b]).
Recall that the hooked arrow means that there is an injection between the two
spaces and that this injection is continuous.

106
3
A Review of Analysis
Proof Let us be given v ‚ààH 1(]a, b[). The distributional derivative v‚Ä≤ is in L2(a, b)
hence is integrable on [a, b]. For all x ‚àà[a, b], we thus deÔ¨Åne
w(x) =
	 x
a
v‚Ä≤(t) dt.
For all x, y ‚àà[a, b], we can consequently write (with the convention

 x
y g dt =
‚àí

 y
x g dt)
w(y) ‚àíw(x) =
	 y
x
v‚Ä≤(t) dt.
Squaring this relation, we see that
(w(y) ‚àíw(x))2 =
	 y
x
v‚Ä≤(t) dt
2
‚â§|y ‚àíx|
	 b
a
(v‚Ä≤(t))2 dt ‚â§|y ‚àíx||v|2
H 1(]a,b[),
by the Cauchy‚ÄìSchwarz inequality. Therefore, for all x Ã∏= y, we obtain
|w(y) ‚àíw(x)|
|y ‚àíx|1/2
‚â§|v|H 1(]a,b[).
(3.11)
It follows from this that w is H√∂lder continuous of exponent 1
2 on [a, b]. Therefore,
w is a distribution on ]a, b[. Let us compute its derivative. For all œï ‚ààD(]a, b[), we
have
‚ü®w‚Ä≤, œï‚ü©= ‚àí‚ü®w, œï‚Ä≤‚ü©= ‚àí
	 b
a
w(x)œï‚Ä≤(x) dx
= ‚àí
	 b
a
	 x
a
v‚Ä≤(t) dt

œï‚Ä≤(x) dx = ‚àí
	 b
a
	 b
t
œï‚Ä≤(x) dx

v‚Ä≤(t) dt
= ‚àí
	 b
a
(œï(b) ‚àíœï(t))v‚Ä≤(t) dt =
	 b
a
œï(t)v‚Ä≤(t) dt = ‚ü®v‚Ä≤, œï‚ü©,
since œï(b) = 0. The integral interchange is justiÔ¨Åed by Fubini‚Äôs theorem. Therefore,
we have shown that w‚Ä≤ = v‚Ä≤, from which it follows that there exists a constant c such
that v = w+c by Proposition 3.12. Consequently, v has a representative that belongs
to C0,1/2([a, b]), namely w + c, and we can write
v(x) = v(y) +
	 x
y
v‚Ä≤(t) dt,
(3.12)

3.8 Properties of Sobolev Spaces in One Dimension
107
for all5 x, y in [a, b] by using the deÔ¨Ånition of w. Squaring this relation and using
the Cauchy‚ÄìSchwarz inequality again, we obtain that
v(x)2 ‚â§2v(y)2 + 2(b ‚àía)
	 b
a
v‚Ä≤(t)2 dt,
which we integrate with respect to y to obtain
(b ‚àía)v(x)2 ‚â§2‚à•v‚à•2
L2(a,b) + 2(b ‚àía)2‚à•v‚Ä≤‚à•2
L2(a,b) ‚â§2 max(1, (b ‚àía)2)‚à•v‚à•2
H 1(]a,b[).
As this holds true for all x in [a, b], it follows that
‚à•v‚à•C0([a,b]) ‚â§

2 max

1
b ‚àía , b ‚àía

‚à•v‚à•H 1(]a,b[).
(3.13)
Putting estimates (3.11) and (3.13) together, we obtain the announced continuous
embedding.
‚ñ°
That all H 1 functions are continuous is speciÔ¨Åc to dimension one, as we will see
later.
Note also that not all C0,1/2 functions belong to H 1 (consider x ‚Üí‚àöx on ]0, 1[).
The injection above is nonetheless optimal since for each Œ≤ > 1/2, there is an H 1
function that is not C0,Œ≤ (consider x ‚Üíx
2Œ≤+1
4
on ]0, 1[).
An important feature of the one-dimensional case is that pointwise values of
a H 1 function are unambiguously deÔ¨Åned as the pointwise value of its continuous
representative. Moreover, such pointwise values depend continuously on the function
in the H 1 norm by estimate (3.13). This is in particular true of the endpoint values
at a and b, which can be surprising because the Sobolev space deÔ¨Ånition is based on
the open set ]a, b[, extremities excluded.
Corollary 3.5 The linear mapping H 1(]a, b[) ‚ÜíR2, u ‚Üí(u(a), u(b)) is contin-
uous.
Proof Obviously max(|u(a)|, |u(b)|) ‚â§‚à•u‚à•C0,1/2([a,b]) ‚â§C‚à•u‚à•H 1(]a,b[).
‚ñ°
Remark 3.16 This is the one-dimensional version of the trace theorem that we will
prove in all dimensions later on. The linear mapping in question is called the trace
mapping. The result also shows that Dirichlet boundary conditions make sense for
functions of H 1(]a, b[), a fact that was not evident from the start.
Because of the continuity of the trace, it is clear that H 1
0 (]a, b[) is included in the
kernel of the trace {u ‚ààH 1(]a, b[); u(a) = u(b) = 0}. It sufÔ¨Åces to take a sequence
œïn of D(]a, b[) that tends to u in H 1(]a, b[). Actually, the reverse inclusion holds
true so that
5And not only almost everywhere, since we are now talking about the continuous representative
of v.

108
3
A Review of Analysis
H 1
0 (]a, b[) = {u ‚ààH 1(]a, b[); u(a) = u(b) = 0},
see Proposition 3.16 in any dimension. The space H 1
0 (]a, b[) is thus adequate for
homogeneous Dirichlet conditions for second order boundary value problems.
‚ñ°
Remark 3.17 We also have H m(]a, b[) ‚ÜíCm‚àí1,1/2([a, b]), the trace on H m(]a, b[)
is u ‚Üí(u(a), u‚Ä≤(a), . . . , u(m‚àí1)(a), u(b), u‚Ä≤(b), . . . , u(m‚àí1)(b)) and H m
0 (]a, b[) is
the set of u such that u(a) = u‚Ä≤(a) = ¬∑ ¬∑ ¬∑ = u(m‚àí1)(a) = u(b) = u‚Ä≤(b) = ¬∑ ¬∑ ¬∑ =
u(m‚àí1)(b) = 0. Similar results can be written for the W m,p(]a, b[) spaces, not with
the same H√∂lder exponent though (exercise).
‚ñ°
To conclude the one-dimensional case, let us mention the Rellich compact embed-
ding theorem.
Theorem 3.8 The injection H 1(]a, b[) ‚ÜíL2(a, b), u ‚Üíu is compact.
Proof A mapping is compact if it transforms bounded sets into relatively compact
sets. Here, it is enough to take the unit ball of H 1(]a, b[) by linearity. By esti-
mates (3.11) and (3.13), this is a bounded subset of C0,1/2([a, b]). Bounded sets
of C0,1/2([a, b]) are equicontinuous, therefore relatively compact in C0([a, b]) by
Ascoli‚Äôs theorem [7, 32, 33, 69]. Finally the embedding C0([a, b]) ‚ÜíL2(a, b) is
continuous, thus transforms relatively compact sets into relatively compact sets. ‚ñ°
Remark 3.18 The Rellich theorem is true in arbitrary dimension d, i.e., the embed-
ding H 1(Œ©) ‚ÜíL2(Œ©) is compact, provided that Œ© is bounded and sufÔ¨Åciently
regular, for example Lipschitz, see [15, 35, 66].
‚ñ°
3.9
Density of Smooth Functions and Trace in Dimension d
We have seen that Sobolev functions in dimension one are continuous. This is no
longer true in dimensions 2 and higher. We will concentrate on the space H 1(Œ©).
Note however that functions in W 1,p(Œ©), where Œ© is an open subset of Rd, are
continuous for p > d, this is known as Morrey‚Äôs theorem, [15, 35]. See also [2, 58]
for functions in W m,p for mp > d.
Let D be the unit disk in R2. It can be checked (exercise) that the function u : x ‚Üí
ln(| ln(‚à•x‚à•/e)|) is in H 1
0 (D). This function tends to +‚àûat the origin, thus there is
no continuous function in its equivalence class, see Fig.3.18.
Now we can do much worse! We extend u by 0 to R2, which still is a function in
H 1(R2). Next, let (xi)i‚ààN be countable, dense set of points in R2. Then the function
v(x) = +‚àû
i=0 2‚àíiu(x ‚àíxi) is in H 1(R2), since ‚à•u(¬∑ ‚àíxi)‚à•H 1(R2) = ‚à•u‚à•H 1(R2) and
we have a normally convergent series, but this function tends to +‚àûat all points xi,
which are dense. Therefore, v is not locally bounded: there is no open set on which it
is bounded. This sounds pretty bad, even though it is a perfectly legitimate, although
hard to mentally picture, function of H 1(R2), see Fig.3.19.

3.9 Density of Smooth Functions and Trace in Dimension d
109
Fig. 3.18 A discontinuous H1-function
Fig. 3.19 An attempt to draw a very bad H1-function (graphics cheat: the spikes should be thinner,
(inÔ¨Ånitely) higher and (inÔ¨Ånitely) denser)

110
3
A Review of Analysis
In higher dimensions, we can picture such singularities occurring on a dense set of
curves or submanifolds of dimension d ‚àí2. In view of this state of things, ascribing
some kind of boundary value to a H 1 function that would be a reasonably deÔ¨Åned
continuous extension from the values taken in Œ© seems difÔ¨Åcult. In PDE problems,
we nonetheless need boundary values, to write Dirichlet conditions for example.
The deÔ¨Ånition of a good boundary value for H 1 functions is by means of a mapping
called the trace mapping. This mapping is deÔ¨Åned by density of smooth functions, so
let us deal with that Ô¨Årst. Besides, as should already be quite clear, density arguments
are very useful in Sobolev spaces [2, 25, 35, 40, 61].
Theorem 3.9 Let Œ© be a Lipschitz open subset of Rd. Then the space C1( ¬ØŒ©) is
dense in H 1(Œ©).
Proof We use the same partition of unity as before. It sufÔ¨Åces to construct a C1( ¬ØŒ©)
approximation for each part u j = œà ju of u. Indeed, we have u j ‚ààH 1(Œ©) for all j
by Proposition 3.11.
We start with the case j = 0. Since u0 is compactly supported in Œ©, its extension
by 0 to the whole of Rd belongs to H 1(Rd) as is easily checked. Let us take a molliÔ¨Åer
œÅ, that is to say a C‚àûfunction with compact support in the unit ball B and such that

B œÅ(y) dy = 1 as in Sect.3.4.
For all integers n ‚â•1, we set œÅn(y) = ndœÅ(ny) and u0,n = œÅn ‚ãÜu0, where the
star denotes the convolution as usual. By the general properties of convolution, u0,n
is compactly supported in Œ© for n sufÔ¨Åciently large, and we have u0,n ‚ààC‚àû(Rd) ‚à©
L2(Rd) and u0,n ‚Üíu0 in L2(Rd) when n ‚Üí+‚àû. Moreover, since ‚àÇiu0,n =
œÅn‚ãÜ‚àÇiu0, the same argument shows that ‚àÇiu0,n ‚Üí‚àÇiu0 in L2(Rd), whence u0,n ‚Üíu0
in H 1(Rd) when n ‚Üí+‚àû. This settles the case j = 0 because the restriction of
u0,n to ¬ØŒ© is of class C1 (in fact, it is even compactly supported as soon as n is large
enough) and the H 1 norm on Œ© is smaller than the H 1 norm on Rd.
The regularity of Œ© comes into play for j > 0, in the hypercubes C j that cover the
boundary. We drop again all subscripts or superscripts j for brevity. The difÔ¨Åculty
compared with j = 0 is that we cannot extend u by 0 to Rd and remain in H 1(Rd).
For example, it is easy to see that the function equal to 1 in Œ© and 0 outside is not
in H 1(Rd). We will use a two step process, Ô¨Årst a translation, then a convolution.
Let n ‚ààN‚àó. We set un(y) = u(y‚Ä≤, yd ‚àí1/n), which is a function deÔ¨Åned on the
translated set Œ©n = {y ‚ààRd; (y‚Ä≤, yd ‚àí1/n) ‚ààŒ© ‚à©C}, see Fig.3.20. We extend un
by 0 to Rd and letun denote this extension. Since u is compactly supported in C, and
the translation shifts it upwards, the restriction of un to Œ© ‚à©C is still in H 1(Œ© ‚à©C)
for n large enough.
It can be shown6 that the translation is continuous on L2(Rd) in the sense that
un ‚Üíu in L2(Rd) when n ‚Üí+‚àû, thus by restriction we have un|Œ©‚à©C ‚Üíu|Œ©‚à©C in
L2(Œ© ‚à©C). Computing the partial derivatives in the sense of distributions shows that
‚àÇi(un|Œ©‚à©C) = (‚àÇiu)n|Œ©‚à©C using the same notation for the translation. Therefore, we
have the same convergence for the partial derivatives, which shows that un|Œ©‚à©C ‚Üí
6The fairly easy proof uses the density of continuous, compactly supported functions in L2(Rd).

3.9 Density of Smooth Functions and Trace in Dimension d
111
u|Œ©‚à©C in H 1(Œ© ‚à©C) when n ‚Üí+‚àû. To conclude, we just need to approximate
un|Œ©‚à©C for any given n by a C1( ¬ØŒ©) function, and use a double limit argument.
We now use the convolution by a molliÔ¨Åer again and set un,p = un ‚ãÜœÅp. By
construction, un,p is of class C‚àûon Rd and un,p ‚Üíun in L2(Rd) when p ‚Üí+‚àû.
Now for the subtle point. We do not have L2 convergence of the gradients, because in
general ‚àÇiun is not a function, let alone in L2(Rd). Take for example œï = 0 and u = 1,
then ‚àÇdun is a Dirac mass on the hyperplane yd = 1
n , cf. the one-dimensional case.
However, since we have shifted the discontinuity outside of Œ© by the translation,
there is hope that the restrictions to Œ© still converge.
To see that this is the case, we let 
‚àÇiun denote the extension of ‚àÇiun to Rd by 0.
We have 
‚àÇiun ‚ààL2(Rd) and 
‚àÇiun ‚ãÜœÅp ‚Üí
‚àÇiun in L2(Rd) when p ‚Üí+‚àûby the
properties of convolution again. Of course, as already noted, 
‚àÇiun Ã∏= ‚àÇiun so that

‚àÇiun ‚ãÜœÅp Ã∏= ‚àÇiun,p. We will show that, for p large enough, we nonetheless have
(
‚àÇiun ‚ãÜœÅp)|Œ©‚à©C = (‚àÇiun,p)|Œ©‚à©C. As we have just seen that 
‚àÇiun ‚ãÜœÅp converges in
L2(Rd), this will lead to the conclusion that (‚àÇiun,p)|Œ©‚à©C ‚Üí‚àÇiun in L2(Œ© ‚à©C),
hence un,p|Œ©‚à©C ‚Üíun|Œ©‚à©C in H 1(Œ© ‚à©C) when p ‚Üí+‚àû. Since un,p|Œ©‚à©C ‚àà
C1(Œ© ‚à©C), we will have our approximation.
To show that the restrictions are equal, we go back to the convolution formula

‚àÇiun ‚ãÜœÅp(x) =
	
Rd œÅp(x ‚àíy)
‚àÇiun(y) dy =
	
B(x,1/p)
œÅp(x ‚àíy)
‚àÇiun(y) dy
since œÅ has support in the unit ball. Now, if for all x ‚ààŒ© ‚à©C, we had B

x, 1
p

‚äÇŒ©n,
then the only values of 
‚àÇiun in the integral would coincide with those of ‚àÇiun, see
Fig.3.20. Hence the equality of the restrictions since ‚àÇiun,p = œÅp ‚ãÜ‚àÇiun.
We are thus down to a geometry question, where the regularity of Œ© intervenes
(at last). We need to estimate the distance between the graph of œï, denoted G, and
the same graph translated upwards by 1
n , denoted Gn. Let L be the Lipschitz constant
of œï and take two points x ‚ààG and y ‚ààGn. We have
‚à•y ‚àíx‚à•2 = ‚à•y‚Ä≤ ‚àíx‚Ä≤‚à•2 +

œï(y‚Ä≤) ‚àíœï(x‚Ä≤) + 1
n
2
,
using the prime notation to denote the projection on Rd‚àí1 as usual. Now
œï(y‚Ä≤) ‚àíœï(x‚Ä≤) + 1
n ‚â•1
n ‚àíL‚à•y‚Ä≤ ‚àíx‚Ä≤‚à•,
therefore if ‚à•y‚Ä≤‚àíx‚Ä≤‚à•‚â§
1
2nL , then ‚à•y‚àíx‚à•‚â•
1
2n . On the other hand, if ‚à•y‚Ä≤‚àíx‚Ä≤‚à•‚â•
1
2nL ,
it follows trivially that ‚à•y ‚àíx‚à•‚â•
1
2nL . We thus see that
‚à•y ‚àíx‚à•‚â•min
 1
2n ,
1
2nL

.

112
3
A Review of Analysis
Fig. 3.20 The translated
open set Œ©n and the ball of
radius 1
p used to compute the
convolution at point x. For x
in ¬ØŒ© ‚à©C, the ball remains
included in Œ©n uniformly for
p ‚Üí+‚àû, n Ô¨Åxed
If we choose
p >
1
min
 1
2n ,
1
2nL
,
then B

x, 1
p

‚äÇŒ©n, hence the Ô¨Ånal result.
‚ñ°
Remark 3.19 There is a slight cheat in the geometric part of the above proof, in that
we have ignored what happens on the lateral sides of C. Indeed, there is actually no
problem, since u vanishes there.
‚ñ°
Remark 3.20 Warning: there are open sets less regular than Lipschitz on which not
only does the above proof not work, but the density result is false (exercise, Ô¨Ånd a
simple example). It is however always true that C1(Œ©)‚à©H 1(Œ©) is dense in H 1(Œ©),
a weaker result (this is the Meyers‚ÄìSerrin theorem, see [1]) which is sometimes
sufÔ¨Åcient, although not here for the existence of the trace mapping.
‚ñ°
Once the density of C1( ¬ØŒ©) is established, we can prove the trace theorem.
Theorem 3.10 Let Œ© be a Lipschitz open subset of Rd. There exists a unique con-
tinuous linear mapping Œ≥0 : H 1(Œ©) ‚ÜíL2(‚àÇŒ©) such that for all u ‚ààC1( ¬ØŒ©), we
have
Œ≥0(u) = u|‚àÇŒ©.
In particular, there exists a constant CŒ≥0 such that, for all u ‚ààH 1(Œ©),
‚à•Œ≥0(u)‚à•L2(‚àÇŒ©) ‚â§CŒ≥0‚à•u‚à•H 1(Œ©).

3.9 Density of Smooth Functions and Trace in Dimension d
113
In other words, the trace is the unique reasonable way of deÔ¨Åning a boundary value
for H 1(Œ©) functions, as the continuous extension of the restriction to the boundary
for functions for which this restriction makes sense unambiguously, i.e., functions
in C1( ¬ØŒ©).
Proof We write the proof only in dimension d = 2, but the general case is strictly
identical, up to heavier notation.
Let u ‚ààC1( ¬ØŒ©). By partition of unity, we consider uœà which is supported in one
of the C j = C for j = 1, . . . , m. Let G = ‚àÇŒ© ‚à©C be the part of the boundary
included in C. By deÔ¨Ånition of the boundary measure, we have
‚à•uœà‚à•2
L2(G) =
	 a
‚àía
(uœà)(y1, œï(y1))2
1 + œï‚Ä≤(y1)2 dy1
=
	 a
‚àía
	 œï(y1)
‚àía
‚àÇ(uœà)
‚àÇy2
(y1, y2) dy2
2
1 + œï‚Ä≤(y1)2 dy1,
since œà(y1, ‚àía) = 0. By the Cauchy‚ÄìSchwarz inequality, we have
	 œï(y1)
‚àía
‚àÇ(uœà)
‚àÇy2
(y1, y2) dy2
2
‚â§|œï(y1) + a|
	 œï(y1)
‚àía
‚àÇ(uœà)
‚àÇy2
(y1, y2)
2
dy2,
with |œï(y1) + a| ‚â§2a. Let us set M = max[‚àía,a]

1 + œï‚Ä≤(y1)2. We obtain
‚à•uœà‚à•2
L2(G) ‚â§2aM
	 a
‚àía
	 œï(y1)
‚àía
‚àÇ(uœà)
‚àÇy2
2
dy2dy1 = 2aM
	
Œ©‚à©C
‚àÇ(uœà)
‚àÇy2
2
dx.
Now ‚àÇ(uœà)
‚àÇy2
= œà ‚àÇu
‚àÇy2 + u ‚àÇœà
‚àÇy2 , so that
‚à•uœà‚à•2
L2(G) ‚â§4aM
	
Œ©‚à©C
œà2 ‚àÇu
‚àÇy2
2
dx +
	
Œ©‚à©C
u2 ‚àÇœà
‚àÇy2
2
dx

‚â§4aM
 ‚àÇu
‚àÇy2

2
L2(Œ©‚à©C) + max
Œ©‚à©C
 ‚àÇœà
‚àÇy2
2
‚à•u‚à•2
L2(Œ©‚à©C)
 
‚â§K 2‚à•u‚à•2
H 1(Œ©),
(remembering that œà is [0, 1]-valued) where K = K j is a constant which depends
on j.
We put all the estimates together by partition of unity and the triangle inequality:
‚à•u‚à•L2(‚àÇŒ©) ‚â§
m

j=0
‚à•uœà j‚à•L2(G j) ‚â§(m + 1)K‚à•u‚à•H 1(Œ©),
forallu ‚ààC1( ¬ØŒ©)where K = max j=1,...,m K j.Thelinearmappingu ‚Üíu|‚àÇŒ© deÔ¨Åned
on C1( ¬ØŒ©) is thus continuous in the H 1(Œ©) and L2(‚àÇŒ©) norms. Since C1( ¬ØŒ©) is dense

114
3
A Review of Analysis
in H 1(Œ©), the mapping has a unique continuous extension to H 1(Œ©) with values in
L2(‚àÇŒ©), which is called the trace mapping Œ≥0.
‚ñ°
Remark 3.21 Note that if u ‚ààH 1(Œ©) ‚à©C0( ¬ØŒ©) the trace Œ≥0(u) is equal to the
restriction of the function to ‚àÇŒ©, u|‚àÇŒ©, even if u is not in C1( ¬ØŒ©).
‚ñ°
Remark 3.22 Again, there are open sets less regular than Lipschitz on which no trace
mapping can be deÔ¨Åned.
‚ñ°
We now are in a position to extend the integration by parts formula(s) to elements
of Sobolev spaces.
Theorem 3.11 Let Œ© be a Lipschitz open set and u, v ‚ààH 1(Œ©). Then we have
	
Œ©
‚àÇu
‚àÇxi
v dx = ‚àí
	
Œ©
u ‚àÇv
‚àÇxi
dx +
	
‚àÇŒ©
Œ≥0(u)Œ≥0(v)ni dŒì,
(3.14)
where ni is the ith component of the normal unit exterior vector n.
Proof We argue by density. We already know that formula (3.14) holds true on
C1( ¬ØŒ©), see Corollary 3.2. Let un, vn be sequences in C1( ¬ØŒ©) such that un ‚Üíu and
vn ‚Üív in H 1(Œ©) when n ‚Üí+‚àû. This means that un ‚Üíu, vn ‚Üív, ‚àÇiun ‚Üí‚àÇiu
and ‚àÇivn ‚Üí‚àÇiu in L2(Œ©). Therefore, ‚àÇiunvn ‚Üí‚àÇiuv and un‚àÇivn ‚Üíu‚àÇiv in L1(Œ©)
and the left-hand side integral and the Ô¨Årst integral in the right-hand side pass to the
limit. Secondly, we have Œ≥0(un) ‚ÜíŒ≥0(u) and Œ≥0(vn) ‚ÜíŒ≥0(v) in L2(‚àÇŒ©) since the
trace mapping is continuous, hence Œ≥0(un)Œ≥0(vn) ‚ÜíŒ≥0(u)Œ≥0(v) in L1(‚àÇŒ©) and the
second integral in the right-hand side also passes to the limit.
‚ñ°
The various corollaries of the integration by parts formula also hold true, provided
all the integrals make sense. For instance, for all u ‚ààH 1(Œ©),
	
Œ©
‚àÇu
‚àÇxi
dx =
	
‚àÇŒ©
Œ≥0(u)ni dŒì,
as is seen from taking v = 1.
The formulas that entail second derivatives should be applied to H 2 functions.
Such functions u are in H 1(Œ©), thus have a trace Œ≥0(u) and they also have a second
trace Œ≥1(u), called the normal trace, that plays the role of the normal derivative
for a regular function. Indeed, ‚àÇiu ‚ààH 1(Œ©) therefore Œ≥1(u) = d
i=1 Œ≥0(‚àÇiu)ni is
well deÔ¨Åned and continuous from H 2(Œ©) into L2(‚àÇŒ©), because the functions ni are
in L‚àû(‚àÇŒ©). Furthermore, if u ‚ààC2( ¬ØŒ©), then Œ≥1(u) = ‚àÇu
‚àÇn . We thus establish the
following result (Green‚Äôs formula for Sobolev spaces).
Proposition 3.15 Let Œ© be a Lipschitz open set. For all u ‚ààH 2(Œ©) and all v ‚àà
H 1(Œ©), we have
	
Œ©
(Œîu)v dx = ‚àí
	
Œ©
‚àáu ¬∑ ‚àáv dx +
	
‚àÇŒ©
Œ≥1(u)Œ≥0(v) dŒì.
(3.15)

3.9 Density of Smooth Functions and Trace in Dimension d
115
Proof The proof is by density of C2( ¬ØŒ©) in H 2(Œ©) and of C1( ¬ØŒ©) in H 1(Œ©), starting
from formula (3.4).
‚ñ°
Proposition 3.16 Let Œ© be a Lipschitz open set. Then we have
H 1
0 (Œ©) = ker Œ≥0.
Proof One inclusion is easy. The space H 1
0 (Œ©) is by deÔ¨Ånition the closure of the
space D(Œ©) in H 1(Œ©). Thus, if u ‚ààH 1
0 (Œ©), then there exist œïn ‚ààD(Œ©) such that
œïn ‚Üíu in H 1(Œ©). It is clear by deÔ¨Ånition of the trace mapping that Œ≥0(œïn) = 0,
thus u ‚ààker Œ≥0 by continuity of the trace, or in other words H 1
0 (Œ©) ‚äÇker Œ≥0.
We just give the idea for the reverse inclusion [25, 35, 66]. Take a zero trace
function u, use a partition of unity adapted to the boundary, extend all the parts to the
whole of Rd by 0 (the integration by parts formula (3.14) shows that the extension
remains in H 1(Rd) this time), translate each function downwards7 by a small amount
in its cube then perform the convolution step which provides a compactly supported,
C‚àûapproximation. We leave the details to the reader, all the necessary technical
elements have already been introduced previously.
‚ñ°
Remark 3.23 By Remark 3.21, if u ‚ààH 1(Œ©) ‚à©C0( ¬ØŒ©) is such that u|‚àÇŒ© = 0, then
u ‚ààH 1
0 (Œ©).
‚ñ°
Remark 3.24 Similar arguments show that H 2
0 (Œ©) = ker Œ≥0 ‚à©ker Œ≥1 and so on.
Everything we have said in terms of traces can also naturally be done in the spaces
W m,p(Œ©).
‚ñ°
It should be noted that the trace mapping Œ≥0 is not onto.
Proposition 3.17 The image space of the trace mapping, im Œ≥0, is a strict, dense
subspace of L2(‚àÇŒ©). This space is denoted H 1/2(‚àÇŒ©). The norm
‚à•g‚à•H 1/2(‚àÇŒ©) =
inf
v‚ààH 1(Œ©)
Œ≥0(v)=g
‚à•v‚à•H 1(Œ©)
makes H 1/2(‚àÇŒ©) into a Hilbert space.
There are other equivalent norms on H 1/2(‚àÇŒ©). We do not pursue the study of
the trace space H 1/2(‚àÇŒ©) here, see for example [25, 58, 61].
3.10
A Summary of Important Results
Let us now give a quick review of the results of this chapter that are essential for
the following chapters, i.e., everything that concerns variational formulations and
variational approximation methods.
7Instead of upwards for the density result.

116
3
A Review of Analysis
The elementary properties of Hilbert spaces of Sect.3.1 are useful to understand
the abstract variational problems considered in the next chapter.
The Green‚Äôs formulas of Corollary 3.2 in the classical case p. 90, and of
Proposition 3.15 in the Sobolev case p. 114, are essential to establish the varia-
tional formulation of elliptic boundary value problems in more than one dimension
of space.
There is no real need for a deep understanding of distribution theory, see [72, 73].
However, the characterization of distributions of Proposition 3.5, p. 92, the deÔ¨Ånition
of distributional derivatives of DeÔ¨Ånition 3.3, p. 94, and the characterization of the
convergence in the sense of distributions of Proposition 3.7, p. 94 are always good
to know.
The hilbertian Sobolev spaces H 1(Œ©) and H 1
0 (Œ©) introduced in DeÔ¨Ånitions 3.5,
p.99and3.6,p.101,arealsoessentialasthebasicfunctionspacesinwhichvariational
problems are set.
We will have to use Poincar√©‚Äôs inequality, Theorem 3.6, p. 101, and its conse-
quences, for example Corollary 3.3, p. 103, for homogeneous Dirichlet problems.
The existence and properties of the trace mapping, Theorem 3.10, p. 112 and
Proposition 3.16, p. 115, are also key for what follows.

Chapter 4
The Variational Formulation of Elliptic PDEs
We now begin the theoretical study of elliptic boundary value problems in a context
that is more general than the one-dimensional model problem treated in Chap.1. We
will focus on one approach, which is called the variational approach. There are other
ways of solving elliptic problems, such as working with Green functions as seen in
Chap.2. The variational approach is quite simple and well suited for a whole class
of approximation methods, as we will see later.
4.1
Model Boundary Value Problems
Let us start with a few more model problems. The simplest of all is a slight general-
ization of the Poisson equation with a homogeneous Dirichlet boundary condition.
Let us thus be given an open Lipschitz subset Œ© of Rd, a function c ‚ààL‚àû(Œ©) and
another function f ‚ààL2(Œ©). We are looking for a function u: ¬ØŒ© ‚ÜíR such that
‚àíŒîu + cu = f in Œ©,
u = 0 on ‚àÇŒ©.
(4.1)
We are going to transform the boundary value problem (4.1) into an entirely different
kind of problem that is amenable to an existence and uniqueness theory, as well as
the deÔ¨Ånition of approximation methods.
Proposition 4.1 Assume that u ‚ààH2(Œ©) solves the PDE in problem (4.1), i.e., the
Ô¨Årst equation in (4.1). Then, for all v ‚ààH1
0(Œ©), we have

Œ©
‚àáu ¬∑ ‚àáv dx +

Œ©
cuv dx =

Œ©
f v dx.
(4.2)
¬© Springer International Publishing Switzerland 2016
H. Le Dret and B. Lucquin, Partial Differential Equations:
Modeling, Analysis and Numerical Approximation, International Series
of Numerical Mathematics 168, DOI 10.1007/978-3-319-27067-8_4
117

118
4
The Variational Formulation of Elliptic PDEs
Proof We take an arbitrary v ‚ààH1
0(Œ©), multiply the equation by v, which yields
‚àí(Œîu)v + cuv = f v,
and then integrate the result over Œ©. Indeed, every term is integrable. First of all, u ‚àà
H2(Œ©) hence Œîu ‚ààL2(Œ©), and v ‚ààL2(Œ©) imply (Œîu)v ‚ààL1(Œ©). Moreover, c ‚àà
L‚àû(Œ©), u ‚ààL2(Œ©) and v ‚ààL2(Œ©) imply cuv ‚ààL1(Œ©). Finally, f ‚ààL2(Œ©) implies
f v ‚ààL1(Œ©). We thus obtain
‚àí

Œ©
(Œîu)v dx +

Œ©
cuv dx =

Œ©
f v dx.
We now use Green‚Äôs formula (3.15), according to which

Œ©
(Œîu)v dx = ‚àí

Œ©
‚àáu ¬∑ ‚àáv dx +

‚àÇŒ©
Œ≥1(u)Œ≥0(v) dŒì,
and we conclude since v ‚ààH1
0(Œ©) is equivalent to Œ≥0(v) = 0.
‚ñ°
Concerning the second equation in (4.1), i.e., the boundary condition, we have to
interpret it in the sense of traces in the Sobolev context. In fact, as we have seen in
the previous chapter, the reasonable way to impose the Dirichlet boundary condition
is to require that Œ≥0(u) = 0, or in other words, that u ‚ààH1
0(Œ©). The conjunction of
(4.2) with the requirement that u ‚ààH1
0(Œ©) is called the variational formulation of
problem (4.1). The functions v are called test-functions.
Let us rewrite the variational formulation in a standard, abstract form. We let
V = H1
0(Œ©), it is a Hilbert space. Then we have a bilinear form on V √ó V
a(u, v) =

Œ©
(‚àáu ¬∑ ‚àáv + cuv) dx
and a linear form on V
‚Ñì(v) =

Œ©
f v dx.
The variational formulation then reads: Find u ‚ààV such that
‚àÄv ‚ààV,
a(u, v) = ‚Ñì(v),
(4.3)
and we have shown that a solution of the boundary value problem with the additional
regularity u ‚ààH2(Œ©) is a solution of the variational problem (4.3).
Now what about the reverse implication? Does a solution of the variational prob-
lem solve the boundary value problem? The answer is basically yes, the two problems
are equivalent.

4.1 Model Boundary Value Problems
119
Proposition 4.2 Assume that u ‚ààH1
0(Œ©) solves the variational problem (4.3). Then
we have
‚àíŒîu + cu = f in the sense o f D‚Ä≤(Œ©).
Moreover Œîu ‚ààL2(Œ©) and the PDE is also satisÔ¨Åed almost everywhere on Œ©.
Proof First of all, note that the variational formulation (4.2) makes sense for u ‚àà
H1
0(Œ©). We have D(Œ©) ‚äÇH1
0(Œ©), therefore we can take v = œï ‚ààD(Œ©) as test-
function in (4.3). Let us examine each term separately.
For the Ô¨Årst term, we have

Œ©
‚àáu ¬∑ ‚àáœï dx =

Œ©
 d

i=1
‚àÇiu‚àÇiœï

dx =
d

i=1

Œ©
‚àÇiu‚àÇiœï dx

=
d

i=1
‚ü®‚àÇiu, ‚àÇiœï‚ü©=
d

i=1
‚àí‚ü®‚àÇiiu, œï‚ü©= ‚àí
 d

i=1
‚àÇiiu, œï

= ‚àí‚ü®Œîu, œï‚ü©,
by deÔ¨Ånition of distributional derivatives. Similarly

Œ©
cuœï dx = ‚ü®cu, œï‚ü©and

Œ©
f œï dx = ‚ü®f, œï‚ü©.
Therefore, we have for all œï ‚ààD(Œ©)
‚ü®‚àíŒîu + cu ‚àíf, œï‚ü©= 0
or
‚àíŒîu + cu ‚àíf = 0 in the sense of D‚Ä≤(Œ©)
andthePDEissatisÔ¨Åedinthesenseofdistributions.TheDirichletboundarycondition
is also satisÔ¨Åed by the simple fact that u ‚ààH1
0(Œ©), hence the boundary value problem
is solved.
To conclude, we note that Œîu = cu ‚àíf ‚ààL2(Œ©). This implies that the distrib-
ution Œîu is an L2-function and thus that the PDE is satisÔ¨Åed almost everywhere in
Œ©.
‚ñ°
Remark 4.1 Note that the condition Œ≥0(u) = 0 also means in a sense that u vanishes
almost everywhere on the boundary ‚àÇŒ©.
‚ñ°
Remark 4.2 The two problems are thus equivalent, except for the fact that we have
assumedu ‚ààH2(Œ©)inonedirection,andonlyrecuperatedŒîu ‚ààL2(Œ©)intheother.1
Actually, the assumption u ‚ààH2(Œ©) is somewhat artiÔ¨Åcial and made only to make
1The Laplacian is a speciÔ¨Åc linear combination of some of the second order derivatives. So it being
in L2 is a priori less than all individual second order derivatives, even those not appearing in the
Laplacian, being in L2, except when d = 1.

120
4
The Variational Formulation of Elliptic PDEs
use of Green‚Äôs formula (3.15). It is possible to dispense with it with a little more
work, but that would take us too far.
It should be noted in any case, that if u ‚ààH1
0(Œ©), Œîu ‚ààL2(Œ©) and Œ© is for exam-
ple of class C2, then u ‚ààH2(Œ©). This is very profound result in elliptic regularity
theory, far beyond the scope of these notes (see [15, 25, 35] for example). We will
come back to this point at the end of the chapter. It is trivial in dimension one though.
Of course, so far we have no indication that either problem has a solution. The
fact is that the variational formulation is signiÔ¨Åcantly easier to treat, once the right
point of view is found. And the right point of view is an abstract point of view, as is
often the case, more of this in Sect.4.2.
‚ñ°
Before we start delving in the abstract, let us give a couple more model problems
of a different kind. First is the higher dimensional analogue of the Neumann boundary
condition already seen in one dimension in Chap.2:
	 ‚àíŒîu + cu = f in Œ©,
‚àÇu
‚àÇn = g on ‚àÇŒ©.
(4.4)
When g = 0, it is naturally called a homogeneous Neumann boundary condition.
In terms of modeling, the Neumann condition is a Ô¨Çux condition. For instance, in
the heat equilibrium interpretation, the condition corresponds to an imposed heat
Ô¨Çux through the boundary, as opposed to the Dirichlet condition which imposes a
given temperature on the boundary. The case g = 0 corresponds to perfect thermal
insulation: no heat is allowed to enter or leave Œ©.
Let us derive the variational formulation informally. Assume Ô¨Årst that u ‚ààH2(Œ©),
take v ‚ààH1(Œ©), multiply, integrate and use Green‚Äôs formula to obtain
‚àÄv ‚ààH1(Œ©),

Œ©
(‚àáu ¬∑ ‚àáv + cuv) dx =

Œ©
f v dx +

‚àÇŒ©
gŒ≥0(v) dŒì.
Note the different test-function space and the additional boundary term in the right-
hand side.
The converse is more interesting. Let u ‚ààH2(Œ©) be a solution of the above vari-
ational problem. Taking Ô¨Årst v = œï ‚ààD(Œ©), we obtain
‚àíŒîu + cu = f in the sense of D‚Ä≤(Œ©)
exactly as in the Dirichlet case. Of course, a test-function with compact support
does not see what happens on the boundary, and no information on the Neumann
condition is recovered. Thus, in a second step, we take v arbitrary in H1(Œ©). By
Green‚Äôs formula again, we have

Œ©
‚àáu ¬∑ ‚àáv dx = ‚àí

Œ©
(Œîu)v dx +

‚àÇŒ©
Œ≥1(u)Œ≥0(v) dŒì.

4.1 Model Boundary Value Problems
121
Recall that the normal trace Œ≥1(u) plays the role of the normal derivative. Since u is
a solution of the variational problem, it follows that

Œ©
(‚àíŒîu + cu)v dx +

‚àÇŒ©
Œ≥1(u)Œ≥0(v) dŒì =

Œ©
f v dx +

‚àÇŒ©
gŒ≥0(v) dŒì.
But we already know that

Œ©(‚àíŒîu + cu)v dx =

Œ© f v dx by the previous step, hence
we are left with

‚àÇŒ©
Œ≥1(u)Œ≥0(v) dŒì =

‚àÇŒ©
gŒ≥0(v) dŒì,
for all v ‚ààH1(Œ©). For simplicity, we assume here that g ‚ààH1/2(‚àÇŒ©), the image
of the trace Œ≥0, see Proposition 3.17 of Chap.3, and that Œ© is smooth. Since u ‚àà
H2(Œ©), it follows that Œ≥1(u) = d
i=1 Œ≥0(‚àÇiu)ni ‚ààH1/2(‚àÇŒ©). Therefore, there exists
v ‚ààH1(Œ©) such that Œ≥0(v) = Œ≥1(u) ‚àíg. With this choice of v, we obtain

‚àÇŒ©
(Œ≥1(u) ‚àíg)2 dŒì = 0,
hence Œ≥1(u) = g, which is the Neumann condition. The last hypotheses (u ‚ààH2(Œ©)
and g ‚ààH1/2(‚àÇŒ©)) are made for brevity only. They are not at all necessary to con-
clude.
Another problem of interest is the non homogeneous Dirichlet problem.
‚àíŒîu + cu = f in Œ©,
u = g on ‚àÇŒ©,
with g ‚ààH3/2(‚àÇŒ©).2 This problem is reduced to the homogeneous problem by taking
a function G ‚ààH2(Œ©) such that Œ≥0(G) = g and setting U = u ‚àíG. Then clearly
U ‚ààH1
0(Œ©) and ‚àíŒîU + cU = ‚àíŒîu + cu + ŒîG ‚àícG = f + ŒîG ‚àícG. Then we
just write the variational formulation of the homogeneous problem for U with right-
hand side F = f + ŒîG ‚àícG ‚ààL2(Œ©). Note that it is also possible to solve the
problem under the more natural assumption g ‚ààH1/2(‚àÇŒ©).
The Dirichlet and Neumann conditions can be mixed together, but not at the same
place on the boundary, yielding the so-called mixed problem. More precisely, let Œì1
and Œì2 be two subsets of ‚àÇŒ© such that Œì1 ‚à©Œì2 = ‚àÖ, ¬ØŒì1 ‚à™¬ØŒì2 = ‚àÇŒ©. Then the mixed
problem reads
‚éß
‚é™‚é®
‚é™‚é©
‚àíŒîu + cu = f in Œ©,
u = g1 on Œì1,
‚àÇu
‚àÇn = g2 on Œì2.
(4.5)
2The space H3/2(‚àÇŒ©) is the space of traces of H2(Œ©) functions.

122
4
The Variational Formulation of Elliptic PDEs
The variational formulation for the mixed problem (in the case g1 = 0 for brevity, if
not follow the above route) is to let V = {v ‚ààH1(Œ©); Œ≥0(v) = 0 on Œì1} and
‚àÄv ‚ààV,

Œ©
(‚àáu ¬∑ ‚àáv + cuv) dx =

Œ©
f v dx +

Œì2
g2Œ≥0(v) dŒì,
with u ‚ààV . Note that the mixed problem reduces to the Neumann problem when
meas (Œì1) Ã∏= 0 and to the Dirichlet problem when meas (Œì2) Ã∏= 0.
Remark 4.3 An important rule of thumb to be remembered from the above examples
is that (homogeneous) Dirichlet conditions are taken into account in the test-function
space, whereas Neumann boundary conditions are taken into account in the linear
form via boundary integrals and a larger test-function space.
4.2
Abstract Variational Problems
We now describe the general abstract framework for all variational problems. We
have just seen that some boundary value problems can be recast in the following
form. We are given a Hilbert space V (in the examples we have seen before H1
0(Œ©)
or H1(Œ©)), a bilinear form a on V √ó V and a linear form ‚Ñìon V . The solution of
the boundary value problem is then a solution of problem (4.3). At this point, we
completely abstract the boundary value problem aspect.
DeÔ¨Ånition 4.1 An abstract variational problem consists in Ô¨Ånding u ‚ààV such that
‚àÄv ‚ààV,
a(u, v) = ‚Ñì(v),
(4.6)
where V is a Hilbert space, a is a bilinear form on V √ó V and ‚Ñìis a linear form
on V .
The basic tool for solving abstract variational problems is the Lax‚ÄìMilgram the-
orem [55]. This theorem is important, not because it is in any way difÔ¨Åcult, which it
is not, but because it has a very wide range of applicability as we will see later.
Theorem 4.1 (Lax‚ÄìMilgram) Let V be a Hilbert space, a be a bilinear form and ‚Ñì
be a linear form. Assume that
(i) The bilinear form a is continuous, i.e., there exists a constant M such that
|a(u, v)| ‚â§M‚à•u‚à•V ‚à•v‚à•V for all u, v ‚ààV ,
(ii) The bilinear form a is V -elliptic3, i.e., there exists a constant Œ± > 0 such that
a(v, v) ‚â•Œ±‚à•v‚à•2
V for all v ‚ààV ,
(iii) The linear form ‚Ñìis continuous, i.e., there exists a constant C such that
|‚Ñì(v)| ‚â§C‚à•v‚à•V for all v ‚ààV .
3This condition is also sometimes called coerciveness.

4.2 Abstract Variational Problems
123
Under the above assumptions, there exists a unique u ‚ààV that solves the abstract
variational problem (4.6).
Proof Let us start with the uniqueness. Let u1 and u2 be two solutions of prob-
lem (4.6). Since a is linear with respect to its Ô¨Årst argument, it follows that
a(u1 ‚àíu2, v) = 0 for all v ‚ààV . In particular, for v = u1 ‚àíu2, we obtain
0 = a(u1 ‚àíu2, u1 ‚àíu2) ‚â•Œ±‚à•u1 ‚àíu2‚à•2
V ,
so that ‚à•u1 ‚àíu2‚à•V = 0 since Œ± > 0.
We next prove the existence of a solution. We Ô¨Årst note that for all u ‚ààV , the
mapping v ‚Üía(u, v) is linear (by bilinearity of a) and continuous (by i) continuity of
a). Therefore, there exists a unique element Au of V ‚Ä≤ such that a(u, v) = ‚ü®Au, v‚ü©V ‚Ä≤,V .
Moreover, the bilinearity of a shows that the mapping A: V ‚ÜíV ‚Ä≤ thus deÔ¨Åned is
linear. It is also continuous since for all v ‚ààV with ‚à•v‚à•V ‚â§1,
|‚ü®Au, v‚ü©V ‚Ä≤,V | = |a(u, v)| ‚â§M‚à•u‚à•V ‚à•v‚à•V ‚â§M‚à•u‚à•V
so that
‚à•Au‚à•V ‚Ä≤ = sup
‚à•v‚à•V ‚â§1
|‚ü®Au, v‚ü©V ‚Ä≤,V | ‚â§M‚à•u‚à•V .
We rewrite the variational problem as: Find u ‚ààV such that
‚àÄv ‚ààV,
‚ü®Au ‚àí‚Ñì, v‚ü©V ‚Ä≤,V = 0
or
Au = ‚Ñì,
and this is where the continuity of ‚Ñìis used.
Thus, proving the existence is equivalent to showing that the mapping A is onto.4
We do this in two independent steps: we show that im A is closed on the one hand
and that it is dense on the other hand.5 For the closedness of the image, we use
assumption (ii) of V -ellipticity. Let ‚Ñìn be a sequence in im A such that ‚Ñìn ‚Üí‚Ñìin V ‚Ä≤.
We want to show that ‚Ñì‚ààim A, which will imply that im A is closed. The sequence
‚Ñìn is a Cauchy sequence in V ‚Ä≤, and for all n, there exists un ‚ààV such that Aun = ‚Ñìn.
By V -ellipticity,
‚à•un ‚àíum‚à•2
V ‚â§1
Œ± a(un ‚àíum, un ‚àíum) = 1
Œ± ‚ü®Aun ‚àíAum, un ‚àíum‚ü©V ‚Ä≤,V
= 1
Œ± ‚ü®‚Ñìn ‚àí‚Ñìm, un ‚àíum‚ü©V ‚Ä≤,V ‚â§1
Œ± ‚à•‚Ñìn ‚àí‚Ñìm‚à•V ‚Ä≤‚à•un ‚àíum‚à•V ,
4Since we already know it is one-to-one, it will then be an isomorphism.
5This is a pretty common strategy, to be kept in mind.

124
4
The Variational Formulation of Elliptic PDEs
by the deÔ¨Ånition of the dual norm. Therefore, if ‚à•un ‚àíum‚à•V = 0 we are happy,
otherwise we divide by ‚à•un ‚àíum‚à•V and in both cases
‚à•un ‚àíum‚à•V ‚â§1
Œ± ‚à•‚Ñìn ‚àí‚Ñìm‚à•V ‚Ä≤,
so that un is a Cauchy sequence in V . Since V is complete, there exists u ‚ààV such
that un ‚Üíu in V . Since A is continuous, it follows that ‚Ñìn = Aun ‚ÜíAu in V ‚Ä≤. Hence
‚Ñì= Au ‚ààim A.
To show the density, we show that (im A)‚ä•= {0} (according to Lemma 3.1 of
Chap.3). We note that (Au|‚Ñì)V ‚Ä≤ = (œÉAu|œÉ‚Ñì)V = ‚ü®Au, œÉ‚Ñì‚ü©V ‚Ä≤,V = a(u, œÉ‚Ñì), where œÉ
is the Riesz isomorphism. Let ‚Ñì‚àà(im A)‚ä•. For all u ‚ààV , we thus have a(u, œÉ‚Ñì) = 0.
In particular, for u = œÉ‚Ñì, we obtain 0 = a(œÉ‚Ñì, œÉ‚Ñì) ‚â•Œ±‚à•œÉ‚Ñì‚à•2
V by V -ellipticity. Since
Œ± > 0, it follows that ‚Ñì= 0.
‚ñ°
Remark 4.4 There is another classical proof of the Lax‚ÄìMilgram theorem using the
Banach Ô¨Åxed point theorem [15, 19, 25]. Note that if V is separable, there is yet
another proof based on the Galerkin method which can be generalized to nonlinear
variational problems [57]. Finally, there is a generalization of the Lax‚ÄìMilgram
theorem, known as the Stampacchia theorem, [15], which is used to solve variational
inequalities, see for example [21].
Remark 4.5 It should be noted that the Lax‚ÄìMilgram theorem is not a particular
case of the Riesz theorem. It is actually more general, since it applies to bilinear
forms that are not necessarily symmetric, and it implies the Riesz theorem when the
bilinear form is just the scalar product.
Sometimes when the bilinear form a is symmetric, people think it advantageous
to apply Riesz‚Äôs theorem in place of the Lax‚ÄìMilgram theorem. This is usually an
illusion: indeed, if a new scalar product deÔ¨Åned by the bilinear form is introduced,
in order to apply Riesz‚Äôs theorem, it is necessary to show that the space equipped
with the new scalar product is still a Hilbert space, i.e., is complete. This is done
by V -ellipticity, hence nothing is gained (although this is the part that people who
think they are seeing a good deal usually forget). The continuity of the linear form
for the new norm must also be checked, which amounts to having the bilinear form
and linear form continuous for the original norm, again, no gain.
The only case when Riesz‚Äôs theorem can be deemed advantageous over the Lax‚Äì
Milgram theorem, is when both above facts to be checked are already known. An
example is the bilinear form a(u, v) =

Œ© ‚àáu ¬∑ ‚àáv dx on V = H1
0(Œ©).
‚ñ°
Remark 4.6 In the case of complex Hilbert spaces and complex-valued variational
problems, the Lax‚ÄìMilgram theorem still holds true for a bilinear or sesquilinear
form. The V -ellipticity assumption can even be relaxed to only involve the real part
of a, i.e., Re (a(u, u)) ‚â•Œ±‚à•u‚à•2 (or the imaginary part), which is rather useful as the
imaginary part can then be pretty arbitrary (exercise).
‚ñ°
Remark 4.7 Let us emphasize again that the Lax‚ÄìMilgram theorem only gives sufÔ¨Å-
cient conditions for existence and uniqueness of the solution of an abstract variational

4.2 Abstract Variational Problems
125
problem. More speciÔ¨Åcally, V -ellipticity is not necessary. Indeed, when V is Ô¨Ånite
dimensional, V -ellipticity is just the positive deÔ¨Åniteness of the operator A (identi-
fying V and V ‚Ä≤ without second thoughts). Obviously, there are more isomorphisms
in L (V ) than just positive deÔ¨Ånite linear mappings.
Replacing V -ellipticity with the following inf-sup condition:
inf
u‚ààV \{0}
sup
v‚ààV \{0}
a(u, v)
‚à•u‚à•V ‚à•v‚à•V
> 0,
combined with the requirement that if v is such that a(u, v) = 0 for all u ‚ààV , then
v = 0, we obtain a set of necessary and sufÔ¨Åcient conditions, as is easily seen along
the same lines as before [7, 41]. Both conditions are clearly implied by V -ellipticity.
As a rule, elliptic problems are usually amenable to the Lax‚ÄìMilgram theorem.
‚ñ°
The linear form in the right-hand side of a variational problem should be thought
of as data. In this respect, the solution depends continuously on the data.
Proposition 4.3 The mapping V ‚Ä≤ ‚ÜíV , ‚Ñì‚Üíu deÔ¨Åned by the Lax‚ÄìMilgram theo-
rem is linear and continuous.
Proof The operator A is linear and invertible, therefore so is A‚àí1. The continuity of
A‚àí1 stems from Banach‚Äôs theorem, see [15]. We actually have a more precise result
since
Œ±‚à•u‚à•2
V ‚â§a(u, u) = ‚Ñì(u) ‚â§‚à•‚Ñì‚à•V ‚Ä≤‚à•u‚à•V ,
hence
‚à•u‚à•V ‚â§1
Œ± ‚à•‚Ñì‚à•V ‚Ä≤,
which shows that the continuity constant of A‚àí1 is smaller than the inverse of the
V -ellipticity constant of a.
‚ñ°
Proposition 4.4 Let the hypotheses of the Lax‚ÄìMilgram theorem be satisÔ¨Åed.
Assume in addition that the bilinear form a is symmetric. Then the solution u of
the variational problem (4.6) is also the unique solution of the minimization prob-
lem:
J(u) = inf
v‚ààV J(v) with
J(v) = 1
2a(v, v) ‚àí‚Ñì(v).
Proof Let u be the Lax‚ÄìMilgram solution. For all v ‚ààV , we let w = v ‚àíu and
J(v) = J(u + w) = 1
2a(u, u) + 1
2a(u, w) + 1
2a(w, u) + 1
2a(w, w) ‚àí‚Ñì(u) ‚àí‚Ñì(w)
= J(u) + a(u, w) ‚àí‚Ñì(w) + 1
2a(w, w)
‚â•J(u),

126
4
The Variational Formulation of Elliptic PDEs
since a(w, w) ‚â•0. Make note of where the symmetry is used. Hence, u minimizes
J on V .
Conversely, assume that u minimizes J on V . Then, for all Œª > 0 and all v ‚ààV ,
we have J(u + Œªv) ‚â•J(u). Expanding the left-hand side, we get
1
2a(u, u) + Œªa(u, v) + Œª2
2 a(v, v) ‚àí‚Ñì(u) ‚àíŒª‚Ñì(v) ‚â•J(u)
so that dividing by Œª
a(u, v) ‚àíl(v) + Œª
2a(v, v) ‚â•0.
We then let Œª ‚Üí0, hence
a(u, v) ‚àíl(v) ‚â•0,
and Ô¨Ånally change v in ‚àív to obtain
a(u, v) ‚àíl(v) = 0,
for all v ‚ààV .
‚ñ°
Remark 4.8 Taking Œª > 0, dividing by Œª and then letting Œª ‚Üí0 is quite clever, and
known as Minty‚Äôs trick.
‚ñ°
Remark 4.9 When the bilinear form a is not symmetric, we can still deÔ¨Åne the
functional J in the same fashion as before and try to minimize it. It is clear from the
above proof that the minimizing element u does not solve the variational problem
associated with a but the variational problem associated with the symmetric part of a.
Note that u exists because we can apply the Lax‚ÄìMilgram theorem to the symmetric
part of the bilinear form a. Of course, when both variational problems are translated
into PDEs, we get entirely different equations.
‚ñ°
4.3
Application to the Model Problems, and More
Here again, Œ© is a Lipschitz open subset of Rd. We now apply the previous abstract
results to concrete examples. We start with the Ô¨Årst model problem (4.1).
Proposition 4.5 Let f ‚ààL2(Œ©), c ‚ààL‚àû(Œ©). Assume that c ‚â•0. Then the problem:
Find u ‚ààV = H1
0(Œ©) such that
‚àÄv ‚ààV,

Œ©
(‚àáu ¬∑ ‚àáv + cuv) dx =

Œ©
f v dx,
has one and only one solution.

4.3 Application to the Model Problems, and More
127
Proof We already know that V is a Hilbert space, for both scalar products that we
deÔ¨Åned earlier. Of course
a(u, v) =

Œ©
(‚àáu ¬∑ ‚àáv + cuv) dx
clearly deÔ¨Ånes a bilinear form on V √ó V and
‚Ñì(v) =

Œ©
f v dx
a linear form on V . Hence, we have an abstract variational problem. Let us try and
apply the Lax‚ÄìMilgram theorem. We need to check the theorem hypotheses. For
deÔ¨Åniteness, we choose to work with the full H1 norm.
First of all, for all (u, v) ‚ààV √ó V ,
|a(u, v)| =


Œ©
(‚àáu ¬∑ ‚àáv + cuv) dx

‚â§

Œ©
|‚àáu ¬∑ ‚àáv + cuv| dx
‚â§

Œ©
|‚àáu ¬∑ ‚àáv| dx +

Œ©
|cuv| dx
‚â§‚à•‚àáu‚à•L2(Œ©)‚à•‚àáv‚à•L2(Œ©) + ‚à•c‚à•L‚àû(Œ©)‚à•u‚à•L2(Œ©)‚à•v‚à•L2(Œ©)
‚â§max

1, ‚à•c‚à•L‚àû(Œ©)

‚à•u‚à•H1(Œ©)‚à•v‚à•H1(Œ©),
by the Cauchy‚ÄìSchwarz inequality to go from the third line to the fourth line, and
again the Cauchy‚ÄìSchwarz inequality in R2 to go from the fourth line to the Ô¨Åfth
line, hence the continuity of the bilinear form a.
Next is the V -ellipticity. For all v ‚ààV , we have
a(v, v) =

Œ©
(‚à•‚àáv‚à•2 + cv2) dx ‚â•

Œ©
‚à•‚àáv‚à•2 dx ‚â•Œ±‚à•v‚à•2
H1(Œ©)
with Œ± = (C2 + 1)‚àí1/2 > 0 by Corollary 3.3 of Chap.3, where C is the Poincar√©
inequality constant, and since c ‚â•0.
Finally, we check the continuity of the linear form. For all v ‚ààV ,
|‚Ñì(v)| =


Œ©
f v dx
 ‚â§‚à•f ‚à•L2(Œ©)‚à•v‚à•L2(Œ©) ‚â§‚à•f ‚à•L2(Œ©)‚à•v‚à•H1(Œ©)
by the Cauchy‚ÄìSchwarz inequality again.
All the hypotheses of the Lax‚ÄìMilgram theorem are satisÔ¨Åed, therefore there is
one and only one solution u ‚ààV .
‚ñ°

128
4
The Variational Formulation of Elliptic PDEs
Remark 4.10 Now is a time to celebrate since we have successfully solved our Ô¨Årst
boundary value problem in arbitrary dimension. Indeed, we have already seen that
any solution of the variational problem is a solution of the PDE in the distributional
sense and in the L2 sense. The solution u depends continuously in H1 on f in L2.
Note that we have also solved the non homogeneous Dirichlet problem at the same
time.
It is an instructive exercise to redo the proof using the H1 semi-norm in place of
the full norm. The same ingredients are used, but not at the same spots.
This is a case of a symmetric bilinear form, therefore the solution u also minimizes
the so-called energy functional
J(v) = 1
2

Œ©
(‚à•‚àáv‚à•2 + cv2) dx ‚àí

Œ©
f v dx
over V .
‚ñ°
Remark 4.11 It should be noted that the positivity condition c ‚â•0 is by no means
a necessary condition for existence and uniqueness via the Lax‚ÄìMilgram theorem.
With a little more work, it is not too hard to allow the function c to take some negative
values. However, we have seen an example at the very beginning of Chap.1 with a
negative function c for which existence and uniqueness fails.
One should also be aware that there is an existence and uniqueness theory that
goes beyond the Lax‚ÄìMilgram theorem, which only gives a sufÔ¨Åcient condition for
existence and uniqueness.
‚ñ°
Let us now consider the non homogeneous Neumann problem (4.4). The hypothe-
ses are slightly different.
Proposition 4.6 Let f ‚ààL2(Œ©), c ‚ààL‚àû(Œ©), g ‚ààL2(‚àÇŒ©). Assume that there exists
a constant c0 > 0 such that c ‚â•c0 almost everywhere. Then the problem: Find u ‚àà
V = H1(Œ©) such that
‚àÄv ‚ààV,

Œ©
(‚àáu ¬∑ ‚àáv + cuv) dx =

Œ©
f v dx +

‚àÇŒ©
gŒ≥0(v) dx,
has one and only one solution.
Proof We have a different Hilbert space (but known to be Hilbert, nothing to check
here), the same bilinear form and a different linear form
‚Ñì(v) =

Œ©
f v dx +

‚àÇŒ©
gŒ≥0(v) dx.

4.3 Application to the Model Problems, and More
129
We have already shown that the bilinear form is continuous in the H1 norm.6
The V -ellipticity is clear since, for all v ‚ààV ,
a(v, v) =

Œ©
(‚à•‚àáv‚à•2 + cv2) dx ‚â•

Œ©
‚à•‚àáv‚à•2 dx + c0

Œ©
v2 dx ‚â•min(1, c0)‚à•v‚à•2
H1(Œ©),
with min(1, c0) > 0. The continuity of the linear form is also clear
|‚Ñì(v)| ‚â§‚à•f ‚à•L2(Œ©)‚à•v‚à•L2(Œ©)+‚à•g‚à•L2(‚àÇŒ©)‚à•Œ≥0(v)‚à•L2(‚àÇŒ©)
‚â§(‚à•f ‚à•L2(Œ©) + CŒ≥0‚à•g‚à•L2(‚àÇŒ©))‚à•v‚à•H1(Œ©)
by the Cauchy‚ÄìSchwarz inequality, where CŒ≥0 is continuity constant of the trace
mapping.
‚ñ°
The mixed problem (4.5) is a nice mixture of the Dirichlet and the Neumann
problems.
Proposition 4.7 Same hypotheses as in Proposition 4.6 and let Œì1 and Œì2 be two
subsets of ‚àÇŒ© such that Œì1 ‚à©Œì2 = ‚àÖ, ¬ØŒì1 ‚à™¬ØŒì2 = ‚àÇŒ© and meas(Œì1) Ã∏= 0. Then the
problem: Find u ‚ààV = {v ‚ààH1(Œ©); Œ≥0(v) = 0 on Œì1} such that
‚àÄv ‚ààV,

Œ©
(‚àáu ¬∑ ‚àáv + cuv) dx =

Œ©
f v dx +

Œì2
gŒ≥0(v) dŒì,
has one and only one solution.
Proof The only real difference with Proposition 4.6 lies with the space V , which we
do not know yet to be a Hilbert space. It sufÔ¨Åces to show that V is a closed subspace
of H1(Œ©). Let vn be a sequence in V such that vn ‚Üív in H1(Œ©). By continuity
of the trace mapping, we have Œ≥0(vn) ‚ÜíŒ≥0(v) in L2(‚àÇŒ©). Therefore, there exists
a subsequence Œ≥0(vnp) that converges to Œ≥0(v) almost everywhere on ‚àÇŒ©. Since
Œ≥0(vn) = 0 almost everywhere on Œì1, it follows that Œ≥0(v) = 0 almost everywhere
on Œì1, hence v ‚ààV , which is thus closed.
‚ñ°
Proposition 4.7 also holds true under the less demanding hypothesis c ‚â•0, using
a different argument for V -ellipticity.
A natural question arises about the Neumann problem for c = 0, see Chap.2,
Sect.2.4 in one dimension. Now, this is an entirely different problem from the pre-
vious ones. First we have to Ô¨Ånd the variational formulation of the boundary value
problem and show that it is equivalent to the boundary value problem, then we have
to apply the Lax‚ÄìMilgram theorem.
Let us thus consider the Neumann problem
‚àíŒîu = f in Œ©,
‚àÇu
‚àÇn = g on ‚àÇŒ©,
(4.7)
6If we had worked with the semi-norm for the Dirichlet problem, we would have had to do the
continuity all over again here‚Ä¶

130
4
The Variational Formulation of Elliptic PDEs
in a Lipschitz open set Œ© in Rd. We see right away that things are going to be different
since we do not have uniqueness here. Indeed, if u is a solution, then u + s is also
a solution for any constant s. Furthermore, by Green‚Äôs formula (3.15) with v = 1, it
follows that if there is a solution, then, necessarily

Œ©
f dx +

‚àÇŒ©
g dŒì = 0.
(4.8)
If the data f, g does not satisfy the compatibility condition (4.8), there is thus no
solution. The two remarks, non uniqueness and non existence, are actually dual to
each other.
There are several ways of going around both problems, thus several variational
formulations.7 We choose to set
V =

v ‚ààH1(Œ©);

Œ©
v dx = 0

.
(4.9)
This is well deÔ¨Åned, since Œ© is bounded and we thus have H1(Œ©) ‚äÇL2(Œ©) ‚äÇ
L1(Œ©). Note that V is the L2-orthogonal in H1(Œ©), which also happens to be the
H1-orthogonal in this case, to the one-dimensional space of constant functions. Note
that these functions are precisely the cause of non uniqueness.
Lemma 4.1 The space V is a Hilbert space for the scalar product of H1(Œ©).
Proof It sufÔ¨Åces to show that V is closed. Let vn be a sequence in V such that vn ‚Üív
in H1(Œ©). Of course, vn ‚Üív in L2(Œ©) and by the Cauchy‚ÄìSchwarz inequality,
vn ‚Üív in L1(Œ©). Therefore
0 =

Œ©
vn dx ‚Üí

Œ©
v dx,
and v ‚ààV .
‚ñ°
We introduce the bilinear form a deÔ¨Åned on V √ó V by a(u, v) =

Œ© ‚àáu ¬∑ ‚àáv dx
and the linear form ‚ÑìdeÔ¨Åned on V by ‚Ñì(v) =

Œ© f v dx +

‚àÇŒ© gŒ≥0(v) dŒì .
Proposition 4.8 Assume that f ‚ààL2(Œ©), g ‚ààL2(‚àÇŒ©) satisfy the compatibility con-
dition(4.8).Then,anysolutionu ‚ààH2(Œ©)oftheNeumannproblem(4.7)isasolution
of the variational problem deÔ¨Åned by the triple (V, a, ‚Ñì). Conversely, any solution
u ‚ààH2(Œ©) of the variational problem is a solution of problem (4.7).
Proof Multiplying the PDE by v ‚ààV and using Green‚Äôs formula, we easily see that
if u ‚ààH2(Œ©) solves problem (4.7), then we have for all v ‚ààV , a(u, v) = ‚Ñì(v).
Conversely, let us be given a function u ‚ààV ‚à©H2(Œ©) such that for all v ‚ààV ,
a(u, v) = ‚Ñì(v). We would like to proceed as before and take v ‚ààD(Œ©) to derive the
PDE. This does not work here because D(Œ©) Ã∏‚äÇV . For all œï ‚ààD(Œ©), we set
7We have always said the variational formulation, but there is no evidence that it is unique in general.

4.3 Application to the Model Problems, and More
131
œà = œï ‚àí
1
meas Œ©

Œ©
œï(x) dx,
so that œà ‚ààV and we can use œà as a test-function. Now œï and œà differ by a constant
k =
1
meas Œ©

Œ© œï(x) dx, therefore ‚àáœà = ‚àáœï. We thus obtain,

Œ©
‚àáu ¬∑ ‚àáœï dx =

Œ©
‚àáu ¬∑ ‚àáœà dx =

Œ©
f œà dx +

‚àÇŒ©
gœà dŒì
=

Œ©
f (œï + k) dx +

‚àÇŒ©
g(œï + k) dŒì
=

Œ©
f œï dx + k

Œ©
f dx +

‚àÇŒ©
g dŒì

=

Œ©
f œï dx,
since œï vanishes on ‚àÇŒ© and f, g satisfy condition (4.8). So we can deduce right
away that ‚àíŒîu = f in the sense of distributions, and since f ‚ààL2(Œ©) in the sense
of L2(Œ©) as well.
We next pick an arbitrary v ‚ààV and apply Green‚Äôs formula again. This yields

Œ©
f v dx +

‚àÇŒ©
gŒ≥0(v) dŒì = ‚àí

Œ©
(Œîu)v dx +

‚àÇŒ©
Œ≥1(u)Œ≥0(v) dŒì.
Hence, taking into account that ‚àíŒîu = f , we obtain

‚àÇŒ©
(g ‚àíŒ≥1(u))Œ≥0(v) dŒì = 0
for all v ‚ààV . Now it is clear that Œ≥0(V ) = H1/2(‚àÇŒ©). Indeed, let us pick a Œ∏ ‚àà
D(Œ©) such that

Œ© Œ∏ dx = 1. Then, for all w ‚ààH1(Œ©), v = w ‚àí

Œ© w dx

Œ∏ ‚ààV
and Œ≥0(v) = Œ≥0(w). Therefore, there are enough test-functions in V to conclude that
Œ≥1(u) = g, since H1/2(‚àÇŒ©) is dense in L2(‚àÇŒ©).
‚ñ°
Remark 4.12 It is possible to establish a variational formulation of the Neumann
problem without the artiÔ¨Åcial hypothesis u ‚ààH2(Œ©).
‚ñ°
To apply the Lax‚ÄìMilgram theorem, we need a new inequality.
Theorem 4.2 (Poincar√©‚ÄìWirtinger inequality) Assume that Œ© is connected. There
exists a constant C such that, for all v ‚ààH1(Œ©),
v ‚àí
1
meas Œ©

Œ©
v dx

L2(Œ©) ‚â§C‚à•‚àáv‚à•L2(Œ©).
(4.10)
Proof We use a contradiction argument. Assume that there is no such constant C.
For all n ‚ààN‚àó, we can thus Ô¨Ånd vn ‚ààH1(Œ©) such that
vn ‚àí
1
meas Œ©

Œ©
vn dx

L2(Œ©) > n‚à•‚àávn‚à•L2(Œ©).

132
4
The Variational Formulation of Elliptic PDEs
In particular, the left-hand side is strictly positive. We let
wn =
vn ‚àí
1
meas Œ©

Œ© vn dx
vn ‚àí
1
meas Œ©

Œ© vn dx

L2(Œ©)
.
By construction, we have ‚à•wn‚à•L2(Œ©) = 1 and wn belongs to the L2-orthogonal of the
one-dimensional space of constant functions, which is closed in L2(Œ©).
Moreover, ‚àáwn = ‚àávn and we have
‚à•‚àáwn‚à•L2(Œ©) < 1
n ‚Üí0 when n ‚Üí+‚àû.
In particular, the sequence wn is bounded in H1(Œ©). By the Rellich theorem, see
Remark 3.18 of Chap.3, it is relatively compact in L2(Œ©). We may thus Ô¨Ånd a
subsequence wnp and an element w ‚ààL2(Œ©) such that wnp ‚Üíw strongly in L2(Œ©)
when p ‚Üí+‚àû.
On the one hand we have ‚à•w‚à•L2(Œ©) = 1 and w also belongs to the L2-orthogonal
of the space of constant functions.
On the other hand, ‚àáwnp ‚Üí0 strongly in L2(Œ©), hence in the sense of distribu-
tions, so that ‚àáw = 0. As Œ© is connected, this implies that w belongs to the space
of constant functions.
We thus see that w belongs to the intersection of one subspace and its orthogonal,
so that w = 0. This contradicts ‚à•w‚à•L2(Œ©) = 1.
‚ñ°
Remark 4.13 Even though there is a certain formal similarity with the Poincar√©
inequality, there are major differences. In particular, the Poincar√©‚ÄìWirtinger inequal-
ity fails for open sets that are not regular enough whereas no regularity is needed for
the Poincar√© inequality. Note that the contradiction argument above is not construc-
tive. It gives no indication about the actual value of C, as opposed to the proof of the
Poincar√© inequality given earlier.
‚ñ°
Proposition 4.9 Assume that Œ© is connected, f ‚ààL2(Œ©) and g ‚ààL2(‚àÇŒ©). Then
the problem: Find u ‚ààV , V given by (4.9), such that
‚àÄv ‚ààV,

Œ©
‚àáu ¬∑ ‚àáv dx =

Œ©
f v dx +

‚àÇŒ©
gŒ≥0(v) dŒì,
has one and only one solution.
Proof We have already shown that V is a Hilbert space for the H1 scalar product.
The continuity of both bilinear and linear forms have also already been proved. Only
the V -ellipticity remains.
For all v ‚ààV , we have

Œ© v dx = 0, hence by the Poincar√©‚ÄìWirtinger inequality
(4.10),
‚à•v‚à•2
H1(Œ©) = ‚à•v‚à•2
L2(Œ©) + ‚à•‚àáv‚à•2
L2(Œ©) ‚â§(C2 + 1)‚à•‚àáv‚à•2
L2(Œ©).

4.3 Application to the Model Problems, and More
133
Therefore,
a(v, v) = ‚à•‚àáv‚à•2
L2(Œ©) ‚â•Œ±‚à•v‚à•2
H1(Œ©)
with Œ± =
1
(C2+1) > 0.
‚ñ°
Remark 4.14 The compatibility condition (4.8) plays no role in the application of
the Lax‚ÄìMilgram theorem. So exercise: What happens when it is not satisÔ¨Åed? What
exactly are we solving then?
‚ñ°
Remark 4.15 Since the space V is a hyperplane of H1 that is L2 orthogonal to the
constants, it follows that the general solution of the Neumann problem is of the form
v + s, where v ‚ààV is the unique solution of the variational problem above and s ‚ààR
is arbitrary.
‚ñ°
We now introduce a new kind of boundary condition, the Fourier condition (also
called the Robin condition or the third boundary condition). The boundary value
problem reads
	 ‚àíŒîu + cu = f in Œ©,
bu + ‚àÇu
‚àÇn = g on ‚àÇŒ©,
(4.11)
where b and c are given functions. When b = 0, we recognize the Neumann problem
(and, in a sense, when b = +‚àûthe Dirichlet problem). This condition is called after
Fourier who introduced it in the context of the heat equation, see Chap.1, Sect.1.7.
In the heat interpretation, ‚àÇu
‚àÇn represents the heat Ô¨Çux through the boundary. Let us
assume that we are modeling a situation in which the boundary is actually a very
thin wall that insulates Œ© from the outside where the temperature is 0‚ó¶. If g = 0,
the Fourier condition states that ‚àÇu
‚àÇn = ‚àíbu, that is to say that the heat Ô¨Çux passing
through the wall is proportional to the temperature difference between the inside and
the outside. For this interpretation to be physically reasonable, it is clearly necessary
that b ‚â•0, i.e., the heat Ô¨Çows inwards when the outside is warmer than the inside
and conversely. It thus to be expected that the sign of b will play a role.
We follow the same pattern as before: First Ô¨Ånd a variational formulation for the
boundary value problem (4.11), second apply the Lax‚ÄìMilgram theorem to prove
existence and uniqueness. We introduce the triple
V = H1(Œ©),
a(u, v) =

Œ©
(‚àáu ¬∑ ‚àáv + cuv) dx +

‚àÇŒ©
bŒ≥0(u)Œ≥0(v) dŒì,
‚Ñì(v) =

Œ©
f v dx +

‚àÇŒ©
gŒ≥0(v) dŒì.
Proposition 4.10 Assume that we have f ‚ààL2(Œ©), g ‚ààL2(‚àÇŒ©), c ‚ààL‚àû(Œ©) and
b ‚ààL‚àû(‚àÇŒ©). Then, any solution u ‚ààH2(Œ©) of the Fourier problem (4.11) is a
solution of the variational problem deÔ¨Åned by the triple (V, a, ‚Ñì). Conversely, any
solution u ‚ààH2(Œ©) of the variational problem is a solution of problem (4.11).

134
4
The Variational Formulation of Elliptic PDEs
Proof As always, we multiply the PDE by v ‚ààV and use Green‚Äôs formula,

Œ©
(‚àáu ¬∑ ‚àáv + cuv) dx =

Œ©
f v dx +

‚àÇŒ©
Œ≥1(u)Œ≥0(v) dŒì
=

Œ©
f v dx +

‚àÇŒ©
(g ‚àíbŒ≥0(u))Œ≥0(v) dŒì,
hence

Œ©
(‚àáu ¬∑ ‚àáv + cuv) dx +

‚àÇŒ©
bŒ≥0(u)Œ≥0(v) dŒì =

Œ©
f v dx +

‚àÇŒ©
gŒ≥0(v) dŒì,
(4.12)
for all v ‚ààV .
Conversely, let us be given a solution u ‚ààH2(Œ©) of the variational problem (4.12).
Taking Ô¨Årst v = œï ‚ààD(Œ©), all the boundary integrals vanish and we obtain ‚àíŒîu +
cu = f exactly as before. Taking then v ‚ààH1(Œ©) arbitrary, using Green‚Äôs formula
and the PDE just obtained, we get

‚àÇŒ©
Œ≥1(u)Œ≥0(v) dŒì +

‚àÇŒ©
bŒ≥0(u)Œ≥0(v) dŒì =

‚àÇŒ©
gŒ≥0(v) dŒì,
so that

‚àÇŒ©
(Œ≥1(u) + bŒ≥0(u) ‚àíg)Œ≥0(v) dŒì = 0,
for all v ‚ààV = H1(Œ©), hence the Fourier boundary condition.
‚ñ°
Remark 4.16 A natural question to ask is why not keep the term Œ≥1(u) in the bilinear
form? The answer is that, while it is true that Œ≥1(u) exists when u ‚ààH2(Œ©) is a
solution of either the boundary value problem or the variational problem, it does not
exist for a general v ‚ààH1(Œ©), hence cannot appear in a bilinear form that is deÔ¨Åned
on H1(Œ©) √ó H1(Œ©). Besides, how would b appear otherwise?
‚ñ°
Let us give a Ô¨Årst existence and uniqueness result.
Proposition 4.11 Let
f ‚ààL2(Œ©), g ‚ààL2(‚àÇŒ©), c ‚ààL‚àû(Œ©) and b ‚ààL‚àû(‚àÇŒ©).
Assume that c ‚â•c0 > 0 for some constant c0 and that ‚à•b‚àí‚à•L‚àû(‚àÇŒ©) < min(1,c0)
C2Œ≥0
,
where CŒ≥0 is the continuity constant of the trace mapping. Then the problem: Find
u ‚ààV = H1(Œ©) such that
‚àÄv ‚ààV,

Œ©
(‚àáu ¬∑ ‚àáv + cuv) dx +

‚àÇŒ©
bŒ≥0(u)Œ≥0(v) dŒì =

Œ©
f v dx +

‚àÇŒ©
gŒ≥0(v) dŒì,
has one and only one solution.
Here b‚àí= ‚àímin(0, b) denotes the negative part of b.

4.3 Application to the Model Problems, and More
135
Proof We check the hypotheses of the Lax‚ÄìMilgram theorem. We already know that
V is a Hilbert space. The continuity of the bilinear form a has also already been
checked, except for the boundary integral terms


‚àÇŒ©
bŒ≥0(u)Œ≥0(v) dŒì
 ‚â§‚à•b‚à•L‚àû(‚àÇŒ©)‚à•Œ≥0(u)‚à•L2(‚àÇŒ©)‚à•Œ≥0(v)‚à•L2(‚àÇŒ©)
‚â§C2
Œ≥0‚à•b‚à•L‚àû(‚àÇŒ©)‚à•u‚à•H1(Œ©)‚à•v‚à•H1(Œ©)
for all u and v. The linear form is also known to be continuous. Let us check the
V -ellipticity. Obviously b ‚â•‚àíb‚àí, thus

Œ©
(‚à•‚àáv‚à•2 + cv2) dx +

‚àÇŒ©
bŒ≥0(v)2 dŒì
‚â•min(1, c0)‚à•v‚à•2
H1(Œ©) ‚àí‚à•b‚àí‚à•L‚àû(‚àÇŒ©)‚à•Œ≥0(v)‚à•2
L2(‚àÇŒ©)
‚â•

min(1, c0) ‚àíC2
Œ≥0‚à•b‚àí‚à•L‚àû(‚àÇŒ©)

‚à•v‚à•2
H1(Œ©),
hence the V -ellipticity.
‚ñ°
Remark 4.17 Under the previous hypotheses, we have existence and uniqueness via
the Lax‚ÄìMilgram theorem provided b is not too negative in some sense.
‚ñ°
All these hypotheses only give sufÔ¨Åcient conditions. Let us give another set of
such hypotheses.
Proposition 4.12 Same hypotheses except that we assume that c ‚â•0 and that b ‚â•
Œº > 0 for some constant Œº. Then the Fourier problem (4.11) has one and only one
solution.
Proof The only point to be established is V -ellipticity. We use a compactness argu-
ment by contradiction based on Rellich‚Äôs theorem, see Remark 3.18 of Chap.3 again.
We have

Œ©
(‚à•‚àáv‚à•2 + cv2) dx +

‚àÇŒ©
bŒ≥0(v)2 dŒì ‚â•

Œ©
‚à•‚àáv‚à•2 dx + Œº

‚àÇŒ©
Œ≥0(v)2 dŒì.
Let us assume for contradiction that there is no constant Œ± > 0 such that

Œ©
‚à•‚àáv‚à•2 dx + Œº

‚àÇŒ©
Œ≥0(v)2 dŒì ‚â•Œ±‚à•v‚à•2
H1(Œ©).
This implies that for all n ‚ààN‚àó, there exists vn ‚ààH1(Œ©) such that

Œ©
‚à•‚àávn‚à•2 dx + Œº

‚àÇŒ©
Œ≥0(vn)2 dŒì < 1
n‚à•vn‚à•2
H1(Œ©).

136
4
The Variational Formulation of Elliptic PDEs
We can assume without loss of generality that
‚à•vn‚à•2
H1(Œ©) = 1,
(4.13)
and that we have

Œ©
‚à•‚àávn‚à•2 dx + Œº

‚àÇŒ©
Œ≥0(vn)2 dŒì ‚Üí0.
(4.14)
Now vn is bounded in H1(Œ©) by (4.13), thus relatively compact in L2(Œ©) by Rellich‚Äôs
theorem. We may extract a subsequence, still denoted vn, and v ‚ààL2(Œ©) such that
vn ‚Üív in L2(Œ©). By (4.14), ‚à•‚àávn‚à•L2(Œ©) ‚Üí0, therefore, since ‚àávn ‚Üí‚àáv in D‚Ä≤(Œ©),
we have ‚àáv = 0 and v is constant on each connected component of Œ©. Therefore
v ‚ààH1(Œ©) and
‚à•vn ‚àív‚à•2
H1(Œ©) = ‚à•‚àávn‚à•2
L2(Œ©) + ‚à•vn ‚àív‚à•2
L2(Œ©) ‚Üí0
(4.15)
so that, by continuity of the trace mapping Œ≥0(vn) ‚ÜíŒ≥0(v) in L2(‚àÇŒ©). By (4.14)
again, we also have ‚à•Œ≥0(vn)‚à•L2(‚àÇŒ©) ‚Üí0 since Œº > 0 and therefore Œ≥0(v) = 0. It fol-
lows that v being a constant with zero trace, it vanishes in each connected component,
i.e., v = 0. We now realize that (4.13) and (4.15) contradict each other, therefore our
premise that there exists no V -ellipticity constant Œ± is false.
‚ñ°
Remark 4.18 As for the proof of the Poincar√©‚ÄìWirtinger inequality, this is a typical
compactness-contradiction argument: we can prove that the constant exists but we
have no idea of its value.
‚ñ°
4.4
General Second Order Elliptic Problems
Up to now, the partial differential operator always was the Laplacian. Let us rapidly
consider more general second order elliptic operators in a Lipschitz open subset Œ© of
Rd. We are given a d √ó d matrix-valued function A(x) = (ai j(x)) with ai j ‚ààC1( ¬ØŒ©).
Let u ‚ààC2(Œ©) (we can lower this regularity considerably), then A‚àáu is a vector
Ô¨Åeld with components
(A‚àáu)i =
d

j=1
ai j‚àÇju
whose divergence is given by
div (A‚àáu) =
d

i=1
‚àÇi(A‚àáu)i
=
d

i, j=1
ai j‚àÇi ju +
d

j=1
 d

i=1
‚àÇiai j

‚àÇju.

4.4 General Second Order Elliptic Problems
137
The principal part of this operator d
i, j=1 ai j‚àÇi j is of the second order. We will
consider the boundary value problem
‚éß
‚é®
‚é©
‚àídiv (A‚àáu) + cu = f in Œ©,
u = h on Œì0,
bu + n ¬∑ A‚àáu = g on Œì1,
(4.16)
where c, b, f , g and h are given functions and Œì0, Œì1 a partition of ‚àÇŒ© as in the
mixed problem. When A = I, we recognize ‚àídiv (A‚àáu) = ‚àíŒîu and n ¬∑ A‚àáu = ‚àÇu
‚àÇn,
so that we are generalizing all the model problems seen up to now. First of all, we
reduce the study to the case h = 0 by subtracting a function with the appropriate
trace, as before.
Proposition 4.13 Assumethat f ‚ààL2(Œ©),g ‚ààL2(Œì1),c ‚ààL‚àû(Œ©)andb ‚ààL‚àû(Œì1).
Then the triple
V = {v ‚ààH1(Œ©); Œ≥0(v) = 0 on Œì1},
a(u, v) =

Œ©
(A‚àáu ¬∑ ‚àáv + cuv) dx +

Œì1
bŒ≥0(u)Œ≥0(v) dŒì,
‚Ñì(v) =

Œ©
f v dx +

Œì1
gŒ≥0(v) dŒì,
deÔ¨Ånes a variational formulation for problem (4.16), at least for H2(Œ©) solutions.
Proof The proof is routine, but we partially write it down for completeness. It is easy
to check that (A‚àáu)i ‚ààH1(Œ©) for all i. We multiply the PDE by v ‚ààV and integrate
by parts. This yields Ô¨Årst
‚àí

Œ©
 d

i=1
‚àÇi(A‚àáu)i

v dx +

Œ©
cuv dx =

Œ©
f v dx,
then

Œ©
d

i=1
(A‚àáu)i‚àÇiv dx ‚àí

Œì1
 d

i=1
Œ≥0

(A‚àáu)i

ni

Œ≥0(v) dŒì +

Œ©
cuv dx =

Œ©
f v dx,
and Ô¨Ånally

Œ©
(A‚àáu ¬∑ ‚àáv + cuv) dx +

Œì1
bŒ≥0(u)Œ≥0(v) dŒì =

Œ©
f v dx +

Œì1
gŒ≥0(v) dŒì.
We leave the converse argument to the reader.
‚ñ°

138
4
The Variational Formulation of Elliptic PDEs
Proposition 4.14 Let f ‚ààL2(Œ©), g ‚ààL2(Œì1), c ‚ààL‚àû(Œ©) and b ‚ààL‚àû(Œì1). We
assume that the matrix A is uniformly elliptic, that is to say that there exists a
constant Œ± > 0 such that
d

i, j=1
ai j(x)ŒæiŒæ j ‚â•Œ±‚à•Œæ‚à•2
for all x ‚àà¬ØŒ© and all Œæ ‚ààRd. We assume in addition that c ‚â•c0 > 0 for some
constant c0 and that b ‚â•0. Then the problem: Find u ‚ààV = {v ‚ààH1(Œ©); Œ≥0(v) =
0 on Œì1} such that
‚àÄv ‚ààV,

Œ©
(A‚àáu ¬∑ ‚àáv + cuv) dx +

Œì1
bŒ≥0(u)Œ≥0(v) dŒì =

Œ©
f v dx +

Œì1
gŒ≥0(v) dŒì,
has one and only one solution.
Proof That V is a Hilbert space and that ‚Ñìis continuous are already known facts.
The proof of the continuity of the bilinear form, which is implied by the boundedness
of the matrix coefÔ¨Åcients ai j(x), is left to the reader. The V -ellipticity is also quite
obvious, since
a(v, v) =

Œ©
(A‚àáv ¬∑ ‚àáv + cv2) dx +

Œì1
bŒ≥0(v)2 dŒì
‚â•Œ±

Œ©
‚à•‚àáv‚à•2 dx + c0

Œ©
v2 dx
‚â•min(Œ±, c0)‚à•v‚à•2
H1(Œ©),
hence the existence, uniqueness and continuous dependence of the solution on the
data by the Lax‚ÄìMilgram theorem.
‚ñ°
Remark 4.19 When the matrix A is not symmetric, neither is the bilinear form a,
even though the principal part of the operator is symmetric since d
i, j=1 ai j‚àÇi j =
d
i, j=1
ai j+a ji
2
‚àÇi j due to the fact that ‚àÇi j = ‚àÇji. When A is symmetric, then so is the
bilinear form and we have an equivalent minimization problem with
J(v) = 1
2

Œ©
(A‚àáv ¬∑ ‚àáv + cv2) dx +

Œì1
bŒ≥0(v)2 dŒì

‚àí

Œ©
f v dx ‚àí

Œì1
gŒ≥0(v) dŒì,
to be minimized over V .
It is quite clear that we can reduce the regularity of A down to L‚àûwithout loosing
the existence and uniqueness of the variational problem. The interpretation in terms of
PDEs stops at the divergence form ‚àídiv (A‚àáu) + cu = f since we cannot develop
the divergence using Leibniz formula in this case. Such lack of regularity of the
coefÔ¨Åcients is useful to model heterogeneous media.
‚ñ°

4.4 General Second Order Elliptic Problems
139
We now give another example of a non symmetric problem, the convection‚Äì
diffusion problem. Let us be given a vector Ô¨Åeld œÉ. The convection‚Äìdiffusion problem
reads
‚àíŒîu + œÉ ¬∑ ‚àáu + cu = f in Œ©,
u = 0 on ‚àÇŒ©.
(4.17)
We have a diffusion term ‚àíŒîu and a transport term œÉ ¬∑ ‚àáu in the same equation that
compete with each other.
Proposition 4.15 Assume that f ‚ààL2(Œ©), œÉ ‚ààC1( ¬ØŒ©; Rd) and c ‚ààL‚àû(Œ©). Then
the triple
V = H1
0(Œ©),
a(u, v) =

Œ©

‚àáu ¬∑ ‚àáv + (œÉ ¬∑ ‚àáu + cu)v

dx,
‚Ñì(v) =

Œ©
f v dx,
deÔ¨Ånes a variational formulation for problem (4.17).
Proof The proof follows the same lines as before and we leave it as an exercise. Note
that the bilinear form a is not symmetric.
‚ñ°
Proposition 4.16 Let f ‚ààL2(Œ©), œÉ ‚ààC1( ¬ØŒ©; Rd) and c ‚ààL‚àû(Œ©). We assume that
c ‚àí1
2 div œÉ ‚â•0. Then the problem: Find u ‚ààV such that
‚àÄv ‚ààV,

Œ©

‚àáu ¬∑ ‚àáv + (œÉ ¬∑ ‚àáu + cu)v

dx =

Œ©
f v dx,
has one and only one solution.
Proof We just prove the V -ellipticity. We have for all v ‚ààV
a(v, v) =

Œ©

‚à•‚àáv‚à•2 + cv2 + (œÉ ¬∑ ‚àáv)v

dx.
It can be checked that œÉiv ‚ààH1(Œ©) and that the Leibniz formula (3.8) holds in this
case for Ô¨Årst derivatives. Let us integrate the last integral by parts

Œ©
(œÉ ¬∑ ‚àáv)v dx =

Œ©
 d

i=1
œÉi‚àÇiv

v dx
= ‚àí

Œ©
 d

i=1
‚àÇi(œÉiv)

v dx = ‚àí

Œ©
 d

i=1
‚àÇiœÉi

v2 dx ‚àí

Œ©
 d

i=1
œÉi‚àÇiv

v dx
= ‚àí

Œ©
div œÉv2 dx ‚àí

Œ©
(œÉ ¬∑ ‚àáv)v dx,

140
4
The Variational Formulation of Elliptic PDEs
since all boundary terms vanish, so that

Œ©
(œÉ ¬∑ ‚àáv)v dx = ‚àí1
2

Œ©
div œÉv2 dx.
Therefore
a(v, v) =

Œ©

‚à•‚àáv‚à•2 +

c ‚àí1
2div œÉ

v2
dx ‚â•|v|2
H1(Œ©),
hence the result by the equivalence of the H1 semi-norm and the H1 norm on H1
0(Œ©),
see Corollary3.3 of Chap.3.
‚ñ°
Remark 4.20 We thus have existence and uniqueness if c = 0 and div œÉ = 0. The
case div œÉ = 0 is interesting because if œÉ represents the velocity Ô¨Åeld of such a Ô¨Çuid
as air or water, the divergence free condition is the expression of the incompressibility
of the Ô¨Çuid. Under usual experimental conditions, both Ô¨Çuids are in fact considered
to be incompressible.
‚ñ°
Let us now give a fourth order example, even though only second order problems
were advertised in the section title. We consider a slight variant of the plate problem
involving the bilaplacian with homogeneous Dirichlet boundary conditions
‚éß
‚é™‚é™‚é®
‚é™‚é™‚é©
Œî2u + cu = f in Œ©,
u = 0 on ‚àÇŒ©,
‚àÇu
‚àÇn = 0 on ‚àÇŒ©.
The derivation of a variational formulation is again fairly routine, but since this
is our Ô¨Årst (and only) fourth order problem, we give some detail. The variational
space for this Dirichlet problem is V = H2
0(Œ©) which incorporates the two boundary
conditions. Assume that u ‚ààH4(Œ©) ‚à©H2
0(Œ©). Then Œîu ‚ààH2(Œ©) and we can use
Green‚Äôs formula

Œ©
(Œî2u)v dx =

Œ©
(Œî(Œîu))v dx
=

Œ©
Œîu Œîv dx +

‚àÇŒ©
(Œ≥0(v)Œ≥1(Œîu) ‚àíŒ≥1(v)Œ≥0(Œîu)) dŒì
=

Œ©
Œîu Œîv dx,
since Œ≥0(v) = Œ≥1(v) = 0 for all v ‚ààH2
0(Œ©). So we have our variational formulation
‚àÄv ‚ààV,

Œ©
(Œîu Œîv + cuv) dx =

Œ©
f v dx,
(4.18)

4.4 General Second Order Elliptic Problems
141
which is easily checked to give rise to a solution of the boundary value problem.
Let ‚àá2v denote the collection of all second order partial derivatives of v. We let
‚à•‚àá2v‚à•2
L2(Œ©) =

1‚â§i, j‚â§d
 ‚àÇ2v
‚àÇxi‚àÇx j

2
L2(Œ©).
We have
Lemma 4.2 The semi-norm ‚à•‚àá2v‚à•L2(Œ©) is a norm on H2
0(Œ©) that is equivalent to
the H2 norm.
Proof It is enough to establish a bound from below. Let v ‚ààH2
0(Œ©). Then we have
‚àÇiv ‚ààH1
0(Œ©) for all i. Therefore ‚à•‚àá(‚àÇiv)‚à•2
L2(Œ©) ‚â•C2‚à•‚àÇiv‚à•2
H1(Œ©), as a consequence
of Poincar√©‚Äôs inequality, and C ‚â§1. Now of course
‚à•‚àÇiv‚à•2
H1(Œ©) = ‚à•‚àá(‚àÇiv)‚à•2
L2(Œ©) + ‚à•‚àÇiv‚à•2
L2(Œ©),
so summing over i, we get
‚à•‚àá2v‚à•2
L2(Œ©) =
d

i=1
‚à•‚àá(‚àÇiv)‚à•2
L2(Œ©) ‚â•C2
‚à•‚àá2v‚à•2
L2(Œ©) + |v|2
H1(Œ©)

‚â•C2‚à•‚àá2v‚à•2
L2(Œ©) + C4‚à•v‚à•2
H1(Œ©) ‚â•C4‚à•v‚à•2
H2(Œ©),
since v ‚ààH1
0(Œ©).
‚ñ°
Proposition 4.17 Let f ‚ààL2(Œ©) and c ‚ààL‚àû(Œ©). We assume that c ‚â•0. Then
problem (4.18) has one and only one solution.
Proof We just prove the V -ellipticity. We have
a(v, v) ‚â•

Œ©
(Œîv)2 dx.
We argue by density. Let œï ‚ààD(Œ©), since Œîœï = d
i=1 ‚àÇiiœï, we can write

Œ©
(Œîœï)2 dx =

Œ©
 d

i=1
‚àÇiiœï
 d

j=1
‚àÇj jœï

dx =
d

i, j=1

Œ©
‚àÇiiœï‚àÇj jœï dx
= ‚àí
d

i, j=1

Œ©
‚àÇiœï‚àÇi j jœï dx =
d

i, j=1

Œ©
‚àÇi jœï‚àÇi jœï dx

142
4
The Variational Formulation of Elliptic PDEs
with two successive integrations by parts, the Ô¨Årst one with respect to xi and the
second one with respect to x j. Hence, for all œï ‚ààD(Œ©), we obtain

Œ©
(Œîœï)2 dx =
d

i, j=1

Œ©
(‚àÇi jœï)2 dx = ‚à•‚àá2œï‚à•2
L2(Œ©).
(4.19)
Now, by deÔ¨Ånition, H2
0(Œ©) is the closure of D(Œ©) in H2(Œ©), thus for all v ‚ààH2
0(Œ©),
there exists a sequence œïn ‚ààD(Œ©) such that œïn ‚Üív in H2(Œ©). Passing to the limit
in the above equality, we thus get

Œ©
(Œîv)2 dx = ‚à•‚àá2v‚à•2
L2(Œ©),
since ‚àÇi jœïn ‚Üí‚àÇi jv in L2(Œ©), hence the result by Lemma 4.2.
‚ñ°
Remark 4.21 Notice the trick used in the above proof. To establish an equality for
H2 functions, we need to use third derivatives, which make no sense as functions in
this context. However, all formulas are valid for smooth functions, for which third
derivatives are not a problem, and since in the end, the resulting equality (4.19) does
not involve any derivatives of order higher than two, it extends to H2 by density.
The formula is actually surprising, since Œîv does not contain any derivative ‚àÇi jv
with i Ã∏= j, and only the sum of all ‚àÇiiv derivatives. Its L2 norm squared is nonetheless
equal to the sum of the L2 norms squared of all individual second derivatives. This
is related to elliptic regularity, which was mentioned in passing before.
‚ñ°
Remark 4.22 This is another symmetric problem, hence we have an equivalent
energy minimization formulation with
J(v) = 1
2

Œ©

(Œîv)2 + cv2
dx ‚àí

Œ©
f v dx,
to be minimized on H2
0(Œ©).
‚ñ°
4.5
Concluding Remarks
To conclude this section, we discuss the general three point strategy for solving
elliptic problems that was repeatedly applied here. First we establish a variational
formulation: (homogeneous) Dirichlet boundary conditions are enforced by the test-
function space, which is included in H1 for second order problems; we multiply the
PDE by a test-function‚Äîpossibly assuming additional regularity on the solution‚Äî
and use integration by parts or Green‚Äôs formula to obtain the variational problem.
The bilinear form must be well-deÔ¨Åned on the test-function space.

4.5 Concluding Remarks
143
The second point is to check that the variational formulation actually gives rise
to a solution of the boundary value problem. This point is usually itself in two steps:
Ô¨Årst obtain the PDE in the sense of distributions by using test-functions in D, second
retrieve Neumann or Fourier boundary conditions by using the full test-function
space. The Ô¨Årst two points can appear somewhat formal because of the assumed
regularity on the solution that is not always easily obtained in the end. This is not a
real problem, since it is possible to write rigorous arguments, at the expense of more
theory than we need here.
The Ô¨Ånal third point is to try and apply the Lax‚ÄìMilgram theorem, by making
precise regularity and possibly sign assumptions on the data and coefÔ¨Åcients in order
to ensure continuity of the linear and bilinear forms as well as V -ellipticity. Here we
prove existence and uniqueness of the solution to the variational problem.
Aquestionthatcanbeaskediswhatistherelevanceofsuchsolutionstoaboundary
value problem, in which the partial derivatives are taken in a rather weak sense. This
is where elliptic regularity theory comes into play. Using elliptic regularity, it is
possible to show that the variational solution given by the Lax‚ÄìMilgram theorem is
indeed a classical solution, provided the coefÔ¨Åcients, right-hand side, boundary of
Œ© and so on are smooth enough.
To be a little more precise on these regularity results, let us mention that they
proceed in two steps
‚Ä¢ Local regularity, which only depends on the regularity of the coefÔ¨Åcients and right-
hand side of the PDE. For example, for the model Dirichlet variational problem
(4.3), with c ‚ààC‚àû(Œ©), we have for any integer k ‚â•0
if f ‚ààHk
loc(Œ©), then u ‚ààHk+2
loc (Œ©),
where
Hk
loc(Œ©) = { f ‚ààD‚Ä≤(Œ©), such that for any œï ‚ààD(Œ©), f œï ‚ààHk(Œ©)}.
‚Ä¢ Global regularity, i.e., up to the boundary Œì of Œ©, which also depends on the
regularity of the boundary and on the boundary conditions, see [3, 4, 15, 25, 35].
We have for example the following result, still for the model Dirichlet problem,
see [44].
Proposition 4.18 Let u be the solution of (4.3) with f ‚ààL2(Œ©). If Œì is of class
C1,1, then u ‚ààH2(Œ©).
The same type of result holds for the Neumann problem of Proposition 4.6 with
g ‚ààH1/2(Œì ), see [44]. We refer for example to [25] for a counterexample when Œ©
is not regular enough.
‚ñ°
In this chapter, we applied the variational method to solve elliptic boundary value
problems from the theoretical point of view. We are now going to see that the vari-
ational approach is also very well suited to numerical approximation, in particular
via the Ô¨Ånite element method.

Chapter 5
Variational Approximation Methods
for Elliptic PDEs
Oneofthevirtuesofthevariationalapproachisthatitleadsnaturallytoawholefamily
of approximation methods. Let us emphasize again that the reason why approxima-
tion methods for PDEs are needed is that, even though we may be able to prove the
existence of a solution, in general there is no closed form formula for it. In addition,
such approximations must be effectively computable.
There are other approximation methods that are not variational, such as the Ô¨Ånite
difference method seen earlier, the Ô¨Ånite volume method that we will see in Chap.10,
and yet many other methods that we will not consider in this book.
5.1
The General Abstract Variational Approximation
Scheme
As we have seen, boundary value problems naturally take place in inÔ¨Ånite dimen-
sional vector spaces. An inÔ¨Ånite dimensional space is too large to Ô¨Åt inside a com-
puter, thus the main idea is to build Ô¨Ånite dimensional approximations thereof. Any
approximation method of this kind falls under the general heading of a Galerkin
method [7, 11, 19, 28, 63, 65, 66]. Let us start with a few deÔ¨Ånitions that pertain to
the variational case.
DeÔ¨Ånition 5.1 Let V be a Hilbert space and (Vn)n‚ààN be a sequence of Ô¨Ånite dimen-
sional vector subspaces of V . We say that this sequence is a conforming approxima-
tion sequence if for all u ‚ààV , there exists a sequence (vn)n‚ààN such that
vn ‚ààVn and ‚à•u ‚àívn‚à•V ‚Üí0 when n ‚Üí+‚àû.
¬© Springer International Publishing Switzerland 2016
H. Le Dret and B. Lucquin, Partial Differential Equations:
Modeling, Analysis and Numerical Approximation, International Series
of Numerical Mathematics 168, DOI 10.1007/978-3-319-27067-8_5
145

146
5
Variational Approximation Methods for Elliptic PDEs
Remark 5.1 Note that in general, we do not have Vn ‚äÇVn+1, i.e., the approximation
spaces do not need to be nested. The conforming approximation condition implies
that 
n‚ààN Vn is dense in V .
There are situations in which non conforming approximations are called for, that
is to say Vn Ã∏‚äÇV , see for example [11, 19, 45]. Of course, in this case ‚à•u ‚àívn‚à•V
does not make sense, and another deÔ¨Ånition is needed.
The traditional notation for an approximation sequence is Vh instead of Vn, where
h is a discretization parameter that is assumed to belong to a sequence that tends to
0 instead of having n ‚Üí+‚àû, the two being equivalent. We will from now on stick
with the tradition.
‚ñ°
The main abstract result is the following, also known under the name of C√©a‚Äôs
lemma, cf. [7, 9, 14].
Theorem 5.1 (C√©a‚Äôs Lemma) Let V be a Hilbert space, a be a bilinear form and ‚Ñì
be a linear form satisfying the hypotheses of the Lax-Milgram theorem. Let Vh be a
closed subspace of V . Then there exists a unique uh ‚ààVh such that
‚àÄvh ‚ààVh,
a(uh, vh) = ‚Ñì(vh),
(5.1)
and we have
‚à•u ‚àíuh‚à•V ‚â§M
Œ± inf
vh‚ààVh ‚à•u ‚àívh‚à•V = M
Œ± d(u, Vh),
where M is the continuity constant of a and Œ± its V -ellipticity constant.
Proof Since Vh is closed, it is a Hilbert space for the restriction of the scalar product of
V . The Lax-Milgram hypotheses for the variational problem on Vh are thus satisÔ¨Åed
and the existence and uniqueness of uh is assured.
Now we have a(u, v) = ‚Ñì(v) for all v ‚ààV , thus in particular for v = wh ‚ààVh.
On the other hand, we also have a(uh, wh) = ‚Ñì(wh), so that subtracting the two
0 = a(u, wh) ‚àía(uh, wh) = a(u ‚àíuh, wh)
(5.2)
for all wh ‚ààVh. By V -ellipticity, for all vh ‚ààVh,
Œ±‚à•u ‚àíuh‚à•2
V ‚â§a(u ‚àíuh, u ‚àíuh)
‚â§a(u ‚àíuh, u ‚àívh) + a(u ‚àíuh, vh ‚àíuh)
= a(u ‚àíuh, u ‚àívh)
‚â§M‚à•u ‚àíuh‚à•V ‚à•u ‚àívh‚à•V ,
since wh = vh ‚àíuh ‚ààVh. The case ‚à•u ‚àíuh‚à•V = 0 is ideal and nothing needs to be
done. If the norm is non zero, we divide by it and obtain
‚à•u ‚àíuh‚à•V ‚â§M
Œ± ‚à•u ‚àívh‚à•V

5.1 The General Abstract Variational Approximation Scheme
147
for all vh ‚ààVh, thus the theorem by taking the inÔ¨Åmum of the right-hand side
over Vh.
‚ñ°
Remark 5.2 A word of warning about the traditional notation vh ‚ààVh. This tradi-
tional notation is rather unfortunate, since vh is not a function of h, but an arbitrary
element of Vh. The subscript h must thus not be understood as a regular subscript,
but just as a typographical reminder that we are talking about an arbitrary element
of Vh. On the other hand, the solution uh can be considered as a function of h insofar
as Vh can be considered as a function of h.
‚ñ°
We now apply C√©a‚Äôs lemma to the case of a conforming approximation sequence.
Corollary 5.1 Let Vh be a conforming approximation sequence. Then the sequence
uh ‚ààVh of approximated solutions converges to the solution u in V , with the a priori
error estimate
‚à•u ‚àíuh‚à•V ‚â§M
Œ± d(u, Vh) ‚Üí0 when h ‚Üí0.
Proof Each subspace Vh is Ô¨Ånite dimensional, hence closed. We thus apply Theo-
rem5.1 and obtain the convergence result since d(u, Vh) ‚â§‚à•u ‚àívh‚à•V where vh is
given by the deÔ¨Ånition of conforming approximation for this u.
‚ñ°
Remark 5.3 We also trivially have ‚à•u ‚àíuh‚à•V ‚â•d(u, Vh), thus the error estimate is
optimal in terms of order of magnitude when h ‚Üí0. Now, if the constant M/Œ± is
very large, then the numerical error can be large too with respect to d(u, Vh).
In the case when a is symmetric, the constant in C√©a‚Äôs lemma can be improved to
‚àöM/Œ±. Indeed, in this case, a deÔ¨Ånes a second scalar product on V , for which V is
also a Hilbert space. Equation(5.2) then says that u ‚àíuh is orthogonal to Vh for the
new scalar product. Therefore, by the orthogonal projection Theorem3.2 of Chap.3,
it minimizes the new distance to Vh and we thus have
Œ±‚à•u ‚àíuh‚à•2
V ‚â§a(u ‚àíuh, u ‚àíuh) ‚â§a(u ‚àívh, u ‚àívh) ‚â§M‚à•u ‚àívh‚à•2
V
for all vh ‚ààVh. Taking the inÔ¨Åmum in the right-hand side with respect to vh yields the
improved estimate. Of course, M ‚â•Œ±, so this is a real improvement of the constant.
An interesting feature of C√©a‚Äôs lemma is that it decomposes the error estimate
into two basically independent parts: The constant M/Œ± which only depends on the
bilinear form, i.e., the PDE, and not on the approximation method, and d(u, Vh)
which depends mostly on the approximation properties of the space Vh. In practice,
the second part will be estimated by constructing a linear operator Œ†h : V ‚ÜíVh,
writing that
d(u, Vh) ‚â§‚à•u ‚àíŒ†hu‚à•V ‚â§‚à•I ‚àíŒ†h‚à•‚à•u‚à•V
and estimating the term ‚à•I ‚àíŒ†h‚à•which depends only on Vh.
‚ñ°
The approximation uh lives in a Ô¨Ånite dimensional space, therefore it is com-
putable, at least in principle. Let us see how to proceed in practice.

148
5
Variational Approximation Methods for Elliptic PDEs
Proposition 5.1 Let Nh = dim Vh and (w1, w2, . . . , wNh) be a basis of Vh. We write
uh = Nh
j=1 uh, jw j. We introduce an Nh √ó Nh matrix A deÔ¨Åned by Ai j = a(w j, wi)
and two vectors B ‚ààRNh by Bi = ‚Ñì(wi) and X ‚ààRNh by X j = uh, j. Then the matrix
A is invertible and we have AX = B. Conversely, the solution of this linear system is
the vector of coordinates of uh in the basis (wi).
Proof Let us take vh = wi in the variational formulation of the Ô¨Ånite dimensional
problem. This yields
Bi = ‚Ñì(wi) = a(uh, wi) = a
 Nh

j=1
uh, jw j, wi
=
Nh

j=1
uh, ja(w j, wi) =
Nh

j=1
Ai jX j = (AX)i
for all i. Hence AX = B.
Conversely, if AX = B, then by the above computation, ‚Ñì(wi) = a(uh, wi) where
uh = Nh
j=1 X jw j. For all vh ‚ààVh, we have vh = Nh
i=1 vh,iwi, therefore
‚Ñì(vh) =
Nh

i=1
vh,i‚Ñì(wi) =
Nh

i=1
vh,ia(uh, wi) = a

uh,
Nh

i=1
vh,iwi
= a(uh, vh)
therefore, by the uniqueness of the Lax-Milgram solution, we have uh = uh. Thus
the variational problem and the linear system are equivalent. Since the variational
problem has one and only one solution for any ‚Ñì, it follows that A is invertible.
‚ñ°
Remark 5.4 The problem of computing the Ô¨Ånite dimensional approximation uh is
thus reduced to that of computing the matrix A and the right-hand side B once a basis
of Vh is chosen, which is called assembling the system, and then of solving the linear
system AX = B. In practical applications, Nh is typically large, ranging from the
thousands to the millions or billions. This is a whole other subject with many facets:
matrix conditioning, efÔ¨Åcient algorithms for large linear systems, high performance
computing. We will not touch on this.
It is important not to lose sight of the fact that the size of the matrix A and of the
right-hand side B depend on h, via Nh, even though the notation fails to make this
dependence apparent. In particular, when h ‚Üí0, we have Nh ‚Üí+‚àû.
Do not forget the exchange of indices Ai j = a(w j, wi) and not Ai j = a(wi, w j)!
Of course if a is symmetric, then the matrix A is symmetric. It is also positive,
deÔ¨Ånite, with a(vh, vh) = Y TAY where Y is the vector of coordinates of vh ‚ààVh in
the basis (wi).
‚ñ°
We now introduce the main example of variational approximation method, the
Ô¨Ånite element method (FEM). There are other variational approximation methods,
such as the spectral method, see [10, 11, 17, 43, 50, 63, 65] as well as such extensions
as discontinuous Galerkin methods, see [14, 31, 52], which are non conforming
methods, among many others.
In the rest of this chapter, we consider the Ô¨Ånite element method in the one-
dimensional case. The two-dimensional case will be the subject of the next chapter.

5.2 The Finite Element Method in Dimension One
149
5.2
The Finite Element Method in Dimension One
Let Œ© = ]a, b[ and consider the model problem
 ‚àíu‚Ä≤‚Ä≤ + cu = f in Œ©,
u(a) = u(b) = 0.
(5.3)
When f ‚ààL2(a, b), c ‚ààL‚àû(a, b) and c ‚â•0, we know that this problem has
one and only one solution by using the variational formulation V = H1
0(]a, b[),
a(u, v) =
	
Œ©(u‚Ä≤v‚Ä≤ + cuv) dx and ‚Ñì(v) =
	
Œ© f v dx.
The idea of the FEM is to take approximation spaces Vh composed of functions
that are piecewise polynomial of low degree, with lots of pieces. In one dimension,
we have H1(]a, b[) ‚äÇC0([a, b]), thus for the approximation to be conforming, we
need to impose Vh ‚äÇC0([a, b]) as well.
The FEM is based on the notion of mesh. In one dimension, a mesh is just a
subdivision of ]a, b[ into a Ô¨Ånite number of subintervals. Each one of the small
intervals is called an element. We will only consider uniform meshes for simplicity.
Nonuniform meshes pose no additional conceptual difÔ¨Åculty as should become clear.
Let N be a positive integer. We set h = b‚àía
N+1, which is called the mesh size, and let
xi = a + ih, i = 0, . . . , N + 1, be the nodes of the mesh.
We thus have N + 1 subintervals [xi, xi+1] of length h, N interior nodes xi,
i = 1, . . . , N, and 2 boundary nodes x0 and xN+1. Even though Fig.5.1 is virtually
identical to Fig.2.1 of Chap.2 depicting a one-dimensional grid, the two concepts of
mesh and grid are really different. In a sense, in a grid only the grid points count and
nothing in between, whereas in a mesh both the elements and nodes are of impor-
tance. Of course, the visual difference between grids and meshes is more apparent
in dimensions 2 and higher.
We now deÔ¨Åne
Vh = {vh ‚ààC0([a, b]); vh|[xi,xi+1] is afÔ¨Åne for i = 0, . . . , N, vh(a) = vh(b) = 0}.
Note that here, the subscript h in Vh is actually the same h as the mesh size. Since
h ‚Üí0 when N ‚Üí+‚àû, we thus have a sequence of spaces. We Ô¨Årst need to verify
that these spaces are subspaces of V .
Proposition 5.2 We have Vh ‚äÇH1
0(]a, b[).
Proof First of all, since Vh ‚äÇC0([a, b]) with [a, b] compact, we have Vh ‚äÇL2(a, b).
Let us compute the distributional derivative of an element vh of Vh. Since vh|[xi,xi+1]
Fig. 5.1 A uniform 1d mesh
h
a = x0
x1
x2
x3
¬∑¬∑¬∑
xN
xN+1 = b

150
5
Variational Approximation Methods for Elliptic PDEs
is an afÔ¨Åne function, we can write vh(x) = Œªix + Œºi for x ‚àà[xi, xi+1], where Œªi, Œºi
are constants that depend on the subinterval. For all œï ‚ààD(]a, b[), we have
‚ü®v‚Ä≤
h, œï‚ü©= ‚àí‚ü®vh, œï‚Ä≤‚ü©= ‚àí

 b
a
vh(x)œï‚Ä≤(x) dx
= ‚àí
N

i=0

 xi+1
xi
vh(x)œï‚Ä≤(x) dx
= ‚àí
N

i=0

 xi+1
xi
(Œªix + Œºi)œï‚Ä≤(x) dx.
Now we can classically integrate each element integral by parts,
‚àí

 xi+1
xi
(Œªix + Œºi)œï‚Ä≤(x) dx =

 xi+1
xi
Œªiœï(x) dx ‚àí[vh(x)œï(x)]xi+1
xi
=

 xi+1
xi
Œªiœï(x) dx ‚àívh(xi+1)œï(xi+1) + vh(xi)œï(xi),
since vh is continuous on [a, b] its right and left limits at xi and xi+1 respectively are
just its value at these points.
Now, if we let
g(x) =
N

i=0
Œªi1]xi,xi+1[(x),
then obviously g is a piecewise constant function, hence is bounded, and thus in
L2(a, b) and
N

i=0

 xi+1
xi
Œªiœï(x) dx =

 b
a
g(x)œï(x) dx.
On the other hand,
‚àí
N

i=0
[vh(x)œï(x)]xi+1
xi
= ‚àívh(x1)œï(x1) + vh(x0)œï(x0)
‚àívh(x2)œï(x2) + vh(x1)œï(x1) ‚àí¬∑ ¬∑ ¬∑
¬∑ ¬∑ ¬∑ ‚àívh(xN+1)œï(xN+1) + vh(xN)œï(xN) = 0,
since all terms involving interior nodes appear twice with opposite signs, and œï(x0) =
œï(xN+1) = 0 since œï has compact support. Finally, we see that
‚ü®v‚Ä≤
h, œï‚ü©=

 b
a
g(x)œï(x) dx = ‚ü®g, œï‚ü©,

5.2 The Finite Element Method in Dimension One
151
with g ‚ààL2(a, b) which shows that vh ‚ààH1(]a, b[) and v‚Ä≤
h = g. Now all elements
of Vh also satisfy vh(a) = vh(b) = 0 so that vh ‚ààH1
0(]a, b[).
‚ñ°
It is fairly clear that the space Vh is Ô¨Ånite dimensional, since any of its elements
is determined by a Ô¨Ånite number of constants Œªi and Œºi. The space Vh is therefore
closed, and the general abstract principle applies, i.e., there exists a unique uh ‚ààVh
such that a(uh, vh) = ‚Ñì(vh) for all vh ‚ààVh, and we have C√©a‚Äôs lemma error estimate.
Let us see how this estimate can be exploited to quantify the convergence rate. Let
us start with a general purpose lemma concerning Vh.
Lemma 5.1 There exists a unique continuous linear mapping Œ†h : H1
0(]a, b[) ‚Üí
Vh, called the Vh-interpolation operator such that for all v in H1
0(]a, b[), v(xi) =
Œ†hv(xi) for i = 0, . . . , N + 1.
Proof First of all, we note that H1
0(]a, b[) ‚ÜíC0([a, b]), therefore the nodal values
v(xi) are unambiguously deÔ¨Åned and v(x0) = v(xN+1) = 0.
Now an afÔ¨Åne function on [xi, xi+1] is uniquely determined by its values at xi
and xi+1. Thus, the relations v(xi) = Œ†hv(xi) for i = 0, . . . , N + 1 deÔ¨Åne a unique
piecewise afÔ¨Åne function on the mesh, that is continuous and vanishes at both ends,
thus belongs to Vh. Let Œ†hv be this function. Clearly, the mapping v ‚ÜíŒ†hv is
linear from H1
0(]a, b[) into Vh. Finally we infer from the fact that the values taken
by an afÔ¨Åne function on an interval lie between the values at the endpoints, that
maxx‚àà[xi,xi+1] |Œ†hv(x)| = max

|v(xi)|, |v(xi+1)|

, and therefore
‚à•Œ†hv‚à•C0([a,b]) = max
i=0,...,N
max
x‚àà[xi,xi+1] |Œ†hv(x)|
= max
i=0,...,N max

|v(xi)|, |v(xi+1)|

‚â§max
x‚àà[a,b] |v(x)| = ‚à•v‚à•C0([a,b]) ‚â§C‚à•v‚à•H1(]a,b[),
by Theorem3.7 of Chap.3. Consequently, the Vh-interpolation operator is
continuous.
‚ñ°
Remark 5.5 A picture is in order here. As can be seen on Fig.5.2, Œ†hv, which we
call the Vh-interpolate of v, is the unique element of Vh that coincides with v at all
nodes of the mesh.
‚ñ°
Theorem 5.2 Assume c and f are continuous on [a, b]. Then the solution u of
problem (5.3) is of class C2([a, b]) and there exists a constant C independent of u
such that
‚à•u ‚àíuh‚à•V ‚â§Ch max
x‚àà[a,b] |u‚Ä≤‚Ä≤(x)|.
(5.4)
Proof If f and c are continuous, since u is also continuous by Theorem3.7 of Chap.3,
then u‚Ä≤‚Ä≤ = cu ‚àíf is continuous on [a, b] and u ‚ààC2([a, b]). By C√©a‚Äôs lemma (viz.
Theorem5.1), we have

152
5
Variational Approximation Methods for Elliptic PDEs
Fig. 5.2 The Vh-interpolate
Œ†hv of a function v
x0
xi
xi+1
xN+1
‚à•u ‚àíuh‚à•V ‚â§M
Œ± inf
vh‚ààVh ‚à•u ‚àívh‚à•V .
We choose vh = Œ†hu. It follows that
‚à•u ‚àíuh‚à•V ‚â§M
Œ± ‚à•u ‚àíŒ†hu‚à•V ,
and we are left with estimating the rightmost norm.
Let us take the H1 semi-norm as a norm on V (this makes for simpler computa-
tions). We have
‚à•u ‚àíŒ†hu‚à•2
V =

 b
a
((u ‚àíŒ†hu)‚Ä≤(x))2 dx =
N

i=0

 xi+1
xi
(u‚Ä≤ ‚àí(Œ†hu)‚Ä≤(x))2 dx.
Let us consider the function w = u ‚àíŒ†hu on [xi, xi+1]. By deÔ¨Ånition of Vh-
interpolation, we have w(xi) = w(xi+1) = 0. Since w is C1 on [xi, xi+1], Rolle‚Äôs
theorem applies and there exists c ‚àà]xi, xi+1[ such that w‚Ä≤(c) = 0. Now, w is also of
class C2 on [xi, xi+1] so that
w‚Ä≤(x) =

 x
c
w‚Ä≤‚Ä≤(t) dt =

 x
c
u‚Ä≤‚Ä≤(t) dt
for all x ‚àà[xi, xi+1], since Œ†hu is afÔ¨Åne there, thus its second derivative vanishes. It
follows from this equality that
|w‚Ä≤(x)| ‚â§

 x
c
|u‚Ä≤‚Ä≤(t)| dt ‚â§

 xi+1
xi
|u‚Ä≤‚Ä≤(t)| dt ‚â§h
max
t‚àà[xi,xi+1] |u‚Ä≤‚Ä≤(t)| ‚â§h max
x‚àà[a,b] |u‚Ä≤‚Ä≤(x)|,
for all x ‚àà[xi, xi+1]. Squaring and integrating, we thus see that

5.2 The Finite Element Method in Dimension One
153

 xi+1
xi
((u ‚àí(Œ†hu))‚Ä≤(x))2 dx =

 xi+1
xi
(w‚Ä≤(x))2 dx ‚â§h2(xi+1 ‚àíxi) max
x‚àà[a,b] |u‚Ä≤‚Ä≤(x)|2.
Now we sum from i = 0 to N
‚à•u ‚àíŒ†hu‚à•2
V ‚â§h2 N

i=0
(xi+1 ‚àíxi)

max
x‚àà[a,b] |u‚Ä≤‚Ä≤(x)|2 = h2(b ‚àía) max
x‚àà[a,b] |u‚Ä≤‚Ä≤(x)|2.
Finally, we obtain
‚à•u ‚àíuh‚à•V ‚â§
M
Œ±
‚àö
b ‚àía

h max
x‚àà[a,b] |u‚Ä≤‚Ä≤(x)|,
which completes the proof.
‚ñ°
Remark 5.6 Note that we have not proved that the sequence Vh is a conforming
approximation sequence in the sense of DeÔ¨Ånition5.1. Rather, we have exploited
C√©a‚Äôs error estimate directly, coupled with an additional regularity hypothesis, here
that u be C2 essentially, to obtain an explicit error estimate and a convergence order
in O(h) when h ‚Üí0, see Fig.5.3. Note that u ‚ààH2(]a, b[) is sufÔ¨Åcient to obtain the
same error estimate, see Theorem6.2 of Chap.6 for a proof in the two-dimensional
case. More precisely, the following inequality holds true
‚à•u ‚àíŒ†hu‚à•V ‚â§Ch‚à•u‚à•H2(]a,b[),
(5.5)
which in turns implies the error estimate
‚à•u ‚àíuh‚à•V ‚â§Ch‚à•u‚à•H2(]a,b[),
(5.6)
Fig. 5.3 A Ô¨Åctitious
computation: the continuous
solution u, the discrete
solution uh, and the
Vh-interpolate Œ†hu of u used
to control the error between
the former two. Note that
only uh is effectively
computable
x0
xi
xi+1
xN+1
u
uh
hu

154
5
Variational Approximation Methods for Elliptic PDEs
due to C√©a‚Äôs lemma. This will be a general fact: additional regularity hypotheses on
the solution will be needed for explicit error estimates. Such regularity can however
often be deduced from elliptic regularity theory.
The sequence Vh is in fact a conforming approximation sequence, but this does
not turn out to be too useful, as the convergence toward a generic element of H1 can
be much slower than O(h).
‚ñ°
Let us now talk about the choice of a basis in Vh. Even though in principle, the
resolution of the Ô¨Ånite dimensional problem should not depend on the basis choice, in
practice this is an extremely important issue since the choice of basis directly impacts
the matrix A. A wrong choice of basis can lead to a linear problem that cannot be
solved numerically (bad conditioning, see Remark2.11 of Chap.2, full matrix) in
the sense that all theoretically convergent algorithms may fail or take too long or use
up too much computer memory. Recall that for a basis (w j), the matrix coefÔ¨Åcients
are given by
Ai j = a(w j, wi) =

 b
a
((w j)‚Ä≤(wi)‚Ä≤ + cw jwi) dx.
For numerical purposes, full matrices are to be avoided and sparse matrices pre-
ferred. Now, there is an easy way of making sure that Ai j = 0, given the above
formula, and that is to arrange for the supports of wi and w j to have negligible
intersection. So we want to Ô¨Ånd a basis for Vh for which the supports are as small
as possible, in order to minimize the intersections. Now clearly, the support of any
function of Vh is at least comprised of two elements. We thus deÔ¨Åne
DeÔ¨Ånition 5.2 For i = 1, . . . , N, let wi
h ‚ààVh be deÔ¨Åned by wi
h(xi) = 1 and wi
h(x j) =
0 for j = 0, . . . , N + 1, j Ã∏= i. We call these functions the hat functions or basis
functions for P1 Lagrange interpolation, see Fig.5.4.
Fig. 5.4 The hat function wi
h
with support [xi‚àí1, xi+1]
1
xi
xi‚àí1
xi+1
0

5.2 The Finite Element Method in Dimension One
155
As we have said before, all functions in Vh are determined by their nodal values.
In particular here, wi
h(a) = wi
h(b) = 0, since the endpoints correspond to j = 0 and
j = N + 1, and 1 ‚â§i ‚â§N. The term P1 Lagrange interpolation stems from the fact
that afÔ¨Åne functions are polynomials of degree at most 1, hence P1, and that these
functions are also used for Lagrange interpolation in Vh, as we will see shortly.
Proposition 5.3 The family (wi
h)i=1,...,N is a basis of Vh. Thus dim Vh = N. More-
over, we have the interpolation property
‚àÄvh ‚ààVh,
vh(x) =
N

i=1
vh(xi)wi
h(x),
(5.7)
for all x ‚àà[a, b].
Proof We use the Kronecker delta symbol: Œ¥i j = 1 if i = j, Œ¥i j = 0 otherwise. The
hat functions thus satisfy wi
h(x j) = Œ¥i j for i = 1, . . . , N and j = 0, . . . , N + 1.
Let us Ô¨Årst show that the family is linearly independent. Let Œªi be scalars such
that
N

i=1
Œªiwi
h = 0.
Evaluating this zero function at point x j yields
0 =
N

i=1
Œªiwi
h(x j) =
N

i=1
ŒªiŒ¥i j = Œª j
since in the last sum, the only nonzero term corresponds to i = j. Thus all coefÔ¨Åcients
vanish and the family is linearly independent.
Next we show that the family spans Vh. For all vh ‚ààVh, we deÔ¨Åne
vh =
N

i=1
vh(xi)wi
h ‚ààVh.
Now, of course vh ‚àívh ‚ààVh and sincevh(x j) = N
i=1 vh(xi)wi
h(x j) = N
i=1 vh(xi)
Œ¥i j = vh(x j) (same computation as above), then (vh ‚àívh)(x j) = 0 for all j =
0, . . . , N + 1. For each element [x j, x j+1], we thus see that vh ‚àívh is afÔ¨Åne on the
segment and vanishes at both endpoints, hence is identically zero on [x j, x j+1]. As
this is true for all j, we have vh ‚àívh = 0 on [a, b], that is to say vh = vh, which
shows both that the family is spanning and that we have formula (5.7).
The family (wi)i=1,...,N is linearly independent and spanning, thus is a basis of Vh.
It has N elements so that dim Vh = N.
‚ñ°

156
5
Variational Approximation Methods for Elliptic PDEs
Remark 5.7 The Lagrange interpolation property (5.7) is very important. It shows
that with this speciÔ¨Åc choice of basis, the coordinates of a function vh are precisely
its nodal values vh(xi). Hence solving the linear system AX = B is going to directly
provide the nodal values of the discrete solution uh, without any post-processing. The
linear forms vh ‚Üívh(xi), which belong to the dual V ‚àó
h of Vh, are called the degrees
of freedom in the FEM context. From the point of view of linear algebra, they are
just the dual basis of the basis (wi)i=1,...,N.
‚ñ°
Corollary 5.2 The N √ó N matrix A is tridiagonal in the hat functions basis.
Proof Indeed, the support of wi
h is [xi‚àí1, xi+1], therefore if |i ‚àíj| ‚â•2, then
xi‚àí1 ‚â•x j+1 or x j‚àí1 ‚â•xi+1 and the intersection of both supports is of zero mea-
sure, hence Ai j = 0. Thus, on any given line of the matrix A, we have at most three
nonzero coefÔ¨Åcients: Ai,i‚àí1 corresponding to the subdiagonal, Aii corresponding to
the diagonal and Ai,i+1 corresponding to the superdiagonal.
‚ñ°
Of course, a tridiagonal matrix is the best kind of matrix that can be expected,
apart from a diagonal matrix which cannot occur. This is because the problem is
exceedingly simple. Actually, it is easy to compute all nonzero coefÔ¨Åcients.
Proposition 5.4 If c = c0 and f = f0 are constant, then we have
Aii = 2
h + 2h
3 c0,
Ai,i‚àí1 = Ai,i+1 = ‚àí1
h + h
6c0 and Bi = h f0.
Proof We start by noticing that wi
h(x) = w1
h(x ‚àíxi) (extending w1
h by zero outside
of [a, b]), thus Aii = A11 and Ai,i‚àí1 = Ai,i+1 = A12.
It is easy to see that w1
h(x) =
x
h on [x0, x1] and w1
h(x) = 2 ‚àíx
h on [x1, x2],
0 elsewhere. Therefore, (w1
h)‚Ä≤(x) =
1
h on [x0, x1], (w1
h)‚Ä≤(x) = ‚àí1
h on [x1, x2], 0
elsewhere.
Thus
A11 =

 x2
x0
((w1
h)‚Ä≤(x)2 + c0w1
h(x)2) dx
=

 x1
x0
((w1
h)‚Ä≤(x)2 + c0w1
h(x)2) dx +

 x2
x1
((w1
h)‚Ä≤(x)2 + c0w1
h(x)2) dx
= 1
h2 √ó h + c0
h2

 x1
x0
x2 dx + 1
h2 √ó h + c0
h2

 x2
x1
(2h ‚àíx)2 dx
= 2
h + 2h
3 c0.
The intersection of the supports of w1
h and w2
h is [x1, x2], hence

5.2 The Finite Element Method in Dimension One
157
A12 =

 x2
x1
((w1
h)‚Ä≤(x)(w2
h)‚Ä≤(x) + c0w1
h(x)w2
h(x)) dx
= ‚àí1
h2 √ó h + c0
h2

 x2
x1
(2h ‚àíx)(x ‚àíh) dx
= ‚àí1
h + h
6c0.
We leave the last value to the reader.
‚ñ°
Remark 5.8 When c or f is not constant, the corresponding terms may not necessar-
ily be exactly computable and it may be necessary to resort to numerical integration
[23, 64, 71]. These terms however are corrections to the dominant terms 2
h and ‚àí1
h,
so that it can be shown that choosing a sufÔ¨Åciently accurate numerical integration
rule does not modify the Ô¨Ånal error estimate.
Numerical methods for linear systems are especially efÔ¨Åcient in the case of a
tridiagonal matrix. The LU factorization is very efÔ¨Åcient, but other methods can be
used such as the Cholesky factorization (the matrix is symmetric), the conjugate
gradient method, and so on, see [6, 18, 59].
‚ñ°
Let us now make a rapid comparison between the Ô¨Ånite element method and the
Ô¨Ånite difference method seen in Chap.2.
5.3
Comparison with the Finite Difference Method
We have shown that the Ô¨Ånite element method is of order one in the case of the
model one-dimensional example, cf. estimate (5.4), under the hypotheses c and f
continuous. Under a slightly stronger hypothesis, namely c and f of class C2, the
Ô¨Ånite difference error estimate (2.13) is of order two. It could thus be thought that
the Ô¨Ånite difference method is better than the Ô¨Ånite element method.
It should however be noticed that these errors are not measured in the same norms.
In particular, the Ô¨Ånite difference error estimate does not involve the derivative of u,
whereas the Ô¨Ånite element does. If we do not take the derivative into account, the
Ô¨Ånite element method also yields an error of order two in the L2 norm. This is called
the Aubin-Nitsche duality trick that we now explain.
Proposition 5.5 Assume that c ‚ààL‚àû(a, b) and f ‚ààL2(a, b), then u ‚ààH2(]a, b[)
and we have
‚à•u ‚àíuh‚à•L2(a,b) ‚â§Ch2‚à•u‚à•H2(]a,b[).
(5.8)
Proof We have seen that u‚Ä≤‚Ä≤ = cu ‚àíf in the sense of D‚Ä≤(]a, b[). Since c ‚ààL‚àû(a, b)
and u ‚ààL2(a, b), it follows that u‚Ä≤‚Ä≤ ‚ààL2(a, b), hence that u ‚ààH2(]a, b[). Let us set
eh = u ‚àíuh. We deÔ¨Åne the adjoint variational problem: Find w ‚ààV such that

158
5
Variational Approximation Methods for Elliptic PDEs
‚àÄv ‚ààV,
a(w, v) =

 b
a
eh(x)v(x) dx.
(5.9)
Clearly, w ‚ààH2(]a, b[) with ‚àíw‚Ä≤‚Ä≤ + cw = eh almost everywhere in ]a, b[. By
Proposition4.3 of Chap.4, we thus have ‚à•w‚à•V ‚â§C‚à•eh‚à•L2(a,b). Therefore,
‚à•w‚Ä≤‚Ä≤‚à•L2(a,b) ‚â§‚à•c‚à•L‚àû(a,b)‚à•w‚à•L2(a,b) + ‚à•eh‚à•L2(a,b) ‚â§C‚à•eh‚à•L2(a,b),
where C is a constant that changes from line to line. It follows that ‚à•w‚à•H2(]a,b[) ‚â§
C‚à•eh‚à•L2(a,b).1
We know that a(eh, vh) = 0 for all vh ‚ààVh. Consequently
‚à•eh‚à•2
L2(a,b) =

 b
a
eh(x)eh(x) dx = a(w, eh) = a(eh, w)
= a(eh, w ‚àíŒ†hw) ‚â§M‚à•eh‚à•V ‚à•w ‚àíŒ†hw‚à•V ,
where we have used the dual problem (5.9), and the symmetry and continuity of the
bilinear form a. By the error estimate (5.6), we have
‚à•eh‚à•V ‚â§Ch‚à•u‚à•H2(]a,b[),
on the one hand, and by the interpolation estimate (5.5), we have
‚à•w ‚àíŒ†hw‚à•V ‚â§Ch‚à•w‚à•H2(]a,b[) ‚â§Ch‚à•eh‚à•L2(a,b),
on the other hand. Combining the above estimates, we obtain
‚à•eh‚à•2
L2(a,b) ‚â§Ch2‚à•u‚à•H2(]a,b[)‚à•eh‚à•L2(a,b),
hence the result.
‚ñ°
It is interesting to make a numerical comparison of the Ô¨Ånite element method with
the Ô¨Ånite difference method in the present context. When c and f are smooth, we
know from the theory that both methods should give good results of about the same
order, and this is conÔ¨Årmed by numerical experiments. We can make the situation a
little more challenging for the Ô¨Ånite difference method by taking nonsmooth data,
which the Ô¨Ånite element method should be able to handle correctly.
Consider thus the homogeneous Dirichlet problem ‚àíu‚Ä≤‚Ä≤ = f in ]0, 1[, u(0) =
u(1) = 0, with f (x) = 20 for x ‚àà] 1
2 ‚àí1
40, 1
2 + 1
40[, f (x) = 0 otherwise.2 We plot in
Fig.5.5 the exact solution, the numerical Ô¨Ånite element solution and the numerical
Ô¨Ånite difference solution.
1This is an elliptic regularity estimate.
2This right-hand side is an approximation of the Dirac mass Œ¥ 1
2 .

5.3 Comparison with the Finite Difference Method
159
Estimate (5.4) is not valid since f is not continuous. However, this function is
in L2(0, 1), and estimate (5.6) applies. Now it is not entirely clear whether or not
the Ô¨Ånite difference method converges in this case, but it is obviously having a
signiÔ¨Åcantly harder time than the Ô¨Ånite element method.
In particular, we see on Fig.5.5 that the convergence of the Ô¨Ånite element method
is very good, with an excellent agreement even for small values of N. On the other
hand, the behavior of the Ô¨Ånite difference approximation is curious. There is a marked
difference between successive values of N, depending on parity. In any case, the
numerical convergence of the Ô¨Ånite difference approximation is here much slower
than the convergence of the Ô¨Ånite element method.
5.4
A Fourth Order Example
Let us now brieÔ¨Çy consider the beam problem
 u(4) + cu = f in Œ©,
u(a) = u(b) = u‚Ä≤(a) = u‚Ä≤(b) = 0.
(5.10)
The variational formulation of this problem is set in V = H2
0(]a, b[) and since
H2(]a, b[) ‚ÜíC1([a, b]), the previous P1 Ô¨Ånite element method is not adapted (exer-
cise, show that if v is piecewise afÔ¨Åne, then v‚Ä≤‚Ä≤ = N
i=1(Œªi ‚àíŒªi‚àí1)Œ¥xi /‚ààL2(a, b)). We
need higher degree polynomials to not only match the values, but also the derivatives
at mesh nodes. In the following, Pk denotes the space of polynomials of degree at
most k. We thus deÔ¨Åne
Vh = {vh ‚ààC1([a, b]); vh|[xi,xi+1] ‚ààP3 for i = 0, . . . , N,
vh(a) = vh(b) = v‚Ä≤
h(a) = v‚Ä≤
h(b) = 0}.
A natural question is why not simply use P2 polynomials. The reason is that even
though in this case, the space Vh is not reduced to {0}, its description is very unwieldy
and it is not clear that it can be used for approximation purposes. This is because the
determination of a P2 polynomial on an interval requires three interpolation data. It
is thus possible to interpolate the value of the polynomial and of its derivative at one
end of an interval, but then, there is only one interpolation value left at the other end,
which makes it difÔ¨Åcult to ensure that the piecewise P2 function thus constructed is
globally C1 and satisÔ¨Åes the boundary conditions.
The above difÔ¨Åculty disappears for degrees k ‚â•3 as we will see shortly.
Proposition 5.6 We have Vh ‚äÇH2
0(]a, b[).
Proof Argue as in the proof of Proposition5.2.
‚ñ°
We thus need C1 functions, and in order to ensure the continuity and derivability
at the endpoints of each element, we need to be able to specify both the value of

160
5
Variational Approximation Methods for Elliptic PDEs
0.00
0.05
0.10
0.15
0.20
0.25
0.30
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
N = 19
0.00
0.05
0.10
0.15
0.20
0.25
0.30
0.35
0.40
0.45
0.50
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
N = 20
0.00
0.05
0.10
0.15
0.20
0.25
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
N = 29
0.00
0.05
0.10
0.15
0.20
0.25
0.30
0.35
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
N = 30
0.00
0.05
0.10
0.15
0.20
0.25
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
N = 59
0.00
0.05
0.10
0.15
0.20
0.25
0.30
0.35
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
N = 60
0.00
0.05
0.10
0.15
0.20
0.25
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
N = 199
0.00
0.05
0.10
0.15
0.20
0.25
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
N = 200
Fig. 5.5 Comparison Ô¨Ånite difference (√ó marks), Ô¨Ånite elements (+ marks) and exact solution
(solid curve), for different values of N

5.4 A Fourth Order Example
161
the polynomial and of its derivative. The simplest way to achieve this is to use P3
Hermite interpolation. Let us rapidly present this interpolation.
Proposition 5.7 For all quadruplets (Œ±0, Œ±1, Œ≤0, Œ≤1) of scalars, there exists a unique
polynomial P ‚ààP3 such that
P(0) = Œ±0,
P(1) = Œ±1,
P‚Ä≤(0) = Œ≤0,
P‚Ä≤(1) = Œ≤1.
This polynomial is given by
P = Œ±0p0 + Œ±1p1 + Œ≤0q0 + Œ≤1q1,
where the P3 Hermite basis polynomials p0, p1, q0 and q1 are given by
p0(x) = (1 ‚àíx)2(1 + 2x), p1(x) =x2(3 ‚àí2x),
q0(x) = x(1 ‚àíx)2, q1(x) = x2(x ‚àí1). (5.11)
Proof The proof of Proposition5.7 follows from a simple dimension argument: we
show that the linear mapping P3 ‚ÜíR4, P ‚Üí(P(0), P(1), P‚Ä≤(0), P‚Ä≤(1)) is an iso-
morphism. Since P3 is four-dimensional, it sufÔ¨Åces to show that its kernel is trivial.
But a polynomial such that P(0) = P(1) = P‚Ä≤(0) = P‚Ä≤(1) = 0 has a double root at
x = 0 and another double root at x = 1, hence a number of roots counting multi-
plicities of at least four. We know that a nonzero polynomial of degree at most three
has at most three roots. Hence P = 0.
The inverse image of the canonical basis of R4 by the previous isomorphism
forms a basis of P3. Its elements are uniquely determined by the following interpo-
lation values: (Œ±0, Œ±1, Œ≤0, Œ≤1) = (1, 0, 0, 0) for p0, (Œ±0, Œ±1, Œ≤0, Œ≤1) = (0, 1, 0, 0) for
p1, (Œ±0, Œ±1, Œ≤0, Œ≤1) = (0, 0, 1, 0) for q0 and (Œ±0, Œ±1, Œ≤0, Œ≤1) = (0, 0, 0, 1) for q1.
Therefore, any polynomial P of P3 is uniquely written as
P = P(0)p0 + P(1)p1 + P‚Ä≤(0)q0 + P‚Ä≤(1)q1.
Formulas (5.11) can then be checked by hand, see Fig.5.6.
‚ñ°
In FEM language, the linear forms P ‚ÜíP(0), P ‚ÜíP(1), P ‚ÜíP‚Ä≤(0) and
P ‚ÜíP‚Ä≤(1) are the degrees of freedom of P3 Hermite interpolation on the reference
element [0, 1].
Once we have Hermite interpolation on the reference element [0, 1], we have
Hermite interpolation on any element [xi, xi+1] by a simple afÔ¨Åne change of variables:
p0
 x‚àíxi
h

, p1
 x‚àíxi
h

, hq0
 x‚àíxi
h

and hq1
 x‚àíxi
h

.
Lemma 5.2 There exists a unique continuous linear mapping Œ†h : H2
0(]a, b[) ‚Üí
Vh, again called the Vh-interpolation operator such that for all v in H2
0(]a, b[), v(xi) =
Œ†hv(xi) and v‚Ä≤(xi) = (Œ†hv)‚Ä≤(xi) for i = 0, . . . , N + 1.

162
5
Variational Approximation Methods for Elliptic PDEs
Fig. 5.6 The four P3
Hermite basis polynomials
0
1
1
p0
p1
q0
q1
Proof First of all, we note that H2
0(]a, b[) ‚ÜíC1([a, b]), therefore the nodal values
v(xi) and v‚Ä≤(xi) are unambiguously deÔ¨Åned.
Now a P3 polynomial on [xi, xi+1] is uniquely determined by its values and the
values of its derivative at xi and xi+1, by Hermite interpolation. Thus, the relations
v(xi) = Œ†hv(xi) and v‚Ä≤(xi) = (Œ†hv)‚Ä≤(xi) for i = 0, . . . , N + 1 deÔ¨Åne a unique
piecewise P3 function on the mesh, that is globally C1 and vanishes at both ends
together with its derivatives, thus belongs to Vh. Let Œ†hv be this function. Clearly,
the mapping v ‚ÜíŒ†hv is linear from H1
0(]a, b[) into Vh. We leave the continuity to
the reader.
‚ñ°
The above proof also shows that Vh Ã∏= {0}. We can now show an error estimate,
along the same lines as before.
Proposition 5.8 Assume c and f are continuous on [a, b]. Then the solution u of
problem (5.10) is of class C4([a, b]) and there exists a constant C independent of u
such that
‚à•u ‚àíuh‚à•V ‚â§Ch2 max
x‚àà[a,b] |u(4)(x)|.
Proof If f and c are continuous, since u is also continuous by Theorem3.7 of Chap.3,
then u(4) = cu ‚àíf is continuous on [a, b] and thus u ‚ààC4([a, b]). By C√©a‚Äôs lemma,
i.e., Theorem5.1, we have
‚à•u ‚àíuh‚à•V ‚â§M
Œ± ‚à•u ‚àíŒ†hu‚à•V .
We use the H2 semi-norm as a norm on V . We have
‚à•u ‚àíŒ†hu‚à•2
V =

 b
a
((u ‚àíŒ†hu)‚Ä≤‚Ä≤(x))2 dx =
N

i=0

 xi+1
xi
(u‚Ä≤‚Ä≤(x) ‚àí(Œ†hu)‚Ä≤‚Ä≤(x))2 dx.

5.4 A Fourth Order Example
163
Let us consider the function w = u ‚àíŒ†hu on [xi, xi+1]. By deÔ¨Ånition of Vh-
interpolation, we have w(xi) = w(xi+1) = 0. Since w is C1 on [xi, xi+1], Rolle‚Äôs
theorem applies and there exists c1 ‚àà]xi, xi+1[ such that w‚Ä≤(c1) = 0. Now, we also
have w‚Ä≤(xi) = w‚Ä≤(xi+1) = 0 by Vh-interpolation, and w‚Ä≤ is also of class C1 so that
Rolle applies again and there exists c2 < c1 < c3 such that w‚Ä≤‚Ä≤(c2) = w‚Ä≤‚Ä≤(c3) = 0.
We apply Rolle one last time since w‚Ä≤‚Ä≤ is C1 and obtain a point c4 ‚àà[xi, xi+1] such
that w‚Ä≤‚Ä≤‚Ä≤(c4) = 0. Consequently
w‚Ä≤‚Ä≤‚Ä≤(x) =

 x
c4
w(4)(t) dt =

 x
c4
u(4)(t) dt
for all x ‚àà[xi, xi+1], since Œ†hu is of degree at most three there, thus its fourth
derivative vanishes. It follows from this equality that
|w‚Ä≤‚Ä≤‚Ä≤(x)| ‚â§

 x
c4
|u(4)(t)| dt ‚â§

 xi+1
xi
|u(4)(t)| dt ‚â§h max
x‚àà[a,b] |u(4)(x)|,
for all x ‚àà[xi, xi+1]. We also have
w‚Ä≤‚Ä≤(x) =

 x
c2
w‚Ä≤‚Ä≤‚Ä≤(t) dt,
so that substituting the previous estimate yields
|w‚Ä≤‚Ä≤(x)| ‚â§h2 max
x‚àà[a,b] |u(4)(x)|.
Squaring and integrating, we thus see that

 xi+1
xi
(u‚Ä≤‚Ä≤(x) ‚àí(Œ†hu)‚Ä≤‚Ä≤(x))2 dx =

 xi+1
xi
(w‚Ä≤‚Ä≤(x))2 dx ‚â§h4(xi+1 ‚àíxi) max
x‚àà[a,b] |u(4)(x)|2.
Now we sum from i = 0 to N
‚à•u ‚àíŒ†hu‚à•2
V ‚â§h4(b ‚àía) max
x‚àà[a,b] |u(4)(x)|2,
which completes the proof.
‚ñ°
Remark 5.9 Under regularity hypotheses, we thus have convergence of the P3 Her-
mite FEM based on the smallness of the interpolation error. It should be noted that
this kind of proof relying on Rolle‚Äôs theorem is not very natural in a Sobolev space
context. There are better proofs using Hilbertian arguments.
‚ñ°
Let us say a few words about bases and matrices. It is apparent that the operator
Œ†h only uses the nodal values of the function and its derivatives. Hence, any set of
interpolation data with N elements for the values and N elements for the derivative
values gives rise to one and only one element of Vh. We thus deÔ¨Åne

164
5
Variational Approximation Methods for Elliptic PDEs
Fig. 5.7 A wi
h basis function
Fig. 5.8 A zi
h basis function
DeÔ¨Ånition 5.3 For i = 1, . . . , N, let wi
h ‚ààVh be deÔ¨Åned by
wi
h(x j) = Œ¥i j and (wi
h)‚Ä≤(x j) = 0,
and zi
h ‚ààVh be deÔ¨Åned by
zi
h(x j) = 0 and (zi
h)‚Ä≤(x j) = Œ¥i j,
for j = 0, . . . , N + 1. We call these functions the basis functions for P3 Hermite
interpolation on the mesh.
The function wi
h is thus equal to 1 at xi and zero at all other nodes, with zero
derivatives at all nodes, whereas the function zi
h has derivative 1 at xi and zero at
all other nodes, with zero values at all nodes, see Figs.5.7 and 5.8. Clearly they are
constructed by pairing together the Hermite basis interpolation polynomials in each
element [xi‚àí1, xi] and [xi, xi+1], which are also called shape functions in the FEM
context.
Proposition 5.9 The family (wi
h, zi
h)i=1,...,N is a basis of Vh. Thus dim Vh = 2N.
Moreover, we have the interpolation property
‚àÄvh ‚ààVh,
vh(x) =
N

i=1
vh(xi)wi
h(x) +
N

i=1
v‚Ä≤
h(xi)zi
h(x).
Proof Similar to the proof of Proposition5.3 but using P3 Hermite interpolation in
each element.
‚ñ°
The supports of the basis functions are again [xi‚àí1, xi+1], thus we can expect lots
of zero coefÔ¨Åcients in the matrix. We do not write the detail here. Let us just mention
that there is an issue of numbering. In the P1 Lagrange case, there was a natural
numbering of basis functions, which was that of the nodes. Here we have several
choices, leading to different matrices. If we choose to number the basis elements as
(w1
h, w2
h, . . . , wN
h , z1
h, z2
h, . . . , zN
h ), then the 2N √ó 2N matrix A is comprised of four

5.4 A Fourth Order Example
165
Fig. 5.9 Matrix structure.
Left block tridiagonal, right
interlaced
N √ó N blocks, and each one of the blocks is tridiagonal. If on the other hand, we
interlace the basis functions like (w1
h, z1
h, w2
h, z2
h, . . . , wN
h , zN
h ), we obtain a matrix
whose nonzero coefÔ¨Åcients are grouped around the diagonal, this is called a band
matrix. More precisely, each row of A has at most six nonzero coefÔ¨Åcients resulting
in seven nonzero diagonal rows: the diagonal plus three above the diagonal and three
under the diagonal, see Fig.5.9.
5.5
Neumann and Fourier Conditions
LetusbrieÔ¨ÇyindicatehowtodealwithNeumannandFourierconditionsforthemodel
second order problem. There are several changes: the test-function space must not
enforce boundary conditions, i.e., V = H1(]a, b[), additional terms come up in the
right hand-side for both problems, and there is an additional term in the bilinear form
for the Fourier condition. Let us just consider the case c ‚â•c0 > 0. We thus let
Vh = {vh ‚ààC0([a, b]); vh|[xi,xi+1] ‚ààP1}.
Compared to the previous version of Vh, we have added two degrees of freedom
vh ‚Üív(a) and vh ‚Üív(b), hence dim Vh = N + 2. We must accordingly complete
the basis by adding two more basis functions w0
h and wN+1
h
deÔ¨Åned by w0
h(x j) = Œ¥0 j
and wN+1
h
(x j) = Œ¥N+1, j for all j ‚àà{0, . . . , N + 1}, see Fig.5.10.
The variational formulation for the Fourier problem (replacing b by d in the
Fourier condition to avoid a conÔ¨Çict in notation with the boundary b) is
Fig. 5.10 The two
additional basis functions w0
h
left and wN+1
h
right
x0
x1
xN
xN+1

166
5
Variational Approximation Methods for Elliptic PDEs

 b
a
(u‚Ä≤v‚Ä≤ + cuv) dx + (duv)(a) + (duv)(b) =

 b
a
f v dx + (gv)(a) + (gv)(b).
We just set d = 0 for the Neumann problem. In matrix terms, the (N + 2) √ó (N + 2)
matrix A is still symmetric tridiagonal, and we have for c and d constants,
A00 = AN+1,N+1 = 1
h + h
3c + d
and
A01 = A10 = AN,N+1 = AN+1,N = ‚àí1
h + h
6c.
Of course
A0i = Ai0 = A j,N+1 = AN+1, j = 0
for i ‚â•2 and j ‚â§N ‚àí1. The other coefÔ¨Åcients are unchanged. The right-hand side
has two additional components B0 = h f
2 + g(a) and BN+1 = h f
2 + g(b).
Similar changes must be made to treat a fourth order Neumann problem.
In the next chapter, we consider the Ô¨Ånite element method in two dimensions.
The abstract framework does not change, but the algebraic and geometric aspects are
considerably more elaborate.

Chapter 6
The Finite Element Method in Dimension
Two
It should already be clear that there is no difference between elliptic problems in one
dimensionandellipticproblemsinseveraldimensionsfromthevariationalviewpoint.
The same goes for the abstract part of variational approximations. The difference lies
in the description of the Ô¨Ånite dimensional approximation spaces. The FEM in any
dimension of space is based on the same principle as in one dimension, that is to
say, we consider spaces of piecewise polynomials of low degree, with lots of pieces
for accuracy. Now things are right away quite different, and actually considerably
more complicated, since polynomials have several variables, and open sets are much
more varied than in dimension one. For simplicity, we limit ourselves to the two-
dimensional case.
6.1
Meshes in 2d
Let Œ© be an open subset of R2. The idea is to cover ¬ØŒ© with a Ô¨Ånite number of closed
sets Tk of simple shape, ¬ØŒ© = NT
k=1 Tk, with T = {Tk}1‚â§k‚â§NT and NT = card T .
This decomposition will be used to decompose integrals over Œ© into sums of integrals
overtheTk,thusweimposethatmeas (Tk ‚à©Tk‚Ä≤) = 0fork Ã∏= k‚Ä≤.Wewillonlyconsider
two cases:
‚Ä¢ The Tk are closed rectangles and ¬ØŒ© is a union of rectangles. For deÔ¨Åniteness,
the sides of the rectangles will be parallel to the coordinate axes, without loss of
generality, see Fig.6.1.
‚Ä¢ The Tk are closed triangles and ¬ØŒ© is a polygon, see Fig.6.2.
Such a structure will be called a triangulation (even in the case of rectangles ‚Ä¶)
or mesh on Œ©. The Tk are called the elements, their sides are called the edges, and
¬© Springer International Publishing Switzerland 2016
H. Le Dret and B. Lucquin, Partial Differential Equations:
Modeling, Analysis and Numerical Approximation, International Series
of Numerical Mathematics 168, DOI 10.1007/978-3-319-27067-8_6
167

168
6
The Finite Element Method in Dimension Two
Fig. 6.1 A rectangular mesh
Tk
Fig. 6.2 A triangular mesh
Tk
their vertices are called mesh nodes.1 The fact that ¬ØŒ© must be a union of rectangles
or more generally a polygon can appear to be unduly restrictive. There are however
ways of going around this restriction and to cover very general domains, see [19, 21]
for example.
In practice, meshes in a domain are not given but must be constructed by computer.
This is a subject all by itself called automatic mesh generation. We will not pursue
this subject here, but refer the reader to [39] for example. See Fig.6.3 for a real-life
example of three-dimensional mesh.
From now on, ¬ØŒ© will always be a polygon in R2.
Given a mesh T = {Tk}1‚â§k‚â§NT , we let h(Tk) = diam Tk = supx,y‚ààTk ‚à•x ‚àíy‚à•and
h = max
Tk‚ààT h(Tk).
1There are often additional mesh nodes, as we will see later.

6.1 Meshes in 2d
169
Fig. 6.3 A real life mesh in
3d. The elements are
tetrahedra that Ô¨Åll the
volume, we just see
triangular faces of those
tetrahedra that touch the
boundary. We will not talk
about 3d problems in this
book, even though most real
life problems occur in 3d.
The conceptual difference
between 3d and 2d is much
less marked than between 2d
and 1d
The scalar h is called the mesh size. The approximation spaces will thus be of the
form
Vh = {v ‚ààV ; v|Tk is a low degree polynomial},
to be made more precise later. This is again a case of bad traditional notation, since
Vh does not depend solely on h, but on the whole mesh, of which h is but one
characteristic length. Accordingly, when we say h ‚Üí0, this means that we are given
a sequence (Tn)n‚ààN of meshes whose mesh size tends to 0 when n ‚Üí+‚àû, and we
will use the classical notation Th instead. Naturally in practice, computer calculations
are executed on one or a small number of meshes. The convergence h ‚Üí0 is only
for theoretical purposes.
In order to be of use, a triangulation must satisfy a certain number of properties.
DeÔ¨Ånition 6.1 A mesh is said to be admissible if
(i) For all k Ã∏= k‚Ä≤, Tk ‚à©Tk‚Ä≤ is either empty, or consists of exactly one node or of one
entire edge.
(ii) No Tk is of zero measure.
Condition (ii) means that no triangle or rectangle is degenerated, that is to say that
no element has all its vertices on a straight line. Condition (i) is easier to understand
in terms of which situations it precludes. For instance, any one of the three cases
shown on Fig.6.4 is forbidden.
For any triangle T, let œÅ(T) be the diameter of the inscribed circle (the center of
the inscribed circle is called the incenter and is located at the intersection of the three
internal angle bissectors, see Fig.6.5).

170
6
The Finite Element Method in Dimension Two
Fig. 6.4 Forbidden meshes
according to rule (i)
Fig. 6.5 Triangle incircle
and diameter
œÅ T
h T
T
DeÔ¨Ånition 6.2 Let Th be a sequence of triangular meshes whose mesh size h tends
to 0. We say that the sequence is a regular family if there exists a constant C > 0
such that for all h,
max
T‚ààTh
h(T)
œÅ(T) ‚â§C.
For a sequence of meshes, not to be regular means that there are smaller and
smallertrianglesthatbecomearbitrarilyÔ¨Çat.Ofcourse,thedeÔ¨ÅnitionneedsaninÔ¨Ånite
sequence of meshes to make sense. A similar condition for rectangular meshes is that
the ratio of the longer side by the smaller side of each rectangle remains bounded
from above. This property is needed for convergence results, as we will see in the

6.1 Meshes in 2d
171
proof of Lemma 6.4, p. 181. Note moreover that computations on a mesh such that
maxT‚ààTh
h(T)
œÅ(T) is large may run into numerical difÔ¨Åculties, so the regularity condition
is also relevant from the practical point of view.
Let us now give a general purpose proposition on piecewise regular functions on
a mesh.
Proposition 6.1 Let T be an admissible mesh on Œ©. DeÔ¨Åne
Xh = {v ‚ààC0( ¬ØŒ©); v|Tk ‚ààC1(Tk) for all Tk ‚ààT }.
Then we have Xh ‚äÇH1(Œ©) and ‚àÇiv = NT
k=1 ‚àÇi(v|Tk)1Tk for all v ‚ààXh.
Proof Let v ‚ààXh. Clearly, v ‚ààL2(Œ©) and we just need to compute its partial deriv-
atives in the sense of distributions. Let us thus take an arbitrary function œï ‚ààD(Œ©).
We have
‚ü®‚àÇiv, œï‚ü©= ‚àí‚ü®v, ‚àÇiœï‚ü©= ‚àí

Œ©
v‚àÇiœï dx = ‚àí
NT

k=1

Tk
v‚àÇiœï dx.
Now v is C1 on each Tk, which is a closed triangle or rectangle, therefore we can use
the integration by parts formula to obtain
‚àí

Tk
v‚àÇiœï dx =

Tk
‚àÇi(v|Tk)œï dx ‚àí

‚àÇTk
vnk,iœï dŒì
=

Œ©
‚àÇi(v|Tk)1Tkœï dx ‚àí

‚àÇTk
vnk,iœï dŒì,
where nk denotes the unit exterior normal vector to ‚àÇTk. Note that since v ‚ààC0( ¬ØŒ©)
there is no need to take the restriction of v to Tk in the boundary term. Summing on
all triangles or rectangles, we obtain
‚ü®‚àÇiv, œï‚ü©=

Œ©
 NT

k=1
‚àÇi(v|Tk)1Tk

œï dx ‚àí
NT

k=1

‚àÇTk
vnk,iœï dŒì.
Now, each ‚àÇTk is composed of three or four edges and there are two cases:
1. Either the edge in question is included in ‚àÇŒ© and in this case œï = 0, hence the
corresponding integral vanishes.
2. Or the edge is included in Œ© (except possibly for one node) and in this case, by
condition (i) of mesh admissibility, see DeÔ¨Ånition 6.1, this edge is the intersection
of exactly two elements Tk and Tk‚Ä≤. The two integrals corresponding to this edge
cancel out each other, since vœï is continuous, it takes the same value on ‚àÇTk ‚à©‚àÇTk‚Ä≤
as seen from either side, and nk = ‚àínk‚Ä≤, see Fig.6.6.

172
6
The Finite Element Method in Dimension Two
Fig. 6.6 Pairwise
cancellation of edge integrals
Finally, we see that
NT

k=1

‚àÇTk
vnk,iœï dŒì = 0
and since the function NT
k=1 ‚àÇi(v|Tk)1Tk is bounded, it is also in L2(Œ©).
‚ñ°
Remark 6.1 The above proof shows that in fact Xh ‚äÇW 1,‚àû(Œ©).
‚ñ°
6.2
Rectangular Q1 Finite Elements
We start over with the model problem
‚àíŒîu + cu = f in Œ©,
u = 0 on ‚àÇŒ©,
(6.1)
with f ‚ààL2(Œ©), c ‚ààL‚àû(Œ©), c ‚â•0 and Œ© = ]0, 1[√ó]0, 1[. The variational formula-
tion is of course of the general form (4.6) with V = H1
0(Œ©), a(u, v) =
	
Œ©(‚àáu ¬∑ ‚àáv + cuv) dx and ‚Ñì(v) =
	
Œ© f v dx.
Let us be given two positive integers N1 and N2 and let h1 =
1
N1+1 and h2 =
1
N2+1.
We deÔ¨Åne a rectangular mesh on Œ© by setting
Rk = {(x1, x2); i1h1 ‚â§x1 ‚â§(i1 + 1)h1, i2h2 ‚â§x2 ‚â§(i2 + 1)h2,
i1 = 0, . . . , N1, i2 = 0, . . . , N2}.
The elements are rectangles with sides parallel to the coordinate axes and of lengths
h1 and h2, see Fig.6.7. There are NT = (N1 + 1)(N2 + 1) elements. In the above
formula, we have k = 1, . . . , NT . As we will see later on, the actual numbering of
the rectangles, i.e., the function (i1, i2) ‚Üík, is largely irrelevant. The mesh size is

6.2 Rectangular Q1 Finite Elements
173
Fig. 6.7 A rectangular mesh
on Œ© = ]0, 1[2, 32 elements,
45 nodes
x1
x2
h1
h2
h =

h2
1 + h2
2. Actually, since max(h1, h2) ‚â§h ‚â§
‚àö
2 max(h1, h2), we may as well
take h = max(h1, h2). The inscribed circle has diameter min(h1, h2), so the regularity
requirement for a family of such meshes would be that max(h1,h2)
min(h1,h2) ‚â§C, or roughly
speaking that N1 and N2 be of the same order of magnitude.
The mesh nodes are the points (i1h1, i2h2), i1 = 0, . . . , N1 + 1, , i2 = 0, . . . ,
N2 + 1. There is a total of Ntot = (N1 + 2)(N2 + 2) nodes, including 2(N1 + 1) +
2(N2 + 1) = 2(N1 + N2) + 4 = Nbdy boundary nodes located on ‚àÇŒ© and Nint =
N1N2 interior nodes located in Œ©. Of course, Ntot = Nint + Nbdy. We will talk about
numbering issues later (numbering of nodes, numbering of elements).
Let us now talk about the discrete approximation space. We Ô¨Årst state a few facts
about the algebra of polynomials in several variables. First of all, there are several
notions of degree for such polynomials. The total degree of a nonzero monomial
in two variables axn
1xm
2 is n + m (and the obvious generalization for more variables,
that we will not use here). The total degree of a polynomial is the maximum total
degree of its monomials. The partial degree of the same monomial is max(n, m).
The partial degree of a polynomial is the maximum partial degree of its monomials.
Since we are working on an inÔ¨Ånite number Ô¨Åeld, R, we can identify polynomials
and polynomial functions on an open set of R2. We will perform this identiÔ¨Åcation
freely.
There are two families of spaces of polynomials that will be of interest to us.
DeÔ¨Ånition 6.3 For each k ‚ààN, we denote by Pk the space of polynomials of total
degree less than or equal to k and by Qk the space of polynomials of partial degree
less than or equal to k.

174
6
The Finite Element Method in Dimension Two
Both spaces obviously are vector spaces. It is an easy exercise in algebra to establish
that dim Pk = (k+1)(k+2)
2
and dim Qk = (k + 1)2.
Since the total degree of a polynomial is always larger than its partial degree, it
follows that Pk ‚äÇQk. Moreover, as the Qk monomial xk
1xk
2 is clearly of the highest
possible total degree, we also have Qk ‚äÇP2k. The only value of k for which these
spaces coincide is thus k = 0, with only constant polynomials. The space P1 is the
space of afÔ¨Åne functions
P1 = {p; p(x) = a0 + a1x1 + a2x2, ai ‚ààR}
and the space Q1 is described in terms of its canonical basis
Q1 = {p; p(x) = a0 + a1x1 + a2x2 + a3x1x2, ai ‚ààR}.
We can now introduce the corresponding approximation spaces. We start with a
version without boundary conditions
Wh = {vh ‚ààC0( ¬ØŒ©); ‚àÄRk ‚ààT , vh|Rk ‚ààQ1},
and the subspace thereof that includes homogeneous Dirichlet conditions
Vh = {vh ‚ààWh; vh = 0 on ‚àÇŒ©},
see Remark 3.23 of Chap.3.
The space Wh thus consists of globally continuous functions the restriction of
which to each element coincides with one Q1 polynomial per element. It is the same
ideaasindimension1.SinceQ1 polynomialsareofcourseofclassC1,Proposition6.1
immediately implies
Proposition 6.2 We have Wh ‚äÇH1(Œ©) and Vh ‚äÇH1
0(Œ©).
We now establish interpolation results for Q1 polynomials and piecewise Q1 func-
tions. We start with a uniqueness result.
Proposition 6.3 A function of Wh is uniquely determined by its values at the nodes
of the mesh.
Proof A function vh in Wh is uniquely determined by the values it takes in each
rectangular element, that is to say by the NT polynomials in Q1 that correspond to
each element. It is thus sufÔ¨Åcient to argue element by element. Let R be such an
element and Si = (xi
1, xi
2) be its four vertices numbered counterclockwise starting
from the lower left corner, see Fig.6.8.
We have h1 = xi
1 ‚àíx1
1 for i = 2, 3 and h2 = xi
2 ‚àíx1
2 for i = 3, 4. Since vh is equal
to a Q1 polynomial in R, there exists four constants Œ± j, j = 1, . . . , 4 such that
vh(x) = Œ±1 + Œ±2(x1 ‚àíx1
1) + Œ±3(x2 ‚àíx1
2) + Œ±4(x1 ‚àíx1
1)(x2 ‚àíx1
2).

6.2 Rectangular Q1 Finite Elements
175
Fig. 6.8 A generic rectangle
R in the mesh
S3
S2
S4
S1
R
x1
x2
Let us express the values of vh at the four vertices.
vh(S1) = Œ±1
vh(S2) = Œ±1 + Œ±2(x2
1 ‚àíx1
1) + Œ±3(x2
2 ‚àíx1
2) + Œ±4(x2
1 ‚àíx1
1)(x2
2 ‚àíx1
2)
= Œ±1 + Œ±2h1
since x2
2 = x1
2,
vh(S4) = Œ±1 + Œ±3h2
vh(S3) = Œ±1 + Œ±2h1 + Œ±3h2 + Œ±4h1h2.
This is a 4 √ó 4 linear system in the four unknowns Œ± j which we can rewrite in matrix
form
‚éõ
‚éú‚éú‚éù
1 0 0
0
1 h1 0
0
1 0 h2
0
1 h1 h2 h1h2
‚éû
‚éü‚éü‚é†
‚éõ
‚éú‚éú‚éù
Œ±1
Œ±2
Œ±3
Œ±4
‚éû
‚éü‚éü‚é†=
‚éõ
‚éú‚éú‚éù
vh(S1)
vh(S2)
vh(S4)
vh(S3)
‚éû
‚éü‚éü‚é†.
The determinant of the triangular matrix above is h2
1h2
2 Ã∏= 0, hence the system has
one and only one solution for any given vertex values for vh. Therefore, we have the
announced uniqueness.
‚ñ°
We also have an existence result.
Proposition 6.4 For any set of values assigned to the nodes of the mesh, there exists
one and only one element vh of Wh that takes these values at the nodes.
Proof The previous proof shows that four values for the four vertices of an element
determine one and only one Q1 polynomial that interpolates the values at the vertices
inside the element. Therefore, if we are given a set of values for each node in the

176
6
The Finite Element Method in Dimension Two
Fig. 6.9 Continuity across
an internal edge [S1, S2]
S2
S1
Rk
Rk‚Ä≤
q‚Ä≤
q
mesh, this set determines one and only one Q1 polynomial per element. The only
thing to be checked is that these polynomials combine into a globally C0 function.
Indeed, discontinuities could arise at internal edges, those that are common to two
elements. We have to show that this is not the case.
Let us thus consider the situation of Fig.6.9, where the common edge between
the two rectangles is parallel to the x2 axis, without loss of generality.
We thus have two Q1 polynomials q and q‚Ä≤ such that q(S1) = q‚Ä≤(S1) and q(S2) =
q‚Ä≤(S2). We can write
(q ‚àíq‚Ä≤)(x) = Œ±1 + Œ±2(x1 ‚àíx1
1) + Œ±3(x2 ‚àíx1
2) + Œ±4(x1 ‚àíx1
1)(x2 ‚àíx1
2),
for some constants Œ± j, j = 1, . . . , 4.
Now, any point on the segment [S1, S2] is such that x1 = x1
1. Therefore, on this
segment, we have
(q ‚àíq‚Ä≤)(x) = Œ±1 + Œ±3(x2 ‚àíx1
2).
Now, (q ‚àíq‚Ä≤)(S1) = 0 implies Œ±1 = 0 and then (q ‚àíq‚Ä≤)(S2) = 0 implies Œ±3 = 0.
Consequently, (q ‚àíq‚Ä≤)|[S1,S2] vanishes identically and thus, the function deÔ¨Åned by
q(x) if x ‚ààRk, q‚Ä≤(x) if x ‚ààRk‚Ä≤ \ Rk is continuous on Rk ‚à™Rk‚Ä≤.
‚ñ°
Remark 6.2 Notice that, in the above proof, the global continuity follows from the
fact that Q1 polynomials are afÔ¨Åne on any segment that is parallel to the coordinate
axes. If two such polynomials coincide at two points of such a segment, they then
coincide on the whole straight line going through the two points. Of course, they are
in general not afÔ¨Åne on any segment that is not parallel to the coordinate axes.
‚ñ°
Corollary 6.1 Let S j, j = 1, . . . , Ntot, be a numbering of the mesh nodes. There
exists a unique family (wi
h)i=1,...,Ntot such that wi
h ‚ààWh and wi
h(S j) = Œ¥i j. This family
is a basis of Wh, which is of dimension Ntot, and for all vh ‚ààWh, we have
vh =
Ntot

i=1
vh(Si)wi
h.
(6.2)
Proof The existence and uniqueness of wi
h follow readily from Propositions 6.3 and
6.4, since for all i, {Œ¥i j; 1 ‚â§j ‚â§Ntot} is a set of values for all the nodes.

6.2 Rectangular Q1 Finite Elements
177
These propositions also show that the linear mapping Wh ‚ÜíRNtot, vh ‚Üí(vh(Si))
is an isomorphism, hence dim Wh = Ntot. The family (wi
h)i=1,...,Ntot is the inverse
image of the canonical basis of RNtot by this isomorphism, therefore it is a basis of
Wh. Finally, every element vh of Wh is decomposed on this basis as vh = Ntot
i=1 Œªiwi
h,
so that taking x = S j, we obtain
vh(S j) =
Ntot

i=1
Œªiwi
h(S j) =
Ntot

i=1
ŒªiŒ¥i j = Œª j
which establishes Eq.(6.2).
‚ñ°
We can now characterize the elements of Vh, i.e., those functions of Wh that vanish
on ‚àÇŒ©.
Corollary 6.2 Assume, for convenience only, that the nodes S j, j = 1, . . . , Nint are
theinteriornodes.Thenthefamily(wi
h)i=1,...,Nint isabasisof Vh,and Vh isofdimension
Nint.
Proof If a function is in Vh, then vh(S j) = 0 for j > Nint. Therefore, we necessarily
have
vh =
Nint

i=1
vh(Si)wi
h.
It remains to be seen that wi
h ‚ààVh for i ‚â§Nint. This is clear, since these functions
vanish on all boundary nodes. Hence by the same token as before, they vanish on all
the edges joining boundary nodes, and the whole boundary ‚àÇŒ© is composed of such
edges.
‚ñ°
Remark 6.3 The functions wi
h are called the basis functions for Q1 Lagrange inter-
polation. The linear mappings vh ‚Üívh(S j) are again called the degrees of freedom.
It is easy to see that the support of wi
h is composed of the four elements surrounding
Si when Si is an interior node, see Fig.6.14, two elements when it is a boundary node,
but not a vertex of Œ©, and just one element when it is one of the four vertices of Œ©.
The graph of a basis function corresponding to an interior node over its support
is made of four hyperbolic paraboloid pieces that look like a tent,2 see Fig.6.10. ‚ñ°
In Figs.6.11 and 6.12, we show pictures of elements of Vh.
6.3
Convergence and Error Estimate for the Q1 FEM
The approximation space Vh is Ô¨Ånite-dimensional, therefore closed, hence C√©a‚Äôs
lemma, i.e., Theorem 5.1 of Chap.5, applies and we denote by uh the solution of
the discrete variational problem (5.1). We thus need to estimate such quantities as
2Which is why they are sometimes called tent-functions.

178
6
The Finite Element Method in Dimension Two
Fig. 6.10 Two views of a Q1
basis function for an interior
node
Fig. 6.11 The graph of a
random element of Vh. The
fact that functions in Vh are
piecewise afÔ¨Åne on segments
parallel to the coordinate
axes is apparent, see Sect.6.4
Fig. 6.12 The graph of the
Vh-interpolate of the
function (x1, x2) ‚Üí
sin(œÄx1) sin(œÄx2)
‚à•u ‚àíŒ†hu‚à•H1(Œ©), where Œ†h is some interpolation operator with values in Vh in order
to obtain an error estimate and prove convergence. We now encounter a new difÔ¨Åculty,
which is that H1 functions are not continuous in two dimensions, therefore, the nodal
values of u a priori do not make any sense and it is not possible to perform any kind
of Lagrange interpolation on H1.
We will thus need to make regularity hypotheses. We will admit the following
particular case of the Sobolev embedding theorems, which is valid in dimension two,
see for example [1].
Theorem 6.1 There is a continuous embedding H2(Œ©) ‚ÜíC0( ¬ØŒ©).
With this theorem at hand, we can Vh-interpolate H2 functions.
Let us thus be given a regular family of admissible meshes, that we index by
h = max(h1, h2), regularity meaning here that there exists a constant C such that
max(h1,h2)
min(h1,h2) ‚â§C. Let u be the solution of problem (6.1) in variational form and uh its

6.3 Convergence and Error Estimate for the Q1 FEM
179
variational approximation on Vh. We will prove the following convergence and error
estimate theorem.
Theorem 6.2 There exists a constant C such that, if u ‚ààH2(Œ©), we have
‚à•u ‚àíuh‚à•H1(Œ©) ‚â§Ch|u|H2(Œ©).
The constant C is naturally not the same constant as a couple of lines higher. Actually,
the proof of Theorem 6.2 will be broken into a series of lemmas, and constants C
will come up that generally vary from line to line. This is what is called a generic
constant‚Ä¶. The important thing is not their actual value, but that they do not depend
on any of the other quantities that appear, in this speciÔ¨Åc case, h and u.
Let R = [0, 1] √ó [0, 1] be the reference rectangle3 or reference element. Its four
verticesS j, j = 1, . . . , 4, are (0, 0), (1, 0), (1, 1) and (0, 1). We let 
Œ† denote the Q1
interpolation operator on the four vertices S j. The Q1 Lagrange interpolation basis
polynomials, or shape functions, on the reference rectangle are
ÀÜp1(ÀÜx) = (1 ‚àíÀÜx1)(1 ‚àíÀÜx2), ÀÜp2(ÀÜx) = ÀÜx1(1 ‚àíÀÜx2),
ÀÜp3(ÀÜx) = ÀÜx1ÀÜx2, ÀÜp4(ÀÜx) = (1 ‚àíÀÜx1)ÀÜx2,
(6.3)
as can be checked by hand. For all ÀÜv ‚ààC0(R), we thus have

Œ† ÀÜv =
4

j=1
ÀÜv(S j)ÀÜp j.
(6.4)
Let us begin our series of lemmas.
Lemma 6.1 The operator 
Œ† is continuous from H2(R) to H1(R).
Proof We equip Q1 with the H1(R) norm (recall that all norms are equivalent on Q1
since it is Ô¨Ånite dimensional). By Theorem 6.1, we have for all ÀÜv ‚ààH2(R)
‚à•ÀÜv‚à•C0(R) ‚â§C‚à•ÀÜv‚à•H2(R),
for some constant C. By formula (6.4), we have
‚à•
Œ† ÀÜv‚à•H1(R) ‚â§
4

j=1
|ÀÜv(S j)|‚à•ÀÜp j‚à•H1(R)
‚â§
 4

j=1
‚à•ÀÜp j‚à•H1(R)

‚à•ÀÜv‚à•C0(R)
3Ok, it‚Äôs a square, and unluckily it happens to look a lot like Œ©, although there is no conceptual
connection between the two.

180
6
The Finite Element Method in Dimension Two
‚â§C
 4

j=1
‚à•ÀÜp j‚à•H1(R)

‚à•ÀÜv‚à•H2(R),
which completes the proof.
‚ñ°
Lemma 6.2 There exists a constant C such that, for all ÀÜv ‚ààH2(R)
‚à•ÀÜv ‚àí
Œ† ÀÜv‚à•H1(R) ‚â§C‚à•‚àá2ÀÜv‚à•L2(R).
Proof We note that P1 ‚äÇQ1, thus for all p ‚ààP1, we have 
Œ†p = p. Therefore
‚à•ÀÜv ‚àí
Œ† ÀÜv‚à•H1(R) = ‚à•ÀÜv ‚àíp ‚àí
Œ†(ÀÜv ‚àíp)‚à•H1(R) ‚â§‚à•I ‚àí
Œ†‚à•L (H2;H1)‚à•ÀÜv ‚àíp‚à•H2(R)
for all ÀÜv ‚ààH2(R), p ‚ààP1, by Lemma 6.1. Consequently
‚à•ÀÜv ‚àí
Œ† ÀÜv‚à•H1(R) ‚â§C inf
p‚ààP1 ‚à•ÀÜv ‚àíp‚à•H2(R) = C‚à•ÀÜv ‚àíPÀÜv‚à•H2(R),
where P denotes the H2 orthogonal projection onto P1.
Let us now show that there is a constant C such that
‚à•ÀÜv ‚àíPÀÜv‚à•H2(R) ‚â§C‚à•‚àá2ÀÜv‚à•L2(R),
which will complete the proof of the Lemma. We argue by contradiction and assume
there is no such constant C. In this case, as in the proof of the Poincar√©‚ÄìWirtinger
inequality, i.e., Theorem 4.2 of Chap.4, there exists a sequence ÀÜvn ‚ààH2(R) such that
‚à•ÀÜvn ‚àíPÀÜvn‚à•H2(R) = 1 and ‚à•‚àá2ÀÜvn‚à•L2(R) ‚Üí0,
when n ‚Üí+‚àû. Let us set ÀÜwn = ÀÜvn ‚àíPÀÜvn, which belongs to P‚ä•
1 . The second deriva-
tives of a P1 polynomial vanish, so that ‚àá2 ÀÜwn = ‚àá2ÀÜvn. By Rellich‚Äôs compact embed-
ding theorem, see Remark 3.18 of Chap.3, there exists a sequence, still denoted ÀÜwn
and a ÀÜw ‚ààH1(R) such that ÀÜwn ‚ÜíÀÜw in H1(R). Then, the condition ‚à•‚àá2 ÀÜwn‚à•L2(R) ‚Üí0
shows that ÀÜwn is a Cauchy sequence in H2(R), which is complete. Hence, ÀÜw ‚ààH2(R)
and ÀÜwn ‚ÜíÀÜw in H2(R) as well. Now, the space P‚ä•
1 is a H2 orthogonal, hence is
closed in H2(R), from which it follows that ÀÜw ‚ààP‚ä•
1 . On the other hand, we have
‚àá2 ÀÜw = 0, so that ÀÜw ‚ààP1. Consequently, ÀÜw = 0 and ÀÜwn ‚Üí0 in H2(R), which con-
tradicts ‚à•ÀÜwn‚à•H2(R) = 1. The proof is complete.
‚ñ°
Remark 6.4 The above proof does not really use Q1-interpolation, but only P1-
interpolation. It would thus equally apply for triangular elements, which we will
discuss later. The proof is non constructive in the sense that we do not have any idea
of the actual value of the constant.
‚ñ°
We now perform a change of variable between the reference element R and a
generic element Rk of the mesh.

6.3 Convergence and Error Estimate for the Q1 FEM
181
Fig. 6.13 The afÔ¨Åne change
of variable from the
reference element to the
generic element
R
Rk
S1
(0,0)
Lemma 6.3 Let Rk be an element of the mesh. There exists a unique afÔ¨Åne bijective
mapping Fk such that Fk(R) = Rk and that maps the vertices counted counterclock-
wise from the lower left corner to their counterparts in Rk.
Proof Consider Fig.6.13.
InviewoftheÔ¨Ågure,itisclearlyenoughtomaptheorigintopointS1 ofcoordinates
(x1(Rk), x2(Rk)) and then to multiply abscissae by h1 and ordinates by h2. This yields
Fk(ÀÜx) =
x1(Rk) + h1ÀÜx1
x2(Rk) + h2ÀÜx2

.
The inverse mapping is given by
F‚àí1
k (y) =
 y1‚àíx1(Rk)
h1
y2‚àíx2(Rk)
h2

.
It is also afÔ¨Åne, naturally.
‚ñ°
Lemma 6.4 There exists a constant C such that for all elements Rk and all v ‚àà
H1(Rk), setting ÀÜv(ÀÜx) = v(Fk(ÀÜx)), we have

Rk
‚à•‚àáv‚à•2 dx ‚â§C

R
‚à•‚àáÀÜv‚à•2 dÀÜx.
Proof This is brute force computation. We have v(x) = ÀÜv(F‚àí1
k (x)) thus
‚àÇv
‚àÇxi
(x) =
2

j=1
‚àÇÀÜv
‚àÇÀÜx j
(F‚àí1
k (x))‚àÇ(F‚àí1
k ) j
‚àÇxi
(x)
= h‚àí1
i
‚àÇÀÜv
‚àÇÀÜxi
(F‚àí1
k (x)),

182
6
The Finite Element Method in Dimension Two
by the multidimensional chain rule. We also need the Jacobian of the change of
variables x = Fk(ÀÜx)
dx = | det DFk(ÀÜx)| dÀÜx = h1h2 dÀÜx
to perform the change of variable in the integral. We obtain

Rk
‚à•‚àáv‚à•2 dx =

R

h‚àí2
1
 ‚àÇÀÜv
‚àÇÀÜx1
2
+ h‚àí2
2
 ‚àÇÀÜv
‚àÇÀÜx2
2
h1h2 dÀÜx
‚â§(min(h1, h2))‚àí2h1h2

R
‚à•‚àáÀÜv‚à•2 dÀÜx.
Now this is where the regularity of the mesh family intervenes. According to
DeÔ¨Ånition 6.2, letting h = max(h1, h2) and œÅ = min(h1, h2), we have h
œÅ ‚â§C. There-
fore (min(h1, h2))‚àí2h1h2 ‚â§C2
h2 h2 = C2, and the proof is complete.
‚ñ°
We now are in a position to prove Theorem 6.2.
Proof of Theorem 6.2. We use the H1 semi-norm. Let Œ†h be the Vh-interpolation
operator and let vk = (u ‚àíŒ†hu)|Rk and uk = u|Rk. It is important to note that


Œ†hu|Rk

= 
Œ† 
u|Rk = 
Œ† 
uk,
using the same hat notation as in Lemma 6.4 for the change of variables in functions.
This is because an afÔ¨Åne change of variables of the form of Fk maps Q1 polynomials
to Q1 polynomials due to their special structure. Moreover, the two sides of the above
equality satisfy the same interpolation conditions at the four vertices of the reference
element, hence are equal everywhere. Therefore, we have
vk = 
uk ‚àí
Œ† 
uk.
We decompose the semi-norm squared as a sum over all elements
|u ‚àíŒ†hu|2
H1(Œ©) =
NT

k=1

Rk
‚à•‚àávk‚à•2 dx ‚â§C
NT

k=1

R
‚à•‚àávk‚à•2 dÀÜx,
by Lemma 6.4.
By Lemma 6.2, we have

R
‚à•‚àávk‚à•2 dÀÜx ‚â§C

R
‚à•‚àá2
uk‚à•2 dÀÜx
‚â§C
2

i, j=1

R
 ‚àÇ2
uk
‚àÇÀÜxi‚àÇÀÜx j
2
dÀÜx

6.3 Convergence and Error Estimate for the Q1 FEM
183
= C
2

i, j=1

Rk

hih j
‚àÇ2uk
‚àÇxi‚àÇx j
2
1
h1h2
dx
‚â§Ch2

Rk
‚à•‚àá2uk‚à•2 dx
by performing the reverse change of variables, and using the regularity of the mesh
family again. It follows that
|u ‚àíŒ†hu|2
H1(Œ©) ‚â§Ch2
NT

k=1

Rk
‚à•‚àá2uk‚à•2 dx = Ch2‚à•‚àá2u‚à•2
L2(Œ©),
and the proof is complete since the H1 semi-norm is equivalent to the H1 norm on
H1
0(Œ©), see Corollary 3.3 of Chap.3.
‚ñ°
Remark 6.5 Under the hypothesis u ‚ààH2(Œ©), which is satisÔ¨Åed in this particular
case, due to elliptic regularity in a convex polygon, we thus have convergence of the
Q1 FEM when h ‚Üí0, and we have an error estimate with a constant C that depends
neither on h nor on u. The drawback however is that the proof does not tell us how
large this constant is, see Remark 6.4.
‚ñ°
6.4
Assembling the Matrix
Let us assume that a numbering of the interior nodes, and thus of the basis functions
of Vh, has been chosen: S j and w j
h, j = 1, . . . , Nint. We have, by Q1 interpolation
uh =
Nint

j=1
uh(S j)w j
h
and the matrix A has coefÔ¨Åcients
Ai j = a(w j
h, wi
h) =

Œ©
(‚àáw j
h ¬∑ ‚àáwi
h + cw j
hwi
h) dx.
If we set
Ai j(Rk) =

Rk
(‚àáw j
h ¬∑ ‚àáwi
h + cw j
hwi
h) dx,
we see that
Ai j =
NT

k=1
Ai j(Rk),

184
6
The Finite Element Method in Dimension Two
and the coefÔ¨Åcients can thus be computed element-wise. The idea is that many of the
numbers Ai j(Rk) do not need to be computed, since it is known that they vanish as
soon as the intersection of the supports of w j
h and wi
h does not meet Rk. This vastly
reduces the computer load.
Likewise, the right-hand side of the linear system can be written as
Bi =

Œ©
f wi
h dx =
NT

k=1

Rk
f wi
h dx =
NT

k=1
Bi(Rk),
with only four nonzero terms in the last sum.
Now the restriction of w j
h to Rk is either zero, or one of the four Q1 interpolation
basis polynomials on Rk, which we denote pk
i , i = 1, . . . , 4. Here again, the reference
element R can be used with proÔ¨Åt to compute the coefÔ¨Åcients of the matrix. The
Q1 Lagrange interpolation basis polynomials, or shape functions, on the reference
rectangle are given by formula (6.3).
We have already noticed that pk
i (x) = ÀÜpi(F‚àí1
k (x)) because both sides are Q1 and
satisfy the same interpolation conditions at the vertices. Let us give an example of
computation with ÀÜp3. We thus have
pk
3(x) = ÀÜp3(F‚àí1
k (x)) =
x1 ‚àíx1(Rk)
h1
x2 ‚àíx2(Rk)
h2

.
Therefore
‚à•‚àápk
3(x)‚à•2 =
1
h2
1h2
2

(x1 ‚àíx1(Rk))2 + (x2 ‚àíx2(Rk))2
,
and assuming Si is the upper right corner of Rk, we obtain by computing the integrals
on Rk
Aii(Rk) = h1h2
3
 1
h2
1
+ 1
h2
2

+ c0
h1h2
9
in the case when c = c0 is a constant. Now there are four such contributions to Aii
coming from the four rectangles that surround Si (see Fig.6.14), which are all equal,
hence
Aii = 4h1h2
3
 1
h2
1
+ 1
h2
2

+ c0
4h1h2
9
.
In the case when h1 = h2 = h, we thus obtain Aii = 8
3 + 4
9c0h2.
The diagonal coefÔ¨Åcients do not depend on the node numbering, but the off-
diagonal ones do depend completely on it. So we have to talk about numbering,
since in the 2d case, as opposed to the 1d case, no natural numbering appears at the
onset.
We Ô¨Årst note that there is a connection between Q1 Lagrange approximation in
two dimensions and P1 Lagrange approximation in one dimension.

6.4 Assembling the Matrix
185
The four basis polynomials on R are given by Eq.(6.3). In one dimension, the
basis polynomials for P1 Lagrange interpolation on [0, 1] are
‚Ñì1(x) = 1 ‚àíx,
‚Ñì2(x) = x.
Therefore, we see that
ÀÜp1(x) = ‚Ñì1(ÀÜx1)‚Ñì1(ÀÜx2), ÀÜp2(x) = ‚Ñì2(ÀÜx1)‚Ñì1(ÀÜx2),
ÀÜp3(x) = ‚Ñì2(ÀÜx1)‚Ñì2(ÀÜx2), ÀÜp4(x) = ‚Ñì1(ÀÜx1)‚Ñì2(ÀÜx2).
In this context, we introduce a useful notation. Let f and g be two functions in one
variable. We deÔ¨Åne a function in two variables f ‚äóg by f ‚äóg(x1, x2) = f (x1)g(x2).
This function is called the tensor product of f and g.4 With this notation, we thus
have p1 = ‚Ñì1 ‚äó‚Ñì1 and so on.
ThistensorproductdecompositionextendstothebasisfunctionsonŒ© themselves.
Let Si be an interior node of coordinates (i1h1, i2h2) and Ri
k, k = 1, . . . , 4, the four
elements surrounding it.
By direct veriÔ¨Åcation of the interpolation relations, we easily check that
wi
h(x) =
‚éß
‚é™‚é™‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é™‚é™‚é©
‚Ñì2
 x1
h1 ‚àí(i1 ‚àí1)

‚Ñì2
 x2
h2 ‚àí(i2 ‚àí1)

in Ri
1,
‚Ñì1
 x1
h1 ‚àíi1

‚Ñì2
 x2
h2 ‚àí(i2 ‚àí1)

in Ri
2,
‚Ñì1
 x1
h1 ‚àíi1

‚Ñì1
 x2
h2 ‚àíi2

in Ri
3,
‚Ñì2
 x1
h1 ‚àí(i1 ‚àí1)

‚Ñì1
 x2
h2 ‚àíi2

in Ri
4,
0
elsewhere.
We remark that the support of wi
h is the union of the four rectangles surrounding Si,
see Fig.6.14. Therefore, if wi1
h1 denotes the 1d hat function associated with node i1h1
of the 1d mesh of [0, 1] of mesh size h1, and likewise for wi2
h2, we see that
Fig. 6.14 The support of wi
h
Ri
1
Ri
2
Ri
3
Ri
4
Si
i1h1
(i1 ‚àí1)h1
(i1 +1)h1
(i2 +1)h2
(i2 ‚àí1)h2
i2h2
4Consider this to be just vocabulary. We do not need to know anything about tensor products in
general.

186
6
The Finite Element Method in Dimension Two
wi
h = wi1
h1 ‚äówi2
h2.
In other words, the basis functions of the Q1 FEM in 2d are nothing but the tensor
products of the one-dimensional P1 basis functions cf. also Fig.6.14.
Let us use this tensor product decomposition to number the basis functions. The
idea is to use the indices i1 and i2 to sweep the rows and then the columns of the
mesh.5 We thus deÔ¨Åne a mapping {1, 2, . . . , N1} √ó {1, 2, . . . , N2} ‚Üí{1, 2, . . . , Nint}
by
(i1, i2) ‚Üíi = i1 + (i2 ‚àí1)N1.
It is clearly a bijection (recall that Nint = N1N2). To compute the inverse mapping,
we note that i1 ‚àí1 is the remainder of the Euclidean division of i ‚àí1 by N1, thus
i1 = i ‚àí
i ‚àí1
N1
 
N1,
i2 =
i ‚àí1
N1
 
+ 1.
(6.5)
Now, the support of a tensor product is the Cartesian product of the supports. Thus
supp wi
h = supp wi1
h1 √ó supp wi2
h2 = [(i1 ‚àí1)h1, (i1 + 1)h1] √ó [(i2 ‚àí1)h2, (i2 + 1)h2].
If an index j in the numbering corresponds to a couple ( j1, j2), we thus see that
Ai j Ã∏= 0 if and only if the supports have non negligible intersection, that is to say
Ai j Ã∏= 0 ‚áê‚áí| j1 ‚àíi1| ‚â§1 and | j2 ‚àíi2| ‚â§1.
In view of the numbering formulas above, saying that | j1 ‚àíi1| ‚â§1 is equivalent
to saying that j ‚àíi = Œ± + kN1 with Œ± = i1 ‚àíj1 = ‚àí1, 0 or 1, and k an integer.
Since we also have i2 = i‚àíi1
N1 , it follows that i2 ‚àíj2 = k = ‚àí1, 0 or 1. Therefore,
for a given i, that is a given row of A, there are at most nine values of j, that is
nine columns, that contain a nonzero coefÔ¨Åcient. Of course, not all rows contain
nine nonzero coefÔ¨Åcients. For example, the Ô¨Årst row has four nonzero coefÔ¨Åcients,
the second row has six nonzero coefÔ¨Åcients, and so on. Rows that correspond to
index pairs (i1, i2) such that 2 ‚â§i1, i2 ‚â§N1 ‚àí1 do have nine nonzero coefÔ¨Åcients
(they correspond to interior nodes with nine neighboring interior nodes, including
themselves). Such a row looks like Fig.6.15.
We see three tridiagonal N1 √ó N1 blocks emerging, that are themselves arranged
block tridiagonally. The whole (N1N2) √ó (N1N2) matrix is thus composed of N2
2
blocks Akl, 1 ‚â§k, l, ‚â§N2, of size N1 √ó N1, that are either zero or tridiagonal. Indeed,
if we deÔ¨Åne the N1 √ó N1 matrix Akl to be the block comprised of lines (k ‚àí1)N1 + 1
to kN1 and columns (l ‚àí1)N1 + 1 to lN1, then using the inverse numbering (6.5),
we see that
Ai j = a(w j
h, wi
h) = a(w j1
h1 ‚äówl
h2, wi1
h1 ‚äówk
h2),
5Or the other way around. But let‚Äôs stick to this one here.

6.4 Assembling the Matrix
187
Fig. 6.15 A typical row in
the matrix
j =
i
i+1
i‚àí1
i+N1
i+N1+1
i+N1‚àí1
i‚àíN1
i‚àíN1+1
i‚àíN1‚àí1
for all (i, j) in this block. Therefore we have (Akl)i1 j1 = a(w j1
h1 ‚äówl
h2, wi1
h1 ‚äówk
h2),
thus Akl = 0 as soon as |k ‚àíl| ‚â•2 and is tridiagonal for |k ‚àíl| ‚â§1, for reasons of
supports. We thus have
A =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éù
A11 A12 0
¬∑ ¬∑ ¬∑
0
A21 A22 A23
¬∑ ¬∑ ¬∑
0
0 A32 A33
...
0
...
...
...
...
...
0
¬∑ ¬∑ ¬∑
0 AN2‚àí1,N2 AN2N2
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚é†
,
where the block tridiagonal structure appears, see also Fig.6.16.
The sweep columns then rows numbering scheme thus gives rise to a well-
structured matrix for which there exist efÔ¨Åcient numerical methods. It is instructive to
see what kind of matrix would result from other numberings that could be considered
just as natural, such as the numbering used to prove that N2 is countable (although
limited to a square here): start from the lower left node, go east one node, then north
west, then north, then south east, etc., see Fig.6.17.
Fig. 6.16 The block
tridiagonal structure of A
(here N1 = N2 = 10 so A is
100 √ó 100). Black squares
indicate nonzero matrix
coefÔ¨Åcients, white areas
zero. The coarse grid shows
the 10 √ó 10 blocks

188
6
The Finite Element Method in Dimension Two
Fig. 6.17 An alternate node
numbering scheme
1
2
3
4
5
6
¬∑¬∑¬∑
20
...
For the same 100 √ó 100 case, we obtain a matrix structure that looks like Fig.6.18.
Of course, the entries of the above matrix are the same as the previous ones after a
permutation, since both matrices are similar to each other via a permutation matrix.
In the case when Œ© is not a rectangle, the structure of the matrix is not as regular.
For instance, the matrix associated with the mesh depicted in Fig.6.1, with the sweep
columns then rows numbering, looks like
A =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù
‚ñ†‚ñ†‚ñ°‚ñ°‚ñ†‚ñ†‚ñ°‚ñ°‚ñ°‚ñ°‚ñ°
‚ñ†‚ñ†‚ñ†‚ñ°‚ñ†‚ñ†‚ñ†‚ñ°‚ñ°‚ñ°‚ñ°
‚ñ°‚ñ†‚ñ†‚ñ†‚ñ°‚ñ†‚ñ†‚ñ°‚ñ°‚ñ°‚ñ°
‚ñ°‚ñ°‚ñ†‚ñ†‚ñ°‚ñ°‚ñ†‚ñ°‚ñ°‚ñ°‚ñ°
‚ñ†‚ñ†‚ñ°‚ñ°‚ñ†‚ñ†‚ñ°‚ñ†‚ñ†‚ñ°‚ñ°
‚ñ†‚ñ†‚ñ†‚ñ°‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ°‚ñ°
‚ñ°‚ñ†‚ñ†‚ñ†‚ñ°‚ñ†‚ñ†‚ñ°‚ñ†‚ñ°‚ñ°
‚ñ°‚ñ°‚ñ°‚ñ°‚ñ†‚ñ†‚ñ°‚ñ†‚ñ†‚ñ†‚ñ†
‚ñ°‚ñ°‚ñ°‚ñ°‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†‚ñ†
‚ñ°‚ñ°‚ñ°‚ñ°‚ñ°‚ñ°‚ñ°‚ñ†‚ñ†‚ñ†‚ñ†
‚ñ°‚ñ°‚ñ°‚ñ°‚ñ°‚ñ°‚ñ°‚ñ†‚ñ†‚ñ†‚ñ†
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†
,
where black squares denote nonzero entries and white squares zero entries.
Let us notice that the structure of the matrix depends solely on the numbering of
nodes, and not on the numbering of elements.

6.5 General DeÔ¨Ånition of a Finite Element
189
Fig. 6.18 Structure of the
alternate matrix
6.5
General DeÔ¨Ånition of a Finite Element
It is now time to look back and see what are the general characteristics of the Ô¨Ånite
elements we have seen so far, so as to Ô¨Ånally deÔ¨Åne what a Ô¨Ånite element is! We let
P = R[x1, x2] denote the space of polynomials in two indeterminates.
DeÔ¨Ånition 6.4 A two-dimensional Ô¨Ånite element is a triple (T, P(T), {œï1, . . . , œïd})
where
(1) T is a compact polygon.
(2) P(T) is a Ô¨Ånite dimensional subspace of P, considered as a function space on T.
(3) œïi, i = 1, . . . , d, are linear forms on P, which are called the degrees of freedom
of the Ô¨Ånite element.
Remark 6.6 In practice, T is either a triangle or a rectangle. The same deÔ¨Ånition
applies in dimensions one and three (Ô¨Ånite elements are rarely used in dimensions
higher than four, although it happens). In dimension one, T is an interval. There is
more variety in dimension three, starting with tetrahedra.
The degrees of freedom are attached to T one way or another.
In the literature, in particular the engineering literature, Ô¨Ånite elements are always
presented this way, and not starting with the discrete space Vh and so on, as we have

190
6
The Finite Element Method in Dimension Two
done up to now. We thus start from the top, i.e. from the discrete space, down to the
Ô¨Ånite element, instead of starting from the bottom.
‚ñ°
DeÔ¨Ånition 6.5 We say that a Ô¨Ånite element is unisolvent if for all d-uples of scalars
(Œ±1, . . . , Œ±d), there exists one and only one polynomial p ‚ààP(T) such that œïi(p) =
Œ±i, i = 1, . . . , d.
Unisolvence is a generalization of the interpolation property for all kinds of
degrees of freedom.
Proposition 6.5 If a Ô¨Ånite element is unisolvent, then, d = dim P(T).
Proof This is fairly obvious. Assume we want to solve the d equations œïi(p) = Œ±i.
Since œïi are linear forms, these equations are linear equations in dim P(T) unknowns,
once we choose a basis of P(T). Hence if the number of equations and the number of
unknowns are different, the system of equations certainly cannot be solved uniquely
for all right-hand sides.
‚ñ°
Remark 6.7 If we do not have the same number of degrees of freedom as the dimen-
sion of the Ô¨Ånite element space, then the element in question is not unisolvent.
Be careful that unisolvence is not just a question of dimensions, as the following
example shows.
Take T = {|x1| + |x2| ‚â§1}, P(T) = Q1 and œïi the values at the four vertices of
T. We have dim Q1 = 4 but this element is not unisolvent, since p(x) = x1x2 is in Q1
and œïi(p) = 0 for all i even though p Ã∏= 0.
If on the other hand, T = [0, 1]2, P(T) = Q1 and œïi the values at the four vertices
of T, then the Ô¨Ånite element is unisolvent. This is the element we have been using so
far in 2d.
Therefore, unisolvence somehow reÔ¨Çects the adequacy of the duality between the
polynomial space and the degrees of freedom.
‚ñ°
In practice, unisolvence is checked using the following result.
Proposition 6.6 A Ô¨Ånite element is unisolvent if and only if d = dim P(T) and there
exists a basis (p j) j=1,...,d of P(T) such that œïi(p j) = Œ¥i j for all i, j.
Proof If the element is unisolvent, we already know that d = dim P(T). Moreover,
choosing Œ±i = Œ¥i j for j = 1, . . . , d yields the existence of p j by the very deÔ¨Ånition.
The family (p j) is linearly independent, for if
d

j=1
Œª jp j = 0,

6.5 General DeÔ¨Ånition of a Finite Element
191
applying the linear form œïi, we obtain
0 =
d

j=1
Œª jœïi(p j) =
d

j=1
Œª jŒ¥i j = Œªi
for all i. Thus it is a basis of P(T).
Conversely, assume that d = dim P(T) and that we have a basis p j with the above
property. Let us be given scalars Œ±i. Then the polynomial p = d
j=1 Œ± jp j is the only
element of P(T) such that œïi(p) = Œ±i by the same argument.
‚ñ°
Remark 6.8 The polynomials p j are called the basis polynomials or shape functions
of the Ô¨Ånite element. They are dual to the degrees of freedom. They are also used to
construct the basis functions of the discrete approximation spaces, as we have seen
already in 1d with the P1 Lagrange and P3 Hermite approximations, and in 2d with
the Q1 Lagrange approximation. In the latter case, the shape functions were already
given in Eq.(6.3) for T = [0, 1]2.
This also indicates that unisolvence is far from being the end of the story in
terms of Ô¨Ånite elements. The basis polynomials must also be such that they can
be combined into globally continuous functions so as to give rise to a conforming
approximation.
‚ñ°
Speaking of duality, we can also introduce Œ£(T) = vect {œï1, . . . , œïd}, the vector
subspaceofP‚àóspannedbythedegreesoffreedom.InasimilarveinasProposition6.5,
we also have
Proposition 6.7 If a Ô¨Ånite element is unisolvent, then, d = dim Œ£(T).
Proof Clear.
‚ñ°
The basis polynomials and the degrees of freedom are obviously dual bases of
their respective spanned spaces. In the counterexample shown above, the four linear
forms are linearly independent as elements of P‚àó, but not as elements of Q‚àó
1.
6.6
Q2 and Q3 Finite Elements
Let us brieÔ¨Çy discuss what happens if we want to use higher degree polynomials. We
start with Q2 Lagrange elements for second order problems. The discrete approxi-
mation space is then
Vh = {vh ‚ààC0( ¬ØŒ©); ‚àÄRk ‚ààT , vh|Rk ‚ààQ2, vh = 0 on ‚àÇŒ©},

192
6
The Finite Element Method in Dimension Two
Fig. 6.19 The nine nodes of
the Q2 Lagrange element
S0
S1
S1,2
S2
S4
S3,4
S3
S4,1
S2,3
on the same rectangular mesh as before and the general approximation theory applies
(note that this space is larger than the previous one). We concentrate on the description
of the Ô¨Ånite element Ô¨Årst. We set R = [0, 1]2, P(R) = Q2 and we need to describe the
degrees of freedom. Since we are going to use Lagrange interpolation, these degrees
of freedom are going to be values at some points of the element. The dimension of
Q2 is nine, therefore nine degrees of freedom are required to deÔ¨Åne a unisolvent Ô¨Ånite
element, i.e., nine points or nodes in R. The choice of points must also be guided by
the necessity of deÔ¨Åning a global C0 interpolation based on the nodal values on the
mesh. The set of points depicted in Fig.6.19 turns out to satisfy both requirements.
We thus take the four vertices Sk as before, plus the four middles of the edges
Sk,k+, where k+ = k + 1 for k = 1, 2, 3 and k+ = 1 for k = 4, plus the center of
gravity S0. A slight misuse of notation: we let p(S) denote the linear form p ‚Üíp(S).
Proposition 6.8 TheÔ¨Åniteelement(R, Q2, {p(Sk), p(Sk,k+), p(S0), k = 1, . . . , 4})is
unisolvent.
Proof The number of degrees of freedom matches the dimension of the space. It is
thus sufÔ¨Åcient to construct the basis polynomials. We will number them the same
way as the node they correspond to. There are three polynomials to be constructed:
p1 from which the other pk are deduced by symmetry, p1,2 from which the other pk,k+
are deduced by symmetry, and p0.
Let us show how to compute p0. The interpolation conditions to be satisÔ¨Åed are
p0(S0) = 1 and p0 = 0 on all other eight nodes. Now p0 is zero at points (0, 0), (0, 1
2)
and (0, 1). The restriction of a Q2 polynomial to the line x2 = 0 is a second degree
polynomial in the variable x1, and we have just seen that this polynomial has three
roots. Therefore it vanishes and p0 = 0 on the straight line x2 = 0. It follows that

6.6 Q2 and Q3 Finite Elements
193
p0 is divisible by x2. The same argument shows that it is divisible by x1, (1 ‚àíx1)
and (1 ‚àíx2). These polynomials are relatively prime, thus p0 is divisible by their
product,
p0(x) = q(x)x1x2(1 ‚àíx1)(1 ‚àíx2),
for some polynomial q. Now x1x2(1 ‚àíx1)(1 ‚àíx2) ‚ààQ2, thus the partial degree of
q is less than 0, i.e., q is a constant C. Evaluating now p0 at point S0 = ( 1
2, 1
2), we
obtain
1 = C √ó 1
2 √ó 1
2 √ó 1
2 √ó 1
2 = C
16.
Finally, we Ô¨Ånd that
p0(x) = 16x1x2(1 ‚àíx1)(1 ‚àíx2).
Conversely, it is clear that this particular polynomial is in Q2 and satisÔ¨Åes the
required interpolation conditions.
The same arguments, that we leave as an exercise, show that
p1(x) = (1 ‚àíx1)(1 ‚àí2x1)(1 ‚àíx2)(1 ‚àí2x2),
p2(x) = ‚àíx1(1 ‚àí2x1)(1 ‚àíx2)(1 ‚àí2x2),
p3(x) = x1(1 ‚àí2x1)x2(1 ‚àí2x2),
p4(x) = ‚àí(1 ‚àíx1)(1 ‚àí2x1)x2(1 ‚àí2x2),
and
p1,2(x) = 4x1(1 ‚àíx1)(1 ‚àíx2)(1 ‚àí2x2),
p2,3(x) = ‚àí4x1(1 ‚àí2x1)x2(1 ‚àíx2),
p3,4(x) = ‚àí4x1(1 ‚àíx1)x2(1 ‚àí2x2),
p4,1(x) = 4(1 ‚àí2x1)(1 ‚àíx1)x2(1 ‚àíx2).
The latter three of each group are obtained by considerations of symmetry from the
Ô¨Årst one of the group.
‚ñ°
We draw the graphs of the different basis polynomials in Figs.6.20, 6.21 and 6.22.
Let us now consider the whole mesh. The nodes no longer are just the element
vertices, but also the middles of the edges and the centers of gravity of the elements,
see Fig.6.23.
We then have the exact analog of Propositions 6.3 and 6.4.
Proposition 6.9 A function of Vh is uniquely determined by its values at the interior
nodes of the mesh and all sets of values are interpolated by one and only one element
of Vh.
Proof By unisolvence, nine values for the nine nodes of an element determine one
and only one Q2 polynomial that interpolates these nodal values (we take the value

194
6
The Finite Element Method in Dimension Two
Fig. 6.20 The graph of p0
Fig. 6.21 The graph of p1,
with the segments where p1
vanishes
0 for the nodes located on the boundary). Therefore, if we are given a set of values
for each node in the mesh, this set determines one Q2 polynomial per element. Let
us check that these polynomials combine into a globally C0 function.
Let us thus consider the situation depicted in Fig.6.24, without loss of generality.
We thus have two Q2 polynomials q and q‚Ä≤ such that q(S1) = q‚Ä≤(S1), q(S1,2) =
q‚Ä≤(S1,2) and q(S2) = q‚Ä≤(S2). On the segment [S1, S2], which is parallel to the x2
axis, q ‚àíq‚Ä≤ is a second degree polynomial in the variable x2 that has three roots.

6.6 Q2 and Q3 Finite Elements
195
Fig. 6.22 The graph of p1,2,
with the segments where p1,2
vanishes
Fig. 6.23 Same mesh as
Fig.6.7, 32 elements, 153
nodes
Therefore, q ‚àíq‚Ä≤ = 0 on this segment, and the function deÔ¨Åned by q(x) if x ‚ààRk,
q‚Ä≤(x) if x ‚ààRk‚Ä≤ \ Rk is continuous on Rk ‚à™Rk‚Ä≤.
‚ñ°
Corollary 6.3 Let us be given a numbering of the nodes Si, i = 1, . . . , N = (2N1 +
1)(2N2 + 1). There is a basis of Vh composed of the functions wi
h deÔ¨Åned by wi
h(S j) =
Œ¥i j and for all vh ‚ààVh, we have

196
6
The Finite Element Method in Dimension Two
Fig. 6.24 Continuity across
an internal edge, Q2 case
S2
S1,2
S1
Rk
Rk‚Ä≤
q‚Ä≤
q
vh =
N

i=1
vh(Si)wi
h.
Proof Same as before.
‚ñ°
Figures6.25, 6.26 and 6.27 show pictures of the different types of basis functions,
depending on which kind of node, i.e., center of gravity of an element, element vertex
or edge middle, they are attached to.
Note that the last two basis functions change sign in Œ©. This was not the case for
Q1 basis functions.
We do not pursue here matrix assembly and node numbering issues. It is to be
expected that the structure of the matrix is more complicated than in the Q1 case.
The question arises as to why introduce Q2 elements and deal with the added
complexity compared with the Q1 case. One reason is that we thus obtain a higher
order approximation method. Indeed, if u ‚ààH3(Œ©), then we have (exercise) a better
error estimate
‚à•u ‚àíuh‚à•H1(Œ©) ‚â§Ch2|u|H3(Œ©),
than with Q1 elements. The estimate is better in the sense that h2 ‚â™h when h is small,
even though we do not have any idea of the order of magnitude of the constants and
Fig. 6.25 Basis function
corresponding to an element
center of gravity

6.6 Q2 and Q3 Finite Elements
197
Fig. 6.26 Basis function
corresponding to an element
vertex
Fig. 6.27 Basis function
corresponding to an edge
middle
the norms in the right-hand side. So the extra implementation and computational
costs induced by the extra degree must be balanced against the increased accuracy
that is expected from the higher degree Ô¨Ånite element approximation. For instance,
a cheaper computation may be achieved with Q2 elements with the same accuracy
by taking less elements than with a Q1 computation.
Let us say a few words about Q3 Ô¨Ånite elements. We could deÔ¨Åne Q3-Lagrange
elements by taking 16 nodes per element, since dim Q3 = 16. We would need four
nodes per edge to ensure global continuity, hence the four vertices plus two points
on the thirds of each edge. Four more points must be chosen inside, with obvious
simple possibilities.
We can also use Q3 Ô¨Ånite elements for Hermite interpolation that result in C1
functions suitable for conforming approximation of fourth order problems, such as
the plate equation (1.10) for example. In this case, the degrees of freedom must also
include partial derivative values. We would thus take as degrees of freedom the 4
vertex values and the 8 Ô¨Årst partial derivatives values at the vertices. This would seem
to be enough, as we recognize 1d P3 Hermite interpolation on each edge, and there
is a tensor product structure Q3[X, Y] = P3[X] ‚äóP3[Y].
Surprisingly, this is not enough. Indeed, this choice would only provide 12 degrees
of freedom for a 16-dimensional space, and there would be inÔ¨Ånitely many different
possible basis polynomials, in the sense that the interpolation relations would be
satisÔ¨Åed, since there is inÔ¨Ånitely many different ways of adding four more degrees of
freedom. Moreover, it is not clear which choice would guarantee global C1 regularity.
Surprisingly again, if we complete the set of degrees of freedom with the four vertex

198
6
The Finite Element Method in Dimension Two
values of the second derivatives
‚àÇ2p
‚àÇx1‚àÇx2 , we obtain a unisolvent element that generates
a C1 approximation. The Q3-Hermite element is well adapted to the approximation
of such fourth order problems.
We have seen an interesting example of the same polynomial space used with
two completely different sets of degrees of freedom and yielding two completely
different approximation spaces, Q3-Lagrange and Q3-Hermite, which are used in
also different contexts.
Let us now switch to triangular Ô¨Ånite elements, which are better adapted for
problems that are posed in open sets that are not just rectangles. First we need a
quick review of afÔ¨Åne geometry.
6.7
Barycentric Coordinates
Triangular Ô¨Ånite elements are much easier to work with using a system of coordinates
in the plane that is quite different from the usual Cartesian system, namely barycentric
coordinates. Actually, barycentric coordinates are natural systems of coordinates for
afÔ¨Åne geometry.
We will be given three points A1, A2 and A3 in the plane. We Ô¨Årst deÔ¨Åne weighted
barycenters of these points.
DeÔ¨Ånition 6.6 Let Œª1, Œª2 and Œª3 be three scalars such that Œª1 + Œª2 + Œª3 = 1. The
barycenter of the points A j with weights Œª j is the unique point M in the plane such
that ‚àí‚Üí
OM = 3
j=1 Œª j
‚àí‚àí‚Üí
OA j, where O is a given point. This point does not depend on
the choice of O and we thus write
M =
3

j=1
Œª jA j.
One statement in this deÔ¨Ånition needs to be checked, namely that M does not
depend on O. Indeed, let O‚Ä≤ be another choice of point, and M‚Ä≤ be such that ‚àí‚àí‚Üí
O‚Ä≤M‚Ä≤ =
3
j=1 Œª j
‚àí‚àí‚Üí
O‚Ä≤A j. We have
‚àí‚àí‚Üí
O‚Ä≤M‚Ä≤ =
3

j=1
Œª j(
‚àí‚àí‚Üí
O‚Ä≤O +
‚àí‚àí‚Üí
OA j) =
 3

j=1
Œª j
‚àí‚àí‚Üí
O‚Ä≤O +
3

j=1
Œª j
‚àí‚àí‚Üí
OA j =
‚àí‚àí‚Üí
O‚Ä≤O + ‚àí‚Üí
OM =
‚àí‚àí‚Üí
O‚Ä≤M
hence M‚Ä≤ = M.
Now of course, barycenters are likewise deÔ¨Åned for any Ô¨Ånite family of points
and weights of sum equal to 1, and in any afÔ¨Åne space, but we will only use three
points in the plane.

6.7 Barycentric Coordinates
199
From now on, we assume that the three points A j are not aligned, in which case
they constitute what is called an afÔ¨Åne basis of the plane. In this case, we have the
following basic result.
Proposition 6.10 ForallpointsM intheplane,thereexistsauniquetriple(Œª1, Œª2, Œª3)
of real numbers with Œª1 + Œª2 + Œª3 = 1 such that
M =
3

j=1
Œª jA j.
The scalars Œªi = Œªi(M) are called the barycentric coordinates of M, with respect to
points A1, A2, A3.
Proof We use Cartesian coordinates. Let (x j
1, x j
2) be the Cartesian coordinates of
A j in some Cartesian coordinate system, and (x1, x2) be the Cartesian coordinates
of point M. We have M = 3
j=1 Œª jA j if and only if xk = 3
j=1 Œª jx j
k for k = 1, 2.
Moreover, we have the condition 1 = 3
j=1 Œª j. We thus Ô¨Ånd a system of three linear
equations in the three unknowns Œª j
‚éß
‚é™‚é®
‚é™‚é©
Œª1 +
Œª2 +
Œª3 = 1,
x1
1Œª1 + x2
1Œª2 + x3
1Œª3 = x1,
x1
2Œª1 + x2
2Œª2 + x3
2Œª3 = x2.
The determinant of this system is
Œî =
!!!!!!!
1 1 1
x1
1 x2
1 x3
1
x1
2 x2
2 x3
2
!!!!!!!
=
!!!!!!!
1
0
0
x1
1 x2
1 ‚àíx1
1 x3
1 ‚àíx1
1
x1
2 x2
2 ‚àíx1
2 x3
2 ‚àíx1
2
!!!!!!!
= (x2
1 ‚àíx1
1)(x3
2 ‚àíx1
2) ‚àí(x3
1 ‚àíx1
1)(x2
2 ‚àíx1
2) Ã∏= 0,
since it is equal to det(
‚àí‚àí‚Üí
A2A1,
‚àí‚àí‚Üí
A3A1) = 2 area(T), where T is the triangle with vertices
A1 A2 and A3, and area(T) is its algebraic area which is nonzero since the points are
not aligned.
Therefore, for any right-hand side, i.e., for any point M, the system has one and
only one solution.
‚ñ°
Remark 6.9 Going from barycentric coordinates to Cartesian coordinates is just
done by applying the deÔ¨Ånition. Conversely, to compute barycentric coordinates
from Cartesian coordinates, we just need to solve the above linear system.
If the three points are aligned, then we get a system which has a solution only if
M is on the line spanned by the points, and there are inÔ¨Ånitely many solutions, and
if the three points are equal, the system only has a solution if M is equal to the other
points, again with an inÔ¨Ånity of solutions.
‚ñ°
Let us give a few miscellaneous properties of barycentric coordinates.

200
6
The Finite Element Method in Dimension Two
Proposition 6.11 We have
(i) Œªi(A j) = Œ¥i j for all i and j.
(ii) The functions Œªi are afÔ¨Åne in (x1, x2) and conversely, (x1, x2) are afÔ¨Åne functions
of (Œª1, Œª2, Œª3).
(iii) Let (Ai, A j) denote the straight line passing through Ai and A j for i Ã∏= j. Then
(Ai, A j) = {M; Œªk(M) = 0, k Ã∏= i, k Ã∏= j}.
(iv) Let T be the closed triangle determined by the three points A j. Then T =
{M, 0 ‚â§Œªi(M) ‚â§1, i = 1, 2, 3}.
Proof (i) We have A1 = 1 √ó A1 + 0 √ó A2 + 0 √ó A3 with 1 + 0 + 0 = 1, hence by
uniqueness of the barycentric coordinates, Œªi(A1) = Œ¥i1.
(ii) Use Cramer‚Äôs rule for solving the above linear system.
(iii) The function Œªk is a nonzero afÔ¨Åne function by (i) and (ii), thus it vanishes
on a straight line. By (i), this straight line contains Ai and A j, so it is equal to
(Ai, A j).
(iv) We have just seen by (iii) that Œªk(M) = 0 is the equation of the straight line
opposite to vertex Ak. Moreover, by (i) the half-plane containing Ak is the
half-plane {M; Œªk(M) ‚â•0}. The triangle T is the intersection of these three
half-planes, so it is the set of points whose barycentric coordinates are all
nonnegative. Since their sum is equal to 1, they are also less than or equal to 1.
‚ñ°
Figure6.28 shows the signs of the barycentric coordinates in the plane. Note that
there is no ‚àí‚àí‚àíregion, it would be hard to have  Œªi = 1 in such a region ‚Ä¶
Fig. 6.28 Signs of the
barycentric coordinates in
order Œª1, Œª2, Œª3. For
instance, + + ‚àímeans that
Œª1(M) ‚â•0, Œª2(M) ‚â•0 and
Œª3(M) ‚â§0, and so on

6.7 Barycentric Coordinates
201
Let us give the barycentric coordinates of a few points of interest in a triangle:
‚Ä¢ Middle of [A1A2]:
 1
2, 1
2, 0

,
‚Ä¢ Middle of [A2A3]:

0, 1
2, 1
2

,
‚Ä¢ Middle of [A1A3]:
 1
2, 0, 1
2

,
‚Ä¢ Center of gravity of the triangle:
 1
3, 1
3, 1
3

.
Proposition 6.12 The equation of any straight line in barycentric coordinates is of
the form
3

i=1
Œ≥iŒªi(M) = 0,
where the constants Œ≥i are not all equal.
Proof Let A and B be two distinct points with barycentric coordinates (Œ±1, Œ±2, Œ±3)
and (Œ≤1, Œ≤2, Œ≤3). This implies not only that (Œ±1, Œ±2, Œ±3) Ã∏= (Œ≤1, Œ≤2, Œ≤3), but also that
the matrix
Œ±1 Œ±2 Œ±3
Œ≤1 Œ≤2 Œ≤3

is of rank 2. Indeed if this matrix was of rank one, the two
row vectors would be proportional, and since the sum of their coefÔ¨Åcients is equal
to one, the proportionality coefÔ¨Åcient would also be equal to one, i.e., A = B.
A point M is on the straight line (A, B) passing through A and B if and only if it
is a barycenter of A and B, i.e., if and only if there exists a scalar Œº such that
M = ŒºA + (1 ‚àíŒº)B.
It follows immediately that
Œªi(M) = ŒºŒ±i + (1 ‚àíŒº)Œ≤i, i = 1, 2, 3,
which is a parametric representation of the straight line in barycentric coordinates
with Œº ‚ààR.
Due to the rank remark above, the existence of Œº is then clearly equivalent to the
equation
!!!!!!
Œª1(M) Œª2(M) Œª3(M)
Œ±1
Œ±2
Œ±3
Œ≤1
Œ≤2
Œ≤3
!!!!!!
= 0,
which reads
Œ≥1Œª1(M) + Œ≥2Œª2(M) + Œ≥3Œª3(M) = 0,
where Œ≥1 = Œ±2Œ≤3 ‚àíŒ±3Œ≤2 and so on. Indeed, the vanishing of the above determinant
implies that the Ô¨Årst line is a linear combination of the other two, or that Œªi(M) =
Œº1Œ±i + Œº2Œ≤i, i = 1, 2, 3. If we sum over i, we obtain 1 = Œº1 + Œº2.
It remains to show that the Œ≥i are not all equal. This is clear since A ‚àà(A, B) so
that 3
i=1 Œ≥iŒ±i = 0. If we had Œ≥i = Œ≥ for all i, this would imply that 0 = 3
i=1 Œ≥iŒ±i =
Œ≥ 3
i=1 Œ±i = Œ≥ . This would in turn imply that (Œ±1, Œ±2, Œ±3) = (Œ≤1, Œ≤2, Œ≤3) or A = B.

202
6
The Finite Element Method in Dimension Two
Conversely, let us be given three scalars Œ≥i not all equal. The afÔ¨Åne function
f : M ‚Üí3
i=1 Œ≥iŒªi(M) is non constant. Indeed, f (Ai) = Œ≥i. It thus vanishes on a
straight line.
‚ñ°
The above equation is homogeneous, multiplying it by a nonzero constant yields
another equation that obviously describes the same straight line. Conversely, two such
homogeneous equations describe the same straight line if and only if their coefÔ¨Åcients
are proportional. Indeed, assume that Œ≥i and Œ≥ ‚Ä≤
i describe the same straight line. This
implies that the linear system
‚éß
‚é™‚é®
‚é™‚é©
Œª1 +
Œª2 +
Œª3 = 1,
Œ≥1Œª1 + Œ≥2Œª2 + Œ≥3Œª3 = 0,
Œ≥ ‚Ä≤
1Œª1 + Œ≥ ‚Ä≤
2Œª2 + Œ≥ ‚Ä≤
3Œª3 = 0,
has inÔ¨Ånitely many solutions. Hence its determinant is zero.
Let us give an example. Consider the line passing through the middle of [A1A2]
and the middle of [A1A3]. One equation for this line is thus
!!!!!!!
Œª1(M) Œª2(M) Œª3(M)
1
2
1
2
0
1
2
0
1
2
!!!!!!!
= 0,
which reads after multiplication by 4
Œª1(M) ‚àíŒª2(M) ‚àíŒª3(M) = 0.
We can rewrite the equation in nonhomogeneous form by using the fact that
‚àíŒª2(M) ‚àíŒª3(M) = Œª1(M) ‚àí1, which yields
2Œª1(M) ‚àí1 = 0,
in other words, this line is the locus of points such that Œª1(M) = 1
2, which is quite
visible on a Ô¨Ågure.
Remark 6.10 Of course, if we are given the equation of a straight line in Cartesian
coordinates, it is immediate to derive an equation for that same line in barycen-
tric coordinates. Indeed, we have seen that the Cartesian coordinates are afÔ¨Åne
functions of the barycentric coordinates, x1(Œª1, Œª2, Œª3), x2(Œª1, Œª2, Œª3). Substitut-
ing these expressions in a Cartesian equation ax1 + bx2 + c = 0, we obtain an
expression Œ±Œª1 + Œ≤Œª2 + Œ≥ Œª3 + Œ¥ = 0, which we can rewrite in homogeneous form
(Œ± + Œ¥)Œª1 + (Œ≤ + Œ¥)Œª2 + (Œ≥ + Œ¥)Œª3 = 0. It is as easy to pass from an equation in
barycentric coordinates to an equation in Cartesian coordinates.
‚ñ°
An important feature of barycentric coordinates is their invariance under afÔ¨Åne
transformations. For this we modify the notation a bit by indicating the dependence

6.7 Barycentric Coordinates
203
on the points A j by writing ŒªA1,A2,A3
i
(M), which is admittedly cumbersome, and will
thus not be used after this.
Proposition 6.13 Let F be an bijective afÔ¨Åne transformation of the plane. Then we
have
ŒªF(A1),F(A2),F(A3)
i
(F(M)) = ŒªA1,A2,A3
i
(M)
for i = 1, 2, 3 and all M.
Proof This is clear since afÔ¨Åne transformations conserve barycenters.
‚ñ°
Thebarycentriccoordinatesalsohaveanicegeometricalinterpretation.Wechoose
an orientation of the plane such that the loop A1 ‚ÜíA2 ‚ÜíA3 ‚ÜíA1 runs counter-
clockwise. Then, the algebraic area of T, which is equal to 1
2 det(
‚àí‚àí‚Üí
A1A2,
‚àí‚àí‚Üí
A1A3), is
strictly positive. For i = 1, we let i+ = 2, for i = 2, we let i+ = 3, and for i = 3, we
let i+ = 1. We also let i++ = (i+)+. For any point M in the plane, we denote by Ti(M)
the possibly degenerate, oriented triangle MAi+Ai++, see Fig.6.29. Its algebraic area
is area Ti(M) = 1
2 det(
‚àí‚àí‚Üí
MAi+,
‚àí‚àí‚àí‚Üí
MAi++).
Proposition 6.14 We have
Œªi(M) = area Ti(M)
area T
for i = 1, 2, 3 and all M.
Proof Taking O = M in the deÔ¨Ånition of barycentric coordinates, we see that
0 =
3

j=1
Œª j(M)
‚àí‚àí‚Üí
MA j.
Fig. 6.29 Algebraic areas
and barycentric coordinates
M
A1
A2
A3
T1(M)
T2(M)
T3(M)

204
6
The Finite Element Method in Dimension Two
In particular
Œª1(M)
‚àí‚àí‚Üí
MA1 = ‚àíŒª2(M)
‚àí‚àí‚Üí
MA2 ‚àíŒª3(M)
‚àí‚àí‚Üí
MA3
for instance, so that
Œª1(M) det(
‚àí‚àí‚Üí
MA1,
‚àí‚àí‚Üí
MA2) = det(‚àíŒª2(M)
‚àí‚àí‚Üí
MA2 ‚àíŒª3(M)
‚àí‚àí‚Üí
MA3,
‚àí‚àí‚Üí
MA2)
= ‚àíŒª3(M) det(
‚àí‚àí‚Üí
MA3,
‚àí‚àí‚Üí
MA2).
Therefore, we have Œª1(M)area T3(M) = Œª3(M)area T1(M) and likewise for the other
two possible choices. Hence, there exists a scalar Œº such that
‚éõ
‚éù
Œª1(M)
Œª2(M)
Œª3(M)
‚éû
‚é†= Œº
‚éõ
‚éù
area T1(M)
area T2(M)
area T3(M)
‚éû
‚é†.
Summing over the three lines on both sides, we obtain 1 = Œº area T and the propo-
sition is proved.
‚ñ°
Remark 6.11 In the context of the Ô¨Ånite element method, in each triangle of a mesh,
we will use the barycentric coordinates associated with the vertices of this particular
triangle to compute all the quantities that concern the triangle in question, such as
basis functions and so on.
‚ñ°
6.8
Triangular P1 Lagrange Elements
Let us return to the model problem (6.1), on a polygonal domain Œ©. Let us be
given a triangular mesh T on Œ©. We remind the reader that P1 denotes the space
of polynomials of total degree less or equal to 1, i.e., afÔ¨Åne functions. We deÔ¨Åne the
corresponding approximation spaces
Wh = {vh ‚ààC0( ¬ØŒ©), vh|Tk ‚ààP1 for all Tk ‚ààT },
without boundary conditions and
Vh = {vh ‚ààWh, vh = 0 on ‚àÇŒ©},
with boundary conditions. The general approximation theory applies and we thus
just need to describe the approximation spaces in terms of Ô¨Ånite elements and basis
functions.
Let T be a triangle with non aligned vertices A1, A2 and A3. We allow the same
misuse of notation as before for the degrees of freedom.

6.8 Triangular P1 Lagrange Elements
205
Proposition 6.15 The Ô¨Ånite element (T, P1, {p(A1), p(A2), p(A3)}) is unisolvent.
Proof We have dim P1 = 3 so the numbers match. The basis polynomials are obvi-
ous: Œª1, Œª2, Œª3, by Proposition 6.11, (i) and (ii).
‚ñ°
Proposition 6.16 A function of Vh is uniquely determined by its values at the inter-
nal nodes of the mesh and conversely, any set of values for the internal nodes is
interpolated by one and only one element of Vh.
Proof By unisolvence, three values for the three nodes of an element determine one
and only one P1 polynomial that interpolates these nodal values (we take the value
0 for the nodes located on the boundary). Therefore, if we are given a set of values
for each node in the mesh, this set determines one P1 polynomial per element. Let
us check that they combine into a globally C0 function.
Since the mesh is admissible, an edge common to two triangles Tk and Tk‚Ä≤ is
delimited by two vertices A1 and A2 which are also common to both triangles, see
Fig.6.30. We thus have two P1 polynomials p and p‚Ä≤ such that p(A1) = p‚Ä≤(A1) and
p(A2) = p‚Ä≤(A2). We parametrize the segment [A1, A2] as M = ŒºA1 + (1 ‚àíŒº)A2 with
Œº ‚àà[0, 1]. Then the restriction of p ‚àíp‚Ä≤ to this segment is a Ô¨Årst degree polynomial
in the variable Œº that has two roots, Œº = 0 and Œº = 1. Therefore, p ‚àíp‚Ä≤ = 0 on this
segment, and the function deÔ¨Åned by p(x) if x ‚ààTk, p‚Ä≤(x) if x ‚ààTk‚Ä≤ is continuous on
Tk ‚à™Tk‚Ä≤.
‚ñ°
Corollary 6.4 Let us be given a numbering of the internal nodes Si, i = 1, . . . , Nint.
There is a basis of Vh composed of the functions wi
h deÔ¨Åned by wi
h(S j) = Œ¥i j and for
all vh ‚ààVh, we have
vh =
Nint

i=1
vh(Si)wi
h.
Proof Same as before, see Fig.6.31.
‚ñ°
Let us now talk a little bit about matrix assembly. We will not touch on the node
numbering issue, which is clearly more complicated in a triangular mesh than in a
rectangular mesh, especially in an unstructured triangular mesh, such as that shown
in Fig.6.2, in which there is no apparent natural numbering.
Fig. 6.30 Continuity across
an internal edge, P1 case
A2
A1
Tk
Tk‚Ä≤
p‚Ä≤
p

206
6
The Finite Element Method in Dimension Two
Fig. 6.31 A P1 basis
function on a triangular mesh
We will however see how the use of a reference triangle and of barycentric coor-
dinates simpliÔ¨Åes the computation of matrix coefÔ¨Åcients. We have the same element-
wise decomposition as in the rectangular case
Ai j =
NT

k=1
Ai j(Tk),
with
Ai j(Tk) =

Tk
(‚àáw j
h ¬∑ ‚àáwi
h + cw j
hwi
h)(x) dx.
On each triangle Tk, the basis functions either vanish or are equal to one barycentric
coordinate. So we need to compute the integral of the product of two barycentric
coordinates (for c constant) and the integral of the scalar product of their gradient.
We thus introduce a reference triangle
T = {(ÀÜx1, ÀÜx2) ‚ààR2, ÀÜx1 ‚â•0, ÀÜx2 ‚â•0, ÀÜx1 + ÀÜx2 ‚â§1}.
Let ÀÜA1 = (0, 0), ÀÜA2 = (1, 0) and ÀÜA3 = (0, 1) be its vertices and ÀÜŒªi the corresponding
barycentric coordinates. Let Tk be a generic triangle in the mesh, with vertices A1
k,
A2
k, A3
k. Now, there exists one and only one afÔ¨Åne mapping Fk such that Fk(ÀÜA j) = A j
k,
j = 1, 2, 3. Indeed, since afÔ¨Åne mappings conserve barycenters, we simply have
Fk(
M) = ÀÜŒª1(
M)A1
k + ÀÜŒª2(
M)A2
k + ÀÜŒª3(
M)A3
k,
or in other words, Œªi(Fk(
M)) = ÀÜŒªi(
M), where the Ô¨Årst barycentric coordinates are
taken relative to the vertices of Tk in increasing superscript order.
Now the expression of barycentric coordinates in the reference triangle in terms
of Cartesian coordinates is particularly simple:
ÀÜŒª1 = 1 ‚àíÀÜx1 ‚àíÀÜx2,
ÀÜŒª2 = ÀÜx1,
ÀÜŒª3 = ÀÜx2,
whereas they are fairly disagreeable in the generic triangle, see Fig.6.32.

6.8 Triangular P1 Lagrange Elements
207
Fig. 6.32 Barycentric
coordinates in the reference
triangle T
0
ÀÜx1 = ÀÜŒª2
ÀÜx2 = ÀÜŒª3

M
ÀÜA1
ÀÜA2
ÀÜA3
1
1
Let us give an example of computation with the integral
	
Tk Œª2
2 dx. We are going
to use the change of variables x = Fk(ÀÜx). Since this change of variable is afÔ¨Åne, its
Jacobian J is constant, and we have
area Tk =

Tk
dx =

T
J dÀÜx = J
2
therefore J = 2 area Tk. Now we can compute

Tk
Œª2
2(x) dx =

T
ÀÜŒª2
2(ÀÜx)J dÀÜx
= 2 area Tk

T
ÀÜx2
1 dÀÜx
= 2 area Tk
 1
0
ÀÜx2
1
 1‚àíÀÜx1
0
dÀÜx2

dÀÜx1
= 2 area Tk
 1
0
ÀÜx2
1(1 ‚àíÀÜx1) dÀÜx1
= 2 area Tk
1
3 ‚àí1
4

= area Tk
6
.
Exchanging the vertices, we Ô¨Ånd
	
Tk Œª2
1(x) dx =
	
Tk Œª2
3(x) dx = area Tk
6
. A similar
computation shows that
	
Tk Œªi(x)Œª j(x) dx = area Tk
12
for all i Ã∏= j. Such terms are thus
of the order of h2.

208
6
The Finite Element Method in Dimension Two
Fig. 6.33 Geometric
elements of a generic triangle
Ai+
Ai++
Ai
ŒΩi(Tk)
Hi
hi(Tk)
bi(Tk)
Let us now turn to the gradient terms. We Ô¨Årst need to compute ‚àáŒªi, which is a
constant vector.
We introduce hi(Tk) and bi(Tk) respectively the height and base of Tk relative to
Ai, Hi the foot of the altitude of Ai and ŒΩi(Tk) the unit vector perpendicular to the
base and pointing from the base toward Ai, see Fig.6.33. Since Œªi is afÔ¨Åne, we have
for all points M
Œªi(M) = Œªi(Hi) + ‚àáŒªi ¬∑ ‚àí‚àí‚Üí
HiM.
Now Hi lies on the straight line (Ai+, Ai++), thus Œªi(Hi) = 0. Since Œªi vanishes on
this straight line, it follows that ‚àáŒªi = ŒºŒΩi(Tk) for some scalar Œº. Taking M = Ai,
we obtain
1 = ŒºŒΩi(Tk) ¬∑ ‚àí‚àí‚Üí
HiM = Œºhi(Tk).
Therefore, we have
‚àáŒªi =
1
hi(Tk)ŒΩi(Tk) =
bi(Tk)
2 area Tk
ŒΩi(Tk).
It follows from instance that
‚à•‚àáŒªi‚à•2 =
bi(Tk)2
4(area Tk)2 ,

6.8 Triangular P1 Lagrange Elements
209
so that

Tk
‚à•‚àáŒªi‚à•2 dx = bi(Tk)2
4 area Tk
.
These terms are of the order of 1. We could likewise compute
	
Tk ‚àáŒªi ¬∑ ‚àáŒª j dx
without difÔ¨Åculty, with expressions that involve the angles of Tk.
6.9
Triangular P2 Lagrange Elements
Let us go one step up in degree and consider P2 elements. We have dim P2 = 6 as is
shown by its canonical basis (1, x1, x2, x2
1, x1x2, x2
2). This canonical basis is useless
for our purposes and it is again much better to work in barycentric coordinates. The
following result is meant to convince the reader of this fact.
Proposition 6.17 Let T be a triangle with vertices A1, A2, A3 and Œª1, Œª2, Œª3 be the
corresponding barycentric coordinates. The family (Œª2
1, Œª2
2, Œª2
3, Œª1Œª2, Œª2Œª3, Œª1Œª3) is
a basis of P2.
Proof The functions Œªi are afÔ¨Åne, thus products ŒªiŒª j belong to P2. We have a family
of 6 vectors in a 6-dimensional space, it thus sufÔ¨Åces to show that it is linearly
independent. Let us be given a family of 6 scalars Œ±i j such that
3

i‚â§j=1
Œ±i jŒªiŒª j = 0.
Evaluating Ô¨Årst this relation at point Ak, we obtain
0 =
3

i‚â§j=1
Œ±i jŒ¥ikŒ¥ jk = Œ±kk
for all k. We are thus left with
Œ±12Œª1Œª2 + Œ±13Œª1Œª3 + Œ±23Œª2Œª3 = 0.
We evaluate this relation at point A1+A2
2
, the middle of A1 and A2, for which Œª1 =
Œª2 = 1
2 and Œª3 = 0. Hence
Œ±12
4
= 0,
and similarly Œ±13 = Œ±23 = 0.
‚ñ°
We need 6 degrees of freedom of Lagrange interpolation. We take the three ver-
tices Ai and the three edge middles Ai,i+, see Fig.6.34. Then we have the following
proposition, using the same misuse of notation as before.

210
6
The Finite Element Method in Dimension Two
Fig. 6.34 The P2 Lagrange
triangle
Œª3 = 1
2
Œª
2 = 1
2
Œª
1 = 1
2
A1
A2
A3
A3,1
A1,2
A2,3
Proposition 6.18 The Ô¨Ånite element

T, P2, {p(Ai), p(Ai,i+)}i=1,2,3

is unisolvent.
Proof We have the right number of degrees of freedom with respect to the dimension
of the polynomial space. It is thus sufÔ¨Åcient to construct the basis polynomials.
Everything being invariant by permutation of the vertices, it is clearly sufÔ¨Åcient to
construct the basis polynomial corresponding to A1 and that corresponding to A1,2,
for example.
Let us start with A1. We thus need a polynomial p1 ‚ààP2 such that p1(A1) = 1
and p1 vanishes at all the other nodes. We will freely use the obvious fact that the
restriction of a polynomial of total degree at most n in two variables to a straight
line is a polynomial of degree at most n in any afÔ¨Åne parametrization of the straight
line. Here, p1 is of degree at most 2 on (A2, A3), with three roots corresponding to
points A2, A2,3 and A3, thus it vanishes on (A2, A3). The equation of the straight
line is Œª1 = 0, hence p1 is divisible by Œª1, i.e., there exists a polynomial q such that
p1 = qŒª1.
Now Œª1 is of degree 1, therefore q is of degree at most one. Moreover, since
Œª1(A1,2) = Œª1(A3,1) = 1
2 Ã∏= 0, we have q(A1,2) = q(A3,1) = 0. Therefore, by the
same token, q vanishes on the straight line (A1,2, A3,1), of equation Œª1 ‚àí1
2 = 0.
Thus q is divisible by Œª1 ‚àí1
2, so that q = c(Œª1 ‚àí1
2) with c of degree at most 0, i.e.,
a constant. Finally, the relation p1(A1) = 1 yields 1 = c
2, hence p1 = Œª1(2Œª1 ‚àí1).
Conversely, it is easy‚Äîbut necessary‚Äîto check that this polynomial is in P2 and
satisÔ¨Åes the required interpolation relations.
To sum up, we have
p1 = Œª1(2Œª1 ‚àí1),
p2 = Œª2(2Œª2 ‚àí1),
p3 = Œª3(2Œª3 ‚àí1),

6.9 Triangular P2 Lagrange Elements
211
for the basis polynomials associated with the vertices. The basis polynomials are
equivalently rewritten in homogeneous form as
pi = Œªi(Œªi ‚àíŒªi+ ‚àíŒªi++),
for i = 1, 2, 3.
Next we deal with A1,2. The polynomial p1,2 has three roots on the line (A1, A3),
where it must thus vanish. Hence it is divisible by Œª2 so that there exists q such
that p1,2 = qŒª2. Likewise, the polynomial p1,2 must also vanish on the line (A2, A3),
hence be divisible by Œª1. Now the polynomials Œª1 and Œª2 are relatively prime, there-
fore p1,2 = cŒª1Œª2 where c is a constant. Using p1,2(A1,2) = 1, we obtain c = 4.
Conversely, this polynomial is in P2 and satisÔ¨Åes the required interpolation relations.
To sum up, we have
p1,2 = 4Œª1Œª2,
p2,3 = 4Œª2Œª3,
p3,1 = 4Œª1Œª3,
for the basis polynomials associated with the middles of the edges.
Wehavefoundsixbasispolynomials,thereforetheP2 Lagrangetriangularelement
is unisolvent.
‚ñ°
Figure6.35 shows the graphs of the different P2 basis polynomials.
The approximation space
Vh = {vh ‚ààC0( ¬ØŒ©); vh|Tk ‚ààP2, ‚àÄTk ‚ààT , vh = 0 on ‚àÇŒ©}
is of course endowed with a set of basis functions that interpolate values at all nodes
(vertices and middles). Let us quickly check the continuity across an edge. We thus
have two polynomials of degree at most two, one on each side of the edge, that
coincide at the vertices and the middle, see Fig.6.36. Their restriction to the edge is
Fig. 6.35 The two different
kinds of P2 basis
polynomials

212
6
The Finite Element Method in Dimension Two
Fig. 6.36 Continuity across
an internal edge, P2 case
A2
A1
Tk
Tk‚Ä≤
A1,2
p‚Ä≤
p
Fig. 6.37 A basis function
associated with a vertex
Fig. 6.38 A basis function
associated with a middle
of degree two in one variable, their difference has three roots, hence they are equal
on the edge. The rest follows as before. Figures6.37 and 6.38 show the graphs of
typical P2 basis functions.
Let us say a few words about P3 Lagrange triangles. We have dim P3 = 10, thus 10
interpolation points are needed. We take the 3 vertices plus 2 points per edge, located
at the thirds (this will obviously imply global continuity). That makes 9 points. A
simple choice for the tenth point is then the center of gravity, see Fig.6.39.
Naturally, this Ô¨Ånite element is unisolvent. We list the basis polynomials:
p0 = 27Œª1Œª2Œª3,

6.9 Triangular P2 Lagrange Elements
213
Fig. 6.39 The 10 nodes of a
P3 Lagrange triangle. We use
the notation
Ai,i,i+ = 2
3Ai + 1
3Ai+ and
Ai,i+,i+ = 1
3Ai + 2
3Ai+. The
center of gravity is of course
A0 = 1
3(A1 + A2 + A3)
corresponding to the center of gravity, also called a bubble due to the shape of its
graph,
pi = 1
2Œªi(3Œªi ‚àí1)(3Œªi ‚àí2), i = 1, 2, 3,
associated with the three vertices, and
pi,i,i+ = 9
2ŒªiŒªi+(3Œªi ‚àí1), pi,i+,i+ = 9
2ŒªiŒªi+(3Œªi+ ‚àí1), i = 1, 2, 3,
associated with the six edge nodes. All these formulas can be rewritten in homoge-
neous form. Figure6.40 shows the graphs of the different P3 basis polynomials.
Also of course, the approximation space
Vh = {vh ‚ààC0( ¬ØŒ©); vh|Tk ‚ààP3, ‚àÄTk ‚ààT , vh = 0 on ‚àÇŒ©}
has the usual basis made of basis functions which we picture in Fig.6.41.
As in the rectangular case, the reason for facing the added complexity of using
higher degree polynomials is to achieve faster convergence. Indeed, we have the
following general result [19, 66], for Pk-Lagrange triangular elements corresponding
to the approximation spaces
Vh = {vh ‚ààC0( ¬ØŒ©); vh|Tl ‚ààPk, ‚àÄTl ‚ààT , vh = 0 on ‚àÇŒ©}
with k ‚â•1.

214
6
The Finite Element Method in Dimension Two
Fig. 6.40 The three
different kinds of P3 basis
polynomials
Theorem 6.3 Let us be given a regular family of triangulations indexed by h. We
consider Pk Lagrange elements on the triangulations. If u ‚ààHk+1(Œ©), then we have
‚à•u ‚àíuh‚à•H1(Œ©) ‚â§Chk|u|Hk+1(Œ©).
The proof is along the same lines as the proof in the Q1 case, but with a lot more
technicality due to the afÔ¨Åne changes of variables between the reference triangle and
the generic triangle.
All the above Lagrange triangular elements are adequate for H1 approximation
and are adapted to C0 approximation spaces. It is also possible to deÔ¨Åne C1 Her-
mite triangular elements for fourth order problems. One possible construction uses
P5 polynomials, hence 21 degrees of freedom. This is the Argyris Ô¨Ånite element,
[14, 19, 21, 27, 82]. More generally, there is a very large diversity of triangular

6.9 Triangular P2 Lagrange Elements
215
Fig. 6.41 A few P3 basis
functions
elements in the literature, sometimes especially crafted for one (class of) boundary
value problem(s). Other generalizations include curvilinear triangles that are used
to approximate curved boundaries. These are called isoparametric elements, see
[19, 21].
6.10
An Example of 2d-Computation
To conclude this chapter, we show an example of computation made with the
FreeFem++ software (a user-friendly free Ô¨Ånite element software package available
at http://www.freefem.org/). We solve the Laplace equation ‚àíŒîu = 1 with a homo-
geneous Dirichlet boundary condition in the polygonal domain shown in Fig.6.42,
using P1 and P2 Lagrange elements on the same mesh.

216
6
The Finite Element Method in Dimension Two
Fig. 6.42 Domain and
triangular mesh
Fig. 6.43 Isovalue lines of
the approximated solution uh
in the P1 case
In this example, see Figs.6.42, 6.43, 6.44, 6.45 and 6.46, FreeFem++ is given the
boundary nodes (105 such nodes) and constructs a ‚Äúgood‚Äù mesh in the domain based
on these boundary nodes using an automatic mesh generator. The mesh has 1,107
triangles and 607 vertices. FreeFem++ then assembles the matrix. It then proceeds
to solve the linear system, then displays the solution and exports various Ô¨Åles for

6.10 An Example of 2d-Computation
217
Fig. 6.44 Isovalue lines of
the approximated solution uh
in the P2 case
Fig. 6.45 3d visualization of
the graph of uh in the P1 case
further use. The second computation uses P2 elements and has 2,320 degrees of
freedom, hence a 2,320√ó2,320 matrix. Both computations only take a small fraction
of a second on a laptop computer.
The 3d visualizations of the graphs are done with medit (free software available
at http://www.ljll.math.upmc.fr/~frey/software.html).

218
6
The Finite Element Method in Dimension Two
Fig. 6.46 3d visualization of
the graph of uh in the P2 case
This example conÔ¨Årms that the Ô¨Ånite element method is much more versatile than
the Ô¨Ånite difference method in two dimensions seen in Chap.2. In fact, its range of
applications is much wider.

Chapter 7
The Heat Equation
We have so far studied elliptic problems, i.e., stationary problems. We now turn to
evolution problems, starting with the archetypal parabolic equation, namely the heat
equation.
In this chapter, we will present a brief and far from exhaustive theoretical study
of the heat equation. We will mostly work in one dimension of space, some of the
results having an immediate counterpart in higher dimensions, others not. The study
of numerical approximations of the heat equation will be the subject of the next
chapter.
7.1
Overview
In Chap.1, we presented the historical derivation of the heat equation by Fourier. In
the general d-dimensional case, the heat equation is as follows. Let us be given Œ© be
an open subset of Rd and T ‚ààR‚àó
+. We note Q = Œ© √ó ]0, T [. When all the physical
constants are set to 1, the heat equation with source term f reads
‚àÇu
‚àÇt (x, t) ‚àíŒîu(x, t) = f (x, t) in Q,
together with an initial condition
u(x, 0) = u0(x) in Œ©,
and boundary values, for instance Dirichlet boundary values
u(x, t) = g(x, t) on ‚àÇŒ© √ó ]0, T [,
where f , u0 and g are given functions. The unknown u is a function from ¬ØQ to R.
This is called an initial-boundary value problem.
¬© Springer International Publishing Switzerland 2016
H. Le Dret and B. Lucquin, Partial Differential Equations:
Modeling, Analysis and Numerical Approximation, International Series
of Numerical Mathematics 168, DOI 10.1007/978-3-319-27067-8_7
219

220
7
The Heat Equation
When d = 1 and Œ© is bounded, we can take Œ© = ]0, 1[ without loss of generality.
The problem reads
‚éß
‚é™‚é®
‚é™‚é©
‚àÇu
‚àÇt (x, t) ‚àí‚àÇ2u
‚àÇx2 (x, t) = f (x, t) in Q,
u(x, 0) = u0(x) in Œ©,
u(0, t) = g(0, t), u(1, t) = g(1, t) in ]0, T [.
(7.1)
Other possible boundary conditions are the Neumann condition and the Fourier
condition. For brevity, we limit ourselves to the Dirichlet case.
7.2
The Maximum Principle for the Heat Equation
We have seen a version of the maximum principle for a second order elliptic equation.
Parabolic equations such as the heat equation also satisfy their own version of the
maximum principle, see for example [5, 35].
Proposition 7.1 We assume that u is a solution of problem (7.1) that belongs to
C0( ¬ØQ) ‚à©C2(Q ‚à™(Œ© √ó {T })). If f ‚â•0 in Q, then u attains its minimum on
(Œ© √ó {0}) ‚à™(‚àÇŒ© √ó [0, T ]).
Proof We write the proof for d = 1. Let us Ô¨Årst assume that f > 0 on Q‚à™(Œ©√ó{T }).
The set ¬ØQ is compact and the function u is continuous on ¬ØQ, thus it attains its
minimum somewhere in ¬ØQ, say at point (x0, t0).
If (x0, t0) ‚ààQ which is an open set, then ‚àÇu
‚àÇt (x0, t0) = 0.1 Moreover, ‚àÇ2u
‚àÇx2 (x0, t0) ‚â•
0 since u is C2 in a neighborhood of (x0, t0). Therefore
 ‚àÇu
‚àÇt ‚àí‚àÇ2u
‚àÇx2

(x0, t0) ‚â§0, which
contradicts f (x0, t0) > 0.
Therefore (x0, t0) ‚àà‚àÇQ =

(Œ© √ó {0}) ‚à™(‚àÇŒ© √ó [0, T ])

‚à™(Œ© √ó {T }). Assume
that (x0, t0) ‚ààŒ© √ó {T }, i.e., that x0 ‚ààŒ© and t0 = T . Since as a function in
the variable x for t = T , u is also C2, it follows again that ‚àÇ2u
‚àÇx2 (x0, T ) ‚â•0 so
that ‚àÇu
‚àÇt (x0, T ) = ‚àÇ2u
‚àÇx2 (x0, T ) + f (x0, T ) > 0. Thus there exists t < T such that
u(x0, t) < u(x0, T ), which is consequently not a minimum value for u.
The only possibility left is that (x0, t0) ‚ààK = (Œ© √ó {0}) ‚à™(‚àÇŒ© √ó [0, T ]).
Consider now the case f ‚â•0. Let Œµ > 0 and uŒµ(x, t) = u(x, t) + Œµx(1 ‚àíx). In
particular u(x, t) ‚â§uŒµ(x, t) in ¬ØQ. We have
‚àÇuŒµ
‚àÇt ‚àí‚àÇ2uŒµ
‚àÇx2 = ‚àÇu
‚àÇt ‚àí‚àÇ2u
‚àÇx2 + 2Œµ = f + 2Œµ > 0.
1The fact that ‚àÇu
‚àÇx (x0, t0) = 0 is not useful here.

7.2 The Maximum Principle for the Heat Equation
221
Fig. 7.1 The set K where u
attains its minimum (thicker
line)
1
0
T
¬ØQ
K
x
t
By the previous argument, uŒµ attains its minimum at a point (xŒµ, tŒµ) of K. We
have
u(x0, t0) ‚â§u(xŒµ, tŒµ) ‚â§uŒµ(xŒµ, tŒµ) ‚â§uŒµ(x0, t0) = u(x0, t0) + Œµx0(1 ‚àíx0).
Therefore,
u(x0, t0) ‚â§u(xŒµ, tŒµ) ‚â§u(x0, t0) + Œµx0(1 ‚àíx0).
We now let Œµ ‚Üí0. Since K is compact, we may extract a subsequence still
denoted by œµ such that (xŒµ, tŒµ) ‚Üí(¬Øx, ¬Øt) ‚ààK. Passing to the limit in the above
inequalities and using the continuity of u, we obtain
u(x0, t0) = u(¬Øx, ¬Øt),
with (¬Øx, ¬Øt) ‚ààK and the minimum is therefore attained on K (see Fig.7.1).
‚ñ°
Remark 7.1 The meaning of the maximum principle is that the minimum tempera-
ture is either attained at t = 0 or on the boundary of Œ© at some other time t ‚àà]0, T ],
but in general not in Œ© √ó ]0, T ]. It is also valid in any dimension d, using the same
proof and the maximum principle for the Laplacian, that we have not proved here.
The result cannot be reÔ¨Åned any further since u = 0 is a solution for f = 0, u0 = 0
that attains its minimum at any point in K.
‚ñ°
The maximum principle has many consequences, some of which we now list.
Corollary 7.1 Under the hypotheses of Proposition7.1, if f ‚â•0, g ‚â•0 and u0 ‚â•0,
then u ‚â•0 in ¬ØQ.

222
7
The Heat Equation
Proof This is clear since the minimum of u is either of the form u0(x0), g(0, t0) or
g(1, t0).
‚ñ°
Remark 7.2 This form of the maximum principle is again a monotonicity result.
The interesting physical interpretation is that if you heat up a room, the walls are
kept at a nonnegative temperature and the initial temperature is nonnegative, then
the temperature in the room stays nonnegative everywhere and at any time.
‚ñ°
We also have a stability result in the C0 norm.
Corollary 7.2 Under the hypotheses of Proposition7.1, if f = 0 and g = 0, then
‚à•u‚à•C0( ¬ØQ) = ‚à•u0‚à•C0( ¬ØŒ©).
Proof Let v+ = u + ‚à•u0‚à•C0( ¬ØŒ©). We have
‚àÇv+
‚àÇt ‚àí‚àÇ2v+
‚àÇx2 = 0,
since f = 0,
v+(0, t) = v+(1, t) = ‚à•u0‚à•C0( ¬ØŒ©) ‚â•0,
since g = 0 and
v+(x, 0) = u0 + ‚à•u0‚à•C0( ¬ØŒ©) ‚â•0.
By Corollary7.1, v+ ‚â•0 in ¬ØQ, or in other words u(x, t) ‚â•‚àí‚à•u0‚à•C0( ¬ØŒ©) in ¬ØQ.
Changing u in ‚àíu, we also have u(x, t) ‚â§‚à•u0‚à•C0( ¬ØŒ©) in ¬ØQ, hence the result.
‚ñ°
Such a stability result immediately entails a uniqueness result.
Proposition 7.2 Problem (7.1) has at most one solution in C0( ¬ØQ) ‚à©C2(Q).
Proof Indeed, if u1 and u2 are two solutions, then v = u1‚àíu2 satisÔ¨Åes the hypotheses
of Corollary7.2 on Œ© √ó [0, T ‚àíŒ∑]) for all Œ∑ > 0 with an initial value u0 = 0.
‚ñ°
7.3
Construction of a Regular Solution
We will see several different ways of constructing solutions to the heat equation. Let
us start with an elementary construction using Fourier series. It should be recalled
that Joseph Fourier invented what became Fourier series in the 1800s, exactly for the
purpose of solving the heat equation, see Chap. 1, Sect.1.7.
We consider the case when f = 0, no heat source, and g = 0, homogeneous
Dirichlet boundary condition, the only nonzero data being the initial condition u0.

7.3 Construction of a Regular Solution
223
Proposition 7.3 Letu0 ‚ààC0([0, 1])bepiecewiseC1 andsuchthatu0(0) = u0(1) =
0. There exists a sequence (bk)k‚ààN‚àóof real numbers such that we have
u0(x) =
+‚àû

k=1
bk sin(kœÄx)
for all x ‚àà[0, 1]. Moreover, 	+‚àû
k=1 |bk| < +‚àû.
Proof We Ô¨Årst extend u0 by imparity by setting 
u0(x) = u0(x) for x ‚àà[0, 1] and

u0(x) = ‚àíu0(‚àíx) for x ‚àà[‚àí1, 0[. The resulting function is odd and continuous on
[‚àí1, 1] by construction since u0(0) = 0 and still piecewise C1.
Secondly, we extend
u0 to R by 2-periodicity by setting
‚âàu0(x) = 
u0(x ‚àí2‚åäx+1
2 ‚åã),
where ‚åä¬∑‚åãdenotes the Ô¨Çoor function. This function is continuous since 
u0(‚àí1) =

u0(1) = 0, piecewise C1 and 2-periodic by construction. Therefore, by Dirichlet‚Äôs
theorem, it can be expanded in Fourier series
‚âàu0(x) = a0
2 +
+‚àû

k=1
ak cos(kœÄx) +
+‚àû

k=1
bk sin(kœÄx),
with 	+‚àû
k=1(|ak| + |bk|) < +‚àû, hence the series is normally convergent. Now
‚âàu0 is
also odd by construction, so that all ak Fourier coefÔ¨Åcients vanish. Restricting the
above expansion to x ‚àà[0, 1], we obtain the result.
‚ñ°
Theorem 7.1 Let u0 be as above. Then the function deÔ¨Åned by
u(x, t) =
+‚àû

k=1
bk sin(kœÄx)e‚àík2œÄ2t
belongs to C0(R √ó [0, +‚àû[) ‚à©C‚àû(R √ó ]0, +‚àû[). Its restriction to ¬ØQ solves the
initial-boundary value problem (7.1) with data f = 0, g = 0.
Proof We Ô¨Årst need to show that the series above is convergent in some sense and that
its sum belongs to the function spaces indicated in the theorem. Normal convergence
on R √ó [0, +‚àû[ is obvious since |bk sin(kœÄx)e‚àík2œÄ2t| ‚â§|bk|, thus u exists and is
continuous on R √ó [0, +‚àû[.
Let us now consider differentiability. Now if u is supposed to coincide with u0 at
t = 0, and u0 is only piecewise C1, we cannot expect u to be C‚àûup to t = 0, hence
the exclusion of t = 0 in the theorem. In order to use theorems on the differentiation
of series, we actually need to stay away from t = 0 as will become clear in the proof.
Let us thus chose Œµ > 0 and work for t ‚â•Œµ. It is convenient to notice that
sin(kœÄx)e‚àík2œÄ2t = Im(eikœÄx‚àík2œÄ2t),

224
7
The Heat Equation
where Im z denotes the imaginary part of a complex number z. Therefore, for any
nonnegative integers p and q, we have
‚àÇp+q
‚àÇx p‚àÇtq

sin(kœÄx)e‚àík2œÄ2t
= (kœÄ)p(‚àík2œÄ2)q Im (i peikœÄx‚àík2œÄ2t).
Thus
bk
‚àÇp+q
‚àÇx p‚àÇtq

sin(kœÄx)e‚àík2œÄ2t ‚â§|bk|œÄ p+2qk p+2qe‚àík2œÄ2t
‚â§|bk|œÄ p+2qk p+2qe‚àík2œÄ2Œµ
for t ‚â•Œµ. Since bk = 1
2
 1
‚àí1 sin(kœÄx)
u0(x) dx, we have |bk| ‚â§‚à•u0‚à•C0([0,1]), thus
bk
‚àÇp+q
‚àÇx p‚àÇtq

sin(kœÄx)e‚àík2œÄ2t ‚â§C p,qk p+2qe‚àík2œÄ2Œµ,
for some constant C p,q, because t ‚â•Œµ. The right-hand side is the general term
of a convergent series due to the e‚àík2œÄ2Œµ term with Œµ > 0, thus the left-hand side
is the general term of a normally, thus uniformly convergent series, for any p and
q. Therefore, u is of class C‚àûon R √ó ]Œµ, +‚àû[, for all Œµ > 0, thus belongs to
C‚àû(R √ó ]0, +‚àû[). Moreover, we have
‚àÇp+qu
‚àÇx p‚àÇtq (x, t) =
+‚àû

k=1
bk
‚àÇp+q
‚àÇx p‚àÇtq

sin(kœÄx)e‚àík2œÄ2t
for all (x, t) ‚ààR √ó ]0, +‚àû[ and all p, q. In particular, we have
‚àÇu
‚àÇt (x, t) =
+‚àû

k=1
bk
‚àÇ
‚àÇt

sin(kœÄx)e‚àík2œÄ2t
= ‚àí
+‚àû

k=1
bkk2œÄ2 sin(kœÄx)e‚àík2œÄ2t
and
‚àÇ2u
‚àÇx2 (x, t) =
+‚àû

k=1
bk
‚àÇ2
‚àÇx2

sin(kœÄx)e‚àík2œÄ2t
= ‚àí
+‚àû

k=1
bkk2œÄ2 sin(kœÄx)e‚àík2œÄ2t
so that
‚àÇu
‚àÇt ‚àí‚àÇ2u
‚àÇx2 = 0 on R √ó ]0, +‚àû[,
and u solves the heat equation.
Concerning the boundary conditions, we note that for all integers k ‚â•1, we have
sin(kœÄ √ó 0) = sin(kœÄ √ó 1) = 0, so that
u(0, t) = u(1, t) = 0

7.3 Construction of a Regular Solution
225
for all t ‚ààR+. Finally,
u(x, 0) =
+‚àû

k=1
bk sin(kœÄx)e‚àík2œÄ2√ó0 =
+‚àû

k=1
bk sin(kœÄx) = u0(x),
and the initial condition is satisÔ¨Åed.
‚ñ°
Remark 7.3 It is worth noticing that both boundary conditions and initial condition
make sense because u is continuous on ¬ØQ. Moreover, the regularity of u is such that
the previous uniqueness result applies, thus we have found the one and only one
solution in that class.
An important feature of the heat equation, and more generally of parabolic equa-
tions, is that whatever regularity u0 may have, if f = 0, then the solution u becomes
C‚àûinstantly for t > 0. This is a smoothing effect.
For t ‚â•0 Ô¨Åxed, the series that gives the function x ‚Üíu(x, t) is also the Fourier
series of the odd and 2-periodic R-extension of this function. The exponential term
e‚àík2œÄ2t makes the corresponding Fourier coefÔ¨Åcients decrease rapidly, which indi-
cates that the sum is smooth (with respect to x), but we knew that already, both in x
and t.
The smoothing effect also tells us why the backward heat equation is ill-posed.
Indeed, there can be no solution to the backward heat equation with an initial condi-
tion that is not C‚àû, since an initial condition for the backward heat equation is a Ô¨Ånal
condition for the forward heat equation. It is not even clear that all C‚àûfunctions can
be reached by the evolution of the heat equation. Therefore, time is irreversible in
the heat equation.
We can see the same effect in the series, since for t < 0, ‚àík2œÄ2t > 0 and the
exponential terms become explosive instead of ensuring extremely fast convergence
of the series. The only way the series can converge for t < 0 is for the Fourier
coefÔ¨Åcients bk of the initial condition to be rapidly decreasing, so as to compensate for
the exponential term. Again, a function with rapidly decreasing Fourier coefÔ¨Åcients
is very smooth.
‚ñ°
The above solution of the heat equation exhibits rapid uniform decay in time.
Proposition 7.4 There exists a constant C such that
|u(x, t)| ‚â§Ce‚àíœÄ2t.
In particular, u(x, t) ‚Üí0 when t ‚Üí+‚àû, uniformly with respect to x.
Proof Indeed, e‚àík2œÄ2t ‚â§e‚àíœÄ2t for all k and all t ‚â•0, so that
|u(x, t)| ‚â§
+‚àû

k=1
|bk|e‚àík2œÄ2t ‚â§e‚àíœÄ2t
+‚àû

k=1
|bk|,
hence the result since 	+‚àû
k=1 |bk| < +‚àû.
‚ñ°

226
7
The Heat Equation
Remark 7.4 If we remember the physical interpretation of the heat equation, keeping
the walls of a room at 0 degree is tantamount to having paper-thin walls and a huge
ice cube surrounding the room. If there is no heat source inside the room, it is not
contrary to physical intuition that the temperature inside should drop to 0 degree
pretty quickly, if it was positive at t = 0. All the heat inside the room eventually
Ô¨Çows outside into the ice since the heat Ô¨Çux is proportional to the opposite of the
temperature gradient.
‚ñ°
Apart from proving the existence of a solution in a particular case, the Fourier
series expansion can also be used as a very precise numerical method, provided the
Fourier coefÔ¨Åcients of the initial condition are known with good accuracy.
In effect, we have a coarse error estimate
u(x, t) ‚àí
N

k=1
bk sin(kœÄx)e‚àík2œÄ2t ‚â§

+‚àû

k=N+1
|bk|

e‚àí(N+1)2œÄ2t,
so that truncating the series and retaining only a few terms, we can expect to achieve
excellent precision as soon as t > 0 is noticeably nonzero. Of course, the sine and
exponential functions are already implemented in all computer languages.
The use of Fourier series in a numerical context is the simplest example of spectral
method. Let us give an example of the numerical application of Fourier series. We
consider a simple continuous, piecewise afÔ¨Åne initial condition such as depicted in
Fig.7.2. Six terms in the Fourier series already provide a very good approximation of
the solution. Figure7.3 shows several views of the graph of u plotted in (x, t) space.
The grey stripes show the graphs of x ‚Üíu(x, t) for a discrete sample of values of t.
Fig. 7.2 An admissible
initial value u0
0
0,25
0,5
0,75
1
0,25
0,5
0,75
1
1,25

7.3 Construction of a Regular Solution
227
Fig. 7.3 Various views of the corresponding solution u, using Fourier series, 0 ‚â§x ‚â§1, 0 ‚â§t ‚â§T
We see the exponential decay in time, the smoothing effect, and also the fact that the
Ô¨Årst nonzero term in the series rapidly becomes dominant as t increases, as can be
expected from the exponential terms. Note also the continuity as t ‚Üí0+, and the
fact that the time derivative goes to ¬±‚àûwhen (x, t) tends to a point (x0, 0) where
the second space derivative of the initial condition is in a sense inÔ¨Ånite,2 i.e., the Ô¨Årst
space derivative is discontinuous. We also see that the minimum is attained where
the maximum principle says it must be attained.3
The Fourier expansion even gives quite good results for cases that are not covered
by the preceding analysis, for instance for an initial condition that does not satisfy
2Or more accurately a Dirac mass.
3Which is reassuring.

228
7
The Heat Equation
Fig. 7.4 Fourier series and
discontinuous solutions, 20
terms. The Gibbs
phenomenon is visible in the
neighborhood of
(x, t) = (0, 0) and
(x, t) = (1, 0)
Fig. 7.5 Fourier series and
discontinuous solutions, 100
terms
the Dirichlet boundary condition, such as u0(x) = 1! Figure7.4 shows 20 terms in
the series, and of course a Gibbs phenomenon, i.e., localized oscillations around the
discontinuities.
We also show the same computation with 100 terms in the Fourier series. The
Gibbs phenomenon is still there, see Figs.7.6 and 7.7, but does not show on Fig.7.5
for sampling reasons: It occurs on a length scale that is too small to be captured by
the graphics program. Recall that high frequency oscillations in space are damped
extremely rapidly in time by the exponential term.
Figure7.7 features a few close-ups of the 100 term Fourier series expansion of u
near (x, t) = (0, 0).

7.3 Construction of a Regular Solution
229
0
0,25
0,5
0,75
1
0,25
0,5
0,75
1
1,25
Fig. 7.6 One hundred terms in the Fourier series of 
u0, with Gibbs phenomenon around 0 and 1
Fig. 7.7 Gibbs phenomenon and bad approximation of discontinuity, up close

230
7
The Heat Equation
7.4
Spaces of Hilbert Space-Valued Functions
In order to work with more general solutions and less smooth data, we need to
introduce a few new function spaces. We will actually consider real-valued functions
in the two variables x and t, as functions in the variable t with values in a space
of functions in the variable x, u(t) = u(¬∑, t).4 This is because the time and space
variables do not play the same role for the heat equation.
Let V denote a separable Hilbert space with norm ‚à•¬∑ ‚à•V . Let T > 0 be given.
The space C0([0, T ]; V ) of continuous functions from [0, T ] with values in V is a
Banach space for its natural norm
‚à•f ‚à•C0([0,T ];V ) = max
t‚àà[0,T ] ‚à•f (t)‚à•V .
A V -valued function on ]0, T [ is differentiable at point t ‚àà]0, T [ if there exists a
vector f ‚Ä≤(t) ‚ààV such that
 f (t + h) ‚àíf (t)
h
‚àíf ‚Ä≤(t)

V ‚Üí0 when h ‚Üí0.
Ofcourse, f ‚Ä≤(t)iscalledthederivativeof f atpointt.Afunctionisclearlycontinuous
at all of its points of differentiability. If f is differentiable at all points t, then its
derivative becomes a V -valued function. We can deÔ¨Åne
C1([0, T ]; V ) =

f ‚ààC0([0, T ]; V ); f ‚Ä≤ ‚ààC0([0, T ]; V )

in the sense that f ‚Ä≤ has a continuous extension at 0 and T . When equipped with its
natural norm
‚à•f ‚à•C1([0,T ];V ) = max

‚à•f ‚à•C0([0,T ];V ), ‚à•f ‚Ä≤‚à•C0([0,T ];V )

,
C1([0, T ]; V ) is a Banach space. More generally, we can deÔ¨Åne Ck([0, T ]; V ) for
all positive integers k. All of these notions are perfectly classical and work the same
as in the real-valued case.
Measurability (and integrability) issues are a little trickier in the inÔ¨Ånite dimen-
sional valued case than in the Ô¨Ånite dimensional valued case. There are different
types of measurability and integrals when V is a Banach space or a more general
topological vector space. We stick to the simplest notions. Besides we will not use
V -valued integrals here. We equip [0, T ] with the Lebesgue œÉ-algebra.
DeÔ¨Ånition 7.1 A function f : [0, T ] ‚ÜíV is called a simple function if there exists
a Ô¨Ånite measurable partition of [0, T ], (Ei)i=1,...,k, and a Ô¨Ånite set of vectors vi ‚ààV
such that
4Beware of the slightly ambiguous notation.

7.4 Spaces of Hilbert Space-Valued Functions
231
f (t) =
k

i=1
1Ei(t)vi,
for all t ‚àà[0, T ].
In other words, f only takes a Ô¨Ånite number of values in V and is equal to vi
exactly on the Lebesgue measurable set Ei. It should be noted that for each t, there
is one and only one nonzero term 1Ei(t) in the sum, due to the fact that the sets Ei
form a partition of [0, T ].
DeÔ¨Ånition 7.2 A function f : [0, T ] ‚ÜíV is said to be measurable if there exists
a negligible set N ‚äÇ[0, T ] and a sequence of simple functions fn such that
‚à•fn(t) ‚àíf (t)‚à•V ‚Üí0 when n ‚Üí+‚àûfor all t /‚ààN.
We also say that f is an almost everywhere limit of simple functions. When
V = R, this notion of measurability coincides with the usual one. It is easy to see
that a continuous function is measurable.
Proposition 7.5 Let f : [0, T ] ‚ÜíV be a measurable function. Then the function
NV f : [0, T ] ‚ÜíR+, NV f (t) = ‚à•f (t)‚à•V , is a measurable function in the usual
sense.
Proof Let fn(t) = 	kn
i=1 1En,i(t)vn,i be a sequence of simple functions that converges
a.e. to f . Since the norm of V is continuous from V into R, we have NV fn ‚ÜíNV f
a.e. Now due to the fact that for all t, there is at most one nonzero term in the sum,
we also have ‚à•fn(t)‚à•V = 	kn
i=1 1En,i(t)‚à•vn,i‚à•V , hence NV fn is a real-valued simple
function. Therefore NV f is measurable.
‚ñ°
DeÔ¨Ånition 7.3 We say that two measurable functions f1, f2 : [0, T ] ‚ÜíV are equal
almost everywhere if there exists a negligible set N ‚äÇ[0, T ] such that f1(t) = f2(t)
for all t /‚ààN.
Almost everywhere equality is an equivalence relation and from now on, we will
not distinguish between a function and its equivalence class. The V -valued Lebesgue
spaces are deÔ¨Åned as would be expected [58]
L p(0, T ; V ) =

f : [0, T ] ‚ÜíV, measurable and such that NV f ‚ààL p(0, T )

,
for all p ‚àà[1, +‚àû]. When equipped with the norms
‚à•f ‚à•L p(0,T ;V ) = ‚à•NV f ‚à•L p(0,T ),
these spaces are Banach spaces. For p = 2, L2(0, T ; V ) is a Hilbert space for the
scalar product
( f |g)L2(0,T ;V ) =
 T
0

f (t)|g(t)

V dt.

232
7
The Heat Equation
The Hilbert norm reads explicitly
‚à•f ‚à•L2(0,T ;V ) =
 T
0
‚à•f (t)‚à•2
V dt
1/2
.
Obviously,
C0([0, T ]; V ) 
‚ÜíL p(0, T ; V ),
for all p ‚àà[1, +‚àû].
It is also possible to deÔ¨Åne V -valued Sobolev spaces and V -valued distributions,
but we will not use these spaces here.
In the case when V is itself a function space on an open set Œ© of Rd, there is a
natural connection between V -valued functions on [0, T ] and real valued functions
on ¬ØQ = ¬ØŒ© √ó [0, T ] in d + 1 variables. Let us give an example of this.
Proposition 7.6 The spaces L2(0, T ; L2(Œ©)) and L2(Q) are canonically isometric.
Proof We leave aside the measurability questions, which are delicate. First of all,
let us take f ‚ààL2(Q). We thus have

Q f (x, t)2 dxdt < +‚àû. By Fubini‚Äôs theorem
applied to f 2, we thus have that

Œ©
f (x, t)2 dx < +‚àûfor almost all t ‚àà[0, T ]
and

Q
f (x, t)2 dxdt =
 T
0

Œ©
f (x, t)2 dx

dt.
Therefore, if we set 
f (t) = f (¬∑, t), then we see that 
f (t) ‚ààL2(Œ©) for almost all t.
Thus we can let 
f (t) = 0 for those t for which the initial 
f is not in L2(Œ©) and 
f
is then an L2(Œ©)-valued function. Moreover, the second relation then reads
‚à•f ‚à•2
L2(Œ©) = ‚à•
f ‚à•2
L2(0,T ;L2(Œ©)),
hence the isometry.
Conversely, taking 
f ‚ààL2(0, T ; L2(Œ©)), then for almost all t, 
f (t) is a function
in the variable x ‚ààŒ© that belongs to L2(Œ©). If we thus set f (x, t) = 
f (t)(x), we
deÔ¨Åne a function on Q which is such that
 T
0

Œ© f (x, t)2 dx

dt < +‚àû. By Fubini‚Äôs
theorem again, it follows that f ‚ààL2(Q) and we have the isometry.
‚ñ°
Itisthuspossibletoswitchbetweenthetwopointsofview:functioninonevariable
with values in a function space on a d dimensional domain and real valued function
in d + 1 variables. If 
f ‚ààC1([0, T ]; L2(Œ©)), then the associated f is in L2(Q)
and it can be shown that its distributional derivative ‚àÇf
‚àÇt is in C0([0, T ]; L2(Œ©)) and

‚àÇf
‚àÇt = ( 
f )‚Ä≤. From now on, we will drop the tilde notation for simplicity.

7.4 Spaces of Hilbert Space-Valued Functions
233
We will also encounter such situations as f ‚ààC0([0, T ]; H) ‚à©L2(0, T ; V ) with
two (or more) different spaces V ‚äÇH, meaning that f (t) is unambiguously deÔ¨Åned
as an element of H for all t, and continuous with values in H, and the same f (t) is
in V for almost all t and square integrable with values in V . It is allowed to exit V
on a negligible subset of [0, T ].
Let us now be given two Hilbert spaces V1 and V2 and A a continuous linear
operator from V1 to V2. Let ‚à•A‚à•denote its operator norm. Given any V1-valued
function f , we can deÔ¨Åne a V2-valued function Af by (Af )(t) = A( f (t)). This
deÔ¨Ånition commutes with all previous notions.
Proposition 7.7 If f ‚ààCk([0, T ]; V1) then Af ‚ààCk([0, T ]; V2) with (Af )( j) =
A( f ( j)) for j ‚â§k, and if f ‚ààL2(0, T ; V1) then Af ‚ààL2(0, T ; V2).
Proof We start with the continuity. We have
‚à•Af (t+h)‚àíAf (t)‚à•V2 = ‚à•A( f (t+h)‚àíf (t))‚à•V2 ‚â§‚à•A‚à•‚à•f (t+h)‚àíf (t)‚à•V1 ‚àí‚Üí
h‚Üí0 0.
Therefore Af ‚ààC0([0, T ]; V2). Moreover, we have ‚à•Af (t)‚à•V2 ‚â§‚à•A‚à•‚à•f (t)‚à•V1 so
that taking the maximum for t ‚àà[0, T ] on both sides, we obtain
‚à•Af ‚à•C0([0,T ];V2) ‚â§‚à•A‚à•‚à•f ‚à•C0([0,T ];V1).
Similarly
 Af (t + h) ‚àíAf (t)
h
‚àíAf ‚Ä≤(t)

V2 ‚â§‚à•A‚à•
 f (t + h) ‚àíf (t)
h
‚àíf ‚Ä≤(t)

V1 ‚àí‚Üí
h‚Üí0 0
and so on for the successive derivatives and their norms. Finally,
 T
0
‚à•Af (t)‚à•2
V2 dt ‚â§‚à•A‚à•2
 T
0
‚à•f (t)‚à•2
V1 dt < +‚àû,
leaving aside measurability issues, which are not difÔ¨Åcult here. Of course, the above
inequality is nothing but
‚à•Af ‚à•L2(0,T ;V2) ‚â§‚à•A‚à•‚à•f ‚à•L2(0,T ;V1),
as with the Ck spaces.
‚ñ°
To get an idea of how this can be used, just take V1 = H 2(Œ©), V2 = L2(Œ©) and
A = ‚àíŒî.
Later on, we will also use Hilbert bases of V , i.e., total orthonormal families in V
(recall that a total family is a family that spans a dense vector subspace). Such bases
are countable since we only consider separable Hilbert spaces.
Proposition 7.8 Let (en)n‚ààN be a Hilbert basis of V . Let f be a V -valued function
and for all n ‚ààN, fn(t) = ( f (t)|en)V .

234
7
The Heat Equation
(i) If f ‚ààCk([0, T ]; V ) then fn ‚ààCk([0, T ]) for all n and f l
n(t) = ( f (l)(t)|en)V
for all l ‚â§k.
(ii) If f ‚ààL2(0, T ; V ) then fn ‚ààL2(0, T ) for all n.
Proof Let f ‚ààC0([0, T ]; V ) and take a sequence tp ‚Üít in [0, T ]. Then f (tp) ‚Üí
f (t) in V and taking the scalar product with en, which is continuous, we see that
( f (tp)|en)V ‚Üí( f (t)|en)V in R. Hence, fn is continuous.
Assume now that f is C1. It similarly follows from the fact that f (tp)‚àíf (t)
tp‚àít
‚Üíf ‚Ä≤(t)
in V , that ( f (tp)|en)V ‚àí( f (t)|en)V
tp‚àít
‚Üí( f ‚Ä≤(t)|en)V by linearity and continuity of the scalar
product. Therefore, fn has a derivative at t for all n and ( fn)‚Ä≤ = ( f ‚Ä≤)n, so that ( fn)‚Ä≤
is continuous by the previous case and thus fn ‚ààC1([0, T ]). The general case of k
derivatives follows by induction on k.
Let now f ‚ààL2(0, T ; V ). Since ‚à•f (t)‚à•2
V = 	
n | fn(t)|2 by Parseval‚Äôs identity,
see [68], we see that
‚à•f ‚à•2
L2(0,T ;V ) =
 T
0
‚à•f (t)‚à•2
V dt =

n
 T
0
| fn(t)|2 dt.
In particular,
 T
0 | fn(t)|2 dt < +‚àûfor all n, or in other words, fn ‚ààL2(0, T ).
‚ñ°
7.5
Energy Estimates, Stability, Uniqueness
In this section, we consider solutions of problem (7.1) with data that is considerably
less smooth than in the previous sections. We assume that the solutions considered
are regular enough so that all computations are justiÔ¨Åed. As the proof in arbitrary
dimension of space d works the same as in one dimension, we will let Œ© ‚äÇRd
bounded and Q = Œ© √ó ]0, T [.
We start with a lemma.
Lemma 7.1 Let u ‚ààC1([0, T ]; L2(Œ©)). Then the function t ‚Üí1
2

Œ©(u(t)(x))2 dx
is of class C1([0, T ]) and its derivative is given by t ‚Üí

Œ©[u(t)u‚Ä≤(t)](x) dx.
Proof Let E(t) = 1
2

Œ© u(x, t)2 dx. We write
E(t + h) ‚àíE(t)
h
= 1
2

Œ©

u(x, t + h) + u(x, t)
u(x, t + h) ‚àíu(x, t)
h

dx.
Now, by L2-valued continuity, u(t+h) ‚Üíu(t) in L2(Œ©) when h ‚Üí0. By L2-valued
differentiability, u(t+h)‚àíu(t)
h
‚Üíu‚Ä≤(t) in L2(Œ©) when h ‚Üí0. Therefore,
E(t + h) ‚àíE(t)
h
‚Üí

Œ©
[u(t)u‚Ä≤(t)](x) dx

7.5 Energy Estimates, Stability, Uniqueness
235
when h ‚Üí0 by the Cauchy‚ÄìSchwarz inequality. By the same inequality, the right-
hand side is a continuous function of t.
‚ñ°
Remark 7.5 Thisresultcanbeconstruedasakindofdifferentiationundertheintegral
sign, since
d
dt

Œ©
u(x, t)2 dx

= 2

Œ©
‚àÇu
‚àÇt (x, t)u(x, t) dx =

Œ©
‚àÇ(u2)
‚àÇt
(x, t) dx,
with the identiÔ¨Åcation ‚àÇu
‚àÇt = u‚Ä≤. It can be generalized with weaker assumptions on u,
namely u ‚ààL2(0, T ; H 1
0 (Œ©)), with u‚Ä≤ ‚ààL2(0, T ; H ‚àí1(Œ©)), see [35].
‚ñ°
Proposition 7.9 Assume that g = 0 (homogeneous Dirichlet condition), u0 ‚àà
L2(Œ©) and f ‚ààL2(Q). Then, if u ‚ààC1([0, T ]; L2(Œ©)) ‚à©L2(0, T ; H 1
0 (Œ©)) is
a solution of the problem, then
‚à•u‚à•C0([0,T ];L2(Œ©)) ‚â§‚à•u0‚à•L2(Œ©) + C‚à•f ‚à•L2(Q),
(7.2)
where C is the Poincar√© inequality constant.
Proof Since u ‚ààC1([0, T ]; L2(Œ©)) ‚à©L2(0, T ; H 1
0 (Œ©)), we have that u(¬∑, t) and
‚àÇu
‚àÇt (¬∑, t) belong to L2(Œ©) for all t and that u(¬∑, t) belongs to H 1
0 (Œ©) for almost
all t. The meaning of the partial differential equation in this context is thus that
u‚Ä≤ ‚àíŒîu = f where u‚Ä≤ ‚ààC0([0, T ]; L2(Œ©)), f ‚ààL2(0, T ; L2(Œ©)) and Œîu ‚àà
L2(0, T ; H ‚àí1(Œ©)), see Corollary3.4 of Chap.3, so that the equation is well deÔ¨Åned
in this sense. Of course, it also coincides with the distributional equation on Q.
For almost all s ‚àà[0, T ], both sides of the equation are in H ‚àí1(Œ©). We thus take
the duality bracket with u and obtain
1
2
d
ds

Œ©
u(x, s)2 dx

+

Œ©
‚à•‚àáu(x, s)‚à•2 dx =

Œ©
f (x, s)u(x, s) dx
‚â§

Œ©
f (x, s)2 dx
 1
2 
Œ©
u(x, s)2 dx
 1
2
by Lemma7.1 and by the Cauchy‚ÄìSchwarz inequality. Because of the homogeneous
Dirichlet condition, we have Poincar√©‚Äôs inequality

Œ©
u(x, s)2 dx
 1
2 ‚â§C

Œ©
‚à•‚àáu(x, s)‚à•2 dx
 1
2 ,
and using Young‚Äôs inequality ab ‚â§1
2a2 + 1
2b2, we obtain
1
2
d
ds

Œ©
u(x, s)2 dx

+

Œ©
‚à•‚àáu(x, s)‚à•2 dx
‚â§C2
2

Œ©
f (x, s)2 dx + 1
2

Œ©
‚à•‚àáu(x, s)‚à•2 dx,

236
7
The Heat Equation
so that
1
2
d
ds

Œ©
u(x, s)2 dx

‚â§1
2
d
ds

Œ©
u(x, s)2 dx

+ 1
2

Œ©
‚à•‚àáu(x, s)‚à•2 dx
‚â§C2
2

Œ©
f (x, s)2 dx.
We integrate the above inequality between 0 and t with respect to s and obtain

Œ©
u(x, t)2 dx‚àí

Œ©
u(x, 0)2 dx ‚â§C2
 t
0

Œ©
f (x, s)2 dx ds ‚â§C2
 T
0

Œ©
f (x, s)2 dx ds,
for all t ‚àà[0, T ] due to Lemma7.1, and since u(x, 0) = u0(x), it follows that
‚à•u(¬∑, t)‚à•L2(Œ©) ‚â§

‚à•u0‚à•2
L2(Œ©) + C2‚à•f ‚à•2
L2(Q)
1/2
hence the result, since
‚àö
a2 + b2 ‚â§a + b for all a, b positive.
‚ñ°
Remark 7.6 The quantity E(t) = 1
2

Œ© u(x, t)2 dx is called the energy (up to phys-
ical constants), hence the term ‚Äúenergy estimate‚Äù. It follows from the proof that the
energy is decreasing when f = 0. In addition, it is quite clear also from the proof
that if f ‚ààL2(Œ© √ó R+), then the energy estimate remains valid for all times, i.e.,
sup
t‚ààR+
‚à•u(¬∑, t)‚à•L2(Œ©) ‚â§‚à•u0‚à•L2(Œ©) + C‚à•f ‚à•L2(Œ©√óR+),
provided such a solution exists.
Let us note that the energy estimate can be proved under lower regularity hypothe-
ses, namely that u ‚ààC0([0, T ]; L2(Œ©)) ‚à©L2(0, T ; H 1
0 (Œ©)). The Ô¨Årst space in the
intersection gives a precise meaning to the initial condition in L2.
‚ñ°
As in the case of the maximum principle, the energy estimate has consequences
in terms of uniqueness and stability.
Corollary 7.3 There is at most one solution u belonging to C1([0, T ]; L2(Œ©)) ‚à©
L2(0, T ; H 1(Œ©)) to the heat equation with initial data u0 ‚ààL2(Œ©), right-hand side
f ‚ààL2(Q) and Dirichlet boundary condition g ‚ààL2(0, T ; H 1/2(‚àÇŒ©)).
Proof Let u1 and u2 be two such solutions. Then, their difference u1 ‚àíu2 belongs
to C1([0, T ]; L2(Œ©)) ‚à©L2(0, T ; H 1
0 (Œ©)) and is a solution of the heat equation with
zero right-hand side and initial condition. By estimate (7.2), it follows that we have
u1 ‚àíu2 = 0.
‚ñ°
Again this also holds in C0([0, T ]; L2(Œ©)) ‚à©L2(0, T ; H 1(Œ©)). Stability or con-
tinuous dependence on the data is straightforward. We just consider here the homo-
geneous Dirichlet condition g = 0.

7.5 Energy Estimates, Stability, Uniqueness
237
Corollary 7.4 Let ui ‚ààC1([0, T ]; L2(Œ©)) ‚à©L2(0, T ; H 1
0 (Œ©)), i = 1, 2, be
solutions corresponding to initial conditions u0,i ‚ààL2(Œ©) and right-hand sides
fi ‚ààL2(Q). Then
‚à•u1 ‚àíu2‚à•C0([0,T ];L2(Œ©)) ‚â§‚à•u0,1 ‚àíu0,2‚à•L2(Œ©) + C‚à•f1 ‚àíf2‚à•L2(Q).
Proof Clear.
‚ñ°
When in addition there is no heat source, i.e., f = 0, we can expect some kind
of exponential decay as in the regular case. Here, the energy is the relevant quantity.
Proposition 7.10 If f = 0, then we have
E(t) ‚â§e‚àí2t
C2 E(0) = e‚àí2t
C2
2
‚à•u0‚à•2
L2(Œ©),
where C is the Poincar√© inequality constant.
Proof As before, we have
d
dt
1
2

Œ©
u(x, t)2 dx

+

Œ©
‚à•‚àáu(x, t)‚à•2 dx = 0.
Thus
dE
dt (t) = ‚àí

Œ©
‚à•‚àáu(x, t)‚à•2 dx ‚â§‚àí1
C2

Œ©
u(x, t)2 dx = ‚àí2
C2 E(t),
byPoincar√©‚Äôsinequality.Solvingthisdifferentialinequality,weobtaintheannounced
result.
‚ñ°
Remark 7.7 A function in L2 is not bounded in general, thus we cannot expect
uniform decay of the temperature as in the regular case. However, it can be shown
that u is of class C‚àûas soon as t > 0, which is the same smoothing effect as before.
Thus, there is also a uniform exponential decay but starting away from t = 0. In
fact, it can be shown that u is C‚àûon any open subset where f is C‚àû, in particular
when it is equal to 0. This property of the heat operator is called hypoellipticity,
see [20].
‚ñ°
7.6
Variational Formulation and Existence of Weak
Solutions
So far, we still have no existence result for the initial-boundary value problem when
f Ã∏= 0 or f = 0 and u0 ‚ààL2(Œ©). For this, we need to recast the problem in

238
7
The Heat Equation
variational form. We only consider the homogeneous Dirichlet boundary condition,
since a non homogeneous Dirichlet condition can be transformed into a homogeneous
one via an appropriate lift of the boundary data. We start with regularity hypotheses
that are a little too strong, but not by much. As in the elliptic case, we deÔ¨Åne the
bilinear form a by a(u, v) =

Œ© ‚àáu ¬∑ ‚àáv dx.
Proposition 7.11 Let u0 ‚ààL2(Œ©), f ‚ààL2(Q). Consider u in C1([0, T ]; L2(Œ©))‚à©
L2(0, T ; H 1
0 (Œ©)) such that u‚Ä≤ ‚àíŒîu = f for almost all t and u(0) = u0. Then we
have, for all v ‚ààH 1
0 (Œ©),
d
dt

(u(t)|v)L2(Œ©)

+ a(u(t), v) = ( f (t)|v)L2(Œ©)
almost everywhere in [0, T ], and
(u(0)|v)L2(Œ©) = (u0|v)L2(Œ©).
Conversely, a solution in C1([0, T ]; L2(Œ©)) ‚à©L2(0, T ; H 1
0 (Œ©)) of the above two
variational equations is a solution of the initial-boundary value problem for the
heat equation with homogeneous Dirichlet boundary condition, initial data u0 and
right-hand side f .
Proof We have already seen that each term in the equation u‚Ä≤ ‚àíŒîu = f is at worst5
in L2(0, T ; H ‚àí1(Œ©)). It is therefore meaningful to take the duality bracket of each
one of them with an arbitrary v ‚ààH 1
0 (Œ©), so that we have
‚ü®u‚Ä≤(t), v‚ü©H ‚àí1(Œ©),H 1
0 (Œ©) ‚àí‚ü®Œîu(t), v‚ü©H ‚àí1(Œ©),H 1
0 (Œ©) = ‚ü®f (t), v‚ü©H ‚àí1(Œ©),H 1
0 (Œ©),
for almost all t.
Arguing as in the proof of Lemma7.1, we see that the real-valued function t ‚Üí
(u(t)|v)L2(Œ©) is of class C1 and that
d
dt

(u(t)|v)L2(Œ©)

=

Œ©
u‚Ä≤(t)(x)v(x) dx = ‚ü®u‚Ä≤(t), v‚ü©H ‚àí1(Œ©),H 1
0 (Œ©),
since u‚Ä≤(t) ‚ààL2(Œ©). Similarly,
‚ü®f (t), v‚ü©H ‚àí1(Œ©),H 1
0 (Œ©) =

Œ©
f (x, t)v(x) dx.
Finally, by Corollary3.4 of Chap.3, we have
‚àí‚ü®Œîu(t), v‚ü©H ‚àí1(Œ©),H 1
0 (Œ©) = a(u(t), v),
so that the Ô¨Årst equation is established. The second equation is trivial.
5In the sense of space regularity.

7.6 Variational Formulation and Existence of Weak Solutions
239
Conversely, let us be given a solution u of the variational problem. Since H 1
0 (Œ©)
is dense in L2(Œ©), the second equation implies that u(0) = u0. Moreover, the above
calculations can be carried out backwards, so that
‚ü®u‚Ä≤(t) ‚àíŒîu(t) ‚àíf (t), v‚ü©H ‚àí1(Œ©),H 1
0 (Œ©) = 0,
for almost all t and all v ‚ààH 1
0 (Œ©). Consequently, for almost all t, u‚Ä≤(t) ‚àíŒîu(t) ‚àí
f (t) = 0 as an element of H ‚àí1(Œ©), hence the heat equation with right-hand side f
is satisÔ¨Åed in this sense.
‚ñ°
As we said above, the regularity in time assumed above is a bit too high. Indeed,
the variational formulation makes sense in a slightly less regular context. This leads
to the following deÔ¨Ånition.
DeÔ¨Ånition 7.4 The variational formulation of the heat equation with homogeneous
Dirichlet boundary condition, initial data u0 ‚ààL2(Œ©) and right-hand side f ‚àà
L2(Q) consists in looking for u ‚ààC0([0, T ]; L2(Œ©)) ‚à©L2(0, T ; H 1
0 (Œ©)) such that,
for all v ‚ààH 1
0 (Œ©),
 
(u|v)L2(Œ©)
‚Ä≤ + a(u, v) = ( f |v)L2(Œ©) in the sense of D‚Ä≤(]0, T [),
(u(0)|v)L2(Œ©) = (u0|v)L2(Œ©).
(7.3)
Remark 7.8 Let us check that this deÔ¨Ånition makes sense. First of all, since
u ‚ààC0([0, T ]; L2(Œ©)) and v does not depend on t, we see that the function
t ‚Üí(u|v)L2(Œ©) is continuous on [0, T ], hence its derivative is a distribution on ]0, T [.
Likewise, since u ‚ààL2(0, T ; H 1
0 (Œ©)), the function t ‚Üía(u, v) is in L1(0, T ) by
the Cauchy‚ÄìSchwarz inequality, hence a distribution on ]0, T [ and the same holds
for t ‚Üí( f |v)L2(Œ©). Therefore, the Ô¨Årst equation in (7.3) is well deÔ¨Åned in the
distributional sense.
We have already seen that the second equation is equivalent to u(0) = u0, and the
continuity of u with respect to t with values in L2(Œ©) makes this initial condition
relevant.
‚ñ°
We use the variational formulation to prove existence and uniqueness of solutions.
We will write the proof in the 1d case, Œ© = ]0, 1[. The general case is entirely similar.
For all k ‚ààN‚àó, we let œÜk(x) =
‚àö
2 sin(kœÄx) and Œªk = k2œÄ2. It is well-known that
the family (œÜk)k‚ààN‚àóis a Hilbert basis of L2(0, 1) as well as a total orthogonal family
in H 1
0 (]0, 1[) [15, 51]. Moreover, for all w ‚ààH 1
0 (Œ©), we have
a(w, œÜk) =
 1
0
dw
dx
dœÜk
dx dx = ‚àí
 1
0
wd2œÜk
dx2 dx = Œªk(w|œÜk)L2(Œ©).
(7.4)

240
7
The Heat Equation
Theorem 7.2 Let u0 ‚ààL2(Œ©), f ‚ààL2(Q). There exists a unique solution u ‚àà
C0([0, T ]; L2(Œ©)) ‚à©L2(0, T ; H 1
0 (Œ©)) of problem (7.3), which is given by
u(t) =
+‚àû

k=1
uk(t)œÜk,
(7.5)
where
uk(t) = (u0|œÜk)L2(Œ©)e‚àíŒªkt +
 t
0
( f (s)|œÜk)L2(Œ©)e‚àíŒªk(t‚àís) ds
(7.6)
and the series converges in C0([0, T ]; L2(Œ©)) ‚à©L2(0, T ; H 1
0 (Œ©)).
Proof We start with the uniqueness. Let u ‚ààC0([0, T ]; L2(Œ©))‚à©L2(0, T ; H 1
0 (Œ©))
be a solution of (7.3). For all t ‚àà[0, T ], u(t) is thus an element of L2(Œ©) and can
therefore be expanded on the Hilbert basis (œÜk)k‚ààN‚àó. Consequently, we have for all t
u(t) =
+‚àû

k=1
uk(t)œÜk
with
uk(t) = (u(t)|œÜk)L2(Œ©)
for all k ‚ààN‚àóand the series converges in L2(Œ©). Now œÜk ‚ààH 1
0 (Œ©) is a legitimate
test-function in problem (7.3). In particular, since u(t) ‚ààH 1
0 (Œ©) almost everywhere,
we have
a(u(t), œÜk) = Œªkuk(t)
almost everywhere by (7.4), hence everywhere since the right-hand side is continuous
(the left-hand side is L1). We thus have by Proposition7.8,

u‚Ä≤
k(t) + Œªkuk(t) = ( f (t)|œÜk)L2(Œ©) in the sense of D‚Ä≤(]0, T [),
uk(0) = (u0|œÜk)L2(Œ©),
for each k ‚ààN‚àó. Now this is a Cauchy problem for a linear ordinary differential equa-
tion, and there are no other distributional solutions than the usual solution obtained
by variation of the constant, or Duhamel‚Äôs formula:
uk(t) = (u0|œÜk)L2(Œ©)e‚àíŒªkt +
 t
0
( f (s)|œÜk)L2(Œ©)e‚àíŒªk(t‚àís) ds,
which is exactly formula (7.6).6 Hence the uniqueness.
6Observe that the function uk is continuous in t.

7.6 Variational Formulation and Existence of Weak Solutions
241
We now use the above series to prove existence. Since u0 ‚ààL2(Œ©), we have
‚à•u0‚à•2
L2(Œ©) =
+‚àû

k=1
(u0|œÜk)2
L2(Œ©)
by Parseval‚Äôs identity. Similarly, f ‚ààL2(Q) and
‚à•f ‚à•2
L2(Q) =
 T
0
+‚àû

k=1
( f (t)|œÜk)2
L2(Œ©) dt.
Let us set u0,k = (u0|œÜk)L2(Œ©) and fk(t) = ( f (t)|œÜk)L2(Œ©). We are going to show
that the series in formula (7.5) converges in both spaces C0(0, T ; L2(Œ©)) and
L2(0, T ; H 1
0 (Œ©)) and that its sum u is a solution of the variational problem. To do
this, we will show that the partial sums Un(t) = 	n
k=1 uk(t)œÜk are Cauchy sequences
for both norms. Let p < q be two given integers and let us estimate Up ‚àíUq.
First of all, due to the continuity of t ‚Üíuk(t), the partial sums Un are continuous
with values in L2(Œ©). Moreover, for all t ‚àà[0, T ], we have
‚à•Up(t) ‚àíUq(t)‚à•2
L2(Œ©) =

q

k=p+1
uk(t)œÜk

2
L2(Œ©)
=
q

k=p+1
uk(t)2
‚â§2
q

k=p+1

u2
0,k +
 t
0
| fk(s)| ds
2
‚â§2
q

k=p+1

u2
0,k + t
 t
0
fk(s)2 ds

‚â§2
q

k=p+1
u2
0,k + 2T
q

k=p+1
 T
0
fk(s)2 ds
since all the exponential terms are less than 1 and by the Cauchy‚ÄìSchwarz inequality.
Therefore
‚à•Up ‚àíUq‚à•2
C0([0,T ];L2(Œ©)) = max
t‚àà[0,T ] ‚à•Up(t) ‚àíUq(t)‚à•2
L2(Œ©)
‚â§2
q

k=p+1
u2
0,k + 2T
q

k=p+1
 T
0
fk(s)2 ds
can be made as small as we wish by taking p large enough, due to the hypotheses
on u0 and f , and the sequence is consequently Cauchy in C0(0, T ; L2(Œ©)).

242
7
The Heat Equation
Similarly, the partial sums are obviously in L2(0, T ; H 1
0 (Œ©)), in fact they even
are continuous with values in H 1
0 (Œ©), although this continuity will not persist in
the limit. We use the H 1
0 seminorm, so that |v|2
H 1
0 (Œ©) = a(v, v) (for a more general
parabolic equation, H 1
0 -ellipticity of the bilinear form would here come into play7).
The family (œÜk)k‚ààN‚àóis also orthogonal in H 1
0 (Œ©) and we have a(œÜk, œÜk) = Œªk by
(7.4). Therefore, for all v ‚ààH 1
0 (Œ©), it follows that
|v|2
H 1
0 (Œ©) =
+‚àû

k=1
Œªkv2
k,
(7.7)
where vk = (v|œÜk)L2(Œ©). In particular, we have
|Up(t) ‚àíUq(t)|2
H 1
0 (Œ©) =
q

k=p+1
Œªkuk(t)2,
so that integrating between 0 and T , we obtain
‚à•Up ‚àíUq‚à•2
L2(0,T ;H 1
0 (Œ©)) =
q

k=p+1
 T
0
Œªkuk(t)2 dt.
Let us estimate each term in the sum on the right. We have
Œªkuk(t)2 ‚â§2Œªk

u2
0,ke‚àí2Œªkt + T
 t
0
fk(s)2e‚àí2Œªk(t‚àís) ds

,
so that
 T
0
Œªkuk(t)2 dt ‚â§2Œªk

u2
0,k
 T
0
e‚àí2Œªkt dt + T
 T
0
 t
0
fk(s)2e‚àí2Œªk(t‚àís) ds

dt

= (1 ‚àíe‚àí2ŒªkT )u2
0,k + 2ŒªkT
 T
0
fk(s)2 T
s
e‚àí2Œªk(t‚àís) dt

ds
= (1 ‚àíe‚àí2ŒªkT )u2
0,k + T
 T
0
(1 ‚àíe‚àí2Œªk(T ‚àís)) fk(s)2 ds
‚â§u2
0,k + T
 T
0
fk(s)2 ds.
7Or even more generally, G√•rding‚Äôs inequality, which reads: for all v ‚ààH1
0 (Œ©), a(v, v) ‚â•
Œ±|v|2
H1
0 (Œ©) ‚àíŒ≤‚à•v‚à•2
L2(Œ©) with Œ± > 0.

7.6 Variational Formulation and Existence of Weak Solutions
243
Therefore
‚à•Up ‚àíUq‚à•2
L2(0,T ;H 1
0 (Œ©)) ‚â§
q

k=p+1
u2
0,k + T
q

k=p+1
 T
0
fk(s)2 ds,
which can again be made as small as we wish by taking p large enough, and the
sequence is Cauchy in L2(0, T ; H 1
0 (Œ©)).
Finally, it remains to be seen that the function u deÔ¨Åned by the series and which
belongs to C0(0, T ; L2(Œ©))‚à©L2(0, T ; H 1
0 (Œ©)) is a solution of the variational prob-
lem (7.3). The initial condition is obvious even in non variational form since
u(0) =
+‚àû

k=1

u0,ke0 +
 0
0
fk(s)eŒªks ds

œÜk =
+‚àû

k=1
u0,kœÜk = u0.
Regarding the evolution equation, we obtain from the ordinary differential equations
for uk that for all v ‚ààspan((œÜk)k‚ààN‚àó)

(u|v)L2(Œ©)
‚Ä≤ + a(u, v) = ( f (t)|v)L2(Œ©) in the sense of D‚Ä≤(]0, T [),
since any such v is a linear combination of the œÜk.
Let now v ‚ààH 1
0 (Œ©) be arbitrary and vn ‚ààspan((œÜk)k‚ààN‚àó) be such that vn ‚Üív in
H 1
0 (Œ©). For any œï ‚ààD(]0, T [), we thus have
‚àí
 T
0
(u(t)|vn)L2(Œ©)œï‚Ä≤(t) dt +
 T
0
a(u(t), vn)œï(t) dt =
 T
0
( f (t)|vn)L2(Œ©)œï(t) dt.
It is then fairly obvious that each term in the above relation passes to the limit as
n ‚Üí+‚àû, thus establishing the evolution equation.
‚ñ°
Remark 7.9 Note that we do not need any compatibility condition between the initial
condition u0 and the Dirichlet boundary condition, as opposed to the regular case.
Indeed, the expansion u0 = 	+‚àû
k=1 u0,kœÜk only holds in the L2 sense.
‚ñ°
Remark 7.10 Formula (7.5)‚Äì(7.6) clearly generalizes the expansion obtained in
Theorem7.1.
‚ñ°
Remark 7.11 The recovery of a bona-Ô¨Åde solution of the heat equation from the
above variational solution would require the use of Hilbert space valued distributions
and integrals. Let us just say that it can be done. There are other approaches to the
heat equation, for instance using semigroups (see for example [28, 58]).
‚ñ°
Remark 7.12 The d-dimensional heat equation can be solved along the exact same
lines, replacing the functions œÜk and scalars Œªk by the eigenfunctions and eigenvalues
of the minus Laplacian in H 1
0 (Œ©), i.e., the solutions of ‚àíŒîœÜk = ŒªkœÜk, œÜk ‚ààH 1
0 (Œ©),
œÜk Ã∏= 0, see [5, 26, 28]. This eigenvalue problem for Œ© bounded only has solutions

244
7
The Heat Equation
for Œªk in a sequence 0 < Œª1 < Œª2 ‚â§Œª3 ‚â§¬∑ ¬∑ ¬∑ such that Œªk ‚Üí+‚àûwhen k ‚Üí+‚àû.
Of course, the eigenvalues and eigenfunctions depend on the shape of Œ©, see Chap.1,
Sect.1.6.
‚ñ°
We also have an energy decay and stability estimate in the present context.
Proposition 7.12 The solution u of problem (7.3) satisÔ¨Åes
‚à•u(t)‚à•L2(Œ©) ‚â§‚à•u0‚à•L2(Œ©)e‚àíŒª1t +
 t
0
‚à•f (s)‚à•L2(Œ©)e‚àíŒª1(t‚àís) ds,
(7.8)
for all t ‚àà[0, T ].
Proof This is a consequence of the series expansion. We Ô¨Årst observe the following
fact. Let g be a L1-function from [0, T ] to a Euclidean space E (i.e., a Ô¨Ånite dimen-
sional Hilbert space). Then the integral
 t
0 g(s) ds is well deÔ¨Åned as a vector of E
by choosing a basis of E and integrating g componentwise. Moreover, since E is
Euclidean, there exists a unit vector e such that

 t
0
g(s) ds

E =
 t
0
g(s) ds

¬∑ e =
 t
0
g(s) ¬∑ e ds ‚â§
 t
0
‚à•g(s)‚à•E ds,
by the Cauchy‚ÄìSchwarz inequality in E.
We now turn to estimate (7.8). We have
u(t) =
+‚àû

k=1

u0,ke‚àíŒªkt +
 t
0
fk(s)e‚àíŒªk(t‚àís) ds

œÜk
so that by the triangle inequality
‚à•u(t)‚à•L2(Œ©) ‚â§

+‚àû

k=1
u0,ke‚àíŒªktœÜk

L2(Œ©) +

+‚àû

k=1
 t
0
fk(s)e‚àíŒªk(t‚àís) ds

œÜk

L2(Œ©).
For the Ô¨Årst term, we note that

+‚àû

k=1
u0,ke‚àíŒªktœÜk

L2(Œ©) =
+‚àû

k=1
u2
0,ke‚àí2Œªkt 1
2 ‚â§
+‚àû

k=1
u2
0,ke‚àí2Œª1t 1
2 = ‚à•u0‚à•L2(Œ©)e‚àíŒª1t,
since the sequence of eigenvalues Œªk is increasing. For the second term, we resort to
the observation above with E = span(œÜ1, . . . , œÜn) equipped with the L2-norm, and
deduce that

7.6 Variational Formulation and Existence of Weak Solutions
245

n

k=1
 t
0
fk(s)e‚àíŒªk(t‚àís) ds

œÜk

L2(Œ©) =

 t
0
 n

k=1
fk(s)e‚àíŒªk(t‚àís)œÜk

ds

L2(Œ©)
‚â§
 t
0

n

k=1
fk(s)e‚àíŒªk(t‚àís)œÜk

L2(Œ©) ds
=
 t
0
 n

k=1
fk(s)2e‚àí2Œªk(t‚àís) 1
2 ds
‚â§
 t
0
 n

k=1
fk(s)2 1
2 e‚àíŒª1(t‚àís) ds.
We now let n ‚Üí+‚àûand conclude by the convergence of the left-hand side series
in L2(Œ©) and by the Lebesgue monotone convergence theorem for the right-hand
side term.
‚ñ°
Remark 7.13 We recover the exponential decay of the energy when f = 0.
‚ñ°
Remark 7.14 The energy estimates and existence of weak solutions can be gene-
ralized to parabolic problems that are more general than the heat equation,
see [58, 66].
‚ñ°
7.7
The Heat Equation on R
Even though it is unphysical, the heat equation on Rd is nonetheless interesting from
the point of view of mathematics. For simplicity, we will only consider the case
d = 1. Let us thus consider the initial value problem
‚éß
‚é®
‚é©
‚àÇu
‚àÇt (x, t) ‚àí‚àÇ2u
‚àÇx2 (x, t) = f (x, t) in R √ó ]0, T [,
u(x, 0) = u0(x) on R.
(7.9)
Note that there is no boundary data since R has no boundary. They may be replaced
by some kind of asymptotic behavior at inÔ¨Ånity.
Let us now introduce an extremely important function [51, 74].
DeÔ¨Ånition 7.5 The function deÔ¨Åned on R2 by
E(x, t) =
‚éß
‚é®
‚é©
1
‚àö
4œÄt
e‚àíx2
4t for t > 0,
0 for t ‚â§0,
is called the (one-dimensional) heat kernel.

246
7
The Heat Equation
Fig. 7.8 Various views of the graph of the heat kernel
We note that for t > 0 Ô¨Åxed, the function x ‚ÜíE(x, t) is a Gaussian. When
t ‚Üí0+, the Gaussian becomes increasingly spiked. Indeed, we see that E(x, t) =
1
‚àö
4t E
 x
‚àö
4t , 1
4). In particular, E(0, t) ‚Üí+‚àû, whereas E(x, t) ‚Üí0 for all x Ã∏= 0
when t ‚Üí0+, see Figs.7.8 and 7.9.
Proposition 7.13 We have E ‚ààL1
loc(R2), hence E ‚ààD‚Ä≤(R2).
Proof Clearly E ‚ààC‚àû(R2\{(0, 0)}), therefore the only potential local integrability
problem is in a compact neighborhood of (0, 0). It sufÔ¨Åces to integrate |E| on the
square [‚àía, a]2 for some a > 0. Since E vanishes for t ‚â§0, only the upper half
square is left. We have

7.7 The Heat Equation on R
247
0,8
1,6
2,4
3,2
4
4,8
0
0,8
1,6
2,4
3,2
4
-2,4
-1,6
-0,8
0
0,8
1,6
2,4
0,8
1,6
2,4
3,2
4
4,8
Fig. 7.9 The heat kernel at t Ô¨Åxed for different values of t (left) and x Ô¨Åxed for different values of
x (right)
 a
‚àía
 a
0
|E(x, t)| dxdt ‚â§
 +‚àû
‚àí‚àû
 a
0
|E(x, t)| dxdt
=
1
2‚àöœÄ
 +‚àû
‚àí‚àû
 a
0
1
‚àöt e‚àíx2
4t dx

dt
=
1
‚àöœÄ
 +‚àû
‚àí‚àû
 a
0
e‚àíy2 dy

dt = a < +‚àû,
where we have performed the change of variables x = 2‚àöt y and because of the
well-known value of the Gaussian integral,
 +‚àû
‚àí‚àûe‚àíy2 dy = ‚àöœÄ.
‚ñ°
The heat kernel is the fundamental solution or elementary solution of the heat
equation in the following sense.
Proposition 7.14 We have
‚àÇE
‚àÇt ‚àí‚àÇ2E
‚àÇx2 = Œ¥0,
where Œ¥0 is the Dirac distribution at (x, t) = (0, 0).
Proof Given œï ‚ààD(R2), our goal is to show that
‚àÇE
‚àÇt ‚àí‚àÇ2E
‚àÇx2 , œï

= œï(0, 0).
We have already noticed that E is of class C‚àûeverywhere except at (x, t) =
(0, 0). Its distributional derivatives thus coincide with its classical derivatives on

248
7
The Heat Equation
R2\{(0, 0)}. Let us Ô¨Årst compute these derivatives using brute force for t > 0 (only
mild force is needed for t < 0). We thus have
‚àÇE
‚àÇt =
1
2‚àöœÄ

‚àí
1
2t3/2 +
x2
4t5/2

e‚àíx2
4t ,
‚àÇE
‚àÇx = ‚àí
1
4‚àöœÄ
x
t3/2 e‚àíx2
4t ,
‚àÇ2E
‚àÇx2 = ‚àí
1
4‚àöœÄ
 1
t3/2 ‚àí
x2
2t5/2

e‚àíx2
4t ,
so that ‚àÇE
‚àÇt ‚àí‚àÇ2E
‚àÇx2 = 0 on R2\{(0, 0)}. Therefore the support of the distribution
‚àÇE
‚àÇt ‚àí‚àÇ2E
‚àÇx2 is included in {(0, 0)}.
Let us now work in the distributional sense. We take a test-function œï ‚ààD(R2).
We have
‚àÇE
‚àÇt ‚àí‚àÇ2E
‚àÇx2 , œï

= ‚àí

E, ‚àÇœï
‚àÇt + ‚àÇ2œï
‚àÇx2

= ‚àí
 +‚àû
‚àí‚àû
 +‚àû
0
E(x, t)
‚àÇœï
‚àÇt + ‚àÇ2œï
‚àÇx2

(x, t) dt

dx,
since E is L1
loc and vanishes for t ‚â§0. The derivatives ‚àÇœï
‚àÇt and ‚àÇ2œï
‚àÇx2 have compact
support, hence E
 ‚àÇœï
‚àÇt + ‚àÇ2œï
‚àÇx2

is in L1(R2) and the Lebesgue dominated convergence
theorem implies that
‚àÇE
‚àÇt ‚àí‚àÇ2E
‚àÇx2 , œï

= ‚àílim
n‚Üí+‚àû
 +‚àû
‚àí‚àû
 +‚àû
1
n
E(x, t)
‚àÇœï
‚àÇt + ‚àÇ2œï
‚àÇx2

(x, t) dt

dx.
Now on the set R√ó[ 1
n , +‚àû[, all the functions are C‚àûand we can integrate by parts,
so that
‚àÇE
‚àÇt ‚àí‚àÇ2E
‚àÇx2 , œï

=
lim
n‚Üí+‚àû
 +‚àû
‚àí‚àû
 +‚àû
1
n
‚àÇE
‚àÇt ‚àí‚àÇ2E
‚àÇx2

(x, t)œï(x, t) dt

dx
+
 +‚àû
‚àí‚àû
E(x, n‚àí1)œï(x, n‚àí1) dx

.
We have already seen that ‚àÇE
‚àÇt ‚àí‚àÇ2E
‚àÇx2 = 0 on R √ó [ 1
n , +‚àû[ so that the Ô¨Årst integral
vanishes. Let us study the second integral. We perform the change of variables y =
‚àönx
2 . This yields
 +‚àû
‚àí‚àû
E(x, n‚àí1)œï(x, n‚àí1) dx =
1
‚àöœÄ
 +‚àû
‚àí‚àû
e‚àíy2œï(2n‚àí1/2y, n‚àí1) dy ‚Üíœï(0, 0)

7.7 The Heat Equation on R
249
by the dominated convergence theorem. Therefore, we have shown that
‚àÇE
‚àÇt ‚àí‚àÇ2E
‚àÇx2 , œï

= œï(0, 0) = ‚ü®Œ¥0, œï‚ü©,
and the proposition is proved.
‚ñ°
The heat kernel can be used to express the solution in various function spaces.
Let us give an example.
Proposition 7.15 Let u0 ‚ààL1(R) and f ‚ààL1(R √ó R+). Then
u(x, t) =
 +‚àû
‚àí‚àû
E(x ‚àíy, t)u0(y) dy +
 +‚àû
‚àí‚àû
 t
0
E(x ‚àíy, t ‚àís) f (y, s) ds

dy
is a solution of problem (7.9).
Proof We write the proof for u0 and f continuous and bounded, for simplicity. First
of all, all the integrals make sense and deÔ¨Åne a function on R √ó R‚àó
+. Moreover,
it is easy to check that all partial derivatives of the heat kernel are integrable on
R √ó [a, +‚àû[ for all a > 0. Therefore, we can differentiate under the integral signs
without any problems as soon as the second argument of E stays bounded away from
0. Let us set, for all (x, t) ‚ààR √ó R‚àó
+,
v(x, t) =
 +‚àû
‚àí‚àû
E(x ‚àíy, t)u0(y) dy
and
w(x, t) =
 +‚àû
‚àí‚àû
 t
0
E(x ‚àíy, t ‚àís) f (y, s) ds

dy.
By the observation above, we have that
‚àÇv
‚àÇt ‚àí‚àÇ2v
‚àÇx2

(x, t) =
 +‚àû
‚àí‚àû
 ‚àÇ
‚àÇt ‚àí‚àÇ2
‚àÇx2

E(x ‚àíy, t)u0(y) dy = 0
for all t > 0. We need to exert a little more care to deal with w. Setting
wn(x, t) =
 +‚àû
‚àí‚àû
 t‚àí1/n
0
E(x ‚àíy, t ‚àís) f (y, s) ds

dy,
we see that wn ‚Üíw uniformly. Indeed,
|w(x, t) ‚àíwn(x, t)| ‚â§‚à•f ‚à•L‚àû(R√óR+)
 t
t‚àí1
n
 +‚àû
‚àí‚àû
E(x ‚àíy, t ‚àís) dy

ds = ‚à•f ‚à•L‚àû(R√óR+)
n
.

250
7
The Heat Equation
Consequently, wn ‚Üíw in the sense of D‚Ä≤(R √ó R‚àó
+) and therefore
‚àÇwn
‚àÇt ‚àí‚àÇ2wn
‚àÇx2 ‚Üí‚àÇw
‚àÇt ‚àí‚àÇ2w
‚àÇx2 in D‚Ä≤(R √ó R‚àó
+).
We have no problem computing the effect of the heat operator on wn:
‚àÇwn
‚àÇt ‚àí‚àÇ2wn
‚àÇx2

(x, t) =
 +‚àû
‚àí‚àû
 t‚àí1/n
0
 ‚àÇ
‚àÇt ‚àí‚àÇ2
‚àÇx2

E(x ‚àíy, t ‚àís) f (y, s) ds

dy
+
 +‚àû
‚àí‚àû
E(x ‚àíy, n‚àí1) f (y, t ‚àín‚àí1) dy
=
 +‚àû
‚àí‚àû
E(x ‚àíy, n‚àí1) f (y, t ‚àín‚àí1) dy ‚Üí
n‚Üí‚àûf (x, t)
simply, and even uniformly on compact sets, as we have essentially already seen
before. Hence
‚àÇw
‚àÇt ‚àí‚àÇ2w
‚àÇx2 = f.
Concerning the initial condition, we obviously have w(x, 0) = 0 and w(x, t) ‚Üí0
when t ‚Üí0. Indeed,
 +‚àû
‚àí‚àûE(x ‚àíy, t ‚àís) f (y, s) dy
 ‚â§‚à•f ‚à•L‚àû(R√óR+). On the
other hand, we have v(x, t) ‚Üíu0(x) when t ‚Üí0 by the same change of variable as
above.
‚ñ°
Remark 7.15 The analysis is a little more difÔ¨Åcult when u0 or f are not continuous.
We have not made precise in which space the above solution is unique.
‚ñ°
Remark 7.16 The solution u is C‚àûon any open set of R √ó R‚àó
+ where f is C‚àû. This
is again hypoellipticity.
‚ñ°
Remark 7.17 When u0 is in L‚àû, the result remains valid. In particular, when u0
is periodic and f = 0, then u is also periodic in x for all t. Moreover if u0 is the
odd periodic extension of an initial condition for the heat equation on a bounded
interval with Dirichlet boundary conditions, we obtain the same solution as the one
obtained via Fourier series by restricting u to a space-time strip based on the interval
in question.
‚ñ°
Remark 7.18 Notice an interesting phenomenon: When u0 is positive with compact
support and f = 0, we have u(x, t) > 0 for all x ‚ààR and all t > 0, however small.
In other words, a compactly supported initial distribution of temperature instantly
spreads to the whole of R. Thus, the heat equation propagates energy at inÔ¨Ånite
speed, which is strongly non physical. However, the validity of the heat equation
as a model of temperature evolution is still extremely good for all classical physics
and engineering applications. Indeed, assuming that the support of u0 is included in
[‚àíA, A] with A > 0, we have the following coarse estimate for |x| > A:

7.7 The Heat Equation on R
251
|u(x, t)| ‚â§
A
‚àöœÄt e‚àí(|x|‚àíA)2
4t
‚à•u0‚à•L‚àû(R),
so that u(x, t) may be nonzero, but it is nonetheless extremely rapidly decreasing at
inÔ¨Ånity in x for t > 0.
‚ñ°
Again, the previous study is far from being exhaustive. There is a lot more to
say about the heat equation, and more generally about parabolic equations, linear
or nonlinear. For the ensuing numerical approximation theory, we are however now
conÔ¨Ådent that solutions exist, are unique and sufÔ¨Åciently regular under reasonable
hypotheses. Moreover, the energy estimate (7.2) will have important discrete coun-
terparts.

Chapter 8
The Finite Difference Method for the Heat
Equation
We now turn to numerical methods that can be used to approximate the solution of the
heat equation. We develop the Ô¨Ånite difference method in great detail, with particular
emphasis on stability issues, which are delicate. We concentrate on the heat equation
in one dimension of space, with homogeneous Dirichlet boundary conditions.
We also give some indications about Ô¨Ånite difference (in time)-Ô¨Ånite element (in
space) approximation.
8.1
The Explicit Euler Three Point Finite Difference
Scheme for the Heat Equation
We thus consider the problem
‚éß
‚é™‚é®
‚é™‚é©
‚àÇu
‚àÇt (x, t) ‚àí‚àÇ2u
‚àÇx2 (x, t) = f (x, t) in Q =]0, 1[√ó]0, T[,
u(x, 0) = u0(x) in Œ©,
u(0, t) = u(1, t) = 0 in ]0, T[.
(8.1)
We assume that the solution u is as regular as we need it to be.
The general idea of Ô¨Ånite difference methods for evolution equations is the same
as for stationary equations that we have already seen in Chap.2. It is simply to replace
derivatives by difference quotients involving approximate discrete unknowns, and
to solve for these unknowns. In the case of an evolution equation, we need a space-
time grid. Let us thus be given two positive integers N and M. We set h = Œ¥x =
1
N+1
and xn = nh for n = 0, 1, . . . , N + 1. Similarly, we set k = Œ¥t =
T
M+1 and tj = jk for
j = 0, 1, . . . , M + 1. The parameter h is called the space grid step and the parameter
k the time grid step, or time step. The grid points are the points (xn, tj). Eventually,
we will let N and M go to inÔ¨Ånity, or equivalently, h and k go to 0. Note that there
¬© Springer International Publishing Switzerland 2016
H. Le Dret and B. Lucquin, Partial Differential Equations:
Modeling, Analysis and Numerical Approximation, International Series
of Numerical Mathematics 168, DOI 10.1007/978-3-319-27067-8_8
253

254
8
The Finite Difference Method for the Heat Equation
are two independent discretization parameters. This makes the analysis signiÔ¨Åcantly
more complicated than in the elliptic case of Chap.2.
The discrete unknowns are scalars uj
n for the above values of n and j, and it is
hoped that uj
n will be an approximation of u(xn, tj), that should become better and
better as N and M are increased. The boundary condition can be enforced exactly by
requiring that
uj
0 = uj
N+1 = 0
for all j = 0, . . . , M + 1. The initial condition is naturally discretized by requiring
that
u0
n = u0(xn)
for all n = 1, . . . , N. If the initial data is consistent with the boundary condition,
the same is true for the discrete unknowns in the sense that u0
0 = u0(0) = u0(1) =
u0
N+1 = 0. The right-hand side of the equation is discretized by setting f j
n = f (xn, tj).
The only values that are left unknown at this stage are thus uj
n for n = 1, . . . , N
and j = 1, . . . , M + 1. We also use the notation1
Uj =
‚éõ
‚éú‚éú‚éú‚éù
uj
1
uj
2...
uj
N
‚éû
‚éü‚éü‚éü‚é†‚ààRN
to denote the vector of approximate values on the space grid at time tj. Note again
a fundamental difference with variational approximation methods such as the Ô¨Ånite
element method, which is that the computed approximation is not a function, but a
Ô¨Ånite set of values.
In the explicit Euler three point scheme, the partial derivatives are approximated in
the same way as the simple derivatives were in the stationary case studied in Chap.2.
For the time derivative of the exact solution, we can use for example the forward
differential quotient approximation
‚àÇu
‚àÇt (xn, tj) ‚âàu(xn, tj+1) ‚àíu(xn, tj)
k
,
and for the second order space derivative, by combining a forward and a backward
differential quotient , we obtain the central approximation, see Remark2.2 of Chap.
2,
1For consistency with the notation used in the stationary case, we should denote these vectors Uj
h,k.
We drop the h, k index for brevity, but of course, these vectors crucially depend on h and k.

8.1 The Explicit Euler Three Point Finite Difference Scheme ‚Ä¶
255
‚àÇ2u
‚àÇx2 (xn, tj) ‚âà
u(xn+1,tj) ‚àíu(xn,tj)
h
‚àíu(xn,tj) ‚àíu(xn‚àí1,tj)
h
h
= u(xn+1, tj) ‚àí2u(xn, tj) + u(xn‚àí1, tj)
h2
,
where the ‚âàsign can be given a precise meaning by using Taylor expansions as in
Chap.2 and we will come back to that later. The Ô¨Ånite difference method mimics these
approximations by replacing the exact values of the solution at the grid points by
the discrete unknowns. In this particular case, we end up with the following explicit
Euler three point Ô¨Ånite difference scheme:
‚éß
‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é©
uj+1
n
‚àíuj
n
k
‚àíuj
n+1 ‚àí2uj
n + uj
n‚àí1
h2
= f j
n for n = 1, . . . , N, j = 0, . . . , M,
u0
n = u0(xn) for n = 1, . . . , N,
uj
0 = uj
N+1 = 0 for j = 0, . . . , M + 1.
(8.2)
Of course, at this point, there is no indication that (8.2) has anything to do with (8.1).
The name explicit or forward Euler comes from the fact that the time derivative is
approximated in the same way as it is approximated in the case of the forward Euler
method for ordinary differential equations, whereas the three point name comes from
the three point centered approximation of the second order space derivative already
used for second order elliptic problems in Chap.2.
We may rewrite the Ô¨Årst N equations of the scheme in vector form as
Uj+1 ‚àíUj
k
+ AhUj = Fj for j = 0, . . . , M,
where Ah is the same N √ó N tridiagonal matrix as in Chap.2 with c = 0,
Ah = 1
h2
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éù
2 ‚àí1
0
¬∑ ¬∑ ¬∑
0
‚àí1
2
‚àí1
¬∑ ¬∑ ¬∑
0
...
...
...
...
...
0
¬∑ ¬∑ ¬∑ ‚àí1
2 ‚àí1
0
¬∑ ¬∑ ¬∑
0
‚àí1
2
‚éû
‚éü‚éü‚éü‚éü‚éü‚é†
,
and Fj is the vector
Fj =
‚éõ
‚éú‚éú‚éú‚éù
f j
1
f j
2...
f j
N
‚éû
‚éü‚éü‚éü‚é†‚ààRN.
The discrete initial condition is also a vector

256
8
The Finite Difference Method for the Heat Equation
U0 =
‚éõ
‚éú‚éú‚éú‚éù
u0(x1)
u0(x2)
...
u0(xN)
‚éû
‚éü‚éü‚éü‚é†‚ààRN.
With this notation, the numerical scheme is equivalent to

Uj+1 = (I ‚àíkAh)Uj + kFj for j = 0, . . . , M,
U0 = U0,
where I is the N √ó N identity matrix.2 This simple recurrence relation shows that
the scheme is well-deÔ¨Åned. As opposed to the stationary case of Chap.2, there is no
linear system to be solved. We can also note the appearance of the factor
k
h2 =
Œ¥t
Œ¥x2
which will play an important role in the sequel.
Let us now introduce, or reintroduce from Chap.2 as the case may be, a few
notions of interest. We will use the notation ut for the function x ‚Üíu(x, t), for Ô¨Åxed
t ‚ààR+, and ux for the function t ‚Üíu(x, t), for Ô¨Åxed x ‚àà[0, 1].
DeÔ¨Ånition 8.1 Let v be a function deÔ¨Åned on [0, 1]. We deÔ¨Åne the space grid sam-
pling operator Sh by
Sh(v) =
‚éõ
‚éú‚éú‚éú‚éù
v(x1)
v(x2)
...
v(xN)
‚éû
‚éü‚éü‚éü‚é†‚ààRN.
Let now u be the solution of problem (8.1). We deÔ¨Åne the truncation error of the
present Ô¨Ånite difference method to be the sequence of vectors
Œµh,k(u)j = Sh(utj+1) ‚àíSh(utj)
k
+ AhSh(utj) ‚àíFj.
To obtain the truncation error, we just take the Ô¨Ånite difference scheme and replace
the discrete unknowns with the corresponding grid samplings of the solution of the
heat equation. Its name stems from the fact that, if we were to Ô¨Åctitiously apply the
numerical scheme with one time step starting from the exact sampling values at tj,
i.e., let
Uj+1 = Sh(utj) ‚àíkAhSh(utj) + kFj,
then we would make an error Sh(utj+1) ‚àíUj+1 = kŒµh,k(u)j. The truncation error is
not however directly related to the actual error between the sampling of the solution
and the discrete unknown, as we will see later. This is because errors accumulate
2Here also, the vectors Fj and U0 depend respectively on h and k, and on h.

8.1 The Explicit Euler Three Point Finite Difference Scheme ‚Ä¶
257
from the start at each iteration of the scheme. The truncation error is however an
important intermediate ingredient in the convergence analysis.
In order to analyze the convergence of Ô¨Ånite difference methods, we need to
introduce the function spaces
Cm,n( ¬ØQ) = {u; ‚àÄt ‚àà[0, T], ut ‚ààCm([0, 1]) and ‚àÄx ‚àà[0, 1], ux ‚ààCn([0, T])
with all derivatives uniformly bounded on ¬ØQ}.
For the time being, we equip the space RN with the inÔ¨Ånity norm as before, except
that the dependence on h is here made explicit,
‚à•U‚à•‚àû,h = max
1‚â§n‚â§N |Un|,
where U1, . . . , UN are the components of U ‚ààRN.
Wehavethefollowingeasyestimateconcerningthetruncationerrorfortheexplicit
Euler three point numerical scheme.
Proposition 8.1 Assume that u ‚ààC4,2( ¬ØQ). Then we have
max
0‚â§j‚â§M ‚à•Œµh,k(u)j‚à•‚àû,h ‚â§C(h2 + k),
where the constant C depends only on u.
We say that the forward Euler three point scheme is consistent for the ‚àû, h norms,
of order 1 in time and order 2 in space, all these terms to be made precise later on.
Proof We use Taylor‚ÄìLagrange expansions exactly as in the one-dimensional elliptic
case. First we use the fact that ux is of class C2. Therefore, for all n and j, there exists
Œ∏j
n ‚àà]tj, tj+1[ such that
u(xn, tj+1) = u(xn, tj) + k ‚àÇu
‚àÇt (xn, tj) + k2
2
‚àÇ2u
‚àÇt2 (xn, Œ∏j
n),
which we rewrite as
u(xn, tj+1) ‚àíu(xn, tj)
k
= ‚àÇu
‚àÇt (xn, tj) + k
2
‚àÇ2u
‚àÇt2 (xn, Œ∏j
n).
Similarly, ut is of class C4. Therefore, for all n and j, there exists Œæ j,+
n
‚àà]xn, xn+1[,
Œæ j,‚àí
n
‚àà]xn‚àí1, xn[ such that
u(xn+1, tj) = u(xn, tj) + h‚àÇu
‚àÇx (xn, tj) + h2
2
‚àÇ2u
‚àÇx2 (xn, tj) + h3
6
‚àÇ3u
‚àÇx3 (xn, tj) + h4
24
‚àÇ4u
‚àÇx4 (Œæj,+
n
, tj),

258
8
The Finite Difference Method for the Heat Equation
and
u(xn‚àí1, tj) = u(xn, tj) ‚àíh‚àÇu
‚àÇx (xn, tj) + h2
2
‚àÇ2u
‚àÇx2 (xn, tj) ‚àíh3
6
‚àÇ3u
‚àÇx3 (xn, tj) + h4
24
‚àÇ4u
‚àÇx4 (Œæj,‚àí
n
, tj),
which we rewrite as
u(xn+1, tj) ‚àí2u(xn, tj) + u(xn‚àí1, tj)
h2
= ‚àÇ2u
‚àÇx2 (xn, tj) + h2
12
‚àÇ4u
‚àÇx4 (Œæ j
n, tj),
where Œæ j
n ‚àà]xn‚àí1, xn+1[, thanks to the intermediate value theorem.3 Taking into ac-
count the boundary conditions u(x0, tj) = u(xN+1, tj) = 0, we see that
Œµh,k(u)j = Sh
‚àÇu
‚àÇt ‚àí‚àÇ2u
‚àÇx2

tj

‚àíFj + Rj
with
Rj
n = k
2
‚àÇ2u
‚àÇt2 (xn, Œ∏j
n) ‚àíh2
12
‚àÇ4u
‚àÇx4 (Œæ j
n, tj).
Now since u is a regular solution of the heat equation, we have Sh
 ‚àÇu
‚àÇt ‚àí‚àÇ2u
‚àÇx2

tj

‚àí
Fj = 0 due to the deÔ¨Ånition of the sampling operator, even for j = 0 by continuity.
Moreover
|Rj
n| ‚â§max
1
2 max
¬ØQ
‚àÇ2u
‚àÇt2
, 1
12 max
¬ØQ
‚àÇ4u
‚àÇx4


(k + h2),
for all n and j, which concludes the proof of the proposition.
‚ñ°
Remark 8.1 A natural question is to wonder whether the above order is optimal
and to make sure that we are not missing a better approximation rate. To settle this
question, it is sufÔ¨Åcient to pursue the Taylor‚ÄìLagrange expansions up to third order
in time and sixth order in space (assuming enough regularity for u) and see what
comes up. The outcome is
Œµh,k(u)j
n = k
2
‚àÇ2u
‚àÇt2 (xn, tj) ‚àíh2
12
‚àÇ4u
‚àÇx4 (xn, tj)
+ k2
6
‚àÇ3u
‚àÇt3 (xn, ÀúŒ∏j
n) ‚àíh4
720
‚àÇ6u
‚àÇx6 (ÀúŒæ j,‚àí
n
, tj) + ‚àÇ6u
‚àÇx6 (ÀúŒæ j,+
n
, tj)

.
Now, the function (h, k) ‚ÜíAk + Bh2 is identically 0 if and only if A = B = 0. Of
course, in general both ‚àÇ2u
‚àÇt2 (xn, tj) and ‚àÇ4u
‚àÇx4 (xn, tj) are nonzero, thus the truncation error
is not of a higher order.
‚ñ°
3This is the same computation as in Chap.2.

8.2 The Implicit Euler and Leapfrog Schemes
259
8.2
The Implicit Euler and Leapfrog Schemes
Before describing and analyzing general Ô¨Ånite difference schemes, we give two more
simple examples. The Ô¨Årst example is the implicit or backward Euler three point
scheme, which is associated with the backward differential quotient approximation
of the time derivative
‚àÇu
‚àÇt (xn, tj) ‚âàu(xn, tj) ‚àíu(xn, tj‚àí1)
k
,
also used under the same name in the context of the numerical approximation of
ordinary differential equations. In vector form, this scheme reads
Uj ‚àíUj‚àí1
k
+ AhUj = Fj for j = 1, . . . , M + 1,
or equivalently
Uj+1 ‚àíUj
k
+ AhUj+1 = Fj+1 for j = 0, . . . , M.
This scheme is called implicit, because the above formula is not a simple recurrence
relation. Indeed, Uj+1 appears as the solution of an equation once Uj is known. It is
not a priori clear that this equation is solvable. In this particular case, we have

Uj+1 = (I + kAh)‚àí1(Uj + kFj+1) for j = 0, . . . , M,
U0 = U0,
since it is not hard to see that the matrix I + kAh is symmetric, positive deÔ¨Ånite, hence
invertible. In practical terms, the implementation of the backward Euler method
entails the solution of a linear system at each time step, whereas the explicit method
is simply a matrix-vector product and vector addition at each time step. The implicit
method is thus more computationally intensive than the explicit method, but it has
other beneÔ¨Åts as we will see later.
The analysis of the truncation error of the implicit Euler scheme is basically the
same as in the explicit case. The method is likewise consistent, of order 1 in time
and order 2 in space.
The second example is the leapfrog or Richardson method, which is associated
with the central differential quotient approximation of the time derivative
‚àÇu
‚àÇt (xn, tj) ‚âàu(xn, tj+1) ‚àíu(xn, tj‚àí1)
2k
,
which leaps over time tj. In vector form, this scheme reads

260
8
The Finite Difference Method for the Heat Equation
Uj+1 ‚àíUj‚àí1
2k
+ AhUj = Fj for j = 1, . . . , M.
This scheme is an explicit two-step method since Uj+1 is explicitly given in terms
of Uj and Uj‚àí1.

Uj+1 = Uj‚àí1 ‚àí2kAhUj + 2kFj for j = 1, . . . , M,
U0 = U0, U1 = U1.
Of course, since this is a two-step method, a given value U1 supposed to approximate
Sh(ut1) must somehow be ascribed to U1 in order to initialize the recurrence, in
addition to U0.
The idea behind the leapfrog scheme is that the truncation error is of order 2
in time and order 2 in space, i.e., the truncation error is bounded from above by a
quantity of the form C(h2 + k2), which would seem to be advantageous as compared
to both Euler schemes. Unfortunately, we will see that the improved truncation error
is accompanied by instability, which prevents the method from being convergent. It
is not usable in practice for the heat equation, and this example shows that a naive
approach to Ô¨Ånite difference schemes may very well badly fail.
8.3
General Finite Difference Schemes, Consistency,
Stability, Convergence
In this section, we introduce a general framework for dealing with Ô¨Ånite difference
schemes. A Ô¨Ånite difference scheme for the heat equation, or for any other linear
evolution partial differential equation, is constructed by forming linear combinations
ofpartialdifferentialquotientsandreplicatingtheselinearcombinationsonthepurely
discretelevel.Itcanbecastinthefollowingform:Letusbegiventwopositiveintegers
l and m with l + m ‚â•1, and a set of l + m + 1 matrices Bi, ‚àím ‚â§i ‚â§l, each of size
N √ó N, the entries of which are functions of h and k. We assume that Bl is invertible.
A general l + m step Ô¨Ånite difference scheme is then a recurrence relation for a
sequence of vectors Uj ‚ààRN, of the form
BlUj+l + Bl‚àí1Uj+l‚àí1 + ¬∑ ¬∑ ¬∑ + B0Uj + ¬∑ ¬∑ ¬∑ + B‚àímUj‚àím = Fj, m ‚â§j ‚â§(T/k) ‚àíl
(8.3)
with given initial data
U0 = U0, U1 = U1, . . . , Ul+m‚àí1 = Ul+m‚àí1.
The right-hand side vector Fj is to be constructed from f , but is not necessarily
equal to Fj. As before, the intended meaning of Uj with components uj
n is that uj
n is
expected to provide an approximation of u(xn, tj).

8.3 General Finite Difference Schemes, Consistency, Stability, Convergence
261
DeÔ¨Ånition 8.2 We say that the scheme (8.3) is explicit if the leading matrix Bl is
diagonal. Otherwise, the scheme is called implicit.
Inanexplicitmethod,thenextvectorUj+l isthusdirectlyobtainedfrompreviously
computed vectors by matrix-vector multiplications and vector additions, whereas an
implicit method entails the actual resolution of a linear system at each time step.
Let us see how the previously introduced schemes Ô¨Åt into this general picture. For
forward Euler, we have
‚éß
‚é®
‚é©
1
k Uj+1 +

‚àí1
k I + Ah

Uj = Fj,
U0 = U0,
(8.4)
so that l = 1, m = 0, B1 = 1
k I, B0 = ‚àí1
k I + Ah and Fj = Fj. It is obviously one step
and explicit. Of course, we can also write it with for example B1 = I, B0 = ‚àíI + kAh
and Fj = kFj, there is no uniqueness of the general form for a given scheme. The
backward Euler method is
‚éß
‚é®
‚é©
1
k I + Ah

Uj ‚àí1
k Uj‚àí1 = Fj,
U0 = U0,
(8.5)
so that l = 0, m = 1, B0 = 1
k I + Ah, B‚àí1 = ‚àí1
k I and Fj = Fj. It is obviously one
step and implicit (recall that 1
k I + Ah is invertible). Finally, the leapfrog scheme is
‚éß
‚é®
‚é©
1
2k Uj+1 + AhUj ‚àí1
2k Uj‚àí1 = Fj,
U0 = U0, U1 = U1.
(8.6)
so that l = 1, m = 1, B1 =
1
2k I, B0 = Ah, B‚àí1 = ‚àí1
2k I and Fj = Fj. It is obviously
two step and explicit.
Remark 8.2 As mentioned before, there is no uniqueness of a general form for a
given scheme. Indeed, given a general form, we can obtain another one by multiplying
everythingbyanarbitraryfunctionof h andk,orevenbyanarbitraryN √ó N invertible
matrix function of h and k. So the deÔ¨Ånition of explicit or implicit scheme as stated
before is attached to a general form and not to the scheme under consideration.
However, it should be quite clear that writing the backward Euler scheme as
Uj ‚àí(I + kAh)‚àí1Uj‚àí1 = k(I + kAh)‚àí1Fj

262
8
The Finite Difference Method for the Heat Equation
and thus declaring it explicit, is somehow cheating. Indeed, the matrix (I + kAh)‚àí1
is not know explicitly.4 Thus the real issue is an implementation issue: do we need
to numerically solve a nontrivial linear system to compute the scheme, or not? In the
former case, the scheme is implicit and the latter case, it is explicit.
Different general forms give rise to different truncation errors, see DeÔ¨Ånition8.3
below. As a general rule, it is better to choose the form that naturally comes from the
discretization of the partial derivatives by differential quotients.
‚ñ°
There is nothing in the deÔ¨Ånition of a general Ô¨Ånite difference scheme given
above that even alludes to a particular partial differential equation that we might
be interested in approximating. We therefore need a way of comparing the vectors
Uj ‚ààRN and the function u solution of problem (8.1). As in the stationary case
of Chap.2, an obvious idea is to use the sampling operator already introduced in
DeÔ¨Ånition8.1.
Even then, quantitatively comparing two vectors of RN involves the choice of a
norm on RN. We are ultimately interested in letting N ‚Üí+‚àû, thus we need a norm
for each value of N. There is no reason at this point to do anything else that to choose
an arbitrary norm ‚à•¬∑ ‚à•N on RN for each N. Two popular choices are
‚à•U‚à•‚àû,h = max
1‚â§n‚â§N |Un| and ‚à•U‚à•2,h =
‚àö
h
 N

n=1
U2
n
1/2
,
(recall that h =
1
N+1). The reason for the
‚àö
h factor in the second norm is for com-
parison with the L2 norm in the limit h ‚Üí0. Of course, it is well-known that any
two norms on RN are equivalent, but the constants in the norm equivalence depend
on N. For instance,
‚à•U‚à•2,h ‚â§‚à•U‚à•‚àû,h ‚â§
1
‚àö
h
‚à•U‚à•2,h
with basically optimal constants. This shows that consistency and convergence (see
DeÔ¨Ånitions8.4 and 8.6 below) in the ‚àû, h norms imply consistency and convergence
in the 2, h norms, but not the converse.
We can now give a few deÔ¨Ånitions.
DeÔ¨Ånition 8.3 Let u be a sufÔ¨Åciently regular solution of problem (8.1). The trunca-
tion error of the general Ô¨Ånite difference method (8.3) is the sequence of vectors
Œµh,k(u)j = BlSh(utj+l) + ¬∑ ¬∑ ¬∑ + B0Sh(utj) + ¬∑ ¬∑ ¬∑ + B‚àímSh(utj‚àím) ‚àíFj,
for m ‚â§j ‚â§(T/k) ‚àíl.
Again, we just replace the discrete unknown with the grid sampling of the solu-
tion in the Ô¨Ånite difference scheme formula. Note that, since for any given scheme,
4Well, actually it may well be known somewhere in the literature, but let us assume it is not known
for the sake of the argument.

8.3 General Finite Difference Schemes, Consistency, Stability, Convergence
263
there are inÔ¨Ånitely many different general formulas describing the same scheme, the
truncation error of a given scheme depends on how it is written in general form. For-
tunately, this is totally irrelevant for the ensuing analysis. We just need to be careful
in the application of the general results in each particular case.
DeÔ¨Ånition 8.4 We say that the scheme in general form (8.3) is consistent for the
family of norms ‚à•¬∑ ‚à•N if
max
m‚â§j‚â§(T/k)‚àíl ‚à•Œµh,k(u)j‚à•N ‚Üí0 when (h, k) ‚Üí(0, 0).
We say that it is of order p in space and q in time for the family of norms ‚à•¬∑ ‚à•N if
max
m‚â§j‚â§(T/k)‚àíl ‚à•Œµh,k(u)j‚à•N ‚â§C(hp + kq),
where the constant C only depends on u.
Consistency means that the scheme is trying its best to locally approximate the
right partial differential equation problem in the norm ‚à•¬∑ ‚à•N. Of course, the above
deÔ¨Ånitions depend on the choice of norm and on the choice of general form. A given
scheme may well be consistent for one family of norms and not for another, or be of
some order in one general form and of another order in another general form. It is up to
us to choose the best norm/general form combination. As in the particular cases that
we have already seen, checking consistency and computing time and space orders is
just a matter of having enough patience to write down the relevant Taylor‚ÄìLagrange
expansions.
A signiÔ¨Åcantly subtler notion is that of stability.
DeÔ¨Ånition 8.5 Let S ‚äÇR‚àó
+ √ó R‚àó
+ be such that (0, 0) ‚àà
¬Ø
S . We say that the scheme
in general form (8.3) is stable for the family of norms ‚à•¬∑ ‚à•N under condition S , if
there exists two constants C1(T) and C2(T) which only depend on T such that, for
all (h, k) ‚ààS , all initial data Uj‚Ä≤, 0 ‚â§j‚Ä≤ ‚â§l + m ‚àí1, and all right-hand sides Fj‚Ä≤‚Ä≤,
m ‚â§j‚Ä≤‚Ä≤ ‚â§(T/k) ‚àíl, we have
max
j‚â§T/k ‚à•Uj‚à•N ‚â§C1(T)
max
0‚â§j‚Ä≤‚â§l+m‚àí1 ‚à•Uj‚Ä≤‚à•N + C2(T)
max
m‚â§j‚Ä≤‚Ä≤‚â§(T/k)‚àíl ‚à•Fj‚Ä≤‚Ä≤‚à•N.
(8.7)
If S ‚äÉ]0, a[ √ó ]0, a[ for some a > 0, we say that the scheme is unconditionally
stable.
Stability makes no reference to the partial differential equation. It is just a property
of the recurrence relation which controls the growth of its solutions in terms of the
initial data and right-hand side. Stability in the present sense is very different from
stability in the stationary case.
Note that in spite of the previous fact, the introduction of stability must be put
in perspective with such continuous energy estimates as estimate (7.2). It is in fact
a discrete version of such estimates in the case of the 2, h norms. We also refer to

264
8
The Finite Difference Method for the Heat Equation
Sect.8.9 for a particularly striking parallel between the stability in the continuous
and discrete cases.
DeÔ¨Ånition 8.6 We say that the scheme is convergent for the family of norms ‚à•¬∑ ‚à•N
if
max
j‚â§T/k ‚à•Uj ‚àíSh(utj)‚à•N ‚Üí0 when (h, k) ‚Üí(0, 0), (h, k) ‚ààS .
Note that this deÔ¨Ånition is independent of the general form under which the scheme is
written, as opposed to the two previous deÔ¨Ånitions. Remembering that Sh(utj) is just
a notation for u(xn, tj), n = 1, . . . , N, we see that convergence of the scheme means
that |uj
n ‚àíu(xn, tj)| tends to 0 (at least if the choice of norms ‚à•¬∑ ‚à•N is reasonable
enough), or that the computed discrete unknowns uj
n are in effect approximations of
the value of the solution at gridpoints.
The relevance of the above deÔ¨Ånitions is clariÔ¨Åed by means of the Lax theorem:
Theorem 8.1 (Lax Theorem) Assume that
max
0‚â§j‚Ä≤‚â§l+m‚àí1 ‚à•Uj‚Ä≤ ‚àíSh(utj‚Ä≤ )‚à•N ‚Üí0 when (h, k) ‚Üí(0, 0), (h, k) ‚ààS .
If the scheme in general form (8.3) is consistent and stable under condition S for
the family of norms ‚à•¬∑ ‚à•N, then it is convergent for that same family of norms.
Proof Let us compare the formulas for the truncation error and for the scheme.
BlSh(utj+l) + ¬∑ ¬∑ ¬∑ + B0Sh(utj) + ¬∑ ¬∑ ¬∑ + B‚àímSh(utj‚àím) = Œµh,k(u)j + Fj,
BlUj+l + ¬∑ ¬∑ ¬∑ + B0Uj + ¬∑ ¬∑ ¬∑ + B‚àímUj‚àím = Fj.
Setting V j = Uj ‚àíSh(utj) and subtracting the above two formulas, we see that
BlV j+l + ¬∑ ¬∑ ¬∑ + B0V j + ¬∑ ¬∑ ¬∑ + B‚àímV j‚àím = ‚àíŒµh,k(u)j,
with the initial data
V j‚Ä≤ = Uj‚Ä≤ ‚àíSh(utj‚Ä≤ ) for 0 ‚â§j‚Ä≤ ‚â§l + m ‚àí1.
By the stability hypothesis, it follows that
max
j‚â§T/k ‚à•V j‚à•N ‚â§C1
max
0‚â§j‚Ä≤‚â§l+m‚àí1 ‚à•Uj‚Ä≤ ‚àíSh(utj‚Ä≤ )‚à•N + C2
max
m‚â§j‚Ä≤‚Ä≤‚â§(T/k)‚àíl ‚à•Œµh,k(u)j‚Ä≤‚Ä≤‚à•N,
and the right-hand side goes to 0 by consistency and the hypothesis on the initial
data for the scheme.
‚ñ°
Remark 8.3 We have written here the most useful part of the Lax theorem, i.e.,
consistency plus stability imply convergence, see [7, 29, 67, 81]. There is a less

8.3 General Finite Difference Schemes, Consistency, Stability, Convergence
265
useful converse part, see Proposition8.4 later on. Therefore, we have not missed
anything by focusing on consistency and stability.
‚ñ°
Corollary 8.1 Assume that the scheme is stable under condition S and of order p
in space and q in time for the family of norms ‚à•¬∑ ‚à•N, and that
max
0‚â§j‚Ä≤‚â§l+m‚àí1 ‚à•Uj‚Ä≤ ‚àíSh(utj‚Ä≤ )‚à•N ‚â§C(hp + kq),
for some constant C. Then
max
j‚â§T/k ‚à•Uj ‚àíSh(utj)‚à•N ‚â§C‚Ä≤(hp + kq),
where C‚Ä≤ only depends on T and u.
Remark 8.4 High order stable schemes thus result in (in principle) more accurate
approximations than low order schemes. This is conditional on the initial data for
the scheme not destroying this accuracy. If the scheme uses several time steps, the
corresponding initial data must therefore be computed by using some other, equally
accurate method. If the scheme is one time step, then we are at liberty to have exact
initial data (discounting round-off errors).
‚ñ°
Remark 8.5 Let us emphasize again that all this is highly dependent on the choice
of norms. Assume that, for one outrageous reason or another, we had chosen
‚à•U‚à•N = 2‚àíN‚à•U‚à•‚àû,h. Then, it is likely that even the most wildly non consistent
scheme for the ‚àû, h norms would become consistent for the new norms! Since sta-
bility is not affected by multiplication of the norm by a constant, if the scheme was
stable for the ‚àû, h norms, then it would also be stable for the ‚à•¬∑ ‚à•N norms.5 Hence,
by the Lax theorem, it would be convergent for that family of norms. There is how-
ever no contradiction. Indeed, saying that 2‚àíN|uj
n ‚àíu(xn, tj)| ‚Üí0 tells us next to
nothing about what we really are interested in, namely, is uj
n a good approximation
of u(xn, tj) or not. In this respect, the two choices ‚à•¬∑ ‚à•‚àû,h and ‚à•¬∑ ‚à•2,h are much more
natural.
‚ñ°
Remark 8.6 Itshouldalsobenotedthatthefactthattheunderlyingpartialdifferential
equation is the heat equation plays no role in the Lax theorem. The theorem holds true
for any Ô¨Ånite difference scheme devised to approximate the solution of any evolution
partial differential equation problem in one or several dimensions of space. We will
thus also use it for hyperbolic equations in Chaps.9 and 10.
‚ñ°
Let us apply the previous results to the explicit Euler scheme. Let ‚à•¬∑ ‚à•N be a norm
on RN and ||| ¬∑ |||N the associated induced matrix norm, see Chap.2. For any N √ó N
real matrix A and vector U ‚ààRN, we have
‚à•AU‚à•N ‚â§|||A|||N‚à•U‚à•N.
5Note that stability is also affected by the general form used to write the scheme, via the term Fj,
see Proposition8.3 and Remark8.12 for a more precise statement.

266
8
The Finite Difference Method for the Heat Equation
In the particular case of the ‚àû, h norm, we have seen in Proposition2.3 of Chap. 2
that
|||A|||‚àû,h = max
1‚â§n‚â§N
 N

j=1
|Anj|

.
Let us choose the general form
1
k Uj+1 ‚àí1
k Uj + AhUj = Fj,
for which we have consistency in the ‚à•¬∑ ‚à•‚àû,h norms and Fj = Fj.
Proposition 8.2 Let S =

(h, k) ‚ààR‚àó
+ √ó R‚àó
+; k
h2 ‚â§1
2

. The explicit three-point
Euler scheme in this general form is stable under condition S for the norms ‚à•¬∑ ‚à•‚àû,h,
hence convergent for these norms.
Proof The above general form can be rewritten as
Uj+1 = Ah,kUj + kFj,
where Ah,k = I ‚àíkAh. Therefore
‚à•Uj+1‚à•‚àû,h ‚â§|||Ah,k|||‚àû,h‚à•Uj‚à•‚àû,h + k‚à•Fj‚à•‚àû,h.
Let us set r = k
h2 . By direct inspection, we see that
Ah,k =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éù
1 ‚àí2r
r
0 ¬∑ ¬∑ ¬∑
0
r
1 ‚àí2r r ¬∑ ¬∑ ¬∑
0
...
...
... ...
...
...
...
... ...
r
0
¬∑ ¬∑ ¬∑
0
r 1 ‚àí2r
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚é†
.
It follows that
|||Ah,k|||‚àû,h = |1 ‚àí2r| + 2r =

1
if r ‚â§1
2,
4r ‚àí1 if r > 1
2.
Therefore, if r ‚â§1
2, we have that
‚à•Uj+1‚à•‚àû,h ‚â§‚à•Uj‚à•‚àû,h + k‚à•Fj‚à•‚àû,h
‚â§‚à•Uj‚à•‚àû,h + k max
n‚â§T/k ‚à•Fn‚à•‚àû,h.
Iterating backwards, we obtain that for all j such that j ‚â§T
k ,

8.3 General Finite Difference Schemes, Consistency, Stability, Convergence
267
Fig. 8.1 Convergence of the
explicit Euler method when
stability is satisÔ¨Åed
0.0e+00
5.0e-06
1.0e-05
1.5e-05
2.0e-05
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
‚à•Uj‚à•‚àû,h ‚â§‚à•U0‚à•‚àû,h + jk max
n‚â§T/k ‚à•Fn‚à•‚àû,h
‚â§‚à•U0‚à•‚àû,h + T max
n‚â§T/k ‚à•Fn‚à•‚àû,h,
hence the stability of the scheme for the norm ‚àû, h under condition S .
‚ñ°
We plot6 in Fig.8.1 the discrete values UM+1 with M corresponding to T = 1.1,
for the initial value u0(x) = 4x(1 ‚àíx). Each curve corresponds to different values
of N going from 3 to 30, and choosing M in such a way that k
h2 ‚âà0.49.
Remark 8.7 The above estimates are not sufÔ¨Åcient to conclude that the scheme is
not stable when r > 1
2. However, numerical experiments with r > 1
2 quickly show
that the explicit Euler scheme is non convergent for the ‚àû, h norm. Since it is
consistent, this means it must be unstable. In particular, round-off errors are ampliÔ¨Åed
exponentially fast.
To illustrate this, we plot in Fig.8.2 the same sequence of computations as above,
with k
h2 ‚âà0.51.
Note the extreme and erratic variations in the vertical scale of the above plots
depending on N (and its parity). The explicit Euler scheme appears to be wildly
non convergent for such values of the discretization parameters, due to the failure of
stability even by a very small amount.
‚ñ°
Remark 8.8 When (h, k) ‚ààS , we thus have k ‚â§h2
2 ‚â™h for h small. For instance,
if we want a modest amount of 1000 points in the space grid, then the time step must
be smaller than 5 √ó 10‚àí7, i.e., to compute up to a Ô¨Ånal time of T = 1s, we need
at least 2 √ó 106 iterations in time. Such stability requirements can rapidly make the
scheme too computationally expensive, in spite of its otherwise simplicity.
‚ñ°
6For an easier visualization, we also plot a linear interpolation of the Ô¨Ånite difference discrete values.

268
8
The Finite Difference Method for the Heat Equation
0e+00
1e-06
2e-06
3e-06
4e-06
5e-06
6e-06
7e-06
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
N = 3, h = 0.25, M = 34, k = 0.0314286, k/h^2 = 0.5028571
0.0e+00
2.0e-06
4.0e-06
6.0e-06
8.0e-06
1.0e-05
1.2e-05
1.4e-05
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
N = 6, h = 0.1428571, M = 105, k = 0.0103774, k/h^2 = 0.5084906
-3e-05
-2e-05
-1e-05
0e+00
1e-05
2e-05
3e-05
4e-05
5e-05
6e-05
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
N = 9, h = 0.1, M = 215, k = 0.0050926, k/h^2 = 0.5092593
0.0e+00
5.0e-06
1.0e-05
1.5e-05
2.0e-05
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
N = 12, h = 0.0769231, M = 364, k = 0.0030137, k/h^2 = 0.5093151
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
N = 15, h = 0.0625, M = 552, k = 0.0019892, k/h^2 = 0.5092224
0.0e+00
5.0e-06
1.0e-05
1.5e-05
2.0e-05
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
N = 18, h = 0.0526316, M = 778, k = 0.0014121, k/h^2 = 0.5097561
-4e+08
-3e+08
-2e+08
-1e+08
0e+00
1e+08
2e+08
3e+08
4e+08
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
N = 21, h = 0.0454545, M = 1043, k = 0.0010536, k/h^2 = 0.5099617
-20
-15
-10
-5
0
5
10
15
20
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
N = 24, h = 0.04, M = 1348, k = 0.0008154, k/h^2 = 0.5096368
-2.0e+19
-1.5e+19
-1.0e+19
-5.0e+18
0.0e+00
5.0e+18
1.0e+19
1.5e+19
2.0e+19
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
N = 27, h = 0.0357143, M = 1690, k = 0.0006505, k/h^2 = 0.5099941
-4e+13
-3e+13
-2e+13
-1e+13
0e+00
1e+13
2e+13
3e+13
4e+13
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
N = 30, h = 0.0322581, M = 2072, k = 0.0005306, k/h^2 = 0.5099373
Fig. 8.2 Divergence of the explicit Euler method when stability is violated

8.3 General Finite Difference Schemes, Consistency, Stability, Convergence
269
Remark 8.9 The above example shows that it is fairly easy to give sufÔ¨Åcient condi-
tions of stability in the ‚àû, h norms for explicit schemes, which is thus a reasonable
choice of norms for such schemes. In the case of an implicit scheme, determining
stability in the ‚àû, h norm family can in some cases be obtained by using the discrete
maximum principle, in the absence of the explicit knowledge of the inverse matrix
involved. Another case when the ‚àû, h norm of the inverse matrix can be estimated
is if there exists Œ¥ > 0 such that |Ann| ‚â•Œ¥ + 
jÃ∏=n |Anj| for all n. In this case, it is
easy to show that ‚à•A‚àí1‚à•‚àû,h ‚â§1
Œ¥ . If Œ¥ ‚â•1, then the implicit scheme is stable in the
‚àû, h norms.
‚ñ°
Remark 8.10 We will see later that the 2, h norms are more adapted to implicit
schemes since it is possible in certain cases to compute the 2, h norm of an inverse
matrix without computing the inverse in question explicitly.
‚ñ°
Corollary 8.2 When k
h2 ‚â§1
2, the explicit three-point Euler scheme satisÔ¨Åes the error
estimate
max
n,j |uj
n ‚àíu(xn, tj)| ‚â§Ch2.
Proof This is a consequence of Corollary8.1, Proposition8.1, and the fact that we
have k ‚â§h2
2 .
‚ñ°
The second order accuracy is however obtained at the expense of a lot of iterations
in time, see Remark8.8.
8.4
General Criteria for Stability
We have seen that proving consistency is always a matter of combining several
Taylor‚ÄìLagrange expansions together, which can be tedious but does not pose much
difÔ¨Åculty in principle. Stability is another matter.
Let us consider a general scheme (8.3). We rewrite it as a one time step scheme
of the form
V j+1 = Ah,kV j + Gj,
(8.8)
where V j ‚ààR(l+m)N is deÔ¨Åned as
V j =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éù
Uj+l‚àí1
...
Uj
...
Uj‚àím
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚é†
for m ‚â§j ‚â§M + 2 ‚àíl,
the matrix Ah,k is the (l + m)N √ó (l + m)N matrix

270
8
The Finite Difference Method for the Heat Equation
Ah,k =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éù
‚àíB‚àí1
l Bl‚àí1 ‚àíB‚àí1
l Bl‚àí2
¬∑ ¬∑ ¬∑
¬∑ ¬∑ ¬∑ ‚àíB‚àí1
l B‚àím
I
0
¬∑ ¬∑ ¬∑
¬∑ ¬∑ ¬∑
0
0
I
0
¬∑ ¬∑ ¬∑
0
...
...
...
...
...
0
¬∑ ¬∑ ¬∑
0
I
0
‚éû
‚éü‚éü‚éü‚éü‚éü‚é†
and
Gj =
‚éõ
‚éú‚éú‚éú‚éù
B‚àí1
l Fj
0
...
0
‚éû
‚éü‚éü‚éü‚é†.
The matrix Ah,k is called the ampliÔ¨Åcation matrix of the scheme. It depends on k
and h through its coefÔ¨Åcients and it must not be forgotten that its size also depends
on h = 1/(N + 1). Note that the ampliÔ¨Åcation matrix Ah,k and the term Gj do not
depend on the general form (8.3), but only on the scheme itself, in the sense that two
general forms for the same scheme will lead to the same iteration (8.8).
In view of the Lax theorem, it is important to prove stability for a general form
(8.3) for which we also have consistency. We give a Ô¨Årst stability criterion for the
family of norms ‚à•¬∑ ‚à•N. We associate to this family of norms the family
‚à•V ‚à•l+m,N =
max
‚àím‚â§k‚â§l‚àí1 ‚à•Uk‚à•N,
with an obvious deÔ¨Ånition of V ‚ààR(l+m)N in terms of Uk ‚ààRN. For each N, this is
a norm on R(l+m)N. We denote the induced matrix norm by ||| ¬∑ |||l+m,N.
Proposition 8.3 Let us consider a general scheme in the form (8.3) for which there
exists a constant C0 independent of h and k such that |||B‚àí1
l |||N ‚â§C0k. Such a scheme
is stable under condition S if and only if there exists a constant C(T) depending
only on T such that for all (h, k) ‚ààS ,7
max
j‚â§(T/k)+1‚àí(l+m) |||A j
h,k|||l+m,N ‚â§C(T).
(8.9)
Proof We remark that, by deÔ¨Ånition of the ‚à•¬∑ ‚à•l+m,N norm, we have
max
j‚â§T/k ‚à•Uj‚à•N =
max
m‚â§j‚â§(T/k)+1‚àíl ‚à•V j‚à•l+m,N.
(8.10)
Let us Ô¨Årst assume that the general form of the scheme is stable. This means
that there exist two constants C1(T) and C2(T) such that for any U0 and Fj and all
(h, k) ‚ààS
7Beware of the notation: up to now V j meant the jth vector in the sequence, but here A j means the
jth power of the matrix A .

8.4 General Criteria for Stability
271
max
j‚â§T/k ‚à•Uj‚à•N ‚â§C1(T)
max
0‚â§j‚Ä≤‚â§l+m‚àí1 ‚à•Uj‚Ä≤‚à•N + C2(T)
max
m‚â§j‚Ä≤‚Ä≤‚â§(T/k)‚àíl ‚à•Fj‚Ä≤‚Ä≤‚à•N.
We take Fj‚Ä≤‚Ä≤ = 0 for all j‚Ä≤‚Ä≤. In this case, V j = A j‚àím
h,k V m so that we have
max
m‚â§j‚â§(T/k)+1‚àíl ‚à•A j‚àím
h,k V m‚à•l+m,N ‚â§C1(T)‚à•V m‚à•l+m,N.
Since this is true for all V m ‚ààR(l+m)N, it follows that
max
m‚â§j‚â§(T/k)+1‚àíl |||A j‚àím
h,k |||l+m,N ‚â§C1(T).
Changing j ‚àím into j, we obtain estimate (8.9).
Conversely, assume that estimate (8.9) holds true for all (h, k) ‚ààS . We can write,
for all m + 1 ‚â§j ‚â§(T/k) + 1 ‚àíl
V j = Ah,kV j‚àí1 + Gj‚àí1
Ah,kV j‚àí1 = A 2
h,kV j‚àí2 + Ah,kGj‚àí2
...
...
A j‚àím‚àí1
h,k
V m+1 = A j‚àím
h,k V m + A j‚àím‚àí1
h,k
Gm,
so that summing these equations, we obtain
V j = A j‚àím
h,k V m +
j‚àí1

n=m
A j‚àín‚àí1
h,k
Gn.
Therefore
‚à•V j‚à•l+m,N ‚â§‚à•A j‚àím
h,k V m‚à•l+m,N +
j‚àí1

n=m
‚à•A j‚àín‚àí1
h,k
Gn‚à•l+m,N
‚â§C(T)‚à•V m‚à•l+m,N + C(T)
j‚àí1

n=m
‚à•Gn‚à•l+m,N
‚â§C(T)‚à•V m‚à•l+m,N + (j ‚àím)C(T)
max
m‚â§n‚â§j‚àí1 ‚à•Gn‚à•l+m,N
‚â§C(T)‚à•V m‚à•l+m,N + T
k C(T)
max
n‚â§(T/k)‚àíl ‚à•Gn‚à•l+m,N
whenever m + 1 ‚â§j ‚â§T/k. In addition, the Ô¨Ånal estimate holds trivially for j = m.
Recall now that ‚à•Gn‚à•l+m,N = ‚à•B‚àí1
l Fn‚à•N. Therefore
‚à•Gn‚à•l+m,N ‚â§|||B‚àí1
l |||N‚à•Fn‚à•N ‚â§C0k‚à•Fn‚à•N

272
8
The Finite Difference Method for the Heat Equation
in view of the hypothesis made on B‚àí1
l . We thus obtain the stability under condition
S , with C1(T) = C(T) and C2(T) = TC0C(T), because of Eq.(8.10) and the fact
that ‚à•V m‚à•l+m,N = max0‚â§j‚Ä≤‚â§l+m‚àí1 ‚à•Uj‚Ä≤‚à•N.
‚ñ°
Remark 8.11 The hypothesis |||B‚àí1
l |||N ‚â§C0k is essential for the above estimate even
though it seems to be often overlooked in the literature, in which the deÔ¨Ånition of
stability is also often different and weaker than the one we present here. Of course,
as was said before, the usefulness of stability is only for general forms for which
consistency holds. In particular, this hypothesis is clearly satisÔ¨Åed for the forward
Euler scheme in the form (8.4) for any family of norms since |||I|||N = 1.
‚ñ°
Remark 8.12 Under the above hypothesis on B‚àí1
l , it follows that stability does not
depend on the right-hand side of the equation. In other words, it is enough to test it
for a zero right-hand side. More precisely, stability in the sense of DeÔ¨Ånition8.5 is
implied by the less demanding estimate
max
j‚â§T/k ‚à•Uj‚à•N ‚â§C1(T)
max
0‚â§j‚Ä≤‚â§l+m‚àí1 ‚à•Uj‚Ä≤‚à•N,
for all (h, k) ‚ààS , where Uj is any solution of the scheme with zero right-hand side.
This is called the Dahlquist zero-stability condition, see [49] for example.
‚ñ°
The criterion given in Proposition8.3 is not too practical in general, since the
quantity maxj |||A j
h,k|||l+m,N is not necessarily easy to estimate. Nonetheless, we have
a sufÔ¨Åcient condition as an immediate corollary.
Corollary 8.3 If|||Ah,k|||l+m,N ‚â§1forall(h, k) ‚ààS ,thentheschemeisstableunder
condition S .
Proof An operator norm is submultiplicative, i.e., |||AB|||l+m,N ‚â§|||A |||l+m,N
|||B|||l+m,N for any A and B. Therefore, |||A j
h,k|||l+m,N ‚â§|||Ah,k|||j
l+m,N ‚â§1 for all
j, thus in particular for all j smaller than(T/k) + 1 ‚àí(l + m).
‚ñ°
This is what we actually did for the forward Euler scheme and the ‚àû, h norms
in the proof of Proposition8.2. In the case of the 2, h norms, we will see in the next
section that it is possible to be a little more precise and give a necessary and sufÔ¨Åcient
condition of stability for a certain class of ampliÔ¨Åcation matrices. This is one of the
main reasons for using these norms, see Sect.8.5.
Let us now show the converse of the Lax theorem.
Proposition 8.4 Let us be given a scheme that is convergent under condition S for
the family of norms ‚à•¬∑ ‚à•N. Then any general form (8.3) such that |||B‚àí1
l |||N ‚â§C0k is
stable under condition S in the sense of DeÔ¨Ånition8.5.
Proof We Ô¨Årst rewrite the scheme in the form (8.8). We argue by contradiction. We
assume that there is no constant C(T) such that inequality (8.9) holds in a neigh-
borhood of (0, 0) in S .8 We are thus given a sequence (hn, kn) ‚ààS such that
8This is the only relevant case.

8.4 General Criteria for Stability
273
(hn, kn) ‚Üí(0, 0) (so that Nn ‚Üí+‚àû). Let Ahn,kn = An be the corresponding se-
quence of ampliÔ¨Åcation matrices. By hypothesis, there exists a subsequence n‚Ä≤ and
a sequence jn‚Ä≤ such that jn‚Ä≤ ‚â§(T/kn‚Ä≤) + 1 ‚àí(l + m) with
|||A jn‚Ä≤
n‚Ä≤ |||l+m,Nn‚Ä≤ = Œªn‚Ä≤ ‚Üí+‚àûwhen n‚Ä≤ ‚Üí+‚àû.
By compactness in Ô¨Ånite dimensional spaces, there exists Vn‚Ä≤ ‚ààR(l+m)Nn‚Ä≤ such that
‚à•Vn‚Ä≤‚à•l+m,Nn‚Ä≤ = 1 and ‚à•A jn‚Ä≤
n‚Ä≤ Vn‚Ä≤‚à•l+m,Nn‚Ä≤ = Œªn‚Ä≤.
Let us set Wn‚Ä≤ = Vn‚Ä≤/Œªn‚Ä≤. It follows that
‚à•Wn‚Ä≤‚à•l+m,Nn‚Ä≤ ‚Üí0 and ‚à•A jn‚Ä≤
n‚Ä≤ Wn‚Ä≤‚à•l+m,Nn‚Ä≤ = 1.
The Ô¨Årst convergence shows that the vectors Wn‚Ä≤ are appropriate discrete initial
conditions for the scheme applied to the case u0 = 0 and f = 0. The scheme being
convergent in this family of norms, it follows that ‚à•A jn‚Ä≤
n‚Ä≤ Wn‚Ä≤‚à•l+m,Nn‚Ä≤ ‚Üí0, which
contradicts the second relation above.
Finally, the hypothesis |||B‚àí1
l |||N ‚â§C0k combined with estimate (8.9) implies the
stability of the general form by Proposition8.3.
‚ñ°
From now on, we will concentrate on one time step schemes in the case of the
2, h norms.
8.5
Stability for One Time Step Schemes in the 2, h Norms
Let us consider a general scheme (8.3) with one time step, i.e., l = 1, m = 0 or l = 0,
m = 1. As before, we rewrite the scheme as
Uj+1 = A Uj + Gj,
where
A =

‚àíB‚àí1
1 B0
if l = 1, m = 0,
‚àíB‚àí1
0 B‚àí1
if l = 0, m = 1,
and
Gj =

B‚àí1
1 Fj
if l = 1, m = 0,
B‚àí1
0 Fj+1
if l = 0, m = 1.
The ampliÔ¨Åcation matrix A is now a N √ó N matrix. We henceforth omit the h, k
subscript in ampliÔ¨Åcation matrices for notational brevity.

274
8
The Finite Difference Method for the Heat Equation
We Ô¨Årst need to determine the 2, h induced matrix norms. We let œÅ(B) denote the
spectral radius of a matrix B, i.e., œÅ(B) = max{|Œªp|, p = 1, . . . , N}, where Œªp ‚ààC
are the eigenvalues of B.
Proposition 8.5 Let A be a real N √ó N matrix. We have
|||A|||2,h =

œÅ(ATA).
Proof For all X ‚ààRN, we have ‚à•AX‚à•2
2,h = h(AX)TAX = hXT(ATA)X. The matrix
ATA is symmetric, hence it is orthogonally diagonalizable: there exists an orthogonal
matrix Q, i.e., a real matrix such that QTQ = QQT = I, such that ATA = QTDQ
where D is a diagonal matrix, the diagonal entries of which are the eigenvalues dp of
ATA. This matrix is also nonnegative, so that these eigenvalues are all nonnegative.
Therefore, œÅ(ATA) is simply the largest eigenvalue of ATA.
We can thus write
‚à•AX‚à•2
2,h = hXT(QTDQ)X = h(QX)TD(QX).
If we set Y = QX, then ‚à•Y‚à•2,h = ‚à•X‚à•2,h since Q is orthogonal and
‚à•AX‚à•2
2,h = hY TDY = h
N

p=1
dpY 2
p
‚â§hœÅ(ATA)
N

p=1
Y 2
p = œÅ(ATA)‚à•Y‚à•2
2,h = œÅ(ATA)‚à•X‚à•2
2,h.
Taking the square root and dividing by ‚à•X‚à•2,h for X Ã∏= 0, we thus obtain
|||A|||2,h ‚â§

œÅ(ATA).
Let now X be a unit eigenvector of ATA associated with the eigenvalue œÅ(ATA),
ATAX = œÅ(ATA)X and ‚à•X‚à•2
2,h = hXTX = 1. For this vector, we have
‚à•AX‚à•2
2,h = hXT(ATAX) = hœÅ(ATA)XTX = œÅ(ATA),
from which we infer that
|||A|||2,h ‚â•

œÅ(ATA),
and the Proposition is proved.
‚ñ°
A real matrix A is said to be normal if ATA = AAT. In particular, a real symmetric
matrix is normal.

8.5 Stability for One Time Step Schemes in the 2, h Norms
275
Proposition 8.6 If A is a normal matrix, then œÅ(A) = œÅ(ATA)1/2 = |||A|||2,h.
Proof A normal matrix A is unitarily similar to a diagonal matrix Œõ. Thus there
exists a unitary matrix U, i.e., a complex matrix satisfying U‚àóU = UU‚àó= I,9 such
that A = U‚àóŒõU and therefore the diagonal entries of Œõ are the eigenvalues Œªp ‚ààC
of A. It follows that
ATA = U‚àóŒõ‚àó(UU‚àó)ŒõU = U‚àóŒõ‚àóŒõU,
so that the eigenvalues of ATA are the diagonal entries of Œõ‚àóŒõ, namely |Œªp|2,
p = 1, . . . , N. Thus œÅ(A)2 =

max |Œªp|
2 = œÅ(ATA).
‚ñ°
Of course, for a general non normal matrix A, we only have œÅ(A) ‚â§|||A|||2,h, with
often a strict inequality (take for instance a nonzero nilpotent matrix A for which
œÅ(A) = 0). Let us apply the above considerations to Ô¨Ånite difference schemes. In the
sequel, when we say that a scheme is stable, we refer to a scheme written in a general
form satisfying the hypotheses of Proposition8.3.
Proposition 8.7 If the ampliÔ¨Åcation matrix A is normal, then the scheme is stable
for the norms ‚à•¬∑ ‚à•2,h if and only of there exists a constant C‚Ä≤(T) ‚â•0 depending only
on T such that
œÅ(A ) ‚â§1 + C‚Ä≤(T)k.
(8.11)
Proof Let us Ô¨Årst assume that there exists C‚Ä≤(T) ‚â•0 such that œÅ(A ) ‚â§1 + C‚Ä≤(T)k.
By hypothesis, A is normal, therefore A j is also normal and |||A j|||2,h = œÅ(A j) =
œÅ(A )j. Consequently, for all j ‚â§T/k,
|||A j|||2,h ‚â§(1 + C‚Ä≤(T)k)j ‚â§eC‚Ä≤(T)kj ‚â§eC‚Ä≤(T)T,
and the constant eC‚Ä≤(T)T depends only on T. Therefore, the scheme is stable according
to Proposition8.3.
Conversely, assume that the scheme is stable. By Proposition8.3 again, this im-
plies that œÅ(A )j ‚â§C(T) or œÅ(A ) ‚â§C(T)1/j for all j ‚â§T/k. There are two cases.
Either C(T) ‚â§1 and thus œÅ(A ) ‚â§1 and we are done with C‚Ä≤(T) = 0, or C(T) > 1.
In this case, we take j = T/k so that
œÅ(A ) ‚â§C(T)
k
T = e
k
T ln(C(T)),
with ln(C(T)) > 0. This implies that the function s ‚Üíes ln(C(T)) is convex on
[0, 1], which in turn implies that for all s ‚àà[0, 1], es ln(C(T)) ‚â§(1 ‚àís) + seln(C(T)) =
1 + s(C(T) ‚àí1). In particular, for s = k/T, we obtain
9For any matrix A, A‚àódenotes the adjoint matrix of A, i.e., its conjugate transpose.

276
8
The Finite Difference Method for the Heat Equation
œÅ(A ) ‚â§1 + C(T) ‚àí1
T
k,
hence estimate (8.11) with C‚Ä≤(T) = C(T) ‚àí1
T
.
‚ñ°
Remark 8.13 Inspection of the above proof shows that the fact that the matrix is
normal is not used in the converse part of Proposition8.7. Therefore, condition (8.11)
is a necessary condition of stability for any matrix A .
‚ñ°
Remark 8.14 It is important to stress again that the matrix A is a function of k and h,
and so is its spectral radius. Therefore, the above estimates are by no means obvious.
Note that a sufÔ¨Åcient condition for stability in the 2, h norm in the case of a
normal ampliÔ¨Åcation matrix, often used in practice, is thus that œÅ(A ) ‚â§1. This is
particularly indicated if we are interested in the computation of long term behavior
of the solution, i.e., T large. Indeed, the less demanding condition (8.11) allows for
exponential growth with T.
We now see that the reason for Remark8.10 is that the eigenvalues of an inverse
matrix are just the inverses of the eigenvalues of that matrix.
‚ñ°
Let us apply all of the above to both Euler schemes and to the leapfrog scheme. We
Ô¨Årst need to determine the eigenvalues of the kind of tridiagonal matrices involved
in these schemes.
Lemma 8.1 Consider the N √ó N matrix
A =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éù
a b
0 ¬∑ ¬∑ ¬∑ 0
b a
b ¬∑ ¬∑ ¬∑ 0
... ... ... ... ...
0 ¬∑ ¬∑ ¬∑ b
a b
0 ¬∑ ¬∑ ¬∑ 0
b a
‚éû
‚éü‚éü‚éü‚éü‚éü‚é†
,
with a, b ‚ààR. The eigenvalues of A are given by
Œªp = a + 2b cos
 pœÄ
N + 1

, p = 1, . . . , N.
Proof We have A = aI + bB with B =
‚éõ
‚éú‚éú‚éú‚éú‚éù
0 1 ¬∑ ¬∑ ¬∑ 0
1 ... ... ...
... ... ... 1
0 ¬∑ ¬∑ ¬∑ 1 0
‚éû
‚éü‚éü‚éü‚éü‚é†
. Of course, AV = ŒªV is equiv-
alent to BV = Œª‚àía
b V . It is thus sufÔ¨Åcient to Ô¨Ånd the eigenvalues of B.
Let V ‚ààRN\{0} be an eigenvector of B associated with the eigenvalue Œª. We thus
have

8.5 Stability for One Time Step Schemes in the 2, h Norms
277
V2 = ŒªV1,
V1 + V3 = ŒªV2,
...
Vj‚àí1 + Vj+1 = ŒªVj,
...
VN‚àí1 = ŒªVN.
If we set V0 = VN+1 = 0, we see that the components of V are a solution of the
linear homogeneous recurrence relation with constant coefÔ¨Åcients
Vj‚àí1 ‚àíŒªVj + Vj+1 = 0, for j = 0, . . . , N.
It is well known that the general solution of such a recurrence relation depends on
the roots of its characteristic equation r2 ‚àíŒªr + 1 = 0. There are two roots r1 and
r2 which are such that r1 + r2 = Œª and r1r2 = 1. If the roots are simple, we have
Vj = Œ±rj
1 + Œ≤rj
2, and if there is a double root, Vj = (Œ± + Œ≤j)rj, where Œ± and Œ≤ are
constants to be determined.
Now the question is: given Œª, can we Ô¨Ånd Œ± and Œ≤ such that V0 = VN+1 = 0
with V Ã∏= 0 (this is a kind of boundary value problem in a sense)? In the case of a
double root, clearly these conditions imply Œ± = Œ≤ = 0, hence such a Œª cannot be an
eigenvalue. Let us thus consider the case of simple roots. We are thus requiring that
0 = V0 = Œ± + Œ≤ and 0 = VN+1 = Œ±rN+1
1
+ Œ≤rN+1
2
.
Therefore, we see that Œª is an eigenvalue if and only if rN+1
1
= rN+1
2
. Multiplying
this equation by rN+1
1
, it follows that r2(N+1)
1
= 1. Consequently, r1 and r2 must be
of the form
r1 = ei pœÄ
N+1 ,
r2 = e‚àíi pœÄ
N+1
for some integer p. It follows that the eigenvalues are necessarily of the form
Œªp = ei pœÄ
N+1 + e‚àíi pœÄ
N+1 = 2 cos
 pœÄ
N + 1

.
Conversely, it is easy to check that the vector Vp given by (Vp)j = sin
 jpœÄ
N+1

, j =
1, . . . , N, is an associated eigenvector. For p = 1, . . . , N, we have thus obtained N
distinct eigenvalues, hence we have found them all.
‚ñ°
Let us remark that the vectors Vp are eigenvectors for all matrices A independently
of the values of a and b.

278
8
The Finite Difference Method for the Heat Equation
Corollary 8.4 The eigenvalues of Ah are
Œªp = 4
h2 sin2
pœÄ
2(N + 1)

, p = 1, . . . , N.
Proof Apply the previous Lemma with a = 2
h2 and b = ‚àí1
h2 .
‚ñ°
We now return to the explicit Euler scheme (8.4).
Proposition 8.8 Let S ‚äÇR‚àó
+ √ó R‚àó
+. The explicit three-point Euler scheme is stable
for the norms ‚à•¬∑ ‚à•2,h under condition S if and only if
S ‚äÇ

(h, k); k
h2 cos2œÄh
2

‚â§1
2 + Ck

,
(8.12)
for some C ‚â•0. In this case, it is convergent for these norms and we have the error
estimate
max
j‚â§T/k ‚à•Uj ‚àíSh(utj)‚à•2,h ‚â§Ch2,
where C depends only on u and T.
Proof First of all, since B‚àí1
1
= kI so that |||B‚àí1
1 |||2,h = k, we can apply Proposition8.3.
We have A = I ‚àíkAh. It is a real symmetric matrix, hence a normal matrix. We may
thus apply Proposition8.7. We have
œÅ(A ) = max
1‚â§p‚â§N
1 ‚àí4k
h2 sin2
pœÄ
2(N + 1)

= max

1 ‚àí4k
h2 sin2
œÄ
2(N + 1)

, 4k
h2 sin2
NœÄ
2(N + 1)

‚àí1

.
The Ô¨Årst expression in the maximum is always between 0 and 1. We thus just need
to consider the second expression. Condition (8.12) is then a simple rewriting of
condition (8.11).
‚ñ°
Remark 8.15 Note that if k
h2 ‚â§1
2, then k
h2 cos2 œÄh
2

‚â§1
2 for all h and k. The region

(h, k); k
h2 ‚â§1
2

is thus a stability region, as was the case for the ‚àû, h norm. Besides,
convergence in the ‚àû, h norm implies convergence in the 2, h norm, so that nothing
new is gained in this case.
We know a little more about instability in the 2, h norm, which on the other hand
does not directly imply instability in the ‚àû, h norm. However, using the converse part
of the Lax theorem, if the scheme is unstable in the 2, h norm, it is not convergent in
the 2, h norm. Therefore, it is not convergent in the ‚àû, h norm. Since it is consistent
in the ‚àû, h norms, it is thus unstable for that same norm.
In this respect, it is in any case better to choose h and k such that
k
h2 ‚â§1
2, since
in this case, we are assured that |||A |||2,h = œÅ(A ) < 1, which is numerically a good
thing. In particular, a spectral radius which is strictly larger than 1 manifests itself

8.5 Stability for One Time Step Schemes in the 2, h Norms
279
Fig. 8.3 The boundaries of a
few stability regions deÔ¨Åned
in the (h; k) plane by formula
(8.12) for different values of
C (C = 0, 0.1, 0.2, 0.3, 0.4)
and of the ‚Äúsafe‚Äù region
k ‚â§h2/2 dashed. They are
all tangent at (0, 0)
0
0,5
1
1,5
2
0,5
1
1,5
k
h
as a numerical instability, with oscillations that become very large exponentially fast
with the number of iterations as we will see in a few examples later, even though this
particular choice of values for h and k belongs to a stability region in the previous
sense.
‚ñ°
We see from Fig.8.3 that there is no practical difference between the different
stability regions where it counts, that is to say in a neighborhood of (0, 0). Let us
now turn to the implicit Euler scheme (8.5).
Proposition 8.9 The implicit Euler three-point scheme is unconditionally stable for
the norms ‚à•¬∑ ‚à•2,h. It is convergent for these norms and we have the error estimate
max
j‚â§T/k ‚à•Uj ‚àíSh(utj)‚à•2,h ‚â§C(h2 + k),
where C depends only on u and T.
Proof We have A = (I + kAh)‚àí1, which is real symmetric, hence normal. Its eigen-
values are
Œªp =
1
1 + 4k
h2 sin2
pœÄ
2(N+1)
, p = 1, . . . , N,
and are all between 0 and 1. Hence œÅ(A ) < 1 for all h and k, and since B‚àí1
0
= kA ,
the scheme is unconditionally stable.
‚ñ°
Remark 8.16 We see here the great advantage of the implicit Euler scheme over the
explicit Euler scheme. The number of time iterations needed to reach a given time
T is not constrained by the space step.
In this example, we also see why the 2, h norms are easier to work with than the
‚àû, h norms, for such an implicit scheme.
We plot in Fig.8.4 the solution of the implicit Euler scheme corresponding to
u0(x) = 4x(1 ‚àíx) at T = 1.1 and N = M ranging from 120 to 240 by increments
of 12. Only the discrete values are drawn, no linear interpolation.

280
8
The Finite Difference Method for the Heat Equation
Fig. 8.4 Convergence of the
implicit Euler scheme
0.0e+00
5.0e-06
1.0e-05
1.5e-05
2.0e-05
2.5e-05
3.0e-05
3.5e-05
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
In the above computations, k
h2 range from approximately 100 to 200, with no ill
effect of course.
‚ñ°
We Ô¨Ånally deal with the leapfrog scheme (8.6). The leapfrog scheme is a two time
step scheme with the general form
B1uj+1 + B0Uj + B‚àí1Uj‚àí1 = Fj
with
B1 = 1
2k I, B0 = Ah, B‚àí1 = ‚àí1
2k I and Fj = Fj.
As in the general case, we rewrite it as a single time step scheme by setting
V j =
 Uj
Uj‚àí1

‚ààR2N,
so that
V j+1 = A V j + Gj,
where
A =
‚àí2kAh I
I
0

(8.13)
is the 2N √ó 2N symmetric ampliÔ¨Åcation matrix and Gj ‚ààR2N. Since |||B‚àí1
1 |||2,h = 2k,
Proposition8.3 applies. However, instead of using the norm used in this proposition,
we use the matrix norm induced by the canonical Euclidean norm on R2N, which is
equivalent. Indeed,
1
‚àö
2
(‚à•U1‚à•2
2,h + ‚à•U2‚à•2
2,h)1/2 ‚â§max(‚à•U1‚à•2,h, ‚à•U2‚à•2,h) ‚â§(‚à•U1‚à•2
2,h + ‚à•U2‚à•2
2,h)1/2
for all U1, U2 ‚ààRN. We thus just need to Ô¨Ånd the spectral radius of the matrix A .

8.5 Stability for One Time Step Schemes in the 2, h Norms
281
Lemma 8.2 Let C be a N √ó N complex matrix and B the 2N √ó 2N complex matrix
deÔ¨Åned by blocks as
B =
C I
I 0

,
where I (resp. 0) is the N √ó N identity (resp. zero) matrix. If Œª ‚ààC is an eigenvalue of
B, then Œª Ã∏= 0 and Œª ‚àí1
Œª is an eigenvalue of C. Conversely, if Œº ‚ààC is an eigenvalue
of C, then there exists an eigenvalue Œª of B such that Œº = Œª ‚àí1
Œª.
Proof Let Œª ‚ààC be such that there exists a vector Y in C2N, Y =
Y1
Y2

, Y Ã∏= 0, such
that BY = ŒªY. Using the block structure of B, we see that this is equivalent to

CY1 + Y2 = ŒªY1,
Y1 = ŒªY2.
If Y1 = 0, the Ô¨Årst equation implies that Y2 = 0, which is impossible. Thus Y1 Ã∏= 0,
which implies Œª Ã∏= 0 by the second equation. We may thus divide by Œª so that
Y2 = 1
ŒªY1 and replacing in the Ô¨Årst equation CY1 =

Œª ‚àí1
Œª

Y1. Since we have already
seen that Y1 Ã∏= 0, this implies that Œª ‚àí1
Œª is an eigenvalue of C.
Conversely, let Œº ‚ààC be an eigenvalue of C with eigenvector Y1 ‚ààCN, Y1 Ã∏= 0.
The polynomial X2 ‚àíŒºX ‚àí1 has two roots in C, which are nonzero since their
product is ‚àí1. Let Œª be one of these roots. Dividing by Œª, we see that Œª ‚àíŒº ‚àí1
Œª = 0,
hence Œº = Œª ‚àí1
Œª. Furthermore
B
 Y1
1
ŒªY1

=

CY1 + 1
ŒªY1
Y1

=

Œº + 1
Œª

Y1
Y1

= Œª
 Y1
1
ŒªY1

,
so that Œª is an eigenvalue of B.
‚ñ°
Remark 8.17 If Œª is an eigenvalue of B, then ‚àí1
Œª is also an eigenvalue of B. This
pair corresponds to the same eigenvalue Œº of C.
‚ñ°
Let us now apply this to the leapfrog scheme.
Proposition 8.10 The leapfrog scheme is unstable for the norms ‚à•¬∑ ‚à•2,h, hence not
convergent for these norms.
Proof The matrix A deÔ¨Åned by (8.13) is real symmetric, hence normal. We may
thus apply Proposition8.7 with the equivalence of matrix norms noted before.
The eigenvalues of the matrix ‚àí2kAh are
Œºp = ‚àí8k
h2 sin2
pœÄ
2(N + 1)

, p = 1, . . . , N,
and those of the matrix A

282
8
The Finite Difference Method for the Heat Equation
Œª¬±
p =
Œºp ¬±

Œº2p + 4
2
according to Lemma8.2. In particular, for p = N, we have
sin2
NœÄ
2(N + 1)

= cos2
œÄ
2(N + 1)

‚â•1
2
since
œÄ
2(N+1) ‚â§œÄ
4 . Therefore
‚àíŒºN ‚â•4k
h2 .
It follows that
œÅ(A ) ‚â•

ŒºN ‚àí

Œº2
N + 4
2
 =

Œº2
N + 4 ‚àíŒºN
2
‚â•2 + 4k
h2
2
= 1 + 2k
h2 .
Consequently, there is no constant C ‚â•0 such that œÅ(A ) ‚â§1 + Ck. Indeed, assume
there was such a constant, for (h, k) in some region S . Then we would have 2
h2 ‚â§C,
which precludes h ‚Üí0. This is inconsistent with (0, 0) ‚àà
¬Ø
S .
‚ñ°
Remark 8.18 The leapfrog scheme is thus not usable in practice for solving the heat
equation. Numerical experiments show that it may diverge very rapidly. We remark
in addition that
œÅ(A M+1) ‚â•

1 + 2k
h2
M+1
‚â•1 + 2(M + 1)k
h2
= 1 + 2T
h2 ‚Üí+‚àûwhen h ‚Üí0.
The same is true for any number of iterations needed to reach a Ô¨Åxed
time T > 0.
‚ñ°
Figure8.5 shows a sequence of plots corresponding to the leapfrog method applied
to u0(x) = 4x(1 ‚àíx) at T = 1.1 for N = M ranging from 3 to 18. Notice the vertical
scale on the plots. The maximum of the exact solution u at time T is of the order of
2 √ó 10‚àí5.
8.6
Stability via the Discrete Fourier Transform
From now on, and for the rest of this chapter, we concentrate on stability criteria
without reference to consistency and convergence, but nonetheless keeping the Lax
theorem in mind. Let us thus present a slightly, although not fundamentally different
way of dealing with stability using the discrete Fourier transform. We consider here
periodic boundary conditions instead of Dirichlet conditions. More precisely, we
are interested in the restriction to [0, 1] √ó R‚àó
+ of functions that are 1-periodic in

8.6 Stability via the Discrete Fourier Transform
283
-15000
-10000
-5000
0
5000
10000
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
N = M = 3
-3e+09
-2e+09
-1e+09
0e+00
1e+09
2e+09
3e+09
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
N = M = 6
-8e+15
-6e+15
-4e+15
-2e+15
0e+00
2e+15
4e+15
6e+15
8e+15
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
N = M = 9
-8e+22
-6e+22
-4e+22
-2e+22
0e+00
2e+22
4e+22
6e+22
8e+22
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
N = M = 12
0.0e+00
5.0e+29
1.0e+30
1.5e+30
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
N = M = 15
-8e+37
-6e+37
-4e+37
-2e+37
0e+00
2e+37
4e+37
6e+37
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
N = M = 18
Fig. 8.5 Divergence of the leapfrog method
space and that satisfy the heat equation on R‚àó
+ √ó R with zero right-hand side. Such
functions are regular and thus obey the following system
‚éß
‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é©
‚àÇu
‚àÇt (x, t) ‚àí‚àÇ2u
‚àÇx2 (x, t) = 0 in Q,
u(x, 0) = u0(x) in Œ©,
u(0, t) = u(1, t) in ]0, T[,
‚àÇu
‚àÇx (0, t) = ‚àÇu
‚àÇx (1, t) in ]0, T[.
(8.14)

284
8
The Finite Difference Method for the Heat Equation
It is easy to check that if u0 satisÔ¨Åes the same boundary conditions, it is given by
its Fourier series expansion u0(x) = a0
2 + +‚àû
l=1 al cos(2lœÄx) + +‚àû
l=1 bl sin(2lœÄx).
In this case, the unique solution to (8.14) is given by
u(x, t) = a0
2 +
+‚àû

l=1
e‚àí4l2œÄ2tal cos(2lœÄx) +
+‚àû

l=1
e‚àí4l2œÄ2tbl sin(2lœÄx),
using similar arguments as in Sect.7.3. It is also possible to write a weak formulation
for this periodic problem.
Up to now, the vectors Uj were always computed in the canonical basis of RN.
It turns out that there is another basis that is better adapted to the study of Ô¨Ånite
difference schemes, provided that we are willing to replace R by C. In this basis, the
Fourier basis, computations are straightforward.
We use the same space-time grid as before, but due to the change of bound-
ary conditions, the forward Euler scheme involves unknowns uj
n, ‚àí1 ‚â§n ‚â§N + 1,
0 ‚â§j ‚â§M, with
‚éß
‚é™‚é™‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é™‚é™‚é©
uj+1
n
‚àíuj
n
k
‚àíuj
n+1 ‚àí2uj
n + uj
n‚àí1
h2
= 0 for n = 0, . . . , N, j = 0, . . . , M,
u0
n = u0(xn) for n = 0, . . . , N + 1,
uj
0 = uj
N+1 for j = 0, . . . , M,
uj
‚àí1 = uj
N for j = 0, . . . , M.
(8.15)
The relation uj
0 = uj
N+1 is a discretization of the periodicity condition u(0, t) =
u(1, t), and the relation uj
‚àí1 = uj
N combined with the previous one discretizes
the other periodicity condition ‚àÇu
‚àÇx (0, t) = ‚àÇu
‚àÇx (1, t). Indeed, ‚àÇu
‚àÇx (0, t) ‚âà
uj
0‚àíuj
‚àí1
h
and
‚àÇu
‚àÇx (1, t) ‚âà
uj
N+1‚àíuj
N
h
.
We assume of course that u0 is periodic. The corresponding vectors Uj now
live in RN+1 with components (uj
0, uj
1, . . . , uj
N) in the canonical basis. We embed
RN+1 into CN+1 in the canonical fashion. We let (U|V ) = N
m=0 um¬Øvm denote the
canonical scalar product on CN+1 and introduce the (discrete) Fourier basis of CN+1
as (œân)n=0,...,N where
(œân)m = e2iœÄ nm
N+1 , for m = 0, . . . , N.
Proposition 8.11 The family (œân)n=0,...,N is an orthogonal basis of CN+1. In fact,
we have
(œâl|œân) = (N + 1)Œ¥ln.
(8.16)
Proof It is enough to compute the scalar products (8.16). Indeed

8.6 Stability via the Discrete Fourier Transform
285
(œâl|œân) =
N

m=0
e2iœÄ
lm
N+1 e‚àí2iœÄ nm
N+1 =
N

m=0
e2iœÄ (l‚àín)m
N+1 =

N + 1
if l = n,
1‚àíe2iœÄ(l‚àín)
1‚àíe2iœÄ l‚àín
N+1 = 0 if l Ã∏= n.
We therefore have an orthogonal, hence linearly independent family of vectors, the
cardinal of which is equal to the dimension of the C-vector space CN+1. It is thus a
basis.
‚ñ°
We now are at liberty to decompose Uj on this basis
Uj =
N

n=0
cj
nœân with cj
n =
1
N + 1(Uj|œân) =
1
N + 1
N

m=0
uj
me2iœÄ nm
N+1 ,
and read the scheme on the discrete Fourier coefÔ¨Åcients cj
n.
Proposition 8.12 We have
cj+1
n
=

1 ‚àí4k
h2 sin2 œÄn
N + 1

cj
n,
and therefore
cj
n =

1 ‚àí4k
h2 sin2 œÄn
N + 1
j
c0
n,
where c0
n are the discrete Fourier coefÔ¨Åcients of the initial condition.
Proof The key observation here is that the space Ô¨Ånite difference operator acts by
multiplication on the Fourier basis vectors. In other words, these vectors are eigen-
vectors of the Ô¨Ånite difference operator. Indeed, for m = 0, . . . , N,
‚àí(œâl)m‚àí1 + 2(œâl)m ‚àí(œâl)m+1
h2
= ‚àíe‚àí2iœÄ
l
N+1 + 2 ‚àíe2iœÄ
l
N+1
h2
e2iœÄ
lm
N+1
= 2
h2

1 ‚àícos
 2œÄl
N + 1

(œâl)m,
with (œâl)‚àí1 = (œâl)N and (œâl)N+1 = (œâl)0 by convention, and the corresponding
eigenvalue is
Œªl = 4
h2 sin2
œÄl
N + 1

.
The result now follows from the Ô¨Årst equation in system (8.15) by linearity.
‚ñ°
Now it is clear that we can analyze other schemes in the case of periodic boundary
conditions, such as the backward Euler scheme or the leapfrog scheme, with the
discrete Fourier transform.
DeÔ¨Ånition 8.7 We say that a scheme is stable in the sense of von Neumann if |cj+1
n
| ‚â§
|cj
n| for all relevant n and j and all initial condition u0.

286
8
The Finite Difference Method for the Heat Equation
We have ‚à•œân‚à•2,h = 1 for all n, therefore ‚à•Uj‚à•2
2,h = N
n=0 |cj
n|2. Thus, stability in
the sense of von Neumann implies stability for the 2, h norms for all T and uniformly
with respect to T.
Proposition 8.13 The forward Euler scheme is stable in the sense of von Neumann
if k
h2 ‚â§1
2.
Proof Assume that k
h2 ‚â§1
2. In view of Proposition8.12, von Neumann stability oc-
curs if and only if
1 ‚àí4k
h2 sin2 œÄn
N + 1
 ‚â§1
for all n, that is to say if
2k
h2 sin2 œÄn
N + 1

‚â§1
for all n. This is obviously the case under our hypothesis.
‚ñ°
Similarly, we Ô¨Ånd that the backward Euler scheme is unconditionally von Neu-
mann stable.
8.7
Stability via Fourier Series
Stability for the 2, h norms is closely related to the spectral radius of the ampliÔ¨Åcation
matrix, at least when the latter is normal. Unfortunately, it is not always easy to com-
pute the eigenvalues of a given matrix. We now present an alternate way using Fourier
series, which is not directly applicable to the previously introduced schemes‚Äîin fact
it applies to a slightly different context‚Äîbut that still gives stability information in
a much more workable fashion.
We thus now work with the heat equation on R, therefore without boundary
conditions. For deÔ¨Åniteness, let us consider the forward Euler scheme
‚éß
‚é™‚é®
‚é™‚é©
uj+1
n
‚àíuj
n
k
‚àíuj
n+1 ‚àí2uj
n + uj
n‚àí1
h2
= 0, n ‚ààZ,
u0
n = u0(nh), n ‚ààZ.
(8.17)
As in the previously considered cases, the discrete unknowns uj
n are intended to be
approximations of the exact values of the solution u(xn, tj), n ‚ààZ, j = 1, . . . , M. We
also write u0 = Sh(u0) to denote the sampling operator on all grid points indexed by
Z.
If we assume that (u0
n)n‚ààZ ‚àà‚Ñì2(Z), i.e., that 
n‚ààZ |u0
n|2 < +‚àû, then it is quite
clear that (uj
n)n‚ààZ is well deÔ¨Åned and belongs to ‚Ñì2(Z) for all j. We equip ‚Ñì2(Z) with
the norm

8.7 Stability via Fourier Series
287
‚à•(vn)n‚ààZ‚à•2,h =
‚àö
h

n‚ààZ
|vn|21/2
for which it is a Hilbert space, using the same notation as in the bounded interval case.
Of course, the forward Euler scheme is also deÔ¨Åned on other spaces of Z-indexed
sequences, but we concentrate here on ‚Ñì2. It should be noted that such schemes are
not implementable in practice, since they involve an inÔ¨Ånite number of unknowns.
Their interest is purely theoretical.
We introduce the operator T : ‚Ñì2(Z) ‚Üí‚Ñì2(Z) deÔ¨Åned by
(T v)n = Œªvn+1 + (1 ‚àí2Œª)vn + Œªvn‚àí1,
with Œª = k
h2 . Then the scheme reads
uj+1 = T uj,
u0 = Sh(u0),
(8.18)
or
uj = T ju0,
for j = 0, . . . , M.10 We introduce a concept of stability adapted to the present context.
DeÔ¨Ånition 8.8 We say that the scheme (8.17) is stable in ‚Ñì2(Z) if there exists a
constant C(T) such that
max
j‚â§T/k ‚à•uj‚à•2,h ‚â§C(T)‚à•u0‚à•2,h,
for all u0 ‚àà‚Ñì2(Z).
Now
for
all
v ‚àà‚Ñì2(Z; C),
we
deÔ¨Åne
Fv ‚ààL2(0, 2œÄ; C)
by
Fv(s) =

n‚ààZ vneins. It is well-known that the series converges in L2(0, 2œÄ; C) and that
operator F is an isometry between ‚Ñì2(Z; C) and L2(0, 2œÄ; C), when we equip the
latter with the norm
‚à•f ‚à•L2(0,2œÄ;C),h =

h
2œÄ
 2œÄ
0
|f (s)|2 ds
1/2
,
due to Parseval‚Äôs formula, see [68]. The coefÔ¨Åcients vk are just the Fourier coefÔ¨Åcients
of the 2œÄ-periodic L2-function Fv. Conversely, any 2œÄ-periodic L2-function gives
rise to an element of ‚Ñì2(Z; C) by considering its Fourier coefÔ¨Åcients. For brevity,
from now on we omit the reference to C in the notation. The next proposition follows
directly from Parseval‚Äôs formula.
10Again, beware of the notation: uj is the jth element in the sequence, whereas T j is the jth iterate
of the operator T .

288
8
The Finite Difference Method for the Heat Equation
Proposition 8.14 The scheme (8.17) is stable in ‚Ñì2(Z) if and only if there exists a
constant C(T) such that
max
j‚â§T/k ‚à•Fuj‚à•L2(0,2œÄ),h ‚â§C(T)‚à•Fu0‚à•L2(0,2œÄ),h,
for all u0 ‚àà‚Ñì2(Z).
We let G = F ‚ó¶T ‚ó¶F ‚àí1. Since uj = T ju0, it follows that Fuj = G j(Fu0).
Therefore we have the following proposition.
Proposition 8.15 The scheme (8.17) is stable in ‚Ñì2(Z) if there exists a constant C(T)
such that
max
j‚â§T/k ‚à•G j‚à•L (L2(0,2œÄ)) ‚â§C(T).
Before continuing further, let us discuss the relationship between the initial data
of the continuous problem, the function u0, and the initial data of the discrete scheme,
the sequence u0, in the L2/‚Ñì2 framework. We need to associate a function in L2(R)
with each sequence of numbers belonging to ‚Ñì2(Z).
Proposition 8.16 For all v ‚àà‚Ñì2(Z), we deÔ¨Åne a piecewise constant interpolation
Ihv by
‚àÄi ‚ààZ, ‚àÄx ‚àà

xn ‚àíh
2, xn + h
2
 
,
Ihv(x) = vn.
The interpolation operator Ih is an isometry between ‚Ñì2(Z) equipped with the ‚à•¬∑ ‚à•2,h
norm and L2(R) equipped with its usual norm.
Proof Indeed,
‚à•Ihv‚à•2
L2(R) =

R
Ihv(x)2 dx =

n‚ààZ
 xn+ h
2
xn‚àíh
2
Ihv(x)2 dx =

n‚ààZ
hv2
n = ‚à•v‚à•2
2,h,
and the proof is complete.
‚ñ°
We can now see in which sense the stability deÔ¨Ånition (DeÔ¨Ånition8.8) relates to the
continuous problem, in the sense that Fu0 ‚ààL2(0, 2œÄ) contains enough information
about the function u0 deÔ¨Åned on R, under some mild regularity assumption.
Proposition 8.17 Assume that u0 ‚ààH1(R), then we have
‚à•u0 ‚àíIhu0‚à•L2(R) ‚â§h
2‚à•u‚Ä≤
0‚à•L2(R).
Proof Since u0 ‚ààH1(R), by formula (3.12), we have for all x ‚ààR and all n ‚ààZ
u0(x) ‚àíu0(nh) =
 x
nh
u‚Ä≤
0(z) dz.

8.7 Stability via Fourier Series
289
Therefore
 nh+ h
2
nh‚àíh
2
|u0(x) ‚àíu0(nh)|2 dx =
 nh+ h
2
nh‚àíh
2

 x
nh
u‚Ä≤
0(z) dz

2
dx
‚â§
 nh+ h
2
nh‚àíh
2

|x ‚àính|
 x
nh
|u‚Ä≤
0(z)|2 dz

dx
‚â§
 nh+ h
2
nh‚àíh
2
|x ‚àính| dx
  nh+ h
2
nh‚àíh
2
|u‚Ä≤
0(z)|2 dz
= h2
4
 nh+ h
2
nh‚àíh
2
|u‚Ä≤
0(z)|2 dz.
Summing over n ‚ààZ, we obtain the Proposition.
‚ñ°
Under the above hypothesis, we thus have
‚à•Fu0‚à•L2(0,2œÄ),h = ‚à•Shu0‚à•2,h = ‚à•Ihu0‚à•L2(R) ‚â§
‚àö
2‚à•u0‚à•H1(R)
for h ‚â§2. Therefore, if the scheme is stable in ‚Ñì2(Z) in the sense of DeÔ¨Ånition8.8,
it follows that
max
j‚â§T/k ‚à•uj‚à•2,h ‚â§
‚àö
2C(T)‚à•u0‚à•H1(R).
The feature of the Fourier series transform that makes it so useful here, in addition
to being an isometry, is that it transforms translations of indices into multiplications
by exponentials. More precisely, if v ‚àà‚Ñì2(Z) and m ‚ààZ, letting (œÑmv)n = vn+m, then
F(œÑmv)(s) =

n‚ààZ
vn+meins =

n‚ààZ
vnei(n‚àím)s = e‚àíimsFv(s).
Proposition 8.18 Let a(s) = 1 ‚àí4Œª sin2 s
2

. Then we have
‚à•G j‚à•L (L2(0,2œÄ)) = max
s‚àà[0,2œÄ] |a(s)|j.
Proof We apply the Fourier series transform to the scheme in the form (8.18). This
yields
F(uj+1)(s) =

1 + Œª(eis ‚àí2 + e‚àíis)

F(uj)(s) = a(s)F(uj)(s).
Iterating this relation, we obtain for all g ‚ààL2(0, 2œÄ)11
(G jg)(s) = a(s)jg(s).
11Again, beware of the notation: here G j is the jth iterate of G and aj is the function a to the power j.

290
8
The Finite Difference Method for the Heat Equation
Let now M be a multiplier operator, i.e., an operator on L2(0, 2œÄ) of the form
(Mg)(s) = m(s)g(s),
with m ‚ààL‚àû(0, 2œÄ), which is the case of G j above. Let us show that
‚à•M‚à•L (L2(0,2œÄ)) = ‚à•m‚à•L‚àû(0,2œÄ).
First of all, for all g ‚ààL2(0, 2œÄ), we have
‚à•Mg‚à•2
L2(0,2œÄ),h = h
2œÄ
 2œÄ
0
|m(s)|2||g(s)|2 ds ‚â§‚à•m‚à•2
L‚àû(0,2œÄ)‚à•g‚à•2
L2(0,2œÄ),h,
so that
‚à•M‚à•L (L2(0,2œÄ)) ‚â§‚à•m‚à•L‚àû(0,2œÄ).
Next, let ‚à•m‚à•L‚àû(0,2œÄ) ‚â•Œµ > 0 and A ‚äÇ[0, 2œÄ] be a set of strictly positive measure
such that |m(t)| ‚â•‚à•m‚à•L‚àû(0,2œÄ) ‚àíŒµ ‚â•0 on A, assuming m Ã∏= 0 since the case m = 0
is not difÔ¨Åcult. We take g = ( h meas A
2œÄ
)‚àí1/21A ‚ààL2(0, 2œÄ). Then ‚à•g‚à•L2(0,2œÄ),h = 1 and
‚à•Mg‚à•2
L2(0,2œÄ),h = h
2œÄ
 2œÄ
0
|m(s)|2|g(s)|2 ds =
1
meas A

A
|m(s)|2 ds
‚â•(‚à•m‚à•L‚àû(0,2œÄ) ‚àíŒµ)2
meas A

A
ds = (‚à•m‚à•L‚àû(0,2œÄ) ‚àíŒµ)2.
Therefore
‚à•M‚à•L (L2(0,2œÄ)) ‚â•‚à•m‚à•L‚àû(0,2œÄ) ‚àíŒµ
for all Œµ > 0, and the proposition is proved, since in our particular case, the function
m = aj is continuous on [0, 2œÄ] and its L‚àûnorm is just the maximum of its absolute
value on [0, 2œÄ].
‚ñ°
Proposition 8.19 TheforwardEulerschemeisstablein‚Ñì2(Z)if k
h2 ‚â§1
2 andunstable
if k
h2 ‚â•Œª0 > 1
2.
Proof We have a(s) = 1 ‚àí4k
h2 sin2 s
2

‚â§1 for all s ‚àà[0, 2œÄ] and a(0) = 1. On the
other hand, the minimum of a(s) is attained for s
2 = œÄ
2 and its minimum value is
1 ‚àí4k
h2 . Therefore
max
s‚àà[0,2œÄ] |a(s)| = max

1,
1 ‚àí4k
h2


.
Consequently, if k
h2 ‚â§1
2, then maxs‚àà[0,2œÄ] |a(s)| = 1 so that ‚à•G j‚à•L (L2(0,2œÄ)) = 1 and
the scheme is stable in ‚Ñì2(Z).
If, on the other hand, k
h2 ‚â•Œª0 > 1
2, then

8.7 Stability via Fourier Series
291
max
s‚àà[0,2œÄ] |a(s)|j ‚â•(4Œª0 ‚àí1)j,
so that
max
j‚â§T/k max
s‚àà[0,2œÄ] |a(s)|j ‚â•(4Œª0 ‚àí1)T/k ‚Üí+‚àûwhen k ‚Üí0,
hence the scheme is unstable.
‚ñ°
We can apply the same philosophy to a general single time step Ô¨Ånite differ-
ence scheme and obtain corresponding schemes on ‚Ñì2(Z) which are of the form
F(uj+1)(s) = a(s)F(uj)(s), F(u0) given, in Fourier space. The function a, which
depends onh andk as parameters, is calledtheampliÔ¨ÅcationcoefÔ¨Åcient of thescheme.
Using the same arguments as those used with matrices, it is easy to prove that a
scheme is stable in ‚Ñì2 if and only if there exists a positive constant C that depends
only on T such that |a(s)| ‚â§1 + Ck for all s. We now introduce the analogue of the
previous notion of von Neumann stability (DeÔ¨Ånition8.7) for schemes on ‚Ñì2(Z).
DeÔ¨Ånition 8.9 We say that a scheme on ‚Ñì2(Z) is stable in the sense of von Neumann
if maxs‚àà[0,2œÄ] |a(s)| ‚â§1.
Clearly, stability in the sense of von Neumann implies stability in ‚Ñì2(Z) for all T
anduniformlywithrespect to T. It is thus asufÔ¨Åcient conditionof stability. Obviously,
computations in Fourier space are much easier than evaluations of spectral radii.
We now consider the example of a family of schemes, collectively known as the
Œ∏-scheme. Let us be given a number Œ∏ ‚àà[0, 1]. The Œ∏-scheme is as follows:
uj+1
n
‚àíuj
n
k
‚àíŒ∏
uj+1
n+1 ‚àí2uj+1
n
+ uj+1
n‚àí1
h2
‚àí(1 ‚àíŒ∏)
uj
n+1 ‚àí2uj
n + uj
n‚àí1
h2
= Œ∏f j+1
n
+ (1 ‚àíŒ∏)f j
n,
(8.19)
with initial conditions. The Œ∏-scheme is thus a weighted average of the explicit Euler
scheme (Œ∏ = 0) and the implicit Euler scheme (Œ∏ = 1). It is implicit as soon as Œ∏ > 0.
Before we can even talk about stability, it is not clear that such an implicit scheme is
actually well-deÔ¨Åned on ‚Ñì2(Z). The Fourier transform is also the key here. Indeed,
in Fourier space, we have (with f = 0)
F(uj+1)(s) ‚àíF(uj)(s)
k
‚àíŒ∏ eis ‚àí2 + e‚àíis
h2
F(uj+1)(s)
‚àí(1 ‚àíŒ∏)eis ‚àí2 + e‚àíis
h2
F(uj)(s) = 0,
which boils down to

1 + Œ∏ 4k
h2 sin2 s
2

F(uj+1)(s) =

1 ‚àí(1 ‚àíŒ∏)4k
h2 sin2 s
2

F(uj)(s).

292
8
The Finite Difference Method for the Heat Equation
Now we see that 1 + Œ∏ 4k
h2 sin2 s
2

‚â•1, hence, its inverse is in L‚àûand the scheme in
Fourier space can be rewritten as a multiplier operator with ampliÔ¨Åcation coefÔ¨Åcient
a(s) = 1 ‚àí(1 ‚àíŒ∏) 4k
h2 sin2 s
2

1 + Œ∏ 4k
h2 sin2 s
2

‚ààL‚àû(0, 2œÄ).
The fact that the Fourier transform is an isomorphism implies that the discrete scheme
is well-deÔ¨Åned.
Now in terms of stability, clearly, a(s) ‚â§1 for all s ‚àà[0, 2œÄ]. Stability in the
sense of von Neumann thus depends on whether or not we have a(s) ‚â•‚àí1 for all
s ‚àà[0, 2œÄ].
Proposition 8.20 If Œ∏ ‚â•1
2, then the Œ∏-scheme is unconditionally stable in the sense
of von Neumann. If Œ∏ < 1
2, it is stable in the sense of von Neumann under the condition
k
h2 ‚â§
1
2(1‚àí2Œ∏).
Proof After a little bit of computation, it can be checked that a(s) ‚â•‚àí1 if and only
if 1 + (2Œ∏ ‚àí1) 2k
h2 sin2 s
2

‚â•0, hence the result.
‚ñ°
The case Œ∏ = 1
2 is special and is called the Crank‚ÄìNicolson scheme. We will go
back to this scheme in detail in Sect.8.9.
8.8
Stability via the Continuous Fourier Transform
We now present yet another approach to stability, using this time the continuous
Fourier transform. Again, this approach is not directly applicable to discrete schemes,
but it makes computations much easier. The ensuing stability analysis turns out to
be very similar to the one done via Fourier series, and we actually basically use the
same notation.
We thus consider again the heat equation on R with zero right-hand side and start
with the forward Euler scheme (8.17) in the ‚Ñì2(Z) context.
Instead of working directly with the above discrete scheme, we introduce a semi-
discrete version of it. In a semi-discrete scheme, only time is fully discretized. Space
is only semi-discretized in the sense that it remains continuous even though we retain
the space step h. We thus consider sequences of functions uj : R ‚ÜíR which are such
that uj is supposed to be an approximation of the function x ‚Üíu(x, tj).
The semi-discrete version of the forward Euler scheme is as follows:
‚éß
‚é®
‚é©
uj+1(x) ‚àíuj(x)
k
‚àíuj(x + h) ‚àí2uj(x) + uj(x ‚àíh)
h2
= 0,
u0(x) = u0,h(x),
(8.20)
where u0,h is some approximation of u0. So the idea is to use the differential quotient
on which the discrete scheme is based to approximate the space derivative, and the

8.8 Stability via the Continuous Fourier Transform
293
usual discrete difference quotient for the time derivative. This way, any discrete
scheme admits a semi-discrete version.
A good functional setting for this is for example L2(R). Indeed, if u0,h ‚ààLp(R),
then clearly, uj is well deÔ¨Åned and belongs to Lp(R). In effect, if u0,h ‚ààL2(R), then we
canwriteuj+1 = G(uj)whereGisthecontinuouslinearoperatorinL (L2(R), L2(R))
deÔ¨Åned by
Gv(x) = v(x) + k
h2 (v(x + h) ‚àí2v(x) + v(x ‚àíh)),
(8.21)
or equivalently
G =

1 ‚àí2k
h2

I + k
h2

œÑh + œÑ‚àíh

,
where œÑs denotes the operator of translation by s, œÑsu(x) = u(x + s). Therefore,
uj = Gj(u0,h) and the properties of the scheme are the properties of the iterates
of the operator G, provided u0,h remains bounded.
Let us discuss the relationship between the fully discrete and semi-discrete points
of view. It turns out that the discrete scheme and the semi-discrete scheme are equiv-
alent when the initial data of the semi-discrete scheme is in the range of the interpo-
lation operator Ih of Proposition8.16.
Proposition 8.21 Let us be given (u0
n)n‚ààZ ‚àà‚Ñì2(Z). If u0,h = Ih

(u0
n)n‚ààZ

, then
uj = Ih

(uj
n)n‚ààZ

for all j ‚ààN.
Proof We prove this by induction on j. The statement is true for j = 0 by hypothesis.
Letusthusassumethatuj = Ih

(uj
n)n‚ààZ

.Thismeansthatforallx ‚àà
!
xn ‚àíh
2, xn + h
2
"
,
we have uj(x) = uj
n. Therefore, in view of (8.21), for the same values of x, we have
Guj(x) = uj(x) + k
h2 (uj(x + h) ‚àí2uj(x) + uj(x ‚àíh))
= uj
n + k
h2 (uj
n+1 ‚àí2uj
n + uj
n‚àí1) = uj+1
n
,
so that uj+1 = Guj = Ih

(uj+1
n
)n‚ààZ

.
‚ñ°
So the idea is that, if we start the semi-discrete scheme with an initial data
constructed by piecewise interpolation from the discrete scheme, the semi-discrete
scheme will construct exactly the same values as the discrete scheme. The advantage
is that the semi-discrete scheme works for much more general initial data, which in
turn makes the study of stability considerably easier.

294
8
The Finite Difference Method for the Heat Equation
DeÔ¨Ånition 8.10 We say that the semi-discrete scheme is stable in L2(R) if there
exists a constant C(T) such that
max
j‚â§T/k ‚à•uj‚à•L2(R) ‚â§C(T)‚à•u0,h‚à•L2(R),
for all u0,h ‚ààL2(R).
Here u0,h is no longer to be thought of as some approximation of u0. Clearly, this is
equivalent to ‚à•Gj‚à•L (L2(R),L2(R)) being bounded independently of j, h and k.12 In view
of Propositions8.16 and 8.21, stability of the semi-discrete scheme implies stability
of the discrete scheme in the ‚à•¬∑ ‚à•2,h norms, hence the interest of the approach.
The reason for singling out L2 among all Lp spaces is that the continuous Fourier
transform is an isometry on L2. Let us brieÔ¨Çy state a few facts about the continuous
Fourier transform. When u ‚ààL1(R), the Fourier transform of u is deÔ¨Åned by
#u(Œæ) = Fu(Œæ) =
1
‚àö
2œÄ
 +‚àû
‚àí‚àû
e‚àíixŒæu(x) dx.
The function #u is continuous and tends to 0 at inÔ¨Ånity. When u ‚ààL1(R) ‚à©L2(R),
it can be shown that #u also belongs to L2(R) and that ‚à•#u‚à•L2(R) = ‚à•u‚à•L2(R), which
is called the Plancherel formula, see [68]. Thus the Fourier transform extends as an
isometry to the whole of L2 by density of L1(R) ‚à©L2(R) in L2(R) (but not by the
simple Lebesgue integral formula above, which makes no sense in the L2 context).
In addition to being an isometry, the continuous Fourier transform transforms
translations into multiplications by exponentials. More precisely, if u ‚ààL1(R) and
s ‚ààR, then
$
œÑsu(Œæ) =
1
‚àö
2œÄ
 +‚àû
‚àí‚àû
e‚àíixŒæu(x + s) dx =
1
‚àö
2œÄ
 +‚àû
‚àí‚àû
e‚àíi(y‚àís)Œæu(y) dy = eisŒæ#u(Œæ),
and the equality $
œÑsu(Œæ) = eisŒæ#u(Œæ) remains true for any u ‚ààL2(R) by density.
Proposition 8.22 Let a(Œæ) = 1 ‚àí4k
h2 sin2 hŒæ
2

. Then we have
‚à•Gj‚à•L (L2(R),L2(R)) = sup
Œæ‚ààR
|a(Œæ)|j.
Proof We apply the Fourier transform to the semi-discrete scheme (8.20). This yields

uj+1(Œæ) ‚àí#uj(Œæ)
k
‚àíeihŒæ ‚àí2 + e‚àíihŒæ
h2
#uj(Œæ) = 0,
or

uj+1(Œæ) = #uj(Œæ) + 2k
h2 (cos(hŒæ) ‚àí1)#uj(Œæ),
12Here again, G depends on h and k even though the notation does not make it plain.

8.8 Stability via the Continuous Fourier Transform
295
or again

uj+1(Œæ) = a(Œæ)#uj(Œæ).
Iterating this relation, we obtain13
F(Gju0)(Œæ) = #uj(Œæ) = a(Œæ)j #
u0(Œæ).
The conclusion follows as in the proof of Proposition8.18.
‚ñ°
Proposition 8.23 The forward Euler semi-discrete scheme is stable in L2(R) if
k
h2 ‚â§1
2 and unstable if k
h2 ‚â•Œª0 > 1
2.
Proof We have a(Œæ) = 1 ‚àí4k
h2 sin2 hŒæ
2

for Œæ ‚ààR. As in the proof of Proposi-
tion8.19, we obtain
sup
Œæ‚ààR
|a(Œæ)| = max

1,
1 ‚àí4k
h2


,
and the conclusion follows along the same lines.
‚ñ°
Corollary 8.5 The forward Euler discrete scheme is stable in the ‚à•¬∑ ‚à•2,h norms if
k
h2 ‚â§1
2.
Any single time step Ô¨Ånite difference scheme has a semi-discrete version, which
is of the form
uj+1(Œæ) = a(Œæ)#uj(Œæ), #
u0 given, in Fourier space. The function a, which
depends on h and k as parameters, is again called the ampliÔ¨Åcation coefÔ¨Åcient of the
scheme.
Of course, a scheme is stable in L2 if and only if there exists a positive constant C
that depends only on T such that |a(Œæ)| ‚â§1 + Ck for all Œæ. There is also a concept
of von Neumann stability for semi-discrete schemes.
DeÔ¨Ånition 8.11 We say that a semi-discrete scheme is stable in the sense of von
Neumann if supŒæ‚ààR |a(Œæ)| ‚â§1.
Clearly, stability in the sense of von Neumann implies stability in L2(R) for all T
and uniformly with respect to T. It is thus a sufÔ¨Åcient condition of stability for both
semi-discrete and discrete schemes.
We now consider the Œ∏-scheme. The semi-discrete version of the Œ∏-scheme (with
0 right-hand side) is
uj+1(x) ‚àíuj(x)
k
‚àíŒ∏ uj+1(x + h) ‚àí2uj+1(x) + uj+1(x ‚àíh)
h2
‚àí(1 ‚àíŒ∏)uj(x + h) ‚àí2uj(x) + uj(x ‚àíh)
h2
= 0.
13Again, beware of the notation: uj is the jth function in the sequence, whereas Gj is the jth iterate
of the operator G and aj is the function a to the power j.

296
8
The Finite Difference Method for the Heat Equation
Again the scheme is implicit for Œ∏ > 0. We must show that it is well-deÔ¨Åned on
L2(R). We use of course the Fourier transform again. Indeed, in Fourier space, we
have

uj+1(Œæ) ‚àí#uj(Œæ)
k
‚àíŒ∏ eihŒæ ‚àí2 + e‚àíihŒæ
h2

uj+1(Œæ)
‚àí(1 ‚àíŒ∏)eihŒæ ‚àí2 + e‚àíihŒæ
h2
#uj(Œæ) = 0,
and the exact same computation as in the Fourier series case yields an ampliÔ¨Åcation
coefÔ¨Åcient
a(Œæ) = 1 ‚àí(1 ‚àíŒ∏) 4k
h2 sin2 hŒæ
2

1 + Œ∏ 4k
h2 sin2 hŒæ
2

‚ààL‚àû(R).
Proposition 8.24 If Œ∏ ‚â•1
2, then the semi-discrete Œ∏-scheme is unconditionally sta-
ble in the sense of von Neumann. If Œ∏ < 1
2, it is stable in the sense of von Neumann
under the condition k
h2 ‚â§
1
2(1‚àí2Œ∏).
Proof See the proof of Proposition8.20.
‚ñ°
8.9
The Crank‚ÄìNicolson Scheme, Stability via the Energy
Method
Let us Ô¨Årst talk about consistency and order of the Œ∏-scheme for problem (8.1),
deÔ¨Åned by (8.19), of which the Crank‚ÄìNicolson scheme is a special case.
Proposition 8.25 The Œ∏-scheme is of order 1 in time and 2 in space for Œ∏ Ã∏= 1
2, and
of order 2 in time and 2 in space for Œ∏ = 1
2, for the ‚àû, h norms.
Proof Let u be a sufÔ¨Åciently regular solution of problem (8.1). Let us list the results of
the application of Taylor‚ÄìLagrange expansions to the various terms, without writing
the remainders explicitly since we know that they are uniformly bounded in terms
of the relevant parameters. For the time derivative, we have
u(xn, tj+1) ‚àíu(xn, tj)
k
= ‚àÇu
‚àÇt (xn, tj) + k
2
‚àÇ2u
‚àÇt2 (xn, tj) + O(k2)
= ‚àÇu
‚àÇt (xn, tj+1) ‚àík
2
‚àÇ2u
‚àÇt2 (xn, tj+1) + O(k2)
For the space derivatives, we obtain
u(xn+1, tj) ‚àí2u(xn, tj) + u(xn‚àí1, tj)
h2
= ‚àÇ2u
‚àÇx2 (xn, tj) + O(h2)

8.9 The Crank‚ÄìNicolson Scheme, Stability via the Energy Method
297
and
u(xn+1, tj+1) ‚àí2u(xn, tj+1) + u(xn‚àí1, tj+1)
h2
= ‚àÇ2u
‚àÇx2 (xn, tj+1) + O(h2).
Therefore, combining these relations together, we see that
Œµh,k(u)j
n = Œ∏
‚àÇu
‚àÇt (xn, tj+1) ‚àí‚àÇ2u
‚àÇx2 (xn, tj+1)

+(1 ‚àíŒ∏)
‚àÇu
‚àÇt (xn, tj) ‚àí‚àÇ2u
‚àÇx2 (xn, tj)

‚àíŒ∏ k
2
‚àÇ2u
‚àÇt2 (xn, tj+1) + (1 ‚àíŒ∏)k
2
‚àÇ2u
‚àÇt2 (xn, tj) + O(k2) + O(h2)
‚àíŒ∏f j+1
n
‚àí(1 ‚àíŒ∏)f j
n.
Now we can write
‚àÇ2u
‚àÇt2 (xn, tj+1) = ‚àÇ2u
‚àÇt2 (xn, tj) + O(k).
Canceling all cancelable terms, we thus obtain
Œµh,k(u)j
n = k
1
2 ‚àíŒ∏
‚àÇ2u
‚àÇt2 (xn, tj) + O(k2) + O(h2),
and the result follows.
‚ñ°
Remark 8.19 The Œ∏-scheme for Œ∏ = 1
2, or Crank‚ÄìNicolson scheme, thus appears to
be particularly attractive: it is unconditionally (von Neumann) stable and of order 2
in time and space on R. Of course, we still have to prove the unconditional stability
of its discrete version on a bounded interval. We rewrite it here in full
‚éß
‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é©
uj+1
n
‚àíuj
n
k
‚àí
1
2h2

uj+1
n+1 ‚àí2uj+1
n
+ uj+1
n‚àí1 + uj
n+1 ‚àí2uj
n + uj
n‚àí1

= 1
2

f j+1
n
+ f j
n

u0 = u0,
uj
0 = uj
N+1 = 0.
(8.22)
The scheme is implicit, with the same computational cost as the backward Euler
scheme, since evaluating Uj+1 in terms of Uj entails solving a tridiagonal linear
system with a very similar, invertible matrix.
‚ñ°
In order to prove the stability of the discrete Crank‚ÄìNicolson scheme, we use
an argument that is the discrete analogue of the energy estimate for the continuous
equation, hence the name stability via the energy method. We Ô¨Årst need a lemma that
is a discrete version of the integration by parts formula.
Let us introduce the forward and backward difference operators
(Df v)n = vn+1 ‚àívn
h
,
(Dbv)n = vn ‚àívn‚àí1
h
,

298
8
The Finite Difference Method for the Heat Equation
which are a priori deÔ¨Åned for real-valued, Z-indexed sequences (vn)n‚ààZ. We clearly
have
Df ‚ó¶Db = Db ‚ó¶Df = D2,
where D2 is the second order centered difference operator
(D2v)n = vn+1 ‚àí2vn + vn‚àí1
h2
that was used to approximate the second order space derivative.
Of course, all these difference operators can be applied to Ô¨Ånite sequences, by
completing them with zeros to the right and to the left, which is appropriate when
dealing with homogeneous Dirichlet boundary conditions. We will be doing this
implicitly in all that follows.
Let us now establish the summation by parts formula, which is an interesting
result by itself with many other applications.
Lemma 8.3 Let v = (vn)n=1,...,N+1 and w = (wn)n=0,...,N+1. We have
N

n=1
(Df v)nwn = ‚àí
N+1

n=1
vn(Dbw)n + 1
h(vN+1wN+1 ‚àív1w0).
(8.23)
In particulier, if w0 = wN+1 = 0, then
N

n=1
(Df v)nwn = ‚àí
N+1

n=1
vn(Dbw)n.
(8.24)
Proof Let us expand the left-hand side of Eq.(8.23). We obtain
N

n=1
(Df v)nwn = 1
h
N

n=1
(vn+1 ‚àívn)wn
= 1
h
 N

n=1
vn+1wn ‚àí
N

n=1
vnwn

= 1
h
N+1

n=2
vnwn‚àí1 ‚àí
N

n=1
vnwn

= 1
h
N+1

n=1
vn(wn‚àí1 ‚àíwn) ‚àív1w0 + vN+1wN+1

= ‚àí
N+1

n=1
vn(Dbw)n + 1
h(vN+1wN+1 ‚àív1w0),
and the result follows.
‚ñ°

8.9 The Crank‚ÄìNicolson Scheme, Stability via the Energy Method
299
Remark 8.20 There are other formulations of the summation by parts, for instance
N

n=1
(Df v)nwn = ‚àí
N

n=1
vn(Dbw)n + 1
h(vN+1wN ‚àív1w0).
which is established in the same way.
‚ñ°
We also need a discrete version of the Poincar√© inequality:
Lemma 8.4 Let w = (wn)n=0,...,N be such that w0 = 0. Then we have
N

n=1
w2
n ‚â§
N

n=1
(Dbw)2
n.
(8.25)
Proof For all n = 1, . . . , N, we can write
wn = wn ‚àíwn‚àí1 + wn‚àí1 ‚àíwn‚àí2 + ¬∑ ¬∑ ¬∑ + w1 ‚àíw0
= h
n

j=1
(Dbw)j.
Therefore, by the Cauchy‚ÄìSchwarz inequality, it follows that
w2
n ‚â§h2n
n

j=1
(Dbw)2
j ‚â§h2N
N

j=1
(Dbw)2
j ‚â§h
N

j=1
(Dbw)2
j
since h =
1
N+1. Summing the above inequality from n = 1 to N, we obtain the
Lemma.
‚ñ°
We now are in a position to mimic the continuous energy estimate at the discrete
level.
Proposition 8.26 The Crank‚ÄìNicolson scheme (8.22) is unconditionally stable for
the 2, h norms.
Proof We let W j = Uj + Uj+1, Fj = Fj+Fj+1
2
and rewrite the scheme as
Uj+1 ‚àíUj
k
‚àí1
2(Df ‚ó¶Db)W j = Fj.
Note that this is exactly the same form as the one for which we have already computed
the orders in time and space in the ‚àû, h norms, hence in the 2, h norms. We multiply
row n of the above relation by hW i
j and sum with respect to n, or equivalently, take
the 2, h scalar product in RN with W j, and obtain

300
8
The Finite Difference Method for the Heat Equation
1
k

‚à•Uj+1‚à•2
2,h ‚àí‚à•Uj‚à•2
2,h

‚àí1
2

(Df ‚ó¶Db)W jW j
2,h =
FjW j
2,h.
Let us estimate the various terms. By the Cauchy‚ÄìSchwarz inequality and the discrete
Poincar√© inequality (8.25), we have
FjW j
2,h ‚â§‚à•Fj‚à•2,h‚à•W j‚à•2,h ‚â§‚à•Fj‚à•2,h‚à•DbW j‚à•2,h
‚â§1
2‚à•Fj‚à•2
2,h + 1
2‚à•DbW j‚à•2
2,h,
indeed, (W j)0 = uj
0 + uj+1
0
= 0 due to the Dirichlet boundary condition.
For the same reason, we also have (W j)N+1 = 0, so that the summation by parts
formula (8.24) implies that
‚àí1
2

(Df ‚ó¶Db)W jW j
2,h = 1
2

DbW jDbW j
2,h = 1
2‚à•DbW j‚à•2
2,h.
Putting these equalities and estimate together, we obtain
1
k

‚à•Uj+1‚à•2
2,h ‚àí‚à•Uj‚à•2
2,h

‚â§1
2‚à•Fj‚à•2
2,h,
so that
‚à•Uj+1‚à•2
2,h ‚â§‚à•Uj‚à•2
2,h + k
2‚à•Fj‚à•2
2,h.
Therefore, summing these inequalities from 0 to j ‚àí1 ‚â§M, we obtain
‚à•Uj‚à•2
2,h ‚â§‚à•U0‚à•2
2,h + jk
2 max
m‚â§T/k ‚à•Fm‚à•2
2,h
‚â§‚à•U0‚à•2
2,h + (M + 1)k
2
max
m‚â§T/k ‚à•Fm‚à•2
2,h = ‚à•U0‚à•2
2,h + T
2 max
m‚â§T/k ‚à•Fm‚à•2
2,h.
This is exactly the stability of the scheme in the 2, h norms, once we apply the
inequality
‚àö
a2 + b2 ‚â§a + b to the right-hand side.
‚ñ°
Remark 8.21 Note that when f = 0, the discrete energy 1
2‚à•Uj‚à•2
2,h is (in general
strictly) decreasing with j, as it is in the continuous case with respect to continuous
time.
‚ñ°
We can now put everything together.
Proposition 8.27 The Crank‚ÄìNicolson scheme (8.22) is unconditionally convergent
for the 2, h norms, of order 2 in time and space.
For purposes of comparison, we plot in Fig.8.6 the results of the backward Euler
scheme, the Crank‚ÄìNicolson scheme with the same discretization parameters h and
k Ô¨Åxed throughout, and the exact solution, for various values of j on the same graphs.

8.9 The Crank‚ÄìNicolson Scheme, Stability via the Energy Method
301
-1.0
-0.5
0.0
0.5
1.0
1.5
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 0, h = 0.0476190, k = 0.0238095, k/h^2 = 10.5
-0.4
-0.2
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 1, h = 0.0476190, k = 0.0238095, k/h^2 = 10.5
-0.1
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 2, h = 0.0476190, k = 0.0238095, k/h^2 = 10.5
-0.05
0.00
0.05
0.10
0.15
0.20
0.25
0.30
0.35
0.40
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 3, h = 0.0476190, k = 0.0238095, k/h^2 = 10.5
0.00
0.05
0.10
0.15
0.20
0.25
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 4, h = 0.0476190, k = 0.0238095, k/h^2 = 10.5
0.00
0.02
0.04
0.06
0.08
0.10
0.12
0.14
0.16
0.18
0.20
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 5, h = 0.0476190, k = 0.0238095, k/h^2 = 10.5
0.00
0.02
0.04
0.06
0.08
0.10
0.12
0.14
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 6, h = 0.0476190, k = 0.0238095, k/h^2 = 10.5
0.00
0.02
0.04
0.06
0.08
0.10
0.12
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 7, h = 0.0476190, k = 0.0238095, k/h^2 = 10.5
0.00
0.01
0.02
0.03
0.04
0.05
0.06
0.07
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 10, h = 0.0476190, k = 0.0238095, k/h^2 = 10.5
0.000
0.001
0.002
0.003
0.004
0.005
0.006
0.007
0.008
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 20, h = 0.0476190, k = 0.0238095, k/h^2 = 10.5
Fig. 8.6 Comparison between implicit Euler, (+) Crank‚ÄìNicolson (‚ó¶), and exact solutions (solid
line)

302
8
The Finite Difference Method for the Heat Equation
The initial condition is u0(x) = sin(œÄx)/2 + sin(2œÄx) and the right-hand side f is
zero. In this case, the exact solution is
u(x, t) = 1
2 sin(œÄx)e‚àíœÄ2t + sin(2œÄx)e‚àí4œÄ2t,
which makes comparisons possible.
The backward Euler scheme solution is drawn with + marks and linearly inter-
polated, that of the Crank‚ÄìNicolson scheme with ‚ó¶marks also linearly interpolated,
and the exact solution with a solid line. The vertical scale varies from plot to plot.
Both schemes are stable and the higher order, hence better accuracy, of the Crank‚Äì
Nicolson scheme is clearly visible for this particular initial data.
8.10
Other Approximations of the Heat Equation
The Ô¨Ånite difference method seems quite satisfactory in the case of one space dimen-
sion, see also [76] for the Ô¨Ånite difference method for general parabolic equations.
Higher dimensional versions exist, see [75] for example. They however suffer from
the same drawbacks as the Ô¨Ånite difference method for elliptic problems in more
than two space dimensions. ChieÔ¨Çy, it is difÔ¨Åcult if not downright impossible to
accommodate complex domain geometries in space Œ© ‚äÇRd.
One way of going around this difÔ¨Åculty is to devise methods that combine a Ô¨Ånite
difference approximation in time, since there is an ordinary differential equation
aspect with respect to time, with a Ô¨Ånite element (or other) method in space, since
there is a PDE boundary value aspect with respect to space. Let us quickly introduce
Ô¨Ånite difference-Ô¨Ånite element schemes.
We start from the variational formulation (7.3). Given u0 ‚ààL2(Œ©) and f ‚ààL2(Q),
the solution u is such that u ‚ààC0([0, T]; L2(Œ©)) ‚à©L2(0, T; H1
0(Œ©)) and for all
v ‚ààH1
0(Œ©),
 
(u|v)L2(Œ©)
‚Ä≤ + a(u, v) = (f |v)L2(Œ©) in the sense of D‚Ä≤(]0, T[),
(u(0)|v)L2(Œ©) = (u0|v)L2(Œ©).
The discretization proceeds in two consecutive steps. First comes the space dis-
cretization, exactly in the same spirit as for the abstract variational approximation
methods for elliptic problems. Next, time discretization is performed. Let us start
with the space discretization.
We thus assume that we are given a Ô¨Ånite element subspace Vh of V = H1
0(Œ©).
We then let uh ‚ààC0([0, T]; Vh) be the solution of
 
(uh|vh)L2(Œ©)
‚Ä≤ + a(uh, vh) = (f |vh)L2(Œ©) in the sense of D‚Ä≤(]0, T[),
(uh(0)|vh)L2(Œ©) = (u0,h|vh)L2(Œ©),

8.10 Other Approximations of the Heat Equation
303
for all vh ‚ààVh, where u0,h ‚ààVh is some approximation of u0, for instance its L2-
orthogonal projection on Vh. This is a Cauchy problem for a system of linear ordinary
differential equations, since Vh is Ô¨Ånite dimensional, hence existence and uniqueness
are not a real issue.
More precisely, assume that dim Vh = N and let us be given a basis (wj)j=1,...,N of
Vh consisting of hat functions that are constructed from the shape functions associated
with the underlying Ô¨Ånite element. We can thus write
uh(t) =
N

j=1
uh,j(t)wj
and uh is determined by the N unknown real-valued functions uh,j ‚ààC0([0, T]).
First of all, the initial condition is obviously equivalent to uh(0) = u0,h, that is in
components uh,j(0) = u0,h,j, for all j.
Next, taking vh = wi for n = 1, . . . , N, we obtain
N

j=1
u‚Ä≤
h,j(t)(wj|wi)L2(Œ©) +
N

j=1
uh,j(t)a(wj, wi) = (f |wi)L2(Œ©)
for n = 1, . . . , N. Let us rewrite this in vector form by introducing the vectors
Uh(t) =
‚éõ
‚éú‚éú‚éú‚éù
uh,1(t)
uh,2(t)
...
uh,N(t)
‚éû
‚éü‚éü‚éü‚é†, U0,h =
‚éõ
‚éú‚éú‚éú‚éù
u0,h,1
u0,h,2
...
u0,h,N
‚éû
‚éü‚éü‚éü‚é†and Fh(t) =
‚éõ
‚éú‚éú‚éú‚éù
(f |w1)L2(Œ©)(t)
(f |w2)L2(Œ©)(t)
...
(f |wN)L2(Œ©)(t)
‚éû
‚éü‚éü‚éü‚é†,
and the N √ó N matrices
M =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éù
(w1|w1)L2(Œ©)
(w2|w1)L2(Œ©)
¬∑ ¬∑ ¬∑
(wN|w1)L2(Œ©)
(w1|w2)L2(Œ©)
(w2|w2)L2(Œ©)
¬∑ ¬∑ ¬∑
(wN|w2)L2(Œ©)
...
...
...
...
(w1|wN‚àí1)L2(Œ©)
¬∑ ¬∑ ¬∑
(wN‚àí1|wN‚àí1)L2(Œ©) (wN|wN‚àí1)L2(Œ©)
(w1|wN)L2(Œ©)
¬∑ ¬∑ ¬∑
(wN‚àí1|wN)L2(Œ©)
(wN|wN)L2(Œ©)
‚éû
‚éü‚éü‚éü‚éü‚éü‚é†
and
A =
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éù
a(w1|w1)
a(w2|w1)
¬∑ ¬∑ ¬∑
a(wN|w1)
a(w1|w2)
a(w2|w2)
¬∑ ¬∑ ¬∑
a(wN|w2)
...
...
...
...
a(w1|wN‚àí1)
¬∑ ¬∑ ¬∑
a(wN‚àí1|wN‚àí1) a(wN|wN‚àí1)
a(w1|wN)
¬∑ ¬∑ ¬∑
a(wN‚àí1|wN)
a(wN|wN)
‚éû
‚éü‚éü‚éü‚éü‚éü‚é†
,

304
8
The Finite Difference Method for the Heat Equation
or in other words, Mnj = (wj|wi)L2(Œ©) and Anj = a(wj, wi). Since we are dealing with
a hat-function basis, both matrices are sparse, and we can assume a good numbering
of the degrees of freedom to obtain a band matrix.
The system then becomes
MU‚Ä≤
h(t) + AU(t) = Fh(t),
with the initial condition
Uh(0) = U0,h.
The matrix M is called the mass matrix and the matrix A is called the stiffness matrix.
Since M is the Gram matrix of a basis, it is nonsingular. Therefore, we can write
U‚Ä≤
h(t) + M‚àí1AU(t) = M‚àí1Fh(t),
from which existence and uniqueness are obvious since this is a system of linear
ordinary differential equations. Conversely, it is clear that the solution of this system
of ordinary differential equations gives rise to a solution of the variational problem
on Vh.
So far, only space was discretized. In order to obtain a fully discrete scheme,
we also need to discretize time. Any ordinary differential equation numerical
scheme may a priori be used here: forward Euler, backward Euler, Crank‚ÄìNicolson,
4th order Runge‚ÄìKutta, linear multistep methods and so on, see [8, 16, 23, 60,
64]. Of course, when using ordinary differential equation schemes, stability crite-
ria such as Dahlquist‚Äôs zero-stability, L-stability or A-stability, become essential,
see [12, 48, 49].
For this, we choose an integer M and let k =
T
M+1 be the time step. We denote by
Uj
h an approximation of Uh(jk). The forward Euler scheme then reads
M Uj+1
h
‚àíUj
h
k
+ AUj
h = Fh(jk),
with the initial condition
U0
h = U0,h,
and so on for the other choices of time Ô¨Ånite difference schemes. We have implicitly
assumed some regularity of f with respect to t. Note that, even for the forward Euler
scheme, we still need to solve a N √ó N linear system with the mass matrix in order
to compute Uj+1
h
from Uj
h.

8.10 Other Approximations of the Heat Equation
305
Of course, the convergence of these methods when h and k simultaneously go to
0 must be established and we do not pursue in this direction. We refer for example
to [5, 52, 62, 64, 66, 77].
After having discussed the Ô¨Årst two main classes of problems, namely elliptic
and parabolic problems, we now turn to the third class of PDE problems, hyperbolic
problems. We Ô¨Årst focus on the wave equation in Chap.9, then on the transport
equation in Chap.10.

Chapter 9
The Wave Equation
In this chapter, we present a short and even more far from exhaustive theoretical study
of the wave equation. We establish the existence and uniqueness of the solution, as
well as the energy estimates. We describe the qualitative behavior of solutions, which
is very different from that of the heat equation. Again, we will mostly work in one
dimension of space.
In the same chapter, we introduce Ô¨Ånite difference methods for the numerical
approximation of the wave equation. Here again, stability issues are prominent, and
signiÔ¨Åcantly more delicate than for the heat equation.
9.1
Regular Solutions of the Wave Equation
Recall that the general wave equation reads
‚àÇ2u
‚àÇt2 ‚àíŒîu = f in Q = Œ© √ó ]0, T [,
where Œ© is an open subset of Rd and f is a given function on Q, complemented
with boundary and initial conditions, see Chap.1, Sects.1.5 and 1.6. The propagation
speed c is set to 1, which we can always assume after a change of time or length
unit. There are two different settings depending on whether Œ© is bounded or not. In
the one-dimensional case, d = 1, we thus have either Œ© = ]a, b[ or Œ© = R without
loss of generality.1
1Admittedly, there is a third case, Œ© = R‚àó
+, but we will not consider it here.
¬© Springer International Publishing Switzerland 2016
H. Le Dret and B. Lucquin, Partial Differential Equations:
Modeling, Analysis and Numerical Approximation, International Series
of Numerical Mathematics 168, DOI 10.1007/978-3-319-27067-8_9
307

308
9
The Wave Equation
Let us begin with the bounded case. We are thus looking for a function u : [a, b] √ó
[0, T ] ‚ÜíR which solves the initial-boundary value problem
‚éß
‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é©
‚àÇ2u
‚àÇt2 ‚àí‚àÇ2u
‚àÇx2 = f in Q,
u(a, t) = u(b, t) = 0 for t ‚àà[0, T ],
u(x, 0) = u0(x), ‚àÇu
‚àÇt (x, 0) = u1(x) for x ‚àà]a, b[,
(9.1)
with homogeneous Dirichlet boundary conditions for simplicity and two initial data,
u0 and u1. If we think of the vibrating string interpretation, this means that the string
is Ô¨Åxed at both ends, and that we are given its initial position and initial velocity.
This is quite normal, since the equation is derived from Newton‚Äôs law of motion and
is of second order in time.
DeÔ¨Ånition 9.1 The quantity
E(t) = 1
2
 b
a
‚àÇu
‚àÇt (x, t)
	2
+
‚àÇu
‚àÇx (x, t)
	2
dx
is called the energy.
Of course, we assume that the solution is regular enough for the above quantity
to make sense. In the vibrating string interpretation, this is exactly the mechanical
energy of the string at time t. The Ô¨Årst term corresponds to the kinetic energy since
it is half the square of the velocity at point x and time t, integrated along the string.
The second term corresponds to the elastic energy, which can be seen by examining
the work done by the exterior forces, based on the analysis in Chap.1, Sect.1.1. The
initial energy is then
E(0) = 1
2
 b
a
(u1(x)2 + u‚Ä≤
0(x)2) dx.
The initial energy is Ô¨Ånite for u0 ‚ààH 1(]a, b[) and u1 ‚ààL2(a, b).
Proposition 9.1 Let u be a smooth enough solution of problem (9.1), then we have
dE
dt (t) =
 b
a
f (x, t)‚àÇu
‚àÇt (x, t) dx.

9.1 Regular Solutions of the Wave Equation
309
Proof By differentiation under the integral sign, we have
dE
dt (t) = 1
2
 b
a
 ‚àÇ
‚àÇt
‚àÇu
‚àÇt
	2	
+ ‚àÇ
‚àÇt
‚àÇu
‚àÇx
	2	
dx
=
 b
a
‚àÇu
‚àÇt
‚àÇ2u
‚àÇt2 + ‚àÇu
‚àÇx
‚àÇ2u
‚àÇx‚àÇt

dx.
We integrate the second term by parts
 b
a
‚àÇu
‚àÇx
‚àÇ2u
‚àÇx‚àÇt dx =
‚àÇu
‚àÇx
‚àÇu
‚àÇt

b
a ‚àí
 b
a
‚àÇ2u
‚àÇx2
‚àÇu
‚àÇt dx = ‚àí
 b
a
‚àÇ2u
‚àÇx2
‚àÇu
‚àÇt dx,
since ‚àÇu
‚àÇt (a, t) = ‚àÇu
‚àÇt (b, t) = 0 due to the Dirichlet boundary condition. Therefore,
dE
dt (t) =
 b
a
‚àÇu
‚àÇt
‚àÇ2u
‚àÇt2 ‚àí‚àÇ2u
‚àÇx2
	
dx =
 b
a
f ‚àÇu
‚àÇt dx,
and the proposition is proved.
‚ñ°
In the vibrating string interpretation, we thus Ô¨Ånd that the time derivative of the
energy is the power of the applied forces, as is expected from physics.
Corollary 9.1 If the right-hand side f in problem (9.1) vanishes, then the energy is
constant
E(t) = E(0).
Proof Indeed, in this case, dE
dt = 0.
‚ñ°
Remark 9.1 We note here a sharp contrast with the heat equation, for which the
energy was exponentially decreasing for a zero right-hand side. The heat equation,
which is a parabolic equation, dissipates the energy, whereas the wave equation‚Äîa
hyperbolic equation‚Äîconserves the energy: a vibrating string keeps vibrating forever
in the absence of dissipation.
‚ñ°
Corollary 9.2 Problem (9.1) has at most one smooth solution.
Proof Let u1 and u2 be solutions of problem (9.1), and u = u1 ‚àíu2. Then u is a
solution of problem (9.1) with right-hand side f = 0, so that E(t) = E(0), and zero
initial data, so that E(0) = 0. It follows from DeÔ¨Ånition 9.1 that u = 0.
‚ñ°
In order to further exploit the energy, we need a general purpose result, known as
Gronwall‚Äôs lemma or Gronwall‚Äôs inequality.
Theorem 9.1 (Gronwall‚Äôs lemma) Let Œ±, Œ≤ and Œ≥ be three continuous functions
deÔ¨Åned on [0, T ] such that Œ± is differentiable on ]0, T [. We assume that
Œ±‚Ä≤(t) ‚â§Œ≤(t)Œ±(t) + Œ≥ (t) for all t ‚àà]0, T [.

310
9
The Wave Equation
Then, we have
Œ±(t) ‚â§e
 t
0 Œ≤(s) dsŒ±(0) +
 t
0
e
 t
s Œ≤(u) duŒ≥ (s) ds.
Proof Let B(t) =
 t
0 Œ≤(s) ds and deÔ¨Åne Œ¥(t) = e‚àíB(t)Œ±(t). Then Œ¥ is differentiable
on ]0, T [ and
Œ¥‚Ä≤(t) = e‚àíB(t)Œ±‚Ä≤(t) ‚àíŒ≤(t)e‚àíB(t)Œ±(t) = e‚àíB(t)(Œ±‚Ä≤(t) ‚àíŒ≤(t)Œ±(t))
‚â§e‚àíB(t)Œ≥ (t).
Therefore, by the mean value inequality,
Œ¥(t) ‚àíŒ¥(0) ‚â§
 t
0
e‚àíB(s)Œ≥ (s) ds
and we conclude by multiplying the above inequality by eB(t) and by noticing that
B(t) ‚àíB(s) =
 t
s Œ≤(u) du.
‚ñ°
Proposition 9.2 We have the energy estimate
sup
t‚àà[0,T ]
E(t) ‚â§eT E(0) + 1
2
 T
0
 b
a
eT ‚àís f (x, s)2 dxds.
Proof It follows from Proposition 9.1 that
E‚Ä≤(t) ‚â§1
2
 b
a
f (x, t)2 dx + 1
2
 b
a
‚àÇu
‚àÇt (x, t)
	2
dx ‚â§1
2
 b
a
f (x, t)2 dx + E(t).
Thus, by Gronwall‚Äôs lemma,
E(t) ‚â§et E(0) + 1
2
 t
0
 b
a
et‚àís f (x, s)2 dxds ‚â§eT E(0) + 1
2
 T
0
 b
a
eT ‚àís f (x, s)2 dxds,
for all t ‚àà[0, T ].
‚ñ°
Remark 9.2 The energy estimate provides a stability result in the energy norm, in the
sense of establishing the continuity of the solution with respect to the initial data and
right-hand side. Indeed, if u1 and u2 are two solutions corresponding to right-hand
sides f1 and f2 and initial data u1,0, u1,1 and u2,0, u2,1, applying the energy estimate
to u1 ‚àíu2, we obtain
sup
t‚àà[0,T ]

‚à•u1 ‚àíu2‚à•2
H 1
0 (]a,b[) +
‚àÇu1
‚àÇt ‚àí‚àÇu2
‚àÇt

2
L2(a,b)
	
‚â§eT (‚à•u1,0 ‚àíu2,0‚à•2
H 1
0 (]a,b[) + ‚à•u1,1 ‚àíu2,1‚à•2
L2(a,b) + ‚à•f1 ‚àíf2‚à•2
L2(Q)).
‚ñ°

9.1 Regular Solutions of the Wave Equation
311
We now use Fourier series to construct regular solutions of problem (9.1) when
f = 0. For simplicity, we let a = 0, b = 1 and we assume that the initial data are
compatible with the Dirichlet condition, i.e., u0(0) = u0(1) = u1(0) = u1(1) = 0.
As in the case of the heat equation, we expand both functions in Fourier series
u0(x) =
+‚àû

k=1
b0
k sin(kœÄx),
u1(x) =
+‚àû

k=1
b1
k sin(kœÄx).
Theorem 9.2 Letu0 ‚ààC4([0, 1])andu1 ‚ààC3([0, 1])besuchthatu‚Ä≤‚Ä≤
0(0) = u‚Ä≤‚Ä≤
0(1) =
u‚Ä≤‚Ä≤
1(0) = u‚Ä≤‚Ä≤
1(1) = 0. Then the function deÔ¨Åned by
u(x, t) =
+‚àû

k=1

b0
k cos(kœÄt) + b1
k
kœÄ sin(kœÄt)
	
sin(kœÄx)
(9.2)
belongs to C2([0, 1] √ó [0, +‚àû[) and solves problem (9.1) with f = 0.
Proof Under the hypotheses made on u0 and u1, it is easy to see that |b0
k| ‚â§Ck‚àí4
and |b1
k| ‚â§Ck‚àí3 for some constant C. Then the series in formula (9.2) as well as the
series of all Ô¨Årst order and second order derivatives are normally convergent. Hence,
u is of class C2. Moreover, since the functions (x, t) 	‚ÜíeikœÄ(t¬±x) are solutions of the
wave equation with zero right-hand side, it is clear that the normal convergence of
second derivatives implies that u is also a solution of the wave equation.
For t = 0, we have
u(x, 0) =
+‚àû

k=1
b0
k sin(kœÄx) = u0(x)
and
‚àÇu
‚àÇt (x, 0) =
+‚àû

k=1
b1
k sin(kœÄx) = u1(x),
hence the initial conditions are satisÔ¨Åed. Finally, the Dirichlet boundary conditions
are also satisÔ¨Åed since sin(kœÄ) = 0.
‚ñ°
Remark 9.3 We Ô¨Ånd that the solution is a superposition of harmonics, see Chap.1,
Sect.1.5. Which harmonics are excited depend on the initial conditions. For instance,
for such a musical instrument as the piano, the strings are initially at rest, u0 = 0,
and are hit by a hammer, u1 Ã∏= 0. In the case of a guitar or a harpsichord, the
strings are typically plucked, u0 Ã∏= 0, sometimes with no initial velocity, u1 = 0.
Note that other combinations are possible, all resulting in different sounds, see
Figs.9.1 and 9.2.
‚ñ°

312
9
The Wave Equation
Fig. 9.1 A view of the
evolution in the case of zero
initial velocity u1, u0 has
four nonzero harmonics
Fig. 9.2 A view of the
evolution in the case of zero
initial position, initial
velocity +1 in ]0, 1
2[, ‚àí1 in
] 1
2, 1[, two hundred nonzero
terms in the Fourier series
Remark 9.4 The regularity hypotheses made on u0 and u1 are just there to ensure
easy convergence of the series of partial derivatives up to the second order. Indeed,
if the series (9.2) converges in a much weaker sense, its sum is still going to be a
solution of the wave equation in the sense of distributions at least, since differentiation
is continuous in the sense of distributions. The difÔ¨Åculty lies in the meaning of the
initial conditions, as some kind of continuity with respect to time is required for them
to make sense.
‚ñ°
Remark 9.5 A fundamental difference with the heat equation is that the Fourier
coefÔ¨Åcients of u(¬∑, t) are not rapidly damped by exponential terms for t > 0, which

9.1 Regular Solutions of the Wave Equation
313
cause the solution of the heat equation to be smooth for t > 0, whatever the initial
data. Here, the wave equation has no smoothing effect whatsoever. The regularity or
lack thereof of the initial conditions is propagated in time without any gain. This is
one of the main differences between parabolic and hyperbolic problems.
‚ñ°
9.2
Variational Formulation and Existence of Weak
Solutions
We now introduce a variational formulation for the wave equation in a manner that
is quite similar to the one described in Sect.7.6 for the heat equation.
DeÔ¨Ånition 9.2 The variational formulation of the wave equation (9.1) with homo-
geneous Dirichlet boundary condition, initial data u0 ‚ààH 1
0 (Œ©), u1 ‚ààL2(Œ©) and
right-hand side f ‚ààL2(Q) is: Find u ‚ààC0([0, T ]; H 1
0 (Œ©)) ‚à©C1([0, T ]; L2(Œ©))
such that, for all v ‚ààH 1
0 (Œ©),
‚éß
‚é™‚é®
‚é™‚é©

(u|v)L2(Œ©)
‚Ä≤‚Ä≤ + a(u, v) = ( f |v)L2(Œ©) in the sense of D‚Ä≤(]0, T [),
(u(0)|v)L2(Œ©) = (u0|v)L2(Œ©),
(u‚Ä≤(0)|v)L2(Œ©) = (u1|v)L2(Œ©).
(9.3)
Remark 9.6 This deÔ¨Ånition clearly makes sense. The last two equations are a weak
form of the initial conditions u(0) = u0, u‚Ä≤(0) = u1.
‚ñ°
For simplicity, we work again on Œ© = ]0, 1[ with the minus Laplacian eigenfunc-
tions œÜk(x) =
‚àö
2 sin(kœÄx) and eigenvalues Œªk = k2œÄ2, and we have a(w, œÜk) =
Œªk(w|œÜk)L2(Œ©) for all w ‚ààH 1
0 (Œ©), see Eq.(7.4).
Theorem 9.3 Let u0 ‚ààH 1
0 (Œ©), u1 ‚ààL2(Œ©), f ‚ààL2(Q). There exists a unique
solution u ‚ààC0([0, T ]; H 1
0 (Œ©)) ‚à©C1([0, T ]; L2(Œ©)) of the initial-boundary value
problem (9.3), which is given by
u(t) =
+‚àû

k=1
uk(t)œÜk,
(9.4)
where
uk(t) = (u0|œÜk)L2(Œ©) cos

Œªkt

+ (u1|œÜk)L2(Œ©)
‚àöŒªk
sin

Œªkt

+
1
‚àöŒªk
 t
0
( f (s)|œÜk)L2(Œ©) sin

Œªk(t ‚àís)

ds. (9.5)

314
9
The Wave Equation
Proof We
start
with
the
uniqueness.
Let
u ‚ààC0([0, T ]; H 1
0 (Œ©)) ‚à©
C1([0, T ]; L2(Œ©)) be a solution of (9.3). We expand u(t) on the Hilbert basis
(œÜk)k‚ààN‚àóof L2(Œ©) so that, for all t,
u(t) =
+‚àû

k=1
uk(t)œÜk
with
uk(t) = (u(t)|œÜk)L2(Œ©)
for all k ‚ààN‚àóand the series converges in L2(Œ©). Likewise, we set u0 = +‚àû
k=1 u0,kœÜk,
u1 = +‚àû
k=1 u1,kœÜk and f (t) = +‚àû
k=1 fk(t)œÜk. Taking œÜk ‚ààH 1
0 (Œ©) as a test-function
in problem (9.3), we obtain
‚éß
‚é™‚é®
‚é™‚é©
u‚Ä≤‚Ä≤
k(t) + Œªkuk(t) = fk(t) in the sense of D‚Ä≤(]0, T [),
uk(0) = u0,k,
u‚Ä≤
k(0) = u1,k,
for all k ‚ààN‚àó. For each k, this is a Cauchy problem for an ordinary differential
equation which has the unique solution
uk(t) = u0,k cos

Œªkt

+ u1,k
‚àöŒªk
sin

Œªkt

+
1
‚àöŒªk
 t
0
fk(s) sin

Œªk(t ‚àís)

ds,
hence the uniqueness.
We now use the above series to prove existence. We have that u0 ‚ààH 1
0 (Œ©) and
u1 ‚ààL2(Œ©) by hypothesis, therefore thanks to formula (7.7),
‚à•u0‚à•2
H 1(Œ©) =
+‚àû

k=1
(1 + Œªk)u2
0,k, |u0|2
H 1(Œ©) =
+‚àû

k=1
Œªku2
0,k and ‚à•u1‚à•2
L2(Œ©) =
+‚àû

k=1
u2
1,k.
(9.6)
Similarly, f ‚ààL2(Q) and
‚à•f ‚à•2
L2(Q) =
 T
0
+‚àû

k=1
fk(t)2 dt.
(9.7)
As before, we consider the sequence of partial sums Un(t) = n
k=1 uk(t)œÜk and
show that it is Cauchy for both C0([0, T ]; H 1
0 (Œ©)) and C1([0, T ]; L2(Œ©)) norms.
Let p < q be two given integers and let us estimate Up ‚àíUq in these various norms.

9.2 Variational Formulation and Existence of Weak Solutions
315
First of all, we have for all t
|Up(t) ‚àíUq(t)|2
H 1
0 (Œ©) =
q

k=p+1
Œªkuk(t)2
‚â§2
q

k=p+1
Œªk

u2
0,k + 1
Œªk
u2
1,k + 1
Œªk
 t
0
| fk(s)| ds
	2
‚â§2
q

k=p+1
Œªku2
0,k + 2
q

k=p+1
u2
1,k + 2T
q

k=p+1
 T
0
fk(s)2 ds,
since all the trigonometric terms are less than 1 in absolute value and by the Cauchy‚Äì
Schwarz inequality. Therefore
‚à•Up ‚àíUq‚à•2
C0([0,T ];H 1
0 (Œ©)) ‚â§2
q

k=p+1
Œªku2
0,k + 2
q

k=p+1
u2
1,k + 2T
q

k=p+1
 T
0
fk(s)2 ds
can be made as small as we wish by taking p large enough, due to the hypotheses
on u0, u1 and f and formulas (9.6)‚Äì(9.7), and the sequence is consequently Cauchy
in C0(0, T ; H 1
0 (Œ©)).
It follows from the previous estimate and the Poincar√© inequality that the sequence
is also Cauchy in C0(0, T ; L2(Œ©)). We need to look at its time derivative. Of course,
U ‚Ä≤
n(t) = n
k=1 u‚Ä≤
k(t)œÜk with
u‚Ä≤
k(t) = ‚àí

Œªku0,k sin

Œªkt

+ u1,k cos

Œªkt

+
 t
0
fk(s) cos

Œªk(t ‚àís)

ds,
so that
‚à•U ‚Ä≤
p ‚àíU ‚Ä≤
q‚à•2
C0([0,T ];L2(Œ©)) ‚â§2
q

k=p+1
Œªku2
0,k + 2
q

k=p+1
u2
1,k + 2T
q

k=p+1
 T
0
fk(s)2 ds
and the sequence U ‚Ä≤
n is Cauchy in C0(0, T ; L2(Œ©)), which completes the proof of
the convergence of the series (9.4) in the above-mentioned spaces.
Regarding the wave equation itself, setting Fn(t) = n
k=1 fk(t)œÜk, we have
n

k=1
u‚Ä≤‚Ä≤
k(t)œÜk +
n

k=1
Œªkuk(t)œÜk = Fn(t).
Foralltest-functionsv ‚ààH 1
0 (Œ©),bytakingthe L2 scalarproductoftheaboveformula
with v = +‚àû
k=1 vkœÜk, we thus obtain

316
9
The Wave Equation
n

k=1
u‚Ä≤‚Ä≤
k(t)vk +
n

k=1
Œªkuk(t)vk = (Fn(t)|v)L2(Œ©).
Now n
k=1 uk(t)vk = (Un(t)|v)L2(Œ©) ‚Üí(u(t)|v)L2(Œ©) in C0([0, T ]), so that
n

k=1
u‚Ä≤‚Ä≤
k(t)vk =

(Un(t)|v)L2(Œ©)
‚Ä≤‚Ä≤ ‚Üí

(u(t)|v)L2(Œ©)
‚Ä≤‚Ä≤ in the sense of D‚Ä≤(]0, T [)
when n ‚Üí+‚àû. Similarly
n

k=1
Œªkuk(t)vk = a(Un(t), v) ‚Üía(u(t), v) in C0([0, T ]).
Finally, Fn ‚Üíf in L2(0, T ; L2(Œ©)) and therefore
(Fn(t)|v)L2(Œ©) ‚Üí( f (t)|v)L2(Œ©) in L2(0, T ),
and we obtain the variational form of the wave equation in the limit n ‚Üí+‚àû.
The initial conditions are obviously satisÔ¨Åed by construction.
‚ñ°
Remark 9.7 For this proof to work, we need the compatibility condition between
the initial condition u0 and the Dirichlet boundary condition, but no such condition
is needed for the initial velocity u1. Formulas (9.4)‚Äì(9.5) clearly generalizes the
expansion obtained in Theorem 9.2.
‚ñ°
Remark 9.8 The d-dimensional wave equation can be solved along the exact same
lines, see [5, 28]. However, here again, other approaches, such as semigroups, are
possible.
‚ñ°
Remark 9.9 The series estimates above immediately imply stability in the energy
norm for the weak solutions as well, in the sense that given two sets of data with
corresponding solutions u1 and u2, we have
‚à•u1 ‚àíu2‚à•2
C0([0,T ];H 1
0 (Œ©)) + ‚à•u1 ‚àíu2‚à•2
C1([0,T ];L2(Œ©))
‚â§C(|u1,0 ‚àíu2,0|2
H 1
0 (Œ©) + ‚à•u1,1 ‚àíu2,1‚à•2
L2(Œ©) + ‚à•f1 ‚àíf2‚à•2
L2(Q)).
This is also a continuity result of the solution with respect to the initial conditions
and right-hand side.
‚ñ°
As a consequence, the energy equality of Proposition 9.1 is still valid here, the
energy being deÔ¨Åned by E(t) = 1
2

‚à•u‚Ä≤(t)‚à•2
L2(Œ©) + |u(t)|2
H 1
0 (Œ©)

as before. More pre-
cisely,
Proposition 9.3 Let u be the solution given by Theorem 9.3. Then we have
E ‚ààH 1(]0, T [) with

9.2 Variational Formulation and Existence of Weak Solutions
317
dE
dt (t) =

f (t)|u‚Ä≤(t)

L2(Œ©).
Proof We approximate u0, u1 and f by smooth functions un
0, un
1 and f n, in their
respective function spaces. By the stability estimate above, the corresponding solu-
tion un is such that un ‚Üíu in C0([0, T ]; H 1
0 (Œ©)) ‚à©C1([0, T ]; L2(Œ©)). We can
apply Proposition 9.1 to un so that2
dEn
dt (t) =

f n(t)|(un)‚Ä≤(t)

L2(Œ©),
where En(t) is the energy of un. Clearly En ‚ÜíE in C0([0, T ]). Moreover,


f n(t)|(un)‚Ä≤(t)

L2(Œ©) ‚àí

f (t)|u‚Ä≤(t)

L2(Œ©)

‚â§


f n(t) ‚àíf (t)|(un)‚Ä≤(t)

L2(Œ©)
 +


f (t)|(un)‚Ä≤(t) ‚àíu‚Ä≤(t)

L2(Œ©)

‚â§‚à•f n(t) ‚àíf (t)‚à•L2(Œ©)‚à•(un)‚Ä≤(t)‚à•L2(Œ©)
+ ‚à•f (t)‚à•L2(Œ©)‚à•(un)‚Ä≤(t) ‚àíu‚Ä≤(t)‚à•L2(Œ©),
so that squaring and integrating in time, we obtain
dEn
dt
‚àí( f |u‚Ä≤)L2(Œ©)

2
L2(0,T ) ‚â§C

‚à•f n ‚àíf ‚à•2
L2(0,T ;L2(Œ©)) + ‚à•(un)‚Ä≤ ‚àíu‚Ä≤‚à•2
C0([0,T ];L2(Œ©))

.
It follows from this that dEn
dt ‚Üí( f |u‚Ä≤)L2(Œ©) in L2(0, T ), and since dEn
dt ‚ÜídE
dt in the
sense of D‚Ä≤(]0, T [), that dE
dt = ( f |u‚Ä≤)L2(Œ©) belongs to L2(0, T ).
‚ñ°
Remark 9.10 In the case f = 0, we obtain that the energy is also conserved for weak
solutions.
‚ñ°
9.3
The Wave Equation on R
WenowconsiderthecaseofthewaveequationonRwith f = 0.Thereisnoboundary
condition. In this case, there is an explicit formula for the solution, similar to that
obtained for the transport equation and known as the d‚ÄôAlembert formula, see [35].
Theorem 9.4 Let u0 ‚ààC1(R) and u1 ‚ààC0(R). The solution of problem (9.1) on R
with f = 0 is given by
u(x, t) = 1
2

u0(x + t) + u0(x ‚àít) +
 x+t
x‚àít
u1(s) ds
	
.
(9.8)
2We admit here that both formulations coincide in the smooth case.

318
9
The Wave Equation
Proof The function given by formula (9.8) is continuous on R √ó R+, hence is a
distribution on R √ó R‚àó
+. It is in fact of class C1 on R √ó R+, and we can write
u(x, t) = F(x + t) + G(x ‚àít)
(9.9)
with F(y) = 1
2

u0(y) +
 y
0 u1(s) ds

and G(y) = 1
2

u0(y) +
 0
y u1(s) ds

. Let us
set U(x, t) = F(x + t) and V (x, t) = G(x ‚àít). Of course, we have
‚àÇU
‚àÇt (x, t) = F‚Ä≤(x + t),
‚àÇU
‚àÇx (x, t) = F‚Ä≤(x + t)
(9.10)
and
‚àÇV
‚àÇt (x, t) = ‚àíG‚Ä≤(x ‚àít),
‚àÇV
‚àÇx (x, t) = G‚Ä≤(x ‚àít).
(9.11)
Let us compute ‚àÇ2U
‚àÇt2 ‚àí‚àÇ2U
‚àÇx2 in the sense of distributions. We thus take œï ‚ààD(R √ó R‚àó
+)
and consider the following duality bracket
‚àÇ2U
‚àÇt2 ‚àí‚àÇ2U
‚àÇx2 , œï

= ‚àí
‚àÇU
‚àÇt ‚àí‚àÇU
‚àÇx , ‚àÇœï
‚àÇt + ‚àÇœï
‚àÇx

= 0,
by Eq.(9.10), and similarly ‚àÇ2V
‚àÇt2 ‚àí‚àÇ2V
‚àÇx2 = 0 in the sense of distributions by Eq.(9.11).
Concerning the initial conditions, of course
u(x, 0) = 1
2

u0(x) + u0(x) +
 x
x
u1(s) ds
	
= u0(x)
and since
‚àÇu
‚àÇt (x, t) = 1
2

u‚Ä≤
0(x + t) ‚àíu‚Ä≤
0(x ‚àít) + u1(x + t) + u1(x ‚àít)

,
we have
‚àÇu
‚àÇt (x, 0) = 1
2

u‚Ä≤
0(x) ‚àíu‚Ä≤
0(x) + u1(x) + u1(x)

= u1(x).
This proves the theorem.
‚ñ°
Remark 9.11 Formula (9.8) makes sense for much less regular data, for example u0
and u1 in L1
loc(R), and still gives rise to a solution of the wave equation in the sense
of distributions. In fact, we may even take u0 and u1 in D‚Ä≤(R) by interpreting the
integral as the sum of two primitives. The problem is thus to make sense of the initial
condition in such a nonsmooth context, see Figs.9.3 and 9.4. Some continuity with
respect to time is needed, but we do not pursue in this direction.
Such an explicit formula as (9.8) is speciÔ¨Åc to the one-dimensional case. The
solution is not so simple in higher dimensions of space.
‚ñ°

9.3 The Wave Equation on R
319
Fig. 9.3 A view of the
evolution in the case of
u0 = 1[‚àí1/2,1/2] and zero
initial velocity, with the two
issuing waves propagating
right and left 1
2u0(x ‚àít) and
1
2u0(x + t). Also pictured in
thicker red line the solution
at t = 1
3 and t = 2
Fig. 9.4 A view of the
evolution in the case of
u1 = 1[‚àí1,1] and u0 = 0.
Also pictured in thicker red
line the solution at t = 1
2,
t = 1 and t = 2. It is only
Lipschitz in space and time
Remark 9.12 The solution pictured in Fig.9.3 is discontinuous in space and time.
It is thus meant to be understood as a solution of the wave equation in the sense of
distributions. The interpretation of the initial conditions, in particular for the velocity,
is admittedly a little more delicate.
‚ñ°
Remark 9.13 Independently of any considerations of initial data, it is easy to see
that all solutions of the wave equation are of the form (9.9). Indeed, the change of
variables w = x + t, z = x ‚àít leads to the equation
‚àÇ2u
‚àÇw‚àÇz = 0 whose solutions are
clearly of the form F(w) + G(z). The solution is thus seen as the superposition of
two waves, one traveling to the left at speed ‚àí1 (F(x + t)) and the other traveling to
the right at speed +1 (G(x ‚àít)). In the general case, c Ã∏= 1, the corresponding form
is u(x, t) = F(x + ct) + G(x ‚àíct).
‚ñ°
Remark 9.14 We also see that the wave equation propagates waves at Ô¨Ånite speed
(¬±c), as opposed to the heat equation which has inÔ¨Ånite speed of propagation. In
particular, if the initial data are compactly supported in [a, b], then the solution at
time t is compactly supported in [a ‚àíct, b + ct]. Another way of seeing this is to
note that the value of the solution at point (x, t) only depends on what happens
in its backward cone of inÔ¨Çuence {(y, s) ‚ààR √ó R+; s ‚â§t, |y ‚àíx| ‚â§c(t ‚àís)}, see
Fig.9.5. The information situated outside of the cone of inÔ¨Çuence does not have the
time to propagate to point (x, t).
‚ñ°

320
9
The Wave Equation
Fig. 9.5 The backward cone
of inÔ¨Çuence of point (x, t)
x
t
x+ ct
x‚àíct
Remark 9.15 If u0 is compactly supported and u1 = 0, an observer located at some
point x > 0 initially outside of the support of u0, sees a wave 1
2u0(x ‚àíct) reach
him or her after some time, pass through, and then go back to exactly 0. This is a
feature of the wave equation in odd dimensions of space. This explains why we see
light and hear sounds as we do: a Ô¨Çash of light at some point in space-time results
in a spherical wavefront expanding at the speed of light that an observer experiences
as a single instantaneous Ô¨Çash when reached by the wavefront. The same goes for
sound. This is not true in even dimensions. For example, if we throw a rock on a
lake, the resulting wave on the surface of the lake expands as a circle traveling at the
speed of waves on water, but never goes back to rest inside the disk, even though
the solution is much smaller there. If we lived on the surface of the water, we would
experience a Ô¨Çash followed by a never-ending afterglow‚Ä¶ good thing we live in an
odd-dimensional space.
‚ñ°
Remark 9.16 The wave equation is invariant under the change t ‚Üí‚àít. This means
that time is reversible in the wave equation, which is another feature in sharp contrast
with the heat equation.
‚ñ°
9.4
Finite Difference Schemes for the Wave Equation
The principle of Ô¨Ånite difference methods for the wave equation is exactly the same
as for the heat equation, and the notation is also the same. Since the wave equation is
of second order in time, a natural idea is to consider two time steps Ô¨Ånite difference
schemes, even though we will see that this is not necessarily a good idea. We will
assume the initial conditions U 0 and U 1 to be given in terms of u0 and u1. For
instance, a simple choice could be
U 0 = Sh(u0),
U 1 = U 0 + kSh(u1),
or higher order approximations for U 1.
The most obvious scheme consists in approximating the second time derivative
by means of the usual central difference, which yields

9.4 Finite Difference Schemes for the Wave Equation
321
u j+1
n
‚àí2u j
n + u j‚àí1
n
k2
‚àíu j
n+1 ‚àí2u j
n + u j
n‚àí1
h2
= f j
n ,
(9.12)
with the usual boundary conditions and initial data. This is obviously an explicit,
two time steps scheme. In vector form, it reads
U j+1 ‚àí2U j + U j‚àí1
k2
+ AhU j = F j,
where Ah is still given by formula (2.8) with c = 0, p. 40 of Chap.2. It should be
quite clear that the scheme is consistent and of order 2 in space and time. Therefore,
its convergence is solely a matter of stability.
We reformulate the above scheme as a single time step scheme by setting
V j =
 U j
U j‚àí1

‚ààR2N,
and
1
k2 V j+1 =
 2
k2 I ‚àíAh ‚àí1
k2 I
1
k2 I
0
  U j
U j‚àí1

+
F j
0

= 1
k2 A V j + G j
with a 2N √ó 2N ampliÔ¨Åcation matrix A =
C ‚àíI
I
0

with C = 2I ‚àík2 Ah, and
G j ‚ààR2N. Unfortunately, the matrix A is not normal. Indeed
A T A =
C2 + I ‚àíC
‚àíC
I

Ã∏=
C2 + I C
C
I

= A A T .
Therefore, we only have œÅ(A ) ‚â§|||A |||2,h and the condition œÅ(A ) ‚â§1 + C(T )k is
just a necessary condition for stability, see Remark8.13 in Chap.8, whereas we also
would like to have a sufÔ¨Åcient condition for stability. In order to have a necessary
stability condition that is valid for all T , it is easier to require œÅ(A ) ‚â§1. Let us see
what we can say about the spectral radius of A .
Lemma 9.1 Let C be a N √ó N complex matrix and B the 2N √ó 2N complex matrix
deÔ¨Åned by blocks as
B =
C ‚àíI
I
0

.

322
9
The Wave Equation
If Œª ‚ààC is an eigenvalue of B, then Œª Ã∏= 0 and Œª + 1
Œª is an eigenvalue of C. Con-
versely, if Œº ‚ààC is an eigenvalue of C, then there exists an eigenvalue Œª of B such
that Œº = Œª + 1
Œª.
Proof The proof is similar to that of Lemma8.2 of Chap.8.
‚ñ°
Proposition 9.4 If k
h ‚â§1, then the necessary stability condition for scheme (9.12)
is satisÔ¨Åed.
Proof Recall that stability is meant here in the sense of œÅ(A ) ‚â§1. So we need to Ô¨Ånd
out when all the eigenvalues Œª of A are such that |Œª| ‚â§1. According to Lemma 9.1,
the eigenvalues in question are of the form Œª¬± =
Œº¬±‚àö
Œº2‚àí4
2
where Œº is an eigenvalue
of C = 2I ‚àík2 Ah, hence is real. We thus see that there are two cases:
1. |Œº| > 2. In this case, the two eigenvalues Œª¬± are real, distinct, and since their
product is equal to 1, one of them is strictly larger than 1 in absolute value. Hence
this is an unstable case.
2. |Œº| ‚â§2. In this case, Œª¬± are complex conjugate, and since their product is equal
to 1, they are both of modulus 1. The necessary stability condition is thus satisÔ¨Åed.
Now we have Œº = 2 ‚àí4 k2
h2 sin2
pœÄ
2(N+1)

, p = 1, . . . , N. Clearly, if k
h ‚â§1, then
we have |Œº| ‚â§2.
‚ñ°
Remark 9.17 The condition k
h ‚â§1 is called the Courant‚ÄìFriedrichs‚ÄìLewy or CFL
condition. In the general case, the CFL condition assumes the form k
h ‚â§1
c. In a sense,
h
k is the numerical velocity needed to reach the neighboring grid points in one time
step starting from one spatial grid point, see Fig.9.6. The CFL condition is that this
numerical velocity must be larger than the propagation velocity.
In other words, the discrete backward cone of inÔ¨Çuence of a point (xn, t j) must
contain its continuous backward cone of inÔ¨Çuence, in order for the scheme to have
access to all the information needed to compute a relevant approximation at that
point. Of course, this kind of requirement only applies to explicit schemes.
‚ñ°
Let us plot the result of the explicit scheme with + marks and the exact solution
in solid line in Fig.9.7. We take the same u0 as for the heat equation, i.e., u0(x) =
sin(œÄx)/2 + sin(2œÄx), and u1 = 0. We have taken U 1 = U 0, which is actually a
Fig. 9.6 Discrete cone of
inÔ¨Çuence versus continuous
cone of inÔ¨Çuence
xn
tj
xn + ctj
xn ‚àíct j
xn + jh
xn ‚àíjh

9.4 Finite Difference Schemes for the Wave Equation
323
- 1.5
- 1.0
-0.5
0.0
0.5
1.0
1.5
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 0, h = 0.0196078, k = 0.0196078, k/h = 1
- 1.5
- 1.0
-0.5
0.0
0.5
1.0
1.5
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 5, h = 0.0196078, k = 0.0196078, k/h = 1
- 1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 11, h = 0.0196078, k = 0.0196078, k/h = 1
- 1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 16, h = 0.0196078, k = 0.0196078, k/h = 1
- 1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 22, h = 0.0196078, k = 0.0196078, k/h = 1
- 1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 28, h = 0.0196078, k = 0.0196078, k/h = 1
- 1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 34, h = 0.0196078, k = 0.0196078, k/h = 1
- 1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 40, h = 0.0196078, k = 0.0196078, k/h = 1
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
j = 45, h = 0.0196078, k = 0.0196078, k/h = 1
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
j = 50, h = 0.0196078, k = 0.0196078, k/h = 1
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
Fig. 9.7 Explicit scheme, u0(x) = sin(œÄx)/2 + sin(2œÄx), u1(x) = 0

324
9
The Wave Equation
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 0, h = 0.0196078, k = 0.0196078, k/h = 1
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 1, h = 0.0196078, k = 0.0196078, k/h = 1
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 2, h = 0.0196078, k = 0.0196078, k/h = 1
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 3, h = 0.0196078, k = 0.0196078, k/h = 1
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 4, h = 0.0196078, k = 0.0196078, k/h = 1
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j = 5, h = 0.0196078, k = 0.0196078, k/h = 1
Fig. 9.8 Explicit scheme, u0 = 1[ 1
3 , 2
3 ], u1 = 0
second order approximation of the condition u1 = 0, hence the good global accuracy
of the scheme in this particular case.
Of course, the initial condition is very smooth here. If we want to compute a
discontinuous solution with this scheme, we run into trouble with severe unwanted
oscillations, see Fig.9.8. This kind of discontinuous solution is of physical interest in
situations where shock waves occur. Devising numerical schemes capable of reliably
capturing shocks thus requires skills that go beyond the scope of these notes.

9.4 Finite Difference Schemes for the Wave Equation
325
Fig. 9.9 Explicit scheme,
u0(x) =
sin(œÄx)/2 + sin(2œÄx),
u1(x) = 0, CFL condition
not satisÔ¨Åed
- 1e+ 08
- 8e+ 07
- 6e+ 07
- 4e+ 07
- 2e+ 07
0e+ 00
2e+ 07
4e+ 07
6e+ 07
8e+ 07
1e+ 08
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
j =  40, h =  0.0196078, k =  0.0243902, k/ h =  1.2439024
For the record, Fig.9.9 shows what happens after a few iterations when the CFL
condition is violated, even with the very smooth initial condition used above.
The next obvious scheme is the implicit version of the former one
u j+1
n
‚àí2u j
n + u j‚àí1
n
k2
‚àíu j+1
n+1 ‚àí2u j+1
n
+ u j+1
n‚àí1
h2
= f j+1
n
,
(9.13)
with the usual boundary conditions and initial data. In vector form, it reads
 1
k2 I + Ah
	
U j+1 = 2
k2 U j ‚àí1
k2 U j‚àí1 + F j+1.
We rewrite it as a single time step scheme
V j+1 = A V j + G j
with
A =
2(I + k2 Ah)‚àí1 ‚àí(I + k2 Ah)‚àí1
I
0

.
Again, the matrix A is not normal, but we can look at its spectral radius. Setting C =
(I + k2 Ah)‚àí1, the same kind of arguments as before show that the eigenvalues Œª of A
are of the form Œª¬± = Œº ¬±

Œº2 ‚àíŒº where Œº is an eigenvalue of C. Now Œº ‚àà]0, 1[,
therefore Œº2 ‚àíŒº < 0 and the eigenvalues Œª+ and Œª‚àíare complex conjugate, of
modulus ‚àöŒº. The necessary condition for stability is thus unconditionally satisÔ¨Åed.
The implicit scheme does a slightly better job of capturing shocks than the explicit
scheme for the same discretization parameters, but it still has a lot of numerical
diffusion that spreads out the shocks, see Fig.9.10.
A third scheme is the Œ∏-scheme for Œ∏ ‚àà[0, 1
2], written here for f = 0,

326
9
The Wave Equation
Fig. 9.10 Implicit scheme,
u0 = 1[ 1
3 , 2
3 ], u1 = 0
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
-1.5
-1.0
-0.5
0.0
0.5
1.0
-1.5
-1.0
-0.5
0.0
0.5
1.0
1.5
1.5
j = 0, h = 0.0196078, k = 0.0196078, k/h = 1
j = 2, h = 0.0196078, k = 0.0196078, k/h = 1
j = 4, h = 0.0196078, k = 0.0196078, k/h = 1
j = 6, h = 0.0196078, k = 0.0196078, k/h = 1
j = 8, h = 0.0196078, k = 0.0196078, k/h = 1
j = 10, h = 0.0196078, k = 0.0196078, k/h = 1
j = 1, h = 0.0196078, k = 0.0196078, k/h = 1
j = 3, h = 0.0196078, k = 0.0196078, k/h = 1
j = 5, h = 0.0196078, k = 0.0196078, k/h = 1
j = 7, h = 0.0196078, k = 0.0196078, k/h = 1
j = 9, h = 0.0196078, k = 0.0196078, k/h = 1
j = 11, h = 0.0196078, k = 0.0196078, k/h = 1
1.0
1.0
1.0
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
1.0
1.0
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
1.0
1.0
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0

9.4 Finite Difference Schemes for the Wave Equation
327
u j+1
n
‚àí2u j
n + u j‚àí1
n
k2
‚àíŒ∏ u j+1
n+1 ‚àí2u j+1
n
+ u j+1
n‚àí1
h2
‚àí(1 ‚àí2Œ∏)u j
n+1 ‚àí2u j
n + u j
n‚àí1
h2
‚àíŒ∏ u j‚àí1
n+1 ‚àí2u j‚àí1
n
+ u j‚àí1
n‚àí1
h2
= 0,
(9.14)
which reduces to the explicit scheme for Œ∏ = 0 and is implicit for Œ∏ > 0.
9.5
Stability via the Fourier Approach
So far we have only obtained necessary conditions for stability, because the matrices
were not normal. As in the case of numerical schemes for the heat equation, we
can also use the Fourier method to obtain sufÔ¨Åcient conditions. Again, we work on
the whole of R. We take f = 0. As was already mentioned, there are no boundary
conditions and let us forget for the moment that the solution is given by an explicit
formula.
Concerning the relationship between discrete and semi-discrete schemes, every
thing said for the heat equation holds true here. In addition, we note that, due to the
Ô¨Ånite speed of propagation, if the initial data is compactly supported in an interval,
a Ô¨Ånite difference scheme on the interval with boundary conditions will compute
exactly the same values as the same scheme on R as long as the wave has not hit the
ends of the interval. Therefore, so does the semi-discrete scheme, and the stability
conditions obtained from the Fourier method actually apply to the scheme on an
interval with boundary conditions (at least under the previous conditions).
Let us Ô¨Årst consider the explicit scheme (9.12), for which we already have a nec-
essary stability condition, but no sufÔ¨Åcient condition. Both Fourier approaches are
more complicated than for the heat equation, since the linear recurrence relations
obtained are two-step relations, which are harder to analyze than the one-step rela-
tions in the heat equation case. Since the two Fourier approaches are very similar to
each other, we Ô¨Årst concentrate on the Fourier series point of view for brevity, see
Sect.8.7.
Since we are working on the whole space, the scheme (9.12) with zero right-hand
side takes the form
u j+1
n
‚àí2u j
n + u j‚àí1
n
k2
‚àíu j
n+1 ‚àí2u j
n + u j
n‚àí1
h2
= 0, for n ‚ààZ.
(9.15)
In Fourier space, the scheme reads
F(u j+1)(s) ‚àí2F(u j)(s) + F(u j‚àí1)(s)
k2
+ 4
h2 sin2s
2
	
F(u j)(s) = 0,
(9.16)
for s ‚àà[0, 2œÄ]. As was mentioned above, this is a two-step linear recurrence rela-
tion, which we rewrite in vector form by introducing the R2-valued sequence

328
9
The Wave Equation
Z j
n =

u j+1
n
u j
n

, the Fourier series transform of which satisÔ¨Åes
F(Z j+1)(s) = A(s)F(Z j)(s)
where
A(s) =
2 ‚àía(s)2 ‚àí1
1
0

with a(s) = 2k
h sin
 s
2

. The matrix A is called the ampliÔ¨Åcation matrix of the scheme.
We list without proof several properties of such schemes, since they are easy gener-
alizations of former results.
Let A ‚ààC0([0, 2œÄ]; M2(C)) and consider the multiplier operator L deÔ¨Åned on
L2([0, 2œÄ]; C2) with values in L2([0, 2œÄ]; C2) by (LY)(s) = A(s)Y(s), for almost
all s ‚àà[0, 2œÄ]. The generalization of Eq. (8.7) in this case is
‚à•L‚à•L (L2([0,2œÄ];C2)) = max
s‚àà[0,2œÄ] |||A(s)|||2
(we use the standard hermitian norm on C2), see [67]. It follows that the scheme
(9.16) is stable in L2 if and only if there exists a constant C(T ) such that
max
s‚àà[0,2œÄ] |||A(s) j|||2 ‚â§C(T )
for all j ‚â§T/k. Since œÅ(A(s)) ‚â§|||A(s) j|||1/j
2 , a necessary condition of stability is
that there exists a nonnegative constant C that does not depend on k and h such that
œÅ(A(s)) ‚â§1 + Ck for all s. We say that the scheme is stable in the sense of von
Neumann if œÅ(A(s)) ‚â§1 for all s.
Proposition 9.5 The scheme (9.16) is stable in the sense of von Neumann if and
only if k
h ‚â§1.
Proof The characteristic polynomial of A(s) is
PA(s)(X) = X2 ‚àí(2 ‚àía(s)2)X + 1.
The product of the two roots is 1, thus if they are both real and simple, one of them
is strictly larger than 1 in absolute value. On the other hand, if they are complex
conjugate, they are both of modulus 1. Consequently, von Neumann stability is
equivalent to the discriminant being non positive.
We thus need to see under which condition Œî(s) = a(s)2(a(s)2 ‚àí4) ‚â§0 for all s.
Taking s = œÄ, we see that a necessary condition is k
h ‚â§1. Conversely, this condition
is clearly sufÔ¨Åcient.
‚ñ°
In the case of a normal ampliÔ¨Åcation matrix, the former conditions are also sufÔ¨Å-
cient for L2-stability. Now the matrix A(s) obtained above is not normal in general,

9.5 Stability via the Fourier Approach
329
except for s = œÄ if k
h = 1, thus we need a more general result. We work directly on
the stability of the scheme expressed in Fourier space by the operator L above, since
this is equivalent to L2-stability for the discrete scheme, due to Parseval‚Äôs formula.
Stability in L2 is ensured if |||A(s) j|||2 ‚â§C(T ) for all s and j ‚â§T/k, where C(T )
does not depend on h or k. It should be noted that this condition is a priori much easier
to check here than it was for (actual) Ô¨Ånite difference schemes, since the matrix in
question is always of the same size, i.e., 2 √ó 2, whereas the size of the matrix in Ô¨Ånite
difference schemes was N √ó N with h =
1
N+1 and the norm also depended on h.
Proposition 9.6 The discrete scheme (9.16) is not stable in L2.
Proof It is enough to look at what happens for s = 0. In this case, the ampliÔ¨Åcation
matrix has the double eigenvalue 1 and is clearly not diagonalizable. In effect,
A(0) =
2 ‚àí1
1 0

= P
1 1
0 1

P‚àí1, where P =
1 1
1 0

,
from which we immediately deduce that
A(0) j =
 j + 1 ‚àíj
j
1 ‚àíj

.
We thus have |||A(0) j|||2 =

2 j2 + 1 + 2 j

j2 + 1 ‚â•2 j. It follows in particular
that |||A(0)T/k|||2 ‚â•2T
k , hence the instability of the discrete scheme.
‚ñ°
Remark 9.18 This is an unsettling result, since we could have rightfully expected
the very natural scheme (9.15) to be stable under the CFL condition k
h ‚â§1 or at least
k
h < 1. This is not the case.
The reason for the natural scheme not to be stable is the following. If it was stable
in ‚Ñì2, then having sequences of initial data (u0)m and (u1)m bounded in ‚Ñì2 would
result in a sequence of solutions (u j)m also bounded in ‚Ñì2, uniformly for j ‚â§T/k.
However, this boundedness could be achieved with (u0)m and (u1)m having strictly
nothing to do with each other. Now we need to remember that u0
n = u0(nh) and u1
n is
supposed to be some approximation of u(nh, k) ‚âàu0(nh) + k ‚àÇu
‚àÇt (nh, 0). Thus both
initial conditions of the wave equation u(x, 0) = u0(x) and ‚àÇu
‚àÇt (x, 0) = u1(x) must
somehow be taken into account in the discrete initial data u0 and u1 for the scheme
to have any chance to converge. This is not the case if (u0)m and (u1)m can be chosen
independently of each other.
Note that the scheme is unstable in spite of being von Neumann stable, an unhappy
effect of terminology.
‚ñ°
Remark 9.19 We can see the instability of the scheme on the following example.
Let us consider the initial data u0 = 0 and u1 given by u1
0 = h‚àí1/2 and u1
n = 0 for
n Ã∏= 0. We have ‚à•u1‚à•2,h = 1. Let us show that ‚à•u j‚à•2,h is not bounded for j ‚â§T/k.
In Fourier space, the recurrence relation reads

330
9
The Wave Equation
F(u j+1)(s) = (2 ‚àía2(s))F(u j)(s) ‚àíF(u j‚àí1)(s).
The characteristic equation of this recurrence relation X2 ‚àí(2 ‚àía2(s))X + 1 = 0
has two roots r¬± = e¬±iŒ∏(s), Œ∏(s) = arccos(1 ‚àía2(s)
2 ) for s Ã∏= 0 and s Ã∏= 2œÄ, and a
double root r = 1 for s = 0 or 2œÄ.
We have F(u0)(s) = 0 and F(u1)(s) = h‚àí1/2, thus
F(u j)(s) =

h‚àí1/2 sin( jŒ∏(s))
sin(Œ∏(s)) , for 0 < s < 2œÄ,
jh‚àí1/2,
for s = 0 or s = 2œÄ.
We are interested in the L2 norm of the above function. Clearly
‚à•F(u j)‚à•2
L2(0,2œÄ),h ‚â•
 Œ∏‚àí1( œÄ
2 j )
0
sin2( jŒ∏(s))
sin2(Œ∏(s)) ds.
Now, on the interval

0, Œ∏‚àí1 œÄ
2 j

, we have sin( jŒ∏(s))
sin(Œ∏(s)) ‚â•2 j
œÄ . Consequently
‚à•F(u j)‚à•2
L2(0,2œÄ),h ‚â•4 j2
œÄ2 Œ∏‚àí1 œÄ
2 j
	
.
After a little bit of computation, we Ô¨Ånd that Œ∏‚àí1 œÄ
2 j

‚àº
œÄ
2
‚àö
2Œª j when j ‚Üí+‚àû.
Therefore, for j large enough, we obtain
‚à•F(u j)‚à•2
L2(0,2œÄ),h ‚â•
j
œÄ
‚àö
2Œª
‚Üí+‚àûwhen j ‚Üí+‚àû.
Going back to the original discrete scheme, it follows that ‚à•u j‚à•2,h ‚Üí+‚àûwhen
j ‚Üí+‚àûfor this particular sequence of bounded initial data.
‚ñ°
In order to obtain sufÔ¨Åcient stability conditions, we actually need to change the
unknowns so as to appropriately take care of the wave equation initial conditions.
First, we rewrite the wave equation: Find u : Q = R √ó [0, T ] ‚ÜíR such that
‚éß
‚é™‚é™‚é®
‚é™‚é™‚é©
‚àÇ2u
‚àÇt2 ‚àí‚àÇ2u
‚àÇx2 = 0 in Q,
u(x, 0) = u0(x), ‚àÇu
‚àÇt (x, 0) = u1(x) for x ‚ààR,
(9.17)
as a Ô¨Årst order system.
Proposition 9.7 Let v = ‚àÇu
‚àÇt and w = ‚àÇu
‚àÇx . Problem (9.17) is equivalent to the system
of Ô¨Årst order PDEs

9.5 Stability via the Fourier Approach
331
‚éß
‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é©
‚àÇv
‚àÇt ‚àí‚àÇw
‚àÇx = 0 in Q,
‚àÇw
‚àÇt ‚àí‚àÇv
‚àÇx = 0 in Q,
v(x, 0) = u1(x), w(x, 0) = u‚Ä≤
0(x) for x ‚ààR,
(9.18)
up to an additive constant.
Proof If u solves problem (9.17), then the Ô¨Årst equation in (9.18) is just the wave
equation, and the second equation is just
‚àÇ2u
‚àÇx‚àÇt =
‚àÇ2u
‚àÇt‚àÇx . The initial conditions are
obvious.
Conversely, let (v, w) solve (9.18). Since Q is simply connected, the second
equation implies that there exists u such that v = ‚àÇu
‚àÇt and w = ‚àÇu
‚àÇx . The Ô¨Årst equation
is the wave equation for u. By the second initial condition, there exists a constant c0
such that u(x, 0) = u0(x) + c0. Hence, u = u ‚àíc0 solves (9.17).
‚ñ°
Remark 9.20 Let us note that, in the case of a bounded interval with Dirichlet con-
ditions, the energy estimate of Corollary 9.1 gives an L2 bound on the variables v
and w, and not directly on u. This explains the choice of these variables for an L2
stability analysis.
‚ñ°
WeperformasimilaroperationontheÔ¨Ånitedifferencescheme.Weusethenotation
xœÑ = œÑh for œÑ ‚ààR, which agrees with the former notation xn when œÑ = n ‚ààZ.
Proposition 9.8 Let
v j
n = u j
n ‚àíu j‚àí1
n
k
and w j
n‚àí1/2 = u j
n ‚àíu j
n‚àí1
h
,
(9.19)
for n ‚ààZ and j ‚ààN‚àó. If u j is a solution of the Ô¨Ånite difference scheme (9.15), then
(v j, w j) are solution of the Ô¨Ånite difference scheme
‚éß
‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é©
v j+1
n
‚àív j
n
k
‚àí
w j
n+1/2 ‚àíw j
n‚àí1/2
h
= 0,
w j+1
n‚àí1/2 ‚àíw j
n‚àí1/2
k
‚àív j+1
n
‚àív j+1
n‚àí1
h
= 0,
(9.20)
with v1
n and w1
n‚àí1/2 given by formula (9.19) in terms of the initial data u0
n and u1
n of
(9.15).
Proof Replacing v j
n = u j
n‚àíu j‚àí1
n
k
and w j
n‚àí1/2 =
u j
n‚àíu j
n‚àí1
h
into (9.20), we see that the sec-
ond relation is satisÔ¨Åed by the very deÔ¨Ånition of v j
n and w j
n‚àí1
2 , and that the Ô¨Årst relation
reduces to the original Ô¨Ånite difference scheme. Moreover, the initial conditions are
satisÔ¨Åed by construction.
‚ñ°

332
9
The Wave Equation
Remark 9.21 We note that the scheme (9.20) is explicit. Indeed, assuming that v j
n and
w j
n+1/2 are already known, the Ô¨Årst relation gives v j+1
n
= v j
n + k
h (w j
n+1/2 ‚àíw j
n‚àí1/2)
for all n ‚ààZ. After that, we see that w j+1
n‚àí1/2 = w j
n‚àí1/2 + k
h (v j+1
n
‚àív j+1
n‚àí1) for all n ‚ààZ
by the second relation. Hence, the solution of (9.20) with initial data v1 and w1 exists
and is unique.
‚ñ°
Remark 9.22 Clearly, v j
n is intended to be an approximation of v(xn, t j) = ‚àÇu
‚àÇt (xn, t j)
and w j
n‚àí1/2 an approximation of w(xn‚àí1/2, t j) = ‚àÇu
‚àÇx (xn‚àí1/2, t j).
In view of this, other initial data are reasonable for (9.20), for example v0
n =
u1(xn) and w0
n‚àí1/2 = u‚Ä≤
0(xn‚àí1
2 ), yielding a different approximation from which an
approximation of u must be reconstructed. These initial conditions directly take into
account the initial conditions of the wave equation.
‚ñ°
This time, we choose to work in the continuous Fourier transform framework, see
Sect.8.8. We thus introduce the semi-discrete version of the scheme as
‚éß
‚é™‚é™‚é®
‚é™‚é™‚é©
v j+1(x) ‚àív j(x)
k
‚àíw j(x + h/2) ‚àíw j(x ‚àíh/2)
h
= 0,
w j+1(x ‚àíh/2) ‚àíw j(x ‚àíh/2)
k
‚àív j+1(x) ‚àív j+1(x ‚àíh)
h
= 0,
(9.21)
for all x ‚ààR and with appropriate initial data. Rewriting this in Fourier space, we
obtain
‚éß
‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é©

v j+1(Œæ) ‚àí
v j(Œæ)
k
‚àíei hŒæ
2 ‚àíe‚àíi hŒæ
2
h

w j(Œæ) = 0,
e‚àíi hŒæ
2

w j+1(Œæ) ‚àí
w j(Œæ)
k
‚àí1 ‚àíe‚àíihŒæ
h

v j+1(Œæ) = 0,
for all Œæ ‚ààR. Writing Y j(x) =
v j(x)
w j(x)

, we obtain

Y j(Œæ) = B(Œæ)
Y j‚àí1(Œæ)
with the ampliÔ¨Åcation matrix
B(Œæ) =

1
ia(Œæ)
ia(Œæ) 1 ‚àía(Œæ)2

where a(Œæ) = 2k
h sin
 hŒæ
2

.
We see that ampliÔ¨Åcation matrices are now complex matrices, we thus need to
generalize the results of Chap.8 to the complex case. First of all, when A is a complex
N √ó N matrix, its induced matrix norm for the canonical Hermitian norm on CN is
deÔ¨Åned as
|||A|||2,h =
sup
X‚ààCN ,XÃ∏=0
‚à•AX‚à•2,h
‚à•X‚à•2,h
.

9.5 Stability via the Fourier Approach
333
A complex matrix A is said to be normal if A‚àóA = AA‚àówhere A‚àóis the adjoint
matrix. The following results are proved along the same lines as the corresponding
results in the real case.
Proposition 9.9 Let A be a complex N √ó N matrix. We have
|||A|||2,h =

œÅ(A‚àóA).
In addition, if A is normal then œÅ(A) = œÅ(A‚àóA)1/2 = |||A|||2,h.
We now return to the stability of scheme (9.21).
Proposition 9.10 The scheme (9.21) is stable in the sense of von Neumann if and
only if k
h ‚â§1.
Proof The matrix B(Œæ) has the same characteristic polynomial as the matrix A(s)
of Proposition 9.5, therefore the proof is the same.
‚ñ°
The matrix B(Œæ) is not normal in general, thus von Neumann stability is not a
priori sufÔ¨Åcient for L2 stability. The following simple matrix result is useful in this
context. Let M ‚ààM2(C). Every complex matrix is triangularisable, thus we can
write M = PU P‚àí1 with P ‚ààGL2(C) and U upper-triangular.
Proposition 9.11 For all diagonalizable matrices M ‚ààM2(C) such that œÅ(M) ‚â§1,
we have
|||M j|||2 ‚â§|||P|||2|||P‚àí1|||2,
for all j ‚ààN.
Proof We can write M = PU P‚àí1 with P ‚ààGL2(C) and U diagonal,
U =
Œª1 0
0 Œª2

,
where Œª1, Œª2 are the eigenvalues of M. We have M j = PU j P‚àí1. Therefore
|||M j|||2 ‚â§|||P|||2|||U j|||2|||P‚àí1|||2.
Now |||U j|||2 = œÅ(M) j, which completes the proof.
‚ñ°
Remark 9.23 The constant |||P|||2|||P‚àí1|||2 appearing in the estimate of M j is nothing
but the condition number (introduced in Remark2.11 of Chap.2) of the change of
basis matrix P.
‚ñ°
Remark 9.24 If M is not diagonalizable, it has a double eigenvalue Œª and we have
U = Œõ + N with
Œõ =
Œª 0
0 Œª

,
N =
0 1
0 0

,

334
9
The Wave Equation
by the Jordan decomposition theorem. The matrix N is nilpotent, N 2 = 0, and com-
mutes with Œõ. Therefore, by the binomial identity,
U j = Œõ j + jŒª j‚àí1N,
for all j ‚ààN. It follows that if œÅ(M) < 1,
|||U j|||2 ‚â§C(œÅ(M)),
for all j ‚ààN, where C is a function of the spectral radius, and if œÅ(M) = 1 then
|||M j|||2 ‚Üí+‚àû
when j ‚Üí+‚àû.
‚ñ°
Let us now apply Proposition 9.11 to the study of the stability of the scheme (9.21)
by applying the proposition to the matrix M = B(Œæ), for any Œæ ‚ààR. We let
B(Œæ) = P(Œæ)U(Œæ)P‚àí1(Œæ)
where P(Œæ) ‚ààGL2(C) and U(Œæ) ‚ààM2(C) is upper-triangular for all Œæ ‚ààR. Of
course, all these matrices are also functions of h and k.
Proposition 9.12 Let 0 < Œª0 < 1 and assume that k
h ‚â§Œª0. Then, the scheme (9.21)
is stable in L2(R).
Proof In the case a(Œæ) = 0, then B(Œæ) = I = U(Œæ) = P(Œæ) and there is nothing to
do. Let us assume that Œæ is such that a(Œæ) Ã∏= 0. In this case, Œî(Œæ) < 0, there are two
simple eigenvalues and B(Œæ) is diagonalizable. We already know that the eigenvalues
of B(Œæ) are of modulus 1, so that œÅ(B(Œæ)) = 1. We have the estimate
|||B j(Œæ)|||2 ‚â§|||P(Œæ)|||2|||P‚àí1(Œæ)|||2,
by Proposition 9.11. Thus, we only need to bound the condition number of the matrix
P(Œæ). Let us note for the record that |a(Œæ)| ‚â§2Œª0 < 2 for all Œæ.
Computing the eigenvectors of A(Œæ), we Ô¨Ånd that the change of basis matrix
P(Œæ) =

ia(Œæ)
ia(Œæ)
Œª+(Œæ) ‚àí1 Œª‚àí(Œæ) ‚àí1

is uniformly bounded since |a(Œæ)| < 2. More importantly, since Œª¬±(Œæ) ‚àí1 =
‚àía(Œæ)2 ¬± ia(Œæ)

4 ‚àía(Œæ)2
2
, we clearly have
|||P(Œæ)|||2 ‚â§C|a(Œæ)|.

9.5 Stability via the Fourier Approach
335
Moreover,
P(Œæ)‚àí1 = det(P(Œæ))‚àí1
Œª‚àí(Œæ) ‚àí1 ‚àíia(Œæ)
1 ‚àíŒª+(Œæ) ia(Œæ)

= det(P(Œæ))‚àí1Q(Œæ).
We likewise have |||Q(Œæ)|||2 ‚â§C|a(Œæ)|. Since
det(P(Œæ)) = ia(Œæ)(Œª‚àí(Œæ) ‚àíŒª+(Œæ)) = a(Œæ)2
4 ‚àía(Œæ)2,
it follows that
| det(P(Œæ))| ‚â•2

1 ‚àíŒª2
0|a(Œæ)|2,
hence
|||P(Œæ)‚àí1|||2 ‚â§C|a(Œæ)|‚àí1,
and the result follows.
‚ñ°
Remark 9.25 We have now established the conditional ‚Ñì2 stability of scheme (9.20).
This means that under the CFL condition, if the initial data v1 and w1 remain in a
bounded set of ‚Ñì2, so do the corresponding solutions v j and w j for j ‚â§T/k. The
unknowns v and w, which are in a sense quite natural for formulating the wave
equation, are however not the initial unknown u, either continuous or discrete. The
initial values v1 and w1 are supposed to be approximations of ‚àÇu
‚àÇt (x, 0) = u1(x) and
‚àÇu
‚àÇx (x, 0) = u‚Ä≤
0(x) respectively. In this sense, they are independent from each other
as opposed to what happened in the case of the natural scheme, cf. Remark 9.18.
A natural question now is to ask if the Ô¨Årst order scheme provides some stability
information for the original scheme. We encounter a difÔ¨Åculty here. Indeed, if we try
to reconstruct u j from w j, i.e., perform a kind of discrete integration, we see that
u j
n = u j
0 + h
n

l=0
w j
n‚àíl‚àí1/2,
for n ‚â•0. Now requiring that u j ‚àà‚Ñì2(Z) implies that u j
n ‚Üí0 when n ‚Üí+‚àû. So
the partial sums on the right must converge and we must have
u j
n = ‚àíh
‚àû

l=n+1
w j
n‚àíl‚àí1/2,
again for n ‚â•0. This is not possible in general since w j ‚àà‚Ñì2(Z) Ã∏‚äÇ‚Ñì1(Z).
What we can say however, is that if we are given u0 ‚àà‚Ñì2(Z) and v1 ‚àà‚Ñì2(Z), and
if we deÔ¨Åne u1 = u0 + kv1 ‚àà‚Ñì2(Z) and set w1
n‚àí1/2 =
u1
n‚àíu1
n‚àí1
h
, that is to say if w1 is
the discrete derivative in some sense of an element of ‚Ñì2(Z), then for all j, so is
w j. Indeed, it is simply the discrete derivative of u j obtained by the original scheme

336
9
The Wave Equation
with the above initial conditions, by uniqueness. In this sense, we can say that the
original scheme is stable in ‚Ñì2(Z) for such initial conditions, but with a stability
measured in the norms ‚à•u j
n‚àíu j‚àí1
n
k
‚à•2,h + ‚à•
u j
n‚àíu j
n‚àí1
h
‚à•2,h, which are more natural in view
of Remark 9.20.
‚ñ°
Remark 9.26 The proof requires Œª0 < 1 to work. Indeed, if k
h = 1, then for Œæ = œÄ
h ,
B(Œæ) =
 1 2i
2i ‚àí3

has the double eigenvalue ‚àí1 and is not diagonalizable. Therefore |||B(Œæ)T/k|||2 ‚àº
Ck‚àí1 with C > 0 for k small for this value of Œæ and the semi-discrete scheme is
thus unstable in this case. Note that this tells us nothing about the stability of the
discrete scheme when k = h, and this instability occurs even though the scheme is
von Neumann stable.
‚ñ°
Remark 9.27 If we modify the second relation of the Ô¨Ånite difference scheme as
follows
w j+1
n‚àí1/2 ‚àíw j
n‚àí1/2
k
‚àív j
n ‚àív j
n‚àí1
h
= 0,
which may seem more natural than the scheme above, we get an ampliÔ¨Åcation matrix
B(Œæ) =

1
ia(Œæ)
ia(Œæ)
1

.
This matrix is normal and its eigenvalues are 1 ¬± ia(Œæ). They are of modulus strictly
larger than 1 (except when a(Œæ) = 0). Hence this scheme is not stable in the sense of
von Neumann, and since the matrix is normal and given the expression of a(Œæ), we
see that it is not stable in L2. This shows again that Ô¨Ånite difference schemes must
be chosen with care and that seemingly natural choices may very well fail.
‚ñ°
Let us now study the stability of the implicit scheme (9.13). The scheme is implicit
and it is not obvious in the ‚Ñì2(Z) context that is even well-deÔ¨Åned.
Proposition 9.13 The implicit scheme (9.13) is well-deÔ¨Åned with initial data in
‚Ñì2(Z).
Proof We use the Fourier series argument. For u ‚àà‚Ñì2(Z), let T denote the contin-
uous linear operator on ‚Ñì2(Z) deÔ¨Åned by
(T u)n = ‚àíŒªun+1 + (1 + 2Œª)un ‚àíŒªun‚àí1, n ‚ààZ,
and Œª = k2
h2 . We rewrite the implicit scheme as follows
T u j+1 = v j,

9.5 Stability via the Fourier Approach
337
with v j
n = 2u j
n ‚àíu j‚àí1
n
. The question is whether or not the operator T is an isomor-
phism.
Regarding uniqueness, we note that if T u = 0, then u is of the form
un = C1rn
1 + C2rn
2 , n ‚ààZ,
(9.22)
for some C1 and C2 in C, where r1 and r2 are the roots of the characteristic equation
‚àíŒªr2 + (1 + 2Œª)r ‚àíŒª = 0. These roots are real, both positive and their product is
1, therefore the only sequence of the form (9.22) that belongs to ‚Ñì2(Z) is such that
C1 = C2 = 0.
We now consider existence. As before, for any v ‚àà‚Ñì2(Z; C) we let Fv ‚àà
L2(0, 2œÄ; C) be deÔ¨Åned by Fv(s) = 
n‚ààZ vneins.
We have
FT u(s) =

n‚ààZ

‚àíŒªun+1 + (1 + 2Œª)un ‚àíŒªun‚àí1

eins
= ‚àíŒª

n‚ààZ
un+1eins + (1 + 2Œª)

n‚ààZ
uneins ‚àíŒª

n‚ààZ
un‚àí1eins
=

‚àíŒªe‚àíis + (1 + 2Œª) ‚àíŒªeis
Fu(s)
=

1 + 4Œª sin2s
2
		
Fu(s).
Now the function s 	‚Üí

1 + 4Œª sin2 s
2
‚àí1 is in L‚àû(0, 2œÄ), therefore
u = F ‚àí1

Fv(s)

1 + 4Œª sin2 s
2


,
is a solution in ‚Ñì2(Z; C) of T u = v. Of course, by uniqueness, when v is real-valued,
so is u.
‚ñ°
Remark 9.28 We could not use the semi-discrete version of the scheme in Fourier
space, because the equivalence of this scheme with the discrete scheme for piecewise
constant initial data rests on the existence of the discrete scheme. The Fourier series
approach does not suffer from this drawback.
‚ñ°
We can now switch to the semi-discrete point of view to study the stability. If we
try to work on the initial formulation of the scheme in Fourier space

u j+1(Œæ) ‚àí2
u j(Œæ) + 
u j‚àí1(Œæ)
k2
+ 4
h2 sin2hŒæ
2
	

u j+1(Œæ) = 0,
we encounter the same kind of difÔ¨Åculties as with the explicit scheme. Namely, we
obtain an ampliÔ¨Åcation matrix

338
9
The Wave Equation
A(Œæ) =

2
1+a(Œæ)2 ‚àí
1
1+a(Œæ)2
1
0

.
This matrix is never normal. For Œæ = 0, it is the same as in Proposition 9.6, therefore
the semi-discrete scheme is not stable.
Once again, we must change the unknowns and use a Ô¨Årst order system version
of the scheme in order to be able to conclude. The Ô¨Årst order scheme is simply
‚éß
‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é©
v j+1
n
‚àív j
n
k
‚àí
w j+1
n+1/2 ‚àíw j+1
n‚àí1/2
h
= 0,
w j+1
n‚àí1/2 ‚àíw j
n‚àí1/2
k
‚àív j+1
n
‚àív j+1
n‚àí1
h
= 0.
(9.23)
Writing down the semi-discrete version of this last scheme, we obtain the following
ampliÔ¨Åcation matrix
B(Œæ) =
1
1 + a(Œæ)2

1
ia(Œæ)
ia(Œæ)
1

.
Now this matrix is normal. Its eigenvalues are Œª¬±(Œæ) = 1¬±ia(Œæ)
1+a(Œæ)2 , so that
œÅ(B(Œæ)) =
1

1 + a(Œæ)2 ‚â§1
for all Œæ ‚ààR. We have thus shown
Proposition 9.14 The implicit scheme (9.23) is unconditionally von Neumann stable
and L2 stable.
Let us close this section by saying a few words about the stability of the Œ∏-
scheme (9.14). If we write the semi-discrete version of the scheme, apply the Fourier
transform and rewrite the result in vector form, we obtain an ampliÔ¨Åcation matrix
A(Œæ) =
‚àíb(Œæ) ‚àí1
1
0

,
with
b(Œæ) = (1 ‚àí2Œ∏)a(Œæ)2 ‚àí2
1 + Œ∏a(Œæ)2
.
This matrix is not normal. Its eigenvalues are the roots of the polynomial P(X) =
X2 + b(Œæ)X + 1. The discriminant reads
Œî(Œæ) = a(Œæ)2
(1 ‚àí4Œ∏)a(Œæ)2 ‚àí4


1 + Œ∏a(Œæ)22
.

9.5 Stability via the Fourier Approach
339
If the discriminant is positive for some value of Œæ, we thus have two distinct real
roots, the product of which is 1, hence von Neumann instability. If on the other hand,
the discriminant is nonpositive for all Œæ, we have two complex conjugate roots of
modulus 1, hence von Neumann stability. Recalling that a(Œæ) = 2k
h sin
 hŒæ
2

, we thus
obtain the following proposition:
Proposition 9.15 The Œ∏-scheme is unconditionally von Neumann stable for Œ∏ ‚â•1
4.
For Œ∏ < 1
4, it is von Neumann stable under the condition k
h ‚â§
1
‚àö1‚àí4Œ∏ .
Of course, in terms of L2 stability, we have the exact same problem as before for
Œæ = 0, which implies L2 instability of the semi-discrete Œ∏-scheme. We can try to go
around this difÔ¨Åculty by using again a system
‚éß
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é™‚é©
v j+1
n
‚àív j
n
k
‚àíŒ∏
w j+1
n+1/2 ‚àíw j+1
n‚àí1/2
h
‚àí(1 ‚àí2Œ∏)
w j
n+1/2 ‚àíw j
n‚àí1/2
h
‚àíŒ∏
w j‚àí1
n+1/2 ‚àíw j‚àí1
n‚àí1/2
h
= 0,
w j+1
n‚àí1/2 ‚àíw j
n‚àí1/2
k
‚àív j+1
n
‚àív j+1
n‚àí1
h
= 0.
(9.24)
Now on the surface, this scheme appears still to be a two time step scheme, hence
nothing seems to be gained. We can however rewrite it as a one time step scheme
as follows. We Ô¨Årst apply the Fourier transform to the semi-discrete version of the
scheme
‚éß
‚é®
‚é©

v j+1(Œæ) ‚àí
v j(Œæ) ‚àíia(Œæ)

Œ∏ 
w j+1(Œæ) + (1 ‚àí2Œ∏)
w j(Œæ) + Œ∏ 
w j‚àí1(Œæ)

= 0,

w j+1(Œæ) ‚àí
w j(Œæ) ‚àíia(Œæ)
v j+1(Œæ) = 0.
In addition to a formula for 
w j+1 in terms of 
w j and 
v j+1, the second equation also
yields

w j‚àí1(Œæ) = 
w j(Œæ) ‚àíia(Œæ)
v j(Œæ).
We replace these expressions in the Ô¨Årst equation

v j+1(Œæ) ‚àí
v j(Œæ) ‚àíia(Œæ)

Œ∏(
w j(Œæ) + ia(Œæ)
v j+1(Œæ))
+ (1 ‚àí2Œ∏)
w j(Œæ) + Œ∏(
w j(Œæ) ‚àíia(Œæ)
v j(Œæ))

= 0,
or
(1 + Œ∏a(Œæ)2)

v j+1(Œæ) ‚àí
v j(Œæ)

‚àíia(Œæ)
w j(Œæ) = 0.

340
9
The Wave Equation
This scheme thus corresponds to the ampliÔ¨Åcation matrix
B(Œæ) =

1
iaŒ∏(Œæ)
ia(Œæ) 1 ‚àía(Œæ)aŒ∏(Œæ)

,
with
aŒ∏(Œæ) =
a(Œæ)
1 + Œ∏a(Œæ)2 .
This matrix is not normal and has the same eigenvalues as the previous one, hence the
same von Neumann stability. The case a(Œæ) = 0 is not a problem anymore however,
since the matrix is then the identity matrix.
Proposition 9.16 The semi-discrete version of the Œ∏-scheme (9.24) is stable in L2
for Œ∏ ‚â•1
4 under the condition k
h ‚â§M, for any given M. For Œ∏ < 1
4, given any
0 < Œª0 <
1
‚àö1‚àí4Œ∏ , it is L2 stable under the condition k
h ‚â§Œª0.
Proof Let us consider the case Œ∏ ‚â•1
4. First of all, at Œæ = 2mœÄ
h , m ‚ààZ, we have
a(Œæ) = 0 so that nothing needs to be done for these values of Œæ, as was already
mentioned. For the other values of Œæ, the matrix B(Œæ) is diagonalizable with two
distinct, complex conjugate eigenvalues of modulus one, therefore no problem for
the diagonal part either. We have the change of basis matrix
P(Œæ) =

‚àí1
2

4aŒ∏(Œæ)
a(Œæ) ‚àíaŒ∏(Œæ)2 + iaŒ∏(Œæ)
	
1
2

4aŒ∏(Œæ)
a(Œæ) ‚àíaŒ∏(Œæ)2 ‚àíiaŒ∏(Œæ)
	
1
1

,
with 4aŒ∏(Œæ)
a(Œæ) ‚àíaŒ∏(Œæ)2 ‚â•0 since Œ∏ ‚â•1
4.
After a little bit of computer algebra aided manipulations, we obtain the following
value for the condition number of P(Œæ):
cond2(P(Œæ)) = sign (a)(a + b) +

a2b2 + (a ‚àíb)2
‚àö
4ab ‚àía2b2
,
where a = a(Œæ) and b = aŒ∏(Œæ) for brevity. Replacing b by its value as a function of
a, we obtain
cond2(P(Œæ)) = 2 + Œ∏a(Œæ)2 + |a(Œæ)|

1 + Œ∏2a(Œæ)2

(4Œ∏ ‚àí1)a(Œæ)2 + 4
‚â§1 + |a(Œæ)|
2
+ a(Œæ)2
2
‚â§1 + M + 2M2,
hence the stability of the scheme. We leave the case Œ∏ < 1
4 as an exercise.
‚ñ°

9.5 Stability via the Fourier Approach
341
Remark 9.29 Proposition 9.16 in the case Œ∏ ‚â•1
4 is a bit of a disappointment. Indeed,
in that case, the scheme is unconditionally von Neumann stable and we only obtain
actual L2 stability under the condition k
h ‚â§M with M arbitrary. Now in practice,
neither k nor h actually go to 0, and such a condition as k
h ‚â§M with M arbitrary is
not discernible from unconditional stability.
‚ñ°
Remark 9.30 Instead of using the Jordan decomposition of B(Œæ), we could think
of using the Schur decomposition of B(Œæ), B(Œæ) = U(Œæ)T (Œæ)U(Œæ)‚àó, where U(Œæ)
is unitary and T (Œæ) is upper triangular. The advantage of the Schur decomposition
over the Jordan decomposition in this context, is that |||B(Œæ) j|||2 = |||T(Œæ) j|||2 for all
j and we lose no information by passing from B(Œæ) to T (Œæ). Moreover, T (Œæ) j is
fairly easy to express explicitly. The disadvantage is that the expression of the upper
right entry of T (Œæ) j is even less user-friendly than cond2(P(Œæ)) when it comes to
estimating it. We do not pursue this direction here.
‚ñ°
9.6
For a Few Schemes More
In the previous section, we rewrote the wave equation as the Ô¨Årst order system (9.18).
This system is of the form
‚àÇU
‚àÇt + ‚àÇ( f (U))
‚àÇx
= 0
with
U(x, t) =
v(x, t)
w(x, t)

and f (U) =
 0 ‚àí1
‚àí1 0

U.
When U is Rp-valued and f is a general nonlinear function from Rp to Rp, satisfy-
ing certain conditions, this is a (nonlinear) hyperbolic system. Such systems are of
paramount importance in many applications, for example in gas dynamics, and there
is a very large body of numerical schemes that are adapted to the approximation of
the solutions of such systems, see [42] for example.
We present a few of these schemes in the case of our simple R2-valued, linear
hyperbolic system (9.18). We will also return to some of these schemes in the next
chapter. Again, we work on the whole line3 and on the usual (nh, jk) space-time Ô¨Ånite
difference grid for the approximations. We start with the Lax‚ÄìFriedrichs scheme,
which reads in general
U j+1
n
‚àí1
2(U j
n+1 + U j
n‚àí1)
k
+ f (U j
n+1) ‚àíf (U j
n‚àí1)
2h
= 0,
3Boundary conditions are a delicate question for such systems.

342
9
The Wave Equation
and in our particular case
‚éß
‚é™‚é®
‚é™‚é©
v j+1
n
= 1
2(v j
n+1 + v j
n‚àí1) + k
2h (w j
n+1 ‚àíw j
n‚àí1),
w j+1
n
= 1
2(w j
n+1 + w j
n‚àí1) + k
2h (v j
n+1 ‚àív j
n‚àí1).
The scheme is one-step, of order one and explicit. We write the usual semi-discrete
version of the scheme, then apply the Fourier transform, and we obtain
‚éß
‚é™‚é®
‚é™‚é©

v j+1(Œæ) = cos(hŒæ)
v j(Œæ) + i k
h sin(hŒæ)
w j(Œæ),

w j+1(Œæ) = cos(hŒæ)
w j(Œæ) + i k
h sin(hŒæ)
v j(Œæ).
Therefore, the ampliÔ¨Åcation matrix of the Lax‚ÄìFriedrichs scheme is
B(Œæ) =
 cos(hŒæ) i k
h sin(hŒæ)
i k
h sin(hŒæ)
cos(hŒæ)

.
This matrix is normal and its spectral radius is œÅ(B(Œæ)) =

cos2(hŒæ) +
k2
h2 sin2(hŒæ)
1/2. It clearly follows that
Proposition 9.17 The Lax‚ÄìFriedrichs scheme is von Neumann stable and L2 stable
under the condition k
h ‚â§1.
We consider next the Lax‚ÄìWendroff scheme. In our particular case, the scheme
reads
‚éß
‚é™‚é™‚é®
‚é™‚é™‚é©
v j+1
n
= v j
n + k
2h (w j
n+1 ‚àíw j
n‚àí1) + k2
2h2 (v j
n+1 ‚àí2v j
n + v j
n‚àí1),
w j+1
n
= w j
n + k
2h (v j
n+1 ‚àív j
n‚àí1) + k2
2h2 (w j
n+1 ‚àí2w j
n + w j
n‚àí1).
The scheme is one-step, of order two and explicit. After Fourier transform, it becomes
‚éß
‚é™‚é™‚é®
‚é™‚é™‚é©

v j+1(Œæ) =

1 ‚àí2k2
h2 sin2hŒæ
2
		

v j(Œæ) + i k
h sin(hŒæ)
w j(Œæ),

w j+1(Œæ) =

1 ‚àí2k2
h2 sin2hŒæ
2
		

w j(Œæ) + i k
h sin(hŒæ)
v j(Œæ),
hence the ampliÔ¨Åcation matrix
B(Œæ) =

1 ‚àí2k2
h2 sin2 hŒæ
2

i k
h sin(hŒæ)
i k
h sin(hŒæ)

1 ‚àí2k2
h2 sin2 hŒæ
2


.

9.6 For a Few Schemes More
343
Thismatrixisagainnormalanditfollowsfromelementarycomputationsthatithas
a spectral radius œÅ(B(Œæ)) =

1 ‚àí4 k2
h2 (1 ‚àík2
h2 ) sin4 hŒæ
2
1/2. Therefore, we see that
Proposition 9.18 The Lax‚ÄìWendroff scheme is von Neumann stable and L2 stable
under the condition k
h ‚â§1.
We can also revisit the leapfrog scheme, which reads here
‚éß
‚é™‚é®
‚é™‚é©
v j+1
n
= v j‚àí1
n
+ k
h (w j
n+1 ‚àíw j
n‚àí1),
w j+1
n
= w j‚àí1
n
+ k
h (v j
n+1 ‚àív j
n‚àí1).
Note that it leapfrogs in time as well as in space. The scheme is two-step, of order two
and explicit. To write an ampliÔ¨Åcation matrix for it, we need to double the dimension
and consider for example the vectors

v j+1(Œæ), 
w j+1(Œæ), 
v j(Œæ), 
w j(Œæ)
T , a choice
which yields the ampliÔ¨Åcation matrix
B(Œæ) =
‚éõ
‚éú‚éú‚éù
0
2i k
h sin(hŒæ)
1
0
2i k
h sin(hŒæ)
0
0
1
1
0
0
0
0
1
0
0
‚éû
‚éü‚éü‚é†.
This matrix is not normal.
Proposition 9.19 The leapfrog scheme is von Neumann stable under the condition
k
h ‚â§1. It is L2 stable under the condition k
h ‚â§Œª0 < 1.
Proof Let b(Œæ) = k
h sin(hŒæ). If we write B(Œæ) as a 2 √ó 2 block matrix of four 2 √ó 2
blocks, we see by Lemma8.2 of Chap.8 that its eigenvalues are given by
Œª = ¬±
‚àö
1 ‚àíb2 ¬± ib when k
h ‚â§1, so that œÅ(B(Œæ)) = 1 for all Œæ.
Concerning the L2-stability, if k
h ‚â§Œª0 < 1, we have four distinct eigenvalues
of modulus 1, so we only need to estimate the condition number of the change of
matrix basis
P(Œæ) =
‚éõ
‚éú‚éú‚éù
1
1
1
1
1
1
‚àí1
‚àí1
‚àö
1 ‚àíb2 ‚àíib
‚àí
‚àö
1 ‚àíb2 ‚àíib
‚àö
1 ‚àíb2 + ib
‚àí
‚àö
1 ‚àíb2 + ib
‚àö
1 ‚àíb2 ‚àíib
‚àí
‚àö
1 ‚àíb2 ‚àíib ‚àí
‚àö
1 ‚àíb2 ‚àíib
‚àö
1 ‚àíb2 ‚àíib
‚éû
‚éü‚éü‚é†.
Using computer algebra again, we Ô¨Ånd that
cond2(P(Œæ)) =
&
1 + |b(Œæ)|
1 ‚àí|b(Œæ)| ‚â§
&
2
1 ‚àíŒª0
,
hence the stability of the scheme.
‚ñ°

344
9
The Wave Equation
Remark 9.31 Theconditionalstabilityoftheleapfrogschemeistobecontrastedwith
the situation for the heat equation, where the leapfrog scheme is always unstable,
see Proposition8.10 in Chap.8.
‚ñ°
Remark 9.32 We note that we cannot allow Œª0 = 1. Indeed, in this case, there are
values of Œæ for which b(Œæ) = ¬±1. For these values of Œæ, the matrix B(Œæ) has two
double eigenvalues ¬±i and is not diagonalizable. Therefore |||B(Œæ) j|||2 ‚Üí+‚àûas
j ‚Üí+‚àû, and the scheme is unstable in L2.
‚ñ°
9.7
Concluding Remarks
To conclude this chapter, we note that there are other issues than just consistency
and stability in the study of Ô¨Ånite difference schemes for hyperbolic systems. Even
though we have not mentioned them at all here, they are important in assessing
the performance of a given scheme. Among these issues are dissipativity, i.e., the
possible damping of wave amplitudes with time, and dispersivity, i.e., the possibility
that numerically approximated waves of different frequencies could travel at different
numerical speeds.
Naturally, there are other numerical methods applicable to the wave equation, for
instance Ô¨Ånite difference-Ô¨Ånite element methods, see for example [65].
We have so far described and analyzed two major classes of numerical methods,
Ô¨Ånite difference methods and Ô¨Ånite element methods, in the contexts of the three
main classes of problems, elliptic, parabolic and hyperbolic. In the last chapter, we
introduce a more recent method, the Ô¨Ånite volume method, on a few elliptic and
hyperbolic examples.

Chapter 10
The Finite Volume Method
The Ô¨Ånite volume method is a more recent method than both Ô¨Ånite difference and
Ô¨Ånite element methods. It is widely used in practice for example in Ô¨Çuid dynamics
computations. We present the method in the simplest possible settings, Ô¨Årst for one-
dimensional elliptic problems, then for the transport equation in one and two dimen-
sions. For the latter, we return to the method of characteristics already introduced
in Chap.1, to solve one-dimensional nonlinear problems as well as two-dimensional
linear problems.
10.1
The Elliptic Case in One Dimension
Let us consider the elliptic problem ‚àíu‚Ä≤‚Ä≤ = f in ]0, 1[, with homogeneous Dirichlet
boundary conditions u(0) = u(1) = 0. The idea of the Ô¨Ånite volume discretization is
tosubdividethedomainintoaÔ¨Ånitenumberofsubsetscalledcells,orcontrolvolumes
especially in higher dimension, which are disjoint up to a set of zero measure, and
integrate the equation on each cell. The resulting integrals are then approximated
by computable quantities. The main difference with all previous methods is that the
discrete unknowns to be introduced will be meant to be approximations of the mean
value of the solution on each cell. In a sense, the Ô¨Ånite volume approximation is an
approximation by piecewise constant functions.
It may seem strange to approximate an a priori smooth function, say of class C2 if
f is continuous, that solves a problem involving derivatives, by piecewise constant
functions. In fact, the method does not approximate the differential equation itself
in one form or another, but starts from the integration of the differential equation
over each cell, followed by approximation. So this is a quite different philosophy
compared to both Ô¨Ånite difference and Ô¨Ånite element methods which work on the
PDE itself expressed in different forms.
¬© Springer International Publishing Switzerland 2016
H. Le Dret and B. Lucquin, Partial Differential Equations:
Modeling, Analysis and Numerical Approximation, International Series
of Numerical Mathematics 168, DOI 10.1007/978-3-319-27067-8_10
345

346
10
The Finite Volume Method
Fig. 10.1 Finite volume cells in 1D
More precisely, let N ‚ààN‚àóbe given. In the one-dimensional case, cells are just
going to be subintervals Cn, n = 1, . . . , N. We let xn denote the middle of Cn and
xn‚àí1/2 < xn+1/2 denote its extremities so that Cn = [xn‚àí1/2, xn+1/2]. The local cell
size is hn = xn+1/2 ‚àíxn‚àí1/2. It is not a priori a constant, see Fig.10.1.
We also set h0 = h1, hN+1 = hN, x0 = ‚àíx1 and xN+1 = 2 ‚àíxN. For all
n = 0, . . . , N, we let hn+1/2 = hn+1+hn
2
= xn+1 ‚àíxn be the distance between the
centers of two consecutive cells. If we integrate the equation ‚àíu‚Ä≤‚Ä≤ = f on Cn, we
obtain
‚àíu‚Ä≤
xn+ 1
2

+ u‚Ä≤
xn‚àí1
2

=

Cn
f (x) dx,
(10.1)
for n = 1, . . . , N. We use the following approximations for the derivatives
u‚Ä≤
xn+ 1
2

‚âà
1
hn+1

Cn+1 u(x) dx ‚àí1
hn

Cn u(x) dx
hn+ 1
2
,
(10.2)
for n = 1, . . . , N ‚àí1,
u‚Ä≤
x 1
2

‚âà
1
h1

C1 u(x) dx
h 1
2
,
(10.3)
and
u‚Ä≤
xN+ 1
2

‚âà‚àí
1
hN

CN u(x) dx
hN+ 1
2
.
(10.4)
Indeed, assuming that u is of class C2, a Taylor‚ÄìLagrange expansion shows that
u(x) = u

xn+ 1
2

+

x ‚àíxn+ 1
2

u‚Ä≤
xn+ 1
2

+ O(h2),

10.1 The Elliptic Case in One Dimension
347
where h = maxn hn. Therefore, if n = 1, . . . , N ‚àí1
1
hn+1

Cn+1
u(x) dx = u

xn+ 1
2

+ hn+1
2
u‚Ä≤
xn+ 1
2

+ O(h2),
1
hn

Cn
u(x) dx = u

xn+ 1
2

‚àíhn
2 u‚Ä≤
xn+ 1
2

+ O(h2),
(10.5)
and thus

1
hn+1

Cn+1 u(x) dx ‚àí1
hn

Cn u(x) dx
hn+ 1
2
‚àíu‚Ä≤
xn+ 1
2

 ‚â§Ch,
(10.6)
where the constant C only depends on u. For n = 0, we have by the same token
1
h1

C1
u(x) dx = u

x 1
2

+ h1
2 u‚Ä≤
x 1
2

+ O(h2) = h1
2 u‚Ä≤
x 1
2

+ O(h2),
due to the Dirichlet boundary condition, so that

1
h1

C1 u(x) dx
h 1
2
‚àíu‚Ä≤
x 1
2

 ‚â§Ch,
and likewise for n = N. We have thus shown that
Proposition 10.1 The Ô¨Ånite volume approximation (10.2)‚Äì(10.4) of Ô¨Årst derivatives
is consistent of order 1.
Following a process that is now familiar, we introduce discrete unknowns un,
n = 1, . . . , N, to take the place of the average value of the exact solution on cell Cn,
1
hn

Cn u(x) dx, and replace it in an analogue of Eq.(10.1). We Ô¨Årst let
Fn+ 1
2 = ‚àíun+1 ‚àíun
hn+ 1
2
for 2 ‚â§n ‚â§N ‚àí1,
and
F1
2 = ‚àíu1
h 1
2
, FN+ 1
2 =
uN
hN+ 1
2
,
where the latter two relations take the Dirichlet condition into account at the discrete
level. The quantities Fn+1/2 are called the numerical Ô¨Çuxes, since they are meant to
approximate the actual Ô¨Çuxes ‚àíu‚Ä≤(xn+1/2). This way, we obtain the Ô¨Ånite volume
scheme
Fn+ 1
2 ‚àíFn‚àí1
2 = fn, n = 1, . . . , N,
(10.7)

348
10
The Finite Volume Method
with
fn =

Cn
f (x) dx.
(10.8)
Rewriting the Ô¨Ånite volume scheme line by line, we obtain for n = 1
 1
h 1
2
+ 1
h 3
2

u1 ‚àí1
h 3
2
u2 = f1,
for 2 ‚â§n ‚â§N ‚àí1,
‚àí
1
hn‚àí1
2
un‚àí1 +

1
hn‚àí1
2
+
1
hn+ 1
2

un ‚àí
1
hn+ 1
2
un+1 = fn,
and for n = N,
‚àí
1
hN‚àí1
2
uN‚àí1 +

1
hN‚àí1
2
+
1
hN+ 1
2

uN = fN.
Thus we see that the scheme assumes the form of a linear system
‚éõ
‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éú‚éù
1
h 1
2
+
1
h 3
2
‚àí1
h 3
2
¬∑ ¬∑ ¬∑
¬∑ ¬∑ ¬∑
0
‚àí1
h 3
2
1
h 3
2
+
1
h 5
2
‚àí1
h 5
2
¬∑ ¬∑ ¬∑
0
...
...
...
...
...
0
¬∑ ¬∑ ¬∑
‚àí
1
hN‚àí3
2
1
hN‚àí3
2
+
1
hN‚àí1
2
‚àí
1
hN‚àí1
2
0
¬∑ ¬∑ ¬∑
¬∑ ¬∑ ¬∑
‚àí
1
hN‚àí1
2
1
hN‚àí1
2
+
1
hN+ 1
2
‚éû
‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚éü‚é†
‚éõ
‚éú‚éú‚éú‚éù
u1
u2
...
uN
‚éû
‚éü‚éü‚éü‚é†=
‚éõ
‚éú‚éú‚éú‚éù
f1
f2
...
fN
‚éû
‚éü‚éü‚éü‚é†,
(10.9)
or in short AhUh = Fh. The matrix Ah of the above linear system bears a strong
resemblance to the matrix by the same name involved in the Ô¨Ånite difference method
in Chap.2. Before we discuss the well-posedness and eventual convergence of the
Ô¨Ånite volume method, let us see that the method is nonetheless fundamentally dif-
ferent from the Ô¨Ånite difference method, in spite of appearances.
Let us thus consider for an instant the linear system (10.9) as stemming from a
Ô¨Ånite difference scheme, that is to say assume that un ‚âàu(xn). Then the approxi-
mation in the left-hand side of Eq.(10.7) divided by hn, so that the right-hand side
becomes a consistent approximation of f (xn), is not a consistent approximation of
‚àíu‚Ä≤‚Ä≤(xn). Indeed, if we compute the truncation error in this context, we Ô¨Ånd
hnŒµh(u)n = ‚àí
1
hn‚àí1
2
u(xn‚àí1)+

1
hn‚àí1
2
+
1
hn+ 1
2

u(xn)‚àí
1
hn+ 1
2
u(xn+1)‚àí

Cn
f (x) dx,

10.1 The Elliptic Case in One Dimension
349
so that using Taylor‚ÄìLagrange expansions, we obtain
Œµh(u)n =

1 ‚àí
hn‚àí1
2 + hn+ 1
2
2hn

u‚Ä≤‚Ä≤(xn) + O(h).
Now, if we are given a sequence of Ô¨Ånite volume meshes indexed by h and such
that h ‚Üí0, there is no reason in general for hn‚àí1/2+hn+1/2
2hn
to tend to 1, except in very
special cases. Actually, it is easy to construct a sequence that does not exhibit such
a convergence. Therefore, the above truncation error does not tend to 0 in general.
This shows that the Ô¨Ånite volume scheme is quite different from a Ô¨Ånite difference
scheme.
We now return to the study of the Ô¨Ånite volume scheme (10.7)‚Äì(10.8). First of all,
the scheme is well-posed.
Proposition 10.2 The matrix Ah is invertible.
Proof We show that the matrix Ah is actually positive deÔ¨Ånite, which implies that it
is invertible. Given X ‚ààRN, we have
X T Ah X = X2
1
h 1
2
+
N‚àí1

n=1
(Xn+1 ‚àíXn)2
hn+ 1
2
+
X2
N
hN+ 1
2
,
from which the result easily follows.
‚ñ°
Let us now show the convergence of the scheme when h ‚Üí0.
Proposition 10.3 Assume that f ‚ààC0([0, 1]). There exists a constant C that does
not depend on h such that
max
1‚â§i‚â§N
un ‚àí1
hn

Cn
u(x) dx
 ‚â§Ch.
Proof We let en = un ‚àí1
hn

Cn u(x) dx for n = 1, . . . , N and e0 = eN+1 = 0. Let
¬ØFn+1/2 = ‚àíu‚Ä≤(xn+1/2) denote the actual Ô¨Çuxes. We have by Eq.(10.1)
¬ØFn+ 1
2 ‚àí¬ØFn‚àí1
2 = fn, n = 1, . . . , N,
so that taking Eq.(10.7) into account, it follows that
Dn+ 1
2 ‚àíDn‚àí1
2 = 0, n = 1, . . . , N,
(10.10)
where Dn+1/2 = Fn+1/2 ‚àí¬ØFn+1/2.

350
10
The Finite Volume Method
Since f is continuous, it follows that u is of class C2, hence estimate (10.6) applies
and we can write
‚àí
1
hn+1

Cn+1 u(x) dx ‚àí1
hn

Cn u(x) dx
hn+ 1
2
= ¬ØFn+ 1
2 + dn+ 1
2 ,
with
dn+1/2
 ‚â§Ch, with the obvious modiÔ¨Åcations for n = 0 and n = N. Therefore
Dn+ 1
2 = ‚àíen+1 ‚àíen
hn+ 1
2
+ dn+ 1
2 ,
and the constancy (10.10) of Dn+1/2 implies that
en ‚àíen‚àí1
hn‚àí1
2
‚àídn‚àí1
2 ‚àíen+1 ‚àíen
hn+ 1
2
+ dn+ 1
2 = 0.
We multiply the previous relation by en and sum for n = 1 to N. This yields
N

n=1
en
en ‚àíen‚àí1
hn‚àí1
2
‚àí
N

n=1
en
en+1 ‚àíen
hn+ 1
2
= ‚àí
N

n=1
dn+ 1
2 en +
N

n=1
dn‚àí1
2 en.
Taking into account the fact that e0 = eN+1 = 0 and reordering the terms, we obtain
N

n=0
(en+1 ‚àíen)2
hn+ 1
2
= ‚àí
N

n=0
dn+ 1
2 (en ‚àíen+1) ‚â§Ch
N

n=0
en ‚àíen+1
.
By the Cauchy‚ÄìSchwarz inequality, the right-hand side is estimated by
N

n=0
en ‚àíen+1
 ‚â§
 N

n=0
(en+1 ‚àíen)2
hn+ 1
2
1/2 N

n=0
hn+ 1
2
1/2
.
Now of course N
n=0 hn+1/2 = 1 and combining the above estimates, we obtain
N

n=0
(en+1 ‚àíen)2
hn+ 1
2
‚â§C2h2.
It follows immediately from the last two estimates that
N

n=0
|en+1 ‚àíen| ‚â§Ch.

10.1 The Elliptic Case in One Dimension
351
To conclude, we notice that en = n‚àí1
j=0(e j+1 ‚àíe j), for n = 1, . . . , N, so that
|en| ‚â§
n‚àí1

j=0
|e j+1 ‚àíe j| ‚â§
N

j=0
|e j+1 ‚àíe j| ‚â§Ch,
by the previous estimate.
‚ñ°
Theaboveproofshowsthatun iscloseto 1
hn

Cn u(x) dx whenh issmall,uniformly
with respect to n. We can easily infer a Ô¨Ånite difference-like convergence result as
follows.
Corollary 10.1 Under the previous hypotheses, we have
max
1‚â§i‚â§N |un ‚àíu(xn)| ‚â§Ch,
where C does not depend on h.
Proof Indeed, for x ‚ààCn, we can write u(x) = u(xn) + (x ‚àíxn)u‚Ä≤(Œæ) for some
Œæ ‚ààCn. Therefore |u(x) ‚àíu(xn)| ‚â§h maxx‚àà[0,1] |u‚Ä≤|. Integrating this inequality on
Cn, we obtain
 1
hn

Cn
u(x) dx ‚àíu(xn)
 ‚â§1
hn

Cn
|u(x) ‚àíu(xn)| dx ‚â§h max
x‚àà[0,1] |u‚Ä≤|,
and the Corollary follows.
‚ñ°
Remark 10.1 If u is C4, it is possible to obtain a better right-hand side of the error
estimate of Corollary 10.1, namely Ch2.
‚ñ°
Remark 10.2 Proposition 10.3 still holds true if f is only supposed to be in L1, see
[36].
‚ñ°
10.2
The Transport Equation in One Dimension
Let us Ô¨Årst expand a little on the presentation of the theory of the transport equation
of Chap.1, Sect.1.4, before describing the Ô¨Ånite volume method in this context.
The Cauchy problem for the transport, or advection, equation reads
‚éß
‚é®
‚é©
‚àÇu
‚àÇt (x, t) + a ‚àÇu
‚àÇx (x, t) = 0, x ‚ààR, t > 0,
u(x, 0) = u0(x), x ‚ààR,
(10.11)
where u(x, t) is the unknown density of some quantity at point x and time t, a
quantity per unit length, and a is a given constant that represents the propagation or

352
10
The Finite Volume Method
advection speed of u. In this interpretation, q(x, t) = au(x, t) represents the Ô¨Çux of
the quantity under consideration passing through x at time t, i.e., a quantity per unit
of time. The initial data u0 is given. We have seen in Chap.1 that when u0 is regular,
there is a unique regular solution given by
u(x, t) = u0(x ‚àíat).
(10.12)
As a matter of fact, a crucial property of the transport equation is that the solution
u is constant along the characteristics, i.e., the integral curves of the vector Ô¨Åeld
a (admittedly, a one-dimensional vector Ô¨Åeld in our present case). By deÔ¨Ånition, a
characteristic is a curve t ‚ÜíX(t) which satisÔ¨Åes the ordinary differential equation
d X
dt (t) = a.
(10.13)
We see that when plotted in space‚Äìtime, all characteristics, i.e., the curves t ‚Üí
(X(t), t),1 are straight lines that are parallel to each other. Moreover, given any
(y, s) ‚ààR2, there is one and only one characteristic passing through point y at time
s, X(t; y, s) = y +a(t ‚àís), t ‚ààR. Note that if x = X(t; y, s), then y = X(s; x, t),
a relation which holds true for more general right-hand sides in Eq.(10.13), of the
form a(X(t), t). With this notation, the solution of the transport equation (10.12)
becomes
u(x, t) = u0(X(0; x, t)).
The initial data is simply propagated on the characteristics, at constant speed a,
to the right if a > 0, to the left if a < 0, and it is stationary if a = 0. To Ô¨Ånd the
value of the solution u at (x, t), it is enough to look at the characteristic passing
through x at time t, and pick the value of u0 at the point x0 = X(0; x, t) where the
characteristic was at time 0, see Fig.1.10 in Chap.1 where the characteristics are
drawn in a space‚Äìtime diagram.
The deÔ¨Ånition of characteristics can be extended to the case of transport equations
with non constant speed, i.e., a is a given function of x and t,
‚àÇu
‚àÇt (x, t) + a(x, t)‚àÇu
‚àÇx u(x, t) = 0.
The characteristics are again deÔ¨Åned by
‚éß
‚é®
‚é©
d
dt X(t; y, s) = a(X(t; y, s), t),
X(s; y, s) = y.
(10.14)
1We call both curves characteristics, even though they do not live in the same space, and switch
between the two meanings without notice.

10.2 The Transport Equation in One Dimension
353
The mapping t ‚ÜíX(t; y, s) is the characteristic going through y at time s. The
characteristics no longer are straight lines in space‚Äìtime. Local existence of such
curves is ensured by the Picard‚ÄìLindel√∂f or Cauchy‚ÄìLipschitz theorem, as soon as
a is sufÔ¨Åciently regular (continuous with respect to (x, t), Lipschitz with respect the
space variable x uniformly with respect to t). It is easily seen that the solution u is
still constant on each characteristic. Moreover, due to Cauchy‚ÄìLipschitz uniqueness,
different characteristics do not intersect and therefore u(x, t) = u0(X(0; x, t)) as
before, as long as the characteristics exist.
The method of characteristics also makes it possible to consider the case when
there is a source term in the right-hand side, i.e., an equation of the form
‚àÇu
‚àÇt (x, t) + a(x, t)‚àÇu
‚àÇx u(x, t) = f (x, t),
where f is a given function. Integrating this equation along the characteristics, we
obtain
u(x, t) = u0(X(0; x, t)) +
 t
0
f (X(œÑ; x, t), œÑ) dœÑ,
(10.15)
see Proposition 10.13 below for a proof in any dimension.
We have already mentioned nonlinear hyperbolic systems in Chap.9. In the one-
dimensional case, such systems become nonlinear transport equations,
‚éß
‚é®
‚é©
‚àÇu
‚àÇt (x, t) + ‚àÇ( f (u))
‚àÇx
(x, t) = 0, x ‚ààR, t > 0
u(x, 0) = u0(x), x ‚ààR,
(10.16)
where f is a given function from R to R, called the Ô¨Çux function. The linear case
corresponds to Ô¨Çux functions of the form f (u) = au with a ‚ààR, and we recover
Eq.(10.11). The simplest nonlinear example is the classical Burgers equation, which
corresponds to f (u) = u2
2 .
The method of characteristics also applies to nonlinear transport equations. In the
nonlinear case, the speed of propagation depends on the solution u, which makes
them much more complicated than linear transport equations. Indeed, if u is a solution
of class C1 of (10.16), we can write
‚àÇu
‚àÇt + f ‚Ä≤(u)‚àÇu
‚àÇx = 0.
For instance, regular solutions of the Burgers equation satisfy
‚àÇu
‚àÇt (x, t) + u(x, t)‚àÇu
‚àÇx (x, t) = 0.

354
10
The Finite Volume Method
In this particular case, we see that when u > 0, the propagation goes to the right with
a speed that increases with u. If we imagine an initial wave proÔ¨Åle u0 with a crest to
the left of a trough, the crest will ride faster than the trough and eventually catch up
with it, which leads to serious difÔ¨Åculties.
In the general case, the propagation speed is thus f ‚Ä≤(u), which is not known a pri-
ori. In the present context, the characteristics are deÔ¨Åned by the ordinary differential
equation
d X
dt (t) = f ‚Ä≤(u(X(t), t)).
It is not too difÔ¨Åcult to show that, as long as it remains regular, the solution u is
constant along the characteristics and that the characteristics are therefore straight
lines again. However, the speed of propagation along such a line, i.e., its slope in
space‚Äìtime, depends on the value of u on this particular characteristic, which in
turn is equal to the value of u0 at the point where the characteristic was at time
0. Consequently, the characteristics are in general no longer parallel to each other.
DifÔ¨Åculties arise when these lines cross, see the crest-trough discussion above. We are
not going to study this problem, which involves so-called weak solutions, or solutions
in the distributional sense, and shock waves, any further here. Nevertheless, as long
as the characteristics do not intersect each other, the regular solution is still given by
the same formula
u(x, t) = u0(X(0; x, t)).
10.3
Finite Volumes for the Transport Equation
We now describe the Ô¨Ånite volume method for the transport equation (10.11) in the
linear case with a constant for simplicity. We Ô¨Årst cover the whole space R by cells
Cn =

xn‚àí1/2, xn+1/2

, with xn‚àí1/2 < xn+1/2, n ‚ààZ, and we look for a piecewise
constant approximation of the solution u, which is constant on each cell Cn, at some
discretized instants.
We set hn = xn+1/2 ‚àíxn‚àí1/2. As in the elliptic case, hn is a local cell size, it is
not necessarily a constant. Let xn denote the middle of Cn. We introduce the mean
value ¬Øun(t) of u(¬∑, t) on cell Cn, i.e.,
¬Øun(t) = 1
hn

Cn
u(x, t) dx.
In a Ô¨Årst step, we want to approximate ¬Øun(t) by a quantity denoted by un(t) ‚ààR
for each t and n. Time will be discretized later on. We Ô¨Årst integrate the equation on
each cell Cn

Cn
‚àÇu
‚àÇt + ‚àÇq
‚àÇx

(x, t) dx = 0,

10.3 Finite Volumes for the Transport Equation
355
where q = au is the Ô¨Çux, then compute both terms. The Ô¨Årst term is

Cn
‚àÇu
‚àÇt (x, t) dx = d
dt

Cn
u(x, t) dx

= hn
d ¬Øun
dt (t)
by differentiation under the integral sign, and the second term reads

Cn
‚àÇq
‚àÇx (x, t) dx = q

xn+ 1
2 , t

‚àíq

xn‚àí1
2 , t

,
by direct integration, so that we have
hn
d ¬Øun
dt (t) + q

xn+ 1
2 , t

‚àíq

xn‚àí1
2 , t

= 0.
So far, there is no approximation, the above relation is an exact consequence of the
transport equation.
Sincethesemi-discreteunknownsun(t)wearelookingforaresupposedtoapprox-
imate the mean values ¬Øun(t), and not the values of u at the interfaces between cells, we
need an approximation of the Ô¨Çuxes q

xn+1/2, t

= au

xn+1/2, t

that is expressed
only in terms of the semi-discrete unknowns. This is achieved by means of an approx-
imated Ô¨Çux or numerical Ô¨Çux, a function g in two variables which is used to compute
this approximation as follows
gn+ 1
2 (t) = g(un(t), un+1(t)) ‚âàq

xn+ 1
2 , t

.
Of course, the numerical Ô¨Çux g must be chosen in such a way that the above approx-
imation makes reasonable sense. This yields a semi-discrete scheme
hn
dun
dt (t) + g(un(t), un+1(t)) ‚àíg(un‚àí1(t), un(t)) = 0,
(10.17)
for t > 0 and n ‚ààZ, which is an inÔ¨Ånite system of ordinary differential equations.
The properties of the scheme partly result from the choice of the numerical Ô¨Çux
g. We will give a few examples below. If un(t) = un+1(t) for some n, and t, there
is one natural Ô¨Çux between the two cells, namely aun(t) = aun+1(t), which should
naturally be retained. This requirement is fulÔ¨Ålled as soon as
‚àÄv ‚ààR, g(v, v) = av.
(10.18)
From now on, we will make the above assumption on the numerical Ô¨Çux, which is
related to consistency, see Proposition 10.8 below.
We now consider the discretization with respect to time. We use a classical method
of approximation for ordinary differential equations, for example the Euler explicit
scheme. Let M ‚ààN be an integer and k =
T
M+1 be the time step. We let t j = jk,

356
10
The Finite Volume Method
0 ‚â§j ‚â§M + 1. We denote by u j
n the approximation of ¬Øu j
n =
1
hn

Cn u(x, t j)dx that
we want to compute. Discretizing system (10.17) in time accordingly, we thus obtain
the following explicit scheme:
hn
u j+1
n
‚àíu j
n
k
+ g(u j
n, u j
n+1) ‚àíg(u j
n‚àí1, u j
n) = 0,
(10.19)
for j ‚â§M. Starting from an initial data u0
n given by
u0
n = 1
hn

Cn
u0(x) dx = ¬Øun(0),
(10.20)
we can thus compute u j
n, n ‚ààZ for all j ‚â§M + 1. Other ordinary differential
equation schemes for the discretization with respect to the time variable can also be
used, for example the implicit Euler scheme, the leapfrog scheme, or any Runge‚Äì
Kutta scheme. Of course, in practical computations, the set of indices n involved
must somehow be restricted to a Ô¨Ånite set, but we do not pursue this here.
Let us discuss the case of the upwind scheme, a commonly used scheme. In all
the sequel, we assume that h = supn‚ààZ hn < +‚àû, infn‚ààZ hn > 0 and that u is
sufÔ¨Åciently regular.
We start from scheme (10.19)‚Äì(10.20). We just have to specify the choice of the
numerical Ô¨Çux g, which is used to approximate au(xn+1/2, t j). The simplest choice
consists inapproximatingu(xn+1/2, t j) byoneof theneighboringapproximatedmean
values u j
n or u j
n+1. In the case a > 0, the upwind scheme corresponds to the choice
u j
n on the left and in the case a < 0, to the choice u j
n+1 on the right.
We thus set, depending on the sign of a,
g(u j
n, u j
n+1) = au j
n if a > 0, or g(u j
n, u j
n+1) = au j
n+1 if a < 0.
The case a = 0 is not interesting. This gives the upwind scheme
u j+1
n
‚àíu j
n
k
+ a u j
n ‚àíu j
n‚àí1
hn
= 0,
(10.21)
when a > 0 and
u j+1
n
‚àíu j
n
k
+ a u j
n+1 ‚àíu j
n
hn
= 0,
(10.22)
when a < 0. In both cases, we enforce the initial condition (10.20). Both choices
satisfy the consistency condition (10.18). The scheme is called upwind, in the sense
that we take into account the direction of the wind, i.e., the exact Ô¨Çux coming from
the left when a > 0 and from the right when a < 0.

10.3 Finite Volumes for the Transport Equation
357
Without loss of generality, we focus on the case a > 0 and consider the upwind
scheme in the form (10.21). We Ô¨Årst remark that, in the general case of a non constant
cell size, this Ô¨Ånite volume upwind scheme differs from the corresponding Ô¨Ånite
difference scheme. In fact, the Ô¨Ånite difference upwind scheme reads
v j+1
n
‚àív j
n
k
+ a v j
n ‚àív j
n‚àí1
hn‚àí1
2
= 0,
(10.23)
v0
n = u0(xn),
(10.24)
where hn‚àí1/2 = xn ‚àíxn‚àí1 = (hn + hn‚àí1)/2 and v j
n represents an approximation of
u(xn, t j). There are two differences between the Ô¨Ånite volume and Ô¨Ånite difference
schemes. The Ô¨Årst difference is that the factor hn in (10.21) is replaced by hn‚àí1/2
in (10.23) in order to write a difference quotient. The second difference lies in the
initial conditions, (10.20) versus (10.24). However, in the case of a constant cell size,
i.e., if hn = h for all n ‚ààZ, then the only difference comes from the discretization
of the initial condition. Moreover, as in the elliptic case, we can remark that the ratio
u j
n‚àíu j
n‚àí1
hn
is not a consistent approximation, in the Ô¨Ånite difference sense, of ‚àÇu
‚àÇx (xn, t j).
Indeed, if we perform the usual Taylor expansions, we obtain
u(xn‚àí1, t j) = u(xn, t j) ‚àíhn‚àí1
2
‚àÇu
‚àÇx (xn, t j) + O(h2),
so that
u(xn, t j) ‚àíu(xn‚àí1, t j)
hn
=
hn‚àí1
2
hn
‚àÇu
‚àÇx (xn, t j) + O(h),
and hn‚àí1/2/hn Ã∏‚Üí1 in general.
Let us now study the convergence of the Ô¨Ånite volume scheme (10.21)‚Äì(10.20).
We Ô¨Årst have the following Ô¨Ånite difference-like convergence result.
Proposition 10.4 We suppose that u is sufÔ¨Åciently regular and that there exists a
constant C ‚â•0 such that
sup
x‚ààR,t‚ààR+
‚àÇu
‚àÇx (x, t)
 ‚â§C,
sup
x‚ààR,t‚ààR+
‚àÇ2u
‚àÇx2 (x, t)
 ‚â§C,
sup
x‚ààR,t‚ààR+
‚àÇ2u
‚àÇt2 (x, t)
 ‚â§C.
Then, under the condition
a
k
infn‚ààZ hn
‚â§1,
(10.25)

358
10
The Finite Volume Method
there exists a constant C(T ) ‚â•0 such that, for any j such that j ‚â§M + 1, we have
sup
n‚ààZ
u j
n ‚àíu

xn+ 1
2 , t j
 ‚â§C(T )(h + k).
(10.26)
Proof Let us compare u j
n to u(xn+1/2, t j). For this purpose, we introduce
r j
n =
u

xn+ 1
2 , t j+1

‚àíu

xn+ 1
2 , t j

k
+ a
u

xn+ 1
2 , t j

‚àíu

xn‚àí1
2 , t j

hn
.
(10.27)
We use Taylor expansions, Ô¨Årst with respect to the space variable and then with
respect to the time variable. We Ô¨Årst have
u

xn‚àí1
2 , t j

= u

xn+ 1
2 , t j

‚àíhn
‚àÇu
‚àÇx

xn+ 1
2 , t j

+ h2
n
2
‚àÇ2u
‚àÇx2 (Œæn, t j),
where Œæn ‚àà]xn‚àí1/2, xn+1/2[, and secondly
u

xn+ 1
2 , t j+1

= u

xn+ 1
2 , t j

+ k ‚àÇu
‚àÇt

xn+ 1
2 , t j

+ k2
2
‚àÇ2u
‚àÇt2

xn+ 1
2 , œÑ j

,
where œÑ j ‚àà]t j, t j+1[. As u satisÔ¨Åes the transport equation (10.11), we have
‚àÇu
‚àÇt

xn+ 1
2 , t j

+ a ‚àÇu
‚àÇx

xn+ 1
2 , t j

= 0,
so that
r j
n = ‚àía hn
2
‚àÇ2u
‚àÇx2 (Œæn, t j) + k
2
‚àÇ2u
‚àÇt2

xn+ 1
2 , œÑ j

.
We deduce that
‚à•r j‚à•‚àû,h = sup
n‚ààZ
|r j
n | ‚â§C‚Ä≤(h + k),
(10.28)
where C‚Ä≤ = C
2 max(a, 1).
Let us now introduce the error e j = (e j
n)n‚ààZ deÔ¨Åned by e j
n = u j
n ‚àíu(xn+1/2, t j).
Comparing the scheme (10.21) with the deÔ¨Ånition (10.27) of r j
n , we obtain
e j+1
n
‚àíe j
n
k
+ a e j
n ‚àíe j
n‚àí1
hn
= ‚àír j
n ,
or equivalently
e j+1
n
=

1 ‚àía k
hn

e j
n + a k
hn
e j
n‚àí1 ‚àíkr j
n .

10.3 Finite Volumes for the Transport Equation
359
Under condition (10.25), we have 1 ‚àía k
hn ‚â•0 for all n, and a k
hn ‚â•0 by hypothesis
on a, so that the Ô¨Årst two terms form a convex combination of e j
n and e j
n‚àí1. Therefore,
by the triangle inequality
‚à•e j+1‚à•‚àû,h ‚â§‚à•e j‚à•‚àû,h + k‚à•r j‚à•‚àû,h ‚â§‚à•e j‚à•‚àû,h + C‚Ä≤k(h + k),
according to (10.28). By an immediate induction argument, we obtain, for any
j ‚â§M + 1
‚à•e j‚à•‚àû,h ‚â§‚à•e0‚à•‚àû,h + C‚Ä≤ jk(h + k) ‚â§‚à•e0‚à•‚àû,h + C‚Ä≤T (h + k).
To conclude, we need to estimate ‚à•e0‚à•‚àû,h. We have
e0
n = v0
n ‚àíu(xn+ 1
2 , 0) = 1
hn

Cn
u0(x)dx ‚àíu0

xn+ 1
2

.
Now, still using a Taylor expansion (see (10.5)), we have
 1
hn

Cn
u0(x)dx ‚àíu0

xn+ 1
2
 ‚â§C hn
2 ,
so that
‚à•e0‚à•‚àû,h ‚â§C
2 h.
This gives estimate (10.26) with C(T ) = C
2 + C‚Ä≤T .
‚ñ°
Remark 10.3 The hypotheses of Proposition 10.4 are satisÔ¨Åed provided u0 is regular
and u‚Ä≤
0 and u‚Ä≤‚Ä≤
0 are uniformly bounded on R.
We also deduce the following Ô¨Ånite volume convergence result.
Corollary 10.2 Under the assumptions of Proposition 10.4, there exists a non neg-
ative constant C(T ) such that, for any j ‚â§M + 1, we have
sup
n‚ààZ
u j
n ‚àí1
hn

Cn
u(x, t j)dx
 ‚â§C(T )(h + k).
Proof This results from the triangle inequality combined on the one hand with esti-
mate (10.26) and, on the other hand, with the Taylor expansion (10.5) applied to
u(¬∑, t j), from which we deduce
u

xn+ 1
2 , t j

‚àí1
hn

Cn
u(x, t j)dx
 ‚â§C
2 h,
hence the result.
‚ñ°

360
10
The Finite Volume Method
Remark 10.4 Condition (10.25) is in fact a CFL stability condition. We will come
back to that later.
Remark 10.5 Proposition 10.4 remains true when a < 0 under the CFL condition
|a|
k
infn‚ààZ hn
‚â§1,
which is thus valid for all a, provided that we change xn+1/2 into xn‚àí1/2 in estimate
(10.26) and in the proof when a < 0. Corollary 10.2 remains true without changes.
We can remark that, thanks to the explicit expression (10.12), the exact solution
u of the transport problem satisÔ¨Åes a maximum principle, in the sense that if there
exists two constants m‚àóand m‚àósuch that m‚àó‚â§u0 ‚â§m‚àó, then the same result holds
at any time t, i.e., we have m‚àó‚â§u(¬∑, t) ‚â§m‚àó. Let us show that, under the stability
condition (10.25), this property remains valid at the discrete level.
Proposition 10.5 We suppose that there exists two constants m‚àóand m‚àósuch that
m‚àó‚â§u0 ‚â§m‚àó. Then, under the stability condition (10.25), we have
for all n,
m‚àó‚â§u j
n ‚â§m‚àó,
(10.29)
for all j ‚â§M + 1. Moreover, setting u j = (u j
n)n‚ààZ, we have
‚à•u j+1‚à•‚àû,h ‚â§‚à•u j‚à•‚àû,h.
(10.30)
Proof The proof is by induction on j. The double inequality (10.29) is true for j = 0
by hypothesis. Let us suppose that it is true for the index j. We have
u j+1
n
=

1 ‚àía k
hn

u j
n + a k
hn
u j
n‚àí1.
By condition (10.25), we have 1 ‚àía k
hn ‚â•0 for all n, and a k
hn ‚â•0 by hypothesis on
a, so that u j+1
n
is a convex combination of u j
n and u j
n‚àí1. It trivially follows that
min(u j
n‚àí1, u j
n) ‚â§u j+1
n
‚â§max(u j
n‚àí1, u j
n),
from which m‚àó‚â§u j+1
n
‚â§m‚àófor all n ensues. Likewise, we obtain (10.30).
‚ñ°
A natural question that arises is what would happen if we had chosen a down-
wind approximation instead of the upwind approximation, i.e., formula (10.22) when
a > 0. Intuitively, the scheme is looking for information in the opposite direction to
whereitiscomingfrominthecontinuouscase.Sowecanexpectsuchaschemetofail.
Let us give a simple numerical example. We computed the solution on [‚àí2, 2] with
a compactly supported initial data u0 with both schemes. The upwind scheme per-
forms quite well, see Fig.10.2, whereas the downwind scheme gives rise to extreme

10.3 Finite Volumes for the Transport Equation
361
Fig. 10.2 Exact solution and upwind scheme for u0(x) =

(1 ‚àíx2)+
2, a = 1
Fig. 10.3 Downwind scheme with the same data
oscillations, see Fig.10.3. This is an instability issue, and we will go back to it later.
Note that if hn = h for all n, if Ô¨Ånite difference initial conditions u0
n = u0(xn) are
chosen and if a k
h = 1, then the upwind scheme computes exact values. Indeed, we
have then
u j
n = u j‚àí1
n‚àí1 = ¬∑ ¬∑ ¬∑ = u0
n‚àíj = u0(xn‚àíj) = u0(xn ‚àíjh) = u0(xn ‚àíat j).
The computations shown are performed using Ô¨Ånite volume initial data.
10.4
Explicit Three Point Schemes
Let us come back to the general form (10.19)‚Äì(10.20) of the scheme. For simplicity,
we suppose from now on that the mesh is uniform, i.e., hn = h for all n ‚ààZ. We set
Œª = k
h ,
and the scheme (10.19) then reads
u j+1
n
= u j
n ‚àíŒª

g(u j
n, u j
n+1) ‚àíg(u j
n‚àí1, u j
n)

.

362
10
The Finite Volume Method
This is a special case of a more general formulation
u j+1
n
= H(u j
n‚àí1, u j
n, u j
n+1),
(10.31)
where H : R3 ‚ÜíR is a given function. This function H must satisfy
H(v, v, v) = v,
(10.32)
for all v ‚ààR, in order for constant states to be preserved by the scheme. Indeed, if
u0(x) = u0 ‚ààR for all x ‚ààR, then obviously u(x, t) = u0 for all x, t.
The scheme (10.31) expresses u j+1
n
explicitly in terms of three values, namely
u j
n‚àí1, u j
n and u j
n+1. We say it is an explicit three point scheme.
DeÔ¨Ånition 10.1 The scheme (10.31) can be put in conservation form, or is conser-
vative, if there exists a function g : R2 ‚ÜíR, such that
H(v‚àí1, v0, v1) = v0 ‚àíŒª[g(v0, v1) ‚àíg(v‚àí1, v0)].
The function g is called the numerical Ô¨Çux, it is deÔ¨Åned up to an additive constant.
Note that when a three point scheme is conservative, then H(v, v, v) = v, for any
v ‚ààR.
Remark 10.6 More generally, we can consider (2‚Ñì+ 1) point schemes, where ‚Ñìis a
positive integer, of the form
u j+1
n
= H(u j
n‚àí‚Ñì, . . . , u j
n, . . . , u j
n+‚Ñì),
(10.33)
where H : R2‚Ñì+1 ‚ÜíR is a given function. The deÔ¨Ånition of conservative scheme
extends to this case with numerical Ô¨Çux g : R2‚Ñì‚ÜíR.
‚ñ°
Remark 10.7 This deÔ¨Ånition can be extended to nonlinear equations with a nonlinear
Ô¨Çux q = f (u). In this case, it is very important to be able to write scheme (10.33)
in conservation form, see [42] for example.
‚ñ°
In the linear case f (u) = au, the function H is often taken as a linear combination
of values v j, i.e., it is of the form
H(v‚àí1, v0, v1) =
1

l=‚àí1
clvl,
(10.34)
where the coefÔ¨Åcients cl only depend on Œª and a. In this case, we say that the scheme
itself is linear. According to condition (10.32), we will thus always have
1

l=‚àí1
cl = 1.
(10.35)

10.4 Explicit Three Point Schemes
363
Let us now study the properties of linear three point schemes. Since the cell size
is constant, these schemes can be interpreted as Ô¨Ånite difference schemes with initial
data given by the average values of u0 on the cells. Therefore, we only concentrate
on the properties of consistency, order and stability in spaces ‚Ñìp(Z).
We introduce the discrete norms on ‚Ñìp(Z),
‚à•v‚à•p,h = h1/p
n‚ààZ
|vn|p1/p
if 1 ‚â§p < +‚àû,
‚à•v‚à•‚àû,h = sup
n‚ààZ
|vn|,
already used for p = 2 in Chaps.8 and 9.2 For simplicity, we adopt the following
deÔ¨Ånition of stability in the present context.
DeÔ¨Ånition 10.2 We say that a scheme (10.31) is stable for the norm ‚à•¬∑ ‚à•p,h, 1 ‚â§
p ‚â§‚àû, if the sequence u j = (u j
n)n‚ààZ satisÔ¨Åes, for all j ‚â•0,
‚à•u j+1‚à•p,h ‚â§‚à•u j‚à•p,h,
for all initial data u0 ‚àà‚Ñìp(Z).
This deÔ¨Ånition of stability is signiÔ¨Åcantly more demanding than the one used before
in Chaps.8 and 9, see DeÔ¨Ånition 33. In practice, only the cases p = 2 and p = +‚àû
are used.
There are sufÔ¨Åcient conditions for ‚Ñì‚àûstability which are very simple to check.
Proposition 10.6 Let us consider a linear scheme (10.34)‚Äì(10.35). The scheme is
stable in ‚Ñì‚àûif and only if the coefÔ¨Åcients cl are all nonnegative.
Proof Let us assume that cl ‚â•0 for all l. Then by condition (10.35), u j+1
n
is a convex
combination of u j
n‚àí1, u j
n, and u j
n+1 so that
min
l=‚àí1,0,1 u j
n+l ‚â§u j+1
n
‚â§
max
l=‚àí1,0,1 u j
n+l
Now we have
‚àí‚à•u j‚à•‚àû,h ‚â§
min
l=‚àí1,0,1 u j
n+l
and
max
l=‚àí1,0,1 u j
n+l ‚â§‚à•u j‚à•‚àû,h,
therefore ‚àí‚à•u j‚à•‚àû,h ‚â§u j+1
n
‚â§‚à•u j‚à•‚àû,h for all n ‚ààZ. This clearly implies the
stability in ‚Ñì‚àû.
Assume now that c0 < 0. We thus have c‚àí1 ‚àíc0 + c1 = 1 ‚àí2c0 > 1. The initial
data u0
n = (‚àí1)n+1 is such that u1
0 = c‚àí1 ‚àíc0 + c1, hence ‚Ñì‚àûstability is violated.
Likewise, if c‚àí1 < 0, then ‚àíc‚àí1 + c0 + c1 = 1 ‚àí2c‚àí1 > 1, and an initial data such
that u0
‚àí1 = ‚àí1, u0
0 = u0
1 = 1 with ‚à•u0‚à•‚àû,h = 1 yields u1
0 = ‚àíc‚àí1 + c0 + c1, and
similarly for the case c1 < 0.
‚ñ°
2Eventhoughthe inÔ¨Ånitynormdoesnot involve h,we keepthe h subscript fornotational consistency.

364
10
The Finite Volume Method
Recall that condition (10.35) implies that constant states are preserved by the
scheme. Moreover, in this case, there exists an associated numerical Ô¨Çux, which is
also linear.
Lemma 10.1 Any linear scheme (10.34)‚Äì(10.35) admits a numerical Ô¨Çux of the form
g(u, v) = 1
Œª(c‚àí1u ‚àíc1v).
(10.36)
Proof The three point scheme reads
u j+1
n
= c‚àí1u j
n‚àí1 + c0u j
n + c1u j
n+1.
By (10.35), it follows that
u j+1
n
= u j
n ‚àí

(c‚àí1u j
n ‚àíc1u j
n+1) ‚àí(c‚àí1u j
n‚àí1 ‚àíc1u j
n)

.
Hence g is given by (10.36).
‚ñ°
DeÔ¨Ånition 10.3 Alinearschemeissaidtobemonotoneifgiventwoinitialconditions
u0 and w0 such that u0
n ‚â•w0
n for all n, we have u1
n ‚â•w1
n for all n.
Obviously, we also have u j
n ‚â•w j
n, for all j and n. Schemes that satisfy the
hypotheses of Proposition 10.6 are monotone. We have already seen one example of
such schemes, the upwind scheme, under the stability condition (10.25). We will see
another example below, the Lax‚ÄìFriedrichs scheme.
As before, ‚Ñì2 stability is studied via Fourier series.
Proposition 10.7 A linear scheme (10.34) is stable in ‚Ñì2 if and only if the function
m(s) =
1

l=‚àí1
cle‚àíils
(10.37)
satisÔ¨Åes
‚àÄs ‚àà[0, 2œÄ],
|m(s)| ‚â§1.
(10.38)
The function m is the ampliÔ¨Åcation coefÔ¨Åcient of the scheme and condition (10.38)
is the von Neumann condition.
Proof We use the Fourier series approach, see Sect.8.7 of Chap.8. For any v ‚àà‚Ñì2,
deÔ¨Åning F(v)(s) = 
n‚ààZ vneins ‚ààL2(0, 2œÄ), we obtain
F(u j+1)(s) = m(s)F(u j)(s),

10.4 Explicit Three Point Schemes
365
where m is deÔ¨Åned by (10.37). We know that the von Neumann condition (10.38) is
then equivalent to
‚à•F(u j+1)‚à•L2(0,2œÄ) ‚â§‚à•F(u j)‚à•L2(0,2œÄ),
(10.39)
for all initial conditions. The Fourier transform is an isometry, thus
‚à•u j+1‚à•2,h ‚â§‚à•u j‚à•2,h
and the scheme is stable in ‚Ñì2. Conversely, if the scheme is stable in ‚Ñì2, then inequality
(10.39) holds, which implies the von Neumann condition (10.38).
‚ñ°
We now consider consistency and order issues. Recall that Œª = k
h . To simplify
the analysis, we assume from now on that Œª is constant, thus linking the time step
and the cell size. Consistency will thus be studied in the limit k ‚Üí0.
DeÔ¨Ånition 10.4 Let u be a bounded, regular solution of Eq.(10.11). The truncation
error of the scheme is the sequence Œµk(u) j, deÔ¨Åned by
Œµk(u) j
n = 1
k

u(xn, t j+1) ‚àíH(u(xn‚àí1, t j), u(xn, t j), u(xn+1, t j))

,
for all n ‚ààZ.
DeÔ¨Ånition 10.5 We say that the three point scheme (10.31) is consistent in the ‚Ñì‚àû
norm, if for any regular solution u of Eq.(10.11) with uniformly bounded derivatives,
we have
sup
j‚â§T/k
‚à•Œµk(u) j‚à•‚àû,h ‚Üí0 when k ‚Üí0.
It is of order p if
sup
j‚â§T/k
‚à•Œµk(u) j‚à•‚àû,h = O(k p).
There are similar deÔ¨Ånitions for 2‚Ñì+ 1 schemes. We now give conditions on the
coefÔ¨Åcients of a linear scheme for it to be consistent. Let us introduce the Courant
number
c = Œªa = ak
h ,
which also plays a crucial role in stability, see condition (10.25) above.
Proposition 10.8 A linear scheme (10.34)‚Äì(10.35) is consistent and at least of order
one, if and only if
1

l=‚àí1
lcl = ‚àíc,

366
10
The Finite Volume Method
or equivalently
g(v, v) = av, for all v ‚ààR,
(10.40)
with g deÔ¨Åned by Eq.(10.36). If in addition we have 1
l=‚àí1 l2cl = c2, then the scheme
is at least of order two.
Proof We use Taylor expansions, assuming that u is regular enough. There exists
œÑ j, Œæn,l such that
u(xn, t j+1) = u(xn, t j) + k ‚àÇu
‚àÇt (xn, t j) + k2
2
‚àÇ2u
‚àÇt2 (xn, t j) + k3
6
‚àÇ3u
‚àÇt3 (xn, œÑ j)
and
u(xn+l, t j) = u(xn, t j) + lh ‚àÇu
‚àÇx (xn, t j) + (lh)2
2
‚àÇ2u
‚àÇx2 (xn, t j) + (lh)3
6
‚àÇ3u
‚àÇx3 (Œæn,l, t j),
for l = ¬±1. Since u is a regular solution of (10.11), we have ‚àÇu
‚àÇt + a ‚àÇu
‚àÇx = 0, but also
‚àÇ2u
‚àÇt2 = ‚àía ‚àÇ
‚àÇt
‚àÇu
‚àÇx

= ‚àía ‚àÇ
‚àÇx
‚àÇu
‚àÇt

= a2 ‚àÇ2u
‚àÇx2 .
Since 1
l=‚àí1 cl = 1, the truncation error is therefore such that
Œµk(u) j
n = ‚àí

a +
1

l=‚àí1
lcl
Œª
‚àÇu
‚àÇx (xn, t j) + k
2

a2 ‚àí
1

l=‚àí1
l2cl
Œª2
‚àÇ2u
‚àÇx2 (xn, t j) + R j
n(k),
where |R j
n(k)| ‚â§Ck2 and C does not depend on n, j and k. This gives the expected
results. Relation (10.40) then follows from Lemma 10.1.
‚ñ°
Remark 10.8 The previous result can be generalized to 2‚Ñì+ 1 point schemes. A
conservative scheme of the form (10.33) is consistent if g(v, . . . , v) = av for all
v ‚ààR, and is then at least of order one. In the nonlinear case, consistency reads
g(v, . . . , v) = f (v) for all v.
‚ñ°
We thus see that consistency or order at least one is equivalent to c‚àí1 ‚àíc1 = c
and order at least two to c‚àí1 + c1 = c2. In fact, we can describe all conservative,
consistent three point schemes as follows.
Corollary 10.3 Any conservative, consistent, three point linear scheme is of the
form
u j+1
n
= u j
n ‚àíŒªa
2 (u j
n+1 ‚àíu j
n‚àí1) + q
2 (u j
n+1 ‚àí2u j
n + u j
n‚àí1).
(10.41)

10.4 Explicit Three Point Schemes
367
for some q ‚ààR, called the viscosity coefÔ¨Åcient of the scheme. Furthermore, the
scheme is of order two if and only if q = c2 = Œª2a2. The numerical Ô¨Çux is given by
g(u, v) = a
2(u + v) ‚àíq
2Œª(v ‚àíu).
(10.42)
Proof We start from
u j+1
n
= c‚àí1u j
n‚àí1 + c0u j
n + c1u j
n+1.
with c‚àí1 + c0 + c1 = 1 and c‚àí1 ‚àíc1 = c = Œªa. Letting q = c‚àí1 + c1 = 1 ‚àíc0,
then c‚àí1 = (q + c)/2, c1 = (q ‚àíc)/2 and the scheme reads
u j+1
n
= q + c
2
u j
n‚àí1 + (1 ‚àíq)u j
n + q ‚àíc
2
u j
n+1,
(10.43)
from which (10.41) immediately follows. The scheme is of order two if moreover
q = c‚àí1 + c1 = c2. Pursuing the Taylor expansions one step further, we check
that the resulting unique scheme is not of order three. Finally, Eq.(10.42) is just a
rewriting of Eq.(10.36) in terms of the new parameters.
‚ñ°
The scheme obtained for q = c2 is the Lax‚ÄìWendroff scheme, that we have
already encountered in the context of the wave equation, see Chap.9, Sect.9.6. The
name viscosity coefÔ¨Åcient comes from the fact that the factor u j
n+1 ‚àí2u j
n + u j
n‚àí1 is
directly linked to the three point Ô¨Ånite difference approximation of ‚àÇ2u
‚àÇx2 (xn, t j). The
corresponding term in the scheme thus acts as some kind of numerical viscosity or
dissipation.
Remark 10.9 Since we have assumed Œª to be a constant, and the constants cl and thus
q only depend on Œª and a, there is no discretization parameter left in the expression
of the scheme (10.41). This can be unsettling since how then can we talk about
convergence when h, and thus k, goes to 0, since the scheme apparently depends
on neither one of the two? Two factors are at play here. First of all, we are working
on R with an inÔ¨Ånite number of discrete values. If we were working on a bounded
interval with boundary conditions, the number of discrete values would be Ô¨Ånite
and depend on h and k. It would of course go to inÔ¨Ånity when h, and thus k, goes
to 0. Secondly, the discretization parameter h is still hidden in the initial data of
the scheme. In a sense, it is the dependence of the initial data on the discretization
parameter that drives the convergence of the scheme when h goes to 0, see also the
proof of Theorem 10.1 below.
‚ñ°
Formula (10.41) is also useful for stability.
Proposition 10.9 A three point linear scheme (10.41) is stable in ‚Ñì2 if and only if
its viscosity coefÔ¨Åcient q and Courant number c satisfy
c2 ‚â§q ‚â§1.

368
10
The Finite Volume Method
Fig. 10.4 ‚Ñì2 stability
Stability in ‚Ñì‚àûis equivalent to
q ‚â•0 and c2 ‚â§q2 ‚â§1.
Proof The ampliÔ¨Åcation coefÔ¨Åcient of the scheme is given by
m(s) = 1 ‚àíc
2(eis ‚àíe‚àíis) + q
2 (eis ‚àí2 + e‚àíis) = 1 ‚àíic sin s + q(cos s ‚àí1).
The image of the mapping s ‚Üím(s) in C is an ellipse with vertices 1, 1 ‚àí2q,
1‚àíq ¬±ic. It is included in the unit disk if and only if it is included in the unit disk in
a neighborhood of 1 and that 1‚àí2q belongs to the unit disk, see Fig.10.4. The second
condition implies that 1‚àí2q ‚â•‚àí1, i.e., q ‚â§1. For the Ô¨Årst condition, we notice that
m(s) = 1‚àíq s2
2 ‚àíics+O(s3) when s ‚Üí0, so that |m(s)|2 = 1‚àíqs2+c2s2+O(s3),
hence the condition c2 ‚àíq ‚â§0.
In view of Eq.(10.43), stability in ‚Ñì‚àûis ensured if and only if
q ‚â§1 and
‚àíq ‚â§c ‚â§q,
by Proposition 10.6. The double inequality implies that q ‚â•0, it is thus is equivalent
to c2 ‚â§q2.
‚ñ°
The ‚Ñì2 stability condition is thus (Œªa)2
‚â§q ‚â§1, whereas the ‚Ñì‚àûstability
condition reads (Œªa)2 ‚â§q2 ‚â§1 with q ‚â•0. The latter is more stringent than the
former since q2 ‚â§q. In particular, it is not satisÔ¨Åed by the Lax‚ÄìWendroff scheme
unless |c| = q = 1.

10.4 Explicit Three Point Schemes
369
Inanycase,thestabilityofanexplicitschemeislinkedtoaCFLstabilitycondition,
see also Chap.9, Proposition 9.4, of the form
|a|k
h ‚â§Œº,
with Œº ‚â§1 for a three point scheme, Œº ‚â§‚Ñìfor a 2‚Ñì+1 point scheme. The scalar |a|k
is the distance covered by the transport phenomenon during one time step at speed
a: the exact solution satisÔ¨Åes u(xn, t j+1) = u(xn ‚àíak, t j). The stability condition
|c| ‚â§1 says that this distance cannot exceed the length of one cell for a three point
scheme (or two cells for a Ô¨Åve point scheme, and so on). This expresses the fact
that the discrete cone of inÔ¨Çuence must contain the backward characteristic passing
through (xn, t j+1) (see Fig.9.6 in Chap.9 in the case of the wave equation).
Let us now say a few words about convergence in this context, in ‚Ñì‚àûfor simplicity.
Convergence thus clearly means (recall that Œª = k/h is constant)
sup
n‚ààZ, j‚â§T/k
|u j
n ‚àíu(xn, t j)| ‚Üí0 when k ‚Üí0,
when u, i.e., u0, is regular enough. As can be expected, we also have a Lax theorem.
Theorem 10.1 A three point linear scheme that is stable and consistent in ‚Ñì‚àûis
convergent in ‚Ñì‚àû.
Proof Let us set v j
n = u(xn, t j) and e j
n = u j
n ‚àív j
n. By deÔ¨Ånition of the truncation
error, we have v j+1
n
= H(v j
n‚àí1, v j
n, v j
n+1) + kŒµk(u) j
n so that
e j+1
n
= H(e j
n‚àí1, e j
n, e j
n+1) ‚àíkŒµk(u) j
n,
e0
n = u0
n ‚àíu0(xn).
Now the scheme is stable, therefore

H(e j
n‚àí1, e j
n, e j
n+1)

n‚ààZ

‚àû,h ‚â§‚à•e j‚à•‚àû,h,
so that
‚à•e j‚à•‚àû,h ‚â§‚à•e0‚à•‚àû,h + k
j‚àí1

l=0
Œµk(u)l
‚àû,h ‚â§‚à•e0‚à•‚àû,h + T sup
l‚â§T/k
‚à•Œµk(u)l‚à•‚àû,h,
for all j ‚â§T/k by a repeated application of the triangle inequality. When k ‚Üí0
then h ‚Üí0, and the Ô¨Årst term in the right-hand side tends to 0 if u0 is regular
enough. The second term tends to 0 by consistency of the scheme in ‚Ñì‚àû, hence the
convergence result.
‚ñ°
Naturally, if the scheme is of order p, we have an error estimate
sup
n‚ààZ, j‚â§T/k
|u j
n ‚àíu(xn, t j)| ‚â§Ck p,

370
10
The Finite Volume Method
provided u0 is regular enough, if we use Ô¨Ånite difference initial data or an order p
approximation thereof.
Let us now give a few more examples of schemes that can be used for the transport
equation, in either the Ô¨Ånite volume or the Ô¨Ånite difference contexts.
10.5
Examples of Linear Schemes
For all these schemes, we assume that h j = h, Œª constant and u0
n = 1
h

Cn u0(x) dx
is given.
Example 10.1 The decentered scheme.
This is the upwind scheme we already studied in the general case h j depending
on j. Let us just give a few more remarks in the light of the previous developments.
First, we have a general expression that is valid whatever the sign of a. We can
write
u j+1
n
= u j
n ‚àíŒª(a‚àí(u j
n+1 ‚àíu j
n) + a+(u j
n ‚àíu j
n‚àí1)),
(10.44)
where a‚àí= min(a, 0) = a if a ‚â§0, 0 otherwise and a+ = max(a, 0) = a if a ‚â•0,
0 otherwise.3 This corresponds to the numerical Ô¨Çux
g(u, v) = a+u + a‚àív.
Formula (10.44) thus combines the two cases (10.21) and (10.22) into one. Since
a = a+ + a‚àí, |a| = a+ ‚àía‚àí, rewriting the scheme in the form (10.41), we obtain
u j+1
n
= u j
n ‚àíŒªa
2 (u j
n+1 ‚àíu j
n‚àí1) + Œª|a|
2 (u j
n+1 ‚àí2u j
n + u j
n‚àí1),
hence a viscosity coefÔ¨Åcient q = Œª|a|. We summarize the main properties of this
scheme.
Proposition 10.10 The CFL condition
Œª|a| ‚â§1,
(10.45)
is a necessary and sufÔ¨Åcient condition of stability in both ‚Ñì‚àûand ‚Ñì2. The scheme is
of order one in ‚Ñì‚àû, it is thus convergent in ‚Ñì‚àû. It also satisÔ¨Åes the discrete maximum
principle.
3Note that this is the opposite convention to the one used for negative parts, which is a‚àí=
‚àímin(a, 0).

10.5 Examples of Linear Schemes
371
Fig. 10.5 Centered scheme divergence, same data as before
Example 10.2 The centered scheme.
The centered scheme is deÔ¨Åned by
u j+1
n
= u j
n ‚àíŒªa
2 (u j
n+1 ‚àíu j
n‚àí1).
This corresponds to the numerical Ô¨Çux
g(u, v) = a
2(u + v),
i.e., the mean value of the exact Ô¨Çuxes at the interfaces, and viscosity coefÔ¨Åcient
q = 0. The scheme is thus unstable in ‚Ñì2 and ‚Ñì‚àûas soon as a Ã∏= 0. The scheme is
not used since it is not convergent, see Fig.10.5.
Example 10.3 The Lax‚ÄìFriedrichs scheme.
We have already encountered this scheme in the context of the wave equation in
Chap.9. It is given by the following formula
u j+1
n
= u j
n+1 + u j
n‚àí1
2
‚àíŒªa
2 (u j
n+1 ‚àíu j
n‚àí1).
This scheme is associated with the numerical Ô¨Çux
g(u, v) = a
2(u + v) ‚àí1
2Œª(v ‚àíu),
and viscosity coefÔ¨Åcient q = 1.
Proposition 10.11 The Lax‚ÄìFriedrichs scheme is stable both in ‚Ñì‚àûand in ‚Ñì2 if and
only if the CFL condition (10.45) is satisÔ¨Åed. It is then monotone. It is of order one
in ‚Ñì‚àû.

372
10
The Finite Volume Method
Example 10.4 The Lax‚ÄìWendroff scheme.
For completeness, we also record the Lax‚ÄìWendroff scheme, that was already
discussed earlier and in Chap.9. The scheme reads
u j+1
n
= u j
n ‚àíŒªa
2 (u j
n+1 ‚àíu j
n‚àí1) + Œª2a2
2
(u j
n+1 ‚àí2u j
n + u j
n‚àí1).
This scheme is associated with the numerical Ô¨Çux
g(u, v) = a
2(u + v) ‚àíŒªa2
2 (v ‚àíu),
and viscosity coefÔ¨Åcient q = c2.
Proposition 10.12 The Lax‚ÄìWendroff scheme is stable in ‚Ñì2 if and only if the CFL
condition (10.45) is satisÔ¨Åed. It is unstable in ‚Ñì‚àûunless c = 1. It is of order two
in ‚Ñì‚àû.
Recall that the Lax‚ÄìWendroff scheme is the only linear three point scheme of
order two.
10.6
Generalizations to Discontinuous Data and Nonlinear
Problems
The above schemes can also be applied when the initial data is discontinuous, see
Figs.10.6 and 10.7. In this case, the exact solution is still given by formula (10.12).
It is thus also discontinuous and must be understood in the distributional sense. As a
consequence, considerations of order of schemes do not apply. The question is more
how accurately do the various numerical schemes capture the jumps in the solution.
We show a computation in which aŒª is close to 1 but strictly lower, see Fig.10.6. The
same computation performed with aŒª = 1 shows a perfect Ô¨Åt of all three schemes
with the exact solution in Fig.10.7. Indeed, it is easily checked that this should be the
case as the three schemes coincide, in particular with the upwind scheme, which we
Fig. 10.6 Various schemes for a discontinuous initial data u0 = 1[‚àí1,1], aŒª < 1

10.6 Generalizations to Discontinuous Data and Nonlinear Problems
373
Fig. 10.7 Same with aŒª = 1
already know computes exact values in this case when Ô¨Ånite difference initial values
are used (which we did here for simplicity).
The latter remark could cast legitimate doubts on why bother with all the previous
developments. The reason is that all problems are not one-dimensional, scalar and
linear (anyway, there is an explicit formula for the solution in this instance). The
simple one-dimensional, scalar and linear situation is a preparation for more chal-
lenging problems. We will talk about the two-dimensional case in the next section.
We have already seen a few vector-valued problems in Chap.9. Let us say a couple
of words about the nonlinear case.
All the above schemes have nonlinear versions, the analysis of which is much
more complicated than that of their linear version, see for example [42]. To illustrate
the nonlinear case, we take the example of the Burgers equation, ‚àÇu
‚àÇt + u ‚àÇu
‚àÇx = 0 or
‚àÇu
‚àÇt + ‚àÇ
‚àÇx
 u2
2

= 0 in conservation form. We consider two initial conditions, u0(x) =

(1‚àíx2)+
2 (compactly supported in [‚àí2, 2]) and u0(x) = 1+sin(œÄx)/2 (periodic
on [‚àí2, 2]). We plot the exact solution by using the characteristics at some time T
small enough so that they have not crossed yet, and the corresponding results of the
upwind, Lax‚ÄìFriedrichs and Lax‚ÄìWendroff schemes, see Figs.10.8 and 10.9.
The Ô¨Årst two schemes assume the same form as in the linear case, with the linear
Ô¨Çux f (u) = au replaced by the nonlinear Ô¨Çux f (u) = u2
2 , namely,
u j+1
n
= u j
n ‚àíŒª

f (u j
n) ‚àíf (u j
n‚àí1)

,
Fig. 10.8 Burgers equation, with initial condition u0(x) =

(1 ‚àíx2)+
2

374
10
The Finite Volume Method
Fig. 10.9 Burgers equation, with periodic initial condition u0(x) = 1+sin(œÄx)/2, hence periodic
solution
for the upwind scheme (the initial conditions are nonnegative, hence the speeds are
nonnegative too), and
u j+1
n
= u j
n+1 + u j
n‚àí1
2
‚àíŒª
2( f (u j
n+1) ‚àíf (u j
n‚àí1)),
for the Lax‚ÄìFriedrichs scheme. The Lax‚ÄìWendroff scheme is of the form
u j+1
n
= u j
n ‚àíŒª
2

f (u j
n+1) ‚àíf (u j
n‚àí1)

+ Œª2
2

A(u j
n+1, u j
n)

f (u j
n+1) ‚àíf (u j
n)

‚àíA(u j
n, u j
n‚àí1)

f (u j
n) ‚àíf (u j
n‚àí1)

,
where A(u, v) = u+v
2
in the particular case of the Burgers equation.
We also give space‚Äìtime pictures of the corresponding characteristics before and
after they cross, see Figs.10.10 and 10.11.
Fig. 10.10 Characteristics for u0(x) =

(1 ‚àíx2)+
2
Fig. 10.11 Characteristics for u0(x) = 1 + sin(œÄx)/2

10.6 Generalizations to Discontinuous Data and Nonlinear Problems
375
Note in both cases the already mentioned fact that the crest of the wave travels
faster than the trough (which does not travel at all in the Ô¨Årst case). One of the main
issues from the theoretical side is what sense to give to a solution after the charac-
teristics have crossed, a situation which results in the formation of a shock wave,
i.e., a jump discontinuity, even if the initial condition is smooth. On the numerical
side, the question is how to reliably compute the shock wave. We leave these difÔ¨Åcult
questions aside, see for example [42].
10.7
The Transport Equation in an Open Set in Higher
Dimensions
In the sequel, Œ© denotes a bounded open set of Rd, with sufÔ¨Åciently regular boundary
Œì = ‚àÇŒ©. We here denote by ŒΩ the normal unit exterior vector. In this d-dimensional
context, the advection velocity a is a given vector Ô¨Åeld deÔ¨Åned on ¬ØQ = ¬ØŒ© √ó [0, T ]
of class C1, with values in Rd. Without loss of generality, we can assume that a is the
restriction of a vector Ô¨Åeld deÔ¨Åned on Rd √óR with bounded derivatives, still denoted
a, to ¬ØQ. We again denote by t ‚ÜíX(t; y, s) the characteristic passing through point
y ‚ààRd at time s ‚ààR, still deÔ¨Åned by (10.14).
For any t ‚ààR, we decompose Œì into three different parts
Œì ‚àí(t) = {x ‚ààŒì, a(x, t) ¬∑ ŒΩ(x) < 0},
Œì +(t) = {x ‚ààŒì, a(x, t) ¬∑ ŒΩ(x) > 0},
Œì 0(t) = {x ‚ààŒì, a(x, t) ¬∑ ŒΩ(x) = 0}.
The part Œì ‚àí(t) is called the incoming part of the boundary at time t, i.e., the part
of the boundary where the advection velocity a points inwards and characteristics
coming from outside Œ© enter Œ©. Likewise, Œì +(t) is the outgoing part where a
points outwards at time t and characteristics leave Œ©. Finally, Œì 0(t) is called the
characteristic part. The velocity and characteristics are tangential to Œì on the char-
acteristic part at time t. When the velocity a is stationary, i.e., does not depend on t,
the above parts also are independent of t and are then denoted by Œì ‚àí, Œì + and Œì 0.
For simplicity, we assume that any characteristic passing through a point y at time
s with (y, s) ‚ààŒì 0(s) does not enter Œ©, see Fig.10.12. We consider the following
general transport problem
‚éß
‚é™‚é™‚é®
‚é™‚é™‚é©
‚àÇu
‚àÇt (x, t) + a(x, t) ¬∑ ‚àáu(x, t) = f (x, t) in Œ© √ó ]0, T [,
u(x, t) = g(x, t) on ‚àÇQ‚àí
u(x, 0) = u0(x) in Œ©,
(10.46)
where f is a given source term deÔ¨Åned on Q, g a given Dirichlet boundary condition
deÔ¨Åned on the set ‚àÇQ‚àí= {(x, t), x ‚ààŒì ‚àí(t), 0 ‚â§t < T } ‚äÇŒì √ó [0, T [ and

376
10
The Finite Volume Method
Fig. 10.12 The characteristic passing through y at time s in the case œÑin(y, s) > 0 and
œÑout(y, s) < T. This particular drawing only makes sense if a does not depend on t
u0 a given initial data deÔ¨Åned on Œ©. This is an initial-boundary value problem. As
already mentioned in Chap.1 in one dimension, no Dirichlet boundary condition is
needed or can even be a priori imposed on the outgoing and characteristic parts of
the boundary.
As in the one-dimensional case, we can express the solution of problem (10.46)
by means of the characteristics, assuming all functions are regular enough. For all
(y, s) ‚àà
¬ØŒ© √ó [0, T ], we let [œÑin(y, s), œÑout(y, s)] denote the connected compo-
nent containing s of the set of times t such that X(t; y, s) ‚àà
¬ØŒ©. We remark that
X(œÑin(y, s); y, s) ‚ààŒì ‚àí(œÑin(y, s)) if œÑin(y, s) > 0, due to the hypothesis made on
characteristics leaving Œì 0.
Problem (10.46) thus has an explicit solution, assuming the characteristics are
known. This solution is obtained by integration along the characteristics. More pre-
cisely, we have the following result which generalizes formula (10.15).
Proposition 10.13 If u is a regular solution of (10.46), then
u(x, t) =
‚éß
‚é™‚é™‚é™‚é®
‚é™‚é™‚é™‚é©
u0(X(0; x, t)) +
 t
0
f (X(œÑ; x, t), œÑ) dœÑ, if œÑin(x, t) = 0,
g(X(œÑin(x, t); x, t), œÑin(x, t)) +
 t
œÑin(x,t)
f (X(œÑ; x, t), œÑ) dœÑ, if œÑin(x, t) > 0.
(10.47)
Proof Let u be a regular solution of (10.46). Let us pick (x, t) ‚ààQ. For œÑ ‚àà
]œÑin(x, t), œÑout(x, t)[, we set y(œÑ) = X(œÑ; x, t) and v(œÑ) = u(y(œÑ), œÑ), so that x =
y(t) and v(t) = u(x, t). Using the Ô¨Årst equation in (10.14) and the Ô¨Årst equation in
(10.46), we have

10.7 The Transport Equation in an Open Set in Higher Dimensions
377
v‚Ä≤(œÑ) = ‚àÇu
‚àÇt (y(œÑ), œÑ) + y‚Ä≤(œÑ) ¬∑ ‚àáu(y(œÑ), œÑ) =
‚àÇu
‚àÇt + a ¬∑ ‚àáu

(y(œÑ), œÑ) = f (y(œÑ), œÑ).
There are now two cases, depending on œÑin(x, t). If œÑin(x, t) = 0, we can integrate
the equation between 0 and t. We obtain
u(x, t) = v(t) = v(0) +
 t
0
f (y(œÑ), œÑ) dœÑ
= u(y(0), 0) +
 t
0
f (y(œÑ), œÑ) dœÑ = u0(y(0)) +
 t
0
f (y(œÑ), œÑ) dœÑ,
using the initial condition. Given the deÔ¨Ånition of y(œÑ), this is the Ô¨Årst expression in
(10.47).
Let us now consider the second case œÑin(x, t) > 0. In this case, we integrate
between œÑin(x, t) and t and obtain
u(x, t) = v(t) = v(œÑin(x, t)) +
 t
œÑin(x,t)
f (y(œÑ), œÑ) dœÑ
= u(y(œÑin(x, t)), œÑin(x, t)) +
 t
œÑin(x,t)
f (y(œÑ), œÑ) dœÑ
= g(y(œÑin(x, t)), œÑin(x, t)) +
 t
œÑin(x,t)
f (y(œÑ), œÑ) dœÑ,
on account of the incoming boundary condition (second equation in (10.46)). We
thus obtain the second expression in (10.47).
‚ñ°
Remark 10.10 Conversely, if the function u given by formulas (10.47) is sufÔ¨Åciently
regular, it is a solution of the transport equation. Indeed, the transport equation is
clearly satisÔ¨Åed along the characteristics issuing from Œì ‚àí, which cover all of Q by
the Cauchy‚ÄìLipschitz theorem, and the initial and boundary conditions are clearly
satisÔ¨Åed. Whether or not u is regular is a question of compatibility between the
functions u0 and g.
‚ñ°
10.8
Finite Volumes for the Transport Equation
in Two Dimensions
For simplicity, we suppose that f = 0 and that a does not depend on x and t, so
that Œì ‚àí, Œì + and Œì 0 are time independent. We also suppose that Œ© is polygonal.
We Ô¨Årst cover ¬ØŒ© by N cells Cn, which are closed polygons such that ¬ØŒ© = ‚à™N
n=1Cn
whose pairwise intersections are of zero measure. Note that these cells do not need
to be triangles or rectangles, as in the case of the Ô¨Ånite element method. They also
do not need to be all of the same type: we can have triangles, quadrilaterals, and so
on, in the same mesh. For simplicity, we suppose that the mesh is admissible in the

378
10
The Finite Volume Method
Fig. 10.13 An admissible Ô¨Ånite volume mesh of Œ©
Ô¨Ånite element sense, i.e., the intersection between two cells is either empty, reduced
to one vertex, or an entire edge, see Fig.10.13.
We denote by ŒΩn the normal unit exterior vector to Cn and by An the area of Cn,
so that the area of Œ© is N
n=1 An. If two cells Cn and Cm have a common edge, this
interface is denoted by Œ£nm = Œ£mn, and ŒΩnm denotes the restriction of ŒΩn to Œ£nm (it
thus points into Cm). The length of the interface is lnm = lmn. By construction, we
have ŒΩnm + ŒΩmn = 0. The boundary of Cn is the union of segments
‚àÇCn =
M(n)

m=1
Œ£nm
M‚àí(n)

p=1
Œì ‚àí
np
M+(n)

q=1
Œì +
nq
M0(n)

r=1
Œì 0
nr,
where M(n) denotes the number of internal edges Œ£nm of Cn (i.e., the edges which
are inside Œ©), while M‚àí(n) (resp. M+(n), M0(n)) denotes the number of edges of
Cn which are on Œì ‚àí(resp. on Œì +, Œì 0).4 The sets
M‚àí(n)

p=1
Œì ‚àí
np = ‚àÇCn ‚à©Œì ‚àí,
M+(n)

q=1
Œì +
nq = ‚àÇCn ‚à©Œì +,
M0(n)

r=1
Œì 0
nr = ‚àÇCn ‚à©Œì 0
4If one of these integers is 0, the corresponding union is empty.

10.8 Finite Volumes for the Transport Equation in Two Dimensions
379
represent all the boundary edges of Cn depending on whether they are on Œì ‚àí, Œì +
or Œì 0. We denote by l‚àí
np (resp. l+
nq, l0
nr) the length of Œì ‚àí
np (resp. Œì +
nq, Œì 0
nr). We also
denote by ŒΩ‚àí
np (resp. ŒΩ+
nq, ŒΩ0
nr) the restriction of ŒΩn to Œì ‚àí
np (resp. Œì +
nq, Œì 0
nr).
As in the 1d-case, we Ô¨Årst integrate the transport equation on Cn at time t and
obtain
d
dt

Cn
u(x, t) dx

+

Cn
(a ¬∑ ‚àáu)(x, t) dx = 0.
(10.48)
We introduce the mean value ¬Øun(t) of u(., t) on the cell Cn, i.e.,
¬Øun(t) = 1
An

Cn
u(x, t) dx.
The Ô¨Årst term in (10.48) thus becomes
d
dt

Cn
u(x, t)dx

= An
d ¬Øun
dt (t).
We can use the Stokes formula (3.6) of Chap.3 with U(x, t) = u(x, t)a since a is
constant. The second term in (10.48) then reads

Cn
(a ¬∑ ‚àáu)(x, t)dx = a ¬∑

‚àÇCn
u(x, t)ŒΩn(x) dŒì

.
Since each Œ£nm, Œì ‚àí
np, Œì +
nq and Œì 0
nr is a segment, we have, taking into account the
incoming boundary condition

Cn
(a ¬∑ ‚àáu)(x, t) dx =
M(n)

m=1
(a ¬∑ ŒΩnm)

Œ£nm
u(x, t) dŒì
+
M‚àí(n)

p=1
(a ¬∑ ŒΩ‚àí
np)

Œì ‚àí
np
g(x, t) dŒì +
M+(n)

q=1
(a ¬∑ ŒΩ+
nq)

Œì +
nq
u(x, t) dŒì,
with the convention that, if M‚àí(n) = 0 or M+(n) = 0, the corresponding sums are
equal to 0. Integrating Eq.(10.48) between t j and t j+1, we have for all n = 1, . . . , N
An[¬Øun(t j+1) ‚àí¬Øun(t j)] +
M(n)

m=1
(a ¬∑ ŒΩnm)
 t j+1
t j

Œ£nm
u(x, t) dŒì dt
+ k
M‚àí(n)

p=1
(a ¬∑ ŒΩ‚àí
np)l‚àí
np g j
np +
M+(n)

q=1
(a ¬∑ ŒΩ+
nq)
 t j+1
t j

Œì +
nq
u(x, t) dŒì dt = 0,
(10.49)

380
10
The Finite Volume Method
where we have set
g j
np =
1
k l‚àí
np
 t j+1
t j

Œì ‚àí
np
g(x, t) dŒì dt.
These relations are exactly satisÔ¨Åed, there is no approximation so far.
First, we approximate each integral with respect to time as
 t j+1
t j
œÜ(t)dt ‚âàkœÜ(t j),
which corresponds to the explicit Euler scheme in time. We next have to approximate
the Ô¨Çuxes on Œ£nm and Œì +
nq at time t j in terms of discrete unknowns u j
n, where u j
n
is meant to be an approximation of ¬Øun(t j). Let us explain how to proceed for the
computation on Œ£nm. We still use the fact that the information is transported by
the characteristic lines. If a ¬∑ ŒΩnm = 0, the corresponding term in (10.49) vanishes,
hence there are two cases left depending on the sign of a ¬∑ ŒΩnm (see Fig.10.14). More
precisely, we consider the following upwind approximation:

Œ£nm
u(x, t j) dŒì ‚âà

lnmu j
n,
if a ¬∑ ŒΩnm > 0,
lnmu j
m, if a ¬∑ ŒΩnm < 0.
Using the same idea for the Ô¨Çux on Œì +
nq, we obtain

Œì +
nq
u(x, t j) dŒì ‚âàl+
nqu j
n.
Note that there is only one possible choice for the numerical Ô¨Çux in this case, and
this choice is consistent with the upwind philosophy, since we are on the outgoing
part of the boundary.
Putting all the above approximations together, we obtain the explicit Ô¨Ånite volume
scheme
An
u j+1
n
‚àíu j
n
k
+

1‚â§m‚â§M(n)
a¬∑ŒΩnm>0
(a ¬∑ ŒΩnm)lnm u j
n +

1‚â§m‚â§M(n)
a¬∑ŒΩnm<0
(a ¬∑ ŒΩnm)lnm u j
m
+
M‚àí(n)

p=1
(a ¬∑ ŒΩ‚àí
np)l‚àí
np g j
np +
M+(n)

q=1
(a ¬∑ ŒΩ+
nq)l+
nq u j
n = 0.
(10.50)
We complement the scheme with the initial condition
u0
n = 1
An

Cn
u0(x) dx,
(10.51)

10.8 Finite Volumes for the Transport Equation in Two Dimensions
381
Fig. 10.14 The two cases depending on the sign of a ¬∑ ŒΩnm
or an approximation thereof. Once a numbering of the cells is chosen, we can intro-
duce the sequence of vectors U j ‚ààRN with components u j
n, and the scheme (10.50)‚Äì
(10.51) takes the usual form U j+1 = AU j + G j, U 0 given, where A is an N √ó N
sparse matrix and G j is a given vector in RN corresponding to the Dirichlet condition
on the incoming part of the boundary.

382
10
The Finite Volume Method
We have the following important property:
Proposition 10.14 The scheme is conservative, i.e., the variation of the total mass
is due to what Ô¨Çows in and out at the boundary of Œ©
N

n=1
An
u j+1
n
‚àíu j
n
k
+
N

n=1
M‚àí(n)

p=1
(a ¬∑ ŒΩ‚àí
np)l‚àí
np g j
np +
N

n=1
M+(n)

q=1
(a ¬∑ ŒΩ+
nq)l+
nq u j
n = 0.
Proof The proof is straightforward. We have in fact
N

n=1

m‚àà{1,...,M(n)}
a¬∑ŒΩnm>0
(a ¬∑ ŒΩnm)lnm u j
n +
N

n=1

m‚àà{1,...,M(n)}
a¬∑ŒΩnm<0
(a ¬∑ ŒΩnm)lnm u j
m = 0.
Indeed, due to the assumption that the Ô¨Ånite volume mesh is admissible, to each
term in the Ô¨Årst sum corresponding to an edge Œ£nm of Cn, there corresponds one
and only one term in the second sum corresponding to the edge Œ£mn of Cm that
is shared with Cn, with lmn = lnm, ŒΩmn = ‚àíŒΩnm and the same value u j
n due to the
upwind approximation. The above pairing clearly exhausts all the terms of the second
sum.
‚ñ°
We do not pursue here the numerical analysis of the above Ô¨Ånite volume scheme
and refer to [30, 36, 56] for a much more comprehensive mathematical analysis of
the Ô¨Ånite volume method. This requires more advanced mathematical techniques, in
particular the use of spaces of functions with bounded variation, which are functions
whose distributional derivatives are not functions but measures, to accommodate
piecewise constant functions.

References
1. R.A. Adams, Sobolev Spaces, vol. 65, Pure and Applied Mathematics (Academic Press, New
York, 1975). A subsidiary of Harcourt Brace Jovanovich, Publishers
2. R.A. Adams, J.J.F. Fournier, Sobolev Spaces, vol. 140, 2nd edn., Pure and Applied Mathematics
(Amsterdam) (Elsevier/Academic Press, Amsterdam, 2003)
3. S. Agmon, A. Douglis, L. Nirenberg, Estimates near the boundary for solutions of elliptic
partial differential equations satisfying general boundary conditions. I. Commun. Pure Appl.
Math. 12, 623‚Äì727 (1959)
4. S. Agmon, A. Douglis, L. Nirenberg, Estimates near the boundary for solutions of elliptic
partial differential equations satisfying general boundary conditions. II. Commun. Pure Appl.
Math. 17, 35‚Äì92 (1964)
5. G. Allaire, Numerical Analysis and Optimization. An Introduction to Mathematical Modelling
and Numerical Simulation, Numerical Mathematics and ScientiÔ¨Åc Computation (Oxford Uni-
versity Press, Oxford, 2007)
6. G. Allaire, S.M. Kaber, Numerical Linear Algebra, vol. 55, Texts in Applied Mathematics
(Springer, New York, 2008)
7. K.E. Atkinson, W. Han, Theoretical Numerical Analysis. A Functional Analysis Framework,
vol. 39, 3rd edn., Texts in Applied Mathematics (Springer, Dordrecht, 2009)
8. K.E. Atkinson, W. Han, D. Stewart, Numerical Solution of Ordinary Differential Equations,
Pure and Applied Mathematics (Wiley, New York, 2009)
9. J.-P. Aubin, Applied Functional Analysis, 2nd edn. Pure and Applied Mathematics (New York)
(Wiley-Interscience, New York, 2000)
10. C. Bernardi, Y. Maday, Spectral methods, in Handbook of Numerical Analysis, vol. V, ed. by
P.G. Ciarlet, J.-L. Lions (North-Holland, Amsterdam, 1997), pp. 209‚Äì485
11. C. Bernardi, Y. Maday, F. Rapetti, Discr√©tisations variationnelles de probl√®mes aux limites
elliptiques, vol. 45, Math√©matiques & Applications (Berlin) [Mathematics & Applications]
(Springer, Berlin, 2004)
12. E. Bohl, Finite Modelle gew√∂hnlicher Randwertaufgaben, vol. 51, Leitf√§den der Angewandten
Mathematik und Mechanik [Guides to Applied Mathematics and Mechanics] (B. G. Teubner,
Stuttgart, 1981). Teubner Studienb√ºcher: Mathematik. [Teubner Study Books: Mathematics]
13. N. Bourbaki, Topological Vector Spaces. Chapters 1‚Äì5, Elements of Mathematics (Berlin)
(Springer, Berlin, 1987). Translated from the French by H.G. Eggleston, S. Madan
14. S.C. Brenner, L.R. Scott, The Mathematical Theory of Finite Element Methods, vol. 15, 3rd
edn., Texts in Applied Mathematics (Springer, New York, 2008)
15. H. Brezis, Functional Analysis, Sobolev Spaces and Partial Differential Equations, Universitext
(Springer, New York, 2011)
16. J.C. Butcher, Numerical Methods for Ordinary Differential Equations, 2nd edn. (Wiley, New
York, 2008)
¬© Springer International Publishing Switzerland 2016
H. Le Dret and B. Lucquin, Partial Differential Equations:
Modeling, Analysis and Numerical Approximation, International Series
of Numerical Mathematics 168, DOI 10.1007/978-3-319-27067-8
383

384
References
17. C. Canuto, M.Y. Hussaini, A. Quarteroni, T.A. Zang, Spectral Methods. Fundamentals in Single
Domains, ScientiÔ¨Åc Computation (Springer, Berlin, 2006)
18. P.G. Ciarlet, Introduction to Numerical Linear Algebra and Optimisation, Cambridge Texts in
Applied Mathematics (Cambridge University Press, Cambridge, 1989)
19. P.G. Ciarlet, The Finite Element Method for Elliptic Problems, Classics in Applied Mathematics
(Society for Industrial and Applied Mathematics (SIAM), Philadelphia, 2002). Reprint of the
1978 original [North-Holland, Amsterdam; MR0520174 (58 #25001)]
20. P.G. Ciarlet, Linear and Nonlinear Functional Analysis With Applications (Society for Indus-
trial and Applied Mathematics, Philadelphia, 2013)
21. P.G. Ciarlet, J.-L. Lions (eds.), Handbook of Numerical Analysis. Finite Element Methods. Part
1, vol. II (North-Holland, Amsterdam, 1991)
22. R. Courant, D. Hilbert, Methods of Mathematical Physics. Partial Differential Equations, vol.
II, Wiley Classics Library (Wiley, New York, 1989). Reprint of the 1962 original, A Wiley-
Interscience Publication
23. M. Crouzeix, A.L. Mignot, Analyse num√©rique des √©quations diff√©rentielles, Collection Math-
√©matiques Appliqu√©es pour la Ma√Ætrise. [Collection of Applied Mathematics for the Master‚Äôs
Degree] (Masson, Paris, 1984)
24. R. Dautray, J.-L. Lions, Mathematical Analysis and Numerical Methods for Science and Tech-
nology. Physical Origins and Classical Methods, vol. 1 (Springer, Berlin, 1990). With the
collaboration of P. B√©nilan, M. Cessenat, A. Gervat, A. Kavenoky, H. Lanchon
25. R. Dautray, J.-L. Lions, Mathematical Analysis and Numerical Methods for Science and Tech-
nology. Functional and variational methods, vol. 2 (Springer, Berlin, 1988). With the collab-
oration of M. Artola, M. Authier, P. B√©nilan, M. Cessenat, J.-M. Combes, H. Lanchon, B.
Mercier, C. Wild, C. Zuily
26. R. Dautray, J.-L. Lions, Mathematical Analysis, Numerical Methods, for Science and Technol-
ogy. Spectral Theory and Applications, vol. 3 (Springer, Berlin, 1990). With the collaboration
of Michel Artola and Michel Cessenat (Translated from the French by J.C. Amson)
27. R. Dautray, J.-L. Lions, Mathematical Analysis and Numerical Methods for Science and Tech-
nology. Integral Equations and Numerical Methods, vol. 4 (Springer, Berlin, 1990). With the
collaboration of M. Artola, P. B√©nilan, M. Bernadou, M. Cessenat, J.-C. N√©d√©lec, J. Planchard,
B. Scheurer
28. R. Dautray, J.-L. Lions, Mathematical Analysis and Numerical Methods for Science and
Technology. Evolution Problems. I, vol. 5 (Springer, Berlin, 1992). With the collaboration of
M. Artola, M. Cessenat, H. Lanchon
29. R. Dautray, J.-L. Lions, Mathematical Analysis and Numerical Methods for Science and Tech-
nology. Evolution Problems. II, vol. 6 (Springer, Berlin, 1993). With the collaboration of
C. Bardos, M. Cessenat, A. Kavenoky, P. Lascaux, B. Mercier, O. Pironneau, B. Scheurer,
R. Sentis
30. B. Despr√©s, Lois de conservations eul√©riennes, lagrangiennes et m√©thodes num√©riques, vol.
68, Math√©matiques & Applications (Berlin) [Mathematics & Applications] (Springer, Berlin,
2010)
31. D.A. Di Pietro, A. Ern, Mathematical Aspects of Discontinuous Galerkin Methods, vol. 69,
Math√©matiques & Applications (Berlin) [Mathematics & Applications] (Springer, Heidelberg,
2012)
32. J. Dieudonn√©, Foundations of Modern Analysis, vol. 10-I, Pure and Applied Mathematics
(Academic Press, New York, 1969). Enlarged and corrected printing
33. N. Dunford, J .T. Schwartz, Linear Operators. Part I. General Theory, Wiley Classics Library
(Wiley, New York, 1988). With the assistance of W. G. Bade, R. G. Bartle. Reprint of the 1958
original, A Wiley-Interscience Publication
34. G. Duvaut, J.-L. Lions, Inequalities in Mechanics and Physics, vol. 219, Grundlehren der
Mathematischen Wissenschaften (Springer, Berlin, 1976)
35. L.C. Evans, Partial Differential Equations, vol. 19, 2nd edn., Graduate Studies in Mathematics
(American Mathematical Society, Providence, 2010)

References
385
36. R. Eymard, R. Herbin, T. Gallou√´t, Finite volume methods, in Handbook of Numerical Analysis.
Solution of Equations in Rn. Part 3. Techniques of ScientiÔ¨Åc Computing, vol. VII, ed. by P.G.
Ciarlet, J.-L. Lions (North-Holland, Amsterdam, 2000), pp. 713‚Äì1020
37. H. Federer, Geometric Measure Theory, vol. 153, Die Grundlehren der mathematischen Wis-
senschaften, Band (Springer, New York, 1969)
38. J.-B.J. Fourier, Th√©orie analytique de la chaleur, Cambridge Library Collection (Cambridge
University Press, Cambridge, 2009). Reprint of the 1822 original, Previously published by
√âditions Jacques Gabay, Paris, 1988 [MR1414430]
39. P.-L. George, Automatic mesh generation and Ô¨Ånite element computation, in Handbook of
Numerical Analysis, ed. by P.G. Ciarlet, J.-L. Lions (North-Holland, Amsterdam, 1996), pp.
69‚Äì190
40. D. Gilbarg, N.S. Trudinger, Elliptic Partial Differential Equations of Second Order, Classics
in Mathematics (Springer, Berlin, 2001). Reprint of the 1998 edition
41. V. Girault, P.-A. Raviart., Finite Element Methods for Navier-Stokes Equations. Theory and
Algorithms, vol. 5, Springer Series in Computational Mathematics (Springer, Berlin, 1986)
42. E. Godlewski, P.-A. Raviart, Numerical Approximation of Hyperbolic Systems of Conservation
Laws, vol. 118, Applied Mathematical Sciences (Springer, New York, 1996)
43. D. Gottlieb, S.A. Orszag, Numerical Analysis of Spectral Methods: Theory and Applications,
CBMS-NSF Regional Conference Series in Applied Mathematics (Society for Industrial and
Applied Mathematics, Philadelphia, 1977)
44. P. Grisvard, Elliptic Problems in Nonsmooth Domains, vol. 24, Monographs and Studies in
Mathematics (Pitman (Advanced Publishing Program), Boston, 1985)
45. C.Grossmann,H.-G.Roos,NumericalTreatmentofPartialDifferentialEquations,Universitext
(Springer, Berlin, 2007). Translated and revised from the 3rd (2005) German edition by Martin
Stynes
46. W. Hackbusch, Elliptic Differential Equations. Theory and Numerical Treatment, vol. 18,
Springer Series in Computational Mathematics (Springer, Berlin, 2010). Translated from the
1986 corrected German edition by R. Fadiman, P.D.F. Ion
47. W. Hackbusch, The Concept of Stability in Numerical Mathematics, vol. 45, Springer Series
in Computational Mathematics (Springer, Heidelberg, 2014)
48. E. Hairer, S.P. N√∏rsett, G. Wanner, Solving Ordinary Differential Equations. I. Nonstiff Prob-
lems, vol. 8, 2nd edn., Springer Series in Computational Mathematics (Springer, Berlin, 1993)
49. E. Hairer, G. Wanner, Solving Ordinary Differential Equations. II. Stiff and Differential-
Algebraic Problems, vol. 14, 2nd edn., Springer Series in Computational Mathematics
(Springer, Berlin, 1996)
50. J.S. Hesthaven, S. Gottlieb, D. Gottlieb, Spectral Methods for Time-Dependent Problems,
vol. 21, Cambridge Monographs on Applied and Computational Mathematics (Cambridge
University Press, Cambridge, 2007)
51. F. Hirsch, G. Lacombe, Elements of Functional Analysis, vol. 192, Graduate Texts in Mathe-
matics (Springer, New York, 1999)
52. C. Johnson, Numerical Solution of Partial Differential Equations by the Finite Element Method
(Dover Publications Inc., Mineola, 2009). Reprint of the 1987 edition
53. R. Kress, Numerical Analysis, vol. 181, Graduate Texts in Mathematics (Springer, New York,
1998)
54. P. Lancaster, M. Tismenetsky, The Theory of Matrices, 2nd edn., Computer Science and Applied
Mathematics (Academic Press Inc, Orlando, 1985)
55. P.D. Lax, A.N. Milgram, Parabolic Equations, Contributions to the Theory of Partial Differen-
tial Equations, vol. 33, Annals of Mathematics Studies (Princeton University Press, Princeton,
1954), pp. 167‚Äì190
56. R.J. LeVeque, Finite Volume Methods for Hyperbolic Problems, Cambridge Texts in Applied
Mathematics (Cambridge University Press, Cambridge, 2002)
57. J.-L. Lions, Quelques m√©thodes de r√©solution des probl√®mes aux limites non lin√©aires (Dunod,
Paris, 1969)

386
References
58. J.-L. Lions, E. Magenes, Non-homogeneous Boundary Value Problems and Applications, vol.
181, Die Grundlehren der mathematischen Wissenschaften (Springer, New York, 1972)
59. B. Lucquin, O. Pironneau, Introduction to ScientiÔ¨Åc Computing (Wiley, New York, 1998)
60. R. Mattheij, J. Molenaar, Ordinary Differential Equations in Theory and Practice, vol. 43,
Classics in Applied Mathematics (Society for Industrial and Applied Mathematics (SIAM),
Philadelphia, 2002). Reprint of the 1996 original
61. J. NeÀácas, Les m√©thodes directes en th√©orie des √©quations elliptiques (Masson et Cie, √âditeurs,
Paris, 1967)
62. O. Pironneau, Finite Element Methods for Fluids (Wiley, New York, 1989)
63. A. Quarteroni, Numerical Models for Differential Problems, vol. 2, MS&A. Modeling, Simu-
lation and Applications (Springer, Milan, 2009)
64. A. Quarteroni, R. Sacco, F. Saleri, Numerical Mathematics, vol. 37, 2nd edn., Texts in Applied
Mathematics (Springer, Berlin, 2007)
65. A. Quarteroni, A. Valli, Numerical Approximation of Partial Differential Equations, vol. 23,
Springer Series in Computational Mathematics (Springer, Berlin, 1994)
66. P.-A. Raviart, J.-M. Thomas, Introduction √† l‚Äôanalyse num√©rique des √©quations aux d√©riv√©es
partielles, Collection Math√©matiques Appliqu√©es pour la Ma√Ætrise. [Collection of Applied
Mathematics for the Master‚Äôs Degree] (Masson, Paris, 1983)
67. R.D. Richtmyer, K.W. Morton, Difference Methods for Initial-value Problems, vol. 4, 2nd edn.,
Interscience Tracts in Pure and Applied Mathematics (Wiley, New York, 1967)
68. W. Rudin, Real and Complex Analysis, 3rd edn. (McGraw-Hill Book Co., New York, 1987)
69. W. Rudin, Functional Analysis, 2nd edn., International Series in Pure and Applied Mathematics
(McGraw-Hill Inc., New York, 1991)
70. A. Samarski, V. Andr√©ev, M√©thodes aux diff√©rences pour √©quations elliptiques, Traduit du russe
par Djilali Embarek (√âditions Mir, Moscow, 1978)
71. M. Schatzman, Numerical Analysis: A Mathematical Introduction (Oxford University Press,
Oxford, 2002). Translated from the French by J. Taylor
72. L. Schwartz, Th√©orie des distributions. Tome I, Actualit√©s Sci. Ind., no. 1091 = Publ. Inst.
Math. Univ. Strasbourg 9 (Hermann & Cie, Paris, 1950)
73. L. Schwartz, Th√©orie des distributions. Tome II, Actualit√©s Sci. Ind., no. 1122 = Publ. Inst.
Math. Univ. Strasbourg 10 (Hermann & Cie., Paris, 1951)
74. L. Schwartz, Mathematics for the Physical Sciences (Hermann, Paris, 1966)
75. J.C. Strikwerda, Finite Difference Schemes and Partial Differential Equations, 2nd edn. (Soci-
ety for Industrial and Applied Mathematics (SIAM), Philadelphia, 2004)
76. V. Thom√©e, Finite difference methods for linear parabolic equations, in Handbook of Numerical
Analysis, I, ed. by P.G. Ciarlet, J.-L. Lions (North-Holland, Amsterdam, 1990), pp. 5‚Äì196
77. V. Thom√©e, Galerkin Finite Element Methods for Parabolic Problems, vol. 25, 2nd edn.,
Springer Series in Computational Mathematics (Springer, Berlin, 2006)
78. F. Tr√®ves, Basic Linear Partial Differential Equations (Dover Publications Inc, Mineola, 2006).
Reprint of the 1975 original
79. G. Windisch, M-Matrices In Numerical Analysis, vol. 115, Teubner-Texte zur Mathematik
[Teubner Texts in Mathematics] (BSB B. G. Teubner Verlagsgesellschaft, Leipzig, 1989). With
German, French and Russian summaries
80. K. Yosida, Functional Analysis, Classics in Mathematics (Springer, Berlin, 1995). Reprint of
the sixth (1980) edition
81. E. Zeidler, Nonlinear Functional Analysis and its Applications. II/A. Linear Monotone Oper-
ators (Springer, New York, 1990)
82. O.C. Zienkiewicz, R.L. Taylor, The Finite Element Method, vol. 1, 5th edn. (Butterworth-
Heinemann, Oxford, 2000)

Index
A
Abstract variational approximation meth-
ods, 145, 302
Abstract variational problem, 122, 123
Adjoint variational problem, 157
AmpliÔ¨Åcation coefÔ¨Åcient, 291, 295, 364, 368
AmpliÔ¨Åcation matrix, 270, 280, 321, 328,
336, 342, 343
Approximation method for ODEs
backward Euler, 6, 304
forward Euler, 6, 9, 255, 304, 380
Runge-Kutta, 6, 9, 304
A priori error estimate, 147, 151, 179
Aubin-Nitsche duality trick, 157
B
Backward differential quotient, 254
Backward Euler three point scheme, see
implicit Euler three point scheme
Backward heat equation, 32, 225
Banach‚Äôs theorem, 125
Barycentric coordinates, 198, 199, 206
equation of a straight line in, 201
invariance under afÔ¨Åne transformation
of, 202
of points of interest, 201
triangle in, 200
Basis functions
of 1d P1 Lagrange interpolation, 154,
186
of 1d P3 Hermite interpolation, 164
of 2d Q1 Lagrange interpolation, 176,
177, 183, 186
of 2d Q2 Lagrange interpolation, 195
Basis polynomials
of 1d P1 Lagrange interpolation, 185
of 2d P1 Lagrange interpolation, 205
of 2d P2 Lagrange interpolation, 211
of 2d P3 Lagrange interpolation, 213
of 2d Q1 Lagrange interpolation, 179,
185
of 2d Q2 Lagrange interpolation, 193
of a general Ô¨Ånite element, 191
Bilaplacian, 18, 140
Bisection method, 9
Black and Scholes equation, 31
Boundary
characteristic part, 375
incoming part, 375, 381
outgoing part, 375, 380
Boundary condition, 5
Dirichlet, 6, 21, 107, 110, 121, 219, 345,
375, 381
Fourier, 133, 134, 143, 165
homogeneous Dirichlet, 6, 12, 16, 25,
117, 174, 235, 237, 308, 311, 345
homogeneous Neumann, 120
incoming, 377, 379
mixed, 121, 129
Neumann, 48, 120, 128, 129, 143, 165
periodic, 21
Robin, see Fourier boundary condition
third, see Fourier boundary condition
Boundary measure, 80
¬© Springer International Publishing Switzerland 2016
H. Le Dret and B. Lucquin, Partial Differential Equations:
Modeling, Analysis and Numerical Approximation, International Series
of Numerical Mathematics 168, DOI 10.1007/978-3-319-27067-8
387

388
Index
Boundary value problem, 5, 117
Bubble, 213
Burgers equation, 353, 373
C
Ck([0, T ]; V ) spaces, 230
Ck() spaces, 72
Ck( ¬Ø) spaces, 73
Ck,Œ≤( ¬Ø) spaces, 74
Cm,n( ¬ØQ) spaces, 257
Call option, 31
Cauchy‚ÄìLipschitz theorem, 353, 377
Cauchy problem, 6, 8, 240, 314, 351
Cauchy‚ÄìSchwarz inequality, 69, 72, 75, 101,
105‚Äì107, 113, 127, 129, 235, 239,
241, 244, 299, 300, 315, 350
C√©a‚Äôs lemma, 146, 147, 151, 162, 177
Center of gravity, 192, 193, 212
Central approximation, 254
Central differential quotient, 259
Characteristics, 20, 21, 352‚Äì354, 373, 375,
376, 380
backward, 369
method of, 20, 353
Compact mapping, 74
Compactness-contradiction argument, 132,
135
Condition number of a matrix, 55, 333, 334,
340, 343
Cone of inÔ¨Çuence
continuous, 319
discrete, 322, 369
Conforming approximation, 145, 154
Conservation law, 18
Consistency
of a Ô¨Ånite difference scheme for the wave
equation, 321
of a Ô¨Ånite volume scheme, 356, 365, 366
of a general scheme for a family of
norms, 263
of the Crank-Nicolson scheme, 297
of the explicit Euler scheme, 257
of the implicit Euler scheme, 259
of the leapfrog method, 260
of the Œ∏-scheme, 296
Consistent approximation, 36, 37, 347
Continuity of the differentiation in the sense
of D‚Ä≤, 96
Control volume, see Ô¨Ånite volume cell
Convection‚Äìdiffusion problem, 22, 139
Convergence
Ô¨Ånite difference method, 41, 266, 278
Ô¨Ånite volume scheme, 349, 357, 359
in the sense of D(), 91
in the sense of D‚Ä≤(), 94
of a general scheme for a family of
norms, 264
of the Q1 FEM, 179
of the Crank-Nicolson scheme for the
2, h norms, 300
of the explicit Euler scheme for the 2, h
norms, 278
of the explicit Euler scheme for the ‚àû, h
norms, 266
of the Ô¨Ånite difference method, 43
of the implicit Euler scheme for the 2, h
norms, 279
Convolution, 82, 91, 110, 115
Courant‚ÄìFriedrichs‚ÄìLewy (CFL) condition,
322, 357, 360, 369‚Äì372
violation of, 325
Courant number, 365, 367
Crank-Nicolson scheme, 297
consistency, 297
order, 297
unconditional convergence, 300
unconditional stability, 299
D
D() spaces, 73, 91
D‚Ä≤() spaces, 91
Dahlquist‚Äôs zero-stability condition, 272,
304
D‚ÄôAlembert, Jean le Rond, 23
D‚ÄôAlembert‚Äôs formula, 317
Degree of a polynomial
partial, 173
total, 173
Degrees of freedom, 304
1d P1 Lagrange, 156, 165
1d P3 Hermite, 161
2d P1 Lagrange triangle, 204
2d P2 Lagrange triangle, 209
2d P3 Lagrange triangle, 212
2d Q1 Lagrange rectangle, 177
2d Q2 Lagrange rectangle, 192
2d Q3 Hermite rectangle, 198
2d Q3 Lagrange rectangle, 197
general element, 189
Difference quotient, 253
Differential quotient, 35, 36
for the second derivative, 37
Diffusion equation, 17
Dirac mass, 93, 247

Index
389
Dirichlet‚Äôs theorem, 223
Discrete Fourier coefÔ¨Åcients, 285
Discrete Fourier transform, 282
Discrete maximum principle, 45, 62, 269,
370
Discrete Poincar√© inequality, 299, 300
Dispersivity, 344
Dissipativity, 344
Distributional derivative, 149
Distributional partial derivatives, 94, 119,
171, 247
Distributional primitive, 96
Distributions, 90
convergence in the sense of, 94
multiplication by a smooth function, 96
partial derivative, 94
Duhamel‚Äôs formula, 240
E
Eigenvalue problem, 26, 243
Eigenvalues, 274, 279, 281, 313, 325, 329,
334, 336, 340, 343
of a tridiagonal matrix, 276
Elastic beam, 10
Elastic membrane equation, 12, 16
Elastic string, 1
Element, 149
generic, 180, 206
reference, 179, 180, 184, 206
Elementary solution, see fundamental solu-
tion
Elliptic equation, 33
Elliptic regularity theory, 120, 142, 143, 154,
183
Energy
conservation (wave eqn.) versus dissipa-
tion (heat eqn.), 309
heat equation, 236
wave equation, 308
Energy estimate
heat equation, 236
wave equation, 310
Energy functional, 128
Equation
Black and Scholes, 31
Burgers, 353, 373
diffusion, 17
elastic membrane, 16
elliptic, 33
heat, 27, 33, 133, 219
hyperbolic, 33, 309
Laplace, 17
Maxwell, 27
parabolic, 33
plate, 17
Poisson, 17, 30, 33, 117
Schr√∂dinger, 30
string, 5
transport, 18, 34, 351, 375
vibrating string, 22
wave, 23, 26, 33, 307
Explicit Euler three point scheme, 254
consistency, 257
convergence for the 2, h norms, 278
convergence for the ‚àû, h norms, 266
divergence when stability is not satisÔ¨Åed,
267
error estimate, 269, 278
stability for the 2, h norms, 278
stability for the ‚àû, h norms, 266
F
Finite
difference
approximation
of
the
Laplacian, 59, 66
Finite difference method
convergence, 41
convergence of order p, 41
Finite difference scheme
central, 53, 59
consistent, 42, 257, 321
consistent of order p, 42
convergent, 43
explicit, 261
explicit Euler, 254
Ô¨Åve point scheme for the Laplacian, 59
for the heat equation, 253
for the wave equation, 320
general l + m step, 260
implicit, 261
implicit Euler, 259
leapfrog, 259
stencil, 59
Œ∏-scheme, 296, 325, 338
three point scheme, 39, 58, 66
truncation error, 262
Finite difference-Ô¨Ånite element schemes,
302
Finite element method (FEM), 148
in dimension one, 149
in dimension two, 167
Finite elements
1d P1 Lagrange, 149
1d P3 Hermite, 159
2d rectangular Q1 Lagrange, 172, 174,
190

390
Index
2d rectangular Q2 Lagrange, 191
2d rectangular Q3 Hermite rectangle,
197
2d rectangular Q3 Lagrange, 197
2d triangular P1 Lagrange, 204
2d triangular P3 Lagrange, 212
general, 189
Finite volume cell, 345, 346, 354, 377‚Äì379,
381
Finite volume method
elliptic case in dimension one, 345
transport equation in dimension one, 354
transport equation in dimension two, 377
Finite volume scheme, 347
centered, 371
conservative, 362, 366, 382
consistency, 365, 366
consistency condition, 356
convergence, 349, 357, 359
convergence in ‚Ñì‚àû, 369, 370
decentered, see upwind
explicit Euler, 355, 380
explicit three point, 361
in conservation form, see conservative
monotone, 364, 371
nonlinear, 373
order, 365
order of a, 365, 366
stability, 363
stability in ‚Ñì2, 364, 367, 370‚Äì372
stability in ‚Ñì‚àû, 363, 368, 370, 371
truncation error, 349, 365, 366
viscosity coefÔ¨Åcient, 367, 370‚Äì372
von Neumann condition, 364, 365
Flux, 352, 355, 380
nonlinear, 362, 373
numerical, 347, 355, 356, 362, 364, 366,
367, 371, 372, 380
Flux function, 353
Forward differential quotient, 254
Forward Euler method for ordinary differen-
tial equations, 255, 380
Forward Euler three point scheme, see
explicit Euler three point scheme
Fourier law, 29
Fourier series, 222, 286, 311, 327, 364
Fourier transform, 33, 327
continuous, 294
discrete, 282
Fourier, Joseph, 27
FreeFem++, 215
Fubini‚Äôs theorem, 88, 89, 98, 102, 106, 232
Functions with compact support, 73
Fundamental solution, 247
Fundamental tone, 25, 26
G
Galerkin method, 145
G√•rding‚Äôs inequality, 242
Gaussian, 246
Gaussian elimination, 64
Generic constant, 179
Gibbs phenomenon, 228, 229
Gradient, 103
Green function, 38
Green‚Äôs formula, 118, 120, 130, 134, 140,
142
for C1 functions, 90
for Sobolev functions, 114
Grid
points, 38, 58, 149, 253
space step, 39, 58, 253
space-time, 253, 284
time step, 253
Grid sampling operator, 41, 50, 262
Gronwall‚Äôs
inequality,
see
Gronwall‚Äôs
lemma
Gronwall‚Äôs lemma, 309, 310
H
H‚àí1() space, 238
H1/2(‚àÇ) space, 115
Hm() spaces, 99
Hm
0 () spaces, 101
Harmonic functions, 17
Harmonic vibrations, 24
Harmonics, 25, 26, 311
Hat functions, 154, 303
Heat conductivity, 29
Heat equation, 27, 33, 133, 219
backward, 32, 225
energy, 236
exponential decay
of the energy, 237, 245
uniform, 225, 227
Ô¨Ånite difference method for the, 253
irreversibility of the, 225
maximum principle, 220, 222, 227
monotonicity, see maximum principle
on R, 245
propagation of the energy at inÔ¨Ånite
speed, 250
regular solution, 223
semi-discrete Ô¨Ånite difference scheme,
292

Index
391
smoothing effect, 225, 227
stability
in the C0 norm, 222
in the C0([0, T ]; L2()) norm, 237
stability of a Ô¨Ånite difference scheme in
the sense of von Neumann, 285, 291,
295
stability of a Ô¨Ånite difference scheme via
Fourier series, 286
stability of a Ô¨Ånite difference scheme via
the continuous Fourier transform, 292
stability of a Ô¨Ånite difference scheme via
the discrete Fourier transform, 282
uniqueness, 222, 236
variational formulation, 239
weak solution, 240
Heat Ô¨Çux, 28, 120
Heat kernel, 245, 247, 249
Heaviside function, 95, 100
Hilbert basis, 233, 239, 314
Hilbert-valued function
measurable, 231
of class Ck, 230
simple, 230
H√∂lder
functions, 74
inequality, 75, 94
Hyperbolic equation, 33, 309
Hyperbolic systems, 341, 353
Hypoellipticity, 237, 250
I
Ill-conditioned matrix, 55
Implicit Euler three point scheme, 259
consistency for the ‚àû, h norms, 259
convergence for the 2, h norms, 279
error estimate, 279
stability for the 2, h norms, 279
IndeÔ¨Ånitely differentiable, compactly sup-
ported functions, 73, 91
Induced matrix norm, 43, 265
2, h, 274
‚àû, h, 266
Inf-sup condition, 125
Initial-boundary value problem, 21, 219,
223, 237, 307, 313, 376
Initial condition, 18, 219, 254, 255, 308, 320,
356, 357, 376, 380
Initial value problem, 19
Inscribed circle, 169, 173
Integration by parts formula, 171
Integration by parts in Rd
in C1( ¬Ø), 87, 95
in H1(), 114
Interpolation operator, 151, 161, 178
Q1, 179
Interpolation property, 155, 164, 190
Inverse nonnegative matrix, 44, 45, 51, 52,
63
J
Jordan decomposition, 341
K
Kinetic description, 18
L
L p(0, T ; V ) spaces, 231
L p() spaces, 74
L p
loc() spaces, 76
Lagrange interpolation, 155, 156, 178, 192,
209
Laplace equation, 17
Laplace operator, 16, 33
Laplacian, 16
Lax‚ÄìFriedrichs scheme, 341, 371, 373
Lax‚ÄìMilgram theorem, 122, 127, 133, 135,
138, 143, 146
Lax‚Äìtheorem, 264
converse of, 272
Lax‚ÄìWendroff scheme, 342, 367, 368, 373
Leapfrog method
heat equation, 259
instability for the 2, h norms, 281
non convergence for the 2, h norms,
281
wave equation, 343
stability, 343
Lebesgue
dominated convergence theorem, 76,
248, 249
monotone convergence theorem, 245
points theorem, 76
Lebesgue spaces
Hilbert-valued, 231
real valued, 74
Leibniz formula, 97, 138
Lions‚Äôs lemma, 105
Localization of a function, 87
M
Matrix

392
Index
ampliÔ¨Åcation, 270, 321, 328, 336
assembling of the, 148, 183
band, 165
block tridiagonal, 60, 186
condition number, 55
full, 154
Galerkin approximation, 148
ill-conditioned, 55, 154
inverse nonnegative, 44, 45, 51, 52, 63
Jordan form, 341
mass, 304
M-matrix, 45
monotone, 44
nonnegative, 44
normal, 274, 333
orthogonal, 274
positive deÔ¨Ånite, 40, 61
sparse, 41, 154, 304, 381
spectral radius, 274, 278, 280
stiffness, 304
tridiagonal, 41, 156, 255, 276
uniformly elliptic, 138
unitary, 275
well-conditioned, 55
Maximum principle, 9, 11
discrete, 45, 62, 269, 370
for the heat equation, 220, 227
for the Poisson equation, 17
for the transport equation, 360
Maxwell‚Äôs equations, 27
Medit, 217
Mesh
generation, 168
Mesh 1d, 149
Ô¨Ånite volume, 349, 361
node
boundary, 149
interior, 149
size, 149
uniform, 149
Mesh 2d, 167
admissible, 169, 171, 205, 377
edge, 167, 171, 211, 378, 382
boundary, 177, 379
internal, 176, 196, 378
middle of, 193
element, 167
Ô¨Ånite volume, 377
node, 168, 192, 193
boundary, 173, 177
interior, 173, 177, 183, 193
rectangular, 172
regular family, 170, 173, 178, 182, 183,
214
size, 169, 172
triangular, 204
unstructured triangular, 205
vertex, 168, 193
Meyers-Serrin theorem, 112
Minimization problem, 125, 128, 138, 142
Minty‚Äôs trick, 126
M-matrix, 45
Modeling error, 5, 27
Modeling hypothesis, 1, 3, 4, 6, 31
MolliÔ¨Åer, 83, 91, 110
Monotone matrix, 44
Multiindex notation for partial derivatives,
72
Multiplier operator, 290, 328
N
Newton‚Äôs law, 2, 4, 14, 22, 308
Nodal values, 151, 156, 162, 163, 178, 193
Node, 149, 164, 174, 192, 211
Non conforming approximation spaces, 146
Norm, 265
induced matrix, 43, 265, 274
operator, 43, 265, 274
submultiplicative, 44, 55, 272
Normal derivative, 18
Normal matrix, 274, 333
Normal trace, 114, 121
Normal unit exterior vector, 79, 80, 87, 171,
375, 378
Numbering
of cells, 381
of elements, 173
of nodes, 173, 176, 183, 184, 205
NumericalÔ¨Çux,347,355,356,362,364,366,
367, 371, 372, 380
Numerical integration, 157
Numerical methods for linear systems, 157
Numerical viscosity, 367
O
Open subset of Rd
Lipschitz, 78
of class Ck,Œ≤, 78
Operator norm, 43, 265, 274
Order
of a Ô¨Ånite volume scheme, 365
of a general scheme for a family of
norms, 263
of the Crank-Nicolson scheme, 297

Index
393
of the explicit Euler scheme, 257
of the implicit Euler scheme, 259
of the leapfrog method, 260
of the Œ∏-scheme, 296
Orthogonal projection
on a closed convex set, 70
on a closed vector subspace, 70
P
P1 Lagrange basis polynomials, 205
P2 Lagrange basis polynomials, 211
P3 Hermite
1d basis polynomials, 161, 164
1d interpolation, 161, 162, 164
P3 Lagrange basis polynomials, 213
Pk space, 173
Parabolic equation, 33
Parseval‚Äôs formula, 287, 329
Parseval‚Äôs identity, 234, 241
Partitions of unity, 82, 115
PDE, v
Picard‚ÄìLindel√∂f theorem, 353, 377
Piecewise polynomial functions, 149
Pivot space, 72
Plancherel‚Äôs formula, 294
Plate equation, 17
Poincar√© inequality, 101, 103, 127, 141, 235,
237, 315
discrete, 299, 300
Poincar√©‚ÄìWirtinger inequality, 131, 132,
136
Poisson equation, 17, 30, 33, 117
probabilistic interpretation of the, 17
Preconditioning, 57
Pricing, 31
Principal value of 1/x, 94
Propagation speed, 23, 307, 351
Q
Q1 Lagrange
basis polynomials, 179, 184
interpolation operator, 179
Q2 Lagrange basis polynomials, 193
Qk space, 173
Quantity of heat, 28
R
Rademacher‚Äôs theorem, 79
Rectangular Q1 Ô¨Ånite elements, 172, 174
Rectangular Q2 Ô¨Ånite elements, 191
Rectangular Q3 Ô¨Ånite elements, 197
Reference
element, 161, 179, 180, 184
rectangle, 179
triangle, 206, 214
Rellich theorem, 108, 132, 135, 180
Richardson method, see leapfrog method
Riesz theorem, 71
vs. Lax‚ÄìMilgram theorem, 124
Rolle‚Äôs theorem, 152, 163
S
Scheme
Crank-Nicolson, 297
explicit Euler, 255
implicit Euler, 259
Lax‚ÄìFriedrichs, 341, 371, 373
Lax‚ÄìWendroff, 342, 367, 368, 373
leapfrog, 259
Œ∏, 291, 325
upwind, 356, 357, 360, 364, 370, 373,
374, 380, 382
Schr√∂dinger equation, 30
Schur decomposition, 341
Scilab, 47, 54
Secant method, 9
Second order operator, 137
Semi-discrete scheme
explicit Euler, 292
Ô¨Ånite difference, 292
Ô¨Ånite volume, 355
relation with discrete scheme, 293
stability in L2(R), 294
explicit Euler scheme, 295
Œ∏-scheme, 296
Separation of variables, 24
Shape functions, 303
1d P3 Hermite, 164
2d P1 Lagrange, 205
2d P2 Lagrange, 211
2d P3 Lagrange, 213
2d Q1 Lagrange, 179, 184
2d Q2 Lagrange, 193
general Ô¨Ånite element, 191
Shock wave, 324, 354, 375
Shooting method, 6, 8
Sobolev embedding, 105, 178
Sobolev spaces, 99
density of smooth functions, 110
in one dimension, 105
Space grid sampling operator, 41, 256
Space-time grid, 253, 284
Spaces

394
Index
Ck(), 72
Pk, 173
Qk, 173
Ck([0, T ]; V ), 230
Ck( ¬Ø), 73
Ck,Œ≤( ¬Ø), 74
Cm,n( ¬ØQ), 257
D(), 73, 91
D‚Ä≤(), 91
H1/2(‚àÇ), 115
Hm(), 99
Hm
0 (), 101
L p(0, T ; V ), 231
L p(), 74
L p
loc(), 76
W m,p(), 99
SpeciÔ¨Åc heat, 29
Spectral methods, 148, 226
Spectral radius, 274, 278, 280, 325, 342, 343
Spectral theory, 26
Stability
of a Ô¨Ånite difference scheme for an ellip-
tic problem, 46, 51, 62
of a Ô¨Ånite volume scheme, 363
of a general scheme for a family of
norms, 263
of the Œ∏-scheme on ‚Ñì2(Z), 292
of the Crank-Nicolson scheme for the
2, h norms, 299
of the explicit Euler scheme for the 2, h
norms, 278
of the explicit Euler scheme for the ‚àû, h
norms, 266
of the explicit Euler scheme on ‚Ñì2(Z),
290
of the implicit Euler scheme for the 2, h
norms, 279
unconditional, 263, 299, 338
via Fourier series, 286, 327, 364
via the continuous Fourier transform,
292, 332
via the discrete Fourier transform, 282
via the energy method, 297
Stability in the sense of von Neumann
of a discrete scheme, 285, 328
of a scheme on ‚Ñì2(Z), 291
of a semi-discrete scheme, 295
of the discrete explicit Euler scheme, 286
of the discrete implicit Euler scheme, 286
of the Œ∏-scheme, 292, 296
Stiffness matrix, 304
Stokes formula, 90, 379
String problem, 5
Summation by parts formula, 298
Support of a function, 73
T
Temperature, 27
Tension
of an elastic membrane, 13
of an elastic string, 2, 5
Tensor product of two functions, 185
Test-function, 104, 118, 131, 142, 143, 240,
314
Test-function space, 120, 142, 143
Tetrahedron, 189
Œ∏-scheme
for the heat equation
consistency, 296
discrete, 291, 295
for Œ∏
=
1
2, see Crank-Nicolson
scheme
order, 296
semi-discrete, 295
for the wave equation, 325, 338
Three point centered approximation, 255
Total family, 233
Trace mapping, 110, 114, 129
continuity of the, 136
in one dimension, 107
Trace space, 115
Trace theorem, 112
in one dimension, 107
Transport equation, 18, 34, 351, 375
nonlinear, 353
Transport operator, 23
Triangular P1 Lagrange Ô¨Ånite elements, 204
Triangular P2 Lagrange Ô¨Ånite elements, 209
Triangular P3 Lagrange Ô¨Ånite elements, 212
Triangulation, see mesh 2d
Truncation error, 42, 54, 67
Ô¨Ånite volume, 349, 365, 366
of a general scheme, 262
of the forward Euler scheme, 256
of the implicit Euler scheme for the ‚àû, h
norms, 259
of the leapfrog method, 260
U
Unconditional stability, 263, 279, 338
Unisolvence, 190, 193
P1 Lagrange triangle, 205
P2 Lagrange triangle, 210
P3 Lagrange triangle, 212
Q1 Lagrange rectangle, 190

Index
395
Q2 Lagrange rectangle, 192
Upwind scheme, 356, 357, 360, 364, 370,
373, 374, 380, 382
V
V -ellipticity, 122, 124, 125, 127, 129, 132,
135, 139, 141, 143
constant, 125, 146
Vh-interpolate, 151
Vh-interpolation, 163
Vh-interpolation operator, 151, 161, 182
Variation of the constant, 240
Variational formulation, 142
of a general second order problem, 137
of the convection‚Äìdiffusion problem,
139
of the Dirichlet problem, 118
of the Fourier problem, 133
of the heat equation, 239
of the mixed problem, 122
of the Neumann problem, 120, 130
of the plate problem, 140
of the wave equation, 313
Vibrating string equation, 22, 308
Von Neumann stability, see stability in the
sense of von Neumann
W
W m,p() spaces, 99
completeness of, 100
Wave equation, 23, 26, 33, 307
cone of inÔ¨Çuence, 319
discrete cone of inÔ¨Çuence, 322
energy, 308
derivative of the, 309, 317
Ô¨Ånite difference method for the, 320
no smoothing effect, 313
on R, 317
propagation at Ô¨Ånite speed, 319
regular solution, 311
reversibility of the, 320
semi-discrete Ô¨Ånite difference scheme,
332
shock, 324
stability in the energy norm, 310, 316
stability of a Ô¨Ånite difference scheme in
the sense of von Neumann, 328
variational formulation, 313
weak solution, 314
Well-conditioned matrix, 55
Y
Young modulus, 11
Young‚Äôs inequality, 235

