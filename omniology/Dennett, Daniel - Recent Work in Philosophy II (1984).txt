ARTIFICIAL INTELLIGENCE 
231 
CORRESPONDENT'S REPORT 
Recent Work in Philosophy II 
Daniel C. Dennett 
Philosophy Department, Tufts University, Medford, 
MA 02155, U.S.A. 
I mentioned in the first of these columns that I was attempting to excite some 
interest in the Frame Problem among philosophers (since I think it is a 
philosophical problem--not 'just' a problem of engineering or computer 
science). It is too early for my efforts to have born fruit in the form of 
published pieces, but there are some stirrings, which I will report on as soon as 
I can cite chapter and verse--supposing of course that they turn out to be 
worth reading. My attempt to advertise the Frame Problem includes a paper, 
"Cognitive Wheels: the Frame Problem of AI", which is forthcoming in a 
volume edited by Christopher Hookway, Minds, Machines and Evolution, 
Cambridge University Press, 1984. There are other papers by philosophers 
dealing with AI in that volume. 
There are a few philosophers who have learned LISP and begun trying their 
hand at serious AI programs. One is Robert Cummins, whose new book, The 
Nature of Psychological Explanation (Bradford Books/MIT Press, 1983), covers 
familiar ground in the "philosophical foundations of cognitive science"--the 
nature of mental representation, the logic of functional explanation, the 
problem of intentionality--but from a more realistic and detailed standpoint 
than previous philosophical work. Under Cummins' patient examination, many 
of the ideological slogans of cognitive science evaporate. This is certainly useful 
for philosophers, the primary intended audience for the book, and I suspect 
many of those working in the trenches will similarly benefit from this clearing 
away of smoke and mist. 
I will not ordinarily report here on current work in logic--because I am no 
logician and don't myself keep up with the field. Besides, my impression is that 
the flow of information from formal logic to AI is not in need of my help, even 
if I could offer it. But here is an exception: just in case it hasn't penetrated to 
all corners of AI, I commend Nuel Belnap's work on relevance logic and 
Artificial Intelligence 22 (1984) 231-233 
0004-3702/84/$3.00 Â© 1984, Elsevier Science Publishers B.V. (North-Holland) 

232 
D.C. DENNETT 
related topics. For starters, see his "How a Computer should Think" in G. 
Ryle, ed., Contemporary Aspects of Philosophy, Oriel Press, 1977, pp. 30-55; 
and N. Belnap and M. Dunn, "Entailment and the Disjunctive Syllogism", in 
Contemporary Philosophy. A New Survey, Vol. 1, Martinus Nijhoff, the Hague, 
1981, pp. 337-366. Another piece that I think might be useful to people in AI is 
Carlos Alchourron and David Makinson, "Hierarchies of Regulations and their 
Logic", in R. Hilpinen, ed., Studies in Deontic Logic, Reidel, Dordrecht, 1980. 
If any field in philosophy ought to be useful to AI, it should be epistemology, 
but until very recently, I think, it has been almost entirely preoccupied with 
artifactual problems that arise only under radically idealized conditions: per- 
fectly rational knowers with indefinitely extensive (and accessible) memories, 
with eternity on their hands and nothing better to do than sit around avoiding 
error. A particularly fine antidote to that lamentable tradition is Lawrence 
Powers, "Knowledge by Deduction", Philosophical Review, 1978, pp. 337-372. 
The times are changing; epistemology is becoming 'naturalized'--see 
Quine's well-known essay, "Epistemology Naturalized", in his Ontological 
Relativity & Other Essays, Columbia, New York, 1969, pp. 69-91. This 
naturalization has taken several healthy directions: 
(1) A general tendency to pay closer attention to the actual epistemological 
problems that arise in the real world (of science, primarily), and to the ways we 
actually tend to resolve them. See, for instance, Clark Glymour's Theory and 
Evidence, Princeton University Press, 1980. 
(2) A recognition of the importance of making one's normative epistemology 
mesh with the hard facts (as they begin to trickle in) of human cognitive 
psychology. See, for instance, Alvin Goldman, "Epistemics: the Regulative 
Theory of Cognition", J. Philosophy, 1978; Christopher Cherniak, "Feasible 
Inferences", Philosophy of Science, 1981, pp. 248-268, and "Rationality and th'~ 
Structure of Human Memory", Synthese, November 1983. 
(3) "Evolutionary epistemology". The term is due to Donald Campbell, 
"Evolutionary Epistemology", in P.A. Schilpp, ed., The Philosophy of Karl 
Popper, LaSalle, 1974, but has now been broadened to include quite a broad 
spectrum of work by philosophers (and a few biologists and psychologists) who 
think that asking evolutionary questions about our cognitive capacities is 
essential to understanding their powers, their limits, their modes of operation. 
One that strikes me as potentially particularly illuminating to people in AI is 
William Wimsatt's "Randomness and Perceived Randomness in Evolutionary 
Biology", in Synthese, 1980, pp. 287-332. 1 dip my own oar into this water in 
"Intentional Systems in Cognitive Ethology: the 'Panglossian Paradigm' 
Defended", in Behavioral and Brain Sciences, September 1983, pp. 343-390. 
There are several good books and articles in preparation in this area. One in 
particular is Ruth Garrett Millikan, Language, Thought and Other Biological 
Categories, forthcoming from Bradford Books/MIT Press. I will report on 
others as they become available. 

CORRESPONDENT'S REPORT 
233 
It is often bruited about by philosophers that people in AI are lamentably 
ignorant of the great works on the mind by the Phenomenologists: Husserl, 
Merleau-Ponty, Heidegger and others. But how is the well-Intentioned Alnik 
to remedy this with anything less than four years of graduate work? The works 
of these authors are as far from self-explanatory as anything ever written. Now 
there is at least a candidate way out: Hubert Dreyfus has edited, "in col- 
laboration with Harrison Hall" (whatever that means), a collection, Husserl, 
Intentionality and Cognitive Science, Bradford/MIT Press, 1982. This book is 
supposed to show how Husserl and the other Phenomenologists foreshadow 
cognitive science, how Husserl's inscrutable noemata are just Minsky's frames 
without a computer Oust think what Minsky's frames would be with a com- 
puter!), and how Heidegger's defeat of Husserl was a preview of John Searle's 
triumph over AI. (An essay by Searle, "What is an Intentional State?" is 
reprinted in the volume.) In fact many of the essays in this volume are almost 
as inaccessible as the originals they discuss, but Dreyfus" introductory essay is 
well worth reading. Once you have finished it you will either know just what 
next to read about Phenomenology, and why, or you will know why you have 
just learned everything you ever needed to know about Husserl's sort of 
Phenomenology. 

