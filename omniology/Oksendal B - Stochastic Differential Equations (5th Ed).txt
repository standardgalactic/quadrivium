Bernt Øksendal
Stochastic Diﬀerential Equations
An Introduction with Applications
Fifth Edition, Corrected Printing
Springer-Verlag Heidelberg New York
Springer-Verlag
Berlin Heidelberg NewYork
London Paris Tokyo
Hong Kong Barcelona
Budapest

To My Family
Eva, Elise, Anders and Karina

2

The front cover shows four sample paths Xt(ω1), Xt(ω2), Xt(ω3) and Xt(ω4)
of a geometric Brownian motion Xt(ω), i.e. of the solution of a (1-dimensional)
stochastic diﬀerential equation of the form
dXt
dt
= (r + α · Wt)Xt
t ≥0 ; X0 = x
where x, r and α are constants and Wt = Wt(ω) is white noise. This process is
often used to model “exponential growth under uncertainty”. See Chapters 5,
10, 11 and 12.
The ﬁgure is a computer simulation for the case x = r = 1, α = 0.6.
The mean value of Xt, E[Xt] = exp(t), is also drawn. Courtesy of Jan Ubøe,
Stord/Haugesund College.

We have not succeeded in answering all our problems.
The answers we have found only serve to raise a whole set
of new questions. In some ways we feel we are as confused
as ever, but we believe we are confused on a higher level
and about more important things.
Posted outside the mathematics reading room,
Tromsø University

Preface to Corrected Printing, Fifth Edition
The main corrections and improvements in this corrected printing are from
Chaper 12. I have beneﬁtted from useful comments from a number of peo-
ple, including (in alphabetical order) Fredrik Dahl, Simone Deparis, Ulrich
Haussmann, Yaozhong Hu, Marianne Huebner, Carl Peter Kirkebø, Niko-
lay Kolev, Takashi Kumagai, Shlomo Levental, Geir Magnussen, Anders
Øksendal, J¨urgen Potthoﬀ, Colin Rowat, Stig Sandnes, Lones Smith, Set-
suo Taniguchi and Bjørn Thunestvedt.
I want to thank them all for helping me making the book better. I also
want to thank Dina Haraldsson for proﬁcient typing.
Blindern, May 2000
Bernt Øksendal

VI

Preface to the Fifth Edition
The main new feature of the ﬁfth edition is the addition of a new chapter,
Chapter 12, on applications to mathematical ﬁnance. I found it natural to
include this material as another major application of stochastic analysis, in
view of the amazing development in this ﬁeld during the last 10–20 years.
Moreover, the close contact between the theoretical achievements and the
applications in this area is striking. For example, today very few ﬁrms (if
any) trade with options without consulting the Black & Scholes formula!
The ﬁrst 11 chapters of the book are not much changed from the previous
edition, but I have continued my eﬀorts to improve the presentation through-
out and correct errors and misprints. Some new exercises have been added.
Moreover, to facilitate the use of the book each chapter has been divided
into subsections. If one doesn’t want (or doesn’t have time) to cover all the
chapters, then one can compose a course by choosing subsections from the
chapters. The chart below indicates what material depends on which sections.
Chapter 8
Chapter 1-5
Chapter 7
Chapter 10
Chapter 6
Chapter 9
Chapter 11
Section
12.3
Chapter 12
Section
9.1
Section
8.6
For example, to cover the ﬁrst two sections of the new chapter 12 it is recom-
mended that one (at least) covers Chapters 1–5, Chapter 7 and Section 8.6.

VIII
Chapter 10, and hence Section 9.1, are necessary additional background for
Section 12.3, in particular for the subsection on American options.
In my work on this edition I have beneﬁtted from useful suggestions
from many people, including (in alphabetical order) Knut Aase, Luis Al-
varez, Peter Christensen, Kian Esteghamat, Nils Christian Framstad, Helge
Holden, Christian Irgens, Saul Jacka, Naoto Kunitomo and his group, Sure
Mataramvura, Trond Myhre, Anders Øksendal, Nils Øvrelid, Walter Schacher-
mayer, Bjarne Schielderop, Atle Seierstad, Jan Ubøe, Gjermund V˚age and
Dan Zes. I thank them all for their contributions to the improvement of the
book.
Again Dina Haraldsson demonstrated her impressive skills in typing the
manuscript – and in ﬁnding her way in the LATEX jungle! I am very grateful
for her help and for her patience with me and all my revisions, new versions
and revised revisions . . .
Blindern, January 1998
Bernt Øksendal

Preface to the Fourth Edition
In this edition I have added some material which is particularly useful for the
applications, namely the martingale representation theorem (Chapter IV),
the variational inequalities associated to optimal stopping problems (Chapter
X) and stochastic control with terminal conditions (Chapter XI). In addition
solutions and extra hints to some of the exercises are now included. Moreover,
the proof and the discussion of the Girsanov theorem have been changed in
order to make it more easy to apply, e.g. in economics. And the presentation
in general has been corrected and revised throughout the text, in order to
make the book better and more useful.
During this work I have beneﬁtted from valuable comments from several
persons, including Knut Aase, Sigmund Berntsen, Mark H. A. Davis, Helge
Holden, Yaozhong Hu, Tom Lindstrøm, Trygve Nilsen, Paulo Ruﬃno, Isaac
Saias, Clint Scovel, Jan Ubøe, Suleyman Ustunel, Qinghua Zhang, Tusheng
Zhang and Victor Daniel Zurkowski. I am grateful to them all for their help.
My special thanks go to H˚akon Nyhus, who carefully read large portions
of the manuscript and gave me a long list of improvements, as well as many
other useful suggestions.
Finally I wish to express my gratitude to Tove Møller and Dina Haralds-
son, who typed the manuscript with impressive proﬁciency.
Oslo, June 1995
Bernt Øksendal

X

Preface to the Third Edition
The main new feature of the third edition is that exercises have been included
to each of the chapters II–XI. The purpose of these exercises is to help the
reader to get a better understanding of the text. Some of the exercises are
quite routine, intended to illustrate the results, while other exercises are
harder and more challenging and some serve to extend the theory.
I have also continued the eﬀort to correct misprints and errors and to
improve the presentation. I have beneﬁtted from valuable comments and
suggestions from Mark H. A. Davis, H˚akon Gjessing, Torgny Lindvall and
H˚akon Nyhus, My best thanks to them all.
A quite noticeable non-mathematical improvement is that the book is
now typed in TEX. Tove Lieberg did a great typing job (as usual) and I am
very grateful to her for her eﬀort and inﬁnite patience.
Oslo, June 1991
Bernt Øksendal

XII

Preface to the Second Edition
In the second edition I have split the chapter on diﬀusion processes in two, the
new Chapters VII and VIII: Chapter VII treats only those basic properties
of diﬀusions that are needed for the applications in the last 3 chapters. The
readers that are anxious to get to the applications as soon as possible can
therefore jump directly from Chapter VII to Chapters IX, X and XI.
In Chapter VIII other important properties of diﬀusions are discussed.
While not strictly necessary for the rest of the book, these properties are
central in today’s theory of stochastic analysis and crucial for many other
applications.
Hopefully this change will make the book more ﬂexible for the diﬀerent
purposes. I have also made an eﬀort to improve the presentation at some
points and I have corrected the misprints and errors that I knew about,
hopefully without introducing new ones. I am grateful for the responses that
I have received on the book and in particular I wish to thank Henrik Martens
for his helpful comments.
Tove Lieberg has impressed me with her unique combination of typing
accuracy and speed. I wish to thank her for her help and patience, together
with Dina Haraldsson and Tone Rasmussen who sometimes assisted on the
typing.
Oslo, August 1989
Bernt Øksendal

XIV

Preface to the First Edition
These notes are based on a postgraduate course I gave on stochastic dif-
ferential equations at Edinburgh University in the spring 1982. No previous
knowledge about the subject was assumed, but the presentation is based on
some background in measure theory.
There are several reasons why one should learn more about stochastic
diﬀerential equations: They have a wide range of applications outside mathe-
matics, there are many fruitful connections to other mathematical disciplines
and the subject has a rapidly developing life of its own as a fascinating re-
search ﬁeld with many interesting unanswered questions.
Unfortunately most of the literature about stochastic diﬀerential equa-
tions seems to place so much emphasis on rigor and completeness that it
scares many nonexperts away. These notes are an attempt to approach the
subject from the nonexpert point of view: Not knowing anything (except ru-
mours, maybe) about a subject to start with, what would I like to know ﬁrst
of all? My answer would be:
1)
In what situations does the subject arise?
2)
What are its essential features?
3)
What are the applications and the connections to other ﬁelds?
I would not be so interested in the proof of the most general case, but rather
in an easier proof of a special case, which may give just as much of the basic
idea in the argument. And I would be willing to believe some basic results
without proof (at ﬁrst stage, anyway) in order to have time for some more
basic applications.
These notes reﬂect this point of view. Such an approach enables us to
reach the highlights of the theory quicker and easier. Thus it is hoped that
these notes may contribute to ﬁll a gap in the existing literature. The course
is meant to be an appetizer. If it succeeds in awaking further interest, the
reader will have a large selection of excellent literature available for the study
of the whole story. Some of this literature is listed at the back.
In the introduction we state 6 problems where stochastic diﬀerential equa-
tions play an essential role in the solution. In Chapter II we introduce the
basic mathematical notions needed for the mathematical model of some of
these problems, leading to the concept of Ito integrals in Chapter III. In
Chapter IV we develop the stochastic calculus (the Ito formula) and in Chap-

XVI
ter V we use this to solve some stochastic diﬀerential equations, including the
ﬁrst two problems in the introduction. In Chapter VI we present a solution
of the linear ﬁltering problem (of which problem 3 is an example), using
the stochastic calculus. Problem 4 is the Dirichlet problem. Although this is
purely deterministic we outline in Chapters VII and VIII how the introduc-
tion of an associated Ito diﬀusion (i.e. solution of a stochastic diﬀerential
equation) leads to a simple, intuitive and useful stochastic solution, which is
the cornerstone of stochastic potential theory. Problem 5 is an optimal stop-
ping problem. In Chapter IX we represent the state of a game at time t by an
Ito diﬀusion and solve the corresponding optimal stopping problem. The so-
lution involves potential theoretic notions, such as the generalized harmonic
extension provided by the solution of the Dirichlet problem in Chapter VIII.
Problem 6 is a stochastic version of F.P. Ramsey’s classical control problem
from 1928. In Chapter X we formulate the general stochastic control prob-
lem in terms of stochastic diﬀerential equations, and we apply the results of
Chapters VII and VIII to show that the problem can be reduced to solving
the (deterministic) Hamilton-Jacobi-Bellman equation. As an illustration we
solve a problem about optimal portfolio selection.
After the course was ﬁrst given in Edinburgh in 1982, revised and ex-
panded versions were presented at Agder College, Kristiansand and Univer-
sity of Oslo. Every time about half of the audience have come from the ap-
plied section, the others being so-called “pure” mathematicians. This fruitful
combination has created a broad variety of valuable comments, for which I
am very grateful. I particularly wish to express my gratitude to K.K. Aase,
L. Csink and A.M. Davie for many useful discussions.
I wish to thank the Science and Engineering Research Council, U.K. and
Norges Almenvitenskapelige Forskningsr˚ad (NAVF), Norway for their ﬁnan-
cial support. And I am greatly indebted to Ingrid Skram, Agder College and
Inger Prestbakken, University of Oslo for their excellent typing – and their
patience with the innumerable changes in the manuscript during these two
years.
Oslo, June 1985
Bernt Øksendal
Note: Chapters VIII, IX, X of the First Edition have become Chapters IX,
X, XI of the Second Edition.

Table of Contents
1.
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Stochastic Analogs of Classical Diﬀerential Equations . . . . . . .
1
1.2
Filtering Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
1.3
Stochastic Approach to Deterministic Boundary Value Prob-
lems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
1.4
Optimal Stopping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.5
Stochastic Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
1.6
Mathematical Finance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
4
2.
Some Mathematical Preliminaries . . . . . . . . . . . . . . . . . . . . . . . .
7
2.1
Probability Spaces, Random Variables and Stochastic Processes
7
2.2
An Important Example: Brownian Motion . . . . . . . . . . . . . . . . .
11
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
14
3.
Itˆo Integrals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
3.1
Construction of the Itˆo Integral . . . . . . . . . . . . . . . . . . . . . . . . . .
21
3.2
Some properties of the Itˆo integral . . . . . . . . . . . . . . . . . . . . . . . .
30
3.3
Extensions of the Itˆo integral . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
4.
The Itˆo Formula and the Martingale Representation Theo-
rem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
43
4.1
The 1-dimensional Itˆo formula . . . . . . . . . . . . . . . . . . . . . . . . . . .
43
4.2
The Multi-dimensional Itˆo Formula . . . . . . . . . . . . . . . . . . . . . . .
48
4.3
The Martingale Representation Theorem . . . . . . . . . . . . . . . . . .
49
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
54
5.
Stochastic Diﬀerential Equations . . . . . . . . . . . . . . . . . . . . . . . . .
61
5.1
Examples and Some Solution Methods . . . . . . . . . . . . . . . . . . . .
61
5.2
An Existence and Uniqueness Result . . . . . . . . . . . . . . . . . . . . . .
66
5.3
Weak and Strong Solutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
70
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
72

XVIII
Table of Contents
6.
The Filtering Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
6.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
6.2
The 1-Dimensional Linear Filtering Problem . . . . . . . . . . . . . . .
83
6.3
The Multidimensional Linear Filtering Problem . . . . . . . . . . . . 102
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
7.
Diﬀusions: Basic Properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
7.1
The Markov Property . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
7.2
The Strong Markov Property . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112
7.3
The Generator of an Itˆo Diﬀusion . . . . . . . . . . . . . . . . . . . . . . . . 117
7.4
The Dynkin Formula . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
7.5
The Characteristic Operator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
8.
Other Topics in Diﬀusion Theory . . . . . . . . . . . . . . . . . . . . . . . . . 133
8.1
Kolmogorov’s Backward Equation. The Resolvent . . . . . . . . . . 133
8.2
The Feynman-Kac Formula. Killing . . . . . . . . . . . . . . . . . . . . . . . 137
8.3
The Martingale Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140
8.4
When is an Itˆo Process a Diﬀusion?. . . . . . . . . . . . . . . . . . . . . . . 142
8.5
Random Time Change . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147
8.6
The Girsanov Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
9.
Applications to Boundary Value Problems . . . . . . . . . . . . . . . . 167
9.1
The Combined Dirichlet-Poisson Problem. Uniqueness. . . . . . . 167
9.2
The Dirichlet Problem. Regular Points . . . . . . . . . . . . . . . . . . . . 169
9.3
The Poisson Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188
10. Application to Optimal Stopping . . . . . . . . . . . . . . . . . . . . . . . . . 195
10.1 The Time-Homogeneous Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195
10.2 The Time-Inhomogeneous Case . . . . . . . . . . . . . . . . . . . . . . . . . . 207
10.3 Optimal Stopping Problems Involving an Integral. . . . . . . . . . . 212
10.4 Connection with Variational Inequalities. . . . . . . . . . . . . . . . . . . 214
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218
11. Application to Stochastic Control . . . . . . . . . . . . . . . . . . . . . . . . . 225
11.1 Statement of the Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225
11.2 The Hamilton-Jacobi-Bellman Equation . . . . . . . . . . . . . . . . . . . 227
11.3 Stochastic control problems with terminal conditions . . . . . . . . 241
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243

Table of Contents
XIX
12. Application to Mathematical Finance . . . . . . . . . . . . . . . . . . . . . 249
12.1 Market, portfolio and arbitrage . . . . . . . . . . . . . . . . . . . . . . . . . . . 249
12.2 Attainability and Completeness . . . . . . . . . . . . . . . . . . . . . . . . . . 259
12.3 Option Pricing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267
Exercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288
Appendix A: Normal Random Variables . . . . . . . . . . . . . . . . . . . . . . 295
Appendix B: Conditional Expectation . . . . . . . . . . . . . . . . . . . . . . . . 299
Appendix C: Uniform Integrability and Martingale Conver-
gence . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 301
Appendix D: An Approximation Result. . . . . . . . . . . . . . . . . . . . . . . 305
Solutions and Additional Hints to Some of the Exercises . . . . . . 309
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 317
List of Frequently Used Notation and Symbols . . . . . . . . . . . . . . . 325
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 329

1. Introduction
To convince the reader that stochastic diﬀerential equations is an important
subject let us mention some situations where such equations appear and can
be used:
1.1 Stochastic Analogs of Classical Diﬀerential
Equations
If we allow for some randomness in some of the coeﬃcients of a diﬀerential
equation we often obtain a more realistic mathematical model of the situation.
Problem 1.
Consider the simple population growth model
dN
dt = a(t)N(t),
N(0) = N0 (constant)
(1.1.1)
where N(t) is the size of the population at time t, and a(t) is the relative
rate of growth at time t. It might happen that a(t) is not completely known,
but subject to some random environmental eﬀects, so that we have
a(t) = r(t) + “noise” ,
where we do not know the exact behaviour of the noise term, only its prob-
ability distribution. The function r(t) is assumed to be nonrandom. How do
we solve (1.1.1) in this case?
Problem 2.
The charge Q(t) at time t at a ﬁxed point in an electric circuit
satisﬁes the diﬀerential equation
L · Q′′(t) + R · Q′(t) + 1
C · Q(t) = F(t), Q(0) = Q0, Q′(0) = I0
(1.1.2)
where L is inductance, R is resistance, C is capacitance and F(t) the potential
source at time t.
Again we may have a situation where some of the coeﬃcients, say F(t),
are not deterministic but of the form
F(t) = G(t) + “noise” .
(1.1.3)

2
1. Introduction
How do we solve (1.1.2) in this case?
More generally, the equation we obtain by allowing randomness in the
coeﬃcients of a diﬀerential equation is called a stochastic diﬀerential equa-
tion. This will be made more precise later. It is clear that any solution of
a stochastic diﬀerential equation must involve some randomness, i.e. we can
only hope to be able to say something about the probability distributions of
the solutions.
1.2 Filtering Problems
Problem 3.
Suppose that we, in order to improve our knowledge about
the solution, say of Problem 2, perform observations Z(s) of Q(s) at times
s ≤t. However, due to inaccuracies in our measurements we do not really
measure Q(s) but a disturbed version of it:
Z(s) = Q(s) + “noise” .
(1.2.1)
So in this case there are two sources of noise, the second coming from the
error of measurement.
The ﬁltering problem is: What is the best estimate of Q(t) satisfying
(1.1.2), based on the observations Zs in (1.2.1), where s ≤t ? Intuitively, the
problem is to “ﬁlter” the noise away from the observations in an optimal way.
In 1960 Kalman and in 1961 Kalman and Bucy proved what is now known
as the Kalman-Bucy ﬁlter. Basically the ﬁlter gives a procedure for estimating
the state of a system which satisﬁes a “noisy” linear diﬀerential equation,
based on a series of “noisy” observations.
Almost immediately the discovery found applications in aerospace en-
gineering (Ranger, Mariner, Apollo etc.) and it now has a broad range of
applications.
Thus the Kalman-Bucy ﬁlter is an example of a recent mathematical
discovery which has already proved to be useful – it is not just “potentially”
useful.
It is also a counterexample to the assertion that “applied mathematics
is bad mathematics” and to the assertion that “the only really useful math-
ematics is the elementary mathematics”. For the Kalman-Bucy ﬁlter – as
the whole subject of stochastic diﬀerential equations – involves advanced,
interesting and ﬁrst class mathematics.
1.3 Stochastic Approach to Deterministic Boundary
Value Problems
Problem 4.
The most celebrated example is the stochastic solution of the
Dirichlet problem:

1.4 Optimal Stopping
3
Given a (reasonable) domain U in Rn and a continuous function f on
the boundary of U, ∂U. Find a function ˜f continuous on the closure
U of U such that
(i)
˜f = f on ∂U
(ii) ˜f is harmonic in U, i.e.
∆˜f: =
n
X
i=1
∂2 ˜f
∂x2
i
= 0
in U .
In 1944 Kakutani proved that the solution could be expressed in terms
of Brownian motion (which will be constructed in Chapter 2): ˜f(x) is the
expected value of f at the ﬁrst exit point from U of the Brownian motion
starting at x ∈U.
It turned out that this was just the tip of an iceberg: For a large class
of semielliptic second order partial diﬀerential equations the corresponding
Dirichlet boundary value problem can be solved using a stochastic process
which is a solution of an associated stochastic diﬀerential equation.
1.4 Optimal Stopping
Problem 5.
Suppose a person has an asset or resource (e.g. a house, stocks,
oil...) that she is planning to sell. The price Xt at time t of her asset on the
open market varies according to a stochastic diﬀerential equation of the same
type as in Problem 1:
dXt
dt
= rXt + αXt · “noise”
where r, α are known constants. The discount rate is a known constant ρ. At
what time should she decide to sell?
We assume that she knows the behaviour of Xs up to the present time t,
but because of the noise in the system she can of course never be sure at the
time of the sale if her choice of time will turn out to be the best. So what
we are searching for is a stopping strategy that gives the best result in the
long run, i.e. maximizes the expected proﬁt when the inﬂation is taken into
account.
This is an optimal stopping problem. It turns out that the solution can be
expressed in terms of the solution of a corresponding boundary value problem
(Problem 4), except that the boundary is unknown (free) as well and this is
compensated by a double set of boundary conditions. It can also be expressed
in terms of a set of variational inequalities.

4
1. Introduction
1.5 Stochastic Control
Problem 6 (An optimal portfolio problem).
Suppose that a person has two possible investments:
(i) A risky investment (e.g. a stock), where the price p1(t) per unit at time
t satisﬁes a stochastic diﬀerential equation of the type discussed in Prob-
lem 1:
dp1
dt = (a + α · “noise”)p1
(1.5.1)
where a > 0 and α ∈R are constants
(ii) A safe investment (e.g. a bond), where the price p2(t) per unit at time t
grows exponentially:
dp2
dt = bp2
(1.5.2)
where b is a constant, 0 < b < a.
At each instant t the person can choose how large portion (fraction)
ut of his fortune Xt he wants to place in the risky investment, thereby
placing (1 −ut)Xt in the safe investment. Given a utility function U and
a terminal time T the problem is to ﬁnd the optimal portfolio ut ∈[0, 1]
i.e. ﬁnd the investment distribution ut; 0 ≤t ≤T which maximizes the
expected utility of the corresponding terminal fortune X(u)
T :
max
0≤ut≤1
n
E
h
U(X(u)
T )
io
(1.5.3)
1.6 Mathematical Finance
Problem 7 (Pricing of options).
Suppose that at time t = 0 the person in Problem 6 is oﬀered the right (but
without obligation) to buy one unit of the risky asset at a speciﬁed price
K and at a speciﬁed future time t = T. Such a right is called a European
call option. How much should the person be willing to pay for such an op-
tion? This problem was solved when Fischer Black and Myron Scholes (1973)
used stochastic analysis and an equlibrium argument to compute a theo-
retical value for the price, the now famous Black and Scholes option price
formula. This theoretical value agreed well with the prices that had already
been established as an equilibrium price on the free market. Thus it repre-
sented a triumph for mathematical modelling in ﬁnance. It has become an
indispensable tool in the trading of options and other ﬁnancial derivatives.
In 1997 Myron Scholes and Robert Merton were awarded the Nobel Prize

1.6 Mathematical Finance
5
in Economics for their work related to this formula. (Fischer Black died in
1995.)
We will return to these problems in later chapters, after having developed
the necessary mathematical machinery. We solve Problem 1 and Problem 2
in Chapter 5. Problems involving ﬁltering (Problem 3) are treated in Chap-
ter 6, the generalized Dirichlet problem (Problem 4) in Chapter 9. Problem 5
is solved in Chapter 10 while stochastic control problems (Problem 6) are dis-
cussed in Chapter 11. Finally we discuss applications to mathematical ﬁnance
in Chapter 12.

6
1. Introduction

2. Some Mathematical Preliminaries
2.1 Probability Spaces, Random Variables and
Stochastic Processes
Having stated the problems we would like to solve, we now proceed to ﬁnd
reasonable mathematical notions corresponding to the quantities mentioned
and mathematical models for the problems. In short, here is a ﬁrst list of the
notions that need a mathematical interpretation:
(1) A random quantity
(2) Independence
(3) Parametrized (discrete or continuous) families of random quantities
(4) What is meant by a “best” estimate in the ﬁltering problem (Problem 3)
(5) What is meant by an estimate “based on” some observations (Prob-
lem 3)?
(6) What is the mathematical interpretation of the “noise” terms?
(7) What is the mathematical interpretation of the stochastic diﬀerential
equations?
In this chapter we will discuss (1)–(3) brieﬂy. In the next chapter we will
consider (6), which leads to the notion of an Itˆo stochastic integral (7). In
Chapter 6 we will consider (4)–(5).
The mathematical model for a random quantity is a random variable.
Before we deﬁne this, we recall some concepts from general probability theory.
The reader is referred to e.g. Williams (1991) for more information.
Deﬁnition 2.1.1. If Ωis a given set, then a σ-algebra F on Ωis a family
F of subsets of Ωwith the following properties:
(i)
∅∈F
(ii) F ∈F ⇒F C ∈F, where F C = Ω\ F is the complement of F in Ω
(iii) A1, A2, . . . ∈F ⇒A: =
∞
S
i=1
Ai ∈F
The pair (Ω, F) is called a measurable space. A probability measure P
on a measurable space (Ω, F) is a function P: F −→[0, 1] such that
(a) P(∅) = 0, P(Ω) = 1

8
2. Some Mathematical Preliminaries
(b) if A1, A2, . . . ∈F and {Ai}∞
i=1 is disjoint (i.e. Ai ∩Aj = ∅if i ̸= j) then
P
Ã ∞
[
i=1
Ai
!
=
∞
X
i=1
P(Ai) .
The triple (Ω, F, P) is called a probability space. It is called a complete
probability space if F contains all subsets G of Ωwith P-outer measure zero,
i.e. with
P ∗(G): = inf{P(F); F ∈F, G ⊂F} = 0 .
Any probability space can be made complete simply by adding to F all
sets of outer measure 0 and by extending P accordingly.
The subsets F of Ωwhich belong to F are called F-measurable sets. In a
probability context these sets are called events and we use the interpretation
P(F) = “the probability that the event F occurs” .
In particular, if P(F) = 1 we say that “F occurs with probability 1”, or
“almost surely (a.s.)”.
Given any family U of subsets of Ωthere is a smallest σ-algebra HU
containing U, namely
HU =
\
{H; H σ-algebra of Ω, U ⊂H} .
(See Exercise 2.3.)
We call HU the σ-algebra generated by U.
For example, if U is the collection of all open subsets of a topological
space Ω(e.g. Ω= Rn), then B = HU is called the Borel σ-algebra on Ωand
the elements B ∈B are called Borel sets. B contains all open sets, all closed
sets, all countable unions of closed sets, all countable intersections of such
countable unions etc.
If (Ω, F, P) is a given probability space, then a function Y : Ω→Rn is
called F-measurable if
Y −1(U): = {ω ∈Ω; Y (ω) ∈U} ∈F
for all open sets U ∈Rn (or, equivalently, for all Borel sets U ⊂Rn).
If X: Ω→Rn is any function, then the σ-algebra HX generated by X is
the smallest σ-algebra on Ωcontaining all the sets
X−1(U) ;
U ⊂Rn open .
It is not hard to show that
HX = {X−1(B); B ∈B} ,
where B is the Borel σ-algebra on Rn. Clearly, X will then be HX-measurable
and HX is the smallest σ-algebra with this property.
The following result is useful. It is a special case of a result sometimes
called the Doob-Dynkin lemma. See e.g. M. M. Rao (1984), Prop. 3, p. 7.

2.1 Probability Spaces, Random Variables and Stochastic Processes
9
Lemma 2.1.2. If X, Y : Ω→Rn are two given functions,then Y is HX-
measurable if and only if there exists a Borel measurable function g: Rn →Rn
such that
Y = g(X) .
In the following we let (Ω, F, P) denote a given complete probability
space. A random variable X is an F-measurable function X: Ω→Rn. Every
random variable induces a probability measure µX on Rn, deﬁned by
µX(B) = P(X−1(B)) .
µX is called the distribution of X.
If
R
Ω
|X(ω)|dP(ω) < ∞then the number
E[X]: =
Z
Ω
X(ω)dP(ω) =
Z
Rn
xdµX(x)
is called the expectation of X (w.r.t. P).
More generally, if f: Rn →R is Borel measurable and
R
Ω
|f(X(ω))|dP(ω) < ∞then we have
E[f(X)]: =
Z
Ω
f(X(ω))dP(ω) =
Z
Rn
f(x)dµX(x) .
The mathematical model for independence is the following:
Deﬁnition 2.1.3. Two subsets A, B ∈F are called independent if
P(A ∩B) = P(A) · P(B) .
A collection A = {Hi; i ∈I} of families Hi of measurable sets is independent
if
P(Hi1 ∩· · · ∩Hik) = P(Hi1) · · · P(Hik)
for all choices of Hi1 ∈Hi1, · · · , Hik ∈Hik with diﬀerent indices i1, . . . , ik.
A collection of random variables {Xi; i ∈I} is independent if the collec-
tion of generated σ-algebras HXi is independent.
If two random variables X, Y : Ω→R are independent then
E[XY ] = E[X]E[Y ] ,
provided that E[|X|] < ∞and E[|Y |] < ∞. (See Exercise 2.5.)
Deﬁnition 2.1.4. A stochastic process is a parametrized collection of ran-
dom variables
{Xt}t∈T
deﬁned on a probability space (Ω, F, P) and assuming values in Rn.

10
2. Some Mathematical Preliminaries
The parameter space T is usually (as in this book) the halﬂine [0, ∞), but
it may also be an interval [a, b], the non-negative integers and even subsets
of Rn for n ≥1. Note that for each t ∈T ﬁxed we have a random variable
ω →Xt(ω) ;
ω ∈Ω.
On the other hand, ﬁxing ω ∈Ωwe can consider the function
t →Xt(ω) ;
t ∈T
which is called a path of Xt.
It may be useful for the intuition to think of t as “time” and each ω
as an individual “particle” or “experiment”. With this picture Xt(ω) would
represent the position (or result) at time t of the particle (experiment) ω.
Sometimes it is convenient to write X(t, ω) instead of Xt(ω). Thus we may
also regard the process as a function of two variables
(t, ω) →X(t, ω)
from T × Ωinto Rn. This is often a natural point of view in stochastic
analysis, because (as we shall see) there it is crucial to have X(t, ω) jointly
measurable in (t, ω).
Finally we note that we may identify each ω with the function t →Xt(ω)
from T into Rn. Thus we may regard Ωas a subset of the space eΩ= (Rn)T of
all functions from T into Rn. Then the σ-algebra F will contain the σ-algebra
B generated by sets of the form
{ω; ω(t1) ∈F1, · · · , ω(tk) ∈Fk} ,
Fi ⊂Rn Borel sets
(B is the same as the Borel σ-algebra on eΩif T = [0, ∞) and eΩis given
the product topology). Therefore one may also adopt the point of view
that a stochastic process is a probability measure P on the measurable space
((Rn)T , B).
The (ﬁnite-dimensional) distributions of the process X = {Xt}t∈T are
the measures µt1,...,tk deﬁned on Rnk, k = 1, 2, . . ., by
µt1,...,tk(F1 × F2 × · · · × Fk) = P[Xt1 ∈F1, · · · , Xtk ∈Fk] ;
ti ∈T .
Here F1, . . . , Fk denote Borel sets in Rn.
The family of all ﬁnite-dimensional distributions determine many (but
not all) important properties of the process X.
Conversely, given a family {νt1,...,tk; k ∈N, ti ∈T} of probability mea-
sures on Rnk it is important to be able to construct a stochastic process
Y
= {Yt}t∈T having νt1,...,tk as its ﬁnite-dimensional distributions. One
of Kolmogorov’s famous theorems states that this can be done provided
{νt1,...,tk} satisﬁes two natural consistency conditions: (See Lamperti (1977).)

2.2 An Important Example: Brownian Motion
11
Theorem 2.1.5 (Kolmogorov’s extension theorem).
For all t1, . . . , tk ∈T, k ∈N let νt1,...,tk be probability measures on Rnk s.t.
νtσ(1),···,tσ(k)(F1 × · · · × Fk) = νt1,···,tk(Fσ−1(1) × · · · × Fσ−1(k))
(K1)
for all permutations σ on {1, 2, . . . , k} and
νt1,...,tk(F1×· · ·×Fk) = νt1,...,tk,tk+1,...,tk+m(F1×· · ·×Fk×Rn×· · ·×Rn)
(K2)
for all m ∈N, where (of course) the set on the right hand side has a total of
k + m factors.
Then there exists a probability space (Ω, F, P) and a stochastic process
{Xt} on Ω, Xt: Ω→Rn, s.t.
νt1,...,tk(F1 × · · · × Fk) = P[Xt1 ∈F1, · · · , Xtk ∈Fk] ,
for all ti ∈T, k ∈N and all Borel sets Fi.
2.2 An Important Example: Brownian Motion
In 1828 the Scottish botanist Robert Brown observed that pollen grains sus-
pended in liquid performed an irregular motion. The motion was later ex-
plained by the random collisions with the molecules of the liquid. To describe
the motion mathematically it is natural to use the concept of a stochastic
process Bt(ω), interpreted as the position at time t of the pollen grain ω. We
will generalize slightly and consider an n-dimensional analog.
To construct {Bt}t≥0 it suﬃces, by the Kolmogorov extension theorem, to
specify a family {νt1,...,tk} of probability measures satisfying (K1) and (K2).
These measures will be chosen so that they agree with our observations of
the pollen grain behaviour:
Fix x ∈Rn and deﬁne
p(t, x, y) = (2πt)−n/2 · exp(−|x −y|2
2t
)
for y ∈Rn, t > 0 .
If 0 ≤t1 ≤t2 ≤· · · ≤tk deﬁne a measure νt1,...,tk on Rnk by
νt1,...,tk(F1 × · · · × Fk) =
(2.2.1)
=
Z
F1×···×Fk
p(t1, x, x1)p(t2−t1, x1, x2) · · · p(tk−tk−1, xk−1, xk)dx1 · · · dxk
where we use the notation dy = dy1 · · · dyk for Lebesgue measure and the
convention that p(0, x, y)dy = δx(y), the unit point mass at x.
Extend this deﬁnition to all ﬁnite sequences of ti’s by using (K1). Since
R
Rn p(t, x, y)dy = 1 for all t ≥0, (K2) holds, so by Kolmogorov’s theorem

12
2. Some Mathematical Preliminaries
there exists a probability space (Ω, F, P x) and a stochastic process {Bt}t≥0
on Ωsuch that the ﬁnite-dimensional distributions of Bt are given by (2.2.1),
i.e.
P x(Bt1 ∈F1, · · · , Btk ∈Fk) =
=
Z
F1×···×Fk
p(t1, x, x1) · · · p(tk −tk−1, xk−1, xk)dx1 . . . dxk .
(2.2.2)
Deﬁnition 2.2.1. Such a process is called (a version of) Brownian motion
starting at x (observe that P x(B0 = x) = 1).
The Brownian motion thus deﬁned is not unique, i.e. there exist several
quadruples (Bt, Ω, F, P x) such that (2.2.2) holds. However, for our purposes
this is not important, we may simply choose any version to work with. As we
shall soon see, the paths of a Brownian motion are (or, more correctly, can be
chosen to be) continuous, a.s. Therefore we may identify (a.a.) ω ∈Ωwith a
continuous function t →Bt(ω) from [0, ∞) into Rn. Thus we may adopt the
point of view that Brownian motion is just the space C([0, ∞), Rn) equipped
with certain probability measures P x (given by (2.2.1) and (2.2.2) above).
This version is called the canonical Brownian motion. Besides having the
advantage of being intuitive, this point of view is useful for the further anal-
ysis of measures on C([0, ∞), Rn), since this space is Polish (i.e. a complete
separable metric space). See Stroock and Varadhan (1979).
We state some basic properties of Brownian motion:
(i)
Bt is a Gaussian process, i.e. for all 0 ≤t1 ≤· · · ≤tk the random variable
Z = (Bt1, . . . , Btk) ∈Rnk has a (multi)normal distribution. This means
that there exists a vector M ∈Rnk and a non-negative deﬁnite matrix
C = [cjm] ∈Rnk×nk (the set of all nk × nk-matrices with real entries)
such that
Exh
exp
µ
i
nk
X
j=1
ujZj
¶i
= exp
µ
−1
2
X
j,m
ujcjmum +i
X
j
ujMj
¶
(2.2.3)
for all u = (u1, . . . , unk) ∈Rnk, where i = √−1 is the imaginary unit
and Ex denotes expectation with respect to P x. Moreover, if (2.2.3)
holds then
M = Ex[Z]
is the mean value of Z
(2.2.4)
and
cjm = Ex[(Zj −Mj)(Zm −Mm)]
is the covariance matrix of Z .
(2.2.5)
(See Appendix A).
To see that (2.2.3) holds for Z = (Bt1, . . . , Btk) we calculate its left hand
side explicitly by using (2.2.2) (see Appendix A) and obtain (2.2.3) with

2.2 An Important Example: Brownian Motion
13
M = Ex[Z] = (x, x, · · · , x) ∈Rnk
(2.2.6)
and
C =












t1In
t1In
· · ·
t1In
t1In
t2In
· · ·
t2In
...
...
...
t1In
t2In
· · ·
tkIn












.
(2.2.7)
Hence
Ex[Bt] = x
for all t ≥0
(2.2.8)
and
Ex[(Bt −x)2] = nt, Ex[(Bt −x)(Bs −x)] = n min(s, t) .
(2.2.9)
Moreover,
Ex[(Bt −Bs)2] = n(t −s) if t ≥s ,
(2.2.10)
since
Ex[(Bt −Bs)2] = Ex[(Bt −x)2 −2(Bt −x)(Bs −x) + (Bs −x)2]
= n(t −2s + s) = n(t −s), when t ≥s .
(ii) Bt has independent increments, i.e.
Bt1, Bt2 −Bt1, · · · , Btk −Btk−1 are independent
for all 0 ≤t1 < t2 · · · < tk .
(2.2.11)
To prove this we use the fact that normal random variables are inde-
pendent iﬀthey are uncorrelated. (See Appendix A). So it is enough to
prove that
Ex[(Bti −Bti−1)(Btj −Btj−1)] = 0
when ti < tj ,
(2.2.12)
which follows from the form of C:
Ex[BtiBtj −Bti−1Btj −BtiBtj−1 + Bti−1Btj−1]
= n(ti −ti−1 −ti + ti−1) = 0 .
From this we deduce that Bs −Bt is independent of Ft if s > t.
(iii) Finally we ask: Is t →Bt(ω) continuous for almost all ω? Stated like this
the question does not make sense, because the set H = {ω; t →Bt(ω)
is continuous} is not measurable with respect to the Borel σ-algebra B
on (Rn)[0,∞) mentioned above (H involves an uncountable number of
t’s). However, if modiﬁed slightly the question can be given a positive
answer. To explain this we need the following important concept:

14
2. Some Mathematical Preliminaries
Deﬁnition 2.2.2. Suppose that {Xt} and {Yt} are stochastic processes on
(Ω, F, P). Then we say that {Xt} is a version of (or a modiﬁcation of) {Yt}
if
P({ω; Xt(ω) = Yt(ω)}) = 1
for all t .
Note that if Xt is a version of Yt, then Xt and Yt have the same ﬁnite-
dimensional distributions. Thus from the point of view that a stochastic pro-
cess is a probability law on (Rn)[0,∞) two such processes are the same, but
nevertheless their path properties may be diﬀerent. (See Exercise 2.9.)
The continuity question of Brownian motion can be answered by using
another famous theorem of Kolmogorov:
Theorem 2.2.3 (Kolmogorov’s continuity theorem). Suppose that the
process X = {Xt}t≥0 satisﬁes the following condition: For all T > 0 there
exist positive constants α, β, D such that
E[|Xt −Xs|α] ≤D · |t −s|1+β ;
0 ≤s, t ≤T .
(2.2.13)
Then there exists a continuous version of X.
For a proof see for example Stroock and Varadhan (1979, p. 51).
For Brownian motion Bt it is not hard to prove that (See Exercise 2.8)
Ex[|Bt −Bs|4] = n(n + 2)|t −s|2 .
(2.2.14)
So Brownian motion satisﬁes Kolmogorov’s condition (2.2.13) with α = 4,
D = n(n+2) and β = 1, and therefore it has a continuous version. From now
on we will assume that Bt is such a continuous version.
Finally we note that
If Bt =(B(1)
t
, · · · , B(n)
t
) is n-dimensional Brownian motion, then
the 1-dimensional processes {B(j)
t }t≥0, 1≤j ≤n are independent,
1-dimensional Brownian motions .
(2.2.15)
Exercises
2.1.
Suppose that X: Ω→R is a function which assumes only countably
many values a1, a2, . . . ∈R.
a) Show that X is a random variable if and only if
X−1(ak) ∈F
for all k = 1, 2, . . .
(2.2.16)
b) Suppose (2.2.16) holds. Show that
E[|X|] =
∞
X
k=1
|ak|P[X = ak] .
(2.2.17)

Exercises
15
c) If (2.2.16) holds and E[|X|] < ∞, show that
E[X] =
∞
X
k=1
akP[X = ak] .
d) If (2.2.16) holds and f: R →R is measurable and bounded, show
that
E[f(X)] =
∞
X
k=1
f(ak)P[X = ak] .
2.2.
Let X: Ω→R be a random variable. The distribution function F of
X is deﬁned by
F(x) = P[X ≤x] .
a) Prove that F has the following properties:
(i) 0 ≤F ≤1,
lim
x→−∞F(x) = 0, lim
x→∞F(x) = 1 .
(ii) F is increasing (= non-decreasing).
(iii) F is right-continuous, i.e. F(x) = lim h→0
h>0 F(x + h) .
b) Let g: R →R be measurable such that E[|g(X)|] < ∞. Prove that
E[g(X)] =
∞
Z
−∞
g(x)dF(x) ,
where the integral on the right is interpreted in the Lebesgue-
Stieltjes sense.
c) Let p(x) ≥0 be a measurable function on R. We say that X has
the density p if
F(x) =
x
Z
−∞
p(y)dy
for all x .
Thus from (2.2.1)–(2.2.2) we know that 1-dimensional Brownian
motion Bt at time t with B0 = 0 has the density
p(x) =
1
√
2πt exp(−x2
2t ); x ∈R .
Find the density of B2
t .
2.3.
Let {Hi}i∈I be a family of σ-algebras on Ω. Prove that
H =
\
{Hi; i ∈I}
is again a σ-algebra.

16
2. Some Mathematical Preliminaries
2.4.
a) Let X: Ω→Rn be a random variable such that
E[|X|p] < ∞
for some p, 0 < p < ∞.
Prove Chebychev’s inequality:
P[|X| ≥λ] ≤1
λp E[|X|p]
for all λ ≥0 .
Hint:
R
Ω
|X|pdP ≥
R
A
|X|pdP, where A = {ω: |X| ≥λ} .
b) Suppose there exists k > 0 such that
M = E[exp(k|X|)] < ∞.
Prove that P[|X| ≥λ] ≤Me−kλ for all λ ≥0 .
2.5.
Let X, Y : Ω→R be two independent random variables and assume
for simplicity that X and Y are bounded. Prove that
E[XY ] = E[X]E[Y ] .
³
Hint: Assume |X| ≤M, |Y | ≤N. Approximate X and Y by sim-
ple functions ϕ(ω) =
m
P
i=1
aiXFi(ω), ψ(ω) =
nP
j=1
bjXGj(ω), respectively,
where Fi = X−1([ai, ai+1)), Gj = Y −1([bj, bj+1)), −M = a0 < a1 <
. . . < am = M, −N = b0 < b1 < . . . < bn = N. Then
E[X] ≈E[ϕ] =
X
i
aiP(Fi),
E[Y ] ≈E[ψ] =
X
j
bjP(Gj)
and
E[XY ] ≈E[ϕψ] =
X
i,j
aibjP(Fi ∩Gj) . . .
´
.
2.6.
Let (Ω, F, P) be a probability space and let A1, A2, . . . be sets in F
such that
∞
X
k=1
P(Ak) < ∞.
Prove the Borel-Cantelli lemma:
P(
∞
\
m=1
∞
[
k=m
Ak) = 0 ,
i.e. the probability that ω belongs to inﬁnitely many A′
ks is zero.

Exercises
17
2.7.
a) Suppose G1, G2, . . . , Gn are disjoint subsets of Ωsuch that
Ω=
n
[
i=1
Gi .
Prove that the family G consisting of ∅and all unions of some (or
all) of G1, . . . , Gn constitutes a σ-algebra on Ω.
b) Prove that any ﬁnite σ-algebra F on Ωis of the type described in
a).
c) Let F be a ﬁnite σ-algebra on Ωand let X: Ω→R be F-
measurable. Prove that X assumes only ﬁnitely many possible
values. More precisely, there exists a disjoint family of subsets
F1, . . . , Fm ∈F and real numbers c1, . . . , cm such that
X(ω) =
m
X
i=1
ciXFi(ω) .
2.8.
Let Bt be Brownian motion on R, B0 = 0. Put E = E0.
a) Use (2.2.3) to prove that
E[eiuBt] = exp(−1
2u2t)
for all u ∈R .
b) Use the power series expansion of the exponential function on both
sides, compare the terms with the same power of u and deduce that
E[B4
t ] = 3t2
and more generally that
E
£
B2k
t
¤
= (2k)!
2k · k!tk ;
k ∈N .
c) If you feel uneasy about the lack of rigour in the method in b), you
can proceed as follows: Prove that (2.2.2) implies that
E[f(Bt)] =
1
√
2πt
Z
R
f(x)e
−x2
2t dx
for all functions f such that the integral on the right converges.
Then apply this to f(x) = x2k and use integration by parts and
induction on k.
d) Prove (2.2.14), for example by using b) and induction on n.
2.9.
To illustrate that the (ﬁnite-dimensional) distributions alone do not
give all the information regarding the continuity properties of a pro-
cess, consider the following example:

18
2. Some Mathematical Preliminaries
Let (Ω, F, P) = ([0, ∞), B, µ) where B denotes the Borel σ-algebra on
[0, ∞) and µ is a probability measure on [0, ∞) with no mass on single
points. Deﬁne
Xt(ω) =
n 1
if t = ω
0
otherwise
and
Yt(ω) = 0
for all (t, ω) ∈[0, ∞) × [0, ∞) .
Prove that {Xt} and {Yt} have the same distributions and that Xt is
a version of Yt. And yet we have that t →Yt(ω) is continuous for all
ω, while t →Xt(ω) is discontinuous for all ω.
2.10. A stochastic process Xt is called stationary if {Xt} has the same dis-
tribution as {Xt+h} for any h > 0. Prove that Brownian motion Bt
has stationary increments, i.e. that the process {Bt+h −Bt}h≥0 has
the same distribution for all t.
2.11. Prove (2.2.15).
2.12. Let Bt be Brownian motion and ﬁx t0 ≥0. Prove that
eBt: = Bt0+t −Bt0 ;
t ≥0
is a Brownian motion.
2.13. Let Bt be 2-dimensional Brownian motion and put
Dρ = {x ∈R2; |x| < ρ}
for ρ > 0 .
Compute
P 0[Bt ∈Dρ] .
2.14. Let Bt be n-dimensional Brownian motion and let K ⊂Rn have zero
n-dimensional Lebesgue measure. Prove that the expected total length
of time that Bt spends in K is zero. (This implies that the Green
measure associated with Bt is absolutely continuous with respect to
Lebesgue measure. See Chapter 9).
2.15. Let Bt be n-dimensional Brownian motion starting at 0 and let
U ∈Rn×n be a (constant) orthogonal matrix, i.e. UU T =I. Prove that
eBt: = UBt
is also a Brownian motion.
2.16. (Brownian scaling). Let Bt be a 1-dimensional Brownian motion
and let c > 0 be a constant. Prove that
bBt: = 1
c Bc2t
is also a Brownian motion.

Exercises
19
2.17. If Xt(·): Ω→R is a continuous stochastic process, then for p > 0 the
p’th variation process of Xt, ⟨X, X⟩(p)
t
is deﬁned by
⟨X, X⟩(p)
t (ω) = lim
∆tk→0
X
tk≤t
¯¯Xtk+1(ω)−Xtk(ω)
¯¯p (limit in probability)
where 0 = t1 < t2 < . . . < tn = t and ∆tk = tk+1 −tk. In particular,
if p = 1 this process is called the total variation process and if p = 2
this is called the quadratic variation process. (See Exercise 4.7.) For
Brownian motion Bt ∈R we now show that the quadratic variation
process is simply
⟨B, B⟩t(ω) = ⟨B, B⟩(2)
t (ω) = t
a.s.
Proceed as follows:
a) Deﬁne
∆Bk = Btk+1 −Btk
and put
Y (t, ω) =
X
tk≤t
(∆Bk(ω))2 ,
Show that
E[(
X
tk≤t
(∆Bk)2 −t)2] = 2
X
tk≤t
(∆tk)2
and deduce that Y (t, ·) →t in L2(P) as ∆tk →∞.
b) Use a) to prove that a.a. paths of Brownian motion do not have
a bounded variation on [0, t], i.e. the total variation of Brownian
motion is inﬁnite, a.s.

20
2. Some Mathematical Preliminaries

3. Itˆo Integrals
3.1 Construction of the Itˆo Integral
We now turn to the question of ﬁnding a reasonable mathematical interpre-
tation of the “noise” term in the equation of Problem 1 in the Introduction:
dN
dt = (r(t) + “noise”)N(t)
or more generally in equations of the form
dX
dt = b(t, Xt) + σ(t, Xt) · “noise” ,
(3.1.1)
where b and σ are some given functions. Let us ﬁrst concentrate on the case
when the noise is 1-dimensional. It is reasonable to look for some stochastic
process Wt to represent the noise term, so that
dX
dt = b(t, Xt) + σ(t, Xt) · Wt .
(3.1.2)
Based on many situations, for example in engineering, one is led to assume
that Wt has, at least approximately, these properties:
(i)
t1 ̸= t2 ⇒Wt1 and Wt2 are independent.
(ii) {Wt} is stationary, i.e. the (joint) distribution of {Wt1+t, . . . , Wtk+t}
does not depend on t.
(iii) E[Wt] = 0 for all t.
However, it turns out there does not exist any “reasonable” stochastic
process satisfying (i) and (ii): Such a Wt cannot have continuous paths. (See
Exercise 3.11.) If we require E[W 2
t ] = 1 then the function (t, ω) →Wt(ω)
cannot even be measurable, with respect to the σ-algebra B × F, where B is
the Borel σ-algebra on [0, ∞]. (See Kallianpur (1980, p. 10).)
Nevertheless it is possible to represent Wt as a generalized stochastic
process called the white noise process.
That the process is generalized means that it can be constructed as a
probability measure on the space S′ of tempered distributions on [0, ∞),
and not as a probability measure on the much smaller space R[0,∞), like an

22
3. Itˆo Integrals
ordinary process can. See e.g. Hida (1980), Adler (1981), Rozanov (1982),
Hida, Kuo, Potthoﬀand Streit (1993) or Holden, Øksendal, Ubøe and Zhang
(1996).
We will avoid this kind of construction and rather try to rewrite equation
(3.1.2) in a form that suggests a replacement of Wt by a proper stochastic
process: Let 0 = t0 < t1 < · · · < tm = t and consider a discrete version of
(3.1.2):
Xk+1 −Xk = b(tk, Xk)∆tk + σ(tk, Xk)Wk∆tk ,
(3.1.3)
where
Xj = X(tj),
Wk = Wtk,
∆tk = tk+1 −tk .
We abandon the Wk-notation and replace Wk∆tk by ∆Vk = Vtk+1 −Vtk,
where {Vt}t≥0 is some suitable stochastic process. The assumptions (i), (ii)
and (iii) on Wt suggest that Vt should have stationary independent increments
with mean 0. It turns out that the only such process with continuous paths
is the Brownian motion Bt. (See Knight (1981)). Thus we put Vt = Bt and
obtain from (3.1.3):
Xk = X0 +
k−1
X
j=0
b(tj, Xj)∆tj +
k−1
X
j=0
σ(tj, Xj)∆Bj .
(3.1.4)
Is it possible to prove that the limit of the right hand side of (3.1.4) exists,
in some sense, when ∆tj →0? If so, then by applying the usual integration
notation we should obtain
Xt = X0 +
t
Z
0
b(s, Xs)ds + “
t
Z
0
σ(s, Xs)dBs”
(3.1.5)
and we would adopt as a convention that (3.1.2) really means that Xt =
Xt(ω) is a stochastic process satisfying (3.1.5).
Thus, in the remainder of this chapter we will prove the existence, in a
certain sense, of
“
t
Z
0
f(s, ω)dBs(ω)”
where Bt(ω) is 1-dimensional Brownian motion starting at the origin, for a
wide class of functions f: [0, ∞]×Ω→R. Then, in Chapter 5, we will return
to the solution of (3.1.5).
Suppose 0 ≤S < T and f(t, ω) is given. We want to deﬁne
T
Z
S
f(t, ω)dBt(ω) .
(3.1.6)

3.1 Construction of the Itˆo Integral
23
It is reasonable to start with a deﬁnition for a simple class of functions f
and then extend by some approximation procedure. Thus, let us ﬁrst assume
that f has the form
φ(t, ω) =
X
j≥0
ej(ω) · X[j·2−n,(j+1)2−n)(t) ,
(3.1.7)
where X denotes the characteristic (indicator) function and n is a natural
number. For such functions it is reasonable to deﬁne
T
Z
S
φ(t, ω)dBt(ω) =
X
j≥0
ej(ω)[Btj+1 −Btj](ω) ,
(3.1.8)
where
tk = t(n)
k
=



k · 2−n
if
S ≤k · 2−n ≤T
S
if
k · 2−n < S
T
if
k · 2−n > T



However, without any further assumptions on the functions ej(ω) this leads
to diﬃculties, as the next example shows.
Here – and in the following – E means the same as E0, the expectation
w.r.t. the law P 0 for Brownian motion starting at 0. And P means the same
as P 0.
Example 3.1.1. Choose
φ1(t, ω) =
X
j≥0
Bj·2−n(ω) · X[j·2−n,(j+1)2−n)(t)
φ2(t, ω) =
X
j≥0
B(j+1)2−n(ω) · X[j·2−n,(j+1)2−n)(t) .
Then
E
·
T
Z
0
φ1(t, ω)dBt(ω)
¸
=
X
j≥0
E[Btj(Btj+1 −Btj)] = 0 ,
since {Bt} has independent increments. But
E
·
T
Z
0
φ2(t, ω)dBt(ω)
¸
=
X
j≥0
E[Btj+1 · (Btj+1 −Btj)]
=
X
j≥0
E[(Btj+1 −Btj)2] = T ,
by (2.2.10) .
So, in spite of the fact that both φ1 and φ2 appear to be very reasonable
approximations to

24
3. Itˆo Integrals
f(t, ω) = Bt(ω) ,
their integrals according to (3.1.8) are not close to each other at all, no matter
how large n is chosen.
This only reﬂects the fact that the variations of the paths of Bt are too
big to enable us to deﬁne the integral (3.1.6) in the Riemann-Stieltjes sense.
In fact, one can show that the paths t →Bt of Brownian motion are nowhere
diﬀerentiable, almost surely (a.s.). (See Breiman (1968)). In particular, the
total variation of the path is inﬁnite, a.s.
In general it is natural to approximate a given function f(t, ω) by
X
j
f(t∗
j, ω) · X[tj,tj+1)(t)
where the points t∗
j belong to the intervals [tj, tj+1], and then deﬁne
TR
S
f(t, ω)dBt(ω) as the limit (in a sense that we will explain) of
P
j
f(t∗
j, ω)[Btj+1 −Btj](ω) as n →∞. However, the example above shows
that – unlike the Riemann-Stieltjes integral – it does make a diﬀerence here
what points t∗
j we choose. The following two choices have turned out to be
the most useful ones:
1) t∗
j = tj (the left end point), which leads to the Itˆo integral, from now on
denoted by
T
Z
S
f(t, ω)dBt(ω) ,
and
2) t∗
j = (tj+tj+1)/2 (the mid point), which leads to the Stratonovich integral,
denoted by
T
Z
S
f(t, ω) ◦dBt(ω) .
(See Protter (1990, Th. V. 5.30)).
In the end of this chapter we will explain why these choices are the best
and discuss the relations and distinctions between the corresponding inte-
grals.
In any case one must restrict oneself to a special class of functions f(t, ω)
in (3.1.6), also if they have the particular form (3.1.7), in order to obtain
a reasonable deﬁnition of the integral. We will here present Itˆo’s choice
t∗
j = tj. The approximation procedure indicated above will work out success-
fully provided that f has the property that each of the functions ω →f(tj, ω)
only depends on the behaviour of Bs(ω) up to time tj. This leads to the fol-
lowing important concepts:

3.1 Construction of the Itˆo Integral
25
Deﬁnition 3.1.2. Let Bt(ω) be n-dimensional Brownian motion. Then we
deﬁne Ft = F(n)
t
to be the σ-algebra generated by the random variables Bs(·);
s ≤t. In other words, Ft is the smallest σ-algebra containing all sets of the
form
{ω; Bt1(ω) ∈F1, · · · , Btk(ω) ∈Fk} ,
where tj ≤t and Fj ⊂Rn are Borel sets, j ≤k = 1, 2, . . . (We assume that
all sets of measure zero are included in Ft).
One often thinks of Ft as “the history of Bs up to time t”. A function
h(ω) will be Ft-measurable if and only if h can be written as the pointwise
a.e. limit of sums of functions of the form
g1(Bt1)g2(Bt2) · · · gk(Btk) ,
where g1, . . . , gk are bounded continuous functions and tj ≤t for j ≤k,
k = 1, 2, . . . . (See Exercise 3.14.) Intuitively, that h is Ft-measurable means
that the value of h(ω) can be decided from the values of Bs(ω) for s ≤t. For
example, h1(ω) = Bt/2(ω) is Ft-measurable, while h2(ω) = B2t(ω) is not.
Note that Fs ⊂Ft for s < t (i.e. {Ft} is increasing) and that Ft ⊂F for
all t.
Deﬁnition 3.1.3. Let {Nt}t≥0 be an increasing family of σ-algebras of sub-
sets of Ω. A process g(t, ω): [0, ∞)×Ω→Rn is called Nt-adapted if for each
t ≥0 the function
ω →g(t, ω)
is Nt-measurable.
Thus the process h1(t, ω) = Bt/2(ω) is Ft-adapted, while h2(t, ω) =
B2t(ω) is not.
We now describe our class of functions for which the Itˆo integral will be
deﬁned:
Deﬁnition 3.1.4. Let V = V(S, T) be the class of functions
f(t, ω): [0, ∞) × Ω→R
such that
(i)
(t, ω) →f(t, ω) is B × F-measurable, where B denotes the Borel σ-
algebra on [0, ∞).
(ii)
f(t, ω) is Ft-adapted.
(iii) E
£ TR
S
f(t, ω)2dt
¤
< ∞.

26
3. Itˆo Integrals
The Itˆo Integral
For functions f ∈V we will now show how to deﬁne the Itˆo integral
I[f](ω) =
T
Z
S
f(t, ω)dBt(ω) ,
where Bt is 1-dimensional Brownian motion.
The idea is natural: First we deﬁne I[φ] for a simple class of functions
φ. Then we show that each f ∈V can be approximated (in an appropriate
sense) by such φ’s and we use this to deﬁne
R
fdB as the limit of
R
φdB as
φ →f.
We now give the details of this construction: A function φ ∈V is called
elementary if it has the form
φ(t, ω) =
X
j
ej(ω) · X[tj,tj+1)(t) .
(3.1.9)
Note that since φ ∈V each function ej must be Ftj-measurable. Thus in
Example 3.1.1 above the function φ1 is elementary while φ2 is not.
For elementary functions φ(t, ω) we deﬁne the integral according to
(3.1.8), i.e.
T
Z
S
φ(t, ω)dBt(ω) =
X
j≥0
ej(ω)[Btj+1 −Btj](ω) .
(3.1.10)
Now we make the following important observation:
Lemma 3.1.5 (The Itˆo isometry). If φ(t, ω) is bounded and elementary
then
E
·µ
T
Z
S
φ(t, ω)dBt(ω)
¶2¸
= E
·
T
Z
S
φ(t, ω)2dt
¸
.
(3.1.11)
Proof. Put ∆Bj = Btj+1 −Btj. Then
E[eiej∆Bi∆Bj] =
½
0
if
i ̸= j
E[e2
j] · (tj+1 −tj)
if
i = j
using that eiej∆Bi and ∆Bj are independent if i < j. Thus
E
·µ
T
Z
S
φdB
¶2¸
=
X
i,j
E[eiej∆Bi∆Bj] =
X
j
E[e2
j] · (tj+1 −tj)
= E
·
T
Z
S
φ2dt
¸
.

3.1 Construction of the Itˆo Integral
27
The idea is now to use the isometry (3.1.11) to extend the deﬁnition from
elementary functions to functions in V. We do this in several steps:
Step 1. Let g ∈V be bounded and g(·, ω) continuous for each ω. Then there
exist elementary functions φn ∈V such that
E
·
T
Z
S
(g −φn)2dt
¸
→0
as n →∞.
Proof. Deﬁne φn(t, ω) = P
j
g(tj, ω)·X[tj,tj+1)(t). Then φn is elementary since
g ∈V, and
T
Z
S
(g −φn)2dt →0
as n →∞, for each ω ,
since g(·, ω) is continuous for each ω. Hence E[
TR
S
(g −φn)2dt] →0 as n →∞,
by bounded convergence.
Step 2. Let h ∈V be bounded. Then there exist bounded functions gn ∈V
such that gn(·, ω) is continuous for all ω and n, and
E
·
T
Z
S
(h −gn)2dt
¸
→0 .
Proof. Suppose |h(t, ω)| ≤M for all (t, ω). For each n let ψn be a non-
negative, continuous function on R such that
(i) ψn(x) = 0 for x ≤−1
n and x ≥0
and
(ii)
∞
R
−∞
ψn(x)dx = 1
Deﬁne
gn(t, ω) =
t
Z
0
ψn(s −t)h(s, ω)ds .
Then gn(·, ω) is continuous for each ω and |gn(t, ω)| ≤M. Since h ∈V we
can show that gn(t, ·) is Ft-measurable for all t. (This is a subtle point; see
e.g. Karatzas and Shreve (1991), p. 133 for details.) Moreover,

28
3. Itˆo Integrals
T
Z
S
(gn(s, ω) −h(s, ω))2ds →0
as n →∞, for each ω ,
since {ψn}n constitutes an approximate identity. (See e.g. Hoﬀman (1962,
p. 22).) So by bounded convergence
E
·
T
Z
S
(h(t, ω) −gn(t, ω))2dt
¸
→0
as n →∞,
as asserted.
Step 3. Let f ∈V. Then there exists a sequence {hn} ⊂V such that hn is
bounded for each n and
E
·
T
Z
S
(f −hn)2dt
¸
→0 as n →∞.
Proof. Put
hn(t, ω) =



−n
if
f(t, ω) < −n
f(t, ω)
if
−n ≤f(t, ω) ≤n
n
if
f(t, ω) > n .
Then the conclusion follows by dominated convergence.
That completes the approximation procedure.
We are now ready to complete the deﬁnition of the Itˆo integral
T
Z
S
f(t, ω)dBt(ω)
for f ∈V .
If f ∈V we choose, by Steps 1-3, elementary functions φn ∈V such that
E
·
T
Z
S
|f −φn|2dt
¸
→0 .
Then deﬁne
I[f](ω): =
T
Z
S
f(t, ω)dBt(ω): = lim
n→∞
T
Z
S
φn(t, ω)dBt(ω) .
The limit exists as an element of L2(P), since
© TR
S
φn(t, ω)dBt(ω)
ª
forms a
Cauchy sequence in L2(P), by (3.1.11).
We summarize this as follows:

3.1 Construction of the Itˆo Integral
29
Deﬁnition 3.1.6 (The Itˆo integral). Let f ∈V(S, T). Then the Itˆo inte-
gral of f (from S to T) is deﬁned by
T
Z
S
f(t, ω)dBt(ω) = lim
n→∞
T
Z
S
φn(t, ω)dBt(ω)
(limit in L2(P))
(3.1.12)
where {φn} is a sequence of elementary functions such that
E
·
T
Z
S
(f(t, ω) −φn(t, ω))2dt
¸
→0
as n →∞.
(3.1.13)
Note that such a sequence {φn} satisfying (3.1.13) exists by Steps 1–3
above. Moreover, by (3.1.11) the limit in (3.1.12) exists and does not depend
on the actual choice of {φn}, as long as (3.1.13) holds. Furthermore, from
(3.1.11) and (3.1.12) we get the following important
Corollary 3.1.7 (The Itˆo isometry).
E
·µ
T
Z
S
f(t, ω)dBt
¶2¸
= E
·
T
Z
S
f 2(t, ω)dt
¸
for all f ∈V(S, T) .
(3.1.14)
Corollary 3.1.8. If f(t, ω) ∈V(S, T) and fn(t, ω) ∈V(S, T) for n = 1, 2, . . .
and E
£ TR
S
(fn(t, ω) −f(t, ω))2dt
¤
→0 as n →∞, then
T
Z
S
fn(t, ω)dBt(ω) →
T
Z
S
f(t, ω)dBt(ω)
in L2(P) as n →∞.
We illustrate this integral with an example:
Example 3.1.9. Assume B0 = 0. Then
t
Z
0
BsdBs = 1
2B2
t −1
2t .
Proof. Put φn(s, ω) = P Bj(ω) · X[tj,tj+1)(s), where Bj = Btj. Then
E
·
t
Z
0
(φn −Bs)2ds
¸
= E
· X
j
tj+1
Z
tj
(Bj −Bs)2ds
¸
=
X
j
tj+1
Z
tj
(s −tj)ds =
X
j
1
2(tj+1 −tj)2 →0
as ∆tj →0 .

30
3. Itˆo Integrals
So by Corollary 3.1.8
t
Z
0
BsdBs =
lim
∆tj→0
t
Z
0
φndBs =
lim
∆tj→0
X
j
Bj∆Bj .
(See also Exercise 3.13.) Now
∆(B2
j ) = B2
j+1 −B2
j = (Bj+1 −Bj)2 + 2Bj(Bj+1 −Bj)
= (∆Bj)2 + 2Bj∆Bj ,
and therefore, since B0 = 0,
B2
t =
X
j
∆(B2
j ) =
X
j
(∆Bj)2 + 2
X
j
Bj∆Bj
or
X
j
Bj∆Bj = 1
2B2
t −1
2
X
j
(∆Bj)2 .
Since P
j
(∆Bj)2 →t in L2(P) as ∆tj →0 (Exercise 2.17), the result follows.
The extra term −1
2t shows that the Itˆo stochastic integral does not behave
like ordinary integrals. In the next chapter we will establish the Itˆo formula,
which explains the result in this example and which makes it easy to calculate
many stochastic integrals.
3.2 Some properties of the Itˆo integral
First we observe the following:
Theorem 3.2.1. Let f, g ∈V(0, T) and let 0 ≤S < U < T. Then
(i)
TR
S
fdBt =
UR
S
fdBt +
TR
U
fdBt for a.a. ω
(ii)
TR
S
(cf + g)dBt = c ·
TR
S
fdBt +
TR
S
gdBt (c constant) for a.a. ω
(iii) E
£ TR
S
fdBt
¤
= 0
(iv)
TR
S
fdBt is FT -measurable.
Proof. This clearly holds for all elementary functions, so by taking limits we
obtain this for all f, g ∈V(0, T).
An important property of the Itˆo integral is that it is a martingale:

3.2 Some properties of the Itˆo integral
31
Deﬁnition 3.2.2. A ﬁltration (on (Ω, F)) is a family M = {Mt}t≥0 of
σ-algebras Mt ⊂F such that
0 ≤s < t ⇒Ms ⊂Mt
(i.e. {Mt} is increasing). An n-dimensional stochastic process {Mt}t≥0 on
(Ω, F, P) is called a martingale with respect to a ﬁltration {Mt}t≥0 (and
with respect to P) if
(i)
Mt is Mt-measurable for all t,
(ii) E[|Mt|] < ∞for all t
and
(iii) E[Ms|Mt] = Mt for all s ≥t.
Here the expectation in (ii) and the conditional expectation in (iii) is
taken with respect to P = P 0. (See Appendix B for a survey of conditional
expectation).
Example 3.2.3. Brownian motion Bt in Rn is a martingale w.r.t. the σ-
algebras Ft generated by {Bs; s ≤t}, because
E[|Bt|]2 ≤E[|Bt|2] = |B0|2 + nt
and if s ≥t then
E[Bs|Ft] = E[Bs −Bt + Bt|Ft]
= E[Bs −Bt|Ft] + E[Bt|Ft] = 0 + Bt = Bt .
Here we have used that E[(Bs −Bt)|Ft] = E[Bs −Bt] = 0 since Bs −Bt is
independent of Ft (see (2.2.11) and Theorem B.2.d)) and we have used that
E[Bt|Ft] = Bt since Bt is Ft-measurable (see Theorem B.2.c)).
For continuous martingales we have the following important inequality
due to Doob: (See e.g. Stroock and Varadhan (1979), Theorem 1.2.3 or Revuz
and Yor (1991), Theorem II.1.7)
Theorem 3.2.4 (Doob’s martingale inequality). If Mt is a martingale
such that t →Mt(ω) is continuous a.s., then for all p ≥1, T ≥0 and all
λ > 0
P[ sup
0≤t≤T
|Mt| ≥λ] ≤1
λp · E[|MT |p] .
We now use this inequality to prove that the Itˆo integral
t
Z
0
f(s, ω)dBs
can be chosen to depend continuously on t :

32
3. Itˆo Integrals
Theorem 3.2.5. Let f ∈V(0, T). Then there exists a t-continuous version
of
t
Z
0
f(s, ω)dBs(ω) ;
0 ≤t ≤T ,
i.e. there exists a t-continuous stochastic process Jt on (Ω, F, P) such that
P[Jt =
t
Z
0
fdB] = 1
for all t, 0 ≤t ≤T .
(3.2.1)
Proof. Let φn = φn(t, ω) = P
j
e(n)
j
(ω)X[t(n)
j
,t(n)
j+1)(t) be elementary functions
such that
E
·
T
Z
0
(f −φn)2dt
¸
→0
when n →∞.
Put
In(t, ω) =
t
Z
0
φn(s, ω)dBs(ω)
and
It = I(t, ω) =
t
Z
0
f(s, ω)dBs(ω) ;
0 ≤t ≤T .
Then In(·, ω) is continuous, for all n. Moreover, In(t, ω) is a martingale with
respect to Ft, for all n :
E[In(s, ω)|Ft] = E
·µ
t
Z
0
φndB +
s
Z
t
φndB
¶¯¯¯Ft
¸
=
t
Z
0
φndB + E
·
X
t≤t(n)
j
≤t(n)
j+1≤s
e(n)
j
∆Bj|Ft
¸
=
t
Z
0
φndB +
X
j
E
£
E[e(n)
j
∆Bj|Ft(n)
j ]|Ft
¤
=
t
Z
0
φndB +
X
j
E
£
e(n)
j
E[∆Bj|Ft(n)
j ]|Ft
¤
=
t
Z
0
φndB = In(t, ω)
(3.2.2)

3.2 Some properties of the Itˆo integral
33
when t < s, using Theorem B.3. and Theorem B.2.d).
Hence In −Im is also an Ft-martingale, so by the martingale inequality
(Theorem 3.2.4) it follows that
P
·
sup
0≤t≤T
|In(t, ω) −Im(t, ω)| > ϵ
¸
≤1
ϵ2 · E
£
|In(T, ω) −Im(T, ω)|2¤
= 1
ϵ2 E
·
T
Z
0
(φn −φm)2ds
¸
→0
as m, n →∞.
Hence we may choose a subsequence nk ↑∞s.t.
P
£
sup
0≤t≤T
|Ink+1(t, ω) −Ink(t, ω)| > 2−k¤
< 2−k .
By the Borel-Cantelli lemma
P
£
sup
0≤t≤T
|Ink+1(t, ω) −Ink(t, ω)| > 2−k
for inﬁnitely many k
¤
= 0 .
So for a.a. ω there exists k1(ω) such that
sup
0≤t≤T
|Ink+1(t, ω) −Ink(t, ω)| ≤2−k
for k ≥k1(ω) .
Therefore Ink(t, ω) is uniformly convergent for t ∈[0, T], for a.a. ω and so the
limit, denoted by Jt(ω), is t-continuous for t ∈[0, T], a.s. Since Ink(t, ·) →
I(t, ·) in L2[P] for all t, we must have
It = Jt a.s. ,
for all t ∈[0, T] .
That completes the proof.
⊔⊓
From now on we shall always assume that
tR
0
f(s, ω)dBs(ω) means a t-
continuous version of the integral.
Corollary 3.2.6. Let f(t, ω) ∈V(0, T) for all T. Then
Mt(ω) =
t
Z
0
f(s, ω)dBs
is a martingale w.r.t. Ft and
P
£
sup
0≤t≤T
|Mt| ≥λ
¤
≤1
λ2 · E
·
T
Z
0
f(s, ω)2ds
¸
;
λ, T > 0 .
(3.2.3)
Proof. This follows from (3.2.2), the a.s. t-continuity of Mt and the martin-
gale inequality (Theorem 3.2.4), combined with the Itˆo isometry (3.1.14).
⊔⊓

34
3. Itˆo Integrals
3.3 Extensions of the Itˆo integral
The Itˆo integral
R
fdB can be deﬁned for a larger class of integrands f than
V. First, the measurability condition (ii) of Deﬁnition 3.1.4 can be relaxed to
the following:
(ii)’ There exists an increasing family of σ-algebras Ht; t ≥0 such that
a)
Bt is a martingale with respect to Ht and
b)
ft is Ht-adapted.
Note that a) implies that Ft ⊂Ht. The essence of this extension is that we
can allow ft to depend on more than Ft as long as Bt remains a martingale
with respect to the “history” of fs; s ≤t. If (ii)’ holds, then E[Bs−Bt|Ht] = 0
for all s > t and if we inspect our proofs above, we see that this is suﬃcient
to carry out the construction of the Itˆo integral as before.
The most important example of a situation where (ii)’ applies (and (ii)
doesn’t) is the following:
Suppose Bt(ω) = Bk(t, ω) is the k’th coordinate of n-dimensional Brown-
ian motion (B1, . . . , Bn). Let F(n)
t
be the σ-algebra generated by B1(s1, ·), · · ·,
Bn(sn, ·); sk ≤t. Then Bk(t, ω) is a martingale with respect to F(n)
t
because
Bk(s, ·) −Bk(t, ·) is independent of F(n)
t
when s > t. Thus we have now de-
ﬁned
tR
0
f(s, ω)dBk(s, ω) for F(n)
t
-adapted integrands f(t, ω). That includes
integrals like
Z
B2dB1
or
Z
sin(B2
1 + B2
2) dB2
involving several components of n-dimensional Brownian motion. (Here we
have used the notation dB1 = dB1(t, ω) etc.)
This allows us to deﬁne the multi-dimensional Itˆo integral as follows:
Deﬁnition 3.3.1. Let B = (B1, B2, . . . , Bn) be n-dimensional Brownian
motion. Then Vm×n
H
(S, T) denotes the set of m × n matrices v = [vij(t, ω)]
where each entry vij(t, ω) satisﬁes (i) and (iii) of Deﬁnition 3.1.4 and (ii)’
above, with respect to some ﬁltration H = {Ht}t≥0.
If v ∈Vm×n
H
(S, T) we deﬁne, using matrix notation
T
Z
S
vdB =
T
Z
S


v11
· · ·
v1n
...
...
vm1
· · ·
vmn




dB1
...
dBn


to be the m×1 matrix (column vector) whose i’th component is the following
sum of (extended) 1-dimensional Itˆo integrals:
n
X
j=1
T
Z
S
vij(s, ω)dBj(s, ω) .

3.3 Extensions of the Itˆo integral
35
If H = F(n) = {F(n)
t
}t≥0 we write Vm×n(S, T) and if m = 1 we write
Vn
H(S, T) (respectively Vn(S, T)) instead of Vn×1
H
(S, T) (respectively
Vn×1(S, T)). We also put
Vm×n = Vm×n(0, ∞) =
\
T >0
Vm×n(0, T) .
The next extension of the Itˆo integral consists of weakening condition (iii)
of Deﬁnition 3.1.4 to
(iii)’
P
·
T
Z
S
f(s, ω)2ds < ∞
¸
= 1 .
Deﬁnition 3.3.2. WH(S, T) denotes the class of processes f(t, ω) ∈R satis-
fying (i) of Deﬁnition 3.1.4 and (ii)’, (iii)’ above. Similarly to the notation for
V we put WH = T
T >0
WH(0, T) and in the matrix case we write Wm×n
H
(S, T)
etc. If H = F(n) we write W(S, T) instead of WF(n)(S, T) etc. If the dimen-
sion is clear from the context we sometimes drop the superscript and write
F for F(n) and so on.
Let Bt denote 1-dimensional Brownian motion. If f ∈WH one can show
that for all t there exist step functions fn ∈WH such that
tR
0
|fn −f|2ds →0
in probability, i.e. in measure with respect to P. For such a sequence one has
that
tR
0
fn(s, ω)dBs converges in probability to some random variable and the
limit only depends on f, not on the sequence {fn}. Thus we may deﬁne
t
Z
0
f(s, ω)dBs(ω) = lim
n→∞
t
Z
0
fn(s, ω)dBs(ω) (limit in probability) for f ∈WH .
(3.3.1)
As before there exists a t-continuous version of this integral. See Friedman
(1975, Chap. 4) or McKean (1969, Chap. 2) for details. Note, however, that
this integral is not in general a martingale. See for example Dudley’s Theorem
(Theorem 12.1.5). It is, however, a local martingale. See Karatzas and Shreve
(1991), p. 146. See also Exercise 7.12.
A comparison of Itˆo and Stratonovich integrals
Let us now return to our original question in this chapter: We have argued
that the mathematical interpretation of the white noise equation
dX
dt = b(t, Xt) + σ(t, Xt) · Wt
(3.3.2)

36
3. Itˆo Integrals
is that Xt is a solution of the integral equation
Xt = X0 +
t
Z
0
b(s, Xs)ds + “
t
Z
0
σ(s, Xs)dBs” ,
(3.3.3)
for some suitable interpretation of the last integral in (3.3.3). However, as
indicated earlier, the Itˆo interpretation of an integral of the form
“
t
Z
0
f(s, ω)dBs(ω)”
(∗)
is just one of several reasonable choices. For example, the Stratonovich in-
tegral is another possibility, leading (in general) to a diﬀerent result. So the
question still remains: Which interpretation of (∗) makes (3.3.3) the “right”
mathematical model for the equation (3.3.2)? Here is an argument that in-
dicates that the Stratonovich interpretation in some situations may be the
most appropriate: Choose t-continuously diﬀerentiable processes B(n)
t
such
that for a.a. ω
B(n)(t, ω) →B(t, ω)
as n →∞
uniformly (in t) in bounded intervals. For each ω let X(n)
t
(ω) be the solution
of the corresponding (deterministic) diﬀerential equation
dXt
dt
= b(t, Xt) + σ(t, Xt)dB(n)
t
dt
.
(3.3.4)
Then X(n)
t
(ω) converges to some function Xt(ω) in the same sense: For a.a.
ω we have that X(n)
t
(ω) →Xt(ω) as n →∞, uniformly (in t) in bounded
intervals.
It turns out (see Wong and Zakai (1969) and Sussman (1978)) that this so-
lution Xt coincides with the solution of (3.3.3) obtained by using Stratonovich
integrals, i.e.
Xt = X0 +
t
Z
0
b(s, Xs)ds +
t
Z
0
σ(s, Xs) ◦dBs .
(3.3.5)
This implies that Xt is the solution of the following modiﬁed Itˆo equation:
Xt = X0 +
t
Z
0
b(s, Xs)ds + 1
2
t
Z
0
σ′(s, Xs)σ(s, Xs)ds +
t
Z
0
σ(s, Xs)dBs , (3.3.6)
where σ′ denotes the derivative of σ(t, x) with respect to x. (See Stratonovich
(1966)).

Exercises
37
Therefore, from this point of view it seems reasonable to use (3.3.6) (i.e.
the Stratonovich interpretation) – and not the Itˆo interpretation
Xt = X0 +
t
Z
0
b(s, Xs)ds +
t
Z
0
σ(s, Xs)dBs
(3.3.7)
as the model for the original white noise equation (3.3.2).
On the other hand, the speciﬁc feature of the Itˆo model of “not looking
into the future” (as explained after Example 3.1.1) seems to be a reason for
choosing the Itˆo interpretation in many cases, for example in biology (see the
discussion in Turelli (1977)). The diﬀerence between the two interpretations
is illustrated in Example 5.1.1. Note that (3.3.6) and (3.3.7) coincide if σ(t, x)
does not depend on x. For example, this is the situation in the linear case
handled in the ﬁltering problem in Chapter 6.
In any case, because of the explicit connection (3.3.6) between the two
models (and a similar connection in higher dimensions – see (6.1.3)), it will
for many purposes suﬃce to do the general mathematical treatment for one
of the two types of integrals. In general one can say that the Stratonovich
integral has the advantage of leading to ordinary chain rule formulas under a
transformation (change of variable), i.e. there are no second order terms in the
Stratonovich analogue of the Itˆo transformation formula (see Theorems 4.1.2
and 4.2.1). This property makes the Stratonovich integral natural to use for
example in connection with stochastic diﬀerential equations on manifolds (see
Elworthy (1982) or Ikeda and Watanabe (1989)).
However, Stratonovich integrals are not martingales, as we have seen that
Itˆo integrals are. This gives the Itˆo integral an important computational
advantage, even though it does not behave so nicely under transformations
(as Example 3.1.9 shows). For our purposes the Itˆo integral will be most
convenient, so we will base our discussion on that from now on.
Exercises
Unless otherwise stated Bt denotes Brownian motion in R, B0 = 0.
3.1.
Prove directly from the deﬁnition of Itˆo integrals (Deﬁnition 3.1.6)
that
t
Z
0
sdBs = tBt −
t
Z
0
Bsds .
(Hint: Note that
X
j
∆(sjBj) =
X
j
sj∆Bj +
X
j
Bj+1∆sj .)

38
3. Itˆo Integrals
3.2.
Prove directly from the deﬁnition of Itˆo integrals that
t
Z
0
B2
sdBs = 1
3B3
t −
t
Z
0
Bsds .
3.3.
If Xt: Ω→Rn is a stochastic process, let Ht = H(X)
t
denote the σ-
algebra generated by {Xs(·); s ≤t} (i.e. {H(X)
t
}t≥0 is the ﬁltration of
the process {Xt}t≥0).
a) Show that if Xt is a martingale w.r.t. some ﬁltration {Nt}t≥0, then
Xt is also a martingale w.r.t. its own ﬁltration {H(X)
t
}t≥0 .
b) Show that if Xt is a martingale w.r.t H(X)
t
, then
E[Xt] = E[X0]
for all t ≥0 .
(∗)
c) Give an example of a stochastic process Xt satisfying (∗) and which
is not a martingale w.r.t. its own ﬁltration.
3.4.
Check whether the following processes Xt are martingales w.r.t. {Ft}:
(i)
Xt = Bt + 4t
(ii) Xt = B2
t
(iii) Xt = t2Bt −2
tR
0
sBsds
(iv) Xt = B1(t)B2(t), where (B1(t), B2(t)) is 2-dimensional Brownian
motion.
3.5.
Prove directly (without using Example 3.1.9) that
Mt = B2
t −t
is an Ft-martingale.
3.6.
Prove that Nt = B3
t −3tBt is a martingale.
3.7.
A famous result of Itˆo (1951) gives the following formula for n times
iterated Itˆo integrals:
n!
Z
· · · (
Z
(
Z
0≤u1≤···≤un≤t
dBu1)dBu2) · · · dBun = t
n
2 hn
µ Bt
√
t
¶
(3.3.8)
where hn is the Hermite polynomial of degree n, deﬁned by
hn(x) = (−1)ne
x2
2 dn
dxn
¡
e
−x2
2 ¢
;
n = 0, 1, 2, . . .
(Thus h0(x) = 1, h1(x) = x, h2(x) = x2 −1, h3(x) = x3 −3x.)
a) Verify that in each of these n Itˆo integrals the integrand satisﬁes
the requirements in Deﬁnition 3.1.4.

Exercises
39
b) Verify formula (3.3.8) for n = 1, 2, 3 by combining Example 3.1.9
and Exercise 3.2.
c) Use b) to give a new proof of the statement in Exercise 3.6.
3.8.
a) Let Y be a real valued random variable on (Ω, F, P) such that
E[|Y |] < ∞.
Deﬁne
Mt = E[Y |Ft] ;
t ≥0 .
Show that Mt is an Ft-martingale.
b) Conversely, let Mt; t ≥0 be a real valued Ft-martingale such that
sup
t≥0
E[|Mt|p] < ∞
for some p > 1 .
Show that there exists Y ∈L1(P) such that
Mt = E[Y |Ft] .
(Hint: Use Corollary C.7.)
3.9.
Suppose f ∈V(0, T) and that t →f(t, ω) is continuous for a.a. ω.
Then we have shown that
T
Z
0
f(t, ω)dBt(ω) =
lim
∆tj→0
X
j
f(tj, ω)∆Bj
in L2(P) .
Similarly we deﬁne the Stratonovich integral of f by
T
Z
0
f(t, ω)◦dBt(ω)= lim
∆tj→0
X
j
f(t∗
j, ω)∆Bj ,
where t∗
j = 1
2(tj + tj+1) ,
whenever the limit exists in L2(P). In general these integrals are dif-
ferent. For example, compute
T
Z
0
Bt ◦dBt
and compare with Example 3.1.9.
3.10. If the function f in Exercise 3.9 varies “smoothly” with t then in fact
the Itˆo and Stratonovich integrals of f coincide. More precisely, assume
that there exists K < ∞and ϵ > 0 such that
E[|f(s, ·) −f(t, ·)|2] ≤K|s −t|1+ϵ ;
0 ≤s , t ≤T .

40
3. Itˆo Integrals
Prove that then we have
T
Z
0
f(t, ω)dBt =
lim
∆tj→0
X
j
f(t′
j, ω)∆Bj
(limit in L1(P))
for any choice of t′
j ∈[tj, tj+1]. In particular,
T
Z
0
f(t, ω)dBt =
T
Z
0
f(t, ω) ◦dBt .
(Hint: Consider E
£
| P
j
f(tj, ω)∆Bj −P
j
f(t′
j, ω)∆Bj|
¤
.)
3.11. Let Wt be a stochastic process satisfying (i), (ii) and (iii) (below
(3.1.2)). Prove that Wt cannot have continuous paths. (Hint: Consider
E[(W (N)
t
−W (N)
s
)2], where
W (N)
t
= (−N) ∨(N ∧Wt), N = 1, 2, 3, . . .) .
3.12. As in Exercise 3.9 we let ◦dBt denote Stratonovich diﬀerentials.
(i) Use (3.3.6) to transform the following Stratonovich diﬀerential
equations into Itˆo diﬀerential equations:
(a)
dXt = γXtdt + αXt ◦dBt
(b)
dXt = sin Xt cos Xtdt + (t2 + cos Xt) ◦dBt
(ii) Transform the following Itˆo diﬀerential equations into Stratonovich
diﬀerential equations:
(a)
dXt = rXtdt + αXtdBt
(b)
dXt = 2e−Xtdt + X2
t dBt
3.13. A stochastic process Xt(·): Ω→R is continuous in mean square if
E[X2
t ] < ∞for all t and
lim
s→t E[(Xs −Xt)2] = 0
for all t ≥0 .
a) Prove that Brownian motion Bt is continuous in mean square.
b) Let f: R →R be a Lipschitz continuous function, i.e. there exists
C < ∞such that
|f(x) −f(y)| ≤C|x −y|
for all x, y ∈R .
Prove that
Yt: = f(Bt)
is continuous in mean square.

Exercises
41
c) Let Xt be a stochastic process which is continuous in mean square
and assume that Xt ∈V(S, T), T < ∞. Show that
T
Z
S
XtdBt = lim
n→∞
T
Z
S
φn(t, ω)dBt(ω)
(limit in L2(P))
where
φn(t, ω) =
X
j
Xt(n)
j (ω)X[t(n)
j
,t(n)
j+1)(t) ,
T < ∞.
(Hint: Consider
E
·
T
Z
S
(Xt −φn(t))2dt
¸
= E
· X
j
t(n)
j+1
Z
t(n)
j
(Xt −Xt(n)
j )2dt
¸
) .
3.14. Show that a function h(ω) is Ft-measurable if and only if h is a point-
wise limit (for a.a. ω) of sums of functions of the form
g1(Bt1) · g2(Bt2) · · · gk(Btk)
where g1, . . . , gk are bounded continuous functions and tj ≤t for j ≤k,
k = 1, 2, . . .
Hint: Complete the following steps:
a) We may assume that h is bounded.
b) For n = 1, 2, . . . and j = 1, 2, . . . put tj = t(n)
j
= j · 2−n. For
ﬁxed n let Hn be the σ-algebra generated by {Btj(·)}tj≤t. Then by
Corollary C.9
h = E[h|Ft] = lim
n→∞E[h|Hn]
(pointwise a.e. limit)
c) Deﬁne hn: = E[h|Hn]. Then by the Doob-Dynkin lemma (Lemma
2.1.2) we have
hn(ω) = Gn(Bt1(ω), . . . , Btk(ω))
for some Borel function Gn:Rk →R, where k=max{j; j · 2−n ≤t}.
Now use that any Borel function G: Rk →R can be approximated
pointwise a.e. by a continuous function F: Rk →R and complete
the proof by applying the Stone-Weierstrass theorem.
3.15. Suppose f, g ∈V(S, T) and that there exist constants C, D such that
C +
T
Z
S
f(t, ω)dBt(ω) = D +
T
Z
S
g(t, ω)dBt(ω)
for a.a. ω ∈Ω.

42
3. Itˆo Integrals
Show that
C = D
and
f(t, ω) = g(t, ω)
for a.a. (t, ω) ∈[S, T] × Ω.
3.16. Let X: Ω→R be a random variable such that E[X2] < ∞and let
H ⊂F be a σ-algebra. Show that
E
£
(E[X|H])2¤
≤E[X2] .
(See Lemma 6.1.1. See also the Jensen inequality for conditional ex-
pectation (Appendix B).)
3.17. Let (Ω, F, P) be a probability space and let X: Ω→R be a random
variable with E[|X|] < ∞. If G ⊂F is a ﬁnite σ-algebra, then by
Exercise 2.7 there exists a partition Ω=
nS
i=1
Gi such that G consists
of ∅and unions of some (or all) of G1, . . . , Gn.
a) Explain why E[X|G](ω) is constant on each Gi. (See Exercise 2.7 c).)
b) Assume that P[Gi] > 0. Show that
E[X|G](ω) =
R
Gi XdP
P(Gi)
for ω ∈Gi .
c) Suppose X assumes only ﬁnitely many values a1, . . . , am. Then from
elementary probability theory we know that (see Exercise 2.1)
E[X|Gi] =
m
X
k=1
akP[X = ak|Gi] .
Compare with b) and verify that
E[X|Gi] = E[X|G](ω)
for ω ∈Gi .
Thus we may regard the conditional expectation as deﬁned in Ap-
pendix B as a (substantial) generalization of the conditional expec-
tation in elementary probability theory.

4. The Itˆo Formula and the Martingale
Representation Theorem
4.1 The 1-dimensional Itˆo formula
Example 3.1.9 illustrates that the basic deﬁnition of Itˆo integrals is not very
useful when we try to evaluate a given integral. This is similar to the situation
for ordinary Riemann integrals, where we do not use the basic deﬁnition but
rather the fundamental theorem of calculus plus the chain rule in the explicit
calculations.
In this context, however, we have no diﬀerentiation theory, only integra-
tion theory. Nevertheless it turns out that it is possible to establish an Itˆo
integral version of the chain rule, called the Itˆo formula. The Itˆo formula is,
as we will show by examples, very useful for evaluating Itˆo integrals.
From the example
t
Z
0
BsdBs = 1
2B2
t −1
2t
or
1
2B2
t = 1
2t +
t
Z
0
BsdBs ,
(4.1.1)
we see that the image of the Itˆo integral Bt =
tR
0
dBs by the map g(x) = 1
2x2
is not again an Itˆo integral of the form
t
Z
0
f(s, ω)dBs(ω)
but a combination of a dBs-and a ds-integral:
1
2B2
t =
t
Z
0
1
2ds +
t
Z
0
BsdBs .
(4.1.2)
It turns out that if we introduce Itˆo processes (also called stochastic integrals)
as sums of a dBs-and a ds-integral then this family of integrals is stable under
smooth maps. Thus we deﬁne
Deﬁnition 4.1.1 (1-dimensional Itˆo processes).
Let Bt be 1-dimensional Brownian motion on (Ω, F, P). A (1-dimensional)

44
4. The Itˆo Formula and the Martingale ...
Itˆo process (or stochastic integral) is a stochastic process Xt on (Ω, F, P) of
the form
Xt = X0 +
t
Z
0
u(s, ω)ds +
t
Z
0
v(s, ω)dBs ,
(4.1.3)
where v ∈WH, so that
P
·
t
Z
0
v(s, ω)2ds < ∞for all t ≥0
¸
= 1
(4.1.4)
(see Deﬁnition 3.3.2). We also assume that u is Ht-adapted (where Ht is as
in (ii)’, Section 3.3) and
P
·
t
Z
0
|u(s, ω)|ds < ∞for all t ≥0
¸
= 1 .
(4.1.5)
If Xt is an Itˆo process of the form (4.1.3) the equation (4.1.3) is sometimes
written in the shorter diﬀerential form
dXt = udt + vdBt .
(4.1.6)
For example, (4.1.1) (or (4.1.2)) may be represented by
d
¡ 1
2B2
t
¢
= 1
2dt + BtdBt .
We are now ready to state the ﬁrst main result in this chapter:
Theorem 4.1.2 (The 1-dimensional Itˆo formula).
Let Xt be an Itˆo process given by
dXt = udt + vdBt .
Let g(t, x) ∈C2([0, ∞) × R) (i.e. g is twice continuously diﬀerentiable on
[0, ∞) × R). Then
Yt = g(t, Xt)
is again an Itˆo process, and
dYt = ∂g
∂t (t, Xt)dt + ∂g
∂x(t, Xt)dXt + 1
2
∂2g
∂x2 (t, Xt) · (dXt)2 ,
(4.1.7)
where (dXt)2 = (dXt) · (dXt) is computed according to the rules
dt · dt = dt · dBt = dBt · dt = 0 ,
dBt · dBt = dt .
(4.1.8)
Before we prove Itˆo’s formula let us look at some examples.

4.1 The 1-dimensional Itˆo formula
45
Example 4.1.3. Let us return to the integral
I =
t
Z
0
BsdBs
from Chapter 3 .
Choose Xt = Bt and g(t, x) = 1
2x2. Then
Yt = g(t, Bt) = 1
2B2
t .
Then by Itˆo’s formula,
dYt = ∂g
∂t dt + ∂g
∂xdBt + 1
2
∂2g
∂x2 (dBt)2 = BtdBt + 1
2(dBt)2 = BtdBt + 1
2dt .
Hence
d( 1
2B2
t ) = BtdBt + 1
2dt .
In other words,
1
2B2
t =
t
Z
0
BsdBs + 1
2t,
as in Chapter 3 .
Example 4.1.4. What is
t
Z
0
sdBs ?
From classical calculus it seems reasonable that a term of the form tBt should
appear, so we put
g(t, x) = tx
and
Yt = g(t, Bt) = tBt .
Then by Itˆo’s formula,
dYt = Btdt + tdBt + 0
i.e.
d(tBt) = Btdt + tdBt
or
tBt =
t
Z
0
Bsds +
t
Z
0
sdBs
or
t
Z
0
sdBs = tBt −
t
Z
0
Bsds ,
which is reasonable from an integration-by-parts point of view.

46
4. The Itˆo Formula and the Martingale ...
More generally, the same method gives
Theorem 4.1.5 (Integration by parts). Suppose f(s, ω) = f(s) only de-
pends on s and that f is continuous and of bounded variation in [0, t]. Then
t
Z
0
f(s)dBs = f(t)Bt −
t
Z
0
Bsdfs .
Note that it is crucial for the result to hold that f does not depend on ω.
(See Exercise 4.3.)
Sketch of proof of the Itˆo formula. First observe that if we substitute
dXt = udt + vdBt
in (4.1.7) and use (4.1.8) we get the equivalent expression
g(t, Xt) = g(0, X0) +
t
Z
0
µ∂g
∂s(s, Xs) + us
∂g
∂x(s, Xs) + 1
2v2
s · ∂2g
∂x2 (s, Xs)
¶
ds
+
t
Z
0
vs · ∂g
∂x(s, Xs)dBs
where us = u(s, ω), vs = v(s, ω) .
(4.1.9)
Note that (4.1.9) is an Itˆo process in the sense of Deﬁnition 4. 1.1.
We may assume that g, ∂g
∂t , ∂g
∂x and ∂2g
∂x2 are bounded, for if (4.1.9) is proved
in this case we obtain the general case by approximating by C2 functions
gn such that gn, ∂gn
∂t , ∂gn
∂x
and
∂2gn
∂x2
are bounded for each n and converge
uniformly on compact subsets of [0, ∞) × R to g, ∂g
∂t , ∂g
∂x, ∂2g
∂x2 , respectively.
(See Exercise 4.9.) Moreover, from (3.3.1) we see that we may assume that
u(t, ω) and v(t, ω) are elementary functions. Using Taylor’s theorem we get
g(t, Xt) = g(0, X0) +
X
j
∆g(tj, Xj) = g(0, X0) +
X
j
∂g
∂t ∆tj +
X
j
∂g
∂x∆Xj
+ 1
2
X
j
∂2g
∂t2 (∆tj)2 +
X
j
∂2g
∂t∂x(∆tj)(∆Xj) + 1
2
X
j
∂2g
∂x2 (∆Xj)2 +
X
j
Rj ,
where ∂g
∂t , ∂g
∂x etc. are evaluated at the points (tj, Xtj),
∆tj = tj+1 −tj, ∆Xj = Xtj+1 −Xtj, ∆g(tj, Xj) = g(tj+1, Xtj+1) −g(tj, Xj)
and Rj = o(|∆tj|2 + |∆Xj|2) for all j.
If ∆tj →0 then

4.1 The 1-dimensional Itˆo formula
47
X
j
∂g
∂t ∆tj =
X
j
∂g
∂t (tj, Xj)∆tj →
t
Z
0
∂g
∂t (s, Xs)ds
(4.1.10)
X
j
∂g
∂x∆Xj =
X
j
∂g
∂x(tj, Xj)∆Xj →
t
Z
0
∂g
∂x(s, Xs)dXs .
(4.1.11)
Moreover, since u and v are elementary we get
X
j
∂2g
∂x2 (∆Xj)2 =
X
j
∂2g
∂x2 u2
j(∆tj)2 + 2
X
j
∂2g
∂x2 ujvj(∆tj)(∆Bj)
+
X
j
∂2g
∂x2 v2
j · (∆Bj)2,
where uj = u(tj, ω), vj = v(tj, ω) .
(4.1.12)
The ﬁrst two terms here tend to 0 as ∆tj →0. For example,
E
·µ X
j
∂2g
∂x2 ujvj(∆tj)(∆Bj)
¶2¸
=
=
X
j
E
·µ∂2g
∂x2 ujvj
¶2¸
(∆tj)3 →0
as ∆tj →0 .
We claim that the last term tends to
t
Z
0
∂2g
∂x2 v2ds
in L2(P), as ∆tj →0 .
To prove this, put a(t) = ∂2g
∂x2 (t, Xt)v2(t, ω), aj = a(tj) and consider
E
·µX
j
aj(∆Bj)2−
X
j
aj∆tj
¶2¸
=
X
i,j
E[aiaj((∆Bi)2−∆ti)((∆Bj)2−∆tj)] .
If i < j then aiaj((∆Bi)2 −∆ti) and (∆Bj)2 −∆tj are independent so the
terms vanish in this case, and similarly if i > j. So we are left with
X
j
E[a2
j((∆Bj)2 −∆tj)2] =
X
j
E[a2
j] · E[(∆Bj)4 −2(∆Bj)2∆tj + (∆tj)2]
=
X
j
E[a2
j] · (3(∆tj)2 −2(∆tj)2 + (∆tj)2) = 2
X
j
E[a2
j] · (∆tj)2
→0
as ∆tj →0 .
In other words, we have established that

48
4. The Itˆo Formula and the Martingale ...
X
j
aj(∆Bj)2 →
t
Z
0
a(s)ds
in L2(P) as ∆tj →0
and this is often expressed shortly by the striking formula
(dBt)2 = dt .
(4.1.13)
The argument above also proves that P Rj →0 as ∆tj →0. That completes
the proof of the Itˆo formula.
⊔⊓
Remark. Note that it is enough that g(t, x) is C2 on [0, ∞) × U, if U ⊂R
is an open set such that Xt(ω) ∈U for all t ≥0, ω ∈Ω. Moreover, it is
suﬃcient that g(t, x) is C1 w.r.t. t and C2 w.r.t. x.
4.2 The Multi-dimensional Itˆo Formula
We now turn to the situation in higher dimensions: Let B(t, ω)=(B1(t, ω), . . .,
Bm(t, ω)) denote m-dimensional Brownian motion. If each of the processes
ui(t, ω) and vij(t, ω) satisﬁes the conditions given in Deﬁnition 4.1.1 (1≤i≤n,
1 ≤j ≤m) then we can form the following n Itˆo processes





dX1 = u1dt + v11dB1 + · · · + v1mdBm
...
...
...
dXn = undt + vn1dB1 + · · · + vnmdBm
(4.2.1)
Or, in matrix notation simply
dX(t) = udt + vdB(t) ,
(4.2.2)
where
X(t) =









X1(t)
...
Xn(t)








,
u =








u1
...
un







,
v =








v11 · · · v1m
...
...
vn1 · · · vnm







,
dB(t) =









dB1(t)
...
dBm(t)









(4.2.3)
Such a process X(t) is called an n-dimensional Itˆo process (or just an Itˆo
process).
We now ask: What is the result of applying a smooth function to X? The
answer is given by
Theorem 4.2.1 (The general Itˆo formula).
Let
dX(t) = udt + vdB(t)
be an n-dimensional Itˆo process as above. Let g(t, x) = (g1(t, x), . . . , gp(t, x))
be a C2 map from [0, ∞) × Rn into Rp. Then the process

4.3 The Martingale Representation Theorem
49
Y (t, ω) = g(t, X(t))
is again an Itˆo process, whose component number k, Yk, is given by
dYk = ∂gk
∂t (t, X)dt +
X
i
∂gk
∂xi
(t, X)dXi + 1
2
X
i,j
∂2gk
∂xi∂xj
(t, X)dXidXj
where dBidBj = δijdt, dBidt = dtdBi = 0.
The proof is similar to the 1-dimensional version (Theorem 4.1.2) and is
omitted.
Example 4.2.2. Let B = (B1, . . . , Bn) be Brownian motion in Rn, n ≥2,
and consider
R(t, ω) = |B(t, ω)| = (B2
1(t, ω) + · · · + B2
n(t, ω))
1
2 ,
i.e. the distance to the origin of B(t, ω). The function g(t, x) = |x| is not C2
at the origin, but since Bt never hits the origin, a.s. when n ≥2 (see Exercise
9.7) Itˆo’s formula still works and we get
dR =
n
X
i=1
BidBi
R
+ n −1
2R dt .
The process R is called the n-dimensional Bessel process because its generator
(Chapter 7) is the Bessel diﬀerential operator Af(x) = 1
2f ′′(x) + n−1
2x f ′(x).
See Example 8.4.1.
4.3 The Martingale Representation Theorem
Let B(t) = (B1(t), . . . , Bn(t)) be n-dimensional Brownian motion. In Chap-
ter 3 (Corollary 3.2.6) we proved that if v ∈Vn then the Itˆo integral
Xt = X0 +
t
Z
0
v(s, ω)dB(s) ;
t ≥0
is always a martingale w.r.t. ﬁltration F(n)
t
(and w.r.t. the probability mea-
sure P). In this section we will prove that the converse is also true: Any
F(n)
t
-martingale (w.r.t. P) can be represented as an Itˆo integral. This result,
called the martingale representation theorem, is important for many applica-
tions, for example in mathematical ﬁnance. See Chapter 12. For simplicity
we prove the result only when n = 1, but the reader can easily verify that
essentially the same proof works for arbitrary n.
We ﬁrst establish some auxiliary results.

50
4. The Itˆo Formula and the Martingale ...
Lemma 4.3.1. Fix T > 0. The set of random variables
{φ(Bt1, . . . , Btn); ti ∈[0, T], φ ∈C∞
0 (Rn), n = 1, 2, . . .}
is dense in L2(FT , P).
Proof. Let {ti}∞
i=1 be a dense subset of [0, T] and for each n = 1, 2, . . . let Hn
be the σ-algebra generated by Bt1(·), . . . , Btn(·). Then clearly
Hn ⊂Hn+1
and FT is the smallest σ-algebra containing all the Hn’s. Choose
g ∈L2(FT , P). Then by the martingale convergence theorem Corollary C.9
(Appendix C) we have that
g = E[g|FT ] = lim
n→∞E[g|Hn] .
The limit is pointwise a.e. (P) and in L2(FT , P). By the Doob-Dynkin Lemma
(Lemma 2.1.2) we can write, for each n,
E[g|Hn] = gn(Bt1, . . . , Btn)
for some Borel measurable function gn: Rn →R. Each such gn(Bt1, . . . , Btn)
can be approximated in L2(FT , P) by functions φn(Bt1, . . . , Btn) where
φn ∈C∞
0 (Rn) and the result follows.
⊔⊓
Lemma 4.3.2. The linear span of random variables of the type
exp
½
T
Z
0
h(t)dBt(ω) −1
2
T
Z
0
h2(t)dt
¾
;
h∈L2[0, T] (deterministic)
(4.3.1)
is dense in L2(FT , P).
Proof. Suppose g ∈L2(FT , P) is orthogonal (in L2(FT , P)) to all functions
of the form (4.3.1). Then in particular
G(λ): =
Z
Ω
exp{λ1Bt1(ω) + · · · + λnBtn(ω)}g(ω)dP(ω) = 0
(4.3.2)
for all λ = (λ1, . . . , λn) ∈Rn and all t1, . . . , tn ∈[0, T]. The function G(λ) is
real analytic in λ ∈Rn and hence G has an analytic extension to the complex
space Cn given by
G(z) =
Z
Ω
exp{z1Bt1(ω) + · · · + znBtn(ω)}g(ω)dP(ω)
(4.3.3)

4.3 The Martingale Representation Theorem
51
for all z =(z1, . . . , zn)∈Cn. (See the estimates in Exercise 2.8 b).) Since G=0
on Rn and G is analytic, G = 0 on Cn. In particular, G(iy1, iy2, . . . , iyn) = 0
for all y = (y1, . . . , yn) ∈Rn. But then we get, for φ ∈C∞
0 (Rn),
Z
Ω
φ(Bt1, . . . , Btn)g(ω)dP(ω)
=
Z
Ω
(2π)−n/2
µ Z
Rn
bφ(y)ei(y1Bt1+···+ynBtn)dy
¶
g(ω)dP(ω)
= (2π)−n/2
Z
Rn
bφ(y)
µ Z
Ω
ei(y1Bt1+···+ynBtn)g(ω)dP(ω)
¶
dy
= (2π)−n/2
Z
Rn
bφ(y)G(iy)dy = 0 ,
(4.3.4)
where
bφ(y) = (2π)−n/2
Z
Rn
φ(x)e−i x·ydx
is the Fourier transform of φ and we have used the inverse Fourier transform
theorem
φ(x) = (2π)−n/2
Z
Rn
bφ(y)ei x·ydy
(see e.g. Folland (1984)).
By (4.3.4) and Lemma 4.3.1 g is orthogonal to a dense subset of L2(FT , P)
and we conclude that g = 0. Therefore the linear span of the functions in
(4.3.1) must be dense in L2(FT , P) as claimed.
⊔⊓
Suppose B(t) = (B1(t), . . . , Bn(t)) is n-dimensional. If v(s, ω) ∈Vn(0, T)
then the random variable
V (ω): =
T
Z
0
v(t, ω)dB(t)
(4.3.5)
is F(n)
T -measurable and by the Itˆo isometry
E[V 2] =
T
Z
0
E[v2(t, ·)]dt < ∞,
so V ∈L2(F(n)
T , P) .
The next result states that any F ∈L2(F(n)
T , P) can be represented this way:
Theorem 4.3.3 (The Itˆo representation theorem).
Let F ∈L2(F(n)
T , P). Then there exists a unique stochastic process f(t, ω) ∈
Vn(0, T) such that

52
4. The Itˆo Formula and the Martingale ...
F(ω) = E[F] +
T
Z
0
f(t, ω)dB(t) .
(4.3.6)
Proof. Again we consider only the case n = 1. (The proof in the general case
is similar.) First assume that F has the form (4.3.1), i.e.
F(ω) = exp
½
T
Z
0
h(t)dBt(ω) −1
2
T
Z
0
h2(t)dt
¾
for some h(t) ∈L2[0, T].
Deﬁne
Yt(ω) = exp
½
t
Z
0
h(s)dBs(ω) −1
2
t
Z
0
h2(s)ds
¾
;
0 ≤t ≤T .
Then by Itˆo’s formula
dYt = Yt(h(t)dBt −1
2h2(t)dt) + 1
2Yt(h(t)dBt)2 = Yth(t)dBt
so that
Yt = 1 +
t
Z
0
Ysh(s)dBs ;
t ∈[0, T] .
Therefore
F = YT = 1 +
T
Z
0
Ysh(s)dBs
and hence E[F] = 1. So (4.3.6) holds in this case. By linearity (4.3.6)
also holds for linear combinations of functions of the form (4.3.1). So if
F ∈L2(FT , P) is arbitrary, we approximate F in L2(FT , P) by linear com-
binations Fn of functions of the form (4.3.1). Then for each n we have
Fn(ω) = E[Fn] +
T
Z
0
fn(s, ω)dBs(ω),
where fn ∈V(0, T) .
By the Itˆo isometry
E[(Fn −Fm)2] = E
·
(E[Fn −Fm] +
T
Z
0
(fn −fm)dB)2
¸
= (E[Fn −Fm])2 +
T
Z
0
E[(fn −fm)2]dt →0
as n, m →∞

4.3 The Martingale Representation Theorem
53
so {fn} is a Cauchy sequence in L2([0, T] × Ω) and hence converges to some
f ∈L2([0, T] × Ω). Since fn ∈V(0, T) we have f ∈V(0, T). (A subsequence
of {fn(t, ω)} converges to f(t, ω) for a.a. (t, ω) ∈[0, T] × Ω. Therefore f(t, ·)
is Ft-measurable for a.a. t. So by modifying f(t, ω) on a t-set of measure 0
we can obtain that f(t, ω) is Ft-adapted.) Again using the Itˆo isometry we
see that
F = lim
n→∞Fn = lim
n→∞
µ
E[Fn] +
T
Z
0
fndB
¶
= E[F] +
T
Z
0
fdB ,
the limit being taken in L2(FT , P). Hence the representation (4.3.6) holds
for all F ∈L2(FT , P).
The uniqueness follows from the Itˆo isometry: Suppose
F(ω) = E[F] +
T
Z
0
f1(t, ω)dBt(ω) = E[F] +
T
Z
0
f2(t, ω)dBt(ω)
with f1, f2 ∈V(0, T). Then
0 = E[(
T
Z
0
(f1(t, ω) −f2(t, ω))dBt(ω))2] =
T
Z
0
E[(f1(t, ω) −f2(t, ω))2]dt
and therefore f1(t, ω) = f2(t, ω) for a.a. (t, ω) ∈[0, T] × Ω.
⊔⊓
Remark.
The process f(t, ω) can be expressed in terms of the Frechet
derivative and also in terms of the Malliavin derivative of F(ω). See Clark
(1970/71) and Ocone (1984).
Theorem 4.3.4 (The martingale representation theorem).
Let B(t) = (B1(t), . . . , Bn(t)) be n-dimensional. Suppose Mt is an F(n)
t
-
martingale (w.r.t. P) and that Mt ∈L2(P) for all t ≥0. Then there exists a
unique stochastic process g(s, ω) such that g ∈V(n)(0, t) for all t ≥0 and
Mt(ω) = E[M0] +
t
Z
0
g(s, ω)dB(s)
a.s., for all t ≥0 .
Proof (n = 1). By Theorem 4.3.3 applied to T = t, F = Mt, we have that
for all t there exists a unique f (t)(s, ω) ∈L2(Ft, P) such that
Mt(ω) = E[Mt] +
t
Z
0
f (t)(s, ω)dBs(ω) = E[M0] +
t
Z
0
f (t)(s, ω)dBs(ω) .
Now assume 0 ≤t1 < t2. Then

54
4. The Itˆo Formula and the Martingale ...
Mt1 = E[Mt2|Ft1] = E[M0] + E
· t2
Z
0
f (t2)(s, ω)dBs(ω)|Ft1
¸
= E[M0] +
Z t1
0
f (t2)(s, ω)dBs(ω) .
(4.3.7)
But we also have
Mt1 = E[M0] +
t1
Z
0
f (t1)(s, ω)dBs(ω) .
(4.3.8)
Hence, comparing (4.3.7) and (4.3.8) we get that
0 = E
·µ t1
Z
0
(f (t2) −f (t1))dB
¶2¸
=
t1
Z
0
E[(f (t2) −f (t1))2]ds
and therefore
f (t1)(s, ω) = f (t2)(s, ω)
for a.a. (s, ω) ∈[0, t1] × Ω.
So we can deﬁne f(s, ω) for a.a. s ∈[0, ∞) × Ωby setting
f(s, ω) = f (N)(s, ω)
if s ∈[0, N]
and then we get
Mt = E[M0]+
t
Z
0
f (t)(s, ω)dBs(ω) = E[M0]+
t
Z
0
f(s, ω)dBs(ω)
for all t ≥0 .
⊔⊓
Exercises
4.1.
Use Itˆo’s formula to write the following stochastic processes Xt on the
standard form
dXt = u(t, ω)dt + v(t, ω)dBt
for suitable choices of u ∈Rn, v ∈Rn×m and dimensions n, m:
a) Xt = B2
t , where Bt is 1-dimensional
b) Xt = 2 + t + eBt (Bt is 1-dimensional)
c) Xt = B2
1(t) + B2
2(t) where (B1, B2) is 2-dimensional
d) Xt = (t0 + t, Bt) (Bt is 1-dimensional)
e) Xt = (B1(t)+B2(t)+B3(t), B2
2(t)−B1(t)B3(t)), where (B1, B2, B3)
is 3-dimensional.

Exercises
55
4.2.
Use Itˆo’s formula to prove that
t
Z
0
B2
sdBs = 1
3B3
t −
t
Z
0
Bsds .
4.3.
Let Xt, Yt be Itˆo processes in R. Prove that
d(XtYt) = XtdYt + YtdXt + dXt · dYt .
Deduce the following general integration by parts formula
t
Z
0
XsdYs = XtYt −X0Y0 −
t
Z
0
YsdXs −
t
Z
0
dXs · dYs .
4.4.
(Exponential martingales)
Suppose θ(t, ω) = (θ1(t, ω), . . . , θn(t, ω)) ∈Rn with θk(t, ω) ∈V[0, T]
for k = 1, . . . , n, where T ≤∞. Deﬁne
Zt = exp
½
t
Z
0
θ(s, ω)dB(s) −1
2
t
Z
0
θ2(s, ω)ds
¾
;
0 ≤t ≤T
where B(s) ∈Rn and θ2 = θ · θ (dot product).
a) Use Itˆo’s formula to prove that
dZt = Ztθ(t, ω)dB(t) .
b) Deduce that Zt is a martingale for t ≤T, provided that
Ztθk(t, ω) ∈V[0, T]
for 1 ≤k ≤n .
Remark.
A suﬃcient condition that Zt be a martingale is the Kazamaki
condition
E
·
exp
µ
1
2
t
Z
0
θ(s, ω)dB(s)
¶¸
< ∞
for all t ≤T .
(4.3.9)
This is implied by the following (stronger) Novikov condition
E
·
exp
µ
1
2
T
Z
0
θ2(s, ω)ds
¶¸
< ∞.
(4.3.10)
See e.g. Ikeda & Watanabe (1989), Section III.5, and the references
therein.

56
4. The Itˆo Formula and the Martingale ...
4.5.
Let Bt ∈R, B0 = 0. Deﬁne
βk(t) = E[Bk
t ] ;
k = 0, 1, 2, . . . ; t ≥0 .
Use Itˆo’s formula to prove that
βk(t) = 1
2k(k −1)
t
Z
0
βk−2(s)ds ;
k ≥2 .
Deduce that
E[B4
t ] = 3t2
(see (2.2.14))
and ﬁnd
E[B6
t ] .
4.6.
a) For c, α constants, Bt ∈R deﬁne
Xt = ect+αBt .
Prove that
dXt = (c + 1
2α2)Xtdt + αXtdBt .
b) For c, α1, . . . , αn constants, Bt = (B1(t), . . . , Bn(t)) ∈Rn deﬁne
Xt = exp
µ
ct +
n
X
j=1
αjBj(t)
¶
.
Prove that
dXt =
µ
c + 1
2
n
X
j=1
α2
j
¶
Xtdt + Xt
µ
n
X
j=1
αjdBj
¶
.
4.7.
Let Xt be an Itˆo integral
dXt = v(t, ω)dBt(ω)
where v ∈Rn, v ∈V(0, T), Bt ∈Rn, 0 ≤t ≤T .
a) Give an example to show that X2
t is not in general a martingale.
b) Prove that if v is bounded then
Mt: = X2
t −
t
Z
0
|vs|2ds
is a martingale .
The process ⟨X, X⟩t: =
tR
0
|vs|2ds is called the quadratic variation
process of the martingale Xt. For general processes Xt it is deﬁned
by

Exercises
57
⟨X, X⟩t = lim
∆tk→0
X
tk≤t
|Xtk+1−Xtk|2
(limit in probability) (4.3.11)
where 0 = t1 < t2 · · · < tn = t and ∆tk = tk+1 −tk. The limit can
be shown to exist for continuous square integrable martingales Xt.
See e.g. Karatzas and Shreve (1991).
4.8.
a) Let Bt denote n-dimensional Brownian motion and let f: Rn →R
be C2. Use Itˆo’s formula to prove that
f(Bt) = f(B0) +
t
Z
0
∇f(Bs)dBs + 1
2
t
Z
0
∆f(Bs)ds ,
where ∆=
nP
i=1
∂2
∂x2
i is the Laplace operator.
b) Assume that g : R →R is C1 everywhere and C2 outside ﬁnitely
many points z1, . . . , zN with |g′′(x)| ≤M for x /∈{z1, . . . , zN}.
Let Bt be 1-dimensional Brownian motion. Prove that the 1-
dimensional version of a) still holds, i.e.
g(Bt) = g(B0) +
t
Z
0
g′(Bs)dBs + 1
2
t
Z
0
g′′(Bs)ds .
(Hint: Choose fk ∈C2(R) s.t. fk →g uniformly, f ′
k →g′ uni-
formly and |f ′′
k | ≤M, f ′′
k →g′′ outside z1, . . . , zN. Apply a) to fk
and let k →∞).
4.9.
Prove that we may assume that g and its ﬁrst two derivatives are
bounded in the proof of the Itˆo formula (Theorem 4.1.2) by proceeding
as follows: For ﬁxed t ≥0 and n = 1, 2, . . . choose gn as in the statement
such that gn(s, x) = g(s, x) for all s ≤t and all |x| ≤n. Suppose we
have proved that (4.1.9) holds for each gn. Deﬁne the stochastic time
τn = τn(ω) = inf{s > 0; |Xs(ω)| ≥n}
(τn is called a stopping time (See Chapter 7)) and prove that
µ
t
Z
0
v ∂gn
∂x (s, Xs)Xs≤τndBs: =
¶
t∧τn
Z
0
v ∂gn
∂x (s, Xs)dBs =
t∧τn
Z
0
v ∂g
∂x(s, Xs)dBs
for each n. This gives that

58
4. The Itˆo Formula and the Martingale ...
g(t ∧τn, Xt∧τn) = g(0, X0)
+
t∧τn
Z
0
µ∂g
∂s + u∂g
∂x + 1
2v2 ∂2g
∂x2
¶
ds +
t∧τn
Z
0
v ∂g
∂xdBs
and since
P[τn > t] →1
as n →∞
we can conclude that (4.1.9) holds (a.s.) for g.
4.10. (Tanaka’s formula and local time).
What happens if we try to apply the Itˆo formula to g(Bt) when Bt is
1-dimensional and g(x) = |x| ? In this case g is not C2 at x = 0, so we
modify g(x) near x = 0 to gϵ(x) as follows:
gϵ(x) =
½
|x|
if
|x| ≥ϵ
1
2(ϵ + x2
ϵ )
if
|x| < ϵ
where ϵ > 0.
a) Apply Exercise 4.8 b) to show that
gϵ(Bt) = gϵ(B0) +
t
Z
0
g′
ϵ(Bs)dBs + 1
2ϵ · |{s ∈[0, t]; Bs ∈(−ϵ, ϵ)}|
where |F| denotes the Lebesgue measure of the set F.
b) Prove that
t
Z
0
g′
ϵ(Bs) · XBs∈(−ϵ,ϵ)dBs =
t
Z
0
Bs
ϵ · XBs∈(−ϵ,ϵ)dBs →0
in L2(P) as ϵ →0.
(Hint: Apply the Itˆo isometry to
E
·µ
t
Z
0
Bs
ϵ · XBs∈(−ϵ,ϵ)dBs
¶2¸
.

Exercises
59
c) By letting ϵ →0 prove that
|Bt| = |B0| +
t
Z
0
sign(Bs)dBs + Lt(ω) ,
(4.3.12)
where
Lt = lim
ϵ→0
1
2ϵ · |{s ∈[0, t]; Bs ∈(−ϵ, ϵ)}|
(limit in L2(P))
and
sign(x) =
½
−1
for
x ≤0
1
for
x > 0 .
Lt is called the local time for Brownian motion at 0 and (4.3.12) is
the Tanaka formula (for Brownian motion). (See e.g. Rogers and
Williams (1987)).
4.11. Use Itˆo’s formula (for example in the form of Exercise 4.3) to prove
that the following stochastic processes are {Ft}-martingales:
a) Xt = e
1
2 t cos Bt
(Bt ∈R)
b) Xt = e
1
2 t sin Bt
(Bt ∈R)
c) Xt = (Bt + t)exp(−Bt −1
2t)
(Bt ∈R).
4.12. Let dXt = u(t, ω)dt + v(t, ω)dBt be an Itˆo process in Rn such that
E
·
t
Z
0
|u(r, ω)|dr
¸
+ E
·
t
Z
0
|vvT (r, ω)|dr
¸
< ∞
for all t ≥0 .
Suppose Xt is an {F(n)
t
}-martingale. Prove that
u(s, ω) = 0
for a.a. (s, ω) ∈[0, ∞) × Ω.
(4.3.13)
Remarks:
0)
1) This result may be regarded as a special case of the Martingale
Representation Theorem.
2) The conclusion (4.3.13) does not hold if the ﬁltration F(n)
t
is re-
placed by the σ-algebras Mt generated by Xs(·); s ≤t, i.e. if we
only assume that Xt is a martingale w.r.t. its own ﬁltration. See
e.g. the Brownian motion characterization in Chapter 8.
Hint for the solution:
If Xt is an F(n)
t
-martingale, then deduce that
E
·
s
Z
t
u(r, ω)dr|F(n)
t
¸
= 0
for all s ≥t .

60
4. The Itˆo Formula and the Martingale ...
Diﬀerentiate w.r.t. s to deduce that
E[u(s, ω)|F(n)
t
] = 0
a.s., for a.a. s > t .
Then let t ↑s and apply Corollary C.9.
4.13. Let dXt = u(t, ω)dt + dBt
(u ∈R,
Bt ∈R) be an Itˆo process
and assume for simplicity that u is bounded. Then from Exercise 4.12
we know that unless u = 0 the process Xt is not an Ft-martingale.
However, it turns out that we can construct an Ft-martingale from Xt
by multiplying by a suitable exponential martingale. More precisely,
deﬁne
Yt = XtMt
where
Mt = exp
µ
−
t
Z
0
u(r, ω)dBr −1
2
t
Z
0
u2(r, ω)dr
¶
.
Use Itˆo’s formula to prove that
Yt
is an Ft-martingale .
Remarks:
a)
a) Compare with Exercise 4.11 c).
b) This result is a special case of the important Girsanov Theorem.
It can be interpreted as follows: {Xt}t≤T is a martingale w.r.t the
measure Q deﬁned on FT by
dQ = MT dP
(T < ∞) .
See Section 8.6.
4.14. In each of the cases below ﬁnd the process f(t, ω) ∈V[0, T] such that
(4.3.6) holds, i.e.
F(ω) = E[F] +
T
Z
0
f(t, ω)dBt(ω) .
a) F(ω) = BT (ω)
b) F(ω) =
TR
0
Bt(ω)dt
c) F(ω) = B2
T (ω)
d) F(ω) = B3
T (ω)
e) F(ω) = eBT (ω)
f) F(ω) = sin BT (ω)
4.15. Let x > 0 be a constant and deﬁne
Xt = (x1/3 + 1
3Bt)3 ;
t ≥0 .
Show that
dXt = 1
3X1/3
t
dt + X2/3
t
dBt ;
X0 = x .

5. Stochastic Diﬀerential Equations
5.1 Examples and Some Solution Methods
We now return to the possible solutions Xt(ω) of the stochastic diﬀerential
equation
dXt
dt
= b(t, Xt) + σ(t, Xt)Wt,
b(t, x) ∈R, σ(t, x) ∈R
(5.1.1)
where Wt is 1-dimensional “white noise”. As discussed in Chapter 3 the Itˆo
interpretation of (5.1.1) is that Xt satisﬁes the stochastic integral equation
Xt = X0 +
t
Z
0
b(s, Xs)ds +
t
Z
0
σ(s, Xs)dBs
or in diﬀerential form
dXt = b(t, Xt)dt + σ(t, Xt)dBt .
(5.1.2)
Therefore, to get from (5.1.1) to (5.1.2) we formally just replace the white
noise Wt by dBt
dt in (5.1.1) and multiply by dt. It is natural to ask:
(A) Can one obtain existence and uniqueness theorems for such equations?
What are the properties of the solutions?
(B) How can one solve a given such equation?
We will ﬁrst consider question (B) by looking at some simple examples,
and then in Section 5.2 we will discuss (A).
It is the Itˆo formula that is the key to the solution of many stochastic
diﬀerential equations. The method is illustrated in the following examples.
Example 5.1.1. Let us return to the population growth model in Chapter 1:
dNt
dt = atNt ,
N0 given
where at = rt + αWt, Wt = white noise, α = constant.
Let us assume that rt = r = constant. By the Itˆo interpretation (5.1.2)
this equation is equivalent to (here σ(t, x) = αx)

62
5. Stochastic Diﬀerential Equations
dNt = rNtdt + αNtdBt
(5.1.3)
or
dNt
Nt
= rdt + αdBt .
Hence
t
Z
0
dNs
Ns
= rt + αBt
(B0 = 0) .
(5.1.4)
To evaluate the integral on the left hand side we use the Itˆo formula for the
function
g(t, x) = ln x ;
x > 0
and obtain
d(ln Nt) =
1
Nt
· dNt + 1
2
µ
−1
N 2
t
¶
(dNt)2
= dNt
Nt
−
1
2N 2
t
· α2N 2
t dt = dNt
Nt
−1
2α2dt .
Hence
dNt
Nt
= d(ln Nt) + 1
2α2dt
so from (5.1.4) we conclude
ln Nt
N0
= (r −1
2α2)t + αBt
or
Nt = N0 exp((r −1
2α2)t + αBt) .
(5.1.5)
For comparison, referring to the discussion at the end of Chapter 3, the
Stratonovich interpretation of (5.1.3),
dN t = rN tdt + αN t ◦dBt ,
would have given the solution
N t = N0 exp(rt + αBt) .
(5.1.6)
The solutions Nt, N t are both processes of the type
Xt = X0 exp(µt + αBt)
(µ, α constants) .
Such processes are called geometric Brownian motions. They are important
also as models for stochastic prices in economics. See Chapters 10, 11, 12.

5.1 Examples and Some Solution Methods
63
Remark.
It seems reasonable that if Bt is independent of N0 we should
have
E[Nt] = E[N0]ert,
(∗)
i.e. the same as when there is no noise in at. To see if this is indeed the case,
we let
Yt = eαBt
and apply Itˆo’s formula:
dYt = αeαBtdBt + 1
2α2eαBtdt
or
Yt = Y0 + α
t
Z
0
eαBsdBs + 1
2α2
t
Z
0
eαBsds .
Since E[
tR
0
eαBsdBs] = 0 (Theorem 3.2.1 (iii)), we get
E[Yt] = E[Y0] + 1
2α2
t
Z
0
E[Ys]ds
i.e.
d
dtE[Yt] = 1
2α2E[Yt], E[Y0] = 1 .
So
E[Yt] = e
1
2 α2t ,
and therefore – as anticipated – we obtain
E[Nt] = E[N0]ert .
For the Stratonovich solution, however, the same calculation gives
E[N t] = E[N0]e(r+ 1
2 α2)t .
Now that we have found the explicit solutions Nt and N t in (5.1.5), (5.1.6)
we can use our knowledge about the behaviour of Bt to gain information on
these solutions. For example, for the Itˆo solution Nt we get the following:
(i)
If r > 1
2α2 then Nt →∞as t →∞, a.s.
(ii) If r < 1
2α2 then Nt →0 as t →∞, a.s.
(iii) If r = 1
2α2 then Nt will ﬂuctuate between arbitrary large and arbitrary
small values as t →∞, a.s.
These conclusions are direct consequences of the formula (5.1.5) for Nt
together with the following basic result about 1-dimensional Brownian motion
Bt:

64
5. Stochastic Diﬀerential Equations
Theorem 5.1.2 (The law of iterated logarithm).
lim sup
t→∞
Bt
√2t log log t = 1 a.s.
For a proof we refer to Lamperti (1977), §22.
For the Stratonovich solution N t we get by the same argument that N t →
0 a.s. if r < 0 and N t →∞a.s. if r > 0.
Thus the two solutions have fundamentally diﬀerent properties and it is an
interesting question what solution gives the best description of the situation.
Example 5.1.3. Let us return to the equation in Problem 2 of Chapter 1:
LQ′′
t + RQ′
t + 1
C Qt = Ft = Gt + αWt .
(5.1.7)
We introduce the vector
X = X(t, ω) =


X1
X2


=


Qt
Q′
t



and obtain
½X′
1 = X2
LX′
2 = −RX2 −1
C X1 + Gt + αWt
(5.1.8)
or, in matrix notation,
dX = dX(t) = AX(t)dt + H(t)dt + KdBt
(5.1.9)
where
dX =
µ
dX1
dX2
¶
, A=
µ
0
1
−1
CL
−R
L
¶
, H(t) =
µ
0
1
LGt
¶
, K =
µ
0
α
L
¶
,
(5.1.10)
and Bt is a 1-dimensional Brownian motion.
Thus we are led to a 2-dimensional stochastic diﬀerential equation. We
rewrite (5.1.9) as
exp(−At)dX(t) −exp(−At)AX(t)dt = exp(−At)[H(t)dt + KdBt] , (5.1.11)
where for a general n × n matrix F we deﬁne exp(F) to be the n × n matrix
given by exp(F) =
∞
P
n=0
1
n!F n. Here it is tempting to relate the left hand side
to
d(exp(−At)X(t)) .
To do this we use a 2-dimensional version of the Itˆo formula (Theorem 4.2.1).
Applying this result to the two coordinate functions g1, g2 of
g: [0, ∞) × R2 →R2
given by
g(t, x1, x2) = exp(−At)
µ
x1
x2
¶
,

5.1 Examples and Some Solution Methods
65
we obtain that
d(exp(−At)X(t)) = (−A) exp(−At)X(t)dt + exp(−At)dX(t) .
Substituted in (5.1.11) this gives
exp(−At)X(t) −X(0) =
t
Z
0
exp(−As)H(s)ds +
t
Z
0
exp(−As)KdBs
or
X(t) = exp(At)[X(0) + exp(−At)KBt
+
t
Z
0
exp(−As)[H(s) + AKBs]ds] ,
(5.1.12)
by integration by parts (Theorem 4.1.5).
Example 5.1.4. Choose X = B, 1-dimensional Brownian motion, and
g(t, x) = eix = (cos x, sin x) ∈R2
for x ∈R .
Then
Y = g(t, X) = eiB = (cos B, sin B)
is by Itˆo’s formula again an Itˆo process.
Its coordinates Y1, Y2 satisfy
(
dY1(t) = −sin(B)dB −1
2 cos(B)dt
dY2(t) = cos(B)dB −1
2 sin(B)dt .
Thus the process Y = (Y1, Y2), which we could call Brownian motion on the
unit circle, is the solution of the stochastic diﬀerential equations
(
dY1 = −1
2Y1dt −Y2dB
dY2 = −1
2Y2dt + Y1dB .
(5.1.13)
Or, in matrix notation,
dY = −1
2Y dt + KY dB ,
where K =
µ
0
−1
1
0
¶
.
Other examples and solution methods can be found in the exercises of
this chapter.
For a comprehensive description of reduction methods for 1-dimensional
stochastic diﬀerential equations see Gard (1988), Chapter 4.

66
5. Stochastic Diﬀerential Equations
5.2 An Existence and Uniqueness Result
We now turn to the existence and uniqueness question (A) above.
Theorem 5.2.1. (Existence and uniqueness theorem for stochastic
diﬀerential equations).
Let T > 0 and b(·, ·): [0, T] × Rn →Rn, σ(·, ·): [0, T] × Rn →Rn×m be
measurable functions satisfying
|b(t, x)| + |σ(t, x)| ≤C(1 + |x|) ;
x∈Rn, t∈[0, T]
(5.2.1)
for some constant C, (where |σ|2 = P |σij|2) and such that
|b(t, x) −b(t, y)| + |σ(t, x) −σ(t, y)| ≤D|x −y| ;
x, y∈Rn, t∈[0, T] (5.2.2)
for some constant D. Let Z be a random variable which is independent of the
σ-algebra F(m)
∞
generated by Bs(·), s ≥0 and such that
E[|Z|2] < ∞.
Then the stochastic diﬀerential equation
dXt = b(t, Xt)dt + σ(t, Xt)dBt ,
0≤t ≤T, X0 = Z
(5.2.3)
has a unique t-continuous solution Xt(ω) with the property that
Xt(ω) is adapted to the ﬁltration FZ
t generated by Z and Bs(·); s ≤t
(5.2.4)
and
E
·
T
Z
0
|Xt|2dt
¸
< ∞.
(5.2.5)
Remarks. Conditions (5.2.1) and (5.2.2) are natural in view of the following
two simple examples from deterministic diﬀerential equations (i.e. σ = 0):
a) The equation
dXt
dt
= X2
t ,
X0 = 1
(5.2.6)
corresponding to b(x) = x2 (which does not satisfy (5.2.1)) has the
(unique) solution
Xt =
1
1 −t ;
0 ≤t < 1 .
Thus it is impossible to ﬁnd a global solution (deﬁned for all t) in this
case.
More generally, condition (5.2.1) ensures that the solution Xt(ω) of (5.2.3)
does not explode, i.e. that |Xt(ω)| does not tend to ∞in a ﬁnite time.

5.2 An Existence and Uniqueness Result
67
b) The equation
dXt
dt
= 3X2/3
t
;
X0 = 0
(5.2.7)
has more than one solution. In fact, for any a > 0 the function
Xt =
½
0
for
t ≤a
(t −a)3
for
t > a
solves (5.2.7). In this case b(x) = 3x2/3 does not satisfy the Lipschitz
condition (5.2.2) at x = 0.
Thus condition (5.2.2) guarantees that equation (5.2.3) has a unique so-
lution. Here uniqueness means that if X1(t, ω) and X2(t, ω) are two t-
continuous processes satisfying (5.2.3), (5.2.4) and (5.2.5) then
X1(t, ω) = X2(t, ω)
for all t ≤T, a.s.
(5.2.8)
Proof of Theorem 5.2.1.
The uniqueness follows from the Itˆo isometry
(Corollary 3.1.7) and the Lipschitz property (5.2.2): Let X1(t, ω) = Xt(ω)
and X2(t, ω) = b
Xt(ω) be solutions with initial values Z, bZ respectively, i.e.
X1(0, ω) = Z(ω), X2(0, ω) = bZ(ω), ω ∈Ω. For our purposes here we only
need the case Z = bZ, but the following more general estimate will be useful
for us later, in connection with Feller continuity (Chapter 8).
Put a(s, ω) = b(s, Xs) −b(s, b
Xs) and γ(s, ω) = σ(s, Xs) −σ(s, b
Xs). Then
E[|Xt −b
Xt|2] = E
·µ
Z −bZ +
t
Z
0
ads +
t
Z
0
γdBs
¶2¸
≤3E[|Z −bZ|2] + 3E
·µ
t
Z
0
ads
¶2¸
+ 3E
·µ
t
Z
0
γdBs
¶2¸
≤3E[|Z −bZ|2] + 3tE
·
t
Z
0
a2ds
¸
+ 3E
·
t
Z
0
γ2ds
¸
≤3E[|Z −bZ|2] + 3(1 + t)D2
t
Z
0
E[|Xs −b
Xs|2]ds .
So the function
v(t) = E[|Xt −b
Xt|2] ;
0 ≤t ≤T
satisﬁes
v(t) ≤F + A
t
Z
0
v(s)ds ,
(5.2.9)
where F = 3E[|Z −bZ|2] and A = 3(1 + T)D2 .

68
5. Stochastic Diﬀerential Equations
By the Gronwall inequality (Exercise 5.17) we conclude that
v(t) ≤F exp(At) .
(5.2.10)
Now assume that Z = bZ. Then F = 0 and so v(t) = 0 for all t ≥0. Hence
P[|Xt −b
Xt| = 0
for all t ∈Q ∩[0, T]] = 1 ,
where Q denotes the rational numbers.
By continuity of t →|Xt −b
Xt| it follows that
P[|X1(t, ω) −X2(t, ω)| = 0
for all t ∈[0, T]] = 1 ,
(5.2.11)
and the uniqueness is proved.
The proof of the existence is similar to the familiar existence proof for
ordinary diﬀerential equations: Deﬁne Y (0)
t
= X0 and Y (k)
t
= Y (k)
t
(ω) induc-
tively as follows
Y (k+1)
t
= X0 +
t
Z
0
b(s, Y (k)
s
)ds +
t
Z
0
σ(s, Y (k)
s
)dBs .
(5.2.12)
Then, similar computation as for the uniqueness above gives
E[|Y (k+1)
t
−Y (k)
t
|2] ≤(1 + T)3D2
t
Z
0
E[|Y (k)
s
−Y (k−1)
s
|2]ds ,
for k ≥1, t ≤T and
E[|Y (1)
t
−Y (0)
t
|2] ≤2C2t2(1 + E[|X0|2])
+2C2t(1 + E[|X0|2]) ≤A1t
where the constant A1 only depends on C, T and E[|X0|2]. So by induction
on k we obtain
E[|Y (k+1)
t
−Y (k)
t
|2] ≤Ak+1
2
tk+1
(k + 1)! ;
k ≥0, t ∈[0, T]
(5.2.13)
for some suitable constant A2 depending only on C, D, T and E[|X0|2]. Now
sup
0≤t≤T
|Y (k+1)
t
−Y (k)
t
| ≤
T
Z
0
|b(s, Y (k)
s
) −b(s, Y (k−1)
s
)|ds
+ sup
0≤t≤T
¯¯¯¯
t
Z
0
(σ(s, Y (k)
s
) −σ(s, Y (k−1)
s
))dBs
¯¯¯¯ .

5.2 An Existence and Uniqueness Result
69
By the martingale inequality (Theorem 3.2.4) we obtain
P
·
sup
0≤t≤T
|Y (k+1)
t
−Y (k)
t
| > 2−k
¸
≤P
·µ
T
Z
0
|b(s, Y (k)
s
) −b(s, Y (k−1)
s
)|ds
¶2
> 2−2k−2
¸
+P
·
sup
0≤t≤T
¯¯¯¯
t
Z
0
(σ(s, Y (k)
s
) −σ(s, Y (k−1)
s
))dBs
¯¯¯¯ > 2−k−1
¸
≤22k+2T
T
Z
0
E(|b(s, Y (k)
s
) −b(s, Y (k−1)
s
)|2)ds
+22k+2
T
Z
0
E[|σ(s, Y (k)
s
) −σ(s, Y (k−1)
s
)|2]ds
≤22k+2D2(T + 1)
T
Z
0
Ak
2tk
k! dt ≤(4A2T)k+1
(k + 1)!
,
if A2 ≥D2(T + 1) .
Therefore, by the Borel-Cantelli lemma,
P
·
sup
0≤t≤T
|Y (k+1)
t
−Y (k)
t
| > 2−k
for inﬁnitely many k
¸
= 0 .
Thus, for a.a. ω there exists k0 = k0(ω) such that
sup
0≤t≤T
|Y (k+1)
t
−Y (k)
t
| ≤2−k
for k ≥k0 .
Therefore the sequence
Y (n)
t
(ω) = Y (0)
t
(ω) +
n−1
X
k=0
(Y (k+1)
t
(ω) −Y (k)
t
(ω))
is uniformly convergent in [0, T], for a.a. ω.
Denote the limit by Xt = Xt(ω). Then Xt is t-continuous for a.a. ω since
Y (n)
t
is t-continuous for all n. Moreover, Xt(·) is FZ
t -measurable for all t,
since Y (n)
t
(·) has this property for all n.
Next, note that for m > n ≥0 we have by (5.2.13)
E[|Y (m)
t
−Y (n)
t
|2]1/2 = ∥Y (m)
t
−Y (n)
t
∥L2(P ) =
°°°
m−1
X
k=n
(Y (k+1)
t
−Y (k)
t
)
°°°
L2(P )
≤
m−1
X
k=n
∥Y (k+1)
t
−Y (k)
t
∥L2(P ) ≤
∞
X
k=n
·(A2t)k+1
(k + 1)!
¸1/2
→0
as n→∞.
(5.2.14)

70
5. Stochastic Diﬀerential Equations
So {Y (n)
t
} converges in L2(P) to a limit Yt, say. A subsequence of Y (n)
t
(ω)
will then converge ω-pointwise to Yt(ω) and therefore we must have Yt = Xt
a.s. In particular, Xt satisﬁes (5.2.4) and (5.2.5).
It remains to show that Xt satisﬁes (5.2.3). For all n we have
Y (n+1)
t
= X0 +
t
Z
0
b(s, Y (n)
s
)ds +
t
Z
0
σ(s, Y (n)
s
)dBs .
(5.2.15)
Now Y (n+1)
t
→Xt as n →∞, uniformly in t ∈[0, T] for a.a. ω. By (5.2.14)
and the Fatou lemma we have
E
·
T
Z
0
|Xt −Y (n)
t
|2dt
¸
≤lim sup
m→∞E
·
T
Z
0
|Y (m)
t
−Y (n)
t
|2dt
¸
→0
as n →∞. It follows by the Itˆo isometry that
t
Z
0
σ(s, Y (n)
s
)dBs →
t
Z
0
σ(s, Xs)dBs
and by the H¨older inequality that
t
Z
0
b(s, Y (n)
s
)ds →
t
Z
0
b(s, Xs)ds
in L2(P). Therefore, taking the limit of (5.2.15) as n →∞we obtain (5.2.3)
for Xt.
⊔⊓
5.3 Weak and Strong Solutions
The solution Xt found above is called a strong solution, because the version
Bt of Brownian motion is given in advance and the solution Xt constructed
from it is FZ
t -adapted. If we are only given the functions b(t, x) and σ(t, x)
and ask for a pair of processes (( e
Xt, eBt), Ht) on a probability space (Ω, H, P)
such that (5.2.3) holds, then the solution e
Xt (or more precisely ( e
Xt, eBt)) is
called a weak solution. Here Ht is an increasing family of σ-algebras such that
e
Xt is Ht-adapted and eBt is an Ht-Brownian motion, i.e. eBt is a Brownian
motion, and eBt is a martingale w.r.t. Ht (and so E[ eBt+h −eBt|Ht] = 0 for all
t, h ≥0). Recall from Chapter 3 that this allows us to deﬁne the Itˆo integral
on the right hand side of (5.2.3) exactly as before, even though e
Xt need not
be FZ
t -adapted.

5.3 Weak and Strong Solutions
71
A strong solution is of course also a weak solution, but the converse is not
true in general. See Example 5.3.2 below.
The uniqueness (5.2.8) that we obtain above is called strong or path-
wise uniqueness, while weak uniqueness simply means that any two solutions
(weak or strong) are identical in law, i.e. have the same ﬁnite-dimensional
distributions. See Stroock and Varadhan (1979) for results about existence
and uniqueness of weak solutions. A general discussion about strong and weak
solutions can be found in Krylov and Zvonkin (1981).
Lemma 5.3.1. If b and σ satisfy the conditions of Theorem 5.2.1 then we
have
A solution (weak or strong) of (5.2.3) is weakly unique .
Sketch of proof . Let (( e
Xt, eBt), e
Ht) and (( b
Xt, bBt), b
Ht) be two weak solutions.
Let Xt and Yt be the strong solutions constructed from eBt and bBt, respec-
tively, as above. Then the same uniqueness argument as above applies to show
that Xt = e
Xt and Yt = b
Xt for all t, a.s. Therefore it suﬃces to show that Xt
and Yt must be identical in law. We show this by proving by induction that if
X(k)
t
, Y (k)
t
are the processes in the Picard iteration deﬁned by (5.2.12) with
Brownian motions eBt and bBt, then
(X(k)
t
, eBt)
and
(Y (k)
t
, bBt)
have the same law for all k.
⊔⊓
This observation will be useful for us in Chapter 7 and later, where we
will investigate further the properties of processes which are solutions of
stochastic diﬀerential equations (Itˆo diﬀusions).
From a modelling point of view the weak solution concept is often natural,
because it does not specify beforehand the explicit representation of the white
noise. Moreover, the concept is convenient for mathematical reasons, because
there are stochastic diﬀerential equations which have no strong solutions but
still a (weakly) unique weak solution. Here is a simple example:
Example 5.3.2 (The Tanaka equation). Consider the 1-dimensional sto-
chastic diﬀerential equation
dXt = sign(Xt)dBt ;
X0 = 0 .
(5.3.1)
where
sign(x) =
½
+1 if x ≥0
−1 if x < 0 .
Note that here σ(t, x) = σ(x) = sign(x) does not satisfy the Lipschitz con-
dition (5.2.2), so Theorem 5.2.1 does not apply. Indeed, the equation (5.3.1)
has no strong solution. To see this, let bBt be a Brownian motion generating
the ﬁltration bFt and deﬁne

72
5. Stochastic Diﬀerential Equations
Yt =
t
Z
0
sign( bBs)d bBs .
By the Tanaka formula (4.3.12) (Exercise 4.10) we have
Yt = | bBt| −| bB0| −bLt(ω) ,
where bLt(ω) is the local time for bBt(ω) at 0. It follows that Yt is measurable
w.r.t. the σ-algebra Gt generated by | bBs(·)|; s ≤t, which is clearly strictly
contained in bFt. Hence the σ-algebra Nt generated by Ys(·); s ≤t is also
strictly contained in bFt.
Now suppose Xt is a strong solution of (5.3.1). Then by Theorem 8.4.2
it follows that Xt is a Brownian motion w.r.t. the measure P. (In case the
reader is worried about the possibility of a circular argument, we point out
that the proof of Theorem 8.4.2 is independent of this example!) Let Mt be
the σ-algebra generated by Xs(·); s ≤t. Since (sign(x))2 = 1 we can rewrite
(5.3.1) as
dBt = sign(Xt)dXt .
By the above argument applied to bBt = Xt, Yt = Bt we conclude that Ft is
strictly contained in Mt.
But this contradicts that Xt is a strong solution. Hence strong solutions
of (5.3.1) do not exist.
To ﬁnd a weak solution of (5.3.1) we simply choose Xt to be any Brownian
motion bBt. Then we deﬁne eBt by
eBt =
t
Z
0
sign( bBs)d bBs =
t
Z
0
sign(Xs)dXs
i.e.
d eBt = sign(Xt)dXt .
Then
dXt = sign(Xt)d eBt ,
so Xt is a weak solution.
Finally, weak uniqueness follows from Theorem 8.4.2, which – as noted
above – implies that any weak solution Xt must be a Brownian motion w.r.t.
P.
Exercises
5.1.
Verify that the given processes solve the given corresponding stochastic
diﬀerential equations: (Bt denotes 1-dimensional Brownian motion)

Exercises
73
(i)
Xt = eBt solves dXt = 1
2Xtdt + XtdBt
(ii) Xt =
Bt
1+t; B0 = 0 solves
dXt = −
1
1 + tXtdt +
1
1 + tdBt ;
X0 = 0
(iii) Xt = sin Bt with B0 = a ∈(−π
2 , π
2 ) solves
dXt =−1
2Xtdt +
q
1−X2
t dBt for t < inf
©
s > 0; Bs /∈
£
−π
2 , π
2
¤ª
(iv) (X1(t), X2(t)) = (t, etBt) solves
·
dX1
dX2
¸
=
·
1
X2
¸
dt +
·
0
eX1
¸
dBt
(v)
(X1(t), X2(t)) = (cosh(Bt), sinh(Bt)) solves
·
dX1
dX2
¸
= 1
2
·
X1
X2
¸
dt +
·
X2
X1
¸
dBt .
5.2.
A natural candidate for what we could call Brownian motion on the
ellipse
n
(x, y); x2
a2 + y2
b2 = 1
o
where a > 0, b > 0
is the process Xt = (X1(t), X2(t)) deﬁned by
X1(t) = a cos Bt ,
X2(t) = b sin Bt
where Bt is 1-dimensional Brownian motion. Show that Xt is a solution
of the stochastic diﬀerential equation
dXt = −1
2Xtdt + MXtdBt
where M =
· 0
−a
b
b
a
0
¸
.
5.3.
Let (B1, . . . , Bn) be Brownian motion in Rn, α1, . . . , αn constants.
Solve the stochastic diﬀerential equation
dXt = rXtdt + Xt
³
n
X
k=1
αkdBk(t)
´
;
X0 > 0 .
(This is a model for exponential growth with several independent white
noise sources in the relative growth rate).
5.4.
Solve the following stochastic diﬀerential equations:

74
5. Stochastic Diﬀerential Equations
(i)
·
dX1
dX2
¸
=
·
1
0
¸
dt +
·
1
0
0
X1
¸ ·
dB1
dB2
¸
(ii) dXt = Xtdt + dBt
(Hint: Multiply both sides with “the integrating factor” e−t and
compare with d(e−tXt))
(iii) dXt = −Xtdt + e−tdBt.
5.5.
a) Solve the Ornstein-Uhlenbeck equation (or Langevin equation)
dXt = µXtdt + σdBt
where µ, σ are real constants, Bt ∈R.
The solution is called the Ornstein-Uhlenbeck process. (Hint: See
Exercise 5.4 (ii).)
b) Find E[Xt] and Var[Xt]: = E[(Xt −E[Xt])2].
5.6.
Solve the stochastic diﬀerential equation
dYt = r dt + αYtdBt
where r, α are real constants, Bt ∈R.
(Hint: Multiply the equation by the ’integrating factor’
Ft = exp
¡
−αBt + 1
2α2t
¢
. )
5.7.
The mean-reverting Ornstein-Uhlenbeck process is the solution Xt of
the stochastic diﬀerential equation
dXt = (m −Xt)dt + σdBt
where m, σ are real constants, Bt ∈R.
a) Solve this equation by proceeding as in Exercise 5.5 a).
b) Find E[Xt] and Var[Xt]: = E[(Xt −E[Xt])2].
5.8.
Solve the (2-dimensional) stochastic diﬀerential equation
dX1(t) = X2(t)dt + αdB1(t)
dX2(t) = −X1(t)dt + βdB2(t)
where (B1(t), B2(t)) is 2-dimensional Brownian motion and α, β are
constants.
This is a model for a vibrating string subject to a stochastic force. See
Example 5.1.3.
5.9.
Show that there is a unique strong solution Xt of the 1-dimensional
stochastic diﬀerential equation
dXt = ln(1 + X2
t )dt + X{Xt>0}XtdBt ,
X0 = a ∈R .

Exercises
75
5.10. Let b, σ satisfy (5.2.1), (5.2.2) and let Xt be the unique strong solution
of (5.2.3). Show that
E[|Xt|2] ≤K1 · exp(K2t)
for t ≤T
(5.3.2)
where K1 = 3E[|Z|2] + 6C2T(T + 1) and K2 = 6(1 + T)C2.
(Hint: Use the argument in the proof of (5.2.10)).
Remark.
With global estimates of the growth of b and σ in (5.2.1) it is
possible to improve (5.3.2) to a global estimate of E[|Xt|2]. See Exercise 7.5.
5.11. (The Brownian bridge).
For ﬁxed a, b ∈R consider the following 1-dimensional equation
dYt = b −Yt
1 −t dt + dBt ;
0 ≤t < 1 , Y0 = a .
(5.3.3)
Verify that
Yt = a(1 −t) + bt + (1 −t)
t
Z
0
dBs
1 −s ;
0 ≤t < 1
(5.3.4)
solves the equation and prove that lim
t→1 Yt = b a.s. The process Yt is
called the Brownian bridge (from a to b). For other characterizations
of Yt see Rogers and Williams (1987, pp. 86–89).
5.12. To describe the motion of a pendulum with small, random perturba-
tions in its environment we try an equation of the form
y′′(t) + (1 + ϵWt)y = 0 ;
y(0), y′(0) given ,
where Wt = dBt
dt is 1-dimensional white noise, ϵ > 0 is constant.
a) Discuss this equation, for example by proceeding as in Exam-
ple 5.1.3.
b) Show that y(t) solves a stochastic Volterra equation of the form
y(t) = y(0) + y′(0) · t +
t
Z
0
a(t, r)y(r)dr +
t
Z
0
γ(t, r)y(r)dBr
where a(t, r) = r −t, γ(t, r) = ϵ(r −t).
5.13. As a model for the horizontal slow drift motions of a moored ﬂoating
platform or ship responding to incoming irregular waves John Grue
(1989) introduced the equation
x′′
t + a0x′
t + w2xt = (T0 −α0x′
t)ηWt ,
(5.3.5)
where Wt is 1-dimensional white noise, a0, w, T0, α0 and η are con-
stants.

76
5. Stochastic Diﬀerential Equations
(i)
Put Xt =
·
xt
x′
t
¸
and rewrite the equation in the form
dXt = AXtdt + KXtdBt + MdBt ,
where
A=
·
0
1
−w2
−a0
¸
,
K =α0η
·
0
0
0
−1
¸
and
M =T0η
·
0
1
¸
.
(ii) Show that Xt satisﬁes the integral equation
Xt =
t
Z
0
eA(t−s)KXsdBs +
t
Z
0
eA(t−s)MdBs
if X0 = 0 .
(iii) Verify that
eAt = e−λt
ξ
{(ξ cos ξt + λ sin ξt)I + A sin ξt}
where λ = a0
2 , ξ = (w2 −a2
0
4 )
1
2 and use this to prove that
xt = η
t
Z
0
(T0 −α0ys)gt−sdBs
(5.3.6)
and
yt = η
t
Z
0
(T0 −α0ys)ht−sdBs ,
with yt: = x′
t ,
(5.3.7)
where
gt = 1
ξ Im(eζt)
ht = 1
ξ Im(ζe
¯ζt) ,
ζ = −λ + iξ
(i =
√
−1) .
So we can solve for yt ﬁrst in (5.3.7) and then substitute in (5.3.6)
to ﬁnd xt.
5.14. If (B1, B2) denotes 2-dimensional Brownian motion we may introduce
complex notation and put
B(t): = B1(t) + iB2(t)
(i =
√
−1) .
B(t) is called complex Brownian motion.

Exercises
77
(i) If F(z) = u(z) + iv(z) is an analytic function i.e. F satisﬁes the
Cauchy-Riemann equations
∂u
∂x = ∂v
∂y ,
∂u
∂y = −∂v
∂x ;
z = x + iy
and we deﬁne
Zt = F(B(t))
prove that
dZt = F ′(B(t))dB(t) ,
(5.3.8)
where F ′ is the (complex) derivative of F. (Note that the usual
second order terms in the (real) Itˆo formula are not present in
(5.3.8)!)
(ii) Solve the complex stochastic diﬀerential equation
dZt = αZtdB(t)
α constant) .
For more information about complex stochastic calculus involving
analytic functions see e.g. Ubøe (1987).
5.15. (Population growth in a stochastic, crowded environment)
The nonlinear stochastic diﬀerential equation
dXt = rXt(K −Xt)dt + βXtdBt ;
X0 = x > 0
(5.3.9)
is often used as a model for the growth of a population of size Xt in
a stochastic, crowded environment. The constant K > 0 is called the
carrying capacity of the environment, the constant r ∈R is a measure
of the quality of the environment and the constant β ∈R is a measure
of the size of the noise in the system.
Verify that
Xt =
exp{(rK −1
2β2)t + βBt}
x−1 + r
tR
0
exp{(rK −1
2β2)s + βBs}ds
;
t ≥0
(5.3.10)
is the unique (strong) solution of (5.3.9). (This solution can be found by
performing a substitution (change of variables) which reduces (5.3.9)
to a linear equation. See Gard (1988), Chapter 4 for details.)
5.16. The technique used in Exercise 5.6 can be applied to more general
nonlinear stochastic diﬀerential equations of the form
dXt = f(t, Xt)dt + c(t)XtdBt ,
X0 = x
(5.3.11)
where f: R × R →R and c: R →R are given continuous (determinis-
tic) functions. Proceed as follows:

78
5. Stochastic Diﬀerential Equations
a) Deﬁne the ’integrating factor’
Ft = Ft(ω) = exp
µ
−
t
Z
0
c(s)dBs + 1
2
t
Z
0
c2(s)ds
¶
.
(5.3.12)
Show that (5.3.11) can be written
d(FtXt) = Ft · f(t, Xt)dt .
(5.3.13)
b) Now deﬁne
Yt(ω) = Ft(ω)Xt(ω)
(5.3.14)
so that
Xt = F −1
t
Yt .
(5.3.15)
Deduce that equation (5.3.13) gets the form
dYt(ω)
dt
= Ft(ω) · f(t, F −1
t
(ω)Yt(ω)) ;
Y0 = x .
(5.3.16)
Note that this is just a deterministic diﬀerential equation in the
function t →Yt(ω), for each ω ∈Ω. We can therefore solve (5.3.16)
with ω as a parameter to ﬁnd Yt(ω) and then obtain Xt(ω) from
(5.3.15).
c) Apply this method to solve the stochastic diﬀerential equation
dXt = 1
Xt
dt + αXtdBt ;
X0 = x > 0
(5.3.17)
where α is constant.
d) Apply the method to study the solutions of the stochastic diﬀeren-
tial equation
dXt = Xγ
t dt + αXtdBt ;
X0 = x > 0
(5.3.18)
where α and γ are constants.
For what values of γ do we get explosion?
5.17. (The Gronwall inequality)
Let v(t) be a nonnegative function such that
v(t) ≤C + A
t
Z
0
v(s)ds
for 0 ≤t ≤T
for some constants C, A. Prove that
v(t) ≤C exp(At)
for 0 ≤t ≤T .
(5.3.19)

Exercises
79
(Hint: We may assume A ̸= 0. Deﬁne w(t) =
tR
0
v(s)ds . Then w′(t) ≤
C + Aw(t). Deduce that
w(t) ≤C
A(exp(At) −1)
(5.3.20)
by considering f(t): = w(t) exp(−At).
Use (5.3.20) to deduce (5.3.19.)

80
5. Stochastic Diﬀerential Equations

6. The Filtering Problem
6.1 Introduction
Problem 3 in the introduction is a special case of the following general ﬁltering
problem:
Suppose the state Xt ∈Rn at time t of a system is given by a stochastic
diﬀerential equation
dXt
dt
= b(t, Xt) + σ(t, Xt)Wt ,
t ≥0 ,
(6.1.1)
where b: Rn+1 →Rn, σ: Rn+1 →Rn×p satisfy conditions (5.2.1), (5.2.2) and
Wt is p-dimensional white noise. As discussed earlier the Itˆo interpretation
of this equation is
(system)
dXt = b(t, Xt)dt + σ(t, Xt)dUt ,
(6.1.2)
where Ut is p-dimensional Brownian motion. We also assume that the distri-
bution of X0 is known and independent of Ut. Similarly to the 1-dimensional
situation (3.3.6) there is an explicit several-dimensional formula which ex-
presses the Stratonovich interpretation of (6.1.1):
dXt = b(t, Xt)dt + σ(t, Xt) ◦dUt
in terms of Itˆo integrals as follows:
dXt = eb(t, Xt)dt + σ(t, Xt)dUt ,
where
ebi(t, x) = bi(t, x) + 1
2
p
X
j=1
n
X
k=1
∂σij
∂xk
σkj ;
1 ≤i ≤n .
(6.1.3)
(See Stratonovich (1966)). From now on we will use the Itˆo interpretation
(6.1.2).
In the continuous version of the ﬁltering problem we assume that the
observations Ht ∈Rm are performed continuously and are of the form
Ht = c(t, Xt) + γ(t, Xt) · f
Wt ,
(6.1.4)

82
6. The Filtering Problem
where c: Rn+1 →Rm, γ: Rn+1 →Rm×r are functions satisfying (5.2.1) and
f
Wt denotes r-dimensional white noise, independent of Ut and X0.
To obtain a tractable mathematical interpretation of (6.1.4) we introduce
Zt =
t
Z
0
Hsds
(6.1.5)
and thereby we obtain the stochastic integral representation
(observations)
dZt = c(t, Xt)dt + γ(t, Xt)dVt ,
Z0 = 0
(6.1.6)
where Vt is r-dimensional Brownian motion, independent of Ut and X0.
Note that if Hs is known for 0≤s≤t, then Zs is also known for 0≤s≤t
and conversely. So no information is lost or gained by considering Zt as our
“observations” instead of Ht. But this allows us to obtain a well-deﬁned
mathematical model of the situation.
The ﬁltering problem is the following:
Given the observations Zs satisfying (6.1.6) for 0 ≤s ≤t, what is the best
estimate b
Xt of the state Xt of the system (6.1.2) based on these observations?
As we have pointed out earlier, it is necessary to ﬁnd a precise mathe-
matical formulation of this problem: By saying that the estimate b
Xt is based
on the observations {Zs; s ≤t} we mean that
b
Xt(·)
is Gt-measurable,
where Gt is the σ-algebra generated by {Zs(·), s ≤t} .
(6.1.7)
By saying that b
Xt is the best such estimate we mean that
Z
Ω
|Xt −b
Xt|2dP = E[|Xt −b
Xt|2] = inf{E[|Xt −Y |2]; Y ∈K} .
(6.1.8)
Here – and in the rest of this chapter – (Ω, F, P) is the probability space
corresponding to the (p + r)-dimensional Brownian motion (Ut, Vt) starting
at 0, E denotes expectation w.r.t. P and
K: = Kt: = K(Z, t): = {Y : Ω→Rn; Y ∈L2(P) and Y is Gt-measurable} ,
(6.1.9)
where L2(P) = L2(Ω, P).
Having found the mathematical formulation of our problem, we now start
to study the properties of the solution b
Xt.
We ﬁrst establish the following useful connection between conditional ex-
pectation and projection:
Lemma 6.1.1. Let H ⊂F be a σ-algebra and let X ∈L2(P) be F-
measurable. Put N = {Y ∈L2(P); Y is H-measurable} and let PN denote

6.2 The 1-Dimensional Linear Filtering Problem
83
the (orthogonal) projection from the Hilbert space L2(P) into the subspace
N. Then
PN (X) = E[X|H] .
Proof. Recall (see Appendix B) that E[X|H] is by deﬁnition the P-unique
function from Ωto R such that
(i) E[X|H] is H-measurable
(ii)
R
A
E[X|H]dP =
R
A
XdP for all A ∈H.
Now PN (X) is H-measurable and
Z
Ω
Y (X −PN (X))dP = 0
for all Y ∈N .
In particular,
Z
A
(X −PN (X))dP = 0
for all A ∈H
i.e.
Z
A
PN (X)dP =
Z
A
XdP
for all A ∈H .
Hence, by uniqueness, PN (X) = E[X|H].
⊔⊓
From the general theory of Hilbert spaces we know that the solution b
Xt
of the problem (6.1.8) is given by the projection PKt(Xt). Therefore Lemma
6.1.1 leads to the following useful result:
Theorem 6.1.2.
b
Xt = PKt(Xt) = E[Xt|Gt] .
This is the basis for the general Fujisaki-Kallianpur-Kunita equation of ﬁl-
tering theory. See for example Bensoussan (1992), Davis (1984) or Kallianpur
(1980).
6.2 The 1-Dimensional Linear Filtering Problem
From now on we will concentrate on the linear case, which allows an explicit
solution in terms of a stochastic diﬀerential equation for b
Xt (the Kalman-
Bucy ﬁlter):
In the linear ﬁltering problem the system and observation equations have
the form:

84
6. The Filtering Problem
(linear system)
dXt =F(t)Xtdt+C(t)dUt;
F(t)∈Rn×n, C(t)∈Rn×p
(6.2.1)
(linear observations)
dZt =G(t)Xtdt+D(t)dVt;
G(t)∈Rm×n, D(t)∈Rm×r
(6.2.2)
To be able to focus on the main ideas in the solution of the ﬁltering
problem, we will ﬁrst consider only the 1-dimensional case:
(linear system)
dXt = F(t)Xtdt + C(t)dUt; F(t), C(t) ∈R
(6.2.3)
(linear observations)
dZt = G(t)Xtdt + D(t)dVt; G(t), D(t) ∈R
(6.2.4)
We assume (see (5.2.1)) that F, G, C, D are bounded on bounded intervals.
Based on our interpretation (6.1.5) of Zt we assume Z0 = 0. We also assume
that X0 is normally distributed (and independent of {Ut}, {Vt}). Finally we
assume that D(t) is bounded away from 0 on bounded intervals.
The (important) extension to the several-dimensional case (6.2.1), (6.2.2)
is technical, but does not require any essentially new ideas. Therefore we shall
only state the result for this case (in the next section) after we have discussed
the 1-dimensional situation. The reader is encouraged to work out the nec-
essary modiﬁcations for the general case for himself or consult Bensoussan
(1992), Davis (1977) or Kallianpur (1980) for a full treatment.
From now on we let Xt, Zt be processes satisfying (6.2.3), (6.2.4). Here is
an outline of the solution of the ﬁltering problem in this case.
Step 1.
Let L = L(Z, t) be the closure in L2(P) of functions which are
linear combinations of the form
c0 + c1Zs1(ω) + · · · + ckZsk(ω) ,
with sj ≤t, cj ∈R .
Let
PL
denote the projection from L2(P) onto L .
Then, with K as in (6.1.9),
b
Xt = PK(Xt) = E[Xt|Gt] = PL(Xt) .
Thus, the best Z-measurable estimate of Xt coincides with the best Z-linear
estimate of Xt.
Step 2. Replace Zt by the innovation process Nt:
Nt = Zt −
t
Z
0
(GX)∧
s ds ,
where (GX)∧
s = PL(Z,s)(G(s)Xs) = G(s) b
Xs .
Then
(i) Nt has orthogonal increments, i.e.
E[(Nt1−Ns1)(Nt2−Ns2)] = 0 for non-overlapping intervals [s1, t1], [s2, t2].

6.2 The 1-Dimensional Linear Filtering Problem
85
(ii) L(N, t) = L(Z, t), so b
Xt = PL(N,t)(Xt).
Step 3. If we put
dRt =
1
D(t)dNt ,
then Rt is a 1-dimensional Brownian motion. Moreover,
L(N, t) = L(R, t)
and
b
Xt = PL(N,t)(Xt) = PL(R,t)(Xt) = E[Xt] +
t
Z
0
∂
∂sE[XtRs]dRs .
Step 4. Find an expression for Xt by solving the (linear) stochastic diﬀer-
ential equation
dXt = F(t)Xtdt + C(t)dUt .
Step 5. Substitute the formula for Xt from Step 4 into E[XtRs] and use
Step 3 to obtain a stochastic diﬀerential equation for b
Xt:
d b
Xt = ∂
∂sE[XtRs]s=tdRt +
µ
t
Z
0
∂2
∂t∂sE[XtRs]dRs
¶
dt
etc.
Before we proceed to establish Steps 1–5, let us consider a simple, but moti-
vating example:
Example 6.2.1. Suppose X, W1, W2, . . . are independent real random vari-
ables, E[X] = E[Wj] = 0 for all j, E[X2] = a2, E[W 2
j ] = m2 for all j. Put
Zj = X + Wj.
What is the best linear estimate b
X of X based on {Zj; j ≤k} ? More
precisely, let
L = L(Z, k) = {c1Z1 + · · · + ckZk; c1, . . . , ck ∈R} .
Then we want to ﬁnd
b
Xk = Pk(X) ,
where Pk denotes the projection into L(Z, k).
We use the Gram-Schmidt procedure to obtain random variables A1, A2, . . .
such that
(i) E[AiAj] = 0 for i ̸= j
(ii) L(A, k) = L(Z, k) for all k.

86
6. The Filtering Problem
Then
b
Xk =
k
X
j=1
E[XAj]
E[A2
j] Aj
for k = 1, 2, . . . .
(6.2.5)
We obtain a recursive relation between b
Xk and b
Xk−1 from this by observing
that
Aj = Zj −b
Xj−1 ,
(6.2.6)
which follows from
Aj = Zj −Pj−1(Zj) = Zj −Pj−1(X) ,
since Pj−1(Wj) = 0 .
By (6.2.6)
E[XAj] = E[X(Zj −b
Xj−1)] = E[X(X −b
Xj−1)] = E[(X −b
Xj−1)2]
and
E[A2
j] = E[(X + Wj −b
Xj−1)2] = E[(X −b
Xj−1)2] + m2 .
Hence
b
Xk = b
Xk−1 +
E[(X −b
Xk−1)2]
E[(X −b
Xk−1)2] + m2 (Zk −b
Xk−1) .
(6.2.7)
If we introduce
Zk = 1
k
k
X
j=1
Zj ,
then this can be simpliﬁed to
b
Xk =
a2
a2 + 1
k · m2 Zk .
(6.2.8)
(This can be seen as follows:
Put
αk =
a2
a2 + 1
km2 ,
Uk = αkZk .
Then
(i) Uk ∈L(Z, k)
(ii) X −Uk⊥L(Z, k), since
E[(X −Uk)Zi] = E[XZi] −αkE[ZkZi]
= E[X(X + Wi)] −αk
1
k
X
j
E[ZjZi]
= a2 −1
k αk
X
j
E[(X+Wj)(X+Wi)] = a2 −1
k αk[ka2+m2] = 0 .)

6.2 The 1-Dimensional Linear Filtering Problem
87
The result can be interpreted as follows:
For large k we put b
Xk ≈Zk, while for small k the relation between a2
and m2 becomes more important. If m2 ≫a2, the observations are to a large
extent neglected (for small k) and b
Xk is put equal to its mean value, 0. See
also Exercise 6.11.
This example gives the motivation for our approach:
We replace the process Zt by an orthogonal increment process Nt (Step 2)
in order to obtain a representation for b
Xt analogous to (6.2.5). Such a rep-
resentation is obtained in Step 3, after we have identiﬁed the best linear
estimate with the best measurable estimate (Step 1) and established the con-
nection between Nt and Brownian motion.
Step 1. Z-Linear and Z-Measurable Estimates
Lemma 6.2.2. Let X, Zs; s ≤t be random variables in L2(P) and assume
that
(X, Zs1, Zs2, . . . , Zsn) ∈Rn+1
has a normal distribution for all s1, s2, . . . , sn ≤t, n ≥1. Then
PL(X) = E[X|G] = PK(X) .
In other words, the best Z-linear estimate for X coincides with the best Z-
measurable estimate in this case.
Proof. Put ˇX = PL(X), e
X = X −ˇX. Then we claim that e
X is independent
of G: Recall that a random variable (Y1, . . . , Yk) ∈Rk is normal iﬀc1Y1 +
· · · + ckYk is normal, for all choices of c1, . . . , ck ∈R. And an L2-limit of
normal variables is again normal (Appendix A). Therefore
( e
X, Zs1, . . . , Zsn)
is normal for all s1, . . . , sn ≤t .
Since E[ e
XZsj] = 0, e
X and Zsj are uncorrelated, for 1 ≤j ≤n. It follows
(Appendix A) that
e
X and (Zs1, . . . , Zsn) are independent .
So e
X is independent from G as claimed. But then
E[XG(X −ˇX)] = E[XG e
X] = E[XG] · E[ e
X] = 0
for all G ∈G
i.e.
R
G
XdP =
R
G
ˇXdP. Since ˇX is G-measurable, we conclude that
ˇX = E[X|G].
⊔⊓

88
6. The Filtering Problem
There is a curious interpretation of this result: Suppose X, {Zt}t∈T are
L2(P)-functions with given covariances. Among all possible distributions of
(X, Zt1, . . . , Ztn)
with these covariances, the normal distribution will be the “worst” w.r.t.
estimation, in the following sense: For any distribution we have
E[(X −E[X|G])2] ≤E[(X −PL(X))2] ,
with equality for the normal distribution, by Lemma 6.2.2. (Note that the
quantity on the right hand side only depends on the covariances, not on
the distribution we might choose to obtain these covariances). For a broad
discussion of similar conclusions, based on an information theoretical game
between nature and the observer, see Tops¨oe (1978).
Finally, to be able to apply Lemma 6.2.2 to our ﬁltering problem, we need
the following result:
Lemma 6.2.3.
Mt =
·
Xt
Zt
¸
∈R2
is a Gaussian process .
Proof. We may regard Mt as the solution of a 2-dimensional linear stochastic
diﬀerential equation of the form
dMt = H(t)Mtdt + K(t)dBt, M0 =
·
X0
0
¸
;
(6.2.9)
where H(t) ∈R2×2, K(t) ∈R2×2 and Bt is 2-dimensional Brownian motion.
Use Picard iteration to solve (6.2.9), i.e. put
M (n+1)
t
= M0 +
t
Z
0
H(s)M (n)
s
ds +
t
Z
0
K(s)dBs ,
n = 0, 1, 2, . . . (6.2.10)
Then M (n)
t
is Gaussian for all n and M (n)
t
→Mt in L2(P) (see the proof of
Theorem 5.2.1) and therefore Mt is Gaussian (Theorem A.7).
⊔⊓
Step 2. The Innovation Process
Before we introduce the innovation process we will establish a useful repre-
sentation of the functions in the space
L(Z, T) = the closure in L2(P) of all linear combinations
c0 + c1Zt1 + · · · + ckZtk;
0 ≤ti ≤T, cj ∈R .
If f ∈L2[0, T], note that

6.2 The 1-Dimensional Linear Filtering Problem
89
E
·µ
T
Z
0
f(t)dZt
¶2¸
= E
·µ
T
Z
0
f(t)G(t)Xtdt
¶2¸
+ E
·µ
T
Z
0
f(t)D(t)dVt
¶2¸
+2E
·µ
T
Z
0
f(t)G(t)Xtdt
¶µ
T
Z
0
f(t)D(t)dVt
¶¸
.
Since
E
·µ
T
Z
0
f(t)G(t)Xtdt
¶2¸
≤A1 ·
T
Z
0
f(t)2dt by the Cauchy-Schwartz inequality,
E
·µ
T
Z
0
f(t)D(t)dVt
¶2¸
=
T
Z
0
f(t)2D2(t)dt
by the Itˆo isometry
and {Xt}, {Vt} are independent, we conclude that
A0
T
Z
0
f 2(t)dt ≤E
·µ
T
Z
0
f(t)dZt
¶2¸
≤A2
T
Z
0
f 2(t)dt ,
(6.2.11)
for some constants A0, A1, A2 not depending on f. We can now show
Lemma 6.2.4. L(Z, T) = {c0 +
TR
0
f(t)dZt; f ∈L2[0, T], c0 ∈R}.
Proof. Denote the right hand side by N(Z, T). It is enough to show that
a) N(Z, T) ⊂L(Z, T)
b) N(Z, T) contains all linear combinations of the form
c0 + c1Zt1 + · · · + ckZtk ;
0 ≤ti ≤T
c) N(Z, T) is closed in L2(P)
a): This follows from the fact that if f is continuous then
T
Z
0
f(t)dZt = lim
n→∞
X
j
f(j · 2−n) · (Z(j+1)2−n −Zj·2−n) .
b): Suppose 0 ≤t1 < t2 < · · · < tk ≤T. We can write
k
X
i=1
ciZti =
k−1
X
j=0
c′
j∆Zj =
k−1
X
j=0
tj+1
Z
tj
c′
jdZt =
T
Z
0
³ k−1
X
j=0
c′
jX[tj,tj+1)(t)
´
dZt ,
where ∆Zj = Ztj+1 −Ztj.
c): This follows from (6.2.11) and the fact that L2[0, T] is complete.
⊔⊓

90
6. The Filtering Problem
Now we deﬁne the innovation process Nt as follows:
Nt = Zt −
t
Z
0
(GX)∧
s ds, where (GX)∧
s = PL(Z,s)(G(s)Xs) = G(s) b
Xs .
(6.2.12)
i.e.
dNt = G(t)(Xt −b
Xt)dt + D(t)dVt .
(6.2.13)
Lemma 6.2.5. (i) Nt has orthogonal increments
(ii) E[N 2
t ] =
tR
0
D2(s)ds
(iii) L(N, t) = L(Z, t) for all t ≥0
(iv) Nt is a Gaussian process
Proof. (i): If s < t and Y ∈L(Z, s) we have
E[(Nt −Ns)Y ] = E
·µ
t
Z
s
G(r)(Xr −b
Xr
¶
dr +
t
Z
s
D(r)dVr)Y
¸
=
t
Z
s
G(r)E[(Xr −b
Xr)Y ]dr + E
·µ
t
Z
s
DdV
¶
Y
¸
= 0 ,
since Xr−b
Xr⊥L(Z, r) ⊃L(Z, s) for r ≥s and V has independent increments.
(ii): By Itˆo’s formula, with g(t, x) = x2, we have
d(N 2
t ) = 2NtdNt + 1
22(dNt)2 = 2NtdNt + D2dt .
So
E[N 2
t ] = E
·
t
Z
0
2NsdNs
¸
+
t
Z
0
D2(s)ds .
Now
t
Z
0
NsdNs =
lim
∆tj→0
X
Ntj[Ntj+1 −Ntj] ,
so since N has orthogonal increments we have
E
·
t
Z
0
NsdNs
¸
= 0 ,
and (ii) follows .
(iii): It is clear that L(N, t) ⊂L(Z, t) for all t ≥0. To establish the opposite
inclusion we use Lemma 6.2.4. So choose f ∈L2[0, t] and let us see what
functions can be obtained in the form

6.2 The 1-Dimensional Linear Filtering Problem
91
t
Z
0
f(s)dNs =
t
Z
0
f(s)dZs −
t
Z
0
f(r)G(r) b
Xrdr
=
t
Z
0
f(s)dZs −
t
Z
0
f(r)
·
r
Z
0
g(r, s)dZs
¸
dr −
t
Z
0
f(r)c(r)dr
=
t
Z
0
·
f(s) −
t
Z
s
f(r)g(r, s)dr
¸
dZs −
t
Z
0
f(r)c(r)dr ,
where we have used Lemma 6.2.2 and Lemma 6.2.4 to write, for each r,
(GX)∧
r = c(r) +
r
Z
0
g(r, s)dZs
for some g(r, ·) ∈L2[0, r], c(r) ∈R .
From the theory of Volterra integral equations (see e.g. Davis (1977), p. 125)
there exists for all h ∈L2[0, t] an f ∈L2[0, t] such that
f(s) −
t
Z
s
f(r)g(r, s)dr = h(s).
So by choosing h = X[0,t1] where 0 ≤t1 ≤t, we obtain
t
Z
0
f(r)c(r)dr +
t
Z
0
f(s)dNs =
t
Z
0
X[0,t1](s)dZs = Zt1 ,
which shows that L(N, t) ⊃L(Z, t).
(iv): b
Xt is a limit (in L2(P)) of linear combinations of the form
M = c0 + c1Zs1 + · · · + ckZsk ,
where sk ≤t .
Therefore
( b
Xt1, . . . , b
Xtm)
is a limit of m-dimensional random variables (M (1), . . . , M (m)) whose com-
ponents M (j) are linear combinations of this form. (M (1), . . . , M (m)) has a
normal distribution since {Zt} is Gaussian, and therefore the limit has. Hence
{ b
Xt} is Gaussian. It follows that
Nt = Zt −
t
Z
0
G(s) b
Xsds
is Gaussian, by a similar argument.
⊔⊓

92
6. The Filtering Problem
Step 3. The Innovation Process and Brownian Motion
Let Nt = Zt −
tR
0
G(s) b
Xsds be the innovation process deﬁned in Step 2.
Recall that we have assumed that D(t) is bounded away from 0 on bounded
intervals. Deﬁne the process Rt(ω) by
dRt =
1
D(t)dNt(ω) ;
t ≥0, R0 = 0 .
(6.2.14)
Lemma 6.2.6. Rt is a 1-dimensional Brownian motion.
Proof. Observe that
(i)
Rt has continuous paths
(ii) Rt has orthogonal increments (since Nt has)
(iii) Rt is Gaussian (since Nt is)
(iv) E[Rt] = 0 and E[RtRs] = min(s, t).
To prove the last assertion in (iv), note that by Itˆo’s formula
d(R2
t ) = 2RtdRt + (dRt)2 = 2RtdRt + dt ,
so, since Rt has orthogonal increments,
E[R2
t ] = E[
t
Z
0
ds] = t .
Therefore, if s < t,
E[RtRs] = E[(Rt −Rs)Rs] + E[R2
s] = E[R2
s] = s .
Properties (i), (iii) and (iv) constitute one of the many characterizations of a
1-dimensional Brownian motion (see Simon (1979), Theorem 4.3). (Alterna-
tively, we could easily deduce that Rt has stationary, independent increments
and therefore – by continuity – must be Brownian motion, by the result previ-
ously referred to in the beginning of Chapter 3. For a general characterization
of Brownian motion see Corollary 8.4.5.) ⊔⊓
Since
L(N, t) = L(R, t)
we conclude that
b
Xt = PL(R,t)(Xt) .
It turns out that the projection down to the space L(R, t) can be described
very nicely: (compare with formula (6.2.5) in Example 6.2.1)

6.2 The 1-Dimensional Linear Filtering Problem
93
Lemma 6.2.7.
b
Xt = E[Xt] +
t
Z
0
∂
∂sE[XtRs]dRs .
(6.2.15)
Proof. From Lemma 6.2.4 we know that
b
Xt = c0(t) +
t
Z
0
g(s)dRs
for some g ∈L2[0, t], c0(t) ∈R .
Taking expectations we see that c0(t) = E[ b
Xt] = E[Xt]. We have
(Xt −b
Xt)⊥
t
Z
0
f(s)dRs
for all f ∈L2[0, t] .
Therefore
E
·
Xt
t
Z
0
f(s)dRs
¸
= E
·
b
Xt
t
Z
0
f(s)dRs
¸
= E
·
t
Z
0
g(s)dRs
t
Z
0
f(s)dRs
¸
= E
·
t
Z
0
g(s)f(s)ds
¸
=
t
Z
0
g(s)f(s)ds ,
for all f ∈L2[0, t] ,
where we have used the Itˆo isometry. In particular, if we choose f = X[0,r]
for some r ≤t, we obtain
E[XtRr] =
r
Z
0
g(s)ds
or
g(r) = ∂
∂rE[XtRr] ,
as asserted .
This completes Step 3.
⊔⊓
Step 4. An Explicit Formula for Xt
This is easily obtained using Itˆo’s formula, as in the examples in Chapter 5.
The result is
Xt = exp
µ
t
Z
0
F(s)ds
¶·
X0 +
t
Z
0
exp
µ
−
s
Z
0
F(u)du
¶
C(s)dUs
¸
= exp
µ
t
Z
0
F(s)ds
¶
X0 +
t
Z
0
exp
µ
t
Z
s
F(u)du
¶
C(s)dUs .

94
6. The Filtering Problem
In particular, we note that E[Xt] = E[X0] exp(
tR
0
F(s)ds).
More generally, if 0 ≤r ≤t, (see Exercise 6.12)
Xt = exp
µ
t
Z
r
F(s)ds
¶
Xr +
t
Z
r
exp
µ
t
Z
s
F(u)du
¶
C(s)dUs .
(6.2.16)
Step 5. The Stochastic Diﬀerential Equation for c
Xt
We now combine the previous steps to obtain the solution of the ﬁltering
problem, i.e. a stochastic diﬀerential equation for b
Xt. Starting with the for-
mula from Lemma 6.2.7
b
Xt = E[Xt] +
t
Z
0
f(s, t)dRs ,
where
f(s, t) = ∂
∂sE[XtRs] ,
(6.2.17)
we use that
Rs =
s
Z
0
G(r)
D(r)(Xr −b
Xr)dr + Vs
from (6.2.13) and (6.2.14))
and obtain
E[XtRs] =
s
Z
0
G(r)
D(r)E[Xt e
Xr]dr ,
where
e
Xr = Xr −b
Xr .
(6.2.18)
Using formula (6.2.16) for Xt, we obtain
E[Xt e
Xr] = exp
µ
t
Z
r
F(v)dv
¶
E[Xr e
Xr] = exp
µ
t
Z
r
F(v)dv
¶
S(r) ,
where
S(r) = E[( e
Xr)2] ,
(6.2.19)
i.e. the mean square error of the estimate at time r ≥0. Thus
E[XtRs] =
s
Z
0
G(r)
D(r) exp
µ
t
Z
r
F(v)dv
¶
S(r)dr

6.2 The 1-Dimensional Linear Filtering Problem
95
so that
f(s, t) = G(s)
D(s) exp
µ
t
Z
s
F(v)dv
¶
S(s) .
(6.2.20)
We claim that S(t) satisﬁes the (deterministic) diﬀerential equation
dS
dt = 2F(t)S(t) −G2(t)
D2(t)S2(t) + C2(t)
(The Riccati equation) . (6.2.21)
To prove (6.2.21) note that by the Pythagorean theorem, (6.2.15) and the
Itˆo isometry
S(t) = E[(Xt −b
Xt)2] = E[X2
t ] −2E[Xt b
Xt] + E[ b
X2
t ] = E[X2
t ] −E[ b
X2
t ]
= T(t) −
t
Z
0
f(s, t)2ds −E[Xt]2 ,
(6.2.22)
where
T(t) = E[X2
t ] .
(6.2.23)
Now by (6.2.16) and the Itˆo isometry we have
T(t) = exp
µ
2
t
Z
0
F(s)ds
¶
E[X2
0] +
t
Z
0
exp
µ
2
t
Z
s
F(u)du
¶
C2(s)ds ,
using that X0 is independent of {Us}s≥0. So
dT
dt = 2F(t) · exp
µ
2
t
Z
0
F(s)ds
¶
E[X2
0] + C2(t)
+
t
Z
0
2F(t) exp
µ
2
t
Z
s
F(u)du
¶
C2(s)ds
i.e.
dT
dt = 2F(t)T(t) + C2(t) .
(6.2.24)
Substituting in (6.2.22) we obtain, using Step 4,
dS
dt = dT
dt −f(t, t)2 −
t
Z
0
2f(s, t) · ∂
∂tf(s, t)ds −2F(t)E[Xt]2
= 2F(t)T(t) + C2(t) −G2(t)S2(t)
D2(t)
−2
t
Z
0
f 2(s, t)F(t)ds −2F(t)E[Xt]2
= 2F(t)S(t) + C2(t) −G2(t)S2(t)
D2(t)
,
which is (6.2.21) .

96
6. The Filtering Problem
We are now ready for the stochastic diﬀerential equation for b
Xt:
From the formula
b
Xt = c0(t) +
t
Z
0
f(s, t)dRs
where c0(t) = E[Xt]
it follows that
d b
Xt = c′
0(t)dt + f(t, t)dRt +
µ
t
Z
0
∂
∂tf(s, t)dRs
¶
dt ,
(6.2.25)
since
u
Z
0
µ
t
Z
0
∂
∂tf(s, t)dRs
¶
dt =
u
Z
0
µ
u
Z
s
∂
∂tf(s, t)dt
¶
dRs
=
u
Z
0
(f(s, u) −f(s, s))dRs = b
Xu −c0(u) −
u
Z
0
f(s, s)dRs .
So
d b
Xt = c′
0(t)dt + G(t)S(t)
D(t)
dRt +
µ
t
Z
0
f(s, t)dRs
¶
F(t)dt
or
d b
Xt = c′
0(t)dt + F(t) · ( b
Xt −c0(t))dt + G(t)S(t)
D(t)
dRt
= F(t) b
Xtdt + G(t)S(t)
D(t)
dRt ,
(6.2.26)
since c′
0(t) = F(t)c0(t) (Step 4).
If we substitute
dRt =
1
D(t)[dZt −G(t) b
Xtdt]
we obtain
d b
Xt = (F(t) −G2(t)S(t)
D2(t)
) b
Xtdt + G(t)S(t)
D2(t) dZt .
(6.2.27)
So the conclusion is:
Theorem 6.2.8 (The 1-dimensional Kalman-Bucy ﬁlter).
The solution b
Xt = E[Xt|Gt] of the 1-dimensional linear ﬁltering problem
(linear system)
dXt = F(t)Xtdt + C(t)dUt; F(t), C(t) ∈R
(6.2.3)
(linear observations)
dZt = G(t)Xtdt + D(t)dVt; G(t), D(t) ∈R
(6.2.4)

6.2 The 1-Dimensional Linear Filtering Problem
97
(with conditions as stated earlier) satisﬁes the stochastic diﬀerential equation
d b
Xt =
µ
F(t) −G2(t)S(t)
D2(t)
¶
b
Xtdt + G(t)S(t)
D2(t) dZt ;
b
X0 = E[X0]
(6.2.28)
where
S(t) = E[(Xt −b
Xt)2] satisﬁes the (deterministic) Riccati equation
dS
dt = 2F(t)S(t) −G2(t)
D2(t)S2(t) + C2(t), S(0) = E[(X0 −E[X0])2] .
(6.2.29)
Example 6.2.9 (Noisy observations of a constant process).
Consider the simple case
(system)
dXt = 0, i.e. Xt = X0; E[X0] = 0, E[X2
0] = a2
(observations)
dZt = Xtdt + mdVt; Z0 = 0
(corresponding to
Ht = dZ
dt = Xt + mWt, Wt = white noise) .
First we solve the corresponding Riccati equation for
S(t) = E[(Xt −b
Xt)2]:
dS
dt = −1
m2 S2 ,
S(0) = a2
i.e.
S(t) =
a2m2
m2 + a2t ;
t ≥0 .
This gives the following equation for b
Xt:
d b
Xt = −
a2
m2 + a2t
b
Xtdt +
a2
m2 + a2tdZt ;
b
X0 = E[X0] = 0
or
d
µ
b
Xt exp
µ Z
a2
m2 + a2tdt
¶¶
= exp
µ Z
a2
m2 + a2tdt
¶
a2
m2 + a2tdZt
which gives
b
Xt =
a2
m2 + a2tZt ;
t ≥0 .
(6.2.30)
This is the continuous analogue of Example 6.2.1.

98
6. The Filtering Problem
Example 6.2.10 (Noisy observations of a Brownian motion).
If we modify the preceding example slightly, so that
(system)
dXt = cdUt; E[X0] = 0, E[X2
0] = a2, c constant
(observations)
dZt = Xtdt + mdVt,
the Riccati equation becomes
dS
dt = −1
m2 S2 + c2, S(0) = a2
or
m2dS
m2c2 −S2 = dt, (S ̸= mc) .
This gives
¯¯¯mc + s
mc −s
¯¯¯ = K exp
µ2ct
m
¶
;
K =
¯¯¯mc + a2
mc −a2
¯¯¯ .
Or
S(t) =









mc K·exp( 2ct
m )−1
K·exp( 2ct
m )+1 ;
if S(0) < mc
mc (constant)
if S(0) = mc
mc K·exp( 2ct
m )+1
K·exp( 2ct
m )−1
if S(0) > mc .
Thus in all cases the mean square error S(t) tends to mc as t →∞.
For simplicity let us put a = 0, m = c = 1. Then
S(t) = exp(2t) −1
exp(2t) + 1 = tanh(t) .
The equation for b
Xt is
d b
Xt = −tanh(t) b
Xtdt + tanh(t)dZt ,
b
X0 = 0
or
d(cosh(t) b
Xt) = sinh(t)dZt .
So
b
Xt =
1
cosh(t)
t
Z
0
sinh(s)dZs .
If we return to the interpretation of Zt :
Zt =
t
Z
0
Hsds ,
where Hs are the “original” observations (see (6.1.4)), we can write

6.2 The 1-Dimensional Linear Filtering Problem
99
b
Xt =
1
cosh(t)
t
Z
0
sinh(s)Hsds ,
(6.2.31)
so b
Xt is approximately (for large t) a weighted average of the observations
Hs, with increasing emphasis on observations as time increases.
Remark. It is interesting to compare formula (6.2.31) with established for-
mulas in forecasting. For example, the exponentially weighted moving average
e
Xn suggested by C.C. Holt in 1958 is given by
e
Xn = (1 −α)nZ0 + α
n
X
k=1
(1 −α)n−kZk ,
where α is some constant; 0 ≤α ≤1. See The Open University (1981), p. 16.
This may be written
e
Xn = β−nZ0 + (β −1)β−n−1
n
X
k=1
βkZk ,
where β =
1
1−α (assuming α < 1), which is a discrete version of (6.2.31), or –
more precisely – of the formula corresponding to (6.2.31) in the general case
when a ̸= 0 and m, c are not necessarily equal to 1.
Example 6.2.11 (Estimation of a parameter).
Suppose we want to estimate the value of a (constant) parameter θ, based
on observations Zt satisfying the model
dZt = θ M(t)dt + N(t)dBt ,
where M(t), N(t) are known functions. In this case the stochastic diﬀerential
equation for θ is of course
dθ = 0 ,
so the Riccati equation for S(t) = E[(θ −bθt)2] is
dS
dt = −
µM(t)S(t)
N(t)
¶2
which gives
S(t) =
µ
S−1
0
+
t
Z
0
M(s)2N(s)−2ds
¶−1
and the Kalman-Bucy ﬁlter is
dbθt = M(t)S(t)
N(t)2
(dZt −M(t)bθtdt) .

100
6. The Filtering Problem
This can be written
µ
S−1
0
+
t
Z
0
M(s)2N(s)−2ds
¶
dbθt + M(t)2N(t)−2bθtdt = M(t)N(t)−2dZt .
We recoqnize the left hand side as
d(
µ
S−1
0
+
t
Z
0
M(s)2N(s)−2ds
¶
bθt)
so we obtain
bθt =
bθ0S−1
0
+
tR
0
M(s)N(s)−2dZs
S−1
0
+
tR
0
M(s)2N(s)−2ds
.
This estimate coincides with the maximum likelihood estimate in classical
estimation theory if S−1
0
= 0. See Liptser and Shiryaev (1978).
For more information about estimates of drift parameters in diﬀusions
and generalizations, see for example Aase (1982), Brown and Hewitt (1975)
and Taraskin (1974).
Example 6.2.12 (Noisy observations of a population growth).
Consider a simple growth model (r constant)
dXt = rXtdt, E[X0] = b > 0 ,
E[(X0 −b)2] = a2 ,
with observations
dZt = Xtdt + mdVt ;
m constant .
The corresponding Riccati equation
dS
dt = 2rS −1
m2 S2 ,
S(0) = a2 ,
gives the logistic curve
S(t) =
2rm2
1 + Ke−2rt ;
where K = 2rm2
a2
−1 .
So the equation for b
Xt becomes
d b
Xt =
µ
r −S
m2
¶
b
Xtdt + S
m2 dZt ;
b
X0 = E[X0] = b .
For simplicity let us assume that a2 = 2rm2, so that

6.2 The 1-Dimensional Linear Filtering Problem
101
S(t) = 2rm2
for all t .
(In the general case S(t) →2rm2 as t →∞, so this is not an unreasonable
approximation for large t). Then we get
d(exp(rt) b
Xt) = exp(rt)2rdZt ,
b
X0 = b
or
b
Xt = exp(−rt)
·
t
Z
0
2r exp(rs)dZs + b
¸
.
As in Example 6.2.10 this may be written
b
Xt = exp(−rt)
·
t
Z
0
2r exp(rs)Hsds + b
¸
,
if Zt =
tR
0
Hsds .
(6.2.32)
For example, assume that Hs = β (constant) for 0 ≤s ≤t, i.e. that our
observations (for some reason) give the same value β for all times s ≤t.
Then
b
Xt = 2β −(2β −b) exp(−rt) →2β
as t →∞.
If Hs = β · exp(αs), s ≥0 (α constant), we get
b
Xt = exp(−rt)
· 2rβ
r + α(exp(r + α)t −1) + b
¸
≈2rβ
r + α exp αt
for large t .
Thus, only if α = r, i.e. Hs = β exp(rs); s ≥0, does the ﬁlter “believe” the
observations in the long run. And only if α = r and β = b, i.e. Hs = b exp(rs);
s ≥0, does the ﬁlter “believe” the observations at all times.
Example 6.2.13 (Constant coeﬃcients – general discussion).
Now consider the system
dXt = FXtdt + CdUt ;
F, C constants ̸= 0
with observations
dZt = GXtdt + DdVt ;
G, D constants ̸= 0 .
The corresponding Riccati equation
S′ = 2FS −G2
D2 S2 + C2 ,
S(0) = a2
has the solution

102
6. The Filtering Problem
S(t) = α1 −Kα2 exp( (α2−α1)G2t
D2
)
1 −K exp( (α2−α1)G2t
D2
)
,
where
α1 = G−2(FD2 −D
p
F 2D2 + G2C2)
α2 = G−2(FD2 + D
p
F 2D2 + G2C2)
and
K = a2 −α1
a2 −α2
.
This gives the solution for b
Xt of the form
b
Xt = exp
µ
t
Z
0
H(s)ds
¶
b
X0 + G
D2
t
Z
0
exp
µ
t
Z
s
H(u)du
¶
S(s)dZs ,
where
H(s) = F −G2
D2 S(s) .
For large s we have S(s) ≈α2. This gives
b
Xt ≈b
X0 exp(
µ
F −G2α2
D2
¶
t) + Gα2
D2
t
Z
0
exp(
µ
F −G2α2
D2
¶
(t −s))dZs
= b
X0 exp(−βt) + Gα2
D2 exp(−βt)
t
Z
0
exp(βs)dZs
(6.2.33)
where β = D−1√
F 2D2 + G2C2 . So we get approximately the same be-
haviour as in the previous example.
6.3 The Multidimensional Linear Filtering Problem
Finally we formulate the solution of the n-dimensional linear ﬁltering problem
(6.2.1), (6.2.2):
Theorem 6.3.1 (The Multi-Dimensional Kalman-Bucy Filter).
The solution b
Xt = E[Xt|Gt] of the multi-dimensional linear ﬁltering problem
(linear system)
dXt =F(t)Xtdt+C(t)dUt;
F(t)∈Rn×n, C(t)∈Rn×p
(6.3.1)
(linear observations)
dZt =G(t)Xtdt+D(t)dVt;
G(t)∈Rm×n, D(t)∈Rm×r
(6.3.2)

Exercises
103
satisﬁes the stochastic diﬀerential equation
d b
Xt = (F −SGT (DDT )−1G) b
Xtdt + SGT (DDT )−1dZt ;
b
X0 = E[X0]
(6.3.3)
where S(t): = E[(Xt −b
Xt)(Xt −b
Xt)T ] ∈Rn×n satisﬁes the matrix Riccati
equation
dS
dt = FS + SF T −SGT (DDT )−1GS + CCT ;
S(0) = E[(X0 −E[X0])(X0 −E[X0])T ] .
(6.3.4)
The condition on D(t) ∈Rm×r is now that D(t)D(t)T is invertible for all t
and that (D(t)D(t)T )−1 is bounded on every bounded t-interval.
A similar solution can be found for the more general situation
(system)
dXt = [F0(t) + F1(t)Xt + F2(t)Zt]dt + C(t)dUt
(6.3.5)
(observations)
dZt = [G0(t) + G1(t)Xt + G2(t)Zt]dt + D(t)dVt ,
(6.3.6)
where Xt ∈Rn, Zt ∈Rm and Bt = (Ut, Vt) is n + m-dimensional Brownian
motion, with appropriate dimensions on the matrix coeﬃcients. See Ben-
soussan (1992) and Kallianpur (1980), who also treat the non-linear case.
An account of non-linear ﬁltering theory is also given in Pardoux (1979) and
Davis (1984).
For the solution of linear ﬁltering problems governed by more general
processes than Brownian motion (processes with orthogonal increments) see
Davis (1977).
For various applications of ﬁltering theory see Bucy and Joseph (1968),
Jazwinski (1970), Gelb (1974), Maybeck (1979) and the references in these
books.
Exercises
6.1.
(Time-varying observations of a constant)
Prove that if the (1-dimensional) system is
dXt = 0, E[X0] = 0 ,
E[X2
0] = a2
and the observation process is
dZt = G(t)Xtdt + dVt ,
Z0 = 0
then S(t) = E[(Xt −b
Xt)2] is given by
S(t) =
1
1
S(0) +
R t
0 G2(s)ds
.
(6.3.7)

104
6. The Filtering Problem
We say that we have exact asymptotic estimation if S(t) →0 as t →∞,
i.e. if
∞
Z
0
G2(s)ds = ∞.
Thus for
G(s) =
1
(1 + s)p
(p > 0 constant)
we have exact asymptotic estimation iﬀp ≤1
2 .
6.2.
Consider the linear 1-dimensional ﬁltering problem with no noise in
the system:
(system)
dXt = F(t)Xtdt
(6.3.8)
(observations)
dZt = G(t)Xtdt + D(t)dVt
(6.3.9)
Put S(t) = E[(Xt −b
Xt)2] as usual and assume S(0) > 0 .
a) Show that
R(t): =
1
S(t)
satisﬁes the linear diﬀerential equation
R′(t) = −2F(t)R(t) + G2(t)
D2(t) ;
R(0) =
1
S(0)
(6.3.10)
b) Use (6.3.10) to prove that for the ﬁltering problem (6.3.8), (6.3.9)
we have
1
S(t) =
1
S(0) exp
µ
−2
t
Z
0
F(s)ds
¶
+
t
Z
0
exp
µ
−2
t
Z
s
F(u)du
¶ G2(s)
D2(s)ds .
(6.3.11)
6.3.
In Example 6.2.12 we found that
S(t) →2rm2
as t →∞,
so exact asymptotic estimation (Exercise 6.1) of Xt is not possible.
However, prove that we can obtain exact asymptotic estimation of X0,
in the sense that
E[(X0 −E[X0|Gt])2] →0
as t →∞.
(Hint: Note that X0 = e−rtXt and therefore E[X0|Gt] = e−rt b
Xt, so
that
E[(X0 −E[X0|Gt])2] = e−2rtS(t)) .

Exercises
105
6.4.
Consider the multi-dimensional linear ﬁltering problem with no noise
in the system:
(system)
dXt = F(t)Xtdt ;
Xt ∈Rn , F(t) ∈Rn×n
(6.3.12)
(observations)
dZt = G(t)Xtdt + D(t)dVt ;
G(t) ∈Rm×n , D(t) ∈Rm×r
(6.3.13)
Assume that S(t) is nonsingular and deﬁne R(t) = S(t)−1. Prove that
R(t) satisﬁes the Lyapunov equation (compare with Exercise 6.2)
R′(t) = −R(t)F(t)−F(t)T R(t)+G(t)T (D(t)D(t)T )−1G(t) .
(6.3.14)
(Hint: Note that since S(t)S−1(t) = I we have
S′(t)S−1(t) + S(t)(S−1)′(t) = 0, which gives
(S−1)′(t) = −S−1(t)S′(t)S−1(t) .)
6.5.
(Prediction)
In the prediction problem one seeks to estimate the value of the system
X at a future time T based on the observations Gt up to the present
time t < T.
Prove that in the linear setup (6.2.3), (6.2.4) the predicted value
E[XT |Gt] ,
T > t
is given by
E[XT |Gt] = exp
µ
T
Z
t
F(s)ds
¶
· b
Xt .
(6.3.15)
(Hint: Use formula (6.2.16).)
6.6.
(Interpolation/smoothing)
The interpolation or smoothing problem consists of estimating the
value of the system X at a time s < t, given the observations up
to time t, Gt.
With notation as in (6.2.1), (6.2.2) one can show that Ms: = E[Xs|Gt]
satisﬁes the diﬀerential equation
(
d
dsMs = F(s)Ms + C(s)CT (s)S−1(s)(Ms −b
Xs) ;
s < t
Mt = b
Xt .
(6.3.16)
(See Davis (1977, Theorem 4.4.4).)
Use this result to ﬁnd E[Xs|Gt] in Example 6.2.9.

106
6. The Filtering Problem
6.7.
Consider the system
dXt =
·
dX1(t)
dX2(t)
¸
=
·
0
0
¸
,
E[X0] =
·
0
0
¸
with observations
·
dZ1(t)
dZ2(t)
¸
=
·
X1
X1 + X2
¸
dt +
·
dV1(t)
dV2(t)
¸
.
Apply (6.3.14) from Exercise 6.4 to prove that
S(t): = E[(Xt −b
Xt)(Xt −b
Xt)T ] is given by
S(t)−1 = S−1(0) +
·
2
1
1
1
¸
t
if S(0) is invertible. Then show that
d b
Xt = −S(t)
·
2
1
1
1
¸
b
Xtdt + S(t)
·
1
1
0
1
¸
dZt .
6.8.
Transform the following Stratonovich equation
dXt = b(t, Xt)dt + σ(t, Xt) ◦dBt
into the corresponding Itˆo equation
dXt = eb(t, Xt)dt + σ(t, Xt)dBt
using (6.1.3):
a)
·
dX1
dX2
¸
=
·
1
X2 + e2X1
¸
dt +
·
0
eX1
¸
◦dBt
(Bt ∈R)
b)
·
dX1
dX2
¸
=
·
X1
X2
¸
dt +
·
X2
X1
¸
◦dBt
(Bt ∈R)
6.9.
Transform the following Itˆo equation
dXt = b(t, Xt)dt + σ(t, Xt)dBt
into the corresponding Stratonovich equation
dXt = bb(t, Xt)dt + σ(t, Xt) ◦dBt ,
using (the converse of) (6.1.3):

Exercises
107
a) dXt = −1
2Xtdt + KXtdBt, where
K =
·
0
−1
1
0
¸
,
Xt =
·
X1(t)
X2(t)
¸
∈R2
and Bt ∈R
(i.e. Xt is Brownian motion on the unit circle (Example 5.1.4)).
b)
·
dX1
dX2
¸
=
·
X1
−X2
X2
X1
¸ ·
dB1
dB2
¸
.
6.10. (On the support of an Itˆo diﬀusion)
The support of an Itˆo diﬀusion X in Rn starting at x ∈Rn is the
smallest closed set F with the property that
Xt(ω) ∈F
for all t ≥0, for a.a. ω .
In Example 5.1.4 we found that Brownian motion on the unit circle,
Xt, satisﬁes the (Itˆo) stochastic diﬀerential equation
·
dX1(t)
dX2(t)
¸
= −1
2
·
X1(t)
X2(t)
¸
dt +
·
0
−1
1
0
¸ ·
X1(t)
X2(t)
¸
dBt .
(6.3.17)
From this equation it is not at all apparent that its solution is situ-
ated on the same circle as the starting point. However, this can be
detected by proceeding as follows: First transform the equation into
its Stratonovich form, which in Exercise 6.9 is found to be
·
dX1(t)
dX2(t)
¸
=
·
0
−1
1
0
¸ ·
X1(t)
X2(t)
¸
◦dBt .
(6.3.18)
Then (formally) replace ◦dBt by φ′(t)dt, where φ is some smooth (de-
terministic) function, φ(0) = 0. This gives the deterministic equation
·
dX(φ)
1
(t)
dX(φ)
2
(t)
¸
=
·
0
−1
1
0
¸
φ′(t)dt .
(6.3.19)
If (X(φ)
1
(0), X(φ)
2
(0)) = (1, 0) the solution of (6.3.19) is
·
X(φ)
1
(t)
X(φ)
2
(t)
¸
=
·
cos φ(t)
sin φ(t)
¸
.
So for any smooth φ the corresponding solution X(φ)(t) of (6.3.19)
has its support on this unit circle. We can conclude that the original
solution X(t, ω) is supported on the unit circle also, in virtue of the
Stroock-Varadhan support theorem. This theorem says that, quite gen-
erally, the support of an Itˆo diﬀusion Xt(ω) coincides with the closure
(in C([0, ∞); Rn)) of {X(φ)(·); φ smooth}, where X(φ)(t) is obtained
by replacing ◦dBt by φ′(t)dt in the same way as above. See e.g. Ikeda

108
6. The Filtering Problem
and Watanabe (1989, Th. VI. 8.1). (In this special case above the
support could also have been found directly from (6.3.18)).
Use the procedure above to ﬁnd the support of the process Xt ∈R2
given by
dXt = 1
2Xtdt +
·
0
1
1
0
¸
XtdBt .
6.11. Consider Example 6.2.1, but now without the assumption that
E[X] = 0. Show that
b
Xk =
m2
ka2 + m2 E[X] +
a2
a2 + 1
km2 Zk ;
k = 1, 2, . . .
(Compare with (6.2.8).)
(Hint: Put ξ = X −E[X], ζk = Zk −E[X]. Then apply (6.2.8) with
X replaced by ξ and Zk replaced by ζk.)
6.12. Prove formula (6.2.16).
(Hint: exp
¡
−
sR
r
F(u)du) is an integrating factor for the stochastic
diﬀerential equation (6.2.3).)
6.13. Consider the 1-dimensional linear ﬁltering problem (6.2.3), (6.2.4).
Find
E[ b
Xt]
and
E[( b
Xt)2] .
(Hint: Use Theorem 6.1.2 and use the deﬁnition of the mean square
error S(t).)
6.14. Let Bt be 1-dimensional Brownian motion.
a) Give an example of a process Zt of the form
dZt = u(t, ω)dt + dBt
such that Zt is a Brownian motion w.r.t. P and u(t, ω) ∈V is not
identically 0.
(Hint: Choose Zt to be the innovation process (6.2.13) in a linear
ﬁltering problem with D(t) ≡1.)
b) Show that the ﬁltration {Zt}t≥0 generated by a process Zt as in a)
must be strictly smaller than {Ft}t≥0, i.e. show that
Zt ⊆Ft
for all t and Zt ̸= Ft for some t .
(Hint: Use Exercise 4.12.)

7. Diﬀusions: Basic Properties
7.1 The Markov Property
Suppose we want to describe the motion of a small particle suspended in a
moving liquid, subject to random molecular bombardments. If b(t, x) ∈R3
is the velocity of the ﬂuid at the point x at time t, then a reasonable math-
ematical model for the position Xt of the particle at time t would be a
stochastic diﬀerential equation of the form
dXt
dt
= b(t, Xt) + σ(t, Xt)Wt ,
(7.1.1)
where Wt ∈R3 denotes “white noise” and σ(t, x) ∈R3×3. The Itˆo interpre-
tation of this equation is
dXt = b(t, Xt)dt + σ(t, Xt)dBt ,
(7.1.2)
where Bt is 3-dimensional Brownian motion, and similarly (with a correction
term added to b) for the Stratonovich interpretation (see (6.1.3)).
In a stochastic diﬀerential equation of the form
dXt = b(t, Xt)dt + σ(t, Xt)dBt ,
(7.1.3)
where Xt ∈Rn, b(t, x) ∈Rn, σ(t, x) ∈Rn×m and Bt is m-dimensional
Brownian motion, we will call b the drift coeﬃcient and σ – or sometimes
1
2σσT – the diﬀusion coeﬃcient (see Theorem 7.3.3).
Thus the solution of a stochastic diﬀerential equation may be thought of
as the mathematical description of the motion of a small particle in a moving
ﬂuid: Therefore such stochastic processes are called (Itˆo) diﬀusions.
In this chapter we establish some of the most basic properties and results
about Itˆo diﬀusions:
7.1 The Markov property.
7.2 The strong Markov property.
7.3 The generator A of Xt expressed in terms of b and σ.
7.4 The Dynkin formula.
7.5 The characteristic operator.

110
7. Diﬀusions: Basic Properties
This will give us the necessary background for the applications in the
remaining chapters.
Deﬁnition 7.1.1. A (time-homogeneous) Itˆo diﬀusion is a stochastic process
Xt(ω) = X(t, ω): [0, ∞)×Ω→Rn satisfying a stochastic diﬀerential equation
of the form
dXt = b(Xt)dt + σ(Xt)dBt ,
t ≥s ;
Xs = x
(7.1.4)
where Bt is m-dimensional Brownian motion and b: Rn →Rn, σ: Rn →
Rn×m satisfy the conditions in Theorem 5.2.1, which in this case simplify to:
|b(x) −b(y)| + |σ(x) −σ(y)| ≤D|x −y| ;
x, y ∈Rn ,
(7.1.5)
where |σ|2 = P |σij|2.
We will denote the (unique) solution of (7.1.4) by Xt = Xs,x
t
; t ≥s. If
s = 0 we write Xx
t for X0,x
t
. Note that we have assumed in (7.1.4) that b and
σ do not depend on t but on x only. We shall see later (Chapters 10, 11) that
the general case can be reduced to this situation. The resulting process Xt(ω)
will have the property of being time-homogeneous, in the following sense:
Note that
Xs,x
s+h = x +
s+h
Z
s
b(Xs,x
u )du +
s+h
Z
s
σ(Xs,x
u )dBu
= x +
h
Z
0
b(Xs,x
s+v)dv +
h
Z
0
σ(Xs,x
s+v)d eBv ,
(u = s + v)
(7.1.6)
where eBv = Bs+v −Bs; v ≥0. (See Exercise 2.12). On the other hand of
course
X0,x
h
= x +
h
Z
0
b(X0,x
v
)dv +
h
Z
0
σ(X0,x
v
)dBv .
Since { eBv}v≥0 and {Bv}v≥0 have the same P 0-distributions, it follows by
weak uniqueness (Lemma 5.3.1) of the solution of the stochastic diﬀerential
equation
dXt = b(Xt)dt + σ(Xt)dBt ;
X0 = x
that
{Xs,x
s+h}h≥0
and
{X0,x
h }h≥0
have the same P 0-distributions, i.e. {Xt}t≥0 is time-homogeneous.
We now introduce the probability laws Qx of {Xt}t≥0, for x ∈Rn. Intu-
itively, Qx gives the distribution of {Xt}t≥0 assuming that X0 = x. To express

7.1 The Markov Property
111
this mathematically, we let M∞be the σ-algebra (of subsets of Ω) generated
by the random variables ω →Xt(ω) = Xy
t (ω), where t ≥0, y ∈Rn.
Deﬁne Qx on the members of M by
Qx[Xt1 ∈E1, · · · , Xtk ∈Ek] = P 0[Xx
t1 ∈E1, · · · , Xx
tk ∈Ek]
(7.1.7)
where Ei ⊂Rn are Borel sets; 1 ≤i ≤k.
As before we let F(m)
t
be the σ-algebra generated by {Br; r ≤t}. Similarly
we let Mt be the σ-algebra generated by {Xr; r ≤t}. We have established
earlier (see Theorem 5.2.1) that Xt is measurable with respect to F(m)
t
, so
Mt ⊆F(m)
t
.
We now prove that Xt satisﬁes the important Markov property: The fu-
ture behaviour of the process given what has happened up to time t is the
same as the behaviour obtained when starting the process at Xt. The precise
mathematical formulation of this is the following:
Theorem 7.1.2 (The Markov property for Itˆo diﬀusions).
Let f be a bounded Borel function from Rn to R. Then, for t, h ≥0
Ex[f(Xt+h)|F(m)
t
](ω) = EXt(ω)[f(Xh)] .
(7.1.8)
(See Appendix B for deﬁnition and basic properties of conditional ex-
pectation). Here and in the following Ex denotes the expectation w.r.t. the
probability measure Qx. Thus Ey[f(Xh)] means E[f(Xy
h)], where E denotes
the expectation w.r.t. the measure P 0. The right hand side means the func-
tion Ey[f(Xh)] evaluated at y = Xt(ω).
Proof. Since, for r ≥t,
Xr(ω) = Xt(ω) +
r
Z
t
b(Xu)du +
r
Z
t
σ(Xu)dBu ,
we have by uniqueness
Xr(ω) = Xt,Xt
r
(ω) .
In other words, if we deﬁne
F(x, t, r, ω) = Xt,x
r (ω)
for r ≥t ,
we have
Xr(ω) = F(Xt, t, r, ω); r ≥t .
(7.1.9)
Note that ω →F(x, t, r, ω) is independent of F(m)
t
. Using (7.1.9) we may
rewrite (7.1.8) as
E[f(F(Xt, t, t + h, ω))|F(m)
t
] = E[f(F(x, 0, h, ω))]x=Xt .
(7.1.10)

112
7. Diﬀusions: Basic Properties
Put g(x, ω) = f ◦F(x, t, t + h, ω). Then (x, ω) →g(x, ω) is measurable. (See
Exercise 7.6). Hence we can approximate g pointwise boundedly by functions
on the form
m
X
k=1
φk(x)ψk(ω) .
Using the properties of conditional expectation (see Appendix B) we get
E[g(Xt, ω)|F(m)
t
] = E
·
lim
X
φk(Xt)ψk(ω)|F(m)
t
¸
= lim
X
φk(Xt) · E[ψk(ω)|F(m)
t
]
= lim
X
E[φk(y)ψk(ω)|F(m)
t
]y=Xt
= E[g(y, ω)|F(m)
t
]y=Xt = E[g(y, ω)]y=Xt .
Therefore, since {Xt} is time-homogeneous,
E[f(F(Xt, t, t + h, ω))|F(m)
t
] = E[f(F(y, t, t + h, ω))]y=Xt
= E[f(F(y, 0, h, ω))]y=Xt
which is (7.1.10).
⊔⊓
Remark. Theorem 7.1.2 states that Xt is a Markov process w.r.t. the family
of σ-algebras {F(m)
t
}t≥0. Note that since Mt ⊆F(m)
t
this implies that Xt
is also a Markov process w.r.t. the σ-algebras {Mt}t≥0. This follows from
Theorem B.3 and Theorem B.2 c)( Appendix B):
Ex[f(Xt+h)|Mt] = Ex[Ex[f(Xt+h)|F(m)
t
]|Mt]
= Ex[EXt[f(Xh)]|Mt] = EXt[f(Xh)]
since EXt[f(Xh)] is Mt-measurable.
7.2 The Strong Markov Property
Roughly, the strong Markov property states that a relation of the form (7.1.8)
continues to hold if the time t is replaced by a random time τ(ω) of a more
general type called stopping time (or Markov time):
Deﬁnition 7.2.1. Let {Nt} be an increasing family of σ-algebras (of subsets
of Ω). A function τ: Ω→[0, ∞] is called a (strict) stopping time w.r.t. {Nt}
if
{ω; τ(ω) ≤t} ∈Nt ,
for all t ≥0 .
In other words, it should be possible to decide whether or not τ ≤t has
occurred on the basis of the knowledge of Nt.

7.2 The Strong Markov Property
113
Example 7.2.2. Let U ⊂Rn be open. Then the ﬁrst exit time
τU: = inf{t > 0; Xt /∈U}
is a stopping time w.r.t. {Mt}, since
{ω; τU ≤t} =
\
m
[
r∈Q
r<t
{ω; Xr /∈Km} ∈Mt
where {Km} is an increasing sequence of closed sets such that U = S
m
Km .
More generally, if H ⊂Rn is any set we deﬁne the ﬁrst exit time from H,
τH, as follows
τH = inf{t > 0; Xt /∈H} .
If we include the sets of measure 0 in Mt (which we do) then the family
{Mt} is right-continuous i.e. Mt = Mt+, where Mt+ = T
s>t
Ms (see Chung
(1982, Theorem 2.3.4., p. 61)) and therefore τH is a stopping time for any
Borel set H (see Dynkin (1965 II, 4.5.C.e.), p. 111)).
Deﬁnition 7.2.3. Let τ be a stopping time w.r.t. {Nt} and let N∞be the
smallest σ-algebra containing Nt for all t ≥0. Then the σ-algebra Nτ consists
of all sets N ∈N∞such that
N
\
{τ ≤t} ∈Nt
for all t ≥0 .
In the case when Nt = Mt, an alternative and more intuitive description
is:
Mτ = the σ-algebra generated by {Xmin(s,τ); s ≥0} .
(7.2.1)
(See Rao (1977, p. 2.15) or Stroock and Varadhan (1979, Lemma 1.3.3,
p. 33).) Similarly, if Nt = F(m)
t
, we get
F(m)
τ
= the σ-algebra generated by {Bs∧τ; s ≥0} .
Theorem 7.2.4 (The strong Markov property for Itˆo diﬀusions).
Let f be a bounded Borel function on Rn, τ a stopping time w.r.t. F(m)
t
,
τ < ∞a.s. Then
Ex[f(Xτ+h)|F(m)
τ
] = EXτ [f(Xh)]
for all h ≥0 .
(7.2.2)
Proof. We try to imitate the proof of the Markov property (Theorem 7.1.2).
For a.a. ω we have that Xτ,x
r
(ω) satisﬁes
Xτ,x
τ+h = x +
τ+h
Z
τ
b(Xτ,x
u )du +
τ+h
Z
τ
σ(Xτ,x
u )dBu .

114
7. Diﬀusions: Basic Properties
By the strong Markov property for Brownian motion (Gihman and Skorohod
(1974a, p. 30)) the process
eBv = Bτ+v −Bτ ;
v ≥0
is again a Brownian motion and independent of F(m)
τ
. Therefore
Xτ,x
τ+h = x +
h
Z
0
b(Xτ,x
τ+v)dv +
h
Z
0
σ(Xτ,x
τ+v)d eBv .
Hence {Xτ,x
τ+h}h≥0 must coincide a.e. with the strongly unique (see (5.2.8))
solution Yh of the equation
Yh = x +
h
Z
0
b(Yv)dv +
h
Z
0
σ(Yv)d eBv .
Since {Yh}h≥0 is independent of F(m)
τ
, {Xτ,x
τ+h} must be independent also.
Moreover, by weak uniqueness (Lemma 5.3.1) we conclude that
{Yh}h≥0 , and hence {Xτ,x
τ+h}h≥0, has the same law as {X0,x
h }h≥0 .
(7.2.3)
Put
F(x, t, r, ω) = Xt,x
r (ω)
for r ≥t .
Then (7.2.2) can be written
E[f(F(x, 0, τ + h, ω))|F(m)
τ
] = E[f(F(x, 0, h, ω))]x=X0,x
τ
.
Now, with Xt = X0,x
t
,
F(x, 0, τ + h, ω) = Xτ+h(ω) = x +
τ+h
Z
0
b(Xs)ds +
τ+h
Z
0
σ(Xs)dBs
= x +
τ
Z
0
b(Xs)ds +
τ
Z
0
σ(Xs)dBs +
τ+h
Z
τ
b(Xs)ds +
τ+h
Z
τ
σ(Xs)dBs
= Xτ +
τ+h
Z
τ
b(Xs)ds +
τ+h
Z
τ
σ(Xs)dBs
= F(Xτ, τ, τ + h, ω) .
Hence (7.2.2) gets the form
E[f(F(Xτ, τ, τ + h, ω))|F(m)
τ
] = E[f(F(x, 0, h, ω))]x=Xτ .

7.2 The Strong Markov Property
115
Put g(x, t, r, ω) = f(F(x, t, r, ω)). As in the proof of Theorem 7.1.2 we may
assume that g has the form
g(x, t, r, ω) =
X
k
φk(x)ψk(t, r, ω) .
Then, since Xτ,x
τ+h is independent of F(m)
τ
we get, using (7.2.3)
E[g(Xτ, τ, τ + h, ω)|F(m)
τ
] =
X
k
E[φk(Xτ)ψk(τ, τ + h, ω)|F(m)
τ
]
=
X
k
φk(Xτ)E[ψk(τ, τ +h, ω)|F(m)
τ
]=
X
k
E[φk(x)ψk(τ, τ +h, ω)|F(m)
τ
]x=Xτ
= E[g(x, τ, τ + h, ω)|F(m)
τ
]x=Xτ = E[g(x, τ, τ + h, ω)]x=Xτ
= E[f(Xτ,x
τ+h)]x=Xτ = E[f(X0,x
h )]x=Xτ = E[f(F(x, 0, h, ω))]x=Xτ .
⊔⊓
We now extend (7.2.2) to the following:
If f1, · · · , fk are bounded Borel functions on Rn, τ an F(m)
t
-stopping time,
τ < ∞a.s. then
Ex[f1(Xτ+h1)f2(Xτ+h2) · · · fk(Xτ+hk)|F(m)
τ
] = EXτ [f1(Xh1) · · · fk(Xhk)]
(7.2.4)
for all 0 ≤h1 ≤h2 ≤· · · ≤hk. This follows by induction: To illustrate the
argument we prove it in the case k = 2:
Ex[f1(Xτ+h1)f2(Xτ+h2)|F(m)
τ
] = Ex[Ex[f1(Xτ+h1)f2(Xτ+h2)|Fτ+h1]|F(m)
τ
]
= Ex[f1(Xτ+h1)Ex[f2(Xτ+h2)|Fτ+h1]|F(m)
τ
]
= Ex[f1(Xτ+h1)EXτ+h1[f2(Xh2−h1)]|F(m)
τ
]
= EXτ [f1(Xh1)EXh1[f2(Xh2−h1)]]
= EXτ [f1(Xh1)Ex[f2(Xh2)|F(m)
h1 ]] = EXτ [f1(Xh1)f2(Xh2)] ,
as claimed .
Next we proceed to formulate the general version we need: Let H be the
set of all real M∞-measurable functions. For t ≥0 we deﬁne the shift operator
θt: H →H
as follows:
If η = g1(Xt1) · · · gk(Xtk) (gi Borel measurable, ti ≥0) we put
θtη = g1(Xt1+t) · · · gk(Xtk+t) .
Now extend in the natural way to all functions in H by taking limits of sums
of such functions. Then it follows from (7.2.4) that
Ex[θτη|F(m)
τ
] = EXτ [η]
(7.2.5)
for all stopping times τ and all bounded η ∈H, where
(θτη)(ω) = (θtη)(ω)
if τ(ω) = t .

116
7. Diﬀusions: Basic Properties
Hitting distribution, harmonic measure and
the mean value property
We will apply this to the following situation: Let H ⊂Rn be measurable and
let τH be the ﬁrst exit time from H for an Itˆo diﬀusion Xt. Let α be another
stopping time, g a bounded continuous function on Rn and put
η = g(XτH)X{τH<∞} ,
τ α
H = inf{t > α; Xt /∈H} .
Then we have
θαη · X{α<∞} = g(Xτ α
H)X{τ α
H<∞} .
(7.2.6)
To prove (7.2.6) we approximate η by functions η(k); k = 1, 2, . . . , of the form
η(k) =
X
j
g(Xtj)X[tj,tj+1)(τH) ,
tj = j · 2−k, j = 0, 1, 2, . . .
Now
θtX[tj,tj+1)(τH) = θtX{∀r∈(0,tj)Xr∈H&∃s∈[tj,tj+1)Xs /∈H}
= X{∀r∈(0,tj)Xr+t∈H&∃s∈[tj,tj+1)Xs+t /∈H}
= X{∀u∈(t,tj+t)Xu∈H&∃v∈[tj+t,tj+1+t)Xv /∈H} = X[tj+t,tj+1+t)(τ t
H) .
So we see that
θtη = lim
k θtη(k) = lim
k
X
j
g(Xtj+t)X[tj+t,tj+1+t)(τ t
H)
= g(Xτ t
H) · X{τ t
H<∞} ,
which is (7.2.6) .
In particular, if α = τG with G ⊂⊂H measurable, τH < ∞a.s. Qx, then
we have τ α
H = τH and so
θτGg(XτH) = g(XτH) .
(7.2.7)

7.3 The Generator of an Itˆo Diﬀusion
117
So if f is any bounded measurable function we obtain from (7.2.5) and
(7.2.7):
Ex[f(XτH)] = Ex[EXτG[f(XτH)]] =
Z
∂G
Ey[f(XτH)] · Qx[XτG ∈dy] (7.2.8)
for x ∈G.
(Deﬁne µx
H(F) = Qx(XτH ∈F) and approximate f in L1(µx
H) by con-
tinuous functions g satisfying (7.2.7)). In other words, the expected value of
f at XτH when starting at x ∈G can be obtained by integrating the ex-
pected value when starting at y ∈∂G with respect to the hitting distribution
(“harmonic measure”) of X on ∂G. This can be restated as follows:
Deﬁne the harmonic measure of X on ∂G, µx
G, by
µx
G(F) = Qx[XτG ∈F]
for F ⊂∂G, x ∈G .
Then the function
φ(x) = Ex[f(XτH)]
satisﬁes the mean value property:
φ(x) =
Z
∂G
φ(y)dµx
G(y) ,
for all x ∈G
(7.2.9)
for all Borel sets G ⊂⊂H.
This is an important ingredient in our solution of the generalized Dirichlet
problem in Chapter 9.
7.3 The Generator of an Itˆo Diﬀusion
It is fundamental for many applications that we can associate a second order
partial diﬀerential operator A to an Itˆo diﬀusion Xt. The basic connection
between A and Xt is that A is the generator of the process Xt:
Deﬁnition 7.3.1. Let {Xt} be a (time-homogeneous) Itˆo diﬀusion in Rn.
The (inﬁnitesimal) generator A of Xt is deﬁned by
Af(x) = lim
t↓0
Ex[f(Xt)] −f(x)
t
;
x ∈Rn .
The set of functions f: Rn →R such that the limit exists at x is denoted by
DA(x), while DA denotes the set of functions for which the limit exists for
all x ∈Rn.

118
7. Diﬀusions: Basic Properties
To ﬁnd the relation between A and the coeﬃcients b, σ in the stochastic
diﬀerential equation (7.1.4) deﬁning Xt we need the following result, which
is useful in many connections:
Lemma 7.3.2. Let Yt = Y x
t be an Itˆo process in Rn of the form
Y x
t (ω) = x +
t
Z
0
u(s, ω)ds +
t
Z
0
v(s, ω)dBs(ω)
where B is m-dimensional. Let f ∈C2
0(Rn), i.e. f ∈C2(Rn) and f has
compact support, and let τ be a stopping time with respect to {F(m)
t
}, and
assume that Ex[τ] < ∞. Assume that u(t, ω) and v(t, ω) are bounded on the
set of (t, ω) such that Y (t, ω) belongs to the support of f. Then
Ex[f(Yτ)] =
f(x) + Ex
·
τ
Z
0
µX
i
ui(s, ω) ∂f
∂xi
(Ys) + 1
2
X
i,j
(vvT )i,j(s, ω)
∂2f
∂xi∂xj
(Ys)
¶
ds
¸
,
where Ex is the expectation w.r.t. the natural probability law Rx for Yt start-
ing at x:
Rx[Yt1 ∈F1, . . . , Ytk ∈Fk] = P 0[Y x
t1 ∈F1, . . . , Y x
tk ∈Fk] ,
Fi Borel sets .
Proof. Put Z = f(Y ) and apply Itˆo’s formula (To simplify the notation we
suppress the index t and let Y1, . . . , Yn and B1, . . . , Bm denote the coordinates
of Y and B, respectively)
dZ =
X
i
∂f
∂xi
(Y )dYi + 1
2
X
i,j
∂2f
∂xi∂xj
(Y )dYidYj
=
X
i
ui
∂f
∂xi
dt + 1
2
X
i,j
∂2f
∂xi∂xj
(vdB)i(vdB)j +
X
i
∂f
∂xi
(vdB)i .
Since
(vdB)i · (vdB)j =
µ X
k
vikdBk
¶µ X
n
vjndBn
¶
=
µ X
k
vikvjk
¶
dt = (vvT )ijdt ,
this gives
f(Yt) = f(Y0) +
t
Z
0
µ X
i
ui
∂f
∂xi
+ 1
2
X
i,j
(vvT )ij
∂2f
∂xi∂xj
¶
ds
+
X
i,k
t
Z
0
vik
∂f
∂xi
dBk .
(7.3.1)

7.3 The Generator of an Itˆo Diﬀusion
119
Hence
Ex[f(Yτ)] = f(x) + Ex
·
τ
Z
0
µ X
i
ui
∂f
∂xi
(Y ) + 1
2
X
i,j
(vvT )i,j
∂2f
∂xi∂xj
(Y )
¶
ds
¸
+
X
i,k
Ex
·
τ
Z
0
vik
∂f
∂xi
(Y )dBk
¸
.
(7.3.2)
If g is a bounded Borel function, |g| ≤M say, then for all integers k we have
Ex
· τ∧k
Z
0
g(Ys)dBs
¸
= Ex
·
k
Z
0
X{s<τ}g(Ys)dBs
¸
= 0 ,
since g(Ys) and X{s<τ} are both F(m)
s
-measurable. Moreover
Ex
·µ
τ
Z
0
g(Ys)dBs −
τ∧k
Z
0
g(Ys)dBs
¶2¸
= Ex
·
τ
Z
τ∧k
g2(Ys)ds
¸
≤M 2Ex[τ −τ ∧k] →0 .
Therefore
0 = lim
k→∞Ex
· τ∧k
Z
0
g(Ys)dBs
¸
= Ex[
τ
Z
0
g(Ys)dBs] .
Combining this with (7.3.2) we get Lemma 7.3.2.
⊔⊓
This gives immediately the formula for the generator A of an Itˆo diﬀusion:
Theorem 7.3.3. Let Xt be the Itˆo diﬀusion
dXt = b(Xt)dt + σ(Xt)dBt .
If f ∈C2
0(Rn) then f ∈DA and
Af(x) =
X
i
bi(x) ∂f
∂xi
+ 1
2
X
i,j
(σσT )i,j(x)
∂2f
∂xi∂xj
.
(7.3.3)
Proof. This follows from Lemma 7.3.2 (with τ = t) and the deﬁnition of A.
⊔⊓

120
7. Diﬀusions: Basic Properties
Example 7.3.4. The n-dimensional Brownian motion is of course the solu-
tion of the stochastic diﬀerential equation
dXt = dBt ,
i.e. we have b = 0 and σ = In, the n-dimensional identity matrix. So the
generator of Bt is
Af = 1
2
X ∂2f
∂x2
i
;
f = f(x1, . . . , xn) ∈C2
0(Rn)
i.e. A = 1
2∆, where ∆is the Laplace operator.
Example 7.3.5 (The graph of Brownian motion). Let B denote 1-di-
mensional Brownian motion and let X =
µ
X1
X2
¶
be the solution of the
stochastic diﬀerential equation
½
dX1 = dt ;
X1(0) = t0
dX2 = dB ;
X2(0) = x0
i.e.
dX = bdt + σdB ;
X(0) =
µ
t0
X0
¶
,
with b =
µ
1
0
¶
and σ =
µ
0
1
¶
. In other words, X may be regarded as the
graph of Brownian motion. The generator A of X is given by
Af = ∂f
∂t + 1
2
∂2f
∂x2 ;
f = f(t, x) ∈C2
0(Rn) .
From now on we will, unless otherwise stated, let A = AX denote the
generator of the Itˆo diﬀusion Xt. We let L = LX denote the diﬀerential
operator given by the right hand side of (7.3.3). From Theorem 7.3.3 we
know that AX and LX coincide on C2
0(Rn).
7.4 The Dynkin Formula
If we combine (7.3.2) and (7.3.3) we get:
Theorem 7.4.1 (Dynkin’s formula).
Let f ∈C2
0(Rn). Suppose τ is a stopping time, Ex[τ] < ∞. Then
Ex[f(Xτ)] = f(x) + Ex
·
τ
Z
0
Af(Xs)ds
¸
.
(7.4.1)

7.4 The Dynkin Formula
121
Remarks.
(i) Note that if τ is the ﬁrst exit time of a bounded set, Ex[τ] < ∞, then
(7.4.1) holds for any function f ∈C2.
(ii) For a more general version of Theorem 7.4.1 see Dynkin (1965 I), p. 133.
Example 7.4.2. Consider n-dimensional Brownian motion B = (B1, . . . , Bn)
starting at a = (a1, . . . , an) ∈Rn(n ≥1) and assume |a| < R. What is the
expected value of the ﬁrst exit time τK of B from the ball
K = KR = {x ∈Rn; |x| < R} ?
Choose an integer k and apply Dynkin’s formula with X = B, τ = σk =
min(k, τK), and f ∈C2
0 such that f(x) = |x|2 for |x| ≤R :
Ea[f(Bσk)] = f(a) + Ea
· σk
Z
0
1
2∆f(Bs)ds
¸
= |a|2 + Ea
· σk
Z
0
n · ds
¸
= |a|2 + n · Ea[σk] .
Hence Ea[σk] ≤1
n(R2 −|a|2) for all k. So letting k →∞we conclude that
τK = lim σk < ∞a.s. and
Ea[τK] = 1
n(R2 −|a|2) .
(7.4.2)
Next we assume that n ≥2 and |b| > R. What is the probability that B
starting at b ever hits K?
Let αk be the ﬁrst exit time from the annulus
Ak = {x; R < |x| < 2kR} ;
k = 1, 2, . . .
and put
TK = inf{t > 0; Bt ∈K} .
Let f = fn,k be a C2 function with compact support such that, if R ≤|x|
≤2kR,
f(x) =
½
−log |x|
when n = 2
|x|2−n
when n > 2 .
Then, since ∆f = 0 in Ak, we have by Dynkin’s formula
Eb[f(Bαk)] = f(b)
for all k .
(7.4.3)
Put
pk = P b[|Bαk| = R] ,
qk = P b[|Bαk| = 2kR] .

122
7. Diﬀusions: Basic Properties
Let us now consider the two cases n = 2 and n > 2 separately:
n = 2.
Then we get from (7.4.3)
−log R · pk −(log R + k · log 2)qk = −log |b|
for all k .
(7.4.4)
This implies that qk →0 as k →∞, so that
P b[TK < ∞] = 1 ,
(7.4.5)
i.e. Brownian motion is recurrent in R2. (See Port and Stone (1979)).
n > 2.
In this case (7.4.3) gives
pk · R2−n + qk · (2kR)2−n = |b|2−n .
Since 0 ≤qk ≤1 we get by letting k →∞
lim
k→∞pk = P b[TK < ∞] =
µ|b|
R
¶2−n
,
i.e. Brownian motion is transient in Rn for n > 2.
7.5 The Characteristic Operator
We now introduce an operator which is closely related to the generator A,
but is more suitable in many situations, for example in the solution of the
Dirichlet problem.
Deﬁnition 7.5.1. Let {Xt} be an Itˆo diﬀusion. The characteristic operator
A = AX of {Xt} is deﬁned by
Af(x) = lim
U↓x
Ex[f(XτU )] −f(x)
Ex[τU ]
,
(7.5.1)
where the U ′s are open sets Uk decreasing to the point x, in the sense that
Uk+1 ⊂Uk and T
k
Uk = {x}, and τU = inf{t > 0; Xt /∈U} is the ﬁrst exit
time from U for Xt. The set of functions f such that the limit (7.5.1) exists
for all x ∈Rn (and all {Uk}) is denoted by DA. If Ex[τU ] = ∞for all open
U ∋x, we deﬁne Af(x) = 0.
It turns out that DA ⊆DA always and that
Af = Af
for all f ∈DA .
(See Dynkin (1965 I, p. 143).)
We will only need that AX and LX coincide on C2. To obtain this we
ﬁrst clarify a property of exit times.

7.5 The Characteristic Operator
123
Deﬁnition 7.5.2. A point x ∈Rn is called a trap for {Xt} if
Qx({Xt = x for all t}) = 1 .
In other words, x is trap if and only if τ{x} = ∞a.s. Qx. For example, if
b(x0) = σ(x0) = 0, then x0 is a trap for Xt (by strong uniqueness of Xt).
Lemma 7.5.3. If x is not a trap for Xt, then there exists an open set U ∋x
such that
Ex[τU ] < ∞.
Proof. See Lemma 5.5 p. 139 in Dynkin (1965 I).
Theorem 7.5.4. Let f ∈C2. Then f ∈DA and
Af =
X
i
bi
∂f
∂xi
+ 1
2
X
i,j
(σσT )ij
∂2f
∂xi∂xj
.
(7.5.2)
Proof. As before we let L denote the operator deﬁned by the right hand side
of (7.5.2). If x is a trap for {Xt} then Af(x) = 0. Choose a bounded open set
V such that x ∈V . Modify f to f0 outside V such that f0 ∈C2
0(Rn). Then
f0 ∈DA(x) and 0 = Af0(x) = Lf0(x) = Lf(x). Hence Af(x) = Lf(x) = 0
in this case. If x is not a trap, choose a bounded open set U ∋x such that
Ex[τU ] < ∞. Then by Dynkin’s formula (Theorem 7.4.1) (and the following
Remark (i)), writing τU = τ
¯¯¯¯
Ex[f(Xτ)] −f(x)
Ex[τ]
−Lf(x)
¯¯¯¯ =
|Ex[
τR
0
{(Lf)(Xs) −Lf(x)}ds]|
Ex[τ]
≤sup
y∈U
|Lf(x) −Lf(y)| →0
as U ↓x ,
since Lf is a continuous function.
Remark. We have now obtained that an Itˆo diﬀusion is a continuous, strong
Markov process such that the domain of deﬁnition of its characteristic oper-
ator includes C2. Thus an Itˆo diﬀusion is a diﬀusion in the sense of Dynkin
(1965 I).
Example 7.5.5 (Brownian motion on the unit circle). The character-
istic operator of the process Y =
µ
Y1
Y2
¶
from Example 5.1.4 satisfying the
stochastic diﬀerential equations (5.1.13), i.e.



dY1 = −1
2Y1dt −Y2dB
dY2 = −1
2Y2dt + Y1dB

124
7. Diﬀusions: Basic Properties
is
Af(y1, y2) = 1
2
·
y2
2
∂2f
∂y2
1
−2y1y2
∂2f
∂y1∂y2
+ y2
1
∂2f
∂y2
2
−y1
∂f
∂y1
−y2
∂f
∂y2
¸
.
This is because dY = −1
2Y dt + KY dB, where
K =
µ
0
−1
1
0
¶
so that
dY = b(Y )dt + σ(Y )dB
with
b(y1, y2) =
Ã
−1
2y1
−1
2y2
!
,
σ(y1, y2) =
µ
−y2
y1
¶
and
a = 1
2σσT = 1
2
µ
y2
2
−y1y2
−y1y2
y2
1
¶
.
Example 7.5.6. Let D be an open subset of Rn such that τD < ∞a.s. Qx
for all x. Let φ be a bounded, measurable function on ∂D and deﬁne
eφ(x) = Ex[φ(XτD)]
(eφ is called the X-harmonic extension of φ). Then if U is open, x ∈U ⊂⊂D,
we have by (7.2.8) that
Ex[eφ(XτU )] = Ex[EXτU [φ(XτD)]] = Ex[φ(XτD)] = eφ(x) .
So eφ ∈DA and
Aeφ = 0
in D ,
in spite of the fact that in general eφ need not even be continuous in D (See
Example 9.2.1).
Exercises
7.1.
Find the generator of the following Itˆo diﬀusions:
a) dXt = µXtdt + σdBt (The Ornstein-Uhlenbeck process) (Bt ∈R;
µ, σ constants).
b) dXt = rXtdt + αXtdBt (The geometric Brownian motion)
(Bt ∈R; r, α constants).
c) dYt = r dt + αYtdBt (Bt ∈R; r, α constants)

Exercises
125
d) dYt =
·
dt
dXt
¸
where Xt is as in a)
e)
·
dX1
dX2
¸
=
·
1
X2
¸
dt +
·
0
eX1
¸
dBt
(Bt ∈R)
f)
·
dX1
dX2
¸
=
·
1
0
¸
dt +
·
1
0
0
X1
¸ ·
dB1
dB2
¸
g) X(t) = (X1, X2, · · · , Xn), where
dXk(t) = rkXkdt + Xk ·
n
X
j=1
αkjdBj ;
1 ≤k ≤n
((B1, · · · , Bn) is Brownian motion in Rn, rk and αkj are constants).
7.2.
Find an Itˆo diﬀusion (i.e. write down the stochastic diﬀerential equa-
tion for it) whose generator is the following:
a) Af(x) = f ′(x) + f ′′(x) ; f ∈C2
0(R)
b) Af(t, x) = ∂f
∂t + cx ∂f
∂x + 1
2α2x2 ∂2f
∂x2 ; f ∈C2
0(R2),
where c, α are constants.
c) Af(x1, x2) = 2x2
∂f
∂x1 + ln(1 + x2
1 + x2
2) ∂f
∂x2
+ 1
2(1 + x2
1) ∂2f
∂x2
1 + x1
∂2f
∂x1∂x2 + 1
2 · ∂2f
∂x2
2 ; f ∈C2
0(R2).
7.3.
Let Bt be Brownian motion on R, B0 = 0 and deﬁne
Xt = Xx
t = x · ect+αBt ,
where c, α are constants. Prove directly from the deﬁnition that Xt is
a Markov process.
7.4.
Let Bx
t be 1-dimensional Brownian motion starting at x ∈R+. Put
τ = inf{t > 0; Bx
t = 0} .
a) Prove that τ < ∞a.s. P x for all x > 0. (Hint: See Example 7.4.2,
second part).
b) Prove that Ex[τ] = ∞for all x > 0. (Hint: See Example 7.4.2, ﬁrst
part).
7.5.
Let the functions b, σ satisfy condition (5.2.1) of Theorem 5.2.1, with
a constant C independent of t, i.e.
|b(t, x)| + |σ(t, x)| ≤C(1 + |x|)
for all x ∈Rn and all t ≥0 .
Let Xt be a solution of
dXt = b(t, Xt)dt + σ(t, Xt)dBt .

126
7. Diﬀusions: Basic Properties
Show that
E[|Xt|2] ≤(1 + E[|X0|2])eKt −1
for some constant K independent of t.
(Hint: Use Dynkin’s formula with f(x) = |x|2 and τ = t ∧τR, where
τR = inf {t > 0; |Xt| ≥R}, and let R →∞to achieve the inequality
E[|Xt|2] ≤E[|X0|2] + K ·
t
Z
0
(1 + E[|Xs|2])ds ,
which is of the form (5.2.9).)
7.6.
Let g(x, ω) = f ◦F(x, t, t + h, ω) be as in the proof of Theorem 7.1.2.
Assume that f is continuous.
a) Prove that the map x →g(x, ·) is continuous from Rn into L2(P)
by using (5.2.9).
For simplicity assume that n = 1 in the following.
b) Use a) to prove that (x, ω) →g(x, ω) is measurable. (Hint: For each
m = 1, 2, . . . put ξk = ξ(m)
k
= k · 2−m, k = 1, 2, . . . Then
g(m)(x, ·): =
X
k
g(ξk, ·) · X{ξk≤x<ξk+1}
converges to g(x, ·) in L2(P) for each x. Deduce that g(m) →g
in L2(dmR × dP) for all R, where dmR is Lebesgue measure on
{|x| ≤R}. So a subsequence of g(m)(x, ω) converges to g(x, ω) for
a.a. (x, ω).)
7.7.
Let Bt be Brownian motion on Rn starting at x∈Rn and let D⊂Rn
be an open ball centered at x.
a) Use Exercise 2.15 to prove that the harmonic measure µx
D of Bt is
rotation invariant (about x) on the sphere ∂D. Conclude that µx
D
coincides with normalized surface measure σ on ∂D.
b) Let φ be a bounded measurable function on a bounded open set
W ⊂Rn and deﬁne
u(x) = Ex[φ(BτW )]
for x ∈W .
Prove that u satisﬁes the classical mean value property:
u(x) =
Z
∂D
u(y)dσ(y)
for all balls D centered at x with D ⊂W.

Exercises
127
7.8.
Let {Nt} be a right-continuous family of σ-algebras of subsets of Ω,
containing all sets of measure zero.
a) Let τ1, τ2 be stopping times (w.r.t. Nt). Prove that τ1∧τ2 and τ1∨τ2
are stopping times.
b) If {τn} is a decreasing family of stopping times prove that τ: =
lim
n τn is a stopping time.
c) If Xt is an Itˆo diﬀusion in Rn and F ⊂Rn is closed, prove that τF
is a stopping time w.r.t. Mt. (Hint: Consider open sets decreasing
to F).
7.9.
Let Xt be a geometric Brownian motion, i.e.
dXt = rXtdt + αXtdBt ,
X0 = x > 0
where Bt ∈R; r, α are constants.
a) Find the generator A of Xt and compute Af(x) when f(x) = xγ;
x > 0, γ constant.
b) If r <
1
2α2 then Xt →0 as t →∞, a.s. Qx (Example 5.1.1).
But what is the probability p that Xt, when starting from x < R,
ever hits the value R ? Use Dynkin’s formula with f(x) = xγ1,
γ1 = 1 −2r
α2 , to prove that
p =
µ x
R
¶γ1
.
c) If r > 1
2α2 then Xt →∞as t →∞, a.s. Qx. Put
τ = inf{t > 0; Xt ≥R} .
Use Dynkin’s formula with f(x) = ln x, x > 0 to prove that
Ex[τ] =
ln R
x
r −1
2α2 .
(Hint: First consider exit times from (ρ, R), ρ > 0 and then let
ρ →0. You need estimates for
(1 −p(ρ)) ln ρ ,
where
p(ρ) = Qx[Xt reaches the value R before ρ ] ,
which you can get from the calculations in a), b).)

128
7. Diﬀusions: Basic Properties
7.10. Let Xt be the geometric Brownian motion
dXt = rXtdt + αXtdBt .
Find Ex[XT |Ft]
for t ≤T by
a) using the Markov property
and
b) writing Xt = x ertMt, where
Mt = exp(αBt −1
2α2t)
is a martingale .
7.11. Let Xt be an Itˆo diﬀusion in Rn and let f: Rn →R be a function such
that
Ex
· ∞
Z
0
|f(Xt)|dt
¸
< ∞
for all x ∈Rn .
Let τ be a stopping time. Use the strong Markov property to prove
that
Ex
· ∞
Z
τ
f(Xt)dt
¸
= Ex[g(Xτ)] ,
where
g(y) = Ey
· ∞
Z
0
f(Xt)dt
¸
.
7.12. (Local martingales)
An Nt-adapted stochastic process Z(t) ∈Rn is called a local martin-
gale with respect to the given ﬁltration {Nt} if there exists an increas-
ing sequence of Nt-stopping times τk such that
τk →∞
a.s. as k →∞
and
Z(t ∧τk)
is an Nt-martingale for all k .
a) Show that if Z(t) is a local martingale and there exists a constant
T ≤∞such that the family {Z(τ)}τ≤T is uniformly integrable
(Appendix C) then {Z(t)}t≤T is a martingale.
b) In particular, if Z(t) is a local martingale and there exists a constant
K < ∞such that
E[Z2(τ)] ≤K
for all stopping times τ ≤T, then {Z(t)}t≤T is a martingale.
c) Show that if Z(t) is a lower bounded local martingale, then Z(t) is
a supermartingale (Appendix C).

Exercises
129
7.13. a) Let Bt ∈R2, B0 = x ̸= 0. Fix 0 < ϵ < R < ∞and deﬁne
Xt = ln |Bt∧τ| ;
t ≥0
where
τ = inf {t > 0; |Bt| ≤ϵ
or
|Bt| ≥R} .
Prove that Xt is an Ft∧τ-martingale. (Hint: Use Exercise 4.8.)
Deduce that ln |Bt| is a local martingale (Exercise 7.12).
b) Let Bt ∈Rn for n ≥3, B0 = x ̸= 0. Fix ϵ > 0, R < ∞and deﬁne
Yt = |Bt∧τ|2−n ;
t ≥0
where
τ = inf{t > 0; |Bt| ≤ϵ
or
|Bt| ≥R} .
Prove that Yt is an Ft∧τ-martingale.
Deduce that |Bt|2−n is a local martingale.
7.14. (Doob’s h-transform)
Let Bt be n-dimensional Brownian motion, D ⊂Rn a bounded open
set and h > 0 a harmonic function on D (i.e. ∆h = 0 in D). Let Xt
be the solution of the stochastic diﬀerential equation
dXt = ∇(ln h)(Xt)dt + dBt
More precisely, choose an increasing sequence {Dk} of open subsets of
D such that Dk ⊂D and
∞
S
k=1
Dk = D. Then for each k the equation
above can be solved (strongly) for t < τDk. This gives in a natural way
a solution for t < τ: = lim
k→∞τDk.
a) Show that the generator A of Xt satisﬁes
Af = ∆(hf)
2h
for f ∈C2
0(D) .
In particular, if f = 1
h then Af = 0.
b) Use a) to show that if there exists x0 ∈∂D such that
lim
x→y∈∂D h(x) =
½
0
if y ̸= x0
∞
if y = x0
(i.e. h is a kernel function), then
lim
t→τ Xt = x0 a.s.
(Hint: Consider Ex[f(XT )] for suitable stopping times T and with
f = 1
h)

130
7. Diﬀusions: Basic Properties
In other words, we have imposed a drift on Bt which causes the
process to exit from D at the point x0 only. This can also be for-
mulated as follows: Xt is obtained by conditioning Bt to exit from
D at x0. See Doob (1984).
7.15. Let Bt be 1-dimensional and deﬁne
F(ω) = (BT (ω) −K)+
where K > 0, T > 0 are constants.
By the Itˆo representation theorem (Theorem 4.3.3) we know that there
exists φ ∈V(0, T) such that
F(ω) = E[F] +
T
Z
0
φ(t, ω)dBt .
How do we ﬁnd φ explicitly? This problem is of interest in mathe-
matical ﬁnance, where φ may be regarded as the replicating portfolio
for the contingent claim F (see Chapter 12). Using the Clark-Ocone
formula (see Karatzas and Ocone (1991) or Øksendal (1996)) one can
deduce that
φ(t, ω) = E[X[K,∞)(BT )|Ft] ;
t < T .
(7.5.3)
Use (7.5.3) and the Markov property of Brownian motion to prove that
for t < T we have
φ(t, ω) =
1
p
2π(T −t)
∞
Z
K
exp
µ
−(x −Bt(ω))2
2(T −t)
¶
dx .
(7.5.4)
7.16. Let Bt be 1-dimensional and let f: R →R be a bounded function.
Prove that if t < T then
Ex[f(BT )|Ft] =
1
p
2π(T −t)
Z
R
f(x) exp
µ
−(x −Bt(ω))2
2(T −t)
¶
dx .
(7.5.5)
(Compare with (7.5.4).)
7.17. Let Bt be 1-dimensional and put
Xt = (x1/3 + 1
3Bt)3 ;
t ≥0 .
Then we have seen in Exercise 4.15 that Xt is a solution of the stochas-
tic diﬀerential equation
dXt = 1
3X1/3
t
dt + X2/3
t
dBt ;
X0 = x .
(7.5.6)

Exercises
131
Deﬁne
τ = inf{t > 0; Xt = 0}
and put
Yt =
n Xt
for t ≤τ
0
for t > τ .
Prove that Yt is also a (strong) solution of (7.5.6). Why does not this
contradict the uniqueness assertion of Theorem 5.2.1?
(Hint: Verify that
Yt = x +
t
Z
0
1
3Y 1/3
s
ds +
t
Z
0
Y 2/3
s
dBs
for all t by splitting the integrals as follows:
t
Z
0
=
t∧τ
Z
0
+
t
Z
t∧τ
. )
7.18. a) Let
dXt = b(Xt)dt + σ(Xt)dBt ;
X0 = x
be a 1-dimensional Itˆo diﬀusion with characteristic operator A. Let
f ∈C2(R) be a solution of the diﬀerential equation
Af(x) = b(x)f ′(x) + 1
2σ2(x)f ′′(x) = 0 ;
x ∈R .
(7.5.7)
Let (a, b) ⊂R be an open interval such that x ∈(a, b) and put
τ = inf{t > 0; Xt ̸∈(a, b)} .
Assume that τ < ∞a.s. Qx and deﬁne
p = P x[Xτ = b] .
Use Dynkin’s formula to prove that if f(b) ̸= f(a) then
p = f(x) −f(a)
f(b) −f(a) .
(7.5.8)
In other words, the harmonic measure µx
(a,b) of X on ∂(a, b) = {a, b}
is given by
µx
(a,b)(b) = f(x) −f(a)
f(b) −f(a) ,
µx
(a,b)(a) = f(b) −f(x)
f(b) −f(a) .
(7.5.9)

132
7. Diﬀusions: Basic Properties
b) Now specialize to the process
Xt = x + Bt ;
t ≥0 .
Prove that
p = x −a
b −a .
(7.5.10)
c) Find p if
Xt = x + µt + σBt ;
t ≥0
where µ, σ ∈R are nonzero constants.
7.19. Let Bx
t be 1-dimensional Brownian motion starting at x > 0. Deﬁne
τ = τ(x, ω) = inf{t > 0; Bx
t (ω) = 0} .
From Exercise 7.4 we know that
τ < ∞
a.s. P x and Ex[τ] = ∞.
What is the distribution of the random variable τ(ω) ?
a) To answer this, ﬁrst ﬁnd the Laplace transform
g(λ): = Ex[e−λτ]
for λ > 0 .
(Hint: Let Mt = exp(−
√
2λ Bt −λt). Then
{Mt∧τ}t≥0
is a bounded martingale .
[Solution: g(λ) = exp(−
√
2λ x) .]
b) To ﬁnd the density f(t) of τ it suﬃces to ﬁnd f(t) = f(t, x) such
that
∞
Z
0
e−λtf(t)dt = exp(−
√
2λ x)
for all λ > 0
i.e. to ﬁnd the inverse Laplace transform of g(λ). Verify that
f(t, x) =
x
√
2πt3 exp
µ
−x2
2t
¶
;
t > 0 .

8. Other Topics in Diﬀusion Theory
In this chapter we study some other important topics in diﬀusion theory and
related areas. Some of these topics are not strictly necessary for the remaining
chapters, but they are all central in the theory of stochastic analysis and
essential for further applications. The following topics will be treated:
8.1 Kolmogorov’s backward equation. The resolvent.
8.2 The Feynman-Kac formula. Killing.
8.3 The martingale problem.
8.4 When is an Itˆo process a diﬀusion?
8.5 Random time change.
8.6 The Girsanov formula.
8.1 Kolmogorov’s Backward Equation. The Resolvent
In the following we let Xt be an Itˆo diﬀusion in Rn with generator A. If we
choose f ∈C2
0(Rn) and τ = t in Dynkin’s formula (7.4.1) we see that
u(t, x) = Ex[f(Xt)]
is diﬀerentiable with respect to t and
∂u
∂t = Ex[Af(Xt)] .
(8.1.1)
It turns out that the right hand side of (8.1.1) can be expressed in terms of
u also:
Theorem 8.1.1 (Kolmogorov’s backward equation).
Let f ∈C2
0(Rn).
a) Deﬁne
u(t, x) = Ex[f(Xt)] .
(8.1.2)
Then u(t, ·) ∈DA for each t and
∂u
∂t = Au ,
t > 0, x ∈Rn
(8.1.3)
u(0, x) = f(x) ;
x ∈Rn
(8.1.4)

134
8. Other Topics in Diﬀusion Theory
where the right hand side is to be interpreted as A applied to the function
x →u(t, x).
b) Moreover, if w(t, x) ∈C1,2(R × Rn) is a bounded function satisfying
(8.1.3), (8.1.4) then w(t, x) = u(t, x), given by (8.1.2).
Proof. a) Let g(x) = u(t, x). Then since t →u(t, x) is diﬀerentiable we have
Ex[g(Xr)] −g(x)
r
= 1
r · Ex[EXr[f(Xt)] −Ex[f(Xt)]]
= 1
r · Ex[Ex[f(Xt+r)|Fr] −Ex[f(Xt)|Fr]]
= 1
r · Ex[f(Xt+r) −f(Xt)]
= u(t + r, x) −u(t, x)
r
→∂u
∂t
as r ↓0 .
Hence
Au = lim
r↓0
Ex[g(Xr)] −g(x)
r
exists and
∂u
∂t = Au, as asserted .
Conversely, to prove the uniqueness statement in b) assume that a function
w(t, x) ∈C1,2(R × Rn) satisﬁes (8.1.3)–(8.1.4). Then
eAw: = −∂w
∂t + Aw = 0
for t > 0, x ∈Rn
(8.1.5)
and
w(0, x) = f(x) ,
x ∈Rn .
(8.1.6)
Fix (s, x) ∈R × Rn. Deﬁne the process Yt in Rn+1 by Yt = (s −t, X0,x
t
),
t ≥0. Then Yt has generator eA and so by (8.1.5) and Dynkin’s formula we
have, for all t ≥0,
Es,x[w(Yt∧τR)] = w(s, x) + Es,x
· t∧τR
Z
0
eAw(Yr)dr
¸
= w(s, x) ,
where τR = inf{t > 0; |Xt| ≥R}.
Letting R →∞we get
w(s, x) = Es,x[w(Yt)] ;
∀t ≥0 .
In particular, choosing t = s we get
w(s, x) = Es,x[w(Ys)] = E[w(0, X0,x
s
)] = E[f(X0,x
s
)] = Ex[f(Xs)] .
⊔⊓

8.1 Kolmogorov’s Backward Equation. The Resolvent
135
Remark.
If we introduce the operator Qt: f →E•[f(Xt)] then we have
u(t, x) = (Qtf)(x) and we may rewrite (8.1.1) and (8.1.3) as follows:
d
dt(Qtf) = Qt(Af) ;
f ∈C2
0(Rn)
(8.1.1)′
d
dt(Qtf) = A(Qtf) ;
f ∈C2
0(Rn) .
(8.1.3)′
Thus the equivalence of (8.1.1) and (8.1.3) amounts to saying that the oper-
ators Qt and A commute, in some sense. Arguing formally, it is tempting to
say that the solution of (8.1.1)′ and (8.1.3)′ is
Qt = etA
and therefore QtA = AQt. However, this argument would require a further
explanation, because in general A is an unbounded operator.
It is an important fact that the operator A always has an inverse, at least
if a positive multiple of the identity is subtracted from A. This inverse can
be expressed explicitly in terms of the diﬀusion Xt:
Deﬁnition 8.1.2. For α > 0 and g ∈Cb(Rn) we deﬁne the resolvent oper-
ator Rα by
Rαg(x) = Ex
· ∞
Z
0
e−αtg(Xt)dt
¸
.
(8.1.7)
Lemma 8.1.3. Rαg is a bounded continuous function.
Proof. Since Rαg(x) =
∞
R
0
e−αtEx[g(Xt)]dt, we see that Lemma 8.1.3 is a
direct consequence of the next result:
Lemma 8.1.4. Let g be a lower bounded, measurable function on Rn and
deﬁne, for ﬁxed t ≥0
u(x) = Ex[g(Xt)] .
a) If g is lower semicontinuous, then u is lower semicontinuous.
b) If g is bounded and continuous, then u is continuous. In other words, any
Itˆo diﬀusion Xt is Feller-continuous.
Proof. By (5.2.10) we have
E[|Xx
t −Xy
t |2] ≤|y −x|2C(t) ,
where C(t) does not depend on x and y. Let {yn} be a sequence of points
converging to x. Then
Xyn
t
→Xx
t
in L2(Ω, P) as n →∞.
So, by taking a subsequence {zn} of {yn} we obtain that
Xzn
t (ω) →Xx
t (ω)
for a.a. ω ∈Ω.

136
8. Other Topics in Diﬀusion Theory
a) If g is lower bounded and lower semicontinuous, then by the Fatou lemma
u(x) = E[g(Xx
t )] ≤E[ lim
n→∞g(Xzn
t )] ≤lim
n→∞E[g(Xzn
t )] = lim
n→∞u(zn) .
Therefore every sequence {yn} converging to x has a subsequence {zn}
such that u(x) ≤lim
n→∞u(zn). That proves that u is lower semicontinuous.
b) If g is bounded and continuous, the result in a) can be applied both to g
and −g. Hence both u and −u are lower semicontinuous and we conclude
that u is continuous.
⊔⊓
We now prove that Rα and α −A are inverse operators:
Theorem 8.1.5. a) If f ∈C2
0(Rn) then Rα(α −A)f = f for all α > 0.
b) If g ∈Cb(Rn) then Rαg ∈DA and (α −A)Rαg = g for all α > 0.
Proof. a) If f ∈C2
0(Rn) then by Dynkin’s formula
Rα(α −A)f(x) = (αRαf −RαAf)(x)
= α
∞
Z
0
e−αtEx[f(Xt)]dt −
∞
Z
0
e−αtEx[Af(Xt)]dt
=
∞¯¯¯
0
−e−αtEx[f(Xt)] +
∞
Z
0
e−αt d
dtEx[f(Xt)]dt −
∞
Z
0
e−αtEx[Af(Xt)]dt
= Ex[f(X0)] = f(x) .
b) If g ∈Cb(Rn) then by the strong Markov property
Ex[Rαg(Xt)] = Ex[EXt
· ∞
Z
0
e−αsg(Xs)ds
¸
]
= Ex[Exh
θt
µ ∞
Z
0
e−αsg(Xs)ds
¶
|Ft
i
] = Ex[Ex
· ∞
Z
0
e−αsg(Xt+s)ds|Ft
¸
]
= Ex
· ∞
Z
0
e−αsg(Xt+s)ds
¸
=
∞
Z
0
e−αsEx[g(Xt+s)]ds .
Integration by parts gives
Ex[Rαg(Xt)] = α
∞
Z
0
e−αs
t+s
Z
t
Ex[g(Xv)]dv ds .
This identity implies that Rαg ∈DA and
A(Rαg) = αRαg −g .
⊔⊓

8.2 The Feynman-Kac Formula. Killing
137
8.2 The Feynman-Kac Formula. Killing
With a little harder work we can obtain the following useful generalization
of Kolmogorov’s backward equation:
Theorem 8.2.1 (The Feynman-Kac formula).
Let f ∈C2
0(Rn) and q ∈C(Rn). Assume that q is lower bounded.
a) Put
v(t, x) = Ex
·
exp
µ
−
t
Z
0
q(Xs)ds
¶
f(Xt)
¸
.
(8.2.1)
Then
∂v
∂t = Av −qv ;
t > 0, x ∈Rn
(8.2.2)
v(0, x) = f(x) ;
x ∈Rn
(8.2.3)
b) Moreover, if w(t, x) ∈C1,2(R × Rn) is bounded on K × Rn for each
compact K ⊂R and w solves (8.2.2), (8.2.3), then w(t, x) = v(t, x),
given by (8.2.1).
Proof. a)
Let Yt = f(Xt), Zt = exp(−
tR
0
q(Xs)ds). Then dYt is given by
(7.3.1) and
dZt = −Ztq(Xt)dt .
So
d(YtZt) = YtdZt + ZtdYt ,
since dZt · dYt = 0 .
Note that since YtZt is an Itˆo process it follows from Lemma 7.3.2 that
v(t, x) = Ex[YtZt] is diﬀerentiable w.r.t. t.
Therefore, with v(t, x) as in (8.2.1) we get
1
r (Ex[v(t, Xr)] −v(t, x)) = 1
r Ex[EXr[Ztf(Xt)] −Ex[Ztf(Xt)]]
= 1
r Ex[Ex[f(Xt+r) exp
µ
−
t
Z
0
q(Xs+r)ds
¶
|Fr] −Ex[Ztf(Xt)|Fr]]
= 1
r Ex[Zt+r · exp
µ
r
Z
0
q(Xs)ds
¶
f(Xt+r) −Ztf(Xt)]
= 1
r Ex[f(Xt+r)Zt+r −f(Xt)Zt]
+1
r Exh
f(Xt+r)Zt+r ·
³
exp
µ
r
Z
0
q(Xs)ds
¶
−1
´i
→∂
∂tv(t, x) + q(x)v(t, x)
as r →0 ,

138
8. Other Topics in Diﬀusion Theory
because
1
r f(Xt+r)Zt+r
³
exp
µ
r
Z
0
q(Xs)ds
¶
−1
´
→f(Xt)Ztq(X0)
pointwise boundedly. That completes the proof of a).
b) Assume that w(t, x) ∈C1,2(R×Rn) satisﬁes (8.2.2) and (8.2.3) and that
w(t, x) is bounded on K × Rn for each compact K ⊂R. Then
bAw(t, x): = −∂w
∂t + Aw −qw = 0
for t > 0, x ∈Rn
(8.2.4)
and
w(0, x) = f(x) ;
x ∈Rn .
(8.2.5)
Fix (s, x, z) ∈R × Rn × Rn and deﬁne Zt = z +
tR
0
q(Xs)ds and Ht = (s −t,
X0,x
t
, Zt). Then Ht is an Itˆo diﬀusion with generator
AHφ(s, x, z) = −∂φ
∂s + Aφ + q(x)∂φ
∂z ;
φ ∈C2
0(R × Rn × Rn) .
Hence by (8.2.4) and Dynkin’s formula we have, for all t ≥0, R > 0 and with
φ(s, x, z) = exp(−z)w(s, x):
Es,x,z[φ(Ht∧τR)] = φ(s, x, z) + Es,x,z
· t∧τR
Z
0
AHφ(Hr)dr
¸
,
where τR = inf{t > 0; |Ht| ≥R}.
Note that with this choice of φ we have by (8.2.4)
AHφ(s, x, z) = exp(−z)
·
−∂w
∂s + Aw −q(x)w
¸
= 0 .
Hence
w(s, x) = φ(s, x, 0) = Es,x,0[φ(Ht∧τR)]
= Exh
exp
µ
−
t∧τR
Z
0
q(Xr)dr
¶
w(s −t ∧τR, Xt∧τR)
i
→Exh
exp
µ
−
t
Z
0
q(Xr)dr
¶
w(s −t, Xt)
i
as R →∞,
since w(r, x) is bounded for (r, x) ∈K ×Rn. In particular, choosing t = s we
get

8.2 The Feynman-Kac Formula. Killing
139
w(s, x) = Exh
exp
µ
−
s
Z
0
q(Xr)dr
¶
w(0, X0,x
s
)
i
= v(s, x) ,
as claimed .
⊔⊓
Remark. (About killing a diﬀusion)
In Theorem 7.3.3 we have seen that the generator of an Itˆo diﬀusion Xt given
by
dXt = b(Xt)dt + σ(Xt)dBt
(8.2.6)
is a partial diﬀerential operator L of the form
Lf =
X
aij
∂2f
∂xi∂xj
+
X
bi
∂f
∂xi
(8.2.7)
where [aij] = 1
2σσT , b = [bi]. It is natural to ask if one can also ﬁnd processes
whose generator has the form
Lf =
X
aij
∂2f
∂xi∂xj
+
X
bi
∂f
∂xi
−cf ,
(8.2.8)
where c(x) is a bounded and continuous function.
If c(x) ≥0 the answer is yes and a process e
Xt with generator (8.2.8) is
obtained by killing Xt at a certain (killing) time ζ. By this we mean that
there exists a random time ζ such that if we put
e
Xt = Xt
if t < ζ
(8.2.9)
and leave e
Xt undeﬁned if t ≥ζ (alternatively, put e
Xt = ∂if t ≥ζ, where
∂/∈Rn is some “coﬃn” state), then e
Xt is also a strong Markov process and
Ex[f( e
Xt)] = Ex[f(Xt), t < ζ] = Ex£
f(Xt) · e
−R t
0 c(Xs)ds¤
(8.2.10)
for all bounded continuous functions f on Rn.
Let v(t, x) denote the right hand side of (8.2.10) with f ∈C2
0(Rn). Then
lim
t→0
Ex[f( e
Xt)] −f(x)
t
= ∂
∂tv(t, x)t=0 = (Av −cv)t=0 = Af(x) −c(x)f(x) ,
by the Feynman-Kac formula.
So the generator of e
Xt is (8.2.8), as required. The function c(x) can be
interpreted as the killing rate:
c(x) = lim
t↓0
1
t Qx[X0 is killed in the time interval (0, t]] .
Thus by applying such a killing procedure we can come from the special case
c = 0 in (8.2.7) to the general case (8.2.8) with c(x) ≥0. Therefore, for many
purposes it is enough to consider the equation (8.2.7).
If the function c(x) ≥0 is given, an explicit construction of the killing
time ζ such that (8.2.10) holds can be found in Karlin and Taylor (1975),
p. 314. For a more general discussion see Blumenthal and Getoor (1968),
Chap. III.

140
8. Other Topics in Diﬀusion Theory
8.3 The Martingale Problem
If dXt = b(Xt)dt + σ(Xt)dBt is an Itˆo diﬀusion in Rn with generator A and
if f ∈C2
0(Rn) then by (7.3.1)
f(Xt) = f(x) +
t
Z
0
Af(Xs)ds +
t
Z
0
∇f T (Xs)σ(Xs)dBs .
(8.3.1)
Deﬁne
Mt = f(Xt) −
t
Z
0
Af(Xr)dr (= f(x) +
t
Z
0
∇f T (Xr)σ(Xr)dBr) .
(8.3.2)
Then, since Itˆo integrals are martingales (w.r.t. the σ-algebras {F(m)
t
}) we
have for s > t
Ex[Ms|F(m)
t
] = Mt .
It follows that
Ex[Ms|Mt] = Ex[Ex[Ms|F(m)
t
]|Mt] = Ex[Mt|Mt] = Mt ,
since Mt is Mt-measurable. We have proved:
Theorem 8.3.1. If Xt is an Itˆo diﬀusion in Rn with generator A, then for
all f ∈C2
0(Rn) the process
Mt = f(Xt) −
t
Z
0
Af(Xr)dr
is a martingale w.r.t. {Mt}.
If we identify each ω ∈Ωwith the function
ωt = ω(t) = Xx
t (ω)
we see that the probability space (Ω, M, Qx) is identiﬁed with
((Rn)[0,∞), B, eQx)
where B is the Borel σ-algebra on (Rn)[0,∞) (see Chapter 2). Thus, regarding
the law of Xx
t as a probability measure eQx on B we can formulate Theo-
rem 8.3.1 as follows:
Theorem 8.3.1’. If eQx is the probability measure on B induced by the law
Qx of an Itˆo diﬀusion Xt, then for all f ∈C2
0(Rn) the process

8.3 The Martingale Problem
141
Mt = f(Xt) −
t
Z
0
Af(Xr)dr (= f(ωt) −
t
Z
0
Af(ωr)dr) ;
ω ∈(Rn)[0,∞)
(8.3.3)
is a eQx-martingale w.r.t. the Borel σ-algebras Bt of (Rn)[0,t], t ≥0. In other
words, the measure eQx solves the martingale problem for the diﬀerential
operator A, in the following sense:
Deﬁnition 8.3.2. Let L be a semi-elliptic diﬀerential operator of the form
L =
X
bi
∂
∂xi
+
X
i,j
aij
∂2
∂xi∂xj
where the coeﬃcients bi, aij are locally bounded Borel measurable functions
on Rn. Then we say that a probability measure eP x on ((Rn)[0,∞), B) solves
the martingale problem for L (starting at x) if the process
Mt = f(ωt) −
t
Z
0
Lf(ωr)dr , M0 = f(x)
a.s. eP x
is a eP x martingale w.r.t. Bt, for all f ∈C2
0(Rn). The martingale problem
is called well posed if there is a unique measure eP x solving the martingale
problem.
The argument of Theorem 8.3.1 actually proves that eQx solves the mar-
tingale problem for A whenever Xt is a weak solution of the stochastic dif-
ferential equation
dXt = b(Xt)dt + σ(Xt)dBt .
(8.3.4)
Conversely, it can be proved that if eP x solves the martingale problem for
L =
X
bi
∂
∂xi
+ 1
2
X
(σσT )ij
∂2
∂xi∂xj
(8.3.5)
starting at x, for all x ∈Rn, then there exists a weak solution Xt of the
stochastic diﬀerential equation (8.3.4). Moreover, this weak solution Xt is a
Markov process if and only if the martingale problem for L is well posed.
(See Stroock and Varadhan (1979) or Rogers and Williams (1987)). There-
fore, if the coeﬃcients b, σ of (8.3.4) satisfy the conditions (5.2.1), (5.2.2) of
Theorem 5.2.1, we conclude that
eQx is the unique solution of the martingale problem
for the operator L given by (8.3.5) .
(8.3.6)
Lipschitz-continuity of the coeﬃcients of L is not necessary for the uniqueness
of the martingale problem. For example, one of the spectacular results of
Stroock and Varadhan (1979) is that

142
8. Other Topics in Diﬀusion Theory
L =
X
bi
∂
∂xi
+
X
aij
∂2
∂xi∂xj
has a unique solution of the martingale problem if [aij] is everywhere positive
deﬁnite, aij(x) is continuous, b(x) is measurable and there exists a constant
D such that
|b(x)| + |a(x)|
1
2 ≤D(1 + |x|)
for all x ∈Rn .
8.4 When is an Itˆo Process a Diﬀusion?
The Itˆo formula gives that if we apply a C2 function φ: U ⊂Rn →Rn to an
Itˆo process Xt the result φ(Xt) is another Itˆo process. A natural question is:
If Xt is an Itˆo diﬀusion will φ(Xt) be an Itˆo diﬀusion too? The answer is no
in general, but it may be yes in some cases:
Example 8.4.1 (The Bessel process). Let n ≥2. In Example 4.2.2 we
found that the process
Rt(ω) = |B(t, ω)| = (B1(t, ω)2 + · · · + Bn(t, ω)2)
1
2
satisﬁes the equation
dRt =
n
X
i=1
BidBi
Rt
+ n −1
2Rt
dt .
(8.4.1)
However, as it stands this is not a stochastic diﬀerential equation of the form
(5.2.3), so it is not apparent from (8.4.1) that R is an Itˆo diﬀusion. But this
will follow if we can show that
Yt: =
t
Z
0
n
X
i=1
Bi
|B|dBi
coincides in law with (i.e. has the same ﬁnite-dimensional distributions as)
1-dimensional Brownian motion eBt. For then (8.4.1) can be written
dRt = n −1
2Rt
dt + d eB
which is of the form (5.2.3), thus showing by weak uniqueness (Lemma 5.3.1)
that Rt is an Itˆo diﬀusion with generator
Af(x) = 1
2f ′′(x) + n −1
2x f ′(x)
as claimed in Example 4.2.2. One way of seeing that the process Yt coincides
in law with 1-dimensional Brownian motion eBt is to apply the following
result:

8.4 When is an Itˆo Process a Diﬀusion?
143
Theorem 8.4.2. An Itˆo process
dYt = vdBt ;
Y0 = 0 with v(t, ω) ∈Vn×m
H
coincides (in law) with n-dimensional Brownian motion if and only if
vvT (t, ω) = In
for a.a. (t, ω) w.r.t. dt × dP
(8.4.2)
where In is the n-dimensional identity matrix.
Note that in the example above we have
Yt =
t
Z
0
vdB
with
v =
· B1
|B|, . . . , Bn
|B|
¸
,
B =


B1
...
Bn


and since vvT = 1, we get that Yt is a 1-dimensional Brownian motion, as
required.
Theorem 8.4.2 is a special case of the following result, which gives a
necessary and suﬃcient condition for an Itˆo process to coincide in law with
a given diﬀusion: (We use the symbol ≃for “coincides in law with”).
Theorem 8.4.3. Let Xt be an Itˆo diﬀusion given by
dXt = b(Xt)dt + σ(Xt)dBt ,
b ∈Rn ,
σ ∈Rn×m,
X0 = x ,
and let Yt be an Itˆo process given by
dYt = u(t, ω)dt + v(t, ω)dBt ,
u ∈Rn ,
v ∈Rn×m,
Y0 = x .
Then Xt ≃Yt if and only if
Ex[u(t, ·)|Nt] = b(Y x
t )
and vvT (t, ω) = σσT (Y x
t )
(8.4.3)
for a.a. (t, ω) w.r.t. dt×dP, where Nt is the σ-algebra generated by Ys; s ≤t.
Proof. Assume that (8.4.3) holds. Let
A =
X
bi
∂
∂xi
+ 1
2
X
i,j
(σσT )ij
∂2
∂xi∂xj
be the generator of Xt and deﬁne, for f ∈C2
0(Rn),
Hf(t, ω) =
X
i
ui(t, ω) ∂f
∂xi
(Yt) + 1
2
X
i,j
(vvT )ij(t, ω)
∂2f
∂xi∂xj
(Yt) .

144
8. Other Topics in Diﬀusion Theory
Then by Itˆo’s formula (see (7.3.1)) we have, for s > t,
Ex[f(Ys)|Nt] = f(Yt) + Ex
·
s
Z
t
Hf(r, ω)dr|Nt
¸
+ Ex
·
s
Z
t
∇f T vdBr|Nt
¸
= f(Yt) + Ex
·
s
Z
t
Ex[Hf(r, ω)|Nr]dr|Nt
¸
= f(Yt) + Ex
·
s
Z
t
Af(Yr)dr|Nt
¸
by (8.4.3) ,
(8.4.4)
where Ex denotes expectation w.r.t. the law Rx of Yt (see Lemma 7.3.2).
Therefore, if we deﬁne
Mt = f(Yt) −
t
Z
0
Af(Yr)dr
(8.4.5)
then, for s > t,
Ex[Ms|Nt] = f(Yt) + Ex
·
s
Z
t
Af(Yr)dr|Nt
¸
−Ex
·
s
Z
0
Af(Yr)dr|Nt
¸
= f(Yt) −Ex
·
t
Z
0
Af(Yr)dr|Nt
¸
= Mt .
Hence Mt is a martingale w.r.t. the σ-algebras Nt and the law Rx. By unique-
ness of the solution of the martingale problem (see (8.3.6)) we conclude that
Xt ≃Yt.
Conversely, assume that Xt ≃Yt. Choose f ∈C2
0. By Itˆo’s formula (7.3.1)
we have, for a.a. (t, ω) w.r.t. dt × dP,
lim
h↓0
1
h(Ex[f(Yt+h)|Nt] −f(Yt))
= lim
h↓0
1
h
µ t+h
Z
t
Exh X
i
ui(s, ω) ∂f
∂xi
(Ys)
+ 1
2
X
i,j
(vvT )ij(s, ω)
∂2f
∂xi∂xj
(Ys)|Nt
i
ds
¶
(8.4.6)
=
X
i
Ex[ui(t, ω)|Nt] ∂f
∂xi
(Yt) + 1
2
X
i,j
Ex[(vvT )ij(t, ω)|Nt]
∂2f
∂xi∂xj
(Yt) . (8.4.7)
On the other hand, since Xt ≃Yt we know that Yt is a Markov process.
Therefore (8.4.6) coincides with

8.4 When is an Itˆo Process a Diﬀusion?
145
lim
h↓0
1
h(EYt[f(Yh)] −EYt[f(Y0)])
=
X
i
EYth
ui(0, ω) ∂f
∂xi
(Y0)
i
+ 1
2
X
i,j
EYth
(vvT )ij(0, ω)
∂2f
∂xi∂xj
(Y0)
i
=
X
i
EYt[ui(0, ω)] ∂f
∂xi
(Yt) + 1
2
X
i,j
EYt[(vvT )ij(0, ω)]
∂2f
∂xi∂xj
(Yt) .
(8.4.8)
Comparing (8.4.7) and (8.4.8) we conclude that
Ex[u(t, ω)|Nt] = EYt[u(0, ω)]
and
Ex[vvT (t, ω)|Nt] = EYt[vvT (0, ω)]
(8.4.9)
for a.a. (t, ω).
On the other hand, since the generator of Yt coincides with the generator
A of Xt we get from (8.4.8) that
EYt[u(0, ω)] = b(Yt)
and
EYt[vvT (0, ω)] = σσT (Yt)
for a.a. (t, ω) .
(8.4.10)
Combining (8.4.9) and (8.4.10) we conclude that
Ex[u|Nt] = b(Yt)
and
Ex[vvT |Nt] = σσT (Yt)
for a.a. (t, ω) .
(8.4.11)
From this we obtain (8.4.3) by using that in fact vvT (t, ·) is always Nt-
measurable, in the following sense:
Lemma 8.4.4. Let dYt = u(t, ω)dt + v(t, ω)dBt, Y0 = x be as in Theo-
rem 8.4.3. Then there exists an Nt-adapted process W(t, ω) such that
vvT (t, ω) = W(t, ω)
for a.a. (t, ω) .
Proof. By Itˆo’s formula we have (if Yi(t, ω) denotes component number i of
Y (t, ω))
YiYj(t, ω) = xixj +
t
Z
0
YidYj(s) +
t
Z
0
YjdYi(s) +
t
Z
0
(vvT )ij(s, ω)ds .
Therefore, if we put
Hij(t, ω) = YiYj(t, ω) −xixj −
t
Z
0
YidYj −
t
Z
0
YjdYi ,
1 ≤i, j ≤n
then Hij is Nt-adapted and
Hij(t, ω) =
t
Z
0
(vvT )ij(s, ω)ds .

146
8. Other Topics in Diﬀusion Theory
Therefore
(vvT )ij(t, ω) = lim
r↓0
H(t, ω) −H(t −r, ω)
r
for a.a. t. This shows Lemma 8.4.4 and the proof of Theorem 8.4.3 is complete.
⊔⊓
Remarks. 1) One may ask if also u(t, ·) must be Nt-measurable. However,
the following example shows that this fails even in the case when v = n = 1:
Let B1, B2 be two independent 1-dimensional Brownian motions and de-
ﬁne
dYt = B1(t)dt + dB2(t) .
Then we may regard Yt as noisy observations of the process B1(t). So by
Example 6.2.10 we have that
E[(B1(t, ω) −bB1(t, ω))2] = tanh(t) ,
where bB1(t, ω) = E[B1(t)|Nt] is the Kalman-Bucy ﬁlter. In particular,
B1(t, ω) cannot be Nt-measurable.
2) The process v(t, ω) need not be Nt-adapted either: Let Bt be 1-
dimensional Brownian motion and deﬁne
dYt = sign(Bt)dBt
(8.4.12)
where
sign(z) =
½
1
if z > 0
−1
if z ≤0 .
Tanaka’s formula says that
|Bt| = |B0| +
t
Z
0
sign(Bs)dBs + Lt
(8.4.13)
where Lt = Lt(ω) is local time of Bt at 0, a non-decreasing process which
only increases when Bt = 0 (see Exercise 4.10). Therefore the σ-algebra
Nt generated by {Ys; s ≤t} is contained in the σ-algebra Ht generated by
{|Bs|; s ≤t}. It follows that v(t, ω) = sign(Bt) cannot be Nt-adapted.
Corollary 8.4.5 (How to recognize a Brownian motion).
Let
dYt = u(t, ω)dt + v(t, ω)dBt
be an Itˆo process in Rn. Then Yt is a Brownian motion if and only if
Ex[u(t, ·)|Nt] = 0
and
vvT (t, ω) = In
(8.4.14)
for a.a. (t, ω).

8.5 Random Time Change
147
Remark. Using Theorem 8.4.3 one may now proceed to investigate when
the image Yt = φ(Xt) of an Itˆo diﬀusion Xt by a C2-function φ coincides in
law with an Itˆo diﬀusion Zt. Applying the criterion (8.4.3) one obtains the
following result:
φ(Xt) ∼Zt
if and only if
A[foφ] = bA[f]oφ
(8.4.15)
for all second order polynomials f(x1, . . . , xn) = P aixi + P cijxixj (and
hence for all f ∈C2
0) where A and bA are the generators of Xt and Zt re-
spectively. (Here o denotes function composition: (f ◦φ)(x) = f(φ(x)).) For
generalizations of this result, see Csink and Øksendal (1983), and Csink,
Fitzsimmons and Øksendal (1990).
8.5 Random Time Change
Let c(t, ω) ≥0 be an Ft-adapted process. Deﬁne
βt = β(t, ω) =
t
Z
0
c(s, ω)ds .
(8.5.1)
We will say that βt is a (random) time change with time change rate c(t, ω).
Note that β(t, ω) is also Ft-adapted and for each ω the map t →βt(ω) is
non-decreasing. Deﬁne αt = α(t, ω) by
αt = inf{s; βs > t} .
(8.5.2)
Then αt is a right-inverse of βt, for each ω :
β(α(t, ω), ω) = t
for all t ≥0 .
(8.5.3)
Moreover, t →αt(ω) is right-continuous.
If c(s, ω) > 0 for a.a. (s, ω) then t →βt(ω) is strictly increasing, t →αt(ω)
is continuous and αt is also a left-inverse of βt:
α(β(t, ω), ω) = t
for all t ≥0 .
(8.5.4)
In general ω →α(t, ω) is an {Fs}-stopping time for each t, since
{ω; α(t, ω) < s} = {ω; t < β(s, ω)} ∈Fs .
(8.5.5)
We now ask the question: Suppose Xt is an Itˆo diﬀusion and Yt an Itˆo process
as in Theorem 8.4.3. When does there exist a time change βt such that
Yαt ≃Xt ? (Note that αt is only deﬁned up to time β∞. If β∞< ∞we
interpret Yαt ≃Xt to mean that Yαt has the same law as Xt up to time β∞).
Here is a partial answer (see Øksendal (1990)):

148
8. Other Topics in Diﬀusion Theory
Theorem 8.5.1. Let Xt, Yt be as in Theorem 8.4.3 and let βt be a time
change with right inverse αt as in (8.5.1), (8.5.2) above. Assume that
u(t, ω) = c(t, ω)b(Yt)
and
vvT (t, ω) = c(t, ω) · σσT (Yt)
(8.5.6)
for a.a. t, ω. Then
Yαt ≃Xt .
This result allows us to recognize time changes of Brownian motion:
Theorem 8.5.2. Let dYt = v(t, ω)dBt, v ∈Rn×m, Bt ∈Rm be an Itˆo
integral in Rn, Y0 = 0 and assume that
vvT (t, ω) = c(t, ω)In
(8.5.7)
for some process c(t, ω) ≥0. Let αt, βt be as in (8.5.1), (8.5.2). Then
Yαt
is an n-dimensional Brownian motion .
Corollary 8.5.3. Let dYt =
nP
i=1
vi(t, ω)dBi(t, ω), Y0 = 0, where B =
(B1, . . . , Bn) is a Brownian motion in Rn. Then
bBt: = Yαt
is a 1-dimensional Brownian motion ,
where αt is deﬁned by (8.5.2) and
βs =
s
Z
0
½
n
X
i=1
v2
i (r, ω)
¾
dr .
(8.5.8)
Corollary 8.5.4. Let Yt, βs be as in Corollary 8.5.3. Assume that
n
X
i=1
v2
i (r, ω) > 0
for a.a. (r, ω) .
(8.5.9)
Then there exists a Brownian motion bBt such that
Yt = bBβt .
(8.5.10)
Proof. Let
bBt = Yαt
(8.5.11)
be the Brownian motion from Corollary 8.5.3. By (8.5.9) βt is strictly increas-
ing and hence (8.5.4) holds, So choosing t = βs in (8.5.11) we get (8.5.10).
⊔⊓

8.5 Random Time Change
149
Corollary 8.5.5. Let c(t, ω) ≥0 be given and deﬁne
dYt =
t
Z
0
p
c(s, ω) dBs ,
where Bs is an n-dimensional Brownian motion. Then
Yαt
is also an n-dimensional Brownian motion .
We now use this to prove that a time change of an Itˆo integral is again an
Itˆo integral, but driven by a diﬀerent Brownian motion eBt. First we construct
eBt:
Lemma 8.5.6. Suppose s →α(s, ω) is continuous, α(0, ω) = 0 for a.a. ω.
Fix t > 0 such that βt < ∞a.s. and assume that E[αt] < ∞. For k = 1, 2, . . .
put
tj =
½
j · 2−k
if
j · 2−k ≤αt
t
if
j · 2−k > αt
and choose rj such that αrj = tj. Suppose f(s, ω) ≥0 is Fs-adapted, bounded
and s-continuous for a.a. ω. Then
lim
k→∞
X
j
f(αj, ω)∆Bαj =
αt
Z
0
f(s, ω)dBs
a.s. ,
(8.5.12)
where αj = αrj, ∆Bαj = Bαj+1 −Bαj and the limit is in L2(Ω, P).
Proof. For all k we have
E
·³ X
j
f(αj, ω)∆Bαj −
αt
Z
0
f(s, ω)dBs
´2¸
= E
·³ X
j
αj+1
Z
αj
(f(αj, ω) −f(s, ω)dBs
´2¸
=
X
j
E
hµ αj+1
Z
αj
(f(αj, ω) −f(s, ω))dBs
¶2i
=
X
j
E
· αj+1
Z
αj
(f(αj, ω) −f(s, ω))2ds
¸
= E
· αt
Z
0
(f −fk)2ds
¸
,
where fk(s, ω) = P
j
f(tj, ω)X[tj ,tj+1)(s) is the elementary approximation to
f. (See Corollary 3.1.8). This implies (8.5.12).
⊔⊓

150
8. Other Topics in Diﬀusion Theory
We now use this to establish a general time change formula for Itˆo inte-
grals. An alternative proof in the case n = m = 1 can be found in McKean
(1969, §2.8).
Theorem 8.5.7 (Time change formula for Itˆo integrals).
Suppose c(s, ω) and α(s, ω) are s-continuous, α(0, ω) = 0 for a.a. ω and that
E[αt] < ∞. Let Bs be an m-dimensional Brownian motion and let v(s, ω) ∈
Vn×m
H
be bounded and s-continuous. Deﬁne
eBt = lim
k→∞
X
j
q
c(αj, ω) ∆Bαj =
αt
Z
0
p
c(s, ω) dBs .
(8.5.13)
Then eBt is an (m-dimensional) F(m)
αt -Brownian motion (i.e. eBt is a Brown-
ian motion and eBt is a martingale w.r.t. F(m)
αt ) and
αt
Z
0
v(s, ω)dBs =
t
Z
0
v(αr, ω)
p
α′r(ω) d eBr
a.s. P ,
(8.5.14)
where α′
r(ω) is the derivative of α(r, ω) w.r.t. r, so that
α′
r(ω) =
1
c(αr, ω)
for a.a. r ≥0, a.a. ω ∈Ω.
(8.5.15)
Proof. The existence of the limit in (8.5.13) and the second identity in (8.5.13)
follow by applying Lemma 8.5.6 to the function
f(s, ω) =
p
c(s, ω) .
Then by Corollary 8.5.5 we have that eBt is an F(m)
αt -Brownian motion. It
remains to prove (8.5.14):
αt
Z
0
v(s, ω)dBs = lim
k→∞
X
j
v(αj, ω)∆Bαj
= lim
k→∞
X
j
v(αj, ω)
s
1
c(αj, ω)
q
c(αj, ω) ∆Bαj
= lim
k→∞
X
j
v(αj, ω)
s
1
c(αj, ω) ∆eBj
=
t
Z
0
v(αr, ω)
s
1
c(αr, ω) d eBr
and the proof is complete.
⊔⊓

8.5 Random Time Change
151
Example 8.5.8 (Brownian motion on the unit sphere in Rn; n>2).
In Examples 5.1.4 and 7.5.5 we constructed Brownian motion on the unit
circle. It is not obvious how to extend the method used there to obtain Brow-
nian motion on the unit sphere S of Rn; n ≥3. However, we may proceed as
follows: Apply the function φ: Rn \ {0} →S deﬁned by
φ(x) = x · |x|−1 ;
x ∈Rn \ {0}
to n-dimensional Brownian motion B = (B1, . . . , Bn). The result is a stochas-
tic integral Y = (Y1, . . . , Yn) = φ(B) which by Itˆo’s formula is given by
dYi = |B|2 −B2
i
|B|3
dBi −
X
j̸=i
BjBi
|B|3 dBj −n −1
2
· Bi
|B|3 dt ;
i = 1, 2, . . . , n .
(8.5.16)
Hence
dY =
1
|B| · σ(Y )dB +
1
|B|2 b(Y )dt ,
where
σ = [σij] ∈Rn×n ,
with σij(Y ) = δij −YiYj; 1 ≤i, j ≤n
and
b(y) = −n −1
2
·



y1
...
yn


∈Rn ,
(y1, . . . , yn are the coordinates of y ∈Rn) .
Now perform the following time change: Deﬁne
Zt(ω) = Yα(t,ω)(ω)
where
αt = β−1
t
,
β(t, ω) =
t
Z
0
1
|B|2 ds .
Then Z is again an Itˆo process and by Theorem 8.5.7
dZ = σ(Z)d eB + b(Z)dt .
Hence Z is a diﬀusion with characteristic operator
Af(y) = 1
2
µ
∆f(y) −
X
i,j
yiyj
∂2f
∂yi∂yj
¶
−n −1
2
·
X
i
yi
∂f
∂yi
;
|y| = 1 .
(8.5.17)

152
8. Other Topics in Diﬀusion Theory
Thus, φ(B) =
B
|B| is – after a suitable change of time scale – equal to a
diﬀusion Z living on the unit sphere S of Rn. Note that Z is invariant under
orthogonal transformations in Rn (since B is). It is reasonable to call Z
Brownian motion on the unit sphere S. For other constructions see Itˆo and
McKean (1965, p. 269 (§7.15)) and Stroock (1971).
More generally, given a Riemannian manifold M with metric tensor g =
[gij] one may deﬁne a Brownian motion on M as a diﬀusion on M whose
characteristic operator A in local coordinates xi is given by
1
2 times the
Laplace-Beltrami operator (here [gij] = [gij]−1)
∆M =
1
p
det(g)
·
X
i
∂
∂xi
µp
det(g)
X
j
gij ∂
∂xj
¶
.
(8.5.18)
See for example Meyer (1966, p. 256–270), McKean (1969, §4.3). The subject
of stochastic diﬀerential equations on manifolds is also treated in Ikeda and
Watanabe (1989), Emery (1989) and Elworthy (1982).
Example 8.5.9 (Harmonic and analytic functions).
Let B = (B1, B2) be 2-dimensional Brownian motion. Let us investigate what
happens if we apply a C2 function
φ(x1, x2) = (u(x1, x2), v(x1, x2))
to B:
Put Y = (Y1, Y2) = φ(B1, B2) and apply Itˆo’s formula:
dY1 = u′
1(B1, B2)dB1 + u′
2(B1, B2)dB2 + 1
2[u′′
11(B1, B2) + u′′
22(B1, B2)]dt
and
dY2 = v′
1(B1, B2)dB1 + v′
2(B1, B2)dB2 + 1
2[v′′
11(B1, B2) + v′′
22(B1, B2)]dt ,
where u′
1 =
∂u
∂x1 etc. So
dY = b(B1, B2)dt + σ(B1, B2)dB ,
with b = 1
2
µ
∆u
∆v
¶
, σ =
µ
u′
1
u′
2
v′
1
v′
2
¶
= Dφ (the derivative of φ).
So Y = φ(B1, B2) is a martingale if (and, in fact, only if) φ is harmonic,
i.e. ∆φ = 0. If φ is harmonic, we get by Corollary 8.5.3 that
φ(B1, B2) = ( eB(1)
β1 , eB(2)
β2 )
where eB(1) and eB(2) are two (not necessarily independent) versions of 1-
dimensional Brownian motion, and
β1(t, ω) =
t
Z
0
|∇u|2(B1, B2)ds ,
β2(t, ω) =
t
Z
0
|∇v|2(B1, B2)ds .

8.6 The Girsanov Theorem
153
Since
σσT =
Ã
|∇u|2
∇u · ∇v
∇u · ∇v
|∇v|2
!
we see that if (in addition to ∆u = ∆v = 0)
|∇u|2 = |∇v|2
and
∇u · ∇v = 0
(8.5.19)
then
Yt = Y0 +
t
Z
0
σdB
with
σσT = |∇u|2(B1, B2)I2 ,
Y0 = φ(B1(0), B2(0)) .
Therefore, if we let
βt = β(t, ω) =
t
Z
0
|∇u|2(B1, B2)ds ,
αt = β−1
t
we obtain by Theorem 8.5.2 that Yαt is a 2-dimensional Brownian motion.
Conditions (8.5.19) – in addition to ∆u = ∆v = 0 – are easily seen to be
equivalent to requiring that the function φ(x + iy) = φ(x, y) regarded as a
complex function is either analytic or conjugate analytic.
Thus we have proved a theorem of P. L´evy that φ(B1, B2) is – after a
change of time scale – again Brownian motion in the plane if and only if
φ is either analytic or conjugate analytic. For extensions of this result see
Bernard, Campbell and Davie (1979), Csink and Øksendal (1983) and Csink,
Fitzsimmons and Øksendal (1990).
8.6 The Girsanov Theorem
We end this chapter by discussing a result, the Girsanov theorem, which
is fundamental in the general theory of stochastic analysis. It is also very
important in many applications, for example in economics (see Chapter 12).
Basically the Girsanov theorem says that if we change the drift coeﬃcient
of a given Itˆo process (with a nondegenerate diﬀusion coeﬃcient), then the
law of the process will not change dramatically. In fact, the law of the new
process will be absolutely continuous w.r.t. the law of the original process
and we can compute explicitly the Radon-Nikodym derivative.
We now make this precise. First we state (without proof) the useful L´evy
characterization of Brownian motion. A proof can be found in e.g. Ikeda &
Watanabe (1989), Theorem II.6.1, or in Karatzas & Shreve (1991), Theo-
rem 3.3.16.

154
8. Other Topics in Diﬀusion Theory
Theorem 8.6.1 (The L´evy characterization of Brownian motion).
Let X(t) = (X1(t), . . . , Xn(t)) be a continuous stochastic process on a proba-
bility space (Ω, H, Q) with values in Rn. Then the following, a) and b), are
equivalent
a) X(t) is a Brownian motion w.r.t. Q, i.e. the law of X(t) w.r.t. Q is the
same as the law of an n-dimensional Brownian motion.
b) (i) X(t) = (X1(t), . . . , Xn(t)) is a martingale w.r.t. Q (and w.r.t. its
own ﬁltration) and
(ii) Xi(t)Xj(t)−δijt is a martingale w.r.t. Q (and w.r.t. its own ﬁltration)
for all i, j ∈{1, 2, . . . , n}.
Remark. In this Theorem one may replace condition (ii) by the condition
(ii)’ The cross-variation processes ⟨Xi, Xj⟩t satisfy the identity
⟨Xi, Xj⟩t(ω) = δijt
a.s., 1 ≤i, j ≤n
(8.6.1)
where
⟨Xi, Xj⟩t = 1
4[⟨Xi + Xj, Xi + Xj⟩t −⟨Xi −Xj, Xi −Xj⟩t] ,
(8.6.2)
⟨Y, Y ⟩t being the quadratic variation process. (See Exercise 4.7.)
Next we need an auxiliary result about conditional expectation:
Lemma 8.6.2. Let µ and ν be two probability measures on a measurable
space (Ω, G) such that dν(ω) = f(ω)dµ(ω) for some f ∈L1(µ). Let X be a
random variable on (Ω, G) such that
Eν[|X|] =
Z
Ω
|X(ω)|f(ω)dµ(ω) < ∞.
Let H be a σ-algebra, H ⊂G. Then
Eν[X|H] · Eµ[f|H] = Eµ[fX|H] a.s.
(8.6.3)
Proof. By the deﬁnition of conditional expectation (Appendix B) we have
that if H ∈H then
Z
H
Eν[X|H]fdµ =
Z
H
Eν[X|H]dν =
Z
H
Xdν
=
Z
H
Xfdµ =
Z
H
Eµ[fX|H]dµ
(8.6.4)
On the other hand, by Theorem B.3 (Appendix B) we have

8.6 The Girsanov Theorem
155
Z
H
Eν[X|H]fdµ = Eµ[Eν[X|H]f · XH] = Eµ[Eµ[Eν[X|H]f · XH|H]]
= Eµ[XHEν[X|H] · Eµ[f|H]] =
Z
H
Eν[X|H] · Eµ[f|H]dµ .
(8.6.5)
Combining (8.6.4) and (8.6.5) we get
Z
N
Eν[X|H] · Eµ[f|H]dµ =
Z
H
Eµ[fX|H]dµ .
Since this holds for all H ∈H, (8.6.3) follows.
⊔⊓
We can now prove the ﬁrst version of the Girsanov formula:
Theorem 8.6.3 (The Girsanov theorem I).
Let Y (t) ∈Rn be an Itˆo process of the form
dY (t) = a(t, ω)dt + dB(t) ;
t ≤T, Y0 = 0 .
where T ≤∞is a given constant and B(t) is n-dimensional Brownian mo-
tion. Put
Mt = exp
µ
−
t
Z
0
a(s, ω)dBs −1
2
t
Z
0
a2(s, ω)ds
¶
;
t ≤T .
(8.6.6)
Assume that a(s, ω) satisﬁes Novikov’s condition
E
h
exp
µ
1
2
T
Z
0
a2(s, ω)ds
¶i
< ∞
(8.6.7)
where E = EP is the expectation w.r.t. P. Deﬁne the measure Q on (Ω, F(n)
T )
by
dQ(ω) = MT (ω)dP(ω) .
(8.6.8)
Then Y (t) is an n-dimensional Brownian motion w.r.t. the probability law
Q, for t ≤T.
Remarks.
(1) The transformation P →Q given by (8.6.9) is called the Girsanov trans-
formation of measures.
(2) As pointed out in Exercise 4.4 the Novikov condition (8.6.7) is suﬃcient to
guarantee that {Mt}t≤T is a martingale (w.r.t. F(n)
t
and P). Actually,
the result holds if we only assume that {Mt}t≤T is a martingale. See
Karatzas and Shreve (1991).

156
8. Other Topics in Diﬀusion Theory
(3) Note that since Mt is a martingale we actually have that
MT dP = MtdP
on F(n)
t
; t ≤T .
(8.6.9)
To see this, let f be a bounded F(n)
t
-measurable function. Then by The-
orem B.3 we have
Z
Ω
f(ω)MT (ω)dP(ω) = E[fMT ] = E[E[fMT |Ft]]
= E[fE[MT |Ft]] = E[fMt] =
Z
Ω
f(ω)Mt(ω)dP(ω) .
Proof of Theorem 8.6.3. For simplicity we assume that a(s, ω) is bounded.
In view of Theorem 8.6.1 we have to verify that
(i)
Y (t) = (Y1(t), . . . , Yn(t)) is a martingale w.r.t. Q
(8.6.10)
and
(ii)
Yi(t)Yj(t) −δijt is a martingale w.r.t. Q,
for all i, j ∈{1, 2, . . . , n} .
(8.6.11)
To verify (i) we put K(t) = MtY (t) and use Itˆo’s formula to get (see
Exercises 4.3, 4.4)
dKi(t) = MtdYi(t) + Yi(t)dMt + dYi(t)dMt
= Mt(ai(t)dt + dBi(t)) + Yi(t)Mt
³
n
X
k=1
−ak(t)dBk(t)
´
+(dBi(t))
³
−Mt
n
X
k=1
ak(t)dBk(t)
´
= Mt(dBi(t) −Yi(t)
n
X
k=1
ak(t)dBk(t)) = Mt γ(i)(t)dB(t)
(8.6.12)
where γ(i)(t) = (γ(i)
1 (t), . . . , γ(i)
n (t)), with
γ(i)
j (t) =
½
−Yi(t)aj(t)
for j ̸= i
1 −Yi(t)ai(t)
for j = i .
Hence Ki(t) is a martingale w.r.t. P, so by Lemma 8.6.2 we get, for t > s,
EQ[Yi(t)|Fs] = E[MtYi(t)|Fs]
E[Mt|Fs]
= E[Ki(t)|Fs]
Ms
= Ki(s)
Ms
= Yi(s) ,
which shows that Yi(t) is a martingale w.r.t. Q. This proves (i). The proof of
(ii) is similar and is left to the reader.
⊔⊓

8.6 The Girsanov Theorem
157
Remark. Theorem 8.6.3 states that for all Borel sets F1, . . . , Fk ⊂Rn and
all t1, t2, . . . , tk ≤T, k = 1, 2, . . . we have
Q[Y (t1) ∈F1, . . . , Y (tk) ∈Fk] = P[B(t1) ∈F1, . . . , B(tk) ∈Fk]
(8.6.13)
An equivalent way of expressing (8.6.8) is to say that Q ≪P (Q is absolutely
continuous w.r.t. P) with Radon-Nikodym derivative
dQ
dP = MT
on F(n)
T
.
(8.6.14)
Note that MT (ω) > 0 a.s., so we also have that P ≪Q. Hence the two
measures Q and P are equivalent. Therefore we get from (8.6.13)
P[Y (t1) ∈F1, . . . , Y (tk) ∈Fk] > 0
⇐⇒Q[Y (t1) ∈F1, . . . , Y (tk) ∈Fk] > 0
⇐⇒P[B(t1) ∈F1, . . . , B(tk) ∈Fk] > 0 ;
t1, . . . , tk ∈[0, T]
(8.6.15)
Theorem 8.6.4 (The Girsanov theorem II).
Let Y (t) ∈Rn be an Itˆo process of the form
dY (t) = β(t, ω)dt + θ(t, ω)dB(t) ;
t ≤T
(8.6.16)
where B(t) ∈Rm, β(t, ω) ∈Rn and θ(t, ω) ∈Rn×m. Suppose there exist
processes u(t, ω) ∈Wm
H and α(t, ω) ∈Wn
H such that
θ(t, ω)u(t, ω) = β(t, ω) −α(t, ω)
(8.6.17)
and assume that u(t, ω) satisﬁes Novikov’s condition
E
·
exp
µ
1
2
T
Z
0
u2(s, ω)ds
¶¸
< ∞.
(8.6.18)
Put
Mt = exp
µ
−
t
Z
0
u(s, ω)dBs −1
2
t
Z
0
u2(s, ω)ds
¶
;
t ≤T
(8.6.19)
and
dQ(ω) = MT (ω)dP(ω)
on F(m)
T
.
(8.6.20)
Then
bB(t): =
t
Z
0
u(s, ω)ds + B(t) ;
t ≤T
(8.6.21)
is a Brownian motion w.r.t. Q and in terms of bB(t) the process Y (t) has the
stochastic integral representation
dY (t) = α(t, ω)dt + θ(t, ω)d bB(t) .
(8.6.22)

158
8. Other Topics in Diﬀusion Theory
Proof. It follows from Theorem 8.6.3 that bB(t) is a Brownian motion w.r.t.
Q. So, substituting (8.6.21) in (8.6.16) we get, by (8.6.17),
dY (t) = β(t, ω)dt + θ(t, ω)(d bB(t) −u(t, ω)dt)
= [β(t, ω) −θ(t, ω)u(t, ω)]dt + θ(t, ω)d bB(t)
= α(t, ω)dt + θ(t, ω)d bB(t) .
⊔⊓
Note that if n = m and θ ∈Rn×n is invertible, then the process u(t, ω)
satisfying (8.6.17) is given uniquely by
u(t, ω) = θ−1(t, ω)[β(t, ω) −α(t, ω)] .
(8.6.23)
Finally we formulate a diﬀusion version:
Theorem 8.6.5 (The Girsanov theorem III).
Let X(t) = Xx(t) ∈Rn and Y (t) = Y x(t) ∈Rn be an Itˆo diﬀusion and an
Itˆo process, respectively, of the forms
dX(t) = b(X(t))dt + σ(X(t))dB(t) ;
t ≤T, X(0) = x
(8.6.24)
dY (t) = [γ(t, ω) + b(Y (t))]dt + σ(Y (t))dB(t) ;
t ≤T, Y (0) = x (8.6.25)
where the functions b: Rn →Rn and σ: Rn →Rn×m satisfy the conditions
of Theorem 5.2.1 and γ(t, ω) ∈Wn
H, x ∈Rn. Suppose there exists a process
u(t, ω) ∈Wm
H such that
σ(Y (t))u(t, ω) = γ(t, ω)
(8.6.26)
and assume that u(t, ω) satisﬁes Novikov’s condition
E
h
exp
µ
1
2
T
Z
0
u2(s, ω)ds
¶i
< ∞.
(8.6.27)
Deﬁne Mt, Q and bB(t) as in (8.6.19), (8.6.20) and (8.6.21). Then
dY (t) = b(Y (t))dt + σ(Y (t))d bB(t) .
(8.6.28)
Therefore,
the Q-law of Y x(t) is the same as
the P-law of Xx(t);
t ≤T .
(8.6.29)
Proof. The representation (8.6.28) follows by applying Theorem 8.6.4 to the
case θ(t, ω) = σ(Y (t)), β(t, ω) = γ(t, ω)+b(Y (t)), α(t, ω) = b(Y (t)). Then the
conclusion (8.6.29) follows from the weak uniqueness of solutions of stochastic
diﬀerential equations (Lemma 5.3.1).
⊔⊓

8.6 The Girsanov Theorem
159
The Girsanov theorem III can be used to produce weak solutions of
stochastic diﬀerential equations. To illustrate this, suppose Yt is a known
weak or strong solution to the equation
dYt = b(Yt)dt + σ(Yt)dB(t)
where b: Rn →Rn, σ: Rn →Rn×m and B(t) ∈Rm. We wish to ﬁnd a weak
solution X(t) of a related equation
dXt = a(Xt)dt + σ(Xt)dB(t)
(8.6.30)
where the drift function is changed to a: Rn →Rn. Suppose we can ﬁnd a
function u0: Rn →Rm such that
σ(y)u0(y) = b(y) −a(y) ;
y ∈Rn .
(If n = m and σ is invertible we choose
u0 = σ−1 · (b −a) .)
Then if u(t, ω) = u0(Yt(ω)) satisﬁes Novikov’s conditions, we have, with Q
and bBt = bB(t) as in (8.6.20) and (8.6.21), that
dYt = a(Yt)dt + σ(Yt)d bBt .
(8.6.31)
Thus we have found a Brownian motion ( bBt, Q) such that Yt satisﬁes (8.6.31).
Therefore (Yt, bBt) is a weak solution of (8.6.30).
Example 8.6.6. Let a: Rn →Rn be a bounded, measurable function. Then
we can construct a weak solution Xt = Xx
t of the stochastic diﬀerential
equation
dXt = a(Xt)dt + dBt ;
X0 = x ∈Rn .
(8.6.32)
We proceed according to the procedure above, with σ = I, b = 0 and
dYt = dBt ;
Y0 = x .
Choose
u0 = σ−1 · (b −a) = −a
and deﬁne
Mt = exp
½
−
t
Z
0
u0(Ys)dBs −1
2
t
Z
0
u2
0(Ys)ds
¾
i.e.
Mt = exp
½
t
Z
0
a(Bs)dBs −1
2
t
Z
0
a2(Bs)ds
¾
.

160
8. Other Topics in Diﬀusion Theory
Fix T < ∞and put
dQ = MT dP
on F(m)
T
.
Then
bBt: = −
t
Z
0
a(Bs)ds + Bt
is a Brownian motion w.r.t. Q for t ≤T and
dBt = dYt = a(Yt)dt + d bBt .
Hence if we set Y0 = x the pair (Yt, bBt) is a weak solution of (8.6.32) for
t ≤T. By weak uniqueness the Q-law of Yt = Bt coincides with the P-law of
Xx
t , so that
E[f1(Xx
t1) . . . fk(Xx
tk)] = EQ[f1(Yt1) . . . fk(Ytk)]
= E[MT f1(Bt1) . . . fk(Btk)]
(8.6.33)
for all f1, . . . , fk ∈C0(Rn); t1, . . . , tk ≤T.
Exercises
8.1.
Let ∆denote the Laplace operator on Rn.
a) Write down (in terms of Brownian motion) a bounded solution g
of the Cauchy problem
( ∂g(t, x)
∂t
−1
2∆xg(t, x) = 0
for t > 0, x ∈Rn
g(0, x) = φ(x)
where φ ∈C2
0 is given. (From general theory it is known that the
solution is unique.)
b) Let ψ ∈Cb(Rn) and α > 0. Find a bounded solution u of the
equation
(α −1
2∆)u = ψ
in Rn .
Prove that the solution is unique.
8.2.
Show that the solution u(t, x) of the initial value problem
∂u
∂t = 1
2β2x2 ∂2u
∂x2 + α x∂u
∂x ;
t > 0, x ∈R
u(0, x) = f(x)
(f ∈C2
0(R) given)
can be expressed as follows:

Exercises
161
u(t, x) = E[f(x · exp{βBt + (α −1
2β2)t}]
=
1
√
2πt
Z
R
f(x · exp{βy + (α −1
2β2)t} exp
µ
−y2
2t
¶
dy ;
t > 0 .
8.3.
(Kolmogorov’s forward equation)
Let Xt be an Itˆo diﬀusion in Rn with generator
Af(y) =
X
i,j
aij(y) ∂2f
∂yi∂yj
+
X
i
bi(y) ∂f
∂yi
;
f ∈C2
0
and assume that the transition measure of Xt has a density pt(x, y),
i.e. that
Ex[f(Xt)] =
Z
Rn
f(y)pt(x, y)dy ;
f ∈C2
0 .
(8.6.34)
Assume that y →pt(x, y) is smooth for each t, x. Prove that pt(x, y)
satisﬁes the Kolmogorov forward equation
d
dtpt(x, y) = A∗
ypt(x, y)
for all x, y ,
(8.6.35)
where A∗
y operates on the variable y and is given by
A∗
yφ(y) =
X
i,j
∂2
∂yi∂yj
(aijφ) −
X
i
∂
∂yi
(biφ) ;
φ ∈C2
(8.6.36)
(i.e. A∗
y is the adjoint of Ay.)
(Hint: By (8.6.34) and Dynkin’s formula we have
Z
Rn
f(y)pt(x, y)dy = f(x) +
t
Z
0
Z
Rn
Ayf(y)ps(x, y)dy ds ;
f ∈C2
0 .
Now diﬀerentiate w.r.t. t and use that
⟨Aφ, ψ⟩= ⟨φ, A∗ψ⟩
for φ ∈C2
0, ψ ∈C2 ,
where ⟨·, ·⟩denotes inner product in L2(dy).)
8.4.
Let Bt be n-dimensional Brownian motion (n ≥1) and let F be a
Borel set in Rn. Prove that the expected total length of time t that
Bt stays in F is zero if and only if the Lebesgue measure of F is zero.
Hint: Consider the resolvent Rα for α > 0 and then let α →0.
8.5.
Show that the solution u(t, x) of the initial value problem

162
8. Other Topics in Diﬀusion Theory
( ∂u
∂t = ρ u + 1
2∆u t > 0 ; x ∈Rn
u(0, x) = f(x)
(f ∈C2
0(Rn) given)
(where ρ ∈R is a constant) can be expressed by
u(t, x) = (2πt)−n/2 exp(ρt)
Z
Rn
f(y) exp
³
−(x −y)2
2t
´
dy .
8.6.
In connection with the deduction of the Black & Scholes formula for
the price of an option (see Chapter 12) the following partial diﬀerential
equation appears:
(
∂u
∂t = −ρ u + αx ∂u
∂x + 1
2β2x2 ∂2u
∂x2 ; t > 0 , x ∈R
u(0, x) = (x −K)+ ;
x ∈R ,
where ρ > 0, α, β and K > 0 are constants and
(x −K)+ = max(x −K, 0) .
Use the Feynman-Kac formula to prove that the solution u of this
equation is given by
u(t, x) = e−ρt
√
2πt
Z
R
(x · exp{(α −1
2β2)t + βy} −K)+e
−y2
2t dy ;
t > 0 .
(This expression can be simpliﬁed further. See Exercise 12.13.)
8.7.
Let Xt be a sum of Itˆo integrals of the form
Xt =
n
X
k=1
t
Z
0
vk(s, ω)dBk(s) ,
where (B1, . . . , Bn) is n-dimensional Brownian motion. Assume that
βt: =
t
Z
0
n
X
k=1
v2
k(s, ω)ds →∞
as t →∞, a.s.
Prove that
lim sup
t→∞
Xt
√2βt log log βt
= 1
a.s.
(Hint: Use the law of iterated logarithm.)
8.8.
Let Zt be a 1-dimensional Itˆo process of the form
dZt = u(t, ω)dt + dBt .

Exercises
163
Let Gt be the σ-algebra generated by {Zs(·); s ≤t} and deﬁne
dNt = (u(t, ω) −E[u|Gt])dt + dBt .
Use Corollary 8.4.5 to prove that Nt is a Brownian motion. (If we inter-
pret Zt as the observation process, then Nt is the innovation process.
See Lemma 6.2.6.)
8.9.
Deﬁne α(t) = 1
2 ln(1 + 2
3t3). If Bt is a Brownian motion, prove that
there exists another Brownian motion eBr such that
αt
Z
0
esdBs =
t
Z
0
rd eBr .
8.10. Let Bt be a Brownian motion in R. Show that
Xt: = B2
t
is a weak solution of the stochastic diﬀerential equation
dXt = dt + 2
p
|Xt|d eBt .
(8.6.37)
(Hint: Use Itˆo’s formula to express Xt as a stochastic integral and
compare with (8.6.37) by using Corollary 8.4.5.)
8.11. a) Let Y (t) = t + B(t);
t ≥0 . For each T > 0 ﬁnd a probability
measure QT on FT such that QT ∼P and {Y (t)}t≤T is Brownian
motion w.r.t. QT . Use (8.6.9) to prove that there exists a probability
measure Q on F∞such that
Q|FT = QT
for all T > 0 .
b) Show that
P
³
lim
t→∞Y (t) = ∞
´
= 1
while
Q
³
lim
t→∞Y (t) = ∞
´
= 0 .
Why does not this contradict the Girsanov theorem?
8.12. Let
dY (t) =
·
0
1
¸
dt +
·
1
3
−1
−2
¸ ·
dB1(t)
dB2(t)
¸
;
t ≤T .
Find a probability measure Q on F(2)
T
such that Q ∼P and such that
dY (t) =
·
1
3
−1
−2
¸ ·
d eB1(t)
d eB2(t)
¸

164
8. Other Topics in Diﬀusion Theory
where
eB(t): =
·
−3t
t
¸
+
·
B1(t)
B2(t)
¸
is a Brownian motion w.r.t. Q.
8.13. Let b: R →R be a Lipschitz-continuous function and deﬁne
Xt = Xx
t ∈R by
dXt = b(Xt)dt + dBt, X0 = x ∈R .
a) Use the Girsanov theorem to prove that for all M < ∞, x ∈R and
t > 0 we have
P[Xx
t ≥M] > 0 .
b) Choose b(x) = −r where r > 0 is constant. Prove that for all x
Xx
t →−∞
as t →∞a.s.
Compare this with the result in a).
8.14. (Polar sets for the graph of Brownian motion)
Let Bt be 1-dimensional Brownian motion starting at x ∈R.
a) Prove that for every ﬁxed time t0 > 0 we have
P x[Bt0 = 0] = 0 .
b) Prove that for every (non-trivial) closed interval J ⊂R+ we have
P x[∃t ∈J
such that Bt = 0] > 0 .
(Hint: If J = [t1, t2] consider P x[Bt1 < 0 & Bt2 > 0] and then use
the intermediate value theorem.)
c) In view of a) and b) it is natural to ask what closed sets F ⊂R+
have the property that
P x[∃t ∈F
such that Bt = 0] = 0 .
(8.6.38)
To investigate this question more closely we introduce the graph
Xt of Brownian motion, given by
dXt =
·
1
0
¸
dt +
·
0
1
¸
dBt ;
X0 =
·
t0
x0
¸
i.e.
Xt = Xt0,x0
t
=
·
t0 + t
Bx0
t
¸
where Bx0
0
= x0 a.s.
Then F satisﬁes (8.6.38) iﬀK: = F × {0} polar for Xt, in the sense
that

Exercises
165
P t0,x0[∃t > 0 ; Xt ∈K] = 0
for all t0, x0 .
(8.6.39)
The key to ﬁnding polar sets for a diﬀusion is to consider its Green
operator R, which is simply the resolvent Rα with α = 0 :
Rf(t0, x0) = Et0,x0
· ∞
Z
t0
f(Xs)ds
¸
for f ∈C0(R2) .
Show that
Rf(t0, x0) =
Z
R2
G(t0, x0; t, x)f(t, x)dt dx ,
where
G(t0, x0; t, x)= Xt>t0 · (2π(t −t0))−1
2 exp
µ
−|x −x0|2
2(t −t0)
¶
(8.6.40)
(G is the Green function of Xt.)
d) The capacity of K, C(K) = CG(K), is deﬁned by
C(K) = sup{µ(K); µ ∈MG(K)} ,
where MG(K)={µ; µ measure on K s.t.
R
K
G(t0, x0; t, x)dµ(t, x)≤1
for all t0, x0}.
A general result from stochastic potential theory states that
P t0,x0[Xt hits K] = 0 ⇔C(K) = 0 .
(8.6.41)
See e.g. Blumenthal and Getoor (1968, Prop. VI.4.3). Use this to
prove that
Λ 1
2 (F) = 0 ⇒P x0[∃t ∈F
such that Bt = 0] = 0 ,
where Λ 1
2 denotes 1/2-dimensional Hausdorﬀmeasure (Folland
(1984, §10.2)).
8.15. Let f ∈C2
0(Rn) and α(x) = (α1(x), . . . , αn(x)) with αi ∈C2
0(Rn) be
given functions and consider the partial diﬀerential equation



∂u
∂t =
nP
i=1
αi(x) ∂u
∂xi + 1
2
nP
i=1
∂2u
∂x2
i ; t > 0, x ∈Rn
u(0, x) = f(x) ;
x ∈Rn .
a) Use the Girsanov theorem to show that the unique bounded solution
u(t, x) of this equation can be expressed by
u(t, x) = Exh
exp
µ
t
Z
0
α(Bs)dBs −1
2
t
Z
0
α2(Bs)ds
¶
f(Bt)
i
,
where Ex is the expectation w.r.t. P x.

166
8. Other Topics in Diﬀusion Theory
b) Now assume that α is a gradient, i.e. that there exists γ ∈C1(Rn)
such that
∇γ = α .
Assume for simplicity that γ ∈C2
0(Rn). Use Itˆo’s formula to prove
that (see Exercise 4.8)
u(t, x) = exp
³
−γ(x))Exh
exp
½
−1
2
t
Z
0
(∇γ2(Bs)
+∆γ(Bs)
´
ds
¾
exp(γ(Bt))f(Bt)
i
.
c) Put v(t, x) = exp(γ(x))u(t, x). Use the Feynman-Kac formula to
show that v(t, x) satisﬁes the partial diﬀerential equation
( ∂v
∂t = −1
2(∇γ2 + ∆γ) · v + 1
2∆v ; t > 0 ; x ∈Rn
v(0, x) = exp(γ(x))f(x) ;
x ∈Rn .
(See also Exercise 8.16.)
8.16. (A connection between B.m. with drift and killed B.m.)
Let Bt denote Brownian motion in Rn and consider the diﬀusion Xt
in Rn deﬁned by
dXt = ∇h(Xt)dt + dBt ;
X0 = x ∈Rn .
(8.6.42)
where h ∈C1
0(Rn).
a) There is an important connection between this process and the
process Yt obtained by killing Bt at a certain rate V . More precisely,
ﬁrst prove that for f ∈C0(Rn) we have
Ex[f(Xt)] = Exh
exp
µ
−
t
Z
0
V (Bs)ds
¶
·exp(h(Bt)−h(x))·f(Bt)
i
,
(8.6.43)
where
V (x) = 1
2|∇h(x)|2 + 1
2∆h(x) .
(8.6.44)
(Hint: Use the Girsanov theorem to express the left hand side of
(8.6.43) in terms of Bt. Then use the Itˆo formula on Zt = h(Bt) to
achieve (8.6.44).)
b) Then use the Feynman-Kac formula to restate (8.6.43) as follows
(assuming V ≥0):
T X
t (f, x) = exp(−h(x)) · T Y
t (f · exp h, x) ,
where T X
t , T Y
t
denote the transition operators of the processes X
and Y , respectively, i.e.
T X
t (f, x) = Ex[f(Xt)]
and similarly for Y .

9. Applications to Boundary Value Problems
9.1 The Combined Dirichlet-Poisson Problem.
Uniqueness
We now use results from the preceding chapters to solve the following gener-
alization of the Dirichlet problem stated in the introduction:
Let D be a domain (open connected set) in Rn and let L denote a semi-
elliptic partial diﬀerential operator on C2(Rn) of the form
L =
n
X
i=1
bi(x) ∂
∂xi
+
n
X
i,j=1
aij(x)
∂2
∂xi∂xj
(9.1.1)
where bi(x) and aij(x) = aji(x) are continuous functions (see below). (By
saying that L is semi-elliptic (resp. elliptic) we mean that all the eigenvalues
of the symmetric matrix a(x) = [aij(x)]n
i,j=1 are non-negative (resp. positive)
for all x.)
The Combined Dirichlet-Poisson Problem
Let φ ∈C(∂D) and g ∈C(D) be given functions. Find w ∈C2(D) such that
(i)
Lw = −g
in D
(9.1.2)
and
(ii)
lim
x→y
x∈D
w(x) = φ(y)
for all y ∈∂D .
(9.1.3)
The idea of the solution is the following: First we ﬁnd an Itˆo diﬀusion {Xt}
whose generator A coincides with L on C2
0(Rn). To achieve this we simply
choose σ(x) ∈Rn×n such that
1
2σ(x)σT (x) = [aij(x)] .
(9.1.4)
We assume that σ(x) and b(x) = [bi(x)] satisfy conditions (5.2.1) and (5.2.2)
of Theorem 5.2.1. (For example, if each aij ∈C2(D) is bounded and has
bounded ﬁrst and second partial derivatives, then such a square root σ can
be found. See Fleming and Rishel (1975).) Next we let Xt be the solution of

168
9. Applications to Boundary Value Problems
dXt = b(Xt)dt + σ(Xt)dBt
(9.1.5)
where Bt is n-dimensional Brownian motion. As usual we let Ex denote
expectation with respect to the probability law Qx of Xt starting at x ∈Rn.
Then our candidate for the solution w of (9.1.2), (9.1.3) is
w(x) = Ex[φ(XτD ) · X{τD <∞}] + Ex
· τD
Z
0
g(Xt)dt
¸
(9.1.6)
provided that φ is bounded and
Ex
· τD
Z
0
|g(Xt)|dt
¸
< ∞
for all x .
(9.1.7)
The Dirichlet-Poisson problem consists of two parts:
(i) Existence of solution.
(ii) Uniqueness of solution.
The uniqueness problem turns out to be simpler and therefore we handle
this ﬁrst. In this section we prove two easy and useful uniqueness results.
Then in the next sections we discuss the existence of solution and other
uniqueness questions.
Theorem 9.1.1 (Uniqueness theorem (1)).
Suppose φ is bounded and g satisﬁes (9.1.7). Suppose w ∈C2(D) is bounded
and satisﬁes
(i)
Lw = −g
in D
(9.1.8)
and
(ii)’
limt↑τD w(Xt) = φ(XτD ) · X{τD <∞}
a.s. Qx for all x .
(9.1.9)
Then
w(x) = Ex[φ(XτD ) · X{τD <∞}] + Ex
· τD
Z
0
g(Xt)dt
¸
.
(9.1.10)
Proof. Let {Dk}∞
k=1 be an increasing sequence of open sets Dk such that
Dk ⊂⊂D and D =
∞
S
k=1
Dk. Deﬁne
αk = k ∧τDk ;
k = 1, 2, . . .
Then by the Dynkin formula and (9.1.8)

9.2 The Dirichlet Problem. Regular Points
169
w(x) = Ex[w(Xαk)] −Ex
· αk
Z
0
Lw(Xt)dt
¸
= Ex[w(Xαk)] + Ex
· αk
Z
0
g(Xt)dt
¸
.
(9.1.11)
By (9.1.9) w(Xαk) →φ(XτD ) · X{τD <∞} pointwise boundedly a.s. Qx. Hence
Ex[w(Xαk)] →Ex[φ(XτD ) · X{τD <∞}]
as k →∞.
(9.1.12)
Moreover,
Ex
· αk
Z
0
g(Xt)dt
¸
→Ex
· τD
Z
0
g(Xt)dt
¸
as k →∞,
(9.1.13)
since
αk
Z
0
g(Xt)dt →
τD
Z
0
g(Xt)dt
a.s.
and
¯¯¯¯
αk
Z
0
g(Xt)dt
¯¯¯¯ ≤
τD
Z
0
|g(Xt)|dt ,
which is Qx-integrable by (9.1.7).
Combining (9.1.12) and (9.1.13) with (9.1.11) we get (9.1.10).
⊔⊓
An immediate consequence is:
Corollary 9.1.2 (Uniqueness theorem (2)).
Suppose φ is bounded and g satisﬁes (9.1.7). Suppose
τD < ∞
a.s. Qx for all x .
(9.1.14)
Then if w ∈C2(D) is a bounded solution of the combined Dirichlet-Poisson
problem (9.1.2), (9.1.3) we have
w(x) = Ex[φ(XτD )] + Ex
· τD
Z
0
g(Xt)dt
¸
.
(9.1.15)
9.2 The Dirichlet Problem. Regular Points
We now consider the more complicated question of existence of solution. It
is convenient to split the combined Dirichlet-Poisson problem in two parts:
The Dirichlet problem and the Poisson problem:

170
9. Applications to Boundary Value Problems
The Dirichlet Problem
Let φ ∈C(∂D) be a given function. Find u ∈C2(D) such that
(I)
Lu = 0
in D
(9.2.1)
and
(II)
lim
x→y
x∈D
u(x) = φ(y)
for all y ∈∂D .
(9.2.2)
The Poisson Problem
Let g ∈C(D) be a given function. Find v ∈C2(D) such that
(a)
Lv = −g
in D
(9.2.3)
and
(b)
lim
x→y
x∈D
v(x) = 0
for all y ∈∂D .
(9.2.4)
Note that if u and v solve the Dirichlet and the Poisson problem, respectively,
then w: = u + v solves the combined Dirichlet-Poisson problem.
We ﬁrst consider the Dirichlet problem and proceed to study the Poisson
problem in the next section.
For simplicity we assume in this section that (9.1.14) holds.
In view of Corollary 9.1.2 the question of existence of a solution of the
Dirichlet problem (9.2.1), (9.2.2) can be restated as follows: When is
u(x): = Ex[φ(XτD )]
(9.2.5)
a solution?
Unfortunately, in general this function u need not be in C2(U). In fact,
it need not even be continuous. Moreover, it need not satisfy (9.2.2), either.
Consider the following example:
Example 9.2.1. Let X(t) = (X1(t), X2(t)) be the solution of the equations
dX1(t) = dt
dX2(t) = 0
so that X(t) = X(0) + t(1, 0) ∈R2; t ≥0. Let
D = ((0, 1) × (0, 1)) ∪((0, 2) × (0, 1
2))
and let φ be a continuous function on ∂D such that
φ = 1
on {1} × [ 1
2, 1]
and
φ = 0
on {2} × [0, 1
2]
φ = 0
on {0} × [0, 1] .

9.2 The Dirichlet Problem. Regular Points
171
Then
u(t, x) = Et,x[φ(XτD )] =



1
if x ∈( 1
2, 1)
0
if x ∈(0, 1
2) ,
so u is not even continuous. Moreover,
lim
t→0+ u(t, x) = 1 ̸= φ(0, x)
if
1
2 < x < 1
so (9.2.2) does not hold.
However, the function u(x) deﬁned by (9.2.5) will solve the Dirichlet prob-
lem in a weaker, stochastic sense: The boundary condition (9.2.2) is replaced
by the stochastic (pathwise) boundary condition (9.1.9) and the condition
(9.2.1) (Lu = 0) is replaced by a condition related to the condition
A u = 0
where A is the characteristic operator of Xt (Section 7.5).
We now explain this in more detail:
Deﬁnition 9.2.2. Let f be a locally bounded, measurable function on D.
Then f is called X-harmonic in D if
f(x) = Ex[f(XτU )]
for all x ∈D and all bounded open sets U with U ⊂D.
We make two important observations:
Lemma 9.2.3.
a) Let f be X-harmonic in D. Then Af = 0 in D.
b) Conversely, suppose f ∈C2(D) and Af = 0 in D. Then f is X-harmonic.
Proof.
a)
follows directly from the formula for A.
b)
follows from the Dynkin formula: Choose U as in Deﬁnition 9.2.2. Then

172
9. Applications to Boundary Value Problems
Ex[f(XτU )] = lim
k→∞Ex[f(XτU∧k)]
= f(x) + lim
k→∞Ex
· τU∧k
Z
0
(Lf)(Xs)ds
¸
= f(x) ,
since Lf = Af = 0 in U.
⊔⊓
The most important examples of X-harmonic functions are given in the
next result:
Lemma 9.2.4. Let φ be a bounded measurable function on ∂D and put
u(x) = Ex[φ(XτD )] ;
x ∈D .
Then u is X-harmonic. Thus, in particular, Au = 0.
Proof. From the mean value property (7.2.9) we have, if V ⊂D
u(x) =
Z
∂V
u(y)Qx[XτV ∈dy] = Ex[u(XτV )] .
⊔⊓
We are now ready to formulate the weak, stochastic version:
The Stochastic Dirichlet Problem
Given a bounded measurable function φ on ∂D, ﬁnd a function u on D such
that
(i)s
u is X-harmonic
(9.2.6)
(ii)s lim
t↑τD
u(Xt) = φ(XτD ) a.s. Qx, x ∈D .
(9.2.7)
We ﬁrst solve the stochastic Dirichlet problem (9.2.6), (9.2.7) and then
relate it to the original problem (9.2.1), (9.2.2).
Theorem 9.2.5 (Solution of the stochastic Dirichlet problem).
Let φ be a bounded measurable function on ∂D.
a) (Existence) Deﬁne
u(x) = Ex[φ(XτD )] .
(9.2.8)
Then u solves the stochastic Dirichlet problem (9.2.6), (9.2.7).
b) (Uniqueness) Suppose g is a bounded function on D such that
(1) g is X-harmonic
(2) lim
t↑τD
g(Xt) = φ(XτD ) a.s. Qx, x ∈D.
Then g(x) = Ex[φ(XτD )], x ∈D.

9.2 The Dirichlet Problem. Regular Points
173
Proof. a) It follows from Lemma 9.2.4 that (i)s holds. Fix x ∈D. Let {Dk}
be an increasing sequence of open sets such that Dk ⊂⊂D and D = S
k
Dk.
Put τk = τDk, τ = τD. Then by the strong Markov property
u(Xτk) = EXτk [φ(Xτ)] = Ex[θτk(φ(Xτ))|Fτk]
= Ex[φ(Xτ)|Fτk] .
(9.2.9)
Now Mk = Ex[φ(Xτ)|Fτk] is a bounded (discrete time) martingale so by the
martingale convergence theorem Corollary C.9 (Appendix C) we get that
lim
k→∞u(Xτk) = lim
k→∞Ex[φ(Xτ)|Fτk] = φ(Xτ)
(9.2.10)
both pointwise for a.a. ω and in Lp(Qx), for all p < ∞. Moreover, by (9.2.9)
it follows that for each k the process
Nt = u(Xτk∨(t∧τk+1)) −u(Xτk) ;
t ≥0
is a martingale w.r.t. Gt = Fτk∨(t∧τk+1).
So by the martingale inequality
Qxh
sup
τk≤r≤τk+1
|u(Xr) −u(Xτk)| > ϵ
i
≤1
ϵ2 Ex[|u(Xτk+1) −u(Xτk)|2]
→0
as k →∞, for all ϵ > 0 .
(9.2.11)
From (9.2.10) and (9.2.11) we conclude that (ii)s holds.
b)
Let Dk, τk be as in a). Then since g is X-harmonic we have
g(x) = Ex[g(Xτk)]
for all k. So by (2) and bounded convergence
g(x) = lim
k→∞Ex[g(Xτk)] = Ex[φ(XτD )] ,
as asserted .
⊔⊓
Finally we return to the original Dirichlet problem (9.2.1), (9.2.2). We
have already seen that a solution need not exist. However, it turns out that
for a large class of processes Xt we do get a solution (for all D) if we reduce
the requirement in (9.2.2) to hold only for a subset of the boundary points
y ∈∂D called the regular boundary points. Before we deﬁne regular points
and state the result precisely, we need the following auxiliary lemmas:
(As before we let Mt and M∞denote the σ-algebras generated by Xs;
s ≤t and by Xs; s ≥0 respectively).
Lemma 9.2.6 (The 0–1 law). Let H ∈T
t>0
Mt. Then either Qx(H) = 0
or Qx(H) = 1.

174
9. Applications to Boundary Value Problems
Proof. From the strong Markov property (7.2.5) we have
Ex[θtη|Mt] = EXt[η]
for all bounded, M∞-measurable η: Ω→R. This implies that
Z
H
θtη · dQx =
Z
H
EXt[η]dQx ,
for all t .
First assume that η = ηk = g1(Xt1) · · · gk(Xtk), where each gi is bounded
and continuous. Then letting t →0 we obtain
Z
H
ηdQx = lim
t→0
Z
H
θtηdQx = lim
t→0
Z
H
EXt[η]dQx = Qx(H)Ex[η]
by Feller continuity (Lemma 8.1.4) and bounded convergence. Approximating
the general η by functions ηk as above we conclude that
Z
H
ηdQx = Qx(H)Ex[η]
for all bounded M∞-measurable η. If we put η = XH we obtain Qx(H) =
(Qx(H))2, which completes the proof.
⊔⊓
Corollary 9.2.7. Let y ∈Rn. Then
either
Qy[τD = 0] = 0
or
Qy[τD = 0] = 1 .
Proof. H = {ω; τD = 0} ∈T
t>0
Mt .
⊔⊓
In other words, either a.a. paths Xt starting from y stay within D for a
positive period of time or a.a. paths Xt starting from y leave D immediately.
In the last case we call the point y regular, i.e.
Deﬁnition 9.2.8. A point y ∈∂D is called regular for D (w.r.t. Xt) if
Qy[τD = 0] = 1 .
Otherwise the point y is called irregular.
Example 9.2.9. Corollary 9.2.7 may seem hard to believe at ﬁrst glance. For
example, if Xt is a 2-dimensional Brownian motion Bt and D is the square
[0, 1] × [0, 1] one might think that, starting from ( 1
2, 0), say, half of the paths
will stay in the upper half plane and half in the lower, for a positive period of
time. However, Corollary 9.2.7 says that this is not the case: Either they all
stay in D initially or they all leave D immediately. Symmetry considerations

9.2 The Dirichlet Problem. Regular Points
175
imply that the ﬁrst alternative is impossible. Thus ( 1
2, 0), and similarly all
the other points of ∂D, are regular for D w.r.t. Bt.
Example 9.2.10. Let D = [0, 1]×[0, 1] and let L be the parabolic diﬀerential
operator
Lf(t, x) = ∂f
∂t + 1
2 · ∂2f
∂x2 ;
(t, x) ∈R2 .
(See Example 7.3.5)
Here
b =
µ
1
0
¶
and
a = [aij] = 1
2
µ
0
0
0
1
¶
.
So, for example, if we choose σ =
µ
0
0
1
0
¶
, we have 1
2σσT = a. This gives the
following stochastic diﬀerential equation for the Itˆo diﬀusion Xt associated
with L:
dXt =
µ
1
0
¶
dt +
µ
0
0
1
0
¶ µ
dB(1)
t
dB(2)
t
¶
.
In other words,
Xt =
µ
t + t0
Bt
¶
,
X0 =
µ
t0
x
¶
where Bt is 1-dimensional Brownian motion. So we end up with the graph
of Brownian motion, which we started with in Example 7.3.5. In the case it
is not hard to see that the irregular points of ∂D consist of the open line
{0} × (0, 1), the rest of the boundary points being regular.

176
9. Applications to Boundary Value Problems
Example 9.2.11. Let ∆= {(x, y); x2 + y2 < 1} ⊂R2 and let {∆n} be
a sequence of disjoint open discs in ∆centered at (2−n, 0), respectively,
n = 1, 2, . . . . Put
D = ∆\
³ ∞
[
n=1
∆n
´
.
Then it is easy to see that all the points of ∂∆∪
∞
S
n=1
∂∆n are regular for
D w.r.t. 2-dimensional Brownian motion Bt, using a similar argument as in
Example 9.2.9. But what about the point 0? The answer depends on the sizes
of the discs ∆n. More precisely, if rn is the radius of ∆n then 0 is a regular
point for D if and only if
∞
X
n=1
n
log 1
rn
= ∞.
(9.2.12)
This is a consequence of the famous Wiener criterion. See Port and Stone
(1979), p. 225.
Having deﬁned regular points we now formulate the announced general-
ized version of the Dirichlet problem:
The Generalized Dirichlet Problem
Given a domain D ⊂Rn and L and φ as before, ﬁnd a function u ∈C2(D)
such that
(i)
Lu = 0
in D
(9.2.13)
and
(ii)
lim
x→y
x∈D
u(x) = φ(y)
for all regular y ∈∂D .
(9.2.14)

9.2 The Dirichlet Problem. Regular Points
177
First we establish that if a solution of this problem exists, it must be the
solution of the stochastic Dirichlet problem found in Theorem 9.2.5, provided
that Xt satisﬁes Hunt’s condition (H):
(H): Every semipolar set for Xt is polar for Xt .
(9.2.15)
A semipolar set is a countable union of thin sets and a measurable set G ⊂Rn
is called thin (for Xt) if Qx[TG = 0] = 0 for all x, where TG = inf{t > 0; Xt ∈
G} is the ﬁrst hitting time of G. (Intuitively: For all starting points the
process does not hit G immediately, a.s). A measurable set F ⊂Rn is called
polar (for Xt) if Qx[TF < ∞] = 0 for all x. (Intuitively: For all starting
points the process never hits F, a.s.). Clearly every polar set is semipolar,
but the converse need not to be true (consider the process in Example 9.2.1).
However, condition (H) does hold for Brownian motion (See Blumenthal and
Getoor (1968)). It follows from the Girsanov theorem that condition (H) holds
for all Itˆo diﬀusions whose diﬀusion coeﬃcient matrix has a bounded inverse
and whose drift coeﬃcient satisﬁes the Novikov condition for all T < ∞.
We also need the following result, the proof of which can be found in
Blumenthal and Getoor (1968, Prop. II.3.3):
Lemma 9.2.12. Let U ⊂D be open and let I denote the set of irregular
points of U. Then I is a semipolar set.
Theorem 9.2.13. Suppose Xt satisﬁes Hunt’s condition (H). Let φ be a
bounded continuous function on ∂D. Suppose there exists a bounded u ∈
C2(D) such that
(i)
Lu = 0 in D
(ii)s
lim
x→y
x∈D
u(x) = φ(y) for all regular y ∈∂D
Then u(x) = Ex[φ(XτD )].
Proof. Let {Dk} be as in the proof Theorem 9.1.1. By Lemma 9.2.3 b) u is
X-harmonic and therefore
u(x) = Ex[u(Xτk)]
for all x ∈Dk and all k .
If k →∞then Xτk →XτD and so u(Xτk) →φ(XτD ) if XτD is regular.
From the Lemma 9.2.12 we know that the set I of irregular points of ∂D is
semipolar. So by condition (H) the set I is polar and therefore XτD /∈I a.s.
Qx. Hence
u(x) = lim Ex[u(Xτk)] = Ex[φ(XτD )] ,
as claimed .
⊔⊓
Under what conditions is the solution u of the stochastic Dirichlet problem
(9.2.6), (9.2.7) also a solution of the generalized Dirichlet problem (9.2.13),
(9.2.14)? This is a diﬃcult question and we will content ourselves with the
following partial answer:

178
9. Applications to Boundary Value Problems
Theorem 9.2.14. Suppose L is uniformly elliptic in D, i.e. the eigenvalues
of [aij] are bounded away from 0 in D. Let φ be a bounded continuous function
on ∂D. Put
u(x) = Ex[φ(XτD )] .
Then u ∈C2+α(D) for all α < 1 and u solves the Dirichlet problem (9.2.13),
(9.2.14), i.e.
(i)
Lu = 0 in D.
(ii)r
lim
x→y
x∈D
u(x) = φ(y) for all regular y ∈∂D .
Remark. If k is an integer, α > 0 and G is an open set Ck+α(G) denotes the
set of functions on G whose partial derivatives up to k’th order is Lipschitz
(H¨older) continuous with exponent α.
Proof. Choose an open ball ∆with ∆⊂D and let f ∈C(∂∆). Then, from
the general theory of partial diﬀerential equations, for all α < 1 there exists
a continuous function u on ∆such that u|∆∈C2+α(∆) and
Lu = 0
in ∆
(9.2.16)
u = f
on ∂∆
(9.2.17)
(see e.g. Dynkin (1965 II, p. 226)). Since u|∆∈C2+α(∆) we have: If K is
any compact subset of ∆there exists a constant C only depending on K and
the Cα-norms of the coeﬃcients of L such that
∥u∥C2+α(K) ≤C(∥Lu∥Cα(∆) + ∥u∥C(∆)) .
(9.2.18)
(See Bers, John and Schechter (1964, Theorem 3, p. 232).) Combining
(9.2.16), (9.2.17) and (9.2.18) we obtain
∥u∥C2+α(K) ≤C∥f∥C(∂∆) .
(9.2.19)
By uniqueness (Theorem 9.2.13) we know that
u(x) =
Z
f(y)dµx(y) ,
(9.2.20)
where dµx = Qx[Xτ∆∈dy] is the ﬁrst exit distribution of Xt from ∆. From
(9.2.19) it follows that
¯¯¯
Z
fdµx1 −
Z
fdµx2
¯¯¯ ≤C∥f∥C(∂∆)|x1 −x2|α ;
x1, x2 ∈K .
(9.2.21)
By approximating a given continuous function on ∂∆uniformly by functions
in C∞(∂∆) we see that (9.2.21) holds for all functions f ∈C(∂∆). Therefore
∥µx1 −µx2∥≤C|x1 −x2|α ;
x1, x2 ∈K
(9.2.22)

9.2 The Dirichlet Problem. Regular Points
179
where ∥∥denotes the operator norm on measures on ∂∆. So if g is any
bounded measurable function on ∂∆we know that the function
bg(x) =
Z
g(y)dµx(y) = Ex[g(Xτ∆)]
belongs to the class Cα(K). Since u(x) = Ex[u(XτU )] for all open sets U
with U ⊂D and x ∈U (Lemma 9.2.4) this applies to g = u and we conclude
that u ∈Cα(M) for any compact subset M of D.
We may therefore apply the solution to the problem (9.2.16), (9.2.17) once
more, this time with f = u and this way we obtain that
u(x) = Ex[u(XτD )]
belongs to C2+α(M)
for any compact M ⊂D. Therefore (i) holds by Lemma 9.2.3 a).
To obtain (ii)r we apply a theorem from the theory of parabolic diﬀerential
equations: The Kolmogorov backward equation
Lv = ∂v
∂t
has a fundamental solution v = p(t, x, y) jointly continuous in t, x, y for t > 0
and bounded in x, y for each ﬁxed t > 0 (See Dynkin (1965 II), Theorem 0.4
p. 227). It follows (by bounded convergence) that the process Xt is a strong
Feller process, in the sense that the function
x →Ex[f(Xt)] =
Z
Rn
f(y)p(t, x, y)dy
is continuous, for all t > 0 and all bounded, measurable functions f. In general
we have:
If Xt is a strong Feller Itˆo diﬀusion and D ⊂Rn is open then
lim
x→y
x∈D
Ex[φ(XτD )] = φ(y)
for all regular y ∈∂D and bounded φ ∈C(∂D) .
(9.2.23)
(See Theorem 13.3 p. 32–33 in Dynkin (1965 II)).
Therefore u satisﬁes property (ii)r and the proof is complete.
⊔⊓
Example 9.2.15. We have already seen (Example 9.2.1) that condition
(9.1.3) does not hold in general. This example shows that it need not hold
even when L is elliptic: Consider Example 9.2.11 again, in the case when the
point 0 is not regular. Choose φ ∈C(∂D) such that
φ(0) = 1, 0 ≤φ(y) < 1
for y ∈∂D \ {0} .
Since {0} is polar for Bt (see Exercise 9.7 a) we have B0
τD ̸= 0 a.s and therefore

180
9. Applications to Boundary Value Problems
u(0) = E0[φ(BτD )] < 1 .
By a slight extension of the mean value property (7.2.9) (see Exercise 9.4)
we get
E0[u(Xσk)] = E0[φ(XτD )] = u(0) < 1
(9.2.24)
where
σk = inf
n
t > 0; Bt /∈D ∩
½
|x| < 1
k
¾o
,
k = 1, 2, . . .
This implies that it is impossible that u(x) →1 as x →0. Therefore (9.1.3)
does not hold in this case.
In general one can show that the regular points for Brownian motion
are exactly the regular points in the classical potential theoretic sense, i.e.
the points y on ∂D where the limit of the generalized Perron-Wiener-Brelot
solution coincide with φ(y), for all φ ∈C(∂D). See Doob (1984), Port and
Stone (1979) or Rao (1977).
Example 9.2.16. Let D denote the inﬁnite strip
D = {(t, x) ∈R2; x < R} ,
where R ∈R
and let L be the diﬀerential operator
Lf(t, x) = ∂f
∂t + 1
2
∂2f
∂x2 ;
f ∈C2(D) .
An Itˆo diﬀusion whose generator coincides with L on C2
0(R2) is (see Exam-
ple 9.2.10)
Xt = (s + t, Bt) ;
t ≥0 ,
and all the points of ∂D are regular for this process. It is not hard to see that
in this case (9.1.14) holds, i.e.
τD < ∞a.s.

9.3 The Poisson Problem
181
(see Exercise 7.4).
Assume that φ is a bounded continuous function on ∂D = {(t, R); t ∈R}.
Then by Theorem 9.2.5 the function
u(s, x) = Es,x[φ(XτD )]
is the solution of the stochastic Dirichlet problem (9.2.6), (9.2.7), where Es,x
denotes expectation w.r.t. the probability law Qs,x for X starting at (s, x).
Does u also solve the problem (9.2.13), (9.2.14)? Using the Laplace transform
it is possible to ﬁnd the distribution of the ﬁrst exit point on ∂D for X, i.e.
to ﬁnd the distribution of the ﬁrst time t = bτ that Bt reaches the value R.
(See Karlin and Taylor (1975), p. 363. See also Exercise 7.19.) The result is
P x[bτ ∈dt] = g(x, t)dt ,
where
g(x, t) =
½
(R −x)(2πt3)−1 exp(−(R−x)2
2t
) ;
t > 0
0 ;
t ≤0 .
(9.2.25)
Thus the solution u may be written
u(s, x) =
∞
Z
0
φ(s + t, R)g(x, t)dt =
∞
Z
s
φ(r, R)g(x, r −s)dr .
From the explicit formula for u it is clear that ∂u
∂s and ∂2u
∂x2 are continuous
and we conclude that Lu = 0 in D by Lemma 9.2.3. So u satisﬁes (9.2.13).
What about property (9.2.14)? It is not hard to see that for t > 0
Et0,x[f(Xt)] = (2πt)−1
2
Z
R
f(t0 + t, y) exp
µ
−|x −y|2
2t
¶
dy
for all bounded, (t, x)-measurable functions f. (See (2.2.2)). Therefore Xt is
not a strong Feller process, so we cannot appeal to (9.2.23) to obtain (9.2.14).
However, it is easy to verify directly that if |y| = R, t1 > 0 then for all ϵ > 0
there exists δ > 0 such that |x−y| < δ, |t−t1| < δ ⇒Qt,x[XτD ∈N] ≥1−ϵ,
where N = [t1 −ϵ, t1 + ϵ] × {y}. And this is easily seen to imply (9.2.14).
Remark. As the above example (and Example 9.2.1) shows, an Itˆo diﬀusion
need not be a strong Feller process. However, we have seen that it is always
a Feller process (Lemma 8.1.4).
9.3 The Poisson Problem
Let L = P aij
∂2
∂xi∂xj +P bi ∂
∂xi be a semi-elliptic partial diﬀerential operator
on a domain D ⊂Rn as before and let Xt be an associated Itˆo diﬀusion,
described by (9.1.4) and (9.1.5). In this section we study the Poisson problem
(9.2.3), (9.2.4). For the same reasons as in Section 9.2 we generalize the
problem to the following:

182
9. Applications to Boundary Value Problems
The Generalized Poisson Problem
Given a continuous function g on D ﬁnd a C2 function v in D such that
a)
Lv = −g
in D
(9.3.1)
b)
lim
x→y
x∈D
v(x) = 0
for all regular y ∈∂D
(9.3.2)
Again we will ﬁrst study a stochastic version of the problem and then in-
vestigate the relation between the corresponding stochastic solution and the
solution (if it exists) of (9.3.1), (9.3.2):
Theorem 9.3.1 (Solution of the stochastic Poisson problem).
Assume that
Ex
· τD
Z
0
|g(Xs)|ds
¸
< ∞
for all x ∈D .
(9.3.3)
(This occurs, for example, if g is bounded and Ex[τD] < ∞for all x ∈D).
Deﬁne
v(x) = Ex
· τD
Z
0
g(Xs)ds
¸
.
(9.3.4)
Then
Av = −g
in D ,
(9.3.5)
and
lim
t↑τD
v(Xt) = 0
a.s. Qx, for all x ∈D .
(9.3.6)
Proof. Choose U open, x ∈U ⊂⊂D. Put η =
τDR
0
g(Xs)ds, τ = τU.
Then by the strong Markov property (7.2.5)
Ex[v(Xτ)] −v(x)
Ex[τ]
=
1
Ex[τ](Ex[EXτ [η]] −Ex[η])
=
1
Ex[τ](Ex[Ex[θτη|Fτ]] −Ex[η]) =
1
Ex[τ](Ex[θτη −η]) .
Approximate η by sums of the form
η(k) =
X
g(Xti)X{ti<τD }∆ti .
Since
θtη(k) =
X
g(Xti+t)X{ti+t<τt
D }∆ti
for all k
(see the argument for (7.2.6)) we see that

9.3 The Poisson Problem
183
θτη =
τD
Z
τ
g(Xs)ds .
(9.3.7)
Therefore
Ex[v(Xτ)] −v(x)
Ex[τ]
=
−1
Ex[τ]Ex
·
τ
Z
0
g(Xs)ds
¸
→−g(x)
as U ↓x ,
since g is continuous. This proves (9.3.5).
Put H(x) = Ex[
τDR
0
|g(Xs)|ds]. Let Dk, τk be as in the proof of Theo-
rem 9.2.5. Then by the same argument as above we get
Ex[H(Xτk∧t)] = Ex[Ex[
τD
Z
τk∧t
|g(Xs)|ds|Fτk∧t]]
= Ex
·
τD
Z
τk∧t
|g(Xs)|ds
¸
→0
as t →τD, k →∞
by dominated convergence. This implies (9.3.6).
⊔⊓
Remark. For functions g satisfying (9.3.3) deﬁne the operator R by
(Rg)(x) = ˇg(x) = Ex
· τD
Z
0
g(Xs)ds
¸
.
Then (9.3.5) can be written
A(Rg) = −g
(9.3.8)
i.e. the operator −R is a right inverse of the operator A. Similarly, if we
deﬁne
Rαg(x) = Ex
· τD
Z
0
g(Xs)e−αsds
¸
for α ≥0
(9.3.9)
then the same method of proof as in Theorem 8.1.5 gives that
(A −α)Rαg = −g ;
α ≥0 .
(9.3.10)
(If α > 0 then the assumption (9.3.3) can be replaced by the assumption that
g is bounded (and continuous as before)).
Thus we may regard the operator Rα as a generalization of the resolvent
operator Rα discussed in Chapter 8, and formula (9.3.10) as the analogue of
Theorem 8.1.5 b).

184
9. Applications to Boundary Value Problems
Next we establish that if a solution v of the generalized problem (9.3.1),
(9.3.2) exists, then v is the solution (9.3.4) of the stochastic problem (9.3.5),
(9.3.6):
Theorem 9.3.2 (Uniqueness theorem for the Poisson equation).
Assume that Xt satisﬁes Hunt’s condition (H) ((9.2.15)). Assume that (9.3.3)
holds and that there exists a function v ∈C2(D) and a constant C such that
|v(x)| ≤C
³
1 + Ex
· τD
Z
0
|g(Xs)|ds
¸´
for all x ∈D
(9.3.11)
and with the properties
Lv = −g
in D ,
(9.3.12)
lim
x→y
x∈D
v(x) = 0
for all regular points y ∈∂D .
(9.3.13)
Then v(x) = Ex[
τDR
0
g(Xs)ds].
Proof. Let Dk, τk be as in the proof of Theorem 9.2.5. Then by Dynkin’s
formula
Ex[v(Xτk)] −v(x) = Ex
· τk
Z
0
(Lv)(Xs)ds
¸
= −Ex
· τk
Z
0
g(Xs)ds
¸
.
By dominated convergence we obtain
v(x) = lim
k→∞
³
Ex[v(Xτk)] + Ex
· τk
Z
0
g(Xs)ds
¸´
= Ex
· τD
Z
0
g(Xs)ds
¸
,
since XτD is a regular point a.s. by condition (H) and Lemma 9.2.12.
⊔⊓
Finally we combine the Dirichlet and Poisson problem and obtain the
following result:
Theorem 9.3.3. (Solution of the combined stochastic Dirichlet and
Poisson problem).
Assume that (9.1.14) holds. Let φ ∈C(∂D) be bounded and let g ∈C(D)
satisfy
Ex
· τD
Z
0
|g(Xs)|ds
¸
< ∞
for all x ∈D .
(9.3.14)
Deﬁne

9.3 The Poisson Problem
185
w(x) = Ex[φ(XτD )] + Ex
· τD
Z
0
g(Xs)ds
¸
,
x ∈D .
(9.3.15)
a) Then
Aw = −g
in D
(9.3.16)
and
lim
t↑τD
w(Xt) = φ(XτD )
a.s. Qx, for all x ∈D .
(9.3.17)
b) Moreover, if there exists a function w1 ∈C2(D) and a constant C such
that
|w1(x)| < C
³
1 + Ex
· τD
Z
0
|g(Xs)|ds
¸´
,
x ∈D ,
(9.3.18)
and w1 satisﬁes (9.3.16) and (9.3.17), then w1 = w.
Remark. With an approach similar to the one used in Theorem 9.2.14 one
can prove that if L is uniformly elliptic in D and g ∈Cα(D) (for some α > 0)
is bounded, then the function w given by (9.3.15) solves the Dirichlet-Poisson
problem, i.e.
Lw = −g
in D
(9.3.19)
and
lim
x→y
x∈D
w(x) = φ(y)
for all regular y ∈∂D .
(9.3.20)
The Green Measure
The solution v given by the formula (9.3.4) may be rewritten as follows:
Deﬁnition 9.3.4. The Green measure (of Xt w.r.t. D at x), G(x, ·) is de-
ﬁned by
G(x, H) = Ex
· τD
Z
0
XH(Xs)ds
¸
,
H ⊂Rn
Borel set
(9.3.21)
or
Z
f(y)G(x, dy) = Ex
· τD
Z
0
f(Xs)ds
¸
,
f bounded, continuous . (9.3.22)

186
9. Applications to Boundary Value Problems
In other words, G(x, H) is the expected length of time the process stays
in H before it exits from D. If Xt is Brownian motion, then
G(x, H) =
Z
H
G(x, y)dy ,
where G(x, y) is the classical Green function w.r.t. D and dy denotes Lebesque
measure. See Doob (1984), Port and Stone (1979) or Rao (1977). See also
Example 9.3.6 below.
Note that using the Fubini theorem we obtain the following relation
between the Green measure G and the transition measure for Xt in D,
QD
t (x, H) = Qx[Xt ∈H, t < τD]:
G(x, H) = Ex
· ∞
Z
0
XH(Xs) · X[0,τD )(s)ds
¸
=
∞
Z
0
QD
t (x, H)dt .
(9.3.23)
From (9.3.22) we get
v(x) = Ex
· τD
Z
0
g(Xs)ds
¸
=
Z
D
g(y)G(x, dy) ,
(9.3.24)
which is the familiar formula for the solution of the Poisson equation in the
classical case.
Also note that by using the Green function, we may regard the Dynkin
formula as a generalization of the classical Green formula:
Corollary 9.3.5 (The Green formula). Let Ex[τD] < ∞for all x ∈D
and assume that f ∈C2
0(Rn). Then
f(x) = Ex[f(XτD )] −
Z
D
(LXf)(y)G(x, dy) .
(9.3.25)
In particular, if f ∈C2
0(D) we have
f(x) = −
Z
D
(LXf)(y)G(x, dy) .
(9.3.26)
(As before LX = P bi ∂
∂xi + 1
2
P(σσT )ij
∂2
∂xi∂xj when
dXt = b(Xt)dt + σ(Xt)dBt . )
Proof. By Dynkin’s formula and (9.3.24) we have
Ex[f(XτD )] = f(x) + Ex
· τD
Z
0
(LXf)(Xs)ds
¸
= f(x) +
Z
D
(LXf)(y)G(x, dy) .

9.3 The Poisson Problem
187
Remark. Combining (9.3.8) with (9.3.26) we see that if Ex[τK] < ∞for all
compacts K ⊂D and all x ∈D, then −R is the inverse of the operator A
on C2
0(D) :
A(Rf) = R(Af) = −f ,
for all f ∈C2
0(D) .
(9.3.27)
More generally, for all α ≥0 we get the following analogue of Theorem 8.1.5:
(A −α)(Rαf) = Rα(A −α)f = −f
for all f ∈C2
0(D) .
(9.3.28)
The ﬁrst part of this is already established in (9.3.10) and the second part
follows from the following useful extension of the Dynkin formula
Ex[e−ατf(Xτ)] = f(x) + Ex
·
τ
Z
0
e−αs(A −α)f(Xs)ds
¸
.
(9.3.29)
If α > 0 this is valid for all stopping times τ ≤∞and all f ∈C2
0(Rn). (See
Exercise 9.6.)
Example 9.3.6. If Xt = Bt is 1-dimensional Brownian motion in a bounded
interval (a, b) ⊂R then we can compute the Green function G(x, y) explicitly.
To this end, choose a bounded continuous function g: (a, b) →R and let us
compute
v(x): = Ex
· τD
Z
0
g(Bt)dt
¸
.
By Corollary 9.1.2 we know that v is the solution of the diﬀerential equation
1
2v′′(x) = −g(x) ;
x ∈(a, b)
v(a) = v(b) = 0 .
Integrating twice and using the boundary conditions we get
v(x) = 2(x −a)
b −a
b
Z
a
µ
y
Z
a
g(z)dz
¶
dy −2
x
Z
a
µ
y
Z
a
g(z)dz
¶
dy .
Changing the order of integration we can rewrite this as
v(x) =
b
Z
a
g(y)G(x, y)dy
where
G(x, y) = 2(x −a)(b −y)
b −a
−2(x −y) · X(−∞,x)(y) .
(9.3.30)

188
9. Applications to Boundary Value Problems
We conclude that the Green function of Brownian motion in the interval
(a, b) is given by (9.3.30).
In higher dimension n the Green function y →G(x, y) of Brownian mo-
tion starting at x will not be continuous at x. It will have a logarithmic
singularity (i.e. a singularity of order ln
1
|x−y|) for n = 2 and a singularity of
the order |x −y|2−n for n > 2.
Exercises
9.1.
In each of the cases below ﬁnd an Itˆo diﬀusion whose generator coin-
cides with L on C2
0:
a) Lf(t, x) = α ∂f
∂t + 1
2β2 ∂2f
∂x2 ; α, β constants
b) Lf(x1, x2) = a ∂f
∂x1 + b ∂f
∂x2 + 1
2( ∂2f
∂x2
1 + ∂2f
∂x2
2 ) ; a, b constants
c) Lf(x) = αxf ′(x) + 1
2β2f ′′(x) ; α, β constants
d) Lf(x) = αf ′(x) + 1
2β2x2f ′′(x) ; α, β constants
e) Lf(x1, x2) = ln(1+x2
1) ∂f
∂x1 +x2
∂f
∂x2 +x2
2
∂2f
∂x2
1 +2x1x2
∂2f
∂x1∂x2 +2x2
1
∂2f
∂x2
2 .
9.2.
Use Theorem 9.3.3 to ﬁnd the bounded solutions of the following
boundary value problems:
(i)
( ∂u
∂t + 1
2 · ∂2u
∂x2 = eρtφ(x) ;
0 < t < T, x ∈R
u(T, x) = ψ(x) ;
x ∈R
where φ, ψ are given bounded, continuous functions.
(ii)
½ αxu′(x) + 1
2β2x2u′′(x) = 0 ;
0 < x < x0
u(x0) = x2
0
where α, β are given constants, α ≥1
2β2.

Exercises
189
(iii) If α < 1
2β2 there are inﬁnitely many bounded solutions of (ii),
and an additional boundary condition e.g. at x = 0 is needed to
provide uniqueness. Explain this in view of Theorem 9.3.3.
9.3.
Write down (using Brownian motion) and compare the solutions u(t, x)
of the following two boundary value problems:
a)
(
∂u
∂t + 1
2∆u = 0
for 0 < t < T, x ∈Rn
u(T, x) = φ(x)
for x ∈Rn .
b)
(
∂u
∂t −1
2∆u = 0
for 0 < t < T, x ∈Rn
u(0, x) = ψ(x)
for x ∈Rn .
9.4.
Let G and H be bounded open subsets of Rn, G ⊂H, and let Bt be
n-dimensional Brownian motion. Use the property (H) for Bt to prove
that
inf{t > 0; Bt /∈H} = inf{t > τG; Bt /∈H}
i.e., with the terminology of (7.2.6),
τH = τ α
H
where α = τG .
Use this to prove that if Xt = Bt then the mean value property (7.2.9)
holds for all bounded open G ⊂H, i.e. it is not necessary to require
G ⊂⊂H in this case. This veriﬁes the statement (9.2.24).
9.5.
(The eigenvalues of the Laplacian)
Let D ⊂Rn be open, bounded and let λ ∈R.
a) Suppose there exists a solution u ∈C2(D)∩C(D), u not identically
zero, such that
½
−1
2∆u = λu
in
D
u = 0
on
∂D .
(9.3.31)
Show that we must have λ > 0. (Hint: If 1
2∆u = −λu in D then
⟨1
2∆u, u⟩= ⟨−λu, u⟩
where
⟨u, v⟩=
Z
D
u(x)v(x)dx .
Now use integration by parts.)
b) It can be shown that if D is smooth then there exist 0 < λ0 < λ1 <
· · · < λn < · · · where λn →∞such that (9.3.31) holds for λ = λn,
n = 0, 1, 2, . . ., and for no other values of λ. The numbers {λn} are
called the eigenvalues of the operator −1
2∆in the domain D and
the corresponding (nontrivial) solutions un of (9.3.31) are called the
eigenfunctions. There is an interesting probabilistic interpretation
of the lowest eigenvalue λ0. The following result indicates this:

190
9. Applications to Boundary Value Problems
Put τ = τD = inf{t > 0; Bt /∈D}, choose ρ > 0 and deﬁne
wρ(x) = Ex[exp(ρτ)] ;
x ∈D .
Prove that if wρ(x) < ∞for all x ∈D then ρ is not an eigenvalue
for −1
2∆. (Hint: Let u be a solution of (9.3.31) with λ = ρ. Apply
Dynkin’s formula to the process dYt = (dt, dBt) and the function
f(t, x) = eρtu(x) to deduce that u(x) = 0 for x ∈D).
c) Conclude that
λ0 ≥sup{ρ; Ex[exp(ρτ)] < ∞for all x ∈D} .
(We have in fact equality here. See for example Durrett (1984),
Chap. 8B).
9.6.
Prove formula (9.3.29), for example by applying the Dynkin formula
to the process
dYt =
·
dt
dXt
¸
and the function g(y) = g(t, x) = e−αtf(x).
9.7.
a) Let Bt be Brownian motion in R2. Prove that
P x[∃t > 0; Bt = y] = 0
for all x, y ∈R2 .
(Hint: First assume x ̸= y. We may choose y = 0. One possible
approach would be to apply Dynkin’s formula with f(u) = ln |u|
and τ = inf{t > 0; |Bt| ≤ρ or |Bt| ≥R}, where 0 < ρ < R. Let
ρ →0 and then R →∞. If x = y consider P x[∃t > ϵ; Bt = x] and
use the Markov property.)
b) Let Bt = (B(1)
t
, B(2)
t
) be Brownian motion in R2. Prove that
eBt = (−B(1)
t
, B(2)
t
) is also a Brownian motion.
c) Prove that 0 ∈R2 is a regular boundary point (for Brownian mo-
tion) of the plane region
D = {(x1, x2) ∈R2; x2
1 + x2
2 < 1} \ {(x1, 0); x1 ≥0} .
d) Prove that 0 ∈R3 is an irregular boundary point (for Brownian
motion) of the 3-dimensional region
U = {(x1, x2, x3) ∈R3, x2
1 + x2
2 + x2
3 < 1} \ {(x1, 0, 0); x1 ≥0} .

Exercises
191
9.8.
a) Find an Itˆo diﬀusion Xt and a measurable set G which is semipolar
but not polar for Xt.
b) Find an Itˆo diﬀusion Xt and a countable family of thin sets Hk;
k = 1, 2, . . . such that
∞
S
k=1
Hk is not thin.
9.9.
a) Let Xt be an Itˆo diﬀusion in Rn and assume that g is a non-constant
locally bounded real Xt-harmonic function on a connected open
set G ⊂Rn. Prove that g satisﬁes the following weak form of the
maximum principle: g does not have a (local or global) maximum
at any point of G. (Similarly g satisﬁes the minimum principle).
b) Give an example to show that a non-constant bounded Xt-harmonic
function g can have a (non-strict) global maximum. (Hint: Consider
uniform motion to the right.)
9.10. Find the (stochastic) solution f(t, x) of the boundary value problem



K(x)e−ρt + ∂f
∂t + αx ∂f
∂x + 1
2β2x2 ∂2f
∂x2 = 0
for x > 0, 0 < t < T
f(T, x) = e−ρT φ(x)
for x > 0
where K, φ are given functions and T, ρ, α, β are constants, ρ>0, T >0.
(Hint: Consider dYt = (dt, dXt) where Xt is a geometric Brownian
motion).
9.11. a) The Poisson kernel is deﬁned by
Pr(θ) =
1 −r2
1 −2r cos θ + r2 = 1 −|z|2
|1 −z|2
where r ≥0, θ ∈[0, 2π], z = reiθ ∈C
(i = √−1 ).
The Poisson formula states that if D denotes the open unit disk in
the plane R2 = C and h ∈C( D ) satisﬁes ∆h = 0 in D then
h(reiθ) = 1
2π
2π
Z
0
Pr(t −θ)h(eit)dt .

192
9. Applications to Boundary Value Problems
Prove that the probability that Brownian motion, starting from
z ∈D, ﬁrst exits from D at a set F ⊂∂D is given by
1
2π
Z
F
Pr(t −θ)dt ,
where z = reiθ .
b) The function
w = φ(z) = i1 + z
1 −z
maps the disc D = {|z| < 1} conformally onto the half plane H =
{w = u+iv; v > 0}, φ(∂D) = R and φ(0) = i. Use Example 8.5.9 to
prove that if µ denotes the harmonic measure for Brownian motion
at the point i = (0, 1) for the half plane H then
Z
R
f(ξ)dµ(ξ) = 1
2π
2π
Z
0
f(φ(eit))dt =
1
2πi
Z
∂D
f(φ(z))
z
dz .
c) Substitute w = φ(z) (i.e. z = ψ(w): = φ−1(w) = w−i
w+i) in the inte-
gral above to show that
Z
R
f(ξ)dµ(ξ) = 1
π
Z
∂H
f(w)
dw
|w −i|2 = 1
π
∞
Z
−∞
f(x)
dx
x2 + 1 .
d) Show that the harmonic measure µw
H for Brownian motion in H at
the point w = u + iv ∈H is given by
dµw
H(x) = 1
π ·
v
(x −u)2 + v2 dx .
9.12. (A Feynman-Kac formula for boundary value problems)
Let Xt be an Itˆo diﬀusion on Rn whose generator coincides with a
given partial diﬀerential operator L on C2
0(Rn). Let D, φ and g be as
in Theorem 9.3.3 and let q(x) ≥0 be a continuous function on Rn.

Exercises
193
Consider the boundary value problem: Find h ∈C2(D) ∩C( D ) such
that
( Lh(x) −q(x)h(x) = −g(x)
on D
lim
x→y h(x) = φ(y) ;
y ∈∂D .
Show that if a bounded solution h exists, then
h(x) = Ex
· τD
Z
0
e
−R t
0 q(Xs)dsg(Xt)dt + e
−R τD
0
q(Xs)dsφ(XτD )
¸
.
(Compare with the Feynman-Kac formula.)
Hint: Proceed as in the proof of Theorem 8.2.1 b).
For more information on stochastic solutions of boundary value problems
see Freidlin (1985).
9.13. Let D = (a, b) be a bounded interval.
a) For x ∈R deﬁne
Xt = Xx
t = x + µt + σBt ;
t ≥0
where µ, σ are constants, σ ̸= 0. Use Corollary 9.1.2 to compute
w(x): = Ex[φ(XτD )] + Ex
· τD
Z
0
g(Xt)dt
¸
when φ: {a, b} →R and g: (a, b) →R are given functions, g
bounded and continuous.
b) Use the results in a) to compute the Green function G(x, y) of the
process Xt.
(Hint: Choose φ = 0 and proceed as in Example 9.3.6.)
9.14. Let D = (a, b) ⊂(0, ∞) be a bounded interval and let
dXt = rXtdt + αXtdBt ;
X0 = x ∈(a, b)
be a geometric Brownian motion.
a) Use Corollary 9.1.2 to ﬁnd
Qx[XτD = b] .
(Hint: Choose g = 0 and φ(a) = 0, φ(b) = 1.)
b) Use Corollary 9.1.2 to compute
w(x) = Ex[φ(XτD )] + Ex
· τD
Z
0
g(Xt)dt
¸

194
9. Applications to Boundary Value Problems
for given functions φ: {a, b} →R and g: (a, b) →R, g bounded and
continuous.
(Hint: The substitution t = ln x, w(x) = h(ln x) transforms the
diﬀerential equation
1
2α2x2w′′(x) + rxw′(x) = −g(x) ;
x > 0
into the diﬀerential equation
1
2α2h′′(t) + (r −1
2α2)h′(t) = −g(et) ;
t ∈R .)
9.15. a) Let D = (a, b) ⊂R be a bounded interval and let Xt = Bt be
1-dimensional Brownian motion. Use Corollary 9.1.2 to compute
h(x) = Ex[e
−ρτD ψ(BτD )] + Ex
· τD
Z
0
e−ρtB2
t dt
¸
for a given function ψ: {a, b} →R, when ρ > 0 is constant.
(Hint: Consider the Itˆo diﬀusion
dYt =
·
dY (1)
t
dY (2)
t
¸
=
·
dt
dBt
¸
=
·
1
0
¸
dt +
·
0
1
¸
dBt ;
Y0 = y = (s, x) .
Then
h(x) = w(0, x)
where
w(s, x) = w(y) = Ey[φ(YτD )] + Ey
· τD
Z
0
g(Yt)dt
¸
with
φ(y) = φ(s, x) = e−ρsψ(x)
and
g(y) = g(s, x) = e−ρsx2 .
Note that
τD = inf{t > 0; Bt ̸∈(a, b)} = inf{t > 0; Y (2)
t
̸∈(a, b)}
= inf{t > 0; Yt ̸∈R × (a, b)} .
To ﬁnd w(s, x) solve the boundary value problem



1
2
∂2w
∂x2 + ∂w
∂s = −e−ρsx2 ;
a < x < b
w(s, a) = e−ρsψ(a) ,
w(s, b) = e−ρsψ(b) .
To this end, try w(s, x) = e−ρsh(x).)
b) Use the method in a) to ﬁnd Ex[e
−ρτD ].
(Compare with Exercise 7.19.)

10. Application to Optimal Stopping
10.1 The Time-Homogeneous Case
Problem 5 in the introduction is a special case of a problem of the following
type:
Problem 10.1.1 (The optimal stopping problem).
Let Xt be an Itˆo diﬀusion on Rn and let g (the reward function) be a given
function on Rn, satisfying
a) g(ξ) ≥0 for all ξ ∈Rn
(10.1.1)
b) g is continuous.
Find a stopping time τ ∗= τ ∗(x, ω) (called an optimal stopping time) for
{Xt} such that
Ex[g(Xτ ∗)] = sup
τ Ex[g(Xτ)]
for all x ∈Rn ,
(10.1.2)
the sup being taken over all stopping times τ for {Xt}. We also want to ﬁnd
the corresponding optimal expected reward
g∗(x) = Ex[g(Xτ ∗)] .
(10.1.3)
Here g(Xτ) is to be interpreted as 0 at the points ω ∈Ωwhere τ(ω) = ∞
and as usual Ex denotes the expectation with respect to the probability law
Qx of the process Xt; t ≥0 starting at X0 = x ∈Rn.
We may regard Xt as the state of a game at time t, each ω corresponds
to one sample of the game. For each time t we have the option of stopping
the game, thereby obtaining the reward g(Xt), or continue the game in the
hope that stopping it at a later time will give a bigger reward. The problem
is of course that we do not know what state the game is in at future times,
only the probability distribution of the “future”. Mathematically, this means
that the possible “stopping” times we consider really are stopping times in
the sense of Deﬁnition 7.2.1: The decision whether τ ≤t or not should only
depend on the behaviour of the Brownian motion Br (driving the process X)
up to time t, or perhaps only on the behaviour of Xr up to time t. So, among

196
10. Application to Optimal Stopping
all possible stopping times τ we are asking for the optimal one, τ ∗, which
gives the best result “in the long run”, i.e. the biggest expected reward in
the sense of (10.1.2).
In the following we will outline how a solution to this problem can be
obtained using the material from the preceding chapter. Later in this chapter
we shall see that our discussion of problem (10.1.2)–(10.1.3) also covers the
apparently more general problems
g∗(s, x) = sup
τ E(s,x)[g(τ, Xτ)] = E(s,x)[g(τ ∗, Xτ ∗)]
(10.1.4)
and
G∗(s, x) = sup
τ E(s,x)
·
τ
Z
0
f(t, Xt)dt + g(τ, Xτ)
¸
= E(s,x)
· τ ∗
Z
0
f(t, Xt)dt + g(τ ∗, Xτ ∗)
¸
(10.1.5)
where f is a given reward rate function (satisfying certain conditions).
We shall also discuss possible extensions of problem (10.1.2)–(10.1.3) to
cases where g is not necessarily continuous or where g may assume negative
values.
A basic concept in the solution of (10.1.2)–(10.1.3) is the following:
Deﬁnition 10.1.2. A measurable function f: Rn →[0, ∞] is called super-
meanvalued (w.r.t. Xt) if
f(x) ≥Ex[f(Xτ)]
(10.1.6)
for all stopping times τ and all x ∈Rn.
If, in addition, f is also lower semicontinuous, then f is called l.s.c. su-
perharmonic or just superharmonic (w.r.t. Xt).
Note that if f: Rn →[0, ∞] is lower semicontinuous then by the Fatou
lemma
f(x) ≤Ex[ lim
k→∞
f(Xτk)] ≤lim
k→∞
Ex[f(Xτk)] ,
(10.1.7)
for any sequence {τk} of stopping times such that τk →0 a.s. P. Combining
this with (10.1.6) we see that if f is (l.s.c.) superharmonic, then
f(x) = lim
k→∞Ex[f(Xτk)]
for all x ,
(10.1.8)
for all such sequences τk.
Remarks. 1) In the literature (see e.g. Dynkin (1965 II)) one often ﬁnds
a weaker concept of Xt-superharmonicity, deﬁned by the supermeanvalued

10.1 The Time-Homogeneous Case
197
property (10.1.6) plus the stochastic continuity requirement (10.1.8). This
weaker concept corresponds to the Xt-harmonicity deﬁned in Chapter 9.
2) If f ∈C2(Rn) it follows from Dynkin’s formula that f is superhar-
monic w.r.t. Xt if and only if
Af ≤0
where A is the characteristic operator of Xt. This is often a useful criterion
(See e.g. Example 10.2.1).
3) If Xt = Bt is Brownian motion in Rn then the superharmonic func-
tions for Xt coincide with the (nonnegative) superharmonic functions in clas-
sical potential theory. See Doob (1984) or Port and Stone (1979).
We state some useful properties of superharmonic and supermeanvalued
functions.
Lemma 10.1.3. a) If f is superharmonic (supermeanvalued) and α > 0,
then αf is superharmonic (supermeanvalued).
b) If f1, f2 are superharmonic (supermeanvalued), then f1 + f2 is superhar-
monic (supermeanvalued).
c) If {fj}j∈J is a family of supermeanvalued functions, then f(x): = inf
j∈J{fj(x)}
is supermeanvalued if it is measurable (J is any set).
d) If f1, f2, · · · are superharmonic (supermeanvalued) functions and fk ↑f
pointwise, then f is superharmonic (supermeanvalued).
e) If f is supermeanvalued and σ ≤τ are stopping times, then Ex[f(Xσ)] ≥
Ex[f(Xτ)].
f) If f is supermeanvalued and H is a Borel set, then ef(x): = Ex[f(XτH)] is
supermeanvalued.
Proof of Lemma 10.1.3.
a) and b) are straightforward.
c) Suppose fj is supermeanvalued for all j ∈J. Then
fj(x) ≥Ex[fj(Xτ)] ≥Ex[f(Xτ)]
for all j .
So f(x) = inf fj(x) ≥Ex[f(Xτ)], as required.
d) Suppose fj is supermeanvalued, fj ↑f. Then
f(x) ≥fj(x) ≥Ex[fj(Xτ)]
for all j, so
f(x) ≥lim
j→∞Ex[fj(Xτ)] = Ex[f(Xτ)] ,
by monotone convergence. Hence f is supermeanvalued. If each fj is also
lower semicontinuous then if yk →x as k →∞we have
fj(x) ≤lim
k→∞
fj(yk) ≤lim
k→∞
f(yk)
for each j .
Hence, by letting j →∞,

198
10. Application to Optimal Stopping
f(x) ≤lim
k→∞
f(yk) .
e) If f is supermeanvalued we have by the Markov property when t > s
Ex[f(Xt)|Fs] = EXs[f(Xt−s)] ≤f(Xs) ,
(10.1.9)
i.e. the process
ζt = f(Xt)
is a supermartingale w.r.t. the σ-algebras Ft generated by {Br; r ≤t}.
(Appendix C). Therefore, by Doob’s optional sampling theorem (see Gih-
man and Skorohod (1975, Theorem 6 p. 11)) we have
Ex[f(Xσ)] ≥Ex[f(Xτ)]
for all stopping times σ, τ with σ ≤τ a.s. Qx.
f) Suppose f is supermeanvalued. By the strong Markov property (7.2.2)
and formula (7.2.6) we have, for any stopping time α,
Ex[ ef(Xα)] = Ex[EXα[f(XτH)]] = Ex[Ex[θαf(XτH)|Fα]]
= Ex[θαf(XτH)] = Ex[f(Xτ α
H)]
(10.1.10)
where τ α
H = inf{t > α; Xt /∈H}. Since τ α
H ≥τH we have by e)
Ex[ ef(Xα)] ≤Ex[f(XτH)] = ef(x) ,
so ef is supermeanvalued.
⊔⊓
The following concepts are fundamental:
Deﬁnition 10.1.4. Let h be a real measurable function on Rn. If f is a
superharmonic (supermeanvalued) function and f ≥h we say that f is a
superharmonic (supermeanvalued) majorant of h (w.r.t. Xt). The function
h(x) = inf
f f(x); x ∈Rn ,
(10.1.11)
the inf being taken over all supermeanvalued majorants f of h, is called the
least supermeanvalued majorant of h.
Similarly, suppose there exists a function bh such that
(i) bh is a superharmonic majorant of h and
(ii) if f is any other superharmonic majorant of h then bh ≤f.
Then bh is called the least superharmonic majorant of h.
Note that by Lemma 10.1.3 c) the function h is supermeanvalued if it is
measurable. Moreover, if h is lower semicontinuous, then bh exists and bh = h.

10.1 The Time-Homogeneous Case
199
Later we will prove that if g is nonnegative (or lower bounded) and lower
semicontinuous, then bg exists and bg = g (Theorem 10.1.7).
Let g ≥0 and let f be a supermeanvalued majorant of g. Then if τ is a
stopping time
f(x) ≥Ex[f(Xτ)] ≥Ex[g(Xτ)] .
So
f(x) ≥sup
τ Ex[g(Xτ)] = g∗(x) .
Therefore we always have
bg(x) ≥g∗(x)
for all x ∈Rn .
(10.1.12)
What is not so easy to see is that the converse inequality also holds, i.e. that
in fact
bg = g∗.
(10.1.13)
We will prove this after we have established a useful iterative procedure for
calculating bg. Before we give such a procedure let us introduce a concept
which is related to superharmonic functions:
Deﬁnition 10.1.5. A lower semicontinuous function f: Rn →[0, ∞] is
called excessive (w.r.t. Xt) if
f(x) ≥Ex[f(Xs)]
for all s ≥0, x ∈Rn .
(10.1.14)
It is clear that a superharmonic function must be excessive. What is not
so obvious, is that the converse also holds:
Theorem 10.1.6. Let f: Rn →[0, ∞]. Then f is excessive w.r.t. Xt if and
only if f is superharmonic w.r.t. Xt.
Proof in a special case.
Let L be the diﬀerential operator associated to
X (given by the right hand side of (7.3.3)), so that L coincides with the
generator A of X on C2
0. We only prove the theorem in the special case when
f ∈C2(Rn) and Lf is bounded: Then by Dynkin’s formula we have
Ex[f(Xt)] = f(x) + Ex
·
t
Z
0
Lf(Xr)dr
¸
for all t ≥0 ,
so if f is excessive then Lf ≤0. Therefore, if τ is a stopping time we get
Ex[f(Xt∧τ)] ≤f(x)
for all t ≥0 .
Letting t →∞we see that f is superharmonic.
⊔⊓
A proof in the general case can be found in Dynkin (1965 II, p. 5).
The ﬁrst iterative procedure for the least superharmonic majorant bg of g
is the following:

200
10. Application to Optimal Stopping
Theorem 10.1.7. (Construction of the least superharmonic majo-
rant).
Let g = g0 be a nonnegative, lower semicontinuous function on Rn and deﬁne
inductively
gn(x) = sup
t∈Sn
Ex[gn−1(Xt)] ,
(10.1.15)
where Sn = {k · 2−n; 0 ≤k ≤4n}, n = 1, 2, . . . . Then gn ↑bg and bg is the
least superharmonic majorant of g. Moreover, bg = g.
Proof. Note that {gn} is increasing. Deﬁne ˇg(x) = lim
n→∞gn(x). Then
ˇg(x) ≥gn(x) ≥Ex[gn−1(Xt)]
for all n and all t ∈Sn .
Hence
ˇg(x) ≥lim
n→∞Ex[gn−1(Xt)] = Ex[ˇg(Xt)]
(10.1.16)
for all t ∈S =
∞
S
n=1
Sn .
Since ˇg is an increasing limit of lower semicontinuous functions (Lemma 8.1.4)
ˇg is lower semicontinuous. Fix t ∈R and choose tk ∈S such that tk →t.
Then by (10.1.16), the Fatou lemma and lower semicontinuity
ˇg(x) ≥lim
k→∞
Ex[ˇg(Xtk)] ≥Ex[ lim
k→∞
ˇg(Xtk)] ≥Ex[ˇg(Xt)] .
So ˇg is an excessive function. Therefore ˇg is superharmonic by Theorem 10.1.6
and hence ˇg is a superharmonic majorant of g. On the other hand, if f is any
supermeanvalued majorant of g, then clearly by induction
f(x) ≥gn(x)
for all n
and so f(x) ≥ˇg(x). This proves that ˇg is the least supermeanvalued majorant
g of g. So ˇg = bg.
⊔⊓
It is a consequence of Theorem 10.1.7 that we may replace the ﬁnite sets
Sn by the whole interval [0, ∞]:
Corollary 10.1.8. Deﬁne h0 = g and inductively
hn(x) = sup
t≥0
Ex[hn−1(Xt)] ;
n = 1, 2, . . .
Then hn ↑bg.
Proof. Let h = lim hn. Then clearly h ≥ˇg = bg. On the other hand, since bg is
excessive we have
bg(x) ≥sup
t≥0
Ex[bg(Xt)].
So by induction
bg ≥hn
for all n .
Thus bg = h and the proof is complete.

10.1 The Time-Homogeneous Case
201
We are now ready for our ﬁrst main result on the optimal stopping prob-
lem. The following result is basically due to Dynkin (1963) (and, in a mar-
tingale context, Snell (1952)):
Theorem 10.1.9 (Existence theorem for optimal stopping).
Let g∗denote the optimal reward and bg the least superharmonic majorant of
a continuous reward function g ≥0.
a) Then
g∗(x) = bg(x) .
(10.1.17)
b) For ϵ > 0 let
Dϵ = {x; g(x) < bg(x) −ϵ} .
(10.1.18)
Suppose g is bounded. Then stopping at the ﬁrst time τϵ of exit from Dϵ
is close to being optimal, in the sense that
|g∗(x) −Ex[g(Xτϵ)]| ≤2ϵ
(10.1.19)
for all x.
c) For arbitrary continuous g ≥0 let
D = {x; g(x) < g∗(x)}
(the continuation region) .
(10.1.20)
For N = 1, 2, . . . deﬁne gN = g ∧N, DN = {x; gN (x) < c
gN (x)} and
σN = τDN . Then DN ⊂DN+1, DN ⊂D ∩g−1([0, N)), D = S
N
DN. If
σN < ∞a.s. Qx for all N then
g∗(x) = lim
N→∞Ex[g(XσN )] .
(10.1.21)
d) In particular, if τD < ∞a.s. Qx and the family {g(XσN )}N is uniformly
integrable w.r.t. Qx (Appendix C), then
g∗(x) = Ex[g(XτD)]
and τ ∗= τD is an optimal stopping time.
Proof. First assume that g is bounded and deﬁne
egϵ(x) = Ex[bg(Xτϵ)]
for ϵ > 0 .
(10.1.22)
Then egϵ is supermeanvalued by Lemma 10.1.3 f). We claim that
g(x) ≤egϵ(x) + ϵ
for all x .
(10.1.23)
To see this suppose
β: = sup
x {g(x) −egϵ(x)} > ϵ .
(10.1.24)
Then for all η > 0 we can ﬁnd x0 such that

202
10. Application to Optimal Stopping
g(x0) −egϵ(x0) ≥β −η .
(10.1.25)
On the other hand, since egϵ +β is a supermeanvalued majorant of g, we have
bg(x0) ≤egϵ(x0) + β .
(10.1.26)
Combining (10.1.25) and (10.1.26) we get
bg(x0) ≤g(x0) + η .
(10.1.27)
Consider the two possible cases:
Case 1: τϵ > 0 a.s. Qx0. Then by (10.1.27) and the deﬁnition of Dϵ
g(x0) + η ≥bg(x0) ≥Ex0[bg(Xt∧τϵ)] ≥Ex0[(g(Xt) + ϵ)X{t<τϵ}]
for all t > 0 .
Hence by the Fatou lemma and lower semicontinuity of g
g(x0) + η ≥lim
t→0
Ex0[(g(Xt) + ϵ)X{t<τϵ}]
≥Ex0[ lim
t→0
(g(Xt) + ϵ)X{t<τϵ}] ≥g(x0) + ϵ .
This is a contradiction if η < ϵ.
Case 2: τϵ = 0 a.s. Qx0. Then egϵ(x0) = bg(x0), so g(x0) ≤egϵ(x0), contra-
dicting (10.1.25) for η < β.
Therefore (10.1.24) leads to a contradiction. Thus (10.1.23) is proved and
we conclude that egϵ + ϵ is a supermeanvalued majorant of g. Therefore
bg ≤egϵ + ϵ = E[bg(Xτϵ)] + ϵ ≤E[(g + ϵ)(Xτϵ)] + ϵ ≤g∗+ 2ϵ
(10.1.28)
and since ϵ was arbitrary we have by (10.1.12)
bg = g∗.
If g is not bounded, let
gN = min(N, g) ,
N = 1, 2, . . .
and as before let c
gN be the least superharmonic majorant of gN. Then
g∗≥g∗
N = c
gN ↑h
as N →∞, where h ≥bg
since h is a superharmonic majorant of g. Thus h = bg = g∗and this proves
(10.1.17) for general g. From (10.1.28) and (10.1.17) we obtain (10.1.19).
Finally, to obtain c) and d) let us again ﬁrst assume that g is bounded.
Then, since
τϵ ↑τD
as ϵ ↓0

10.1 The Time-Homogeneous Case
203
and τD < ∞a.s we have
Ex[g(Xτϵ)] →Ex[g(XτD)]
as ϵ ↓0 ,
(10.1.29)
and hence by (10.1.28) and (10.1.17)
g∗(x) = Ex[g(XτD)]
if g is bounded .
(10.1.30)
Finally, if g is not bounded deﬁne
h = lim
N→∞c
gN .
Then h is superharmonic by Lemma 10.1.3 d) and since c
gN ≤bg for all N we
have h ≤bg. On the other hand gN ≤c
gN ≤h for all N and therefore g ≤h.
Since bg is the least superharmonic majorant of g we conclude that
h = bg .
(10.1.31)
Hence by (10.1.30), (10.1.31) we obtain (10.1.21):
g∗(x) = lim
N→∞c
gN (x) = lim
N→∞Ex[gN (XσN )] ≤lim
N→∞Ex[g(XσN )] ≤g∗(x) .
Note that c
gN ≤N everywhere, so if gN (x)< c
gN (x) then gN (x)<N and there-
fore g(x) = gN (x) < c
gN (x) ≤bg(x) and gN+1(x) = gN (x) < c
gN (x) ≤d
gN+1(x).
Hence DN ⊂D ∩{x; g(x) < N} and DN ⊂DN+1 for all N. So by (10.1.31)
we conclude that D is the increasing union of the sets DN; N = 1, 2, . . .
Therefore
τD = lim
N→∞σN .
So by (10.1.21) and uniform integrability we have
bg(x) =
lim
N→∞c
gN (x) = lim
N→∞Ex[gN (XσN )]
= Ex[ lim
N→∞gN (XσN )] = Ex[g(XτD)] ,
and the proof of Theorem 10.1.9 is complete.
⊔⊓
Remarks.
1) Note that the sets D, Dϵ and DN are open, since bg = g∗is lower semicon-
tinuous and g is continuous.
2) By inspecting the proof of a) we see that (10.1.17) holds under the weaker
assumption that g ≥0 is lower semicontinuous.
The following consequence of Theorem 10.1.9 is often useful:
Corollary 10.1.10. Suppose there exists a Borel set H such that
egH(x): = Ex[g(XτH)]
is a supermeanvalued majorant of g. Then
g∗(x) = egH(x) ,
so τ ∗= τH is optimal .

204
10. Application to Optimal Stopping
Proof. If egH is a supermeanvalued majorant of g then clearly
g(x) ≤egH(x) .
On the other hand we of course have
egH(x) ≤sup
τ Ex[g(Xτ)] = g∗(x) ,
so g∗= egH by Theorem 10.1.7 and Theorem 10.1.9 a).
⊔⊓
Corollary 10.1.11. Let
D = {x; g(x) < bg(x)}
and put
eg(x) = egD(x) = Ex[g(XτD)] .
If eg ≥g then eg = g∗.
Proof. Since XτD /∈D we have g(XτD) ≥bg(XτD) and therefore g(XτD) =
bg(XτD), a.s. Qx. So eg(x) = Ex[bg(XτD)] is supermeanvalued since bg is, and
the result follows from Corollary 10.1.10.
⊔⊓
Theorem 10.1.9 gives a suﬃcient condition for the existence of an optimal
stopping time τ ∗. Unfortunately, τ ∗need not exist in general. For example,
if
Xt = t
for t ≥0 (deterministic)
and
g(ξ) =
ξ2
1 + ξ2 ;
ξ ∈R
then g∗(x) = 1, but there is no stopping time τ such that
Ex[g(Xτ)] = 1 .
However, we can prove that if an optimal stopping time τ ∗exists, then the
stopping time given in Theorem 10.1.9 is optimal:
Theorem 10.1.12 (Uniqueness theorem for optimal stopping).
Deﬁne as before
D = {x; g(x) < g∗(x)} ⊂Rn .
Suppose there exists an optimal stopping time τ ∗= τ ∗(x, ω) for the problem
(10.1.2) for all x. Then
τ ∗≥τD
for all x ∈D
(10.1.32)
and
g∗(x) = Ex[g(XτD)]
for all x ∈Rn .
(10.1.33)
Hence τD is an optimal stopping time for the problem (10.1.2).

10.1 The Time-Homogeneous Case
205
Proof. Choose x ∈D. Let τ be an Ft-stopping time and assume
Qx[τ < τD] > 0. Since g(Xτ) < g∗(Xτ) if τ < τD and g ≤g∗always, we have
Ex[g(Xτ)] =
Z
τ<τD
g(Xτ)dQx +
Z
τ≥τD
g(Xτ)dQx
<
Z
τ<τD
g∗(Xτ)dQx +
Z
τ≥τD
g∗(Xτ)dQx = Ex[g∗(Xτ)] ≤g∗(x) ,
since g∗is superharmonic. This proves (10.1.32).
To obtain (10.1.33) we ﬁrst choose x ∈D. Since bg is superharmonic we
have by (10.1.32) and Lemma 10.1.3 e)
g∗(x) = Ex[g(Xτ∗)] ≤Ex[bg(Xτ∗)] ≤Ex[bg(XτD)]
= Ex[g(XτD)] ≤g∗(x) ,
which proves (10.1.33) for x ∈D .
Next, choose x ∈∂D to be an irregular boundary point of D. Then τD > 0
a.s. Qx. Let {αk} be a sequence of stopping times such that 0 < αk < τD
and αk →0 a.s. Qx, as k →∞. Then Xαk ∈D so by (10.1.32), (7.2.6) and
the strong Markov property (7.2.2)
Ex[g(XτD)]=Ex[θαkg(XτD)]=Ex[EXαk [g(XτD)]]=Ex[g∗(Xαk)]
for all k .
Hence by lower semicontinuity and the Fatou lemma
g∗(x) ≤Ex[ lim
k→∞
g∗(Xαk)] ≤lim
k→∞
Ex[g∗(Xαk)] = Ex[g(XτD)] .
Finally, if x ∈∂D is a regular boundary point of D or if x ̸∈D we have
τD = 0 a.s. Qx and hence g∗(x) = Ex[g(XτD)].
⊔⊓
Remark. The following observation is sometimes useful:
Let A be the characteristic operator of X. Assume g ∈C2(Rn). Deﬁne
U = {x; Ag(x) > 0} .
(10.1.34)
Then, with D as before, (10.1.20),
U ⊂D .
(10.1.35)
Consequently, from (10.1.32) we conclude that it is never optimal to stop the
process before it exits from U. But there may be cases when U ̸= D, so that
it is optimal to proceed beyond U before stopping. (This is in fact the typical
situation.) See e.g. Example 10.2.2.
To prove (10.1.35) choose x ∈U and let τ0 be the ﬁrst exit time from a
bounded open set W ∋x, W ⊂U. Then by Dynkin’s formula, for u > 0
Ex[g(Xτ0∧u)] = g(x) + Ex
· τ0∧u
Z
0
Ag(Xs)ds
¸
> g(x)
so g(x) < g∗(x) and therefore x ∈D.

206
10. Application to Optimal Stopping
Example 10.1.13. Let Xt = Bt be a Brownian motion in R2. Using that Bt
is recurrent in R2 (Example 7.4.2) one can show that the only (nonnegative)
superharmonic functions in R2 are the constants (Exercise 10.2).
Therefore
g∗(x) = ∥g∥∞: = sup{g(y); y ∈R2}
for all x .
So if g is unbounded then g∗= ∞and no optimal stopping time exists.
Assume therefore that g is bounded. The continuation region is
D = {x; g(x) < ∥g∥∞} ,
so if ∂D is a polar set i.e. cap (∂D) = 0, where cap denotes the logarithmic
capacity (see Port and Stone (1979)), then τD = ∞a.s. and no optimal
stopping exists. On the other hand, if cap(∂D) > 0 then τD < ∞a.s. and
Ex[g(BτD)] = ∥g∥∞= g∗(x) ,
so τ ∗= τD is optimal.
Example 10.1.14. The situation is diﬀerent in Rn for n ≥3.
a) To illustrate this let Xt = Bt be Brownian motion in R3 and let the
reward function be
g(ξ) =
½
|ξ|−1
for |ξ| ≥1
1
for |ξ| < 1 ;
ξ ∈R3 .
Then g is superharmonic (in the classical sense) in R3, so g∗= g every-
where and the best policy is to stop immediately, no matter where the
starting point is.
b) Let us change g to
h(x) =
½
|x|−α
for |x| ≥1
1
for |x| < 1
for some α > 1. Let H = {x; |x| > 1} and deﬁne
eh(x) = Ex[h(BτH)] = P x[τH < ∞] .
Then by Example 7.4.2
eh(x) =
½
1
if |x| ≤1
|x|−1
if |x| > 1 ,
i.e. eh = g (deﬁned in a)), which is a superharmonic majorant of h. There-
fore by Corollary 10.1.10
h∗= eh = g ,
H = D and τ ∗= τH is an optimal stopping time.

10.2 The Time-Inhomogeneous Case
207
Reward Functions Assuming Negative Values
The results we have obtained so far regarding the problem (10.1.2)–(10.1.3)
are based on the assumptions (10.1.1). To some extent these assumptions
can be relaxed, although neither can be removed completely. For example,
we have noted that Theorem 10.1.9 a) still holds if g ≥0 is only assumed to
be lower semicontinuous.
The nonnegativity assumption on g can also be relaxed. First of all, note
that if g is bounded below, say g ≥−M where M > 0 is a constant, then we
can put
g1 = g + M ≥0
and apply the theory to g1. Since
Ex[g(Xτ)] = Ex[g1(Xτ)] −M
if τ < ∞a.s. ,
we have g∗(x) = g∗
1(x) −M, so the problem can be reduced to the optimal
stopping problem for the nonnegative function g1. (See Exercise 10.4.)
If g is not bounded below, then problem (10.1.2)–(10.1.3) is not well-
deﬁned unless
Ex[g−(Xτ)] < ∞
for all τ
(10.1.36)
where
g−(x) = −min(g(x), 0) .
If we assume that g satisﬁes the stronger condition that
the family {g−(Xτ); τ stopping time} is uniformly integrable
(10.1.37)
then basically all the theory from the nonnegative case carries over. We re-
fer to the reader to Shiryaev (1978) for more information. See also Theo-
rem 10.4.1.
10.2 The Time-Inhomogeneous Case
Let us now consider the case when the reward function g depends on both
time and space, i.e.
g = g(t, x): R × Rn →[0, ∞) ,
g is continuous .
(10.2.1)
Then the problem is to ﬁnd g0(x) and τ ∗such that
g0(x) = sup
τ Ex[g(τ, Xτ)] = Ex[g(τ ∗, Xτ ∗)] .
(10.2.2)
To reduce this case to the original case (10.1.2)–(10.1.3) we proceed as follows:
Suppose the Itˆo diﬀusion Xt = Xx
t has the form

208
10. Application to Optimal Stopping
dXt = b(Xt)dt + σ(Xt)dBt ;
t ≥0 , X0 = x
where b: Rn →Rn and σ: Rn →Rn×m are given functions satisfying the con-
ditions of Theorem 5.2.1 and Bt is m-dimensional Brownian motion. Deﬁne
the Itˆo diﬀusion Yt = Y (s,x)
t
in Rn+1 by
Yt =
·
s + t
Xx
t
¸
;
t ≥0 .
(10.2.3)
Then
dYt =
·
1
b(Xt)
¸
dt +
·
0
σ(Xt)
¸
dBt = bb(Yt)dt + bσ(Yt)dBt
(10.2.4)
where
bb(η) = bb(t, ξ) =
·
1
b(ξ)
¸
∈Rn+1 ,
bσ(η) = bσ(t, ξ) =


0 · · · 0
- - - -
σ(ξ)

∈R(n+1)×m ,
with η = (t, ξ) ∈R × Rn.
So Yt is an Itˆo diﬀusion starting at y = (s, x). Let Ry = R(s,x) denote the
probability law of {Yt} and let Ey = E(s,x) denote the expectation w.r.t. Ry.
In terms of Yt the problem (10.2.2) can be written
g0(x) = g∗(0, x) = sup
τ E(0,x)[g(Yτ)] = E(0,x)[g(Yτ ∗)]
(10.2.5)
which is a special case of the problem
g∗(s, x) = sup
τ E(s,x)[g(Yτ)] = E(s,x)[g(Yτ ∗)] ,
(10.2.6)
which is of the form (10.1.2)–(10.1.3) with Xt replaced by Yt.
Note that the characteristic operator b
A of Yt is given by
b
Aφ(s, x) = ∂φ
∂s (s, x) + Aφ(s, x) ;
φ ∈C2(R × Rn)
(10.2.7)
where A is the characteristic operator of Xt (working on the x-variables).
Example 10.2.1. Let Xt = Bt be 1-dimensional Brownian motion and let
the reward function be
g(t, ξ) = e−αt+βξ ;
ξ ∈R
where α, β ≥0 are constants. The characteristic operator b
A of Y s,x
t
=
h
s+t
Bx
t
i
is given by
b
Af(s, x) = ∂f
∂s + 1
2 · ∂2f
∂x2 ;
f ∈C2 .

10.2 The Time-Inhomogeneous Case
209
Thus
Ag = (−α + 1
2β2)g ,
so if β2 ≤2α then g∗= g and the best policy is to stop immediately. If
β2 > 2α we have
U: = {(s, x); b
Ag(s, x) > 0} = R2
and therefore by (10.1.35) D = R2 and hence τ ∗does not exist. If β2 > 2α
we can use Theorem 10.1.7 to prove that g∗= ∞:
sup
t∈Sn
E(s,x)[g(Yt)] = sup
t∈Sn
E[e−α(s+t)+βBx
t ]
= sup
t∈Sn
[e−α(s+t) · e
βx+ 1
2 β2t]
(see the remark following (5.1.6))
= sup
t∈Sn
g(s, x) · e
(−α+ 1
2 β2)t = g(s, x) · exp((−α + 1
2β2)2n) ,
so gn(s, x) →∞as n →∞.
Hence no optimal stopping exists in this case.
Example 10.2.2. (When is the right time to sell the stocks?)
We now return to a speciﬁed version of Problem 5 in the introduction:
Suppose the price Xt at time t of a person’s assets (e.g. a house, stocks,
oil ...) varies according to a stochastic diﬀerential equation of the form
dXt = rXtdt + αXtdBt, X0 = x > 0 ,
where Bt is 1-dimensional Brownian motion and r, α are known constants.
(The problem of estimating α and r from a series of observations can be
approached using the quadratic variation ⟨X, X⟩t of the process {Xt} (Ex-
ercise 4.7) and ﬁltering theory (Example 6.2.11), respectively. Suppose that
connected to the sale of the assets there is a ﬁxed fee/tax or transaction cost
a > 0. Then if the person decides to sell at time t the discounted net of the
sale is
e−ρt(Xt −a) ,
where ρ > 0 is given discounting factor. The problem is to ﬁnd a stopping
time τ that maximizes
E(s,x)[e−ρτ(Xτ −a)] = E(s,x)[g(τ, Xτ)] ,
where
g(t, ξ) = e−ρt(ξ −a) .
The characteristic operator b
A of the process Yt = (s + t, Xt) is given by
b
Af(s, x) = ∂f
∂s + rx∂f
∂x + 1
2α2x2 ∂2f
∂x2 ;
f ∈C2(R2) .

210
10. Application to Optimal Stopping
Hence b
Ag(s, x) = −ρe−ρs(x −a) + rxe−ρs = e−ρs((r −ρ)x + ρa). So
U: = {(s, x); b
Ag(s, x) > 0} =
½ R × R+
if r ≥ρ
{(s, x); x <
aρ
ρ−r}
if r < ρ .
So if r ≥ρ we have U = D = R × R+ so τ ∗does not exist. If r > ρ then
g∗= ∞while if r = ρ then
g∗(s, x) = xe−ρs .
(The proofs of these statements are left as Exercise 10.5.)
It remains to examine the case r < ρ. (If we regard ρ as the sum of
interest rate, inﬂation and tax etc., this is not an unreasonable assumption
in applications.) First we establish that the region D must be invariant w.r.t.
t, in the sense that
D + (t0, 0) = D
for all t0 .
(10.2.8)
To prove (10.2.8) consider
D + (t0, 0) = {(t + t0, x); (t, x) ∈D} = {(s, x); (s −t0, x) ∈D}
= {(s, x); g(s −t0, x) < g∗(s −t0, x)} = {(s, x); eρt0g(s, x) < eρt0g∗(s, x)}
= {(s, x); g(s, x) < g∗(s, x)} = D ,
where we have used that
g∗(s −t0, x) = sup
τ E(s−t0,x)[e−ρτ(Xτ −a)] = sup
τ E[e−ρ(τ+(s−t0))(Xx
τ −a)]
= eρt0 sup
τ E[e−ρ(τ+s)(Xx
τ −a)] = eρt0g∗(s, x) .
Therefore the connected component of D that contains U must have the form
D(x0) = {(t, x); 0 < x < x0}
for some x0 ≥
aρ
ρ−r .
Note that D cannot have any other components, for if V is a component of
D disjoint from U then b
Ag < 0 in V and so, if y ∈V ,
Ey[g(Yτ)] = g(y) + Ey
·
τ
Z
0
b
Ag(Yt)dt
¸
< g(y)
for all exit times τ bounded by the exit time from an x-bounded strip in V .
From this we conclude by Theorem 10.1.9 c) that g∗(y) = g(y), which implies
V = ∅.
Put τ(x0) = τD(x0) and let us compute
eg(s, x) = egx0(s, x) = E(s,x)[g(Yτ(x0))] .
(10.2.9)

10.2 The Time-Inhomogeneous Case
211
From Chapter 9 we know that f = eg is the (bounded) solution of the bound-
ary value problem
∂f
∂s + rx∂f
∂x + 1
2α2x2 ∂2f
∂x2 = 0
for 0 < x < x0
f(s, x0) = e−ρs(x0 −a) .



(10.2.10)
(Note that R×{0} does not contain any regular boundary points of D w.r.t.
Yt = (s + t, Xt).)
If we try a solution of (10.2.10) of the form
f(s, x) = e−ρsφ(x)
we get the following 1-dimensional problem
−ρφ + rxφ′(x) + 1
2α2x2φ′′(x) = 0
for 0 < x < x0
φ(x0) = x0 −a .
¾
(10.2.11)
The general solution φ of (10.2.11) is
φ(x) = C1xγ1 + C2xγ2 ,
where C1, C2 are arbitrary constants and
γi = α−2h
1
2α2 −r ±
q
(r −1
2α2)2 + 2ρα2
i
(i = 1, 2) , γ2 < 0 < γ1 .
Since φ(x) is bounded as x →0 we must have C2 = 0 and the boundary
requirement φ(x0) = x0 −a gives C1 = x−γ1
0
(x0 −a). We conclude that the
bounded solution f of (10.2.10) is
egx0(s, x) = f(s, x) = e−ρs(x0 −a)
µ x
x0
¶γ1
.
(10.2.12)
If we ﬁx (s, x) then the value of x0 which maximizes egx0(s, x) is easily seen
to be given by
x0 = xmax =
aγ1
γ1 −1
(10.2.13)
(note that γ1 > 1 if and only if r < ρ).
Thus we have arrived at the candidate egxmax(s, x) for g∗(s, x) =
sup
τ E(s,x)[e−ρτ(Xτ −a)]. To verify that we indeed have egxmax = g∗it would
suﬃce to prove that egxmax is a supermeanvalued majorant of g (see Corol-
lary 10.1.10). This can be done, but we do not give the details here, since this
problem can be solved more easily by Theorem 10.4.1 (see Example 10.4.2).
The conclusion is therefore that one should sell the assets the ﬁrst time
the price of them reaches the value xmax =
aγ1
γ1−1. The expected discounted
proﬁt obtained from this strategy is

212
10. Application to Optimal Stopping
g∗(s, x) = egxmax(s, x) = e−ρs
µγ1 −1
a
¶γ1−1µ x
γ1
¶γ1
.
Remark.
The reader is invited to check that the value x0 = xmax is the
only value of x0 which makes the function
x →egx0(s, x)
(given by (10.2.9))
continuously diﬀerentiable at x0. This is not a coincidence. In fact, it illus-
trates a general phenomenon which is known as the high contact (or smooth
ﬁt) principle. See Samuelson (1965), McKean (1965), Bather (1970) and
Shiryaev (1978). This principle is the basis of the fundamental connection
between optimal stopping and variational inequalities. Later in this chapter
we will discuss some aspects of this connection. More information can be
found in Bensoussan and Lions (1978) and Friedman (1976). See also Brekke
and Øksendal (1991).
10.3 Optimal Stopping Problems Involving an Integral
Let
dYt = b(Yt)dt + σ(Yt)dBt ,
Y0 = y
(10.3.1)
be an Itˆo diﬀusion in Rk. Let g: Rk →[0, ∞) be continuous and let f: Rk →
[0, ∞) be Lipschits continuous with at most linear growth. (These conditions
can be relaxed. See (10.1.37) and Theorem 10.4.1.) Consider the optimal
stopping problem: Find G∗(y) and τ ∗such that
G∗(y) = sup
τ Ey
·
τ
Z
0
f(Yt)dt + g(Yτ)
¸
= Ey
· τ ∗
Z
0
f(Yt)dt + g(Yτ ∗)
¸
. (10.3.2)
This problem can be reduced to our original problem (10.1.2)–(10.1.3) by
proceeding as follows: Deﬁne the Itˆo diﬀusion Zt in Rk × R = Rk+1 by
dZt =
·
dYt
dWt
¸
: =
·
b(Yt)
f(Yt)
¸
dt +
·
σ(Yt)
0
¸
dBt ;
Z0 = z = (y, w) .
(10.3.3)
Then we see that
G∗(y) = sup
τ E(y,0)[Wτ + g(Yτ)] = sup
τ E(y,0)[G(Zτ)]
(10.3.4)
with
G(z): = G(y, w): = g(y) + w ;
z = (y, w) ∈Rk × R .
(10.3.5)

10.3 Optimal Stopping Problems Involving an Integral
213
This is again a problem of the type (10.1.2)–(10.1.3) with Xt replaced by Zt
and g replaced by G. Note that the connection between the characteristic
operators AY of Yt and AZ of Zt is given by
AZφ(z) = AZφ(y, w) = AY φ(y, w) + f(y) ∂φ
∂w ,
φ ∈C2(Rk+1) .
(10.3.6)
In particular, if G(y, w) = g(y) + w ∈C2(Rk+1) then
AZG(y, w) = AY g(y) + f(y) .
(10.3.7)
Example 10.3.1. Consider the optimal stopping problem
γ(x) = sup
τ Ex
·
τ
Z
0
θe−ρtXtdt + e−ρτXτ
¸
,
where
dXt = αXtdt + βXtdBt ;
X0 = x > 0
is geometric Brownian motion (α, β, θ constants, θ > 0). We put
dYt =
·
dt
dXt
¸
=
·
1
αXt
¸
dt +
·
0
βXt
¸
dBt ;
Y0 = (s, x)
and
dZt =
·
dYt
dWt
¸
=


1
αXt
e−ρtXt

dt +


0
βXt
0

dBt ;
Z0 = (s, x, w) .
Then with
f(y) = f(s, x) = θe−ρsx ,
g(y) = e−ρsx
and
G(s, x, w) = g(s, x) + w = e−ρsx + w
we have
AZG = ∂G
∂s + αx∂G
∂x + 1
2β2x2 ∂2G
∂x2 + θe−ρsx∂G
∂w = (−ρ + α + θ)e−ρsx .
Hence
U = {(s, x, w); AZG(s, x, w) > 0} =
½
R3
if ρ < α + θ
∅
if ρ ≥α + θ .
From this we conclude (see Exercise 10.6):
If ρ ≥α + θ then τ ∗= 0
and G∗(s, x, w) = G(s, x, w) = e−ρsx + w .
(10.3.8)
If α < ρ < α + θ then τ ∗does not exist
and G∗(s, x, w)=
θx
ρ−αe−ρs+w .
(10.3.9)
If ρ ≤α then τ ∗does not exist and G∗= ∞.
(10.3.10)

214
10. Application to Optimal Stopping
10.4 Connection with Variational Inequalities
The ‘high contact principle’ says, roughly, that – under certain conditions –
the solution g∗of (10.1.2)–(10.1.3) is a C1 function on Rn if g ∈C2(Rn).
This is a useful information which can help us to determine g∗. Indeed, this
principle is so useful that it is frequently applied in the literature also in cases
where its validity has not been rigorously proved.
Fortunately it turns out to be easy to prove a suﬃciency condition of
high contact type, i.e. a kind of veriﬁcation theorem for optimal stopping,
which makes is easy to verify that a given candidate for g∗(that we may have
found by guessing or intuition) is actually equal to g∗. The result below is a
simpliﬁed variant of a result in Brekke and Øksendal (1991):
In the following we ﬁx a domain V in Rk and we let
dYt = b(Yt)dt + σ(Yt)dBt ;
Y0 = y
(10.4.1)
be an Itˆo diﬀusion in Rk. Deﬁne
T = T(y, ω) = inf{t > 0; Yt(ω) /∈V } .
(10.4.2)
Let f: Rk →R, g: Rk →R be continuous functions satisfying
(a) Ey[
T
Z
0
|f(Yt)|dt] < ∞
for all y ∈Rk
(10.4.3)
and
(b) the family {g−(Yτ); τ stopping time, τ ≤T} is uniformly integrable
w.r.t. Ry (the probability law of Yt), for all y ∈Rk.
(10.4.4)
Consider the following problem: Find Φ(y) and τ ∗≤T such that
Φ(y) = sup
τ≤T
Jτ(y) = Jτ ∗(y) ,
(10.4.5)
where
Jτ(y) = Ey
·
τ
Z
0
f(Yt)dt + g(Yτ)
¸
for τ ≤T .
Note that since J0(y) = g(y) we have
Φ(y) ≥g(y)
for all y ∈V .
(10.4.6)
We can now formulate the variational inequalities. As usual we let
L = LY =
k
X
i=1
bi(y) ∂
∂yi
+ 1
2
k
X
i,j=1
(σσT )ij(y)
∂2
∂yi∂yj
be the partial diﬀerential operator which coincides with the generator AY of
Yt on C2
0(Rk).

10.4 Connection with Variational Inequalities
215
Theorem 10.4.1 (Variational inequalities for optimal stopping).
Suppose we can ﬁnd a function φ: V →R such that
(i)
φ ∈C1(V ) ∩C(V )
(ii)
φ ≥g on V and φ = g on ∂V .
Deﬁne
D = {x ∈V ; φ(x) > g(x)} .
Suppose Yt spends 0 time on ∂D a.s., i.e.
(iii)
Ey[
T
Z
0
X∂D(Yt)dt] = 0 for all y ∈V
and suppose that
(iv)
∂D is a Lipschitz surface, i.e. ∂D is locally the graph of a function
h: Rk−1 →R such that there exists K < ∞with
|h(x) −h(y)| ≤K|x −y|
for all x, y .
Moreover, suppose the following:
(v)
φ ∈C2(V \ ∂D) and the second order derivatives of φ are locally
bounded near ∂D
(vi)
Lφ + f ≤0 on V \ D
(vii)
Lφ + f = 0 on D
(viii) τD: = inf{t > 0; Yt /∈D} < ∞a.s. Ry for all y ∈V
and
(ix)
the family {φ(Yτ); τ ≤τD} is uniformly integrable w.r.t. Ry, for all
y ∈V .
Then
φ(y) = Φ(y) = sup
τ≤T
Ey
·
τ
Z
0
f(Yt)dt + g(Yτ)
¸
;
y ∈V
(10.4.7)
and
τ ∗= τD
(10.4.8)
is an optimal stopping time for this problem.
Proof. By (i), (iv) and (v) we can ﬁnd a sequence of functions
φj ∈C2(V ) ∩C(V ), j = 1, 2, . . ., such that
(a)
φj →φ uniformly on compact subsets of V , as j →∞
(b)
Lφj →Lφ uniformly on compact subsets of V \ ∂D, as j →∞
(c)
{Lφj}∞
j=1 is locally bounded on V .
(See Appendix D).
For R > 0 put TR = min(R, inf {t > 0; |Yt| ≥R}) and let τ ≤T be a
stopping time. Let y ∈V . Then by Dynkin’s formula

216
10. Application to Optimal Stopping
Ey[φj(Yτ∧TR)] = φj(y) + Ey
· τ∧TR
Z
0
Lφj(Yt)dt
¸
(10.4.9)
Hence by (a), (b), (c) and (iii) and the Fatou lemma
φ(y) = lim
j→∞Ey
· τ∧TR
Z
0
−Lφj(Yt)dt + φj(Yτ∧TR)
¸
≥Ey
· τ∧TR
Z
0
−Lφ(Yt)dt + φ(Yτ∧TR)
¸
.
(10.4.10)
Therefore, by (ii), (iii), (vi) and (vii),
φ(y) ≥Ey
· τ∧TR
Z
0
f(Yt)dt + g(Yτ∧TR)
¸
.
Hence by the Fatou lemma and (10.4.3), (10.4.4)
φ(y) ≥lim
R→∞
Ey
· τ∧TR
Z
0
f(Yt)dt + g(Yτ∧TR)
¸
≥Ey
·
τ
Z
0
f(Yt)dt + g(Yτ)
¸
.
Since τ ≤T was arbitrary, we conclude that
φ(y) ≥Φ(y)
for all y ∈V .
(10.4.11)
If y /∈D then φ(y) = g(y) ≤Φ(y) so by (10.4.11) we have
φ(y) = Φ(y)
and
bτ = bτ(y, ω): = 0
is optimal for y /∈D .
(10.4.12)
Next, suppose y ∈D. Let {Dk}∞
k=1 be an increasing sequence of open sets Dk
such that Dk ⊂D, Dk is compact and D=
∞
S
k=1
Dk. Put τk =inf{t>0; Yt ̸∈Dk},
k = 1, 2, . . . By Dynkin’s formula we have for y ∈Dk,
φ(y) = lim
j→∞φj(y) = lim
j→∞Ey
· τk∧TR
Z
0
−Lφj(Yt)dt + φj(Yτk∧TR)
¸
= Ey
· τk∧TR
Z
0
−Lφ(Yt)dt + φ(Yτk∧TR)
¸
=Ey
· τk∧TR
Z
0
f(Yt)dt + φ(Yτk∧TR)
¸
So by uniform integrability and (ii), (vii), (viii) we get

10.4 Connection with Variational Inequalities
217
φ(y) =
lim
R,k→∞Ey
· τk∧TR
Z
0
f(Yt)dt + φ(Yτk∧TR)
¸
= Ey
· τD
Z
0
f(Yt)dt + g(YτD)
¸
= JτD(y) ≤Φ(y) .
(10.4.13)
Combining (10.4.11) and (10.4.13) we get
φ(y) ≥Φ(y) ≥JτD(y) = φ(y)
so
φ(y) = Φ(y)
and
bτ(y, ω): = τD
is optimal when y ∈D .
(10.4.14)
From (10.4.12) and (10.4.14) we conclude that
φ(y) = Φ(y)
for all y ∈V .
Moreover, the stopping time bτ deﬁned by
bτ(y, ω) =
½
0
for y /∈D
τD
for y ∈D
is optimal. By Theorem 10.1.12 we conclude that τD is optimal also.
⊔⊓
Example 10.4.2. To illustrate Theorem 10.4.1 let us apply it to reconsider
Example 10.2.2:
Rather than proving (10.2.8) and the following properties of D, we now
simply guess/assume that D has the form
D = {(s, x); 0 < x < x0}
for some x0 > 0, which is intuitively reasonable. Then we solve (10.2.11) for
arbitrary x0 and we arrive at the following candidate φ for g∗:
φ(s, x) =
½ e−ρs(x0 −a)( x
x0 )γ1
for 0 < x < x0
e−ρs(x −a)
for x ≥x0 .
The requirement that φ ∈C1 (Theorem 10.4.1 (i)) gives the value (10.2.13)
for x0. It is clear that φ ∈C2 outside ∂D and by construction Lφ = 0 on
D. Moreover, conditions (iii), (iv), (viii) and (ix) clearly hold. It remains to
verify that
(ii)
φ(s, x)>g(s, x) for 0<x<x0, i.e. φ(s, x)>e−ρs(x −a) for 0<x<x0
and
(v)
Lφ(s, x) ≤0 for x > x0, i.e. Lg(s, x) ≤0 for x > x0.
This is easily done by direct calculation (assuming r < ρ).
We conclude that φ = g∗and τ ∗= τD is optimal (with the value (10.2.13)
for x0).

218
10. Application to Optimal Stopping
Exercises
10.1. In each of the optimal stopping problems below ﬁnd the supremum
g∗and – if it exists – an optimal stopping time τ ∗. (Here Bt denotes
1-dimensional Brownian motion)
a) g∗(x) = sup
τ Ex[B2
τ]
b) g∗(x) = sup
τ Ex[|Bτ|p],
where p > 0.
c) g∗(x) = sup
τ Ex[e−B2
τ ]
d) g∗(s, x) = sup
τ E(s,x)[e−ρ(s+τ)cosh Bτ]
where ρ > 0 and cosh x = 1
2(ex + e−x).
10.2. a) Prove that the only nonnegative (Bt-) superharmonic functions in
R2 are the constants.
(Hint: Suppose u is a nonnegative superharmonic function and that
there exist x, y ∈R2 such that
u(x) < u(y) .
Consider
Ex[u(Bτ)] ,
where τ is the ﬁrst hitting time for Bt of a small disc centered at
y).
b) Prove that the only nonnegative superharmonic functions in R are
the constants and use this to ﬁnd g∗(x) when
g(x) =
½
xe−x
for x > 0
0
for x ≤0 .
c) Let γ ∈R, n ≥3 and deﬁne, for x ∈Rn,
fγ(x) =
½
|x|γ
for |x| ≥1
1
for |x| < 1 .
For what values of γ is fγ(·) (Bt)-) harmonic for |x| > 1 ? Prove
that fγ is superharmonic in Rn iﬀγ ∈[2 −n, 0] .
10.3. Find g∗, τ ∗such that
g∗(s, x) = sup
τ E(s,x)[e−ρ(s+τ)B2
τ] = E(s,x)[e−ρ(s+τ ∗)B2
τ ∗] ,
where Bt is 1-dimensional Brownian motion, ρ > 0 is constant.
Hint: First assume that the continuation region has the form
D = {(s, x); −x0 < x < x0}
for some x0 and then try to determine x0. Then apply Theorem 10.4.1.

Exercises
219
10.4. Let Xt be an Itˆo diﬀusion on Rn and g: Rn →R+ a continuous reward
function. Deﬁne
g⋄(x) = sup{Ex[g(Xτ)] ; τ stopping time, Ex[τ] < ∞} .
Show that g⋄= g∗.
(Hint: If τ is a stopping time put τk = τ ∧k for k = 1, 2, . . . and
consider
Ex[g(Xτ) · Xτ<∞] ≤Ex[ lim
k→∞
g(Xτk)]) .
10.5. With g, r, ρ as in Example 10.2.2 prove that
a) if r > ρ then g∗= ∞,
b) if r = ρ then g∗(s, x) = xe−ρs.
10.6. Prove statements (10.3.8), (10.3.9), (10.3.10) in Example 10.3.1.
10.7. As a supplement to Exercise 10.4 it is worth noting that if g is not
bounded below then the two problems
g∗(x) = sup{Ex[g(Xτ)] ; τ stopping time}
and
g⋄(x) = sup{Ex[g(Xτ)] ; τ stopping time, Ex[τ] < ∞}
need not have the same solution. For example, if g(x)=x, Xt =Bt ∈R
prove that
g∗(x) = ∞
for all x ∈R
while
g⋄(x) = x
for all x ∈R .
(See Exercise 7.4.)
10.8. Give an example with g not bounded below where Theorem 10.1.9 a)
fails. (Hint: See Exercise 10.7.)
10.9. Solve the optimal stopping problem
γ(x) = sup
τ Ex
·
τ
Z
0
e−ρtB2
t dt + e−ρτB2
τ
¸
.
10.10. Prove the following simple, but useful, observation, which can be
regarded as an extension of (10.1.35):
Let W = {(s, x); ∃τ with g(s, x) < E(s,x)[g(s + τ, Xτ)]}.
Then W ⊂D.

220
10. Application to Optimal Stopping
10.11. Consider the optimal stopping problem
g∗(s, x) = sup
τ E(s,x)[e−ρ(s+τ)B+
τ ] ,
where Bt ∈R and x+ = max{x, 0}.
a) Use the argument for (10.2.8) and Exercise 10.10 to prove that the
continuation region D has the form
D = {(s, x); x < x0}
for some x0 > 0.
b) Determine x0 and ﬁnd g∗.
c) Verify the high contact principle:
∂g∗
∂x = ∂g
∂x
when (s, x) = (s, x0) ,
where g(t, x) = e−ρtx+.
10.12. The ﬁrst time the high contact principle was formulated seems to
be in a paper by Samuelson (1965), who studied the optimal time for
selling an asset, if the reward obtained by selling at the time t and
when price is ξ is given by
g(t, ξ) = e−ρt(ξ −1)+ .
The price process is assumed to be a geometric Brownian motion Xt
given by
dXt = rXtdt + αXtdBt ,
X0 = x > 0 ,
where r < ρ.
In other words, the problem is to ﬁnd g∗, τ ∗such that
g∗(s, x) = sup
τ E(s,x)[e−ρ(s+τ)(Xτ−1)+] = E(s,x)[e−ρ(s+τ ∗)(Xτ ∗−1)+] .
a) Use the argument for (10.2.8) and Exercise 10.10 to prove that the
continuation region D has the form
D = {(s, x); 0 < x < x0}
for some x0 >
ρ
ρ−r.
b) For a given x0 >
ρ
ρ−r solve the boundary value problem





∂f
∂s + rx ∂f
∂x + 1
2α2x2 ∂2f
∂x2 = 0
for
0 < x < x0
f(s, 0) = 0
f(s, x0) = e−ρs(x0 −1)+
by trying f(s, x) = e−ρsφ(x).

Exercises
221
c) Determine x0 by using the high contact principle, i.e. by using that
∂f
∂x = ∂g
∂x
when x = x0 .
d) With f, x0 as in b), c) deﬁne
γ(s, x) =
½
f(s, x) ;
x < x0
e−ρs(x −1)+ ;
x ≥x0 .
Use Theorem 10.4.1 to verify that γ = g∗and that τ ∗= τD is
optimal.
10.13. (A resource extraction problem)
Suppose the price Pt of one unit of a resource (e.g. gas, oil) at time t
is varying like a geometric Brownian motion
dPt = αPtdt + βPtdBt ;
P0 = p
where Bt is 1-dimensional Brownian motion and α, β are constants.
Let Qt denote the amount of remaining resources at time t. Assume
that the rate of extraction is proportional to the remaining amount,
so that
dQt = −λQtdt ;
Q0 = q
where λ > 0 is a constant.
If the running cost rate is K > 0 and we stop the extraction at the
time τ = τ(ω) then the expected total discounted proﬁt is given by
Jτ(s, p, q) = E(s,p,q)
·
τ
Z
0
(λPtQt −K)e−ρ(s+t)dt + e−ρ(s+τ)g(Pτ, Qτ)
¸
,
where ρ > 0 is the discounting exponent and g(p, q) is a given bequest
function giving the value of the remaining resource amount q when the
price is p.
a) Write down the characteristic operator A of the diﬀusion process
dXt =


dt
dPt
dQt

;
X0 = (s, p, q)
and formulate the variational inequalities of Theorem 10.4.1 corre-
sponding to the optimal stopping problem
G∗(s, p, q) = sup
τ Jτ(s, p, q) = Jτ ∗(s, p, q) .

222
10. Application to Optimal Stopping
b) Assume that g(p, q) = pq and ﬁnd the domain U corresponding to
(10.1.34), (10.3.7), i.e.
U = {(s, p, q); A(e−ρsg(p, q)) + f(s, p, q) > 0} ,
where
f(s, p, q) = e−ρs(λpq −K) .
Conclude that
(i)
if ρ ≥α then τ ∗= 0 and G∗(s, p, q) = pqe−ρs
(ii)
if ρ < α then D ⊃{(s, p, q); pq >
K
α−ρ}.
c) As a candidate for G∗when ρ < α we try a function of the form
φ(s, p, q) =
½
e−ρspq ;
0 < pq ≤y0
e−ρsψ(pq) ;
pq > y0
for a suitable ψ: R →R, and a suitable y0. Use Theorem 10.4.1 to
determine ψ, y0 and to verify that with this choice of ψ, y0 we have
φ = G∗and τ ∗= inf{t > 0; PtQt ≤y0}, if ρ < α < ρ + λ.
d) What happens if ρ + λ ≤α ?
10.14. (Finding the optimal investment time (I))
Solve the optimal stopping problem
G∗(s, p) = sup
τ E(s,p)
· Z ∞
τ
e−ρ(s+t)Ptdt −Ce−ρ(s+τ)
¸
,
where
dPt = αPtdt + βPtdBt ;
P0 = p ,
Bt is 1-dimensional Brownian motion and α, β, ρ, C are constants,
0 < α < ρ and C > 0. (We may interprete this as the problem of
ﬁnding the optimal time τ for investment in a project. The proﬁt rate
after investment is Pt and the cost of the investment is C. Thus G∗
gives the maximal expected discounted net proﬁt.)
Hint: Write
∞
R
τ
e−ρ(s+t)Ptdt = e−ρs[
∞
R
0
e−ρtPtdt −
τR
0
e−ρtPtdt]. Compute
E[
∞
R
0
e−ρtPtdt] by using the solution formula for Pt (see Chapter 5) and
then apply Theorem 10.4.1 to the problem
Φ(s, p) = sup
τ E(s,p)
·
−
τ
Z
0
e−ρ(s+t)Ptdt −Ce−ρ(s+τ)
¸
.
10.15. Let Bt be 1-dimensional Brownian motion and let ρ > 0 be constant.

Exercises
223
a) Show that the family
{e−ρτBτ; τ stopping time}
is uniformly integrable w.r.t. P x.
b) Solve the optimal stopping problem
g∗(s, x) = sup
τ E(s,x)[e−ρ(s+τ)(Bτ −a)]
when a > 0 is constant. This may be regarded as a variation of
Example 10.2.2/10.4.2 with the price process represented by Bt
rather than Xt.
10.16. (Finding the optimal investment time (II))
Solve the optimal stopping problem
G∗(s, p) = sup
τ E(s,p)
· ∞
Z
τ
e−ρ(s+t)Ptdt −Ce−ρ(s+τ)
¸
where
dPt = µ dt + σ dBt ;
P0 = p
with µ, σ ̸= 0 constants. (Compare with Exercise 10.14.)

224
10. Application to Optimal Stopping

11. Application to Stochastic Control
11.1 Statement of the Problem
Suppose that the state of a system at time t is described by an Itˆo process
Xt of the form
dXt = dXu
t = b(t, Xt, ut)dt + σ(t, Xt, ut)dBt ,
(11.1.1)
where Xt ∈Rn, b: R × Rn × U →Rn, σ: R × Rn × U →Rn×m and Bt is m-
dimensional Brownian motion. Here ut ∈U ⊂Rk is a parameter whose value
we can choose in the given Borel set U at any instant t in order to control
the process Xt. Thus ut = u(t, ω) is a stochastic process. Since our decision
at time t must be based upon what has happened up to time t, the function
ω →u(t, ω) must (at least) be measurable w.r.t. F(m)
t
, i.e. the process ut
must be F(m)
t
-adapted. Thus the right hand side of (11.1.1) is well-deﬁned as
a stochastic integral, under suitable assumptions on the functions b and σ. At
the moment we will not specify the conditions on b and σ further, but simply
assume that the process Xt satisfying (11.1.1) exists. See further comments
on this in the end of this chapter.
Let {Xs,x
h }h≥s be the solution of (11.1.1) such that Xs,x
s
= x, i.e.
Xs,x
h
= x +
h
Z
s
b(r, Xs,x
r
, ur)dr +
h
Z
s
σ(r, Xs,x
r
, ur)dBr ;
h ≥s
and let the probability law of Xt starting at x for t = s be denoted by Qs,x,
so that
Qs,x[Xt1 ∈F1, . . . , Xtk ∈Fk] = P 0[Xs,x
t1
∈F1, . . . , Xs,x
tk ∈Fk]
(11.1.2)
for s ≤ti, Fi ⊂Rn; 1 ≤i ≤k, k = 1, 2, . . .
Let F: R×Rn×U →R (the “utility rate” function) and K: R×Rn →R
(the “bequest” function) be given continuous functions, let G be a ﬁxed
domain in R × Rn and let bT be the ﬁrst exit time after s from G for the
process {Xs,x
r
}r≥s, i.e.
bT = bT s,x(ω) = inf{r > s; (r, Xs,x
r
(ω)) /∈G} ≤∞.
(11.1.3)

226
11. Application to Stochastic Control
Suppose
Es,x
· b
T
Z
s
|F ur(r, Xr)|dr+|K( bT, Xb
T )|X{b
T <∞}
¸
< ∞
for all s, x, u (11.1.4)
where F u(r, z) = F(r, z, u). Then we deﬁne the performance function Ju(s, x)
by
Ju(s, x) = Es,x
· b
T
Z
s
F ur(r, Xr)dr + K( bT, Xb
T )X{b
T <∞}
¸
.
(11.1.5)
To obtain an easier notation we introduce
Yt = (s + t, Xs,x
s+t)
for t ≥0, Y0 = (s, x)
and we observe that if we substitute this in (11.1.1) we get the equation
dYt = dY u
t = b(Yt, ut)dt + σ(Yt, ut)dBt .
(11.1.6)
(Strictly speaking, the u, b and σ in (11.1.6) are slightly diﬀerent from the
u, b and σ in (11.1.1).) The probability law of Yt starting at y = (s, x) for
t = 0 is (with slight abuse of notation) also denoted by Qs,x = Qy.
Note that
b
T
Z
s
F ur(r, Xr)dr =
b
T −s
Z
0
F us+t(s + t, Xs+t)dt =
T
Z
0
F us+t(Yt)dt ,
where
T: = inf{t > 0; Yt /∈G} = bT −s .
(11.1.7)
Moreover,
K( bT, Xb
T ) = K(Yb
T −s) = K(YT ) .
Therefore the performance function may be written in terms of Y as follows,
with y = (s, x),
Ju(y) = Ey
·
T
Z
0
F ut(Yt)dt + K(YT )X{T <∞}
¸
.
(11.1.8)
(Strictly speaking this ut is a time shift of the ut in (11.1.6).)
The problem is – for each y ∈G – to ﬁnd the number Φ(y) and a control
u∗= u∗(t, ω) = u∗(y, t, ω) such that
Φ(y): = sup
u(t,ω)
Ju(y) = Ju∗(y)
(11.1.9)

11.2 The Hamilton-Jacobi-Bellman Equation
227
where the supremum is taken over all F(m)
t
-adapted processes {ut} with
values in U. Such a control u∗– if it exists – is called an optimal control and
Φ is called the optimal performance or the value function. Examples of types
of control functions that may be considered are:
(1) Functions of the form u(t, ω) = u(t) i.e. not depending on ω. These
controls are sometimes called deterministic or open loop controls.
(2) Processes {ut} which are Mt-adapted, i.e. for each t the function ω →
u(t, ω) is Mt-measurable, where Mt is the σ-algebra generated by
{Xu
r ; r ≤t}. These controls are called closed loop or feedback controls.
(3) The controller has only partial knowledge of the state of the system. More
precisely, to the controller’s disposal are only (noisy) observations Rt of
Xt, given by an Itˆo process of the form
dRt = a(t, Xt)dt + γ(t, Xt)d bBt ,
where bB is a Brownian motion (not necessarily related to B). Hence the
control process {ut} must be adapted w.r.t. the σ-algebra Nt generated
by {Rs; s ≤t}. In this situation the stochastic control problem is linked
to the ﬁltering problem (Chapter 6). In fact, if the equation (11.1.1)
is linear and the performance function is integral quadratic (i.e. F and
K are quadratic) then the stochastic control problem splits into a linear
ﬁltering problem and a corresponding deterministic control problem. This
is called the Separation Principle. See Example 11.2.4.
(4) Functions u(t, ω) of the form u(t, ω) = u0(t, Xt(ω)) for some function
u0: Rn+1 →U ⊂Rk. In this case we assume that u does not depend
on the starting point y = (s, x): The value we choose at time t only
depends on the state of the system at this time. These are called Markov
controls, because with such u the corresponding process Xt becomes an
Itˆo diﬀusion, in particular a Markov process. In the following we will not
distinguish between u and u0. Thus we will identify a function
u: Rn+1 →U with the Markov control u(Y ) = u(t, Xt) and simply call
such functions Markov controls.
11.2 The Hamilton-Jacobi-Bellman Equation
Let us ﬁrst consider only Markov controls
u = u(t, Xt(ω)) .
Introducing Yt = (s + t, Xs+t) (as explained earlier) the system equation
becomes
dYt = b(Yt, u(Yt))dt + σ(Yt, u(Yt))dBt .
(11.2.1)
For v ∈U and f ∈C2
0(R × Rn) deﬁne

228
11. Application to Stochastic Control
(Lvf)(y) = ∂f
∂s (y) +
n
X
i=1
bi(y, v) ∂f
∂xi
+
n
X
i,j=1
aij(y, v)
∂2f
∂xi∂xj
(11.2.2)
where aij = 1
2(σσT )ij, y = (s, x) and x = (x1, . . . , xn). Then for each choice
of the function u the solution Yt = Y u
t
is an Itˆo diﬀusion with generator A
given by
(Af)(y) = (Lu(y)f)(y)
for f ∈C2
0(R × Rn) (see Theorem 7.3.3) .
For v ∈U deﬁne F v(y) = F(y, v). The ﬁrst fundamental result in stochastic
control theory is the following:
Theorem 11.2.1 (The Hamilton-Jacobi-Bellman (HJB) equation (I)).
Deﬁne
Φ(y) = sup{Ju(y); u = u(Y ) Markov control} .
Suppose that Φ ∈C2(G) ∩C(G ) satisﬁes
Ey
·
|Φ(Yα)| +
α
Z
0
|LvΦ(Yt)|dt
¸
< ∞
for all bounded stopping times α ≤T, all y ∈G and all v ∈U. Moreover,
suppose that T < ∞a.s. Qy for all y ∈G and that an optimal Markov control
u∗exists. Suppose ∂G is regular for Y u∗
t
(Deﬁnition 9.2.8). Then
sup
v∈U
{F v(y) + (LvΦ)(y)} = 0
for all y ∈G
(11.2.3)
and
Φ(y) = K(y)
for all y ∈∂G .
(11.2.4)
The supremum in (11.2.3) is obtained if v = u∗(y) where u∗(y) is optimal.
In other words,
F(y, u∗(y)) + (Lu∗(y)Φ)(y) = 0
for all y ∈G .
(11.2.5)
Proof. The last two statements are easy to prove: Since u∗= u∗(y) is optimal
we have
Φ(y) = Ju∗(y) = Ey
·
T
Z
0
F(Ys, u∗(Ys))ds + K(YT )
¸
.
If y ∈∂G then T = 0 a.s. Qy (since ∂G is regular) and (11.2.4) follows. By
the solution of the Dirichlet-Poisson problem (Theorem 9.3.3)
(Lu∗(y)Φ)(y) = −F(y, u∗(y))
for all y ∈G ,

11.2 The Hamilton-Jacobi-Bellman Equation
229
which is (11.2.5). We proceed to prove (11.2.3). Fix y = (s, x) ∈G and choose
a Markov control u. Let α ≤T be a stopping time.
Since
Ju(y) = Ey
·
T
Z
0
F u(Yr)dr + K(YT )
¸
,
we get by the strong Markov property (7.2.5), combined with (7.2.6) and
(9.3.7)
Ey[Ju(Yα)] = Eyh
EYα
·
T
Z
0
F u(Yr)dr + K(YT )
¸i
= Eyh
Eyh
θα
µ
T
Z
0
F u(Yr)dr + K(YT )
¶¯¯¯Fα
ii
= Eyh
Ey
·
T
Z
α
F u(Yr)dr + K(YT )|Fα
¸i
= Ey
·
T
Z
0
F u(Yr)dr + K(YT ) −
α
Z
0
F u(Yr)dr
¸
= Ju(y) −Ey
·
α
Z
0
F u(Yr)dr
¸
.
So
Ju(y) = Ey
·
α
Z
0
F u(Yr)dr
¸
+ Ey[Ju(Yα)] .
(11.2.6)
Now let W ⊂G be of the form W = {(r, z) ∈G; r < t1} where s < t1. Put
α = inf{t ≥0; Yt ̸∈W}. Suppose an optimal control u∗(y) = u∗(r, z) exists
and choose
u(r, z) =
½
v
if (r, z) ∈W
u∗(r, z)
if (r, z) ∈G \ W
where v ∈U is arbitrary. Then
Φ(Yα) = Ju∗(Yα) = Ju(Yα)
(11.2.7)

230
11. Application to Stochastic Control
and therefore, combining (11.2.6) and (11.2.7) we obtain
Φ(y) ≥Ju(y) = Ey
·
α
Z
0
F v(Yr)dr
¸
+ Ey[Φ(Yα)] .
(11.2.8)
Since Φ ∈C2(G) we get by Dynkin’s formula
Ey[Φ(Yα)] = Φ(y) + Ey
·
α
Z
0
(LuΦ)(Yr)dr
¸
,
which substituted in (11.2.8) gives
Φ(y) ≥Ey
·
α
Z
0
F v(Yr)dr
¸
+ Φ(y) + Ey
·
α
Z
0
(LvΦ)(Yr)dr
¸
or
Ey
·
α
Z
0
(F v(Yr) + (LvΦ)(Yr))dr
¸
≤0 .
So
Ey£ αR
0
(F v(Yr) + (LvΦ)(Yr))dr
¤
Ey[α]
≤0
for all such W .
Letting t1 ↓s we obtain, since F v(·) and (LvΦ)(·) are continuous at y, that
F v(y) + (LvΦ)(y) ≤0, which combined with (11.2.5) gives (11.2.3). That
completes the proof.
⊔⊓
Remark. The HJB (I) equation states that if an optimal control u∗exists,
then we know that its value v at the point y is a point v where the function
v →F v(y) + (LvΦ)(y) ;
v ∈U

11.2 The Hamilton-Jacobi-Bellman Equation
231
attains its maximum (and this maximum is 0). Thus the original stochastic
control problem is associated to the easier problem of ﬁnding the maximum
of a real function in U ⊂Rk. However, the HJB (I) equation only states that
it is necessary that v = u∗(y) is the maximum of this function. It is just as
important to know if this is also suﬃcient: If at each point y we have found
v = u0(y) such that F v(y) + (LvΦ)(y) is maximal and this maximum is 0,
will u0(Y ) be an optimal control? The next result states that (under some
conditions) this is actually the case:
Theorem 11.2.2 (The HJB (II) equation – a converse of HJB (I)).
Let φ be a function in C2(G) ∩C(G ) such that, for all v ∈U,
F v(y) + (Lvφ)(y) ≤0 ;
y ∈G
(11.2.9)
with boundary values
lim
t→T φ(Yt) = K(YT ) · X{T <∞}
a.s. Qy
(11.2.10)
and such that
{φ(Yτ)}τ≤T
is uniformly Qy-integrable for all Markov
controls u and all y ∈G .
(11.2.11)
Then
φ(y) ≥Ju(y)
for all Markov controls u and all y ∈G .
(11.2.12)
Moreover, if for each y ∈G we have found u0(y) such that
F u0(y)(y) + (Lu0(y)φ)(y) = 0
(11.2.13)
then u0 = u0(y) is a Markov control such that
φ(y) = Ju0(y)
and hence u0 must be an optimal control and φ(y) = Φ(y).
Proof. Assume that φ satisﬁes (11.2.9) and (11.2.10) above. Let u be a
Markov control. Since Luφ ≤−F u in G we have by Dynkin’s formula
Ey[φ(YTR)] = φ(y) + Ey
· TR
Z
0
(Luφ)(Yr)dr
¸
≤φ(y) −Ey
· TR
Z
0
F u(Yr)dr
¸

232
11. Application to Stochastic Control
where
TR = min{R, T, inf{t > 0; |Yt| ≥R}}
(11.2.14)
for all R < ∞. This gives, by (11.1.4), (11.2.10) and (11.2.11)
φ(y) ≥Ey
· TR
Z
0
F u(Yr)dr + φ(YTR)
¸
→Ey
·
T
Z
0
F u(Yr)dr + K(YT )X{T <∞}
¸
= Ju(y)
as R →∞, which proves (11.2.12). If u0 is such that (11.2.13) holds, then
the calculations above give equality and the proof is complete.
⊔⊓
The HJB equations (I), (II) provide a very nice solution to the stochastic
control problem in the case where only Markov controls are considered. One
might feel that considering only Markov controls is too restrictive, but for-
tunately one can always obtain as good performance with a Markov control
as with an arbitrary F(m)
t
-adapted control, at least if some extra conditions
are satisﬁed:
Theorem 11.2.3. Let
ΦM(y) = sup{Ju(y); u = u(Y ) Markov control}
and
Φa(y) = sup{Ju(y); u = u(t, ω) F(m)
t
-adapted control} .
Suppose there exists an optimal Markov control u0 = u0(Y ) for the Markov
control problem (i.e. ΦM(y) = Ju0(y) for all y ∈G) such that all the boundary
points of G are regular w.r.t. Y u0
t
and that ΦM is a function in C2(G)∩C(G )
satisfying
Ey
·
|ΦM(Yα)| +
α
Z
0
|LuΦM(Yt)|dt
¸
< ∞
(11.2.15)
for all bounded stopping times α ≤T, all adapted controls u and all y ∈G.
Then
ΦM(y) = Φa(y)
for all y ∈G .
Proof. Let φ be a function in C2(G) ∩C(G ) satisfying (11.2.15) and
F v(y) + (Lvφ)(y) ≤0
for all y ∈G, v ∈U
(11.2.16)
and
φ(y) = K(y)
for all y ∈∂G .
(11.2.17)

11.2 The Hamilton-Jacobi-Bellman Equation
233
Let ut(ω) = u(t, ω) be an F(m)
t
-adapted control. Then Yt is an Itˆo process
given by
dYt = b(Yt, ut)dt + σ(Yt, ut)dBt
so by Lemma 7.3.2, with TR as in (11.2.14),
Ey[φ(YTR)] = φ(y) + Ey
· TR
Z
0
(Lu(t,ω)φ)(Yt)dt
¸
,
where
(Lu(t,ω)φ)(y) =
= ∂φ
∂t (y) +
n
X
i=1
bi(y, u(t, ω)) ∂φ
∂xi
(y) +
n
X
i,j=1
aij(y, u(t, ω))
∂2φ
∂xi∂xj
(y) ,
with aij = 1
2(σσT )ij. Thus by (11.2.16) and (11.2.17) this gives
Ey[φ(YTR)] ≤φ(y) −Ey
· TR
Z
0
F(Yt, u(t, ω))dt
¸
.
(11.2.18)
Letting R →∞we obtain
φ(y) ≥Ju(y) .
(11.2.19)
But by Theorem 11.2.1 the function φ(y) = ΦM(y) satisﬁes (11.2.16) and
(11.2.17). So by (11.2.19) we have ΦM(y) ≥Φa(y) and Theorem 11.2.3 fol-
lows.
⊔⊓
Remark.
The theory above also applies to the corresponding minimum
problem
Ψ(y) = inf
u Ju(y) = Ju∗(y) .
(11.2.20)
To see the connection we note that
Ψ(y) = −sup
u {−Ju(y)} = −sup
u
n
Ey
·
T
Z
0
−F u(Yt)dt −K(Yt)
¸o
so −Ψ coincides with the solution Φ of the problem (11.1.9), but with F
replaced by −F and K replaced by −K. Using this, we see that the HJB
equations apply to Ψ also but with reverse inequalities. For example, equation
(11.2.3) for Φ gets for Ψ the form
inf
v∈U{F v(y) + (LvΨ)(y)} = 0
for all y ∈G .
(11.2.21)
We now illustrate the results by some examples:

234
11. Application to Stochastic Control
Example 11.2.4 (The linear stochastic regulator problem).
Suppose that the state Xt of the system at time t is given by a linear stochastic
diﬀerential equation:
dXt = (HtXt + Mtut)dt + σtdBt ,
t ≥s ; Xs = x
(11.2.22)
and the cost is of the form
Ju(s, x) = Es,x
· t1
Z
s
{XT
t CtXt + uT
t Dtut}dt + XT
t1RXt1
¸
,
s ≤t1
(11.2.23)
where all the coeﬃcients Ht ∈Rn×n, Mt ∈Rn×k, σt ∈Rn×m, Ct ∈Rn×n,
Dt ∈Rk×k and R ∈Rn×n are t-continuous and deterministic. We assume
that Ct and R are symmetric, nonnegative deﬁnite and Dt is symmetric,
positive deﬁnite, for all t. We also assume that t1 is a deterministic time.
The problem is then to choose the control u = u(t, Xt) ∈Rk such that
it minimizes Ju(s, x). We may interpret this as follows: The aim is to ﬁnd a
control u which makes |Xt| small fast and such that the energy used
(∼uT Du) is small. The sizes of Ct and R reﬂect the cost of having large
values of |Xt|, while the size of Dt reﬂects the cost (energy) of applying large
values of |ut|.
In this case the HJB-equation for Ψ(s, x) = inf
u Ju(s, x) becomes
0 = inf
v {F v(s, x) + (LvΨ)(s, x)}
= ∂Ψ
∂s + inf
v
½
xT Csx + vT Dsv +
n
X
i=1
(Hsx + Msv)i
∂Ψ
∂xi
+ 1
2
n
X
i,j=1
(σsσT
s )ij
∂2Ψ
∂xi∂xj
¾
for s < t1
(11.2.24)
and
Ψ(t1, x) = xT Rx .
(11.2.25)
Let us try to ﬁnd a solution ψ of (11.2.24)–(11.2.25) of the form
ψ(t, x) = xT Stx + at
(11.2.26)
where S(t) = St ∈Rn×n is symmetric, nonnegative deﬁnite, at ∈R and
both at and St are continuously diﬀerentiable w.r.t. t (and deterministic). In
order to use Theorem 11.2.2 we need to determine St and at such that
inf
v {F v(t, x) + (Lvψ)(t, x)} = 0
for t < t1
(11.2.27)
and
ψ(t1, x) = xT Rx .
(11.2.28)

11.2 The Hamilton-Jacobi-Bellman Equation
235
To obtain (11.2.28) we put
St1 = R
(11.2.29)
at1 = 0 .
(11.2.30)
Using (11.2.26) we get
F v(t, x) + (Lvψ)(t, x) = xT S′
tx + a′
t + xT Ctx + vT Dtv +
+(Htx + Mtv)T (Stx + ST
t x) +
X
i,j
(σtσT
t )ijSij ,
(11.2.31)
where S′
t =
d
dtSt, a′
t =
d
dtat. The minimum of this expression is obtained
when
∂
∂vi
(F v(t, x) + (Lvψ)(t, x)) = 0 ;
i = 1, . . . , k
i.e. when
2Dtv + 2M T
t Stx = 0
i.e. when
v = −D−1
t M T
t Stx .
(11.2.32)
We substitute this value of v in (11.2.31) and obtain
F v(t, x) + (Lvψ)(t, x) =
= xT S′
tx + a′
t + xT Ctx + xT StMtD−1
t DtD−1
t M T
t Stx
+(Htx −MtD−1
t M T
t Stx)T 2Stx + tr(σσT S)t
= xT (S′
t + Ct −StMtD−1
t M T
t St + 2HT
t St)x + a′
t + tr(σσT S)t ,
where tr denotes the (matrix) trace. We obtain that this is 0 if we choose St
such that
S′
t = −2HT
t St + StMtD−1
t M T
t St −Ct ;
t < t1
(11.2.33)
and at such that
a′
t = −tr(σσT S)t ;
t < t1 .
(11.2.34)
We recognize (11.2.33) as a Riccati type equation from linear ﬁltering the-
ory (see (6.3.4)). Equation (11.2.33) with boundary condition (11.2.29) de-
termines St uniquely. Combining (11.2.34) with the boundary condition
(11.2.30) we obtain
at =
t1
Z
t
tr(σσT S)sds .
(11.2.35)
With such a choice of St and at we see that (11.2.27) and (11.2.28) hold, so
by Theorem 11.2.2 we conclude that
u∗(t, x) = −D−1
t M T
t Stx ,
t < t1
(11.2.36)

236
11. Application to Stochastic Control
is an optimal control and the minimum cost is
Ψ(s, x) = xT Ssx +
t1
Z
s
tr(σσT S)tdt ,
s < t1 .
(11.2.37)
This formula shows that the extra cost due to the noise in the system is given
by
as =
t1
Z
s
tr(σσT S)tdt .
The Separation Principle (see Davis (1977), Davis and Vinter (1985) or Flem-
ing and Rishel (1975)) states that if we had only partial knowledge of the
state Xt of the system, i.e. if we only had noisy observations
dZt = gtXtdt + γtd eBt
(11.2.38)
to our disposal, then the optimal control u∗(t, ω) (required to be Gt-adapted,
where Gt is the σ-algebra generated by {Zr; r ≤t}), would be given by
u∗(t, ω) = −D−1
t M T
t St b
Xt(ω) ,
(11.2.39)
where b
Xt is the ﬁltered estimate of Xt based on the observations {Zr; r ≤t},
given by the Kalman-Bucy ﬁlter (6.3.3). Comparing with (11.2.36) we see
that the stochastic control problem in this case splits into a linear ﬁltering
problem and a deterministic control problem.
An important ﬁeld of applications of the stochastic control theory is eco-
nomics and ﬁnance. Therefore we illustrate the results above by applying
them to a simple case of optimal portfolio diversiﬁcation. This problem has
been considered in more general settings by many authors, see for example
Markowitz (1976), Merton (1971), Harrison and Pliska (1981), Aase (1984),
Karatzas, Lehoczky and Shreve (1987) and the survey article Duﬃe (1994)
and the references therein.
Example 11.2.5 (An optimal portfolio selection problem).
Let Xt denote the wealth of a person at time t. Suppose that the person has
the choice of two diﬀerent investments. The price p1(t) at time t of one of
the assets is assumed to satisfy the equation
dp1
dt = p1(a + αWt)
(11.2.40)
where Wt denotes white noise and a, α > 0 are constants measuring the
average relative rate of change of p and the size of the noise, respectively.
As we have discussed earlier we interpret (11.2.40) as the (Itˆo) stochastic
diﬀerential equation

11.2 The Hamilton-Jacobi-Bellman Equation
237
dp1 = p1adt + p1αdBt .
(11.2.41)
This investment is called risky, since α > 0. We assume that the price p2 of
the other asset satisﬁes a similar equation, but with no noise:
dp2 = p2bdt .
(11.2.42)
This investment is called safe. So it is natural to assume b < a. At each
instant the person can choose how big fraction u of his wealth he will invest
in the risky asset, thereby investing the fraction 1 −u in the safe one. This
gives the following stochastic diﬀerential equation for the wealth Xt = Xu
t :
dXt = uXtadt + uXtαdBt + (1 −u)Xtbdt
= Xt(au + b(1 −u))dt + αuXtdBt .
(11.2.43)
Suppose that, starting with the wealth Xt = x > 0 at time t, the person
wants to maximize the expected utility of the wealth at some future time
t0 > t. If we allow no borrowing (i.e. require X ≥0) and are given a utility
function N: [0, ∞) →[0, ∞), N(0) = 0 (usually assumed to be increasing and
concave) the problem is to ﬁnd Φ(s, x) and a (Markov) control u∗= u∗(t, Xt),
0 ≤u∗≤1, such that
Φ(s, x) = sup{Ju(s, x); u Markov control, 0 ≤u ≤1} = Ju∗(s, x) ,
where Ju(s, x) = Es,x[N(Xu
T )]
(11.2.44)
and T is the ﬁrst exit time from the region G = {(r, z); r < t0, z > 0}. This is
a performance criterion of the form (11.1.6)/(11.1.8) with F = 0 and K = N.
The diﬀerential operator Lv has the form (see (11.2.2))
(Lvf)(t, x) = ∂f
∂t + x(av + b(1 −v))∂f
∂x + 1
2α2v2x2 ∂2f
∂x2 .
(11.2.45)
The HJB equation becomes
sup
v {(LvΦ)(t, x)} = 0 ,
for (t, x) ∈G ;
(11.2.46)
and
Φ(t, x) = N(x)
for t = t0 ,
Φ(t, 0) = N(0)
for t < t0 .
(11.2.47)
Therefore, for each (t, x) we try to ﬁnd the value v = u(t, x) which maximizes
the function
η(v) = LvΦ = ∂Φ
∂t + x(b + (a −b)v)∂Φ
∂x + 1
2α2v2x2 ∂2Φ
∂x2 .
(11.2.48)
If Φx: = ∂Φ
∂x > 0 and Φxx: = ∂2Φ
∂x2 < 0, the solution is

238
11. Application to Stochastic Control
v = u(t, x) = −(a −b)Φx
xα2Φxx
.
(11.2.49)
If we substitute this into the HJB equation (11.2.48) we get the following
nonlinear boundary value problem for Φ :
Φt + bxΦx −(a −b)2Φ2
x
2α2Φxx
= 0
for t < t0, x > 0
(11.2.50)
Φ(t, x) = N(x)
for t = t0 or x = 0 .
(11.2.51)
The problem (11.2.50), (11.2.51) is hard to solve for general N. Important
examples of increasing and concave functions are the power functions
N(x) = xr
where 0 < r < 1 .
(11.2.52)
If we choose such a utility function N, we try to ﬁnd a solution of (11.2.50),
(11.2.51) of the form
φ(t, x) = f(t)xr .
Substituting we obtain
φ(t, x) = eλ(t0−t)xr ,
(11.2.53)
where λ = br +
(a−b)2r
2α2(1−r) .
Using (11.2.49) we obtain the optimal control
u∗(t, x) =
a −b
α2(1 −r) .
(11.2.54)
If
a−b
α2(1−r) ∈(0, 1) this is the solution to the problem, in virtue of Theo-
rem 11.2.2. Note that u∗is in fact constant.
Another interesting choice of the utility function is N(x) = log x, called
the Kelly criterion. As noted by Aase (1984) (in a more general setting)
we may in this case obtain the optimal control directly by evaluating
Es,x[log(XT )] using Dynkin’s formula:
Es,x[log(XT )] =
= log x + Es,x
·
T
Z
s
{au(t, Xt) + b(1 −u(t, Xt)) −1
2α2u2(t, Xt)}dt
¸
since Lv(log x) = av + b(1 −v) −1
2α2v2.
So it is clear that Ju(s, x) = Es,x[log(XT )] is maximal if we for all r, z
choose u(s, z) to have the value of v which maximizes
av + b(1 −v) −1
2α2v2
i.e. we choose

11.2 The Hamilton-Jacobi-Bellman Equation
239
v = u(t, Xt) = a −b
α2
for all t, ω .
(11.2.55)
So this is the optimal control if the Kelly criterion is used. Similarly, this
direct method also gives the optimal control when N(x) = xr (See Exer-
cise 11.8).
Example 11.2.6. Finally we include an example which shows that even
quite simple – and apparently innocent – stochastic control problems can
lead us beyond the reach of the theory developed in this chapter:
Suppose the system is a 1-dimensional Itˆo integral
dXt = dXu
t = u(t, ω)dBt ,
t ≥s; Xs = x > 0
(11.2.56)
and consider the stochastic control problem
Φ(t, x) = sup
u Et,x[K(Xu
τ )] ,
(11.2.57)
where τ is the ﬁrst exit time from G = {(r, z); r ≤t1, z > 0} for Yt =
(s + t, Xs,x
s+t) and K is a given bounded continuous function.
Intuitively, we can think of the system as the state of a game which
behaves like an “excited” Brownian motion, where we can control the size u
of the excitation at every instant. The purpose of the control is to maximize
the expected payoﬀK(Xt1) of the game at a ﬁxed future time t1.
Assuming that Φ ∈C2 and that u∗exists we get by the HJB (I) equation
sup
v∈R
½∂Φ
∂t + 1
2v2 ∂2Φ
∂x2
¾
= 0
for t < t1, Φ(t1, x) = K(x) .
(11.2.58)
From this we see that we necessarily have

240
11. Application to Stochastic Control
∂2Φ
∂x2 ≤0 ,
v∗∂2Φ
∂x2 = 0
and
∂Φ
∂t = 0
for t < t1 ,
(11.2.59)
where v∗is the value of v ∈R which gives the supremum in (11.2.58). But
if ∂Φ
∂t = 0, then Φ(t, x) = Φ(t1, x) = K(x). However, this cannot possibly be
the solution in general, because we have not assumed that ∂2K
∂x2 ≤0 – in fact,
K was not even assumed to be diﬀerentiable.
What went wrong? Since the conclusion of the HJB (I) equation was
wrong, the assumptions cannot hold. So either Φ is not C2 or u∗does not
exist, or both.
To simplify the problem assume that
K(x) =
½
x2 ;
0 ≤x ≤1
1
;
x > 1 .
Then considering the ﬁgure above and using some intuition we see that it
is optimal to excite as much as possible if Xt is in the strip 0 < x < 1 to
avoid exiting from G in the interval {t1}×(0, 1). Using that Xt is just a time
change of Brownian motion (see Chapter 8) we conclude that this optimal
control leads to a process X∗which jumps immediately to the value 1 with
probability x and to the value 0 with probability 1 −x, if the starting point
is x ∈(0, 1). If the starting point is x ∈[1, ∞) we simply choose our control
to be zero. In other words, heuristically we should have
u∗(t, x) =
½
∞
if
x ∈(0, 1)
0
if
x ∈[1, ∞)
(11.2.60)
with corresponding expected payoﬀ
φ∗(s, x) = Es,x[K(X∗
t1)] =
½
x
if
0 ≤x ≤1
1
if
x > 1 .
(11.2.61)
Thus we see that our candidate u∗for optimal control is not continuous
(not even ﬁnite!) and the corresponding optimal process X∗
t is not an Itˆo
diﬀusion (it is not even continuous). So to handle this case mathematically
it is necessary to enlarge the family of admissible controls (and the family of
corresponding processes). For example, one can prove an extended version of
Theorem 11.2.2 which allows us to conclude that our choice of u∗above does
indeed give at least as good performance as any other Markov control u and
that φ∗given by (11.2.61) does coincide with the maximal expected payoﬀΦ
deﬁned by (11.2.57).
This last example illustrates the importance of the question of existence
in general, both of the optimal control u∗and of the corresponding solution
Xt of the stochastic diﬀerential equation (11.1.1). We brieﬂy outline some
results in this direction:

11.3 Stochastic control problems with terminal conditions
241
With certain conditions on b, σ, F, ∂G and assuming that the set of control
values is compact, one can show, using general results from nonlinear partial
diﬀerential equations, that a smooth function φ exists such that
sup
v {F v(y) + (Lvφ)(y)} = 0
for y ∈G
and
φ(y) = K(y)
for y ∈∂G .
Then by a measurable selection theorem one can ﬁnd a (measurable) function
u∗(y) such that
F u∗(y) + (Lu∗φ)(y) = 0 ,
(11.2.62)
for a.a. y ∈G w.r.t. Lebesgue measure in Rn+1. Even if u∗is only known
to be measurable, one can show that the corresponding solution Xt = Xu∗
t
of (11.1.1) exists (see Stroock and Varadhan (1979) for general results in
this direction). Then by inspecting the proof of Theorem 11.2.2 one can
see that it suﬃces to have (11.2.62) satisﬁed outside a subset of G with
Green measure 0 (see Deﬁnition 9.3.4). Under suitable conditions on b and σ
one can in fact show that the Green measure is absolutely continuous w.r.t.
Lebesgue measure. Thus by (11.2.62) (and a strengthened Theorem 11.2.2)
u∗is an optimal control. We refer the reader to Fleming and Rishel (1975),
Bensoussan and Lions (1978), Dynkin and Yushkevich (1979) and Krylov
(1980) for details and further studies.
11.3 Stochastic control problems with terminal
conditions
In many applications there are constraints on the types of Markov controls u
to be considered, for example in terms of the probabilistic behaviour of Y u
t
at the terminal time t = T. Such problems can often be handled by applying
a kind of “Lagrange multiplier” method, which we now describe:
Consider the problem of ﬁnding Φ(y) and u∗(y) such that
Φ(y) = sup
u∈K
Ju(y) = Ju∗(y)
(11.3.1)
where
Ju(y) = Ey
·
T
Z
0
F u(Y u
t )dt + K(Y u
T )
¸
,
(11.3.2)
and where the supremum is taken over the space K of all Markov controls
u: Rn+1 →U ⊂Rk such that
Ey[Mi(Y u
T )] = 0 ,
i = 1, 2, . . . , l ,
(11.3.3)

242
11. Application to Stochastic Control
where M = (M1, . . . , Ml): Rn+1 →Rl is a given continuous function,
Ey[|M(Y u
T )|] < ∞
for all y, u .
(11.3.4)
Now we introduce a related, but unconstrained problem as follows:
For each λ ∈Rl and each Markov control u deﬁne
Ju
λ(y) = Ey
·
T
Z
0
F u(Y u
t )dt + K(Y u
T ) + λ · M(Y u
T )
¸
(11.3.5)
where · denotes the inner product in Rl. Find Φλ(y) and u∗
λ(y) such
that
Φλ(y) = sup
u Ju
λ(y) = Ju∗
λ
λ (y) ,
(11.3.6)
without terminal conditions.
Theorem 11.3.1. Suppose that we for all λ ∈Λ ⊂Rl can ﬁnd Φλ(y) and
u∗
λ solving the (unconstrained) stochastic control problem (11.3.5)–(11.3.6).
Moreover, suppose that there exists λ0 ∈Λ such that
Ey[M(YT
u∗
λ0 )] = 0 .
(11.3.7)
Then Φ(y): = Φλ0(y) and u∗: = u∗
λ0 solves the constrained stochastic control
problem (11.3.1)–(11.3.3).
Proof. Let u be a Markov control, λ ∈Λ. Then by the deﬁnition of u∗
λ we
have
Ey
·
T
Z
0
F u∗
λ(Y u∗
λ
t
)dt + K(Y u∗
λ
T ) + λ · M(Y u∗
λ
T )
¸
= Ju∗
λ
λ (y)
≥Ju
λ(y) = Ey
·
T
Z
0
F u(Y u
t )dt + K(Y u
T ) + λ · M(Y u
T )
¸
.
(11.3.8)
In particular, if λ = λ0 and u ∈K then
Ey[M(YT
u∗
λ0)] = 0 = Ey[M(Y u
T )]
and hence by (11.3.8)
J
u∗
λ0 (y) ≥Ju(y)
for all u ∈K .
Since u∗
λ0 ∈K the proof is complete.
⊔⊓
For an application of this result, see Exercise 11.11.

Exercises
243
Exercises
11.1.
Write down the HJB equation for the problem
Ψ(s, x) = inf
u Es,x
· ∞
Z
s
e−αt(g(Xt) + u2
t)dt
¸
where
dXt = utdt + dBt ;
Xt, ut, Bt ∈R ,
α > 0 is a constant and g: R →R is a given bounded, continuous
function. Show that if Ψ satisﬁes the conditions of Theorem 11.2.1
and u∗exists then
u∗(t, x) = −1
2eαt ∂Ψ
∂x .
11.2.
Consider the stochastic control problem
Ψ0(s, x) = inf
u Es,x
· ∞
Z
s
e−ρtf(ut, Xt)dt
¸
,
where
dXt = dXu
t = b(ut, Xt)dt + σ(ut, Xt)dBt
Xt ∈Rn, ut ∈Rk, Bt ∈Rm ,
f is a given bounded continuous real function, ρ > 0 and the inf is
taken over all time-homogeneous Markov controls u, i.e. controls u
of the form u = u(Xt). Prove that
Ψ0(s, x) = e−ρsξ(x) ,
where ξ(x) = Ψ(0, x) .
(Hint: By deﬁnition of Es,x we have
Es,x
· ∞
Z
s
e−ρtf(u(Xt), Xt)dt] = E[
∞
Z
0
e−ρ(s+t)f(u(Xs,x
s+t), Xs,x
s+t)dt
¸
where E denotes expectation w.r.t. P.)
11.3.
Deﬁne
dXt = rutXtdt + αutXtdBt ;
Xt, ut, Bt ∈R
and
Φ(s, x) = sup
u Es,x
· ∞
Z
s
e−ρtf(Xt)dt
¸
,

244
11. Application to Stochastic Control
where r, α, ρ are constants, ρ > 0 and f is a bounded continuous real
function.
Assume that Φ satisﬁes the conditions of Theorem 11.2.1 and that
an optimal Markov control u∗exists.
a) Show that
sup
v∈R
½
e−ρtf(x) + ∂Φ
∂t + rvx∂Φ
∂x + 1
2α2v2x2 ∂2Φ
∂x2
¾
= 0 .
Deduce that
∂2Φ
∂x2 ≤0 .
b) Assume that ∂2Φ
∂x2 < 0. Prove that
u∗(t, x) = −
r ∂Φ
∂x
α2x ∂2Φ
∂x2
and that
2α2
µ
e−ρtf + ∂Φ
∂t
¶∂2Φ
∂x2 −r2
µ∂Φ
∂x
¶2
= 0 .
c) Assume that ∂2Φ
∂x2 = 0. Prove that ∂Φ
∂x = 0 and
e−ρtf(x) + ∂Φ
∂t = 0 .
d) Assume that u∗
t = u∗(Xt) and that b) holds. Prove that Φ(t, x) =
e−ρtξ(x) and
2α2(f −ρξ)ξ′′ −r2(ξ′)2 = 0 .
(See Exercise 11.2)
11.4.
The assumptions in Theorem 11.2.1 often fail (see e.g. Exercise 11.10),
so it is useful to have results in such cases also. For example, if we
deﬁne Φa as in Theorem 11.2.3 then, without assuming that u∗ex-
ists and without smoothness conditions on Φ, we have the Bellman
principle (compare with (11.2.6)–(11.2.7))
Φa(y) = sup
u Ey
·
α
Z
0
F u(Y u
r )dr + Φa(Y u
α )
¸
for all y ∈G and all stopping times α ≤T, the sup being taken over
all F(m)
t
-adapted controls u. (See Krylov (1980, Th. 6, p. 150).)
Deduce that if Φa ∈C2(G) then
F v(y) + LvΦa(y) ≤0
for all y ∈G, v ∈U .

Exercises
245
11.5.
Assume that F = 0 in (11.1.8) and that an optimal Markov control
u∗exists. Prove that the function Φ is superharmonic in G w.r.t. the
process Y u
t , for any Markov control u. (Hint: See (11.2.6)–(11.2.7).)
11.6.
Let Xt denote your wealth at time t. Suppose that at any time t you
have a choice between two investments:
1) A risky investment where the unit price p1 = p1(t, ω) satisﬁes the
equation
dp1 = a1p1dt + σ1p1dBt .
2) A safer (less risky) investment where the unit price p2 = p2(t, ω)
satisﬁes
dp2 = a2p2dt + σ2p2d eBt
where ai, σi are constants such that
a1 > a2 ,
σ1 > σ2
and Bt, eBt are independent 1-dimensional Brownian motions.
a) Let u(t, ω) denote the fraction of the fortune Xt(ω) which is
placed in the riskier investment at time t. Show that
dXt = dX(u)
t
= Xt(a1u+a2(1−u))dt+Xt(σ1udBt+σ2(1−u)d eBt) .
b) Assuming that u is a Markov control, u = u(t, Xt), ﬁnd the gen-
erator Au of (t, Xu
t ).
c) Write down the HJB equation for the stochastic control problem
Φ(s, x) = sup
u Es,xh
(X(u)
T )γi
where T = min(t1, τ0), τ0 = inf{t > s; Xt = 0} and t1 is a given
future time (constant), γ ∈(0, 1) is a constant.
d) Find the optimal control u∗for the problem in c).
11.7.
Consider the stochastic control problem
(system)
dXt = audt + udBt ;
X0 = x > 0
where Bt ∈R, u ∈R and a ∈R is a given constant, and
(performance)
Φ(s, x) = sup
u Es,x[(XT )r] ,
where 0 < r < 1 is constant and
T = inf{t > s; Xt = 0} ∧t1 ,
t1 being a given future time (constant).
Show that this problem has the optimal control

246
11. Application to Stochastic Control
u∗(t, x) =
ax
1 −r
with corresponding optimal performance
Φ(s, x) = xr exp
µa2(t1 −s)r
2(1 −r)
¶
.
11.8.
Use Dynkin’s formula to prove directly that
u∗(t, x) = min
µ
a −b
α2(1 −r) , 1
¶
is the optimal control for the problem in Example 11.2.5, with utility
function N(x) = xr. (Hint: See the argument leading to (11.2.55).)
11.9.
In Beneˇs (1974) the following stochastic control problem is consid-
ered:
Ψ(s, x) = inf
u Es,x
· ∞
Z
s
e−ρtX2
t dt
¸
,
where
dXt = dX(u)
t
= autdt + dBt ;
Xt, Bt ∈R
and a, ρ are (known) constants, ρ > 0. Here the controls u are re-
stricted to take values in U = [−1, 1].
a) Show that the HJB equation for this problem is
inf
v∈[−1,1]
½
e−ρsx2 + ∂Ψ
∂s + av ∂Ψ
∂x + 1
2 · ∂2Ψ
∂x2
¾
= 0 .
b) If Ψ ∈C2 and u∗exists, show that
u∗(x) = −sign(ax) ,
where
sign z =
½
1
if z > 0
−1
if z ≤0 .
(Hint: Explain why x > 0 ⇒∂Ψ
∂x > 0 and x < 0 ⇒∂Ψ
∂x < 0.)
11.10.
Let
f(x) =
½
x2
for 0 ≤x ≤1
√x
for x > 1
and put
Ju(s, x) = Es,x
·
T
Z
s
e−ρtf(Xu
t )dt
¸
,
Φ(s, x) = sup
u Ju(s, x)

Exercises
247
where
dXu
t = utdBt ;
t ≥s
with control values ut ∈R, Bt ∈R and
T = inf{t > s; Xu
t ≤0} .
a) Deﬁne
φ(s, x) = 1
ρe−ρs bf(x)
for x ≥0, s ∈R
where
bf(x) =
½ x
for 0 ≤x ≤1
√x
for x > 1 .
Prove that
Ju(s, x) ≤φ(s, x)
for all s, x and all (ﬁnite) Markov controls u.
(Hint: Put φ1(s, x) = 1
ρe−ρsx for all s, x and φ2(s, x) = 1
ρe−ρs√x
for all s, x. Then
Ju(s, x) ≤φi(s, x)
for i = 1, 2
by Theorem 11.2.2.)
b) Show that
Φ(s, x) = φ(s, x) .
(Hint: Consider Juk(s, x), where
uk(x) =
½
k
for 0 ≤x < 1
0
for x ≥1
and let k →∞).
Thus u∗does not exist and Φ is not a C2 function. Hence both
conditions for the HJB (I) equation fail in this case.
11.11.
Consider a 1-dimensional version of the stochastic linear regulator
problem of Example 11.2.4:
Ψ(s, x) = inf
u∈K Es,x
· t1
Z
s
((Xu
r )2 + θu2
r)dr
¸
(11.3.9)
where
dXu
t = utdt + σdBt ;
for t ≥s, Xs = x ,
ut, Bt ∈R, σ, θ constants, θ > 0, the inﬁnum being over the space
K of all Markov controls u satisfying
Es,x[(Xu
t1)2] = m2 ,
where m is a constant .
(11.3.10)

248
11. Application to Stochastic Control
Solve this problem by using Theorem 11.3.1.
(Hint: Solve for each λ ∈R the unconstrained problem
Ψλ(s, x) = inf
u Es,x
· t1
Z
s
((Xu
r )2 + θu2
r)dr + λ(Xu
t1)2
¸
with optimal control u∗
λ. Then try to ﬁnd λ0 such that
Es,x[
¡
Xt1
u∗
λ0¢2] = m2 .)
11.12.
Solve the stochastic control problem
Ψ(s, x) = inf
u Ju(s, x) = Ju∗(s, x)
where
Ju(s, x) = Es,x
· ∞
Z
s
e−ρr(X2
r + θu2
r)dr
¸
and
dXt = utdt + σdBt ,
with ut, Bt ∈R and σ ∈R, ρ > 0, θ > 0 are constants. (Hint:
Try ψ(s, x) = e−ρs(ax2 + b) for suitable constants a, b and apply
Theorem 11.2.2.)
11.13.
Consider the stochastic control problem
Φ(s, x) = sup
u Es,x
·
T
Z
s
e−ρtut dt
¸
where the (1-dimensional) system Xt is given by
dXt = dXu
t = (1 −ut)dt + dBt .
The control ut = ut(ω) can assume any value in U = [0, 1] and
T = inf{t > s; Xu
t ≤0}
(the time of bankruptcy) .
Show that if ρ ≥2 then the optimal control is
u∗
t = 1
for all t
and the corresponding value function is
Φ(s, x) = e−ρs 1
ρ
³
1 −e−√2ρ x´
;
x ≥0 .

12. Application to Mathematical Finance
12.1 Market, portfolio and arbitrage
In this chapter we describe how the concepts, methods and results in the
previous chapters can be applied to give a rigorous mathematical model of
ﬁnance. We will concentrate on the most fundamental issues and those topics
which are most closely related to the theory in this book. We emphasize
that this chapter only intends to give a brief introduction to this exciting
subject, which has developed very fast during the last years and shows no
signs of slowing down. For a more comprehensive treatment see for example
Bingham and Kiesel (1998), Elliott and Kopp (1999), Duﬃe (1996), Karatzas
(1997), Karatzas and Shreve (1998), Lamberton and Lapeyre (1996), Musiela
and Rutkowski (1997), Kallianpur and Karandikar (2000), Merton (1990),
Shiryaev (1999) and the references therein.
First we give the mathematical deﬁnitions of some fundamental ﬁnance
concepts. We point out that other mathematical models are also possible
and in fact actively investigated. Other models include more general (possibly
discontinuous) semimartingale models (see e.g. Barndorﬀ-Nielsen (1998)) and
even models based on stochastic processes which are not semimartingales,
such as fractional Brownian motion. See e.g. Cutland, Kopp and Willinger
(1995), Lin (1995), Hu and Øksendal (1999).
Deﬁnition 12.1.1. a) A market is an F(m)
t
-adapted (n + 1)-dimensional
Itˆo process X(t) = (X0(t), X1(t), . . . , Xn(t)); 0 ≤t ≤T which we will
assume has the form
dX0(t) = ρ(t, ω)X0(t)dt ;
X0(0) = 1
(12.1.1)
and
dXi(t) = µi(t, ω)dt +
m
X
j=1
σij(t, ω)dBj(t)
(12.1.2)
= µi(t, ω)dt + σi(t, ω)dB(t) ;
Xi(0) = xi ,
where σi is row number i of the n × m matrix [σij]; 1 ≤i ≤n ∈N.
b) The market {X(t)}t∈[0,T ] is called normalized if X0(t) ≡1.

250
12. Application to Mathematical Finance
c) A portfolio in the market {X(t)}t∈[0,T ] is an (n + 1)-dimensional (t, ω)-
measurable and F(m)
t
-adapted stochastic process
θ(t, ω) = (θ0(t, ω), θ1(t, ω), . . . , θn(t, ω));
0 ≤t ≤T .
(12.1.3)
d) The value at time t of a portfolio θ(t) is deﬁned by
V (t, ω) = V θ(t, ω) = θ(t) · X(t) =
n
X
i=0
θi(t)Xi(t)
(12.1.4)
where · denotes inner product in Rn+1.
e) The portfolio θ(t) is called self-ﬁnancing if
T
Z
0
n
|θ0(s)ρ(s)X0(s)+
n
X
i=1
θi(s)µi(s)|+
m
X
j=1
h
n
X
i=1
θi(s)σij(s)
i2o
ds<∞
a.s.
(12.1.5)
and
dV (t) = θ(t) · dX(t)
(12.1.6)
i.e.
V (t) = V (0) +
t
Z
0
θ(s) · dX(s)
for t ∈[0, T] .
(12.1.7)
Comments to Deﬁnition 12.1.1.
a) We think of Xi(t) = Xi(t, ω) as the price of security/asset number i at
time t. The assets number 1, . . . , n are called risky because of the presence
of their diﬀusion terms. They can for example represent stock investments.
The asset number 0 is called safe because of the absence of a diﬀusion term
(although ρ(t, ω) may depend on ω). This asset can for example represent a
bank investment. For simplicity we will assume that ρ(t, ω) is bounded.
b) Note that we can always make the market normalized by deﬁning
Xi(t) = X0(t)−1Xi(t);
1 ≤i ≤n .
(12.1.8)
The market
X(t) = (1, X1(t), . . . , Xn(t))
is called the normalization of X(t).
Thus normalization corresponds to regarding the price X0(t) of the safe
investment as the unit of price (the numeraire) and computing the other
prices in terms of this unit. Since
X0(t) = exp
µ
t
Z
0
ρ(s, ω)ds
¶

12.1 Market, portfolio and arbitrage
251
we have
ξ(t): = X−1
0 (t) = exp
µ
−
t
Z
0
ρ(s, ω)ds
¶
> 0
for all t ∈[0, T]
(12.1.9)
and
dXi(t)=d(ξ(t)Xi(t))=ξ(t)[(µi−ρXi)dt+σidB(t)];
1≤i≤n
(12.1.10)
or
dX(t)=ξ(t)[dX(t) −ρ(t)X(t)dt] .
(12.1.11)
c) The components θ0(t, ω), . . . , θn(t, ω) represent the number of units of the
securities number 0, . . . , n, respectively, which an investor holds at time t.
d) This is simply the total value of all investments held at time t.
e) Note that condition (12.1.5) is required to make (12.1.7) well-deﬁned. See
Deﬁnition 3.3.2.
This part e) of Deﬁnition 12.1.1 represents a subtle point in the mathe-
matical model. According to Itˆo’s formula the equation (12.1.4) would lead
to
dV (t) = θ(t) · dX(t) + X(t) · dθ(t) + dθ(t) · dX(t)
if θ(t) was also an Itˆo process. However, the requirement (12.1.6) stems
from the corresponding discrete time model: If investments θ(tk) are made
at discrete times t = tk, then the increase in the wealth ∆V (tk) = V (tk+1) −
V (tk) should be given by
∆V (tk) = θ(tk) · ∆X(tk)
(12.1.12)
where ∆X(tk) = X(tk+1)−X(tk) is the change in prices, provided that no
money is brought in or taken out from the system i.e. provided the portfolio
is self-ﬁnancing. If we consider our continuous time model as a limit of the
discrete time case as ∆tk = tk+1 −tk goes to 0, then (12.1.6) (with the Itˆo
interpretation of the integral) follows from (12.1.12).
f) Note that if θ is self-ﬁnancing for X(t) and
V
θ(t) = θ(t) · X(t) = ξ(t)V θ(t)
(12.1.13)
is the value process of the normalized market, then by Itˆo’s formula and
(12.1.11) we have
dV
θ(t) = ξ(t)dV θ(t) + V θ(t)dξ(t)
= ξ(t)θ(t)dX(t) −ρ(t)ξ(t)V θ(t)dt
= ξ(t)θ(t)[dX(t) −ρ(t)X(t)dt]
= θ(t)dX(t) .
(12.1.14)

252
12. Application to Mathematical Finance
Hence θ is also self-ﬁnancing for the normalized market.
Remark. Note that by combining (12.1.4) and (12.1.6) we get
θ0(t)X0(t) +
n
X
i=1
θi(t)Xi(t) = V (0) +
t
Z
0
θ0(s)dX0(s) +
n
X
i=1
t
Z
0
θi(s)dXi(s) .
Hence, if we put
Y0(t) = θ0(t)X0(t) ,
then
dY0(t) = ρ(t)Y0(t)dt + dA(t) ,
where
A(t) =
n
X
i=1
µ
t
Z
0
θi(s)dXi(s) −θi(t)Xi(t)
¶
.
(12.1.15)
This equation has the solution
ξ(t)Y0(t) = θ0(0) +
t
Z
0
ξ(s)dA(s)
or
θ0(t) = θ0(0) +
t
Z
0
ξ(s)dA(s) .
Using integration by parts we may rewrite this as
θ0(t) = θ0(0) + ξ(t)A(t) −A(0) −
t
Z
0
A(s)dξ(s)
or
θ0(t) = V (0) + ξ(t)A(t) +
t
Z
0
ρ(s)A(s)ξ(s)ds .
(12.1.16)
In particular, if ρ = 0 this gives
θ0(t) = V (0) + A(t).
(12.1.17)
Therefore, if θ1(t), . . . , θn(t) are chosen, we can always make the portfolio
θ(t) = (θ0(t), θ1(t), . . . , θn(t)) self-ﬁnancing by choosing θ0(t) according to
(12.1.16).
We now make the following deﬁnition

12.1 Market, portfolio and arbitrage
253
Deﬁnition 12.1.2. A portfolio θ(t) which satisﬁes (12.1.5) and which is
self-ﬁnancing is called admissible if the corresponding value process V θ(t) is
(t, ω) a.s. lower bounded, i. e. there exists K = K(θ) < ∞such that
V θ(t, ω) ≥−K
for a.a. (t, ω) ∈[0, T] × Ω.
(12.1.18)
This is the analogue of a tame portfolio in the context of Karatzas (1996).
The restriction (12.1.18) reﬂects a natural condition in real life ﬁnance: There
must be a limit to how much debt the creditors can tolerate. See Exam-
ple 12.1.4.
Deﬁnition 12.1.3. An admissible portfolio θ(t) is called an arbitrage (in
the market {Xt}t∈[0,T ]) if the corresponding value process V θ(t) satisﬁes
V θ(0) = 0 and
V θ(T) ≥0
a.s. and
P[V θ(T) > 0] > 0 .
In other words, θ(t) is an arbitrage if it gives an increase in the value from
time t = 0 to time t = T a.s., and a strictly positive increase with positive
probability. So θ(t) generates a proﬁt without any risk of losing money.
Intuitively, the existence of an arbitrage is a sign of lack of equilibrium in
the market: No real market equilibrium can exist in the long run if there are
arbitrages there. Therefore it is important to be able to determine if a given
market allows an arbitrage or not. Not surprisingly, this question turns out to
be closely related to what conditions we pose on the portfolios that should be
allowed to use. We have deﬁned our admissible portfolios in Deﬁnition 12.1.2
above, where condition (12.1.18) was motivated from a modelling point of
view. One could also obtain a mathematically sensible theory with other
conditions instead, for example with L2-conditions which imply that
E[V 2(t)] < ∞
for all t ∈[0, T] .
(12.1.19)
In any case, some additional conditions are required on the self-ﬁnancial
portfolios: If we only require the portfolio to be self-ﬁnancing (and satisfying
(12.1.5)) we can generate virtually any ﬁnal value V (T), as the next example
illustrates:
Example 12.1.4. Consider the following market
dX0(t) = 0,
dX1(t) = dB(t),
0 ≤t ≤T = 1 .
Let
Y (t) =
t
Z
0
dB(s)
√1 −s
for 0 ≤t < 1 .
By Corollary 8.5.5 there exists a Brownian motion bB(t) such that

254
12. Application to Mathematical Finance
Y (t) = bB(βt) ,
where
βt =
t
Z
0
ds
1 −s = ln
µ
1
1 −t
¶
for 0 ≤t < 1 .
Let a ∈R be a given constant and deﬁne
τ: = τa: = inf{t > 0; bB(t) = a}
and
α: = αa: = inf{t > 0; Y (t) = a} .
Then
τ < ∞
a.s.
(Exercise 7.4a))
and
τ = ln
µ
1
1 −α
¶
,
so α < 1 a.s.
Let θ(t) = (θ0(t), θ1(t)) be a self-ﬁnancing portfolio with
θ1(t) =
(
1
√1−t
for 0 ≤t < α
0
for α ≤t ≤1 .
Then the corresponding value process is given by
V (t) =
t∧α
Z
0
dB(s)
√1 −s = Y (t ∧α)
for 0 ≤t ≤1 ,
if we assume that V (0) = 0. In particular,
V (1) = Y (α) = a
a.s.
In this case condition (12.1.5) reduces to
1
Z
0
θ2
1(s)ds < ∞
a.s.
Now
1
Z
0
θ2
1(s)ds =
α
Z
0
ds
1 −s = ln
µ
1
1 −α
¶
= τ < ∞
a.s. ,
so (12.1.5) holds. But θ(t) is not admissible, because V (t) = Y (t ∧α) =
bB(ln(
1
1−t∧α)) is not (t, ω)-a.s. lower bounded for (t, ω) ∈[0, T] × Ω. Note
that θ(t) does not satisfy (12.1.19) either, because

12.1 Market, portfolio and arbitrage
255
E[V 2(t)] = E[Y 2(t∧α)] = E
· t∧α
Z
0
ds
1 −s
¸
= E
·
ln
µ
1
1 −t ∧α
¶¸
→E[τ] = ∞
as t →T (Exercise 7.4b).
This example illustrates that with portfolios only required to be self-
ﬁnancing and satisfy (12.1.5) one can virtually generate any terminal value
V (T, ω) from V0 = 0, even when the risky price process X1(t) is Brownian
motion. This clearly contradicts the real life situation in ﬁnance, so a re-
alistic mathematical model must put stronger restrictions than (12.1.5) on
the portfolios allowed. One such natural restriction is (12.1.18), as we have
adopted.
To emphasize the phenomenon illustrated by this example, we state the
following striking result, which is due to Dudley (1977):
Theorem 12.1.5. Let F be an F(m)
T
-measurable random variable and let
B(t) be m-dimensional Brownian motion. Then there exists φ ∈Wm such
that
F(ω) =
T
Z
0
φ(t, ω)dB(t) .
(12.1.20)
Note that φ is not unique. See Exercise 3.4.22 in Karatzas and Shreve
(1991). See also Exercise 12.4.
This implies that for any constant z there exists φ ∈Wm such that
F(ω) = z +
T
Z
0
φ(t, ω)dB(t) .
Thus, if we let m = n and interprete B1(t) = X1(t), . . . , Bn(t) = Xn(t) as
prices, and put X0(t) ≡1, this means that we can, with any initial fortune
z, generate any F(m)
T
-measurable ﬁnal value F = V (T), as long as we are
allowed to choose the portfolio φ freely from Wm. This again underlines the
need for some extra restriction on the family of portfolios allowed, like con-
dition (12.1.18).
How can we decide if a given market {X(t)}t∈[0,T ] allows an arbitrage or
not? The following simple result is useful:
Lemma 12.1.6. Suppose there exists a measure Q on F(m)
T
such that P ∼Q
and such that the normalized price process {X(t)}t∈[0,T ] is a local martingale
w.r.t. Q. Then the market {X(t)}t∈[0,T ] has no arbitrage.

256
12. Application to Mathematical Finance
Proof. Suppose θ(t) is an arbitrage for {X(t)}t∈[0,T ]. Let V
θ(t) be the cor-
responding value process for the normalized market with V
θ(0) = 0. Then
V
θ(t) is a lower bounded local martingale w.r.t. Q, by (12.1.14). Therefore
V
θ(t) is a supermartingale w.r.t. Q, by Exercise 7.12. Hence
EQ[V θ(T)] ≤V θ(0) = 0 .
(12.1.21)
But since V θ(T, ω) ≥0 a.s. P we have V θ(T, ω) ≥0 a.s. Q (because Q ≪P)
and since P[V θ(T) > 0] > 0 we have Q[V θ(T) > 0] > 0 (because P ≪Q).
This implies that
EQ[V θ(T)] > 0 ,
which contradicts (12.1.21). Hence arbitrages do not exist for the normalized
price process {X(t)}. It follows that {X(t)} has no arbitrage. (Exercise 12.1).
⊔⊓
Deﬁnition 12.1.7. A measure Q ∼P such that the normalized process
{X(t)}t∈[0,T ] is a (local) martingale w.r.t. Q is called an equivalent (local)
martingale measure.
Thus Lemma 12.1.6 states that if there exists an equivalent local martin-
gale measure then the market has no arbitrage. In fact, then the market also
satisﬁes the stronger condition “no free lunch with vanishing risk” (NFLVR).
Conversely, if the market satisﬁes the NFLVR condition, then there exists
an equivalent martingale measure. See Delbaen and Schachermayer (1994),
(1995), (1997), Levental and Skorohod (1995) and the references therein.
Here we will settle with a weaker result, which nevertheless is good enough
for many applications:
Theorem 12.1.8. a) Suppose there exists a process u(t, ω) ∈Vm(0, T) such
that, with b
X(t, ω) = (X1(t, ω), . . . , Xn(t, ω)),
σ(t, ω)u(t, ω) = µ(t, ω) −ρ(t, ω) b
X(t, ω)
for a.a. (t, ω)
(12.1.22)
and such that
E
·
exp
µ
1
2
T
Z
0
u2(t, ω)dt
¶¸
< ∞.
(12.1.23)
Then the market {X(t)}t∈[0,T ] has no arbitrage.
b) (Karatzas (1996), Th. 0.2.4)
Conversely, if the market {X(t)}t∈[0.T ] has no arbitrage, then there exists
an F(m)
t
-adapted, (t, ω)-measurable process u(t, ω) such that
σ(t, ω)u(t, ω) = µ(t, ω) −ρ(t, ω) b
X(t, ω)
for a.a. (t, ω).

12.1 Market, portfolio and arbitrage
257
Proof. a) We may assume that {X(t)} is normalized, i.e. that ρ = 0 (Exercise
12.1). Deﬁne the measure Q = Qu on F(m)
T
by
dQ(ω) = exp
µ
−
T
Z
0
u(t, ω)dB(t) −1
2
T
Z
0
u2(t, ω)dt
¶
dP(ω) .
(12.1.24)
Then Q ∼P and by the Girsanov theorem II (Theorem 8.6.4) the process
eB(t): =
t
Z
0
u(s, ω)ds + B(t)
(12.1.25)
is a Q-Brownian motion and in terms of eB(t) we have
dXi(t) = µidt + σidB(t) = σid eB(t);
1 ≤i ≤n .
Hence X(t) is a local Q-martingale and the conclusion follows from Lemma
12.1.6.
b) Conversely, assume that the market has no arbitrage and is normalized.
For t ∈[0, T], ω ∈Ωlet
Ft =
{ω; the equation (12.1.22) has no solution}
=
{ω; µ(t, ω) does not belong to the linear span of the columns
of σ(t, ω)}
=
{ω; ∃v = v(t, ω) with σT (t, ω)v(t, ω) = 0 and
v(t, ω) · µ(t, ω) ̸= 0} .
Deﬁne
θi(t, ω) =
½sign(v(t, ω) · µ(t, ω))vi(t, ω) for ω ∈Ft
0
for ω ̸∈Ft
for 1 ≤i ≤n and θ0(t, ω) according to (12.1.17). Since σ(t, ω), µ(t, ω) are
F(m)
t
-adapted and (t, ω)-measurable, it follows that we can choose θ(t, ω)
to be F(m)
t
-adapted and (t, ω)-measurable also. Moreover, θ(t, ω) is self-
ﬁnancing and it generates the following gain in the value function
V θ(t, ω) −V θ(0) =
t
Z
0
n
X
i=1
θi(s, ω)dXi(s)
=
t
Z
0
XFs(ω)|v(s, ω) · µ(s, ω)|ds +
t
Z
0
m
X
j=1
µ
n
X
i=1
θi(s, ω)σij(s, ω)
¶
dBj(s)

258
12. Application to Mathematical Finance
=
t
Z
0
XFs(ω)|v(s, ω) · µ(s, ω)|ds
+
t
Z
0
sign(v(s, ω) · µ(s, ω))XFs(ω)σT (s, ω)v(s, ω)dB(s)
=
t
Z
0
XFs(ω)|v(s, ω) · µ(s, ω)|ds ≥0
for all t ∈[0, T] .
Since the market has no arbitrage we must (by Exercise 12.1 b) have that
XFt(ω) = 0
for a.a. (t, ω)
i.e. that (12.1.22) has a solution for a.a. (t, ω).
⊔⊓
Example 12.1.9. a) Consider the price process X(t) given by
dX0(t) = 0,
dX1(t) = 2dt + dB1(t),
dX2(t) = −dt + dB1(t) + dB2(t) .
In this case we have
µ =
·
2
−1
¸
,
σ =
·
1 0
1 1
¸
and the system σu = µ has the unique solution
u =
· u1
u2
¸
=
· 2
−3
¸
.
From Theorem 12.1.8a) we conclude that X(t) has no arbitrage.
b) Next, consider the price process Y (t) given by
dY0(t) = 0 ,
dY1(t) = 2dt + dB1(t) + dB2(t) ,
dY2(t) = −dt −dB1(t) −dB2(t) .
Here the system of equations σu = µ gets the form
· 1
1
−1 −1
¸ · u1
u2
¸
=
· 2
−1
¸
which has no solutions. So the market has an arbitrage, according to Theo-
rem 12.1.8 b). Indeed, if we choose
θ(t) = (θ0, 1, 1)
we get

12.2 Attainability and Completeness
259
V θ(T) = V θ(0) +
T
Z
0
2dt + dB1(t) + dB2(t) −dt −dB1(t) −dB2(t)
= V θ(0) + T .
In particular, if we choose θ0 constant such that
V θ(0) = θ0Y0(0) + Y1(0) + Y2(0) = 0 ,
then θ will be an arbitrage (see Exercise 12.2).
12.2 Attainability and Completeness
We start this section by stating without proof the following useful result,
which is a special case of Proposition 17.1 in Yor (1997):
Lemma 12.2.1. Suppose a process u(t, ω) ∈Vm(0, T)satisﬁes the condition
E
·
exp
µ
1
2
T
Z
0
u2(s, ω)ds
¶¸
< ∞.
(12.2.1)
Deﬁne the measure Q = Qu on F(m)
T
by
dQ(ω) = exp
µ
−
T
Z
0
u(t, ω)dB(t) −1
2
T
Z
0
u2(t, ω)dt
¶
dP(ω) .
(12.2.2)
Then
eB(t): =
t
Z
0
u(s, ω)ds + B(t)
(12.2.3)
is an F(m)
t
-martingale (and hence an F(m)
t
-Brownian motion) w.r.t. Q and
any F ∈L2(F(m)
T
, Q) has a unique representation
F(ω) = EQ[F] +
T
Z
0
φ(t, ω)d eB(t) ,
(12.2.4)
where φ(t, ω) is an F(m)
t
-adapted, (t, ω)-measurable Rm-valued process such
that
EQ
·
T
Z
0
φ2(t, ω)dt
¸
< ∞.
(12.2.5)

260
12. Application to Mathematical Finance
Remark.
a) Note that the ﬁltration { eF(m)
t
} generated by { eB(t)} is con-
tained in {F(m)
t
} (by (12.2.3)), but not necessarily equal to {F(m)
t
}. Therefore
the representation (12.2.4) is not a consequence of the Itˆo representation the-
orem (Theorem 4.2.3) or the Dudley theorem (Theorem 12.1.5), which in this
setting would require that F be eF(m)
T
-measurable.
b) To prove that eB(t) is an F(m)
t
-martingale w.r.t Q, we apply Itˆo’s formula
to the process
Y (t): = Z(t) eB(t) ,
where
Z(t) = exp
µ
−
t
Z
0
u(s, ω)dB(s) −1
2
t
Z
0
u2(s, ω)ds
¶
,
and use the Bayes formula, Lemma 8.6.2. The details are left to the reader.
(Exercise 12.5.)
Next we make the following simple, but useful observation:
Lemma 12.2.2. Let X(t) = ξ(t)X(t) be the normalized price process, as
in (12.1.8)–(12.1.11). Suppose θ(t) is an admissible portfolio for the market
{X(t)} with value process
V θ(t) = θ(t) · X(t) .
(12.2.6)
Then θ(t) is also an admissible portfolio for the normalized market {X(t)}
with value process
V
θ(t): = θ(t) · X(t) = ξ(t)V θ(t)
(12.2.7)
and vice versa.
In other words,
V θ(t) = V θ(0) +
tR
0
θ(s)dX(s) ;
0 ≤t ≤T
(12.2.8)
⇕
ξ(t)V θ(t) = V θ(0) +
tR
0
θ(s)dX(s) ; 0 ≤t ≤T
(12.2.9)
Proof. Note that V
θ(t) is lower bounded if and only if V θ(t) is lower bounded
(since ρ(t) is bounded). Consider ﬁrst the market consisting of the price
process X(t). Let θ(t) be an admissible portfolio for this market with value
process V θ(t). Then
V
θ(t) = θ(t) · X(t) = ξ(t)V θ(t)
(12.2.10)

12.2 Attainability and Completeness
261
and since θ(t) is self-ﬁnancing for the market {X(t)} we have, by (12.1.14),
dV
θ(t) = θ(t)dX(t) .
(12.2.11)
Hence θ(t) is also admissible for {X(t)} and V
θ(t) = V θ(0) +
tR
0
θ(s)dX(s),
which shows that (12.2.8) implies (12.2.9).
The argument goes both ways, so the lemma is proved.
⊔⊓
Before we proceed we note the following useful result:
Lemma 12.2.3. Suppose there exists an m-dimensional process u(t, ω) ∈
Vm(0, T) such that, with b
X(t, ω) = (X1(t, ω), . . . , Xn(t, ω)),
σ(t, ω)u(t, ω) = µ(t, ω) −ρ(t, ω) b
X(t, ω)
for a.a. (t, ω)
(12.2.12)
and
E
h
exp
µ
1
2
T
Z
0
u2(s, ω)ds
¶i
< ∞.
(12.2.13)
Deﬁne the measure Q = Qu and the process eB(t) as in (12.2.2), (12.2.3),
respectively. Then eB is a Brownian motion w.r.t. Q and in terms of eB we
have the following representation of the normalized market X(t) = ξ(t)X(t) :
dX0(t) = 0
(12.2.14)
dXi(t) = ξ(t)σi(t)d eB(t) ;
1 ≤i ≤n .
(12.2.15)
In particular, if
TR
0
EQ[ξ2(t)σ2
i (t)]dt < ∞, then Q is an equivalent martingale
measure (Deﬁnition 12.1.7).
In any case the normalized value process V
θ(t) of an admissible portfolio
θ is a local Q-martingale given by
dV
θ(t) = ξ(t)
n
X
i=1
θi(t)σi(t)d eB(t)
(12.2.16)
Proof. The ﬁrst statement follows from the Girsanov theorem. To prove the
representation (12.2.15) we compute
dXi(t) = d(ξ(t)Xi(t)) = ξ(t)dXi(t) + Xi(t)dξ(t)
= ξ(t)[(µi(t) −ρ(t)Xi(t))dt + σi(t)dB(t)]
= ξ(t)[(µi(t) −ρ(t)Xi(t))dt + σi(t)(d eB(t) −ui(t)dt)]
= ξ(t)σi(t)d eB(t) .

262
12. Application to Mathematical Finance
In particular, if
TR
0
EQ[ξ2(t)σ2
i (t)]dt < ∞, then Xi(t) is a martingale w.r.t. Q
by Corollary 3.2.6.
Finally, the representation (12.2.16) follows from (12.2.11) and (12.2.15).
⊔⊓
Note.
From now on we assume that there exists a process u(t, ω) ∈
Vm(0, T) satisfying (12.2.12) and (12.2.13) and we let Q and eB be
as in (12.2.2), (12.2.3), as described in Lemma 12.2.3.
Deﬁnition 12.2.4. a) A (European) contingent T-claim (or just a T-claim
or claim) is a lower bounded F(m)
T
-measurable random variable F(ω).
b) We say that the claim F(ω) is attainable (in the market {X(t)}t∈[0,T ]) if
there exists an admissible portfolio θ(t) and a real number z such that
F(ω) = V θ
z (T): = z +
T
Z
0
θ(t)dX(t)
a.s.
and such that
V
θ(t) = z +
t
Z
0
ξ(s)
n
X
i=1
θi(s)σi(s)d eB(s) ;
0 ≤t ≤T is a Q-martingale .
If such a θ(t) exists, we call it a replicating or hedging portfolio for F.
c) The market {X(t)}t∈[0,T ] is called complete if every bounded T-claim is
attainable.
In other words, a claim F(ω) is attainable if there exists a real number z
such that if we start with z as our initial fortune we can ﬁnd an admissible
portfolio θ(t) which generates a value V θ
z (T) at time T which a.s. equals F:
V θ
z (T, ω) = F(ω)
for a.a. ω .
In addition we require tht the corresponding normalized value process V
θ(t),
which has the representation (12.2.16), is a martingale and not just a local
martingale w.r.t. Q.
Remark.
a) The boundedness condition in part c) of Deﬁnition 12.2.1 is
technically convenient, but other, related deﬁnitions are also possible. Note
that if the market is complete in the sense of c), then it often follows that
many unbounded claims are attainable as well. See Exercise 12.3.
b) If we drop the martingale condition in Deﬁnition 12.2.4b) then the repli-
cating portfolio θ need not be unique. See Exercise 12.4.

12.2 Attainability and Completeness
263
What claims are attainable? Which markets are complete? These are im-
portant, but diﬃcult questions in general. We will give some partial answers.
We are now ready for the main result of this section:
Theorem 12.2.5. The market {X(t)} is complete if and only if σ(t, ω) has
a left inverse Λ(t, ω) for a.a. (t, ω), i.e. there exists an F(m)
t
-adapted matrix
valued process Λ(t, ω) ∈Rm×n such that
Λ(t, ω)σ(t, ω) = Im
for a.a. (t, ω) .
(12.2.17)
Remark. Note that the property (12.2.17) is equivalent to the property
rank σ(t, ω) = m
for a.a. (t, ω) .
(12.2.18)
Proof of Theorem 12.2.5. (i) Assume that (12.2.17) hold. Let Q and eB be
as in (12.2.2), (12.2.3). Let F be a bounded T-claim. We want to prove that
there exists an admissible portfolio θ(t) = (θ0(t), . . . , θn(t)) and a real number
z such that if we put
V θ
z (t) = z +
t
Z
0
θ(s)dX(s) ;
0 ≤t ≤T
then V
η
z(t) is a Q-martingale and
V θ
z (T) = F(ω)
a.s.
By (12.2.16) this is equivalent to
ξ(T)F(ω) = V
θ(T) = z +
T
Z
0
ξ(t)
n
X
i=1
θi(t)σi(t)d eB(t) .
By Lemma 12.2.1 we have a unique representation
ξ(T)F(ω) = EQ[ξ(T)F]+
T
Z
0
φ(t, ω)d eB(t) = EQ[ξ(T)F]+
T
Z
0
m
X
j=1
φj(t, ω)d eBj(t)
for some φ(t, ω) = (φ1(t, ω), . . . , φm(t, ω)) ∈Rm. Hence we put
z = EQ[ξ(T)F]
and we choose bθ(t) = (θ1(t), . . . , θn(t)) such that
ξ(t)
n
X
i=1
θi(t)σij(t) = φj(t) ;
1 ≤j ≤m

264
12. Application to Mathematical Finance
i.e. such that
ξ(t)bθ(t)σ(t) = φ(t) .
By (12.2.17) this equation in bθ(t) has the solution
bθ(t, ω) = X0(t)φ(t, ω)Λ(t, ω) .
By choosing θ0 according to (12.1.16) the portfolio becomes self-ﬁnancing.
Moreover, since ξ(t)V θ
z (t) = z +
tR
0
θ(s)dX(s) = z +
tR
0
φ(s)d eB(s), we get the
useful formula
ξ(t)V θ
z (t) = EQ[ξ(T)V θ
z (T)|Ft] = EQ[ξ(T)F|Ft] .
(12.2.19)
In particular, V θ
z (t) is lower bounded. Hence the market {X(t)} is complete.
(ii) Conversely, assume that {X(t)} is complete. Then {X(t)} is com-
plete, so we may assume that ρ = 0. The calculation in part a) shows
that the value process V θ
z (t) generated by an admissible portfolio θ(t) =
(θ0(t), θ1(t), . . . , θn(t)) is
V θ
z (t) = z +
t
Z
0
m
X
j=1
µ
n
X
i=1
θiσij
¶
d eBj = z +
t
Z
0
bθσ d eB ,
(12.2.20)
where bθ(t) = (θ1(t), . . . , θn(t)).
Since {X(t)} is complete we can hedge any bounded T-claim. Choose
an F(m)
t
-adapted process φ(t, ω) ∈Rm such that EQ[
TR
0
φ2(t, ω)dt] < ∞and
deﬁne F(ω): =
TR
0
φ(t, ω)d eB(t). Then EQ[F 2] < ∞so we can ﬁnd a sequence
of bounded T-claims Fk(ω) such that
Fk →F
in
L2(Q)
and
EQ[Fk] = 0 .
By completeness there exists for all k an admissible portfolio θ(k) = (θ(k)
0 , bθ(k))
such that V θ(k)(t) =
tR
0
bθ(k)σd eB is a Q-martingale and
Fk(ω) = V θ(k)(T) =
T
Z
0
bθ(k)σ d eB .
Then by the Itˆo isometry the sequence {bθ(k)σ}∞
k=1 is a Cauchy sequence in
L2(λ × Q), where λ denotes Lebesgue measure on [0, T]. Hence there exists
ψ(t, ω) = (ψ1(t, ω), . . . , ψm(t, ω)) ∈L2(λ × Q) such that

12.2 Attainability and Completeness
265
bθ(k)σ →ψ
in L2(λ × Q) .
But then
t
Z
0
ψd eB = lim
k→∞
t
Z
0
bθ(k)σd eB = lim
k→∞E[Fk | eF(m)
t
] = E[F | eF(m)
t
] =
t
Z
0
φd eB
a.s. for all t ∈[0, T], where eF(m)
t
is the σ-algebra generated by eB(s); s ≤t.
Hence by uniqueness we have φ(t, ω) = ψ(t, ω) for a.a. (t, ω). By taking a
subsequence we obtain that for a.a. (t, ω) there exists a sequence x(k)(t, ω) =
(x(k)
1 (t, ω), . . . , x(k)
m (t, ω)) ∈Rm such that
x(k)(t, ω)σ(t, ω) →φ(t, ω)
as k →∞.
This implies that φ(t, ω) belongs to the linear span of the rows {σi(t, ω)}n
i=1
of σ(t, ω). Since φ ∈L2(λ × Q) was arbitrary, we conclude that the linear
span of {σi(t, ω)}n
i=1 is the whole of Rm for a.a. (t, ω). So rank σ(t, ω) = m
and there exists Λ(t, ω) ∈Rm×n such that
Λ(t, ω)σ(t, ω) = Im .
⊔⊓
Corollary 12.2.6. (a) If n = m then the market is complete if and only if
σ(t, ω) is invertible for a.a. (t, ω).
(b) If the market is complete, then
rank σ(t, ω) = m
for a.a. (t, ω) .
In particular, n ≥m.
Moreover, the process u(t, ω) satisfying (12.2.12) is unique.
Proof. (a) is a direct consequence of Theorem 12.2.5, since the existence of a
left inverse implies invertibility when n = m. The existence of a left inverse
of an n × m matrix is only possible if the rank is equal to m, which again
implies that n ≥m. Moreover, the only solution u(t, ω) of (12.2.12) is given
by
u(t, ω) = Λ(t, ω)[µ(t, ω) −ρ(t, ω) b
X(t, ω)] .
This shows (b).
⊔⊓
Example 12.2.7. Deﬁne X0(t) ≡1 and


dX1(t)
dX2(t)
dX3(t)

=


1
2
3

dt +


1
0
0
1
1
1


·
dB1(t)
dB2(t)
¸
.
Then ρ = 0 and the equation (12.2.12) gets the form

266
12. Application to Mathematical Finance
σ u =


1
0
0
1
1
1


· u1
u2
¸
=


1
2
3


which has the unique solution u1 = 1, u2 = 2. Since u is constant, it is
clear that (12.2.12) and (12.2.13) hold. It is immediate that rank σ = 2, so
(12.2.18) holds and the market is complete by Theorem 12.2.5.
Since
· 1
0
0
0
1
0
¸ 

1
0
0
1
1
1

=
· 1
0
0
1
¸
= I2 ,
we see that in this case
Λ =
·
1
0
0
0
1
0
¸
is a left inverse of σ =


1
0
0
1
1
1

.
Example 12.2.8. Let X0(t) ≡1 and
dX1(t) = 2dt + dB1(t) + dB2(t) .
Then µ = 2, σ = (1, 1) ∈R1×2, so n = 1 < 2 = m. Hence this market cannot
be complete, by Corollary 12.2.6. So there exist bounded T-claims which
cannot be hedged. Can we ﬁnd such a T-claim? Let θ(t) = (θ0(t), θ1(t)) be
an admissible portfolio. Then the corresponding value process V θ
z (t) is given
by (see (12.2.20))
V θ
z (t) = z +
t
Z
0
θ1(s)(d eB1(s) + d eB(s)) .
So if θ hedges a T-claim F(ω) we have
F(ω) = z +
T
Z
0
θ1(s)(d eB1(s) + d eB(s)) .
(12.2.21)
Choose F(ω) = g( eB1(T)), where g: R →R is bounded. Then by the Itˆo
representation theorem applied to the 2-dimensional Brownian motion eB(t) =
( eB1(t), eB2(t)) there is a unique φ(t, ω) = (φ1(t, ω), φ2(t, ω)) such that
g( eB1(T)) = EQ[g( eB1(T))] +
T
Z
0
φ1(s)d eB1(s) + φ2(s)d eB2(s)

12.3 Option Pricing
267
and by the Itˆo representation theorem applied to eB1(t), we must have φ2 =0,
i.e.
g( eB1(T)) = EQ[g( eB1(T))] +
T
Z
0
φ1(s)d eB1(s)
Comparing this with (12.2.21) we see that no such θ1 exists. So F(ω) =
g( eB1(T)) cannot be hedged.
Remark. There is a striking characterization of completeness in terms of
equivalent martingale measures, due to Harrison and Pliska (1983) and Jacod
(1979):
A market {X(t)} is complete if and only if there is one and only one
equivalent martingale measure for the normalized market {X(t)}.
(Compare this result with the equivalent martingale measure characteri-
zation of markets with no arbitrage/NFLVR, stated after Deﬁnition 12.1.7!)
12.3 Option Pricing
European Options
Let F(ω) be a T-claim. A European option on the claim F is a guarantee
to be paid the amount F(ω) at time t = T > 0. How much would you be
willing to pay at time t = 0 for such a guarantee? You could argue as follows:
If I – the buyer of the option – pay the price y for this guarantee, then I
have an initial fortune −y in my investment strategy. With this initial fortune
(debt) it must be possible to hedge to time T a value V θ
−y(T, ω) which, if the
guaranteed payoﬀF(ω) is added, gives me a nonnegative result:
V θ
−y(T, ω) + F(ω) ≥0
a.s.
Thus the maximal price p = p(F) the buyer is willing to pay is
(Buyer’s price of the (European) contingent claim F)
(12.3.1)
p(F) = sup{y; There exists an admissible portfolio θ
such that V θ
−y(T, ω): = −y +
T
Z
0
θ(s)dX(s) ≥−F(ω) a.s.}
On the other hand, the seller of this guarantee could argue as follows:
If I – the seller – receive the price z for this guarantee, then I can use
this as the initial value in an investment strategy. With this initial fortune it
must be possible to hedge to time T a value V θ
z (T, ω) which is not less than
the amount F(ω) that I have promised to pay to the buyer:

268
12. Application to Mathematical Finance
V θ
z (T, ω) ≥F(ω)
a.s.
Thus the minimal price q = q(F) the seller is willing to accept is
(Seller’s price of the (European) contingent claim F)
(12.3.2)
q(F) = inf{z; There exists an admissible portfolio θ
such that V θ
z (T, ω): = z +
T
Z
0
θ(s)dX(s) ≥F(ω) a.s.}
Deﬁnition 12.3.1. If p(F) = q(F) we call this common value the price (at
t = 0) of the (European) T-contingent claim F(ω).
Two important examples of European contingent claims are
a) the European call, where
F(ω) = (Xi(T, ω) −K)+
for some i ∈{1, 2, . . . , n} and some K > 0. This option gives the owner
the right (but not the obligation) to buy one unit of security number i at
the speciﬁed price K (the exercise price) at time T. So if Xi(T, ω) > K
then the owner of the option will obtain the payoﬀXi(T, ω) −K at time
T, while if Xi(T.ω) ≤K then the owner will not exercise his option and
the payoﬀis 0.
b) Similarly, the European put option gives the owner the right (but not
the obligation) to sell one unit of security number i at a speciﬁed price
K at time T. This option gives the owner the payoﬀ
F(ω) = (K −Xi(T, ω))+ .
Theorem 12.3.2. a) Suppose (12.2.12) and (12.2.13) hold and let Q be as
in (12.2.2). Let F be a (European) T-claim such that EQ[ξ(T)F] < ∞.
Then
ess inf F(ω) ≤p(F) ≤EQ[ξ(T)F] ≤q(F) ≤∞.
(12.3.3)
b) Suppose, in addition to the conditions in a), that the market {X(t)} is
complete. Then the price of the (European) T-claim F is
p(F) = EQ[ξ(T)F] = q(F) .
(12.3.4)
Proof. a) Suppose y ∈R and there exists an admissible portfolio θ such that
V θ
−y(T, ω) = −y +
T
Z
0
θ(s)dX(s) ≥−F(ω)
a.s.

12.3 Option Pricing
269
i.e., using (12.2.7) and Lemma 12.2.4,
−y +
T
Z
0
n
X
i=1
θi(s)ξ(s)σi(s)d eB(s) ≥−ξ(T)F(ω)
a.s.
(12.3.5)
where eB is deﬁned in (12.2.3).
Since
tR
0
nP
i=1
θi(s)ξ(s)σi(s)d eB(s) is a lower bounded local Q-martingale, it is
a supermartingale, by Exercise 7.12. Hence EQ[
tR
0
nP
i=1
θi(s)ξ(s)σi(s)d eB(s)] ≤0
for all t ∈[0, T]. Therefore, taking the expectation of (12.3.5) with respect
to Q we get
y ≤EQ[ξ(T)F] .
Hence
p(F) ≤EQ[ξ(T)F] ,
provided such a portfolio θ exists for some y ∈R. This proves the second
inequality in (12.3.3). Clearly, if y < F(ω) for a.a. ω, we can choose θ = 0.
Hence the ﬁrst inequality in (12.3.3) holds.
Similarly, if there exists z ∈R and an admissible portfolio θ such that
z +
T
Z
0
θ(s)dX(s) ≥F(ω)
a.s.
then, as in (12.3.5)
z +
T
Z
0
n
X
i=1
θi(s)ξ(s)σi(s)d eB(s) ≥ξ(T)F(ω)
a.s.
Taking Q-expectations we get
z ≥EQ[ξ(T)F] ,
provided such z and θ exist.
If no such z, θ exist, then q(F) = ∞> EQ[ξ(T)F].
b) Next, assume in addition that the market is complete. Deﬁne
Fk(ω) =
½
k
if F(ω) ≥k
F(ω)
if F(ω) < k .
Then Fk is a bounded T-claim, so by completeness we can ﬁnd (unique)
yk ∈R and θ(k) such that

270
12. Application to Mathematical Finance
−yk +
T
Z
0
θ(k)(s)dX(s) = −Fk(ω)
a.s.
i.e. (by (12.2.7) and Lemma 12.2.4)
−yk +
T
Z
0
n
X
i=1
θ(k)
i
(s)ξ(s)σi(s)d eB(s) = −ξ(T)Fk(ω)
a.s. ,
which gives, since
tR
0
nP
i=1
θ(k)
i
(s)ξ(s)σi(s)d eB(s) is a Q-martingale (Deﬁnition
12.2.4c)),
yk = EQ[ξ(T)Fk] .
Hence
p(F) ≥p(Fk)≥EQ[ξ(T)Fk] →EQ[ξ(T)F]
as k →∞,
by monotone convergence .
Combined with a) this gives
p(F) = EQ[ξ(T)F] .
A similar argument gives that
q(F) = EQ[ξ(T)F] .
⊔⊓
How to Hedge an Attainable Claim
We have seen that if V θ
z (t) is the value process of an admissible portfolio θ(t)
for the market {X(t)}, then V
θ
z(t): = ξ(t)V θ
z (t) is the value process of θ(t)
for the normalized market {X(t)} (Lemma 12.2.3). Hence we have
ξ(t)V θ
z (t) = z +
t
Z
0
θ(s)dX(s) .
(12.3.6)
If (12.2.12) and (12.2.13) hold, then – if Q, eB are deﬁned as before ((12.2.2)
and (12.2.3)) – we can rewrite this as (see Lemma 12.2.4)
ξ(t)V θ
z (t) = z +
t
Z
0
n
X
i=1
θi(s)ξ(s)
m
X
j=1
σij(s)d eBj(s) .
(12.3.7)
Therefore, the portfolio θ(t) = (θ0(t), . . . , θn(t)) needed to hedge a given
T-claim F is given by

12.3 Option Pricing
271
ξ(t, ω)(θ1(t), . . . , θn(t))σ(t, ω) = φ(t, ω) ,
(12.3.8)
where φ(t, ω) ∈Rm is such that
ξ(T)F(ω) = z +
T
Z
0
φ(t, ω)d eB(t)
(12.3.9)
(and θ0(t) is given by (12.1.14)).
In view of this it is of interest to ﬁnd explicitly the integrand φ(t, ω)
when F is given. One way of doing this is by using a generalized version
of the Clark-Ocone theorem from the Malliavin calculus. See Karatzas and
Ocone (1991). A survey containing their result is in Øksendal (1996)). In the
Markovian case, however, there is a simpler method, which we now describe.
It is a modiﬁcation of a method used by Hu (1995).
Let Y (t) be an Itˆo diﬀusion in Rn of the form
dY (t) = b(Y (t))dt + σ(Y (t))dB(t),
Y (0) = y
(12.3.10)
where b: Rn →Rn and σ: Rn →Rn×m are given Lipschitz continuous func-
tions. Assume that Y (t) is uniformly elliptic, i.e. that there exists a constant
c > 0 such that
ξT σ(x)σT (x)ξ ≥c|ξ|2
(12.3.11)
for all ξ ∈Rn, x ∈Rn.
Suppose ρ: Rn →R is a bounded Lipschitz continuous function. Let Z(t)
be the Itˆo diﬀusion in Rn given by
dZ(t) = ρ(Z(t))Z(t)dt + σ(Z(t))dB(t) ;
Z(0) = z .
(12.3.12)
Let h: Rn →R be a continuous function such that Ez[|h(Z(t))|] < ∞for all
z and all t ∈[0, T] and deﬁne
w(t, z) = Ez[h(Z(t))]
(12.3.13)
and
g(t, z) = w(T −t, z) .
Then by uniform ellipticity it is known that w(t, z) ∈C1,2((0, ∞) × Rn)
(see Dynkin 1965 II, Theorem 13.18 p. 53 and Dynkin 1965 I, Theorem 5.11
p. 162) and hence Kolmogorov’s backward equation (Theorem 8.1.1) gives
∂w
∂t = ρ(z)
n
X
i=1
zi
∂w
∂zi
+ 1
2
n
X
i,j=1
(σσT )ij(z) ·
∂2w
∂zi∂zj
.
Hence, if we apply Itˆo’s formula to the process
η(t): = g(t, Y (t)) = w(T −t, Y (t))
(12.3.14)

272
12. Application to Mathematical Finance
we get
dη(t) =
·∂g
∂t (t, Y (t))
+
n
X
i=1
∂g
∂zi
(t, Y (t))bi(Y (t))+ 1
2
n
X
i,j=1
∂2g
∂zi∂zj
(t, Y (t)) · (σσT )ij(Y (t))
¸
dt
+
n
X
i=1
∂g
∂zi
(t, Y (t))
m
X
j=1
σij(Y (t))dBj(t)
=
n
X
i=1
∂g
∂zi
(t, Y (t))
·
(bi(Y (t)) −ρ(Y (t))Yi(t))dt
+
m
X
j=1
σij(Y (t))dBj(t)
¸
.
(12.3.15)
Suppose that for all y ∈Rn there exists u(y) ∈Rm such that
σ(y)u(y) = b(y) −ρ(y)y and E
·
exp
µ
1
2
T
Z
0
u2(Y (s))ds
¶¸
< ∞.
(12.3.16)
If we as usual deﬁne the measure Q = Qu on FT by
dQ(ω) = exp
µ
−
T
Z
0
u(Y (t))dB(t) −1
2
T
Z
0
u2(Y (t))dt
¶
dP(ω) ,
(12.3.17)
then
eB(t) =
t
Z
0
u(Y (s))ds + B(t) .
(12.3.18)
is a Brownian motion with respect to Q and (12.3.15) gives
dη(t) =
n
X
i=1
∂g
∂zi
(t, Y (t))
m
X
j=1
σij(Y (t))d eBj(t) .
(12.3.19)
Now by (12.3.14) we have
η(T) = w(0, Y (T))=Ez[h(Z(0))]z=Y (T ) =h(z)z=Y (T ) =h(Y (T))
(12.3.20)
and
η(0) = w(T, Y (0)) = Ey[h(Z(T))] .
(12.3.21)
Hence by (12.3.19)–(12.3.21)

12.3 Option Pricing
273
h(Y (T)) = Ey[h(Z(T))] +
T
Z
0
(∇g)T (t, Y (t))σ(Y (t))d eB(t) .
(12.3.22)
By (12.3.10) and (12.3.18) Y (t) is a weak solution of
dY (t) = ρ(Y (t))Y (t)dt + σ(Y (t))d eB(t) .
Hence, by weak uniqueness (Lemma 5.3.1) we have
w(t, y) = Ey[h(Z(t))] = Ey
Q[h(Y (t))]
for all t .
(12.3.23)
Substituting this in (12.3.22) we get:
Theorem 12.3.3. Let Y (t) and Z(t) be as in (12.3.10) and (12.3.12), re-
spectively, and assume that h: Rn →R is as in (12.3.13). Assume that
(12.3.11) and (12.3.16) hold and deﬁne Q and eB(t) by (12.3.17) and (12.3.18).
Then
h(Y (T)) = Ey
Q[h(Y (T))] +
T
Z
0
φ(t, ω)d eB(t) ,
where φ = (φ1, . . . , φm), with
φj(t, ω) =
n
X
i=1
∂
∂yi
(Ey[h(Z(T −t))])y=Y (t)σij(Y (t)) ;
1≤j ≤m .
(12.3.24)
In particular, if ρ = b = 0 and σ = Im then u = 0, P = Q and Y (t) = Z(t) =
B(t). Hence we get the representation
h(B(T)) = Ey[h(B(T))] +
T
Z
0
m
X
j=1
∂
∂zj
Ez[h(B(T −t))]z=B(t)dBj(t) (12.3.25)
We summarize our results about pricing and hedging of European T-
claims as follows:
Theorem 12.3.4. Let {X(t)}t∈[0,T ] be a complete market. Suppose (12.2.12)
and (12.2.13) hold and let Q, eB be as in (12.2.2), (12.2.3). Let F be a Eu-
ropean T-claim such that EQ[ξ(T)F] < ∞. Then the price of the claim F
is
p(F) = EQ[ξ(T)F] .
(12.3.26)
Moreover, to ﬁnd a replicating (hedging) portfolio θ(t) = (θ0(t), . . . , θn(t)) for
the claim F we ﬁrst ﬁnd (for example by using Theorem 12.3.3 if possible)
φ ∈Wm such that

274
12. Application to Mathematical Finance
ξ(T)F = EQ[ξ(T)F] +
T
Z
0
φ(t, ω)d eB(t) .
(12.3.27)
Then we choose bθ(t) = (θ1(t), . . . , θn(t)) such that
bθ(t, ω)ξ(t, ω)σ(t, ω) = φ(t, ω)
(12.3.28)
and we choose θ0(t) as in (12.1.14).
Proof. (12.3.26) is just part b) of Theorem 12.3.2. The relation (12.3.28)
follows from (12.3.8). Note that the equation (12.3.28) has the solution
bθ(t, ω) = X0(t)φ(t, ω)Λ(t, ω)
(12.3.29)
where Λ(t, ω) is the left inverse of σ(t, ω) (Theorem 12.2.5).
⊔⊓
Example 12.3.5. Suppose the market is X0(t) = eρt, X1(t) = Y (t), where
ρ > 0 is constant and Y (t) is an Ornstein-Uhlenbeck process
dY (t) = αY (t)dt + σdB(t);
Y (0) = y
where α, σ are constants, σ ̸= 0. How do we hedge the claim
F(ω) = exp(Y (T)) ?
The portfolio θ(t) = (θ0(t), θ1(t)) that we seek is given by (12.3.29), i.e.
θ1(t, ω) = eρtσ−1φ(t, ω)
where φ(t, ω) and V (0) are uniquely given by (12.3.9), i.e.
ξ(T)F(ω) = z +
T
Z
0
φ(t, ω)d eB(t) .
To ﬁnd φ(t, ω) explicitly we apply Theorem 12.3.3: In this case we choose
h(y) = exp(y)e−ρT and dZ(t) = ρZ(t)dt + dB(t). Then (see Exercise 5.5)
Z(t) = Z(0)eρt + σ
t
Z
0
eρ(t−s)dB(s) .
Hence
eρT Ey
Q[h(Y (T −t))] = eρT Ey[h(Z(T −t))]
= Ey[exp(yeρ(T −t) + σ
T −t
Z
0
eρ(T −t−s)dB(s))]
= exp
³
yeρ(T −t) + σ2
4ρ(e2ρ(T −t) −1)
´
if ρ ̸= 0 .

12.3 Option Pricing
275
This gives
φ(t, ω) =
∂
∂y
³
exp
³
yeρ(T −t) + σ2
4ρ(e2ρ(T −t) −1)
´´
y=Y (t)σ e−ρT
= σe−ρt exp
n
Y (t)eρ(T −t) + σ2
4ρ(e2ρ(T −t) −1)
o
and hence, if ρ ̸= 0,
θ1(t) = exp
n
Y (t)eρ(T −t) + σ2
4ρ(e2ρ(T −t) −1)
o
.
If ρ = 0 then θ1(t) = exp
©
Y (t) + σ2
2 (T −t)
ª
.
The Generalized Black & Scholes Model
Let us now specialize to a situation where the market has just two securities
X0(t), X1(t) where X0, X1 are Itˆo processes of the form
dX0(t) = ρ(t, ω)X0(t)dt
(as before)
(12.3.30)
dX1(t) = α(t, ω)X1(t)dt + β(t, ω)X1(t)dB(t) ,
(12.3.31)
where B(t) is 1-dimensional and α(t, ω), β(t, ω) are 1-dimensional processes
in W.
Note that the solution of (12.3.31) is
X1(t) = X1(0) exp
µ
t
Z
0
β(s, ω)dB(s)+
t
Z
0
(α(s, ω)−1
2β2(s, ω))ds
¶
. (12.3.32)
The equation (12.2.12) gets the form
X1(t)β(t, ω)u(t, ω) = X1(t)α(t, ω) −X1(t)ρ(t, ω)
which has the solution
u(t, ω) = β−1(t, ω)[α(t, ω) −ρ(t, ω)]
if β(t, ω) ̸= 0 .
(12.3.33)
So (12.2.13) holds iﬀ
E
·
exp
µ
1
2
T
Z
0
(α(s, ω) −ρ(s, ω))2
β2(s, ω)
ds
¶¸
< ∞.
(12.3.34)
In this case we have an equivalent martingale measure Q given by (12.2.2)
and the market has no arbitrage, by Theorem 12.1.8. Moreover, the market
is complete by Corollary 12.2.5. Therefore we get by Theorem 12.3.2 that

276
12. Application to Mathematical Finance
the price at t = 0 of a European option with payoﬀgiven by a contingent
T-claim F is
p(F) = q(F) = EQ[ξ(T)F] ,
(12.3.35)
provided this quantity is ﬁnite.
Now suppose that ρ(t, ω) = ρ(t) and β(t, ω) = β(t) are deterministic and
that the payoﬀF(ω) has the form
F(ω) = f(X1(T, ω))
for some lower bounded function f: R →R such that
EQ[f(X1(T))] < ∞.
Then by (12.3.35) the price p = p(F) = q(F) is, with x1 = X1(0),
p = ξ(T)EQ
·
f
µ
x1 exp
µ
T
Z
0
β(s)d eB(s) +
T
Z
0
(ρ(s) −1
2β2(s))ds
¶¶¸
.
Under the measure Q the random variable Y =
TR
0
β(s)d eB(s) is normally
distributed with mean 0 and variance δ2: =
TR
0
β2(t)dt and therefore we can
write down a more explicit formula for p. The result is the following:
Theorem 12.3.6 (The generalized Black & Scholes formula).
Suppose X(t) = (X0(t), X1(t)) is given by
dX0(t) = ρ(t)X0(t)dt ;
X0(0) = 1
(12.3.36)
dX1(t) = α(t, ω)X1(t)dt + β(t)X1(t)dB(t) ;
X1(0) = x1 > 0
(12.3.37)
where ρ(t), β(t) are deterministic and
E
·
exp
µ
1
2
T
Z
0
(α(t, ω) −ρ(t))2
β2(t)
dt
¶¸
< ∞.
a) Then the market {X(t)} is complete and the price at time t = 0 of the
European T-claim F(ω) = f(X1(T, ω)) where EQ[f(X1(T, ω))] < ∞is
p = ξ(T)
δ
√
2π
Z
R
f
µ
x1 exp
·
y+
T
Z
0
(ρ(s)−1
2β2(s))ds
¸¶
exp
µ
−y2
2δ2
¶
dy
(12.3.38)
where ξ(T) = exp(−
TR
0
ρ(s)ds) and δ2 =
TR
0
β2(s)ds.

12.3 Option Pricing
277
b) If ρ, α, β ̸= 0 are constants and f ∈C1(R), then the self-ﬁnancing
portfolio θ(t) = (θ0(t), θ1(t)) needed to replicate the T-claim F(ω) =
f(X1(T, ω)) is given by
θ1(t, ω) =
1
p
2π(T −t)
Z
R
f ′(X1(t, ω) exp{βx + (ρ −1
2β2)(T −t)})
· exp
³
βx −
x2
2(T −t) −1
2β2(T −t)
´
dx
(12.3.39)
and θ0(t, ω) is given by (12.1.14).
Proof. Part a) is already proved and part b) follows from Theorem 12.3.3
and Theorem 12.3.4: (Strictly speaking condition (12.3.11) is not satisﬁed for
the process X1 (unless x is bounded away from 0), but in this case it can be
veriﬁed directly that u(t, z) given by (12.3.13) belongs to C1,2((0, ∞) × R),
so Theorem 12.3.3 is still valid.) The portfolio we seek is by (12.3.28) given
by
θ1(t, ω) = X0(t)(βX1(t, ω))−1φ(t, ω)
where φ(t, ω) is given by (12.3.24) with h(y) = e−ρT f(y) and
Y (t) = X1(t) = x1 exp{βB(t) + (α −1
2β2)t}
and
Zy(t) = y exp
n
βB(t) +
³
ρ −1
2β2´
t
o
.
Hence
θ1(t, ω) = eρt(βX1(t, ω))−1 ∂
∂y
£
Ey[e−ρT f(Z(T −t))]
¤
y=Y (t) · βX1(t, ω)
= eρ(t−T ) ∂
∂y E
£
f(y exp{βB(T −t) + (ρ −1
2β2)(T −t)})
¤
y=Y (t)
= eρ(t−T )E
£
f ′(y exp{βB(T −t) + (ρ −1
2β2)(T −t)})
· exp{βB(T −t) + (ρ −1
2β2)(T −t)}
¤
y=Y (t)
=
eρ(t−T )
p
2π(T −t)
Z
R
f ′(Y (t, ω) exp{βx + (ρ −1
2β2)(T −t)})
· exp{βx + (ρ −1
2β2)(T −t)}e
−
x2
2(T −t) dx ,
which is (12.3.39).
⊔⊓
American options
The diﬀerence between European and American options is that in the latter
case the buyer of the option is free to choose any exercise time τ before or at

278
12. Application to Mathematical Finance
the given expiration time T (and the guaranteed payoﬀmay depend on both
τ and ω.) This exercise time τ may be stochastic (depend on ω), but only in
such a way that the decision to exercise before or at a time t only depends
on the history up to time t. More precisely, we require that for all t we have
{ω; τ(ω) ≤t} ∈F(m)
t
.
In other words, τ must be an F(m)
t
-stopping time (Deﬁnition 7.2.1).
Deﬁnition 12.3.7. An American contingent T-claim is an F(m)
t
-adapted,
(t, ω)-measurable and a.s. lower bounded continuous stochastic process F(t) =
F(t, ω); t ∈[0, T], ω ∈Ω. An American option on such a claim F(t, ω)
gives the owner of the option the right (but not the obligation) to choose
any stopping time τ(ω) ≤T as exercise time for the option, resulting in a
payment F(τ(ω), ω) to the owner.
Let F(t) = F(t, ω) be an American contingent claim. Suppose you were
oﬀered a guarantee to be paid the amount F(τ(ω), ω) at the (stopping) time
τ(ω) ≤T that you are free to choose. How much would you be willing to pay
for such a guarantee? We repeat the argument preceding Deﬁnition 12.3.1:
If I – the buyer – pay the price y for this guarantee, then I will have an
initial fortune (debt) −y in my investment strategy. With this initial fortune
−y it must be possible to ﬁnd a stopping time τ ≤T and an admissible
portfolio θ such that
V θ
−y(τ(ω), ω) + F(τ(ω), ω) ≥0
a.s.
Thus the maximal price p = pA(F) the buyer is willing to pay is
(Buyer’s price of the American contingent claim F)
(12.3.40)
pA(F) = sup{y; There exists a stopping time τ ≤T
and an admissible portfolio θ such that
V θ
−y(τ(ω), ω): = −y +
τ(ω)
Z
0
θ(s)dX(s) ≥−F(τ(ω), ω) a.s.}
On the other hand, the seller could argue as follows: If I – the seller – receive
the price z for such a guarantee, then with this initial fortune z it must be
possible to ﬁnd an admissible portfolio θ which generates a value process
which at any time is not less than the amount promised to pay to the buyer:
V θ
z (t, ω) ≥F(t, ω)
a.s. for all t ∈[0, T] .
Thus the minimal price q = qA(F) the seller is willing to accept is

12.3 Option Pricing
279
(Seller’s price of the American contingent claim F)
(12.3.41)
qA(F) = inf{z; There exists an admissible portfolio θ
such that for all t ∈[0, T] we have
V θ
z (t, ω): = z +
t
Z
0
θ(s)dX(s) ≥F(t, ω) a.s.}
We can now prove a result analogous to Theorem 12.3.2. The result is basi-
cally due to Bensoussan (1984) and Karatzas (1988).

280
12. Application to Mathematical Finance
Theorem 12.3.8 (Pricing formula for American options).
a) Suppose (12.2.12) and (12.2.13) and let Q be as in (12.2.2). Let F(t) =
F(t, ω); t ∈[0, T] be an American contingent T-claim such that
sup
τ≤T
EQ[ξ(τ)F(τ)] < ∞
(12.3.42)
Then
pA(F) ≤sup
τ≤T
EQ[ξ(τ)F(τ)] ≤qA(F) ≤∞.
(12.3.43)
b) Suppose, in addition to the conditions in a), that the market {X(t)} is
complete. Then
pA(F) = sup
τ≤T
EQ[ξ(τ)F(τ)] = qA(F) .
(12.3.44)
Proof. a) We proceed as in the proof of Theorem 12.3.2: Suppose y ∈R and
there exists a stopping time τ ≤T and an admissible portfolio θ such that
V θ
−y(τ, ω) = −y +
τ
Z
0
θ(s)dX(s) ≥−F(τ)
a.s.
Then as before we get
−y +
τ
Z
0
n
X
i=1
θi(s)ξ(s)σi(s)d eB(s) ≥−ξ(τ)F(τ)
a.s.
Taking expectations with respect to Q we get
y ≤EQ[ξ(τ)F(τ)] ≤sup
τ≤T
EQ[ξ(τ)F(τ)] .
Since this holds for all such y we conclude that
pA(F) ≤sup
τ≤T
EQ[ξ(τ)F(τ)] .
(12.3.45)
Similarly, suppose z ∈R and there exists an admissible portfolio θ such that
V θ
z (t, ω) = z +
t
Z
0
θ(s)dX(s) ≥F(t)
a.s. for all t ∈[0, T] .
Then, as above, if τ ≤T is a stopping time we get
z +
τ
Z
0
n
X
i=1
θi(s)ξ(s)σi(s)d eB(s) ≥ξ(τ)F(τ)
a.s.

12.3 Option Pricing
281
Again, taking expectations with respect to Q and then supremum over τ ≤T
we get
z ≥sup
τ≤T
EQ[ξ(τ)F(τ)] .
Since this holds for all such z, we get
qA(F) ≥sup
τ≤T
EQ[ξ(τ)F(τ)] .
(12.3.46)
b) Next, assume in addition that the market is complete. Choose a stopping
time τ ≤T. Deﬁne
Fk(t) = Fk(t, ω) =
½
k
if
F(t, ω) ≥k
F(t, ω)
if
F(t, ω) < k
and put
Gk(ω) = X0(T)ξ(τ)Fk(τ) .
Then Gk is a bounded T-claim, so by completeness we can ﬁnd yk ∈R and
a portfolio θ(k) such that
−yk +
T
Z
0
θ(k)(s)dX(s) = −Gk(ω)
a.s.
and such that
−yk +
t
Z
0
θ(k)(s)dX(s)
is a Q-martingale. Then, by (12.2.8)–(12.2.9),
−yk +
T
Z
0
θ(k)(s)dX(s) = −ξ(T)Gk(ω) = −ξ(τ)Fk(τ)
and hence
−yk +
τ
Z
0
θ(k)(s)dX(s) = EQ
h
−yk +
T
Z
0
θ(k)(s)dX(s) | F(m)
τ
i
= EQ[−ξ(τ)Fk(τ) | F(m)
τ
] = −ξ(τ)Fk(τ) .
From this we get, again by (12.2.8)–(12.2.9),
−yk +
τ
Z
0
θ(k)(s)dX(s) = −Fk(τ)
a.s.

282
12. Application to Mathematical Finance
and
yk = EQ[ξ(τ)Fk(τ)] .
This shows that any price of the form EQ[ξ(τ)Fk(τ)] for some stopping time
τ ≤T would be acceptable for the buyer of an American option on the claim
Fk(t, ω). Hence
pA(F) ≥pA(Fk) ≥sup
τ≤T
EQ[ξ(τ)Fk(τ)] .
Letting k →∞we obtain by monotone convergence
pA(F) ≥sup
τ≤T
EQ[ξ(τ)F(τ)] .
It remains to show that if we put
z =
sup
0≤τ≤T
EQ[ξ(τ)F(τ)]
(12.3.47)
then there exists an admissible portfolio θ(s, ω) which superreplicates F(t, ω),
in the sense that
z +
t
Z
0
θ(s, ω)dX(s) ≥F(t, ω)
for a.a. (t, ω) ∈[0, T] × Ω.
(12.3.48)
The details of the proof of this can be found in Karatzas (1997), Theo-
rem 1.4.3. Here we only sketch the proof:
Deﬁne the Snell envelope
S(t) =
sup
t≤τ≤T
EQ[ξ(τ)F(τ)|F(m)
t
] ;
0 ≤t ≤T .
Then S(t) is a supermartingale w.r.t. Q and {F(m)
t
}, so by the Doob-Meyer
decomposition we can write
S(t) = M(t) −A(t) ;
0 ≤t ≤T
where M(t) is a Q, {F(m)
t
}-martingale with M(0) = S(0) = z and A(t) is a
nondecreasing process with A(0) = 0. It is a consequence of Lemma 12.2.1
that we can represent the martingale M as an Itˆo integral w.r.t eB. Hence
z +
t
Z
0
φ(s, ω)d eB(s) = M(t) = S(t) + A(t) ≥S(t) ;
0 ≤t ≤T
(12.3.49)
for some F(m)
t
-adapted process φ(s, ω). Since the market is complete, we
know by Theorem 12.2.5 that σ(t, ω) has a left inverse Λ(t, ω). So if we deﬁne
bθ = (θ1, . . . , θn) by

12.3 Option Pricing
283
bθ(t, ω) = X0(t)φ(t, ω)Λ(t, ω)
then by (12.3.49) and Lemma 12.2.4 we get
z +
t
Z
0
bθ dX = z +
t
Z
0
n
X
i=1
ξθiσid eB = z +
t
Z
0
φ d eB ≥S(t) ;
0 ≤t ≤T .
Hence, by Lemma 12.2.3,
z +
t
Z
0
θ(s, ω)dX(s) ≥X0(t)S(t) ≥X0(t)ξ(t)F(t) = F(t) ;
0 ≤t ≤T .
⊔⊓
The Itˆo Diﬀusion Case: Connection to Optimal Stopping
Theorem 12.3.8 shows that pricing an American option is an optimal stopping
problem. In the general case the solution to this problem can be expressed
in terms of the Snell envelope. See e.g. El Karoui (1981) and Fakeev (1970).
In the Itˆo diﬀusion case we get an optimal stopping problem of the type
discussed in Chapter 10. We now consider this case in more detail:
Assume the market is an (n + 1)-dimensional Itˆo diﬀusion X(t) =
(X0(t), X1(t), . . . , Xn(t)); t ≥0 of the form (see (12.1.1)–(12.1.2))
dX0(t) = ρ(t, X(t))X0(t)dt ;
X0(0) = 1
(12.3.50)
and
dXi(t) = µi(t, X(t))dt +
m
X
j=1
σij(t, X(t))dBj(t)
(12.3.51)
= µi(t, X(t))dt + σi(t, X(t))dB(t) ;
Xi(0) = xi ,
where ρ, µi and σij are given functions satisfying the conditions of Theo-
rem 5.2.1.
Further, assume that the conditions corresponding to (12.2.12)–(12.2.13)
are satisﬁed, i.e. there exists u(t, x) ∈Rm×1 such that, for all t, x =
(x0, x1, . . . , xn),
σi(t, x)u(t, x) = µi(t, x) −ρ(t, x)xi
for i = 1, . . . , n .
(12.3.52)
and
Exh
exp
µ
1
2
T
Z
0
u2(t, X(t))dt
¶i
< ∞
for all x
(12.3.53)
where as usual Ex denotes the expectation w.r.t. the law of Xt when starting
at x = (1, x1, . . . , xn). For 0 ≤t ≤T put

284
12. Application to Mathematical Finance
M(t) = M(t, ω) = exp
µ
−
t
Z
0
u(s, X(s))dB(s)−1
2
t
Z
0
u2(s, X(s))ds
¶
(12.3.54)
and deﬁne, as in (12.2.2), the probability measure Q on F(m)
T
by
dQ(ω) = M(T, ω)dP(ω) .
(12.3.55)
Now assume that F(t, ω) is an American contingent T-claim of Markovian
type, i.e.
F(t, ω) = g(t, X(t, ω))
(12.3.56)
for some continuous, lower bounded function g: R × Rn+1 →R. Then if
the market {X(t)}t∈[0,T ] is complete, the price pA(F) of this claim is by
Theorem 12.3.8 given by
pA(F) = sup
τ≤T
EQ[ξ(τ)g(τ, X(τ))] = sup
τ≤T
E[M(T)ξ(τ)g(τ, X(τ))]
= sup
τ≤T
E[E[M(T)ξ(τ)g(τ, X(τ))|Fτ]]
= sup
τ≤T
E[ξ(τ)g(τ, X(τ))E[M(T)|Fτ]]
= sup
τ≤T
E[M(τ)ξ(τ)g(τ, X(τ))]
(12.3.57)
where we have used that M(t) is a P-martingale and Doob’s optional sam-
pling theorem (see Gihman and Skorohod (1975, Theorem 6, p. 11)). Deﬁne
K(t) = M(t)ξ(t) = exp
µ
−
t
Z
0
u(s, X(s)dB(s)
−
t
Z
0
£ 1
2u2(s, X(s)) + ρ(s, X(s))
¤
ds
¶
.
(12.3.58)
Then
dK(t) = −ρ(t, X(t))K(t)dt −u(t, X(t))K(t)dB(t) .
Hence if we deﬁne the (n + 3) – dimensional Itˆo diﬀusion Y (t) by
dY (t)=


dt
dK(t)
dX(t)

=


dt
dK(t)
dX0(t)
dX1(t)
...
dXn(t)


=


1
−ρK
ρX0
µ1
...
µn


dt +


0
−uK
0
σ1
...
σn


dB(t) ;
Y (0) = y
(12.3.59)

12.3 Option Pricing
285
we see that
pA(F) = sup
τ≤T
E[G(Y (τ))] ,
(12.3.60)
where
G(y) = G(s, k, x) = kg(s, x) ;
y = (s, k, x) ∈R × R × Rn+1 .
We have proved:
Theorem 12.3.9. The price pA(F) of an American contingent T-claim F of
the Markovian form (12.3.56) is the solution of the optimal stopping problem
(12.3.60), with Itˆo diﬀusion Y (t) given by (12.3.59).
We recognize (12.3.60) as a special case of the optimal stopping problem
considered in Theorem 10.4.1. We can therefore use the method there to
evaluate pA(F) in special cases.
Example 12.3.10. Consider the Black and Scholes market
dX0(t) = ρX0(t)dt ;
X0(0) = 1
dX1(t) = αX1(t)dt + βX1(t)dB(t) ;
X1(0) = x1 > 0 .
where ρ, α, β are constants, β ̸= 0. Then equation (12.3.52) becomes
βx1u(x1) = αx1 −ρx1
i.e.
u(x1) = u = α −ρ
β
for all x1 .
Hence
K(t) = exp
µ
−α −ρ
β
B(t) −
½
1
2
µα −ρ
β
¶2
+ ρ
¾
t
¶
.
Suppose the American claim is given by
F(t, ω) = g(t, X1(t))
for some continuous lower bounded function g(t, x1). Then the price of the
American option is
pA(F) = sup
τ≤T
E[K(τ)g(τ, X1(τ))] .
If we regard this price pA(F) as a function Φ(s, k, x) of the starting point y =
(s, k, x) of the process dY (t) = (dt, dK(t), dX(t)), then to ﬁnd Φ it suﬃces
to ﬁnd a function φ(s, k, x) which satisﬁes the conditions of Theorem 10.4.1.
In this case f = 0 and

286
12. Application to Mathematical Finance
Lφ(s, k, x) = ∂φ
∂s −ρk ∂φ
∂k + ρx0
∂φ
∂x0
+ αx1
∂φ
∂x1
+ 1
2
µα −ρ
β
¶2
k2 ∂2φ
∂k2 −(α −ρ)kx1
∂2φ
∂k∂x1
+ 1
2β2x2
1
∂2φ
∂x2
1
.
If T < ∞then we cannot factor out the dependence on time s as we often
did in Chapter 10. Therefore the problem of ﬁnding φ is much harder in this
case. To illustrate the diﬃculty let us simplify even further by assuming that
α = ρ
(so that P = Q)
and that
g(t, x1) = (a −x1)+
where a > 0 is a constant .
Then the problem becomes to ﬁnd the American put option price
pA(F) = sup
τ≤T
E[e−ρτ(a −X1(τ))+] ,
(12.3.61)
which is related to the ﬁnite horizon version of Example 10.2.2 (and Exam-
ple 10.4.2). A description of the American put option is as follows: The owner
of this option has the right (but not the obligation) to sell one stock at a
speciﬁed price a at any time τ he chooses before or at the terminal time T. If
he sells at a time τ ≤T when the market price is X1(τ) < a, he increases his
fortune with the diﬀerence a−X1(τ). Thus (12.3.61) represents the maximal
expected discounted payoﬀto the owner of the option.
In this case we can disregard the variables k and x0, so we search for a
function φ(s, x1) ∈C1(R2) satisfying the variational inequalities (see Theo-
rem 10.4.1)
φ(s, x1) ≥e−ρs(a −x1)+
for all s, x1
(12.3.62)
∂φ
∂s + ρx1
∂φ
∂x1
+ 1
2β2x2
1
∂2φ
∂x2
1
≤0
outside D
(12.3.63)
and
∂φ
∂s + ρx1
∂φ
∂x1
+ 1
2β2x2
1
∂2φ
∂x2
1
= 0
on D ,
(12.3.64)
where
D = {(s, x1); φ(s, x1) > e−ρs(a −x1)+}
(12.3.65)
is the continuation region.
If such a φ is found, and the additional assumptions of Theorem 10.4.1
hold, then we can conclude that
φ(s, x1) = Φ(s, x1)
and hence pA(F) = φ(0, x1) is the option price at time t = 0. Moreover,

12.3 Option Pricing
287
τ ∗= τD = inf{t > 0; (s + t, X1(t)) ̸∈D}
is the corresponding optimal stopping time, i.e. the optimal time to exercise
the American option. Unfortunately, even in this case it seems that an explicit
analytic solution is very hard (possibly impossible) to ﬁnd. However, there
are interesting partial results and good approximation procedures. See e.g.
Barles et al. (1995), Bather (1997), Jacka (1991), Karatzas (1997), Musiela
and Rutkowski (1997) and the references therein. For example, it is known
(see Jacka (1991)) that the continuation region D has the form
D = {(t, x1) ∈(0, T) × R , x1 > f(t)} ,
i.e. D is the region above the graph of f, for some continuous, increasing
function f: (0, T) →R. Thus the problem is to ﬁnd the function f. In Barles
et al. (1995) it is shown that
f(t) ∼a −βa
p
(T −t)| ln(T −t)|
as t →T −,
in the sense that
f(t) −a
−βa
p
(T −t)| ln(T −t)|
→1
as t →T −.
This indicates that the continuation region has the shape shown in the ﬁgure.
But its exact form is still unknown.
For the corresponding American call option the situation is much simpler.
See Exercise 12.14.

288
12. Application to Mathematical Finance
Exercises
12.1. a) Prove that the price process {X(t)}t∈[0,T ] has an arbitrage iﬀthe
normalized price process {X(t)}t∈[0,T ] has an arbitrage.
b) Suppose {X(t)}t∈[0,T ] is normalized. Prove that {X(t)}t∈[0,T ] has
an arbitrage iﬀthere exists an admissible portfolio θ such that
V θ(0) ≤V θ(T)
a.s. and
P[V θ(T) > V θ(0)] > 0 .
(12.3.66)
In other words, in normalized markets it is not essential that we
require V θ(0) = 0 for an arbitrage θ, only that the gains V θ(T) −
V θ(0) is nonnegative a.s. and positive with positive probability.
(Hint: If θ is as in (12.3.66) deﬁne eθ(t) = (eθ0(t), . . . , eθn(t)) as fol-
lows:
Let eθi(t) = θ(t) for i = 1, . . . , n; t ∈[0, T]. Then choose eθ0(0) such
that V eθ(0) = 0 and deﬁne eθ0(t) according to (12.1.15) to make eθ
self-ﬁnancing. Then
V eθ(t)= eθ(t) · X(t)=
t
Z
0
eθ(s)dX(s)=
t
Z
0
θ(s)dX(s)=V θ(t) −V θ(0) .)
12.2. Let θ(t) = (θ0, . . . , θn) be a constant portfolio.
Prove that θ is self-ﬁnancing.
12.3. Suppose {X(t)} is a complete normalized market and that (12.2.12)
and (12.2.13) hold. Suppose n = m and that σ is invertible with a
bounded inverse. Then any lower bounded claim F such that
EQ[F 2] < ∞
is attainable.
(Hint: Use the argument in the proof of Theorem 12.2.5: Choose
bounded T-claims Fk such that
Fk →F
in L2(Q)
and
E[Fk] = E[F] .
By completeness there exist admissible portfolios θ(k) = (θ(k)
0 , . . . , θ(k)
n )
and constants Vk(0) such that
Fk(ω) = Vk(0) +
T
Z
0
θ(k)(s)dX(s) = Vk(0) +
T
Z
0
bθ(k)(s)σ(s)d eB(s)
where bθ(k) = (θ(k)
1 , . . . , θ(k)
n ). It follows that Vk(0) = EQ[Fk] →EQ[F]
as k →∞.

Exercises
289
By the Itˆo isometry the sequence {bθ(k)σ}k is a Cauchy sequence in
L2(λ × Q) and hence converges in this space. Conclude that there
exists an admissible θ such that
F(ω) = EQ[F] +
T
Z
0
θ(s)dX(s) .)
12.4. Let B(t) be 1-dimensional Brownian motion. Show that there exist
θ1(t, ω), θ2(t, ω) ∈W such that if we deﬁne
V1(t) = 1+
t
Z
0
θ1(s, ω)dB(s),
V2(t) = 2+
t
Z
0
θ2(s, ω)dB(s) ;
t ∈[0, 1]
then
V1(1) = V2(1) = 0
and
V1(t) ≥0 ,
V2(t) ≥0
for a.a. (t, ω).
Therefore both θ1(t, ω) and θ2(t, ω) are admissible portfolios for the
claim F(ω) = 0 in the normalized market with n = 1 and X1(t) = B(t).
In particular, if we drop the martingale condition in Deﬁnition 12.2.4b)
we have no uniqueness of replicating portfolios, even if we require the
portfolio to be admissible. (Note, however, that we have uniqueness if
we require that θ ∈V(0, 1), by Theorem 4.3.3).
(Hint: Use Example 12.1.4 with a = −1 and with a = −2. Then deﬁne,
for i = 1, 2,
θi(t) =
(
1
√1−t
for 0 ≤t < α−i
0
for α−i ≤t ≤1
and
Vi(t) = i +
t
Z
0
θi(s)dB(s) = i + Y (t ∧α−i) ;
0 ≤t ≤1 .)
12.5. Prove the ﬁrst part of Lemma 12.2.2, i.e. that eB(t) given by (12.2.3)
is an F(m)
t
-martingale (see the Remark b) following this lemma).
12.6. Determine if the following normalized markets {X(t)}t∈[0,T ] allow an
arbitrage. If so, ﬁnd one.
a) (n = m = 2)
dX1(t) = 3dt + dB1(t) + dB2(t),
dX2(t) = −dt + dB1(t) −dB2(t).

290
12. Application to Mathematical Finance
b) (n = 2, m = 3)
dX1(t) = dt + dB1(t) + dB2(t) −dB3(t)
dX2(t) = 5dt −dB1(t) + dB2(t) + dB3(t)
c) (n = 2, m = 3)
dX1(t) = dt + dB1(t) + dB2(t) −dB3(t)
dX2(t) = 5dt −dB1(t) −dB2(t) + dB3(t)
d) (n = 2, m = 3)
dX1(t) = dt + dB1(t) + dB2(t) −dB3(t)
dX2(t) = −3dt −3dB1(t) −3dB2(t) + 3dB3(t)
e) (n = 3, m = 2)
dX1(t) = dt + dB1(t) + dB2(t)
dX2(t) = 2dt + dB1(t) −dB2(t)
dX3(t) = 3dt −dB1(t) + dB2(t)
f) (n = 3, m = 2)
dX1(t) = dt + dB1(t) + dB2(t)
dX2(t) = 2dt + dB1(t) −dB2(t)
dX3(t) = −2dt −dB1(t) + dB2(t)
12.7. Determine which of the nonarbitrage markets {X(t)}t∈[0,T ] of Exer-
cise 12.6 a)–f) are complete. For those which are not complete, ﬁnd a
T-claim which is not attainable.
12.8. Let Bt be 1-dimensional Brownian motion. Use Theorem 12.3.3 to ﬁnd
z ∈R and φ(t, ω) ∈V(0, T) such that
F(ω) = z +
T
Z
0
φ(t, ω)dB(t)
in the following cases:
(i)
F(ω) = B2(T, ω)
(ii) F(ω) = B3(T, ω)
(iii) F(ω) = exp B(T, ω).
(Compare with the methods you used in Exercise 4.14.)
12.9. Let Bt be n-dimensional Brownian motion. Use Theorem 12.3.3 to ﬁnd
z ∈R and φ(t, ω) ∈Vn(0, T) such that
F(ω) = z +
T
Z
0
φ(t, ω)dB(t)
in the following cases
(i) F(ω) = B2(T, ω) (= B2
1(T, ω) + · · · + B2
n(T, ω))
(ii) F(ω) = exp(B1(T, ω) + · · · + Bn(T, ω)).

Exercises
291
12.10. Let X(t) be a geometric Brownian motion given by
dX(t) = αX(t)dt + βX(t)dB(t) ,
where α and β are constants. Use Theorem 12.3.3 to ﬁnd z ∈R and
φ(t, ω) ∈V(0, T) such that
X(T, ω) = z +
T
Z
0
φ(t, ω)dB(t) .
12.11. Suppose the market is given by
dX0(t) = ρX0(t)dt ;
X0(0) = 1
dX1(t) = (m −X1(t))dt + σdB(t) ;
X1(0) = x1 > 0 .
(the mean-reverting Ornstein-Uhlenbeck process) where ρ > 0, m > 0
and σ ̸= 0 are constants.
a) Find the price EQ[ξ(T)F] of the European T-claim
F(ω) = X1(T, ω) .
b) Find the replicating portfolio θ(t) = (θ0(t), θ1(t)) for this claim.
(Hint: Use Theorem 12.3.4, as in Example 12.3.5.)
12.12. Consider a market (X0(t), X1(t)) ∈R2 where
dX0(t) = ρX0(t)dt ;
X0(0) = 1
ρ > 0 constant) .
Find the price EQ[ξ(T)F] of the European T-claim
F(ω) = B(T, ω)
and ﬁnd the corresponding replicating portfolio θ(t) = (θ0(t), θ1(t)) in
the following cases
a) dX1(t) = αX1(t)dt + βX1(t)dB(t);
α, β constants, β ̸= 0
b) dX1(t) = c dB(t) ;
c ̸= 0 constant
c) dX1(t) = αX1(t)dt + σ dB(t) ;
α, σ constants, σ ̸= 0.
12.13. (The classical Black & Scholes formula).
Suppose X(t) = (X0(t), X1(t)) is given by
dX0(t) = ρX0(t)dt ;
X0(0) = 1
dX1(t) = αX1(t)dt + βX1(t)dB(t) ;
X1(0) = x1 > 0
where ρ, α, β are constants, β ̸= 0. Moreover, suppose that the Euro-
pean T-claim is the European call, deﬁned by

292
12. Application to Mathematical Finance
F(ω) = (X1(T, ω) −K)+ =
½
X1(T, ω) −K if X1(T, ω) > K
0
if X1(T, ω) ≤K
where K > 0 is a given constant (the exercise price). Prove that in
this case the option pricing formula (12.3.38) of Theorem 12.3.6 can
be written
p = x1Φ(u) −e−ρT KΦ(u −β
√
T )
(12.3.67)
where
Φ(u) =
1
√
2π
u
Z
−∞
e
−x2
2 dx
(12.3.68)
is the distribution function of the standard normal density and
u = ln( x1
K ) + (ρ + 1
2β2)T
β
√
T
.
(12.3.69)
This is the celebrated Black & Scholes formula (Black and Scholes
(1973)), which is of fundamental importance in today’s ﬁnance.
12.14. (The American call)
Let X(t) = (X0(t), X1(t)) be as in Exercise 12.13. If the American
T-claim is given by
F(t, ω) = (X1(t, ω) −K)+ ,
0 ≤t ≤T ,
then the corresponding option is called the American call.
According to Theorem 12.3.8 the price of an American call is given by
pA(F) = sup
τ≤T
EQ[e−ρτ(X1(τ) −K)+] .
Prove that
pA(F) = e−ρT EQ[(X1(T) −K)+] ,
i.e. that it is always optimal to exercise the American call at the ter-
minal time T, if at all. Hence the price of an American call option
coincides with that of a European call option.
(Hint: Deﬁne
Y (t) = e−ρt(X1(t) −K) .
a) Prove that Y (t) is a Q-submartingale (Appendix C), i.e.
Y (t) ≤EQ[Y (s)|Ft]
for s > t .
b) Then use the Jensen inequality (Appendix B) to prove that
Z(t): = e−ρt(X1(t) −K)+
is also a Q-submartingale.

Exercises
293
c) Complete the proof by using Doob’s optional sampling theorem (see
the proof of Lemma 10.1.3 e)).
12.15. (The perpetual American put)
Solve the optimal stopping problem
Φ(s, x) = sup
τ≥0
Ex[e−ρ(s+τ)(a −X(τ))+]
where
dX(t) = αX(t)dt + βX(t)dB(t) ;
X(0) = x > 0 .
Here ρ > 0, a > 0, α and β ̸= 0 are constants.
If α = ρ then Φ(s, x) gives the price of the American put option with
inﬁnite horizon (T = ∞). (Hint: Proceed as in Example 10.4.2.)

294
12. Application to Mathematical Finance

Appendix A: Normal Random Variables
Here we recall some basic facts which are used in the text.
Deﬁnition A.11. Let (Ω, F, P) be a probability space. A random variable
X: Ω→R is normal if the distribution of X has a density of the form
pX(x) =
1
σ
√
2π · exp
µ
−(x −m)2
2σ2
¶
,
(A.1)
where σ > 0 and m are constants. In other words,
P[X ∈G] =
Z
G
pX(x)dx ,
for all Borel sets G ⊂R .
If this is the case, then
E[X] =
Z
Ω
XdP =
Z
R
xpX(x)dx = m
(A.2)
and
var[X] = E[(X −m)2] =
Z
R
(x −m)2pX(x)dx = σ2 .
(A.3)
More generally, a random variable X: Ω→Rn is called (multi-) normal
N(m, C) if the distribution of X has a density of the form
pX(x1, · · · , xn) =
p
|A|
(2π)n/2 · exp
µ
−1
2 ·
X
j,k
(xj −mj)ajk(xk −mk)
¶
(A.4)
where m = (m1, · · · , mn) ∈Rn and C−1 = A = [ajk] ∈Rn×n is a symmetric
positive deﬁnite matrix.
If this is the case then
E[X] = m
(A.5)
and
A−1 = C = [cjk]
is the covariance matrix of X, i.e.
cjk = E[(Xj −mj)(Xk −mk)] .
(A.6)

296
Appendix A: Normal Random Variables
Deﬁnition A.12. The characteristic function of a random variable
X: Ω→Rn is the function φX: Rn →C (where C denotes the complex
numbers) deﬁned by
φX(u1, · · · , un)=E[exp(i(u1X1+· · ·+unXn))]=
Z
Rn
ei⟨u,x⟩·P[X ∈dx] , (A.7)
where ⟨u, x⟩= u1x1 + · · · + unxn (and i ∈C is the imaginary unit). In other
words, φX is the Fourier transform of X (or, more precisely, of the measure
P[X ∈dx]). Therefore we have
Theorem A.13. The characteristic function of X determines the distribu-
tion of X uniquely.
It is not hard to verify the following:
Theorem A.14. If X: Ω→Rn is normal N(m, C), then
φX(u1, · · · , un) = exp
µ
−1
2
X
j,k
ujcjkuk + i
X
j
ujmj
¶
.
(A.8)
Theorem A.4 is often used as a basis for an extended concept of a normal
random variable: We deﬁne X: Ω→Rn to be normal (in the extended sense)
if φX satisﬁes (A.8) for some symmetric non-negative deﬁnite matrix C =
[cjk] ∈Rn×n and some m ∈Rn. So by this deﬁnition it is not required that C
be invertible. From now on we will use this extended deﬁnition of normality.
In the text we often use the following result:
Theorem A.15. Let Xj: Ω→R be random variables; 1 ≤j ≤n. Then
X = (X1, · · · , Xn)
is normal
if and only if
Y = λ1X1 + · · · + λnXn
is normal for all λ1, . . . , λn ∈R .
Proof. If X is normal, then
E[exp(iu(λ1X1 + · · · + λnXn))] = exp
µ
−1
2
X
j,k
uλjcjkuλk + i
X
j
uλjmj
¶
= exp
µ
−1
2u2 X
j,k
λjcjkλk + iu
X
j
λjmj
¶
,
so Y is normal with E[Y ] = P λjmj, var[Y ] = P λjcjkλk.
Conversely, if Y = λ1X1 + · · · + λnXn is normal with E[Y ] = m and
var[Y ] = σ2, then

Appendix A: Normal Random Variables
297
E[exp(iu(λ1X1 + · · · + λnXn))] = exp(−1
2u2σ2 + ium) ,
where
m =
X
j
λjE[Xj], σ2 = E
·µ X
j
λjXj −
X
j
λjE[Xj]
¶2¸
= E
·µ X
j
λj(Xj −mj)
¶2¸
=
X
j,k
λjλkE[(Xj −mj)(Xk −mk)] ,
where mj = E[Xj]. Hence X is normal.
Theorem A.16. Let Y0, Y1, . . . , Yn be real, random variables on Ω. Assume
that X = (Y0, Y1, . . . , Yn) is normal and that Y0 and Yj are uncorrelated for
each j ≥1, i.e
E[(Y0 −E[Y0])(Yj −E[Yj])] = 0 ;
1 ≤j ≤n .
Then Y0 is independent of {Y1, · · · , Yn}.
Proof. We have to prove that
P[Y0 ∈G0, Y1 ∈G1, . . . , Yn ∈Gn] = P[Y0 ∈G0] · P[Y1 ∈G1, . . . , Yn ∈Gn] ,
(A.9)
for all Borel sets G0, G1, . . . , Gn ⊂R.
We know that in the ﬁrst line (and the ﬁrst column) of the covariance
matrix cjk = E[(Yj −E[Yj])(Yk −E[Yk])] only the ﬁrst entry c00 = var[Y0],
is non-zero. Therefore the characteristic function of X satisﬁes
φX(u0, u1, . . . , un) = φY0(uo) · φ(Y1,...,Yn)(u1, . . . , un)
and this is equivalent to (A.9).
Finally we establish the following:
Theorem A.17. Suppose Xk: Ω→Rn is normal for all k and that Xk →X
in L2(Ω), i.e.
E[|Xk −X|2] →0
as k →∞.
Then X is normal.
Proof. Since |ei⟨u,x⟩−ei⟨u,y⟩| < |u| · |x −y|, we have
E[{exp(i⟨u, Xk⟩) −exp(i⟨u, X⟩)}2] ≤|u|2 · E[|Xk −X|2] →0
as k →∞.
Therefore
E[exp(i⟨u, Xk⟩)] →E[exp(i⟨u, X⟩)]
as k →∞.
So X is normal, with mean E[X] = lim E[Xk] and covariance matrix
C = lim Ck, where Ck is the covariance matrix of Xk.

298
Appendix A: Normal Random Variables

Appendix B: Conditional Expectation
Let (Ω, F, P) be a probability space and let X: Ω→Rn be a random vari-
able such that E[|X|] < ∞. If H ⊂F is a σ-algebra, then the conditional
expectation of X given H, denoted by E[X|H], is deﬁned as follows:
Deﬁnition B.1. E[X|H] is the (a.s. unique) function from Ωto Rn satis-
fying:
(1) E[X|H] is H-measurable
(2)
R
H
E[X|H]dP =
R
H
XdP, for all H ∈H.
The existence and uniqueness of E[X|H] comes from the Radon-Nikodym
theorem: Let µ be the measure on H deﬁned by
µ(H) =
Z
H
XdP ;
H ∈H .
Then µ is absolutely continuous w.r.t. P|H, so there exists a P|H-unique
H-measurable function F on Ωsuch that
µ(H) =
Z
H
FdP
for all H ∈H .
Thus E[X|H]: = F does the job and this function is unique a.s. w.r.t. the
measure P|H.
Note that (2) is equivalent to
(2)’
Z
Ω
Z · E[X|H]dP =
Z
Ω
Z · XdP
for all H-measurable Z .
We list some of the basic properties of the conditional expectation:
Theorem B.2. Suppose Y : Ω→Rn is another random variable with
E[|Y |] < ∞and let a, b ∈R. Then
a) E[aX + bY |H] = aE[X|H] + bE[Y |H]
b) E[E[X|H]] = E[X]
c) E[X|H] = X if X is H-measurable

300
Appendix B: Conditional Expectation
d) E[X|H] = E[X] if X is independent of H
e) E[Y · X|H] = Y · E[X|H] if Y is H-measurable, where · denotes the usual
inner product in Rn.
Proof. d): If X is independent of H we have for H ∈H
Z
H
XdP =
Z
Ω
X · XHdP =
Z
Ω
XdP ·
Z
Ω
XHdP = E[X] · P(H) ,
so the constant E[X] satisﬁes (1) and (2).
e): We ﬁrst establish the result in the case when Y = XH (where X denotes
the indicator function), for some H ∈H.
Then for all G ∈H
Z
G
Y · E[X|H]dP =
Z
G∩H
E[X|H]dP =
Z
G∩H
XdP =
Z
G
Y XdP ,
so Y · E[X|H] satisﬁes both (1) and (2). Similarly we obtain that the
result is true if Y is a simple function
Y =
m
X
j=1
cjXHj ,
where Hj ∈H .
The result in the general case then follows by approximating Y by such
simple functions.
⊔⊓
Theorem B.3. Let G, H be σ-algebras such that G ⊂H. Then
E[X|G] = E[E[X|H]|G] .
Proof. If G ∈G then G ∈H and therefore
Z
G
E[X|H]dP =
Z
G
XdP .
Hence E[E[X|H]|G] = E[X|G] by uniqueness.
⊔⊓
The following useful result can be found in Chung (1974), Theorem 9.1.4:
Theorem B.4 (The Jensen inequality).
If φ: R →R is convex and E[|φ(X)|] < ∞then
φ(E[X|H]) ≤E[φ(X)|H] .
Corollary B.5. (i) |E[X|H]| ≤E[|X| | H]
(ii) |E[X|H]|2 ≤E[|X|2 | H] .
Corollary B.6. If Xn →X in L2 then E[Xn | H] →E[X | H] in L2.

Appendix C: Uniform Integrability and
Martingale Convergence
We give a brief summary of the deﬁnitions and results which are the back-
ground for the applications in this book. For proofs and more information we
refer to Doob (1984), Liptser and Shiryaev (1977), Meyer (1966) or Williams
(1979).
Deﬁnition C.1. Let (Ω, F, P) be a probability space. A family {fj}j∈J of
real, measurable functions fj on Ωis called uniformly integrable if
lim
M→∞
µ
sup
j∈J
½
Z
{|fj|>M}
|fj|dP
¾¶
= 0 .
One of the most useful tests for uniform integrability is obtained by using
the following concept:
Deﬁnition C.2. A function ψ: [0, ∞) →[0, ∞) is called a u.i. (uniform in-
tegrability) test function if ψ is increasing, convex (i.e. ψ(λx + (1 −λ)y) ≤
λψ(x) + (1 −λ)ψ(y) for all x, y ∈[0, ∞), λ ∈[0, 1]) and
lim
x→∞
ψ(x)
x
= ∞.
So for example ψ(x) = xp is a u.i. test function if p > 1, but not if p = 1.
The justiﬁcation for the name in Deﬁnition C.2 is the following:
Theorem C.3. The family {fj}j∈J is uniformly integrable if and only if
there is a u.i. test function ψ such that
sup
j∈J
½ Z
ψ(|fj|)dP
¾
< ∞.
One major reason for the usefulness of uniform integrability is the fol-
lowing result, which may be regarded as the ultimate generalization of the
various convergence theorems in integration theory:
Theorem C.4. Suppose {fk}∞
k=1 is a sequence of real measurable functions
on Ωsuch that

302
Appendix C: Uniform Integrability and Martingale Convergence
lim
k→∞fk(ω) = f(ω)
for a.a. ω .
Then the following are equivalent:
1)
{fk} is uniformly integrable
2)
f ∈L1(P) and fk →f in L1(P), i.e.
R
|fk −f|dP →0 as k →∞.
An important application of uniform integrability is within the conver-
gence theorems for martingales:
Let (Ω, N, P) be a probability space and let {Nt}t≥0 be an increasing
family of σ-algebras, Nt ⊂N for all t. A stochastic process Nt: Ω→R is
called a supermartingale (w.r.t. {Nt}) if Nt is Nt-adapted, E[|Nt|] < ∞for
all t and
Nt ≥E[Ns|Nt]
for all s > t .
(C.1)
Similarly, if (C.1) holds with the inequality reversed for all s > t, then Nt is
called a submartingale. And if (C.1) holds with equality then Nt is called a
martingale.
As in customary we will assume that each Nt contains all the null sets
of N, that t →Nt(ω) is right continuous for a.a.ω and that {Nt} is right
continuous, in the sense that Nt = T
s>t
Ns for all t ≥0.
Theorem C.5 (Doob’s martingale convergence theorem I).
Let Nt be a right continuous supermartingale with the property that
sup
t>0
E[N −
t ] < ∞,
where N −
t = max(−Nt, 0). Then the pointwise limit
N(ω) = lim
t→∞Nt(ω)
exists for a.a. ω and E[N −] < ∞.
Note, however, that the convergence need not be in L1(P). In order to
obtain this we need uniform integrability:
Theorem C.6 (Doob’s martingale convergence theorem II).
Let Nt be a right-continuous supermartingale. Then the following are equiv-
alent:
1) {Nt}t≥0 is uniformly integrable
2) There exists N ∈L1(P) such that Nt →N a.e. (P) and Nt →N in
L1(P), i.e.
R
|Nt −N|dP →0 as t →∞.
Combining Theorems C.6 and C.3 (with ψ(x) = xp) we get

Appendix C: Uniform Integrability and Martingale Convergence
303
Corollary C.7. Let Mt be a continuous martingale such that
sup
t>0
E[|Mt|p] < ∞
for some p > 1 .
Then there exists M ∈L1(P) such that Mt →M a.e. (P) and
Z
|Mt −M|dP →0
as t →∞.
Finally, we mention that similar results can be obtained for the analogous
discrete time super/sub-martingales {Nk, Nk}, k = 1, 2, . . .. Of course, no
continuity assumptions are needed in this case. For example, we have the
following result, which is used in Chapter 9:
Corollary C.8. Let Mk; k = 1, 2, . . . be a discrete time martingale and as-
sume that
sup
k
E[|Mk|p] < ∞
for some p > 1 .
Then there exists M ∈L1(P) such that Mk →M a.e. (P) and
Z
|Mk −M|dP →0
as k →∞.
Corollary C.9. Let X ∈L1(P), let {Nk}∞
k=1 be an increasing family of σ-
algebras, Nk ⊂F and deﬁne N∞to be the σ-algebra generated by {Nk}∞
k=1.
Then
E[X|Nk] →E[X|N∞]
as k →∞,
a.e. P and in L1(P).
Proof. Mk: = E[X|Nk] is a u.i. martingale, so there exists M ∈L1(P) such
that Mk →M a.e. P and in L1(P), as k →∞. It remains to prove that
M = E[X|N∞]: Note that
∥Mk −E[M|Nk]∥L1(P ) = ∥E[Mk|Nk] −E[M|Nk]∥L1(P )
≤∥Mk −M∥L1(P ) →0
as k →∞.
Hence if F ∈Nk0 and k ≥k0 we have
Z
F
(X−M)dP =
Z
F
E[X−M|Nk]dP =
Z
F
(Mk−E[M|Nk])dP →0
as k →∞.
Therefore
Z
F
(X −M)dP = 0
for all F ∈
∞
S
k=1
Nk
and hence
E[X|N∞] = E[M|N∞] = M .
⊔⊓

304
Appendix C: Uniform Integrability and Martingale Convergence

Appendix D: An Approximation Result
In this Appendix we prove an approximation result which was used in The-
orem 10.4.1. We use the notation from that Theorem.
Theorem C.1. Let D ⊂V ⊂Rn be open sets such that
∂D
is a Lipschitz surface
(C.1)
and let φ: V →R be a function with the following properties
φ ∈C1(V ) ∩C(V )
(C.2)
φ ∈C2(V \ ∂D)
and the second order derivatives
(C.3)
of φ are locally bounded near ∂D ,
Then there exists a sequence {φj}∞
j=1 of functions φj ∈C2(V ) ∩C(V ) such
that
φj →φ
uniformly on compact subsets of V , as j →∞
(C.4)
Lφj →Lφ
uniformly on compact subsets of V \ ∂D, as j →∞
(C.5)
{Lφj}∞
j=1
is locally bounded on V .
(C.6)
Proof. We may assume that φ is extended to a continuous function on the
whole of Rn. Choose a C∞function η: Rn →[0, ∞) with compact support
such that
Z
Rn
η(y)dy = 1
(C.7)
and put
ηϵ(x) = ϵ−nη
µx
ϵ
¶
for ϵ > 0, x ∈Rn .
(C.8)
Fix a sequence ϵj ↓0 and deﬁne
φj(x) = (φ ∗ηϵj)(x) =
Z
Rn
φ(x −z)ηϵj(z)dz =
Z
Rn
φ(y)ηϵj(x −y)dy ,
(C.9)

306
Appendix D: An Approximation Result
i.e. φj is the convolution of φ and ηϵj. Then it is well-known that φj(x) →φ(x)
uniformly on compact subsets of any set in V where φ is continuous. See e.g.
Folland (1984), Theorem 8.14 (c). Note that since η has compact support
we need not assume that φ is globally bounded, just locally bounded (which
follows from continuity).
We proceed to verify (D.4)–(D.6): Let W ⊂V be open with a Lipschitz
boundary. Put V1 = W ∩D, V2 = W \ D.
Then V1, V2 are Lipschitz domains and integration by parts gives, for i = 1, 2
and x ∈W \ ∂D
Z
Vi
φ(y)
∂2
∂yk∂yℓ
ηϵj(x −y)dy =
Z
∂Vi
φ(y) ∂
∂yℓ
ηϵj(x −y)nikdν(y) −
Z
Vi
∂φ
∂yk
(y) ∂
∂yℓ
ηϵj(x −y)dy ,
(C.10)
where nik is component number k of the outer unit normal ni from Vi at
∂Vi. (This outer normal exists a.e. with respect to the surface measure ν on
∂Vi since ∂Vi is a Lipschitz surface.)
Another integration by parts yields
Z
Vi
∂φ
∂yk
(y) ∂
∂yℓ
ηϵj(x −y)dy =
Z
∂Vi
∂φ
∂yk
(y)ηϵj(x −y)niℓdν(y) −
Z
Vi
∂2φ
∂yk∂yℓ
(y)ηϵj(x −y)dy .
(C.11)
Combining (D.10) and (D.11) we get
Z
Vi
φ(y)
∂2
∂yk∂yℓ
ηϵj(x −y)dy =

Appendix D: An Approximation Result
307
Z
∂Vi
·
φ(y) ∂
∂yℓ
ηϵj(x −y)nik −∂φ
∂yk
(y)ηϵj(x −y)niℓ
¸
dν(y)
+
Z
Vi
∂2φ
∂yk∂yℓ
(y)ηϵj(x −y)dy ;
i = 1, 2 .
(C.12)
Adding (D.12) for i = 1, 2 and keeping in mind that the outer unit normal
for Vi is the inner unit normal for V1−i on ∂V1 ∩∂V2, we get
Z
W
φ(y)
∂2
∂yk∂yℓ
ηϵj(x −y)dy =
Z
∂W
½
φ(y) ∂
∂yℓ
ηϵj(x −y)Nk −∂φ
∂yk
(y)ηϵj(x −y)Nℓ
¾
dν(y)
+
Z
W
∂2φ
∂yk∂yℓ
(y)ηϵj(x −y)dy ,
(C.13)
where Nk, Nℓare components number k, ℓof the outer unit normal N from
W at ∂W.
If we ﬁx x ∈W \ ∂D then for j large enough we have ηϵj(x −y) = 0 for
all y outside W and for such j we get from (D.13)
Z
Rn
φ(y)
∂2
∂yk∂yℓ
ηϵj(x −y)dy =
Z
Rn
∂2φ
∂yk∂yℓ
(y)ηϵj(x −y)dy .
(C.14)
In other words, we have proved that
∂2
∂xk∂xℓ
φj(x) =
µ
∂2φ
∂yk∂yℓ
∗ηϵj
¶
(x)
for x ∈V \ ∂D .
(C.15)
Similarly, integration by parts applied to W gives, if j is large enough
Z
W
φ(y) ∂
∂yk
ηϵj(x −y)dy = −
Z
W
∂φ
∂yk
(y)ηϵj(x −y)dy
from which we conclude that
∂
∂xk
φj(x) =
µ ∂φ
∂yk
∗ηϵj
¶
(x)
for x ∈V .
(C.16)
From (D.15) and (D.16), combined with Theorem 8.14 (c) in Folland (1984),
we get that
∂φj
∂xk
→∂φ
∂x
uniformly on compact subsets of V as j →∞
(C.17)

308
Appendix D: An Approximation Result
and
∂2φj
∂xk∂xℓ
→
∂2φ
∂xk∂xℓ
uniformly on compact subsets of V \ ∂D as j →∞.
(C.18)
Moreover,
n
∂φj
∂xk
o∞
j=1 and
n
∂2φj
∂xk∂xℓ
o∞
j=1 are locally bounded on V , by (D.15),
(D.16) combined with the assumptions (D.2), (D.3).
We conclude that (D.4)–(D.6) hold.
⊔⊓

Solutions and Additional Hints to Some of the
Exercises
2.13. P 0[Bt ∈Dρ] = 1 −e
−ρ2
2t .
2.14. Ex£ ∞
R
0
XK(Bt)dt
¤
=
∞
R
0
P x[Bt ∈K]dt=
∞
R
0
(2πt)−n/2¡ R
K
e
−(x−y)2
2t
dy
¢
dt=0
for all x ∈Rn, if K ⊂Rn has n-dimensional Legesgue measure equal
to 0.
2.15. P[ eBt1 ∈F1, . . . , eBtk ∈Fk] = P[Bt1 ∈U −1F1, . . . , Btk ∈U −1Fk]
=
R
U −1F1×···×U −1Fk
p(t1, 0, x1)p(t2−t1, x1, x2) · · · p(tk−tk−1, xk−1, xk)dx1 · · · dxk
=
R
F1×···×Fk
p(t1, 0, y1)p(t2−t1, y1, y2) · · · p(tk−tk−1, yk−1, yk)dy1 · · · dyk
= P[Bt1 ∈F1, . . . , Btk ∈Fk] ,
by (2.2.1), using the substitutions yj = Uxj and the fact that
|Uxj −Uxj−1|2 = |xj −xj−1|2.
2.17. a) E[(Yn(t, ·) −t)2] = E
·µ P2n−1
k=0 (∆Bk)2 −P2n−1
k=0 2−nt
¶2¸
= E
·½ 2n−1
X
k=0
((∆Bk)2 −2−nt)
¾2¸
= E
· 2n−1
X
j,k=0
((∆Bj)2 −2−nt)((∆Bk)2−2−nt)
¸
=
2n−1
X
k=0
E[((∆Bk)2 −2−nt)2]
=
2n−1
X
k=0
E[(∆Bk)4 −2 · 2−2nt2 −2−2nt2]
=
2n−1
X
k=0
2 · 2−2nt2 = 2 · 2−nt2 →0
as n →∞.
b) This follows from the following general result: If the quadratic vari-
ation of a real function over an interval is positive, then the total
variation of the function over that interval is inﬁnite.

310
Solutions and Additional Hints to Some of the Exercises
3.1.
tBt = Pn−1
j=0 ∆(sjBj) = Pn−1
j=0 sj∆Bj + Pn−1
j=0 Bj+1∆sj
→
tR
0
sdBs +
tR
0
Bsds
as n →∞.
3.4.
The processes in (iii) and (iv) are martingales, but those in (i) and
(ii) are not.
3.9.
TR
0
Bt ◦dBt = 1
2B2
T
if B0 = 0 .
3.12. (i) a)
dXt = (γ + 1
2α2)Xtdt + αXtdBt .
b)
dXt = 1
2 sin Xt[cos Xt −t2]dt + (t2 + cos Xt)dBt .
(ii) a)
dXt = (r −1
2α2)Xtdt + αXt ◦dBt .
b)
dXt = (2e
−Xt −X3
t )dt + X2
t ◦dBt .
4.1.
a) dXt = 2BtdBt + dt .
b) dXt = (1 + 1
2eBt)dt + eBtdBt .
c) dXt = 2dt + 2B1dB1(t) + 2B2dB2(t) .
d) dxt =
·
dt
dBt
¸
=
·
1
0
¸
dt +
·
0
1
¸
dBt .
e) dX1(t) = dB1(t) + dB2(t) + dB3(t)
dX2(t) = dt −B3(t)dB1(t) + 2B2(t)dB2(t) −B1(t)dB3(t)
or
dXt =
·
dX1(t)
dX2(t)
¸
=
·
0
1
¸
dt +
·
1
1
1
−B3(t) 2B2(t) −B1(t)
¸

dB1(t)
dB2(t)
dB3(t)

.
4.5.
E[B6
t ] = 15t3
if B0 = 0 .
5.3.
Xt = X0 · exp
¡³
r −1
2
nP
k=1
α2
k
´
t +
nP
k=1
αkBk(t)
¢
(if B(0) = 0).
5.4.
(i)
X1(t) = X1(0) + t + B1(t) ,
X2(t) = X2(0) + X1(0)B2(t) +
tR
0
sdB2(s) +
tR
0
B1(s)dB2(s),
as-
suming (as usual) that B(0) = 0.
(ii) Xt = etX0 +
tR
0
et−sdBt .
(iii) Xt = e−tX0 + e−tBt
(assuming B0 = 0).
5.6.
Yt = exp(αBt −1
2α2t)[Y0 + r
tR
0
exp(−αBs + 1
2α2s)ds]
(B0 = 0).
5.7.
a) Xt = m + (X0 −m)e−t + σ
tR
0
es−tdBs .
b) E[Xt] = m + (X0 −m)e−t.
Var[Xt] = σ2
2 [1 −e−2t] .
5.8.
X(t) =
·
X1(t)
X2(t)
¸
= exp(tJ)X(0)+exp(tJ)
tR
0
exp(−sJ)MdB(s), where

Solutions and Additional Hints to Some of the Exercises
311
J =
·
0
1
−1
0
¸
,
M =
·
α
0
0
β
¸
,
dB(s) =
·
dB1(s)
dB2(s)
¸
and
exp(tJ) = I + tJ + t2
2 J2 + · · · + tn
n!Jn + · · · ∈R2×2 .
Using that J2 = −I this can be rewritten as
X1(t) = X1(0) cos(t) + X2(0) sin(t) +
tR
0
α cos(t −s)dB1(s)
+
tR
0
β sin(t −s)dB2(s) ,
X2(t) = −X1(0) sin(t) + X2(0) cos(t) −
tR
0
α sin(t −s)dB1(s)
+β
tR
0
cos(t −s)dB2(s) .
5.11. Hint: To prove that lim
t→1(1 −t)
tR
0
dBs
1−s = 0 a.s., put Mt =
tR
0
dBs
1−s for
0 ≤t < 1 and apply the martingale inequality to prove that
P[sup{(1 −t)|Mt|; t ∈[1 −2−n, 1 −2−n−1]} > ϵ] ≤2ϵ−2 · 2−n .
Hence by the Borel-Cantelli lemma we obtain that for a.a. ω there
exists n(ω) < ∞such that
n ≥n(ω) ⇒ω /∈An ,
where
An = {ω; sup{(1 −t)|Mt|; t ∈[1 −2−n, 1 −2−n−1]} > 2
−n
4 } .
5.16. c) Xt = exp(αBt −1
2α2t)
h
x2 + 2
tR
0
exp(−2αBs + α2s)ds
i1/2
.
7.1.
a) Af(x) = µxf ′(x) + 1
2σ2f ′′(x);
f ∈C2
0(R).
b) Af(x) = rxf ′(x) + 1
2α2x2f ′′(x);
f ∈C2
0(R).
c) Af(y) = rf ′(y) + 1
2α2y2f ′′(y);
f ∈C2
0(R).
d) Af(t, x) = ∂f
∂t + µx ∂f
∂x + 1
2σ2 ∂2f
∂x2 ;
f ∈C2
0(R2).
e) Af(x1, x2) =
∂f
∂x1 + x2
∂f
∂x2 + 1
2e2x1 ∂2f
∂x2
2 ;
f ∈C2
0(R2).
f) Af(x1, x2) =
∂f
∂x1 + 1
2
∂2f
∂x2
1 + 1
2x2
1
∂2f
∂x2
2 ;
f ∈C2
0(R2).
g) Af(x1, . . . , xn) =
nP
k=1
rkxk
∂f
∂xk + 1
2
nP
i,j=1
xixj(
nP
k=1
αikαjk)
∂2f
∂xi∂xj ;
f ∈C2
0(Rn).
7.2.
a) dXt = dt +
√
2 dBt .

312
Solutions and Additional Hints to Some of the Exercises
b) dX(t) =
·
dX1(t)
dX2(t)
¸
=
·
1
cX2(t)
¸
dt +
·
0
αX2(t)
¸
dBt .
c) dX(t) =
·
dX1(t)
dX2(t)
¸
=
·
2X2(t)
ln(1+X2
1(t)+X2
2(t))
¸
dt+
·
X1(t) 1
1
0
¸·
dB1(t)
dB2(t)
¸
.
(Several other diﬀusion coeﬃcients are possible.)
7.4.
a), b). Let τk = inf{t > 0; Bx
t = 0 or Bx
t = k}; k > x > 0 and put
ρk = P x[Bτk = k] .
Then by Dynkin’s formula applied to f(y) = y2 for 0 ≤y ≤k we get
Ex[τk] = k2pk −x2 .
(S1)
On the other hand, Dynkin’s formula applied to f(y) = y for 0 ≤y ≤k
gives
kpk = x .
(S2)
Combining these two identities we get that
Ex[τ] = lim
k→∞Ex[τk] = lim
k→∞x(k −x)) = ∞.
(S3)
Moreover, from (S2) we get
P x[∃t < ∞with Bt = 0] = lim
k→∞P x[Bτk = 0] = lim
k→∞(1 −pk) = 1 ,
(S4)
so τ < ∞a.s. P x.
7.18. c) p =
exp(−2bx
σ2 )−exp(−2ab
σ2 )
exp(−2b2
σ2 )−exp(−2ab
σ2 ) .
8.1.
a) g(t, x) = Ex[φ(Bt)] .
b) u(x) = Ex[
∞
R
0
e−αtψ(Bt)dt] .
8.12. dQ(ω) = exp(3B1(T) −B2(T) −5T)dP(ω) .
9.1.
a) dXt =
·
α
0
¸
dt +
·
0
β
¸
dBt .
b) dXt =
·
a
b
¸
dt +
·
1
0
0
1
¸
dBt .
c) dXt = αXtdt + βdBt .
d) dXt = αdt + βXtdBt .
e) dXt =
·
dX1(t)
dX2(t)
¸
=
·
ln(1+X2
1(t))
X2(t)
¸
dt +
√
2
·
X2(t)
0
X1(t) X1(t)
¸·
dB1(t)
dB2(t)
¸
.
9.3.
a) u(t, x) = Ex[φ(BT −t)] .
b) u(t, x) = Ex[ψ(Bt)] .

Solutions and Additional Hints to Some of the Exercises
313
9.8.
a) Let Xt ∈R2 be uniform motion to the right, as described in Ex-
ample 9.2.1. Then each one-point set {(x1, x2)} is thin (and hence
semipolar) but not polar.
b) With Xt as in a) let Hk = {(ak, 1)}; k = 1, 2, . . . where {ak}∞
k=1
is the set of rational numbers. Then each Hk is thin but
Q(x1,1)[TH = 0] = 1 for all x1 ∈R .
9.10. Let Yt = Y s,x
t
= (s + t, Xx
t ) for t ≥0, where Xt = Xx
t satisﬁes
dXt = αXtdt + βXtdBt ;
t ≥0, X0 = x > 0 .
Then the generator bA of Yt is given by
bAf(s, x) = ∂f
∂s + αx∂f
∂x + 1
2β2x2 ∂2f
∂x2 ;
f ∈C2
0(R2) .
Moreover, with D = {(t, x); x > 0 and t < T} we have
τD: = inf[t > 0; Yt /∈D} = inf{t > 0; s + t > T} = T −s .
Hence
YτD = (T, XT −s) .
Therefore, by Theorem 9.3.3 the solution is
f(s, x) = E
·
e−ρT φ(Xx
T −s) +
T −s
Z
0
e−ρ(s+t)K(Xx
t )dt
¸
.
10.1. a) g∗(x) = ∞,
τ ∗does not exist.
b) g∗(x) = ∞,
τ ∗does not exist.
c) g∗(x) = 1,
τ ∗= inf{t > 0; Bt = 0}.
d) If ρ < 1
2 then g∗(s, x) = ∞and τ ∗does not exist.
If ρ ≥1
2 then g∗(s, x) = g(s, x) = e−ρs cosh x and τ ∗= 0 .
10.3. x0 > 0 is given implicitly by the equation
x0 =
r2
ρ · e
2√
2ρ x0 + 1
e
2√
2ρ x0 −1
,
and g∗(s, x) = e−ρsx2
0
cosh(√2ρ x)
cosh(√2ρ x0) for −x0 ≤x ≤x0, where
cosh ξ = 1
2(eξ + e−ξ) .
10.9. If 0 < ρ ≤1 then γ(x) = 1
ρx2 + 1
ρ2 but τ ∗does not exist. If ρ > 1 then
γ(x) =
½ 1
ρx2 + 1
ρ2 + C cosh(√2ρ x)
for |x| ≤x∗
x2
for |x| > x∗
where C > 0, x∗> 0 are the unique solutions of the equations

314
Solutions and Additional Hints to Some of the Exercises
C cosh(
p
2ρ x∗) =
µ
1 −1
ρ
¶
(x∗)2 −1
ρ2
C
p
2ρ sinh(
p
2ρ x∗) = 2
µ
1 −1
ρ
¶
x∗.
10.12. If ρ > r then g∗(s, x) = e−ρs(x0 −1)+( x
x0 )γ and
τ ∗= inf{t > 0; Xt ≥x0}, where
γ = α−2
·
1
2α2 −r +
r
(1
2α2 −r)2 + 2α2ρ
¸
and
x0 =
γ
γ −1
(γ > 1 ⇔ρ > r) .
10.13. If α ≤ρ then τ ∗= 0 .
If ρ < α < ρ + λ then
G∗(s, p, q) =
½ e−ρspq
;
if 0 < pq < y0
e−ρs(C1(pq)γ1 +
λ
ρ+λ−α · pq −K
ρ ) ;
if pq ≥y0
where
γ1 = β−2
·
1
2β2 + λ −α −
r
(1
2β2 + λ −α)2 + 2ρβ2
¸
< 0 ,
y0 = (−γ1)K(ρ + λ −α)
(1 −γ1)ρ(α −ρ)
> 0
and
C1 =
(α −ρ)y
1−γ1
0
(−γ1)(ρ + λ −α) .
The continuation region is
D = {(s, p, q); pq > y0} .
If ρ + λ ≤α then G∗= ∞.
11.6. u∗= a1−a2−σ2
2(1−γ)
(σ2
1+σ2
2)(1−γ)
(constant),
Φ(s, x) = e
λ(t−t1)xγ
for t < t1, x > 0
where
λ = 1
2γ(1 −γ)[σ2
1(u∗)2 + σ2
2(1 −u∗)2] −γ[a1u∗+ a2(1 −u∗)] .

Solutions and Additional Hints to Some of the Exercises
315
11.11. Additional hints:
For the solution of the unconstrained problem try a function φλ(s, x)
of the form
φλ(s, x) = aλ(s)x2 + bλ(s) ,
for suitable functions aλ(s), bλ(s) with λ ∈R ﬁxed. By substituting
this into the HJB equation we arrive at the equations
a′
λ(s) = 1
θa2
λ(s) −1
for s < t1
aλ(t1) = λ
and
b′
λ(s) = −σ2aλ(s)
for s < t1
bλ(t1) = 0 ,
with optimal control u∗(s, x) = −1
θaλ(s)x .
Now substitute this into the equation for Xu∗
t
and use the terminal
condition to determine λ0 .
If we put s = 0 for simplicity, then λ = λ0 can be chosen as any
solution of the equation
Aλ3 + Bλ2 + Cλ + D = 0 ,
where
A = m2(et1 −e−t1)2 ,
B = m2(e2t1 + 2 −3e−2t1) −σ2(et1 −e−t1)2 ,
C = m2(−e2t1 + 2 + 3e−2t1) −4x2 −2σ2(1 −e−2t1)
D = −m2(et1 + e−t1)2 + 4x2 + σ2(e2t1 −e−2t1) .
12.6. a) no arbitrage
b) no arbitrage
c) θ(t) = (0, 1, 1) is an arbitrage
d) no arbitrage
e) arbitrages exist
f) no arbitrage.
12.7. a) complete
b) not complete. For example, the claim
F(ω) =
T
Z
0
B3(t)dB3(t) = 1
2B2
3(T) −1
2T
cannot be hedged.

316
Solutions and Additional Hints to Some of the Exercises
c) (arbitrages exist)
d) not complete
e) (arbitrages exist)
f) complete.
12.12. c) EQ[ξ(T)F] = σ−1x1(1 −α
ρ )(1 −e−ρT ). The replicating portfolio is
θ(t) = (θ0(t), θ1(t)), where
θ1(t) = σ−1
·
1 −α
ρ (1 −eρ(t−T ))
¸
and θ0(t) is determined by (12.1.14).
12.15.
Φ(s, x) =
½ e−ρs(a −x)
for
x ≤x∗
e−ρs(a −x∗)( x
x∗)γ
for
x > x∗
where
γ = β−2
·
1
2β2 −α −
q¡ 1
2β2 −α
¢2 + 2ρβ2
¸
< 0
and
x∗=
aγ
γ −1 ∈(0, a) .
Hence it is optimal to stop the ﬁrst time X(t) ≤x∗.
If α = ρ this simpliﬁes to
γ = −2ρ
β2
and
x∗=
a2ρ
β2 + 2ρ .

References
1. Aase, K.K. (1982): Stochastic continuous-time model reference adaptive systems
with decreasing gain. Advances in Appl. Prop. 14, 763–788
2. Aase, K.K. (1984): Optimum portfolio diversiﬁcation in a general continuous
time model. Stoch. Proc. and their Applications 18, 81–98
3. Adler, R.J. (1981): The Geometry of Random Fields. Wiley & Sons
4. Andersen, E.S., Jessen, B. (1948): Some limit theorems on set-functions. Danske
Vid. Selsk. Mat.-Fys. Medd. 25, #5, 1–8
5. Arnold, L. (1973): Stochastische Diﬀerentialgleichungen. Theorie und Anwen-
dung. Oldenbourgh Verlag
6. Barles, G., Burdeau, J., Romano, M., Samsoen, N. (1995): Critical stock price
near expiration. Math. Finance 5, 77–95
7. Barndorﬀ-Nielsen, O.E. (1998): Processes of normal inverse Gaussian type. Fi-
nance and Stochastics 2, 41–68
8. Bather, J.A. (1970): Optimal stopping problems for Brownian motion. Advances
in Appl. Prob. 2, 259–286
9. Bather, J.A. (1997): Bounds on optimal stopping times for the American put.
Preprint, University of Sussex
10. Beneˇs, V.E. (1974): Girsanov functionals and optimal bang-bang laws for ﬁnal-
value stochastic control. Stoch. Proc. and Their Appl. 2, 127–140
11. Bensoussan, A. (1984): On the theory of option pricing. Acta Appl. Math. 2,
139–158
12. Bensoussan, A. (1992): Stochastic Control of Partially Observable Systems.
Cambridge Univ. Press
13. Bensoussan, A., Lions, J.L. (1978): Applications des in´equations variationelles
en controle stochastique. Dunod. (Applications of Variational Inequalities in
Stochastic Control. North-Holland)
14. Bernard, A., Campbell, E.A., Davie, A.M. (1979): Brownian motion and gen-
eralized analytic and inner functions. Ann. Inst. Fourier 729, 207–228
15. Bers, L., John, F., Schechter, M. (1964): Partial Diﬀerential Equations. Inter-
science
16. Biais, B., Bjørk, T., Cvitanic, J., El Karoui, N., Jouini, E., Rochet, J.C. (1997):
Financial Mathematics. Lecture Notes in Mathematics, Vol. 1656. Springer-
Verlag
17. Bingham, N.H., Kiesel, R. (1998): Risk-Neutral Valuation. Springer-Verlag
18. Black, F., Scholes, M. (1973): The pricing of options and corporate liabilities.
J. Political Economy 81, 637–654
19. Blumenthal, R.M., Getoor, R.K. (1968): Markov Processes and Potential The-
ory. Academic Press
20. Borodin, A.N., Salminen, P. (1996): Handbook of Brownian Motion – Facts
and Formulae. Birkh¨auser

318
References
21. Brekke, K.A., Øksendal, B. (1991): The high contact principle as a suﬃciency
condition for optimal stopping. To appear in D. Lund and B. Øksendal (editors):
Stochastic Models and Option Values. North-Holland
22. Brown, B.M., Hewitt, J.I. (1975): Asymptotic likelihood theory for diﬀusion
processes. J. Appl. Prob. 12, 228–238
23. Bucy, R.S., Joseph, P.D. (1968): Filtering for Stochastic Processes with Appli-
cations to Guidance. Interscience
24. Chow, Y.S., Robbins, H., Siegmund, D. (1971): Great Expectations: The The-
ory of Optimal Stopping. Houghton Miﬃn Co
25. Chung, K.L. (1974): A Course in Probability Theory. Academic Press
26. Chung, K.L. (1982): Lectures from Markov Processes to Brownian Motion.
Springer-Verlag
27. Chung, K.L., Williams, R. (1990): Introduction to Stochastic Integration. Sec-
ond Edition. Birkh¨auser
28. Clark, J.M. (1970, 1971): The representation of functionals of Brownian motion
by stochastic integrals. Ann. Math. Stat. 41, 1282–1291 and 42, 1778
29. Csink, L., Øksendal, B. (1983): Stochastic harmonic morphisms: Functions
mapping the paths of one diﬀusion into the paths of another. Ann. Inst. Fourier
330, 219–240
30. Csink, L., Fitzsimmons, P., Øksendal, B. (1990): A stochastic characterization
of harmonic morphisms. Math. Ann. 287, 1–18
31. Cutland, N.J., Kopp, P.E., Willinger, W. (1995): Stock price returns and the
Joseph eﬀect: A fractional version of the Black-Scholes model. In Bolthausen,
Dozzi and Russo (editors): Seminar on Stochastic Analysis, Random Fields and
Applications. Birkh¨auser, 327–351
32. Davis, M.H.A. (1977): Linear Estimation and Stochastic Control. Chapman
and Hall
33. Davis, M.H.A. (1984): Lectures on Stochastic Control and Nonlinear Filtering.
Tata Institute of Fundamental Research 75. Springer-Verlag
34. Davis, M.H.A. (1993): Markov Models and Optimization. Chapman & Hall,
London
35. Davis, M.H.A., Vinter, R.B. (1985): Stochastic Modelling and Control. Chap-
man and Hall
36. Delbaen, F., Schachermayer, W. (1994): A general version of the fundamental
theorem of asset pricing. Math. Ann. 300, 463–520
37. Delbaen, F., Schachermayer, W. (1995): The existence of absolutely continuous
local martingale measures. Annals of Applied Probability 5, 926–945
38. Delbaen, F., Schachermayer, W. (1997): The fundamental theorem of asset
pricing for unbounded stochastic processes. (To appear)
39. Dixit, A.K., Pindyck, R.S. (1994): Investment under Uncertainty. Princeton
University Press
40. Doob, J.L. (1984): Classical Potential Theory and Its Probabilistic Counter-
part. Springer-Verlag
41. Dudley, R.M. (1977): Wiener functionals as Itˆo integrals. Ann. Probability 5,
140–141
42. Duﬃe, D. (1994): Martingales, arbitrage, and portfolio choice. First European
Congress of Mathematics, vol. II, Birkh¨auser, 3–21
43. Duﬃe, D. (1996): Dynamic Asset Pricing Theory. Second Edition. Princeton
University Press
44. Durrett, R. (1984): Brownian Motion and Martingales in Analysis. Wadsworth
Inc
45. Dynkin, E.B. (1963): The optimum choice of the instant for stopping a Markov
process. Soviet Mathematics 4, 627–629

References
319
46. Dynkin, E.B. (1965 I): Markov Processes, vol. I. Springer-Verlag
47. Dynkin, E.B. (1965 II): Markov Processes, vol. II. Springer-Verlag
48. Dynkin, E.B., Yushkevich, A.A. (1979): Controlled Markov Processes. Springer-
Verlag
49. El Karoui (1981): Les aspects probabilistes du contrˆol stochastique. Lecture
Notes in Math. 876, 73–238. Springer-Verlag
50. Elliott, R.J. (1982): Stochastic Calculus and Applications. Springer-Verlag
51. Elliott, R.J., Kopp, P.E. (1999): Mathematics of Financial Markets. Springer-
Verlag
52. Elworthy, K.D. (1982): Stochastic Diﬀerential Equations on manifolds. Cam-
bridge University Press
53. Emery, M. (1989): Stochastic Calculus in Manifolds. Springer-Verlag
54. Fakeev, A.G. (1970): Optimal stopping rules for processes with continuous pa-
rameter. Theory Probab. Appl. 15, 324–331
55. Fleming, W.H., Rishel, R.W. (1975): Deterministic and Stochastic Optimal
Control. Springer-Verlag
56. Fleming, W.H., Soner, H.M. (1993): Controlled Markov Processes and Viscosity
Solutions. Springer-Verlag
57. Folland, G.B. (1984): Real Analysis. J. Wiley & Sons
58. Freidlin, M. (1985): Functional Integration and Partial Diﬀerential Equations.
Princeton University Press
59. Friedman, A. (1975): Stochastic Diﬀerential Equations and Applications, vol.
I. Academic Press
60. Friedman, A. (1976): Stochastic Diﬀerential Equations and Applications, vol.
II. Academic Press
61. Fukushima, M. (1980): Dirichlet Forms and Markov Processes. North-
Holland/Kodansha
62. Gard, T.C. (1988): Introduction to Stochastic Diﬀerential Equations. Dekker
63. Gelb, A. (1974): Applied Optimal Estimation. MIT
64. Gihman, I.I., Skorohod, A.V. (1974a): Stochastic Diﬀerential Equations.
Springer-Verlag
65. Gihman, I.I., Skorohod, A.V. (1974b): The Theory of Stochastic Processes, vol.
I. Springer-Verlag
66. Gihman, I.I., Skorohod, A.V. (1975): The Theory of Stochastic Processes, vol.
II. Springer-Verlag
67. Gihman, I.I., Skorohod, A.V. (1979): Controlled Stochastic Processes. Springer-
Verlag
68. Grue, J. (1989): Wave drift damping of the motions of moored platforms by
the method of stochastic diﬀerential equations. Manuscript, University of Oslo
69. Harrison, J.M., Kreps, D. (1979): Martingales and arbitrage in multiperiod
securities markets. J. Economic Theory 20, 381–408
70. Harrison, J.M., Pliska, S. (1981): Martingales and stochastic integrals in the
theory of continuous trading. Stoch. Proc. and Their Applications 11, 215–260
71. Harrison, J.M., Pliska, S. (1983): A stochastic calculus model of continuous
trading: Complete markets. Stoch. Proc. Appl. 15, 313–316
72. He, S., Wang, J., Yan, J. (1992): Semimartingale Theory and Stochastic Cal-
culus. Science Press and CRC Press
73. Hida, T. (1980): Brownian Motion. Springer-Verlag
74. Hida, T., Kuo, H.-H,, Potthoﬀ, J., Streit, L. (1993): White Noise. An Inﬁnite
Dimensional Approach. Kluwer
75. Hoel, P.G., Port, S.C., Stone, C.J. (1972): Introduction to Stochastic Processes.
Waveland Press, Illinois 60070
76. Hoﬀmann, K. (1962): Banach Spaces of Analytic Functions. Prentice Hall

320
References
77. Holden, H., Øksendal, B., Ubøe, J., Zhang, T. (1996): Stochastic Partial Dif-
ferential Equations. Birkh¨auser
78. Hu, Y. (1995): Itˆo-Wiener chaos expansion with exact residual and correlation,
variance inequalities. (To appear)
79. Hu, Y., Øksendal, B. (1999): Fractional white noise calculus and applications
to ﬁnance. Preprint, University of Oslo 1999
80. Ikeda, N., Watanabe, S. (1989): Stochastic Diﬀerential Equations and Diﬀusion
Processes. Second Edition. North-Holland/Kodansha
81. Itˆo, K. (1951): Multiple Wiener integral. J. Math. Soc. Japan 3, 157–169
82. Itˆo, K., McKean, H.P. (1965): Diﬀusion Processes and Their Sample Paths.
Springer-Verlag
83. Jacka, S. (1991): Optimal stopping and the American put. Mathematical Fi-
nance 1, 1–14
84. Jacod, J. (1979): Calcul Stochastique et Problemes de Martingales. Springer
Lecture Notes in Math. 714
85. Jacod, J., Shiryaev, A.N. (1987): Limit Theorems for Stochastic Processes.
Springer-Verlag
86. Jaswinski, A.H. (1970): Stochastic Processes and Filtering Theory. Academic
Press
87. Kallianpur, G. (1980): Stochastic Filtering Theory. Springer-Verlag
88. Kallianpur, G., Karandikar, R.L. (2000): Introduction to Option Pricing The-
ory. Birkh¨auser
89. Karatzas, I. (1988): On the pricing of American options. Appl. Math. Opti-
mization 17, 37–60
90. Karatzas, I. (1997): Lectures on the Mathematics of Finance. American Math-
ematical Society
91. Karatzas, I., Lehoczky, J., Shreve, S.E. (1987): Optimal portfolio and consump-
tion decisions for a ’Small Investor’ on a ﬁnite horizon. SIAM J. Control and
Optimization 25, 1157–1186
92. Karatzas, I., Ocone, D. (1991): A generalized Clark representation formula,
with application to optimal portfolios. Stochastics and Stochastics Reports 34,
187–220
93. Karatzas, I., Shreve, S.E. (1991): Brownian Motion and Stochastic Calculus.
Second Edition. Springer-Verlag
94. Karatzas, I., Shreve, S.E. (1998): Methods of Mathematical Finance. Springer-
Verlag
95. Karlin, S., Taylor, H. (1975): A First Course in Stochastic Processes. Second
Edition. Academic Press
96. Kloeden, P.E., Platen, E. (1992): Numerical Solution of Stochastic Diﬀerential
Equations. Springer-Verlag
97. Knight, F.B. (1981): Essentials of Brownian Motion. American Math. Soc.
98. Kopp, P. (1984): Martingales and Stochastic Integrals. Cambridge University
Press
99. Krishnan, V. (1984): Nonlinear Filtering and Smoothing: An Introduction to
Martingales, Stochastic Integrals and Estimation. J. Wiley & Sons
100. Krylov, N.V. (1980): Controlled Diﬀusion Processes. Springer-Verlag
101. Krylov, N.V., Zvonkin, A.K. (1981): On strong solutions of stochastic diﬀer-
ential equations. Sel. Math. Sov. I, 19–61
102. Kushner, H.J. (1967): Stochastic Stability and Control. Academic Press
103. Lamperti, J. (1977): Stochastic Processes. Springer-Verlag
104. Lamberton, D., Lapeyre, B. (1996): Introduction to Stochastic Calculus Ap-
plied to Finance. Chapman & Hall

References
321
105. Levental, S., Skorohod, A.V. (1995): A necessary and suﬃcient condition for
absence of arbitrage with tame portfolios. Ann. Appl. Probability 5, 906–925
106. Lin, S.J. (1995): Stochastic analysis of fractional Brownian motions. Stochas-
tics 55, 121–140
107. Liptser, R.S., Shiryaev, A.N. (1977): Statistics of Random Processes, vol. I.
Springer-Verlag
108. Liptser, R.S., Shiryaev, A.N. (1978): Statistics of Random Processes, vol. II.
Springer-Verlag
109. McDonald, R., Siegel, D. (1986): The valueof waiting to invest. Quarterly J.
of Economics 101, 707–727
110. McGarty, T.P. (1974): Stochastic Systems and State Estimation. J. Wiley &
Sons
111. McKean, H.P. (1965): A free boundary problem for the heat equation arising
from a problem of mathematical economics. Industrial managem. review 60,
32–39
112. McKean, H.P. (1969): Stochastic Integrals. Academic Press
113. Malliaris, A.G. (1983): Itˆo’s calculus in ﬁnancial decision making. SIAM Re-
view 25, 481–496
114. Malliaris, A.G., Brock, W.A. (1982): Stochastic Methods in Economics and
Finance. North-Holland
115. Markowitz, H.M. (1976): Portfolio Selection. Eﬃcient Diversiﬁcation of In-
vestments. Yale University Press
116. Maybeck, P.S. (1979): Stochastic Models, Estimation, and Control. Vols. 1–3.
Academic Press
117. Merton, R.C. (1971): Optimum consumption and portfolio rules in a
continuous-time model. Journal of Economic Theory 3, 373–413
118. Merton, R.C. (1990): Continuous-Time Finance. Blackwell Publishers
119. Metivier, M., Pellaumail, J. (1980): Stochastic Integration. Academic Press
120. Meyer, P.A. (1966): Probability and Potentials. Blaisdell
121. Meyer, P.A. (1976): Un cours sur les int´egrales stochastiques. Sem. de Prob.
X. Lecture Notes in Mathematics, vol. 511. Springer-Verlag, 245–400
122. Musiela, M., Rutkowski, M. (1997): Martingale Methods in Financial Mod-
elling. Springer-Verlag
123. Ocone, D. (1984): Malliavin’s calculus and stochastic integral: representation
of functionals of diﬀusion processes. Stochastics 12, 161–185
124. Øksendal, B. (1984): Finely harmonic morphisms, Brownian path preserving
functions and conformal martingales. Inventiones math. 750, 179–187
125. Øksendal, B. (1990): When is a stochastic integral a time change of a diﬀusion?
Journal of Theoretical Probability 3, 207–226
126. Øksendal, B. (1996): An Introduction to Malliavin Calculus with Application
to Economics. Preprint, Norwegian School of Economics and Business Admin-
istration
127. Olsen, T.E., Stensland, G. (1987): A note on the value of waiting to invest.
Manuscript CMI, N–5036 Fantoft, Norway
128. Pardoux, E. (1979): Stochastic partial diﬀerential equations and ﬁltering of
diﬀusion processes. Stochastics 3, 127–167
129. Port, S., Stone, C. (1979): Brownian Motion and Classical Potential Theory.
Academic Press
130. Protter, P. (1990): Stochastic Integration and Diﬀerential Equations. Springer-
Verlag
131. Ramsey, F.P. (1928): A mathematical theory of saving. Economic J. 38, 543–
549

322
References
132. Rao, M. (1977): Brownian Motion and Classical Potential Theory. Aarhus
Univ. Lecture Notes in Mathematics 47
133. Rao, M.M. (1984): Probability Theory with Applications. Academic Press
134. Revuz, D., Yor, M. (1991): Continuous Martingales and Brownian Motion.
Springer-Verlag
135. Rogers, L.C.G., Williams, D. (1994): Diﬀusions, Markov Processes, and Mar-
tingales. Vol. 1, 2nd edition. J. Wiley & Sons
136. Rogers, L.C.G., Williams, D. (1987): Diﬀusions, Markov Processes, and Mar-
tingales. Vol. 2. J. Wiley & Sons
137. Rozanov, Yu.A. (1982): Markov Random Fields. Springer-Verlag
138. Samuelson, P.A. (1965): Rational theory of warrant pricing. Industrial man-
agem. review 6, 13–32
139. Shiryaev, A.N. (1978): Optimal Stopping Rules. Springer-Verlag
140. Shiryaev, A.N. (1999): Essentials of Stochastic Finance. World Scientiﬁc
141. Simon, B. (1979): Functional Integration and Quantum Physics. Academic
Press
142. Snell, J.L. (1952): Applications of martingale system theorems. Trans. Amer.
Math. Soc. 73, 293–312
143. Stratonovich, R.L. (1966): A new representation for stochastic integrals and
equations. J. Siam Control 4, 362–371
144. Stroock, D.W. (1971): On the growth of stochastic integrals. Z. Wahr. verw.
Geb. 18, 340–344
145. Stroock, D.W. (1981): Topics in Stochastic Diﬀerential Equations. Tata Insti-
tute of Fundamental Research. Springer-Verlag
146. Stroock, D.W. (1993): Probability Theory, An Analytic View. Cambride Uni-
versity Press
147. Stroock, D.W., Varadhan, S.R.S. (1979): Multidimensional Diﬀusion Pro-
cesses. Springer-Verlag
148. Sussmann, H.J. (1978): On the gap between deterministic and stochastic or-
dinary diﬀerential equations. The Annals of Prob. 60, 19–41
149. Taraskin, A. (1974): On the asymptotic normality of vectorvalued stochas-
tic integrals and estimates of drift parameters of a multidimensional diﬀusion
process. Theory Prob. Math. Statist. 2, 209–224
150. The Open University (1981): Mathematical models and methods, unit 11. The
Open University Press
151. Topsøe, F. (1978): An information theoretical game in connection with the
maximum entropy principle (Danish). Nordisk Matematisk Tidsskrift 25/26,
157–172
152. Turelli, M. (1977): Random environments and stochastic calculus. Theor. Pop.
Biology 12, 140–178
153. Ubøe, J. (1987): Conformal martingales and analytic functions. Math. Scand.
60, 292–309
154. Van Moerbeke, P. (1974): An optimal stopping problem with linear reward.
Acta Mathematica 132, 111–151
155. Williams, D. (1979): Diﬀusions, Markov Processes and Martingales. J. Wiley
& Sons
156. Williams, D. (1981) (editor): Stochastic Integrals. Lecture Notes in Mathe-
matics, vol. 851. Springer-Verlag
157. Williams, D. (1991): Probability with Martingales. Cambridge University
Press
158. Wong, E. (1971): Stochastic Processes in Information and Dynamical Systems.
McGraw-Hill

References
323
159. Wong, E., Zakai, M. (1969): Riemann-Stieltjes approximations of stochastic
integrals. Z. Wahr. verw. Geb. 120, 87–97
160. Yeh, J. (1995): Martingales and Stochastic Analysis. World Scientiﬁc
161. Yong, J., Zhou, X.Y. (1999): Stochastic Controls: Hamiltonian Systems and
HJB Equations. Springer-Verlag
162. Yor, M. (1992): Some Aspects of Brownian Motion, Part I. ETH Lectures in
Math. Birkh¨auser
163. Yor, M. (1997): Some Aspects of Brownian Motion, Part II. ETH Lectures in
Math. Birkh¨auser

324
References

List of Frequently Used Notation and Symbols
Rn
n-dimensional Euclidean space
R+
the non-negative real numbers
Q
the rational numbers
Z
the integers
Z+ = N
the natural numbers
C
the complex plane
Rn×m
the n × m matrices (real entries)
AT
the transposed of the matrix A
|C|
the determinant of the n × n matrix C
Rn ≃Rn×1
i.e. vectors in Rn are regarded as n × 1-matrices
Cn = C × · · · × C
the n-dimensional complex space
|x|2 = x2
nP
i=1
x2
i if x = (x1, . . . , xn) ∈Rn
x · y
the dot product
nP
i=1
xiyi if x = (x1, . . . , xn),
y = (y1, . . . , yn)
x+
max(x, 0) if x ∈R
x−
max(−x, 0) if x ∈R
sign x
½
1
if x ≥0
−1 if x < 0
C(U, V )
the continuous functions from U into V
C(U)
the same as C(U, R)
C0(U)
the functions in C(U) with compact support
Ck = Ck(U)
the functions in C(U, R) with continuous deriva-
tives up to order k
Ck
0 = Ck
0 (U)
the functions in Ck(U) with compact support in U
Ck+α
the functions in Ck whose k’th derivatives are Lip-
schitz continuous with exponent α
C1,2(R × Rn)
the functions f(t, x): R × Rn →R which are C1
w.r.t. t ∈R and C2 w.r.t. x ∈Rn
Cb(U)
the bounded continuous functions on U
f|K
the restriction of the function f to the set K
A = AX
the generator of an Itˆo diﬀusion X
A = AX
the characteristic operator of an Itˆo diﬀusion X

326
List of Frequently Used Notation and Symbols
L = LX
the second order partial diﬀerential operator which
coincides with AX on C2
0 and with AX on C2
Bt (or (Bt, F, Ω, P x))
Brownian motion
DA
the domain of deﬁnition of the operator A
∇
the gradient: ∇f = ( ∂f
∂x1 , . . . , ∂f
∂xn )
∆
the Laplace operator: ∆f = P
i
∂2f
∂x2
i
L
a semielliptic second order partial diﬀerential oper-
ator of the form L = P
i
bi ∂
∂xi + P
i,j
aij
∂2
∂xi∂xj
Rα
the resolvent operator
iﬀ
if and only if
a.a., a.e., a.s.
almost all, almost everywhere, almost surely
w.r.t.
with respect to
s.t.
such that
≃
coincides in law with (see Section 8.5)
E[Y ] = Eµ[Y ] =
R
Y dµ the expectation of the random variable Y w.r.t. the
measure µ
E[Y |N]
the conditional expectation of Y w.r.t. N
F∞
the σ-algebra generated by S
t>0
Ft
B
the Borel σ-algebra
Ft, F(m)
t
the σ-algebra generated by {Bs; s ≤t}, Bs is m-
dimensional
Fτ
the σ-algebra generated by {Bs∧τ; s ≥0} (τ is a
stopping time)
⊥
orthogonal to (in a Hilbert space)
Mt
the σ-algebra generated by {Xs; s ≤t} (Xt is an
Itˆo diﬀusion)
Mτ
the σ-algebra generated by {Xs∧τ; s ≥0} (τ is a
stopping time)
∂G
the boundary of the set G
G
the closure of the set G
G ⊂⊂H
G is compact and G ⊂H
d(y, K)
the distance from the point y ∈Rn to the set K ⊂
Rn
τG
the ﬁrst exit time from the set G of a process
Xt: τG = inf{t > 0; Xt /∈G}
V(S, T), Vn(S, T)
Deﬁnition 3.3.1
W, Wn
Deﬁnition 3.3.2
(H)
Hunt’s condition (Chapter 9)
HJB
the Hamilton-Jacobi-Bellman equation (Chapter 11)
In
the n × n identity matrix
XG
the indicator function of the set G XG(x) = 1 if
x ∈G, XG(x) = 0 if x /∈G

List of Frequently Used Notation and Symbols
327
P x
the probability law of Bt starting at x
P = P 0
the probability law of Bt starting at 0
Qx
the probability law of Xt starting at x (X0 = x)
R(s,x)
the probability law of
Yt = (s + t), Xx
t )t≤0 with
Y0 = (s, x) (Chapter 10)
Qs,x
the probability law of
Yt = (s + t, Xs,x
s+t)t≥0 with
Y0 = (s, x) (Chapter 11)
P ≪Q
the measure P is absolutely continuous w.r.t. the
measure Q
P ∼Q
P is equivalent to Q, i.e. P ≪Q and Q ≪P
Ex, E(s,x), Es,x
the expectation operator w.r.t. the measures Qx,
R(s,x) and Qs,x, respectively
EQ
the expectation w.r.t. the measure Q
E
the expectation w.r.t. a measure which is clear from
the context (usually P 0)
s ∧t
the minimum of s and t
(= min(s, t))
s ∨t
the maximum of s and t
(= max(s, t))
σT
the transposed of the matrix σ
δx
the unit point mass at x
δij
δij = 1 if i = j, δij = 0 if i ̸= j
θt
the shift operator: θt(f(Xs)) = f(Xt+s) (Chap-
ter 7)
θ(t)
portfolio (see (12.1.3))
V θ(t)
= θ(t) · X(t), the value process (see (12.1.4))
V θ
z (t)
= z +
tR
0
θ(s)dX(s), the value generated at time t by
the self-ﬁnancing portfolio θ if the initial value is z
(see (12.1.7))
X(t)
the normalized price vector (see (12.1.8)–(12.1.11))
ξ(t)
the discounting factor (see (12.1.9))
: =
equal to by deﬁnition
lim , lim
the same as lim inf, lim sup
ess inf f
sup{M ∈R ;
f ≥M a.s.}
ess sup f
inf{N ∈R ;
f ≤N a.s.}
⊔⊓
end of proof
“increasing” is used with the same meaning as “nondecreasing”, “decreas-
ing” with the same meaning as “nonincreasing”. In the strict cases “strictly
increasing/strictly decreasing” are used.

328
List of Frequently Used Notation and Symbols

Index
adapted process
25
admissible portfolio
251
American call option
284, 289
American contingent T-claim
276
American options
275–284
American put option
283–284
American put option, perpetual
289
analytic functions (and Brownian
motion)
76, 150
arbitrage
251
attainable claim
260
Bayes’ rule
152 (8.6.3)
Bellman principle
241
Bessel process
49, 140
bequest function
223
Black and Scholes formula
4, 160, 274,
288
Borel sets, Borel σ-algebra
8
Borel-Cantelli lemma
16
Brownian bridge
75
Brownian motion, in Rn
3, 11–14
Brownian motion, complex
76
Brownian motion, on the ellipse
73
Brownian motion, on the unit circle
65, 121
Brownian motion, on the unit sphere
149
Brownian motion, on a Riemannian
manifold
150
Brownian motion, the graph of
118
Brownian motion, w.r.t. an increasing
family Ht of σ-algebras
70
capacity
163
carrying capacity
77
characteristic function
292
characteristic operator
120
change of time
145
change of variable in an Itˆo integral
148
Chebychev’s inequality
16
coincide in law
140, 141
combined Dirichlet-Poisson problem
165–167, 182
complete market
260
complete probability space
8
complex Brownian motion
76
conditional expectation
295
conditioned Brownian motion
127
contingent T-claim (American)
276
contingent T-claim (European)
259
continuation region
201
continuous in mean square
40
control, deterministic (open loop)
225
control, feedback (closed loop)
225
control, Markov
225
control, optimal
224
convolution
302
covariance matrix
12, 291
cross-variation processes
152
crowded environment
77
density (of a random variable)
15
diﬀusion, Itˆo
107
diﬀusion, Dynkin
121
diﬀusion coeﬃcient
107
Dirichlet problem
2, 167
Dirichlet problem (generalized)
174
Dirichlet problem (stochastic version)
170
Dirichlet-Poisson problem
165–167,
182
distribution (of a random variable)
9
distribution (of a process)
10
distribution function (of a random
variable)
15
Doob-Dynkin lemma
8–9
Doob-Meyer decomposition
279
drift coeﬃcient
107
Dudley’s theorem
253
Dynkin’s formula
118
329

330
Index
eigenvalues (of the Laplacian)
187
elementary function/process
26
elliptic partial diﬀerential operator
165, 176
equivalent martingale measure
254,
264
estimate (linear/measurable)
85
estimation of a parameter
97
estimation, exact asymptotic
101, 102
European call option
4, 265, 288–289
European contingent T-claim
259
European option
265
European put option
266
events
8
excessive function
197
expectation
9
explosion (of a diﬀusion)
66, 78
exponential martingale
55
Feller-continuity
133
Feynman-Kac formula
135, 190
ﬁltering problem, general
2, 79–81
ﬁltering problem, linear
81–101
ﬁltration
31, 38
ﬁnite-dimensional distributions (of a
stochastic process)
10
ﬁrst exit distribution
130, 192
ﬁrst exit time
111
Gaussian process
12
generalized (distribution valued)
process
21
generator (of an Itˆo diﬀusion)
115,
117
geometric Brownian motion
62
Girsanov’s theorem
60, 153–158
Girsanov transformation
153
Green formula
184
Green function
163, 183, 191
Green function (classical)
183, 185
Green measure
18, 183, 238
Green operator
164
Gronwall inequality
68, 78
Hamilton-Jacobi-Bellman (HJB)
equation
226–230
harmonic extension (w.r.t. an Itˆo
diﬀusion)
122
harmonic function (and Brownian
motion)
150
harmonic function (w.r.t. a diﬀusion)
169
harmonic measure (of Brownian
motion)
124
harmonic measure (of a diﬀusion)
114, 115, 129
hedging portfolio
260
Hermite polynomials
38
high contact (smooth ﬁt) principle
210, 212, 218
hitting distribution
114, 115
Ht-Brownian motion
70
h-transform (of Brownian motion)
127
Hunt’s condition (H)
175
independent
9
independent increments
13, 22
innovation process
82, 86, 87, 90
integration by parts (stochastic)
46,
55
interpolation (smoothing)
103
irregular point
172, 188
iterated Itˆo integrals
38
iterated logarithm (law of)
64
Itˆo diﬀusion
107
Itˆo integral
24–37
Itˆo integral; multidimensional
34, 35
Itˆo interpretation (of a stochastic
diﬀerential equation)
36, 61, 79
Itˆo isometry
26, 29
Itˆo process
44, 48
Itˆo representation theorem
51
Itˆo’s formula
44, 48
Jensen inequality
296
Kalman-Bucy ﬁlter
2, 95, 100
Kazamaki condition
55
kernel function
127
killing (a diﬀusion)
137
killing rate
138, 164
Kolmogorov’s backward equation
131
Kolmogorov’s continuity theorem
14
Kolmogorov’s extension theorem
11
Kolmogorov’s forward equation
159
Langevin equation
74
Laplace operator ∆
3, 57
Laplace-Beltrami operator
150
law of iterated logarithm
64
least superharmonic majorant
196
least supermeanvalued majorant
196
Levy’s characterization of Brownian
motion
152
Levy’s theorem
151

Index
331
linear regulator problem
231
Lipschitz surface
213, 301
local martingale
126
local time
58, 59, 72
Lyapunov equation
103
Malliavin derivative
53
market
247
market, complete
260
market, normalized
247, 248
Markov control
225
Markov process
110
Markov property
109
martingale
31, 33, 298
martingale, local
126
martingale convergence theorem
298
martingale inequality
31
martingale problem
138
martingale representation theorem
49, 53
maximum likelihood
98
maximum principle
189
mean-reverting Ornstein-Uhlenbeck
process
74
mean square error
92
mean value property, classical
124
mean value property (for a diﬀusion)
114, 115
measurable function (w.r.t. a σ-algebra)
8
measurable sets (w.r.t. a σ-algebra)
8
measurable space
7
moving average, exponentially weighted
97
noise
1–4, 21–22, 61
normal distribution
12, 291
normalization (of a market process)
248
Novikov condition
55
numeraire
248
observation process
80
optimal control
224
optimal performance
224
optimal portfolio selection
4, 234
optimal stopping
3, 193–215
optimal stopping time
193, 199, 202,
213
optimal stopping existence theorem
199
optimal stopping uniqueness theorem
202
option pricing
4, 265–284
Ornstein-Uhlenbeck equation/process
74
orthogonal increments
82
path (of a stochastic process)
10
performance function
224
Perron-Wiener-Brelot solution
178
Poisson formula
189
Poisson kernel
189
Poisson problem
168
Poisson problem (generalized)
180
Poisson problem (stochastic version)
180
polar set
162, 175
population growth
1, 61, 77
portfolio
4, 236, 248–251
prediction
103
probability measure
7
probability space
8
p’th variation process
19
quadratic variation process
19, 56
random time change
145
random variable
9
recurrent
120
regular point
172–174, 188
replicating portfolio
260
resolvent operator
133
reward function
193
reward rate function
194
Riccati equation
93, 95, 101, 233
scaling (Brownian)
19
self-ﬁnancing portfolio
248
semi-elliptic partial diﬀerential operator
165
semi-polar set
175
separation principle
225, 233
shift operator
113
Snell envelope
279
smoothing (interpolation)
103
stationary process
21, 22
stochastic control
4, 223–240
stochastic diﬀerential equation;
deﬁnition
61
stochastic diﬀerential equation;
existence and uniqueness of solution
66
stochastic diﬀerential equation; weak
and strong solution
70
stochastic Dirichlet problem
170
stochastic integral
44
stochastic Poisson problem
180

332
Index
stochastic process
9
stopping time
57, 110
Stratonovich integral
24, 35–37, 39, 40
Stratonovich interpretation (of a
stochastic diﬀerential equation)
36,
62, 63, 64, 79
strong Feller process
177
strong Markov property
110–113
strong solution (of a stochastic
diﬀerential equation)
70
strong uniqueness (of a stochastic
diﬀerential equation)
67, 71
submartingale
298
superharmonic function
194
superharmonic majorant
196
supermartingale
(126), 196, 253, 266,
279, 298
supermeanvalued function
194
supermeanvalued majorant
196
superreplicate
279
support (of a diﬀusion)
105
Tanaka’s equation
71
Tanaka’s formula
58, 59, 72
terminal conditions (in stochastic
control)
239–240, 245
thin set
175
time-homogeneous
108
time change formula Itˆo integrals
148
total variation process
19
transient
120
transition measure
184
transition operator
164
trap
121
uniformly elliptic partial diﬀerential
operator
176, 269
uniformly integrable
297–298
utility function
4, 234
value function
224
value process
248
value process, normalized
249
variational inequalities (and optimal
stopping)
3, 212–215
version (of a process)
(12), 14, 32
Volterra equation, deterministic
89
Volterra equation, stochastic
75
weak solution (of a stochastic
diﬀerential equation)
70
weak uniqueness
71
well posed (martingale problem)
139
white noise
21, 61
Wiener criterion
174
X-harmonic
169
zero-one law
171
σ-algebra
7
σ-algebra, generated by a family of sets
8
σ-algebra, generated by a random
variable
8

