10/12/13	

1	

Statistics One 
Lecture 7 
Introduction to Regression 
1 
Three segments 
•  Overview 
•  Calculation of regression coefficients 
•  Assumptions 
2 
Lecture 7 ~ Segment 1 
Regression: Overview 
3 
Regression: Overview 
•  Important concepts & topics 
– Simple regression vs. multiple regression 
– Regression equation  
– Regression model 
4 

10/12/13	

2	

Regression: Overview 
•  Regression: a statistical analysis used to 
predict scores on an outcome variable, 
based on scores on one or multiple 
predictor variables 
– Simple regression: one predictor variable 
– Multiple regression: multiple predictors 
5 
Regression: Overview 
•  Example: IMPACT (see Lab 2) 
– An online assessment tool to investigate the 
effects of sports-related concussion 
•  http://www.impacttest.com 
6 
IMPACT example 
•  IMPACT provides data on 6 variables 
–  Verbal memory 
–  Visual memory 
–  Visual motor speed  
–  Reaction time  
–  Impulse control  
–  Symptom score 
7 
IMPACT: Correlations pre-
injury 
8 

10/12/13	

3	

IMPACT: Correlations pre-
injury 
9 
IMPACT: Correlations post-
injury 
10 
IMPACT: Correlations post-
injury 
11 
IMPACT example 
12 
•  For this example, assume: 
– Symptom Score is the outcome variable 
– Simple regression example: 
•  Predict Symptom Score from just one variable  
– Multiple regression example: 
•  Predict Symptom Score from two variables  

10/12/13	

4	

Regression equation 
•  Y = m + bX + e  
– Y is a linear function of X 
– m = intercept 
– b = slope 
– e = error (residual) 
13 
Regression equation 
•  Y = B0 + B1X1 + e 
– Y is a linear function of X1 
– B0 = intercept = regression constant 
– B1 = slope = regression coefficient 
– e = error (residual) 
14 
Model R and R2 
•  R = multiple correlation coefficient 
– R = rÝY 
– The correlation between the predicted scores 
and the observed scores  
•  R2 
– The percentage of variance in Y explained by 
the model 
15 
IMPACT example 
•  Y = B0 + B1X1 + e 
–  Let Y = Symptom Score 
–  Let X1 = Impulse Control 
–  Solve for B0 and B1 
– In R, function lm 
16 

10/12/13	

5	

IMPACT example 
17 
Ŷ = 20.48 + 1.43(X)	

	

r = .40	

	

R2 = 16%	

	

IMPACT example 
18 
Regression model 
•  The regression model is used to model or 
predict future behavior 
– The model is just the regression equation 
– Later in the course we will discuss more 
complex models that consist of a set of 
regression equations 
19 
Regression: It gets better 
•  The goal is to produce better models so 
we can generate more accurate 
predictions 
– Add more predictor variables, and/or… 
– Develop better predictor variables  
  
20 

10/12/13	

6	

IMPACT example 
•  Y = B0 + B1X1 + B2X2 + e 
–  Let Y = Symptom Score 
–  Let X1 = Impulse Control 
–  Let X2 = Verbal Memory 
–  Solve for B0 and B1 and B2 
– In R, function lm 
21 
IMPACT example 
22 
Ŷ = 4.13 + 1.48(X1) + 0.22(X2)	

	

R2 = 22%	

	

IMPACT example 
23 
Model R and R2 
•  R = multiple correlation coefficient 
– R = rÝY 
– The correlation between the predicted scores 
and the observed scores  
•  R2 
– The percentage of variance in Y explained by 
the model 
24 

10/12/13	

7	

IMPACT example 
25 
R2 = 22%	

	

rÝY = .47	

Segment summary 
•  Important concepts & topics 
– Simple regression vs. multiple regression 
– Regression equation  
– Regression model 
26 
END SEGMENT 
27 
Lecture 7 ~ Segment 2 
Calculation of regression coefficients 
28 

10/12/13	

8	

Estimation of coefficients  
•  Regression equation: 
– Y = B0 + B1X1 + e 
– Ŷ = B0 + B1X1  
•  (Y – Ŷ) = e (residual) 
29 
Estimation of coefficients 
•  The values of the coefficients (e.g., B1) are 
estimated such that the regression model 
yields optimal predictions   
– Minimize the residuals! 
30 
Estimation of coefficients 
•  Ordinary Least Squares estimation  
– Minimize the sum of the squared (SS) 
residuals 
– SS.RESIDUAL = Σ(Y – Ŷ)2  
 
31 
IMPACT example 
32 

10/12/13	

9	

Estimation of coefficients 
•  Sum of Squared deviation scores (SS) in variable 
Y 
–  SS.Y 
33 
SS.Y à	

Estimation of coefficients 
•  Sum of Squared deviation scores (SS) in variable 
X 
–  SS.X 
34 
SS.X à	

Estimation of coefficients 
•  Sum of Cross Products 
–  SP.XY  
 
35 
SS.Y à	

SS.X à	

SP.XY	

Estimation of coefficients 
•  Sum of Cross Products = SS of the Model 
–  SP.XY = SS.MODEL  
 
36 
SS.Y à	

SS.X à	

SS.MODEL	


10/12/13	

10	

Estimation of coefficients 
•  SS.RESIDUAL = (SS.Y – SS.MODEL) 
37 
SS.Y à	

SS.X à	

SS.MODEL	

SS.RESIDUAL	

Estimation of coefficients 
•  Formula for the unstandardized coefficient 
– B1 = r x (SDy/ SDx) 
38 
Estimation of coefficients 
•  Formula for the standardized coefficient  
– If X and Y are standardized then 
•  SDy = SDx = 1 
•  B = r x (SDy/ SDx) 
•  β = r 
 
39 
Segment summary 
•  Important concepts 
– Regression equation and model 
– Ordinary least squares estimation 
– Unstandardized regression coefficients 
– Standardized regression coefficients  
40 

10/12/13	

11	

END SEGMENT 
41 
Lecture 7 ~ Segment 3 
Assumptions 
42 
Assumptions 
•  Assumptions of linear regression 
– Normal distribution for Y 
– Linear relationship between X and Y 
– Homoscedasticity 
43 
Assumptions 
•  Assumptions of linear regression 
– Reliability of X and Y 
– Validity of X and Y 
– Random and representative sampling 
44 

10/12/13	

12	

Assumptions 
•  Assumptions of linear regression 
– Normal distribution for Y 
– Linear relationship between X and Y 
– Homoscedasticity 
45 
Anscombe’s quartet 
46 
Anscombe’s quartet 
•  Regression equation for all 4 examples: 
– Ŷ = 3.00 + 0.50(X1) 
47 
Anscombe’s quartet 
•  To test assumptions, save residuals  
–  Y = B0 + B1X1 + e 
–  e = (Y – Ŷ) 
48 

10/12/13	

13	

Anscombe’s quartet 
•  Then examine a scatterplot with  
– X on the X-axis 
– Residuals on the Y-axis 
49 
Anscombe’s quartet 
50 
Segment summary 
•  Assumptions when interpreting r 
– Normal distributions for Y 
– Linear relationship between X and Y 
– Homoscedasticity 
– Examine residuals to evaluate assumptions 
51 
END SEGMENT 
52 

10/12/13	

14	

END LECTURE 7 
53 

