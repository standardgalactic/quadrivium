Pawel Scharoch 
Maciej P. Polak 
Radoslaw Szymon
A FIRST GUIDE TO
COMPUTATIONAL 
MODELLING
IN PHYSICS

A First Guide to Computational Modelling in Physics
This innovative text helps demystify numerical modelling for early- 
stage physics and engineering students. It takes a hands-on, project­
based approach, with each project focusing on an intriguing physics 
problem taken from classical mechanics, electrodynamics, thermody­
namics, astrophysics, and quantum mechanics. To solve these prob­
lems, students must apply different numerical methods for themselves, 
building up their knowledge and practical skills organically. Each 
project includes a discussion of the fundamentals, the mathematical for­
mulation of the problem, an introduction to the numerical methods and 
algorithms, and exercises, with solutions available to instructors. The 
methods presented focus primarily on differential equations, both ordi­
nary and partial, as well as basic mathematical operations. Developed 
over many years of teaching a computational modelling course, this 
stand-alone book equips students with an essential numerical modelling 
toolkit for today’s data-driven landscape, and gives them new ways to 
explore science and engineering.
Paw el Scharoch is University Professor within the Department 
of Semiconductor Materials Engineering at Wroclaw University of Sci­
ence and Technology, Poland. He has also held positions at Durham 
University, the Fritz Haber Institute, Berlin, and at Orange Labs Poland. 
His principal work is on structural and electronic properties of atomic 
systems. Professor Scharoch also has around thirty years of experi­
ence in teaching various courses in general physics and computational 
physics.
MAcIEJ P. POLAK holds a PhD in Physics from Wroclaw Univer­
sity of Science and Technology and is currently a dedicated researcher 
at University of Wisconsin-Madison’s Department of Materials Science 
and Engineering. He works on first-principles modelling of the elec­
tronic band structure of highly mismatched semiconductor alloys for 
their use in opto-electronics and metals for space applications devices. 
With over thirty published peer-reviewed articles, he consistently strives 
to push the boundaries in scientific exploration.
RADOSlAW SZYMON, MSc, graduated with honours from Wroclaw 
University of Science and Technology in 2022. He is currently pursuing 
a PhD in semiconductor technology at the same institution, supported 
by the prestigious Pearl of Science grant. He also enjoys conducting 
physics simulations, in particular in electromagnetism and quantum 
mechanics.

A First Guide
to Computational 
Modelling
in Physics
Pawet Scharoch
Wroclaw University of
Science and Technology
M a c i e j P. P o l a k
University of
Wisconsin-Madison
Rad o staw
Szymon
Wroclaw University of
Science and Technology
Software developed by
Katarzyna
H o t o d n i k -
M a t e c k a
Wroclaw University of
Science and Technology
@1 CAMBRIDGE
W.F UNIVERSITY PRESS

CAMBRIDGE
UNIVERSITY PRESS
Shaftesbury Road, Cambridge CB2 8EA, United Kingdom
One Liberty Plaza, 20th Floor, New York, NY 10006, USA
477 Williamstown Road, Port Melbourne, VIC 3207, Australia
314-321, 3rd Floor, Plot 3, Splendor Forum, Jasola District Centre,
New Delhi - 110025, India
103 Penang Road, #05-06/07, Visioncrest Commercial, Singapore 238467
Cambridge University Press is part of Cambridge University Press & Assessment, 
a department of the University of Cambridge.
We share the University’s mission to contribute to society through the pursuit of 
education, learning and research at the highest international levels of excellence.
www.cambridge.org
Information on this title: www.cambridge.org/9781009413121
DOI: 10.1017/9781009413138
© Pawet Scharoch, MaciejP. Polak and Radostaw Szymon 2024
Software components © Katarzyna Hotodnik-Matecka 2024
This publication is in copyright. Subject to statutory exception and to the provisions 
of relevant collective licensing agreements, no reproduction of any part may take 
place without the written permission of Cambridge University Press & Assessment.
First published 2024
A catalogue record for this publication is available from the British Library
A Cataloging-in-Publication data record for this book is available from the Library of 
Congress
ISBN 978-1-009-41312-1 Hardback
ISBN 978-1-009-41310-7 Paperback
Cambridge University Press & Assessment has no responsibility for the persistence 
or accuracy of URLs for external or third-party internet websites referred to in this 
publication and does not guarantee that any content on such websites is, or will 
remain, accurate or appropriate.

Contents
Preface
How to Use the Book
First Steps
Basic Mathematical Operations
0.1 Finding Roots of a 1D Function
0.2 Finding Minimum of a 1D Function
0.3 Exercises
Project 1: Rectangular Finite Quantum
Well - Stationary Schrodinger Equation in
1D
1.1 
Physics Background: Chosen Ideas of Quantum 
Mechanics
1.2 
Problem: Eigenenergies and Eigenfunctions
in Rectangular Finite Quantum Well
1.3 
Numerical Methods: Finding Roots of Characteristic 
Functions
1.4 
Exercises
Project 2: Diffraction of Light on a Slit
2.1 
Physics Background: Elements of Wave Physics
2.2 
Problem: Diffraction of a Wave on a Slit
2.3 
Numerical Methods: Schemes Based on Local 
Approximations of a Function
2.4 
Exercises
Project 3: Pendulum as a Standard 
of the Unit of Time
3.1 
Physics Background: Newton’s Laws of Motion, 
Equation of Motion
3.2 
Problem: Simple Pendulum as a Standard of the Unit 
of Time
page ix 
xii
xv
xv
xv
xvi
xviii
1
1
4
5
6
7
7
10
11
14
18
18
19
v

vi Contents
3.3 
Numerical Methods: Recursive Methods Based
on Local Extrapolation of One-Step Integral
Integrand 
21
3.4 
Exercises 
23
Project 4: Planetary System 
26
4.1 
Physics Background: Law of Universal
Gravitation 
26
4.2 
Problem: Motion of Planets in the Field of a Fixed
Star 
28
4.3 
Reduction of a Single Planet Motion in a Central
Field to 1D 
29
4.4 
Numerical Method: Verlet Algorithm 
31
4.5 
Exercises 
31
Project 5: Gravitation inside a Star 
34
5.1 
Physics Background: Gauss’s Law, Poisson’s
Equation 
35
5.2 
Problem: Gravitational Field Due to a Continuous
Mass Density Distribution 
36
5.3 
Numerical Method: Numerov-Cowells
Algorithm 
37
5.4 
Exercises 
38
Project 6: Normal Modes in a Cylindrical
Waveguide 
40
6.1 
Physics Background: Wave Equation, Standing
Waves 
40
6.2 
Problem: Normal Modes in an Optical Fibre 
41
6.3 
Numerical Method: Shooting Method 
42
6.4 
Exercises 
43
Project 7: Thermal Insulation Properties
of a Wall 
45
7.1 
Physics Background: Steady-State Diffusion 
45
7.2 
Problem: Steady-State Diffusion of Heat through the
Wall 
46
7.3 
Numerical Method: Finite Difference Method 
47
7.4 
Exercises 
50
Project 8: Cylindrical Capacitor 
52
8.1 
Physics Background: Variational Principle for
Electrostatic Systems 
53

Contents vii
8.2 
Problem: Cylindrical Capacitor 
54
8.3 
Numerical Method: Finite Elements (FE)
Method 
54
8.4 
Exercises 
56
Advanced Projects 
57
Project 9: Coupled Harmonic Oscillators 
58
9.1 
Problem: Equations of Motion of Coupled
Oscillators 
58
9.2 
Exercises 
60
Project 10: The Fermi-Pasta-Ulam-Tsingou
Problem 
64
10.1 
Problem: Dynamics of a One-Dimensional Chain of
Interacting Point Masses 
64
10.2 
Exercises 
70
Project 11: Hydrogen Star 
72
11.1 
Problem: Mass Density Distribution in a Cold
Hydrogen Star 
72
11.2 Numerical Method 
73
11.3 
Exercises 
76
Project 12: Rectangular Quantum Well Filled with 
Electrons - The Idea of Self-Consistent
Calculations 
78
12.1 
Problem: Quantum Well Filled with Electrons and
Charge Neutralising Jellium 
79
12.2 
Exercises 
80
Project 13: Time Dependent Schrodinger Equation 
81
Dawid Dworzanski
13.1 
Problem: Time Evolution of a Wave Function in 2D
Quantum Well 
81
13.2 
Exercises 
84
Project 14: Poisson’s Equation in 2D 
86
14.1 
Problem: Variational Computational Approach to a
2D Electrostatic System 
86
14.2 Numerical Method: Finite Elements (FE) 
Method 
87
14.3 
Exercises 
89

viii Contents
Appendix A: Supplementary Materials
92
A.1 Euler Representation of a Complex Number
92
A.2 Local Representation of a Function as a Power
Series
94
A.3 Wilberforce’s Pendulum
96
A.4 Dispersion Relation for FPU Problem
96
A.5 Equivalence of Variational Principle and Poisson’s
Equation in Electrostatics
97
A.6 First and Second Uniqueness Theory
98
A.7 Discretisation of 2D Laplace’s Functional
100
A.8 Density of Star
102
A.9 Energy and Pressure of a Cubic Hydrogen Atom
Lattice as a Function of Unit Cell Volume
105
Further Reading
107
Index
108

Preface
Numerical modelling is a relatively recent and powerful scientific tool 
that has experienced remarkable development since the mid-twentieth 
century, fuelled by advancements in computer technology. Today, it 
is difficult to find a field in science or engineering where compu­
tational methods do not play a crucial role. The list of benefits is 
extensive, including new opportunities such as predicting the properties 
of physical systems, exploring properties that are not experimentally 
accessible, obtaining quantitative data that require massive amounts of 
mathematical operations, processing vast amounts of data, and facil­
itating machine learning, among others. These new opportunities are 
accompanied by the relative ease of application, rapid acquisition 
of valuable results, and cost-effectiveness. As a result of these fea­
tures, computational methods have become an independent scientific 
tool, complementing experiment and theory. On the one hand, they 
extend mathematical modelling and could not exist without it; on the 
other hand, they establish their own methodology, often resembling 
experimental work through the use of virtual systems. Computational 
methods have proven to be invaluable in supporting experimental 
research, technological advancements, and even theoretical physics, 
where mathematical models often require extensive numerical calcu­
lations to yield results in the form of quantitative data. Considering 
the aforementioned points, it is clear that various aspects of numerical 
modelling should be an integral part of academic education, partic­
ularly in the fields of science and engineering. In fact, universities 
worldwide have been offering such educational components for years, 
often as independent specialisations, such as Applied Computer Sci­
ence or Big Data. These specialisations focus on diverse aspects of 
computer applications in science and technology, with an emphasis on 
numerical modelling. This course is designed to address the need for 
numerical modelling education. Its level is tailored so that first-year 
physics or engineering students can fully engage with the material. It 
is crucial to introduce these methods early in higher education, as they 
continue to grow in popularity. The course employs a project-oriented 
ix

x Preface
teaching approach, as suggested by the title A First Guide to Com­
putational Modelling in Physics. Rather than systematically covering 
numerical methods, the course introduces them as tools necessary for 
solving specific problems. This approach makes learning the methods 
more engaging and goal-oriented. Aside from the ‘First Steps’ section, 
which teaches students numerical methods for basic mathematical oper­
ations (finding zeros and extrema of a function), the course is divided 
into eight basic and six advanced projects. Each basic project begins 
with an introduction to the necessary physics background, followed by 
a presentation and discussion ofa specific problem and its mathematical 
description. Next, the required numerical methods and algorithms are 
introduced, and finally, a set of exercises is proposed. Advanced projects 
build upon the previously introduced physics background and provide 
opportunities for students to conduct their first computational investiga­
tions, allowing for the realisation of individual research scenarios. This 
book is designed as a stand-alone resource, containing all the necessary 
materials for the completion of each project. While there is no strict 
requirement to use other sources, students are strongly encouraged to 
expand their knowledge base by consulting additional literature, as this 
is an inherent aspect of higher education.
The methods presented in this book primarily focus on differential 
equations, both ordinary (ODE) and partial (PDE), while also covering 
basic mathematical operations, derivatives, and quadrature, as intro­
duced in the second project (Diffraction on a Slit). The book addresses 
typical problems such as initial value problems (IVP), boundary value 
problems (BVP), and eigenvalue problems (EVP). Most of the methods 
discussed are based on variable discretisation and recursive algorithms 
for ODEs. For PDEs, the methods of finite difference (FD) and finite 
elements (FE) are explained, along with selected matrix methods for 
solving systems of equations (FD) and chosen iterative optimisation 
methods (FE). In the case of PDEs, system symmetry is utilised to 
reduce dimensionality from 3D to 1D, simplifying implementation and 
allowing projects to be completed within reasonable time constraints.
An additional benefit of this course is the effective learning of 
physics, as it offers strong motivation for revisiting and expanding 
upon one’s knowledge. Each project is prefaced by a brief presenta­
tion of the relevant physical background. While these presentations 
are not exhaustive, they are designed to be coherent, provide sufficient 
information for project execution, and inspire deeper study.
The authors would like to extend their gratitude to Anna Latosinska 
for her creative review of the and to Dawid Dworzanski for develop­
ing the project ‘Evolution of a Wave Function in a 1D Quantum Well’, 

Preface
xi
and to Kamil Wrzos and Piotr Tokarczyk for their contribution to the 
project ‘Hydrogen Star’. Additionally, they acknowledge the significant 
contributions of Technical Physics and Quantum Engineering students 
from the Faculty of Fundamental Problems of Technology at Wroclaw 
University of Science and Technology, who contributed to development 
and verification of computer codes in C++ and Python.

How to Use the Book
Students participating in this course are expected to possess a general 
understanding of physics at an academic level, be familiar with a chosen 
operating system, know how to use a selected graphics application, and 
have basic programming skills in a chosen language.
Before embarking on the projects, it is recommended that stu­
dents read the ‘First Steps’ chapter and complete the exercises therein. 
The basic mathematical operations discussed in this chapter (find­
ing zeros and extrema of a function) are relatively simple yet highly 
useful. Completing these exercises will familiarise students with the 
working environment, including the computer, operating system, pro­
gramming environment, and graphical tools, thereby making it easier 
to work on subsequent projects. The first eight projects are Basic, 
each containing four sections: 1. Physical Background, 2. The Prob­
lem, 3. Numerical Methods, and 4. Exercises. Project 4 includes an 
additional section, ‘Reduction of a Single Planet Motion in a Cen­
tral Field to 1D’. Advanced projects (9-14) build upon the physical 
background introduced earlier and typically contain only problem defi­
nitions, occasionally featuring a description of the numerical algorithm 
if not previously introduced, and exercises. When working on basic 
projects, students should begin by reviewing or learning the phys­
ics background and familiarising themselves with the physical system 
under consideration, along with its mathematical description (Sections 
1 and 2). If necessary, students should consult additional sources to 
address any difficulties in understanding, although the material pro­
vided in the book should be sufficient for completing the projects. 
The next section, ‘Numerical Methods’, is crucial to achieving the pri­
mary goal of the course. In this section, numerical algorithms are either 
fully derived or their underlying concepts are explained to facilitate 
their conscientious use and help prevent errors arising from the digital 
character of analysis. Students are also encouraged to derive numerical 
formulas on their own, following the given ideas (which often appear 
xii

How to Use the Book xiii
as exercises). Understanding the rationale behind a specific numerical 
formula is more important than being able to derive it. The final section 
contains exercises that should be completed using a computer program.
Exercises in this course are divided into three categories: basic 
(which should be completed by all students), supplementary (designed 
to deepen and strengthen knowledge and skills), and advanced 
(intended for students with a particular interest in the subject mat­
ter). Within the basic exercises, emphasis is placed on crucial steps in 
computational work:
1. Testing the program. This involves running the program for cases 
where the results are known from other sources (e.g., analytical solu­
tions) and verifying that the program reproduces these results. This 
step is typically associated with the initial runs of the program after 
the code has been written and cleared of any errors that may have 
arisen.
2. Testing the effect of control parameters and establishing their 
correct values. This step is an essential aspect of computational 
work. The creation and implementation of numerical algorithms 
always involve the digitisation of analog formulas, which introduces 
technical parameters controlling the procedure, such as time steps 
or grid parameters for spatial variables. Incorrect values for these 
parameters can adversely affect the results and lead to errors. A fun­
damental method for assessing the impact of control parameters is 
the convergence test, which examines results as a function of a given 
parameter value. The issue becomes more complex when multiple 
control parameters are involved, as correlations between them may 
exist. However, the aim of this course is mostly to highlight the 
problem. Methods for evaluating the influence of control parame­
ters by examining physical quantities (e.g., conservation laws) will 
be further described in the book.
3. Virtual experiments. This stage represents the primary objective 
of all preceding work. Once we are confident that the program is 
functioning correctly and have determined the appropriate values for 
control parameters, we can begin investigating the properties of a 
system. This process usually involves conducting experiments on a 
virtual system, observing its behaviour under various physical condi­
tions (e.g. the motion of planets in a planetary system with different 
initial conditions).

xiv How to Use the Book
Preliminary versions of the codes can be found in the online 
repository.
Figure 0.1 Internet 
repository;
https://wppt.pwr.edu.pl/ 
PhysModelCodes
It is recommended that students write the first two to three codes in 
their chosen programming language to test and practice their program­
ming skills and, if necessary, expand their knowledge. Model codes 
have been prepared in Python, complete with detailed descriptions 
(Python Notebooks), but Fortran and C++ versions are also availa­
ble if preferred. The programs have been designed for clarity rather 
than optimisation in terms of efficiency. Some exercises require code 
modifications, providing an opportunity to practice programming skills 
further.
In addition to the eight basic projects, the book offers six advanced 
projects. These projects allow students to apply the methods learned 
throughout the course to the analysis of more complex physical sys­
tems. It is recommended that students with a particular interest in 
computational research undertake a chosen advanced project individ­
ually. All work throughout the course can be completed using free 
tools available on the Internet (e.g. Spyder for Python, Force for 
FORTRAN, Gnuplot for graphics).

First Steps
During this first computer lab session, students will learn or review the 
basic elements of their chosen programming language, programming 
environment, and graphical program. They will be introduced to numer­
ical methods for fundamental mathematical operations, such as finding 
the roots and the minimum or maximum ofa 1D function. Furthermore, 
students will practice essential programming operations, including loop 
instructions and tabulating data from 1D and 2D functions.
Basic Mathematical Operations
0.1 Finding Roots of a 1D Function
0.1.1 Bisection Method
Let’s start from the case where we are sure that a single root of a func­
tion f (x) is somewhere within the interval (xl, xr) (Figure 0.2). That 
means we already know the root of the function with an uncertainty of 
1 x d (xr — xl). To reduce the uncertainty, we cut the interval from the 
previous step in half, and find the point in the middle xm d (xr — xl)=2. 
We then get two new intervals, two times shorter than the previous one. 
However, the root of the function may be present only in one of them 
(it may happen that xm is already the root, and this should be checked 
in the program). In order to identify the one within which the function 
crosses zero we check the condition f (xm) f (xr) < 0 (the function 
changes its sign). If the condition is true, the root is in the (xl, xr) inter­
val, if not, then it is in the other one. We denote the ends of the new 
interval again by (xl , xr) by replacing xm D xl (or xm D xr) and repeat 
the procedure. After n steps, the length of the domain segment contain­
ing zero is reduced by of factor 2n and when it is less than the assumed
Figure 0.2 The bisection 
method
xv

xvi Basic Mathematical Operations
uncertainty , that is the condition 1x < is fulfilled, the whole proce­
dure stops. Alternatively, we can predict how many steps (n) are needed 
from the condition that after n steps the initial interval is reduced by a 
factor of 2n, and perform only this number of steps.
0.1.2 Secant and Newton-Rhapson Methods
The bisection method is very safe but not the most efficient. The 
popular (and often more effective) alternatives are the secant and 
Newton-Raphson methods (Figure 0.3). The Newton-Raphson method 
is useful when together with the function f (x) its analytical derivative is 
also known. Using the derivative we construct a linear approximation 
of the function f (x) at the point xn. Then we approximate the root of 
f (x) by the zero of the linear function (xn +1), xn +1 d xn — f (xn)=f0(xn). 
This root is treated as the new starting point and the iteration procedure 
continues until a few subsequent changes in xn are smaller than the 
assumed uncertainty . The algorithm can be applied only if a power 
series expansion of the function f (x) in the vicinity of its root contains 
a linear term. Of course, we usually do not know in advance if this is 
the case. Thus this procedure, although quickly convergent, should be 
applied with caution. The secant method is similar to Newton-Raphson 
except that the derivative of a function is found numerically, using, for 
example a three-point scheme (see Project 2). However, it should be 
noted that this scheme requires several evaluations of the function f (x) 
at each iteration step, and this may appear to be less efficient than the 
safer bisection method.
Figure 0.3 The Newton-
Raphson method
0.2 Finding Minimum of a 1D Function
0.2.1 Golden Section Search
Determining the minimum (or maximum) of a 1D function is a crucial 
task, as many optimisation methods in multidimensional spaces rely on 
directional minimisation. It is worth noting that finding the minimum

0.2 Finding Minimum of a 1D Function xvii
is equivalent to finding the maximum since changing the sign of the 
function converts maxima to minima and vice versa. Therefore, our 
discussion will primarily focus on identifying the minimum.
Figure 0.4 The Golden
Section Search
To identify the domain interval containing a minimum in the inter­
val, assuming that there is only one, we need a checking point xc within 
the interval (xl, xr) (Figure 0.4). We can be sure that the minimum is 
present in the interval if f (xc) < f (xl) and f (xc) < f (xr). In con­
structing the algorithm one should focus on a proper choice of the 
new, fourth checking point xn . By introducing the fourth point in the 
interval (xl , xr) we obtain two overlapping regions, each defined by 
three points. We can then identify the one containing the minimum 
using the condition above. To assure the optimal convergence, the two 
regions should have the shortest possible and equal length (at each 
step). This can be achieved if at each step the fourth point splits the 
longer of the two segments (xl, xc) and (xc, xr) in golden section ratio, 
that is hl=(hl C hs) D hs=hl (hl is the longer segment, hs is the shorter 
segment). By substituting x D hs=hl into the above golden section con­
dition we get the equation x2 C x — 1 = 0, whose one of the solutions 
(V5 - 1)=2 « 0.62 is the Golden Section proportion, known in art 
and architecture from ancient times. Thus, after n steps the length of 
starting interval reduces by factor (0.62)n, which is a little bit slower 
than in the bisection algorithm of finding the root. The Golden Section 
Search is an always convergent, safe, and effective method of finding a 
minimum, but it is not the most efficient.
0.2.2 Other Methods
If the analytical form of the first derivative is known, then the minimum 
(or maximum) can be found by finding a root of the derivative. The 
derivative can be also approximated by a numerical formula.

xviii Basic Mathematical Operations
The method of parabolas is based on a parabolic approximation, 
is analogous to the secant method for finding roots, and is often very 
effective. Using three points, xl, xc , xr we can unambiguously locally 
approximate the function with a parabola. The position of the parabola’s 
minimum is already an approximation of the function minimum but can 
be treated as the fourth control point xc. The condition f (xc) < f (xl) and 
f (xc) < f (xr) allows to identify the segment containing the minimum. 
The function is then approximated with a parabola again in the new 
interval, and the procedure is repeated until a required uncertainty , in 
relation to the length of the last interval, is achieved.
Figure 0.5 The Simplex 
method
The 1D Simplex method (Figure 0.5) is the simplest method to 
search for the minimum which uses a test window rather than three 
points. Starting from a certain point, the domain is scanned in the 
direction where function decreases, let’s say to the right, by moving 
a window (xl,xr) of certain length h d (xr — xl). The domain interval 
containing minimum is found if the function begins to increase, that is 
f (xl) < f (xr). At this point the window length is cut in half and the 
search continues from the xr where the increase has been noticed, but 
in the opposite direction, until the condition f (xr) < f (xl) is fulfilled, 
which, again, is a signal to turn around. The procedure continues until 
h < , where is the assumed uncertainty. A great advantage of the 
method is that it can serve for finding interval containing the minimum 
in general, and then other, more effective methods can be applied to 
find it precisely.
0.3 Exercises
Obligatory
1. Using the program FTABLE tabulate your own function and visu­
alise it with a graphical program.

0.3 Exercises xix
2. Modify the FTABLE code so that it can tabulate a 2D function; set 
your own function and visualise it.
3. Test the BISEC code by finding the roots of a chosen second-order 
polynomial and comparing the results with analytical solutions.
4. Find the value of the number as a zero of the sin(x) function. What 
precision can you achieve? Explain why.
Advanced
1. Write a 1DMINIMUM code that finds the minimum of a 1D func­
tion using one of the algorithms presented above (Golden Search, 
Parabolas or 1D Simplex). Test the program by finding the mini­
mum of a chosen second-order polynomial and compare the results 
with analytical solution. Find the value of number as a minimum 
of cos(x) function. What precision can you achieve? Explain why.


Project 1
Rectangular Finite Quantum
Well - Stationary Schrodinger Equation 
in 1D
In this project, participants utilise the procedure of finding roots of 
functions to solve the eigenvalue problem of a rectangular quantum 
well (QWELL code). When considering the rectangular quantum well 
as the simplest model of a hydrogen atom, the code can be applied to 
determine its first two to three energy levels, which is the primary exer­
cise in the project. The eigenvalue problem itself, appearing in various 
areas of physics (such as vibration mechanics, wave optics, and quan­
tum mechanics), will be the subject of a separate project (Project 6) and 
one of the advanced projects (Project 12), where a rectangular quantum 
well partially filled with electrons is examined. It is somewhat para­
doxical that despite employing the simplest mathematical operations in 
the current project, it is based on advanced physical concepts, such as 
quantum mechanics, often unfamiliar to first-year students. Learning 
the basics of quantum mechanics typically requires a 30-hour course 
and knowledge of advanced mathematics. Therefore, we will only intro­
duce its fundamental and most straightforward ideas here, just enough 
to enable the conscious execution of the project.
1.1 Physics Background: Chosen Ideas of 
Quantum Mechanics
In quantum mechanics, while the physical quantities of interest, such 
as position or momentum of a particle, remain the same as in classical 
physics, their representation is entirely different. Focusing on the prob­
lem of a single particle, the central object is the quantum state rather 
than the coordinates in the chosen system (as it would be in classi­
cal physics). In the so-called position representation, the quantum state 
is a particular function of the position variable (r), which, from a 
mathematical perspective, must meet special conditions of differenti­
ability and integrability. The function itself does not have a physical 
interpretation, but its squared modulus jV'j2 does — it represents the 
1

2 Project 1: Rectangular Finite Quantum Well
probability density of finding the particle at a given point in space, 
that is becomes a probability when multiplied by the volume element 
(the Born probabilistic interpretation). Here lies the main difference 
between classical and quantum physics - the probabilistic nature of 
the latter, with the concept of probability being inherent to the theory. 
When measuring a physical quantity, the outcome can only be predicted 
with a certain probability. The deterministic nature of phenomena, jus­
tified in classical physics, no longer holds, and this fact was challenging 
for many physicists to accept during the early stages of quantum the­
ory development. For instance, Albert Einstein proposed the hidden 
variables hypothesis, suggesting that there are unknown variables that 
determine the measurement results. Modern interpretations, such as the 
Copenhagen Interpretation, go even further, positing that a particle can 
simultaneously exist in multiple positions with different probabilities 
(which is entirely impossible in the classical world), and only the act of 
measurement localises it to a specific position (e.g. the role of the meas­
urement instrument is played by the screen in the ‘electron diffraction 
on a double slit’ experiment). The same concept applies to other physi­
cal quantities, meaning that quantum systems can simultaneously exist 
in various states of a particular quantity (with different probabilities), 
and during the measurement, the system selects one of these states. 
Currently, quantum mechanics is a coherent and complete theory, with 
the Copenhagen Interpretation being widely accepted, and no scientific 
evidence has emerged to challenge its validity.
The central and historically first equation for evaluating the state 
function is the Schrodinger equation
- ~2- r2 C V(r)! ( (r, t) d i ~ @^), 
(1.1.1)
2m 
@ t
where ~ D h=2, h is Planck’s constant, m mass of the particle, r2 D 
@X2 C @@2 C al^ is Laplace’s operator, and V(r) the particle potential 
energy.
The equation resembles a wave equation, which is why the function 
(r (r) is also called the wave function. As we can see, this is a function 
of both space and time variables. However, when the left-hand side of 
the equation (potential energy) does not explicitly depend on time, the 
function can be represented as a product of a space variable and time­
dependent parts, with the latter having a known form ((r)ei(!t) (using 
the Euler representation of complex numbers, see Appendix A.1). A 
similar situation has been described (with respective derivation) in Proj­
ect 6 for the case of a standing wave. If we substitute the factorised

1.1 Physics Background: Chosen Ideas of Quantum Mechanics 3
function into Eq. 1.1.1, we can easily eliminate the time-dependent part, 
which leads to the stationary Schrodinger equation
~2 
2r 2 C V (r)
2m
(r) D " (r),
(1.1.2)
where " D ~!.
This equation is a starting point of the project. From a mathemat­
ical point of view it is an eigenvalue problem, the solution to which 
is a set of pairs: eigenvalues and corresponding eigenfunctions obey­
ing the imposed boundary conditions, f("n , n (r))g. The solutions are 
indexed with the integer n called the quantum number. The operator 
appearing on the left-hand side represents the total energy of the par­
ticle (Hamiltonian), and the eigenvalue problem leads to eigenenergies 
and eigenfunctions of the particle. From this an interpretation follows - 
the quantum system (a particle in a potential well, for example, an 
electron in the Coulomb potential of a proton) can have only strictly 
established energies and can occupy corresponding states described by 
the eigenfunctions. The modulus squared of these functions describes 
the spatial distribution of probability of finding the particle. It should 
be added that in quantum mechanics all physical quantities are rep­
resented by operators having certain mathematical properties, and the 
associated eigenvalue problems lead to eigenvalues (possible results 
of the measurement) and corresponding states. The measurement 
leads to a collapse of a quantum state into an eigenstate of a given 
quantity.
Two facts should be pointed out. First, the time-dependent part of 
the wave function, although it has been separated out, is still present 
in the full solution, but it does not affect the probability distribution 
of and eigenstate since its modulus squared equals 1. However, the sit­
uation changes if we consider a state being a superposition of a few 
eigenstates. Then we must not forget about time-dependent parts, and 
their presence results in time evolution of the probability distribution. 
The second issue is the normalisation of the wave function, which is 
necessary since its modulus squared multiplied by the volume element 
is the probability, and the probability of finding a particle overall must 
be equal to 1. From mathematical point of view this means that the inte­
gral of the modulus squared over the whole considered space must be 
equal to 1. Such normalisation is always possible since the Schrodinger 
equation is linear, that is any function being its solution when multiplied 
by a number still remains the solution.

4 Project 1: Rectangular Finite Quantum Well
1.2 Problem: Eigenenergies and Eigenfunctions 
in Rectangular Finite Quantum Well
In this project we will use the stationary Schrodinger equation (1.1.2) 
to find eigenvalues and eigenstates of an electron in a rectangular finite 
quantum well. This is not purely an academic problem since such sys­
tems are used to model, for example, semiconductor heterostructures. 
We describe the system as quasi one-dimensional because the changes 
of important physical characteristics appear in one direction only. Here, 
however, we will treat the quantum well as the simplest possible 1D 
model of the hydrogen atom. Thus Eq. 1.1.2 takes the form
~2 d2
-——C C V(x) (x(x) D "x(x), 
2me dx2
(1.2.1)
where potential is equal (Figure 1.1)
- Vo 
if - a/2 < x < a/2,
0 if x < - a/2or x > a/2.
In Hartree atomic units, ~ D me D e D 1
V(x) D
d2
—c C k2 (x) x (x) D 0, 
dx2
(1.2.2)
where k2(x) D 2(" - V(x)).
The analytical solutions fall into three categories, two inside the 
well (Figure 1.1), which differ in symmetry (even and odd), and the 
third category are the corresponding solutions outside the well
x (x) D
A cos(kx)
A sin(kx)
B exp(x)
for - a/2 < x < a/2 
(even),
for - a/2 < x < a/2 (odd), 
for x < — a/2 or x > a/2.
(1.2.3)
As one can see, the solutions are parametrised by two param­
eters: k - the wave number (inside the well) and k - the rate of 
exponential decrease (outside). It will be shown in the next section
Figure 1.1 A potential well 
and its solution: the even 
(lower) and the odd (upper)

1.3 Numerical Methods: Finding Roots of Characteristic Functions 5
that the numerical method will consist of finding the values of these 
parameters for consecutive eigenstates (thus they will become indexed).
It is worth noting that the eigenfunction (thus also its modulus 
squared) has finite values outside the well, that is in the region where 
the kinetic energy of electron is negative. In classical physics a par­
ticle must not have negative kinetic energy and that is why we call 
such a region ‘classically forbidden’ and the phenomenon ‘quantum 
tunnelling’.
1.3 Numerical Methods: Finding Roots 
of Characteristic Functions
The condition for the eigenvalue is that the two solutions (inside and 
outside the region of the well) must join smoothly (Figure 1.2), that is 
they must have equal values and equal values of their first derivatives at 
a=2 (because of the symmetry of the system it is sufficient to consider 
only one border). Thus, we have, for even solutions
±A cos(ka=2) = ±B exp(-Ka=2),
^Aksin(ka=1) = ^Bk exp(-Ka=2),
(1.3.1)
and for odd solutions
±A sin(ka=2) = ±B exp(-Ka=2),
±Ak cos(ka=2) = ^Bk exp(-Ka=2),
(1.3.2)
where k d p2(e C Vo) and k d V-2".
Dividing the first equation by the second one in the above systems, 
we obtain two conditions, for even (symmetric) and odd (antisymmet­
ric) solutions:
Feven(") d sin(ka=2) - k=k ■ cos(ka=2) d 0 (even), 
Fodd(") D sin(ka=2) C k=k cos(ka=2) D 0 (odd).
(1.3.3)
The eigenvalues " are found by solving these equations.
Figure 1.2 The solutions 
inside and outside the well 
(f (x) and g(x), respectively) 
must have same values and 
equal derivatives at the well 
border

6 Project 1: Rectangular Finite Quantum Well
1.4 Exercises
Obligatory
1. Using the QWELL code, tabulate functions Feven(") and Fodd(") 
These functions correspond to even and odd solutions, respectively, 
whose zeros are energies of quantum levels. Visualise the functions 
Feven (") and Fodd(") in one figure. Repeat the calculation and visual­
isation of Feven (") and Fodd(") for three significantly different values 
of the well parameters, a and V0 (e.g. wide and shallow well, deep 
and narrow, intermediate).
2. (Square finite quantum well as a model of the hydrogen atom). Try 
to fit the first two energy levels to the ones of the hydrogen atom 
through variation of the parameters a and V0, by a trial and error 
method. (Hint: In the beginning set the values a D 3Bohr and V0 D 
1Hartree.) What is the value of the third energy level? One might 
try also to fit the first and the third levels. What would be the value 
of the second level then? Would it be very different from the true 
value? (Note that in atomic units the energy levels should be "n D 
-1=(2n2); since the well is a two-parameter system, it should be 
possible, in principle, to fit any two levels.)
Challenge
1. Try to construct an algorithm and write a code which automatically 
finds the parameters of a quantum well with energy levels close to 
those of the hydrogen atom with arbitrarily low uncertainty.
2. For the found eigenenergies plot the corresponding eigenfunctions 
and their moduli squared, with the picture of the well in back­
ground (do not normalise the functions). Note the effect of quantum 
tunnelling.

Project 2
Diffraction of Light on a Slit
By working on this project, students will learn numerical differentia­
tion and quadrature procedures. In particular, this project discusses the 
important issue of convergence with respect to the grid parameter. The 
numerical quadrature procedure is used to construct the DIFFRAC­
TION code, which simulates diffraction of a scalar wave by a single 
infinite slit and a system of parallel infinite slits. The code then serves 
for studying the physical properties of the system.
2.1 Physics Background: Elements of Wave 
Physics
One can look at a wave as time- and space-dependent variation ofa cer­
tain physical quantity (pressure, stress in material, displacement of an 
atom from its equilibrium position, etc.). It is described by a function 
'(t, r), on which, from a mathematical point of view, special condi­
tions for differentiability are imposed. Some waves require a medium 
(mechanical), while others do not (electromagnetic, gravitational). The 
amplitudes in some waves are scalars (like in an acoustic wave), while 
in others they are vectors (like in an electromagnetic wave). The dif­
ferential equation for the so-called linear regime (when the response 
is a linear function of perturbation, like change in volume vs. pressure 
in air, strain vs. stress in material, or the force acting on an atom in 
crystal vs. its displacement from equilibrium) is shown in Project 6. 
Here, we will focus on a certain aspect of wave physics only - the 
superposition principle which is a consequence of a linear character 
of the wave equations. Namely, if two waves '1 and '2 are solutions
Figure 2.1 We know the 
principle of superposition 
from the water waves 
propagation
7

8 Project 2: Diffraction of Light on a Slit
Figure 2.2 The intensity 
versus the phase difference 
of two superimposed 
harmonic oscillations
to wave equation, then also their superposition A' D '1 C B'2 is 
(A, B - any variables). Using this principle it is possible to analyse the 
phenomena connected with the superimposing waves (Figure 2.1), like 
interference.
We begin with considering an abstract situation when two scalar, 
harmonic (sinusoidal) oscillations of the same frequency ! and ampli­
tude A, but differing in phase by , are superimposed in some point in 
space. We will use the Euler representation of a complex number (see 
Appendix A.1) in which, for example, the real part describes physical 
reality. The result of superposition is
'(t) D Ae(i!t) C Aei(!tC). 
(2.1.1)
Observations of wave phenomena (e.g. what we see or what we 
hear) are connected with the wave energy, which is proportional to the 
amplitude squared. Let us call it intensity (of light or sound) I . Using 
Equation (2.1.1), after simple algebra we find (Figure 2.2)
I D j'(t)j2 D'(t)'(t) D 2A2[1 C cos()], 
(2.1.2)
where the symbol ‘*’ denotes the complex conjugate.
When the effect of the superposition is stable, we call it interfer­
ence. However, an important condition has to be fulfilled for it to be 
stable, namely the phase difference must not vary with time. This con­
dition, combined with the requirement of same frequency form more 
general condition which we call coherence. In real systems, achieving 
coherence may be a big problem; for example, in the famous Young’s 
experiment with light diffraction on a double slit, the complexity of the 
experimental set-up (filter, single slit, double slit) was forced just by 
the coherence requirement. At present, achieving coherence is one of 
the main challenges and scientific problems in applications of quantum 
systems (quantum cryptography, quantum computer).

2.1 Physics Background: Elements of Wave Physics
9
Figure 2.3 Constructive 
versus destructive 
interference in a single slit 
diffraction, a schematic view 
The obtained formula for intensity is fundamental and general, and 
it shows that the effect of interference of two oscillations depends on 
the phase difference . There are two types of characteristic extrema: 
maxima for D 0 n2 (n is an integer number) corresponding to 
constructive interference, and minima for D n2 correspond­
ing to destructive interference (zeroth intensity). Besides, there is a big 
range of intermediate intensities.
Passing to real systems, that is the situation where oscillations 
depend not only on time but also on spatial variable, we should ask the 
question what can be the reason for the phase difference at a certain 
point in space. Most often the reason is the difference in so-called opti­
cal paths, that is the distance from a reference point, of known phase, 
for each beam, expressed in wave lengths . For example, for two point 
sources of spherical waves the phase difference is connected with the 
difference in distances from the sources 0 = k(r2 - r 1), where k is the 
wave number k D 2=. This is exactly what happens in the Young’s 
experiment (Figure 2.3), which in the history of science became the first 
irrefutable confirmation of the wave nature of light (although at this 
time nobody knew what kind of wave is this). A certain funny paradox 
is that the proof of the wave nature of light was always observed by peo­
ple, in the form of coloured patterns appearing on spots of oil spilled 
on the surface of water. The phenomenon is a result of wave interfer­
ence by division of amplitude (unlike in the Young’s experiment, which 
is based on the division of wavefront), where the phase difference is 
caused by the difference in optical paths of the part reflected from the 
upper oil surface and the other part reflected from the oil-water inter­
face. The coherence is most often assured here since the thickness of 
the oil film is usually smaller than the so-called coherence length of 
the light beam, that is the length within which the phase differences 
between chosen points do not depend on time. Presumably, the colours 
on the oil spots were a great puzzle for people until their origin has 
been explained. It is worth mentioning that the interference by division 
of amplitude finds presently significant application in interferometers,

10 Project 2: Diffraction of Light on a Slit
that is instruments for precise measurement of length. The Michelson 
interferometer is an example; its role in the history of science cannot 
be overvalued, and it was used to disprove the theory of Ether and to 
detect gravitational waves.
2.2 Problem: Diffraction of a Wave on a Slit
We will apply the superposition principle discussed in the previous 
section to construct a virtual system of wave diffraction on a certain 
aperture. A particular case will be an infinite slit with parallel edges. 
Using this virtual system it will be possible to investigate into the dif­
fraction phenomena on such a slit at various configurations (width of 
the slit, the distance of the screen). Thus, we consider a plane wave of 
stabilised phase on a wavefront, falling on a certain aperture. Accord­
ing to Huygens’ principle, we can treat the region of the aperture as an 
infinite and continuous set of point sources of spherical waves. The dif­
fraction phenomenon is a result of the superposition of waves emitted 
by these sources. To be more exact, the diffraction itself is associated 
more with the wave deflection, that is, the fact that there is never a sharp 
shadow of the aperture on the screen. This is because the spherical 
waves emitted by point sources propagate into the whole space and not 
along straight lines. We will observe this for the case of a very narrow 
slit, whose width is much smaller than the wavelength. When addition­
ally the interference takes place, characteristic patterns of brighter and 
darker regions appear. Generally, the term diffraction is used to denote 
both the deflection and interference at the same time. Coming back to 
calculus, we have to sum up the waves emitted by all the point sources, 
which for the case of their continuous distribution denotes quadrature. 
We get the diffraction integral
D d y 
A)(s) exp (_ikr ^ ^))^^, 
(2.2.1)
where A0(s) is the amplitude at the elementary source (or more 
exactly the amplitude density), (s) is the initial phase (at the ele­
mentary source), k D 2= is the wave number, r is the distance 
from the elementary source to the observation point, and (Ao(s)=r) 
exp (-ikr C 0(s)) is the complex amplitude.
It should be noted that the 1=r factor holds for a spherical wave, 
for a cylindrical one (the case considered here) it should be replaced 
by 1 =pr because we deal here with cylindrical waves. It should also be 
explained why there is no time in Eq. 2.2.1, if it is to represent a super­
position of elementary waves. This is because in Euler representation 

2.3 Numerical Methods: Schemes Based on Local Approximations 11
of an elementary wave, exp[i(!t - kr)], the time-dependent factor is 
identical for all waves and can be factored out of the integral. When the 
intensity is calculated (as a modulus squared of the diffraction integral) 
its contribution is equal to 1. The intensity (which forms the diffraction 
pattern) is given by
I D jDj2 D Re(D)2 C Im(D)2. 
(2.2.2)
In the case ofan infinite slit of width a, the problem becomes two­
dimensional, in the sense that no quantity varies in the direction parallel 
to the slit, so only two remaining directions are of interest. Assuming 
that the initial amplitude and phase (A0, ) are constant along the slit, 
the diffraction integral on the screen placed at the distance d takes the 
form
a=2
D d y A(r)exp(-ikr)dx, 
(2.2.3)
- a/2
where r = ^/(y - x)2 C d2, A(r) = A0/pr (for a cylindrical wave 
emitted by an elementary line source), A0 is the amplitude at the source, 
x is the coordinate of the elementary source, andy is the coordinate of 
the observation point on the screen.
2.3 Numerical Methods: Schemes Based on Local 
Approximations of a Function
2.3.1 Derivatives: 2, 3, and 5-Point Schemes
Suppose we want to numerically calculate derivatives of various orders 
of a function f (x) at a certain point x. We start from power series 
expansions
8 f (x ± h) = f (x) ± f0(x)h C 2f"(x)h2 ± 1f"'(x)h3 C O(h4), 
■ f (x ± 2h) = f (x) ± f'(x)2h C 1f"(x)(2h)2 ± 1f'"(x)(2h)3 C O(h4), 
:::,
(2.3.1) 
where h is a small grid parameter and O(h4) stands for the remainder 
of the series in which the leading (the biggest) term contains h4 . The 
above power series expansions, when truncated at certain order, form a 
system of linear equations whose unknowns are subsequent derivatives.
For example, if only the terms up to second order are preserved we 
get

12 Project 2: Diffraction of Light on a Slit
Figure 2.4 3-Point scheme
f (x C h) D f (x) C f '(xx)h C f00(x)h2 C O(h3),
f (x - h) d f (x) - f'{x)h C 2f"(x)h2 C O(h3), 
(2.3.2)
where the symbol O(h3) means that the leading term in the remainder 
of the series is of the order of h3.
By subtracting or adding these equations (2.3.2), we can easily 
derive the 3-point schemes for the first and the second derivatives, 
respectively,
,(x) D f(x C h)f(x - h> C O(h2),
(2.3.3)
f,,(x> D f (x C h> Cf (x - h> - 2f(x> C O(h2).
h2
(2.3.4)
Note that the uncertainty of the second derivative is of the order 
of h2; this is because the leading terms of the third order in the two 
expansions cancel out. The above formulas are called 3-point schemes 
because a local approximation of the function based on three points 
(parabolic) is used. The formulas give exact values of derivatives for 
quadratic functions. It is also interesting to note that the first derivative 
formula uses only two points, in spite of the fact that this is a 3-point 
scheme (Figure 2.4).
Using the above procedure it is easy to derive the schemes based on 
a larger number of points (higher order polynomial approximations) 
as well as derivatives of a higher order. It is also easy to incorpo­
rate a non-uniform grid (h is different at each step), although then 
the formulas become more complicated. It should also be noted that 
with high precision of representation of a number it is favourable to 
increase the accuracy of the derivatives simply by applying a smaller 
grid parameter h rather than using higher-order schemes, since higher- 
order schemes involve more evaluations of a function, which increases 
the computation time.

13
2.3 Numerical Methods: Schemes Based on Local Approximations
2.3.2 Quadrature: Rectangle, Trapezoid, and Simpson’s 
Methods
The schemes presented here are based on the assumption that the func­
tion f (x) which we want to integrate is tabulated, meaning its values 
are known at some points of the domain uniformly distributed along 
the integration interval. The grid parameter h is the distance between 
subsequent values of the argument in the grid h = xiC1 - xi. The idea 
behind the construction of the quadrature schemes is simple. Once we 
can numerically calculate the derivatives of any order at the points of 
the grid, the function can be approximated by a polynomial of any order 
along certain local intervals. Thus, it can also be analytically integrated 
along the same local interval (Figure 2.5). The quadrature along the 
whole interval of interest is obtained by summing up the values of local 
integrals. For example by preserving only the constant in the expansion 
we get the ‘rectangle method’ (see Figure 2.5(a)), and preserving only 
the constant and the linear term leads to the ‘trapezoid method’ (see 
Figure 2.5(b)).
A very popular Simpson’s algorithm is based on the 3-point 
schemes for the first and the second derivatives given in Section 2.3.1, 
and local quadratic approximation of the function (Figure 2.6)
h
D D If (t)dt D h(f (xi c h) c 4f(xi) cf (xi - h)) c O(h5), (2.3.5) 
- h
where t = x - xi is a local integration variable.
Note that the local uncertainty of the quadrature is very low (of 
the order of h5). It should be noted that the global uncertainty (after 
summation of local contributions) can increase because the local uncer­
tainties may also accumulate (in worst case); however it will never be 
higher than N O(h5) D 1=hO(h5) D O(h4) (for the quadrature interval
Figure 2.5 Simple 
quadrature methods: (a) 
Rectangle, (b) Trapezoid

14 Project 2: Diffraction of Light on a Slit
Figure 2.6 Simpson’s 
method
equal to 1 the lattice parameter h D 1=N). The strategy presented here 
can be used for the construction of higher-order schemes. As opposed 
to derivatives, in this case it can indeed lead to better accuracy at sim­
ilar effectiveness, because at the same number of the f (x) function 
evaluation its local approximation is more precise. On the other hand, 
decreasing the value of h (to get better local approximation) requires 
a larger number of evaluations. One should remember, however, that 
the application of higher-order polynomials always involves the risk of 
unwanted local behaviour of the approximating function.
2.4 Exercises
Numerical Procedures
Obligatory 
1. Derive the formulas in 2.3.3 and 2.3.4 and explain why their 
uncertainties are O(h1 
2 3 4
).
2. (Testing the DERIV code) Substitute your own function in the seg­
ment FUNC and calculate its derivatives. Compare the results with 
analytical values.
3. Check the convergence of the first and the second derivatives with 
respect to the grid parameter h (draw derivatives as functions of 
- log 10(h)). Perform the tests for a single and double precision of 
real numbers. Discuss the results.
4. Derive the formula in Eq. 2.3.5 and explain why its uncertainty is 
O(h5 6
).
5. Test the QUADRAT code by integrating a function whose analytical 
quadrature is known.
6. Check the convergence of the Simpson’s algorithm with respect 
to the grid parameter h. How does it compare with the derivative

2.4 Exercises 15
convergence? Pay attention on the computation time. Discuss your 
observations.
7. Estimate the number from the length of an arc or from the surface 
area of a semicircle using the QUADRAT code. What precision can 
be achieved? Compare it with the previous exercises concerning the 
evaluation of .
Supplementary
1. Derive the 5-point finite difference formulas for the first and the 
second derivatives of a function. Construct the functions fp5 and 
fpp5 (the first and the second derivatives with the use of the 5- 
point scheme) in the DERIV code and repeat Ex. 2. Compare the 
convergence of 3-point and the 5-point schemes.
2. Substitute second- and fifth-order polynomials in the segment 
FUNC and test the convergence with respect to h. Discuss the 
results.
Diffraction
Obligatory
1. Test the DIFFRACTION code by comparing the first minimum posi­
tion in the far field with the analytical value. (Hint: The far-field 
condition can be recognised by the fact that intensities at all the 
minima are zero; the position of the first minimum should obey the 
condition =a y=d.) One should assume the wavelength D 1
because the results scale with the wavelength (are qualitatively the 
same e.g. for optical waves and for microwaves, if only the pro­
portions between system dimensions and the wavelength are the 
same).
2. Evaluate the diffraction patterns for different physical conditions: 
near (d a) and far (d 
a) fields, very narrow (a 
), nar­
row (a ), and wide (a ) slits. Try to interpret the results.
Discuss the effect of computational parameters on the results, and 
how to check whether the obtained result is physical or affected by 
numerical effects.
3. Modify the code so that it could calculate the diffraction pattern 
produced by a system of two slits. In the far field one should 
expect the pattern presented in Figure 2.7. Does the position of 
the first-order maximum agree with the theoretical prediction? The 
single-slit pattern, after some renormalisation, forms an envelope for

16 Project 2: Diffraction of Light on a Slit
Figure 2.7 An example of 
the diffraction patterns in the 
far field for a single and a 
double slit. In both cases the 
parameters of a single slit are 
the same. The patterns have 
been normalised to 1.0 at 
maximum (the true value of 
the double slit intensity is 
four times higher than the 
single slit one)
Figure 2.8 An example of 
pattern for diffraction grating
the double-slit pattern. Explain why and what is the renormalisation 
factor.
Supplementary
1. Modify the program to calculate the diffraction pattern produced by 
a system of many parallel slits (Figure 2.8); use a loop for that pur­
pose. Use the modified program to simulate a diffraction grating and 
draw graphs of diffraction patterns in the far field for different grat­
ing parameters. How does the position of the first maximum depend 
on the grating parameters?
Challenge
1. Consider various initial phase distributions 8(s) across a single slit 
(or at slits in diffraction grating). How do they affect the diffrac­
tion pattern? (In this task there is an analogy to GSM transmitting 
antenna, being usually a system of radiators, and their radiation 
patterns are shaped by exiting the radiators with different initial 
phases.)

2.4 Exercises
17
Figure 2.9 An example of 
diffraction pattern due to 
circular aperture (Airy’s disc). 
Colour scale has been 
modified to enhance the 
outer rings
2. Consider an irregular diffraction grating in the form of periodically 
repeated slits of two different widths. How many parameters decide 
the properties of such system. Check the influence of the parameters 
on the diffraction pattern in the far field.
3. Consider diffraction due to a circular aperture or an aperture of an 
arbitrary shape. Try to construct respective program. (Hint: Instead 
of integration a summation over a discrete points of elementary 
sources should be applied.) See Figure 2.9 for reference.

Project 3
Pendulum as a Standard
of the Unit of Time
This project is devoted to the Initial Value Problem (IVP) for ordi­
nary differential equations. Here, students will learn various multipoint 
recursion schemes, apply them to examples of equations whose ana­
lytical solutions are known, check the convergence with respect to the 
grid parameter, and compare the effectiveness of the schemes. Finally, 
a chosen scheme is applied to study the properties of the compound 
pendulum, in particular the dependence of the period of oscillation 
on energy. The results may serve to discuss the applicability of the 
pendulum as a standard of the unit of time.
3.1 Physics Background: Newton’s Laws of 
Motion, Equation of Motion
This project is a good opportunity to recall and discuss briefly Newton’s 
laws of motion, published in 1687 in the famous work Philosophiae 
Naturalis Principia Mathematica. This work, in spite of concepts, lan­
guage, and mathematical apparatus being far from modern standards, 
became a foundation of physics and the whole science. The first law 
of motion, although at first sight looks very simple and seems to be 
a consequence of the second law of motion, is in fact the first funda­
mental physics law discovered by people. It says that an isolated body 
(body not subjected to any external interactions) does not change the 
state of its motion, that is will either stay at rest or keep moving at 
constant velocity. This law should be treated as a postulate, since it 
cannot be experimentally verified on the Earth (nor in fact anywhere 
else). According to our everyday experience, bodies in motion will 
sometimes stop, and such a view was obligatory over ages (Aristotle) 
before Newton presented his first law of motion. An important aspect 
of Newton’s first law is that it can be used to introduce the concept 
of inertial reference frame, as the one in which we could hypotheti­
cally observe the described phenomenon. It is also worth mentioning 
that in the formulation of the law we do not have to use the concept of 
force (not defined yet). Unfortunately, in many textbooks force is used 
18

3.2 Problem: Simple Pendulum as a Standard of the Unit of Time 19
in its formulation (‘no force is acting’ or ‘all the forces cancel out’), 
maybe following Newton himself, who in his work also used the con­
cept of force to express the first law. However, the richness of concepts 
in modern science (e.g. an isolated system, postulate) allows for the for­
mulation which is formally correct and internally uniform. In Newton’s 
second law the concept of force appears as the reason for the change 
in the state of motion. Force can be defined via acceleration, which is 
a well-established kinematic quantity. At this point, the fact should be 
taken into account that the change in the state of motion is determined 
by certain internal characteristics of the body - inertia, measured by a 
quantity called mass. Until recently, in the SI system of units, the unit 
of mass, 1 kilogram, was defined by a physical standard. At present, the 
SI system uses universal physical constants to define units. Next, ifwe 
know already the unit of mass, then the measure of force is an accel­
eration of a body of unit mass under the action of this force. Now, we 
can formulate Newton’s second law: ifon a body acts a force FN, being a 
vector sum of all the forces present, then its instantaneous acceleration 
aN is directly proportional to the force and inversely proportional to its 
mass. Finally, Newton’s third law says that in an inertial reference frame 
the forces appear as a consequence of interactions between bodies, and 
the interactions are always mutual, that is ifa body A acts on a body B 
with a certain force, then body B also acts on body A with the force of 
the same value but opposite direction.
The equation of motion is just Newton’s second law expressed in 
the form of differential equation
d2 r 
F (t, r, v)
dt2 D 
m
(3.1.1)
where rN is the position vector and vN velocity vector.
This is the second-order non-uniform differential equation, being 
most often the basis of the so-called IVP. In such problems we want to 
find the evolution of trajectory in phase space (position and momentum) 
of systems at given initial conditions. This will also be a basis of the 
present and the following projects.
3.2 Problem: Simple Pendulum as a Standard of 
the Unit of Time
We will apply Newton’s second law for a simple pendulum - a point 
mas suspended from a massless, stiff rod of length l. The uniform (inde­
pendent of position) vertical force, whose origin is gravitation (will be

20 Project 3: Pendulum as a Standard of the Unit of Time
Figure 3.1 The 
mathematical model of 
pendulum
discussed in the next project), acts on the point mass. The force and 
its convenient decomposition is shown in Figure 3.1. The gravitational 
force has a component along the rod Fr, which cancels out with the 
force due tension in the rod N . Another component is tangent to the 
circle drawn by the moving point mass and is a cause of motion. The 
equation of motion Eq. 3.1.1 takes the form
d2s
dt2 d -g sin(9), 
(3.2.1)
where s is a coordinate of the mass position along the circle, measured 
from the lowest point.
When we divide both sides of the equation by the length l, and note 
that the ratio of the arc length and the radius of the circle is just an angle 
in arc measure, we get
d2 9 
dt2
- g sin(9),
(3.2.2)
where 9 D s=l is the swing angle and g the free fall acceleration.
For small swing angles sin(9 ) 
9 , the oscillation is harmonic
d29 g
dtfi D~ 1
(3.2.3)
9 (t) d 90 sin(^t),
(3.2.4)
where 90 is the swing angle amplitude, and • d 2n=T0 d g=1Jl.
The period of harmonic oscillations T0 does not depend on the 
amplitude. This phenomenon (isochronism) allows us to use a pendu­
lum as the standard of the unit of time in pendulum clocks (the first 
one constructed in 1656 by Christiaan Huygens). However, for bigger 
angular amplitudes the period begins to change and to find it, it is nec­
essary to numerically solve the differential equation (3.2.2) for given 
initial values of angle and their first derivatives (IVP).

3.3 Numerical Methods: Recursive Methods 21
A convenient way of setting the initial state of the pendulum is to 
use its total energy E D mgl(1 - cos(0)) C ml2!2 =2 expressed in units 
of the maximum potential energy (with respect to the lowest position), 
that is D E=2mgl. Then we expect the period to be constant for 1 
(isochronism), tend to infinity for approaching 1, and to behave like 
1 =p? for e » 1 where the rotational energy prevails.
3.3 Numerical Methods: Recursive Methods 
Based on Local Extrapolation of One-Step Integral 
Integrand
A system of first order, linear, non-uniform differential equation reads
dyi 
dx D f(y1,:::,yN,x),
(3.3.1)
(3.3.2)
where x is the independent variable, and fy1, :::,yNg are the dependent 
variables (functions of x).
Linear differential equations of higher order can be decomposed 
into a system of equations (3.3.1) by defining auxiliary functions as 
derivatives of the function y(x).
Developing the numerical methods for a single equation
dy D f(y, x) 
dx
is sufficient, since the methods can be easily adopted to the system 
(3.3.1).
The algorithms presented here are based on discretisation of the 
independent variables. A regular mesh (grid) of points fx0, x1, :::,xNg, 
in the interval (x0 , xN ), is introduced. The distance between neighbour­
ing points h D (xiC1 - xi), also h D (xN — x0)=N, is called the grid 
parameter h. We seek a recursion formula of the form
ynC1 D F(yn,yn_1,yn_2,:::), 
(3.3.3)
which would allow the function y(x) to evolve, beginning from the 
initial point y0 (x0).
A starting formula is an exact integral of the equation (3.3.2) over 
the interval (xn, xnC1)
xnC1
ynC1 D yn C f(x, y)dx;
xn
(3.3.4)

22 Project 3: Pendulum as a Standard of the Unit of Time
Figure 3.2 Euler’s method
let us call the integral appearing in Eq. (3.3.4) (exact) formula a one- 
step integral.
In general, the explicit form off(x,y) is not known since the y(x) is 
not known (it is to be found). However, values of y(x) at previous points 
of meshyn,yn_1,yn_2,... are known and they can be used to extrapo­
late f(x) over the interval (xn, xnC1), which will allow us to perform the 
one-step integration. Depending on the number of points used in the 
extrapolation we get the so-called explicit schemes of various orders. 
For example, the most simple Euler’s formula (Figure 3.2) (based on 
the extrapolation by a step function) reads
ynC1 DynCfnhCO(h2), 
(3.3.5)
where fn D f (xn, yn). The leading term of the local deviation from the 
exact solution is on the order of h2. It should be noted that after N steps 
the uncertainty (global) will be one order lower because h ' 1=N , thus 
h2N Dh2=hDh.
The three step Adams-Bashforth scheme, based on the parabolic 
extrapolation, has the form
yn +1 d yn C 1h2(5fn-2 - 16fn-i C 23f) C O(h4). 
(3.3.6)
3.3.1 Runge-Kutta Methods
The Runge-Kutta methods are based on more advanced mathematical 
concepts which will not be discussed here, although the integral (3.3.4) 
is still used as the starting point. They are regarded as the best integra­
tion schemes, whose great advantage is the fact that only one, already 
known, point xn, yn (e.g. the initial condition) is needed to perform the 
integration step, whereas the multipoint recursion schemes cannot be 
started from a single initial condition. As an example, the fourth-order

3.4 Exercises 23
Runge-Kutta method has the form
k1 D hf (xn, yn),
k2 D hf (xn C 1=2h, yn C 1=2k1),
k3 D hf (xn C 1=2h, yn C 1=2k2), 
(3.3.7)
k4 Dhf(xn Ch,yn C k3),
ynC1 D yn C 6(k 1 C 1 2 3 4k2 C 2k3 C k4) C O(h6).
1. Derive Eq. 3.3.6.
2. Use the IVP code to evaluate the function which is a solution to 
the differential equation dy=dx D y, y(0) D 1, with the use of 
three methods: Euler, third-order Adams-Bashforth, and fourth­
order Runge-Kutta. Visualise the results, together with the analytic 
solution y D ex.
3. Modify the code so that it gives at the output the y(1) value as a 
function of the grid parameter - log 10( h) (the logarithmic scale). 
Check the convergence of the three schemes with respect to the grid 
parameter. Classify the schemes with respect to their quality and 
efficiency.
4. Look at the construction of the IVP2D code and note how the 1D 
algorithms are adopted to solve the second-order differential equa­
tion. Use the code to evaluate the function being a solution to the 
harmonic oscillator equation d2y=dx2 D - k ■ y. Draw the function 
y(x) and interpret the result (Figure 3.3(a)). Add a line to the code 
that calculates the total energy of the oscillator and output the result. 
Find the range of the grid parameter at which the energy is con­
served. Repeat the calculations for Euler and Runge-Kutta methods.
The unknown function y(x) appearing in the integrand (3.3.4) can 
be also approximated by a polynomial of any order. In this case the 
unknown value ynC1 appears on the right-hand side of the formula as 
well and has to be evaluated by solving the equation. This strategy leads 
to a group of the so-called implicit schemes. They are most often used 
in the predictor-corrector methods in which a predicted value of ynC1 
found from one of explicit schemes is then corrected by the implicit 
scheme of higher order (by substituting the predicted value on the right­
hand side of the equation).
3.4 Exercises
Numerical Procedures
Obligatory

24 Project 3: Pendulum as a Standard of the Unit of Time
Figure 3.3 Different cases of 
oscillators motion: (a) 
Harmonic oscillator, (b) 
Damped harmonic oscillator, 
and (c) Driven harmonic 
oscillator
Supplementary
1. Modify the IVP2D code so that it could solve the equations:
(a) d2y=dx2 — ft ■ dy=dxCk■ y d 0 (damped oscillator Figure 3.3(b)). 
For the chosen parameters elastic constant, mass, damping con­
stant, and a proper time-step (grid parameter), perform the 
calculations.
(b) d2y=dx2 - ft ■ dy=dx C k ■ y d A sin(! ■ x) (driven oscillator 
Figure 3.3(c)) for different driving frequencies. Draw resulting 
functions y(x) and identify the time ranges of unstable and sta­
ble oscillations. Observe and discuss the behaviour of oscillation 
energy (kinetic plus potential) as a function of time. Try to find 
a few points on the resonance curve, close to maximum (near 
the resonant frequency), and much lower and higher frequen­
cies. Note that for higher frequencies a smaller time-step may 
be needed (how to check it?).
Challenge
1. Consider the case of coupled harmonic oscillators described 
in Project 9. Read the project and follow the exercises given 
there.

3.4 Exercises 25
Compound Pendulum
1. Test the PENDULUM code by comparing the period of small 
oscillations with the analytic solution.
2. Perform a few calculations for different total energies of the pendu­
lum (the total energy is expressed in units of the maximum potential 
energy) and draw the time dependence of the angle and angular 
speed. Propose an algorithm for automatic calculation of the period 
and implement it. (Hint: For that purpose it is easier to use the angu­
lar speed rather than the angle - explain why?) Evaluate the relative 
deviation of the period at a given energy T() from the analytic value 
(for small oscillation) T0 = 2~P(l=g), (T(e) - T0)=T0, for three 
energy ranges: e = (0.001-0.01), e « 1.0, and e » 1.0. Draw and 
discuss the results.
3. Focus on a case where e = 1.0 and perform the calculations for dif­
ferent time steps (differing by a few orders of magnitude). Draw the 
time dependence of the angle and explain the observed differences.

Project 4
Planetary System
Molecular dynamics (MD) is a very popular type of simulation in phys­
ics. It is essentially just a procedure of solving the equations of motion 
for a system of many particles, either classical (Newtonian) or relativ­
istic, from atomic to cosmic scale. A rigorous analytical solution exists 
only for two-particle systems (and three-particle in special cases), thus 
a computer simulation seems to provide the only possibility of studying 
such systems theoretically. Molecular dynamics simulations are very 
popular in studying dynamics and thermodynamics of polyatomic sys­
tems but they are also used on a cosmic scale (motion of planets, stars, 
galaxies). All we need to know to construct a MD code is the law of 
interaction between the particles and Newton’s (or relativistic) equa­
tions of motion. In this project, a simple two-dimensional planetary 
system will be considered with two planets and a fixed star as the source 
of the central force. Newton’s law of universal gravitation is used as the 
interaction law between planets and between planets and the star. The 
Verlet algorithm, in its simplest form (most often used in simple MD 
simulations), for solving the initial value problem will be applied.
4.1 Physics Background: Law of Universal
Gravitation
In this project we will solve equations of motion - an initial value prob­
lem for a system of two planets moving in the field of a fixed star. As 
has been mentioned in introduction of this project, besides the laws of 
motion which have been discussed in previous project, the law of inter­
action between objects is needed. Here, it is the gravitational interaction 
presented and described by Isaac Newton in Philosophiae naturalis 
principia mathematica, quoted in the previous chapter. It says that two 
point masses m1, m2 at distance r attract each other with the force FN 
whose value is directly proportional to the product of masses, inversely 
proportional to the distance squared, and the force is attractive
m1 m2
F D-G rr, 
(4.1.1)
26

4.1 Physics Background: Law of Universal Gravitation 27
where rO D r=r is a unit vector along r. In this equation gravitational 
constant G is necessary since the units of mass and distance have 
been established in advance. Moreover, the multiplication of the ratio 
(m1 m2)=r2 by G makes the force realistic (extremely small for 1 kilo­
gram and 1 metre). Even if the force seems to be so small, it plays a 
key role on a cosmic scale and is responsible for the structure of the 
universe (stars, planets, galaxies, black holes, etc.). Also, owing to this 
force, we are safely kept on the surface of the Earth, but it creates chal­
lenges when we want to leave the Earth and travel to outer space. When 
considering gravitational interactions, one should always keep in mind 
that Newton’s third law applies: it states the mutuality of interactions. 
A force of value given in Eq. 4.1.1 acts on both point masses along the 
line joining them and is attractive, that is, it always acts in the direction 
towards the other mass.
There are a few issues that deserve a brief discussion here. The first 
issue is the important superposition principle which says that the inter­
action between two point masses does not depend on the presence of 
other masses in the region. In other words, the gravitational force act­
ing on a certain mass is a vector sum of all the gravitational forces due 
to other objects. This is not an obvious fact since, for example, in the 
system of many atoms they attract or repel each other in a complicated 
way, and often many-body force fields are necessary. For example, two 
hydrogen atoms interact in a different way when they are in the H2 
molecule and when the oxygen atom is nearby (in the water molecule 
H2O ).
The second issue is the principle of equivalence, being something 
very mysterious over two ages. It turns out that the mass responsible for 
the gravitational interaction is exactly the same mass which is a measure 
of inertia of a body. Thus, for example, no experiment can differen­
tiate between gravitational and inertial forces within a closed room. 
This concept forms a fundamental basis for Albert Einstein’s construc­
tion of the general theory of relativity. Developed in the early twentieth 
century, this represents the modern theory of gravitation.
Finally, it should be recalled that the gravitational force is conserva­
tive, which means, for example, that the work done by an external force 
opposite to the gravitational force along a closed path is zero. A related 
property of such force field is that it can be described by the potential 
energy U(r), a scalar function of position. The relationship between the 
potential energy and the force is F d -r U(r), where r is the gradient 
operator.

28 Project 4: Planetary System
Figure 4.1 All massive 
objects attract each other 
according to Newton’s law of 
universal gravitation
For two point masses the potential energy is given by the expression
U D - Gm1 m2
r
(4.1.2)
which will be used in Section 4.3, at the reduction of the single particle 
motion in the field of a star to one dimension.
4.2 Problem: Motion of Planets in the Field of a
Fixed Star
The forces acting on planets due to the Star fixed in the origin of a 
reference system and due to the other planets moving in the same plane 
(two-dimensional system Figure 4.1) can be expressed as
m1M 
m1m2
F1 d - G—r1 C G—2— o12 and 
r1 r12
m2M 
m2m1
F2 d -G—r2 C G—2— r2i, 
r2 r21
(4.2.1)
where rij d rj - ri.
The Newton equations of motion for the two planets are
dp1 =dt D F1 , 
dr1 =dt D p1 =m1, 
dp2=dt D F2, 
dr2=dt D p2=m2.
(4.2.2)
This is a system of differential equations, linear and non-uniform. 
They can be solved with the methods described in the previous proj­
ect. However, here we will apply an algorithm which is specific for 
the equations of motion and often used in MD problems - the Verlet

4.3 Reduction of a Single Planet Motion in a Central Field to 1D 29
Figure 4.2 Construction of a 
local rectangular coordinate 
system for representing 
vectors in polar coordinates
Figure 4.3 In general the 
origin of the coordinate 
system can be placed at any 
point of the space (not 
associated with star’s 
position)
algorithm. Its construction starts from a second-order equation, and its 
basic version is described in this project.
4.3 Reduction of a Single Planet Motion in a 
Central Field to 1D
The exercises related to the present project begin with the analysis of 
a single planet motion in a central field of a star. Such a motion can 
be reduced to one dimension, which helps to understand its properties. 
The transformation is presented next.
We begin with writing the classical Hamiltonian of the system (its 
total energy)
H p2 mM 
D 2m G~
If p is represented in polar coordinates (see Figure 4.2), p D peO C 
preOr , where eO , eOr are unit vectors of the local (attached to the 
particle-planet) rectangular coordinate system (Figure 4.3), then the 
Hamiltonian takes the form
H = p2 
(p r r)2 
GmjM
2m 
2mr2 
r ’
where, in the second term, the factor r2 has been introduced in both the 
numerator and denominator. Since the quantity pr is just the angular 
momentum L which is conserved in the central field, we can rewrite the 
Hamiltonian as follows:
(4.3.1)
(4.3.2)
H D 2pm, C Veff (r),
(4.3.3)

30 Project 4: Planetary System
Figure 4.4 The scheme of a 
planet motion along an 
ellyptical orbit with respect 
to the star located in one of 
the foci of the ellipse, 
according to Kepler’s first law
Figure 4.5 Effective 
potential, after reduction of 
2D system to one dimension. 
It is the sum of two terms: 
the centrifugal potential
1=r2 and the gravitational 
potential 1= r. The graph 
identifies planet trajectories 
depending on its energy
where Veff (r) = 2^22 - GmrM is r-dependent effective potential energy 
of the particle in non-inertial reference frame attached to the position 
vector, being a sum of the centrifugal potential energy (present in 
the non-inertial reference frame) and the gravitational potential energy 
—GmrM (Figure 4.4). Once the Hamiltonian is known, the Hamilton 
canonical equations for 1D motion can be written, but here the effec­
tive potential (potential energy of a unit mass) Veff will be of interest. 
For a given angular momentum (conserved) the effective potential does 
not change, but the total energy (also conserved) of the moving par­
ticle can have different values. Figure 4.5 shows how the character 
of the trajectory depends on its total energy relative to the effective 
potential. One can easily distinguish circular, elliptic, parabolic, and 
hyperbolic trajectories, which is a subject of one of the exercises in this 
project.
It should be mentioned here that a very similar operation (reduction 
ofa system to 1D) is performed when the hydrogen atom is considered. 
In this case the quantum 3D Hamiltonian is reduced to 1D by introduc­
ing the centrifugal potential. The angular momentum is quantised, and 
its quantisation is represented by the so-called orbital quantum number 
l. The quantum number l then enters the effective potential and thus the 
solutions (quantum states) of the hydrogen atom.

4.5 Exercises 31
4.4 Numerical Method: Verlet Algorithm
The Verlet algorithm is a method developed for numerically solving 
Newton’s equations of motion for a system of particles (Molecular 
Dynamics), and is most often used in such simulations. Here, we will 
learn its simplest form and the idea of the algorithm will be presented 
as an example of 1D motion; however, as was the case in previously 
discussed algorithms, it can be easily generalised to many dimensional 
systems of many particles.
Newton’s equation of motion of a point mass m in 1D reads
d2x
dtfi D F=m,
(4.4.1)
where F is the force acting on a particle of mass m, and x is the 
coordinate of the particle on the X axis.
To study the trajectory in phase space, the velocity v D dx=dt is 
also needed.
We use three-point numerical formulas for function derivatives 
(2.3.3,2.3.4) to express acceleration and velocity, which, when rear­
ranged, lead to the following recursive schemes (Verlet algorithm):
Xnci D 2xn - Xn_i C T2F=m C O(t4),
Vn D (Xnci - Xn-1)=(2t) C O(t2),
(4.4.2)
where T is the time step.
It should be noted that as initial conditions usually position and 
velocity (or momentum) are given (Xo, vo), thus, there is certain diffi­
culty in starting the recursive scheme since it needs two initial points. 
The difficulty can be overcome, for example, by assuming that over the 
first time step the system performs in a uniformly accelerated motion
Xi D Xo C voT C (F=m)T2 =2 C O(T 3), 
(4.4.3)
which, however, is less accurate by one order of magnitude of T and thus 
should be applied with caution. Alternatively, more accurate schemes 
(e.g. Runge-Kutta) for the first time step can be used.
4.5 Exercises
Obligatory
i. (Testing the program) Test the PLANETS code on the example of 
a motion of a single planet along a circular orbit. For that purpose 
modify the code so that one of the planets is fixed far aside and its 

32 Project 4: Planetary System
mass is very low. Check the energy and the linear momentum con­
servation and find the maximum time-step for which those quantities 
are conserved. Compare the results with an analytical solution.
2. (Motion of a single planet) For a given angular momentum L, 
draw the effective potential and try to identify the circular, elliptic, 
parabolic, and hyperbolic trajectories for a single planet. Perform 
simulations for each of these cases and draw the trajectories. Hint: 
To set the appropriate initial conditions for different energies you 
should use the Eq. 4.3.2 with the radial momentum set to zero pr D 0
H 
L2 
(mMM
D 2mr2 “ G r'
(4.5.1)
Then, at given L the total energy becomes a function of r. However, 
one should remember that to keep the angular momentum constant 
when r is varied, it is necessary to change also the transversal com­
ponent of the momentum, according to p D L=r. In practice, set r 
as the x component (at y D 0), and p D py (at px D 0).
3. For an elongated elliptical orbit, observe the evolution of the total 
energy, and explain the observed behaviour.
4. Include the motion of the second planet. Choose one of the sug­
gested scenarios and perform a simulation.
(a) Planetary system - motion of planets of different masses along 
independent orbits, in the central field of a star
(b) Collision of planets - motion of planets along close orbits but 
in opposite directions, observation of collision and its conse­
quences
(c) Planet with a moon - treat one of the planets as a satellite of the 
other one, or double system of two identical planets on an orbit 
along a star
(d) Planet in a double-star system - treat one of the planets as the 
second heavy star, and observe the motion of the second planet 
between the two stars
(e) Double star - treat both planets as heavy stars (reduce the mass 
of the central star to a small value), and observe the system 
dynamics for different initial conditions
(f) Your own scenario.
To be sure that the observed effects are physical and are not the result 
of numerical artefacts, for each simulation it is obligatory to observe 
the behaviour of energy with time (it should always be conserved) 
and of the angular momentum (if it should be conserved in a given 

4.5 Exercises 33
system). If the conservation principles are not obeyed, appropriate 
changes in the computational parameters should be introduced.
Supplementary
1. Perturbed motion: change the mass and position of the fixed planet, 
and observe its effect on the trajectory of the second planet (a pertur­
bation). Check the energy and the momentum conservation. Should 
both these quantities be conserved? Try to characterise the effect of 
the perturbation on motion of the planet.
Challenge
1. By introducing proper numerical values of the parameters observe 
the effect of the presence of Venus (or Mars) on the trajectory 
of the Earth. (Hint: Keep the position of Venus (Mars) fixed.) Note 
that the period of motion of the Earth is about 365 days, what should 
be the time-step in this case?
2. For an elliptical orbit of a single planet, check the third Kepler law 
of planetary motion.
3. The choice of the simulation time-step is always a compromise 
between the simulation time and accuracy. From that point of view 
the optimal choice is the biggest step which guarantees good accu­
racy. However, there are some situations where a constant time 
step leads to the waste of computer resources. An example of such 
situation is the case of elongated elliptical orbit simulation (see 
obligatory Ex. 3). At the long part of the orbit the motion is almost 
along a straight line, where a long time-step is sufficient. A critical 
point is near the star (perihelion), where there are abrupt changes 
in the value and the direction of velocity, and a short time-step is 
necessary. Setting a constant time-step would require the use of the 
shorter one, which would lead to a significant and useless elonga­
tion of the computation time. Moreover, in the case of many particle 
systems, it is difficult to predict where the short time-step is needed.
In view of these remarks, propose an algorithm in which the time­
step changes dynamically, depending on the need. (Hint: Use the 
behaviour of the velocity.) Implement this algorithm and test it on 
the example of the elongated orbit (obligatory Ex. 3).

Project 5
Gravitation inside a Star
This project is devoted to the boundary value problem (BVP) for ordi­
nary differential equations. The case of gravitational field inside a star 
of a model radial mass density distribution is considered. The prob­
lem is formally equivalent to the problem of the electric field inside 
an atom (the Hartree contribution). The partial differential equation of 
Poisson’s type, due to high symmetry (spherical), reduces to a second- 
order ordinary differential equation. Unlike the initial value problem, 
here, two conditions necessary to uniquely identify the solution are 
given at two ends of the independent variable range (not at one end, 
like in the initial value problem). Usually, the values of the function 
are given at the boundaries (BVP). It is worth noting at this point that 
for this type of equation a whole family of functions differing by a lin­
ear function (established by two parameters of arbitrary values) form 
solutions. Application of boundary values eliminates all functions from 
this family except one. We will try to use a very accurate three-point 
recursive Numerov’s (Cowell’s) algorithm, presented later in this proj­
ect. To start the three-point recursive algorithm, values of the function 
at two points at one end are needed. For the purpose of this project 
we take the second point value from the known analytic solution, but 
this will turn out to be insufficient since analytic solution of differen­
tial equation is not the same as the solution to a discretised equation. 
Thus, we face a problem: the numerical solutions wander linearly up 
or down and appear to be very sensitive to the value chosen for the 
second point. Fortunately, in the considered problem the solution func­
tion converges to a known constant in infinity which allows us to apply 
a recursive scheme backwards (at a sufficient distance the two initial 
values of the function are the same), and obtain the solution that way. 
However, such situations are not always the case and recursive schemes 
in principle cannot be applied. An interesting alternative is to treat the 
three-point recursive formula as a tridiagonal system of linear equations 
for the unknown values of the function at grid points (with the known 
values at both ends), and they should be solved by the Gaussian 
Elimination with Backward Substitution algorithm described in 
Project 7.
34

5.1 Physics Background: Gauss’s Law, Poisson’s Equation 35
This project is also an introduction to one of the advanced projects, 
described in Project 11, in which the gravitation inside a star is found 
together with the density distribution.
5.1 Physics Background: Gauss’s Law, Poisson’s 
Equation
Gauss’s law is expressed by the first four Maxwell’s equations describ­
ing completely the classical electrodynamic phenomena. It can be 
formulated in integral or differential form. The forms are mathemat­
ically equivalent and the latter one, if additionally the relationship 
between the electric field and the potential is taken into account 
(E d -r0(r)), is called the Poisson’s equation. Mathematically, the 
integral form of Gauss law can be expressed as
E(s) ds D AQw, 
(5.1.1)
in other words, the total flux of electric field through a closed surface 
is equal to the resultant charge (i.e. considering also the signs) inside 
the surface. In the integrand there is a dot product of electric field and 
oriented surface element, which means that the projection of the elec­
tric field on the direction perpendicular to the surface is multiplied by 
the area of the surface element. This is an elementary contribution to 
the flux and the sum (integral) of these contributions will result in the 
total flux. According to convention, in this formulation the direction of 
the oriented surface element vector is outwards. Gauss’s law is a direct 
consequence of 1=r2 type of interaction, which appears, for example, 
in electrostatics (Coulomb’s law) or in universal gravitation law, and 
can be derived from this kind of interaction. Therefore, it can be used in 
both electrostatics and gravitation (as in this project), only the constants 
A will differ, for example in SI unit system in electrostatics A D 1="0, 
where "0 is the permittivity, and in gravitation A D 4 G, where G is 
the gravitational constant. In gravitation, the role of the electric field is 
taken over by the gravitational acceleration aG .
The differential form can be formally derived from the integral 
one, and after taking into account the Eq. 5.1.1 relationship between 
the electric (gravitational) potential and the electric field (gravitational 
potential) we get
r2^(r) D-Ap(r), 
(5.1.2)
where r2 is, known from previous projects, Laplace’s operator and (rN) 
is the density of charge (mass).

36 Project 5: Gravitation inside a Star
Figure 5.1 Spherical 
coordinates
5.2 Problem: Gravitational Field Due to a
Continuous Mass Density Distribution
Poisson’s equation is, in general, a partial differential equation which 
together with the boundary conditions forms the BVP, the solution to 
which is the electric potential function (r) for a given charge density 
distribution (r).
We begin with writing the Laplacian operator in Eq. 5.1.2 in 
spherical coordinates (see Figure 5.1)
V2 _ 1 @ 
@A 1 
@ fintf9^ 
1 
@^
D 
r2 @r \ @r ) C r2 sin # @# \ 
@# / C r2 sin2 # @‘
(5.2.1)
Since in spherical symmetry all partial derivatives of the potential 
with respect to angles disappear, Poisson’s equation acquires a simpler 
1D form
1 d fd^(r) 
r2 dr \ dr
4(r).
(5.2.2)
In Eq. 5.2.2, we assumed the value of the gravitational constant 
GD 1 and omitted the minus sign, which holds for the gravitational 
field. A standard substitution (r)D '(r)=r simplifies the formula even 
further
d2'(r)
--T^D d 4~rp(r). 
(5.2.3)
dr2
This is a second-order, linear, inhomogeneous, ordinary differential 
equation. Such an equation needs two conditions to uniquely define the 
solution. In the case of an initial value problem, these are usually the 
value of the function and its first derivative at certain initial point, which 
allows to start the three-point recursive numerical algorithm (like the 
Verlet algorithm). However, in the case of Eq. 5.2.3, there are boundary 
conditions, that is values of the function at two ends of certain argu­
ment interval. This makes the application of the recursive schemes very

5.3 Numerical Method: Numerov-Cowells Algorithm 37
Figure 5.2 Analytical 
solution of Eq. 5.2.2 (a) 
given density of mass, and 
(b) gravitational potential
inconvenient because an additional condition must be found in order to 
use them.
We will use Eqs. 5.2.1-5.2.3 to find the gravitational potential 
inside a star. Suppose the mass density distribution inside a star is given 
by the formula (Figure 5.2(a))
P(r) D 71-e~r, 
(5.2.4)
8
in which case the total mass of the star is equal to 1 (the mass of the 
Star becomes the unit of mass)
M D 
P(r)d3r D 
P(r)4 r2dr D 1. 
(5.2.5)
The exact solution to this problem is (Figure 5.2(b))
'(r) D 1 - rC2e~r, 
(5.2.6)
from which (r) D '=r follows immediately (note that specific units for 
the gravitational potential are used here). Through independent specu­
lations it is possible to find the additional initial condition to start the 
recursion Numerov algorithm (described in the next section), but for 
the purpose of this project we will use the above formula to find the 
necessary conditions (e.g. values '(r D 0) and '(r D h)).
5.3 Numerical Method: Numerov-Cowells
Algorithm
We consider a class of the second order, linear, inhomogeneous dif­
ferential equations, which describe various physical systems (including 
almost all discussed so far)
d2y
—2 C k2(x)y D S(x), 
(5.3.1)
dx2

38 Project 5: Gravitation inside a Star
where k2(x) is a real function and S(x) is a ‘driving’ term, making the 
equation inhomogeneous.
Using the expansions (2.3.1) one can write down
ynC1 ~ 
nC yn ~1 d y n c h2 y «' c o (* 4). 
(5.3.2)
On the right-hand side of the above equation a second derivative of 
the differential equation can be applied
yn'D (-k2y)n C Sn, 
(5.3.3)
and the forth derivative can be evaluated numerically using the three- 
point scheme as the second derivative of y00(x)
h2
nn 
(ky)nci 
2(ky)n C(ky)n-1 
Snci 
2Sn C Sn 1 
0(1^)
yn D 
h2 
C^t
which, when substituted into (5.3.2), leads to the numerical expression 
(Numerov-Cowell’s algorithm)
h2 2 
5h2 2 
h2 2
I 1 C 12k2cA ynci - 2 H - — k2 I yn C I 1 C 12k2_ J yn_1 D 
h2
D 12. Sn ci c 10 Sn c Sn _1/ c O (h 6).
(5.3.5)
Note that the substitution does not spoil the overall uncertainty 
(accuracy) (O(h4)) and the final local uncertainty of the scheme remains 
very high (O(h6 )).
An important advantage of the expression is that it can be rear­
ranged to give recursive formulas either in ‘forward’ or ‘backward’ 
direction, which will be used in this project. It can also be treated as 
a three-diagonal system of equations, which can be very effectively 
solved numerically with the use of ‘Gauss elimination with backward 
substitution’ (see Project 7).
5.4 Exercises
Obligatory
1. Derive the formula 5.3.5.
2. The power expansion of expression 5.2.6 leads to an approximation 
(for small h) ‘(h) D - 0.5h (verify). Use this in the BVP1D code 
(Boundary Value Problem in 1D) to set the second point for the 
scheme 5.3.5. Evaluate the function '(r) at small variations of'(h), 

5.4 Exercises 39
say in the range -0.4h 4—0.6h (h should be sufficiently small to 
assure high accuracy). Observe and interpret the behaviour of the 
function '(r) in reference to the analytical solution (plot both in 
the same graph). Find the coefficient at h for which both solutions 
coincide. Is the coefficient the same when h is changed?
3. Modify the code so that the Numerov scheme works ‘backwards’, 
that is starting the recursive procedure in ‘infinity’ (in practice suf­
ficiently far, set the appropriate initial conditions). Compare the 
resulting function with the analytical one, and draw conclusions.
4. Extend the code so that it calculates the gravitational field from 
the formula ag = - d0(r)=dr. Assuming that the radius of a star is 
defined as the distance from the centre to the point at which the force 
reaches maximum (this is also what happens in a planet, and how the 
radius of an atom is defined), find the radius of the star.

Project 6
Normal Modes in a Cylindrical 
Waveguide
The eigenvalue problem (EVP) appears, for example, in the descrip­
tion of standing waves or stationary quantum systems. Many theoretical 
techniques have been developed to solve this problem. Here, a numeri­
cal method based on recursive schemes for solving ordinary differential 
equations is presented: the shooting method. The method, although 
seemingly simple, since it deals with 1D case and thus can be applied 
only to low dimensional or high symmetry structures, is employed in 
real-life research, for example in finding the atomic structure within 
Density Functional Theory. In this project, a simple classical system is 
analysed, namely a cylindrical waveguide (e.g. optical fibre) in which 
the normal modes of a scalar wave have to be found.
6.1 Physics Background: Wave Equation, Standing 
Waves
Let us begin with recalling the wave equation in 3D, for a scalar wave 
8(r, t) 
r 20 -
1 a 20
Vp @ 12 D 0,
(6.1.1)
where Vp D !=k is the phase speed, k D (2 )= is the wave number, 
and ! D (2 )=T represents angular frequency.
We consider the case of axial symmetry (like in the cylindri­
cal waveguide) and write down the Laplace operator in cylindrical 
coordinates (see Figure 6.1)
/ \
@ 20 
1 @0 
1 @ 20 
@ 20
' @ r2 C r @ r C r2 @‘ 2 C @ z2
'^^^^“^{'^^^^“^}
1 @0 (r @0 \
\ r ar ^' ar ) 
/
Due to axial symmetry all the partial derivatives with respect to 
and z disappear, and the wave equation takes the form
40

6.2 Problem: Normal Modes in an Optical Fibre 41
@ 2<£ 1 @<£ 
@ r2 C r @ r
1 @2<£ _ 
V2 ~tfi D 0.
(6.1.2)
The field of the scalar waves still remains a function of radial 
coordinates and time (r, t). In the case of a cylindrical waveguide 
there are boundary conditions: (r D 1,t) D 0, (r D 0,t) D 1, 
(@(r, t)=@r)jrD0 D 0, which make the expected solution to be a stand­
ing wave along r (we assume the radius of the waveguide R D 1 and 
use the fact the wave can be arbitrarily normalised, that is its amplitude 
is equal to 1 at the central axis). In such situation the wave function 
can be represented as the product of only the r-dependent part and 
only the time-dependent part (r, t) D r(r)t(t). When substituting 
this product into Eq. 6.1.2 and after simple rearrangement we get
1 
1
k2 <P r (r)
d2^ r (r) 
drr2
1 dr(r) 
C r dr
J__ d 2^ t (t)
!2 0 t (t) dtt-
(6.1.3)
In this equation we have also separated the two constants that com­
prise the phase speed, ! being the time domain characteristics of a 
wave, and k the position space characteristics. In this way, on the left­
hand side we only have the r-dependent function and on the right side 
the t-dependent one. It means that both sides must be equal to a con­
stant, and the fact that locally we can expect harmonic oscillations 
indicates the value — 1 for this constant (then, with the time-dependent 
part it forms an equation for a harmonic oscillator).
The reasoning described here leads to the stationary wave equation 
di C 1 d) ^(r) D -(n(r)k)2<Mr), 
(6.1.4)
dr2 
r dr
with the boundary conditions (rD 1) D 0, (rD 0) D 1, (d(r)=dr)jr D 0 
D 0; additionally, it has been taken into account that in a medium (such 
as an optical fibre) the wave number can be locally modified by a 
refraction coefficient n(r), k0(r) D n(r)k.
6.2 Problem: Normal Modes in an Optical Fibre
The stationary wave equation derived in previous section is an EVP, 
thus we expect the solutions in the form of a sequence of pairs 
f(n (r), kn )g, the so-called normal modes and associated wave numbers 
kn. A standard substitution 0(r) D ‘=pr allows to simplify the equation 
to a form suitable for application of the Numerov-Cowell’s algorithm
r d 2
dr2 C 12
—C C (n (r) k )2 
4r2
'(r) D 0.
(6.2.1)

42 Project 6: Normal Modes in a Cylindrical Waveguide
Figure 6.1 Cylindrical 
coordinates
Note that the asymptotic behaviour of the function '(r) in the limit 
r ! 0 must be ~ pr (see the third boundary condition). This fact 
will be used to avoid singularity in the term 1=(4r)2 in numerical cal­
culations. We will solve the problem numerically using the ‘shooting 
method’ described next for the EVP.
6.3 Numerical Method: Shooting Method
The idea of the shooting method is simple. We perform the recursive 
procedure (like the Numerow-Cowell’s algorithm) with a certain trial 
value of k2 , starting at one end of the independent variable interval. 
When the other end is reached we check the value of the function. 
If it obeys the boundary condition, then the trial value of k2 is the 
eigenvalue. In practice, the problem reduces to finding the roots of the 
function F(k2) D 'rD1(k2).
In the case of a 1D quantum well we also deal with the EVP (see 
also Project 1)
1 d2
2 7772 + V(x)
2 dx
2
(x) D " (x).
(6.3.1)
However, the problem here is slightly more complicated. When 
integrating into the classically forbidden region (negative kinetic 
energy), if the eigenenergy differs from the true one (even by a very 
small amount), a rapidly (exponentially) increasing solution appears, 
and it is very difficult to match the eigenvalue. In this case, the recur­
sion procedure must be conducted from both ends of the domain, that 
is always from within the classically forbidden region into the allowed 
one. The criterion for finding the eigenvalue is a smooth connection 
of the two solutions (the one ‘from the left’ and ‘from the right’) at a 
certain testing point which should be in the classically allowed region 
(note that the same condition has been used in Project1, see Figure 1.2). 
Since the quantum states can formally be arbitrarily normalised, so that 

6.4 Exercises 43
the two solutions connect each other at the testing point, the next con­
dition must be applied, that is their derivatives are equal, which using 
the two-point scheme for the derivative gives
<<(xm 
h ) 
Vr<(xm ) 
Vr>(xm 
h ) 
Vr>(xm )
(6.3.2)
h
h
We reduce h from Eq. 6.3.2 and divide it by >(xm) (or <(xm)) 
to have the expressions on both sides typically equal to 1. A small 
rearrangement leads to the criterion
[ [ [ DA<(xm 
h) 
>>(xm 
h)] — 0, 
(6.3.3)
< (xm )
where '< and '> are recursively found functions ‘from the left’ and 
‘from the right’, respectively, and xm is the testing point.
Unlike in the case of method described in Project1 (for rectangular 
quantum well), this method can be used to solve the EVP for a quantum 
well of arbitrary shape, provided it does not contain potential barriers 
inside, and it will be used in one of advanced projects (see Project 12).
6.4 Exercises
Obligatory
1. The application of the shooting method in the problem considered 
here involves certain complication, namely although we know the 
initial value of the function '(r — 0) — 0, the multiplicative term in 
the stationary wave equation is singular, due to the 1=(4r2 ) compo­
nent. To omit this singularity, we have to start the recursive scheme 
at a certain small distance from zero, r— ". Thus, in principle, two 
control parameters emerge: " and h (the grid parameter). However, 
to simplify the computation, we will use only one parameter, h, and 
start the recursive scheme atr— h. In such an approach it is sufficient 
to study the convergence of results with respect to the grid parameter 
only. Another issue is how to set the values of the function at r— h 
andr— 2h (two initial values are needed for the three-point scheme). 
For that purpose we will use the fact that the asymptotic behaviour 
of the function ‘(r) is known, ‘(r ! 0) ! pr (see the discussion 
of the problem). Since the function can be arbitrarily normalised, we 
can set the values ‘(h) — Wh and '(h) — W2h, where a is an 
arbitrary coefficient.
Run the WAVEGUIDE code and test the convergence of the results 
with respect to the grid parameter h.

44 Project 6: Normal Modes in a Cylindrical Waveguide
2. Calculate the eigenvalues of the wave number and compare the 
numerical results with the analytical values of 2.404826, 5.520078, 
8.653728, and 11.791534. Is it possible to get the exact analytical 
values from the numerical calculations? (Hint: Note that there are 
two parameters which affect the results: the grid h in real space, and 
the uncertainty in the finding roots procedure.)
3. Extend the code so that it outputs the radial functions of normal 
modes amplitudes. Visualise the results.
Supplementary
1. Modify the code so that it calculates the eigenenergies and eigen­
functions for an infinite quantum well and/or the normal modes 
(functions and wave numbers) for a string fixed at both ends. 
Compare the results with the well-known analytical values.
2. For the string from previous exercise consider a situation of a non­
uniform mass distribution (e.g. linear) and check how it affects the 
results.
Challenge
1. Consider the case of a non-uniform but still cylindrically symmetric 
refractive index k(r) D n(r)kc , where kc is a wave number in a vac­
uum and n(r) is the radial distribution of the refractive index (must 
not exceed 2.0 and its value at the wall of the waveguide should 
be 1.0 - vacuum). How do various functions n(r) affect the wave 
numbers of normal modes? Try parabolic or exponential functions.
2. Modify the code so that it finds the energy levels of a rectangular 
quantum well discussed in Project 1, compare the results with the 
results obtained with the QWELL code.

Project 7
Thermal Insulation Properties 
of a Wall
This is the first project devoted to partial differential equations (PDEs), 
and although, due to symmetry, the problem is still reduced to 1D, and 
the differential equation becomes ordinary, a numerical technique typ­
ically applied to PDEs, finite difference (FD), will be introduced and 
discussed.
We will study the insulating properties of a house wall, in particular, 
how temperature across the wall depends on the thermal conductivity 
distribution of an insulating material. To do this we have to apply the 
steady-state diffusion equation.
7.1 Physics Background: Steady-State Diffusion
To derive the steady-state diffusion equation we will use two fundamen­
tal laws: Fick’s law (diffusion) and Continuity law (Figure 7.1), which 
are expressed, respectively, by the following equations:
J(r, t) = -D(r, t)r<p(r, t), 
(7.1.1)
@(r, t)
r- J(r, t) d- C S(r, t), 
(7.1.2)
@t
where (r, t) is the density of the diffusing substance, J(r, t) is its 
flux (current density), D(r, t) is the diffusion coefficient, and S(r, t) 
is the ‘source’ function, that is the rate at which the density of the 
substance (r, t) is produced at the point r.
Figure 7.1 Diffusion’s laws: 
(a) Fick’s law (b) Continuity 
law
45

46 Project 7: Thermal Insulation Properties of a Wall
Figure 7.2 Examples of 
gradients (arrows) of scalar 
functions represented by a 
colour intensity scale
The ’nabla’ vector differential operator reads
r Dbb@ Cbb@ Cbb@-, 
(7.1.3)
@x 
@y 
@z
and plays the role of a gradient (Figure 7.2) in the first equation, and a 
divergence in the second one.
Note that all the quantities appearing in the equations till now are, in 
general, functions of position and time, but in the next step we assume 
that there are no variations with time (stationary system), and substitute 
Eq. 7.1.1 into Eq. 7.1.2. As a result we get
r ■ [D(r)r0(r)] D -S(r). 
(7.1.4)
The S(r) and (r) may have different meanings, depending on the 
type of system considered. In particular, they can be interpreted as the 
source of heat and temperature, respectively. In that case, the diffusion 
coefficient D(r) represents the thermal conductivity.
The equation is an elliptic partial differential equation which, 
together with the boundary conditions (values of the function and/or 
values of its derivatives at some borders surrounding the region of 
interest, and sometimes also inside the region), forms the boundary 
value problem. It is interesting and surprising to note that at a constant 
diffusion coefficient Eq. 7.1.4 becomes the Poisson’s equation.
7.2 Problem: Steady-State Diffusion of Heat 
through the Wall
In this project, we will consider the quasi-1D case (such a statement 
means that although the system is three-dimensional, all the quantities 
vary only with one spacial variable). This is the heat diffusion through 
a wall, say along the X axis, and then the equation simplifies to
- S(xx) D d- (D(xx)“^^), 
(7.2.1)
dx 
dx

7.3 Numerical Method: Finite Difference Method 47
or
- S(.v) D D'(.v)■ C D(x).x, 
(7.2.2)
dx 
dx
with known values of the function at the interval ends: (. D 0) D 0 
and (. D L) D N (where L is the wall thickness).
We assume that the wall is in contact with the heat reservoirs at 
both sides, which stabilises the temperature, so that 0 and N corre­
spond to the temperature at both ends. Moreover, we assume that there 
are no heat sources inside the wall (S(.) D 0), which means that the 
temperature distribution across the wall must be monotonic, no matter 
the heat conductivity.
7.3 Numerical Method: Finite Difference Method
In this project, the FD method will be applied. First, a regular grid is 
introduced, with a grid parameter h. Second, the differential equation is 
discretised, using the three-point formula for derivatives. In the example 
considered, the discretization of Eq. 7.2.2 takes the form
S D D0 0iC1 - 0i-1 C D $iC1 C 0i-1 - 2r'i>i
(7.3.1)
or
Di - 2 dA 0 i _1 - 2 Di 0 i C DDi C 2 D A ^ i C1 d - Sih 2- (7.3.2)
As a result we obtain a system of linear equations where the values 
of the function at grid nodes are unknown. Thus, the FD method 
converts the boundary value problem for differential equations into a 
system of linear equations.
In our case this is a tri-diagonal system of linear equations of the 
form
Al ^i-1 C A0^i C AC ^iC1 d bi -
(7.3.3)
Note that the boundary conditions 0 and N have to be moved to 
the right-hand side of the equation.
To solve this system of equations we will use the very efficient 
Gaussian elimination with back-substitution algorithm. We assume that 
the solution satisfies a one-step forward linear recursion relation of the 
form

48 Project 7: Thermal Insulation Properties of a Wall
iC1 D ii C i,
(7.3.4)
where i and i are the coefficients to be determined. Substituting this 
into Eq. (7.3.3), we get
A7(«iti C Pi) C A0«i C At^i-1 D bi, 
(7.3.5)
which can be solved for i to yield
<£i d YiAi Ai-1 C Yi(ACPi - bi), 
(7.3.6)
with
1
A0 C AiCai'
(7.3.7)
Upon comparing Eq. (7.3.4) with Eq. (7.3.6) we obtain the back­
ward recursion relations for the a0s and P0s
ai_i d yiAp, 
(7.3.8)
Pi_i d yi(ACPi - bi). 
(7.3.9)
The strategy now is as follows: we use the recursion relations 
(7.3.8, 7.3.9) to determine the ai and Pi, for i running from N - 2 down 
to zeros. The starting values to be used are
an-1 d 0, Pn-1 d 0n, 
(7.3.10)
which guarantee the correct value of at the upper boundary. Know­
ing these coefficients, we use the recursion relation (7.3.4) in a forward 
sweep from i = 0 to N - 1 to find the solution, with the starting value 
0 known from the boundary condition. Thus, the solution is deter­
mined in only two sweeps of the involving arithmetic operations of the 
order N.
Note that this technique can be also applied to the boundary value 
problem discussed in Project 5 (Gravitation inside a star). The method 
of solving the tri-diagonal system of linear equations can be treated here 
as a tricky way of ‘moving’ one of boundary conditions to the opposite 
side.
At the end we should refer to the case of partial differential equation 
in many dimensions, in the context of the FD method. We will do it on 
the example of the Laplace elliptic partial differential equation
@2~C C @2C @2) ^x,y,z) D 0, 
(7.3.11)
@ x2 @ y2 @ z2 

7.3 Numerical Method: Finite Difference Method 49
with the boundary conditions in the form of values of at a boundary 
and some places inside the region of interest (Dirichlet type), and/or 
derivatives of at the boundary, in normal directions (von Neuman 
type).
We limit the discussion to 2D to shorten the equations, but the 
methods presented also apply to 3D cases. Thus, in the first step, 
the differential equation is discretised by introducing a regular grid 
in the domain at a given coordinate system, that is the differential 
operators are converted into the FD operators, using the three-point 
formula
0iCi,j C 0i-i,j - 20i,j C 0i,jC1 + 0i,j-1 ~ 20i,j D 0 
(7 3 12)
hx2
hy2
where the labels i D 1, :::,Nx,j D 1, :::,Ny indicate the grid points 
along x and y, respectively, with Nx , Ny being the respective numbers 
of the grid points. Next, we have to create a mutually unambiguous 
mapping of the double indexes onto single ones, for example (i, j) ! 
k D i + Ny(j — 1). Now, the set of values f0i,jg becomes a vector f0kg, 
and Eq. 7.3.12 clearly appears as the system of linear equations of the 
form
AO D a,
(7.3.13)
where the vector a is formed from the values of the 0 function at 
the grid points at which the values are known from the boundary 
conditions. Thus, the problem is reduced to the inversion of the AO 
matrix
0 D A 1a,
(7.3.14)
which seems not be a trivial operation considering the fact that the 
matrix can be very big. For example, in 3D, at the grid 100 100 100 
(which is not particularly dense) the order of the matrix is 106. How­
ever, a good news is that this is a so-called sparse matrix in which a 
vast majority of elements are zero, and there are special methods of 
their storage and very effective algorithms of their inversion. Finally, 
it should be mentioned that a great shortcoming of the FD methods is 
that the shape of the considered domain as well as the related regular 
grid must fit the chosen coordinate system. This limitation does not 
appear in the finite elements methods, which are discussed in the next 
project.

50 Project 7: Thermal Insulation Properties of a Wall
D(a:)
Figure 7.3 The considered 
step function as a model of a 
wall with insulation
7.4 Exercises
Obligatory
1. Using the FTABLE code tabulate a few chosen functions of the ther­
mal conductivity coefficient D(x) and their first derivatives D0(x) 
(e.g. linear, parabolic, nonmonotonic - such as sinefunction, etc.). In 
particular, consider a step function (Fermi-Dirac type) which would 
emulate the wall consisting of two layers: a high thermal conductiv­
ity material (mechanically strong), and a low thermal conductivity 
material (mechanically weak), for example a brick and a styrofoam 
(Figure 7.3). The Fermi-Dirac (step-like) function is expressed by
D(x) D
D1
1 C exp (x=b) 
0,
(7.4.1)
where the parameter is responsible for the step smearing (for small 
the step is sharp), b denotes a coordinate of the border between
the two materials, D1 C D0 and D0 are thermal conductivities of 
higher and lower conductivity materials, respectively. Evaluate the 
derivative of the function and tabulate both D(x) and D0(x).
2. Test the DIFFUSION code for a uniform linear equation dy d 0 
(D0 D 0,D D 1) with different boundary values and grid parameters.
3. Calculate the temperature across the wall for thermal conductivities 
tabulated in the first exercise. Is the temperature distribution always 
monotonic, even if the thermal conductivity is non-monotonic? 
Check what is the effect of reflecting the thermal conductivity func­
tion with respect of the central point? Does the speed of the flow 
change? Is the temperature distribution across the wall for the step­
like thermal conductivity as you expected? What is better from a

7.4 Exercises
51
practical point of view, to put the styrofoam layer inside or outside 
the building? Why?
Challenge
1. Introduce ‘heat sources’ inside the wall by setting additional con­
ditions in the form of the values of (x) function at chosen points 
(there can be more than one point) (Figure 7.3). Observe the effect 
of the additional sources on the temperature distribution and on the 
heat flow (see Figure 7.4).
Figure 7.4 The considered 
source of heat can be 
heating pipes inside a well, 
whose temperature would be 
constant

Project 8
Cylindrical Capacitor
The electrostatic problems described by Poisson’s equation, that is find­
ing the electric potential for given boundary conditions and charge 
density distribution, have their variational formulation (as many other 
problems in physics). In physics language this principle says that the 
potential being the solution minimises the total energy of the system 
(energy of the field plus the potential energy of the charge). How­
ever, there also exists a rigorous mathematical proof that solving the 
Poisson’s differential equation is equivalent to the problem of min­
imisation of a certain functional (the variational principle), thus the 
method can be extended on the systems where the ‘energy’ inter­
pretation does not apply. The variational principles constitute a base 
on which a very important and widely employed class of numerical 
techniques is based - the finite element (FE) methods, which will 
be discussed in this project. A great advantage of these methods is 
a big freedom in the choice of points (the grid) in the independent 
variable space, which is not limited by the choice of the coordinate 
system, and also can be adjusted to the expected behaviour of the 
function we want to find (denser grid in the regions of expected big 
variations of the function). For the sake of simplicity, a high sym­
metry (cylindrical) electrostatic system has been chosen which can 
be described by 1D equation. This allows to present the ideas while 
significantly simplifying the computational procedure. However, in 
Project 14 the discussion will be extended to 2D (which also applies 
to 3D).
The system considered here is a capacitor consisting of two coax­
ial metallic cylinders of different radii. This is not a purely academic 
problem since an important practical reference of such a system exists, 
namely the coaxial transmission cables (antenna, telecommunication, 
etc.) whose main specification is the capacitance per unit of length, 
which determines the cable frequency-dependent transmittance and 
thus its transmission spectrum (one of the exercises is devoted to the 
calculation of capacitance).
52

8.1 Physics Background: Variational Principle for Electrostatic Systems 53
Figure 8.1 The variational 
principle tests a series of 
functions to minimise 
functional
8.1 Physics Background: Variational Principle for 
Electrostatic Systems
An electrostatic system is described by Poison’s equation (see Project 5)
-r20(r) D 4^p(r), 
(8.1.1)
which, for a given charge density distribution (r) and boundary val­
ues, forms the boundary value problem for an elliptic partial differential 
equation (see Project 5), the solution to which is the electric poten­
tial function (r) (Figure 8.1). However, an alternative approach to 
the problem exists, the variational principle. It can be formally proved 
(Chapter A.5) that the function (r) being the solution to Eq. (8.1.1) 
minimises the functional
F[] D
d3r 2(r<£(r))2 - 4Mr)<£(r)
(8.1.2)
In the case of an electrostatic system the functional above corre­
sponds to the total energy, but since the proof is general it can be treated 
just as a generic functional in other cases. The problem is then conver­
ted into the problem of finding the minimum of Eq. (8.1.2). Upon any 
parametrisation of the function (r) with a set of parameters fig, the 
functional becomes a function F(fig) and the problem reduces to find­
ing the minimum of the function. In the finite elements (Figure 8.2)
Figure 8.2 The finite 
elements method applied to 
a circle

54 Project 8: Cylindrical Capacitor
method, the function is represented by its values at the grid nodes fig, 
which become the parameters to be found. At variance with the finite 
difference method the grid can be shaped in an arbitrary way (inde­
pendent of the choice of the coordinate system); it can be denser in the 
regions where the function is expected to vary at a high rate, or can have 
a triangular rather than rectangular geometry.
8.2 Problem: Cylindrical Capacitor
The system considered in this project has cylindrical symmetry. The 
Poisson’s equation takes the form (see Eq. 6.1, and the preceding 
discussion)
@ 
@
- 4~p-r)r D @- ( r 
,
(8.2.1)
which together with the boundary values (r1) and (r2) leads to 
the boundary value problem (similar to that discussed in Project 5). 
Equation (8.2.1) is also formally equivalent to the diffusion equation 
discussed in the previous project, and thus the method introduced there 
can be also applied. In this project, however, we will use the variational 
principle. A respective functional in the cylindrical coordinates has the 
form
Z r2
F[] D
r1
1 / d 0( r)\2
2 \ dr )
— 4np(r)0(r) r.
(8.2.2)
8.3 Numerical Method: Finite Elements (FE) 
Method
The discrete representation of the functional 8.2.2 will be based on the 
simplest possible numerical quadrature scheme, the rectangles method 
Z r2 
N 1
I drf(r) * h£ -if Cf _i), 
(8.3.1)
r1 
i 2
where 2(f C f _1) is the value of the function f (r) in the middle of the 
interval (ri, ri_1) at a linear approximation of the function within the 
interval.
Equation (8.3.1), when applied to 8.2.2 leads to (do the derivation) 
1N 
N
F f i g] 
5"^ (01 - ^ i-1)2 r, 1 - 2x hY' (<£ i p iri C ^ i-1p i-1 ri _1),
2 h 
i 2
ii
(8.3.2) 

8.3 Numerical Method: Finite Elements (FE) Method 55
where ri d r 1 C ih, ri-1=2 d ri — 1 h, h d (r2 - r 1)/N and F becomes 
a function of many variables F[] ! F(fig).
The condition for the minimum
@F
— D 0
@0 i
(8.3.3)
leads to
0iC1 fiC . - 0i(riC. C fi_ 1) C 0i-1 ri_ 1 C h24npiri d 0. 
(8.3.4)
This is a starting equation for the Gauss-Seidel iterative minimisation 
procedure. Let us solve it for i
0i D 0ic1-iC2 C 0i-1-ir2 C 2^h2pi, 
(8.3.5)
2ri 
2ri
or
^i d 1(<£iC1 C 0i-1) C h(0iC1 - 0i-1) C 2nh2pi. 
(8.3.6)
2 
4ri
The strategy is then as follows:
i. Make an initial guess of the function 0 (e.g. the linear 
function between 00 D 0 (r1) and 0N D 0 (r2)).
ii. Calculate the new value of0i form Eq. (8.3.6) at each point of 
the grid ri (except for the boundary values); we will call this 
step a ‘sweep’.
iii. At the new set f0ig (after the sweep) calculate the value of the 
functional (8.3.2).
iv. Repeat the whole procedure until Eq. (8.3.2) stabilises, that 
is the criterion that in three subsequent sweeps the functional 
does not vary more than given is fulfilled.
This procedure can be further improved by mixing the result of a 
sweep with the previous one. This is done via the mixing parameter ! 
in the following way:
00 d 0old(1 - !) c 0new!, 
(8.3.7)
where 0inew is the result of the last sweep, 0iold is the result of the 
previous sweep, and 0i0 is the value to be taken in the nest sweep.
It can be formally proven that the procedure is convergent for a 
certain range of! values, but here we will find the range by performing 
numerical experiments (as one of the exercises). In all the exercises 
(except one) we will also assume that the density of the charge p is zero 
in the space between metallic cylinders; only the values of the potential 

56 Project 8: Cylindrical Capacitor
at the cylinders (r1) and (r2) are given (boundary conditions). This 
means that we are in fact solving Laplace’s equation.
8.4 Exercises
Obligatory
1. Test the CAPACITOR code for different boundary conditions and 
control parameters. Check the convergence of the functional F with 
respect to the grid parameter, and find the optimum value of h, that 
is that value at which the energy assumes minimum. Note that at 
too small values of h the energy increases. The reason for this can 
be found in Eq. 8.3.2, where the term containing the difference 
between neighbouring potentials appears (tending to zero when h 
is too small). Similar situation takes place in the Gauss-Seidel for­
mula 8.3.6, thus the last exercise in this list must be performed with 
caution as for the choice of h.
2. Investigate into the effect of ‘mixing’. Find the range of the param­
eter ! at which the procedure is convergent and find the value at 
which the relaxation is the fastest. (Hint: Modify the code so that 
it outputs the values of the F functional as a function of the iter­
ation number, and plot the functions for different computational 
parameters.)
3. Modify the code so that it takes into account a non-zero density dis­
tribution in Eq. (8.3.6) and repeat the above test for some model 
density distribution (r) of your own choice. Find the optimum value 
of!. Repeat it for two to three different model densities.
4. Perform fully converged calculations for chosen boundary condi­
tions and compare the results with the analytical solution '(r) D 
A ln(r) C B (the values of constants A, B should be found from 
boundary conditions, by solving a system of two linear equations).

Advanced Projects
The following projects are advanced, which means they involve more 
complex physical systems. Both the physics background and numer­
ical methods required do not exceed the material covered in the first 
eight projects, so no theoretical introductions are provided. The pri­
mary formulations of the presented problems have been solved, and 
their respective computational codes can be found in an online reposi­
tory. However, undertaking these projects offers ample opportunity for 
individual creativity, posing new problems, asking questions, and dis­
covering answers. These projects are specifically designed for students 
with a keen interest in research utilising computational methods.
57

Project 9
Coupled Harmonic Oscillators
The first advanced project refers to Project 3, where numerical meth­
ods for solving differential equation were presented. Every physicist 
in their career realises that a model of a harmonic oscillator is rele­
vant in numerous fields of science, including mechanics, atomic and 
quantum physics, optics or electronics. It is frequently used to describe 
physical phenomena present in natural and artificial systems. Here, 
we propose to expand this problem to a system of coupled oscilla­
tors. Coupled oscillators are relevant in both nature and technology and 
can be a useful model to describe the physics of musical instruments, 
electronic devices used for communication, electromagnetic wave and 
matter interactions or biological systems such as the function of a heart 
and its irregularities. Coupled oscillators have been studied by Lionel 
Robert Wilberforce in a laboratory setting, where he built the famous 
pendulum named after him. The Wilberforce pendulum consists of a 
weight suspended from a spring which twists as the spring stretches and 
retracts. During the experiment, Wilberforce observed the energy trans­
fer between two degrees of freedom of oscillations: rotation around the 
spring axis and longitudinal movement along that axis, while the total 
energy was conserved (except for the losses due to friction).
9.1 Problem: Equations of Motion of Coupled 
Oscillators
Coupled oscillators can be mathematically expressed through equations 
of motion of each of the oscillators, with the coupling term (their inter­
action) taken into account. As an example we can consider two simple 
cases (Figure 9.1). The first one is a 1D system of two point masses sus­
pended from two springs of k1 and k2 constants, connected with a third 
spring of k3 spring constant. The second one is a system of two simple 
pendulums moving in the same plane, where the masses are connected 
with a spring. In addition, in Ex. 4 the Wilberforce pendulum will be 
studied, as it is an example of a coupled oscillator as well.
For simplicity, we assume that both masses are the same and m D1, 
which means that their frequencies ! d pk=m depend only on the 
constant k. In the first case, the equations of motions are expressed as
58

9.1 Problem: Equations of Motion of Coupled Oscillators
59
J/10 
S/20 
CAAAT
Figure 9.1 Two possible 
realisations of a coupled 
harmonic oscillator
d2y 1= dx2 D -k1y 1 - k(y 1 - y2), 
d2y2= dx2 d -k2y2 - k(y2 - y 1),
(9.1.1)
where y is the position of the mass relative to the equilibrium. In the 
second case (refer to Project 3, Figure 3.1), we know that in a simple 
pendulum the driving force is the projection of the gravitational force 
on the tangent of the arc of motion. The equation of motion is then
d2s
dt2
- g sin G,
(9.1.2)
where s is the position of the point on the arc. For small angles (which 
is what we consider here) we can assume that s is related to y by the 
relation y D l sin(G ) on the horizontal axis. The equation of motion can 
then be written as
d 2y 
g
dt2 
Iy'
(9.1.3)
It is a slightly modified form of Eq. 3.2.3 from Project 3, where 
instead ofy we had G D s=l y=l. However, this form allows to intro­
duce coupling between the two pendulums: a spring connecting the two
masses:
d2y 1= dx2 D - gy 1 - d-(y 1 - y2), 
d2y2= dx2 D -igy2 - ^(y 1 -y2).
(9.1.4)
If we assume that the masses are the same and equal to 1, m1 D 
m2 D 1 (which means that the frequency of the oscillations is con­
trolled only with the length of the pendulum), and we use the relations 
g=l1 D k1 and g=l2 D k2, we can arrive at a system of equation identi­
cal to Eq. 9.1.1. This means that the two qualitatively different systems 
can be described by the same mathematical model. What is left is to 
take a closer look at the nature of solving those equations, and through 
computational experimentation getting familiar with the physics of this 

60 Project 9: Coupled Harmonic Oscillators
system, its behaviour depending on the parameters of the pendulums 
and their coupling, and, in particular, the energy transfer between the 
pendulums. A system of coupled oscillators, described with Eq. 9.1.1, 
is an IVP for ordinary differential equations. The numerical methods 
necessary to solve that problem have already been discussed in Proj­
ect 3. In this project, the Runge-Kutta algorithm will be used, as it has 
been identified as the most effective in previous Project.
9.2 Exercises
Compound Pendulum
1. In the program CHO, set the coupling constant k D 0 and check 
the convergence of results with respect to the time-step h. Observe 
the total energy of the system which should be conserved during 
simulation. Repeat this exercise for different spring constants k1 
and k2. Check whether the frequencies of oscillators agree with the 
analytical values.
2. Perform simulations of two simple cases: Sloshing mode and Breath­
ing mode, see Figure 9.2. In order to do this, set appropriate initial 
conditions, and then find the dependence on time of the total energy 
of the system and energies of both oscillators. Interpret the results. 
Check how the coupling constant k affects such oscillations.
3. The most interesting phenomenon appearing in coupled oscillators 
is the energy flow between them. This phenomenon finds many refer­
ences in nature and technology. For example, in physics of musical 
instruments - in violin and similar instruments - the string oscil­
lations are transferred to oscillations of wooden plates and the air 
cavity of resonant box. In electronics, RLC systems, coupled via 
electromagnetic waves, can transfer energy between themselves (e.g.
Figure 9.2 Special cases of («) 
coupled oscillator’s
behaviour: (a) sloshing 
4'
mode, (b) breathing mode 
2
o
-2­
-4­
-6 
vww« 
wvw1.
0 2 4 6 8 10
6-y
0-
■•NWW, 
-6-1- T--- T--
T--
T--
T--
T- 1
0 
2 
4 
6 
8 
10

9.2 Exercises 61
Figure 9.3 E1 is the total 
energy (kinetic and 
potential) of the first body, 
E2 is the total energy of the 
second body, and E3 is the 
potential energy of the 
spring connecting the bodies
in radiocommunication, telecommunication, contactless control sys­
tems, and electronic bank cards). In quantum physics, when an 
energetically excited quantum system (e.g. in an atom) falls down 
to the ground state, it can emit a photon which, in turn, can excite 
another quantum system. These are only examples of phenomena for 
which coupled oscillators serve as a basic classical model. It should 
be pointed out that the phenomenon of resonance plays an important 
role here. Namely, the energy transfer is most effective if it is of a 
resonant character, that is the agent exciting an oscillator (originat­
ing from another oscillator) has the same frequency as its natural 
frequency, which is called resonant coupling. This exercise gives an 
opportunity to investigate into the phenomenon.
Resonant Coupling. Consider weakly coupled oscillators (k 
k1, k2). For equal spring constants k1 D k2, find how the frequency 
of energy flow between oscillators depends on the coupling constant 
k (Figure 9.3). Try to formulate a universal conclusion by finding 
the dependence of the frequency on the ratio k=k1 D k=k2 .
Non-resonant Coupling. For weakly coupled oscillators, find the 
dependence of energy flow between oscillators on the difference 
between spring constants k1 and k2. To do it systematically, try to 
find the dependence of the ratio of amplitudes E1max=E2max on the 
ratio of spring constants k1 =k2. How does the coupling constant 
affect this dependence? Observe the frequency of energy flow and 
try to find similar dependencies for the frequency.
4. Wilberforce Pendulum. Let us consider a system mentioned in the 
introduction to this project, that is the Wilberforce pendulum. The 
system consists of a spring of negligible mass, a spring constant k, 
and torsional spring constant . A body of mass m and moment 
of inertia I with respect to the vertical axis z is suspended from 
the spring (Figure 9.4). We will assume a linear dependence of

62 Project 9: Coupled Harmonic Oscillators
Figure 9.4 The Wilberforce 
pendulum model with 
dependencies of 
displacement z and twist 
angle on time, equivalent to 
typical dependencies in 
coupled oscillators
Figure 9.5 Trajectory of a 
point on the border of the 
body. Scale of brightness 
corresponds to time scale 
(dark colour represents first 
moments of motion which 
begins in the point (0, 1, 10), 
bright - the last moments)
forces (torque) on the linear (angular) displacement, and a bilin­
ear dependence of coupling between the two degrees of freedom 
1 ez0, where e is a coupling constant. We begin the derivation of 
the equations of motion from writing down the Lagrangian of the 
system
L d 1mz C 102 — kz — S02 — ez0. 
(9.2.1)
The use of the Euler-Lagrange equations leads to
mz d — kz — 2 e0, 
10 d - k0 - 1 e z.
Modify the CHO program so that it simulates the motion of a 
Wilberforce pendulum, with the possibility of setting different val­
ues of parameters. The program should output the values of the total 

9.2 Exercises
63
energy and its components (potential and kinetic energies, of trans­
lational and torsional motions), and position of chosen point in the 
body as dependent on time in 3D cartesian coordinates.
Using the modified program simulate the motion of the Wilberforce 
pendulum. As a test for correct simulation check the dependence of 
the total energy on time (it should be conserved). Plot the dependen­
cies of all the energy components on time. For a chosen point in the 
body plot the 3D trajectory of the motion (e.g. Figure 9.5). Repeat 
the calculations for a few significantly different sets of parameters.
5. Lissajous curves. Jules Antoine Lissajous used two vibrating tuning 
forks with mirrors to generate figures which were named Lissajous 
curves, following his name. To obtain this result using the CHO 
code, consider a system of independent oscillators (k D 0). In this 
case, find the appropriate initial value and draw Lissajous curves in 
Cartesian coordinates (y1 D x,y2 D y) (Figure 9.6a) and polar coor­
dinates (y1 D r, y2 D ) (Figure 9.6b). Next, check what happens 
if the oscillators are not independent; consider only a really weak 
interaction. Consider the system when k1 D k2. What is the motion 
of the oscillator with and without interaction?
Figure 9.6 The examples of 
Lissajous curves: (a) in 
Cartesian coordinates, (b) in 
Polar coordinates

Project 10
The Fermi-Pasta-Ulam-Tsingou 
Problem
At the beginning of this book we discussed a simple problem of a har­
monic oscillator (Project 3), which we then expanded into a problem 
of coupled oscillators (Project 9). Throughout this project, however, 
we considered only linear interactions between the oscillators. We also 
covered methods of solving differential equations and their use in initial 
value problems (IVP). In this project, we consider a chain of many bod­
ies interacting with each other through a non-linear force. In literature, 
it is known as the Fermi-Pasta-Ulam-Tsingou problem. The analysis 
of the physical properties of such a system leads to unexpected obser­
vations. First, we see a spontaneous generation of oscillation modes 
of higher frequencies (i.e. frequency multiplication). Second, from a 
seemingly chaotic motion an order emerges, which includes a periodic­
ity of that motion in time. This has been possible through the numerical 
methods described in this book.
10.1 Problem: Dynamics of a One-Dimensional 
Chain of Interacting Point Masses
Let us consider a chain of interacting point masses m (Figure 10.1). 
Their equilibrium positions are expressed by a vector of coordinates 
on the X axis, x d (...,x°_1,xO,xOC1,...). Let’s also assume that the 
distance between neighbouring masses is constant xi - xi_1 d a, and 
call it the lattice constant a. The masses are allowed to move along the X 
axis, which is expressed by a time-dependent displacement vector y D
Figure 10.1 Chain of 
oscillating masses
64

10.1 Problem: Dynamics of a One-Dimensional Chain of Interacting Point 65
Time (arb. units)
Figure 10.2 Coordinates of 
the central mass in a 
harmonic motion N D 32, 
a D 1, m D 1, D 1, D 0: 
(a) time dependent, (b) in 
the form of phase diagram
(:::, j;_1,yi,yi+1,:::), whereyi = xi - x andxi is the time-dependent 
position of the mass.
Newton’s equations of motion for the i-th mass
@2yi
--D d F(yi+i - yi) - F(yi - yi_ 1). 
(10.1.1)
@t2
The expression for the force (right side of the equation) suggests 
that only the nearest-neighbour interactions are considered, and that the 
force depends on the difference in the displacements (a relative dis­
placement). Let’s start from a linear dependence of the force on the 
relative displacement F(yi+i - yi) = a(yi +1 - yi), which simplifies 
Eq.10.1.1 to
@2yi
2£ d a(yi+1 + yi_1 - 2yi). 
(10.1.2)
@t2
With this form of the equation, we expect that locally the oscil­
lations are harmonic (Figure 10.2), and the motion of two different 
masses can differ only by a phase factor (due to their periodic sym­
metry). Taking those two factors into consideration, we can postulate a 
solution
y{ d Aei(!t-kxi). 
(10.1.3)
It is a function that describes a wave, where ! = T is the angu­
lar frequency (T is the period of oscillation) and k = 2F is the 
wavenumber ( is the wavelength, equal to or greater than the mini­
mum wavelength allowed in the system, 
2a). A substitution of
Eq. 10.1.3 in Eq. 10.1.2 leads to an expression for the dispersion rela­
tion, a detailed derivation of which can be found in the supplementary 
material (Appendix A.4)
,., 
12a _ 
,, s 
, s
!(k) = v —[1 _ cos(ka)], 
(10.1.4)
m

66 Project 10: The Fermi-Pasta-Ulam-Tsingou Problem
with k varying between — ^ and y (first Brillouin Zone). If we limit the 
length of the chain, assuming that masses x0 and xN are immobilised, 
that is y0 D yN D 0, then only standing waves (or their superpositions) 
can be excited in the chain, for which Eq. 10.1.4 can be factorised into 
spatial temporal components (see Project 6)
y D A cos(!t) sin(kx). 
(10.1.5)
The left boundary condition for the spatial part is automatically 
fulfilled, due to the choice of the sine function. In order to fulfil the 
right boundary condition, the following condition must be fulfilled
yN D A sin(kaN) D A sin(kL) D 0,
where L D aN is the total length of the chain. This leads to a 
discretisation of allowed wave modes (normal modes)
knL D n,
which means that the wavevector can only have discrete values
kn = — 
k L ’
with n D 1, ::: , N - 1.
For a given chain of length L, the longest normal mode is always 
max D 2L, while the shortest is the above-mentioned shortest wave­
length Xmin d N2L1. This means that the set of allowed modes is not 
only discrete but also finite, because we can have at most N — 1 normal 
modes. The set can be expressed as
f yn0 D An sin( knX01), ::: , $in( ^X^ _1)), n D 1, : : : ,(N - 1)}.
(10.1.6)
In the above equation, An is the amplitude of the n-th mode and 
the upper index 0 indicates t D 0 in Eq. (10.1.5). The normal modes 
make up an orthonormal base in N - 1 dimensional space, which can 
be normalised by an appropriate choice of the amplitudes An , so that 
the following relation is fulfilled
yi0yj0Dij.
An inclusion of the time-dependent part results in
yn(t) Dyn0 cos(!nt), 
(10.1.7)
where !n D !(kn ) is the angular frequency associated with the n-th 
mode, given by the dispersion relation (10.1.4).

67
10.1 Problem: Dynamics of a One-Dimensional Chain of Interacting Point
We can now derive the vector of velocities in the n-th mode as a 
time derivative of the displacement vector (10.1.7)
vn(t) D -yn0!n sin(!nt). 
(10.1.8)
This allowed us to find the trajectory in a multidimensional phase 
space for each mode.
Let’s include a non-linear, second-order interaction
F(yici -yi) d ayici -yi)C £(yici -yi)2. 
(10.1.9)
We assume that the initial state of the chain is the first normal mode 
from the yn0 set, with an amplitude A
A
y (t D 0) D A1 y D A (sin( k1 xo1),::: ,Sm( k1 xoN(10.1.10) 
with zero initial velocities vN(t D 0) D (0, : : : , 0).
The energy of such a chain is therefore initially only the potential 
energy of the interaction
N
e d X u (yi1 o - y1-1), 
(10.1.11)
where U(y) d -(^ay2 C 3^y3), and should be conserved throughout 
the entire motion.
Therefore, we have a system of differential equations (10.1.1) to 
solve. We use numerical methods, similarly as in the pendulum (Proj­
ect 3), and coupled oscillator projects (Project 9). As a result, we obtain 
a time evolution of the trajectories in a multidimensional phase space 
of the coordinate and velocity vectors y(t) and v(t). The observation of 
the time evolution of a trajectory of a chosen mass (which can be done 
by plotting velocity as a function of position, see Figure 10.3) leads to 
0.10
0.05
0.00
-0.05
-0.10
0.00 0.25 0.50 4.50 4.75 5.00
Time (arb. units)
-1.0 -0.5 
0.0 
0.5 
1.0
Figure 10.3 Coordinates of 
the central mass in a 
non-harmonic motion 
N D 32, a D 1, m D 1, a D 1,
D 0.25: (a) time 
dependent, (b) phase 
diagram

68 Project 10: The Fermi-Pasta-Ulam-Tsingou Problem
the conclusion that the motion is chaotic. However, a certain order can 
be observed within that chaos. To do this observation, let us project the 
time-dependent displacements vector into fundamental modes, which, 
as we can remember, form an orthonormal basis
N -1
y(t) D X an (t)yOn0. 
(10.1.12)
nD1
The coefficients an are projections of the state of the system onto 
the fundamental modes
an(t) D y(t) yOn0. 
(10.1.13)
A similar representation can be performed for the velocity (using 
the same basis)
N -1
v(t) D X bn(t)yOn0, 
(10.1.14)
nD1
where the coefficients bn are
bn(t) D v(t) yOn0. 
(10.1.15)
By doing this, we moved the entire time dependence to the 
coefficients fan (t)g and fbn (t)g. Now, instead of tracking the position 
and velocity of a given mass, we can observe the evolution of the 
coefficients, where the trajectories appear to be quite regular (see Fig­
ure 10.4). Let’s focus on the energy and its flow through the modes 
(Figure 10.5). The energy associated with a given mode n is the sum of
Figure 10.4 Coefficients ai(t) 
and bi(t) for i=1, 2, 3, and 4 
respectively, for the case as in 
Figure 10.3: (a) time 
dependent, (b) phase 
diagram
-4-2 
0 
2 
4 
-0.8 -0.4 0.0 
0.4 
0.8

10.1 Problem: Dynamics of a One-Dimensional Chain of Interacting Point 69
Figure 10.5 Solution for 
N D 32, D 1 and D 1=4, 
originally obtained by Enrico 
Fermi, John Pasta, Stanis+aw 
Ulam and Mary Tsingou in 
1955 (The numbers above 
the curves denote modes.)
potential and kinetic energies
N 
N-1 1
En(t) D X U(ynn -ynn-i) C X 2mvnn2, 
(10.1.16) 
where the upper index is the mode number, and the lower index indi­
cates the mass. We can also write the condition for energy conservation
N-1 
N
X En(t) D const D X U(y10 - y101). 
(10.1.17)
nD1 
iD1
The computational procedure is now as follows. We solve the sys­
tem of coupled differential equations (IVP - initial value problem), 
using one of the methods described in Project 3, while similarly to 
the coupled oscillators (Project 9), we recommend the Runge-Kutta 
method. For every fixed number of time steps (which speeds up the 
algorithm), we calculate the coefficients an (t) and bn (t) from the dot 
products (10.1.13) and (10.1.15), which allow us to calculate the ener­
gies En(t) with the use of (10.1.12), (10.1.14), and (10.1.16). That way 
we can obtain the time dependence of these quantities. The total energy 
as a function of time (which should be constant) will serve as a criterion 
for a proper choice of the time step (the optimal time step is the biggest 
time step that still keeps the conservation of energy).

70 Project 10: The Fermi-Pasta-Ulam-Tsingou Problem
Figure 10.6 Displacements 
of masses at different 
instances of time
10.2 Exercises
1. Before proceeding to each of the exercises where the parameters of 
the system are changed (the number of masses, coefficients of inter­
actions), a convergence test with respect to the time step h should 
be performed. The criterion for a proper choice is the conservation 
of energy with respect to time. In order to practice the procedure, 
try to find the largest h for which the energy is conserved. Use the 
amplitude distribution for the first mode as initial positions (and zero 
velocities).
2. For the system from the previous exercise perform a simulation of 
motion. For a few chosen time instances plot the positions of the 
mass (see Figure 10.6). Based on that plot, choose one relatively 
complicated state of positions, and knowing the coefficients an(t) 
plot in a single figure y(t), and its component fan (t)yOn0g.
3. For a chosen system plot the time dependence and phase portraits 
of position and velocity of a chosen mass and an(t) and bn (t) coef­
ficients (see Figures 10.3 and 10.4). Repeat the exercise for three 
cases: linear interaction only, non-linear interaction only, and both 
interactions at the same time.
4. The most interesting aspect of the FPUT problem is the frequency 
multiplication and energy transfer between modes. The first one was 
present in Exercise 2 already, where the initial condition was a fun­
damental mode; higher-order modes appear after some time. Now 
we investigate the time dependence of the energy components.
For a given system, plot the total energy E(t) and energy components 
fEn (t)g as a function of time (see Figure 10.5). Repeat the exercise 
for three cases: linear interaction only, non-linear interaction only, 
and both interactions at the same time.

10.2 Exercises 71
Energy (a.u.
Figure 10.7 Results for
N D 32, a D 1, m D 1, D 1, 
D 1. Larger magnitude of 
the parameter results in 
the emergence of 
higher-order modes
5. Investigate how the non-linear interaction parameter influences the 
speed of higher-order mode generation, their number and amplitude 
(see Figure 10.7). Suggest an appropriate numerical experiment. 
Add a third-order interaction and check its influence on a chosen 
example (without a detailed analysis).

Project 11
Hydrogen Star
In Project 5 we discussed the problem of gravitation inside a star when 
the distribution of its mass density inside is known. In that case we 
applied the Numerov-Cowells algorithm to solve Poisson’s equation 
in spherical coordinates - a boundary value problem. We can now 
go back to that problem and attempt to determine the mass density 
distribution.
11.1 Problem: Mass Density Distribution in a Cold 
Hydrogen Star
We already know how to determine the potential when a radial mass 
density distribution is known, so let us focus on the density. In order 
to do that we can use a condition for equivalence of forces acting on a 
mass dm at a distance r from the centre of the star and perpendicular to 
r. Two forces act on dm: a gravitational force and a force coming from 
the change in pressure as the distance is changed by dr (Figure 11.1). 
We can write this down as
aG(r)(r)drds D dP(r)ds, 
(11.1.1)
where aG(r) is a gravitational acceleration at a distance r from the 
centre, (r) is the mass density, and ds is an element of the surface 
perpendicular to the radius. The surface element ds can be elimi­
nated from both sides of the equation, leaving the condition to be 
aG(r)(r)dr D dP(r) (we are comparing the magnitudes of the forces 
here).
Figure 11.1 The condition 
for equivalence of forces 
acting on a mass dm
72

11.2 Numerical Method 73
The quantities present in this equation need further analysis. The 
gravitational acceleration can be determined from the integral form of 
Gauss law
a aG(r) ds d -4n GMr, 
Sr
(11.1.2)
where G is the gravitational constant, Sr is a spherical surface with 
a radius r, and Mr is the mass inside that sphere. To simplify further 
calculations we will assume G D 1.
Taking into account that the mass Mr is
Mr D 
(r0)4 r02 dr0, 
(11.1.3)
0
and that aG has the same value on the entire sphere S, from the integral 
form of Gauss law we have
4~r2aG(r) d -4n [ p(r0)4^r02 dr0, 
(11.1.4)
0
aG(r) dP p(r')4^r02 dr'. 
(11.1.5)
r2 0
On the right-hand side of the condition for force equivalence we 
will use the expression for P(p) (from equation of state) for the gas 
that makes up the star, in order to express the differential dP through a 
partial derivative @p and a differential dp
@P
dP d — d p. 
@p
(11.1.6)
Circling back to the condition for equivalence of forces we arrive 
at
1 Z r 
2 
@P
----pp(r)dr I p(r^4^r2 dr d— dp, 
(11.1.7) 
r2 
0 
@p
which leads to an integro-differential equation
d p 
1 
/ 9 P V1 f r , 
,2 ,
— d—2p(r)( —) I p(r)4^r2 dr . 
(11.1.8)
dr 
r2 
@p 0
11.2 Numerical Method
In the discussed problem we are dealing with an integro-differential 
equation. It turns out, as we will show in this project, that the method 

74 Project 11: Hydrogen Star
used in Project 3 can also be used here. For solving numerically a 
differential equation
dy D f (y,x), 
(11.2.1)
dx
a uniform grid xn with a constant h is introduced, which leads to a 
recursive scheme
xnC1
ynC1 D yn C h f (x, y)dx. 
(11.2.2)
xn
We should note that the equation, even though it is an integro­
differential equation, also has the form of 11.2.1. The function f(x, y) 
in the integral needs to be extrapolated in the interval (xn , xnC1) based 
on the known previous points. We will use a linear extrapolation from 
points fn-i,fn. We can introduce a local variable f d x - xn), then
f (f) D fn 
fn~1 f Cfn, 
(11.2.3)
h
and
ynC1 D yn C 
fnn fn-1 f C f^ df. 
(11.2.4)
0
After the integration, we arrive at a second-order Adams-Bashforth 
scheme
ynC1 D yn C 2h(3fn - fn_1). 
(11.2.5)
In our equation, y is replaced with , the independent variable is r, 
and the function f takes the form
1 
/ @ P V1 fr 
. 
,
f(r) d—2p(r)( —) 
/ p(r)4nr2dr. 
(11.2.6)
r2 
@ r 0
In the next step, the form of fn after the discretisation frn D 
nh, n D 0, :::,Ng has to be found. In order to determine the integral 
in Eq. 11.2.6 we will use the trapezoid method
p (r0)4 r02 dr0 D
0
n1
= 4n 
-h[p((i - 1)h)(i - 1)2h2 C p(ih)i2h2].
iD1
(11.2.7)

11.2 Numerical Method 75
Therefore, 
fn D f (nh)
1 
(@ p> 1 
A 1
d —2,2P(nh) (^“J 4^^ oh[p((i_1)h)(i“1)2h2 C P(ih)i2h2],
n2h2 
@ hn 
iD1 2
(11.2.8)
and after simplification
p / @ P\~1 n
fn 
2-h^nl —) 
y>i-1(i - 1)2 C Pii2]. 
(11.2.9)
n2 @O hn iD1
Equation (11.2.9) can be used in a recursive scheme
PnC1 D Pn C 2h(3fn ~ fn-1), 
(11.2.10)
beginning with n D 1. As we can see, it is necessary to use the initial 
values P0 and P1.
We should note that the density cannot change abruptly as we cross 
the centre of the star, which means that the derivative of the density 
with respect to r for r D 0 has to be equal zero, dP=drjrD0 D 0. This 
condition is not fulfilled for the model density from Project 5, which 
is its significant flaw. Therefore, we can assume P0 D P1. We can also 
demonstrate that f0 D 0 and subsequent values offn can be determined 
from 11.2.9.
We now need a non-recursive form of pressure P(P). That pres­
sure comes from the equation of state, and for an ideal gas it is linear. 
However, it turns out that the linear dependence is too weak to coun­
teract a gravitational collapse. We note that as the density increases, 
the atoms come closer together, atomic orbitals start to overlap, and 
quantum interactions lead to a rapid increase in density. Here, we will 
propose an exponential form of P(P).
p (p) d a (eBp -1), 
(11.2.11)
where A and B are parameters which influence the final result of P(r) in 
one of the student exercises. In the limit of small density we obtain a lin­
ear dependence, like in an ideal gas; however, as the density increases, 
that increase is controlled by the constants A and B and can be sudden.
A partial derivative that appears in Eq. 11.2.9 is of the form
^P0) D 2ABpeBp2. 
(11.2.12)
@P
Therefore, we built a model to determine the mass density distri­
bution in a star that has three parameters: the density in the centre of

76 Project 11: Hydrogen Star
the star 0 and two parameters A and B that describe the properties of 
the gas. The numerical experiments to be performed should focus on 
the influence of these parameters on the density distribution, a physical 
interpretation of that influence and the relation of the model to real life 
systems.
11.3 Exercises
1. Using the initial value for the density from the density model in 
Project 5, 0 D 1=(8), choose the parameters A andB that describe 
the properties of the gas so that the density is close to the model one. 
Plot both densities in one figure and describe qualitative differences 
between them.
2. Try to make the model realistic by introducing the true value of the 
gravitational constant and by using SI units. Using the pressure as 
a function of volume per 1 atom, Vcell, obtained from density func­
tional theory (DFT) (see Appendix A.9), find the relation between 
pressure and density P(), in order to determine the constants A and 
B from a fit to Eq. 11.2.11. Add also to the pressure versus density 
model (11.2.11) the term accounting for the equation of state of an 
ideal gas: P d RTp, where R is universal gas constant, p. is molar 
mass of hydrogen, and T is the temperature. Note that with this term 
also the derivative 11.2.12 has to be modified.
3. Plot the gravitational acceleration aG (Eq. 11.1.5) as a function of 
the radius for different masses and temperatures, and determine the 
radius of the star RS by finding the maximum value of the acceler­
ation. Note that the mass of the star is determined by the density in 
the centre, p0, and must be calculated from integral 11.1.3, at the 
upper limit determined by density approaching zero.
4. Using the realistic model of the star, determine the pressure at the 
centre of the star as a function of the star mass for a given tem­
perature. The extrapolation of that dependence to zero gives the 
critical mass of the star M , that is the mass above which the sys­
tem is stable (the gravitational force keeps the star), and below 
which the gas would disperse. Note that in these considerations 
also the escape speed of the hydrogen atom must be taken into 
account, that is the average velocity of the atom estimated from 
the formula vH d P3kBT=m (where kB is Boltzmann constant and 
m is atomic mass of hydrogen) should not exceed the escape speed 
vesc d p2GM =RS (where G is gravitational constant and RS can be 
taken as calculated previously radius of the star). This condition can 

11.3 Exercises 77
be used to establish the temperature range which can be considered 
for a given mass of the star.
5. Using literature data for hydrogen nuclear fusion reaction (pressure 
vs. temperature) discuss the possibility of such nuclear reaction in 
considered stars.
6. Assuming that the phase transition between gaseous and solid 
(metallic) hydrogen occurs at 400GPa (at T D 0K), find the radius of 
the metallic core of the star as a function of the mass of a hypothet­
ical cold hydrogen star (T D 0K). For simplicity, assume that there 
is no change in density when the phase transition between hydrogen 
gas and metallic hydrogen occurs.

Project 12
Rectangular Quantum Well Filled with
Electrons - The Idea of Self-Consistent 
Calculations
A quantum well, an example of which has already been discussed in 
Project 1, is an interesting problem relevant in real life applications. 
Semiconductor heterostructures, that is systems of layered semicon­
ductor materials of varying properties (band gaps, effective masses, 
etc.), have a multitude of applications; therefore, it is not purely an 
academic exercise. In the direction perpendicular to that structure we 
observe a system of quantum wells with complicated electronic struc­
tures of discrete energy levels resulting from quantisation due to spatial 
confinement and electronic structure of the materials. In this project 
we partially address that problem by analysing a single quantum well 
(similar to that from Project 1) filled with electrons.
It is necessary to pay particular attention to the conditions required 
for such well to be formed. An empty quantum well, as in Project 1, 
is made of two infinite and infinitely thin dipole planes separated by a 
width a and of opposite dipole orientations. In that case, charge neutral­
ity is present and, simultaneously, the plane introduces a sharp change 
in the potential to — V0. If we were to fill that well with electrons, the 
situation would get more complicated. Charge neutrality has to be ful­
filled but by introducing electrons (a certain amount of electrons per 
unit area), the well becomes negatively charged. One way to neutralise 
that charge is to introduce a uniform positive charge between the dipole 
planes, of equal charge per unit area. This model is called jellium and 
will be used in this project.
Let’s start from an empty quantum well composed of infinite dipole 
planes filled with positively charged jellium. As we will soon realise, 
the shape will be different from that shown in Project 1. Utilising the 
algorithm of finding energy levels for a quantum well of any shape, dis­
cussed in Project 1, we will determine these levels and then populate 
them with electrons in numbers equivalent to the positive charge of the 
jellium. The presence of electrons will significantly modify the shape of 
the well compared to that for a single electron, since it now has to inter­
act with a non-uniform electron gas. The problem is complicated on its 
own and is a basis for a whole field of studies, for example in density 
78

12.1 Problem: Quantum Well Filled with Electrons 79
functional theory (DFT); we, however, will greatly simplify the prob­
lem by considering only the Hartree interactions, that is the coulomb 
interaction of a single electron with an average charge of the remaining 
electrons. The calculations will be self-consistent. After determining 
the energy levels in an empty well, we populate them with electrons 
(respecting the Pauli’s exclusion principle), therefore introducing a neg­
ative charge density to the positive charge density of the jellium. The 
negative charge is evaluated from the formula
ne(x) D - X qij^i(x)j2, 
(12.0.1)
i
where i assumes values 0, 1, 2, when the number of electrons in a 
given state is 0, 1, or 2, respectively (Pauli’s exclusion principle). As 
one can see, the summation covers occupied states only. Next, we 
add the electron density ne(x) to the uniform density of jellium nj (x), 
n(x) D ne(x) C nj(x), and solve the Poisson’s equation for the new 
density
d2 V(x)
-----(-) d -4xn(x) 
(12.0.2) 
dx2
to find the new shape of the potential energy of the well V (x). We then 
determine the new energy levels, populate them with electrons, and 
continue that loop until a certain property, such as the total energy, the 
value of the ground state energy, or the electron density, converges. 
An appropriate criterion for the convergence should be worked out 
and implemented. Usually, when the differences between three to four 
subsequent values of a chosen quantity (or residual of a function) do 
not exceed an assumed small value, the loop stops (convergence is 
achieved).
Here, we do not consider the electron self-interaction - occupying 
the ground state with a single electron also modifies the potential, even 
though the electron does not interact with itself.
12.1 Problem: Quantum Well Filled with Electrons 
and Charge Neutralising Jellium
Simple reasoning, even using just the integral form of the Gauss law, 
leads to a conclusion that positive jellium introduced between two 
infinite dipole planes is described with a parabolic potential inside 
the system and a linear one outside. The electric field at the edge 
of the jellium on both sides of the dipole layer has to be equal and 
have the value ofEo D 1=2N per a surface unit (in Hartree), where N is

80 Project 12: Rectangular Quantum Well Filled with Electrons
Figure 12.1 Results of the 
self-consistent calculations. 
The dashed lines represent 
the results for the first 
iteration, and the solid lines 
represent the last iteration 
(after convergence is 
achieved), for a well of width 
1, a potential 10 eV deep, 
and N D 3. The left panel 
shows the potential with the 
eigenenergies and their 
eigenfunctions. The right 
panel shows the total 
electron density for the same 
potential
the expected number of electrons to be placed in the well. The direction 
of the field on both sides of jellium will be opposite.
The potential of an empty well can, therefore, be defined as
V(x) D
- Nx2 - Vo
Nx 
aX
-X-x 
ax
dla - a=2 < x < a=2,
dla x < — a=2,
dla x > a=2, 
where a is the width of the well (the distance between the dipole 
planes - the thickness of the jellium), N is the number of electrons 
that will occupy the states in the well, and Vo is the minimal depth 
of the well. The electric field at the well’s edge is -N=2, CN=2, for 
negative and positive sides of the X axis. As a consequence of the self- 
consistent procedure, the potential outside of the well, initially linear, 
should flatten out, since the well is electrically neutral (Figure 12.1).
In the code, the algorithm described in Project 6 is used to 
determine the eigenstates of the quantum well. In the self-consistent 
procedure, the ground state energy is used as the convergence criterion.
12.2 Exercises
1. Analyse the Hartree code and run it for a chosen set of parameters.
2. Perform the calculation for different sets of parameters a,N, and Vo. 
Pay attention to how the potential changes with different values of 
N.
3. Perform the calculation for N D 1. Discuss the result.

Project 13
Time-Dependent Schrodinger Equation
Dawid Dworzanski
In this project, we discuss the problem of time evolution of a wave 
function in a given quantum well.
13.1 Problem: Time Evolution of a Wave Function
in 2D Quantum Well
In previous projects we solved for stationary states for some quantum 
wells (1). These stationary states fulfil the equation
HO i(x,t)D"i i(x, t). 
(13.1.1)
In order to determine their evolution in time, we solve the time­
dependent Schrodinger equation, which (in atomic units, ~ d me d 
e D 1) reads
id(x(xx,t) d Hx(x, t). 
(13.1.2)
If the Hamiltonian is not explicitly dependent on time, the wave 
function can be written as a product of its position-dependent part and 
its time-dependent part
i(x,t) D i(x) i(t). 
(13.1.3)
Introducing the wave function to the Schrodinger equation 13.1.2 
and utilising Eq. 13.1.1 we obtain
d (t)
ixixx' 
d "iixxxx)xixt), 
(13.1.4)
dt
and 
d (t)
—— d -1"ixi(t). 
(13.1.5)
dt
The solution to that equation is an exponential function
i(t(t) d e-i"it. 
(13.1.6)
It is a complex number of magnitude 1 and phase -"it, so the time 
evolution of stationary states is characterised with a uniform change of 
81

82 Project 13: Time Dependent Schrodinger Equation
global phase at a speed proportional to the energy, since for a given x0, 
only the phase of the wave function changes while the amplitude stays 
the same.
We can now determine the time evolution of any wave functions. 
In order to do that we will rely on the fact that the wave functions of 
stationary states form a complete basis in the Hilbert space; therefore, 
we can express any wave function as a linear combination of functions
(x(x, t) D «1^1(x) C «2^2(x) C «3(3(x) c-----. 
(13.1.7)
To obtain the i coefficients we use the fact that the stationary 
function are orthonormal, that is
y (i(x)*(j(x) dx D &i,, 
(13.1.8)
where i,j is the Kronecker delta. We arrive at
i i(i(x)((x)dx D ai. 
(13.1.9)
We can now determine the time evolution of any wave func­
tion (provided we know the stationary states of the hamiltonian) by 
decomposing the wave function into a linear combination of station­
ary functions 13.1.7 with the use of 13.1.9. Next, we complement each 
component with a time-dependent part due to 13.1.3 (notice that the 
above relations for stationary states are also fulfilled when we turn off 
the time-dependent part, and for t D 0 we get the stationary state basis)
((x, t) d a1(1(x)e~i"1 t C a2(2(x)e~i"2t C a3(3(x)e~i"3t C ::: .
(13.1.10)
In the numerical calculations we have to limit the number of sta­
tionary functions to those of the lowest energies. In order to determine 
ai we will use the numerical integration methods described in Project 2.
This method is simple and demonstrates the idea behind the reason 
for time evolution of wave functions. However, the task of determin­
ing the stationary states for a given potential, necessary to apply the 
method, is not simple. For that reason, we propose a different method 
which relies on direct discretisation of time-dependent Schrodinger 
equation (13.1.2), with the use of the three-point formulas for deriva­
tives. The wave function is discretised in space with a step ofhx and in 
time with a step of ht. Then, for x, t 2 Z we can write
(x,t d ((xhx,tht). 
(13.1.11)

13.1 Problem: Time Evolution of a Wave Function in 2D Quantum Well 83
We separate the Hamiltonian into kinetic and potential parts in the
Schrodinger equation
dP 
- , 
P2 , 
- , 
1 d2P 
, . ,
i^ d Hp d dpc + vp = _ 2 _JL + v(x)p,
(13.1.12)
and using the formulas for numerical derivative from Sec. .3 we get
Px, t + 1 — px, t -1 
2ht
i_ Px-1,t + Px +1,t - 2px,t
2 
h2r
- iV (x )Px, t. (13.1.13)
We can solve it for x,tC1, which leads us to
ht
Px,t+1 D Px,t-1 + _h2(Px-1,t + Px +1,t - 2px,t) - iV(x)Px,12ht.
x 
(13.1.14)
It is important to notice that h^ is present in that equation; therefore, 
in order to obtain sufficiently lowxorder, ht has to be at least three orders 
lower than hx .
In addition, a problem with boundary condition appears. We can 
assume that the values on the boundaries are equal to zero and do not 
change. This corresponds to a situation in which an infinite barrier is 
present at the boundary. Alternatively, we can use periodic boundary 
conditions if we assume that the next value of the wave function to the 
left of the left boundary is the first value of the wave function at the right 
boundary, and vice versa. By iterating the obtained formula we obtain 
the wave function at any given time. In order to ensure the simulation is 
free of numerical errors and physically correct, we can investigate the 
expected value of the energy
h Hl} = 
P *(x) HO P (x) dx = 
P *(x)
d2P 
, 
, z s
--TT + V (x)P (x)
dx,
which should be conserved.
Using this method we can demonstrate many phenomena in quan­
tum physics.
For sake of clarity, the plots show only 10% of the potential. We 
also use the concept of a wave packet, that is a wave function in the 
form
P(x) = Cekxe-(x-x0)2=2ff2, 
(13.1.15)
where Cis a normalisation constant which can be obtained for any func­
tion as an inverse of the integral of the function, in this case C = —^, 
2 
k is the expectation value of the momentum, x0 is the expectation value 
of the position, and is the standard deviation of the position.

84 Project 13: Time Dependent Schrodinger Equation
13.2 Exercises
Mandatory
1. Run the WAVE_BASE code, which decomposes a given wave func­
tion into stationary states of an infinite rectangular quantum well 
(Figure 13.1(a)), then run the WAVE code, which uses finite dif­
ferences, and compare the evolution of the wave functions for both 
approaches for different initial wave functions, in particular station­
ary states of an infinite square well, wave packet of momentum equal 
to zero (Figure 13.1(b)), and a wave packet of momentum not equal 
to zero (Figure 13.1(c)).
2. Run the WAVE code for a parabolic potential for a wave packet 
at equilibrium (Figure 13.2(a)) and a non-zero momentum (Fig­
ure 13.2(b)). Plot the expectation value of the position
hxOi D 
(x) x (x) dx D 
xj (x)j2 dx
as a function of time.
3. For a quantum harmonic oscillator, plot the expectation value of en­
ergy as a function of time. Check how the kinetic and potential parts 
R 
d2 
R
change, that is J_1 -^*(x)dx^ dx and J_1Vf*(x)V(x) Vz’(x) dx.
4. Investigate the phenomenon of quantum tunnelling (Figure 13.3). 
Check how much of the wave packet reflects off of the barrier, and
Figure 13.1 For a zero 
potential (placed in a wide 
infinite quantum well) the 
above scenarios can be 
considered (a) infinite 
quantum well results in a 
stationary probability 
distribution, (b) a zero 
momentum results in the 
wavefunction spreading, that 
is increasing the uncertainty 
of position, and (c) a 
non-zero momentum results 
in the wavefunction 
spreading an moving

13.2 Exercises 85
Figure 13.2 For a parabolic 
potential we obtain a 
quantum harmonic 
oscillator: (a) choosing a 
non-zero momentum and
2 D 0, the obtained state 
oscillates around the 
equilibrium position without 
changing its shape (sloshing 
modes), (b) setting 2 D 2 
and p D 0, we observe an 
alternating spreading and 
tightening of the state, 
without changing its position 
(breathing modes)
Figure 13.3 For a potential 
barrier we can observe 
quantum tunnelling. A wave 
packet after a collision with 
the barrier partially reflects 
and partially tunnels through 
it
how much tunnels through it, as a function of width and thickness 
of the barriers and the wave packet’s momentum.
Advanced
1. Modify the WAVE_BASE code so that using stationary functions 
for a parabolic potential it calculates the time evolution of any wave 
function for this potential.

Project 14
Poisson’s Equation in 2D
In the projects presented until now, the systems had high symmetry 
(cylindrical or spherical). Owing to this, even very complicated equa­
tions, such as the Laplace’s equation, could be greatly simplified. For 
example, in the problem described in Project 5, the symmetry was 
spherical, while in Project 8 we took advantage of cylindrical symme­
try to search for a quasi-1D potential. In this project we will search 
for a potential for a given distribution of charges in a two-dimensional 
system which does not have any symmetry. This is an extension of 
the project from Project 8. We also use the method of minimising a 
functional, in particular the Gauss-Seidel method of iterative minimisa­
tion. The Poisson’s equation will be adjusted to a two-dimensional case, 
which means neglecting one partial derivative in Cartesian coordinates. 
The resulting code will be capable of modelling typical electrostatic 
systems such as an electric dipole, systems of charges, parallel plates 
of a capacitor, or a Faraday’s cage. One should remember, however, 
that a point charge in this representation is in fact an infinite line of 
certain charge density, and a segment represents an infinite plate of 
width equal to the length of the segment. It is interesting to note that 
the interaction between such point charges has no 1=r2 character any­
more but 1=r. This should be kept in mind while analysing the results 
of the simulations.
14.1 Problem: Variational Computational
Approach to a 2D Electrostatic System
In this project we will analyse a two-dimensional system, for which
Poisson’s equation (8.1.1) takes the form
@2 
@2 \
@ x2 C @y 2)
x,y) d -4np(x,y),
(14.1.1)
86

14.2 Numerical Method: Finite Elements (FE) Method 87
which, together with the boundary conditions, leads to a boundary value 
problem (analogous to the one discussed in Project 5). The functional 
(8.1.2), written in two dimensions is
@Mx, y) V 
@ x C
F[] D
d2r
S
'1
2
@<Kx, y) V 
@y 
J
(14.1.2)
- 4np(xx, y )^(x, y)
The fundamental question of electrostatics can be summarised as 
What is the potential of the electric field for a given distribution of 
charges? It is worth spending some time on looking at some peculiar 
features of solutions to this problem. An important, non-trivial issue, 
known to those well versed in this field of physics, is the uniqueness of 
the results. This means that we would like to know whether Poisson’s 
equation is uniquely (unequivocally) given by the boundary conditions. 
If that was not the case, we could have a situation in which the func­
tional would have not one, but multiple global minima. This question 
has to be answered before we proceed with the discussion of the numeri­
cal approach to solving the problem, as this is of a deeper character than 
being just a numerical problem to solve, and is rooted in an analytical 
approach to searching for the solution for the field. We should expect 
that the uniqueness of the solution does not result from the method 
chosen to search for it, but from the fundamental laws that define it.
It should be clear that the determined potential is always unique. 
Otherwise we could suspect that the world, as any other system, exists 
in one of many metastable states in terms of the distribution of the elec­
trostatic field, and due to some hard to determine factors could switch 
between them, which obviously does not happen. The uniqueness theo­
rems prove that, in the form of two laws. Therefore, we expect that any 
initial conditions should always lead to the same solution, which the 
reader should verify as an exercise. Both these theorems are presented 
in depth in the Appendix (A.6).
14.2 Numerical Method: Finite Elements (FE)
Method
Similarly to previously discussed problems, we start by discretisation 
of the space we work in, which means we introduce a grid of points 
on which the calculations are performed. We use a rectangular grid, in

88 Project 14: Poisson’s Equation in 2D
which the grid parameters in the two directions may differ (hx , hy). As 
a result of discretisation the functional (14.1.2) takes the form
F[] D
hxhyX* 1 ii.
 iii.
 NX1 "
, (14.2.2)
which in a special case of a square grid (hX D hy 
h) simplifies to
0ij d 1 (h24npij C 0i-ij C ^iCij C ^ij-i C ^ijCi) . 
(14.2.3)
Detailed derivation of the above relations is presented in the 
Appendix (A.7. Interestingly, the above relations could have also been 
obtained in a slightly simpler way, by discretising the Poisson’s equation 
(5.i.2), or directly from an expression for an average potential (A.6.i) 
in two dimensions, which for (r) D 0 is just a regular arithmetic mean, 
^ij d 4(0i-ij C 0iCij C 0y-i C 0jCi). It is important to note that 
the boundary condition can be imposed not only on the boundaries but 
also inside the considered area through fixed values in chosen nodes 
of the grid. This way different electrostatic systems can be simulated 
(capacitors, Faraday cage, point charges).
To sum up, the algorithm does not fundamentally differ from that 
used for the cylindrical capacitor (a quasi one-dimensional system):
i. Start with some initial function 0ij (e.g. a surface 0(Xi, yj) D a, 
between 0(0, yj), 0(Xi, 0), 0(XNi, yj), 0(Xi, yNj)) (excluding cer­
tain points of previously set values).
ii. Calculate the new 0ij using Eq. i4.2.2 at each point on the 
grid Xi, yj, except the boundaries.
iii. For the new f0ijg, calculate the value of the functional F[0] 
(i4.2.i).
iv. Repeat the procedure until the value stabilises by reaching a 
F[0new] — F[0old] less than ".
iD2 jD2
(0ij - 0i-1j)2 
hX
, (0j - 0j -i)2 
h2
Ni-1 Nj-1
-hxhy Y2 12 4npij0j. 
iD2 jD2
(1.2.1)
After discretisation, the functional becomes a multi-variable func­
tion, F() ! F(ij), and the condition of zeroing of F reduces to 
a condition of zeroing of partial derivatives, @F=@ij D 0. Using that 
condition, we arrive at
hX hy4npy C hy(0 i-ij C 0 i+ij) C h2(^j -i C <pij+i)
2(hx2 C hy2)

14.3 Exercises 89
The procedure can be slightly modified by mixing the potentials ij
0j D 0new! C 0Ojld(1 - !), 
(14.2.4)
where injew is the new solution calculated with the use of the old value 
(14.2.2) 0o.ld.
However, the two-dimensional case introduces a new freedom in 
the choice of the sequence of actions in which the values are updated. 
We take the new values of from neighbouring nodes, and it may then 
turn out that the sequence of actions in which the values are updated 
(randomly, in rows, in columns, both at the same time), can influence 
the efficiency of calculations. As an exercise, the reader should check 
different possibilities.
14.3 Exercises
Test0ng of the Algor0thm
1. Analyse the 2POISSON code and test different boundary conditions 
and control parameters.
2. Investigate the effect of mixing the potentials. Find the range of the 
! parameter for which the algorithm converges and check when the 
convergence is achieved the fastest. Note that the convergence may 
be dependent on the distribution of charges.
3. Perform fully converged calculations for boundary conditions for 
which the analytical solution is known, and compare the results to 
this analytical solution.
4. Verify the uniqueness theorem. In order to do that determine the 
potential for a given charge distribution with given fixed boundary 
conditions for different initial conditions of the iterative procedure.
Appl0cat0on of the Model
5. Consider two, metal, infinite (in thez direction), grounded (potential 
equals zero) planes y D 0 and y D Ca of a given width l, con­
nected by a third plane x D 0, on which the potential V(y) is given 
(Figure 14.1) Find the potential between the planes for
(a) V(y) D V0
(b) V(y) D V0y
(c) V(y) D- V0y(y - a)
6. Consider two, metal, infinite (in the z direction) planes of width l at 
y D 0 iy D Ca with a constant potential CV, which are

90 Project 14: Poisson’s Equation in 2D
Figure 14.1 The model 
considered in this exercise - 
two connected planes
Figure 14.2 The model 
considered this exercise - 
two connected planes by 
two strips
Figure 14.3 The box 
proposed to study in this 
exercise
(a) isolated
(b) connected by two planes with a constant potential V0 (Fig­
ure 14.2):
i. 0 < V0 < V
ii. V < V0
iii. 0 < V0 < V on the first one V < V0 on the second 
one
7. Metal, grounded, rectangular cuboid box, covered by a lid insulated 
from the walls and uniformly charged with a potential V (Fig­
ure 14.3). Find the potential inside the box, around its centre (in 
the z direction).
8. Consider a model of a two-dimensional crystal of 10 10 positively 
charged ions of a metal (CQ), and alternating positive and negative 
ions (notice that it is actually a system of infinite linear charges). 
Investigate into the distribution of the potential in such a system.
9. Find the distribution of charges, which would result in a point of 
persistent equilibrium for a freely moving charged mass somewhere 

14.3 Exercises 91
between the points in which the charges reside. Is such a situation 
possible at all?
10. Design and simulate simple electrostatic systems such as an electric 
dipole, quadrupole, flat capacitor, Faraday’s cage. (As mention ear­
lier the code simulates quasi two-dimensional systems, therefore a 
single charge is represented here as an infinite linear charge.) As a 
boundary condition for the whole area of the simulation, a constant 
value has to be assumed, for example zero.

Appendix A
Supplementary Materials
A.1 Euler Representation of a Complex Number
A complex number z is an expression z D a C ib, where a, b are real 
numbers: a D Re(z) is the real part, b D Im(z) the imaginary part, and 
i d p(-1) is a unit of imaginary part. A complex number conjugate 
to z is z* d a - ib and modulus of a complex number jzj = p(zz*) = 
P(a2 C b2).
Using the above quantities we can represent a complex number in 
the form
ab
z = jzj( p - C i p =). 
(A.1.1)
P(a2 C b2) 
P(a2 C b2)
The fractions appearing in the above expression can be represented 
as cos and sin functions ofa right triangle, thus we can write
z = jzj(cos() C i sin()). 
(A.1.2)
This form suggests a useful graphical representation of a complex 
number, the so-called Argand diagram (Figure A.1). This is just a rec­
tangular coordinate system on a complex plane, in which we represent 
the real part on a horizontal axis, and imaginary part of the vertical 
axis. The point (vector) on a plane defined in this way represents a 
complex number, and its representation via the angle (between the 
horizontal axis and the position vector) and the length of the vector 
(jzj) are formally analogous to polar coordinates associated with the 
Cartesian coordinates on a plane.
Moreover, an interesting mathematical fact can be noted, which 
leads to Euler (exponential) representation of a complex number z = 
jzjei . Namely, it turns out that if we expand this exponential function 
into a power series then the series splits into a real part (for even pow­
ers of i) and an imaginary part (for odd powers of i). These two series 
appear to be power expansions of cos and sin functions of:
92

A.1 Euler Representation of a Complex Number 93
Figure A.1 Euler 
representation
e
(i)2 
(i)3 
(i)4 
(i)5 
(i)6 
(i)7
1 C i 0 C^- C C ■ 
■ 
■ C ■ ■ ■
C C 2 C 3! C 4! C 5! C 
6! C 7! C
1+„-1-i A00+i 05 - 
2 
3! C 4! C 5!
0 6
6!
e-+...
7! C
1-A04-A.. V i (e
2 C 4! 
6! C ) C A0 _03+05_£:+... 
3! C 5! 7! C
D cos C i sin .
Looking at Eq. A.1.2 we find out that a complex number can be 
represented in the Euler representation
z D jzjei . 
(A.1.3)
Such a form is very convenient in the physics of oscillations and 
waves, when used with the superposition principle. Additionally, there 
are methods for solving linear differential equations that utilise the 
Euler representation of a complex function as a trial solution.
Here, to show advantages of Euler representation we will derive 
well-known relations for cos and sin functions of a sum of angles.
On the one hand, we have
ei(C ) D cos( C ) C i sin( C ),
on the other hand,
ei(C) D ei ei D .cos() C i sin()/.cos() C i sin()/,
d (cos(a) cos(^) - sin(a) sin(^)/ C i (cos(a)sin(fi)
C sin() cos()/ .

94 Appendix: A Supplementary Materials
By comparing the real and imaginary parts we get the following 
relations
cos(a C ft) d cos(a) cos(fi) - sin(a) sin(/->), 
sin( C ) D cos() sin() C sin() cos().
A.2 Local Representation of a Function as a Power 
Series
A.2.1 Taylor Series and Polynomials
An infinitely differentiable function f (x) can be described as a following 
series (called the Taylor series)
f(x) D XX ' (x - x0)k
k!
kD0
D f (x0) C f'(xo)(x - x0) C f 2xo) (x - xo)2 C :::. 
(A.2.1)
Taylor polynomials of n-th degree can be constructed by truncating 
the Taylor series (Eq. A.2.1) at the n-th term (i.e. by replacing the 1 in 
the summation by n):
f(x) D Pn(x) C Rn(x), 
(A.2.2)
where Pn (x) is the n-th Taylor polynomial
n f(k) (x )
Pn(x) D E/ ((x - x0)k, 
(A.2.3)
k!
kD0
and Rn (x) is the remainder or the truncation error, which may be 
expressed as
*n(x) D f ((CC1)x)) (x - x0)nC1. 
(A.2.4)
The remainder term may be used to estimate the uncertainty of a 
method derived from Taylor polynomials.
A.2.2 Taylor Series in Two Variables
Although not used in this book, it is worth to know how the Taylor series 
in two variables looks like, which can be easily extended to three and

A.2 Local Representation of a Function as a Power Series 95
more variables. Itis based on the same notion: however, due to the intro­
duction of a second variable the terms become much more complex, and 
the general formula is
f(x,y) D
@ (kf (x 0, y 0) 
@ x(k -j)@y (j')
(x - x0)k j(yy - y0)
@f (x0, y0) 
@f (x0, y0)
D f (X0,y0) C (x - x0)— ----------C (y - y0)
C 
1 ky 
0 07 
i\
@x 
@y
■(x - x0)2 @2f (x0,y0) 
@ 
d2f (x0,y0)
C (x - x0)(y - y0)——-----
@ x@y
@f(x 0, y 0) 1 C : : : ,
@ x2
2 @ f (-X0,y0) 1 C ( y _ y 0)
2!
(y - y 0)
2! 
@y2
@y
C
(A.2.5)
where (k) is the binomial coefficient defined as
(A.2.6)
A.2.3 Lagrange Polynomials
An interesting alternative to Taylor expansion, of constructing polyno­
mials passing through a set of points, is the Lagrange polynomial. The 
general formula may be written as
n
L(x) D X BB yj 
jD0
n
x xk
x xXJ - xk
kD1
k6Dj
(x - x 1)(x - x 2) ::: (x ~ xn )
------------------------------------- y 0
(x 0 - x 1 )(x 0 - x 2) : : : (x 0 ~ x„^ )
(x - x 0)(x - x 2) :: : (x ~ xn)
C 7 v 7 y yy 1
(x 1 - x 0)(x 1 - x2) : : : (x 1 - x„^ )
(x - x 1)(x - x2) ::: (x ~ xn)
■ ■ ■ 
(x0 - x 1)(x0 - x2) : : : (x0 - xn)yn.
(A.2.7)
The derivation of Lagrange polynomials is fairly simple.
It is worth to mention that the Lagrange polynomial for a given set 
of points is unique and its uniqueness, although not explicitly shown in 
this text, can be proven and found in a number of textbooks.

96 Appendix: A Supplementary Materials
A.3 Wilberforce’s Pendulum
Lagrangian of Wilberforce’s pendulum has the form
L D 1 mz2 C 11P - 1 kz - 2302 - 1 ez0. 
(A.3.1)
We use Euler-Lagrange equation
d @LL\ dL 
dlt\ @i)~ @x D ,
(A.3.2)
to obtain equations of motiondi
— (mz/ C kz C^ e0 D 0,
(A.3.3)
di
d^t (IQ) C30 C 2ez D 0,
(A.3.4)
mZC kz C -e0 D 0,
(A.3.5)
i
I 0 C k0 C - e z.
(A.3.6)
A.4 Dispersion Relation for FPU Problem
To receive dispersion relation for an infinite chain of interacting masses 
(Project 10) we start with Newton’s equation for i-th mass 
@2yi
m~t^ D «(yiCi Cyi-i - 2yi), 
(A.4.1)
in which we introduce a solution in a waveform
yi D Aei(!t-kxi), 
(A.4.2)
This substitution leads to
- m!2yi D a(yiCi Cyi_i - 2yi). 
(A.4.3)
We want to determine !, so we note that
yC- D AegZt "'X-ix'1 D e~ik(xiCi"xi) D e~ika, 
(A.4.4)
where we use lattice constant a as a distance between two masses in 
equilibrium points.
We use this result when dividing the previous equation by yi
- m!2 D a(e~ika C eikl - 2) D a(2 cos(ka) - 2) D 2a[cos(ka) - i],
(A.4.5)

A.5 Equivalence of Variational Principle 97
which leads to the dispersion relation
2
'(k) = 1/ —[1 _ cos(ka)]. 
m
(A.4.6)
A.5 Equivalence of Variational Principle 
and Poisson’s Equation in Electrostatics
To prove the equivalence of the Poisson’s differential equation and the 
variational principle, let us consider the functional
F [] = 
d3
V
r 2(r0(r))2 - 4^p(r)^(r) .
(A.5.1)
and its change with respect to potential variation 
(r), which, accord­
ing to the variational principle, should be zero
3F = I d3r [V<£(r) -V3<£(r) - 4^p(r)3<£(r)]. 
(A.5.2)
V
Using the identity
r - (ab) = (ra) -bCa(r -b), 
(A.5.3)
in which we substitute a = 3(r) and b = r3(r), we obtain another 
identity
r - (3(r)r(r)) = r3(r) - r(r) C 3(r)r - (r(r)) 
= r3(r) - r(r) C 3(r)r2(r), 
which when substituted to the functional change leads to 
3F = y d3r hv - (30(r)V0(r)) — 3^(r)V20(r) — 4np(r)30(r)J
= y d3r [V - (30(r)V0(r))]^" d3r [3^(r) (v2^(r) C 4np(r)^] .
The first integral in the result can be evaluated using Gauss’s 
theorem
d3r(V -F) = 
d2r(F - n), 
(A.5.4)
where the left side is the volume integral and the right one is the surface 
integral over volume V boundary. Thus
d3r [V - (3(r)V(r))] = 
d2r [3(r)V(r)] -n.
Owing to the fact that over the surface S 3(r) is zero, the integral 
is equal to zero too.

98 Appendix: A Supplementary Materials
Finally, we get
5 F D_y d 3r |j50 (r) (r 20(r) C 4np (r))j .
The above equation proves the equivalence of the Poisson’s differ­
ential equation and the variational principle. Namely, if the differential 
equation is fulfiled, then the functional is stationary 5F D 0, and if the 
functional is stationary 5F D 0, then the Poisson’s equation must be 
fulfilled because 5(r) is non-zero everywhere except at the boundary.
A.6 First and Second Uniqueness Theory
The following theories allow to prove that solutions of Laplace’s 
(first u.t.) and Poisson’s (second u.t.) equations for given boundary 
conditions are uniquely determined.
A.6.1 First Uniqueness Theory
Let us consider a space in which certain boundary conditions for poten­
tial are given. From electrodynamics it is known that at every point the 
value of (r) is equal to average value of (r) over a spherical surface 
of radius R around this point (Figure A.2)
<£(r) D 4xR2 fsd2r[^(r)]. 
(A.6.1)
Notice that every possible potential cannot have extreme (maxi­
mum or minimum) inside considered space beyond the boundaries. 
Also, average value cannot be higher or lower than any of the values 
entering the averaging formula. Specially, if the boundary values are 
equal to zero, then the only possible solution is (r), equal to zero in 
whole space.
Figure A.2 Graphic 
representation equation 
(A.6.1) in two dimensions

A.6 First and Second Uniqueness Theory 99
Now consider any boundary conditions and suppose that there exist 
two solutions 1(r) and 2(r). Both must fulfill Laplace’s equation
r21(r) D 0,
r22(r) D 0.
The potential
<fc(r) = <£1(r) - <fe(r),
(A.6.2)
must fulfil Laplace’s equation too
r2<Mr) d rW) - ^2(r)) = r20i(r) - r202(r) = 0.
For points at boundary i(r) D 2(r), so 3(r) D 0, but as we 
have noticed previously, if the potential boundary value is zero, then 
the only possible result is 3(r), equal to zero for every point, which 
implies i(r) D 2(r) in the whole space.
A.6.2 Second Uniqueness Theory
Until now we were considering a space without charges inside; they 
were present only at the boundary and were accounted for via appro­
priate boundary conditions. Now, we additionally assume that there 
exists an arbitrary charge distribution (r) inside. Thus, we consider 
a finite electrostatic system, but this time we will start from Poisson’s 
law for the electric field strength E(r) - (the Gauss law, Figure A.3) in 
the forms: differential
r E(r) D 4(r), 
(A.6.3)
Figure A.3 Graphic 
representation of Gauss’s law

100 Appendix: A Supplementary Materials
and integral
ds E(r) D 4Q, 
(A.6.4)
where in the integrand there is a dot product of an oriented surface 
element and the electric field strength. The integral states that a total 
electric field flux through a closed surface is equal to the total charge 
enclosed in the surface. In its differential form we say that the charge is 
a source of the electric field.
The solution of the Poisson’s equation (A.6.3) can be divided into 
two components: a solution to the uniform equation, that is the Laplace 
one, together with the boundary conditions, and a particular solution 
dependent on the charge distribution, for which the only boundary con­
dition is the disappearing electric field at infinity. The general solution 
is a superposition of those two components E D Eo C Es .
Consider now the issue of uniqueness of the general solution. In 
the previous section, we proved that the contribution from Laplace’s 
equation (potential, thus also the field) is uniquely specified, it suffices 
then to prove that the particular solution Es is also unique. For this 
purpose we will use the integral form of the Gauss law.
Suppose there exist two different solutions E1s and Es2 for the same 
charge density distribution (r). For an arbitrary closed surface S within 
the considered space we have
ds Es1(S) D 4Q,
ds Es2(S) D 4Q.
By subtracting both sides of the above equations we get
d dS ■ (E1(S) - E2(S)) D 0. 
(A.6.5)
Since the above equality holds for an arbitrarily chosen surface 
inside the considered region, at any point
E1(r) D E2(r).
This means that the general solution to Poisson’s equation (A.6.3) 
is uniquely specified.
A.7 Discretisation of 2D Laplace’s Functional
To represent (14.1.2) after discretisation we replace differential opera­
tors with finite differences (using a three-point scheme). Note that not

A.7 Discretisation of 2D Laplace’s Functional 101
Figure A.4 The grid with 
marked selected areas
only the grid points are used but also the points halfway between them 
(Figure A.4).
/ @£ \ 
_ faj - fai -ij
\@ x/i C1/2j 
hx
/ @£ \ 
_ faj - faj -i
\dy C1C1/2 
hy
This allows us to represent the functional (14.1.2)
hxh 
F [fa ] d x
XX XX 
(faij ~ fai-1j')2 
(faij ~ faij-1)2 *
2 
2 
2 
2 
22
hx C hy) faij-(hy(fai-1j C faiC1j) C hx(faij-1 C faijC1)J D hxhy4^Pij.
hx 
hy
iD2 jD2
Ni-i Nj-1
- hxhy 12 12 4^'jfaij. 
iD2 jD2
The condition for the minimum
@ F 
@faij
leads to
hxhy 
2(faij 
fa i -1j) 
2(faij 
faij -1)
~L 
h2 
h2
2(fa i C1j 
faij )
hx
2(faij C1 
faij )
hy
- hxhy4npij D 0,
hy (faij 
fai-1j) C hx (faij 
faij-1) 
hy (faic1j 
faij) 
hx (faijc1 
faij)
D hx2 hy24pij,

102 Appendix: A Supplementary Materials
This is a starting equation for the Gauss-Seidel iterative minimisa­
tion procedure. Let us solve it for ij
hXhUnpj C hy(fri 1j C fri +1j) C hX(<faj i C frj +i) 
y y y 
y
frij D 
2(hX C h2) 
.
In the case hx D hy 
h it becomes simpler
frij D 4 hh24npij C fri-1j C friC1j C frj-1 C frjC1
A.8 Density of Star
Suppose the model mass density distribution inside a star is given by 
the formula
p(r) D M'e~Re . 
(A.8.1)
* r e
Let us derive the relations used in Project 5. First we calculate mass 
of the star
M D y %(r)d3r D f p(r)4^r2dr D 
^3 e R® 4^r2dr
D 4Me 1 e - 
■ dr D
R3 
0
3r D r' ! r D R .r
Re 
2
£- dr D dr' ! dr D R-drr-
Re 
2
4Me [1 -r- (Rer’\2 RQdrr
R e /o e \ 2 ) 
2
D M^J 
e -r' (r )2 dr'
f D (r-)2 f-D2r- 
g D - e ~r' g0 D e -r'
Me
2
D Me j e - rr' dr' D
fDr0 
f0D1
g D - e ~ r g' D e -r'
and the contractual radius of the star is
. 
2 / s 
4^3 
-T2®
%(r) D 4nr2p(r) D —— r2e R® , 
Re
%'(r) D 4M® [2re~Re c r2 (-— e~Re
R3e 
Re

A.8 Density of Star 103
8 M& 
_ Rr.
= —r— re R &
R 3
r \
1 _ R&),
8 Mo _2R / R \ 
~
—rere R& ^1 - — = = 0 ! R = R&.
Poisson’s equation is
d2'( r) 
dr2
M©
= —4n Gr—& e R& ,
* R e
(A.8.2)
and the exact solution to this problem is by integration by parts
d ‘(r) 
dr
4 GM& re - RRdr =
Rer0
2 e
2p = r ! r = gr
R & 
2
72- dr = dr' ! dr = R-g-
R & 
2
r0 R& dr0 
r
2
R 3
r0 e-r' dd
f = r0 
g = - e ~ 
GM& r
f ’ = 1 
g' = e -r'
-e r' dr
R e L J
GM& (-r'e-r'- e~r')
R e
GM' e - r( r'+ 1)C C, 
R &
[ GMq . , RQdr' 
GMq f _r
'(r) = 
& 'e r(r C 11 & 
- e (r C 1)dr
R& 
2 
2
f = r' C 1 f = 1 
g = - e ~ r g = e -r
= GM& [[■(r C 1)(e~r)] - / -e-r'dr
GM^ e-r(r C 2)Ccr C D
= GM& [-(r C 1)e-r' - e-r ] = - 2
= _ GM& e - ig (2L C 2^ C Cr C D
2 
\R & 
C
= - GM& e ~ R& (— C 1 ) C Cr C D, 
R&
from which $(r) = ‘/r follows immediately
<£(r) = -GMoe R& ( — C 1 | CC C D. 
\R & 
r J r
(A.8.3)
Moreover, we can see that our solution is not unequivocal. Owing to 
Poisson’s equation we should notice that if g(x) is solution, g(x)C CxCD 

104 Appendix: A Supplementary Materials
is solution too (g"(x) = f (x) ! (g(x) C CxCD)" = g(x)" + (CxCd)" = 
g(x)" = f (x)). To determine these constants we use the boundary values 
potential function.
Following the above solution,
0 M° e- RO 4. rdr =- 4^ f 0 e~ ^rdr
O . R 3 
R3 Joo
-2r = r' ! r = R r
R O 
2
dr = dr ! dr = R-dr-
R o 
2
0 e - r' R O r R O dr'
2
GMq [0 _r- 
,
------  I e r r dr =
R o 1
GMq
f = r'
g = - e ~ r
0 - e - r dr'
f0= 1 
g' = e -r'
[-r' e -r' .
R q
GMq _ r 0 _ GMq 
e
R o 
r q
Thus, for both boundary values
lim 0(r) = 0
r!1
C - ) C C C 
r
lim
r!1
_ 2 r / 1
-GMq e Rq —
\R O
D- = C = 0,
r g g GMq 
lim ®(r) =, 
r!(M' = R O ’
1
rq c
GMo e - R2O C
R O
GMq _ 2^ \ 
-----------e R q
lim — GM>e Rq 
r!0
1\ D'
r C r
= lim
r !0
GMq
= lim
r !0
R o
GM 
1
-Q^ c GMo 
r^GM^q
D
---------------e R q 
r \GMq
T GMq
C lim 
r!0
D -r
--------e R q
r 
\G1Oq
D _ 2r 
------------- e R q
2 r
r

A.9 Energy and Pressure of a Cubic Hydrogen Atom Lattice 105
This limit must be finite, thus to apply L’Hopital’s rule we must 
assume
D D D -2r_ \ 
lim I--------- e R0 
= 0,
r!0 GM
D
_ 1 = 0 ! D = GM0, 
GM0
then
- GM0 C GM lim I"1 11 - e R20
R0 
0 r!0 r
GM0 C GM lim 2 2 e R0
R0 
0 r!0VR0
GM:0 
2 GM.0 
GM.0
I 
.
R0 
R0 
R0
That shows that both constants fulfil our conditions. In conclusion, 
we are given exact solution for our problem:
r) = - GM0e R0 f -2 c 
c GM0 1,
R0 r R0 r
or
0(r) = GM0 "1 f1 - e~R0) - e~R0 .
R0 r
When we assume that G = M0 = R0 = 1, then
p(r) = — er ! ^(r) = - fl - er) - er. 
r
(A.8.4)
(A.8.5)
(A.8.6)
A.9 Energy and Pressure of a Cubic Hydrogen
Atom Lattice as a Function of Unit Cell Volume
Vcell(Bohr3)
Etotal (Hartree)
P(Hartree=Bohr3)
5.83
0.1350
-0.10400
8.00
-0.0312
-0.05700
10.60
-0.1460
-0.03280
13.80
-0.2260
-0.01960
17.60
-0.2840
-0.01210
22.00
-0.3260
-0.00761
27.00
-0.3570
-0.00490

106 Appendix: A Supplementary Materials
Vcell(Bohr3)
Etotal(Hartree)
P(Hartree=Bohr3)
32.80
-0.3800
-0.00320
39.30
-0.3970
-0.00212
46.70
-0.4100
-0.00142
54.90
-0.4190
-0.00096
64.00
-0.4260
-0.00065
74.10
-0.4320
-0.00044
85.20
-0.4360
-0.00030
97.30
-0.4390
-0.00020
111.00
-0.4410
-0.00014
125.00
-0.4430
-0.00009
141.00
-0.4440
-0.00006
157.00
-0.4450
-0.00004
176.00
-0.4450
-0.00003
195.00
-0.4460
-0.00002
216.00
-0.4460
-0.00001
238.00
-0.4460
0.00000
262.00
-0.4460
0.00000

Further Reading
There are many sources in literature and on the Internet which may 
serve as additional reading material, to extend and/or deepen the knowl­
edge of the subjects covered in this book. Some examples are given 
next.
Physics
l Freedman R. A. and Young H. D. (2019) University Physics with 
Modern Physics, 15th ed. Harlow: Pearson Education.
l Griffiths D. J. (2017) Introduction to Electrodynamics, 4th ed. Cam­
bridge: Cambridge University Press. https://doi.org/10.1017/978110 
8333511.
l Fermi E., Pasta J., Ulam S. and Tsingou M. (1955) Studies of 
non Linear Problems. Document LA-1940, Los Alamos National 
Laboratory, 978-988. https://doi.org/10.2172/4376203.
l Dauxois T. (2008) Fermi, Pasta, Ulam, and a Mysterious Lady, 
Physics Today 61, 55-57. https://doi.org/10.1063/1.2835154.
Numerical Methods
l Koonin S. E. (1998) Computational Physics: Fortran Version, 1st ed. 
CRC Press.
l Cheney W. and Kincaid D. (2008) Numerical Mathematics and 
Computing, 6th ed. Belmont: Brooks Cole.
l Gezerlis A. (2023) Numerical Methods in Physics with Python, 2nd 
ed. Cambridge: Cambridge University Press.
l Flannery B. P., Press W. H., Teukolsky S. A. and Vetterling W. T.
(2007) Numerical Recipes: The Art of Scientific Computing, 3rd ed. 
Cambridge: Cambridge University Press.
107

Index
1D simplex method, xviii
Adams-Bashforth scheme, 22
bisection, xvi
boundary value problem (BVP), 34
central force, 26
centrifugal force, 30
coherence, 8
complex amplitude, 10
conservative force, 27 
constructive interference, 8
coupled harmonic oscillators, 24
coupled oscillators, 58
cylindrical coordinates, 40
cylindrical waveguide, 40
damped oscillator, 24
density functional theory - DFT, 78
destructive interference, 8
differential equation, 21
diffraction, 7, 10
diffraction integral, 10
division of amplitude, 10
division of wavefront, 10
driven oscillator, 24
eigenenergy, 3
eigenfunction, 2
eigenvalue problem, 1, 42
eigenvalue problem (EVP), 40
energy conservation, 30, 32
equation of motion, 18
Euler representation of a complex
number, 92
Euler scheme for ordinary differential 
equation, 22
explicit schemes, 23
Fick’s law, 45
Finite Difference (FD) method, 47
finite elements method, 52, 54, 87
First Newton’s Law, 19
Gauss law, 35
Gauss-Seidel iteration, 55, 88
Gaussian elimination with back
substitution, 47
general relativity, 27
golden section search, xvii
gravitational force, 26
gravitational potential, 27
Hamiltonian, 29, 30
harmonic oscillation, 20
Hartree interaction, 78
Huygens’ principle, 10
implicit schemes, 23
initial value problem (IVP), 18
interference, 8
isochronism, 20
Kepler’s law of planetary motion, 30,
33
Lagrange polynomials, 95
Laplacian, 36
light intensity, 11
linear momentum conservation, 30, 32
Lissajous curves, 63
method of parabolas, xvii
minimum ofa function, xvi
molecular dynamics (MD), 26
Newton’s law of universal gravitation, 
26
Newton’s laws of motion, 18
Newton’s third law, 19, 27
Newton-Raphson, xvi
non-inertial reference frame, 30
non-linear interaction, 67
normal modes, 41, 66
108

Index 109
numerical derivatives, 11
numerical quadrature, 13
Numerow-Cowells algorithm, 37
optical fibre, 41
optical path, 8
partial differential equations (PDEs), 45
Poisson’s equation, 36, 79
predictor-corrector schemes, 23
principle of equivalence, 27
quantum mechanics, 1
quantum state, 1
quantum tunnelling, 85
rectangle method, 13
rectangular quantum well, 1
resonant coupling, 61
root of a function, xv
Runge-Kutta method, 22
Schrodinger equation, 2
secant method, xvi, xvii 
second Newton’s law, 19 
shooting method, 42 
simple pendulum, 19 
Simpson method, 13 
spherical coordinates, 36 
steady-state diffusion, 45 
superposition principle, 8, 27
Taylor series, 94
time-dependent Schrodinger equation, 
81
trapezoid method, 13
variational principle, 52, 53
Verlet algorithm, 31
wave, 8
wave equation, 40
wave function, 2
Wilberforce pendulum, 58, 63


