OPTICAL SCANNING HOLOGRAPHY       
WITH MATLAB® 

OPTICAL SCANNING HOLOGRAPHY
WITH MATLAB® 
TING-CHUNG POON 
Bradley Department of Electrical and Computer Engineering, Virginia Tech, 
Blacksburg,Virginia  24061. 

Dr. Ting-Chung Poon 
Virginia Tech 
Bradley Dept. Electrical and Computer Engineering 
Blacksburg, VA 24061 
USA 
tcpoon@vt.edu 
Library of Congress Control Number:  2007921127 
ISBN-10:  0-387-36826-4            e-ISBN-10:  0-387-36826-4 
ISBN-13:  978-0-387-36826-9     e-ISBN-13:  978-0-387-68851-0 
Printed on acid-free paper. 
© 2007 Springer Science+Business Media, LLC 
9  8  7  6  5  4  3  2  1
 
springer.com 
 
The use in this publication of trade names, trademarks, service marks and similar terms, even if they are 
not identified as such, is not to be taken as an expression of opinion as to whether or not they are subject 
to proprietary rights. 
permission of the publisher (Springer Science+Business Media, LLC, 233 Spring Street, New York, 
All rights reserved. This work may not be translated or copied in whole or in part without the written 
NY 10013, USA), except for brief excerpts in connection with reviews or scholarly analysis. Use in 
connection with any form of information storage and retrieval, electronic adaptation, computer software, 
or by similar or dissimilar methodology now know or hereafter developed is forbidden. 

Dedication 
This book is dedicated to 
Eliza (M.S., Iowa 1980), 
Christina (B.S., Cornell 2004), and 
Justine (B.S., Virginia Tech 2007). 

 
Contents 
Preface 
 
ix 
 
1 
1 
     1.2  Linear and Invariant Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .   
10 
            1.2.2  Convolution and Correlation Concept. . . . . . . . . . . . . . . . . . .   
14 
      
21 
21 
25 
             2.2.1  Plane Wave Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .      
25 
             2.2.2  Spherical Wave Solution . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
27 
29 
             2.3.1  Fresnel Diffraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
33 
      2.4  Ideal Lens, Imaging Systems, Pupil Functions   
 
 
40 
43 
45 
49 
49 
 
 
 
      2.3  Scalar Diffraction Theory . . . . . . . . . . . . . . . . . . . .  . . . . . . . . . . . .  
      2.2  Three-Dimensional Scalar Wave Equation . . . . . . . . . . . . . . . . . . . 
1.  Mathematical Background and Linear System. . . . . . . . . . . . . . . . . . . . . . . . . . .    
     1.1  Fourier Transformation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  . . . . . 
  
.  . . . . .
            1.2.1  Linearity and Invariance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  1  0 
. . . . . .
  . . . . . .
2.  Wave Optics and Holography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
  . . . . . .
 
  . . . . . .
 
     
  . . . . . .
 
      
  . . . . . .
 
       
  . . . . . .
       
 
             2.3.2  Diffraction of a Square Aperture. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36 
             2.5.3  Digital Holography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  60 
             2.5.2  Off-Axis Holography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  57 
             2.5.1  Fresnel Zone Plate as a Point-Source Hologram . . . . . . . . . . . . . . . .
      2.5  Holography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
             2.4.3  Incoherent Image Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
             2.4.2  Coherent Image Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
             2.4.1  Ideal Lens and Optical Fourier Transformation . . . . . . . . . . . . . . . . .
     and Transfer Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  .    .   . . . .  40 
      2.1  Maxwell’s Equations and Homogeneous Vector Wave Equation . . . . . . . .   

 
65 
72 
75  
81 
92 
       
97 
97 
 
141 
143 
       
 
 
149 
 
 
 
viii 
Optical Scanning Holography with MATLAB
       3.1  Principle of Optical Scanning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
3.  Optical Scanning Holography: Principles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  65 
       3.2  Optical Heterodyning. . . . . . . . . . . . . . . . .  . . . . . . . .  . . . . . . . . . . . . . . . .  69
       3.3  Acousto-Optic Frequency Shifting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
       3.4  Two-Pupil Optical Heterodyne Scanning Image Processor . . . . . . . . . . . . 
       3.5  Scanning Holography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
       3.6  Physical Intuition to Optical Scanning Holography . . . . . . . . . . . . . . . . . .  
4.  Optical Scanning Holography: Applications . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
      4.1  Scanning Holographic Microscopy . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
      4.3  Optical Scanning Cryptography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
      5.3  PSF Engineering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 
      5.2  Single-Beam Scanning vs. Double-Beam Scanning . . . . . . . . . . . . . . . . . . 
      5.1  Coherent and Incoherent Holographic Processing . . . . . . . . . .  . . . . . . . . .   135
5.  Optical Scanning Holography: Advances . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  135
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .  
      4.2  Three-Dimensional Holographic TV and 3-D Display . . . . . . . . . . . . . . . .    
106

 
Preface 
This book serves two purposes. The first is to succinctly cover the necessary 
mathematical background and wave optics that pertain to Fourier optics and 
holography. The second is to introduce optical scanning holography (OSH) - 
a form of electronic (or digital) holography - to the readers, and to provide 
them with experience in modeling the theory and applications utilizing 
MATLAB®.  
 
Optical Scanning Holography with MATLAB® consists of tutorials (with 
numerous MATLAB examples throughout the text), research material, as 
well as new ideas and insights that are useful for engineering or physics 
students, scientists, and engineers working in the fields of Fourier optics, 
optical scanning imaging and holography. The book is self-contained and 
covers the basic principles of OSH. Thus, this book will be relevant for years 
to come. The writing style of this book is geared towards undergraduate 
seniors or first-year graduate-level students in the fields of engineering and 
physics. The material covered in this book is suitable for a one-semester 
course in Fourier optics, optical scanning imaging and holography.  
 
Optical scanning holography is a highly sophisticated technology that 
consists of numerous facets and applications. It is a real-time (or on-the-fly) 
holographic recording technique that is based on active optical heterodyne 
scanning. It is a relatively new area in electronic holography and will 
potentially lead science and technology to many novel applications such as 
cryptography, 3-D display, scanning holographic microscopy, 3-D pattern 
recognition and 3-D optical remote sensing. The main purpose of this book 
is to introduce optical scanning holography to the readers in a manner that 
will allow them to feel comfortable enough to explore the technology on 

x
their own - possibly even encourage them to begin implementing their own 
set-ups in order to create novel OSH applications. Optical scanning 
holography is generally a simple yet powerful technique for 3-D imaging, 
and it is my aspiration that this book will stimulate further research of 
optical scanning holography and its various novel applications.          
 
I have incorporated some of the material from this book into my short course 
entitled Optical Scanning Holography  at SPIE Photonics West, in lectures 
given at the Institute of Optical Sciences (IOS), which is now known as the 
Department of Optics and Photonics, National Central University (NCU), 
Taiwan, and also at the Department of Electronics and Computer Science, 
Nihon University, Japan. The book was finally completed during my time as 
a visiting professor at Nihon University. I want to take this opportunity to 
thank my host, Professor Hiroshi Yoshikawa, for his hospitality and 
arranging a spacious office for me that allowed me to concentrate on the last 
phase of this book. I would also like to thank Professor Hon-Fai Yau of 
NCU for providing me with some early opportunities (when the book was 
still in its infancy) to “rehearse” my optical scanning holography lectures at 
IOS. 
 
I would like to thank my wife, Eliza, and my children, Christina and Justine, 
for their encouragement, patience, and love. This book is dedicated to them. 
In addition, I would also like to thank Christina Poon for reading the 
manuscript and providing comments and suggestions for improvement.  
 
“
”
Optical Scannning Holography with MATLAB

Chapter 1
Mathematical Background and
Linear Systems
1.1      Fourier Transformation
In electrical engineering, we are most concerned with a signal as a function
of time, 
. The signal in question could be a voltage or a current. The
0Ð>Ñ
forward temporal Fourier transform 
 
 
of
is given as
0Ð>Ñ
Y Ö0Ð>Ñ× œ JÐ Ñ œ
0Ð>Ñ
Ð 4 >Ñ .>
=
=
(
_
_
exp
 
,
(1.1-1a)
where the transform variables are time,  [second], and temporal radian
>
frequency,  [radian/second]. In Eq. (1.1a), 
 . The inverse Fourier
=
4 œ
"
È
transform is
Y "ÖJÐ Ñ× œ 0Ð>Ñ œ
JÐ Ñ
Ð4 >Ñ .
"
#
=
=
=
=
1(
_
_
exp
 
.
(1.1-1b)
In optics, we are most interested in dealing with a two-dimensional (2-D)
.
Hence, the two-dimensional spatial 
 of a signal 
 is
Fourier transform
0ÐBß CÑ
given as [Banerjee and Poon (1991), Poon and Banerjee (2001)]
YBCÖ0ÐBß CÑ× œ JÐ5 5 Ñ œ
0ÐBß CÑ
Ð45 B 45 CÑ .B.C
B
C
B
C
_
_
_
_
,
exp
 
,
(
(
(1.1-2a)
and the inverse Fourier transform is
           
,
 
YBC
"ÖJÐ5 5 Ñ×
B
C
          
     
œ 0ÐBß CÑ
        
,
exp
 
,
(1.1-2b)
œ
JÐ5 5 Ñ
Ð 45 B 45 CÑ .5 .5
"
%1#
_
_
_
_
B
C
B
C
B
C
(
(
where the transform variables are spatial variables, 
 [meter], and spatial
Bß C
radian frequencies, 
, 
 [radian/meter]. 
 and 
,
 are a Fourier
5
5
ÐBß CÑ
JÐ5 5 Ñ
B
C
B
C
0
signal. Examples include images or the transverse profile of an electro-
magnetic or optical field at some plane of spatial variables B
C
 and 

transform pair and the statement is symbolically represented by
                                      
,
0ÐBß CÑ Í JÐ5 5 ÑÞ
B
C
Note that the definitions for the forward and inverse transforms [see Eqs.
(1.1-2a) and (1.1-2b)] are consistent with the engineering convention for a
traveling wave, as explained in 
[Banerjee and
Principles of Applied Optics 
Poon (1991)]. Common properties and examples of 2-D Fourier transform
appear in the Table below.
Table 1.1 Properties and examples of some two-dimensional Fourier Transforms.

 Function in 
  
 
Fourier transform in (
)
ÐBß CÑ
5 ß 5
B
C
 . 
  
 
 
        
,
1 0ÐBß CÑ
JÐ5 5 Ñ
B
C
 . 
 
 
        
,
exp
2 0ÐB B ß C C Ñ
JÐ5 5 Ñ
Ð45 B 45 C Ñ
!
!
B
C
B
!
C
!
 
 complex constants 
       
,
3Þ 0Ð+Bß ,CÑà +ß ,
JÐ
Ñ
"
+,
5
+
,
5
¸
¸
B
C
 . 
 
 
 
       
,
4 0 ÐBß CÑ
J Ð 5
5 Ñ
‡
‡
B
C
 
/
 
 
 
      
,
5Þ `0ÐBß CÑ `B
45 JÐ5 5 Ñ
B
B
C
 . 
/
  
 
      
,
6 ` 0ÐBß CÑ `B`C
5 5 JÐ5 5 Ñ
#
B
C
B
C
 
. 
7 delta function
 
 $ÐBß CÑ œ
/
.5 .5
"
"
%
_
_
_
_
„45 B„45 C
B
C
1#
B
C
'
'
 . 1 
 
 
 
       
,
8
%
Ð5 5 Ñ
1 $
#
B
C
 
. 
 
 
9 rectangle function
sinc function
    rect
rect
rect
,  
sinc
sinc
sinc
,
ÐBß CÑ œ
ÐBÑ
ÐCÑ
Ð
ß
Ñ œ
Ð
Ñ
Ð
Ñ
5
5
#
#
#
#
5
5
B
B
C
C
1
1
1
1
    where rect
 
where sinc
ÐBÑ œ
ÐBÑ œ
Š
‹
"ß B "Î#
!ß
Ð BÑ
B
 
 
otherwise
sin
¸ ¸
1
1
 
. 
 
 
10 Gaussian function
Gaussian function
     exp
] 
 
   exp
Ò 
ÐB C Ñ
Ò 
Ó
!
#
#
5 5
%
1
!
!
B
C
#
#
 
Example 1.1 
Fourier Transform of rect
 plus MATLAB
 
ÐBß CÑ
The one-dimensional (1-D) rectangular function or simply 
,
rect function
rect
, is given by
ÐBÎ+Ñ
rect
(1.1-3a)
otherwise
ÐBÎ+Ñ œ
ß
"ß B +Î#
!ß
Œ

¸ ¸
where  is the width of the function. The function is shown in Fig. 1.1a). The
+
two-dimensional version of the rectangular function is given by
  rect
rect
rect
.
(1.1-3b)
ÐBÎ+ß CÎ,Ñ œ
ÐBÎ,Ñ
ÐCÎ,Ñ
Figure 1.1b) and 1.1c) show the three-dimensional plot and the gray scale
plot of the function. In the gray scale plot, we have assumed that an
amplitude of 1 translates to
white  and an amplitude of zero to
black
Therefore, from the definition of Eq. (1.1-3b), the white area is 
.
+ ‚ ,
2

“
”
“
”
Optical Scanning Holography with MATLAB

3
Fig. 1.1 Rect function.
To find the Fourier transform of the 2-D rectangular function, we simply
evaluate the integral given by Eq. (1.1-2a) by recognizing that 0ÐBß CÑ œ
rect
.  Therefore, we write
ÐBÎ+ß CÎ,Ñ
Y
Y
BC
BC
Ö0
Ö
ÐBß CÑ× œ
ÐBÎ+ß CÎ,Ñ×
rect
œ
ÐBÎ+ß CÎ,Ñ
Ð45 B 45 CÑ.B.C
(
(
_
_
_
_
B
C
rect
exp
. 
(1.1-4)
Since rect
 is a 
[see Eq. 1.1-3b)], we re-write
ÐBÎ+ß CÎ,Ñ
separable function 
Eq. (1.1-4) as follows:
YBCÖrectÐBÎ+ß CÎ,Ñ×
œ
ÐBÎ+Ñ
Ð45 BÑ.B ‚
ÐCÎ,Ñ
Ð45 CÑ.C
(
(
_
_
_
_
B
C
rect
exp
rect
exp
         
exp
exp
.
(1.1-5)
œ
"
Ð45 BÑ.B ‚
"
Ð45 CÑ.C
(
(
+Î#
,Î#
+Î#
,Î#
B
C
Mathematical Background and Linear Systems

4
By writing the last step, Eq. (1.1-5), we have used the definition of the
rectangular function given by Eq. (1.1-3a). We can now evaluate Eq. (1.1-5)
by using
                                       
exp
exp
.
(1.1-6)
(
Ð-BÑ.B œ
Ð-BÑ
"
-
Therefore,
                                  
exp
sinc
,
(1.1-7)
(
+Î#
+Î#
B
B
"
Ð45 BÑ.B œ +
Ð
Ñ
+5
#1
where
is defined as the 
. Table 1.2 shows the
sincÐBÑ œ sinÐ BÑ
1
1B
sinc function
m-file for plotting the sinc function and its output is shown in Fig. 1.2. Note
that the sinc function has zeros at 
...
B œ „ "ß „ #ß „ $ß
Table 1.2 Plot_sinc.m: m-file for plotting the sinc function.
-----------------------------------------------------
%Plot_sinc.m   Plotting of sinc(x) function
x= -5.5:0.01:5.5;
sinc=sin(pi*x)./(pi*x);
plot(x,sinc)
axis([-5.5 5.5 -0.3 1.1])
grid on
xlabel('x')
ylabel('sinc (x)')
------------------------------------------------------
Fig. 1.2 Sinc function.
To complete the original problem of determining the Fourier transform of a
rect function, we take advantage of the result of Eq. (1.1-7); Eq. (1.1-5)
−5
−4
−3
−2
−1
0
1
2
3
4
5
−0.2
0
0.2
0.4
0.6
0.8
1
x
sinc (x)
Optical Scanning Holography with MATLAB

5
becomes
   
rect
sinc
sinc
YBCÖ
ÐBÎ+ß CÎ,Ñ× œ +,
Ð
Ñ
Ð
Ñ
+5
#
#
,5
B
C
1
1
œ +,
Ð
ß
Ñ
+5
#
#
,5
 
sinc
.
(1.1-8a)
B
C
1
1
Hence, we may write
                    rect
sinc
.
(1.1-8b)
ÐBÎ+ß CÎ,Ñ Í +,
Ð
ß
Ñ
+5
#
#
,5
B
C
1
1
Note that when the width of the rect function along  is , the first zero along
B
+
5
5
œ # Î+Þ
B
Bß!
 is 
 Figure 1.3 shows the transform pair of Eq. (1.1-8b). The
1
top figures are 2-D gray-scale plots, and the bottom figures are line traces
along the horizontal axis through the center of the top figures. These figures
are generated using the m-file shown in Table 1.3 where M
11. For this
œ
value of M, 
 units of length and the first zero 
+ œ !Þ!%#*
5
œ "%'Þ#$
Bß!
radian/ unit of length . Note that the area of display in the -  plane has been
Ð
Ñ
B C
scaled to 1 unit of length by 1 unit of length.
Fig. 1.3 Rect function and its Fourier transform.
Table 1.3 fft2Drect.m: m-file for 2-D Fourier transform of rect
.
 
ÐBÎ+ß CÎ,Ñ
------------------------------------------------------
%fft2Drect.m %Simulation of Fourier transformation of a 2-D rect function
%
clear
Mathematical Background and Linear Systems

6
L=1; %display area is L by L, L has unit of length
N=256; % number of sampling points
dx=L/(N-1); % dx : step size
% Create square image, M by M square, rect(x/a,y/a), M=odd number
M=input ('M (size of rect(x/a,y/a), enter odd numbers from 3-33)=');
a=M/256;
kx0=2*pi/a;
sprintf('a = %0.5g[unit of length]',a)
sprintf('kx0 (first zero)= %0.5g[radian/unit of length]',kx0)
R=zeros(256); %assign a matrix (256x256) of zeros
r=ones(M); % assign a matrix (MxM) of ones
n=(M-1)/2;
R(128-n:128+n,128-n:128+n)=r;
%End of creating square input image M by M
%Axis Scaling
for k=1:256
   X(k)=1/255*(k-1)-L/2;
   Y(k)=1/255*(k-1)-L/2;
     %Kx=(2*pi*k)/((N-1)*dx)
   %in our case, N=256, dx=1/255
   Kx(k)=(2*pi*(k-1))/((N-1)*dx)-((2*pi*(256-1))/((N-1)*dx))/2;
   Ky(k)=(2*pi*(k-1))/((N-1)*dx)-((2*pi*(256-1))/((N-1)*dx))/2;
end
%Image of the rect function
figure(1)
image(X+dx/2,Y+dx/2,255*R);
title('rect function: gray-scale plot')
xlabel('x')
ylabel('y')
colormap(gray(256));
axis square
%Computing Fourier transform
FR=(1/256)^2*fft2(R);
FR=fftshift(FR);
% plot of cross-section of rect function
figure(2)
plot(X+dx/2,R(:,127))
title('rect function: cross-section plot')
xlabel('x')
ylabel('rect(x/a)')
grid
axis([-0.5 0.5 -0.1 1.2])
%Centering the axis and plot of cross-section of transform along kx
figure(3)
plot(Kx-pi/(dx*(N-1)),10*abs(FR(:,127)))
title('Square-absolute value of Fourier transform of rect function: cross-section plot')
xlabel('kx')
ylabel('|a*b*sinc(a*kx/2pi)|')
Optical Scanning Holography with MATLAB

7
axis([-800 800 0 max(max(abs(FR)))*10.1])
grid
%Mesh the Fourier transformation
figure(4);
mesh(Kx,Ky,(abs(FR)).^2)
title('Square-absolute value of Fourier transform of rect function: 3-D plot,scale
arbitrary')
xlabel('kx')
ylabel('ky')
axis square
%Image of the Fourier transformation of rectangular function
figure(5);
gain=10000;
image(Kx,Ky,gain*(abs(FR)).^2/max(max(abs(FR))).^2)
title('Square-absolute value of Fourier transform of the rect function: gray-scale plot')
xlabel('kx')
ylabel('ky')
axis square
colormap(gray(256))
------------------------------------------------------
Example 1.2 
MATLAB Example:
Fourier Transform of Bitmap Images
When the 2-D function or image is given with a bitmap file, we can use the
m-file given in Table 1.4 to find its Fourier transform. Figure 1.4a) is the
bitmap image used when the image file of the size is 256 by 256. It is easily
generated with Microsoft® Paint. Figure 1.4b) is the corresponding absolute
value of the transformed image.
Table 1.4 fft2Dbitmap_image.m: m-file for 2-D Fourier transform of  bitmap image.
------------------------------------------------------
%fft2Dbitmap_image.m
%Simulation of Fourier transformation of bitmap images
clear
I=imread('triangle.bmp','bmp'); %Input bitmap image
I=I(:,:,1);
figure(1)  %displaying input
colormap(gray(255));
image(I)
axis off
FI=fft2(I);
FI=fftshift(FI);
max1=max(FI);
max2=max(max1);
scale=1.0/max2;
FI=FI.*scale;
figure(2) %Gray scale image of the absolute value of transform  
Mathematical Background and Linear Systems

8
colormap(gray(255));
image(10*(abs(256*FI)));
axis off
------------------------------------------------------
 
Fig. 1.4 Bitmap image and its transform generated using the m-file in Table 1.4.
Example 1.3 
Delta Function and its Transform
The 
, 
, is one of the most important functions in the study
delta function $ÐBÑ
of systems. We can define the delta function as follows:
$ÐBÑ œ
Ö
Ð
Ñ×
"
B
+
+
lim
+Ä!
rect
.
(1.1-9)
The situation is shown graphically in Fig. 1.5.
   Fig. 1.5 Illustration of the definition of the delta function graphically.
The delta function has three important properties, which are listed as follows:
Property #1: Unit Area
(
_
_
!
$ÐB B Ñ.B œ ".
(1.1-10a)
Optical Scanning Holography with MATLAB

9
The delta function has a unit area (or strength), which is denoted by a (1)
beside the arrow, as shown in Fig. 1.5.  This unit area property is clearly
demonstrated by the definition illustrated on the left hand side of Fig. 1.5.
The area is always a unity regardless of the value of .+
Property #2: Product Property
0ÐBÑ ÐB B Ñ œ 0ÐB Ñ ÐB B Ñ
$
$
!
!
! .
(1.1-10b)
The result of this property can be confirmed graphically by the illustration
shown in Fig. 1.6 where an arbitrary function,
, is shown to be
0ÐBÑ
overlapped with the offset delta function, 
, located at 
.  The
$ÐB B Ñ
B œ B
!
!
product of the two functions is clearly equal to 
 multiplied by
0ÐB Ñ
!
$ÐB B ÑÞ
!
 Therefore, the result has become an offset delta function with its
strength given by
.
0ÐB Ñ
!
Fig. 1.6 Illustrating the result of the Product Property.
Property #3: Sampling Property
                             
.
(1.1-10c)
(
_
_
!
!
0ÐBÑ ÐB B Ñ.B œ 0ÐB Ñ
$
To obtain the result above, we simply use Properties #1 and #2. From Eq.
(1.1-10c) and by using Property #2, we have
(
(
_
_
_
_
!
!
!
0ÐBÑ ÐB B Ñ.B œ
0ÐB Ñ ÐB B Ñ.B
$
$
                               
,
œ 0ÐB Ñ
ÐB B Ñ.B œ 0ÐB Ñ
!
!
!
_
_
(
$
“
”
Mathematical Background and Linear Systems

10
where we have used Property #1 to obtain the last step of the result. Equation
(1.1-10c) is known as the 
 because the delta function
sampling property
selects, or samples, a particular value of the function, 
, at the location of
0ÐBÑ
the delta function (i.e., 
) in the integration process.
B!
 
While a 1-D delta function is called an impulse function in electrical
YBCÖ$
$
ÐBß CÑ× œ
ÐBß CÑ
Ð45 B 45 CÑ .B.C
(
(
_
_
_
_
B
C
exp
 
      
exp
exp
œ
ÐBÑ
Ð45 BÑ.B
ÐCÑ
Ð45 CÑ.C
(
(
_
_
_
_
B
C
$
$
 
 
   
,
œ "
where we have used the sampling property of the delta function to evaluate
the above integrals. Figure 1.7 shows the 2-D delta function as well as its
corresponding Fourier transform.
Fig. 1.7 Two-dimensional delta function and its Fourier transform.
1.2      Linear and Invariant Systems
1.2.1 
Linearity and Invariance  
A system is defined as the mapping of an input or set of inputs into an output
or set of outputs. A system is linear if 
 applies. For a single-
superposition
input
single-output system, if an input 
 gives an output of 

0 Ð>Ñ
"
1 Ð>Ñ
"
, and if
another input 
, then superposition means if the
0 Ð>Ñ
#
 gives an output of 1 Ð>Ñ
#
input is given by +
+1
0 Ð>Ñ ,0 Ð>Ñ
Ð>Ñ ,1 Ð>Ñß
"
#
"
#
, the system s output is 
where   and  are some constants. The situation of a 
 is further
+
,
linear system
illustrated in Fig. 1.8.
sents an idealized point source of light in optics. According to Eq. (1.1-2a),
the 2-D Fourier transform of $ÐBß CÑ is given by
’
Optical Scanning Holography with MATLAB
engineering, the 2-D version of a delta function, $ÐBß CÑ œ $ÐBÑ$ÐCÑ, repre-

11
Figure 1.8 Linear system.
Systems with parameters that do not change with time are time-invariant
systems. Consequently, a time delay in the input results in a corresponding
time delay in the output. This property of the system is shown graphically in
Fig. 1.9, where  is the time delay.
>!
Fig. 1.9 Time-invariant system.
As it turns out, if a system is linear and time-invariant (LTI) with all initial
conditions being zero, there is a definite relationship between the input and
output. The relationship is given by the so-called convolution integral,
1Ð>Ñ œ
0Ð> Ñ2Ð> > Ñ.> œ 0Ð>Ñ‡2Ð>Ñ
(
_
_
w
w
w
,
(1.2-1)
where  
 is called the 
of the LTI system, and
is a
2Ð>Ñ
‡
impulse response 
symbol denoting the convolution of  
 and  
. The expression 
 reads
0Ð>Ñ
2Ð>Ñ
0‡1
as 
convolves with . To see why 
 is called the impulse response, if we
0
1
2Ð>Ñ
let the input be a delta function, 
, then the output, according to Eq. (1.2-
$Ð>Ñ
1), is
1Ð>Ñ œ Ð>Ñ‡2Ð>Ñ œ
Ð> Ñ2Ð> > Ñ.> œ 2Ð>Ñ
$
$
(
_
_
w
w
w
,
Mathematical Background and Linear Systems

12
where we use the sampling property of the delta function to obtain the last
step of the result. Once we know 
 of the LTI system, which can be
2Ð>Ñ
determined experimentally by simply applying an impulse to the input of the
system, we can find the response to any arbitrary input, say, 
to the
0Ð>Ñß
system through the calculation of Eq. (1.2-1).
Fig. 1.10 Concept of space-invariance.
 
In optics, when we are dealing with signals of spatial coordinates, we
can extend the concept of LTI systems to the so-called linear space-invariant
(LSI) system. Hence we can extend the 1-D convolution integral to two
dimensions as follows:
 1ÐBß CÑ œ
0ÐB ß C Ñ2ÐB B ß C C Ñ.B .C
(
(
_
_
_
_
w
w
w
w
w
w
 
,
 
(1.2-2)
œ 0ÐBß CÑ‡2ÐBß CÑ
where 
 is the 2-D input to the LSI system. 
and 
 are the
0ÐBß CÑ
2ÐBß CÑ
1ÐBß CÑ
corresponding impulse response and output of the system, respectively.
While the concept of time-invariance is clearly delineated by Fig. 1.9 for
electrical signals, the concept of space-invariance for optical signals is not
immediately clear. In Fig. 1.10, we can clarify this concept. We see that as
the input image, 
, is shifted or translated to a new origin,
, 
, its
0ÐBß CÑ
ÐB
C Ñ
!
!
output, 
, is shifted accordingly on the -  plane. Hence, we see that
1ÐBß CÑ
B C
the delay of an input signal in electrical systems corresponds to the
translation of an output image over the output plane.
 
Figure 1.11 shows the block diagrams of a LSI optical system both in
spatial and frequency domain. To analyze the LSI system in frequency
domain, we simply take the Fourier transform of Eq. (1.2-2) to obtain
 
,
(1.2-3a)
Y
Y
BC
BC
Ö
Ö
1ÐBß CÑ × œ
0ÐBß CÑ‡2ÐBß CÑ×
Optical Scanning Holography with MATLAB

13
which is shown to be
KÐ5 5 Ñ œ JÐ5 5 ÑLÐ5 5 Ñ
B
C
B
C
B
C
,
,
,
,
(1.2-3b)
where 
,
and 
,
are the Fourier transform of 
and
KÐ5 5 Ñ
LÐ5 5 Ñ
1ÐBß CÑ
B
C
B
C
2ÐBß CÑ
2ÐBß CÑ
, respectively. While 
 is called the 
 or
spatial impulse response
point spread function (PSF) of the LSI system, its Fourier transform,
LÐ5 5 Ñ
B
C
,
, is called the 
 or the system s
spatial frequency response
frequency
transfer function. The proof of Eq. (1.2-3b) is demonstrated in Example 1.4.
Fig. 1.11 Block diagrams of LSI system.
Example 1.4 
Fourier Transform of the Convolution
of Two Functions
From Eq. (1.2-3a), we have
Y
Y
BC
BC
Ö
Ö
1ÐBß CÑ × œ
0ÐBß CÑ‡2ÐBß CÑ×
œ
Ò0ÐBß CÑ‡2ÐBß CÑÓ
Ð45 B 45 CÑ .B.C
(
(
_
_
_
_
B
C
exp
 
’
Mathematical Background and Linear Systems

14
œ
0ÐB ß C Ñ2ÐB B ß C C Ñ.B .C
(
(
(
(
’
“
_
_
_
_
_
_
_
_
w
w
w
w
w
w
                     
exp
 
,
‚
Ð45 B 45 CÑ .B.C
B
C
where we have utilized the definition of convolution. After grouping the B
and  variables together, the above equation can be written as
C
YBCÖ
×
0ÐBß CÑ‡2ÐBß CÑ
œ
0ÐB ß C Ñ
(
(
_
_
_
_
w
w
‚
2ÐB B ß C C Ñ
Ð45 B 45 CÑ.B.C .B .C
’
“
(
(
_
_
_
_
w
w
w
w
B
C
exp
.
The inner integral is the Fourier transform of 
. Using Table
2ÐB B ß C C Ñ
w
w
1.1 (item #2), the transform is given by 
,
exp
. Hence
LÐ5 5 Ñ
Ð45 B 45 C Ñ
B
C
B
C
w
w
YBCÖ0ÐBß CÑ‡2ÐBß CÑ×
œ
0ÐB ß C Ñ LÐ5 5 Ñ
Ð45 B 45 C Ñ .B .C
(
(
’
“
_
_
_
_
w
w
w
w
w
w
B
C
B
C
,
exp
œ LÐ5 5 Ñ
0ÐB ß C Ñ
Ð45 B 45 C Ñ.B .C
B
C
B
C
_
_
_
_
w
w
w
w
w
w
,
exp
(
(
œ JÐ5 5 ÑLÐ5 5 Ñ
B
C
B
C
,
,
.
1.2.2 
Convolution and Correlation Concept
In the last section, we have demonstrated that in the LSI system, the
convolution integral is involved. In this section we will first explain the
 
In Fig. 1.12, we illustrate the convolution of two images, 
 and
0ÐBß CÑ
2ÐBß CÑ. According to the definition in Eq. (1.2-2), the convolution of the two
images involves the calculation of the area under the product of two
functions, 
 and 
, for different shifts, 
.
0ÐB ß C Ñ
2ÐB B ß C C Ñ
ÐBß CÑ
w
w
w
w
concept of convolution, and then, we will discuss another important opera-
tion called correlation. Finally we will make distinction between the two
processes.
Optical Scanning Holography with MATLAB

15
Fig. 1.12 Concept of 2-D convolution.
Fig. 1.13 Concept of 2-D correlation (assuming  is real).
0
Mathematical Background and Linear Systems
 
g(x, y)
g(x, y)
f(x, y) h(x, y)  f(x9, y9) h(x9, y9)h( 2 x9, y9) h( 2 x9, 2 y9)
f(x9, y9)h(x 2 x9, y 2 y9)dx9dy9
h(x 2 x9, y 2 y9)
=
∫
∫
`
2`
`
2`
x9
x9
y9
y
x
y9
centered
at (x, y)

16
The first row of figures in Fig. 1.12 shows the construction of 
 and
0ÐB ß C Ñ
w
w
2Ð B ß C Ñ
0ÐBß CÑ
2ÐBß CÑ
w
w  from the original images 
 and 
. We then
construct 
 as shown in Fig. 1.12 by translating
2ÐB B ß C C Ñ
w
w
2Ð B ß C Ñ
ÐBß CÑ
2ÐB B ß C C Ñ
w
w
w
w
 to a center at 
 to form 
. Once we have
0ÐB ß C Ñ
2ÐB B ß C C Ñ
B C
w
w
w
w
w
w
 and 
, we superimpose them on the 
-
plane as
illustrated in Fig. 1.12. Finally, we need to calculate the area of the product
of 
 and 
 for different shifts
 to obtain a 2-D
0ÐB ß C Ñ
2ÐB B ß C C Ñ
ÐBß CÑ
w
w
w
w
gray-scale plot of 
.
1ÐBß CÑ
    
Another important integral is called the 
 
. 
correlation integral The
correlation, 
, of two functions 
 and 
, is defined as
G
ÐBß CÑ
0ÐBß CÑ
2ÐBß CÑ
02
G
ÐBß CÑ œ
0 ÐB ß C Ñ2ÐB B ß C C Ñ.B .C
02
_
_
_
_
‡
w
w
w
w
w
w
(
(
                     
.
(1.2-4)
œ 0ÐBß CÑ Œ 2ÐBß CÑ
This integral is useful when comparing the similarity of two functions, and it
has been knowingly used for applications in pattern recognition. For
simplicity, if we assume in Fig. 1.13 that 
is real,
0ÐBß CÑ
 we can illustrate the
correlation of the two images, 
 and 
. Similar to the convolution
0ÐBß CÑ
2ÐBß CÑ
of the two images, the correlation involves the calculation of the area under
the product of two functions, 
 and 
, for different
0ÐB ß C Ñ
2ÐB B ß C C Ñ
w
w
w
w
shifts, 
. The first row of images in Fig. 1.13 shows the construction of
ÐBß CÑ
0ÐB ß C Ñ
2ÐB ß C Ñ
0ÐBß CÑ
2ÐBß CÑ
w
w
w
w
 and 
 from the original images, 
 and 
. Unlike
convolution, to calculate he area of the product of 
 and
0ÐB ß C Ñ
w
w
2ÐB B ß C C Ñ
ÐBß CÑ
w
w  for different shifts ,
, there is no need to flip the image,
2ÐB ß C Ñ
B
C
w
w
w
w
, upon the 
- axis and the -axis to obtain the 2-D plot of 
.
G
ÐBß CÑ
02
Example 1.5 
Relationship between Convolution and Correlation
In this example, we will show that correlation can be expressed in terms of
convolution through the following relationship:
0ÐBß CÑ Œ 2ÐBß CÑ œ 0 Ð Bß CÑ‡2ÐBß CÑ
‡
.
(1.2-5)
According to the definition of convolution [see Eq. (1.2-2)], we write
                  0 Ð Bß CÑ‡2ÐBß CÑ
‡
œ
0 Ð B ß C Ñ2ÐB B ß C C Ñ.B .C
(
(
_
_
_
_
‡
w
w
w
w
w
w
Optical Scanning Holography with MATLAB

17
œ
0 ÐB Bß C CÑ2ÐB ß C ÑÐ .B ÑÐ .C Ñ
(
(
_
_
_
_
‡
ww
ww
ww
ww
ww
ww ,
where we have made the substitutions 
 and 
 to obtain
B B œ B
C C œ C
w
ww
w
ww
the last step of the equation. By re-arranging the last step and substituting the
equivalents for 
 and 
, we obtain  
B B œ B
C C œ C
ww
ww
μ
μ
                         0 Ð Bß CÑ‡2ÐBß CÑ
‡
œ
0 ÐBß CÑ2ÐB Bß C CÑ.B.C
(
(
_
_
_
_
‡ μ μ
μ
μ
μ
μ,
    œ 0ÐBß CÑ Œ 2ÐBß CÑ
by the definition of correlation. Therefore, we have proven Eq. (1.2-5).
With reference to Eq. (1.2-4), when 
, the result is known as 
0 Á 2
cross-
correlation
auto-correlation
, 
When 
, the result is known as 
, 
G
G
02
00
Þ
0 œ 2
,
of the function 
 As it turns out, we can show that
0Þ
                                    l
l
G
Ð!ß !Ñl   G
ÐBß CÑl
00
00
,
(1.2-6)
i.e., autocorrelation always has a central maximum. The use of this fact has
been employed by pattern recognition. Pioneering schemes of optical pattern
recognition, implementing Eq. (1.2-5), are due to Vander Lugt [1964], and
Weaver and Goodman [1966]. The book, 
,
Optical Pattern Recognition
provides a comprehensive review of optical pattern recognition, covering
theoretical aspects and details of some practical implementations [Yu and
Jutamulia (1998)]. For some of the most novel approaches to optical pattern
recognition, the reader is encouraged to refer to the article by Poon and Qi
[2003].
Example 1.6 
MATLAB Example: Pattern Recognition
For pattern recognition applications, one implements correlation given by Eq.
(1.2-4). In this example, we implement the equation in the frequency domain.
To do this, we realize that
 
      YBCÖ0ÐBß CÑ Œ 2ÐBß CÑ× œ J Ð5 5 ÑLÐ5 5 Ñ
‡
B
C
B
C
,
,
,
(1.2-7)
which can be shown using the procedure similar to Example 1.4.  For the
given images 
and 
, we first find their corresponding 2-D Fourier
0
2
Mathematical Background and Linear Systems

18
transforms, and then the correlation is evident when we take the inverse
transform of Eq. (1.2-7):
0ÐBß CÑ Œ 2ÐBß CÑ œ
J Ð5 5 ÑLÐ5 5 Ñ×
YBC
"Ö
‡
B
C
B
C
,
,
.
(1.2-8)
Figure 1.14 shows the result of auto-correlation for two identical images,
while Fig. 1.15 shows the cross-correlation result for two different images.
These figures are generated using the m-file shown in Table 1.5. Two 256 by
256 smiley.bmp files have been used for the auto-correlation calculation.
Note that in auto-correlation, shown in Fig. 1.14, a bright spot in the center
of the correlation output represents the
match  of the two patterns, as
suggested by Eq. (1.2-6), whereas in Fig. 1.15, there is no discernible bright
spot in the center.
Fig. 1.14 Auto-correlation.
Fig. 1.15 Cross-correlation.
Table 1.5 correlation.m: m-file for performing 2-D correlation.
------------------------------------------------------
%correlation.m
clear
I1=imread('smiley.bmp','bmp'); %Input image 1 (reference image)
I1=I1(:,:,1);
figure(1)  %displaying input image 1
colormap(gray(255));
image(I1)
axis off
FI1=fft2(I1);
max1=max(FI1);
max2=max(max1);
scale=1.0/max2;
FI1=FI1.*scale;
I2=imread('smiley.bmp','bmp'); %Input image 2 (image to be recognized)
“
”
Optical Scanning Holography with MATLAB

19
I2=I2(:,:,1);
figure(2)  %displaying input image 2
colormap(gray(255));
image(I2)
axis off
FI2=fft2(I2);
max1=max(FI2);
max2=max(max1);
scale=1.0/max2;
FI2=FI2.*scale;
FPR=FI1.*conj(FI2);%calculating correlation
PR=ifft2(FPR);
PR=fftshift(PR);
max1=max(PR);
max2=max(max1);
scale=1.0/max2;
PR=PR.*scale;
figure(3)%display of correlation in spatial domain 
colormap(gray(255));
image(abs(256*PR));
axis off
------------------------------------------------------
References
1.1 
Banerjee, P.P. and T.-C. Poon (1991). 
 Irwin, Illinois.
Principles of Applied Optics.
1.2 
Poon T.-C. and P. P. Banerjee (2001). Contemporary Optical Image Processing
with MATLAB . 
® Elsevier, Oxford, UK.
1.3 
Poon, T.-C. and Y. Qi (2003). Novel real-time joint-transform correlation by use of
acousto-optic heterodyning,
,  42, 4663-4669.
Applied Optics
1.4 
VanderLugt, A. (1964).
Signal detection by complex spatial filter, IEEE Trans.
Inf. Theory IT-10, 139–146.
1.5 
Weaver, C.S. and J. W. Goodman (1969). A technique for optical convolving two
functions,
, 5, 1248-1249.
Applied Optics
1.6  
Yu, F.T.S. and S. Jutamulia, ed. (1998). 
 Cambridge
Optical Pattern Recognition.
University Press, Cambridge, UK.
“
”
“
”
“
”
Mathematical Background and Linear Systems

Chapter 2
Wave Optics and Holography
In Chapter 1, we presented some mathematical background of Fourier optics
as well as some important systems properties including linearity and space
invariance. In this chapter, we present some fundamentals of wave optics by
starting from Maxwell s equations and deriving the vector wave equation. We
response in Fourier optics. In the context of diffraction, we will also develop
wavefront transformation by using a lens, show the Fourier transforming
properties of the lens, and discuss how spatial filtering is obtained by using a
standard two-lens system, leading to the distinction between coherent and
incoherent image processing. In the last section of this chapter, we will
discuss the basics of holography and show that a Fresnel zone plate is the
hologram of a point source object, leading to the concept that the hologram
of an arbitrary 3-D object can be considered as a collection of Fresnel zone
plates. Finally, we will discuss electronic holography (often called digital
holography in literature). This will culminate with the next chapter, which we
will discuss a unique holographic recording technique called optical scanning
holography.
2.1 Maxwell s Equations and Homogenous Vector Wave Equation
Generally, in the study of optics, we are concerned with four vector
quantities called electromagnetic (EM) fields: the electric field strength X
(V/m), the electric flux density 
 (C/m ), the magnetic field strength 
W
#
[
(A/m), and the magnetic flux density 
 (Wb/m ). The fundamental theory of
U
#
electromagnetic fields is based on Maxwell s Equations. In differential form,
these equations are expressed as
 
 
 
f †
œ
W
3@ ,
(2.1-1)
 
 
 
f †
œ !
U
 ,
(2.1-2)
we will develop diffraction theory by using the Fresnel diffraction for-
will then discuss some simple solutions of the scalar wave equation. Next, 
mula, which is uniquely derived by using Fourier transforms. In the process, 
we will define the spatial frequency transfer function and the spatial impulse
’
’
’

f ‚ X œ 

U
t  ,
(2.1-3)
               
 
 ,
(2.1-4)
f ‚ [ œ
œ

]
]
W
-

t
where 
 is the current density [A/m ] and 
denotes the electric charge
]
3
-
#
@ 
density [C/m ]. 
 and 
are the sources generating the electromagnetic
3
]
3
-
@ 
fields. Maxwell s equations express the physical laws governing the electric
fields
magnetic fields
sources
 
,
and the 
 
 and
. From
X
[
U
 
 
and 
 
and 
, 
W
]
3
 
 
 
-
@
Eqs. (2.1-3) and (2.1-4), we see that a time-varying magnetic field produces a
time-varying electric field. Conversely, a time-varying electric field produces
a time-varying magnetic field. It is precisely this coupling between the
electric and magnetic fields that generate electromagnetic waves capable of
propagating through a medium or even in free space.
For any given current and charge density distribution, we can solve
Maxwell s equations. However, we need to note that Eq. (2.1-1) is not
independent of Eq. (2.1-4). Similarly, Eq. (2.1-2) is a consequence of Eq.
(2.1-3). By taking the divergence on both sides of Eqs. (2.1-3) and (2.1-4)
and using the continuity equation:
f †
œ
]
3
- + 

@
t
0,
(2.1-5)
which is the 
 we can show that
principle of conservation of charge,
f † W œ 3@. Similarly, Eq. (2.1-2) is a consequence of Eq. (2.1-3). Hence,
 
 
from Eqs. (2.1-1) to (2.1-4), we really have six independent scalar equations
(three scalar equations for each curl equation) and twelve unknowns. The
unknowns are the 
and components of , 
, 
, and 
. The six more
Bß Cß
D
X
[
U
W
scalar equations required are provided by the 
:
constitutive relations
 
 
 
            
,
(2.1-6a)
W
X
œ %
and
 
 
 
           U
[
œ .
,
(2.1-6b)
where denotes the permittivity [F/m] and 
denotes the permeability [H/m]
%
.
 
 
 
of the medium. In this book, we take  and  to be scalar constants. Indeed,
%
.
this is true for a 
, 
, and 
 medium. A medium is
linear homogeneous
isotropic
linear if its properties do not depend on the amplitude of the fields in the
medium. It is 
 if its properties are not functions of space. And
homogeneous
the medium is 
 if its properties are the same in all direction from any
isotropic
given point.
 
Returning our focus to linear, homogeneous, and isotropic media,
constants worth remembering are the values of  and  for free space (or
%
.
vacuum): 
(1/36 )
10
F/m and 
4
10
H/m.
%
1
.
1
!
!
*

œ
‚
œ
‚
7
22
    
’
’
Optical Scanning Holography with MATLAB

23
 
Using Maxwell s equations and the constitutive relations, we can
derive the wave equation, which describes the propagation of the electric and
magnetic fields. Example 2.1 shows the derivation of the wave equation for
X.
Example 2.1 
Derivation of Vector Wave Equation
in a Linear, Homogenous, and Isotropic Medium
By taking the curl of both sides of Eq. (2.1-3), we have
   
 
 
f
f
f
‚
‚
œ 
‚
X


U
t  
     
( 
)
( 
),
(2.1-7)
œ 
œ 




.
t
t
f
f
‚
‚
U
[
 
 
where we have used the second of the constitutive relations [Eq. (2.1-6b)]
and assumed  to be space- and time-independent. Now, by employing Eq.
.
(2.1-4), Eq. (2.1-7) becomes
f
f
 
 
‚
‚
œ 

X
.%
.




#
-
X
]
t
t
#
,
(2.1-8)
where we have used the first of the constitutive relations [Eq. (2.1-6a)] and
assumed  to be time-independent. Then, by using the following vector
%
identity (
 is some arbitrary vector)
T
f
f
f f †
f
f œ f † f
‚
‚
œ

T
T
(
) 
,   
 
,
(2.1-9)
A
#
#
in Eq. (2.1-8), we get
f

f f †
#X
X
.%



.
#
-
X
]
t
t
# œ
 + 
(
).
 (2.1-10)
If we also assume the permittivity, , to be space-independent, then we can
%
now recast the first of Maxwell s equations [Eq. (2.1-1)] in the form of
f † X œ 3@
% ,
(2.1-11)
by using the first of the constitutive relations [Eq. (2.1-6a)]. Incorporating
Eq. (2.1-11) into Eq. (2.1-10), we can finally obtain
f

f
#X
.%



%
.
#
-
X
]
3
t
t
# œ
"
@,
(2.1-12)
’
’
Wave Optics and Holography

24
which is a 
 having source terms on the right-hand side.
vector wave equation
This is the wave equation for 
in 
X 
a linear, homogeneous, and isotropic
medium characterized by .
%
 and .
For the given 
 and 
in a localized region 
 and , say,
]
3
-
@ 
characterized by .
%
 we can solve for the electric field, , in the region according to Eq. (2.1-
X  
12). Once the generated field reaches the source-free region V 
0,
(]- œ
3@ œ 0), the field must then satisfy the homogenous vector wave equation,
f

#X
.%

#X
t# œ !.
(2.1-13)
The situation is delineated in Fig. 2.1. Note that the quantity, 
, has the unit
.%
value of (1/velocity) . We call this velocity 
#
@ and define it as
@# œ "
.%.
(2.1-14)
For free space, 
, 
, and 
.  We can calculate the value of 
.
.
%
%
œ
œ
!
!
@ œ c
c
from the values of 
 and 
. This works out to be about 3
10  m/s. This
%
.
!
!
‚
8
theoretical value, which was first calculated by Maxwell, was in remarkable
agreement with Fizeau s previously measured speed of light (315,300 km/s).
Fig. 2.1 Vector wave equations in a linear, homogeneous, and isotropic medium.
’
This led Maxwell to the conclusion that light is an electromagnetic distur-
bance in the form of waves propagated through the electromagnetic field
based on electromagnetic laws.
V',
Optical Scanning Holography with MATLAB

25
2.2 Three-Dimensional Scalar Wave Equation
Equation (2.1-13) is equivalent to three scalar equations - one for every
component of . 
 to be of the form
X
X
We shall let the field
                           
  
 X œ X
X
X
B B
C
C
D
D
a
a
a  
 + 
,
(2.2-1)

where a
a
a
B
C
D
, 
, and 
 denote the unit vectors in the , , and  directions,
B C
D
respectively. Now, the expression for the Laplacian (
) operator in
f#
Cartesian (
) coordinates is given by
Bß Cß D
f# œ 





#
#
#
B
C
#
#
#
 + 
 + 
.
D
(2.2-2)
Using the above equation, Equation (2.1-13) becomes
Ð
Ð
Ñ






#
#
#
B
C
D
#
#
#
 + 
 + 
Ñ

X
X
X
B B
C
C
D
D
a
a
a
 + 
œ
Ð
Ñ
.%
X
X
X


#
t#
B B
C
C
D
D
a
a
a
 + 
.
(2.2-3)

Comparing the 
-component on both sides of the equation, we have
aB








#
#
#
#
X
X
X
X
.%
B
B
B
B
B
C
D
#
#
#
#
 + 
 + 
œ
t
.
Similarly, we end up with the same type of equation shown above for the XC
and 
 component by comparing the other components in Eq. (2.2-3).
XD
Therefore, we can write
f#< œ "
@#
#


<
t#  
(2.2-4)
,
where  may represent a component, 
, 
 or 
, of the electric field , and
<
X
X
X
B
C
D
X  
Equation (2.2-4) is called the 
 We shall look at
3-D scalar wave equation.
some of its simplest solutions in the next section.
2.2.1 Plane Wave Solution
For waves oscillating at the 
 
, 
 (rad/s), one of the
angular frequency =!
simplest solutions to Eq. (2.2-4) is
                 
, , ,  
 exp
<
=
Ð
Ò4Ð

B C D
Ñt
t
œ
5
!
! † VÑÓ
Wave Optics and Holography
where @ is the velocity of the wave in the medium by using Eq. (2.1-14).

26
   
 
 
exp
,
(2.2-5)
œ
Ò4Ð



=!
!B
!C
!D
t
k
k
k
B
C
DÑÓ
where 
 + 
 + 
 is the position vector, 
V œ B
C
D
a
a
a
a
a
B
C
D
B
C
5!
!B
!C
œ k
 
k
 
+ 
+
k
propagation vector
k
propagation
!D
!
!
aD is the 
, and |
|
 is called the 
5
œ
constant [rad/m]. With the condition that
=
=
2
2
2
2
2
2
!
!
!B
!C
!D
!
#
k
k
k
k
+  
+  
,
(2.2-6)
œ
œ @
Eq. (2.2-5) is called a plane-wave solution and the wave is called a plane
wave of unit amplitude. Figure 2.2 shows the direction of propagation of the
plane wave, which is determined from the three components 
, 
, and
k
k
!B
!C
k!D.
Fig. 2.2 Plane wave propagating along the 5! direction.
 
Since the electromagnetic fields are real functions of space and time,
we can define, for example, the electric field by taking the real part of  to
<
obtain a real quantity,
                Re
( , , , ) 
cos
(2.2-7)
Ò
Ó œ
Ð



<
=
B C D
B
C
DÑ
t
t
k
k
k
.
!
!B
!C
!D
Let us now consider a plane wave propagating along the -direction. In one
D
spatial dimension, i.e., <ÐDß >Ñ, the wave equation [Eq. (2.2-4)] reads
                                           
  
(2.2-8)
1
<
<


#
#
D
@
>
#
#
œ
2
and its plane wave solution then becomes
      
,
(2.2-9)
<
=
=
)
( , )
exp
exp
exp
D
DÑÓ œ
ÑÓ
t
t
k
t
œ
Ò4Ð

Ò4Ð
Ò 4 ÐDÑÓ
!
!
!
where
is called the 
 of the wave with 
indicating
)ÐDÑ œ k
 
phase
 
!D œ
D
#
!
1
-!
-
the wavelength of the wave. Let us take the origin of the coordinates as a
Optical Scanning Holography with MATLAB

27
zero-phase position, i.e., 
In fact, over the whole plane 
,
)Ð
D œ !
D œ !Ñ œ !. 
the phase is zero. At 
, we have  
So for every
D œ
D œ
Ñ œ
œ #
-
-
-
1
!
!
!
#
 
. 
)Ð
1
-!
distance of propagation of a wavelength, the phase of the wave gains #1.
D
 Fig. 2.3 Plane wave propagating along the -direction exhibiting planar wavefronts.
D
2.2.2 Spherical Wave Solution
Consider now the spherical coordinates shown in Fig. 2.4.
Fig. 2.4 Spherical coordinate system.
The expression for the Laplacian (
) operator is
f#
      
 
(2.2-10)
f# œ




) 


) 


#
#
#
#
#
R
R R
R
R
R
#
#
#
#
#
 + 
 + 
 + 
 + 
.
2
cot
sin
"
"
9
)
)
One of the 
spherical symmetry
simplest cases is called 
, which requires that
<
) 9
<
9
)
Ð
>Ñ
Ð
R
R t
, , , 
,
. Therefore, for spherical symmetry ( /
 = 0 = /
),
œ
Ñ
the wave equation, Eq. (2.2-4), combined with Eq. (2.2-10) assumes the form
                                 
  + 
.
(2.2-11)
2
1
Œ

<
<
<



2
2
2
2
2
R
R R
t
œ @
-direction. The situation is demonstrated in Fig. 2.3.
Therefore, we have what is known as the planar wavefronts along the 
Wave Optics and Holography

28
Since
R
R
R R
R
R
Œ

<
<

<



2
2
2
2
  + 
,
2
œ
Ð
Ñ
we can re-write Eq. (2.2-11) to become

<

<


2
2
2
2
2
Ð
Ñ
Ð
Ñ
œ
R
R
R
t
1
.
(2.2-12)
@
Now, the above equation is of the same form as that of Eq. (2.2-8). Since Eq.
(2.2-9) is the solution to Eq. (2.2-8), we can therefore construct a simple
solution to Eq. (2.2-12) as
<
=
Ð
œ
Ò4Ð

R t
t
k R
,
exp
 ,
(2.2-13)
Ñ
ÑÓ
"
V
!
!
which is called a 
Again, we can write
spherical wave. 
<
=
=
)
( , )
exp
exp
exp
,
R t
t
k R
t
R
œ
Ò4Ð

œ
Ð4
Ò 4 Ð ÑÓ
"
"
V
V
ÑÓ
Ñ
!
!
!
where
 We then take the origin of the coordinates as a
)Ð Ñ œ
R
k R
R.
!
œ #1
-!
zero-phase position, i.e., 
and 
So, for
)
)
Ð
Ð
R
 
R
. 
œ !Ñ œ !
œ
Ñ œ
œ #
-
-
1
!
!
#1
-!
every distance of propagation of a wavelength, the phase of the wave gains
#1. 
spherical wavefronts
We, therefore, have the so-called 
 moving along the
R-direction. The situation is shown in Fig. 2.5.
  Fig. 2.5 Spherical wavefronts.
 
While we have previously seen that plane waves and spherical waves
are some of the simplest solutions of the 3-D scalar wave equation, we can
effectively generate these useful waves in the laboratory. The situation is
Optical Scanning Holography with MATLAB

29
shown in Fig. 2.6, where the distance between the two lenses are separated
by the sum of their focal lengths, 
, and we have assumed that the rays
0 0
"
#
emitting from the laser are parallel, i.e., the wave fronts are planar. Note that
the parallel rays emerging from the lens of focal length 
 have a separation
0#
of an expansion factor, 
, larger than the separation of the rays
Q œ 0 Î0
#
"
originally emerging from the laser.
 Fig. 2.6 Practical implementation of spherical waves and plane waves.
2.3 Scalar Diffraction Theory
Figure 2.7 shows a simple example of diffraction geometry where a plane
wave oscillating at 
is incident on an 
 or a 
,
=!
aperture
diffracting screen
located on the plane 
The problem is to determine the diffracted field
D œ !Þ
distribution after the aperture. To tackle the problem, we will need to solve
the 3-D scalar wave equation, which is subject to an initial condition. Let us
now formulate the problem mathematically.
 
Since a plane wave of amplitude  propagating along the -direction
E
D
is given by <
=
Ð
œ E
Ò4Ð

D
Ñ
DÑÓ
, 
exp
with the wave s zero-phase position
t
t
k
 
!
!
defined at 
, we can then model the field immediately in front of the
D œ !
aperture as 
,
exp
. The field immediately after the
<
=
Ð
œ E
Ð4
D œ ! Ñ
Ñ
t
t
!
aperture is then given by 
, 
exp
<
<
=
ÐBß Cß
œ
ÐBß Cà
Ð4
D œ !
Ñ
D œ !Ñ
Ñ
t
t .
:
!
<:ÐBß Cà D œ !Ñ is called the 
 under consideration. For
initial condition
example, if the aperture has a rectangular opening of width 
 by 
, we can
B
C
!
!
then write 
rect
.
<:
!
!
ÐBß Cà
œ E
ÐBÎB ß CÎC Ñ
D œ !Ñ
’
Wave Optics and Holography

30
 
It is necessary to find the field distribution at , and to do so, we can
D
model the solution as
<
<
=
ÐBß Cß
œ
ÐBß Cà
Ð4
D Ñ
DÑ
Ñ
,
exp
,
(2.3-1)
t
t
:
!
where 
is the unknown to be found. In optics, 
is called
<
<
:
:
ÐBß Cà
ÐBß Cà
DÑ
DÑ
 
a 
 and we see that it is riding on a 
of
complex amplitude 
carrier 
<:ÐBß Cß DÑ
frequency 
 (
 is known as a
 in electrical engineering).
=
<
!
:
 phasor
 
Since the light field must satisfy the wave equation, we therefore
substitute this into the 3-D scalar wave equation [Eq. (2.2-4)] to find
<
<
:
:
ÐBß Cà
ÐBß Cà
DÑ
D œ !Ñ
 under the given initial condition, 
.
 Fig. 2.7 Diffraction geometry.
After substituting Eq. (2.3-1) into Eq. (2.2-4), we get the Helmholtz equation
for <:,
             
 
, 
 






#
#
#
#
!
!
<
<
<
=
<
:
:
:
!
:
B
C
D
@
5
5 œ
#
#
#
 + 
 + 
 + 
.
(2.3-2)
œ !
By taking the 2-D Fourier transform, i.e., 
, of Eq. (2.3-2) and after further
YBC
manipulations, we obtain
.
5
.D
5 Ð" 

Ñ
5
5
5
#
#
#
!
B
#
#
!
!
#
C
G
G
:
:
#
 
(2.3-3)
œ !,
where 
(
 is the Fourier transform of 
. We can now
G
<
:
B
C
:
5 ß 5 à DÑ
ÐBß Cà DÑ
readily solve the above equation to get
G
G
:
B
C
:
B
C
(
 exp
5 ß 5 à DÑ œ
Ð5 ß 5 Ñ
4
0

5
" 5 Î5
5 Î5 D
!
#
#
B
C
#
#
!
!
É
‘,   
(2.3-4)
where 
0
G
G
:
B
C
:
B
C
0Ð5 ß 5 Ñ œ
Ð5 ß 5 à D œ Ñ
 
 
   
.
œ
ÐBß Cà D œ !Ñ× œ
ÐBß CÑ×
Y
Y
BC
BC
Ö
Ö
<
<
:
:!
Optical Scanning Holography with MATLAB

31
We can interpret Eq. (2.3-4) by considering a linear system with 
(
G:
B
C
0 5 ß 5 Ñ
as its input spectrum (i.e., at 
) and where the output spectrum is
D œ !
G:
B
C
Ð5 ß 5 à DÑ. Conclusively, the spatial frequency response of the system is
G
G
[
:
B
C
:
B
C
B
C
Ð5 ß 5 à DÑ
Ð5 ß 5 Ñ
œ
Ð5 ß 5 à DÑ
0
 
    
 exp
 
œ
4

5
" 5 Î5
5 Î5 D
!
#
#
B
C
#
#
!
!
É
‘  .
(2.3-5)
We call 
 the 
 
[ Ð5 ß 5 à DÑ
B
C
spatial frequency transfer function of propagation
of light through a distance 
 in the medium. Figure 2.8 shows the
D
relationship between the input spectrum and the output spectrum.
 Fig. 2.8 Spatial frequency transfer function of propagation
relating input spectrum to output spectrum.
Example 2.2 
Derivation of the Helmholtz Equation
When we substitute 
 into the 3-D scalar
<
<
=
ÐBß Cß
œ
ÐBß Cà
Ð4
D Ñ
DÑ
Ñ
,
exp
t
t
:
!
wave equation given by Eq. (2.2-4), we have
Ò
Ó
œ Ð4
@



=



=
<
=
#
#
#
#
!
:
!
!
#
<
<
<
:
:
:
B
C
D
Ð4
ÐBß Cà
Ð4
Ñ
#
#
#
 + 
 + 
exp
exp
 
t
t
Ñ
DÑ
Ñ
or
              Ò
Ó œ
œ 

@



=



<
<
#
#
#
#
!
#
:
:
#
!
<
<
<
:
:
:
B
C
D
ÐBß Cà
5
#
#
#
 + 
 + 
DÑ
which is the Helmholtz equation [Eq. (2.3-2)], where we have incorporated
the fact that 
.  Note that the Helmholtz equation contains no time
5 œ
@
!
=!/
variable.
Example 2.3 
Derivation of Eq. (2.3-3) and its Solution
By taking the 2-D Fourier transform, i.e., 
, of Eq. (2.3-2) and by using
YBC
item #5 of Table 1.1, we can obtain
Wave Optics and Holography
given by 

32
Y






BC
#
#
#
#
!
Ö
5
B
C
D
<
<
<
<
:
:
:
:
#
#
#
 + 
 + 
 + 
 
× œ !
or
Ð5 5 Ñ
Ð5 ß 5 à DÑ 
Ð5 ß 5 à DÑ œ !
Ð5 ß 5 à DÑ
#
#
B
C
:
B
C
:
B
C
:
B
C
G
G
G
.
.D
5
#
#
!
 
, 
#
which can then be re-arranged to become
.
5
.D
5 Ð" 

Ñ
5
5
5
#
#
#
!
B
#
#
!
!
#
C
G
G
:
:
#
 
œ !.
(2.3-6)
This equation is of the form
.
.D

C
#
#
C
œ !
#
!
,
which has the solution 
exp
 where 
 is given
CÐDÑ œ C
Ð 4 DÑ
C œ CÐD œ !Ñ
!
!
!
as the initial condition. Using this result, the solution to Eq. (2.3-6) becomes
G
G
:
B
C
B
C
Ð5 ß 5 à DÑ œ
Ð5 ß 5 à D œ !Ñ
4
exp
5
" 5 Î5
5 Î5 D
!
#
#
B
C
#
#
!
!
É
‘
 
exp
œ
Ð5 ß 5 Ñ
4
G:
B
C
0

5
" 5 Î5
5 Î5 D
!
#
#
B
C
#
#
!
!
É
‘,
(2.3-7)
which is Eq. (2.3-4).
To find the field distribution at  in the spatial domain, we take the inverse
D
Fourier transform of Eq. (2.3-7):
  
 
 
<
G
:
:
B
C
ÐBß Cà DÑ œ
Ð5 ß 5 à DÑ
Y "
BC š
›
œ
5
" 5 Î5
5 Î5 DÓ
"
%
Ð5 ß 5 Ñ
4
1
G
#
:
B
C
( (
0
exp
!
B
C
#
#
#
#
!
!
É
 
 
exp
 .
(2.3-8)
‚
Ð 45 B 45 CÑ .5 .5
B
C
B
C
 
 
 
 
 
 
 
 
 
Now, by substituting 
 
we can
G
<
:
B
C
:!
0(
 =
 into Eq. (2.3-8), 
5 ß 5 Ñ
ÐBß CÑ
YBCš
›
Optical Scanning Holography with MATLAB

33
express 
 as
<:ÐBß Cà DÑ
<
<
:
:!
w
w
w
w
w
w
ÐBß Cà DÑ œ
ÐB ß C ÑKÐB B ß C C à DÑ .B .C
 
 ( (
 
 
 
,
(2.3-9)
œ
ÐBß CÑ ‡ KÐBß Cà DÑ
<:!
where
KÐBß Cà DÑ œ
4
"
%1#( ( exp
5
" 5 Î5
5 Î5 D
!
B
C
#
#
#
#
!
!
É
‘
‚
Ð 45 B 45 CÑ .5 .5
exp
 .
B
C
B
C
The result of  Eq. (2.3-9) indicates that 
 can be considered as the
KÐBß Cà DÑ
spatial impulse response of propagation
 
 of light, which can be evaluated to
become [Poon and Banerjee (2001)]
KÐBß Cà DÑ œ 45
Ð 4
Ñ
!exp
 
2
5
B C D
B C D
!
#
#
#
#
#
#
È
È
1
‚
B C D
B C D
D
"
Ð" 
Ñ
45
È
È
#
#
#
#
#
#
!
.
(2.3-10)
2.3.1 Fresnel Diffraction
Equation (2.3-10) is complicated to use as is, and we shall need to make the
following approximations to obtain the well-known Fresnel diffraction
formula commonly used in Fourier optics:
(1) For 
i.e., we observe the field distribution many
D ¦
œ # Î5 ß
-
1
!
!
wavelengths away from the diffracting aperture, and we have
Ð" 
Ñ ¸
"
45!ÈB C D
#
#
#  
1 .
(2) Using the binomial expansion, the factor
ÈB C D
¸ D B C
#D
#
#
#
#
#
 
,
provided  that 
<<
. This condition is called the 
B C
D
#
#
#
paraxial
approximation. If this approximation is used in the more sensitive phase term
and only used the first expansion term in the less sensitive denominators of
Wave Optics and Holography

34
the first and second terms of 
becomes the so-
Eq. (2.3-10), then KÐBß Cà DÑ
called spatial impulse response in Fourier optics, 
[Poon and
2ÐBß Cà DÑ
Banerjee (2001), Goodman (2005)]:
2ÐBß Cà DÑ œ
Ð 45 DÑ 45
# D
exp
exp
.
(2.3-11)
!
!
1
’ 45 ÐB C Ñ
#D
!
#
#
“
If Eq. (2.3-11) is now used in  Eq. (2.3-9), we obtain
    
  
 
 
<
<
:
:!
ÐBß Cà DÑ œ
ÐBß CÑ ‡ 2ÐBß Cà DÑ
œ
Ð 45 DÑ
ÐB ß C Ñ
45
# D
exp
 
!
:!
!
w
w
1
<
( (
‚
Ö
B B Ñ
C C Ñ
.B .C
exp
.
(2.3-12)
45
#D
ÒÐ
Ð
Ó×
!
#
#
w
w
w
w
+
Equation (2.3-12) is called the 
and describes the
Fresnel diffraction formula 
Fresnel diffraction of a beam during propagation and having an arbitrary
initial complex profile, <:!ÐBß CÑ. To obtain the output field distribution
<:ÐBß Cà DÑ
D
 at a distance  away from the input (the location of the diffracting
screen), we would simply convolve the input field distribution, 
,
<:!ÐBß CÑ
with the spatial impulse response, 
.
2ÐBß Cà DÑ
 
By taking the 2-D
 
, we obtain
 Fourier transform of 2ÐBß Cà DÑ
 
 
 
 
LÐ5 ß 5 à DÑ œ
2ÐBß Cà DÑ
B
C
YBCš
›
œ
Ð 45 DÑ
exp
exp
(2.3-13)
!
’
4 Ð5 5 ÑD
#5
Þ
B
C
#
#
!
“
LÐ5 ß 5 à DÑ
B
C
 is known as the 
 
spatial frequency transfer function in Fourier
optics. Indeed, we can derive Eq. (2.3-13) directly if we assume that
5 5 ¥ 5
B
C
B
C
#
#
#
!, meaning that the 
 and  components of the propagation
vector of a wave are relatively small, from Eq. (2.3-5), we have
G
G
[
:
B
C
:
B
C
B
C
(
(
5 ß 5 à DÑ
5 ß 5 Ñ
œ
Ð5 ß 5 à DÑ
0
œ
4
exp
5
" Ð5 5 ÑÎ5 D
!
#
#
B
C
#
!
É
‘ 
¶
4 Ð5 5 ÑD
#5
 exp
exp
Ð 45 DÑ
!
’
B
C
#
#
!
“
œ LÐ5 ß 5 à DÑ
B
C
Optical Scanning Holography with MATLAB

35
or
           
 G
G
:
B
C
:
B
C
B
C
(
(
.
(2.3-14)
5 ß 5 à DÑ œ
5 ß 5 ÑLÐ5 ß 5 à DÑ
0
Figure 2.9 summarizes the results of Fresnel diffraction in terms of block
diagrams in the spatial domain as well as in the spatial frequency domain.
Fig. 2.9 Block diagrams to summarize Fresnel diffraction.
Example 2.4 
Diffraction of a Point Source
A point source is represented by 
,
 From Eq. (2.3-12), the
<
$
:!ÐBß CÑ œ ÐB CÑÞ
complex field at a distance  away is given by
D
 
,
<
$
:ÐBß Cß DÑ œ ÐB CÑ‡2ÐBß Cà DÑ
œ
Ð 45 DÑ
Ò 
Ó
45
45 ÐB C Ñ
# D
#D
exp
exp
.
(2.3-15)
!
!
!
#
#
1
This expression is the paraxial approximation to a 
.
diverging spherical wave
The variable 
in the argument of the exponential function is called the
D
radius of curvature of the spherical wave. The wavefronts are divergent
Wave Optics and Holography

36
when 
 and convergent when 
We can re-write Eq. (2.3-15) as
D !
D !Þ
<
1
:
!
!
#
#
ÐBß Cß DÑ œ
Ò 45 ÐD 
ÑÓ
45
B C
# D
#D
exp
.
Now, by considering the argument of the exponential function, we see that
by using the binomial expansion 
, 
ÈB C D
¸ D 
#
#
#
B C
#D
 
we can write
#
#
<
1
:
!
!
#
#
#
ÐBß Cß DÑ ¶
45 B C D
45
# D exp[
(
) ]
 
"
#
¶
Ð 45 VÑ
45
# V
!
!
1
exp
,
(2.3-16)
where we have used 
 in the less sensitive 
D ¶ V
denominator. Eq. (2.3-16)
corresponds to Eq. (2.2-13) for a 
cal wave.
diverging spheri
Example 2.5 
Diffraction of a Plane Wave
For 
a 
plane 
wave, 
we 
can 
write 
 
Then
<p!ÐBß CÑ œ "Þ
G
1 $
$
:!
B
C
B
C
#
Ð5 ß 5 Ñ œ %
Ð5 Ñ Ð5 Ñ. Using Eq. (2.3-14), we have
    
exp
exp 
 
G
1 $
$
:
B
C
B
C
!
#
B
C
#
#
!
Ð5 ß 5 à DÑ œ %
Ð5 Ñ Ð5 Ñ
Ð 45 DÑ
Ò
Ó
4Ð5 5 ÑD
#5
 
           
exp
.
œ %
Ð5 Ñ Ð5 Ñ
Ð 45 DÑ
1 $
$
#
B
C
!
Its inverse transform gives the expression of a plane wave [see Eq. (2.2-9)],
 
 
exp
.
<:
!
ÐBß Cß DÑ œ
Ð 45 DÑ
As the plane wave travels, it only acquires phase shift and, as expected, is
undiffracted.
2.3.2 Diffraction of a Square Aperture
In general, when a light field illuminates a transparency of transmission
function given by 
, and if the complex amplitude of the light just in
>ÐBß CÑ
front of the transparency is 
, then the complex field immediately
<3ß:ÐBß CÑ
after the transparency is given by 
. In writing this product
<3ß:ÐBß CÑ>ÐBß CÑ
result, we assume that the transparency is infinitely thin.
Optical Scanning Holography with MATLAB

37
 
Now, let us consider a simple situation where a plane wave of unit
amplitude is incident normally on the transparency 
, and the field
>ÐBß CÑ
emerging from the transparency is then 
 as 
 in the
" ‚ >ÐBß CÑ
ÐBß CÑ œ "
<3ß:
present case. We want to find the field distribution, which is a distance D
away from the transparency. This corresponds to the Fresnel diffraction of an
arbitrary beam profile as the transparency modifies the incident plane wave.
The situation is demonstrated in Fig. 2.10.
Fig. 2.10 Fresnel diffraction of an arbitrary beam profile
.
>ÐBß CÑ
Let us further consider a specific case where >ÐBß CÑ œ rect
, a
ÐBÎ+ß CÎ+Ñ
square aperture, is used for MATLAB simulations. We then implement
<
<
:
:!
ÐBß Cà DÑ œ
ÐBß CÑ ‡ 2ÐBß Cà DÑ in the spatial frequency domain, i.e.,
using Eq. (2.3-14), where 
 is 
given by rect
<:!ÐBß CÑ
ÐBÎ+ß CÎ+Ñ
>ÐBß CÑ and is 
with 
cm. 
+ œ !Þ%$$'
The m-file, Fresnel_diffraction.m shown in Table 2.1,
generates the three figures shown below. Figure 2.11a) shows the square
aperture, rect
, which is illuminated by a plane wave of red
ÐBÎ+ß CÎ+Ñ
wavelength (
cm).  Figure 2.11b) and c) show the central
-!
%
œ !Þ'$#) ‚ "!
cross-section of the square aperture, i.e., 
, and the Fresnel
l
ÐBß !à !Ñl
<:
diffracted magnitude, i.e., 
, at 
cm, respectively.
l
ÐBß !à DÑl
D œ &
<:
cm
cm
−0.5
0
0.5
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
0.5
a)
Wave Optics and Holography

38
Fig. 2.11 a) Square aperture, b) Central cross-section of a),
c) Central cross-section of diffracted amplitude at 
cm.
D œ &
Table 2.1 Fresnel_diffraction.m:
m-file for calculating the Fresnel diffraction of a square aperture.
------------------------------------------------------
%Fresnel_diffraction.m
%Simulation of Fresnel diffraction of a square aperture
%Adapted from "Contemporary optical image processing with MATLAB®,"
%by T.-C. Poon and P. P. Banerjee,  Elsevier 2001, pp. 64-65.
clear
L=1;  %L : length of display area
N=256;  %N : number of sampling points
dx=L/(N-1); % dx : step size
%Create square image, M by M square, rect(x/a), M=odd number
M=111;
a=M/256
R=zeros(256); %assign a matrix (256x256) of zeros
r=ones(M);  %assign a matrix (MxM) of ones
n=(M-1)/2;
R(128-n:128+n,128-n:128+n)=r;
%End of creating input image
%Axis Scaling
−0.5 −0.4 −0.3 −0.2 −0.1
0
0.1
0.2
0.3
0.4
0.5
−0.5 −0.4 −0.3 −0.2 −0.1
0
0.1 0.2 0.3 0.4 0.5
0
0.2
0.4
0.6
0.8
1
cm
cm
b)
0
0.2
0.4
0.6
0.8
1
1.2
1.4
c)
Optical Scanning Holography with MATLAB

39
for k=1:256
   X(k)=1/255*(k-1)-L/2;
   Y(k)=1/255*(k-1)-L/2;
   %Kx=(2*pi*k)/((N-1)*dx)
   %in our case, N=256, dx=1/255
   Kx(k)=(2*pi*(k-1))/((N-1)*dx)-((2*pi*(256-1))/((N-1)*dx))/2;
   Ky(k)=(2*pi*(k-1))/((N-1)*dx)-((2*pi*(256-1))/((N-1)*dx))/2;
 end
%Fourier transformation of R
 FR=(1/256)^2*fft2(R);
 FR=fftshift(FR);
%Free space impulse response function
% The constant factor exp(-jk0*z) is not calculated
%sigma=ko/(2*z)=pi/(wavelength*z)
%z=5cm,red light=0.6328*10^-4(cm)
sigma=pi/((0.6328*10^-4)*5);
for r=1:256,
   for c=1:256,
      %compute free-space impulse response with Gaussian apodization against aliasing
    h(r,c)=j*(sigma/pi)*exp(-4*200*(X(r).^2+Y(c).^2))*exp(-j*sigma*(X(r).^2+Y(c).^2));
   end
end
H=(1/256)^2*fft2(h);
H=fftshift(H);
HR=FR.*H;
H=(1/256)^2*fft2(h);
H=fftshift(H);
HR=FR.*H;
hr=ifft2(HR);
hr=(256^2)*hr;
hr=fftshift(hr);
%Image of the rectangle object
figure(1)
image(X,Y,255*R);
colormap(gray(256));
axis square
xlabel('cm')
ylabel('cm')
% plot of cross section of square
figure(2)
plot(X+dx/2,R(:,127))
grid
Wave Optics and Holography

40
axis([-0.5 0.5 -0.1 1.2])
xlabel('cm')
figure(3)
plot(X+dx/2,abs(hr(:,127)))
grid
axis([-0.5 0.5 0 max(max(abs(hr)))*1.1])
xlabel('cm')
------------------------------------------------------
2.4 Ideal Lens, Imaging Systems, Pupil Functions
and Transfer Functions
2.4.1 Ideal Lens and Optical Fourier Transformation
In the previous section, we have discussed light diffraction by apertures. In
this section, we will discuss the passage of light through an 
. An
ideal lens
ideal lens is a phase object. When an ideal focusing (or convex) lens has
focal length , its phase transformation function, 
, is given by
0
> ÐBß CÑ
0
  > ÐBß CÑ œ
Ò4#0
0
exp
5 ÐB C ÑÓ
!
#
# ,
(2.4-1)
where we have assumed that the ideal lens is infinitely thin. For a uniform
plane wave incident upon the lens, the wavefront behind the lens is a
converging spherical wave (for > 0) that converges ideally to a point source
0
( a distance of 
 ) behind the lens. We can see that this is the case when
D œ 0
we apply the 
Eq. (2.3-12)] :
Fresnel diffraction formula [see 
 
 
  
,
(2.4-2)
<
<
:
:!
ÐBß Cß D œ 0Ñ œ
ÐBß CÑ ‡ 2ÐBß Cà D œ 0Ñ
where 
 is now given by 
<:!ÐBß CÑ
" ‚ > ÐBß CÑ
0
. The constant, 1, in front of
> ÐBß CÑ
0
 signifies that we have a plane wave (of unit amplitude) incident. For
example, if we have an incident 
 of the profile given by
Gaussian beam
exp
, then 
exp
Ò +ÐB C ÑÓ
Ò +ÐB C ÑÓ
#
#
#
#
<:!ÐBß CÑ
‚
 will be given by 
> ÐBß CÑ
> ÐBß CÑ
0
0
. Let us now return to Eq. (2.4-2) where 
 
, and by
<:!ÐBß CÑ œ
using Eq. (2.3-12) we have
<
1
:
!
!
w
w
ÐBß Cà 0Ñ œ
Ð 45 0Ñ
ÐB ß C Ñ
45
# 0
exp
 ( (  >0
‚
B B Ñ
C C Ñ
.B .C
expœ
45
#0
Ò Ð
Ð
Ó
!
#
#
w
w
w
w

 
º
"
ÐB
C ÑÓ
5
( (
exp Ò4
#0
!
w
w
#
#
Optical Scanning Holography with MATLAB

41
‚
B
C
#BB #CC
.B .C
exp’ 45
#0
Ð
Ñ
!
w
w
w
w
w
w
#
#
“
œ
"
BB CC
.B .C
( (
’
exp
,
45
0 Ð
Ñ
!
w
w
w
w
“
which is recognized to be proportional to a 2-D Fourier transform of , i.e.,
"
$ÐBß CÑÞ
 
Let us now investigate the effect of placing a transparency,
,
>ÐBß CÑ
against the ideal lens, which is shown in Fig. 2.12. In general, 
 is a
>ÐBß CÑ
complex function such that if a complex field, 
, is incident on it,
<3ß:ÐBß CÑ
then the field immediately behind the transparency-lens combination is
<
<
3ß:
3ß:
!
#
#
ÐBß CÑ >ÐBß CÑ
ÐBß CÑ>ÐBß CÑ
ÐB C ÑÓÞ
5
> ÐBß CÑ œ
Ò4#0
0
exp
Fig. 2.12 A transparency immediately before an ideal lens
 
under complex field illumination.
Again, for brevity, when illuminated by a unit-amplitude plane wave, the
field immediately behind the combination is given by " ‚ >ÐBß CÑexp
Ò4 5
#
#
!
#0 ÐB C ÑÓ
D œ 0
. We can then find the field distribution at a distance 
 by
using the Fresnel diffraction formula, Eq. (2.3-12) as
ß
 
exp
<
1
:
!
!
ÐBß Cà D œ 0Ñ œ
Ð 45 0Ñ
Ò
B
C
45
# 0 exp 45
#0
Ð

ÑÓ
!
#
#
Wave Optics and Holography

42
‚
>ÐB ß C Ñ
ÐBB CC ÑÓ.B .C
5
( (
w
w
w
w
w
w
!
exp Ò4 0
 
 
 œ
Ð 45 0Ñ
Ò
B
C
45
# 0
exp
exp
!
!
1
45
#0
Ð

ÑÓ
!
#
#
 
 
 
 
 
      
(2.4-3)
‚
>
YBCš
›º
5Cœ5 CÎ0
!
5 œ5 BÎ0
B
!
,  
where 
 and 
 denote the transverse coordinates at 
. Hence, the
B
C
D œ 0
complex field on the focal plane (
 is proportional to the Fourier
D œ 0Ñ
transform of 
, but has 
 term 
. Note
>ÐBß CÑ
Ð

ÑÓ
phase curvature
expÒ
B
C
45
#0
#
#
!
that if 
, i.e., the transparency is completely clear, then we have
>ÐBß CÑ œ "
<
$
:ÐBß Cß D œ 0Ñ º ÐBß CÑ, which corresponds to the focusing of a plane
wave by a lens, as discussed earlier.
 
Example 2.5 
Transparency in front of a Lens
Suppose that a transparency, 
, is located at a distance, 
, in front of an
>ÐBß CÑ
.!
ideal convex lens and is illuminated by a plane wave with a unit strength
shown in Fig. 2.13. The physical situation is shown in Fig. 2.13a), which can
be represented by a block diagram given by Fig. 2.13b). According to the
block diagram, we write
 
,
(2.4-4)
<:
!
0
ÐBß Cà 0Ñ œ ÖÒ>ÐBß CÑ‡2ÐBß Cà . ÑÓ> ÐBß CÑ×‡2ÐBß Cà 0Ñ
which, apart from some constant, can be evaluated to obtain
<
1
:
!
!
!
#
#
ÐBß Cà 0Ñ œ
Ò 45 Ð. 0ÑÓ
Ò 4
Ð" 
ÑÐB C ÑÓ
45
5
.
# 0
#0
0
exp
exp
0
0
(2.4-5)
‚
Ö
YBC
º
5Cœ5 CÎ0
!
5 œ5 BÎ0
B
!
As in Eq. (2.4-3), note that a phase curvature factor as a function of  and 
B
C
again precedes the Fourier transform, which represents the phase error if one
wishes to compute the optical Fourier transformation. However, the phase
curvature vanishes for the special case of 
. That is, from Eq. (2.4-5)
. œ 0
!
and by disregarding some inessential constant, we now have
Optical Scanning Holography with MATLAB
ÐBß CÑ
>ÐBß CÑ×
.

43
<
Y
:
BC
!
!
ÐBß Cà 0Ñ œ
Ö>ÐBß CÑ×
œ XÐ5 BÎ0ß 5 CÎ0Ñ
º
5Cœ5 CÎ0
!
5 œ5 BÎ0
B
!
.
(2.4-6)
Therefore, when the transparency is placed in the front focal plane of the
convex lens, the phase curvature disappears and we recover the exact Fourier
transform on the back focal plane.
 of an input
 Fourier-plane processing
transparency located on the front focal plane can now be performed on the
back focal plane. This is the essence of Fourier optics to perform coherent
image processing.
Fig. 2.13 Plane-wave illumination of a transparency 
 located a distance 
 in front
  
>ÐBß CÑ
.!
of a convex lens of focal length : a) Physical situation, b) Block diagram.
0
 
2.4.2 Coherent Image Processing
The two-lens system is traditionally attractive for coherent image processing
because, in the configuration shown in the Fig. 2.14, the Fourier transform of
the input transparency, 
, appears on the common focal plane, or
>ÐBß CÑ
Fourier plane. In order to perform Fourier-plane processing of the input
“
”
Wave Optics and Holography

44
transparency, we can insert a transparency on the Fourier plane that will
suitably modify the Fourier transform of the input transparency.
 
Fig. 2.14 Standard
  
 two-lens imaging processing system.
 
 The Fourier plane transparency is commonly called a 
,
spatial filter
:ÐBß CÑ.  According to Eq. (2.4-6), when a transparency 
is placed on
>ÐBß CÑ
the front focal plane of lens 
 as shown in Fig. 2.14, the field distribution
P"
on the common focal plane is given by 
, where we assume
XÐ5 BÎ0 ß 5 CÎ0 Ñ
!
"
!
"
that the transparency is illuminated by a plane wave. After this field
distribution is modified by the spatial filter, we can finally find the field
distribution on the back focal plane of lens 
, 
, by again using Eq. (2.4-
P#
:3
<
6) and neglecting some constant, as
       
,
<:3
!
"
!
"
ÐBß CÑ œ
XÐ5 BÎ0 ß 5 CÎ0 Ñ
YBCš
:ÐBß CÑ›º
5Cœ5 CÎ0
!
#
5 œ5 BÎ0
B
!
#
which can be evaluated, in terms of convolution, to give
<:3ÐBß CÑ œ >ÐBÎQß CÎQÑ ‡  
(2.4-7)
YBCš:ÐBß CÑ›º
5Cœ5 CÎ0
!
#
5 œ5 BÎ0
B
!
#
œ
ß
Ñß
5
5 C
>ÐBÎQß CÎQÑ ‡ TÐ
B
0
0
  
!
!
#
#
where 
 is the magnification factor and 
 is the Fourier
Q œ 0 Î0
T
#
"
transform of :. By comparing Eq. (2.4-7) with Eq. (1.2-2), we can describe
the impulse response of the two-lens system, or the coherent point spread
function (CPSF), as
Optical Scanning Holography with MATLAB

45
2 ÐBß CÑ œ
œ TÐ
B
0
0
-
#
#
YBC
!
!
š:ÐBß CÑ
ß
Ñ
5
5 C
›º
5Cœ5 CÎ0
!
#
5 œ5 BÎ0
B
!
#
.
(2.4-8)
:ÐBß CÑ is often called the 
 of the system. We can see that the
pupil function
coherent PSF is given by the Fourier transform of the pupil function as
shown in Eq. (2.4-8). By definition, the corresponding coherent transfer
function is the Fourier transform of the coherent PSF:
       
 
L Ð5 ß 5 Ñ œ
2 ÐBß CÑ
-
B
C
-
YBCš
›
œ
TÐ
œ :Ð
B
0 5
0
0
5
5
0 5
YBC
!
!
š
5
5 C

ß
Ñ
ß
ÑÞ

#
#
!
!
#
B
#
C
›
(2.4-9)
We observe that 
 is directly proportional to the functional
spatial filtering
form of the pupil function in coherent image processing.
 
The complex field on the image plane can then be written as
 
  
,
(2.4-10)
<:3
-
ÐBß CÑ º >ÐBÎQß CÎQÑ‡2 ÐBß CÑ
and hence the corresponding 
 is
image intensity
       
 
.
(2.4-11)
M ÐBß CÑ œ l
ÐBß CÑl º >ÐBÎQß CÎQÑ ‡ 2 ÐBß CÑl
3
:3
-
#
#
<
l
 
2.4.3 Incoherent Image Processing
So far, we have discussed that the illumination of an object is spatially
coherent - 
. 
an example being the use of a laser This means that the complex
amplitudes of light falling on all parts of an object vary in unison, meaning
that any two points on an object receive light that has a fixed relative phase
and does not vary with time. On the other hand, an object may be illuminated
with light having the property that the complex amplitudes on all parts of the
object vary randomly, so that any two points on the object receive light of
illumination is termed 
. Light from extended sources,
spatially incoherent
such as fluorescent tube lights, is incoherent. As it turns out, a coherent
system is linear with respect to the complex fields and hence Eqs. (2.4-10)
and (2.4-11) hold for 
. On the other hand, 
coherent optical systems
an
incoherent optical system is linear with respect to the intensities. To find the
image intensity, we perform convolution with the given intensity quantities
as follows:
 
|   |
.
(2.4-12)
M ÐBß CÑ º >ÐBÎQß CÎQÑ
‡ 2 ÐBß CÑl
3
-
#
#
l
Wave Optics and Holography

46
-
#
algorithms (e.g., highpass, derivative, etc.), which requires a bipolar PSF
[Lohmann and Rhodes (1978)].
 
As usual, the Fourier transform of an impulse response will give a
transfer function known as the 
of the
optical transfer function (OTF) 
incoherent imaging system. For this case, it is given by
 
 |
,
(2.4-13)
SXJÐ5 ß 5 Ñ œ
Ö 2 ÐBß CÑl × œ L Ð5 ß 5 Ñ Œ L Ð5 ß 5 Ñ
B
C
BC
-
-
B
C
-
B
C
#
Y
which can be explicitly written in terms of the coherent transfer function 
:
L-
SXJÐ5 ß 5 Ñ œ
L Ð5 ß 5 Ñ L Ð5 5 ß 5 5 Ñ .5 5
B
C
-
B
C
‡
w
w
w
w
w
w
-
B
C
B
C
B
C
( (  
 
 
.
(2.4-14)
Note that one of the most important properties of the 
, which follows a
SXJ
property of correlation, is that
 
 
|
|
|
0 0 |.
(2.4-15)
SXJÐ5 ß 5 Ñ Ÿ SXJÐ ß Ñ
B
C
This property states that the OTF always has a central maximum, which
always signifies lowpass filtering disregardless of the pupil function used in
the system [Lukosz (1962)].
Example 2.6 
Coherent Transfer Functions and OTFs
 
Consider a two-lens system as shown in Fig. 2.14 with 0 œ 0 œ 0
1
#
and 
rect
, i.e , a slit of width 
along the -direction. Using
:ÐBß CÑ œ
ÐBÎ\Ñ
Þ
\
C
Eq. (2.4-9), the coherent transfer function becomes
 
rect
L Ð5 ß 5 Ñ œ
B
\
-
B
C
Bœ05 Î5
ˆ
‰¹
B
!
œ
5
\5 Î0
rect
,
(2.4-16)
ˆ
‰
B
!
which is plotted in Fig. 2.15a). Now, the OTF is the autocorrelation of 
 as
L-
calculated by Eq. (2.4-13) and is plotted in Fig. 2.15b). Observe that both
is
 
 |2 Ð ß Ñl
 B C
This equation is the basis for incoherent image processing.
the impulse response of the incoherent optical system and is often called
IPSF is real and non-negative, which particularly means that it is not possi-
ble to directly implement even the simplest enhancement and restoration
the intensity point spread functio n (IPSF) of the optical system. Note that the
Optical Scanning Holography with MATLAB

47
situation perform lowpass filtering of spatial frequencies on an input image.
Under incoherent illumination, it is possible to transmit twice the range of
a)
b)
Fig. 2.15  a) The coherent transfer function, and b) the OTF
for the pupil function 
rect
.
:ÐBß CÑ œ
ÐBÎ\Ñ
Now, let us consider
:ÐBß CÑ œ

B 
B B
B B
\
\
\
”
Œ

Œ
•
rect
rect
,   
,
2
!
!
!
spatial frequency of an image as compared to the use of coherent illumi-
nation. However, the spectrum of an image transmitted through the pass-
band is modified by the shape of the OTF.
0
2f
−Xk0
2f
Xk0
kx
Hc
0
f
Xk0
−
OTF
f
Xk0
kx
Wave Optics and Holography

48
which is a two-slit object aligned along the -direction. 
C
The coherent transfer
function is
   
 
L Ð5 ß 5 Ñ œ
-
B
C
Bœ05 Î5
”
Œ

Œ
•
rect
rect
B B
B B
\
\

!
!
¹
B
!
œ

B
B
\
Î
\
Î
”
Œ

Œ
•
rect
rect
.
5
5 Î0
5
5 Î0
5
0
5
0
B
!
B
!
!
!
!
!
a)
b)
Fig. 2.16  a) The coherent transfer function, and b) the OTF
  
for the pupil function :ÐBß CÑ œ
Ò B B
\Ó 
Ò B B
\Ó
rect (
)/
rect (
)/
.
!
!
We plot L-Ð5 ß 5 Ñ
B
C  in Fig. 2.16a) along with the OTF in Fig. 2.16b). Note
that even though it may be possible to achieve 
 with
band-pass filtering
f
x0k0
x0k0
f
Xk0
f
Xk0
f
− 
kx
Hc
0
OTF
f
f
f
Xk0
Xk0
f
2x0k0
2x0k0
−
−
kx
Optical Scanning Holography with MATLAB

49
coherent illumination, incoherent processing always gives rise to inherently
low-pass characteristics because its point spread function is real and positive
[see Eq. (2.4-13)]. A large amount of attention has been focused on devising
methods to realize band-pass characteristics by using novel incoherent image
processing techniques [see, e.g., Lohmann and Rhodes (1978), Stoner (1978),
Poon and Korpel (1979), Mait (1987)], where the synthesis of bipolar or even
complex point spread functions (PSFs) in incoherent optical systems is
possible. Such techniques are called bipolar incoherent image processing.
The article by Indebetouw and Poon [1992] provides a comprehensive
review of bipolar incoherent image processing.
2.5 Holography
2.5.1 Fresnel Zone Plate as a Point-Source Hologram
A photograph is  a 2-D recording of a 3-D scene. What is actually recorded is
the light intensity at the plane of the photographic recording film - the film
being light sensitive only to the intensity variations  Hence, the developed
Þ
film s amplitude transparency is 
|
| , where 
 is the
>ÐBß CÑ º MÐBß CÑ œ <
<
:
:
2
complex field on the film. As a result of this intensity recording, all the
information on the relative phases of light waves from the original 3-D scene
is lost. This loss of phase information on the light field destroys the 3-D
character of the scene, i.e., we cannot change the perspective of the image in
the photograph by viewing it from a different angle (i.e.,
) and we
 parallax
cannot interpret the depth of the original 3-D scene.
 
As an example, let us take the photographic recording of a point
source located at the origin, but with a distance of 
. The
D! away from the film
situation is shown in Fig. 2.17a). Now, according to Eq. (2.3-15), the
complex field just before the film is given by
<
$
:
!
!
ÐBß Cà D Ñ œ ÐBß CÑ‡2ÐBß Cà D Ñ
                 
exp
exp
.
œ
Ð 45 D Ñ
Ò 
Ó
45
45 ÐB C Ñ
# D
#D
! !
!
!
!
!
#
#
1
Hence, the developed film s amplitude transparency is
>ÐBß CÑ º MÐBß CÑ œ
ÐBß Cà D Ñ
œ Ð
|
|
<:
!
2
5
# D Ñ
!
!
#
1
 .
(2.5-1)
Note that the phase information of 
 Now, for a
<:
!
ÐBß Cà D Ñ is completely lost.
point source located at (
, 
), as shown in Fig. 2.17b), t
B
C
!
!
he complex field
just before the film is given by
’
’
Wave Optics and Holography

50
a)
b)
!
!
!
<
$
:
!
!
!
!
!
!
ÐBß Cà B ß C
D Ñ œ ÐB B ß C C Ñ‡2ÐBß Cà D Ñ
, 
           
  
exp
exp
+
œ
Ð 45 D Ñ
Ò 
Óß
45
45 ÒÐB B Ñ
ÐC C Ñ Ó
# D
#D
! !
!
!
!
!
!
!
#
#
1
and what is recorded is
 
|
|
>ÐBß CÑ º MÐBß CÑ œ
œ Ð
<
1
:
!
!
!
!
!
#
ÐBß Cà B ß C
D Ñ
Ñ
5
# D
, 
,
(2.5-2)
2
which is identical to the result given by Eq. (2.5-1). Again the phase
information of 
,
 is lost, and we also notice that the 3-D
<:
!
!
!
ÐBß Cà B ß C D Ñ
location of the point source, i.e., 
, and 
, is mostly lost.
B ß C
D
!
!
!
b) located at (B ß C ), both D  away from the film.
Fig. 2.17   Photographic recording of a point source: a) located at the origin Ð!ß !Ñ, and
Optical Scanning Holography with MATLAB

51
 
Holography is an extraordinary technique that was invented by
Gabor [1948], where not only the amplitude, but also the phase of a light
field can be recorded. The word holography  combines parts of two Greek
words: 
, meaning complete, and 
, meaning to record.  Thus,
holos
graphein
holography means the recording of complete information. Hence, in the
holographic process, the film records both the amplitude and phase of a light
field. The resulting recorded film is called a
 When a hologram is
hologram.
properly illuminated, an exact replica of the original 3-D wave field is
reconstructed. We shall discuss the 
 of a point object
holographic recording
as an example. Once we know how a single point is recorded, the recording
of a complicated object can be regarded as the recording of a collection of
points.
 
Fig. 2.18   Holographic recording of a point source object.
Figure 2.18 shows a collimated laser which is split into two plane waves and
then recombined by using two mirrors (M) and two beam splitters (BS). One
plane wave is used to illuminate the pinhole aperture (our point object), and
the other is used to illuminate directly the recording film. The plane wave
that is diffracted by the pinhole aperture generates a diverging spherical
wave. In holography, this diverging wave is known as an 
. The
object wave
plane wave that directly illuminates the photographic plate is known as a
reference wave. Let 
 represent the field distribution of the object wave on
<o
the plane of the recording film, and similarly, let 
represent the field
<r  
distribution of the reference wave on the plane of the recording film. The
film now records the interference of the reference wave and the object wave,
i.e., what is recorded is given by 
, provided that the reference
l

l
<
<
r
o #
wave and the object wave are mutually coherent over the film. The
“
”
“
”
“
”
“
”
Wave Optics and Holography

52
coherency of the light waves is guaranteed by the use of a laser source and
ensures that the difference between the two paths is less than the coherent
length of the laser. This kind of recording is known as holographic
recording, and is distinct from a photographic recording where the reference
wave does not exist and, therefore, only the object wave is recorded.
 
Let us now consider the recording of an off-axis point object at a
distance of 
 from the recording film. The pinhole aperture is then modeled
D!
as 
. According to Fresnel diffraction, the object wave arises
$a
b
B B ß C C
!
!
from the point object on the film and is given by
<
$
o œ
B B ß C C
a
b
!
! ‡ 2ÐBß Cà D Ñ
!
     
 exp
/
. 
2
œ
D
Ö 45 ÒÐB B Ñ ÐC C Ñ Ó #D ×
45
D
expÐ 45
Ñ
! !
!
!
!
!
!
!
1
2
2
This object wave is a 
.
spherical wave
 
For the reference plane wave, we assume that the plane wave has the
same initial phase as the point object at a distance of 
 away from the film.
D!
Therefore, its field distribution on the film is 
, where 
<r œ +
D
+
expÐ 45
Ñ
! !
is the amplitude of the plane wave. Hence, the intensity distribution that is
being recorded on the film, or the transmittance of the hologram, is given by
>ÐBß CÑ º l

l
<
<
r
o
#
 
 
 exp
/ 
2
œ l + 
Ö 45 ÒÐB B Ñ ÐC C Ñ Ó #D ×l
45
D
!
!
!
!
!
!
1
2
2
2
œ E F
Ö
ÒÐB B Ñ ÐC C Ñ Ó×
5
D
 
2
sin
!
!
!
!
2
2
œ J^TÐB B ß C C à D Ñ
!
!
!
(2.5-3)
where 
( 
 ) , 
 and 
.
E œ + 
F œ
5 œ # Î
#
5
5
D
D
!
!
!
!
!
!
2
2
1
1
1 -
 
The expression in Eq. (2.5-3) is called the sinusoidal Fresnel zone
plate (FZP)
 
 
, which is a hologram of the point source object. Note that the
center of the zone plate specifies the location, 
 and 
, of the point object,
B
C
!
!
and the spatial variation of the zone plate is governed by a sine function with
a quadratic spatial dependence. For an on-axis point source, i.e., B œ C œ !
!
!
!
on-axis Fresnel zone plate as
in Eq. (2.5-3),  located a distance of D  away from the film, we have an 
Optical Scanning Holography with MATLAB

53
>ÐBß CÑ º l

l
<
<
r
o
#
 
 
 exp
2
œ l + 
Ò 
ÐB C ÑÓl
45
45
D
#D
!
!
!
!
1
2
2
2
œ E F
Ò
ÐB C ÑÓ
5
#D
 
sin
!
!
2
2
œ J^TÐBß Cà D Ñ
! .
(2.5-4)
 
Let us now investigate the quadratic spatial dependence of
J^TÐBß Cà D Ñ
! . The spatial rate of change of the phase on the zone plate
along the -direction is
B
0
œ
Ð
B Ñ œ
"
.
5
B
#
.B
D
D
69-+6
!
!
! !
#
1
-
2
.
(2.5-5)
This is a local fringe frequency that increases linearly with the spatial
coordinate, . The farther it is away from the origin of the zone, the higher
B
the frequency will be. So, for a fixed point (local) on the hologram, we can
deduce the depth information, 
by finding the local fringe frequency for a
D ß
!
given wavelength of light, 
. Therefore, we see that the depth information is
-!
encoded within the phase of the FZP. Figure 2.19 shows the dependence of
the Fresnel zone plate characteristic as a function of the depth parameter D
(for 
and 
). As the point source becomes further away from the
D œ D
#D
!
!
recording film, the recorded FZP has a lower local fringe frequency.
 
Figure 2.20 shows us that as the point source moves to a new
location 
, the center of the zone plate translates accordingly. Hence, we
B ß C
!
!
see that the zone contains the complete 3-D information of the point source.
The center of the zone, 
 and 
, defines the transverse location of the point
B
C
!
!
object, and the fringe variation defines the depth location, 
. Table 2.2
D!
shows the MATLAB code used to generate Fresnel zone plates that are
presented in Figs. 2.19 and 2.20. For an arbitrary 3-D object, we can think of
the object as a collection of points, and therefore, we can envision that we
have a collection of zones on the hologram, where each zone carries the
transverse location as well as the depth information of each individual point.
In fact, a hologram has been considered as a type of Fresnel zone plate, and
the holographic imaging process has been discussed previously in terms of
zone plates [Rogers (1950), Siemens-Wapniarski and Parker Givens (1968)].
Wave Optics and Holography

54
Fig. 2.19  On-axis Fresnel zone plate as a function of depth, D.
Fig. 2.20  Fresnel zone plate due to point sources at different transverse locations
but otherwise located at the same depth D!.
Optical Scanning Holography with MATLAB

55
Table 2.2 Fresnel_zone_plate.m:
m-file for calculating FZPs illustrated in Figs. 2.19 and 2.20.
------------------------------------------------------
%Fresnel_zone_plate.m
%Adapted from "Contemporary optical image processing with MATLAB®,"
%by T.-C. Poon and P. P. Banerjee, Elsevier 2001, pp.177-178.
%
%display function is 1+sin(sigma*((x-x0)^2+(y-y0)^2)). All scales are arbitrary.
%sigma=pi/(wavelength*z)
clear;
z0=input ('z0, distance from the point object to film, enter z0 (from 2 to 10)=');
x0=input ('Inputting the location of the center of the FZP x0=y0,enter x0 (from -8 to 8) =');
ROWS=256;
COLS=256;
colormap(gray(255))
sigma=1/z0;
y0=-x0;
y=-12.8;
for r=1:COLS,
 x=-12.8;
   for c=1:ROWS,      %compute Fresnel zone plate
      fFZP(r,c)=exp(j*sigma*(x-x0)*(x-x0)+j*sigma*(y-y0)*(y-y0));
      x=x+.1;
      end
  y=y+.1;
end
%normalization
max1=max(fFZP);
max2=max(max1);
scale=1.0/max2;
fFZP=fFZP.*scale;
R=127*(1+imag(fFZP));
figure(1)
image(R);
axis square on
axis off
------------------------------------------------------
 
So far, we have discussed the transformation of a point object to a
zone plate on the hologram, which corresponds to a 
 or 
recording
coding
process. In order to retrieve the point object from the hologram, we need a
reconstruction
decoding process
 or 
. This can be done by simply illuminating
the hologram with a 
. Figure 2.21 corresponds to the
reconstruction wave
reconstruction of a hologram of the point object located on-axis, i.e., the
reconstruction of the hologram given by Eq. (2.5-4).
Wave Optics and Holography

56
Fig. 2.21   Holographic reconstruction of a point source object.
 
Note that in practice as is shown in Fig. 2.21, the reconstruction
wave is usually identical to the reference wave. Therefore, we take the
reconstruction wave to have a field distribution on the plane of the hologram
given by 
=
Hence, the field distribution of the transmitted wave
<rca
b
Bß C
+Þ
immediately after the hologram is 
 and the field at
<rc> Bß C œ +> Bß C
a
b
a
b
arbitrary distance of  away, according to Fresnel diffraction, is given by the
D
evaluation of
 
 
 
         
. 
+> Bß C ‡ 2 Bß Cà D
a
b
a
b
For the point-object hologram given by (2.5-4), after we expand the sine term
of the hologram 
, we obtain
> Bß C
a
b
>ÐBß CÑ œ E
Ò4
ÐB C ÑÓ
F
5
4
#D
 + 
exp
2 š
!
!
#
#
   
exp
.

Ò 4
ÐB C ÑÓ
5
#D
!
!
#
# ›
Therefore, as a result of the illumination of the hologram by the
reconstruction wave, we have three waves. These waves, according to the
convolution operation, 
, are as follows:
+> Bß C ‡ 2 Bß Cà D
a
b
a
b
Zero-order beam:
    
 (
)
.
(2.5-6a)
+E ‡ 2 Bß Cà D œ D
œ + E
0
Real image (or the twin image):
μ
Ò4
ÐB C ÑÓ‡2 Bß Cà D œ D Ñ μ ÐB CÑ
5
#D
exp
(
, 
. 
(2.5-6b)
!
!
#
#
0
$
Optical Scanning Holography with MATLAB

57
Virtual image: 
μ
Ò 4
ÐB C ÑÓ‡2 Bß Cà D œ D Ñ μ ÐB CÑ
5
#D
 exp
(
, 
.
(2.5-6c)
!
!
#
#
0
$
By writing Eq. (2.5-6c), we have back-propagated the field immediately
behind the hologram by a distance of 
 to demonstrate that a virtual image
D!
will form behind the hologram. As illustrated in Fig. 2.21, optical fields from
this virtual image correspond to a diverging wave behind the hologram. We
notice that the zero-order beam is caused by the bias in the hologram and the
virtual image is the reconstructed original point object. The real image is
located at a distance of 
 in front of the hologram, which is known as the
D0
twin image.
Fig. 2.22  Holographic recording and reconstruction of a three-point object.
 
Figure 2.22 shows the holographic recording of a 3-point object and
its reconstruction.  Note that the virtual image appears at the correct 3-D
location as the original object, while the real image (the twin image) is the
mirror-image of the original object, with the axis of reflection on the plane of
the hologram.  
2.5.2 Off-Axis Holography
In the last section, we discussed the so-called 
.  The term
on-axis holography
on-axis  refers to the use of a reference wave that is coaxially illuminating
the hologram with the object wave. Although this technique can record 3-D
“
”
Wave Optics and Holography

58
information of an object, it also create an annoying effect when we view the
reconstructed virtual image. The real image (or the twin image) will also be
reconstructed along the viewing direction [see Figs. 2.21 and 2.22]. In
holography, this is infamously known as the twin-image problem.
 
Off-axis holography is a method that was devised by Leith and
the desired image. To achieve off-axis recording, the reference plane wave
will need to be incident on the recording film off-axis. Referring back to Fig.
2.18, this can be done by simply, for example, rotating the beamsplitter (BS)
between the pinhole aperture and the film in a clockwise direction so that the
reference plane wave is incident on the film at an angle. The situation is
shown in Fig. 2.23, where the plane reference wave is incident at an angle, .)
) is called the 
 in off-axis holographic recording.
recording angle
Fig. 2.23  Recording with off-axis reference plane wave.
The point object is 
 away from the film.
D!
 
For off-axis recording, we have 
, where the
>ÐBß CÑ œ l

l
<
<
r
o #
reference plane wave, 
, is now an off-axis plane wave given by
<r
+
Ð45 B
Ñ
exp
sin
0
o
)
<
. The object wave, 
, is the spherical wave generated by the
!
!
>ÐBß CÑ œ l +
Ð45 B
Ñ 
Ò 45 ÐB C Ñ #D Ól
45
D
exp
sin
0
2
2
2
)
1
!
!
!
!
2
exp
/ 
                     
 
 
,
(2.5-7)
2
œ E F
Ò
ÐB C Ñ 5 B
Ó
5
D
sin
sin
!
!
2
2
0
)
where 
and 
. 
 given by Eq. (2.5-7) is called
E œ + Ð
Ñ
F œ
> Bß C
#
5
+5
D
D
!
!
!
!
2
2
1
1
a
b
“
”
on-axis point object, we now have
on-axis  point  source. Similar to Eq. (2.5-3), where B œ C
œ !  for an
Optical Scanning Holography with MATLAB
Upatnieks [1964] to separate the twin-image and the zero-order beam from

59
an 
.  Eq. (2.5-7) can be expanded into three terms as
off-axis hologram
>ÐBß CÑ œ E 
4Ò
ÐB C Ñ 5 B
Ó
F
5
#4
D
œ
”
•
exp
sin
!
!
2
2
2
0
)
                         
   
.
2

4Ò
ÐB C Ñ 5 B
Ó
5
D
exp
sin
”
•
!
!
2
2
0
)
  Fig. 2.24  Holographic reconstruction of off-axis hologram.
The twin image (or the real image) is not observed if  is large enough.
)
By illuminating the hologram with a reconstruction wave identical to the
reference wave, we have 
 immediately after the hologram, where
<rc> Bß C
a
b
<
)
<
rc
0
r
œ +
Ð45 B
Ñ œ
exp
sin
. As in the case of on-axis holography, by
performing Fresnel diffraction, we have 
, thereby
<rc> Bß C ‡ 2 Bß Cà D
a
b
a
b
creating three waves as follows:
Zero-order beam:
E +
Ð45 B
Ñ ‡ 2ÐBß Cà D
D Ñ
exp
sin
0
)
  = !
μ
Ð45 B
Ñ
exp
sin
0
) .
(2.5-8a)
virtual
image
real image
off-axis
hologram
reconstruction
wave
observer
2q
Wave Optics and Holography

60
Real image (or the twin image):
+
Ð45 B
Ñ
4Ò
ÐB C Ñ 5 B
Ó ‡ 2ÐBß Cà D
D Ñ
exp
sin
exp
sin
0
0
2
2
2
)
)
š
›
5
D
!
!
!
  = 
μ ÐB #D
CÑ
$
)
!sin , 
 .
(2.5-8b)
Virtual image:
+
Ð45 B
Ñ
4Ò
ÐB C Ñ 5 B
Ó ‡ 2ÐBß Cà D
D Ñ
exp
sin
exp
sin
0
0
2
2
2
)
)
š
›
5
D
!
!
!
 
  =
μ ÐB CÑ Þ
$
, 
  
(2.5-8c)
The situation is depicted in Fig. 2.24.
2.5.3 Digital Holography
As discussed in the last section, in regards to off-axis holographic
reconstruction, the three reconstructed beams propagate along different
directions, and if the recording angle is sufficiently large, the virtual image
can be viewed without any disturbances from the zero-order beam and the
real image. This technique of off-axis recording is also known as carrier-
frequency holography. We can re-write Eq. (2.5-7) as
>ÐBß CÑ œ E F
Ò
ÐB C Ñ # 0 BÓ
5
D
sin
!
!
-
2
,
(2.5-9)
2
2
1
where 
/
/
 is the 
. For realistic parameter
0 œ 5
#
œ
-
!
0sin
sin
)
1
) -
spatial carrier
values, 
45  and 
 for red laser light, we have
)
-
.
œ
œ !Þ' 7
‰
!
sin) -
/
cycle/mm. This technique translates to a film resolution of
! μ "ß !!!
at least 1000 lp/mm [or line-pair/mm] in order to employ this technique for
holographic recording. Common holographic films have a resolution of about
5000 lp/mm. For comparison, standard black and white film resolution is
about 80-100 lp/mm and color film is about 40-60 lp/mm. But can we use
electronic devices such as CCD cameras for holographic recording? If we
can do it, we can bypass the darkroom preparation of films and, therefore, we
can perform real-time or electronic recording of holographic information.
Some of the best CCD camera in the market, such as Canon D60 (3072x2048
pixels, 67.7 lp/mm, 7.4 m pixel size), could not record off-axis holograms
.
efficiently because its resolution is about a couple of orders of magnitude
worse than the resolution of holographic films. We can see that off-axis
recording places a stringent resolution requirement on electronic recording
Optical Scanning Holography with MATLAB

61
media. We can relax the resolution requirement by making the recording
angle smaller, but this approach requires a very small recording angle that
often makes it impractical. Because of this reason, on-axis holography seems
to be prevalent in digital holography [Piestun, Shamir, Wekamp, and
Bryngdahl (1997)]. On the other hand, twin-image problems need to be
tackled when on-axis holography is employed. Indeed twin-image
elimination is an important research topic [Poon et al. (2000)].
 
While we have discussed holographic recording electronically or
digitally, for reconstruction, we can also perform it digitally. Once the
holographic information is in the electronic or the digital domain, we can
digitally evaluate Fresnel diffraction by performing the convolution, which is
+> Bß C ‡ 2 Bß Cà D
+
a
b
a
b, where 
 is some constant amplitude of the
reconstruction beam, 
is the recorded hologram, and 
 is the
>ÐBß CÑ
2ÐBß Cà DÑ
spatial impulse response in Fourier optics. For various values of 
, 
,
D œ D
D
"
#
etc., we can reconstruct different planes normal to the hologram. The whole
3-D volume of the object is then constructed plane by plane. The situation is
shown in Fig. 2.25.
  Fig. 2.25  Digital holographic reconstruction.
An alternative way to utilize electronically or digitally recorded hologram is
to have it displayed on some sort of 
(SLM) for real-
spatial light modulator 
time coherent reconstruction. A 2-D spatial light modulator is a device with
which one can imprint a 2-D pattern on a laser beam by passing the laser
beam through it (or by reflecting the laser beam off the device). A liquid
Wave Optics and Holography

62
crystal television (LCTV) (upon suitably modification) is a good example of
spatial light modulators. In fact, we can think of a spatial light modulator as a
real-time transparency because one can update 2-D images or holograms
upon the spatial light modulator in real time without developing films into
 
All in all, in this section we mention electronic or digital recording
and manipulation of holographic information. This type of research is
commonly known as 
(or
)
. The reader may find
digital 
 electronic  holography
a pioneering contribution in the work of Goodman and Lawrence [1967].
Ever since, digital holography has become a practical tool with an increasing
number of applications [Schnars and Juptner (2002)]. Most recently, an
edited book on the subject organizes a collection of key chapters that covers
digital holography and 3-D display techniques so as to provide the reader
with the state-of-the-art developments in these important areas around the
world [Poon (2006)]. Starting in the next chapter, we will discuss a unique
electronic holographic recording technique called optical scanning
holography.
References
2.1 
Banerjee, P.P. and T.-C. Poon (1991). 
 Irwin, Illinois.
Principles of Applied Optics.
2.2 
Gabor, D. (1948). A new microscopic principle, Nature
2.3 
Goodman, J. W. and R.W. Lawrence (1967).
Digital image formation from
electronically detected holograms,
2.4 
Goodman, J. W. (2005). 
. 3rd. ed., Roberts and
Introduction to Fourier Optics
Company Publishers, Englewood, Colorado.
2.5 
Indebetouw, G. and T.-C. Poon (1992). Novel approaches of incoherent image
processing with emphasis on scanning methods,
 31, 2159–
Optical Engineering
2167.
2.6 
E. N. Leith, E.N and J. Upatnieks (1962).
Reconstructed wavefronts and
communication theory,
 52, 1123–1130.
Journal of the Optical Society of America
2.7 
functions,
 17, 1141-1150.
Applied Optics
2.8 
Lukosz, W. (1962). Properties of linear low pass filters for non-negative signals,
Journal of the Optical Society of America 52, 827-829.
2.9 
Mait, J. N. (1987). Pupil-function design for complex incoherent spatial filtering,
Journal of the Optical Society of America A  4, 1185- 1193.
2.10 
Piestun R., J. Shamir, B. Wekamp, and O. Bryngdahl (1997). On-axis computer-
generated holograms for three-dimensional display,
22, 922-924.
Optics Letters 
2.11 
Poon, T.-C. and A. Korpel (1979).
Optical transfer function of an acousto-optic
heterodyning image processor,
 4, 317-319.
Optics Letters
2.12 
Poon, T.-C., T. Kim, G. Indebetouw, B. W. Schilling, M. H. Wu, K. Shinoda, and
Y. Suzuki (2000). Twin-image elimination experiments for three-dimensional
images in optical scanning holography,
 25, 215-217.
Optics Letters
transparencies. Again, off-axis holographic recording places stringent reso-
lution requirement on SLMs and we will come back to this later when dis-
cussing 3-D display applications in Chapter 4.
“
”
“
”
“
”
“
”
”
“
”
“
”
“
”
“
”
“
”
Applied Physics Letters 11, 77-79.
Lohmann A.W. and W. T. Rhodes (1978). “Two-pupil synthesis of optical transfer
Optical Scanning Holography with MATLAB

63
2.13 
Poon T.-C. and P. P. Banerjee (2001). Contemporary Optical Image Processing
with MATLAB . 
® Elsevier, Oxford, UK.
2.14 
Poon, T.-C., ed., (2006). Digital Holography and Three-Dimensional Display:
2.15 
Rogers, G.L. (1950). The black and white holograms,
166, 1027.
Nature 
2.16 
Siemens-Wapniarski, W.J. and M. Parker Givens (1968).
The experimental
production of synthetic holograms,
 7, 535-538.
 Applied Optics
2.17 
Stoner, W. (1978). Incoherent optical processing via spatially offset pupil masks,
Applied Optics 17, 2454-2466.
2.18 
Schnars, U. and W. P. O. Juptner (2002).
Digital recording and numerical
reconstruction of holograms,
13, R85–R101.
Meas. Sci. Technol.
“
”
“
”
“
”
“
”
Wave Optics and Holography
Principles and Applications. . Springer, New York, USA.

 
Chapter 3
Optical Scanning Holography: Principles
Optical scanning holography (OSH) is a form of electronic (or digital)
single 2-D optical scan. OSH was first implicated by Poon and Korpel when
they investigated bipolar incoherent image processing on their acousto-optic
heterodyning image processor [1979]. The original idea is later formulated
and becomes known as 
 [Poon (1985)]. The first
scanning holography
experimental results were then demonstrated and the technique was
eventually called optical scanning holography in order to emphasize the
novel fact that holographic recording can be achieved by active optical
scanning [Duncan and Poon (1992)]. Thus far, applications of OSH include
scanning holographic microscopy [(Poon, Doh, Schilling, Wu, Shinoda, and
Suzuki (1995)], 3-D image recognition [(Poon and Kim (1999)], 3-D optical
remote sensing [Kim and Poon (1999)], 3-D TV and display [Poon (2002a)],
and 3-D cryptography [Poon, Kim, and Doh (2003)]. Scanning holographic
microscopy is, by far, the most developed technique that utilizes OSH.
Unlike any other holographic microscopes, scanning holographic microscope
has a unique property that allows it to take the holographic information of
fluorescent specimens in three dimensions. Recently, scientists have been
able to achieve better than one-micron resolution in holographic fluorescence
microscopy [Indebetouw and Zhong (2006)]. While in chapters 1 and 2, we
have covered the necessary backgrounds in mathematics and optics to better
understand OSH, in this chapter, we discuss the basic principles of OSH. In
chapter 4, we will then discuss some of the previously mentioned
applications of OSH in detail. Finally in chapter 5, we will discuss some
recent advances in OSH.
3.1 Principle of Optical Scanning
Optical scanning holography involves active 
 and 
optical scanning
optical
heterodyning. In this section, we will discuss the basics of optical scanning.
An optical scanner or optical processor scans out a transparency, i.e.,
information, with an optical beam by moving either the beam or the
transparency. A photodetector accepts all light and gives an electrical output
holography. It is a unique, real-time technique where holographic infor-
mation of a three-dimensional (3-D) object can be acquired by using a

that can either be stored or displayed by some means or another. Hence,
optical information will have been converted into electrical information.
 
Figure 3.1 shows a standard, active optical scanning image
processing system. A plane wave (such as the use of a laser in practice) of
frequency 
, illuminates a pupil function, 
 The complex field
=!
:ÐBß CÑÞ
emerging from the pupil is then projected through the x-y optical scanner in
order to scan over the input object specified by a transparency of 
.
>!ÐBß CÑ
The photodetector (PD) then accepts all the light to give out an electrical
signal, which contains the processed information for the scanned object. If
the scanned electrical signal is digitally stored (i.e., in a computer) in
synchronization with the 2-D scan signals of the scanning mechanism (such
as the x-y scanning mirrors), what is stored as a 2-D record is then a
processed image of the scanned object.
Fig. 3.1 An active optical scanning image processing system.
 
Let us now discuss photodetection and see how light information can
be converted into electrical information. Assume that the photodetector s
surface is on the 
 plane and that the incident complex field on the
D œ !
detector s surface is given by 
exp
 as shown in Fig. 3.2
<
=
:
!
ÐBß CÑ
Ð4
>Ñ
Þ Since
the photodetector only responds to intensity, i.e., 
| , it gives the
l<:
#
expÐ4
>Ñ
=!
current, , as an output by spatially integrating the intensity over the active
3
area, 
, of the detector:
H
                    3 º
l
Ð4
>Ñ .B.C œ
l
.B.C
(
(
H
H
:
!
:
#
#
<
=
<
exp
|
|
.
(3.1-1)
66
’
’
Optical Scanning Holography with MATLAB

67
For example, if the incident field is a plane wave of amplitude 
, i.e.,
E
<: œ E, the current output is given by
  3 º
lE .B.C œ E H
(
H
#
#
|
,
(3.1-2)
which is a constant. However, take for instance that if the light has been
intensity-modulated, i.e., |
|
, where 
is the modulating signal,
<: # œ 7Ð>Ñ
7Ð>Ñ
the current will then give an output that varies with the modulation. This is
useful for laser communications systems [Pratt (1969)].
 
Note that since 
exp
, the output
<
<
9
:
:
ÐBß CÑ œ l
ÐBß CÑl
Ò4 ÐBß CÑÓ
current can only contain the magnitude information, i.e., 
, and the phase
l
l
<:
information is completely lost. This type of photodetection is known as
optical direct detection 
optical incoherent detection
(or 
).
Figure 3.2  Optical direct detection.
Once we comprehend photodetection, we can return to Fig. 3.1 to calculate
the current output given after scanning the transparency, 
. Instead of
>!ÐBß CÑ
modeling the transparency that is being scanned by an optical beam, as
shown by Fig. 3.3, we assume that the transparency, 
, is moving through
>!
the optical beam. In Fig. 3.3, the plane of the photodetector is on the B C
w
w
plane and the optical scanning beam specified by a complex field,
, is
,ÐB ß C Ñ
w
w
stationary at the origin of the 
 plane. By scanning or sampling we
B C
w
w
mean that successive points ( , , in transparency coordinates) of 
 are
B C
>!
brought into coincidence with the center (
, 
) of the optical beam in
B
C œ !
w
w
the 
 plane.
B C
w
w
Fig. 3.3 Scanning situation.
Optical Scanning Holography: Principles

68
In Fig. 3.3, the arguments,  and , of 
 signify that the transparency is
B
C
>!
moving or translating with respect to the optical beam. Therefore, the total
complex field reaching the photodetector is 
. The
,ÐB ß C Ñ
w
w >!
w
w
ÐB Bß C CÑ
photodetector collects all the transmitted light and delivers a current, .3
According to Eq. (3.1-1),  is given by
3
  3ÐBß CÑ º
l,ÐB ß C Ñ
B .C
(
H
w
w
w
w
 
|
(3.1-3)
>!
w
w
#
ÐB Bß C CÑ .
,
where 
 and 
 represent the instantaneous position of the
B œ BÐ>Ñ
C œ CÐ>Ñ
transparency. Alternatively, scanning imaging can be modeled by moving the
optical beam across the transparency, which results in the following
equation:
   
,
3ÐBß CÑ º
,ÐB Bß C CÑl
B .C Þ
(
H
w
w
#
w
w
l
ÐB C Ñ
.
>!
w
w
If we let B B œ B
C C œ C
w
ww
w
ww
 and 
 and then substitute them into the
above equation, we have
3ÐBß CÑ º
,ÐB ß C Ñl
B .C
(
H
ww
ww
#
ww
ww
l
ÐB B C CÑ
.
>!
ww
ww
,
,
3ÐBß CÑ º
l,ÐB ß C Ñl
B .C
(
H
w
w
#
w
w
 
|
l
ÐB Bß C CÑ .
>!
w
w
#
                              
| .
(3.1-4)
œ
l
ÐBß CÑ
l,ÐBß CÑl Œ
#
>!
#
Note that this result is interesting because it is an incoherent optical system
where only the intensities are processed, i.e., 
| is processed by
l
ÐBß CÑ
>!
#
l,ÐBß CÑl# even though the object, 
originally may be complex in
>!ÐBß CÑ, 
nature. Since the beam complex field, 
, and the pupil, 
, are in
,ÐBß CÑ
:ÐBß CÑ
the back and the front focal plane of lens L1, respectively, as shown in Fig.
3.1, they are related by a Fourier transformation where [see Eq. (2.4-6)]
    
 .
(3.1-5)
,ÐBß CÑ œ
Ö:ÐBß CÑ×
YBC
º
5Cœ5 CÎ0
!
5 œ5 BÎ0
B
!
 
Figure 3.4 shows a commercially available x-y scanning system from
General Scanning™. The mirrors are driven by galvanometers. The figure on
rearrange Eq. (3.1-3), we have
Ð>Ñ œ Z > and CÐ>Ñ œ Z >. When we 
which is identical to Eq. (3.1-3). We shall use the formulation shown in 
Eq. (3.1-3) to represent optical scanning throughout the book. Note that
for uniform scan speed Z
B
,  we have
 
Optical Scanning Holography with MATLAB

69
the right is a close-up of the x-y scanning mirrors positioned orthogonally to
each other (one direction for the x-scanning and the other for the y-
scanning).
Fig. 3.4 x-y optical scanning system.
3.2 Optical Heterodyning
In the last section, we have shown that a simple optical scanning system that
employs optical direct detection cannot extract any phase information of the
incident complex field. While holography requires the preservation of the
phase information, we, therefore, need to find a way to preserve the phase
information during photodetection if we are expected to use optical scanning
to record holographic information. The solution to this problem is optical
heterodyning.
 
Figure 3.5 shows an optical heterodyne detection. The half-silvered
mirror combines two mutually coherent laser beams; the information optical
signal beam and the reference optical signal beam, having temporal
frequencies of 
 and 
, respectively [in the next section, we will show
=
=
H
!
! 
how laser beams of different temporal frequencies can be achieved by using
acousto-optics]. For simplicity, we will consider the information signal and
the reference signal, both as plane waves expressed by 
exp
 and
<
=
:
!
Ð4
>Ñ
F
Ò4Ð

Ñ>Ó
exp
 on the surface of the photodetector, respectively. Hence,
=
H
!
<
<
=
=
>
:
!
!
œ
Ð4
>Ñ 
F
Ò4Ð
exp
exp
3 º
.
(
H
l
B.C
<>
#|
the total field on the surface of the photodetector is
HÑ>Ó. Since the photodetector only detects intensity, the current
output is then given by
Optical Scanning Holography: Principles

70
œ
Ð4
>Ñ F
Ò4Ð

Ñ>Ó .
(
H
l
B.C
<
=
=
H
:
!
!
#
exp
exp
|
œ HÒE F #EF
> 
ÑÓ
#
#
cos(
,
(3.2-1)
H
9
where we assume that the information signal is 
e , which has an
<:
4
œ E
9
amplitude of 
and phase information, . Also, for simplicity, we assume
E
9
that  is real in the above equation. The term, 
, is the DC current (or
F
E F
#
#
the
), whereas the term 
cos(
 is the AC current
 baseband current
EF
> 
Ñ
H
9
(or the 
) due to the 
 or 
 of the two
heterodyne current
mixing
heterodyning
optical signals at different frequencies [Poon (2002b), Poon and Kim
(2006)]. Also note that the amplitude and the phase of the information signal
both have been preserved in the current as it is clearly indicated in the last
term of Eq. (3.2-1). Hence, optical heterodyning can preserve the amplitude
and phase of the information signal. This type of photodetection is known as
Fig. 3.5 Optical heterodyne detection.
Now that we have shown how the current, , contains the amplitude and
3
phase information through heterodyning, we will discuss how to extract this
information electronically. Figure 3.6 shows an electronic multiplexing
detection.
 
The current, , first passes through a bandpass filter that is tuned to
3
the heterodyne frequency, 
, in order to reject the baseband current and to
H
extract the heterodyne current, 
cos(
. The heterodyne current
3
º E
> 
Ñ
H
H
9
splits into two channels to obtain two outputs,  and , as shown in Fig. 3.6.
3
3
-
=
Each channel actually performs 
, which consists of
lock-in detection
electronically multiplying the incoming signal with the cosine or sine of the
heterodyne frequency, and then using lowpass filtering to extract the phase of
the heterodyne current. Let us now see how it is mathematically performed.
Optical Scanning Holography with MATLAB
optical heterodyne detection (or optical coherent detection).

71
First, consider the upper channel where the electronic multiplier gives
3 ‚
>Ñ œ E
> 
Ñ
>Ñ
H
cos(
cos(
cos(
H
H
9
H
œ
E
Ð 
Ñ 
E
Ð# > 
Ñ
"
"
#
#
cos
cos
(3.2-2)
9
H
9
as output, and where we have used the following trigonometric identity:
cos cos
cos
cos
.
!
"
!
"
!
"
œ
Ð

Ñ 
Ð

Ñ
"
"
#
#
Fig. 3.6 Electronic multiplexing detection.
By using a lowpass filter on the output of the multiplier (which means we are
rejecting the frequency of 
), we can obtain the 
of the
#H
in-phase component 
heterodyne current, 
, which is given by
3H
                                               
cos
.
(3.2-3a)
3 œ E
Ð Ñ
-
9
Apart from some constant, Eq. (3.2-3a) is really the first term of Eq. (3.2-2).
Similarly, the lower channel of Fig. 3.6 gives the 
 of
quadrature component
the heterodyne current, 
, which is given by
3H
                                                
sin
,
(3.2-3b)
3 œ E
Ð Ñ
s
9
where we can use the identity,
cos sin
sin
sin
,  
!
"
!
"
!
"
œ
Ð

Ñ 
Ð

Ñ
"
"
#
#
Optical Scanning Holography: Principles

72
to obtain this result. Now, once  and  have been extracted and stored in a
3
3
-
s
computer, we can perform the following complex addition:
3 4 3 œ E
Ð Ñ 4E
Ð Ñ œ E
Ð4 Ñ
-
 
cos
sin
exp
.
(3.2-4)
s
9
9
9
Note that this result is the full recovery of the information signal, 
e ,
<:
4
œ E
9
from the photodetector s current given by Eq. (3.2-1). In fact, we will take
advantage of optical heterodyning and electronic multiplexing detection by
obtaining holographic information without the twin-image noise. We will
return to this topic later.
3.3 Acousto-Optic Frequency Shifting
When we employ optical heterodyning as shown in Fig. 3.5, we need to
create two laser beams of different temporal frequencies. In this section, we
will discuss a common device used for shifting light frequency known as the
acousto-optic frequency shifter
acousto-optic modulator
 (AOFS) or 
 (AOM)
[Korpel (1981)].
Fig. 3.7 Acousto-optic modulator.
An acousto-optic modulator is a spatial light modulator that consists of an
acoustic medium, such as glass, that is bonded to a piezoelectric transducer.
When an electrical signal is applied to the transducer, a sound wave
propagates through the acoustic medium causing perturbations in the index
of refraction, which is  proportional to the electrical excitation. This in turn
modulates the laser beam that traverses the acoustic medium. Thus, the
’
Optical Scanning Holography with MATLAB

73
acousto-optic modulator, as shown in Figure 3.7, may be thought to act
similar to 
 with an effective grating line separation equal to the
phase grating
wavelength, 
, of the sound in the acoustic medium. As it turns out, for a
A
very specific incident angle, 
, the sound grating splits incident light into
9inc
two diffracted beams, namely the 1-st order diffracted beam and the 0-th
"
!
 
One of the simplest explanations used to describe the interaction
between sound and a laser is to treat the interaction as a collision of particles,
namely 
 and 
. In order f
photons
phonons
or these particles to have well-
defined momenta and energies, we must assume that we have an interaction
of plane waves of light and sound. In other words, we assume that the width
of the transducer is sufficiently wide enough to produce plane wave fronts at
a single frequency.
 
We will now consider two conservation laws that exist during the
collison: the 
 and the 
. The
conservation of energy
conservation of momentum
condition for conservation of momentum is
   
 ,  
(3.3-1)
h5
œ h5 hO
t
t
t

!
1
where 
 and 
 are the momenta of the incident photon and phonon,
h5
hO
t
t
!
respectively, and 
 is the momentum of the scattered photon. 
, 
,
h5
5
5
t
t
t


!
1
1
and 
 are the corresponding wavevectors of the particles, and 
/2
O
h œ 2
t
1
where  is 
. Now, from the conservation of energy, we have
2
Planck s constant
h
œ h
h
=
=
H
1
0
,
(3.3-2)
where 
, 
, and 
 are the energies of the scattered photon, incident
h
h
h
=
=
H
1
0
photon, and phonon, respectively. 
, 
, and 
 are the corresponding
=
=
H
1
0
radian frequencies of the particles.
 
After dividing Eq. (3.3-1) by , we have
h
5
œ 5 O
t
t
t

!
1
 .  
(3.3-3)
Also, from Eq. (3.3-2), the corresponding conservation of energy takes the
form
=
=
H
1
0
œ

 
.
 
(3.3-4)
Figure 3.8a) shows the wave-vector interaction diagram and is constructed
based on Eq. (3.3-3). For all practical cases, |
|
|
|, the magnitude of
O ¥ 5
t
t!
5
5
t
t

!
1 is essentially equal to that of
, and the wave-vector triangle shown in
 
Fig. 3.8a) is, therefore, nearly isosceles. Note that the closed triangle in
Figure 3.8a) stipulates that there are certain critical angles of incidence for
the interaction of plane waves of light and sound. The stipulated incident
angle, 
, is called the 
, which is given by
9inc
Bragg angle
9
order diffracted beam at angles 
Fig. 3.7. We shall identify these angles next.
 and 9 , respectively. This is shown in
’
Optical Scanning Holography: Principles

74
sin
 = 
 = 
, 
(3.3-5)
2
2
Ð
Ñ
O
5
9
-
A
B
0
!
where 
 is the wavenumber of light inside the acoustic
5 œ l 5 l œ # Î
t
0
!
!
1 -
medium and 
 is the wavelength of light. 
is the
-
1 A
!
O œ l Ol œ # Î
t
wavenumber of sound and 
 is the wavelength of sound. Note that the
A
diffracted beams differ in direction by an angle equal to 2
 as shown in Fig.
9B
3.8a). 
and 
 in Fig. 3.7 must then be equal to 
.
9
9
9
1
0
B
 
Figure 3.8b) shows that the 1-st diffracted beam is being up-shifted
diffracted beam, 
, has been upshifted by the amount of the sound
=1
frequency, .  It is also clear that since we really do have a traveling sound
H
wave, the frequency of the diffracted light is Doppler shifted.
Fig. 3.8 Acousto-optic interaction:
a) wave-vector diagram, b) experimental configuration.
 
The frequencies of sound waves produced in laboratories range from
about 100 KHz to 3 GHz. Figure 3.9 shows a commercially available
acousto-optic modulator, Model AOM-40, from 
 t
IntraAction Corporation. I
uses dense flint glass as an acoustic medium (refractive index 8 μ "Þ'&Ñ
!
and operates at a sound center frequency of 
40 MHz. Therefore, in Fig.
0 œ
=
3.9, the sound wave travels in the glass from the left to the right at a velocity
of 
~ 4000m/s with a sound wavelength of  = 
/
 ~ 0.l mm. If a He-Ne
Z
Z 0
=
=
=
A
laser is used (its wavelength is about 0.6328
 in air), its wavelength inside
.7
the glass  is 
~ 0.6328
0.3743
. Hence, according to Eq. (3.3-
-
.
.
!
!
7Î8
μ
7
5), the Bragg angle,  inside the acoustic medium is ~ 1.9 
10
radian or
‚
$
about 0.1 degrees. n Fig. 3.9, we have identified the two diffracted laser
I
spots at the far background. The incident laser beam (not visible to the eye as
it traverses across a transparent medium of glass) is traveling through the
glass along the long dimension of the piezoelectric transducer.
Eq. (3.3-4) is called an upshifted interaction because the frequency of the
in frequency as is required by Eq. (3.3-4). The interaction described by 
Optical Scanning Holography with MATLAB

75
Fig. 3.9 Typical acousto-optic modulator operating at 40 MHz
 [Adapted from Poon (2002b)].
3.4  Two-Pupil Optical Heterodyne Scanning Image Processor
We have previously discussed optical scanning and optical heterodyning in
prior sections. We have also discussed pupil function in an optical system,
and we have shown that the pupil function can modify the characteristics of
spatial filtering in an optical system [see Fig. 2.14]. In this section, we are in
a position to discuss optical heterodyne scanning from which optical
scanning holography is based. Since optical heterodyne scanning requires
two optical beams to mix or heterodyne, we must, therefore, have two pupils
in the optical system. One can envision that an optical system that has two
pupils will have greater processing power because spatial filtering will now
be controlled not only by a single pupil, as in conventional optical systems,
but by two pupils. These systems are called 
 [Lohmann and
two-pupil systems
Rhodes (1978), Poon and Korpel (1979)]. The article by Indebetouw and
Poon provides a review of two-pupil approaches on incoherent image
processing [1992].
 
Figure 3.10 shows a typical two-pupil optical heterodyne scanning
image processor, which was originally developed and analyzed by Poon
[1985]. We shall develop some mathematical descriptions of this system,
which will eventually lead to the concept of optical scanning holography.
 
Beamsplitters BS and BS , and mirrors M and M  form the Mach-
"
"
Zehnder interferometer. The pupil, 
, is illuminated by a collimated
: ÐBß CÑ
1
laser at temporal frequency 
. The other pupil, 
, is illuminated by
=!
: ÐBß CÑ
2
the laser of temporal frequency 
. The laser s temporal frequency offset
=
H
! 
by  is introduced by an acousto-optic frequency shifter (AOFS) as shown in
H
’
Optical Scanning Holography: Principles

the figure. Note that the figure shown in Fig. 3.10 is highly schematic
because the details on selecting the first-order diffracted beam, which is the
frequency-shifted beam at frequency 
, emerging from the AOFS are
=
H
! 
not shown. The two pupils are located at the front focal planes of lens L  and
"
L , both with a focal length of . The two pupils are then combined by the
#
0
beamsplitter, BS , in order to focus the light onto the 2-D, 
scanning
"
B C
mirrors, which are located on the back focal plane of lenses L  and L  The
"
#Þ
combined optical beams are then used to 2-D raster scan over an object of
amplitude distribution, 
, which is located at a distance of  away
>!ÐBß Cà DÑ
D
from the focal plane of the two lenses. Lens L  is used to collect all the
3
transmitted light (or scattered light if the object is diffusely reflecting) onto
the photodetector (PD), which gives 
 as its current output. An
3ÐBß CÑ
electronic bandpass filter (BPF) tuned at the heterodyne frequency of H
provides an output of a scanned and processed current 
. We shall
3 ÐBß CÑ
H
further develop the mathematical expression of 
.
3 ÐBß CÑ
H
Fig. 3.10 A typical two-pupil optical heterodyne scanning system.
 
The combined optical scanning complex field, 
, located at a
WÐBß Cà DÑ
distance of  away from the focal plane of the two lenses, is given by
D
WÐBß Cà DÑ œ T Ð
Ñ
Ð4
>Ñ
T Ð
Ñ
Ò4Ð
Ñ>Ó
5 B 5 C
5 B 5 C
0
0
0
0
"D
!
#D
!
!
!
!
!
,
 exp
 + 
,
exp
+
 ,
=
=
H
(3.4-1)
76
Optical Scanning Holography with MATLAB

77
where 
,
 is the field distribution  away from the scanning mirrors
T Ð
Ñ
D
3D
5 B 5 C
0
0
!
!
and through Fresnel diffraction is given by  
ß
T Ð
Ñ œ T Ð
Ñ‡ 2ÐBß Cà DÑ 3 œ "ß #
5 B 5 C
5 B 5 C
0
0
0
0
3D
3
!
!
!
!
,
,
, 
.
   
(3.4-2)
In Eq. (3.4-2), 
,
 is the field distribution in the back focal plane of
T Ð
Ñ
3
5 B 5 C
0
0
!
!
lenses L  and L , and apart from some inessential constant and a constant
"
#
phase factor, is given by [see Eq. (2.4-6)]
  
,
 =  
(
 .
(3.4-3)
T Ð
Ñ
Ö: Bß CÑ×
5 B 5 C
0
0
3
3
!
!
Y
º
5Cœ5 CÎ0
!
5 œ5 BÎ0
B
!
Now, as previously mentioned, the combined optical field or the scanning
pattern, given by Eq. (3.4-1), is used to two-dimensionally scan an object
with an amplitude transparency of 
;
 located at a distance  from the
>0ÐBß C DÑ
D
scanning mirrors. According to the principle established by Eq. (3.1-3) for
optical scanning, the photodetector, which responds to the incident intensity
of the optical transmitted field or scattered field, generates a current given by
3ÐBß Cà DÑ º
l
B .C
(
H
w
w
WÐB ß C à DÑ
ÐB Bß C Cà DÑ .
w
w
w
w
#
!
>
|
œ
T Ð
Ñ
Ð4
>Ñ
T Ð
Ñ
Ò4Ð
Ñ>Ó
5 B 5 C
5 B 5 C
0
0
0
0
( º
H
’
“
"D
!
#D
!
!
!
!
!
w
w
w
w
,
 exp
 + 
,
exp
+
 
=
=
H
‚
ÐB B ß C C à DÑ .B .C
>!
w
w
w
w
#
º
.
(3.4-4)
After a bandpass filter (BPF) is tuned to a frequency of 
, the heterodyne
H
current from Eq. (3.4-4) becomes
3 ÐBß Cà DÑ œ
T Ð
Ñ T Ð
Ñ
5 B 5 C
5 B 5 C
0
0
0
0
H
Re
,
 
,
’(
H
"D
!
!
!
!
w
w
w
w
#D
*
‚ l
ÐB B ß C C DÑl .B .C
Ð4 >Ñ
>
H
!
w
w
#
w
w
;
exp
,
(3.4-5)
“
where we have adopted the convention for the phasor 
as 
<
<
: 
ÐBß Cß >Ñ œ
Re
exp
) , where Re
denotes the real part of the content
Ò
ÐBß Cß >Ñ
Ð4 > Ó
ÒÞÓ
<
H
: 
inside the bracket. Equation (3.4-5) can be written as
Optical Scanning Holography: Principles

3 ÐBß Cà DÑ
Ò3
ÐBß Cà DÑ
Ð4 >ÑÓ
H
H
 = Re
exp
,
(3.4-6a)
:
H
where
3
ÐBß Cà DÑ œ
T Ð
ÑT Ð
Ñ
5 B 5 C
5 B 5 C
0
0
0
0
H:
( (
H
"D
!
!
!
!
w
w
w
w
#D
*
,
,
(3.4-6b)
‚ l
ÐB B ß C C DÑl .B .C
>!
w
w
#
w
w
;
is the output phasor containing the amplitude and the phase information of
the heterodyne current. The amplitude and the phase information of the
current constitute the scanned and the processed version of the object
l
l
>! #and from Eq. (3.4-6), we can write
3 ÐBß Cà DÑ œ 3
ÐBß Cà DÑ
ÒÐ > 
ÐBß Cà DÑÓ
H
H
|
|cos
,
:
H
9:
where 
|
|exp
. Note that we can re-write Eq. (3.4-6b) in terms of
3
œ 3
Ð4
Ñ
H
H
:
:
9:
the following correlation:
    
,
 
,
;
.
(3.4-7)
3
ÐBß Cà DÑ œ T Ð
Ñ T Ð
Ñ
l
ÐBß C DÑl
5 B 5 C
5 B 5 C
0
0
0
0
H:
"D
!
!
!
!
!
#D
#
*
Œ >
Similar to conventional optical scanning systems (or incoherent optical
systems), only the intensity distribution, i.e., 
 will be processed and the
l
l
>! #
optical system is therefore incoherent. However, 
 is not strictly
l
l
>! #
processed by an intensity quantity, and as indicated by Eq. (3.4-7) the
processing element,
, can be bipolar or even complex, thereby leading
T T
"D
#D
*
to the concept of 
.
complex incoherent image processing
 
Equation (3.4-7) relates the input quantity to the output quantity and
from this we can now define the optical transfer function (OTF) of the
system to be
 
;
.
(3.4-8)
SXJ Ð5 ß 5 à DÑ œ
Ö3
ÐBß Cà DÑ×Î
Öl
ÐBß C DÑl ×
H
H
B
C
!
#
Y
Y
>
:
By taking the Fourier transform of Eq. (3.4-7) and combining its result with
Eq. (3.4-8), we obtain the equivalent,
SXJ Ð5 ß 5 à DÑ œ
Ö T Ð
Ñ T Ð
Ñ×
Ð
Ñ
5 B 5 C
5 B 5 C
0
0
0
0
H
B
C
‡
‡
"D
#D
!
!
!
!
Y
,
 
,
.
3.4-9
In terms of the pupils 
and
, we substitute Eqs. (3.4-2) and (3.4-3) into
:
:
"
#
 
Eq. (3.4-9) to get
78
Optical Scanning Holography with MATLAB

79
SXJ Ð5 ß 5 à DÑ œ
Ò4
Ð5
5 ÑÓ
D
#5
H
B
C
!
#
#
B
C
exp
 + 
‚
: ÐB C Ñ: ÐB 
5
C 
5 Ñ
Ò4
ÐB 5 C 5 ÑÓ.B .C
0
0
D
5
5
0
( (
‡
w
w
w
w
w
w
w
w
"
#
!
!
B
C
B
C
, 
,
exp
.
(3.4-10)
This equation was first derived by Poon [1985], and it states that the optical
transfer function of the system, 
, can be modified based on the
SXJH
we obtain
ß
H
3 ÐBß Cà DÑ œ
Ò3
ÐBß Cà DÑ
Ð4 >ÑÓ
H
H
Re
exp
:
H
œ
Ò
Ö
Öl
ÐBß Cà DÑl ×SXJ Ð5 ß 5 à DÑ×
Ð4 >ÑÓÞ
Re
exp
Y
Y
>
H
"
#
!
B
C
H
(3.4-11)
By defining the spatial impulse response (or the point spread function) of the
optical heterodyne scanning system as
 
, 
(3.4-12)
2 ÐBß Cà DÑ œ
ÖSXJ ×
H
H
Y "
we can now re-write Eq. (3.4-11) in the spatial domain as
          
Re
exp
.
3.4-13
3 ÐBß Cà DÑ œ
Òl
ÐBß Cà DÑl ‡2 ÐBß Cà DÑÓ
Ð4 >Ñ
Ð
Ñ
H
H
š
›
>
H
!
#
Equation 3.4-11  or (3.4-13) represents the scanned and processed output
Ð
Ñ
current, which is modulated by a temporal carrier at a frequency of 
. By
H
H
     
Re
   (frequency domain)
3 ÐBß Cà DÑ œ
Ò
Ö
Öl
l ×SXJ ×Ó
-
!
"
#
Y
Y
>
H
Ð
Ñ
3.4-14a
#
H
and
     
Im
    (frequency domain)
3 ÐBß Cà DÑ œ
Ò
Ö
Öl
l ×SXJ ×Ó
=
!
"
#
Y
Y
>
H
 
Im
,             (spatial domain)
3.4-14b
œ
Òl
l ‡2 ÐBß Cà DÑÓ
Ð
Ñ
>! #
H
where Im[.] denotes the imaginary part of the quantity within the bracket.
The subscripts c
and 
s
represent the use of cos
 and sin
Ð >Ñ
Ð >Ñ
H
H
respectively, to extract the information from 
.
3H
Eq. (3.4-6a) in terms of SXJ
selection of the two pupils. Now, by using Eq. (3.4-8) and by re-writing
 
3
H>
mixing 
 with cos(
) or sin(
), we can demodulate and extract the 
H>
dulation system is shown in Fig. 3.6, and the two outputs are given by
“ ”
“ ”
Optical Scanning Holography: Principles
in-phase component or the quadrature component, respectively. The demo-
œ ReÒl> l ‡2 ÐBß Cà DÑÓ             (spatial domain)
!

 
In Eqs. (3.4-14), we have assumed that the input object,
l
ÐBß Cà DÑl
D
>!
#, is an infinitely thin 2-D object located at a distance of  away
from the 2-D scanning mirrors shown in Fig. 3.10. To generalize Eqs. (3.4-
14) for 3-D objects we need to integrate the equations over the depth, i.e.,
ß
over , of the 3-D objects. Eqs. (3.4-14) then become [Poon and Kim (1999)]
D
3 ÐBß CÑ œ
Ò
Ö
Öl
ÐBß Cà DÑl ×SXJ ×.DÓ
-
!
"
#
Re
(3.4-15a)
( Y
Y
>
H
œ
Ò
l
ÐBß Cà DÑl ‡2 ÐBß Cà DÑ.DÓ
Re
(3.4-15b)
( >!
#
H
and
3 ÐBß CÑ œ
Ò
Ö
Öl
ÐBß Cà DÑl ×SXJ ×.DÓ
=
!
"
#
Im
(3.4-15c)
( Y
Y
>
H
œ
Ò
l
ÐBß Cà DÑl ‡2 ÐBß Cà DÑ.DÓ
Ð
Ñ
Im
.
3.4-15d
( >!
#
H
Note that we have left the -dependence out on the left-hand side of Eqs.
D
(3.4-15) to emphasize that the recorded information is strictly 2-D even for 3-
D objects. 
 and 
 represent the scanned and processed current
3 ÐBß CÑ
3 ÐBß CÑ
-
=
(or information) of 
and can be stored as 2-D records if these currents are
l
l
>! #
stored in synchronization with the signals used to drive the  
 scanning
B C
mirrors. Equations (3.4-15) represent the major results  of the two-pupil
optical heterodyne scanning of a 3-D object. Figure 3.11 shows the overall
two-pupil optical heterodyne image processor. The 3-D object is
l
ÐBß Cà DÑl
3 ÐBß CÑ
>!
-
#, and the final outputs given by Eqs. (3.4-15) are 
and
3 ÐBß CÑ
=
. Note that while the input object is given by the amplitude
distribution, 
, the information that can be processed is the intensity
>!ÐBß Cà DÑ
distribution given by 
. As it turns out, this is the incoherent
l
ÐBß Cà DÑl
>!
#
mode of operation for the processor, which has so far been inclusively used
chapter 4, we will further elaborate on some of these applications. In chapter
5, when we consider the advancements towards optical scanning holography,
we will describe a coherent mode where the complex distribution of the
object can be processed [Indebetouw, Klysubun, Kim, and Poon (2000)].
This can be important when we deal with the phase specimens in biological
applications.
80
3-D pattern recognition, optical remote sensing, and 3-D cryptography. In
for various applications such as 3-D fluorescence holographic microscopy,
Optical Scanning Holography with MATLAB

81
Fig. 3.11 The complete two-pupil optical scanning image processor.
3.5  Scanning Holography
In this section, we will discuss how holographic recording can be
accomplished by using the two-pupil optical heterodyne scanning image
processor discussed in the last section. The idea was first implicated by Poon
and Korpel [1979]. They realized that interesting OTF s can be obtained by
drastically modifying one of the pupils in relation to the other. In this
context, it is intriguing to realize that there exists a possibility of creating a
Fresnel-zone-plate-type impulse response (i.e., its phase is a quadratic
function of  and  ) in an out-of-focus plane near the focal plane of lenses
B
C
L1 and L2, i.e.,  away from the scanning mirrors shown in Fig. 3.11, by
D
making 
uniform and 
a delta function. When investigating
: ÐBß CÑ
: ÐBß CÑ
"
#
the chirp property, we can determine how far  is from the scanning mirrors,
D
and thus, it carries obvious implication to holographic recording. The
original idea, which was later analyzed and called scanning holography
[Poon (1985)], is to scan the 3-D object in a 2-D raster with a complex
’
Optical Scanning Holography: Principles

Fresnel-zone-plate-type impulse response created by the interference of a
point source and a plane wave emerging from each pupil. A temporal
frequency offset is introduced between the two pupils, and the desired signal
from a spatially integrating detector is obtained using a heterodyne detection.
 
Hence, for scanning holography we mathematically let : ÐBß CÑ œ "
"
and 
, which are both clearly pictured in Fig. 3.11. With this
: ÐBß CÑ œ ÐBß CÑ
#
$
choice of pupils, according to Eq. (3.4-10), the OTF of the heterodyne
scanning system becomes
SXJ Ð5 ß 5 à DÑ
œ
Ò 4
Ð5
5 ÑÓ
D
#5
H
B
C
!
#
#
B
C
ºosh
exp
 + 
œ SXJ
Ð5 ß 5 à DÑ
Ð
Ñ
osh
B
C
,
3.5-1a
and according to Eq. (3.4-12), the corresponding spatial impulse response is
         2 ÐBß Cà DÑ
œ
H
ºosh
45
45 ÐB C Ñ
# D
#D
Ò
Ó
!
!
#
#
1
exp
.
(3.5-1b)
Apart from the constant phase factor, it is interesting to point out that by
comparing the spatial frequency transfer function in Fourier optics [see Eq.
(2.3-13)] to Eq. (3.5-1a),  we have
 
 
 
*
,
(3.5-2a)
SXJ
Ð5 ß 5 à DÑ œ L Ð5 ß 5 à DÑ
osh
B
C
B
C
and similarly in reference to Eq. (2.3-11), we have
 
 
     
*
.
(3.5-2b)
2 ÐBß Cà DÑ
2 ÐBß Cà DÑ
H
ºosh œ
From the result of Eq. (3.5-1b) for scanning holography, apart from some
constant, the spatial domain equations, Eqs. (3.4-15b) and (3.4-15d), become
            
sin
3 ÐBß CÑ œ
l
ÐBß Cà DÑl ‡
Ò
Ð
.D
-
!
#
( š
›
>
5
5
# D
#D B C ÑÓ
!
!
#
#
1
        
(3.5-3a)
œ L
ÐBß CÑ
sin
and
           
(3.5-3b)
3 ÐBß CÑ œ
l
ÐBß Cà DÑl ‡
Ò
Ð
.D
=
!
#
( š
›
>
5
5
# D
#D B C ÑÓ
!
!
#
#
1 cos
                        
,
œ L
ÐBß CÑ
cos
82
Optical Scanning Holography with MATLAB

83
respectively. What is being two-dimensionally recorded is a hologram.
L
ÐBß CÑ
L
ÐBß CÑ
sin
cos
 is called the 
, and 
 is the 
sine-FZP hologram
cosine-FZP
hologram of 
.
l
ÐBß Cà DÑl
>!
#
 
To see why Eqs. (3.5-3) correspond to holographic recordings, we
will let 
, which is a point source located 
l
ÐBß Cà DÑl œ ÐBß CÑ ÐD D Ñ
D
>
$
$
!
!
!
#
away from the scanning mirrors. Then Eq. (3.5-3a) becomes
         
sin
L
ÐBß CÑ œ
ÐBß CÑ ÐD D Ñ‡
Ò
Ð
.D
sin
( š
›
$
$
!
5
5
# D
#D B C ÑÓ
!
!
#
#
1
         
sin
œ
ÐD D Ñ
Ò
Ð
.D
( š
›
$
!
5
5
# D
#D B C ÑÓ
!
!
#
#
1
after the 2-D convolution involving  and . And finally, after the integration
B
C
along , the above equation becomes
D
L
ÐBß CÑ œ
Ò
Ð
D
D
sin
5
5
#
#
B C ÑÓ
!
!
#
#
1 !
!
sin
.
(3.5-4a)
Note that this is basically the hologram of a point source without the constant
bias of 
, which appears in Eq. (2.5-4). The constant bias simply gives a
E
zero-order beam upon optical reconstruction. Similarly, Eq. (3.5-3b) gives
L
ÐBß CÑ œ
Ò
Ð
D
D
cos
5
5
#
#
B C ÑÓ
!
!
#
#
1 !
!
cos
.
(3.5-4b)
In summary, in scanning holography for a single 2-D raster-scan we have
two records of the holograms, due to electronic multiplexing detection. Both
of the holograms given by Eq. (3.5-3) contain holographic information, but
they are not redundant as we will later see that with the two holograms, we
can obtain a
 hologram even the recording is made on-axis.
  twin-image-free
 
Figure 3.12 shows the very first hologram using scanning
holography [Duncan and Poon (1992)]. The hologram is a slit with the size
of 50 m. The term 
 was first coined in this
.
 
optical scanning holography
article to emphasize that this was the first electronic hologram created by
using the active optical scanning technique. To put optical scanning
holography into perspective, holograms obtained by scanning techniques at
long wavelengths have long been achieved. This has been possible because
there is no need to supply a physical reference beam in order to extract
holographic information because detectors that are capable of measuring the
 
In general, optical scanning holography (OSH) can be applied to
other shorter and longer wavelength systems as long as we can find devices
“
”
oscillation of low-frequency radiation (such as acoustic waves or micro-
waves) are commonly available, permitting amplitude and phase informa-
tion to be directly extracted from long wavelength signals.
Optical Scanning Holography: Principles

of that particular wavelength that can generate a collimated beam and a
focused beam so that the two beams interfere on the object. In addition, a
frequency shifter for that wavelength must be available. In a more futuristic
vision, 
 for active optical remote sensing can be
CO  scanning holography
#
possible as 10.6 m can penetrate the atmosphere with little absorption. At
.
the other end of the light spectrum, 
 is becoming a
X-ray scanning holography
reality because of the increasing existence of X-ray lasers, which should be
Fig. 3.12 The first hologram obtained using optical scanning holography: solid line:
theoretical results; dotted line: experimental results. The object is a 50 m-slit. Reprinted from
.
Duncan and Poon, JOSA A 9, 229 (1992), with permission. © OSA.
 
 
The extension of the capabilities of one-dimensional to two-
dimensional imaging by using optical scanning holography was subsequently
demonstrated by Poon, Doh, Schilling, Wu, Shinoda, and Suzuki [1995]. Fig.
3.13 shows a hologram of a pinhole object. A sine-hologram of the pinhole is
shown (this is the well-known FZP). The pinhole is about 50 m in diameter
.
and approximately 10 cm away from the 2-D scanning mirrors. The plane
wave on the pinhole is about 10mm, and comes from a collimated HeNe
laser. The spherical wave on the pinhole comes from a focused laser beam of
a size of about 3.5 m. The temporal frequency difference between the plane
.
wave and the spherical wave is 40 MHz. In the same paper mentioned, the
authors reported the first 3-D imaging capability using optical scanning
holography. Three-dimensional imaging was demonstrated by digitally
reconstructing an acquired hologram to show various depths of an image.
84
important if atomic resolution for 3-D specimens is required. In the remain-
der of the book, we shall use the term optical scanning holography or OSH
−3.0
−1.75
−0.88
0.00
−0.88
1.75
−2.5
−2.0
−1.5
−1.0
−0.5
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0
INTENSITY
x(mm)
Optical Scanning Holography with MATLAB
instead of scanning holography.

85
Fig. 3.13 Sine-hologram of a pinhole. The first 3-D imaging capability using OSH is also
reported in the paper. Reprinted from T.-C. Poon at al., Optical Engineering 34, 1338,
with permission. © 1995 SPIE.
 
We have discussed the twin-image problem in on-axis holography.
And off-axis (or carrier-frequency) holography has been employed to avoid
the annoying effect of the twin-image. One of the most popular electronic
holographic techniques used to obtain reconstruction free of the twin image
is called 
[Yamaguchi and Zhang (1997)]  This
phase-shifting holography 
.
Using optical scanning holography, we only need to perform a single 2-D
scan in order to simultaneously obtain two on-axis holograms - namely the
sine-hologram and the cosine-hologram. Since the two holograms can be
stored  digitally, we can perform a complex addition or subtraction as
follows:
L
ÐBß CÑ œ
-„
L
ÐBß CÑ „ 4L
ÐBß CÑ
cos
sin
   
,
(3.5-5)
œ
l
ÐBß Cà DÑl ‡
Ò „ 4
Ð
.D
( š
›
>!
#
5
5
# D
#D B C ÑÓ
!
!
#
#
1 exp
where we have used Eqs. (3.5-3a) and (3.5-3b). L
ÐBß CÑ
-„
 is called a
complex Fresnel zone plate hologram, which contains no twin-image
information [Doh, Poon, Wu, Shinoda, and Suzuki (1996)]. To better
understand this, we will construct a complex hologram for a point object.
Substituting Eqs. (3.5-4a) and (3.5-4b) into Eq. (3.5-5), and apart from some
constant, we have
                        
.
(3.5-6)
L
ÐBß CÑ œ
Ò „
Ð
4
D
-„
!
exp
5
#
B C ÑÓ
!
#
#
on-axis holograms in order to calculate the phase of the complex object wave.
technique employs phase-shifting on the reference beam to obtain four
Optical Scanning Holography: Principles

According to Eqs. (2.5-6b) and (2.5-6c), this hologram can construct either a
real point source or a virtual point source, depending on the sign of the
argument being chosen in Eq. (3.5-6). For the positive sign in the argument,
we will have a real image reconstruction, and for the negative sign, we will
have a virtual image reconstruction. In either case, there is no twin-image
formation within the complex hologram.
Fig. 3.14 Twin-image elimination with two holograms: a) Cosine-hologram. b) Sine-
hologram. c) Reconstruction of a), the cosine-hologram, focused on the square (twin-image
noise noticeable). d) Reconstruction of the complex hologram, focused on the square (no
twin-image noise). e) Reconstruction of a), focused on the triangle (twin-image noise
noticeable). f) Reconstruction of the complex hologram, focused on the triangle (no twin-
image noise). Reprinted from Poon et al., Optics Letters 5, 215, (2000),
 with permission. © OSA.
Figure 3.14 shows the experimental results of eliminating the twin image for
three-dimensional images in optical scanning holography. In the experiment,
the 3D object consisted of two 35-mm slides that were set up side-by-side
and at different distances from the scanning beam. One slide is a square, and
the other is a triangle. The depth difference between the two slides is 15-cm.
Figure 3.14a) and b) show the cosine- and sine-holograms, respectively.
Figure 3.14c) shows the reconstruction of the cosine-hologram. This
86
Optical Scanning Holography with MATLAB

87
reconstruction is focused on the square object but is spoiled by twin-image
noise. In Fig. 3.14d), where the complex hologram is used to reconstruct and
focus on the square object, twin-image noise is not present. In Fig. 3.14e),
the cosine hologram reconstructs an image that is focused on the triangle but
spoiled by twin-image noise. In fig. 3.14f), the complex hologram gives a
reconstruction without twin-image noise. Thus, the elimination of twin-
image in optical scanning holography has been demonstrated using only two
holograms. In the demonstration, the use of digital reconstruction has been
employed. By using two SLM’s (one for the display of a sine-hologram and
the other for a cosine-hologram), we can achieve all-optical reconstruction.
However, this has yet to be demonstrated optically [Poon (2006)].
Example 3.1      MATLAB Example: Optical Scanning Holography
By substituting the OTF of optical scanning holography, given by Eq. (3.5-
1a), into Eqs. (3.4-15a) and (3.4-15c), the sine-hologram and the cosine-
hologram will be expressed in terms of spatial frequencies. Therefore, we
have
3 ÐBß CÑ œ
Ò
Ö
Öl
ÐBß Cà DÑl ×SXJ
5 ß 5 à D ×.DÓ
-
!
B
C
"
#
Re
(
)
( Y
Y
>
osh
   
(3.5-7a)
œ L
ÐBß CÑ
sin
and
3 ÐBß CÑ œ
Ò
Ö
Öl
ÐBß Cà DÑl ×SXJ
5 ß 5 à D ×.DÓ
s
osh
Im
(
)
( Y
Y
>
"
#
!
B
C
   
,
(3.5-7b)
œ L
ÐBß CÑ
cos
where 
(
)
exp
 + 
. For this example, we are
SXJ
5 ß 5 à D œ
Ò 4
Ð5
5 ÑÓ
osh
B
C
D
#5
#
#
B
C
!
assuming a planar object to be at a distance of 
 away from the x-y scanning
D!
mirrors, i.e., 
, where 
 is the planar
l
ÐBß Cà DÑl œ MÐBß CÑ ÐD D Ñ
MÐBß CÑ
>
$
!
!
#
intensity distribution shown in Fig. 3.15a). For the planar intensity object,
after integrating over , Eqs. (3.5-7a) and (3.5-7b)  become
D
    
 
Re
(
)
(3.5-8a)
L
ÐBß CÑ œ
Ò
Ö
ÖMÐBß CÑ×SXJ
5 ß 5 à D ×Ó
sin
osh
Y
Y
"
B
C
!
and
 
Im
(
) ,
(3.5-8b)
L
ÐBß CÑ œ
Ò
Ö
ÖMÐBß CÑ×SXJ
5 ß 5 à D ×Ó
cos
osh
Y
Y
"
B
C
!
Optical Scanning Holography: Principles

respectively. The above holograms are simulated and shown in Fig. 3.15b)
and Fig. 3.15c), respectively where sigma
 in OSH.m listed
œ D Î#5 œ #Þ!
!
!
in Table 3.1. We can also construct a complex FZP hologram by using Eq.
(3.5-5):
L ÐBß CÑ œ
-+
L
ÐBß CÑ 4L
ÐBß CÑ
cos
sin
  
(
)
(3.5-9)
œ
ÖMÐBß CÑ×SXJ
5 ß 5 à D
Y
Y
"
B
C
!
Ö
×
osh
.
For digital reconstruction, we will simply convolve the above holograms
with the spatial impulse response in order to simulate Fresnel diffraction for a
distance of 
. To obtain real image reconstruction formed in front of the
D!
hologram, we will use the following equation:
L
ÐBß CÑ‡2ÐBß Cà D Ñ
any
! ,
where 
 represents any one of the above holograms, i.e., the sine-
L
ÐBß CÑ
any
hologram, the cosine-hologram or the complex hologram. In OSH.m, the
above equation is implemented in the Fourier domain using the following
equation [see Eqs. (1.2-3a) and (1.2-3b)]:
  
Reconstructed real image
º
ÖL
ÐBß CÑ×LÐ5 ß 5 à D Ñ
Y
Y
"
B
C
!
Ö
×
any
     
*(
) ,
(3.5-10)
œ
ÖL
ÐBß CÑ×SXJ
5 ß 5 à D
Y
Y
"
B
C
!
Ö
×
any
osh
where we have used Eq. (3.5-2a) to relate 
 with the spatial frequency
SXJosh
response, 
, to obtain the last step. Figures 3.15d), e) and f) show
LÐ5 ß 5 à D Ñ
B
C
!
the reconstruction of the sine-hologram, the cosine-hologram, and the
complex hologram, respectively.
 
Note that if the complex hologram is constructed as
            
   
,
L
ÐBß CÑ œ
-
L
ÐBß CÑ 4L
ÐBß CÑ
cos
sin
then it will have a reconstructed virtual image that is located at a distance of
D! behind the hologram. However, if we perform
L
ÐBß CÑ‡2ÐBß Cà D Ñ
-
!
for reconstruction, we will see a severely out-of-focus image formed at
!
diffraction pattern of the original object at a distance of 
.
D œ #D!
88
Optical Scanning Holography with MATLAB
D œ D  as shown in Fig. (3.15g), which is equivalent to the Fresnel

89
Fig. 3.15 Simulation results using OSH.m.
Optical Scanning Holography: Principles

   Table 3.1 OSH.m : m-file for illustrating optical scanning holography.
------------------------------------------------------
% OSH.m
% Adapted from "Contemporary Optical Image Processing with MATLAB,"
% by Ting-Chung Poon and Partha Banerjee, Table 7.2,
% Pages 222-223, Elsevier (2001).
clear all,
%%Reading input bitmap file
I=imread('vatech.bmp','bmp');
I=I(:,:,1);
figure(1)%displaying input
colormap(gray(255));
image(I)
title('Original image')
axis off
pause
%%Creating OTFosh with SIGMA=z/2*k0 (Eq.(3.5-1a))
ROWS=256;
COLS=256;
sigma=2.0; %not necessary to scale
%kx,ky are spatial frequencies
ky=-12.8;
for r=1:COLS,
   kx=-12.8;
   for c=1:ROWS,
        OTFosh(r,c)=exp(-j*sigma*kx*kx-j*sigma*ky*ky);
        kx=kx+.1;
        end
   ky=ky+.1;
end
max1=max(OTFosh);
max2=max(max1);
scale=1.0/max2;
OTFosh=OTFosh.*scale;
%Recording hologram
% Taking Fourier transform of I
FI=fft2(I);
FI=fftshift(FI);
max1=max(FI);
max2=max(max1);
scale=1.0/max2;
FI=FI.*scale;
% FH is the recorded hologram in Fourier domain
FH=FI.*OTFosh;
H=ifft2(FH);
max1=max(H);
max2=max(max1);
scale=1.0/max2;
90
Optical Scanning Holography with MATLAB

91
H=H.*scale;
figure(1)
colormap(gray(255));
%Displaying the real part becomes sine-FZP hologram
% Eq. (3.5-8a)
image(2.5*real(256*H));
title('Sine-FZP hologram')
axis off
figure(2)
colormap(gray(255));
%Displaying the imaginary part becomes cosine-FZP hologram
% Eq. (3.5-8b)
image(2.5*imag(256*H));
title('Cosine-FZP hologram')
axis off
%Reconstructing holograms
%Reconstruction of sine-hologram,twin-image noise exists
figure(3)
colormap(gray(255))
H=ifft2(FH);
FRSINEH=fft2(real(H)).*conj(OTFosh); %Eq. (2.5-10)
RSINEH=ifft2(FRSINEH);
image(256*abs(RSINEH)/max(max(abs(RSINEH))))
title('Reconstruction of sine-FZP hologram')
axis off
%FH=FHI;
%Reconstruction with cosine-hologram, twin-image noise exists
figure(4)
colormap(gray(255))
FRCOSINEH=fft2(imag(H)).*conj(OTFosh);
RCOSINEH=ifft2(FRCOSINEH); %Eq. (3.5-10)
image(256*abs(RCOSINEH)/max(max(abs(RCOSINEH))))
title('Reconstruction of cosine-FZP hologram')
axis off
figure(5)
colormap(gray(255))
FRCOMPLEXH=fft2(real(H)+j*imag(H)).*conj(OTFosh);
RCOMPLEX=ifft2(FRCOMPLEXH);
image(1.4*256*abs(RCOMPLEX)/max(max(abs(RCOMPLEX))))
title('Real image reconstruction of complex FZP hologram,Hc+')
axis off
figure(6)
colormap(gray(255))
FRCOMPLEXH2=fft2(real(H)-j*imag(H)).*conj(OTFosh);
RCOMPLEX2=ifft2(FRCOMPLEXH2);
image(1.4*256*abs(RCOMPLEX2)/max(max(abs(RCOMPLEX2))))
title('Reconstruction of complex FZP hologram, Hc-')
axis off
------------------------------------------------------
Optical Scanning Holography: Principles

3.6  Physical Intuition to Optical Scanning Holography
While we have devoted the last section to developing optical scanning
holography from a mathematical point of view, in this section we will be
describing optical scanning holography from a physical point of view. Again,
to accomplish optical scanning holography, we select 
 and
: ÐBß CÑ œ "
"
: ÐBß CÑ œ ÐBß CÑ
#
$
 in the two-pupil heterodyne image processor (the situation
is shown in Fig. 3.10 clearly) where lens L1 forms a point source and lens L2
forms a plane wave on the scanning mirrors. At a distance of 
 away
D œ D!
from the scanning mirrors, where the object, l
ÐBß Cà DÑl œ MÐBß CÑ
>!
#
$ÐD D Ñ
! , is located, we have an interference between a plane wave and a
spherical wave of different temporal frequencies. Hence, the scanning beam
intensity is
M
ÐBß Cà >Ñ
scan
œ l +
Ò4Ð
Ñ>Ó 
Ò 
Ó
Ð4
>Ñl
45
45 ÐB C Ñ
D
#D
exp
+
 exp
exp
2
=
H
=
1
!
!
!
!
!
!
#
2
2
   
 
2
œ E F
Ò
ÐB C Ñ 
>Ó
5
D
sin
!
!
2
2
H
           
,
(3.6-1)
œ
ÐBß Cà D ß >Ñ
TDFZP
!
where we have assumed that the plane wave is of amplitude , and  and 
+
E
F
have been defined in Eq. (2.5-3). Note that this equation is basically the same
form as that of Eq. (2.5-4) for the recording of an on-axis point source except
for the time variable, . We shall call this a 
>
time-dependent Fresnel zone
plate (TDFZP), which is used to scan over the object in a raster fashion. For
a pinhole object, i.e., 
, the photodetector s current, 
,
MÐBß CÑ œ ÐBß CÑ
3ÐBß CÑ
$
is clearly given by 
 as the pinhole samples the intensity
TDFZPÐBß Cà D ß >Ñ
!
pattern, which then gives the intensity pattern as output. We can also see
mathematically that if we make use of Eq. (3.1-4), we can obtain
  
3ÐBß CÑ μ
ÐBß Cà D ß >Ñ
TDFZP
!
Œ ÐBß CÑ
$
   
œ
ÐBß Cà D ß >Ñ
TDFZP
!
œ E F
Ò
ÐB C Ñ 
>ÓÞ
5
D
 
2
sin
!
!
2
2
H
After bandpass filtering at , the heterodyne current becomes
H
92
’
Optical Scanning Holography with MATLAB

93
   
,
(3.6-2)
2
3 ÐBß CÑ μ
Ò
ÐB C Ñ 
>Ó
5
D
H
sin
!
!
2
2
H
and after electronic detection, i.e., multiplying with, say cos
, and
Ð >Ñ
H
lowpass filtering, we obtain
3 ÐBß CÑ μ
Ò
ÐB C ÑÓ
5
D
-
!
!
sin 2
,
(3.6-3)
2
2
which is again Eq. (3.5-4a). So we can see that optical scanning holography
is simply accomplished by raster-scanning a TDFZP over a 3-D object in
order to obtain two holograms. The physical situation is shown in Fig. 3.16,
where in the pupil plane, we have a point source and a plane wave. In the
figure, we show the pattern of the scanning beam on the object slice for a
fixed time, say, at 
, which becomes a “static” Fresnel zone plate
> œ > œ !
!
(FZP). If we let the time run in Eq. (3.6-1), we will physically have running
fringes that will be moving toward the center of the zone pattern. Hence, the
basic principle of OSH is to simply use the TDFZP to 2-D scan a 3-D object
to obtain holographic information for the scanned object. The m-file
presented in Table 3.2 will allow us to generate a TDFZP and illustrate the
running of fringes.
 Fig. 3.16 Principle of OSH: use of time-dependent Fresnel zone plate to scan over an object.
Adapted from T. -C. Poon, Journal of Holography and Speckle 1, 6-25, (2004).
Optical Scanning Holography: Principles

 
We can also select the pupils differently to achieve optical scanning
holography as long as we can create a time-dependent FZP to scan the 3-D
object. For example, we can select 
 and 
1
: ÐBß CÑ œ ÐBß CÑ
: ÐBß CÑ œ
"
#
$
instead of 
1 and 
 as we had previously
: ÐBß CÑ œ
: ÐBß CÑ œ ÐBß CÑ
"
#
$
discussed in the two-pupil heterodyne image processor. Then, the scanning
intensity become
M
ÐBß Cà >Ñ
scan
œ l +
Ð4
>Ñ 
Ò 
Ó
Ò4Ð
Ñ>Ó l
45
45 B C Ñ
D
#D
exp
 exp
exp
+
2
(
=
=
H
1
!
!
!
!
!
!
#
2
2
œ E F
Ò
ÐB C Ñ 
>Ó
5
D
 
2
sin
!
!
2
2
H
        
.
(3.6-4)
œ
ÐBß Cà D ß >Ñ
TDFZP
!
This will give fringes running away from the center of the zone, and this can
be verified by changing the sign in front of B in the expression of
FZP(ii,jj,kk) in the TDFZP.m file. As it turns out, this scanning beam gives
the same expression for the sine-hologram given by Eq. (3.5-3a). However,
the expression for the cosine-hologram is different with a negative  sign in
front of it. Note that the errors and sensitivities produced by the heterodyne
method, as well as the impact created by these errors, will not be discussed in
this book. Readers should refer to Section 5.4 of the Handbook of
Holographic Interferometry [Kreis, 2005], which will provide insight into the
practical limitations of heterodyning holographic interferometry.
 
When H is set to zero, we have 
 and the time-dependent
homodyning
Fresnel zone plate becomes static. Now by introducing phase shifts between
the two interfering waves that are used to generate the Fresnel zone plate,
one can obtain three holograms (as a result of three different phase shifts) to
alternatively solve the twin-image problem in optical scanning holography
[Rosen, Indebetouw and Brooker (2006)].
        Table 3.2 TDFZP.m : m-file for illustrating running fringes in TDFZP.
------------------------------------------------------
% TDFZP.m
% Illustration of running fringes in TDFZP
% The author thanks Kelly Dobson for her initial programming
clear;
B=10.01*10^6;  %temporal frequency, arbitrary
D=6; %Scale arbitrary
t=linspace(0,1,35);
x=linspace(-2.5,2.5,256);
y=linspace(-2.5,2.5,256);
94
“
”
Optical Scanning Holography with MATLAB

95
for ii=1:length(x)
 for jj=1:length(y)
   for kk=1:length(t)
   FZP(ii,jj,kk)=(1+sin(D*(x(ii)^2+y(jj)^2)+B*t(kk))); %TDFZP
   end
 end
end
for ll=1:length(t)
    max1=max(FZP(:,:,ll));
    max2=max(max1);
    scale=1/max2;
    FZP(:,:,ll)=FZP(:,:,ll).*scale;
figure(ll);
colormap(gray(256));
image(256*FZP(:,:,ll));
axis off
F(ll)=getframe;
end
movie(F,10)
------------------------------------------------------
References
3.1 
Duncan, B.D. and T.-C. Poon (1992). Gaussian beam analysis of optical scanning
holography,
 9, 229-236.
Journal of the Optical Society of America A
3.2 
Doh, K., T.-C. Poon, M. Wu, K. Shinoda, and Y. Suzuki (1996).
141.
3.3 
General Scanning. http://www.gsig.com/scanners/
3.4 
Indebetouw, G. and T.-C. Poon (1992). Novel approaches of incoherent image
processing with emphasis on scanning methods,
31, 2159-
Optical Engineering 
2167.
3.5 
Indebetouw, G., P. Klysubun, T. Kim, and T.-C. Poon (2000). Imaging properties
of scanning holographic microscopy, Journal of the Optical Society of America A
17, 380-390.
3.6 
Indebetouw, G and W. Zhong (2006). Scanning holographic microscopy of three-
dimensional fluorescent specimens,
.
Journal of the Optical Society of America A
23, 1699-1707.
3.7 
IntraAction Corp. http://www.intraaction.com/
3.8 
 T.-C. Poon (1999). Extraction of 3-D location of matched 3-D object
using power fringe-adjusted filtering and Wigner analysis,
38,
Optical Engineering 
2176-2183.
3.9 
Korpel, A. (1981). Acousto-optics-a review of fundamentals, Proceedings of the
IEEE 69, 48-53.
3.10 
Kreis, T. (2005). 
. Wiley-VCH GmbH &
Handbook of Holographic Interferometry
Co. KGaA, Weinheim.
3.11 
Lohmann, A. W. and W. T. Rhodes (1978). Two-pupil synthesis of optical transfer
functions,
 17, 1141-1150.
 Applied Optics
“
”
“
”
“
”
“
”
“
”
“
”
“
”
“
”
Kim, T and
Optical Scanning Holography: Principles
Twin-image
Laser & Optics Technology 28, 135-
elimination in optical scanning holography,

3.12 
Poon, T.-C. (1985). Scanning holography and two-dimensional image processing
by acousto-optic two-pupil synthesis, Journal of the Optical Society of America A
4, 521-527
3.13 
Poon, T.-C. (2002a).
Three-dimensional television using optical scanning
holography,” 
 3, 12-16.
Journal of Information Display
3.14 
Poon, T.-C. (2002b). Acousto-Optics,
Encyclopedia of Physical Science and
Technology, Academic Press.
3.15 
Poon, T.-C. (2004). Recent progress in optical scanning holography  
, Journal of
Holography and Speckle 1, 6-25.
3.16 
Poon, T.-C. (2006).
Horizontal-parallax-only optical scanning holography,
in
chapter 10 of Digital Holography and Three-Dimensional Display: Principles and
Applications  , T.-C. Poon ed., Springer, New York, USA.
3.17 
Poon, T.-C. and A. Korpel. (1979). Optical transfer function of an acousto-optic
heterodyning image processor,
 4, 317-319.
Optics Letters
3.18 
Poon, T.-C., K. Doh, B. Schilling, M. Wu, K. Shinoda, and Y. Suzuki (1995).
3.19 
Poon, T.-C. and T. Kim (1999).
Optical image recognition of three-dimensional
objects,
 38, 370-381.
Applied Optics
3.20 
Poon, T.-C., T. Kim, G. Indebetouw, B. W. Schilling, M. H. Wu, K. Shinoda, and
Y. Suzuki (2000). Twin-image elimination experiments for three-dimensional
images in optical scanning holography,
 25, 215-217.
Optics Letters
3.21 
Poon T.-C. and P. P. Banerjee (2001). Contemporary Optical Image Processing
with MATLAB . 
® Elsevier, Oxford, UK.
3.22 
Poon, T.-C., T. Kim and K. Doh (2003) Optical scanning cryptography for secure
wireless transmission,
 42, 6496-6503.
Applied Optics
3.23 
Poon, T.-C. and T. Kim (2006). 
World
Engineering Optics with MATLAB®. 
Scientific Publishing Co., Singapore.
3.24 
Pratt, W.K. (1969). 
, John Wiley & Sons.
Laser Communications Systems
3.25  
Rosen, J., G. Indebetouw, and G. Brooker.
Homodyne scanning holography,
Optics Express 14, 4280-4285.
3.26 
Yamaguchi, I. and T. Zhang (1997). Phase-shifting digital holography,
Optics
Letters 22, 1268-1270.
96
“
”
“
“
”
“
”
“
”
“
”
“
”
“
”
“
”
“
”
“
”
“
”
Optical  Engi-
Three-dimensional microscopy by optical scanning holography,
neering 34, 1338–1344.
Optical Scanning Holography with MATLAB

 
Chapter 4
Optical Scanning Holography: Applications
So far, the applications of optical scanning holography span over five diverse
areas: scanning holographic microscopy [(Poon, Doh, Schilling, Wu,
Shinoda, and Suzuki (1995)], 3-D image recognition [(Poon and Kim
(1999)], 3-D optical remote sensing [Kim and Poon (1999)], 3-D holographic
TV and 3-D display [Poon (2002a)], and 3-D cryptography [Poon, Kim, and
4.1 Scanning Holographic Microscopy
Three-dimensional (3-D) imaging is a formidable task for optical microscopy
as it is well known that the greater the 
 
 is, the shorter
lateral resolution ?<
the 
 
 will be. In other words, if we want to create a higher
depth of focus ?D
lateral resolution in the microscopic imaging system, say by using a high
numerical aperture (NA) lens, we will have to compromise the system with a
shorter depth of focus where only a thin section of the specimen can be
imaged. To demonstrate this fact, a simple quantum mechanical argument is
convenient to use here.
Fig. 4.1 Uncertainty principle used to find resolution and depth of focus.
Doh (2003)]. In this chapter, we will only cover three areas of the applica-
tions mentioned above. We will focus on scanning holographic microscopy,
3-D holographic TV and 3-D display, and 3-D cryptography in that order,
as the other areas have been recently reviewed in the book chapters [Poon
(2002b), Poon (2005)].

Let us first find the lateral resolution, 
. Quantum mechanics relates the
?<
minimum uncertainty in a position of quantum, 
, to the uncertainty of its
?<
momentum, 
, according to the relationship
?:<
? ?
<
:   2
<
,
(4.1-1)
where 
 is the momentum difference between rays CA and CC  along the
?:<
w
<-direction, i.e., the transverse direction as shown in Fig. 4.1, where parallel
rays are focused by a lens. Now the momentum of the CA ray and the CCw
ray is 
sin
 and zero along the 
-direction, respectively, where
:
Ð Î#Ñ
<
!
)
: œ 2Î
: œ :
Ð Î#Ñ
!
<
!
!
-
?
)
 is the momentum of the quantum. Hence, 
sin
. By
substituting this into Eq. (4.1-1), we obtain
?
?
)
-
)
)
-
<  
œ
œ
œ
2
2
2
:
:
Ð Î#Ñ
Ð2Î
Ñ
Ð Î#Ñ
Ð Î#Ñ
 
.
sin
sin
sin
<
!
!
!
If the object space or the specimen space has a refractive index of 
, we
8!
must use the fact that the wavelength in the medium is equal to /
, where
- 8!
- is the wavelength in air or in vacuum. The above equation, therefore,
becomes
                                    
 
,
(4.1-2)
sin
?
-
-
)
<  
œ
8
Ð Î#Ñ
RE
!
where 
sin
 is called the 
. Similarly, to find
RE œ 8
Ð Î#Ñ
!
)
numerical aperture
the depth of focus, 
, we have
?D
                                           
 
,
(4.1-3)
? ?
D
:
  2
D
where 
 is the momentum difference between rays CA  and CC  along the
?:D
w
w
D-direction as shown in Fig. 4.1, which is given by
?
)
: œ : :
Ð Î#Ñ
D
!
!cos
.
By substituting this expression into Eq. (4.1-3), we have
?
?
)
)
-
D  
œ
œ
2
2
:
: Ò" 
Ð Î#ÑÓ
Ò" 
Ð Î#ÑÓ
D
!
!
cos
cos
,
which can be written as
?
-
)
D   Ò" 
" 
Ð Î#ÑÓ
!
#
È
sin
98
Optical Scanning Holography with MATLAB

99
¸
œ
#
#8
Ð Î#Ñ
RE
-
-
)
!
!
#
#
sin
,
(4.1-4)
where we have used 
sin
sin
 by assuming
È" 
Ð Î#Ñ ¸ " 
Ð Î#Ñ
#
"
#
#
)
)
sin
 in order to obtain the last expression. Now, by combining
#Ð Î#Ñ ¥ "
)
Eqs. (4.1-2) and (4.1-4), we have
.
(4.1-5)
Ð
<Ñ
D
#
 
?
-
?
#
!
This 
 tells us that, for example, by increasing the
uncertainty relationship
lateral resolution by a factor of two, the depth of focus must then be
decreased by a factor of four. Hence, we see that the higher the lateral
resolution is, the shorter the depth of focus will be. Three-dimensional
imaging in microscopy therefore aims to develop techniques that can provide
high lateral resolution, and at the same time maintain a large depth of focus
in order to observe a thick specimen without any difficulty.
 
In the past decade, we have witnessed an impressive emergence of
Fig. 4.2 Optical sectioning microscope (OSM).
 
“
”
three-dimensional (3-D) imaging techniques for microscopy. Optical section-
ing microscopy and scanning confocal microscopy are the two most common
techniques currently available in practice.
a wide-field microscope to sequentially record a series of images focused
An optical sectioning microscope (OSM), shown in Fig. 4.2, uses
at different depths [Agard (1984)]. Since each 2-D image contains the in-
focus as well as the out-of-focus information, reconstruction of the 3-D
Optical  Scanning Holography: Applications

100
information, i.e., extraction of the in-focus information from these 2-D
images, is required. Many reconstruction algorithms have been developed for
this purpose. However, the difficulty of optical sectioning lies in the fact that
during the recording stage it is important that exact longitudinal spacing
between adjacent 2-D images must be accurately controlled. Also, precise
registration of the 2-D images is critical even before any computer
processing can be performed.
 
By recognizing these problems, a radically new microscope design
known as the scanning confocal microscope (SCM) has emerged [Wilson and
Sheppard (1984)]. The confocal principle was first described by Minsky
[Minsky, US Patent (1961)]. In scanning confocal microscopy, a doubly
focused objective lens system and a pin-hole aperture in front of a
photodetector are used to image only a single point within the 3-D specimen,
as shown in Fig. 4.3. All the light from the point on the plane of focus (solid
rays) is focused at the pin-hole aperture and passed into the photodetector.
The light from the out-of-focus plane (dashed rays) is rejected by the pin-
hole. Three-dimensional information is gathered by scanning the specimen in
three dimensions while collecting the light transmitted through the specimen
with the photodetector.
Fig. 4.3 Scanning confocal microscope (SCM).
 
Theoretically, SCMs provide a slightly better lateral resolution than
that of OSMs. If the lateral resolution in optical sectioning microscopy is
?
-
< œ
ÎRE, the lateral resolution of the scanning confocal microscope is
!Þ($
<
?  [Corle and Kino (1996)]. In other words, one can achieve better
resolution through confocal imaging. However, such a theoretical limit has
never been achieved in practice. One of the main problems associated with
SCMs is that the scanning instrumental tolerances required to achieve high
resolution imaging and a long working 
are very difficult to
depth of field 
obtain in practice. The term depth of field, 
, here refers to the range of
?6
Optical Scanning Holography with MATLAB

101
object (or specimen) distances that are imaged within a distance, 
, i.e., the
?D
depth of focus in the image space. In fact, if 
 is the lateral magnification of
Q
the imaging system, then 
/
[see Example 4.1, page 112].
?
?
6 œ
D Q #
 
In essence, both methods (OSM and SCM) require precise 3-D
positioning devices. This is particularly critical for the confocal methods
whose technologically sophisticated and expensive equipment need special
technical training to ensure proper use. However, for certain applications in
biology, the main drawback of these instruments is that the data is
sequentially acquired by a slow 3-D scan. This tedious data acquisition time
is a serious drawback for 
 studies. It precludes, for example, the
in vivo
possibility of monitoring dynamic interactions at the intercellular level. In
addition, an extensive data acquisition time exacerbates the photo-bleaching
problem in 
Briefly, damage
fluorescence microscopy 
. 
[Pawley (1995)]
caused by photo-bleaching refers to the fact that a specimen will not
fluoresce when it is over-exposured. The severity of this problem in cell
studies has prompted the development of extremely sophisticated techniques
such as 
, for example. We also
two-photon scanning fluorescence imaging
want to point out that 
 (OCT), which is based on
optical coherent tomography
interferometry, is another pertinent and emerging technique used for 3-D
microscopy [Huang, Swanson, Lin, Shuman, Stinson, Chang, Hee, Flotte,
Gregory, Puliafito, and Fujimoto (1991)]. But once again, this technique also
requires scanning the object along the depth direction. Actually, all existing
commercialized microscopes (OSM, SCM, and OCT) require axial-scanning
in order to achieve 3-D imaging. Eliminating the need for a 3-D scan, or
more specifically for a depth-scan gives us the impetus to study novel
holographic methods for 3-D microscopy.
 
Holography can be used in applications where 3-D data sets are
desirable but axial scanning is difficult or sometimes impossible to utilize.
With holography, we have the ability to capture high resolution 3-D
information in a large volume space. In recent years, holographic microscopy
has become more and more prevalent because it represents a novel departure
from conventional 3-D microscopy mentioned above [Zhang and Yamaguchi
(1998), Kim (2000)]. Traditionally, holographic microscopy has been used in
biology, however it is inherently insensitive to incoherent emissions, such as
fluorescence, which makes its usefulness severely limited in life sciences
applications. A scanning holographic microscope (SHM), which is based on
the principle of optical scanning holography (OSH), can acquire 3-D
information by only using single 2-D x-y scanning (no axial scanning is
involved and hence there are reduced acquisition times for 3-D imaging).
Most importantly, the SHM has the ability to image fluorescent samples,
which is a breakthrough in holography since conventional holographic
microscopes simply could not capture fluorescent specimens prior to the
invention of optical scanning holography [Poon, Schilling, Indebetouw, and
Optical  Scanning Holography: Applications

102
    
Storrie, U.S. Patent (2000)]. In addition, the SHM will provide better
theoretical transverse resolution even in comparison to a SCM. The
resolution of a SHM is 
5
, where 
 is again the resolution of a wide
!Þ
<
<
?
?
field microscope [Indebetouw (2002)]. We will further elaborate on this topic
in chapter 5. Note that OCT techniques are also not capable of fluorescent
imaging. Hence, OSH is a very unique technique for 3-D biomedical
applications.
  
In the spirit of keeping the scanning holographic microscope (SHM)
at the same level of simplicity illustrated with the OSM and the SCM shown
in Figs. 4.2 and 4.3, respectively, we show a SHM in Fig. 4.4. In principle,
we need a time-dependent Fresnel zone plate (TDFZP) to two-dimensionally
raster scan the thick specimen as shown in Fig. 4.4.
 
Fig. 4.4 Scanning holographic microscope (SHM).
 
Figure 4.5a) shows the actual setup of a scanning holographic
microscope used for fluorescence applications. In this figure, two broad laser
beams (originating from a 
nm-line of an argon laser), separated in
&"%
temporal frequency by 
, are incident on the mirror and the beamsplitter
?H
(BS). The frequency shift in each beam is achieved by using an acousto-optic
frequency shifter (AOFS). The AOFS is used in a configuration that allows
us to split the laser into two beams separated in frequency by 
2
10.7
?H
1
Î
œ
MHz. The beams are then collimated and set parallel to each other as shown
in the figure. Lens L  is placed in one of the beams to form the spherical
"
wave, which is then combined collinearly with the other beam at the
beamsplitter (BS). This will form a TDFZP on the object, which is at a
distance of  beyond the focus of the spherical wave.
D
The dichroic beamsplitter transmits light at 
nm and reflects light at
&"%
around 
nm  Therefore, the laser light is allowed to pass through the
&*&
Þ
dichroic beamsplitter and excite the fluorescent sample, which fluoresces at
&60nm. Also, the emission filter directly in front of the photomultiplier tube
photodetector
thick specimen
lens
point
source
at ω0
plane wave at
 1 Ω
Optical Scanning Holography with MATLAB
ω0

103
(PMT) allows fluorescent light to pass through while rejecting the
background laser light at 
nm. The sample is scanned through the TDFZP
&"%
in a raster pattern using a computer-controlled mechanical x-y scanning
platform. The current of the PMT, which contains holographic information of
the scanned object, is electronically filtered, amplified at 10.7 MHz,
demodulated and then digitized in synchronization with the x-y scanners in
order to ultimately produce an electronic hologram. Note that the
demodulation is performed by the usual electronic detection as we had
previously discussed in Fig. 3.6. However, only one channel, specifically the
experiment.
  
                    a) 
                                         
    b)
 
Fig. 4.5a) Experimental setup used to record the hologram of a fluorescent specimen
by using OSH. PMT is a photomultiplier tube. Reprinted from B.W. Schilling et al., Optics
Letters 22, 1506 (1997), with permission. © OSA. b) Experimental configuration of
fluorescent solution on the ends of two wires. After Schilling (1997).
 
The fluorescent sample used in the experiment consists of a solution
containing a high concentration of fluorescent latex beads. The beads are 15
.m in diameter and characteristically reached peak excitation at 530nm and
peak emission at 560nm. To demonstrate the depth-discriminating capability
of the system, we use a fluorescent object that consists of two wires
adjacently placed and parallel to the optical axis but with their ends at
slightly different distances from the focus of lens L1. A drop of fluorescent
solution is placed on the end of each of these wires, and the two drops of
solution are separated in depth by approximately mm (the drop on the right
#
at 
5 mm and the drop on the left at 
mm, as shown in Fig.
D ¸ $
D ¸ $(
!
1
4.5b). A hologram of this fluorescent sample was recorded and is displayed
in Fig. 4.6. The two drops are easily distinguishable in the hologram.
Optical  Scanning Holography: Applications
in-phase component of the heterodyne current, was utilized during the

104
    
Fig. 4.6 Hologram of  a fluorescent specimen recorded by using optical scanning holography.
The object consists of  two drops of solution containing a high concentration of fluorescent
latex beads separated in depth by about 2 mm.  The image is at a 256 level gray scale image
consisting of 256x256 pixels.  The area scanned is about 2.0 mm x 2.0 mm. Reprinted from
B.W. Schilling et al., Optics Letters 22, 1506 (1997), with permission. © OSA.
The resolution of the OSH system is limited by the system s numerical
aperture (NA), which actually depends on the focal length of lens L1
(
mm) and the diameter of the plane wave focused by lens L
0 œ "&!
1
m and
?
.
D ¸ "!#)Þ% 7, according to Eqs. (4.1-2) and (4.1-4), respectively. The 15
.m bead size is very close to the limit that we can expect to resolve laterally
with the setup.
 
Once the hologram has been recorded and stored, the 3-D image can
then be reconstructed either optically or numerically. Numerical image
reconstruction has been performed on the hologram at two different depths.
Figure 4.7a) is a reconstructed image at 
5mm, and Fig. 4.7b) is an
D œ $
!
image reconstruction at 
7mm.  Since the individual attributes of each
D œ $
1
fluorescent drop are not obvious in these figures, arrows are marked on the
figures to indicate particular areas of interest. In Fig. 4.7a), the fluorescent
drop on the left is in better focus than that on the right. The arrow in Fig.
4.7a) indicates particular beads that are more clearly visible when the
hologram is reconstructed at a depth of 
 than in Fig. 4.7b) for a depth at 
.
D
D
!
1
Similarly, the arrow in Fig. 4.7b) points out a string of four beads that are
individually distinguishable when the hologram is reconstructed at a depth of
D
D
1, but that are blurred in the image reconstruction plane 
 in Fig. 4.7a).
!
’
(H œ "!mmÑ. The NA of the system is approximately !Þ!$$ which cor-
responds to the diffraction-limited resolution limit of ?
.
< ¸ ")Þ&
Optical Scanning Holography with MATLAB

105
 
Fig. 4.7 Reconstruction of the hologram shown in Fig. 4.6. a) At a depth of
D œ $
!
5mm. Arrow shows individual fluorescent beads that are in focus at this depth. b) At a
depth of 
7mm. The arrow shows four individual  fluorescent beads that are in focus at
D œ $
1
this depth. Reprinted from B.W. Schilling et al., Optics Letters 22, 1506 (1997),
with permission. © OSA.
 
Optical  Scanning Holography: Applications

106
    
 
Note that since only the in-phase component of the heterodyne
current has been recorded to create the hologram shown in Fig. 4.6, twin-
image noise (residual fringing ) exists in these reconstructions.
 
An important attribute of scanning holographic imaging is that this is
the first time the hologram of a fluorescent specimen has been recorded by
using an optical holographic technique [Poon et al., U.S. Patent (2000)].
Holography and fluorescence imaging would never seem to make
conventional sense because holographic techniques require the coherent
interference of light waves and fluorescence imaging does not generate
coherent light. And yet, we have been able to record holograms of
fluorescent specimens because optical scanning holography makes this
possible. In fact, optical scanning holographic techniques can be applied to
3-D biomedical applications as fluorescence imaging [Indebetouw, Kim,
Poon, and Schilling (1998)] as well as near-infared imaging [Sun and Xie
(2004)] through turbid media have been demonstrated. Most recently a better
than 1 m-resolution also has been established with a holographic
.
fluorescence microscope [Indebetouw and Zhong (2006)].
4.2  Three-Dimensional Holographic TV and 3-D Display
Figure 4.8 shows a conceptual holographic system used for 3-D display with
a complete recording and reconstruction stages of a point source object. As
we had mentioned in chapter 2, if the recording film is replaced by, say,
some electronic device such as a CCD video camera, then we can create a 3-
D display by transferring the CCD s electronic output into some spatial light
modulator. As we transfer the holographic information at video rate to a
spatial light modulator, we create a holographic 3-D display system.
 
The first television transmission of a hologram was demonstrated by
Enloe, Murphy, and Rubinstein [1966]. A television camera was used to
record an off-axis hologram where the interference between the Fresnel
diffraction pattern of an object transparency and an off-axis plane wave was
recorded. The recorded hologram was then transmitted over a closed-circuit
TV and displayed on a 2-D monitor. The displayed 2-D record was then
photographed to form a hologram, which was subsequently reconstructed  by
a coherent optical system. Since then, much progress has been made and
many novel devices have been invented [Macovski (1971), Brown, Noble
and Markevitch, U.S. Patent (1983), Kirk, International Patent (1984),
Benton (1991), Shinoda, Suzuki, Wu and Poon, U.S. Patent (1991), Schilling
and Poon, U.S. Patent (2004)].
“
”
’
Optical Scanning Holography with MATLAB

107
Fig. 4.8 Conceptual holographic system for 3-D display.
 
In this section, we will describe a recently proposed holographic TV
system that uses optical scanning holography (OSH) to acquire holographic
information and employs a spatial light modulator (SLM) for an eventual
coherent 3-D display [Poon (2002a)]. We should be familiar with OSH by
now and, therefore, we will first describe the SLM used in this system. The
overall system will be subsequently discussed. The SLM, which has been
experimented on the proposed TV holographic system, is called an electron-
beam-addressed spatial light modulator (EBSLM) [Hamamatsu Photonics
K.K., Japan 
]. The device is shown in
and Hamamatsu Corp., Bridgewater, NJ
Fig. 4.9.
 
A serial video signal is the required input to the EBSLM controller.
The controller in turn provides the signal that modulates the intensity of the
emission from the electron gun within the EBSLM head. This electron beam
is then two-dimensionally scanned onto the surface of a LiNbO  crystal with
3
a deflection coil. As a result, electric charges accumulate on the surface of
Optical  Scanning Holography: Applications

108
    
the crystal. The spatially induced electric field deforms the crystal as a result
of the 
[Poon and Kim (2006)]. A pair of crossed polarizers is
Pockels effect 
used in order to read the resulting spatial distribution on the crystal by laser.
Conjunctly, a coherent spatial distribution of the output laser would
correspond to the 2-D scanned video information on the crystal.
Fig. 4.9  Electron-beam-addressed spatial light modulator (EBSLM) for coherent display.
 
By incorporating optical scanning holography for holographic
recording with EBSLM for coherent display, we can create a complete
holographic TV system. This is shown in Fig. 4.10, where we have included
a system for optical scanning holography on the top portion of the figure.
 
In the top part of the system, M1, M2, and M3 represent the mirrors,
BS1 and BS2 denote the beamsplitters, AOM is an acousto-optic modulator
used to shift the laser beam at a frequency of 
, and BE1 and BE2 are the
H
beam expanders. Note that lens L is used to focus a point source on the BS2,
that projects a spherical wave through the x-y scanner to the object, while
BE2 provides a plane wave onto the object. After 2-D raster scanning of the
object, the photomultiplier picks up the scattered light from the object and
delivers a heterodyne current as an output current. If the heterodyne current
is at the radio frequency (rf) range, then it can be directly radiated through an
antenna to a remote site for demodulation. At the demodulation site, we will
have the usual electronic multiplexing detection. The PC can manipulate the
two holograms (sine and cosine holograms) and thus deliver its output to the
controller of the EBSLM for coherent reconstruction of the holographic
information in order to display the output light for the audience. Hence, we
have a complete holographic TV system. This system has been proposed by
Poon [2002a], and this idea of using OSH to acquire holographic information
and to use SLMs for display has been tested in the system shown in Fig.
4.11. It is clear from the figure that a TDFZP is used to scan the 3-D object,
Optical Scanning Holography with MATLAB

109
c
Fig. 4.10 Proposed holographic TV system. Adapted from T.-C. Poon,
 J. Information Display 3, 12 (2002a).
 
The 
IPMS) is a device that
Image Processing and Measuring System (
acts as an interface that accepts a slow-scan electrical signal and stores the
information in its digital memory. The information is then converted into a
NTSC video signal [Hamamatsu Photonics K.K. and Hamamatsu Corp., NJ].
When the video of the IPMS is displayed on a TV monitor, the sine-FZP
hologram of a 3-D object is displayed as shown in Fig. 4.12. The 3-D object
consists of two transparencies, the letters V  and T,  located side by side
but separated by a depth-distance of about 15 cm  The V  is located closer to
the 2-D scanner at a distance of about 23 cm, i.e., z
23 cm. Both letters are
œ
printed on 35
 film, have a line width of about 100 m, and are
77
.
transmissive on an opaque background. By passing the reflected light of the
EBSLM through an analyzer as shown in Fig. 4.11, a coherent image is
reconstructed at a distance of 
z away from the analyzer, where z is the
Q ‚
distance from the scanning mirror to the object (as indicated at the
holographic recording stage in the figure), and 
 is a magnification factor
Q
’
Eq. (3.5-3a), for coherent reconstruction by the EBSLM.
mixed  with  cosÐ >
H Ñ  to get  the  sine-FZP  hologram, 3 ÐBß CÑ, as given by
“ ”
“ ”
“ ”
and the photodetector s output is bandpass filtered at , H and then it is finally
Optical  Scanning Holography: Applications

110
    
that takes into account the longitudinal magnification of the holographic
imaging system that arises because of various hologram scalings. An
example of the cause of 
 may be that the displaying area of
hologram scaling
the hologram in the EBSLM is different from the actual optical scan area of
the object. Holographic magnification is discussed in Example 4.1.
 
The reconstruction of a hologram along depth can be observed
through the movable CCD camera, which focuses on different reconstruction
planes. Figure 4.13a), c), and e) show the real-time reconstruction of a
hologram of different depths by using the electron-beam-addressed spatial
light modulator. In the 3-D reconstruction, the 
z  for Fig. 4.13a) and
Q ‚
Fig. 4.13e) are 23cm and 41cm, respectively. In Fig. 4.13a), we notice that
the V  is in focus, and in Fig. 4.13e) the T  is now in focus. Also note that
the reconstructed image planes have been contaminated by the twin-image
noise because only one channel, namely the sine-FZP hologram, has been
used. For comparison, we have shown digital reconstructions in Fig. 4.13b),
d), and f) [Poon, Doh, Schilling, Wu, Shinoda, and Suzuki (1995)].
 
The EBSLM system is capable of displaying holograms at a video
rate and, of course, some commercial 
 scanners are also capable of
B C
working at a video rate. But what we have done is really the use of a SLM to
display the acquired hologram along depth for coherent reconstruction. So
what is the prospect of displaying true 3-D images in holographic television?
Fig. 4.11 Experimental 3-D holographic television system.
Adapted from  T.-C. Poon et al. Optical Review 4, 576 (1997).
“
”
“ ”
Optical Scanning Holography with MATLAB

111
Figure 4.12 Sine-FZP hologram of two letters V  and T  located at different depths.
 Reprinted from T.-C. Poon et al., Optical Engineering  34, 1338 (1995),
with permission. © SPIE.
“ ”
“ ”
Optical  Scanning Holography: Applications

112
    
Fig. 4.13 Holographic Reconstruction.  a) ,c), and e) EBSLM s reconstruction. Reprinted from
T.-C. Poon et al., Optical Review 4, 576 (1997); b), d), and f) Digital reconstruction.
Reprinted from T.-C. Poon et al., Optical Engineering 34, 1338 (1995),
with permission. © SPIE.
Example 4.1      Holographic Magnification
We will derive holographic magnification in the context of OSH. We
consider a three-point object given by
   
, , 
, , 
, , 
,
(4.2-1)
$
$
$
?
ÐB C D D Ñ ÐB B
C D D Ñ ÐB C D ÐD 
D ÑÑ
!
!
!
!
!
where the first two points are located at a distance of 
 away from the point
D!
source, which generates the spherical wave shown in Fig. 4.4. The two points
have a lateral separation of 
. The third point is located at a distance of
B!
D 
D
!
!
?
 away from the first two points. According to Eq. (3.5-3a), when
this three-point object is scanned, the scanned demodulated electrical signal,
3-, gives a sine-hologram, which is given by
L
ÐBß CÑ μ
Ò
ÐB
C ÑÓ 
Ö
ÒÐB B Ñ C Ó×
5
5
D
D
$ :
!
!
!
!
!
#
#
#
#
-
 sin
 + 
sin
 
2
2
          
sin
 + 
 .
(4.2-2)
2

Ò
ÐB
C ÑÓ
5
ÐD 
D Ñ
!
!
!
#
#
?
If this hologram is illuminated by a plane wave at 
 , the three points will be
-!
reconstructed at their respective locations. We will now consider holographic
magnification.
’
Optical Scanning Holography with MATLAB

113
a) Hologram Scaling
Magnification can be achieved by enlarging holograms, however, it is a
difficult task especially when we deal with off-axis holograms where fringe
densities are of the order of several thousands lp/mm. Most photographic
enlargers do not have a sufficient resolution in order to handle these details.
Hence, the method is not very practical. With the scanning technique,
however, on-axis holograms are generated and scaling is straightforward.
The hologram can be scaled by a factor of 
, simply by displaying the
Q
hologram in an area that is different from the optical scan area. In this case,
Eq. (4.2-2) becomes
L
ÐQB QCÑ œ
Ö
ÒÐQBÑ ÐQCÑ Ó×
5
D
$ :
!
!
#
#
-
,
sin 2

Ö
ÒÐQB B Ñ ÐQCÑ Ó×
5
D
sin 2
!
!
!
#
#

Ö
ÒÐQBÑ ÐQCÑ Ó×
5
ÐD 
D Ñ
sin
.
(4.2-3)
2
!
!
!
#
#
?
When 
<1, we have magnification, whereas 
>1 corresponds to
Q
Q
demagnification. By re-writing Eq. (4.2-3), we have
L
ÐQB QCÑ œ
Ò
ÐB C ÑÓ
5
D Q
$ :
!
!
#
#
#
-
, 
sin 2
/

Ö
ÒÐB B QÑ C Ó× 
Ö
ÐB C Ñ×
5
5
D Q
ÐD 
D Ñ Q
sin
/
sin
.
2
/
2
/
!
!
!
!
!
#
#
!
#
#
#
#
?
(4.2-4)
 
Now, during optical reconstruction using a wavelength 
, we see
-!
that by inspection of the first and second term in Eq. (4.2-4), the two real
image points are now formed at a distance of 
/
 away from the
D Q
!
#
hologram, and with a reconstructed lateral distance of 
/
 away from each
B Q
!
other. By defining the 
, M , as the ratio of the
lateral magnification
lat
reconstructed lateral distance to the original lateral distance, 
, we have
B!
M
1/
. In order to determine the magnification along the longitudinal
lat œ
Q
direction, we must focus on the first and the third terms, and upon
reconstruction, we see that the two points are reconstructed at 
/
 and
D Q
!
#
(
)/
, respectively. By defining the 
,
D 
D
Q
!
!
#
?
longitudinal magnification
M
, as the ratio of the reconstructed longitudinal distance, 
/
, to the
long
?D Q
!
#
original longitudinal distance, 
, we have  M
=1/
.
?D
Q
!
#
long
Optical  Scanning Holography: Applications

114
    
b) Wavelength Scaling
We could reconstruct the hologram with a different wavelength, say m
 (or
-!
5!/m), where m is a constant.  Hence, according to Fresnel diffraction, the
field distribution at away from the hologram is now given by
D
L
ÐB CÑ ‡ 2ÐB C D 5
Ñ
$ :
!
-
,
  
, ; , 
/m
º
Ò
ÐB C ÑÓ 
Ö
ÒÐB B Ñ C Ó×
5
5
D
D
šsin
sin
2
2
!
!
!
!
#
#
#
#
!

Ò
ÐB
C ÑÓ
‡
Ò 
ÐB C ÑÓ
5
45
45
ÐD 
D Ñ
D
D
sin
 + 
  
 exp
. 
2
2
2
/m
/m
!
!
!
!
!
#
#
#
#
?
1
›
 
 (4.2-5)
This equation suggests that there will be no magnification in the lateral
direction. Along the longitudinal direction, we can inspect the results of the
first and the third terms. And again when we consider real image
reconstruction, the first and the second term will form an image at 
/m.
D œ D!
The third term gives rise to a real image at 
)/m. Hence,  in this
D œ ÐD 
D
!
!
?
case M
1, and M
1/m. The reconstructed volume is either
lat
long
œ
œ
compressed or expanded by a factor of 1/m with the same lateral
magnification. When m>1, we have compression. With visible light for
recording and reconstruction, m is in the range of 0.5 to 1.8.  However, when
using digital reconstruction, m can be arbitrarily chosen.
c) Reconstruction combining hologram scaling and wavelength scaling
If we change the scale of the hologram and use a different wavelength for
reconstruction, then the combined magnification along the lateral and
longitudinal direction will be M
1/
 and M
1/m
.  Therefore,
lat
long
œ
Q
œ
Q #
we see that the reconstructed volume, 
/m
, is different from the
B
D
Q
!
!
$
?
original volume
. This creates distortion when we magnify the original
B
D
!
!
?
3-D object. This is a well-known result of magnification in 3-D optical
imaging. In order to have a true 3-D perspective on reconstruction, when the
scale change of the hologram is given by 
, we let m
1/
 which gives us
Q
œ
Q
M
m and M
m, and therefore, we obtain M
M
. In other
lat
long
lat
long
œ
œ
œ
words, in order to prevent distortion in 3-D imaging, we scale the hologram
by a factor 
, and then the reconstructing wavelength should be m
, where
Q
-!
-! is the recording wavelength and m is equal to 1/
. This is the original
Q
idea of Gabor [1949] who first conceptualized the notion during the pre-laser
era to improve upon the electron microscope. Electron microscopy was the
motivational factor in the development of holography.
Optical Scanning Holography with MATLAB

115
In order to address the prospect of a true 3-D holographic TV, we will
consider some issues of 3-D holographic display.
A. Spatial frequency resolution issue
Let us first delve into the spatial frequency resolution of an SLM for 3-D
display. For simplicity, we will take a point source hologram as our
hologram displayed on a SLM. From previous chapters, we know that the
expression of such a hologram is given by sin
. Remember that
Ò
ÐB C ÑÓ
5
#D
#
#
!
!
D! is the distance of the point source away from the recording device. The
local spatial frequency along the -direction across the hologram has been
B
given by Eq. (2.5-5), and is defined as
0
œ
Ð
B Ñ œ
"
.
5
B
#
.B
D
D
69-+6
!
!
! !
#
1
-
2
.
(4.2-6)
If the size of the limiting aperture of the hologram is 
, then 
 
B
B
max
max
069-+6 at 
is
0
œ
D
max
Bmax
-! !
,
(4.2-7)
which is the highest spatial frequency of the hologram fringes. Now assume
that the SLM has a maximum spatial resolution of 
, and if we want to
0!
record 
, then we must obey the requirement of 
. Now,
0
0 œ 0
max
max
!
according to the geometry shown in Fig. 4.14, the 
 of the hologram is
RE
sinÐ Î#Ñ œ
)
B
ÎD
max
! ,
(4.2-8)
where 
sing Eq. (4.2-7), Eq. (4.2-8)
) is defined as the 
. By u
viewing angle
becomes
    
(4.2-9)
RE œ sin
. 
Ð Î#Ñ œ
0
œ
0
)
-
-
!
! !
max
Fig. 4.14 Viewing angle.
Optical  Scanning Holography: Applications

116
    
For any given spatial resolution of the SLM, we can therefore find the
viewing angle according to Eq. (4.2-9). For example, Hamamatsu’s EBSLM
has a spatial resolution of about 
8 lp/mm, which gives us a viewing
0 œ
!
angle of about 0.6° at 
. Hence, such a device is not useful for
-
.
! œ !Þ'$#) m
applications in 3-D display. However, if we desire to obtain a sequential 2-D
display along the depth, then the EBSLM system is adequate enough because
it is capable of updating holograms at a video rate. Table 4.1 shows the
viewing angle for some existing SLMs. We currently do not have SLMs that
are suitable for 3-D display as their viewing angles are severely limited. The
situation becomes even worse if we use off-axis holography because we will
need to resolve the carrier frequency. As we recall, for 45 degrees of the
recording angle, the carrier frequency is about 1,000 lp/mm, which is well
beyond the capability of existing SLMs (see Table 4.1).
Table 4.1 Viewing angles for 
.
-
.
! œ !Þ'$#) m
0!(SLM s resolution)
 (viewing angle)
)
8 lp/mm
0.6 degree
EBSLM/Hamamatsu
100 lp/mm
6.8 degrees
PALSLM/Hamamatsu
500 lp/mm
34 degrees
not available
B. Spatial resolution issue
,
0=, required in order to generate the hologram is
                                          
  0 œ #
=
0!.
The number of samples, 
that will then be required to create a hologram of
Rß
size 6 ‚ 6 is
R œ Ð 6
Ñ
œ Ð6 ‚ #
Ñ œ Ð#6
Ñ
RE
 
 
 
,
(4.2-10)
0=
#
#
#
0!
!
 -
where we have used Eq. (4.2-9). According to Eq. (4.2-10), for full parallax,
#
‚ #
0mm
0mm on-axis hologram to be presented on an SLM, with a viewing
angle of 60 , the number of resolvable pixels required is about 
 billion. To
!
"Þ"
put things into perspective, some of the best CCD cameras, such as Canon
D60 (3072x2048 pixels, 67.7 lp/mm, 7.4 m pixel size), have just a little
.
over 6 Mega pixels.
’
!
displayed by an SLM. For a given spatial frequency resolution of an SLM, 0
device/company
Let us calculate the number of samples that are required for a hologram to be
 and according to the Nyquist sampling, the minim um sampling frequency,
Optical Scanning Holography with MATLAB

117
C. Data transmission issue
As we had previously calculated, a single frame of a 
0mm
0mm
#
‚ #
hologram with a viewing angle of 60° requires about 1.1 billion pixels on the
SLM. To update such a frame with an 8-bit resolution at 30 frames/s, a serial
data rate of
   1.1 billion samples/frame
8 bits/sample
30 frames/s
0.26 Tbit/s
‚
‚
œ
is required for  full parallax.
 
Basically, all the issues that we have discussed illustrate the fact that
content of information held within a hologram is enormous. This implies that
the content of information in the hologram must be significantly reduced in
order to achieve 3-D holographic TV for 3-D display. Live 3-D TV with
holographic images is truly a formidable problem. However, since we are
used to looking at the world with our two eyes more or less on a horizontal
level, we are usually satisfied with horizontal parallax. Hence, for 512
vertical lines, the number of pixels required becomes 
,
&"# ‚ Ð#6 ‚ #REÎ
Ñ
-!
which is approximately 17 million, if we are to eliminate vertical parallax.
By scarifying vertical parallax, the data rate becomes 4 Gbits per second
instead of 0.26 Tbits per second, which is calculated for full parallax. And
this is manageable with advanced modern optical communications systems.
real-world applications. The possibility of real-time holographic TV becomes
 
Optical scanning holography with horizontal-parallax-only recording
is possible if we scan the object with a 1-D TDFZP. This idea, called HPO-
optical scanning holography, has been proposed recently while computer
simulations have been performed [Poon, Akin, Indebetouw, and Kim (2005),
Poon (2006)].
4.3  Optical Scanning Cryptography
Due to the recent progress in the development of optical components and the
increased technical performance of optical systems, optical cryptography has
By using fiber optics, data rates of up to 40 Gbit/s indeed can be achieved in
a reality if the horizontal-parallax-only (HPO)-electronic holographic recor-
ding technique becomes available. Indeed, by using computer-generated,
horizontal-parallax-only holographic information, the MIT group has demon-
strated a 3-D holographic display having 64 vertical lines and with viewing
angle of about 15 degrees [St. Hilaire, Benton, Lucente, Jepsen, Kollin,  
Yoshikawa, Underkoffler (1990), St. Hilaire, Benton, and Lucente (1992)].
However, this HPO-holographic information is computer generated and no
HPO-holographic information has actually been generated by or recorded
from actual real objects.
Optical  Scanning Holography: Applications

118
    
a significant potential in advances for security applications. Indeed there has
been a plethora of articles that deal with secure systems that use optical
methods [Lohmann, Stork, and Stucke (1986), Refregier and Javidi (1995),
Lai and Neifeld (2000), Wang, Sun, Su, and Chiou (2000), Magensen and
Gluckstad (2001)]. One of the reasons for using optical encryption is that
information, such as images, that needs to be encrypted exists already in the
optical domain. Another reason is that optical encryption, as opposed to
electronic or digital encryption, can provide many degrees of freedom when
securing sensitive information. When large volumes of information need to
be encrypted, such as a 3-D object, using optical encryption methods is
probably the most logical choice. Although most optical encryption
techniques are typically coherent, some incoherent optical techniques for
encryption have recently been proposed [Tajahuerce, Lancis, Javidi, and
Andres (2001)]. In general, incoherent optical techniques have many
advantages over their coherent counterparts. This includes a better S/N ratio
and insensitivity to the misalignment of optical elements. In this section, we
will discuss an incoherent optical method based on optical scanning
holography for encryption. This method is called optical scanning
cryptography (OSC) [Poon, Kim, and Doh (2003)]. While having the
capability to utilize incoherent processing, the method also has many other
advantages. These advantages include the following. 1) Since it is an optical
scanning method, it can process incoherent objects, such as printed
documents, without using a spatial light modulator (SLM) to convert an
incoherent image into a coherent image as existing coherent techniques
currently do. The proposed system can indeed perform real-time or on-the-fly
encryption. 2) Since the output signal is a heterodyne electrical signal, and
hence the encrypted information is riding on a heterodyne frequency (or a
carrier frequency as used in communications), it can immediately be radiated
for wireless transmission to a secure site for storage and then subsequently be
encrypted. This may have important applications in radio frequency
identification RFID
(
) [Radio Frequency Identification Technologies: A
Workshop Summary (2004)]. 3) Because the technique is based on
holography, it can be easily extended to the use of encrypting 3-D
information.
 
Figure 4.15 shows the optical system utilized for encryption and
decryption. The system contains two subsystems: an encryption stage and a
decryption stage. It is noted that the two subsystems have an identical two-
pupil optical heterodyne scanning image processor, which we have
extensively studied in section 3.4. We will first briefly summarize the
previous results of the image processor, and then we will discuss encryption
and decryption.
Optical Scanning Holography with MATLAB

119
Fig. 4.15 Optical scanning cryptography.
Adapted from T.-C. Poon et al., Applied Optics 42, 496 (2003).
Optical  Scanning Holography: Applications
Decryption stage
Pinhole
aperture
antenna
PD
x-y scanner
Decryption key
1
2
ω0 + W
ω0
f
f
zd
x
x
y
y
ic
is
BPF
@ W
LPF
LPF
Digital Computer
cos(Wt)
sin(Wt)
Encryption key
Encryption stage
antenna
Wireless
transmission
PD
x-y scanner
p1
2
Γ0(x, y; zc)
ω0 + W
ω0
f
f
zc
x
x
y
y
ic
W
p  (x,y)
p  (x,y)
p  (x,y)
(x,y)
2

120
    
 
If we concentrate on the optical system of the encryption stage, we
can see that the two pupils, 
, are located at the front focal
: Bß CÑ
: Bß CÑ
"
#
(
 and 
(
plane of the lens and are illuminated by two broad laser beams of temporal
frequencies,  
 and 
 +  , respectively. The two beams are then combined
=
=
H
!
!
by a beamsplitter and used to 2-D scan a planar object, l
ÐBß Cà D Ñl ß
>!
-
#
located at a distance 
 away from the back focal plane of the lens. The
D-
distance of 
 is called a 
, and 
 is the object to
D
l
ÐBß Cà D Ñl
-
-
#
!
coding distance
>
be encrypted. The photodetector, PD, collects all the light transmitted by the
object if the object is transparent (or collects all the scattered light if the
object is diffusely reflecting). The photodetector will have a heterodyning
current at a frequency of  as one of its outputs (where the other output is a
H
baseband signal). After electronic tuning at 
, the heterodyne current,
H
3 ÐBß Cà D Ñ
D
-
-
H
, is given by Eq. (3.4-11) where  is replaced by the coding
distance 
,
D-
 
Re
exp
3 ÐBß Cà D Ñ œ
Ò3
ÐBß Cà D Ñ
Ð4 >ÑÓ
-
-
-
H
H:
H
   
Re
exp
.
œ
Ò
Ö
Öl
ÐBß Cà D Ñl ×SXJ Ð5 ß 5 à D Ñ×
Ð4 >ÑÓ
Y
Y
>
H
"
-
#
-
!
B
C
H
(4.3-1)
Again 
 is called the optical transfer function (OTF) of the
SXJ Ð5 ß 5 à D Ñ
H
B
C
-
heterodyne scanning system, which has been given by Eq. (3.4-10) as
follows:
SXJ Ð5 ß 5 à D Ñ œ
4
5
5
D
#5
H
B
C
-
#
#
-
!
B
C
exp
 + 
”
•
ˆ
‰
‚
: ÐB C Ñ : ÐB 
5
C 
5 Ñ
4
ÐB 5 C 5 Ñ .B .C
0
0
D
5
5
0
( (
”
•
‡
w
w
w
w
w
w
w
w
"
#
!
!
B
C
B
C
-
, 
, 
exp
,
(4.3-2)
where  is the focal length of the lens shown in the encryption stage in Fig.
0
4.15. The processing elements are the two pupil functions, 
(
 and
: Bß CÑ
"
: Bß CÑ
3 ÐBß Cà D Ñ
#(
. 
-
-
H
 is the scanned and processed version of the input,
l
ÐBß Cà D Ñl Þ
>!
-
#  By manipulating the pupils, we will have a different
processed output because the OTF in Eq. (4.3-2) is expressed in terms of the
two pupils. Now the processed information is carried by a temporal carrier at
a frequency of 
, and if 
 is chosen to be in the radio frequency domain
H
H
(which can be done easily through the use of acousto-optic modulators), then
the processed information can be readily radiated to a secure site (or a
decryption site) for further processing. The situation is shown in Fig. 4.15.
After receiving the decrypted information from an antenna at the secure site
(the output of the antenna in the secure site is switched to the input of the
Optical Scanning Holography with MATLAB

121
bandpass filter for electronic processing), the information is further
-
=
been given by Eqs. (3.4-14a) and (3.4-14b) as follows:
3 ÐBß Cà D Ñ œ
Ö
Öl
ÐBß Cà D Ñl ×SXJ Ð5 ß 5 à D Ñ×
Ð
Ñ
-
!
B
C
-
"
-
#
-
Re
4.3-3a
c
d
Y
Y
>
H
and
3 ÐBß Cà D Ñ œ
Ö
Öl
ÐBß Cà D Ñl Ñ×SXJ Ð5 ß 5 à D Ñ× Þ
Ð
=
!
B
C
-
"
-
#
-
Im
4.3-3b)
c
d
Y
Y
>
H
If we now apply addition to the above expressions in the following manner:
3ÐBß Cà D Ñ œ 3 ÐBß Cà D Ñ 4 3 ÐBß Cà D Ñ
-
-
-
-
=
, we have a complex expression
where the full amplitude and phase information of the processed object are
available:
       
.
(4.3-4)
3ÐBß Cà D Ñ œ
Ö
Öl
ÐBß Cà D Ñl Ñ×SXJ Ð5 ß 5 à D Ñ×
-
"
-
#
-
!
B
C
Y
Y
>
H
Encryption
From Eq. (4.3-4), we will now discuss encryption. To perform encryption on
the input object, 
, located at a distance of  
 away from the
l
ÐBß Cà D Ñl
D
>!
-
#
-
back focal plane of the lens at the encryption stage, we generally can
manipulate the two pupils, 
 and 
. As a simple example, we
: ÐBß CÑ
: ÐBß CÑ
1
2
will let 
 = 
, a pin hole, and keep 
 as is. The situation is
: ÐBß CÑ
ÐBß CÑ
: ÐBß CÑ
2
$
"
shown in Fig. 4.15. We shall call 
(
 an 
Under these
: Bß CÑ
"
encryption key. 
conditions, according to Eq. (4.3-2), the OTF of the system becomes
SXJ
5 ß 5 à D
œ
4
5
5
: Ð
5
5 Ñ
D
0
0
#5
5
5
H(
)
exp
 + 
 , 
, 
B
C
B
C
-
#
#
‡
-
!
!
!
B
C
"

ˆ
‰‘
(4.3-5)
and Eq. (4.3-4) then becomes
3ÐBß Cà D Ñ œ
Öl
ÐBß Cà D Ñl ×
-
"
-
#
!
Y
Y
>
˜
‚
4
5
5
‚ : Ð
5
5 Ñ
D
0
0
#5
5
5
exp
 + 
 , 
.
(4.3-6)

ˆ
‰‘
™
-
!
!
!
#
#
‡
B
C
"
B
C
3 Bß Cà D
a
b
- is the coded or encrypted object and can be stored by the digital
computer. Note that the spectrum of 
is multiplied by two
l
ÐBß Cà D Ñl
>!
-
#
terms. Since the product of the object s spectrum with the term
processed electronically as shown in Fig. 4.15. In other words, by multi-
plying the incoming signal by cosa
b
H
H
>
>
 and sina
b, and through lowpass
filtering, we obtain two signals, 3  and 3 , respectively, which have been
’
Optical  Scanning Holography: Applications

122
    
exp
 + 
 corresponds to the spectrum of the hologram of
ˆ
‰
4
5
5
D
#5
#
#
B
C
-
!
l
ÐBß Cà D Ñl
>!
-
# [see Eq. (3.5-9)], where the object is recorded at a distance of
D- away from the focal plane of the lens, we can interpret Eq. (4.3-6) as the
holographic information (or hologram) of the object that is encrypted or
coded by 
, i.e., we
encrypt the hologram of the object.  This idea of
:"
coding holographic information was first investigated by Schilling and Poon
in the context of optical scanning holography [Schilling and Poon (1995)].
Decryption
After the object has been coded or encrypted, it will be necessary to decode
or decrypt it. To do this, we turn to the optical system at the secure site.
Again, note that the optical system is the same except for the choice of the
selected pupils, and the laser beams are now scanning a pin hole as an object,
i.e., 
, located at a distance 
 away from the back
l
ÐBß Cà D Ñl œ ÐBß Cà D Ñ
D
>
$
!
.
#
.
.
focal plane of the lens at the decryption stage. We shall call  
 the 
D.
decoding
distance.
 
However, this time the switch, as shown in Fig. 4.15, is connected to
the output of the optical system at the secure site. Through electronic
processing, the output of the photodetector will then be processed. The result
of Eq. (4.3-4) can be applied again, but by replacing 
 with by 
.  Now we
D
D
-
.
choose 
 = 
, a pin hole, and keep 
 as is.  We shall call
: ÐBß CÑ
ÐBß CÑ
: ÐBß CÑ
"
#
$
: ÐBß CÑ
#
 a
. According to Eq. (4.3-2), this selection of the
 decryption key
pupils gives the following OTF,
SXJ Ð5 ß 5 à D Ñ œ
4
5
5
: Ð
5
5 ÑÞ
D
0
0
#5
5
5
H
B
C
B
C
.
#
#
.
!
!
!
B
C
#
exp
 + 
 , 
 
(4.3-7)
”
•
ˆ
‰
By using Eq. (4.3-4) and the fact that 
, we have
Y
>
Öl
ÐBß Cà D Ñl × œ "
!
.
#
3ÐBß Cà D Ñ œ
4
5
5
: Ð
5
5 Ñ
D
0
0
#5
5
5
.
"
#
#
.
!
!
!
B
C
#
B
C
Y
š
›
”
•
ˆ
‰
exp
 + 
 , 
.
(4.3-8)
This is the output generated at the decryption stage, where the decryption key
has been inserted into the stage and a pin hole has been scanned. The
information is now stored in the digital computer to be used to later decrypt
the information coming from the encryption site via a wireless transmission.
To decrypt the information represented by Eq. (4.3-6), a digital decryption
unit (DDU), shown in Fig. 4.16, has been proposed.
 
Again, 
 is the transmitted encrypted information
3ÐBß Cà D Ñ
-
transmitted via wireless from the encryption stage, and 
is the
3ÐBß Cà D Ñ
.
information generated at the decryption site. We see that by using Eq. (4.3-6)
“
”
Optical Scanning Holography with MATLAB
”
•

123
and (4.3-8), at the output of the unit we have
output of DDU
{
}
{
}
º
Ö
3ÐBß Cà D Ñ ‚
3ÐBß Cà D Ñ ×
Y
Y
Y
"
-
.
œ
Öl
ÐBß Cà D Ñl ×
4
5
5
D
#5
Y
Y
>
"
-
#
#
#
!
-
!
B
C
š
”
•
ˆ
‰
exp
 + 
‚ : Ð
5
5 Ñ
4
5
5
: Ð
5
5 Ñ
0
0
D
0
0
5
5
#5
5
5
‡
#
#
"
B
C
#
!
!
!
!
!
B
C
B
C
.
,
exp
 + 
, 
”
•
ˆ
‰
›
œ l
ÐBß Cà D Ñl
 
(4.3-9)
>!
-
#
if the following conditions are simultaneously met. 1) 
, i.e., the
D œ D
.
-
coding distance in the encryption stage and the decoding distance in the
decryption stage are the same, and 2) 
.  Condition
: Ð Bß CÑ: ÐBß CÑ œ "
‡
1
#
(1) simply means that the holographic reconstruction is in focus if Condition
(2) has already been met. For any values of 
, we have what is known
D Á D
.
-
as defocused image reconstruction. Condition (2) allows us to choose the
functional form of the encryption key, 
, in the encryption stage and
: ÐBß CÑ
1
the decryption key
, at the decryption site.  As a simple example, the
ß : ÐBß CÑ
#
choice of phase keys works well. We shall demonstrate this in the following
example.
 
 Fig. 4.16 Digital Decryption Unit (DDU) : 3ÐBß Cà D Ñ
- is the encrypted
information with encryption key, 
, inserted into the encryption stage, which is sent
: ÐBß CÑ
"
from the encryption site via wireless transmission. 
is the signal generated at the
3ÐBß Cà D Ñ
.
decryption site where the decryption key, 
, is inserted into the scanning stage to scan a
: ÐBß CÑ
#
pin hole aperture. Adapted from T.-C. Poon et el., Applied Optics 42, 496 (2003).
Optical  Scanning Holography: Applications

124
Example 4.2 
MATLAB Example on
Optical Scanning Cryptography
As a simple example, we can immediately see that the choice of a random
phase mask is a good encryption key, i.e., we let 
exp
: ÐBß CÑ œ
4# QÐBß CÑ
1
c
d
1
where
is a function of random numbers chosen from a uniform
QÐBß CÑ
distribution between the interval (0.0,1.0). Again, 
 = 
, i.e., a
: ÐBß CÑ
ÐBß CÑ
2
$
pin-hole is the other pupil in the encryption stage. For this choice of pupils,
the encrypted image from Eq. (4.3-6) becomes
 
 
exp
 + 
3ÐBß Cà D Ñ œ
Öl
ÐBß Cà D Ñl ×
4
5
5
D
#5
-
"
-
#
#
#
!
-
!
B
C
Y
Y
>
š
”
•
ˆ
‰
‚
4# QÐ
ß
Ñ
05
5
5
05
exp
.
(4.3-10)
”
•›
1
B
!
!
C
The above encrypted information can be made more secure if, for example,
exp
,
Ò4# <ÐBß CÑÓ
1
 
{
exp
}
3ÐBß Cà D Ñ œ
l
ÐBß Cà D Ñl
Ò4# <ÐBß CÑÓ
-
"
-
#
!
Y
Y
>
1
š
                
exp
 + 
exp
.
‚
4
5
5
4# QÐ
ß
Ñ
D
05
#5
5
5
05
”
•
”
•
ˆ
‰
›
-
!
!
!
#
#
B
C
B
C
1
(4.3-11)
This technique used to obtain the above resulting encrypted image is called
double-random phase encoding [Refregier and Javidi (1995)]. We shall use
MATLAB in order to simulate this coding. Note that 
and
<ÐBß CÑ
QÐBß CÑ
should be chosen as two independent random functions.
 
Table 4.2 contains the m-file for the simulations shown in this
example. Figure 4.17a) shows the original document, 
. Figure
l
ÐBß Cà D Ñl
>!
-
#
4.17b) and 4.17c) show the real part and imaginary part of the original
document multiplied by a random phase mask, exp
, placed
Ò4# <ÐBß CÑÓ
1
immediately in front of the original document. Figure 4.17d) shows the
intensity  of the encrypted document, |
| , which is calculated using
3ÐBß Cà D Ñ
-
Eq. (4.3-11) where we have used sigma
(zc*ld)/(4*pi)
(30)*(0.6*10^-
œ
œ
6)/4  in the m-file [sigma is 
/
 in Eq. (4.3-11)].
1
D #5
-
!
the original document is multiplied by a random phase mask,
where <ÐBß CÑ is a function of random numbers. By using Eq. (4.3-10), the
overall encrypted image then becomes
“
”
Optical Scanning Holography with MATLAB

125
a) Original document.
b) Real part of the image multiplied by random phase mask.
c) Imaginary part of the image multiplied by random phase mask.
Optical  Scanning Holography: Applications

126
d) Intensity of encrypted document.
 
For decryption, we need to gather information in the decryption
stage by scanning a pin-hole object located at a distance of 
 away from the
D.
back focal plane of the lens, where the pupils are 
 (a pin
: ÐBß CÑ œ ÐBß CÑ
"
$
hole) and 
exp
, which satisfies Condition (2) as
: ÐBß CÑ œ
4# QÐ Bß CÑ
#
c
d
1
previously discussed. According to Eq. (4.3-8), the scanned output to be
stored in the digital computer then becomes
3ÐBß Cà D Ñ œ
4
5
5
4# QÐ
ß
Ñ
Þ
D
05
#5
5
5
05
.
"
#
#
.
!
!
!
B
C
B
C
Y
1
š
›

ˆ
‰‘

‘
exp
 + 
exp
  (4.3-12)
According to Fig. 4.16, when the information from Eqs. (4.3-11) and
(4.3-12) are the inputs of the DDU, the output is as follows:
output of DDU º
Ö
×
Y
Y
"š
l
ÐBß Cà D Ñl
Ò4# <ÐBß CÑÓ
>
1
!
-
#exp
‚
4
5
5
4
5
5
D
D
#5
#5
exp
 + 
exp
 + 
”
•
”
•
ˆ
‰
ˆ
‰ ›
-
.
!
!
#
#
#
#
B
C
B
C
œ l
ÐBß Cà D Ñl
Ò4# <ÐBß CÑÓ
>
1
!
-
#exp
,
(4.3-12)
theoretically 
. The decrypted output intensity, i.e., the absolute value
D œ D
.
-
of the DDU s output, is shown in Fig. 4.18a). If the decryption key is chosen
incorrectly (such as the guessing of a random phase mask), Fig. 4.18b) shows
its unusable output intensity. Finally, when the decryption key is used
correctly and if sigma or 
 is guessed or chosen incorrectly, say,
D.
D œ
‚ D
.
-
1.5
, then the absolute value of the DDU s output is shown in Fig.
Fig. 4.17 Cryptography simulations.
’
’
when the sigma used in the m-file is the same as that used for encryption, i.e.,
Optical Scanning Holography with MATLAB

127
4.18c), which is a defocused version of Fig. 4.18a). We see that the
introduction of 
 and 
 gives an extra security measure.
D
D
-
.
.
-.
b) Intensity of decrypted document with mismatched key and D œ D
.
-.
c)Intensity of decrypted document with matched key but with D œ "Þ&D
.
-.
Fig. 4.18 Decryption simulations.
Optical  Scanning Holography: Applications
a) Intensity of decrypted document with matched key and D œ D

128
Table 4.2 Cryptography.m:
m-file for simulating optical scanning cryptography.
------------------------------------------------------
%Cryptography.m
%Simulation of Optical Encryption and Decryption
%This program was adapted from the one developed by Taegeun Kim
%of Sejong Univ., Korea
clear
%L : Normalized length of back ground (field of view)
L=1;
%Dl: Physical field of view in this simulation 20% of L
Dl=0.02;
%N : sampling number
N=255;
% dx : step size
dx=L/N;
%Unit Axis Scaling
%Normalized length and Spatial Frequency according to the Normalized length
for k=1:256
   X(k)=1/255*(k-1)-L/2;
   Y(k)=1/255*(k-1)-L/2;
   %Kx=(2*pi*k)/(N*dx)
   %k is sampling number, N is number of sample,
   %in our case, N=255, dx=1/255(unit length)
   Kx(k)=(2*pi*(k-1))/(N*dx)-((2*pi*(256-1))/(N*dx))/2;
   Ky(k)=(2*pi*(k-1))/(N*dx)-((2*pi*(256-1))/(N*dx))/2;
 end
 %Real length and real spatial frequency
 X=Dl*X;
 Y=Dl*Y;
 Kx=Kx./Dl;
 Ky=Ky./Dl;
%Read Input image, image size must be 575x577x3
%for the program to function properly
CH1=imread('vt.bmp','bmp');
CH1=CH1(:,:,1);
[x,y]=meshgrid(1:577,1:575);
[xi,yi]=meshgrid(1: 2.2539:577,1:2.2461:575);
CH1p=double(CH1);
I0=interp2(x,y,CH1p,xi,yi);
I0=double(I0);
I0=I0./max(max(I0)); %Image to be encrypted
M=rand(256);
M2=rand(256);
%Encryption key in frequency domain,
Optical Scanning Holography with MATLAB

129
%the last term in Eq. (4.3-10)
P=exp(-j*2*pi*M2);
RPM=exp(j*2*pi*M); %random phase mask, exp(j*2*pi*r(x,y))
R1=I0.*RPM;%Random phase mask times the image
%OTF(kx,ky;zc)
%sigma=z/(2Ko)=(z*ld)/(4*pi)
%where Ko is the wave number, z is the distance from the source
%and ld is the wavelength of the source
ld=0.6*10^-6; % wavelength=ld=0.6*10^-6
zc=0.3; %coding distance
sigma=(zc*ld)/(4*pi);
for r=1:256,
    for c=1:256,
   OTF(r,c)=exp(-j*sigma*(Kx(r).^2+Ky(c).^2));
    end
end
for r=1:256,
    for c=1:256,
   OTF2(r,c)=exp(-j*1.5*sigma*(Kx(r).^2+Ky(c).^2));
    end
  end
%Fourier transformation
FR=(1/256)^2*fft2(R1);
FR=fftshift(FR);
Ho=FR.*OTF;
%Encrypted image in the frequency domain
E=Ho.*P;
%Encrypted image in the space domain
e=ifft2(E); %Eq. (4.3-10)
%Key info for decryption key is achieved by scanning the pin hole that is
%located at z=zc
Key_info=conj(OTF.*P); % Fourier transform of Eq. (4.3-11),zd=zc
Key_info2=conj(OTF2.*P); % Fourier transform of Eq. (4.3-11), zd=1.5zc
%Different random phase
M3=rand(256);
P1=exp(j*2*pi*M3);
Key_info_mis=conj(OTF.*P1);% Fourier transform of Eq. (4.3-11) but with a wrong
phase key
%Decrypted image with matched key in the frequency domain
De=E.*Key_info;
%Decrypted image with matched key in the frequency domain
%but with twice distance of zc
Optical  Scanning Holography: Applications

130
De2=E.*Key_info2;
%Decrypted image with matched key in the space domain
de=ifft2(De); %Eq. (4.3-12)
%Decrypted image with matched key in the space domain
%but with zd=1.5 zc
de2=ifft2(De2); %Eq. (4.3-12)
%Decrypted image with mis_matched key in the frequency domain
De_mis=E.*Key_info_mis;
%Decrypted image with mis_matched key in the space domain
de_mis=ifft2(De_mis);
figure(1)
image(X,Y,256*I0);
colormap(gray(256));
axis square
title('image to be encrypted')
axis off
figure(2)
image(X,Y,255*real(R1));
colormap(gray(256));
axis square
title('Real part of the image multiplied by random phase mask')
axis off
figure(3)
image(X,Y,255*imag(R1));
colormap(gray(256));
axis square
title('Imaginary part of the image multiplied by random phase mask')
axis off
figure(4)
image(X,Y,255*abs(e)/max(max(abs(e))))
colormap(gray(256))
axis square
title('Intensity of encrypted image')% absolute value of Eq. (4.3-10)
axis off
figure(5)
image(X,Y,255*abs(de)/max(max(abs(de))));
colormap(gray(256));
axis square
title('Intensity of decrypted image with matched key with zd=zc')
axis off
figure(6)
image(X,Y,255*abs(de_mis)/max(max(abs(de_mis))));
Optical Scanning Holography with MATLAB

131
colormap(gray(256));
axis square
title('Intensity of decrypted image with mismatched key with zd=zc')
axis off
figure(7)
image(X,Y,255*abs(de2)/max(max(abs(de2))));
colormap(gray(256));
axis square
title('Intensity of decrypted image with matched key with zd=1.5zc')
axis off
------------------------------------------------------
References
4.1 
Agard, D. A. (1984). Optical sectioning microscopy: cellular architecture in three
dimensions,
4.2  
Benton, S.A. (1991). Experiments in holographic video,
 IS-08, 247-
Proc. SPIE
267.
4.3 
4.4 
Corle, T. R. and G. S. Kino (1996). Confocal Scanning Optical Microscopy and
Related Imaging Systems, Academic Press, San Diego, CA.
4.5 
Enloe, L. H., J.A. Murphy, and C. B. Rubinstein (1966). Hologram transmission
via television,
 . 45, 333-335.
Bell Syst. Techn. J
4.6  
Gabor, D. (1949). Microscopy by reconstructed wavefronts, Proc. Roy. Soc., ser.
A, 197, 454-487.
4.7 
Hamamatsu Photonics K.K., Japan, and Hamamatsu Corp., Bridgewater, NJ. Image
Processing and Measuring System (IPMS), Model DVS-3010/SS.
4.8 
Hamamatsu Photonics K.K., Japan, and Hamamatsu Corp., Bridgewater, NJ.
Product information sheet for EBSLM model X3636.
4.9 
Huang, D., E.A. Swanson, C. P. Lin, J.S. Shuman, W.G. Stinson, W. Chang, M.R.
Hee, T. Flotte, K. Gregory, C.A. Puliafito, and J. G. Fujimoto (1991).
Optical
coherent tomography,
, Vol. 254, 1178-1181.
Science
4.10 
Indebetouw, G. (2002). Properties of a scanning holographic microscope: improved
resolution, extended depth of focus, and/or optical sectioning, Journal of Modern
Optics 49, 1479–1500.
4.11 
Indebetouw, G., T. Kim, T.-C. Poon, and B. Schilling (1998). Three-dimensional
location of fluorescent inhomogeneities in turbid media using scanning heterodyne
holography,
23, 135-137.
Optics Letters 
4.12 
Indebetouw, G. and W. Zhong (2006) Scanning holographic microscopy of three-
dimensional fluorescent specimens,
A
Journal of the Optical Society of America 
23, 1699-1707.
4.13 
Kim, M (2000) Tomographic three-dimensional imaging of a biological specimen
using wave-scanning digital interference holography,
 7, 305-310.
Optics Express
4.14 
Extraction of 3-D location of matched 3-D object
using power fringe-adjusted filtering and Wigner analysis,
38,
Optical Engineering 
2176-2183.
4.15 
Kirk, R. L. (1984). Electronically generated holography, 
No.
International Patent 
WO 84/00070.
“
”
“
”
“
”
“
”
“
”
“
”
“
”
“
”
“
”
“
”
Brown, H. B., S.C. Noble and B.V. Markevitch (1983). Three-dimensional tele-
vision system using holographic technique, U.S. Patent # 4,376,950.
Kim, T and T.-C. Poon (1999).
Optical  Scanning Holography: Applications
Ann. Rev. Biophys. Bioeng. 13, 191-219.

132
4.16  
Lai, S. and M. A. Neifeld (2000). Digital wavefront reconstruction and its
applications to image encryption,
 178, 283-289.
Optics Communications
4.17 
Lohmann, A.W.,  W. Stork, and G. Stucke (1986), Optical perfect shuffle, Applied
Optics 25 , 1530-1531.
4.18  
Macovski, A. (1971). Considerations of television holography,
, 18,
Optica Acta
31-39.
4.19  
Magensen, P.C. and J. Gluckstad (2001). Phase-only optical decryption of a fixed
mask,
 8, 1226-1235.
Applied Optics
4.20 
Minsky, M. (1961). Microscopy Apparatus, 
 # 3,013,467.
US Patent
4.21 
Pawley, J. ed. (1995).
Handbook of Biological Confocal Microscopy, 2  ed., Plenum Press.
nd
4.22 
Poon, T.-C. (2002a).
Three-dimensional television using optical scanning
holography,” 
 3, 12-16.
Journal of Information Display
4.23 
Poon, T.-C. (2002b).
in
Optical scanning holography: principles and applications,
Three-Dimensional Holographic Imaging, C.J. Kuo and M. H. Tsai, ed., John Wiley
& Sons, Inc.
4.24 
Poon, T.-C. (2005). Three-dimensional optical remote sensing by optical scanning
holography,  Current Research on Image Processing for 3D information displays,
sponsored by SPIE Russia Chapter, V. Petrov, ed., 
,
Proc. SPIE  Vol. 5821, 41-59.
4.25 
Poon, T.-C. (2006).
Horizontal-parallax-only optical scanning holography,
in
Applications, T.-C. Poon ed., Springer, New York, USA.
4.26 
Poon, T.-C, K. Doh, B. Schilling, M. Wu, K. Shinoda, and Y. Suzuki (1995).
4.27 
Poon, T.-C., K. Doh, B. Schilling, K. Shinoda, Y. Suzuki, and M. Wu (1997).
Holographic three-dimensional display using an electron-beam-addressed spatial-
light-modulator,
 567-571.
 Optical Review
4.28 
Poon, T.-C. and T. Kim (1999).
Optical image recognition of three-dimensional
objects,
38, 370-381.
 Applied Optics 
4.29 
Poon, T.-C., B. D. Schilling, G. Indebetouw, and B. Storrie (2000). Three-
dimensional holographic fluorescence microscopy, 
 # 6,038,041.
U.S. Patent
4.30 
Poon, T.-C.,  T. Kim, and K. Doh (2003) Optical scanning cryptography for secure
wireless transmission,
 42, 6496-6503.
Applied Optics
4.31 
Poon, T.-C., T. Akin, G. Indebetouw and T. Kim (2005). Horizontal-parallax-only
electronic holography   
 13, 2427-2432.
,
Optics Express
4.32 
Poon, T.-C. and T. Kim (2006). 
, World
Engineering Optics with MATLAB®
Scientific, Singapore.
4.33 
National Academies Press, Washington, D.C.
4.34 
plane random phase encoding,
20, 767-769.
Optics Letters 
4.35  
Schilling, B. W. and T.-C. Poon (1995). Real-time pre-processing of holographic
information,
 34, 3174-3180.
 Optical Engineering
4.36 
Schilling, B. W. (1997).
Three-dimensional fluorescence microscopy by optical
scanning holography,  Ph.D. dissertation, Virginia Tech.
4.37 
Schilling, B., T.-C. Poon, G. Indebetouw, B. Storrie, K. Shinoda, and M. Wu
(1997).
Three-dimensional holographic fluorescence microscopy,
Optics Letters
22, 1506-1508.
“
”
“
”
“
”
“
”
“
”
“
“
”
“
”
“
”
neering 34, 1338–1344.
“
”
“
”
“
”
”
“
”
“
”
“
”
“
”
chapter 10 of Digital Holography and Three-Dimensional Display: Principles and
Fundamental limits in confocal microscopy,  in chapter 2 of
“Three-dimensional microscopy by optical scanning holography,” Optical Engi-
Radio Frequency Identification Technologies: A Workshop Summary (2004). The
Refregier P. and B. Javidi (1995) “Optical image encryption using input and Fourier
Optical Scanning Holography with MATLAB

133
4.38 
Schilling, B.W. and T.-C. Poon (2004). Multicolor electronic holography and 3-D
image projection system, 
# 6760134.
U.S. Patent 
4.39 
Shinoda, K., Y. Suzuki, M. Wu and T.-C. Poon (1991). Optical heterodyne scanning
type holography device, 
# 5064257.
U.S. Patent 
4.40 
Proc. SPIE, vol. 1212, 174-182.
4.41 
St. Hilaire, P., S. A. Benton, and M. Lucente (1992).
Synthetic aperture
holography: a novel approach to three-dimensional displays, Journal of the Optical
Society of America A 9, 1969-1977.
4.42 
Sun, P and J. -H. Xie (2004).
images in scanning holography with a Fresnel-zone-plate coded aperture, Applied
Optics 43, 4214-4218.
4.43  
Tajahuerce, E., J. Lancis, B. Javidi, and P. Andres (2001).
Optical security and
encryption with totally incoherent light,
 26, 678-680.
Applied Optics
4.44  
Wang, B, C.-C. Sun, W.-C. Su, and A. Chiou (2000). Shift-tolerance property of an
optical double-random phase-encoding encryption system,
39,
Applied Optics 
4788-4793.
4.45 
Wilson, T. and C. Sheppard (1984). Theory and Practice of Scanning Optical
Microscopy  , Academic Press.
4.46  
Zhang, T. and I. Yamaguchi (1998).
Three-dimensional microscopy with phase-
shifting digital holography,
  23, 1221-1223.
Optics Letters
“
”
“
”
“
”
“
”
“
”
“
”
Electronic display system for computational holography,
J. Underkoffler (1990).
St. Hilaire, P., S. A. Benton, M. Lucente, M. Jepsen, J. Kollin, H. Yoshikawa, and
Method for reduction of background artifacts of
Optical  Scanning Holography: Applications

Chapter 5
Optical Scanning Holography: Advances
5.1 Coherent and Incoherent Holographic Processing
In chapter 4, we have discussed some applications that employ optical
scanning holography (OSH). OSH has been implemented by the two-pupil
optical heterodyne scanning image processor that we have discussed in
chapter 3 [see Fig. 3.11]. All of our discussions regarding the applications
that we use OSH have so far been confined to incoherent image processing,
i.e., the objects that are processed are incoherent and this leads to some of the
important applications of 3-D fluorescence microscopy and remote sensing.
Coherent 3-D imaging, nevertheless, is an important extension of the
processor in biological imaging for the area of quantitative phase-contrast
imaging [Cuche, Bevilacqua, and Depeursinge (1999)].
Fig. 5.1 Generalized two-pupil image processor. Adapted from T.-C. Poon,
J. Holography Speckle 1, 6-25 (2004).

In this section, we will discuss how the image processor can be configured
(or generalized) in order to work in a coherent mode, i.e., the amplitude
instead of the intensity of the object can be processed. We shall use Fourier
optics discussed in chapter 2, in order to fully analyze the processor.
 
The generalized processor is shown in Fig. 5.1 with its usual two-
pupil set-up for optical scanning of the 3-D object. As compared to the
standard setup shown in Fig. 3.11, note that the Fourier transform lens, L2,
and the mask, 
, are the additional elements in the system. We will
QÐBß CÑ
model the 3-D object as a stack of transverse slices where each slice of the
object is represented by an amplitude transmittance, 
, which is thin
XÐBß Cà DÑ
and weakly scattering. We will place the 3-D object in front of the Fourier
transform lens, L2. 
 is a mask locate
QÐBß CÑ
d at the back focal plane of lens
L2. The photodetector, PD, collects all the light transmitted by the mask and
delivers the processed and scanned current, 
, as output of the system.
3Ð>Ñ
Finally, for the usual multiplexing electronic detection the bandpass filter
(BPF) is tuned to 
 to give the heterodyne current, 
. By using Fourier
H
3 Ð>Ñ
H
optics, we shall outline the procedures used to obtain 
 upon scanning the
3Ð>Ñ
object.
 
The amplitude distribution of the light field, 
 just before
at position D
the object 
is given by
slice, 
       
,
(5.1-1a)
T ÐBß Cà D D Ñ
Ð4
>Ñ T ÐBß Cà D D Ñ
Ò4Ð

Ñ>Ó
"
!
!
#
!
!
exp
exp
=
=
H
where, according to Fresnel diffraction,
      
{
}
(5.1-1b)
T ÐBß Cà D D Ñ œ
: ÐBß CÑ
‡2ÐBß Cà D D Ñ
3
!
!
3
5
ß5
Y
B
C
5 B
5 C
!
!
0
0
=
=
with 
or  and 
 is the pupil functions shown in Fig. 5.1.
3 œ "
#
: ÐBß CÑ
3
 
According to the principle of optical scanning developed in section
3.1, t
slice 
he field just after the object 
is
;
=
ÐB ß C ß Bß Cà DÑ œ ÖT ÐB ß C à D D Ñ
Ð4
>Ñ
w
w
w
w
"
!
!
exp
     
,
(5.1-2))
(5.1-2
T ÐB ß C à D D Ñ
Ò4Ð

>Ó×XÐB Bß C Cà DÑ
#
!
!
w
w
w
w
exp
=
H
where 
 and 
 represent the instantaneous 2-D position of the
B œ BÐ>Ñ
C œ CÐ>Ñ
object with respect to the incident light amplitude distribution. This field then
propagates through the Fourier transform lens, L2, and reaches the mask,
 
QÐBß CÑÞ According to Eq. (2.4-5), the field just before the mask, apart from
some inessential constant, is
136
Optical Scanning Holography with MATLAB

137
expÒ 4
ÐB
C
ÑÓ
5 D
#0
!
#
7
7
#
#
‚
ÐB ß C ß Bß Cà DÑ
Ò4
ÐB B
C C ÑÓ.B .C
5
0
( ( ;
w
w
w
w
w
w
!
7
7
exp
,
where we have set 
 in Eq. (2.4-5) to obtain the phase factor in
. œ 0 D
!
front of the integral. 
 and 
 are the coordinates
B
C
7
7
 in the plane of the mask.
The above field is caused by a single object slide. For a 3-D object, we need
to integrate the above field over the thickness, , of the 3-D object to find the
D
total field just before the mask. This becomes the following expression
( šexpÒ 4
ÐB
C
ÑÓ
5 D
#0
!
#
7
7
#
#
‚
ÐB ß C ß Bß Cà DÑ
Ò4
ÐB B
C C ÑÓ.B .C
.D
5
0
( (
›
;
w
w
w
w
w
w
!
7
7
exp
.
By multiplying the above field by the mask, the field, just after the mask is
then given by
<ÐBß Cà B ß C Ñ œ
Ò 4
ÐB
C
ÑÓ
5 D
#0
7
7
7
7
!
#
#
#
š
’
(
exp
‚
ÐB ß C ß Bß Cà DÑ
Ò4
ÐB B
C C ÑÓ.B .C .D QÐB ß C Ñ
5
0
( (
“
›
;
w
w
w
w
w
w
!
7
7
7
7
exp
.
Finally, the photodetector, PD, which responds to intensity, gives 
current
the 
output
  
 
 by spatially integrating the intensity:
3Ð>Ñ
3Ð>Ñ º
l ÐBß Cà B ß C Ñl .B .C
( <
7
7
7
7
#
 .
3Ð>Ñ consists of a baseband current and a heterodyne current at a frequency of
H. After some manipulations, the heterodyne current, 
, at the output of a
3 Ð>Ñ
H
bandpass filter [see Fig. (5.1)], becomes
3 Ð>Ñ º
T B ß C à D D T
B ß C à D D
4 >
H
( c
a
b
a
b
a
b
"
!
!
w
w
w
‡
ww
ww
ww
#
exp
H
a
b
a
b
a
b
T B ß C à D D T
B ß C à D D
4 > Ó
#
!
!
w
w
w
‡
ww
ww
ww
"
exp
H
‚
Ö4
ÒB ÐB B Ñ C ÐC C ÑÓ×
5
0
exp
!
7
7
w
ww
w
ww
Optical Scanning Holography: Advances

138
‚
Ò 4
ÐB
C
ÑÓXÐB Bß C Cà D Ñ
5 ÐD D Ñ
#0
exp
!
w
ww
#
7
7
#
#
w
w
w
‚ X ÐB
Bß C Cà D Ñ QÐB ß C Ñ
‡
ww
ww
ww
7
7
#
k
k
‚ .B .C .B .C .D .D .B .C
w
w
ww
ww
w
ww
7
7.
(5.1-3)
This heterodyne current contains the scanned and processed information of
the 3-D object. Different processing operations can be expected with the
specified selections of the pupils, 
 and 
, as well as the mask,
: ÐBß CÑ
: ÐBß CÑ
1
#
QÐBß CÑ, which is located at the back focal plane of lens L2. As calculated
by Indebetouw, Klysubun, Kim, and Poon [2000], the coherency of the two-
pupil scanning system can be modified by changing the mask, 
.
QÐB ß C Ñ
7
7
We shall summarize the results of Eq. (5.1-3) for 
 and
QÐB ß C Ñ œ "
7
7
QÐB ß C Ñ œ ÐBß CÑ
7
7
$
.
 
For the mask being an open mask, i.e., 
 Eq. (5.1-3)
QÐBß CÑ œ "ß
becomes
 3 Ð>Ñ º
H
Re’( T ÐB ß C à D D ÑT ÐB ß C à D D Ñ
‡
w
w
w
w
"
!
#
!
‚ l ÐB Bß C Cà DÑl .B .C .D
Ð4 >Ñ
X
w
w
w
w
2
exp
H “.
(5.1-4)
This equation is basically identical to Eq. (3.4-5), which corresponds to
incoherent processing, because only the intensity values, i.e.,
, are
lXl#
processed. However, note that the intensity can be processed by the two
pupils, : ÐBß CÑ
: ÐBß CÑ
1
 and 
.
#
 
On the other hand, for a pinhole mask centered on the axis, i.e.,
QÐBß CÑ œ ÐBß CÑ
$
. Equation (5.1-3) then becomes
3 Ð>Ñ º
Ò
T ÐB ß C à D D ÑXÐB Bß C Cà D Ñ .B .C .D Ó
H
Re’ (
2
w
w
w
w
w
w
w
w
w
!
‚ Ò
T ÐB ß C à D D ÑX ÐB
Bß C Cà D Ñ .B .C .D Ó
Ð4 >Ñ
(
“
‡
ww
ww
ww
‡
ww
ww
ww
ww
ww
ww
"
!
exp
H
.
For a specific case, if we let 
, i.e., one of the scanning
: ÐBß CÑ œ ÐBß CÑ
1
$
beams is a uniform plane wave, and leave 
 as is, then
: ÐBß CÑ
#
'_
_
‡
ww
ww
ww
‡
ww
ww
ww
ww
ww
ww
"
!
T ÐB ß C à D D ÑX ÐB
Bß C Cà D Ñ .B .C .D is 
a 
constant,
and the above equation becomes
3 Ð>Ñ º
H
Re’( ÒT ÐB ß C à D D Ñ
2
w
w
!
Optical Scanning Holography with MATLAB

139
‚ X
Ð4 >Ñ
ÐB Bß C Cà DÑ .B .C .D Ó
w
w
w
w
exp
H “.
(5.1-5)
We see that we can process the object s amplitude transmittance by pupil
: ÐBß CÑ
#
. Equations (5.1-4) and (5.1-5) represent the important results of the
generalized two-pupil heterodyne scanning image processor. By varying the
detection mode from pinhole to spatially integrating detection, we are able to
change the coherence property of the imaging process of a 3-D object from
linear in intensity [see Eq. (5.1-4)] to linear in amplitude [see Eq. (5.1-5)].
By varying the size of the mask, it is possible to obtain 3-D partial coherent
image processing [Poon and Indebetouw (2003)].
 
By incorporating Eq. (5.1-4) and (5.1-5) into one simple important
result, we have
 
3 Ð>Ñ º
3
ÐBß CÑ
Ð4 >Ñ
H
H
Re
,
(5.1-6a)
c
d
:
exp
H
where, 
 the following
for 
 and 
 we have
QÐBß CÑ œ ÐBß CÑ
: ÐBß CÑ œ ÐBß CÑ
$
$
1
coherent processing equation,
    
.
(5.1-6b)
3
ÐBß CÑ œ
T ÐB ß C à D D Ñ ÐB Bß C Cà DÑ .B .C .D
H:
w
w
w
w
w
w
!
(
2
X
F
, we have the incoherent processing equation,
or QÐBß CÑ œ "
          3
ÐBß CÑ œ
T ÐB ß C à D D ÑT ÐB ß C à D D Ñ
H:
‡
w
w
w
w
"
!
#
!
(
      
.  
(5.1-6c)
‚ l ÐB Bß C Cà DÑl .B .C .D
X
w
w
#
w
w
 
Again 
or 
is the input object that is being scanned and it can be
X
lXl#
a complex amplitude object or intensity object. 3 Ð>Ñ
H
 is the scanned and
processed heterodyne output current at a temporal frequency of 
 from the
H
photodetector, and 
 is in general a complex function. Hence, the
3
ÐBß CÑ
H:
amplitude and the phase of the heterodyne current, 
, carry the complete
3 Ð>Ñ
H
processed information.
 
The scanned and processed current can be demodulated according to
Fig. 5.1 under the usual multiplexing electronic detection, and this gives the
following two outputs:
 
 
         
sin
, 
(5.1-7a)
3 ÐBß CÑ º l3
ÐBß CÑl
Ð Ñ
c
H:
)
and
 
 
         
cos
,
(5.1-7b)
3 ÐBß CÑ º l3
ÐBß CÑl
Ð Ñ
=
:
H
)
’
Optical Scanning Holography: Advances

140
where 
exp
. Processing operations can be
3
ÐBß CÑ œ l3
ÐBß CÑl
Ò4 ÐBß CÑÓ
H
H
:
:
)
manipulated by the selected choice of pupils, : ÐBß CÑ
: ÐBß CÑ
1
2
 and/or 
,
according to Eq. (5.1-6).
 
These important results open up new avenues for unconventional
processing, we can perform 
. The
3-D complex incoherent image processing
term 3-D means the object being processed can be of a 3-D nature, and the
term
complex  means that the processing element for the intensity object
can be represented by a complex function [see Eq. (5.1-4) as the processing
element is 
. Thus, we have mentioned some of the virtually unexplored
T T
‡
"
#]
topics in 3-D optical image processing [Poon and Indebetouw (2003)].
Example 5.1 
Holographic Recording in Coherent Mode
For coherent processing, we will use Eq. (5.1-6b). In general, XÐBß Cà DÑ is
processed by selecting : ÐBß CÑ
2
. For a simple holographic recording, we
select 
. For this selection, according to Eq. (5.1-1b) and by using
: ÐBß CÑ œ "
2
Table 1.1 and Eq. (2.3-11), 
 becomes
T ÐBß Cà D D Ñ
#
!
T ÐBß Cà D D Ñ œ
: ÐBß CÑ
‡2ÐBß Cà D D Ñ
#
!
!
#
5
ß5
Y{
}
B
C
5 B
5 C
!
!
0
0
=
=
         œ %1 $
# Ð
Ñ
5 B
0
0
5 C
!
!
,
                    ‡
D D
D D
D D
š
›
exp
exp
Ò 45 Ð
ÑÓ
45
# Ð
Ñ
Ð
Ñ
!
!
!
!
!
1
’ 45 ÐB C Ñ
#
!
#
#
“
                
exp
exp
(5.1-8)
º
Ò 45 Ð
ÑÓ
45
# Ð
Ñ
Ð
Ñ
!
!
D D
D D
D D
!
!
!
1
’ 45 ÐB C Ñ
#
!
#
#
“.
By substituting Eq. (5.1-8) into Eq. (5.1-6b), we  now have
 3
ÐBß CÑ œ
H:
( expÒ 45 Ð
ÑÓ
45
# Ð
Ñ
!
!
D D
D D
!
!
1
                  
; 
‚
ÐB Bß C C
.B .C .D
exp’ 45 ÐB
C Ñ
#
X
!
w
w
#
#
Ð
Ñ
DÑ
D D!
“
w
w
w
w
                œ ( expÒ 45 Ð
ÑÓ
45
# Ð
Ñ
!
!
D D
D D
!
!
1
imaging. For one, coherent processing has been recently assessed experi-
mentally [Indebetouw, Tada and Leacock (2006)], and the other is its abi-
lity to perform 3-D coherent image processing. In the case of incoherent
“
”
“
”
Optical Scanning Holography with MATLAB

141
      
 
‚
ÐBß Cà DÑ .D
”
•
šexp’ 45 ÐB
C Ñ
#
Œ
!
#
#
‡
+ 
Ð
Ñ
D D
X
!
“›
 
according to the definition of correlation. By using Eq. (1.2-5), the above
integration can be written in terms of convolution to become
     3
ÐBß CÑ œ
H:
( expÒ 45 Ð
ÑÓ
45
# Ð
Ñ
!
!
D D
D D
!
!
1
 
.
(5.1-9)
‚
ÐBß Cà DÑ .D
”
•
šexp’ 45 ÐB
C Ñ
#
‡ X
!
#
#
+ 
Ð
Ñ
D D!
“›
Note that this corresponds to the holographic recording of coherent
information, 
, because it is clearly shown by comparing it to the
XÐBß Cà DÑ
incoherent case given by Eq. (3.5-5). Indeed, Eq. (5.1-9) tells us that we have
a complex Fresnel zone plate hologram of 
.
XÐBß Cà DÑ
5.2  Single-Beam Scanning vs. Double-Beam Scanning
Recently, the applicability of optical scanning holography (OSH) to 3-D
microscopy has been assessed by taking into account polarization effects,
high numerical apertures, and generalized illumination wavefronts [Swoger,
Martinez-Corral, Huisken, and Stelzer (2002)]. In low-
 systems,
RE
polarization remains the same during light propagation. Polarization is
necessarily taken into account when high-
 lenses are used. Generalized
RE
illumination refers to the use of the two pupils associated with the two
scanning beams. Ideally, one of the pupils is a delta function and the other is
 that the object, lXÐBß C DÑl
T
;
, is actually illuminated by 
#
"
#
*
 
The authors also use the term reference beam  and object beam
when referring to the plane wave and the spherical wave in the ideal case. In
addition, a single-beam scanning technique has been proposed and compared
to double-beam scanning. 
 in OSH refers to the fact
Double-beam scanning
that the combination of a plane wave and a spherical wave is used to raster
scan a thick specimen, while 
means that only one of
single-beam scanning 
the waves is used to scan and the other wave remains stationary with respect
the beam and mirror M2 is fixed. For double-beam scanning, M2 is used to
“
”
“
”
unity. This gives a plane wave and a spherical wave on the object, res-
pectively. For arbitrary pupil functions, we have a generalized illumination
wavefront on the object [Indeed, for example, Eq. (5.1-4) points to the fact
T , thereby pro-
viding a generalized illumination].
to the specimen. Figure 5.2 shows the schematics of the scanning con-
figurations for OSH. For single-beam scanning, mirror M1 is used to scan
Optical Scanning Holography: Advances

142
scan and M1 is fixed. The specimen and the mask are placed in the front
focal plane and in the back focal plane of lens L2, respectively. This
corresponds to the situation shown in Fig. 5.1. In the following section, we
will summarize some observations made by Swoger et al.
Fig. 5.2 Scanning configurations for optical scanning holography.
 (M: mirror, M1,2: scanning mirrors, BS:beamsplitter, L1 and L2: lenses; PD: photodetector).
 
Regardless of the polarization directions of the two scanning beams,
double-beam scanning is well suited for optical scanning holography when
working in the incoherent mode (open mask in front of the detector).
However, in order to obtain holographic information in a coherent mode
(pin-hole mask in front of the detector), it is necessary to have a uniform
plane wave as one of the scanning beams on the object. In any case, if the
reference beam is a uniform plane wave and the object wave has the same
polarization of the plane wave, the results reduce to the conclusion developed
earlier by Indebetouw, Klysubun Kim, and Poon [2000]. On the other hand,
during single-beam scanning for the coherent mode, there is no need for the
reference beam to be uniform and the polarization directions do not need to
be constant. The reference beam here now refers specifically to the beam that
is not being scanned. However, the incoherent mode is restricted by the
constant polarization direction of the reference beam when we attempt to
obtain holographic information. Therefore, there are several pros and cons
Optical Scanning Holography with MATLAB

143
associated with the two scanning configurations and for future work we
should include the actual implementation of a high-
 optical scanning
RE
holographic system that is capable of allowing us to observe live biological
specimens in both fluorescence and phase contrasts. Recently, optical
scanning holographic systems operating in the coherent mode have been
implemented to test its phase contrast capabilities [Indebetouw, Tada, and
Leacock (2006)]. To end this section, I also want to point out that recent
experiments have been demonstrated by using single-beam scanning [Chien,
Dilworth, Liu and Leith (2006)]. The authors consider the term scanning
holography  and synthetic-aperture optics  to be essentially interchangeable
because both techniques imply phase-preserving scanning. Indeed, it was
pointed out as early as the late 1970 s in the article by Poon and Korpel
[1979] that scanning holographic recording was analogous to synthetic-
aperture radar.
5.3 PSF Engineering
"
 and : ÐBß CÑ œ
ÐBß CÑ
#
$
!
M
ÐBß Cà >Ñ
scan
œ l +
Ò4Ð
Ñ>Ó 
Ò 
Ó
Ð4
>Ñl
45
45 B C Ñ
D
#D
exp
+
 exp
exp
,
2
(
=
H
=
1
!
!
!
!
!
!
#
2
2
  
 
,
(5.3-1)
2
œ E F
Ò
ÐB C Ñ 
>Ó
5
D
sin
!
!
2
2
H
where it is understood that the two pupils are of different temporal
frequencies accordingly. The scanning beam intensity is the time-dependent
Fresnel zone plate, and the situation is shown schematically in Fig. 5.3a).
 
If the object is a pin hole, a delta function mathematically, then the
output after electronic detection (for example, multiplying with cos
 and
H>
lowpass filtering) is given by Eq. (3.6-3) as follows:
3 ÐBß CÑ μ
Ò
ÐB C ÑÓ
5
D
-
!
!
sin 2
.
(5.3-2)
2
2
“
”
“
”
’
As pointed out in section 3.6, the basic principle of optical scanning hologra-
phy is that we simply create the time-dependent Fresnel zone plate (TDFZP)
in order to raster scan the object that allows us to obtain holographic infor-
mation. This can be implemented by the two-pupil heterodyne image pro-
cessor that was discussed in section 3.4. In the processor, we let the two
pupil functions be : ÐBß CÑ œ "
shown in Fig. 5.3a), so that the scanning beam intensity at a distance of
 on the pupil plane, as
D
away from the focal point, c, of the lens is given by Eq. (3.6-1) as follows:
Optical Scanning Holography: Advances

144
The result above is the hologram of a pin-hole object for the single channel.
For brevity, the channel due to the multiplying with sin
 and lowpass
H>
filtering is not considered here. Upon plane-wave illumination of the
hologram, a real image will focus at 
 in front of the hologram. If the
D!
hologram has a limiting aperture size of radius , then its 
 is 
, which
<
RE
<ÎD0
gives 
as the resolution of the reconstructed point source. This
-0ÎRE
reconstructed point source is the point spread function (PSF) of the system
being considered. Now, by manipulating the functional form of the pupils,
we can modify the PSF of the system as we see fit. Nowadays, this is known
as 
 [Martinez-Corral (2003)].
PSF-engineering
Fig. 5.3a) Optical scanning holography with time-dependent FZP as a scanning beam.
b) Optical scanning holography with scanning spherical waves of opposite curvatures.
Adapted from T.-C. Poon, J. Holography and Speckle 1, 6 (2004).
"
set 
exp
. We shall find the PSF with these choices of
: ÐBß CÑ œ
Ò 
Ó
#
45 B C Ñ
#D
!
3
( 2
2
the pupils. We are familiar with the choice of 
 because it gives a
: ÐBß CÑ œ "
"
Let us consider the following situation. We let : ÐBß CÑ œ " as before, but
Optical Scanning Holography with MATLAB

145
spherical wave on the object at a distance 
 away from the focal plane of the
D!
lens, which corresponds to the term 
 exp
exp
 in Eq.
45
D
#D
45 B C Ñ
!
!
!
!
!
2
(
1
Ò 
Ó
Ð4
>Ñ
2
2
=
(5.3-1).  The situation is shown in Fig. 5.3b). Let us find what  is in Eq.
+
(5.3-1) for the choice of  
 given above. Note that 
 is now a
: ÐBß CÑ
+ÐBß CÑ
#
function of  and . Through the Fourier transformation of the lens [see Eq.
B
C
(2.4-6)] and Fresnel diffraction at a distance of 
 [see Eq. (2.3-12)], we can
D!
write the field distribution due to 
 on the object as
: ÐBß CÑ
#
 
(5.3-3)
+ÐBß CÑ œ
: ÐBß CÑ
D
YBCÖ
×
‡ 2ÐBß Cà
Ñ
#
!
º
5Cœ5 CÎ0
!
5 œ5 BÎ0
B
!
œ
Ò 
Ó
D
45 ÐB C Ñ
#D
 
exp
YBC˜
™º
!
3
!
2
2
5 œ5 CÎ0
C
!
5 œ5 BÎ0
B
!
‡ 2ÐBß Cà
Ñ,
where  is the focal length of the lens. The above Fourier transformation can
0
be found by using Table 1.1 on page 2. We then perform the convolution and
the result, apart from some constant, is given as follows:
+ÐBß CÑ œ
Ò
Ó
45
45 ÐB C Ñ
D
#D
!
!
"
"
2
exp
.
(5.3-4)
1
2
2
w
"
"
3
"
"
"
0 D
0 D D
0

œ
3
!
"
 
.
(5.3-5)
Therefore, we can design 
 with a different radius of curvature.
: ÐBß CÑ
#
 
For the choices of 
 and 
, Eq. (5.3-5) will be
D œ #0
D œ D œ 0Î%
3
!
"
satisfied. Since 
, we will have spherical waves of opposite curvatures
D œ D
!
"
illuminating the specimen. Hence, with Eq. (5.3-4) and 
, the scanning
D œ D
!
"
beam intensity becomes
M
ÐBß Cà >Ñ
scan
º l
Ò
Ó
Ò4Ð

Ñ>Ó 
Ò 
Ó
Ð4
>Ñl
45 ÐB C Ñ
45 ÐB C Ñ
#D
#D
exp
exp
exp
exp
!
!
!
!
!
!
#
2
2
2
2
=
H
=
Note that +ÐBß CÑ can either be converging wavefronts or divergent wave-
fronts on the specimen and this is dependent on the location of the focused
point, p. In Fig. 5.3b), we show that point c is the image point of the focused
point, p, and hence the radius of curvature, D , is positive in the situation
Example 2.4 on spherical wave]. The value of D  can be designed accordingly
by properly locating point p or the distance, D , under the imaging condition
so that
because we have converging wavefronts illuminating the specimen [see
Optical Scanning Holography: Advances

146
  
 
,
(5.3-6)
2
œ E F
Ò
ÐB C Ñ 
>Ó
5
ÐD Î#Ñ
w
w
!
!
sin
2
2
H
where 
 and
 are some constants. The above scanning beam gives
E
F
w
w
3 ÐBß CÑ μ
Ò
ÐB C ÑÓ
5
D
-
!
!
sin
2
2
(5.3-7)
as our new hologram for the selected pupils. Upon real image reconstruction
of the hologram given by Eq. (5.3-7), we see that the image is formed at a
distance of 
. For the same limiting aperture size of the hologram, ,
D Î#
<
!
similar to the standard optical scanning setup, its 
 now becomes
RE
<ÎÐD Î#Ñ
ÎÐ#REÑ
0
0
. This gives 
as the resolution of the reconstructed point
-
source, which is our new PSF. The result means that for the same hologram
aperture size, it is possible to synthesize the point-spread function in optical
scanning holography in order to obtain holographic reconstructions with a
transverse resolution exceeding the Rayleigh limit of the aperture up to a
factor of 2, at least in the limit of low 
. Indeed, this has been investigated
RE
by Indebetouw (2002) and was recently confirmed by optical experiments
[Indebetouw, Maghnouji, and Foster (2005)]. Other pupils examined so far
include 
, which have been used to achieve optical sectioning,
axicons
however, thus far only simulations have been provided [Indebetouw, Zhong,
and Chamberlin-Long (2006)].
 
In general, arbitrary complex amplitude distributions of the pupils
can be synthesized by using masks, refractive or diffractive optical elements
(DOEs), or spatial light modulators which allow dynamic changes. For
: ÐBß CÑ œ
Ò 
#
45 B C Ñ
#D
exp
!
!
( 2
2
3
plane as shown in Fig. 5.3b). In general, I want to point out that the two-
pupil method offers a broad range of possibilities when synthesizing
applications is 
 [Indebetouw, Tada, Rosen and Brooker
super-resolution
(2007)].
References
5.1 
Chien, W.-C., D. S. Dilworth, E. Liu, and E. N. Leith (2006). Synthetic-aperture
chirp confocal imaging,
 45, 501-510.
Applied Optics
5.2 
Cuche, E., F. Bevilacqua, and C. Depeursinge (1999).
quantitative phase-contrast imaging,
 24, 291-293.
Optics Letters
Ó shown in this example, we can simply imple-
ment it by placing a point source at a distance, D , in front of the pupil
“
”
”
unconventional PSFs for potential novel applications. One of the new
“Digital holography for
Optical Scanning Holography with MATLAB

147
5.3  
Indebetouw, G. (2002). Properties of a scanning holographic microscope: improved
resolution, extended depth of focus, and/or optical sectioning,  Journal of Modern
Optics 49, 1479-1500.
5.4  
Indebetouw, G., P. Klysubun, T. Kim, and T.-C. Poon (2000). Imaging properties
of scanning holographic microscopy, Journal of the Optical Society of America A
17, 380-390.
5.5 
Indebetouw, G., A. El Maghnouji, and R. Foster (2005).
Scanning holographic
microscopy with transverse resolution exceeding the Rayleigh limit and extended
depth of focus,
 22, 829-898.
Journal of the Optical Society of America A
5.6 
Indebetouw, G., Y. Tada and J. Leacock (2006). Quantitative phase imaging with
scanning holographic microscopy: an experimental assessment,  available at
http://www.biomedical-engineering-online.com/content/5/1/63.
5.7 
Indebetouw, G., W. Zhong, and D. Chamberlin-Long (2006). Point-spread function
synthesis in scanning holographic microscopy,
Journal of the Optical Society of
America A 23, 1708-1717.
5.8 
Indebetouw, J., Y. Tada, J. Rosen, and G. Brooker (2007). Scanning holographic
microscopy with resolution exceeding the Rayleigh limit of the objective by
superposition of off-axis holograms,
, to appear.
Applied Optics
5.9 
Martinez-Corral, M. (2003).
Point spread function engineering in confocal
scanning microscopy,
, Vol. 5182, 112-122.
Proceedings of SPIE
5.10 
Poon, T.-C. and A. Korpel (1979).
Optical transfer function of an acousto-optic
heterodyning image processor,
 4, 317-319.
Optics Letters
5.11 
Poon, T.-C. (2004).
Recent progress in optical scanning holography  
, Journal of
Holography and Speckle 1, 6-25.
5.12 
Poon, T.-C. and G. Indebetouw (2003). Three-dimensional point spread functions
of an optical heterodyne scanning image processor,
42, 1485-1492.
Applied Optics 
5.13 
Swoger, J., M. Martínez-Corral, J. Huisken, and E. H. K. Stelzer (2002). Optical
scanning holography as a technique for high-resolution three-dimensional biological
microscopy,
 19, 1910-1918.
Journal of the Optical Society of America A
“
”
“
”
“
”
“
”
“
”
“
”
“
”
“
”
“
”
“
”
“
”
Optical Scanning Holography: Advances

 
Index 
A 
acousto-optic frequency 
 
shifter 72 
acousto-optic modulator 72 
angular frequency 25 
aperture 29 
axicon 146 
 
B 
bipolar PSF 46,49 
bitmap 7 
Bragg angle 73 
 
C 
carrier 30 
coding process 55 
coherent point spread function 44 
coherent transfer function 45 
complex amplitude 30 
conservation of energy 73 
conservation of momentum 73 
constitution relations 22 
continuity equation 22 
convolution 14, 16 
correlation 14, 16 
 
auto- 17 
 
cross- 17 
current 
 
baseband 70 
 
heterodyne 70 
 D 
decoding process 55 
decryption 121 
depth of field 100 
depth of focus 97 
detection 
 
electronic multiplexing 70 
 
lock-in 70 
 
optical coherent 70 
 
optical direct 67 
 
optical incoherent 67 
diffracting screen 29 
display 
 
3-D 106 
distance 
 
coding 120 
 
decoding 122 
 
 
E 
electric field 22 
encoding 
double-random phase 124 

 
encryption 121 
 
on-the-fly 118 
 F 
filtering 
 
bandpass 48 
 
lowpass 47 
 
spatial 45 
Fourier optics  
spatial frequency transfer
function in 34 
spatial impulse response in 34 
Fourier plane 43 
frequency transfer function 13 
Fourier transform 1 
Fresnel diffraction 34 
Fresnel diffraction formula 34 
Fresnel zone plate  (FZP) 49, 52 
 
time-dependent 92, 102 
function 
 
 
Gaussian 2 
 
 
separabale 3 
 
transfer 13 
 
G 
Gaussian beam 40 
Gaussian function 2 
 
H 
Helmholtz equation 30 
heterodyning 69 
hologram 51 
 
complex Fresnel zone plate 85
 
 
cosine-FZP 83 
 
off-axis 59 
 
sine-FZP 83 
 
twin-image-free 83 
hologram scaling 110, 113 
holographic recording 51 
holography 49 
 
carrier-frequency 60 
 
CO2  scanning 84 
 
digital 60 
 
electronic 62 
 
HPO-optical scanning 117 
 
phase-shifting 85 
 
scanning 65, 81 
 
off-axis 56 
 
 
X-ray scanning 84 
homodyning 94 
 
I 
ideal lens 40 
image intensity 45 
image processing 
 
3-D complex incoherent 140 
 
bipolar incoherent  48 
 
coherent 43 
 
complex incoherent 78 
 
incoherent 44 
impulse response 11 
initial condition 29 
in-phase component 71 
integral 
 
convolution 11 
 
correlation 16 
invariance 10 
issue  
spatial frequency resolution
115 
 
spatial resolution 116 
 
data transmission 117 
 
K 
key  
decryption 122 
encryption 121 
 
 
150
delta 2, 8 
rect 2, 3 
    sinc 2, 4 
optical scanning 65, 83, 87, 92 
Optical Scanning Holography with MATLAB

 
lateral resolution 97 
linearity 10 
liquid crystal television 61 
lock-in detection 70 
 
M 
magnetic field 22 
magnification 
 
lateral 113 
 
longitudinal 113 
 
holographic 112 
Maxwell’s equations 21  
medium 
 
homogeneous 22 
 
isotropic 22 
 
linear 22 
microscopy 
 
fluorescence 101 
 
optical sectioning 99 
 
scanning confocal 99 
 
scanning holographic 97 
mixing 70 
modulator 
 
 acousto-optic 72 
electron-beam-addressed 
spatial light 107 
 
N 
numerical aperture 98 
Nyquist sampling 116 
 
O 
optical coherent detection 70 
optical coherent tomography  
 
(OCT) 101 
optical direct detection 67 
optical heterodyning 65, 69 
optical incoherent detection 67 
optical pattern recognition 17 
optical scanning 65 
optical scanning holography 65, 
97, 117 
HPO- 117  
optical transfer function(OTF) 46, 
78 
 
P 
parallax 49 
paraxial approximation 33 
pattern recognition 17 
phase 26 
phase curvature 42 
phase grating 73 
phasor 30 
phonon 73 
photo-bleaching 101 
photon 73 
planar wavefront 27 
Planck’s constant 73 
Pockels effect 108 
point spread function (PSF) 13 
 
bipolar 46 
coherent 44 
complex 49  
intensity 46  
principle of conservation of   
   charge 22 
processing 
 
coherent holographic 136 
 
Fourier-plane 43 
 
incoherent holographic 136 
propagation constant 26 
propagation vector 26 
PSF-engineering 143 
pupil function 45 
 
Q 
quadrature component 71 
quantitative phase-contrast  
imaging 133 
 
 
151
L
optical scanning cryptography  117 
Index

 
radio frequency identification  
 
(RFID) 118 
radius of curvature 35 
real image 56, 60 
reconstruction 55 
recording 55 
recording angle 58 
 
S 
sampling property 9 
scalar diffraction theory 29 
scalar wave equation 25 
scanning 
 
single-beam 141 
 
double-beam scanning 141 
separable function 3 
solution  
 
planar wave 25 
 
spherical wave 27 
source 22 
spatial carrier 60 
spatial filter 44 
spatial frequency response 13 
spatial frequency transfer function  
 
in Fourier optics 34 
spatial frequency transfer function  
 
of propagation 31 
spatial impulse response  
 
in Fourier optics 34 
spatial impulse response 13 
spatial impulse response   
 
of propagation 33 
spatial light modulator (SLM) 61 
 
electron-beam addressed 107 
spherical wavefront 28 
square aperture 36 
superposition 10 
super-resolution 146 
synthetic-aperture radar 143 
system 
 
coherent optical 45 
incoherent optical 45 
 
linear 10 
 
linear space-invariant 12 
 
time-invariant 11 
 
two-pupil 75 
 
 
T 
TV  
 
holographic 106 
twin image 57 
twin-image problem 58 
two-pupil system 75 
 
U 
uncertainty relationship 99 
upshifted interaction 74 
 
V 
vector wave equation 23 
 
homogeneous 24 
viewing angle 115 
virtual image 57, 60 
 
W 
Wave 
 
divering spherical 35 
 
object 51 
 
plane 26 
 
reconstruction 55, 59 
 
reference 51 
 
spherical 28, 52 
wavelength scaling 114 
 
Z 
 
R
152
Optical Scanning Holography with MATLAB
zero-order beam 56, 59 

 
Author 
 
 
Ting-Chung Poon 
Bradley Department of Electrical and Computer Engineering 
Virginia Tech 
Blacksburg, Virginia, USA 24061 
e-mail: tcpoon@vt.edu  
 
Dr. Ting-Chung Poon received his physics and engineering degrees from the
Bradley Department of Electrical and Computer Engineering. His current
University of Iowa, Iowa City. He is a professor at Virginia Tech in the
research interests include acousto-optics, hybrid (optical/electronic/digital)
3-D image processing; optical scanning holography and its applications in
3-D cryptography, 3-D display, 3-D microscopy, 3-D optical remote sensing,
and 3-D pattern recognition. Dr. Poon is the co-author of the textbooks 
Engineering Optics with MATLAB® (World Scientific 2006), Contemporary 
Optical Image Processing with MATLAB® (Elsevier 2001), and Principles 
of Applied Optics (McGraw-Hill 1991). He is also editor of the book Digital 
Holography and Three-Dimensional Display (Springer 2006) and has served 
as a panelist for the National Institutes of Health and the National Science 
Foundation, and as guest editor of, among other journals, International 
Journal of Optoelectronics and Optical Engineering. Dr. Poon currently 
serves as a topical/associate editor for Applied Optics and the International 
Journal of Optomechatronics. He is also on the editorial board of Optics and 
Laser Technology and the Journal of Holography and Speckle. Dr. Poon is a 
fellow of the OSA and SPIE and is a senior member of the IEEE.
 

