Texts and Readings in Mathematics 38 
Analysis II
Third Edition
Terence Tao

Texts and Readings in Mathematics
Volume 38
Advisory Editor
C.S. Seshadri, Chennai Mathematical Institute, Chennai
Managing Editor
Rajendra Bhatia, Indian Statistical Institute, New Delhi
Editor
Manindra Agrawal, Indian Institute of Technology Kanpur, Kanpur
V. Balaji, Chennai Mathematical Institute, Chennai
R.B. Bapat, Indian Statistical Institute, New Delhi
V.S. Borkar, Indian Institute of Technology Bombay, Mumbai
T.R. Ramadas, Chennai Mathematical Institute, Chennai
V. Srinivas, Tata Institute of Fundamental Research, Mumbai

More information about this series at http://www.springer.com/series/15141
The Texts and Readings in Mathematics series publishes high-quality textbooks,
research-level monographs, lecture notes and contributed volumes. Undergraduate
and graduate students of mathematics, research scholars, and teachers would ﬁnd
this book series useful. The volumes are carefully written as teaching aids and
highlight characteristic features of the theory. The books in this series are
co-published with Hindustan Book Agency, New Delhi, India.

Terence Tao
Analysis II
Third Edition
123

Terence Tao
Department of Mathematics
University of California, Los Angeles
Los Angeles, CA
USA
This work is a co-publication with Hindustan Book Agency, New Delhi, licensed for sale in all
countries in electronic form only. Sold and distributed in print across the world by Hindustan
BookAgency,P-19GreenParkExtension,NewDelhi110016,India.ISBN:978-93-80250-65-6
© Hindustan Book Agency 2015.
ISSN 2366-8725
(electronic)
Texts and Readings in Mathematics
ISBN 978-981-10-1804-6
(eBook)
DOI 10.1007/978-981-10-1804-6
Library of Congress Control Number: 2016940817
© Springer Science+Business Media Singapore 2016 and Hindustan Book Agency 2015
This work is subject to copyright. All rights are reserved by the Publishers, whether the whole or part
of the material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations,
recitation, broadcasting, reproduction on microﬁlms or in any other physical way, and transmission
or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar
methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this
publication does not imply, even in the absence of a speciﬁc statement, that such names are exempt from
the relevant protective laws and regulations and therefore free for general use.
The publishers, the authors and the editors are safe to assume that the advice and information in this
book are believed to be true and accurate at the date of publication. Neither the publishers nor the
authors or the editors give a warranty, express or implied, with respect to the material contained herein or
for any errors or omissions that may have been made.
This Springer imprint is published by Springer Nature
The registered company is Springer Science+Business Media Singapore Pte Ltd.

To my parents, for everything

Contents
xi
1
Metric spaces
1
1.1
Deﬁnitions and examples . . . . . . . . . . . . . . . . . .
1
1.2
Some point-set topology of metric spaces . . . . . . . . .
10
1.3
Relative topology
. . . . . . . . . . . . . . . . . . . . . .
15
1.4
Cauchy sequences and complete metric spaces
. . . . . .
17
1.5
Compact metric spaces . . . . . . . . . . . . . . . . . . .
21
2
Continuous functions on metric spaces
28
2.1
Continuous functions . . . . . . . . . . . . . . . . . . . .
28
2.2
Continuity and product spaces . . . . . . . . . . . . . . .
31
2.3
Continuity and compactness . . . . . . . . . . . . . . . .
34
2.4
Continuity and connectedness
. . . . . . . . . . . . . . .
36
2.5
Topological spaces (Optional)
. . . . . . . . . . . . . . .
39
3
Uniform convergence
45
3.1
Limiting values of functions
. . . . . . . . . . . . . . . .
46
3.2
Pointwise and uniform convergence
. . . . . . . . . . . .
48
3.3
Uniform convergence and continuity . . . . . . . . . . . .
53
3.4
The metric of uniform convergence
. . . . . . . . . . . .
56
3.5
Series of functions; the Weierstrass M-test . . . . . . . .
58
3.6
Uniform convergence and integration
. . . . . . . . . . .
61
3.7
Uniform convergence and derivatives
. . . . . . . . . . .
63
3.8
Uniform approximation by polynomials . . . . . . . . . .
66
4
Power series
75
4.1
Formal power series . . . . . . . . . . . . . . . . . . . . .
75
4.2
Real analytic functions . . . . . . . . . . . . . . . . . . .
78
About the Author
vii
ix
xvii
Preface to the second and third editions
Preface to the ﬁrst edition

viii
Contents
4.3
Abel’s theorem . . . . . . . . . . . . . . . . . . . . . . . .
83
4.4
Multiplication of power series
. . . . . . . . . . . . . . .
87
4.5
The exponential and logarithm functions . . . . . . . . .
90
4.6
A digression on complex numbers . . . . . . . . . . . . .
93
4.7
Trigonometric functions . . . . . . . . . . . . . . . . . . . 101
5
Fourier series
107
5.1
Periodic functions . . . . . . . . . . . . . . . . . . . . . . 108
5.2
Inner products on periodic functions . . . . . . . . . . . . 110
5.3
Trigonometric polynomials . . . . . . . . . . . . . . . . . 114
5.4
Periodic convolutions . . . . . . . . . . . . . . . . . . . . 116
5.5
The Fourier and Plancherel theorems . . . . . . . . . . . 121
6
Several variable diﬀerential calculus
127
6.1
Linear transformations
. . . . . . . . . . . . . . . . . . . 127
6.2
Derivatives in several variable calculus
. . . . . . . . . . 134
6.3
Partial and directional derivatives . . . . . . . . . . . . . 137
6.4
The several variable calculus chain rule . . . . . . . . . . 144
6.5
Double derivatives and Clairaut’s theorem
. . . . . . . . 147
6.6
The contraction mapping theorem . . . . . . . . . . . . . 149
6.7
The inverse function theorem in several variable calculus 152
6.8
The implicit function theorem . . . . . . . . . . . . . . . 157
7
Lebesgue measure
162
7.1
The goal: Lebesgue measure . . . . . . . . . . . . . . . . 164
7.2
First attempt: Outer measure
. . . . . . . . . . . . . . . 166
7.3
Outer measure is not additive
. . . . . . . . . . . . . . . 174
7.4
Measurable sets . . . . . . . . . . . . . . . . . . . . . . . 176
7.5
Measurable functions . . . . . . . . . . . . . . . . . . . . 183
8
Lebesgue integration
187
8.1
Simple functions . . . . . . . . . . . . . . . . . . . . . . . 187
8.2
Integration of non-negative measurable functions . . . . . 193
8.3
Integration of absolutely integrable functions . . . . . . . 201
8.4
Comparison with the Riemann integral . . . . . . . . . . 205
8.5
Fubini’s theorem . . . . . . . . . . . . . . . . . . . . . . . 207
Index
213
Texts and Readings in Mathematics
219

Preface to the second and third editions
Since the publication of the ﬁrst edition, many students and lectur-
ers have communicated a number of minor typos and other corrections
to me.
There was also some demand for a hardcover edition of the
texts. Because of this, the publishers and I have decided to incorporate
the corrections and issue a hardcover second edition of the textbooks.
The layout, page numbering, and indexing of the texts have also been
changed; in particular the two volumes are now numbered and indexed
separately. However, the chapter and exercise numbering, as well as the
mathematical content, remains the same as the ﬁrst edition, and so the
two editions can be used more or less interchangeably for homework and
study purposes.
The third edition contains a number of corrections that were reported
for the second edition, together with a few new exercises, but is otherwise
essentially the same text.
ix

Preface to the ﬁrst edition
This text originated from the lecture notes I gave teaching the honours
undergraduate-level real analysis sequence at the University of Califor-
nia, Los Angeles, in 2003. Among the undergraduates here, real anal-
ysis was viewed as being one of the most diﬃcult courses to learn, not
only because of the abstract concepts being introduced for the ﬁrst time
(e.g., topology, limits, measurability, etc.), but also because of the level
of rigour and proof demanded of the course. Because of this percep-
tion of diﬃculty, one was often faced with the diﬃcult choice of either
reducing the level of rigour in the course in order to make it easier, or
to maintain strict standards and face the prospect of many undergradu-
ates, even many of the bright and enthusiastic ones, struggling with the
course material.
Faced with this dilemma, I tried a somewhat unusual approach to
the subject. Typically, an introductory sequence in real analysis assumes
that the students are already familiar with the real numbers, with math-
ematical induction, with elementary calculus, and with the basics of set
theory, and then quickly launches into the heart of the subject, for in-
stance the concept of a limit. Normally, students entering this sequence
do indeed have a fair bit of exposure to these prerequisite topics, though
in most cases the material is not covered in a thorough manner. For in-
stance, very few students were able to actually deﬁne a real number, or
even an integer, properly, even though they could visualize these num-
bers intuitively and manipulate them algebraically. This seemed to me
to be a missed opportunity. Real analysis is one of the ﬁrst subjects
(together with linear algebra and abstract algebra) that a student en-
counters, in which one truly has to grapple with the subtleties of a truly
rigorous mathematical proof. As such, the course oﬀered an excellent
chance to go back to the foundations of mathematics, and in particular
xi

xii
Preface to the ﬁrst edition
the opportunity to do a proper and thorough construction of the real
numbers.
Thus the course was structured as follows. In the ﬁrst week, I de-
scribed some well-known “paradoxes” in analysis, in which standard laws
of the subject (e.g., interchange of limits and sums, or sums and inte-
grals) were applied in a non-rigorous way to give nonsensical results such
as 0 = 1. This motivated the need to go back to the very beginning of the
subject, even to the very deﬁnition of the natural numbers, and check
all the foundations from scratch. For instance, one of the ﬁrst homework
assignments was to check (using only the Peano axioms) that addition
was associative for natural numbers (i.e., that (a + b) + c = a + (b + c)
for all natural numbers a, b, c: see Exercise 2.2.1). Thus even in the
ﬁrst week, the students had to write rigorous proofs using mathematical
induction. After we had derived all the basic properties of the natural
numbers, we then moved on to the integers (initially deﬁned as formal
diﬀerences of natural numbers); once the students had veriﬁed all the
basic properties of the integers, we moved on to the rationals (initially
deﬁned as formal quotients of integers); and then from there we moved
on (via formal limits of Cauchy sequences) to the reals. Around the
same time, we covered the basics of set theory, for instance demonstrat-
ing the uncountability of the reals. Only then (after about ten lectures)
did we begin what one normally considers the heart of undergraduate
real analysis - limits, continuity, diﬀerentiability, and so forth.
The response to this format was quite interesting. In the ﬁrst few
weeks, the students found the material very easy on a conceptual level,
as we were dealing only with the basic properties of the standard num-
ber systems. But on an intellectual level it was very challenging, as one
was analyzing these number systems from a foundational viewpoint, in
order to rigorously derive the more advanced facts about these number
systems from the more primitive ones. One student told me how diﬃcult
it was to explain to his friends in the non-honours real analysis sequence
(a) why he was still learning how to show why all rational numbers
are either positive, negative, or zero (Exercise 4.2.4), while the non-
honours sequence was already distinguishing absolutely convergent and
conditionally convergent series, and (b) why, despite this, he thought
his homework was signiﬁcantly harder than that of his friends. Another
student commented to me, quite wryly, that while she could obviously
see why one could always divide a natural number n into a positive
integer q to give a quotient a and a remainder r less than q (Exercise
2.3.5), she still had, to her frustration, much diﬃculty in writing down

Preface to the ﬁrst edition
xiii
a proof of this fact. (I told her that later in the course she would have
to prove statements for which it would not be as obvious to see that
the statements were true; she did not seem to be particularly consoled
by this.) Nevertheless, these students greatly enjoyed the homework, as
when they did perservere and obtain a rigorous proof of an intuitive fact,
it solidiﬁed the link in their minds between the abstract manipulations
of formal mathematics and their informal intuition of mathematics (and
of the real world), often in a very satisfying way. By the time they were
assigned the task of giving the infamous “epsilon and delta” proofs in
real analysis, they had already had so much experience with formalizing
intuition, and in discerning the subtleties of mathematical logic (such
as the distinction between the “for all” quantiﬁer and the “there exists”
quantiﬁer), that the transition to these proofs was fairly smooth, and we
were able to cover material both thoroughly and rapidly. By the tenth
week, we had caught up with the non-honours class, and the students
were verifying the change of variables formula for Riemann-Stieltjes in-
tegrals, and showing that piecewise continuous functions were Riemann
integrable. By the conclusion of the sequence in the twentieth week, we
had covered (both in lecture and in homework) the convergence theory of
Taylor and Fourier series, the inverse and implicit function theorem for
continuously diﬀerentiable functions of several variables, and established
the dominated convergence theorem for the Lebesgue integral.
In order to cover this much material, many of the key foundational
results were left to the student to prove as homework; indeed, this was
an essential aspect of the course, as it ensured the students truly ap-
preciated the concepts as they were being introduced. This format has
been retained in this text; the majority of the exercises consist of proving
lemmas, propositions and theorems in the main text. Indeed, I would
strongly recommend that one do as many of these exercises as possible
- and this includes those exercises proving “obvious” statements - if one
wishes to use this text to learn real analysis; this is not a subject whose
subtleties are easily appreciated just from passive reading. Most of the
chapter sections have a number of exercises, which are listed at the end
of the section.
To the expert mathematician, the pace of this book may seem some-
what slow, especially in early chapters, as there is a heavy emphasis
on rigour (except for those discussions explicitly marked “Informal”),
and justifying many steps that would ordinarily be quickly passed over
as being self-evident. The ﬁrst few chapters develop (in painful detail)
many of the “obvious” properties of the standard number systems, for

xiv
Preface to the ﬁrst edition
instance that the sum of two positive real numbers is again positive (Ex-
ercise 5.4.1), or that given any two distinct real numbers, one can ﬁnd
rational number between them (Exercise 5.4.5). In these foundational
chapters, there is also an emphasis on non-circularity - not using later,
more advanced results to prove earlier, more primitive ones. In partic-
ular, the usual laws of algebra are not used until they are derived (and
they have to be derived separately for the natural numbers, integers,
rationals, and reals). The reason for this is that it allows the students
to learn the art of abstract reasoning, deducing true facts from a lim-
ited set of assumptions, in the friendly and intuitive setting of number
systems; the payoﬀfor this practice comes later, when one has to utilize
the same type of reasoning techniques to grapple with more advanced
concepts (e.g., the Lebesgue integral).
The text here evolved from my lecture notes on the subject, and
thus is very much oriented towards a pedagogical perspective; much
of the key material is contained inside exercises, and in many cases I
have chosen to give a lengthy and tedious, but instructive, proof in-
stead of a slick abstract proof. In more advanced textbooks, the student
will see shorter and more conceptually coherent treatments of this ma-
terial, and with more emphasis on intuition than on rigour; however,
I feel it is important to know how to do analysis rigorously and “by
hand” ﬁrst, in order to truly appreciate the more modern, intuitive and
abstract approach to analysis that one uses at the graduate level and
beyond.
The exposition in this book heavily emphasizes rigour and formal-
ism; however this does not necessarily mean that lectures based on
this book have to proceed the same way.
Indeed, in my own teach-
ing I have used the lecture time to present the intuition behind the
concepts (drawing many informal pictures and giving examples), thus
providing a complementary viewpoint to the formal presentation in the
text. The exercises assigned as homework provide an essential bridge
between the two, requiring the student to combine both intuition and
formal understanding together in order to locate correct proofs for a
problem. This I found to be the most diﬃcult task for the students,
as it requires the subject to be genuinely learnt, rather than merely
memorized or vaguely absorbed. Nevertheless, the feedback I received
from the students was that the homework, while very demanding for
this reason, was also very rewarding, as it allowed them to connect the
rather abstract manipulations of formal mathematics with their innate
intuition on such basic concepts as numbers, sets, and functions. Of

Preface to the ﬁrst edition
xv
course, the aid of a good teaching assistant is invaluable in achieving this
connection.
With regard to examinations for a course based on this text, I would
recommend either an open-book, open-notes examination with problems
similar to the exercises given in the text (but perhaps shorter, with no
unusual trickery involved), or else a take-home examination that involves
problems comparable to the more intricate exercises in the text. The
subject matter is too vast to force the students to memorize the deﬁni-
tions and theorems, so I would not recommend a closed-book examina-
tion, or an examination based on regurgitating extracts from the book.
(Indeed, in my own examinations I gave a supplemental sheet listing the
key deﬁnitions and theorems which were relevant to the examination
problems.) Making the examinations similar to the homework assigned
in the course will also help motivate the students to work through and
understand their homework problems as thoroughly as possible (as op-
posed to, say, using ﬂash cards or other such devices to memorize mate-
rial), which is good preparation not only for examinations but for doing
mathematics in general.
Some of the material in this textbook is somewhat peripheral to
the main theme and may be omitted for reasons of time constraints.
For instance, as set theory is not as fundamental to analysis as are
the number systems, the chapters on set theory (Chapters 3, 8) can be
covered more quickly and with substantially less rigour, or be given as
reading assignments. The appendices on logic and the decimal system
are intended as optional or supplemental reading and would probably
not be covered in the main course lectures; the appendix on logic is
particularly suitable for reading concurrently with the ﬁrst few chapters.
Also, Chapter 5 (on Fourier series) is not needed elsewhere in the text
and can be omitted.
For reasons of length, this textbook has been split into two volumes.
The ﬁrst volume is slightly longer, but can be covered in about thirty
lectures if the peripheral material is omitted or abridged. The second
volume refers at times to the ﬁrst, but can also be taught to students
who have had a ﬁrst course in analysis from other sources. It also takes
about thirty lectures to cover.
I am deeply indebted to my students, who over the progression of
the real analysis course corrected several errors in the lectures notes
from which this text is derived, and gave other valuable feedback. I am
also very grateful to the many anonymous referees who made several
corrections and suggested many important improvements to the text.

xvi
Preface to the ﬁrst edition
I also thank Biswaranjan Behera, Tai-Danae Bradley, Brian, Eduardo
Buscicchio, Carlos, EO, Florian, G¨okhan G¨u¸cl¨u, Evangelos Georgiadis,
Ulrich Groh, Bart Kleijngeld, Erik Koelink, Wang Kuyyang, Matthis
Lehmk¨uhler, Percy Li, Ming Li, Jason M., Manoranjan Majji, Geoﬀ
Mess, Pieter Naaijkens, Vineet Nair, Cristina Pereyra, David Radnell,
Tim Reijnders, Pieter Roﬀelsen, Luke Rogers, Marc Schoolderman, Kent
Van Vels, Daan Wanrooy, Yandong Xiao, Sam Xu, Luqing Ye, and the
students of Math 401/501 and Math 402/502 at the University of New
Mexico for corrections to the ﬁrst and second editions.
Terence Tao

xvii
About the Author
Terence Tao, FAA FRS, is an Australian mathematician. His areas of interests are
in harmonic analysis, partial differential equations, algebraic combinatorics, arith-
metic combinatorics, geometric combinatorics, compressed sensing and analytic
number theory. As of 2015, he holds the James and Carol Collins chair in math-
ematics at the University of California, Los Angeles. Professor Tao is a co-recipient
of the 2006 Fields Medal and the 2014 Breakthrough Prize in Mathematics. He
maintains a personal mathematics blog, which has been described by Timothy
Gowers as “the undisputed king of all mathematics blogs”.

Chapter 1
Metric spaces
1.1
Deﬁnitions and examples
In Deﬁnition 6.1.5 we deﬁned what it meant for a sequence (xn)∞
n=m of
real numbers to converge to another real number x; indeed, this meant
that for every ε > 0, there exists an N ≥m such that |x −xn| ≤ε for
all n ≥N. When this is the case, we write limn→∞xn = x.
Intuitively, when a sequence (xn)∞
n=m converges to a limit x, this
means that somehow the elements xn of that sequence will eventually
be as close to x as one pleases. One way to phrase this more precisely
is to introduce the distance function d(x, y) between two real numbers
by d(x, y) := |x −y|. (Thus for instance d(3, 5) = 2, d(5, 3) = 2, and
d(3, 3) = 0.) Then we have
Lemma 1.1.1. Let (xn)∞
n=m be a sequence of real numbers, and let x
be another real number. Then (xn)∞
n=m converges to x if and only if
limn→∞d(xn, x) = 0.
Proof. See Exercise 1.1.1.
One would now like to generalize this notion of convergence, so that
one can take limits not just of sequences of real numbers, but also se-
quences of complex numbers, or sequences of vectors, or sequences of
matrices, or sequences of functions, even sequences of sequences. One
way to do this is to redeﬁne the notion of convergence each time we
deal with a new type of object. As you can guess, this will quickly get
tedious. A more eﬃcient way is to work abstractly, deﬁning a very gen-
eral class of spaces - which includes such standard spaces as the real
numbers, complex numbers, vectors, etc. - and deﬁne the notion of con-
vergence on this entire class of spaces at once. (A space is just the set
1
© Springer Science+Business Media Singapore 2016 and Hindustan Book Agency 2015
T. Tao, Analysis II, Texts and Readings in Mathematics 38,
DOI 10.1007/978-981-10-1804-6_1

2
1.
Metric spaces
of all objects of a certain type - the space of all real numbers, the space
of all 3 × 3 matrices, etc. Mathematically, there is not much distinction
between a space and a set, except that spaces tend to have much more
structure than what a random set would have. For instance, the space of
real numbers comes with operations such as addition and multiplication,
while a general set would not.)
It turns out that there are two very useful classes of spaces which do
the job. The ﬁrst class is that of metric spaces, which we will study here.
There is a more general class of spaces, called topological spaces, which
is also very important, but we will only deal with this generalization
brieﬂy, in Section 2.5.
Roughly speaking, a metric space is any space X which has a concept
of distance d(x, y) - and this distance should behave in a reasonable
manner. More precisely, we have
Deﬁnition 1.1.2 (Metric spaces). A metric space (X, d) is a space X
of objects (called points), together with a distance function or metric
d : X × X →[0, +∞), which associates to each pair x, y of points in X
a non-negative real number d(x, y) ≥0. Furthermore, the metric must
satisfy the following four axioms:
(a) For any x ∈X, we have d(x, x) = 0.
(b) (Positivity) For any distinct x, y ∈X, we have d(x, y) > 0.
(c) (Symmetry) For any x, y ∈X, we have d(x, y) = d(y, x).
(d) (Triangle inequality) For any x, y, z ∈X, we have d(x, z) ≤
d(x, y) + d(y, z).
In many cases it will be clear what the metric d is, and we shall abbre-
viate (X, d) as just X.
Remark 1.1.3. The conditions (a) and (b) can be rephrased as follows:
for any x, y ∈X we have d(x, y) = 0 if and only if x = y. (Why is this
equivalent to (a) and (b)?)
Example 1.1.4 (The real line). Let R be the real numbers, and let d :
R×R →[0, ∞) be the metric d(x, y) := |x−y| mentioned earlier. Then
(R, d) is a metric space (Exercise 1.1.2). We refer to d as the standard
metric on R, and if we refer to R as a metric space, we assume that the
metric is given by the standard metric d unless otherwise speciﬁed.

1.1.
Deﬁnitions and examples
3
Example 1.1.5 (Induced metric spaces). Let (X, d) be any metric
space, and let Y be a subset of X. Then we can restrict the metric
function d : X × X →[0, +∞) to the subset Y × Y of X × X to cre-
ate a restricted metric function d|Y ×Y : Y × Y →[0, +∞) of Y ; this
is known as the metric on Y induced by the metric d on X. The pair
(Y, d|Y ×Y ) is a metric space (Exercise 1.1.4) and is known the subspace
of (X, d) induced by Y . Thus for instance the metric on the real line in
the previous example induces a metric space structure on any subset of
the reals, such as the integers Z, or an interval [a, b], etc.
Example 1.1.6 (Euclidean spaces). Let n ≥1 be a natural number,
and let Rn be the space of n-tuples of real numbers:
Rn = {(x1, x2, . . . , xn) : x1, . . . , xn ∈R}.
We deﬁne the Euclidean metric (also called the l2 metric) dl2 : Rn ×
Rn →R by
dl2((x1, . . . , xn), (y1, . . . , yn)) :=

(x1 −y1)2 + . . . + (xn −yn)2
=
 n

i=1
(xi −yi)2
1/2
.
Thus for instance, if n = 2, then dl2((1, 6), (4, 2)) =
√
32 + 42 = 5. This
metric corresponds to the geometric distance between the two points
(x1, x2, . . . , xn), (y1, y2, . . . , yn) as given by Pythagoras’ theorem. (We
remark however that while geometry does give some very important ex-
amples of metric spaces, it is possible to have metric spaces which have
no obvious geometry whatsoever. Some examples are given below.) The
veriﬁcation that (Rn, d) is indeed a metric space can be seen geomet-
rically (for instance, the triangle inequality now asserts that the length
of one side of a triangle is always less than or equal to the sum of the
lengths of the other two sides), but can also be proven algebraically (see
Exercise 1.1.6). We refer to (Rn, dl2) as the Euclidean space of dimen-
sion n. Extending the convention from Example 1.1.4, if we refer to Rn
as a metric space, we assume that the metric is given by the Euclidean
metric unless otherwise speciﬁed.
Example 1.1.7 (Taxi-cab metric). Again let n ≥1, and let Rn be
as before. But now we use a diﬀerent metric dl1, the so-called taxicab

4
1.
Metric spaces
metric (or l1 metric), deﬁned by
dl1((x1, x2, . . . , xn), (y1, y2, . . . , yn)) := |x1 −y1| + . . . + |xn −yn|
=
n

i=1
|xi −yi|.
Thus for instance, if n = 2, then dl1((1, 6), (4, 2)) = 3 + 4 = 7. This
metric is called the taxi-cab metric, because it models the distance a
taxi-cab would have to traverse to get from one point to another if the
cab was only allowed to move in cardinal directions (north, south, east,
west) and not diagonally. As such it is always at least as large as the
Euclidean metric, which measures distance “as the crow ﬂies”, as it were.
We claim that the space (Rn, dl1) is also a metric space (Exercise 1.1.7).
The metrics are not quite the same, but we do have the inequalities
dl2(x, y) ≤dl1(x, y) ≤√ndl2(x, y)
(1.1)
for all x, y (see Exercise 1.1.8).
Remark 1.1.8. The taxi-cab metric is useful in several places, for in-
stance in the theory of error correcting codes. A string of n binary digits
can be thought of as an element of Rn, for instance the binary string
10010 can be thought of as the point (1, 0, 0, 1, 0) in R5. The taxi-cab
distance between two binary strings is then the number of bits in the
two strings which do not match, for instance dl1(10010, 10101) = 3. The
goal of error-correcting codes is to encode each piece of information (e.g.,
a letter of the alphabet) as a binary string in such a way that all the
binary strings are as far away in the taxicab metric from each other as
possible; this minimizes the chance that any distortion of the bits due
to random noise can accidentally change one of the coded binary strings
to another, and also maximizes the chance that any such distortion can
be detected and correctly repaired.
Example 1.1.9 (Sup norm metric). Again let n ≥1, and let Rn be as
before. But now we use a diﬀerent metric dl∞, the so-called sup norm
metric (or l∞metric), deﬁned by
dl∞((x1, x2, . . . , xn), (y1, y2, . . . , yn)) := sup{|xi −yi| : 1 ≤i ≤n}.
Thus for instance, if n = 2, then dl∞((1, 6), (4, 2)) = sup(3, 4) = 4. The
space (Rn, dl∞) is also a metric space (Exercise 1.1.9), and is related to

1.1.
Deﬁnitions and examples
5
the l2 metric by the inequalities
1
√ndl2(x, y) ≤dl∞(x, y) ≤dl2(x, y)
(1.2)
for all x, y (see Exercise 1.1.10).
Remark 1.1.10. The l1, l2, and l∞metrics are special cases of the more
general lp metrics, where p ∈[1, +∞], but we will not discuss these more
general metrics in this text.
Example 1.1.11 (Discrete metric). Let X be an arbitrary set (ﬁnite or
inﬁnite), and deﬁne the discrete metric ddisc by setting ddisc(x, y) := 0
when x = y, and ddisc(x, y) := 1 when x ̸= y. Thus, in this metric,
all points are equally far apart. The space (X, ddisc) is a metric space
(Exercise 1.1.11). Thus every set X has at least one metric on it.
Example
1.1.12
(Geodesics). (Informal) Let X
be the sphere
{(x, y, z) ∈R3 : x2 + y2 + z2 = 1}, and let d((x, y, z), (x′, y′, z′)) be
the length of the shortest curve in X which starts at (x, y, z) and ends
at (x′, y′, z′). (This curve turns out to be an arc of a great circle; we will
not prove this here, as it requires calculus of variations, which is beyond
the scope of this text.) This makes X into a metric space; the reader
should be able to verify (without using any geometry of the sphere) that
the triangle inequality is more or less automatic from the deﬁnition.
Example 1.1.13 (Shortest paths). (Informal) Examples of metric
spaces occur all the time in real life.
For instance, X could be all
the computers currently connected to the internet, and d(x, y) is the
shortest number of connections it would take for a packet to travel from
computer x to computer y; for instance, if x and y are not directly con-
nected, but are both connected to z, then d(x, y) = 2. Assuming that
all computers in the internet can ultimately be connected to all other
computers (so that d(x, y) is always ﬁnite), then (X, d) is a metric space
(why?). Games such as “six degrees of separation” are also taking place
in a similar metric space (what is the space, and what is the metric,
in this case?). Or, X could be a major city, and d(x, y) could be the
shortest time it takes to drive from x to y (although this space might
not satisfy axiom (c) in real life!).
Now that we have metric spaces, we can deﬁne convergence in these
spaces.

6
1.
Metric spaces
Deﬁnition 1.1.14 (Convergence of sequences in metric spaces). Let m
be an integer, (X, d) be a metric space and let (x(n))∞
n=m be a sequence
of points in X (i.e., for every natural number n ≥m, we assume that
x(n) is an element of X). Let x be a point in X. We say that (x(n))∞
n=m
converges to x with respect to the metric d, if and only if the limit
limn→∞d(x(n), x) exists and is equal to 0. In other words, (x(n))∞
n=m
converges to x with respect to d if and only if for every ε > 0, there
exists an N ≥m such that d(x(n), x) ≤ε for all n ≥N. (Why are these
two deﬁnitions equivalent?)
Remark 1.1.15. In view of Lemma 1.1.1 we see that this deﬁnition gen-
eralizes our existing notion of convergence of sequences of real numbers.
In many cases, it is obvious what the metric d is, and so we shall often
just say “(x(n))∞
n=m converges to x” instead of “(x(n))∞
n=m converges to
x with respect to the metric d” when there is no chance of confusion.
We also sometimes write “x(n) →x as n →∞” instead.
Remark 1.1.16. There is nothing special about the superscript n in
the above deﬁnition; it is a dummy variable.
Saying that (x(n))∞
n=m
converges to x is exactly the same statement as saying that (x(k))∞
k=m
converges to x, for example; and sometimes it is convenient to change
superscripts, for instance if the variable n is already being used for some
other purpose. Similarly, it is not necessary for the sequence x(n) to
be denoted using the superscript (n); the above deﬁnition is also valid
for sequences xn, or functions f(n), or indeed of any expression which
depends on n and takes values in X. Finally, from Exercises 6.1.3, 6.1.4
we see that the starting point m of the sequence is unimportant for the
purposes of taking limits; if (x(n))∞
n=m converges to x, then (x(n))∞
n=m′
also converges to x for any m′ ≥m.
Example 1.1.17. We work in the Euclidean space R2 with the
standard Euclidean metric dl2.
Let (x(n))∞
n=1 denote the sequence
x(n)
:=
(1/n, 1/n) in R2, i.e., we are considering the sequence
(1, 1), (1/2, 1/2), (1/3, 1/3), . . .. Then this sequence converges to (0, 0)
with respect to the Euclidean metric dl2, since
lim
n→∞dl2(x(n), (0, 0)) = lim
n→∞

1
n2 + 1
n2 = lim
n→∞
√
2
n = 0.
The sequence (x(n))∞
n=1 also converges to (0, 0) with respect to the taxi-
cab metric dl1, since
lim
n→∞dl1(x(n), (0, 0)) = lim
n→∞
1
n + 1
n = lim
n→∞
2
n = 0.

1.1.
Deﬁnitions and examples
7
Similarly the sequence converges to (0, 0) in the sup norm metric dl∞
(why?). However, the sequence (x(n))∞
n=1 does not converge to (0, 0) in
the discrete metric ddisc, since
lim
n→∞ddisc(x(n), (0, 0)) = lim
n→∞1 = 1 ̸= 0.
Thus the convergence of a sequence can depend on what metric one
uses1.
In the case of the above four metrics - Euclidean, taxi-cab, sup norm,
and discrete - it is in fact rather easy to test for convergence.
Proposition 1.1.18 (Equivalence of l1, l2, l∞). Let Rn be a Euclidean
space, and let (x(k))∞
k=m be a sequence of points in Rn. We write x(k) =
(x(k)
1 , x(k)
2 , . . . , x(k)
n ), i.e., for j = 1, 2, . . . , n, x(k)
j
∈R is the jth co-
ordinate of x(k) ∈Rn. Let x = (x1, . . . , xn) be a point in Rn. Then the
following four statements are equivalent:
(a) (x(k))∞
k=m converges to x with respect to the Euclidean metric dl2.
(b) (x(k))∞
k=m converges to x with respect to the taxi-cab metric dl1.
(c) (x(k))∞
k=m converges to x with respect to the sup norm metric dl∞.
(d) For every 1 ≤j ≤n, the sequence (x(k)
j )∞
k=m converges to xj.
(Notice that this is a sequence of real numbers, not of points in
Rn.)
Proof. See Exercise 1.1.12.
In other words, a sequence converges in the Euclidean, taxi-cab,
or sup norm metric if and only if each of its components converges
individually. Because of the equivalence of (a), (b) and (c), we say that
the Euclidean, taxicab, and sup norm metrics on Rn are equivalent.
(There are inﬁnite-dimensional analogues of the Euclidean, taxicab, and
sup norm metrics which are not equivalent, see for instance Exercise
1.1.15.)
1For a somewhat whimsical real-life example, one can give a city an “automobile
metric”, with d(x, y) deﬁned as the time it takes for a car to drive from x to y, or a
“pedestrian metric”, where d(x, y) is the time it takes to walk on foot from x to y.
(Let us assume for sake of argument that these metrics are symmetric, though this is
not always the case in real life.) One can easily imagine examples where two points
are close in one metric but not another.

8
1.
Metric spaces
For the discrete metric, convergence is much rarer: the sequence
must be eventually constant in order to converge.
Proposition 1.1.19 (Convergence in the discrete metric). Let X be
any set, and let ddisc be the discrete metric on X.
Let (x(n))∞
n=m be
a sequence of points in X, and let x be a point in X. Then (x(n))∞
n=m
converges to x with respect to the discrete metric ddisc if and only if there
exists an N ≥m such that x(n) = x for all n ≥N.
Proof. See Exercise 1.1.13.
We now prove a basic fact about converging sequences; they can only
converge to at most one point at a time.
Proposition 1.1.20 (Uniqueness of limits). Let (X, d) be a metric
space, and let (x(n))∞
n=m be a sequence in X. Suppose that there are
two points x, x′ ∈X such that (x(n))∞
n=m converges to x with respect to
d, and (x(n))∞
n=m also converges to x′ with respect to d. Then we have
x = x′.
Proof. See Exercise 1.1.14.
Because of the above Proposition, it is safe to introduce the following
notation: if (x(n))∞
n=m converges to x in the metric d, then we write
d −limn→∞x(n) = x, or simply limn→∞x(n) = x when there is no
confusion as to what d is. For instance, in the example of ( 1
n, 1
n), we
have
dl2 −lim
n→∞
 1
n, 1
n

= dl1 −lim
n→∞
 1
n, 1
n

= (0, 0),
but ddisc −limn→∞( 1
n, 1
n) is undeﬁned.
Thus the meaning of d −
limn→∞x(n) can depend on what d is; however Proposition 1.1.20 assures
us that once d is ﬁxed, there can be at most one value of d−limn→∞x(n).
(Of course, it is still possible that this limit does not exist; some se-
quences are not convergent.) Note that by Lemma 1.1.1, this deﬁnition
of limit generalizes the notion of limit in Deﬁnition 6.1.8.
Remark 1.1.21. It is possible for a sequence to converge to one point
using one metric, and another point using a diﬀerent metric, although
such examples are usually quite artiﬁcial. For instance, let X := [0, 1],
the closed interval from 0 to 1.
Using the usual metric d, we have
d −limn→∞1
n = 0. But now suppose we “swap” the points 0 and 1 in
the following manner. Let f : [0, 1] →[0, 1] be the function deﬁned by
f(0) := 1, f(1) := 0, and f(x) := x for all x ∈(0, 1), and then deﬁne

1.1.
Deﬁnitions and examples
9
d′(x, y) := d(f(x), f(y)). Then (X, d′) is still a metric space (why?), but
now d′−limn→∞1
n = 1. Thus changing the metric on a space can greatly
aﬀect the nature of convergence (also called the topology) on that space;
see Section 2.5 for a further discussion of topology.
— Exercises —
Exercise 1.1.1. Prove Lemma 1.1.1.
Exercise 1.1.2. Show that the real line with the metric d(x, y) := |x−y| is indeed
a metric space. (Hint: you may wish to review your proof of Proposition 4.3.3.)
Exercise 1.1.3. Let X be a set, and let d : X × X →[0, ∞) be a function.
(a) Give an example of a pair (X, d) which obeys axioms (bcd) of Deﬁnition
1.1.2, but not (a). (Hint: modify the discrete metric.)
(b) Give an example of a pair (X, d) which obeys axioms (acd) of Deﬁnition
1.1.2, but not (b).
(c) Give an example of a pair (X, d) which obeys axioms (abd) of Deﬁnition
1.1.2, but not (c).
(d) Give an example of a pair (X, d) which obeys axioms (abc) of Deﬁnition
1.1.2, but not (d). (Hint: try examples where X is a ﬁnite set.)
Exercise 1.1.4. Show that the pair (Y, d|Y ×Y ) deﬁned in Example 1.1.5 is indeed
a metric space.
Exercise 1.1.5. Let n ≥1, and let a1, a2, . . . , an and b1, b2, . . . , bn be real num-
bers. Verify the identity
 n

i=1
aibi
2
+ 1
2
n

i=1
n

j=1
(aibj −ajbi)2 =
 n

i=1
a2
i
 ⎛
⎝
n

j=1
b2
j
⎞
⎠,
and conclude the Cauchy-Schwarz inequality

n

i=1
aibi
 ≤
 n

i=1
a2
i
1/2 ⎛
⎝
n

j=1
b2
j
⎞
⎠
1/2
.
(1.3)
Then use the Cauchy-Schwarz inequality to prove the triangle inequality
 n

i=1
(ai + bi)2
1/2
≤
 n

i=1
a2
i
1/2
+
⎛
⎝
n

j=1
b2
j
⎞
⎠
1/2
.
Exercise 1.1.6. Show that (Rn, dl2) in Example 1.1.6 is indeed a metric space.
(Hint: use Exercise 1.1.5.)

10
1.
Metric spaces
Exercise 1.1.7. Show that the pair (Rn, dl1) in Example 1.1.7 is indeed a metric
space.
Exercise 1.1.8. Prove the two inequalities in (1.1). (For the ﬁrst inequality,
square both sides. For the second inequality, use Exercise (1.1.5).
Exercise 1.1.9. Show that the pair (Rn, dl∞) in Example 1.1.9 is indeed a
metric space.
Exercise 1.1.10. Prove the two inequalities in (1.2).
Exercise 1.1.11. Show that the discrete metric (Rn, ddisc) in Example 1.1.11 is
indeed a metric space.
Exercise 1.1.12. Prove Proposition 1.1.18.
Exercise 1.1.13. Prove Proposition 1.1.19.
Exercise 1.1.14. Prove Proposition 1.1.20. (Hint: modify the proof of Propo-
sition 6.1.7.)
Exercise 1.1.15. Let
X :=

(an)∞
n=0 :
∞

n=0
|an| < ∞

be the space of absolutely convergent sequences. Deﬁne the l1 and l∞metrics
on this space by
dl1((an)∞
n=0, (bn)∞
n=0) :=
∞

n=0
|an −bn|;
dl∞((an)∞
n=0, (bn)∞
n=0) := sup
n∈N
|an −bn|.
Show that these are both metrics on X, but show that there exist sequences
x(1), x(2), . . . of elements of X (i.e., sequences of sequences) which are conver-
gent with respect to the dl∞metric but not with respect to the dl1 metric.
Conversely, show that any sequence which converges in the dl1 metric auto-
matically converges in the dl∞metric.
Exercise 1.1.16. Let (xn)∞
n=1 and (yn)∞
n=1 be two sequences in a metric space
(X, d). Suppose that (xn)∞
n=1 converges to a point x ∈X, and (yn)∞
n=1 con-
verges to a point y ∈X. Show that limn→∞d(xn, yn) = d(x, y). (Hint: use
the triangle inequality several times.)
1.2
Some point-set topology of metric spaces
Having deﬁned the operation of convergence on metric spaces, we now
deﬁne a couple other related notions, including that of open set, closed
set, interior, exterior, boundary, and adherent point. The study of such
notions is known as point-set topology, which we shall return to in Sec-
tion 2.5.

1.2.
Some point-set topology of metric spaces
11
We ﬁrst need the notion of a metric ball, or more simply a ball.
Deﬁnition 1.2.1 (Balls). Let (X, d) be a metric space, let x0 be a point
in X, and let r > 0. We deﬁne the ball B(X,d)(x0, r) in X, centered at
x0, and with radius r, in the metric d, to be the set
B(X,d)(x0, r) := {x ∈X : d(x, x0) < r}.
When it is clear what the metric space (X, d) is, we shall abbreviate
B(X,d)(x0, r) as just B(x0, r).
Example 1.2.2. In R2 with the Euclidean metric dl2, the ball
B(R2,dl2)((0, 0), 1) is the open disc
B(R2,dl2)((0, 0), 1) = {(x, y) ∈R2 : x2 + y2 < 1}.
However, if one uses the taxi-cab metric dl1 instead, then we obtain a
diamond:
B(R2,dl1)((0, 0), 1) = {(x, y) ∈R2 : |x| + |y| < 1}.
If we use the discrete metric, the ball is now reduced to a single point:
B(R2,ddisc)((0, 0), 1) = {(0, 0)},
although if one increases the radius to be larger than 1, then the ball
now encompasses all of R2. (Why?)
Example 1.2.3. In R with the usual metric d, the open interval (3, 7)
is also the metric ball B(R,d)(5, 2).
Remark 1.2.4. Note that the smaller the radius r, the smaller the ball
B(x0, r). However, B(x0, r) always contains at least one point, namely
the center x0, as long as r stays positive, thanks to Deﬁnition 1.1.2(a).
(We don’t consider balls of zero radius or negative radius since they are
rather boring, being just the empty set.)
Using metric balls, one can now take a set E in a metric space X,
and classify three types of points in X: interior, exterior, and boundary
points of E.
Deﬁnition 1.2.5 (Interior, exterior, boundary). Let (X, d) be a metric
space, let E be a subset of X, and let x0 be a point in X. We say
that x0 is an interior point of E if there exists a radius r > 0 such that
B(x0, r) ⊆E. We say that x0 is an exterior point of E if there exists a

12
1.
Metric spaces
radius r > 0 such that B(x0, r) ∩E = ∅. We say that x0 is a boundary
point of E if it is neither an interior point nor an exterior point of E.
The set of all interior points of E is called the interior of E and is
sometimes denoted int(E). The set of exterior points of E is called the
exterior of E and is sometimes denoted ext(E). The set of boundary
points of E is called the boundary of E and is sometimes denoted ∂E.
Remark 1.2.6. If x0 is an interior point of E, then x0 must actually
be an element of E, since balls B(x0, r) always contain their center x0.
Conversely, if x0 is an exterior point of E, then x0 cannot be an element
of E.
In particular it is not possible for x0 to simultaneously be an
interior and an exterior point of E. If x0 is a boundary point of E, then
it could be an element of E, but it could also not lie in E; we give some
examples below.
Example 1.2.7. We work on the real line R with the standard metric
d. Let E be the half-open interval E = [1, 2). The point 1.5 is an interior
point of E, since one can ﬁnd a ball (for instance B(1.5, 0.1)) centered
at 1.5 which lies in E. The point 3 is an exterior point of E, since one
can ﬁnd a ball (for instance B(3, 0.1)) centered at 3 which is disjoint
from E. The points 1 and 2 however, are neither interior points nor
exterior points of E, and are thus boundary points of E. Thus in this
case int(E) = (1, 2), ext(E) = (−∞, 1) ∪(2, ∞), and ∂E = {1, 2}. Note
that in this case one of the boundary points is an element of E, while
the other is not.
Example 1.2.8. When we give a set X the discrete metric ddisc, and
E is any subset of X, then every element of E is an interior point of E,
every point not contained in E is an exterior point of E, and there are
no boundary points; see Exercise 1.2.1.
Deﬁnition 1.2.9 (Closure). Let (X, d) be a metric space, let E be a
subset of X, and let x0 be a point in X. We say that x0 is an adherent
point of E if for every radius r > 0, the ball B(x0, r) has a non-empty
intersection with E. The set of all adherent points of E is called the
closure of E and is denoted E.
Note that these notions are consistent with the corresponding notions
on the real line deﬁned in Deﬁnitions 9.1.8, 9.1.10 (why?).
The following proposition links the notions of adherent point with
interior and boundary point, and also to that of convergence.

1.2.
Some point-set topology of metric spaces
13
Proposition 1.2.10. Let (X, d) be a metric space, let E be a subset
of X, and let x0 be a point in X. Then the following statements are
logically equivalent.
(a) x0 is an adherent point of E.
(b) x0 is either an interior point or a boundary point of E.
(c) There exists a sequence (xn)∞
n=1 in E which converges to x0 with
respect to the metric d.
Proof. See Exercise 1.2.2.
From the equivalence of Proposition 1.2.10(a) and (b) we obtain an
immediate corollary:
Corollary 1.2.11. Let (X, d) be a metric space, and let E be a subset
of X. Then E = int(E) ∪∂E = X\ext(E).
As remarked earlier, the boundary of a set E may or may not lie in
E. Depending on how the boundary is situated, we may call a set open,
closed, or neither:
Deﬁnition 1.2.12 (Open and closed sets). Let (X, d) be a metric space,
and let E be a subset of X. We say that E is closed if it contains all of
its boundary points, i.e., ∂E ⊆E. We say that E is open if it contains
none of its boundary points, i.e., ∂E ∩E = ∅. If E contains some of its
boundary points but not others, then it is neither open nor closed.
Example 1.2.13. We work in the real line R with the standard metric
d. The set (1, 2) does not contain either of its boundary points 1, 2 and
is hence open. The set [1, 2] contains both of its boundary points 1, 2
and is hence closed. The set [1, 2) contains one of its boundary points
1, but does not contain the other boundary point 2, so is neither open
nor closed.
Remark 1.2.14. It is possible for a set to be simultaneously open and
closed, if it has no boundary. For instance, in a metric space (X, d), the
whole space X has no boundary (every point in X is an interior point
- why?), and so X is both open and closed. The empty set ∅also has
no boundary (every point in X is an exterior point - why?), and so is
both open and closed. In many cases these are the only sets that are
simultaneously open and closed, but there are exceptions. For instance,
using the discrete metric ddisc, every set is both open and closed! (why?)

14
1.
Metric spaces
From the above two remarks we see that the notions of being open
and being closed are not negations of each other; there are sets that
are both open and closed, and there are sets which are neither open nor
closed. Thus, if one knew for instance that E was not an open set, it
would be erroneous to conclude from this that E was a closed set, and
similarly with the rˆoles of open and closed reversed. The correct rela-
tionship between open and closed sets is given by Proposition 1.2.15(e)
below.
Now we list some more properties of open and closed sets.
Proposition 1.2.15 (Basic properties of open and closed sets). Let
(X, d) be a metric space.
(a) Let E be a subset of X. Then E is open if and only if E = int(E).
In other words, E is open if and only if for every x ∈E, there
exists an r > 0 such that B(x, r) ⊆E.
(b) Let E be a subset of X. Then E is closed if and only if E contains
all its adherent points. In other words, E is closed if and only if
for every convergent sequence (xn)∞
n=m in E, the limit limn→∞xn
of that sequence also lies in E.
(c) For any x0 ∈X and r > 0, then the ball B(x0, r) is an open
set. The set {x ∈X : d(x, x0) ≤r} is a closed set. (This set is
sometimes called the closed ball of radius r centered at x0.)
(d) Any singleton set {x0}, where x0 ∈X, is automatically closed.
(e) If E is a subset of X, then E is open if and only if the complement
X\E := {x ∈X : x ̸∈E} is closed.
(f ) If E1, . . . , En are a ﬁnite collection of open sets in X, then E1 ∩
E2 ∩. . . ∩En is also open. If F1, . . . , Fn is a ﬁnite collection of
closed sets in X, then F1 ∪F2 ∪. . . ∪Fn is also closed.
(g) If {Eα}α∈I is a collection of open sets in X (where the index
set I could be ﬁnite, countable, or uncountable), then the union

α∈I Eα := {x ∈X : x ∈Eα for some α ∈I} is also open. If
{Fα}α∈I is a collection of closed sets in X, then the intersection

α∈I Fα := {x ∈X : x ∈Fα for all α ∈I} is also closed.
(h) If E is any subset of X, then int(E) is the largest open set which
is contained in E; in other words, int(E) is open, and given any

1.3.
Relative topology
15
other open set V ⊆E, we have V ⊆int(E). Similarly E is the
smallest closed set which contains E; in other words, E is closed,
and given any other closed set K ⊃E, K ⊃E.
Proof. See Exercise 1.2.3.
— Exercises —
Exercise 1.2.1. Verify the claims in Example 1.2.8.
Exercise 1.2.2. Prove Proposition 1.2.10. (Hint: for some of the implications
one will need the axiom of choice, as in Lemma 8.4.5.)
Exercise 1.2.3. Prove Proposition 1.2.15. (Hint: you can use earlier parts of
the proposition to prove later ones.)
Exercise 1.2.4. Let (X, d) be a metric space, x0 be a point in X, and r > 0.
Let B be the open ball B := B(x0, r) = {x ∈X : d(x, x0) < r}, and let C be
the closed ball C := {x ∈X : d(x, x0) ≤r}.
(a) Show that B ⊆C.
(b) Give an example of a metric space (X, d), a point x0, and a radius r > 0
such that B is not equal to C.
1.3
Relative topology
When we deﬁned notions such as open and closed sets, we mentioned
that such concepts depended on the choice of metric one uses.
For
instance, on the real line R, if one uses the usual metric d(x, y) = |x−y|,
then the set {1} is not open, however if instead one uses the discrete
metric ddisc, then {1} is now an open set (why?).
However, it is not just the choice of metric which determines what
is open and what is not - it is also the choice of ambient space X. Here
are some examples.
Example 1.3.1. Consider the plane R2 with the Euclidean metric dl2.
Inside the plane, we can ﬁnd the x-axis X := {(x, 0) : x ∈R}. The
metric dl2 can be restricted to X, creating a subspace (X, dl2|X×X) of
(R2, dl2). (This subspace is essentially the same as the real line (R, d)
with the usual metric; the precise way of stating this is that (X, dl2|X×X)
is isometric to (R, d). We will not pursue this concept further in this
text, however.) Now consider the set
E := {(x, 0) : −1 < x < 1}

16
1.
Metric spaces
which is both a subset of X and of R2. Viewed as a subset of R2, it is not
open, because the point 0, for instance, lies in E but is not an interior
point of E. (Any ball BR2,dl2(0, r) will contain at least one point that
lies outside of the x-axis, and hence outside of E. On the other hand, if
viewed as a subset of X, it is open; every point of E is an interior point
of E with respect to the metric space (X, dl2|X×X). For instance, the
point 0 is now an interior point of E, because the ball BX,dl2|X×X(0, 1)
is contained in E (in fact, in this case it is E.)
Example 1.3.2. Consider the real line R with the standard metric d,
and let X be the interval X := (−1, 1) contained inside R; we can then
restrict the metric d to X, creating a subspace (X, d|X×X) of (R, d).
Now consider the set [0, 1). This set is not closed in R, because the
point 1 is adherent to [0, 1) but is not contained in [0, 1).
However,
when considered as a subset of X, the set [0, 1) now becomes closed; the
point 1 is not an element of X and so is no longer considered an adherent
point of [0, 1), and so now [0, 1) contains all of its adherent points.
To clarify this distinction, we make a deﬁnition.
Deﬁnition 1.3.3 (Relative topology). Let (X, d) be a metric space,
let Y be a subset of X, and let E be a subset of Y . We say that E
is relatively open with respect to Y if it is open in the metric subspace
(Y, d|Y ×Y ). Similarly, we say that E is relatively closed with respect to
Y if it is closed in the metric space (Y, d|Y ×Y ).
The relationship between open (or closed) sets in X, and relatively
open (or relatively closed) sets in Y , is the following.
Proposition 1.3.4. Let (X, d) be a metric space, let Y be a subset of
X, and let E be a subset of Y .
(a) E is relatively open with respect to Y if and only if E = V ∩Y for
some set V ⊆X which is open in X.
(b) E is relatively closed with respect to Y if and only if E = K ∩Y
for some set K ⊆X which is closed in X.
Proof. We just prove (a), and leave (b) to Exercise 1.3.1. First suppose
that E is relatively open with respect to Y . Then, E is open in the
metric space (Y, d|Y ×Y ). Thus, for every x ∈E, there exists a radius
r > 0 such that the ball B(Y,d|Y ×Y )(x, r) is contained in E. This radius r
depends on x; to emphasize this we write rx instead of r, thus for every

1.4.
Cauchy sequences and complete metric spaces
17
x ∈E the ball B(Y,d|Y ×Y )(x, rx) is contained in E. (Note that we have
used the axiom of choice, Proposition 8.4.7, to do this.)
Now consider the set
V :=

x∈E
B(X,d)(x, rx).
This is a subset of X. By Proposition 1.2.15(c) and (g), V is open. Now
we prove that E = V ∩Y . Certainly any point x in E lies in V ∩Y ,
since it lies in Y and it also lies in B(X,d)(x, rx), and hence in V . Now
suppose that y is a point in V ∩Y . Then y ∈V , which implies that
there exists an x ∈E such that y ∈B(X,d)(x, rx). But since y is also in
Y , this implies that y ∈B(Y,d|Y ×Y )(x, rx). But by deﬁnition of rx, this
means that y ∈E, as desired. Thus we have found an open set V for
which E = V ∩Y as desired.
Now we do the converse. Suppose that E = V ∩Y for some open set
V ; we have to show that E is relatively open with respect to Y . Let x
be any point in E; we have to show that x is an interior point of E in
the metric space (Y, d|Y ×Y ). Since x ∈E, we know x ∈V . Since V is
open in X, we know that there is a radius r > 0 such that B(X,d)(x, r)
is contained in V . Strictly speaking, r depends on x, and so we could
write rx instead of r, but for this argument we will only use a single
choice of x (as opposed to the argument in the previous paragraph) and
so we will not bother to subscript r here. Since E = V ∩Y , this means
that B(X,d)(x, r) ∩Y is contained in E. But B(X,d)(x, r) ∩Y is exactly
the same as B(Y,d|Y ×Y )(x, r) (why?), and so B(Y,d|Y ×Y )(x, r) is contained
in E. Thus x is an interior point of E in the metric space (Y, d|Y ×Y ),
as desired.
— Exercises —
Exercise 1.3.1. Prove Proposition 1.3.4(b).
1.4
Cauchy sequences and complete metric spaces
We now generalize much of the theory of limits of sequences from Chap-
ter 6 to the setting of general metric spaces. We begin by generalizing
the notion of a subsequence from Deﬁnition 6.6.1:
Deﬁnition 1.4.1 (Subsequences). Suppose that (x(n))∞
n=m is a sequence
of points in a metric space (X, d).
Suppose that n1, n2, n3, . . . is an

18
1.
Metric spaces
increasing sequence of integers which are at least as large as m, thus
m ≤n1 < n2 < n3 < . . . .
Then we call the sequence (x(nj))∞
j=1 a subsequence of the original se-
quence (x(n))∞
n=m.
Examples 1.4.2. the sequence (( 1
j2 , 1
j2 ))∞
j=1 in R2 is a subsequence
of the sequence (( 1
n, 1
n))∞
n=1 (in this case, nj := j2).
The sequence
1, 1, 1, 1, . . . is a subsequence of 1, 0, 1, 0, 1, . . ..
If a sequence converges, then so do all of its subsequences:
Lemma 1.4.3. Let (x(n))∞
n=m be a sequence in (X, d) which converges
to some limit x0. Then every subsequence (x(nj))∞
j=1 of that sequence
also converges to x0.
Proof. See Exercise 1.4.3.
On the other hand, it is possible for a subsequence to be conver-
gent without the sequence as a whole being convergent. For example,
the sequence 1, 0, 1, 0, 1, . . . is not convergent, even though certain subse-
quences of it (such as 1, 1, 1, . . .) converge. To quantify this phenomenon,
we generalize Deﬁnition 6.4.1 as follows:
Deﬁnition 1.4.4 (Limit points). Suppose that (x(n))∞
n=m is a sequence
of points in a metric space (X, d), and let L ∈X. We say that L is a
limit point of (x(n))∞
n=m iﬀfor every N ≥m and ε > 0 there exists an
n ≥N such that d(x(n), L) ≤ε.
Proposition 1.4.5. Let (x(n))∞
n=m be a sequence of points in a metric
space (X, d), and let L ∈X. Then the following are equivalent:
• L is a limit point of (x(n))∞
n=m.
• There exists a subsequence (x(nj))∞
j=1 of the original sequence
(x(n))∞
n=m which converges to L.
Proof. See Exercise 1.4.2.
Next, we review the notion of a Cauchy sequence from Deﬁnition
6.1.3 (see also Deﬁnition 5.1.8).

1.4.
Cauchy sequences and complete metric spaces
19
Deﬁnition 1.4.6 (Cauchy sequences). Let (x(n))∞
n=m be a sequence
of points in a metric space (X, d).
We say that this sequence is a
Cauchy sequence iﬀfor every ε > 0, there exists an N ≥m such that
d(x(j), x(k)) < ε for all j, k ≥N.
Lemma 1.4.7 (Convergent sequences are Cauchy sequences). Let
(x(n))∞
n=m be a sequence in (X, d) which converges to some limit x0.
Then (x(n))∞
n=m is also a Cauchy sequence.
Proof. See Exercise 1.4.3.
It is also easy to check that subsequence of a Cauchy sequence is
also a Cauchy sequence (why)? However, not every Cauchy sequence
converges:
Example 1.4.8. (Informal) Consider the sequence
3, 3.1, 3.14, 3.141, 3.1415, . . .
in the metric space (Q, d) (the rationals Q with the usual metric
d(x, y) := |x −y|).
While this sequence is convergent in R (it con-
verges to π), it does not converge in Q (since π ̸∈Q, and a sequence
cannot converge to two diﬀerent limits).
So in certain metric spaces, Cauchy sequences do not necessarily
converge. However, if even part of a Cauchy sequence converges, then
the entire Cauchy sequence must converge (to the same limit):
Lemma 1.4.9. Let (x(n))∞
n=m be a Cauchy sequence in (X, d). Suppose
that there is some subsequence (x(nj))∞
j=1 of this sequence which con-
verges to a limit x0 in X. Then the original sequence (x(n))∞
n=m also
converges to x0.
Proof. See Exercise 1.4.4.
In Example 1.4.8 we saw an example of a metric space which con-
tained Cauchy sequences which did not converge. However, in Theorem
6.4.18 we saw that in the metric space (R, d), every Cauchy sequence
did have a limit. This motivates the following deﬁnition.
Deﬁnition 1.4.10 (Complete metric spaces). A metric space (X, d)
is said to be complete iﬀevery Cauchy sequence in (X, d) is in fact
convergent in (X, d).

20
1.
Metric spaces
Example 1.4.11. By Theorem 6.4.18, the reals (R, d) are complete; by
Example 1.4.8, the rationals (Q, d), on the other hand, are not complete.
Complete metric spaces have some nice properties.
For instance,
they are intrinsically closed: no matter what space one places them in,
they are always closed sets. More precisely:
Proposition 1.4.12.
(a) Let (X, d) be a metric space,
and let
(Y, d|Y ×Y ) be a subspace of (X, d). If (Y, d|Y ×Y ) is complete, then
Y must be closed in X.
(b) Conversely, suppose that (X, d) is a complete metric space, and
Y is a closed subset of X. Then the subspace (Y, d|Y ×Y ) is also
complete.
Proof. See Exercise 1.4.7.
In contrast, an incomplete metric space such as (Q, d) may be con-
sidered closed in some spaces (for instance, Q is closed in Q) but not
in others (for instance, Q is not closed in R).
Indeed, it turns out
that given any incomplete metric space (X, d), there exists a completion
(X, d), which is a larger metric space containing (X, d) which is com-
plete, and such that X is not closed in X (indeed, the closure of X in
(X, d) will be all of X); see Exercise 1.4.8. For instance, one possible
completion of Q is R.
— Exercises —
Exercise 1.4.1. Prove Lemma 1.4.3. (Hint: review your proof of Proposition
6.6.5.)
Exercise 1.4.2. Prove Proposition 1.4.5. (Hint: review your proof of Proposi-
tion 6.6.6.)
Exercise 1.4.3. Prove Lemma 1.4.7. (Hint: review your proof of Proposition
6.1.12.)
Exercise 1.4.4. Prove Lemma 1.4.9.
Exercise 1.4.5. Let (x(n))∞
n=m be a sequence of points in a metric space (X, d),
and let L ∈X. Show that if L is a limit point of the sequence (x(n))∞
n=m, then
L is an adherent point of the set {x(n) : n ≥m}. Is the converse true?
Exercise 1.4.6. Show that every Cauchy sequence can have at most one limit
point.
Exercise 1.4.7. Prove Proposition 1.4.12.

1.5.
Compact metric spaces
21
Exercise 1.4.8. The following construction generalizes the construction of the
reals from the rationals in Chapter 5, allowing one to view any metric space
as a subspace of a complete metric space. In what follows we let (X, d) be a
metric space.
(a) Given any Cauchy sequence (xn)∞
n=1 in X, we introduce the formal limit
LIMn→∞xn. We say that two formal limits LIMn→∞xn and LIMn→∞yn
are equal if limn→∞d(xn, yn) is equal to zero. Show that this equality
relation obeys the reﬂexive, symmetry, and transitive axioms.
(b) Let X be the space of all formal limits of Cauchy sequences in X, with
the above equality relation. Deﬁne a metric dX : X×X →R+ by setting
dX(LIMn→∞xn, LIMn→∞yn) := lim
n→∞d(xn, yn).
Show that this function is well-deﬁned (this means not only that the
limit limn→∞d(xn, yn) exists, but also that the axiom of substitution is
obeyed; cf. Lemma 5.3.7), and gives X the structure of a metric space.
(c) Show that the metric space (X, dX) is complete.
(d) We identify an element x ∈X with the corresponding formal limit
LIMn→∞x in X; show that this is legitimate by verifying that x =
y
⇐⇒LIMn→∞x = LIMn→∞y. With this identiﬁcation, show that
d(x, y) = dX(x, y), and thus (X, d) can now be thought of as a subspace
of (X, dX).
(e) Show that the closure of X in X is X (which explains the choice of
notation X).
(f) Show that the formal limit agrees with the actual limit, thus if (xn)∞
n=1
is any Cauchy sequence in X, then we have limn→∞xn = LIMn→∞xn
in X.
1.5
Compact metric spaces
We now come to one of the most useful notions in point set topology,
that of compactness. Recall the Heine-Borel theorem (Theorem 9.1.24),
which asserted that every sequence in a closed and bounded subset X
of the real line R had a convergent subsequence whose limit was also
in X. Conversely, only the closed and bounded sets have this property.
This property turns out to be so useful that we give it a name.
Deﬁnition 1.5.1 (Compactness). A metric space (X, d) is said to be
compact iﬀevery sequence in (X, d) has at least one convergent subse-
quence. A subset Y of a metric space X is said to be compact if the
subspace (Y, d|Y ×Y ) is compact.

22
1.
Metric spaces
Remark 1.5.2. The notion of a set Y being compact is intrinsic, in
the sense that it only depends on the metric function d|Y ×Y restricted
to Y , and not on the choice of the ambient space X. The notions of
completeness in Deﬁnition 1.4.10, and of boundedness below in Deﬁni-
tion 1.5.3, are also intrinsic, but the notions of open and closed are not
(see the discussion in Section 1.3).
Thus, Theorem 9.1.24 shows that in the real line R with the usual
metric, every closed and bounded set is compact, and conversely every
compact set is closed and bounded.
Now we investigate how the Heine-Borel extends to other metric
spaces.
Deﬁnition 1.5.3 (Bounded sets). Let (X, d) be a metric space, and let
Y be a subset of X. We say that Y is bounded iﬀthere exists a ball
B(x, r) in X which contains Y .
Remark 1.5.4. This deﬁnition is compatible with the deﬁnition of a
bounded set in Deﬁnition 9.1.22 (Exercise 1.5.1).
Proposition 1.5.5. Let (X, d) be a compact metric space. Then (X, d)
is both complete and bounded.
Proof. See Exercise 1.5.2.
From this proposition and Proposition 1.4.12(a) we obtain one half
of the Heine-Borel theorem for general metric spaces:
Corollary 1.5.6 (Compact sets are closed and bounded). Let (X, d) be
a metric space, and let Y be a compact subset of X. Then Y is closed
and bounded.
The other half of the Heine-Borel theorem is true in Euclidean spaces:
Theorem 1.5.7 (Heine-Borel theorem). Let (Rn, d) be a Euclidean
space with either the Euclidean metric, the taxicab metric, or the sup
norm metric. Let E be a subset of Rn. Then E is compact if and only
if it is closed and bounded.
Proof. See Exercise 1.5.3.
However, the Heine-Borel theorem is not true for more general met-
rics. For instance, the integers Z with the discrete metric is closed (in-
deed, it is complete) and bounded, but not compact, since the sequence

1.5.
Compact metric spaces
23
1, 2, 3, 4, . . . is in Z but has no convergent subsequence (why?). Another
example is in Exercise 1.5.8. However, a version of the Heine-Borel the-
orem is available if one is willing to replace closedness with the stronger
notion of completeness, and boundedness with the stronger notion of
total boundedness; see Exercise 1.5.10.
One can characterize compactness topologically via the following,
rather strange-sounding statement: every open cover of a compact set
has a ﬁnite subcover.
Theorem 1.5.8. Let (X, d) be a metric space, and let Y be a compact
subset of X. Let (Vα)α∈I be a collection of open sets in X, and suppose
that
Y ⊆

α∈I
Vα.
(i.e., the collection (Vα)α∈I covers Y ). Then there exists a ﬁnite subset
F of I such that
Y ⊆

α∈F
Vα.
Proof. We assume for sake of contradiction that there does not exist any
ﬁnite subset F of A for which Y ⊂
α∈F Vα.
Let y be any element of Y . Then y must lie in at least one of the
sets Vα. Since each Vα is open, there must therefore be an r > 0 such
that B(X,d)(y, r) ⊆Vα. Now let r(y) denote the quantity
r(y) := sup{r ∈(0, ∞) : B(X,d)(y, r) ⊆Vα for some α ∈A}.
By the above discussion, we know that r(y) > 0 for all y ∈Y . Now, let
r0 denote the quantity
r0 := inf{r(y) : y ∈Y }.
Since r(y) > 0 for all y ∈Y , we have r0 ≥0. There are two cases:
r0 = 0 and r0 > 0.
• Case 1: r0 = 0. Then for every integer n ≥1, there is at least
one point y in Y such that r(y) < 1/n (why?). We thus choose,
for each n ≥1, a point y(n) in Y such that r(y(n)) < 1/n (we
can do this because of the axiom of choice, see Proposition 8.4.7).
In particular we have limn→∞r(y(n)) = 0, by the squeeze test.
The sequence (y(n))∞
n=1 is a sequence in Y ; since Y is compact, we

24
1.
Metric spaces
can thus ﬁnd a subsequence (y(nj))∞
j=1 which converges to a point
y0 ∈Y .
As before, we know that there exists some α ∈A such that y0 ∈Vα,
and hence (since Vα is open) there exists some ε > 0 such that
B(y0, ε) ⊆Vα. Since y(nj) converges to y0, there must exist an
N ≥1 such that y(nj) ∈B(y0, ε/2) for all n ≥N. In particular,
by the triangle inequality we have B(y(nj), ε/2) ⊆B(y0, ε), and
thus B(y(nj), ε/2) ⊆Vα.
By deﬁnition of r(y(nj)), this implies
that r(y(nj)) ≥ε/2 for all n ≥N. But this contradicts the fact
that limn→∞r(y(n)) = 0.
• Case 2: r0 > 0. In this case we now have r(y) > r0/2 for all
y ∈Y . This implies that for every y ∈Y there exists an α ∈A
such that B(y, r0/2) ∈Vα (why?).
We now construct a sequence y(1), y(2), . . . by the following re-
cursive procedure.
We let y(1) be any point in Y .
The ball
B(y(1), r0/2) is contained in one of the Vα and thus cannot cover
all of Y , since we would then obtain a ﬁnite cover, a contradiction.
Thus there exists a point y(2) which does not lie in B(y(1), r0/2),
so in particular d(y(2), y(1)) ≥r0/2. Choose such a point y(2). The
set B(y(1), r0/2) ∪B(y(2), r0/2) cannot cover all of Y , since we
would then obtain two sets Vα1 and Vα2 which covered Y , a con-
tradiction again. So we can choose a point y(3) which does not lie
in B(y(1), r0/2) ∪B(y(2), r0/2), so in particular d(y(3), y(1)) ≥r0/2
and d(y(3), y(2)) ≥r0/2. Continuing in this fashion we obtain a
sequence (y(n))∞
n=1 in Y with the property that d(y(k), y(j)) ≥r0/2
for all k > j. In particular the sequence (y(n))∞
n=1 is not a Cauchy
sequence, and in fact no subsequence of (y(n))∞
n=1 can be a Cauchy
sequence either. But this contradicts the assumption that Y is
compact (by Lemma 1.4.7).
It turns out that Theorem 1.5.8 has a converse: if Y has the property
that every open cover has a ﬁnite sub-cover, then it is compact (Exercise
1.5.11). In fact, this property is often considered the more fundamental
notion of compactness than the sequence-based one. (For metric spaces,
the two notions, that of compactness and sequential compactness, are
equivalent, but for more general topological spaces, the two notions are
slightly diﬀerent; see Exercise 2.5.8.)

1.5.
Compact metric spaces
25
Theorem 1.5.8 has an important corollary: that every nested se-
quence of non-empty compact sets is still non-empty.
Corollary 1.5.9. Let (X, d) be a metric space, and let K1, K2, K3, . . .
be a sequence of non-empty compact subsets of X such that
K1 ⊃K2 ⊃K3 ⊃. . . .
Then the intersection ∞
n=1 Kn is non-empty.
Proof. See Exercise 1.5.6.
We close this section by listing some miscellaneous properties of com-
pact sets.
Theorem 1.5.10. Let (X, d) be a metric space.
(a) If Y is a compact subset of X, and Z ⊆Y , then Z is compact if
and only if Z is closed.
(b) If Y1, . . . , Yn are a ﬁnite collection of compact subsets of X, then
their union Y1 ∪. . . ∪Yn is also compact.
(c) Every ﬁnite subset of X (including the empty set) is compact.
Proof. See Exercise 1.5.7.
— Exercises —
Exercise 1.5.1. Show that Deﬁnitions 9.1.22 and 1.5.3 match when talking
about subsets of the real line with the standard metric.
Exercise 1.5.2. Prove Proposition 1.5.5. (Hint: prove the completeness and
boundedness separately. For both claims, use proof by contradiction. You will
need the axiom of choice, as in Lemma 8.4.5.)
Exercise 1.5.3. Prove Theorem 1.5.7. (Hint: use Proposition 1.1.18 and Theo-
rem 9.1.24.)
Exercise 1.5.4. Let (R, d) be the real line with the standard metric. Give an
example of a continuous function f : R →R, and an open set V ⊆R, such
that the image f(V ) := {f(x) : x ∈V } of V is not open.
Exercise 1.5.5. Let (R, d) be the real line with the standard metric. Give an
example of a continuous function f : R →R, and a closed set F ⊆R, such
that f(F) is not closed.
Exercise 1.5.6. Prove Corollary 1.5.9. (Hint: work in the compact metric space
(K1, d|K1×K1), and consider the sets Vn := K1\Kn, which are open on K1.
Assume for sake of contradiction that ∞
n=1 Kn = ∅, and then apply Theorem
1.5.8.)

26
1.
Metric spaces
Exercise 1.5.7. Prove Theorem 1.5.10. (Hint: for part (c), you may wish to
use (b), and ﬁrst prove that every singleton set is compact.)
Exercise 1.5.8. Let (X, dl1) be the metric space from Exercise 1.1.15. For each
natural number n, let e(n) = (e(n)
j
)∞
j=0 be the sequence in X such that e(n)
j
:= 1
when n = j and e(n)
j
:= 0 when n ̸= j. Show that the set {e(n) : n ∈N} is
a closed and bounded subset of X, but is not compact. (This is despite the
fact that (X, dl1) is even a complete metric space - a fact which we will not
prove here. The problem is that not that X is incomplete, but rather that it
is “inﬁnite-dimensional”, in a sense that we will not discuss here.)
Exercise 1.5.9. Show that a metric space (X, d) is compact if and only if every
sequence in X has at least one limit point.
Exercise 1.5.10. A metric space (X, d) is called totally bounded if for ev-
ery ε > 0, there exists a positive integer n and a ﬁnite number of balls
B(x(1), ε), . . . , B(x(n), ε) which cover X (i.e., X = n
i=1 B(x(i), ε).
(a) Show that every totally bounded space is bounded.
(b) Show the following stronger version of Proposition 1.5.5: if (X, d) is
compact, then complete and totally bounded. (Hint: if X is not totally
bounded, then there is some ε > 0 such that X cannot be covered by
ﬁnitely many ε-balls. Then use Exercise 8.5.20 to ﬁnd an inﬁnite se-
quence of balls B(x(n), ε/2) which are disjoint from each other. Use this
to then construct a sequence which has no convergent subsequence.)
(c) Conversely, show that if X is complete and totally bounded, then X is
compact. (Hint: if (x(n))∞
n=1 is a sequence in X, use the total bound-
edness hypothesis to recursively construct a sequence of subsequences
(x(n;j))∞
n=1 of (x(n))∞
n=1 for each positive integer j, such that for each j,
the elements of the sequence (x(n;j))∞
n=1 are contained in a single ball of
radius 1/j, and also that each sequence (x(n;j+1))∞
n=1 is a subsequence of
the previous one (x(n;j))∞
n=1. Then show that the “diagonal” sequence
(x(n;n))∞
n=1 is a Cauchy sequence, and then use the completeness hypoth-
esis.)
Exercise 1.5.11. Let (X, d) have the property that every open cover of X has
a ﬁnite subcover. Show that X is compact. (Hint: if X is not compact, then
by Exercise 1.5.9, there is a sequence (x(n))∞
n=1 with no limit points. Then for
every x ∈X there exists a ball B(x, ε) containing x which contains at most
ﬁnitely many elements of this sequence. Now use the hypothesis.)
Exercise 1.5.12. Let (X, ddisc) be a metric space with the discrete metric ddisc.
(a) Show that X is always complete.
(b) When is X compact, and when is X not compact? Prove your claim.
(Hint: the Heine-Borel theorem will be useless here since that only ap-
plies to Euclidean spaces.)

1.5.
Compact metric spaces
27
Exercise 1.5.13. Let E and F be two compact subsets of R (with the standard
metric d(x, y) = |x −y|). Show that the Cartesian product E × F := {(x, y) :
x ∈E, y ∈F} is a compact subset of R2 (with the Euclidean metric dl2).
Exercise 1.5.14. Let (X, d) be a metric space, let E be a non-empty compact
subset of X, and let x0 be a point in X. Show that there exists a point x ∈E
such that
d(x0, x) = inf{d(x0, y) : y ∈E},
i.e., x is the closest point in E to x0.
(Hint:
let R be the quantity
R := inf{d(x0, y) : y ∈E}. Construct a sequence (x(n))∞
n=1 in E such that
d(x0, x(n)) ≤R + 1
n, and then use the compactness of E.)
Exercise 1.5.15. Let (X, d) be a compact metric space. Suppose that (Kα)α∈I
is a collection of closed sets in X with the property that any ﬁnite subcollection
of these sets necessarily has non-empty intersection, thus 
α∈F Kα ̸= ∅for all
ﬁnite F ⊆I. (This property is known as the ﬁnite intersection property.) Show
that the entire collection has non-empty intersection, thus 
α∈I Kα ̸= ∅. Show
by counterexample that this statement fails if X is not compact.

Chapter 2
Continuous functions on metric spaces
2.1
Continuous functions
In the previous chapter we studied a single metric space (X, d), and the
various types of sets one could ﬁnd in that space. While this is already
quite a rich subject, the theory of metric spaces becomes even richer,
and of more importance to analysis, when one considers not just a single
metric space, but rather pairs (X, dX) and (Y, dY ) of metric spaces, as
well as continuous functions f : X →Y between such spaces. To deﬁne
this concept, we generalize Deﬁnition 9.4.1 as follows:
Deﬁnition 2.1.1 (Continuous functions). Let (X, dX) be a metric
space, and let (Y, dY ) be another metric space, and let f : X →Y
be a function. If x0 ∈X, we say that f is continuous at x0 iﬀfor every
ε > 0, there exists a δ > 0 such that dY (f(x), f(x0)) < ε whenever
dX(x, x0) < δ. We say that f is continuous iﬀit is continuous at every
point x ∈X.
Remark 2.1.2. Continuous functions are also sometimes called con-
tinuous maps. Mathematically, there is no distinction between the two
terminologies.
Remark 2.1.3. If f : X →Y is continuous, and K is any subset of X,
then the restriction f|K : K →Y of f to K is also continuous (why?).
We now generalize much of the discussion in Chapter 9. We ﬁrst
observe that continuous functions preserve convergence:
Theorem 2.1.4 (Continuity preserves convergence). Suppose that
(X, dX) and (Y, dY ) are metric spaces. Let f : X →Y be a function,
28
© Springer Science+Business Media Singapore 2016 and Hindustan Book Agency 2015
T. Tao, Analysis II, Texts and Readings in Mathematics 38,
DOI 10.1007/978-981-10-1804-6_2

2.1.
Continuous functions
29
and let x0 ∈X be a point in X. Then the following three statements are
logically equivalent:
(a) f is continuous at x0.
(b) Whenever (x(n))∞
n=1 is a sequence in X which converges to x0 with
respect to the metric dX, the sequence (f(x(n)))∞
n=1 converges to
f(x0) with respect to the metric dY .
(c) For every open set V ⊂Y that contains f(x0), there exists an open
set U ⊂X containing x0 such that f(U) ⊆V .
Proof. See Exercise 2.1.1.
Another important characterization of continuous functions involves
open sets.
Theorem 2.1.5. Let (X, dX) be a metric space, and let (Y, dY ) be an-
other metric space. Let f : X →Y be a function. Then the following
four statements are equivalent:
(a) f is continuous.
(b) Whenever (x(n))∞
n=1 is a sequence in X which converges to some
point x0
∈
X with respect to the metric dX, the sequence
(f(x(n)))∞
n=1 converges to f(x0) with respect to the metric dY .
(c) Whenever V is an open set in Y , the set f−1(V ) := {x ∈X :
f(x) ∈V } is an open set in X.
(d) Whenever F is a closed set in Y , the set f−1(F) := {x ∈X :
f(x) ∈F} is a closed set in X.
Proof. See Exercise 2.1.2.
Remark 2.1.6. It may seem strange that continuity ensures that the
inverse image of an open set is open. One may guess instead that the
reverse should be true, that the forward image of an open set is open;
but this is not true; see Exercises 1.5.4, 1.5.5.
As a quick corollary of the above two Theorems we obtain
Corollary 2.1.7 (Continuity preserved by composition). Let (X, dX),
(Y, dY ), and (Z, dZ) be metric spaces.
(a) If f : X →Y is continuous at a point x0 ∈X, and g : Y →Z is
continuous at f(x0), then the composition g ◦f : X →Z, deﬁned
by g ◦f(x) := g(f(x)), is continuous at x0.

30
2.
Continuous functions on metric spaces
(b) If f : X →Y is continuous, and g : Y →Z is continuous, then
g ◦f : X →Z is also continuous.
Proof. See Exercise 2.1.3.
Example 2.1.8. If f : X →R is a continuous function, then the func-
tion f2 : X →R deﬁned by f2(x) := f(x)2 is automatically continuous
also. This is because we have f2 = g ◦f, where g : R →R is the
squaring function g(x) := x2, and g is a continuous function.
— Exercises —
Exercise 2.1.1. Prove Theorem 2.1.4. (Hint: review your proof of Proposition
9.4.7.)
Exercise 2.1.2. Prove Theorem 2.1.5. (Hint: Theorem 2.1.4 already shows that
(a) and (b) are equivalent.)
Exercise 2.1.3. Use Theorem 2.1.4 and Theorem 2.1.5 to prove Corollary 2.1.7.
Exercise 2.1.4. Give an example of functions f : R →R and g : R →R such
that
(a) f is not continuous, but g and g ◦f are continuous;
(b) g is not continuous, but f and g ◦f are continuous;
(c) f and g are not continuous, but g ◦f is continuous.
Explain brieﬂy why these examples do not contradict Corollary 2.1.7.
Exercise 2.1.5. Let (X, d) be a metric space, and let (E, d|E×E) be a sub-
space of (X, d). Let ιE→X : E →X be the inclusion map, deﬁned by setting
ιE→X(x) := x for all x ∈E. Show that ιE→X is continuous.
Exercise 2.1.6. Let f : X →Y be a function from one metric space (X, dX)
to another (Y, dY ). Let E be a subset of X (which we give the induced metric
dX|E×E), and let f|E : E →Y be the restriction of f to E, thus f|E(x) := f(x)
when x ∈E.
If x0 ∈E and f is continuous at x0, show that f|E is also
continuous at x0. (Is the converse of this statement true? Explain.) Conclude
that if f is continuous, then f|E is continuous. Thus restriction of the domain
of a function does not destroy continuity. (Hint: use Exercise 2.1.5.)
Exercise 2.1.7. Let f : X →Y be a function from one metric space (X, dX)
to another (Y, dY ). Suppose that the image f(X) of X is contained in some
subset E ⊂Y of Y . Let g : X →E be the function which is the same as f
but with the range restricted from Y to E, thus g(x) = f(x) for all x ∈X. We
give E the metric dY |E×E induced from Y . Show that for any x0 ∈X, that
f is continuous at x0 if and only if g is continuous at x0. Conclude that f is
continuous if and only if g is continuous. (Thus the notion of continuity is not
aﬀected if one restricts the range of the function.)

2.2.
Continuity and product spaces
31
2.2
Continuity and product spaces
Given two functions f : X →Y and g : X →Z, one can deﬁne their
direct sum f ⊕g : X →Y × Z deﬁned by f ⊕g(x) := (f(x), g(x)),
i.e., this is the function taking values in the Cartesian product Y × Z
whose ﬁrst co-ordinate is f(x) and whose second co-ordinate is g(x) (cf.
Exercise 3.5.7). For instance, if f : R →R is the function f(x) := x2+3,
and g : R →R is the function g(x) = 4x, then f ⊕g : R →R2 is the
function f ⊕g(x) := (x2 + 3, 4x). The direct sum operation preserves
continuity:
Lemma 2.2.1. Let f : X →R and g : X →R be functions, and let
f ⊕g : X →R2 be their direct sum. We give R2 the Euclidean metric.
(a) If x0 ∈X, then f and g are both continuous at x0 if and only if
f ⊕g is continuous at x0.
(b) f and g are both continuous if and only if f ⊕g is continuous.
Proof. See Exercise 2.2.1.
To use this, we ﬁrst need another continuity result:
Lemma 2.2.2. The addition function (x, y) →x + y, the subtrac-
tion function (x, y) →x −y, the multiplication function (x, y) →xy,
the maximum function (x, y) →max(x, y), and the minimum func-
tion (x, y) →min(x, y), are all continuous functions from R2 to R.
The division function (x, y) →x/y is a continuous function from
R × (R\{0}) = {(x, y) ∈R2 : y ̸= 0} to R.
For any real number
c, the function x →cx is a continuous function from R to R.
Proof. See Exercise 2.2.2.
Combining these lemmas we obtain
Corollary 2.2.3. Let (X, d) be a metric space, let f : X →R and
g : X →R be functions. Let c be a real number.
(a) If x0 ∈X and f and g are continuous at x0, then the functions
f + g : X →R, f −g : X →R, fg : X →R, max(f, g) : X →R,
min(f, g) : X →R, and cf : X →R (see Deﬁnition 9.2.1 for
deﬁnitions) are also continuous at x0. If g(x) ̸= 0 for all x ∈X,
then f/g : X →R is also continuous at x0.

32
2.
Continuous functions on metric spaces
(b) If f and g are continuous, then the functions f + g : X →R,
f −g : X →R, fg : X →R, max(f, g) : X →R, min(f, g) : X →
R, and cf : X →R are also continuous at x0. If g(x) ̸= 0 for all
x ∈X, then f/g : X →R is also continuous at x0.
Proof. We ﬁrst prove (a). Since f and g are continuous at x0, then by
Lemma 2.2.1 f ⊕g : X →R2 is also continuous at x0. On the other
hand, from Lemma 2.2.2 the function (x, y) →x + y is continuous at
every point in R2, and in particular is continuous at f ⊕g(x0). If we
then compose these two functions using Corollary 2.1.7 we conclude that
f +g : X →R is continuous. A similar argument gives the continuity of
f −g, fg, max(f, g), min(f, g) and cf. To prove the claim for f/g, we
ﬁrst use Exercise 2.1.7 to restrict the range of g from R to R\{0}, and
then one can argue as before. The claim (b) follows immediately from
(a).
This corollary allows us to demonstrate the continuity of a large class
of functions; we give some examples below.
— Exercises —
Exercise 2.2.1. Prove Lemma 2.2.1. (Hint: use Proposition 1.1.18 and Theorem
2.1.4.)
Exercise 2.2.2. Prove Lemma 2.2.2. (Hint: use Theorem 2.1.5 and limit laws
(Theorem 6.1.19).)
Exercise 2.2.3. Show that if f : X →R is a continuous function, so is the
function |f| : X →R deﬁned by |f|(x) := |f(x)|.
Exercise 2.2.4. Let π1 : R2 →R and π2 : R2 →R be the functions π1(x, y) :=
x and π2(x, y) := y (these two functions are sometimes called the co-ordinate
functions on R2).
Show that π1 and π2 are continuous.
Conclude that if
f : R →X is any continuous function into a metric space (X, d), then the
functions g1 : R2 →X and g2 : R2 →X deﬁned by g1(x, y) := f(x) and
g2(x, y) := f(y) are also continuous.
Exercise 2.2.5. Let n, m ≥0 be integers. Suppose that for every 0 ≤i ≤n and
0 ≤j ≤m we have a real number cij. Form the function P : R2 →R deﬁned
by
P(x, y) :=
n

i=0
m

j=0
cijxiyj.
(Such a function is known as a polynomial of two variables; a typical example
of such a polynomial is P(x, y) = x3 + 2xy2 −x2 + 3y + 6.) Show that P
is continuous. (Hint: use Exercise 2.2.4 and Corollary 2.2.3.) Conclude that
if f : X →R and g : X →R are continuous functions, then the function
P(f, g) : X →R deﬁned by P(f, g)(x) := P(f(x), g(x)) is also continuous.

2.2.
Continuity and product spaces
33
Exercise 2.2.6. Let Rm and Rn be Euclidean spaces. If f : X →Rm and
g : X →Rn are continuous functions, show that f ⊕g : X →Rm+n is also
continuous, where we have identiﬁed Rm × Rn with Rm+n in the obvious
manner. Is the converse statement true?
Exercise 2.2.7. Let k ≥1, let I be a ﬁnite subset of Nk, and let c : I →R be
a function. Form the function P : Rk →R deﬁned by
P(x1, . . . , xk) :=

(i1,...,ik)∈I
c(i1, . . . , ik)xi1
1 . . . xik
k .
(Such a function is known as a polynomial of k variables; a typical example of
such a polynomial is P(x1, x2, x3) = 3x3
1x2x2
3 −x2x2
3 + x1 + 5.) Show that P is
continuous. (Hint: use induction on k, Exercise 2.2.6, and either Exercise 2.2.5
or Lemma 2.2.2.)
Exercise 2.2.8. Let (X, dX) and (Y, dY ) be metric spaces. Deﬁne the metric
dX×Y : (X × Y ) × (X × Y ) →[0, ∞) by the formula
dX×Y ((x, y), (x′, y′)) := dX(x, x′) + dY (y, y′).
Show that (X × Y, dX×Y ) is a metric space, and deduce an analogue of Propo-
sition 1.1.18 and Lemma 2.2.1.
Exercise 2.2.9. Let f : R2 →R be a function from R2 to R. Let (x0, y0) be a
point in R2. If f is continuous at (x0, y0), show that
lim
x→x0 lim sup
y→y0
f(x, y) = lim
y→y0 lim sup
x→x0
f(x, y) = f(x0, y0)
and
lim
x→x0 lim inf
y→y0 f(x, y) = lim
y→y0 lim inf
x→x0 f(x, y) = f(x0, y0).
(Recall that lim supx→x0 f(x)
:=
infr>0 sup|x−x0|<r f(x) and lim infx→x0
f(x) := supr>0 inf|x−x0|<r f(x).) In particular, we have
lim
x→x0 lim
y→y0 f(x, y) = lim
y→y0 lim
x→x0 f(x, y)
whenever the limits on both sides exist. (Note that the limits do not neces-
sarily exist in general; consider for instance the function f : R2 →R such
that f(x, y) = y sin 1
x when xy ̸= 0 and f(x, y) = 0 otherwise.) Discuss the
comparison between this result and Example 1.2.7.
Exercise 2.2.10. Let f : R2 →R be a continuous function. Show that for
each x ∈R, the function y →f(x, y) is continuous on R, and for each y ∈R,
the function x →f(x, y) is continuous on R. Thus a function f(x, y) which is
jointly continuous in (x, y) is also continuous in each variable x, y separately.
Exercise 2.2.11. Let f : R2 →R be the function deﬁned by f(x, y) :=
xy
x2+y2
when (x, y) ̸= (0, 0), and f(x, y) = 0 otherwise. Show that for each ﬁxed x ∈R,
the function y →f(x, y) is continuous on R, and that for each ﬁxed y ∈R, the
function x →f(x, y) is continuous on R, but that the function f : R2 →R is
not continuous on R2. This shows that the converse to Exercise 2.2.10 fails; it
is possible to be continuous in each variable separately without being jointly
continuous.

34
2.
Continuous functions on metric spaces
2.3
Continuity and compactness
Continuous functions interact well with the concept of compact sets
deﬁned in Deﬁnition 1.5.1.
Theorem 2.3.1 (Continuous maps preserve compactness). Let f :
X →Y be a continuous map from one metric space (X, dX) to an-
other (Y, dY ). Let K ⊆X be any compact subset of X. Then the image
f(K) := {f(x) : x ∈K} of K is also compact.
Proof. See Exercise 2.3.1.
This theorem has an important consequence. Recall from Deﬁnition
9.6.5 the notion of a function f : X →R attaining a maximum or
minimum at a point. We may generalize Proposition 9.6.7 as follows:
Proposition 2.3.2 (Maximum principle). Let (X, d) be a compact met-
ric space, and let f : X →R be a continuous function.
Then f is
bounded. Furthermore, f attains its maximum at some point xmax ∈X,
and also attains its minimum at some point xmin ∈X.
Proof. See Exercise 2.3.2.
Remark 2.3.3. As was already noted in Exercise 9.6.1, this principle
can fail if X is not compact. This proposition should be compared with
Lemma 9.6.3 and Proposition 9.6.7.
Another advantage of continuous functions on compact sets is that
they are uniformly continuous. We generalize Deﬁnition 9.9.2 as follows:
Deﬁnition 2.3.4 (Uniform continuity). Let f : X →Y be a map
from one metric space (X, dX) to another (Y, dY ). We say that f is
uniformly continuous if, for every ε > 0, there exists a δ > 0 such that
dY (f(x), f(x′)) < ε whenever x, x′ ∈X are such that dX(x, x′) < δ.
Every uniformly continuous function is continuous, but not con-
versely (Exercise 2.3.3).
But if the domain X is compact, then the
two notions are equivalent:
Theorem 2.3.5. Let (X, dX) and (Y, dY ) be metric spaces, and suppose
that (X, dX) is compact. If f : X →Y is function, then f is continuous
if and only if it is uniformly continuous.

2.3.
Continuity and compactness
35
Proof. If f is uniformly continuous then it is also continuous by Ex-
ercise 2.3.3. Now suppose that f is continuous. Fix ε > 0. For ev-
ery x0 ∈X, the function f is continuous at x0. Thus there exists a
δ(x0) > 0, depending on x0, such that dY (f(x), f(x0)) < ε/2 when-
ever dX(x, x0) < δ(x0). In particular, by the triangle inequality this
implies that dY (f(x), f(x′)) < ε whenever x ∈B(X,dX)(x0, δ(x0)/2) and
dX(x′, x) < δ(x0)/2 (why?).
Now consider the (possibly inﬁnite) collection of balls
{B(X,dX)(x0, δ(x0)/2) : x0 ∈X}.
Each ball in this collection is of course open, and the union of all these
balls covers X, since each point x0 in X is contained in its own ball
B(X,dX)(x0, δ(x0)/2).
Hence, by Theorem 1.5.8, there exist a ﬁnite
number of points x1, . . . , xn such that the balls B(X,dX)(xj, δ(xj)/2) for
j = 1, . . . , n cover X:
X ⊆
n
j=1
B(X,dX)(xj, δ(xj)/2).
Now let δ := minn
j=1 δ(xj)/2.
Since each of the δ(xj) are positive,
and there are only a ﬁnite number of j, we see that δ > 0.
Now
let x, x′ be any two points in X such that dX(x, x′) < δ.
Since
the balls B(X,dX)(xj, δ(xj)/2) cover X, we see that there must exist
1 ≤j ≤n such that x ∈B(X,dX)(xj, δ(xj)/2). Since dX(x, x′) < δ,
we have dX(x, x′) < δ(xj)/2, and so by the previous discussion we have
dY (f(x), f(x′)) < ε. We have thus found a δ such that dY (f(x), f(x′)) <
ε whenever d(x, x′) < δ, and this proves uniform continuity as de-
sired.
— Exercises —
Exercise 2.3.1. Prove Theorem 2.3.1.
Exercise 2.3.2. Prove Proposition 2.3.2. (Hint: modify the proof of Proposition
9.6.7.)
Exercise 2.3.3. Show that every uniformly continuous function is continuous,
but give an example that shows that not every continuous function is uniformly
continuous.
Exercise 2.3.4. Let (X, dX), (Y, dY ), (Z, dZ) be metric spaces, and let f :
X →Y and g : Y →Z be two uniformly continuous functions. Show that
g ◦f : X →Z is also uniformly continuous.

36
2.
Continuous functions on metric spaces
Exercise 2.3.5. Let (X, dX) be a metric space, and let f : X →R and g : X →
R be uniformly continuous functions. Show that the direct sum f ⊕g : X →R2
deﬁned by f ⊕g(x) := (f(x), g(x)) is uniformly continuous.
Exercise 2.3.6. Show that the addition function (x, y) →x + y and the sub-
traction function (x, y) →x −y are uniformly continuous from R2 to R, but
the multiplication function (x, y) →xy is not. Conclude that if f : X →R
and g : X →R are uniformly continuous functions on a metric space (X, d),
then f +g : X →R and f −g : X →R are also uniformly continuous. Give an
example to show that fg : X →R need not be uniformly continuous. What is
the situation for max(f, g), min(f, g), f/g, and cf for a real number c?
2.4
Continuity and connectedness
We now describe another important concept in metric spaces, that of
connectedness.
Deﬁnition 2.4.1 (Connected spaces). Let (X, d) be a metric space. We
say that X is disconnected iﬀthere exist disjoint non-empty open sets
V and W in X such that V ∪W = X. (Equivalently, X is disconnected
if and only if X contains a non-empty proper subset which is simultane-
ously closed and open.) We say that X is connected iﬀit is non-empty
and not disconnected.
We declare the empty set ∅as being special - it is neither connected
nor disconnected; one could think of the empty set as “unconnected”.
Example 2.4.2. Consider the set X := [1, 2] ∪[3, 4], with the usual
metric.
This set is disconnected because the sets [1, 2] and [3, 4] are
open relative to X (why?).
Intuitively, a disconnected set is one which can be separated into
two disjoint open sets; a connected set is one which cannot be separated
in this manner.
We deﬁned what it means for a metric space to be
connected; we can also deﬁne what it means for a set to be connected.
Deﬁnition 2.4.3 (Connected sets). Let (X, d) be a metric space, and
let Y be a subset of X. We say that Y is connected iﬀthe metric space
(Y, d|Y ×Y ) is connected, and we say that Y is disconnected iﬀthe metric
space (Y, d|Y ×Y ) is disconnected.
Remark 2.4.4. This deﬁnition is intrinsic; whether a set Y is connected
or not depends only on what the metric is doing on Y , but not on what
ambient space X one placing Y in.

2.4.
Continuity and connectedness
37
On the real line, connected sets are easy to describe.
Theorem 2.4.5. Let X be a subset of the real line R. Then the following
statements are equivalent.
(a) X is connected.
(b) Whenever x, y ∈X and x < y, the interval [x, y] is also contained
in X.
(c) X is an interval (in the sense of Deﬁnition 9.1.1).
Proof. First we show that (a) implies (b). Suppose that X is connected,
and suppose for sake of contradiction that we could ﬁnd points x < y
in X such that [x, y] is not contained in X. Then there exists a real
number x < z < y such that z ̸∈X. Thus the sets (−∞, z) ∩X and
(z, ∞) ∩X will cover X. But these sets are non-empty (because they
contain x and y respectively) and are open relative to X, and so X is
disconnected, a contradiction.
Now we show that (b) implies (a).
Let X be a set obeying the
property (b). Suppose for sake of contradiction that X is disconnected.
Then there exist disjoint non-empty sets V , W which are open relative
to X, such that V ∪W = X. Since V and W are non-empty, we may
choose an x ∈V and y ∈W. Since V and W are disjoint, we have
x ̸= y; without loss of generality we may assume x < y. By property
(b), we know that the entire interval [x, y] is contained in X.
Now consider the set [x, y] ∩V . This set is both bounded and non-
empty (because it contains x). Thus it has a supremum
z := sup([x, y] ∩V ).
Clearly z ∈[x, y], and hence z ∈X. Thus either z ∈V or z ∈W.
Suppose ﬁrst that z ∈V . Then z ̸= y (since y ∈W and V is disjoint
from W). But V is open relative to X, which contains [x, y], so there
is some ball B([x,y],d)(z, r) which is contained in V . But this contradicts
the fact that z is the supremum of [x, y] ∩V . Now suppose that z ∈W.
Then z ̸= x (since x ∈V and V is disjoint from W). But W is open
relative to X, which contains [x, y], so there is some ball B([x,y],d)(z, r)
which is contained in W. But this again contradicts the fact that z is the
supremum of [x, y] ∩V . Thus in either case we obtain a contradiction,
which means that X cannot be disconnected, and must therefore be
connected.

38
2.
Continuous functions on metric spaces
It remains to show that (b) and (c) are equivalent; we leave this to
Exercise 2.4.3.
Continuous functions map connected sets to connected sets:
Theorem 2.4.6 (Continuity preserves connectedness). Let f : X →Y
be a continuous map from one metric space (X, dX) to another (Y, dY ).
Let E be any connected subset of X. Then f(E) is also connected.
Proof. See Exercise 2.4.4.
An important corollary of this result is the intermediate value theo-
rem, generalizing Theorem 9.7.1.
Corollary 2.4.7 (Intermediate value theorem). Let f : X →R be a
continuous map from one metric space (X, dX) to the real line. Let E
be any connected subset of X, and let a, b be any two elements of E. Let
y be a real number between f(a) and f(b), i.e., either f(a) ≤y ≤f(b)
or f(a) ≥y ≥f(b). Then there exists c ∈E such that f(c) = y.
Proof. See Exercise 2.4.5.
— Exercises —
Exercise 2.4.1. Let (X, ddisc) be a metric space with the discrete metric. Let
E be a subset of X which contains at least two elements.
Show that E is
disconnected.
Exercise 2.4.2. Let f : X →Y be a function from a connected metric space
(X, d) to a metric space (Y, ddisc) with the discrete metric. Show that f is
continuous if and only if it is constant. (Hint: use Exercise 2.4.1.)
Exercise 2.4.3. Prove the equivalence of statements (b) and (c) in Theorem
2.4.5.
Exercise 2.4.4. Prove Theorem 2.4.6. (Hint: the formulation of continuity in
Theorem 2.1.5(c) is the most convenient to use.)
Exercise 2.4.5. Use Theorem 2.4.6 to prove Corollary 2.4.7.
Exercise 2.4.6. Let (X, d) be a metric space, and let (Eα)α∈I be a collection
of connected sets in X. Suppose also that 
α∈I Eα is non-empty. Show that

α∈I Eα is connected.
Exercise 2.4.7. Let (X, d) be a metric space, and let E be a subset of X. We
say that E is path-connected iﬀ, for every x, y ∈E, there exists a continuous
function γ : [0, 1] →E from the unit interval [0, 1] to E such that γ(0) = x and
γ(1) = y. Show that every path-connected set is connected. (The converse is
false, but is a bit tricky to show and will not be detailed here.)

2.5.
Topological spaces (Optional)
39
Exercise 2.4.8. Let (X, d) be a metric space, and let E be a subset of X. Show
that if E is connected, then the closure E of E is also connected. Is the converse
true?
Exercise 2.4.9. Let (X, d) be a metric space. Let us deﬁne a relation x ∼y on
X by declaring x ∼y iﬀthere exists a connected subset of X which contains
both x and y.
Show that this is an equivalence relation (i.e., it obeys the
reﬂexive, symmetric, and transitive axioms). Also, show that the equivalence
classes of this relation (i.e., the sets of the form {y ∈X : y ∼x} for some
x ∈X) are all closed and connected. (Hint: use Exercise 2.4.6 and Exercise
2.4.8.) These sets are known as the connected components of X.
Exercise 2.4.10. Combine Proposition 2.3.2 and Corollary 2.4.7 to deduce a
theorem for continuous functions on a compact connected domain which gen-
eralizes Corollary 9.7.4.
2.5
Topological spaces (Optional)
The concept of a metric space can be generalized to that of a topological
space. The idea here is not to view the metric d as the fundamental
object; indeed, in a general topological space there is no metric at all.
Instead, it is the collection of open sets which is the fundamental concept.
Thus, whereas in a metric space one introduces the metric d ﬁrst, and
then uses the metric to deﬁne ﬁrst the concept of an open ball and then
the concept of an open set, in a topological space one starts just with
the notion of an open set. As it turns out, starting from the open sets,
one cannot necessarily reconstruct a usable notion of a ball or metric
(thus not all topological spaces will be metric spaces), but remarkably
one can still deﬁne many of the concepts in the preceding sections.
We will not use topological spaces at all in this text, and so we shall
be rather brief in our treatment of them here. A more complete study
of these spaces can of course be found in any topology textbook, or a
more advanced analysis text.
Deﬁnition 2.5.1 (Topological spaces). A topological space is a pair
(X, F), where X is a set, and F ⊂2X is a collection of subsets of X,
whose elements are referred to as open sets. Furthermore, the collection
F must obey the following properties:
• The empty set ∅and the whole set X are open; in other words,
∅∈F and X ∈F.
• Any ﬁnite intersection of open sets is open.
In other words, if
V1, . . . , Vn are elements of F, then V1 ∩. . . ∩Vn is also in F.

40
2.
Continuous functions on metric spaces
• Any arbitrary union of open sets is open (including inﬁnite unions).
In other words, if (Vα)α∈I is a family of sets in F, then 
α∈I Vα is
also in F.
In many cases, the collection F of open sets can be deduced from context,
and we shall refer to the topological space (X, F) simply as X.
From Proposition 1.2.15 we see that every metric space (X, d) is au-
tomatically also a topological space (if we set F equal to the collection
of sets which are open in (X, d)).
However, there do exist topologi-
cal spaces which do not arise from metric spaces (see Exercise 2.5.1,
2.5.6).
We now develop the analogues of various notions in this chapter and
the previous chapter for topological spaces. The notion of a ball must
be replaced by the notion of a neighbourhood.
Deﬁnition 2.5.2 (Neighbourhoods). Let (X, F) be a topological space,
and let x ∈X. A neighbourhood of x is deﬁned to be any open set in F
which contains x.
Example 2.5.3. If (X, d) is a metric space, x ∈X, and r > 0, then
B(x, r) is a neighbourhood of x.
Deﬁnition 2.5.4 (Topological convergence). Let m be an integer,
(X, F) be a topological space and let (x(n))∞
n=m be a sequence of points
in X. Let x be a point in X. We say that (x(n))∞
n=m converges to x if
and only if, for every neighbourhood V of x, there exists an N ≥m such
that x(n) ∈V for all n ≥N.
This notion is consistent with that of convergence in metric spaces
(Exercise 2.5.2). One can then ask whether one has the basic property
of uniqueness of limits (Proposition 1.1.20). The answer turns out to
usually be yes - if the topological space has an additional property known
as the Hausdorﬀproperty - but the answer can be no for other topologies;
see Exercise 2.5.4.
Deﬁnition 2.5.5 (Interior, exterior, boundary). Let (X, F) be a topo-
logical space, let E be a subset of X, and let x0 be a point in X. We
say that x0 is an interior point of E if there exists a neighbourhood V
of x0 such that V ⊆E. We say that x0 is an exterior point of E if there
exists a neighbourhood V of x0 such that V ∩E = ∅. We say that x0

2.5.
Topological spaces (Optional)
41
is a boundary point of E if it is neither an interior point nor an exterior
point of E.
This deﬁnition is consistent with the corresponding notion for metric
spaces (Exercise 2.5.3).
Deﬁnition 2.5.6 (Closure). Let (X, F) be a topological space, let E be
a subset of X, and let x0 be a point in X. We say that x0 is an adherent
point of E if every neighbourhood V of x0 has a non-empty intersection
with E. The set of all adherent points of E is called the closure of E
and is denoted E.
There is a partial analogue of Theorem 1.2.10, see Exercise 2.5.10.
We deﬁne a set K in a topological space (X, F) to be closed iﬀ
its complement X\K is open; this is consistent with the metric space
deﬁnition, thanks to Proposition 1.2.15(e). Some partial analogues of
that Proposition are true (see Exercise 2.5.11).
To deﬁne the notion of a relative topology, we cannot use Deﬁnition
1.3.3 as this requires a metric function. However, we can instead use
Proposition 1.3.4 as our starting point:
Deﬁnition 2.5.7 (Relative topology). Let (X, F) be a topological
space, and Y be a subset of X. Then we deﬁne FY := {V ∩Y : V ∈F},
and refer this as the topology on Y induced by (X, F). We call (Y, FY )
a topological subspace of (X, F). This is indeed a topological space, see
Exercise 2.5.12.
From Proposition 1.3.4 we see that this notion is compatible with
the one for metric spaces.
Next we deﬁne the notion of continuity.
Deﬁnition 2.5.8 (Continuous functions). Let (X, FX) and (Y, FY ) be
topological spaces, and let f : X →Y be a function. If x0 ∈X, we say
that f is continuous at x0 iﬀfor every neighbourhood V of f(x0), there
exists a neighbourhood U of x0 such that f(U) ⊆V . We say that f is
continuous iﬀit is continuous at every point x ∈X.
This deﬁnition is consistent with that in Deﬁnition 2.1.1 (Exercise
2.5.15).
Partial analogues of Theorems 2.1.4 and 2.1.5 are available
(Exercise 2.5.16).
In particular, a function is continuous iﬀthe pre-
images of every open set is open.
There is unfortunately no notion of a Cauchy sequence, a complete
space, or a bounded space, for topological spaces.
However, there is

42
2.
Continuous functions on metric spaces
certainly a notion of a compact space, as we can see by taking Theorem
1.5.8 as our starting point:
Deﬁnition 2.5.9 (Compact topological spaces). Let (X, F) be a topo-
logical space. We say that this space is compact if every open cover of
X has a ﬁnite subcover. If Y is a subset of X, we say that Y is compact
if the topological space on Y induced by (X, F) is compact.
Many basic facts about compact metric spaces continue to hold true
for compact topological spaces, notably Theorem 2.3.1 and Proposition
2.3.2 (Exercise 2.5.17). However, there is no notion of uniform continu-
ity, and so there is no analogue of Theorem 2.3.5.
We can also deﬁne the notion of connectedness by repeating Deﬁni-
tion 2.4.1 verbatim, and also repeating Deﬁnition 2.4.3 (but with Deﬁni-
tion 2.5.7 instead of Deﬁnition 1.3.3). Many of the results and exercises
in Section 2.4 continue to hold for topological spaces (with almost no
changes to any of the proofs!).
— Exercises —
Exercise 2.5.1. Let X be an arbitrary set, and let F := {∅, X}. Show that
(X, F) is a topology (called the trivial topology on X). If X contains more
than one element, show that the trivial topology cannot be obtained from by
placing a metric d on X. Show that this topological space is both compact and
connected.
Exercise 2.5.2. Let (X, d) be a metric space (and hence a topological space).
Show that the two notions of convergence of sequences in Deﬁnition 1.1.14 and
Deﬁnition 2.5.4 coincide.
Exercise 2.5.3. Let (X, d) be a metric space (and hence a topological space).
Show that the two notions of interior, exterior, and boundary in Deﬁnition
1.2.5 and Deﬁnition 2.5.5 coincide.
Exercise 2.5.4. A topological space (X, F) is said to be Hausdorﬀif given
any two distinct points x, y ∈X, there exists a neighbourhood V of x and a
neighbourhood W of y such that V ∩W = ∅. Show that any topological space
coming from a metric space is Hausdorﬀ, and show that the trivial topology is
not Hausdorﬀ. Show that the analogue of Proposition 1.1.20 holds for Hausdorﬀ
topological spaces, but give an example of a non-Hausdorﬀtopological space in
which Proposition 1.1.20 fails. (In practice, most topological spaces one works
with are Hausdorﬀ; non-Hausdorﬀtopological spaces tend to be so pathological
that it is not very proﬁtable to work with them.)
Exercise 2.5.5. Given any totally ordered set X with order relation ≤, declare a
set V ⊂X to be open if for every x ∈V there exists a set I which is an interval
{y ∈X : a < y < b} for some a, b ∈X, a ray {y ∈X : a < y} for some a ∈X,

2.5.
Topological spaces (Optional)
43
the ray {y ∈X : y < b} for some b ∈X, or the whole space X, which contains
x and is contained in V . Let F be the set of all open subsets of X. Show
that (X, F) is a topology (this is the order topology on the totally ordered set
(X, ≤)) which is Hausdorﬀin the sense of Exercise 2.5.4. Show that on the real
line R (with the standard ordering ≤), the order topology matches the standard
topology (i.e., the topology arising from the standard metric). If instead one
applies this to the extended real line R∗, show that R is an open set with
boundary {−∞, +∞}. If (xn)∞
n=1 is a sequence of numbers in R (and hence in
R∗), show that xn converges to +∞if and only if lim infn→∞xn = +∞, and
xn converges to −∞if and only if lim supn→∞xn = −∞.
Exercise 2.5.6. Let X be an uncountable set, and let F be the collection of all
subsets E in X which are either empty or co-ﬁnite (which means that X\E is
ﬁnite). Show that (X, F) is a topology (this is called the coﬁnite topology on
X) which is not Hausdorﬀin the sense of Exercise 2.5.4, and is compact and
connected. Also, show that if x ∈X (Vn)∞
n=1 is any countable collection of
open sets containing x, then ∞
n=1 Vn ̸= {x}. Use this to show that the coﬁnite
topology cannot be obtained by placing a metric d on X. (Hint: what is the
set ∞
n=1 B(x, 1/n) equal to in a metric space?)
Exercise 2.5.7. Let X be an uncountable set, and let F be the collection of
all subsets E in X which are either empty or co-countable (which means that
X\E is at most countable).
Show that (X, F) is a topology (this is called
the cocountable topology on X) which is not Hausdorﬀin the sense of Exercise
2.5.4, and connected, but cannot arise from a metric space and is not compact.
Exercise 2.5.8. Show that there exists an uncountable well-ordered set ω1 + 1
that has a maximal element ∞, and such that the initial segments {x ∈ω1 +1 :
x < y} are countable for all y ∈ω1+1\{∞}. (Hint: Well-order the real numbers
using Exercise 8.5.19, take the union of all the countable initial segments, and
then adjoin a maximal element ∞.)
If we give ω1 + 1 the order topology
(Exercise 2.5.5), show that ω1 + 1 is compact; however, show that not every
sequence has a convergent subsequence.
Exercise 2.5.9. Let (X, F) be a compact topological space. Assume that this
space is ﬁrst countable, which means that for every x ∈X there exists a count-
able collection V1, V2, . . . of neighbourhoods of x, such that every neighbour-
hood of x contains one of the Vn. Show that every sequence in X has a con-
vergent subsequence, by modifying Exercise 1.5.11. Explain why this does not
contradict Exercise 2.5.8.
Exercise 2.5.10. Prove the following partial analogue of Proposition 1.2.10 for
topological spaces: (c) implies both (a) and (b), which are equivalent to each
other. Show that in the co-countable topology in Exercise 2.5.7, it is possible
for (a) and (b) to hold without (c) holding.
Exercise 2.5.11. Let E be a subset of a topological space (X, F). Show that E
is open if and only if every element of E is an interior point, and show that E
is closed if and only if E contains all of its adherent points. Prove analogues

44
2.
Continuous functions on metric spaces
of Proposition 1.2.15(e)-(h) (some of these are automatic by deﬁnition).
If
we assume in addition that X is Hausdorﬀ, prove an analogue of Proposition
1.2.15(d) also, but give an example to show that (d) can fail when X is not
Hausdorﬀ.
Exercise 2.5.12. Show that the pair (Y, FY ) deﬁned in Deﬁnition 2.5.7 is indeed
a topological space.
Exercise 2.5.13. Generalize Corollary 1.5.9 to compact sets in a topological
space.
Exercise 2.5.14. Generalize Theorem 1.5.10 to compact sets in a topological
space.
Exercise 2.5.15. Let (X, dX) and (Y, dY ) be metric spaces (and hence a topo-
logical space). Show that the two notions continuity (both at a point, and on
the whole domain) of a function f : X →Y in Deﬁnition 2.1.1 and Deﬁnition
2.5.8 coincide.
Exercise 2.5.16. Show that when Theorem 2.1.4 is extended to topological
spaces, that (a) implies (b). (The converse is false, but constructing an example
is diﬃcult.) Show that when Theorem 2.1.5 is extended to topological spaces,
that (a), (c), (d) are all equivalent to each other, and imply (b). (Again, the
converse implications are false, but diﬃcult to prove.)
Exercise 2.5.17. Generalize both Theorem 2.3.1 and Proposition 2.3.2 to com-
pact sets in a topological space.

Chapter 3
Uniform convergence
In the previous two chapters we have seen what it means for a sequence
(x(n))∞
n=1 of points in a metric space (X, dX) to converge to a limit x; it
means that limn→∞dX(x(n), x) = 0, or equivalently that for every ε > 0
there exists an N > 0 such that dX(x(n), x) < ε for all n > N. (We have
also generalized the notion of convergence to topological spaces (X, F),
but in this chapter we will focus on metric spaces.)
In this chapter, we consider what it means for a sequence of functions
(f(n))∞
n=1 from one metric space (X, dX) to another (Y, dY ) to converge.
In other words, we have a sequence of functions f(1), f(2), . . ., with each
function f(n) : X →Y being a function from X to Y , and we ask what
it means for this sequence of functions to converge to some limiting
function f.
It turns out that there are several diﬀerent concepts of convergence
of functions; here we describe the two most important ones, pointwise
convergence and uniform convergence. (There are other types of conver-
gence for functions, such as L1 convergence, L2 convergence, convergence
in measure, almost everywhere convergence, and so forth, but these are
beyond the scope of this text.) The two notions are related, but not
identical; the relationship between the two is somewhat analogous to
the relationship between continuity and uniform continuity.
Once we work out what convergence means for functions, and thus
can make sense of such statements as limn→∞f(n) = f, we will then ask
how these limits interact with other concepts. For instance, we already
have a notion of limiting values of functions: limx→x0;x∈X f(x). Can we
interchange limits, i.e.
lim
n→∞
lim
x→x0;x∈X f(n)(x) =
lim
x→x0;x∈X lim
n→∞f(n)(x)?
45
© Springer Science+Business Media Singapore 2016 and Hindustan Book Agency 2015
T. Tao, Analysis II, Texts and Readings in Mathematics 38,
DOI 10.1007/978-981-10-1804-6_3

46
3.
Uniform convergence
As we shall see, the answer depends on what type of convergence we have
for f(n). We will also address similar questions involving interchanging
limits and integrals, or limits and sums, or sums and integrals.
3.1
Limiting values of functions
Before we talk about limits of sequences of functions, we should ﬁrst
discuss a similar, but distinct, notion, that of limiting values of functions.
We shall focus on the situation for metric spaces, but there are similar
notions for topological spaces (Exercise 3.1.3).
Deﬁnition 3.1.1 (Limiting value of a function). Let (X, dX) and
(Y, dY ) be metric spaces, let E be a subset of X, and let f : X →Y
be a function. If x0 ∈X is an adherent point of E, and L ∈Y , we
say that f(x) converges to L in Y as x converges to x0 in E, or write
limx→x0;x∈E f(x) = L, if for every ε > 0 there exists a δ > 0 such that
dY (f(x), L) < ε for all x ∈E such that dX(x, x0) < δ.
Remark 3.1.2. Some authors exclude the case x = x0 from the above
deﬁnition, thus requiring 0 < dX(x, x0) < δ. In our current notation,
this would correspond to removing x0 from E, thus one would consider
limx→x0;x∈E\{x0} f(x) instead of limx∈x0;x∈E f(x). See Exercise 3.1.1 for
a comparison of the two concepts.
Comparing this with Deﬁnition 2.1.1, we see that f is continuous at
x0 if and only if
lim
x→x0;x∈X f(x) = f(x0).
Thus f is continuous on X iﬀwe have
lim
x→x0;x∈X f(x) = f(x0) for all x0 ∈X.
Example 3.1.3. If f : R →R is the function f(x) = x2 −4, then
lim
x→1 f(x) = f(1) = 1 −4 = −3
since f is continuous.
Remark 3.1.4. Often we shall omit the condition x ∈X, and abbrevi-
ate limx→x0;x∈X f(x) as simply limx→x0 f(x) when it is clear what space
x will range in.

3.1.
Limiting values of functions
47
One can rephrase Deﬁnition 3.1.1 in terms of sequences:
Proposition 3.1.5. Let (X, dX) and (Y, dY ) be metric spaces, let E be
a subset of X, and let f : X →Y be a function. Let x0 ∈X be an
adherent point of E and L ∈Y . Then the following four statements are
logically equivalent:
(a) limx→x0;x∈E f(x) = L.
(b) For every sequence (x(n))∞
n=1 in E which converges to x0 with re-
spect to the metric dX, the sequence (f(x(n)))∞
n=1 converges to L
with respect to the metric dY .
(c) For every open set V ⊂Y which contains L, there exists an open
set U ⊂X containing x0 such that f(U ∩E) ⊆V .
(d) If one deﬁnes the function g : E∪{x0} →Y by deﬁning g(x0) := L,
and g(x) := f(x) for x ∈E\{x0}, then g is continuous at x0.
Furthermore, if x0 ∈E, then f(x0) = L.
Proof. See Exercise 3.1.2.
Remark 3.1.6. Observe from Proposition 3.1.5(b) and Proposition
1.1.20 that a function f(x) can converge to at most one limit L as x
converges to x0. In other words, if the limit
lim
x→x0;x∈E f(x)
exists at all, then it can only take at most one value.
Remark 3.1.7. The requirement that x0 be an adherent point of E
is necessary for the concept of limiting value to be useful, otherwise x0
will lie in the exterior of E, the notion that f(x) converges to L as x
converges to x0 in E is vacuous (for δ suﬃciently small, there are no
points x ∈E so that d(x, x0) < δ).
Remark 3.1.8. Strictly speaking, we should write
dY −
lim
x→x0;x∈E f(x) instead of
lim
x→x0;x∈E f(x),
since the convergence depends on the metric dY . However in practice it
will be obvious what the metric dY is and so we will omit the dY−preﬁx
from the notation.

48
3.
Uniform convergence
— Exercises —
Exercise 3.1.1. Let (X, dX) and (Y, dY ) be metric spaces, let E be a subset of
X, let f : E →Y be a function, and let x0 be an element of E. Show that
the limit limx→x0;x∈E f(x) exists if and only if the limit limx→x0;x∈E\{x0} f(x)
exists and is equal to f(x0).
Also, show that if the limit limx→x0;x∈E f(x)
exists at all, then it must equal f(x0).
Exercise 3.1.2. Prove Proposition 3.1.5. (Hint: review your proof of Theorem
2.1.4.)
Exercise 3.1.3. Use Proposition 3.1.5(c) to deﬁne a notion of a limiting value of
a function f : X →Y from one topological space (X, FX) to another (Y, FY ).
Then prove the equivalence of Proposition 3.1.5(c) and 3.1.5(d). If in addition
Y is a Hausdorﬀtopological space (see Exercise 2.5.4), prove an analogue of
Remark 3.1.6. Is the same statement true if Y is not Hausdorﬀ?
Exercise 3.1.4. Recall from Exercise 2.5.5 that the extended real line R∗comes
with a standard topology (the order topology). We view the natural numbers
N as a subspace of this topological space, and +∞as an adherent point of N
in R∗. Let (an)∞
n=0 be a sequence taking values in a topological space (Y, FY ),
and let L ∈Y . Show that limn→+∞;n∈N an = L (in the sense of Exercise 3.1.3)
if and only if limn→∞an = L (in the sense of Deﬁnition 2.5.4). This shows that
the notions of limiting values of a sequence, and limiting values of a function,
are compatible.
Exercise 3.1.5. Let (X, dX), (Y, dY ), (Z, dZ) be metric spaces, and let x0 ∈X,
y0 ∈Y , z0 ∈Z. Let f : X →Y and g : Y →Z be functions, and let E be a
set. If we have limx→x0;x∈E f(x) = y0 and limy→y0;y∈f(E) g(y) = z0, conclude
that limx∈x0;x∈E g ◦f(x) = z0.
Exercise 3.1.6. State and prove an analogue of the limit laws in Proposition
9.3.14 when X is now a metric space rather than a subset of R. (Hint: use
Corollary 2.2.3.)
3.2
Pointwise and uniform convergence
The most obvious notion of convergence of functions is pointwise con-
vergence, or convergence at each point of the domain:
Deﬁnition 3.2.1 (Pointwise convergence). Let (f(n))∞
n=1 be a sequence
of functions from one metric space (X, dX) to another (Y, dY ), and let
f : X →Y be another function.
We say that (f(n))∞
n=1 converges
pointwise to f on X if we have
lim
n→∞f(n)(x) = f(x)
for all x ∈X, i.e.
lim
n→∞dY (f(n)(x), f(x)) = 0.

3.2.
Pointwise and uniform convergence
49
Or in other words, for every x and every ε > 0 there exists N > 0 such
that dY (f(n)(x), f(x)) < ε for every n > N. We call the function f the
pointwise limit of the functions f(n).
Remark 3.2.2. Note that f(n)(x) and f(x) are points in Y , rather than
functions, so we are using our prior notion of convergence in metric
spaces to determine convergence of functions. Also note that we are
not really using the fact that (X, dX) is a metric space (i.e., we are not
using the metric dX); for this deﬁnition it would suﬃce for X to just
be a plain old set with no metric structure. However, later on we shall
want to restrict our attention to continuous functions from X to Y ,
and in order to do so we need a metric on X (and on Y ), or at least a
topological structure. Also when we introduce the concept of uniform
convergence, then we will deﬁnitely need a metric structure on X and
Y ; there is no comparable notion for topological spaces.
Example 3.2.3. Consider the functions f(n) : R →R deﬁned by
f(n)(x) := x/n, while f : R →R is the zero function f(x) := 0. Then
f(n) converges pointwise to f, since for each ﬁxed real number x we have
limn→∞f(n)(x) = limn→∞x/n = 0 = f(x).
From Proposition 1.1.20 we see that a sequence (f(n))∞
n=1 of functions
from one metric space (X, dX) to another (Y, dY ) can have at most one
pointwise limit f (this explains why we can refer to f as the pointwise
limit).
However, it is of course possible for a sequence of functions
to have no pointwise limit (can you think of an example?), just as a
sequence of points in a metric space do not necessarily have a limit.
Pointwise convergence is a very natural concept, but it has a number
of disadvantages: it does not preserve continuity, derivatives, limits, or
integrals, as the following three examples show.
Example 3.2.4. Consider the functions f(n) : [0, 1] →R deﬁned by
f(n)(x) := xn, and let f : [0, 1] →R be the function deﬁned by setting
f(x) := 1 when x = 1 and f(x) := 0 when 0 ≤x < 1. Then the functions
f(n) are continuous, and converge pointwise to f on [0, 1] (why? treat
the cases x = 1 and 0 ≤x < 1 separately), however the limiting function
f is not continuous. Note that the same example shows that pointwise
convergence does not preserve diﬀerentiability either.
Example 3.2.5. If limx→x0;x∈E f(n)(x) = L for every n, and f(n)
converges pointwise to f, we cannot always take limits conclude that

50
3.
Uniform convergence
limx→x0;x∈E f(x) = L. The previous example is also a counterexam-
ple here: observe that limx→1;x∈[0,1) xn = 1 for every n, but xn con-
verges pointwise to the function f deﬁned in the previous paragraph,
and limx→1;x∈[0,1) f(x) = 0. In particular, we see that
lim
n→∞
lim
x→x0;x∈X f(n)(x) ̸=
lim
x→x0;x∈X lim
n→∞f(n)(x).
(cf.
Example 1.2.8).
Thus pointwise convergence does not preserve
limits.
Example 3.2.6. Suppose that f(n) : [a, b] →R a sequence of Riemann-
integrable functions on the interval [a, b].
If

[a,b] f(n) = L for every
n, and f(n) converges pointwise to some new function f, this does not
mean that

[a,b] f = L. An example comes by setting [a, b] := [0, 1], and
letting f(n) be the function f(n)(x) := 2n when x ∈[1/2n, 1/n], and
f(n)(x) := 0 for all other values of x. Then f(n) converges pointwise to
the zero function f(x) := 0 (why?). On the other hand,

[0,1] f(n) = 1
for every n, while

[0,1] f = 0. In particular, we have an example where
lim
n→∞

[a,b]
f(n) ̸=

[a,b]
lim
n→∞f(n).
One may think that this counterexample has something to do with the
f(n) being discontinuous, but one can easily modify this counterexample
to make the f(n) continuous (can you see how?).
Another example in the same spirit is the “moving bump” example.
Let f(n) : R →R be the function deﬁned by f(n)(x) := 1 if x ∈
[n, n + 1] and f(n)(x) := 0 otherwise. Then

R f(n) = 1 for every n
(where

R f is deﬁned as the limit of

[−N,N] f as N goes to inﬁnity). On
the other hand, f(n) converges pointwise to the zero function 0 (why?),
and

R 0 = 0.
In both of these examples, functions of area 1 have
somehow “disappeared” to produce functions of area 0 in the limit. See
also Example 1.2.9.
These examples show that pointwise convergence is too weak a con-
cept to be of much use. The problem is that while f(n)(x) converges to
f(x) for each x, the rate of that convergence varies substantially with
x. For instance, consider the ﬁrst example where f(n) : [0, 1] →R was
the function f(n)(x) := xn, and f : [0, 1] →R was the function such
that f(x) := 1 when x = 1, and f(x) := 0 otherwise. Then for each

3.2.
Pointwise and uniform convergence
51
x, f(n)(x) converges to f(x) as n →∞; this is the same as saying that
limn→∞xn = 0 when 0 ≤x < 1, and that limn→∞xn = 1 when x = 1.
But the convergence is much slower near 1 than far away from 1. For
instance, consider the statement that limn→∞xn = 0 for all 0 ≤x < 1.
This means, for every 0 ≤x < 1, that for every ε, there exists an N ≥1
such that |xn| < ε for all n ≥N - or in other words, the sequence
1, x, x2, x3, . . . will eventually get less than ε, after passing some ﬁnite
number N of elements in this sequence. But the number of elements
N one needs to go out to depends very much on the location of x. For
instance, take ε := 0.1. If x = 0.1, then we have |xn| < ε for all n ≥2 -
the sequence gets underneath ε after the second element. But if x = 0.5,
then we only get |xn| < ε for n ≥4 - you have to wait until the fourth
element to get within ε of the limit. And if x = 0.9, then one only has
|xn| < ε when n ≥22. Clearly, the closer x gets to 1, the longer one has
to wait until f(n)(x) will get within ε of f(x), although it still will get
there eventually. (Curiously, however, while the convergence gets worse
and worse as x approaches 1, the convergence suddenly becomes perfect
when x = 1.)
To put things another way, the convergence of f(n) to f is not uniform
in x - the N that one needs to get f(n)(x) within ε of f depends on x
as well as on ε. This motivates a stronger notion of convergence.
Deﬁnition 3.2.7 (Uniform convergence). Let (f(n))∞
n=1 be a sequence
of functions from one metric space (X, dX) to another (Y, dY ), and let
f : X →Y be another function.
We say that (f(n))∞
n=1 converges
uniformly to f on X if for every ε > 0 there exists N > 0 such that
dY (f(n)(x), f(x)) < ε for every n > N and x ∈X. We call the function
f the uniform limit of the functions f(n).
Remark 3.2.8. Note that this deﬁnition is subtly diﬀerent from the
deﬁnition for pointwise convergence in Deﬁnition 3.2.1. In the deﬁnition
of pointwise convergence, N was allowed to depend on x; now it is not.
The reader should compare this distinction to the distinction between
continuity and uniform continuity (i.e., between Deﬁnition 2.1.1 and
Deﬁnition 2.3.4). A more precise formulation of this analogy is given in
Exercise 3.2.1.
It is easy to see that if f(n) converges uniformly to f on X, then
it also converges pointwise to the same function f (see Exercise 3.2.2);
thus when the uniform limit and pointwise limit both exist, then they

52
3.
Uniform convergence
have to be equal. However, the converse is not true; for instance the
functions f(n) : [0, 1] →R deﬁned earlier by f(n)(x) := xn converge
pointwise, but do not converge uniformly (see Exercise 3.2.2).
Example 3.2.9. Let f(n) : [0, 1] →R be the functions f(n)(x) := x/n,
and let f : [0, 1] →R be the zero function f(x) := 0. Then it is clear that
f(n) converges to f pointwise. Now we show that in fact f(n) converges
to f uniformly. We have to show that for every ε > 0, there exists an
N such that |f(n)(x) −f(x)| < ε for every x ∈[0, 1] and every n ≥N.
To show this, let us ﬁx an ε > 0. Then for any x ∈[0, 1] and n ≥N, we
have
|f(n)(x) −f(x)| = |x/n −0| = x/n ≤1/n ≤1/N.
Thus if we choose N such that N > 1/ε (note that this choice of N
does not depend on what x is), then we have |f(n)(x) −f(x)| < ε for all
n ≥N and x ∈[0, 1], as desired.
We make one trivial remark here: if a sequence f(n) : X →Y of
functions converges pointwise (or uniformly) to a function f : X →Y ,
then the restrictions f(n)|E : E →Y of f(n) to some subset E of X will
also converge pointwise (or uniformly) to f|Y . (Why?)
— Exercises —
Exercise 3.2.1. The purpose of this exercise is to demonstrate a concrete rela-
tionship between continuity and pointwise convergence, and between uniform
continuity and uniform convergence. Let f : R →R be a function. For any
a ∈R, let fa : R →R be the shifted function fa(x) := f(x −a).
(a) Show that f is continuous if and only if, whenever (an)∞
n=0 is a sequence of
real numbers which converges to zero, the shifted functions fan converge
pointwise to f.
(b) Show that f is uniformly continuous if and only if, whenever (an)∞
n=0 is
a sequence of real numbers which converges to zero, the shifted functions
fan converge uniformly to f.
Exercise 3.2.2.
(a) Let (f (n))∞
n=1 be a sequence of functions from one metric
space (X, dX) to another (Y, dY ), and let f : X →Y be another function
from X to Y . Show that if f (n) converges uniformly to f, then f (n) also
converges pointwise to f.
(b) For each integer n ≥1, let f (n) : (−1, 1) →R be the function f (n)(x) :=
xn. Prove that f (n) converges pointwise to the zero function 0, but does
not converge uniformly to any function f : (−1, 1) →R.

3.3.
Uniform convergence and continuity
53
(c) Let g : (−1, 1) →R be the function g(x) := x/(1−x). With the notation
as in (b), show that the partial sums N
n=1 f (n) converges pointwise as
N →∞to g, but does not converge uniformly to g, on the open interval
(−1, 1). (Hint: use Lemma 7.3.3.) What would happen if we replaced
the open interval (−1, 1) with the closed interval [−1, 1]?
Exercise 3.2.3. Let (X, dX) a metric space, and for every integer n ≥1, let
fn : X →R be a real-valued function. Suppose that fn converges pointwise
to another function f : X →R on X (in this question we give R the standard
metric d(x, y) = |x −y|). Let h : R →R be a continuous function. Show that
the functions h ◦fn converge pointwise to h ◦f on X, where h ◦fn : X →R
is the function h ◦fn(x) := h(fn(x)), and similarly for h ◦f.
Exercise 3.2.4. Let fn : X →Y be a sequence of bounded functions from
one metric space (X, dX) to another metric space (Y, dY ). Suppose that fn
converges uniformly to another function f : X →Y .
Suppose that f is a
bounded function; i.e., there exists a ball B(Y,dY )(y0, R) in Y such that f(x) ∈
B(Y,dY )(y0, R) for all x ∈X. Show that the sequence fn is uniformly bounded;
i.e. there exists a ball B(Y,dY )(y0, R) in Y such that fn(x) ∈B(Y,dY )(y0, R) for
all x ∈X and all positive integers n.
3.3
Uniform convergence and continuity
We now give the ﬁrst demonstration that uniform convergence is signiﬁ-
cantly better than pointwise convergence. Speciﬁcally, we show that the
uniform limit of continuous functions is continuous.
Theorem
3.3.1
(Uniform limits preserve continuity I). Suppose
(f(n))∞
n=1 is a sequence of functions from one metric space (X, dX) to
another (Y, dY ), and suppose that this sequence converges uniformly to
another function f : X →Y . Let x0 be a point in X. If the functions
f(n) are continuous at x0 for each n, then the limiting function f is also
continuous at x0.
Proof. See Exercise 3.3.1.
This has an immediate corollary:
Corollary 3.3.2 (Uniform limits preserve continuity II). Let (f(n))∞
n=1
be a sequence of functions from one metric space (X, dX) to another
(Y, dY ), and suppose that this sequence converges uniformly to another
function f : X →Y . If the functions f(n) are continuous on X for each
n, then the limiting function f is also continuous on X.

54
3.
Uniform convergence
This should be contrasted with Example 3.2.4.
There is a slight
variant of Theorem 3.3.1 which is also useful:
Proposition 3.3.3 (Interchange of limits and uniform limits). Let
(X, dX) and (Y, dY ) be metric spaces, with Y complete, and let E be
a subset of X. Let (f(n))∞
n=1 be a sequence of functions from E to Y ,
and suppose that this sequence converges uniformly in E to some func-
tion f : E →Y .
Let x0 ∈X be an adherent point of E, and sup-
pose that for each n the limit limx→x0;x∈E f(n)(x) exists. Then the limit
limx→x0;x∈E f(x) also exists, and is equal to the limit of the sequence
(limx→x0;x∈E f(n)(x))∞
n=1; in other words we have the interchange of lim-
its
lim
n→∞
lim
x→x0;x∈E f(n)(x) =
lim
x→x0;x∈E lim
n→∞f(n)(x).
Proof. See Exercise 3.3.2.
This should be constrasted with Example 3.2.5. Finally, we have a
version of these theorems for sequences:
Proposition 3.3.4. Let (f(n))∞
n=1 be a sequence of continuous functions
from one metric space (X, dX) to another (Y, dY ), and suppose that this
sequence converges uniformly to another function f : X →Y . Let x(n)
be a sequence of points in X which converge to some limit x.
Then
f(n)(x(n)) converges (in Y ) to f(x).
Proof. See Exercise 3.3.4.
A similar result holds for bounded functions:
Deﬁnition 3.3.5 (Bounded functions). A function f : X →Y from
one metric space (X, dX) to another (Y, dY ) is bounded if f(X) is a
bounded set, i.e., there exists a ball B(Y,dY )(y0, R) in Y such that f(x) ∈
B(Y,dY )(y0, R) for all x ∈X.
Proposition
3.3.6
(Uniform
limits
preserve
boundedness). Let
(f(n))∞
n=1 be a sequence of functions from one metric space (X, dX) to
another (Y, dY ), and suppose that this sequence converges uniformly to
another function f : X →Y . If the functions f(n) are bounded on X
for each n, then the limiting function f is also bounded on X.
Proof. See Exercise 3.3.6.

3.3.
Uniform convergence and continuity
55
Remark 3.3.7. The above propositions sound very reasonable, but one
should caution that it only works if one assumes uniform convergence;
pointwise convergence is not enough. (See Exercises 3.3.3, 3.3.5, 3.3.7.)
— Exercises —
Exercise 3.3.1. Prove Theorem 3.3.1. Explain brieﬂy why your proof requires
uniform convergence, and why pointwise convergence would not suﬃce. (Hints:
it is easiest to use the “epsilon-delta” deﬁnition of continuity from Deﬁnition
2.1.1. You may ﬁnd the triangle inequality
dY (f(x), f(x0)) ≤dY (f(x), f (n)(x)) + dY (f (n)(x), f (n)(x0))
+ dY (f (n)(x0), f(x0))
useful. Also, you may need to divide ε as ε = ε/3 + ε/3 + ε/3. Finally, it is
possible to prove Theorem 3.3.1 from Proposition 3.3.3, but you may ﬁnd it
easier conceptually to prove Theorem 3.3.1 ﬁrst.)
Exercise 3.3.2. Prove Proposition 3.3.3. (Hint: this is very similar to Theorem
3.3.1. Theorem 3.3.1 cannot be used to prove Proposition 3.3.3, however it is
possible to use Proposition 3.3.3 to prove Theorem 3.3.1.)
Exercise 3.3.3. Compare Proposition 3.3.3 with Example 1.2.8. Can you now
explain why the interchange of limits in Example 1.2.8 led to a false statement,
whereas the interchange of limits in Proposition 3.3.3 is justiﬁed?
Exercise 3.3.4. Prove Proposition 3.3.4. (Hint: again, this is similar to Theo-
rem 3.3.1 and Proposition 3.3.3, although the statements are slightly diﬀerent,
and one cannot deduce this directly from the other two results.)
Exercise 3.3.5. Give an example to show that Proposition 3.3.4 fails if the
phrase “converges uniformly” is replaced by “converges pointwise”.
(Hint:
some of the examples already given earlier will already work here.)
Exercise 3.3.6. Prove Proposition 3.3.6. Discuss how this proposition diﬀers
from Exercise 3.2.4.
Exercise 3.3.7. Give an example to show that Proposition 3.3.6 fails if the
phrase “converges uniformly” is replaced by “converges pointwise”.
(Hint:
some of the examples already given earlier will already work here.)
Exercise 3.3.8. Let (X, d) be a metric space, and for every positive integer n,
let fn : X →R and gn : X →R be functions. Suppose that (fn)∞
n=1 con-
verges uniformly to another function f : X →R, and that (gn)∞
n=1 converges
uniformly to another function g : X →R. Suppose also that the functions
(fn)∞
n=1 and (gn)∞
n=1 are uniformly bounded, i.e., there exists an M > 0 such
that |fn(x)| ≤M and |gn(x)| ≤M for all n ≥1 and x ∈X. Prove that the
functions fngn : X →R converge uniformly to fg : X →R.

56
3.
Uniform convergence
3.4
The metric of uniform convergence
We have now developed at least four, apparently separate, notions of
limit in this text:
(a) limits limn→∞x(n) of sequences of points in a metric space (Deﬁ-
nition 1.1.14; see also Deﬁnition 2.5.4);
(b) limiting values limx→x0;x∈E f(x) of functions at a point (Deﬁnition
3.1.1);
(c) pointwise limits f of functions f(n) (Deﬁnition 3.2.1; and
(d) uniform limits f of functions f(n) (Deﬁnition 3.2.7).
This proliferation of limits may seem rather complicated. However,
we can reduce the complexity slightly by observing that (d) can be
viewed as a special case of (a), though in doing so it should be cautioned
that because we are now dealing with functions instead of points, the
convergence is not in X or in Y , but rather in a new space, the space of
functions from X to Y .
Remark 3.4.1. If one is willing to work in topological spaces instead of
metric spaces, we can also view (b) as a special case of (a), see Exercise
3.1.4, and (c) is also a special case of (a), see Exercise 3.4.4. Thus the
notion of convergence in a topological space can be used to unify all the
notions of limits we have encountered so far.
Deﬁnition 3.4.2 (Metric space of bounded functions). Suppose (X, dX)
and (Y, dY ) are metric spaces. We let B(X →Y ) denote the space1 of
bounded functions from X to Y :
B(X →Y ) := {f
f : X →Y is a bounded function}.
We deﬁne a metric d∞: B(X →Y ) × B(X →Y ) →R+ by deﬁning
d∞(f, g) := sup
x∈X
dY (f(x), g(x)) = sup{dY (f(x), g(x)) : x ∈X}
for all f, g ∈B(X →Y ). This metric is sometimes known as the sup
norm metric or the L∞metric. We will also use dB(X→Y ) as a synonym
for d∞.
1Note that this is a set, thanks to the power set axiom (Axiom 3.10) and the axiom
of speciﬁcation (Axiom 3.5).

3.4.
The metric of uniform convergence
57
Notice that the distance d∞(f, g) is always ﬁnite because f and g
are assumed to be bounded on X.
Example 3.4.3. Let X := [0, 1] and Y = R. Let f : [0, 1] →R and
g : [0, 1] →R be the functions f(x) := 2x and g(x) := 3x. Then f
and g are both bounded functions and thus live in B([0, 1] →R). The
distance between them is
d∞(f, g) = sup
x∈[0,1]
|2x −3x| = sup
x∈[0,1]
|x| = 1.
This space turns out to be a metric space (Exercise 3.4.1). Conver-
gence in this metric turns out to be identical to uniform convergence:
Proposition 3.4.4. Let (X, dX) and (Y, dY ) be metric spaces.
Let
(f(n))∞
n=1 be a sequence of functions in B(X →Y ), and let f be an-
other function in B(X →Y ). Then (f(n))∞
n=1 converges to f in the
metric dB(X→Y ) if and only if (f(n))∞
n=1 converges uniformly to f.
Proof. See Exercise 3.4.2.
Now let C(X →Y ) be the space of bounded continuous functions
from X to Y :
C(X →Y ) := {f ∈B(X →Y )
f is continuous}.
This set C(X →Y ) is clearly a subset of B(X →Y ). Corollary
3.3.2 asserts that this space C(X →Y ) is closed in B(X →Y ) (why?).
Actually, we can say a lot more:
Theorem 3.4.5 (The space of continuous functions is complete). Let
(X, dX) be a metric space, and let (Y, dY ) be a complete metric space.
The space (C(X →Y ), dB(X→Y )|C(X→Y )×C(X→Y )) is a complete sub-
space of (B(X →Y ), dB(X→Y )). In other words, every Cauchy sequence
of functions in C(X →Y ) converges to a function in C(X →Y ).
Proof. See Exercise 3.4.3.
— Exercises —
Exercise 3.4.1. Let (X, dX) and (Y, dY ) be metric spaces. Show that the space
B(X →Y ) deﬁned in Deﬁnition 3.4.2, with the metric dB(X→Y ), is indeed a
metric space.
Exercise 3.4.2. Prove Proposition 3.4.4.

58
3.
Uniform convergence
Exercise 3.4.3. Prove Theorem 3.4.5. (Hint: this is similar, but not identical,
to the proof of Theorem 3.3.1).
Exercise 3.4.4. Let (X, dX) and (Y, dY ) be metric spaces, and let Y X := {f
f :
X →Y } be the space of all functions from X to Y (cf. Axiom 3.10). If x0 ∈X
and V is an open set in Y , let V (x0) ⊆Y X be the set
V (x0) := {f ∈Y X : f(x0) ∈V }.
If E is a subset of Y X, we say that E is open if for every f ∈E, there exists a
ﬁnite number of points x1, . . . , xn ∈X and open sets V1, . . . , Vn ⊆Y such that
f ∈V (x1)
1
∩. . . ∩V (xn)
n
⊆E.
• Show that if F is the collection of open sets in Y X, then (Y X, F) is a
topological space.
• For each natural number n, let f (n) : X →Y be a function from X to
Y , and let f : X →Y be another function from X to Y . Show that f (n)
converges to f in the topology F (in the sense of Deﬁnition 2.5.4) if and
only if f (n) converges to f pointwise (in the sense of Deﬁnition 3.2.1).
The topology F is known as the topology of pointwise convergence, for obvious
reasons; it is also known as the product topology. It shows that the concept
of pointwise convergence can be viewed as a special case of the more general
concept of convergence in a topological space.
3.5
Series of functions; the Weierstrass M-test
Having discussed sequences of functions, we now discuss inﬁnite series
∞
n=1 fn of functions. Now we shall restrict our attention to functions
f : X →R from a metric space (X, dX) to the real line R (which we of
course give the standard metric); this is because we know how to add
two real numbers, but don’t necessarily know how to add two points in
a general metric space Y . Functions whose range is R are sometimes
called real-valued functions.
Finite summation is, of course, easy:
given any ﬁnite collection
f(1), . . . , f(N) of functions from X to R, we can deﬁne the ﬁnite sum
N
i=1 f(i) : X →R by
 N

i=1
f(i)

(x) :=
N

i=1
f(i)(x).
Example 3.5.1. If f(1) : R →R is the function f(1)(x) := x, f(2) :
R →R is the function f(2)(x) := x2, and f(3) : R →R is the function

3.5.
Series of functions; the Weierstrass M-test
59
f(3)(x) := x3, then f := 3
i=1 f(i) is the function f : R →R deﬁned by
f(x) := x + x2 + x3.
It is easy to show that ﬁnite sums of bounded functions are bounded,
and ﬁnite sums of continuous functions are continuous (Exercise 3.5.1).
Now to add inﬁnite series.
Deﬁnition 3.5.2 (Inﬁnite series). Let (X, dX) be a metric space. Let
(f(n))∞
n=1 be a sequence of functions from X to R, and let f be another
function from X to R. If the partial sums N
n=1 f(n) converge pointwise
to f on X as N →∞, we say that the inﬁnite series ∞
n=1 f(n) converges
pointwise to f, and write f = ∞
n=1 f(n). If the partial sums N
n=1 f(n)
converge uniformly to f on X as N →∞, we say that the inﬁnite series
∞
n=1 f(n) converges uniformly to f, and again write f = ∞
n=1 f(n).
(Thus when one sees an expression such as f = ∞
n=1 f(n), one should
look at the context to see in what sense this inﬁnite series converges.)
Remark 3.5.3. A series ∞
n=1 f(n) converges pointwise to f on X if
and only if ∞
n=1 f(n)(x) converges to f(x) for every x ∈X. (Thus if
∞
n=1 f(n) does not converge pointwise to f, this does not mean that it
diverges pointwise; it may just be that it converges for some points x
but diverges at other points x.)
If a series ∞
n=1 f(n) converges uniformly to f, then it also converges
pointwise to f; but not vice versa, as the following example shows.
Example 3.5.4. Let f(n) : (−1, 1) →R be the sequence of functions
f(n)(x) := xn. Then ∞
n=1 f(n) converges pointwise, but not uniformly,
to the function x/(1 −x) (see Exercise 3.2.2 and Example 3.5.8).
It is not always clear when a series ∞
n=1 f(n) converges or not.
However, there is a very useful test that gives at least one test for uniform
convergence.
Deﬁnition 3.5.5 (Sup norm). If f : X →R is a bounded real-valued
function, we deﬁne the sup norm ∥f∥∞of f to be the number
∥f∥∞:= sup{|f(x)| : x ∈X}.
In other words, ∥f∥∞= d∞(f, 0), where 0 : X →R is the zero function
0(x) := 0, and d∞was deﬁned in Deﬁnition 3.4.2. (Why is this the
case?)

60
3.
Uniform convergence
Example 3.5.6. Thus, for instance, if f : (−2, 1) →R is the function
f(x) := 2x, then ∥f∥∞= sup{|2x| : x ∈(−2, 1)} = 4 (why?). Notice
that when f is bounded then ∥f∥∞will always be a non-negative real
number.
Theorem 3.5.7 (Weierstrass M-test). Let (X, d) be a metric space, and
let (f(n))∞
n=1 be a sequence of bounded real-valued continuous functions
on X such that the series ∞
n=1 ∥f(n)∥∞is convergent. (Note that this
is a series of plain old real numbers, not of functions.) Then the se-
ries ∞
n=1 f(n) converges uniformly to some function f on X, and that
function f is also continuous.
Proof. See Exercise 3.5.2.
To put the Weierstrass M-test succinctly: absolute convergence of
sup norms implies uniform convergence of functions.
Example 3.5.8. Let 0 < r < 1 be a real number, and let f(n) : [−r, r] →
R be the series of functions f(n)(x) := xn. Then each f(n) is continuous
and bounded, and ∥f(n)∥∞= rn (why?). Since the series ∞
n=1 rn is
absolutely convergent (e.g., by the ratio test, Theorem 7.5.1), we thus
see that f(n) converges uniformly in [−r, r] to some continuous function;
in Exercise 3.2.2(c) we see that this function must in fact be the function
f : [−r, r] →R deﬁned by f(x) := x/(1 −x).
In other words, the
series ∞
n=1 xn is pointwise convergent, but not uniformly convergent,
on (−1, 1), but is uniformly convergent on the smaller interval [−r, r] for
any 0 < r < 1.
The Weierstrass M-test is especially useful in relation to power se-
ries, which we will encounter in the next chapter.
— Exercises —
Exercise 3.5.1. Let f (1), . . . , f (N) be a ﬁnite sequence of bounded functions
from a metric space (X, dX) to R. Show that N
i=1 f (i) is also bounded. Prove
a similar claim when “bounded” is replaced by “continuous”. What if “contin-
uous” was replaced by “uniformly continuous”?
Exercise 3.5.2. Prove Theorem 3.5.7.
(Hint: ﬁrst show that the sequence
N
i=1 f (i) is a Cauchy sequence in C(X →R). Then use Theorem 3.4.5.)

3.6.
Uniform convergence and integration
61
3.6
Uniform convergence and integration
We now connect uniform convergence with Riemann integration (which
was discussed in Chapter 11), by showing that uniform limits can be
safely interchanged with integrals.
Theorem 3.6.1. Let [a, b] be an interval, and for each integer n ≥1,
let f(n) : [a, b] →R be a Riemann-integrable function. Suppose f(n)
converges uniformly on [a, b] to a function f : [a, b] →R. Then f is also
Riemann integrable, and
lim
n→∞

[a,b]
f(n) =

[a,b]
f.
Proof. We ﬁrst show that f is Riemann integrable on [a, b]. This is the
same as showing that the upper and lower Riemann integrals of f match:

[a,b]f =

[a,b]f.
Let ε > 0. Since f(n) converges uniformly to f, we see that there
exists an N > 0 such that |f(n)(x) −f(x)| < ε for all n > N and
x ∈[a, b]. In particular we have
f(n)(x) −ε < f(x) < f(n)(x) + ε
for all x ∈[a, b]. Integrating this on [a, b] we obtain

[a,b]
(f(n) −ε) ≤

[a,b]
f ≤

[a,b]
f ≤

[a,b]
(f(n) + ε).
Since f(n) is assumed to be Riemann integrable, we thus see

[a,b]
f(n)

−ε(b −a) ≤

[a,b]
f ≤

[a,b]
f ≤

[a,b]
f(n)

+ ε(b −a).
In particular, we see that
0 ≤

[a,b]
f −

[a,b]
f ≤2ε(b −a).
Since this is true for every ε > 0, we obtain

[a,b]f =

[a,b]f as desired.
The above argument also shows that for every ε > 0 there exists an
N > 0 such that


[a,b]
f(n) −

[a,b]
f
 ≤2ε(b −a)

62
3.
Uniform convergence
for all n ≥N. Since ε is arbitrary, we see that

[a,b] f(n) converges to

[a,b] f as desired.
To rephrase Theorem 3.6.1: we can rearrange limits and integrals
(on compact intervals [a, b]),
lim
n→∞

[a,b]
f(n) =

[a,b]
lim
n→∞f(n),
provided that the convergence is uniform.
This should be contrasted
with Example 3.2.5 and Example 1.2.9.
There is an analogue of this theorem for series:
Corollary 3.6.2. Let [a, b] be an interval, and let (f(n))∞
n=1 be a se-
quence of Riemann integrable functions on [a, b] such that the series
∞
n=1 f(n) is uniformly convergent. Then we have
∞

n=1

[a,b]
f(n) =

[a,b]
∞

n=1
f(n).
Proof. See Exercise 3.6.1.
This Corollary works particularly well in conjunction with the Weier-
strass M-test (Theorem 3.5.7):
Example 3.6.3. (Informal) From Lemma 7.3.3 we have the geometric
series identity
∞

n=1
xn =
x
1 −x
for x ∈(−1, 1), and the convergence is uniform (by the Weierstrass
M-test) on [−r, r] for any 0 < r < 1. By adding 1 to both sides we
obtain
∞

n=0
xn =
1
1 −x
and the converge is again uniform. We can thus integrate on [0, r] and
use Corollary 3.6.2 to obtain
∞

n=0

[0,r]
xn dx =

[0,r]
1
1 −x dx.
The left-hand side is ∞
n=0 rn+1/(n + 1). If we accept for now the use
of logarithms (we will justify this use in Section 4.5), the anti-derivative

3.7.
Uniform convergence and derivatives
63
of 1/(1 −x) is −log(1 −x), and so the right-hand side is −log(1 −r).
We thus obtain the formula
−log(1 −r) =
∞

n=0
rn+1/(n + 1)
for all 0 < r < 1.
— Exercises —
Exercise 3.6.1. Use Theorem 3.6.1 to prove Corollary 3.6.2.
3.7
Uniform convergence and derivatives
We have already seen how uniform convergence interacts well with con-
tinuity, with limits, and with integrals. Now we investigate how it in-
teracts with derivatives.
The ﬁrst question we can ask is: if fn converges uniformly to f,
and the functions fn are diﬀerentiable, does this imply that f is also
diﬀerentiable? And does f′
n also converge to f′?
The answer to the second question is, unfortunately, no.
To
see a counterexample, we will use without proof some basic facts
about trigonometric functions (which we will make rigorous in Sec-
tion 4.7).
Consider the functions fn
: [0, 2π] →R deﬁned by
fn(x) := n−1/2 sin(nx), and let f : [0, 2π] →R be the zero func-
tion f(x) := 0.
Then, since sin takes values between -1 and 1, we
have d∞(fn, f) ≤n−1/2, where we use the uniform metric d∞(f, g) :=
supx∈[0,2π] |f(x)−g(x)| introduced in Deﬁnintion 3.4.2. Since n−1/2 con-
verges to 0, we thus see by the squeeze test that fn converges uniformly
to f. On the other hand, f′
n(x) = n1/2 cos(nx), and so in particular
|f′
n(0) −f′(0)| = n1/2. Thus f′
n does not converge pointwise to f′, and
so in particular does not converge uniformly either. In particular we
have
d
dx lim
n→∞fn(x) ̸= lim
n→∞
d
dxfn(x).
The answer to the ﬁrst question is also no. An example is the se-
quence of functions fn : [−1, 1] →R deﬁned by fn(x) :=

1
n2 + x2.
These functions are diﬀerentiable (why?). Also, one can easily check
that
|x| ≤fn(x) ≤|x| + 1
n

64
3.
Uniform convergence
for all x ∈[−1, 1] (why? square both sides), and so by the squeeze test
fn converges uniformly to the absolute value function f(x) := |x|. But
this function is not diﬀerentiable at 0 (why?). Thus, the uniform limit
of diﬀerentiable functions need not be diﬀerentiable. (See also Example
1.2.10).
So, in summary, uniform convergence of the functions fn says nothing
about the convergence of the derivatives f′
n. However, the converse is
true, as long as fn converges at at least one point:
Theorem 3.7.1. Let [a, b] be an interval, and for every integer n ≥1, let
fn : [a, b] →R be a diﬀerentiable function whose derivative f′
n : [a, b] →
R is continuous. Suppose that the derivatives f′
n converge uniformly to
a function g : [a, b] →R. Suppose also that there exists a point x0 such
that the limit limn→∞fn(x0) exists.
Then the functions fn converge
uniformly to a diﬀerentiable function f, and the derivative of f equals
g.
Informally, the above theorem says that if f′
n converges uniformly,
and fn(x0) converges for some x0, then fn also converges uniformly, and
d
dx limn→∞fn(x) = limn→∞d
dxfn(x).
Proof. We only give the beginning of the proof here; the remainder of
the proof will be an exercise (Exercise 3.7.1).
Since f′
n is continuous, we see from the fundamental theorem of cal-
culus (Theorem 11.9.4) that
fn(x) −fn(x0) =

[x0,x]
f′
n
when x ∈[x0, b], and
fn(x) −fn(x0) = −

[x,x0]
f′
n
when x ∈[a, x0].
Let L be the limit of fn(x0) as n →∞:
L := lim
n→∞fn(x0).
By hypothesis, L exists. Now, since each f′
n is continuous on [a, b], and
f′
n converges uniformly to g, we see by Corollary 3.3.2 that g is also
continuous. Now deﬁne the function f : [a, b] →R by setting
f(x) := L −

[a,x0]
g +

[a,x]
g

3.7.
Uniform convergence and derivatives
65
for all x ∈[a, b]. To ﬁnish the proof, we have to show that fn converges
uniformly to f, and that f is diﬀerentiable with derivative g; this shall
be done in Exercise 3.7.1.
Remark 3.7.2. It turns out that Theorem 3.7.1 is still true when the
functions f′
n are not assumed to be continuous, but the proof is more
diﬃcult; see Exercise 3.7.2.
By combining this theorem with the Weierstrass M-test, we obtain
Corollary 3.7.3. Let [a, b] be an interval, and for every integer n ≥1,
let fn : [a, b] →R be a diﬀerentiable function whose derivative f′
n :
[a, b] →R is continuous. Suppose that the series ∞
n=1 ∥f′
n∥∞is abso-
lutely convergent, where
∥f′
n∥∞:= sup
x∈[a,b]
|f′
n(x)|
is the sup norm of f′
n, as deﬁned in Deﬁnition 3.5.5. Suppose also that
the series ∞
n=1 fn(x0) is convergent for some x0 ∈[a, b].
Then the
series ∞
n=1 fn converges uniformly on [a, b] to a diﬀerentiable function,
and in fact
d
dx
∞

n=1
fn(x) =
∞

n=1
d
dxfn(x)
for all x ∈[a, b].
Proof. See Exercise 3.7.3.
We now pause to give an example of a function which is continu-
ous everywhere, but diﬀerentiable nowhere (this particular example was
discovered by Weierstrass). Again, we will presume knowledge of the
trigonometric functions, which will be covered rigorously in Section 4.7.
Example 3.7.4. Let f : R →R be the function
f(x) :=
∞

n=1
4−n cos(32nπx).
Note that this series is uniformly convergent, thanks to the Weierstrass
M-test, and since each individual function 4−n cos(32nπx) is continuous,
the function f is also continuous. However, it is not diﬀerentiable (Ex-
ercise 4.7.10); in fact it is a nowhere diﬀerentiable function, one which
is not diﬀerentiable at any point, despite being continuous everywhere!

66
3.
Uniform convergence
— Exercises —
Exercise 3.7.1. Complete the proof of Theorem 3.7.1. Compare this theorem
with Example 1.2.10, and explain why this example does not contradict the
theorem.
Exercise 3.7.2. Prove Theorem 3.7.1 without assuming that f ′
n is continuous.
(This means that you cannot use the fundamental theorem of calculus. How-
ever, the mean value theorem (Corollary 10.2.9) is still available. Use this to
show that if d∞(f ′
n, f ′
m) ≤ε, then |(fn(x) −fm(x)) −(fn(x0) −fm(x0))| ≤
ε|x −x0| for all x ∈[a, b], and then use this to complete the proof of Theorem
3.7.1.)
Exercise 3.7.3. Prove Corollary 3.7.3.
3.8
Uniform approximation by polynomials
As we have just seen, continuous functions can be very badly behaved,
for instance they can be nowhere diﬀerentiable (Example 3.7.4).
On
the other hand, functions such as polynomials are always very well be-
haved, in particular being always diﬀerentiable. Fortunately, while most
continuous functions are not as well behaved as polynomials, they can
always be uniformly approximated by polynomials; this important (but
diﬃcult) result is known as the Weierstrass approximation theorem, and
is the subject of this section.
Deﬁnition 3.8.1. Let [a, b] be an interval. A polynomial on [a, b] is a
function f : [a, b] →R of the form f(x) := n
j=0 cjxj, where n ≥0 is
an integer and c0, . . . , cn are real numbers. If cn ̸= 0, then n is called
the degree of f.
Example 3.8.2. The function f : [1, 2] →R deﬁned by f(x) := 3x4 +
2x3 −4x + 5 is a polynomial on [1, 2] of degree 4.
Theorem 3.8.3 (Weierstrass approximation theorem). If [a, b] is an
interval, f : [a, b] →R is a continuous function, and ε > 0, then there
exists a polynomial P on [a, b] such that d∞(P, f) ≤ε (i.e., |P(x) −
f(x)| ≤ε for all x ∈[a, b]).
Another way of stating this theorem is as follows.
Recall that
C([a, b] →R) was the space of continuous functions from [a, b] to R,
with the uniform metric d∞.
Let P([a, b] →R) be the space of all
polynomials on [a, b]; this is a subspace of C([a, b] →R), since all poly-
nomials are continuous (Exercise 9.4.7). The Weierstrass approximation
theorem then asserts that every continuous function is an adherent point

3.8.
Uniform approximation by polynomials
67
of P([a, b] →R); or in other words, that the closure of the space of poly-
nomials is the space of continuous functions:
P([a, b] →R) = C([a, b] →R).
In particular, every continuous function on [a, b] is the uniform limit of
polynomials. Another way of saying this is that the space of polynomials
is dense in the space of continuous functions, in the uniform topology.
The proof of the Weierstrass approximation theorem is somewhat
complicated and will be done in stages. We ﬁrst need the notion of an
approximation to the identity.
Deﬁnition 3.8.4 (Compactly supported functions). Let [a, b] be an
interval.
A function f : R →R is said to be supported on [a, b] iﬀ
f(x) = 0 for all x ̸∈[a, b]. We say that f is compactly supported iﬀit is
supported on some interval [a, b]. If f is continuous and supported on
[a, b], we deﬁne the improper integral
 ∞
−∞f to be
 ∞
−∞f :=

[a,b] f.
Note that a function can be supported on more than one interval,
for instance a function which is supported on [3, 4] is also automati-
cally supported on [2, 5] (why?). In principle, this might mean that our
deﬁnition of
 ∞
−∞f is not well deﬁned, however this is not the case:
Lemma 3.8.5. If f : R →R is continuous and supported on an interval
[a, b], and is also supported on another interval [c, d], then

[a,b] f =

[c,d] f.
Proof. See Exercise 3.8.1.
Deﬁnition 3.8.6 (Approximation to the identity). Let ε > 0 and 0 <
δ < 1. A function f : R →R is said to be an (ε, δ)-approximation to
the identity if it obeys the following three properties:
(a) f is supported on [−1, 1], and f(x) ≥0 for all −1 ≤x ≤1.
(b) f is continuous, and
 ∞
−∞f = 1.
(c) |f(x)| ≤ε for all δ ≤|x| ≤1.
Remark 3.8.7. For those of you who are familiar with the Dirac delta
function, approximations to the identity are ways to approximate this
(very discontinuous) delta function by a continuous function (which is
easier to analyze). We will not however discuss the Dirac delta function
in this text.

68
3.
Uniform convergence
Our proof of the Weierstrass approximation theorem relies on three
key facts. The ﬁrst fact is that polynomials can be approximations to
the identity:
Lemma 3.8.8 (Polynomials can approximate the identity). For every
ε > 0 and 0 < δ < 1 there exists an (ε, δ)-approximation to the identity
which is a polynomial P on [−1, 1].
Proof. See Exercise 3.8.2.
We will use these polynomial approximations to the identity to ap-
proximate continuous functions by polynomials. We will need the fol-
lowing important notion of a convolution.
Deﬁnition 3.8.9 (Convolution). Let f : R →R and g : R →R be
continuous, compactly supported functions. We deﬁne the convolution
f ∗g : R →R of f and g to be the function
(f ∗g)(x) :=
 ∞
−∞
f(y)g(x −y) dy.
Note that if f and g are continuous and compactly supported, then
for each x the function f(y)g(x −y) (thought of as a function of y) is
also continuous and compactly supported, so the above deﬁnition makes
sense.
Remark 3.8.10. Convolutions play an important rˆole in Fourier anal-
ysis and in partial diﬀerential equations (PDE), and are also important
in physics, engineering, and signal processing.
An in-depth study of
convolution is beyond the scope of this text; only a brief treatment will
be given here.
Proposition 3.8.11 (Basic properties of convolution). Let f : R →
R, g : R →R, and h : R →R be continuous, compactly supported
functions. Then the following statements are true.
(a) The convolution f ∗g is also a continuous, compactly supported
function.
(b) (Convolution is commutative) We have f ∗g = g∗f; in other words
f ∗g(x) =
 ∞
−∞
f(y)g(x −y) dy
=
 ∞
−∞
g(y)f(x −y) dy
= g ∗f(x).

3.8.
Uniform approximation by polynomials
69
(c) (Convolution is linear) We have f ∗(g + h) = f ∗g + f ∗h. Also,
for any real number c, we have f ∗(cg) = (cf) ∗g = c(f ∗g).
Proof. See Exercise 3.8.4.
Remark 3.8.12. There are many other important properties of con-
volution, for instance it is associative, (f ∗g) ∗h = f ∗(g ∗h), and it
commutes with derivatives, (f ∗g)′ = f′ ∗g = f ∗g′, when f and g
are diﬀerentiable. The Dirac delta function δ mentioned earlier is an
identity for convolution: f ∗δ = δ ∗f = f. These results are slightly
harder to prove than the ones in Proposition 3.8.11, however, and we
will not need them in this text.
As mentioned earlier, the proof of the Weierstrass approximation
theorem relies on three facts. The second key fact is that convolution
with polynomials produces another polynomial:
Lemma 3.8.13. Let f : R →R be a continuous function supported on
[0, 1], and let g : R →R be a continuous function supported on [−1, 1]
which is a polynomial on [−1, 1]. Then f ∗g is a polynomial on [0, 1].
(Note however that it may be non-polynomial outside of [0, 1].)
Proof. Since g is polynomial on [−1, 1], we may ﬁnd an integer n ≥0
and real numbers c0, c1, . . . , cn such that
g(x) =
n

j=0
cjxj for all x ∈[−1, 1].
On the other hand, for all x ∈[0, 1], we have
f ∗g(x) =
 ∞
−∞
f(y)g(x −y) dy =

[0,1]
f(y)g(x −y) dy
since f is supported on [0, 1]. Since x ∈[0, 1] and the variable of integra-
tion y is also in [0, 1], we have x −y ∈[−1, 1]. Thus we may substitute
in our formula for g to obtain
f ∗g(x) =

[0,1]
f(y)
n

j=0
cj(x −y)j dy.
We expand this using the binomial formula (Exercise 7.1.4) to obtain
f ∗g(x) =

[0,1]
f(y)
n

j=0
cj
j

k=0
j!
k!(j −k)!xk(−y)j−k dy.

70
3.
Uniform convergence
We can interchange the two summations (by Corollary 7.1.14) to obtain
f ∗g(x) =

[0,1]
f(y)
n

k=0
n

j=k
cj
j!
k!(j −k)!xk(−y)j−k dy
(why did the limits of summation change? It may help to plot j and k
on a graph). Now we interchange the k summation with the integral,
and observe that xk is independent of y, to obtain
f ∗g(x) =
n

k=0
xk

[0,1]
f(y)
n

j=k
cj
j!
k!(j −k)!(−y)j−k dy.
If we thus deﬁne
Ck :=

[0,1]
f(y)
n

j=k
cj
j!
k!(j −k)!(−y)j−k dy
for each k = 0, . . . , n, then Ck is a number which is independent of x,
and we have
f ∗g(x) =
n

k=0
Ckxk
for all x ∈[0, 1]. Thus f ∗g is a polynomial on [0, 1].
The third key fact is that if one convolves a uniformly continuous
function with an approximation to the identity, we obtain a new function
which is close to the original function (which explains the terminology
“approximation to the identity”):
Lemma 3.8.14. Let f : R →R be a continuous function supported on
[0, 1], which is bounded by some M > 0 (i.e., |f(x)| ≤M for all x ∈R),
and let ε > 0 and 0 < δ < 1 be such that one has |f(x) −f(y)| < ε
whenever x, y ∈R and |x −y| < δ. Let g be any (ε, δ)-approximation to
the identity. Then we have
|f ∗g(x) −f(x)| ≤(1 + 4M)ε
for all x ∈[0, 1].
Proof. See Exercise 3.8.6.

3.8.
Uniform approximation by polynomials
71
Combining these together, we obtain a preliminary version of the
Weierstrass approximation theorem:
Corollary 3.8.15 (Weierstrass approximation theorem I). Let f : R →
R be a continuous function supported on [0, 1]. Then for every ε > 0,
there exists a function P : R →R which is polynomial on [0, 1] and such
that |P(x) −f(x)| ≤ε for all x ∈[0, 1].
Proof. See Exercise 3.8.7.
Now we perform a series of modiﬁcations to convert Corollary 3.8.15
into the actual Weierstrass approximation theorem.
We ﬁrst need a
simple lemma.
Lemma 3.8.16. Let f : [0, 1] →R be a continuous function which
equals 0 on the boundary of [0, 1], i.e., f(0) = f(1) = 0. Let F : R →
R be the function deﬁned by setting F(x) := f(x) for x ∈[0, 1] and
F(x) := 0 for x ̸∈[0, 1]. Then F is also continuous.
Proof. See Exercise 3.8.9.
Remark 3.8.17. The function F obtained in Lemma 3.8.16 is some-
times known as the extension of f by zero.
From Corollary 3.8.15 and Lemma 3.8.16 we immediately obtain
Corollary 3.8.18 (Weierstrass approximation theorem II). Let f :
[0, 1] →R be a continuous function supported on [0, 1] such that
f(0) = f(1) = 0.
Then for every ε > 0 there exists a polynomial
P : [0, 1] →R such that |P(x) −f(x)| ≤ε for all x ∈[0, 1].
Now we strengthen Corollary 3.8.18 by removing the assumption
that f(0) = f(1) = 0.
Corollary 3.8.19 (Weierstrass approximation theorem III). Let f :
[0, 1] →R be a continuous function supported on [0, 1]. Then for every
ε > 0 there exists a polynomial P : [0, 1] →R such that |P(x)−f(x)| ≤ε
for all x ∈[0, 1].
Proof. Let F : [0, 1] →R denote the function
F(x) := f(x) −f(0) −x(f(1) −f(0)).

72
3.
Uniform convergence
Observe that F is also continuous (why?), and that F(0) = F(1) = 0.
By Corollary 3.8.18, we can thus ﬁnd a polynomial Q : [0, 1] →R such
that |Q(x) −F(x)| ≤ε for all x ∈[0, 1]. But
Q(x) −F(x) = Q(x) + f(0) + x(f(1) −f(0)) −f(x),
so the claim follows by setting P to be the polynomial P(x) := Q(x) +
f(0) + x(f(1) −f(0)).
Finally, we can prove the full Weierstrass approximation theorem.
Proof of Theorem 3.8.3. Let f : [a, b] →R be a continuous function on
[a, b]. Let g : [0, 1] →R denote the function
g(x) := f(a + (b −a)x) for all x ∈[0, 1]
Observe then that
f(y) = g((y −a)/(b −a)) for all y ∈[a, b].
The function g is continuous on [0, 1] (why?), and so by Corollary 3.8.19
we may ﬁnd a polynomial Q : [0, 1] →R such that |Q(x) −g(x)| ≤ε for
all x ∈[0, 1]. In particular, for any y ∈[a, b], we have
|Q((y −a)/(b −a)) −g((y −a)/(b −a))| ≤ε.
If we thus set P(y) := Q((y −a)/(b−a)), then we observe that P is also
a polynomial (why?), and so we have |P(y) −f(y)| ≤ε for all y ∈[a, b],
as desired.
Remark 3.8.20. Note that the Weierstrass approximation theorem
only works on bounded intervals [a, b]; continuous functions on R cannot
be uniformly approximated by polynomials. For instance, the exponen-
tial function f : R →R deﬁned by f(x) := ex (which we shall study
rigorously in Section 4.5) cannot be approximated by any polynomial,
because exponential functions grow faster than any polynomial (Exer-
cise 4.5.9) and so there is no way one can even make the sup metric
between f and a polynomial ﬁnite.
Remark 3.8.21. There is a generalization of the Weierstrass approx-
imation theorem to higher dimensions: if K is any compact subset of
Rn (with the Euclidean metric dl2), and f : K →R is a continuous
function, then for every ε > 0 there exists a polynomial P : K →R

3.8.
Uniform approximation by polynomials
73
of n variables x1, . . . , xn such that d∞(f, P) < ε. This general theorem
can be proven by a more complicated variant of the arguments here,
but we will not do so. (There is in fact an even more general version
of this theorem applicable to an arbitrary metric space, known as the
Stone-Weierstrass theorem, but this is beyond the scope of this text.)
— Exercises —
Exercise 3.8.1. Prove Lemma 3.8.5.
Exercise 3.8.2.
(a) Prove that for any real number 0 ≤y ≤1 and any nat-
ural number n ≥0, that (1 −y)n ≥1 −ny. (Hint: induct on n. Alter-
natively, diﬀerentiate with respect to y.)
(b) Show that
 1
−1(1−x2)n dx ≥
1
√n. (Hint: for |x| ≤1/√n, use part (a); for
|x| ≥1/√n, just use the fact that (1 −x2) is positive. It is also possible
to proceed via trigonometric substitution, but I would not recommend
this unless you know what you are doing.)
(c) Prove Lemma 3.8.8. (Hint: choose f(x) to equal c(1−x2)N for x ∈[−1, 1]
and to equal zero for x ̸∈[−1, 1], where N is a large number N, where c
is chosen so that f has integral 1, and use (b).)
Exercise 3.8.3. Let f : R →R be a compactly supported, continuous function.
Show that f is bounded and uniformly continuous. (Hint: the idea is to use
Proposition 2.3.2 and Theorem 2.3.5, but one must ﬁrst deal with the issue
that the domain R of f is non-compact.)
Exercise 3.8.4. Prove Proposition 3.8.11. (Hint: to show that f∗g is continuous,
use Exercise 3.8.3.)
Exercise 3.8.5. Let f : R →R and g : R →R be continuous, compactly
supported functions. Suppose that f is supported on the interval [0, 1], and g
is constant on the interval [0, 2] (i.e., there is a real number c such that g(x) = c
for all x ∈[0, 2]). Show that the convolution f ∗g is constant on the interval
[1, 2].
Exercise 3.8.6.
(a) Let g be an (ε, δ) approximation to the identity. Show
that 1 −2ε ≤

[−δ,δ] g ≤1.
(b) Prove Lemma 3.8.14. (Hint: begin with the identity
f ∗g(x) =

f(x −y)g(y) dy =

[−δ,δ]
f(x −y)g(y) dy
+

[δ,1]
f(x −y)g(y) dy +

[−1,−δ]
f(x −y)g(y) dy.
The idea is to show that the ﬁrst integral is close to f(x), and that the
second and third integrals are very small. To achieve the former task,

74
3.
Uniform convergence
use (a) and the fact that f(x) and f(x −y) are within ε of each other;
to achieve the latter task, use property (c) of the approximation to the
identity and the fact that f is bounded.)
Exercise 3.8.7. Prove Corollary 3.8.15. (Hint: combine Exercise 3.8.3, Lemma
3.8.8, Lemma 3.8.13, and Lemma 3.8.14.)
Exercise 3.8.8. Let f : [0, 1] →R be a continuous function, and suppose that

[0,1] f(x)xn dx = 0 for all non-negative integers n = 0, 1, 2, . . .. Show that f
must be the zero function f ≡0. (Hint: ﬁrst show that

[0,1] f(x)P(x) dx = 0
for all polynomials P. Then, using the Weierstrass approximation theorem,
show that

[0,1] f(x)f(x) dx = 0.)
Exercise 3.8.9. Prove Lemma 3.8.16.

Chapter 4
Power series
4.1
Formal power series
We now discuss an important subclass of series of functions, that of
power series. As in earlier chapters, we begin by introducing the notion
of a formal power series, and then focus in later sections on when the
series converges to a meaningful function, and what one can say about
the function obtained in this manner.
Deﬁnition 4.1.1 (Formal power series). Let a be a real number. A
formal power series centered at a is any series of the form
∞

n=0
cn(x −a)n
where c0, c1, . . . is a sequence of real numbers (not depending on x); we
refer to cn as the nth coeﬃcient of this series.
Note that each term
cn(x −a)n in this series is a function of a real variable x.
Example 4.1.2. The series ∞
n=0 n!(x −2)n is a formal power series
centered at 2. The series ∞
n=0 2x(x −3)n is not a formal power series,
since the coeﬃcients 2x depend on x.
We call these power series formal because we do not yet assume that
these series converge for any x. However, these series are automatically
guaranteed to converge when x = a (why?). In general, the closer x
gets to a, the easier it is for this series to converge. To make this more
precise, we need the following deﬁnition.
Deﬁnition 4.1.3 (Radius of convergence). Let ∞
n=0 cn(x −a)n be a
formal power series. We deﬁne the radius of convergence R of this series
75
© Springer Science+Business Media Singapore 2016 and Hindustan Book Agency 2015
T. Tao, Analysis II, Texts and Readings in Mathematics 38,
DOI 10.1007/978-981-10-1804-6_4

76
4.
Power series
to be the quantity
R :=
1
lim supn→∞|cn|1/n
where we adopt the convention that 1
0 = +∞and
1
+∞= 0.
Remark 4.1.4. Each number |cn|1/n is non-negative, so the limit
lim supn→∞|cn|1/n can take on any value from 0 to +∞, inclusive. Thus
R can also take on any value between 0 and +∞inclusive (in particular
it is not necessarily a real number). Note that the radius of convergence
always exists, even if the sequence |cn|1/n is not convergent, because the
lim sup of any sequence always exists (though it might be +∞or −∞).
Example 4.1.5. The series ∞
n=0 n(−2)n(x −3)n has radius of conver-
gence
1
lim supn→∞|n(−2n)|1/n =
1
lim supn→∞2n1/n = 1
2.
The series ∞
n=0 2n2(x + 2)n has radius of convergence
1
lim supn→∞|2n2|1/n =
1
lim supn→∞2n =
1
+∞= 0.
The series ∞
n=0 2−n2(x + 2)n has radius of convergence
1
lim supn→∞|2−n2|1/n =
1
lim supn→∞2−n = 1
0 = +∞.
The signiﬁcance of the radius of convergence is the following.
Theorem 4.1.6. Let ∞
n=0 cn(x−a)n be a formal power series, and let
R be its radius of convergence.
(a) (Divergence outside of the radius of convergence) If x ∈R is such
that |x −a| > R, then the series ∞
n=0 cn(x −a)n is divergent for
that value of x.
(b) (Convergence inside the radius of convergence) If x ∈R is such
that |x −a| < R, then the series ∞
n=0 cn(x −a)n is absolutely
convergent for that value of x.
For parts (c)-(e) we assume that R > 0 (i.e., the series converges at
at least one other point than x = a). Let f : (a −R, a + R) →R be the

4.1.
Formal power series
77
function f(x) := ∞
n=0 cn(x −a)n; this function is guaranteed to exist
by (b).
(c) (Uniform convergence on compact sets) For any 0 < r < R, the
series ∞
n=0 cn(x −a)n converges uniformly to f on the compact
interval [a−r, a+r]. In particular, f is continuous on (a−R, a+R).
(d) (Diﬀerentiation of power series) The function f is diﬀerentiable
on (a−R, a+R), and for any 0 < r < R, the series ∞
n=1 ncn(x−
a)n−1 converges uniformly to f′ on the interval [a −r, a + r].
(e) (Integration of power series) For any closed interval [y, z] con-
tained in (a −R, a + R), we have

[y,z]
f =
∞

n=0
cn
(z −a)n+1 −(y −a)n+1
n + 1
.
Proof. See Exercise 4.1.1.
Theorem 4.1.6 (a) and (b) of the above theorem give another way to
ﬁnd the radius of convergence, by using your favorite convergence test
to work out the range of x for which the power series converges:
Example 4.1.7. Consider the power series ∞
n=0 n(x −1)n. The ratio
test shows that this series converges when |x −1| < 1 and diverges
when |x −1| > 1 (why?). Thus the only possible value for the radius
of convergence is R = 1 (if R < 1, then we have contradicted Theorem
4.1.6(a); if R > 1, then we have contradicted Theorem 4.1.6(b)).
Remark 4.1.8. Theorem 4.1.6 is silent on what happens when |x−a| =
R, i.e., at the points a −R and a + R. Indeed, one can have either
convergence or divergence at those points; see Exercise 4.1.2.
Remark 4.1.9. Note that while Theorem 4.1.6 assures us that the
power series ∞
n=0 cn(x −a)n will converge pointwise on the interval
(a −R, a + R), it need not converge uniformly on that interval (see
Exercise 4.1.2(e)). On the other hand, Theorem 4.1.6(c) assures us that
the power series will converge on any smaller interval [a −r, a + r]. In
particular, being uniformly convergent on every closed subinterval of
(a −R, a + R) is not enough to guarantee being uniformly convergent
on all of (a −R, a + R).

78
4.
Power series
— Exercises —
Exercise 4.1.1. Prove Theorem 4.1.6. (Hints: for (a) and (b), use the root test
(Theorem 7.5.1). For (c), use the Weierstrass M-test (Theorem 3.5.7). For (d),
use Theorem 3.7.1. For (e), use Corollary 3.6.2.
Exercise 4.1.2. Give examples of a formal power series ∞
n=0 cnxn centered at
0 with radius of convergence 1, which
(a) diverges at both x = 1 and x = −1;
(b) diverges at x = 1 but converges at x = −1;
(c) converges at x = 1 but diverges at x = −1;
(d) converges at both x = 1 and x = −1.
(e) converges pointwise on (−1, 1), but does not converge uniformly on
(−1, 1).
4.2
Real analytic functions
A function f(x) which is lucky enough to be representable as a power
series has a special name; it is a real analytic function.
Deﬁnition 4.2.1 (Real analytic functions). Let E be a subset of R,
and let f : E →R be a function. If a is an interior point of E, we say
that f is real analytic at a if there exists an open interval (a−r, a+r) in
E for some r > 0 such that there exists a power series ∞
n=0 cn(x −a)n
centered at a which has a radius of convergence greater than or equal to
r, and which converges to f on (a −r, a + r). If E is an open set, and
f is real analytic at every point a of E, we say that f is real analytic
on E.
Example 4.2.2. Consider the function f : R\{1} →R deﬁned by
f(x) := 1/(1 −x). This function is real analytic at 0 because we have
a power series ∞
n=0 xn centred at 0 which converges to 1/(1 −x) =
f(x) on the interval (−1, 1).
This function is also real analytic at 2
because we have a power series ∞
n=0(−1)n+1(x−2)n which converges to
−1
1−(−(x−2)) =
1
1−x = f(x) on the interval (1, 3) (why? use Lemma 7.3.3).
In fact this function is real analytic on all of R\{1}; see Exercise 4.2.2.
Remark 4.2.3. The notion of being real analytic is closely related to
another notion, that of being complex analytic, but this is a topic for
complex analysis, and will not be discussed here.

4.2.
Real analytic functions
79
We now discuss which functions are real analytic. From Theorem
4.1.6(c) and (d) we see that if f is real analytic at a point a, then f is
both continuous and diﬀerentiable on (a −r, a + r) for some r > 0. We
can in fact say more:
Deﬁnition 4.2.4 (k-times diﬀerentiability). Let E be a subset of R. We
say a function f : E →R is once diﬀerentiable on E iﬀit is diﬀerentiable.
More generally, for any k ≥2 we say that f : E →R is k times
diﬀerentiable on E, or just k times diﬀerentiable, iﬀf is diﬀerentiable,
and f′ is k −1 times diﬀerentiable. If f is k times diﬀerentiable, we
deﬁne the kth derivative f(k) : E →R by the recursive rule f(1) := f′,
and f(k) = (f(k−1))′ for all k ≥2. We also deﬁne f(0) := f (this is
f diﬀerentiated 0 times), and we allow every function to be zero times
diﬀerentiable (since clearly f(0) exists for every f). A function is said to
be inﬁnitely diﬀerentiable (or smooth) iﬀit is k times diﬀerentiable for
every k ≥0.
Example 4.2.5. The function f(x) := |x|3 is twice diﬀerentiable on
R, but not three times diﬀerentiable (why?). Indeed, f(2) = f′′ = 6|x|,
which is not diﬀerentiable, at 0.
Proposition 4.2.6 (Real analytic functions are k-times diﬀerentiable).
Let E be a subset of R, let a be an interior point of E, and and let f be
a function which is real analytic at a, thus there is an r > 0 for which
we have the power series expansion
f(x) =
∞

n=0
cn(x −a)n
for all x ∈(a−r, a+r). Then for every k ≥0, the function f is k-times
diﬀerentiable on (a −r, a + r), and for each k ≥0 the kth derivative is
given by
f(k)(x) =
∞

n=0
cn+k(n + 1)(n + 2) . . . (n + k)(x −a)n
=
∞

n=0
cn+k
(n + k)!
n!
(x −a)n
for all x ∈(a −r, a + r).
Proof. See Exercise 4.2.3.

80
4.
Power series
Corollary 4.2.7 (Real analytic functions are inﬁnitely diﬀerentiable).
Let E be an open subset of R, and let f : E →R be a real analytic func-
tion on E. Then f is inﬁnitely diﬀerentiable on E. Also, all derivatives
of f are also real analytic on E.
Proof. For every point a ∈E and k ≥0, we know from Proposition
4.2.6 that f is k-times diﬀerentiable at a (we will have to apply Exercise
10.1.1 k times here, why?). Thus f is k-times diﬀerentiable on E for
every k ≥0 and is hence inﬁnitely diﬀerentiable. Also, from Proposition
4.2.6 we see that each derivative f(k) of f has a convergent power series
expansion at every x ∈E and thus f(k) is real analytic.
Example 4.2.8. Consider the function f : R →R deﬁned by f(x) :=
|x|. This function is not diﬀerentiable at x = 0, and hence cannot be
real analytic at x = 0. It is however real analytic at every other point
x ∈R\{0} (why?).
Remark 4.2.9. The converse statement to Corollary 4.2.7 is not true;
there are inﬁnitely diﬀerentiable functions which are not real analytic.
See Exercise 4.5.4.
Proposition 4.2.6 has an important corollary, due to Brook Taylor
(1685–1731).
Corollary 4.2.10 (Taylor’s formula). Let E be a subset of R, let a be
an interior point of E, and let f : E →R be a function which is real
analytic at a and has the power series expansion
f(x) =
∞

n=0
cn(x −a)n
for all x ∈(a −r, a + r) and some r > 0. Then for any integer k ≥0,
we have
f(k)(a) = k!ck,
where k! := 1 × 2 × . . . × k (and we adopt the convention that 0! = 1).
In particular, we have Taylor’s formula
f(x) =
∞

n=0
f(n)(a)
n!
(x −a)n
for all x in (a −r, a + r).

4.2.
Real analytic functions
81
Proof. See Exercise 4.2.4.
The power series ∞
n=0
f(n)(a)
n!
(x−a)n is sometimes called the Taylor
series of f around a. Taylor’s formula thus asserts that if a function is
real analytic, then it is equal to its Taylor series.
Remark 4.2.11. Note that Taylor’s formula only works for functions
which are real analytic; there are examples of functions which are in-
ﬁnitely diﬀerentiable but for which Taylor’s theorem fails (see Exercise
4.5.4).
Another important corollary of Taylor’s formula is that a real ana-
lytic function can have at most one power series at a point:
Corollary 4.2.12 (Uniqueness of power series). Let E be a subset of R,
let a be an interior point of E, and let f : E →R be a function which
is real analytic at a. Suppose that f has two power series expansions
f(x) =
∞

n=0
cn(x −a)n
and
f(x) =
∞

n=0
dn(x −a)n
centered at a, ecah with a non-zero radius of convergence. Then cn = dn
for all n ≥0.
Proof. By Corollary 4.2.10, we have f(k)(a) = k!ck for all k ≥0. But
we also have f(k)(a) = k!dk, by similar reasoning. Since k! is never zero,
we can cancel it and obtain ck = dk for all k ≥0, as desired.
Remark 4.2.13. While a real analytic function has a unique power
series around any given point, it can certainly have diﬀerent power series
at diﬀerent points. For instance, the function f(x) :=
1
1−x, deﬁned on
R −{1}, has the power series
f(x) :=
∞

n=0
xn
around 0, on the interval (−1, 1), but also has the power series
f(x)
=
1
1 −x =
2
1 −2(x −1
2)
=
∞

n=0
2

2

x −1
2
n
=
∞

n=0
2n+1

x −1
2
n

82
4.
Power series
around 1/2, on the interval (0, 1) (note that the above power series has
a radius of convergence of 1/2, thanks to the root test. See also Exercise
4.2.8.
— Exercises —
Exercise 4.2.1. Let n ≥0 be an integer, let c, a be real numbers, and let f be
the function f(x) := c(x −a)n. Show that f is inﬁnitely diﬀerentiable, and
that f (k)(x) = c
n!
(n−k)!(x −a)n−k for all integers 0 ≤k ≤n. What happens
when k > n?
Exercise 4.2.2. Show that the function f deﬁned in Example 4.2.2 is real ana-
lytic on all of R\{1}.
Exercise 4.2.3. Prove Proposition 4.2.6. (Hint: induct on k and use Theorem
4.1.6(d)).
Exercise 4.2.4. Use Proposition 4.2.6 and Exercise 4.2.1 to prove Corollary
4.2.10.
Exercise 4.2.5. Let a, b be real numbers, and let n ≥0 be an integer. Prove
the identity
(x −a)n =
n

m=0
n!
m!(n −m)!(b −a)n−m(x −b)m
for any real number x. (Hint: use the binomial formula, Exercise 7.1.4.) Ex-
plain why this identity is consistent with Taylor’s theorem and Exercise 4.2.1.
(Note however that Taylor’s theorem cannot be rigorously applied until one
veriﬁes Exercise 4.2.6 below.)
Exercise 4.2.6. Using Exercise 4.2.5, show that every polynomial P(x) of one
variable is real analytic on R.
Exercise 4.2.7. Let m ≥0 be a positive integer, and let 0 < x < r be real
numbers. Use Lemma 7.3.3 to establish the identity
r
r −x =
∞

n=0
xnr−n
for all x ∈(−r, r). Using Proposition 4.2.6, conclude the identity
r
(r −x)m+1 =
∞

n=m
n!
m!(n −m)!xn−mr−n
for all integers m ≥0 and x ∈(−r, r). Also explain why the series on the
right-hand side is absolutely convergent.

4.3.
Abel’s theorem
83
Exercise 4.2.8. Let E be a subset of R, let a be an interior point of E, and let
f : E →R be a function which is real analytic in a, and has a power series
expansion
f(x) =
∞

n=0
cn(x −a)n
at a which converges on the interval (a −r, a + r). Let (b −s, b + s) be any
sub-interval of (a −r, a + r) for some s > 0.
(a) Prove that |a −b| ≤r −s, so in particular |a −b| < r.
(b) Show that for every 0 < ε < r, there exists a C > 0 such that |cn| ≤
C(r −ε)−n for all integers n ≥0. (Hint: what do we know about the
radius of convergence of the series ∞
n=0 cn(x −a)n?)
(c) Show that the numbers d0, d1, . . . given by the formula
dm :=
∞

n=m
n!
m!(n −m)!(b −a)n−mcn for all integers m ≥0
are well-deﬁned, in the sense that the above series is absolutely conver-
gent. (Hint: use (b) and the comparison test, Corollary 7.3.2, followed
by Exercise 4.2.7.)
(d) Show that for every 0 < ε < s there exists a C > 0 such that
|dm| ≤C(s −ε)−m
for all integers m ≥0. (Hint: use the comparison test, and Exercise
4.2.7.)
(e) Show that the power series ∞
m=0 dm(x −b)m is absolutely convergent
for x ∈(b −s, b + s) and converges to f(x). (You may need Fubini’s
theorem for inﬁnite series, Theorem 8.2.2, as well as Exercise 4.2.5).
(f) Conclude that f is real analytic at every point in (a −r, a + r).
4.3
Abel’s theorem
Let f(x) = ∞
n=0 cn(x−a)n be a power series centered at a with a radius
of convergence 0 < R < ∞strictly between 0 and inﬁnity. From Theo-
rem 4.1.6 we know that the power series converges absolutely whenever
|x −a| < R, and diverges when |x −a| > R. However, at the boundary
|x−a| = R the situation is more complicated; the series may either con-
verge or diverge (see Exercise 4.1.2). However, if the series does converge
at the boundary point, then it is reasonably well behaved; in particular,
it is continuous at that boundary point.

84
4.
Power series
Theorem 4.3.1 (Abel’s theorem). Let f(x) = ∞
n=0 cn(x −a)n be a
power series centered at a with radius of convergence 0 < R < ∞. If the
power series converges at a + R, then f is continuous at a + R, i.e.
lim
x→a+R:x∈(a−R,a+R)
∞

n=0
cn(x −a)n =
∞

n=0
cnRn.
Similarly, if the power series converges at a −R, then f is continuous
at a −R, i.e.
lim
x→a−R:x∈(a−R,a+R)
∞

n=0
cn(x −a)n =
∞

n=0
cn(−R)n.
Before we prove Abel’s theorem, we need the following lemma.
Lemma 4.3.2 (Summation by parts formula). Let (an)∞
n=0 and (bn)∞
n=0
be sequences of real numbers which converge to limits A and B respec-
tively, i.e., limn→∞an = A and limn→∞bn = B. Suppose that the sum
∞
n=0(an+1 −an)bn is convergent. Then the sum ∞
n=0 an+1(bn+1 −bn)
is also convergent, and
∞

n=0
(an+1 −an)bn = AB −a0b0 −
∞

n=0
an+1(bn+1 −bn).
Proof. See Exercise 4.3.1.
Remark 4.3.3. One should compare this formula with the more well-
known integration by parts formula
 ∞
0
f′(x)g(x) dx = f(x)g(x)|∞
0 −
 ∞
0
f(x)g′(x) dx,
see Proposition 11.10.1.
Proof of Abel’s theorem. It will suﬃce to prove the ﬁrst claim, i.e., that
lim
x→a+R:x∈(a−R,a+R)
∞

n=0
cn(x −a)n =
∞

n=0
cnRn
whenever the sum ∞
n=0 cnRn converges; the second claim will then
follow (why?) by replacing cn by (−1)ncn in the above claim. If we

4.3.
Abel’s theorem
85
make the substitutions dn := cnRn and y := x−a
R , then the above claim
can be rewritten as
lim
y→1:y∈(−1,1)
∞

n=0
dnyn =
∞

n=0
dn
whenever the sum ∞
n=0 dn converges. (Why is this equivalent to the
previous claim?)
Write D := ∞
n=0 dn, and for every N ≥0 write
SN :=
N−1

n=0
dn

−D
so in particular S0 = −D. Then observe that limN→∞SN = 0, and that
dn = Sn+1 −Sn. Thus for any y ∈(−1, 1) we have
∞

n=0
dnyn =
∞

n=0
(Sn+1 −Sn)yn.
Applying the summation by parts formula (Lemma 4.3.2), and noting
that limn→∞yn = 0, we obtain
∞

n=0
dnyn = −S0y0 −
∞

n=0
Sn+1(yn+1 −yn).
Observe that −S0y0 = +D. Thus to ﬁnish the proof of Abel’s theorem,
it will suﬃce to show that
lim
y→1:y∈(−1,1)
∞

n=0
Sn+1(yn+1 −yn) = 0.
Since y converges to 1, we may as well restrict y to [0, 1) instead of
(−1, 1); in particular we may take y to be positive.
From the triangle inequality for series (Proposition 7.2.9), we have

∞

n=0
Sn+1(yn+1 −yn)
 ≤
∞

n=0
|Sn+1(yn+1 −yn)|
=
∞

n=0
|Sn+1|(yn −yn+1),

86
4.
Power series
so by the squeeze test (Corollary 6.4.14) it suﬃces to show that
lim
y→1:y∈[0,1)
∞

n=0
|Sn+1|(yn −yn+1) = 0.
The expression ∞
n=0 |Sn+1|(yn −yn+1) is clearly non-negative, so it will
suﬃce to show that
lim
sup
y→1:y∈[0,1)
∞

n=0
|Sn+1|(yn −yn+1) = 0.
Let ε > 0. Since Sn converges to 0, there exists an N such that |Sn| ≤ε
for all n > N. Thus we have
∞

n=0
|Sn+1|(yn −yn+1) ≤
N

n=0
|Sn+1|(yn −yn+1) +
∞

n=N+1
ε(yn −yn+1).
The last summation is a telescoping series, which sums to εyN+1 (See
Lemma 7.2.15, recalling from Lemma 6.5.2 that yn →0 as n →∞), and
thus
∞

n=0
|Sn+1|(yn −yn+1) ≤
N

n=0
|Sn+1|(yn −yn+1) + εyN+1.
Now take limits as y →1. Observe that yn −yn+1 →0 as y →1 for
every n ∈0, 1, . . . , N. Since we can interchange limits and ﬁnite sums
(Exercise 7.1.5), we thus have
lim sup
n→∞
∞

n=0
|Sn+1|(yn −yn+1) ≤ε.
But ε > 0 was arbitrary, and thus we must have
lim sup
n→∞
∞

n=0
|Sn+1|(yn −yn+1) = 0
since the left-hand side must be non-negative. The claim follows.
— Exercises —
Exercise 4.3.1. Prove Lemma 4.3.2.
(Hint: ﬁrst work out the relationship
between the partial sums N
n=0(an+1 −an)bn and N
n=0 an+1(bn+1 −bn).)

4.4.
Multiplication of power series
87
4.4
Multiplication of power series
We now show that the product of two real analytic functions is again
real analytic.
Theorem 4.4.1. Let f : (a −r, a + r) →R and g : (a −r, a + r) →R
be functions analytic on (a −r, a + r), with power series expansions
f(x) =
∞

n=0
cn(x −a)n
and
g(x) =
∞

n=0
dn(x −a)n
respectively. Then fg : (a−r, a+r) →R is also analytic on (a−r, a+r),
with power series expansion
f(x)g(x) =
∞

n=0
en(x −a)n
where en := n
m=0 cmdn−m.
Remark 4.4.2. The sequence (en)∞
n=0 is sometimes referred to as the
convolution of the sequences (cn)∞
n=0 and (dn)∞
n=0; it is closely related
(though not identical) to the notion of convolution introduced in Deﬁ-
nition 3.8.9.
Proof. We have to show that the series ∞
n=0 en(x −a)n converges to
f(x)g(x) for all x ∈(a−r, a+r). Now ﬁx x to be any point in (a−r, a+r).
By Theorem 4.1.6, we see that both f and g have radii of convergence at
least r. In particular, the series ∞
n=0 cn(x −a)n and ∞
n=0 dn(x −a)n
are absolutely convergent. Thus if we deﬁne
C :=
∞

n=0
|cn(x −a)n|
and
D :=
∞

n=0
|dn(x −a)n|
then C and D are both ﬁnite.

88
4.
Power series
For any N ≥0, consider the partial sum
N

n=0
∞

m=0
|cm(x −a)mdn(x −a)n|.
We can rewrite this as
N

n=0
|dn(x −a)n|
∞

m=0
|cm(x −a)m|,
which by deﬁnition of C is equal to
N

n=0
|dn(x −a)n|C,
which by deﬁnition of D is less than or equal to DC. Thus the above
partial sums are bounded by DC for every N. In particular, the series
∞

n=0
∞

m=0
|cm(x −a)mdn(x −a)n|
is convergent, which means that the sum
∞

n=0
∞

m=0
cm(x −a)mdn(x −a)n
is absolutely convergent.
Let us now compute this sum in two ways. First of all, we can pull
the dn(x −a)n factor out of the ∞
m=0 summation, to obtain
∞

n=0
dn(x −a)n
∞

m=0
cm(x −a)m.
By our formula for f(x), this is equal to
∞

n=0
dn(x −a)nf(x);
by our formula for g(x), this is equal to f(x)g(x). Thus
f(x)g(x) =
∞

n=0
∞

m=0
cm(x −a)mdn(x −a)n.

4.4.
Multiplication of power series
89
Now we compute this sum in a diﬀerent way. We rewrite it as
f(x)g(x) =
∞

n=0
∞

m=0
cmdn(x −a)n+m.
By Fubini’s theorem for series (Theorem 8.2.2), because the series was
absolutely convergent, we may rewrite it as
f(x)g(x) =
∞

m=0
∞

n=0
cmdn(x −a)n+m.
Now make the substitution n′ := n + m, to rewrite this as
f(x)g(x) =
∞

m=0
∞

n′=m
cmdn′−m(x −a)n′.
If we adopt the convention that dj = 0 for all negative j, then this is
equal to
f(x)g(x) =
∞

m=0
∞

n′=0
cmdn′−m(x −a)n′.
Applying Fubini’s theorem again, we obtain
f(x)g(x) =
∞

n′=0
∞

m=0
cmdn′−m(x −a)n′,
which we can rewrite as
f(x)g(x) =
∞

n′=0
(x −a)n′
∞

m=0
cmdn′−m.
Since dj was 0 when j is negative, we can rewrite this as
f(x)g(x) =
∞

n′=0
(x −a)n′
n′

m=0
cmdn′−m,
which by deﬁnition of e is
f(x)g(x) =
∞

n′=0
en′(x −a)n′,
as desired.

90
4.
Power series
4.5
The exponential and logarithm functions
We can now use the machinery developed in the last few sections to de-
velop a rigorous foundation for many standard functions used in math-
ematics. We begin with the exponential function.
Deﬁnition 4.5.1 (Exponential function). For every real number x, we
deﬁne the exponential function exp(x) to be the real number
exp(x) :=
∞

n=0
xn
n! .
Theorem 4.5.2 (Basic properties of exponential).
(a) For every real number x, the series ∞
n=0
xn
n! is absolutely conver-
gent. In particular, exp(x) exists and is real for every x ∈R, the
power series ∞
n=0
xn
n! has an inﬁnite radius of convergence, and
exp is a real analytic function on (−∞, ∞).
(b) exp is diﬀerentiable on R, and for every x ∈R, exp′(x) = exp(x).
(c) exp is continuous on R, and for every interval [a, b], we have

[a,b] exp(x) dx = exp(b) −exp(a).
(d) For every x, y ∈R, we have exp(x + y) = exp(x) exp(y).
(e) We have exp(0) = 1. Also, for every x ∈R, exp(x) is positive,
and exp(−x) = 1/ exp(x).
(f ) exp is strictly monotone increasing: in other words, if x, y are real
numbers, then we have exp(y) > exp(x) if and only if y > x.
Proof. See Exercise 4.5.1.
One can write the exponential function in a more compact form,
introducing famous Euler’s number e = 2.71828183 . . ., also known as
the base of the natural logarithm:
Deﬁnition 4.5.3 (Euler’s number). The number e is deﬁned to be
e := exp(1) =
∞

n=0
1
n! = 1
0! + 1
1! + 1
2! + 1
3! + . . . .

4.5.
The exponential and logarithm functions
91
Proposition 4.5.4. For every real number x, we have exp(x) = ex.
Proof. See Exercise 4.5.3.
In light of this proposition we can and will use ex and exp(x) inter-
changeably.
Since e > 1 (why?), we see that ex →+∞as x →+∞, and ex →0
as x →−∞. From this and the intermediate value theorem (Theorem
9.7.1) we see that the range of the function exp is (0, ∞). Since exp is
increasing, it is injective, and hence exp is a bijection from R to (0, ∞),
and thus has an inverse from (0, ∞) →R. This inverse has a name:
Deﬁnition 4.5.5 (Logarithm). We deﬁne the natural logarithm function
log : (0, ∞) →R (also called ln) to be the inverse of the exponential
function. Thus exp(log(x)) = x and log(exp(x)) = x.
Since exp is continuous and strictly monotone increasing, we see that
log is also continuous and strictly monotone increasing (see Proposition
9.8.3). Since exp is also diﬀerentiable, and the derivative is never zero,
we see from the inverse function theorem (Theorem 10.4.2) that log is
also diﬀerentiable. We list some other properties of the natural logarithm
below.
Theorem 4.5.6 (Logarithm properties).
(a) For every x ∈(0, ∞), we have ln′(x) = 1
x. In particular, by the
fundamental theorem of calculus, we have

[a,b]
1
x dx = ln(b)−ln(a)
for any interval [a, b] in (0, ∞).
(b) We have ln(xy) = ln(x) + ln(y) for all x, y ∈(0, ∞).
(c) We have ln(1) = 0 and ln(1/x) = −ln(x) for all x ∈(0, ∞).
(d) For any x ∈(0, ∞) and y ∈R, we have ln(xy) = y ln(x).
(e) For any x ∈(−1, 1), we have
ln(1 −x) = −
∞

n=1
xn
n .
In particular, ln is analytic at 1, with the power series expansion
ln(x) =
∞

n=1
(−1)n+1
n
(x −1)n
for x ∈(0, 2), with radius of convergence 1.

92
4.
Power series
Proof. See Exercise 4.5.5.
Example 4.5.7. We now give a modest application of Abel’s the-
orem (Theorem 4.3.1):
from the alternating series test we see that
∞
n=1
(−1)n+1
n
is convergent. By Abel’s theorem we thus see that
∞

n=1
(−1)n+1
n
= lim
x→2
∞

n=1
(−1)n+1
n
(x −1)n
= lim
x→2 ln(x) = ln(2),
thus we have the formula
ln(2) = 1 −1
2 + 1
3 −1
4 + 1
5 −. . . .
— Exercises —
Exercise 4.5.1. Prove Theorem 4.5.2. (Hints: for part (a), use the ratio test.
For parts (bc), use Theorem 4.1.6. For part (d), use Theorem 4.4.1. For part
(e), use part (d). For part (f), use part (d), and prove that exp(x) > 1 when x
is positive. You may ﬁnd the binomial formula from Exercise 7.1.4 to be useful.
Exercise 4.5.2. Show that for every integer n ≥3, we have
0 <
1
(n + 1)! +
1
(n + 2)! + . . . < 1
n!.
(Hint: ﬁrst show that (n + k)! > 2kn! for all k = 1, 2, 3, . . ..) Conclude that n!e
is not an integer for every n ≥3. Deduce from this that e is irrational. (Hint:
prove by contradiction.)
Exercise 4.5.3. Prove Proposition 4.5.4. (Hint: ﬁrst prove the claim when x
is a natural number. Then prove it when x is an integer. Then prove it when
x is a rational number. Then use the fact that real numbers are the limits of
rational numbers to prove it for all real numbers. You may ﬁnd the exponent
laws (Proposition 6.7.3) to be useful.)
Exercise 4.5.4. Let f : R →R be the function deﬁned by setting f(x) :=
exp(−1/x) when x > 0, and f(x) := 0 when x ≤0. Prove that f is inﬁnitely
diﬀerentiable, and f (k)(0) = 0 for every integer k ≥0, but that f is not real
analytic at 0.
Exercise 4.5.5. Prove Theorem 4.5.6.
(Hints: for part (a), use the inverse
function theorem (Theorem 10.4.2) or the chain rule (Theorem 10.1.15). For
parts (bcd), use Theorem 4.5.2 and the exponent laws (Proposition 6.7.3). For
part (e), start with the geometric series formula (Lemma 7.3.3) and integrate
using Theorem 4.1.6).

4.6.
A digression on complex numbers
93
Exercise 4.5.6. Prove that the natural logarithm function is real analytic on
(0, +∞).
Exercise 4.5.7. Let f : R →(0, ∞) be a positive, real analytic function such
that f ′(x) = f(x) for all x ∈R. Show that f(x) = Cex for some positive
constant C; justify your reasoning. (Hint: there are basically three diﬀerent
proofs available. One proof uses the logarithm function, another proof uses the
function e−x, and a third proof uses power series. Of course, you only need to
supply one proof.)
Exercise 4.5.8. Let m > 0 be an integer. Show that
lim
x→+∞
ex
xm = +∞.
(Hint: what happens to the ratio between ex+1/(x + 1)m and ex/xm as x →
+∞?)
Exercise 4.5.9. Let P(x) be a polynomial, and let c > 0. Show that there
exists a real number N > 0 such that ecx > |P(x)| for all x > N; thus an
exponentially growing function, no matter how small the growth rate c, will
eventually overtake any given polynomial P(x), no matter how large. (Hint:
use Exercise 4.5.8.)
Exercise 4.5.10. Let f : (0, +∞) × R →R be the exponential function
f(x, y) := xy.
Show that f is continuous.
(Hint: note that Propositions
9.4.10, 9.4.11 only show that f is continuous in each variable, which is in-
suﬃcient, as Exercise 2.2.11 shows.
The easiest way to proceed is to write
f(x, y) = exp(y ln x) and use the continuity of exp() and ln(). For an extra
challenge, try proving this exercise without using the logarithm function.)
4.6
A digression on complex numbers
To proceed further we need the complex number system C, which is an
extension of the real number system R. A full discussion of this im-
portant number system (and in particular the branch of mathematics
known as complex analysis) is beyond the scope of this text; here, we
need the system primarily because of a very useful mathematical oper-
ation, the complex exponential function z →exp(z), which generalizes
the real exponential function x →exp(x) introduced in the previous
section.
Informally, we could deﬁne the complex numbers as
Deﬁnition 4.6.1 (Informal deﬁnition of complex numbers). The com-
plex numbers C are the set of all numbers of the form a + bi, where a, b
are real numbers and i is a square root of −1, i2 = −1.

94
4.
Power series
However, this deﬁnition is a little unsatisfactory as it does not explain
how to add, multiply, or compare two complex numbers. To construct
the complex numbers rigorously we will ﬁrst introduce a formal version
of the complex number a+bi, which we shall temporarily denote as (a, b);
this is similar to how in Chapter 4, when constructing the integers Z,
we needed a formal notion of subtraction a−−b before the actual notion
of subtraction a −b could be introduced, or how when constructing the
rational numbers, a formal notion of division a//b was needed before it
was superceded by the actual notion a/b of division. It is also similar to
how, in the construction of the real numbers, we deﬁned a formal limit
LIMn→∞an before we deﬁned a genuine limit limn→∞an.
Deﬁnition 4.6.2 (Formal deﬁnition of complex numbers). A complex
number is any pair of the form (a, b), where a, b are real numbers, thus for
instance (2, 4) is a complex number. Two complex numbers (a, b), (c, d)
are said to be equal iﬀa = c and b = d, thus for instance (2+1, 3+4) =
(3, 7), but (2, 1) ̸= (1, 2) and (2, 4) ̸= (2, −4). The set of all complex
numbers is denoted C.
At this stage the complex numbers C are indistinguishable from the
Cartesian product R2 = R × R (also known as the Cartesian plane).
However, we will introduce a number of operations on the complex num-
bers, notably that of complex multiplication, which are not normally
placed on the Cartesian plane R2. Thus one can think of the complex
number system C as the Cartesian plane R2 equipped with a number of
additional structures. We begin with the notion of addition and nega-
tion. Using the informal deﬁnition of the complex numbers, we expect
(a, b) + (c, d) = (a + bi) + (c + di) = (a + c) + (b + d)i = (a + c, b + d)
and similarly
−(a, b) = −(a + bi) = (−a) + (−b)i = (−a, −b).
As these derivations used the informal deﬁnition of the complex num-
bers, these identities have not yet been rigorously proven. However we
shall simply encode these identities into our complex number system by
deﬁning the notion of addition and negation by the above rules:
Deﬁnition 4.6.3 (Complex addition, negation, and zero). If z = (a, b)
and w = (c, d) are two complex numbers, we deﬁne their sum z + w
to be the complex number z + w := (a + c, b + d). Thus for instance

4.6.
A digression on complex numbers
95
(2, 4) + (3, −1) = (5, 3). We also deﬁne the negation −z of z to be the
complex number −z := (−a, −b), thus for instance −(3, −1) = (−3, 1).
We also deﬁne the complex zero 0C to be the complex number 0C =
(0, 0).
It is easy to see that notion of addition is well-deﬁned in the sense
that if z = z′ and w = w′ then z + w = z′ + w′. Similarly for negation.
The complex addition, negation, and zero operations obey the usual laws
of arithmetic:
Lemma 4.6.4 (The complex numbers are an additive group). If
z1, z2, z3 are complex numbers, then we have the commutative property
z1 + z2 = z2 + z1, the associative property (z1 + z2) + z3 = z1 + (z2 + z3),
the identity property z1 + 0C = 0C + z1 = z1, and the inverse property
z1 + (−z1) = (−z1) + z1 = 0C.
Proof. See Exercise 4.6.1.
Next, we deﬁne the notion of complex multiplication and reciprocal.
The informal justiﬁcation of the complex multiplication rule is
(a, b) · (c, d) = (a + bi)(c + di)
= ac + adi + bic + bidi
= (ac −bd) + (ad + bc)i
= (ac −bd, ad + bc)
since i2 is supposed to equal −1. Thus we deﬁne
Deﬁnition 4.6.5 (Complex multiplication). If z = (a, b) and w = (c, d)
are complex numbers, then we deﬁne their product zw to be the complex
number zw := (ac −bd, ad + bc). We also introduce the complex identity
1C := (1, 0).
This operation is easily seen to be well-deﬁned, and also obeys the
usual laws of arithmetic:
Lemma 4.6.6. If z1, z2, z3 are complex numbers, then we have the
commutative property z1z2 = z2z1, the associative property (z1z2)z3 =
z1(z2z3), the identity property z11C = 1Cz1 = z1, and the distributivity
properties z1(z2 + z3) = z1z2 + z1z3 and (z2 + z3)z1 = z2z1 + z3z1.
Proof. See Exercise 4.6.2.

96
4.
Power series
The above lemma can also be stated more succinctly, as the assertion
that C is a commutative ring.
As is usual, we now write z −w as
shorthand for z + (−w).
We now identify the real numbers R with a subset of the complex
numbers C by identifying any real number x with the complex number
(x, 0), thus x ≡(x, 0). Note that this identiﬁcation is consistent with
equality (thus x = y iﬀ(x, 0) = (y, 0)), with addition (x1 + x2 = x3 iﬀ
(x1, 0) + (x2, 0) = (x3, 0)), with negation (x = −y iﬀ(x, 0) = −(y, 0)),
and multiplication (x1x2 = x3 iﬀ(x1, 0)(x2, 0) = (x3, 0)), so we will
no longer need to distinguish between “real addition” and “complex
addition”, and similarly for equality, negation, and multiplication. For
instance, we can compute 3(2, 4) by identifying the real number 3 with
the complex number (3, 0) and then computing (3, 0)(2, 4) = (3 × 2 −
0 × 4, 3 × 4 + 0 × 2) = (6, 12). Note also that 0 ≡0C and 1 ≡1C, so we
can now drop the C subscripts from the zero 0 and the identity 1.
We now deﬁne i to be the complex number i := (0, 1). We can now
reconstruct the informal deﬁnition of the complex numbers as a lemma:
Lemma 4.6.7. Every complex number z ∈C can be written as z = a+bi
for exactly one pair a, b of real numbers. Also, we have i2 = −1, and
−z = (−1)z.
Proof. See Exercise 4.6.3.
Because of this lemma, we will now refer to complex numbers in
the more usual notation a + bi, and discard the formal notation (a, b)
henceforth.
Deﬁnition 4.6.8 (Real and imaginary parts). If z is a complex number
with the representation z = a + bi for some real numbers a, b, we shall
call a the real part of z and denote ℜ(z) := a, and call b the imaginary
part of z and denote ℑ(z) := b, thus for instance ℜ(3 + 4i) = 3 and
ℑ(3 + 4i) = 4, and in general z = ℜ(z) + iℑ(z). Note that z is real iﬀ
ℑ(z) = 0. We say that z is imaginary iﬀℜ(z) = 0, thus for instance 4i
is imaginary, while 3 + 4i is neither real nor imaginary, and 0 is both
real and imaginary. We deﬁne the complex conjugate z of z to be the
complex number z := ℜ(z) −iℑ(z), thus for instance 3 + 4i = 3 −4i,
i = −i, and 3 = 3.
The operation of complex conjugation has several nice properties:
Lemma 4.6.9 (Complex conjugation is an involution). Let z, w be com-
plex numbers, then z + w = z+w, −z = −z, and zw = z w. Also z = z.

4.6.
A digression on complex numbers
97
Finally, we have z = w if and only if z = w, and z = z if and only if z
is real.
Proof. See Exercise 4.6.4.
The notion of absolute value |x| was deﬁned for rational numbers x
in Deﬁnition 4.3.1, and this deﬁnition extends to real numbers in the
obvious manner. However, we cannot extend this deﬁnition directly to
the complex numbers, as most complex numbers are neither positive
nor negative. (For instance, we do not classify i as either a positive or
negative number; see Exercise 4.6.15 for some reasons why). However,
we can still deﬁne absolute value by generalizing the formula |x| =
√
x2
from Exercise 5.6.3:
Deﬁnition 4.6.10 (Complex absolute value). If z = a+bi is a complex
number, we deﬁne the absolute value |z| of z to be the real number
|z| :=
√
a2 + b2 = (a2 + b2)1/2.
From Exercise 5.6.3 we see that this notion of absolute value general-
izes the notion of real absolute value. The absolute value has a number
of other good properties:
Lemma 4.6.11 (Properties of complex absolute value). Let z, w be com-
plex numbers. Then |z| is a non-negative real number, and |z| = 0 if and
only if z = 0. Also we have the identity zz = |z|2, and so |z| =
√
zz. As
a consequence we have |zw| = |z||w| and |z| = |z|. Finally, we have the
inequalities
−|z| ≤ℜ(z) ≤|z|;
−|z| ≤ℑ(z) ≤|z|;
|z| ≤|ℜ(z)| + |ℑ(z)|
as well as the triangle inequality |z + w| ≤|z| + |w|.
Proof. See Exercise 4.6.6.
Using the notion of absolute value, we can deﬁne a notion of recip-
rocal:
Deﬁnition 4.6.12 (Complex reciprocal). If z is a non-zero complex
number, we deﬁne the reciprocal z−1 of z to be the complex number
z−1 := |z|−2z (note that |z|−2 is well-deﬁned as a positive real number
because |z| is positive real, thanks to Lemma 4.6.11). Thus for instance
(1 + 2i)−1 = |1 + 2i|−2(1 −2i) = (12 + 22)−1(1 −2i) = 1
5 −2
5i. If z is
zero, z = 0, we leave the reciprocal 0−1 undeﬁned.

98
4.
Power series
From the deﬁnition and Lemma 4.6.11, we see that
zz−1 = z−1z = |z|−2zz = |z|−2|z|2 = 1,
and so z−1 is indeed the reciprocal of z. We can thus deﬁne a notion of
quotient z/w for any two complex numbers z, w with w ̸= 0 in the usual
manner by the formula z/w := zw−1.
The complex numbers can be given a distance by deﬁning d(z, w) =
|z −w|.
Lemma 4.6.13. The complex numbers C with the distance d form a
metric space. If (zn)∞
n=1 is a sequence of complex numbers, and z is
another complex number, then we have limn→∞zn = z in this metric
space if and only if limn→∞ℜ(zn) = ℜ(z) and limn→∞ℑ(zn) = ℑ(z).
Proof. See Exercise 4.6.9.
This metric space is in fact complete and connected, but not com-
pact: see Exercises 4.6.10, 4.6.12, 4.6.13. We also have the usual limit
laws:
Lemma 4.6.14 (Complex limit laws). Let (zn)∞
n=1 and (wn)∞
n=1 be con-
vergent sequences of complex numbers, and let c be a complex number.
Then the sequences (zn + wn)∞
n=1, (zn −wn)∞
n=1, (czn)∞
n=1, (znwn)∞
n=1,
and (zn)∞
n=1 are also convergent, with
lim
n→∞zn + wn = lim
n→∞zn + lim
n→∞wn
lim
n→∞zn −wn = lim
n→∞zn −lim
n→∞wn
lim
n→∞czn = c lim
n→∞zn
lim
n→∞znwn =

lim
n→∞zn
 
lim
n→∞wn

lim
n→∞zn = lim
n→∞zn
Also, if the wn are all non-zero and limn→∞wn is also non-zero, then
(zn/wn)∞
n=1 is also a convergent sequence, with
lim
n→∞zn/wn =

lim
n→∞zn)/( lim
n→∞wn

.
Proof. See Exercise 4.6.14.

4.6.
A digression on complex numbers
99
Observe that the real and complex number systems are in fact quite
similar; they both obey similar laws of arithmetic, and they have sim-
ilar structure as metric spaces.
Indeed many of the results in this
textbook that were proven for real-valued functions, are also valid for
complex-valued functions, simply by replacing “real” with “complex” in
the proofs but otherwise leaving all the other details of the proof un-
changed. Alternatively, one can always split a complex-valued function
f into real and imaginary parts ℜ(f), ℑ(f), thus f = ℜ(f) + iℑ(f), and
then deduce results for the complex-valued function f from the corre-
sponding results for the real-valued functions ℜ(f), ℑ(f). For instance,
the theory of pointwise and uniform convergence from Chapter 3, or the
theory of power series from this chapter, extends without any diﬃculty
to complex-valued functions. In particular, we can deﬁne the complex
exponential function in exactly the same manner as for real numbers:
Deﬁnition 4.6.15 (Complex exponential). If z is a complex number,
we deﬁne the function exp(z) by the formula
exp(z) :=
∞

n=0
zn
n! .
One can state and prove the ratio test for complex series and
use it to show that exp(z) converges for every z.
It turns out that
many of the properties from Theorem 4.5.2 still hold: we have that
exp(z + w) = exp(z) exp(w), for instance; see Exercise 4.6.16.
(The
other properties require complex diﬀerentiation and complex integra-
tion, but these topics are beyond the scope of this text.) Another useful
observation is that exp(z) = exp(z); this can be seen by conjugating the
partial sums N
n=0
zn
n! and taking limits as N →∞.
The complex logarithm turns out to be somewhat more subtle,
mainly because exp is no longer invertible, and also because the various
power series for the logarithm only have a ﬁnite radius of convergence
(unlike exp, which has an inﬁnite radius of convergence). This rather
delicate issue is beyond the scope of this text and will not be discussed
here.
— Exercises —
Exercise 4.6.1. Prove Lemma 4.6.4.
Exercise 4.6.2. Prove Lemma 4.6.6.
Exercise 4.6.3. Prove Lemma 4.6.7.

100
4.
Power series
Exercise 4.6.4. Prove Lemma 4.6.9.
Exercise 4.6.5. If z is a complex number, show that ℜ(z) = z+z
2
and ℑ(z) =
z−z
2i .
Exercise 4.6.6. Prove Lemma 4.6.11. (Hint: to prove the triangle inequality,
ﬁrst prove that ℜ(zw) ≤|z||w|, and hence (from Exercise 4.6.5) that zw+zw ≤
2|z||w|. Then add |z|2 + |w|2 to both sides of this inequality.)
Exercise 4.6.7. Show that if z, w are complex numbers with w ̸= 0, then |z/w| =
|z|/|w|.
Exercise 4.6.8. Let z, w be non-zero complex numbers. Show that |z + w| =
|z| + |w| if and only if there exists a positive real number c > 0 such that
z = cw.
Exercise 4.6.9. Prove Lemma 4.6.13.
Exercise 4.6.10. Show that the complex numbers C (with the usual metric d)
form a complete metric space.
Exercise 4.6.11. Let f : R2 →C be the map f(a, b) := a + bi. Show that f is
a bijection, and that f and f −1 are both continuous maps.
Exercise 4.6.12. Show that the complex numbers C (with the usual metric d)
form a connected metric space. (Hint: ﬁrst show that C is path connected, as
in Exercise 2.4.7.)
Exercise 4.6.13. Let E be a subset of C. Show that E is compact if and only if
E is closed and bounded. (Hint: combine Exercise 4.6.11 with the Heine-Borel
theorem, Theorem 1.5.7.) In particular, show that C is not compact.
Exercise 4.6.14. Prove Lemma 4.6.14. (Hint: split zn and wn into real and
imaginary parts and use the usual limit laws, Lemma 6.1.19, combined with
Lemma 4.6.13.)
Exercise 4.6.15. The purpose of this exercise is to explain why we do not try to
organize the complex numbers into positive and negative parts. Suppose that
there was a notion of a “positive complex number” and a “negative complex
number” which obeyed the following reasonable axioms (cf. Proposition 4.2.9):
• (Trichotomy) For every complex number z, exactly one of the following
statements is true: z is positive, z is negative, z is zero.
• (Negation) If z is a positive complex number, then −z is negative. If z
is a negative complex number, then −z is positive.
• (Additivity) If z and w are positive complex numbers, then z + w is also
positive.
• (Multiplicativity) If z and w are positive complex numbers, then zw is
also positive.

4.7.
Trigonometric functions
101
Show that these four axioms are inconsistent, i.e., one can use these axioms
to deduce a contradiction. (Hints: ﬁrst use the axioms to deduce that 1 is
positive, and then conclude that −1 is negative. Then apply the Trichotomy
axiom to z = i and obtain a contradiction in any one of the three cases).
Exercise 4.6.16. Prove the ratio test for complex series, and use it to show
that the series used to deﬁne the complex exponential is absolutely convergent.
Then prove that exp(z + w) = exp(z) exp(w) for all complex numbers z, w.
4.7
Trigonometric functions
We now discuss the next most important class of special functions, af-
ter the exponential and logarithmic functions, namely the trigonometric
functions. (There are several other useful special functions in mathemat-
ics, such as the hyperbolic trigonometric functions and hypergeometric
functions, the gamma and zeta functions, and elliptic functions, but they
occur more rarely and will not be discussed here.)
Trigonometric functions are often deﬁned using geometric concepts,
notably those of circles, triangles, and angles. However, it is also possi-
ble to deﬁne them using more analytic concepts, and in particular the
(complex) exponential function.
Deﬁnition 4.7.1 (Trigonometric functions). If z is a complex number,
then we deﬁne
cos(z) := eiz + e−iz
2
and
sin(z) := eiz −e−iz
2i
.
We refer to cos and sin as the cosine and sine functions respectively.
These formulae were discovered by Leonhard Euler (1707–1783) in
1748, who recognized the link between the complex exponential and the
trigonometric functions. Note that since we have deﬁned the sine and
cosine for complex numbers z, we automatically have deﬁned them also
for real numbers x. In fact in most applications one is only interested
in the trigonometric functions when applied to real numbers.
From the power series deﬁnition of exp, we have
eiz = 1 + iz −z2
2! −iz3
3! + z4
4! + . . .
and
e−iz = 1 −iz −z2
2! + iz3
3! + z4
4! −. . .

102
4.
Power series
and so from the above formulae we have
cos(z) = 1 −z2
2! + z4
4! −. . . =
∞

n=0
(−1)nz2n
(2n)!
and
sin(z) = z −z3
3! + z5
5! −. . . =
∞

n=0
(−1)nz2n+1
(2n + 1)! .
In particular, cos(x) and sin(x) are always real whenever x is real.
From the ratio test we see that the two power series ∞
n=0
(−1)nx2n
(2n)!
,
∞
n=0
(−1)nx2n+1
(2n+1)!
are absolutely convergent for every x, thus sin(x) and
cos(x) are real analytic at 0 with an inﬁnite radius of convergence. From
Exercise 4.2.8 we thus see that the sine and cosine functions are real an-
alytic on all of R. (They are also complex analytic on all of C, but
we will not pursue this matter in this text). In particular the sine and
cosine functions are continuous and diﬀerentiable.
We list some basic properties of the sine and cosine functions below.
Theorem 4.7.2 (Trigonometric identities). Let x, y be real numbers.
(a) We have sin(x)2 + cos(x)2 = 1. In particular, we have sin(x) ∈
[−1, 1] and cos(x) ∈[−1, 1] for all x ∈R.
(b) We have sin′(x) = cos(x) and cos′(x) = −sin(x).
(c) We have sin(−x) = −sin(x) and cos(−x) = cos(x).
(d) We have cos(x+y) = cos(x) cos(y)−sin(x) sin(y) and sin(x+y) =
sin(x) cos(y) + cos(x) sin(y).
(e) We have sin(0) = 0 and cos(0) = 1.
(f ) We have eix = cos(x) + i sin(x) and e−ix = cos(x) −i sin(x). In
particular cos(x) = ℜ(eix) and sin(x) = ℑ(eix).
Proof. See Exercise 4.7.1.
Now we describe some other properties of sin and cos.
Lemma 4.7.3. There exists a positive number x such that sin(x) is
equal to 0.

4.7.
Trigonometric functions
103
Proof. Suppose for sake of contradiction that sin(x) ̸= 0 for all x ∈
(0, ∞).
Observe that this would also imply that cos(x) ̸= 0 for all
x ∈(0, ∞), since if cos(x) = 0 then sin(2x) = 0 by Theorem 4.7.2(d)
(why?). Since cos(0) = 1, this implies by the intermediate value theorem
(Theorem 9.7.1) that cos(x) > 0 for all x > 0 (why?).
Also, since
sin(0) = 0 and sin′(0) = 1 > 0, we see that sin increasing near 0, hence
is positive to the right of 0. By the intermediate value theorem again
we conclude that sin(x) > 0 for all x > 0 (otherwise sin would have a
zero on (0, ∞)).
In particular if we deﬁne the cotangent function cot(x)
:=
cos(x)/ sin(x), then cot(x) would be positive and diﬀerentiable on all
of (0, ∞). From the quotient rule (Theorem 10.1.13(h)) and Theorem
4.7.2 we see that the derivative of cot(x) is −1/ sin(x)2 (why?) In par-
ticular, we have cot′(x) ≤−1 for all x > 0. By the fundamental theorem
of calculus (Theorem 11.9.1) this implies that cot(x + s) ≤cot(x) −s
for all x > 0 and s > 0. But letting s →∞we see that this contradicts
our assertion that cot is positive on (0, ∞) (why?).
Let E be the set E := {x ∈(0, +∞) : sin(x) = 0}, i.e., E is the
set of roots of sin on (0, +∞). By Lemma 4.7.3, E is non-empty. Since
sin′(0) > 0, there exists a c > 0 such that E ⊆[c, +∞) (see Exercise
4.7.2). Also, since sin is continuous in [c, +∞), E is closed in [c, +∞)
(why? use Theorem 2.1.5(d)). Since [c, +∞) is closed in R, we conclude
that E is closed in R. Thus E contains all its adherent points, and thus
contains inf(E). Thus if we make the deﬁnition
Deﬁnition 4.7.4. We deﬁne π to be the number
π := inf{x ∈(0, ∞) : sin(x) = 0}
then we have π ∈E ⊆[c, +∞) (so in particular π > 0) and sin(π) =
0. By deﬁnition of π, sin cannot have any zeroes in (0, π), and so in
particular must be positive on (0, π), (cf. the arguments in Lemma 4.7.3
using the intermediate value theorem). Since cos′(x) = −sin(x), we thus
conclude that cos(x) is strictly decreasing on (0, π). Since cos(0) = 1,
this implies in particular that cos(π) < 1; since sin2(π) + cos2(π) = 1
and sin(π) = 0, we thus conclude that cos(π) = −1.
In particular we have Euler’s famous formula
eπi = cos(π) + i sin(π) = −1.
We now conclude with some other properties of sine and cosine.

104
4.
Power series
Theorem 4.7.5 (Periodicity of trigonometric functions). Let x be a real
number.
(a) We have cos(x + π) = −cos(x) and sin(x + π) = −sin(x). In
particular we have cos(x + 2π) = cos(x) and sin(x + 2π) = sin(x),
i.e., sin and cos are periodic with period 2π.
(b) We have sin(x) = 0 if and only if x/π is an integer.
(c) We have cos(x) = 0 if and only if x/π is an integer plus 1/2.
Proof. See Exercise 4.7.3.
We can of course deﬁne all the other trigonometric functions: tan-
gent, cotangent, secant, and cosecant, and develop all the familiar iden-
tities of trigonometry; some examples of this are given in the exercises.
— Exercises —
Exercise 4.7.1. Prove Theorem 4.7.2. (Hint: write everything in terms of ex-
ponentials whenever possible.)
Exercise 4.7.2. Let f : R →R be a function which is diﬀerentiable at x0, with
f(x0) = 0 and f ′(x0) ̸= 0. Show that there exists a c > 0 such that f(y) is
non-zero whenever 0 < |x0 −y| < c. Conclude in particular that there exists a
c > 0 such that sin(x) ̸= 0 for all 0 < x < c.
Exercise 4.7.3. Prove Theorem 4.7.5. (Hint: for (c), you may wish to ﬁrst
compute sin(π/2) and cos(π/2), and then link cos(x) to sin(x + π/2).)
Exercise 4.7.4. Let x, y be real numbers such that x2+y2 = 1. Show that there
is exactly one real number θ ∈(−π, π] such that x = sin(θ) and y = cos(θ).
(Hint: you may need to divide into cases depending on whether x, y are positive,
negative, or zero.)
Exercise 4.7.5. Show that if r, s > 0 are positive real numbers, and θ, α are real
numbers such that reiθ = seiα, then r = s and θ = α + 2πk for some integer k.
Exercise 4.7.6. Let z be a non-zero complex number. Using Exercise 4.7.4, show
that there is exactly one pair of real numbers r, θ such that r > 0, θ ∈(−π, π],
and z = reiθ. (This is sometimes known as the standard polar representation
of z.)
Exercise 4.7.7. For any real number θ and integer n, prove the de Moivre
identities
cos(nθ) = ℜ((cos θ + i sin θ)n);
sin(nθ) = ℑ((cos θ + i sin θ)n).

4.7.
Trigonometric functions
105
Exercise 4.7.8. Let tan
:
(−π/2, π/2)
→
R be the tangent function
tan(x) := sin(x)/ cos(x).
Show that tan is diﬀerentiable and monotone in-
creasing, with
d
dx tan(x) = 1 + tan(x)2, and that limx→π/2 tan(x) = +∞
and limx→−π/2 tan(x) = −∞. Conclude that tan is in fact a bijection from
(−π/2, π/2) →R, and thus has an inverse function tan−1 : R →(−π/2, π/2)
(this function is called the arctangent function). Show that tan−1 is diﬀeren-
tiable and
d
dx tan−1(x) =
1
1+x2 .
Exercise 4.7.9. Recall the arctangent function tan−1 from Exercise 4.7.8. By
modifying the proof of Theorem 4.5.6(e), establish the identity
tan−1(x) =
∞

n=0
(−1)nx2n+1
2n + 1
for all x ∈(−1, 1).
Using Abel’s theorem (Theorem 4.3.1) to extend this
identity to the case x = 1, conclude in particular the identity
π = 4 −4
3 + 4
5 −4
7 + . . . = 4
∞

n=0
(−1)n
2n + 1.
(Note that the series converges by the alternating series test, Proposition
7.2.12). Conclude in particular that 4−4
3 < π < 4. (One can of course compute
π = 3.1415926 . . . to much higher accuracy, though if one wishes to do so it is
advisable to use a diﬀerent formula than the one above, which converges very
slowly).
Exercise 4.7.10. Let f : R →R be the function
f(x) :=
∞

n=1
4−n cos(32nπx).
(a) Show that this series is uniformly convergent, and that f is continuous.
(b) Show that for every integer j and every integer m ≥1, we have
|f
j + 1
32m

−f
 j
32m

| ≥4−m.
(Hint: use the identity
∞

n=1
an =
m−1

n=1
an

+ am +
∞

n=m+1
an
for certain sequences an.
Also, use the fact that the cosine function
is periodic with period 2π, as well as the geometric series formula
∞
n=0 rn =
1
1−r for any |r| < 1.
Finally, you will need the inequal-
ity | cos(x) −cos(y)| ≤|x −y| for any real numbers x and y; this can

106
4.
Power series
be proven by using the mean value theorem (Corollary 10.2.9), or the
fundamental theorem of calculus (Theorem 11.9.4).)
(c) Using (b), show that for every real number x0, the function f is not
diﬀerentiable at x0. (Hint: for every x0 and every m ≥1, there exists
an integer j such that j ≤32mx0 ≤j + 1, thanks to Exercise 5.4.3.)
(d) Explain brieﬂy why the result in (c) does not contradict Corollary 3.7.3.

Chapter 5
Fourier series
In the previous two chapters, we discussed the issue of how certain func-
tions (for instance, compactly supported continuous functions) could be
approximated by polynomials. Later, we showed how a diﬀerent class
of functions (real analytic functions) could be written exactly (not ap-
proximately) as an inﬁnite polynomial, or more precisely a power series.
Power series are already immensely useful, especially when dealing
with special functions such as the exponential and trigonometric func-
tions discussed earlier. However, there are some circumstances where
power series are not so useful, because one has to deal with functions
(e.g., √x) which are not real analytic, and so do not have power series.
Fortunately, there is another type of series expansion, known as
Fourier series, which is also a very powerful tool in analysis (though
used for slightly diﬀerent purposes).
Instead of analyzing compactly
supported functions, it instead analyzes periodic functions; instead of
decomposing into polynomials, it decomposes into trigonometric poly-
nomials. Roughly speaking, the theory of Fourier series asserts that just
about every periodic function can be decomposed as an (inﬁnite) sum
of sines and cosines.
Remark 5.0.6. Jean-Baptiste Fourier (1768-1830) was, among other
things, an administrator accompanying Napoleon on his invasion of
Egypt, and then a Prefect in France during Napoleons reign. After the
Napoleonic wars, he returned to mathematics. He introduced Fourier
series in an important 1807 paper in which he used them to solve what
is now known as the heat equation. At the time, the claim that every
periodic function could be expressed as a sum of sines and cosines was
extremely controversial, even such leading mathematicians as Euler de-
clared that it was impossible. Nevertheless, Fourier managed to show
107
© Springer Science+Business Media Singapore 2016 and Hindustan Book Agency 2015
T. Tao, Analysis II, Texts and Readings in Mathematics 38,
DOI 10.1007/978-981-10-1804-6_5

108
5.
Fourier series
that this was indeed the case, although the proof was not completely
rigorous and was not totally accepted for almost another hundred years.
There will be some similarities between the theory of Fourier series
and that of power series, but there are also some major diﬀerences. For
instance, the convergence of Fourier series is usually not uniform (i.e.,
not in the L∞metric), but instead we have convergence in a diﬀerent
metric, the L2-metric. Also, we will need to use complex numbers heavily
in our theory, while they played only a tangential rˆole in power series.
The theory of Fourier series (and of related topics such as Fourier in-
tegrals and the Laplace transform) is vast, and deserves an entire course
in itself. It has many, many applications, most directly to diﬀerential
equations, signal processing, electrical engineering, physics, and analy-
sis, but also to algebra and number theory. We will only give the barest
bones of the theory here, however, and almost no applications.
5.1
Periodic functions
The theory of Fourier series has to do with the analysis of periodic func-
tions, which we now deﬁne. It turns out to be convenient to work with
complex-valued functions rather than real-valued ones.
Deﬁnition 5.1.1. Let L > 0 be a real number. A function f : R →C
is periodic with period L, or L-periodic, if we have f(x + L) = f(x) for
every real number x.
Example 5.1.2. The real-valued functions f(x) = sin(x) and f(x) =
cos(x) are 2π-periodic, as is the complex-valued function f(x) = eix.
These functions are also 4π-periodic, 6π-periodic, etc.
(why?).
The
function f(x) = x, however, is not periodic.
The constant function
f(x) = 1 is L-periodic for every L.
Remark 5.1.3. If a function f is L-periodic, then we have f(x+kL) =
f(x) for every integer k (why? Use induction for the positive k, and
then use a substitution to convert the positive k result to a negative k
result. The k = 0 case is of course trivial). In particular, if a function
f is 1-periodic, then we have f(x + k) = f(x) for every k ∈Z. Because
of this, 1-periodic functions are sometimes also called Z-periodic (and
L-periodic functions called LZ-periodic).
Example 5.1.4. For any integer n, the functions cos(2πnx), sin(2πnx),
and e2πinx are all Z-periodic. (What happens when n is not an integer?).

5.1.
Periodic functions
109
Another example of a Z-periodic function is the function f : R →C
deﬁned by f(x) := 1 when x ∈[n, n+ 1
2) for some integer n, and f(x) := 0
when x ∈[n + 1
2, n + 1) for some integer n. This function is an example
of a square wave.
Henceforth, for simplicity, we shall only deal with functions which are
Z-periodic (for the Fourier theory of L-periodic functions, see Exercise
5.5.6). Note that in order to completely specify a Z-periodic function
f : R →C, one only needs to specify its values on the interval [0, 1),
since this will determine the values of f everywhere else. This is because
every real number x can be written in the form x = k + y where k is
an integer (called the integer part of x, and sometimes denoted [x])
and y ∈[0, 1) (this is called the fractional part of x, and sometimes
denoted {x}); see Exercise 5.1.1. Because of this, sometimes when we
wish to describe a Z-periodic function f we just describe what it does
on the interval [0, 1), and then say that it is extended periodically to all
of R. This means that we deﬁne f(x) for any real number x by setting
f(x) := f(y), where we have decomposed x = k + y as discussed above.
(One can in fact replace the interval [0, 1) by any other half-open interval
of length 1, but we will not do so here.)
The space of complex-valued continuous Z-periodic functions is de-
noted C(R/Z; C). (The notation R/Z comes from algebra, and denotes
the quotient group of the additive group R by the additive group Z;
more information in this can be found in any algebra text.) By “contin-
uous” we mean continuous at all points on R; merely being continuous
on an interval such as [0, 1] will not suﬃce, as there may be a discon-
tinuity between the left and right limits at 1 (or at any other integer).
Thus for instance, the functions sin(2πnx), cos(2πnx), and e2πinx are
all elements of C(R/Z; C), as are the constant functions, however the
square wave function described earlier is not in C(R/Z; C) because it is
not continuous. Also the function sin(x) would also not qualify to be in
C(R/Z; C) since it is not Z-periodic.
Lemma 5.1.5 (Basic properties of C(R/Z; C)).
(a) (Boundedness) If f ∈C(R/Z; C), then f is bounded (i.e., there
exists a real number M > 0 such that |f(x)| ≤M for all x ∈R).
(b) (Vector space and algebra properties) If f, g ∈C(R/Z; C), then the
functions f +g, f −g, and fg are also in C(R/Z; C). Also, if c is
any complex number, then the function cf is also in C(R/Z; C).

110
5.
Fourier series
(c) (Closure under uniform limits) If (fn)∞
n=1 is a sequence of func-
tions in C(R/Z; C) which converges uniformly to another function
f : R →C, then f is also in C(R/Z; C).
Proof. See Exercise 5.1.2.
One can make C(R/Z; C) into a metric space by re-introducing the
now familiar sup-norm metric
d∞(f, g) = sup
x∈R
|f(x) −g(x)| = sup
x∈[0,1)
|f(x) −g(x)|
of uniform convergence. (Why is the ﬁrst supremum the same as the
second?) See Exercise 5.1.3.
— Exercises —
Exercise 5.1.1. Show that every real number x can be written in exactly one
way in the form x = k + y, where k is an integer and y ∈[0, 1). (Hint: to prove
existence of such a representation, set k := sup{l ∈Z : l ≤x}.)
Exercise 5.1.2. Prove Lemma 5.1.5. (Hint: for (a), ﬁrst show that f is bounded
on [0, 1].)
Exercise 5.1.3. Show that C(R/Z; C) with the sup-norm metric d∞is a metric
space. Furthermore, show that this metric space is complete.
5.2
Inner products on periodic functions
From Lemma 5.1.5 we know that we can add, subtract, multiply, and
take limits of continuous periodic functions. We will need a couple more
operations on the space C(R/Z; C), though. The ﬁrst one is that of
inner product.
Deﬁnition 5.2.1 (Inner product). If f, g ∈C(R/Z; C), we deﬁne the
inner product ⟨f, g⟩to be the quantity
⟨f, g⟩=

[0,1]
f(x)g(x) dx.
Remark 5.2.2. In order to integrate a complex-valued function, f(x) =
g(x)+ih(x), we use the deﬁnition that

[a,b] f :=

[a,b] g+i

[a,b] h; i.e., we
integrate the real and imaginary parts of the function separately. Thus
for instance

[1,2](1+ix) dx =

[1,2] 1 dx+i

[1,2] x dx = 1+ 3
2i. It is easy
to verify that all the standard rules of calculus (integration by parts,
fundamental theorem of calculus, substitution, etc.) still hold when the
functions are complex-valued instead of real-valued.

5.2.
Inner products on periodic functions
111
Example 5.2.3. Let f be the constant function f(x) := 1, and let g(x)
be the function g(x) := e2πix. Then we have
⟨f, g⟩=

[0,1]
1e2πix dx
=

[0,1]
e−2πix dx
= e−2πix
−2πi |x=1
x=0
= e−2πi −e0
−2πi
= 1 −1
−2πi
= 0.
Remark 5.2.4. In general, the inner product ⟨f, g⟩will be a complex
number.
(Note that f(x)g(x) will be Riemann integrable since both
functions are bounded and continuous.)
Roughly speaking, the inner product ⟨f, g⟩is to the space C(R/Z; C)
what the dot product x · y is to Euclidean spaces such as Rn. We list
some basic properties of the inner product below; a more in-depth study
of inner products on vector spaces can be found in any linear algebra
text but is beyond the scope of this text.
Lemma 5.2.5. Let f, g, h ∈C(R/Z; C).
(a) (Hermitian property) We have ⟨g, f⟩= ⟨f, g⟩.
(b) (Positivity) We have ⟨f, f⟩≥0. Furthermore, we have ⟨f, f⟩= 0
if and only if f = 0 (i.e., f(x) = 0 for all x ∈R).
(c) (Linearity in the ﬁrst variable) We have ⟨f +g, h⟩= ⟨f, h⟩+⟨g, h⟩.
For any complex number c, we have ⟨cf, g⟩= c⟨f, g⟩.
(d) (Antilinearity in the second variable) We have ⟨f, g +h⟩= ⟨f, g⟩+
⟨f, h⟩. For any complex number c, we have ⟨f, cg⟩= c⟨f, g⟩.
Proof. See Exercise 5.2.1.
From the positivity property, it makes sense to deﬁne the L2 norm
∥f∥2 of a function f ∈C(R/Z; C) by the formula
∥f∥2 :=

⟨f, f⟩=

[0,1]
f(x)f(x) dx
1/2
=

[0,1]
|f(x)|2 dx
1/2
.

112
5.
Fourier series
Thus ∥f∥2 ≥0 for all f. The norm ∥f∥2 is sometimes called the root
mean square of f.
Example 5.2.6. If f(x) is the function e2πix, then
∥f∥2 =

[0,1]
e2πixe−2πix dx
1/2
=

[0,1]
1 dx
1/2
= 11/2 = 1.
This L2 norm is related to, but is distinct from, the L∞norm
∥f∥∞:= supx∈R |f(x)|. For instance, if f(x) = sin(x), then ∥f∥∞= 1
but ∥f∥2 =
1
√
2. In general, the best one can say is that 0 ≤∥f∥2 ≤
∥f∥∞; see Exercise 5.2.3.
Some basic properties of the L2 norm are given below.
Lemma 5.2.7. Let f, g ∈C(R/Z; C).
(a) (Non-degeneracy) We have ∥f∥2 = 0 if and only if f = 0.
(b) (Cauchy-Schwarz inequality) We have |⟨f, g⟩| ≤∥f∥2∥g∥2.
(c) (Triangle inequality) We have ∥f + g∥2 ≤∥f∥2 + ∥g∥2.
(d) (Pythagoras’ theorem) If ⟨f, g⟩= 0, then ∥f + g∥2
2 = ∥f∥2
2 + ∥g∥2
2.
(e) (Homogeneity) We have ∥cf∥2 = |c|∥f∥2 for all c ∈C.
Proof. See Exercise 5.2.4.
In light of Pythagoras’ theorem, we sometimes say that f and g are
orthogonal iﬀ⟨f, g⟩= 0.
We can now deﬁne the L2 metric dL2 on C(R/Z; C) by deﬁning
dL2(f, g) := ∥f −g∥2 =

[0,1]
|f(x) −g(x)|2 dx
1/2
.
Remark 5.2.8. One can verify that dL2 is indeed a metric (Exercise
5.2.2). Indeed, the L2 metric is very similar to the l2 metric on Euclidean
spaces Rn, which is why the notation is deliberately chosen to be similar;
you should compare the two metrics yourself to see the analogy.
Note that a sequence fn of functions in C(R/Z; C) will converge in
the L2 metric to f ∈C(R/Z; C) if dL2(fn, f) →0 as n →∞, or in
other words that
lim
n→∞

[0,1]
|fn(x) −f(x)|2 dx = 0.

5.2.
Inner products on periodic functions
113
Remark 5.2.9. The notion of convergence in L2 metric is diﬀerent from
that of uniform or pointwise convergence; see Exercise 5.2.6.
Remark 5.2.10. The L2 metric is not as well-behaved as the L∞metric.
For instance, it turns out the space C(R/Z; C) is not complete in the
L2 metric, despite being complete in the L∞metric; see Exercise 5.2.5.
— Exercises —
Exercise 5.2.1. Prove Lemma 5.2.5. (Hint: the last part of (b) is a little tricky.
You may need to prove by contradiction, assuming that f is not the zero
function, and then show that

[0,1] |f(x)|2 is strictly positive. You will need to
use the fact that f, and hence |f|, is continuous, to do this.)
Exercise 5.2.2. Prove that the L2 metric dL2 on C(R/Z; C) does indeed turn
C(R/Z; C) into a metric space. (cf. Exercise 1.1.6).
Exercise 5.2.3. If f ∈C(R/Z; C) is a non-zero function, show that 0 < ∥f∥2 ≤
∥f∥L∞. Conversely, if 0 < A ≤B are real numbers, so that there exists a
non-zero function f ∈C(R/Z; C) such that ∥f∥2 = A and ∥f∥∞= B. (Hint:
let g be a non-constant non-negative real-valued function in C(R/Z; C), and
consider functions f of the form f = (c+dg)1/2 for some constant real numbers
c, d > 0.)
Exercise 5.2.4. Prove Lemma 5.2.7. (Hint: use Lemma 5.2.5 frequently. For
the Cauchy-Schwarz inequality, begin with the positivity property ⟨f, f⟩≥0,
but with f replaced by the function f∥g∥2
2 −⟨f, g⟩g, and then simplify using
Lemma 5.2.5. You may have to treat the case ∥g∥2 = 0 separately. Use the
Cauchy-Schwarz inequality to prove the triangle inequality.)
Exercise 5.2.5. Find a sequence of continuous periodic functions which converge
in L2 to a discontinuous periodic function. (Hint: try converging to the square
wave function.)
Exercise 5.2.6. Let f ∈C(R/Z, C), and let (fn)∞
n=1 be a sequence of functions
in C(R/Z; C).
(a) Show that if fn converges uniformly to f, then fn also converges to f in
the L2 metric.
(b) Give an example where fn converges to f in the L2 metric, but does not
converge to f uniformly. (Hint: take f = 0. Try to make the functions
fn large in sup norm.)
(c) Give an example where fn converges to f in the L2 metric, but does not
converge to f pointwise. (Hint: take f = 0. Try to make the functions
fn large at one point.)
(d) Give an example where fn converges to f pointwise, but does not con-
verge to f in the L2 metric. (Hint: take f = 0. Try to make the functions
fn large in L2 norm.)

114
5.
Fourier series
5.3
Trigonometric polynomials
We now deﬁne the concept of a trigonometric polynomial. Just as poly-
nomials are combinations of the functions xn (sometimes called monomi-
als), trigonometric polynomials are combinations of the functions e2πinx
(sometimes called characters).
Deﬁnition 5.3.1 (Characters). For every integer n, we let en ∈
C(R/Z; C) denote the function
en(x) := e2πinx.
This is sometimes referred to as the character with frequency n.
Deﬁnition
5.3.2
(Trigonometric polynomials). A function f
in
C(R/Z; C) is said to be a trigonometric polynomial if we can write
f = N
n=−N cnen for some integer N ≥0 and some complex numbers
(cn)N
n=−N.
Example 5.3.3. The function f = 4e−2 + ie−1 −2e0 + 0e1 −3e2 is a
trigonometric polynomial; it can be written more explicitly as
f(x) = 4e−4πix + ie−2πix −2 −3e4πix.
Example 5.3.4. For any integer n, the function cos(2πnx) is a trigono-
metric polynomial, since
cos(2πnx) = e2πinx + e−2πinx
2
= 1
2e−n + 1
2en.
Similarly the function sin(2πnx) =
−1
2i e−n + 1
2ien is a trigonometric
polynomial. In fact, any linear combination of sines and cosines is also
a trigonometric polynomial, for instance 3 + i cos(2πx) + 4i sin(4πx) is
a trigonometric polynomial.
The Fourier theorem will allow us to write any function in C(R/Z; C)
as a Fourier series, which is to trigonometric polynomials what power se-
ries is to polynomials. To do this we will use the inner product structure
from the previous section. The key computation is
Lemma 5.3.5 (Characters are an orthonormal system). For any inte-
gers n and m, we have ⟨en, em⟩= 1 when n = m and ⟨en, em⟩= 0 when
n ̸= m. Also, we have ∥en∥= 1.

5.3.
Trigonometric polynomials
115
Proof. See Exercise 5.3.2.
As a consequence, we have a formula for the co-eﬃcients of a trigono-
metric polynomial.
Corollary 5.3.6. Let f = N
n=−N cnen be a trigonometric polynomial.
Then we have the formula
cn = ⟨f, en⟩
for all integers −N ≤n ≤N.
Also, we have 0 = ⟨f, en⟩whenever
n > N or n < −N. Also, we have the identity
∥f∥2
2 =
N

n=−N
|cn|2.
Proof. See Exercise 5.3.3.
We rewrite the conclusion of this corollary in a diﬀerent way.
Deﬁnition
5.3.7
(Fourier
transform). For
any
function
f
∈
C(R/Z; R), and any integer n ∈Z, we deﬁne the nth Fourier coeﬃ-
cient of f, denoted ˆf(n), by the formula
ˆf(n) := ⟨f, en⟩=

[0,1]
f(x)e−2πinx dx.
The function ˆf : Z →C is called the Fourier transform of f.
From Corollary 5.3.6, we see that whenever f = N
n=−N cnen is a
trigonometric polynomial, we have
f =
N

n=−N
⟨f, en⟩en =
∞

n=−∞
⟨f, en⟩en
and in particular we have the Fourier inversion formula
f =
∞

n=−∞
ˆf(n)en
or in other words
f(x) =
∞

n=−∞
ˆf(n)e2πinx.

116
5.
Fourier series
The right-hand side is referred to as the Fourier series of f. Also, from
the second identity of Corollary 5.3.6 we have the Plancherel formula
∥f∥2
2 =
∞

n=−∞
| ˆf(n)|2.
Remark 5.3.8. We stress that at present we have only proven the
Fourier inversion and Plancherel formulae in the case when f is a
trigonometric polynomial. Note that in this case that the Fourier coef-
ﬁcients ˆf(n) are mostly zero (indeed, they can only be non-zero when
−N ≤n ≤N), and so this inﬁnite sum is really just a ﬁnite sum in
disguise. In particular there are no issues about what sense the above
series converge in; they both converge pointwise, uniformly, and in L2
metric, since they are just ﬁnite sums.
In the next few sections we will extend the Fourier inversion and
Plancherel formulae to general functions in C(R/Z; C), not just trigono-
metric polynomials. (It is also possible to extend the formula to discon-
tinuous functions such as the square wave, but we will not do so here). To
do this we will need a version of the Weierstrass approximation theorem,
this time requiring that a continuous periodic function be approximated
uniformly by trigonometric polynomials. Just as convolutions were used
in the proof of the polynomial Weierstrass approximation theorem, we
will also need a notion of convolution tailored for periodic functions.
— Exercises —
Exercise 5.3.1. Show that the sum or product of any two trigonometric poly-
nomials is again a trigonometric polynomial.
Exercise 5.3.2. Prove Lemma 5.3.5.
Exercise 5.3.3. Prove Corollary 5.3.6.
(Hint:
use Lemma 5.3.5.
For the
second identity, either use Pythagoras’ theorem and induction, or substitute
f = N
n=−N cnen and expand everything out.)
5.4
Periodic convolutions
The goal of this section is to prove the Weierstrass approximation the-
orem for trigonometric polynomials:
Theorem 5.4.1. Let f ∈C(R/Z; C), and let ε > 0. Then there exists
a trignometric polynomial P such that ∥f −P∥∞≤ε.

5.4.
Periodic convolutions
117
This theorem asserts that any continuous periodic function can be
uniformly approximated by trigonometric polynomials. To put it an-
other way, if we let P(R/Z; C) denote the space of all trigonomet-
ric polynomials, then the closure of P(R/Z; C) in the L∞metric is
C(R/Z; C).
It is possible to prove this theorem directly from the Weierstrass
approximation theorem for polynomials (Theorem 3.8.3), and both the-
orems are a special case of a much more general theorem known as the
Stone-Weierstrass theorem, which we will not discuss here. However we
shall instead prove this theorem from scratch, in order to introduce a
couple of interesting notions, notably that of periodic convolution. The
proof here, though, should strongly remind you of the arguments used
to prove Theorem 3.8.3.
Deﬁnition 5.4.2 (Periodic convolution). Let f, g ∈C(R/Z; C). Then
we deﬁne the periodic convolution f ∗g : R →C of f and g by the
formula
f ∗g(x) :=

[0,1]
f(y)g(x −y) dy.
Remark 5.4.3. Note that this formula is slightly diﬀerent from the con-
volution for compactly supported functions deﬁned in Deﬁnition 3.8.9,
because we are only integrating over [0, 1] and not on all of R. Thus,
in principle we have given the symbol f ∗g two conﬂicting meanings.
However, in practice there will be no confusion, because it is not possi-
ble for a non-zero function to both be periodic and compactly supported
(Exercise 5.4.1).
Lemma 5.4.4 (Basic properties of periodic convolution). Let f, g, h ∈
C(R/Z; C).
(a) (Closure) The convolution f ∗g is continuous and Z-periodic. In
other words, f ∗g ∈C(R/Z; C).
(b) (Commutativity) We have f ∗g = g ∗f.
(c) (Bilinearity) We have f ∗(g + h) = f ∗g + f ∗h and (f + g) ∗h =
f ∗h + g ∗h.
For any complex number c, we have c(f ∗g) =
(cf) ∗g = f ∗(cg).
Proof. See Exercise 5.4.2.

118
5.
Fourier series
Now we observe an interesting identity: for any f ∈C(R/Z; C) and
any integer n, we have
f ∗en = ˆf(n)en.
To prove this, we compute
f ∗en(x) =

[0,1]
f(y)e2πin(x−y) dy
= e2πinx

[0,1]
f(y)e−2πiny dy = ˆf(n)e2πinx = ˆf(n)en
as desired.
More generally, we see from Lemma 5.4.4(iii) that for any trigono-
metric polynomial P = n=N
n=−N cnen, we have
f ∗P =
n=N

n=−N
cn(f ∗en) =
n=N

n=−N
ˆf(n)cnen.
Thus the periodic convolution of any function in C(R/Z; C) with a
trigonometric polynomial, is again a trigonometric polynomial. (Com-
pare with Lemma 3.8.13.)
Next, we introduce the periodic analogue of an approximation to the
identity.
Deﬁnition 5.4.5 (Periodic approximation to the identity). Let ε > 0
and 0 < δ < 1/2. A function f ∈C(R/Z; C) is said to be a periodic
(ε, δ) approximation to the identity if the following properties are true:
(a) f(x) ≥0 for all x ∈R, and

[0,1] f = 1.
(b) We have f(x) < ε for all δ ≤|x| ≤1 −δ.
Now we have an analogue of Lemma 3.8.8:
Lemma 5.4.6. For every ε > 0 and 0 < δ < 1/2, there exists a trigono-
metric polynomial P which is an (ε, δ) approximation to the identity.
Proof. We sketch the proof of this lemma here, and leave the completion
of it to Exercise 5.4.3. Let N ≥1 be an integer. We deﬁne the Fej´er
kernel FN to be the function
FN =
N

n=−N

1 −|n|
N

en.

5.4.
Periodic convolutions
119
Clearly FN is a trigonometric polynomial. We observe the identity
FN = 1
N

N−1

n=0
en

2
(why?). But from the geometric series formula (Lemma 7.3.3) we have
N−1

n=0
en(x) = eN −e0
e1 −e0
= eπi(N−1)x sin(πNx)
sin(πx)
when x is not an integer, (why?) and hence we have the formula
FN(x) = sin(πNx)2
N sin(πx)2 .
When x is an integer, the geometric series formula does not apply, but
one has FN(x) = N in that case, as one can see by direct computation.
In either case we see that FN(x) ≥0 for any x. Also, we have

[0,1]
FN(x) dx =
N

n=−N

1 −|n|
N
 
[0,1]
en =

1 −|0|
N

1 = 1
(why?). Finally, since sin(πNx) ≤1, we have
FN(x) ≤
1
N sin(πx)2 ≤
1
N sin(πδ)2
whenever δ < |x| < 1 −δ (this is because sin is increasing on [0, π/2]
and decreasing on [π/2, π]). Thus by choosing N large enough, we can
make FN(x) ≤ε for all δ < |x| < 1 −δ.
Proof of Theorem 5.4.1. Let f be any element of C(R/Z; C); we know
that f is bounded, so that we have some M > 0 such that |f(x)| ≤M
for all x ∈R.
Let ε > 0 be arbitrary. Since f is uniformly continuous, there exists a
δ > 0 such that |f(x)−f(y)| ≤ε whenever |x−y| ≤δ. Now use Lemma
5.4.6 to ﬁnd a trigonometric polynomial P which is a (ε, δ) approxima-
tion to the identity. Then f ∗P is also a trigonometric polynomial. We
now estimate ∥f −f ∗P∥∞.

120
5.
Fourier series
Let x be any real number. We have
|f(x) −f ∗P(x)| = |f(x) −P ∗f(x)|
=
f(x) −

[0,1]
f(x −y)P(y) dy

=


[0,1]
f(x)P(y) dy −

[0,1]
f(x −y)P(y) dy

=


[0,1]
(f(x) −f(x −y))P(y) dy

≤

[0,1]
|f(x) −f(x −y)|P(y) dy.
The right-hand side can be split as

[0,δ]
|f(x) −f(x −y)|P(y) dy +

[δ,1−δ]
|f(x) −f(x −y)|P(y) dy
+

[1−δ,1]
|f(x) −f(x −y)|P(y) dy
which we can bound from above by
≤

[0,δ]
εP(y) dy +

[δ,1−δ]
2Mε dy
+

[1−δ,1]
|f(x −1) −f(x −y)|P(y) dy
≤

[0,δ]
εP(y) dy +

[δ,1−δ]
2Mε dy +

[1−δ,1]
εP(y) dy
≤ε + 2Mε + ε
= (2M + 2)ε.
Thus we have ∥f −f ∗P∥∞≤(2M + 2)ε. Since M is ﬁxed and ε is
arbitrary, we can thus make f ∗P arbitrarily close to f in sup norm,
which proves the periodic Weierstrass approximation theorem.
— Exercises —
Exercise 5.4.1. Show that if f : R →C is both compactly supported and
Z-periodic, then it is identically zero.

5.5.
The Fourier and Plancherel theorems
121
Exercise 5.4.2. Prove Lemma 5.4.4. (Hint: to prove that f ∗g is continuous,
you will have to do something like use the fact that f is bounded, and g is
uniformly continuous, or vice versa. To prove that f ∗g = g ∗f, you will need
to use the periodicity to “cut and paste” the interval [0, 1].)
Exercise 5.4.3. Fill in the gaps marked (why?) in Lemma 5.4.6. (Hint: for the
ﬁrst identity, use the identities |z|2 = zz, en = e−n, and enem = en+m.)
5.5
The Fourier and Plancherel theorems
Using the Weierstrass approximation theorem (Theorem 5.4.1), we can
now generalize the Fourier and Plancherel identities to arbitrary contin-
uous periodic functions.
Theorem 5.5.1 (Fourier theorem). For any f ∈C(R/Z; C), the series
∞
n=−∞ˆf(n)en converges in L2 metric to f. In other words, we have
lim
N→∞
f −
N

n=−N
ˆf(n)en

2
= 0.
Proof. Let ε > 0. We have to show that there exists an N0 such that
∥f −N
n=−N ˆf(n)en∥2 ≤ε for all suﬃciently large N.
By the Weierstrass approximation theorem (Theorem 5.4.1), we
can ﬁnd a trigonometric polynomial P
= N0
n=−N0 cnen such that
∥f −P∥∞≤ε, for some N0 > 0. In particular we have ∥f −P∥2 ≤ε.
Now let N > N0, and let FN := n=N
n=−N ˆf(n)en. We claim that
∥f −FN∥2 ≤ε. First observe that for any |m| ≤N, we have
⟨f −FN, em⟩= ⟨f, em⟩−
N

n=−N
ˆf(n)⟨en, em⟩= ˆf(m) −ˆf(m) = 0,
where we have used Lemma 5.3.5. In particular we have
⟨f −FN, FN −P⟩= 0
since we can write FN −P as a linear combination of the em for which
|m| ≤N. By Pythagoras’ theorem we therefore have
∥f −P∥2
2 = ∥f −FN∥2
2 + ∥FN −P∥2
2

122
5.
Fourier series
and in particular
∥f −FN∥2 ≤∥f −P∥2 ≤ε
as desired.
Remark 5.5.2. Note that we have only obtained convergence of the
Fourier series ∞
n=−∞ˆf(n)en to f in the L2 metric.
One may ask
whether one has convergence in the uniform or pointwise sense as well,
but it turns out (perhaps somewhat surprisingly) that the answer is no
to both of those questions. However, if one assumes that the function f
is not only continuous, but is also continuously diﬀerentiable, then one
can recover pointwise convergence; if one assumes continuously twice
diﬀerentiable, then one gets uniform convergence as well. These results
are beyond the scope of this text and will not be proven here. How-
ever, we will prove one theorem about when one can improve the L2
convergence to uniform convergence:
Theorem 5.5.3. Let f ∈C(R/Z; C), and suppose that the series
∞
n=−∞| ˆf(n)| is absolutely convergent. Then the series ∞
n=−∞ˆf(n)en
converges uniformly to f. In other words, we have
lim
N→∞
f −
N

n=−N
ˆf(n)en

∞
= 0.
Proof. By the Weierstrass M-test (Theorem 3.5.7),
we see that
∞
n=−∞ˆf(n)en converges to some function F, which by Lemma 5.1.5(iii)
is also continuous and Z-periodic. (Strictly speaking, the Weierstrass M
test was phrased for series from n = 1 to n = ∞, but also works for se-
ries from n = −∞to n = +∞; this can be seen by splitting the doubly
inﬁnite series into two pieces.) Thus
lim
N→∞
F −
N

n=−N
ˆf(n)en

∞
= 0
which implies that
lim
N→∞
F −
N

n=−N
ˆf(n)en

2
= 0
since the L2 norm is always less than or equal to the L∞norm. But the
sequence N
n=−N ˆf(n)en is already converging in L2 metric to f by the

5.5.
The Fourier and Plancherel theorems
123
Fourier theorem, so can only converge in L2 metric to F if F = f (cf.
Proposition 1.1.20). Thus F = f, and so we have
lim
N→∞
f −
N

n=−N
ˆf(n)en

∞
= 0
as desired.
As a corollary of the Fourier theorem, we obtain
Theorem 5.5.4 (Plancherel theorem). For any f ∈C(R/Z; C), the
series ∞
n=−∞| ˆf(n)|2 is absolutely convergent, and
∥f∥2
2 =
∞

n=−∞
| ˆf(n)|2.
This theorem is also known as Parseval’s theorem.
Proof. Let ε > 0. By the Fourier theorem we know that
f −
N

n=−N
ˆf(n)en

2
≤ε
if N is large enough (depending on ε). In particular, by the triangle
inequality this implies that
∥f∥2 −ε ≤

N

n=−N
ˆf(n)en

2
≤∥f∥2 + ε.
On the other hand, by Corollary 5 we have

N

n=−N
ˆf(n)en

2
=

N

n=−N
| ˆf(n)|2
1/2
and hence
(∥f∥2 −ε)2 ≤
N

n=−N
| ˆf(n)|2 ≤(∥f∥2 + ε)2.
Taking lim sup, we obtain
(∥f∥2 −ε)2 ≤lim sup
N→∞
N

n=−N
| ˆf(n)|2 ≤(∥f∥2 + ε)2.

124
5.
Fourier series
Since ε is arbitrary, we thus obtain by the squeeze test that
lim sup
N→∞
N

n=−N
| ˆf(n)|2 = ∥f∥2
2
and the claim follows.
There are many other properties of the Fourier transform, but we
will not develop them here. In the exercises you will see a small number
of applications of the Fourier and Plancherel theorems.
— Exercises —
Exercise 5.5.1. Let f be a function in C(R/Z; C), and deﬁne the trigonometric
Fourier coeﬃcients an, bn for n = 0, 1, 2, 3, . . . by
an := 2

[0,1]
f(x) cos(2πnx) dx;
bn := 2

[0,1]
f(x) sin(2πnx) dx.
(a) Show that the series
1
2a0 +
∞

n=1
(an cos(2πnx) + bn sin(2πnx))
converges in L2 metric to f. (Hint: use the Fourier theorem, and break
up the exponentials into sines and cosines. Combine the positive n terms
with the negative n terms.)
(b) Show that if ∞
n=1 an and ∞
n=1 bn are absolutely convergent, then the
above series actually converges uniformly to f, and not just in L2 metric.
(Hint: use Theorem 5.5.3).
Exercise 5.5.2. Let f(x) be the function deﬁned by f(x) = (1 −2x)2 when
x ∈[0, 1), and extended to be Z-periodic for the rest of the real line.
(a) Using Exercise 5.5.1, show that the series
1
3 +
∞

n=1
4
π2n2 cos(2πnx)
converges uniformly to f.
(b) Conclude that ∞
n=1
1
n2 = π2
6 . (Hint: evaluate the above series at x = 0.)
(c) Conclude that ∞
n=1
1
n4 = π4
90 . (Hint: expand the cosines in terms of
exponentials, and use Plancherel’s theorem.)

5.5.
The Fourier and Plancherel theorems
125
Exercise 5.5.3. If f ∈C(R/Z; C) and P is a trigonometric polynomial, show
that

f ∗P(n) = ˆf(n)cn = ˆf(n) ˆP(n)
for all integers n. More generally, if f, g ∈C(R/Z; C), show that

f ∗g(n) = ˆf(n)ˆg(n)
for all integers n. (A fancy way of saying this is that the Fourier transform
intertwines convolution and multiplication).
Exercise 5.5.4. Let f ∈C(R/Z; C) be a function which is diﬀerentiable, and
whose derivative f ′ is also continuous. Show that f ′ also lies in C(R/Z; C),
and that f ′(n) = 2πin ˆf(n) for all integers n.
Exercise 5.5.5. Let f, g ∈C(R/Z; C). Prove the Parseval identity
ℜ
 1
0
f(x)g(x) dx = ℜ

n∈Z
ˆf(n)ˆg(n).
(Hint: apply the Plancherel theorem to f +g and f −g, and subtract the two.)
Then conclude that the real parts can be removed, thus
 1
0
f(x)g(x) dx =

n∈Z
ˆf(n)ˆg(n).
(Hint: apply the ﬁrst identity with f replaced by if.)
Exercise 5.5.6. In this exercise we shall develop the theory of Fourier series for
functions of any ﬁxed period L.
Let L > 0, and let f : R →C be a complex-valued function which is
continuous and L-periodic. Deﬁne the numbers cn for every integer n by
cn := 1
L

[0,L]
f(x)e−2πinx/L dx.
(a) Show that the series
∞

n=−∞
cne2πinx/L
converges in L2 metric to f. More precisely, show that
lim
N→∞

[0,L]
|f(x) −
N

n=−N
cne2πinx/L|2 dx = 0.
(Hint: apply the Fourier theorem to the function f(Lx).)

126
5.
Fourier series
(b) If the series ∞
n=−∞|cn| is absolutely convergent, show that
∞

n=−∞
cne2πinx/L
converges uniformly to f.
(c) Show that
1
L

[0,L]
|f(x)|2 dx =
∞

n=−∞
|cn|2.
(Hint: apply the Plancherel theorem to the function f(Lx).)

Chapter 6
Several variable diﬀerential calculus
6.1
Linear transformations
We shall now switch to a diﬀerent topic, namely that of diﬀerentiation
in several variable calculus. More precisely, we shall be dealing with
maps f : Rn →Rm from one Euclidean space to another, and trying to
understand what the derivative of such a map is.
Before we do so, however, we need to recall some notions from linear
algebra, most importantly that of a linear transformation and a matrix.
We shall be rather brief here; a more thorough treatment of this material
can be found in any linear algebra text.
Deﬁnition 6.1.1 (Row vectors). Let n ≥1 be an integer. We refer to
elements of Rn as n-dimensional row vectors. A typical n-dimensional
row vector may take the form x = (x1, x2, . . . , xn), which we abbreviate
as (xi)1≤i≤n; the quantities x1, x2, . . . , xn are of course real numbers. If
(xi)1≤i≤n and (yi)1≤i≤n are n-dimensional row vectors, we can deﬁne
their vector sum by
(xi)1≤i≤n + (yi)1≤i≤n = (xi + yi)1≤i≤n,
and also if c ∈R is any scalar, we can deﬁne the scalar product
c(xi)1≤i≤n by
c(xi)1≤i≤n := (cxi)1≤i≤n.
Of course one has similar operations on Rm as well. However, if n ̸= m,
then we do not deﬁne any operation of vector addition between vectors
in Rn and vectors in Rm (e.g., (2, 3, 4) + (5, 6) is undeﬁned). We also
refer to the vector (0, . . . , 0) in Rn as the zero vector and also denote it
by 0. (Strictly speaking, we should denote the zero vector of Rn by 0Rn,
as they are technically distinct from each other and from the number
127
© Springer Science+Business Media Singapore 2016 and Hindustan Book Agency 2015
T. Tao, Analysis II, Texts and Readings in Mathematics 38,
DOI 10.1007/978-981-10-1804-6_6

128
6.
Several variable diﬀerential calculus
zero, but we shall not take care to make this distinction). We abbreviate
(−1)x as −x.
The operations of vector addition and scalar multiplication obey a
number of basic properties:
Lemma 6.1.2 (Rn is a vector space). Let x, y, z be vectors in Rn,
and let c, d be real numbers. Then we have the commutativity property
x + y = y + x, the additive associativity property (x + y) + z = x +
(y + z), the additive identity property x + 0 = 0 + x = x, the additive
inverse property x+(−x) = (−x)+x = 0, the multiplicative associativity
property (cd)x = c(dx), the distributivity properties c(x + y) = cx + cy
and (c + d)x = cx + dx, and the multiplicative identity property 1x = x.
Proof. See Exercise 6.1.1.
Deﬁnition 6.1.3 (Transpose). If (xi)1≤i≤n = (x1, x2, . . . , xn) is an n-
dimensional row vector, we can deﬁne its transpose (xi)T
1≤i≤n by
(xi)T
1≤i≤n = (x1, x2, . . . , xn)T :=
⎛
⎜
⎜
⎜
⎝
x1
x2
...
xn
⎞
⎟
⎟
⎟
⎠.
We refer to objects such as (xi)T
1≤i≤n as n-dimensional column vectors.
Remark 6.1.4. There is no functional diﬀerence between a row vector
and a column vector (e.g., one can add and scalar multiply column
vectors just as well as we can row vectors), however we shall (rather
annoyingly) need to transpose our row vectors into column vectors in
order to be consistent with the conventions of matrix multiplication,
which we will see later.
Note that we view row vectors and column
vectors as residing in diﬀerent spaces; thus for instance we will not deﬁne
the sum of a row vector with a column vector, even when they have the
same number of elements.
Deﬁnition 6.1.5 (Standard basis row vectors). We identify n special
vectors in Rn, the standard basis row vectors e1, . . . , en. For each 1 ≤
j ≤n, ej is the vector which has 0 in all entries except for the jth entry,
which is equal to 1.

6.1.
Linear transformations
129
For instance, in R3, we have e1 = (1, 0, 0), e2 = (0, 1, 0), and e3 =
(0, 0, 1). Note that if x = (xj)1≤j≤n is a vector in Rn, then
x = x1e1 + x2e2 + . . . + xnen =
n

j=1
xjej,
or in other words every vector in Rn is a linear combination of the stan-
dard basis vectors e1, . . . , en. (The notation n
j=1 xjej is unambiguous
because the operation of vector addition is both commutative and asso-
ciative). Of course, just as every row vector is a linear combination of
standard basis row vectors, every column vector is a linear combination
of standard basis column vectors:
xT = x1eT
1 + x2eT
2 + . . . + xneT
n =
n

j=1
xjeT
j .
There are (many) other ways to create a basis for Rn, but this is a
topic for a linear algebra text and will not be discussed here.
Deﬁnition 6.1.6 (Linear transformations). A linear transformation T :
Rn →Rm is any function from one Euclidean space Rn to another Rm
which obeys the following two axioms:
(a) (Additivity) For every x, x′ ∈Rn, we have T(x + x′) = Tx + Tx′.
(b) (Homogeneity) For every x ∈Rn and every c ∈R, we have
T(cx) = cTx.
Example 6.1.7. The dilation operator T1 : R3 →R3 deﬁned by
T1x := 5x (i.e., it dilates each vector x by a factor of 5) is a linear trans-
formation, since 5(x+x′) = 5x+5x′ for all x, x′ ∈R3 and 5(cx) = c(5x)
for all x ∈R3 and c ∈R.
Example 6.1.8. The rotation operator T2 : R2 →R2 deﬁned by a
clockwise rotation by π/2 radians around the origin (so that T2(1, 0) =
(0, 1), T2(0, 1) = (−1, 0), etc.) is a linear transformation; this can best
be seen geometrically rather than analytically.
Example 6.1.9. The projection operator T3 : R3 →R2 deﬁned by
T3(x, y, z) := (x, y) is a linear transformation (why?).
The inclusion
operator T4 : R2 →R3 deﬁned by T4(x, y) := (x, y, 0) is also a linear
transformation (why?). Finally, the identity operator In : Rn →Rn,
deﬁned for any n by Inx := x is also a linear transformation (why?).

130
6.
Several variable diﬀerential calculus
As we shall shortly see, there is a connection between linear trans-
formations and matrices.
Deﬁnition 6.1.10 (Matrices). An m × n matrix is an object A of the
form
A =
⎛
⎜
⎜
⎜
⎝
a11
a12
. . .
a1n
a21
a22
. . .
a2n
...
...
...
...
am1
am2
. . .
amn
⎞
⎟
⎟
⎟
⎠;
we shall abbreviate this as
A = (aij)1≤i≤m;1≤j≤n.
In particular, n-dimensional row vectors are 1 × n matrices, while n-
dimensional column vectors are n × 1 matrices.
Deﬁnition 6.1.11 (Matrix product). Given an m × n matrix A and an
n × p matrix B, we can deﬁne the matrix product AB to be the m × p
matrix deﬁned as
(aij)1≤i≤m;1≤j≤n(bjk)1≤j≤n;1≤k≤p :=
⎛
⎝
n

j=1
aijbjk
⎞
⎠
1≤i≤m;1≤k≤p
.
In particular, if xT = (xj)T
1≤j≤n is an n-dimensional column vector, and
A = (aij)1≤i≤m;1≤j≤n is an m×n matrix, then AxT is an m-dimensional
column vector:
AxT =
⎛
⎝
n

j=1
aijxj
⎞
⎠
T
1≤i≤m
.
We now relate matrices to linear transformations. If A is an m × n
matrix, we can deﬁne the transformation LA : Rn →Rm by the formula
(LAx)T := AxT .
Example 6.1.12. If A is the matrix
A =
 1
2
3
4
5
6

,

6.1.
Linear transformations
131
and x = (x1, x2, x3) is a 3-dimensional row vector, then LAx is the
2-dimensional row vector deﬁned by
(LAx)T =
 1
2
3
4
5
6
 ⎛
⎝
x1
x2
x3
⎞
⎠=
 x1 + 2x2 + 3x3
4x1 + 5x2 + 6x3

or in other words
LA(x1, x2, x3) = (x1 + 2x2 + 3x3, 4x1 + 5x2 + 6x3).
More generally, if
A =
⎛
⎜
⎜
⎜
⎝
a11
a12
. . .
a1n
a21
a22
. . .
a2n
...
...
...
...
am1
am2
. . .
amn
⎞
⎟
⎟
⎟
⎠
then we have
LA(xj)1≤j≤n =
⎛
⎝
n

j=1
aijxj
⎞
⎠
1≤i≤m
.
For any m × n matrix A, the transformation LA is automatically linear;
one can easily verify that LA(x+y) = LAx+LAy and LA(cx) = c(LAx)
for any n-dimensional row vectors x, y and any scalar c. (Why?)
Perhaps surprisingly, the converse is also true, i.e., every linear trans-
formation from Rn to Rm is given by a matrix:
Lemma 6.1.13. Let T : Rn →Rm be a linear transformation. Then
there exists exactly one m × n matrix A such that T = LA.
Proof. Suppose T
: Rn
→Rm is a linear transformation.
Let
e1, e2, . . . , en
be the standard basis row vectors of Rn.
Then
Te1, Te2, . . . , Ten are vectors in Rm. For each 1 ≤j ≤n, we write
Tej in co-ordinates as
Tej = (a1j, a2j, . . . , amj) = (aij)1≤i≤m,
i.e., we deﬁne aij to be the ith component of Tej.
Then for any n-
dimensional row vector x = (x1, . . . , xn), we have
Tx = T
⎛
⎝
n

j=1
xjej
⎞
⎠,

132
6.
Several variable diﬀerential calculus
which (since T is linear) is equal to
=
n

j=1
T(xjej)
=
n

j=1
xjTej
=
n

j=1
xj(aij)1≤i≤m
=
n

j=1
(aijxj)1≤i≤m
=
⎛
⎝
n

j=1
aijxj
⎞
⎠
1≤i≤m
.
But if we let A be the matrix
A =
⎛
⎜
⎜
⎜
⎝
a11
a12
. . .
a1n
a21
a22
. . .
a2n
...
...
...
...
am1
am2
. . .
amn
⎞
⎟
⎟
⎟
⎠
then the previous vector is precisely LAx. Thus Tx = LAx for all n-
dimensional vectors x, and thus T = LA.
Now we show that A is unique, i.e., there does not exist any other
matrix
B =
⎛
⎜
⎜
⎜
⎝
b11
b12
. . .
b1n
b21
b22
. . .
b2n
...
...
...
...
bm1
bm2
. . .
bmn
⎞
⎟
⎟
⎟
⎠
for which T is equal to LB. Suppose for sake of contradiction that we
could ﬁnd such a matrix B which was diﬀerent from A. Then we would
have LA = LB. In particular, we have LAej = LBej for every 1 ≤j ≤n.
But from the deﬁnition of LA we see that
LAej = (aij)1≤i≤m
and
LBej = (bij)1≤i≤m

6.1.
Linear transformations
133
and thus we have aij = bij for every 1 ≤i ≤m and 1 ≤j ≤m, thus A
and B are equal, a contradiction.
Remark 6.1.14. Lemma 6.1.13 establishes a one-to-one correspondence
between linear transformations and matrices, and is one of the funda-
mental reasons why matrices are so important in linear algebra. One
may ask then why we bother dealing with linear transformations at all,
and why we don’t just work with matrices all the time.
The reason
is that sometimes one does not want to work with the standard basis
e1, . . . , en, but instead wants to use some other basis. In that case, the
correspondence between linear transformations and matrices changes,
and so it is still important to keep the notions of linear transformation
and matrix distinct. More discussion on this somewhat subtle issue can
be found in any linear algebra text.
Remark 6.1.15. If T = LA, then A is sometimes called the matrix
representation of T, and is sometimes denoted A = [T]. We shall avoid
this notation here, however.
The composition of two linear transformations is again a linear trans-
formation (Exercise 6.1.2). The next lemma shows that the operation
of composing linear transformations is connected to that of matrix mul-
tiplication.
Lemma 6.1.16. Let A be an m×n matrix, and let B be an n×p matrix.
Then LALB = LAB.
Proof. See Exercise 6.1.3.
— Exercises —
Exercise 6.1.1. Prove Lemma 6.1.2.
Exercise 6.1.2. If T : Rn →Rm is a linear transformation, and S : Rp →Rn
is a linear transformation, show that the composition TS : Rp →Rm of the
two transforms, deﬁned by TS(x) := T(S(x)), is also a linear transformation.
(Hint: expand TS(x + y) and TS(cx) carefully, using plenty of parentheses.)
Exercise 6.1.3. Prove Lemma 6.1.16.
Exercise 6.1.4. Let T : Rn →Rm be a linear transformation. Show that there
exists a number M > 0 such that ∥Tx∥≤M∥x∥for all x ∈Rn. (Hint: use
Lemma 6.1.13 to write T in terms of a matrix A, and then set M to be the sum
of the absolute values of all the entries in A. Use the triangle inequality often -
it’s easier than messing around with square roots etc.) Conclude in particular
that every linear transformation from Rn to Rm is continuous.

134
6.
Several variable diﬀerential calculus
6.2
Derivatives in several variable calculus
Now that we’ve reviewed some linear algebra, we turn now to our main
topic of this chapter, which is that of understanding diﬀerentiation of
functions of the form f : Rn →Rm, i.e., functions from one Euclidean
space to another.
For instance, one might want to diﬀerentiate the
function f : R3 →R4 deﬁned by
f(x, y, z) = (xy, yz, xz, xyz).
In single variable calculus, when one wants to diﬀerentiate a function
f : E →R at a point x0, where E is a subset of R that contains x0,
this is given by
f′(x0) :=
lim
x→x0;x∈E\{x0}
f(x) −f(x0)
x −x0
.
One could try to mimic this deﬁnition in the several variable case f :
E →Rm, where E is now a subset of Rn, however we encounter a
diﬃculty in this case: the quantity f(x) −f(x0) will live in Rm, and
x −x0 lives in Rn, and we do not know how to divide an m-dimensional
vector by an n-dimensional vector.
To get around this problem, we ﬁrst rewrite the concept of derivative
(in one dimension) in a way which does not involve division of vectors.
Instead, we view diﬀerentiability at a point x0 as an assertion that a
function f is “approximately linear” near x0.
Lemma 6.2.1. Let E be a subset of R, f : E →R be a function,
x0 ∈E, and L ∈R. Then the following two statements are equivalent.
(a) f is diﬀerentiable at x0, and f′(x0) = L.
(b) We have limx→x0;x∈E−{x0}
|f(x)−(f(x0)+L(x−x0))|
|x−x0|
= 0.
Proof. See Exercise 6.2.1.
In light of the above lemma, we see that the derivative f′(x0) can
be interpreted as the number L for which |f(x) −(f(x0) + L(x −x0))|
is small, in the sense that it tends to zero as x tends to x0, even if
we divide out by the very small number |x −x0|.
More informally,
the derivative is the quantity L such that we have the approximation
f(x) −f(x0) ≈L(x −x0).

6.2.
Derivatives in several variable calculus
135
This does not seem too diﬀerent from the usual notion of diﬀeren-
tiation, but the point is that we are no longer explicitly dividing by
x −x0. (We are still dividing by |x −x0|, but this will turn out to be
OK). When we move to the several variable case f : E →Rm, where
E ⊆Rn, we shall still want the derivative to be some quantity L such
that f(x) −f(x0) ≈L(x −x0). However, since f(x) −f(x0) is now
an m-dimensional vector and x −x0 is an n-dimensional vector, we no
longer want L to be a scalar; we want it to be a linear transformation.
More precisely:
Deﬁnition 6.2.2 (Diﬀerentiability). Let E be a subset of Rn, f : E →
Rm be a function, x0 ∈E be a point, and let L : Rn →Rm be a linear
transformation. We say that f is diﬀerentiable at x0 with derivative L
if we have
lim
x→x0;x∈E−{x0}
∥f(x) −(f(x0) + L(x −x0))∥
∥x −x0∥
= 0.
Here ∥x∥is the length of x (as measured in the l2 metric):
∥(x1, x2, . . . , xn)∥= (x2
1 + x2
2 + . . . + x2
n)1/2.
Example 6.2.3. Let f : R2 →R2 be the map f(x, y) := (x2, y2), let
x0 be the point x0 := (1, 2), and let L : R2 →R2 be the map L(x, y) :=
(2x, 4y). We claim that f is diﬀerentiable at x0 with derivative L. To
see this, we compute
lim
(x,y)→(1,2):(x,y)̸=(1,2)
∥f(x, y) −(f(1, 2) + L((x, y) −(1, 2)))∥
∥(x, y) −(1, 2)∥
.
Making the change of variables (x, y) = (1, 2) + (a, b), this becomes
lim
(a,b)→(0,0):(a,b)̸=(0,0)
∥f(1 + a, 2 + b) −(f(1, 2) + L(a, b))∥
∥(a, b)∥
.
Substituting the formula for f and for L, this becomes
lim
(a,b)→(0,0):(a,b)̸=(0,0)
∥((1 + a)2, (2 + b)2) −(1, 4) −(2a, 4b))∥
∥(a, b)∥
,
which simpliﬁes to
lim
(a,b)→(0,0):(a,b)̸=(0,0)
∥(a2, b2)∥
∥(a, b)∥.

136
6.
Several variable diﬀerential calculus
We use the squeeze test. The expression ∥(a2,b2)∥
∥(a,b)∥is clearly non-negative.
On the other hand, we have by the triangle inequality
∥(a2, b2)∥≤∥(a2, 0)∥+ ∥(0, b2)∥= a2 + b2
and hence
∥(a2, b2)∥
∥(a, b)∥
≤

a2 + b2.
Since
√
a2 + b2 →0 as (a, b) →0, we thus see from the squeeze test that
the above limit exists and is equal to 0. Thus f is diﬀerentiable at x0
with derivative L.
As you can see, verifying that a function is diﬀerentiable from ﬁrst
principles can be somewhat tedious. Later on we shall ﬁnd better ways
to verify diﬀerentiability, and to compute derivatives.
Before we proceed further, we have to check a basic fact, which is
that a function can have at most one derivative at any interior point of
its domain:
Lemma 6.2.4 (Uniqueness of derivatives). Let E be a subset of Rn,
f : E →Rm be a function, x0 ∈E be an interior point of E, and let
L1 : Rn →Rm and L2 : Rn →Rm be linear transformations. Suppose
that f is diﬀerentiable at x0 with derivative L1, and also diﬀerentiable
at x0 with derivative L2. Then L1 = L2.
Proof. See Exercise 6.2.2.
Because of Lemma 6.2.4, we can now talk about the derivative of f
at interior points x0, and we will denote this derivative by f′(x0). Thus
f′(x0) is the unique linear transformation from Rn to Rm such that
lim
x→x0;x̸=x0
∥f(x) −(f(x0) + f′(x0)(x −x0))∥
∥x −x0∥
= 0.
Informally, this means that the derivative f′(x0) is the linear transfor-
mation such that we have
f(x) −f(x0) ≈f′(x0)(x −x0)
or equivalently
f(x) ≈f(x0) + f′(x0)(x −x0)
(this is known as Newton’s approximation; compare with Proposition
10.1.7).

6.3.
Partial and directional derivatives
137
Another consequence of Lemma 6.2.4 is that if you know that f(x) =
g(x) for all x ∈E, and f, g are diﬀerentiable at x0, then you also know
that f′(x0) = g′(x0) at every interior point of E. However, this is not
necessarily true if x0 is a boundary point of E; for instance, if E is just
a single point E = {x0}, merely knowing that f(x0) = g(x0) does not
imply that f′(x0) = g′(x0). We will not deal with these boundary issues
here, and only compute derivatives on the interior of the domain.
We will sometimes refer to f′ as the total derivative of f, to distin-
guish this concept from that of partial and directional derivatives below.
The total derivative f is also closely related to the derivative matrix Df,
which we shall deﬁne in the next section.
— Exercises —
Exercise 6.2.1. Prove Lemma 6.2.1.
Exercise 6.2.2. Prove Lemma 6.2.4. (Hint: prove by contradiction. If L1 ̸= L2,
then there exists a vector v such that L1v ̸= L2v; this vector must be non-zero
(why?). Now apply the deﬁnition of derivative, and try to specialize to the case
where x = x0 + tv for some scalar t, to obtain a contradiction.)
6.3
Partial and directional derivatives
We now connect the notion of diﬀerentiability with that of partial and
directional derivatives, which we now introduce.
Deﬁnition 6.3.1 (Directional derivative). Let E be a subset of Rn,
f : E →Rm be a function, let x0 be an interior point of E, and let v be
a vector in Rn. If the limit
lim
t→0;t>0,x0+tv∈E
f(x0 + tv) −f(x0)
t
exists, we say that f is diﬀerentiable in the direction v at x0, and we
denote the above limit by Dvf(x0):
Dvf(x0) :=
lim
t→0;t>0
f(x0 + tv) −f(x0)
t
.
Remark 6.3.2. One should compare this deﬁnition with Deﬁnition
6.2.2. Note that we are dividing by a scalar t, rather than a vector,
so this deﬁnition makes sense, and Dvf(x0) will be a vector in Rm. It is
sometimes possible to also deﬁne directional derivatives on the boundary
of E, if the vector v is pointing in an “inward” direction (this generalizes

138
6.
Several variable diﬀerential calculus
the notion of left derivatives and right derivatives from single variable
calculus); but we will not pursue these matters here.
Example 6.3.3. If f : R →R is a function, then D+1f(x) is the same
as the right derivative of f(x) (if it exists), and similarly D−1f(x) is the
same as the left derivative of f(x) (if it exists).
Example 6.3.4. We use the function f : R2 →R2 deﬁned by f(x, y) :=
(x2, y2) from before, and let x0 := (1, 2) and v := (3, 4). Then
Dvf(x0) =
lim
t→0;t>0
f(1 + 3t, 2 + 4t) −f(1, 2)
t
=
lim
t→0;t>0
(1 + 6t + 9t2, 4 + 16t + 16t2) −(1, 4)
t
=
lim
t→0;t>0(6 + 9t, 16 + 16t) = (6, 16).
Directional derivatives are connected with total derivatives as fol-
lows:
Lemma 6.3.5. Let E be a subset of Rn, f : E →Rm be a function,
x0 be an interior point of E, and let v be a vector in Rn.
If f is
diﬀerentiable at x0, then f is also diﬀerentiable in the direction v at x0,
and
Dvf(x0) = f′(x0)v.
Proof. See Exercise 6.3.1.
Remark 6.3.6. One consequence of this lemma is that total diﬀerentia-
bility implies directional diﬀerentiability. However, the converse is not
true; see Exercise 6.3.3.
Closely related to the concept of directional derivative is that of
partial derivative:
Deﬁnition 6.3.7 (Partial derivative). Let E be a subset of Rn, let
f : E →Rm be a function, let x0 be an interior point of E, and let
1 ≤j ≤n.
Then the partial derivative of f with respect to the xj
variable at x0, denoted
∂f
∂xj (x0), is deﬁned by
∂f
∂xj
(x0) :=
lim
t→0;t̸=0,x0+tej∈E
f(x0 + tej) −f(x0)
t
= d
dtf(x0 + tej)|t=0
provided of course that the limit exists. (If the limit does not exist, we
leave
∂f
∂xj (x0) undeﬁned).

6.3.
Partial and directional derivatives
139
Informally, the partial derivative can be obtained by holding all the
variables other than xj ﬁxed, and then applying the single-variable cal-
culus derivative in the xj variable. Note that if f takes values in Rm,
then so will ∂f
∂xj . Indeed, if we write f in components as f = (f1, . . . , fm),
it is easy to see (why?) that
∂f
∂xj
(x0) =
∂f1
∂xj
(x0), . . . , ∂fm
∂xj
(x0)

,
i.e., to diﬀerentiate a vector-valued function one just has to diﬀerentiate
each of the components separately.
We sometimes replace the variables xj in
∂f
∂xj with other symbols.
For instance, if we are dealing with the function f(x, y) = (x2, y2), then
we might refer to ∂f
∂x and ∂f
∂y instead of
∂f
∂x1 and
∂f
∂x2 .
(In this case,
∂f
∂x(x, y) = (2x, 0) and ∂f
∂y (x, y) = (0, 2y)). One should caution however
that one should only relabel the variables if it is absolutely clear which
symbol refers to the ﬁrst variable, which symbol refers to the second
variable, etc.; otherwise one may become unintentionally confused. For
instance, in the above example, the expression ∂f
∂x(x, x) is just (2x, 0),
however one may mistakenly compute
∂f
∂x(x, x) = ∂
∂x(x2, x2) = (2x, 2x);
the problem here is that the symbol x is being used for more than just
the ﬁrst variable of f. (On the other hand, it is true that
d
dxf(x, x) is
equal to (2x, 2x); thus the operation of total diﬀerentiation
d
dx is not the
same as that of partial diﬀerentiation
∂
∂x).
From Lemma 6.3.5, we know that if a function is diﬀerentiable at a
point x0, then all the partial derivatives
∂f
∂xj exist at x0, and that
∂f
∂xj
(x0) = f′(x0)ej.
Also, if v = (v1, . . . , vn) = 
j vjej, then we have
Dvf(x0) = f′(x0)

j
vjej =

j
vjf′(x0)ej
(since f′(x0) is linear) and thus
Dvf(x0) =

j
vj
∂f
∂xj
(x0).

140
6.
Several variable diﬀerential calculus
Thus one can write directional derivatives in terms of partial derivatives,
provided that the function is actually diﬀerentiable at that point.
Just because the partial derivatives exist at a point x0, we cannot
conclude that the function is diﬀerentiable there (Exercise 6.3.3). How-
ever, if we know that the partial derivatives not only exist, but are
continuous, then we can in fact conclude diﬀerentiability, thanks to the
following handy theorem:
Theorem 6.3.8. Let E be a subset of Rn, f : E →Rm be a function,
F be a subset of E, and x0 be an interior point of F. If all the partial
derivatives
∂f
∂xj exist on F and are continuous at x0, then f is diﬀeren-
tiable at x0, and the linear transformation f′(x0) : Rn →Rm is deﬁned
by
f′(x0)(vj)1≤j≤n =
n

j=1
vj
∂f
∂xj
(x0).
Proof. Let L : Rn →Rm be the linear transformation
L(vj)1≤j≤m :=
m

j=1
vj
∂f
∂xj
(x0).
We have to prove that
lim
x→x0;x∈E−{x0}
∥f(x) −(f(x0) + L(x −x0))∥
∥x −x0∥
= 0.
Let ε > 0. It will suﬃce to ﬁnd a radius δ > 0 such that
∥f(x) −(f(x0) + L(x −x0))∥
∥x −x0∥
≤ε
for all x ∈B(x0, δ)\{x0}. Equivalently, we wish to show that
∥f(x) −f(x0) −L(x −x0)∥≤ε∥x −x0∥
for all x ∈B(x0, δ)\{x0}.
Because x0 is an interior point of F, there exists a ball B(x0, r) which
is contained inside F. Because each partial derivative
∂f
∂xj is continuous
on F, there thus exists an 0 < δj < r such that ∥∂f
∂xj (x) −∂f
∂xj (x0)∥≤
ε/nm for every x ∈B(x0, δj). If we take δ = min(δ1, . . . , δn), then we
thus have ∥∂f
∂xj (x) −∂f
∂xj (x0)∥≤ε/nm for every x ∈B(x0, δ) and every
1 ≤j ≤n.

6.3.
Partial and directional derivatives
141
Let x ∈B(x0, δ). We write x = x0 + v1e1 + v2e2 + . . . + vnen for
some scalars v1, . . . , vn. Note that
∥x −x0∥=

v2
1 + v2
2 + . . . + v2n
and in particular we have |vj| ≤∥x −x0∥for all 1 ≤j ≤n. Our task is
to show that

f(x0 + v1e1 + . . . + vnen) −f(x0) −
n

j=1
vj
∂f
∂xj
(x0)

≤ε∥x −x0∥.
Write f in components as f = (f1, f2, . . . , fm) (so each fi is a function
from E to R). From the mean value theorem in the x1 variable, we see
that
fi(x0 + v1e1) −fi(x0) = ∂fi
∂x1
(x0 + tie1)v1
for some ti between 0 and v1. But we have

∂fi
∂xj
(x0 + tie1) −∂fi
∂xj
(x0)
 ≤

∂f
∂xj
(x0 + tie1) −∂f
∂xj
(x0)
 ≤ε/nm
and hence
fi(x0 + v1e1) −fi(x0) −∂fi
∂x1
(x0)v1
 ≤ε|v1|/nm.
Summing this over all 1 ≤i ≤m (and noting that ∥(y1, . . . , ym)∥≤
|y1| + . . . + |ym| from the triangle inequality) we obtain
f(x0 + v1e1) −f(x0) −∂f
∂x1
(x0)v1
 ≤ε|v1|/n;
since |v1| ≤∥x −x0∥, we thus have
f(x0 + v1e1) −f(x0) −∂f
∂x1
(x0)v1
 ≤ε∥x −x0∥/n.
A similar argument gives
f(x0 + v1e1 + v2e2) −f(x0 + v1e1) −∂f
∂x2
(x0)v2
 ≤ε∥x −x0∥/n.

142
6.
Several variable diﬀerential calculus
and so forth up to
f(x0 + v1e1 + . . . + vnen) −f(x0 + v1e1 + . . . + vn−1en−1)
−∂f
∂xn
(x0)vn
 ≤ε∥x −x0∥/n.
If we sum these n inequalities and use the triangle inequality ∥x + y∥≤
∥x∥+ ∥y∥, we obtain a telescoping series which simpliﬁes to

f(x0 + v1e1 + . . . + vnen) −f(x0) −
n

j=1
∂f
∂xj
(x0)vj

≤ε∥x −x0∥
as desired.
From Theorem 6.3.8 and Lemma 6.3.5 we see that if the partial
derivatives of a function f : E →Rm exist and are continuous on some
set F, then all the directional derivatives also exist at every interior
point x0 of F, and we have the formula
D(v1,...,vn)f(x0) =
n

j=1
vj
∂f
∂xj
(x0).
In particular, if f : E →R is a real-valued function, and we deﬁne
the gradient ∇f(x0) of f at x0 to be the n-dimensional row vector
∇f(x0) := ( ∂f
∂x1 (x0), . . . , ∂f
∂xn (x0)), then we have the familiar formula
Dvf(x0) = v · ∇f(x0)
whenever x0 is in the interior of the region where the gradient exists and
is continuous.
More generally, if f : E →Rm is a function taking values in Rm,
with f = (f1, . . . , fm), and x0 is in the interior of the region where the
partial derivatives of f exist and are continuous, then we have from
Theorem 6.3.8 that
f′(x0)(vj)1≤j≤n =
n

j=1
vj
∂f
∂xj
(x0)
=
⎛
⎝
n

j=1
vj
∂fi
∂xj
(x0)
⎞
⎠
m
i=1
,

6.3.
Partial and directional derivatives
143
which we can rewrite as
LDf(x0)(vj)1≤j≤n
where Df(x0) is the m × n matrix
Df(x0) :=
 ∂fi
∂xj
(x0)

1≤i≤m;1≤j≤n
=
⎛
⎜
⎜
⎜
⎜
⎝
∂f1
∂x1 (x0)
∂f1
∂x2 (x0)
. . .
∂f1
∂xn (x0)
∂f2
∂x1 (x0)
∂f2
∂x2 (x0)
. . .
∂f2
∂xn (x0)
...
...
...
...
∂fm
∂x1 (x0)
∂fm
∂x2 (x0)
. . .
∂fm
∂xn (x0)
⎞
⎟
⎟
⎟
⎟
⎠
.
Thus we have
(Dvf(x0))T = (f′(x0)v)T = Df(x0)vT .
The matrix Df(x0) is sometimes also called the derivative matrix or
diﬀerential matrix of f at x0, and is closely related to the total derivative
f′(x0). One can also write Df as
Df(x0) =
 ∂f
∂x1
(x0)T , ∂f
∂x2
(x0)T , . . . , ∂f
∂xn
(x0)T

,
i.e., each of the columns of Df(x0) is one of the partial derivatives of f,
expressed as a column vector. Or one could write
Df(x0) =
⎛
⎜
⎜
⎜
⎝
∇f1(x0)
∇f2(x0)
...
∇fm(x0)
⎞
⎟
⎟
⎟
⎠
i.e., the rows of Df(x0) are the gradient of various components of f. In
particular, if f is scalar-valued (i.e., m = 1), then Df is the same as
∇f.
Example 6.3.9. Let f : R2 →R2 be the function f(x, y) = (x2 +
xy, y2). Then ∂f
∂x = (2x + y, 0) and ∂f
∂y = (x, 2y). Since these partial
derivatives are continuous on R2, we see that f is diﬀerentiable on all
of R2, and
Df(x, y) =
 2x + y
x
0
2y

.

144
6.
Several variable diﬀerential calculus
Thus for instance, the directional derivative in the direction (v, w) is
D(v,w)f(x, y) = ((2x + y)v + xw, 2yw).
— Exercises —
Exercise 6.3.1. Prove Lemma 6.3.5. (This will be similar to Exercise 6.2.1).
Exercise 6.3.2. Let E be a subset of Rn, let f : E →Rm be a function, let
x0 be an interior point of E, and let 1 ≤j ≤n. Show that
∂f
∂xj (x0) exists
if and only if Dejf(x0) and D−ejf(x0) exist and are negatives of each other
(thus Dejf(x0) = D−ejf(x0)); furthermore, one has
∂f
∂xj (x0) = Dejf(x0) in
this case.
Exercise 6.3.3. Let f : R2 →R be the function deﬁned by f(x, y) :=
x3
x2+y2
when (x, y) ̸= (0, 0), and f(0, 0) := 0. Show that f is not diﬀerentiable at
(0, 0), despite being diﬀerentiable in every direction v ∈R2 at (0, 0). Explain
why this does not contradict Theorem 6.3.8.
Exercise 6.3.4. Let f : Rn →Rm be a diﬀerentiable function such that f ′(x) =
0 for all x ∈Rn. Show that f is constant. (Hint: you may use the mean-value
theorem or fundamental theorem of calculus for one-dimensional functions,
but bear in mind that there is no direct analogue of these theorems for several-
variable functions. I would not advise proceeding via ﬁrst principles.) For a
tougher challenge, replace the domain Rn by an open connected subset Ω of
Rn.
6.4
The several variable calculus chain rule
We are now ready to state the several variable calculus chain rule. Recall
that if f : X →Y and g : Y →Z are two functions, then the composition
g ◦f : X →Z is deﬁned by g ◦f(x) := g(f(x)) for all x ∈X.
Theorem 6.4.1 (Several variable calculus chain rule). Let E be a subset
of Rn, and let F be a subset of Rm. Let f : E →F be a function, and let
g : F →Rp be another function. Let x0 be a point in the interior of E.
Suppose that f is diﬀerentiable at x0, and that f(x0) is in the interior of
F. Suppose also that g is diﬀerentiable at f(x0). Then g ◦f : E →Rp
is also diﬀerentiable at x0, and we have the formula
(g ◦f)′(x0) = g′(f(x0))f′(x0).
Proof. See Exercise 6.4.3.
One should compare this theorem with the single-variable chain rule,
Theorem 10.1.15; indeed one can easily deduce the single-variable rule
as a consequence of the several-variable rule.

6.4.
The several variable calculus chain rule
145
Intuitively, one can think of the several variable chain rule as follows.
Let x be close to x0. Then Newton’s approximation asserts that
f(x) −f(x0) ≈f′(x0)(x −x0)
and in particular f(x) is close to f(x0). Since g is diﬀerentiable at f(x0),
we see from Newton’s approximation again that
g(f(x)) −g(f(x0)) ≈g′(f(x0))(f(x) −f(x0)).
Combining the two, we obtain
g ◦f(x) −g ◦f(x0) ≈g′(f(x0))f′(x0)(x −x0)
which then should give (g ◦f)′(x0) = g′(f(x0))f′(x0). This argument
however is rather imprecise; to make it more precise one needs to ma-
nipulate limits rigorously; see Exercise 6.4.3.
As a corollary of the chain rule and Lemma 6.1.16 (and Lemma
6.1.13), we see that
D(g ◦f)(x0) = Dg(f(x0))Df(x0);
i.e., we can write the chain rule in terms of matrices and matrix multi-
plication, instead of in terms of linear transformations and composition.
Example 6.4.2. Let f : Rn →R and g : Rn →R be diﬀerentiable
functions. We form the combined function h : Rn →R2 by deﬁning
h(x) := (f(x), g(x)). Now let k : R2 →R be the multiplication function
k(a, b) := ab. Note that
Dh(x0) =
 ∇f(x0)
∇g(x0)

while
Dk(a, b) = (b, a)
(why?). By the chain rule, we thus see that
D(k◦h)(x0) = (g(x0), f(x0))
 ∇f(x0)
∇g(x0)

= g(x0)∇f(x0)+f(x0)∇g(x0).
But k ◦h = fg (why?), and D(fg) = ∇(fg). We have thus proven the
product rule
∇(fg) = g∇f + f∇g.

146
6.
Several variable diﬀerential calculus
A similar argument gives the sum rule ∇(f + g) = ∇f + ∇g, or the
diﬀerence rule ∇(f −g) = ∇f −∇g, as well as the quotient rule (Exercise
6.4.4). As you can see, the several variable chain rule is quite powerful,
and can be used to deduce many other rules of diﬀerentiation.
We do record one further useful application of the chain rule. Let
T : Rn →Rm be a linear transformation.
From Exercise 6.4.1 we
observe that T is continuously diﬀerentiable at every point, and in fact
T ′(x) = T for every x. (This equation may look a little strange, but
perhaps it is easier to swallow if you view it in the form
d
dx(Tx) = T).
Thus, for any diﬀerentiable function f : E →Rn, we see that Tf : E →
Rm is also diﬀerentiable, and hence by the chain rule
(Tf)′(x0) = T(f′(x0)).
This is a generalization of the single-variable calculus rule (cf)′ = c(f′)
for constant scalars c.
Another special case of the chain rule which is quite useful is the
following: if f : Rn →Rm is some diﬀerentiable function, and xj : R →
R are diﬀerentiable functions for each j = 1, . . . n, then
d
dtf(x1(t), x2(t), . . . , xn(t)) =
n

j=1
x′
j(t) ∂f
∂xj
(x1(t), x2(t), . . . , xn(t)).
(Why is this a special case of the chain rule?).
— Exercises —
Exercise 6.4.1. Let T : Rn →Rm be a linear transformation. Show that T is
continuously diﬀerentiable at every point, and in fact T ′(x) = T for every x.
What is DT?
Exercise 6.4.2. Let E be a subset of Rn. Prove that if a function f : E →Rm
is diﬀerentiable at an interior point x0 of E, then it is also continuous at x0.
(Hint: use Exercise 6.1.4.)
Exercise 6.4.3. Prove Theorem 6.4.1. (Hint: you may wish to review the proof
of the ordinary chain rule in single variable calculus, Theorem 10.1.15. The
easiest way to proceed is by using the sequence-based deﬁnition of limit (see
Proposition 3.1.5(b)), and use Exercise 6.1.4.)
Exercise 6.4.4. State and prove some version of the quotient rule for functions
of several variables (i.e., functions of the form f : E →R for some subset E of
Rn). In other words, state a rule which gives a formula for the gradient of f/g;
compare your answer with Theorem 10.1.13(h). Be sure to make clear what all
your assumptions are.

6.5.
Double derivatives and Clairaut’s theorem
147
Exercise 6.4.5. Let ⃗x : R →R3 be a diﬀerentiable function, and let r : R →R
be the function r(t) := ∥⃗x(t)∥, where ∥⃗x∥denotes the length of ⃗x as measured
in the usual l2 metric. Let t0 be a real number. Show that if r(t0) ̸= 0, then r
is diﬀerentiable at t0, and
r′(t0) = ⃗x′(t0) · ⃗x(t0)
r(t0)
.
(Hint: use Theorem 6.4.1.)
6.5
Double derivatives and Clairaut’s theorem
We now investigate what happens if one diﬀerentiates a function twice.
Deﬁnition 6.5.1 (Twice continuous diﬀerentiability). Let E be an open
subset of Rn, and let f : E →Rm be a function. We say that f is con-
tinuously diﬀerentiable if the partial derivatives
∂f
∂x1 , . . . , ∂f
∂xn exist and
are continuous on E. We say that f is twice continuously diﬀerentiable if
it is continuously diﬀerentiable, and the partial derivatives
∂f
∂x1 , . . . , ∂f
∂xn
are themselves continuously diﬀerentiable.
Remark 6.5.2. Continuously diﬀerentiable functions are sometimes
called C1 functions; twice continuously diﬀerentiable functions are some-
times called C2 functions. One can also deﬁne C3, C4, etc. but we shall
not do so here.
Example 6.5.3. Let f : R2 →R2 be the function f(x, y) = (x2 +
xy, y2). Then f is continuously diﬀerentiable because the partial deriva-
tives ∂f
∂x(x, y) = (2x + y, 0) and ∂f
∂y (x, y) = (x, 2y) exist and are contin-
uous on all of R2. It is also twice continuously diﬀerentiable, because
the double partial derivatives
∂
∂x
∂f
∂x(x, y) = (2, 0),
∂
∂y
∂f
∂x(x, y) = (1, 0),
∂
∂x
∂f
∂y (x, y) = (1, 0),
∂
∂y
∂f
∂y (x, y) = (0, 2) all exist and are continuous.
Observe in the above example that the double derivatives
∂
∂y
∂f
∂x and
∂
∂x
∂f
∂y are the same. This is a in fact a general phenomenon:
Theorem 6.5.4 (Clairaut’s theorem). Let E be an open subset of Rn,
and let f : E →Rm be a twice continuously diﬀerentiable function on
E. Then we have
∂
∂xj
∂f
∂xi (x0) =
∂
∂xi
∂f
∂xj (x0) for all 1 ≤i, j ≤n.
Proof. By working with one component of f at a time we can assume
that m = 1.
The claim is trivial if i = j, so we shall assume that

148
6.
Several variable diﬀerential calculus
i ̸= j.
We shall prove the theorem for x0 = 0; the general case is
similar. (Actually, once one proves Clairaut’s theorem for x0 = 0, one
can immediately obtain it for general x0 by applying the theorem with
f(x) replaced by f(x + x0).)
Let a be the number a :=
∂
∂xj
∂f
∂xi (0), and a′ denote the quantity
a′ :=
∂
∂xi
∂f
∂xj (0). Our task is to show that a′ = a.
Let ε > 0. Because the double derivatives of f are continuous, we
can ﬁnd a δ > 0 such that

∂
∂xj
∂f
∂xi
(x) −a
 ≤ε
and

∂
∂xi
∂f
∂xj
(x) −a′
 ≤ε
whenever |x| ≤2δ.
Now we consider the quantity
X := f(δei + δej) −f(δei) −f(δej) + f(0).
From the fundamental theorem of calculus in the ei variable, we have
f(δei + δej) −f(δej) =
 δ
0
∂f
∂xi
(xiei + δej) dxi
and
f(δei) −f(0) =
 δ
0
∂f
∂xi
(xiei) dxi
and hence
X =
 δ
0
 ∂f
∂xi
(xiei + δej) −∂f
∂xi
(xiei)

dxi.
But by the mean value theorem, for each xi we have
∂f
∂xi
(xiei + δej) −∂f
∂xi
(xiei) = δ ∂
∂xj
∂f
∂xi
(xiei + xjej)
for some 0 ≤xj ≤δ. By our construction of δ, we thus have

∂f
∂xi
(xiei + δej) −∂f
∂xi
(xiei) −δa
 ≤εδ.

6.6.
The contraction mapping theorem
149
Integrating this from 0 to δ, we thus obtain
|X −δ2a| ≤εδ2.
We can run the same argument with the rˆole of i and j reversed
(note that X is symmetric in i and j), to obtain
|X −δ2a′| ≤εδ2.
From the triangle inequality we thus obtain
|δ2a −δ2a′| ≤2εδ2,
and thus
|a −a′| ≤2ε.
But this is true for all ε > 0, and a and a′ do not depend on ε, and so
we must have a = a′, as desired.
One should caution that Clairaut’s theorem fails if we do not assume
the double derivatives to be continuous; see Exercise 6.5.1.
— Exercises —
Exercise 6.5.1. Let f : R2 →R be the function deﬁned by f(x, y) :=
xy3
x2+y2
when (x, y) ̸= (0, 0), and f(0, 0) := 0. Show that f is continuously diﬀeren-
tiable, and the double derivatives
∂
∂y
∂f
∂x and
∂
∂x
∂f
∂y exist, but are not equal to
each other at (0, 0). Explain why this does not contradict Clairaut’s theorem.
6.6
The contraction mapping theorem
Before we turn to the next topic - namely, the inverse function theorem
- we need to develop a useful fact from the theory of complete metric
spaces, namely the contraction mapping theorem.
Deﬁnition 6.6.1 (Contraction). Let (X, d) be a metric space, and
let f : X →X be a map.
We say that f is a contraction if we
have d(f(x), f(y)) ≤d(x, y) for all x, y ∈X.
We say that f is a
strict contraction if there exists a constant 0 < c < 1 such that
d(f(x), f(y)) ≤cd(x, y) for all x, y ∈X; we call c the contraction con-
stant of f.

150
6.
Several variable diﬀerential calculus
Examples 6.6.2. The map f : R →R deﬁned by f(x) := x + 1 is a
contraction but not a strict contraction. The map f : R →R deﬁned by
f(x) := x/2 is a strict contraction. The map f : [0, 1] →[0, 1] deﬁned
by f(x) := x −x2 is a contraction but not a strict contraction. (For
justiﬁcations of these statements, see Exercise 6.6.5.)
Deﬁnition 6.6.3 (Fixed points). Let f : X →X be a map, and x ∈X.
We say that x is a ﬁxed point of f if f(x) = x.
Contractions do not necessarily have any ﬁxed points; for instance,
the map f : R →R deﬁned by f(x) = x+1 does not. However, it turns
out that strict contractions always do, at least when X is complete:
Theorem 6.6.4 (Contraction mapping theorem). Let (X, d) be a metric
space, and let f : X →X be a strict contraction. Then f can have at
most one ﬁxed point. Moreover, if we also assume that X is non-empty
and complete, then f has exactly one ﬁxed point.
Proof. See Exercise 6.6.7.
Remark 6.6.5. The contraction mapping theorem is one example of
a ﬁxed point theorem - a theorem which guarantees, assuming certain
conditions, that a map will have a ﬁxed point. There are a number of
other ﬁxed point theorems which are also useful. One amusing one is
the so-called hairy ball theorem, which (among other things) states that
any continuous map f : S2 →S2 from the sphere S2 := {(x, y, z) ∈
R3 : x2 + y2 + z2 = 1} to itself, must contain either a ﬁxed point, or
an anti-ﬁxed point (a point x ∈S2 such that f(x) = −x). A proof of
this theorem can be found in any topology text; it is beyond the scope
of this text.
We shall give one consequence of the contraction mapping theorem
which is important for our application to the inverse function theorem.
Basically, this says that any map f on a ball which is a “small” pertur-
bation of the identity map, remains one-to-one and cannot create any
internal holes in the ball.
Lemma 6.6.6. Let B(0, r) be a ball in Rn centered at the origin, and
let g : B(0, r) →Rn be a map such that g(0) = 0 and
∥g(x) −g(y)∥≤1
2∥x −y∥

6.6.
The contraction mapping theorem
151
for all x, y ∈B(0, r) (here ∥x∥denotes the length of x in Rn). Then the
function f : B(0, r) →Rn deﬁned by f(x) := x+g(x) is one-to-one, and
furthermore the image f(B(0, r)) of this map contains the ball B(0, r/2).
Proof. We ﬁrst show that f is one-to-one.
Suppose for sake of con-
tradiction that we had two diﬀerent points x, y ∈B(0, r) such that
f(x) = f(y). But then we would have x + g(x) = y + g(y), and hence
∥g(x) −g(y)∥= ∥x −y∥.
The only way this can be consistent with our hypothesis ∥g(x)−g(y)∥≤
1
2∥x −y∥is if ∥x −y∥= 0, i.e., if x = y, a contradiction. Thus f is one-
to-one.
Now we show that f(B(0, r)) contains B(0, r/2). Let y be any point
in B(0, r/2); our objective is to ﬁnd a point x ∈B(0, r) such that
f(x) = y, or in other words that x = y −g(x). So the problem is now
to ﬁnd a ﬁxed point of the map x →y −g(x).
Let F : B(0, r) →B(0, r) denote the function F(x) := y −g(x).
Observe that if x ∈B(0, r), then
∥F(x)∥≤∥y∥+∥g(x)∥≤r
2 +∥g(x)−g(0)∥≤r
2 + 1
2∥x−0∥< r
2 + r
2 = r,
so F does indeed map B(0, r) to itself. The same argument shows that
for a suﬃciently small ε > 0, F maps the closed ball B(0, r −ε) to itself.
Also, for any x, x′ in B(0, r) we have
∥F(x) −F(x′)∥= ∥g(x′) −g(x)∥≤1
2∥x′ −x∥
so F is a strict contraction on B(0, r), and hence on the complete space
B(0, r −ε). By the contraction mapping theorem, F has a ﬁxed point,
i.e., there exists an x such that x = y −g(x).
But this means that
f(x) = y, as desired.
— Exercises —
Exercise 6.6.1. Let f : [a, b] →R be a diﬀerentiable function of one variable
such that |f ′(x)| ≤1 for all x ∈[a, b]. Prove that f is a contraction. (Hint:
use the mean-value theorem, Corollary 10.2.9.) If in addition |f ′(x)| < 1 for
all x ∈[a, b] and f ′ is continuous, show that f is a strict contraction.
Exercise 6.6.2. Show that if f : [a, b] →R is diﬀerentiable and is a contraction,
then |f ′(x)| ≤1.

152
6.
Several variable diﬀerential calculus
Exercise 6.6.3. Give an example of a function f : [a, b] →R which is con-
tinuously diﬀerentiable and such that |f(x) −f(y)| < |x −y| for all distinct
x, y ∈[a, b], but such that |f ′(x)| = 1 for at least one value of x ∈[a, b].
Exercise 6.6.4. Given an example of a function f : [a, b] →R which is a strict
contraction but which is not diﬀerentiable for at least one point x in [a, b].
Exercise 6.6.5. Verify the claims in Examples 6.6.2.
Exercise 6.6.6. Show that every contraction on a metric space X is necessarily
continuous.
Exercise 6.6.7. Prove Theorem 6.6.4. (Hint: to prove that there is at most one
ﬁxed point, argue by contradiction. To prove that there is at least one ﬁxed
point, pick any x0 ∈X and deﬁne recursively x1 = f(x0), x2 = f(x1), x3 =
f(x2), etc.
Prove inductively that d(xn+1, xn) ≤cnd(x1, x0), and conclude
(using the geometric series formula, Lemma 7.3.3) that the sequence (xn)∞
n=0
is a Cauchy sequence. Then prove that the limit of this sequence is a ﬁxed
point of f.)
Exercise 6.6.8. Let (X, d) be a complete metric space, and let f : X →X and
g : X →X be two strict contractions on X with contraction coeﬃcients c and
c′ respectively. From Theorem 6.6.4 we know that f has some ﬁxed point x0,
and g has some ﬁxed point y0. Suppose we know that there is an ε > 0 such
that d(f(x), g(x)) ≤ε for all x ∈X (i.e., f and g are within ε of each other
in the uniform metric). Show that d(x0, y0) ≤ε/(1 −min(c, c′)). Thus nearby
contractions have nearby ﬁxed points.
6.7
The inverse function theorem in several variable
calculus
We recall the inverse function theorem in single variable calculus (The-
orem 10.4.2), which asserts that if a function f : R →R is invertible,
diﬀerentiable, and f′(x0) is non-zero, then f−1 is diﬀerentiable at f(x0),
and
(f−1)′(f(x0)) =
1
f′(x0).
In fact, one can say something even when f′ is not invertible, as
long as we know that f is continuously diﬀerentiable. If f′(x0) is non-
zero, then f′(x0) must be either strictly positive or strictly negative,
which implies (since we are assuming f′ to be continuous) that f′(x) is
either strictly positive for x near x0, or strictly negative for x near x0.
In particular, f must be either strictly increasing near x0, or strictly
decreasing near x0. In either case, f will become invertible if we restrict
the domain and range of f to be suﬃciently close to x0 and to f(x0)

6.7.
The inverse function theorem in several variable calculus
153
respectively.
(The technical terminology for this is that f is locally
invertible near x0.)
The requirement that f be continuously diﬀerentiable is important;
see Exercise 6.7.1.
It turns out that a similar theorem is true for functions f : Rn →Rn
from one Euclidean space to the same space. However, the condition that
f′(x0) is non-zero must be replaced with a slightly diﬀerent one, namely
that f′(x0) is invertible. We ﬁrst remark that the inverse of a linear
transformation is also linear:
Lemma 6.7.1. Let T : Rn →Rn be a linear transformation which is
also invertible. Then the inverse transformation T −1 : Rn →Rn is also
linear.
Proof. See Exercise 6.7.2.
We can now prove an important and useful theorem, arguably one
of the most important theorems in several variable diﬀerential calculus.
Theorem 6.7.2 (Inverse function theorem). Let E be an open subset
of Rn, and let f : E →Rn be a function which is continuously diﬀer-
entiable on E. Suppose x0 ∈E is such that the linear transformation
f′(x0) : Rn →Rn is invertible. Then there exists an open set U in
E containing x0, and an open set V in Rn containing f(x0), such that
f is a bijection from U to V . In particular, there is an inverse map
f−1 : V →U. Furthermore, this inverse map is diﬀerentiable at f(x0),
and
(f−1)′(f(x0)) = (f′(x0))−1.
Proof. We ﬁrst observe that once we know the inverse map f−1 is dif-
ferentiable, the formula (f−1)′(f(x0)) = (f′(x0))−1 is automatic. This
comes from starting with the identity
I = f−1 ◦f
on U, where I : Rn →Rn is the identity map Ix := x, and then
diﬀerentiating both sides using the chain rule at x0 to obtain
I′(x0) = (f−1)′(f(x0))f′(x0).
Since I′(x0) = I, we thus have (f−1)′(f(x0)) = (f′(x0))−1 as desired.
We remark that this argument shows that if f(x0) is not invertible,
then there is no way that an inverse f−1 can exist and be diﬀerentiable
at f(x0).

154
6.
Several variable diﬀerential calculus
Next, we observe that it suﬃces to prove the theorem under the
additional assumption f(x0) = 0. The general case then follows from
the special case by replacing f by a new function ˜f(x) := f(x) −f(x0)
and then applying the special case to ˜f (note that V will have to shift
by f(x0)). Note that f−1(y) = ˜f−1(y −f(x0)) (why?). Henceforth we
will always assume f(x0) = 0.
In a similar manner, one can make the assumption x0 = 0. The
general case then follows from this case by replacing f by a new function
˜f(x) := f(x + x0) and applying the special case to ˜f (note that E and
U will have to shift by x0). Note that f−1(y) = ˜f−1(y) + x0 - why?
Henceforth we will always assume x0 = 0.
Thus we now have that
f(0) = 0 and that f′(0) is invertible.
Finally, one can assume that f′(0) = I, where I : Rn →Rn is the
identity transformation Ix = x.
The general case then follows from
this case by replacing f with a new function ˜f : E →Rn deﬁned by
˜f(x) := f′(0)−1f(x), and applying the special case to this case. Note
from Lemma 6.7.1 that f′(0)−1 is a linear transformation. In particular,
we note that ˜f(0) = 0 and that
˜f′(0) = f′(0)−1f′(0) = I,
so by the special case of the inverse function theorem we know that
there exists an open set U ′ containing 0, and an open set V ′ containing
0, such that ˜f is a bijection from U ′ to V ′, and that ˜f−1 : V ′ →U ′
is diﬀerentiable at 0 with derivative I. But we have f(x) = f′(0) ˜f(x),
and hence f is a bijection from U ′ to f′(0)(V ′) (note that f′(0) is also
a bijection). Since f′(0) and its inverse are both continuous, f′(0)(V ′)
is open, and it certainly contains 0. Now consider the inverse function
f−1 : f′(0)(V ′) →U ′. Since f(x) = f′(0) ˜f(x), we see that f−1(y) =
˜f−1(f′(0)−1y) for all y ∈f′(0)(V ′) (why?
use the fact that ˜f is a
bijection from U ′ to V ′). In particular we see that f−1 is diﬀerentiable
at 0.
So all we have to do now is prove the inverse function theorem in the
special case, when x0 = 0, f(x0) = 0, and f′(x0) = I. Let g : E →Rn
denote the function f(x)−x. Then g(0) = 0 and g′(0) = 0. In particular
∂g
∂xj
(0) = 0

6.7.
The inverse function theorem in several variable calculus
155
for j = 1, . . . , n. Since g is continuously diﬀerentiable, there thus exists
a ball B(0, r) in E such that

∂g
∂xj
(x)
 ≤
1
2n2
for all x ∈B(0, r). (There is nothing particularly special about
1
2n2 , we
just need a nice small number here.) In particular, for any x ∈B(0, r)
and v = (v1, . . . , vn) we have
∥Dvg(x)∥=

n

j=1
vj
∂g
∂xj
(x)

≤
n

j=1
|vj|

∂g
∂xj
(x)

≤
n

j=1
∥v∥1
2n2 ≤1
2n∥v∥.
But now for any x, y ∈B(0, r), we have by the fundamental theorem of
calculus
g(y) −g(x) =
 1
0
d
dtg(x + t(y −x)) dt
=
 1
0
Dy−xg(x + t(y −x)) dt.
By the previous remark, the vectors Dy−xg(x + t(y −x)) have a magni-
tude of at most
1
2n∥y −x∥. Thus every component of these vectors has
magnitude at most
1
2n∥y −x∥. Thus every component of g(y)−g(x) has
magnitude at most
1
2n∥y −x∥, and hence g(y) −g(x) itself has magni-
tude at most 1
2∥y −x∥(actually, it will be substantially less than this,
but this bound will be enough for our purposes). In other words, g is a
contraction. By Lemma 6.6.6, the map f = g + I is thus one-to-one on
B(0, r), and the image f(B(0, r)) contains B(0, r/2). In particular we
have an inverse map f−1 : B(0, r/2) →B(0, r) deﬁned on B(0, r/2).
Applying the contraction bound with y = 0 we obtain in particular
that
∥g(x)∥≤1
2∥x∥

156
6.
Several variable diﬀerential calculus
for all x ∈B(0, r), and so by the triangle inequality
1
2∥x∥≤∥f(x)∥≤3
2∥x∥
for all x ∈B(0, r).
Now we set V := B(0, r/2) and U := f−1(B(0, r/2)).
Then by
construction f is a bijection from U to V . V is clearly open, and U =
f−1(V ) is also open since f is continuous. (Notice that if a set is open
relative to B(0, r), then it is open in Rn as well). Now we want to show
that f−1 : V →U is diﬀerentiable at 0 with derivative I−1 = I. In other
words, we wish to show that
lim
x→0;x∈V \{0}
∥f−1(x) −f−1(0) −I(x −0)∥
∥x∥
= 0.
Since f(0) = 0, we have f−1(0) = 0, and the above simpliﬁes to
lim
x→0;x∈V \{0}
∥f−1(x) −x∥
∥x∥
= 0.
Let (xn)∞
n=1 be any sequence in V \0 that converges to 0. By Proposition
3.1.5(b), it suﬃces to show that
lim
n→∞
∥f−1(xn) −xn∥
∥xn∥
= 0.
Write yn := f−1(xn). Then yn ∈B(0, r) and xn = f(yn). In particular
we have
1
2∥yn∥≤∥xn∥≤3
2∥yn∥
and so since ∥xn∥goes to 0, ∥yn∥goes to zero also, and their ratio
remains bounded. It will thus suﬃce to show that
lim
n→∞
∥yn −f(yn)∥
∥yn∥
= 0.
But since yn is going to 0, and f is diﬀerentiable at 0, we have
lim
n→∞
∥f(yn) −f(0) −f′(0)(yn −0)∥
∥yn∥
= 0
as desired (since f(0) = 0 and f′(0) = I).

6.8.
The implicit function theorem
157
The inverse function theorem gives a useful criterion for when a func-
tion is (locally) invertible at a point x0 - all we need is for its derivative
f′(x0) to be invertible (and then we even get further information, for
instance we can compute the derivative of f−1 at f(x0)). Of course, this
begs the question of how one can tell whether the linear transformation
f′(x0) is invertible or not. Recall that we have f′(x0) = LDf(x0), so by
Lemmas 6.1.13 and 6.1.16 we see that the linear transformation f′(x0)
is invertible if and only if the matrix Df(x0) is. There are many ways
to check whether a matrix such as Df(x0) is invertible; for instance, one
can use determinants, or alternatively Gaussian elimination methods.
We will not pursue this matter here, but refer the reader to any linear
algebra text.
If f′(x0) exists but is non-invertible, then the inverse function theo-
rem does not apply. In such a situation it is not possible for f−1 to exist
and be diﬀerentiable at x0; this was remarked in the above proof. But
it is still possible for f to be invertible. For instance, the single-variable
function f : R →R deﬁned by f(x) = x3 is invertible despite f′(0) not
being invertible.
— Exercises —
Exercise 6.7.1. Let f : R →R be the function deﬁned by f(x) := x +
x2 sin(1/x4) for x ̸= 0 and f(0) := 0.
Show that f is diﬀerentiable and
f ′(0) = 1, but f is not increasing on any open set containing 0 (Hint: show
that the derivative of f can turn negative arbitrarily close to 0. Drawing a
graph of f may aid your intuition.)
Exercise 6.7.2. Prove Lemma 6.7.1.
Exercise 6.7.3. Let f : Rn →Rn be a continuously diﬀerentiable function such
that f ′(x) is an invertible linear transformation for every x ∈Rn. Show that
whenever V is an open set in Rn, that f(V ) is also open. (Hint: use the inverse
function theorem.)
6.8
The implicit function theorem
Recall (from Exercise 3.5.10) that a function f : R →R gives rise to a
graph
{(x, f(x)) : x ∈R}
which is a subset of R2, usually looking like a curve. However, not all
curves are graphs, they must obey the vertical line test, that for every
x there is exactly one y such that (x, y) is in the curve. For instance,
the circle {(x, y) ∈R2 : x2 + y2 = 1} is not a graph, although if one

158
6.
Several variable diﬀerential calculus
restricts to a semicircle such as {(x, y) ∈R2 : x2 + y2 = 1, y > 0} then
one again obtains a graph. Thus while the entire circle is not a graph,
certain local portions of it are. (The portions of the circle near (1, 0)
and (−1, 0) are not graphs over the variable x, but they are graphs over
the variable y).
Similarly, any function g
:
Rn
→
R gives rise to a graph
{(x, g(x)) : x ∈Rn} in Rn+1, which in general looks like some sort
of n-dimensional surface in Rn+1 (the technical term for this is a hy-
persurface). Conversely, one may ask which hypersurfaces are actually
graphs of some function, and whether that function is continuous or
diﬀerentiable.
If the hypersurface is given geometrically, then one can again invoke
the vertical line test to work out whether it is a graph or not.
But
what if the hypersurface is given algebraically, for instance the surface
{(x, y, z) ∈R3 : xy + yz + zx = −1}? Or more generally, a hypersurface
of the form {x ∈Rn : g(x) = 0}, where g : Rn →R is some function?
In this case, it is still possible to say whether the hypersurface is a graph,
locally at least, by means of the implicit function theorem.
Theorem 6.8.1 (Implicit function theorem). Let E be an open subset of
Rn, let f : E →R be continuously diﬀerentiable, and let y = (y1, . . . , yn)
be a point in E such that f(y) = 0 and
∂f
∂xn (y) ̸= 0. Then there exists an
open subset U of Rn−1 containing (y1, . . . , yn−1), an open subset V of E
containing y, and a function g : U →R such that g(y1, . . . , yn−1) = yn,
and
{(x1, . . . , xn) ∈V : f(x1, . . . , xn) = 0}
= {(x1, . . . , xn−1, g(x1, . . . , xn−1)) : (x1, . . . , xn−1) ∈U}.
In other words, the set {x ∈V : f(x) = 0} is a graph of a function over
U. Moreover, g is diﬀerentiable at (y1, . . . , yn−1), and we have
∂g
∂xj
(y1, . . . , yn−1) = −∂f
∂xj
(y)/ ∂f
∂xn
(y)
(6.1)
for all 1 ≤j ≤n −1.
Remark 6.8.2. The equation (6.1) is sometimes derived using implicit
diﬀerentiation. Basically, the point is that if you know that
f(x1, . . . , xn) = 0

6.8.
The implicit function theorem
159
then (as long as
∂f
∂xn ̸= 0) the variable xn is “implicitly” deﬁned in terms
of the other n −1 variables, and one can diﬀerentiate the above identity
in, say, the xj direction using the chain rule to obtain
∂f
∂xj
+ ∂f
∂xn
∂xn
∂xj
= 0
which is (6.1) in disguise (we are using g to represent the implicit func-
tion deﬁning xn in terms of x1, . . . , xn).
Thus, the implicit function
theorem allows one to deﬁne a dependence implicitly, by means of a con-
straint rather than by a direct formula of the form xn = g(x1, . . . , xn−1).
Proof. This theorem looks somewhat fearsome, but actually it is a fairly
quick consequence of the inverse function theorem. Let F : E →Rn be
the function
F(x1, . . . , xn) := (x1, . . . , xn−1, f(x1, . . . , xn)).
This function is continuously diﬀerentiable. Also note that
F(y) = (y1, . . . , yn−1, 0)
and
DF(y) =
 ∂f
∂x1
(y)T , ∂f
∂x2
(y)T , . . . , ∂f
∂xn
(y)T

=
⎛
⎜
⎜
⎜
⎜
⎜
⎝
1
0
. . .
0
0
0
1
. . .
0
0
...
...
...
...
...
0
0
. . .
1
0
∂f
∂x1 (y)
∂f
∂x2 (y)
. . .
∂f
∂xn−1 (y)
∂f
∂xn (y)
⎞
⎟
⎟
⎟
⎟
⎟
⎠
.
Since
∂f
∂xn (y) is assumed by hypothesis to be non-zero, this matrix is
invertible; this can be seen either by computing the determinant, or
using row reduction, or by computing the inverse explicitly, which is
DF(y)−1 =
⎛
⎜
⎜
⎜
⎜
⎜
⎝
1
0
. . .
0
0
0
1
. . .
0
0
...
...
...
...
...
0
0
. . .
1
0
−∂f
∂x1 (y)/a
−∂f
∂x2 (y)/a
. . .
−
∂f
∂xn−1 (y)/a
1/a
⎞
⎟
⎟
⎟
⎟
⎟
⎠
,

160
6.
Several variable diﬀerential calculus
where we have written a =
∂f
∂xn (y) for short. Thus the inverse function
theorem applies, and we can ﬁnd an open set V in E containing y, and an
open set W in Rn containing F(y) = (y1, . . . , yn−1, 0), such that F is a
bijection from V to W, and that F −1 is diﬀerentiable at (y1, . . .,yn−1, 0).
Let us write F −1 in co-ordinates as
F −1(x) = (h1(x), h2(x), . . . , hn(x))
where x ∈W. Since F(F −1(x)) = x, we have hj(x1, . . . , xn) = xj for all
1 ≤j ≤n −1 and x ∈W, and
f(x1, . . . , xn−1, hn(x1, . . . , xn)) = xn.
Also, hn is diﬀerentiable at (y1, . . . , yn−1, 0) since F −1 is.
Now we set U := {(x1, . . . , xn−1) ∈Rn−1 : (x1, . . . , xn−1, 0) ∈W}.
Note that U is open and contains (y1, . . . , yn−1). Now we deﬁne g : U →
R by g(x1, . . . , xn−1) := hn(x1, . . . , xn−1, 0). Then g is diﬀerentiable at
(y1, . . . , yn−1). Now we prove that
{(x1, . . . , xn) ∈V : f(x1, . . . , xn) = 0}
= {(x1, . . . , xn−1, g(x1, . . . , xn−1)) : (x1, . . . , xn−1) ∈U}.
First suppose that (x1, . . . , xn) ∈V and f(x1, . . . , xn) = 0.
Then
we have F(x1, . . . , xn) = (x1, . . . , xn−1, 0), which lies in W.
Thus
(x1, . . . , xn−1) lies in U.
Applying F −1, we see that (x1, . . . , xn) =
F −1(x1, . . . , xn−1, 0). In particular xn = hn(x1, . . . , xn−1, 0), and hence
xn = g(x1, . . . , xn−1). Thus every element of the left-hand set lies in the
right-hand set. The reverse inclusion comes by reversing all the above
steps and is left to the reader.
Finally, we show the formula for the partial derivatives of g. From
the preceding discussion we have
f(x1, . . . , xn−1, g(x1, . . . , xn−1)) = 0
for all (x1, . . . , xn−1) ∈U. Since g is diﬀerentiable at (y1, . . . , yn−1), and
f is diﬀerentiable at (y1, . . . , yn−1, g(y1, . . . , yn−1)) = y, we may use the
chain rule, diﬀerentiating in xj, to obtain
∂f
∂xj
(y) + ∂f
∂xn
(y) ∂g
∂xj
(y1, . . . , yn−1) = 0
and the claim follows by simple algebra.

6.8.
The implicit function theorem
161
Example 6.8.3. Consider the surface S := {(x, y, z) ∈R3 : xy + yz +
zx = −1}, which we rewrite as {(x, y, z) ∈R3 : f(x, y, z) = 0}, where
f : R3 →R is the function f(x, y, z) := xy + yz + zx + 1. Clearly f is
continuously diﬀerentiable, and ∂f
∂z = y+x. Thus for any (x0, y0, z0) in S
with y0 +x0 ̸= 0, one can write this surface (near (x0, y0, z0)) as a graph
of the form {(x, y, g(x, y)) : (x, y) ∈U} for some open set U containing
(x0, y0), and some function g which is diﬀerentiable at (x0, y0). Indeed
one can implicitly diﬀerentiate to obtain that
∂g
∂x(x0, y0) = −y0 + z0
y0 + x0
and ∂g
∂y(x0, y0) = −x0 + z0
y0 + x0
.
In the implicit function theorem, if the derivative
∂f
∂xn equals zero at
some point, then it is unlikely that the set {x ∈Rn : f(x) = 0} can
be written as a graph of the xn variable in terms of the other n −1
variables near that point. However, if some other derivative
∂f
∂xj is zero,
then it would be possible to write the xj variable in terms of the other
n −1 variables, by a variant of the implicit function theorem. Thus
as long as the gradient ∇f is not entirely zero, one can write this set
{x ∈Rn : f(x) = 0} as a graph of some variable xj in terms of the
other n −1 variables. (The circle {(x, y) ∈R2 : x2 + y2 −1 = 0} is a
good example of this; it is not a graph of y in terms of x, or x in terms
of y, but near every point it is one of the two. And this is because the
gradient of x2 + y2 −1 is never zero on the circle.) However, if ∇f does
vanish at some point x0, then we say that f has a critical point at x0
and the behavior there is much more complicated. For instance, the set
{(x, y) ∈R2 : x2 −y2 = 0} has a critical point at (0, 0) and there the
set does not look like a graph of any sort (it is the union of two lines).
Remark 6.8.4. Sets which look like graphs of continuous functions at
every point have a name, they are called manifolds. Thus {x ∈Rn :
f(x) = 0} will be a manifold if it contains no critical points of f. The
theory of manifolds is very important in modern geometry (especially
diﬀerential geometry and algebraic geometry), but we will not discuss it
here as it is a graduate level topic.

Chapter 7
Lebesgue measure
In the previous chapter we discussed diﬀerentiation in several variable
calculus. It is now only natural to consider the question of integration in
several variable calculus. The general question we wish to answer is this:
given some subset Ω of Rn, and some real-valued function f : Ω →R,
is it possible to integrate f on Ω to obtain some number

Ω f? (It is
possible to consider other types of functions, such as complex-valued
or vector-valued functions, but this turns out not to be too diﬃcult
once one knows how to integrate real-valued functions, since one can
integrate a complex or vector valued function, by integrating each real-
valued component of that function separately.)
In one dimension we already have developed (in Chapter 11) the
notion of a Riemann integral

[a,b] f, which answers this question when
Ω is an interval Ω = [a, b], and f is Riemann integrable. Exactly what
Riemann integrability means is not important here, but let us just re-
mark that every piecewise continuous function is Riemann integrable,
and in particular every piecewise constant function is Riemann inte-
grable. However, not all functions are Riemann integrable. It is possible
to extend this notion of a Riemann integral to higher dimensions, but it
requires quite a bit of eﬀort and one can still only integrate “Riemann
integrable” functions, which turn out to be a rather unsatisfactorily
small class of functions. (For instance, the pointwise limit of Riemann
integrable functions need not be Riemann integrable, and the same goes
for an L2 limit, although we have already seen that uniform limits of
Riemann integrable functions remain Riemann integrable.)
Because of this, we must look beyond the Riemann integral to obtain
a truly satisfactory notion of integration, one that can handle even very
discontinuous functions. This leads to the notion of the Lebesgue inte-
gral, which we shall spend this chapter and the next constructing. The
162
© Springer Science+Business Media Singapore 2016 and Hindustan Book Agency 2015
T. Tao, Analysis II, Texts and Readings in Mathematics 38,
DOI 10.1007/978-981-10-1804-6_7

163
Lebesgue integral can handle a very large class of functions, including
all the Riemann integrable functions but also many others as well; in
fact, it is safe to say that it can integrate virtually any function that one
actually needs in mathematics, at least if one works on Euclidean spaces
and everything is absolutely integrable. (If one assumes the axiom of
choice, then there are still some pathological functions one can construct
which cannot be integrated by the Lebesgue integral, but these functions
will not come up in real-life applications.)
Before we turn to the details, we begin with an informal discussion.
In order to understand how to compute an integral

Ω f, we must ﬁrst
understand a more basic and fundamental question: how does one com-
pute the length/area/volume of Ω? To see why this question is connected
to that of integration, observe that if one integrates the function 1 on the
set Ω, then one should obtain the length of Ω (if Ω is one-dimensional),
the area of Ω (if Ω is two-dimensional), or the volume of Ω (if Ω is three-
dimensional). To avoid splitting into cases depending on the dimension,
we shall refer to the measure of Ω as either the length, area, volume, (or
hypervolume, etc.) of Ω, depending on what Euclidean space Rn we are
working in.
Ideally, to every subset Ω of Rn we would like to associate a non-
negative number m(Ω), which will be the measure of Ω (i.e., the length,
area, volume, etc.). We allow the possibility for m(Ω) to be zero (e.g., if
Ω is just a single point or the empty set) or for m(Ω) to be inﬁnite (e.g., if
Ω is all of Rn). This measure should obey certain reasonable properties;
for instance, the measure of the unit cube (0, 1)n := {(x1, . . . , xn) : 0 <
xi < 1} should equal 1, we should have m(A ∪B) = m(A) + m(B) if
A and B are disjoint, we should have m(A) ≤m(B) whenever A ⊆B,
and we should have m(x + A) = m(A) for any x ∈Rn (i.e., if we shift
A by the vector x the measure should be the same).
Remarkably, it turns out that such a measure does not exist; one
cannot assign a non-negative number to every subset of Rn which has the
above properties. This is quite a surprising fact, as it goes against one’s
intuitive concept of volume; we shall prove it later in these notes. (An
even more dramatic example of this failure of intuition is the Banach-
Tarski paradox, in which a unit ball in R3 is decomposed into ﬁve pieces,
and then the ﬁve pieces are reassembled via translations and rotations to
form two complete and disjoint unit balls, thus violating any concept of
conservation of volume; however we will not discuss this paradox here.)
What these paradoxes mean is that it is impossible to ﬁnd a reason-
able way to assign a measure to every single subset of Rn. However, we

164
7.
Lebesgue measure
can salvage matters by only measuring a certain class of sets in Rn -
the measurable sets. These are the only sets Ω for which we will deﬁne
the measure m(Ω), and once one restricts one’s attention to measurable
sets, one recovers all the above properties again. Furthermore, almost
all the sets one encounters in real life are measurable (e.g., all open and
closed sets will be measurable), and so this turns out to be good enough
to do analysis.
7.1
The goal: Lebesgue measure
Let Rn be a Euclidean space.
Our goal in this chapter is to deﬁne
a concept of measurable set, which will be a special kind of subset of
Rn, and for every such measurable set Ω ⊂Rn, we will deﬁne the
Lebesgue measure m(Ω) to be a certain number in [0, ∞]. The concept
of measurable set will obey the following properties:
(i) (Borel property) Every open set in Rn is measurable, as is every
closed set.
(ii) (Complementarity) If Ω is measurable, then Rn\Ω is also measur-
able.
(iii) (Boolean algebra property) If (Ωj)j∈J is any ﬁnite collection of
measurable sets (so J is ﬁnite), then the union 
j∈J Ωj and inter-
section 
j∈J Ωj are also measurable.
(iv) (σ-algebra property) If (Ωj)j∈J are any countable collection of
measurable sets (so J is countable), then the union 
j∈J Ωj and
intersection 
j∈J Ωj are also measurable.
Note that some of these properties are redundant; for instance, (iv)
will imply (iii), and once one knows all open sets are measurable, (ii) will
imply that all closed sets are measurable also. The properties (i-iv) will
ensure that virtually every set one cares about is measurable; though as
indicated in the introduction, there do exist non-measurable sets.
To every measurable set Ω, we associate the Lebesgue measure m(Ω)
of Ω, which will obey the following properties:
(v) (Empty set) The empty set ∅has measure m(∅) = 0.
(vi) (Positivity) We have 0 ≤m(Ω) ≤+∞for every measurable set Ω.

7.1.
The goal: Lebesgue measure
165
(vii) (Monotonicity) If A ⊆B, and A and B are both measurable, then
m(A) ≤m(B).
(viii) (Finite sub-additivity) If (Aj)j∈J are a ﬁnite collection of measur-
able sets, then m(
j∈J Aj) ≤
j∈J m(Aj).
(ix) (Finite additivity) If (Aj)j∈J are a ﬁnite collection of disjoint mea-
surable sets, then m(
j∈J Aj) = 
j∈J m(Aj).
(x) (Countable sub-additivity) If (Aj)j∈J are a countable collection of
measurable sets, then m(
j∈J Aj) ≤
j∈J m(Aj).
(xi) (Countable additivity) If (Aj)j∈J are a countable collection of dis-
joint measurable sets, then m(
j∈J Aj) = 
j∈J m(Aj).
(xii) (Normalization) The unit cube [0, 1]n = {(x1, . . . , xn) ∈Rn : 0 ≤
xj ≤1 for all 1 ≤j ≤n} has measure m([0, 1]n) = 1.
(xiii) (Translation invariance) If Ω is a measurable set, and x ∈Rn, then
x+Ω := {x+y : y ∈Ω} is also measurable, and m(x+Ω) = m(Ω).
Again, many of these properties are redundant; for instance the
countable additivity property can be used to deduce the ﬁnite addi-
tivity property, which in turn can be used to derive monotonicity (when
combined with the positivity property). One can also obtain the sub-
additivity properties from the additivity ones. Note that m(Ω) can be
+∞, and so in particular some of the sums in the above properties may
also equal +∞. (Since everything is positive we will never have to deal
with indeterminate forms such as −∞+ +∞.)
Our goal for this chapter can then be stated thus:
Theorem 7.1.1 (Existence of Lebesgue measure). .
There exists a
concept of a measurable set, and a way to assign a number m(Ω) to
every measurable subset Ω ⊆Rn, which obeys all of the properties (i)-
(xiii).
It turns out that Lebesgue measure is pretty much unique; any other
concept of measurability and measure which obeys axioms (i)-(xiii) will
largely coincide with the construction we give. However there are other
measures which obey only some of the above axioms; also, we may be in-
terested in concepts of measure for other domains than Euclidean spaces
Rn. This leads to measure theory, which is an entire subject in itself
and will not be pursued here; however we do remark that the concept

166
7.
Lebesgue measure
of measures is very important in modern probability, and in the ﬁner
points of analysis (e.g., in the theory of distributions).
7.2
First attempt: Outer measure
Before we construct Lebesgue measure, we ﬁrst discuss a somewhat naive
approach to ﬁnding the measure of a set - namely, we try to cover the
set by boxes, and then add up the volume of each box. This approach
will almost work, giving us a concept called outer measure which can be
applied to every set and obeys all of the properties (v)-(xiii) except for
the additivity properties (ix), (xi). Later we will have to modify outer
measure slightly to recover the additivity property.
We begin by starting with the notion of an open box.
Deﬁnition 7.2.1 (Open box). An open box (or box for short) B in Rn
is any set of the form
B =
n

i=1
(ai, bi) := {(x1, . . . , xn) ∈Rn : xi ∈(ai, bi) for all 1 ≤i ≤n},
where bi ≥ai are real numbers. We deﬁne the volume vol(B) of this
box to be the number
vol(B) :=
n

i=1
(bi −ai) = (b1 −a1)(b2 −a2) . . . (bn −an).
For instance, the unit cube (0, 1)n is a box, and has volume 1. In one
dimension n = 1, boxes are the same as open intervals. One can easily
check that in general dimension that open boxes are indeed open. Note
that if we have bi = ai for some i, then the box becomes empty, and has
volume 0, but we still consider this to be a box (albeit a rather silly one).
Sometimes we will use voln(B) instead of vol(B) to emphasize that we
are dealing with n-dimensional volume, thus for instance vol1(B) would
be the length of a one-dimensional box B, vol2(B) would be the area of
a two-dimensional box B, etc.
Remark 7.2.2. We of course expect the measure m(B) of a box to be
the same as the volume vol(B) of that box. This is in fact an inevitable
consequence of the axioms (i)-(xiii) (see Exercise 7.2.5).
Deﬁnition 7.2.3 (Covering by boxes). Let Ω ⊆Rn be a subset of Rn.
We say that a collection (Bj)j∈J of boxes cover Ω iﬀΩ ⊆
j∈J Bj.

7.2.
First attempt: Outer measure
167
Suppose Ω ⊆Rn can be covered by a ﬁnite or countable collection
of boxes (Bj)j∈J. If we wish Ω to be measurable, and if we wish to have
a measure obeying the monotonicity and sub-additivity properties (vii),
(viii), (x) and if we wish m(Bj) = vol(Bj) for every box j, then we must
have
m(Ω) ≤m
⎛
⎝
j∈J
Bj
⎞
⎠≤

j∈J
m(Bj) =

j∈J
vol(Bj).
We thus conclude
m(Ω) ≤inf
⎧
⎨
⎩

j∈J
vol(Bj) : (Bj)j∈J covers Ω; J at most countable
⎫
⎬
⎭.
Inspired by this, we deﬁne
Deﬁnition 7.2.4 (Outer measure). If Ω is a set, we deﬁne the outer
measure m∗(Ω) of Ω to be the quantity
m∗(Ω) := inf
⎧
⎨
⎩

j∈J
vol(Bj) : (Bj)j∈J covers Ω; J at most countable
⎫
⎬
⎭.
Since ∞
j=1 vol(Bj) is non-negative, we know that m∗(Ω) ≥0 for all
Ω. However, it is quite possible that m∗(Ω) could equal +∞. Note that
because we are allowing ourselves to use a countable number of boxes,
that every subset of Rn has at least one countable cover by boxes; in
fact Rn itself can be covered by countably many translates of the unit
cube (0, 1)n (how?). We will sometimes write m∗
n(Ω) instead of m∗(Ω)
to emphasize the fact that we are using n-dimensional outer measure.
Note that outer measure can be deﬁned for every single set (not just
the measurable ones), because we can take the inﬁmum of any non-empty
set. It obeys several of the desired properties of a measure:
Lemma 7.2.5 (Properties of outer measure). Outer measure has the
following six properties:
(v) (Empty set) The empty set ∅has outer measure m∗(∅) = 0.
(vi) (Positivity) We have 0 ≤m∗(Ω) ≤+∞for every measurable set
Ω.

168
7.
Lebesgue measure
(vii) (Monotonicity) If A ⊆B ⊆Rn, then m∗(A) ≤m∗(B).
(viii) (Finite sub-additivity) If (Aj)j∈J are a ﬁnite collection of subsets
of Rn, then m∗(
j∈J Aj) ≤
j∈J m∗(Aj).
(x) (Countable sub-additivity) If (Aj)j∈J are a countable collection of
subsets of Rn, then m∗(
j∈J Aj) ≤
j∈J m∗(Aj).
(xiii) (Translation invariance) If Ω is a subset of Rn, and x ∈Rn, then
m∗(x + Ω) = m∗(Ω).
Proof. See Exercise 7.2.1.
The outer measure of a closed box is also what we expect:
Proposition 7.2.6 (Outer measure of closed box). For any closed
box
B =
n

i=1
[ai, bi] := {(x1, . . . , xn) ∈Rn : xi ∈[ai, bi] for all 1 ≤i ≤n},
we have
m∗(B) =
n

i=1
(bi −ai).
Proof. Clearly, we can cover the closed box B = $n
i=1[ai, bi] by the open
box $n
i=1(ai −ε, bi + ε) for every ε > 0. Thus we have
m∗(B) ≤vol
 n

i=1
(ai −ε, bi + ε)

=
n

i=1
(bi −ai + 2ε)
for every ε > 0. Taking limits as ε →0, we obtain
m∗(B) ≤
n

i=1
(bi −ai).
To ﬁnish the proof, we need to show that
m∗(B) ≥
n

i=1
(bi −ai).

7.2.
First attempt: Outer measure
169
By the deﬁnition of m∗(B), it suﬃces to show that

j∈J
vol(Bj) ≥
n

i=1
(bi −ai)
whenever (Bj)j∈J is a ﬁnite or countable cover of B.
Since B is closed and bounded, it is compact (by the Heine-Borel
theorem, Theorem 1.5.7), and in particular every open cover has a ﬁ-
nite subcover (Theorem 1.5.8). Thus to prove the above inequality for
countable covers, it suﬃces to do it for ﬁnite covers (since if (Bj)j∈J′ is
a ﬁnite subcover of (Bj)j∈J then 
j∈J vol(Bj) will be greater than or
equal to 
j∈J′ vol(Bj)).
To summarize, our goal is now to prove that

j∈J
vol(B(j)) ≥
n

i=1
(bi −ai)
(7.1)
whenever (B(j))j∈J is a ﬁnite cover of $n
j=1[ai, bi]; we have changed the
subscript Bj to superscript B(j) because we will need the subscripts to
denote components.
To prove the inequality (7.1), we shall use induction on the dimension
n. First we consider the base case n = 1. Here B is just a closed interval
B = [a, b], and each box B(j) is just an open interval B(j) = (aj, bj). We
have to show that

j∈J
(bj −aj) ≥(b −a).
To do this we use the Riemann integral. For each j ∈J, let f(j) : R →R
be the function such that f(j)(x) = 1 when x ∈(aj, bj) and f(j)(x) = 0
otherwise. Then we have that f(j) is Riemann integrable (because it is
piecewise constant, and compactly supported) and
 ∞
−∞
f(j) = bj −aj.
Summing this over all j ∈J, and interchanging the integral with the
ﬁnite sum, we have
 ∞
−∞

j∈J
f(j) =

j∈J
bj −aj.

170
7.
Lebesgue measure
But since the intervals (aj, bj) cover [a, b], we have 
j∈J f(j)(x) ≥1 for
all x ∈[a, b] (why?). For all other values if x, we have 
j∈J f(j)(x) ≥0.
Thus
 ∞
−∞

j∈J
f(j) ≥

[a,b]
1 = b −a
and the claim follows by combining this inequality with the previous
equality. This proves (7.1) when n = 1.
Now assume inductively that n > 1, and we have already proven the
inequality (7.1) for dimensions n −1. We shall use a similar argument
to the preceding one. Each box B(j) is now of the form
B(j) =
n

i=1
(a(j)
i , b(j)
i ).
We can write this as
B(j) = A(j) × (a(j)
n , b(j)
n )
where A(j) is the n −1-dimensional box A(j) := $n−1
i=1 (a(j)
i , b(j)
i ). Note
that
vol(B(j)) = voln−1(A(j))(b(j)
n −a(j)
n )
where we have subscripted voln−1 by n −1 to emphasize that this is
n −1-dimensional volume being referred to here. We similarly write
B = A × [an, bn]
where A := $n−1
i=1 [ai, bi], and again note that
vol(B) = voln−1(A)(bn −an).
For each j ∈J, let f(j) be the function such that f(j)(xn) =
voln−1(A(j)) for all xn ∈(a(j)
n , b(j)
n ), and f(j)(xn) = 0 for all other xn.
Then f(j) is Riemann integrable and
 ∞
−∞
f(j) = voln−1(A(j))(b(j)
n −a(j)
n ) = vol(B(j))
and hence

j∈J
vol(B(j)) =
 ∞
−∞

j∈J
f(j).

7.2.
First attempt: Outer measure
171
Now let xn ∈[an, bn] and (x1, . . . , xn−1) ∈A. Then (x1, . . . , xn) lies in
B, and hence lies in one of the B(j). Clearly we have xn ∈(a(j)
n , b(j)
n ), and
(x1, . . . , xn−1) ∈A(j). In particular, we see that for each xn ∈[an, bn],
the set
{A(j) : j ∈J; xn ∈(a(j)
n , b(j)
n )}
of n −1-dimensional boxes covers A. Applying the inductive hypothesis
(7.1) at dimension n −1 we thus see that

j∈J:xn∈(a(j)
n ,b(j)
n )
voln−1(A(j)) ≥voln−1(A),
or in other words

j∈J
f(j)(xn) ≥voln−1(A).
Integrating this over [an, bn], we obtain

[an,bn]

j∈J
f(j) ≥voln−1(A)(bn −an) = vol(B)
and in particular
 ∞
−∞

j∈J
f(j) ≥voln−1(A)(bn −an) = vol(B)
since 
j∈J f(j) is always non-negative. Combining this with our pre-
vious identity for
 ∞
−∞

j∈J f(j) we obtain (7.1), and the induction is
complete.
Once we obtain the measure of a closed box, the corresponding result
for an open box is easy:
Corollary 7.2.7. For any open box
B =
n

i=1
(ai, bi) := {(x1, . . . , xn) ∈Rn : xi ∈(ai, bi) for all 1 ≤i ≤n},
we have
m∗(B) =
n

i=1
(bi −ai).
In particular, outer measure obeys the normalization (xii).

172
7.
Lebesgue measure
Proof. We may assume that bi > ai for all i, since if bi = ai this follows
from Lemma 7.2.5(v). Now observe that
n

i=1
[ai + ε, bi −ε] ⊂
n

i=1
(ai, bi) ⊂
n

i=1
[ai, bi]
for all ε > 0, assuming that ε is small enough that bi −ε > ai + ε for all
i. Applying Proposition 7.2.6 and Lemma 7.2.5(vii) we obtain
n

i=1
(bi −ai −2ε) ≤m∗
 n

i=1
(ai, bi)

≤
n

i=1
(bi −ai).
Sending ε →0 and using the squeeze test (Corollary 6.4.14), one obtains
the result.
We now compute some examples of outer measure on the real line
R.
Example 7.2.8. Let us compute the one-dimensional measure of R.
Since (−R, R) ⊂R for all R > 0, we have
m∗(R) ≥m∗((−R, R)) = 2R
by Corollary 7.2.7. Letting R →+∞we thus see that m∗(R) = +∞.
Example 7.2.9. Now let us compute the one-dimensional measure of
Q. From Proposition 7.2.6 we see that for each rational number Q, the
point {q} has outer measure m∗({q}) = 0. Since Q is clearly the union
Q = 
q∈Q{q} of all these rational points q, and Q is countable, we have
m∗(Q) ≤

q∈Q
m∗({q}) =

q∈Q
0 = 0,
and so m∗(Q) must equal zero. In fact, the same argument shows that
every countable set has measure zero. (This, incidentally, gives another
proof that the real numbers are uncountable, Corollary 8.3.4.)
Remark 7.2.10. One consequence of the fact that m∗(Q) = 0 is that
given any ε > 0, it is possible to cover the rationals Q by a countable
number of intervals whose total length is less than ε. This fact is some-
what un-intuitive; can you ﬁnd a more explicit way to construct such a
countable covering of Q by short intervals?

7.2.
First attempt: Outer measure
173
Example 7.2.11. Now let us compute the one-dimensional measure of
the irrationals R\Q. From ﬁnite sub-additivity we have
m∗(R) ≤m∗(R\Q) + m∗(Q).
Since Q has outer measure 0, and m∗(R) has outer measure +∞, we
thus see that the irrationals R\Q have outer measure +∞. A similar ar-
gument shows that [0, 1]\Q, the irrationals in [0, 1], have outer measure
1 (why?).
Example 7.2.12. By Proposition 7.2.6, the unit interval [0, 1] in R has
one-dimensional outer measure 1, but the unit interval {(x, 0) : 0 ≤x ≤
1} in R2 has two-dimensional outer measure 0. Thus one-dimensional
outer measure and two-dimensional outer measure are quite diﬀerent.
Note that the above remarks and countable additivity imply that the
entire x-axis of R2 has two-dimensional outer measure 0, despite the
fact that R has inﬁnite one-dimensional measure.
— Exercises —
Exercise 7.2.1. Prove Lemma 7.2.5. (Hint: you will have to use the deﬁnition
of inf, and probably introduce a parameter ε. You may have to treat separately
the cases when certain outer measures are equal to +∞. (viii) can be deduced
from (x) and (v). For (x), label the index set J as J = {j1, j2, j3, . . .}, and for
each Aj, pick a covering of Aj by boxes whose total volume is no larger than
m∗(Aj) + ε/2j.)
Exercise 7.2.2. Let A be a subset of Rn, and let B be a subset of Rm. Note that
the Cartesian product {(a, b) : a ∈A, b ∈B} is then a subset of Rn+m. Show
that m∗
n+m(A × B) ≤m∗
n(A)m∗
m(B). (It is in fact true that m∗
n+m(A × B) =
m∗
n(A)m∗
m(B), but this is substantially harder to prove).
In Exercises 7.2.3-7.2.5, we assume that Rn is a Euclidean space, and we
have a notion of measurable set in Rn (which may or may not coincide with
the notion of Lebesgue measurable set) and a notion of measure (which may
or may not co-incide with Lebesgue measure) which obeys axioms (i)-(xiii).
Exercise 7.2.3.
(a) Show that if A1 ⊆A2 ⊆A3 . . . is an increasing sequence of measur-
able sets (so Aj ⊆Aj+1 for every positive integer j), then we have
m(∞
j=1 Aj) = limj→∞m(Aj).
(b) Show that if A1 ⊇A2 ⊇A3 . . . is a decreasing sequence of measurable
sets (so Aj ⊇Aj+1 for every positive integer j), and m(A1) < +∞, then
we have m(∞
j=1 Aj) = limj→∞m(Aj).

174
7.
Lebesgue measure
Exercise 7.2.4. Show that for any positive integer q > 1, that the open box
(0, 1/q)n := {(x1, . . . , xn) ∈Rn : 0 < xj < 1/q for all 1 ≤j ≤n}
and the closed box
[0, 1/q]n := {(x1, . . . , xn) ∈Rn : 0 ≤xj ≤1/q for all 1 ≤j ≤n}
both measure q−n. (Hint: ﬁrst show that m((0, 1/q)n) ≤q−n for every q ≥1
by covering (0, 1)n by some translates of (0, 1/q)n. Using a similar argument,
show that m([0, 1/q]n) ≥q−n. Then show that m([0, 1/q]n\(0, 1/q)n) ≤ε for
every ε > 0, by covering the boundary of [0, 1/q]n with some very small boxes.)
Exercise 7.2.5. Show that for any box B, that m(B) = vol(B). (Hint: ﬁrst
prove this when the co-ordinates aj, bj are rational, using Exercise 7.2.4. Then
take limits somehow (perhaps using Q1) to obtain the general case when the
co-ordinates are real.)
Exercise 7.2.6. Use Lemma 7.2.5 and Proposition 7.2.6 to furnish another proof
that the reals are uncountable (i.e., reprove Corollary 8.3.4).
7.3
Outer measure is not additive
In light of Lemma 7.2.5, it would seem now that all we need to do is
to verify the additivity properties (ix), (xi), and we have everything we
need to have a usable measure. Unfortunately, these properties fail for
outer measure, even in one dimension.
Proposition 7.3.1 (Failure of countable additivity). There exists
a countable collection (Aj)j∈J of disjoint subsets of R, such that
m∗(
j∈J Aj) ̸= 
j∈J m∗(Aj).
Proof. We shall need some notation. Let Q be the rationals, and R be
the reals. We say that a set A ⊂R is a coset of Q if it is of the form
A = x+Q for some real number x. For instance,
√
2+Q is a coset of R,
as is Q itself, since Q = 0 + Q. Note that a coset A can correspond to
several values of x; for instance 2+Q is exactly the same coset as 0+Q.
Also observe that it is not possible for two cosets to partially overlap;
if x + Q intersects y + Q in even just a single point z, then x −y must
be rational (why? use the identity x −y = (x −z) −(y −z)), and thus
x + Q and y + Q must be equal (why?). So any two cosets are either
identical or distinct.
We observe that every coset A of the rationals R has a non-empty
intersection with [0, 1]. Indeed, if A is a coset, then A = x + Q for some

7.3.
Outer measure is not additive
175
real number x. If we then pick a rational number q in [−x, 1 −x] then
we see that x + q ∈[0, 1], and thus A ∩[0, 1] contains x + q.
Let R/Q denote the set of all cosets of Q; note that this is a set
whose elements are themselves sets (of real numbers). For each coset A
in R/Q, let us pick an element xA of A∩[0, 1]. (This requires us to make
an inﬁnite number of choices, and thus requires the axiom of choice, see
Section 8.4.) Let E be the set of all such xA, i.e., E := {xA : A ∈R/Q}.
Note that E ⊆[0, 1] by constrution.
Now consider the set
X =

q∈Q∩[−1,1]
(q + E).
Clearly this set is contained in [−1, 2] (since q + x ∈[−1, 2] whenever
q ∈[−1, 1] and x ∈E ⊆[0, 1]). We claim that this set contains the
interval [0, 1]. Indeed, for any y ∈[0, 1], we know that y must belong
to some coset A (for instance, it belongs to the coset y + Q). But we
also have xA belonging to the same coset, and thus y −xA is equal to
some rational q. Since y and xA both live in [0, 1], then q lives in [−1, 1].
Since y = q + xA, we have y ∈q + E, and hence y ∈X as desired.
We claim that
m∗(X) ̸=

q∈Q∩[−1,1]
m∗(q + E),
which would prove the claim. To see why this is true, observe that since
[0, 1] ⊆X ⊆[−1, 2], that we have 1 ≤m∗(X) ≤3 by monotonicity
and Proposition 7.2.6. For the right hand side, observe from translation
invariance that

q∈Q∩[−1,1]
m∗(q + E) =

q∈Q∩[−1,1]
m∗(E).
The set Q ∩[−1, 1] is countably inﬁnite (why?). Thus the right-hand
side is either 0 (if m∗(E) = 0) or +∞(if m∗(E) > 0). Either way, it
cannot be between 1 and 3, and the claim follows.
Remark 7.3.2. The above proof used the axiom of choice. This turns
out to be absolutely necessary; one can prove using some advanced tech-
niques in mathematical logic that if one does not assume the axiom of
choice, then it is possible to have a mathematical model where outer
measure is countably additive.

176
7.
Lebesgue measure
One can reﬁne the above argument, and show in fact that m∗is not
ﬁnitely additive either:
Proposition 7.3.3 (Failure of ﬁnite additivity). There exists a ﬁnite
collection (Aj)j∈J of disjoint subsets of R, such that
m∗
⎛
⎝
j∈J
Aj
⎞
⎠̸=

j∈J
m∗(Aj).
Proof. This is accomplished by an indirect argument. Suppose for sake
of contradiction that m∗was ﬁnitely additive.
Let E and X be the
sets introduced in Proposition 7.3.1. From countable sub-additivity and
translation invariance we have
m∗(X) ≤

q∈Q∩[−1,1]
m∗(q + E) =

q∈Q∩[−1,1]
m∗(E).
Since we know that 1 ≤m∗(X) ≤3, we thus have m∗(E) ̸= 0, since
otherwise we would have m∗(X) ≤0, a contradiction.
Since m∗(E) ̸= 0, there exists a ﬁnite integer n > 0 such that
m∗(E) > 1/n. Now let J be a ﬁnite subset of Q ∩[−1, 1] of cardinality
3n. If m∗were ﬁnitely additive, then we would have
m∗
⎛
⎝
q∈J
q + E
⎞
⎠=

q∈J
m∗(q + E) =

q∈J
m∗(E) > 3n 1
n = 3.
But we know that 
q∈J q+E is a subset of X, which has outer measure
at most 3. This contradicts monotonicity. Hence m∗cannot be ﬁnitely
additive.
Remark 7.3.4. The examples here are related to the Banach-Tarski
paradox, which demonstrates (using the axiom of choice) that one can
partition the unit ball in R3 into a ﬁnite number of pieces which, when
rotated and translated, can be reassembled to form two complete unit
balls! Of course, this partition involves non-measurable sets. We will
not present this paradox here as it requires some group theory which is
beyond the scope of this text.
7.4
Measurable sets
In the previous section we saw that certain sets were badly behaved with
respect to outer measure, in particular they could be used to contradict

7.4.
Measurable sets
177
ﬁnite or countable additivity. However, those sets were rather patho-
logical, being constructed using the axiom of choice and looking rather
artiﬁcial. One would hope to be able to exclude them and then somehow
recover ﬁnite and countable additivity. Fortunately, this can be done,
thanks to a clever deﬁnition of Constantin Carath´eodory (1873–1950):
Deﬁnition 7.4.1 (Lebesgue measurability). Let E be a subset of Rn.
We say that E is Lebesgue measurable, or measurable for short, iﬀwe
have the identity
m∗(A) = m∗(A ∩E) + m∗(A\E)
for every subset A of Rn. If E is measurable, we deﬁne the Lebesgue
measure of E to be m(E) = m∗(E); if E is not measurable, we leave
m(E) undeﬁned.
In other words, E being measurable means that if we use the set E
to divide up an arbitrary set A into two parts, we keep the additivity
property. Of course, if m∗were ﬁnitely additive then every set E would
be measurable; but we know from Proposition 7.3.3 that not every set
is ﬁnitely additive. One can think of the measurable sets as the sets for
which ﬁnite additivity works. We sometimes subscript m(E) as mn(E)
to emphasize the fact that we are using n-dimensional Lebesgue measure.
The above deﬁnition is somewhat hard to work with, and in practice
one does not verify a set is measurable directly from this deﬁnition.
Instead, we will use this deﬁnition to prove various useful properties of
measurable sets (Lemmas 7.4.2-7.4.11), and after that we will rely more
or less exclusively on the properties in those lemmas, and no longer need
to refer to the above deﬁnition.
We begin by showing that a large number of sets are indeed mea-
surable. The empty set E = ∅and the whole space E = Rn are clearly
measurable (why?). Here is another example of a measurable set:
Lemma 7.4.2 (Half-spaces are measurable). The half-space
{(x1, . . . , xn) ∈Rn : xn > 0}
is measurable.
Proof. See Exercise 7.4.3.
Remark 7.4.3. A similar argument will also show that any half-space
of the form {(x1, . . . , xn) ∈Rn : xj > 0} or {(x1, . . . , xn) ∈Rn : xj < 0}
for some 1 ≤j ≤n is measurable.

178
7.
Lebesgue measure
Now for some more properties of measurable sets.
Lemma 7.4.4 (Properties of measurable sets).
(a) If E is measurable, then Rn\E is also measurable.
(b) (Translation invariance) If E is measurable, and x ∈Rn, then
x + E is also measurable, and m(x + E) = m(E).
(c) If E1 and E2 are measurable, then E1 ∩E2 and E1 ∪E2 are mea-
surable.
(d) (Boolean algebra property) If E1, E2, . . . , EN are measurable, then
N
j=1 Ej and N
j=1 Ej are measurable.
(e) Every open box, and every closed box, is measurable.
(f ) Any set E of outer measure zero (i.e., m∗(E) = 0) is measurable.
Proof. See Exercise 7.4.4.
From Lemma 7.4.4, we have proven properties (ii), (iii), (xiii) on our
wish list of measurable sets, and we are making progress towards (i).
We also have ﬁnite additivity (property (ix) on our wish list):
Lemma 7.4.5 (Finite additivity). If (Ej)j∈J are a ﬁnite collection of
disjoint measurable sets and any set A (not necessarily measurable), we
have
m∗
⎛
⎝A ∩

j∈J
Ej
⎞
⎠=

j∈J
m∗(A ∩Ej).
Furthermore, we have m(
j∈J Ej) = 
j∈J m(Ej).
Proof. See Exercise 7.4.6.
Remark 7.4.6. Lemma 7.4.5 and Proposition 7.3.3, when combined,
imply that there exist non-measurable sets: see Exercise 7.4.5.
Corollary 7.4.7. If A ⊆B are two measurable sets, then B\A is also
measurable, and
m(B\A) = m(B) −m(A).
Proof. See Exercise 7.4.7.
Now we show countable additivity.

7.4.
Measurable sets
179
Lemma 7.4.8 (Countable additivity). If (Ej)j∈J are a countable col-
lection of disjoint measurable sets, then 
j∈J Ej is measurable, and
m(
j∈J Ej) = 
j∈J m(Ej).
Proof. Let E := 
j∈J Ej. Our ﬁrst task will be to show that E is mea-
surable. Thus, let A be an arbitrary set (not necessarily measurable);
we need to show that
m∗(A) = m∗(A ∩E) + m∗(A\E).
Since J is countable, we may write J = {j1, j2, j3, . . .}. Note that
A ∩E =
∞

k=1
(A ∩Ejk)
(why?) and hence by countable sub-additivity
m∗(A ∩E) ≤
∞

k=1
m∗(A ∩Ejk).
We rewrite this as
m∗(A ∩E) ≤sup
N≥1
N

k=1
m∗(A ∩Ejk).
Let FN be the set FN := N
k=1 Ejk. Since the A∩Ejk are all disjoint,
and their union is A ∩FN, we see from Lemma 7.4.5 that
N

k=1
m∗(A ∩Ejk) = m∗(A ∩FN)
and hence
m∗(A ∩E) ≤sup
N≥1
m∗(A ∩FN).
Now we look at A\E. Since FN ⊆E (why?), we have A\E ⊆A\FN
(why?). By monotonicity, we thus have
m∗(A\E) ≤m∗(A\FN)
for all N. In particular, we see that
m∗(A ∩E) + m∗(A\E) ≤sup
N≥1
m∗(A ∩FN) + m∗(A\E)

180
7.
Lebesgue measure
≤sup
N≥1
m∗(A ∩FN) + m∗(A\FN).
But from Lemma 7.4.5 we know that FN is measurable, and hence
m∗(A ∩FN) + m∗(A\FN) = m∗(A).
Putting this all together we obtain
m∗(A ∩E) + m∗(A\E) ≤m∗(A).
But from ﬁnite sub-additivity we have
m∗(A ∩E) + m∗(A\E) ≥m∗(A)
and the claim follows. This shows that E is measurable.
To ﬁnish the lemma, we need to show that m(E) is equal to

j∈J m(Ej). We ﬁrst observe from countable sub-additivity that
m(E) ≤

j∈J
m(Ej) =
∞

k=1
m(Ejk).
On the other hand, by ﬁnite additivity and monotonicity we have
m(E) ≥m(FN) =
N

k=1
m(Ejk).
Taking limits as N →∞we obtain
m(E) ≥
∞

k=1
m(Ejk)
and thus we have
m(E) =
∞

k=1
m(Ejk) =

j∈J
m(Ej)
as desired.
This proves property (xi) on our wish list. Next, we do countable
unions and intersections.
Lemma 7.4.9 (σ-algebra property). If (Ωj)j∈J are any countable col-
lection of measurable sets (so J is countable), then the union 
j∈J Ωj
and the intersection 
j∈J Ωj are also measurable.

7.4.
Measurable sets
181
Proof. See Exercise 7.4.8.
The ﬁnal property left to verify on our wish list is (a). We ﬁrst need
a preliminary lemma.
Lemma 7.4.10. Every open set can be written as a countable or ﬁnite
union of open boxes.
Proof. We ﬁrst need some notation. Call a box B = $n
i=1(ai, bi) rational
if all of its components ai, bi are rational numbers. Observe that there are
only a countable number of rational boxes (this is since a rational box
is described by 2n rational numbers, and so has the same cardinality
as Q2n. But Q is countable, and the Cartesian product of any ﬁnite
number of countable sets is countable; see Corollaries 8.1.14, 8.1.15).
We make the following claim: given any open ball B(x, r), there
exists a rational box B which is contained in B(x, r) and which contains
x. To prove this claim, write x = (x1, . . . , xn). For each 1 ≤i ≤n, let
ai and bi be rational numbers such that
xi −r
n < ai < xi < bi < xi + r
n.
Then it is clear that the box $n
i=1(ai, bi) is rational and contains x. A
simple computation using Pythagoras’ theorem (or the triangle inequal-
ity) also shows that this box is contained in B(x, r); we leave this to the
reader.
Now let E be an open set, and let Σ be the set of all rational boxes
B which are subsets of E, and consider the union 
B∈Σ B of all those
boxes. Clearly, this union is contained in E, since every box in Σ is
contained in E by construction. On the other hand, since E is open, we
see that for every x ∈E there is a ball B(x, r) contained in E, and by
the previous claim this ball contains a rational box which contains x. In
particular, x is contained in 
B∈Σ B. Thus we have
E =

B∈Σ
B
as desired; note that Σ is countable or ﬁnite because it is a subset of the
set of all rational boxes, which is countable.
Lemma 7.4.11 (Borel property). Every open set, and every closed set,
is Lebesgue measurable.

182
7.
Lebesgue measure
Proof. It suﬃces to do this for open sets, since the claim for closed sets
then follows by Lemma 7.4.4(a) (i.e., property (ii)). Let E be an open
set. By Lemma 7.4.10, E is the countable union of boxes. Since we
already know that boxes are measurable, and that the countable union
of measurable sets is measurable, the claim follows.
The construction of Lebesgue measure and its basic properties are
now complete. Now we make the next step in constructing the Lebesgue
integral - describing the class of functions we can integrate.
— Exercises —
Exercise 7.4.1. If A is an open interval in R, show that m∗(A) = m∗(A ∩
(0, ∞)) + m∗(A\(0, ∞)).
Exercise 7.4.2. If A is an open box in Rn, and E is the half-plane E :=
{(x1, . . . , xn) ∈Rn : xn > 0}, show that m∗(A) = m∗(A ∩E) + m∗(A\E).
(Hint: use Exercise 7.4.1.)
Exercise 7.4.3. Prove Lemma 7.4.2. (Hint: use Exercise 7.4.2.)
Exercise 7.4.4. Prove Lemma 7.4.4. (Hints: for (c), ﬁrst prove that
m∗(A) = m∗(A∩E1∩E2)+m∗(A∩E1\E2)+m∗(A∩E2\E1)+m∗(A\(E1∪E2)).
A Venn diagram may be helpful. Also you may need the ﬁnite sub-additivity
property. Use (c) to prove (d), and use (bd) and the various versions of Lemma
7.4.2 to prove (e)).
Exercise 7.4.5. Show that the set E used in the proof of Propositions 7.3.1 and
7.3.3 is non-measurable.
Exercise 7.4.6. Prove Lemma 7.4.5.
Exercise 7.4.7. Use Lemma 7.4.5 to prove Corollary 7.4.7.
Exercise 7.4.8. Prove Lemma 7.4.9. (Hint: for the countable union problem,
write J = {j1, j2, . . .}, write FN := N
k=1 Ωjk, and write EN := FN\FN−1, with
the understanding that F0 is the empty set. Then apply Lemma 7.4.8. For the
countable intersection problem, use what you just did and Lemma 7.4.4(a).)
Exercise 7.4.9. Let A ⊆R2 be the set A := [0, 1]2\Q2; i.e A consists of all
the points (x, y) in [0, 1]2 such that x and y are not both rational. Show that

7.5.
Measurable functions
183
A is measurable and m(A) = 1, but that A has no interior points. (Hint: it’s
easier to use the properties of outer measure and measure, including those in
the exercises above, than to try to do this problem from ﬁrst principles.)
Exercise 7.4.10. Let A ⊆B ⊆Rn. Show that if B is Lebesgue measurable
with measure zero, then A is also Lebesgue measurable with measure zero.
7.5
Measurable functions
In the theory of the Riemann integral, we are only able to integrate a
certain class of functions - the Riemann integrable functions. We will
now be able to integrate a much larger range of functions - the measur-
able functions. More precisely, we can only integrate those measurable
functions which are absolutely integrable - but more on that later.
Deﬁnition 7.5.1 (Measurable functions). Let Ω be a measurable subset
of Rn, and let f : Ω →Rm be a function. A function f is measurable
iﬀf−1(V ) is measurable for every open set V ⊆Rm.
As discussed earlier, most sets that we deal with in real life are
measurable, so it is only natural to learn that most functions we deal
with in real life are also measurable. For instance, continuous functions
are automatically measurable:
Lemma 7.5.2 (Continuous functions are measurable). Let Ω be a mea-
surable subset of Rn, and let f : Ω →Rm be continuous. Then f is also
measurable.
Proof. Let V be any open subset of Rm. Then since f is continuous,
f−1(V ) is open relative to Ω (see Theorem 2.1.5(c)), i.e., f−1(V ) = W∩Ω
for some open set W ⊆Rn (see Proposition 1.3.4(a)). Since W is open,
it is measurable; since Ω is measurable, W ∩Ω is also measurable.
Because of Lemma 7.4.10, we have an easy criterion to test whether
a function is measurable or not:
Lemma 7.5.3. Let Ω be a measurable subset of Rn, and let f : Ω →Rm
be a function. Then f is measurable if and only if f−1(B) is measurable
for every open box B.
Proof. See Exercise 7.5.1.

184
7.
Lebesgue measure
Corollary 7.5.4. Let Ω be a measurable subset of Rn, and let f : Ω →
Rm be a function. Suppose that f = (f1, . . . , fm), where fj : Ω →R is
the jth co-ordinate of f. Then f is measurable if and only if all of the
fj are individually measurable.
Proof. See Exercise 7.5.2.
Unfortunately, it is not true that the composition of two measur-
able functions is automatically measurable; however we can do the next
best thing: a continuous function applied to a measurable function is
measurable.
Lemma 7.5.5. Let Ω be a measurable subset of Rn, and let W be an
open subset of Rm. If f : Ω →W is measurable, and g : W →Rp is
continuous, then g ◦f : Ω →Rp is measurable.
Proof. See Exercise 7.5.3.
This has an immediate corollary:
Corollary 7.5.6. Let Ω be a measurable subset of Rn. If f : Ω →R is
a measurable function, then so is |f|, max(f, 0), and min(f, 0).
Proof. Apply Lemma 7.5.5 with g(x) := |x|, g(x) := max(x, 0), and
g(x) := min(x, 0).
A slightly less immediate corollary:
Corollary 7.5.7. Let Ω be a measurable subset of Rn. If f : Ω →R
and g : Ω →R are measurable functions, then so is f + g, f −g, fg,
max(f, g), and min(f, g). If g(x) ̸= 0 for all x ∈Ω, then f/g is also
measurable.
Proof. Consider f + g. We can write this as k ◦h, where h : Ω →R2
is the function h(x) = (f(x), g(x)), and k : R2 →R is the function
k(a, b) := a + b. Since f, g are measurable, then h is also measurable by
Corollary 7.5.4. Since k is continuous, we thus see from Lemma 7.5.5
that k ◦h is measurable, as desired. A similar argument deals with all
the other cases; the only thing concerning the f/g case is that the space
R2 must be replaced with {(a, b) ∈R2 : b ̸= 0} in order to keep the map
(a, b) →a/b continuous and well-deﬁned.

7.5.
Measurable functions
185
Another characterization of measurable functions is given by
Lemma 7.5.8. Let Ω be a measurable subset of Rn, and let f : Ω →
R be a function. Then f is measurable if and only if f−1((a, ∞)) is
measurable for every real number a.
Proof. See Exercise 7.5.4.
Inspired by this lemma, we extend the notion of a measurable func-
tion to the extended real number system R∗:= R ∪{+∞} ∪{−∞}:
Deﬁnition 7.5.9 (Measurable functions in the extended reals). Let Ω
be a measurable subset of Rn. A function f : Ω →R∗is said to be
measurable iﬀf−1((a, +∞]) is measurable for every real number a.
Note that Lemma 7.5.8 ensures that the notion of measurability for
functions taking values in the extended reals R∗is compatible with that
for functions taking values in just the reals R.
Measurability behaves well with respect to limits:
Lemma 7.5.10 (Limits of measurable functions are measurable). Let Ω
be a measurable subset of Rn. For each positive integer n, let fn : Ω →
R∗be a measurable function. Then the functions supn≥1 fn, infn≥1 fn,
lim supn→∞fn, and lim infn→∞fn are also measurable. In particular, if
the fn converge pointwise to another function f : Ω →R∗, then f is
also measurable.
Proof. We ﬁrst prove the claim about supn≥1 fn. Call this function g.
We have to prove that g−1((a, +∞]) is measurable for every a. But by
the deﬁnition of supremum, we have
g−1((a, +∞]) =

n≥1
f−1
n ((a, +∞])
(why?), and the claim follows since the countable union of measurable
sets is again measurable.
A similar argument works for infn≥1 fn. The claim for lim sup and
lim inf then follow from the identities
lim sup
n→∞fn = inf
N≥1 sup
n≥N
fn
and
lim inf
n→∞fn = sup
N≥1
inf
n≥N fn
(see Deﬁnition 6.4.6).

186
7.
Lebesgue measure
As you can see, just about anything one does to a measurable func-
tion will produce another measurable function. This is basically why
almost every function one deals with in mathematics is measurable. (In-
deed, the only way to construct non-measurable functions is via artiﬁcial
means such as invoking the axiom of choice.)
— Exercises —
Exercise 7.5.1. Prove Lemma 7.5.3. (Hint: use Lemma 7.4.10 and the σ-algebra
property.)
Exercise 7.5.2. Use Lemma 7.5.3 to deduce Corollary 7.5.4.
Exercise 7.5.3. Prove Lemma 7.5.5.
Exercise 7.5.4. Prove Lemma 7.5.8. (Hint: use Lemma 7.5.3. As a preliminary
step, you may need to show that if f −1((a, ∞)) is measurable for all a, then
f −1([a, ∞)) is also measurable for all a.)
Exercise 7.5.5. Let f : Rn →R be Lebesgue measurable, and let g : Rn →R
be a function which agrees with f outside of a set of measure zero, thus there
exists a set A ⊆Rn of measure zero such that f(x) = g(x) for all x ∈Rn\A.
Show that g is also Lebesgue measurable. (Hint: use Exercise 7.4.10.)

Chapter 8
Lebesgue integration
In Chapter 11, we approached the Riemann integral by ﬁrst integrating
a particularly simple class of functions, namely the piecewise constant
functions. Among other things, piecewise constant functions only attain
a ﬁnite number of values (as opposed to most functions in real life,
which can take an inﬁnite number of values).
Once one learns how
to integrate piecewise constant functions, one can then integrate other
Riemann integrable functions by a similar procedure.
We shall use a similar philosophy to construct the Lebesgue inte-
gral. We shall begin by considering a special subclass of measurable
functions - the simple functions. Then we will show how to integrate
simple functions, and then from there we will integrate all measurable
functions (or at least the absolutely integrable ones).
8.1
Simple functions
Deﬁnition 8.1.1 (Simple functions). Let Ω be a measurable subset of
Rn, and let f : Ω →R be a measurable function. We say that f is a
simple function if the image f(Ω) is ﬁnite. In other words, there exists
a ﬁnite number of real numbers c1, c2, . . . , cN such that for every x ∈Ω,
we have f(x) = cj for some 1 ≤j ≤N.
Example 8.1.2. Let Ω be a measurable subset of Rn, and let E be
a measurable subset of Ω. We deﬁne the characteristic function χE :
Ω →R by setting χE(x) := 1 if x ∈E, and χE(x) := 0 if x ̸∈E.
(In some texts, χE is also written 1E, and is referred to as an indicator
function). Then χE is a measurable function (why?), and is a simple
function, because the image χE(Ω) is {0, 1} (or {0} if E is empty, or {1}
if E = Ω).
187
© Springer Science+Business Media Singapore 2016 and Hindustan Book Agency 2015
T. Tao, Analysis II, Texts and Readings in Mathematics 38,
DOI 10.1007/978-981-10-1804-6_8

188
8.
Lebesgue integration
We remark on three basic properties of simple functions: that they
form a vector space, that they are linear combinations of characteris-
tic functions, and that they approximate measurable functions. More
precisely, we have the following three lemmas:
Lemma 8.1.3. Let Ω be a measurable subset of Rn, and let f : Ω →R
and g : Ω →R be simple functions. Then f +g is also a simple function.
Also, for any scalar c ∈R, the function cf is also a simple function.
Proof. See Exercise 8.1.1.
Lemma 8.1.4. Let Ω be a measurable subset of Rn, and let f : Ω →
R be a simple function.
Then there exists a ﬁnite number of real
numbers c1, . . . , cN, and a ﬁnite number of disjoint measurable sets
E1, E2, . . . , EN in Ω, such that f = N
i=1 ciχEi.
Proof. See Exercise 8.1.2.
Lemma 8.1.5. Let Ω be a measurable subset of Rn, and let f : Ω →R
be a measurable function. Suppose that f is always non-negative, i.e.,
f(x) ≥0 for all x ∈Ω. Then there exists a sequence f1, f2, f3, . . . of
simple functions, fn : Ω →R, such that the fn are non-negative and
increasing,
0 ≤f1(x) ≤f2(x) ≤f3(x) ≤. . . for all x ∈Ω
and converge pointwise to f:
lim
n→∞fn(x) = f(x) for all x ∈Ω.
Proof. See Exercise 8.1.3.
We now show how to compute the integral of simple functions.
Deﬁnition 8.1.6 (Lebesgue integral of simple functions). Let Ω be a
measurable subset of Rn, and let f : Ω →R be a simple function which
is non-negative; thus f is measurable and the image f(Ω) is ﬁnite and
contained in [0, ∞). We then deﬁne the Lebesgue integral

Ω f of f on
Ω by

Ω
f :=

λ∈f(Ω);λ>0
λm({x ∈Ω : f(x) = λ}).

8.1.
Simple functions
189
We will also sometimes write

Ω f as

Ω f dm (to emphasize the
rˆole of Lebesgue measure m) or use a dummy variable such as x, e.g.,

Ω f(x) dx.
Example 8.1.7. Let f : R →R be the function which equals 3 on the
interval [1, 2], equals 4 on the integral (2, 4), and is zero everywhere else.
Then

Ω
f := 3 × m([1, 2]) + 4 × m((2, 4)) = 3 × 1 + 4 × 2 = 11.
Or if g : R →R is the function which equals 1 on [0, ∞) and is zero
everywhere else, then

Ω
g = 1 × m([0, ∞)) = 1 × +∞= +∞.
Thus the simple integral of a simple function can equal +∞. (The reason
why we restrict this integral to non-negative functions is to avoid ever
encountering the indeﬁnite form +∞+ (−∞)).
Remark 8.1.8. Note that this deﬁnition of integral corresponds to one’s
intuitive notion of integration (at least of non-negative functions) as the
area under the graph of the function (or volume, if one is in higher
dimensions).
Another formulation of the integral for non-negative simple functions
is as follows.
Lemma 8.1.9. Let Ω be a measurable subset of Rn, and let E1, . . . , EN
are a ﬁnite number of disjoint measurable subsets in Ω. Let c1, . . . , cN
be non-negative numbers (not necessarily distinct). Then we have

Ω
N

j=1
cjχEj =
n

j=1
cjm(Ej).
Proof. We can assume that none of the cj are zero, since we can just
remove them from the sum on both sides of the equation. Let f :=
N
j=1 cjχEj. Then f(x) is either equal to one of the cj (if x ∈Ej) or
equal to 0 (if x ̸∈N
j=1 Ej). Thus f is a simple function, and f(Ω) ⊆

190
8.
Lebesgue integration
{0} ∪{cj : 1 ≤j ≤N}. Thus, by the deﬁnition,

Ω
f =

λ∈{cj:1≤j≤N}
λm({x ∈Ω : f(x) = λ})
=

λ∈{cj:1≤j≤N}
λm(

1≤j≤N:cj=λ
Ej).
But by the ﬁnite additivity property of Lebesgue measure, this is equal
to

λ∈{cj:1≤j≤N}
λ

1≤j≤N:cj=λ
m(Ej)

λ∈{cj:1≤j≤N}

1≤j≤N:cj=λ
cjm(Ej).
Each j appears exactly once in this sum, since cj is only equal to exactly
one value of λ. So the above expression is equal to 
1≤j≤N cjm(Ej) as
desired.
Some basic properties of Lebesgue integration of non-negative simple
functions:
Proposition 8.1.10. Let Ω be a measurable set, and let f : Ω →R and
g : Ω →R be non-negative simple functions.
(a) We have 0 ≤

Ω f ≤∞. Furthermore, we have

Ω f = 0 if and
only if m({x ∈Ω : f(x) ̸= 0}) = 0.
(b) We have

Ω(f + g) =

Ω f +

Ω g.
(c) For any positive number c, we have

Ω cf = c

Ω f.
(d) If f(x) ≤g(x) for all x ∈Ω, then we have

Ω f ≤

Ω g.
We make a very convenient notational convention: if a property P(x)
holds for all points in Ω, except for a set of measure zero, then we say
that P holds for almost every point in Ω. Thus (a) asserts that

Ω f = 0
if and only if f is zero for almost every point in Ω.
Proof. From Lemma 8.1.4 or from the formula
f =

λ∈f(Ω)\{0}
λχ{x∈Ω:f(x)=λ}

8.1.
Simple functions
191
we can write f as a combination of characteristic functions, say
f =
N

j=1
cjχEj,
where E1, . . . , EN are disjoint subsets of Ω and the cj are positive. Sim-
ilarly we can write
g =
M

k=1
dkχFk
where F1, . . . , FM are disjoint subsets of Ω and the dk are positive.
(a) Since

Ω f = N
j=1 cjm(Ej) it is clear that the integral is between
0 and inﬁnity. If f is zero almost everywhere, then all of the Ej
must have measure zero (why?) and so

Ω f = 0. Conversely, if

Ω f = 0, then N
j=1 cjm(Ej) = 0, which can only happen when
all of the m(Ej) are zero (since all the cj are positive). But then
N
j=1 Ej has measure zero, and hence f is zero almost everywhere
in Ω.
(b) Write E0 := Ω\ N
j=1 Ej and c0 := 0, then we have Ω = E0 ∪E1 ∪
. . . ∪EN and
f =
N

j=0
cjχEj.
Similarly if we write F0 := Ω\ M
k=1 Fk and d0 := 0 then
g =
M

k=0
dkχFk.
Since Ω = E0 ∪. . . ∪EN = F0 ∪. . . ∪FM, we have
f =
N

j=0
M

k=0
cjχEj∩Fk
and
g =
M

k=0
N

j=0
dkχEj∩Fk

192
8.
Lebesgue integration
and hence
f + g =

0≤j≤N;0≤k≤M
(cj + dk)χEj∩Fk.
By Lemma 8.1.9, we thus have

Ω
(f + g) =

0≤j≤N;0≤k≤M
(cj + dk)m(Ej ∩Fk).
On the other hand, we have

Ω
f =

0≤j≤N
cjm(Ej) =

0≤j≤N;0≤k≤M
cjm(Ej ∩Fk)
and similarly

Ω
g =

0≤k≤M
dkm(Fk) =

0≤j≤N;0≤k≤M
dkm(Ej ∩Fk)
and the claim (b) follows.
(c) Since cf = N
j=1 ccjχEj, we have

Ω cf = N
j=1 ccjm(Ej). Since

Ω f = N
j=1 cjm(Ej), the claim follows.
(d) Write h := g−f. Then h is simple and non-negative and g = f +h,
hence by (b) we have

Ω g =

Ω f +

Ω h. But by (a) we have

Ω h ≥0, and the claim follows.
— Exercises —
Exercise 8.1.1. Prove Lemma 8.1.3.
Exercise 8.1.2. Prove Lemma 8.1.4.
Exercise 8.1.3. Prove Lemma 8.1.5. (Hint: set
fn(x) := sup{ j
2n : j ∈Z, j
2n ≤min(f(x), 2n)},
i.e., fn(x) is the greatest integer multiple of 2−n which does not exceed either

8.2.
Integration of non-negative measurable functions
193
f(x) or 2n. You may wish to draw a picture to see how f1, f2, f3, etc. works.
Then prove that fn obeys all the required properties.)
8.2
Integration of non-negative measurable functions
We now pass from the integration of non-negative simple functions to
the integration of non-negative measurable functions. We will allow our
measurable functions to take the value of +∞sometimes.
Deﬁnition 8.2.1 (Majorization). Let f : Ω →R and g : Ω →R be
functions. We say that f majorizes g, or g minorizes f, iﬀwe have
f(x) ≥g(x) for all x ∈Ω.
We sometimes use the phrase “f dominates g” instead of “f ma-
jorizes g”.
Deﬁnition 8.2.2 (Lebesgue integral for non-negative functions). Let Ω
be a measurable subset of Rn, and let f : Ω →[0, ∞] be measurable
and non-negative. Then we deﬁne the Lebesgue integral

Ω f of f on Ω
to be

Ω
f := sup
%
Ω
s : s is simple and non-negative, and minorizes f
&
.
Remark 8.2.3. The reader should compare this notion to that of a
lower Riemann integral from Deﬁnition 11.3.2. Interestingly, we will not
need to match this lower integral with an upper integral here.
Remark 8.2.4. Note that if Ω′ is any measurable subset of Ω, then we
can deﬁne

Ω′ f as well by restricting f to Ω′, thus

Ω′ f :=

Ω′ f|Ω′.
We have to check that this deﬁnition is consistent with our previous
notion of Lebesgue integral for non-negative simple functions; in other
words, if f : Ω →R is a non-negative simple function, then the value
of

Ω f given by this deﬁnition should be the same as the one given in
the previous deﬁnition. But this is clear because f certainly minorizes
itself, and any other non-negative simple function s which minorizes f
will have an integral

Ω s less than or equal to

Ω f, thanks to Proposition
8.1.10(d).
Remark 8.2.5. Note that

Ω f is always at least 0, since 0 is simple,
non-negative, and minorizes f. Of course,

Ω f could equal +∞.

194
8.
Lebesgue integration
Some basic properties of the Lebesgue integral on non-negative mea-
surable functions (which supercede Proposition 8.1.10):
Proposition 8.2.6. Let Ω be a measurable set, and let f : Ω →[0, ∞]
and g : Ω →[0, ∞] be non-negative measurable functions.
(a) We have 0 ≤

Ω f ≤∞. Furthermore, we have

Ω f = 0 if and
only if f(x) = 0 for almost every x ∈Ω.
(b) For any positive number c, we have

Ω cf = c

Ω f.
(c) If f(x) ≤g(x) for all x ∈Ω, then we have

Ω f ≤

Ω g.
(d) If f(x) = g(x) for almost every x ∈Ω, then

Ω f =

Ω g.
(e) If Ω′ ⊆Ω is measurable, then

Ω′ f =

Ω fχΩ′ ≤

Ω f.
Proof. See Exercise 8.2.1.
Remark 8.2.7. Proposition 8.2.6(d) is quite interesting; it says that
one can modify the values of a function on any measure zero set (e.g.,
you can modify a function on every rational number), and not aﬀect its
integral at all. It is as if no individual point, or even a measure zero
collection of points, has any “vote” in what the integral of a function
should be; only the collective set of points has an inﬂuence on an integral.
Remark 8.2.8. Note that we do not yet try to interchange sums and
integrals. From the deﬁnition it is fairly easy to prove that

Ω(f + g) ≥

Ω f +

Ω g (Exercise 8.2.2), but to prove equality requires more work
and will be done later.
As we have seen in previous chapters, we cannot always interchange
an integral with a limit (or with limit-like concepts such as supremum).
However, with the Lebesgue integral it is possible to do so if the functions
are increasing:
Theorem 8.2.9 (Lebesgue monotone convergence theorem). Let Ω be a
measurable subset of Rn, and let (fn)∞
n=1 be a sequence of non-negative
measurable functions from Ω to R which are increasing in the sense that
0 ≤f1(x) ≤f2(x) ≤f3(x) ≤. . . for all x ∈Ω.
(Note we are assuming that fn(x) is increasing with respect to n; this

8.2.
Integration of non-negative measurable functions
195
is a diﬀerent notion from fn(x) increasing with respect to x.) Then we
have
0 ≤

Ω
f1 ≤

Ω
f2 ≤

Ω
f3 ≤. . .
and

Ω
sup
n fn = sup
n

Ω
fn.
Proof. The ﬁrst conclusion is clear from Proposition 8.2.6(c). Now we
prove the second conclusion. From Proposition 8.2.6(c) again we have

Ω
sup
m fm ≥

Ω
fn
for every n; taking suprema in n we obtain

Ω
sup
m fm ≥sup
n

Ω
fn
which is one half of the desired conclusion. To ﬁnish the proof we have
to show

Ω
sup
m fm ≤sup
n

Ω
fn.
From the deﬁnition of

Ω supm fm, it will suﬃce to show that

Ω
s ≤sup
n

Ω
fn
for all simple non-negative functions which minorize supm fm.
Fix s. We will show that
(1 −ε)

Ω
s ≤sup
n

Ω
fn
for every 0 < ε < 1; the claim then follows by taking limits as ε →0.
Fix ε. By construction of s, we have
s(x) ≤sup
n fn(x)
for every x ∈Ω. Hence, for every x ∈Ω there exists an N (depending
on x) such that
fN(x) ≥(1 −ε)s(x).

196
8.
Lebesgue integration
Since the fn are increasing, this will imply that fn(x) ≥(1 −ε)s(x) for
all n ≥N. Thus, if we deﬁne the sets En by
En := {x ∈Ω : fn(x) ≥(1 −ε)s(x)}
then we have E1 ⊂E2 ⊂E3 ⊂. . . and ∞
n=1 En = Ω.
From Proposition 8.2.6(cdf) we have
(1 −ε)

En
s =

En
(1 −ε)s ≤

En
fn ≤

Ω
fn
so to ﬁnish the argument it will suﬃce to show that
sup
n

En
s =

Ω
s.
Since s is a simple function, we may write s = N
j=1 cjχFj for some
measurable Fj and positive cj. Since

Ω
s =
N

j=1
cjm(Fj)
and

En
s =

En
N

j=1
cjχFj∩En =
N

j=1
cjm(Fj ∩En)
it thus suﬃces to show that
sup
n m(Fj ∩En) = m(Fj)
for each j. But this follows from Exercise 7.2.3(a).
This theorem is extremely useful. For instance, we can now inter-
change addition and integration:
Lemma 8.2.10 (Interchange of addition and integration). Let Ω be a
measurable subset of Rn, and let f : Ω →[0, ∞] and g : Ω →[0, ∞] be
measurable functions. Then

Ω(f + g) =

Ω f +

Ω g.
Proof. By Lemma 8.1.5, there exists a sequence 0 ≤s1 ≤s2 ≤. . . ≤f
of simple functions such that supn sn = f, and similarly a sequence
0 ≤t1 ≤t2 ≤. . . ≤g of simple functions such that supn tn = g. Since
the sn are increasing and the tn are increasing, it is then easy to check

8.2.
Integration of non-negative measurable functions
197
that sn + tn is also increasing and supn(sn + tn) = f + g (why?). By the
monotone convergence theorem (Theorem 8.2.9) we thus have

Ω
f = sup
n

Ω
sn

Ω
g = sup
n

Ω
tn

Ω
(f + g) = sup
n

Ω
(sn + tn).
But by Proposition 8.1.9(b) we have

Ω(sn + tn) =

Ω sn +

Ω tn. By
Proposition 8.1.9(d),

Ω sn and

Ω tn are both increasing in n, so
sup
n

Ω
sn +

Ω
tn

=

sup
n

Ω
sn

+

sup
n

Ω
tn

and the claim follows.
Of course, once one can interchange an integral with a sum of two
functions, one can handle an integral and any ﬁnite number of functions
by induction. More surprisingly, one can handle inﬁnite sums as well of
non-negative functions:
Corollary 8.2.11. If Ω is a measurable subset of Rn, and g1, g2, . . .
are a sequence of non-negative measurable functions from Ω to [0, ∞],
then

Ω
∞

n=1
gn =
∞

n=1

Ω
gn.
Proof. See Exercise 8.2.3.
Remark 8.2.12. Note that we do not need to assume anything about
the convergence of the above sums; it may well happen that both sides
are equal to +∞. However, we do need to assume non-negativity; see
Exercise 8.2.4.
One could similarly ask whether we could interchange limits and
integrals; in other words, is it true that

Ω
lim
n→∞fn = lim
n→∞

Ω
fn.
Unfortunately, this is not true, as the following “moving bump” example
shows. For each n = 1, 2, 3 . . ., let fn : R →R be the function fn =

198
8.
Lebesgue integration
χ[n,n+1). Then limn→∞fn(x) = 0 for every x, but

R fn = 1 for every n,
and hence limn→∞

R fn = 1 ̸= 0. In other words, the limiting function
limn→∞fn can end up having signiﬁcantly smaller integral than any
of the original integrals. However, the following very useful lemma of
Fatou shows that the reverse cannot happen - there is no way the limiting
function has larger integral than the (limit of the) original integrals:
Lemma 8.2.13 (Fatou’s lemma). Let Ω be a measurable subset of Rn,
and let f1, f2, . . . be a sequence of non-negative functions from Ω to
[0, ∞]. Then

Ω
lim inf
n→∞fn ≤lim inf
n→∞

Ω
fn.
Proof. Recall that
lim inf
n→∞fn = sup
n

inf
m≥n fm

and hence by the monotone convergence theorem

Ω
lim inf
n→∞fn = sup
n

Ω

inf
m≥n fm

.
By Proposition 8.2.6(c) we have

Ω

inf
m≥n fm

≤

Ω
fj
for every j ≥n; taking inﬁma in j we obtain

Ω

inf
m≥n fm

≤inf
j≥n

Ω
fj.
Thus

Ω
lim inf
n→∞fn ≤sup
n inf
j≥n

Ω
fj = lim inf
n→∞

Ω
fn
as desired.
Note that we are allowing our functions to take the value +∞at
some points. It is even possible for a function to take the value +∞
but still have a ﬁnite integral; for instance, if E is a measure zero set,
and f : Ω →R is equal to +∞on E but equals 0 everywhere else, then

8.2.
Integration of non-negative measurable functions
199

Ω f = 0 by Proposition 8.2.6(a). However, if the integral is ﬁnite, the
function must be ﬁnite almost everywhere:
Lemma 8.2.14. Let Ω be a measurable subset of Rn, and let f : Ω →
[0, ∞] be a non-negative measurable function such that

Ω f is ﬁnite.
Then f is ﬁnite almost everywhere (i.e., the set {x ∈Ω : f(x) = +∞}
has measure zero).
Proof. See Exercise 8.2.5.
Form Corollary 8.2.11 and Lemma 8.2.14 one has a useful lemma:
Lemma 8.2.15 (Borel-Cantelli lemma). Let Ω1, Ω2, . . . be measurable
subsets of Rn such that ∞
n=1 m(Ωn) is ﬁnite. Then the set
{x ∈Rn : x ∈Ωn for inﬁnitely many n}
is a set of measure zero. In other words, almost every point belongs to
only ﬁnitely many Ωn.
Proof. See Exercise 8.2.6.
— Exercises —
Exercise 8.2.1. Prove Proposition 8.2.6. (Hint: do not attempt to mimic the
proof of Proposition 8.1.10; rather, try to use Proposition 8.1.10 and Deﬁnition
8.2.2. For one direction of part (a), start with

Ω f = 0 and conclude that
m({x ∈Ω : f(x) > 1/n}) = 0 for every n = 1, 2, 3, . . ., and then use the
countable sub-additivity. To prove (e), ﬁrst prove it for simple functions.)
Exercise 8.2.2. Let Ω be a measurable subset of Rn, and let f : Ω →[0, +∞]
and g : Ω →[0, +∞] be measurable functions. Without using Theorem 8.2.9
or Lemma 8.2.10, prove that

Ω(f + g) ≥

Ω f +

Ω g.
Exercise 8.2.3. Prove Corollary 8.2.11. (Hint: use the monotone convergence
theorem with fN := N
n=1 gn.)
Exercise 8.2.4. For each n = 1, 2, 3, . . ., let fn : R →R be the function
fn = χ[n,n+1) −χ[n+1,n+2); i.e., let fn(x) equal +1 when x ∈[n, n + 1), equal
−1 when x ∈[n + 1, n + 2), and 0 everywhere else. Show that

R
∞

n=1
fn ̸=
∞

n=1

R
fn.
Explain why this does not contradict Corollary 8.2.11.
Exercise 8.2.5. Prove Lemma 8.2.14.

200
8.
Lebesgue integration
Exercise 8.2.6. Use Corollary 8.2.11 and Lemma 8.2.14 to prove Lemma 8.2.15.
(Hint: use the indicator functions χΩn.)
Exercise 8.2.7. Let p > 2 and c > 0. Using the Borel-Cantelli lemma, show
that the set
{x ∈[0, 1] : |x −a
q | ≤c
qp for inﬁnitely many positive integers a, q}
has measure zero. (Hint: one only has to consider those integers a in the range
0 ≤a ≤q (why?). Use Corollary 11.6.5 to show that the sum ∞
q=1
c(q+1)
qp
is
ﬁnite.)
Exercise 8.2.8. Call a real number x ∈R diophantine if there exist real numbers
p, C > 0 such that |x −a
q | > C/|q|p for all non-zero integers q and all integers
a. Using Exercise 8.2.7, show that almost every real number is diophantine.
(Hint: ﬁrst work in the interval [0, 1]. Show that one can take p and C to be
rational and one can also take p > 2. Then use the fact that the countable
union of measure zero sets has measure zero.)
Exercise 8.2.9. For every positive integer n, let fn : R →[0, ∞) be a non-
negative measurable function such that

R
fn ≤1
4n .
Show that for every ε > 0, there exists a set E of Lebesgue measure m(E) ≤ε
such that fn(x) converges pointwise to zero for all x ∈R\E. (Hint: ﬁrst prove
that m({x ∈R : fn(x) >
1
ε2n }) ≤
ε
2n for all n = 1, 2, 3, . . ., and then consider
the union of all the sets {x ∈R : fn(x) >
1
ε2n }.)
Exercise 8.2.10. For every positive integer n, let fn : [0, 1] →[0, ∞) be a non-
negative measurable function such that fn converges pointwise to zero. Show
that for every ε > 0, there exists a set E of Lebesgue measure m(E) ≤ε such
that fn(x) converges uniformly to zero for all x ∈[0, 1]\E. (This is a special
case of Egoroﬀ’s theorem. To prove it, ﬁrst show that for any positive integer
m, we can ﬁnd an N > 0 such that m({x ∈[0, 1] : fn(x) > 1/m}) ≤ε/2m for
all n ≥N.) Is the claim still true if [0, 1] is replaced by R?
Exercise 8.2.11. Give an example of a bounded non-negative function f :
N × N →R+ such that ∞
m=1 f(n, m) converges for every n, and such that
limn→∞f(n, m) exists for every m, but such that
lim
n→∞
∞

m=1
f(n, m) ̸=
∞

m=1
lim
n→∞f(n, m).
(Hint: modify the moving bump example. It is even possible to use a function
f which only takes the values 0 and 1.) This shows that interchanging limits
and inﬁnite sums can be dangerous.

8.3.
Integration of absolutely integrable functions
201
8.3
Integration of absolutely integrable functions
We have now completed the theory of the Lebesgue integral for non-
negative functions. Now we consider how to integrate functions which
can be both positive and negative. However, we do wish to avoid the
indeﬁnite expression +∞+ (−∞), so we will restrict our attention to a
subclass of measurable functions - the absolutely integrable functions.
Deﬁnition 8.3.1 (Absolutely integrable functions). Let Ω be a mea-
surable subset of Rn. A measurable function f : Ω →R∗is said to be
absolutely integrable if the integral

Ω |f| is ﬁnite.
Of course, |f| is always non-negative, so this deﬁnition makes sense
even if f changes sign. Absolutely integrable functions are also known
as L1(Ω) functions.
If f : Ω →R∗is a function, we deﬁne the positive part f+ : Ω →
[0, ∞] and negative part f−: Ω →[0, ∞] by the formulae
f+ := max(f, 0);
f−:= −min(f, 0).
From Corollary 7.5.6 we know that f+ and f−are measurable. Observe
also that f+ and f−are non-negative, that f = f+ −f−, and |f| =
f+ + f−. (Why?).
Deﬁnition 8.3.2 (Lebesgue integral). Let f : Ω →R∗be an absolutely
integrable function. We deﬁne the Lebesgue integral

Ω f of f to be the
quantity

Ω
f :=

Ω
f+ −

Ω
f−.
Note that since f is absolutely integrable,

Ω f+ and

Ω f−are less
than or equal to

Ω |f| and hence are ﬁnite. Thus

Ω f is always ﬁnite;
we are never encountering the indeterminate form +∞−(+∞).
Note that this deﬁnition is consistent with our previous deﬁnition
of the Lebesgue integral for non-negative functions, since if f is non-
negative then f+ = f and f−= 0. We also have the useful triangle
inequality


Ω
f
 ≤

Ω
f+ +

Ω
f−=

Ω
|f|
(8.1)
(Exercise 8.3.1).

202
8.
Lebesgue integration
Some other properties of the Lebesgue integral:
Proposition 8.3.3. Let Ω be a measurable set, and let f : Ω →R and
g : Ω →R be absolutely integrable functions.
(a) For any real number c (positive, zero, or negative), we have that
cf is absolutely integrable and

Ω cf = c

Ω f.
(b) The function f +g is absolutely integrable, and

Ω(f +g) =

Ω f +

Ω g.
(c) If f(x) ≤g(x) for all x ∈Ω, then we have

Ω f ≤

Ω g.
(d) If f(x) = g(x) for almost every x ∈Ω, then

Ω f =

Ω g.
Proof. See Exercise 8.3.2.
As mentioned in the previous section, one cannot necessarily inter-
change limits and integrals, lim

fn =

lim fn, as the “moving bump
example” showed. However, it is possible to exclude the moving bump
example, and successfully interchange limits and integrals, if we know
that the functions fn are all majorized by a single absolutely integrable
function. This important theorem is known as the Lebesgue dominated
convergence theorem, and is extremely useful:
Theorem 8.3.4 (Lebesgue dominated convergence thm). Let Ω be a
measurable subset of Rn, and let f1, f2, . . . be a sequence of measur-
able functions from Ω to R∗which converge pointwise. Suppose also
that there is an absolutely integrable function F : Ω →[0, ∞] such that
|fn(x)| ≤F(x) for all x ∈Ω and all n = 1, 2, 3, . . .. Then

Ω
lim
n→∞fn = lim
n→∞

Ω
fn.
Proof. Let f : Ω →R∗be the function f(x) := limn→∞fn(x); this
function exists by hypothesis. By Lemma 7.5.10, f is measurable. Also,
since |fn(x)| ≤F(x) for all n and all x ∈Ω, we see that each fn is
absolutely integrable, and by taking limits we obtain |f(x)| ≤F(x) for
all x ∈Ω, so f is also absolutely integrable. Our task is to show that
limn→∞

Ω fn =

Ω f.
The functions F + fn are non-negative and converge pointwise to
F + f. So by Fatou’s lemma (Lemma 8.2.13)

Ω
F + f ≤lim inf
n→∞

Ω
F + fn

8.3.
Integration of absolutely integrable functions
203
and thus

Ω
f ≤lim inf
n→∞

Ω
fn.
But the functions F −fn are also non-negative and converge pointwise
to F −f. So by Fatou’s lemma again

Ω
F −f ≤lim inf
n→∞

Ω
F −fn.
Since the right-hand side is

Ω F −lim supn→∞

Ω fn (why did the lim
inf become a lim sup?), we thus have

Ω
f ≥lim sup
n→∞

Ω
fn.
Thus the lim inf and lim sup of

Ω fn are both equal to

Ω f, as desired.
Finally, we record a lemma which is not particularly interesting in
itself, but will have some useful consequences later in these notes.
Deﬁnition 8.3.5 (Upper and lower Lebesgue integral). Let Ω be a mea-
surable subset of Rn, and let f : Ω →R be a function (not necessarily
measurable). We deﬁne the upper Lebesgue integral

Ωf to be

Ω
f := inf{

Ω
g : g is an absolutely integrable function
from Ω to R that majorizes f}
and the lower Lebesgue integral

Ωf to be

Ω
f := sup{

Ω
g : g is an absolutely integrable function
from Ω to R that minorizes f}.
It is easy to see that

Ωf ≤

Ωf (why? use Proposition 8.3.3(c)).
When f is absolutely integrable then equality occurs (why?). The con-
verse is also true:
Lemma 8.3.6. Let Ω be a measurable subset of Rn, and let f : Ω →R
be a function (not necessarily measurable). Let A be a real number, and
suppose

Ωf =

Ωf = A. Then f is absolutely integrable, and

Ω
f =

Ω
f =

Ω
f = A.

204
8.
Lebesgue integration
Proof. By deﬁnition of upper Lebesgue integral, for every integer n ≥
1 we may ﬁnd an absolutely integrable function f+
n : Ω →R which
majorizes f such that

Ω
f+
n ≤A + 1
n.
Similarly we may ﬁnd an absolutely integrable function f−
n : Ω →R
which minorizes f such that

Ω
f−
n ≤A −1
n.
Let F + := infn f+
n and F −:= supn f−
n . Then F + and F −are mea-
surable (by Lemma 7.5.10) and absolutely integrable (because they are
squeezed between the absolutely integrable functions f+
1
and f−
1 , for
instance). Also, F + majorizes f and F −minorizes f. Finally, we have

Ω
F + ≤

Ω
f+
n ≤A + 1
n
for every n, and hence

Ω
F + ≤A.
Similarly we have

Ω
F −≥A.
but F + majorizes F −, and hence

Ω F + ≥

Ω F −. Hence we must have

Ω
F + =

Ω
F −= A.
In particular

Ω
F + −F −= 0.
By Proposition 8.2.6(a), we thus have F +(x) = F −(x) for almost every
x. But since f is squeezed between F −and F +, we thus have f(x) =
F +(x) = F −(x) for almost every x. In particular, f diﬀers from the
absolutely integrable function F + only on a set of measure zero and is
thus measurable (see Exercise 7.5.5) and absolutely integrable, with

Ω
f =

Ω
F + =

Ω
F −= A
as desired.

8.4.
Comparison with the Riemann integral
205
— Exercises —
Exercise 8.3.1. Prove (8.1) whenever Ω is a measurable subset of Rn and f is
an absolutely integrable function.
Exercise 8.3.2. Prove Proposition 8.3.3. (Hint: for (b), break f, g, and f + g
up into positive and negative parts, and try to write everything in terms of
integrals of non-negative functions only, using Lemma 8.2.10.)
Exercise 8.3.3. Let f : R →R and g : R →R be absolutely integrable,
measurable functions such that f(x) ≤g(x) for all x ∈R, and that

R f =

R g.
Show that f(x) = g(x) for almost every x ∈R (i.e., that f(x) = g(x) for all
x ∈R except possibly for a set of measure zero).
8.4
Comparison with the Riemann integral
We have spent a lot of eﬀort constructing the Lebesgue integral, but have
not yet addressed the question of how to actually compute any Lebesgue
integrals, and whether Lebesgue integration is any diﬀerent from the
Riemann integral (say for integrals in one dimension). Now we show
that the Lebesgue integral is a generalization of the Riemann integral.
To clarify the following discussion, we shall temporarily distinguish the
Riemann integral from the Lebesgue integral by writing the Riemann
integral

I f as R.

I f.
Our objective here is to prove
Proposition 8.4.1. Let I ⊆R be an interval, and let f : I →R be a
Riemann integrable function. Then f is also absolutely integrable, and

I f = R.

I f.
Proof. Write A := R.

I f. Since f is Riemann integrable, we know that
the upper and lower Riemann integrals are equal to A. Thus, for every
ε > 0, there exists a partition P of I into smaller intervals J such that
A −ε ≤

J∈P
|J| inf
x∈J f(x) ≤A ≤

J∈P
|J| sup
x∈J
f(x) ≤A + ε,
where |J| denotes the length of J. Note that |J| is the same as m(J),
since J is a box.
Let f−
ε : I →R and f+
ε : I →R be the functions
f−
ε (x) =

J∈P
inf
x∈J f(x)χJ(x)
and
f+
ε (x) =

J∈P
sup
x∈J
f(x)χJ(x);

206
8.
Lebesgue integration
these are simple functions and hence measurable and absolutely inte-
grable. By Lemma 8.1.9 we have

I
f−
ε =

J∈P
|J| inf
x∈J f(x)
and

I
f+
ε =

J∈P
|J| sup
x∈J
f(x)
and hence
A −ε ≤

I
f−
ε ≤A ≤

I
f+
ε ≤A + ε.
Since f+
ε majorizes f, and f−
ε minorizes f, we thus have
A −ε ≤

Ω
f ≤

Ω
f ≤A + ε
for every ε, and thus

Ω
f =

Ω
f = A
and hence by Lemma 8.3.6, f is absolutely integrable with

I f = A, as
desired.
Thus every Riemann integrable function is also Lebesgue integrable,
at least on bounded intervals, and we no longer need the R.

I f notation.
However, the converse is not true. Take for instance the function f :
[0, 1] →R deﬁned by f(x) := 1 when x is rational, and f(x) := 0 when
x is irrational. Then from Proposition 11.7.1 we know that f is not
Riemann integrable. On the other hand, f is the characteristic function
of the set Q ∩[0, 1], which is countable and hence measure zero. Thus
f is Lebesgue integrable and

[0,1] f = 0. Thus the Lebesgue integral
can handle more functions than the Riemann integral; this is one of the
primary reasons why we use the Lebesgue integral in analysis.
(The
other reason is that the Lebesgue integral interacts well with limits,
as the Lebesgue monotone convergence theorem, Fatou’s lemma, and
Lebesgue dominated convergence theorem already attest. There are no
comparable theorems for the Riemann integral).

8.5.
Fubini’s theorem
207
8.5
Fubini’s theorem
In one dimension we have shown that the Lebesgue integral is connected
to the Riemann integral. Now we will try to understand the connection
in higher dimensions.
To simplify the discussion we shall just study
two-dimensional integrals, although the arguments we present here can
easily be extended to higher dimensions.
We shall study integrals of the form

R2 f. Note that once we know
how to integrate on R2, we can integrate on measurable subsets Ω of
R2, since

Ω f can be rewritten as

R2 fχΩ.
Let f(x, y) be a function of two variables. In principle, we have three
diﬀerent ways to integrate f on R2. First of all, we can use the two-
dimensional Lebesgue integral, to obtain

R2 f. Secondly, we can ﬁx x
and compute a one-dimensional integral in y, and then take that quantity
and integrate in x, thus obtaining

R(

R f(x, y) dy) dx. Secondly, we
could ﬁx y and integrate in x, and then integrate in y, thus obtaining

R(

R f(x, y) dx) dy.
Fortunately, if the function f is absolutely integrable on f, then all
three integrals are equal:
Theorem 8.5.1 (Fubini’s theorem). Let f : R2 →R be an absolutely
integrable function.
Then there exists absolutely integrable functions
F : R →R and G : R →R such that for almost every x, f(x, y)
is absolutely integrable in y with
F(x) =

R
f(x, y) dy,
and for almost every y, f(x, y) is absolutely integrable in x with
G(y) =

R
f(x, y) dx.
Finally, we have

R
F(x) dx =

R2 f =

R
G(y) dy.
Remark 8.5.2. Very roughly speaking, Fubini’s theorem says that

R

R
f(x, y) dy

dx =

R2 f =

R

R
f(x, y) dx

dy.
This allows us to compute two-dimensional integrals by splitting them
into two one-dimensional integrals. The reason why we do not write

208
8.
Lebesgue integration
Fubini’s theorem this way, though, is that it is possible that the in-
tegral

R f(x, y) dy does not actually exist for every x, and similarly

R f(x, y) dx does not exist for every y; Fubini’s theorem only asserts
that these integrals only exist for almost every x and y. For instance, if
f(x, y) is the function which equals 1 when y > 0 and x = 0, equals −1
when y < 0 and x = 0, and is zero otherwise, then f is absolutely inte-
grable on R2 and

R2 f = 0 (since f equals zero almost everywhere in
R2), but

R f(x, y) dy is not absolutely integrable when x = 0 (though
it is absolutely integrable for every other x).
Proof. The proof of Fubini’s theorem is quite complicated and we will
only give a sketch here. We begin with a series of reductions.
Roughly speaking (ignoring issues relating to sets of measure zero),
we have to show that

R

R
f(x, y) dy

dx =

R2 f
together with a similar equality with x and y reversed. We shall just
prove the above equality, as the other one is very similar.
First of all, it suﬃces to prove the theorem for non-negative func-
tions, since the general case then follows by writing a general function f
as a diﬀerence f+ −f−of two non-negative functions, and applying Fu-
bini’s theorem to f+ and f−separately (and using Proposition 8.3.3(a)
and (b)). Thus we will henceforth assume that f is non-negative.
Next, it suﬃces to prove the theorem for non-negative functions f
supported on a bounded set such as [−N, N] × [−N, N] for some pos-
itive integer N.
Indeed, once one obtains Fubini’s theorem for such
functions, one can then write a general function f as the supremum of
such compactly supported functions as
f = sup
N>0
fχ[−N,N]×[−N,N],
apply Fubini’s theorem to each function fχ[−N,N]×[−N,N] separately, and
then take suprema using the monotone convergence theorem. Thus we
will henceforth assume that f is supported on [−N, N] × [−N, N].
By another similar argument, it suﬃces to prove the theorem for non-
negative simple functions supported on [−N, N]×[−N, N], since one can
use Lemma 8.1.4 to write f as the supremum of simple functions (which
must also be supported on [−N, N]), apply Fubini’s theorem to each
simple function, and then take suprema using the monotone convergence

8.5.
Fubini’s theorem
209
theorem. Thus we may assume that f is a non-negative simple function
supported on [−N, N] × [−N, N].
Next, we see that it suﬃces to prove the theorem for characteristic
functions supported in [−N, N]×[−N, N]. This is because every simple
function is a linear combination of characteristic functions, and so we can
deduce Fubini’s theorem for simple functions from Fubini’s theorem for
characteristic functions. Thus we may take f = χE for some measurable
E ⊆[−N, N] × [−N, N]. Our task is then to show (ignoring sets of
measure zero) that

[−N,N]

[−N,N]
χE(x, y) dy

dx = m(E).
It will suﬃce to show the upper Lebesgue integral estimate

[−N,N]

[−N,N]
χE(x, y) dy

dx ≤m(E).
(8.2)
We will prove this estimate later. Once we show this for every set E, we
may substitute E with [−N, N] × [−N, N]\E and obtain

[−N,N]

[−N,N]
(1 −χE(x, y)) dy

dx ≤4N2 −m(E).
But the left-hand side is equal to

[−N,N]
(2N −

[−N,N]
χE(x, y) dy) dx
which is in turn equal to
4N 2 −

[−N,N]

[−N,N]
χE(x, y) dy

dx
and thus we have

[−N,N]

[−N,N]
χE(x, y) dy

dx ≥m(E).

210
8.
Lebesgue integration
In particular we have

[−N,N]

[−N,N]
χE(x, y) dy

dx ≥m(E)
and hence by Lemma 8.3.6 we see that

[−N,N]χE(x, y) dy is absolutely
integrable and

[−N,N]

[−N,N]
χE(x, y) dy

dx = m(E).
A similar argument shows that

[−N,N]

[−N,N]
χE(x, y) dy

dx = m(E)
and hence

[−N,N]

[−N,N]
χE(x, y) dy −

[−N,N]
χE(x, y)

dx = 0.
Thus by Proposition 8.2.6(a) we have

[−N,N]
χE(x, y) dy =

[−N,N]
χE(x, y) dy
for almost every x ∈[−N, N]. Thus χE(x, y) is absolutely integrable in
y for almost every x, and

[−N,N] χE(x, y) is thus equal (almost every-
where) to a function F(x) such that

[−N,N]
F(x) dx = m(E)
as desired.
It remains to prove the bound (8.2). Let ε > 0 be arbitrary. Since
m(E) is the same as the outer measure m∗(E), we know that there exists
an at most countable collection (Bj)j∈J of boxes such that E ⊆
j∈J Bj
and

j∈J
m(Bj) ≤m(E) + ε.

8.5.
Fubini’s theorem
211
Each box Bj can be written as Bj = Ij × I′
j for some intervals Ij and
I′
j. Observe that
m(Bj) = |Ij||I′
j| =

Ij
|I′
j| dx =

Ij

I′
j
dy

dx
=

[−N,N]

[−N,N]
χIj×I′
j(x, y) dx

dy
=

[−N,N]

[−N,N]
χBj(x, y) dx

dy.
Adding this over all j ∈J (using Corollary 8.2.11) we obtain

j∈J
m(Bj) =

[−N,N]
⎛
⎝

[−N,N]

j∈J
χBj(x, y) dx
⎞
⎠dy.
In particular we have

[−N,N]
⎛
⎝

[−N,N]

j∈J
χBj(x, y) dx
⎞
⎠dy ≤m(E) + ε.
But 
j∈J χBj majorizes χE (why?) and thus

[−N,N]

[−N,N]
χE(x, y) dx

dy ≤m(E) + ε.
But ε is arbitrary, and so we have (8.2) as desired. This completes the
proof of Fubini’s theorem.

Index
π, 103, 104
σ-algebra, 164, 180
Abel’s theorem, 84
absolute value
for complex numbers, 96
absolutely integrable, 201
abstraction, 1
addition
of complex numbers, 94
(countably) additive measure,
164, 178
adherent point
of sets, 12
ambient space, 15
approximation to the identity,
67, 70, 118
arctangent:, see trigonometric
functions
associativity
of addition in C, 94
of scalar multiplication, 131
of vector addition, 128
ball, 11
Banach-Tarski paradox, 163,
176
base of the natural logarithm:,
see e
basis
standard basis of row
vectors, 128
Boolean algebra, 164, 178
Borel property, 164, 181
Borel-Cantelli lemma, 199
boundary (point), 11, 41
bounded
function, 54
set, 22
C, C0, C1, C2, Ck, 147
Cauchy sequence, 18
Cauchy-Schwarz inequality, 9,
112
chain rule
in higher dimensions, 144,
146
character, 114
characteristic function, 187
Clairaut’s theorem:, see
interchanging
derivatives with
derivatives
closed
box, 168
set, 13, 41
closure, 12, 41
cocountable topology, 43
coeﬃcient, 75
213
© Springer Science+Business Media Singapore 2016 and Hindustan Book Agency 2015
T. Tao, Analysis II, Texts and Readings in Mathematics 38,
DOI 10.1007/978-981-10-1804-6

214
Index
coﬁnite topology, 43
column vector, 128
commutativity
of addition in C, 94
of addition in vector
spaces, 128
of convolution, 68, 117
,see also: ring, ﬁeld, laws of
algebra
compactness, 21, 42
compact support, 67
completeness
of metric spaces, 19
of the space of continuous
functions, 57
completion of a metric space, 21
complex numbers C, 93
complex conjugation, 96
connectedness, 36
connected component, 39
continuity, 28, 41
and compactness, 34
and connectedness, 38
and convergence, 28
contraction, 149
mapping theorem, 150
convergence
in L2, 517, 112
of a function at a point, 46
of sequences, 6, 40
pointwise:, see pointwise
convergence
uniform:, see uniform
convergence
convolution, 68, 87, 117
coset, 174
cosine:, see trigonometric
functions
cotangent:, see trigonometric
functions
cover, 166
,see also: open cover
critical point, 161
de Moivre identities, 104
degree, 66
dense, 67
derivative
directional, 137
in higher dimensions, 135,
138, 143, 146
matrix, 143
partial, 138
total, 137, 146
uniqueness of, 136
diﬀerentiability
k-fold, 79, 147
continuous, 147
directional, 137
in higher dimensions, 135
inﬁnite, 79
diﬀerential matrix:, see
derivative matrix
dilation, 129
diophantine, 200
Dirac delta function, 67
direct sum
of functions, 32
discrete metric, 5
distance
in C, 98
in R, 2
distributive law
for complex numbers, 95
dominate: see majorize
dominated convergence:,
see Lebesgue

Index
215
dominated convergence
theorem
e, 90
Egoroﬀ’s theorem, 200
empty
set, 164, 167
error-correcting codes, 4
Euclidean metric, 3
Euclidean space, 3
Euler’s formula, 101, 103
Euler’s number:, see e
exponential function, 90, 99
exterior (point), 11, 40
Fatou’s lemma, 198
Fej´er kernel, 118
ﬁnite intersection property, 27
ﬁxed point theorem, 150
Fourier
coeﬃcients, 115
inversion formula, 115
series, 116
series for arbitrary periods,
125
theorem, 121
transform, 115
fractional part, 109
frequency, 114
Fubini’s theorem, 207
geodesic, 5
geometric series
formula, 63
gradient, 142
graph, 158
hairy ball theorem, 150
half-space, 177
Hausdorﬀspace, 42, 43
Heine-Borel theorem, 22
Hermitian form, 111
homogeneity, 112, 129
hypersurface, 158
identity map (or operator), 129
imaginary, 96
implicit diﬀerentiation, 158
implicit function theorem, 158
inconsistent, 101
indicator function:, see
characteristic function
induced
metric, 3, 16
topology, 16, 41
inner product, 110
integer part, 109
integration
by parts, 84
interchanging
derivatives with derivatives,
147
integrals with integrals,
198, 206
limits with derivatives, 65
limits with integrals, 64,
194, 202
limits with limits, 54
limits with sums, 200
sums with derivatives, 65,
77
sums with integrals, 62, 77,
197, 198, 200
interior (point), 11, 40
intermediate value theorem, 38
intrinsic, 22
inverse
function theorem, 153
invertible function: see
bijection
local, 153

216
Index
involution, 96
isometry, 15
l1, l2, l∞, L1, L2, L∞, 3–5, 111,
201
equivalence of in ﬁnite
dimensions, 7
,
see also: absolutely
integrable
laws of algebra
for complex numbers, 94,
95
laws of arithmetic:, see laws of
algebra
laws of exponentiation, 90
Lebesgue dominated
convergence theorem,
202
Lebesgue integral
of absolutely integrable
functions, 201
of nonnegative functions,
193
of simple functions, 188
upper and lower, 203
vs. the Riemann integral,
205
Lebesgue measurable, 177
Lebesgue measure, 165
motivation of, 164, 165
Lebesgue monotone
convergence theorem,
194
Leibnitz rule, 145
limit
formal (LIM), 21
laws, 98
limiting values of functions,
46
pointwise, 49
uniform, see uniform limit
uniqueness of, 8, 47
limit point
of sequences, 18
linear combination, 129
linearity
approximate, 134
of convolution, 72, 117
of inner product, 111
of integration, 191, 196
of transformations, 129
logarithm (natural), 91
power series of, 62, 91
majorize, 193
manifold, 161
map:, see function
matrix, 130
identiﬁcation with linear
transformations,
130–133
maximum
principle, 34
measurability
for functions, 183
for sets, 177
motivation of, 163
,see also: Lebesgue
measure, outer measure
metric, 2
ball:, see ball
on C, 98
on R, 3
space, 2
monomial, 114
monotone (increasing or
decreasing)

Index
217
convergence:, see Lebesgue
monotone convergence
theorem
measure, 165, 168
moving bump example, 50, 197
multiplication
of complex numbers, 95
of matrices, 130, 133
negation
of complex numbers, 96
neighbourhood, 40
Newton’s approximation, 136
non-degenerate, 112
nowhere diﬀerentiable function,
65, 105
of sets
adherent point, 41
open
box, 166
cover, 23
set, 13
order topology, 43
orthogonality, 112
orthonormal, 114
non-additivity of, 175
outer measure, 167
non-additivity of, 174
Parseval identity, 125
,see also: Plancherel
formula
path-connected, 38
periodic, 108
extension, 109
Plancherel formula (or
theorem), 116, 123
pointwise convergence, 48
of series, 59
topology of, 58
polar representation, 104
polynomial, 66
and convolution, 68
approximation by, 66, 71
positive
complex number, 96, 100
inner product, 111
measure, 164, 167
power series, 75
formal, 75
multiplication of, 87
uniqueness of, 81
pre-image:, see inverse image
product topology, 58
projection, 129
Pythagoras’ theorem, 112
Quotient rule, 146
radius of convergence, 75
real analytic, 78
real numbers R
are uncountable:, see
uncountability of the
reals
real part, 96
real-valued, 58
reciprocal
of complex numbers, 97
relative topology:, see induced
topology
ring
commutative, 95
root
mean square:, see L2
row vector, 127
scalar multiplication, 127
series
of functions, 62

218
Index
simple function, 187
sine:, see trigonometric
functions
space, 2
square wave, 109, 113
Stone-Weierstrass theorem, 73,
117
sub-additive measure, 165, 168
subsequence, 17
summation by parts, 84
sup norm:, see supremum as
norm
support, 67
supremum (and inﬁmum)
as metric, 4
as norm, 4, 59
taxi-cab metric, 3
Taylor series, 80
Taylor’s formula:, see Taylor
series
topological space, 39
totally bounded, 26
translation invariance, 165, 168,
178
transpose, 128
triangle inequality
for integrals, 201
in C, 97
in Euclidean space, 9
in inner product spaces,
112
in metric spaces, 2
trigonometric functions, 101,
106
and Fourier series, 124
power series, 101, 105
trigonometric polynomials,
114
trivial topology, 42
uniform continuity, 34
uniform convergence, 51
and anti-derivatives, 64
and derivatives, 54
and integrals, 62
and limits, 53
and radius of convergence,
75
as a metric, 56, 110
of series, 59
uniform limit
and Riemann integration,
61
of bounded functions, 54
of continuous functions, 53
vector space, 128
vertical line test, 68
volume, 166
Weierstrass M-test, 60
Weierstrass approximation
theorem, 66, 71–72, 116
Weierstrass example:, see
nowhere diﬀerentiable
function

Texts and Readings in Mathematics
1.  R. B. Bapat:  Linear Algebra and Linear Models (
 Edition)
2.  Rajendra Bhatia:  Fourier Series (Second Edition)
3.  C. Musili:  Representations of Finite Groups
4.  H. Helson:  Linear Algebra (Second Edition)
5.  D. Sarason:  Complex Function Theory (Second Edition)
6.  M. G. Nadkarni:  Basic Ergodic Theory (Third Edition)
7.  H. Helson:  Harmonic Analysis (Second Edition)
8.  K. Chandrasekharan:  A Course on Integration Theory
9.  K. Chandrasekharan:  A Course on Topological Groups
10. R. Bhatia (ed.):  Analysis, Geometry and Probability
11. K. R. Davidson:  C* – Algebras by Example (Reprint)
12. M. Bhattacharjee et al.:  Notes on Infinite Permutation Groups
13. V. S. Sunder:  Functional Analysis — Spectral Theory
14. V. S. Varadarajan:  Algebra in Ancient and Modern Times
15. M. G. Nadkarni:  Spectral Theory of Dynamical Systems
16. A. Borel:  Semisimple Groups and Riemannian Symmetric Spaces
17. M. Marcolli:  Seiberg – Witten Gauge Theory 
18. A. Bottcher and S. M. Grudsky:  Toeplitz Matrices, Asymptotic 
 
Linear Algebra and Functional Analysis
19. A. R. Rao and P. Bhimasankaram:  Linear Algebra (Second Edition)
20. C. Musili:  Algebraic Geometry for Beginners
21. A. R. Rajwade:  Convex Polyhedra with Regularity Conditions 
and Hilbert's Third Problem
22. S. Kumaresan:  A Course in Differential Geometry and Lie Groups 
23. Stef Tijs:  Introduction to Game Theory
24. B. Sury:  The Congruence Subgroup Problem
25. R. Bhatia (ed.):  Connected at Infinity
26. K. Mukherjea:  Differential Calculus in Normed Linear Spaces 
(Second Edition)
27. Satya Deo:  Algebraic Topology: A Primer (Corrected Reprint)
28. S. Kesavan:  Nonlinear Functional Analysis: A First Course
29. S. Szabó:  Topics in Factorization of Abelian Groups
30. S. Kumaresan and G. Santhanam:  An Expedition to Geometry
31. D. Mumford:  Lectures on Curves on an Algebraic Surface (Reprint)
32. J. W. Milnor and J. D. Stasheff:  Characteristic Classes (Reprint)
33. K. R. Parthasarathy:  Introduction to Probability and Measure 
(Corrected Reprint)
34. Amiya Mukherjee:  Topics in Differential Topology
35. K. R. Parthasarathy:  Mathematical Foundations of Quantum 
Mechanics
36. K. B. Athreya and S. N. Lahiri:  Measure Theory
37. Terence Tao: Analysis I (Third Edition)
38. Terence Tao: Analysis II (
 Edition)
Third
Third
219
© Springer Science+Business Media Singapore 2016 and Hindustan Book Agency 2015
T. Tao, Analysis II, Texts and Readings in Mathematics 38,
DOI 10.1007/978-981-10-1804-6

39. W. Decker and C. Lossen: Computing in Algebraic Geometry
40. A. Goswami and B. V. Rao: A Course in Applied Stochastic 
Processes
41. K. B. Athreya and S. N. Lahiri:  Probability Theory
42. A. R. Rajwade and A. K. Bhandari: Surprises and Counterexamples
in Real Function Theory
43. G. H. Golub and C. F. Van Loan: Matrix Computations (Reprint of the
Third Edition)
44. Rajendra Bhatia: Positive Definite Matrices
45. K. R. Parthasarathy:  Coding Theorems of Classical and Quantum 
Information Theory (Second Edition) 
46. C. S. Seshadri:  Introduction to the Theory of Standard Monomials 
(Second Edition)
47. Alain Connes and Matilde Marcolli:  Noncommutative Geometry, 
Quantum Fields and Motives
48. Vivek S. Borkar: Stochastic  Approximation: A  Dynamical  Systems  
Viewpoint
49. B. J. Venkatachala: Inequalities: An Approach Through Problems
50. Rajendra Bhatia: Notes on Functional Analysis
51. A. Clebsch (ed.): Jacobi's Lectures on Dynamics  
(Second Revised Edition)
52. S. Kesavan: Functional Analysis
53. V. Lakshmibai and Justin Brown: Flag Varieties: An Interplay of 
 Combinatorics, and Representation Theory
54. S. Ramasubramanian: Lectures on Insurance Models
55. Sebastian M. Cioaba and M. Ram Murty: A First Course in Graph Theory and 
Combinatorics
56. Bamdad R. Yahaghi: Iranian Mathematics Competitions, 1973-2007
57. Aloke Dey: Incomplete Block Designs
58  R. B. Bapat:  Graphs and Matrices
59. Hermann Weyl:  Algebraic Theory of Numbers (Reprint)
60. Carl Ludwig Siegel:  Transcendental Numbers (Reprint)
61. Steven J. Miller and Ramin Takloo-Bighash: An Invitation to Number Theory
(Reprint)
62. John Milnor: Dynamics in One Complex Variable  (Reprint)
63. R. P. Pakshirajan: Probability Theory: A Foundational Course
64. Sharad S. Sane: Combinatorial Techniques
65. Hermann Weyl: The Classical Groups: Their Invariants and Representations 
(Reprint)
66. John Milnor: Morse Theory (Reprint)
67. R. Bhatia (ed.):  Connected at Infinity II
68. Donald Passman: A Course in Ring Theory
69. Amiya Mukherjee: Atiyah-Singer Index Theorem: An Introduction
70. Fumio Hiai and Dénes Petz: Introduction to Matrix Analysis and Applications 
Geometry,
220
Texts and Readings in Mathematics

