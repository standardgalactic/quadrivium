Week 1
Capstone project 
and Recommender 
Systems

Python Data Products
Course 4: Implementing and Deploying data-driven predictive 
systems
Lecture: Introduction

Python Data Products
Course 4: Implementing and Deploying data-driven predictive 
systems
Lecture: Introduction to Recommender Systems

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Learning objectives
In this lecture we will...
• Motivate the problem of recommender systems as an 
important Data Product
• Describe several examples of recommender systems 
on the Web

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Why recommendation?
The goal of recommender systems is…
•
To help people discover new content

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Why recommendation?
The goal of recommender systems is…
•
To help us find the content we were already looking for
Are these 
recommendations 
good or bad?

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Why recommendation?
The goal of recommender systems is…
•
To discover which things go together

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Why recommendation?
The goal of recommender systems is…
•
To personalize user experiences in 
response to user feedback

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Why recommendation?
The goal of recommender systems is…
•
To recommend incredible products 
that are relevant to our interests

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Why recommendation?
The goal of recommender systems is…
•
To identify things that we like

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Recommendation in non-e-commerce 
The goal of recommender systems is…
• Priority Inbox
• Personalized 
Health
• Friend 
Recommendation

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Why recommendation?
The goal of recommender systems is…
•
To help people discover new content​
•
To help us find the content we were 
already looking for​
•
To discover which things go together​
•
To personalize user experiences in 
response to user feedback​
•
To identify things that we like
•
To model peoples preferences, 
opinions, and behavior

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Summary of concepts
• Described some of the common use-cases of 
recommender systems on the web

Python Data Products
Course 4: Implementing and Deploying data-driven predictive 
systems
Lecture: Recommender Systems versus other forms of 
supervised learning

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Learning objectives
In this lecture we will...
• Explain the difference between recommender 
systems and other types of machines learning
• Introduce the two recommender systems we will 
develop in this course

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Recommending things to people
Suppose we want to build a movie 
recommender
e.g. which of these films will I rate highest?

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Recommending things to people
We already have 
a few tools in our 
“supervised 
learning” toolbox 
that may help us

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Recommending things to people
Movie features: genre, 
actors, rating, length, etc.
User features: age, gender, 
location, etc.

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Recommending things to people
With the models we’ve seen so far, we 
can build predictors that account for…
• Do women give higher ratings than men?
• Do Americans give higher ratings than Australians?
• Do people give higher ratings to action movies?
• Are ratings higher in the summer or winter?
• Do people give high ratings to movies with Vin Diesel?
So what can’t we do yet?

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Recommending things to people
Consider the following linear predictor 
(e.g. from Course 1):

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Recommending things to people
But this is essentially just two separate 
predictors!
user predictor
movie predictor
That is, we’re treating user and movie 
features as though they’re independent!

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Recommending things to people
But these predictors should (obviously?) 
not be independent
do I tend to give high ratings?
does the population tend to give high ratings to this genre of movie?
But what about a feature like “do I give 
high ratings to this genre of movie”?

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Recommending things to people
Recommender Systems go beyond the methods we’ve seen so 
far by trying to model the relationships between people and 
the items they’re evaluating
my (user’s)
“preferences”
HP’s (item) 
“properties”
preference
Toward
“action”
preference toward
“special effects”
is the movie 
action-
heavy?
are the special effects good?
Compatibility

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Recommending things to people
We’ll look at two common types of 
recommender systems in this course:
1. “Similarity-based” recommender 
systems and collaborative filtering
2. “Model-based” recommender 
systems

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Recommending things to people
•
“Similarity-based” recommender systems measure 
similarity between items in terms of users who have 
purchased them
(E.g. “People who bought 
X also bought Y”)

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Recommending things to people
•
“Model-based” recommender systems use machine 
learning to estimate specific outcomes
(E.g. rating prediction 
on Netflix)

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Summary of concepts
• Introduced two classes of recommender systems for 
future study

Python Data Products
Course 4: Implementing and Deploying data-driven predictive 
systems
Lecture: Collaborative filtering-based recommendation

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Learning objectives
In this lecture we will...
• Introduce collaborative-filtering (or “similarity-
based”) recommender systems
• Demonstrate three instances of this type of 
recommender system

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Defining similarity between users & items
Q: How can we measure the similarity
between two users?
A: In terms of the items they 
purchased!
Q: How can we measure the similarity 
between two items?
A: In terms of the users who purchased 
them!

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Defining similarity between users & items
e.g.:
Amazon

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Definitions
Definitions
= set of items purchased by user u
= set of users who purchased item i

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Definitions
Or equivalently…
users
items
= binary representation of items purchased by u
= binary representation of users who purchased i

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
0. Euclidean distance
A
B
Euclidean distance:
e.g. between two items i,j (similarly defined between two users)

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
0. Euclidean distance
Euclidean distance:
e.g.: U_1 = {1,4,8,9,11,23,25,34}
U_2 = {1,4,6,8,9,11,23,25,34,35,38}
U_3 = {4}
U_4 = {5}
Problem: favors small sets, even if they 
have few elements in common

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
1. Jaccard similarity
A
B
→Maximum of 1 if the two 
users purchased exactly the 
same set of items
(or if two items were purchased by the 
same set of users)
→Minimum of 0 if the two users 
purchased completely 
disjoint sets of items
(or if the two items were purchased by 
completely disjoint sets of users)

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
2. Cosine similarity
(vector representation of 
users who purchased 
harry potter)
(theta = 0) →A and B point in 
exactly the same direction
(theta = 180) →A and B point 
in opposite directions (won’t 
actually happen for 0/1 vectors)
(theta = 90) →A and B are 
orthogonal

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
2. Cosine similarity
Why cosine?
• Unlike Jaccard, works for arbitrary vectors
• E.g. what if we have opinions in addition to purchases?
bought and liked
didn’t buy
bought and disliked

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
2. Cosine similarity
(vector representation of 
users’ ratings of Harry 
Potter)
(theta = 0) →Rated by the 
same users, and they all agree
(theta = 180) →Rated by the 
same users, but they 
completely disagree about it
(theta = 90) →Rated by 
different sets of users
E.g. our previous example, now with 
“thumbs-up/thumbs-down” ratings 

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
3. Pearson correlation
What if we have numerical ratings 
(rather than just thumbs-up/down)?
bought and liked
didn’t buy
bought and disliked

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
3. Pearson correlation
What if we have numerical ratings 
(rather than just thumbs-up/down)?

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
3. Pearson correlation
What if we have numerical ratings 
(rather than just thumbs-up/down)?
• We wouldn’t want 1-star ratings to be parallel to 5-
star ratings
• So we can subtract the average – values are then 
negative for below-average ratings and positive
for above-average ratings
items rated by both users
average rating by user v

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
3. Pearson correlation
Compare to the cosine similarity:
items rated by both users
average rating by user v
Pearson similarity (between users):
Cosine similarity (between users):

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Collaborative filtering in practice
How does amazon generate their recommendations?
Given a product:
Let      be the set of users
who viewed it 
Rank products according to:                      (or cosine/pearson)
.86
.84             .82             .79               …
Linden, Smith, & York (2003)

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Collaborative filtering in practice
Note: (surprisingly) that we built 
something pretty useful out of 
nothing but rating data – we 
didn’t look at any features of the 
products whatsoever

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Collaborative filtering in practice
1.
This is actually kind of slow given a huge 
enough dataset – if one user purchases one 
item, this will change the rankings of every 
other item that was purchased by at least 
one user in common
2.
Of no use for new users and new items (“cold-
start” problems
3.
Won’t necessarily encourage diverse results
But: we still have
a few problems left to address…

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Summary of concepts
• Introduced three similarity-based recommender 
systems
• Described situations where each of these systems 
would be preferable over the others

Python Data Products
Course 4: Implementing and Deploying data-driven predictive 
systems
Lecture: Latent factor models, part 1

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Learning objectives
In this lecture we will...
• Introduce machine-learning based recommender 
systems (“latent-factor models”)
• Introduce some history behind this type of model

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Latent factor models
In the previous lecture we looked at 
approaches that try to define some 
definition of user/user and item/item 
similarity
Recommendation then consists of​
• Finding an item i that a user likes (gives a 
high rating)​
• Recommending items that are similar to it 
(i.e., items j with a similar rating profile to i)

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Latent factor models
What we’ve seen so far are 
unsupervised approaches and whether 
the work depends highly on whether we 
chose a “good” notion of similarity
So, can we perform recommendations 
via supervised learning?

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Latent factor models
e.g. if we can model
Then recommendation 
will consist of identifying

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Background: The Netflix prize
In 2006, Netflix created a dataset of 100,000,000 movie ratings
Data looked like:
The goal was to reduce the (R)MSE at predicting ratings:
Whoever first manages to reduce the RMSE by 10% versus 
Netflix’s solution wins $1,000,000
model’s prediction
ground-truth

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
This led to a lot of research on rating 
prediction by minimizing the Mean-
Squared Error
(it also led to a lawsuit against Netflix, once somebody 
managed to de-anonymize their data)
We’ll look at a few of the main 
approaches
The Netflix prize

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Rating prediction
Let’s start with the 
simplest possible model:
user item
Here the RMSE is just equal to the 
standard deviation of the data
(and we cannot do any better with a 0th order predictor)

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Rating prediction
What about the 2nd simplest model?
user item
how much does 
this user tend to 
rate things above 
the mean?
does this item tend 
to receive higher 
ratings than others
e.g.

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Rating prediction
The optimization problem becomes:
Although various solution techniques 
exist, we can solve this problem via 
gradient descent
error
regularizer

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Rating prediction
Differentiate:

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Rating prediction
Differentiate:

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Rating prediction
user predictor
movie predictor
Looks good (and actually works 
surprisingly well), but doesn’t solve the 
basic issue that we started with
That is, we’re still fitting a function that 
treats users and items independently

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Summary of concepts
• Introduced latent factor models
• Described some history behind this type of model
• Showed how simple versions of this model can be 
optimized using gradient descent
On your own...
•
Compute the gradient update equations 
for the remaining terms

Python Data Products
Course 4: Implementing and Deploying data-driven predictive 
systems
Lecture: Latent factor models, part 2

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Learning objectives
In this lecture we will...
• Further develop the latent factor model introduced in 
the previous lecture

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Rating prediction
So far we developed an approach that incorporates 
user and item biases
user item
user bias
item bias
e.g.

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Rating prediction
So far we developed an approach that incorporates 
user and item biases
We saw that this type of approach, while effective, 
cannot actually personalize recommendations to 
individual users

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Recommending things to people
How about an approach based on 
dimensionality reduction?
my (user’s)
“preferences”
HP’s (item) 
“properties”
i.e., let’s come up with low-dimensional representations of the 
users and the items so as to best explain the data

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Dimensionality reduction
Methodologically, our idea is based on the 
idea of matrix factorization:
What is the best low-
rank approximation of 
R in terms of the mean-
squared error?

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Dimensionality reduction
eigenvectors of
eigenvectors of
(square roots of)
eigenvalues of
Singular Value 
Decomposition
This gives the “best” rank-K approximation (in terms of the MSE)
Methodologically, our idea is based on the 
idea of matrix factorization:

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Dimensionality reduction
But! Our matrix of ratings is only partially 
observed; and it’s really big!
Missing ratings
SVD is not defined for 
partially observed matrices, 
and it is not practical for 
matrices with 1Mx1M+ 
dimensions
; and it’s really big!

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Latent-factor models
So instead, let’s solve approximately using 
gradient descent
items
users
K-dimensional 
representation 
of each user
K-dimensional 
representation 
of each item

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Latent-factor models
my (user’s)
“preferences”
HP’s (item) 
“properties”
Let’s write this as:

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Latent-factor models
Let’s write this as:
Our optimization problem is then
error
regularizer

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Latent-factor models

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Latent-factor models

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Latent-factor models
•
Note: applying gradient descent with these 
terms will not necessarily lead to a global 
optimum
•
Need to be careful about initialization (or run 
with several random restarts) in order to obtain 
a good solution

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Summary of concepts
• Finished our description of latent factor models
• Showed how to optimize the model using gradient 
descent
On your own...
•
Compute the gradient update equations 
for the remaining terms

Week 2
Capstone project 
and Recommender 
Systems 

Python Data Products
Course 4: Implementing and Deploying data-driven predictive 
systems
Lecture: Implementing a similarity-based 
recommender

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Learning objectives
In this lecture we will...
• Implement a simple recommender system that 
recommends products based on the Jaccard similarity

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Reading the data
First we read the data. Note we use a larger dataset for this exercise, 
though could use a smaller one if running time is an issue.

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Reading the data
Our goal is to make recommendations of products based on users’ purchase 
histories. The only information needed to do so is user and item IDs

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Useful data structures
To perform set intersections/unions efficiently, we first build data structures 
representing the set of items for each user and users for each item

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Jaccard similarity
The Jaccard similarity implementation follows the definition directly:

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Recommendation
We want a recommendation function that return items similar to a 
candidate item i. Our strategy will be as follows:
•
Find the set of users who purchased i
•
Iterate over all other items other than i
•
For all other items, compute their similarity with i (and store it)
•
Sort all other items by (Jaccard) similarity
•
Return the most similar

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Recommendation
Now we can implement the recommendation function itself:

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Recommendation
Next, let’s use the code to make a recommendation. The query to the 
system is just a product ID:

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Recommendation
Next, let’s use the code to make a recommendation. The query to the 
system is just a product ID:

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Recommendation
Finally, let’s look at the items that were recommended:

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Recommending more efficiently
Our implementation was not very efficient. The slowest component is the 
iteration over all other items:
•
Find the set of users who purchased i
•
Iterate over all other items other than i
•
For all other items, compute their similarity with i (and store it)
•
Sort all other items by (Jaccard) similarity
•
Return the most similar
This can be done more efficiently as most items will have no overlap

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Recommending more efficiently
In fact it is sufficient to iterate over those items purchased by one of the 
users who purchased i
•
Find the set of users who purchased i
•
Iterate over all users who purchased i
•
Build a candidate set from all items those users consumed
•
For items in this set, compute their similarity with i (and store it)
•
Sort all other items by (Jaccard) similarity
•
Return the most similar

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Faster implementation
Our more efficient implementation works as follows:

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Faster recommendation
Which ought to recommend the same set of items, but much more 
quickly:

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Summary of concepts
• Implemented a similarity-based recommender based 
on the Jaccard similarity
• Showed how to make our implementation more 
efficient
On your own...
•
Our code recommends items that are similar to a given item. 
Adapt it to recommend users who are similar to a given user
•
Typcially we want to recommender items similar to one to 
which a user has already given a high rating (e.g. “you’ll like 
X because you liked Y”). Adapt our code so that it takes as 
input a given user, and recommends items similar to those 
that user liked

Python Data Products
Course 4: Implementing and Deploying data-driven predictive 
systems
Lecture: Using our similarity-based 
recommender for rating prediction

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Learning objectives
In this lecture we will...
• Show how similarity-based recommenders can be 
used as a heuristic for rating prediction
• Provide code examples to do so

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Collaborative filtering for rating prediction
In the previous lecture we provided code 
to make recommendations based on the 
Jaccard similarity
How can the same ideas be used for 
rating prediction?

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Collaborative filtering for rating prediction
A simple heuristic for rating prediction 
works as follows:
• The user (u)’s rating for an item i is a 
weighted combination of all of their 
previous ratings for items j
• The weight for each rating is given by 
the Jaccard similarity between i and j

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Collaborative filtering for rating prediction
This can be written as:
All items the user has 
rated other than i
Normalization 
constant

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Collaborative filtering for rating prediction
Now we can adapt our previous 
recommendation code to predict ratings
We’ll use the mean rating as a 
baseline for comparison
List of reviews per 
user and per item

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Collaborative filtering for rating prediction
Our rating prediction code works as follows:

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Collaborative filtering for rating prediction
As an example, select a rating for prediction:

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Collaborative filtering for rating prediction
Similarly, we can evaluate accuracy across the entire corpus:

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Collaborative filtering for rating prediction
Note that this is just a heuristic for rating prediction
• In fact in this case it did worse (in terms of the 
MSE) than always predicting the mean
• We could adapt this to use:
1. A different similarity function (e.g. cosine)
2. Similarity based on users rather than items
3. A different weighting scheme

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Summary of concepts
• Showed how similarity-based recommenders can be 
used to predict ratings
• Provided code for an implementation of this idea
On your own...
•
Adapt the code to implement one of the 
modifications on the previous slide (e.g. 
cosine, or similarity between users rather 
than items), and measure its effect on 
performance

Python Data Products
Course 4: Implementing and Deploying data-driven predictive 
systems
Lecture: Implementing a simple (bias-only) 
latent factor model

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Learning objectives
In this lecture we will...
• Begin implementing the latent factor model (starting 
with a simple bias-only version)
• Introduce another library for gradient descent

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Latent factor models
We’ll start by implementing a “bias only” model, since its 
gradient update equations are simpler:
With this model, our tasks will be to:
1. Write down code for the gradient equations
2. Use a gradient descent library to optimize the model

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Latent factor models
We’ll start by defining some basic terms. Note that code to 
determine some of these values (e.g. the rating mean) is 
given in previous lectures
Alpha and beta (userbiases) are 
parameters we’ll fit. This code sets their 
initial values (alpha to the mean 
rating, and beta_u/beta_i to zero)

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Latent factor models
Our prediction function in this case just implements the 
bias only model:
user item
user bias
item bias

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Latent factor models
The first complex function to implement is this “unpack” 
function. The gradient descent library we’ll use expects a 
single vector of parameters (  ), which we have to unpack to 
produce alpha and beta:

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Latent factor models
The next function (also required by the gradient descent 
library) just implements the full cost function:

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Latent factor models
Next we implement the derivative function, which has a 
corresponding derivative term for each parameter:

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Latent factor models
Note that the function must also return the derivatives as a 
single vector:

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Latent factor models
Before we test this model, let’s see the accuracy of always 
predicting the mean for comparison:

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Gradient descent with LBFGS
The gradient descent library we’ll use is called lbfgs
(see "Updating Quasi-Newton Matrices with Limited Storage“, Nocedal, 1980)
It has a simple interface which works as follows:
Cost function 
(returns scalar)
Initial parameter 
values (as vector)
Derivative function 
(returns vector)
Other arguments to be 
passed to the cost and 
derivative functions

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Gradient descent with LBFGS
The code runs for several iterations, and returns a value of theta 
(a vector of parameters) after convergence. Convergence criteria 
etc. can be set with additional arguments 

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Gradient descent with LBFGS
This is a general-purpose gradient descent algorithm, which 
simply requires that we provide a cost function (f(x)), and a 
derivative function (f’(x)). It can be (relatively) straightforwardly 
adapted to other gradient descent problems.
(we could also have used Tensorflow for the same task)
In the next lecture we’ll extend this code to implement the full 
latent-factor model

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Summary of concepts
• Implemented a bias-only version of a latent factor 
model
On your own...
•
(HARD) Try implementing the same model 
using Tensorflow

Python Data Products
Course 4: Implementing and Deploying data-driven predictive 
systems
Lecture: Implementing a latent factor model (Part 2)

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Learning objectives
In this lecture we will...
• Complete our implementation of a full-fledged latent 
factor model

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Latent factor models
In this lecture we’ll extend our implementation from the 
previous lecture to implement the complete latent factor 
model:
Again our tasks will be to:
1. Write down code for the gradient equations
2. Use a gradient descent library to optimize the model

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Latent factor models
Again we start with a few definitions/utilities:
Number of latent factors (i.e., 
dimensionality of gamma)

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Latent factor models
Again we need a method to convert from a flat 
parameter vector (  ), to our parameters (   ,   , and   )

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Latent factor models
Other utility functions, and our updated 
prediction function:

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Latent factor models
Our updated cost function:

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Latent factor models
And our updated derivative function
(which is now much more complicated):

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Code: Latent factor models
Finally we can run the model, and observe its performance:
(though note that 
we could be 
overfitting!)

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Summary of concepts
• Completed our implementation of the latent factor 
model
On your own...
•
Try optimizing the code to make use of 
numpy to be more efficient
•
Experiment with different initialization 
strategies for alpha, beta, and gamma
•
Experiment with different values of the 
parameter K

Python Data Products
Course 4: Implementing and Deploying data-driven predictive 
systems
Lecture: Description of Capstone Tasks (Part 1)

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Learning objectives
In this lecture we will...
• Describe the various components and tasks of the 
capstone project

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Capstone tasks
The Capstone project requires you to:
1. Harness your knowledge of machine 
learning, evaluation, and feature design
2. Implement four practical tasks on a real-
world dataset

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Capstone tasks
The dataset you are given is a relatively large set of Amazon 
musical instrument reviews
•
The code stub already separates the data into “training” and “test 
portions”
•
You have to implement techniques that lead to good performance on 
the test set, but which are based only on data from the training set
•
In other words, you have to implement your own 
training/validation/test pipeline

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Capstone tasks
The four tasks consist of the following:
1.
A basic data processing task
2.
A Classification task
3.
A Regression task
4.
A Recommender Systems task

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Task 1: Data processing
For the data processing task, you must implement a variety of 
simple functions to compute basic statistics of the data. E.g.:
•
How many unique users are there in the dataset?
•
What is the average rating?
•
What fraction of reviews are verified?
•
For each of these tasks you must fill in a function stub

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Task 2: Classification
For the classification task, you must predict whether an 
Amazon review corresponds to a verified purchase.
•
This is a binary classification task
•
The main challenge in this task is that the data are imbalanced – i.e., 
most reviews correspond to verified purchases
•
Thus we will use a balanced evaluation metric (the BER)
•
So, you must select classification techniques that lead to good 
performance on this evaluation metric
•
Your method should beat a simple baseline that performs logistic 
regression based on the length and rating of the review

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Task 3: Regression
For the regression task, you must use word features (and 
other features) to perform sentiment analysis
•
This is a regression task (rating prediction)
•
The main challenge in this task is to properly avoid overfitting, 
since you will be using high-dimensional features
•
To do this, you will have to carefully implement a train/validation/test 
pipeline
•
You will also have to carefully engineer your features to consider the 
different choices when pre-processing text
•
You should beat a simple baseline that considers the 100 most 
popular words only

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Task 4: Recommendation
For the recommendation task, you must predict ratings that 
users will give to items
•
This is a recommender systems task (predict a rating given a user 
and an item)
•
The main challenge in this task is to correctly implement a 
complex model
•
Again you will have to be careful about overfitting, as well as 
initialization
•
Your solution should outperform a simple bias-only model

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Capstone project: evaluation
For all tasks, your goal is to beat the baselines given on the 
test set
•
Beating these solutions on the training set should be easy – you can 
make small modifications to the existing techniques.
•
However these performance gains may not translate well to the test 
set unless you are careful about overfitting and correctly 
implementing a validation pipeline
•
To do so will require leveraging several ideas from throughout this 
Specialization

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Summary of concepts
• Introduced the Capstone project for Course 4

Week 3
Web Server Frameworks 
for Python

Python Data Products
Course 4: Implementing and Deploying data-driven predictive 
systems
Lecture: Introduction to Web Frameworks

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Learning objectives
In this lecture we will learn…
• Background on server-side web frameworks

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Web Terminology
• Web page: a document 
• Website: webpages + multimedia + domain name 

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Web Server and Communication Protocol
HTTP Request
HTTP Response
Web Server
Client
Database Server
Data 
Request
Data 
Response

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Some examples….

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Python Web Frameworks 
Clien
t
Web 
Serve
r
App 
Serve
r
Python Web 
Frameworks
•
Django
•
Flask

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Summary of concepts
•
Basic terminology and basic architecture of web applications
•
Webpage
•
Website
•
Web Server
•
What a web framework means 

Django: A Python Web framework
Course: Learn to build a Web Application using Django
Lecture: A Short Introduction to Django

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Learning objectives
In this lecture we will learn…
•
What is Django?
•
Django Architecture
•
Why Django
•
Real world companies built with Django Framework

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Django
• Python-based high level web framework
• Free and open-source
• Model-View-Template (MVT) Design Pattern

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Django MVT Architecture
HTTP Request
HTTP Response
Django Web application 
Framework
User
Database Server
Data 
Request
Data 
Response
Model
(models.py)
)
View
(views.py)
Template
(<filename>.html)
URLS
(urls.py
)

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Advantages - Why Django? 
• Loose coupling between Model, View and 
Template
• Fast and easy web-development
• Library of pre-built packages
• Security
• Scalability 
• Versatile 

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Using Django Framework

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Summary of concepts
• Described Django web framework 
architecture, main features, and 
Django based popular web 
application platforms. 

Flask: A Python Web framework
Course: Learn to build a Web Application using Django
Lecture: A Short Introduction to Flask

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Learning objectives
In this lecture we will learn…
•
What is Flask?
•
Flask Architecture
•
A data product in Flask using our models

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Flask
• Micro-framework
• Lightweight and secure
• Some Flask-powered websites
• Netflix
• Lyft
• Uber
• Airbnb
• …

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Web HTML
Web Server
Application Server
Flask Application Framework
Flask Route
Python Function
Flask Application Architecture

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Model (Flask Form)
Data you want to represent
(Plain Python Object with 
only data attributes) 
View (Flask 
Template)
Html Presentation
(uses model data) 
Controller (Flask 
Route)
Logic that generates model 
and calls the view to be 
created
HTTP 
Request
Model-View-Controller (MVC) Architecture 

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Start Flask
from flask import Flask
app = Flask(__name__)
if __name__ == '__main__':
app.run(debug=True, host='0.0.0.0')
Main Flask 
Object

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Flask Routes
@app.route('/', methods=['GET'])
def index():
return 'hello from flask!'
HTTP Verb
(GET, POST, PUT, 
PATCH, DELETE)
HTTP Route, can 
be anything you 
want, this is for 
http://localhost/
Python function 
to run when the / 
route is called

mlModel = SimilarItemsMlModel()
@app.route('/items/similar', methods=['GET', 'POST'])
def similar_item_form():
form = SimilarItemsForm()
if request.method == 'POST':
form.similarItems = 
mlModel.get_similar_items(form.item_id.data)
return render_template('similar.html', form=form)
Object that hold model 
code
Object that holds form data
Get similar items if POST
Render html given form 
bj
t

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Flask Html Templates
<ul>
{% for item in data['items'] %}
<li>{{ item['product_id'] }}: {{ item['product_title'] }}</li>
{% endfor %}
</ul>
Python loop 
logic
Print Python data

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Docker & Docker-Compose
$ docker-compose 
up
docker-
compose.yml
Dockerfi
le
Docker 
Container
Local 
Files

Data to Products: Course 4: Implementing and Deploying data-driven predictive systems
Summary of concepts
• Described Flask web framework 
architecture, main features, and a 
Flask example for recommender 
models we developed

Python Data Products
Course 4: Implementing and Deploying data-driven predictive 
systems
Lecture: Description of Capstone Tasks (Part 2)

