Academic Press is an imprint of Elsevier
The Boulevard, Langford Lane, Kidlington, Oxford OX5 1GB, UK
225 Wyman Street, Waltham, MA 02451, USA
First edition 2014
Copyright © 2014 Elsevier Ltd. All rights reserved.
No part of this publication may be reproduced, stored in a retrieval system or transmitted in any form or by any 
means electronic, mechanical, photocopying, recording or otherwise without the prior written permission of the 
publisher.
Permissions may be sought directly from Elsevier’s Science & Technology Rights Department in Oxford, UK: 
phone (+44) (0) 1865 843830; fax (+44) (0) 1865 853333; email: permissions@elsevier.com. Alternatively you 
can submit your request online by visiting the Elsevier web site at http://elsevier.com/locate/permissions, and 
selecting Obtaining permission to use Elsevier material.
Notice
No responsibility is assumed by the publisher for any injury and/or damage to persons or property as a matter of 
products liability, negligence or otherwise, or from any use or operation of any methods, products, instructions or 
ideas contained in the material herein. Because of rapid advances in the medical sciences, in particular, indepen-
dent verification of diagnoses and drug dosages should be made.
Library of Congress Cataloging in Publication Data
A catalog record for this book is available from the Library of Congress
British Library Cataloguing in Publication Data
A catalogue record for this book is available from the British Library
ISBN: 978-0-12-396500-4
For information on all Elsevier publications
visit our website at www.store.elsevier.com
Printed and bound in Poland.
14  15  16  17  10  9  8  7  6  5  4  3  2  1

xxxi
CHAPTER 2
Mounir Ghogho received the Ph.D. degree in 1997 from the National 
Polytechnic Institute of Toulouse, France. He was an EPSRC Research Fellow 
with the University of Strathclyde, Glasgow (Scotland), from September 
1997 to November 2001. Since December 2001, he has been a faculty mem-
ber with the school of Electronic and Electrical Engineering at the University 
of Leeds (UK), where he is currently a Professor. He is also currently a 
Professor at the International University of Rabat (Morocco). He served as an 
Associate Editor of the IEEE Signal Processing Letters from 2001 to 2004, the 
IEEE Transactions on Signal Processing from 2005 to 2008, and the Elsevier 
Digital Signal Processing journal from 2011 to 2012. He served as a member of the IEEE Signal 
Processing Society SPCOM Technical Committee from 2005 to 2010, a member of IEEE Signal 
Processing Society SPTM Technical Committee from 2006 to 2011, and is currently a member 
of the IEEE Signal Processing Society SAM Technical Committee. He was the general co-chair 
of the eleventh IEEE workshop on Signal Processing for Advanced Wireless Communications 
(SPAWC’2010), the technical co-chair of the MIMO symposium of IWCMC 2007 and IWCMC 
2008, and a technical area co-chair of Eusipco 2008, Eusipco 2009, and ISCCSP’05. He is the 
general co-chair of Eusipco 2013. He was the guest co-editor of special issues of the EURASIP 
Journal on Wireless Communications and Networking and the Elsevier Physical Communications 
Journal. His research interests are in signal processing and communication. He held invited sci-
entist/professor positions at many institutions including the US Army Research Lab (USA), 
Telecom Paris-Tech (France), National Institute of Informatics (Japan), University Carlos 3rd 
of Madrid (Spain), ENSICA (France), Darmstadt Technical University (Germany), and Beijing 
University of Posts and Telecommunication (China). He was awarded the prestigious five-year 
Royal Academy of Engineering Research Fellowship in September 2000.
Philippe Ciblat was born in Paris, France, in 1973. He received the Engineering 
degree from Telecom ParisTech (formerly, Ecole Nationale Superieure des 
Telecommunications—ENST) and the M.Sc. degree in automatic control and 
signal processing from the University of Paris-Sud, both in 1996, and the Ph.D. 
degree from University of Paris-Est at Marne-la-Vallee in 2000. He eventually 
received the HDR degree from the University of Paris-Est at Marne-la-Vallee in 
2007. In 2001, he was a Postdoctoral Researcher with University of Louvain, 
Belgium. Then, he joined the Communications and Electronics Department 
at Télécom ParisTech, as an Associate Professor. Since 2011, he has been 
(full) Professor in the same institution. He also is the Head of Digital Communications Group. 
He is Technical program committee (TPC) member for several flagship conferences (ICASSP, 
EUSIPCO, GLOBECOM, etc). He served as Associate Editor for the IEEE Communications 
Letters from 2004 to 2007. He served as Associate Editor (2008–2012) and then Senior Area 
Editor (2011–2012) for the IEEE Transactions on Signal Processing. His research areas include 
Authors Biography

xxxii
Authors Biography
statistical signal processing (blind equalization, frequency estimation, and distributed estima-
tion), signal processing for digital communications (synchronization), and resource allocation 
(multiple access technique optimization, power allocation).
Ananthram Swami received the B.Tech. degree from Indian Institute of 
Technology (IIT), Bombay; the M.S. degree from Rice University, Houston, 
TX, and the Ph.D. degree from the University of Southern California (USC), 
Los Angeles, all in electrical engineering. He has held positions with Unocal 
Corporation, USC, CS-3, and Malgudi Systems. He was a Statistical Consultant 
to the California Lottery, developed a Matlab-based toolbox for non-Gauss-
ian signal processing, and has held visiting faculty positions at INP, Toulouse, 
France. He is with the US. Army Research Laboratory (ARL) where he is the 
ST for Network Science. His work is in the broad area of network science, 
with emphasis on wireless communication networks. He was the co-editor of “Wireless Sensor 
Networks: Signal Processing and Communications Perspectives” (New York: Wiley, 2007). He 
is a member of the IEEE SPS Technical Committee on Sensor Array and Multi-channel sys-
tems, and serves on the Senior Editorial Board of the IEEE Journal on Selected Topics in Signal 
Processing. He is an IEEE Fellow and an ARL Fellow. He has served as an Associate Editor for 
the IEEE Transactions on Signal Processing, IEEE Signal Processing Letters, Signal Processing 
Magazine, the IEEE Transactions on Circuits and Systems II, the IEEE Transactions on Wireless 
Communications, and as Guest Editor for the IEEE Journal on Selected Areas in Communications. 
He was a tutorial speaker on “Networking Cognitive Radios for Dynamic Spectrum Access” at 
ICASSP 2008, DySpan 2008, MILCOM 2008, and ICC 2010. He received the best conference 
paper award at IEEE Trustcom 2008, and was co-Organizer and co-Chair of three IEEE work-
shops related to signal processing and communications, including IEEE SPAWC’10.
CHAPTER 3
Jitendra K. Tugnait received the B.Sc. (Hons.) degree in electronics and electrical 
communication engineering from the Punjab Engineering College, Chandigarh, 
India in 1971, the M.S. and the E.E. degrees from Syracuse University, 
Syracuse, NY and the Ph.D. degree from the University of Illinois, Urbana-
Champaign in 1973, 1974, and 1978, respectively, all in electrical engineering.
From 1978 to 1982 he was an Assistant Professor of Electrical and 
Computer Engineering at the University of Iowa, Iowa City, IA. He was 
with the Long Range Research Division of the Exxon Production Research 
Company, Houston, TX, from June 1982 to September 1989. He joined 
the Department of Electrical and Computer Engineering, Auburn University, Auburn, AL, in 
September 1989 as a Professor. He currently holds the title of James B. Davis Professor. His 
current research interests are in statistical signal processing, wireless and wireline digital com-
munications, cognitive radio networks, multiple sensor multiple target tracking, and stochastic 
systems analysis. He was elected Fellow of IEEE in 1994.
He is a past Associate Editor of the IEEE Transactions on Automatic Control, the IEEE 
Transactions on Signal Processing, IEEE Signal Processing Letters, and the IEEE Transactions 

xxxiii
Authors Biography
on Wireless Communications. He is currently a Senior Area Editor of the IEEE Transactions on 
Signal Processing, and a Senior Editor of IEEE Wireless Communications Letters.
CHAPTER 4
Antoine Chevreuil (M’97) was born in 1971 in Caen, France. He received 
the M.Sc and the Ph.D. degrees from Ecole Nationale Supérieure des 
Télécommunications in Paris (previously ENST, now Telecom Paris-Tech) 
respectively, in 1994 and 1997. In 1997, he obtained a grant from the 
Institut National de Recherche en Informatique et en Automatique (INRIA) 
and worked with Luc Vandendorpe in the TELE team in the University of 
Louvain-la-neuve (Belgium).
From 1998 until 2009 he was Assistant Professor of Electrical Engineering 
in the University of Paris-East/Marne-la-Vallée. Since 2009, he is Professor 
in the Ecole Supérieure d’Ingénieurs en Electronique et Electrotechnique (ESIEE) located in 
Champs-sur-Marne (France).
He is a member of the laboratory UMR 8049 LIGM (Computing Department of the 
University of Paris-East). His present research interests are in statistical signal processing, and 
digital communications with a special emphasis on blind equalization, multi-user communication 
systems, and multicarrier modulations.
Philippe Loubaton (M’88) was born in 1958 in Villers Semeuse, France. He 
received the M.Sc and the Ph.D. degrees from Ecole Nationale Supérieure 
des Télécommunications, Paris, France, in 1981 and 1988, respectively.
From 1982 to 1986, he was a member of the technical staff of Thomson-
CSF/RGS, where he worked in digital communications. From 1986 to 1988, 
he worked with the Institut National des Télécommunications as an Assistant 
Professor of Electrical Engineering. In 1988, he joined the Ecole Nationale 
Supérieure des Télécommunications, Paris, France, working in the Signal 
Processing Department. Since 1995, he has been Professor of Electrical 
Engineering at Marne la Vallée University, Champs sur Marne, France. From 1996 to 2000, he 
was Director of the Laboratoire Systéme de Communication of Marne la Vallée Universty and 
is now a member of the Laboratoire Traitement et Communication de l’Information (CNRS/
Ecole Nationale Supérieure des Télécommunications). His research interests are in statistical 
signal processing, and digital communications with a special emphasis on blind equalization, 
multi-user communication systems, and multi carrier modulations. His present research works 
concern the application of the theory of large random matrices to signal processing and digital 
telecommunications.
He is currently associate editor for the IEEE Transactions on Signal Processing and IEEE 
Communications Letters, and is a member of the IEEE Signal Processing for Communications 
technical committee.

xxxiv
Authors Biography
CHAPTER 5
Paolo Banelli received the Laurea degree in electronics engineering and the 
Ph.D. degree in telecommunications from the University of Perugia, Perugia, 
Italy, in 1993 and 1998, respectively. In 2005, he was appointed Associate 
Professor at the Department of Electronic and Information Engineering (DIEI), 
University of Perugia, where he has been an Assistant Professor since 1998. 
In 2001, he joined the SpinComm group at the Electrical and Computer 
Engineering Department, University of Minnesota, Minneapolis, as a Visiting 
Researcher. His research interests mainly focus on signal processing for wire-
less communications, with emphasis on multicarrier transmissions, and more 
recently on signal processing for biomedical applications, with emphasis on electrocardiography 
and medical ultrasounds. In 2011 he has been elected as a member of the SP-COM Technical 
Committee of the IEEE Signal Processing Society. Since the end of 2012 he is serving as Associate 
Editor of the IEEE Transactions on Signal Processing, and the EURASIP Journal on Advances in 
Signal Processing. He was a General Co-Chair of the IEEE International Symposium on Signal 
Processing Advances for Wireless Communications 2009, he has been serving as a Reviewer for 
several technical journals, and as technical program committee member of leading international 
conferences on signal processing and telecommunications.
Luca Rugini was born in Perugia, Italy, in 1975. He received the Laurea degree 
in electronic engineering and the Ph.D. degree in telecommunications from 
the University of Perugia in 2000 and 2003, respectively. From February to 
July 2007, he visited Delft University of Technology, The Netherlands. He 
is currently an Assistant Professor with the Department of Electronic and 
Information Engineering at the University of Perugia. His research inter-
ests lie in the area of signal processing for multicarrier and spread-spectrum 
communications.
CHAPTER 6
Itsik Bergel received the B.Sc. degree in electrical engineering and the B.Sc. 
degree in physics from Ben Gurion University, Beer-Sheva, Israel, in 1993 and 
1994, respectively, and the M.Sc. degree and Ph.D. in electrical engineering 
from the University of Tel Aviv, Tel-Aviv, Israel, in 2000 and 2005, respectively. 
From 2001 to 2003 he was a senior researcher at INTEL communications 
research laboratory in 2005 he did a postdoc research at the Dipartimento di 
Elettronica of Politecnico di Torino. He is currently a faculty member in the 
faculty of engineering at Bar-Ilan University, Ramat-Gan, Israel.

xxxv
Authors Biography
Amir Leshem (SM’06) received the B.Sc. (cum laude) in mathematics and phys-
ics, the M.Sc. (cum laude) in mathematics, and the Ph.D. in mathematics 
all from the Hebrew University, Jerusalem, Israel, in 1986,1990, and 1998, 
respectively.
From 1998 to 2000 he was with Faculty of Information Technology and 
Systems, Delft University of Technology, The Netherlands, as a postdoctoral 
fellow working on algorithms for the reduction of terrestrial electromag-
netic interference in radio-astronomical radio-telescope antenna arrays and 
signal processing for communication. From 2000 to 2003 he was director 
of advanced technologies with Metalink Broadband where he was responsible for research and 
development of new DSL and wireless MIMO modem technologies and served as a member of 
ITU-T SG15, ETSI TM06, NIPP-NAI, IEEE 802.3 and 802.11.
From 2000 to 2002 he was also a visiting researcher at Delft University of Technology. From 
2003 to 2005 he was also the technical manager of the U-BROAD consortium developing tech-
nologies to provide 100 Mbps and beyond over copper lines.
In 2002 he was one of the founders of the faculty of engineering at Bar-Ilan university where 
he is a Professor and heads the Signal Processing track.
From 2008 to 2011 he was an associate editor of the IEEE Transactions on Signal Processing. 
Since 2010 he is member of the IEEE technical committee on Signal processing for communi-
cations. He was a leading quest editor for special issues on signal processing for astronomy and 
cosmology of IEEE SP magazine and IEEE Journal of Selected Topics in Signal Processing, and a 
guest editor of several other special issues on game theory and learning. He was also the technical 
co-chair of the IEEE SAM 2010.
His main research interests include multichannel wireless and wireline communication, appli-
cations of game theory to dynamic and adaptive spectrum management of communication net-
works, array and statistical signal processing with applications to multiple element sensor arrays 
and networks, wireless communications, radio-astronomical imaging and brain research, set the-
ory, logic, and foundations of mathematics.
CHAPTER 7
Sergio Barbarossa (S’84, M’88, F’12) received the M.Sc. degree in 1984 and 
the Ph.D. degree in electrical engineering in 1988, both from the University 
of Rome ‘‘La Sapienza,’’ Rome, Italy. He has held positions as a Research 
Engineer with Selenia SpA (1984–1986) and with the Environmental 
Institute of Michigan (1988), as a Visiting Professor with the University of 
Virginia (1995 and 1997) and with the University of Minnesota (1999). He 
has taught short graduate courses at the Polytechnic University of Catalunya 
(2001 and 2009). Currently, he is a Full Professor with the University of 
Rome ‘‘La Sapienza.’’ His current research interests lie in the area of sig-
nal processing for self-organizing networks, bio-inspired signal processing, femtocell networks, 

xxxvi
Authors Biography
mobile cloud computing, graph theory, game theory, and distributed optimization algorithms. He 
is the author of a research monograph titled ‘‘Multiantenna Wireless Communication Systems.’’ 
He has been the scientific coordinator of the European projects WINSOC, on wireless sensor 
networks, and FREEDOM, on femtocell networks. He is currently the scientific coordinator 
of the European Project TROPIC, on cloud computing over small cell networks. He is also a 
principal investigator in the European Project SIMTISYS, on the radar monitoring of maritime 
traffic from satellites.
He has been nominated as an IEEE Fellow for his contributions to signal processing, 
sensor networks, and wireless communications. He received the 2010 EURASIP Technical 
Achievements Award for his contributions to synthetic aperture radar, sensor networks, and 
communication networks. He received the 2000 IEEE Best Paper Award from the IEEE 
Signal Processing Society. He is the coauthor of papers that received the Best Student Paper 
Award at ICASSP 2006, SPAWC 2010, EUSIPCO 2011, and CAMSAP 2011. From 1997 
until 2003, he was a member of the IEEE Technical Committee for Signal Processing in 
Communications. He served as an Associate Editor for the IEEE Transactions on Signal 
processing for two terms (1998–2000 and 2004–2006). He is now a member of the IEEE 
Signal Processing Magazine Editorial Board. He has been the General Chairman of the IEEE 
Workshop on Signal Processing Advances in Wireless Communications (SPAWC) 2003 and he 
is the Technical Co-Chair of SPAWC 2013. He has been the Guest Editor for Special Issues 
on the IEEE Journal on Selected Areas in Communications, EURASIP Journal of Applied 
Signal Processing, EURASIP Journal on Wireless Communications and Networking, and the 
IEEE Signal Processing Magazine. In 2012, he was nominated IEEE Distinguished Lecturer 
from the Signal Processing Society.
Stefania Sardellitti (M’12) received the Dr. Eng. degree in Electronic 
Engineering from the University of Rome ‘‘La Sapienza,’’ Italy, in 1998 and the 
Ph.D. degree in Electrical and Information Engineering from the University of 
Cassino, Italy, in 2005. Since 2005 she is an appointed Professor of digital com-
munications at the University of Cassino, Italy. She is currently a research assis-
tant at the Department of Information, Electronics and Telecommunications, 
University of Rome, Sapienza, Italy. She has participated in the European 
project WINSOC, on wireless sensor networks and in the European project 
FREEDOM on femtocell networks. She is currently involved in the European 
TROPIC, on distributed computing, storage, and radio resource allocation over cooperative fem-
tocells. Her research interests are in the area of statistical signal processing, in particular on 
multiple antenna and multiple access systems. Currently, her primary research activity is on the 
field of cognitive radios, femtocell networks, and wireless sensor networks, with emphasis on 
distributed decision.
Paolo Di Lorenzo (S’10-M’13) received the M.Sc. degree in 2008 and the Ph.D. in electrical 
engineering in 2012, both from University of Rome ‘‘La Sapienza,’’ Italy. He is currently a post-
doctoral researcher in the Department of Information, Electronics and Telecommunications, 
University of Rome, ‘‘La Sapienza.’’ During 2010 he held a visiting research appointment in the 

xxxvii
Authors Biography
Department of Electrical Engineering, University of California at Los Angeles 
(UCLA). He has participated in the European research project FREEDOM 
on femtocell networks. He is currently involved in the European projects 
SIMTISYS, on moving target detection through satellite constellations, and 
TROPIC, on distributed computing, storage, and radio resource allocation 
over cooperative femtocells. His primary research interests are in statisti-
cal signal processing, distributed optimization algorithms for communication 
and sensor networks, graph theory, game theory, and adaptive filtering. He 
received three best student paper awards, respectively, at IEEE SPAWC’10, 
EURASIP EUSIPCO’11, and IEEE CAMSAP’11, for works in the area of signal processing for 
communications and synthetic aperture radar systems. He is recipient of the 2012 GTTI (Italian 
national group on telecommunications and information theory) award for the Best Ph.D. Thesis 
in information technologies and communications.
CHAPTER 8
Mingyi Hong received his B.E. degree in Communications Engineering from 
Zhejiang University, China, in 2005, and his M.S. degree in Electrical Engineering 
from Stony Brook University in 2007, and Ph.D. degree in Systems Engineering 
from University of Virginia in 2011. He is currently a post-doctoral fellow 
with the Department of Electrical and Computer Engineering, University of 
Minnesota. His research interests are primarily in the fields of statistical signal 
processing, wireless communications, and optimization theory.
Zhi-Quan Luo received his B.Sc. degree in Applied Mathematics in 1984 from 
Peking University, Beijing, China. Subsequently, he was selected by a joint com-
mittee of the American Mathematical Society and the Society of Industrial and 
Applied Mathematics to pursue Ph.D study in the United States. After a one-
year intensive training in mathematics and English at the Nankai Institute of 
Mathematics, Tianjin, China, he studied in the Operations Research Center and 
the Department of Electrical Engineering and Computer Science at MIT, where 
he received a Ph.D. degree in Operations Research in 1989. From 1989 to 2003, 
he held a faculty position with the Department of Electrical and Computer 
Engineering, McMaster University, Hamilton, Canada, where he eventually became the department 
head and held a Canada Research Chair in Information Processing. Since April of 2003, he has been 
with the Department of Electrical and Computer Engineering at the University of Minnesota (Twin 
Cities) as a Full Professor and holds an endowed ADC Chair in digital technology. His research 
interests include optimization algorithms, signal processing, and digital communication.
He is a fellow of IEEE and SIAM, and serves as the chair of the IEEE Signal Processing Society 
Technical Committee on the Signal Processing for Communications (SPCOM). He is a recipient 
of the 2004 and 2009 IEEE Signal Processing Society Best Paper Awards, the 2010 Farkas Prize 

xxxviii Authors Biography
from the INFRMS Optimization Society, the 2011 EURASIP Best Paper Award, and the 2011 
ICC Best Paper Award. He has held editorial positions for several international journals including 
Journal of Optimization Theory and Applications, SIAM Journal on Optimization, Mathematics 
of Computation, and IEEE Transactions on Signal Processing. He currently serves as the Editor-
in-Chief for the journal IEEE Transactions on Signal Processing.
CHAPTER 9
Seung-Jun Kim (SM’12) received his B.S. and M.S. degrees from Seoul 
National University in Seoul, Korea in 1996 and 1998, respectively, and 
his Ph.D. from the University of California at Santa Barbara in 2005, all in 
electrical engineering. From 2005 to 2008, he worked for NEC Laboratories 
America in Princeton, New Jersey, as a research staff member. Since 2008, he 
has been with the Department of Electrical and Computer Engineering at the 
University of Minnesota, where he is currently a Research Assistant Professor. 
His research interests lie in applying signal processing and optimization tech-
niques to various domains including wireless communication and networking 
as well as smart power grids.
Emiliano Dall’Anese received the Laurea Triennale (B.Sc. Degree) and the 
Laurea Specialistica (M.Sc. Degree) in Telecommunications Engineering from 
the University of Padova, Italy, in 2005 and 2007, respectively, and the Ph.D 
in Information Engineering from the Department of Information Engineering 
(DEI), University of Padova, Italy, in 2011. From January 2009 to September 
2010 he was a visiting scholar at the Department of Electrical and Computer 
Engineering, University of Minnesota, USA. Since January 2011, he has 
been a postdoctoral associate at the Department of Electrical and Computer 
Engineering and Digital Technology Center, University of Minnesota, USA.
His research interests lie in the areas of statistical signal processing, networking, and smart 
power systems. Current research includes optimal energy management in smart power distribu-
tion networks; robust, distributed, and sparsity-aware statistical inference; and, and optimization 
of wireless cognitive radio networks.
Juan Andrés Bazerque (S’06) received his B.Sc. degree in Electrical Engineering 
from Universidad de la Rep´ublica (UdelaR), Montevideo, Uruguay in 2003. 
Since August 2006 he has been a research assistant at the University of 
Minnesota (U of M), Minneapolis, where he received his M.Sc. in Electrical 
Engineering in August 2009, and his Ph.D. in May 2013. From 2000 to 2006 he 
was a teaching assistant with the Department of Mathematics and Statistics, 
and with the Department of Electrical Engineering (UdelaR). From 2003 to 
2006 he worked as a telecommunications engineer at the Uruguayan company 
Uniotel S.A. developing applications for Voice over IP. His broad research 
interests lie in the general areas of networking and signal processing. His current research focuses 
on distributed signal processing, cooperative wireless communications, compressive sampling, 

xxxix
Authors Biography
sparsity-aware statistical modeling, and gene expression networks. He received the UofM’s 
Distinguished M.Sc. Thesis Award in 2009, and the best student paper award at the second 
International Conference on Cognitive Radio Oriented Wireless Networks and Communication 
(CROWNCOM) 2007. 
Ketan Rajawat received his B.Tech and M.Tech degrees in Electrical Engineering 
from Indian Institute of Technology Kanpur, in 2007; and his Ph.D. degree 
in Electrical and Computer Engineering from University of Minnesota, in 
2012. Currently, he is an Assistant Professor in the Department of Electrical 
Engineering, IIT Kanpur. His research interests lie in the areas of Signal pro-
cessing and Communication Networks. His current research focuses on cross-
layer network optimization dynamic network monitoring.
Georgios B. Giannakis (Fellow’97) received his Diploma in Electrical 
Engineering from the Ntl. Tech. University of Athens, Greece, 1981. From 
1982 to 1986 he was with the University of Southern California (USC), where 
he received his M.Sc. in Electrical Engineering, 1983, M.Sc. in Mathematics, 
1986, and Ph.D. in Electrical Engineering, 1986. Since 1999 he has been a 
Professor with the University of Minnesota, where he now holds an ADC 
Chair in Wireless Telecommunications in the ECE Department and serves as 
Director of the Digital Technology Center.
His general interests span the areas of communications, networking, and 
statistical signal processing - subjects on which he has published more than 350 journal papers, 
580 conference papers, 20 book chapters, two edited books, and two research monographs 
(h-index 103). Current research focuses on sparsity and big data analytics, wireless cognitive 
radios, mobile ad hoc networks, renewable energy, power grid, gene-regulatory, and social net-
works. He is the (co-) inventor of 21 patents issued, and the (co-) recipient of 8 best paper awards 
from the IEEE Signal Processing (SP) and Communications Societies, including the G. Marconi 
Prize Paper Award in Wireless Communications. He also received Technical Achievement Awards 
from the SP Society (2000), from EURASIP (2005), a Young Faculty Teaching Award, and the 
G. W. Taylor Award for Distinguished Research from the University of Minnesota. He is a Fellow 
of EURASIP, and has served the IEEE in a number of posts, including that of a Distinguished 
Lecturer for the IEEE-SP Society.
CHAPTER 11
Maria S. Greco graduated in Electronic Engineering in 1993 and received the 
Ph.D. degree in Telecommunication Engineering in 1998, from University of 
Pisa, Italy. From December 1997 to May 1998 she joined the Georgia Tech 
Research Institute, Atlanta, USA as a visiting research scholar where she carried 
on research activity in the field of radar detection in non-Gaussian background.
In 1993 she joined the Department of “Ingegneria dell’Informazione” of the 
University of Pisa, where she is Associate Professor since December 2011. She 
is IEEE fellow since January 2011 and she was co-recipient of the 2001 IEEE 

xl
Authors Biography
Aerospace and Electronic Systems Society’s Barry Carlton Award for Best Paper and recipient of 
the 2008 Fred Nathanson Young Engineer of the Year award for contributions to signal processing, 
estimation, and detection theory. She has been general-chair, technical chair, and technical com-
mittee member of many conferences. She was guest co-editor of the special issue of the Journal 
of the IEEE Signal Processing Society on Special Topics in Signal Processing on “Adaptive Waveform 
Design for Agile Sensing and Communication,” published in June 2007 and was lead guest editor 
of the special issue of International Journal of Navigation and Observation on” Modeling and 
Processing of Radar Signals for Earth Observation published in August 2008. She is Associate Editor 
of IET Proceedings—Sonar, Radar and Navigation, of the IEEE Transactions on Signal Processing, 
of the IEEE Aerospace and Electronic Systems Magazine, member of the Editorial Board of the 
Journal of Advances in Signal Processing (JASP), member of the IEEE Signal Processing Theory 
and Methods (SPTM) and Signal Array Processing (SAM) Technical Committees.
Her general interests are in the areas of statistical signal processing, estimation, and detection 
theory. In particular, her research interests include clutter models, spectral analysis, coherent 
and incoherent detection in non-Gaussian clutter, CFAR techniques, radar waveform diversity, 
and bistatic/multistatic radars. She co-authored two book chapters, more than 100 journal and 
conference papers.
Simon Watts graduated from the University of Oxford in 1971, obtained an 
M.Sc. from the University of Birmingham in 1972 and a Ph.D. from the CNAA 
in 1987. He is currently deputy Scientific Director and Technical Fellow in 
Thales UK and is also a Visiting Professor in the department of Electronic and 
Electrical Engineering at University College London. He joined Thales (then 
EMI Electronics) in 1967 and since then has worked on a wide range of radar 
and EW projects, with a particular research interest in maritime radar and sea 
clutter. He is author and co-author of over 50 journal and conference papers, 
a book on sea clutter and several patents. He was Chairman of the interna-
tional radar conference RADAR-97 in Edinburgh UK. He received the IEE JJ Thomson Premium 
Award in 1987 and the IEE Mountbatten Premium Award in 1991. He serves on the IEEE AESS 
Radar Systems Panel, is an Associate Editor for Radar for the IEEE Transactions AES and a mem-
ber of the Editorial Board of IET Radar, Sonar and Navigation. He was appointed MBE in 1996 
for services to the UK defence industry and is a Fellow of the Royal Academy of Engineering, 
Fellow of the IET, Fellow of the IMA, and Fellow of the IEEE.
CHAPTER 12
William L. Melvin is Director of the Sensors and Electromagnetic Applications 
Laboratory at the Georgia Tech Research Institute and an Adjunct Professor in 
Georgia Tech’s Electrical and Computer Engineering Department. His research 
interests include all aspects of RF and acoustic sensor development. He has 
authored over 180 publications in his areas of research interest and holds 
three US patents on sensor technology.

xli
Authors Biography
Among his distinctions, he is the recent recipient of the 2006 IEEE AESS Young Engineer of 
the Year Award, the 2003 US Air Force Research Laboratory Reservist of the Year Award, and 
the 2002 US Air Force Materiel Command Engineering and Technical Management Reservist of 
the Year Award. He was chosen as an IEEE Fellow for his contributions to adaptive radar technol-
ogy. Also, he is a member of the Board on Army Science and Technology through the National 
Academy of Science.
He received the Ph.D. in Electrical Engineering from Lehigh University, as well as the MSEE 
and BSEE degrees (with high honors) from this same institution, respectively.
CHAPTER 13
Qian He received her B.E. and Ph.D. degrees both with honors in Electronic 
Engineering from the University of Electronic Science and Technology of China 
(UESTC), Chengdu, China, in 2004 and 2010, respectively.
From 2007 to 2009, she was a visiting scholar in the Electrical and 
Computer Engineering Department, Lehigh University, Bethlehem, PA. From 
2010 to 2011, she was a Postdoctoral Research Associate in the same depart-
ment at Lehigh University. In 2010, she joined the faculty of the Electronic 
Engineering Department at UESTC, where she is currently an Associate 
Professor. Her current research interests include statistical signal processing, 
array signal processing, adaptive signal processing, and their applications in radar, communication, 
and smart grid systems.
She is a member of Sigma Xi. She received the 2010 Excellent Doctoral Dissertation Award 
of Sichuan Province and the 2012 Outstanding Faculty Member Award from the School of 
Electronic Engineering at UESTC. She is on the editorial board for the Journal of Communications 
and Information Sciences and for the Advances in Energy and Power Engineering. She is an 
affiliate member of the Sensor Array and Multichannel Technical Committee of the IEEE Signal 
Processing Society.
Yang Yang received the B.E. degree in Information Engineering from Xi’an 
Jiaotong University, Xi’an, China, in 2001, the M.E degree in Electrical 
Engineering from the National University of Singapore in 2004, and the Ph.D. 
degree in Electrical Engineering from Lehigh University, Bethlehem, PA, in 2009.
From 2002 to 2004, he was with the Institute for Infocomm Research, 
Singapore, as a research scholar. During the summer of 2007, he was an intern 
at Bell Laboratories, Alcatel-Lucent, Crawford Hill, Holmdel, NJ. From 2009 
to 2011, he was a Postdoctoral Research Associate at Lehigh University. He is 
currently with Broadcom Corporation, Matawan, NJ.
His research interests include signal processing, communications, and their applications to 
distributed sensor processing and wireless sensor networks.

xlii
Authors Biography
Rick S. Blum received a B.S. in Electrical Engineering from the Pennsylvania 
State University in 1984 and his M.S. and Ph.D in Electrical Engineering from 
the University of Pennsylvania in 1987 and 1991.
From 1984 to 1991 he was a member of technical staff at General Electric 
Aerospace in Valley Forge, Pennsylvania and he graduated from GE‘s Advanced 
Course in Engineering. Since 1991, he has been with the Electrical and Computer 
Engineering Department at Lehigh University in Bethlehem, Pennsylvania 
where he is currently a Professor and holds the Robert W. Wieseman Chaired 
Research Professorship in Electrical Engineering. His research interests include 
signal processing for smart grid, communications, sensor networking, radar and sensor processing. 
He is on the editorial board for the Journal of Advances in Information Fusion of the International 
Society of Information Fusion. He was an associate editor for IEEE Transactions on Signal Processing 
and for IEEE Communications Letters. He has edited special issues for IEEE Transactions on Signal 
Processing, IEEE Journal of Selected Topics in Signal Processing and IEEE Journal on Selected 
Areas in Communications. He is a member of the SAM Technical Committee (TC) of the IEEE 
Signal Processing Society. He was a member of the Signal Processing for Communications TC of 
the IEEE Signal Processing Society and is a member of the Communications Theory TC of the IEEE 
Communication Society. He was on the awards Committee of the IEEE Communication Society.
He is a Fellow of the IEEE, an IEEE Third Millennium Medal winner, a member of Eta Kappa 
Nu and Sigma Xi, and holds several patents. He was awarded an ONR Young Investigator Award 
in 1997 and an NSF Research Initiation Award in 1992. His IEEE Fellow Citation “for scientific 
contributions to detection, data fusion and signal processing with multiple sensors” acknowledges 
contributions to the field of sensor networking.
CHAPTER 14
Joseph R. Guerci has over 29 years of experience in advanced technology 
research and development in government, industrial, and academic settings. 
His government service included a 7-year term with the Defense Advanced 
Research Projects Agency (DARPA) in which he held the positions of Program 
Manager, Deputy Office Director, and finally Director of the Special Projects 
Office (SPO). In these capacities, he was involved in the inception, research, 
development, execution, and ultimately transition of next generation multi-
disciplinary defense technologies.
He is also a recognized leader in the research and development of next gen-
eration sensor and electronic warfare systems. In addition to authoring over 100 peer-reviewed 
articles, he has several book chapters and is the author of Space-Time Adaptive Processing for 
Radar (Artech House, 2003), and the recently published Cognitive Radar: The Knowledge-Aided 
Fully Adaptive Approach, (Artech House, 2010). He also recently received the Warren D. White 
Award from the Institute of Electrical and Electronics Engineers (IEEE) for “Excellence in Radar 
Adaptive Processing and Waveform Diversity,” and the IEEE Waveform Diversity Person of the 
Year for 2010 for “For Scientific, Technical, and Executive Leadership Contributions in Making 
Waveform Diversity a Fielded Technology.” He has also recently been appointed the General 

xliii
Authors Biography
Chair for the 2015 IEEE International Radar Conference, and is an elected member of the IEEE 
Aerospace and Electronic Systems Society (AESS) Board of Governors.
A graduate of Polytechnic University (now NYU School of Engineering) with a Ph.D.E.E 
(System Engineering), he has held adjunct professorships in engineering and applied math-
ematics at The City University of New York, Polytechnic University, The Cooper Union for 
Advancement of Art and Science, and Virginia Tech. Additionally, he has held senior engineer 
and scientist positions in industry and was Chief Technology Officer (CTO) for SAIC’s $2B+/
year Research, Development, Test & Evaluation (RDT&E) Group. A member of the IEEE Radar 
Systems panel, he is also a Fellow of the IEEE for “Contributions to Advanced Radar Theory 
and its Embodiment in Real-World Systems,” holds eight US Patents, and is a member of several 
industrial, academic, and government advisory boards including the Air Force Scientific Advisory 
Board (SAB) for a 4-year term beginning in the Fall of 2013.
CHAPTER 15
X. Chen  He was born in P.R. China, 1981. He received his B.Eng. and M.Eng. 
degrees, both in electronic engineering, from the University of Electronic 
Science and Technology of China (UESTC), ChengDu, SiChuan Prov., P.R. 
China in 2004 and 2007, respectively. He received his Ph.D. degree in electri-
cal and computer engineering from McMaster University, Hamilton, Ontario, 
Canada, in 2012. Currently he is working as a Postdoctoral Researcher in the 
Electrical and Computer Engineering Department at McMaster University, 
Canada. His research interests include point processes, multitarget-multisen-
sor state estimation and tracking, probability density estimation, and general 
stochastic signal processing using the stochastic differential equation (SDE).
R. Tharmarasa He received the B.Sc.Eng. degree in electronic and telecom-
munication engineering from University of Moratuwa, Sri Lanka in 2001, 
and the M.A.Sc. and Ph.D. degrees in electrical engineering from McMaster 
University, Canada in 2003 and 2007, respectively. From 2001 to 2002 he 
was an instructor in electronic and telecommunication engineering at the 
University of Moratuwa, Sri Lanka. During 2002–2007 he was a graduate 
student/research assistant in ECE department at the McMaster University, 
Canada. Currently he is working as a Research Associate in the Electrical 
and Computer Engineering Department at McMaster University, Canada. His 
research interests include target tracking, information fusion and sensor resource management.
T. Kirubarajan Thiagalingam Kirubarajan received the B.A. and M.A. degrees in electrical and 
information engineering from Cambridge University, England, in 1991 and 1993, and the M.S. 
and Ph.D. degrees in electrical engineering from the University of Connecticut, Storrs, in 1995 
and 1998, respectively. Currently, he is a professor in the Electrical and Computer Engineering 

xliv
Authors Biography
Department at McMaster University, Hamilton, Ontario. He is also serving as 
an Adjunct Assistant Professor and the Associate Director of the Estimation 
and Signal Processing Research Laboratory at the University of Connecticut. 
His research interests are in estimation, target tracking, multisource infor-
mation fusion, sensor resource management, signal detection and fault diag-
nosis. His research activities at McMaster University and at the University 
of Connecticut are supported by US Missile Defense Agency, US Office of 
Naval Research, NASA, Qualtech Systems, Inc., Raytheon Canada Ltd. and 
Defense Research Development Canada, Ottawa. In September 2001, Dr. 
Kirubarajan served in a DARPA expert panel on unattended surveillance, homeland defense 
and counterterrorism. He has also served as a consultant in these areas to a number of compa-
nies, including Motorola Corporation, Northrop-Grumman Corporation, Pacific-Sierra Research 
Corporation, Lockhead Martin Corporation, Qualtech Systems, Inc., Orincon Corporation and 
BAE systems. He has worked on the development of a number of engineering software programs, 
including BEARDAT for target localization from bearing and frequency measurements in clut-
ter, FUSEDAT for fusion of multisensor data for tracking. He has also worked with Qualtech 
Systems, Inc., to develop an advanced fault diagnosis engine. He has published about 100 articles 
in areas of his research interests, in addition to one book on estimation, tracking and navigation 
and two edited volumes. He is a recipient of Ontario Premier’s Research Excellence Award 
(2002).
CHAPTER 16
Hugh Griffiths holds the THALES/Royal Academy Chair of RF Sensors in the 
Department of Electronic and Electrical Engineering at University College 
London, England. From 2006 to 2008 he was Principal of the Defence 
Academy College of Management and Technology. He received the MA degree 
in Physics from Oxford University in 1975, then spent 3 years working in indus-
try, before joining University College London, where he received the Ph.D. 
degree in 1986 and the DSc(Eng) degree in 2000. He served as Head of 
Department from 2001 to 2006.
His research interests include radar and sonar systems and signal pro-
cessing (particularly synthetic aperture radar and bistatic and multistatic radar), and antenna 
measurement techniques. He has published over 400 papers and technical articles in the fields 
of radar, antennas, and sonar. In 1996 he received the IEEE AESS Nathanson Award (Radar 
Systems Panel Award). He has also received the URSI Young Scientist Award, the IERE Brabazon 
Premium and the IEE Mountbatten and Maxwell Premium Awards, and he received the NATO 
SET Panel Award in 2012 as one of the lecturers on the NATO SET-119 Lecture Series on 
“Waveform Diversity.” He is a Fellow of the IET, Fellow of the IEEE, and in 1997 he was elected 
to Fellowship of the Royal Academy of Engineering. He serves as President of the IEEE Aerospace 
and Electronic Systems Society for 2012/2013.

xlv
Authors Biography
CHAPTER 17
Moeness G. Amin received his Ph.D. degree in 1984 from University of 
Colorado, in Electrical Engineering. He has been on the Faculty of the 
Department of Electrical and Computer Engineering at Villanova University 
since 1985. In 2002, he became the Director of the Center for Advanced 
Communications, College of Engineering.
He is the Recipient of the 2009 Individual Technical Achievement Award 
from the European Association of Signal Processing, and the Recipient of the 
2010 NATO Scientific Achievement Award. He is a Fellow of the Institute 
of Electrical and Electronics Engineers (IEEE), Fellow of the International 
Society of Optical Engineering; and a Fellow of the Institute of Engineering and Technology 
(IET). He is a Recipient of the IEEE Third Millennium Medal; Recipient of the Chief of Naval 
Research Challenge Award, 2010; Distinguished Lecturer of the IEEE Signal Processing Society, 
2003–2004; Active Member of the Franklin Institute Committee on Science and the Arts; 
Recipient of Villanova University Outstanding Faculty Research Award, 1997; and the Recipient 
of the IEEE Philadelphia Section Award, 1997. He is a member of IEEE, SPIE, EURASIP, ION, 
Eta Kappa Nu, Sigma Xi, and Phi Kappa Phi.
He has over 450 journal and conference publications in the areas of Wireless Communications, 
Time-Frequency Analysis, Smart Antennas, Waveform Design and Diversity, Interference 
Cancellation in Broadband Communication Platforms, Anti- Jam GPS, Target Localization 
and Tracking, Direction Finding, Channel Diversity and Equalization, Ultrasound Imaging and 
Radar Signal Processing. He is a recipient of seven best paper awards. He currently serves on the 
Overview Board of the IEEE Transactions on Signal Processing. He also serves on the Editorial 
Board of the EURASIP Signal Processing Journal and the Editorial Board of the Signal Processing 
Magazine. He was a Plenary Speaker at ICASSP 2010. He was the Special Session Co-Chair of 
the 2008 IEEE International Conference on Acoustics, Speech, and Signal Processing. He was 
the Technical Program Chair of the second IEEE International Symposium on Signal Processing 
and Information Technology, 2002. He was the General and Organization Chair of the IEEE 
Workshop on Statistical Signal and Array Processing, 2000. He was the General and Organization 
Chair of the IEEE International Symposium on Time-Frequency and Time-Scale Analysis, 1994. 
He was an Associate Editor of the IEEE Transactions on Signal Processing during 1996–1998. He 
was a member of the IEEE Signal Processing Society Technical Committee on Signal Processing 
for Communications during 1998–2002. He was a Member of the IEEE Signal Processing Society 
Technical Committee on Statistical Signal and Array Processing during 1995–1997.
He was the Guest Editor of the Journal of Franklin Institute September 2008 Special Issue on 
Advances in Indoor Radar Imaging. He was a Guest Editor of the IEEE Transactions on Geoscience 
and Remote Sensing May 2009 Special Issue on Remote Sensing of Building Interior, and a Guest 
Editor of the IET Signal Processing December 2009 Special Issue on Time-Frequency Approach 
to Radar Detection, Imaging, and Classification.
Fauzia Ahmad received her MS degree in Electrical Engineering in 1996, and Ph.D. degree in 
Electrical Engineering in 1997, both from the University of Pennsylvania, Philadelphia, PA.
From 1998 to 2000, she was an Assistant Professor in the College of Electrical and 
Mechanical Engineering, National University of Sciences and Technology, Pakistan. During 

xlvi
Authors Biography
2000–2001, she served as an Assistant Professor at Fizaia College of 
Information Technology, Pakistan. Since 2002, she has been with the Center 
for Advanced Communications, Villanova University, Villanova, PA, where 
she is now a Research Associate Professor and the Director of the Radar 
Imaging Laboratory.
She has over 110 journal and conference publications in the areas of radar 
imaging, radar signal processing, waveform design and diversity, compressive 
sensing, array signal processing, sensor networks, ultrasound imaging, and 
over-the-horizon radar.
CHAPTER 18
Stefan V. Baumgartner received the Dipl.-Ing. degree in Electrical Engineering 
and Communication Technology from the Graz University of Technology, 
Graz, Austria in 2004.
Since 2004, he has been with the Microwaves and Radar Institute (HR), 
German Aerospace Center (DLR), Oberpfaffenhofen, Germany. He is cur-
rently with the Radar Concepts Department, where his field of activity is the 
development of ground moving target indication and parameter estimation 
algorithms for future road-traffic-monitoring applications using multichannel 
air- and spaceborne synthetic aperture radars (SAR). His research interests 
include SAR along-track interferometry, time–frequency analysis, and other advanced signal and 
imaging processing techniques.
Gerhard Krieger received the Dipl.-Ing. (M.S.) and Dr.-Ing. (Ph.D.) degrees 
(with honors) in electrical and communication engineering from the Technical 
University of Munich, Germany, in 1992 and 1999, respectively. 
From 1992 to 1999, he was with the Ludwig Maximilians University, 
Munich, where he conducted multidisciplinary research on neuronal model-
ing and nonlinear information processing in biological and technical vision sys-
tems. Since 1999, he has been with the Microwaves and Radar Institute (HR) 
of the German Aerospace Center (DLR), Oberpfaffenhofen, Germany, where 
he developed signal and image processing algorithms for a novel forward look-
ing radar system employing digital beamforming on receive. From 2001 to 2007 he led the New 
Synthetic Aperture Radar (SAR) Missions Group which pioneered the development of advanced 
bistatic and multistatic radar systems as exemplified by the TanDEM-X mission, as well as inno-
vative multichannel SAR techniques and algorithms for high-resolution wide-swath SAR imaging. 
Since 2008, he has been the Head of the new Radar Concepts Department of the Microwaves 
and Radar Institute, DLR, Oberpfaffenhofen, Germany. Gerhard Krieger has authored more 
than 50 peer-reviewed journal papers, 7 invited book chapters, about 300 conference papers, 
and 5 patent families. His current research interests focus on the development of multichannel 
radar techniques and algorithms for innovative Multiple-Input Multiple-Output (MIMO) SAR 
systems, the demonstration of novel interferometric and tomographic Earth observation applica-
tions, and the conceptual design of advanced bi- and multistatic radar missions.

xlvii
Authors Biography
He is IEEE Fellow and received several national and international awards, including the 
W.R.G. Baker Prize Paper Award from the IEEE Board of Directors and the Transactions Prize 
Paper Award of the IEEE Geoscience and Remote Sensing Society. In 2012, he and his colleagues 
were nominated for the German President’s Award for Technology and Innovation. Since 2012, 
he has been Associate Editor of the IEEE Transactions on Geoscience and Remote Sensing.
CHAPTER 19
Marco Martorella received his Laurea degree (Bachelor+Masters) in 
Telecommunication Engineering in 1999 (cum laude) and his PhD in Remote 
Sensing in 2003, both at the University of Pisa. He is now an Associate Professor 
at the Department of Information Engineering of the University of Pisa where 
he lectures “Fundamentals of Radar” and “Digital Communications” and an 
external Professor at the University of Cape Town where he lectures “High 
Resolution and Imaging Radar” within the “Masters in Radar and Electronic 
Defence.” He is a regular visiting Professor at the University of Adelaide and 
at the University of Queensland in Australia. He is author of more than a 100 
international journal and conference papers and three book chapters. He has presented several 
tutorials at international radar conferences and organized a special issue on Inverse Synthetic 
Aperture Radar for the Journal of Applied Signal Processing. He is a member of the IET Radar 
Sonar and Navigation Editorial Board, a senior member of the IEEE, and a member of AFCEA. 
He is also chair of the NATO SET-196 on “Multichannel/Multistatic radar imaging of non-coop-
erative targets.” He has been recipient of the 2008 Italy-Australia Award for young researchers, 
the 2010 Best Reviewer for the IEEE GRSL and the IEEE 2013 Fred Nathanson Memorial Radar 
Award. His research interests are mainly in the field of radar imaging, including passive, multi-
channel, multistatic and polarimetric radar imaging.
CHAPTER 20
Gianfranco Fornaro received the M.S. degree (summa cum laude) in electronic 
engineering and the Ph.D. degree from the University of Naples “Federico 
II” in 1992 and 1997, respectively. Since 1993 he has been with Institute for 
Electromagnetic Sensing of the Environment (IREA) of the Italian National 
Research Council, Naples, where he is currently a senior researcher work-
ing in the area of Synthetic Aperture Radar (SAR) focusing, SAR interfer-
ometry, and SAR tomography. He has been Adjunct Professor in the area of 
communications in several Universities, currently at the University of Napoli 
“Parthenope.” He has been visiting scientist at the Politecnico of Milano and at 
the German Aerospace Establishment (DLR), also for within the Italy-Germany cooperation dur-
ing the SIR-C/X-SAR mission. He has been United Nations consultant at the Istituto Tecnologico 
de Aeronautica (ITA) in Sao José dos Campos (Brazil) and at RESTEC (Tokyo). Since 2010 he has 
been Lecturer at the International radar/SAR Summer School of the Fraunhofer Institute; he has 
been also Convener, Tutorial Lecturer, and Chairman of sessions dedicated to SAR processing and 

xlviii
Authors Biography
SAR interferometry in several international conferences. He has authored more than a hundred 
of papers (peer-review journals and proceedings of international conferences); in 2005 served as 
Editor of the “Advances in Interferometric SAR processing” special issue of the EURASIP Journal 
on Applied Signal Processing (JASP). He received the Mountbatten Premium by the Institution 
of Electrical Engineers (IEE) in 1997, the Institute of Electrical and Electronics Engineers (IEEE) 
Geoscience and 2011 Remote Sensing Letters Best Paper Award, and the Mention for Best 2011 
Reviewer for the IEEE Transactions on Geoscience and Remote Sensing journal.
Vito Pascazio graduated summa cum laude in 1986 at the Università di Bari, 
Italy, in Electronic Engineering. In the same year he joined the Department of 
Electronic Engineering of the Università di Napoli Federico II, Italy, where, in 1990 
he received the Ph.D. degree in Electronic Engineering and Computer Science. 
During the same year he was awarded of the Philip Morris Prize for Scientific 
and Technological Research. In 1990 he was first at the Research Institute on 
Electromagnetics and Electronic Devices (IRECE) of the Italian National Council 
of Research (CNR), Napoli, Italy, and then he joined the Università di Napoli 
Parthenope, Italy, where he is presently Full Professor of Telecommunications. 
In 1994–1995 he was visiting scientist at the Laboratoire des Signaux et Systemes of the Ecole 
Superieure d’Electricite (Supelec), Gif sur Yvette, France, and in 1998–1999 at the Universite de 
Nice Sophia-Antipolis, France. He is presently also Director of National Laboratory of Multi-Media 
Communications of the Italian Inter- University Consortium of Telecommunications (CNIT), 
Napoli, Italy. His main scientific interests are in the fields of Remote Sensing, and Linear and Non-
linear Estimation, with particular emphasis to image computing and processing and reconstruction 
of microwave and radar images. He is Associate Editor of International Journal of Navigation and 
Observation. He published more than 150 technical papers, and he is Senior Member of IEEE.
CHAPTER 21
Laurent Ferro-Famil received the Laurea degree in electronics systems and com-
puter engineering, the M.S. degree in electronics, and the Ph.D. degree from the 
University of Nantes, Nantes, France, in 1996, 1996, and 2000, respectively.
In 2001 he became an Associate Professor and since 2011 he has been a 
Full Professor with the University of Rennes 1, Rennes, France, where he is 
currently the head of the Remote Sensing department, within the Institute of 
Electronics and Telecommunications of Rennes. His current activities in edu-
cation are concerned with analog electronics, digital communications, micro-
wave theory, signal processing, and polarimetric SAR remote sensing. He is 
particularly interested in polarimetric SAR signal statistical processing, radar polarimetry theory, 
and natural media remote sensing using multibaseline PolInSAR data, with application to clas-
sification, electromagnetic scattering modeling and physical parameter retrieval, time-frequency 
analysis, and 3-D reconstruction of environments using tomography.
Eric Pottier (M’95, SM’06, F’11) received the M.Sc. and Ph.D. in signal processing and telecom-
munication from the University of Rennes 1, respectively, in 1987 and 1990, and the Habilitation 
from the University of Nantes in 1998.

xlix
Authors Biography
Since 1999, he has been a Full Professor at the University of Rennes 1, 
France, where he is currently the Director of the Institute of Electronics 
and Telecommunications of Rennes (I.E.T.R—CNRS UMR 6164). His cur-
rent activities of research and education are centered in the topics of ana-
log electronics, microwave theory, and radar imaging with emphasis in radar 
polarimetry. His research covers a wide spectrum of areas from radar image 
processing (SAR, ISAR), polarimetric scattering modeling, supervised/unsu-
pervised polarimetric segmentation, and classification to fundamentals and 
basic theory of polarimetry.
He has published 10 chapters in books, more than 60 papers in refereed journals and pre-
sented more than 350 papers during International Conferences, Symposiums, and Workshops. 
He has presented advance courses and seminars on Radar Polarimetry to a wide range of organiza-
tions and events.
He was presented the Best Paper Award at the Third European Conference on Synthetic 
Aperture Radar (EUSAR2000) and received the 2007 IEEE GRS-S Letters Prize Paper Award.
He has published a book co-authored with Dr. Jong-Sen Lee: Polarimetric Radar Imaging: 
From basics to applications,” CRC Press, Taylor & Francis editor, 397 pages, January. 2009, ISBN: 
978-1-4200-5497-2.
He is a recipient of the 2007 IEEE GRS-S Education Award “In recognition of his significant 
educational contributions to Geoscience and Remote Sensing.”
He has been elevated to IEEE Fellow (January 2011) with the accompanying citation: “for 
contributions to polarimetric Synthetic Aperture Radar.”
He is a recipient of the 2012 Einstein Professorship from the Chinese Academy of Science.
CHAPTER 22
Alfonso Farina (M’95–SM’98–F’00) received the doctor degree in electronic 
engineering from the University of Rome (I), Italy, in 1973. 
In 1974, he joined Selenia, now SELEX Electronic Systems, where he 
has been a Manager since May 1988. He was Scientific Director in the Chief 
Technical Office. He was the Director of the Analysis of Integrated Systems 
Unit. He was also the Director of Engineering in the Large Business Systems 
Division. In 2012, he was the Chief Technology Officer of the Company 
(SELEX Sistemi Integrati) reporting directly to the President. Today he is 
Senior Advisor to CTO of SELEX ES. In his professional life, he has provided 
technical contributions to detection, signal, data, image processing and fusion for the main radar 
systems conceived, designed, and developed in the Company. He has provided leadership in 
many projects—also conducted in the international arena—in surveillance for ground and naval 
applications, in airborne early warning and in imaging radar. From 1979 to 1985, he has also 
been a Professor of radar techniques with the University of Naples; in 1985 he was appointed 
Associate Professor. He is the author of more than 500 peer-reviewed technical publications and 
the author of books and monographs: Radar Data Processing (Vol. 1 and 2) (translated in Russian 
and Chinese), (UK: Researches Studies Press, and New York: Wiley, 1985–1986); Optimized 
Radar Processors, (on behalf of IEE, London, UK: Peter Peregrinus, 1987); and Antenna Based 

l
Authors Biography
Signal Processing Techniques for Radar Systems, 1992. He wrote the chapter “ECCM Techniques” 
in the Radar Handbook (2nd ed., 1990, and 3rd ed., 2008), edited by Dr. M. I. Skolnik  
(NRL, USA).
He has been session chairman at many international radar conferences. In addition to lec-
turing at universities and research centers in Italy and abroad, he also frequently gives tutori-
als at the International Radar Conferences on signal, data, and image processing for radar; in 
particular on multisensor fusion, adaptive signal processing, space-time adaptive processing 
(STAP), and detection. In 1987, he received the Radar Systems Panel Award of IEEE Aerospace 
and Electronic Systems Society (AESS) for development of radar data processing techniques. 
He is the Italian representative of the International Radar Systems Panel of the IEEE AESS. 
He is VP for industry in the BoG of IEEE AESS. He has been the Italian industrial represen-
tative (Panel Member at Large) at the Sensor and Electronic Technology (SET) of Research 
Technology Organisation (RTO) of NATO. He has been on the BoD of the International Society 
for Information Fusion (ISIF). He has been the Executive Chair of the International Conference 
on Information Fusion (Fusion) 2006, Florence, Italy, July 10–13, 2006.  He has been nominated 
Fellow of IEEE with the following citation: “For development and application of adaptive signal 
processing methods for radar systems.” Recently, he has been nominated international fellow of 
the Royal Academy of Engineering, UK; this fellowship was presented to him by HRH Prince 
Philip, the Duke of Edinburgh. He is a referee of numerous publications submitted to several 
journals of IEEE, IEE, Elsevier, etc. He has also cooperated with the Editorial Board of the IEE 
Electronics & Communication Engineering Journal. More recently, he has served as a member of 
the Editorial Board of Signal Processing (Elsevier) and has been Co-Guest Editor of its Special 
Issue on New Trends and Findings in Antenna Array Processing for Radar, September 2004. 
He is the corecipient of the following Best Paper Awards: entitled to B. Carlton of the IEEE 
TRANSACTIONS ON AEROSPACE AND ELECTRONIC SYSTEMS for 2001 and 2003 and 
also of the International Conference on Fusion 2005. He has been the leader of the team that 
received the 2002 AMS CEO award for Innovation Technology. He has been the corecipient of 
the AMS Radar Division award for Innovation Technology in 2003. Moreover, he has been the 
corecipient of the 2004 AMS CEO Award for Innovation Technology.
He has been the leader of the team that won the 2004 First Prize Award for Innovation 
Technology of Finmeccanica, Italy. This award context has seen the submission of more than 320 
projects. This award has been set for the first time in 2004. In September 7, 2006, he received 
the Annual European Group Technical Achievement Award 2006 by the European Association 
for Signal, Speech and Image Processing (EURASIP), with the citation: “For development and 
application of adaptive signal processing technique in practical radar systems.” In 2006 and 2009, 
he was a corecipient of the annual Innovation Technology award of SELEX Sistemi Integrati. 
He has been appointed member in the Editorial Boards of IET Radar, Sonar and Navigation and 
of Signal, Image, and Video Processing Journal (SIVP). He has been the General Chairman of 
the IEEE Radar Conference 2008, Rome, May 26–30, 2008. He is a Fellow of the Institution of 
Engineering and Technology (IET), UK. He has been recently nominated Fellow of EURASIP, 
the citation reads: “For contributions to radar system design, signal, data and image process-
ing, data fusion and particularly for the development of innovative algorithms for deployment 
into practical radar systems.” He is also the recipient of the 2010 IEEE Dennis J. Picard Gold 

li
Authors Biography
Medal for Radar Technologies and Applications with the following citation: “For continuous, 
innovative, theoretical and practical contributions to radar systems and adaptive signal processing 
techniques.”
Luciana Ortenzi received the Doctor Degree in Telecommunications 
Engineering in October 2001 from the University of Rome, “La Sapienza” 
and Ph.D. in Remote Sensing applications in March 2007. She joined AMS, 
now SELEX Electronic Systems, in February 2002, and since then she works in 
the area of Integrated System Analysis Group as a system analyst. Her areas of 
investigation are oriented toward adaptive signal processing, detection, estima-
tion, and tracking filtering for radar systems development, integrated system 
design for homeland security. She has been the corecipient of the 2003 AMS 
MD Award for Innovation Technology for and the 2006 Innovation Technology 
Award of Selex-Sistemi Integrati.
Branko Ristic received Ph.D. degree in 1995 from Queensland University 
of Technology. He held various research/engineering positions in former 
Yugoslavia and Australia before joining in 1996 the Australian Defence Science 
and Technology Organization (DSTO). His research interests include nonlinear 
filtering, target tracking, sensor fusion, and reasoning under uncertainty.
He co-authored two books: Beyond the Kalman filter, (Artech House, 
2004), and Particle filters for random set models (Springer, 2013, in press) 
and published over 60 journal papers. He is currently an Associate Editor of 
the IEEE Transactions on Signal Processing.
Alex Skvortsor He holds PhD degree from Moscow Tech University in 
Mathematical Physics.  Dr Skvortsov has been working in Defence Science and 
Technology Organisation (DSTO) since 2005. His current role is the Science 
Team Leader in Hazard Modelling. His areas of research include atmospheric 
dispersion, hazard source backtracking, sensor systems and mathematical 
biology. He published more than 50 papers.

xxiii
Signal Processing at Your Fingertips!
Let us flash back to the 1970s when the editors-in-chief of this e-reference were graduate students. 
One of the time-honored traditions then was to visit the libraries several times a week to keep track of 
the latest research findings. After your advisor and teachers, the librarians were your best friends. We 
visited the engineering and mathematics libraries of our Universities every Friday afternoon and poured 
over the IEEE Transactions, Annals of Statistics, the Journal of Royal Statistical Society, Biometrika, 
and other journals so that we could keep track of the recent results published in these journals. Another 
ritual that was part of these outings was to take sufficient number of coins so that papers of interest 
could be xeroxed. As there was no Internet, one would often request copies of reprints from authors 
by mailing postcards and most authors would oblige. Our generation maintained thick folders of hard-
copies of papers. Prof. Azriel Rosenfeld (one of RC’s mentors) maintained a library of over 30,000 
papers going back to the early 1950s!
Another fact to recall is that in the absence of Internet, research results were not so widely dis-
seminated then and even if they were, there was a delay between when the results were published in 
technologically advanced western countries and when these results were known to scientists in third 
world countries. For example, till the late 1990s, scientists in US and most countries in Europe had a 
lead time of at least a year to 18 months since it took that much time for papers to appear in journals 
after submission. Add to this the time it took for the Transactions to go by surface mails to various 
libraries in the world. Scientists who lived and worked in the more prosperous countries were aware of 
the progress in their fields by visiting each other or attending conferences.
Let us race back to 21st century! We live and experience a world which is fast changing with rates 
unseen before in the human history. The era of Information and Knowledge societies had an impact on 
all aspects of our social as well as personal lives. In many ways, it has changed the way we experience 
and understand the world around us; that is, the way we learn. Such a change is much more obvious to 
the younger generation, which carries much less momentum from the past, compared to us, the older 
generation. A generation which has grew up in the Internet age, the age of Images and Video games, the 
age of IPAD and Kindle, the age of the fast exchange of information. These new technologies comprise 
a part of their “real” world, and Education and Learning can no more ignore this reality. Although many 
questions are still open for discussions among sociologists, one thing is certain. Electronic publishing 
and dissemination, embodying new technologies, is here to stay. This is the only way that effective 
pedagogic tools can be developed and used to assist the learning process from now on. Many kids in the 
early school or even preschool years have their own IPADs to access information in the Internet. When 
they grow up to study engineering, science, or medicine or law, we doubt if they ever will visit a library 
as they would by then expect all information to be available at their fingertips, literally!
Another consequence of this development is the leveling of the playing field. Many institutions in 
lesser developed countries could not afford to buy the IEEE Transactions and other journals of repute. 
Even if they did, given the time between submission and publication of papers in journals and the time 
it took for the Transactions to be sent over surface mails, scientists and engineers in lesser developed 
countries were behind by two years or so. Also, most libraries did not acquire the proceedings of confer-
ences and so there was a huge gap in the awareness of what was going on in technologically advanced 
Introduction

xxiv
Introduction
countries. The lucky few who could visit US and some countries in Europe were able to keep up with 
the progress in these countries. This has changed. Anyone with an Internet connection can request or 
download papers from the sites of scientists. Thus there is a leveling of the playing field which will lead 
to more scientist and engineers being groomed all over the world.
The aim of Online Reference for Signal Processing project is to implement such a vision. We all 
know that asking any of our students to search for information, the first step for him/her will be to click 
on the web and possibly in the Wikipedia. This was the inspiration for our project. To develop a site, 
related to the Signal Processing, where a selected set of reviewed articles will become available at a 
first “click.” However, these articles are fully refereed and written by experts in the respected topic. 
Moreover, the authors will have the “luxury” to update their articles regularly, so that to keep up with 
the advances that take place as time evolves. This will have a double benefit. Such articles, besides the 
more classical material, will also convey the most recent results providing the students/researchers with 
up-to-date information. In addition, the authors will have the chance of making their article a more 
“permanent” source of reference, that keeps up its freshness in spite of the passing time.
The other major advantage is that authors have the chance to provide, alongside their chapters, any 
multimedia tool in order to clarify concepts as well as to demonstrate more vividly the performance of 
various methods, in addition to the static figures and tables. Such tools can be updated at the author’s 
will, building upon previous experience and comments. We do hope that, in future editions, this aspect 
of this project will be further enriched and strengthened.
In the previously stated context, the Online Reference in Signal Processing provides a revolutionary 
way of accessing, updating and interacting with online content. In particular, the Online Reference will 
be a living, highly structured, and searchable peer-reviewed electronic reference in signal/image/video 
Processing and related applications, using existing books and newly commissioned content, which 
gives tutorial overviews of the latest technologies and research, key equations, algorithms, applications, 
standards, code, core principles, and links to key Elsevier journal articles and abstracts of non-Elsevier 
journals.
The audience of the Online Reference in Signal Processing is intended to include practicing engi-
neers in signal/image processing and applications, researchers, PhD students, post Docs, consultants, 
and policy makers in governments. In particular, the readers can be benefited in the following needs:
• 
To learn about new areas outside their own expertise.
• 
To understand how their area of research is connected to other areas outside their expertise.
• 
To learn how different areas are interconnected and impact on each other: the need for a 
“helicopter” perspective that shows the “wood for the trees.”
• 
To keep up-to-date with new technologies as they develop: what they are about, what is their 
potential, what are the research issues that need to be resolved, and how can they be used.
• 
To find the best and most appropriate journal papers and keeping up-to-date with the newest, best 
papers as they are written.
• 
To link principles to the new technologies.
The Signal Processing topics have been divided into a number of subtopics, which have also dic-
tated the way the different articles have been compiled together. Each one of the subtopics has been 
coordinated by an AE (Associate Editor). In particular:

xxv
Introduction
	 1.	 Signal Processing Theory (Prof. P. Diniz)
	 2.	 Machine Learning (Prof. J. Suykens)
	 3.	 DSP for Communications (Prof. N. Sidiropulos)
	 4.	 Radar Signal Processing (Prof. F. Gini)
	 5.	 Statistical SP (Prof. A. Zoubir)
	 6.	 Array Signal Processing (Prof. M. Viberg)
	 7.	 Image Enhancement and Restoration (Prof. H. J. Trussell)
	 8.	 Image Analysis and Recognition (Prof. Anuj Srivastava)
	 9.	 Video Processing (other than compression), Tracking, Super Resolution, Motion Estimation, 
etc. (Prof. A. R. Chowdhury)
10.	 Hardware and Software for Signal Processing Applications (Prof. Ankur Srivastava)
11.	 Speech Processing/Audio Processing (Prof. P. Naylor)
12.	 Still Image Compression
13.		 Video Compression
We would like to thank all the Associate Editors for all the time and effort in inviting authors as well  
as coordinating the reviewing process. The Associate Editors have also provided succinct summaries  
of their areas.
The articles included in the current editions comprise the first phase of the project. In the second 
phase, besides the updates of the current articles, more articles will be included to further enrich the 
existing number of topics. Also, we envisage that, in the future editions, besides the scientific articles 
we are going to be able to include articles of historical value. Signal Processing has now reached an age 
that its history has to be traced back and written.
Last but not least, we would like to thank all the authors for their effort to contribute in this new 
and exciting project. We earnestly hope that in the area of Signal Processing, this reference will help 
level the playing field by highlighting the research progress made in a timely and accessible manner to 
anyone who has access to the Internet. With this effort the next breakthrough advances may be coming 
from all around the world.
The companion site for this work: http://booksite.elsevier.com/9780124166165 includes multimedia 
files (Video/Audio) and MATLAB codes for selected chapters.
Rama Chellappa
Sergios Theodoridis

xxvii
Rama Chellappa received the B.E. (Hons.) degree in Electronics and Communication 
Engineering from the University of Madras, India in 1975 and the M.E. (with 
Distinction) degree from the Indian Institute of Science, Bangalore, India in 1977. 
He received the M.S.E.E. and Ph.D. Degrees in Electrical Engineering from Purdue 
University, West Lafayette, IN, in 1978 and 1981, respectively. During 1981–
1991, he was a faculty member in the department of EE-Systems at University 
of Southern California (USC). Since 1991, he has been a Professor of Electrical 
and Computer Engineering (ECE) and an affiliate Professor of Computer Science 
at University of Maryland (UMD), College Park. He is also affiliated with the 
Center for Automation Research, the Institute for Advanced Computer Studies (Permanent Member) 
and is serving as the Chair of the ECE department. In 2005, he was named a Minta Martin Professor 
of Engineering. His current research interests are face recognition, clustering and video summariza-
tion, 3D modeling from video, image and video-based recognition of objects, events and activities, 
dictionary-based inference, compressive sensing, domain adaptation and hyper spectral processing.
Prof. Chellappa received an NSF Presidential Young Investigator Award, four IBM Faculty 
Development Awards, an Excellence in Teaching Award from the School of Engineering at USC, and 
two paper awards from the International Association of Pattern Recognition (IAPR). He is a recipient 
of the K.S. Fu Prize from IAPR. He received the Society, Technical Achievement, and Meritorious 
Service Awards from the IEEE Signal Processing Society. He also received the Technical Achievement 
and Meritorious Service Awards from the IEEE Computer Society. At UMD, he was elected as a 
Distinguished Faculty Research Fellow, as a Distinguished Scholar-Teacher, received an Outstanding 
Innovator Award from the Office of Technology Commercialization, and an Outstanding GEMSTONE 
Mentor Award from the Honors College. He received the Outstanding Faculty Research Award and the 
Poole and Kent Teaching Award for Senior Faculty from the College of Engineering. In 2010, he was 
recognized as an Outstanding ECE by Purdue University. He is a Fellow of IEEE, IAPR, OSA, and 
AAAS. He holds four patents.
Prof. Chellappa served as the Editor-in-Chief of IEEE Transactions on Pattern Analysis and Machine 
Intelligence. He has served as a General and Technical Program Chair for several IEEE international 
and national conferences and workshops. He is a Golden Core Member of the IEEE Computer Society 
and served as a Distinguished Lecturer of the IEEE Signal Processing Society. Recently, he completed 
a two-year term as the President of the IEEE Biometrics Council.
About the Editors

xxviii
About the Editors
Sergios Theodoridis is currently Professor of Signal Processing and 
Communications in the Department of Informatics and Telecommunications 
of the University of Athens. His research interests lie in the areas of Adaptive 
Algorithms and Communications, Machine Learning and Pattern Recognition, 
Signal Processing for Audio Processing and Retrieval. He is the co-editor of the 
book “Efficient Algorithms for Signal Processing and System Identification,” 
Prentice Hall 1993, the co-author of the best selling book “Pattern Recognition,” 
Academic Press, 4th ed. 2008, the co-author of the book “Introduction to Pattern 
Recognition: A MATLAB Approach,” Academic Press, 2009, and the co-author of 
three books in Greek, two of them for the Greek Open University. He is Editor-in-Chief for the Signal 
Processing Book Series, Academic Press and for the E-Reference Signal Processing, Elsevier.
He is the co-author of six papers that have received best paper awards including the 2009 IEEE 
Computational Intelligence Society Transactions on Neural Networks Outstanding paper Award. He 
has served as an IEEE Signal Processing Society Distinguished Lecturer. He was Otto Monstead Guest 
Professor, Technical University of Denmark, 2012, and holder of the Excellence Chair, Department of 
Signal Processing and Communications, University Carlos III, Madrid, Spain, 2011.
He was the General Chairman of EUSIPCO-98, the Technical Program co-Chair for ISCAS-2006 
and ISCAS-2013, and co-Chairman and co-Founder of CIP-2008 and co-Chairman of CIP-2010. He 
has served as President of the European Association for Signal Processing (EURASIP) and as member 
of the Board of Governors for the IEEE CAS Society. He currently serves as member of the Board of 
Governors (Member-at-Large) of the IEEE SP Society.
He has served as a member of the Greek National Council for Research and Technology and he 
was Chairman of the SP advisory committee for the Edinburgh Research Partnership (ERP). He has 
served as Vice Chairman of the Greek Pedagogical Institute and he was for 4 years member of the 
Board of Directors of COSMOTE (the Greek mobile phone operating company). He is Fellow of IET, 
a Corresponding Fellow of the Royal Society of Edinburgh (RSE), a Fellow of EURASIP, and a Fellow 
of IEEE.

xxix
Nicholas D. Sidiropoulos received the Diploma in Electrical Engineering from 
the Aristotelian University of Thessaloniki, Greece, and M.S. and Ph.D. degrees 
in Electrical Engineering from the University of Maryland—College Park, in 
1988, 1990 and 1992, respectively. He has served as Assistant Professor in the 
Department of Electrical Engineering at the University of Virginia (1997–1999); 
Associate Professor in the Department of Electrical and Computer Engineering 
at the University of Minnesota—Minneapolis (2000–2002); Professor in 
the Department of Electronic and Computer Engineering at the Technical 
University of Crete, Chania—Crete, Greece (2002–2011); and Professor in the 
Department of Electrical and Computer Engineering at the University of Minnesota—Minneapolis 
(2011–). His research interests are in signal processing for communications, convex optimization, 
cross-layer resource allocation for wireless networks, and multiway analysis—i.e., linear algebra for 
data arrays indexed by three or more variables. His current research focuses primarily on signal and 
tensor analytics, with applications in cognitive radio, big data, and preference measurement. He 
received the NSF/CAREER award in 1998, and the IEEE Signal Processing Society (SPS) Best Paper 
Award in 2001, 2007, and 2011. He served as IEEE SPS Distinguished Lecturer (2008–2009), and 
as Chair of the IEEE Signal Processing for Communications and Networking Technical Committee 
(2007–2008). He received the 2010 IEEE Signal Processing Society Meritorious Service Award. He 
is a Fellow of IEEE.
Fulvio Gini (Fellow, IEEE) received the Doctor Engineer (cum laude) and the 
Research Doctor degrees in electronic engineering from the University of 
Pisa, Italy, in 1990 and 1995, respectively. In 1993 he joined the Department 
of Ingegneria dell’Informazione of the University of Pisa, where he became 
Associate Professor in 2000 and he is Full Professor since 2006. From July 
1996 through January 1997, he was a visiting researcher at the Department of 
Electrical Engineering, University of Virginia, Charlottesville. He is an Associate 
Editor for the IEEE Transactions on Aerospace and Electronic Systems and for 
the Elsevier Signal Processing journal. He has been AE for the Transactions 
on Signal Processing (2000–2006) and a Member of the EURASIP JASP Editorial Board. He is 
the Editor-in-Chief of the Hindawi International Journal on Navigation and Observation (IJNO).
He has been the Area Editor for the Special issues of the IEEE Signal Processing Magazine. He 
was co-recipient of the 2001 IEEE AES Society’s Barry Carlton Award for Best Paper. He was 
recipient of the 2003 IEE Achievement Award for outstanding contribution in signal process-
ing and of the 2003 IEEE AES Society Nathanson Award to the Young Engineer of the Year. 
He is a Member of the Signal Processing Theory and Methods (SPTM) Technical Committee 
(TC) of the IEEE Signal Processing Society and he has been a Member of the Sensor Array and 
Multichannel (SAM) TC. He is a Member of the Board of Directors (BoD) of the EURASIP 
Section Editors
Section 2
Section 1

xxx
﻿ Section Editors
Society and the Award Chair since 2006 and he is the EURASIP President elected for the years 
2013–2014. He was the Technical co-Chair of the 2006 EURASIP Signal and Image Processing 
Conference (EUSIPCO), Florence, Italy, September 2006, and the Technical co-Chair of the 
2008 Radar Conference, Rome, Italy, May 2008. He was the General co-Chair of the second 
Workshop on Cognitive Information Processing (CIP2010) and the General co-Chair of the 
forthcoming ICASSP2014, to be held in Florence in May 2014. He was the guest co-editor of 
the special section of the Journal of the IEEE SP Society on Special Topics in Signal Processing 
on “Adaptive Waveform Design for Agile Sensing and Communication” (2007), guest editor of 
the special section of the IEEE Signal Processing Magazine on “Knowledge Based Systems for 
Adaptive Radar Detection, Tracking and Classification” (2006), guest co-editor of the two special 
issues of the EURASIP Signal Processing journal on “New trends and findings in antenna array 
processing for radar” (2004) and on “Advances in Sensor Array Processing (in memory of Alex 
Gershman)” (2013). He is co-editor and author of the book ”Knowledge Based Radar Detection, 
Tracking and Classification” (2008) and of the book “Waveform Diversity and Design” (2012). 
His research interests include modeling and statistical analysis of radar clutter data, non-Gauss-
ian signal detection and estimation, parameter estimation and data extraction from multichannel 
interferometric SAR data. He authored or co-authored 5 book chapters, more than 100 journal 
papers and about 120 conference papers.

1
CHAPTER
Introduction to Signal Processing
for Communications
Nicholas D. Sidiropoulos
Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN, USA
2.01.1 Some history
Signal processing and communications have always been closely intertwined, owing in part to their
common foundation on signals and systems, to the many distinguished researchers that “wore double
hats” and had a pivotal role in cross-fertilizing the two disciplines, and to . . . mere necessity, since
•
Analog and digital ﬁlters are critical components of any transmitter or receiver chain.
•
Timing, carrier frequency, and phase offset estimation are bread-and-butter signal processing tasks.
•
System identiﬁcation tools from control theory and signal processing are important for channel
estimation.
Beyond those core issues, there are many well-established aspects of communication theory and algo-
rithms which were co-developed by signal processing researchers, such as adaptive equalization, blind
equalization, adaptive beamforming, and signal intelligence. In the mid 1990s, a number of emerging
developments, including
•
multi-user communications, particularly multi-user detection;
•
multi-channel communications, including multi-antenna systems and fractionally sampled equali-
zation; and
•
digital subscriber line (DSL) communications,
opened up new and exciting problems at the intersection of signal processing and communications,
generating a wave and making a lasting impact to both disciplines. A decade later, wireless networking
aspects were added, as ad hoc and multi-hop wireless communications, cross-layer network design,
optimization, and resource allocation came into the picture. Sensor networks, cognitive radio networks,
distributed detection, estimation, computation, and optimization are prominent trends in recent years.
Nowadays, a signiﬁcant percentage of contributions to the ﬂagship signal processing journals are con-
cerned with communications problems and applications—I quickly estimated 15–20% by perusing
recent issues. Reciprocating, a good percentage of articles in the ﬂagship communications journals is
contributed by signal processing researchers.
Interestingly, whereas new areas and topics continuously emerge and fade away, much of what we do
remains ﬁrmly anchored close to the heart of signal processing. Spectrum sensing, for example, which
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-396500-4.00001-6
© 2014 Elsevier Ltd. All rights reserved.
3

4
CHAPTER 1 Introduction to Signal Processing for Communications
is a key component of cognitive radio, is so near and dear to spectral analysis that we feel right at home
with it.
Signal processing does not have a chartered application, so signal processing researchers often switch
hats and move on to new application areas. But, as a good friend of mine once told me “You can chase
after fashion, or wait for it to come back to what you like.” Well, he started from Ithaca! For the rest of
us: happy travels in signal processing for communications and beyond!
2.01.2 Contents and contributors
When Sergios Theodoridis enlisted me as area editor for this section, I ﬁrst mapped out the key titles
needed, then called upon and enlisted some of the very best researchers in the area, renown not only for
their research but also for their effectiveness in writing tutorials. I was delighted that they accepted my
invitation. This section is largely the result of their diligent efforts, and I’m sure you will appreciate the
breadth, depth, and overall quality of their work. I also owe a big thanks to the many colleagues who were
kind enough to review the various contributions, providing valuable feedback and detailed, constructive
comments. Many thanks are also due to Georgios Giannakis, Athanasios Liavas, Zhi-Quan (Tom)
Luo, Xiaoli Ma, Evaggelia Matskani, Shuichi Ohno, Ioannis Schizas, Brian Sadler, Erchin Serpedin,
Slawomir Stanczak, Paschalis Tsiaﬂakis, Alle-Jan van der Veen, Arie Yeredor, Wei Yu, Pengfei Xia,
Yan Xin, for their advice and feedback on various aspects and versions of the overall section.
2.01.2.1 Synchronization
Synchronization is the ﬁrst task in any communication system, so let me begin my short guided tour
from the contribution of Ghogho, Ciblat, and Swami [1], an impressively comprehensive tutorial on
synchronization and associated performance analysis for a broad variety of communication systems.
The clarity of exposition and right level of detail will make this article an indispensable tool in the hands
of students and practitioners alike—I felt ready to program some of the methods as I was reading their
article.
2.01.2.2 Channel estimation, equalization, precoding, and tracking
Channel estimation and equalization are the next step after (or intertwined with) synchronization.
Channel estimation and equalization are needed to combat intersymbol interference due to multipath
propagation in wireless and wireline systems. Precoding can be used as an alternative or complement to
equalization, provided that channel state information is available at the transmitter. Following channel
acquisition, channel tracking is used to lock on slow channel variations, at low complexity and signaling
overhead. The article by Tugnait [2] is an impressive tour over two decades of research in the area, by one
of the leading experts. It covers a broad spectrum of techniques, from maximum likelihood sequence
estimation, linear, decision-feedback, and on to turbo equalization, training-based, semi-blind, and
blind techniques, doubly-selective channels and basis expansion models, precoding (including the case
of partial channel state information at the transmitter), and judicious simulations.

2.01.2 Contents and Contributors
5
2.01.2.3 Blind signal separation
Much of the initial ﬂurry of signal processing for communications research back in the mid- to late-
1990s was motivated by blind signal separation and equalization problems in wireless communications,
aiming to do without training in situations where the transmitter(s) are not cooperating (e.g., signal
interception), or, in an attempt to boost the data rate. The article by Chevreuil and Loubaton [3] reviews
important theoretical and algorithmic aspects of the blind signal separation and equalization problem
with an eye toward applications in digital communications.
2.01.2.4 OFDM and multicarrier signal processing
The basic idea behind multicarrier communications was known many decades before Orthogonal Fre-
quency Division Multiplexing (OFDM) and various other multicarrier communication modalities made
their debut in practical systems. The key is that complex exponentials are eigenfunctions of linear
time invariant systems, hence signaling using complex exponentials has the potential to circumvent
inter-symbol interference. What made it all practical though was discrete-time baseband-equivalent
processing using digital signal processing chipsets, and the use of circularity to restore exact orthogo-
nality of the subcarriers. Banelli and Rugini [4] have spared no effort in bringing multicarrier “down
to baseband,” with insightful illustrations providing valuable intuition, in a broad and technically deep
tutorial that is sure to be appreciated by graduate students and practicing engineers alike.
2.01.2.5 Signal processing for vectored multichannel VDSL
Multicarrier modulation is now used across the board in all types of wireless systems, but is most
prevalent in DSL. DSL systems have gone long ways in recent years, reaching previously unthinkable
rates over legacy twisted pairs—owing in part to the push to get the back-end modems closer to the
customer premises, and in part due to the use of multiple-input, multiple-output (MIMO) technologies—
simultaneously signaling over and/or listening to multiple twisted pairs. The article by Bergel and
Leshem [5] offers an insightful tutorial introduction to state-of-art MIMO DSL technology and the
requisite signal processing behind it. Coming from researchers who have actually designed and built
VDSL modems, the exposition strikes the right balance between theory and practice.
2.01.2.6 Distributed detection and estimation in wireless sensor networks
Wirelesssensornetworks(WSNs)havediverseapplicationsinenvironmental,production,criticalinfras-
tructure, and radio spectrum monitoring, and new potential application domains are rapidly emerging,
e.g., in monitoring renewable energy sources and the smart grid. The article by Barbarossa et al. [6] offers
an intuitive, well-rounded, and technically rewarding tutorial overview of distributed and decentralized
detection and estimation over WSNs, taking into account communication and energy considerations.
The celebrated network consensus problem is revisited under realistic channel models, and basic and
advanced distributed estimation and detection methodologies are explained with clear examples. The
problem of matching the network topology to the given inference task is also considered.

6
CHAPTER 1 Introduction to Signal Processing for Communications
2.01.2.7 Signal processing and optimal resource allocation for the
interference channel
The article by Hong and Luo [7] is a comprehensive tour of recent developments in resource allocation
and signal processing for the interference channel, coming from a leading research group in the area.
As wireless network design and operation continuously pushes the technological boundaries, network
optimization becomes increasingly important. As shown by Luo et al. however, most network optimiza-
tion problems are very hard to solve. This represents a grand challenge and fertile ground for signal
processing and communications research. Hong and Luo show how many of these problems can be
(approximately) tackled using computationally efﬁcient algorithms. The contents of this article have
far broader use in many other signal processing application areas.
2.01.2.8 Advances in spectrum sensing and cross-layer design for cognitive
radio networks
Last but not least is an article addressing what is currently perhaps the most actively researched topic
in signal processing for communications: dynamic spectrum sensing and access using a network of
collaborating sensors. The article by Giannakis et al. [8] overviews the concept of radio spectrum
cartography, which has already drawn considerable attention. The interplay between spectrum sensing
and spectrum access is further considered, leading to a simple and elegant comprehensive solution for
spatio-temporal collaborative cognitive sensing and access. This article is indicative of the present focus
and state of art of signal processing for communications research, by one of the leading groups in the
area.
2.01.3 Outlook
No project of this type is ever complete, in part because one can always augment the fundamentals, and
in part because new topics emerge and should be covered in due time. On the fundamentals front, a
tutorial dedicated to multiple-input, multiple-output communications would be useful, albeit the mate-
rial is partially covered in other contributions. Likewise, tutorials on channel modeling, cooperative
communications, and a focused account of modern MIMO detection would be very welcome. Inter-
ference alignment has recently attracted much attention, and it brings together information theory,
communications, signal processing, and optimization tools—a fertile ground for new innovations.
On the emerging topics front, research on signal processing and communication aspects of social
networks is the new thing, together with signal processing tools for big data analytics. Which simply
means that the E-reference in Signal Processing is looking forward to future editions!
References
[1] M. Ghogho, P. Ciblat, Ananthram Swami, Synchronization, Elsevier Major Reference Works: E-reference
Signal Processing, vol. 2.
[2] J. Tugnait, Channel Estimation, Equalization, Precoding, and Tracking, Elsevier Major Reference Works:
E-reference, Signal Processing, vol. 2.

References
7
[3] A. Chevreuil, P. Loubaton, Blind Signal Separation for Digital Communication Data, Elsevier Major Reference
Works: E-reference, Signal Processing, vol. 2.
[4] P. Banelli, L. Rugini, OFDM and Multicarrier Signal Processing, Elsevier Major Reference Works: E-reference,
Signal Processing, vol. 2.
[5] I. Bergel, A. Leshem, Signal Processing for Vectored Multichannel VDSL, Elsevier Major Reference Works:
E-reference, Signal Processing, vol. 2.
[6] S. Barbarossa, S. Sardellitti, P. Di Lorenzo, Distributed Detection and Estimation in Wireless Sensor Networks,
Elsevier Major Reference Works: E-reference, Signal Processing, vol. 2.
[7] M. Hong, Z.-Q. Luo, Signal Processing and Optimal Resource Allocation for the Interference Channel, Elsevier
Major Reference Works: E-reference, Signal Processing, vol. 2.
[8] Seung-Jun Kim, Emiliano DallAnese, Juan Andrés Bazerque, Ketan Rajawat, Georgios B. Giannakis, Advances
in Spectrum Sensing and Cross-Layer Design for Cognitive Radio Networks, Elsevier Major Reference Works:
E-reference, Signal Processing, vol. 2.

2
CHAPTER
Synchronization
Mounir Ghogho*,†, Philippe Ciblat‡, and Ananthram Swami§
*School of Electronic and Electrical Engineering, University of Leeds, UK
†International University of Rabat, Morocco
‡Telecom Paris-Tech, Paris, France
§US Army Research Lab, MD, USA
2.02.1 Introduction
Synchronization is fundamental to the proper operation of communication networks. Synchronization
may be performed at various levels: from very coarse to very ﬁne-grained; the required accuracy depends
upon the application and the network environment, and hence can change dynamically. For example,
coarse time synchronization sufﬁces for many detection and tracking applications, but ﬁner synchro-
nization is required for high data-rate communication, distributed array processing, analog to digital
conversion (ADC), slot synchronization, and cooperative communications.
According to Wikipedia, synchronization is timekeeping which requires the coordination of events
to operate a system in unison. The familiar conductor of an orchestra serves to keep the orchestra in
time. Systems operating with all their parts in synchrony are said to be synchronous or in sync. Some
systems may be only approximately synchronized, or plesiochronous. For some applications relative
offsets between events need to be determined, for others only the order of the events is important.
The aim of synchronization may be different in different applications, as illustrated next.
•
Reliable coherent digital communication systems require accurate synchronization, particularly
when the data rate or bandwidth is large. Synchronization consists of a number of tasks. First, car-
rier synchronization aims at generating a reference carrier with a phase that closely matches that of
the data signal, thus compensating for the effects of oscillators mismatch and Doppler effects. This
generated carrier is used at the receiver to perform coherent demodulation of the received signal to
generate the baseband signal. The second task, referred to as symbol time synchronization, aims at
synchronizing the receiver clock with the baseband data-symbol signal. If these tasks are carried
out by multiplexing known symbols (also called training symbols), the synchronization method
is referred to as data-aided; otherwise it is referred to as non-data-aided or blind. Non-data-aided
synchronization techniques have been proposed in order to save bandwidth. However, there is a
tradeoff between accuracy, implementation complexity and power consumption. Practical systems
typically use some form of training (or pilot) symbols which may be prepended, appended, or embed-
ded in the data packet. Training typically leads to low complexity receivers and good performance
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-396500-4.00002-8
© 2014 Elsevier Ltd. All rights reserved.
9

10
CHAPTER 2 Synchronization
with moderate sacriﬁce in rate. In addition to the above tasks, for most modern communication
systems, frame and packet synchronization are also required to determine the start of the frame/
packet.
•
In energy constrained WSNs and MANETs, accurate clock synchronization facilitates energy-
efﬁcient Medium Access Control (MAC). Node geo-location also typically requires time synchro-
nization.
•
Many networked signal processing tasks depend critically upon a common time reference; examples
include event detection and target tracking, localization, (multi-modal) sensor fusion, distributed
array processing, and synchronization of distributed information caches.
•
In robotics, synchronization and delay management are crucial components of networked control and
actuation; poor synchronization can lead to control instabilities. Other applications in collaborative
robotics, such as mapping or geo-location, also require a common time reference.
•
Synchronization is crucial for distributed communications such as cooperative communications and
relaying, and in network management (probing and monitoring).
Network synchronization deals with timekeeping ensuring coordination of events to operate a system
in unison when universal clock and so time reference is not available. This type of synchronization is
a well-studied topic with an extensive history. Typically, these works assumed high quality devices,
availability of ﬁne control of the network, extensive connectivity with little or no mutual interference,
as well as known (or repeatable and measurable) propagation and processing delays [1]. These works
usually lead to the development of synchronization protocols which describe the different operations
that the network nodes have to do in order to be jointly synchronized. This type of synchronization is of
great importance in wireless sensors networks (WSN) and mobile ad-hoc networks (MANET) where
a coordinating entity with a time reference may not be available. Surveys of WSN synchronization
protocols may be found in [1–6].
Notice that network synchronization is a very old problem. Indeed, a fascinating book by Peter Gali-
son [7] describes the pioneering work of Einstein and Poincaré on ﬁnding common time references (circa
1909). Einstein, then a young obscure German physicist, was experimenting with measuring time using
telegraph networks and with the coordination of clocks at train stations. The renowned mathematician
Poincaré, president of the French Bureau of Longitude, was mapping time coordinates across conti-
nents. Sundials and watches had been in use for centuries and they were relatively inaccurate. However,
travel and communications were slow (until at least the end of the nineteenth century), and those local
time differences were of little importance. Synchronization is often encountered in nature. Strogatz [8]
provides an elegant description of synchronization among ﬁreﬂies in Malaysia, and circadian rhythms.
Studies of the robustness of circadian clocks (e.g., via clock neurons in the superchiasmatic nucleus)
indicate that individual neurons are sloppy timekeepers but synchronized neurons are precise clocks.
Bio-inspired approaches have led to the development of algorithms for synchronizing communication
networks (e.g., transmit beamforming, GPS) that exploit combinations of local and global signaling
[9]. The process of synchronization, whether it be in nature or in engineered systems, can also be re-
interpreted via more recent tools developed for distributed control [10], and opinion dynamics [11],
since the goal is broadly to coordinate actions in order to reach a common objective.
The ensuing sections in this chapter will study the synchronization problem. Our main focus is on time
and carrier synchronization when a reference is available (typically via a base station). In such a context,

2.02.2 Synchronization in Flat Fading Channel
11
we will consider both single and multi-carrier systems, both single and multi-user scenarios, and both
ﬂat-fading and non-ﬂat-fading (frequency-selective) channels. In the last section, a brief state-of-the-art
on network synchronization is provided.
The chapter is written at the beginner graduate level. The reader is assumed to have a working
knowledge of digital communications (e.g., [12,13]) and estimation theory (e.g., [14]).
2.02.2 Synchronization in ﬂat fading channel
In this section, we assume that the multipath delay spread in the propagation channel does not lead
to Inter-Symbol Interference (ISI). In practice, this holds if the symbol period is sufﬁciently larger
than the delay spread of the channel. The frequency response of the channel is thus considered ﬂat.
From a practical point of view, such an assumption on the channel is satisﬁed in satellite communi-
cations (e.g., DVB-S), anisotropic transmissions (e.g., between two DVB-T transmitters), optical ﬁber
communications (e.g., with pre-compensation of the static chromatic dispersion) [15,16].
As the channel does not induce ISI, the OFDM modulation scheme does not provide advantages over
single-carrier transmissions. Therefore, we will only focus on the single-carrier case in this Section.
The transmitted signal (in baseband) [12,13] is given by
xa(t) =
N−1

n=0
snha(t −kTs),
where
•
{s0, . . . , sN−1} are the transmitted symbols belonging to ASK, PSK or QAM constellations or any
linearly precoded scheme, with N being the sequence length used for estimating the synchronization
(sync) parameters;
•
Ts is the symbol period which is assumed to be known throughout this chapter. For more information
about the blind estimation of Ts, the reader is referred to [17];
•
ha(t) is the shaping ﬁlter that classically is a square-root Nyquist ﬁlter. For example, in 3G systems,
it is the square-root raised cosine ﬁlter with roll-off 0.35. The main property that we need further is
that the ﬁlter is band-limited with bandwidth between 1/Ts and 2/Ts.
For the ﬂat fading channel, the received signal (in baseband) is described by
ya(t) = xa(t −τ0)e2π( f0t+φ0) + ba(t),
where
•
the synchronization parameters are the symbol timing τ0, the (constant) phase φ0, and the carrier
frequency offset (CFO) f0 [18–20].
•
ba(t) is the complex-valued circularly-symmetric white zero-mean Gaussian process with variance
N0 per real dimension (for more details about the assumption on the noise, see [13]). The concept
of circularity is crucial and will be deﬁned in detail later.

12
CHAPTER 2 Synchronization
The received signal can be re-written as follows:
ya(t) =
N−1

n=0
snha(t −kTs −τ0)

e2iπ( f0t+φ0) + ba(t).
We do not assume an a-priori distribution for the timing and phase parameters. Indeed, the timing
can be assumed uniformly distributed across the interval [0,Ts) since the receiver and the transmitter are
not synchronized in time. Due to the channel propagation, the phase can take any value over [0, 2π).
In contrast, the CFO, which is due either to a mismatch between local oscillators or Doppler effects,
lies in a pre-deﬁned interval. To illustrate this, let us consider the worst case when only a cheap local
oscillator is available. Its precision is about 40 ppm which leads to a CFO of 40 kHz at carrier frequency
1 GHz. Assuming a rather high vehicle speed of 360 km/h, the Doppler induced offset is upper-bounded
by 333 Hz. Consequently, the CFO is much smaller than the typical signal bandwidth which is often
equal to several MHz. Note that the main source of CFO is the local oscillator mismatch and not the
Doppler effect. Indeed, the Doppler effect has a greater inﬂuence on the coherence time of the channel
and thus on the statistical model of the channel (for instance, according to the Doppler value, the channel
can be viewed as a fast ﬂat fading channel or a slow ﬂat fading channel). The nature of the ﬂat fading
channel (fast or slow) is crucial for designing properly the communication scheme (feedback link,
diversity management, etc.) but not the synchronization step since, except in very infrequent cases, the
synchronization step duration is always much smaller than the channel coherence time.
Before going further, we recap the optimal symbol detector when synchronization is perfect
(τ0 = 0, φ0 = 0, and f0 = 0) [12,13,18,19]. If the information symbols are equally likely, the maxi-
mum likelihood detector is the optimal one in the sense of error probability minimization. Therefore,
we have that
{ˆsn}N−1
n=0 = arg
max
{sn}n=0,...,N−1
p(y(t)|{sn}n=0,...,N−1).
Due to the Gaussianity of the noise process, we have that [21]
p(y(t)|{sn}n=0,...,N−1) ∝e
−

R
y(t)−N−1
n=0 snh(t−nTs)

2
dt/2N0.
Thus
ˆsn = arg
min
{sn}n=0,...,N−1

R
y(t) −
N−1

n=0
snh(t −nTs)

2
dt.
We ﬁnally obtain that
ˆsn = arg
min
{sn}n=0,...,N−1
JN(s),
where
JN(s) =

R
|y(t)|2 dt +
N−1

n,n′=0
sns∗
n′ ˜h(n −n′) −2
N−1

n=0
ℜ{s∗
nz(n)},

2.02.2 Synchronization in Flat Fading Channel
13
where
•
za(t) = ha(−t)∗⋆ya(t) is the continuous-time output of the so-called matched ﬁlter;
•
z(n) = za(nTs) is the sampled version (at symbol rate) of the matched ﬁlter output;
•
˜ha(t) = ha(−t)∗⋆ha(t) is the continuous-time equivalent ﬁlter; and
•
˜h(n) = ˜ha(nTs) is the discrete equivalent ﬁlter.
We remark that the optimality criterion depends on the received signal only through the discrete-time
matched ﬁlter output. The introduction of the signal z(n) can be also justiﬁed by following an alternative
way: the received signal (under the perfect synchronization assumption) can be re-written as follows:
ya(t) =

n
snn(t) + ba(t),
where n(t) = ha(t −nTs). As the useful information in ya(t) are the symbols sn, the received
signal can be split into two parts: the useful one associated with the signal subspace spanned by the
functions n(t), and the other one generated by the space orthogonal to the signal subspace, the so-
called “noise subspace.” Let ˜z(n) = ⟨ya(t)|n(t)⟩be the projected signal onto the signal subspace,
where ⟨•|•⟩denotes the canonical inner product. One can easily check that ˜z(n) = z(n). As the noise
is Gaussian, its contribution to the signal subspace is independent of those to the orthogonal noise
subspace. Therefore, without loss of optimality, one needs to only work with ˜z(n) = z(n) and can drop
the projection onto the noise subspace.
Moreover, one can easily see that
z(n) =

k
˜h(k)sn−k + ˜b(n),
(2.1)
where ˜b(n) = ha(−t)∗⋆ba(t)|t=nTs is circularly-symmetric Gaussian noise with zero mean and power
spectral density S˜b(e2iπ f ) = 2N0 ˜h(e2iπ f ) = 2N0

k ˜h(k)e−2iπk f . The maximum likelihood (ML)
criterion depends on the shaping and propagation ﬁlters only through the so-called discrete-time equiva-
lent ﬁlter ˜h. Therefore the system performance will only be driven by the ﬁlter ˜h and the signal-to-noise
ratio (SNR).
Now the second step of the optimal detector is to ﬁnd the minimum of JN(s). When the shaping ﬁlter
ha(t) is a square-root Nyquist ﬁlter, it is well known that ˜ha(t) is the Nyquist ﬁlter and ˜h(n) = δ0,n
where δ0,n is the Kronecker index. Thus, the function JN(s) can be signiﬁcantly simpliﬁed to
JN(s) =
N−1

n=0
|z(n) −sn|2.
Consequently, the optimal detector is a symbol-by-symbol detector
ˆsn = arg min
sn |z(n) −sn|2
which is the so-called threshold detector. When the Nyquist condition is not satisﬁed (especially when
the channel is not ﬂat), the minimization of JN(s) is much harder and can be done via the famous

14
CHAPTER 2 Synchronization
za(t)
ha(−t)∗
ˆs
z(n)
mins JN (s)
ya(t)
t = nTs
FIGURE 2.1
Optimal receiver structure (with perfect synchronization).
×
×
za(t)
ha(−t)∗
ˆs
z(n)
mins JN (s)
ya(t)
e−2iπf0t
nTs+τ0
e−2iπφ0
FIGURE 2.2
Optimal receiver structure (with known synchronization parameters).
Viterbi algorithm [22,23]. When the Viterbi algorithm is too complex (channel too long and/or high
modulation size), suboptimal detectors, such as the zero-forcing (ZF), minimum mean-square error
(MMSE), decision-feedback equalizer (DFE), can be used. For details, mathematical explanations and
derivations, we refer the reader to [12,13]. The optimal receiver is summarized in Figure 2.1.
When the synchronization parameters are non-zero but known, the continuous-time received signal
is given by
ya(t) =

n
snn(t −nTs) + ba(t)
with n(t) = ha(t −nTs −τ0)e2iπ( f0t+φ0). Once again, the optimal operation at the receiver side is to
project ya(t) onto the function n(t). Therefore, the optimal receiver is now given in Figure 2.2.
Notice that the phase compensator can be located anywhere in Figure 2.2 since it commutes with the
other operators. The CFO compensator can be located anywhere if and only if the CFO is small enough
compared to the ﬁlter bandwidth1. This last assumption is usually satisﬁed as mentioned earlier.
Let us now move on to some performance evaluation when the synchronization step is not carried
out. In order to understand the inﬂuence of each parameter, we will consider the sync parameters one
by one, assuming the remaining ones known. Let us ﬁrst focus on the timing. In the ﬂat fading context,
the shaping ﬁlter is usually a square-root Nyquist and more precisely a square-root raised cosine ﬁlter
with roll-off ρ. Under the perfect synchronization assumption, z(n) is not distorted by Inter-Symbol
Interference (ISI). But if the timing is not perfectly known, z(n) will be affected by ISI. In Figure 2.3
(left), we display the eye diagram of za(t) when τ0 = 0 and ρ = 0.5 with BPSK modulation. We remark
that if the sampling operation is not done at a multiple of Ts, the eye will be less open and performance
will be degraded. In Figure 2.3 (right), the bit-error rate (BER) versus SNR Eb/N0 curves are shown
1Let h1(t) and h2(t) be two ﬁlters of bandwidth 1/Ts. Let us assume also that f0Ts ≪1. We have that h1(t) ⋆(h2(t)e2iπ f0t) =
e2iπ f0t
H2(ν)H1(ν + f0)e2iπνtdν ≈e2iπ f0t(h1(t) ⋆h2(t)) where Hk is the Fourier transform of hk. The approximation
holds since f0 is small compared to 1/Ts. We thus conclude that the CFO operation can be permuted with the ﬁltering operator.

2.02.2 Synchronization in Flat Fading Channel
15
−0 5
−0.4
−0 3
−0.2
−0.1
0
0.1
0.2
0 3
0.4
0 5
−2
−1 5
−1
−0 5
0
0 5
1
1 5
2
Eye diagram (noiseless, roll−off=0.5)
*Ts
0
1
2
3
4
5
6
7
8
9
10
10
6
10
5
10
4
10
3
10
2
10
1
10
0
BER with timing error
Eb/N0
BER
τ0=0
τ0=0.05Ts
τ0=0.1Ts
τ0=0.15Ts
τ0=0.2Ts
τ0=0.25Ts
τ0=0.3Ts
τ0=0.35Ts
τ0=0.4Ts
FIGURE 2.3
Eye diagram (left) in the noiseless case and BER (right) versus Eb/N0 in the presence of timing
mis-synchronization.
for different values of τ0. Notice that performance degrades signiﬁcantly when the timing error exceeds
10% of the symbol period.
We next consider perfect timing synchronization, but without any phase synchronization. The shaping
ﬁlter is once again a square-root raised cosine ﬁlter with roll-off ρ = 0.5. In Figure 2.4 (left), we plot
the samples z(n) when BSPK is employed and the phase shift is equal to 0.1 at Eb/N0 = 10 dB. The
constellation is thus rotated, which induces an increase of the BER. In Figure 2.4 (right), we display
the BER versus Eb/N0 for different values of the phase shift. Performance degradation is signiﬁcant.
We next examine the inﬂuence of the CFO on performance. The same simulation set-up is used as
previously. In Figure 2.5 (left), we plot the samples z(n) when the CFO is equal to 0.01 at Eb/N0 =
30 dB. We remark that the BPSK constellation is rotated with different rotation angles f0n at each time
index n which leads to a circle if the frame is long enough. Due to the noise, we observe a ring. In
Figure 2.5 (right), we compute the BER versus Eb/N0 for different values of CFO. The frame length
in this example is 1000 data symbols.
For each synchronization parameter, a loss in performance is observed, which may lead to commu-
nication failure. Therefore, we clearly need to add a synchronization step at the receiver side in order
to keep the performance as high as possible.
As we just saw, synchronization parameters have a great inﬂuence on system performance; therefore,
estimating these parameters is crucial. The following remarks are in order:
•
Why should we estimate the timing parameter τ0? Knowledge of τ0 is crucial for choosing the
correct sampling time when the continuous-time signal is converted to the (symbol rate) discrete-
time signal (see Figure 2.3). The need for sampling at the symbol rate at the exact timing has
its origin in the non-satisfaction of the Nyquist-Shannon sampling theorem. Therefore, by over-
sampling at least at the baud rate (but in practice twice the symbol rate), the discrete-time signal

16
CHAPTER 2 Synchronization
−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
−1.5
−1
−0.5
0
0.5
1
1.5
real part
imaginary part
BPSK constellation with phase shift 0.1 at E b/N0=10dB
0
1
2
3
4
5
6
7
8
9
10
10
6
10
5
10
4
10
3
10
2
10
1
10
0
BER with phase error
Eb/N0
BER
φ0=0
φ0=0.05
φ0=0.1
φ0=0.15
φ0=0.2
φ0=0.25
FIGURE 2.4
Samples z(n) before decision (left) when φ0 = 0.1 and Eb/N0 = 10 dB and BER (right) versus Eb/N0 in
the presence of phase mis-synchronization.
−1 5
−1
−0 5
0
0 5
1
1 5
−1 5
−1
−0 5
0
0 5
1
1 5
real part
imaginary part
BPSK constellation with frequency shift 0.01 at Eb/ N0=30dB
0
1
2
3
4
5
6
7
8
9
10
10
6
10
5
10
4
10
3
10
2
10
1
10
0
BER with frequency error
Eb/N0
BER
f0=0
f0=1e−4
f0=1 5e−4
f0=2e−4
f0=5e−4
f0=1e−3
f0=1e−2
FIGURE 2.5
Samples z(n) before decision (left) when f0 = 0.01 and Eb/N0 = 30 dB and BER (right) versus Eb/N0 in
the presence of frequency mis-synchronization.
˜y(n) = ya(nTs/2) contains all the information in ya(t). Then the “symbol timing” matching can be
done via digital processing, namely, interpolation. More interestingly, by considering the bivariate
process y(n) = [ya(nTs), ya(nTs + Ts/2)]T which corresponds exactly to ˜y(n), a fractionally-
spaced (FS) equalizer can be used to retrieve the information symbol. To implement this, one
needs to know the ﬁlters h1(n) = ha(nTs) and h2(n) = ha(nTs + Ts/2). Thus, the symbol timing

2.02.2 Synchronization in Flat Fading Channel
17
estimation issue has been replaced by a pair of ﬁlter estimation. Notice that at least one ﬁlter (usually
h2(n) does not satisfy the Nyquist criterion) is non-ﬂat (i.e., frequency-selective) in its discrete-time
version. Another way to cope with timing offset is to incorporate the timing into the channel by
rewriting the received signal as:
ya(t) =
N−1

n=0
sn ˇha(t −kTs)

e2iπ( f0t+φ0) + ba(t),
where
ˇha(t) = ha(t −τ0),
is the new equivalent channel. Now the channel is unknown since τ0 is unknown. Therefore, once
again the timing estimation issue boils down to a channel estimation issue.
•
As the phase rotation is a linear time-invariant operation, it can be viewed as a ﬁltering operator and
thus incorporated into the ﬁlter. Therefore we have that
ya(t) =
N−1

n=0
sn ˚ha(t −kTs)

e2iπ f0t + ba(t),
where
˚ha(t) = ha(t −τ0)e2iπφ0
and the phase estimation issue can be avoided.
•
The CFO cannot be viewed as the modiﬁcation of a linear ﬁlter since the CFO is not a time-invariant
transformation. Therefore, the CFO estimation issue cannot be avoided.
In the case of a ﬂat fading channel, if channel estimation is used to synchronize in time and phase (in
order to avoid the “real” synchronization steps), we do not use all of our knowledge about the signal,
and in particular its Nyquist property. Nevertheless, if the synchronization step has to be avoided, the
estimation issue deals with the joint frequency and (non-ﬂat) channel estimation issue. This problem
can be treated similarly to the frequency estimation issue in the ﬂat channel context [24,25] and so will
be omitted here. In the non-data-aided mode, the CFO can be estimated regardless of the channel, as
shown in Section 2.02.2.2.2, and the channel can also be estimated by following the approaches given
in the “Channel Estimation” E-reference.
The communication protocol permits the transmitter to explicitly adjust its signaling so as to facilitate
receiver side synchronization. Therefore, there are two main classes of estimation problems:
•
Data-Aided (DA)2: the receiver knows a sequence of transmitted symbols sn. These symbols belong
to the so-called “training sequence.” Obviously, this leads to a loss in spectral efﬁciency since
during the transmission of the training symbols, no information symbols are sent. Nevertheless this
approach (which is very popular in civilian applications such as GSM, 3G, DVB-S) has several
advantages since it enables us to dramatically simplify the design and the implementation of the
2Also called training approach, supervised mode.

18
CHAPTER 2 Synchronization
synchronization parameter estimators as will be seen later. Moreover, good performance can usually
be attained with only a few (training) symbols, and thus the cost in spectral efﬁciency remains quite
low and acceptable.
•
Non-Data-aided (NDA)3: the transmitter does not send any training sequences per se; thus the
receiver does not have deterministic knowledge about a symbol sub-sequence. However, the receiver
will have some structural or statistical information about the symbols such as the nature of the con-
stellation, the correlation between the symbols, etc. Such a scenario obviously occurs in passive
listening in security applications. In civilian applications, the NDA approach is sometimes useful
for tracking parameter ﬂuctuations or in broadcasting applications (e.g., TV). Indeed, the TV appli-
cation differs completely from a peer-to-peer application (such as GSM between the mobile and
the Base Station) since the TV receiver can be switched on at any moment and will not warn the
broadcast transmitter that it is switched on (for otherwise the broadcast transmitter would always
be “interrupted,” since there is no dedicated channel for learning the channel and synchronization
parameters). So the broadcast transmitter will not transmit a training sequence when a TV receiver
goes live in the network. To speed up the process, the TV receiver has to synchronize itself in a blind
manner.
Some remarks before going further:
1. The main property used in this section compared to the non-ﬂat fading channel case is that the
channel here is assumed to be known. The fact that the ﬁlter is also a square-root Nyquist is not
required but will greatly simplify some derivations and thus the algorithms.
2. The estimation procedure that we will develop can be used and adapted (sometimes) to the non-ﬂat
fading channel case.
3. The trade-off between the estimation quality (provided by training) and the remaining time for
transmitting data can be studied within the framework of information theory (see [26] for more
details).
2.02.2.1 DA case
Let ˆθN be an unbiased estimator of the sought parameter θ relying on N observation samples. Based
on [21,27], we know that the Mean Square Error (MSE), deﬁned as E[∥ˆθ −θ∥2] of any unbiased
estimator of θ is lower-bounded by the so-called Cramer-Rao bound (CRB) which will be described
mathematically in this chapter. An estimator whose MSE is equal to the CRB is called efﬁcient. Efﬁcient
estimators do not exist for many estimation problems. Therefore, the notion of asymptotic efﬁciency
has been introduced. This means that the ratio between the MSE and the CRB tends to 1 as the number
of samples N goes to inﬁnity. Under mild conditions (see e.g., [21,27]), the Maximum-Likelihood
estimator is asymptotically efﬁcient and normally distributed.
In view of the asymptotic efﬁciency and normality, it is natural to consider the maximum-likelihood
estimator ﬁrst. If the ML estimator can be implemented, one often considers the problem to be solved.
In contrast, if the ML estimator cannot be implemented (because of its complexity or sometimes even
intractability), the estimation issue is open and other estimators have to be found. We hasten to add that
3Also called blind, unsupervised.

2.02.2 Synchronization in Flat Fading Channel
19
if an efﬁcient estimator does not exist, then it may be possible to ﬁnd better estimators than the ML.
Second, the CRB may not be tight when the number of samples (or SNR) is low, and tighter bounds
may (such as the Bhattacharya and Ziv-Zakai bounds) may need to be considered. We refer the reader
to [27] for details.
So let us start with the introduction of the ML estimator for the joint synchronization parameters.
The likelihood function can be written as follows
p(y(t)|τ, φ, f ) ∝e
−

R
y(t)−N−1
n=0 snha(t−nTs−τ)e2iπ( f t+φ)
2
dt/2N0,
where the training sequence, {sn}, is known. The ML estimator is given by
[ˆτN, ˆφN, ˆfN] = arg min
τ,φ, f

R
y(t) −
N−1

n=0
snha(t −nTs −τ)e2iπ( f t+φ)

2
dt.
Setting the derivative to zero, and assuming that the CFO is small compared to the signal bandwidth,
we obtain the following set of equations:
⎧
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎪⎪⎪⎩
ℜ
N−1

n=0
s∗
ne−2iπφe−2iπ f Tsnz′
τ(n)

= 0,
ℑ
N−1

n=0
s∗
ne−2iπφe−2iπ f Tsnzτ(n)

= 0,
ℑ
N−1

n=0
s∗
ne−2iπφne−2iπ f Tsnzτ(n)

= 0,
(2.2)
where
zτ(n) =

R
ya(t)ha(t −nTs −τ)∗dt = ha(−t)∗⋆ya(t)|t=nTs+τ
z′
τ(n) =

R
ya(t)h′
a(t −nTs −τ)∗dt = h′
a(−t)∗⋆ya(t)|t=nTs+τ
with h′
a(t) is the derivative of ha(t).
A typical approach is variable elimination: we try to express a parameter in terms of the others, and
eliminate it by using the previously-found expression. Here, this algebraic manipulation can be applied
to the phase (as a function of the timing and the CFO), thanks to Eq. (2.2). But the timing and the CFO
cannot then be written as explicit functions due to the non-linearity of these equations. Therefore, the
joint (timing, phase, CFO) problem is intractable.
We remark that joint frequency and phase estimators can be developed when the timing is known.
Indeed, as we will see, if the timing is known (and thus assumed to be zero without loss of generality),
then the second and third equations can lead to practical estimators with reasonable computational
complexity. Therefore, we split our problem into two different problems that will be treated separately:
(i) the timing sub-task and (ii) the phase and CFO estimation sub-tasks.
The ordering of the two problems has a great inﬂuence on the nature of estimators that will be used,
as we see next:

20
CHAPTER 2 Synchronization
•
First scheme: Timing is estimated ﬁrst and then the phase and CFO are estimated, assuming that the
timing estimate is perfect. As the DA timing cannot be derived in closed-form when the phase and
CFO are unknown, we need to develop a NDA timing estimator that is insensitive to the actual phase
and CFO values. The second part of this scheme deals with phase and CFO estimations issues. As the
timing is now known, DA estimators can be developed. If training is not available, NDA estimators
can also be considered.
•
Second scheme: the phase and the CFO are estimated ﬁrst; timing is then estimated, assuming that
the phase and CFO estimates are perfect, and thus perfectly corrected. Once again, the phase and
CFO estimators here have to be NDA and insensitive to timing error. As the timing can be wrong, the
sampled ﬁlter can generate ISI. Therefore, we need to design joint phase and CFO NDA estimators
that can work even when the (non-ﬂat) fading channel is unknown. Assuming that phase and CFO
are perfectly compensated, the timing estimator can be blind or aided by a training sequence.
(if training available)
DA Phase and CFO
estimation
(if training unavailable)
estimation
NDA Phase and CFO
ya(t)
(insensitive to phase and CFO)
NDA Timing
estimation
Flat channel
(if training available)
estimation
(if training unavailable)
estimation
ya(t)
estimation
DA Timing
NDA Timing
NDA Phase and CFO
(insensitive to timing )
Flat channel
Non ﬂat channel
FIGURE 2.6
Summary of the ﬁrst scheme (top) and the second scheme (bottom).

2.02.2 Synchronization in Flat Fading Channel
21
The two schemes are summarized in Figure 2.6.
Consequently, we need to solve the following issues (even if training sequences are assumed
available!):
•
Problem 1: DA Phase and CFO estimation (when timing is known and so can be considered to be
zero, without loss of generality (wlog)).
•
Problem 1′: DA Timing estimation (when Phase and CFO are known and so can be assumed to be
zero wlog).
•
Problem 2: NDA Phase and CFO estimation (insensitive to unknown timing and hence a non-ﬂat
channel).
•
Problem 2′: NDA Timing estimation (insensitive to unknown phase and CFO).
Notice that the ﬁrst scheme (associated with Problems 1 and 2′) is used frequently and advocated
in a lot of practical systems. Hereafter, we ﬁrst focus on Problem 1 and Problem 1′ relying on training
sequences.
2.02.2.1.1
DA timing estimation
In this subsection, we focus on the following estimation problem:
ya(t) =
N−1

n=0
snha(t −nTs −τ0) + ba(t).
After simple algebraic manipulations (similar to those associated with the maximum-likelihood detec-
tor), the ML timing estimator can be expressed as:
ˆτN = arg max
τ
N−1

n=0
ℜ{s∗
nzτ(n)}



JN (τ)
,
(2.3)
where we recall that zτ(n) is the output of the matched ﬁlter sampled at nTs + τ.
The cost function JN(·) of (2.3) is plotted in Figure 2.7 for Eb/N0 = 5 dB (left) and Eb/N0 = 10 dB
(right) with N = 100. The shaping ﬁlter is a square-root raised cosine with roll-off ρ = 0.5. The value
of the sought τ0 is 0.1Ts and the x-axis has been normalized by Ts.
Observe that the cost function is concave around the true point. Therefore, one can proceed to ﬁnd
the maximum of JN(·) in two steps
•
A coarse search through a 1-D grid which provides a ﬁrst estimate ˆτ (0)
N
of τ0.
•
Once the coarse search has roughly localized the maximum, one can use a gradient-descent algorithm
on the function JN(·) initialized by ˆτ (0)
N , as follows
ˆτ (m)
N
= ˆτ (m−1)
N
+ μJ ′
N

ˆτ (m−1)
N

= ˆτ (m−1)
N
+ μ
N−1

n=0
ℜ

s∗
n
∂zτ(n)
∂τ

ˆτ (m−1)
N

,
(2.4)

22
CHAPTER 2 Synchronization
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
0.5
0
20
40
60
80
100
Cost function for timing (with τ0= 0.1Ts, N=100, and Eb/N0=5dB)
Cost function for timing (with τ0= 0.1Ts, N=100, and Eb/N0= 10dB)
τ/Ts
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
0.5
0
20
40
60
80
100
τ/Ts
FIGURE 2.7
Cost function JN(τ) for Eb/N0 = 5 dB (left) and Eb/N0 = 10 dB (right) with N = 100 and τ0 = 0.1Ts.
where m is the iteration index of the gradient algorithm. The implementation of the derivative term
is actually quite easy since its corresponds to the sampled version

at ˆτ (m−1)
N

of the output of the
received signal passed through the matched ﬁlter associated with the derivative ﬁlter h′
a(t). This
can be done digitally (via interpolation) if the received signal ya(t) has been sampled at twice the
symbol rate or faster.
In order to benchmark different estimators associated with the same estimation issue, it is useful to
have a performance lower-bound on the MSE. The CRB is the most popular one because it is quite
simple to derive (especially in DA mode) and tight (we remind that under mild conditions, the ML is
asymptotically efﬁcient). We remind below the CRB deﬁnition.
CRB(τ) =
1
E

∂log p(y|τ)
∂τ

τ0
2 = −
1
E

∂2 log p(y|τ)
(∂τ)2

τ0
.
After standard algebraic manipulations, we have
log p(y|τ) = 1
N0
ℜ
N−1

n=0
s∗
n

R
ya(t)ha(t −nTs −τ)∗dt

+ const.
Thus, we obtain
∂2 log p(y|τ)
(∂τ)2
= 1
N0
ℜ
N−1

n=0
s∗
n

R
ya(t)h′′
a(t −nTs −τ)∗dt

,

2.02.2 Synchronization in Flat Fading Channel
23
with h′′
a(t) the second derivative function of ha(t). By taking the mathematical expectation (and using
the zero-mean property of the noise), we obtain
E
∂2 log p(y|τ)
(∂τ)2

= 1
N0
ℜ
⎧
⎨
⎩
N−1

n,n′=0
s∗
nsn′

R
ha(t −n′Ts)h′′
a(t −nTs −τ)∗dt
⎫
⎬
⎭.
Using Parseval’s identity, we ﬁnally obtain
E
∂2 log p(y|τ)
(∂τ)2

= −4π2
N0
ℜ
⎧
⎨
⎩
N−1

n,n′=0
s∗
nsn′

R
f 2|H( f )|2e2iπ(n′−n) f Tsd f
⎫
⎬
⎭,
where H( f ) is the Fourier transform of ha(t).
Consequently, the CRB for the timing estimation issue is given by
CRB(τ) =
N0
4π2ℜ
"N−1
n,n′=0s∗nsn′ 
R f 2|H( f )|2e2iπ(n′−n) f Tsd f
#.
This expression shows the inﬂuence of the shaping ﬁlter through the integral of the square of f H( f ). But
the inﬂuence of the training sequence (especially its size) is still quite unclear. To address this issue, we
will model our training sequence as a realization of a random process. More precisely, sn is a realization
of pseudo-noise stationary process. In practice, the training sequence is generally generated through
a shift register. Let us consider rs(m) = E[sn+ms∗
n] the autocorrelation function and the associated
spectrum Ss(e2iπ f ) = 
m rs(m)e−2iπm f . By using results on Cesaro sums, one can prove that
1
N
N−1

n,n′=0
E[sn′s∗
n]e2iπ(n′−n) f Ts a.s.
→Ss(e−2iπ f Ts),
when
N →∞.
As a consequence, we have that
CRB(τ) =
N0
4π2N

R f 2|H( f )|2Ss(e−2iπ f Ts)d f .
For channel estimation (when synchronization is perfectly done), a white training sequence (i.e.,
with ﬂat spectrum) is optimal [28,29]. But a white sequence is not necessarily the best choice for the
synchronization parameters.4 Further, the best training sequence correlation property may be different
for different synchronization parameters. Since a white sequence always leads to reasonable perfor-
mance, it provides a good trade-off. Therefore, a white training sequence is chosen in current real-life
systems.
4For example, for the timing, the best sequence is one whose spectrum is Ss(e2iπ f Ts ) = σ 2
s δ(( f −fmax)Ts) where
fmax = arg max f f 2|H( f )|2.

24
CHAPTER 2 Synchronization
When the training sequence is white, the CRB simpliﬁes to
CRB(τ) =
N0
4π2Es N

R f 2|H( f )|2d f ,
where Es is the variance of sn.
The CRB provides some insights about the behavior of the estimates.
•
CRB is O(1/N). This is reasonable since the CRB associated with channel estimation (cf. “Channel
estimation” E-reference) is also O(1/N). We recall that the timing could be incorporated into the
channel estimation box without loss in performance. Thus, fortunately the CRB offers the same
behavior.
•
CRB is O(1/SNR). Once again, this result is consistent with that one associated with channel
estimation.
•
The inﬂuence of the shaping ﬁlter can be analyzed, especially the inﬂuence of the roll-off factor.
Recall that the system is most sensitive to timing error if the roll-off is small and thus if the occupied
extra bandwidth is small. Unfortunately, the quality of estimation also decreases when the roll-off
becomes small (see [18,19] for more details).
So far, we have considered a blockwise approach. In the past, adaptive approaches (i.e., sample-
by-sample) were of great interest due to buffer size limitation and computational complexity. Today,
the adaptive approach is mainly useful for tracking parameter variations during data (and not training)
transmission. The parameter update can be implemented under two different modes: (i) the NDA mode
since it is carried out during data transmission and (ii) the Decision-Directed (DD) mode. In the NDA
mode, different updates can be developed and usually are obtained through the adaptive version of the
blockwise approaches described in Section 2.02.2.2. In the DD mode, different updates are obtained by
calculating the adaptive version of the DA estimators and then replacing the training sn with a decision
on data symbol ˆsn. Therefore, it is useful to develop an adaptive version of the previously-described
DA ML timing estimator. Thus, instead of working block-by-block, we work sample-by-sample. The
(stochastic) gradient-descent algorithm at time n can be derived from the blockwise version of the
gradient descent algorithm (cf. Eq. (2.4)) by keeping only the derivative term associated with time n.
We thus have
ˆτn = ˆτn−1 + μ ℜ

s∗
n
∂zτ(n)
∂τ

ˆτ (m−1)
N




e(n)
,
(2.5)
where ˆτn is the estimated value of τ0 at time n. Now the time index and the iteration number coincide.
Such an adaptive algorithm can be fully analyzed by using the stochastic approximation tool [30], but
this analysis is out of the scope of this chapter.
In DD mode, the symbol sn which is unknown during data transmission has to be replaced with the
(hard) decision of the symbol denoted by ˆsn. DD algorithm can be also applied with soft decision on the
symbol as was done in [31]. More details about the DD algorithm with soft decision will be given later,
in the context of phase estimation. To perform well, the error probability should be small enough to
limit the impact of error propagation. Therefore, DD mode is always implemented after an initialization

2.02.2 Synchronization in Flat Fading Channel
25
step (feasible thanks to the training sequence) in order to ensure low data detection error. In order to
avoid the calculation of the derivative at each symbol period (notice that in the blockwise approach the
number of iterations and thus of derivative calculations is much smaller than the number of samples),
we estimate it with
∂zτ(n)
∂τ

ˆτ (m−1)
N
=
z ˆτ (m−1)
N
+(n) −z ˆτ (m−1)
N
−(n)
2
,
where  is a design parameter that must be carefully adjusted. We have just described the very popular
early-late (adaptive) estimator [32]. Notice that other update equations with ad hoc e(n) have been
proposed in the literature [33,34] and often perform much better.
2.02.2.1.2
DA phase and CFO estimation
In this subsection, we assume that the timing is known and thus can be considered to be zero wlog.
Therefore, our received signal model is
ya(t) =
N−1

n=0
snha(t −nTs)

e2iπ( f0t+φ0) + ba(t).
Once again the likelihood can be written as follows:
p(y(t)|φ, f ) ∝e
−

R
ya(t)−N−1
n=0 snha(t−nTs)e2iπ( f t+φ)
2
dt/2N0.
Recall that the sequence {sn} is known. So the joint ML estimator for the phase and CFO takes the
following form:
[ ˆφN, ˆfN] = arg min
φ, f

R
ya(t) −
N−1

n=0
snha(t −nTs)e2iπ( f t+φ)

2
dt



JN (φ, f )
.
By assuming that the CFO is small compared to the bandwidth and by manipulating the square, we
obtain
JN(φ, f ) = −2ℜ
N−1

n=0
s∗
nz(n)e−2iπ( f Tsn+φ)

+ const.,
(2.6)
where z(n) = ha(−t)∗⋆ya(t)|t=nTs and can be written as follows (under the small CFO assumption)
z(n) = sne2iπ( f0Tsn+φ0) + b(n),
(2.7)
where b(n) is still a white noise process due to the square-root Nyquist property of the shaping ﬁlter.
By letting
αN( f ) = 1
N
N−1

n=0
s∗
nz(n)e−2iπ f Tsn,

26
CHAPTER 2 Synchronization
we have that
JN(φ, f ) = −2Nℜ{αN( f )e−2iπφ} + const.
Then, it is easy to check that the value of φ minimizing JN(φ, f ) for a given f, is
ˆφN = 1
2π ∠

αN( f )

= 1
2π arctan
 ℑ(αN( f ))
ℜ(αN( f ))

(2.8)
where ∠stands for the phase of a complex-valued number. Now by inserting Eq. (2.8) into Eq. (2.6),
we can easily show that the frequency estimator is obtained by maximizing the modulus of αN( f ).
Therefore, the joint DA ML phase and CFO estimates can be expressed as follows:
ˆfN =arg max
f

1
N
N−1

n=0
s∗
nz(n)e−2iπ f Tsn

2
and
ˆφN = 1
2π arctan
⎛
⎝
ℑ

1
N
N−1
n=0 s∗
nz(n)e−2iπ ˆfN Tsn
ℜ

1
N
N−1
n=0 s∗nz(n)e−2iπ ˆfN Tsn

⎞
⎠.
(2.9)
While the phase estimate is in closed-form, the CFO estimate still needs a maximization step. Actually
the function to be maximized is a periodogram-like function. As in the case of timing, this (periodogram)
maximization step may be carried out in two steps: the coarse step is done using an FFT of size N. The
resulting frequency estimate enables us to initialize a gradient-descent algorithm around the true point.
Remark.
The estimators have been developed by developing the MLE based on the continuous-time received
signal. Another way is as follows. The received signal can be viewed as
ya(t) =
N−1

n=0
sne2iπ( f0t+φ0)n(t) + ba(t),
where n(t) = ha(t −nTs). As the shaping ﬁlter is a square-root Nyquist ﬁlter, the basis functions
n(t) are orthogonal. In the absence of CFO, the useful part of the received signal is generated by
n(t); hence, we can project the received signal onto these basis functions without loss of information
on the data. Let u(n) = ⟨ya(t)|n(t)⟩with ⟨· | · ⟩the inner product. One can check that u(n) = z(n)
where z(n) is given in Eq. (2.7). Developing the ML estimator of the phase and CFO based on z(n) will
lead fortunately to the equations reported above. We can also prove that the CRBs obtained by both
approaches are identical.
As an illustration, we plot in Figure 2.8 (left) a realization of 1000 samples of z(n) when φ0 = 0.1
and f0Ts = 0.01 at Eb/N0 = 30 dB with BSPK modulation. In Figure 2.8 (right) the corresponding
cost function JN(φ, f ) has been displayed for N = 100. A peak can be observed around the true values
of φ0 and f0.
Let us now analyze the CRB associated with this estimation issue. In case of estimation of more than
one parameter, the CRB is deﬁned through a matrix as follows:
CRB(φ, f ) = F−1(φ, f ),

2.02.2 Synchronization in Flat Fading Channel
27
0
20
40
60
80
100
120
140
160
180
200
−1.5
−1
−0.5
0
0.5
1
1.5
Sample index
z(n)
Observed samples (with φ0=0.25, f0 =0.01, N=200, and Eb/ N0=30dB)
FIGURE 2.8
Samples z(n) (left) and corresponding cost function (φ, f ) →JN(φ, f ) (right).
where F(φ, f ) is the Fisher information matrix whose components here are
F(φ, f ) = −
⎡
⎢⎢⎣
∂2 log p(y|φ, f )
(∂φ)2
∂2 log p(y|φ, f )
∂φ∂f
∂2 log p(y|φ, f )
∂f ∂φ
∂2 log p(y|φ, f )
(∂f )2
⎤
⎥⎥⎦.
After straightforward algebraic manipulations, we obtain the CRB associated with the phase, that is
deﬁned as the ﬁrst element of the diagonal of CRB(φ, f ), as [24]
CRB(φ) =
N0w2
4π2N(w0w2 −w2
1),
where for any integer k,
wk =
1
N (k+1)
N−1

n=0
nk|sn|2.
The CRB associated with the frequency is the second element of the diagonal of CRB(φ, f ), and is
given by
CRB( f ) =
N0w0
T 2s 4π2N 3(w0w2 −w2
1).
These expressions can be simpliﬁed if N ≫1. We then obtain the so-called asymptotic CRB.
One can prove that
wk
a.s.
→
σ 2
s
k + 1.

28
CHAPTER 2 Synchronization
Consequently, we have
CRB(φ) ≈1
π2
N0
Es
1
N
and CRB( f ) ≈
3
T 2s π2
N0
Es
1
N 3 .
(2.10)
Notice that, in [25], the (large samples) MSEs of the ML have been calculated and are identical to those
given by the asymptotic CRB. Consequently the ML is asymptotically efﬁcient and thus we do not need
to spend time to design other estimators since the ML is almost optimal and can be implemented easily
in practice.
Thanks to these expressions, some insights about the estimation performance can be given:
•
MSE of the phase estimator is O(1/N) and O(1/SNR). The behavior mimics that of the channel
estimator. This is reasonable since the phase rotation can be viewed as a one-tap linear ﬁltering
operation.
•
In contrast, the MSE for the CFO decreases much faster as O(1/N 3). The convergence speed seems
to be very high. We will see that we need to have this high convergence speed for the system to
operate properly. Let us consider a frame with a training sequence of length NT followed by a
data sequence of length ND. For the system to operate well, the phase rotation due to the CFO
should be kept as low as possible. At the end of the frame, the phase rotation (after correction)
is 2πTs( ˆfN −f )(NT + ND) which is of order O((NT + ND)/N 3/2
T
). Assume a constant ratio β
between NT and ND. Thus β = NT /ND and corresponds to the loss in spectral efﬁciency caused
by the training. Then the phase rotation is proportional to 1/√ND and this tends to zero when the
frame is large enough. Notice that if the frequency MSE was O(1/N p) with p ≤2, the system
cannot perform well due to the unbounded phase rotation associated with CFO.
The inﬂuence of the noise is similar since the MSE is of order O(1/SNR).
In Figure 2.9, we plot the MSE of the phase and CFO ML estimate and the corresponding CRB:
versus Eb/N0 (left) with N = 32, Ts = 1 s, and versus N (right) with Eb/N0 = 3 dB and Ts = 1 s.
The training sequence was BPSK modulated.
We ﬁrst observe that when the SNR and the number of samples are high enough, ML estimate
performance perfectly matches CRB as expected. We also observe a strange phenomenon at low SNR
and/or when the number of samples is not large enough: there is a mismatch between the theoretical
performance and the empirical one. Moreover the ML is no longer efﬁcient. This is the so-called outliers
effect [35–38]. It is associated with the failure of the ﬁrst step of the periodogram maximization. This
phenomenon has been analyzed in the literature, and modiﬁed expressions for MSE, taking into account
this effect have been derived. The most interesting question is: can we ﬁll up the gap between the ML and
the CRB by using another estimator? The answer is no. To answer this, other lower bounds have been
developed and analyzed. One can mention Barankin-like bounds [39–43], Bhattacharya-like bounds
[44], and Ziv-Zakaï-like bounds [45–48]. A lot of work has been done on deriving such bounds for the
harmonic retrieval problem, where it has been shown that the CRB was not tight at low SNR. Other
bounds (especially the Ziv-Zakaï one) are actually very close to ML performance, so that it is hard to
ﬁnd better estimates.
In Figure 2.10, we plot CRB, the (ﬁrst-order) Barankin Bound (BB), the Ziv-Zakaï Bound (ZZB)
and the MSE of the ML estimator for CFO parameter versus Eb/N0 (left) when N = 32 and versus

2.02.2 Synchronization in Flat Fading Channel
29
−5
0
5
10
10
7
10
6
10
5
10
4
10
3
10
2
10
1
Eb/N0
MSE
MSE and CRB (with N=32 and Ts =1s)
MSE and CRB (with N=32 and Ts =1s)
phase
CRB phase
CFO
CRB CFO
0
20
40
60
80
100
120
140
10
8
10
7
10
6
10
5
10
4
10
3
10
2
10
1
10 0
N
MSE
phase
CRB phase
CFO
CRB CFO
FIGURE 2.9
MSE and CRB for phase and CFO versus Eb/N0 (left) and N (right).
−20
−15
−10
−5
0
5
10
10
7
10
6
10
5
10
4
10
3
10
2
10
1
10
0
Eb/N0
MSE
MSE, CRB, BB, and ZZB (with N=32 and Ts= 1s)
MSE
CRB
BB
ZZB
0
5
10
15
20
25
30
35
10
6
10
5
10
4
10
3
10
2
10
1
10 0
N
MSE
MSE, CRB, BB, and ZZB (with Eb/ N0= 3dB and Ts= 1s)
MSE
CRB
BB
ZZB
FIGURE 2.10
MSE, CRB, BB, and ZZB for CFO versus Eb/N0 (left) and N (right).
N (right) when Eb/N0 = 3 dB. Notice that the threshold (from which the ML performance can be
distinguished from the CRB) can be moved to the left by increasing the SNR (when N is ﬁxed) or by
increasing N (when the SNR is ﬁxed) in order to obtain the target performance.
Let us now move on to the adaptive version of the ML. As the CFO can be viewed as phase variations
(with a very speciﬁc structure), the adaptive algorithm which has the ability of tracking phase variation
has been almost always developed under the assumption that only the phase is non-zero and that the

30
CHAPTER 2 Synchronization
CFO is zero. Therefore, we work with the following discrete-time signal:
z(n) = sne2iπφ + b(n)
(2.11)
and the (blockwise) ML for the phase leads to the following cost function (cf. Eq. (2.6)
ˆφN = arg max
φ
N−1

n=0
ℜ
"
s∗
nz(n)e−2iπφ#
.
Following an approach similar to that for timing, ˆφn, the estimate of the phase at the nth iteration of the
(stochastic) gradient algorithm, is updated as follows:
ˆφn = ˆφn−1 + μ ∂ℜ
.
s∗
nz(n)e−2iπφ/
∂φ
 ˆφn−1
= ˆφn−1 + μ ℑ
"
s∗
nz(n)e−2iπ ˆφn−1
#



e(n)
.
(2.12)
Thanks to this update equation, we can introduce the well-known digital Phase-Locked Loop (PLL)
scheme to track the phase.
Note that ˆφn −ˆφn−1 can be written as [1 −z−1] · ˆφn which means that ˆφn is obtained after the phase
error e(n) is passed through a ﬁlter whose Z-transform is z →1/(1−z−1). Therefore, the PLL scheme
can be described as in Figure 2.11.
We would now like to inspect the convergence of the PLL ﬁrst when the phase is ﬁxed, and then
when the phase is time-varying. To do this, we consider that φ0 is ﬁxed for the ﬁrst 1000 samples z(n),
and then is time-varying for the next 1000 samples as follows:
φ0,n = φ0,n−1 + wn,
for n = 1001, . . . , 2000,
where φ0,1000 = φ0 and wn is a real-valued i.i.d. Gaussian process with zero-mean and variance σ 2
w. In
Figure 2.12, we display a realization of the estimated ˆφn and the true phase φ0,n with σ 2
w = 10−4 and
Eb/N0 = 20 dB .
We remark that proper choice of μ is crucial for good PLL performance. If μ is high, the PLL will
rapidly reach an interval around the true value but then will oscillate around the true point without
converging. Moreover, a high value of μ enables us to efﬁciently track the phase variation/noise. In
contrast, when μ is small, the convergence speed is low but the phase estimate does not oscillate very
much around the true point. But the small value of μ prevents us from following the (too-fast) phase
variation/noise.
Indeed, if the phase to be estimated is ﬁxed, it is well known that it is best to consider a time-varying
step size μn satisfying 
n μn = +∞and 
n μ2
n < +∞[30]. Therefore, an appropriate choice is
μn = μ/n when the phase is ﬁxed. However, such a choice leads to very poor performance if the
phase becomes time-varying. A lot of work has been done on designing μn to adapt to phase noise
characteristics [30].

2.02.2 Synchronization in Flat Fading Channel
31
X
z −1
ˆφn
e(n)
X
sn
z(n)
e−2iπ ˆφn
1
First-order ﬁlter
Phase comparator
e−2iπ •
1
1−z
1
Filter
Loop
K (z) = µ
*
FIGURE 2.11
PLL scheme (in DA context).
0
500
1000
1500
2000
2500
3000
3500
4000
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
n
Phase value
PLL for fixed phase until n=2000 and then time−varying phase (Eb/N0=20dB, μ=0.01, and σw
2 =1e−4)
Estimated phase
True phase
0
500
1000
1500
2000
2500
3000
3500
4000
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0.18
0.2
n
Phase value
PLL for fixed phase until n=2000 and then time−varying phase (E b/N0=20dB, μ=0.001, and σw
2 =1e−4 )
Estimated phase
True phase
FIGURE 2.12
Estimated phase and true phase versus the number of iterations/samples for μ = 0.01 (left) and μ = 0.001
(right).
2.02.2.2 NDA case
Here we will develop NDA estimators:
•
for timing insensitive to phase and CFO (Problem 2′),
•
for phase and frequency insensitive to timing (Problem 2).

32
CHAPTER 2 Synchronization
As before, we will start with the ML estimators. As in DA mode, the global estimation issue (for timing,
phase and frequency) is not tractable. Therefore, we will focus on
•
NDA timing ML estimator when phase and CFO are known and thus zero wlog.
•
NDA phase and CFO ML estimators when timing is known and thus zero wlog.
2.02.2.2.1
NDA ML timing estimator
Now the symbols sn are unknown. We just assume that sn belongs to a particular constellation with
P states (P-PAM, P-PSK, P-QAM) and that each constellation point is equally-likely. We denote by
{s(p)}p=0,...,P−1 the set of these constellation points. We also denote by sN = [s0, . . . , sN−1]T the set
of transmitted data symbols. The likelihood takes a much more complicated form due to the need to
average over all the potential symbols. Therefore, we have
p(y|τ) =

· · ·

p(y|τ, sN)ps(sN)dsN,
where ps(·) is the probability density function of sN. Obviously, we have
p(y|τ, sN) ∝e
−

R
y(t)−N−1
n=0 snha(t−nTs−τ)

2
dt/2N0
and
ps(sN) =
N−1
0
n=0
⎛
⎝1
P
P−1

p=0
δ(sn −s(p))
⎞
⎠
as sn are i.i.d.
After simple but tedious algebraic manipulations (using the fact that the shaping ﬁlter is a square-root
Nyquist ﬁlter), we obtain
ˆτN = arg max
τ
N−1

n=0
log
⎛
⎝1
P
P−1

p=0
e−|s(p)|2
2N0 e
ℜ{(s(p))∗zτ (n)}
N0
⎞
⎠.
When BPSK is employed, we obtain
ˆτN = arg max
τ
N−1

n=0
log

cosh
ℜ{zτ(n)}
N0

.
At low SNR, the Taylor series expansion of log (cosh (·)) can be used to yield
ˆτN = arg max
τ
N−1

n=0

ℜ{zτ(n)2} + |zτ(n)|2
(BPSK at low SNR).
When QPSK is employed, similar derivations lead to
ˆτN = arg max
τ
N−1

n=0
|zτ(n)|2
(QPSK at low SNR).

2.02.2 Synchronization in Flat Fading Channel
33
We will see that the NDA ML approach for timing is very complicated except for BPSK and QPSK.
To handle constellations with more states, Expectation-Maximization (EM) algorithm can be employed
and will be explained later in the section devoted to Code-aided synchronization. Notice that in [49] EM
algorithm is also implemented but in another way: indeed, the timing error is viewed as the nuisance
parameter with an a-priori distribution while the data are viewed as the useful parameters to be detected.
The authors thus attempt to extend the Maximum Likelihood Sequence Estimator to the case of timing
error and are able to correct it through an iterative implementation.
Actually, this timing estimator is very sensitive to phase and CFO. Therefore, we do not continue its
analysis in depth. Obviously, an adaptive version may be implemented and the early-late trick can be
employed as well.
It is clear that in the NDA case, we need to develop a sub-optimal (non-ML) timing estimator which
is insensitive to phase and CFO. We do so next.
2.02.2.2.2
NDA ML phase and CFO estimator
We now assume that the timing is known and thus zero wlog. Once again, we would like to characterize
the NDA joint ML phase and CFO estimator.
By following the same reasoning as for the timing, we obtain that
[ ˆφN, ˆfN] = arg max
φ, f
N−1

n=0
log
⎛
⎝1
P
P−1

p=0
e−|s(p)|2
2N0 e
ℜ{(s(p))∗z(n)e−2iπ( f Tsn+φ)}
N0
⎞
⎠.
(2.13)
In contrast with the DA case, we are not able to write φ with respect to f. As a consequence, the
maximization remains a 2-D search which is extremely time consuming. Therefore, we could focus on
(i) CFO estimation issue when phase is known and (ii) phase estimation when CFO is known. The ﬁrst
scheme is clearly unrealistic, and thus will be omitted. In contrast, the second scheme is of interest,
especially in the tracking regime.
We now assume that CFO is known and thus can be assumed to be zero wlog. Equation (2.13) can
be simpliﬁed as follows:
ˆφN = arg max
φ
N−1

n=0
log
⎛
⎝1
P
P−1

p=0
e−|s(p)|2
2N0 e
ℜ{(s(p))∗z(n)e−2iπφ}
N0
⎞
⎠.
(2.14)
In Figure 2.13, we have plotted the cost function given in Eq. (2.14) for various QAM constellations.
Notice that the smaller the constellation, the sharper is the cost function. Therefore, it is easier to
estimate phase for small constellation sizes. When a high-order constellation is used, the SNR must
be high enough to ensure accurate synchronization (this is not necessarily a drawback since high-order
modulation requires high SNR for detection) and the number of samples must be large enough as
well (which clearly may become an issue). Figure 2.14 depicts the MSE of NDA ML based phase
estimate versus SNR, N and the timing error respectively for BPSK constellation. The MSE decreases
proportionally to 1/SNR and 1/N. Moreover it is insensitive to timing error.
To overcome the implementation issues due to the highly complicated shape of the cost function,
EM algorithm can be employed as in [50].

34
CHAPTER 2 Synchronization
17000
17500
18000
18500
19000
19500
20000
0.05
0.06
0.07
0.08
0.09
0.1
0.11
0.12
0.13
0.14
0.15
Cost function
φ
ML Cost function for NDA phase estimation ( φ0=0.1, E b/N0=20dB, N=100)
4QAM
16QAM
64QAM
256QAM
FIGURE 2.13
Cost function of NDA ML phase estimate (with φ0 = 0.1, Eb/N0 = 20 dB, N = 100) for various P-QAM.
Once again, as with the NDA ML based timing estimate, the cost function in Eq. (2.14) can be
simpliﬁed to when BPSK is used
ˆφN = arg max
φ
N−1

n=0
log

cosh
ℜ{z(n)e−2iπφ}
N0

(BPSK).
(2.15)
An exhaustive search to solve Eq. (2.15) would be quite time consuming. However, at low SNR, as with
the timing case, we obtain that
ˆφN = arg max
φ
N−1

n=0
ℜ{z(n)2e−2iπ2φ}
⇔ˆφN = 1
2∠
N−1

n=0
z(n)2

(BPSK at low SNR).
The NDA ML phase estimate is equivalent to the so-called square-power estimate at low SNR which
can be easily implemented. Similar results can be obtained for any P-QAM or any P-PSK. Indeed, the
NDA ML phase estimate is equivalent to the Mth Power estimate with M = 4 for any P-QAM and
M = P for any P-PSK [51]. Further information about other phase estimators, with PSK modulation,
can be found in [52].
Let us consider the BPSK case in more detail. We would like to implement Eq. (2.15) in an adaptive
manner. Let ˆφn be the value of the estimated phase at time n (i.e., at the nth iteration). The update

2.02.2 Synchronization in Flat Fading Channel
35
0
2
4
6
8
10
12
14
16
18
20
10
6
10
5
10
4
10
3
Eb/N0
MSE
MSE for ML NDA phase estimate (N=100)
0
50
100
150
200
250
300
350
400
450
500
10
6
10
5
10
4
N
MSE
MSE for ML NDA phase estimate (E b/ N0=10dB)
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
10
6
10
5
10
4
10
3
τ/Ts
MSE
MSE for ML NDA phase estimate (Eb/ N0=10dB, N=100)
FIGURE 2.14
MSE of NDA ML phase estimate with BPSK modulation versus Eb/N0 (top), N (middle), and τ0 (bottom).

36
CHAPTER 2 Synchronization
equation is
ˆφn = ˆφn−1 + μ
∂log

cosh

ℜ{z(n)e−2iπφ}
N0

∂φ
 ˆφn−1
= ˆφn−1 + μℑ
"
ˇsnz(n)e−2iπ ˆφn−1
#
with
ˇsn = tanh

ℜ{z(n)e−2iπ ˆφn−1}
N0

.
(2.16)
Notice that the update equation is very similar to that in the DA case (cf. Eq. (2.12)) except that sn has
been replaced with ˇsn. By looking carefully at ˇsn, we observe that it corresponds to the so-called soft
decision under BPSK constellation assumption. If the soft decision is replaced with a hard decision,
then we are in the Decision Directed context, and the estimator ˇsn becomes
ˇsn = sign

ℜ{z(n)e−2iπ ˆφn−1}
N0

(Decision-Directed).
If a decision is made (other than soft or hard), the term ˇsn can be written as
ˇsn = ℜ{z(n)e−2iπ ˆφn−1}
N0
(No data decision)
and corresponds to the famous Costas loop originally introduced for continuous-time amplitude-
modulated signals [53,54].
Inconclusion,werecallthatthejointNDAsyncparametersestimationissueisintractable.Tosimplify
it, we ﬁrst focus on the timing. The NDA ML timing estimator is quite complicated (except for BPSK
and QPSK) and very sensitive to phase and CFO. So it is useless in practice. We next consider phase
and CFO estimation issues. Clearly the joint problem is still intractable. Therefore, we only focus on
the phase estimation issue assuming CFO is known. When the constellation size is small enough, the
NDA ML phase is implementable in blockwise or adaptive manner and is not too sensitive to timing
error.
Consequently, in order to build practical system, we still need sub-optimal (non-ML) blind methods
•
For estimating the timing without the knowledge of the phase and the CFO.
•
For estimating the CFO without the knowledge of the timing and the phase.
•
For estimating the phase when the constellation size becomes high. The insensitivity to the timing
and the CFO is not required since the phase estimator is often carried out after timing and CFO
correction.
2.02.2.2.3
Sub-optimal estimators
In this section, we will develop sub-optimal estimators for the sync parameters. To do that, we will
analyze carefully some statistical properties of the received signal. Based on these properties, we will

2.02.2 Synchronization in Flat Fading Channel
37
be able to introduce some powerful estimators. The main statistical tools we need are brieﬂy described
below:
•
The Cyclostationarity tool: For sake of simplicity, we will only deﬁne second-order cyclostationarity.
For more details about any-order cyclostationarity, the reader may refer to [55,56]. Let us consider
x(t) a (complex-valued) continuous-time process and its correlation function (t, τ) →r(t, τ) =
E[x(t + τ)x(t)∗]. When the process is second-order stationary, then the function (t, τ) →r(t, τ)
is independent of t. In contrast, if the function (t, τ) →r(t, τ) is periodic with respect to t (and
the period is independent of τ), the process is said to be cyclostationary. Let Tc be the period of
the correlation function. Tc is called the cyclic period. By considering a Fourier series expansion,
we have
r(t, τ) =

k
r(k)(τ)e2iπk/Tc,
where
–
fk = k/Tc is the so-called kth cyclic frequency,
– τ →r(k)(τ) is the cyclic correlation (at cyclic frequency k),
– S(k)(e2iπ f ) = 
τ r(k)(τ)e−2iπ f τ is the cyclic spectrum (at cyclic frequency k).
A similar analysis can be done with the pseudo-correlation (t, τ) →u(t, τ) = E[x(t + τ)x(t)] if
it is not identically zero.
•
The Non-Circularity tool: let us consider a random (complex-valued) zero-mean scalar variable x.
A variable is said to be circularly-symmetric (or simpler circular) if x and ˜x = e2iπθ x have the
same distribution regardless of the rotation angle θ. Consequently the distribution is rotationally
invariant. By assuming that the moment at any order exists, we have E[x px∗q] = E[˜x p ˜x∗q] which
implies that E[x px∗q] = 0 as soon as p ̸= q. Thus, when a variable is circularly-symmetric, only
the moment at even orders may be non-zero. Moreover only the moments depending on a power of
|x| are non-zero. In digital communications, many variables are circular not for arbitrary orders but
only until a certain order. If
E[x px∗q] = 0
for p ̸= q and p + q < M, the random variable x is said to be circular until the (M −1)th order or
equivalently to be non-circular from the Mth order. For more details about the non-circularity, the
reader may refer to [13,51,57].
The rest of this section is organized as follows: we focus on the timing estimator (based on the
cyclostationary tool), then the CFO estimator (based on the cyclostationary or non-circularity tools),
and the phase estimator (based on the non-circularity tool).
Timing estimation
We observe that the signal ya(t) is cyclostationary with period Ts [17]. Consequently the discrete-time
(over-sampled) signal ˜y(n) = ya(nTs/Q) is also cyclostationary with period Q, i.e., the sequence
E[ ˜y(n + m) ˜y(n)∗] = E[ ˜y(Q + n + m) ˜y(Q + n)∗] is periodic for any integer m. Notice that if the
continuous-time received signal is sampled at the symbol rate, Q = 1 and thus y(n) is stationary. In
contrast, if Q ≥2, ˜y(n) is strictly cyclostationary.

38
CHAPTER 2 Synchronization
First of all, assuming that the CFO is zero, it has been remarked in [58] that r(k)(m) = αk,me−2iπkτ/Ts
for k ̸= 0, with αk,m a known complex-valued constant depending on the shaping ﬁlter. Thanks to this
relationship between r(k)(m) and τ, the following ad hoc estimator was proposed in [58]:
ˆτN = −Ts

k∈K∗

m∈M
1
k ∠

ˆr(k)(m)α−1
k,m

,
(2.17)
where K∗is any set of integers, not including 0, and M is any set of integers m such that r(k)(m) ̸= 0.
The term ˆr(k)(m) is the empirical estimate of r(k)(m) based on N samples, and is given by
ˆr(k)(m) = 1
N
N−1

n=0
˜y(n + m) ˜y(n)∗e−2iπnk/Q.
(2.18)
The performance of such an empirical cyclic correlation estimate can be found in [17,58–61].
Notice that the timing estimator is insensitive to the phase, and thus can be used before the phase
estimation step. In contrast, when the CFO is not zero, it must be estimated ﬁrst; the timing estimate is
then modiﬁed as follows:
ˆτN = −Ts

k∈K∗

m∈M
1
k ∠

ˆr(k)(m)α−1
k,me−2iπm ˆfN Ts/Q
,
(2.19)
where ˆfN is the CFO estimate.
When K = {1}, M = {0}, and the conjugate operation on ˜y is removed, we obtain the heuristic
algorithm introduced in [62] which actually is well-suited for BPSK constellation. When K = {1} and
M is any singleton, we obtain the algorithm in [63]. With K = {−1, 1} and M = {0}, the estimator
reduces to that in [64]. This last algorithm has the great advantage of being insensitive to the CFO since,
for m = 0, Eq. (2.17) is identical to Eq. (2.19).
All these timing estimators have been theoretically analyzed and closed-form expressions for the
Mean-Square Error are given in [65].
The question now is: what is the best blind estimator for timing relying on the cyclic correlation.
When P = 2, the answer can be found in [65] and corresponds to the weighted covariance matching
principle [66,67]. The gain in performance is only incremental at the expense of higher complexity.
Therefore, the NDA timing estimator proposed in Eq. (2.17) (especially that in [64] which is insensitive
to CFO) is a strong candidate for our problem.
CFO estimation
The cyclostationarity property can also be used for estimating the CFO blindly. Indeed, in [58], it has
been remarked that r(k)(m) = αk,me2iπkτ/Tse2iπm f Ts/Q with βk a complex valued scalar which induces
the following estimator:
ˆfN =
P
4πTs

k∈K∗

m∈M∗
1
m ∠

ˆr(k)(m)ˆr(−k)(m)α−1
k,mα−1
−k,m

,
(2.20)

2.02.2 Synchronization in Flat Fading Channel
39
where M∗corresponds to any set of integers that does not contain zero. This estimator is insensitive to
timing and phase. Once again, by taking speciﬁc elements for the set K and M, we obtain the estimators
introduced in [63,64]. The theoretical analysis of the estimator has been done in [59].
Another approach to estimate the CFO independent of the timing and the phase is to use the non-
circularity property of the received signal ya(t). Indeed, it is easy to check [51] that
E
1
sM
n
2
̸= 0
with
•
M = 2 for P-PAM constellation,
•
M = P for P-PSK constellation,
•
M = 4 for P-QAM constellation.
Consequently, the received signal is also non-circular of Mth order. For the sake of simplicity, let us
consider that the received signal has been sampled at the symbol rate after passing through the matched
ﬁlter. Extension to the oversampled case is straightforward. Then
y(n) =
 L

ℓ=0
g(ℓ)sn−ℓ

e2iπ f Tsn + b(n),
where g(n) = ˜ha(nTs −τ0)e2iπφ0, (L + 1) is the channel length and b(n) the additive white Gaussian
noise. Notice that if the timing has been perfectly corrected and the shaping ﬁlter is a square-root Nyquist
ﬁlter, we have g(n) = δ0,ne2iπφ0 and thus L = 0. When the timing is not fully corrected, the ﬁlter g(n)
is no longer a one-tap ﬁlter and ISI occurs. Moreover as τ0 and φ0 are unknown, we have to assume
that g(n) is unknown as well.
We can rewrite y(n) as
y(n) = a(n)e2iπ f Tsn + b(n) where a(n) =
L

ℓ=0
g(ℓ)sn−ℓ.
Our estimation problem is then equivalent to the estimation of a harmonic f disturbed by additive white
Gaussian noise b(n) and multiplicative noise a(n). A lot of work has been done on the problem of
harmonic retrieval in multiplicative and additive noise. We will summarize the essential results.
Let us ﬁrst assume P-PAM constellation. Let ua(m) = E[a(n + m)a(n)] be the pseudo-correlation
at lag m. As PAM is employed, there exists at least one lag such that ua(m) is non-zero. Let pm(n) =
y(n + m)y(n). We have
pm(n) = ua(m)e2iπ(2 f Ts)n + em(n),
where em(n) is a zero-mean process which can be viewed as noise. But this noise is not Gaussian, not
white, and not stationary. Nevertheless, by working with pm(n), we now have to estimate a harmonic

40
CHAPTER 2 Synchronization
(2 f ) disturbed only by additive noise. The multiplicative noise has been removed. We recall that if e(n)
is Gaussian white and stationary, the ML based on pm(n) will lead to peak-picking the periodogram.
Even if e(n) does not satisfy these standard assumptions, it is still usual practice to estimate the frequency
through periodogram peak-selection (even if it no longer has any link with the ML). Then, we have
ˆfN = arg max
f

m

1
N
N−1

n=0
pm(n)e−2iπ(2 f )Tsn

2
.
When m = 0, we have
ˆfN = arg max
f

1
N
N−1

n=0
y(n)2e−2iπ(2 f )Tsn

2
,
which is the well-known (and classical) square-power estimator.
To analyze the theoretical performance of these estimators, the standard work on harmonic retrieval
(which assumes the additive noise is Gaussian) cannot be applied [68–70]. However, the analysis has
been done quite recently in [71]. Notice that the above approach holds if a(n) is real-valued without
assuming any speciﬁc structure [61,72]. However, the previous estimator has limited impact since the
PAM constellation is not spectrally efﬁcient.
We now consider P-PSK and P-QAM constellations. Let M be the non-circularity order. Recall that
M = P for PSK and M = 4 for QAM. Let q(n) = y(n)M. Then
q(n) = E[q(n)]e2iπ(M f )n + e′(n),
where e′(n) is a zero-mean process that can be interpreted as additive noise. Once again one can carry
out periodogram peak-picking for retrieving f. Thus, we have
ˆfN = arg max
f

1
N
N−1

n=0
y(n)Me2iπ(M f )Tsn

2
.
(2.21)
This estimator has been introduced by [73] for PSK. Several extensions of these estimators may be
introduced. For example, instead of relying only on y(n)M, one could also work with y(n)y(n +
m1) · · · y(n + mM−1). This has not been done in the literature. One could also ﬁnd the best non-linear
transformationF suchthatpeak-pickingtheperiodogrambasedonF(y(n))hassomedesiredproperties.
One can ﬁnd some results about optimization of F in [74].
In Figures 2.15 and 2.16, we plot the theoretical and empirical performance of the Mth power estimate
for various QAM constellations, varying the SNR and the number of samples N, respectively.
For QAM, we observe a self-noise phenomenon since the performance has an error ﬂoor with respect
to SNR. It is due to the fact that s4
n ̸= E[s4
n]. A recent approach can be used to remove the self-noise
(see [75]).
The outliers effect still occurs as in any approach based on peak-picking periodogram. The theoretical
MSE taking into account the outliers has been analyzed in [38] for modulated signals and [35] for
unmodulated signals.

2.02.2 Synchronization in Flat Fading Channel
41
−2
0
2
4
6
8
10
12
14
16
18
20
10
12
10
10
10
8
10
6
10
4
10
2
10
0
Eb/N0
MSE
Theoretical and Empirical MSE versus Eb/N0 (N=128, QPSK/4QAM)
Empirical MSE
Theoretical MSE
0
5
10
15
20
25
30
10
12
10
10
10
8
10
6
10
4
10
2
10
0
Eb/N0
MSE
Theoretical and Empirical MSE versus Eb/N0 (N=128, 256QAM)
Empirical MSE
Theoretical MSE
FIGURE 2.15
Theoretical and Empirical MSE of Mth power CFO estimate versus Eb/N0 for 4-QAM (left) and 256-QAM
(right) with N = 128.
50
100
150
200
250
300
350
400
450
500
10
12
10
10
10
8
10
6
10
4
10
2
10
0
N
MSE
Theoretical and Empirical MSE versus N (E b/N0=5dB − 4QAM)
Empirical MSE
Theoretical MSE
50
100
150
200
250
300
350
400
450
500
10
12
10
10
10
8
10
6
10
4
10
2
10
0
N
MSE
Theoretical and Empirical MSE versus N (Eb/N0=20dB − 256QAM)
Empirical MSE
Theoretical MSE
FIGURE 2.16
Theoretical and Empirical MSE of Mth power CFO estimate versus N for 4-QAM at Eb/N0 = 5 dB (left) and
256-QAM at Eb/N0 = 20 dB (right).
Phase estimation
For estimating the phase, we will assume that the timing and CFO have already been correctly com-
pensated. Then we focus on the sampled (at the symbol rate) output of the matched ﬁlter. Therefore,
we have
z(n) = sne2iπφ0 + b(n).

42
CHAPTER 2 Synchronization
The approach for estimating the phase will be similar to that for the estimation of CFO by using the
non-circularity property of the constellation. Since
q(n) = y(n)M = E[sM
n ]e2iπ(Mφ0) + e(n),
where e(n) is a zero-mean process and E[sM
n ] is assumed to be known with phase φ∗. Then it is easy to
build a simple estimator as follows:
ˆφN = 1
M ∠

1
N
N−1

n=0
y(n)M

−φ∗.
(2.22)
Obviously we have an ambiguity of 2π/M since the constellation is invariant to rotations of angle
2πk/M, for any integer k. We recall that this estimate is close to the ML at low SNR.
This approach was introduced for PSK by [73] and for QAM by [51]. Notice that other less powerful
estimates of the phase have been introduced in the literature. A deep theoretical analysis of the estimators
can be found in [76].
2.02.2.2.4
CRB
In the DA case, we have observed that the derivations of CRB was not a difﬁcult task. Moreover,
we were able to obtain rather nice closed-form expressions that enable us to provide some interesting
insights. In the NDA case, in contrast, the CRB expressions in closed-form are much more difﬁcult to be
achieved due to the presence of the unknown data sequence. We thus work in the framework of the CRB
with nuisance parameters. Obviously the nuisance parameters here are the data. Why is it difﬁcult? To
calculate the CRB, we need at least to have a closed-form expression for the likelihood. As noted earlier
in the discussion of blind ML estimators, a closed-form expression of the likelihood is very difﬁcult to
obtain.
The main idea is to deﬁne a variant of the CRB assuming a speciﬁc property for the data sequence
(the nuisance parameters). In order to be useful, these CRB variations should be easier to derive and
should provide some insights. Typically, these CRB variants will not be as tight as the classical CRB,
and hence they will be optimistic.
A lot of work has been done on the derivation of the CRB for synchronization parameters and/or
channel estimators [77–87]. We will summarize the main principle in deriving CRB with nuisance
parameters. Applications to phase and CFO estimation are provided with more details.
Let us start with the deﬁnition of several CRBs:
•
True-TCRB (also called Unconditional-UCRB or Stochastic-SCRB): The data sequence is viewed
as a random process with a known distribution (a product of sum of Dirac distributions). Let θ be
the synchronization parameter vector [83–85,87]. The true Fisher Information Matrix is deﬁned as
Ft(θ) = −E
∂2 log (p(y|θ)
∂θ(∂θ)T

with the true likelihood
p(y, θ) = Es
3
p(y|θ, s)
4
=

· · ·

p(y, |θ, s)p(s)ds.

2.02.2 Synchronization in Flat Fading Channel
43
Then the true CRB is obtained as
TCRB(θ) = Ft(θ)−1.
The main drawback is that it is usually intractable to express this in closed-form. Some expressions
are given in [84] but it is not really in closed-form due to the huge number of sums and products.
•
Conditional-CCRB(alsocalledDeterministic-DCRB):Thedatasequenceisassumedtobeofinterest
and is added to the parameters to be estimated. Notice that the structure of the data sequence (i.e.,
data belong to a speciﬁc discrete constellation) is not taken into account. If we would like to take this
structure into account, we should calculate the CRB when strong constraints on the parameters have
to be satisﬁed. Such a problem is very hard [88,89] and thus we are far away from our objective of
simplifying the CRB derivations. The difﬁculty can be partially overcome by considering Bayesian
CRBs which use a-priori distributions on the data [27]. Let us come back to the CCRB [77]. Let Fc
be the Fisher information matrix when ˆsN is given. We have
Fc(θ) = −E
∂2 log (p(y|θ, ˆsN)
∂θ(∂θ)T

,
where ˆsN is obtained by maximizing over s (by omitting all the constraints on s) the conditioned
likelihood s →p(y|θ, s). Then the conditioned CRB is obtained as
CCRB(θ) = Fc(θ)−1.
Usually the asymptotic version is used i.e., the number of samples is assumed to be large.
•
Gaussian-GCRB: The true CRB is very difﬁcult to compute due to the distribution of s. To overcome
this problem, one can assume that s is Gaussian distributed (even though this is not true). The
GCRB is thus obtained by using the same deﬁnition of the true CRB but by assuming a Gaussian
data sequence. Obviously this GCRB is not generally a bound since it implicitly assumes that the
higher-order cumulants are zero. For example, if the data is PSK and QAM, we have seen that the
higher-order moments are very important through the Mth power estimate and thus the GCRB does
not capture this information. Nevertheless the GCRB has two advantages: it is quite easy to derive
in closed-form, and it is a bound on the MSE for all the estimates based on second-order statistics
(even if the data sequence is not Gaussian) [79,80,86].
•
Modiﬁed-MCRB: Data are assumed to be known in order to calculate the Fisher Information Matrix.
In order to have a Fisher Information Matrix (FIM) independent of data, the data-dependent FIM is
averaged over the data. Therefore, we have
Fm(θ) = −Es

Ey
∂2 log (p(y|θ, s)
∂θ(∂θ)T

.
Then the MCRB [78,81,82] is deﬁned as
MCRB(θ) = Fm(θ)−1.
In terms of derivations, the main difference from the TCRB is that the average over the data is outside
the log (for MCRB) and inside the log for the TCRB. This quite small difference leads to tractable

44
CHAPTER 2 Synchronization
MCRB and usually intractable TCRB. Indeed, the log will be removed by the exp in p(y) due to
the Gaussian additive noise. In MCRB, log will directly remove the exp although it is not the case
for TCRB, thus leading to very hard calculations.
In the sequel, we provide some general results on the links between the various CRBs. This relation-
ship is independent of the estimation problem:
•
At low SNR, the TCRB is much more tractable by doing a Taylor series expansion of ex for small
x [83,85,87].
•
At any SNR, the MCRB is a bound but sometimes too optimistic and thus not tight enough.
•
At any SNR, we have TCRB ≥MCRB and CCRB ≥MCRB [77].
•
At high SNR, if the data sequence belongs to a discrete set, we have TCRB/MCRB →1. So in our
context where data belong to a ﬁnite constellation, this property holds and thus the MCRB is very
useful as soon as the SNR is large enough [83].
Let us now focus on our speciﬁc estimation problem: for timing estimation (when phase and CFO
are perfectly corrected), there already exists a very good tutorial [20,77]. Therefore, we focus on phase
and CFO estimation (when timing is known and thus zero wlog). Then we work with the (symbol-rate)
sampled output of the matched ﬁlter. Thus our signal model is
y(n) = sne2iπ( f0Tsn+φ0) + b(n).
Let us focus on a “toy” example to highlight some interesting results. We ﬁrst assume that sn can be
decomposed as follows
sn = σRs(R)
n
+ iσIs(I)
n ,
where s(R)
n
and s(I)
n
are two unit-variance white BPSK sequences independent of each other;
σ 2
R = (1 + u)/2 and σ 2
I = (1 −u)/2 with u ∈[0, 1] such that the correlation E[|sn|2] = 1 and
E[s2
n] = u. Notice that if u = 1, then sn becomes a standard BPSK. And if u = 0, sn is no longer a
(second-order) non-circular process. Even though both phase and CFO have to be estimated, we only
provide the expressions for CRB associated with the CFO estimate.
•
TCRB derivations: As the nuisance parameter is discrete, we know that at high SNR the TCRB
is equivalent to the MCRB; the latter can be calculated very easily by averaging the FIM given in
Eq. (2.10). Therefore, we have
TCRB( f )|high SNR =
3N0
π2T 2s N 3 .
At low SNR [83], a derivation based on the Taylor series expansion of x →ex leads to
TCRB( f )|low SNR =
3N 2
0
π2u2T 2s N 3 .
We observe that the non-circularity power (induced by u) has a great impact at low SNR where the
performance is proportional to SNR2/u2.

2.02.2 Synchronization in Flat Fading Channel
45
•
CCRB derivations: As we deal with the (symbol rate) sampled signal y(n), the CCRB corresponds
to an under-determined estimation problem: we have N samples to estimate N + 2 parameters, and
no additional constraints. As a consequence, the CCRB is not ﬁnite. To overcome the problem, we
need to work with the oversampled version of the received signal. This is out of the scope of our toy
example. For more details, please refer to [77,90].
•
GCRB derivations: The expressions can be found in [86] and are reported below
GCRB( f ) = 3(1 −u2 + 4N0 + 4N 2
0 )
4π2u2T 2s N 3
(for N large enough).
Once again the non-circularity power (representing by u) has a great impact which veriﬁes that the
non-circularity property is an important tool in blind estimation of frequency and phase. We can
even show that when u ̸= 0 (and especially for u = 1, i.e., BPSK), the square-power estimate MSE
is identical to GCRB. Therefore, the square-power estimator for non-circular white multiplicative
noise is the best second order estimator.
If u = 0, sn is not (second-order) non-circular anymore. The second order statistics reduce to the
correlation ry(m) = rs(m)e2iπ f0Tsm + 2N0δ(m). If sn is white, we do not have information about f
and GCRB will go to inﬁnity. In contrast, if sn is colored, we can easily build an estimate as follows:
ˆfN = (∠ˆry(m)−∠(rs(m)))/m where ˆry(m) is the empirical estimate of ry(m) and rs(m) is known.
The frequency is thus viewed as the phase of the correlation function. GCRB is given by [80]
GCRB( f )|circular case =
1
N
 1
0

S′s(e2iπ f )
Ss(e2iπ f )+2N0
2
d f
(for N large enough),
where Ss(e2iπ f ) is the power spectrum of sn and S′
s(e2iπ f ) its derivative function. We note that
GCRB decreases as 1/N which is the convergence speed associated with the phase estimation
issue. So, clearly, to have faster convergence, we need to use high-order statistics of sn when it is
second-order circular.
•
MCRB derivations: We just have to average the FIM and it is the term given in Eq. (2.10).
MCRB( f ) =
3N0
π2T 3s N 3 .
The MCRB does not capture the inﬂuence of non-circularity; it is not tight enough and is too
optimistic except at high SNR.
Let us now assume that sn is an i.i.d. sequence drawn from a PSK or QAM constellation. GCRB and
MCRB are not modiﬁed at all although the process is no longer (second-order) non-circular. In contrast,
TCRB (at low SNR) is completely different and is given [83] by
TCRB|low SNR,Mth order non.circ = O(1/SNRM).
Once again, the non-circularity tool is fundamental for estimating the CFO and the phase. TCRB has
similar behavior as the MSE of the Mth power (if outlier effects are not taken into account) at low SNR.
In Figures 2.17–2.19, we plot various CRBs and empirical MSE of the Mth power estimate versus
SNR, N and u, respectively, for the process sn used in the toy example.

46
CHAPTER 2 Synchronization
−20
−15
−10
−5
0
5
10
15
20
10
12
10
10
10
8
10
6
10
4
10
2
10
0
Eb/N0
MSE
Various CRB and MSE of square−power estimate (u=1, N=100)
TCRB (high SNR)
TCRB (low SNR)
GCRB
MCRB
MSE of Square−Power Estimate
−20
−10
0
10
20
30
40
10
18
10
16
10
14
10
12
10
10
10
8
10
6
10
4
10
2
10
0
Eb/N0
MSE
Various CRB and MSE of square−power estimate (u=0 5, N=100)
TCRB (high SNR)
TCRB (low SNR)
GCRB
MCRB
MSE of Square−Power Estimate
FIGURE 2.17
Various CRBs and MSE versus Eb/N0 for u = 1 (left) and for u = 0.5 (right).
50
100
150
200
250
300
350
400
450
500
10
12
10
11
10
10
10
9
10
8
10
7
10
6
N
MSE
Various CRB and MSE of square−power estimate (E b/N0=10dB, u=1)
TCRB (high SNR)
TCRB (low SNR)
GCRB
MCRB
MSE of Square−Power Estimate
50
100
150
200
250
300
350
400
450
500
10
11
10
10
10
9
10
8
10
7
10
6
10
5
10
4
10
3
N
MSE
Various CRB and MSE of square−power estimate (E b/N0=10dB, u=0.5)
TCRB (high SNR)
TCRB (low SNR)
GCRB
MCRB
MSE of Square−Power Estimate
FIGURE 2.18
Various CRBs and MSE versus N for u = 1 (left) and for u = 0.5 (right).
2.02.2.2.5
Code-Aided synchronization
When the SNR is low, the NDA estimators may offer poor performance with realistic number of samples.
Until now, we have not exploited the usual structure of the data. Indeed, in order to obtain the targeted
BER in current systems, channel coding is used. There are two ways of using the channel structure to
improve the synchronization step:

2.02.2 Synchronization in Flat Fading Channel
47
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
10
12
10
10
10
8
10
6
10
4
10
2
10
0
u
MSE
Various CRB and MSE of square−power estimate (Eb/N0=10dB, N=200)
TCRB (high SNR)
TCRB (low SNR)
GCRB
MCRB
MSE of Square−Power Estimate
FIGURE 2.19
Various CRBs and MSE versus u (EB/N0 = 10 dB and N = 200).
•
DD with hard/soft decision: The hard decision has already been introduced in this tutorial when hard
decision was done after the channel decoding. Hard decision can be replaced with soft decision.
As soft decision is usually needed for iterative decoding, we can implement jointly the decoding of
turbo or LDPC and the synchronization which leads to the so-called turbo-synchronization concept.
More details will be given below.
•
LLR maximization: The performance of the system will be better if the sync parameters are well
chosen. Therefore, sync estimators relying on cost function depending on reliable functions can be
developed [91].
Here, we will focus on DD with soft decision. The use of soft decision is really interesting at low
SNR when synchronization is very difﬁcult. Usually, at low SNR, the channel coding requires the use
of turbo-codes or LDPC, namely, of iterative coding. Therefore the next synchronization way is usually
called “turbo-synchronization” developed by Vandendorpe-Luise, and others. A nice tutorial treatment
is given in [31]. Here, we brieﬂy provide the main points. For simplicity of exposition, we focus only
on phase estimation (assuming the other synchronization parameters are known).
Let ˆφ(n) be the phase estimator at the nth iteration. The EM algorithm has two basic steps:
E-Step : Q(φ, ˆφ(n)) =

p( ˜y|y, ˆφ(n)) log (p( ˜y|φ))d ˜y,
M-Step : ˆφ(n+1) = arg max
φ
Q(φ, ˆφ(n)),
where
•
˜y is the complete set of data.
•
y is the incomplete set of data.

48
CHAPTER 2 Synchronization
By considering the complete set of data as the received signal and the transmitted symbols, i.e.,
˜y = [y, sN], one can obtain that
Q(φ, ˆφ(n)) = ℜ
N−1

n=0
ˇsn, ˆφ(n)z(n)e−2iπφ

,
(2.23)
where
ˇsn, ˆφ(n) =
P−1

p=0
s(p) p(sn = s(p)|y, ˆφ(n)).
(2.24)
Thus, the M-step leads to the following solution:
ˆφ(n+1) = ∠
N−1

n=0
ˇsn, ˆφ(n)z(n)

.
We thus remark that the phase estimator is very similar to DA or DD estimator but now the symbol is
neither known, nor decided, but is replaced with the mean of the a posteriori distribution.
The previous EM approach can be considered with or without coding. The performance will just be
different because the a posteriori mean will be more or less accurate compared to the true transmitted
symbol (see [49] for non-coded case). In order to connect some previous results, let us consider the
non-coded BPSK case. We then have
ˇsn, ˆφ(n) = p(sn = 1|y, ˆφ(n)) −p(sn = −1|y, ˆφ(n)),
(2.25)
= tanh

1
2 log

p(sn = 1|y, ˆφ(n))
p(sn = −1|y, ˆφ(n))

,
(2.26)
= tanh
⎛
⎝
ℜ
"
z(n)e−2iπ ˆφ(n)#
N0
⎞
⎠.
(2.27)
Equation (2.26) corresponds to the LLR of the symbol, and Eq. (2.27) corresponds to the standard soft
decision on the BPSK symbol. We remark that the EM approach (which is strongly connected to ML)
leads “fortunately” to the equation of the true ML developed for the non-coded BPSK in Eq. (2.16)
even though the iteration does not mean the same thing. In the EM approach, we iterate inside a data
block, whereas in Eq. (2.16) we iterate at each ongoing sample. The non-coded BPSK based example
shows that there exists a strong link between EM and LLR. Nevertheless, this link cannot be extended
directly to coded system (whatever the constellation). For more details, we refer the reader to [31].
In terms of complexity, we need to compute Eq. (2.24). For (coded) BPSK, the BCJR algorithm can
be used. For other constellations, usually approximations are done [92,93]. Notice that we need the soft
decision directed approach only at low SNR when the constellation size is in practice small enough
which reduces the computational load for obtaining Eq. (2.24).

2.02.3 Synchronization for Non-Flat Fading Channels
49
Table 2.1 Some Algorithms Associated with Each Problem Statement
Problem
Algorithms
1 (DA phase and CFO estimation with perfect timing)
(2.9)
1’ (DA Timing estimation with perfect carrier recovery)
(2.3)
2 (NDA Phase and CFO estimation insensitive to timing)
(2.20, 2.21, 2.22)
2’ (NDA Timing estimation insensitive to phase and CFO)
(2.19) if M = {0}
2.02.2.2.6
Summary
In Table 2.1, we summarize the links between the various estimators that we have discussed and the
assumptions under which they work. We also indicate whether each of the problems (1,1’,2,2’) has a
solution.
2.02.3 Synchronization for non-ﬂat fading channels
When the channel is frequency-selective, the orthogonal frequency-division multiplexing (OFDM)
modulation scheme is the standard of choice. OFDM has been widely employed in various commercial
applications that include wireless local area networks (IEEE 802.11a/g/n and HIPERLAN/2), wire-
less metropolitan area networks (WMAN/WiMax, IEEE 802.16), terrestrial digital audio broadcasting
(DAB) and terrestrial digital video broadcasting (DVB) systems in Europe, Multimedia Mobile Access
Communications (MMAC) in Japan. The popularity of OFDM stems from its ability to transform a
wideband frequency-selective channel to a set of parallel ﬂat-fading narrowband channels, which sub-
stantially simpliﬁes the channel equalization problem. Because of the time-frequency granularity that it
offers, OFDM appears to be a natural solution when the available spectrum is not contiguous, for overlay
systems, and to cope with issues such as narrowband jamming. In the multiuser context, this granularity
also accommodates variable quality-of-service (QoS) requirements and bursty data. A noticeable exam-
ple of this multiuser application is the combination of OFDM with frequency-division multiple access
(FDMA) protocol, i.e., orthogonal frequency-division multiple access (OFDMA), which has become
part of the IEEE 802.16 standards for WMAN. Since subcarriers are allocated to distinct users in a
non-overlapping manner, one attractive feature of OFDMA is its capability to mitigate the effects of
multiple-accessinterference(MAI).AnotherappealingfeatureofOFDMAisdynamicsubcarrierassign-
ment which enables it to optimally allocate system resources such as transmission power and spectrum.
Despite the above-mentioned appealing features, the synchronization task turns out to be a critical
issue for OFDM based systems. The synchronization problems of OFDM based systems include timing
and frequency synchronization. Timing and frequency offsets come from two sources. One source
is the local oscillator frequency mismatch between the transmitter and the receiver, and the other is
the Doppler spread due to the relative motion between the transmitter and the receiver. Both timing
and frequency synchronization errors introduce extra interference to OFDM systems and result in
performance degradation. In addition, timing synchronization may affect the performance of channel

50
CHAPTER 2 Synchronization
estimation [94]. Therefore, effective synchronization is a key to improve the performance of an OFDM
based system [95].
2.02.3.1 Signal model and preliminaries
The operational principle of an OFDM system is that the available bandwidth is divided into a large
number of subchannels, over each of which the wireless channel can be considered non-dispersive or
ﬂat fading. The original data stream at rate R is split into N parallel data streams, each at rate R/N.
The symbol duration, Ts, for these parallel data streams is therefore increased by a factor of N, i.e.,
T = NTs as shown in Figure 2.20a. Conceptually, each of the data streams modulates a carrier with
a different frequency and the resulting signals are transmitted simultaneously. The carriers for each
subchannels are made orthogonal to one another, allowing them to be spaced very close together with
no overhead. This is shown in Figure 2.20b for four carriers. Correspondingly, the receiver consists of
N parallel receiver paths. Due to the increased symbol duration, the intersymbol interference (ISI) over
each channel is reduced to ⌈τmax/(NTs)⌉symbols. Thus, an advantage of OFDM is that, for frequency-
selective fading channels, the OFDM symbols are less affected by channel fades than are single-carrier
transmitted symbols. This is due to the increased symbol duration in an OFDM system. While many
symbols during a channel fade might be lost in a single-carrier system, the symbols of an OFDM
system can still be correctly detected since only a fraction of each symbol might be affected by the fade.
On the other hand, if the channel is time selective, i.e., the channel impulse response varies signiﬁcantly
within the OFDM symbol period, then the channel matrix is no longer Toeplitz and conventional OFDM
would fail.
Since multicarrier modulation is based on a block transmission scheme, measures have to be taken
to avoid or compensate for interblock interference (IBI), which contributes to the overall ISI. OFDM
systems can be categorized by the way they handle IBI. In the most popular systems, a guard time is
inserted between consecutive OFDM symbols in the form of a cyclic preﬁx (CP); i.e., the tail of the
OFDM symbol is preﬁxed as shown in Figure 2.20c. The length of the CP is chosen to be larger than the
expected delay spread; after proper time synchronization, the receiver discards the CP and thus the IBI
is eliminated. Time guarding by zero padding the OFDM symbols has also been proposed in [96,97].
The issue here is one of turning the transmitter on and off and increased receiver complexity versus the
increased signal-to-noise ratio (SNR) and decreased symbol error rate (SER). Comparisons between
cyclic-preﬁxing and zero-padding OFDM systems may be found in [98]. In this chapter, we focus on
CP based OFDM systems only.
The choice of the OFDM parameters is a trade-off between various, often conﬂicting requirements.
The length of the CP is dictated by the delay spread of the channel. Introduction of the CP entails
a reduction in rate (or wasted bandwidth), as well as an SNR loss; to minimize these inefﬁciencies,
the number of subcarriers, N, should be large. However, a large number of subcarriers induces high
implementation complexity, increased sensitivity to frequency offset and phase noise (since the sub-
carriers get closer to each other as N increases), and increased peak-to-average power ratios (PAPRs).
N is dictated by concerns regarding practical FFT sizes as well as the coherence time of the channel.
We will not address the issue of practical choice of OFDM parameters here; we refer the reader to [99]
and references therein. In this chapter, we address the crucial issue of timing and frequency offsets
estimation.

2.02.3 Synchronization for Non-Flat Fading Channels
51
sT
s
NT
1f
2f
3f
4f
(0) (1)
(
1)
i
i
i
g
x
x
x N
N
(
)
(
1)
i
g
i
x
x
N
N
N
(
)
( 1)
i
g
i
x
N
x
g
N
N
(a)
(b)
(c)
FIGURE 2.20
The operational principle of an OFDM system.
2.02.3.1.1
Subcarrier allocation strategies
Conventionally, all subcarriers are allocated to one speciﬁc user in single user OFDM systems. For
multiuser OFDM or OFDMA systems, subcarrier allocation strategies are needed. Let N and Ku denote
the total number of subcarriers and maximum number of active users, respectively. The current number
of users M is limited to Ku, i.e., M ≤Ku. Let Ii and Ii indicate the number and indices of subcarriers
allocated to the ith user, respectively; we have that
M

i=1
Ii ≤N,
(2.28)
Ii ∩I j = ∅,
i ̸= j.
(2.29)
As shown in Figure 2.21, generally, there are three subcarrier allocation schemes. For illustration
purposes, we set N = 32, M = 3, Ku = 4 and Ii = 8 in Figure 2.21. The subband carrier allocation

52
CHAPTER 2 Synchronization
(a)
(b)
(c)
FIGURE 2.21
Illustration of subcarrier allocation schemes.
scheme (CAS) is shown in Figure 2.21a. A group of Ii adjacent subcarriers is assigned to the ith
user in the subband CAS so that the signal of each user can be separated easily at the base station
(BS) through a ﬁlter bank. However, subband CAS prevents the possibility of optimally exploiting the
channel diversity. A deep fade might hit a substantial number of subcarriers of a given user if they are
close together [100]. To reserve some multipath diversity, interleaved CAS shown in Figure 2.21b can
be adopted for an uplink OFDMA system. The assigned subcarriers of the ith user are equi-spaced with
a distance Ku in interleaved CAS. More dynamic resource allocation and ﬂexibility can be achieved
by employing generalized CAS, where no strict association between subcarriers and users is required,
as illustrated in Figure 2.21c. However, generalized CAS will increase the synchronization complexity
signiﬁcantly as shown later.
2.02.3.1.2
OFDM transmission
The discrete-time block diagram of a standard downlink OFDMA transmission system is depicted in
Figure 2.22. According to the CAS employed, Ii data symbols for each user and N −M
i=1 Ii zeros are
assembled into one OFDM symbol as
X(k) =
 Xi(k), if k ∈Ii,
0,
otherwise.
(2.30)
After the inverse DFT modulation, each OFDM block is preceded by a CP whose duration is usually
longer than the delay spread of the propagation channel, so that IBI can be eliminated at the receiver

2.02.3 Synchronization for Non-Flat Fading Channels
53
( )
r n
ˆ
ˆ
( )
n
2
/
j
n N
e
1( )
X n
1
X
X
x
x
1
N
1
N
1
a
N
( )
M
X
n
M
X
FIGURE 2.22
Discrete-time complex baseband representation of downlink OFDMA transmission.
without affecting the orthogonality of the subcarriers. The time-domain samples after CP insertion can
be expressed as
˜x(n) =
 x(N + n), −Ng ≤n ≤−1,
x(n),
0 ≤n ≤N −1,
(2.31)
where x(n) =
1
√
N
N−1
k=0 X(k)e j2πnk/N. The (Na = N + Ng) samples of each block are then pulse
shaped, upconverted to the carrier frequency, and transmitted sequentially through the channel.
In this chapter, we model the frequency-selective channel as a ﬁnite impulse response (FIR) ﬁlter
with channel impulse response (CIR) h = [h(0), . . . , h(L −1)]T , where L is the channel order and
is determined by the maximum channel delay spread and data sampling rate. In practice, the system
is usually designed such that L ≤Ng ≤N. We assume that the CIR is time invariant over NT ≥1
consecutive symbol blocks, but could vary from one set of NT blocks to the next.

54
CHAPTER 2 Synchronization
At the receiver, the signal is downconverted to baseband and sampled at the rate of Na samples
per extended OFDM symbol. We will index these received samples by [−Ng, . . . , N −1]. Discarding
the samples with indices n = −Ng, . . . , −1 is known as discarding the cyclic preﬁx. In a perfectly
synchronized system, the received signal can be written as
r(n) =
L−1

l=0
h(l)˜x(n −l) + υ(n)
(2.32)
for n = 0, . . . , N −1; here υ(n) is complex-valued additive white Gaussian noise (AWGN) with
variance σ 2
υ. Recall that with the insertion of CP, collected samples {r(n)}N−1
n=0 can be expressed as
r = Hx + υ,
(2.33)
where H is an (N ×N) circulant matrix whose ﬁrst column is [h(0), h(1), . . . , h(L−1), 0, . . . , 0]T . The
circulant matrix H can be written as H
=
FHHF, where F is the DFT matrix with
[F]m,n =
1
√
N e−j2πmn/N and H = diag{H(0), H(1), . . . , H(N −1)} with
H(k) =
L−1

l=0
h(l)e−j2πkl/N.
(2.34)
Hence, after performing DFT, the output R can be expressed as
R = HX + ϒ,
(2.35)
where X = [X(0), . . . , X(N −1)]T and ϒ = [ϒ(0), . . . , ϒ(N −1)]T is again AWGN with covariance
matrix σ 2
υI. Since H is a diagonal matrix, Eq. (2.35) indicates that the effect of the frequency-selective
channel on the OFDM signal is completely captured by scalar multiplications of the data symbols by the
frequency responses of the channel at the subcarrier frequencies. Further, demodulation at the receiver
does not color the additive noise. If none of the channel zeros coincide with an activated subcarrier,
maximum likelihood detection of the symbols is straightforward. Zero-forcing and minimum mean
square error (MMSE) equalisers can also be applied on a per-carrier basis.
As we mentioned previously, the signal model (2.35) is only valid for an ideal timing and frequency
synchronized system. However, in practical systems, Doppler shifts and instable oscillators result in a
carrier frequency offset (CFO) f0 between the received carrier and the local sinusoids used for signal
demodulation. In addition, unknown transmission timing and propagation delay cause the DFT window
to be placed in a wrong position at the receiver. This results in a timing error, denoted by td, which
must properly be compensated to avoid severe performance degradation. Since fractional (normalized
to sampling period) timing offsets can be absorbed into the channel, it is a common practice to model
the timing offsets as a multiple of the sampling period. Letting ω (a real number) and τ denote the CFO
normalized to the subcarrier spacing and the integer part of the timing offset normalized to the sample
period, respectively, i.e., ω = N f0Ts and τ = ⌊td/Ts⌋, in the presence of timing and frequency offsets,
then Eq. (2.32) becomes
r(n) = e j2πωn/N
L−1

l=0
h(l)˜x(n −l −τ) + υ(n).
(2.36)

2.02.3 Synchronization for Non-Flat Fading Channels
55
1
L
g
N
IBI-free part
of the CP
Corrupted part
of the CP
data
data
(m)th block
(m-1)th block
CP
FIGURE 2.23
Illustration of the effect of multipath dispersion on CP.
For single timing and frequency offset, the timing and frequency offsets can be estimated and
corrected as shown in Figure 2.22. However, it is a tough task to estimate and compensate multiple
timing and frequency offsets. Next, we will review the effects of timing and frequency offsets on the
performance of OFDM systems.
2.02.3.1.3
Effects of timing errors on system performance
Due to the multipath dispersion, the tail of each received block extends over the ﬁrst L −1 samples of
the successive OFDM block as shown in Figure 2.23. By inserting a CP which consists of more than
L −1 samples, the interference from the previous OFDM block can be readily removed by properly
determining the starting point of the OFDM symbol. However, the inaccuracy of timing offset estimation
will cause performance degradation. To quantify the effect of timing errors on system performance, we
assume perfect frequency synchronization here, i.e., ω = 0.
Since the length of CP is (assumed to be) always larger than the maximum channel delay spread,
and using the time-shift property of the Fourier transform, we ﬁnd that the timing error τ = ˆτ −τ
within interval [−Ng + L −1, 0] only causes a linear phase rotation across the subcarriers as
R(k) = e j2πkτ/N H(k)X(k) + ϒ(k).
(2.37)
The effect of this timing error can be readily compensated by the channel equaliser. On the other hand,
if the timing error is outside interval [−Ng + L −1, 0], samples from adjacent OFDM blocks not only
cause IBI, but also result in a loss of orthogonality among subcarriers which generates inter-carrier
interference (ICI). A comprehensive mathematical analysis of the effects of timing errors is discussed
in [94,101]. In this case, the received signal after DFT can be written as
R(k) = αd
N (k)e j2πkτ/N H(k)X(k) + γ (k) + ϒ(k),
(2.38)
where
αd(k) =

(1 −e j2πkd/N)/(1 −e j2πk/N), k ̸= 0,
N −d,
k = 0,
(2.39)
d =
τ,
if τ > 0,
max{L −1 −(Ng + τ), 0},
if τ ≤0,
(2.40)

56
CHAPTER 2 Synchronization
and γ (k) is the combination of IBI and ICI which is deﬁned as in [101]. Following the same lines as
derived in [101], the signal-to-interference (SIR) in the presence of timing errors can be expressed as
SIR =
(N −d)2
d(2N −d) −2 N−d
σ 2
h β(d)
,
(2.41)
where σ 2
h =
L−1

l=0
σ 2
h(l) and
β(d) =
⎧
⎪⎪⎪⎨
⎪⎪⎪⎩
d−1

m=0
L−1

l=m+1
σ 2
h(l),
τ > 0,
d−1

m=0
Ng+τ+m−1

l=0
σ 2
h(l), τ ≤0.
(2.42)
Figure 2.24 shows the SIR versus timing error τ for N = 64. Both the exponential power delay
proﬁle, i.e., E
.
|h(l)|2/L−1
l=0 = C exp (−0.2l) where C is a scalar factor that ensures that the total energy
of the channel taps is normalized to unity, and the uniform power delay proﬁle, i.e., E
.
|h(l)|2/L−1
l=0 =
1/L proﬁle, have been tested. The length of the CP and CIR are set to 16 and 8, respectively, i.e.,
−30
−20
−10
0
10
20
30
−5
0
5
10
15
20
25
Timing error Δτ
SIR (in dB)
exponential power delay
uniform power delay
FIGURE 2.24
SIR versus timing error τ.

2.02.3 Synchronization for Non-Flat Fading Channels
57
Ng = 16 and L = 8. As discussed previously, the timing error within interval [−Ng + L −1, 0],
which is [−9, 0] for our simulation setup, will not cause ICI and IBI. The timing error outside the
interval [−9, 0] results in a signiﬁcant SIR loss, especially for positive timing errors. To keep the SIR
degradation within a tolerable level, accurate timing offset estimation is necessary.
2.02.3.1.4
Effects of carrier frequency offsets on system performance
As we mentioned in a previous section, CFO is caused by Doppler shifts and mismatched oscillators.
In general, the CFO can be several times the subchannel spacing. Thus, the CFO is usually divided into
an integer part and a fractional part by normalizing to the subcarrier spacing. Assuming perfect timing
synchronization and using the frequency-shift property of the Fourier transform, the received signal
under an integer valued CFO ω can be expressed as
R(k) = H

(k −ω)mod N

X

(k −ω)mod N

+ ϒ(k).
(2.43)
It can be seen from the above equation that the integer valued CFO causes a circular shift of the
transmitted symbols, but does not cause ICI; i.e., the orthogonality of the subcarriers is maintained. The
fractional part, however, causes ICI. Assuming that CFO ω is a fractional value, the received signal can
be written as
R(k) =
N−1

n=0
H(n)X(n) f (ω + n −k) + ϒ(k),
(2.44)
where
f (n) =
sin (πn)
N sin (πn/N)e jπn(N−1)/N.
(2.45)
Equation (2.44) can be re-written as
R(k) = H(k)X(k) f (ω) + γ (k) + ϒ(k),
(2.46)
where γ (k) = N−1
n=0̸=k H(n)X(n) f (ω + n −k) is the zero-mean ICI term with power σ 2
γ (ω).
After some manipulations as shown in [102], we have
σ 2
γ (ω) = σ 2
x (1 −| f (ω)|2).
Thus, the SIR can be expressed as
SIR =
| f (ω)|2
1 −| f (ω)|2 .
(2.47)
The SIR versus CFO ω for N = 64 is shown in Figure 2.25. Notice that the SIR decreases rapidly as
the CFO is increased. Again, to keep the SIR degradation to a tolerable level, effective CFO estimation
and compensation methods are required. More precise techniques for computing the SNR loss due to
CFO can be found in [103].
2.02.3.2 Downlink OFDMA
As shown in Figure 2.26, the BS broadcasts training sequences followed by data blocks to the potential
users and each user operates independently in downlink OFDMA transmission. Thus, the synchro-
nization problem in downlink OFDMA is similar to that of single-user OFDM systems. Generally,

58
CHAPTER 2 Synchronization
0
0.1
0.2
0.3
0.4
0.5
−5
0
5
10
15
20
25
30
35
ω
SIR (in dB)
FIGURE 2.25
SIR versus fractional carrier frequency offset ω.
synchronization can be divided into a coarse acquisition phase and a ﬁne tracking phase. In this
section, we provide a brief survey of existing synchronization techniques in the downlink OFDMA
scenario.
2.02.3.2.1
Coarse synchronization methods
The coarse synchronization task typically has two sub-tasks, i.e., ﬁnding the start of an OFDM frame
over an approximate range of sample values and aligning the local oscillator of the receiver to the
received carrier frequency. Coarse timing acquisition is usually the ﬁrst task performed in the synchro-
nization procedure. In practice, the CFO is assumed to be completely unknown at this stage. Hence, the
orthogonality of the subcarriers may not be retained to provide a useful post-FFT signal. Consequently,
coarse timing acquisition is obtained in the time domain. In coarse frequency synchronization, the usual
approach is to decompose the CFO into a fractional part plus an integer part. Pre-FFT or post-FFT
methods may be adopted to estimate the CFO.
Depending on the system requirements, coarse timing and frequency acquisition can be carried
out by exploiting either the repeated cyclic preﬁx [104–106] or specially designed training sequences
(preambles) [107–110]. Exploiting the correlation of CP, CP-based algorithms can work blindly without
the overhead of an explicit training sequence. However, as standardized in many commercial systems,
reliable coarse acquisition methods for frequency-selective channels are based on a training sequence
with a repetitive structure. The motivation behind this idea is that the repetitive property is preserved

2.02.3 Synchronization for Non-Flat Fading Channels
59
FIGURE 2.26
Downlink OFDMA representation.
after propagation through a multipath channel, except for a phase rotation due to the CFO. In this
chapter, we consider training-sequence based synchronization in the following.
Second-order statistics based methods
There are basically two methods for training-sequence based coarse synchronization, i.e., ﬁrst-order
statistics based and second-order statistics based methods. The latter class was ﬁrst proposed by Moose
in [111] and further studied by Schmidl and Cox (S&C) in [107], where two identical slots with length
of N/2 were used in the ﬁrst training symbol as shown in Figure 2.27. The CFO normalized to the
subcarrier spacing is decomposed into two parts as
ω = ν + 2ε,
(2.48)
where ν ∈(−1, 1] and ε is an integer. To generate the repetitive-structure of the ﬁrst training symbol,
we can simply transmit a pseudonoise (PN) sequence on the even subcarriers, while zeros are used
on the odd subcarriers. For the second training symbol, a PN sequence PN1 is transmitted on the odd
subcarriers which may be employed in channel estimation; and a differentially-modulated PN sequence
PN2 deployed on the even subcarriers is used for the integer CFO estimation. Let {r(n)}N−1
n=0 denote the

60
CHAPTER 2 Synchronization
CP
PN1 and PN2 sequences
CP
first half
second half
first training symbol
second training symbol
estimation of  timing offset
and fractional CFO part
estimation of integer CFO part
FIGURE 2.27
Training symbols of S&C algorithm.
received signals, we have
r(n) = z(n) + υ(n),
(2.49)
where
z(n) = e j2πωn/N
L−1

l=0
h(l)x(n −τ −l),
(2.50)
x(n) =
1
√
N
N/2−1

k=0
X(2k)e−j4πkn/N,
(2.51)
where τ, an integer, is the normalized nonfractional part of the timing offset, ω is the CFO normalized
to the subcarrier spacing, x(n) and X(k) are respectively the transmitted time domain and frequency
domain training sequences, h(l) is the lth tap of the CIR and υ(n) is an AWGN with variance σ 2
υ. It can
be easily veriﬁed that the ﬁrst and second halves of the received signal can be expressed as
r(n) = z(n) + υ(n),
τ ≤n ≤τ + N
2 −1,
(2.52)
r

n + N
2

= e jπνz(n) + υ

n + N
2

,
τ ≤n ≤τ + N
2 −1.
(2.53)
Exploiting the correlation between ﬁrst and second halves, the S&C timing estimator can be expressed as
ˆτ = arg max
˜τ
(˜τ),
(2.54)
where
(˜τ) =

˜τ+N/2−1

n=˜τ
r∗(n)r

n + N
2


2

˜τ+N/2−1

n=˜τ
|r

n + N
2

|2
2 .
Moreover, assuming perfect timing synchronization, the estimate of fractional part CFO ν can be
obtained as
ˆν = 1
π arg
⎧
⎨
⎩
τ+N/2−1

n=τ
r∗(n)r

n + N
2
⎫
⎬
⎭.
(2.55)

2.02.3 Synchronization for Non-Flat Fading Channels
61
In practice, the timing offset τ in Eq. (2.55) can be replaced by its estimated value ˆτ given in eq. (2.54).
If the normalized CFO can be guaranteed to be less than 1, the second training symbol would not be
needed. Otherwise, the second training symbol and a post-FFT method can be adopted to estimate the
integer part of the CFO, ε, as we describe next.
After compensating the fractional offset by multiplying the two training symbols by e−j2π ˆνn/N, the
FFT output of two training symbols, denoted as R1(k) and R2(k), can be expressed as
R1(k) = Z1(k) + W1(k)
(2.56)
R2(k) = Z2(k) + W2(k)
(2.57)
for k = 0, . . . , N −1 and
Z1(k) = H((k −2ε)mod N)X1((k −2ε)mod N)
(2.58)
Z2(k) = e jφ H((k −2ε)mod N)X2((k −2ε)mod N),
(2.59)
where φ = 4πε(N + Ng)/N. Let d(k) = X2(k)
X1(k) represent the differentially-modulated PN sequence on
the even subcarriers of the second training symbol, we have
Z2(k) = e jφd((k −2ε)mod N)Z1(k)
(2.60)
for even k. Thus, the estimator of the integer part of the CFO, ε, can be expressed as
ˆε = arg max
˜ε
(˜ε),
(2.61)
where
(˜ε) =

k even R∗
1(k)d∗((k −2˜ε)mod N)R2(k)
2
2

k even |R2(k)|22
,
(2.62)
and integer ˜ε varies over the range of possible frequency offsets. Then, the frequency offset estimate
would be ˆω = ˆν + 2ˆε.
The S&C timing estimator (2.54) is expected to capture a peak when the correlation window
is perfectly aligned with the received training sequence. Unfortunately, as shown in Figure 2.28,
the timing metric of the S&C estimator exhibits a “plateau” which reduces the acquisition accu-
racy signiﬁcantly. To obtain a steeper timing metric trajectory, many training patterns were proposed
in [108,109]. In [109], a training of the form [B, B, −B, B] in time domain was proposed by Shi
and Serpedin (S&S). Arranging the received N samples [r(˜τ) · · ·r(˜τ + N −1)]T into four parts as
{ri(˜τ) = [r(i N/4 + ˜τ) · · ·r((i + 1)N/4 + ˜τ −1)]T }3
i=0, the S&S timing estimator can be expressed as
ˆτ = arg max
˜τ
(˜τ),
(2.63)
where
(˜τ) =
2
i=0 |Pi(˜τ)|
3
2
3
i=0 ∥ri(˜τ)∥2 ,

62
CHAPTER 2 Synchronization
−150
−100
−50
0
50
100
150
0
0.2
0.4
0.6
0.8
1
Δτ
Timing metic of S&C
−150
−100
−50
0
50
100
150
0
0.2
0.4
0.6
0.8
1
Δτ
Timing metic of S&S
FIGURE 2.28
Timing metrics for S&C and S&S estimators, N = 128, Ng = 16, L = 16, SNR=20 dB.
and
P0(˜τ) = r H
0 (˜τ)r1(˜τ) −r H
1 (˜τ)r2(˜τ) −r H
2 (˜τ)r3(˜τ),
P1(˜τ) = r H
1 (˜τ)r3(˜τ) −r H
0 (˜τ)r2(˜τ),
P2(˜τ) = r H
0 (˜τ)r3(˜τ).
Since the training symbol is divided into four parts, we ﬁnd that the CFO causes a phase shift of πω/2
in each part for a ﬂat fading channel. Thus, the CFO estimator of S&S algorithm for practical systems
can be expressed as
ˆω = 2
π arg
.
P0(ˆτ)
/
.
(2.64)
Compared to the S&C CFO estimator (2.55), we can see that the acquisition range of (2.64) increased
to [−2, 2).
BothtimingmetricsoftheS&CandS&Stimingestimators,(˜τ),areillustratedinFigure2.28,where
τ = ˜τ −τ. The results are obtained under the exponential power delay proﬁle channel introduced
previously and the SNR is deﬁned as σ 2
x /σ 2
υ. We can see that the “plateau” present in the S&C estimator
is signiﬁcantly reduced in the S&S estimator. As pointed out in [108], a steeper timing metric trajectory
can be obtained by increasing the number of repetitive slots.

2.02.3 Synchronization for Non-Flat Fading Channels
63
Although the correlation method adopted in S&C and S&S estimators has low computational com-
plexity, those estimators will exhibit a ﬂoor effect since they are still based on second-order statistics
of the received signal. As shown in [112], much more accurate timing and frequency estimation can
be achieved by using the ﬁrst-order statistics, at the expense of a slight increase in implementation
complexity.
First-order statistics based methods
Using the signal model (2.49), the mean of the received signal is given by
E {r(n)} = e j2πωn/N
L−1

l=0
h(l)x(n −τ −l), n = τ −Ng, . . . , τ + N + L −1.
(2.65)
Let r ˜τ
=
[r(˜τ), . . . ,r(˜τ + N −1)]T
and E {r ˜τ}
≜
μ
=
(ω)Xh, where (ω)
=
diag{1, . . . , e j2πω(N−1)/N}. X is a circulant matrix whose ﬁrst column is x.
The variance of the received signal is
var {r(n)} =
σ 2
υ,
n = 0, . . . , τ + N −1,
> σ 2
υ, n > τ + N −1.
(2.66)
Thus, the variance of the received signal is minimum during the noise-only period, which precedes
reception of the frame, and during the reception of the training block. During data reception, it is
equal to σ 2
υ + ∥h∥2, where we assume that data symbols have unit power, without loss of generality.
Figure 2.29 illustrates these observation. If μ were known, τ could be estimated by minimizing the
Euclidean distance between r ˜τ and μ over ˜τ. Since this is not the case and in order to avoid the noise-
only period, Ghogho and Swami [112] proposed two estimators which are obtained by minimizing the
following modiﬁed versions of the nonlinear least-squares (NLLS) criterion:
C1(˜τ, ˜ω, ˜h) = ∥r ˜τ −˜μ∥2
∥r ˜τ∥2
(2.67)
and
C2(˜τ, ˜ω, ˜h) = ∥r ˜τ −˜μ∥2 −∥r ˜τ∥2
(2.68)
over ˜τ, ˜ω and ˜h, where ˜μ is obtained as in μ after replacing h and ω by ˜h and ˜ω, respectively.
Both the normalization factor in (2.67) and the second term of the RHS of (2.68) guarantee the
uniqueness of the solution, i.e., avoid the noise-only (i.e., ˜h = 0) solution. Indeed, in the noise-only
period, the minima of E {C1} and E {C2}, which are obtained with ˜h = 0, are (approximately) one
and zero, respectively. During data reception, the minima of E {C1} and E {C2} are again obtained
with ˜h = 0 and are also approximately equal to one and zero, respectively. During the reception of the
training sequence, the minima of the E {C1} and E {C2} are (approximately) 1/(1 + SNR) and −∥h∥2,
respectively, where SNR is deﬁned as SNR = ∥rτ∥2/(Nσ 2
υ). These minima are smaller than those
obtained in the noise-only and data transmission periods. Hence, when the processed signal contains
the received preamble, the minima of E {C1} and E {C2} are achieved if and only if ˜τ = τ and ˜μ = μ.
Figure 2.29 illustrates some of these results.

64
CHAPTER 2 Synchronization
0
g
N
N
g
N
N
2
2
2
h
FIGURE 2.29
Real part of one realization of the received signal as well as the corresponding instantaneous mean and
variance.
Since the statistical expectation of C1 and C2 are unknown, only estimates of the unknown parameters
can be obtained by minimizing C1 and C2 themselves. The obtained estimators were referred to as
modiﬁed nonlinear least squares estimators (MNLLS) in [112], since they combine the NLLS estimation
method and detection. The above optimization problems can be simpliﬁed by noting that C1 and C2 are
quadratic in ˜h. Thus, closed-form expressions for ˆh1 and ˆh2 can be obtained as
ˆhi = X†H( ˆωi)r ˆτi ,
i = 1, 2.
(2.69)
Substituting the above estimates for ˜h in C1 and C2, the equivalent criterion is to maximize
C′′
i (˜τ, ˜ω) = gi(˜τ)r H
˜τ ( ˜ω)XH( ˜ω)r ˜τ,
i = 1, 2,
(2.70)
where g1(˜τ) = ∥r ˜τ∥−2 and g2(˜τ) = 1, and X = X(XHX)−1XH, which is a ﬁxed matrix and can thus
be precomputed and stored at the receiver.
The above optimization problems are two-dimensional. Although they are discrete in one dimension,
they are still computationally challenging to solve. To reduce the computational complexity, timing
acquisition using C′′
i is performed by ignoring the CFO-related terms. It was shown that a coarse but
closed-form estimate of the CFO for each timing offset candidate is good enough to (nearly) obtain ˆτ1
and ˆτ2. To obtain the CFO estimate, the repetitive structure of the training block and the second-order
statistic-based method in [107] were adopted to estimate the fractional part of ω, i.e., ν. The estimate
of the integer part of ω, ˆε and timing offset ˆτi are given by
{ˆτi, ˆεi} = arg max
˜τ,˜ε
gi(˜τ)r H
˜τ (˜ε + ˜ν)XH(˜ε + ˜ν)r ˜τ,
(2.71)

2.02.3 Synchronization for Non-Flat Fading Channels
65
where candidate values for ˜ε are in (−Q + 1, Q −1), and ˜ν is given by [107]
˜ν = 1
π arg
⎧
⎨
⎩
˜τ+N/2−1

n=˜τ
r∗(n)r(n + N/2)
⎫
⎬
⎭.
(2.72)
Although the optimization problem (2.71) is two-dimensional, it is discrete and the possible values of
ε dictated by Q may be small in practice. It is worth pointing out that the optimization problems can
be reduced to one-dimensional problems if the preamble is made of Q repetitive slots, since in this
case, a closed-form estimate of ω can be obtained (see [113,114]). However, the performance of timing
acquisition in this case becomes similar to that of existing methods, unless N ≫2Q(L + 1).
Once τ and ε are estimated, estimates of ω are obtained as ˆωi = ˆν + ˆε, where ˆν is given by
(2.72) with ˜τ = ˆτ. A more accurate estimate can be obtained by maximizing C′′
i (ˆτ, ˜ω) over ˜ω after
initialising with ˆωi. Since this results in the optimization of a continuous-valued variable, ω, it may
not be appropriate in practice, especially for the downlink. Moreover, simulations have shown that the
performance improvement is not signiﬁcant.
Finally, as a product of the above synchronization method, estimates of the channel can be obtained
from (2.69) after replacing τ and ω by the above estimates.
To further reduce the complexity of the computation of the cost functions C′′
i , the projection matrix
X can be replaced by (1/N)XXH obtained by approximating XHX by NI, since N/2 > L + 1, and
using the law of large numbers. Using this, C′′
2 is obtained as the squared L2-norm of a vector and C′′
1
is its normalized version, and the corresponding estimates of τi and εi are given by
{ˇτi, ˇεi} =
arg max
˜τ,˜ε∈(−Q/2,Q/2)
N −1gi(˜τ)
|XHH(˜ν + ˜ε)r ˜τ
|2.
(2.73)
Note that the computation of XH y requires only changing the sign of some of the elements of the vector
y and additions. Also, note that the computation of the simpliﬁed version of C′′
2 is simpler than that of
C′′
1 since in the former, ∥r ˜τ∥2 needs to be computed. However, the normalization in C′′
1 is desirable for
reducing the complexity of the search procedure for real-time implementation.
2.02.3.2.2
Fine synchronization methods
In certain applications, due to unstable oscillators or high-mobility environment, the coarse estimates
may be inadequate for the entire frame. Thus, timing and frequency tracking are required to compensate
the short-term variations produced by oscillator drifts and/or time-varying Doppler shifts.
Fine timing synchronization can be achieved through correlation either in the time domain [115,116]
or in the frequency domain [117–120]. A timing tracking scheme based on time-domain PN-sequence
correlation and a weighted time correlation scheme exploiting the redundancy in both the cyclic preﬁx
and available pilot symbols were shown to provide better performance than repetitive-structured OFDM
symbols in [115,116], respectively. Frequency-domain based schemes model the timing error as part of
the CIR vector. This is motivated by the fact that the estimated CIR shifts cyclicly with respect to the
FFT-window. Since the frequency-domain based schemes can resolve channel multipaths effectively,
they generally provide better performance than the time-domain schemes in multipath fading channels.
There are several approaches to update the coarse timing estimate in frequency-domain based tracking

66
CHAPTER 2 Synchronization
algorithms. One method is to locate the peak position of the estimated CIR ˆh [118]. Many modiﬁed
peak-ﬁnding versions were studied in [108], to take into account both the effects of noise, as well as
the fact that the ﬁrst peak may not be the largest peak in the CIR. Another method which maximizes
the energy window of the channel estimation has been investigated in [105,117]. Exploiting the timing
information embedded in pilot-aided channel estimation, timing can be estimated without a speciﬁc
training sequence, as was shown in [121,122].
Similar to ﬁne timing synchronization, frequency tracking can be performed either in the time domain
[104,123] or in the frequency domain [124,125]. In [104,123], the correlation between the CP and the
last Nc samples of each block is exploited to estimate the residual frequency offset. The residual CFO
was tracked using the temporal correlation in the data-aided post-FFT stage and the frequency domain
channel estimate was adopted to deduce the weights for a weighted-least-squares CFO estimator in
[124,125], respectively. Several blind CFO estimation methods, e.g., [126–136], also can be employed
during the tracking step without increasing synchronization overhead.
2.02.3.2.3
Simulation results for downlink OFDMA systems
We consider an downlink OFDMA system with a total of N = 128 subcarriers. In the simulation,
we assume that the CIR length is L = 16, and a cyclic preﬁx of length Ng = 16. The channel
taps h(l) are uncorrelated zero-mean Gaussian random variables with exponential power delay proﬁle
E
.
|h(l)|2/L−1
l=0 = C exp (−0.2l), where C is a scalar factor that ensures that the total energy of the
0
5
10
15
20
25
30
10
−2
10
−1
10
0
10
1
10
2
SNR in dB
STD of timing estimates
S&C
S&S
MNLLS1
Simplified MNLLS1
MNLLS2
Simplified MNLLS2
FIGURE 2.30
Standard deviation of timing estimates for downlink OFDMA.

2.02.3 Synchronization for Non-Flat Fading Channels
67
channel taps is normalized to unity. Correspondingly, the SNR of received signal is equal to σ 2
x /σ 2
υ,
where σ 2
x is the power allocated to each subcarrier. Since only the fractional part of the CFO can be
estimated by the S&S algorithm in [109], we generate ω randomly from the interval [−0.5, 0.5] and
generate a new random channel for each Monte Carlo run. Moreover, as the integer part of the CFO
is zero, the second training symbol shown in Figure 2.27 is unnecessary and we set Q = 1 for the
ﬁrst-order statistics based methods.
The results of timing and frequency estimates are calculated using 20,000 Monte Carlo runs.
Figures 2.30–2.32 show that the ﬁrst-order statistics based methods signiﬁcantly outperform the second-
order statistics based methods in terms of timing and CFO estimation. For timing estimation, MNLLS1
outperforms MNLLS2. The simpliﬁed MNLLS algorithms yield the same timing estimation perfor-
mance. In Figure 2.31, the probability of exact timing refers to the probability that the associated
algorithm identiﬁes τ without error. For comparison, in Figure 2.32, we also show the Cramér-Rao
bound (CRB) for the case where timing is perfect. Using the method in [137], the CRB is found to be
var
.
ˆω
/
≥CRB( ˆω) =
2σ 2
υ
Nπ2σ 2x
.
(2.74)
Notice that the performance of ﬁrst-order statistics based methods is close to CRB. The simpliﬁed
MNLLS methods have the same CFO estimation performance merits as the MNLLS methods. From
the simulation results, we can see that the S&S algorithm achieves more accurate timing estimation
0
5
10
15
20
25
30
10
−2
10
−1
10
0
SNR in dB
Probability of exact timing
S&C
S&S
MNLLS1
Simplified MNLLS1
MNLLS2
Simplified MNLLS2
FIGURE 2.31
Probability of exact timing acquisition for downlink OFDMA.

68
CHAPTER 2 Synchronization
0
5
10
15
20
25
30
10
−6
10
−5
10
−4
10
−3
10
−2
10
−1
SNR in dB
MSE of CFO estimates
S&C
S&S
MNLLS1
Simplified MNLLS1
MNLLS2
Simplified MNLLS2
CRB
FIGURE 2.32
Mean square error of CFO estimates for downlink OFDMA.
performance than the S&C algorithm at the price of a decrease in the CFO estimation performance. As
we discussed previously, the gains of ﬁrst-order statistics based methods come along with the increasing
complexity. For real-time implementation, it is important to set a threshold on the synchronization crite-
rion so that complexity can be reduced by pruning the set of timing candidates. Details of implementation
issues of ﬁrst-order statistics based methods can be found in [112].
2.02.4 Multiuser synchronization
2.02.4.1 Uplink signal model and synchronization policy
We consider an uplink OFDMA system where M active users simultaneously communicate with the BS
as shown in Figure 2.33. The users’ data streams are assembled into OFDM symbols according to the
CAS employed.
Let r(n) denote the signal received at the BS; we have that
r(n) =
M

i=1
z(i)(n) + υ(n),
(2.75)

2.02.4 Multiuser Synchronization
69
FIGURE 2.33
OFDMA uplink representation.
where z(i)(n) is the signal transmitted from the ith user and can be expressed as
z(i)(n) = e j2πωin/N
L−1

l=0
hi(l)xi(n −l −τi),
(2.76)
and
xi(n) =
1
√
N

k∈I⟩
X(k)e−j2πkn/N.
(2.77)
It can be seen from Eq. (2.75) that the received signal at BS is the combination of the signal from all
active users. Thus, the uplink synchronization is a multi-parameter estimation procedure. To guarantee
that the residual synchronization errors of the uplink transmission are much smaller than that of a
completely asynchronous system, before uplink transmission, an initial synchronization is performed
during downlink procedure. The timing offsets among users in the uplink are mainly due to different
propagation distances between users and BS. The frequency offsets between users and BS are caused
by the Doppler spread and/or the instability of local oscillators. Generally, after the synchronization
performed via downlink transmission, the CFO can be guaranteed to be in a small range. In this chapter,
we assume the frequency offset is smaller than half the subcarrier spacing.
To combat the residual synchronization errors simply and directly, a method based on downlink
control channel is suggested in [100,138], where the synchronization parameters are estimated at the
BS and adjustment is performed at the user side based on the information derived from feedback channel.

70
CHAPTER 2 Synchronization
A similar idea is adopted in IEEE 802.16e [139] standard to accomplish the synchronization task. By
using interference cancelation or multiuser detection algorithms, e.g., [140–143] and references therein,
the effects or multiple frequency offsets also can be mitigated at the BS at the price of increased receiver
complexity. In this chapter, we focus only on the estimation of the timing and frequency offsets at the
BS. Depending on the CAS employed, the synchronization task in uplink OFDMA can be categorized
into three cases as explained next.
2.02.4.2 Synchronization with subband CAS
The ML estimation of timing and frequency offsets for subband CAS uplink OFDMA was ﬁrst studied
in [138], where the users’ signals are separated by a bank of band-pass ﬁlters at BS as shown in
Figure 2.34. After signal separation, the timing and frequency offsets can be estimated independently
for each active user, which is similar to the downlink OFDMA case. Since perfect signal separation is
impractical, the ﬁltered ith subband signal r(i)(n) can be written as
r(i)(n) = z(i)(n) + (i)(n) + υ(i)(n),
(2.78)
where the (i)(n) and υ(i)(n) denote the inter-carrier interference due to imperfect separation and noise
corresponding to ith subband signal. Possible ways of reducing the interference term (i)(n) include
the adoption of higher order band-pass ﬁlters or increasing the number of guard carriers used between
adjacent frequency bands. The timing and frequency offsets estimators in [138] exploit the redundancy
of CP; the estimates for the ith user can be expressed as:
ˆτi = arg max
˜τi
{i(˜τi) −ρiCi(˜τi)} ,
(2.79)
ˆωi = 1
2π arg
.
i(ˆτi)
/
,
(2.80)
( )
r n
(1)( )
r
n
(2)( )
r
n
(
)( )
M
r
n
1
1ˆ
ˆ ,
2
2ˆ
ˆ ,
ˆ
ˆ ,
M
M
FIGURE 2.34
Timing and frequency offsets estimation for subband CAS uplink OFDMA.

2.02.4 Multiuser Synchronization
71
where
i

˜τi

=
˜τi−1

n=˜τi−Ng
r∗
(i)(n)r(i)(n + N),
(2.81)
Ci(˜τi) = 1
2
˜τi−1

n=˜τi−Ng

|r(i)(n)|2 + |r(i)(n + N)|2
,
(2.82)
and ρi = σ 2
x /(σ 2
x + σ 2
υ). The estimates in (2.79) and (2.80) are one-shot estimators in the sense that
the estimates are based on the observation of a single OFDM symbol. More accurate estimates can be
obtained by averaging the cost function over Q successive OFDM blocks as
ˆτi = arg max
˜τi
⎧
⎨
⎩
Q−1

q=0

i

˜τi + q(N + Ng)

−ρiCi

˜τi + q

N + Ng

⎫
⎬
⎭,
(2.83)
ˆωi = 1
2π arg
⎧
⎨
⎩
Q−1

q=0
i

ˆτi + q

N + Ng

⎫
⎬
⎭.
(2.84)
An alternative blind scheme to obtain estimates of timing and frequency offsets for subband CAS
can be found in [144]. As pointed out in [145], the subband CAS offers the possibility of separating
signals from different users through a simple ﬁlter bank even in a completely asynchronous scenario
with arbitrarily large timing errors. Synchronization algorithms for the downlink OFDMA can be easily
extended to subband-based OFDMA systems. On the other hand, grouping subcarriers together makes
systems vulnerable to frequency-selective fading. The adoption of an interleaved CAS can provide
users with some form of frequency diversity at the expense of slightly increasing the complexity of
synchronization.
2.02.4.3 Synchronization with interleaved CAS
Interleavedsubcarrierallocationminimizesthedistancesbetweensubcarriersassignedtodifferentusers;
hence, in the presence of frequency synchronization errors, signals from different users will overlap
in the time domain and interfere with each other in the frequency domain due to loss of orthogonality
[146]. Thus, it is a challenging task to separate the multiple user signals compared to the subband CAS.
However, advanced signal-processing algorithms, e.g., subspace decomposition based methods, can be
employed to reduce the synchronization complexity of interleaved systems.
Subspace-based CFO estimation algorithms are studied in [146] and later in [147,148] for the uplink
OFDMA systems; the key is to exploit the periodic structure of the interleaved transmission. generalized
subspace-based CFO estimation also have been studied by [114,127,130,132] for single user OFDM
systems. Let Ii = {ηi + pKu}P−1
p=0 denote the indices set of the subcarriers allocated to ith user, where
ηi is an integer in the interval [0, Ku−1] and ηi ̸= η j if i ̸= j, Ku is the maximum number of users
and P = N/Ku. We assume that the total number of subcarriers N is an integer multiple of Ku in this

72
CHAPTER 2 Synchronization
chapter. The signal from ith user, given in Eq. (2.76), can be re-written as
z(i)(n) = αe j2π(ωi+ηi)n/N
P−1

p=0
Hi(ηi + pKu)Xi(ηi + pKu)e j2π p(n−τi)/P
(2.85)
for n = 0, . . . , N −1 and α = e−j2πηiτi/N. It can be found readily that
z(i)(n + μP) = e jμθi z(i)(n)
(2.86)
for n = 0, . . . , P −1, μ = 0, . . . , Ku −1 and θi = 2π(ωi + ηi)/Ku. From Eq. (2.75), we get
(n + μP) =
M

i=1
e jμθi z(i)(n) + υ(n + μP)
n = 0, . . . , P −1, μ = 0, . . . , Ku −1.
(2.87)
We arrange the {r(n)}N−1
n=0 samples into a Ku × P matrix
R =
⎡
⎢⎢⎢⎣
r(0)
· · ·
r(P −1)
r(P)
· · ·
r(2P −1)
...
...
...
r((Ku −1)P)
· · ·
r(N −1)
⎤
⎥⎥⎥⎦
Ku×P
.
(2.88)
Letting Rp denote the pth column of matrix R, we have that
Rp = Gz p + υp,
p = 0, . . . , P −1,
(2.89)
where z p =
3
z(1)(p)z(2)(p) · · · z(M)(p)
4T and G is a (Ku × M) matrix given by
G =
⎡
⎢⎢⎢⎣
1
1
· · ·
1
e jθ1
e jθ2
· · ·
e jθM
...
...
...
...
e j(Ku−1)θ1
e j(Ku−1)θ2
· · · e j(Ku−1)θM
⎤
⎥⎥⎥⎦
Ku×M
.
Once we express the received samples as in Eq. (2.87), CFO estimation can be carried out using a
signal subspace decomposition approach. The dimension of the null subspace is dictated by the number
of null subcarriers, which is equal to (Ku −M)P. The main idea behind the low-complexity CFO
estimation algorithms studied in [146–148] is to estimate the θis, which are distinct from each other if
|ωi| < 0.5. Indeed, the θis in Eq. (2.87) cause phase shifts to identical P-sample long segments. Hence,
the subspace approach can in a way be seen as an extension of the repetitive-slot CFO estimation
approach (see e.g., [110,113]) to the case of multiple CFO estimation. Employing the estimation of
signal parameters via rotational invariance technique (ESPRIT) algorithm, the multiple CFOs can be
estimated using the following steps:

2.02.4 Multiuser Synchronization
73
Step 1.
Arrange the received signal {r(n)}N−1
n=0 into matrix R.
Step 2. The covariance matrix  = E
"
Rp RH
p
#
of Rp is estimated by
5 = 1
P RRH.
Step 3. Compute singular value decomposition (SVD) of 5:
5 =
3
UsUz
4 s 0
0 z
 
UH
s
UH
z

,
(2.90)
where Us is a Ku × M matrix composed of M eigenvectors corresponding to the M largest
eigenvalues λ1 ≥λ2 ≥· · · ≥λM and Uz is a Ku × (Ku −M) matrix composed of Ku −M
eigenvectors corresponding to the rest eigenvalues λM+1 ≥· · · ≥λKu.
Step 4. Let Us1 denote the ﬁrst (Ku −1) rows of Us and Us2 denote the last (Ku −1) rows of Us. The
θis are estimated as
ˆθi = ∠(βi),
(2.91)
where ∠(·) denotes the angle of the complex number and {βi}M−1
i=0 are the eigenvalues of
 =

UH
s1Us1
−1
UH
s1Us2.
Step 5. After estimating the ˆθi,s, the estimate of CFO ωi can be computed as
ˆωi = Ku ˆθi
2π
−ηi,
i = 1, . . . , M.
(2.92)
Another subspace-based method, the spectral multiple signal classiﬁcation (MUSIC) algorithm can also
be applied to estimate the multiple CFOs by replacing Step 4 above by
Step 4.
Find the M largest peaks of following metric:
( ˜θ) =
1
|aH( ˜θ)UzUHz a( ˜θ)|2 ,
(2.93)
where a( ˜θ) = [1, e j ˜θ, . . . , e j(Ku−1) ˜θ]T .
As compared in [148], the ESPRIT based estimation algorithm outperforms the Spectral MUSIC
based estimation algorithm at low SNR region. Moreover, ESPRIT algorithm avoids the search operation
required by Spectral MUSIC. Thus, the ESPRIT based estimation algorithm is preferred in practice.
As shown in [148], the estimation error of CFOs can be reduced by using more than one OFDM block.
To apply the subspace-based CFO estimation algorithm, we have to ﬁnd the starting point of
the receive signal ﬁrst. As argued in [146], the CFO estimation algorithm is applicable to a quasi-
synchronous system. The starting point is determined by the downlink procedure and the effect of

74
CHAPTER 2 Synchronization
g
N
N
1
2nd arrival signal 
Last arrival signal 
FFT window
1st arrival signal 
1
M
ch
N
dl
N
FIGURE 2.35
CP for quasi-synchronous uplink OFDMA uplink.
timing offsets due to propagation delay can be removed by introducing a long CP. As shown in
Figure 2.35, the CP is composed of two parts Ng = Nch + Ndl, where Nch is the portion of the CP for
accommodating channel delay spreads, while the additional Ndl samples are intended for accommodat-
ing different timing offsets among users. To completely remove the inter-block interference, a necessary
condition is that Nch ≥L and Ndl ≥M−1, where L is the maximum channel delay spread and M−1
is the maximum timing offset among users. In this case, the extra overhead, i.e., Ndl, will be increased
by an increasing M−1. To reduce the overhead, accurate knowledge of the timing offset of each user
is necessary to align all user signals at BS. As shown in [145,149], a possible way to estimate the
multiple timing offsets is to estimate the timing offsets together with the channel responses. Similar to
ﬁne timing estimation in downlink OFDMA, the maximum energy criterion for timing offset estimation
can be expressed as:
˜τi = arg max
˜τi
⎧
⎨
⎩
˜τi+L−1

l=˜τi
|ˆh′
i(l)|2
⎫
⎬
⎭,
(2.94)
where ˆh′
i(l) is the lth entry of ˆh′
i and h′
i = [0τi hi0Lex−τi−L]T is the extended channel vector with length
Lex. We can set Lex = Ng for simplicity.
Alternative timing estimation algorithms can be found in [150,151]. However, the introduced iterative
approaches make the algorithms much more complicated compared to the maximum energy criterion
discussed above.
2.02.4.4 Synchronization with generalized CAS
As mentioned before, since there is no rigid constraint between subcarriers and users in generalized
CAS, this subcarrier allocation scheme is more ﬂexible than the subband or interleaved CAS. The BS
can assign the best subcarriers which are currently available to a user according to the users’ channel
condition. Thus, the generalized CAS can improve the systems performance signiﬁcantly. On the other
hand, lack of constraint among subcarriers makes the synchronization task even more challenging than
that of interleaved CAS.
The joint ML estimation of timing and frequency offsets for the generalized CAS was ﬁrst studied
by Morelli [100] and a suboptimal solution was proposed based on repetitively transmitted training

2.02.4 Multiuser Synchronization
75
symbols. However, it assumes that only one new user enters the network at each time, which may be
too strict in practical applications. Alternative ML-based synchronization schemes for the generalized
CAS are described in [149,152], where iterative alternating projection and space-alternating generalized
expectation-maximization (SAGE) algorithms are employed to reduce the complexity of ML estimation,
respectively. Similartothesubspace-basedalgorithmforinterleavedCAS,theiterative-basedalgorithms
studied in [149,152] are only applicable to a quasi-synchronous system.
Under the quasi-synchronous assumption as shown in Figure 2.35, after removing the CP, the IBI
free received signal expressed in (2.75) can be re-written in matrix form as
r =
M

i=1
(ωi)Aih′
i + υ,
(2.95)
or equivalently
r =
M

i=1
(ωi)Di(τi)hi + υ,
(2.96)
where
r = [r(0), . . . ,r(N −1)]T ,
(2.97)
(ωi) = diag{1, e j2πωi/N, . . . , e j2πωi(N−1)/N},
(2.98)
3
Ai
4
m,n = [xi](m−n)mod N,
0 ≤m ≤N −1, n = 0 ≤n ≤Ng −1,
(2.99)
3
Di(τi)
4
m,n = [xi](m−n−τi)mod N,
0 ≤m ≤N −1, n = 0 ≤n ≤L −1,
(2.100)
hi = [hi(0), . . . , hi(L −1)]T ,
(2.101)
h′
i =
1
0T
τi×1hT
i 0T
(Ng−L−τi)×1
2T
,
(2.102)
where
3
Ai
4
m,n denotes the (m, n)th entry of matrix Ai and [xi]m represents the mth entry of vector xi.
Rewrite (2.95) as
r = B(ω)h′ + υ,
(2.103)
where B(ω) = [(ω1)A1(ω2)A2 · · · (ωM)AM] and h′ = [(h′
1)T · · · (h′
M)T ]T . The log-likelihood
function for the frequency offsets ω and extended equivalent channel h′ can be expressed as
( ˜ω, ˜h′) = −N ln

πσ 2
υ

−1
σ 2υ
∥r −B( ˜ω)˜h′∥2,
(2.104)
where ˜ω and ˜h′ are trial values of ω and h′ respectively. Thus, the joint ML estimates of ω and h′ can
be obtained as
ˆω = arg max
˜ω
"
∥B( ˜ω)r∥2#
,
(2.105)
ˆh′ =

BH( ˆω)B( ˆω)
−1
BH( ˆω)r,
(2.106)

76
CHAPTER 2 Synchronization
where B( ˜ω) = B( ˜ω)

BH( ˜ω)B( ˜ω)
−1 BH( ˜ω). The maximization in (2.105) requires a grid-search
over the multidimensional domain spanned by ˜ω, which is too cumbersome in practice [149]. A simple
way to reduce the complexity is to use the iterative alternating projection method studied in [149].
Let ˆω(k)
i
denote the estimate of ωi at the kth iteration and deﬁne the M −1 dimensional vector ˆω(k)
i
as
ˆω(k)
i
=
1
ˆω(k+1)
1
, . . . , ˆω(k+1)
i−1 , ˆω(k)
i+1, . . . , ˆω(k)
M
2T
.
(2.107)
At the ith step of the (k + 1)th iteration, the estimate of ωi is updated by the alternating projection
frequency estimator (APFE) as
ˆω(k+1)
i
= arg max
˜ωi
666B

˜ωi, ˆω(k)
i

r
666
2
.
(2.108)
Exploiting the structure of B

˜ωi, ˆω(k)
i

, the estimator (2.108) can be further simpliﬁed as
ˆω(k+1)
i
= arg max
˜ωi
666CB

˜ωi, ˆω(k)
i

r
666
2
,
(2.109)
where
CB

˜ωi, ˆω(k)
i

= CB

˜ωi, ˆω(k)
i
 
CH
B

˜ωi, ˆω(k)
i

CB

˜ωi, ˆω(k)
i
−1
CH
B ( ˜ωi, ˆω(k)
i
),
(2.110)
CH
B

˜ωi, ˆω(k)
i

= IN −C

ˆω(k)
i

( ˜ωi)Ai,
(2.111)
C

ˆω(k)
i

= C

ˆω(k)
i
 
CH 
ˆω(k)
i

C

ˆω(k)
i
−1
CH 
ˆω(k)
i

,
(2.112)
C

ˆω(k)
i

=
1


ˆω(k+1)
1

A1 · · · 

ˆω(k+1)
i−1

Ai−1

ˆω(k)
i+1

Ai+1 · · · 

ˆω(k)
M

AM
2
.
(2.113)
Computing CB( ˜ωi, ˆω(k)
i
) only requires the inversion of a Ng × Ng matrix, which is signiﬁcantly less
complex than computing B( ˜ωi, ˆω(k)
i
). From (2.109), we see that the M-D search required by the ML
estimator (2.105) is split into a series of 1-D maximization problems, and is this much more effective
than the original maximization problem. After obtaining the frequency estimates ˆω, the ML estimates
of timing offsets can be derived from Eq. (2.96) as
ˆτ = arg max
˜τ
.
∥( ˆω, ˜τ)r∥
/
,
(2.114)
where
( ˆω, ˜τ) = ( ˆω, ˜τ)

 H( ˆω, ˜τ)( ˆω, ˜τ)
−1
 H( ˆω, ˜τ),
(2.115)
( ˆω, ˜τ) = [( ˆω1)D1(˜τ1) · · · ( ˆωM)DM(˜τM)].
(2.116)

2.02.4 Multiuser Synchronization
77
Similar to the problem in (2.105), the maximization problem in (2.114) can be efﬁciently solved by
resorting to iterative alternating projection methods; the resulting estimator is referred to as alternating
projection timing estimator (APTE) in [149]. Since the timing and frequency estimators introduced
above are iterative, initial estimates of ω and τ, referred to as ˆω(0) and ˆτ (0) respectively, are required.
A simple way to initialise the estimates of CFOs is to use the expected value of ωi, i.e., ˆω(0)
i
= 0.
Alternatively, ˆω(0) can be taken as the output of the frequency estimator proposed in [153]. The initial
estimates ˆτ (0) can be obtained by ﬁrst estimating h′
i according to Eq. (2.106) and then exploiting the
speciﬁc structure of ˆh′
i. The index of the ﬁrst signiﬁcant element of ˆh′
i is taken as ˆτ (0)
i
.
Another alternative approach to avoid the multidimensional search in ML based estimator is employ-
ing the SAGE algorithm as in [151,152]. Since the estimates of timing offsets can be obtained via (2.94),
we assume that the timing offsets are estimated ﬁrst for SAGE algorithm. From Eq. (2.96), the ith cycle
of the kth iteration of the SAGE algorithm can be performed as follows:
1. Expectation step: Compute
y(k)
i
= r −
i−1

j=1
ˆr(k)
j
−
M

j=i+1
ˆr(k−1)
j
.
(2.117)
2. Maximization step: The likelihood function for the unknown frequency offset ωi and channel hi can
be expressed as
( ˜ωi, ˜hi) = −N ln

πσ 2
υ

−1
σ 2υ
∥y(k)
i
−( ˜ωi)Di(ˆτi)˜hi∥2.
(2.118)
Thus, the joint ML estimates of ωi and hi can be written as
ˆω(k)
i
= arg max
˜ωi
"
∥W( ˜ωi)y(k)
i
∥2#
,
(2.119)
ˆh(k)
i
=

DH
i

ˆτi

Di(ˆτi)
−1
DH
i (ˆτi)H( ˆω(k)
i
)y(k)
i
,
(2.120)
where W = ( ˜ωi)Di(ˆτi)

DH
i (ˆτi)Di(ˆτi)
−1 DH
i (ˆτi)H( ˜ωi). After obtaining the estimates ˆω(k)
i
and ˆhi, ˆr(k)
i
which is utilized in the Expectation step of the next cycle or iteration can be updated as
ˆr(k)
i
= 

ˆω(k)
i

Di(ˆτi)ˆh(k)
i .
(2.121)
Again, the initial estimates of CFOs for the SAGE algorithm can be obtained via iterative alternating
projection methods. Moreover, we can see from Eq. (2.121) that initial channel estimates are required
for the SAGE algorithm while no such requirement is needed for the iterative alternating projection
methods. Inaccurate channel estimates will deteriorate the SAGE performance signiﬁcantly. With the
aim of obtaining a tradeoff between performance and complexity, several non-ML based multiple CFOs
estimators were proposed in [154,155].
2.02.4.5 Simulation results for uplink OFDMA systems
The synchronization of uplink OFDMA systems depends on the subcarrier allocation schemes. Here,
we compare the synchronization performance of subspace based and ML based methods, based on

78
CHAPTER 2 Synchronization
0
5
10
15
20
25
30
10
−7
10
−6
10
−5
10
−4
10
−3
SNR (in dB)
MSE of CFO estimation
ESPRIT
APFE
SAGE
SD−CRB
ML−CRB
FIGURE 2.36
Mean square error of CFO estimates for uplink OFDMA without timing offsets.
interleaved CAS. The total number of subcarriers is set to 512 with a CP of length 32, i.e., N = 512
and Ng = 32. The maximum and active numbers of users are set to 4 and 3, respectively, i.e., Ku = 4
and M = 3. The channel with the exponential power delay proﬁle, introduced previously, is considered.
The maximum channel delay spread L is equal to 16 and the channels for different users are assumed
uncorrelated. We set the CFOs of the three users to −0.1, −0.2 and 0.3, respectively.
Figure 2.36 shows the CFO estimation performance without timing offsets. From Eq. (2.95), the
CRB of ML based CFO estimation algorithm is given in [149] as
var
.
ˆωi
/
≥CRB ˆωi = N 2σ 2
υ
8π2
1
ℜ
"
 H⊥
B
#2
i,i ,
(2.122)
where  = [1, . . . , M], i = W(ωi)Aih′
i with W = diag{0, 1, . . . , N −1}; ⊥
B = I −B(ω).
The CRB corresponding to the subspace decomposition based CFO estimation algorithm can be found
in [95]. From Figure 2.36, we can ﬁnd that ML based algorithms, i.e., APFE and SAGE, have identical
performances and provide nearly 3-dB gains over ESPRIT algorithm. This can be ascribed to the fact
that subspace decomposition based CFO estimation is actually a non-data aided method. Both ML and
subspace decomposition based CFO estimation algorithms can achieve their “corresponding CRBs.”
Under the quasi-synchronous assumption, we assume that the ﬁrst arriving signal is known perfectly
by the BS and the timing offsets of other two user’s signals are normally distributed in an interval
[0, 16]. Figure 2.37 shows the timing estimation performance of ESPRIT and SAGE based estimators,

2.02.5 Network Synchronization
79
0
5
10
15
20
25
30
10
−2
10
−1
10
0
SNR (in dB)
STD of timing estimates
ESPRIT based
APTE
SAGE based
FIGURE 2.37
Standard deviation of timing estimates for uplink OFDMA.
and the ML estimator (2.114), i.e., APTE. As we can see from the ﬁgure, the ML estimator outperforms
the maximum channel energy based estimators signiﬁcantly at the price of increased computational
complexity. Since APFE and ESPRIT based CFO estimators can work without timing offset information,
weestimateCFOpriortotimingoffsetestimation.Ontheotherhand,timingoffsetsinformationiscrucial
to the SAGE based CFO estimator. Thus we perform timing offset estimation before SAGE based CFO
estimation. From Figure 2.37, we see that ESPRIT based timing estimator outperforms SAGE. This can
be ascribed to the fact that employing the CFO estimates obtained in the ESPRIT based CFO estimator
improves timing estimation. Figure 2.38 shows the CFO estimation performance with timing offsets
estimation. We see that the performance of SAGE based CFO estimator is affected signiﬁcantly by the
inaccuracy of timing estimation. On the other hand, both ESPRIT and APFE estimators are robust to
timing inaccuracies.
2.02.5 Network synchronization
In this section, we discuss the challenges in the network time synchronization problem and the per-
formance metrics of interest. We provide a brief overview of current devices and their limitations, and
describe common clock models. We then describe a taxonomy of network time sync protocols and
provide some examples.

80
CHAPTER 2 Synchronization
0
5
10
15
20
25
30
10
−7
10
−6
10
−5
10
−4
10
−3
SNR (in dB)
MSE of CFO estimation
ESPRIT
APFE
SAGE
SD−CRB
ML−CRB
FIGURE 2.38
Mean square error of CFO estimates for uplink OFDMA with timing offsets.
As stated in the Introduction to this chapter, network synchronization is a well-studied topic with
an extensive history, especially for wired networks, e.g., see [156,157], and references therein. Typi-
cally, these works assumed high quality devices, availability of ﬁne control of the network, extensive
connectivity with little or no mutual interference, as well as often assuming known (or repeatable and
measurable) propagation and processing delays [1]. Surveys of WSN sync protocols may be found in
the papers by Sivrikaya and Yener [2], Johannessen [3], Sundararaman et al. [1,4–6].
The network synchronization problem is to ensure that all nodes in the network operate on a common
clock, i.e., have a common time reference.
Challenges in synchronization in WSN stem from several sources, broadly related to the transmitter,
the propagation channel, and the receiver:
1. Channel conditions (such as fading, shadowing, interference) lead to time-varying connectivity even
for static nodes: scatterers move in any case; mobility adds its own challenges.
2. The devices are cheap and clocks drift, often erratically, due to ﬂuctuations in ambient temperature,
and with age. The time difference between two clocks may be ﬁxed (a ﬁxed offset) or may vary with
time (due to clock oscillator frequency drifts).
3. Queuing and processing delays are variable (thus rendering it difﬁcult to use standard protocols such
as NTP). There is variability in the time it takes for a packet to go from the application layer to the
MAC layer, variable delays within the MAC layer (the major source of error), in packet generation

2.02.5 Network Synchronization
81
and transmission at the PHY layer. There are similar variations at the receiver, including inaccuracy
in detecting packet arrival.
4. Variabilities in propagation time due to non-line of sight issues, and non-reciprocity of the channel.
Typically, the propagation time is negligible compared with the queueing and processing delays.
5. Communication rates are variable in a large network; if a node is involved infrequently in regular
communications, then “heartbeat” signals may be essential to keep the node in quasi-sync with the
rest of the network, and thus connected to the network.
6. Protocols must be scalable to a large number of nodes, and must deal with heterogeneity of nodes.
7. These devices are often battery powered so that energy is a ﬁnite resource, and energy consumption
directly affects node lifetime.
8. Given energy constraints, WSN nodes must exploit external assets which may have more relaxed
energy constraints; e.g., basestations, unmanned aerial vehicles (UAVs), various broadcast beacons.
Metrics: How should one evaluate the performance of a network sync protocol? When GPS is
available, a reasonable metric could be the bias compared to the “true” time. But access to GPS can
be difﬁcult, particularly indoors, under forest canopy, and in other challenging conditions. Often, it
sufﬁces that the nodes converge on some common time reference (regardless of whether it is “true”).
Some commonly used metrics are:
•
Synchronization accuracy: Worst case (or average case) pair wise error between any one-hop
neighbors
•
Energy efﬁciency: The number of packet transmissions and receptions necessary to achieve sync,
and the rate and frequency of messages that need to be exchanged to maintain sync.
•
Synchronization convergence time: The time taken for all nodes (or a given percentage of nodes) to
be in sync with one-hop neighbors.
•
Fault tolerance: The robustness of sync schemes under (intermittent) failure of (critical) nodes
and/or links; robustness to (slow) time variations in clock parameters and clock jitter.
•
Scalability with network size: Does the sync-error increase with size? Does convergence time
increase (only) with the diameter of the network? Or other aspects of topology such as degree
distribution?
•
Impact of stochastic channel conditions: How well does the protocol perform in the presence of
stochastic channel conditions (congestion, mobility, duty cycling, queueing delays, propagation
delays, processing times)?
•
Engineering design: Is the protocol simple versus complex?
From the above questions, it is clear that a given protocol offers a set of alternatives in this rich tradespace.
2.02.5.1 Clock models
Let Tk(t) denote the local time at node k, where t denotes the “true” time; often, we will drop the node
index k. Formally, clock drift is deﬁned as
ρ(t) = dT (t)
dt
−1.

82
CHAPTER 2 Synchronization
Table 2.2 Compariosn of Clock Characteristics
Accuracy (PPM)
Power
Lifetime in hours AA battery
GPS
10−8 10−11
180 mW
16.7 h
Chip-Scale Atomic Clock
10−11
30 mW
100 h
MCXO
3 × 10−8
75 mW
40 h
TCXO
6 × 10−6
6 mW
21 days
Watch clock
200 × 10−6
1 µW
342 years
A reasonable assumption is that the drifts are bounded, and the clocks do not run backwards, which
translate to
|ρ(t)| < ρmax; ρ(t) > −1.
A Taylor expansion of the local clock time T (t) wrt the global clock t yields
Tk(t) = αk + βkt + γkt2 + · · · ,
(2.123)
wherein α is the offset and β the skew. The quadratic term, denoted by γ , is typically used only to
test for departures from the linear model. Skew has been modeled as an AR process in [158] (see
Table 2.2).
2.02.5.2 Net sync protocols
With the above background, we can broadly classify net sync protocols into four broad categories:
1. Broadcast protocols: Based on the notion of broadcast, possibly over a hierarchical tree topology.
2. Distributed synchronization: builds consensus on clock parameters in a peer-to-peer setting.
3. Unilateral sync to an external (broadcast) reference clock.
Other classiﬁcations are possible depending upon the viewpoint: e.g., client (sensor node) initiated
versus server (gateway) initiated.
Many WSN synchronization protocols have been proposed. Popular ones include the Reference
Broadcast Systems (RBS) [159], a time-stamp transformation approach based on bounded offsets [160],
the Tiny/Mini-Sync (TMS) protocol [161], Timing-sync Protocol for Sensor Networks (TPSN) [162],
Lightweight Tree-based Synchronization (LTS) [163], and the networked Control Time Protocol (CTP)
[164]. Probabilistic approaches were considered in [165], and reﬁned and extended in [166]. Bounds
under various assumptions are derived in [167–169] and citeNoh-Serpedin.
Among the above protocols, several primary themes emerge. One natural and common notion is the
use of time-stamps: time-stamp a packet with the transmitter’s clock, time-stamp the reception time, use
these stamps to estimate the round trip time (RTT), which is then used to synchronize the two clocks.
RTT is often highly variable, and often has a heavy-tailed distribution, which naturally calls for the
use of robust estimation techniques. Reliability increases as the number of such exchanges increases,
but with a concomitant increase in delay and energy, and sometimes (more than linear) complexity.

2.02.5 Network Synchronization
83
A second recurring theme is that the estimation of relative clock offset and skew can be cast as a linear
estimation problem.
2.02.5.2.1
Unilateral synchronization
Assume that an external source broadcasts time-stamped messages at “true” times T (i), which are
received by a node at R(i) on its local clock. Then from the clock model considered earlier in (2.123),
we have
R(i) = α + βT (i) + ε(i),
i = 1, . . . , I,
(2.124)
where n is the number of observations. Here ε(i) represents the modeling errors. Let 1 be I × 1 vector
of ones, t = [T (1), . . . , T (I)]′, r = [R(1), . . . , R(I)]′, Z = [1, t]. Then linear regression yields
 ˆα
ˆβ

= (Z′Z−1Z′r)
which is the best linear estimate if the ε(i) are zero-mean. Note that in this unilateral scheme, one cannot
account separately for the propagation delay, or a non-zero-mean ε: both are absorbed into the offset.
Thus clocks that are at relatively different distances from the broadcast source will not be in sync with
each other.
2.02.5.2.2
Pairwise synchronization
As in the classical Network Time Protocol (NTP) [170], clock offset can be estimated by exchanging
time-stampedmessagesandcomputingtheroundtriptime(RTT).Ifthequeuingdelaysareexponentially
distributed with the same mean delay then the MLE of the offset is given by the minimum of the observed
delays [171]; if the mean delays vary from node to node, then the bootstrap-bias correction method of
[172] can be used. Further details may be found in [173].
In these pair-wise protocols, a node “B” synchronizes with a node “A” which is treated as the reference
node. Let α and β denote the relative offset and skew of node B wrt node A. Nodes exchange multiple
time-stamped messages as follows. Nodes A sends a time-stamped message to node be at its local
time TA,k, where k is the round number. Node B receives it at its local time RB,k. At TB,k, it sends
a time-stamped message which includes RB,k; this is received by node A at RA,k. K such rounds of
message exchange take place. Let δ denote the ﬁxed portion of the delay and εAB,k, εB A,k, the variable
portion; delay here includes propagation delay, processing delay and queueing delay. The time-stamps
are related via:
RB,k = (TA,k + δ + εAB,k)β + α,
(2.125)
TB,k = (RA,k −δ −εB A,k)β + α.
(2.126)
Assuming that the delays are independent and exponentially distributed, it is shown in [171,173] that
the MLE of α is given by
ˆα = 1
2

min
k
(RB,k −TA,k) −min
k
(RA,k −TB,k)

.

84
CHAPTER 2 Synchronization
Let i = arg mink (RA,k −TA,k) and j = arg mink,k̸=i (RA,k −TA,k), which are the ﬁrst two order
statistics of RA,k −TA,k. Then the proposed estimator of the skew in [173] is
ˆβ = RB,i + TB,i −RB, j −TB, j
RA,i + TA,i −RA, j −TA, j
.
Once α, β have been estimated, it is easy to estimate the propagation delay as well. These algorithms
have been shown to be robust to other delay models.
In the RBS protocol [159], a beacon node transmits a reference packet (as above), but the K receiving
nodes exchange time-of-receipt to estimate offsets and skews. Consider (2.124), now indexed by the
receiving node’s id:
Ri(n) = αi + βiT (n) + εi(n).
(2.127)
Deﬁning i j := αi −βi jα j and βi j := βi
β j , as the relative offset and skew, one can eliminate T (n) to
obtain
Ri(n) = βi j R j(n) + i j + εi j(n).
Notes i and j can estimate the relative skew and offset via linear regression.
The tree-based sync protocol in [162] is similar to the above algorithms in the estimation part. Here
a root node broadcasts a beacon. Its set of 1-hop neighbors (i.e., those who hear the root directly) are
called level 1 nodes. Level 1 nodes, in turn, relay the beacon to level-2 nodes, and so on. Nodes at level
i synchronize to a parent node at level i −1. The relative skew is assumed to be unity, so the focus is on
estimating offsets. Consider a pair of parent-child nodes; one can write the packet reception times as
RB,k = TA,k + α + δ + εAB,k,
RA,k = TB,k −α + δ + εB A,k.
After K messages, one can estimate
ˆα =
1
2K
K

k=1
(RB,k −RA,k + TB,k −TA,k),
ˆδ =
1
2K
K

k=1
(RB,k + RA,k −TB,k −TA,k).
Under the assumption that the noise terms, the εs are zero-mean and independent, one obtains the
following equation for the variance of the estimators:
var( ˆβ) = var(ˆδ) = σ 2
12 + σ 2
21
K
.
The TPSN protocol is easy to implement. However, it assumes unit skew. Tine-Sync and Mini-Sync are
variations that can cope with skew [161].
Another variation was proposed in [1]. The basic idea is that if node A transmits a pair of time-
stamped messages ρ units apart on its own clock, then node B should be able to estimate the relative
skew.

2.02.5 Network Synchronization
85
2.02.5.3 Distributed clock sync
The notion of distributed consensus, i.e., distributed agreement on a parameter (vector) via repeated
exchange of messages has recently become popular, and several protocols have been proposed. Here,
the idea is that there is no single root node and hence no single point of failure. These protocols seek
to achieve global consensus via local exchange of information. They rely upon the broadcast nature of
the wireless slink.
2.02.5.3.1
Bio-inspired approaches
The seminal work of Mirollo and Strogatz [174] introduced the basic idea that a population of “integrate-
and-ﬁre” oscillators will start ﬁring simultaneously after a ﬁnite time starting from all almost any initial
condition. Empirical evidence for this is the well-cited ﬁreﬂy sync [8] and circadian sync [9]. The
work was extended to multi-hop and time-varying topologies in [175] who made use of results from
Algebraic Graph theory. These results have been recently reﬁned, corrected and extended by [176]. The
Mirollo-Strogatz model has been exploited in [177] for network time sync. Another consensus-based
approach is the so-called diffusion-based approach of [178].
2.02.5.3.2
Consensus-type approaches
We consider next one example of a consensus-based approach [179]. This scheme assumes the presence
of a reference node (i.e., a root node whose clock is assumed to be correct, and which does not update
its clock). Multiple consistent reference nodes may be present as well. For simplicity assume that all
nodes have unit skew, and node i has offset αi wrt the reference node. Using one of the pairwise schemes
described earlier, nodes can obtain an estimate of the relative offset
yi, j = αi −α j + εi, j,
where εi, j is the measurement noise which we model as zero-mean and with variance σ 2
i, j. A node i
would have such an estimate for each j ∈Ni, the set of neighbors that it can hear. At every iteration, a
node receives the current estimates of its neighbors which are used to update its own estimate. Node is
estimate of its offset αi in the kth iteration is given by
ˆαi(k) =
⎛
⎝
j∈Ni
1
σ 2
i, j
⎞
⎠
−1

j∈Ni
1
σ 2
i, j

ˆα j(k −1) + yi j

.
The convergence if this algorithm was studied in [179].
Convergence depends upon the topology, the coupling and the measurement statistics. We can asso-
ciate a graph G = (V , E) with this problem; here V is the set of nodes, and E the set of edges representing
one-hop links. The energy (convergence time) spent for achieving consensus is proportional to 1/λ2(L)
where L is the graph Laplacian and λ2(·) is the second-largest eigenvalue. The algebraic network con-
nectivity (the so-called Fiedler value), λ2(L) can be increased by increasing the transmit power, i.e.,
making the graph more connected. However, this also increases the total energy consumption, since the
total power consumed by the network is proportional to pT /λ2(L(pT )), where L(pT ) is the Laplacian
of the graph corresponding to transmit power pT . A question then is: does a global trade-off exist
between local transmit power, convergence rate and network topology? Analysis in [180] indicates that
when the path loss is high, the optimal topology tends to be sparse, with few connections.

86
CHAPTER 2 Synchronization
2.02.6 Conclusion
Synchronization is a critical element of ensuring performance of communication systems, such as
cellular networks, wireless sensor networks and mobile ad hoc networks, networked signal processing,
controls and robotic systems.
In this chapter, our focus was largely on time and frequency synchronization. We ﬁrst reviewed point-
to-point synchronization over a ﬂat-fading link. We studied both the data-aided as well as blind scenarios;
we deveopled the maximum-likelihood estimator, derived the Cramer-Rao bound; investigated sub-
optimal estimators and characterized their performance. We then studied the synchronization problem
in the context of a frequency-selective channel, focusing on OFDMA systems. We reviewed several
estimators and compared their performance with the Cramer-Rao bound. We then turned our attention
to multi-user synchronization, again developing estimators and establishing performance bounds. The
last section provided a review of the network time synchronization problem, commonly used protocols
and performance metrics. We reviewed both broadcast protocols as well as distributed schemes.
Relevant Theory: Signal Processing Theory and Statistical Signal Processing
See Vol. 1, Chapter 3 Discrete-Time Signals and Systems
See Vol. 1, Chapter 4 Random Signals and Stochastic Processes
See Vol. 1, Chapter 11 Parametric Estimation
See Vol. 3, Chapter 4 Bayesian Computational Methods in Signal Processing
See Vol. 3, Chapter 8 Performance Analysis and Bounds
References
[1] B. Sadler, A. Swami, Synchronization in sensor networks: an overview, in: IEEE MILCOM 2006, 2006.
[2] F. Sivrikaya, B. Yener, Time synchronization in sensor networks: a survey, IEEE Network 18 (4) (2004)
45–50.
[3] S. Johannessen, Time synchronization in a local area network, IEEE Control Syst. Mag. 24 (2) (2004) 61–69.
[4] B. Sundararaman, U. Buy, A. Kshemkalyani, Clock Synchronization for Wireless Sensor Networks: A
Survey, Ad Hoc Networks, Elsevier, vol. 3 (3) 2005, pp. 281–323.
[5] Y.R. Faizulkhakov, Time synchronization methods for wireless sensor networks: a survey, Program. Comput.
Soft. 33 (4) (2007) 214–226 (SpringerLink).
[6] Y.C. Wu, Q. Chaudhari, E. Serpedin, Clock synchronization in wireless sensor networks: an overview, IEEE
Signal Process. Mag. 28 (1) 2011.
[7] P. Galison, Einstein’s Clocks, Poincare’s Maps: Empires of Time, Norton, 2003.
[8] S. Strogatz, SYNC: The Emerging Science of Spontaneous Order, Hyperion, Hyperion Press, 2003.
[9] Y. Wang, F. J. Doyle III, On inﬂuences of global and local cues on the rate of synchronization of oscillator
networks, Automatica 47 (6) (2011) 1236–1242.
[10] A. Olshevsky, J. Tsitsiklis, Convergence speed in distributed consensus and averaging, SIAM Review 53 (4)
(2011) 747–772.
[11] V.D. Blondel, J.M. Hendrickx, A. Olshevsky, J. Tsitsiklis, Convergence in multiagent coordination, consen-
sus, and ﬂocking, in: Proceedings of the Joint 44th IEEE Conference on Decision and Control and European
Control Conference (CDC-ECC’05), Seville, Spain, 2005.

References
87
[12] J. Proakis, Digital Communications, Mc-Graw-Hill, 2001.
[13] D. Tse, P. Viswanath, Fundamentals of Wireless Communication, Cambridge University Press, 2005.
[14] S. Kay, Fundamentals of Statistical Signal Processing, Volume 1: Estimation Theory, Prentice Hall, 1993.
[15] E. Tozer, Broadcast Engineer’s Reference Book, Focal Press, 2004.
[16] S. Savory, Digital ﬁlters for coherent optical receivers, Opt. Express 16 (2) (2008) 804–817.
[17] P. Ciblat, P. Loubaton, E. Serpedin, G. Giannakis, Asymptotic analysis of blind cyclic correlation based
symbol rate estimation, IEEE Trans. Inform. Theory 48 (7) (2002) 1922–1934.
[18] U. Mengali, A. d’Andrea, Synchronization Techniques for Digital Receivers, Plenum Press, 1997.
[19] H. Meyr, M. Moeneclaey, S. Fechtel, Digital Communications Receivers: Synchronization, Channel Esti-
mation, and Signal Processing, J. Wiley & Sons, 1998.
[20] C. Georghiades, E. Serpedin, Synchronization, The Handbook of Communications, CRC Press, 2002.
[21] B. Porat, Digital Signal Processing of Random Signals, Prentice Hall, 1994.
[22] A. Viterbi, Error bounds for convolutional codes and an asymptotically optimum decoding algorithm, IEEE
Trans. Inform. Theory (1967).
[23] G. Forney, The viterbi algorithm, Proc. IEEE, 1973.
[24] M. Morelli, U. Mengali, Carrier frequency estimation for transmissions over selective channels, IEEE Trans.
Commun. 48 (9) (2000) 1580–1589.
[25] P. Ciblat, L. Vandendorpe, On the maximum-likelihood based data-aided frequency offset and channel
estimates, in: EURASIP European Signal Processing Conference (EUSIPCO), vol. 1, Toulouse, France,
September 2002, pp. 627–630.
[26] B. Hassibi, B. Hochwald, How much training is needed in multiple-antenna wireless links? IEEE Trans.
Inform. Theory 49 (4) (2003) 951–963.
[27] H.V. Trees, Detection, Estimation, and Modulation Theory, J. Wiley & Sons, 2003.
[28] S. Crozier, D. Falconer, S. Mahmoud, Least sum of squared errors channel estimation, IEE Proc. F Radar
Signal Process. 138 (4) (1991) 371–378.
[29] C. Tellambura, M. Parker, Y. Guo, S. Sheperd, S. Barton, Optimal sequences for channel estimation using
discrete Fourier transform techniques, IEEE Trans. Commun. 47 (2) (1999) 230–237.
[30] A. Benveniste, M. Métivier, P. Priouret, Adaptive Algorithms and Stochastic Approximations, Springer-
Verlag, 1990.
[31] C. Herzet, N. Noels, V. Lottici, H. Wymeersch, M. Luise, M. Moeneclaey, L. Vandendorpe, Code-aided turbo
synchronization, Proc. IEEE 95 (6) (2007) 1255–1271.
[32] W. Lindsey, M. Simon, Telecommunications Systems Engineering, Prentice Hall, Englewood Cliffs, 1972.
[33] F. Gardner, Demodulator Reference recovery techniques suitable for digital implementation, ESTEC Contrat
No. 6847/86/NL/DG, European Space Agency, 1988.
[34] K. Mueller, M. Mueller, Timing recovery in digital synchronous data receivers, IEEE Trans. Commun. 24
(5) (1976) 516–531.
[35] D. Rife, R. Boorstyn, Single-tone parameter estimation from discrete-time observations, IEEE Trans. Inform.
Theory 20 (5) (1974) 591–598.
[36] R.M. Aulay, L. Seidman, A useful form of Barankin lower bound ans its application to PPM threshold
analysis, IEEE Trans. Inform. Theory 15 (2) (1969) 273–279.
[37] L. Atallah, J.-P. Barbot, P. Larzabal, SNR threshold indicators in data-aided phase and frequency synchro-
nization for QAM, IEEE Signal Process. Lett. 11 (8) (2004) 652–654.
[38] P. Ciblat, M. Ghogho, Blind NLLS carrier frequency-offset estimation for QAM, PSK, and PAM modulations:
performance at low SNR, IEEE Trans. Commun. 54 (10) (2006) 1725–1730.
[39] E. Barankin, Locally best unbiaised estimates, Ann. Math. Statist. 20 (1949) 447–501.
[40] L. Knockaert, The Barankin bound and threshold behavior in frequency estimation, IEEE Trans. Signal
Process. 45 (1997) 2398–2401.

88
CHAPTER 2 Synchronization
[41] R.M. Aulay, E. Hofstetter, Barankin bounds on parameter estimation, IEEE Trans. Inform. Theory 17 (6)
(1971) 669–676.
[42] I. Reuven, H. Messer, A Barankin-type lower bound on the estimation error of hybrid parameter vector, IEEE
Trans. Inform. Theory 43 (3) (1997) 1084–1093.
[43] I. Reuven, H. Messer, On the effect of nuisance parameters on the threshold SNR value of the Barankin
bound, IEEE Trans. Signal Process. 47 (1999) 523–527.
[44] P. Forster, P. Larzabal, On lower bounds for deterministic parameter estimation, in: IEEE International
Conference on Acoutics, Speech, and Signal Processing (ICASSP), vol. 2, Orlando, FL, May 2002, pp. 1137–
1140.
[45] J. Ziv, M. Zakai, Some lower bounds on Signal Processing estimation, IEEE Trans. Inform. Theory 15 (3)
(1969) 386–391.
[46] K. Bell, Y. Steinberg, Y. Ephraim, H.V. Trees, Extended Ziv-Zakai lower bound for vector parameter esti-
mation, IEEE Trans. Inform. Theory 43 (2) (1997) 624–637.
[47] A. Weiss, E. Weinstein, Fundamental limitations in passive time-delay estimation—Part I: Narrow-band
systems, IEEE Trans. Acoust. Speech Signal Process. 31 (2) (1983) 472–486.
[48] P. Ciblat, M. Ghogho, Ziv-zakai bound for harmonic retrieval in multiplicative and additive Gaussian noise,
in: IEEE Workshop on Statistical Signal Processing (SSP), Bordeaux, France, July 2005.
[49] C. Georghiades, D. Snyder, The expectation-maximization algorithm for symbol unsynchronized sequence
detection, IEEE Trans. Commun. 39 (1) (1991) 54–61.
[50] E. Panagirci, C. Georghiades, Joint ML timing and phase estimation in OFDM systems using the EM
algorithm, in: IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), vol. 3,
July 2000, pp. 2949–2952.
[51] M. Moeneclaey, G. de Jonghe, Ml-oriented nda carrier synchronization for general rotationally symmetric
signal constellations, IEEE Trans. Commun. 42 (8) (1994) 2531–2533.
[52] M. Morelli, U. Mengali, Feedforward frequency estimation for PSK: a tutorial review, Eur. Trans. Telecom-
mun. 9 (2) (1998) 103–115.
[53] J. Costas, Synchronous communications, Proc. IRE 44 (12) (1956) 1713–1718.
[54] D. Taylor, Introduction TP synchronous communications, Proc. IEEE 90 (8) (2002) 1459–1460.
[55] W. Gardner, A. Napolitano, L. Paura, Cyclostationarity: half a century of research, Signal Process. 86 (4)
(2006) 639–697.
[56] G.B. Giannakis, F. Panduru, E. Serpedin, I. Sari, A bibliography on cyclostationary signal processing, Signal
Process. 85 (12) (2005) 2233–2303.
[57] B. Picinbono, P. Chevalier, Widely linear estimation with complex data, IEEE Trans. Signal Process. 43 (8)
(1995) 2030–2033.
[58] F. Gini, G. Giannakis, Frequency offset and symbol timing recovery in ﬂat-fading channels: a cyclostationary
approach, IEEE Trans. Commun. 46 (3) (1998) 400–411.
[59] Y. Wang, P. Ciblat, E. Serpedin, P. Loubaton, Performance analysis of a class of non-data aided carrier
frequency offset and symbol timing delay estimators for ﬂat-fading channels, IEEE Trans. Signal Process.
50 (9) (2002) 2295–2305.
[60] A. Dandawate, G. Giannakis, Asymptotic theory of mixed time averages and kth-order cyclic moment and
cumulant statistics, IEEE Trans. Inform. Theory 41 (1) (1995) 216–232.
[61] G. Zhou, G. Giannakis, Harmonics in multiplicative and additive noise: performance analysis of cyclic
estimators, IEEE Trans. Signal Process. 43 (6) (1995) 1445–1460.
[62] M. Oerder, H. Meyr, Digital ﬁlter ans square timing recovery, IEEE Trans. Commun. 36 (5) (1988) 605–612.
[63] K. Scott, E. Olasz, Simultaneous clock phase and frequency offset estimation, IEEE Trans. Commun. 43 (7)
(1995) 2263–2270.

References
89
[64] M. Ghogho, A. Swami, T. Durrani, On blind carrier recovery in time-selective fading channel, in: Asilomar
Conference on Signals, Systems and Computers, vol. 1, 1999, pp. 243–247.
[65] Y. Wang, E. Serpedin, P. Ciblat, Blind feedforward cyclostationarity-based timing estimation for linear
modulations, IEEE Trans. Wireless Commun. 3 (3) (2004) 709–715.
[66] J. Delmas, Asymptotic performance of second-order algorithms, IEEE Trans. Signal Process. 50 (1) (2002)
49–57.
[67] B. Ottersten, P. Stoica, R. Roy, Covariance matching estimation techniques for array signal processing
applications, Digital Signal Process. 8 (1998) 185–210.
[68] E. Hannan, Non linear time series regression, J. Appl. Probab. 8 (1972) 767–780.
[69] E. Hannan, The estimation of frequency, J. Appl. Probab. 10 (1973) 510–519.
[70] T. Hasan, Non linear time series regression for a class of amplitude modulated cosinusoids, J. Time Ser.
Anal. 3 (2) (1982) 109–122.
[71] P. Ciblat, P. Loubaton, E. Serpedin, G. Giannakis, Performance analysis of blind carrier frequency offset
estimators for non-circular transmissions through frequency-selective channels, IEEE Trans. Signal Process.
50 (1) (2002) 130–140.
[72] O. Besson, P. Stoica, Nonlinear least-squares approach to frequency estimation and detection for sinusoidal
signals with arbitrary envelope, Digital Signal Process. 9 (1) (1999) 45–56.
[73] A. Viterbi, A. Viterbi, Non-linear estimation of PSK-modulated carrier phase with application to burst digital
transmissions, IEEE Trans. Inform. Theory 29 (July 1983) 543–551.
[74] Y. Wang, E. Serpedin, P. Ciblat, Optimal blind nonlinear least-squares carrier phase and frequency offset
estimation for general QAM modulations, IEEE Trans. Wireless Commun. 2 (2003) 1040–1054.
[75] S. Colonnese, S. Rinauro, G. Panci, G. Scarano, Gain-control-free blind carrier frequency offset acquisition
for QAM constellations, IEEE Trans. Signal Process. 58 (2010) 349–361.
[76] E. Serpedin, P. Ciblat, G.B. Giannakis, P. Loubaton, Performance analysis of blind carrier phase estimators
for general QAM constellations, IEEE Trans. Signal Process. 49 (2001) 1816–1823.
[77] G. Vazquez, J. Riba, Signal Processing Advances for Wireless Mobile Communcations, vol. 2, Englewood
Cliffs, Prentice-Hall, 2000, (Chapter 9 Non-Data-Aided Digital Synchronization).
[78] A. d’Andrea, U. Mengali, R. Reggiannini, The modiﬁed Cramer-Rao bound and its application to synchro-
nization problems, IEEE Trans. Commun. 42 (2–4) (1994) 1391–1399.
[79] G. Zhou, G. Giannakis, Harmonics in Gaussian multiplicative and additive white noise: Cramer-Rao bounds,
IEEE Trans. Signal Process. 43 (1996) 1217–1231.
[80] M. Ghogho, A. Swami, T. Durrani, Frequency estimation in the presence of Doppler spread: performance
analysis, IEEE Trans. Signal Process. 49 (4) (2001) 777–789.
[81] F. Gini, R. Reggiannini, U. Mengali, The modiﬁed Cramer-Rao Bound in vector parameter estimation, IEEE
Trans. Commun. 46 (1) (1998) 52–60.
[82] F. Gini, M. Luise, R. Reggiannini, Cramer-Rao bounds in the parametric estimation of fading radiotransmis-
sion channels, IEEE Trans. Commun. 46 (1998) 1390–1398.
[83] M. Moeneclaey, On the true and the modiﬁed Cramer-Rao Bounds for the estimation of a scalar paramter in
the presence of nuisance parmaters, IEEE Trans. Commun. 46 (11) (1998) 1536–1544.
[84] F. Rice, B. Cowley, B. Moran, M. Rice, Cramer-Rao lower bound for QAM phase and frequency estimation,
IEEE Trans. Commun. 49 (2001) 1582–1591.
[85] H. Steendam, M. Moeneclaey, Low-SNR limit of the Cramer-Rao Bound for estimating the carrier phase
and frequency of a PAM, PSK, or QAM waveform, IEEE Commun. Lett. 5 (5) (2001) 218–220.
[86] P. Ciblat, M. Ghogho, P. Larzabal, P. Forster, Harmonic retrieval in the presence of non-circular Gaussian
multiplicative noise: Performance bounds, EURASIP Signal Process. 85 (2005) 737–749.
[87] N. Noels, H. Steendam, M. Moeneclaey, The true Cramer-Rao bound for carrier frequency estimation from
a PSK signal, IEEE Trans. Commun. 52 (2004) 834–844.

90
CHAPTER 2 Synchronization
[88] P. Stoica, B. Ng, On the Cramer-Rao bound under parametric constraints, IEEE Signal Process. Lett. 5 (1998)
177–179.
[89] Z. Ben-Haim, Y. Eldar, On the constrained Cramer-Rao bound with singular ﬁsher information matrix, IEEE
Signal Process. Lett. 16 (2009) 453–456.
[90] G. Riba, G. Vazquez, S. Calvo, Conditional maximum likelihood frequency estimation for offset modulation,
in: IEEE International Conference on Acoustic, Speech, and Signal Processing (ICASSP), vol. 6, May 1998,
pp. 3425–3428.
[91] R. Imad, S. Houcke, M. Ghogho, Blind estimation of the phase and carrier frequency offset for LDPC coded
systems, EURASIP J. Adv. Signal Process. 2010 (2010).
[92] T. Heskes, O. Zoeter, W. Wiegerinck, Advances in Neural Information Processing. MIT Press, 2004 (Chapter
Approximate Expectation-Maximization).
[93] N. Noels, C. Herzet, A. Dejonghe, V. Lottici, H. Steendam, M. Moeneclaey, M. Luise, L. Vandendorpe,
Turbo-synchronization: an EM approach, in: IEEE International Conference on Communications (ICC),
2003, pp. 2933–2937.
[94] M. Speth, S. Fechtel, G. Fock, H. Meyr, Optimum receiver design for wireless broad-band systems using
OFDM—Part I, IEEE Trans. Commun. 47 (11) (1999) 1668–1677.
[95] Q. Huang, M. Ghogho, Synchronization in OFDM-based systems, in: F. Bader, N. Zorba (Eds.),
OFDM/OFDMA Wireless Communication Systems, Nova Publishers, 2011.
[96] G.B. Giannakis, Filterbanks for blind channel identiﬁcation and equalization, IEEE Signal Process. Lett. 4
(6) (1997) 184–187.
[97] A. Scaglione, G.B. Giannakis, S. Barbarossa, Redundant ﬁlter-bank precoders and equalizers. Part I. Uni-
ﬁcation and optimal designs and Part II. Blind channel estimation, synchronization and direct equalization,
IEEE Trans. Signal Process. 47 (7) (1999) 1988–2022.
[98] B. Muquet, Z. Wang, G. Giannakis, M. de Courville, P. Duhamel, Cyclic preﬁxing or zero padding for
wireless multicarrier transmissions?, IEEE Trans. Commun. 50 (12) (2002) 2136–2148.
[99] L. Hanzo, M. Muenster, B.-J. Choi, T. Keller, OFDM and MC-CDMA for broadband multi-user communi-
cations, John Wiley & Sons, New York, 2003.
[100] M. Morelli, Timing and frequency synchronization for the uplink of an OFDMA system, IEEE Trans.
Commun. 52 (2) (2004) 296–306.
[101] Y. Mostoﬁ, D.C. Cox, Mathematical analysis of the impact of timing synchronization errors on the perfor-
mance of an OFDM system, IEEE Trans. Commun. 54 (2) (2006) 226–230.
[102] X. Ma, H. Kobayashi, S. Schwartz, Effect of frequency offset on BER of OFDM and single carrier systems,
in: Proceedings of the IEEE International Symposium on Personal Indoor and Mobile Radio Communication,
vol. 3, 7–10 September 2003, pp. 2239–2243.
[103] K. Sathananthan, C. Tellambura, Probability of error calculation of OFDM systems with frequency offset,
IEEE Trans. Commun. 49 (11) (2001) 1884–1888.
[104] J.J. Van de Beek, M. Sandell, P.O. Borjesson, ML estimation of timing and frequency offset in OFDM
systems, IEEE Trans. Signal Process. 45 (6) (1997) 1800–1805.
[105] M.Speth,S.Fechtel,G.Fock,H.Meyr,OptimumreceiverdesignforOFDM-basedbroadbandtransmission—
Part II: a case study, IEEE Trans. Commun. 49 (4) (2001) 571–578.
[106] D. Lee, K. Cheun, Coarse symbol synchronization algorithms for OFDM systems in multipath channels,
IEEE Trans. Commun. 6 (10) (2002) 446–448.
[107] T.M. Schmidl, D.C. Cox, Robust frequency and timing synchronization for OFDM, IEEE Trans. Commun.
45 (12) (1997) 1613–1621.
[108] H. Minn, V.K. Bhargava, K.B. Letaief, A robust timing and frequency synchronization for OFDM systems,
IEEE Trans. Wireless Commun. 2 (4) (2003) 822–839.

References
91
[109] K. Shi, E. Serpedin, Coarse frame and carrier synchronization of OFDM systems: a new metric and com-
parison, IEEE Trans. Wireless Commun. 3 (4) (2004) 1271–1284.
[110] M. Ghogho, P. Ciblat, A. Swami, P. Bianchi, Training design for repetitive-slot-based CFO estimation in
OFDM, IEEE Trans. Signal Process. 57 (12) (2009) 4958–4964.
[111] P. Moose, A technique for orthogonal frequency division multiplexing frequency offset correction, IEEE
Trans. Commun. 42 (10) (1994) 2908–2914.
[112] M. Ghogho, A. Swami, Frame and frequency acquisition for OFDM, IEEE Signal Process. Lett. 15 (2008)
605–608.
[113] M. Morelli, U. Mengali, An improved frequency offset estimator for OFDM applications, IEEE Trans.
Commun. 3 (3) (1999) 75–77.
[114] M. Ghogho, A. Swami, Uniﬁed framework for a class of frequency-offset estimation techniques for OFDM,
in: IEEE ICASSP 2004, May 2004.
[115] F. Tufvesson, O. Edfors, M. Faulkner, Time and frequency synchronization for OFDM using PN-sequence
preambles, in: IEEE Vehicular Technology Conference, vol. 4, September 1999, pp. 2203–2207.
[116] D. Landstrom, S.K. Wilson, J.J. Beek, P. Odling, P.O. Borjesson, Symbol time offset estimation in coherent
OFDM systems, IEEE Trans. Commun. 50 (4) (2002) 545–549.
[117] M. Speth, F. Classen, H, Meyr, Frame synchronization of OFDM systems in frequency selective fading
channels, in: IEEE Vehicular Technology Conference 1997, 1997, pp. 1807–1811.
[118] B. Yang, K.B. Letaief, R.S. Cheng, Z. Cao, Timing recovery for OFDM transmission, IEEE J. Sel. Areas
Commun. 18 (11) (2000) 2278–2291.
[119] N.Chen,M.Tanaka,R.Heaton,OFDMtimingsynchronisationundermulti-pathchannels,in:IEEEVehicular
Technology Conference, vol. 1, April 2003, pp. 378–382.
[120] H. Zhou, Y.-F. Huang, A maximum likelihood ﬁne timing estimation for wireless OFDM systems, IEEE
Trans. Broadcast. 55 (1) (2009) 31–41.
[121] Y. Mostoﬁ, D.C. Cox, A robust timing synchronization design in OFDM systems? Part I: low-mobility cases,
IEEE Trans. Wireless Commun. 6 (12) (2007) 4329–4339.
[122] Y. Mostoﬁ, D.C. Cox, A robust timing synchronization design in OFDM systems—Part II: high-mobility
cases, IEEE Trans. Wireless Commun. 6 (12) (2007) 4340–4348.
[123] F. Daffara, O. Adami, A novel carrier recovery technique for orthogonal multicarrier systems, Eur. Trans.
Telecommun. 7 (1996) 323–334.
[124] F. Daffara, A. Chouly, Maximum likelihood frequency detectors for orthogonal multicarrier systems, in:
IEEE International Conference on Communications 1993, pp. 766–771.
[125] M. Morelli, A. Andrea, U. Mengali, Feedback frequency synchronization for OFDM applications, IEEE
Trans. Commun. 5 (1) (2001) 28–30.
[126] H. Liu, U. Tureli, A high-efﬁciency carrier estimator for OFDM communications, IEEE Trans. Commun. 2
(4) (1998) 104–106.
[127] U. Tureli, H. Liu, M.D. Zoltowski, OFDM blind carrier offset estimation: ESPRIT, IEEE Trans. Commun.
48 (9) (2000) 1459–1461.
[128] G. Santella, A frequency and symbol synchronization system for OFDM signals: architecture and simulation
results, IEEE Trans. Veh. Technol. 49 (1) (2000) 245–275.
[129] X. Ma, C. Tepedelenlioglu, G.B. Giannakis, S. Barbarossa, Non-data-aided carrier offset estimator for OFDM
with null subcarriers, IEEE J. Sel. Areas Commun. 19 (12) (2001) 2504–2515.
[130] M. Ghogho, A. Swami, G.B. Giannakis, Optimized null-subcarrier selection for CFO estimation in OFDM
over frequency selective fading channels, in: IEEE Globecom 2001, vol. 48, November 2001, pp. 202–206.
[131] H. Bolcskei, Blind estimation of symbol timing and carrier frequency offset in wireless OFDM systems,
IEEE Trans. Commun. 48 (6) (2001) 988–999.

92
CHAPTER 2 Synchronization
[132] U. Tureli, D. Kivanc, H. Liu, Experimental and analytical studies on high-resolution OFDM carrier frequency
offset estimator, IEEE Trans. Veh. Technol. 50 (2001) 629–643.
[133] M. Ghogho, A. Swami, Semi-blind frequency offset synchronization for OFDM, in: IEEE ICASSP 2002,
vol. 3, May 2002, pp. 2333–2336.
[134] M. Ghogho, A. Swami, Blind frequency-offset estimator for OFDM systems transmitting constant-modulus
symbols, IEEE Trans. Commun. 6 (8) (2002) 343–345.
[135] F. Yang, K.H. Li, K.C. Teh, A carrier frequency offset estimator with minimum output variance for OFDM
systems, IEEE Trans. Commun. 8 (11) (2004) 677–679.
[136] Y.W. Yao, G.B. Giannakis, Blind carrier frequency offset estimation in SISO, MIMO, and multiuser OFDM
systems, IEEE Trans. Commun. 53 (1) (2005) 173–183.
[137] D. Rife, R. Boorstyn, Single-tone parameter estimation from discrete-time observations, IEEE Trans. Inform.
Theory 20 (5) (1974) 591–598.
[138] J. Van de Beek, P. Borjesson, M. Boucheret, D. Landstrom, J. Arenas, P. Odling, C. Ostberg, M. Wahlqvist,
S. Wilson, A time and frequency synchronization scheme for multiuser OFDM, IEEE J. Sel. Areas Commun.
17 (11) (1999) 1900–1914.
[139] IEEE Standard for Local and metropolitan area networks Part 16: Air Interface for Broadband Wire-
less Access Systems, IEEE Std 802.16-2009 (Revision of IEEE Std 802.16-2004), vol. 29, 2009,
pp. C1–2004.
[140] D. Huang, K.B. Letaief, An interference-cancellation scheme for carrier frequency offsets correction in
OFDMA systems, IEEE Trans. Commun. 53 (7) (2005) 1155–1165.
[141] D. Marabissi, R. Fantacci, S. Papini, Robust multiuser interference cancellation for OFDM systems with
frequency offset, IEEE Trans. Wireless Commun. 5 (11) (2006) 3068–3076.
[142] S. Manohar, D. Sreedhar, V. Tikiya, A. Chockalingam, Cancellation of multiuser interference due to carrier
frequency offsets in uplink OFDMA, IEEE Trans. Wireless Commun. 6 (7) (2007) 2560–2571.
[143] S.-W. Hou, C.C. Ko, Multiple-access interference suppression for interleaved OFDMA system uplink, IEEE
Trans. Veh. Technol. 57 (1) (2008) 194–205.
[144] S. Barbarossa, M. Pompili, G.B. Giannakis, Channel-independent synchronization of orthogonal frequency
division multiple access systems, IEEE J. Sel. Areas Commun. 20 (2) (2002) 474–486.
[145] M. Morelli, C.-C.J. Kuo, M.-O. Pun, Synchronization techniques for orthogonal frequency division multiple
access (OFDMA): a tutorial review, Proc. IEEE 95 (7) (2007) 1394–1427.
[146] Z. Cao, U. Tureli, Y. Yao, Deterministic multiuser carrier-frequency offset estimation for interleaved OFDMA
uplink, IEEE Trans. Commun. 52 (9) (2004) 1585–1594.
[147] D.S. Radovic, M.M. Eric, Performance of subspace based multi-user CFO estimation for interleaved OFDMA
uplink, in: Proc. Int. Conf. Computer as a Tool, vol. 2, Belgrade, Serbia and Montenegro, November 2005,
pp. 1602–1605.
[148] J. Lee, S. Lee, K.-J. Bang, S. Cha, D. Hong, Carrier frequency offset estimation using ESPRIT for interleaved
OFDMA uplink systems, IEEE Trans. Veh. Technol. 56 (5) (2007) 3227–3231.
[149] M.-O. Pun, M. Morelli, C.-C. Kuo, Maximum-likelihood synchronization and channel estimation for
OFDMA uplink transmissions, IEEE Trans. Commun. 54 (4) (2006) 726–736.
[150] X.Y. Fu, Y.H. Li, H. Minn, A new ranging method for OFDMA systems, IEEE Trans. Commun. 6 (2) (2007)
659–669.
[151] J.-H. Lee, S.-C. Kim, Time and frequency synchronization for OFDMA uplink system using the SAGE
algorithm, IEEE Trans. Wireless Commun. 6 (4) (2007) 1176–1181.
[152] M.-O. Pun, M. Morelli, C.-C. Kuo, Iterative detection and frequency synchronization for OFDMA uplink
transmissions, IEEE Trans. Wireless Commun. 6 (2) (2007) 629–639.
[153] M. Morelli, U. Mengali, Carrier-frequency estimation for transmissions over selective channels, IEEE Trans.
Commun. 48 (9) (2000) 1580–1589.

References
93
[154] S. Sezginer, P. Bianchi, Asymptotically efﬁcient reduced complexity frequency offset and channel estimators
for uplink MIMO-OFDMA systems, IEEE Trans. Signal Process. 56 (3) (2008) 964–979.
[155] X.N. Zeng, A. Ghrayeb, Joint CFO and channel estimation for OFDMA uplink: an application of the variable
projection method, IEEE Trans. Wireless Commun. 8 (5) (2009) 2306–2311.
[156] W.C. Lindsey, F. Ghazvinian, W.C. Hagmann, K. Dessouky, Network synchronization, Proc. IEEE 73 (10)
(1985) 1445–1467.
[157] S. Bregni, A historical perspective on telecommunications network synchronization, IEEE Commun. Mag.
(1988) 150–166.
[158] B. Hamilton, X. Ma, Q. Zhao, J. Xu, ACES: adaptive clock estimation and synchronization using kalman
ﬁltering, in: Proc. MobiCom’08, 2008.
[159] J. Elson, L. Girod, D. Estrin, Fine-grained network time synchronization using reference broadcasts, in: Proc.
Fifth ACM SIGOPS Operating Syst. Review, December 2002, pp. 147–163.
[160] K. Romer, Time synchronization in ad hoc networks, in: Proc. 2nd ACM Int. Symp. Mobile Ad Hoc Net-
working Comp., 2002, pp. 173–182.
[161] M. Sichitiu, C. Veerarittiphan, Simple, accurate time synchronization for wireless sensor networks, in: Proc.
IEEE Wireless Commun. Networking Conf. (WCNC), 2003.
[162] S. Ganeriwal, R. Kumar, M.B. Srivastava, Timing-sync protocol for sensor networks, in: Proc. First Intl.
Conf. Embedded Networked Sensor Syst. (SenSys-03), 2003.
[163] J. van Greunen, J. Rabaey, Lightweight time synchronization for sensor networks, in: Proc. WSNA’03, 2003.
[164] S. Graham, P.R. Kumar, Time in general-purpose control systems: the control time protocol and an experi-
mental evaluation, in: Proc. 43rd IEEE Conf. Decision Control, 2004, pp. 4004–4009.
[165] F. Cristian, A probabilistic approach to distributed clock synchronization, Distrib. Comput. 3 (1989) 146–158.
[166] K. Arvind, Probabilistic clock synchronization in distributed systems, IEEE Trans. Parallel Distrib. Syst. 5
(5) (1994) 474–487.
[167] D. Dolev, J. Halpern, H.R. Strong, On the possibility and impossibility of achieving clock synchronization,
in: Proc. 16th Annual ACM Symp. Theory Comput. 1984.
[168] J. Lundelius, N. Lynch, An upper and lower bound for clock synchronization, Inform. Control 62 (1984)
190–204.
[169] S. Biaz, J.L. Welch, Closed form bounds for clock synchronization under simple uncertainty assumptions,
IPL: Inform. Process. Lett. 80 (3) (2001) 151–157.
[170] D.L. Mills, Internet time synchronization: the network time protocol, IEEE Trans. Commun. 39 (10) (1991)
1482–1493.
[171] D.R. Jeske, On maximum-likelihood estimation of clock offset, IEEE Trans. Commun. 53 (1) (2005) 53–54.
[172] D.R. Jeske, A. Sampath, Estimation of clock offset using bootstrap bias-correction techniques, Technometrics
45 (3) (2003) 256–261.
[173] Q. Chaudhari, E. Serpedin, K. Qaraqe, On maximum likelihood estimation of clock offset and skew in
networks with exponential distirbution, IEEE Trans. Signal Process. 56 (4) 2008 1685–1697.
[174] Mirollo, S. Strogatz, Synchronization of pulse-coupled biological oscillators, SIAM J. Appl. Math. 50 (6)
(1990) 1645–1662.
[175] D. Lucarelli, I.-J. Wang, Decentralized synchronization protoocols with nearest neighbor communications,
in: Proc. ACM SenSys, 2004.
[176] E.Mallada,A.Tang,Synchronizationofphase-coupledoscillatorswitharbitrarytopology,in:Proc.American
Control Conference (ACC’10), 2010.
[177] Y.-W. Hong, A. Scaglione, A scalable synchronization protocol for large sensor networks and its applications,
IEEE J. Sel. Areas Commun. 23 (5) (2005) 1085–1099.
[178] Q. Li, D. Rus, Global clock synchronization in sensor networks, IEEE Trans. Comput. 55 (2) (2006) 214–226.

94
CHAPTER 2 Synchronization
[179] P. Barooah, J. Hespanha, A. Swami, On the effect of asymmetric communication on distributed time syn-
chronization, in: Proc. 46th IEEE Conf. Decision Control (CDC’07), 2007.
[180] S. Sardellitti, S. Barbarossa, A. Swami, Optimal topology control and power allocation for minimum energy
consumption in consensus networks, IEEE Trans. Signal Process. 60 (1) (2012) 383–399.

3
CHAPTER
Channel Estimation, Equalization,
Precoding, and Tracking
Jitendra K. Tugnait
Department of Electrical and Computer Engineering, Auburn University, Auburn, AL, USA
2.03.1 Introduction
Multipath propagation results in a received signal that is a superposition of several delayed and scaled
copies of the transmitted signal giving rise to frequency-selective fading. It leads to intersymbol inter-
ference (ISI) at the receiver which, in turn, may lead to high error rates in symbol detection. Equal-
izers are designed to compensate for these channel distortions. One may directly design an equalizer
given the received signal, or one may ﬁrst estimate the channel impulse response and then design an
equalizer based on the estimated channel. After some processing (matched ﬁltering, for instance), the
continuous-time received signals are sampled at the baud (symbol) or higher (fractional) rate before
processing them for channel estimation and/or equalization. It is therefore convenient to work with a
baseband-equivalent discrete-time channel model. Depending upon the sampling rate, one has either
a single-input single-output (SISO) (baud rate sampling), or a single-input multiple-output (SIMO)
(fractional sampling), complex discrete-time equivalent baseband channel. Knowledge of the channel
response can be advantageously used at the transmitter to precode the information sequence to be trans-
mitted so as to simplify the equalizer complexity at the receiver and to mitigate interference in MIMO
systems.
In this chapter, we present an overview/review of various approaches to channel estimation and
equalization for wireless mobile systems with a brief discussion of channel precoding techniques.
Since approaches to channel estimation depend upon the underlying channel model, we also review
various approaches to channel modeling. In Section 2.03.2 we present the relevant channel models
including time-variant and time-invariant models. In Section 2.03.3 various channel estimation methods
are discussed. In Section 2.03.4 equalization approaches are reviewed and in Section 2.03.5 a brief
discussion of precoding approaches is presented. In Section 2.03.6 we discuss tracking to adapt to
time-varying channels.
Notation 1.
Superscripts H, ∗, T , and † denote the complex conjugate transpose, complex conjuga-
tion, transpose, and Moore-Penrose pseudo-inverse operations, respectively. The function δ(l) is the
Kronecker delta function with δ(l) = 1 if l = 0, = 0 otherwise, and IN is the N × N identity matrix.
The symbol ⊗denotes the Kronecker product, and tr(A) is the trace of a square matrix A. The (n, m)th
entry of a matrix C is denoted by [C]n,m.
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-396500-4.00003-X
© 2014 Elsevier Ltd. All rights reserved.
95

96
CHAPTER 3 Channel Estimation, Equalization, Precoding, and Tracking
2.03.2 Channel models
2.03.2.1 Time-variant (doubly selective) channels
Consider a time-varying (e.g., mobile wireless) channel (linear system) with complex baseband,
continuous-time, received signal r(t) and transmitted complex baseband, continuous-time information
signal s(t) (with symbol interval Ts seconds) related by [1]
r(t) =
 ∞
−∞
˜h(t; τ)˜s(t −τ)dτ + w(t),
(3.1)
where ˜h(t; τ) is the time-varying impulse response of the channel denoting the response of the channel
at time t to a unit impulse input at time t −τ and w(t) is the additive noise (typically white Gaussian).
A delay-Doppler spread function H( f ; τ) is deﬁned as the Fourier transform of ˜h(t; τ) with respect to
t [1,2]
H( f ; τ) =
 ∞
−∞
˜h(t; τ)e−j2π f t dt.
(3.2)
If |H( f ; τ)| ≈0 for |τ| > τd, then τd is called the (multipath) delay-spread of the channel. If
|H( f ; τ)| ≈0 for | f | > fd, then fd is called the Doppler spread of the channel. In order to cap-
ture the complexity of the physical interactions characterizing the transmission through a real channel,
˜h(t; τ) is typically modeled as a two-dimensional zero-mean random process. If ˜h(t; τ) is wide-sense
stationary in variable t, and ˜h(t; τ1) is uncorrelated with ˜h(t; τ2) for τ1 ̸= τ2 and any t, one obtains the
well-known wide-sense stationary uncorrelated scattering (WSSUS) channel [1,2, Chapter 14].
2.03.2.1.1
Tapped delay line model
We now consider a discrete-time channel model. If a linear modulation scheme is used, the baseband
transmitted signal can be represented as
˜s(t) =
∞

k=−∞
s(k)pT (t −kTs),
(3.3)
where {s(k)} is the information sequence and pT (t) is the transmit (lowpass) ﬁlter (typically a root
raised cosine ﬁlter). Therefore, the baseband signal at the receiver is given by
r(t) =
∞

k=−∞
s(k)
 ∞
−∞
˜h(t; α)pT (t −kTs −α)dα + w(t).
(3.4)
After ﬁltering with a receive ﬁlter with impulse response pR(t), the received baseband signal is given by
˜y(t) =
∞

k=−∞
s(k)
 ∞
−∞
 ∞
−∞
pR(t −β)˜h(β; α)pT (β −kTs −α)dα dβ + ˜v(t),
(3.5)

2.03.2 Channel Models
97
where ˜v(t) =

pR(τ)w(t −τ)dτ. If the continuous-time signal ˜y(t) is sampled at once every Ts sec.,
we obtain the discrete-time sequence
y(n) := ˜y(t)|t=nTs =
∞

k=−∞
s(k)h(n; n −k) + v(n) =
∞

l=−∞
h(n;l)s(n −l) + v(n),
(3.6)
where h(n;l) is the (effective) channel response at time n to a unit impulse input at time n −l and
h(n; n −k) :=
 ∞
−∞
 ∞
−∞
pR(nTs −β)˜h(β; α)pT (β −kTs −α)dα dβ.
(3.7)
Note that the noise sequence {v(n)} in (3.6) is no longer necessarily white; it can be whitened by further
time-invariant linear ﬁltering (see [1]). Henceforth, we assume that a whitening ﬁlter has been applied
to y(n), but with an abuse of notation, we will still use (3.6). For a causal system, h(n;l) = 0 for l < 0
(∀n) and for a ﬁnite length channel of maximum length Ts L, h(n;l) = 0 for l > L (∀n). In this case
we modify (3.6) as (recall the noise whitening ﬁlter)
y(n) =
L

l=0
h(n;l)s(n −l) + v(n).
(3.8)
The model (3.8) represents a time- and frequency-selective linear channel. A tapped delay line
structure for this model is shown in Figure 3.1. For a slowly (compared to the baud-rate) time-varying
system, one often simpliﬁes (3.8) to a time-invariant system as
y(n) =
L

l=0
h(l)s(n −l) + v(n),
(3.9)
where h(l) = h(0;l) is the time-invariant channel response to a unit impulse input at time 0. The model
(3.9) represents a frequency-selective linear channel with no time selectivity. It is a widely used model
for receiver design.
s(n)
D
D
s(n−2)
D
s(n−L)
×
×
×
×
h(n; 0)
h(n; 1)
h(n; 2)
h(n; L)
+
+
+
+
v(n)
y(n)
FIGURE 3.1
Tapped delay line model of frequency- and time-selective channel with ﬁnite impulse response. D represents
a unit (symbol duration) delay.

98
CHAPTER 3 Channel Estimation, Equalization, Precoding, and Tracking
Suppose that h(n;l) = h(n)δ(l). Then we have the time-selective and frequency-nonselective
channel whose output is given by
y(n) = h(n)s(n) + v(n).
(3.10)
Finally, a time-nonselective and frequency-nonselective channel is modeled as
y(n) = hs(n) + v(n),
(3.11)
where h is a random variable (or a constant).
2.03.2.1.2
Autoregressive (AR) models
It is possible to accurately represent a wide-sense stationary uncorrelated scattering (WSSUS) channel
by a large order AR model; see [3–5] and references therein. Let
˜h(n) := [h(n; 0) h(n; 1) · · · h(n; L)]T ,
(3.12)
where ˜h(n) is (L + 1) × 1 vector. Then a pth order AR model, AR(p), for ˜h(n) is given by
˜h(n) =
p

i=1
Ai ˜h(n −i) + G0 ˜w(n),
(3.13)
where Ais are the (L + 1) × (L + 1) AR coefﬁcient matrices, G0 is also (L + 1) × (L + 1) and
independent and identically distributed (i.i.d.), (L +1)×1 driving noise ˜w(n) is zero-mean with identity
covariance matrix. Suppose that we know the correlation function Rh(m) = E

˜h(n + m)˜hH(n)

for
lags m = 0, 1, . . . , p. The following Yule-Walker equation holds for (3.13) [6]:
Rh(m) =
p

i=0
AiRh(m −i) + G0GH
0 δ(m).
(3.14)
Using (3.14) for m = 1, 2, . . . , p, and the fact that Rh(−m) = RH
h (m), one can estimate Ais. Using
the estimated Ais and (3.14) for m = 0, one can ﬁnd G0GH
0 , from which one can ﬁnd (non-unique)
G0 by computing its “square root” [7, p. 358]. In [3] high values of p (several tens) have been used for
channel simulation, whereas in [4,5] only AR(1) or AR(2) models have been used where the objective
is channel estimation and related issues. An AR(1) model is given by
h(n;l) = αch(n −1;l) + wc(n),
(3.15)
where αc is the AR coefﬁcient, and the driving noise wc(n) is zero-mean complex Gaussian with variance
σ 2
wc and statistically independent of h(n−1;l). Assume that h(n;l) is also zero-mean, complex Gaussian
with variance σ 2
h . Then [8]
αc = 1
σ 2
h
E{h(n;l)h∗(n −1;l)},
σ 2
wc = σ 2
h (1 −|αc|2).
(3.16)

2.03.2 Channel Models
99
2.03.2.1.3
Basis expansion models
Basis expansion models (BEMs) have also been widely investigated to represent doubly selective chan-
nels in wireless applications [9–13], where the time-varying taps are expressed as superpositions of
time-varying basis functions in modeling Doppler effects, weighted by time-invariant coefﬁcients. Can-
didate basis functions include complex exponential (Fourier) functions [10,11], polynomials [9], and
discrete prolate spheroidal sequences [13], etc. In contrast to AR models that describe temporal variation
on a symbol-by-symbol update basis, a BEM depicts the evolution of the channel over a period (block)
of time. Intuitively, the coefﬁcients of the BEM approximation should evolve much more slowly in time
than the channel, and hence are more convenient to track in a fast fading environment.
Suppose that we include the effects of transmit and receive ﬁlters in the time-variant impulse response
˜h(t; τ) in (3.1). Suppose that this channel has a delay-spread τd and a Doppler spread fd. Consider the
kth block of data consisting of an observation window of TB symbols where the baud-rate data samples
in the block are indexed as n = ¯nk, ¯nk +1, . . . , ¯nk +TB −1, ¯nk := (k−1)TB. If 2 fdτd < 1 (underspread
channel), the complex exponential basis expansion model (CE-BEM) representation of h(n;l) in (3.8)
is given by
h(n;l) =
Q

q=1
hq(l)e jωqn, n = ¯nk, ¯nk + 1, . . . , ¯nk + TB −1,
(3.17)
where one chooses (l = 0, 1, . . . , L, and K is an integer)
T := K TB,
K ≥1,
Q ≥2⌈fdT Ts⌉+ 1,
(3.18)
ωq := 2π
T [q −(Q + 1)/2],
q = 1, 2, . . . , Q,
L := ⌊τd/Ts⌋.
(3.19)
The BEM coefﬁcients hq(l)s remain invariant during this block, but are allowed to change at the next
block, and the Fourier basis functions

e jωqn
(q = 1, 2, . . . , Q) are common for each block. If the
delay spread τd and the Doppler spread fd of the channel (or at least their upper-bounds) are known,
one can infer the basis functions of the CE-BEM [11]. Treating the basis functions as known, estimation
of a time-varying process is reduced to estimating the invariant coefﬁcients over a block of length TB
symbols. Note that the BEM period is T = K TB whereas the block size is TB symbols. If K > 1 (e.g.,
K = 2 or K = 3), then the Doppler spectrum is said to be over-sampled [14] compared to the case K = 1
where the Doppler spectrum is said to be critically sampled. In [10,11] only K = 1 (henceforth called
CE-BEM) is considered whereas [14] considers K ≥2 (henceforth called over-sampled CE-BEM).
Equation (3.17) applies to single-input single-output systems—one user and one receiver with
symbol-rate sampling. It is easily modiﬁed to handle multiuser, multiple transmit and receive antennas,
and higher than symbol rate sampling (multiple samples per symbol)—the basic representation remains
essentially unchanged.
The representation h(n;l) in (3.17) is a special case of a more general representation
h(n;l) =
Q

q=1
hq(l)φq(n),
(3.20)

100
CHAPTER 3 Channel Estimation, Equalization, Precoding, and Tracking
where {φq(n)}Q
q=1 are a set of orthogonal basis functions (over the time interval under consideration).
Examples include wavelet-based expansions as in [15], polynomial bases as in [9] and other possibilities
[16]. In discrete prolate spheroidal BEM (DPS-BEM), the ith DPS vector
ui := [ui(0), . . . , ui(TB −1)]T
(called Slepian sequence in [13], which is a time-windowed (inﬁnite) DPS sequence) is the ith eigen-
vector of a matrix C [17]:
Cui = λiui,
where [C]n,m = sin [2π(n −m) fdTs]
[π
	
n −m

]
is the (n, m)th entry of C and λ1 ≥λ2 ≥· · · ≥λTB are the eigenvalues of C. The Slepian sequences
{uq(n)} are orthonormal over the ﬁnite time interval [0, TB −1]. The modeling error of the CE-BEM can
result in a noticeable ﬂoor in BER curves [18]. The polynomial basis functions are neither time-limited
nor band-limited and their square bias varies heavily over the range of Doppler spread considered
in [13]. DPS sequences are a good alternative as a basis set to approximate bandlimited channels
alleviating the spectral leakage of CE-BEM [13]. The (inﬁnite) DPS sequences have their maximum
energy concentration in an interval with length T while being bandlimited to [−fdTs, fdTs], where u1(n)
is the unique sequence that is bandlimited and most time-concentrated, u2(n) is the next sequence having
maximum energy concentration among the DPS sequences orthogonal to u1(n), and so on [17].
Figure 3.2 shows the channel modeling errors resulting from (critically sampled) CE-BEM, DPS-
BEM and oversampled CE-BEM (K = 2 or 3) when the underlying channel is a one-tap time-selective
channel following Jakes’ spectrum. The results are based on Monte Carlo averaging over 1000 runs with
TB = 400, Ts = 25 µs and varying Doppler spreads. (The results were obtained following the procedure
in [13].) For a ﬁxed value of Q, DPS-BEM provides the best ﬁt whereas CE-BEM (no oversampling)
yields minor improvements with increasing Q. On the other hand, the basis functions in oversampled
CE-BEM are not mutually orthogonal leading to “analytical” difﬁculties. There exists a vast literature
based on CE-BEM (no oversampling) where it is assumed that physical channel is accurately described
by CE-BEM both for analysis and simulations; see e.g., [11,19–24].
2.03.2.2 Time-invariant channels
For a baud (symbol)-rate sampled system, the equivalent baseband channel model is given by (3.9) which
is a single-input single-output (SISO) complex discrete-time baseband-equivalent channel model. The
output sequence {y(n)} in (3.9) is discrete-time stationary. When there is excess channel bandwidth
[bandwidth > 1
2× (baud rate)], baud rate sampling is below the Nyquist rate leading to aliasing and
depending upon the symbol timing phase, in certain cases, causing deep spectral notches in sampled,
aliased channel transfer function [25]. Linear equalizers designed on the basis of the baud-rate sampled
channel response, are quite sensitive to symbol timing errors. Initially, in the trained case, fractional
sampling was investigated to robustify the equalizer performance against timing errors. The model
(3.9) does not apply to fractionally-spaced samples, i.e., when the sampling interval is a fraction of
the symbol duration. The fractionally sampled digital communication signal is a cyclostationary signal
[26] which may be represented as a vector stationary sequence using a time series representation (TSR)

2.03.2 Channel Models
101
0
20
40
60
80
100
120
140
160
180
200
−100
−90
−80
−70
−60
−50
−40
−30
−20
−10
0
Doppler Spread (Hz)
Normalized Mean Square Error (dB)
Modeling Error of CE− and DPS−BEM
CE−BEM: Q=3,5,7
CE−BEM: K=2, Q=5,7,9
CE−BEM: K=3, Q=5,7,9
DPS−BEM: Q=4,5,6
FIGURE 3.2
Channel modeling error for one-tap Jakes’ channel, TB = 400, Ts = 25 µs.
([26] Section 12.6). Suppose that we sample at N-times the baud rate with signal samples spaced Ts/N
sec. apart where Ts is the symbol duration. Then a TSR for the sampled signal is given by
yi(n) =
L

l=0
hi(l)s(n −l) + vi(n);
(i = 1, 2, . . . , N),
(3.21)
where now we have N samples every symbol period, indexed by i. Notice, however, that the information
sequence s(n) is still one “sample” per symbol. It is assumed that the signal incident at the receiver is
ﬁrst passed through a receive ﬁlter whose transfer function equals the square root of a raised cosine
pulse, and that the receive ﬁlter is matched to the transmit ﬁlter. The noise sequence in (3.21) is the result
of the fractional rate sampling of a ﬁltered continuous-time white Gaussian noise process. Therefore,
the sampled noise sequence is white at the symbol rate, but correlated at the fractional rate. Stack N
consecutive received samples in the nth symbol duration to form a N-vector y(n) satisfying
y(n) =
L

l=0
h(l)s(n −l) + v(n),
(3.22)
where h(n) is the vector impulse response of the SIMO equivalent channel model given by
h(n) =
 h1(n) h2(n) · · · hN(n)T ,
(3.23)
and y(n) and v(n) are deﬁned similarly.

102
CHAPTER 3 Channel Estimation, Equalization, Precoding, and Tracking
2.03.2.3 MIMO channels
A general MIMO channel model with K inputs (users, antennas, · · ·) and N outputs (receivers,
antennas, · · ·) can be formulated as in (3.48) (given later); however, it lacks “physical” parameters
(such as antenna spacing and arrangement). Representative works on MIMO channel models that incor-
porate “propagation” effects include [27–31] and references therein. The Kronecker model of [30] is
a popular analytical model for spatially-correlated MIMO channels. It models the correlation at the
receiver and at the transmitter independently, neglecting the statistical interdependence of both link
ends. Improvements upon this model include the virtual channel representation model of [29] and the
stochastic model of [31] where joint correlation at both link ends have been considered and experi-
mentally validated. These models are suitable for wireless local area networks (WLANs). For wireless
personal area networks (WPANs), a different MIMO channel model has been proposed in [28] to account
for irregular (nonuniform) antenna arrangements and other deviations.
2.03.3 Channel estimation
We ﬁrst consider three types of channel estimators within the framework of maximizing the likeli-
hood function. [Unless otherwise noted the underlying channel model is given by the time-invariant
model (3.22).] In general, one of the most effective and popular parameter estimation algorithms is the
maximum likelihood (ML) method.
Let us consider the N-vector channel model given in (3.22). Suppose that we have collected M
samples of the observation ˜y = [yT (TB −1), . . . , yT (0)]T . We then have the following linear model
˜y =
⎛
⎜⎝
s(TB −1)IN
s(TB −2)IN
· · ·
s(TB −L −1)IN
...
Block
Hankel
Matrix
s(0)IN
s(−1)IN
· · ·
s(−L)IN
⎞
⎟⎠
⎛
⎜⎝
h(0)
...
h(L)
⎞
⎟⎠+
⎛
⎜⎝
v(TB −1)
...
v(0)
⎞
⎟⎠
= T (s)˜h + ˜v,
(3.24)
where IN is an N × N identity matrix, s and ˜v are vectors consisting of samples of the input sequence
{s(n)} and noise {v(n)}, respectively, ˜h is the vector of the channel parameters, and a block Hankel
matrix has identical block entries on its block antidiagonals. Let θ be the vector of unknown parameters
that may include the channel parameters ˜h and possibly the entire or part of the input vector s. Given
the probability space that describes jointly the noise vector ˜v and possibly the input data vector s, we
can then obtain, in principle, the probability density function (pdf) of the observation ˜y. As a function
of the unknown parameter θ, the pdf of the observation f (˜y | θ) is referred to as the likelihood function.
The maximum likelihood estimator is deﬁned by the following optimization
ˆθ = arg max
θ∈ f (˜y | θ),
(3.25)
where  deﬁnes the domain of the optimization.

2.03.3 Channel Estimation
103
While the ML estimator is conceptually simple, and it usually has good performance when the sample
size is sufﬁciently large, the implementation of ML estimator is sometimes computationally intensive.
Furthermore, the optimization of the likelihood function in (3.25) is often hampered by the existence of
local maxima. Therefore, it is desirable that effective initialization techniques are used in conjunction
with the ML estimation.
2.03.3.1 Training-based channel estimation
The training-based channel estimation assumes the availability of the input vector s (as training symbols)
and its corresponding observation vector ˜y. When the noise samples are zero mean, white Gaussian,
i.e., ˜v is a zero mean, Gaussian random vector with covariance σ 2
v ITB N, the ML estimator deﬁned in
(3.25), with θ = ˜h, is given by
˜h = arg min
˜h
∥˜y −T (s)˜h∥2 = T †(s)˜h
(3.26)
where T †(s) is the Moore-Penrose pseudo-inverse of the T (s) deﬁned in (3.24). This is also the classical
linear least-squares estimator which can be implemented recursively, and it turns out to be the best (in
terms of having minimum mean square error) among all unbiased estimators and it is the most efﬁcient
in the sense that it achieves the Cramer-Rao lower bound. Various adaptive implementations can be
found in [1].
2.03.3.1.1
Time-variant channels
In case of general time-varying channels represented by (3.6), a simple generalization of [32] (see also
[11]) is to use a periodic Kronecker delta function sequence with period ¯P as training:
s(n) =

m
δ(n −m ¯P).
(3.27)
With (3.27) as input to model (3.6), one obtains
y(n) =

m
h(n; n −m ¯P) + v(n),
(3.28)
so that if ¯P > L, we have for 0 ≤i ≤L,
y(k ¯P + i) = h(k ¯P + i; i) + v(k ¯P + i).
(3.29)
Therefore, one may take the estimate of h(k ¯P; i) as
ˆh(k ¯P; i) = y(k ¯P + i) = h(k ¯P + i; i) + v(k ¯P + i).
(3.30)
For time samples between k ¯P (k an integer), linear interpolation may be used to obtain channel estimates.

104
CHAPTER 3 Channel Estimation, Equalization, Precoding, and Tracking
If we use the BEM representation (3.20), then we directly estimate the time-invariant parameters
hq(l)s. From (3.6) and (3.20) we have
y(n) =
L

l=0
Q

q=1
hq(l)φq(n)s(n −l) + v(n)
(3.31)
=
L

l=0
s(n −l)
φq(n) · · · φq(n) 



φ(n)
⎡
⎢⎣
h1(l)
...
hQ(l)
⎤
⎥⎦



h(l)
+v(n).
(3.32)
Collecting TB samples of the observations y = [y(TB −1), . . . , y(0)]T we have the linear model
y =
⎛
⎜⎝
s(TB −1)φ(TB −1) · · · s(TB −L −1)φ(TB −1)
...
...
s(0)φ(0)
· · ·
s(−L)φ(0)
⎞
⎟⎠
⎛
⎜⎝
h(0)
...
h(L)
⎞
⎟⎠+
⎛
⎜⎝
v(TB −1)
...
v(0)
⎞
⎟⎠. (3.33)
Now we have a model similar to (3.24) with a solution similar to (3.26).
2.03.3.2 Blind channel estimation
Here no training symbols are available (or exploited). Blind techniques can not resolve phase ambiguity
in the channel estimate.
2.03.3.2.1
Combined channel and symbol estimation
The simultaneous estimation of the input vector and the channel is general ill-posed; however, utilization
of qualitative information about the channel and the input can help alleviate this deﬁciency. To this end,
we consider two different types of maximum likelihood techniques based on different models of the
input sequence.
Stochastic Maximum Likelihood Estimation. While the input vector s is unknown, it may be modeled
as a random vector with a known distribution. In such a case, the likelihood function of the unknown
parameter θ = ˜h (cf. (3.24)) can be obtained by
f (˜y | ˜h) =

f (˜y|s, ˜h) f (s)ds,
(3.34)
where f (s) is the marginal pdf of the input vector and f (˜y|s, ˜h) is the likelihood function when the
input is known. Assume, for example, that the input data symbol s(n) takes, with equal probability, a
ﬁnite number ( ¯K) of values. Consequently, the input data vector s also takes values from the signal set
{s1, . . . , s ¯K }. The likelihood function of the channel parameters is then given by
f (˜y | ˜h) =
¯K

i=1
f (˜y|si, ˜h)Prob(s = si) = c
¯K

i=1
exp

−∥˜y −T (si)˜h∥2
2σ 2

,
(3.35)

2.03.3 Channel Estimation
105
where c is a constant, ∥˜y∥2 := ˜yH ˜y, and the stochastic maximum likelihood estimator is given by
˜h = arg min
˜h
¯K

i=1
exp

−∥˜y −T (si)˜h∥2
2σ 2

.
(3.36)
The maximization of the likelihood function deﬁned in (3.34) is in general difﬁcult because f (˜y | θ) is
non-convex. The Expectation-Maximization (EM) algorithm can be applied to transform the compli-
cated optimization to a sequence of quadratic optimizations. Kaleh and Vallet [33] ﬁrst applied the EM
algorithm to the equalization of communication channels with input sequence having ﬁnite alphabet
property. By using a Hidden Markov Model (HMM), they developed a batch (off-line) procedure that
includes the so-called forward and backward recursions. The complexity of this algorithm increases
exponentially with the channel memory.
To relax the memory requirements and facilitate channel tracking, “on-line” sequential approaches
have been proposed in [34] for input with ﬁnite alphabet properties under a HMM formulation. Given the
appropriate regularity conditions and a good initialization guess, it can be shown that these algorithms
converge to the true channel value.
Deterministic Maximum Likelihood Estimation. The deterministic ML approach assumes no statisti-
cal model for the input sequence {s(n)}. In other words, both the channel vector ˜h and the input source
vector s are parameters to be estimated. When the noise is zero-mean Gaussian with covariance σ 2
v ITB N,
the ML estimates can be obtained by the nonlinear least squares optimization
{˜h,s} = arg min ∥˜y −T (s)˜h∥2.
(3.37)
The joint minimization of the likelihood function with respect to both the channel and the source
parameter spaces is difﬁcult. Fortunately, the observation vector ˜y is linear in both the channel and the
input parameters individually. In particular, we have
˜y = T (s)˜h + ˜v = F(˜h)s + ˜v,
(3.38)
where
F(˜h) =
⎛
⎜⎝
h(0) · · · h(L)
...
...
h(0)
· · · h(L)
⎞
⎟⎠
(3.39)
is the so-called ﬁltering matrix. We therefore have a separable nonlinear least squares problem that can
be solved sequentially
{˜h, ˆs} = arg min
s {min
˜h
∥˜y −T (s)˜h∥2} = arg min
˜h
{min
s
∥˜y −F(˜h)s∥2}.
(3.40)
If we are only interested in estimating the channel, the above minimization can be rewritten as
˜h = arg min
˜h
∥(I −F(˜h)F†(˜h))



P(˜h)
˜y∥2 = arg min
˜h
∥P(˜h)˜y∥2,
(3.41)

106
CHAPTER 3 Channel Estimation, Equalization, Precoding, and Tracking
where P(˜h) is a projection transform of ˜y into the orthogonal complement of the range space of F(˜h),
or the noise subspace of the observation, and F†(˜h) denotes the pseudo-inverse of F(˜h). Discussions
of algorithms of this type can be found in [35].
Similar to the HMM for statistical maximum likelihood approach, the ﬁnite alphabet properties of
the input sequence can also be incorporated into the deterministic maximum likelihood methods. These
algorithms, ﬁrst proposed by Seshadri [36] and Ghosh and Weber [37], iterate between estimates of the
channel and the input. At iteration k, with an initial guess of the channel ˜h(k), the algorithm estimates
the input sequence s(k) and the channel ˜h(k+1) for the next iteration by
s(k) = arg min
s∈S ∥Y −F(˜h(k))s∥2,
(3.42)
˜h(k+1) = arg min
˜h
∥˜y −T (s(k))˜h∥2,
(3.43)
where S is the (discrete) domain of s. The optimization in (3.43) is a linear least squares problem
whereas the optimization in (3.42) can be achieved by using the Viterbi algorithm [1]. Seshadri [36]
presented blind trellis search techniques. Reduced-state sequence estimation was proposed in [37].
Raheli et al. proposed a per-survivor processing technique in [38]. The convergence of such approaches
is not guaranteed in general. Interesting examples have been provided in [39] where two different
combinations of ˜h and s lead to the same cost ∥˜y −T (s)˜h∥2.
2.03.3.2.2
The methods of moments
Although the ML channel estimator discussed in Section 2.03.3.2.1 usually provides better performance,
the computation complexity and the existence of local optima are the two major difﬁculties. Therefore,
“simpler” approaches have also been investigated.
SISO Channel Estimation. For baud-rate data, second-order statistics of the data do not carry enough
information to allow estimation of the channel impulse response as a typical channel is nonminimum-
phase. On the other hand, higher order statistics (in particular, fourth-order cumulants) of the baud-rate
(or fractional rate) data can be exploited to yield the channel estimates to within a scale factor. Given the
mathematical model (3.9), there are two broad classes of direct approaches to channel estimation, the
distinguishing feature among them being the choice of the optimization criterion. All of the approaches
involve (more or less) a least-squares error measure. The error deﬁnition differs, however, as follows:
•
Fitting error: Match the model-based higher-order (typically fourth-order) statistics to the estimated
(data-based) statistics in a least-squares sense to estimate the channel impulse response, as in [40,41],
for example. This approach allows consideration of noisy observations. In general, it results in a
nonlinear optimization problem. It requires availability of a good initial guess to prevent convergence
to a local minimum. It yields estimates of the channel impulse response.
•
Equation error: It is based on minimizing an “equation error” in some equation which is satisﬁed
ideally. The approaches of [42,43] (among others) fall in this category. In general, this class of
approaches results in a closed-form solution for the channel impulse response so that a global
extremum is always guaranteed provided that the channel length (order) is known. These approaches
may also provide good initial guesses for the nonlinear ﬁtting error approaches. Quite a few of these
approaches fail if the channel length is unknown.
Further details may be found in [44] and references therein.

2.03.3 Channel Estimation
107
SIMO Channel Estimation. Here we will concentrate upon second-order statistical methods. For
single-input multiple-output vector channels the autocorrelation function of the observation is sufﬁcient
for the identiﬁcation of the channel impulse response up to an unknown constant [45,46], provided that
the various subchannels have no common zeros. This observation led to a number of techniques under
both statistical and deterministic assumptions of the input sequence [35]. By exploiting the multichannel
aspects of the channel (e.g., crosscorrelation among the outputs of various subchannels), many of these
techniques lead to a constrained quadratic optimization
˜h = arg min
||˜h||=1
˜hH Q(˜y)˜h,
(3.44)
where Q(˜y) is a positive deﬁnite matrix constructed from the observation. Asymptotically (either as the
sample size increases to inﬁnity or the noise variance approaches to zero), these estimates converge to
true channel parameters.
2.03.3.3 Semi-blind approaches
Semi-blind approaches utilize a combination of training-based and blind approaches. Here we present
a brief discussion about the idea and refer the reader to the survey [47] for details. The objective of
semi-blind channel estimation (and equalization) is to exploit the information used by blind methods as
well as the information exploited by the training-based methods. Semi-blind channel estimation assumes
additional knowledge of the input sequence. Speciﬁcally, part of the input data vector is known. Both the
statistical and deterministic maximum likelihood estimators remain the same except that the likelihood
function needs to be modiﬁed to incorporate the knowledge of the input. However, semi-blind channel
estimation may offer signiﬁcant performance improvement over either the blind or the training based
methods as demonstrated in the evaluation of Cramer-Rao lower bound in [47].
Therearemanygeneralizationsofblindchannelestimationtechniquestoincorporateknownsymbols.
In [48], Tsatsanis and Cirpan extended the approach of Kaleh and Vallet by restricting the transition
of hidden Markov model. In [49], the knowledge of the known symbol is used to avoid the local
maxima in the maximization of the likelihood function. A popular approach is to combine the objective
function used to derive blind channel estimator with the least squares cost in the training-based channel
estimation. For example, a weighted linear combination of the cost for blind channel estimator and that
for the training based estimator can be used [50,51].
2.03.3.4 Superimposed training-based approaches
In the superimposed training (hidden pilots) based approach, one takes
s(n) = b(n) + c(n),
(3.45)
where {b(n)} is the information sequence and {c(n)} is a non-random periodic training (pilot) sequence.
Exploitation of the periodicity of {c(n)} allows identiﬁcation of the channel without allocating any
explicit time slots for training, unlike traditional training methods. There is no loss in data transmission
rate. On the other hand, some useful power is wasted in superimposed training which could have
otherwise been allocated to the information sequence. This lowers the effective signal-to-noise ratio
(SNR) for the information sequence and affects the bit error rate (BER) at the receiver.

108
CHAPTER 3 Channel Estimation, Equalization, Precoding, and Tracking
Superimposed training-based approaches have been discussed in [52–54] for SISO systems.
A block transmission method has been proposed in [55,56] where a data-dependent component is
added to the superimposed training such that interference due to data (information sequence) is greatly
reduced in channel estimation at the receiver. This method is applicable to time-invariant channels
only and it requires “data-blocking” for block transmissions and insertion of a cyclic preﬁx in each
data block. Its extension to a class of time-variant channels is given in [57]; see also [58]. The UTRA
speciﬁcation for 3G systems [59] allows to adopt a spread pilot (superimposed) sequence in the base
station’s common pilot channel, which is suitable for downlinks. Periodic superimposed training for
channel estimation via ﬁrst-order statistics for SISO systems have been discussed in [60–63]. In [64]
performance bounds for training and superimposed training-based semiblind SISO channel estimation
for time-varying ﬂat fading channels have been discussed.
2.03.3.5 MIMO channel estimation
All of the channel estimation approaches described earlier apply to MIMO channels; however, efﬁcacy
of the approaches depends upon the underlying analytical model used. For MIMO channel estimation
in correlated fading enviroments, Chen and su [27] presents two analytical MIMO channel models and
low-complexity iterative channel estimation methods based on these models, exploiting the optimal
training sequences proposed in [65,66]. Further details may be found in these papers and references
therein.
2.03.4 Equalization
A communication channel is typically modeled as a linear system whose output is corrupted by additive
noise. Equalizers are designed to compensate for channel distortions as well as noise. One may directly
design an equalizer given the received signal, or one may ﬁrst estimate the channel impulse response
and then design an equalizer based on the estimated channel. The structure of the equalizer is dictated
by channel models, computational complexity and possible exchange of information with a channel
(error correction) decoder.
2.03.4.1 Linear equalization
The most common channel equalizer structure is a linear transversal ﬁlter. Given model (3.9) for the
baud-rate sampled received signal, the linear transversal equalizer output ˆs(k) is an estimate of s(k)
given by
ˆs(k) =
Ne

n=−Ne
c(n)y(k −n),
(3.46)
where {c(n)}n=Ne
n=−Ne are the (2Ne +1)-tap weight (equalizer) coefﬁcients of the (2Ne +1)-tap equalizer.
Two criteria have found widespread use in optimizing the equalizer coefﬁcients: peak distortion crite-
rion and mean-square error (MSE) criterion. Under the MSE criterion one chooses c(n)s to minimize
E{|ˆs(k) −s(k)|2}. Linear equalizers designed on the basis of the baud-rate sampled received signal are
quite sensitive to symbol timing errors [25]. Therefore, fractionally-spaced linear equalizers (typically

2.03.4 Equalization
109
with twice the baud-rate sampling: oversampling by a factor of two) are quite widely used to miti-
gate sensitivity to symbol timing errors. A fractionally spaced equalizer (FSE) in the linear transversal
structure has the output
ˆs(k) =
Ne

n=−Ne
 N

i=1
ci(n)yi(k −n)
!
,
(3.47)
where {ci(n)}n=Ne
n=−Ne are the (2Ne +1) tap weight coefﬁcients of the ith sub-equalizer. Note that the FSE
outputs data at the symbol rate. Various criteria and cost functions exist to design the linear equalizers
in both batch and recursive (adaptive) form [1, Chapters 10, 14].
For time-varying channels the equalizer coefﬁcients c(n) or ci(n) in (3.46) and (3.47), respectively,
arealsofunctionsofk.AnalternativeistouseeitheraBEM-basedequalizerwithtime-invariantequalizer
coefﬁcients coupled with time-varying exponential basis function [67] or a Kalman ﬁxed-lag smoother
(Kalman Detector) [68]. To illustrate the Kalman detector, consider a multi-input multi-output (MIMO)
channel with K inputs (users, antennas, . . .) and N outputs (receivers, antennas, . . .); one can adapt this
easily to single-input single-output (SISO) or single-input multi-output (SIMO) systems. Let {sk(n)}
denote kth user’s information sequence that is input to the time-varying channel with discrete-time
response {hk(n;l)} (channel response for the kth user at time instance n to a unit input at time instance
n −l). We assume that {sk(n)}s are mutually independent and identically distributed (i.i.d.) with zero
mean and variance E{sk(n) s∗
k (n)} = σ 2
sk = σ 2
s for k = 1, 2, . . . , K. Then, at symbol-rate sampling,
the noisy N-column channel output vector is given by (n = 0, 1, . . .)
y(n) =
K

k=1
L

l=0
hk(n;l)sk(n −l) + v(n),
(3.48)
where the N-column vector v(n) is zero-mean, white, uncorrelated with sk(n), complex Gaussian noise,
with the autocorrelation E{v(n + τ)vH(n)} = σ 2
v INδ(τ). Deﬁne
s(n) := [ s1(n) s2(n) · · · sK (n)]T
H(n;l) := [ h1(n;l) h2(n;l) · · · hK (n;l)].
Then we may rewrite (3.48) as
y(n) =
L

l=0
H(n;l)s(n −l) + v(n).
(3.49)
2.03.4.1.1
Kalman detector (KD)
The Kalman ﬁlter, together with a quantizer, acts as the symbol detector at the receiver end. The state
and the measurement equations are given by
sd(n) = sd(n −1) + ¯s(n) + ˜s(n),
(3.50)
y(n) = ˜Hd(n)sd(n) + v(n),
(3.51)

110
CHAPTER 3 Channel Estimation, Equalization, Precoding, and Tracking
with the following deﬁnitions
sd(n) := 
sT (n) sT (n −1) · · · sT (n −d)
T ,
¯s(n) := E{s(n)},
˜s(n) := s(n) −¯s(n),
 :=
"
0T
d
0
Id
0d
#
⊗IK ,
 :=

1 0T
d
T ⊗IK ,
˜Hd(n) := [ ˆH (n; 0)
ˆH (n; 1) · · ·
ˆH(n; L) 0N×K(d−L)]
where s(n) is K-column vector of symbols (data or training), ˆH(n;l) is the known or estimated N × K
channel matrix and integer d ≥L (it will also be the equalization delay). Assume data symbols are
zero-mean and white. If s(n) is a data symbol, we have ¯s(n) = 0, ˜s(n) = s(n) and σ 2
s (n) = σ 2
s ; if s(n)
is a training symbol, ¯s(n) = s(n), ˜s(n) = 0 and σ 2
s (n) = 0.
Kalman ﬁltering for the system described by (3.50) and (3.51) is initialized with
ˆsd(−1|−1) = 0K(d+1) and P(−1|−1) = T ,
where ˆsd(k|m) denotes the estimate of sk(p) given the observations {y(n)}m
n=0, and P(k|m) denotes the
error covariance matrix of ˆsd(k|m), deﬁned as
P(k|m) := E{[ˆsd(k|m) −sd(k)][ˆsd(k|m) −sd(k)]H}.
Then recursive ﬁltering (for n = 0, 1, . . .) is applied via the following steps:
1. Time update:
ˆsd(n | n −1) = ˆsd(n −1 | n −1) + ¯s(n),
P(n | n −1) = P(n −1 | n −1)T + σ 2
s (n)T ;
2. Kalman gain:
Pη(n) = σ 2
v IN + ˜Hd(n)P(n | n −1) ˜HH
d (n),
K(n) = P(n | n −1) ˜HH
d (n)P−1
η (n);
3. Measurement update:
ˆsd(n|n) = ˆsd(n|n −1) + K(n)

y(n) −˜Hd(n)ˆsd(n|n −1)

,
P(n|n) =

IK(d+1) −K(n) ˜Hd(n)

P(n|n −1).
The estimated state vector is given by
ˆsd(n | n) = [ ˆsT (n | n)
ˆsT (n −1 | n) · · ·
ˆsT (n −d | n)]T
and we extract its last (K-column vector) term ˆs(n −d | n) as the desired equalized output for K-users
with equalization delay d. Finally, we hard-quantize ˆs(n −d | n) to acquire the detected symbols.

2.03.4 Equalization
111
When using the estimated channel, one may rewrite the received signal (3.48) as
y(n) =
L

l=0
ˆh(n;l)s(n −l) +
L

l=0
$
h(n;l) −ˆh(n;l)
%
s(n −l) + v(n)



=:˜v(n)
,
(3.52)
where the “effective” noise is ˜v(n) instead of v(n). In order to compensate for this channel estimation
error, as a ﬁrst-order approximation, one may wish to take the variance of ˜v(n) in (3.52) to be larger
than σ 2
v , the variance of v(n).
2.03.4.2 Decision feedback equalization
Linear equalizers do not perform well when the underlying channels have deep spectral nulls in the
passband. Several nonlinear equalizers have been developed to deal with such channels. One of them
Decision Feedback Equalizer (DFE) is a nonlinear equalizer that employs previously detected symbols
to eliminate the ISI due to the previously detected symbols on the current symbol to be detected. The
use of the previously detected symbols makes the equalizer output a nonlinear function of the data. DFE
can be symbol-spaced or fractionally spaced.
In [69,70] MMSE design of ﬁnite-length DFEs have been considered for time-invariant channels.
Their approach extends trivially to time-varying channels. We now discuss application of their approach
to model (3.48).
The DFE structure is shown in Figure 3.3 to equalize the delayed symbols s(n −d), with the
feed-forward (FF) and feed-back (FB) ﬁlters. Since each measurement y(n) contains inter-symbol-
interference (ISI) caused by prior symbols, DFE is designed to reduce ISI and to recover s(n) using FIR
ﬁlters. The FF ﬁlter takes current and prior measurements y f as its input to get information correlated
with ISI and to remove its effect.
Stack the inputs of the FF ﬁlter with l f taps at time n into a “tall” vector
y f (n) :=

yT (n) yT (n −1) · · · yT (n −l f + 1)
T ,
where y(n) is N -column vector and also deﬁne v f (n) likewise. Then, the received signal is given as
y f (n) = H(n)s f (n) + v f (n),
(3.53)
FIGURE 3.3
Decision-feedback equalizer (DFE).

112
CHAPTER 3 Channel Estimation, Equalization, Precoding, and Tracking
with
H(n) :=
⎡
⎢⎣
h(n; 0) · · ·
h(n; L)
...
...
...
h(n −l f + 1; 0) · · · h(n −l f + 1; L)
⎤
⎥⎦
s f (n) :=

sT (n) sT (n −1) · · · sT (n −l f −L + 1)
T
where h(n;l) is N × K matrix channel response at time n to a unit input at time n −l and s(n) is
K-column vector. As shown in Figure 3.3, the input to the FB ﬁlter comes from the decision output,
denoted by ˘s f (n −d). The FB ﬁlter uses prior symbol decisions to cancel the trailing ISI by mapping
the estimate ˆs f (n −d) to the closest point in the symbol constellation. We deﬁne the input vector of
FB ﬁlter with lb taps as
sb(n) :=

˘sT (n −d)
˘sT (n −d −1) · · ·
˘sT (n −d −lb)
T .
The estimate of the information symbol, ˆs(n −d) is obtained by combining the outputs of FF and
FB ﬁlters and can be written at time n with delay d as
ˆs(n −d) =
l f −1

i=0
FT
i (n)y(n −i) −
lb

j=1
B j(n)˘s
	
n −d −j

,
(3.54)
where Fi(n)s (that are N × K matrices) and B j(n)s (that are K × K matrices) are the taps of FF and
FB time-varying ﬁlters at time n, and ˘s(n −d −j) is the hard decision of ˆs(n −d −j). The estimate
ˆs(n −d) is also fed into the quantizer to obtain the symbol decision ˘s(n −d). Let F(n) and B(n) denote
the vectors of time-varying taps of FF and FB ﬁlters,
F(n) :=
$
FT
0 (n) FT
1 (n) · · · FT
l f −1(n)
%T
,
B(n) :=
 I B1(n) B2(n) · · · Blb(n)T ,
then the error signal is given by
˜s(n −d) = s(n −d) −ˆs(n −d) = B(n)sb(n) −F(n)y f (n).
(3.55)
Assuming the decisions {˘s(n)} are correct and equal to {s(n)}, we can solve a nonlinear optimization
problem which minimizes the variance of the error signal in (3.55),
min
{F(n),B(n)} E
&&B(n)sb(n) −F(n)y f (n)
&&2
.
(3.56)
Solve a standard linear least-mean-squares estimation problem over F(n) with B(n) ﬁxed and then we
have a constrained optimization problem; note that the leading entry of B(n) is the identity matrix.
Therefore, the FF and the FB time-varying ﬁlters of the MMSE-DFE are given by [69]
BMMSE(n) = R−1
δ (T R−1
δ )−1,
(3.57)
FMMSE(n) = R−1
yy (n)RH
sy(n)BMMSE(n),
(3.58)

2.03.4 Equalization
113
where
 := [1 0 0 · · · 0 ]T ⊗IK ,
Rδ := Rss(n) −Rsy(n)R−1
yy (n)RH
sy(n)
= 
" 1
σ 2v
H(n)HH(n) + 1
σ 2s
INl f
#−1
H.
By the assumption that {s(n)} are independent and identically distributed (i.i.d.) with variance σ 2
s , and
based on (3.53), we have
Rss(n) := E

sb(n)sH
b (n)

= σ 2
s IK
	
lb+1

,
Rsy(n) := E

sb(n)yH
f (n)

= σ 2
s H H(n),
Ryy(n) := E

y f (n)yH
f (n)

= σ 2
s H(n)HH(n) + σ 2
v INl f ,
where
sb(n) = s f (n),
 :=
0(lb+1)×d
Ilb+1
0(lb+1)×(l f +L−d−lb−1)

⊗IK .
Using (3.57) and (3.58) in (3.54), we have the symbol estimate {ˆs(n −d)}.
2.03.4.3 Maximum likelihood sequence detection
Maximum Likelihood Sequence Detector (MLSD) estimates the information sequence to maximize
the joint probability of the received sequence conditioned on the information sequence. It is sequence
estimator compared to the linear equalizers and DFE which are symbol-by-symbol detectors. For a
scalar system a detailed discussion may be found in [1]; for MIMO channels see [71, Section 7.8]. The
optimal equalization methods for minimizing sequence error rate or the bit error rate (BER) are based
on MAP (maximum a posteriori) estimation, which turns into maximum likelihood (ML) estimation
when the transmitted symbols are equally likely. For instance, see Viterbi algorithm (VA) [1,72,73]
for ML sequence estimation and BCJR algorithm [74] for MAP sequence estimation. The MAP/ML-
based solutions often suffer from high computational load for channels with long memory or large
constellation sizes. For model (3.9), the ML estimate of the channel input sequence s(n) based on
a sequence of channel output {y(n)}TB
n=1 and given knowledge of the channel, can be obtained by
maximizing the likelihood function, or equivalently, by minimizing
TB

n=1
&&&&&y(n) −
N

l=0
h(l)s(n −l)
&&&&&
2
.
(3.59)
If the symbol alphabet size is M, then the Viterbi algorithm can be implemented by denoting M L states
as all possible L-tuples of (s(n), s(n −1), . . . , s(n −L + 1)). The trellis is determined by the symbol
alphabet S while the metrics of the Viterbi algorithm depend upon the channel.

114
CHAPTER 3 Channel Estimation, Equalization, Precoding, and Tracking
2.03.4.4 Turbo equalization
In turbo equalization one exploits the information obtained from a channel decoder to improve equal-
ization. A practical digital communication system has a forward error correction (FEC) channel encoder
at the transmitter which adds redundancies to the information symbols before transmitting the encoded
sequence over the channel. At the receiver, compensation for channel distortions is the task of equalizers
while subsequent recovery of the data symbols from the equalized (and quantized) symbols making
use of the FEC encoding is the task for the channel decoder. Typically these two tasks are considered
separately (to reduce computational complexity) with limited interaction between the two [75]. An
optimal joint processing of the equalization and decoding steps is usually impossible due to complexity
considerations. A number of iterative receiver algorithms repeat the equalization and decoding tasks
on the same set of received data, where feedback information from the decoder is incorporated into the
equalization process. This method, called turbo equalization, was originally developed for concatenated
convolutional codes (turbo code [76]) and is now adapted to various communication problems.
Communicating soft information probability distribution between the equalizer and the decoder,
instead of hard information (symbol estimates only), improves the BER performance but usually requires
more complex decoding algorithms. State-of-the-art systems for a variety of communication channels
employ convolutional codes and ML equalizers together with an interleaver after the encoder and a
deinterleaver before the decoder [75]. Interleaving shufﬂes symbols within a given time frame or block
of data and thus decorrelates error events introduced by the equalizer between neighboring symbols. The
MAP/ML-based solutions often suffer from high computational load for channels with long memory
or large constellation sizes (expensive equalizer) or convolutional codes with long memory (expensive
decoder).Thissituationisexacerbatedbytheneedtoperformequalizationanddecodingseveraltimesfor
each block of data. A major research issue is thus the complexity reduction of such iterative algorithms.
2.03.4.4.1
Principle of turbo equalization
Consider a simple transmitter where a sequence of data b(n′) = [b1(n′), b2(n′), . . . , bk0(n′)] ∈{1, 0}k0
is encoded to the code symbols c(n′) = [c1(n′), c2(n′), . . . , cn0(n′)] ∈{1, 0}n0 with a code rate
Rc = k0/n0, which is interleaved in a block and then mapped into binary phase shift keying (BPSK)
symbols. Figure 3.4 depicts the receiver structure for turbo equalization [77], where both the soft-input
soft-output (SISOf: we use subscript f to distinguish between single-input single-output abbreviated as
SISO and soft-input soft-output abbreviated as SISOf) equalizer and SISOf decoder are of the MAP type.
The extrinsic log-likelihood ratios (LLRs), Le{c(·)} are transferred iteratively between the equalizer
FIGURE 3.4
A turbo equalization receiver.

2.03.4 Equalization
115
and decoder. [The subscript “e” for representing “extrinsic,” the superscript “E” and “D” for output
of “Equalizer” and “Decoder” respectively]. The MAP equalizer computes the a posteriori probabili-
ties (APPs) given Tr received symbols, P

ci(n) = b | y(l), 1 ≤l ≤Tr

, b ∈{1, 0} and generates the
extrinsic LLR as (a posteriori LLR – a priori LLR)
L E
e {ci(n)} := ln P{ci(n) = 1 | y(l), 0 ≤l < Tr}
P{ci(n) = 0 | y(l), 0 ≤l < Tr} −ln P{ci(n) = 1}
P{ci(n) = 0}



=:L{ci(n)}
.
(3.60)
The a priori LLR of the MAP equalizer, L{ci(n)} is provided by the interleaved output of the MAP
decoder at the previous iteration but L{ci(n)} = 0 for the ﬁrst iteration. The extrinsic LLRs LE
e {c(n)}
produced by the MAP demodulator is sent to the MAP decoder as the a priori LLRs for channel
decoding. Based on the a priori LLRs and the channel code constraints, the MAP decoder computes
the APPs P{ci(n′) = b | LE
e {c(l)}, 1 ≤l ≤Tr}, b ∈{1, 0} and generates the extrinsic LLR as
L D
e {ci(n′)} := ln P{ci(n′) = 1 | L{c(l)}, 0 ≤l < Tr}
P{ci(n′) = 0|L{c(l)}, 0 ≤l < Tr} −ln P

ci(n′) = 1

P{ci(n′) = 0}



=:L{ci(n′)}
.
(3.61)
The extrinsic output of the MAP decoder is fed back to the MAP equalizer iteratively. Note that
(3.60) and (3.61) are valid only if the a posteriori outputs are independent of the a priori inputs
for the equalizer and the decoder. Assuming ideal interleaver between the equalizer and the decoder,
we can apply the turbo principle and the correct ordering of the LLRs L

c(n′)

= π−1 
LE
e {c(n)}

and
L{c(n)} = π

LD
e

c(n′)

, which are input to the MAP decoder and the MAP equalizer respectively.
The MAP decoder also compute the a posteriori probabilities of the input data bit and then the data
estimate ˆb(n′) = [ˆb1(n′), ˆb2(n′), . . . , ˆbk0(n′)] as
ˆbi(n′) = arg max
b∈{1,0} P{bi(n′) = b | L{c(l)}, 1 ≤l ≤Tr}.
(3.62)
By combining a MAP equalizer and a MAP decoder, and exchanging probabilistic information about
data symbols iteratively, turbo equalization usually can achieve close-to-optimal performance but much
lower complexity [77,78]. In [79], a turbo-equalization-like system using linear equalizers based on
soft interference cancellation and linear minimum mean-square error (MMSE) ﬁltering is proposed as
part of a multiuser detector for CDMA. Based on this work, a variety of SISOf equalizers employing
linear MMSE and decision feedback equalization (DFE) are proposed in [75,80,81].
2.03.4.4.2
Turbo equalization for doubly-selective channels
For doubly-selective channels, an adaptive SISOf equalizer has been presented in [5], using extended
Kalman ﬁlter (EKF) to incorporate channel estimation into the equalization process. This adaptive soft
nonlinear Kalman equalizer takes the soft decisions of data symbols from the SISOf decoder as its a
priori information, and performs equalization process iteratively. With such an approach, the proposed
scheme jointly optimizes the estimates of the channel and data symbols in each iteration. This avoids
the common drawback in separate channel estimation and equalization/detection approach in that the

116
CHAPTER 3 Channel Estimation, Equalization, Precoding, and Tracking
correlation between channel estimate and data symbol decision is considered. The complexity of the
method of [5] is comparable to that of the turbo equalizers using linear ﬁlters [82–84], and is usually
much lower than that of the ML/MAP based joint channel estimation and data detection schemes.
Based on the turbo equalization approach proposed in [5] and CE-BEM, an adaptive turbo equalizer
with nonlinear Kalman ﬁltering has been proposed in [85]. It is discussed in more detail in later under
adaptive channel estimation and equalization.
2.03.5 Precoding
Thus far we have discussed channel estimation and equalization at the receiver. The basic idea behind
channel precoding is that if the channel state information (CSI) is known at the transmit side, one can
move the “equalizer” to the transmitter thereby simplifying the equalizer at the receiver and/or minimiz-
ing noise enhancement at the receiver [1,86–88]. In the SISO case precoding helps in ISI mitigation. In
the MIMO case the objective is both ISI cancellation and multiuser/multiantenna interference mitiga-
tion. The book [87] provides a recent comprehensive review of recent advances, and [89,90] are good
review articles for SISO and MIMO channels, respectively.
2.03.5.1 Precoding for SISO channels
Precoding the information symbols at the transmitter with full knowledge of CSI to mitigate ISI
was ﬁrst proposed in [86,88]. Since then it has been generalized to a wide variety of scenarios
[87,89,90]. In the original works of [86,88], real-valued M ary PAM (pulse amplitude modulation)
signal set was considered which is what we do here. The information alphabet is taken from the set
A := {±1, ±3, . . . , ±(M −1)}. Consider the channel given by (3.9). Unlike (3.9), the information
symbol s(n) is precoded to x(n) chosen from A as follows
x(n) = s(n) −
L

l=1
˜h(l)x(n −l) modulo 2M
where
˜h(l) = h(l)/h(0).
(3.63)
The transmitter transmits the precoded sequence {x(n)} instead of {s(n)} over the channel represented
by (3.9). At the receiver one has y(n) = 'L
l=0 h(l)x(n −l) + v(n). By (3.63) there exists a unique
integer b(n) such that
x(n) = s(n) −
L

l=1
˜h(l)x(n −l) + 2Mb(n) ∈(−M, M].
(3.64)
Using z-transform of the sequences in (3.64) we have
X(z) = S(z) −
( H(z)
h(0) −1
)
X(z) + 2M B(z).
(3.65)
Therefore at the receiver we have the z-transform of the received sequence {y(n)} as
Y(z) = X(z)H(z) + V (z) = h(0)(S(z) + 2M B(z)) + V (z).
(3.66)
Thus there is no ISI in (3.66) unlike (3.9).

2.03.5 Precoding
117
2.03.5.2 Precoding for MIMO channels
This is a very active area of current research [87,90] and our overview will be quite brief. The basic idea
here is to map a block of information symbols si into a larger block of data xi via some linear trans-
formation (precoding) xi = Fsi), and the precoded symbol block xi is then modulated and transmitted
over the channel. At the receiver one designs a decoder G to operate on the noisy received signal block
yi = Hxi + vi (H represents the channel effect) to yield the symbol block estimate ˆsi = GHxi + Gvi.
The structure of F, the redundancy added per block and the design criteria for the choice of precoder-
decoder pair F and G together with the underlying channel matrix H dictate the resulting performance
of the system.
Consider (3.49) with K users (transmit antennas), N receive antennas and input of precoded symbols
x(n) instead of information symbols s(n). Following [91], for some integer M > 0, let P = M + L
and deﬁne the blocks
xi = vec
	
[x(i P), x(i P + 1), . . . , x(i P + P −1)]

,
(3.67)
yi = vec
	
[y(i P + L), y(i P + 1), . . . , y(i P + P −1)]

,
(3.68)
where xi is K P ×1 and yi is N M ×1. In (3.68) the ﬁrst L vectors have been deleted to cancel interblock
interference (IBI); an alternative is to zero-pad the tail of every block si [91]. From (3.49), (3.67), and
(3.68), one can deduce
yi = H xi + vi,
(3.69)
where H is an N M ×K P block-banded matrix and it becomes a block Toeplitz matrix for time-invariant
channels. A block of Ns information symbols si is precoded as
xi = Fsi
where
Ns ≤min(K P, N M).
(3.70)
In [91] under additive white Gaussian noise, various designs of precoder-decoder pairs F, G are
considered. Let
MSE(F, G) = E{∥ˆsi −si∥2 | F, G}.
(3.71)
For given F and H, decoder G is chosen to minimize MSE(F, G). Then under a transmit power or
similar constraint, F is chosen to minimize a function of MSE(F, Gopt).
The joint linear precoder/decoder design is in general a complicated non-convex problem [87]. The
linear precoder/decoder optimization decouples the MIMO channel into parallel subchannels if the
criterion is the minimization of the weighted sum of MSEs of all subchannels. Note also that MSE is
not the only criterion for precoder design; other criteria include maximization of SNR, maximization
of information rate, and minimization of bit error probability [87].
2.03.5.3 Precoding with partial or no CSI at transmitter
When the channel is time-varying, the assumption of knowledge of CSI at the transmitter is not entirely
justiﬁed. Thenanappropriateapproachistodesignprecoder/decoderonthebasisofthestatisticalknowl-
edgeoftheCSIorresorttoblindmethods.Forprecoderdesignsusingtheﬁrst-andsecond-orderstatistics
of the channels at the transmitter, see [92] and references therein. Precoding can also facilitate blind
channel estimation and equalization in the absence of any training; see [93,94] and references therein.
A fairly comprehensive review of some of these issues and techniques may be found in [87,90].

118
CHAPTER 3 Channel Estimation, Equalization, Precoding, and Tracking
2.03.6 Tracking
2.03.6.1 Adaptive channel estimation for slowly varying channels
When the channel characteristics vary slowly with time, recursive implementations of the “traditional”
(linear or DFE) equalizers aided with initial transmission of a training sequence work well [1, Chapter
11]. The equalization parameters are often updated through the MMSE criterion. This requires that a
known channel input sequence be transmitted initially. Adaptive channel equalizers begin adaptation
with the assistance of a known training sequence transmitted during the initial training stage by the
transmitter. Since the input signal is available, adaptive algorithms can be used to adjust the equalizer
parameters by minimizing the MSE between the equalizer output and the known channel input with
an equalization delay s(n −d). After training, equalizer parameters should be sufﬁciently close to
the desired settings such that much of the ISI is removed. As the channel input can now be correctly
recovered from the equalizer output through a decision device (hard quantizer), the second (opera-
tional) stage can begin. In the operational stage, the receivers typically switch to decision-directed
mode where the equalized signal is sent to a symbol detector and the detected symbols are used as
a (pseudo-)training sequence to update equalizer coefﬁcients. Baud-rate linear transversal equalizers,
FSE and DFE all can be updated in this way. During either stage, the equalizer parameters can be
determined using the well-known recursive least-squares (RLS) or least mean square (LMS) algorithms
[1,70].
In the absence of training, blind equalizers may be employed; they tend to be much slower in
convergence and tracking.
2.03.6.2 Block-adaptive channel estimation using CE-BEM
Here we summarize the time-multiplexed training approach of [11]. In [11] each transmitted block
of symbols {s(n)}TB−1
n=0
is segmented into ¯P subblocks of time-multiplexed training and information
symbols. Each subblock is of equal length lb symbols with ld information symbols and lt training
symbols (lb = ld + lt). If s denotes a column-vector composed of {s(n)}TB−1
n=0 , then s is arranged as
s :=
$
bT
0
cT
0
bT
1
cT
1
· · · bT
¯P−1
cT
¯P−1
%T
,
(3.72)
where bp (p = 0, 1, . . . , ¯P −1) is a column of ld information symbols and cp is a column of lt training
symbols. We clearly have TB = ¯Plb. Given (3.8) and CE-BEM (3.17), Ma et al. [11] has shown that
(3.72) is an optimum structure for K = 1 with lt = 2L + 1, ¯P ≥Q and
cp :=

0T
L
γ
0T
L
T ,
γ > 0.
(3.73)
Thus, given a transmission block of size TB, (2L + 1) ¯P symbols have to be devoted to training and the
remaining TB −(2L + 1) ¯P are available for information symbols.

2.03.6 Tracking
119
Let n p := plb + ld + L (p = 0, 1, . . . ¯P −1) denote the location of (nonzero) γ ’s in the optimum
cp’s in the P subblocks. Then by design, received signal (assuming timing synchronization)
y(n p + l) = γ h(n p + l;l) + v(n p + l)
(3.74)
for l = 0, 1, . . . , L. Using (3.17) in these y(n p +l)s, one can uniquely obtain hq(l)s via a least-squares
approach. The channel estimates are given by the CE-BEM (3.17) using the estimated BEM coefﬁcients.
2.03.6.3 Adaptive channel estimation via subblock tracking
Suppose that we collect the received signal over a time interval of ˜T symbols. We wish to estimate
the time-variant channel using a channel model and time-multiplexed training (such as that discussed
in Section 2.03.6.2 and [11]), and subsequently using the estimated channel, estimate the information
symbols. For CE-BEM, if we choose ˜T as the block size, then in general Q value will be very high
requiring estimation of a large number of parameters, thereby degrading the channel estimation perfor-
mance. If we divide ˜T into blocks of size TB, and then ﬁt CE-BEM block by block, we need smaller Q;
however, estimation of hq(l)’s is now based on a shorter observation size of TB symbols which might
also degrade channel estimation performance. Thus one has to strike a balance between estimation vari-
ance and block size. Such considerations do not apply to the AR channel model ﬁtting. [95] proposes
a novel subblock tracking approach to CE-BEM channel estimation where one updates estimates of
hq(l)s every subblock based on all of the past training symbols (see Figure 3.5).
FIGURE 3.5
Subblock-wise channel estimation: overlapping blocks and subblocks, where one block comprises several
subblocks and each subblock has an information session followed by a training session.

120
CHAPTER 3 Channel Estimation, Equalization, Precoding, and Tracking
By exploiting the invariance of the coefﬁcients of CE-BEM over each block, hence, each of the ¯P
subblocks per block of length TB symbols, one seeks subblock-wise tracking of the BEM coefﬁcients of
the doubly-selective channel. Consider two overlapping blocks that differ by just one subblock: blocks
with n = m, m + 1, . . . , m + TB −1 where m = m0 for the “past” block and m = m0 + mb for the
“current” block. If the two blocks overlap so signiﬁcantly, one would expect the BEM coefﬁcients to
vary only a little from the past block to the current overlapping block. Therefore, rather than estimate
hq(l)s anew with every non-overlapping block as in Section 2.03.6.2 and [11], one can track the BEM
coefﬁcients subblock by subblock using a ﬁrst-order AR model for their variations. Stack the channel
coefﬁcients in (3.17) into vectors
hl :=
 h1(l) h2(l) · · · hQ(l)T ,
(3.75)
h :=

hT
0
hT
1
· · · hT
L
T ,
(3.76)
of size Q and M := Q(L + 1) respectively. The coefﬁcient vector in (3.76) for the pth subblock
(p = 0, 1, . . .) will be denoted by h(p). We assume that the BEM coefﬁcients over each subblock
are Markovian: a simpliﬁed model is given by the ﬁrst-order AR process, i.e.,
h(p) = αh(p −1) + w(p),
(3.77)
where α is the AR coefﬁcient, and the driving noise vector w(p) is zero-mean complex Gaussian with
variance σ 2
wIM and statistically independent of h(p −1). If the channel is stationary and coefﬁcients
hq(l)s are independent (as assumed in [11]), then it follows from (3.77) that σ 2
w = σ 2
h (1−|α|2)/Q with
σ 2
h := E{h(n;l)h∗(n;l)}. Since the coefﬁcients evolve slowly, we have α ≈1 (but α <1 for tracking).
Under this formulation we do not have a “strict” deﬁnition of the block size TB because, although we
still use (3.17) for any n, we allow hq(l)s to change subblock by subblock based on the training symbols.
Deﬁne e(n) :=

e−jω1n
e−jω2n
· · ·
e−jωQnT . If at time n the pth subblock is being received,
by (3.6), (3.17–3.19) and (3.75–3.76), the received signal can be written as
y(n) = sT (n)

IL+1 ⊗e(n)
H h(p) + v(n),
(3.78)
where s(n) :=

s(n) s(n −1)
· · ·
s(n −L)
T . Treating (3.77) and (3.78) as the state and the mea-
surement equations respectively, Kalman ﬁltering can be applied to track the coefﬁcient vector h(p)for
each subblock; further details are in [95]. Alternatively, one can devise RLS-based approaches for
subblock-based tracking one does not need any prior models for BEM coefﬁcients; further details are
in [95].
2.03.6.4 Symbol-adaptive joint channel estimation and data detection
Representative approaches in this category are [4,5] and references therein. A Gauss-Markov model for
channel variations (typically an autoregressive model) is coupled with a state-space model for received
data to form an augmented state-space model with nonlinear measurement equation. This results in a
nonlinear state estimation problem. In [4] a ﬁnite-length minimum mean-square error (MMSE) DFE is
used during non-data-aided periods to generate hard decisions. Reference [5] presents a low complexity

2.03.6 Tracking
121
turbo equalization receiver for coded signals where a nonlinear Kalman ﬁltering based adaptive equalizer
(using Extended Kalman Filter (EKF)) is coupled with a soft-in soft-out decoder. These approaches
work well so long as the channel does not fade too fast.
2.03.6.4.1
Turbo equalization using EKF and CE-BEM
Now we describe an extension of [5] as reported in [85] where a CE-BEM-based subblock tracking
model (with one sample long subblock) is used. Kin and Tuguait [85] considers two overlapping blocks
(each of TB symbols) that differ by just one symbol: the “past” block beginning at time n0 and the
“present” block beginning at time n0 + 1. Since the two blocks overlap so signiﬁcantly, one would
expect the BEM coefﬁcients to vary only “a little” from the past block to the present overlapping one.
One can track the BEM coefﬁcients (rather than the channel tap gains) symbol-by-symbol using a
ﬁrst-order AR model for their variations. Kin and Tuguait [85] use (3.17) for all times n, not just the
particular block of size TB symbols, by allowing the coefﬁcients hq(l)s to change with time. Note that
model (3.17) is periodic with period K TB whereas the channel is by no means periodic. So long as
the effective “memory” of the Kalman ﬁlter used later is less than the model period Tp, there are no
deleterious effects due to the use of (3.17) for all time.
Bit-Interleaved Coded Modulation (BICM). We consider a BICM transmitter (as in [96]) for
a doubly-selective fading channel as shown in Figure 3.6. A sequence of independent data vector
b(n′) = [b1(n′), b2(n′), . . . , bk0(n′)] ∈{1, 0}k0 are fed into a convolutional encoder with a code rate
Rc = k0/n0. The coded output c(n′) = [c1(n′), c2(n′), . . . , cn0(n′)] ∈{1, 0}n0 is passed through a
bit-wise random interleaver π, generating the interleaved coded bit sequence c(n) = π[c(n′)]. The
binary coded bits are then mapped to a signal sequence d(n) over a 2-dimensional signal constellation
X of cardinality M = 2m by a M-ary modulator with an one-to-one binary map μ : {1, 0}m →X. In
this section, we only consider the case of phase-shift keying (PSK) or quadrature amplitude modulation
(QAM) with the average energy of the constellation X to be unity. That is, the signal d(n) drawn from
X has mean E[d(n)] = 0 and variance E[|d(n)|2] = 1. After modulation, we periodically insert short
training sequences into the data symbol sequence. The training symbols t(n), which are known to the
receiver, are randomly drawn from the signal constellation X with equal probabilities. The symbol {s(n)}
will be used to denote the symbol sequence after training {t(n)} insertion into data symbol sequence
{d(n)}.
Receiver structure. A turbo equalization structure, as depicted in Figure 3.7, is employed in the
receiver, as in [5] except that [5] uses symbol-wise AR models. The adaptive SISOf equalizer is embed-
ded into the iterative decoding (ID) process of the BICM transmission system (BICM-ID) [96]. In each
decoding iteration, the equalizer takes the training symbols and the soft decision information about
FIGURE 3.6
Bit-interleaved coded modulation system model for doubly-selective fading channel.

122
CHAPTER 3 Channel Estimation, Equalization, Precoding, and Tracking
FIGURE 3.7
Turbo equalization receiver. Following [5,97,98] and contrary to the original turbo principle, a posteriori LLR
La {c(n)} = LM
e {c(n)} + LD
e {c(n)} instead of the extrinsic LLR LD
e {c(n)} can be input to the LLR-to-symbol
block. Inclusion of LM
e {c(n)} to create a posteriori LLR is shown via dashed line. For our proposed approach
we follow [5,97,98].
data symbols supplied by the SISOf decoder from the previous iteration as its a priori information
to perform joint adaptive channel estimation and equalization. The equalizer produces the soft-valued
extrinsic estimate of the data symbols, which are independent of their a priori information. The output
of the equalizer is an updated sequence of soft estimates ˆd(n) and its error variance σ 2(n). Using the
adaptive SISOf equalizer described later, we have extrinsic information for the data symbols d(n). The
training symbols are removed at the SISOf equalizer output and the iterative process that follows is only
for data symbols. The SISOf equalizer based on the CE-BEM is described later. The SISOf demodulator
follows [96] whereas the SISOf decoder follows the MAP decoding algorithm (“BCJR”) [99] Section
6.2.
Adaptive SISOf nonlinear Kalman equalizer. Using a symbol-wise AR-model for channel varia-
tions, an adaptive SISOf equalizer using ﬁxed-lag EKF was presented in [5] for joint channel estimation
and equalization where their correlation was (implicitly) considered. The CE-BEM model-based SISOf
nonlinear Kalman equalizer for turbo equalization follows a similar approach. We will perform equal-
ization with a delay δ > 0. Deﬁne a parameter
¯δ := max{δ + 1, L + 1}
(3.79)
and the data vector
z(n) := [ s(n) s(n −1) · · · s
	
n −¯δ + 1

]T .
(3.80)
In order to apply (extended) Kalman ﬁltering to joint channel estimation and equalization, we stack
h(n) (which is given by (3.77) after replacing p therein with n to reﬂect the fact our subblock size now
is one sample) and data vector z(n) together into a J × 1 state vector x(n)at time n as
x(n) := [ zT (n) hT (n)]
T ,
J := ¯δ + Q(L + 1).
(3.81)

2.03.6 Tracking
123
As in [5] (and others), we consider the symbol sequence {s(n)} as a stochastic process so as to
utilize the soft decisions on the data symbols generated in the iterative decoding process as its a priori
information. We can express s(n) as s(n) = ¯s(n)+˜s(n) where ¯s(n) = E[s(n)] and ˜s(n) is approximated
as a zero-mean uncorrelated sequence such that E[˜s(n)˜s∗(n + j)] = γ (n)δ( j), assuming an ideal
interleaver. Note that ¯s(n) and γ (n) are provided via the a priori information. We have ¯s(n) = ¯d(n) and
γ (n) = γ d(n) for a data symbol d(n) (where ¯d(n) and γ d(n) are obtained from the extrinsic LLRs of
the SISOf decoder), while ¯s(n) = t(n) and γ (n) = 0 for a training symbol t(n). Using x(n), the state
equation turns out to be
x(n) = T x(n −1) + e0¯s(n) + u(n),
(3.82)
where
T =
"

0¯δ×Q(L+1)
0Q(L+1)×¯δ
F
#
J×J
,
F = αIQ(L+1),
(3.83)
 =
" 01×(¯δ−1)
01×1
I(¯δ−1)
0(¯δ−1)×1
#
¯δ×¯δ
,
e0 = [ 1 01×(J−1) ]T ,
(3.84)
the vector
u(n) :=
$
eT
¯δ ˜s(n) wT (n)
%T
(3.85)
is zero-mean uncorrelated process noise where e¯δ = [1 01×(¯δ−1)]T , w(n) is given in (3.77) and
Q(n) := E[u(n)uH(n)] = ˜Q + γ (n)e0eT
0 ,
˜Q :=
"
0¯δ×¯δ
0¯δ×Q(L+1)
0Q(L+1)×¯δ
σ 2
wIQ(L+1)
#
J×J
.
(3.86)
The channel output y(n) in (3.6) can be rewritten by CE-BEM given in (3.17) as
y(n) = sT (n)

I(L+1) ⊗e(n)
H h(n) + v(n),
(3.87)
where s(n) =

s(n) s(n −1) · · · s(n −L)
T and e(n) := [e−jω1n
e−jω2n · · · e−jωQn]T . Using the
state vector that comprises the information symbols and channel coefﬁcients, the measurement equation
can be given as
y(n) = f [x(n)] + v(n),
(3.88)
where
f [x(n)] := xT (n)
I(L+1)
0(L+1)×(J−L−1)
T 
I(L+1) ⊗E(n)
H 0[Q(L+1)]×¯δ
IQ(L+1)




=:D
x(n).
(3.89)
With (3.82) and (3.88) as the state and measurement equations, respectively, nonlinear Kalman ﬁltering
via EKF is applied to track x(n) for joint channel estimation and equalization.
Structure of adaptive soft-input soft-output equalizer. The ﬁxed-lag EKF takes soft inputs and
generates a delayed a posteriori estimate for s(n). In order to generate extrinsic estimate independent

124
CHAPTER 3 Channel Estimation, Equalization, Precoding, and Tracking
FIGURE 3.8
Structure of the adaptive SISOf equalizer proposed in [5].
of the a priori information {¯s(n), γ (n)}, a “comb” structure in conjunction with the EKF in Figure 3.8
is used for the SISOf equalization, just as in [5]. At each time n, the vertical branch composed of (δ +1)
EKFs produce the extrinsic estimate ˆs(n), while the horizontal branch keeps updating the a posteriori
estimate ˆx(n | n) and its error covariance P(n | n); here ˆx(p|m) denotes the estimate of x(p) given
the observations {y(0), y(1), . . . , y(m)}, and P(p|m) denotes the error covariance matrix of ˆx(p|m).
The ﬁrst vertical EKF has an input {0, 1} in place of {¯s(n), γ (n)} to exclude the effect of the a priori
information. Let ˆxe(n +i | n +i) and Pe(n +i | n +i) denote the state estimate and its error covariance
matrix, respectively, generated by the (i +1)th vertical ﬁltering branch. Then the extrinsic estimate ˆs(n)
of s(n) and its error variance σ 2(n) are given by
ˆs(n) = δth component of vector ˆxe(n + δ | n + δ),
(3.90)
σ 2(n) = (δ, δ)th component of matrix Pe(n + δ | n + δ).
(3.91)
Note that the extrinsic outputs ˆs(n) and σ 2(n) are computed for data symbol d(n), not for training
symbol t(n), and then used in the later parts of the turbo-equalization receiver (see Figure 3.7). Further
details regarding generation of extrinsic estimates can be found in [5].
Simulation examples. A random time- and frequency-selective Rayleigh fading channel is con-
sidered. We assume h(n;l) is zero-mean, complex Gaussian, and white with autocorrelation σ 2
h . We
take L = 2 (3 taps) and σ 2
h = 1/(L + 1). For different ls, h(n;l)s are mutually independent and
satisfy Jakes’ model. To this end, we simulate each single tap following [100] (with a correction in the
Appendix of [13]). We consider a normalized Doppler spread fdTs from 0.001 to 0.01. The additive
noise is zero-mean complex white Gaussian. The (receiver) SNR refers to the average energy per sym-
bol over one-sided noise spectral density. In the simulations, we use a four-state convolutional code of

2.03.6 Tracking
125
rate Rc = 1/2 with octal generators (5, 7). The information block size is set to 3000 bits (Ti = 3000)
leading to a coded block size of 6000 bits, and the interleaver size is equal to the coded block size. In
the modulator, the QPSK constellation with Gray mapping is used, which gives M = 4 and a block
size of 3000 symbols. After modulation, training symbol sequences of length lp are inserted in front
of every ls data symbols, leading to a sequence of length Tr = 3750 when lp = 5 and ls = 20 (20%
training overhead).
We compared the following schemes:
•
The approach of [83] that uses the linear MMSE equalizer (e.g., [80]) coupled with modiﬁed RLS
channel estimation, where we set the linear ﬁlter length = 3 (6 pre-cursor taps and 3 post-cursor
taps are used). This scheme is denoted by “TE-LE.”
•
The AR(p) model-based scheme in [5]. The AR(p) model is ﬁtted using [3] to Jakes’ spectrum with
fdTs = 0.01 (the maximum anticipated normalized Doppler spread), denoted by “TE-AR5” for
AR(5) model and “TE-AR9” for AR(9) model.
•
The proposed BEM-based turbo equalization schemes, where we consider BEM period T = 200
and 400 respectively, so that Q = 5 and 9 , respectively, by (3.19). For the channel BEM coefﬁcients,
we take the AR-coefﬁcient in (3.17) as α = 0.996 for T = 200 and α = 0.998 for T = 400. This
scheme is denoted by “TE-BEM(200)” for T = 200 and “TE-BEM(400)” for T = 400.
4
6
8
10
12
14
16
−20
−18
−16
−14
−12
−10
−8
−6
−4
−2
0
SNR(dB)
NCMSE (dB)
QPSK,L=2,d=5,lp=5,ls=20,fd=400Hz,1000runs
1st iteration
5th iteration
TE−LE
TE−AR5
TE−AR9
TE−BEM(200)
TE−BEM(400)
FIGURE 3.9
Turbo equalization: performance comparison for SNRs under fdTs = 0.01, lp = 5, ls = 20 (20% training
overhead).

126
CHAPTER 3 Channel Estimation, Equalization, Precoding, and Tracking
•
The turbo equalizer based on the ﬁxed-lag Kalman ﬁlter with perfect knowledge of the true channel,
denoted by “TrueCH.”
•
The turbo equalizer based on the optimum trellis-based MAP (BJCR) method [101] with perfect
knowledge of the true channel, denoted by “Opt-MAP-TrueCH.”
We evaluate the performances of various schemes by considering their normalized channel mean square
error (NCMSE) and their bit error rates (BER). The NCMSE is deﬁned as
NCMSE :=
'Mr
i=1
'TN −1
n=0
'L
l=0
***ˆh(i)(n;l) −h(i)(n;l)
***
2
'Mr
i=1
'TN −1
n=0
'L
l=0
**h(i)(n;l)
**2
,
where h
	
i

(n;l) is the true channel and ˆh(i)(n;l) is the estimated channel at the ith Monte Carlo run,
among total Mr runs. The BERs are evaluated by employing the equalization delay δ = 5, using the
decoded information symbol sequences at the turbo-equalization receiver. All the simulation results are
based on 1000 runs.
In Figures 3.9 and 3.10, the performance of all the above schemes, under normalized Doppler spread
fdTs = 0.01, are compared for different SNRs. In Figures 3.11 and 3.12 those schemes are compared
over varying Doppler spread fds, under SNR = 10 dB. It is clear from these ﬁgures that since the
4
6
8
10
12
14
16
10−6
10−5
10−4
10−3
10−2
10−1
100
SNR(dB)
BER
QPSK,L=2,d=5,l p=5,ls=20,fd=400Hz,1000runs
1st iteration
2nd iteration
5th iteration
TE−LE
TE−AR5
TE−AR9
TE−BEM(200)
TE−BEM(400)
TrueCH
Opt−MAP−TrueCH
FIGURE 3.10
Turbo equalization: performance comparison for SNRs under fdTs = 0.01, lp = 5, ls = 20 (20% training
overhead).

2.03.6 Tracking
127
channel variations are well captured by the BEM coefﬁcients, TE-BEM-based approach yields good
performance even for “low” SNRs and over a wide range of Doppler spreads. Note that TE-BEM with
larger block parameter Tp = 400 has a (slightly) better performance than with the smaller parameter
Tp = 200. The BER of TE-BEM varies only “slightly” with increasing normalized Doppler spread
implying that its performance is not sensitive to the actual Doppler spread. Therefore, we do not have
to know the exact Doppler spread of the channel—an upper bound on it is sufﬁcient in practice. The
performance of TE-AR5 is signiﬁcantly worse than that of TE-BEM(200) (the two approaches have
comparable computational complexity) in Figure 3.10 with increasing SNR for a ﬁxed fdTs = 0.01,
and is slightly worse in Figure 3.12 for a ﬁxed SNR of 10 dB and varying Doppler spreads. On the
other hand, while the performance of TE-AR9 is slightly better than that of TE-BEM(400) (the two
approaches have comparable computational complexity) in Figure 3.10 with increasing SNR for a ﬁxed
fdTs = 0.01, it is signiﬁcantly worse in Figure 3.12 for a ﬁxed SNR of 10 dB and varying Doppler
spreads. While increasing the BEM period Tp improves performance, increasing the AR model order
does not necessarily do so: we get inconsistent performance. A possible reason is that, as noted in [3], AR
model ﬁtting to a given correlation function can be numerically ill-conditioned for “large” model orders.
In Figures 3.10 and 3.12 the scheme TE-LE refers to the approach of [83] that uses the linear
MMSE equalizer (e.g., [80]) coupled with modiﬁed RLS channel estimation. It is seen that this approach
only works for normalized Doppler spread values of ≤0.002. In Figure 3.10 we also present the
1
2
3
4
5
6
7
8
9
10
x 10
−3
−20
−18
−16
−14
−12
−10
−8
−6
−4
−2
0
Normalized Doppler spread (fdTs)
NCMSE (dB)
QPSK,L=2,d=5,lp=5,ls=20,SNR=10dB,1000runs
1st iteration
5th iteration
TE−LE
TE−AR5
TE−AR9
TE−BEM(200)
TE−BEM(400)
FIGURE 3.11
Turbo equalization: performance comparison for normalized Doppler spread (fdTs)s under SNR = 10 dB,
lp = 5, ls = 20 (20% training overhead).

128
CHAPTER 3 Channel Estimation, Equalization, Precoding, and Tracking
1
2
3
4
5
6
7
8
9
10
x 10−3
10−6
10−5
10−4
10−3
10−2
10−1
100
Normalized Doppler spread (fdTs)
BER
QPSK,L=2,d=5,lp=5,ls =20,SNR=10dB,1000runs
1st iteration
5th iteration
TE−LE
TE−AR5
TE−AR9
TE−BEM(200)
TE−BEM(400)
FIGURE 3.12
Turbo equalization: performance comparison for normalized Doppler spread (fdTs)s under SNR = 10 dB,
lp = 5, ls = 20 (20% training overhead).
performance of the turbo equalizer based on the ﬁxed-lag Kalman ﬁlter with knowledge of the true
channel (curves with plus sign marker and labeled “TrueCH”) in order to illustrate the effectiveness of
the proposed channel estimation approach; as there was little improvement beyond the second iteration,
we only show the second iterative result with dotted curve labeled “TrueCH.” It is seen that there is
a slightly more than 2 dB SNR penalty due to channel estimation. As has been noted in the literature,
the Kalman ﬁlter based equalization is a sub-optimum equalizer compared to the trellis-based MAP
(BCJR) equalizer [101]. In Figure 3.10 we present the performance of the turbo equalizer based on the
optimum BCJR method with knowledge of the true channel (curves with asterisk marker and labeled
“Opt-MAP-TrueCH”) in order to illustrate loss in performance due to suboptimality of the Kalman
equalizer; as there was little improvement beyond the second iteration, we only show the second itera-
tive result with dotted curve labeled “Opt-MAP-TrueCH”. It is seen that while there is a large difference
in performance initially (see 1st iteration results for “TrueCH” and “Opt-MAP-TrueCH” where both
are dashed curves with plus sign and asterisk markers, respectively), just one turbo iteration yields very
close performance (see the two dotted curves). That is, at least for this example, performance loss in
using Kalman equalizer instead of the BCJR equalizer is quite negligible.
2.03.7 Conclusion
A review of various approaches to channel estimation and equalization for communications sys-
tems was presented. Emphasis was on linear baseband equivalent models with a tapped delay line

References
129
structure, and both time-invariant and time-variant (doubly-selective) models were discussed. Also
emphasis was on basis expansion modeling for time-variant channels where the basis functions are
related to the physical parameters of the channel (such as Doppler and delay spreads). Channel model-
ing was followed by a discussion of various approaches to channel estimation including training-based
approaches, blind approaches, semi-blind approaches and superimposed training based approaches.
Channel estimation approaches were followed by a discussion of channel equalization approaches
including turbo-equalization for time-varying channels. A brief discussion of precoding was presented
when the channel state information is available at the transmitter. We concluded the chapter with a
discussion of channel tracking and combined data detection and channel tracking for time-varying
channels. Channel tracking can be at block level suitable for block transmissions, or symbol-by-symbol
level suitable for serial transmissions. Some of the approaches were illustrated via simulations.
Relevant Theory: Signal Processing Theory
See Vol. 1, Chapter 11 Parametric Estimation
See Vol. 1, Chapter 12 Adaptive Filters
References
[1] J. Proakis, Digital Communications, fourth ed., McGraw-Hill, New York, NY, 2001.
[2] P. Bello, Characterization of randomly time-variant channels, IEEE Trans. Comm. Syst. 11 (1963) 360–393.
[3] K.E. Baddour, N.C. Beaulieu, Autoregressive modeling for fading channel simulation, IEEE Trans. Wireless
Commun. 4 (2005) 1650–1662.
[4] C. Komninakis, C. Fragouli, A. Sayed, R. Wesel, Multi-input multi-output fading channel tracking and
equalization using Kalman estimation, IEEE Trans. Signal Process. 50 (5) (2002) 1065–1076.
[5] X. Li, T. Wong, Turbo equalization with nonlinear Kalman ﬁltering for time-varying frequncy-selective
fading channels, IEEE Trans. Wireless Commun. 6 (2007) 691–700.
[6] S.M. Kay, Modern Spectral Analysis: Theory and Application, Prentice Hall, Englewoods Cliffs, NJ, 1988.
[7] P. Stoica, R. Moses, Spectral Analysis of Signals, Pearson Prentice Hall, Upper Saddle River, NJ, 2005.
[8] Z. Liu, X. Ma, G. Giannakis, Space-time coding and Kalman ﬁltering for time-selective fading channels,
IEEE Trans. Commun. 50 (2002) 183–186.
[9] D. Borah, B. Hart, Receiver structures for time-varying frequency-selective fading channels, IEEE J. Sel.
Areas Commun. 17 (1999) 1863–1875.
[10] G. Giannakis, C. Tepedelenlio˘glu, Basis expansion models and diversity techniques for blind identiﬁcation
and equalization of time-varying channels, Proc. IEEE 86 (1998) 1969–1986.
[11] X. Ma, G. Giannakis, S. Ohno, Optimal training for block transmissions over doubly selective wireless fading
channels, IEEE Trans. Signal Process. 51 (2003) 1351–1366.
[12] A. Sayeed, B. Aazhang, Joint multipath-doppler diversity in mobile wireless communications, IEEE Trans.
Commun. 47 (1999) 123–132.
[13] T. Zemen, C. Mecklenbräuker, Time-variant channel estimation using discrete prolate spheroidal sequences,
IEEE Trans. Signal Process. 53 (2005) 3597–3607.
[14] G. Leus, On the estimation of rapidly time-varying channels, in: Proceedings of the European Signal Pro-
cessing, Vienna, Austria, 2004, pp. 2227–2230.
[15] M. Martone, Wavelet-based separating kernels for array processing of cellular DS/CDMA signals in fast
fading, IEEE Trans. Commun. 48 (2000) 979–995.

130
CHAPTER 3 Channel Estimation, Equalization, Precoding, and Tracking
[16] M. Niedzwiecki, Identiﬁcation of Time-Varying Processes, Wiley, New York, NY, 2000.
[17] D. Slepian, Prolate spheroidal wave functions, Fourier analysis, and uncertainty—V: The discrete case, Bell
Syst. Tech. J. 57 (1978) 1371–1430.
[18] S. He, J. Tugnait, On bias-variance trade-off in superimposed training-based doubly selective channel esti-
mation, in: Proceedings of the 2006 Conference on Information Systems and Sciences, Princeton University,
NJ, 2006.
[19] M.-A. Baissas, A. Sayeed, Pilot-based estimation of time-varying multipath channels for coherent CDMA
receivers, IEEE Trans. Signal Process. 50 (2002) 2037–2049.
[20] A. Kannu, P. Schniter, Capacity analysis of MMSE pilot-aided transmission for doubly selective channels,
in: Proceedings of the 6th IEEE Workshop on Signal Processing Advances in Wireless, Communications,
2005, pp. 801–805.
[21] A. Kannu, P. Schniter, MSE-optimal training for linear time-varying c.hannels, in: Proceedings of the 2005
IEEE Conference on Acoustics, Speech and Signal Processing, Philadelphia, PA, 2005, pp. 789–792.
[22] A. Kannu, P. Schniter, Minimum mean-squared error pilot-aided transmision for MIMO doubly selective
channels, in: Proceedings of the 2006 Conference on Information Systems & Sciences, Princeton University,
NJ, 2006.
[23] G. Leus, S. Zhou, G. Giannakis, Orthogonal multiple access over time- and frequency-selective channels,
IEEE Trans. Inform. theory 49 (2003) 1942–1950.
[24] A. Sayeed, A. Sendonaris, B. Aazhang, Multiuser detection in fast-fading multipath environment, IEEE
J. Sel. Areas Commun. 16 (1998) 1691–1701.
[25] R. Gitlin, S. Weinstein, Fractionally-spaced equalization: an improved digital transversal equalizer, Bell Syst.
Tech. J. 60 (1981) 275–296.
[26] W. Gardner, Introduction to Random Processes with Applications to Signals and Systems, McGraw-Hill,
New York, NY, 1989.
[27] Y.-C. Chen, Y. Su, MIMO channel estimation in correlated fading environments, IEEE Trans. Wireless
Commun. 9 (3) (2010) 1108–1119.
[28] J. Karedal, P. Almers, A. Johansson, F. Tufvesson, A. Molisch, A MIMO channel model for wireless personal
area networks, IEEE Trans. Wireless Commun. 9 (1) (2010) 245–255.
[29] A. Sayeed, Deconstructing multiantenna fading channels, IEEE Trans. Signal Process. 50 (10) (2002)
2563–2579.
[30] D. Shiu, G. Foschini, M. Gans, J. Kahn, Fading correlation and its effect on the capacity of multielement
antenna systems, IEEE Trans. Commun. 48 (3) (2000) 502–513.
[31] W. Weichselberger, M. Herdin, H. Ozcelik, E. Bonek, A stochastic MIMO channel model with joint corre-
lation of both link ends, IEEE Trans. Wireless Commun. 5 (3) (2006) 90–100.
[32] J. Cavers, Pilot symbol assisted modulation and differential detection in fading and delay spread, IEEE Trans.
Commun. 43 (1995) 2206–2212.
[33] G. Kaleh, R. Vallet, Joint parameter estimation and symbol detection for linear or nonlinear unknown dis-
persive channels, IEEE Trans. Commun. 42 (1994) 2406–2413.
[34] V. Krishnamurthy, J. Moore, On-line estimation of hidden Markov model parameters based on Kullback-
Leibler information measure, IEEE Trans. Signal Process. 41 (1993) 2557–2573.
[35] L. Tong, S. Perreau, Multichannel blind channel estimation: from subspace to maximum likelihood methods.
Proc. IEEE 86 (1998) 1951–1968.
[36] N. Seshadri, Joint data and channel estimation using blind trellis search techniques, IEEE Trans. Commun.
42 (1994) 1000–1011.
[37] M. Ghosh, C. Weber, Maximum-likelihood blind equalization, Optical Eng. 31 (1992) 1224–1228.
[38] R. Raheli, A. Polydoros, C. Tzou, Per-survivor processing: A general approach to MLSE in uncertain
environments, IEEE Trans. Commun. 43 (1995) 354–364.

References
131
[39] K. Chugg, Blind acquisition characteristics of PSP-based sequence detectors, IEEE J. Sel. Areas Commun.
16 (1998) 1518–1529.
[40] J. Tugnait, Blind estimation and equalization of digital communication FIR channels using cumulant match-
ing, IEEE Trans. Commun. 43 (1995) 1240–1245.
[41] J. Tugnait, Blind equalization and estimation of FIR communications channels using fractional sampling,
IEEE Trans. Commun. 44 (1996) 324–336.
[42] D. Hatzinakos, C. Nikias, Blind equalization using a tricepstrum based algorithm, IEEE Trans. Commun.
39 (1991) 669–681.
[43] J. Vidal, J. Fonollosa, Adaptive blind equalization using weighted cumulant slices, Int. J. Adapt. Control
Signal Process. 10 (1996) 213–238.
[44] J. Tugnait, Channel estimation and equalization using higher-order statistics, in: G. Giannakis, Y. Hua,
P. Stoica, L. Tong (Eds), Signal Processing Advances in Wireless and Mobile Communications, Trends in
Channel Estimation and Equalization, vol. I, Prentice Hall, Upper Saddle River, NJ, 2001, pp. 1–39.
[45] L. Tong, G. Xu, T. Kailath, A new approach to blind identiﬁcation and equalization of multipath channels,
IEEE Trans. Inform. Theory 40 (1994) 340–349.
[46] J. Tugnait, On blind identiﬁability of multipath channels using fractional sampling and second-order cyclo-
stationary statistics, IEEE Trans. Inform. Theory 41 (1995b) 308–311.
[47] E. de Carvalho, D. Slock, Stochastic maximum likelihood methods for semi-blind channel estimation, in:
G. Giannakis, Y. Hua, P.Stoica, L. Tong (Eds.), Signal Processing Advances in Wireless and Mobile Com-
munications, vol. I, Prentice Hall, Upper Saddle River, NJ, 2001 (Chapter 7).
[48] H. Cirpan, M. Tsatsanis, Stochastic maximum likelihood methods for semi-blind channel estimation, IEEE
Signal Proc. Lett. 5 (1998) 21–24.
[49] J. Laurila, K. Kopsa, E. Bonek, Semi-blind signal estimation for smart antennas using subspace tracking. In
Proceedings of the IEEE Workshop on Signal Processing Advances in Wireless Communications, Annapolis,
MD, 1999.
[50] A. Gorokhov, P. Loubaton, Semi-blind second order identiﬁcation of convolutive channels, in: Proceedings
of the 1997 IEEE Conference on Acoustics, Speech and Signal Processing, Munich, Germany, 1997, pp.
3905–3908.
[51] S. Lasaulce, P. Loubaton, E. Moulines, A semi-blind channel estimation technique based on second-order
blind method for CDMA systems, IEEE Trans. Signal Process. 51 (2003) 1894–1904.
[52] P. Hoeher, F. Tufvesson, Channel estimation with superimposed pilot sequence, in: Proceedings of the IEEE
Global Communications Conference, Rio de Janeiro, Brazil, 1999, pp. 2162–66.
[53] T. Holden, K. Feher, A spread spectrum based system technique for synchronization of digital mobile
communication system, IEEE Trans. Broadcast. 36 (1990) 185–194.
[54] F. Mazzenga, Channel estimation and equalization for M-QAM transmission with a hidden pilot sequence,
IEEE Trans. Broadcast. 46 (2000) 170–176.
[55] M. Ghogho, D. McLernon, E. Alamdea-Hernandez, A. Swami, Channel estimation and symbol detection for
block transmission using data-dependent superimposed training, IEEE Signal Proc. Lett. 12 (2005) 226–229.
[56] M. Ghogho, D. McLernon, E. Alamdea-Hernandez, A. Swami, SISO and MIMO channel estimation and
symbol detection using data-dependent superimposed training. in: Proceedings of the IEEE Conference on
Acoustics, Speech and Signal Processing, PA, Philadelphia, 2005, pp. III-461–III-464,.
[57] J. Tugnait, S. He, Doubly-selective channel estimation using data-dependent superimposed training and
exponential bases models, in: Proceedings of the Conf. on Information Systems and Sciences, Princeton
University, NJ, 2006.
[58] J. Tugnait, S. He, Multiuser/MIMO doubly selective fading channel estimation using superimposed training
and Slepian sequences, IEEE Trans. Veh. Technol. 59 (2010) 1341–1354.

132
CHAPTER 3 Channel Estimation, Equalization, Precoding, and Tracking
[59] H. Holma, A.E. Toskala, second ed., WCDMA for UMTS: Radio Access for Third Generation Mobile
Communications, Wiley, New York, NY, 2002.
[60] A. Orozco-Lugo, M. Lara, D. McLernon, Channel estimation using implicit training, IEEE Trans. Signal
Proc. 52 (2004) 240–254.
[61] J. Tugnait, W. Luo, On channel estimation using superimposed training and ﬁrst-order statistics, in: Proceed-
ings of the, IEEE Conference on Acoustics, Speech and Signal Processing, Hong Kong, 2003.
[62] J. Tugnait, W. Luo, On channel estimation using superimposed training and ﬁrst-order statistics, IEEE
Commun. Lett. 8 (2003) 413–415.
[63] G. Zhou, M. Viberg, T. McKelvey, A ﬁrst-order statistical method for channel estimation, IEEE Signal
Process. Lett. 10 (2003) 57–60.
[64] M. Dong, L. Tong, B. Sadler, Optimal insertion of pilot symbols for transmissions over time-varying ﬂat
fading channels, in: Proceedings of the 2003 IEEE Workshop on Signal Processing Advances in Wireless
Communications, Rome, Italy. IEEE, 2003, pp. 472–476.
[65] M. Biguesh, A. Gershman, Training-based MIMO channel estimation: a study of estimator tradeoffs and
optimal training signals, IEEE Trans. Signal Proc. 54 (3) (2006) 884–893.
[66] X. Ma, L. Yang, G. Giannakis, Optimal training for MIMO frequency-selective fading channels, IEEE Trans.
Wireless Commun. 4 (2) (2005) 453–466.
[67] I. Barhumi, G. Leus, M. Moonen, Time-varying FIR equalization for doubly selective channels, IEEE Trans.
Wireless Commun. 4 (1) (2005) 202–214.
[68] L. Song, J. Tugnait, Doubly-selective fading channel equalization: A comparison of the Kalman ﬁlter
approach with the basis expansion model-based equalizers, IEEE Trans. Wireless Commun. 8 (1) (2009)
60–65.
[69] N. Al-Dhahir, J.M. Ciofﬁ, MMSE decision-feedbck equalizers: ﬁnite-length results, IEEE Trans. Inf. Theory
41 (4) (1995) 961–975.
[70] A.H. Sayed, Fundamentals of Adaptive Filtering, Wiley, New York, NY, 2003.
[71] G.L. Stüber, Principles of Mobile Communication, second ed., Kluwer, Boston, MA, 2002.
[72] G. Forney, Maximum-likelihood sequence estimation of digital sequences in the presence of intersymbol
interference, IEEE Trans. Inform. Theory 18 (1972) 363–378.
[73] S. Lin, J.J. Costello, Error Control Coding, Prentice-Hall, Englewood Cliffs, NJ, 1983.
[74] L. Bahl, J. Cocke, F. Jelinek, J. Raviv, Optimal decoding of linear codes for minimizing symbol error rate,
IEEE Trans. Inform. Theory 20 (1974) 284–287.
[75] M. Tuchler, A. Singer, Turbo equalization: an overview, IEEE Trans. Inform. theory 70 (2) (2011) 920–952.
[76] C. Berrou, A. Glavieux, P. Thitimajshima, Near Shannon limit error-correcting coding and decoding: turbo
codes, in: Proceedings of IEEE Int. Conf. on Commun., Geneva, Switzerland, 1993.
[77] C. Douillard, M. Jézéquel, C. Berrou, A. Picart, P. Didier, A. Glavieux, Iterative correction of intersymbol
interference: turbo-equalization. Eur. Trans. Telecommun. 6 (1995) 507–511.
[78] A. Anastassopoulos, K. Chugg, Iterative equalization/decoding for TCM for frequency-selective channels.
in: Proceedings of the 1997 Asilomar Conf. on Signals, Systems, Compueters, Pciﬁc Grove, CA, 1997, pp.
177–181.
[79] X. Wang, H. Poor, Iterative (turbo) soft interference cancellation and decoding for coded CDMA, IEEE
Trans. Commun 47 (7) (1999) 1046–1061.
[80] M. Tuchler, Minimum mean squared error equalization using a priori information, IEEE Trans. Signal Process
50 (3) (2002) 673–683.
[81] M. Tuchler, Turbo equalization: principles and new results, IEEE Trans. Commun. 50 (5) (2002) 754–767.
[82] M. Nissilä, S. Pasupathy, Adaptive Bayesian and EM-based detectors for frequency-selective fading channels,
IEEE Trans. Commun. 51 (2003) 1325–1336.

References
133
[83] R. Otnes, M. Tuchler, Iterative channel estimation for turbo equalization for time-varying frequency-selective
channels, IEEE Trans. Wireless Commun. 3 (2004) 1918–1923.
[84] S. Song, A. Singer, K. Sung, Soft input channel estimation for turbo equalization, IEEE Trans. Signal Process.
52 (2004) 2885–2894.
[85] H. Kim, J. Tugnait, Turbo equalization for doubly-selective fading channels using nonlinear Kalman ﬁltering
and basis expansion models, IEEE Trans. Wireless Commun. 9 (2010) 2076–87.
[86] H. Harashima, H. Miyakawa, Matched-transmission technique for channels with intersymbol interference,
IEEE Trans. Commun. 20 (1972) 774–780.
[87] J.C.-C. Kuo, S.-O. Tsai, L. Tadjpour, Y.-H. Chang, Precoding Techniques for Digital Communication Sys-
tems, Springer, New York, NY, 2008.
[88] M. Tomlinson, New automatic equalizer employing modulo arithmetic, Electron. Lett. 7 (1971) 138–139.
[89] G. Forney, M. Eyuboglu, Combined equalization and coding using precoding, IEEE Commun. Mag. 29
(1991) 25–34.
[90] M. Vu, A. Paulraj, MIMO wireless linear precoding, IEEE Signal Proc. Mag. 24 (5) (2007) 86–105.
[91] A. Scaglione, P. Stoica, S. Barbarossa, G. Giannakis, H. Sampath, Optimal designs for space-time linear
precoders and decoders, IEEE Trans. Signal Process. 50 (2002) 1051–1063.
[92] T. Liu, J.-K. Zhang, K. Wong, Optimal precoder design for correlated MIMO communication systems using
zero-forcing decision feedback equalization, IEEE Trans. Signal Proc. 57 (2009) 3600–3612.
[93] W. Su, W. Zheng, L. Chai, Precoder design and blind channel identiﬁcation of MIMO channels, IEEE Trans.
Signal Process. 54 (7) (2006) 2725–2736.
[94] Z. Wang,G.Giannakis,Blockprecodingfor MUI/ISI-resilient generalized multicarrier CDMA with multirate
capabilities, IEEE Trans. Commun. 49 (11) (2001) 2016–2027.
[95] J. Tugnait, S. He, H. Kim, Doubly-selective channel estimation using exponential basis models and subblock
tracking, IEEE Trans. Signal Process. 58 (2010) 1275–1289.
[96] X. Li, J. Ritcey, Bit-interleaved coded modulation with iterative decoding, in: Proceedings of IEEE Interna-
tional Conference Communication, 1999, pp. 858–864.
[97] R. Lopes, J. Berry, The soft-feedback equalizer for turbo equalization of highly dispersive channels, IEEE
Trans. Commun. 54 (5) (2006) 783–788.
[98] F. Vogelbruch, S. Haar, Low complexity turbo equalization based on soft feedback interference cancelation,
IEEE Commun. Lett. 9 (7) (2005) 586–588.
[99] X. Wang, H. Poor, Wireless Communication Systems: Advanced Techiques for Signal Reception, Prentice
Hall, Upper Saddle River, NJ, 2004.
[100] Y. Zheng, C. Xiao, Simulation models with correct statistical properties for Rayleigh fading channels, IEEE
Trans. Commun. 51 (2003) 920–928.
[101] R. Koetter, A. Singer, M. Tuchler, Turbo equalization, IEEE Signal Proc. Mag. 21 (2004) 67–80.

4
CHAPTER
Blind Signal Separation
for Digital Communication Data
Antoine Chevreuil* and Philippe Loubaton†
*ESIEE Paris/UMR 8049 LIGM, 2 bd Blaise Pascal BP 99, 93162 Noisy-le-grand cedex, France
†Université de Paris-Est Marne-la-Vallée, UMR 8049 LIGM, 5 bd Descartes, 77454 Marne-la-Vallée cedex 2, France
2.04.1 Introduction
2.04.1.1 Generalities on blind source separation
The goal of blind source separation is to retrieve the components of a mixture of independent signals
when no a priori information is available on the mixing matrix. This question was introduced in the
eighties in the pioneering works of Jutten and Herault [1]. Since then, Blind Source Separation (BSS),
also called independent component analysis, was developed by many research teams in the context of
various applicative contexts. The purpose of this chapter is to present BSS methods that have been
developed in the past in the context of digital communications. In this case, K digital communication
devices sharing the same band of frequencies transmit simultaneously K signals. The receiver is equipped
with M ≥K antennas, and has to retrieve a part of (or even all) the transmitted signals. The use of BSS
techniques appears to be relevant when the receiver has no a priori knowledge on the channels between
the transmitters and the receiver. As many digital communication systems use training sequences which
allow one to estimate the channels at the receiver side, blind source separation is in general not a very
useful tool. However, it appears to be of particular interest in contexts such as spectrum monitoring or
passive listening in which it is necessary to characterize unknown transmitters (estimation of technical
parameters such as the carrier frequency, symbol rate, symbol constellation,…) interfering in a certain
bandwidth. For this, it is reasonable to try to ﬁrstly retrieve the transmitted signals, and then to analyze
each of them in order to characterize the system it has been generated by. In this chapter, we provide a
comprehensive introduction to the blind separation techniques that can be used to achieve the ﬁrst step.
In order to explain the speciﬁcity of the problems we address in the following, we ﬁrst recall
what are the most classical BSS methodologies. The observation is a discrete-time M-variate signal
y(n) deﬁned as y(n) = Hs(n) where the components of the K-dimensional (K ≤M ) time series
s(n) = (s1(n), . . . , sK (n))T represent K signals which are statistically independent. The signal y is
thus an instantaneous mixture of the K independent source signals (sk)k=1,...,K in the sense that y(n)
only depends on the value of s at time n. The signal y is said to be a convolutive mixture of the K
independent source signals (sk)k=1,...,K if y(n) = 
ℓHℓs(n −ℓ) = [H(z)]s(n) where H(z) represents
the transfer function H(z) = 
ℓHℓz−ℓ. For the sake of simplicity, we just consider the context of
instantaneous mixtures in this introductory section. The goal of blind source separation is to retrieve
the signals (sk)k=1,...,K from the sole knowledge of the observations. Fundamental results of Darmois
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-396500-4.00004-1
© 2014 Elsevier Ltd. All rights reserved.
135

136
CHAPTER 4 Blind Signal Separation for Digital Communication Data
(see e.g., [2]) show that if the source signals are non Gaussian, then it is possible to achieve the sep-
aration of the sources by adapting a matrix G in such a way that the components of r(n) = Gy(n)
are statistically independent. For this, it has been shown that it is sufﬁcient to optimize over G a func-
tion, usually called a contrast function, that can be expressed in terms of certain moments of the joint
probability distribution of r(n). A number of successful contrast functions have been derived in the
case where the signal (sk)k=1,...,K are stationary sequences [2–5]. However, it will be explained below
that in the context of digital communications, the signals (sk)k=1,...,K are not stationary, but cyclosta-
tionary, in the sense that their statistical properties are almost periodic function of the time index. For
example, for each k, the sequence n →E[|sk(n)|2] appears to be a superposition of sinusoids whose
frequencies, called cyclic frequencies, depend on the symbol rate of transmitter k, and are therefore
unknown at the receiver side. The cyclostationarity of the (sk)k=1,...,K induces speciﬁc methodological
difﬁculties that are not relevant in other applications of blind source separation.
2.04.1.2 Illustration of the potential of BSS techniques
for communication signals
The example we provide is purely academical. We consider the transmission of two BSPK sequences
modulated with a Nyquist raised-cosine ﬁlter (see Section 2.04.2.1) whose symbol period is T = 1 and
roll-off factor is ﬁxed to 50%. The energy per symbol equals E1 for the ﬁrst source and E2 for the second
source. The receiver has M = 2 antennas and the channel between the source no i and the antenna no
j is a delay times a real constant hi, j. After sampling at T /3, the noiseless model of the received data
is Y(n) = Hs(n) as speciﬁed in the introduction, where the component (i, j) of H is hi, j(more details
are provided in Section 2.04.2.3). An additive white noise Gaussian corrupts the model whose variance
is N0
Te where E1
N0 is ﬁxed to 100 dB (we purposely ﬁxed the noise level to a low value in order to show
results that can be graphically interpreted). Moreover, E1
E2 = 3 dB.
Suppose in a ﬁrst step that the channel is ideal such that the mixing matrix H is the identity matrix. We
may have a look at the eye diagrams of the two components of the received data. We obtain Figure 4.1.
This is almost a perfectly opened eye since the noise is negligible. We may also have a look at a 2D-
histogram of the data. Notice that the components of X(n) are not stationary. We hence down-sample
these data by a factor 3 in order to have stationary data. We plot the 2D-histogram: see Figure 4.2. As
the two components are independent, their joint probability density function (pdf) is separable which
seems to be the case in view of the ﬁgure.
Let us now consider the case of the channel matrix:
H =
 1
0.7
0.5
1

.
We obtain Figures 4.3 and 4.4 respectively for the eye diagrams and the 2D-histograms. Clearly the
channels are severe and close the eyes. Moreover, the pdf is obviously not separable, which attests to
the non independency of the two components of X(n).
We run the JADE algorithm (see Sections 2.04.3.5 and 2.04.3.8) on the data (the observation duration
is ﬁxed to 1000 symbols): we obtain a 2 × 2 matrix G such that, theoretically at least, GH should be
diagonal. We form the data Y(n) = GX(n) and plot Figures 4.5 and 4.6. The eyes have been opened and

2.04.1 Introduction
137
0
5
10
15
20
25
30
2.5
2
1.5
1
0.5
0
0.5
1
1.5
2
2.5 x 10
5
0
5
10
15
20
25
30
1.5
1
0.5
0
0.5
1
1.5 x 10
5
FIGURE 4.1
Eye diagram. E1
N0 = 100 dB. After the JADE algorithm.
the joint pdf is hence separable. This is not a surprise since we have computed the resulting matrix GH:
GH ≈
 0.8439
−0.0129
−0.0039
1.1829

which is close to a diagonal matrix. We need to explain why BSS has been successfully achieved in this
simple example and why it can also be achieved in much more difﬁcult contexts.

138
CHAPTER 4 Blind Signal Separation for Digital Communication Data
60
40
20
0
20
40
60
50
40
30
20
10
0
10
20
30
40
50
0
5
10
15
20
25
30
FIGURE 4.2
2D-histogram. E1
N0 = 100dB. Ideal channels.
2.04.1.3 Organisation of the paper
This chapter is organized as follows. In Section 2.04.2, we provide the model of the signals which are
supposed to be linear modulations of symbols (Section 2.04.2.1). We discuss the statistics of the sampled
versions of the transmitted sources in Section 2.04.2.2: in general, a sampled version is cyclo-stationary
and we provide the basic tools and notation used along the paper. The model of the received data is
speciﬁed in Section 2.04.2.3: (1) If the propagation channel between each transmitter and the receiver
is a single path channel, the received signal is an instantaneous mixture of the transmitted signals; (2)
if at least one of the propagation channel is a multipath channel, the mixture appears to be convolutive.
Besides, we discuss the assumptions under which the received data are stationary. In general, however,
the data are cyclo-stationary with unknown cyclic frequencies.
The case of instantaneous mixtures is addressed in Section 2.04.3. When the sources are indepen-
dent and identically distributed (i.i.d.) (this case is discussed in Section 2.04.2.3), and that strong a
priori information on the constellations are known, it is possible to provide algebraic solutions to the
BSS problem, e.g., the Iterative Least Squares Projections (ILSP) algorithm or the Algebraic Constant
Modulus Algorithms (ACMA): these methods are explained in Section 2.04.3.2. In Section 2.04.3.3,
we consider the case of second-order methods (one of the advantages of these latter is that they are
robust to the cyclo-stationarities, hence can be applied to general scenarios): the outlines of one of

2.04.1 Introduction
139
0
10
20
30
3
2
1
0
1
2
3 x 10
5
0
10
20
30
3
2
1
0
1
2
3
4 x 10
5
FIGURE 4.3
Eye diagrams. E1
N0 = 100 dB. Channel H. Left: ﬁrst component. Right: second component.
the most popular approach, the Second-Order Blind Identiﬁcation (SOBI) algorithm, which consists in
estimating the mixing matrix from the autocorrelation function of the received signal. This approach
is conceptually simple, and the corresponding scheme allows one to identify the mixture and hence, to
separate the source signals. That SOBI is rarely considered for BSS of digital communication signals
is explained. The subsections that follow cope with BSS methods based on fourth-order cumulants.
They are called “direct” BSS methods since they provide estimates of the sources with no prior estima-
tion of the unknown channel matrix. For pedagogical and historical reasons, we ﬁrstly cope with the
very particular case of stationary signals. One-by-one methods based are explained (Section 2.04.3.4)
and are shown to be convergent; the associated deﬂation procedure is introduced and an improvement
is presented. Global methods (also called joint separating methods) aim at separating jointly the K
sources: they are depicted in Section 2.04.3.5; these approaches are based on the minimization of well
chosen contrast functions over the set of K × K unitary matrices: the famous Joint Approximate Diag-
onalization of Eigenmatrices (JADE) algorithm is presented, since it represents a touchstone in the
domain of BSS. When the sources are cyclo-stationary, which is really the interesting point for the

140
CHAPTER 4 Blind Signal Separation for Digital Communication Data
80
60
40
20
0
20
40
60
80
100
80
60
40
20
0
20
40
60
80
100
0
10
20
30
40
50
60
70
80
FIGURE 4.4
2D-histogram. E1
N0 = 100 dB. Channel H.
context of this paper, the preceding “stationary” methods (one-by-one and global) are again consid-
ered. The following problem is addressed: do the convergence result still hold when the algorithms
are fed by cyclo-stationary data instead of stationary ones? Sufﬁcient conditions are shown to assure
the convergence: semi-analytical computations (Section 2.04.3.9) prove that the conditions in question
hold true.
In Sections 2.04.4 and 2.04.5, the case of convolutive mixtures is addressed. In certain particular
scenarios, e.g., sparse channels, the gap between the instantaneous case and the convolutive one can
be bridged quite directly (Section 2.04.4). More precisely, if the delays of the various multipaths are
sufﬁciently spread out on the one hand and if, on the other hand, the number of antennas of the receiver
is large enough, it is still possible to formulate the source separation problem as the separation of
a certain instantaneous mixture. If these conditions do not hold, we face a real convolutive mixture,
i.e., the received data are the output of a Multi-Input/Multi-Output (MIMO) unknown ﬁlter driven by
jointly independent (cyclo-) stationary sources. Due to their historical and theoretical importance, we
present algebraic methods (Section 2.04.5.1) when the data are stationary. Under this latter assumption,
the identiﬁcation of the unknown transfer function can be achieved using standard methods using the
Moving Average (MA) or Auto-Regressive (AR) properties: see Section 2.04.5.2. The famous subspace
method, introduced in Section 2.04.5.3, is based on second-order moments and can be used for general
cyclo-stationary data; its inherent numerical problems are discussed. In Section 2.04.5.4, global direct

2.04.2 Signals
141
0
10
20
30
5000
4000
3000
2000
1000
0
1000
2000
3000
4000
5000
5000
4000
3000
2000
1000
0
1000
2000
3000
4000
5000
0
10
20
30
FIGURE 4.5
Eye diagram. E1
N0 = 100 dB. After the JADE algorithm.
methods are evoked (temporal domain and frequency domain) for stationary data. In Section 2.04.5.5,
the case of one-to-one methods previously introduced in Section 2.04.3.4 is extended to the convolutive
case and positive results for BSS are provided. The results are further extended for the cyclo-stationary
case in Section 2.04.5.6 where convergence results are shown.
In Section 2.04.7, we discuss several points that have not been developed in the core of the paper.
Further bibliographic entries are provided.
2.04.2 Signals
We have speciﬁed in the Introduction that the domain of source separation is not restricted to the context
of telecommunication signals. In the following, however, most of the results apply speciﬁcally to digital
telecommunication signals.

142
CHAPTER 4 Blind Signal Separation for Digital Communication Data
1.5
1
0.5
0
0.5
1
1.5
1.5
1
0.5
0
0.5
1
1.5
0
5
10
15
20
25
30
35
FIGURE 4.6
2D-histogram. E1
N0 = 100 dB. After the JADE algorithm.
2.04.2.1 Source signals. Basic assumptions
We assume that K digital telecommunication devices simultaneously transmit information in the same
band of frequencies. For t ∈R, we denote by sa,k(t) the complex envelope of the kth transmitted signal
(“the kth source”). The subscript “a” in sa,k(t) underlines that the signal is “analog”. Throughout this
contribution, sa,k(t) is supposed to stem from a linear modulation of a sequence of symbols. The model
is hence:
∀t ∈R sa,k(t) =

n
dk(n) ca,k(t −nTk).
(4.1)
In this latter equation, dk(n) is a sequence of symbols belonging to a certain constellation. The function
ca,k is a shaping function and Tk is the duration of a symbol dk(n). We denote by fk the carrier frequency
associated with the kth source. Along this contribution, the following assumptions and notation are
adopted.
Assumptions on the source signals: For a given index k, the sequence dk(n) is assumed to be independent
and identically distributed (i.i.d.). We assume that it has zero mean E[dk(n)] = 0. With no restriction at
all, the normalization E[|dk(n)|2] = 1 holds. We also suppose that it is second-order complex-circular
in the sense that
E[dk(n)2] = 0.
(4.2)

2.04.2 Signals
143
It is undoubtedly a restriction to impose the condition (4.2) especially in the telecommunication context
of this paper; indeed, the BPSK modulation for instance does not verify (4.2). Some points on the
extensions to general non circular mixtures are provided in Section 2.04.7.1.
The Kurtosis of the symbol dk(n), is deﬁned as
κ(dk) = cum(dk(n), dk(n)∗, dk(n), dk(n)∗),
where the fourth-order cumulant of a complex-valued random variable X is deﬁned when it makes
sense, as cum(X, X∗, X, X∗) = E[|X|4] −2(E[|X|2])2 −|E[X2]|2: see for instance [6]. Here, by the
circularity Assumption 4.2, we have
κ(sk) = E[|dk(n)|4] −2(E[|dk(n)|2])2.
We assume that we have, for any index k:
κ(dk) < 0.
(4.3)
This inequality is given as an assumption; is has more the ﬂavor of a result, since we do not know
complex-circular constellations such that (4.3) is not satisﬁed.
We may now come to the key assumption: the sources d1, d2, . . . , dK are mutually independent.
Concerning the shaping ﬁlter, ca,k we suppose that ca,k is a square-root raised cosine with excess
bandwidth (also called roll-off factor) 0 ≤γk ≤1.
2.04.2.2 Cyclo-stationarity of a source
In this short paragraph, we drop the index of the source and sa, T , ca, d(n) refer to respectively
sa,k, Tk, ca,k, dk(n). Thanks to Eq. (4.1), it is quite obvious that sa(t) and sa(t + T ) are similarly
distributed since dk(n) is i.i.d. This simple reasoning applies to any vector (sa(t1), . . . , sa(tm)) whose
distribution equals this of (sa(t1+T ), . . . , sa(tm +T )). This shows that the process sa is cyclo-stationary
in the strict sense with period T. In particular, its second and fourth-order moments evolve as T-periodic
functions of the time. Let us focus on the second-order moments: t →E[sa(t + τ)sa(t)∗] is hence a
periodic function with period T. We let its Fourier expansion be
E[sa(t + τ)sa(t)∗] =

m∈Z
R(m/T )
sa
(τ)eı2πmt/T ,
(4.4)
where R(m/T )
sa
(τ) is called “cyclo-correlation” of sa at cyclic frequency m/T and time lag τ. We have
the reverse formula:
R(m/T )
sa
(τ) = 1
T
 T
0
E[sa(t + τ)sa(t)∗]e−ı2πmt/T dt
or
R(m/T )
sa
(τ) = lim
→∞
1

 /2
−/2
E[sa(t + τ)sa(t)∗]e−ı2πmt/T dt.
Generally, we may introduce the cyclo-correlation at any cyclic frequency α:
R(α)
sa (τ) = lim
→∞
1

 /2
−/2
E[sa(t + τ)sa(t)∗]e−ı2παtdt.

144
CHAPTER 4 Blind Signal Separation for Digital Communication Data
In the case of sa given by Eq. (4.1), R(α)
sa (τ) is identically zero for cyclic frequencies α that are not
multiples of 1/T . In passing, we have the following symmetry:
R(α)
sa (τ) = R(−α)
sa
( −τ)∗.
(4.5)
Let us inspect a bit further a main speciﬁcity of linear modulations on the Fourier expansion of
Eq. (4.4). In this respect, denote by f →S(α)
sa (f) the Fourier transform of the cyclo-correlation function
τ →R(α)
sa (τ). We have, after elementary calculus (see [7,8]):
S(m/T )
sa
(f) = 1
T ˆca(f)ˆca(f −m/T )∗,
where ˆca(f) =

R ca(t)e−ı2πftdt is the Fourier transform of ca. This formula is visibly a generalization
of the so-called Benett Equality (see [9] Section 4.4.1) that gives the power spectral density of sa:
indeed, in the above equation, if one takes m = 0, we obtain S(0)
sa (f) = 1
T |ˆca(f)|2 which is the power
spectral density. An important consequence was underlined in [8]:
Lemma 1.
For any excess bandwidth factor γ such that γ ≤1, we have:
∀|m| > 1
R(m/T )
sa
(τ) is uniformly zero.
In other words, the cyclic frequencies of sa(t) given by Eq. (4.1) belong to the set {0, ± 1
T }.
Proof.
The proof is obvious since the support of ˆca(f) is [−1+γ
2T , 1+γ
2T ] with γ < 1 hence the supports
of ˆca(f) and ˆca(f −m/T )∗do not overlap except if m = 0, ±1.
□
We deduce from what precedes some consequences on the second-order statistics of a sampled
version of a source. In this respect, we denote by Te any sampling period; the discrete-time signal
associated with sa(t) is hence s(n) = sa(nTe) for n ∈Z. Thanks to Lemma 1, the expansion (4.4) may
be re-written as:
∀ℓ∈Z
E[s(n + ℓ)s(n)∗] =

m∈{−1,0,1}
R(m/T )
sa
(ℓTe)eı2πnmα,
(4.6)
where we let α be α = Te/T . We distinguish between three cases:
1. If α = Te/T is a integer, the three terms of the r.h.s. of (4.6) all aggregate in a single term, making
the function E[s(n + ℓ)s(n)∗] not depend on the time index n. This is not surprising since the
condition Te = pT where p is a non-null integer corresponds to a strict-sense stationary signal (see
the polyphase decomposition in [10]). In particular, if Te = T , we have:
s(n) = [c0(z)]d(n),
(4.7)
where c0(z) = 
n ca(nT )z−n. In the following, we will not study the case Te = pT with p ≥2.
2. If α ̸= 0 modulo 1/2: unless α is rational, it cannot be said that, as a function of n, E[s(n +ℓ)s(n)∗]
is periodic: it is called an almost periodic function [11] and s(n) is hence called almost periodically
correlated, having 0, ±α as cyclic-frequencies. We introduce
R(α)
s
(ℓ) = ⟨E[s(n + ℓ)s(n)∗]e−ı2παn⟩n,
(4.8)

2.04.2 Signals
145
where the operator ⟨·⟩is the time-averaging one, i.e., for a complex-valued (deterministic) series u(n)
⟨u(n)⟩n = lim
N→∞
1
N
N−1

n=0
u(n)
when the limit makes sense. As the three cyclic-frequencies in the expansion (4.6) are distinct
modulo 1 then we obtain
∀m ∈{0, ±1}
R(mTe/T )
s
(ℓ) = R(m/T )
sa
(ℓTe),
which reminds us of the Shannon sampling theorem.
3. If α = 1
2 it turns out that, similarly to the previous case, the discrete-time source is cyclo-stationary,
having 0, ± 1
2 as cyclic- frequencies. Moreover R(0)
s (ℓ) = R(0)
sa (ℓTe) and R(1/2)
s
(ℓ) = R(−1/2)
s
(ℓ) =
R(1/T )
sa
(ℓTe) + R(−1/T )
sa
(ℓTe).
2.04.2.3 Received signals
The receiver is equipped with M antennas, the number of antennas being as big as the number of sources,
i.e., M ≥K (see section 2.04.2.3.2). We denote by
ya(t) =
⎛
⎜⎝
y(1)
a (t)
...
y(m)
a
(t)
⎞
⎟⎠
the complex envelope of the received M × 1 vector computed at a frequency of demodulation denoted
by f0. We consider that ya(t) obeys the linear model
ya(t) =
K

k=1
ya,k(t),
where ya,k(t) is the contribution of the kth source to the observation. We further assume that ya,k(t)
stems from delayed/attenuated versions of sa,k(t). In this respect, we may write y(m)
a,k (t), the component
of ya,k(t) associated with the mth sensor, as:
y(m)
a,k (t) =
Lk

ℓ=1
λk,m,ℓe−ı2π f0τk,m,ℓ˜sa,k(t −τk,m,ℓ),
(4.9)
where the index ℓrepresents the path index, Lk the number of paths associated with the source no
k, λk,m,ℓan attenuation factor and τk,m,l the delay of the propagation along the path no ℓbetween the
source no k and the sensor no m. In this latter equation, ˜sa,k(t) is the complex envelope of the modulated
signal sa,k(t)eı2π fkt at the demodulation frequency, i.e., ˜sa,k(t) = sa,k(t)eı2π( fk−f0)t.

146
CHAPTER 4 Blind Signal Separation for Digital Communication Data
2.04.2.3.1
Models of the sampled data
We distinguish between two cases:
1. Instantaneous mixture: This scenario holds when the signal ya,k(t) evolves in a linear space of
dimension 1, that is when the components ˜sa,k(t −τk,m,ℓ) in (4.9) do not depend neither on ℓ
nor on m. This holds when there exists τk such that |τk,m,ℓ−τk| ≪Tk for all indices m, ℓ. This
happens, for instance, when there is a single path (Lk = 1) and the transmitted signal is narrow-band
( fk ≫1/Tk). In this case we have
ya(t) =
K

k=1
h1,ksa,k(t −τk)eı2π( fk−f0)t.
More compactly, this gives
∀t ∈R ya(t) = H sa(t),
where H = (h1,1, . . . , h1,K ) is a M × K mixing matrix, and
sa(t) = (sa,1(t −τ1)eı2π( f1−f0)t, . . . , sa,K (t −τK )eı2π( fK −f0)t)T .
(4.10)
If Te is the sampling period of the receiver, it is supposed that all the components of the data are
low-pass ﬁltered in the sampling band (the matched-ﬁlter cannot be considered since the shaping
ﬁlters are not supposed to be known to the receiver). Finally, the (noiseless model) of the data is
General instantaneous model: ∀n ∈Z y(n) = H s(n),
(4.11)
where
s(n) = (sa,1(nTe −τ1)eı2π( f1−f0)nTe, . . . , sa,K (nTe −τK )eı2π( fK −f0)nTe)T .
(4.12)
Generally speaking, any of the components of the source vector s(n) is cyclo-stationary (see Section
2.04.2.2)hencethemodelgivenby(4.11)isacyclo-stationaryone.Forsimpliﬁcation,letussuppose
in the following that fk = f0 for all the indices k (this point is discussed in Section 2.04.7). As
the original theory of BSS assumed stationary data, we inspect under which conditions the above
model can be stationary. A necessary and sufﬁcient condition is that all the components of s(n) be
stationary. As discussed previously, this can happen when all the symbol periods are equal to, say,
T and if the sampling period Te = T . Under these conditions, we even have:
sa,k(t −τk) = [cτk,k(z)]dk(n),
where we have set for any delay τ
cτ,k(z) =

ℓ
ca,k(ℓTk −τ)z−ℓ.
(4.13)
The stationary model can be written as:
Stationary instantaneous model: ∀n ∈Z y(n) = H s(n),
(4.14)

2.04.2 Signals
147
where we have set
s(n) =
⎛
⎜⎝
[cτ1,1(z)] d1(n)
...
[cτK ,K (z)] dK (n)
⎞
⎟⎠.
(4.15)
(note: the notation might be confusing since s(n) was already deﬁned in (4.12): in the following
sections, the context is always speciﬁed which prevents the confusion) In the literature, it is some-
times required that the sources be i.i.d. In the context of this paper, this i.i.d. condition is fulﬁlled
when the ﬁlters cτk,k(z) all have the form of a constant times a delay: in short, this happens when
(1) all the transmitted symbols are synchronized (2) the receiver runs a matched ﬁlter (square-root
Nyquist), and (3) the symbol synchronization is performed at the receiver. In this case we have:
i.i.d. instantaneous model: ∀n ∈Z y(n) = H
⎛
⎜⎝
d1(n)
...
dK (n)
⎞
⎟⎠.
(4.16)
The reader may ﬁnd this set of condition very restrictive in real scenarios. It is indeed; however, the
developments of BSS are based on the stationary assumption. Moreover, many interesting methods
exploit the i.i.d. condition.
2. Convolutive mixture: This is the general case when multi-paths affect the propagation. We provide
the discrete-time version of Eq. (4.9). Let us begin by the general case. In this respect, we assume
that the sampling period Te veriﬁes the Shannon sampling condition, i.e.,
1
Te
> max
k
1 + γk
Tk
+ | fk −f0|

.
This is a non-restrictive condition whatever the scenario: a crude prior spectral analysis of the
data is simply needed. Provided this condition, the discrete-time signal sa,k(nTe −τk,m,ℓ), for any
indices k, m, ℓ, is a ﬁltered version of (sa,k(nTe))n∈Z. It is hence easy to deduce that the sampled
data y(n) follows the equation:
General convolutive model: ∀n ∈Z y(n) = [H(z)]s(n),
(4.17)
where s(n) = (sa,1(nTe)eı2π( f1−f0)nTe, . . . , sa,K (nTe)eı2π( fK −f0)nTe) is a vector of mutually
independent sources and H(z) is certain the M × K transfer function whose kth column is
the digital channel between the kth source and the receiver: it depends on the parameters
(λk,m,ℓ, τk,m,ℓ)ℓ=1,...,Lk, m=1,...,M. The above general model is, in general, cyclo-stationary. For
simpliﬁcation, we assume ion the following that fk = f0 for all indices k. Similarly to the case of
instantaneous mixtures, it is instructive to ﬁnd conditions under which the data are stationary. This
occurs when the symbol periods Tk all coincide with a certain T, and when the sampling period Te
equals T. Under all these conditions, yk(n), the contribution of the kth source to the mixture, can
be written as
yk(n) =
⎛
⎜⎝

ℓλk,1,ℓ[cτk,1,ℓ,k(z)]dk(n)
...

ℓλk,M,ℓ[cτk,M,ℓ,k(z)]dk(n)
⎞
⎟⎠= [Ek(z)]dk(n),

148
CHAPTER 4 Blind Signal Separation for Digital Communication Data
hence, setting E(z) = (E1(z), . . . , EK (z)), it yields
Stationary convolutive model: ∀n ∈Z y(n) = [E(z)]d(n),
(4.18)
where d(n) = (d1(n), . . . , dK (n))T and E(z) is a certain M × K unknown ﬁlter matrix. This shows
that E(z) depends on the shaping ﬁlters, the steering vectors associated with the paths and their
corresponding delays.
2.04.2.3.2
Assumptions on the channels
In this paper, we consider over-determined mixtures, that is: mixtures such that the number of sensors
exceeds the number of sources (M ≥K). This condition is necessary in order to retrieve the vector
s(n)—see model (4.11) (respectively (4.17) )—from the data y(n) by means of a K × M constant matrix
(respectively a K × M ﬁlter). This has to be speciﬁed.
For instantaneous mixtures, the following condition holds:
Assumption (instantaneous mixtures): rank(H) = K.
(4.19)
Under this assumption, there exist K × M matrices G such that Gy(n) = s(n).
For convolutive mixtures, it is conventional to assume that the components of H(z) are polynomials
in z−1 (this is an approximation that is justiﬁed since the shaping ﬁlters ca,k(t) are rapidly vanishing
when |t| →∞). We further assume that
Assumption (convolutive cyclostationary mixtures): ∀z ̸= 0 rank(H(z)) = K.
(4.20)
Under this condition, there exist polynomial matrices G(z) such that [G(z)]y(n) = s(n): see for instance
[12,13]. The same kind of assumption holds in the stationary case—see the model (4.18): namely,
Assumption (convolutive stationary mixtures): ∀z ̸= 0 rank(E(z)) = K.
(4.21)
At this level, we would like to point out a curiosity. In this respect, we assume further that the excess
bandwidth factors of one source—say the ﬁrst one—equals zero. As the choice Te = T1 satisﬁes the
Shannon sampling condition, we may write sa,1(nT1 −τ) = [φτ(z)]sa,1(nT1) where
φτ(z) =

k
T1
π(kT1 −τ) sin
π(kT −τ)
T1

z−k.
As sa,1(nT1) = [c0,1(z)]d1(n), the ﬁrst column E1(z) of E(z) can be factored as c0,1(z) ˜E1(z). In
particular, after the standard FIR approximations, it yields that the condition given in (4.21) is not
fulﬁlled.
2.04.3 Instantaneous mixtures
The model of the data y(n) is given by (4.11). The mixing matrix H is unknown. BSS can be achieved
either by estimating H—this is the point of Section 2.04.3.3—or by computing directly estimates of the
sources (up to indeterminacies).

2.04.3 Instantaneous Mixtures
149
2.04.3.1 Indeterminacies
It is always possible to consider that the sources have equal and normalized power. Indeed, as s1(n) =
ρ1 s1(n)
ρ1
where ρ1 =

⟨E[|s1(n)|2]⟩is the square-root of the power of the ﬁrst source, we suggest to
scale the ﬁrst column of H by ρ1. Repeating this process for all the sources, we have constructed a
new matrix ˜H. Eventually denoting ˜s(n) =

s1(n)
ρ1 , s2(n)
ρ2 , . . . , sK (n)
ρK
T
, we obviously show that the data
alternatively writes
∀n ∈Z y(n) = ˜H ˜s(n).
Though apparently innocent, this remark gives precious a priori indications. First of all, it says that
the model (4.22) is not uniquely deﬁned. As a consequence, it is always possible to consider, without
restricting the model, that the sources have equal power equal to one—this precisely corresponds to the
above deﬁned ˜s(n); speciﬁcally, we will assume in the following that

E

s(n)s(n)H
= IK
(4.22)
This shows it is beyond a reasonable expectation to retrieve the sources with no scaling ambiguities.
Similarly, if P is a permutation matrix, y(n) = (HP−1)(Ps(n)), underlining the non-unicity of the model.
With no further assumptions on the sources, the ultimate result that can be achieved is: retrieve the
sources up to unknown complex scaling factors (scaling and phase ambiguities) and a permutation.
2.04.3.2 Algebraic methods (i.i.d. scenario)
The model of the data is given by (4.16). We may collect the N available data in a M × N matrix Y,
we have: Y = HD where D = (d(0), . . . , d(N −1)). As any entry of D corresponds to a symbol,
associated speciﬁcities (e.g., ﬁnite alphabet constellations or modulus one symbols) are a priori relations
the receiver can make use of. As far as the identiﬁability is concerned, it is proven in [14] (Lemma 1)
that the above factorization is essentially unique for modulus one symbols, at least if the number of
snapshots N veriﬁes N ≥2K (which is the case in practical contexts). By essentially unique, we mean
that the rows of D may be permuted and/or multiplied by modulus one constants.
Talwar et al. [15,16] propose iterative algorithms that assume known the alphabets of the symbols.
Call ˆH(ℓ) an estimate of H at the iteration no ℓ. The Iterative Least Square with Projection (ILSP) is:
1. Take any full rank ˆH(0) for iteration ℓ= 0
2. ℓ←ℓ+ 1
•
ˆD(ℓ) = ( ˆH(ℓ−1))♯Y where (.)♯denotes the pseudo-inverse.
•
ˆD(ℓ) ←projection of each component of ˆD(ℓ) on the corresponding alphabet.
•
ˆH(ℓ) = Y( ˆD(ℓ))♯.
Similar projection-based algorithms that rather take into account the constant modulus property of
the entries of D have been considered [17,18]: similarly to the IMSP algorithm, no results on the
convergence can be given (how many samples are required? are there local minima the algorithm could
be trapped in?). Van der Veen et al. [14] proposes a non-iterative algorithm, called the Algebraic CMA

150
CHAPTER 4 Blind Signal Separation for Digital Communication Data
(ACMA): the ACMA provides exactly “the” solution (up to the above mentioned ambiguities) of the
factorization of Y—at least if the number of data N exceeds K 2. It is based on a joint diagonalization
of a pencil of K matrices.
Certain BSS methods for convolutive mixtures need, as a ﬁnal step, to run such algorithms (see
e.g., Section 2.04.5.1).
2.04.3.3 Second-order based identiﬁcation (general cyclo-stationary case)
In this section, we address the “indirect” BSS; by this terminology, we mean that the BSS is achieved
in two steps. The ﬁrst step consists in estimating the unknown mixing matrix H by, say, ˆH. In a second
step, the proper separation is carried out. If ˆH is an accurate estimate, then ˆs(n) = ˆH♯y(n) is the natural
estimate of the source vector. In general, however, noise is present (estimation noise and additive noise
in the observed signals) and other strategies have to be considered: this aspect is not addressed in
this paper.
The ﬁrst point to be addressed in this section is the pre-whitening of the data. We suppose that
M = K (notice: in the non-square case, a principal component analysis is processed). In this respect,
we consider the auto-correlation matrix of the data R(0)
y (0) = ⟨E[y(n)y(n)H]⟩can be written (we recall
that the sources are assumed to have equal normalized powers as discussed previously):
R(0)
y (0) = HHH.
Since H is full rank, the above matrix is positive deﬁnite and we form the new data
x(n) =

R(0)
y (0)
−1/2 y(n).
We have:
x(n) = Us(n),
where U =

HHH−1/2H is a unitary matrix.
The second point concerns the estimation of the unitary matrix U. The data x(n) is cyclo-stationary.
As the cyclic-frequencies are not always directly accessible, the identiﬁcation of the unknown mixing
matrix U is done by solely considering the statistics
R(0)
x (ℓ) =

x(n + ℓ)x(n)H
,
which can be expressed as
R(0)
x (ℓ) = UR(0)
s (ℓ)UH.
This says that the normal matrix R(0)
x (ℓ), for any index ℓ, is diagonalized in the orthonormal basis
formed by the columns of U. For ℓ= 0, this gives R(0)
x (0) = UUH = I and this is clearly not sufﬁcient
to identify U! On the contrary, consider that the spectra of the sources S(0)
sk (ν) = 
ℓR(0)
sk (ℓ)e−ı2πℓν
are all different at least for a frequency ν. For any unitary matrix V, the matrix VH R(0)
x (ℓ)V is diagonal
for every indices ℓif and only if the columns of V equal these of U up to a modulus one factor and
a permutation. This remark was done in [19] and an algorithm (SOBI) was deduced based on a joint
diagonalization technique [20].

2.04.3 Instantaneous Mixtures
151
The reader has noticed the suboptimality of the above method when the mixture is cyclo-stationary.
The exploited statistics are only the R(0)
x (ℓ) for certain indices ℓ. In [21], it is suggested to take advantage
of the cyclic-statistics of the mixture. In this respect, notice that for any α cyclic frequency of the mixture,
we have
R(α)
x (ℓ) = UR(α)
s
(ℓ)UH
hence these “new” statistics could be added in the pencil of matrices to be jointly diagonalized. This
theoretical appeal is attenuated by the fact that the non null-components of R(α)
s
(ℓ) are numerically
inconsistent.
At this level, we should emphasize that the statistics R(α)
x (ℓ) for any α (zero or not) are not accessible
to the receiver and should be replaced by the empirical estimate denoted by ˆR(α)
x (ℓ) and deﬁned for
ℓ≥0 as
ˆR(α)
x (ℓ) = 1
N
N−ℓ−1

n=0
x(n + ℓ)x(n)He−ı2παn,
(4.23)
where N is the number of snapshots. This estimate is a consistent estimate of the matrix R(α)
x (ℓ). In an
ideal scenario where the model x(n) = Us(n) holds true, it is remarkable that ˆR(α)
x (ℓ) = U ˆR(α)
s
(ℓ)UH
and the joint diagonalization of the estimated statistics should provide the exact mixing matrix: the
algorithm is called deterministic. In a realistic context, however, the data are perturbed by an additive
noise term: in this case, the above factorization does not hold true anymore and the joint diagonalization
is an approximate joint diagonalization.
In practice, despite its attractivity, SOBI is seldom used to achieve BSS of digital communication data.
Indeed, the condition that there are no two sources whose spectra are identical (up to a multiplicative
constant) does not make sense most of the time. Indeed, the transmitted symbols are generally white
sequences whose shaping functions are close from to one another. As the spectra are numerically similar,
the joint diagonalization approach is bound to suffer from numerical problems.
2.04.3.4 Iterative BSS (stationary case)
As was speciﬁed, the stationary scenario assumes that for all indices k : Tk = T , i.e., all the baud-rates
are equal, and Te = T . Under these very speciﬁc circumstances, the model (4.14) involves a source
vector s(n) whose components are stationary and mutually independent. We insist on the fact that the
components of the source vector are not the i.i.d. symbol sequences but linear processes generated by
these symbol sequences as indicated by Eq. (4.15). BSS aims at estimating the sources, not the symbol
sequences. Hence, BSS may be seen as a preliminary step before the estimation of the symbols.
Contrary to other methods, no pre-processing of the data is necessary (PCA, pre-whitening).
In this section, we ﬁrstly design methods able to recover one of the sources (or a scaled version).
In a second step, we present the so-called deﬂation that allows one to run the extraction of another source
from a deﬂated mixture where the contribution of the ﬁrst estimated source has been removed. The
convergence is established: after K such steps, the K sources are expected to be estimated. Convergence
properties are discussed.

152
CHAPTER 4 Blind Signal Separation for Digital Communication Data
2.04.3.4.1
Estimation of one source: theoretical considerations
Thanks to the mixing matrix H having full-rank—see condition (4.19)—we know that, for any source
index k, there exist column vectors gk such that
gT
k y(n) = sk(n).
Denoting rk(n) = gT
k y(n), we may call this new signal as the reconstructed source since it involves
only one source. This new signal is obtained after a so-called spatial ﬁltering of the data. Of course, it
is not possible to compute gk since H is not accessible. A possible approach hence consists in adapting
a spatial ﬁlter g that makes
r(n) = gT y(n)
(4.24)
resemble one of the sources. This will be done by considering particular statistics of the signal r(n).
We may write this signal under this form
r(n) =
K

k=1
fksk(n),
(4.25)
where the taps fk are the components of the vector
f = gT H.
(4.26)
The term fksk(n) in r(n) represents the contribution of the kth source to the reconstructed signal r(n).
As may be easily understood, we aim at ﬁnding a “good” g, i.e., such that f is a vector having a single
non-null component.
Deﬁnition 2.
A vector f is said to be separating if all its components are null except one.
Evidently, the signal r(n) involves a single source if and only if the composite vector f is separating.
We may inspect higher-order statistics and particularly the fourth-order ones. It has been proposed
to consider the fourth-order cumulant (see Section 2.04.3.6 for theoretical justiﬁcations):
κ(r) = cum(r(n),r(n)∗,r(n),r(n)∗).
In this respect, we may introduce the following function, called normalized (fourth-order) cumulant:
ϒ(r) =
κ(r)

E

|r(n)|22 .
(4.27)
Thanks to the deﬁnition of the cumulants, we have: κ(r) = E[|r(n)|4] −2(E[|r(n)|2]) −|E[r(n)2]|2.
Now, the circularity assumption of the symbol sequences (4.2) implies the circularity of the sources,
hence
E

r(n)2
= 0.
We re-express ϒ(r) as a function of the moments of r(n):
ϒ(r) =
E

|r(n)|4

E

|r(n)|22 −2.
(4.28)

2.04.3 Instantaneous Mixtures
153
We have the result:
Proposition 3.
As, by assumption, the Kurtosis of the sources, κ(dk), are strictly negative, the function
ϒ(r) achieves its minimum at a separating vector. Moreover, the separating vector in question has its
single non-null element located at an index k0 such that ϒ(sk0) = mink=1,...,K ϒ(sk).
Proof.
On the one hand, the mixture r(n) is a linear mixture of independent random variables.
The multi-linearity of the cumulants [6] gives:
κ(r) =
K

k=1
| fk|4 κ(sk).
After noticing that E

|r(n)|2
= 
k | fk|2 we arrive at the expansion:
ϒ(r) =
K
k=1 κ(sk)| fk|4
K
k=1 | fk|2
2 .
(4.29)
On the other hand, sk(n) is a linear process generated by the i.i.d. symbol sequence dk(n):
see Eq. (4.7). As was supposed (or noticed) in the Introduction, κ(dk) < 0 hence
κ(sk) < 0
for any index k. The sources are sometimes referred to as platykurtic sources. Denote by κmin =
min (κ(s1), . . . , κ(sK )). Thanks to the above result, κmin < 0. Hence κ(r) ≥−|κmin| 
k | fk|4. Besides,
we recall that

k | fk|22 ≥
k | fk|4 with equality if and only if the coefﬁcients | fk| are all null except
one, i.e., if and only if the vector f is separating.
We insist on the fact that the assumption that one of the κ(sk) is strictly negative is funda-
mental. Imagine on the contrary that, for all the indices k, κ(dk) > 0. Then K
k=1 κ(sk)| fk|4 ≥
mink κ(sk)
K
k=1 | fk|4
. As

1
K
K

k=1
| fk|4

≥

1
K
K

k=1
| fk|2
2
with equality iff all the | fk| are equal, this implies that the argument minima of ϒ(r) are not separating
(on the contrary, the coefﬁcients fk equally weigh the sources).
□
As a remark, it is instructive, though superﬂuous in this paper since the digital communication
symbols have negative Kurtosis, to address the optimization of ϒ(r) for general distributions of the
κ(sk): the reader may ﬁnd the details in [5].
One may inspect the minimum minimorum of ϒ(r) over all the possible constellations. The Jensen
inequality (see [22] p. 80) gives: E[(ϕ|r(n)|2)] ≥ϕ(E[|r(n)|2]) for a convex mapping ϕ; the equality
is achieved when |r(n)| = 1. Taking ϕ(x) = x2, we obtain
ϒ(r) ≥−1

154
CHAPTER 4 Blind Signal Separation for Digital Communication Data
and the equality is achieved when r(n) has unit modulus. Of course, this can only happen if one of the
sources has a modulus equal to one or, there exists an index k such that ϒ(sk) = −1. This does not
happen in general, but this remark shows that the minimization of ϒ(r) tends to make r(n) resemble as
much as possible a constant modulus sequence. We inspect this point a bit further. A way to measure
the distance of r(n) to the modulus one is simply to consider
ϒC M(r) = E

|r(n)|2 −1
2
.
(4.30)
This function was originally considered for deconvolution problems [23,24] and then for source sepa-
ration problems ([25–27] for instance).
We may bridge the gap between ϒ(r) and ϒC M(r):
Proposition 4.
Deﬁne ϒC M,inf = infr ϒC M(r) and ϒinf = infr ϒ(r). The minimization of ϒC M(r)
is linked to the minimization of ϒ(r) in the sense that:
ϒC M,inf = 1 −
1
2 + ϒinf
,
if f achieves to minimize ϒ then

1
2+inf ϒ
1
∥f∥f is a minimizer of ϒC M. Conversely, if f achieves to
minimize ϒC M, then ρf minimizes ϒ for any ρ ̸= 0.
Proof.
For any f, we have: ϒC M(r) = E[|r(n)|4]−2E[|r(n)|2]+1. Thanks to the expression of ϒ(r)
in (4.28), it is always true that: E[|r(n)|4] ≥(2 + ϒinf)(E[|r(n)|2])2. We hence have:
ϒC M(r) ≥(2 + ϒinf)

E

|r(n)|22 −2E

|r(n)|2
+ 1.
We set ρ = E

|r(n)|2
. The second-order polynomial ρ →(2 + ϒinf)ρ2 −2ρ + 1 has minimal value
1 −
1
2+ϒinf for ρ =
1
2+ϒinf . We deduce the inequality: ϒC M(r) ≥1 −
1
2+ϒinf . If f reaches the inﬁmum
of ϒ(r) then, evidently, the choice

1
2+ϒinf
1
∥f∥f makes ϒC M(r) = 1 −
1
2+ϒinf . Hence 1 −
1
2+ϒinf is the
minimum of ϒC M(r). Conversely, for any r(n), by deﬁnition, we have: E

|r(n)|4
−2E

|r(n)|2
+1 ≥
ϒC M,inf. In this inequality, substitute √ρr(n) for any positive ρ. We have:
ρ2E

|r(n)|4
−2ρE

|r(n)|2
+ 1 ≥ϒC M,inf.
This is in particular true for ρ = E

|r(n)|2
E[|r(n)|4] hence showing that −(E[|r(n)|2])2
E[|r(n)|4]
+ 1 ≥ϒC M,inf or
ϒ(r) ≥2 +
1
1 −ϒC M,inf
.
The case of equality in the latter equation occurs when f is any non-null scaled version of a minimizer
of ϒC M
□

2.04.3 Instantaneous Mixtures
155
As is explained in the next section, the search of a global minimum of ϒ(r) or ϒC M(r) is done
according to a gradient method. It is well known that such an algorithm may be stuck in a local
minimum of the function to be minimized. We have the result (see [5], Lemma 1):
Lemma 5.
Fix K real constants βk < 0. The local minima of the function f →K
k=1 βk| fk|4 over
the unit sphere K
k=1 | fk|2 = 1 are the separating vectors (of unit norm).
Thanks to the expansion (4.29), and the fact that for all the sources βk = κ(sk) < 0, the local
minima of ϒ(r) over the unit sphere are the separating vectors (of unit norm). After simple topological
considerations, it can even be deduced that:
Proposition 6.
Any local minimum of ϒ is separating.
As far as the function ϒC M is concerned, we have:
Proposition 7.
Any local minimum of ϒC M is separating.
Proof.
We consider the arguments given in [28]. The idea consists in writing f in its polar form
f = ρ˜f where ρ = ∥f∥and ∥˜f∥= 1. After setting ˜r(n) =
1
∥f ∥r(n) the normalized version of r(n), we
have: ϒC M(r) = ρ4E

|˜r(n)|4
−2ρ2E

|˜r(n)|2
+ 1. Write this function ψ(ρ, ˜f). Necessarily, for a
stationary point of ϒC M the derivative of ψ w.r.t. ρ is zero. This gives: ρ = 0 or ρ(˜f) =
E

|˜r(n)|2
E

|˜r(n)|4.
The case ρ = 0 can be shown to correspond to a local maximum [26]. This says that a local minimum
of ϒC M is a local minimum of ψ(ρ(˜f), ˜f). Now, this latter function is:
ψ(ρ(˜f), ˜f) = 1 −
1
ϒ(˜r).
We deduce that such a local minimum is also a local minimum of ϒ(r) on the unit sphere. Thanks to
Lemma 5 we deduce that the local minimum in question is separating.
□
2.04.3.4.2
Estimation of one source: practical aspects
Basic algorithms: Two problems arise when one focuses on the implementation of the results presented
so forth: the ﬁrst one concerns the estimation of the cost functions ϒ(r) or ϒC M(r), the second one is
to choose a method able to ﬁnd the argument minima of these estimated functions.
The two functions we have considered involve second and fourth-order moments of the signal r(n).
As the number of available data is ﬁnite—say, we observe y(n) for n = 0, . . . , N −1—it is not possible
to compute any of the moments of r(n). However, a version of the law of large numbers allows one to
consider estimates of the moments:
Lemma 8.
For p = 2, 4, we have, with probability one:
1
N
N−1

n=0
|r(n)|p −→E[|r(n)|p].

156
CHAPTER 4 Blind Signal Separation for Digital Communication Data
We are in position to estimate both functions ϒ(r) and ϒC M(r) respectively by
ˆϒ(r) =
1
N
N−1
n=0 |r(n)|4

1
N
N−1
n=0 |r(n)|2
2 −2,
(4.31)
ˆϒC M(r) = 1
N
N−1

n=0

|r(n)|2 −1
2
.
(4.32)
Indeed, we have the result:
Proposition 9.
ˆϒC M(r) −→ϒC M(r) and ˆϒ(r) −→ϒ(r) with probability one.
The functions ˆϒC M(r) and ˆϒ(r) to be minimized are non-convex, and the associated machinery
cannot be considered. The functions, however, are regular w.r.t. the parameter g. Hence, we choose to
seek the argument minima by means of a gradient method. For instance, consider the minimization of
ϒC M. The notation for the gradient of ˆϒC M calculated at the point g being ∇ˆϒC M(r), the gradient
algorithm, for a ﬁxed μ > 0, can be written as:
1. choose an initial vector g(0) and compute r(0)(n) = g(0)T y(n) for all the available data;
2. at the mth step: compute g(m) = g(m−1) + μ∇ˆϒC M(r(m−1)) and the associated updated signal
r(m)(n) = g(m)T y(n);
3. redo the above step until the convergence is reached.
The same algorithm could be written for the minimization of ˆϒ. However, the fact this latter function is
homogeneous may involve numerical problems (the vector g is not bounded). This is why the projected
gradient algorithm is prefered: it consists in normalizing at each iteration of the algorithm the updated
signal r(m)(n), i.e., projecting the current parameter g(m) on the set

g | gT

1
N
N−1

n=0
E[y(n)y(n)H]

g = 1

.
Whatever the considered cost function, the parameter μ controls the performance. The next section
faces the problem of choosing μ.
Reﬁnement: choosing a locally optimal μ. For simplicity, the minimization of ϒC M is addressed. The
same idea may be considered for the minimization of ϒ by means of the projected gradient. In order
to boost the speed of convergence, it has been proposed to change μ at each step of the algorithm: the
parameter μ is chosen such that the value of the function evaluated at the point g(m) is minimum. It is
easily seen that the function μ →ˆϒC M(r(m)) is a polynomial of degree four. The minimum is hence
easily (numerically) computed.
Robustness of the algorithms to the presence of local minima: It is well-known that such a gradient
algorithm may be trapped in a local minimum: this, in general, is a clear limitation to the use of such
an algorithm. Of course, it is not possible to say much on the local minima of the estimated functions
ˆϒ(r) and ˆϒC M(r). However, Propositions 6 and 7 indicate that, asymptotically, if the algorithms are
trapped in a local minimum, this does not impact the performance since this local minimum is precisely
separating. This remark certainly explains why the algorithms show very good performance.

2.04.3 Instantaneous Mixtures
157
2.04.3.4.3
The deﬂation step
The algorithms depicted above provide a way to retrieve one of the sources. Of course, we aim at
estimating all the sources. An idea hence consists in running again the previous algorithm. However, it
is not possible to guarantee that the second extracted source is not the ﬁrst extracted one. In the literature,
three methods have been presented that overcome this major problem.
In the ﬁrst one [29] it is proposed to penalize the cost function ϒ(r) or ϒC M(r) by adding to them a
positive term that gives a measure of decorrelation between the current signal r(n) and the previously
extracted source. It is simple to show that, indeed, the global minimum is achieved if and only if the r(n)
is an other source. However, this approach has been noticed to show poor performance. The reason is
that the extended cost function, contrary to the original, has many local minima that do not correspond
to separating solutions. The algorithms is known to be trapped in such local minima and, in this case,
the provided solution is not an estimate of one of the remaining sources.
The second one is algebraic: the idea is to estimate the subspace associated with the ﬁrst estimated
source and to run the minimization of ϒ(r) or ϒC M(r) on the orthogonal complement of the subspace
in question: see [5].
The third is the most popular for source separation [30,31]: it consists in deﬂating the mixture by
subtracting an estimation of the contribution of the extracted source and then to redo the minimization
of ϒ(r) or ϒC M(r). Ideally, the “new” mixture should not involve the source that has been extracted
and the minimization hence allows one to estimate another source. We provide some details.
Thanks to the previous results, we may suppose that we haver(1)(n) ≈αs1(n) where α is an unknown
scaling. We have arbitrarily considered that the extracted source was the one numbered “1”: this has
of course no impact on the generality. The contribution of the ﬁrst source in the mixture y(n) has the
form h1s1(n) where h1 is the ﬁrst column of the mixing matrix. We adopt a least square approach: the
contribution of the ﬁrst source is estimated as ˆh(1) where this vector is deﬁned as the minimizer of
h →
N−1

n=0
  y(n) −hr(1)(n)
  2.
Then the “deﬂated mixture” to be considered is
y(2)(n) = y(n) −ˆh(1)r(1)(n).
Ideally, the deﬂated mixture should not involve the ﬁrst source. Hence running the Constant Modulus
algorithm on this mixture should provide an estimate r(2)(n) of another source—say s2(n). The deﬂation
is done again: this time ˆh(2)r(2)(n) is an estimation of the contribution of the second source. The deﬂated
mixture is
y(3)(n) = y(2)(n) −ˆh(2)r(2)(n).
And so forth until all the source are estimated. Notice that, asymptotically (when N →∞) the deﬂation
procedure is convergent: in K steps the K sources are estimated.
2.04.3.4.4
Improving the deﬂation
Though its inherent advantages (simplicity, convergence of the algorithm of extraction), the above
approach is supposed to suffer from the K deﬂation steps. Indeed, the deﬂation is expected to increase,

158
CHAPTER 4 Blind Signal Separation for Digital Communication Data
step after step, the noise level, impinging dramatically the extraction of the “last” source. This aspect
has already been addressed and partially got round: we shortly address the re-initialization procedure
introduced in [32].
Consider the extraction of the “second” source and apply the deﬂation technique. The source extrac-
tion algorithm is run on the deﬂated mixture and is likely to provide a spatial ﬁlter g(2). We have, up to
a scaling factor:
g(2)T
⎛
⎝y(n) −ˆh(1)g(1)T y(n)
!
"#
$
deﬂated mixture
⎞
⎠≈s2(n),
which provides the approximation:
gT y(n) ≈s2(n),
where gT = g(2)T (IM −ˆh(1)g(1)T ). We hence have computed a spatial ﬁlter g that is close to a separating
ﬁlter w.r.t. the initial mixture. The idea is hence the following: run the algorithm of minimization on the
initial mixture, taking g as an initial point. As g is close to a ﬁlter that is a local minimum of the function
to minimize (see Propositions 6, 7), the computed spatial ﬁlter hence obtained after convergence is likely
to separate s2 from the initial mixture. This procedure can be iterated: at each step, the separation is
processed on the initial y(n) and not on a deﬂated mixtures. Though simple, this procedure considerably
enhances the performance.
2.04.3.4.5
Extensions
Many contributions in BSS consider such functions as
ϕ(κ(r))
(4.33)
over the unit sphere E[|r(n)|2] = 1 where ϕ : R →R is any continuous function on R such that
ϕ(0) = 0 and ϕ is strictly monotone over R+ and R−. The most common choices are ϕ1(x) = x2 and
ϕ2(x) = |x| and ϕ3(x) = −x. It quite simple to prove the following result:
Proposition 10.
Provided that ϕ(κ(rk)) > 0 for at least one source, then the local maxima of (4.33)
are separating.
2.04.3.5 Global BSS (stationary mixture)
In this section, we present global methods, i.e., methods that “invert” the system in one shot. Assuming
that K = M, it is possible to linearly transform the data such as in Section 2.04.3.3. The “new” data
can be written as
x(n) = U s(n),
where U is a unitary K × K matrix. A global BSS method hence aims at determining a unitary matrix
V such that the components of
r(n) = Vx(n)
correspond to the sources up to modulus one scalings and a permutation. In this respect, we suggest to
take proﬁt of certain results of Section 2.04.3.4.

2.04.3 Instantaneous Mixtures
159
2.04.3.5.1
First result
Denote by rk(n) the kth component of r(n). Due to the pre-whitening, we have: E[|rk|2] = 1, hence
ϒ(rk) = κ(rk). This later can be seen as a function of the kth row of the matrix V. We have shown that
ϒ(rk) is minimum if rk corresponds to one of the sources up to a modulus one scaling, i.e., if the kth
row of F = VU is separating, its non-zero component being located at an index corresponding to the
sources that have the smallest Kurtosis. The idea is hence to form the function
(r) =
K

k=1
κ(rk).
(4.34)
Obviously, we have (r) ≥K mink=1,...,K κ(sk). Conversely, this lower bound cannot be achieved
in general: assume for instance that mink=1,...,K κ(sk) is reached once: say, the ﬁrst source. The above
lower bound is achieved only if F is the matrix having non-zero components on the ﬁrst column only.
This of course violates the constraint that F is unitary. We have the following tight result:
Proposition 11.
As κ(sk) < 0 for all the sources, we have, for any unitary F:
(r) ≥(s) =
K

k=1
κ(sk).
(4.35)
Moreover, the inequality is an equality if and only if F = VU essentially equals the identity matrix.
Proof.
By “essentially equal to,” we mean that F is a diagonal matrix with modulus entries, whose
columns are permuted. The proof of this result follows the proof of Proposition 3 and was suggested
by Common in [2]. We indeed, express (r) as
(r) =
K

i=1
K

k=1
κ(sk)| fi,k|4 = −
K

i=1
K

k=1
(|κ(sk)|1/4| fi,k|)4.
On the other hand, we have the inequality:
K

k=1

|κ(sk)|1/4| fi,k|
4
≤
 K

k=1
|κ(sk)|1/2| fi,k|2
2
implying that
−(r) ≤
K

i=1
 K

k=1
|κ(sk)|1/2| fi,k|2
2
.
(4.36)
We now denote by F the matrix whose component (i, k) is | fi,k|2
and by b(1/2)
=
(|κ(s1)|1/2, . . . , |κ(sK )|1/2)T so that the r.h.s. of (4.36) is simply ∥F b(1/2)∥2
2. As FFH = IK we deduce
that the sum of the elements of any row/column of F is equal to one: F is called doubly stochastic.
As a consequence of the Birkhoff theorem (see [33] Chapter 2), F can be seen as the convex sum of

160
CHAPTER 4 Blind Signal Separation for Digital Communication Data
permutation matrices, i.e., F = K
j=1 λ jP j where, for any index j, λ j ≥0 and K
j=1 λ j = 1. We
deduce that
  F b(1/2)  2
2 ≤
⎛
⎝
K

j=1
λ j
  P j b(1/2)  
2
⎞
⎠
2
=
⎛
⎝
K

j=1
λ j∥b(1/2)∥2
⎞
⎠
2
=
K

j=1
|κ(sk)|.
This proves Eq. (4.35). Let us inspect the case of equality. If equality occurs, the inequality (4.36) is
necessarily an equality. Hence we have, for any indices i and k1 ̸= k2
κ4(sk1)κ4(sk2) fi,k1 fi,k2 = 0.
If all the numbers κ(sk) are strictly negative, hence non-null, the above conditions implies that, for
any index i, the vector ( fi,1, . . . , fi,K ), i.e., the ith row of the matrix F, has at most one non zero
component. On the other hand, the matrix F is unitary. This imposes that F essentially equals the identity
matrix.
□
In practice, the function (r) given by Eq. (4.34)cannot be computed. As the data are supposed to
be complex-circular at the second-order, we have
κ(rk) = E

|rk(n)|4
−2.
A consistent estimate of (r) is hence
ˆ(r) =
K

k=1

1
N
N

n=1
|rk(n)|4 −2

.
(4.37)
The minimization of this function is carried out over the space of unitary matrices. This can be done
by using a Jacobi-like algorithm: unitary matrices are parametrized by means of the Given angles. The
reader may ﬁnd details in [2]. Notice that no results concerning the convergence of the algorithm can
be said, since it has not been shown that the local minima of the “true” function (r) are “good ones”,
i.e., achieve the BSS.
2.04.3.5.2
Generalization: notion of contrast function
We introduce the function
ϕ(r) =
K

k=1
ϕ(κ(rk)),
(4.38)
where ϕ : R →R is a function to be speciﬁed. Rather than minimizing ϕ, we address its maximization.
If the maximum is attained when (and only when) BSS is achieved, ϕ is called a contrast function.
As seen previously, the choice ϕ = −Id makes ϕ be a contrast function. We have, more generally:

2.04.3 Instantaneous Mixtures
161
Proposition 12.
If ϕ is a convex function on R such that ϕ(0) = 0 and if, for any source index k the
condition ϕ(κ(sk)) > 0 is fulﬁlled, then ϕ is a contrast function.
Proof.
For any index i, we have: 
k | fi,k|4 ≤

k | fi,k|22. As F is unitary, we deduce that

k | fi,k|2 = 1. Hence 
k | fi,k|4 ≤1. We set ρ = 1 −
k | fi,k|4. The Jensen inequality gives
here:
ϕ

k
κ(sk)| fi,k|4 + 0 (1 −ρ)

≤

k
ϕ

κ(sk)

| fi,k|4 + ϕ(0) (1 −ρ).
As ϕ(0) = 1, we deduce that
ϕ(r) ≤

i

k
ϕ(κ(sk))| fi,k|4.
By assumption all the ϕ(κ(sk)) > 0 hence the same argument as the one given in the proof of
Proposition 11 shows that the maximum is 
k ϕ(κ(sk)) and that this maximum is reached if and
only if the matrix F is essentially the identity.
□
The standard choice for ϕ is ϕ(x) = x2. In this case, is enlightening to notice that maximizing ϕ
is equivalent to minimizing:

i, j,k,ℓnon all equal

cum

ri,r∗
j ,rk,r∗
ℓ
2
(4.39)
which is clearly a measure of independence (up to the fourth-order).
2.04.3.5.3
A popular algorithm: JADE
If the indices j, k are ﬁxed, it may be noticed that the matrix M j,k whose entry i, ℓis given by
cum(xi,, x∗
j , xk, x∗
ℓ)admits the factorization
M j,k = UD j,kU∗,
where D j,k is diagonal; the entry (ℓ, ℓ) is u∗
j,ℓuk,ℓκ(sℓ). Otherwise stated, U diagonalizes the normal
matrix M j,k whatever the indices j, k. Introducing the off(.) operator that sums all the entries of a
matrix except the ones located on the main diagonal, this says that

j,k
off (VM j,kV∗)2
(4.40)
is minimum, equal to zero, when F = VU essentially equals the identity matrix. Conversely, it can
be shown that (4.40) can be written as (4.39). Hence a minimizer of the function given in (4.40) is a
maximizer of φ(r) with φ(x) = x2. Now, Proposition 12 with the fact that, for any index k, (κ(sk))2 >
0 proves that the maximizers of φ(r) are such that F is essentially equal to the identity matrix. This
trick of algebra allows one to achieve the maximization of φ thanks to a joint diagonalization of a set
of normal matrices. It has been proposed by Cardoso [4] The algorithm associated with this approach
is called JADE. It is very popular since efﬁcient algorithms of joint diagonalization are known [20].

162
CHAPTER 4 Blind Signal Separation for Digital Communication Data
Notice that the pencil of matrices is a pencil of normal matrices hence the matrix U is searched
in the set of unitary matrices. Recently, Yeredor et al. [34] suggest to relax the unitary constraint.
These authors even suggest to skip the pre-whitening of the data: they argue that the pre-whitening may
limit the attainable performance as Cardoso pointed it out in [35]. With no whitening of the data, the
matrices of cumulants are still jointly diagonalized; if the channel matrix H is square, the columns of
this latter form a basis for the diagonalization. The converse is not clear on the one hand and, on the
other hand, the case of tall matrices H remains to be addressed.
2.04.3.6 Generalizations
We have presented ad’hoc BSS methods, whose theoretical foundations are solid and whose good
performance is well-known. In the literature, however, many other methods can be found. They stem
from considerations of information theory. We provide some key ideas and related bibliographical
references.
After pre-whitening, we recall that the received data is x = U s (we have dropped the time index):
on the one hand, U is unitary and on the other hand, the component of the random variables in s are
mutually independent. The idea of independent Component Analysis (ICA) is hence to exhibit matrices
V such that the components of r = V x are “as much independent as possible”. This independency may
be measured by the Kullback-Leibler divergence between the distribution of r and this of the product
of the marginals: this is the mutual information I(r). It is well-known that I(r) ≥0 with equality iff
the components of r are independent.
Besides, it has been underlined by Comon in [2] that the Darmois theorem states the fact: as the
sources are non-Gaussian, the fact that the components of r are pair-wise independent (which is naturally
the case if they are mutually independent) implies that F = V U is essentially equal to the identity matrix.
Hence, the minimization of the mutual information of I(r) is legitimate. This induces of course no BSS
algorithm, since the mutual information cannot be simply estimated.
Now, Comon underlines in the seminal paper [2] that I(r) = J (r) −K
k=1 J (rk) where J (r) is
the negentropy of the vector r, i.e., J (r) = H(rgaussian) −H(r): here, H(r) is the differential entropy
of r and H(rgaussian) the differential entropy of the Gaussian vector whose mean and covariance matrix
are those of r. The negentropy shows the nice property of invariance w.r.t. any invertible change of
variables: hence J (r) does not depend on F. The independence is then obtained by maximizing
K

k=1
J (rk).
(4.41)
Notice that J (rk) ≥0 with equality when rk is Gaussian. Hence the maximization in question tends to
maximize the distance of the reconstructed source r to the Gaussian case.
On the other hand, this shows that, in order to achieve independency, it sufﬁces to consider the
maximization of a sum of functions, each of which simply depends on a component of the reconstructed
source vector. Evidently, the maximization of the function J (r1) under the constraint that the ﬁrst row
of F has norm one, is achieved when r1 coincides with one of the sources up to a modulus one factor. In
this respect, this remark provides a justiﬁcation of the iterative methods proposed in Section 2.04.3.4,
even if the function considered are not the negentropy. As far as the function φ(r) is concerned, notice
that it has the form (4.41).

2.04.3 Instantaneous Mixtures
163
Comon proposes an approximation of the negentropy, based on the Edgeworth expansion of the
probability density functions of the random variables rk. Thanks to the circularity assumption, this
approximation is J (rk) ≈
1
48κ(rk)2. This calls for an important remark: the function φ(r) given in
Eq. (4.38) with φ(x) = x2 is hence closely connected to a measure of independence—this conﬁrms a
remark previously done.
Hyvarinen departs from functions based on the cumulants. In [36], it is suggested to consider a
wider class of functions which are not directly related to cumulants. In short, the new functions to
be maximized are more robust to outliers. The price to be paid is the weaker results concerning the
separation: for instance, the precious results concerning the separability of the local maxima do not
hold. An efﬁcient algorithm has given rise to the popular method called FastICA. In the original paper
[36], the sources are real valued which is not the case in this paper. An extension to complex-valued
sources can be found in [3].
2.04.3.7 Iterative BSS (general cyclo-stationary case)
We speciﬁed that the assumption of stationarity of the sources, as required in the previous sections,
is somewhat restrictive in a realistic scenario of telecommunication. Indeed, the stationarity implicitly
assumes that all the sources have the same symbol period and that the data are sampled at a period
equal to the symbol period. In general—think for instance of a passive listening context—the sources
have different baud-rates. We denote the symbol periods of the K sources by T1, . . . , TK . If Te is the
sampling period—a priori different of any of the symbol periods—we have deduce from Section 2.04.2
that, for any index k, the source sk(n) is cyclostationary. In particular, the second moment E

|sk(n)|2
varies with the time-index n. More speciﬁcally, we have
E[|sk(n)|2] =

α∈Ik
R(α)
sk eı2παkn,
where
Ik =
%
0, ± Te
Tk
&
is the set of the second-order cyclic frequencies of sk and the Fourier coefﬁcients R(α)
sk
are given by
Eq. (4.8) (we have dropped the time-lag in R(α)
sk (ℓ) since, in the sequel, no other time delay than ℓ= 0
is considered). In this section, the channel is supposed to be memoryless, as in all the Section 2.04.3.
Hence, the model given by Eq. (4.11) still holds: the components of the source vector s(n) are effectively
mutually independent, but are not individually stationary. As far as the normalization of the sources is
concerned, it may also be assumed: in the cyclo-stationary context of this section, this means that
⟨E[s(n)s(n)H]⟩n = IK .
(4.42)
In the following, we provide assumptions on the sources that guarantee that the algorithms of source
separation depicted in Section 2.04.3.4 still converge to desirable solutions, i.e., allow one to separate the
sources. In other words, the algorithms previously considered are run as if the data were stationary: this

164
CHAPTER 4 Blind Signal Separation for Digital Communication Data
means that nothing has to be changed in any part of the stationary BSS algorithms. Surprisingly, the fact
that the data are not stationary is shown not to impact the convergence to a good (separating) solution.
The algorithms encountered for stationary data (see Section 2.04.3.4) are designed to minimize either
the function ˆϒ(r) given by Eq. (4.31) or the Godard function ˆϒC M(r) given by Eq. (4.32). Let us recall
that the signal r(n) is the output of the variable spatial ﬁlter g, i.e.,
r(n) = gT y(n),
= fT s(n),
wherefT = gT H.Asinthestationarycase,weanalyzetheargumentminimaofthetheoreticalassociated
function. The ﬁrst point to be addressed is hence: to which functions ˆϒ(r) and ˆϒC M(r) converge? Due
to the non-stationarity of the model, the function ˆϒ(r) for instance does not converge to ϒ(r) as given
in Eq. (4.30): this cannot be the case since the latter function depends on the time-lag n.
There is a version of the law of the large numbers for non-stationary data. Lemma 8 can be written
in this context under this form:
Lemma 13.
For p = 2, 4, we have, with probability one:
1
N
N−1

n=0
|r(n)|p −→⟨E[|r(n)|p]⟩.
We deduce that ˆϒC M(r) −→

E

|r(n)|2 −1
2
. We deﬁne this limit as (the superscript “c” means
“cyclo-stationary”):
ϒ(c)
C M(r) =
'
E
(
|r(n)|2 −1
2)*
n
.
(4.43)
For the same reason, we have ˆϒ(r) −→ϒ(c)(r) where
ϒ(c)(r) =

E

|r(n)|4
n

E

|r(n)|2
n
2 −2.
(4.44)
Notice that, in the case of stationary data, ϒ(c)(r) (respectively ϒ(c)
C M(r)) equals ϒ(r) (respectively
ϒC M(r)).
We ﬁrst address the minimization of ϒ(c)(r). Once done, we deduce results concerning the mini-
mization of ϒ(c)
C M(r).
We consider a prior expansion of the moments involved in ϒ(c)(r). The following equality always
holds true (we recall that the signals are all complex-circular at the second-order):
E

|r(n)|4
= κ(r(n)) + 2

E

|r(n)|22.
(4.45)
The multi-linearity of the cumulant gives:
⟨κ(r(n))⟩n =
K

k=1
η(sk)| fk|4,

2.04.3 Instantaneous Mixtures
165
where we let for any source s = sk the number η(s) be
η(s) = ⟨κ(s(n))⟩n.
(4.46)
The output of the spatial ﬁlter, r(n), is obviously a linear combination of the sources s1, . . . , sK : r(n) =
K
k=1 fksk(n). As sk admits Ik = {0, ±αk} as the set of its second-order cyclic frequencies, we deduce
that r(n) is cyclo-stationary and its second-order cyclo-frequencies are in the set
I =
K
+
k=1
Ik.
This means that E[|r(n)|2] = 
α∈I R(α)
r
eı2παn. As a consequence, the term

E

|r(n)|22
n, may
be computed thanks to the Parseval equality. We have indeed
',,,E

|r(n)|2,,,
2*
n
=

α∈I
,,,R(α)
r
,,,
2
.
On the other hand, the sources are mutually decorrelated hence
R(α)
r
=
K

k=1
R(α)
fksk
=
K

k=1
| fk|2R(α)
sk .
By deﬁnition, I∗= I \ {0} is the set of all the non-null cyclic frequencies of the mixture. After isolating
the term associated with the cyclic frequency α = 0, we may hence write that
'
E

|r(n)|22*
n
=

R(0)
r
2
+

α∈I∗
,,,,,
K

k=1
| fk|2 R(α)
sk
,,,,,
2
=

R(0)
r
2
+
K

k=1
| fk|4
⎛
⎝
α∈I∗
k
,,,R(αk)
sk
,,,
2
⎞
⎠+ 1
2

k1̸=k2
,, fk1
,,2 ,, fk2
,,2 ε(sk1, sk2)
=

R(0)
r
2
+ 2
K

k=1
| fk|4 ,,,R(αk)
sk
,,,
2
+ 1
2

k1̸=k2
| fk1|2| fk2|2ε(sk1, sk2),
where
ε(sk1, sk2) = 2

α∈I∗
R(α)
sk1 R(α)∗
sk2 .
(4.47)
We have used the symmetry:
R(−αk)
sk
= R(αk)∗
sk
.
(4.48)

166
CHAPTER 4 Blind Signal Separation for Digital Communication Data
The set I∗is simply {±αk | k = 1, . . . , K}. Denoting by I∗
+ the set {αk | k = 1, . . . , K} we have, due
to (4.48), the alternative expression of ε that underlines that ε is real:
ε(sk1, sk2) = 4Re
⎛
⎝
α∈I∗
+
R(α)
sk1 R(α)∗
sk2
⎞
⎠.
(4.49)
We hence have the following expression:
ϒ(c)(r) =
K
k=1 ζ(sk)| fk|4 + 
k1̸=k2 | fk1|2| fk2|2ε(sk1, sk2)
K
k=1 | fk|2
2
(4.50)
where we have let, for any of the sources s = sk whose positive cyclic frequency is α the number ζ(s) be
ζ(s) = η(s) + 4
,,,R(α)
s
,,,
2
.
(4.51)
It is to be noticed that ζ(s) can also be expressed as
ζ(s) =

E

|s(n)|4
n −2.
(4.52)
We are in position to discuss the minimization of this function. Two cases have to be distinguished.
2.04.3.7.1
Case of different baud-rates
If the cyclic frequencies ± Te
Tk are all different modulo 1, the coefﬁcients ε(sk1, sk2) all verify:
∀k1 ̸= k2
ε(sk1, sk2) = 0.
(4.53)
Indeed, it sufﬁces to consider the expression of Eq. (4.47): let αk be the positive cyclo-frequency of the
source no k : αk = Te
Tk . In Eq. (4.47), there are at most two terms: α is either αk1 or −αk1 = 1 −αk1
modulo 1. Take for instance α = αk1. The associated term is non null if α = αk2 or α = −αk2 = 1−αk2:
if ±αk1 and ±αk2 are different modulo 1, this cannot occur. The same reasoning applies for α = −αk1.
In other words, ε(sk1, sk2) = 0.
Remark.
It is desirable to bridge the gap between this condition on the disparity of the cyclo-
frequencies and practical considerations. We insist on the fact that the above condition is not equivalent
to condition that the symbol frequencies are different. Indeed, consider α1 = 1/8 and α2 = 7/8. Then
−α2 = α1 modulo 1 and the condition is not fulﬁlled whereas the symbol periods are different. However,
if the sampling frequency is big enough such that for all indices k : αk < 1/2 then the condition on the
disparity of the cyclic frequencies simply means: all the symbol periods are different. In the following,
we systematically assume the condition
αk < 1
2.
(4.54)

2.04.3 Instantaneous Mixtures
167
Proposition 3 can be written in the non-stationary context:
Proposition 14.
If the cyclic frequencies ± Te
Tk are all different modulo 1, then the cost function
ϒ(c)(r) achieves its minimum at a separating vector if and only if one of the ζ(sk) is strictly negative.
Moreover, the separating vector in question has its single non-null element located at an index k0 such
that ζ(sk0) = mink=1,...,K ζ(sk).
We hence consider the following assumption
A1
for any of source s of the mixture ζ(s) < 0
(4.55)
that is analyzed in Section 2.04.3.9.
Together with Proposition 14, this assumption A1 allows one to claim that the minimization of the
estimated function ˆϒ(r) is legitimate as far as the extraction of a source is concerned. Moreover, the
result of Lemma 5 still holds: indeed, the expression of ϒ(c)(r) given by (4.50) simpliﬁes as
ϒ(c)(r) =
K
k=1 ζ(sk)| fk|4
K
k=1 | fk|2
2
which is formally the same as the function ϒ(r) considered in the stationary case—see Eq. (4.29).
The local minima of ϒ(c)(r) are separating, which makes the minimization algorithm based on a
gradient method robust to the presence of local minima.
We now face the minimization of the function ϒ(c)
C M(r). The question is whether the non-stationarity
of the data changes such a result as the one given in Proposition 7 or not. The careful reader will be
assured that indeed Proposition 7 is true in the non-stationary case. Moreover, the result of Proposition
4 is unchanged in the cyclo-stationary case. We can claim:
Proposition 15.
If the cyclic frequencies ± Te
Tk are all different modulo 1, and if Assumption A1 in
(4.55) holds, then the local minima of the cost functions ϒ(c)(r) and ϒ(c)
C M are separating.
2.04.3.7.2
General case
Contrary to the case where the cyclic-frequencies are different, the Eq. (4.53) does not hold in general,
and the results given in the stationary context concerning the minimization of ϒ(c)(r) cannot be directly
recast. However, numerical considerations may help to give similar results. In this respect, the reader
should understand that the quantities ε(sk1, sk2) are either zero or “small” since they involve cyclo-
correlation at non-null frequencies. This is speciﬁc of telecommunication signals; the reason is due to
the fact that the excess bandwidth of a transmitted signal is small (see [37]). We will discuss this fact
further on, but for the moment, we simply consider the following assumption for any of the sources,
denoted by s:
A2
for any source s of the mixture
,,R(α)
s
,, < 1
2

|ζ(s)|.
(4.56)
We discuss this assumption further in Section 2.04.3.9. For the moment, we suppose that Assumptions
A1 and A2 both hold.

168
CHAPTER 4 Blind Signal Separation for Digital Communication Data
Consider two distinct indices k1 and k2; for sake of simplicity, let them be k1 = 1 and k2 = 2.
Notice that if the sources numbered 1 and 2 are such that their associated (single) cyclic frequencies
are different modulo 1 then ε(s1, s2) = 0. Suppose on the contrary now that the cyclic frequencies are
equal modulo 1 (thanks to (4.54) this happens if and only if the two baud-rates are the same). In this
case, the summation (4.49) has only one term and ε(s1, s2) = 4R(R(α)
s1 R(α)∗
s2
). Assumption A2 given in
(4.56) holds, it follows in both cases that |ε(s1, s2)| < √|ζ(s1)||ζ(s2)|. Whatever the indices k1 ̸= k2
may be, Assumption A2 implies
∀k1 ̸= k2
|ε(sk1, sk2)| <

|ζ(sk1)ζ(sk2)|.
(4.57)
We may consider the expression of ϒ(c)(r) given in Eq. (4.50). We have, thanks to (4.57):
K

k=1
ζ(sk)| fk|4 +
K

k1̸=k2
| fk1|2| fk2|2ε(sk1, sk2) ≥−
K

k=1
|ζ(sk)|| fk|4 −

k1̸=k2
| fk1|2| fk2|2
|ζ(sk1)ζ(sk2)|.
(4.58)
As the r.h.s of the latter equation is simply −

k
√|ζ(sk)|| fk|22, this shows that
ϒ(c)(r) ≥−

k
√|ζ(sk)|| fk|2

k | fk|2
2
≥−max
k
|ζ(sk)|.
If Assumption A1 holds, this lower bound is evidently reached. It remains to inspect the cases of
equality for this lower-bound. In this respect, we suppose that ϒ(c)(r) = ζmin where ζmin = mink ζ(sk).
For convenience, we assume that p
k=1 | fk|2 = 1. The case of equality implies that (4.58) is an equality.
It implies that

k1̸=k2
| fk1|2| fk2|2 
ε(sk1, sk2) +

|ζ(sk1)ζ(sk2)|

= 0.
Now, the inequality A2 implies that ε(sk1, sk2) +

|ζ(sk1)ζ(sk2)| > 0. Necessarily, we must have that,
for every couples (k1, k2) such that k1 ̸= k2, fk1 fk2 = 0. Otherwise stated: the vector f has a single
non-null component, hence is separating.
We have shown the result:
Proposition 16.
If the Assumptions A1 and A2 hold, then the cost function ϒ(c)(r) and ϒ(c)
C M achieve
their minimum at a separating vector.
2.04.3.8 Global BSS (general cyclo-stationary case)
Again in this section, the global source separation method depicted in Section 2.04.3.5 is considered.
Its convergence was speciﬁcally shown for stationary sources. We show that the convergence of the
algorithm to a separating matrix is not affected when the data are cyclo-stationary. This key-result was
ﬁrst provided in [38]; a condition of separability of JADE was given, which was rather difﬁcult to
interpret especially when the number of sources is greater than 3. We show the result quite differently,
following [39].

2.04.3 Instantaneous Mixtures
169
Notice that the pre-whitening of the observed data is still possible even when the data are cyclo-
stationary: the algorithm is even not changed at all. Hence, we begin by considering the estimate ˆ(r)
given by Eq. (4.37). Obviously, this estimate can not converge to the function of the cumulants given by
Eq. (4.34) since the terms in this equation depend on the time lag. Nevertheless, the limit as the number
of snapshots grows can be expressed as
(c)(r) =
K

i=1

E

|ri(n)|4
n −2

.
Thanks to the algebra already done along Section 2.04.3.7, we may directly write
(c)(r) =
K

i=1
⎛
⎝
K

k=1
ζ(sk)| fi,k|4 +

k1̸=k2
| fi,k1|2| fi,k2|2ε(sk1, sk2)
⎞
⎠.
It remains little to do as soon as Assumptions A1 and A2 hold, since the following inequality holds:
(c)(r) ≥−
K

i=1
 K

k=1
  ζ(sk)
  fi,k
,,2
2
=
  Fz(1/2)  2
2,
where z(1/2) = (|ζ|(s1), . . . , |ζ|(sK ))T . The same argument as the one given in Section 2.04.3.5
(Birkhoff theorem) proves that (c)(r) ≥−K
k=1 |ζ(sk)|. As the numbers ζ(sk), thanks to Assump-
tion A1, are strictly negative, we directly show that −K
k=1 |ζ(sk)| is the inﬁmum of (c)(r) and this
inﬁmum is reached for unitary matrices F that are essentially equal to the identity matrix. This proves
the following proposition, that is the sister of Proposition 11:
Proposition 17.
If Assumptions A1 and A2 hold, we have, for any unitary F:
(c)(r) ≥(c)(s) =
K

k=1
ζ(sk).
Moreover, the inequality is an equality if and only if F essentially equals the identity matrix.
2.04.3.9 Validity of assumptions A1 and A2: semi-analytical considerations
In essence, we have shown that the cyclo-stationarity of the data does not affect neither the one-by-
one methods of Section 2.04.3.7, nor the global method depicted in Section 2.04.3.5. This positive
answer to our question however requires to inspect the validity of Assumptions A1 and A2. We ﬁrst
discuss A1. We recall that, in a stationary environment, ζ(s) is simply the fourth-order cumulant of the
(normalized) source. As this latter is a ﬁltered version of an i.i.d. sequence of symbols having a strictly
negative Kurtosis, it is straight-forward that ζ(s) < 0. In a cyclo-stationary environment, the mentioned
argument does not hold anymore. In this case, indeed, ζ(s) is given by (4.51) and it is not possible to
conclude directly that ζ(s) < 0. However, these statistics can be shown to express as integrals of the

170
CHAPTER 4 Blind Signal Separation for Digital Communication Data
0
0.2
0.4
0.6
0.8
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
excess bandwidth
stochastic simulation
semi analytical result
4 QAM
256
QAM
16 QAM
FIGURE 4.7
Validity of A1.
shaping ﬁlter ca(t), at least for a generic sampling frequency (see [40]). More precisely, except for four
sampling frequencies that are irrelevant to consider, it can be shown quite simply that
R(α)
s
= 1
T

|ca(t)|2e−ı2πt/T dt
and
ζ(s) = κ(d) 1
T

|ca(t)|4dt + 4|R(α)
s
|2,
where ca, as speciﬁed in the introduction, is a normalized square-root raised-cosine ﬁlter. In [40], it
is shown rigorously that R(α)
s
and ζ(s) do not depend on the symbol period T. It is hence possible to
compute numerically ζ(s) as a function of the excess bandwidth, while considering a few values of
κ(d) corresponding to typical modulations. The reader may ﬁnd details on the computation of these
numbers in the above reference. The results are reported in Figure 4.7. In order to validate that the above
formulas are correct, we also have plotted the estimate of ζ(s) obtained by stochastic simulations with
respect to Eq. (4.52) (we have generated sequences of 10,000 symbols according to the modulation).
For all the values of the excess bandwidth, the numerical results let us claim that A1 is true.

2.04.4 Convolutive Mixtures: Case of Sparse Channels
171
0
0.2
0.4
0.6
0.8
1
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
excess bandwidth
0.5| (s)|1/2 for a 4
QAM
0.5| (s)|1/2 for a 16
QAM
0.5| (s)|1/2 for a 256 QAM
|R( )(s)|
FIGURE 4.8
Validity of A2.
At a ﬁrst sight, Assumption A2 looks quite audacious; indeed it is. As far as we know, it is not
possible, for the same reasons as those mentioned above, to prove this result analytically. Resorting
again to semi-analytical considerations, we compute the numbers 1
2
√|ζ(s)| and |R(α)
s
| for differ-
ent modulations and excess-bandwidth factors. We have obtained the results that can be seen in
Figure 4.8. These computations indicate that A2 can be claimed to hold.
2.04.4 Convolutive mixtures: case of sparse channels
We now face the problem of blind source separation when the channel is not memoryless. The contribu-
tion of a given source to received data is not simply the delayed source up to an unknown constant, but
a ﬁltered version of the source. In this section, we specify the model and we explain how it is possible
to connect quite directly the previous results (on instantaneous mixtures) to this model: this requires a
strong assumption on the delays as will be explained. We refer to [41] (Chapter 17) for more details.
The convolutive effect stems from the presence of multiple paths as speciﬁed in Section 2.04.2.1.
Consider a source sa,k(t) ; the contribution of this source on the received signal (mth sensor) is given
by (4.9). In most of the high-rate digital communication systems, the narrow-band assumption may be

172
CHAPTER 4 Blind Signal Separation for Digital Communication Data
taken for granted. By narrow-band signal, we mean that the carrier frequency is big enough to consider
the signal as monochromatic. More speciﬁcally, this means that the bandwidth of the signal in baseband
is much smaller than the carrier frequency, i.e.,
1
Tk
≪fk.
On the other hand, for any delay τ such that τ ≪Tk, we have the approximation: sa,k(t −τ) ≈sa,k(t).
In order to take the full beneﬁt of the antenna array, the distance between two consecutive antennas
should be of the order of half the wave-length. This says that the delay of propagation between two
consecutive antennas is of the order of
1
2 fk ≪Tk. As a consequence, the contribution of the kth source
and ℓth path to the mixture is a rank one signal and can be written as hk,ℓsa(t −τk,ℓ) where hk,ℓis
called steering vector.
We assume that the associated delays are sorted such that τ1,k < τ2,k < . . . We consider the case
when the delays are “sufﬁciently spread out.” In this respect, the reader should notice that it is possible
to use the fact that the shaping function ca,k numerically vanishes: ca,k(t) can be numerically neglected
if |t| > PkTk where the integer Pk depends on the roll-off. This implies that
sa,k(t) ≈
-
t
Tk
.
+Pk

ℓ=
-
t
Tk
.
−Pk
dk(ℓ)ca,k(t −ℓTk).
Consider that the above approximation is an equality. As a consequence, if τ2,k −τ1,k > 2PkTk then
the random variables sa,k(t −τ1,k) and sa,k(t −τ2,k) do not involve the same symbols hence they are
independent. Two consecutive paths can hence be treated as independent sources. Suppose that all the
successive delays are separated by more than 2PkTk, this property holding true for all the sources. As Lk
denotes the number of paths associated with the kth source, we may write the observed data according
to Eq. (4.11). This time, the “source vector” sa(t) is deﬁned as
⎛
⎜⎝sa,1(t −τ1,1), . . . , sa,1(t −τ1,L1)
!
"#
$
L1“sources”
, . . . , sa,K (t −τ1,K ), . . . , sa,K (t −τL K,K )
!
"#
$
L K “sources”
⎞
⎟⎠
T
.
The ˜K = L1 + L2 + · · · + L K ≥K “sources” in the vector sa(t) are (approximately) mutually
independent. The advantage of this formulation is that all the results given in Section 2.04.3.7 remain
true. Nevertheless, we want to stress the drawbacks of this approach.
1. A fundamental requirement is that the number of sensors, M, is greater than the number of sources.
We recall that this necessary condition comes from the requirement that the mixing matrix H should
have full -column rank. This gives here
M ≥˜K.
This condition may be limiting as soon as the number of paths per communication source is big.
2. The source separation methods all require that the components of sa(t) be mutually indepen-
dent. Now, the delays are spread out in very speciﬁc conditions; this particular consition occurs

2.04.5 Convolutive Mixtures
173
in long-range communication channels (ionospheric transmissions): we refer to the reference [41]
(Chapter 17) for details. On the contrary, this assumption on the distribution of the delays associated
with a given source is scarcely fulﬁlled in many cases (urban GSM channels for instance).
3. The complexity of the instantaneous (one-by-one or global) methods directly increases with the
number of sources.
4. The algorithms of source separation, ideally, should provide, up to constants, all the components of
sa(t). For instance, L1 of these “sources” among the ˜K components involve the sequence of symbols
d1(n). As the ultimate goal is to eventually estimate these transmitted symbols, a recombination of
the L1 “sources” has to be computed. Notice that the sources are generally not ordered in any way.
The association of th e reconstructed paths can be processed after lagged correlation between the
reconstructed sources. This is clearly not a child’s play.
For practical considerations, we refer to Chapter 17 of reference [41] where a comparison between
instantaneous (described in this section) and convolutive approaches described in the next section
are done.
2.04.5 Convolutive mixtures
We now face the case of the general multi-path channels; no such condition as the sparsity of the channels
is assumed to hold.
2.04.5.1 Identifying the symbols: algebraic methods (stationary data)
In this section, the model of the data is stationary and is given by (4.18). We have justiﬁed in the
introduction that it is legitimate to approximate the MIMO ﬁlter E(z) by a polynomial. We denote by
L its order, i.e.,
E(z) = L
ℓ=0 Eℓz−1. The approaches that we want to introduce exploit algebraic properties of
the model (convolution) and of the source signal d(n). Van der Veen et al. [42] suggest the following
method.
Consider the vector
yP(n) = (y(n)T , y(n −1)T , . . . , y(n −(P −1))T )T
(4.59)
for P ≥L. We remark that
yP(n) = TP(E)dP+L−1(n),
wheredP+L−1(n)isdeﬁnedinthesamemannerasyP(n)andwherematrixTP(E)isthe M P×K(L+P)
block-Toeplitz matrix given by
TP(E) =
⎛
⎜⎜⎜⎝
E0
. . . EL
0
. . .
0
0
E0
. . .
EL
0
0
0
...
...
...
...
0
0
. . .
0
E0
. . . EL
⎞
⎟⎟⎟⎠,
(4.60)

174
CHAPTER 4 Blind Signal Separation for Digital Communication Data
where we have set E = (E0, . . . , EL). Denote by YP the M P ×(N −P −L) matrix (N is the number of
snapshots) in which all the data y(n) from n = L + P to n = N are collected (P ≥L): the n th column
of YP is yP(n)—see (4.59). It yields YP = TP(E) DP+L,N where DP+L,N is the block-Toeplitz matrix
deﬁned by
DP+L,N =
⎛
⎜⎜⎜⎜⎝
d(P + L −1)
d(P + L)
d(N)
d(P + L −2) d(P + L −1)
...
...
...
d(0)
d(1)
d(N −P −L + 1)
⎞
⎟⎟⎟⎟⎠
.
It is known (see [13,43]) that the assumption given in (4.21) involves that TP(E) is a full column rank
matrix. We deduce that the row space of YP equals the row space of DP+L,N. An idea consists in ﬁnding
the matrices ˆDP+L,N having the Toeplitz structure of DP+L,N such that their row space is prescribed.
Notice that an ambiguity arises since the estimated ˆd(n) of d(n) coincide up to an invertible matrix. This
latter can be removed by considering one of the algebraic methods (instantaneous mixtures) evoked in
Section 2.04.3.2 in which a priori information on the symbols is exploited (ﬁnite alphabets or constant
modulus modulations).
2.04.5.2 Estimation of the channels: MA/AR structures (stationary data)
Again in this section, the data are stationary and follow the model (4.18), so that y(n) appears to be
a moving average model driven by non-Gaussian i.i.d. sequences. A number of blind identiﬁcation
methods of MA models using higher statistics have been derived, and could be used in the present
context (see e.g., [44]). However, the corresponding algorithms show poor performance.
If E(z) is irreducible—see (4.21)—there exists a left polynomial inverse of E(z) [43]—say G(z).
This implies that [G(z)]y(n) = d(n) where d(n) is i.i.d., which says that y(n) is an AR model. This can
be used in order to identify the matrix E(z) thanks to a linear prediction approach, and hence to retrieve
the symbol sequences [45] up to a constant K × K matrix. We note however that the irreducibility of
E(z) does not hold when the excess band-width are all zero due to the factorization evoked at the end
of Section 2.04.2.3.2. This tends to indicate a certain lack of robustness of the linear prediction method
when the excess bandwidth factors are small.
2.04.5.3 Estimation of the channels: subpace methods (cyclo-stationary data)
In the previous sections, the main assumption is that the data are stationary. Here, we rather consider
the general model (4.17). We consider here the general cyclo-stationary model.
In order to achieve BSS, it is suggested here to identify the transfer function H(z), and then to evaluate
one of its left inverse in order to retrieve the source signals (this kind of approaches is sometimes called
indirect). In this respect, H(z) is usually modeled as a FIR causal ﬁlter, i.e., H(z) = L
ℓ=0 Hℓz−ℓ.
It has been shown in [43] that if M > K and TP(H) is full column rank, then H(z) can be identiﬁed
from the column space of TP(H) up to a constant K × K matrix which can itself be estimated using any
instantaneous mixture blind source separation method. In practice, the column space of TP(H) is usually
estimated by means of the eigenvalue/ eigenvector decomposition of an estimate of the covariance matrix

2.04.5 Convolutive Mixtures
175
of vector yP(n) given in (4.59). We should perhaps specify this point. Indeed, we have
ˆRyP(0) = 1
N
N

n=L+P
yP(n)yP(n)H
= TP(H) ˆ TP(H)H,
where ˆ =
1
N
N
n=L+P sP+L−1(n)sP+L−1(n). If this latter is full rank, the column space of ˆRyP(0)
coincides with the column space of TP(H). However, it should be emphasized that it is not always
legitimate to assume that ˆ is full rank except when all the sources occupy all the band of frequencies

−1
2Te ,
1
2Te

. On the contrary, the rank of ˆ is expected to fall. We do not provide the details: the reader
should compute the limit of ˆ as N →∞and show that the limit  is a block Toeplitz matrix whose
block (p, q) has the expression:
p,q =
 1
0
e−ı2π(p−q)νS(0)
s (eı2πν)dν,
where S(0)
s (eı2πν) is the (diagonal) power spectral density of the vector s(n). As the sampling period
veriﬁes the Shannon sampling condition, some of the entries of S(0)
s (eı2πν) are band-limited, which
prevents the rank of  from being full (see the works of Slepian and Pollak on the prolate spheroidal
wave functions).
Further reﬁnements are proposed in [12]. Notice that this subspace method, although apparently
quite appealing, performs poorly as soon as the matrix TP(H) is ill-conditioned, which, in practice, is
quite often the case.
2.04.5.4 Global BSS approaches
2.04.5.4.1
Temporal approaches: extensions of the Comon
contrast function (stationary data)
We now focus on the direct and global BSS methods, i.e., methods that allow one to compute a global
separator in one shot (up to indeterminacies that will be speciﬁed). In this respect, we intend to provide
extensions of the approaches given for the instantaneous context—see Section 2.04.3.5. For simpliﬁ-
cation, assume the (restrictive) stationary case. As speciﬁed in the previous paragraph, the model of
the data is not stricto sensu [H(z)]s(n) as in Eq. (4.17) since the Shannon sampling condition does not
hold, but rather (4.18).
On the one hand, a direct extension of a contrast as deﬁned by Comon can be done (see Section 8.4.2
of [41]). The ﬁrst step to be considered is the decorrelation of the data (the prewhitening), i.e., a ﬁlter
matrix Q(z) is computed such that x(n) = [Q(z)]y(n) is decorrelated both spatially and temporally.
This is equivalent to computing Q(z) such that U(z) = Q(z)E(z) is para-unitary, i.e., U(z) veriﬁes for
any frequency ν ∈

−1
2, 1
2

: U(eı2πν)U(eı2πν)H = IK . The reader may ﬁnd details of this procedure
in [46,47]. The reconstructed vector of the sources may hence be searched as r(n) = [V(z)]x(n) where

176
CHAPTER 4 Blind Signal Separation for Digital Communication Data
V(z) is a para-unitary matrix. It is possible to consider, as in the instantaneous case, the function
(r) =
N

k=1
ϕ(κ(rk)),
where ϕ shows the same properties as in Proposition 12. It can be simply shown that , as a function
of the para-unitary matrix V(z), is a contrast, i.e., achieves its maximum for separating matrices U(z):
see [48]. Theoretically appealing (at least in a stationary environment), this solution calls for implicit
prerequisites, namely the pre-whitening and the optimization over the set of para-unitary matrices.
Concerning this latter point, solutions have been given (see [10,49]); Comon et al. also suggested to
consider a subset of the set of the para-unitary matrices [50]. The solutions are not simple. Besides, the
algorithms might be trapped in local maxima.
2.04.5.4.2
Frequency-domain approaches
In the case of stationary data (same restrictive context as in the above subsection), it is possible to
recast the results of the instantaneous case after processing the discrete Fourier transform of the data:
the separation in processed at each frequency. The difﬁculty is that the indeterminacies change from a
frequency to the other which makes the approach quite difﬁcult. The reader may ﬁnd references in [51].
Assuming now the general cyclo-stationary model given by (4.17), one may focus on second-order
methods. The power spectrum of the data, deﬁned as the discrete Fourier transform of the correlation
function at the null cyclic frequency (R(0)
y (ℓ))ℓ∈Z can be written as
S(0)
y

eı2πν
= H

eı2πν
S(0)
s

eı2πν
H

eı2πνH,
(4.61)
where S(0)
s (eı2πν) is the K × K power spectrum of the source vector given by (4.10). The components
of s being jointly independent, hence decorrelated, the matrices S(0)
s (eı2πν) are diagonal. As far as the
identiﬁability of the unknown H(z) based on the relation (4.61) is addressed, it is shown in [52] that the
conditions required are that (4.20) holds on the one hand and, on the other hand, that spectral diversity
occurs namely that the entries of S(0)
s (eı2πν) are all distinct for every frequency. In [53,54] its is shown
that the matrices G(eı2πν) such that G(eı2πν)H S(0)
y (eı2πν)G(eı2πν) is diagonal for all the frequencies
ν are separating matrices. Criteria measuring the closeness to diagonal matrices have been proposed.
See also [55] and the references therein. Again, the diversity of the spectra is not always pertinent for
digital communication contexts.
2.04.5.5 Iterative BSS (stationary case)
Instead of considering a simple spatial ﬁltering of the data as indicated in Eq. (4.24) we rather process
a spatio-temporal ﬁltering as depicted below:
r(n) =

g(z)T 
y(n).
(4.62)
The “reconstructed source” r(n) can be expanded as
r(n) =
K

k=1
[ fk(z)]dk(n)
!
"#
$
rk(n)
,
(4.63)

2.04.5 Convolutive Mixtures
177
where the fk(z) are components of the global ﬁlter
f(z) = g(z)T E(z).
(4.64)
A key trick for the following results is the normalization step: we might write rk(n) = ∥fk∥˜rk where
E

|˜rk|2
= 1 and
∥fk∥2 =
 1
0
| fk(eı2πν)|2dν.
(4.65)
Notice that the separation is achieved if and only if the real-valued vector (∥f1∥, . . . , ∥fK ∥)T is
separating in the sense given in Section 2.04.3.4. As a consequence, when the separation is achieved,
the “reconstructed source” is one of the sources up to a ﬁlter with unit norm.
With no modiﬁcation as compared to the method given for the instantaneous case in 2.04.3.4, we
consider the optimization of the function ϒ(r) as given in Eq. (4.27)—or equivalently (4.28). For sake
of simplicity, we keep the notation ϒ(c)
C M(r) and ϒ(c)(r) even if it should be understood that the functions
in question depend on the ﬁlters f1(z), . . . , fK (z). No extra computation is needed as compared to the
instantaneous case: indeed, it sufﬁces to substitute the “new source” ˜rk(n) to the actual source sk(n):
one arrives at the expression:
ϒ(r) =
K
k=1 κ(˜rk)∥fk∥4
K
k=1 ∥fk∥2
2 .
This time, the cumulants κ(˜rk) are not constant but depend on the norm-one ﬁlter ˜fk(z). Anyway, ˜rk(n)
is a linear process generated by the symbol sequence dk(n): indeed, ˜rk(n) = [ ˜fk(z)]sk(n) and sk(n) has
the form given by Eq. (4.7). As such, κ

˜rk

< 0 since by assumption κ(dk) < 0. We let κmin,k be:
κmin,k =
inf
  ˜fk
  =1
κ([ ˜fk(z)]sk(n))
and κmin = mink κmin,k. We obviously have: κmin,k < 0 and κmin < 0. As a consequence, the following
inequality holds:
ϒ(r) ≥κmin
K
k=1 ∥fk∥4
K
k=1 ∥fk∥2
2 ≥κmin.
Moreover, the equality holds if and only if
1. ∥fk∥= ∥fk0∥δ(k −k0).
2.
˜fk0(z) is such that κmin = κmin,k0 = κ(˜rk0(n)) where ˜rk0(n) = [ ˜fk0(z)]sk0(n).
We suggest an qualitative interesting remark as far as the reconstructed signal r(n) = ∥fk0∥˜rk0(n).
Indeed, this ﬁlter minimizes the Kurtosis of ˜rk0(n). As ˜rk0(n) is a ﬁltered version of the non-Gaussian
i.i.d. sequence (dk0(n)),∈Z, it is shown in [56] that its minimum is reached when ˜rk0(n) is eıθdk0(n −n0)
where θ is an unknown phase and n0 an uncontrolled delay. The reader might show that such a result
also holds for the function ϒC M(r) = E[(|r(n)|2 −1)2].
Ultimately, any local minimum of ϒ(r) or ϒC M(r) can be shown to be separating [31,57].

178
CHAPTER 4 Blind Signal Separation for Digital Communication Data
2.04.5.6 Iterative BSS (general cyclo-stationary)
Similary to the instantaneous case (Section 2.04.3.7), we recast the approach of the previous section
for cyclo-stationary data. The received data is y(n) = [H(z)]s(n), the reconstructed source r(n) is still
given by (4.62). We may expand this signal as
r(n) =
K

k=1
[ fk(z)]sk(n)
!
"#
$
rk(n)
.
(4.66)
This time the global ﬁlter f(z) is
f(z) = gT (z)H(z).
As far as the normalization of r(n) is concerned, we still have r(n) = 
k ∥fk∥˜rk(n) but ∥fk∥does not
have the expression (4.65) since sk(n) is not i.i.d. with unit power but has a non-constant power spectral
density S(0)
k

eı2πν
:
∥fk∥2 =
 1
0
,,, fk(eı2πν)
,,,
2
S(0)
k

eı2πν
dν.
(4.67)
As a consequence, we consider the minimization of the functions ϒ(c)
C M(r) and ϒ(c)(r) whose deﬁnition
is given by Eqs. (4.43) and 4.44. Similarly to the instantaneous case, the minimization of ϒ(c)
C M(r) and
ϒ(c)(r) are equivalent problems in the sense of Proposition 4. Here, the functions in question depend
not only on the positive coefﬁcients ∥f1∥, . . . , ∥fK ∥but also on the norm-one ﬁlters ˜f1(z), . . . , ˜fK (z).
We recall that ˜rk(n) =

˜fk(z)

sk(n) where ∥˜fk∥= 1; then, with practically no effort, we deduce from
Section 2.04.3.7 that
ϒ(c)(r) =
K
k=1 ζ(˜rk)∥fk∥4 + 
k1̸=k2 ∥fk1∥2∥fk2∥2ε(˜rk1, ˜rk2)
K
k=1 ∥fk∥2
2
,
(4.68)
where
ε(˜rk1, ˜rk2) = 4Re
⎛
⎝
α∈I∗
+
R(α)
˜rk1 R(α)∗
˜rk2
⎞
⎠,
(4.69)
ζ(˜rk) = η(˜rk) + 4
,,,R(α)
˜rk
,,,
2
,
(4.70)
η(˜rk) =

κ

˜rk(n)

.
It is to be noticed that ζ(˜rk) can also be expressed as
ζ(˜rk) =

E

|˜rk(n)|4
n −2.
(4.71)
Similarly to the instantaneous case, where the ﬁlters ˜fk(z) are reduced to being 1, the minimization
of ϒ(c)(r) is considerably easier when the cross-terms in (4.68) vanish, i.e., when for all the couples

2.04.5 Convolutive Mixtures
179
(k1, k2) with k1 ̸= k2 we have ε(˜rk1, ˜rk2) = 0. Indeed, in this case,
ϒ(c)(r) =
K
k=1 ζ(˜rk)∥fk∥4
K
k=1 ∥fk∥2
2
which resembles the expression (4.29) except that here, the numbers ζ(˜rk) depend on the parame-
ters the minimization is run over. In the following we hence restrict the further analysis to this case.
We recall that ε(˜rk1, ˜rk2) = 0 as soon as the cyclic frequencies αk = ± Te
Tk are all different modulo
one. This condition is fulﬁlled when all the baud rates are different and the sampling frequency is high
enough, i.e., 1
Te > maxk 2
Tk .
We deﬁne ζmin,k = inf∥˜fk∥=1 ζ([ ˜fk(z)]sk(n)).
Proposition 18.
If the cyclic frequencies ± Te
Tk are all different modulo 1 then the cost function ϒ(c)(r)
achieves its minimum at a separating vector f∗(z) if and only if at least one of the ζmin,k is strictly
negative. Moreover, the f∗in question has its single non-null element located at an index k0 such that
ζmin,k0 = mink=1,...,K ζmin,k.
Proof.
If ζmin,k < 0 for a certain index k, then ζmin < 0 where we have deﬁned ζmin = minℓζmin,ℓ.
Evidently, K
ℓ=1 ζ(˜rℓ)∥fℓ∥4 ≥K
ℓ=1 ζmin,ℓ∥fℓ∥4 ≥ζmin
K
ℓ=1 ∥fℓ∥4. This shows that ϒ(c)(r) ≥ζmin
and this lower bound is attained for any vector f∗(z) whose components are all zero except at an index
k0 such that ζmin,k0 = ζmin and ζ

˜fk0(z)

sk0(n)

= ζmin,k0. Conversely, if ζmin,k ≥0 whatever k, the
lower bound is attained for non separating ﬁlters (see the proof of Proposition 3).
□
Contrary to the stationary case, it is not possible to say much about the minimizing ﬁlter ˜fk0(z)
and hence about the reconstructed signal r(n). However, the residual ﬁlter ˜fk0(z) minimizes the ζ(˜rk0)
hence tends to make the modulus of ˜rk(n) the most constant as possible.
At this point, we have to analyze the condition: ζmin,k < 0. Recall that this condition is the adaptation
to the convolutive case of the assumption A1. This latter was proven to hold true by means of semi-
analytical considerations. Curiously, it is possible to prove that the condition ζmin,k < 0 holds; no
numerical computation is needed. We have:
Proposition 19.
As the Kurtosis of the symbols κ(dk) are all strictly negative, we have
ζmin,k =
inf
∥˜fk∥=1
ζ([ ˜fk(z)]sk(n)) < 0.
Proof.
More solid arguments than the ones we give here are provided in [40]. The band of frequencies
of the sampled version sk(n) of the source number k is the interval [−1+γk
2 αk, 1+γk
2 αk] ⊂[−1
2, 1
2].
The inﬁmum to be computed is hence over the set of unit-norm ﬁlters ˜fk(z) belonging to F(γk) where
F(γk) is the set of digital ﬁlters whose transfer function is limited to the band [−1+γk
2 αk, 1+γk
2 αk].
Naturally, γ ′
k < γk implies that F(γ ′
k) ⊂F(γk). Taking γ ′
k = 0, we deduce the following inequality:
ζmin,k =
inf
∥˜fk∥=1, ˜fk(z)∈F(γk)
ζ([ ˜fk(z)]sk(n)) ≤
inf
∥˜fk∥=1, ˜fk(z)∈F(0)
ζ([ ˜fk(z)]sk(n)).

180
CHAPTER 4 Blind Signal Separation for Digital Communication Data
On the other hand, we recall that ζ([ ˜fk(z)]sk(n)) = ζ(˜rk) = ⟨κ(˜rk(n))⟩+4
,,,R(αk)
˜rk
,,,
2
. Thanks to Section
2.04.2.2, we know that R(αk)
˜rk
= 0 when the excess bandwidth factor is zero. Hence, for any unit norm
ﬁlter ˜fk(z) ∈F(0), ζ(˜rk) = ⟨κ(˜rk(n))⟩. We deduce that, for such a ﬁlter, ζ(˜rk) < 0.
□
When all the baud-rates are equal, the minimization of ϒ(c)
C M(r) is much more difﬁcult and sufﬁcient
conditions on the sources have been set forth that assure that the minimizers of ϒ(c)
C M(r) are separating.
We refer to [40].
However, the general case remains to be addressed (i.e., for any distribution of the baud-rates):
we conjecture that the global minimum is separating and even that any local minimum is also separating.
These conjectures come from intensive simulation experiments.
2.04.6 Simulation
This section does not aim at making a benchmark of all the previous methods. It rather intends to show
the pertinence of BSS in digital communication contexts.
We ﬁrst present the environment. We have considered a mixture of K = 3 sources; the modulations
are QPSK (two sources) and 16-QAM (one source). The symbol periods are all equal to T and 1/T =
277 kHz (which is the rate of GSM); the carrier frequency is 1 GHz. This later is assumed known to
the receiver so that there are no frequency offset in the source vectors. The excess bandwidth factors all
equal γ = 0.5. As far as the antenna array is concerned, we have simulated a circular array of M = 5
sensors distanced from one another by half a wavelength, i.e., 30 cm. The sampling period Te is ﬁxed
to Te = T /1.6 so that the Shannon sampling condition is fulﬁlled.
The propagation channels are multi path and affected by a Rayleigh fading. An arbitrary path—say
number ℓis characterized by its delay (propagation between the source and a sensor of reference), its
elevation, azimuth and attenuation. We consider the ETSI channels BUx, TUx, HTx, RAx. For each
experiment, the arrival angles of a path are randomly chosen in [−π/2, π/2] for the elevation and
[−π, π] for the azimuth. The different complex amplitudes on each path are also randomly chosen for
each experiment.
The received signal is corrupted by a white, additive complex gaussian noise with power spectral
density N0. The received signals are low-pass ﬁltered in the band

−1
2Te ,
1
2Te

. The three sources have
the same energy per symbol Es. This latter is chosen so that the Es/N0 of the 16-QAM source would
be associated with a bit error rate of 10−3 if the channel were a single-path channel and if there were
only one antenna.
We have considered three algorithms for the separation. In order to have a reference, we have com-
puted the Wiener solution (the MMSE separator): this is naturally a non-blind algorithm. In this respect,
we have supposed that the receiver has access to the transmitted symbols. The two BSS algorithms
we have considered are the iterative CMA (see Section 2.04.5.6) and the global method JADE. Once
the separation is (supposedly) achieved, we need to equalize each source in order to compute the bit
error rate. This extra-step is done after re-sampling the three “source estimates” at the true sampling
rate (supposed at this level to be known). The re-sampled signals are expected to be ﬁltered versions

2.04.6 Simulation
181
Table 4.1 Some Simulation Results
2000
1000
500
channel BUx
QAM-4
QAM-16
QAM-4
QAM-4
QAM-16
QAM-4
QAM-4
QAM-16
QAM-4
MMSE
100%
68.8%
100%
100%
55.9%
100%
100%
23%
100%
CMA
100%
70.5%
100%
100%
20.6%
99.8%
95.9%
0.1 %
97.6%
JADE
58.4
1.3%
60.7%
55.5%
0.7%
57.7%
48.8%
0.1%
51.7%
channel TUx
QAM-4
QAM-16
QAM-4
QAM-4
QAM-16
QAM-4
QAM-4
QAM-16
QAM-4
MMSE
100%
80.2%
100 %
100%
69.8%
100%
100%
35.3%
100%
CMA
99.7%
84.3%
99.3%
99.3%
47.5%
99.2%
98.5%
0.7%
98.9%
JADE
94.9%
29.9%
95.1%
93.9%
18.1%
94.4%
93.1%
3%
92.9%
channel RAx
QAM-4
QAM-16
QAM-4
QAM-4
QAM-16
QAM-4
QAM-4
QAM-16
QAM-4
MMSE
99.8%
91.9%
99.6%
99.8%
88.8%
99.6%
99.7%
70.4%
99.6%
CMA
99.1%
84.7%
99.2%
99%
50.2%
99.3%
98.1%
0.6%
98.6%
JADE
99.7%
89.2%
99.6%
99.6%
79.7%
99.6%
99.6%
24.5%
99.5%
channel HTx
QAM-4
QAM-16
QAM-4
QAM-4
QAM-16
QAM-4
QAM-4
QAM-16
QAM-4
MMSE
99.4%
36.2%
99.6%
99.4%
26.8%
99.7%
99.4%
9%
99.5%
CMA
92%
13%
93.2%
90.8%
1.8%
91.6%
83.5%
0%
82.1%
JADE
86.7%
13.1%
87.4%
85.7%
6.3%
86.3%
83.6%
1.1%
84.1%
of the symbols. A blind equalization algorithm is run (the CMA) in order to compute estimates of the
transmitted symbols. The scaling ambiguity is removed non-blindly.
The performance index for the tested algorithms and for a given source is the following: for each
experiment, we inspect if the bit error rate (for the transmitted symbols) is less than 10−2. Averaging
the process on 1000 independent trials allows us to provide a percentage of success.
Three observation durations were considered: 500T , 1000T , and 2000T .
The performance of the algorithms can be seen in Table 4.1. The performance of the MMSE (non-
blind) provides, in some sense, an ultimate bound. In this respect, one may notice that the channels BUx
and HTx are by far the “most difﬁcult” channels since they are associated with the weakest performance
of the MMSE. For these two channels, the multipath effects are severe and this explains why the JADE
algorithm, designed for instantaneous mixtures, performs poorly. On the contrary, the CMA shows good
performance as far as the extraction of the two modulus-one sources is concerned, even if the observation
duration is small (500 symbols): the performance index is above 80%. However, the 16-QAM source is
associated with a miserable performance: the CMA as a BSS algorithm is not to be incriminated, since
the two other sources are correctly equalized, hence the 16-QAM is itself correctly separated. Hence the
bad performance is due to the equalization algorithm (again the CMA run this time on the re-sampled
extracted signal): this is a well-known fact that the CMA equalizes the non-modulus one modulation
with difﬁculties.
As far as the TUx and RAx channels are concerned, they are associated with less severe multi-path
effects: this explains why the JADE algorithm performs well—even better than the CMA for the RAx
channel.

182
CHAPTER 4 Blind Signal Separation for Digital Communication Data
2.04.7 Extensions and further readings
2.04.7.1 Case of non-circular sources
Along this paper, the data we considered as circular. This assumption is not crucial for second-order
or algebraic methods. However, the presence of a non-circular source in the mixture considerably
affects the higher-than-second-order methods. For instance, the fourth-order cumulant κ(r(n)) if r(n)
is the output of a separator, does not have the same expression as when all the sources are circu-
lar. It can be even been shown that the separation is not always achieved when two sources are
non-circular.
The interested reader might ﬁnd results and references in the following works: [38,58–60].
2.04.7.2 Exploiting the non-stationarity
Cyclo-stationarity is a main statistical feature of the mixture that has long been thought of as a
beneﬁt for source separation. For instantaneous BSS using second-order moments, see [61,62]: the
idea is that the mixing matrix is constant during the observation, while the second-order statistics
of the sources vary. An idea is hence to cut the observation interval in subintervals. Recalling the
SOBI approach (see Section 2.04.3.3), the receiver may compute the correlation matrices for the uth
interval: R(u)
y (ℓ) = HR(u)
s (ℓ)HH. As the sources are non-stationary, the diagonal matrices R(u)
s (ℓ)
vary with u hence the pencil of matrices to be jointly diagonalized has more elements and the con-
ditions of identiﬁability are weaker, hence the algorithm is more robust. We refer to the work of
Pham [63] for the Maximum Likelihood approach. The reader might be interested by a work of
Wang et al. [64].
In the case of digital communication signals, the cyclo-stationarity is not strong enough in order to
consider such approaches: we have pointed out that the power of a source E[sa(t + τ)sa(t)∗] has very
small variations since the cyclo-spectra at the cyclic-frequencies ± 1
T are numerically small due to the
spectral limitation of the shaping functions. On the one hand, the strength of cyclo-stationarity is too
weak to be exploited. On the other hand, it cannot be neglected in the computations (for instance in the
expression of the fourth-order cumulants).
2.04.7.3 Presence of additive noise
In this paper, we have considered a noise-free model. Many references may be found where the impact
of the noise on the BSS methods is analyzed. Among others, we would like to cite the work of Cardoso
concerning the performance analysis a class of BSS algorithms who have a the so-called “invariance”
feature [35]. Concerning the CMA when noise is present: the reader may have a look at the work of
Fijalkow et al. [29] for the use of the CMA as an equalizer algorithm and the proximity of a solution in
the presence of noise to a Minimum Mean Square Error (MMSE) equalizer; the case of BSS is analyzed
in [25,65] where it is shown that the local minima of the CM cost function are “not far” from MMSE
separator. A systematic analysis is provided in Leshem et al. [66] where both the presence of noise and
the effect of a ﬁnite number of samples are considered.

References
183
2.04.8 Conclusion
In this paper, we have given some methods for achieving the BSS in the context of telecommuni-
cation. We have focused our attention on contrast functions (joint or deﬂation-based approaches), and
particularly the contrast functions depending on fourth-order statistics of the data. These approaches
ﬁt the blind problems evoked in the introduction (spectrum monitoring) since they are associated with
convergent and performance algorithms. When the channels involve multi-path effects and no a priori
information on the distribution of the delays is available, the deﬂation-based algorithms such as the
CMA or the minimization of the normalized Kurtosis are good candidates for the BSS.
Relevant Theory: Signal Processing Theory and Statistical Signal Processing
See Vol. 1, Chapter 4 Random Signals and Stochastic Processes
See Vol. 3, Chapter 3 Non-stationary Signal Analysis
References
[1] C. Jutten, J. Hérault, Blind separation of sources, Part I—An adaptative algorithm based on neuromimetic
architecture, Signal Process. 24 (1991) 1–10.
[2] P. Comon, Independent component analysis, a new concept? Signal Process. 36 (3) (1994) 287–314 (special
issue on higher-order statistics).
[3] E. Bingham, H. Hyvarinen, A fast ﬁxed-point algorithm for independent component analysis of complex
valued signals, Int. J. Neural Syst. 10 (1) (2000) 1–8.
[4] J.F. Cardoso, A. Souloumiac, Blind beamforming for non gaussian signals, IEE Proc. F 140 (6) (1993) 362–
370.
[5] N. Delfosse, P. Loubaton, Adaptative blind separation of independant sources: a deﬂation approach, Signal
Process. 45 (1995) 59–83.
[6] Boaz Porat, A Course in Digital Signal Processing, ﬁrst ed., Wiley, October 1996.
[7] W.A. Gardner, Spectral correlation of modulated signals: Part I—Analog modulations, IEEE Trans. Commun.
35 (1987) 584–594.
[8] Antonio Napolitano, Cyclic higher-order statistics: Input/output relations for discrete- and continuous-time
MIMO linear almost-periodically time-variant systems, Signal Process. 42 (2) (1995) 147–166.
[9] John Proakis, Digital Communications. McGraw-Hill Science/Engineering/Math, fourth ed., August 2000.
[10] P.P. Vaidyanathan, Multirate Systems And Filter Banks, ﬁrst ed., Prentice Hall, 1992.
[11] C. Corduneanu, Almost Periodic Functions, second ed., American Mathematical Society, 1989.
[12] A. Gorokhov, P. Loubaton, Subspace-based techniques for blind separation of mixtures with temporally
correlated sources, IEEE Trans. Circ. Syst. 44 (9) (1997) 813–820.
[13] Yujiro Inouye, Ruey-Wen Liu, A system-theoretic foundation for blind equalization of an FIR MIMO channel
systemchannel system, IEEE Trans. Circ. Syst.—I 49 (4) (2002) 425–436.
[14] A.J. Van Der Veen, A. Paulraj, An analytical constant modulus algorithm, IEEE Trans. Signal Process. 5 (44)
(1996) 1136–1155.
[15] S. Talwar, M. Viberg, A. Paulraj, Blind estimation of multiple co-channel digital signals using an antenna
array, Signal Process. Lett. 1 (2) (1994) 29–31.

184
CHAPTER 4 Blind Signal Separation for Digital Communication Data
[16] S. Talwar, M. Viberg, A. Paulraj, Blind separation of synchronous co-channel digital signals using an antenna
array—Part I: Algorithms, IEEE Trans. Signal Process. 44 (5) (1996) 1184–1197.
[17] B.G. Agee, The least-squares CMA: a new technique for rapid correction of constant modulus signals, in:
Proceedings of the ICASSP, Tokyo, 1986, pp. 953–956.
[18] R.P. Gooch, J.P. Lundell, The CM array: an adaptive beamformer for constant modulus signals, in: Proceedings
of the ICASSP, Tokyo, Japan, 1986, pp. 2523–2526.
[19] A. Belouchrani, K. Abed-Meraim, J-F. Cardoso, E. Moulines, A blind source separation technique using
second-order statistics, IEEE Trans. Signal Process. 45 (2) (1997) 434–444.
[20] A.
Bunse-Gerstner,
R.
Byers,
V.
Mehrmann,
Numerical
methods
for
simultaneous
diagonali-
zation, SIAM J. Matrix Anal. Appl. 14 (4) (1993) 927–949.
[21] K. Abed-Meraim, Y. Xiang, H. Manton, Y. Hua, Blind source separation using second-order cyclostationary
statistics, IEEE Trans. Signal Process. 49 (4) (2001) 694–701.
[22] Patrick Billingsley, Probability and Measure, third ed., Wiley-Interscience, 1995.
[23] D N Godard, Self-recovering equalization and carrier tracking in two-dimensionnal data communication
systems, IEEE Trans. Commun. 28 (11) (1980) 1867–1875.
[24] Y. Sato, A method of self-recovering equalization for multilevel amplitude-modulation systems, IEEE Trans.
Commun. 23 (6) (1975) 679–682.
[25] D. Liu, L. Tong, An analysis of constant modulus algorithm for array signal processing, Signal Process. 73
(1999) 81–104.
[26] J.R. Treichler, B.G. Agee, A new approach to multipath correction of constant modulus signals, in: IEEE
Trans. Acoust. Speech, Signal Process. vol. 31, 1983, pp. 459–472.
[27] J.R. Treichler, M.G. Larimore, New processing techniques based on constant modulus adaptive algorithm,
IEEE Trans. Acoust. Speech Signal Process. 33 (8) (1985) 420–431.
[28] P.A. Regalia, On the equivalence between the Godard and Shalvi-Weinstein schemes of blind equalization,
Signal Process. 73 (1999) 185–190.
[29] I. Fijalkow, A. Touzni, J.R. Treichler, Fractionally spaced equalization using CMA: robustness to channel
noise and lack of disparity, IEEE Trans. Signal Process. 46 (1) (1998) 227–231.
[30] C. Simon, Ph Loubaton, C. Jutten, Separation of a class of convolutive mixtures: a contrast function approach,
Signal Process. 81 (2001) 883–887.
[31] J.K. Tugnait, Identiﬁcation and deconvolution of multi-channel non-gaussian processes using higher-order
statistics and inverse ﬁlter criteria, IEEE Trans. Signal Process. 45 (3) (1997) 658–672.
[32] J.K. Tugnait, Adaptive blind separation of convolutive mixtures of independent linear signals, Signal Process.
73 (1999) 139–152.
[33] Albert W. Marshall, Ingram Olkin, Barry Arnold, Inequalities: Theory of Majorization and Its Applications,
Springer, September, 2010.
[34] A. Yeredor, Non-orthogonal joint diagonalization in the least-squares sense with application in blind source
separation, IEEE Trans. Signal Process. 50 (7) (2002) 1545–1553.
[35] J.-F. Cardoso, On the performance of orthogonal source separation algorithms, in: EUSIPCO, Edinburgh,
1994, pp. 776–779.
[36] A. Hyvarinen, Fast and robust ﬁxed-point algorithms for independent component analysis, IEEE Trans. Neural
Networks 10 (3) (1999) 626–634.
[37] L. Mazet, P. Loubaton, Cyclic correlation based symbol rate estimation, in: proc. Asilomar Conference on
Signals, Systems, and Computers, 1999, pp. 1008–1012.
[38] A. Ferréol, P. Chevalier, On the behavior of current second and higher order blind source separation methods
for cyclostationary sources, IEEE Trans. Signal Process. 48 (2002) 990 (6 (Erratum: 50, N◦4) 1712–1725).
[39] P. Jallon, A. Chevreuil, Separation of instantaneous mixtures of cyclostationary sources, Signal Process. 87
(2007) 2718–2732.

References
185
[40] Pierre Jallon, Antoine Chevreuil, Philippe Loubaton, Separation of digital communication mixtures with the
CMA: case of unknown symbol rates, Signal Process. (2010) 2633–2647.
[41] Pierre Comon, Christian Jutten, Handbook of Blind Source Separation: Independent Component Analysis and
Applications, Academic Press, 2010.
[42] A.J. Van Der Veen, S. Talwar, A. Paulraj, A subspace approach to blind space-time signal processing for
wireless communication systems, IEEE Trans. Signal Process. 45 (1) (1997) 173–190.
[43] K. Abed-Meraim, P. Loubaton, E. Moulines, A subspace algorithm for certain blind identiﬁcation problems,
IEEE Trans. Inform. Theory 43 (2) (1997) 499–511.
[44] A. Swami, G.B. Giannakis, S. Shamsunder, Multichannel ARMA processes, Trans. Signal Process. 42 (4)
(1994) 898–913.
[45] A. Gorokhov, Ph Loubaton, Blind identiﬁcation of MIMO-FIR systems: a generalized linear prediction
approach, Signal Process. 73 (1999) 104–124.
[46] A. Belouchrani, A. Cichocki, Robust whitening procedure in blind separation context, Electron. Lett. 36 (24)
(2000) 2050–2051.
[47] Peter J. Brockwell, Richard A. Davis, Time Series: Theory and Methods, second ed., Springer, 1991.
[48] P.
Comon,
Contrasts
for
multichannel
blind
deconvolution,
IEEE
Signal
Process.
Lett.
3
(209–211) (1996).
[49] John G. McWhirter, Paul D. Baxter, Tom Cooper, Soydan Redif, Joanne Foster, An EVD algorithm for
Para-Hermitian polynomial matrices, IEEE Trans. Signal Process. 55 (5) (2007) 2158–2169.
[50] P. Comon, L. Rota, Blind separation of independant sources from convolutive mixtures, IEICE Trans. Fund.
Electron. Commun. Comput. Sci. E86-A (3) (2003) 542–549.
[51] W. Wang, S. Sanei, J.A. Chambers, Penalty function-based joint diagonalization approach for convolutive
blind separation of non-stationary sources, IEEE Trans. Signal Process. 53 (5) (2005) 1654–1669.
[52] Yingbo Hua, Jitendra K. Tugnait, Blind identiﬁability of FIR-MIMO systems with colored input using second
order statistics 7 (12) (2000) 348–350.
[53] Mitsuru Kawamoto, Yujiro Inouye, Blind deconvolution of MIMO-FIR systems with colored inputs using
second-order statistics, IEICE Trans. Fund. Electron. Commun. Comput. Sci. E86-A (3) (2003) 597–604.
[54] Mitsuru Kawamoto, Yujiro Inouye, Blind separation of multiple convolved colored signals using second-order
statistics, in: Proceedings of the ICA’03, Nara, Japan, 2003.
[55] K. Sabri, M. El Badaoui, F. Guillet, A. Adib, D. Aboutajdine, A frequency domain-based approach for blind
MIMO system identiﬁcation using second-order cyclic statistics, Signal Process. 89 (1) (2009) 77–86.
[56] O. Shalvi, E. Weinstein, New criteria for blind deconvolution of non-minimum phase systems, IEEE Trans.
Inform. Theory 36 (1990) 312–321.
[57] P. Loubaton, P.A. Regalia, Blind deconvolution of multivariate signals: a deﬂation approach, in: International
Conference on Communications (ICC), Geneva, Switzerland, 1993.
[58] E. Florian, A. Chevreuil, P. Loubaton, Blind source separation of convolutive mixtures of non circular linearly
modulated signals with unknown baud rates, Signal Process. 92 (2012) (715–726).
[59] M. Novey, T. Adali, On extending the complex fastica algorithm to non-circular sources, IEEE Trans. Signal
Process. 56 (5) (2008) 2148–2153 .
[60] H. Zhang, L. Li, W. Li, Independent vector analysis for convolutive blind non-circular source separation,
Signal Process. 92 (9) (2012) 2275–2283.
[61] M.K. Tsatsanis, C. Kweon, Source separation using second-order statistics: identiﬁability conditions and
algorithms, in: Asilomar Conference on Signals, Systems and Computers 1998, pp. 1574–1578.
[62] A. Souloumiac, Blind source detection and separation using second-order nonstationarity, in: ICASSP, 1995,
pp. 1912–1915.
[63] D-T. Pham, J-F. Cardoso, Blind separation of instantaneous mixtures of nonstationary sources, IEEE Trans.
Signal Process. 49 (9) 2001 1837–1848.

186
CHAPTER 4 Blind Signal Separation for Digital Communication Data
[64] W. Wang, M.G. Jafari, S. Sanei, J.A. Chambers, Blind separation of convolutive mixtures of cyclo-stationary
signals, Int. J. Adapt. Control Signal Process. 18 (3) (2004) 279–298.
[65] L. Tong H. Zeng, C. Johnson, An analysis of constant modulus receivers, IEEE Trans, Signal Process, 47
(1999) 2990–2999.
[66] A. Leshem, A.-J. van der Veen, Blind source separation: the location of local minima in the case of ﬁnitely
many samples, IEEE Trans. Signal Process. 59 (2008) 4340–4353.

5
CHAPTER
OFDM and Multicarrier
Signal Processing
Paolo Banelli and Luca Rugini
Dipartimento di Ingegneria, Università degli Studi di Perugia, Perugia, Italy
2.05.1 Introduction
Orthogonal Frequency-Division Multiplexing (OFDM) is indubitably a milestone in wired and wireless
communications, which pervades most of the telecommunication standards developed in the last two
decades, such as DAB, DVB-T/H, WiFi (IEEE 802.11a/n), WiMAX (IEEE 802.16e), UMTS-LTE,
ADSL, etc. [71–73,104,105,107,237]. However, the OFDM principle dates back to the early 1960s
for military communication systems [69,268]. More generally, the roots of OFDM are at the end of
the nineteenth century when frequency division multiplexing (FDM) was investigated to increase the
efﬁciency of telegraph systems [209], and successively was widely employed during the twentieth
century in analog telephone lines [209]. Thus, OFDM is the typical example of a technology, whose
idea has evolved theoretically for a long time, and that had to wait for mature electronic and software
technologies to be implemented, at reasonable costs, for mass-market applications. The interested
readers can ﬁnd in [256] an excellent historical perspective of OFDM evolution, and a recent survey
of OFDM literature in [103]. Additional information about OFDM and multicarrier techniques can be
found in tutorial articles and books such as [12,29,53,120,136,145,251,269].
The success of OFDM with respect to classical single-carrier (SC) communications is mainly due
to its capability to enable wideband communications in time-dispersive (frequency-selective) channels
with low-complexity channel equalization, and high spectral efﬁciency. The simpler equalization with
respect to SC is somehow borrowed from classical FDM, where the whole data stream is split in multiple
sub-streams with lower data-rate (bandwidth), each one modulated by a different carrier frequency.
This way, each sub-stream experiences an almost frequency-ﬂat channel, which requests a simple
equalization.
Additionally, OFDM doubles the spectral efﬁciency with respect to FDM by employing properly
separated (e.g., orthogonal) carriers, which let the spectrum of each sub-stream overlap with one another
[48]. By exploiting orthogonality, the multiple sub-streams can be separated at the receiver side by a
bank of correlation-based receivers, rather than by the bandpass ﬁltering of FDM, where the spectra
of different sub-streams cannot overlap. Although the orthogonality principle is quite intuitive and
mathematically simple, its implementation in the analog OFDM systems of the 1960s was requesting
a bank of perfectly tuned oscillators, both at the transmitter and the receiver side, making OFDM
implementation costly and limited to a small number of parallel carriers [268]. Actually, at the beginning
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-396500-4.00005-3
© 2014 Elsevier Ltd. All rights reserved.
187

188
CHAPTER 5 OFDM and Multicarrier Signal Processing
of the 1970s, Weinstein and Ebert recognized that OFDM signals can be generated and demodulated
by Fourier-based synthesis [257], foreseeing the substitution of the bank of analog oscillators by digital
Discrete Fourier Transform (DFT) processing together with digital-to-analog (D/A) [and analog-to-
digital (A/D)] conversion. The introduction of a cyclic-preﬁx (CP) between each transmitted symbol
has been another crucial step towards easy OFDM implementation in frequency-selective channels,
as ﬁrstly proposed in [179]. Thanks to the CP, the almost frequency-ﬂat channel experienced by each
sub-stream in the continuous domain, is turned in a perfectly ﬂat channel in the discrete (e.g., DFT)
domain. Thus, by standard DFT processing, OFDM is capable to convert the transmission of multiple
symbols through a frequency-selective channel, in a set of independent parallel transmissions through
a set of frequency-ﬂat channels, which can be easily and independently equalized. When at the end
of the 1980s, the progress of electronic technology (A/D and D/A converters, CPU clock frequencies,
memories, etc.) made real-time digital signal processor (DSP) a reality, the concurrent increasing request
for high data-rate transmissions in frequency-selective channels suggested that the time for OFDM “has
come” [29]. At the beginning of the 1990s European broadcasting manufacturers and operators were
among the ﬁrst to recognize the potentiality of OFDM, by producing DAB and DVB-T as the ﬁrst
wireless communication standards for digital audio and video broadcasting [71,72,184].
Similarly, in the same decades, telephone companies and operators recognized to OFDM [or discrete
multi-tone (DMT)], the capability to convey high data-rate bit-streams by classical twisted-pairs wires,
practically solving the so called last-mile problem for widespread connection of user homes with high-
speed digital communications. Indeed, according to the water-ﬁlling principle, the use of wires for
digital communications permitted also to exploit the almost optimality of OFDM from the capacity
point of view, as predicted by the famous Shannon’s paper in 1948 [212]. The ﬁrst pioneering work
of Ciofﬁand his co-workers on the subject [58], found successively full application in the ADSL
standard [107].
The smart use of multiple antennas is another important milestone of wireless communications in
the last two decades, while historically multiple antennas were only employed as a source of diversity
at the receiver side. Conversely, it has been recognized that multiple transmit and receive antennas
can boost the capacity of wireless links by multiple-input multiple-output (MIMO) systems [79], and
improve coverage and connection quality by space-time (ST) coding [229]. For instance, the Alamouti
ST-coding [5], currently adopted in several communications standards [such as [105]], is a remarkable
example of a quite simple idea, which greatly improves the performance of a wireless communication
link by employing only two transmit antennas and one, or more, receive antennas.
Anyway, both MIMO and ST-coding approaches have been conceived, and are quite easy to deploy,
for SC communications on frequency-ﬂat channels. Thus, the capability to convert frequency-selective
channels in a set of parallel frequency-ﬂat channels made OFDM the perfect tool to enable both MIMO
and ST-coding techniques. However, this topic is out of the scope of this paper, which for space con-
straint will address only the fundamental signal processing aspects of OFDM and multicarrier (MC)
communications. The interested readers are redirected to [84,88,178], and references therein, for an
overview of MIMO and ST-coding, and to [37,111,263], for their use in OFDM-based systems. For a
thorough introduction and deep survey of MIMO techniques, the interested readers are redirected to the
E-Reference contribution of Davidson [66].

2.05.2 Mathematical Background
189
2.05.2 Mathematical background
The paper is written targeting an electrical engineering student with adequate background on Fourier
transforms (continuous and discrete), signal and systems theory, linear algebra basics (vector, matrices,
eigenvalues,eigenvector,singularvaluedecomposition,etc.),basicsofprobabilityandestimationtheory,
and basics of digital communications. In order to better motivate why OFDM emerged and obscured
classical SC communications in the last decades, the background on classical SC digital communications
is summarized in the next paragraph, which is also useful to clarify similarities and differences between
SC and OFDM systems.
2.05.3 Single carrier background
The baseband equivalent x(t) of a radio-frequency (RF) modulated signal
xRF(t) = Re{x(t)e j2π fct},
(5.1)
which conveys a stream of digital information symbols {di ∈D ⊂C}i∈N by the RF carrier fc, has the
general expression [183]
x(t) =
+∞

i=−∞
ϕ(t, di; φi).
(5.2)
Equation (5.2) highlights that in general the waveform ϕ(·) associated to the ith symbol di may depend
on a state variable ϕi = ϕ(di−1, di−2, . . . ) that takes into account some memory, i.e., dependence, on
the previously emitted symbols, as it happens for instance for continuous-phase modulations [183].
Focusing on the simpler scenario of linear modulations without memory, (5.2) may be rewritten as
x(t) =
+∞

i=−∞
di p(t −iTs),
(5.3)
where Ts is the symbol period, fs = 1/Ts is the symbol rate, and p(t) ∈R is the pulse-shaping ﬁlter
that imposes the spectral occupancy.1 Speciﬁcally, for a given information stream, the spectrum of the
transmitted signal is expressed by
X( f ) = P( f )
+∞

i=−∞
di e−j2π f iTs = P( f )DTs( f ),
(5.4)
where X( f ) = F{x(t)} =
 +∞
−∞x(t)e−j2π f t dt is the Fourier transform (FT) of x(t), and DTs( f ) is the
discrete-time FT (DTFT) of the transmitted sequence {di}i∈N. Thus, the information associated to each
1A more general expression could consider different pulse-shaping ﬁlters for the real and imaginary parts of {di}. This is not
common in practical applications, and it is not considered herein for notation simplicity. See [28] for further details.

190
CHAPTER 5 OFDM and Multicarrier Signal Processing
symbol di spreads by DTs( f ) throughout all the frequencies, it is mixed with the information associated
to the other symbols {di} j̸=i, and it is shaped (and band-limited) by P( f ).
The signal y(t) received on an additive white Gaussian noise (AWGN) channel is expressed by
y(t) = kx(t −to) + w(t),
(5.5)
where k and to represent attenuation and delay, respectively, and w(t) stands for the thermal receiver
noise. Thus, the AWGN channel is characterized by the propagation of the transmitted signal through a
linear system with impulse response hc(t) = kδ(t −to), where δ(t) is the Dirac delta function. In order
to recover the transmitted signal, and assuming k = 1 and to = 0 without restriction of generality, the
receiver processes y(t) by a ﬁlter pr(t), which is responsible to maximize the signal-to-noise power-
ratio (SNR), and to avoid inter-symbol interference (ISI) [183]. The SNR is maximized by a matched
ﬁlter (MF), e.g., pr(t) = p∗(−t) [183], leading to a ﬁltered signal y f (t) expressed by
y f (t) =
+∞

i=−∞
di p(t −iTs)∗p∗(−t) + n(t)∗p∗(−t)
=
+∞

i=−∞
di Rpp(t −iTs) + w f (t).
(5.6)
In (5.6), ∗stands for the linear convolution operator, ∗is the complex-conjugate operator, Rpp(t) =
p(t) ∗p∗(−t) is the pulse-shape autocorrelation function, and w f (t) is the ﬁltered noise. Thus, the
MF is also known as correlator receiver [183]. If the pulse shaper p(t) is designed with unit energy
Rpp(0) = 1 and such that

Rpp(iTs) = 0

i̸=0, the sample yk extracted at tk = kTs is expressed by
yk = y f (kTs) = Rpp(0)dk +

i̸=k
di Rpp((k −i)Ts) + wk
= dk + wk,
(5.7)
do not experience any ISI from adjacent symbols, and optimal reception can be performed on a symbol
by symbol basis [183]. The ISI-free constraint on Rpp(t) imposes a constraint on its FT F

Rpp(t)

=
|P( f )|2, which has to be shaped such that [183]
+∞

i=−∞
|P( f −i/Ts)|2 = Rpp(0).
(5.8)
The ISI-free constraint in (5.8) can be satisﬁed if |P( f )| has an anti-symmetrical shape with respect to
the frequency 1/(2Ts) and P( f ) = 0 when | f | > 1/Ts (see Figure 5.1). This is known as the Nyquist
criterion, and suggests that the positive (half) bandwidth B associated with a linear digital modulation
is B ∈[ fs/2, fs], where fs = 1/Ts. A typical prototype ﬁlter that respects such constraints is the root
raised-cosine ﬁlter [183], whose shape is shown in Figure 5.1 together with the graphical interpretation
of (5.8).

2.05.3 Single carrier background
191
2
( )
P f
2
(
)
1
s
i
P f
i f
+∞
= –∞
–
=
sf
2
sf
2
sf
–
sf
–
2 sf
2 sf
–
f
B
1
∑
FIGURE 5.1
Shape of |P(f )|2 for a root raised-cosine ﬁlter and ISI-free condition in the frequency-domain.
However, in most of wireless and wired communication systems, the propagation channel is not
AWGN. Indeed, because of multipath propagation in wireless communications [222], and of frequency-
dependent attenuation in wired communications [183], the propagation channel is modeled by a
frequency-selective channel with a time-dispersive impulse response hc(t) ̸= kδ(t −to).
A typical baseband representation for a linear time-invariant (LTI) channel, with P + 1 path is
summarized by its time-dispersive impulse response
hc(t) =
P

p=0
αpδ(t −τp),
(5.9)
where αp and τp are the attenuation and delay, respectively, associated with the pth path, and
Hc( f ) =
P

p=0
αpe−j2π f τp
(5.10)
is the frequency-selective channel spectrum, as shown in Figure 5.6.
In the presence of a time-dispersive (frequency-selective) channel, the received signal at the MF
output is expressed by
y f (t) =
+∞

i=−∞
dih(t −iTs) + w f (t),
(5.11)
where h(t) = p(t) ∗hc(t) ∗pr(t) = Rpp(t) ∗hc(t) is the overall pulse shape that is perceived at the
receiver side. The effect of the channel in the frequency-domain is captured by
Y f ( f ) = P∗( f )Hc( f )X( f ) = H( f )DTs( f ),
(5.12)
where H( f ) = Hc( f )|P( f )|2 replaces the role of |P( f )|2 in (5.8).

192
CHAPTER 5 OFDM and Multicarrier Signal Processing
Thus, if Hc( f ) is not constant in the frequency support where P( f ) ̸= 0, e.g., if Hc( f ) ̸= ko when
| f | ≤B, the frequency selectivity of the physical channel destroys the ISI-free design of Figure 5.1. This
means that, in the presence of multipath (frequency-selectivity), the time dispersion of the channel hc(t)
destroys the ISI-free design, because h(iTs) ̸= 0, and the received samples at the MF output become
yk = dk +

i̸=k
dihk−i + wk,
(5.13)
where hi = h(iTs) is the equivalent discrete-time impulse response of the overall channel, which is
generally modeled as a ﬁnite impulse response (FIR) ﬁlter of order L.
The presence of ISI from adjacent symbols requests both the estimation of the channel coefﬁcients
{hi}i=0,...,L and more complex detection techniques. For equiprobable transmitted symbols, the optimal
detection choice consists in a maximum likelihood (ML) receiver that can exploit the Viterbi algorithm
[183], whose complexity grows exponentially with the discrete-time channel length L + 1. Alternative
and simpler detection schemes, characterized by (sometimes signiﬁcant) bit-error-rate (BER) perfor-
mance degradation, ﬁrst try to counteract the effect of the channel by a linear ﬁlter (equalizer), and
successively resort to a single-symbol decision as in (5.7). The simplest choice for the linear equalizer
is represented by a transversal FIR ﬁlter, whose coefﬁcients (taps) can be determined according to differ-
ent criteria [zero-forcing, minimum mean-squared error (MMSE), etc. [183]]. The channel equalization
complexity for each transmitted symbol dk, without considering the channel estimation and the equalizer
design, is linearly proportional to the number of taps Leq of the FIR equalizer. Typically the FIR equal-
izer suffers from noise ampliﬁcation and gives acceptable BER performance, when Leq ∈[3L, 5L].
Thus, we can conclude that the simplest linear equalization in SC is characterized by a complexity for
transmitted symbol that grows linearly with the channel order L, rather than exponentially as for ML
equalizers.
Another possibility to contrast the effect of the ISI, and avoid the noise ampliﬁcation associated with
linear equalization is to use decision feedback equalization, which is a nonlinear data-aided approach
that represents a trade-off between BER performance and computational complexity [183].
It is important to observe that any physical channel is characterized by its own frequency selec-
tivity and coherence bandwidth Bc, i.e., a band | f | ≤Bc where Hc( f ) ≈ko is almost constant.
If the frequency support of the transmitted signal is within the channel coherence bandwidth, i.e.,
if the bandwidth of P( f ) is B ≤Bc, the channel will not signiﬁcantly alter the ISI-free design of
Eq. (5.8) and Figure 5.1, which will be almost respected by H( f ) = Hc( f )|P( f )|2 ≈k0|P( f )|2.
On the contrary, the effect of ISI becomes critical if the system symbol rate fs increases, leading to a
proportional increase of the system bandwidth B (see Figure 5.1), which may become greater than the
coherence bandwidth Bc. In the discrete-time domain, the increase of the symbol rate would correspond
to an increased number L + 1 of channel coefﬁcients hi ̸= 0 [222], and consequently an increased
complexity for the channel equalizer.
Just to give an idea, a wireless SC system in a urban environment is typically characterized by a
multipath channel hc(t) with a maximum delay spread τ = τP −τ0 ∈[7, 20] µs [60]: if the requested
system capacity can be granted by a bandwidth W = 2B = 10 MHz, this means that the channel length
is of the order L ≈τ/Ts ≈τW ∈[70 ÷ 200], and a linear transversal FIR equalizers with at least
[210 ÷ 600] taps is request to obtain acceptable BER performance. Needless to say that in this scenario
it is impossible to think about ML equalization/detection, whose complexity is exponential in L.

2.05.4 The path to OFDM
193
Thus, the ever increasing demand for high data-rate communications in the last decades has posed
tremendous challenges to channel estimation and equalization of classical SC wideband communica-
tions. This was the main motivation, even if not the single one, to look for an alternative communication
scheme that could more easily handle the propagation through frequency-selective (multipath) channels.
2.05.4 The path to OFDM
This section is dedicated to show how the OFDM principle can naturally evolve from SC communica-
tions, through the classical concept of FDM.
2.05.4.1 Frequency division multiplexing
When the information stream {di} is characterized by a very-high symbol rate fs, a natural way to
deal with the frequency selectivity of the channel is to split the data stream into M multiple parallel
sub-streams. This way, each sub-stream is characterized by a reduced symbol rate f ′
s = fs/M and,
consequently, can be transmitted by a baseband signal x(m)(t) expressed by
x(m)(t) =
+∞

k=−∞
dm,k pm(t −kMTs),
(5.14)
where dm,k = dkM+m represents a serial-to-parallel (S/P) conversion, and pm(t) is the pulse-shaping
waveform of the mth sub-stream. The simplest way to separate M data streams at RF was historically
offered by FDM [29], where all the streams are characterized by the same bandwidth Wm = W/M =
2B/M, and are modulated at RF on different (sub-) carriers fRF,m = fc+(m−M/2) f . The subcarrier
separation  f > W/M grants that each sub-stream can be separated from the others by simple band-
pass ﬁltering at the receiver side (see Hm( f ) in Figure 5.2), followed by a classical MF receiver for
each sub-stream.
Thus, taking into account (5.1), the equivalent baseband model of the overall transmitted stream is
simply represented by the superposition of the M parallel baseband streams, as expressed by
x(t) =
M−1

m=0
x(m)(t) =
+∞

k=−∞
M−1

m=0
dm,k pm(t −kMTs),
(5.15)
where
pm(t) = p(t)e j2π fmt,
(5.16)
and fm = (m −M/2) f , thus producing a multicarrier (MC) communication system.
As for SC communications, the role of p(t) is twofold, i.e., to shape the spectrum X(m)( f ) and
to guarantee ISI-free reception by the receiver MF of each single sub-stream. The role of e j2π fmt
is to shift in frequency each single sub-stream, such that the sub-streams are almost separated, i.e.,
X(m)( f )X(n)( f ) ≃0: this way, each single sub-stream can be easily separated by bandpass ﬁltering
(see also Figure 5.2). In practice, in order to ﬁlter each sub-stream with physically realizable ﬁlters, it
is also necessary to introduce a frequency guard-band Bg between adjacent frequency channels and,

194
CHAPTER 5 OFDM and Multicarrier Signal Processing
f
1
m
f
−
m
f
1
m
f
+
(
)
X
f
( )
m
H
f
1
m
f
+
/
W
M
f
Δ
(
)( )
m
X
f
(
1)( )
m
X
f
−
(
1) ( )
m
X
f
+
(
1)( )
m
X
f
+
FIGURE 5.2
The concept of frequency division multiplexing.
consequently,  f = 2 B
M + Bg. Thus, the overall RF spectral occupancy is 2B + (M −1)Bg and
FDM sacriﬁces spectral efﬁciency with respect to the SC solution, whose spectrum support is 2B (see
Figure 5.1).
2.05.4.2 Orthogonal multiplexing principle
The multiple-stream expression in (5.14) and (5.15) may have a much broader interpretation than simple
FDM. On one hand, in order to allow for a simple receiver architecture, e.g., a parallel of M SC-like
receivers (see Figure 5.3), the pulse shaper pm(t) has to guarantee the maximum SNR by MF and the ISI-
free properties of each single sub-stream, as in FDM. On the other hand, additionally, the pulse shaper
pm(t) should guarantee the absence of interference from the other (superimposed) M −1 sub-streams.
By means of (5.6), the output of the mth MF is
y(m)
f
(t) =
+∞

l=−∞
dm,l Rpm pm(t −lMTs) +

j̸=m
+∞

l=−∞
d j,l Rpm p j (t −lMTs) + n(m)
f
(t),
(5.17)
which, assuming the ISI-free design for pm(t) and a sampling rate f ′
s = (1/MTs), corresponds to a
discrete-time signal expressed by
ym,k = y(m)
f

kMTs
	
= Rpm pm(0)dm,k +

j̸=m
+∞

l=−∞
d j,k Rpm p j ((k −l)MTs) + nm,k.
(5.18)
Equation (5.18) highlights that the interference caused by the symbols

d j,k

j̸=m of the other streams
j ̸= m can be eliminated if, and only if, the pulse-shaper cross-correlation Rpm p j (t) = pm(t)∗p∗
j(−t)
is characterized by equispaced samples Rpm p j (i MTs) = 0.

2.05.4 The path to OFDM
195
FIGURE 5.3
System architecture with a bank of parallel MF at the receiver side.
For practical considerations, such as the transmission of a symbol in a limited time, it is natural to
consider pulse shapers with a limited duration (time support) Tu. To this end, let us express the mth
pulse shaper as
pm(t) = cm(t)rectTu(t −Tu/2),
(5.19)
where rectT (t) = 1 when |t| < T /2 and rectT (t) = 0 elsewhere, and cm(t) contains the shape of
the pulse within the limited time support. The ﬁnite time support Tu leads also to autocorrelation
and cross-correlation functions with limited time-support 2Tu, i.e., Rpm p j (t) = 0 when |t| ≥Tu, for
j = 0, . . . , m, . . . , M −1. Thus, choosing Tu ≤MTs would easily guarantee that Rpm p j (i MTs) = 0
when i ̸= 0. This allows for the elimination of the ISI caused by those symbols (of all the M sub-
streams) transmitted in the interval l ̸= k, where k is the interval index of the target symbol. Thus, for
time-limited pulse shapers with unit energy Rpm pm(0) = 1 and duration Tu = MTs, (5.18) reduces to
ym,k = dm,k +

j̸=m
d j,k Rpm p j (0) + nm,k,
(5.20)
where the mth stream suffers only from the interference caused by those symbols (of the M −1 sub-
streams with j ̸= m) transmitted during the same kth symbol interval. In order to avoid such an
interference, it is necessary to design the M pulses such that
Rpm p j (0) =

 +∞
−∞
p∗
m(t)p j(t)dt =

 Tu
0
c∗
m(t)c j(t)dt = 0,
(5.21)
which means that the pulse shapers have to be orthogonal over the ﬁnite support Tu. Therefore, for any
orthogonal and unit-energy design of the pulse shapers, the output of the mth MF branch in Figure 5.3,
is expressed by
ym,k = dm,k + nm,k,
m = 0, . . . , M −1.
(5.22)

196
CHAPTER 5 OFDM and Multicarrier Signal Processing
There are wide classes of functions that are orthogonal over a ﬁnite interval, and every choice would
be equivalent in this respect. By such a design, the system in Figure 5.3 is nothing else than a classical
(short) code-division multiple-access (CDMA) receiver [183], where cm(t) is the signature waveform
(i.e., the pulse-shaped code) associated with the mth sub-stream. The interested reader can refer to [247]
for further details on CDMA principles and systems, and Section 2.05.10.2 for a comparison of MC
and CDMA philosophies.
2.05.4.3 Orthogonal frequency-division multiplexing principle
Noteworthy, the exponential functions e j2π fmt involved in the FDM design are candidate functions
for cm(t) in (5.21), if the frequencies { fm} are carefully selected. Indeed, in order to approximate
any regular function on a ﬁnite time-interval, the Fourier series [173] exploits orthogonal exponen-
tial functions whose frequencies are proportional to the fundamental frequency f1 = 1/Tu, e.g.,
fm = m fs/M. This way the baseband spectrum would exploit only positive frequencies, and in order
to be consistent with (5.1) where fc is the central RF spectrum frequency, it would be necessary to use
fm = m fs/M −M−1
2
fs
M . However, this choice implies only a ﬁxed frequency shift of the spectrum,
which is inessential. Thus, in the rest of the paper the frequency shift M−1
2
fs
M is ignored, which can also
be interpreted as assuming fc + M−1
2
fs
M as the RF central frequency.
Consequently, a multicarrier design that guarantees an easy sub-stream separation exploits
pm(t) =
1
√MTs
e j2π
m
MTs trectMTs(t −MTs/2)
(5.23)
and the overall transmitted signal is expressed by
x(t) =
M−1

m=0
x(m)(t) =
1
√MTs
+∞

k=−∞
M−1

m=0
dm,k e j2π
m
MTs (t−kMTs)rectMTs(t −(k + 1/2)MTs).
(5.24)
Equation (5.23) is analogous to (5.16) for FDM, where p(t) =
1
√MTs rectMTs(t −MTs/2): this fact high-
lights that the system designed with (5.23) and (5.24) is a special FDM system that exploits (baseband)
orthogonal frequencies fm = m fs/M and, as such, is typically called OFDM.
However, the philosophy of OFDM is noticeably different from FDM, as can be noted from the
following observations:
a. The ISI-free condition for each sub-stream is granted by a pulse shaper p(t) with a ﬁnite time-support
Tu = MTs.
b. The rectangular pulse shaper p(t) induces, for each sub-stream, a baseband spectrum with |P( f )| =
|√Tusinc

πTu f

|. Thus, each sub-stream is not band-limited, although a high percentage of its
energy is mainly concentrated into its main lobe, i.e., on an RF frequency support equal to 2/Tu =
2 fs/M.
c. The spectra P(m)( f ) = P( f −fm) of different sub-streams, separated by fm −f j = (m −j)/Tu,
are not disjoint in the frequency-domain and they signiﬁcantly overlap with the adjacent ones
(see Figure 5.4).

2.05.4 The path to OFDM
197
1,
m
k
d
−
o o o o o o
f
,
m k
d
1,
m
k
d
+
1
m
f
−
m
f
1
m
f
+
o o o o o o
(
)
k
X
f
FIGURE 5.4
Spectrum of a single OFDM block (k is the block index).
We now focus on the signal xk(t) associated with a block of M parallel symbols transmitted during
a single OFDM interval of duration Tu = MTs, expressed by
xk(t) =
1
√Tu
M−1

m=0
dm,ke j2π m
Tu trectTu(t −(k + 1/2)Tu).
(5.25)
The signal xk(t) in (5.25), or equivalently the data {dm,k}m=0,...,M−1 in (5.25), is usually denoted as the
kth OFDM symbol or the kth OFDM block. The spectrum associated with the single OFDM block in
(5.25) is
Xk( f ) =

Tu
M−1

m=0
dm,k sinc

πTu

f −fm
	
e−jφk( f −fm),
(5.26)
where φk( f ) = π(2k+1)Tu f is a linear-phase term that takes into account the delay associated with the
kth OFDM block. Observing the shape of Xk( f ) in Figure 5.4 (where the phase φk( f ) = π(2k +1)Tu f
is not considered for simplicity), it is evident that the transmission of an OFDM symbol corresponds to
the parallel transmission of M data symbols

dm,k

m=0,...,M−1, each one modulating the amplitude of a
pulse-shaper spectrum P( f ) = √Tusinc

πTu f

e jφk( f ). From the same ﬁgure, it is also evident that the
middle points of the M overlapping spectra are equispaced in the frequency-domain, by  f = fs/M.
Thus, also the data overlap (interfere) in the frequency-domain, except in the equispaced locations of
the zeros of each sinc-like spectrum where
Xk( fm) =

Tudm,k,
m = 0, . . . , M −1.
(5.27)
Consequently, as Figure 5.4 clariﬁes, OFDM performs in the frequency-domain a dual operation of SC
transmissions in the time-domain: the equispaced zero-location property of |P( f )|2 at frequencies fm =
m f ′
s is the dual of the equispaced zero-location property of Rpp(t) that grants ISI-free transmission at
tk = kTs inSCsystems.Inthiscase, fm = m f ′
s arethepointsinthefrequency-domainwherethesymbols
dm,k belonging to different subcarriers do not interfere with each other. In the multicarrier literature

198
CHAPTER 5 OFDM and Multicarrier Signal Processing
[29,59,94,196,246], this kind of interference is called intercarrier interference (ICI), or interchannel
interference: OFDM is characterized by an ICI-free design for P( f ).
Figure 5.4 suggests that in order to recover the data

dm,k

m=0,...,M−1 transmitted during the kth
OFDM block, it would be sufﬁcient to sample its spectrum at the frequencies { fm}m=0,...,M−1. Indeed,
the signal received in an AWGN channel during the kth OFDM block is
yk(t) = xk(t) + nk(t) =

1
√Tu
M−1

m=0
dm,k e j2π m
Tu t + n(t)

rectTu(t −Tu/2)
(5.28)
and the output ym,k of the mth receiver branch in (5.22) is expressed by
ym,k =
1
√Tu

 Tu
0
yk(t)e−j2π fmt dt =
1
√Tu

 +∞
−∞
yk(t)e−j2π fmt dt
=
1
√Tu
Yk

fm
	
=
1
√Tu

Xk

fm
	
+ Nk

fm
	
= dm,k + nm,k,
(5.29)
which conﬁrms the intuition that in the OFDM case the optimal parallel MF architecture in Figure 5.3
actually performs an equispaced (frequency-domain) sampling of the received spectrum.
2.05.4.4 DFT-based implementation of OFDM
By the Nyquist-Shannon sampling theorem [213], it is well known that an equispaced spectrum sampling
of a band-limited signal can be accomplished by the DFT of its time-domain samples, collected with
a sampling frequency Fs ≥2B in order to avoid aliasing. Actually, the spectrum X( f ) in Figure 5.4
is not rigorously band-limited, because of the everlasting tails of the sinc(·) function associated to
the rectangular pulse shaper p(t) in (5.19). However, if the sampling frequency is chosen such that
Fs = pfs = pM( fs/M), where p is a positive integer, by the Nyquist sampling theorem the sampled
signal
x(s)
k (t) =
+∞

n=−∞
xk(n/Fs)δ(t −n/Fs) =
M−1

n=0
xk(n/Fs)δ(t −n/Fs),
(5.30)
has a spectrum that is the sum of the replicas of the original spectrum, as summarized by
X(s)
k ( f ) = F

x(s)
k (t)

= Fs
+∞

l=−∞
Xk

f −lFs
	
= Fs

Tu
+∞

l=−∞
M−1

m=0
dm,k sinc

πTu

f −(m + lpM) fs
M

e−jφk( f −fm−lFs).
(5.31)
Due to the fact that also the spectral aliases are centered at integer multiples of the OFDM symbol
frequency fs/M, also (some of) the zeros of their sinc-like functions will coincide with the orthogonal
frequencies { fm = m fs/M}m=0,...,M−1. Thus, aliasing is null on the frequency grid {m/Tu}m=0,...,M−1
where the spectrum is sampled in order to recover the transmitted data

dm,k

m=0,...,M−1. In formulas,

2.05.4 The path to OFDM
199
when p = 1, i.e., when the signal is sampled at the receiver side by Fs = fs, and ignoring the presence
of the noise, we have
X(s)
k

fm
	
=

M
Ts
+∞

l=−∞
M−1

m′=0
dm,k sinc

π(m −m′ + lM)

e−jϕk((m−m′+lM) fs)
= Fs Xk

fm
	
=

M
Ts
dm,k,
m = 0, . . . , M −1.
(5.32)
The last equation highlights that the receiver can recover the transmitted data

dm,k

m=0,...,M−1 by
sampling the spectrum of the (discrete-time) received signal. In the absence of noise, sampling the
spectrum of the discrete-time received signal corresponds to compute
dm,k =

Ts
M X(s)
k ( fm) =

Ts
M

 +∞
−∞
x(s)
k (t)e−j2π fmt dt
=

Ts
M
M−1

n=0
xk(nTs)

 +∞
−∞
δ(t −nTs)e−j2π fmt dt
=

Ts
M
M−1

n=0
xn,k e−j2π fmTsn =

Ts
M
M−1

n=0
xn,k e−j 2π
M mn,
m = 0, . . . , M −1,
(5.33)
which, by the last equality [173], corresponds to compute the DFT of the discrete-time sequence

xn,k = xk(nTs)

n=0,...,M−1, scaled by √Ts/M.
Consequently, also the inverse is true by exploiting the properties of DFT, i.e., the transmitted
discrete-time symbols

xn,k

n=0,...,M−1 can be obtained by the inverse DFT (IDFT) of the spectrum
samples Xm,k = fs Xk( fm) =

M
Ts dm,k, scaled by √M/Ts. This can be also easily veriﬁed by direct
substitution in (5.25), which leads to
xn,k = xk(nTs) =
1
√MTs
M−1

n=0
dm,k e j 2π
M mn
=

M
Ts

1
M
M−1

n=0
dm,k e j 2π
M mn

,
n = 0, . . . , M −1.
(5.34)
Equations (5.33) and (5.34) highlight that an efﬁcient digital implementation of OFDM is possible by
exploiting (inverse) fast Fourier transform (FFT) algorithms for (inverse) DFT computations [173].
This observation was ﬁrst recognized in [257] and it is at the base of the renewed interest in OFDM
between 1980 and 1990, when the sampling frequencies of A/D and D/A converters, as well as the
clock frequencies of integrated circuits (IC) and memories, have started to become compatible with a
real-time implementation. It was indeed at the end of that decade that the ﬁrst mass-market commercial
OFDM standards were deployed, namely digital audio broadcasting (DAB) [71] and digital video
broadcasting-terrestrial (DVB-T) [72].

200
CHAPTER 5 OFDM and Multicarrier Signal Processing
2.05.5 OFDM in frequency-selective multipath channels
Note that, the architecture in Figure 5.5 has solved only the problem of efﬁciently separating M parallel
streams in AWGN channels. In the presence of frequency-selective (multipath) channels, each of the M
orthogonal single (sub-) carrier systems would suffer from the classical problem of ISI. However, the
reduction of the symbol rate of each stream to fs/M leads to consequent reduction, by a factor M, of
the length of the discrete-time impulse response hm[n] associated with each of the M parallel systems.
Thus, the OFDM system could be equalized by M parallel SC equalizers. As we already mentioned at
the end of Section 2.05.1, the complexity grows linearly and exponentially with the channel length for
time-domain linear and ML equalization, respectively [183]: thus we can immediately conclude that
the equalization complexity of OFDM is signiﬁcantly reduced with respect to a SC system with the
same bandwidth. Furthermore, we will show that the smart use of time guards further reduces OFDM
equalization, by a frequency-domain approach.
In order to identify how to recover the transmitted data also in the presence of a frequency-selective
channel, let us investigate the expression for the received signal in case of a typical time-invariant
multipath propagation, as shown in Figure 5.6 and summarized by
h(t) = hc(t) ∗g(t) =
P

p=0
αpg(t −τp),
(5.35)
where hc(t) has been deﬁned in (5.9), and g(t) captures the low-pass ﬁltering included in the A/D
and D/A converters, as well as the baseband (BB) equivalent of the band-pass ﬁltering stages in the
RF-to-BB and the BB-to-RF conversion.
To better understand the effect of the channel, and the potential resistance of OFDM to multipath
propagation, ﬁrst it is convenient to consider the spectrum of the received signal, which is given by
Yk( f ) = H( f )Xk( f ) + W( f ).
(5.36)
Focusing on a single OFDM symbol, the useful part of the spectrum (i.e., ignoring the noise) is
expressed by
H( f )Xk( f ) = Tu
M−1

m=0
dm,k H( f )sinc

πTu

f −fm
	
e−jφk( f −fm),
(5.37)
,
m k
d
k
d
k
x
,
n k
x
H
M
F
IDFT
,
n k
r
k
y
(f )
ky
+
m k,
,
m k
d
W
M
F
DFT
sf
AWGN Channel
D/A
( )
w t
A/D
sf
SP
PS
PS
SP
FIGURE 5.5
Discrete-time equivalent model of an OFDM system in AWGN (without CP).

2.05.5 OFDM in frequency-selective multipath channels
201
FIGURE 5.6
Frequency selective channel induced by multipath propagation.
which clariﬁes that a frequency-selective channel H( f ) does not destroy the orthogonality of the
transmitted data on the equispaced frequency grid { fm = m fs/M}m=0,...,M−1, as shown in Figure 5.1,
and summarized by
H( fm)X0( fm)
Tu
= H( fm)dm,0,
m = 0, . . . , M −1.
(5.38)
Thus, the receiver can effectively separate and detect the data transmitted during a single OFDM block,
still by sampling the OFDM spectrum of the received signal yk(t) = xk(t) ∗h(t) + nk(t). However, in
time-dispersive channels, because of the convolution with the channel impulse response (CIR) (5.35),
the duration of each single received OFDM block will be longer than Tu = MTs. If the CIR h(t) has a
time support (duration) Th, the received OFDM block yk(t) will have duration Tr = Tu + Th, as shown
in Figure 5.7.
Thus, sampling the OFDM spectrum of the 0th block requests to compute
Y0( fm) = Ts H( fm)dm,0 + Nm
=

 +∞
−∞
y0(t)e−j2π fmt dt =

 Tu+Th
0
y0(t)e−j2π fmt dt,
(5.39)

202
CHAPTER 5 OFDM and Multicarrier Signal Processing
t
h
T
t
*
( )
h t
u
T
=
t
u
h
T
T
+
0
0
( )
( )
( )
y t
x
t
h t
=
*
0( )
x
t
FIGURE 5.7
Effect of a time-dispersive channel on a single OFDM block.
which can be obtained by the DTFT of the sequence yn,0 = y0(nTs), evaluated at f = fm, as
expressed by
Y0( fm) =
M+L−1

n=0
yn,0 e−j 2π
M nm.
(5.40)
Note that (5.40) is quite similar to a DFT processing: the only difference is that the summation index
n exceeds the DFT period [0, M −1]. However, because of the periodicity of the discrete Fourier
exponentials, i.e., e−j 2π
M mn = e−j 2π
M m(n)mod M , it is evident that
Y0( fm) =
M−1

n=0

yn,0 + yn+M,0

e−j 2π
M nm.
(5.41)
Equation (5.41) highlights that the sampling can still be performed by an M-point DFT processing, on a
new M-length sequence ˜yn,0 = yn,0 + yn+M,0 obtained adding to the received sequence yn,0 its replica
anticipated by M discrete-time indexes, by an overlap-and-add strategy [173]. This way, the tail of yn,0
that exceeds the transmitted length M is added at the beginning of the original sequence, as shown in
Figure 5.8, making (5.41) equivalent to (5.40).
2.05.5.1 Zero-padded OFDM (ZP-OFDM)
Equation (5.38), and consequently (5.41), has shown a simple receiving strategy that preserves orthogo-
nality among the subcarriers at the receiver side, also in the presence of a time-dispersive channel. This
strategy, which has not been outlined in any of the historical and classical papers on OFDM [29,59,257],
is an alternative to the CP-OFDM transmission that will be described shortly. However, note that
(5.41) alone leads to a simple DFT-based receiver in frequency-selective channels, for a single OFDM
block. Actually, the transmission of consecutive OFDM blocks through a time-dispersive channel would
introduce ISI between successive blocks, typically called inter-block interference (IBI), as shown in
Figure 5.9.
This means that (5.41) avoids the ISI between different subcarriers (i.e., the ICI), but each (sub-) SC
signal y(m)(t) that constitutes the overall OFDM signal still suffers from the ISI between adjacent symbol
periods of duration Tu = MTs (i.e., IBI). Anyway, by designing Tu ≫Th, i.e., by employing a high
number M of carriers, the IBI impairs only a small fraction of the symbol period Tu. Consequently, the
performance degradation induced on each (sub-) SC system would be much lower than for a single SC
system with the same data rate, whose symbol duration is Ts = Tu/M. Obviously, there exist methods to

2.05.5 OFDM in frequency-selective multipath channels
203
FIGURE 5.8
The cyclic processing induced by frequency-domain sampling.
FIGURE 5.9
IBI induced by a time-dispersive channel.
compensate for such IBI (i.e., equalization algorithms), as we will detail later on; however, if the goal is
a very low-complexity receiver, it would be easy to deterministically avoid IBI by designing an OFDM
system that inserts a silent period Tg ≥Th (i.e., a time-guard) between consecutive OFDM symbols.

204
CHAPTER 5 OFDM and Multicarrier Signal Processing
channel dispersion (convoluon)
FIGURE 5.10
ZP to avoid IBI.
This approach, shown in Figure 5.10, is summarized by
xzp(t) =
M−1

m=0
x(m)
zp (t) =
+∞

k=−∞
xzp,k(t) =
+∞

k=−∞
M−1

m=0
dm,k e j2π m
Tu (t−kT )rectTu(t −(k + 1/2)T ),
(5.42)
where T = MTs + Tg, is the new duration of each OFDM block, including the time guard Tg ﬁlled
with a signal equal to zero. As a consequence, a multicarrier system based on (5.42) is typically called
zero-padded (ZP)-OFDM [251] or trailing-zeros (TZ) OFDM [166].
The insertion of a null symbol, with duration greater than the channel delay spread Th, grants an IBI-
free design and consequently the possibility to recover the data

dm,k

m=0,...,M−1 transmitted during
each OFDM block, by the simple per-subcarrier receiver architecture subsumed by (5.41). However, note
that this simple receiver is not the optimal one for ZP-OFDM from the BER performance point-of-view
[251], as it will be clariﬁed later on.
2.05.5.2 Cyclic-preﬁx OFDM (CP-OFDM)
A careful observation of the simple receiver for ZP-OFDM, induced by (5.41) and shown in
Figure 5.8, suggests that the superposition to each received OFDM symbol of L samples from its

2.05.5 OFDM in frequency-selective multipath channels
205
anticipated replica (tail) could be induced also at the transmitter side. Indeed, by some abuse of nota-
tion, it could be observed that
yk(t + MTs) = xk(t + MTs) ∗h(t) + wk(t),
(5.43)
i.e., an anticipated replica of the signal received during the kth OFDM symbol can be obtained by
transmitting, through the same channel, a replica of the original signal xk(t) anticipated by M samples,
i.e., anticipated by the useful symbol period Tu = MTs. Moreover, only the last L + 1 samples of
yk[n + M] are necessary in (5.41) to enable the simple per-subcarrier receiver: therefore it is necessary
to transmit only the last LTs seconds of the anticipated signal x(t + Tu). This strategy leads to the
so called CP-OFDM, shown in Figure 5.11, which is nowadays the most used approach in wireless
communications standards [71,72,104,105,237].
Thanks to the periodicity of the IDFT, mathematically the insertion of the CP is simply represented
by a longer rectangular pulse shaper with duration T = Tu + Tg, which is anticipated by Tg, as
summarized by
xcp(t) =
M−1

m=0
x(m)
cp (t) =
+∞

k=−∞
xcp,k(t) =
+∞

k=−∞
M−1

m=0
dm,k e j2π m
Tu (t−kT )rectT (t + Tg −(k + 1/2)T ).
(5.44)
2(
)
IBI
IBI
IBI
IBI-free circular convoluon
FIGURE 5.11
CP to avoid IBI and induce circular convolution.

206
CHAPTER 5 OFDM and Multicarrier Signal Processing
Figure 5.11 shows that the time guard Tg ≥Th is exploited for the insertion of the CP, rather than to
insert zeros as in ZP-OFDM. This CP insertion induces at the receiver side both the desired overlap
during the useful time period Tu, and an undesired IBI during the time guards. However, the IBI can
just be removed because the signal received during the useful period Tu = MTs has the same structure
of Figure 5.8 and, consequently, grants the simple separation of the M data ﬂows by frequency-domain
sampling. This separation is obtained by DFT processing through
Y (cp)
k
( fm) = Ts
M−1

n=0
y(cp)
n,k e−j 2π
M nm
= Ts
M−1

n=0

x(cp)
n,k ∗hn + wn,k

e−j 2π
M nm
= MTs H( fm)dm,k + Wm,k.
(5.45)
Equation (5.45) highlights that, similarly to ZP-OFDM in (5.39), CP-OFDM performs a separation of
the data in M orthogonal data-ﬂows, where channel equalization reduces to a simple per-subcarrier
equalization (PSE) of the ﬂat channel H( fm). Noteworthy, CP-OFDM performs the orthogonalization
by overlapping only the transmitted signal and not the noise wn,k, as it conversely happens for ZP-OFDM
in (5.41) and Figure 5.8. Thus, PSE of CP-OFDM has a noise performance advantage with respect to
PSE of ZP-OFDM. However, it should be taken in mind that PSE is not the optimal equalization strategy
for ZP-OFDM, as it will be clariﬁed later on.
An easy interpretation of CP-OFDM is that the CP induces a circular convolution of the transmitted
signal with the CIR, instead of the classical linear convolution. Thus, passing to the digital domain,
and after removal of the time guards, the discrete-time received signal during the kth OFDM symbol is
expressed by
yn,k = hn ∗M xn,k + wn,k,
n = 0, . . . , M −1,
(5.46)
where hn = 1
Ts h(nTs) is the discrete-time equivalent of the overall CIR, and ∗M stands for the M-point
discrete circular convolution operator [173]. By well-known DFT properties, the DFT of a time-domain
circular convolution of two sequences corresponds to the product of their DFTs, as expressed by
Ym,k = Hm Xm,k + Wm,k
= Hmdm,k + Wm,k,
m = 0, . . . , M −1,
(5.47)
which enables the easy and optimal PSE and detection [251]
˜dm,k = Ym,k
Hm
= dm,k + Wm,k
Hm
,
m = 0, . . . , M −1,
(5.48)
ˆdm,k = arg min
d∈D

|d −˜dm,k|

,
m = 0, . . . , M −1.
(5.49)
The capability to convert any system affected by a frequency-selective channel into a set of M inde-
pendent ﬂat-fading channels by the insertion of a CP longer than the channel delay spread, is the main

2.05.6 A vector-matrix representation for OFDM
207
motivation for the OFDM success. The main price to be paid is a waste of power efﬁciency, by a factor
equal to Lg/(Lg + M), due to the insertion of Lg time samples employed for the CP. Additionally, for
both CP-OFDM and ZP-OFDM, the CP or ZP insertion to grant IBI-free transmission induces also a
data-rate loss, again of a factor Lg/(Lg + M).
2.05.6 A vector-matrix representation for OFDM
Figure 5.5 shows the discrete-time equivalent model of an OFDM system that exploiting a serial-to-
parallel (S/P) converter, selects a block of M data symbols every MTs seconds, then generates the M
discrete-time samples to be transmitted by IDFT processing, and ﬁnally, after a parallel-to-serial (P/S)
conversion, sends the M samples to a D/A converter. In a vector-matrix notation equivalent to (5.34),
the OFDM symbol xk =

x0,k, . . . , xM−1,k
T transmitted during the kth period is obtained by
xk = FH
Mdk,
(5.50)
where dk =

d0,k, . . . , dM−1,k
T is a zero-mean uncorrelated data vector with covariance Rd = σ 2
d IM,
and

FM

n+1,m+1 =
1
√
M exp

−j 2π
M mn
	
is the unitary DFT matrix of size M. For notational conve-
nience, in (5.50) we have normalized the transmitted samples with respect to √Ts. In AWGN channels,
the received vector yk =

y0,k, . . . , yM−1,k
T is simply expressed by
yk = xk + wk,
(5.51)
where wk =

w0,k, . . . , wM−1,k
T , is an i.i.d. zero-mean Gaussian vector with covariance Rw = σ 2
wIM,
whose elements wm,k = wlp((kM + m)Ts) are the samples of the noise wlp(t) generated by low-pass
ﬁltering of w(t) in the A/D converter. Thus, the transmitted data dk can be recovered by a DFT processing
that generates the soft estimate y( f )
k
of the data vector dk, as expressed by
y( f )
k
= FMyk = FM

FH
Mdk + wk

= dk + w( f )
k
,
(5.52)
where

y( f )
k

m = Ym,k =
1
√
M
M−1
n=0 yn,k e−j 2π
M mn is the mth sample of the unitary DFT of the received
vector yk, and w( f )
k
is a vector containing the frequency-domain samples of the noise, which is still
AWGN.
The presence of an LTI multipath channel induces a dispersion in time of the symbols transmitted
during the kth block, as expressed by
rn,k =
L

l=0
hlsn−l,k,
n = 0, . . . , M + L −1,
(5.53)
where L is the CIR order, and sn,k = xn,k for OFDM transmissions. In a vector-matrix notation, this
time-domain spreading is captured by the N × (N −L) Toeplitz convolution matrix of the channel
H(N)
t
, which is expressed by

208
CHAPTER 5 OFDM and Multicarrier Signal Processing
H(N)
t
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
h0
0
· · ·
0
h1
h0
...
...
...
h1
...
0
hL
...
...
h0
0
hL
...
h1
...
... ...
...
0
0
hL
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
(5.54)
such that a transmitted vector sk of size M, generates a received vector r(N)
k
, of size N = M + L, as
expressed by
r(N)
k
= H(N)
t
sk.
(5.55)
However, because of the channel delay spread L, the received blocks associated to different OFDM
blocks overlap in time, thereby generating IBI (see Figure 5.9). As detailed in Section 2.05.3, a simple
way to contrast IBI is the introduction of a time guard between OFDM blocks, with a duration Lg ≥L,
which can be exploited to insert either zeros as in ZP-OFDM, or the CP as in CP-OFDM. Thus, as
shown in Figure 5.12, each transmitted block sk, of size M + Lg, is expressed by
sk = Txk,
(5.56)
where xk is the M-size OFDM block before the insertion of the time-guard, T = Tcp = [PT
cp IM]T with
Pcp
=

0Lg×(M−Lg) ILg

is the (M + Lg) × M CP insertion matrix for CP-OFDM, and
m,k
d
kx
,
n k
s
H
M
F
PS
IDFT
ky
(f)
k
y
sf
AWG
Noise
sf
Θ
T
DA
SP
LP/CDMA
CP/ZP
Insertion
NL[
]
f
⋅
NL Amplifier &
Predistortion
( )
p
k
d
ks
k
d
( )
ks
t
( )
ch t
+
( )
w t
(
)( )
out
ks
t
( )
k
y t
( )
kr t
Time/Freq
Synchron.
A
D
S
P
Channel
Estimate
Channel
R
CP/ZP
Removal
M
F
Channel
Equaliz.
Θ
CF Decod.
Despread.
ˆk
d
PS
,
ˆm k
d
(Coded)
Data
kr
ˆf
h
Θ
Η
Ε
DFT
Equalization & Detection
(
)
N
t
H
FIGURE 5.12
Baseband equivalent system model of a LP-OFDM/MC-CDMA system in a multipath fading channel.

2.05.6 A vector-matrix representation for OFDM
209
T = Tzp = [IM 0Lg]T is the (M + Lg) × M ZP insertion matrix for ZP-OFDM. Assuming for
simplicity that Lg = L, and that the delay spread L of the discrete-time channel is shorter than the
OFDM block length M, the received samples associated to the kth transmitted symbol can be collected
in a vector rk of size N + L = M + 2L, as expressed by
rk = Sar(N+L)
k−1
+ r(N+L)
k
+ Sdr(N+L)
k+1
+ ˜wk
= SaH(N+L)
t
sk−1 + H(N+L)
t
sk + SdH(N+L)
t
sk+1 + ˜wk
= SaH(N+L)
t
Txk−1 + H(N+L)
t
Txk + SdH(N+L)
t
Txk+1 + ˜wk
= H−1xk−1 + H0xk + H1xk+1 + ˜wk.
(5.57)
In (5.57) Sa =
 0L×N IL
0N×N+L

is the (N + L) × (N + L) matrix that shifts up a vector, inserting zeros in
the empty positions, to mimic the time advance associated with the transmission of consecutive OFDM
blocks,Sd =
 0N×N+L
IL
0L×N

isthe(N+L)×(N+L)matrixthatshiftsdownavector,insertingzerosinthe
empty positions, to represent the time delay, H-1 = SaH(N+L)
t
T, H0 = H(N+L)
t
T, H1 = SdH(N+L)
t
T,
and ˜wk is the AWGN term.
2.05.6.1 Vector-matrix representation of CP-OFDM
In CP-OFDM, it is straightforward to derive that the structure of the three channel matrices
H(cp)
−1
= SaH(N+L)
t
Tcp, H(cp)
0
= H(N+L)
t
Tcp, H(cp)
1
= SdH(N+L)
t
Tcp, is expressed by (5.58). From
(5.57) and (5.58), it is clear that the vector rk, of size N + L = M + 2L, suffers from IBI caused by
the previous (successive) block only in the ﬁrst (last) L samples of rk (see also Figure 5.11). Thus, a
simple way to remove the IBI is to select only the central M = N −L samples of rk: this corresponds
to remove the CP and to ignore the last L samples induced by the channel delay spread. Note that the
last L samples of rk overlap with the CP of rk+1, which has to be removed as well, because we adopted
a receiving window (of length N + L) that overlaps for adjacent blocks.
(5.58)

210
CHAPTER 5 OFDM and Multicarrier Signal Processing
Thus, the received vector typically used for the detection of a CP-OFDM symbol is expressed by
y(cp)
k
= [Rcp 0M×L]rk
= [Rcp 0M×L]H(cp)
0
xk + [Rcp 0M×L]wk,
(5.59)
where Rcp =

0M×LIM

is the CP removal matrix deﬁned in [251] for non-overlapping receiving
windows. Summarizing, the overall effect of inserting a CP by Tcp, removing it by Rcp, and discarding
the last L samples, leads to an overall observation equation equal to
y(cp)
k
= H(cp)
t
xk + wk
= H(cp)
t
FH
Mdk + wk,
(5.60)
where H(cp)
t
corresponds to the M central rows of H(cp)
0
in (5.58), as expressed by
H(cp)
t
= [Rcp 0N×L]H(cp)
0
= [Rcp 0N×L]H(N)
t
Tcp = RcpH(M)
t
Tcp.
(5.61)
The matrix H(cp)
t
is circulant, its ﬁrst column contains the CIR ht = [h0, h1, . . . , hL, 0, . . . , 0]T , and
the last equality in (5.61) highlights the equivalence with the notation in [251]. A circulant matrix can
be always diagonalized by DFT matrices [89], as expressed by
H(cp)
t
= FH
Mdiag(h f )FM,
(5.62)
where h f =
√
MFMht is the frequency transfer function of the discrete-time channel, whose (m +1)th
element is expressed by (see Figure 5.6)
Hm =

h f

m =
M−1

n=0
hn e−j 2π
M mn = H( fm),
(5.63)
for perfectly band-limited channel models H( f ).
Consequently, taking into account (5.50)
y(cp)
k
= FH
Mdiag(h f )dk + wk,
(5.64)
and applying a DFT on the received vector after the CP removal, we obtain
y( f )
k
= FMy(cp)
k
= diag(h f )dk + w( f )
k
.
(5.65)
Equation (5.65) highlights that the data transmitted on different subcarriers do not interfere with each
other, i.e., there is no ICI, and that the transmitted data are simply scaled by the diagonal frequency-
domain channel matrix H(cp)
f
= diag(h f ). Thus, for a Gaussian white noise w( f )
k
= FMwk, the optimal

2.05.6 A vector-matrix representation for OFDM
211
reception based on (5.65) is equivalent to the ML reception based on (5.60), as expressed by [117]
ˆdk = arg min
d∈DM
"""y(cp)
k
−H(cp)
t
FH
Md
"""
2
= arg min
d∈DM
"""y( f )
k
−diag(h f )d
"""
2
.
(5.66)
Since the frequency-domain channel matrix is diagonal, (5.66) can be separated in M independent ML
decisions
ˆdm,k =

ˆdk

m = arg min
d∈D

|yk,m −Hmd|

= arg min
d∈D

|yk,m/Hm −d|

.
(5.67)
Thus, the ML detector for a CP-OFDM system (that discards the CP) is a per-subcarrier zero-forcing
equalizer, followed by a threshold device that selects from the alphabet D the constellation symbol that
is closest to the equalizer output yk,m/Hm.
2.05.6.2 A note on the CP philosophy
A careful observation of (5.60) and (5.62) reveals that the easy equalization of OFDM is granted by
the CP insertion and removal (which produce a circulant channel convolution) rather than by the use of
orthogonal subcarriers. Thus, also SC communications could exploit this easy equalization property, by
inserting a CP of length L every M symbols. This type of block transmission is typically called CP-SC
[199,251]. For CP-SC systems, the kth transmitted block is
s(cp)
sc,k = Tcpdk,
(5.68)
and, after CP removal by Rcp and DFT processing, the observation vector in the frequency-domain at
the receiver side is
y( f )
sc,k = FMRcpH(M)
t
Tcpdk + w( f )
k
= FMH(cp)
t
dk + w( f )
k
= diag(h f )FMdk + w( f )
k
.
(5.69)
Equation (5.69) also allows for an easy non-ML detection, which consists in a diagonal equalization in
the frequency-domain (M complex divisions), followed by an IDFT processing and by M scalar data
detections, as expressed by
ˆdm,k = arg max
d∈D

˜dk

m −d

,
m = 0, . . . , M −1,
(5.70)
where
˜dk = FH
Mdiag−1(h f )y( f )
sc,k
= dk + FH
Mdiag−1(h f )FMwk
= dk + M−1/2circ(FH
Mh−1
f )wk,
(5.71)

212
CHAPTER 5 OFDM and Multicarrier Signal Processing
where circ

x
	
is the circulant matrix with x as ﬁrst column. Note that (5.70) is not the joint ML detector
of dk in (5.69), and that the least-squares (LS) estimator (5.71) is not the linear minimum variance
estimator for dk in (5.69). As ﬁrstly suggested in [199], and subsequently analyzed in [251,253,254],
the CP-SC transmission is the equivalent of the CP-OFDM transmission of Figure 5.5, where also
the IDFT processing is moved at the receiver side. Noteworthy, SC block transmission could induce
a circulant convolution, and exploit diagonal frequency-domain equalization, also by substituting the
CP with a known symbol [46] that can be further exploited for channel estimation and synchronization
purposes.
2.05.6.3 Vector-matrix representation of ZP-OFDM
For ZP-OFDM, the three channel matrices H(zp)
−1 = SaH(N+L)
t
Tzp, H(zp)
0
= H(N+L)
t
Tzp and H(zp)
1
=
SdH(N+L)
t
Tzp in (5.57) are expressed by (5.72). Thanks to the insertion of zeros among the blocks, the
received vector rk does not contain any IBI (see also Figure 5.10). The useful information about the
data xk transmitted during the kth block is contained in the ﬁrst N samples.
(5.72)
Therefore, inorder torecover thedata, it is sufﬁcient toemployareceivingwindowof size N = M+L
to collect
y(zp)
k
= [Rzp 0N×L]rk
= [Rzp 0N×L]H(zp)
0
xk + [Rzp0N×L] ˜wk
= [Rzp 0N×L]H(N+L)
t
Tzpxk + wk
= Rzp ˜H(N)
t
Tzpxk + wk
= H(zp)
t
xk + wk,
(5.73)
where the receiving matrix for ZP-OFDM is simply expressed by Rzp = IN, and ˜H(N)
t
contains the ﬁrst
N rows of H(N+L)
t
. In (5.73), the last-but-one equality highlights the equivalence with the notation used
in [251]. Summarizing, the ZP-OFDM transmission through a time-dispersive channel is affected by the
banded Toeplitz channel matrix H(zp)
t
, contained in the ﬁrst N rows of H(zp)
0
in (5.72), which has always

2.05.6 A vector-matrix representation for OFDM
213
full rank. In this case, the channel matrix is not circulant, and the received vector has a size N = M + L.
Thus, a receiver that employs a pure DFT operation should use a DFT matrix FH
M+L of size M + L,
which would correspond to project the received vector on a set of discrete frequencies different from
those used at the transmitter side, which does not make any sense. The intuition would suggest to use,
at the receiver side, the same discrete frequencies fm = M−1/2 
1, . . . , e−j 2π
M mn, . . . , e−j 2π
M m(M−1)T
used at the transmitter (which are periodic), by extending them on the longer time-support N = M + L.
This corresponds to use a set of basis functions contained in the columns of the matrix
B =

FM
F(1:L)
M
H
,
(5.74)
where F(1:L)
M
= FM

IL
0L×M−L
T is the M × L matrix containing the ﬁrst L columns of FM, to
extend each basis vector. Thus, projecting the received vector onto the extended basis, we obtain
˜y( f )
k
= BHy(zp)
k
=

FM
FM[IL 0L×M−L]T 
y(zp)
k
= FM
⎡
⎣
IL
IM
0M−L×L
⎤
⎦y(zp)
k
= FM
⎛
⎝
IM
0M×L

+
⎡
⎣
IL
0M×M
0M−L×L
⎤
⎦
⎞
⎠y(zp)
k
= FM

y(s)
k + y(a)
k

,
(5.75)
where y(s)
k
=

IM
0M×L

y(zp)
k
is a shortened version of y(zp)
k
to its ﬁrst M values, and y(a)
k
is an M
vector containing an anticipated version of y(zp)
k
, with its last L samples in the ﬁrst L positions, and
zeros elsewhere. Thus, (5.75) is the vector-matrix equivalent of (5.40) and (5.41), which enabled in
ZP-OFDM the simple PSE and decoding of the data transmitted on each separate subcarrier fm. Indeed,
plugging (5.73) in (5.75), we obtain
˜y( f )
k
= FM
⎡
⎢⎣
IL
IM
0M−L×L
⎤
⎥⎦˜H(N)
t
Tzpxk + FM

wk + w(a)
k

= FM
⎡
⎢⎣
IL
IM
0M−L×L
⎤
⎥⎦˜H(N)
t

IM
0L×M

xk + FM

wk + w(a)
k

.
(5.76)
By direct substitution, it is straightforward to prove that
⎡
⎢⎣
IL
IM
0M−L×L
⎤
⎥⎦˜H(N)
t

IM
0L×M

= H(cp)
t
,
(5.77)

214
CHAPTER 5 OFDM and Multicarrier Signal Processing
and consequently
˜y( f )
k
= FMH(cp)
t
FH
Mdk + FM

wk + w(a)
k

= diag(h f )dk + w( f )
k
+ e(zp)
k
= diag(h f )dk + w(zp)
k
.
(5.78)
Note that, except for the extra noise term e(zp)
k
induced by the anticipated replica y(a)
k , (5.78) is equivalent
to the receiving Eq. (5.65) for CP-OFDM, and consequently simple PSE is possible also in this case.
However, PSE and detection by (5.67) would not result in the ML estimator of dk in (5.78), because
e(zp)
k
is characterized by a (non-diagonal) circulant correlation matrix, expressed by
Re = σ 2
wFMdiag

1L
01×M−L
	
FH
M
= σ 2
wM−1/2circ

FM

1L 01×M−L
	
= σ 2
wM−1/2circ
'L−1

m=0
fm
(
,
which introduces a color on the overall noise w(zp)
k
[117]. Indeed, in this case, the ML estimator of dk
in (5.78), with a perfect channel knowledge, would request to compute
ˆdk = arg max
d∈DM

f˜y( f )
k

˜y( f )
k
; d

= arg max
d∈DM

fw(zp)
k

˜y( f )
k
−H(cp)
f
d

= arg max
d∈DM

exp

˜y( f )
k
−H(cp)
f
d
H
Rw(zp)
k

˜y( f )
k
−H(cp)
f
d

= arg min
d∈DM

˜y( f )
k
−H(cp)
f
d
H
Rw(zp)
k

˜y( f )
k
−H(cp)
f
d

(5.79)
that reduces to
ˆdk = arg min
d∈DM
"""˜y( f )
k
−H(cp)
f
d
"""
2
(5.80)
only if the noise is white and uncorrelated, that is if Rw(zp)
k
is a scaled identity matrix, which is not this
case since Rw(zp)
k
= σ 2
wIM + Re.
2.05.7 Symbol error rate (SER) performance analysis
The SER analysis for ML detection of CP-OFDM is quite simple, because of the frequency-domain
channel diagonalization induced by the CP. Indeed, (5.65) and (5.45) show that the data transmitted on
each separate subcarrier are impaired by a ﬂat-fading channel, as expressed by
ym,k = Hmdm,k + Wm,k.
(5.81)

2.05.7 Symbol error rate (SER) performance analysis
215
If the discrete-time channel taps {hl}l=0,...,L are zero-mean Gaussian distributed, then it is straightfor-
ward to verify that Hm in (5.63) is also zero-mean Gaussian, |Hm| is Rayleigh distributed with a prob-
ability density function (pdf) expressed by f|Hm|( |Hm| ) =
|Hm| /α2
m
	
e−|Hm|2/2α2
m, with |Hm| > 0,
and
2α2
m = E

|Hm|2
=
L

l=0
L

i=0

Rht

l+1,i+1 e j 2π
M (l−i)m,
(5.82)
where Rht = E

hthH
t

is the autocorrelation matrix of the discrete-time channel, and Wm,k is the
AWGN in the frequency-domain. Thus, the symbol error rate (SER) performance on a frequency-ﬂat
Rayleigh fading channel for each subcarrier is expressed by [183]
SERm = P{ ˆdk,m ̸= dd,m} =

 +∞
0
αQ Q
⎛
⎝

βQ
|Hm|2 σ 2
d
σ 2w
⎞
⎠f|Hm|
|Hm|	
d |Hm| ,
(5.83)
where αQ and βQ depend on the complex alphabet D of dm,k. Deﬁning the average SNR for each
subcarrier as SNRm = E
|Hm|2
σ 2
d /σ 2
w, if dm,k is drawn from a QPSK alphabet, (5.83) leads to [183]
SERm = 1
2
'
1 −

SNRm
2 + SNRm
(
,
(5.84)
and the total SER is the average of (5.84) over all the subcarriers, as expressed by
SER = 1
M
M−1

m=0
SERm.
(5.85)
Equation (5.84), together with (5.82), highlights that the SER performance depends on the sum of the
second order moments of the time-domain channel paths rather than on the number L of the paths. For
instance, in the simpler case when the channel paths are independents (i.e.,

Rht

l, j = σ 2
l δ[l −j]),
(5.82) becomes
E

|Hm|2
=
L

l=0
σ 2
l ,
(5.86)
which highlights the two following observations:
i. SNRm, and consequently SERm, is the same for all the subcarriers, and SER = SERm.
ii. The SER depends only on the total power Ph = L
l=0 σ 2
l of the multipath channel and does not
depend on the power distribution among the different paths (i.e., does not depend on the power-
delay proﬁle of the channel). Thus, the performance of CP-OFDM in a multipath Rayleigh fading
channel would be the same performance in a single-path Rayleigh fading channel, where all the
power is concentrated in the single path.

216
CHAPTER 5 OFDM and Multicarrier Signal Processing
The last observation indicates that an uncoded CP-OFDM system is not capable to exploit the
potential diversity offered by a multipath fading channel. Indeed, while it is highly improbable that all
the L time-domain paths fade to zero simultaneously, the single frequency-domain path associated to
each data in (5.81) has a greater probability to fade towards zero, making the data dm,k unrecoverable also
in the presence of a low noise value Wm,k. Actually, each single path of the CIR is a potential source
of diversity,2 because the receiver collects multiple (independent) copies of the transmitted signal.
This is similar to the space diversity offered by multi-antenna receiving systems [183]. However, the
CP insertion and removal, which leads to the frequency-domain channel diagonalization, destroys the
multipath diversity and sacriﬁces uncoded SER performance for a simpler per-subcarrier equalization.
Such loss of diversity for uncoded SER performance can be recovered by channel coding (see Section
2.05.6), or by linear precoding (see Section 2.05.7), which spreads each uncoded data over all (or
several) different subcarriers [167]. The SER analysis for ML decoding of ZP-OFDM is not as simple
as for CP-OFDM, because the ML detection based on (5.73) leads to
ˆdk = arg min
d∈DM
"""y(zp)
k
−H(zp)
t
FH
Md
"""
2
,
(5.87)
which does not have an equivalent (diagonal) formulation in the frequency-domain, because of the
banded Toeplitz structure of H(zp)
t
. Consequently, differently from CP-OFDM, the ML detector for
ZP-OFDM is not based on PSE. SER and diversity analysis for ML problems like in (5.87) are typically
addressed by the probability that a given transmitted data vector da ∈DM is confused at the receiver side
with another possible transmitted vector db ∈DM. This leads to the so-called pairwise-error probability
(PEP) [218,219,229,236], which is deﬁned as
PEPa→b = P{ˆdk = db|dk = da},
(5.88)
and dominates the SER. As detailed in [250], the minimum PEP for all the possible couples {da, db} is
granted if the observation matrix (zp)
H
= H(zp)
t
FH
M has a full column rank for any channel realization.
This is equivalent to state that, in the absence of noise, is not possible to confuse da with db at the
receiver, or equivalently, to the symbol detectability condition [251]
(zp)
H (da −db) ̸= 0M×1, ∀ht, ∀da ̸= db.
(5.89)
Actually, (5.89) is granted because both FH
M and H(zp)
t
are always full column rank, and consequently
rank

(zp)
H

= M. The same analysis for CP-OFDM highlights that the observation matrix in (5.66)
is (cp)
H
= diag(h f ), which is not full rank for those channel realizations h f that contain a zero in
one of its elements. Indeed, in CP-OFDM, if the discrete-time channel ht induces a frequency-domain
channel h f =
√
MFMht with a zero on the (m + 1)th subcarrier, i.e.,

h f

m = Hm = 0, the data
dm,k on that subcarrier would be not recoverable even in the absence of noise, as clariﬁed by (5.81).
2The diversity d captured by a communication system is deﬁned as the negative slope of the SER curve plotted (on a
logarithmic scale) versus (SNR)dB, for (SNR)dB →+∞. In frequency-ﬂat Rayleigh fading channels, the diversity is d = 1.
A discrete-time channel with L + 1 independent paths potentially offers a maximum diversity L + 1. See [148,229] for a
rigorous deﬁnition of diversity in block transmissions.

2.05.7 Symbol error rate (SER) performance analysis
217
Thus, at the receiver side, those data vectors db that differ from da only on the (m +1)th element would
be undistinguishable from da, causing a degradation of the average PEP and SER.
The price paid by ZP-OFDM with respect to CP-OFDM, for better uncoded SER performance with
ML detection, is the higher detection complexity induced by (5.87), which grows exponentially with
the vector size M and the cardinality of the data alphabet D. Conversely, if ZP-OFDM is detected
by exploiting the overlap-and-add (OLA) approach of (5.75), the detection complexity is signiﬁcantly
reduced. Indeed, the OLA operation of (5.75) induces a circulant channel at the receiver side: in this
case, a simpler PSE can be employed by compensating for the diag(h f ) term in (5.78). Therefore,
OLA-based per-subcarrier detection of ZP-OFDM presents a decoding complexity O(M log M) that
is similar to CP-OFDM. In addition, using OLA-based per-subcarrier detection of ZP-OFDM, also the
SER performance would be somewhat similar to CP-OFDM (see Figure 5.13). Indeed, with respect to
CP-OFDM, OLA-based ZP-OFDM presents a noise power penalty caused by the extra noise term e(zp)
k
0
5
10
15
20
25
30
35
40
10
-5
10
-4
10
-3
10
-2
10
-1
10
0
Eb / N0  (dB)
BER
 
CP OFDM
ZP OFDM (OLA)
ZP OFDM (ZF)
ZP OFDM (MMSE)
ZP OFDM (fast MMSE)
FIGURE 5.13
Performance comparison between CP-OFDM and different ZP-OFDM detectors in a multipath Rayleigh fading
channel (Uncoded BER, QPSK, M = 64, L = 16, Channel A of HIPERLAN/2). This ﬁgure has been generated
using the MATLAB script zp_vs_cp.m.

218
CHAPTER 5 OFDM and Multicarrier Signal Processing
in (5.78), and an equivalent advantage on the average (useful) signal power due to the absence of CP
transmission. Each of these two effects compensates with one another, as shown in Figure 5.13.
2.05.7.1 Suboptimal linear equalization/detection for ZP-OFDM
As detailed in [167], other suboptimal receivers for ZP-OFDM are possible, allowing for different
performance-complexity trade-offs. For instance, linear receivers produce a soft estimate of the trans-
mitted data by
˜dk = EHy(zp)
k
,
(5.90)
where the equalization/detection matrix can be designed according to a LS or MMSE approach [117],
as expressed by
E(ls)
H =

H
HH
−1
H
H = FM

H(zp)H
t
H(zp)
t
−1
H(zp)H
t
,
(5.91)
and
E(mmse)
H
=

H
HH +
1
SNRI
−1
H
H = FM

H(zp)H
t
H(zp)
t
+
1
SNRI
−1
H(zp)H
t
.
(5.92)
It is clear from (5.91) and (5.92), that this approach consists in a LS and MMSE equalization of the tall
and Toeplitz channel matrix H(zp)
t
in (5.73), followed by a frequency-domain per subcarrier detection.
These LS and MMSE approaches, denoted in Figure 5.13 with ZF and MMSE, respectively, give a
performance gain with respect to OLA-based detection, at the price of increased complexity, which is
O((M + L)2).
Another low-complexity suboptimal approach, denoted with fast-MMSE in Figure 5.13, relies on a
sliding window of dimension M + 2L that includes two ZP parts: the ZP part that precedes, and the ZP
part that follows, the data vector of size M. In this case, the ﬁrst ZP part, of size L, can be interpreted
as the CP of the remaining vector, of size M + L, because the last part of the remaining vector is the
second ZP part. As a consequence, the detection approach can be similar to CP-OFDM: the ﬁrst ZP
part is discarded, and the FFT of size M + L is applied on the remaining vector of size M + L. The
complexity of this fast-MMSE approach is O((M + L) log (M + L)).
2.05.8 Coded—OFDM
As highlighted in Section 2.05.5, and summarized by (5.81) and (5.83), CP-OFDM is not capable to
exploit the potential diversity offered by a multipath fading channel, whose taps fade in an independent
fashion. This is a direct consequence of transmitting each single data dm,k onto a single subcarrier:
if the mth frequency channel Hm fades to zero, there is no way to recover dm,k, because dm,k is not
contained in any other diversely received sample. Thus, in highly frequency-selective channels, the
SER performance is signiﬁcantly degraded because of the loss of the data dm,k on those subcarriers that
are impaired by an almost null channel transfer function. For instance, in multipath Rayleigh fading
conditions, the SER performance is equivalent to that of a single-carrier system impaired by a Rayleigh
ﬂat-fading channel, with diversity order equal to one.

2.05.9 Linearly precoded-OFDM (LP-OFDM)
219
Possible counter-measures to channel fading are typically known as diversity techniques and his-
torically emerged in telecommunications by providing the receiver with multiple copies of the same
information. These multiple copies of the same information are transmitted in the frequency-domain
[or in the space (antenna)-domain or in the time-domain], and possibly are impaired by independent
fading distortions [183]. The correct combination of multiple information manifests in an increase of
the average SNR, a better SNR statistic, and consequently a SER performance that tends to the SER in
AWGN channels, when the number of independent information copies is high enough [183]. Anyway, a
pure diversity technique cannot improve performance over the SER threshold represented by the AWGN
scenario.
Actually, Forward Error Correcting codes (FECs), or channel codes, were historically designed to
contrast the errors in AWGN scenarios, by introducing algebraically-structured redundancy [183]. This
form of redundancy, introduced at the transmitter side, distributes the information data on almost all the
subcarriers: consequently, by channel decoding at the receiver side, it is possible to exploit this redun-
dancy to jointly contrast the errors induced by fading channels and collect part of the channel diversity.
Some examples of popular FEC schemes [183] exploited in standard Coded-OFDM (C-OFDM) systems
include block-codes (e.g., Reed-Solomon codes), convolutional codes (CC), and concatenated codes,
which were exploited since the beginning of the OFDM era in commercial systems such as DAB [71],
DVB-T/S [72], WiFi [104], WiMAX [105], while BCH codes, turbo codes and low-density parity-check
(LDPC) codes [183] have been more recently exploited in DVB-T2/S2 [73] and UMTS-LTE [237].
The basic idea to use FEC to contrast fading is to make the errors statistic induced by fading looks
similar to the error statistic introduced by the noise in AWGN channels: this is obtained by equipping
the OFDM system with appropriate interleavers, which scramble the coded data through the subcarriers
to collect the channel frequency diversity, and through consecutive OFDM blocks to collect the channel
time diversity. The price for such a joint resistance to fading and AWGN is the increase of decoding
delay, because the interleaver depth may span several OFDM blocks in order to be effective. Thus,
especially for time-sensitive communications, it could be preferable to have some sort of diversity
resistance that does not require coding over several consecutive OFDM blocks.
This possibility has been explored more recently, by exploiting the possibility to transmit (possibly
redundant) linear combinations of the data dm,k by the so called linearly precoded-OFDM (see Section
2.05.9), or by antenna-diversity through space-time coding (see [66,84,88,178] ad references therein
for further details).
2.05.9 Linearly precoded-OFDM (LP-OFDM)
FEC are typically designed to contrast AWGN channels and therefore are designed in order to maximize
the Euclidean distance among codewords in order to be resistant to an additive distortion. This Euclidean
maximization is not the optimal strategy in a fading channel, where the Hamming distance is the key
element to minimize the PEP among codewords [229,250], in order to be resistant to a multiplicative
Distortion.
In an OFDM system, which conveys information on parallel carriers, the transmitter could spread a
group of data

dm,k

over several of these carriers, by exploiting a linear precoding (LP) matrix . The
aim is to introduce frequency diversity and potentially be capable to recover all the transmitted data

220
CHAPTER 5 OFDM and Multicarrier Signal Processing
(exploiting the ﬁnite alphabet of dm,k) even if one of the carriers fades to zero. Thus, an LP transmitter
generates a (potentially redundant) vector d(p)
k
by performing a linear combination of the original data,
as shown in Figure 5.12 and expressed by
d(p)
k
= dk,
(5.93)
where  =

θ0, . . . , θ M−1

, is the (possibly redundant) precoding matrix3 of size M′ × M. Thus, with
LP, a CP-OFDM system transmits d(p)
k
through a multipath fading channel ht, and (5.65) becomes
y( f )
k
= diag(h f )dk + w( f )
k
,
(5.94)
where the number of subcarriers (i.e., the size of y( f )
k
and h f ) is M′ ≥M. From (5.94), ML detection
requests to compute
ˆdk = arg min
d∈DM
"""y( f )
k
−diag(h f )dk
"""
2
,
(5.95)
which involves the non-diagonal channel-precoding matrix H = diag(h f ). Thus, the easy PSE (and
easy ML detection) of OFDM is lost, but the PEP (and SER) performance can be boosted by a proper
design of the precoding matrix .
As clariﬁed in [172], in order to exploit all the diversity d offered by a multipath fading channel, the
overall observation matrix should guarantee that in the absence of noise any couple of transmitted data
vectors are observable at the receiver side with a minimum Hamming distance greater than or equal to d.
To this end, it is sufﬁcient (but not necessary) to guarantee the symbol detectability condition, i.e., that
H has full column rank. Note that the discrete-time frequency response h f of a time-domain channel
ht with L + 1 non-zero paths may have at most L zeros: therefore, diag(h f ) can cancel-out up to L
rows of . Thus, it would be enough to redundantly design  with M′ = M + L linearly independent
rows, such that any set of M rows of  are linearly independent. If this design condition is veriﬁed, the
row cancellation in diag(h f ) still guarantee that H = diag(h f ) has (full-column) rank M. Thus,
by the M out of M′ observations in (5.94) that are different from zero, it would be always possible in
the absence of noise to distinguish any transmitted data vector da from any other db. A possible choice
for such precoding matrices are Vandermonde matrices where [251]



i, j = ρ j−1
i
,
with ρi ̸= ρl and ρi ∈C,
(5.96)
or cosine matrices with



i, j = cos

( j + 0.5)φi
	
,
where φi ± φl ̸= 2kπ,
∀i ̸= l,
∀k ∈Z.
(5.97)
When ρi = e j 2π
M i and M′ = M, the Vandermonde matrix becomes the DFT matrix  = FM, while,
when φi = iπ/N,  represents the discrete cosine transform (DCT) matrix. Moreover, note that the
3Note that by (5.93) it is possible to describe also classical block channel coding techniques developed for AWGN channels,
with some minor differences. While for LP the precoded data is constructed on the complex ﬁeld, i.e., dk ∈CM′, in
classical binary block codes dk ∈{−1, 1}M′ for binary PSK, such that the coded vectors can be represented on a lattice,



i, j , [dk]i ∈GF(2), and the redundancy inserted by  is typically exploited to increase the minimum Euclidean distance
among codewords.

2.05.9 Linearly precoded-OFDM (LP-OFDM)
221
precoding matrix should be normalized such that all the columns have a unit norm, i.e., ∥θm∥2 = 1
[250] in order to not decrease the minimum Euclidean distance between the precoded vectors and
consequently penalize the SER performance in AWGN channels where diag(h f ) = hoIM′.
An interesting choice for the redundant precoding matrix is  =

F(1:M)
M+L
H
, i.e., the Vandermonde
matrix obtained by selecting the ﬁrst M columns of an IDFT matrix of size M + L. By this choice, the
precoded vector to be transmitted, is expressed by
d(p)
k
= FM+L

F(1:L)
M+L
H
dk =
IM
0L×M

dk = Tzpdk,
(5.98)
which is nothing else than a ZP-SC system, which does not need the use of a CP. Thus, the redundancy
introduced by ZP in a block SC system grants not only IBI suppression, but also symbol detectability
and, consequently, the capability by ML decoding to exploit the maximum diversity offered by the
channel [253,254].
In practice, LP-OFDM systems (including ZP-SC), can capture (part of) the diversity [236] also by
exploiting suboptimal linear equalization/detection schemes by producing the soft estimate
˜dk = EHy( f )
k
,
(5.99)
where the equalization/detection matrix EH can be computed by an LS or MMSE approach [117], by
substituting H with H in (5.91) and (5.92), respectively. Further details can be found in [250].
However, the sufﬁcient condition rank

diag(h f )

= M guarantees that any couple of vectors
da ̸= db could be distinguished at the receiver side in the absence of noise, without exploiting the fact
that the elements of dk belong to a ﬁnite alphabet D. Thus, by exploiting the structure imposed on the
possible data vectors by the ﬁnite alphabet and algebraic number theory, it is possible to design also
non-redundant (square) precoding matrices  that are capable to capture all the diversity offered by
the channel, with M′ = M. As detailed in [148], such a matrix is proved to always exist: it is a square
Vandermonde matrix, whose elements are expressed by
ρi = e j 2π
P

P(i−1)/M+p

√
M
,
such that
(P) = 2kM, k ∈N+,
p ∈[1, P/M) ∩N+,
MCD

P(i −1)/M + p

, P
	
= 1,
(5.100)
where (P) is the Euler’s totient function, which identiﬁes the number of integers that are lower, and
relative prime, with respect to P. Although for a given size M the solution of (5.100) is not unique, for
the special but important case where M is a power of two, the precoding matrix can be always written
as
 = FMdiag([1, ρ1, . . . , ρM−1
1
]),
(5.101)
which highlights that the precoding matrix is unitary, i.e., H = IM. Moreover, (5.101) practically
states that the diversity-optimum CP-aided block transmission, is a CP-SC system equipped by a simple
diagonal non-redundant precoder, as expressed by the transmitted data vector
x(cp-lp-sc)
k
= TcpFH
Md(p)
k
= TcpFH
Mdk = Tcpdiag([1, ρ1, . . . , ρM−1
1
])dk.
(5.102)

222
CHAPTER 5 OFDM and Multicarrier Signal Processing
It is important to highlight that the non redundant precoding based on (5.100) or (5.101) is not only
capable to capture all the diversity, but can also maximize the coding gain4 in SER performance, by
selecting the lowest p that satisﬁes (5.100). For further details on optimal constellation rotations, the
interested readers are redirected to [24,32,87].
The price to be paid for the exploitation of the channel diversity is the computational complexity of
ML decoding, which grows exponentially with the size M of the data vector dk. Quasi-ML decoding
performance can be obtained by algorithms such as sphere decoding [250] characterized by reduced
complexity for moderate precoder sizes and many SNR values [108].
However, it can be observed that, in order to not sacriﬁce too much the system efﬁciency, the CP or ZP
length is in general L +1 ≪M, and consequently, in order to collect the diversity d ≤L +1 offered by
the channel, it would be enough to spread each symbol on a number of subcarriers Qp = M/Gp ≥L+1,
where Gp is an integer greater than 1. Therefore, instead of a large precoder of size M equal to the
number of subcarriers, many precoders can be applied to different groups of Qp = M/Gp subcarriers.
This corresponds to an overall precoded matrix that can be written as
 = P
⎡
⎢⎢⎢⎢⎢⎢⎣
0
0
· · ·
0
0
1
...
...
...
...
...
0
0
· · ·
0
Gp−1
⎤
⎥⎥⎥⎥⎥⎥⎦
,
(5.103)
where P is a permutation matrix that establishes how the M subcarriers are grouped into the Gp groups,
and

g = 0

g=0,...,Gp−1 isa Qp×Qp non-redundantprecodingmatrixdesignedaccordingto(5.101).
Since the beneﬁt in SER performance tends to reduce for increasing diversity [183], suboptimal designs
based on (5.103) with Qp = 3, 4 < d ≤L + 1 can be employed: this way, the ML decoding in (5.95)
leads to Gp parallel ML decoding problems for the data observed (and transmitted) on the Gp orthogonal
sets, with a complexity O(Gp |D|Qp ) instead of O( |D|QpGp ). The parallel ML decoding is expressed
by
ˆdk,g = arg min
dg∈DQp
"""y( f )
k,g −diag(h f ,g)0dk,g
"""
2
,
g = 0, . . . , Gp −1.
(5.104)
The data sub-vectors dk,g, as well as the other quantities in (5.104), are just the sub-vectors selected
from the corresponding ones in (5.95), by means of (5.103). This approach has been proposed in [148],
where it is called grouped linear precoding (GLP). In order to collect the highest possible diversity for all
the subgroups, and thus optimize the average SER, the best strategy is to design the permutation matrix
P such that each subgroups of data dk,g is assigned to a different set of equispaced subcarriers, which,
being separated, are most likely different (more diverse) than contiguous subcarriers [148]. In the context
of non-redundant GLP-OFDM, the performance of ML and other suboptimal equalization/detection
schemes, such as ZF and MMSE, is shown in Figure 5.14.
4While the diversity gain is a measure of the (negative) slope of the SER (or PEP) curve versus (SNR)dB, in high SNR regimes,
the coding gain (for a ﬁxed diversity gain) measures the (SNR)dB shift to the left of the SER, with respect to a precoder that
does not provide any coding gain. While the diversity gain is imposed by the rank of the overall channel observation matrix,
the coding gain is established by the determinant of the observation matrix [148,229].

2.05.9 Linearly precoded-OFDM (LP-OFDM)
223
0
2
4
6
8
10
12
14
16
18
10-4
10-3
10-2
10-1
100
Eb / N0 (dB)
 
 
OFDM
LP-OFDM (ZF)
LP-OFDM (MMSE)
LP-OFDM (DFE)
LP-OFDM (ML)
BER
FIGURE 5.14
Performance comparison among different detection criteria for GLP-OFDM (Uncoded BER, BPSK,
M = 16,GP = 2, QP = 8, L = 2, multipath channel with uniform power-delay proﬁle). This ﬁgure has
been generated using the MATLAB script lp_ofdm.m.
Linear precoding approaches for multicarrier transmissions have been discussed also in [38], which
compares linear precoders based on rotated (Fourier or Walsh-Hadamard) transforms, and in [146],
which derives the conditions for minimum-SER precoding design for a linear detector.
A fundamental contribution to redundant LP can be found in [201,202]. The ﬁrst of these two
companion papers generalizes OFDM, DMT, CDMA, and TDMA communications, and establishes
sufﬁcient conditions for a precoded transmission scheme to perfectly equalize any FIR channel (channel
identiﬁability), independently of its zeros locations. Additionally, a joint ZF design of the transmitter
and receiver ﬁlterbanks is proposed, under MMSE and maximum SNR criteria. The second paper, by a
ZP approach, derives also blind channel estimators, block synchronizers, and direct-equalizers for the
proposed ﬁlterbank structure. Note that, also multiuser MC systems, such those addressed in the next
section, fall within the general ﬁlterbank formulation in [201,202].
As a ﬁnal remark, it should be noted that LP and FEC are not alternative with one another, but they
are both valuable tools to protect an OFDM system from errors induced by a fading channel. As already
explained, FECs have been historically introduced to protect digital communications from AWGN, they
introduce redundancy, and can be effective also to combat channel fading by properly scrambling and

224
CHAPTER 5 OFDM and Multicarrier Signal Processing
interleaving the coded data. Conversely, LP techniques are designed to exploit the channel diversity (if
it is present), cannot improve performance in AWGN, and they do not necessarily request redundancy.
Thus, a proper design could combine LP with FEC, in order to collect the channel diversity (if any) to
make the equivalent channel almost AWGN, and then exploit FEC mainly to protect from AWGN. In
severe multipath fading channels, this approach can guarantee SER performance equivalent to those of a
pure FEC-OFDM system, with lower redundancy, lower complexity, and lower decoding delay. Readers
interested on a comparison of LP with FEC, and on their joint design, are redirected to [252–254].
2.05.10 Multiuser multicarrier systems
Section 2.05.2 has clariﬁed that OFDM can be seen as a special case of CDMA, where M parallel data
ﬂows are simultaneously transmitted in time and distinguished by the use of different codes cm(t), as
expressed by
x(t) =
M−1

m=0
x(m)(t) =
+∞

k=−∞
M−1

m=0
dm,kcm(t −kT )rectT (t −(k + 1/2)T ),
(5.105)
where T is the symbol period and T is the symbol duration, less than or equal to the symbol period.
For instance, a CDMA system with M parallel transmissions, can be represented during the useful kth
symbol by a transmitted data vector x(c)
k
=

x(kT ), . . . , x

kT + (M −1)Ts
	T expressed by
x(c)
k
=
M−1

m=0
cmdm,k = Cdk,
(5.106)
where cm =

cm,0, . . . , cm,M−1
T , with cm,n = cm(nTs), is the mth spreading sequence, also known as
spreading code, and C =

c1, . . . , cM−1

is the code matrix. Additionally, to handle IBI as in OFDM
transmissions, each transmitted block in (5.105) could be separated in time by T = Tu + Th, leading to
a CP-CDMA when T = T , or to a ZP-CDMA when T = Tu. Further considerations on CDMA are
left for the end of this section where CDMA systems are brieﬂy compared with multiuser MC systems.
In the case of OFDM, the codes are cm(t) = e j2π fmt, which are orthogonal on the useful duration
Tu by (21), C = FH
M, and the overall transmitted block is
Tx(c)
k
= T
M−1

m=0
fmdm,k = TFH
Mdk,
(5.107)
withT = Tcp forCP-OFDMandT = Tzp forZP-OFDM.Whenorthogonalfrequenciesfm areemployed
to distinguish different users, the system is identiﬁed as an OFDM access (OFDMA) systems, which
has the nice property to preserve users’ orthogonality in LTI channels. Moreover, different data rates
can be easily handled in OFDMA by reserving different groups of subcarriers to different users, as it
happens for instance in WiMAX and LTE [105,237].

2.05.10 Multiuser multicarrier systems
225
Researchers have historically tried to combine the easy equalization of OFDM, with desirable prop-
erties of classical CDMA systems, such as resistance to narrowband interference, and capability to
exploit diversity in multipath fading channels [183,247].
A possibility is to use a code in the frequency-domain, to spread a single data du,k on all the sub-
carries, such that, after spreading, the data vector for the uth user is d(c)
u,k = cudu,k, and the overall data
vector for all the U users is expressed by
d(c)
k
=
U−1

u=0
d(c)
u,k =
U−1

u=0
cudu,k = Cdk,
(5.108)
which is transmitted by OFDM through
xk = TFH
Md(c)
k
= TFH
MCdk = T
U−1

u=0
FH
Mcudu,k
= T
U−1

u=0
c( f )
u du,k =TC( f )dk,
(5.109)
and where the number of orthogonal codes (users) is U ≤M.
The transmission mode with T = Tcp is typically called multicarrier CDMA (MC-CDMA) [95,251],
whose implementation principle is shown in Figure 5.15.
Note that the last line in (5.109) highlights that MC-CDMA corresponds to a CP-CDMA system,
which transmits the inverse spectra c( f )
u
= FH
Mcu of the original codes cu, plus a CP to handle IBI
and to guarantee easy frequency-domain equalization. This way, MC-CDMA grants both easy PSE and
multipath diversity exploitation, since each data symbol is transmitted (spread) by the code matrix C
on several (potentially all) subcarriers. Indeed, the frequency-domain spreading operation expressed
FIGURE 5.15
An MC-CDMA system.

226
CHAPTER 5 OFDM and Multicarrier Signal Processing
in (5.109) is performed on all the M subcarriers, and therefore tries to achieve a diversity gain of M.
However, the frequency-domain channel coefﬁcients on the M subcarriers are correlated, because they
are obtained by DFT of L + 1 nonzero time-domain channel coefﬁcients in (5.63), with L + 1 ≪M.
Therefore, the maximum achievable diversity gain is only L + 1. For this reason, similarly to GLP in
(5.103), multicarrier CDMA systems can employ an alternative frequency-domain spreading operation
that uses only L +1 subcarriers out of M. In order to minimize the correlation, the L +1 subcarriers are
chosen as maximally separated, i.e., equispaced. Therefore, using spreading sequences of length L +1,
we can accommodate up to L + 1 users into the L + 1 subcarriers. If we assume that M/(L + 1) is
integer, there are M/(L +1) different groups of equispaced subcarriers, and therefore M/(L +1) groups
of L + 1 users can be accommodated. This scheme is usually known as group-orthogonal MC-CDMA
[42], because each group behaves as a reduced-dimension MC-CDMA systems, while the different
groups are orthogonal in the frequency-domain, similarly to OFDMA.
The above mentioned group approach is also suitable for multirate transmissions. For instance, the
L + 1 subcarriers of a given group, and all the L + 1 associated spreading codes, can be assigned to the
same user. In this case, only M/(L +1) users can be accommodated, but the data rate of each user can be
L + 1 times higher than conventional MC-CDMA. This multirate scheme is basically a combination of
linear precoding and OFDMA, since users, which are orthogonal in the frequency-domain, can apply a
linear precoder onto the L+1 assigned subcarriers, as detailed in Section 2.05.7. Alternatively, multirate
transmissions may be obtained by multicode MC-CDMA, as detailed in [187].
Another possibility to mix CDMA with OFDM is to apply the CDMA spreading principle to each of
the M independent SC transmissions embedded in OFDM, as shown in Figure 5.16. Indeed, by (5.105),
each SC data ﬂow can accommodate U ≤G different users by expressing
x(m)(t) =
U−1

u=0
x(m)
u
(t) =
U−1

u=0
+∞

k=−∞
d(u)
m,kc(u)
m (t −kT ),
(5.110)
FIGURE 5.16
MC-DS-CDMA and MT-CDMA systems.

2.05.10 Multiuser multicarrier systems
227
where, ignoring the potential presence of time guards to prevent IBI, the pulse shaper c(u)
m (t) associated to
each data is spread by the chip sequence

cu,g

g=0,...,G−1 through the signal G−1
g=0 cu,grectTc(t −gTc),
as expressed by
c(u)
m (t)rectTG(t −TG/2) = e j2π fmt
G−1

g=0
cu,grectTc(t −gTc −Tc/2),
(5.111)
where the code duration is TG = GTc. The time spreading of each waveform in (5.111) induces a
spectrum
C(u)
m ( f ) = sinc

πTc( f −fm)
	 G−1

g=0
cu,ge−i2π( f −fm)gTc,
(5.112)
and an overall spectrum support on the mth subcarrier expressed by
X(m)
k
( f ) = e−j2π f kT
U−1

u=0
d(u)
m,kC(u)
m ( f ),
(5.113)
which is centered on fm and has equispaced zeros on the frequency grid { fz = fm ± i/Tc}i∈N+.
Thus, similarly to classical OFDM, the spectra on different subcarriers will preserve orthogonality
if the subcarriers are chosen such that the subcarrier separations are multiple of 1/Tc, e.g., when
fm = m/Tc = mG/TG. This transmission mode is typically called multicarrier direct-sequence CDMA
(MC-DS-CDMA) [95]: this corresponds to an OFDM system that transmits a chip of duration Tc in
each OFDM block, i.e., in MC-DS-CDMA the OFDM block duration is Tc, and the symbol duration
is GTc (see Figure 5.16). Thus, assuming a ﬁxed number M of subcarriers, if we want to compare
MC-DS-CDMA (with block duration Tc) with respect to single-user OFDM (with block duration Tu),
two cases are of interest. First, if each MC-DS-CDMA user wants to preserve the same data rate with
respect to single-user OFDM systems, the spreading operation imposes a shorter OFDM block duration
Tc = Tu/G = MTs/G, and, consequently, a bandwidth overexpansion of a factor G. Alternatively, if
each MC-DS-CDMA user wants to preserve the same bandwidth with respect to single-user OFDM
systems, the spreading operation leads to a data rate reduction of a factor 1/G, which is a direct
consequence of the OFDM block duration Tc = Tu and of the increased symbol duration GTc = GTu.
However, it should be emphasized that CDMA systems allows for a maximum of G orthogonal users:
therefore, in the second case, the aggregate data rate of the G MC-DS-CDMA users would be equal to
that of single-user OFDM systems.
Moreover, in MC-DS-CDMA, in order to prevent IBI (i.e., inter-chip interference) and grant easy
equalization in LTI channels, CP or ZP has to be inserted between each OFDM block (i.e., between
each chip). In a vector-matrix notation, this corresponds to a coded (row) vector for each subcarrier
expressed by
s(u)T
m,k = d(u)
m,kcT
u ,
(5.114)
which leads to an overall spread data-matrix for each user
D(u)
k
=

d(u)
0,k, . . . , d(u)
G−1,k

=

s(u)
0,k, . . . , s(u)
M−1,k
T
= diag

s(u)
k
 
1M ⊗cT
u

,
(5.115)

228
CHAPTER 5 OFDM and Multicarrier Signal Processing
whose columns are sequentially transmitted by OFDM. In (5.115), ⊗stands for the Kronecker product.
The vector transmitted during each chip period is expressed by
d(u)
g,k = cu,gd(u)
k
(5.116)
and the overall transmitted OFDM chip, i.e., OFDM block, is
U−1

u=0
TFH
Mcu,gd(u)
k
=TFH
M
U−1

u=0
cu,gd(u)
k
= TFH
MDk

CT 
:,g ,
(5.117)
where Dk =

d(0)
k , . . . , d(G−1)
k

is the column-wise data matrix containing the data vector associated
to each user, and

CT 
:,g is the column vector containing the gth chips of all the users, i.e., the gth row
of the code matrix C. Equation (5.117) highlights that MC-DS-CDMA grants the easy separation (and
equalization) of the mth ﬂow on the M subcarriers by preserving the subcarrier orthogonality through a
frequency-selective channel, and the separation among different users by orthogonal design of the code
matrix, which requests to collect all the G chips associated with a single data matrix Dk.
Alternatively, as also shown in Figure 5.16, it is possible to renounce to easy equalization and
separation of subcarriers by resorting to the so-called multi-tone CDMA (MT-CDMA) [95]. This system
corresponds to choose subcarriers that are not orthogonal on the chip duration, and which would be
orthogonal (in the absence of spreading) on the symbol duration TG = GTc, that is, fm = m/TG =
m/(GTc). Thus, the spectra in (5.112), for different m, are not centered on the zeros of the other spectra
as shown in Figure 5.17.
This way, ICI would emerge at the receiver side, independently of the presence or absence of CP or
ZP. For this reason, MT-CDMA systems typically avoid the use of a CP [244]. MT-CDMA corresponds
to an OFDM system, without CP, on the time interval TG, followed by a chip spreading (bandwidth
expansion) to distinguish different users [244]. This signal could be generated by a classical OFDM
modulator at the symbol rate, followed by G up-sampling to describe the signal at the chip-rate and by
the spreading operation, which is just a chip-by chip multiplication. Due to the fact that a time-domain
up-sampling can be easily generated by DFT processing, through a zero-ﬁlled spectrum [173], a possible
matrix representation for the overall data vector transmitted by the uth user is
diag(1M ⊗cu)FH
GM
⎡
⎢⎣
d(u)
k,up
0(G−1)M
d(u)
k,low
⎤
⎥⎦= diag(1M ⊗cu)˜FH
GMd(u)
k ,
(5.118)
where ˜FGM is a selection of the DFT matrix FGM, containing its ﬁrst and last M/2 rows, and d(u)
k,up and
d(u)
k,low are two vectors of size M/2 obtained by splitting d(u)
k
into two parts.
2.05.10.1 Equalization and data recovery for multiuser multicarrier systems
In multicarrier multiuser systems, different data recovery algorithms may be employed, depending on
the type of system (e.g., MC-CDMA, MC-DS-CDMA, or MT-CDMA), on the type of communication

2.05.10 Multiuser multicarrier systems
229
(a)
(b)
FIGURE 5.17
Spectrum of (a) MC-DS-CDMA fm = m/Tc = mG/TG, (b) MT-CDMA fm = m/TG = m/(GTc).
(e.g., downlink or uplink), and on the type of channel (e.g., linear or nonlinear, time invariant or
time varying, with or without multipath, and so on). In this work, as an example, we consider MC-
CDMA downlink communications subject to time-invariant multipath channels. We also assume channel
knowledge at the receiver side. In this case, after CP removal and FFT processing, by means of (5.65)
and (5.108) the frequency-domain received vector can be expressed as
y( f )
k
= diag(h f )d(c)
k
+ w( f )
k
= diag(h f )Cdk + w( f )
k
,
(5.119)
where y( f )
k
represents the kth received block, with size equal to the number of subcarriers M, h f is
the frequency-domain channel, C is the code matrix deﬁned after (5.106), with size M × G, where G
is the number of users, dk is the transmitted data vector of all the G users, and w( f )
k
is the AWGN. Note
the similarity of (5.119) with (5.94): indeed, when the number of users is G = M, MC-CDMA becomes
a non-redundant LP-OFDM system with  = C, and therefore the detection techniques suitable for
LP-OFDM can be employed (see Figure 5.14). On the other hand, when G < M, in general the user of
interest does not know which codes have been assigned to the other users, and hence the full knowledge
of C cannot be exploited. Similarly to the suboptimal equalization/detection schemes of ZP-OFDM and
LP-OFDM, summarized by (5.90) and (5.99), linear detection schemes can be used also for MC-CDMA,
to produce a soft estimate
˜dk = EHCy( f )
k
,
(5.120)
and where EHC is obtained either by (5.91) or (5.92), by substituting HC = diag(h f )C to H.

230
CHAPTER 5 OFDM and Multicarrier Signal Processing
Usually, for MC-CDMA downlink channels, the uth user is interested only to its transmitted data,
and consequently performs the data estimation by means of a linear detector that employs only the code
cu [95]. In this case, when the uth user has no knowledge about the codes of the other users, the joint
equalization/despreading in (5.120) can be split in two, as expressed by
ˆdu,k = cH
u Ehy( f )
k
= cH
u Ehdiag(h f )Cdk + cH
u Ehw( f )
k
,
(5.121)
where Eh is a diagonal matrix that depends on the frequency-domain channel. As clearly expressed by
(5.121), Eh performs the equalization task, and cu performs the despreading operation.
For the matrix Eh, different choices are possible [95]. The choice
E(orc)
h
= (diag(h f ))−1,
(5.122)
known as orthogonal restoring combining (ORC), perfectly compensates for the multipath channel
h f in (5.119) and restores the orthogonality between users. Therefore, ORC eliminates the inter-user
interference, also known as multiple-access interference (MAI). However, the drawback of this ZF
approach is a noise enhancement that arises when one or more elements of h f have a low modulus:
indeed, in this case, the corresponding elements of E(orc)
h
have a high modulus, and hence the noise term
w( f )
k
in (5.121) is enhanced. To reduce the noise enhancement, some subcarriers may be excluded from
the detection: this ORC variant is known as controlled equalization [95]. An alternative choice for E is
the maximum ratio combining (MRC), as expressed by
E(mrc)
h
= (diag(h f ))H.
(5.123)
By inserting (5.123) into (5.121), it is clear that the MRC approach weights the subcarriers proportionally
to their channel amplitudes, and compensate for the different phase offsets of the frequency-domain
channel. Therefore, the MRC approach is a sort of frequency-domain matched ﬁlter, which maximizes
the SNR when there is only a single active user. However, in the presence of multiple users, the amount
of MAI may be signiﬁcant [95]. A third approach, known as equal-gain combining (EGC), tries to avoid
both excessive MAI and signiﬁcant noise boosting, by means of
E(egc)
h
=

diag

e j∡h f 		H,
(5.124)
where e j∡h f is the vector that contains the phases of the elements of h f . In general, when there are many
active users, EGC provides better performance than ORC and MRC [95]. Another possible approach
is the MMSE combining (MMSEC), which also tries to balance residual MAI and noise at the detector
output. For MMSEC, the matrix Eh in (5.121) is expressed by [95,117]
E(mmse)
h
= (diag(h f ))H 
Gdiag(h f )(diag(h f ))H + σ 2
wIM
−1
.
(5.125)
Note that the MMSEC expression (5.125) requires also the knowledge of the number of active users
G and AWGN power σ 2
w. Speciﬁcally, at high SNR, σ 2
w in (5.125) becomes negligible and therefore

2.05.10 Multiuser multicarrier systems
231
MMSEC tends to ORC (5.122), thereby minimizing the MAI at the detector output. From (5.125), it is
also clear that noise enhancement is avoided, because, when some elements of h f have a low modulus,
Eh does not contain elements with high modulus. For these reasons, usually the MMSEC detector
outperforms ORC, MRC, and also EGC [95].
If the spreading codes of the other users are known to the user of interest, many other detection
strategies are possible [95], including those used for LP-OFDM. For instance, (soft or hard) interference
cancellation approaches, or quasi-ML detection techniques, may be pursued. However, we remind that
the knowledge of the spreading codes of all users is more reasonable in uplink rather than in downlink.
Indeed, in uplink communications, the base station has to detect the signals of all users, and therefore
may perform a joint detection of the multiuser signals.
For MC-DS-CDMA, the detection strategies are usually different than for MC-CDMA. Speciﬁ-
cally, in time-invariant frequency-selective channels, because of the time-domain spreading of MC-DS-
CDMA, the use of orthogonal codes preserves user orthogonality. Hence, the despreading operation is
performed in the time-domain, as in DS-CDMA [191] whereas the channel compensation is performed
in the frequency-domain, as in OFDM. However, because of the absence of frequency-domain spread-
ing, pure MC-DS-CDMA does not collect frequency diversity, and therefore presents a performance loss
1 2
4
8
12
16
24
32
10
-6
10
-5
10
-4
10
-3
10
-2
10
-1
10
0
Number of users
BER
 
 
OFDMA
DS-CDMA (rake)
DS-CDMA with CP (FDE)
MC-CDMA (MMSEC)
MC-DS-CDMA
FIGURE 5.18
Performance comparison among OFDMA, DS-CDMA, MC-CDMA, and MC-DS-CDMA (Uncoded BER, QPSK,
Eb/N0 = 6 dB, M = 32, G = 32 and Walsh-Hadamard spreading codes for both MC-CDMA and MC-DS-
CDMA, G = 31 and Gold spreading codes for DS-CDMA, L = 4, multipath channel with uniform power-delay
proﬁle).

232
CHAPTER 5 OFDM and Multicarrier Signal Processing
with respect to MC-CDMA (see Figure 5.18). To avoid this performance loss, MC-DS-CDMA must
incorporate additional features, such as in [127,225], and [259]. On the other hand, MT-CDMA suffers
from ICI, and therefore also presents a performance loss with respect to MC-CDMA, especially when
the number of users is high (see [95]).
2.05.10.2 A note on CDMA versus MC communications
It has been clariﬁed in Section 2.05.2, that according to the orthogonal design in (5.21) OFDM can be
seen as a special case of a CDMA system, where each code is an exponential function as in (5.23). This
is indeed the principle underlying OFDMA, where each (set of) carrier(s) is assigned to a speciﬁc user.
Differently, in a classical short-sequence CDMA system the pulse assigned to each user is expressed by
pm(t) =
G

g=1
cm,grectTc

t −gTc −Tc/2
	
(5.126)
and the orthogonality condition among two different users in (5.21) simply becomes

 +∞
−∞
p j(t)p∗
m(t)dt = Tc
G−1

g=0
c j,gc∗
m,g = 0,
(5.127)
which is guaranteed if the two user codes c j and cm are orthogonal vectors, such as the Walsh-Hadamard
codes [247]. However, the exponential codes used by OFDM and MC, are the only codes that preserve
orthogonality through a frequency-selective channel, because they are eigenvectors of linear time-
invariant systems, as explained in detail in Section 2.05.3.
Thus, a CDMA system in frequency-selective channels typically suffers signiﬁcant BER performance
degradation with respect to a MC system, because of the lost of codes orthogonality, i.e., the multiuser
interference (MUI) that is introduced. This MUI can be contrasted by employing multiuser receivers
[247] that anyway request the knowledge of the codes of all the users, which may be impractical in the
downlink of cellular systems. Moreover, CDMA systems are particularly sensitive to MUI introduced
by asynchronous reception (delay) of the users’ codes, as it happens in the uplink of cellular systems.
This is the reason why typically CDMA systems employ non-orthogonal codes (which would not be
preserved anyway) such as the Gold codes, which conversely are designed in order to minimize the
MUI in the presence of asynchronism among users [247].
The other difference, and probably the most important one, among classical CDMA systems and MC
system is the insertion of the CP [or ZP, or a known-symbol padding (KP)], which greatly simpliﬁes
channels estimation and equalization in the frequency-domain, as deeply explained in the previous
sections. Actually, it has been shown that, likewise in OFDM, also CP-SC systems can effectively
diagonalize the channel in the frequency-domain. In this view, it is further possible to observe in Figure
5.12 that a classical SC-CDMA system equipped with a CP, is equivalent to a LP-OFDM system that
employs  = FMC.
Thus, for CP-CDMA the signal received in the frequency-domain would be
y( f )
k
= diag(h f )FMCdk + w( f )
k
,
(5.128)

2.05.11 OFDM and multicarrier communications in nonlinear systems
233
and a simple (diagonal) frequency-domain equalization is possible by means of the ORC or MMSE
principles in (5.122) and (5.125), respectively. Note that, for CP-CDMA the use of orthogonal codes
could be preferred: indeed, the possible different delays between different users in a cellular uplink
can be handled by a proper design of the CP (or ZP) duration, i.e., by granting that the CP length is
greater than the sum of the maximum channel length with the maximum user delay. Thus, if the codes
are orthonormal, after the simple diagonal equalization by Eh, the data belonging to user m can be
recovered by a simple per-user decision on the soft estimate
˜dm,k = cH
m FH
MEhy( f )
k
,
(5.129)
whose computational complexity is dominated by the IDFT processing, i.e., is of the order of M log M.
For instance, in the case of ORC equalization (5.129) becomes
˜dm,k = cH
m FH
Mdiag

h f
	−1 y( f )
k
= cH
m Cdk + cH
m FH
Mdiag

h f
	−1 w( f )
k
= dm,k + em,k.
(5.130)
Anyway, the error em,k may suffer noise enhancement introduced by diag

h f
	−1 when the values of
h f are close to zero: consequently Eh(mmse) in (5.125) is in general a preferable choice for the equalizer.
2.05.11 OFDM and multicarrier communications in nonlinear systems
For the reader convenience, we report again the analytical expression (5.25) of the OFDM signal xk(t)
transmitted during the useful period Tu of the kth symbol
xk(t) =
1
√Tu
M−1

m=0
dm,ke j2π m
Tu trectTu(t −(k + 1/2)Tu),
(5.131)
which reveals that the transmitted signal is characterized by a highly variable envelope Rk(t) = |xk(t)|,
because at any different time instant t ∈

kTu,

k + 1
	
Tu

the M exponentials in (5.131) may add
in phase or out-of-phase, depending on the phases of the transmitted data symbols {dm,k}m=0,...,M−1.
Therefore, the OFDM signal is particularly sensitive to any baseband nonlinear device, such as A/D and
D/A converters with limited dynamic [63,171], and RF distortions, such those introduced by nonlinear
(NL) high power ampliﬁers (HPA). Generally, also RF nonlinearities without memory can be summa-
rized by their equivalent (possibly complex) BB nonlinearity [30]. For instance, a bandpass NL HPA,
whose input is
x(in)
RF (t) = R(t) cos

2π fot + θ(t)
	
,
has an output that can be expressed by
x(out)
RF (t) = A

R(t)

cos

2π fot + θ(t) + 

R(t)
	
,
where A[·] and [·] are the so called AM/AM and AM/PM distortion functions [30,118]. Thus, the
BB equivalent of the OFDM signal xk(t) = Rk(t)e jθk(t) that passes through a (band-pass) NL HPA is
expressed by
x(out)
k
(t) = fNL

xk(t)

= G

Rk(t)

e jθk(t) = A

Rk(t)

e j



Rk(t)

+θk(t)

,
(5.132)

234
CHAPTER 5 OFDM and Multicarrier Signal Processing
which highlights how the NL function is generally complex (e.g., when AM/PM is present), and that the
NL function operates on the OFDM signal envelope Rk(t). Alternatively, if the nonlinearity is induced
by an A/D conversion stage, it generally operates separately on the real and imaginary components of
the OFDM BB signal, as expressed by
x(out)
k
(t) = fNL

xk(t)

= QNL

Re{xk(t)}

+ j QNL

Im{xk(t)}

,
(5.133)
where QNL[·] is a real-valued NL function representing the A/D input-output characteristic.
Whichever is the situation, the overall NL distortion [ fNL[·] in (5.132) or QNL[·] in (5.133)] induces
the intermodulation [65] of each subcarrier in (5.131) with the others, thus producing new spectral
components that are partially superimposed to the OFDM tones, and partially spread out on the adjacent
bands. The former intermodulation products induce a sort of ICI and, consequently, SER performance
degradation, while the out-of-band intermodulation products are a source of potential interference for
users or services on the adjacent bands.
In order to quantify the interference power generated by NL distortions, and their effect on the
SER performance, it would be possible to resort to the classical literature for the characterization of the
intermodulation products of FDM systems in satellite transponders [23,80,216]. However, an alternative
and quite accurate analysis is possible when the number M of the OFDM subcarriers is sufﬁciently high,
to make the OFDM signal well modeled as a complex Gaussian process, by central limit Theorem (CLT)
arguments [15,64,171]. In this case, it is possible to exploit the Bussgang Theorem [177] and its complex
extensions in [64,158] to express the NL outputs as a scaled replica of the input plus an uncorrelated
distortion term d(NL)
k
(t), as expressed in
x(out)
k
(t) = α(t)x(in)
k
(t) + d(NL)
k
(t),
(5.134)
where the scaling coefﬁcient α(t) is expressed by
α(t) =
E

x(out)
k
(t)

x(in)
k
(t)
∗
E
)***x(in)
k
(t)
***
2+
.
(5.135)
Actually, under fairly mild conditions [64], which hold true for classical OFDM, the coefﬁcient α(t) is
constant, as expressed by
α(t) ≃αo = E

fNL

x(in)
k
(0)
 
x(in)
k
(0)
∗
/2σ 2
x ,
(5.136)
and its computation in closed form is available for a wide class of NL distorting function, either expressed
by (5.132) or (5.133) (see [15,64,171], and the references therein).
The uncorrelatedness of the distortion d(NL)
k
(t) with the OFDM input x(in)
k
(t) lets to express the NL
output autocorrelation function as
R(out)
xx (τ) = |αo|2 R(in)
xx (τ) + Rdd(τ),
(5.137)

2.05.11 OFDM and multicarrier communications in nonlinear systems
235
where Rdd(τ) = E

f ∗
NL

x(in)
k
(t)

fNL

x(in)
k
(t + τ)

is the autocorrelation function of the NL distortion.
The Gaussian approximation of the OFDM signal x(in)
k
(t) lets to compute Rdd(τ) in closed form for a
wide set of NL distortions. The general result states that [65]
R(out)
xx (τ) =
∞

n=0
cn

R(in)
xx (τ)/2σ 2
x
2n+1
= c0
2σ 2x
R(in)
xx (τ) +
∞

n=1
cn

R(in)
xx (τ)/2σ 2
x
2n+1
,
(5.138)
where |α0|2 = c0/2σ 2
x , the terms of the series for n ≥1 represent the expansion of Rdd(τ), and the
coefﬁcients cn = f

2σ 2
x , fNL[·]
	
depend on both the OFDM input power 2σ 2
x and the NL shape fNL[·].
Thus, the power spectral density (PSD) S(out)
xx
( f ) = F

R(out)
xx (τ)

of the NL output is expressed by
S(out)
xx
( f ) = |α0|2 S(in)
xx ( f ) + Sdd( f ) = c0
2σ 2x
S(in)
xx ( f ) +
∞

n=1
cn

2σ 2x
	2n+1
⎡
⎣S(in)
xx ( f ) ∗· · · ∗
, -. /
2n
S(in)
xx ( f )
⎤
⎦,
(5.139)
where S(in)
xx ( f ) = F

R(in)
xx (τ)

is the input PSD, and ∗· · · ∗
, -. /
2n
stands for 2n successive convolution
integrals of S(in)
xx ( f ) by itself, which induces the NL distortion PSD.
When the NL distortion fNL[r] is expressed by (5.132), the coefﬁcients {cn} are generally expressed
by [15,30]
cn =
1
2σ 2x
1
n + 1
*****

 ∞
0
fNL[r] r2
σ 2x
e
−r2
2σ2x L(1)
n
 r2
2σ 2x

dr
*****
2
,
(5.140)
where L(1)
n (x) is the Laguerre polynomial of the ﬁrst type and order n [2], and (5.140) leads to closed
form expressions for a wide class on NL distorting functions (see [15,30]). Similar results are also
available for NL distortion fNL[r] expressed by (5.133) (see, [64,65,171,186] and references therein).
For instance, if the NL in (5.132) clips the signal envelope only when the input envelope overpasses
a given threshold A (i.e., the NL is an ideally predistorted ampliﬁer [15]), as expressed by
x(out)
k
(t) = fNL

xk(t)

=
0
GhpaRk(t)e jθk(t), 0 ≤Rk(t) < A,
GhpaAe jθk(t),
Rk(t) ≥A,
(5.141)
where Ghpa is the gain of the predistorted ampliﬁer in the linear region, then
cn = G2
hpa
2σ 2
x
n!

n + 1
	
!

2n
	
!
n!
√
2π
2n+1
A
σx
+
∞

k=0

n + k + 1
	
!
k!

k + 2
	
!

−1
	k+1

2k + 3
	
 A2
2σ 2x
k+22
,
n = 0, 1, . . . , ∞.
(5.142)

236
CHAPTER 5 OFDM and Multicarrier Signal Processing
By some manipulations, expression (5.142) can be further simpliﬁed to
c0 = G2
hpaσ 2
x

1 −e
−A2
2σ2x + 1
2
π
2
A
σx
erfc

A
√
2σx
2
,
c1 = G2
hpaσ 2
x

1
2
A2
2σ 2x
e
−A2
2σ2x + 1
4
π
2
A
σx
erfc

A
√
2σx
2
,
cn =
G2
hpa2σ 2
x
n!

n + 1
	
!
'
2n
	
!
22nn! −
n−2

i=0
δi,n
 A2
2σ 2x
i+1(
A2
2σ 2x
e
−A2
2σ2x +

2n
	
!
22n+1n!
π
2
A
σx
erfc

A
√
2σx
2
,
n = 2, . . . , ∞,
(5.143)
which avoids the inﬁnite series, and where δi,n are opportune coefﬁcients that can be computed
recursively [15].
Otherwise, if fNL[·] does not amplify the signal (e.g., Ghpa = 1) and separately clips to A the real
and imaginary components of the OFDM signal by means of (5.133), than the coefﬁcients are expressed
by [215]
c0 = 2σ 2
x

erf

A
√
2σx
2
,
cn = 1
π
2σ 2
x
4n−1 
2n + 1
	
! H2
2n−1

A
√
2σx

e
−A2
σ2x ,
n ≥1,
(5.144)
where Hn(x) is the Hermite polynomial of order n [2].
In the following, we report the normalized PSD for the output of an HPA, that has been perfectly
predistorted [118] up to its saturation input power, whose residual AM/AM distortion is summarized by
the envelope clipper in (5.141), and the coefﬁcients {cn} in (5.139) are expressed by (5.142) or (5.143).
Note that Figure 5.19 has been obtained using some simplifying assumptions: (a) the input PSD S(in)
xx ( f )
is approximated by a rectangular shape, which is acceptable for OFDM modulations; (b) the bandwidth
has been normalized with respect to the subcarrier separation; (c) there is no CP; (d) the input signal is
Gaussian distributed, as it happens by CLT when OFDM employs a high number M of carriers. Further
results on the performance of practical (i.e., not ideal) HPA predistorters can be found in [6,16,67,114].
The PSD curves in Figure 5.19 are drawn for different ratios among the average input power 2σ 2
x and
the input saturation power A2, as captured by the ampliﬁer input power back-off (ibo), deﬁned by5
ibo = A2/(2σ 2
x ). It can be noted that a higher ibo corresponds to a lower distortion and, consequently,
alowerintermodulationspectralregrowth.However,aloweriboalsoinducesalowerHPAoutputpower
and, consequently, a lower coverage and BER performance degradation. In order to quantify the average
5Note that, in general, the coefﬁcients {cn} in (5.140) depends on ibo = A2/(2σ 2
x ), as conﬁrmed by the speciﬁc cases of
(5.142), (5.143), and (5.144).

2.05.11 OFDM and multicarrier communications in nonlinear systems
237
0
20
40
60
80
100
120
-60
-50
-40
-30
-20
-10
0
Baseband PSD (normalized)
Subcarrier index (first half)
Saleh Amplifier OFDM-16QAM
 
 
Linear
obo = 22.2 dB
obo = 20.3 dB
obo = 18.4 dB
obo = 16.5 dB
obo = 14.8 dB
obo = 13.1 dB
obo = 11.5 dB
obo = 10.2 dB
obo = 9.03 dB
obo = 8.14 dB
0
20
40
60
80
100
120
-60
-50
-40
-30
-20
-10
0
Baseband PSD (normalized)
Subcarrier index (first half)
Clipping Predist. OFDM-16QAM
 
 
Linear
obo = 8.01 dB
obo = 7.03 dB
obo = 6.08 dB
obo = 5.19 dB
obo = 4.37 dB
obo = 3.64 dB
obo =    3 dB
obo = 2.45 dB
obo = 1.99 dB
obo = 1.62 dB
(a)
(b)
FIGURE 5.19
PSD at the output of (a) Saleh-ampliﬁer and (b) Ideal-predistorter for different obos.
output power, it is useful to deﬁne the output power back-off (obo) that, by CLT arguments [15], is
accurately approximated by
obo = G2
hpaA2/E

|x(out)
k
(t)|2
≈ibo/

1 −e−ibo	
.
(5.145)
In order to quantify the performance degradation induced by the HPA NL distortion, it is useful to
exploit (5.134)–(5.136), which let to express the signal received through an LTI frequency-selective
channel h(t), during the kth block, by
yk(t) = x(out)
k
(t) ∗h(t) + wk(t) = αox(in)
k
(t) ∗h(t) + d(NL)
k
(t) ∗h(t) + wk(t).
(5.146)
The NL distortion noise d(NL)
k
(t) (which has a CP-based structure like x(in)
k
(t)), is ﬁrst ﬁltered by
the propagation channel and successively adds-up with the thermal receiver noise wk(t). OFDM data
modulation and detection are based on the signal spectrum X(in)
k
( f ) and, by means of (5.45)–(5.47),
after CP removal and DFT processing, the data received on the mth subcarrier is expressed by
Ym,k = α0Hm Xm,k + Hm D(NL)
m,k + Wm,k,
m = 0, . . . , M −1.
(5.147)
The term D(NL)
m,k = M−1
n=0 d(NL)
k
(nTs)e−j 2π
M mn represents the NL distortion noise spectrum on the mth
subcarrier. Note that, although d(NL)
k
(t) is not Gaussian distributed, if the number of subcarriers is
sufﬁciently high, by CLT arguments Dm,k is almost Gaussian distributed. Actually, it is also necessary
that d(NL)
k
(nTs) ̸= 0, which means that the number of distorted samples in a single OFDM block should
be high enough, as it happens for instance in (5.141) when the ibo is not too high, or equivalently,
when the ibo is signiﬁcantly different from the obo.

238
CHAPTER 5 OFDM and Multicarrier Signal Processing
Under this assumption, conditionally on a ﬁxed channel realization Hm, the data Xm,k transmitted on
themthsubcarrierduringthekthblockisimpairedbyanoveralladditivenoise W ′
m,k = Hm D(NL)
m,k +Wm,k,
which is Gaussian distributed, with power σ 2
m,k =
**Hm,k
**2 E

|D(NL)
m,k |2
+σ 2
w, similarly to (5.81). Thus,
the optimum detector employs a PSE and, similarly to (5.49) the ML detector is expressed by
ˆdm,k = arg min
d∈D

|d −Ym,k/(αoHm)|

,
m = 0, . . . , M −1.
(5.148)
The BER performance associated with (5.148), conditioned on a ﬁxed channel Hm, is the classical one
under AWGN assumption [183], as expressed by
SERm|Hm = P{ ˆdk,m ̸= dd,m|Hm} = αQ Q

βQ SNRm|Hm
	
,
(5.149)
where SNRm|Hm is the conditional SNR on the mth subcarrier, as expressed by
SNRm|Hm = |α0|2|Hm|2σ 2
d
σ 2
m,k
,
(5.150)
and αQ and βQ are two constellation-dependent parameters. By observing that the power of the distortion
noise on the mth subcarrier is represented by the sample of the NL distortion PSD Sdd( f ) on the mth
subcarrier [15]
σ 2
m,k = |Hm|2 E

|D(NL)
m,k |2
+ σ 2
w = |Hm|2 Sdd

m/MTs
	
+ σ 2
w,
(5.151)
it is clear that SERm|Hm can be computed in closed form for several NL distortions by plugging in
SNRm|Hm the values of α0 and σ 2
m,k obtained by (5.139) and (5.140).
If the channel h(t) is not ﬁxed from block to block, but it (slowly and randomly) changes from block
to block, then the conditional SERm|Hm should be averaged on the SNRm|Hm statistic, which actually
depends on the pdf of |Hm| and, similarly to (5.83), is expressed by
SERm = P{ ˆdk,m ̸= dd,m} =

 +∞
0
αQ Q
'
βQ
|α0|2 |Hm|2 σ 2
d
Sdd

m/MTs
	 |Hm|2 + σ 2w
(
f|Hm|
|Hm|	
d |Hm| .
(5.152)
When the channel h(t) in (5.35) is zero-mean Gaussian distributed, then |Hm| in (5.63) is Rayleigh
distributed and the integral in (5.152) can be computed in closed form by resorting to generalized
hypergeometric functions, as detailed in [189].
Figure 5.20 shows the uncoded SER performance obtained by (5.152) for an OFDM system impaired
by a Saleh-Ampliﬁer [197] and the improvement in performance obtained by an ideal predistortion

2.05.11 OFDM and multicarrier communications in nonlinear systems
239
0
5
10
15
20
25
30
10-6
10-5
10-4
10-3
10-2
10-1
100
BER
Eb/No (dB)
Clipping Predist. OFDM-16QAM in AWGN
Linear
obo = 6.08 dB
obo = 5.19 dB
obo = 4.37 dB
obo = 3.64 dB
obo = 3.31 dB
obo =    3 dB
0
5
10
15
20
25
30
35
40
45
50
10-6
10-5
10-4
10-3
10-2
10-1
100
BER
Eb/No (dB)
Clipping Predist. OFDM-16QAM in Rayleigh fading
Linear
obo = 5.19 dB
obo = 3.64 dB
obo = 3.31 dB
obo =    3 dB
obo = 2.88 dB
obo =  2.8 dB
0
5
10
15
20
25
30
10-6
10-5
10-4
10-3
10-2
10-1
100
BER
Eb/No (dB)
Saleh Amplifier OFDM-16QAM in AWGN
Linear
obo = 15.6 dB
obo = 13.1 dB
obo = 12.3 dB
obo = 11.5 dB
obo = 10.8 dB
obo = 10.2 dB
0
5
10
15
20
25
30
35
40
45
50
10-6
10-5
10-4
10-3
10-2
10-1
100
BER
Eb/No (dB)
Saleh Amplifier OFDM-16QAM in Rayleigh fading
Linear
obo = 12.3 dB
obo = 11.5 dB
obo = 10.8 dB
obo = 10.5 dB
obo = 10.2 dB
obo = 9.87 dB
obo = 9.69 dB
(a)
(c)
(d)
(b)
FIGURE 5.20
SER of 16-QAM as a function of the obo, for (c,d) Saleh-ampliﬁer and (a,b) Ideal-predistortion in (a,c) AWGN
and (b,d) Rayleigh fading channels.
strategy (e.g., envelope clipping). As can be observed in Figure 5.20, the SER performance degrades for
decreasing obos. However low values of the obo is appealing for HPA efﬁciency and also for higher
transmitted power and, consequently, coverage. Actually, only a part of the higher transmitted power
would beneﬁt the useful signal: indeed, as highlighted by (5.134) and (5.147), part of it will increase α0
and another part will increase the NL distortion noise power σ 2
d . From the performance point of view
there exists an optimum obo that minimizes the SER. Closed form expressions for such an optimum
obo as a function of the speciﬁc data constellation, speciﬁc non-linearity, channel statistic and receiver
noise power σ 2
n are not easy to derive, and involve minimization of (5.152) with respect to obo. An
analogous approach deﬁnes another cost function to be minimized with respect to the obo, which is

240
CHAPTER 5 OFDM and Multicarrier Signal Processing
called total degradation (TD) [116], and it is deﬁned as
TDdB =

SNR(obo)
dB
(SERt) −SNR(lin)
dB

SERt
	
+ obodB.
(5.153)
The TD is the sum of two power penalty terms: one is the excess SNR for a given obo that is requested
at the receiver side (due to the insertion of distortion noise) to obtain the same target SER (SERt) that
is obtained in a linear scenario; the other, which is the obo, is the transmitter power penalty induced
by backing-off the maximum HPA output power.
Note that the minimum SER and minimum TD criteria are quite similar, but not mathematically
equivalent. Obviously also the TD-wise optimum obo depends on the channel statistic, on the speciﬁc
nonlinearity, and the data constellations that are used [14,17], as shown in Figure 5.21.
As a last comment it should be observed that Figure 5.21 shows the TD curves obtained by the SER
analysis in (5.152). This analysis is based on the assumption that D

NL
	
m,k in (5.147) is Gaussian distributed
and independent through the different subcarriers, which lead to the easy PSE and ML detection in
(5.148). Actually, the independence hypothesis is not really true due to the NL distortion introduced
on each time-domain sample distributes by DFT across all the subcarriers in the frequency-domain.
Thus, if the receiver has knowledge of the NL distortion fNL[·] that has distorted the signal, it should
exploit this information to end-up with a different (non-per subcarrier) ML detector of the transmitted
data dk. This fact has been investigated in [52,122,234] and lets to signiﬁcantly improve the SER in
a wide set of scenarios, by iterative data-aided receivers coupled with an ideal predistortion strategy.
Obviously, these smart joint-ML receivers will end-up with different (lower) SER and consequently a
different (lower) optimum obo.
0
5
10
15
20
0
5
10
15
20
OBO (dB)
Total Degradation (dB)
OFDM in AWGN  [BER Bound = 1.00e-003]
4-QAM (Id. Pred.)
16-QAM (Id. Pred.)
64-QAM (Id. Pred.)
4-QAM (Saleh Amp)
16-QAM (Saleh Amp)
64-QAM (Saleh Amp)
Linear
0
5
10
15
20
0
5
10
15
20
25
OBO (dB)
Total Degradation (dB)
OFDM in Rayleigh fading  [BER Bound = 1.00e-003]
4-QAM (Id. Pred.)
16-QAM (Id. Pred.)
64-QAM (Id. Pred.)
4-QAM (Saleh Amp)
16-QAM (Saleh Amp)
64-QAM (Saleh Amp)
Linear
(a)
(b)
FIGURE 5.21
Total degradation of OFDM systems for Saleh-ampliﬁer and Ideal-predistortion in (a) AWGN and (b) Rayleigh
fading channels.

2.05.11 OFDM and multicarrier communications in nonlinear systems
241
2.05.11.1 PAPR reduction methods
One of the main parameters that characterize the variability of the envelope of xk(t) in (5.131) is the
peak-to-average power ratio (PAPR) of the transmitted signal xk(t). The baseband PAPR is the ratio
between the maximum instantaneous peak power and the average power of the transmitted signal, as
expressed by [93]
PAPRxk(t) =
max
kTu≤t<(k+1)Tu
|xk(t)|2
1
Tu
 (k+1)Tu
kTu
|xk(t)|2 dt
.
(5.154)
For constant-envelope communications in the time domain, such as frequency modulation (FM), the
PAPR is equal to 1, which is the lowest possible value. However, since the OFDM signal in (5.131)
is obtained by summing many different subcarrier signals (up to M), its PAPR can be very high. For
OFDM with PSK, the PAPR can be as high as the number of subcarriers M, while the PAPR value
can be on the order of 3M for OFDM signals with QAM [112]. Therefore, signiﬁcant distortion may
be introduced by NL devices, such as HPA when the ibo is kept low for power-efﬁciency reasons. In
order to diminish the NL distortion, the PAPR could be reduced by means of suitable techniques that we
will brieﬂy describe in the following paragraphs. Since the PAPR is a random variable, PAPR reduction
techniques reduce the probability that the PAPR exceeds a ﬁxed threshold [93,112].
Instead of the continuous-time PAPR (5.154), usually PAPR reduction techniques target the reduction
of the discrete-time PAPR, expressed by
PAPRxk[n] =
max
kOs M≤n<(k+1)Os M
|xk[n]|2
E
|xk[n]|2
,
(5.155)
where xk[n] is a discrete-time version of xk(t) obtained by sampling at a rate Os M/Tu. In (5.155), Os
is the oversampling rate with respect to the OFDM chip-rate M/Tu, where chip-rate sampling means
that the number of samples for each OFDM block duration Tu (excluding the CP) is equal to the number
of subcarriers M. Indeed, when Os ≥4, the discrete-time PAPR (5.155) is a good approximation of
the continuous-time PAPR (5.154), and therefore the reduction of the discrete-time PAPR produces a
corresponding reduction of the continuous-time PAPR [112]. The discrete-time signal xk[n] in (5.155)
can be easily expressed by
xk[n] =
1
√Tu
Os M−1

m=0
d(a)
m,k e j2π
m
Os M n,
(5.156)
where d(a)
m,k is the augmented data sequence of the kth OFDM block, of size Os M, which is obtained
by zero padding the original data sequence dm,k of size M.
Among the PAPR reduction techniques, the simplest method is equivalent to an ideally predistorted
HPA, which behaves as a clipper of the envelope of the HPA input signal. As clearly explained by
(5.145), the clipping method reduces the PAPR as long as the obo is reduced. The main drawback of
the clipping method is the distortion introduced at low obo. As explained in the previous discussion, the
NL distortion caused by clipping falls both into the signal band, thereby worsening the SER performance,
and outside the signal band, thereby producing adjacent channel interference (ACI). The ACI can be

242
CHAPTER 5 OFDM and Multicarrier Signal Processing
reduced by ﬁltering, but ﬁltering may augment the PAPR. As a consequence, in order to reduce the
PAPR, usually a sequence of clipping and ﬁltering operations is performed [8,93,112].
A second way to reduce the PAPR is by means of coding techniques [113]. For instance, a convenient
codeword design may exclude those codewords that would increase the PAPR, thereby selecting only
those codewords that keep the PAPR below a given threshold. However, both the code design and the
decoding procedure have an inherent complexity that makes this option suitable only for low values of M
[93,112]. In addition, coding techniques also reduce the data rate for a ﬁxed bandwidth, or equivalently
require a bandwidth expansion for a ﬁxed data rate.
A third PAPR reduction approach is based on deliberate introduction of phase offsets into the
frequency-domain data symbols, before the IDFT. The underlying idea is to choose those phase offsets
that, together with the data-phases, avoids that (almost) all the subcarriers can add in phase during the
OFDM block duration. For instance, the technique known as partial transmit sequences (PTS) splits the
OFDM block into GPTS sub-blocks: then, each sub-block is multiplied by a phase offset to be chosen
from a given set of allowed phase offsets, where QPTS is the number of possible phase offsets. Basically,
the PTS technique evaluates the PAPR that would be obtained for all the (QPTS)GPTS−1 possible combi-
nations of phase offsets, and then selects the phase offsets that produce the lowest PAPR [93,112,169].
Alternatively, the technique known as selected mapping (SLM) multiplies the frequency-domain data
block, of size M, with USLM sequences of known phase offsets, where the length of each phase off-
set sequence is of course equal to M. Then, among the USLM sequences, SLM chooses the one that
yields the best PAPR reduction [26,93,112]. The main disadvantage of PTS and SLM techniques is the
computational complexity required for ﬁnding the best phase-offset sequence. Moreover, both PTS and
SLM have a data-rate loss caused by the transmission of side information, which is necessary at the
receiver in order to compensate for the phase offsets [93,112].
A fourth method for PAPR reduction exploits multiple interleavers [245]. Basically, before the IDFT,
the frequency-domain data symbols are scrambled in Uint different ways. Since the resulting signals,
after the IDFT, have different PAPR values, the transmitter can select the signal with lowest PAPR.
Similarly to PTS and SLM, a drawback of the interleaving approach is the data-rate loss caused by
the side information transmitted in order to inform the receiver about which deinterleaver should be
used [93].
A ﬁfth option for PAPR reduction is known as tone reservation (TR) [233]. In this case, some
predetermined subcarriers are not used for data symbols but are reserved for PAPR reduction purposes.
Basically, TR adds a data-dependent signal onto the reserved subcarriers, in order to minimize the
peak of the time-domain signal. The signal transmitted onto the reserved subcarriers is usually chosen
by convex optimization techniques [93]. Obviously, the subcarriers reserved for peak reduction are
orthogonal to the data subcarriers, and hence the TR method does not produce any distortion of the data
signal. From the receiver complexity viewpoint, the TR technique is one of the simplest methods, since
the receiver can simply ignore the subcarriers used for PAPR reduction. However, the TR technique
has two drawbacks: a data-rate loss caused by the reserved subcarriers, which are unused for the data
symbols, and a power loss caused by the signal transmitted on the reserved subcarriers [93,112].
Similarly to TR, the tone injection (TI) method adds a data-dependent signal onto some speciﬁc sub-
carriers in order to reduce the PAPR [233]. However, differently from TR, the TI method superimposes
the added signal onto the data subcarriers, in order to avoid the data-rate loss. To avoid signal distortion,
the constellation size is redundantly increased, so that multiple points of the constellation correspond

2.05.12 Estimation of LTI channels for OFDM
243
to the same information symbol: given the information symbol, the choice of the speciﬁc constellation
point is performed aiming at reducing the PAPR. Unfortunately, also the TI method suffers from power
loss, because of the increased constellation size [93]. A technique closely related to TI is called active
constellation extension (ACE) [129]. In this case, the PAPR is reduced by allowing some change of the
points of the constellations: the PAPR reduction is obtained by conveniently moving away the outer
points of the constellations, in a data-dependent and subcarrier-dependent way [93]. The ACE method
does not complicate the receiver, because the detection thresholds can remain the same. However, in
this case the detection will not be ML. Besides, the dynamic change of the outer constellation points
generates a power loss [93].
A further PAPR reduction method makes use of companding after the IDFT [112,249]. Similarly
to clipping, the companding method applies an instantaneous nonlinear function to the time-domain
OFDM signal. However, the companding technique smoothly modiﬁes the OFDM signal in order to
expand the weak amplitudes and compress the high amplitudes, which obviously reduces the PAPR.
The nonlinear function can be designed using the probability density function of OFDM signals, which
is approximately Gaussian, in order to target a predetermined pdf of the companded signal [112].
Using a monotone nonlinear function, the receiver can recover the original signal by applying inverse
companding. The main drawbacks of the companding approach are two: the ACI generated by the
nonlinear function, and the performance loss caused by inverse companding, which modiﬁes the noise
statistics.
The last PAPR reduction technique we are going to mention is frequency-domain linear precoding,
by means of (5.93). Actually, the PAPR-optimum non-redundant linear precoder is  = FM: indeed,
applying a DFT precoder before the IDFT, the aggregate effect of DFT and IDFT vanishes, so the
resulting signal is CP-SC, which has the minimum discrete PAPR (potentially imposed by not constant
modulus data) and much lower PAPR than the corresponding CP-OFDM [199]. Note moreover, that the
use of (5.101) would guarantee not only the minimum PAPR but also a diversity optimal design. Clearly,
this PAPR reduction method changes the type of transmission, which is not OFDM anymore. By the
way, precoding moves the complexity toward the receiver, which now needs both DFT and IDFT for
frequency-domain equalization (and more complex ML decoding for the diversity-optimum design).
2.05.12 Estimation of LTI channels for OFDM
From (5.64) and (5.78), it is clear that ML detection of OFDM signals requires an estimate of the
frequency-domain channel h f , or equivalently an estimate of the discrete-time CIR ht = M−1/2FH
Mh f .
Since the frequency-domain discrete-time channel h f is the sampled version of the channel frequency
response H( f ) of the continuous-time channel, channel estimation tries to reconstruct the continuous-
time channel on equispaced frequency locations. Intuitively, if the channel frequency response H( f )
is known for some speciﬁc frequencies, the whole function H( f ) could be reconstructed by means of
interpolation, as depicted in Figure 5.22.
For instance, let us assume that H( f ) is known for all the frequency locations separated by multiples
of Fs = SP f , where  f = 1/Tu = 1/(MTs) is the OFDM subcarrier separation, and SP is a positive
integer greater than 1. In this case, the whole H( f ) can be reconstructed without error, provided that
Fs is chosen in such a way to respect the Shannon sampling theorem. Speciﬁcally, in order to avoid

244
CHAPTER 5 OFDM and Multicarrier Signal Processing
f
s
P
F
S
f
=
Δ
m
m
H
H
channel        on the pilot positions
channel        on the data positions
H(f)
FIGURE 5.22
Pilot-based estimation of frequency-selective channels.
aliasing of the CIR in the time-lag domain, 1/Fs must be greater than or equal to (L + 1)Ts, which is
the maximum duration of the continuous-time CIR. This leads to
SP ≤
M
L + 1.
(5.157)
Despite blind methods are also possible [94], commonly channel estimation techniques make use of pilot
symbols for channel sounding and consequent interpolation [174]. The pilot symbols can be placed in
the time-domain, in the frequency-domain, or in both domains [174]. Usually, for packet transmissions,
such as WLAN, time-domain pilot symbols are preferred. For instance, a known pilot symbol can be
inserted at the beginning of the frame, and can be used also for synchronization purposes. In this case,
channel estimation can be performed using the same methods employed for single-carrier systems.
Therefore, herein we omit the mathematical description of channel estimation methods based on time-
domain pilot symbols. When the CIR is slowly time varying, in order to update or reﬁne the channel
estimate, the pilot symbol can be repeated after some OFDM data blocks. Alternatively to repetition
in the time-domain, few subcarriers can be reserved for the frequency-domain allocation of additional
pilot symbols, commonly known as pilot tones.
On the other hand, for continuous transmissions, frequency-domain or joint time-frequency-domain
pilot symbols are usually adopted. For instance, in DVB-T, there are two sets of pilot tones, denoted as
continuous pilot tones and scattered pilot tones [72]. The continuous pilot tones are dedicated subcarriers
used only for pilot symbols. The scattered pilot tones are frequency-domain pilot symbols whose
frequency location changes on a per OFDM-block basis, and therefore the pilot pattern is designed in
the time-frequency-domain.
Frequency-domain pilot symbols seem a natural choice for OFDM systems, because the subcarrier
orthogonality keeps the pilot tones separated from the data symbols after the LTI channel. In the
following, we describe some channel estimation methods assuming frequency-domain pilot tones.
The main assumptions are:
a. At the transmitter, P out of M subcarrier are reserved for pilot symbols, while the remaining
D = M −P are used for data symbols. We assume M = PSP, where the spacing SP between
adjacent pilot tones is integer. We also assume that the 0th subcarrier is a pilot subcarrier, and that

2.05.12 Estimation of LTI channels for OFDM
245
pilot tones are equispaced. We denote with ak the frequency-domain transmitted vector, obtained
by interlacing the pilot vector pk of size P with the data vector dk of size D. The number of pilot
symbols is greater than or equal to the number of discrete-time channel paths, that is, P ≥L + 1.
Pilot symbols are taken from a PSK constellation, i.e., |[pk]m| = 1.
b. The transmission format is CP-OFDM.
c. The multipath channel is assumed time invariant, at least for the duration of an OFDM block, and
characterized by Rayleigh fading.
d. At the receiver, the number of discrete-time channel paths L+1 is known, and the channel estimation
is performed using only a single OFDM block.
The transmitted vector, after IFFT processing and before CP insertion, similarly to (5.50) can be
expressed as
xk = FH
Mak,
(5.158)
while the received vector, after CP removal and FFT processing, similarly to (5.65) can be expressed as
y( f )
k
= diag(h f )ak + w( f )
k
= diag(ak)h f + w( f )
k
.
(5.159)
The receiver now selects the subvector of y( f )
k
that corresponds to the pilot positions by applying the
P × M pilot selection matrix SP = IP ⊗[1, 01×SP−1], as expressed by
y( f )
k,P = SPy( f )
k
= diag(pk)SPh f + SPw( f )
k
,
(5.160)
and then compensates for the pilot symbols, as expressed by
˜h( f )
k,P =

diag(pk)
	−1 y( f )
k,P = SPh f + ˜w( f )
k,P
=
√
MSPFMht + ˜w( f )
k,P,
(5.161)
where ˜w( f )
k,P =

diag(pk)
	−1 SPw( f )
k
isanAWGNterm.BydeﬁningF(1:L+1)
M
= FM

IL+10L+1×M−L−1
T
as the M × L + 1 matrix containing the ﬁrst L + 1 columns of FM, and observing that FMht =
F(1:L+1)
M
h(1:L+1)
t
, where h(1:L+1)
t
= [h0, h1, . . . , hL]T , (5.160) becomes
˜h( f ,P)
k
= BPh(1:L+1)
t
+ ˜w( f ,P)
k
,
(5.162)
where BP =
√
MSPF(1:L+1)
M
is a P × L + 1 matrix. As a consequence, the ML estimate of h(1:L+1)
t
is
expressed by [117,164]
ˆh(1:L+1)
ML,t
=

BH
P BP
−1
BH
P ˜h( f )
k,P,
(5.163)
and the ML estimate of h f is obtained by projecting ˆh(1:L+1)
ML,t
in the frequency-domain, as expressed by
[164]
ˆhML, f = F(1:L+1)
M
ˆh(1:L+1)
ML,t
= FM

ˆh(1:L+1)
ML,t
T
, 01×M−L−1
T
.
(5.164)

246
CHAPTER 5 OFDM and Multicarrier Signal Processing
Note that ML estimation does not require any knowledge about the noise power. It can be shown that
ML estimation achieves the Cramér-Rao lower bound (CRLB) [164], which is expressed by
MSE(Hm) = L + 1
P
σ 2
w.
(5.165)
If additional information is available at the receiver, such as the channel covariance matrix Ch(1:L+1)
t
and
the noise power σ 2
˜w( f )
k,P
, the mean-squared error (MSE) of the channel estimate can be further reduced
by a Bayesian MMSE estimation approach [117], as expressed by [164]
ˆh(1:L+1)
MMSE,t =

BH
P BP + σ 2
˜w( f )
k,P
C−1
h(1:L+1)
t
−1
BH
P ˜h( f )
k,P.
(5.166)
Note that, with respect to ML estimation, MMSE estimation is characterized by greater computational
complexity, because the matrix inverse in (5.166) depends on the noise power σ 2
˜w( f )
k,P
. However, the
complexity order for both ML and MMSE methods is O

P(L + 1) + M log2 M
	
.
A low-complexity alternative to ML and MMSE estimation is linear interpolation in the frequency-
domain of the channel estimates over two adjacent pilot tones, obtained as
ˆhlin, f = L

˜h( f )
k,P ⊗[1,
01×SP−1]T 
,
(5.167)
where L is an M × M symmetric banded circulant nonnegative matrix with elements
[L]m,m+n =
⎧
⎪⎪⎪⎪⎪⎪⎨
⎪⎪⎪⎪⎪⎪⎩
1 −|n|
SP
,
0 ≤|n| ≤SP −1,
0,
SP ≤|n| ≤M −SP,
1 −M −|n|
SP
, M −SP + 1 ≤|n| ≤M −1.
(5.168)
Figures 5.23 and 5.24 compare the performance of the above mentioned estimators: ML, MMSE and
piecewise linear interpolation. The equations above may be generalized to multicarrier systems with
guard frequency bands and non-equispaced pilot subcarriers. In general, the MSE of the channel depends
not only on the estimation method, but also on the subcarrier index. Obviously, the MSE is reduced
for those subcarriers that are close to the pilot subcarriers. In addition, the MSE tends to increase for
the edge subcarriers, i.e., for those subcarriers close to the guard frequency bands. This distortion,
sometimes referred to as leakage effect, can be reduced by leakage suppression [210] or by reducing
the pilot spacing for the edge subcarriers [164].
The equations above may be generalized also to the estimation of slowly time-varying channels,
assuming that the CIR stays constant for one OFDM block, but changes from block to block. In this
case, frequency-domain channel estimation may be repeated after a certain number of OFDM blocks.
The channel in between two successive estimates may be recovered by time-domain interpolation
techniques. This approach, based on successive one-dimensional interpolations, has been adopted in
[102] and [132]. Alternatively, joint interpolation/estimation in the time-frequency-domain may be
performed, such as the Wiener ﬁltering approaches proposed in [98] and [211].

2.05.12 Estimation of LTI channels for OFDM
247
5
10
15
20
25
30
10-4
10-3
10-2
10-1
100
SNR (dB)
MSE
 
 
MMSE estimation
ML estimation
CRLB
Piecewise linear interpolation
FIGURE 5.23
Channel MSE performance comparison among different channel estimation techniques (M = 256, P =
L + 1 = 16, multipath channel with an exponntially decaying power-delay proﬁle). This ﬁgure has been
generated using the MATLAB script perf_chann_estim.m.
0
5
10
15
20
25
30
10-4
10-3
10-2
10-1
100
E  /N  (dB)
b
0
BER
 
 
Perfect CSI
MMSE estimation
ML estimation
Piecewise linear interpolation
FIGURE 5.24
BER performance comparison among different channel estimation techniques (Uncoded BER, QPSK, M =
256, P = L + 1 = 16, multipath channel with an exponentially decaying power-delay proﬁle). This ﬁgure
has been generated using the MATLAB script perf_chann_estim.m.

248
CHAPTER 5 OFDM and Multicarrier Signal Processing
Adaptive estimators have been proposed in [198,207], and [203].
In addition to pilot-based techniques, joint pilot-data-aided channel estimators have been proposed
by many authors (see the references in [94] and [174]). Joint pilot-data-aided techniques, also known
as decision-directed channel estimation algorithms and iterative (turbo) processing methods, make use
of estimated data symbols as “virtual pilots” in order to reﬁne the channel estimate and further improve
the reliability of the data estimate itself.
2.05.13 OFDM propagation in rapidly time-varying channels
In the presence of a mobile transmitter or receiver, the (multipath) channel becomes time varying, that
is, its CIR changes with time. A simple physical interpretation is offered by the Doppler effect, which
affects a sinusoid transmitted between two equipments in relative motion.
If a sinusoidal signal cT(t) = A sin

2π fot + φ0
	
is transmitted in a wireless channel, and the
receiver is in relative motion with velocity v = vθ/ cos

θ0
	
and angle θ0 with respect to the direction
of the wave propagation, the received signal is expressed by [97]
cR(t) = β0cT

1 + vθ/c
	
t −τ0
	
= β0 A sin

2π f ′
ot + φ0 −φ0
	
,
(5.169)
where c is the speed of the traveling wave, φ0 = 2π foτ0, β0 ∈R is an attenuation coefﬁcient, τ0 is
the propagation delay in the absence of movement, and the perceived frequency f ′
o at the receiver side
is expressed by
f ′
o = fo ± fD cos

θ0
	
= fo ± fo
v
c cos

θ0
	
.
(5.170)
In (5.170), fD is the maximum Doppler frequency experienced when the two equipments are moving
towards (+ fD), or away (−fD) from each other. Equation (5.170) establishes that the receiver perceives
a Doppler shift fd0 = fD cos

θ0
	
with respect to the nominal frequency fo. If the transmitted carrier
reaches the receiver through different paths, the receiver perceives a different frequency shift fdi for
each path, depending on the different angle of arrival of each path with respect to the direction of motion
(see Figure 5.25).
If the transmitted waveform x(rf)
T (t) = xT(t)cT(t) is amplitude modulated by a signal xT(t), whose
bandwidth B ≪f0, i.e., the signal is almost constant during each period of the carrier, the signal
received through a single path can be approximated as
x(rf)
R (t) = x

1 ± vθ
c

t −τ0

cR(t) ≃β0xT(t −τ0)A sin

2π f ′
ot + φ0 −φ0
	
,
(5.171)
where vθ = v cos

θ
	
is the component of the velocity in the direction of the wave propagation. The
BB equivalent of right-hand side of (5.171) is expressed by
xR(t) = xT(t −τ0)βoe−jφ0 e j2π fd0t = α0 e j2π fd0txT(t −τ0),
(5.172)
where α0 = β0e−jφ0 ∈C is the complex attenuation coefﬁcient in a time invariant set-up, i.e., when
vθ = 0 and fd0 = 0. Note that the approximation in (5.171) means that the change in time-scale can
be safely ignored when vθ ≪c, for instance for electromagnetic propagation, where c is the speed of

2.05.13 OFDM propagation in rapidly time-varying channels
249
FIGURE 5.25
Multiple Doppler shifts for a moving receiver.
light, while this is not the case for ultrasound communications in underwater acoustic, where c is the
speed of sound [97].
It is straightforward to verify that (5.172) is obtained by the time-varying convolution operator ∗t,
summarized by
xR(t) = h0(t, τ) ∗t xT(t) =

 +∞
−∞
h0(t, τ)xT(t −τ)dτ,
(5.173)
where
h0

t, τ
	
= α0 e j2π fd0tδ

τ −τ0
	
= α0(t)δ

τ −τ0
	
(5.174)
is the time-varying CIR associated to a single-path propagation channel with propagation delay τo. By
means of (5.172) and (5.173), the effect of a single time-varying path on the transmitted signal is a delay,
and the multiplication for a time-varying signal α0(t) = α0e j2π fd0t. Thus, the effect on its spectrum is
a linear phase shift, plus a convolution with the spectrum F {α0(t)} = α0δ

f −fd0
	
, which causes a
frequency shift fd0, as expressed by
XR( f ) = XT( f −fd0)e−j2π( f −fd0)τ0.
(5.175)
Thus, if xT(t) = xk(t) is the (useful) signal transmitted during the kth OFDM symbol, and expressed by
(5.25), a single-path linear time-varying (LTV) channel as in (5.174) would cause a shift at the receiver
side of the frequency spectrum Xk( f ) in (5.26) and Figure 5.4. If left uncompensated, this frequency
shift would introduce ICI, because the zeros of the spectrum of each subcarrier are shifted from fm
to fm −fd0, while the DFT processing at the receiver produces a sampling at the original frequencies
fm, as clariﬁed in Figure 5.26. Note that this is the same effect introduced in AWGN channels, when

250
CHAPTER 5 OFDM and Multicarrier Signal Processing
FIGURE 5.26
ICI introduced by a Doppler shift or carrier frequency offset (CFO).
there is a carrier frequency offset (CFO) between the receiver RF local oscillator, tuned at a frequency
f ′
o = fo −fd0, and the transmitter RF local oscillator tuned at fo.
Obviously, a CFO or a single-path LTV channel can be compensated at the receiver side by a single-
tap time-varying equalizer, by simply multiplying the received signal xR(t) in (5.172) by α−1
0 e−j2π fd0t.
However, the RF propagation generally experiences Np different paths that emerge with the same delay
τp, and consequently a more general expression for the time-varying CIR is
hc

t, τ
	
=
P−1

p=0
h p(t, τ) =
P−1

p=0
αp(t)δ(τ −τp)
=
P−1

p=0
Np−1

n=0
αn,pe j2π fdp,n tδ(τ −τp),
(5.176)
where αn,p and fdn,p are the complex attenuation and the Doppler shift, respectively, associated to the
nth path that experiences the delay τp, and αp(t) = Np−1
n=0
αn,p e j2π fdp,n t is the time-varying gain
associated to each path. The spectrum of αp(t) would be consequently composed by several frequencies,
as expressed by F{αp(t)} = Np−1
n=0
αn,pδ( f −fdp,n), and the received signal would be composed by
several shifted replicas of the transmitted signal, as expressed by
XR

f
	
=
P−1

p=0

XT

f
	
e−j2π f τp

∗F

αp(t)

=
P−1

p=0
Np−1

n=0
αn,pXT

f −fdp,n
	
e−j2π( f −fdp,n )τp.
(5.177)

2.05.13 OFDM propagation in rapidly time-varying channels
251
Equation (5.177) reveals that the sum of the P convolutions introduces ICI, which needs for a more
complex mitigation technique rather than the simple frequency-shift compensation used for P = 1
[see (5.175) and discussion after (5.175)]. More generally, also the directions of the user movement
may change with time, making each path characterized by a time-varying angle θp,n(t) and time-
varying frequencies fdp,n(t). Consequently, αp(t) = Np−1
n=0
αn,p e−j2π fdp,n (t)t is characterized by a
continuous spectrum Ap( f ) that destroys the sinc shape associated to each subcarrier of Xk( f ) in
(5.26), by changing the zeros and leading to ICI, as expressed by
XR( f ) =
P−1

p=0

XT( f )e−j2π f τp

∗Ap( f )
= Tu
P−1

p=0
M−1

m=0
dm,k(Xm,k( f )e−j2π f τp) ∗Ap( f )
= Tu
P−1

p=0
M−1

m=0
dm,k

 +∞
−∞
sinc

πTu

ν −fm
	
Ap( f −ν)e−j

φk(ν−fm)+2πντp

dν.
(5.178)
The ICI introduced by (5.178) is graphically shown in Figure 5.27, focusing on the effect of a single
time-varying tap on the spectrum Xm,k( f ) of a single subcarrier.
Thus, assuming that the path delays τp remain constant with time, when the OFDM signal passes
through the LTV channel expressed in ﬁrst line of (5.176), in the presence of AWGN the received signal
,
m k
d
f
, ( )
m k
X
f
0
f
*
( )
p
A f
Single-Tap
Doppler Spectrum
,
m k
d
, ( ) *
( )
m k
p
X
f
A f
The data  dm,k transmitted on 
each subcarrier interferes with all 
the others (ICI)
Carrier  fm
of the OFDM signal
D
o
v
f
f
c
+
=
D
f
−
1
(
)
m
m
f
f
f
−
Δ
=
−
/
D
D
u
f
f
f MT
∝
Δ
=
ICI
m
f
1
m
f
+
1
m
f
−
m
f
1
m
f
+
1
m
f
−
FIGURE 5.27
ICI introduced by Doppler spread.

252
CHAPTER 5 OFDM and Multicarrier Signal Processing
can be expressed as [27]
y(t) =

 +∞
−∞
hc(t, τ)x(t −τ)dτ + w(t)
=
P

p=0

 +∞
−∞
αp(t)δ(τ −τp)x(t −τ)dτ + w(t)
=
P

p=0
αp(t)x(t −τp) + w(t),
(5.179)
which, after ﬁltering [matched to p(t)], becomes
y f (t) = y(t) ∗p∗(−t) =
P

p=0

 +∞
−∞
αp(t)x(t −τp)p∗(τ −t)dτ + w(t)∗p∗(−t)
≃
P

p=0
αp(t)

x(t−τp)∗p∗(−t)

+ w f (t).
(5.180)
The last equality in (5.180) is a good approximation under the hypothesis that the attenuation αp(t)
of each path is virtually constant for a time interval with duration Ts, which is the time support of the
pulse p(t). Thus, if the transmitted signal is expressed by means of its digital samples xn = x(nTs), the
received signal is expressed by
y f (t) ≃
P

p=0
αp(t)
+∞

i=−∞
xi p(t −τp −iTs) ∗p∗(−t) + w f (t)
≃
P
p=0
αp(t)
+∞

i=−∞
xi Rpp(t −τp −iTs) + w f (t),
(5.181)
which after uniform sampling with period Ts, leads to a received signal yn = y f (nTs) expressed by
yn =
+∞

i=−∞
xi
P

p=0
αp(iTs)Rpp((n −i)Ts −τp) + w f (nTS)
=
+∞

i=−∞
xi ˜hi,n−i + wn =
+∞

l=−∞
hn,lxn−l + wn,
(5.182)
where hn,l = ˜hn−l,l = P
p=0 αp(n −l)Rpp(lTs −τp) is the discrete-time equivalent time-varying CIR.
2.05.13.1 Carrier frequency offset (CFO)
As brieﬂy anticipated after (5.175), a special case of LTV channel is obtained in the presence of a
CFO fdo between the transmitter and the receiver oscillators, i.e., in the absence of (perfect) frequency

2.05.13 OFDM propagation in rapidly time-varying channels
253
synchronization. In this case, each multipath component is affected by the same time-varying coefﬁcient,
and therefore the discrete-time channel becomes hn,l = e j2πεn/M P
p=0 αp Rpp(lTs −τp), where ε =
fdoTu = fdo/ f represents the CFO normalized to the subcarrier spacing  f = 1/Tu = 1/(MTs).
Thus, instead of (5.60), the kth received vector after CP removal is expressed by [188]
y(cp)
k
= e j2πε(kN+Lg)/Mdiag(e)H(cp)
t
xk + wk
= e j2πε(kN+Lg)/Mdiag(e)H(cp)
t
FH
Mdk + wk,
(5.183)
where e = [1, e j2πε/M, . . . , e j2πε(M−1)/M]T and N = M + Lg. By applying the DFT on the received
vector y(cp)
k
, (5.183) becomes
y( f )
k
= FMy(cp)
k
= e j2πε(kN+Lg)/MEdiag(h f )dk + w( f )
k
,
(5.184)
where E = FMdiag(e)FH
M is circulant, with (m, n)th element expressed by
[E]m,n =
sin

π((n −m)mod M + ε)
	
M sin

π((n −m)mod M + ε)/M
	e jπ M−1
M

(n−m)mod M+ε
	
.
(5.185)
As a result of (5.184) and (5.185), a CFO produces three effects on the received signal, described in
the following. First, since E is not diagonal, y( f )
k
contains interference among the data elements of
the vector dk. This is the ICI, introduced by the frequency-shift of each subcarrier spectrum, which
is no longer sampled on its zero-crossing locations, as shown in Figure 5.26. Therefore, in order to
compensate this ﬁrst effect, equalization or ICI cancellation is necessary. Second, since the elements
on the main diagonal of E have modulus lower than one, the energy of the useful signal is reduced
by a factor sinc2(πε), as also clariﬁed by Figure 5.26. Note that E is unitary, and hence this energy
reduction is exactly balanced by the energy of the ICI. Also this second effect can be compensated
using equalization or ICI cancellation techniques. If the ICI is ignored at the equalizer, such as the
conventional equalizer of (5.67), the signal-to-interference ratio (SIR) on the estimated symbol is [185]
SIR =
sinc2(πε)
1 −sinc2(πε) ≈
3
(πε)2 −1,
(5.186)
where the last approximation is reasonable for ε < 0.15. Third, due to the complex exponential term
e j2πε(kN+Lg)/M in (5.184), the CFO also introduces a phase shift that depends on the OFDM block
index. This phase shift can be easily estimated (and successively compensated) by using pilot subcarri-
ers or, equivalently, the estimation (and equalization) can be included in the (block-by-block) channel
estimation techniques described in Section 2.05.12. The estimation of the CFO is the frequency syn-
chronization problem for OFDM, and as such it will be addressed in Section 2.05.15.
2.05.13.2 LTV channel equalization
Omitting the OFDM symbol index for notational compactness, in the case of a general LTV channel,
after discarding the CP the input-output relation expressed by (5.182) can be rewritten in vector-matrix

254
CHAPTER 5 OFDM and Multicarrier Signal Processing
form as
y(cp) = H(cp)
t
x + w
= H(cp)
t
FH
Md + w,
(5.187)
where y(cp), d, and w are vectors of size M that represent the received time-domain elements, the
transmitted frequency-domain symbols, and the received AWGN, respectively, for a generic OFDM
block, and H(cp)
t
stands for the M × M time-domain system matrix. From (5.188), it is evident that
each diagonal of H(cp)
t
contains different elements, i.e., the discrete-time evolution of each channel tap.
In other words, differently from the time-invariant channel case, H(cp)
t
in (5.188) is not circulant and
therefore cannot be diagonalized using FFT matrices.
H(cp)
t
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
h0,0
0
· · ·
0
h0,L
· · ·
h0,1
h1,1
h1,0
0
...
0
...
...
...
h2,1
...
...
...
...
hL−1,L
hL,L
...
...
...
...
...
0
0
hL+1,L
...
...
...
0
...
...
...
...
...
... hM−2,0
0
0
· · ·
0 hM−1,L · · · hM−1,1 hM−1,0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
.
(5.188)
By applying an FFT we obtain
y( f ) = FMy(cp) = H f d + w( f ),
(5.189)
where H f is not diagonal. Similarly to the CFO case, also a general LTV channel introduces ICI [144]
onto the frequency-domain received vector y( f ), because the data symbol dm transmitted on the mth
subcarrier is received also on the subcarriers with index different than m, as shown in Figure 5.27.
In order to reduce the ICI, different equalization techniques are possible [41,56,90,97,204,193]. For
instance, a zero-forcing (ZF) equalizer produces the data estimate
ˆdZF = H−1
f y( f ) = d + H−1
f w( f ).
(5.190)
This means that, in general, channel estimation is necessary for the availability of H f . When the
channel is rapidly time-varying, channel estimation must be repeated for each block. An example of
channel estimation for LTV channels will be described later on. Moreover, ZF equalization requires
a matrix inversion whose complexity is O(M3) per block. Therefore, when the number of subcarrier
is large, the pure ZF approach of (5.190) is impractical. In this case, the equalizer may exploit some
speciﬁc structured models for the LTV channel in order to enable fast inversion algorithms of H f . By
observing Figure 5.27, because of the sinc(·) shape of each subcarrier spectrum, it is clear that most
of the ICI is introduced in the nearby subcarriers. Equivalently, by observing the signal received on a
single subcarrier, it is reasonable to assume that most of the ICI comes from the nearby subcarriers and,
consequently, H f is modeled as banded and can be inverted with complexity O(M log M) per block.
In addition, the frequency-domain channel matrix H f is usually ill-conditioned [89], and therefore

2.05.13 OFDM propagation in rapidly time-varying channels
255
the noise enhancement produced by H−1
f w( f ) may be excessive. To reduce the noise enhancement
introduced by ZF equalization, classical linear MMSE equalization may be applied, as expressed by
ˆdMMSE =

HH
f H f +

σ 2
w/σ 2
d
	
IM
−1
HH
f y( f ),
(5.191)
which, analogously to the ZF solution, can be implemented with reduced complexity by exploiting the
almost banded structure of H f [41,194,204,193]. A BER performance comparison of some different
ZF and MMSE alternatives is shown in Figure 5.28.
Alternatively, nonlinear techniques may be employed, using decision feedback methods for ICI
cancellation or any other tree-search approach. An example of the performance advantages provided
by DFE methods with respect to linear MMSE approaches is shown in Figure 5.29.
Iterative or turbo approaches that can incorporate channel decoding have also been proposed [75,97,
204]. When the channel statistics are known at the receiver, the equalizer may also exploit this knowledge
by applying a pre-processing stage with specially designed windows [304]. Nonlinear and statistic-aided
methods usually outperform linear equalization, at the price of somewhat increased complexity [97]. A
performance comparison, for some potential NL equalization alternatives is shown in Figure 5.30.
2.05.13.3 LTV channel estimation
The estimation of a multipath LTV channel is a non trivial task, because each channel path changes
in time. Thus, during the transmission of an M-length OFDM block, there are M(L + 1) unknowns
to be estimated in the discrete-time-domain, which are contained in the circulant channel matrix H(cp)
t
in (5.188). However, these unknowns are not independent from each other, especially those that represent
5
10
15
20
25
30
35
10
-4
10
-3
10
-2
10
-1
10
0
Eb/N0(dB)
BER
 
 
Conventional
ZF (full)
ZF (banded)
MMSE (full)
MMSE (banded)
MMSE (windowing)
FIGURE 5.28
BER performance comparison among ZF and MMSE equalizers for LTV channels [Uncoded BER, QPSK,
M = 128 subcarriers with Mact = 96 consecutive data subcarriers and Mvir = M−Mact = 32 zero subcarriers,
Db = 2 for banded and window-aided equalizers, MBAE-SOE window [195], L = 7, Multipath channel with
uniform power-delay proﬁle, max

fdp,n

/f = 0.1, perfect channel state information (CSI)]. This ﬁgure has
been generated using the MATLAB script perf_ltv_equaliz.m.

256
CHAPTER 5 OFDM and Multicarrier Signal Processing
5
10
15
20
25
30
35
10
-4
10
-3
10
-2
10
-1
10
0
BER
 
MMSE (full)
MMSE (banded)
MMSE (windowing)
DFE (full)
DFE (banded)
DFE (windowing)
Eb/N0(dB)
FIGURE 5.29
BER performance comparison among MMSE and DFE equalizers for LTV channels [Uncoded BER, QPSK,
M = 128 subcarriers with Mact = 96 consecutive data subcarriers and Mvir = M−Mact = 32 zero subcarriers,
Db = 2 for banded and window-aided equalizers, MBAE-SOE window [195], L = 7, Multipath channel with
uniform power-delay proﬁle, max

fdp,n

/f = 0.1, perfect channel state information (CSI)]. This ﬁgure has
been generated using the MATLAB script perf_ltv_equaliz.m.
5
10
15
20
25
30
35
10
-4
10
-3
10
-2
10
-1
BER
 
 
Perfect CSI, 1st iter.
Perfect CSI, 2nd iter.
Perfect CSI, 4th iter.
Estimated CSI, 1st iter.
Estimated CSI, 2nd iter.
Estimated CSI, 4th iter.
E  / N  (dB)
b
0
FIGURE 5.30
BER performance of turbo MMSE equalizers for LTV channels [Uncoded BER, QPSK, M = 128 subcarriers
with Mact = 107 non-consecutive data subcarriers and P = M−Mact = 21 pilot subcarriers, whose Mvir = 14
are zero and P −Mvir = 7 are nonzero, Db = 2, MBAE-SOE window [195], L = 5, Multipath channel with
uniform power-delay proﬁle, max

fdp,n

/f = 0.1].

2.05.13 OFDM propagation in rapidly time-varying channels
257
the time-evolution of a single delay path. Thus, the structure in the problem can be exploited to recast it in
an equivalent estimation problem, with a reduced number of unknowns. For instance, by approximating
the quasi-banded frequency-domain channel matrix H f in (5.189) as perfectly banded with only Db
super and lower diagonals different from zeros, the number of unknowns are M

2Db + 1
	
, which is
convenient when Db < L/2. Actually, each diagonal in H f represents a discrete Doppler frequency
shift induced by the LTV channel [97,204], and assuming H f as perfectly banded corresponds to assume
that each LTV channel tap can be expressed by a linear combination of 2Db + 1 discrete-time (Fourier)
exponentials, as expressed by
hn,l =
2Db

q=0
cq,l e j 2π
M (q−Db)n,
n ∈[0, M −1],
l ∈[0, L].
(5.192)
Thus, the M unknowns that characterize the time-evolution of each channel tap are turned in 2Db + 1
unknowns by the coefﬁcients cq,l, while the time evolution is captured by a known set of complex
exponential functions, which are the same for all the L + 1 taps. Globally the problem can be casted as
the estimation of (L + 1)(2Db + 1) unknowns, where typically 2Db + 1 ≤5 is enough to accurately
represent the time-evolution of each channel tap, or equivalently to model the ICI only on 2Db adjacent
subcarriers, by H f . More generally, the time evolution of the paths can be captured by other basis
functions, by the so called basis expansion model (BEM), expressed by
hn,l =
Q

q=0
cq,luq[n],
n ∈[0, M −1],
l ∈[0, L],
(5.193)
where Q + 1 is the number of BEM functions, and uq[n] is the qth BEM function. Basically, the
BEM functions {uq[n]}, are the same for different OFDM blocks and different channel taps. Several
choices have been investigated, such as power polynomials [33], complex exponential (CE) [239],
Legendre polynomials [99], generalized complex exponentials (GCE) [139], discrete prolate spheroidal
(DPS) functions [266], discrete Karhunen-Loève (DKL) [235]. For instance, Figure 5.31 shows the
time evolution of a single channel path hn,l, and its LS ﬁtting obtained by either Fourier or Legendre
polynomial functions.
On the other hand, the unknown BEM coefﬁcients {cq,l} are time invariant within (at least) the
considered OFDM block, but change from block to block (or from multiple blocks to multiple blocks),
and therefore must be re-estimated, or updated, every OFDM block (or multiple blocks).
As already discussed for LTI channel estimation, based on the transmission of training pilots, several
options are available, with pilots either in the frequency, or in the time-domain, or both. Preamble-
based pilot design may be preferable in WLAN applications characterized by burst transmissions,
while frequency-domain pilots interleaved with data within each OFDM block may be preferable for
continuous transmission, such as in broadcasting applications (DVB-T/H, DAB). In the following,
we describe a frequency-domain pilot-based LTV channel estimation technique, which exploits the
structured BEM model for the channel time variation. However, the BEM structure can be similarly
exploited also by preamble-based approaches in the time-domain, as detailed for instance in [231] for
SC block transmissions. Speciﬁcally we make the following assumptions:

258
CHAPTER 5 OFDM and Multicarrier Signal Processing
time (µs)
time (µs)
time (µs)
time (µs)
(a)
(b)
(d)
(c)
0
20
40
60
80
100
120
-0.5
-0.4
-0.3
-0.2
-0.1
0
0.1
0.2
0.3
0.4
0.5
real part of channel path amplitude
 
exact
Polynomial (Q=1)
CE (Q=2)
GCE (Q=2)
0
20
40
60
80
100
120
-0.5
-0.4
-0.3
-0.2
-0.1
0
0.1
0.2
0.3
0.4
0.5
real part of channel path amplitude
 
exact
Polynomial (Q=2)
CE (Q=4)
GCE (Q=4)
0
20
40
60
80
100
120
-0.05
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
real part of channel path amplitude
 
 
exact
Polynomial (Q=1)
CE (Q=2)
GCE (Q=2)
0
20
40
60
80
100
120
-0.05
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
real part of channel path amplitude
 
 
exact
Polynomial (Q=2)
CE (Q=4)
GCE (Q=4)
FIGURE 5.31
LTV channel tap gain for normalized Doppler spread (a,b) max

fdp,n

/f = 100%; (c,d) max

fdp,n

/f =
20%.
a. The transmission format is CP-OFDM.
b. At the transmitter, P out of M subcarrier are reserved for pilot symbols, while the remaining
D = M −P are used for data symbols. We assume that the P pilots are arranged in L P +1 clusters,
with P = (2Q P + 1)(L P + 1), where each pilot cluster is a vector of size 2Q P + 1 with p on
the central position and Q P zeros on each side. We also assume that L P ≥L. We denote with
a the frequency-domain transmitted vector, obtained by interlacing the pilot clusters with the data
clusters. For convenience, we denote with p the pilot vector, which is zero also on the data positions,
and with d the data vector, which is zero on the pilot positions, so that a = p + d.
We assume that the time variation of each discrete-time channel path can be represented by a
BEM, as expressed by (5.193), and the BEM coefﬁcients {cq,l} estimated every OFDM block.
c. At the receiver, the channel estimation is performed using only a single OFDM block.

2.05.13 OFDM propagation in rapidly time-varying channels
259
Using the BEM, it can be shown that [97,230]
H f =
L

l=0
Q

q=0
cq,lUqZl,
(5.194)
where Uq = FMdiag(uq)FH
M is the circulant matrix that takes into account for the discrete Doppler spec-
trum associated with the qth BEM-function vector uq = [uq[0], . . . , uq[M −1]]T , and Zl = diag(zl)
with zl = [1, e j2πl/M, . . . , e j2πl(M−1)/M]T . For instance, choosing Q = 2Db even and complex expo-
nential BEM functions uq[n] = e j2π(q−Q/2)n/M as in (5.192), the matrix Uq in (5.194) is a cyclic-shift
matrix of q −Q/2 positions: in this case, the ICI on a certain subcarrier comes only from the Q closest
subcarriers (Q/2 on each side), and a choice Q P ≥Q is sufﬁcient to avoid ICI [230]. After some
algebra, the matrix (5.194) may be rewritten as
H f = G(c ⊗IM),
(5.195)
whereG = [U0Z0, . . . , UQZ0, . . . , U0ZL, . . . , UQZL]andc = [c0,0, . . . , cQ,0, . . . , c0,L, . . . , cQ,L]T .
Combining (5.195) with y( f ) = H f a + w( f ), we obtain
y( f ) = G(c ⊗IM)a + w( f ) = G(I(Q+1)(L+1) ⊗a)c + w( f ),
(5.196)
which clearly highlights the linear relation between the unknown coefﬁcients in c and the received
frequency-domain vector y( f ). By selecting the (Q P + 1)(L P + 1) subcarriers that correspond to the
L P + 1 pilot clusters, we obtain
y( f )
P
= SPy( f ) = BPc + i + SPw( f ),
(5.197)
where SP is the (Q P + 1)(L P + 1) × M selection matrix, BP = SPG(I(Q+1)(L+1) ⊗p), and i =
SPG(I(Q+1)(L+1) ⊗d)c is the residual ICI caused by the data d. For a complex exponential BEM with
Q P ≥Q, it can be shown that the residual ICI is virtually absent, that is [230]
y( f )
P
= BPc + SPw( f ).
(5.198)
Therefore, an estimate ˆc = [ˆc0,0, . . . , ˆcQ,0, . . . , ˆc0,L, . . . , ˆcQ,L]T of the channel coefﬁcients may be
obtained by LS (or linear MMSE) estimation by
ˆc = Geqy( f )
P ,
(5.199)
where Geq is equivalent to (5.190) [or to (5.191)] using BP for H f and y( f )
P
for y( f ) [117]. Then, by
(5.193) an estimate of the LTV channel ˆhn,l is obtained as
ˆhn,l =
Q

q=0
ˆcq,luq[n],
(5.200)

260
CHAPTER 5 OFDM and Multicarrier Signal Processing
and, by (5.194) and (5.195), an estimate of the frequency-domain channel matrix is obtained as
ˆH f =
L

l=0
Q

q=0
ˆcq,lUqZl = G(ˆc ⊗IM).
(5.201)
When the interference i in (5.197) is not negligible, iterative approaches that make use of (hard or soft)
ICI cancellation may be employed [74,230].
Figure 5.32a and c shows the MSE performance of the proposed approach, for different choices of
the basis functions and different maximum Doppler spread, for several channel estimators such as the
MMSE, LS, and best linear unbiased estimator [117]. Figure 5.32b and d show the corresponding BER
performance for QPSK modulation and the banded version of the linear MMSE equalizer in (5.191)
[230,193].
The BEM channel estimation approach described by (5.192)–(5.201) is appropriate when the LTV
channel is wide-sense stationary (WSS), that is, when the statistics of the LTV channel, such as the
Doppler power spectral density, do not change with time. In some cases, non-WSS channels have to
be estimated, such as when the mobile receiver changes its speed. Indeed, a speed change entails a
change of the maximum Doppler frequency. In these cases, adaptive approaches are more suitable for
channel (i.e., BEM coefﬁcients) tracking purposes. Examples of these techniques have been presented
in [18,19,44,123,168,223].
Readers interested in further hints on channel estimation and tracking are redirected to the E-
Reference contribution in [241].
2.05.14 Design of OFDM systems: practical guidelines and commercial
standards
This section aims at providing general guidelines for the design of the typical parameters of an OFDM
system, i.e., how to choose the number M of subcarriers, the subcarrier separation  f , the CP length
Tg, the OFDM symbol period Tu. We also highlight the interplay among the different parameters,
because Tu = MTs, where Ts is the sampling period, Tg = LgTs, where Lg is the number of samples
in the guard period (CP, ZP, or KP), and  f = 1/Tu. We also deﬁne the bandwidth of the OFDM
system as W = M f = 1/Ts, which is equal to the (gross) symbol rate fs. Often, the bandwidth
requirement is imposed, either by the physical medium constraints or by the symbol rate requirements,
and consequently the sampling period is ﬁxed by Ts = 1/W.
As explained in Section 2.05.3, historically the main motivation for OFDM has been the need to
efﬁciently contrast frequency-selective (multipath) channels. Assuming that the maximum delay of the
multipath channel is Th, in order to avoid IBI between successive OFDM blocks, the guard time should
be Tg ≥Th. Since the guard time reduces the information rate, it is convenient to select its minimum
value, i.e., Tg = Th. In this case, the number of samples in the guard period Lg = Tg/Ts is equal to the
discrete-time channel order L = Th/Ts. Therefore, we use L in order to denote both the channel order
and the number of samples of the guard period.
Thus, for a given frequency bandwidth that is available or it is necessary to guarantee speciﬁc
capacity requirements, the increase of the number M of subcarriers reduces the system sensitivity to the

2.05.14 Design of OFDM systems: practical guidelines and commercial standards
261
10
15
20
25
30
35
40
10
-2
10
-1
10
0
10
1
10
2
SNR (dB)
MSE
CE
DKL-mmse
GCE-blue
GCE-ls
10
15
20
25
30
35
40
10
-4
10
-3
10
-2
10
-1
10
0
SNR (dB)
BER
CE
DKL-mmse
GCE-blue
GCE-ls
Perfect CSI
10
15
20
25
30
35
40
10
-2
10
-1
10
0
10
1
10
2
SNR (dB)
MSE
CE
DKL-mmse
GCE-blue
GCE-ls
10
15
20
25
30
35
40
10
-4
10
-3
10
-2
10
-1
SNR (dB)
BER
CE
DKL-mmse
GCE-blue
GCE-ls
Perfect CSI
(a)
(b)
(d)
(c)
FIGURE 5.32
Channel MSE and BER versus SNR. Q = 4. (a)–(b) max

fdp,n

/f = 0.2, (c)–(d) max

fdp,n

/f = 1.0.
frequency selectivity of multipath channels (see Figure 5.6). However, note that this intuitive statement
loses part of its signiﬁcance when a guard-time (by CP, ZP, or KP) is inserted between successive OFDM
symbols. Indeed, as proved by (5.47) and (5.65) the CP (and similarly the ZP or the KP) is capable
to turn the time-domain multipath channel into a set of parallel and orthogonal single-path frequency-
domain channels, independently of the number of subcarriers. Consequently, the use of a high number
of subcarriers is attractive in order to maximize the OFDM system efﬁciency, whereas the resistance
to the channel selectivity is caused by the presence of the CP rather than the use of a high number
of subcarriers. In this respect, the efﬁciency of the OFDM system that does not transmit information
during the CP (ZP, or KP) is inversely proportional to the CP versus the OFDM symbol duration, as
expressed by
ηofdm =
Tu
Tu + Tg
=
M
M + L −→
M≫L 1.
(5.202)

262
CHAPTER 5 OFDM and Multicarrier Signal Processing
If we call Bc = 1/Th = 1/Tg the channel coherence bandwidth (other deﬁnitions are possible for the
coherence bandwidth [222]), (5.202) shows that Tg ≪Tu in order to obtain an adequate efﬁciency: in
this case, the subcarrier separation should be
 f = 1/Tu ≪1/Tg = Bc.
(5.203)
Equivalently, in order to maximize the overall efﬁciency, the system designer is tempted to use a number
M of subcarriers much greater than the discrete-time channel length L = Tg/Ts, which is imposed by
the environment (indoor/outdoor, urban/rural area, etc.) and by the system bandwidth W = 1/Ts.
However, there are also good reasons to not increase M over a certain limit. Indeed, higher values
of M induces a longer OFDM symbol duration Tu = 1/ f . Very long symbol durations may be
not desirable for many reasons. The symbols transmitted on each subcarrier are detected every OFDM
symbol period Tu +Tg: the consequent detection delay with respect to SC communications may become
unacceptable for real-time communications if Tu = MTs is too long. Most importantly, a very long
OFDM symbol duration Tu may be not desirable in mobile communications, where the channel is not
only frequency-selective but also time-varying (i.e., doubly-selective). In this last case, the assumptions
that lead us to the easy per-subcarrier equalization for time-invariant multipath channels are no longer
true, as detailed in Section 2.05.10. In other words, the CP-enabled subcarriers lose their orthogonality
in time-varying (mobile) channels, due to the Doppler spread that modiﬁes the sinc(·) shaped spectrum
of the data transmitted on each subcarrier, introducing ICI (see Figure 5.27). Thus, if the designer prefers
to avoid the use of complex time-varying equalization schemes, it is necessary to design the OFDM
symbol duration Tu ≪Tc, where Tc is the so called coherence time [222], within which the channel can
be safely considered as time-invariant. Since the channel coherence time Tc is inversely proportional to
the maximum Doppler spread fD induced by the time-varying channel [222], the time-variation (thus
the ICI) can be safely ignored when the subcarrier separation is  f = 1/Tu ≫fD (see Figure 5.27).
Actually, the fact that closer subcarriers are more sensitive to Doppler effects is also quite intuitive:
as a practical rule of thumb, the BER performance degradation induced by a time varying channel
is negligible when the maximum Doppler spread of the channel is within 1 ÷ 2% of the subcarrier
separation, that is fD/ f = fDTu = fD NTs ≤0.01 ÷ 0.02.
Furthermore, note that a frequency synchronization error induced at the receiver by an oscillator drift
fD has similar effects (see Section 2.05.11) and the same considerations hold true to make the OFDM
system resistant to such inaccuracy. Another reason for avoiding long symbol durations, or equivalently
a high number of subcarriers, is the FFT complexity, which scales as O(M log2 M) per block: as a
consequence, the complexity per data sample (logarithmically) increases with M.
Obviously, the OFDM designer would like to ﬁnd a good compromise between the two opposite
requirements on the OFDM block duration, in order to design an OFDM system that is both efﬁcient, in
time-dispersive (frequency-selective) channels, and resistant, in the time-varying (frequency-dispersive)
channels induced by equipment mobility or oscillators drifts. Anyway, in order to make this possible,
the OFDM symbol duration has to satisfy both the previous inequalities, that is
1
Bc
< Tu < 1
fD
.
(5.204)
This is obviously possible only when the channel is characterized by
fD/Bc = fDTc < 1,
(5.205)
which is known as the underspread-channel condition [97].

2.05.15 OFDM time and frequency synchronization
263
Table 5.1 summarizes the main OFDM parameters employed in popular standards such as DVB-T,
DVB-T2, IEEE 802.11a/g, IEEE 802.16e, LTE and ADSL [72,73,104,105,107,237]. Note that DVB-T
and DVB-T2 have a ﬁxed sampling frequency fs and hence a ﬁxed bandwidth W, while the number
of subcarriers M depends on the transmission mode. Therefore, when the number of subcarriers M
increases, the useful block duration Tu = M/ fs increases and the subcarrier separation  f = 1/Tu
decreases. As a consequence, DVB-T/T2 modes with many subcarriers are very sensitive to time-
varying channels and Doppler effects. On the other hand, IEEE.802.16e and LTE have a ﬁxed subcarrier
separation and hence their sensitivity to Doppler effects is the same for all the transmission modes: in this
case, the useful block duration Tu = 1/ f is ﬁxed and the normalized Doppler spread is fD/ f < 2%.
For IEEE.802.16e and LTE standards, the increase of the number of subcarriers M implies an increased
sampling frequency fs = M/Tu and hence an increased bandwidth W. Note that IEEE 802.11a/g
standards have a ﬁxed sampling frequency and a ﬁxed subcarrier separation, which implies a single
transmission mode with M = 64. For IEEE 802.11a/g standards, the mobile speed is very low (e.g.,
v = 5 km/h) and the subcarrier separation is quite great (i.e.,  f = 312.5 kHz), and therefore the
Doppler effects are practically absent. Thus, in the IEEE 802.11p version for car-to-car communications,
it has been necessary to increase resistance to longer channel multipath (by a longer CP duration Tg)
rather than to Doppler spread: actually, IEEE 802.11p uses also a closer subcarrier separation (longer
block duration Tu = 1/ f ) in order to preserve a quite high efﬁciency ratio Tu/

Tu + Tg
	
.
Note that the ADSL standard, for wired communications, is quite sensitive to multipath channels:
when the CP length L = 32 is insufﬁcient to deal with the multipath length of the channels, channel
shortening techniques may be employed.
2.05.15 OFDM time and frequency synchronization
Synchronization is an important task for communication receivers of MC block transmissions. Time
synchronization algorithms aim at identifying the correct starting point of an OFDM block, whereas
frequency synchronization algorithms try to minimize the CFO (discussed in Section 2.05.12) between
the transmitter oscillator and the receiver oscillator.
The lack of perfect synchronization, either in time or frequency, induces a dual effect on the received
signal, with a phase rotation in frequency or time, respectively. These effects are summarized by (5.175)
and (5.172), respectively, interpreting τ0 in (5.175) as the time error, i.e., τ0 = τoff/Fs, where τoff is the
discrete-time offset between receiver and transmitter, and interpreting fd0 in (5.172) as the frequency
synchronization error, i.e., fd0 = εFs/M. Note that a discrete-time offset τoff > 0 in (5.172) introduces
not only the phase rotation in (5.175) on each subcarrier but also a partial loss of information on the
received OFDM block and ISI from the next OFDM block, as clariﬁed by Figure 5.33. The partial loss
of time support for the transmitted data causes both an attenuation of the useful data and the introduction
of ICI among subcarriers, which degrades the perceived SNR and the SER, as quantiﬁed in [226] for
AWGN scenarios.
There is a large amount of possible methods that exploit the structure induced by (5.175) and (5.172)
to estimate τoff and ε, performing time and frequency synchronization in OFDM by their compensation.
These methods may be based either on known training (pilot) signals, placed in the time- or frequency-
domain, or on frequency-domain data symbols, or on both training and data (see Figure 5.34). However,

264
CHAPTER 5 OFDM and Multicarrier Signal Processing
Table 5.1 Main Parameters for Some OFDM-Based Standards
Standard
FFT
Bandwidth
Gross Bit
Subcarrier
Sampling
Useful
CP
CP
Carrier
Speed
Normalized
(Mode,
Size
Rate
Separation
Rate
Block
Size
Duration
Frequency
Doppler
Parameters)
(16-QAM)
Duration
Spread
M
W (MHz)
(Mb/s)
f (kHz)
fs (MHz)
Tu (µs)
L
Tg (µs)
fc (MHz)
ν (km/h) fD/f
DVB-T
2048
7.61
28.66
4.46
9.14
224
128
14
702
100
0.0146
(2k, CP 1/16)
DVB-T
8192
7.61
28.64
1.12
9.14
896
512
56
702
100
0.0582
(8k, CP 1/16)
DVB-T
1024
7.62
28.67
8.93
9.14
112
64
7
702
100
0.0073
(1k, CP 1/16)
DVB-T
16,384
7.61
28.64
0.56
9.14
1792
1024
112
702
100
0.1165
(16k, CP 1/16)
IEEE 802.11a
64
16.56
52
312.5
20
3.2
16
0.8
5200
5
7.7E-05
(CP 1/4)
IEEE 802.11 g
64
16.56
52
312.5
20
3.2
16
0.8
2412
5
3.6E-05
(CP 1/4)
IEEE 802.116e
128
1.25
3.27
10.94
1.4
91.43
16
11.43
3500
60
0.0178
(1.25 MHz, CP 1/8)
IEEE 802.116e
2048
20
65.33
10.94
22.4
91.43
256
11.43
3500
60
0.0178
(20 MHz, CP 1/8)
LTE downlink
512
5
14.4
15
7.68
66.67
128
16.67
2140
100
0.0132
(5 MHz, CP 1/4)
LTE downlink
2048
20
57.6
15
30.72
66.67
512
16.67
2140
100
0.0132
(20 MHz, CP 1/4)
ADSL (Downstream)
512
1.10
4.12
4.31
2.21
231.88
32
14.49
0.55
0
0

2.05.15 OFDM time and frequency synchronization
265
FIGURE 5.33
OFDM with time offset at the receiver side.
τ
f
° ° ° °
° ° ° °
 
FIGURE 5.34
Time-domain and frequency-domain training for OFDM synchronization.
a suitable synchronization method should take into account the type of transmission, i.e., burst or
continuous. In (burst) packet-based OFDM transmissions, such as WLAN, the acquisition time should
be kept to a minimum. In this case, it is convenient to transmit a specially designed training sequence,
possibly placed in the time-domain, at the beginning of the whole frame, in order to speed up the

266
CHAPTER 5 OFDM and Multicarrier Signal Processing
acquisition of time-frequency synchronization parameters. On the other hand, in continuous OFDM
transmissions, such as broadcasting, it is meaningful to exploit repeated (periodic) transmission of
training sequences, in order to track also slow frequency drifts of the oscillators. However, this approach
produces a data-rate reduction. Therefore, for continuous OFDM transmissions, (blind) data-aided
methods based on the CP presence or on statistical average over data symbols may be more convenient
than training-based methods.
The remainder of this section brieﬂy presents two joint time and frequency synchronization algo-
rithms for OFDM. The ﬁrst algorithm, proposed in [208], uses a training sequence at the beginning of
the OFDM frame, and is well suited to burst transmissions. The second algorithm, proposed in [243],
exploits the redundancy generated by the CP, and is well suited to continuous transmissions. Although
there exist many other algorithms that outperform those described in this section, the algorithms of
[208] and [243] are important because they establish the basic principles for OFDM synchronization
and are often considered as a benchmark for performance comparison.
The time synchronization idea behind the Schmidl and Cox algorithm (SCA) is to detect the training
sequence by using a time-domain correlation-maximization approach [208]. In AWGN, the receiver
could perform a sliding-window correlation between the time-domain noisy received signal and the
training sequence template, similarly to a sliding-window MF. However, in multipath channels, this
correlation approach is not convenient, because the training sequence inside the received signal is mod-
iﬁed by the LTI channel. Therefore, in multipath channels, the received signal should be correlated with
a multipath-affected training sequence. Unfortunately, before time synchronization has been achieved,
the multipath CIR is still unknown, and hence the multipath-affected template is not available. The SCA
overcomes this problem by using a training sequence with two identical halves in the time-domain. Since
both halves are affected in the same way by an LTI channel, half of the training sequence may be used
as a (noisy) template in order to detect the other half of the training sequence. Let us denote with LT the
number of samples of each half sequence. Since a CP is inserted, the total length of the whole training
sequence is 2LT + Lg. By denoting with rn the generic received sample in the time-domain, the SCA
constructs the sliding-window correlation function
P(τ) =
τ+LT −1

n=τ
r∗
nrn+LT ,
(5.206)
where τ denotes a candidate time offset, and then estimates the time offset τoff by selecting the value
ˆτoff that maximizes the metric |P(τ)|2 /R(τ), where R(τ) is a power normalization factor deﬁned as
R(τ) =
τ+LT −1

n=τ
**rn+LT
**2.
(5.207)
After time synchronization has been performed, the SCA compensates for the CFO as follows. Let us
denote with wn the generic noise sample in the time-domain at the receiver, and r′
n = rn −wn, such
that rn = r′
n + wn. It can be shown that, in case of perfect time synchronization (i.e., ˆτoff = τoff), it
holds true that [161,208]
r′
n+LT = r′
n e j2πεLT /M.
(5.208)

2.05.15 OFDM time and frequency synchronization
267
Therefore, at the correct time offset τoff, and in the absence of noise, by (5.208) the sliding-window
correlation function P(τ) in (5.206) would produce
P(τoff) =
τoff+LT −1

n=τoff

r′
n
	∗r′
n+LT = E e j2πεLT /M,
(5.209)
where E = τoff+LT −1
n=τoff
**r′
n
**2 is the energy of half of the training sequence. As a consequence, the CFO
can be estimated as
ˆε =
M
2π LT
angle(P(ˆτoff)) =
M
2π LT
tan−1
Im{P(ˆτoff)}
Re{P(ˆτoff)}

.
(5.210)
The CFO estimator (5.210) is valid only if the CFO ε is within the CFO acquisition range |ε| <
M
2LT .
Therefore, a longer training sequence reduces the frequency offset acquisition range. However, by
(5.206), a longer training sequence also improves the time offset estimation accuracy, because the
average (5.206) is more accurate, at the expense of an increased overhead (reduced data rate). In [161],
the half-length of the training sequence is chosen as LT = M, and therefore the CFO acquisition range
is half of the subcarrier spacing. However, using LT = M permits to replace the two identical halves of
a known training sequence with an unknown OFDM data symbol repeated twice [161], thereby reducing
the overhead. In [208], a second training sequence is inserted in the time-domain, after the two identical
halves of the ﬁrst training sequence. The aim of this second sequence is to increase the CFO acquisition
range.
For joint time-frequency synchronization and channel estimation purposes, the IEEE 802.11 WLAN
standard [104] uses a mixed approach with both time-domain training and frequency-domain pilots.
The time-domain training is inserted at the beginning of each OFDM packet: there are 10 identical
short training symbols followed by 2 identical long training symbols with a CP. In addition, in each
subsequent OFDM symbol, 4 pilot tones are inserted for CFO correction and tracking purposes.
The time synchronization idea behind the algorithm of van de Beek et al. is to detect the CP, again
by using a time-domain correlation-maximization approach [243], as shown in Figure 5.33. Indeed, in
the absence of both noise and multipath, the Lg samples of the CP are identical to the last Lg samples of
the OFDM block: hence, similarly to the SCA, there are two identical sequences, separated in time by
M samples, where M is the DFT size. The algorithm of van de Beek et al. evaluates the sliding-window
correlation function
P2(τ) =
τ+Lg−1

n=τ
rnr∗
n+M,
(5.211)
and the power term
R2(τ) = 1
2
τ+Lg−1

n=τ

|rn|2 + |rn+M|2
,
(5.212)
and then estimates the time offset τoff by selecting the value ˆτoff such that
ˆτoff = arg max
τ

MCP(τ)

= arg max
τ
|P2(τ)| −ρR2(τ)

,
(5.213)
which is the ML estimates in AWGN scenarios, and where ρ = SNR/(1 + SNR).

268
CHAPTER 5 OFDM and Multicarrier Signal Processing
Since the CP is included in every OFDM block, the functions in (5.211) and (5.212) may be averaged
over multiple OFDM blocks, thereby improving the time offset estimation performance at the expense
of increased complexity and increased delay.
Actually, as previously clariﬁed, OFDM transmissions are conceived for non-AWGN channels, i.e., to
easily handle the frequency selectivity of multipath channels, which request some further reﬁnements
to the CP-based time synchronization approach. Indeed, in the presence of multipath, the CP of the
current OFDM block is affected by the samples of the previous OFDM block, while the last Lg samples
of the current OFDM block are affected by other samples of the current OFDM block. Therefore, at
the correct time offset τoff, the two sequences (CP and last Lg samples of the current OFDM block)
are no longer identical. This problem may be solved when the CIR order L is strictly lower than the
CP length Lg, because, in the absence of noise, the last Lg −L samples of the CP are still identical
to the last Lg −L samples of the OFDM block. As a consequence, in multipath channels, it may be
convenient to replace the ﬁrst summation index τ in (5.211) and (5.212) with τ + L. In this case, the
time synchronization performance would be reduced, because the noise averages in (5.211) and (5.212)
are performed over a lower number of samples (Lg −L instead of Lg).
Further improvements to the CP-based approach, are possible by exploiting also the pilot tones that
are typically inserted in the frequency-domain for channel estimation. For instance, [133] proposes to
estimate τoff by
ˆτoff = arg max
τ

ρMCP(τ) +

1 −ρ
	
MFP(τ)

,
(5.214)
where
MFP(τ) = (1 + ρ)
******
τ+Lg−1

n=τ
r∗
nmn−τ
******
−ρ
******
τ+Lg−1

n=τ
(rn + rn+N)∗mn−τ
******
representsthefrequencypilot(FP)contributiontotheMLestimates,andmn isthetime-domainsequence
corresponding to the FP. Further improvements [165] can be obtained by a decision-aided approach,
which reﬁnes the initial (coarse) estimate of ˆτoff by minimizing a cost function, as expressed by
ˆτ

ref
	
off
= arg min
τ
M−1

m=0
***Rm(τ)/ ˆHm(τ) −˜Xm(τ)
***
2

,
ˆτoff −τ ≤τ ≤ˆτoff + τ,
(5.215)
where ˆHm(τ) and ˆXm(τ) are the (frequency-domain) channel and data estimates on the mth carrier,
respectively, which are obtained for a speciﬁc τ in the neighborhood τ of the coarse estimate ˆτoff.
After time synchronization has been performed, the algorithm in [243] compensates for the CFO
similarly to the SCA algorithm in (5.210), as expressed by
ˆε = −1
2π angle(P2(ˆτoff)) = −1
2π tan−1
Im{P2(ˆτoff)}
Re{P2(ˆτoff)}

.
(5.216)
Another possibility, for CFO estimation and frequency synchronization, can exploit the redundancy
in the frequency-domain represented by the insertion of null subcarriers at the edges of the OFDM
spectrum, which are employed as guard frequency bands from adjacent RF channels. Indeed, while in

2.05.16 Capacity for OFDM transmissions: bit and power-loading
269
the presence of perfect synchronization the receiver should perceive only noise on those subcarriers,
the presence of a CFO induces by ICI (see Figure 5.26) a leakage of the data on those guard frequency
bands. Thus, it is possible to perform frequency synchronization by minimizing the energy leakage on
those subcarriers, by simple gradient-based algorithms as proposed in [242] and further analyzed and
discussed in [20] and [153]. Interestingly, this simple approach is robust to frequency-selective channels
and can be applied also in multiuser OFDM communications, with minor modiﬁcations. In a multiuser
set-up, (i.e., OFDMA) where different subcarriers are assigned to different users, the CFO estimation
and synchronization for downlink transmissions can be generally borrowed from classical OFDM, due
to the fact that each user perceives a single (although different) CFO (and time offset) with respect to
the signal transmitted by the base-station (BS). Conversely, in the OFDMA uplink, the BS perceives
the super-position of the signal transmitted by each user, each one characterized by a speciﬁc CFO and
time-offset. Consequently, the estimation problem is more complex and noteworthy synchronization
cannot be performed at the receiver side, but only by proper feedback to each transmitter of its own CFO
and time offset, which have to be pre-compensated for. In order to simplify the estimation problem,
the best strategy is to design different, and orthogonal, training pilots for each user, in such way, the
BS can perform a separate estimation for each CFO (and time offset) [162]. The interested readers are
redirected to [163] for a thorough survey on this subject. Readers interested in a thorough survey of
signal processing algorithms for synchronization are redirected to the E-Reference contribution in [85].
2.05.16 Capacity for OFDM transmissions: bit and power-loading
Multicarrier systems are particularly attractive also due to the straightforward possibility to boost the sys-
tem capacity when a frequency-selective channel is known at the transmitter, as theoretically motivated
by the Shannon water-ﬁlling principle [61,213]. Indeed, OFDM transforms a single-input single-output
(SISO) time-invariant multipath channel in a set of M orthogonal frequency-ﬂat channels, as summa-
rized by (5.65), which is rewritten in the following for the reader convenience
y( f )
k
= diag(h f )dk + w( f )
k
.
(5.217)
Analogously to the classical expression of the capacity of a SISO ﬂat-fading AWGN channel, the
capacity of the diagonal MIMO system in (5.217) with an AWGN term w( f )
k
with covariance matrix
E

w( f )
k
w( f )H
k

= σ 2
wIM, is achievable by a Gaussian distributed data vector dk and is expressed by [61]
COFDM = log2
****IM + 1
σ 2w
DHdDH
H
****
[bits/channel use],
(5.218)
where DH = diag(h f ), d = E{dkdH
k } is the data vector covariance, and |A| stands for the determinant
of the matrix A. Analogously, the capacity of any other system equipped with a CP, which transmits a
vector xk of (possibly precoded) data is expressed by
CCP = log2
****IM + 1
σ 2w
HcpxHH
cp
**** ,

270
CHAPTER 5 OFDM and Multicarrier Signal Processing
where x = E{xkxH
k }. Bearing in mind the Hadamard inequality|A| ≤5M
i=1 [A]i,i (with equality if and
only if A = diag(a)), and reminding that Hcp = FH
MDHFM, and |AB| = |A||B|, it is straightforward
to prove that
****IM + 1
σ 2w
HcpxHcp
**** =
****IM + 1
σ 2w
DHFMxFH
MDH
**** .
Consequently, in order to make the overall argument a diagonal matrix and maximize CCP, it is necessary
that x = FH
MDpFM, with Dp = diag([P0, · · · , PM−1]). This is actually obtained when the transmitted
vector is expressed by xk = FH
Mdk = FH
MD1/2
p
˜dk, i.e., when the system employs CP-OFDM, and
transmits uncorrelated data dk = D1/2
p
˜dk, where d = E{dkdH
k } = Dp contains on the diagonal the
power load on each subcarrier, that is [Dp]m,m = E{|dk,m|2} = Pm, and where PT = M−1
m=0 Pm =
trace(Dp) is the power budget at the transmitter side. For further details on capacity-optimal block
transmissions, the interested readers are redirected to [200].
Thus, it has been established that OFDM is the optimum choice for CP-based transmissions, and
that the transmission of uncorrelated data lets to express (5.218) as
COFDM = log2
****IM + 1
σ 2w
D2
|H|Dp
**** = log2
M
6
m=1

1 + |Hm|2Pm/σ 2
w

=
M

i=1
log2

1 + SNRm
	
,
(5.219)
i.e., as intuitive, the capacity of an OFDM system is the sum of the capacity associated to each (also
statistically) orthogonal channel that experiences an SNRm = |Hm|2Pm/σ 2
w.
The power loading problem consists on the optimal distribution of the power budget PT = M−1
m=0 Pm
among the different subcarriers such that the overall capacity is maximized. Mathematically, this is
expressed by
arg max
Pm
M−1

m=0
log2

1 + Pmγm
	

, s.t.
M−1

m=0
Pm ≤PT ,
, s.t.
Pm ≥0,
∀m,
(5.220)
where γm = |Hm|2/σ 2
w represents the SNR at the receiver side for a unitary transmitted power on each
subcarrier. Thus the OFDM power loading is a convex optimization problem with convex constraints that
admits a unique solution (computable by Lagrange multipliers), which, according to the Kuhn-Tucker
conditions is expressed by [61,213]
P+
m =

ν −1/γm
	+ =
⎧
⎨
⎩
ν −1/γm, ν > 1/γm,
0,
ν < 1/γm,
(5.221)
where λ = −1/ν is the Lagrange multiplier and, consequently, is determined by the power constraint
such that M−1
m=0

ν −1/γm
	+ ≤PT .
The solution (5.221) for maximum capacity power-loading is depicted in Figure 5.35, which clariﬁes
why such a distribution is called the water-ﬁlling (WF) (or water-pouring) principle. Indeed, the total
available power (water) distributes itself on each subcarrier as it would distribute the water poured on

2.05.16 Capacity for OFDM transmissions: bit and power-loading
271
FIGURE 5.35
OFDM subcarrier power loading according to the water-ﬁlling principle.
a vessel whose ﬂoor is represented by the inverse of the “channel” SNR γm. As expected, most of the
power is given to the carrier with the best (e.g., highest) channel |Hm|. However, since the increase in
capacity Cm = log2

1 + Pmγm
	
saturates for increasing power, after a certain amount of power has
been “poured” to the ﬁrst subcarrier, it is convenient to distribute the power also to other subcarriers,
and so forth.
In some standards, such as ADSL [107], there is a limit to the maximum power ¯Pm that can be
assigned to a single subcarrier, which means that the transmitted signal should respect a power spectral
emission mask
 ¯Pm

m=0,...,M−1, which is mainly enforced to control the interference to coexisting
services and systems. Consequently, the optimization problem in (5.220) has a more stringent constraint
0 ≤Pm ≤¯Pm, whose solution can be analogously derived and leads to the so-called “cap-limited”
WF, which means that the vessel where to pour the power resembles a “pipe” which has not only the
ﬂoor 1/γm shown in Figure 5.35 but also the cap 1/γm + ¯Pm. Consequently, the poured water (power)
cannot overpass the cap and the part of water of the classical WF solution that would be over the cap
redistributes inside the “pipe”: the water level increases and more power (up to the cap) is assigned to
other subcarriers (possibly also not used by the classical WF). For more details, see [176] and references
therein.
A dual problem to the capacity (rate) maximization is the minimization of the total transmitted power
subject to a minimum capacity constraint that, due to
Pm =

2Cm −1

/γm
(5.222)

272
CHAPTER 5 OFDM and Multicarrier Signal Processing
is expressed by
arg min
Cm
M−1

m=0

2Cm −1

/γm

, s.t.
M−1
m=0 Cm ≥Cmin,
, s.t. Cm ≥0,
∀m.
(5.223)
Also the solution of (5.223) can be derived by the Lagrange approach, which applying the Kuhn-Tucker
conditions similarly leads to
C+
m =

χ −log2 (1/γm)
	+ ,
(5.224)
where λ = −1/χ is the Lagrange multiplier determined by the capacity constraint such that
M−1
m=0

χ −log2 (1/γm)
	+ = Cmin. By substituting (5.224) in (5.222), it is evident that the optimal
distribution among the subcarriers of the requested capacity Cmin, corresponds to a WF principle on the
associated power, as expressed by
P+
m =

2C+
m −1

/γm =

2χ −1/γm
	+ .
(5.225)
Actually (5.225) is exactly the solution we would obtain by solving a capacity maximization problem
with PT = M−1
m=0 P+
m , and where 2χ is the water level.
Note that the optimal solutions in (5.221) and (5.224) have been obtained for dk belonging to
Gaussian distributed alphabets, and represent information theoretic bounds obtainable by ideal inﬁnite-
length coding and arbitrary small error probability at the receiver side [183]. However, any digital
communication system transmits data dk that belong to ﬁnite alphabets (e.g., M-PSK, M-QAM, etc.)
and suffers a certain SER. This fact can be modeled as an SNR penalty m with respect to an ideal
system, which means that each subcarrier is capable to transmit with a rate per channel use
Rm = log2

1 + Pmγm/m
	
< Cm.
(5.226)
The rationale behind (5.226) is to associate the rate penalty Rm < Cm to a BER penalty suffered by the
practical system with respect to an ideal one. Indeed, if we focus on an M-QAM constellation on each
subcarrier, it is known that the SER can be approximated as [183]
SER ≃4Q
'
3SNRm
Mm −1
(
= 4Q
'
3Pmγm
2bm −1
(
,
(5.227)
which inverted with respect to bm gives
bm ≃log2
'
1 +
Pmγm
1
3 Q−1 
SER/4
	
(
.
(5.228)
Actually, (5.228) represents the approximated (non-integer) number of bits it is possible to load on the
mth subcarrier for a target SER and, interestingly, it can be interpreted as (5.226) with
m = fM-QAM(SER) = 1
3 Q−1 
SER/4
	
. More generally, (5.226) can be used with m = f (SER)/Gc,
where f

SER
	
depends on the speciﬁc modulation and Gc represents the SNR gain granted by the

2.05.16 Capacity for OFDM transmissions: bit and power-loading
273
channel coding that is employed. Once m is known for a speciﬁc modulation/coding scheme, a prac-
tical system such as ADSL [107] may be interested to the best way to allocate (load) the power Pm and
the bits bm (e.g., determine the constellation size Mm = 2bm to be used) on the mth subcarrier, in order
to maximize the sum rate M−1
m=0 bm for a given power budget PT = M−1
m=0 Pm, and target (uncoded)
SER. Thus, in view of (5.226) and (5.228), the problem can be formalized by (5.220), substituting γm
with γ ′
m = γm/m, and the solutions are
P+
m =

ν −m/γm
	+ =
⎧
⎨
⎩
ν −m/γm, ν > m/γm,
0,
ν < m/γm,
(5.229)
bm =
7
log2

1 + γm
m
P+
m
8
=
7
log2
 γm
M
ν
8
,
(5.230)
where ⌊·⌋is the rounding operator to obtain an integer number of bits, and ν is determined by
M−1
m=0

ν −m/γm
	+ = PT . Similarly (5.224) and (5.225) can be adapted to solve the dual prob-
lem to distribute a given number of bits BT = M−1
m=0 bm on the different subcarriers in order to employ
the minimum amount of power M−1
m=0 Pm, for a target SER.
The highest complexity of all the water-ﬁlling approaches is represented by the identiﬁcation of the
water level (i.e., ν in Figure 5.35), or equivalently of the Lagrange multiplier. Different strategies have
been proposed in the literature: see [130], and [176] and the references therein.
In the rate-maximization case, the water level is determined by the constraint equation
M−1
m=0 (ν −1/γm)+ = PT , (using γm/m to include the system margin [57]). Consequently, indi-
cating with IA = {m ∈[0, M −1] : (ν −1/γm) > 0} the set of subcarrier indexes that are effectively
loaded with a power Pm > 0, it is straightforward to derive that the water level is expressed by
ν

MA
	
= PT
MA
+
1
MA
MA−1

m=0
1/γm,
(5.231)
where MA = |IA| is the number of active subcarriers. Thus, the problem consists in the identiﬁcation
of those subcarriers that participate to the water-ﬁlling. It is obvious that the best subcarrier, i.e., the
subcarrier with the highest channel SNR γm is included in IA, and probably also the second-best
subcarrier, and so forth, while maybe the power is not enough to include the worst subcarrier with the
lowest γm. This observation has inspired a bunch of similar algorithms, which are based on sorting the
subcarrier indexes in increasing (or decreasing) γm, as shown in Figure 5.36, which considers the same
(ordered) WF problem of Figure 5.35.
Figure 5.36 highlights that the water level ν has to be such that 1/γMA−1 ≤ν < 1/γMA: this
observation together with (5.231) suggests to identify the (sorted) subcarriers that participate to the
water pouring by searching the only integer in [0, M −1] that satisﬁes both
ν

MA
	
≥1/γMA−1
and ν

MA + 1
	
< 1/γMA.
(5.232)
Once MA [and ν

MA
	
] is known, the bit and power loading that maximize the sum-rate can be performed
by (5.229) and (5.230). Similar consideration can be drawn for the bit and power loading that minimizes
the power consumption for a target sum-rate.

274
CHAPTER 5 OFDM and Multicarrier Signal Processing
FIGURE 5.36
Water ﬁlling with subcarrier ordered by their channel SNR γm.
It should be observed that the solution in (5.230) is suboptimal because the bit-loading problem is
actually an integer optimization problem. Conversely, it has been solved by a relaxation approach [35]
to the real optimization problem in (5.220) by ignoring the further constraint log2

1 + Pmγm
	
∈Z+
0 ,
and rounding the real solution to the closest integer. The true integer optimization problem can be solved
by greedy algorithms [11], which are iterative algorithms that (i) deﬁne a cost function associated to a
unitary increment/decrement of the possible (integer) solution to the bit-loading problem, (ii) at every
step moves towards the solution (among the ones at a unit step distance) characterized by the lowest
value of the cost function, (iii) they never trace back to an already explored solution. By observing
(5.226), and denoting with P(+)
m
(Rm) the power cost to add a bit to Rm, it is possible to write
Rm + 1 = log2

1 + (Pm + P(+)
m
)γm/m

,
(5.233)
which solved with respect to P(+)
m
together with (5.226) leads to
P(+)
m
= 2Rm+1 −1
γm/m
−Pi =
2Rm
γm/m
.
(5.234)
Analogously, the power saving P(−)
m
(Rm) granted by reducing Rm to Rm −1 is
P(−)
m
= 2Rm−1 −1
γm/m
−Pi = 2Rm−1
γm/m
.
(5.235)
Note that (5.234) and (5.235) are monotone convex cost and revenue functions, respectively. Conse-
quently, when integer and convex optimization problems [such as (5.220) with the additional constraint
log2

1 + Pmγm
	
∈Z+
0 ] are solved by means of iterative greedy algorithms based on the functions

2.05.17 Further research topics and directions
275
(5.234) and (5.235), the convergence to a unique and optimal solution is guaranteed. Thus, a simple
(bit-ﬁlling) algorithm that exploits (5.234) is that one that iteratively assigns an incremental bit to the
subcarrier that requests the lower incremental cost in term of power, until the power budget is ﬁnished.
This algorithm is summarized by the following pseudo code.
1. Set k = 0, Ps = 0, bm = 0, and Pm = 0, m = 0, . . . , M −1
2. compute P(+)
m
= 2bm/(γm/m), m = 0, . . . , M −1
3. set m∗= arg min
m

P(+)
m

;
4. Ps = Ps + P(+)
m∗;
5. if Ps ≤PT
6.
bm∗= bm∗+ 1;
7.
Pm∗= Pm∗+ P(+)
m∗;
8.
go to Step 2
9. end
The previous algorithm, as intuitive, starts assigning the ﬁrst bit to the subcarrier m with the best channel
(highest γm = |Hm|2/σ 2
w assuming the SNR margin m =  is the same for all the subcarriers).
However, due to the fact that the rate (capacity) does not increase linearly with the power, it could cost
less power to assign the second bit to another subcarrier (i.e., the second-best subcarrier) and so forth.
Similar greedy algorithms, which exploit (5.235), are called bit-removal algorithms, and the interested
readers are redirected to [176] and references therein, for further details.
Instead of rate maximization or transmitted power minimization approaches, other approaches may
be considered, such as the SNR maximization approach of [78]. Readers interested in more advanced
algorithms for ADSL power- and bit-loading are redirected to the E-Reference contribution in [137].
Finally, it should be observed that the algorithms discussed so far address the bit and power loading
optimization for single-user (SU) scenarios. The multiuser (MU) case, which is more complicated,
has been investigated, for instance, in [258] and [124]. An effective approach to solve the MU bit and
power loading problem, is to split it in multiple SU optimization problems, which are run sequentially
and iteratively, each one looking for the optimal solution for a speciﬁc user and assuming the power
allocated to the other users as interference that adds to the Gaussian noise. It has been proven for
instance that the MU water-ﬁlling problem can be accurately solved this way, with a guaranteed and fast
convergence to the unique optimal solution. About this point, the interested readers may ﬁnd detailed
information in [47,109,205,206,214,261,262]. Another survey to inspire optimal allocation strategies
is the E-Reference contribution of [151].
2.05.17 Further research topics and directions
In the following we shortly comment a non-exhaustive list of research topics that we did not consider
in the previous sections: these topics have attracted a signiﬁcant research effort in the recent years and
we believe they may continue to be appealing in the near-future.

276
CHAPTER 5 OFDM and Multicarrier Signal Processing
2.05.17.1 Power and bit loading with CSI information feedback
The availability of CSI information at the transmitter side can rely either on the use of symmetric time-
domain duplexing between two transceivers, or on channel feedback from the receiver to the transmitter.
In this second view, a critical factor is the coherence time of the channel which has to be signiﬁcantly
greater than the round-trip propagation/processing delay in order for the fed-back CSI to be not outdated.
In this framework, there is substantial trade-off between the amount of the CSI information that is fed-
back from the receiver (capacity loss) and the increase in rate this CSI is capable to guarantee (capacity
gain) [54,150].
For instance, in MIMO-OFDM, a possible way to reduce the amount of feed-back information is the
use of codebooks which are predeﬁned, and the receiver only select the best one to be used for the actual
channel and accordingly informs the transmitter [55,121]. Limited feedback schemes for OFDMA have
been investigated in [3,50], and [131].
2.05.17.2 Time-varying channel estimation and equalization for MIMO, and
underwater communications
The estimation, equalization and linear precoding for OFDM and MC time-varying channels have
been quite investigated topics in the recent past [41,56,74,75,90,110,152,181,193,204,230,265,304].
Although some results have been extended to MIMO scenarios [125,192,224,227], this is an area where
improvements are still possible, for instance, to design efﬁcient sounding techniques coupled with low
complexity implementations of channel estimation, tracking, and equalization [1,49,83].
Moreover, OFDM and MC communications, have been recently considered as a viable technol-
ogy for underwater communications and sensor networks [140,182,291], where the ultrasound waves
are typically the preferred choice for medium-range distances, in shallow-water environments [147].
Notably, wireless underwater communications present harder challenges with respect to air communi-
cations: the propagation channel is characterized by a very rich multi-path (especially in shallow-water),
the Doppler effect is exacerbated by the reduced speed of ultrasound with respect to electromagnetic
waves, and further (time-varying) distortions are also introduced by the movements of the propagation
medium, which is not observed in electromagnetic communications. Thus, base-band signal processing
algorithms developed for classical air-based OFDM and MC systems should be adapted, or completely
redesigned, to take into account for more sophisticated system models. For instance, as already high-
lighted is Section 2.05.11, the reduced speed of ultrasound propagation does not allow to ignore the
time-scale distortion in (5.171) which induces time-varying delays τl(t) in the channel impulse response
and non uniform Doppler shifts [142,143]. Actually, the time-scale change could be different for each
single path, depending on its direction of arrival. Although some possible solution to deal with [115] and
compensate (e.g., equalize) such different channels have been recently proposed in [100,240,255,260]
this is still a quite active research ﬁeld including its MIMO implementation [45,180,126,141].
2.05.17.3 OFDM-based cognitive radio applications
The cognitive radio paradigm [96,160] is one of the most investigated topics in the last decade, due to the
potentiality for secondary opportunistic networks to exploit the unused resources (in time, frequency,

2.05.17 Further research topics and directions
277
space, codes, etc.) of primary legacy networks. Due to the fact that OFDM is the underlying modulation
of several primary users’ networks (i.e., DVB-T/H, WiFi, WiMAX, UMTS-LTE. etc.), the secondary
users networks can exploit the knowledge of the OFDM signal structure (e.g., multitones, CP, almost
Gaussian distribution) to design efﬁcient statistical inference (spectrum sensing) on the presence or
absence of a primary users to potentially exploit vacant resources [9,10,13,138]. OFDMA, due to
its ﬂexibility to allocate frequencies to a speciﬁc user is one of the natural candidates to deploy a
secondary network that accommodate to its users those frequencies that are not in use in the primary
network.
If the secondary network is equipped with multiple-antennas further degrees of freedom are available
to possibly cancel or minimize the interference towards the primary users. This approach falls within
the more general topic of interference alignment [39,40,70,155], which is recently revitalizing research
efforts on MIMO-based resource management for multi-user and multi-cell communications. Anyway,
in order to exploit the potentiality of cognitive-radio communications, it is of fundamental importance
that the network has knowledge both of the spatial distribution of the electromagnetic ﬁelds, as well
as of the channel gains each couple of node in the primary and secondary networks is linked with.
Due to the sparsity of the users in the coverage area, channel sounding and estimation techniques can
exploit quite recent results coming from compressive and sparse sampling theories [31,43,159], as for
instance in [7,25,119,267]. Noteworthy, these approaches can also be exploited for channel estimation
of OFDM communications when the channel is sparse [232]. Readers interested in thorough survey for
spectrum sensing in cognitive radio is redirected to the E-Reference contribution of [86].
2.05.17.4 Filterbank multicarriers
Another variant of multicarrier communications that recently attracted a signiﬁcant research effort is
ﬁlter-bank multicarrier (FBMC) [4,22,36,51,76,91,128,156,220]. The basic idea is that the data on
each subcarrier can be (differently) ﬁltered, in such a way to exhibits a spectrum different from the
sinc-shaped one of classical-OFDM. Moreover, also the time support of each symbol may extend to
more than a single multicarrier block (possibly introducing controlled ISI/IBI) and the use of CP is
no longer fundamental and can be avoided. The higher degrees of freedom available can be exploited
by properly designing the transmitter (and receiver) ﬁlterbanks in order to fulﬁll speciﬁc requests
[34,157,238]. For instance, it is possible to reduce the spectral leakage of each subcarrier spectrum on
adjacent subcarriers making FBMC less sensitive to CFO problems [81,149] and also an interesting
option for OFDMA-like implementation of secondary networks in cognitive-radio-systems [77]. The
price to pay for the ﬂexibility of FBMC is an increased implementation complexity, especially, at the
receiver side, where channel estimation and equalization are not trivial [101,106], and for multiuser
and MIMO implementations, where still some research effort is required to make FBMC an attractive
and practical modulation for future wireless standards.
2.05.17.5 OFDM-based relay communications
Relay-based communications is another topic that is attracting the interests of the wireless research
community because of the potential increase in capacity, reliability, and coverage area of communication
networks [134,170]. In addition to classical relaying strategies, the use of relays as virtual antennas

278
CHAPTER 5 OFDM and Multicarrier Signal Processing
lead to the so-called distributed ST-coding approaches [135], and naturally ask for an OFDM-based
implementation in order to turn frequency-selective fading channels into frequency-ﬂat-fading channels.
The multi-hop relay system of [248] aim at maximizing the system capacity using joint subcarrier
matching and power allocation with separate power constraints. Different power allocation techniques
are proposed: the optimal joint subcarrier matching and power allocation, and a reduced-complexity
suboptimal scheme. Simulation results in [248] have shown that the capacity of the optimal scheme
approaches the upper bound of the system capacity, and that the capacity of the suboptimal scheme is also
quite close. For comparison purposes, the low-complexity one-to-one subcarrier matching technique
is also included in [248]. Resource allocation algorithms for cooperative OFDM systems have been
proposed also in [62,154,175].
The power allocation algorithms in [92] target the two-hop MIMO-OFDM case. Both frequency
and space domains are considered, in order to maximize the instantaneous rate when channel state
information at the transmitter is available. Two approaches are investigated: separate power-allocation
optimization with individual per-node transmit-power constraints, and joint power-allocation optimiza-
tion with joint transmit power constraint. The results of [92] also show that alternately repeating the
separate optimization converges, and improves the achievable rate of the considered link.
In [68], a cooperative OFDM system with precoding is proposed, with the aim of collecting the
available multipath diversity. In this case, the diversity order is given by the summation of the channel
length in the direct link and the minimum of channel lengths in each relaying link. Two relaying strategies
are compared: although the per-subcarrier basis strategy performs better, also the all-subcarrier basis
strategy gives a performance improvement with respect to OFDM without cooperation. Additionally,
relay selection methods are included in [68]. The work in [221] proposes a diversity-achieving protocol
that makes use of limited feedback. Analytical studies about the performance of OFDM with amplify-
and-forward relays have been carried out, for instance, in [228].
The ST cooperative design of [217] demonstrates the overall performance advantage of a cooperative
OFDM system over an OFDM system without cooperation, not only under ideal conditions, but also
in the presence of synchronization and channel estimation errors. Channel estimation is investigated
also in OFDM systems with two-way relay networks, where the relays allow for bidirectional com-
munications [82]. A two-phase channel-estimation training protocol is proposed, in order to maintain
the compatibility with the two-phase data transmission scheme. First, a block-based training is studied,
for the estimation of the cascaded source-relay-source channels. Second, a pilot-tone-based training
is considered in [82], for the direct estimation of the individual channels between sources and relay.
CFO mitigation is critical also in OFDM-based cooperative transmissions, especially when the num-
ber of cooperative transmitters or relays is large. In [142], the CP is exploited to mitigate the CFO.
Depending on the CP length, the CFO error can be reduced or even eliminated. In [190], focusing on the
relay-destination links, two pilot-aided algorithms for the joint estimation of the CFOs and the CIRs are
proposed. The ﬁrst algorithm uses a BEM to turn the joint estimation problem into the estimation of an
LTV channel, from which CFOs and CIRs are extracted using ESPRIT. The second algorithm exploits
a speciﬁc pilot structure and estimates the CFOs by directly applying ESPRIT on the observed signal.
Channel estimation in the presence of CFO has been investigated also in [264]. Readers interested in
signal processing algorithms for (distributed) cooperative systems are redirected to the E-Reference
contribution in [21].

References
279
Relevant Theory: Signal Processing Theory
See Vol. 1, Chapter 2 Continuous-Time Signals and Systems
See Vol. 1, Chapter 3 Discrete-Time Signals and Systems
See Vol. 1, Chapter 9 Discrete Multi-Scale Transforms in Signal Processing
See Vol. 1, Chapter 7 Multirate Signal Processing for Software Radio Architectures
References
[1] N. Aboutorab, W. Hardjawana, B. Vucetic, A new iterative Doppler-assisted channel estimation joint with
parallel ICI cancellation for high-mobility MIMO-OFDM systems, IEEE Trans. Veh. Technol. 61 (4) (2012)
1577–1589.
[2] M. Abramowitz, I.A. Stegun, Handbook of Mathematical Functions: With Formulas, Graphs, and Mathe-
matical Tables, 10th printing, Dover Publications, New York, 1972.
[3] R. Agarwal, V. Majjigi, Z. Han, R. Vannithamby, J. Ciofﬁ, Low complexity resource allocation with oppor-
tunistic feedback over downlink OFDMA networks, IEEE J. Sel. Areas Commun. 26 (8) (2008) 1462–1472.
[4] A.N. Akansu, P. Duhamel, X. Lin, M. de Courville, Orthogonal transmultiplexers in communication: a
review, IEEE Trans Signal Process. 46 (4) (1998) 979–995.
[5] S.M. Alamouti, A simple transmit diversity technique for wireless communications, J. Sel. Areas Commun.
16 (8) (1998) 1451–1458.
[6] S. Andreoli, H.G. McClure, P. Banelli, S. Cacopardi, Digital linearizer for RF ampliﬁers, IEEE Trans.
Broadcast. 43 (1) (1997) 12–19.
[7] D. Angelosante, G.B. Giannakis, N.D. Sidiropoulos, Estimating multiple frequency-hopping signal param-
eters via sparse linear regression, IEEE Trans. Signal Process. 58 (10) (2010) 5044–5056.
[8] J. Armstrong, Peak-to-average power reduction for OFDM by repeated clipping and frequency domain
ﬁltering, Electron. Lett. 38 (8) (2002) 246–247.
[9] E. Axell, E.G. Larsson, Optimal and sub-optimal spectrum sensing of OFDM signals in known and unknown
noise variance, IEEE J. Sel. Areas Commun. 29 (2) (2011) 290–304.
[10] E. Axell, G. Leus, E.G. Larsson, H.V. Poor, Spectrum sensing for cognitive radio: state-of-the-art and recent
advances, IEEE Signal Process. Mag. 29 (3) (2012) 101–116.
[11] E. Baccarelli, M. Biagi, Optimal integer bit-loading for multicarrier ADSL systems subject to spectral-
compatibility limits, Signal Process. 84 (4) (2004) 729–741.
[12] A.R.S.Bahai,B.R.Saltzberg,M.Ergen,Multi-CarrierDigitalCommunications,seconded.,Springer,Boston,
2004.
[13] G. Bafna, P. Banelli, L. Rugini, Three-stage centralized spectrum sensing of OFDM signals, in: IEEE Int.
Work. Signal Process. Adv. Wireless Commun, San Francisco, CA, June, 2011, pp. 26–29.
[14] P. Banelli, Theoretical analysis and performance of OFDM signals in nonlinear fading channels, IEEE Trans.
Wireless Commun. 2 (2) (2003) 284–293.
[15] P. Banelli, S. Cacopardi, Theoretical analysis and performance of OFDM signals in nonlinear AWGN chan-
nels, IEEE Trans. Commun. 48 (3) (2000) 430–441.
[16] P. Banelli, G. Baruffa, Mixed BB-IF predistortion of OFDM signals in non-linear channels, IEEE Trans.
Broadcast. 47 (2) (2001) 137–146.
[17] P. Banelli, G. Baruffa, S. Cacopardi, Effects of HPA non linearity on frequency multiplexed OFDM signals,
IEEE Trans. Broadcast. 47 (2) (2001) 123–136.

280
CHAPTER 5 OFDM and Multicarrier Signal Processing
[18] P. Banelli, R.C. Cannizzaro, L. Rugini, Data-aided Kalman tracking for channel estimation in Doppler-
affected OFDM systems, in: IEEE Int. Conf. Acoust. Speech Signal Process., Honolulu, HI, April 15–20,
2007.
[19] P. Banelli, L. Rugini, An H-inﬁnity ﬁltering approach for robust tracking of OFDM doubly-selective channels,
in: IEEE Int. Work. Signal Process. Adv. Wireless Commun, Marrakech, Morocco, June 2010, pp. 20–23.
[20] S. Barbarossa, M. Pompili, G.B. Giannakis, Channel-independent synchronization of orthogonal frequency
division multiple access systems, IEEE J. Sel. Areas Commun. 20 (2) (2002) 474–486.
[21] S. Barbarossa, Distributed estimation and detection with applications in wireless communication and sensing
networks, E-Reference Signal Processing, Elsevier, 2013.
[22] A. Barbieri, D. Fertonani, G. Colavolpe, Time-frequency packing for linear modulations: Spectral efﬁciency
and practical detection schemes, IEEE Trans. Commun. 57 (10) (2009) 2951–2959.
[23] G. Baruffa, G. Reali, A fast algorithm to ﬁnd generic odd and even order intermodulation products, IEEE
Trans. Wireless Commun. 6 (10) (2007) 3749–3759.
[24] E. Bayer-Fluckiger, F. Oggier, E. Viterbo, New algebraic constructions of rotated Zn-lattice constellations
for the Rayleigh fading channel, IEEE Trans. Inform. Theory 50 (4) (2004) 702–714.
[25] J.A. Bazerque, G.B. Giannakis, Distributed spectrum sensing for cognitive radio networks by exploiting
sparsity, IEEE Trans. Signal Process. 58 (3) (2010) 1847–1862.
[26] R.W. Bäuml, R.F.H. Fisher, J.B. Huber, Reducing the peak-to-average power ratio of multicarrier modulation
by selected mapping, Electron. Lett. 32 (22) (1996) 2056–2057.
[27] P. Bello, Characterization of randomly time-variant linear channels, IEEE Trans. Commun. Syst. 11 (4)
(1963) 360–393.
[28] S. Benedetto, E. Biglieri, Principles of Digital Transmission: With Wireless Applications, Kluwer Academic
/ Plenum Publishers, New York, 1999.
[29] J.A.C. Bingham, Multicarrier modulation for data transmission: an idea whose time has come, IEEE Com-
mun. Mag. 28 (5) (1990) 5–14.
[30] N. Blachman, Band-pass nonlinearities, IEEE Trans. Inform. Theory 10 (2) (1964) 162–164.
[31] T. Blu, P.-L. Dragotti, M. Vetterli, P. Marziliano, L. Coulot, Sparse sampling of signal innovations, IEEE
Signal Process. Mag. 25 (2) (2008) 31–40.
[32] J. Boutros, E. Viterbo, Signal space diversity: a power- and bandwidth-efﬁcient diversity technique for the
Rayleigh fading channel, IEEE Trans. Inform. Theory 44 (4) (1998) 1453–1467.
[33] D.K. Borah, B.T. Hart. Frequency-selective fading channel estimation with a polynomial time-varying chan-
nel model. IEEE Trans. Commun. 47 (6) (1999) 862–873.
[34] B. Borna, T.N. Davidson, Efﬁcient design of FMT systems, IEEE Trans. Commun. 54 (5) (2006) 794–797.
[35] S. Boyd, L. Vandenberghe, Convex Optimization, Cambridge University Press, Cambidge, UK, 2004.
[36] H. Bölcskei, Orthogonal frequency division multiplexing based on offset QAM, in: H.G. Feichtinger, T.
Strohmer (Eds.), Advances in Gabor Analysis, Birkhäuser, Boston, 2003.
[37] H. Bölcskei, MIMO-OFDM wireless systems: Basics, perspectives, and challenges, IEEE Wireless Commun.
13 (4) (2006) 31–37.
[38] A. Bury, J. Egle, J. Lindner, Diversity comparison of spreading transforms for multicarrier spread spectrum
transmission, IEEE Trans. Commun. 51 (5) (2003) 774–781.
[39] V.R. Cadambe, S.A. Jafar, Interference alignment and degrees of freedom of the K-user interference channel,
IEEE Trans. Inform. Theory 54 (8) (2008) 3425–3441.
[40] V.R. Cadambe, S.A. Jafar, S. Shamai, Interference alignment on the deterministic channel and appli-
cation to fully connected Gaussian interference networks, IEEE Trans. Inform. Theory 55 (1) (2009)
269–274.
[41] X. Cai, G.B. Giannakis, Bounding performance and suppressing intercarrier interference in wireless mobile
OFDM, IEEE Trans. Commun. 51 (12) (2003) 2047–2056.

References
281
[42] X. Cai, S. Zhou, G.B. Giannakis, Group-orthogonal multicarrier CDMA, IEEE Trans. Commun. 52 (1)
(2004) 90–99.
[43] E.J. Candes, M.B. Wakin, An introduction to compressive sampling, IEEE Signal Process. Mag. 25 (2)
(2008) 21–30.
[44] C.R. Cannizzaro, P. Banelli, G. Leus, Adaptive channel estimation for OFDM systems with Doppler spreads,
in: IEEE Int. Work. Signal Process. Adv. Wireless Commun, Cannes, France, July 2006, pp. 2–5.
[45] P.C. Carrascosa, M. Stojanovic, Adaptive channel estimation and data detection for underwater acoustic
MIMO-OFDM systems, IEEE J. Ocean. Eng. 35 (3) (2010) 635–646.
[46] R. Cendrillon, M. Moonen, Efﬁcient equalizers for single and multi-carrier environments with known symbol
padding, in: IEEE Int. Symp. Signal Process. Appl., Kuala Lumpur, Malaysia, August 13–16, 2001.
[47] R. Cendrillon, W. Yu, M. Moonen, J. Verlinden, T. Bostoen, Optimal multiuser spectrum balancing for digital
subscriber lines, IEEE Trans. Commun. 54 (5) (2006) 922–933.
[48] R.W. Chang, Synthesis of band-limited orthogonal signals for multichannel data transmission, Bell Syst.
Tech. J. 45 (10) (1966) 1775–1796.
[49] B.-S. Chen, C.-Y. Yang, W.-J. Liao, Robust fast time-varying multipath fading channel estimation and
equalization for MIMO-OFDM systems via a fuzzy method, IEEE Trans. Veh. Technol. 61 (4) (2012) 1599–
1609.
[50] J. Chen, R. Berry, M. Honig, Limited feedback schemes for downlink OFDMA based on sub-channel groups,
IEEE J. Sel. Areas Commun. 26 (8) (2008) 1451–1461.
[51] G. Cherubini, E. Eleftheriou, S. Ölçer, J.M. Ciofﬁ, Filter bank modulation techniques for very high speed
digital subscriber lines, IEEE Commun. Mag. 38 (5) (2000) 98–104.
[52] H. Chen, A.M. Haimovich, Iterative estimation and cancellation of clipping noise for OFDM signals. IEEE
Commun. Lett. 7 (7) (2003) 305–307.
[53] T.D. Chiueh, P.Y. Tsai, OFDM Baseband Receiver Design for Wireless Communications, Wiley, Singapore,
2007.
[54] E.H. Choi, W. Choi, J.G. Andrews, B.F. Womack, Power loading using order mapping in OFDM systems
with limited feedback, IEEE Signal Process. Lett. 15 (2008) 545–548.
[55] J. Choi, R.W. Heath, Interpolation based transmit beamforming for MIMO-OFDM with limited feedback,
IEEE Trans. Signal Process. 53 (11) (2005) 4125–4135.
[56] Y.-S. Choi, P.J. Voltz, F.A. Cassara, On channel estimation and detection for multicarrier signals in fast and
selective Rayleigh fading channels, IEEE Trans. Commun. 49 (8) (2001) 1375–1387.
[57] P.S. Chow, J.M. Ciofﬁ, J.A.C. Bingham, A practical discrete multitone transceiver loading algorithm for data
transmission over spectrally shaped channels, IEEE Trans. Commun. 43 (2/3/4) (1995) 773–775.
[58] P.S. Chow, J.C. Tu, J.M. Ciofﬁ, Performance evaluation of a multichannel transceiver system for ADSL and
VHDSL services, IEEE J. Sel. Areas Commun. 9 (6) (1991) 909–919.
[59] L.J. Cimini, Analysis and simulation of a digital mobile channel using orthogonal frequency division mul-
tiplexing, IEEE Trans. Commun. 33 (7) (1985) 665–675.
[60] COST 207, Digital land mobile radio communications, Ofﬁce for Ofﬁcial Publications of the European
Communities, Final report, Luxembourg, 1989.
[61] T.M. Cover, J.A. Thomas, Elements of Information Theory, John Wiley & Sons, New York, 1991.
[62] W. Dang, M. Tao, H. Mu, J. Huang, Subcarrier-pair based resource allocation for cooperative multi-relay
OFDM systems, IEEE Trans. Wireless Commun. 9 (5) (2010) 1640–1649.
[63] D. Dardari, Joint clip and quantization effects characterization in OFDM receivers, IEEE Trans. Circ. Syst.
I, Reg. Papers 53 (8) (2006) 1741–1748.
[64] D. Dardari, V. Tralli, A. Vaccari, A theoretical characterization of nonlinear distortion effects in OFDM
systems, IEEE Trans. Commun. 48 (10) (2000) 1755–1764.

282
CHAPTER 5 OFDM and Multicarrier Signal Processing
[65] W.B. Davenport, W.L. Root, An Introduction to the Theory of Random Signals and Noise, McGraw-Hill,
New York, 1958.
[66] T. Davidson, The art of communicating over MIMO channels: contemporary perspectives, E-Reference
Signal Processing, Elsevier, 2013.
[67] L. Ding, G.T. Zhou, D.R. Morgan, Z. Ma, J.S. Kenney, J. Kim, C.R. Giardina, A robust digital baseband
predistorter constructed using memory polynomials, IEEE Trans. Commun. 52 (1) (2004) 159–165.
[68] Y. Ding, M. Uysal, Amplify-and-forward cooperative OFDM with multiple-relays: performance analysis
and relay selection methods, IEEE Trans. Wireless Commun. 8 (10) (2009) 4963–4968.
[69] M.L. Doelz, E.T. Heald, D.L. Martin, Binary data transmission techniques for linear systems, Proc. IRE 45
(1957) 656–661.
[70] O.ElAyach,S.W.Peters,R.W.Heath,ThefeasibilityofinterferencealignmentovermeasuredMIMO-OFDM
channels, IEEE Trans. Veh. Technol. 59 (9) (2010) 4309–4321.
[71] ETSI European Telecommunications Standards Institute, Digital audio broadcasting (DAB): data
broadcasting—MPEG-2 TS streaming, ETSI TS 102 427, V1.1.1, Sophia Antipolis, France, July 2005.
[72] ETSI European Telecommunications Standards Institute, Digital video broadcasting (DVB): framing struc-
ture channel coding and modulation for digital terrestrial television, ETSI EN 300 744, V1.5.1, Sophia
Antipolis, France, November 2004.
[73] ETSI, European Telecommunications Standards Institute, Digital Video Broadcasting (DVB), Frame struc-
ture channel coding and modulation for a second generation digital terrestrial television broadcasting system
(DVB-T2), ETSI EN 302 755, V1.1.1, Sophia Antipolis, France, September 2009.
[74] K. Fang, L. Rugini, G. Leus, Block transmissions over doubly selective channels: iterative channel estimation
and turbo equalization, EURASIP J. Adv. Signal Process. (2010) 1–13 Article ID 974652.
[75] K. Fang, L. Rugini, G. Leus, Low-complexity block turbo equalization for OFDM systems in time-varying
channels, IEEE Trans. Signal Process. 56 (11) (2008) 5555–5566.
[76] B. Farhang-Boroujeny, OFDM versus ﬁlter bank multicarrier, IEEE Signal Process. Mag. 28 (3) (2011)
92–112.
[77] B. Farhang-Boroujeny, R. Kempter, Multicarrier communication techniques for spectrum sensing and
communication in cognitive radios, IEEE Commun. Mag. 46 (4) (2008) 80–85.
[78] R.F.H. Fischer, J.B. Huber, A new loading algorithm for discrete multitone transmission, in: IEEE Global
Telecommun. Conf., London, UK, November 18–22, 1996.
[79] G.J. Foschini, M.J. Gans, On limits of wireless communications in a fading environment when using multiple
antennas, Wireless Pers. Commun. 6 (3) (1998) 311–335.
[80] J.C.Fuenzalida,O.Shimbo,W.L.Cook,Time-domainanalysisofintermodulationeffectscausedbynonlinear
ampliﬁers, COMSAT Tech. Rev. 3 (1) (1973) 89–143.
[81] T. Fusco, A. Petrella, M. Tanda, Data-aided symbol timing and CFO synchronization for ﬁlter bank multi-
carrier systems, IEEE Trans. Wireless Commun. 8 (5) (2009) 2705–2715.
[82] F. Gao, R. Zhang, Y.-C. Liang, Channel estimation for OFDM modulated two-way relay networks, IEEE
Trans. Signal Process. 57 (11) (2009) 4443–4455.
[83] J. Gao, H. Liu, Low-complexity MAP channel estimation for mobile MIMO-OFDM systems, IEEE Trans.
Wireless Commun. 7 (3) (2008) 774–780.
[84] D. Gesbert, M. Shaﬁ, D. Shiu, P.J. Smith, A. Naguib, From theory to practice: An overview of MIMO
space-time coded wireless systems, IEEE J. Sel. Areas Commun. 21 (3) (2003) 281–302.
[85] M. Ghogho, Synchronization and localization, E-Reference Signal Processing, Elsevier, 2013.
[86] G.B. Giannakis, Spectrum Sensing for Cognitive Radio, E-reference Signal Processing, Elsevier, 2013.
[87] X. Giraud, E. Boutillon, J.C. Belﬁore, Algebraic tools to build modulation schemes for fading channels,
IEEE Trans. Inform. Theory 43 (3) (1997) 938–952.

References
283
[88] A. Goldsmith, S.A. Jafar, N. Jindal, S. Vishwanath, Capacity limits of MIMO channels, IEEE J. Sel. Areas
Commun. 21 (5) (2003) 684–702.
[89] G.H. Golub, C.F. Van Loan, Matrix Computations, third ed., Johns Hopkins University Press, London, UK,
1996.
[90] A. Gorokhov, J.-P. Linnartz, Robust OFDM receivers for dispersive time-varying channels: equalization and
channel acquisition, IEEE Trans. Commun. 52 (4) (2004) 572–583.
[91] R. Haas, J.-C. Belﬁore, A time-frequency well-localized pulse for multiple carrier transmission, Wireless
Pers. Commun. 5 (1) (1997) 1–18.
[92] I. Hammerstrom, A. Wittneben, Power allocation schemes for amplify-and-forward MIMO-OFDM relay
links, IEEE Trans. Wireless Commun. 6 (8) (2007) 2798–2802.
[93] S.H. Han, J.H. Lee, An overview of peak-to-average power ratio reduction techniques for multicarrier trans-
mission, IEEE Wireless Commun. 12 (2) (2005) 56–65.
[94] L. Hanzo, M. Münster, B.J. Choi, T. Keller, OFDM and MC-CDMA for Broadband Multi-User Communi-
cations, WLANs and Broadcasting, IEEE Press/John Wiley & Sons, Chichester, UK, 2003.
[95] S. Hara, R. Prasad, Overview of multicarrier CDMA, IEEE Commun. Mag. 35 (12) (1997) 126–133.
[96] S. Haykin, Cognitive radio: brain-empowered wireless communications, IEEE J. Sel. Areas Commun. 23
(2) (2005) 201–220.
[97] F. Hlawatsch, G. Matz, Wireless Communications Over Rapidly Time-Varying Channels, Academic Press,
Oxford, UK, 2011.
[98] P. Hoeher, S. Kaiser, P. Robertson, Two-dimensional pilot-symbol-aided channel estimation by Wiener
ﬁltering, in: IEEE Int. Conf. Acoust. Speech Signal Process., Munich, Germany, April 21–24, 1997.
[99] T. Hrycak, S. Das, G. Matz, H.G. Feichtinger, Practical estimation of rapidly varying channels for OFDM
systems, IEEE Trans. Commun. 59 (11) (2011) 3040–3048.
[100] J. Huang, S. Zhou, J. Huang, C.R. Berger, P. Willett, Progressive inter-carrier interference equalization for
OFDM transmission over time-varying underwater acoustic channels, IEEE J. Sel. Topics Signal Process. 5
(8) (2011) 1524–1536.
[101] T. Hunziker, D. Dahlhaus, Iterative detection for multicarrier transmission employing time-frequency con-
centrated pulses, IEEE Trans. Commun. 51 (4) (2003) 641–651.
[102] A.A. Hutter, R. Hasholzner, J.S. Hammerschmidt, Channel estimation for mobile OFDM systems, in: IEEE
Veh. Technol. Conf. Fall, Amsterdam, The Netherlands, September 19–22, 1999.
[103] T. Hwang, C. Yang, G. Wu, S. Li, G.Y. Li, OFDM and its wireless applications: a survey, IEEE Veh. Technol.
58 (4) (2009) 1673–1694.
[104] IEEE, Institute of Electrical and Electronics Engineers, Part 11: wireless LAN medium access control (MAC)
and physical layer (PHY) speciﬁcations: high-speed physical layer in the 5 GHz band, IEEE Std 802.11a-
1999, New York, NY, December 1999.
[105] IEEE, Institute of Electrical and Electronics Engineers, Part 16: air interface for ﬁxed and mobile broadband
wireless access systems, IEEE Std 802.16-2004, New York, NY, October 2004.
[106] T. Ihalainen, A. Ikhlef, J. Louveaux, M. Renfors, Channel equalization for multi-antenna FBMC/OQAM
receivers, IEEE Trans. Veh. Technol. 60 (5) (2011) 2070–2085.
[107] ITU, International Telecommunication Union, Series G: transmission systems and media, digital systems
and networks, Asymmetric digital subscriber line (ADSL) transceivers, ITU-T Recommendation G.992.1,
Geneva, Switzerland, June 1999.
[108] J. Jaldén, B. Ottersten, On the complexity of sphere decoding in digital communications, IEEE Trans. Signal
Process. 53 (4) (2005) 1474–1484.
[109] J. Jang, K.B. Lee, Transmit power adaptation for multiuser OFDM systems, IEEE J. Sel. Areas Commun.
21 (2) (2003) 171–178.

284
CHAPTER 5 OFDM and Multicarrier Signal Processing
[110] W.G. Jeon, K.H. Chang, Y.S. Cho, An equalization technique for orthogonal frequency-division multiplexing
systems in time-variant multipath channels, IEEE Trans. Commun. 47 (1) (1999) 27–32.
[111] M. Jiang, L. Hanzo, Multiuser MIMO-OFDM for next-generation wireless systems, Proc. IEEE 95 (7) (2007)
1430–1469.
[112] T. Jiang, Y. Wu, An overview: peak-to-average power ratio reduction techniques for OFDM signals, IEEE
Trans. Broadcast. 54 (2) (2008) 257–268.
[113] A.E. Jones, T.A. Wilkinson, S.K. Barton, Block coding scheme for reduction of peak to mean envelope
power ratio of multicarrier transmission scheme, Electron. Lett. 30 (22) (1994) 2098–2099.
[114] H.W. Kang, Y.S. Cho, D.H. Youn, On compensating nonlinear distortions of an OFDM system using an
efﬁcient adaptive predistorter, IEEE Trans. Commun. 47 (4) (1999) 522–526.
[115] T. Kang, R.A. Iltis, Iterative carrier frequency offset and channel estimation for underwater acoustic OFDM
systems, IEEE J. Sel. Areas Commun. 26 (9) (2008) 1650–1661.
[116] G. Karam, H. Sari, Data predistortion techniques using intersymbol interpolation, IEEE Trans. Commun. 38
(10) (1990) 1716–1723.
[117] S.M. Kay, Fundamentals of Statistical Signal Processing: Estimation Theory, Prentice-Hall, Englewood
Cliffs, 1993.
[118] A. Kaye, D. George, M. Eric, Analysis and compensation of bandpass nonlinearities for communications,
IEEE Trans. Commun. 20 (5) (1972) 965–972.
[119] V. Kekatos, G.B. Giannakis, From sparse signals to sparse residuals for robust sensing, IEEE Trans. Signal
Process. 59 (7) (2011) 3355–3368.
[120] T.Keller,L.Hanzo,Adaptivemulticarriermodulation:aconvenientframeworkfortime-frequencyprocessing
in wireless communications, Proc. IEEE 88 (5) (2000) 611–640.
[121] N. Khaled, B. Mondal, G. Leus, R.W. Heath, F. Petre, Interpolation-based multi-mode precoding for MIMO-
OFDM systems with limited feedback, IEEE Trans. Wireless Commun. 6 (3) (2007) 1003–1013.
[122] D. Kim, G.L. Stüber, Clipping noise mitigation for OFDM by decision-aided reconstruction, IEEE Commun.
Lett. 3 (1) (1999) 4–6.
[123] H. Kim, J.K. Tugnait, Turbo equalization for doubly-selective fading channels using nonlinear Kalman
ﬁltering and basis expansion models, IEEE Trans. Wireless Commun. 9 (6) (2010) 2076–2087.
[124] I. Kim, I.-S. Park, Y.H. Lee, Use of linear programming for dynamic subcarrier and bit allocation in multiuser
OFDM, IEEE Trans. Veh. Technol. 55 (4) (2006) 1195–1207.
[125] J.-G. Kim, J.-T. Lim, MAP-based channel estimation for MIMO-OFDM over fast Rayleigh fading channels,
IEEE Trans. Veh. Technol. 57 (3) (2008) 1963–1968.
[126] S.Kim,Angle-domainfrequency-selectivesparsechannelestimationforunderwaterMIMO-OFDMsystems,
IEEE Commun. Lett. 16 (5) (2012) 685–687.
[127] S. Kondo, B. Milstein, Performance of multicarrier DS CDMA systems, IEEE Trans. Commun. 44 (2) (1996)
238–246.
[128] W. Kozek, A.F. Molisch, Nonorthogonal pulseshapes for multicarrier communications in doubly dispersive
channels, IEEE J. Sel. Areas Commun. 16 (8) (1998) 1579–1589.
[129] B.S. Krongold, D.L. Jones, PAR reduction in OFDM via active constellation extension, IEEE Trans. Broad-
cast. 49 (3) (2003) 258–268.
[130] B.S. Krongold, K. Ramchandran, D.L. Jones, Computationally efﬁcient optimal power allocation algorithms
for multicarrier communication systems, IEEE Trans. Commun. 48 (1) (2000) 23–27.
[131] A. Kuhne, A. Klein, Throughput analysis of multi-user OFDMA-systems using imperfect CQI feedback and
diversity techniques, IEEE J. Sel. Areas Commun. 26 (8) (2008) 1440–1450.
[132] I.-W. Lai, T.-D. Chiueh, One-dimensional interpolation based channel estimation for mobile DVB-H recep-
tion, in: IEEE Int. Symp. Circ. Syst., Kos, Greece, May 2006, pp. 21–24.

References
285
[133] D. Landström, S.K. Wilson, J.-J. van de Beek, P. Ödling, P.O. Börjesson, Symbol time offset estimation in
coherent OFDM systems, IEEE Trans. Commun. 50 (4) (2002) 545–549.
[134] J.N. Laneman, D.N.C. Tse, G.W. Wornell, Cooperative diversity in wireless networks: efﬁcient protocols
and outage behaviour, IEEE Trans. Inform. Theory 50 (12) (2004) 3062–3080.
[135] J.N. Laneman, G.W. Wornell, Distributed space-time-coded protocols for exploiting cooperative diversity in
wireless networks, IEEE Trans. Inform. Theory 49 (10) (2003) 2415–2425.
[136] B. Le Floch, M. Alard, C. Berrou, Coded orthogonal frequency division multiplex, Proc. IEEE 83 (6) (1995)
982–996.
[137] A. Leshem, I. Bergel, Signal processing for digital subscriber lines, E-Reference Signal Processing, Elsevier,
2013.
[138] B.K. Letaief, W. Zhang, Cooperative communications for cognitive radio networks, Proc. IEEE 97 (5) (2009)
878–893.
[139] G. Leus, On the estimation of rapidly time-varying channels, in: European Signal Process. Conf., Vienna,
Austria, September 6–10, 2004.
[140] G. Leus, P. van Walree, Multiband OFDM for covert acoustic communications, IEEE J. Sel. Areas Commun.
26 (9) (2008) 1662–1673.
[141] B.Li,J.Huang,S.Zhou,K.Ball,M.Stojanovic,L.Freitag,P.Willett,MIMO-OFDMforhigh-rateunderwater
acoustic communications, IEEE J. Ocean. Eng. 34 (4) (2009) 634–644.
[142] B. Li, S. Zhou, M. Stojanovic, L. Freitag, P. Willett, Multicarrier communication over underwater acoustic
channels with nonuniform Doppler shifts, IEEE J. Ocean. Eng. 33 (2) (2008) 198–209.
[143] X. Li, F. Ng, T. Han, Carrier frequency offset mitigation in asynchronous cooperative OFDM transmissions,
IEEE Trans. Signal Process. 56 (2) (2008) 675–685.
[144] Y. Li, L.J. Cimini, Bounds on the interchannel interference of OFDM in time-varying impairments, IEEE
Trans. Commun. 49 (3) (2001) 401–404.
[145] Y. Li, G.L. Stüber, Orthogonal Frequency Division Multiplexing for Wireless Communications, Springer,
New York, 2006.
[146] Y.-P. Lin, S.-M. Phoong, BER minimized OFDM systems with channel independent precoders, IEEE Trans.
Signal Process. 51 (9) (2003) 2369–2380.
[147] L. Liu, S. Zhou, J.H. Cui, The prospects and problems of wireless communication for underwater sensor
networks, Wireless Commun. Mobile Comput. 8 (8) (2008) 977–994.
[148] Z. Liu, Y. Xin, G.B. Giannakis, Linear constellation precoding for OFDM with maximum multipath diversity
and coding gains, IEEE Trans. Commun. 51 (3) (2003) 416–427.
[149] V. Lottici, M. Luise, C. Saccomando, F. Spalla, Blind carrier frequency tracking for ﬁlterbank multicarrier
wireless communications, IEEE Trans. Commun. 53 (10) (2005) 1762–1772.
[150] D.J. Love, R.W. Heath, OFDM power loading using limited feedback, IEEE Trans. Veh. Technol. 54 (5)
(2005) 1773–1780.
[151] Z.-Q. Luo, Signal processing and optimal resource allocation for the interference channel, E-Reference
Signal Processing, Elsevier, 2013.
[152] X. Ma, G.B. Giannakis, S. Ohno, Optimal training for block transmissions over doubly selective wireless
fading channels, IEEE Trans. Signal Process. 51 (5) (2003) 1351–1366.
[153] X. Ma, C. Tepedelenlioglu, G.B. Giannakis, S. Barbarossa, Non-data-aided carrier offset estimators for
OFDM with null subcarriers: identiﬁability, algorithms, and performance, IEEE J. Sel. Areas Commun. 19
(12) (2001) 2504–2515.
[154] Y. Ma, N. Yi, R. Tafazolli, Bit and power loading for OFDM-based three-node relaying communications,
IEEE Trans. Signal Process. 56 (7) (2008) 3236–3247.
[155] M.A. Maddah-Ali, A.S. Motahari, A.K. Khandani, Communication over MIMO X channels: interference
alignment, decomposition, and performance analysis, IEEE Trans. Inform. Theory 54 (8) (2008) 3457–3470.

286
CHAPTER 5 OFDM and Multicarrier Signal Processing
[156] G. Matz, D. Schafhuber, K. Gröchenig, M. Hartmann, F. Hlawatsch, Analysis, optimization, and imple-
mentation of low-interference wireless multicarrier systems, IEEE Trans. Wireless Commun. 6 (5) (2007)
1921–1931.
[157] Y. Medjahdi, M. Terre, D. Le Ruyet, D. Roviras, A. Dziri, Performance analysis in the downlink of asyn-
chronous OFDM/FBMC based multi-cellular networks, IEEE Trans. Wireless Commun. 10 (8) (2011) 2630–
2639.
[158] J. Minkoff, The role of AM-to-PM conversion in memoryless nonlinear systems, IEEE Trans. Commun. 33
(2) (1985) 139–144.
[159] M. Mishali, Y.C. Eldar, From theory to practice: Sub-Nyquist sampling of sparse wideband analog signals,
IEEE Sel. Topics Signal Process. 4 (2) (2010) 375–391.
[160] J. Mitola, G.Q. Maguire, Cognitive radio: making software radios more personal, IEEE Pers. Commun. 6
(4) (1999) 13–18.
[161] P.H. Moose, A technique for orthogonal frequency division multiplexing frequency offset correction, IEEE
Trans. Commun. 42 (10) (1994) 2908–2914.
[162] M. Morelli, Timing and frequency synchronization for the uplink of an OFDMA system, IEEE Trans.
Commun. 52 (2) (2004) 296–306.
[163] M. Morelli, C.-C.J. Kuo, M.-O. Pun, Synchronization techniques for orthogonal frequency division multiple
access (OFDMA): a tutorial review, Proc. IEEE 95 (7) (2007) 1394–1427.
[164] M. Morelli, U. Mengali, A comparison of pilot-aided channel estimation methods for OFDM systems, IEEE
Trans. Signal Process. 49 (12) (2001) 3065–3073.
[165] Y.Mostoﬁ,D.C.Cox,TimingsynchronizationinhighmobilityOFDMsystems,in:IEEEInt.Conf.Commun.,
Paris, France, June 20–24, 2004.
[166] B. Muquet, M. de Courville, P. Duhamel, G. Giannakis, OFDM with trailing zeros versus OFDM with cyclic
preﬁx: links, comparisons and application to the HiperLAN/2 system, in: IEEE Int. Conf. Commun, New
Orleans, LA, June 2000, pp. 18–22.
[167] B. Muquet, Z. Wang, G.B. Giannakis, M. de Courville, P. Duhamel, Cyclic preﬁxing or zero padding for
wireless multicarrier transmissions?, IEEE Trans. Commun. 50 (12) (2002) 2136–2148.
[168] K. Muralidhar, K.H. Li, A low-complexity Kalman approach for channel estimation in doubly-selective
OFDM systems, IEEE Signal Process. Lett. 16 (7) (2009) 632–635.
[169] S.H. Müller, J.B. Huber, OFDM with reduced peak-to-average power ratio by optimum combination of
partial transmit sequences, Electron. Lett. 33 (5) (1997) 368–369.
[170] A. Nosratinia, T.E. Hunter, A. Hedayat, Cooperative communication in wireless networks, IEEE Commun.
Mag. 42 (10) (2004) 74–80.
[171] H. Ochiai, H. Imai, Performance analysis of deliberately clipped OFDM signals, IEEE Trans. Commun. 50
(1) (2002) 89–101.
[172] S. Ohno, G.B. Giannakis, Optimal training and redundant precoding for block transmissions with application
to wireless OFDM, IEEE Trans. Commun. 50 (12) (2002) 2113–2123.
[173] A.V. Oppenheim, R.W. Schafer, Discrete-Time Signal Processing, Prentice-Hall, Englewood Cliffs, 1989.
[174] M.K. Ozdemir, H. Arslan, Channel estimation for wireless OFDM systems, IEEE Commun. Surv. Tutor. 9
(2) (2007) 18–48.
[175] A.Y. Panah, R.W. Heath, Single-user and multicast OFDM power loading with nonregenerative relaying,
IEEE Trans. Veh. Technol. 58 (9) (2009) 4890–4902.
[176] N. Papandreou, T. Antonakopoulos, Bit and power allocation in constrained multicarrier systems: the single-
user case, EURASIP J. Adv. Signal Process. (2008) 1–14 Article ID 643081.
[177] A. Papoulis, Probability, Random Variables, and Stochastic Processes, third ed., McGraw-Hill, New York,
1991.

References
287
[178] A.J. Paulraj, D.A. Gore, R.U. Nabar, H. Bölcskei, An overview of MIMO communications -A key to gigabit
wireless, Proc. IEEE 92 (2) (2004) 198–218.
[179] R.Peled, A. Ruiz, Frequency domain data transmission using reduced computational complexity algorithms,
in: IEEE Int. Conf. Acoust. Speech Signal Process., Denver, CO., April 9–11, 1980.
[180] K. Pelekanakis, A.B. Baggeroer, Exploiting space-time-frequency diversity with MIMO-OFDM for under-
water acoustic communications, IEEE J. Ocean. Eng. 36 (4) (2011) 502–513.
[181] M. Poggioni, L. Rugini, P. Banelli, DVB-T/H and T-DMB: Physical layer performance comparison in fast
mobile channels, IEEE Trans. Broadcast. 55 (4) (2009) 719–730.
[182] C. Polprasert, J.A. Ritcey, M. Stojanovic, Capacity of OFDM systems over fading underwater acoustic
channels, IEEE J. Ocean. Eng. 36 (4) (2011) 514–524.
[183] J.G. Proakis, M. Salehi, Digital Communications, ﬁfth ed., McGraw-Hill, New York, 2008.
[184] U. Reimers, Digital video broadcasting, IEEE Commun. Mag. 36 (6) (1998) 104–110.
[185] P. Robertson, S. Kaiser, The effects of Doppler spreads in OFDM(A) mobile radio systems, in: IEEE Veh.
Technol. Conf. Fall, Amsterdam, The Netherlands, September 19–22, 1999.
[186] H.E. Rowe, Memoryless nonlinearities with Gaussian inputs: elementary results, Bell Syst. Tech. J. 61 (7)
(1982) 1519–1525.
[187] L. Rugini, Linear equalization for multicode MC-CDMA downlink channels, IEEE Commun. Lett. 16 (9)
(2012) 1353–1356.
[188] L. Rugini, P. Banelli, BER of OFDM systems impaired by carrier frequency offset in multipath fading
channels, IEEE Trans. Wireless Commun. 4 (5) (2005) 2279–2288.
[189] L. Rugini, P. Banelli, Probability of error of linearly modulated signals with Gaussian cochannel interference
in maximally correlated Rayleigh fading channels, EURASIP J. Wireless Commun. Network (2010) 1–13
ID 193183.
[190] L. Rugini, P. Banelli, Pilot-aided estimation of carrier frequency offsets and channel impulse responses for
OFDM cooperative communications, in: IEEE Int. Work. Signal Process Adv. Wireless Commun., Cesme,
Turkey, June 2012, pp. 17–20.
[191] L. Rugini, P. Banelli, S. Cacopardi, A full-rank regularization technique for MMSE detection in multiuser
CDMA systems, IEEE Commun. Lett. 9 (1) (2005) 34–36.
[192] L. Rugini, P. Banelli, K. Fang, G. Leus, Enhanced turbo MMSE equalization for MIMO-OFDM over rapidly
time-varying frequency-selective channels, in: IEEE Int. Work. Signal Process Adv. Wireless Commun,
Perugia, Italy, June, 2009, pp. 21–24.
[193] L. Rugini, P. Banelli, G. Leus, Block DFE and windowing for Doppler-affected OFDM systems, IEEE Int.
Workshop on Signal Processing Advances in Wireless Communications (SPAWC 2005), New York, USA,
June 5–8, 2005, pp. 470–474.
[194] L. Rugini, P. Banelli, G. Leus, Simple equalization of time-varying channels for OFDM, IEEE Commun.
Lett. 9 (7) (2005) 619–621.
[195] L. Rugini, P. Banelli, G. Leus, Low-complexity banded equalizers for OFDM systems in Doppler spread
channels, EURASIP J. Appl. Signal Process. (2006) 1–13 ID 67404.
[196] M. Russell, G.L. Stüber, Interchannel interference analysis for OFDM in a mobile environment, in: IEEE
Veh. Technol. Conf, Chicago, IL, July 1995, pp. 25–28.
[197] A.A.M. Saleh, Frequency-independent and frequency-dependent nonlinear models of TWT ampliﬁers, IEEE
Trans. Commun. 29 (11) (1981) 1715–1720.
[198] F. Sanzi, J. Speidel, An adaptive two-dimensional channel estimator for wireless OFDM with application to
mobile DVB-T, IEEE Trans. Broadcast. 46 (2) (2000) 128–133.
[199] H. Sari, G. Karam, I. Jeanclaude, Transmission techniques for digital terrestrial TV broadcasting, IEEE
Commun. Mag. 33 (2) (1995) 100–109.

288
CHAPTER 5 OFDM and Multicarrier Signal Processing
[200] A. Scaglione, S. Barbarossa, G.B. Giannakis, Filterbank transceivers optimizing information rate in block
transmissions over dispersive channels, IEEE Trans. Inform. Theory 45 (3) (1999) 1019–1032.
[201] A. Scaglione, G.B. Giannakis, S. Barbarossa, Redundant ﬁlterbank precoders and equalizers-Part I: uniﬁca-
tion and optimal designs, IEEE Trans. Signal Process. 47 (7) (1999) 1988–2006.
[202] A. Scaglione, G.B. Giannakis, S. Barbarossa, Redundant ﬁlterbank precoders and equalizers-Part II: Blind
channel estimation, synchronization, and direct equalization, IEEE Trans. Signal Process. 47 (7) (1999)
2007–2022.
[203] D. Schafhuber, G. Matz, F. Hlawatsch, Adaptive Wiener ﬁlters for time-varying channel estimation in wireless
OFDM systems, in: IEEE Int. Conf. Acoust. Speech Signal Process., Hong Kong, April 6–10, 2003.
[204] P. Schniter, Low-complexity equalization of OFDM in doubly selective channels, IEEE Trans. Signal Process.
52 (4) (2004) 1002–1011.
[205] G. Scutari, D.P. Palomar, S. Barbarossa, Asynchronous iterative water-ﬁlling for Gaussian frequency-
selective interference channels, IEEE Trans. Inform. Theory 54 (7) (2008) 2868–2878.
[206] G. Scutari, D.P. Palomar, S. Barbarossa, The MIMO iterative water-ﬁlling algorithm, IEEE Trans. Signal
Process. 57 (5) (2009) 1917–1935.
[207] D. Schafhuber, G. Matz, MMSE and adaptive prediction of time-varying channels for OFDM systems, IEEE
Trans. Wireless Commun. 4 (2) (2005) 593–602.
[208] T.M. Schmidl, D.C. Cox, Robust frequency and timing synchronization for OFDM, IEEE Trans. Commun.
45 (12) (1997) 1613–1621.
[209] M. Schwartz, The origins of carrier multiplexing: Major George Owen Squier and AT&T, IEEE Commun.
Mag. 46 (5) (2008) 20–24.
[210] J. Seo, S. Jang, J. Yang, W. Jeon, D.K. Kim, Analysis of pilot-aided channel estimation with optimal leakage
suppression for OFDM systems, IEEE Commun. Lett. 14 (9) (2010) 809–811.
[211] C. Sgraja, J. Lindner, Estimation of rapid time-variant channels for OFDM using Wiener ﬁltering, in: IEEE
Int. Conf. Commun, Anchorage, AK, May 2003, pp. 11–15.
[212] C.E Shannon, A mathematical theory of communication, Bell Syst. Tech. J. 27 (3–4) (1948) 379–423,
623–656.
[213] C.E. Shannon, Communication in the presence of noise, Proceedings of the Institute of Radio Engineers 37
(1) (1949) 10–21, Reprinted in, Proc. IEEE 86 (2) (1998) 447–457.
[214] Z. Shen, J.G. Andrews, B.L. Evans, Adaptive resource allocation in multiuser OFDM systems with propor-
tional rate constraints, IEEE Trans. Wireless Commun. 4 (6) (2005) 2726–2737.
[215] Q. Shi, OFDM in bandpass nonlinearity, IEEE Trans. Consum. Electron. 42 (3) (1996) 253–258.
[216] O. Shimbo, Effects of intermodulation, AM-PM conversion, and additive noise in multicarrier TWT systems,
Proc. IEEE 59 (2) (1971) 230–238.
[217] O.-S. Shin, A.M. Chan, H.T. Kung, V. Tarokh, Design of an OFDM cooperative space-time diversity system,
IEEE Trans. Veh. Technol. 56 (4) (2007) 2203–2215.
[218] M.K. Simon, M.-S. Alouini, Digital Communication over Fading Channels, second ed., Wiley-IEEE Press,
Hoboken, 2005.
[219] M.K. Simon, H. Jafarkhani, Performance evaluation of super-orthogonal space-time trellis codes using a
moment generating function-based approach, IEEE Trans. Signal Process. 51 (11) (2003) 2739–2751.
[220] P. Siohan, C. Siclet, N. Lacaille, Analysis and design of OFDM/OQAM systems based on ﬁlterbank theory,
IEEE Trans. Signal Process. 50 (5) (2002) 1170–1183.
[221] W. Siriwongpairat, A. Sadek, K.J.R. Liu, Cooperative communications protocol for multiuser OFDM net-
works, IEEE Trans. Wireless Commun. 7 (7) (2008) 2430–2435.
[222] B. Sklar, Rayleigh fading channels in mobile digital communication systems–Part I: Characterization, IEEE
Commun. Mag. 35 (7) (1997) 90–100.

References
289
[223] L. Song, J.K. Tugnait, Doubly-selective fading channel equalization: a comparison of the Kalman ﬁlter
approach with the basis expansion model-based equalizers, IEEE Trans. Wireless Commun. 8 (1) (2009)
60–65.
[224] W.-G. Song, J.-T. Lim, Channel estimation and signal detection for MIMO-OFDM with time varying chan-
nels, IEEE Commun. Lett. 10 (7) (2006) 540–542.
[225] E.A. Sourour, M. Nakagawa, Performance of orthogonal multicarrier CDMA in a multipath fading channel,
IEEE Trans. Commun. 44 (3) (1996) 356–367.
[226] M. Speth, S.A. Fechtel, G. Fock, H. Meyr, Optimum receiver design for wireless broad-band systems using
OFDM–Part I, IEEE Trans. Commun. 47 (11) (1999) 1668–1677.
[227] A. Stamoulis, S.N. Diggavi, N. Al-Dhahir, Intercarrier interference in MIMO OFDM, IEEE Trans. Signal
Process. 50 (10) (2002) 2451–2464.
[228] H.A. Suraweera, J. Armstrong, Performance of OFDM-based dual-hop amplify-and-forward relaying, IEEE
Commun. Lett. 11 (9) (2007) 726–728.
[229] V. Tarokh, N. Seshadri, A.R. Calderbank, Space-time codes for high data rate wireless communication:
performance criterion and code construction, IEEE Trans. Inform. Theory 44 (2) (1998) 744–765.
[230] Z. Tang, R.C. Cannizzaro, G. Leus, P. Banelli, Pilot-assisted time-varying channel estimation for OFDM
systems, IEEE Trans. Signal Process. 55 (5) (2007) 2226–2238.
[231] Z. Tang, G. Leus, A novel receiver architecture for single-carrier transmission over time-varying channels,
IEEE J. Sel. Areas Commun. 26 (2) (2008) 366–377.
[232] G. Tauböck, F. Hlawatsch, D. Eiwen, H. Rauhut, Compressive estimation of doubly selective channels in
multicarrier systems: leakage effects and sparsity-enhancing processing, IEEE J. Sel. Topics Signal Process.
4 (2) (2010) 255–271.
[233] J. Tellado, Peak to Average Power Reduction for Multicarrier Modulation, Ph.D. Thesis, Stanford University,
Stanford, CA, 2000.
[234] J. Tellado, L.M.C. Hoo, J.M. Ciofﬁ, Maximum-likelihood detection of nonlinearly distorted multicarrier
symbols by iterative decoding, IEEE Trans. Commun. 51 (2) (2003) 218–228.
[235] K.D. Teo, S. Ohno, Optimal MMSE ﬁnite parameter model for doubly-selective channels, in: IEEE Global
Telecommun. Conf., St. Louis, MO, November 28–December 2, 2005.
[236] C. Tepedelenlioglu, Maximum multipath diversity with linear equalization in precoded OFDM systems,
IEEE Trans. Infrom. Theory 50 (1) (2004) 232–235.
[237] 3GPP 3rd Generation Partnership Project, Technical speciﬁcation group Radio Access Network, Evolved
Universal Terrestrial Radio Access (E-UTRA): Physical channels and modulation, 3GPP TS 36.211 V8.5.0,
Sophia Antipolis, France, December 2008.
[238] A.M. Tonello, Performance limits for ﬁltered multitone modulation in fading channels, IEEE Trans. Wireless
Commun. 4 (5) (2005) 2121–2135.
[239] M.K. Tsatsanis, G.B. Giannakis, Modeling and equalization of rapidly fading channels, Int. J. Adapt. Control
Signal Process. 10 (1996) 159–176.
[240] K. Tu, D. Fertonani, T.M. Duman, M. Stojanovic, J.G. Proakis, P. Hursky, Mitigation of intercarrier inter-
ference for OFDM over time-varying underwater acoustic channels, IEEE J. Ocean. Eng. 36 (2) (2011)
156–171.
[241] J. Tugnait, Channel estimation, tracking, equalization, and precoding, E-Reference Signal Processing,
Elsevier, 2013.
[242] U. Tureli, H. Liu, M.D. Zoltowski, A high efﬁciency carrier estimator for OFDM communications, in: IEEE
Asilomar Conf. Signals, Syst. Comput., Paciﬁc Grove, CA, November 2–5, (1997).
[243] J.-J. van de Beek, M. Sandell, P.O. Börjesson, ML estimation of time and frequency offset in OFDM systems,
IEEE Trans. Signal Process. 45 (7) (1997) 1800–1805.

290
CHAPTER 5 OFDM and Multicarrier Signal Processing
[244] L. Vandendorpe, Multitone spread spectrum multiple access communications system in a multipath Rician
fading channel, IEEE Trans. Veh. Technol. 44 (2) (1995) 327–337.
[245] P. Van Eetvelt, G. Wade, M. Tomlinson, Peak to average power reduction for OFDM schemes by selective
scrambling, Electron. Lett. 32 (21) (1996) 1963–1964.
[246] R. van Nee, R. Prasad, OFDM for Wireless Multimedia Communications, Artech House, Boston, 2000.
[247] S. Verdú, Multiuser Detection, Cambridge University Press, New York, 1998.
[248] W. Wang, R. Wu, Capacity maximization for OFDM two-hop relay system with separate power constraints,
IEEE Trans. Veh. Technol. 58 (9) (2009) 4943–4954.
[249] X.B. Wang, T.T. Tjhung, C.S. Ng, Reduction of peak-to-average power ratio of OFDM system using a
companding technique, IEEE Trans. Broadcast. 45 (3) (1999) 303–307.
[250] Z. Wang, G.B. Giannakis, Complex-ﬁeld coding for OFDM over fading wireless channels, IEEE Trans.
Inform. Theory 49 (3) (2003) 707–720.
[251] Z. Wang, G.B. Giannakis, Wireless multicarrier communications: Where Fourier meets Shannon, IEEE
Signal Process. Mag. 17 (3) (2000) 29–48.
[252] Z. Wang, G.B. Giannakis, Linearly precoded or coded OFDM against wireless channel fades?, in: IEEE Int.
Work. Signal Process. Adv. Wireless Commun, Taiwan, March 20–23, 2001.
[253] Z. Wang, X. Ma, G.B. Giannakis, OFDM or single-carrier block transmissions?, IEEE Trans. Commun. 52
(3) (2004) 380–394.
[254] Z. Wang, S. Zhou, G.B. Giannakis, Joint coding-precoding with low-complexity turbo-decoding, IEEE Trans.
Wireless Commun. 3 (3) (2004) 832–842.
[255] Z. Wang, S. Zhou, G.B. Giannakis, C.R. Berger, J. Huang, Frequency-domain oversampling for
zero-padded OFDM in underwater acoustic communications, IEEE J. Ocean. Eng. 37 (1) (2012)
14–24.
[256] S.B. Weinstein, The history of orthogonal frequency-division multiplexing, IEEE Commun. Mag. 47 (11)
(2009) 26–35.
[257] S.B. Weinstein, P.M. Ebert, Data transmission for frequency-division multiplexing using the discrete Fourier
transform, IEEE Trans. Commun. Technol. 19 (5) (1971) 628–634.
[258] C.Y. Wong, R.S. Cheng, K.B. Letaief, R.D. Murch, Multiuser OFDM with adaptive subcarrier, bit, and power
allocation, IEEE J. Sel. Areas Commun. 17 (10) (1999) 1747–1758.
[259] L.-L. Yang, L. Hanzo, Performance of generalized multicarrier DS-CDMA over Nakagami-m fading chan-
nels, IEEE Trans. Commun. 50 (6) (2002) 956–966.
[260] S. Yerramalli, U. Mitra, Optimal resampling of OFDM signals for multiscale-multilag underwater acoustic
channels, IEEE J. Ocean. Eng. 36 (1) (2011) 126–138.
[261] W. Yu, G. Ginis, J.M. Ciofﬁ, Distributed multiuser power control for digital subscriber lines, IEEE J. Sel.
Areas Commun. 20 (5) (2002) 1105–1115.
[262] W. Yu, W. Rhee, S. Boyd, J.M. Ciofﬁ, Iterative water-ﬁlling for Gaussian vector multiple-access channels,
IEEE Trans. Inform. Theory 50 (1) (2004) 145–152.
[263] W. Zhang, X.-G. Xia, K.B. Letaief, Space-time/frequency coding for MIMO-OFDM in next generation
broadband wireless systems, IEEE Wireless Commun. 14 (3) (2007) 32–43.
[264] Z. Zhang, W. Zhang, C. Tellambura, Cooperative OFDM channel estimation in the presence of frequency
offsets, IEEE Trans. Veh. Technol. 58 (7) (2009) 3447–3459.
[265] M. Zhao, Z. Shi, M.C. Reed, Iterative turbo channel estimation for OFDM system over rapid dispersive
fading channel, IEEE Trans. Wireless Commun. 7 (8) (2008) 3174–3184.
[266] T.Zemen,C.F.Mecklenbräuker,Time-variantchannelestimationusingdiscreteprolatespheroidalsequences,
IEEE Trans. Signal Process. 53 (9) (2005) 3597–3607.
[267] H. Zhu, G. Leus, G.B. Giannakis, Sparsity-cognizant total least-squares for perturbed compressive sampling,
IEEE Trans. Signal Process. 59 (5) (2011) 2002–2016.

Additional References
291
[268] M.S. Zimmerman, A.L. Kirsch, The AN/GSC-10 (KATHRYN) variable rate data modem for HF radio, IEEE
Trans. Commun. Technol. 15 (2) (1967) 197–204.
[269] W.Y. Zou, Y. Wu, COFDM: an overview, IEEE Trans. Broadcast. 41 (1) (1995) 1–8.
Additional References
[270] N. Al-Dhahir, J.M. Ciofﬁ, Optimum ﬁnite-length equalization for multicarrier transceivers, IEEE Trans.
Commun. 44 (1) (1996) 56–64.
[271] J. Armstrong, Analysis of new and existing methods of reducing intercarrier interference due to carrier
frequency offset in OFDM, IEEE Trans. Commun. 47 (3) (1999) 365–369.
[272] G. Arslan, B.L. Evans, S. Kiaei, Equalization for discrete multitone transceivers to maximize bit rate, IEEE
Trans. Signal Process. 49 (12) (2001) 3123–3135.
[273] I. Barhumi, G. Leus, M. Moonen, Optimal training design for MIMO OFDM systems in mobile wireless
channels, IEEE Trans. Signal Process. 51 (6) (2003) 1615–1624.
[274] N. Benvenuto, R. Dinis, D. Falconer, S. Tomasin, Single carrier modulation with nonlinear frequency domain
equalization: an idea whose time has come-again, Proc. IEEE 98 (1) (2010) 69–96.
[275] H. Bölcskei, Blind estimation of symbol timing and carrier frequency offset in wireless OFDM systems,
IEEE Trans. Commun. 49 (6) (2001) 988–999.
[276] H. Bölcskei, D. Gesbert, A.J. Paulraj, On the capacity of OFDM-based spatial multiplexing systems, IEEE
Trans. Commun. 50 (2) (2002) 225–234.
[277] H.-H. Chen, J.-F. Yeh, N. Suehiro, A multicarrier CDMA architecture based on orthogonal complementary
codes for new generations of wideband wireless communications, IEEE Commun. Mag. 39 (10) (2001)
126–135.
[278] G. Cherubini, E. Eleftheriou, S. Ölçer, Filtered multitone modulation for very high-speed digital subscriber
lines, IEEE J. Sel. Areas Commun. 20 (5) (2002) 1016–1028.
[279] L.J. Cimini, N.R. Sollenberger, Peak-to-average power ratio reduction of an OFDM signal using partial
transmit sequences, IEEE Commun. Lett. 4 (3) (2000) 86–88.
[280] S. Coleri, M. Ergen, A. Puri, A. Bahai, Channel estimation techniques based on pilot arrangement in OFDM
systems, IEEE Trans. Broadcast. 48 (3) (2002) 223–229.
[281] O. Edfors, M. Sandell, J.-J. van de Beek, S.K. Wilson, P.O. Börjesson, OFDM channel estimation by singular
value decomposition, IEEE Trans. Commun. 46 (7) (1998) 931–939.
[282] M. Ghosh, Analysis of the effect of impulse noise on multicarrier and single carrier QAM systems, IEEE
Trans. Commun. 44 (2) (1996) 145–147.
[283] B. Hirosaki, An orthogonally multiplexed QAM system using the discrete Fourier transform, IEEE Trans.
Commun. 29 (7) (1981) 982–989.
[284] D. Kivanc, G. Li, H. Liu, Computationally efﬁcient bandwidth allocation and power control for OFDMA,
IEEE Trans. Wireless Commun. 2 (6) (2003) 1150–1158.
[285] Y. Li, Pilot-symbol-aided channel estimation for OFDM in wireless systems, IEEE Trans. Veh. Technol. 49
(4) (2000) 1207–1215.
[286] Y. Li, Simpliﬁed channel estimation for OFDM systems with multiple transmit antennas, IEEE Trans.
Wireless Commun. 1 (1) (2002) 67–75.
[287] Y. Li, L.J. Cimini Jr, N.R. Sollenberger, Robust channel estimation for OFDM systems with rapid dispersive
fading channels, IEEE Trans. Commun. 46 (7) (1998) 902–915.
[288] Y. Li, N. Seshadri, S. Ariyavisitakul, Channel estimation for OFDM systems with transmitter diversity in
mobile wireless channels, IEEE J. Sel. Areas Commun. 17 (3) (1999) 461–471.

292
CHAPTER 5 OFDM and Multicarrier Signal Processing
[289] H. Liu, U. Tureli, A high-efﬁciency carrier estimator for OFDM communications, IEEE Commun. Lett. 2
(4) (1998) 104–106.
[290] Z. Liu, Y. Xin, G.B. Giannakis, Space-time-frequency coded OFDM over frequency-selective fading chan-
nels, IEEE Trans. Signal Process. 50 (10) (2002) 2465–2476.
[291] S. Mason, C. Berger, S. Zhou, P. Willett, Detection, synchronization, and Doppler scale estimation with
multicarrier waveforms in underwater acoustic communication, IEEE J. Sel. Areas Commun. 26 (9) (2008)
1638–1649.
[292] F. Meshkati, M. Chiang, H.V. Poor, S.C. Schwartz, A game-theoretic approach to energy-efﬁcient power
control in multicarrier CDMA systems, IEEE J. Sel. Areas Commun. 24 (6) (2006) 1115–1129.
[293] H. Minn, V.K. Bhargava, K.B. Letaief, A robust timing and frequency synchronization for OFDM systems,
IEEE Trans. Wireless Commun. 2 (4) (2003) 822–839.
[294] H. Minn, M. Zeng, V.K. Bhargava, On timing offset estimation for OFDM systems, IEEE Commun. Lett. 4
(7) (2000) 242–244.
[295] M. Morelli, U. Mengali, An improved frequency offset estimator for OFDM applications, IEEE Commun.
Lett. 3 (3) (1999) 75–77.
[296] B. Natarajan, C.R. Nassar, S. Shattil, M. Michelini, Z. Wu, High-performance MC-CDMA via carrier inter-
ferometry codes, IEEE Trans. Veh. Technol. 50 (6) (2001) 1344–1353.
[297] R. Negi, J. Ciofﬁ, Pilot tone selection for channel estimation in a mobile OFDM system, IEEE Trans. Consum.
Electron. 44 (3) (1998) 1122–1128.
[298] S. Ohno, G.B. Giannakis, Capacity maximizing MMSE-optimal pilots for wireless OFDM over frequency-
selective block Rayleigh-fading channels, IEEE Trans. Inform. Theory 50 (9) (2004) 2138–2145.
[299] D.P. Palomar, J.M. Ciofﬁ, M.A. Lagunas, Joint Tx-Rx beamforming design for multicarrier MIMO channels:
A uniﬁed framework for convex optimization, IEEE Trans. Signal Process. 51 (9) (2003) 2381–2401.
[300] M. Poggioni, L. Rugini, P. Banelli, A novel simulation model for coded OFDM in Doppler scenarios, IEEE
Trans. Veh. Technol. 57 (5) (2008) 2969–2980.
[301] T. Pollet, M. Van Bladel, M. Moeneclaey, BER sensitivity of OFDM systems to carrier frequency offset and
Wiener phase noise, IEEE Trans. Commun. 43 (2/3/4) (1995) 191–193.
[302] Y. Rong, X. Tang, Y. Hua, A uniﬁed framework for optimizing linear nonregenerative multicarrier MIMO
relay communication systems, IEEE Trans. Signal Process. 57 (12) (2009) 4837–4851.
[303] L. Rugini, P. Banelli, Joint impact of frequency synchronization errors and intermodulation distortion on
the performance of multicarrier DS-CDMA systems, EURASIP J. Appl. Signal Process. 2005 (5) (2005)
730–742.
[304] L. Rugini, P. Banelli, G.B. Giannakis, Local ML detection for multicarrier DS-CDMA downlink systems
with grouped linear precoding, IEEE Trans. Wireless Commun. 5 (2) (2006) 306–311.
[305] B.R. Saltzberg, Performance of an efﬁcient parallel data transmission system, IEEE Trans. Commun. Technol.
15 (6) (1967) 805–811.
[306] O. Simeone, Y. Bar-Ness, U. Spagnolini, Pilot-based channel estimation for OFDM systems by tracking the
delay-subspace, IEEE Trans. Wireless Commun. 3 (1) (2004) 315–325.
[307] G.L. Stüber, J.R. Barry, S.W. McLaughlin, Y. Li, M.A. Ingram, T.G. Pratt, Broadband MIMO-OFDM wireless
communications, Proc. IEEE 92 (2) (2004) 271–294.
[308] V. Tarokh, H. Jafarkhani, On the computation and reduction of the peak-to-average power ratio in multicarrier
communications, IEEE Trans. Commun. 48 (1) (2000) 37–44.
[309] L. Tomba, On the effect of Wiener phase noise in OFDM systems, IEEE Trans. Commun. 46 (5) (1998)
580–583.
[310] U. Tureli, H. Liu, M.D. Zoltowski, OFDM blind carrier offset estimation: ESPRIT, IEEE Trans. Commun.
48 (9) (2000) 1459–1461.

References
293
[311] L.-L. Yang, L. Hanzo, Multicarrier DS-CDMA: a multiple access scheme for ubiquitous broadband wireless
communications, IEEE Commun. Mag. 41 (10) (2003) 116–124.
[312] W. Yu, R. Lui, Dual methods for nonconvex spectrum optimization of multicarrier systems, IEEE Trans.
Commun. 54 (7) (2006) 1310–1322.
[313] Y. Zhao, S.-G. Häggman, Intercarrier interference self-cancellation scheme for OFDM mobile communica-
tion systems, IEEE Trans. Commun. 49 (7) (2001) 1185–1191.
[314] S. Zhou, G.B. Giannakis, Finite-alphabet based channel estimation for OFDM and related multicarrier
systems, IEEE Trans. Commun. 49 (8) (2001) 1402–1414.

6
CHAPTER
Signal Processing for Vectored
Multichannel VDSL
Itsik Bergel and Amir Leshem
Faculty of Engineering, Bar-Ilan University, Ramat-Gan, Israel
2.06.1 Introduction
Digital subscriber line (DSL) is currently the most widespread technique for delivering broadband
internet to homes worldwide. By the end of 2010, over 300 million customers were served with DSL,
a number representing approximately 60% of global broadband customers. Furthermore, the telephone
network infrastructure is still capable of providing the ever increasing demand for larger bandwidth. Data
services to home customers began with the use of dialup modems over the public switched telephone
network (PSTN). The rates supported by these modems increased from 300 bps in the ﬁrst commercial
modem introduced in 1962 to 56 kbps in the v.92 standardized in 1998. To provide these increasing
data rates, more advanced communication and signal processing techniques have been developed. From
FSK in the 300 bps mode to a system using advanced precoding, shaping and trellis coding in the v.34
and the newer modems. However, it was clear from the outset that signaling over the 4 kHz voiceband
is an unnecessary limitation. In 1988 the UN telecommunication organization CCITT (which was later
renamed ITU) deﬁned the Integrated Services Data Networks (ISDN), which support symmetric rates
of up to 128 kbps using 256 kHz. At the same time as the development of the ISDN another standard
known as the high speed digital subscriber line (HDSL) was developed with the goal of providing
operators with a replacement for the expensive T1 (in the US) and E1 (in Europe) lines used to carry 24
or 32 voice channels. The idea was to use improved communication techniques so that the data could
be transmitted over regular telephone lines (commonly termed “twisted pairs”) instead of the special
lines used previously. HDSL supported rates of up to 2.048 Mbps over two twisted pairs using a 2B1Q
baseband modulation (similar to the ISDN modulation) and channel compensation techniques such as
a decision feedback equalizer (DFE) and reduced state Viterbi. However transmission was un-coded.
A good overview of the HDSL technology is given in [1]. Since transmission over two twisted pairs
is costly, a new standard HDSL2 was developed in the US and later extended to the Single Pair High
bit rate DSL (SHDSL) by the ITU-T. Concomitantly, an Asymmetric DSL (ADSL) was deﬁned [2]
mostly for residential broadband services. ADSL was the ﬁrst system to use multicarrier modulation,
dubbed Discrete Multi-Tone (DMT). In contrast to OFDM, the DMT modulation uses a different bit
loading on each carrier and real baseband signaling. Riding on the success of ADSL, the VDSL standard
was deﬁned [3]. The major difference between VDSL and ADSL is the larger bandwidth used by the
former. This allows for much higher upstream rates, but requires shorter lines. Therefore, the use of
the VDSL was delayed until optical network units were deployed in street cabinets and basements.
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-396500-4.00006-5
© 2014 Elsevier Ltd. All rights reserved.
295

296
CHAPTER 6 Signal Processing for Vectored Multichannel VDSL
VDSL provided data rates of up to 50 Mbps in the downstream and up to 25 Mbps in the downstream
in typical loops of 300 m and above. A good overview of single line DSL technology can be found in
books by Starr et al. [4] and Bingham [5].
To understand the ways data rates can be increased beyond VDSL rates, and achieve 100 Mbps
symmetric rates over typical twisted pairs, the channel characteristics of the twisted pair channel as
well as the crosstalk coupling between twisted pairs in a typical binder of twisted pairs need further
explanation. The characterization of the twisted pair channel and its capacity dates back many years.
A good example is the paper by Foschini [6] that described the binder using a multiport model. Later, the
statistical characteristics of crosstalk at low frequencies using log normal distributions was proposed
by Adie and Gibbs [7] and by Lin [8,9]. The models for the average and the 1% worst case were
proposed by Werner [10] and reﬁned by Kerpez [11,12]. Kalet and Shamai [13] and Aslanis and Ciofﬁ
[14] studied the capacity of single channel DSL systems using the above models. Later Karipidis et al.
[15,16] veriﬁed these models for frequencies up to 30 MHz, and studied the impact of crosstalk on the
capacity of multichannel DSL systems.
These studies make it clear that crosstalk is the limiting factor for increasing the rate of DSL systems.
To increase the data rates provided by single line VDSL, the crosstalk between twisted pairs has to be
eliminated. This prompted the need for multichannel processing, in which the signals of several modems
are jointly processed to overcome the crosstalk between the different twisted pairs. Such systems are
often termed “vectored” systems, as the signals of the relevant modems can be ordered in a vector form
that enables the use of matrix manipulations and linear algebra tools.
Unlike standard MIMO techniques, crosstalk cancellation in DSL systems can only be done at the
network side, where all twisted pairs originate. Lechleider was one of the ﬁrst to realize that crosstalk
cancellation might be an advantage in the context of two pair HDSL systems [17]. Ginis and Ciofﬁ[18]
proposed a single sided cancellation in the downstream direction using a multidimensional Tomlinson-
Harashima precoder. It was quickly observed that the loss in linear precoding is quite insubstantial, due
to the diagonal dominance of the DSL channel [19,20]. In these papers they showed that both upstream
and downstream crosstalk cancellation can be done using a linear zero forcing multichannel transmitter
(upstream) or receiver (downstream). At the same time, Leshem and Li [21–23] demonstrated that the
linear precoder can be simpliﬁed even further using an approximated power series expansion. This
completely reduced the complexity of the required matrix inversion. Cendrillon et al. [24,25] analyzed
the case of partial precoding where only some modems are coordinated.
An alternative adaptive precoder design was proposed by Louvaux and van der Veen [26]. Another
simpliﬁed version of the adaptive precoder was suggested independently by Louvaux and van der Veen
[27] and by Bergel and Leshem [28]. Bergel and Leshem provided a detailed analytic analysis. This
analysis showed that there are advantages in not precoding the signals of modems that do not gain much
from this precoding, since this can cause signiﬁcant delay in the convergence of the adaptive precoder.
Binyamini et al. [29] generalized this analysis to the case of partial precoding, where similarly to [24]
only some of the modems’ signals are precoded.
Along with the advances in precoding techniques, initial prototypes were built and an ITU stan-
dard G.993.5 was developed that deﬁned the requirements for vectoring VDSL systems. Recently,
commercial systems have been developed. These systems use the vectoring capabilities to achieve reli-
able rates at much larger distances, or to provide much higher data rates for the same line lengths.
One of the early prototypes was developed by an Israeli consortium called iSMART, which developed

2.06.2 System Model
297
FIGURE 6.1
Typical V41 ONU deployment.
techniques for vectoring. The outcome of this research was the V41 vectoring system developed by
ECI Telecom,1 which is depicted in Figure 6.1. A typical vectored VDSL system consists of an ONU,
which is typically deployed in a street cabinet or in the basement of high-rise buildings and multiple
customer premises equipment units (CPE). The ONU is connected to the operator’s network through
a high bandwidth optical link, and contains a multiuser vectored VDSL2 transceiver (V2DSL2) [30],
which jointly receives the information from all CPEs and precodes the information transmitted to all
CPEs such that all crosstalk between the lines is removed.
The V41 system can increase the coverage of 50 Mbps service from 400 m to 800 m over 0.4 mm
copper twisted pairs. This results in a factor 4 reduction in the ONUs required to provide a universal
50 Mbps service. Similarly, rates of 85 Mbps can be provided at a distance of 400 m.
The purpose of this chapter is to present the mathematical principles behind the current-day massive
multi-user systems, serving simultaneously 50–200 customers and canceling interference between all
these customers. It is remarkable that similar systems in the wireless domain serve 4–8 customers
simultaneously using the same spectrum. The main reason for the success of massive vectoring in the
DSL world is that the loss due to zero forcing precoding is marginal because of a channel property called
diagonal dominance and the ease of tracking the channels, which are relatively stationary compared to
wireless channels.
2.06.2 System model
A typical DSL channel is composed of many users, each connected through a twisted copper wire pair
to an Optical Network Unit (ONU), as depicted in Figure 6.2. Many of these twisted pairs are enclosed
1We thank Ido Shargil from ECI Telecom for providing the information on the v41 platform.

298
CHAPTER 6 Signal Processing for Vectored Multichannel VDSL
NEXT
NEXT
ONU
Fiber
FEXT
CPE1
h1,1
h1,2
h2,2
hL,L
h2,1
CPE2
CPEL
FIGURE 6.2
The DSL channel structure.
(at least part of the way) in the same binder. In this work we focus on a group of users that are served
through the same binder.
Each user’s modem (termed also customer premises equipment, CPE) aims to transmit data to
the network and receive data from the network over its twisted pair. The connection to the network is
established through an optical network unit (ONU) which is connected to the network backbone through
an optical ﬁber. The ONU can be located at the telephone switch (also termed central ofﬁce). However,
in recent years, in order to enable higher data rates, the ONU is typically located closer to the users,
in street cabinets or even in the users’ building. A shorter distance between the CPE and ONU will
result in lower signal attenuation, which can lead to a higher signal to noise ratio (SNR) and higher data
rates in the absence of interference. But, as the typical SNR increases, the main limiting factor of DSL
systems is inter-user interference.
This inter-user interference results from electromagnetic coupling in the binder, and is divided into
two types as shown in Figure 6.2. The crosstalk from signals that originate from the same end as the
affected receiver is termed near end crosstalk (NEXT). In VDSL, the impact of NEXT is suppressed by
employing frequency-division duplexing (FDD) and transmitters synchronization. The crosstalk from
signals that originate from the opposite side of the binder is termed far end crosstalk (FEXT). FEXT is
typically the main limiting factor on the performance of DSL systems.
The downstream and upstream of the DSL channel share the same channel, but are rather different
in nature. The difference comes from the fact that multichannel processing can be applied only at the
ONU. The upstream describes the transmission of data from the CPEs and reception in the ONU. This
is a multiple access channel, in which the ONU decodes the data transmitted from multiple CPEs.
The downstream describes the transmission of data from the ONU and reception in the CPEs. This is a
broadcast channel, in which the ONU transmits data to multiple CPEs while minimizing the interference
between the transmitted signals.

2.06.2 System Model
299
Since the upstream and downstream share the same channel, in this section we describe this shared
channel. We therefore refer to transmitters and receivers, which will later be translated into CPEs and
ONU according to the context. Note that regardless of the actual ONU internal structure, in the following
we refer to the ONU as a set of cooperating transmitters/receivers, where each transmitter/receiver is
connected to a single twisted pair.
The channel received at the ith receiver is:
yi[n] =
L−1

j=0
n

m=n−ν+1
ht
i, j(m)x j[n −m] + wi[n],
(6.1)
where L is the number of transmitters, x j[n] is the sample transmitted by transmitter j at time n, and
wi[n] is the sampled noise. In this model, the sampled noise term can include in addition to thermal
noise also interference from various sources such as radio transmissions, neighboring DSL systems
and more. Nevertheless, it is generally assumed that the noise samples are independent and identically
distributed (i.i.d) Gaussian random variables with zero mean and variance of E

|wi[n]|2
= σ 2.
The impulse response of the channel between the jth transmitter and the ith receiver is denoted
by ht
i, j(m) and ν is the maximal length of the channel impulse response (also termed the channel
memory).2 Note that each receiver is affected by all the transmitters in the system. Thus, ht
i,i(m)
describes the channels for the direct signals, and ht
i, j(m) for i ̸= j describes the crosstalk channels.
Typically, the actual lengths of the various channel impulse responses are different. In the following
we take ν to denote the maximal channel memory handled by the system, and assume that all channel
impulse responses are zero padded to a length of ν.
Without loss of generality, in the following we focus on the transmission and reception of symbol
number 0, i.e., the block of N input samples, xt
j =

x j[0], . . . , x j[N −1]
T . DSL systems achieve
reception that is free of inter symbol interference (ISI) using the discrete Fourier transform (DFT) and
a cyclic preﬁx (CP).
The DFT processing of multiple user signals requires the synchronized reception of all transmis-
sions. Such a synchronization is easily achieved at the downstream, as all transmission originate in
the same location. In the upstream, the synchronized reception of all signals transmitted from different
CPEs needs more attention. This synchronization is achieved by shifting the transmission time of each
CPE according to the delay between the speciﬁc CPE and the ONU (using timing feedback from the
ONU). This procedure is analogous to the problem of synchronized uplink transmissions in cellular
networks. The synchronization timing requirements can be further relaxed using the “Zipper” technique
(see [31,32]).
The ν −1 samples prior to the transmission of each block are devoted to the CP using:
x j[−n] = x j[N −n]
(6.2)
2We use the notation •t to indicate time domain quantities. In the following we will also use the notations •f and •F to indicate
frequency domain quantities.

300
CHAPTER 6 Signal Processing for Vectored Multichannel VDSL
for n = 1, 2, . . . , ν −1. Using (6.2) in (6.1), the vector of output symbols yt
j =

y j[0], . . . , y j
[N −1]
T can be described by:
yt
i =
L−1

j=0
Ht
i, jxt
j + wt
i,
(6.3)
where wt
i =

wi[0], . . . , wi[N −1]
T is the vector of noise samples, and the Ht
i, j is a circulant channel
matrix in which the (a, b) element is:
Ht
i, j(a, b) =
 ht
i, j(a −b mod N)
0 ≤a −b mod N ≤ν −1,
0
otherwise.
(6.4)
More graphically, the circulant channel matrix has the form:
Ht
i, j =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
ht
i, j(0)
0
· · ·
0
ht
i, j(ν −1)
· · ·
ht
i, j(1)
ht
i, j(1)
ht
i, j(0)
...
...
0
...
...
...
ht
i, j(1)
...
0
...
0
ht
i, j(ν −1)
ht
i, j(ν −1)
...
...
ht
i, j(0)
0
...
0
0
ht
i, j(ν −1) ...
ht
i, j(1)
...
...
...
...
...
...
...
...
ht
i, j(0)
0
0
· · ·
0 ht
i, j(ν −1)
· · ·
ht
i, j(1)
ht
i, j(0)
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
.
(6.5)
In DSL the data processing is performed in the frequency domain using the discrete Fourier transform
(DFT). The normalized DFT matrix is given by:
QDFT(a, b) =
1
√
N
e−j 2π
N ab
(6.6)
and satisﬁes Q−1
DFT = QH
DFT. The transmitted samples of the jth user are generated using an inverse
DFT (IDFT) operation: xt
j = QH
DFTxF
j . Then, taking the DFT of the output vector, (6.3), results in the
frequency domain channel output:
yF
i = QDFTyt
i =
L−1

j=0
HF
i, jxF
j + wF
i ,
(6.7)
where
HF
i, j = QDFTHt
i, jQH
DFT
(6.8)
is the frequency domain channel matrix between transmitter j and receiver i, and wF
i = QDFTwt
i is the
frequency domain Gaussian noise with zero mean and covariance matrix of E[wF
i (wF
i )H] = σ 2 · I.

2.06.2 System Model
301
Recalling that the time domain channel matrix, (6.4), is a circulant matrix, the frequency domain channel
matrix HF
i, j is a diagonal matrix,3 and hence the received signal matrix is free of ISI.
Although the DSL signal is not degraded by ISI, inspecting the sum in (6.7) one can see that it is
highly affected by another type of interference, namely, inter user interference that results from FEXT.
To better characterize and resolve the FEXT, it is convenient to restate the input-output relation, grouping
all users for each frequency bin separately. Deﬁning y f =

yF
0 ( f ), . . . , yF
L−1( f )
T , the output sample
at the f th frequency bin for all users can be described by:
y f = H f x f + w f ,
(6.9)
where x f =

xF
0 ( f ), . . . , xF
L−1( f )
T is the vector of samples transmitted by all users, w f =

wF
0( f ),
. . . , wF
L−1( f )
T is the vector of noise measured by all users and the combined channel matrix is
given by:
H f (i, j) = HF
i, j( f , f ).
(6.10)
In most cases, the processing and analysis of DSL signals is performed for a single frequency bin at
a time. Thus, the relation described by Eq. (6.9) is very useful. In many cases we will even drop the
frequency bin indices (f ) where the speciﬁc frequency bin number is not crucial.
The power constraint is also stated in the frequency domain in the form of a spectrum power mask.
In the following we assume that all users follow the same spectrum mask, and the power constraint is
given by:
E

|x f ( j)|2
≤p f .
(6.11)
2.06.2.1 Channel matrix structure
As the FEXT results from electromagnetic coupling and not from a direct wire connection, in most
frequencies the FEXT is signiﬁcantly smaller from the direct signal. Thus, it has been noted [19] that
upstream VDSL channel matrices are column-wise diagonally dominant (CWDD), while downstream
matrices are row-wise diagonally dominant (RWDD). This diagonal dominance channel matrix structure
is one of the main features that distinguish DSL systems from other MIMO systems. Hence, most DSL
speciﬁc research has used this feature in some way or another.
For simplicity we will ﬁrst describe the RWDD structure of the downstream channel and then
comment on the upstream channel. Basically, in a RWDD matrix, the diagonal element dominates all
other elements in the row. The weakest deﬁnition states that a matrix is weakly RWDD if
|H(i, i)| > |H(i, j)|
(6.12)
for j ̸= i. One can also quantify how much is the matrix RWDD using:
βD,1 = max
i, j
|H(i, j)|
|H(i, i)| .
(6.13)
3Recalling that the eigenvalue decomposition of a circulant matrix contains the DFT and IDFT matrices, and a diagonal
frequency domain channel matrix.

302
CHAPTER 6 Signal Processing for Vectored Multichannel VDSL
ℓ
FEXT
ONU
CPE1
CPE2
2
h1,1
h2,1
h1,2
h2,2
ℓ1
FIGURE 6.3
Mixed length downstream DSL.
A matrix is weakly RWDD if βD,1 < 1, and as βD,1 decreases the matrix is said to be “more”
RWDD.
An alternative measure compares the diagonal element to the sum of the absolute values of the
elements in the rest of the row:
βrow = max
i

j̸=i |H(i, j)|
|H(i, i)|
.
(6.14)
A matrix that satisﬁes βrow < 1 is said to be strongly RWDD.
If all pairs in the binder have the same length, the magnitude of the diagonal elements in the matrix is
nearly identical, and the matrix can be termed simply diagonally dominant. The differentiation between
RWDD and CWDD is important mostly in mixed length scenarios. Figure 6.3 depicts a 2-user mixed
length downstream scenario with a short link of length ℓ1 and a long link of length ℓ2. Note that the
FEXT is only generated in the joint part (of length ℓ1). Thus, the FEXT into the short link is equivalent
to the FEXT in the case of equal link binder, and it is signiﬁcantly smaller than the direct link signal.
For the longer link, the FEXT contribution can be split into a cascade of two systems: in the ﬁrst system
there is a FEXT contribution into the ℓ1 initial segment of the link, and in the second system this FEXT
is further attenuated by a link of length ℓ2 −ℓ1. Hence its mean response is [10]:
KFEXT f 2ℓ1I L(ℓ1, f )I L(ℓ2 −ℓ1, f ),
(6.15)
where I L(ℓ, f ) is the typical loop insertion loss at length ℓand frequency f and KFEXT is a constant
that depends on the type of cable. Note that from the equal length case we already concluded that
KFEXT f 2ℓ1 ≪I L(ℓ1, f ). Recalling that
I L(ℓ1, f )I L(ℓ2 −ℓ1, f ) = I L(ℓ2, f ),
(6.16)
the cascade of the two LTI systems shows that
KFEXT f 2ℓ1I L(ℓ2, f ) ≪I L(ℓ2, f ).
(6.17)
From(6.17)wecanconcludethatanevenmoreaccuraterepresentationofthechannelmatrixstructure
is given by [22]:
H = D(I + E),
(6.18)
where the matrix E has zeros on its diagonal and all its elements are (signiﬁcantly) smaller than one.
This type of deﬁnition turns out to be important for the convergence analysis of adaptive precoders.

2.06.2 System Model
303
The corresponding measure is:
βD,max = max

max
i

j̸=i |H(i, j)|
|H(i, i)|
, max
j

i̸= j |H(i, j)|
|H(i, i)|

.
(6.19)
Note that although the sum in the ﬁrst maximization in (6.19) is taken over rows and the sum in the
second maximization is taken over columns, both are measures of RWDD. This is because in both cases
each matrix element, H(i, j), is divided by the diagonal element in its own row, H(i, i). Thus the
βD,max serves as another indication that no element in the matrix is signiﬁcant compared to the diagonal
element in its row.
As for the upstream, one only needs to observe that due to the channel reciprocity, the upstream
channel matrix at each frequency is the transpose of the upstream channel matrix at the same frequency.
DSL systems work in FDD mode and hence no frequency is used simultaneously for both upstream and
downstream. However, for channel characterization purposes the channel reciprocity holds, and we can
simply apply the above deﬁnitions ((6.13), (6.14) and (6.19)) to the transposed channel matrix. Thus,
we deﬁne:
βU,1 = max
i, j
|H( j, i)|
|H(i, i)| ,
(6.20)
βcol = max
i

j̸=i |H( j, i)|
|H(i, i)|
(6.21)
and
βU,max = max

max
i

j̸=i |H( j, i)|
|H(i, i)|
, max
j

i̸= j |H( j, i)|
|H(i, i)|

.
(6.22)
A matrix is weakly CWDD if βD,1 < 1, and strongly CWDD if βrow < 1. The channel decomposition
of (6.18) is replaced from the upstream with: [22]:
H = (I + G)D,
(6.23)
where the matrix G has the same characteristics as the matrix E, i.e., it has a zero on its diagonal and
all its elements are (signiﬁcantly) smaller than one.
To demonstrate the diagonal dominance of the channel matrices, Figure 6.4 depicts the values of
βD,1 and βD,max as a function of frequency for binder lengths of 150–300 m. It is clear that, at both
lengths, the channel matrices are strongly diagonal dominant for practically all frequencies. In this plot
we do not show βrow, as it was nearly identical to βD,max for all frequencies at both binder links.
Note on ﬁgures: All the numerical results in this paper rely on channel measurements carried out by
France Telecom at different lengths over a binder with 28 twisted pairs.4 All simulations presented here
were carried out under the assumption that the whole bandwidth of the VDSL system is completely
dedicated to the downstream or completely dedicated to the upstream. The transmission SNR is set
to η = p/σ 2 = 80 dB (corresponding to the typical values of p = −60 + 10 log10 B dBm and
σ 2 = −14010 log10 B dBm, where 1/B is the symbol length).
4The authors thank M. Ouzzif, R. Taraﬁ, H. Marriott, and F. Gauthier of France Telecom R&D, who conducted the VDSL
channel measurements under the auspices of the U-BROAD project.

304
CHAPTER 6 Signal Processing for Vectored Multichannel VDSL
0
5
10
15
20
25
30
0
0.2
0.4
0.6
0.8
1
Frequency [MHz]
βmax, d=300m
βmax, d=150m
β1, d=300m
β1, d=150m
FIGURE 6.4
Row-wise diagonal dominance measures: βD,1 and βD, max as a function of frequency for two binder lengths.
2.06.3 Downstream transmission
2.06.3.1 Nonlinear precoding
In the downstream (or in its more general term: the broadcast channel) the receiving modems are located
in different customer premises and cannot cooperate to achieve FEXT cancellation. On the other hand,
the transmitting modems are co-located at the ONU, and hence FEXT cancellation is feasible using
joint signal processing of the transmitted symbols.
Ginis and Ciofﬁ[18] considered the use of a QR decomposition followed by a Tomlinson-Harashima
like modulo operation [33,34]. Considering the LQ decomposition of the channel matrix we can write:
H = LQH,
(6.24)
where Q is a unitary matrix and L is a lower triangular matrix. An even more convenient representation
is the QR decomposition of the conjugate transpose of the channel matrix, given by HH = QR where
R = LH is an upper triangular matrix.
Let u denote the modulated symbols that need to be transmitted in the f th frequency bin by all users.
In the following we consistently assume that the modulated symbols of all users in the same subcarrier

2.06.3 Downstream Transmission
305
are iid random variables (which is reasonable given our assumption that all users comply with the same
spectral mask). We further assume that E

u(i)

= 0 and E

|u(i)|2
= p.
The modulated symbols are ﬁrst precoded to reduce interference due to the matrix R:
x′(0) = u(0),
x′(1) = c1

u(1) −R∗(0, 1)
R∗(1, 1) x′(0)

,
...
x′(L −1) = cL−1

u(L −1) −
L−2

i=0
R∗(i, L −1)
R∗(L −1, L −1)x′(i)

,
(6.25)
where the modulo operation is deﬁned by:
ci {u} = Re(ci)mod
 Re(u)
Re(ci)

+ j · Im(ci)mod
 Im(u)
Im(ci)

(6.26)
the index ci gives the constellation size for user i, i.e., Re(ci) is the number of possible modulation
values for the real part of u(i) multiplied by the distance between modulation points, Im(ci) is the
number of possible modulation values for the imaginary part of u(i) multiplied by the distance between
modulation points. The operation mod() is a modulo type operation that returns values in the range
[−0.5, 0.5), i.e., mod (u) = (u + 0.5 mod 1) −0.5.
Figure 6.5 illustrates this precoding with a modulo operation for the case of QPSK modulation. The
possible modulation values are depicted by circles. The allowed transmission range is depicted by the
middle square, and its modulo equivalents are depicted by dashed squares. The transmitter wishes to
transmit the top right modulation value (u( j)). The solid arrow represents the subtraction of interference
from previous users, and hence, the square mark represents the value to be transmitted in order to achieve
full interference cancellation without the modulo operation. The dashed arrow represents the modulo
operation, and the ﬁnal resulting precoded value, x′( j), is represented by the x-mark.
In order to achieve interference-free reception, the symbols, x′, still need to be rotated using the
matrix Q. This rotation is given by:
x = Qx′.
(6.27)
It is easy to verify that without the modulo operation, this scheme already achieves complete FEXT can-
cellation. The role of the modulo operation is to reduce the power increase due to the FEXT cancellation
(just as in the classic Tomlinson-Harashima setting [33,34]).
To reciprocate the modulo operation, each receiver performs the modulo operation:
ˆu(i) = ci

y(i)
R∗(i, i)

.
(6.28)

306
CHAPTER 6 Signal Processing for Vectored Multichannel VDSL
d
2 ⋅ d
FIGURE 6.5
Illustration of the TH modulo operation.
To verify the FEXT cancellation, we substitute (6.9), (6.24), (6.25), and (6.27) in (6.28)
and get:
ˆu(i) = ci
i
j=0 R∗( j, i)x′( j) + w(i)
R∗(i, i)

= ci
⎧
⎨
⎩x′(i) +
i−1

j=0
R∗( j, i)
R∗(i, i) x′( j) +
w(i)
R∗(i, i)
⎫
⎬
⎭
= ci
⎧
⎨
⎩ci
⎧
⎨
⎩u(i) −
i−1

j=0
R∗( j, i)
R∗(i, i) x′( j)
⎫
⎬
⎭+
i−1

j=0
R∗( j, i)
R∗(i, i) x′( j) +
w(i)
R∗(i, i)
⎫
⎬
⎭
= ci

u(i) +
w(i)
R∗(i, i)

,
(6.29)
where the last line results from ci {ci {a} + b} = ci {a + b}. It is further shown in [18] that the noise
increase as well as the power increase are negligible in DSL systems, hence resulting in a near optimal
FEXT free communication scheme.

2.06.3 Downstream Transmission
307
The above method can be interpreted as a suboptimal implementation of the zero-forcing “dirty-
paper” precoding scheme proposed in [35] and studied in [36]. An improvement of the scheme was
proposed in [37], where Tomlinson-Harashima precoding was replaced by more efﬁcient trellis precod-
ing schemes. The broadcast channel has been further studied in many works, mostly in the context of
wireless MIMO systems. However, for DSL systems, most of the focus has shifted to linear precoders
that combine very good performance and lower implementation complexity.
2.06.3.2 Linear precoding
2.06.3.2.1
The zero forcing precoder
Linear precoders have often been considered for low complexity interference cancellation over broadcast
channels. A linear precoder transmits a signal which is a linear combination of the modulated data
symbols. Denoting the precoding matrix by F, the transmitted vector for all users is given by:
x = Fu.
(6.30)
The linear precoder must satisfy the system power constraint. Assuming that all users have the same
power constraint in each frequency (same spectral mask) and that the modulated data symbols u satisﬁes
the power constraint, the constraint on the precoder is given by:
L−1

i=0
|F( j, i)|2 ≤1 ∀j.
(6.31)
Linear precoders attracted considerable attention in DSL systems mostly following the work of Cen-
drillon et al. [38]. In that work, the authors showed that the zero forcing (ZF) precoder achieves near
optimal performance in most DSL channels. Cendrillon et al. adopted the ZF linear precoder given by:
F = γ H−1D,
(6.32)
where D is the diagonal matrix with the same diagonal elements as H and γ is a constant chosen to
satisfy the power constraint (6.31). (In that work they termed this precoder the diagonalizing precoder,
to distinguish it from the more trivial ZF precoder: F = H−1.) Obviously, substituting (6.32) and (6.30)
in (6.9) results in FEXT free reception:
y = γ Du
(6.33)
and the achievable data rate by user i in any speciﬁc subcarrier is given by:
R = 
F · log2

1 + −1γ 2|H(i, i)|2η

,
(6.34)
where  is the gap between the used precoder performance and the actual capacity (commonly termed
the Shannon gap [39]), and 
F is the symbol rate.
The main question is how large can γ be. In their work Cendrillon et al. [38] showed that γ can
typically be set very close to 1, and hence the ZF precoder achieves near optimal performance. The
key to this near optimality is the structure of the DSL channel matrix, and in particular the row-wise
diagonally dominant (RWDD) channel matrix. To prove this, they presented an upper bound on the

308
CHAPTER 6 Signal Processing for Vectored Multichannel VDSL
capacity and a lower bound on the achievable data rates using the ZF linear precoder. Here we present
the simpler (but generally tighter) bounds of Bergel and Leshem [40], which rely on the strong diagonal
dominance measures. The upper bound is described by the following theorem.
Theorem 1.
The data rate achievable by user i in any speciﬁc subcarrier of the downstream of DSL
systems is upper bounded by:
C ≤
F · log2

1 + −1η|H(i, i)|2 
1 + βrow
2
.
(6.35)
Proof.
Considering only the ith receiver. Taking into account the channel structure, (6.9), and the
power constraint on the precoder, (6.31), the maximal signal power for this user is achieved using
a precoder in which only the ith column is non-zero, and the absolute value of all elements in this
column is 1. Using such a precoder, the maximal signal power for the ith user is: ( L−1
j=0 |H(i, j)|)2 · p.
Calculating the achievable user rate, and maximizing over all users results in (6.35), and completes the
proof of the theorem.
On the other side we have:
Theorem 2 [40]. The data rate achievable by user i in any speciﬁc subcarrier when the ONU applies
a ZF precoder is lower bounded by:
R ≥
F · log2

1 + −1 f (βD,max)|H(i, i)|2η

,
(6.36)
where
f (βD,max) = max

0, 1 −2βD,max −β2
D,max

.
(6.37)
Figure 6.6 depicts the achievable performance using a ZF precoder and compares it to the upper and
lower bounds. In this ﬁgure, as well as in all numerical rates evaluation in what follows, we assume a
0 dB Shannon gap, i.e.,  = 1. Note that the bounds are tight for low frequencies. For such frequencies
βD,max is very small, and comparing (6.35) and (6.36) the bound tightness for small enough βD,max
is obvious. For higher frequencies the lower bound becomes useless when βD,max >
√
2 −1. Yet,
the actual ZF performance is still very close to the upper bound for all frequencies. For reference, the
ﬁgure also depicts the achievable rates without precoding, and the achievable rates in the single user
case, i.e., when only a single twisted pair in the binder is used. It shows that ZF performance nearly
matches the single user performance and is signiﬁcantly higher than the no precoding scheme. However,
although the single user performance seems as worthy target, it is important to note that this curve is not
a performance bound. This is because we cannot rule out the possibility that the inter-user connections
will be used to increase user capacity. In particular, the upper bound corresponds to the case where
all the inter-user connections for one of the users are used to increase this user’s capacity. Thus, the
importance of the upper bound is in showing that even in the most optimistic case, the achievable rate
cannot exceed the ZF rates by more than 10%.
Figure 6.7 shows that the Cendrillon et al. [38] bounds were ahead of their time. The ﬁgure depicts
the actual achievable rate in the case that all of the VDSL bandwidth is dedicated to the downstream vs.

2.06.3 Downstream Transmission
309
0
5
10
15
20
25
30
0
20
40
60
80
100
120
Frequency [MHz]
Rate [Kbps]
Upper bound
ZF
Single user
Lower bound
No precoding
FIGURE 6.6
Average achievable user rate over a single subcarrier and bounds, as a function of the subcarrier frequency,
at a 150 m binder.
the distance between the ONU and the CPEs. The ﬁgure also presents the upper bound of Theorem 3
and the lower bound of Theorem 2. It is clear that the bounds are tighter and the achievable data rate
is higher for shorter link distances. In recent years, as the optical ﬁbers deployment has expanded, the
lengths of VDSL links have continually decreased. Hence, although the bounds presented by Cendrillon
et al. were not tight for the typical link length at the time, nowadays, and certainly in the future, the
typical link length is much shorter, and the bounds can be considered tight.
Nevertheless, it should be pointed out that the ﬁnal conclusions of Cendrillon et al. [38] hold for
all practical link distances. Comparing the achievable data rates of the ZF precoder to the upper bound
shows that the precoder is indeed close to optimal. Furthermore, the performance of the ZF precoder
is nearly identical to the more reasonable target of the single user performance (i.e., a system with a
single user, transmitting over only one twisted pair).
2.06.3.2.2
Reduced complexity ZF precoding
The use of linear precoders reduces the transmitter implementation complexity, and does not require any
modiﬁcation of the CPE (the downstream receivers). But as DSL technology achieves ever higher data
rates, the implementation complexity of linear receivers is still too high. The implementation complexity

310
CHAPTER 6 Signal Processing for Vectored Multichannel VDSL
0
100
200
300
400
500
600
0
100
200
300
400
500
600
700
Binder length [meter]
Rate [Mbps]
Upper bound
ZF
Single user
Lower bound
No precoding
FIGURE 6.7
Average achievable user rate over the whole bandwidth vs. binder length.
is composed of the computation of the precoding matrix, and the computation of the precoded signals
using the precoding matrix.
To reduce the complexity of the ﬁrst part, Leshem and Li [22] suggested computing the precoder
matrix using a ﬁrst or second order approximation of the channel matrix. As stated above, the γ power
normalization constant in (6.32) is very close to 1. Neglecting this power normalization constant, the
ZF precoder is given by:
FZF = H−1D.
(6.38)
Using the notation of (6.18) the ZF precoder can be rewritten as:
FZF = (I + E)−1.
(6.39)
As shown in [28], if βD,max < 1, then the maximal singular value of E is smaller than one, and hence
the ZF precoder, (6.39), can be represented by a converging Taylor expansion:
FZF = I −E + · · · + ( −1)ℓEℓ+ · · · .
(6.40)
Hence, they suggested using a ﬁrst or second order Taylor approximation of (6.40), which eliminates
the need for matrix inversion.

2.06.3 Downstream Transmission
311
The ﬁrst order approximation is given by:
FZF1 = I −E = 2 · I −D−1H.
(6.41)
The complexity reduction is signiﬁcant in that the matrix inverse operation in (6.38) is replaced by the
inverse of a diagonal matrix, which requires only L single element inversions. For the cases in which
the ﬁrst order approximation is not accurate enough, Leshem and Li suggested using the second order
approximation, given by:
FZF2 = I −E + E2 = I + (I −D−1H)(2 · I −D−1H).
(6.42)
See [22] for a detailed analysis of this implementation approach and the complexity reduction factor.
They also provided a lower bound on the performance of their proposed precoders. Interestingly,
their bounds require only a form of weak RWDD, i.e., the bounds hold even in cases where the Taylor
expansion in (6.40) might not converge. For example, for the ﬁrst order ZF precoder they give the
following bound:
Theorem 3 [22]. If the channel matrix is weekly RWDD, and satisﬁes (L −1)β2
D,1 < 1, then the data
rate achievable by user i in any speciﬁc subcarrier of the downstream of a DSL system that applies the
ﬁrst order precoder given in (6.41) is lower bounded by:
R ≥
F · log2
⎛
⎝1 +
η(1 −(L −1)β2
D,1)|H(i, i)|2


1 + η(L −2)2(L −1)β4
D,1|H(i, i)|2

⎞
⎠.
(6.43)
Figure 6.8 shows the performance of the approximated precoders over real channel measurements.
As can be seen, the ﬁrst order approximation is good when the FEXT is low (in particular at low
frequencies). For higher frequencies, the ﬁrst order approximation precoder still achieves reasonable
precoding at a link distance of 300 m (a capacity loss of around 10%). As link distances get shorter,
the SNR increases and the FEXT cancellation of the ﬁrst order approximation is not sufﬁcient, as can
be seen for the 75 m binder in the ﬁgure. On the other hand, the second order approximation precoder
achieves near optimal performance in all the tested scenarios.
However, the computational complexity of the matrix inversion is not the only problem. With 4000
symbols per second, and thousands of subcarriers, even the application of the precoder (i.e., the multi-
plication F · u) requires too many computations. This implementation complexity has been researched
from two points of view. First, the number of bits per sample needs to be considered.
2.06.3.2.3
Quantization of word length for ZF precoding
Sayag et al. [41] studied the effect of word length on the performance of ZF precoders. Their main
theorem formulates the capacity loss in a system that uses d bits for the quantization of the real part and
d bits for the quantization of the imaginary part of the precoding matrix. Their main theorem is:
Theorem 4. If the number of quantization bits of the ZF precoder satisﬁes d ≥1
2 + log2 (1 + βrow),
then the transmission rate loss of the ith user at any speciﬁc subcarrier due to quantization is upper
bounded by:
log2 (1 + 2(L −1)(1 + βrow)22−2d|H(i, i)|2η) −2 log2 (1 −
√
2(1 + βrow)2−d).
(6.44)

312
CHAPTER 6 Signal Processing for Vectored Multichannel VDSL
0
5
10
15
20
25
30
0
10
20
30
40
50
60
70
80
90
100
110
d=75
d=300
Frequency [MHz]
Rate [Kbps]
ZF precoder
Second order precoder
First order precoder
FIGURE 6.8
Average achievable user rate over a single subcarrier as a function of the subcarrier frequency, for the ZF
precoder, and its ﬁrst and second order approximation. The ﬁgure shows results for a 75 m binder and for a
300 m binder.
In their work they further studied the rate loss using the Werner channel model [10], and show, for
example, that a quantization of 14 bits for the real part and 14 bits for the imaginary part is sufﬁcient to
guarantee a rate loss of no more than 1% for links of 300 m or more. Note that shorter links experience
higher signal levels, and hence the FEXT cancellation requirements are stricter (thus requiring more
quantization bits).
2.06.3.2.4
Partial ZF precoding
Another way to reduce the complexity of FEXT cancellation is to cancel only some of the interference
sources. Writing explicitly the computation of each transmitted symbol, from (6.30) we have:
x(i) =
L−1

j=0
F(i, j)u( j).
(6.45)
Thus, every zero element in the precoder matrix, F, saves one multiplication. Cendrillon et al. [25]
studied the performance of ZF DSL precoders with various constraints on the number of non-zero
elements in F.

2.06.3 Downstream Transmission
313
Given the set of interference sources to be canceled for each user, the evaluation of the optimal
precoder is not trivial. Cendrillon et al. suggested an adjustment of the ZF criterion for this case, by
reducing the number of constraints. If the total number of non-zero elements in the precoding matrix F
is rT, one can solve a system of rT linear equations, i.e., force rT zeros in the resulting effective channel,
HF. Cendrillon et al. showed how to solve this ZF problem when the zero elements of HF are in the same
locations as the zero elements in the precoding matrix, F. The description given here is slightly more
general than the original, to include also the equations needed for partial adaptive precoding presented
in Section 2.06.3.3.
Let G j = {g1
j . . . g
r j
j } ⊆{1, 2 . . . L} be the set of receivers that need to cancel the FEXT originating
from user j. Denote the set size by 0 ≤r j =
$$G j
$$ ≤L.5 We deﬁne the ZF partial precoder as:
FP = ˆFP + I,
(6.46)
where the matrix ˆFP satisﬁes ˆFP(i, j) = 0 for any i /∈G j. The elements with non-zero values in ˆFP are
constructed according to the generalization of the ZF principle, which completely cancels the FEXT
generated by the jth user to all users i ∈G j. To simplify the precoder analysis we deﬁne the (r j × L)
selection matrices,  j:
 j(m, i) =
 1 i = gm
j
0 otherwise .
(6.47)
Applying the partial ZF criterion, the jth column of the precoder is constructed to satisfy:
 jHF( j)
P
=  jD( j),
(6.48)
where A( j) is the jth column of the matrix A. Note that ˆF( j)
P
has zeros in the rows that do not belong
to the set G j; thus, the non-zero elements of ˆF( j)
P
are given by  j ˆF( j)
P , and:
ˆF( j)
P
= T
j  j ˆF( j)
P .
(6.49)
Substituting (6.46) and (6.49), in (6.48) we have:
 jD( j) =  jH( j) +  jHT
j  j ˆF( j)
P ,
(6.50)
and the non-zero elements of ˆF( j)
P
are given by:
 j ˆF( j)
P
=

 jHT
j
−1
 j

D( j) −H( j)
.
(6.51)
Note that  jHT
j is a non singular matrix formed by the elements of the channel matrix that are located
in the rows and columns that belong to G j (i.e., by H(m, i) : m, i ∈G j). Partial precoder results with
5Note that we allow the set G jto be empty. On the other hand, Cendrillon et al. [25] required G j to always include at least the
element j. As can be seen from (6.46), setting G j = G j
% j does not increase the implementation complexity. Thus, G j = ∅
is required only in the context of adaptive precoding.

314
CHAPTER 6 Signal Processing for Vectored Multichannel VDSL
residual FEXT whose powers (for all users) are given by the diagonal of:
Z = p
L

j=1

HF( j)
P
−D( j) 
HF( j)
P
−D( j)H
.
(6.52)
However, the utilization of a partial precoder requires the transmitter to ﬁrst obtain a good enough
channel estimation, and then apply a good enough selection algorithm. Cendrillon et al. [25] considered
several user selectionalgorithms. Theytestedabinder with8users inwhichusers at 900 m couldincrease
their rate by 72% using complete FEXT cancellation. They showed that by proper user selection, a
system can achieve 41% of this rate increase with only 20% of the implementation complexity. They
also considered a FEXT cancellation over only part of the DMT subcarriers, and showed that a scheme
that performs both user and tone selection can perform even better and achieve 77% of the rate increase
with 20% of the implementation complexity. (Note however for shorter link lengths that FEXT is more
dominant and the gains with the same implementation complexity will be smaller). Figure 6.11 below
also depicts the performance of a partial precoder for a 28 user binder over a length of 300 m. Note
that rT represents the number of multiplications per precoding operation, averaged over all subcarriers.
Again a signiﬁcant part of the rate gain can be achieved with a relatively small part of the complexity.
Vangorp et al. [42] extended this work, and presented a low complexity algorithm for optimal resource
allocation given limited complexity for the partial FEXT cancellation.
Uplink partial FEXT cancellation was also considered in the same framework [24]. We will not
describe this here in more detail, since the analysis and results are quite similar. It should be noted that
for the upstream Pandey et al. [43] also considered a partial MMSE receiver. But as demonstrated in
Section 2.06.4.1, the MMSE receiver does not gain much in most common scenarios.
2.06.3.3 Adaptive precoding
The use of low complexity linear precoders made FEXT cancellation feasible in high rate DSL systems.
However, recall that in the downstream the transmitter at the ONU cannot directly measure the channel
matrix. Hence, the calculation of the precoding matrix must rely on feedback from the receivers. Two
main types of feedback have been considered: channel estimation feedback and signal error feedback.
Channel estimation feedback is based on the transmission of orthogonal (synchronized) pilot symbols
from all transmitters simultaneously, and an estimation of a row of the channel matrix by each receiver.
This estimated row is then transmitted (through the upstream) back to the transmitter, which uses it to
construct the full channel matrix H and to calculate the precoding matrix F. This approach mostly uses
standard (and not DSL speciﬁc) techniques, and hence has mostly been discussed in implementation
oriented publications.
Signal error feedback is a more DSL speciﬁc method, and is based on the feedback of a quantized
version of the error signal measured by each receiver. The error signal measured by the ith receiver is:
ϵ(i) = y(i) −H(i, i)u(i).
(6.53)
The ONU collects all error signals feedback into a vector:
ϵ = [ϵ(0), . . . , ϵ(L −1)]T = y −Du = (HF −D)u + w.
(6.54)

2.06.3 Downstream Transmission
315
This error signal vector can be used by the transmitter to adapt a precoder that attempts to minimize the
error signal energy.
However, because the error signal is measured by the receiver, it needs to be quantized and sent
back to the receiver. We assume hereafter that the error signal is ﬁrst normalized and then quantized.
Each receiver normalizes its error signal by dividing it with the direct channel gain, H(i, i). Thus, the
quantized error signal ˆϵn can be written as:
ˆϵ = D−1(y −Du) + z
= (D−1HF −I)u + D−1w + z,
(6.55)
and z is the quantization error. Note that z can be statistically dependent on ϵ.
Adaptive precoding for DSL was ﬁrst suggested by Louveaux and van der Veen [26]. They considered
an adaptive precoder designed to minimize the norm ∥ϵ∥2. Taking the derivative with respect to the
precoding matrix, using the instantaneous correlation matrix and taking some approximations, they
suggested using the update equation:
Fn+1 = Fn −αF−T
n
D

y∗
nuT
n

nd ,
(6.56)
where the subscript indicates the time (i.e., Fn, yn, and un denotes the value at time n of the precoding
matrix the received symbol and modulated data, respectively), α is the precoder update constant, and
[•]nd denotes the operation of zeroing all diagonal elements of a matrix. They also considered the use
of a quantized version of the received signal, but gave no details. This adaptive precoder was studied
only by simulations.
A simpler version of an adaptive precoder was proposed independently by Louveaux and van der
Veen [27] and by Bergel and Leshem [28]. Their suggested precoder update is given by6:
Fn+1 = Fn −αˆϵnuH
n .
(6.57)
This adaptive precoder has much lower implementation complexity than (6.56), as it does not include
multiplication by the inverse matrix. This precoder is also simpler in terms of analysis. In [28] Bergel and
Leshem considered the simpliﬁed case of rich enough quantization, such that the quantization error, z is
statistically independent on the error signal ϵ. For this simpliﬁed case they provided both convergence
bounds and a steady state error analysis. The convergence is guaranteed by the following theorem:
Theorem 5 [28]. A sufﬁcient condition for the precoder given by (6.57) to converge is that:
βD,max < 1 and α <
2
K p ·
1
1 + βD,max
,
(6.58)
where K = L −1 + E

|u(i)|4
/p2(i.e., E[uuHuuH] = K p2I). If (6.58) is satisﬁed, then after sufﬁ-
ciently long convergence time, the Frobenius norm of the difference between the zero forcing precoder
6The version by Louveaux and van der Veen only takes the non-diagonal elements of the update matrix. This version is not
described here as its analysis is more complicated.

316
CHAPTER 6 Signal Processing for Vectored Multichannel VDSL
(FZF = H−1D) and the adaptive precoder is upper bounded by:
lim
n→∞Tr

(Fn −FZF)(Fn −FZF)H
≤
αL L−1
i=0

σ 2
z +
σ 2
|H(i,i)|2

2 −αK p(1 + β2
D,max) −2|1 −αK p|βD,max
,
(6.59)
where σ 2
z is the variance of the quantization noise z.
As can be seen in Figure 6.4 the strong RWDD condition in the theorem (βD,max < 1) is satisﬁed
practically for all frequencies for link distances of up to 300 m. Thus, the precoder is very robust, and
can converge in all channels. As βD,max is typically not known in advance, a practical approach would
be to take its maximal value when choosing the update constant, and use α ≤1/K p. In such case,
(6.59) simpliﬁes to:
lim
n→∞Tr

(Fn −FZF)(Fn −FZF)H
≤
αL L−1
i=0

σ 2
z +
σ 2
|H(i,i)|2

2(1 −βD,max) −αK p(1 −βD,max)2 .
(6.60)
The convergence bound is important to guarantee the converge of the precoder. However, once the
precoder has converged to a steady state, (6.59) does not provide a convenient performance measure,
as it relates to the precoder error and not to the ﬁnal performance. In the same work they also provide
a more convenient steady state approximation. For large enough n (so that the precoder reaches steady
state), the covariance matrix of the error signal is approximated by:
E[ϵϵ H] ≃

1 +
αLp
2 −αK p

σ 2 · I +
αLp
2 −αK p σ 2
z DDH,
(6.61)
where σ 2
z = E

z(i)|2
is the variance of the quantization noise. The covariance matrix in (6.61) is
composed of two terms. The ﬁrst is the error increase due to the use of the iterative precoder (note that
the error signal covariance matrix with no FEXT is I). This error increase is negligible if αLp ≪1.
The second term is due to the quantization error, and does not depend on the noise power.
Nevertheless, the simplifying assumption of rich quantization [28] is impractical, because such a
quantization would cause a high feedback rate, and overload the upstream. Louveaux and van der Veen
[44] presented an approximate analysis for the case of phase feedback only, under the assumption that
the signal of each modem can be analyzed independently (which holds for very low βD,max). In a recent
work, Binyamini and Bergel [45] analyzed the same precoder with low rate quantization. In particular
they considered a low bit rate dithered [46] uniform quantization only of the phase of the error signal.
This work showed that the precoder will converge for any update constant, α, and for any quantization
level (even 1 bit per sample) as long as the channel is strongly RWDD and βD,max < 1.
Their quantization scheme uses a sequence of pseudo random phase variables, φn(i), which are
designed to behave as iid random variabled uniformly distributed over [0, 2π) (in the what follows we
assume that this is their actual distribution). This sequence is known in advance both at the transmitter
and at all receivers. The error signal of the ith user at time n, ϵn(i), is ﬁrst rotated by multiplying it with
e jφn(i), and then quantized to one of the values e j k2π
M , where k = 0, 1, . . . , M −1, and M is the number
of quantization values. At the transmitter, the actual quantization value is obtained by multiplying the

2.06.3 Downstream Transmission
317
received quantization level by e−j k2π
M . Thus, the quantized error signal can be written as:
ˆϵn(i) = e jθn(i) H−1(i, i) · ϵn(i)
$$H−1(i, i) · ϵn(i)
$$,
(6.62)
and θn(i) is the phase quantization error. Note that the dithering operation ensures that the phase
quantization error is an iid sequence, and each element is uniformly distributed over [−π/M, π/M).
In [45] the authors show that the dithering has a negligible effect on system performance, and is
required mostly for analysis purposes, due to the convenient distribution of the quantization error. The
convergence of a precoder that employs a dithered phase quantization scheme is guaranteed by:
Theorem 6 [45]. Considering an adaptive precoder of the form of (6.57) which uses dithered phase
quantization as described in (6.62). If βD,max < 1, the precoder converges, and after a sufﬁciently long
convergence time, the averaged in time expectation on the absolute error measured by the ith receiver
is upper bounded by:
lim
T →∞
1
T
T

n=1
E
|ϵn(i)|
≤αLp

1 + βD,max
2 |H(i, i)|
2

1 −βD,max

· M
π sin π
M
+
&
π
4 · σ

1 −βD,max
.
(6.63)
The theorem shows that the error signal is bounded by a noise increase of 1−βD,max plus an additional
term which is linear with the precoder update constant, α. Thus, it is feasible to approach FEXT free
performance by a choosing small enough precoder update, up to the noise increase term.
Naturally such low rate quantization results in lower performance than the rich quantization in
Theorem 5 (i.e., slower convergence and/or higher steady state errors). Nevertheless, unlike Theorem 5,
the phase quantization scheme in Theorem 6 achieves convergence for every value of the update constant.
Note however that the bound (6.63) is not very tight. The authors observed that a better approximation
of the actual error signal magnitude is obtained by substituting βD,max = 0 in (6.63) instead of the
actual value of βD,max.
Figure 6.9 shows the (averaged over all users) normalized error signal magnitude of two adaptive
precoders vs. the time (in symbols), over the subcarrier at a frequency of 5.78 MHz. The lower curve
shows the magnitude of the error signal, divided by σ, in the precoder of (6.57) with no quantization and
with α = 1/(2Lp) (about half the maximal allowed value). The doted curve with stars shows the steady
state approximation in (6.61) for the no quantization case (i.e., 10 log10 (1+
αLp
2−αK p)). The higher curve
depicts the magnitude of the error signal, divided by σ when the adaptive precoder employs the low rate
quantization of Theorem 6 with M = 2 (1-bit feedback) and α = 0.002/L√p (note that the measured
user gain at this frequency is 0.21). As can be seen, the precoder converges at about the same time as
the no quantization precoder, but with much higher error signal magnitude. The dashed line shows the
cumulative averaged in time error signal divided by σ : 20 log10

1
LT
T
n=1
L−1
i=0 |ϵn(i)| /σ

, and the
dotted line with triangles depicts the steady state bound of (6.63). The dotted line with circles shows
the steady state approximation (calculated by substituting βD,max = 0 in (6.63)). As can be seen, the
precoders converge reasonably fast, and the suggested approximations are quite good.
To further demonstrate the accuracy of the suggested steady state error magnitude approximations,
Figure 6.10 shows the average steady state error magnitude and compares it to the approximations

318
CHAPTER 6 Signal Processing for Vectored Multichannel VDSL
0
1000
2000
3000
4000
5000
6000
−5
0
5
10
15
20
25
30
35
time [Symbols]
Error signal magnitude [dB]
2−bit quantization
Cumulative average
2−bit upper bound
2−bit approximation
No−Quantization
No−Quantization approximation
FIGURE 6.9
Error signal magnitude vs. time for two adaptive precoders.
of (6.61) and (6.63) vs. the normalized precoder update constant. (Note that in order to match the
approximation expressions, the average is taken over the absolute value of the error signal magnitude
for the low rate precoder, while for the non quantized precoder the average is taken over the square
magnitude). The normalized precoder update constant is given by ˆα = αLp for the no quantization case,
and by ˆα = 100αL√p for the low rate quantization precoder. One can see that both approximations
are quite good. In particular, the low rate quantization precoder approximation holds even for very high
values of α. This demonstrates the claim of Theorem 6 that the precoder converges for every value of α.
Note however that very high values of α are not desirable, as they can cause even a FEXT increase
compared to the original no precoding scheme.
The situation is slightly more complicated in mixed length scenarios, where the different pairs in the
binder reach destinations at different distances. From (6.59) it can be seen that the precoder convergence
is dominated by the channel gain of the user with the longest (weakest) link. On the other hand, in many
cases, these weak users are noise limited and not FEXT limited, and hence FEXT cancellation is not use-
ful for them. For this reason, it was suggested in [28] not to implement FEXT cancellation for such users,
based on an SNR threshold test. (Note that the FEXT from these users to other users is still canceled.)
Such an approach was shown to signiﬁcantly shorten the convergence times in mixed length scenarios.
Binyamini et al. [29] observed that partial FEXT cancellation is also desirable to reduce implemen-
tation complexity. In this work the partial FEXT cancellation described above (in which some users do

2.06.3 Downstream Transmission
319
10−1
100
101
102
−5
0
5
10
15
20
25
30
35
Normalized precoder update constant: ˆα
Error signal magnitude [dB]
2−bit quantization
No−Quantization
2−bit approximation
No−Quantization approximation
FIGURE 6.10
Steady state error signal magnitude vs. normalized precoder update constant. The normalized precoder
update constant is given by ˆα = αLp for the no quantization case (marked by stars), and by ˆα = 100αL√p
for the low rate quantization precoder (marked by circles).
not employ FEXT cancellation at all) is termed partial FEXT cancellation of type I. They also deﬁne
a partial FEXT cancellation of type II, where (for some users) only the FEXT from a subgroup of the
users is canceled. This precoder takes advantage of the implementation complexity gain described by
Cendrillon et al. [25] and in Section 2.06.3.2.4.
They suggested a simple adaption of the precoder in (6.57), which does not update the precoder at
the non-canceled terms. The mathematical formulation (as well as the analysis) of this type of precoder
is more complicated, as its update equation cannot be described in a matrix form. Instead, the precoder
update for the jth column is given by:
F( j)
n+1 = F( j)
n
−αT
j  j ˆϵnuH
n ,
(6.64)
wherethematrix j describestheselectedusersforFEXTcancellationasdescribedinSection2.06.3.2.4.
Note that the set of L update Eq. (6.64), j = 1, . . . , L, are actually coupled, because the error signal
at the n + 1th symbol depends on all the columns of the precoding matrix that were updated in the nth
symbol.
Although the analysis is more complicated, Binyamini et al. [29] showed that it complies with the
same sufﬁcient convergence condition as in the full update precoder (Theorem 5). More speciﬁcally:

320
CHAPTER 6 Signal Processing for Vectored Multichannel VDSL
Theorem 7 [29]. Assuming that the quantization noise is statistically independent of the error signal,
a sufﬁcient condition for the partial precoder given by (6.64) to converge is that:
βD,max < 1 and α <
2
K p ·
1
1 + βD,max
.
(6.65)
If (6.65) is satisﬁed, then after sufﬁciently long convergence time, the Frobenius norm of the difference
between the precoder Fn and the non-adaptive partial precoder FP that satisﬁes (6.48) and (6.49) is
upper bounded by:
lim
n→∞Tr

(Fn −FP)(Fn −FP)H
≤
α L−1
j=0

i∈G j

σ 2
z + σ 2+Z(i,i)
|H(i,i)|2

2 −αK p(1 + β2
D,max) −2|1 −αK p|βD,max
,
(6.66)
where σ 2
z is the variance of the quantization noise z and Z(i, i) is the residual FEXT of the non-adaptive
partial FEXT precoder, i.e., the ith element on the diagonal of the covariance residual FEXT covariance
matrix, Z given in (6.52).
In the same work, they also provide a steady state approximation which is demonstrated to be quite
accurate. This approximation is given by:
lim
n→∞
L−1

j=0
E[|ϵn( j)|2] ≈

α p
2 −αK p
rT
L + 1
 L−1

j=0

σ 2 + Z( j, j)

+
α pσ 2
z
2 −αK p
rT
L
L−1

j=0
|H(i, i)|2,
(6.67)
where rT = 
j r j is the total number of elements used in the partial adaptive precoder. Note that
the sum over

1 + Z( j, j)

is the power of the noise plus residual FEXT in the non-adaptive partial
precoder of Section 2.06.3.2.4. Thus, the term
α p
2 −αK p
rT
L represents the increase in the error signal
power due to the adaptive precoding. The second term in the right hand side of (6.67) represents the
effect of the error signal quantization noise, σ 2
z .
The performance of the partial adaptive precoder is depicted in Figure 6.11, with a comparison to
the non adaptive partial precoder described in Section 2.06.3.2.4. The ﬁgure depicts the average user
rates (when all the bandwidth is allocated to the downstream) using partial precoding as a function of
time, for various complexity levels. The case of rT = 282 = 784 corresponds to full FEXT cancellation
(i.e., in this case all the precoding matrix is updated). The performance in this case are identical to
the performance described above. In the two other cases rT < 784 represents the number of non-zero
elements in the precoding matrix, averaged over all sub-carriers. It is clear that the adaptive partial
precoder converges quite fast, and achieves rates close to those of the non-adaptive precoder. Note also
that the difference between the adaptive and non-adaptive precoders is smaller for smaller values of rT.
This behavior is consistent with the approximation in (6.67), which shows that the additional FEXT
due to the adaptive precoding is linear with rT.
It is worth noting that the selection of the important terms for FEXT cancellation has not been studied
so far in the context of adaptive precoding. This is an open issue because adaptive precoding systems do

2.06.3 Downstream Transmission
321
0
50
100
150
200
250
300
350
400
450
150
200
250
300
350
400
450
time [Symbols]
Rate [Mbps]
rT =784, Non-adaptive
rT =784, adaptive
rT =392, Non-adaptive
rT =392, adaptive
rT =196, Non-adaptive
rT =196, adaptive
FIGURE 6.11
Average achievable user rate over the whole bandwidth at a 300 m 28 user binder, using a adaptive and
non-adaptive partial precoders.
not employ channel estimation, and only use the error signal feedback to adapt the precoder. Thus, such
systems are required to select the important FEXT terms based on this error signal feedback. This can
be done for example by testing long term correlations between the error signals and the transmitted
symbols. Alternatively, one can try to use the precoder adaption as a learning mechanism, adapt the
precoder for some test elements and then use the resulting precoder to decide on the signiﬁcance of
each element. Further research is required to deﬁne such methods and characterize their performance.
An alternative to the adaptive precoding scheme using error signal feedback is adaptive precoding
using SNR measurement feedback, as presented by Whiting et al. [47]. The major advantage of this
approach is that it requires only SNR feedback reports, which are inherent to all VDSL modems. Thus,
adaptive FEXT cancellation can be applied without any change in the CPE. But, SNR reports have no
phase information, and hence a more complex algorithm is required to learn the correct direction for
precoder adaptation. The updated algorithm is composed of several stages in which the various lines
are perturbed in various directions. Then the received SNR reports are compiled into an adaption of
the precoder, and the process starts over again. Whiting et al. [47] provided convergence bounds and
analytic expressions for the convergence time and expected performance. Comparing to the adaptive
precoding using error signal described above, one should keep in mind that SNR feedback adaptive

322
CHAPTER 6 Signal Processing for Vectored Multichannel VDSL
precoding does not require any change in the CPE. On the other hand, its main disadvantage is its
convergence time, which is several orders of magnitude slower (hundreds of symbols, i.e., less than a
second using error signal feedback compared to minutes and even hours using SNR feedback).
2.06.4 Upstream transmission
2.06.4.1 Linear receiver
In the upstream, the receiving modems are colocated at the ONU. This allows for joint reception of
the signals transmitted on the different twisted pairs. As was the case for the downstream, upstream
performance has also been shown to be nearly optimized with a ZF receiver [48]. Using
ˆy = H−1y = x + H−1w,
(6.68)
and recalling that the upstream channel matrix is CWDD, Cendrillon et al. [48] presented bounds that
guarantee that ZF precoder performance is very close to the maximal achievable performance. Their
upper bound is given by:
Theorem 8 [48]. The data rate achievable by user i in any speciﬁc subcarrier of the upstream of DSL
systems is upper bounded by:
C ≤
F · log2

1 + −1ησ −2|H(i, i)|2 
1 + (L −1)β2
U,1

.
(6.69)
For the lower bound, we give here the bound from [40], which is slightly better than the original
bound in [48]:
Theorem 9 [40]. The data rate achievable by user i in any speciﬁc subcarrier of the upstream of DSL
systems when the ONU applies a ZF receiver is lower bounded by:
R ≥
F · log2

1 + −1η|H(i, i)|2 
1 −2βU,max −β2
U,max

.
(6.70)
In some cases, the system is subject to interference from alien sources. This interference can be highly
correlated between the different twisted pairs in the binder. Unlike the downstream, in the upstream
the receiver can take advantage of this correlation and reduce the effect of alien interference. The ZF
receiver does not take advantage of this correlation, and hence can suffer a dramatic decrease in capacity,
as seen for example in Figure 6.12. To better visualize why the ZF receiver can be far from optimal in
this case, one can consider a noise whitening approach:
˜y = −1/2y = ˜Hx + ˜w,
(6.71)
where  is the covariance matrix of w, which includes both noise and interference. The resulting channel
model is quite similar to the initial model in that the resulting noise is white (E[ ˜w ˜wH] = I). However,
Chen et al. [49,50] observed that in some cases, the resulting effective channel matrix, ˜H, is no longer
diagonal dominant. Thus, Theorem 9 does not help, and ZF performance can be far from optimal.7
7Note that in most cases, vectored VDSL systems coordinate all pairs in the binder. In such cases, the alien noise is usually
negligible.

2.06.4 Upstream Transmission
323
0
100
200
300
400
500
600
0
100
200
300
400
500
600
700
System capacity vs. distance
Binder length [meter]
User rate [Mbps]
No alien noise
MMSE−GDFE
ZF−GDFE
MMSE
ZF
FIGURE 6.12
Average achievable user rate over the whole bandwidth in the upstream vs. binder length, for various receiver
structures.
Pandey et al. [43] suggested that a MMSE linear receiver can gain from the alien noise correlation.
They showed that for an 1200 m link in the presence of strong alien noise an MMSE receiver can
achieve rates 5 times better than the rates achievable by ZF, and more than half of the actual capacity.
However, for shorter link lengths, the signal power becomes more signiﬁcant. Hence the MMSE receiver
focuses on FEXT cancellation, and its performance is very close to the performance of the ZF receiver
(see Figure 6.12).
2.06.4.2 Decision feedback equalizer
For cases in which the linear processing discussed above is too far from optimal, Chen et al. [50]
proposed using a ZF generalized decision feedback equalizer (GDFE). The authors demonstrate that
the ZF-GDFE is a simpliﬁed version of the MMSE-GDFE, which was shown to achieve optimal capacity
in the Gaussian multiple access channel [51]. In the following we do not describe the MMSE-GDFE, as
this general technique was developed mostly for wireless channels and has no particular characteristics
in DSL systems.

324
CHAPTER 6 Signal Processing for Vectored Multichannel VDSL
In the ZF-GDFE scheme, the receiver applies a QR decomposition of the channel ˜H of (6.71):
˜H = QR,
(6.72)
where Q is a unitary matrix and R is an upper triangular matrix. Rotating the input by:
QH ˜y = QH−1/2y = Rx + QH ˜w
(6.73)
results in a simpler structure, which is convenient for GDFE. Due to the upper triangular structure of
R, the last user in the model of (6.73) receives the transmitted signal with no interference. This user
is decoded ﬁrst.8 Then, the effect of the decoded user is subtracted from the received signal, and the
second user can be decoded with no interference. This scheme continues, until the effect of users 1
through L −1 is subtracted, and user number 0 is decoded with no interference.
Note that in this description user number 0 has the highest priority, as the effect of all users is sub-
tracted before its decoding. In order to optimize system performance, user priorities must be controlled.
This is done by reordering the users before the detection. In addition, one can control the power allo-
cation between the different users. Such an optimization is described in [50] (see also [52] for such an
optimization for the MMSE-GDFE receiver).
On the other hand Leshem and Zehavi [53] noted that in DSL systems, the spectral mask power
constraint is more dominant. Thus, the optimization with respect to the transmission powers is much
simpler than in the problem considered by [50]. When the spectral mask power constraint is dominant,
the optimal power allocation simply uses the maximal allowed power for each user at each subcarrier.
As for the user priorities and ordering, it turns out that in most cases there exists a trivial ordering
that results in near optimal performance. For example, in the simulation of Figure 6.12, the ZF-GDFE
receiver does not optimize user priorities, and selects user ordering in a random manner. The ﬁgure
depicts the performance of several receiver types over various link lengths. The simulation includes 28
users and alien noise which is 30 dB stronger than the white noise. Without the alien noise, all receivers
achieve nearly the same performance which is very close to channel capacity. In the presence of alien
noise, the ZF receiver performs very poorly. The MMSE receiver performs somewhat better, but this
advantage only holds for the longer link distances. As explained above, for short links the performance
of the MMSE receiver is nearly identical to the performance of the ZF receiver. On the other hand, the
ZF-GDFE receiver performs quite well, and can achieve 90% of the channel capacity. Note that the
channel capacity (achievable using the MMSE-GDFE receiver) is only slightly affected by the presence
of the alien noise.
It should be noted that complete FEXT cancellation may not always be feasible in near future
practical systems. One factor is the complexity of MMSE-GDFE receivers that may prevent complete
FEXT cancellation in the presence of alien noise. Another factor is the large amount of deployed
CPEs that do not support vectoring. Thus, in the coming years we expect to see many systems that are
partially vectored and partially non-vectored. In such cases it is important to combine FEXT cancellation
techniques with dynamic spectrum management (DSM) techniques (see for example [54,55]).
8Decoding can mean the decoding of the complete code word for this user. But due to complexity constraints, a more typical
approach just takes hard decisions on the symbol value.

References
325
2.06.5 Conclusion
This chapter discussed the properties of the DSL multi-access and broadcast channels. It provided the
basic system and channel models and presented the main solutions for both upstream and downstream.
It is clear that a massive deployment of G.993.5 will take place in the near future. These systems perform
multi-user MIMO-DMT transmission and reception using an order of 4000 tones and providing rates
up to 100 Mbps. This massive vectoring is extremely important for reducing the need for ﬁber to the
home deployment, and will enable aggregate rates larger than 5 Gbps for 64 users over distances of up to
800 m. Vectored DSL systems provide an excellent illustration of the fact that ﬁtting signal processing
and communication techniques to the speciﬁc properties of the channel at hand results in excellent
performance at moderate computational cost.
Relevant Theory: Signal Processing Theory
See Vol. 1, Chapter 9 Discrete Multi-Scale Transforms in Signal Processing
References
[1] J. Lechleider, Coordinated transmission for two-pair digital subscriber lines, IEEE J. Sel. Areas Commun.
9 (6) (1991) 920–930.
[2] Symmetric Digital Subscriber Line (ADSL) Transceivers, ITU-T Recommendation G.992.1, SERIES G:
Transmission Systems and Media, Digital Systems and Networks, 1999.
[3] ITU-T Recommendation G.993.1-2004: Very High Speed Digital Subscriber Line. SERIES G: Transmission
Systems and Media, Digital Systems and Networks, October 2004.
[4] T. Starr, J.M. Ciofﬁ, P. Silverman, Understanding Digital Subscribe Line Technology, Prence-Hall, Upper
Saddle River, NJ, 1999.
[5] J.A.C. Bingham, ADSL, VDSL, and Multicarrier Modulation, John Wiley & Sons, Inc., 2000.
[6] G. Foschini, Crosstalk in outside plant cable systems, Bell Syst. Tech. J. 50 (7) (1971) 2421–2450.
[7] R. Addie, A. Gibbs, The covariance of near end crosstalk and its application to pcm system engineering in
multipair cable, IEEE Trans. Commun. 27 (2) (1979) 469–477.
[8] S. Lin, Statistical behaviour of multipair crosstalk, Bell Syst. Tech. J. 59 (6) (1980) 955–974.
[9] S. Lin, Statistical behaviour of multipair crosstalk with dominant components, Bell Syst. Tech.
J. 59 (6) (1980).
[10] J. Werner, The HDSL environment, IEEE J. Sel. Areas Commun. 9 (6) (1991) 785–800.
[11] K. Kerpez, Near-end crosstalk is almost gaussian, IEEE Trans. Commun. 41 (5) (1993) 670–672.
[12] K. Kerpez, Models for the number of next disturbers and next loss, Tech. Rep., 1999, t1E1.4/99-471 (Online).
Available: <ftp://ftp.t1.org/pub/t1e1/e1.4/DIR99/9e144710.pdf>.
[13] I. Kalet, S. Shamai (Shitz), On the capacity of a twisted pair: Gaussian model, IEEE Trans. Commun. 38(3)
(1990) 379–383.
[14] J. Aslanis, J. Ciofﬁ, Achievable information rates on digital subscriber loops: limiting information rates with
crosstalk, IEEE Trans. Commun. 40 (2) (1992) 361–372.
[15] E. Karipidis, N. Sidiropoulos, A. Leshem, Y. Li, Experimental evaluation of capacity statistics for short VDSL
loops, IEEE Trans. Commun. 53 (7) (2005) 1119–1122.
[16] E. Karipidis, N. Sidiropoulos, A. Leshem, Y. Li, R. Taraﬁ, M. Ouzzif, Crosstalk models for short VDSL2
lines from measured 30 MHz data, EURASIP J. Appl. Signal Process. 2006 (1) (2006) 90–90.

326
CHAPTER 6 Signal Processing for Vectored Multichannel VDSL
[17] J. Lechleider, Coordinated transmission for two-pair digital subscriber lines, IEEE J. Sel. Areas Commun.
9 (6) (1991) 920–930.
[18] G. Ginis, J. Ciofﬁ, Vectored transmission for digital subscriber line systems, IEEE J. Sel. Areas Commun.
20 (5) (2002) 1085–1104.
[19] R. Cendrillon, M. Moonen, J. Verlinden, T. Bostoen, G. Ginis, Improved linear crosstalk precompensation
for DSL, in: IEEE International Conference on Acoustics, Speech and Signal Processing, Montreal, Canada,
May, 2004, p. 4.
[20] R. Cendrillon, M. Moonen, T. Bostoen, G. Ginis, The linear zero-forcing crosstalk canceller is near-optimal
in DSL channels, in: IEEE Global Communications Conference, TX, Dallas, 2004, p. 5.
[21] A. Leshem, Y. Li, A low complexity coordinated fext cancellation for VDSL, in: Proceedings of IEEE ICECS
2004, December 2004, pp. 338–341.
[22] A. Leshem, Y. Li, A low complexity linear precoding technique for next generation VDSL downstream
transmission over copper, IEEE Trans. Signal Process. 55 (11) (2007) 5527–5534.
[23] Y. Li, A. Leshem, A lower bound on the performance of simpliﬁed linear precoding for vectored DSL, Int.
J. Pure Appl. Math. 43 (1) (2008).
[24] R. Cendrillon, M. Moonen, G. Ginis, K. Van Acker, T. Bostoen, P. Vandaele, Partial crosstalk cancellation for
upstream VDSL, EURASIP J. Appl. Signal Process. 2004 (2004) 1520–1535.
[25] R. Cendrillon, G. Ginis, M. Moonen, K. Van Acker, Partial crosstalk precompensation in downstream VDSL,
Signal Process. 84 (11) (2004) 2005–2019.
[26] J. Louveaux, A. van der Veen, Adaptive DSL crosstalk precancellation design using low-rate feedback from
end users, IEEE Signal Process. Lett. 13 (11) (2006) 665–668.
[27] J. Louveaux, A.-J. van der Veen, Adaptive Precoding for Downstream Crosstalk Precancelation in DSL
Systems Using Sign-Error Feedback, IEEE Trans. Signal Process. 58 (6) (2010) 3173–3179.
[28] I. Bergel, A. Leshem, Convergence Analysis of Downstream VDSL Adaptive Multichannel Partial FEXT
Cancellation, IEEE Trans. Commun. 58 (10) (2010) 3021–3027.
[29] I. Binyamini, I. Bergel, A. Leshem, Arbitrary partial FEXT cancellation in adaptive precoding for multichannel
downstream VDSL, IEEE Trans. Signal Process 60 (11) (2012) 5754–5763.
[30] ITU-T Recommendation G.993.5-2010, Self-FEXT Cancellation (Vectoring), 2010.
[31] F. Sjöberg, M. Isaksson, R. Nilsson, P. Ödling, S. Wilson, P. Börjesson, Zipper: a duplex method for VDSL
based on DMT, IEEE Trans. Commun. 47 (8) (1999) 1245–1252.
[32] D.Mestdagh,M.Isaksson,P.Ödling,ZipperVDSL:asolutionforrobustduplexcommunicationovertelephone
lines, IEEE Commun. Mag. 38 (5) (2000) 90–96.
[33] M. Tomlinson, New automatic equaliser employing modulo arithmetic, Electron. Lett. 7 (5) (1971) 138–139.
[34] H. Harashima, H. Miyakawa, Matched-transmission technique for channels with intersymbol interference,
IEEE Trans. Commun. 20 (4) (1972) 774–780.
[35] G. Caire, S. Shamai, On achievable rates in a multi-antenna broadcast downlink, in: Proc. 38th Annu. Allerton
Conf. Communication, Control and Computing, 2000, pp. 1188–1193.
[36] G. Caire, S. Shamai, On the achievable throughput of a multiantenna gaussian broadcast channel, IEEE Trans.
Inform. Theory 49 (7) (2003) 1691–1706.
[37] W. Yu, J. Ciofﬁ, Trellis precoding for the broadcast channel, in: IEEE Global Telecommunications Conference,
2001, GLOBECOM’01, vol. 2, 2001, pp. 1344–1348.
[38] R. Cendrillon, G. Ginis, E. Van den Bogaert, M. Moonen, A near-optimal linear crosstalk precoder for
downstream VDSL, IEEE Trans. Commun. 55 (5) (2007) 860–863.
[39] J. Ciofﬁ, G. Dudevoir, M. Eyuboglu, G. Forney Jr., MMSE decision-feedback equalizers and coding. II. Coding
results, IEEE Trans. Commun. 43 (10) (1995) 2595–2604.
[40] I. Bergel, A. Leshem, The performance of zero forcing DSL systems, IEEE Signal Process. Lett. 20 (5) (2013)
527–530.

References
327
[41] E. Sayag, A. Leshem, N.D. Sidiropouios, Finite word length effects on transmission rate in
zero forcing linear precoding for multichannel DSL, IEEE Trans. Signal Process. 57 (4) (2009) 1469–1482.
[42] J. Vangorp, P. Tsiaﬂakis, M. Moonen, J. Verlinden, G. Ysebaert, Dual decomposition approach to partial
crosstalk cancelation in a multiuser DMT-xDSL environment, EURASIP J. Adv. Signal Process. 2007 (2007)
1–11.
[43] P. Pandey, M. Moonen, L. Deneire, MMSE-based partial crosstalk cancellation for upstream VDSL, in: IEEE
International Conference on Communications (ICC), 2010.
[44] J. Louveaux, A. van der Veen, Adaptive precoding for downstream crosstalk precancelation in DSL systems
using sign-error feedback, IEEE Trans. Signal Process. 58 (6) (2010) 3173–3179.
[45] Binyamini, I. Bergel, Adaptive precoder using sign error feedback for FEXT cancellation in multichannel
downstream VDSL, IEEE Trans. Signal Process. 61 (9) (2013) 2383–2393.
[46] M. Gray, T.G. Stockham, Dithered quantizers, IEEE Trans. Inform. Theory 39 (3) 1993.
[47] P. Whiting, G. Kramer, C. Nuzman, A. Ashikhmin, A. van Wijngaarden, M. Živkovi´c, Analysis of inverse
crosstalk channel estimation using SNR feedback, IEEE Trans. Signal Process. 59 (2011) 1102–1115.
[48] R. Cendrillon, G. Ginis, E. Van den Bogaert, M. Moonen, A near-optimal linear crosstalk canceler for upstream
VDSL, IEEE Trans. Signal Process. 54 (8) (2006) 3136–3146.
[49] C. Chen, K. Seong, R. Zhang, J. Ciofﬁ, Optimized transmission for upstream vectored DSL systems using
zero-forcing generalized decision-feedback equalizers, in: Proc. IEEE Globecom, 2006.
[50] C. Chen, K. Seong, R. Zhang, J. Ciofﬁ, Optimized resource allocation for upstream vectored DSL systems
with zero-forcing generalized decision feedback equalizer, IEEE J. Sel. Top. Signal Process. 1 (4) (2007)
686–699.
[51] M. Varanasi, T. Guess, Optimum decision feedback multiuser equalization with successive decoding achieves
the total capacity of the gaussian multiple-access channel, in: Conference Record of the 31st Asilomar Con-
ference on Signals, Systems and Computers, vol. 2, 1997, pp. 1405–1409.
[52] P. Tsiaﬂakis, J. Vangorp, J. Verlinden, M. Moonen, Multiple access channel optimal spectrum balancing for
upstream DSL transmission, IEEE Commun. Lett. 11 (4) (2007) 398–300.
[53] A. Leshem, E. Zehavi, Rate control for PSD limited multiple access systems through linear programming, in:
IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2011, pp. 3220–3223.
[54] V. Chan, W. Yu, Joint multiuser detection and optimal spectrum balancing for digital subscriber lines,
EURASIP J. Appl. Signal Process. 2006 (2006) 1–13.
[55] A. Chowdhery, J. Ciofﬁ, Dynamic spectrum management for upstream mixtures of vectored and non-vectored
DSL, in: IEEE Global, Telecommunications Conference (GLOBECOM).

7
CHAPTER
Distributed Detection and
Estimation in Wireless
Sensor Networks∗
Sergio Barbarossa, Stefania Sardellitti, and Paolo Di Lorenzo
Department of Information Engineering, Electronics and Telecommunications, Sapienza University of Rome, Via
Eudossiana 18, 00184 Rome, Italy
2.07.1 Introduction
Wireless sensor networks (WSN) are receiving a lot of attention from both the theoretical and application
sides, in view of the many applications spanning from environmental monitoring, as a tool to control
physical parameters such as temperature, vibration, pressure, or pollutant concentration, to the moni-
toring of civil infrastructures, such as roads, bridges, buildings, etc. [1]. Some new areas of applications
are emerging rapidly and have great potentials. A ﬁeld that is gaining more and more interest is the use
of WSNs as a support for smart grids. In such a case, a WSN is useful to: (i) monitor and predict energy
production from renewable sources of energy such as wind or solar energy; (ii) monitor energy con-
sumption; (iii) detect anomalies in the network. A further area of increasing interest is vehicular sensor
networks. In such a case, the vehicles are nodes of an ad hoc network. The sensors onboard the vehicle
can measure speed and position of the vehicle and forward this information to nearby vehicles or to the
road side units (RSU). This information enables the construction of dynamic spatial trafﬁc maps, which
can be exploited to reroute trafﬁc in case of accidents or to minimize energy consumption. A relatively
recent and interesting application of WSNs is cognitive radio (CR). In such a case, opportunistic (or
secondary) users are allowed to access temporally unoccupied spectrum holes, under the constraint of
not interfering with licensed (primary) users, and to release the channels as soon as they are requested
by licensed users. The basic step enabling this dynamic access is sensing. The problem is that if sensing
is carried out at a single location, it might be severely degraded by shadowing phenomena: If the sensor
is in shadowed area, it might miss the presence of a primary user and then transmit by mistake over
occupied slots, thus generating an undue interference. To overcome shadowing, it is useful to resort to a
WSN whose nodes sense the channels and exchange information with each other in order to mitigate the
effect of local shadowing phenomena. The goal of the WSN in such an application is to build a spatial
map of channel occupancy. An opportunistic user willing to access radio resources within a conﬁned
region could then interrogate the closest sensor of a WSN and get a reliable information about which
channels are temporarily availableand when this utilization has to be stopped. The plethora of applica-
tions raises a series of challenging technical issues, which may be seen as sources of opportunities for
engineers. Probably the ﬁrst most important question concerns energy supply. In many applications, in
∗This work has been partially supported by the European project TROPIC, nr. ICT-318784.
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-396500-4.00007-7
© 2014 Published by Elsevier Ltd. All rights reserved.
329

330
CHAPTER 7 Distributed Detection and Estimation
fact, the sensors are battery-operated and it may be difﬁcult or costly to recharge the batteries or to sub-
stitute them. As a consequence, energy consumption is a basic constraint that should be properly taken
into account. A second major concern is reliability of the whole system. In many cases, to allow for an
economy of scale, the single sensors are devices with limited accuracy and computational capabilities.
Nevertheless, the decision taken by the network as a whole must be very reliable, because it might affect
crucial issues like security, safety, etc. The question is then how to build a reliable system out of the
combination of many potentially unreliable nodes. Nature exhibits many examples of such systems.
Human beings are capable of solving very sophisticated tasks and yet they are essentially built around
basic unreliable chemical reactions occurring within cells whose lifetime is typically much smaller than
the lifetime of a human being. Clearly, engineering is still far away from approaching the skills of living
systems, but important inspirations can be gained by observing biological systems. Two particular fea-
tures possessed by biological systems are self-organization and self-healing capabilities. Introducing
these capabilities within a sensor network is the way to tackle the problem of building a reliable system
out of the cooperation of many potentially unreliable units. In particular, self-organization is a key tool
to enable the network to reconﬁgure itself, in terms of acquisition and transfer of information from the
sensing nodes to the control centers, responsible for taking decisions, launching alarms or activating
actuators aimed to counteract adverse phenomena. The network architecture plays a fundamental role
in terms of reliability of the whole system. In conventional WSNs, there is typically one or a few sink
nodes that collect the observations taken by the sensor nodes and process them, in a centralized fashion,
to produce the desired decision about the observed phenomenon. This architecture arises a number of
critical issues, such as: (a) potential congestion around the sink nodes; (b) vulnerability of the whole
network to attacks or failure of sink nodes; (c) efﬁciency of the communication links established to
send data from the sensor nodes to the sink. For all these reasons, a desirable characteristic of a WSN
is to be designed in such a way that decisions are taken in a decentralized manner. Ideally, every node
should be able, in principle, to achieve the ﬁnal decision, thanks to the exchange of information with
the other nodes, either directly or through multiple hops. In this way, vulnerability would be strongly
reduced and the system would satisfy a scalability property. In practice, it is not necessary to make every
single node to be able to take decisions as reliably as in a centralized system. But what is important to
emphasize is that proper interaction among the nodes may help to improve reliability of single nodes,
reduce vulnerability and congestion events, and make a better usage of radio resource capabilities. This
last issue points indeed to one of the distinctive features of decentralized decision systems, namely
the fact that sensing and communicating are strictly intertwined with each other and a proper system
design must consider them jointly. The ﬁrst important constraint inducing a strict link between sensing
and communicating is that the transmission of the measurements collected by the nodes to the decision
points occurs over realistic channels, utilizing standard communication protocols. For example, adopt-
ing common digital communication systems, the data gathered by the sensors need to be quantized and
encoded before transmission. In principle, the number of bits used in each sensor should depend on the
accuracy of the data acquisition on that sensor. At the same time, the number of bits transmitted per each
channel use is upper bounded by the channel capacity, which depends on the transmit power and on the
channel between sensor and sink node. This suggests that the number of bits to be used in each node
for data quantization should be made dependent on both sensor accuracy and transmission channel. A
further important consequence of the network architecture and of the resulting ﬂow of information from
peripheral sensing nodes to central decision nodes is the latency with which a global decision can be

2.07.1 Introduction
331
taken. In a centralized decision system, the ﬂow of information proceeds from the sensing nodes to the
central control nodes, usually through multiple hops. The control node collects all the data, it carries out
the computations, and takes a decision. Conversely, in a decentralized decision system, there is typically
an iterated exchange of data among the nodes. This determines an increase of the time necessary to
reach a decision. Furthermore, an iterated exchange of data implies an iterated energy consumption.
Since in WSNs energy consumption is a fundamental concern, all the means to minimize the overall
energy consumption necessary to reach a decision within a maximum latency are welcome. At a very
fundamental level, we will see how an efﬁcient design of the network requires a global cross layer
design where the physical and the routing layers take explicitly into account the speciﬁc application for
which the network has been built.
This chapter is organized as follows. In Section 2.07.2, we provide a general framework aimed to
show how an efﬁcient design of a sensor network requires a joint organization of in-network processing
and communication. We show how the organization of the ﬂow of information from the sensing nodes
to the decision centers should depend not only on the WSN topology, but also on the statistical model
of the observation. Finally, we brieﬂy recall some fundamental information theoretical issues showing
how in a multi-terminal decision network source and channel coding are strictly related to each other.
In Section 2.07.3, we introduce the graph model as the formal tool to describe the interaction among the
nodes. Then, we illustrate the so called consensus algorithm as a basic tool to reach globally optimal
decisions through a decentralized approach. Since the interaction among the nodes occurs through a
wireless channel, we also consider the impact of realistic channel models on consensus algorithm and
show how consensus algorithms can be made robust against channel impairments. In Section 2.07.4,
we address the distributed estimation problem. We show ﬁrst an entirely decentralized approach, where
observations and estimations are performed without the intervention of a fusion center. In such a case,
we show how to achieve a globally optimal estimation through the local exchange of information among
nearby nodes. Then, we consider the case where the estimation is performed at a decision center. In such
a case, we show how to allocate quantization bits and transmit powers in the links between the sensing
nodes and the fusion center, in order to accommodate the requirement on the maximum estimation
variance, under a constraint on the global transmit power. In Section 2.07.5, we extend the approach
to the detection problem. Also in this case, we consider the entirely distributed approach, where every
node is enabled to achieve a globally optimal decision, and the case where the decision is taken at a
central control node. In such a case, we show how to allocate coding bits and transmit power in order
to maximize the detection probability, under constraints on the false alarm rate and the global transmit
power. Then, in Section 2.07.6, we generalize consensus algorithms illustrating a distributed procedure
that does not force all the nodes to reach a common value, as in consensus algorithms, but rather to
converge to the projection of the overall observation vector onto a signal subspace. This algorithm is
especially useful, for example, when it is required to smooth out the effect of noise, but without destroy-
ing valuable information present in the spatial variation of the useful signal. In wireless sensor networks,
a special concern is energy consumption. We address this issue in Section 2.07.7, where we show how to
optimize the network topology in order to minimize the energy necessary to achieve a global consensus.
We show how to convert this, in principle, combinatorial problem, into a convex problem with minimal
performance losses. Finally, in Section 2.07.8, we address the problem of matching the topology of the
observation network to the graph describing the statistical dependencies among the observed variables.
Finally, in Section 2.07.9, we draw some conclusions and we try to highlight some open problems and
possible future developments.

332
CHAPTER 7 Distributed Detection and Estimation
2.07.2 General framework
The distinguishing feature of a decentralized detection or estimation system is that the measurements are
gathered by a multiplicity of sensors dispersed over space, while the decision about what is being sensed
is taken at one or a few fusion centers or sink nodes. The information gathered by the sensors has then to
propagate from the peripheral nodes to the central control nodes. The challenge coming from this set-up
is that in a WSN, information propagates through wireless channels, which are inherently broadcast,
affected by fading and prone to interference. Installing a WSN requires then to set up a proper medium
access control protocol (MAC) able to handle the communications among the nodes, in order to avoid
interference and to ensure that the information reaches the ﬁnal destination in a reliable manner. But
what is decidedly speciﬁc of a WSN is that the sensing and communication aspects are strictly related
to each other. In designing the MAC of a WSN, there are some fundamental aspects that distinguish a
WSN from a typical telecommunication (TLC) network. The main difference stems from the analysis of
goal and constraints of these two kinds of networks. A TLC network must make sure that every source
packet reaches the ﬁnal destination, perhaps through retransmission in case of errors or packet drop,
irrespective of the packet content. In a WSN, what is really important is that the decision about what is
being sensed be taken in the most reliable way, without necessarily implying the successful delivery of
all source packets. Moreover, one of the major constraints in WSNs is energy consumption, because the
nodes are typically battery operated and recharging the batteries is sometimes troublesome, especially
when the nodes are installed in hard to reach places. Conversely, in a TLC network, energy provision
is of course important, but it is not the central issue. At the same time, the trend in TLC networks is to
support higher and higher data rates to accommodate for ever more demanding applications, while the
data rates typically required in most WSNs are not so high. These considerations suggest that an efﬁcient
design of a WSN should take into account the application layer directly. This means, for example, that
it is not really necessary that every packet sent by a sensor node reaches the ﬁnal destination. What is
important is only that the correct decision is taken in a reliable manner, possibly with low latency and
low energy consumption. This enables data aggregation or in-network processing to avoid unnecessary
data transmissions. It is then important to formulate this change of perspective in a formal way to
envisage ad hoc information transmission and processing techniques.
2.07.2.1 Computing while communicating
In a very general setting, taking a decision based on the data collected by the sensors can be interpreted
as computing a function of these data. Let us denote by xi, with i = 1, . . . , N, the measurements
collected by the ith node of the network, and by f (x) = f (x1, . . . , xN) the function to be computed.
The straightforward approach for computing this function consists in sending all the measurements xi to
a fusion center through a proper communication network and then implement the computation of f (x)
at the fusion center. However, if f (x) possesses a structure, it may be possible to take advantage of such
a structure to better organize the ﬂow of data from the sensing nodes to the fusion center. The idea of
mingling computations and communications to make an efﬁcient use of the radio resources, depending
on the properties that the function f (x) might possess, was proposed in [2]. Here, we will ﬁrst recall
the main results of [2]. Then, we will show how the interplay between computation and communication
will be further affected by the structure of the probabilistic model underlying the observations.

2.07.2 General Framework
333
To exploit the structure of the function f (x1, . . . , xN) to be computed, it is necessary to deﬁne some
relevant structural properties. One important property is divisibility. Let C be a subset of {1, 2, . . . , N}
and let π := {C1, . . . , Cs} be a partition of C. We denote by xCi the vector composed by the set of
measurements collected by the nodes whose indices belong to Ci. A function f (x1, . . . , xN) is said to
be divisible if, for any C ⊂{1, 2, . . . , N} and any partition π, there exists a function g(π) such that
f (xC) = g(π) 
f (xC1), f (xC2), . . . , f (xCs)

.
(7.1)
In words, (7.1) represents a sort of “divide and conquer” property: A function f (x) is divisible if it is
possible to split its computation into partial computations over subsets of data and then recombine the
partial results to yield the desired outcome.
Let us suppose now that the N sensing nodes are randomly distributed over a circle of radius R. We
assume a simple propagation model, such that two nodes are able to send information to each other in
a reliable way if their distance is less than a coverage radius r0(N). At the same time, the interference
between two links is considered negligible if the interfering transmitter is at a distance greater than
αr0(N) from the receiver, where α is chosen according to the propagation model. For any random
deployment of the nodes, the choice of r0(N) induces a network topology, such that there is a link
between two nodes if their distance is less than r0(N). The resulting graph having the nodes as vertices
and the edges as links, is a random graph, because the positions of the nodes are random. This kind of
graph is known as a Random Geometric Graph (RGG).1 To make an efﬁcient use of the radio resources,
it is useful to take r0(N) as small as possible, to save local transmit power and make possible the reuse
of radio resources, either frequency or time slots. However, r0(N) should not be too small to loose
connectivity. In other words, we do not want the network to split in subnetworks that do not interact
with each other. Since the node location is random, network connectivity can only be guaranteed in
probability. It has been proved in [3] that, if r0(N) is chosen as follows:
r0(N) = R

log N + c(N)
π N
(7.2)
with c(N) going to inﬁnity, as N goes to inﬁnity, the resulting RGG is asymptotically connected with
high probability, as N goes to inﬁnity. For instance, if we take c(N) = (π −1) log N, the coverage radius
can be expressed simply as
r0(N) = R

log N
N
.
(7.3)
A further property of a node is the number of neighbors of that node. For an undirected graph, the
number of neighbors of a node is known as the degree of the node. Denoting by d(N) the degree of
an RGG with N nodes, it was proved in [4] that, choosing the coverage radius as in (7.2), d(N) is
(asymptotically) upper bounded by a function that behaves as log N. More speciﬁcally,
lim
N→∞P {d(N) ≤c log N} = 1.
(7.4)
1A basic review of graph properties is reported in Appendix A.

334
CHAPTER 7 Distributed Detection and Estimation
In [4] it was established an interesting link between the properties of the function f (x) to be computed
by the network and the topology of the communication network. In particular, assuming as usual that
the measurements are quantized in order to produce a value belonging to a ﬁnite alphabet, let us denote
by R( f , N) the range of f (x) and by |R( f , N)| the cardinality of R( f , N). In [4], it was proved that,
under the following assumptions:
A.1.
f (x) is divisible;
A.2.
the network is connected;
A.3.
the degree of each node is chosen as d(N) ≤k1 log |R( f , N)|;
then, the rate for computing f (x) scales with N as
R(N) ≥
c1
log |R( f , N)|.
(7.5)
This is an important result that has practical consequences. It states, in fact, that, whenever log |R( f , N)|
scales with a law that increases more slowly than N, we can have an increase of efﬁciency if we organize
the local computation and the ﬂow of partial results properly. For instance, if the sensors communicate to
the sink node through a Time Division Multiplexing Access (TDMA) scheme, with a standard approach
it is necessary to allocate N time slots to send all the data to the sink node. Conversely, Eq. (7.5)
suggests that, to compute the function f (x), it is sufﬁcient to allocate log |R( f , N)|/c1 slots. The same
result would apply in a Frequency Division Multiplexing Access (FDMA) scheme, simply reverting
the role of time slots and frequency subchannels. This is indeed a paradigm shift, because it suggests
that an efﬁcient radio resource allocation in a WSN should depend on the cardinality of R( f , N). This
implies a sort of cross-layer approach that involves physical, MAC and application layers jointly. The
next question is how to devise an access protocol that enables such an efﬁcient design. To this regard,
the theorem proved in [4] contains a constructive proof, which suggests how to organize the ﬂow of
information from the sensing nodes to the control center. In particular, the strategy consists in making
a tessellation of the area monitored by the sensor network, similarly to a cellular network, as pictorially
described in Figure 7.1. Furthermore, the information ﬂows from the peripheral nodes to the fusion
center through a tree-like graph, having the fusion center as its root. In each cell, the nodes (circles)
identify a node as the relay node (square). The relay node collects data from the nodes within its own
cell and from relay nodes of its leaves, performs local computations and communicates the result to
the parent relay nodes, with the goal of propagating these partial results towards the root (sink node).
To handle interference, a graph coloring scheme is used to avoid interference among adjacent cells.
This allows spatial reuse of radio resources, e.g., frequency or time slots, which can be used in parallel
without generating an appreciable interference. The communication structure is conceptually similar to
a cellular network, with the important difference that now the ﬂow of information is directly related to
the computational task. A few examples are useful to better grasp the possibilities of this approach.
Data uploading: Suppose it is necessary to convey all the data to the sink node. If each observed vector
belongstoanalphabetX,withcardinality|X|,thecardinalityofthewholedatasetis|R( f , N)| = |X|N.
Hence, log |R( f , N)| = N log |X|. This means that, according to (7.5), the capacity of the network
scales as 1/N. This is a rather disappointing result, as it shows that there is no real beneﬁt with respect

2.07.2 General Framework
335
FC
FIGURE 7.1
Hierarchical organization of information ﬂow from peripheral nodes to fusion center.
to the simplest communication case one could envisage: The nodes have to split the available bandwidth
into a number of sub-bands equal to the number of nodes, with a consequent rate reduction per node.
Decision based on the histogram of the measurements: Let us suppose now that the decision to be taken
at the control node can be based on the histogram of the data collected by the nodes, with no information
loss. In this case, the function f (x) is the histogram. It can be veriﬁed that the histogram is a divisible
function. Furthermore, the cardinality of the histogram is
|R( f , N)| =
 N + |X| −1
|X| −1

.
(7.6)
Furthermore, it can be shown that

N/|X|
|X | ≤
 N + |X| −1
|X| −1

≤

N + 1
|X | .
(7.7)
Hence, in this case log |R( f , N)| behaves as log N and then the rate R(N) in (7.5) scales as 1/ log N.
This is indeed an interesting result, showing that if the decision can be based on the histogram of the
data, rather than on each single measurement, adopting the right communication scheme, the rate per
node behaves as 1/ log N, rather than 1/N, with a rate gain N/ log N, which increases as the number
of nodes increases.
Symmetric functions: Let us consider now the case where f (x) is a symmetric function. We recall that a
function f (x) is symmetric if it is invariant to permutations of its arguments, i.e., f (x) = f (x) for any
permutation matrix  and any argument vector x. This property reﬂects the so called data-centric view,
where what it important is the measurement per se, and not which node has taken which measurement.

336
CHAPTER 7 Distributed Detection and Estimation
Examples of symmetric functions include the mean, median, maximum/minimum, histogram, and so
on. The key property of symmetric functions is that it can be shown that they depend on the argument
x only through the histogram of x. Hence, the computation of symmetric functions is a particular case
of the example examined before. Thus, the rate scales again as 1/ log N.
2.07.2.2 Impact of observation model
Having recalled that the efﬁcient design of a WSN requires an information ﬂow that depends on the
scope of the network, more speciﬁcally, on the structural properties of the function to be computed by
the network, it is now time to be more speciﬁc on the decision tasks that are typical of WSNs, namely
detection and estimation. Let us consider for example the simple hypothesis testing problem. In such a
case, an ideal centralized detector having error-free access to the measurements collected by the nodes,
should compute the likelihood ratio and compare it with a suitable threshold [5]. We denote with H0
and H1 the two alternative hypotheses, i.e., absence or presence of the event of interest, and with xi the
set of measurements collected by node i. If we indicate with p(x1, . . . , xN; Hi) the joint probability
density function of the whole set of observed data, under the hypothesis Hi, with i = 0, 1, the likelihood
ratio test amounts to comparing the likelihood ratio (LR) with a threshold γ , and decide for H1 if the
threshold is exceeded or for H0, otherwise. In formulas
(x) := (x1, . . . , xN) = p(x1, . . . , xN; H1)
p(x1, . . . , xN; H0)
H1
⋛
H0
γ.
(7.8)
The LR test (LRT) is optimal under a Bayes or a Neyman-Pearson criterion, the only difference being
that the threshold γ assumes different values in the two cases [5]. In principle, to implement the LRT
at the fusion center, every node should send its observation vector xi to the fusion center, through a
proper MAC protocol. The fusion center, after having collected all the data, should then implement the
LRT, as indicated in (7.8). However, the computation of the LR in (7.8) does not necessarily imply the
transmissionofthesinglevectors xi.Conversely,accordingtothetheoryrecalledabove,thetransmission
strategy should depend on the structural properties of the LR function, if any. Let us see how to exploit
the structure of the LR function in two cases of practical interest.
2.07.2.2.1
Statistically independent observations
Let us start assuming that the observations taken by different sensors are statistically independent,
conditioned to each hypothesis. This is an assumption valid in many cases. Under such an assumption,
the LR can be factorized as follows
(x) :=
N
n=1 p(xn; H1)
N
n=1 p(xn; H0)
:=
N

n=1
n(xn)
H1
⋛
H0
γ,
(7.9)
where n(xn) = p(xn; H1)/p(xn; H0) denotes the local LR at the nth node. In this case, the global
function 

x

in (7.9) possesses a clear structure: It is factorizable in the product of the local LR
functions. Then, since a factorizable function is divisible, it is possible to implement the efﬁcient
mechanisms described in the previous section to achieve an efﬁcient design. The network nodes should

2.07.2 General Framework
337
cluster as in Figure 7.1. Every relay node should compute the local LR, multiply it to the data received
from the relays pertaining to the lower clusters and send the partial result to the relay of the upper cluster,
until the result reaches the fusion center. The efﬁciency comes from the fact that many transmissions
can occur in parallel, exploiting spatial reuse of radio resources. This result suggests also that the proper
source encoding to be implemented at each sensor node consists in the computation of the local LR.
2.07.2.2.2
Markov observations
The previous result is appealing, but it pertains to the simple situation where the observations are sta-
tistically independent, conditioned to the hypotheses. In some circumstances, however, this assumption
is unjustiﬁed. This is the case, for example, when the sensors monitor a ﬁeld of spatially correlated
values, like a temperature or atmospheric pressure ﬁeld. In such cases, nearby nodes sense correlated
values and then the statistical independence assumption is no longer valid. It is then of interest, in such
cases, to check whether the statistical properties of the observations can still induce a structure on the
function to be computed that can be exploited to improve network efﬁciency.
There is indeed a broad class of observation models where the joint pdf cannot be factorized into the
product of the individual pdf’s pertaining to each node, but it can still be factorized into functions of
subsets of variables. This is the case of Bayes networks or Markov random ﬁelds. Here we will recall
the basic properties of these models, as relevant to our problem. The interested reader can refer to many
excellent books, like, for example, [6] or [7].
In the Bayes network’s case, the statistical dependency among the random variables is described
by an acyclic directed graph, whose vertices represent the random variables, while the edges represent
local conditional probabilities. In particular, given a node xi, whose parent nodes are identiﬁed by the
set of indices pa(i), the joint probability density function (pdf) of a Bayes network can be written as
p(x1, . . . , xN) =
N

i=1
p(xi/xpa(i)),
(7.10)
where xpa(i) collects all the variables corresponding to the parents of node i. If a node in (7.10) does
not have parents, the corresponding probability is unconditional.
Alternatively, a Markov random ﬁeld is represented through an undirected graph. More speciﬁcally,
a Markov network consists of:
1. An undirected graph G = (V , E), where each vertex v ∈V represents a random variable and each
edge {u, v} ∈E represents statistical dependency between the random variables u and v;
2. A set of potential (or compatibility) functions ψc(xc) (also called clique potentials), that associate
a non-negative number to the cliques2 of G.
Let us denote by C the set of all cliques present in the graph. The random vector x is Markovian if
its joint pdf admits the following factorization
p(x) = 1
Z

c∈C
ψc(xc),
(7.11)
2A clique is a subset of nodes which are fully connected and maximal, i.e., no additional node can be added to the subset so
that the subset remains fully connected.

338
CHAPTER 7 Distributed Detection and Estimation
1
2
3
4
5
6
7
C
C
C
1
2
3
FIGURE 7.2
Example of Markov graph.
where xc denotes the vector of variables belonging to the clique c. The functions ψc(xc) are called
compatibility functions. The term Z is simply a normalization factor necessary to guarantee that p(x)
is a valid pdf. A node p is conditionally independent of another node q in the Markov network, given
some set S of nodes, if every path from p to q passes through a node in S. Hence, representing a set of
random variables by drawing the correspondent Markov graph is a meaningful pictorial way to identify
the conditional dependencies occurring across the random variables. As an example, let us consider the
graph reported in Figure 7.2. The graph represents conditional independencies among seven random
variables. The variables are grouped into 3 cliques. In this case, for example, we can say that nodes 1–4
are statistically independent of nodes 6 and 7, conditioned to the knowledge of node 5. In this example,
the joint pdf can be written as follows
p(x) = 1
Z ψ1(x1, x2, x3, x4)ψ2(x5, x6, x7)ψ3(x4, x5).
(7.12)
If the product in (7.11) is strictly positive for any x, we can introduce the functions
Vc(xc) = −log ψc(xc)
(7.13)
so that (7.11) can be rewritten in exponential form as
p(x) = 1
Z exp
	
−

c∈C
Vc(xc)

.
(7.14)
This distribution is known, in physics, as the Gibbs (or Boltzman) distribution with interaction potentials
Vc(xc) and energy 
c∈C Vc(xc).
The independence graph conveys the key probabilistic information through absent edges: If nodes i
and j are not neighbors, the random variables xi and x j are statistically independent, conditioned to the
other variables. This is the so called pairwise Markov property. Given a subset a ⊂V of vertices, p(x)
factorizes as
p(x) = 1
Z

c:c∩a̸=∅
ψc(xc)

c:c∩a=∅
ψc(xc),
(7.15)

2.07.2 General Framework
339
where the second factor does not depend on a. As a consequence, denoting by S −a the set of all
nodes except the nodes in a and by Na the set of neighbors of the nodes in a, p(xa/xS−a) reduces to
p(xa/Na). Furthermore,
p(xa/Na) = 1
Za

c:c∩a̸=∅
ψc(xc) = 1
Za
exp
⎛
⎝−

c:c∩a̸=∅
Vc(xc)
⎞
⎠.
(7.16)
This property states that the joint pdf factorizes in terms that contain only variables whose vertices are
neighbors.
An important example of jointly Markov random variables is the Gaussian Markov Random Field
(GMRF), characterized by having a pdf expressed as in (7.14), with the additional property that the
energy function is a quadratic function of the variables. In particular, a vector x of random variables is
a GMRF if its joint pdf can be written as
p(x) =
1

(2π)N|C|
e−1
2 (x−μ)T C−1(x−μ) =

|A|
(2π)N e−1
2 (x−μ)T A(x−μ),
(7.17)
where μ = E{x} is the expected value of x, C = E{(x −μ)(x −μ)T } is the covariance matrix of x and
A = C−1 is the so called precision matrix. In this case, the Markovianity of x manifests itself through
the sparsity of the precision matrix. As a particular case of (7.16), the coefﬁcient ai j of A is different
from zero if and only if nodes i and j are neighbors.
Having recalled the main properties of GMRF’s, let us now go back to the problem of organizing
the ﬂow of information in a WSN aimed at deciding between two alternative hypotheses of GMRF. Let
us consider for example the decision about the two alternative hypotheses:
H0 : x ∼p(x; H0) = 1
Z0

c∈C
ψc(xc; H0),
(7.18)
H1 : x ∼p(x; H1) = 1
Z1

c′∈C′
ψc′(xc′; H1),
(7.19)
where the sets of cliques involved in the two cases are, in general, different. The factorizations in (7.18,
7.19) suggest how to implement the computation of the LRT:
1. Each cluster in the WSN should be composed of the nodes associated to the random variables
pertaining to the same clique in the statistical dependency graph;
2. The observations gathered by the nodes pertaining to a clique c are locally encoded into the clique
potential ψc(xc; Hi). This is the value that has to be transmitted by each cluster towards upper
layers or to the FC;
3. As in Figure 7.1, each relay in the lowest layer compute the local potentials and forward these results
to the upper layers. The relays of the intermediate clusters receive the partial results from the lower
clusters, multiply these values by the local potential and forward the results to the relay of the upper
cluster, until reaching the FC.

340
CHAPTER 7 Distributed Detection and Estimation
In general, different grouping may occur depending on the hypothesis. This organization represents a
generalization of the distributed computation observed in the conditionally independent case, where the
groups are simply singletons, i.e., sets composed by exactly one element. In that case, the clustering
among nodes is only instrumental to the communication purposes, i.e., to enable spatial reuse of radio
resources. In the more general Markovian case, the organization of the communication network in clus-
ters (cells) should take into account, jointly, the grouping suggested by the cliques of the underlying
dependency graph and the spatial grouping of nodes to enable concurrent transmission over the same
radio resources without incurring in undesired interference. To visualize this general perspective, it is
useful to have in mind two superimposed graphs, as depicted in Figure 7.3: the communication graph
(top), whose vertices are the network nodes while the edges are the radio links; the dependency graph
(bottom), whose vertices represent random variables, while the arcs represent statistical dependencies.
Each communication cluster should incorporate at least one clique. Furthermore, in each cluster there is
a relay node that is responsible for the exchange of data with nearby clusters. The whole communication
network has a hierarchical tree-structure. Each node in the tree is a relay node belonging to a cluster. This
node collects the measurements from the nodes belonging to its cluster, computes the potential (or the
product of potentials if more cliques belong to the same cluster) and forwards this value to its relay par-
ents. While we have depicted the two graphs as superimposed in Figure 7.3, it is useful to clarify that the
nodes of the communication network are located in space and their relative position is well deﬁned in a
Communication network
Dependency graph
FIGURE 7.3
Superposition of communication layer (top) over a Markov statistical dependency graph (bottom).

2.07.2 General Framework
341
metric space. Conversely, the nodes of the Markov graph represent random variables for which there is no
well deﬁned notion of distance or, even if we deﬁne one, it is a notion that in general does not have a cor-
respondence with distance in space. In other words, while the neighborhood of nodes in the top graph has
to do with the concept of spatial distance among the nodes, the neighborhood of the nodes in the Markov
graph has only to do with statistical dependencies. Nevertheless, it is also true that in the observation of
physical entities like a temperature ﬁeld, for example, it is reasonable to expect higher correlation among
nearby (in the spatial sense) nodes (variables). An example of GMRF where the statistical dependencies
incorporate the spatial distances was suggested in [8]. In summary, the previous considerations suggest
that an efﬁcient design of the communication network topology should keep into account the structure, if
any, of dependency graph describing the observed variables. At the same time, the design of the network
topology should keep into account physical constraints like the power consumption necessary to main-
tain the links with sufﬁcient reliability (i.e., to insure the sufﬁcient signal-to-noise ratio at the receiver).
This is indeed an interesting line of research: How to match the network topology to the dependency
graph, under physical constraints dictated by energy consumption, delay, etc. Some works have already
addressed this issue. For example, in [9] the authors addressed the problem of implementing data fusion
policies with minimal energy consumption, assuming a Markov random ﬁeld observation model, and
established the scaling laws for optimal and suboptimal fusion policies. An efﬁcient message-passing
algorithm taking into account the communication network constraints was recently proposed in [10].
2.07.2.3 Fundamental information-theoretical issues
In this section, we recall very brieﬂy some of the fundamental information-theoretic limits of multi-
terminal decision networks. We will not go into the details of this challenging fundamental problem.
The interested reader can refer to [11] and the references therein. In a WSN, each sensor is observing a
physical phenomenon, which can be regarded as a source of information, and the goal of the network is
to take decisions about what is being sensed. In some cases, the decision is taken by a fusion center; in
others, the decision is distributed across the nodes. In general, the data gathered by the nodes has to travel
through realistic channels, prone to additive noise, channel fading and interference. This requires source
and channel coding. In a point-to-point communication, when there is only one sensor transmitting data
to the fusion center, the encoding of the data gathered by the sensor follows well known rules. In
particular, the observation is ﬁrst time-sampled and each sample is encoded in a ﬁnite number, let us
say R, of bits per symbol. This converts an analog source of information into a digital source. In this
analog-to-digital (AD) conversion, there is usually a distortion that can be properly quantiﬁed. More
precisely, the source coding rate R depends on the constraint on the mean-square distortion level D. At the
same time, given a constraint on the power budget (cost) P available at the transmit side, the maximum
rate that can be transmitted with arbitrarily low error probability is the channel capacity C(P), which
depends on the transmit power constraint. A rate-distortion pair (D, P) is achievable if and only if
R(D) ≤C(P).
(7.20)
The source-channel coding separation theorem [12] states that the encoding operation necessary to
transmit information through a noisy channel can be split, without loss of optimality, into the cascade of
two successive independent operations: (i) source coding, where each symbol emitted by the source is
encoded in a ﬁnite number of bits per symbol; (ii) channel coding, where a string of k bits are encoded
into a codeword of length n bits, to make the codeword error probability arbitrarily low. This theorem has

342
CHAPTER 7 Distributed Detection and Estimation
been a milestone in digital communications, as it allows system designers to concentrate, separately, on
source coding and channel coding techniques, with no loss of optimality. However, when we move from
the point-to-point link to the multipoint-to-multipoint case, there is no equivalent of the source-channel
coding separation theorem. This means that in the multi-terminal setting, splitting coding into source
and channel coding does not come without a cost, anymore. Rephrasing the source/channel coding the-
orem in the multi-terminal context, denoting by R(D) the rate region, comprising all the source codes
that satisfy the distortion constraint D, and by C(P) the capacity region, containing all the transmission
rates satisfying the transmit power constraint P, a pair (D, P) is achievable if
R(D) ∩C(P) ̸= ∅.
(7.21)
However, Eq. (7.21) is no longer a necessary condition, meaning that there may exist a code that achieves
the prescribed distortion D at a power cost P, which cannot be split into a source compression encoder
followed by a channel encoder. In general, in the multiterminal case, a joint source/channel encoding is
necessary. This suggests, from a fundamental theoretical perspective, that, again, in a distributed WSN
local processing and communication have to be considered jointly.
2.07.2.4 Possible architectures
Alternative networks architectures may be envisaged depending on how the nodes take decision and
exchange information with each other. A few examples are shown in Figure 7.4 where there is a set of N
nodes observing a given phenomenon, denoted as “nature” for simplicity. The measurements made by
node i are collected into the vector xi, with i = 1, . . . , N. In Figure 7.4a, each node takes an individual
decision, which is represented by the variable ui : ui = 1 if node i decides for the presence of the event,
otherwise ui = 0. More generally, ui could also be the result of a local source encoder, whose aim is to
reduce the redundancy present in the observed data. The simplest case is sketched in Figure 7.4a, where
a set of nodes observes a state of nature and each node takes a decision. Even if this is certainly the
simplest form of monitoring, if the local decisions are taken according to a global optimality criterion,
even in the case of statistically independent observations, the local decisions are coupled in a non trivial
form. The next step, in terms of complexity, is to combine all the observations collected by the sensing
nodes in a centralized node, called fusion center or sink node. This strategy is depicted in the architecture
of Figure 7.4b. In such a case, each node takes a local decision and sends this information to the fusion
center, which combines the local decision according to a globally optimum criterion. What is important,
in a practical setting, is that the limitations occurring in the transmission of information from the sensing
nodes to the fusion center are properly taken into account. An alternative approach is reported in Figure
7.4c, where node 1 takes a local decision and it notiﬁes node 2 about this decision. Node 2, on its turn,
based on the decision of node 1 and on its own measurements as well, takes a second decision, and so
on. A further generalization occurs in the example of Figure 7.4d, where the nodes take local decisions
and exchange information with the other nodes. In such a case, there is no fusion center and the ﬁnal
decision can be taken, in principle, by every node.
Besides the architecture describing the ﬂow of information through the network, a key aspect con-
cerns the constraint imposed by the communication links. Realistic channels are in fact affected by
noise, fading, delays, and so on. Hence, a globally optimal design must incorporate the decision and

2.07.3 Graphical Models and Consensus Algorithm
343
x1
xN
x2
nature
u1
uN
u2
1
2
N
x1
xN
x2
nature
fusion center
uN
u0
u2
u1
1
2
N
x1
x3
x2
nature
u1
u3
u2
1
2
3
x1
x3
x2
nature
1
2
3
5
4
x4
(c)
(a)
(b)
(d)
FIGURE 7.4
Alternative communication architectures between peripheral nodes and fusion center.
communication aspects jointly in a common context. The ﬁrst step in this global design passes through
a formal description of the interaction among the nodes.
2.07.3 Graphical models and consensus algorithm
The proper way to describe the interactions among the network nodes is to introduce the graph model of
thenetwork.LetusconsideranetworkcomposedofNsensors.Theﬂowofinformationacrossthesensing
nodes implementing some form of distributed computation can be properly described by introducing a
graph model whose vertices are the sensors and there is an edge between two nodes if they exchange
information with each other.3 Let us denote the graph as G = {V, E} where V denotes the set of N vertices
(nodes) vi and E ⊆V × V is the set of edges ei j(vi, v j). The most powerful tool to grasp the properties
of a graph is algebraic graph theory [13], which is based on the description of the graph through
appropriate matrices, whose deﬁnition we recall here below. Let A ∈RN×N be the adjacency matrix of
the graph G, whose elements ai j represent the weights associated to each edge with ai j > 0 if ei j ∈E and
ai j = 0 otherwise. According to this notation and assuming no self-loops, i.e., aii = 0, ∀i = 1, . . . , N,
3We refer the reader to Appendix 2.07.9 for a review of the basic notations and properties of graphs.

344
CHAPTER 7 Distributed Detection and Estimation
the out-degree of node vi is deﬁned as degout(vi) = N
j=1 a ji. Similarly, the in-degree of node vi is
degin(vi) = N
j=1 ai j. The degree matrix D is deﬁned as the diagonal matrix whose ith diagonal entry
is dii = degin(vi). Let Ni denote the set of neighbors of node i, so that |Ni| = deg(vi).4 The Laplacian
matrix L ∈RN×N of the graph G is deﬁned as L := D −A. Some properties of the Laplacian will be
extensively used in our distributed algorithms to be presented later on and then it is useful to recall them.
Properties of the Laplacian matrix
P.1.
L has, by construction, a null eigenvalue with associated eigenvector the vector 1 composed
by all ones. This property can be easily checked verifying that L1 = 0 since by construction,
N
j=1 ai j = dii
P.2. The multiplicity of the null eigenvalue is equal to the number of connected components of the
graph. Hence, the null eigenvalue is simple (it has multiplicity one) if and only if the graph is
connected.
P.3. If we associate a state variable xi to each node of the graph, if the graph is undirected, the disagree-
ment between the values assumed by the variables is a quadratic form built on the Laplacian [13]:
J(x) := 1
4
N

i=1

j∈Ni
ai j(xi −x j)2 = 1
2 xT Lx,
(7.22)
where x = [x1, . . . , xN]T denotes the network state vector.
2.07.3.1 Consensus algorithm
Given a set of measurements xi(0), for i = 1, . . . , N, collected by the network nodes, the goal of
consensus algorithm is to minimize the disagreement among the nodes. This can be useful, for example,
when the nodes are measuring some common variable and their measurement is affected by error. The
scope of the interaction among the nodes is to reduce the effect of errors on the ﬁnal estimate. In fact,
consensus is one of fundamental tools to design distributed decision algorithms that satisfy a global
optimality principle, as corroborated by many works on distributed optimization, see, e.g., [14–20]. We
recall now the consensus algorithm as this will form the basis of the distributed estimation and detection
algorithms developed in the ensuing sections. Let us consider, for simplicity, the case where the nodes
are measuring a temperature and the goal is to ﬁnd the average temperature. In this case, reaching a
consensus over the average temperature can be seen as the minimization of the disagreement, as deﬁned
in (7.22), between the states xi(0) associated to the nodes.
The minimization of the disagreement can be obtained by using a simple gradient-descent algorithm.
More speciﬁcally, using a continuous-time system, the minimum of (7.22) can be achieved by running
the following dynamical system [15]
˙x(t) = −Lx(t),
(7.23)
initialized with x(0) = x0, where x0 is the vector containing all the initial measurements collected by
the network nodes. This means that the state of each node evolves in time according to the ﬁrst order
differential equation
˙xi(t) =

j∈Ni
ai j(x j(t) −xi(t)),
(7.24)
4By | · | we denote the cardinality of the set.

2.07.3 Graphical Models and Consensus Algorithm
345
where Ni indicates the set of neighbors of node i. Hence, every node updates its own state only by
interacting with its neighbors.
Equation (7.23) assumes the form of a diffusion equation. Let us consider for example the evolution
of a diffusing physical quantity ψ(z; t) as a function of the spatial variable z and of time t (ψ(z; t) could
represent, for instance, the heat distribution), the diffusion equation assumes the form
∂ψ(z; t)
∂t
= D ∂2ψ(z; t)
∂z2
,
(7.25)
where D is the diffusion coefﬁcient. If we discretize the space variable and approximate the second
order derivative with a discrete-time second order difference, the diffusion Eq. (7.25) can be written
as in (7.23), where the Laplacian matrix represents the discrete version of the Laplacian operator. This
conceptual link between consensus equation and diffusion equation has been exploited in [21] to derive a
fast consensus algorithm, mimicking the effect of advection. The interesting result derived in [21] is that
to speed up the consensus (diffusion) process, it is necessary to use a directed graph, with time-varying
adjacency matrix coefﬁcients ai j.
The solution of (7.23) is given by
x(t) = exp (−Lt)x(0).
(7.26)
In the case analyzed so far, since the consensus algorithm has been deduced from the minimization of the
disagreement and the disagreement has been deﬁned for undirected graphs, the matrix L is symmetric.
Hence, its eigenvalues are real. The convergence of (7.26) is guaranteed because all the eigenvalues of
L are non-negative, by construction. If the graph is connected, according to property P.2, the eigenvalue
zero has multiplicity one. Furthermore, the eigenvector associated to the zero eigenvalue is the vector
1. Hence, the system (7.23) converges to the consensus state:
lim
t→∞x(t) = 1
N 11T x(0).
(7.27)
This means that every node converges to the average value of the measurements collected by the whole
network, i.e.,
lim
t→∞xi(t) = 1
N
N

i=1
xi(0) = x∗.
(7.28)
The convergence rate of system (7.24) is lower bounded by the slowest decaying mode of the dynamical
system (7.23), i.e., by the second smallest eigenvalue of L, λ2(L), also known as the algebraic con-
nectivity of the graph [22]. More speciﬁcally, if the graph is connected or, equivalently, if λ2(L) > 0,
then the dynamical system (7.23) converges to consensus exponentially [15], i.e., ∥x(t) −x∗1∥≤
∥x(0) −x∗1∥O(e−rt) with r = λ2(L).
In some applications, the nodes are required to converge to a weighted consensus, rather than average
consensus. This can be achieved with a slight modiﬁcation of the consensus algorithm. If we premultiply
the left side of (7.24) by a positive coefﬁcient ci, the resulting equation
ci ˙xi(t) =

j∈Ni
ai j(x j(t) −xi(t))
(7.29)

346
CHAPTER 7 Distributed Detection and Estimation
converges to the weighted average
lim
t→∞xi(t) =
N
i=1ci xi(0)
N
i=1ci
.
(7.30)
This property will be used in deriving distributed estimation mechanisms in the next section.
Alternatively, the minimization of (7.22) can be achieved in discrete-time through the following
iterative algorithm
x[k + 1] = x[k] −ϵLx[k] := W x[k],
(7.31)
where we have introduced the so called transition matrix W = I −ϵL. Also in this case, the discrete
time equation is initialized with the measurements taken by the sensor nodes at time 0, i.e., x[0] := x0.
This time, to guarantee convergence of the system (7.31), we need to choose the coefﬁcient ϵ properly.
More speciﬁcally, the discrete time Eq. (7.31) converges if the eigenvalues of W are bounded between
−1 and 1. This can be seen very easily considering that reiterating (7.31) k times, we get
x[k] = Wkx[0].
(7.32)
Let us denote by uk the eigenvectors of W associated to the eigenvalues λk(W), with k = 1, . . . , N.
The eigenvalues of W are real and we consider them ordered in increasing sense, so that λN(W) ≥
λN−1(W) ≥· · · λ1(W). Hence, the evolution of system (7.32) can be written as
x[k] =
N

n=1
λk
n(W)unuT
n x[0].
(7.33)
The matrix W has an eigenvector equal to 1/
√
N, associated to the eigenvalue 1 by construction. In
fact, W1/
√
N = 1/
√
N −ϵL1/
√
N = 1/
√
N. If the graph is connected, the eigenvalue 1 of W has
multiplicity one. Furthermore, if ϵ is chosen such that ϵ(L) < 2/λN(L), all other eigenvalues are less
than 1. Hence, for a connected graph, the system (7.33) converges to
lim
k→∞x[k] = 1
N 11T x[0].
(7.34)
Again, this corresponds to having every node converging to the average consensus.
The consensus algorithm can be extended to the case of directed graphs. This case is indeed much
richer of possibilities than the undirected case, because the consensus value ends up to depend more
strictly on the graph topology. In the directed case, in fact, L is an asymmetric matrix. The most important
difference is that the graph connectivity turns out to depend on the orientation of the edges. Furthermore,
each eigenvalue of L gives rise to a pair of left and right eigenvectors which do not coincide with each
other. These differences affect the ﬁnal consensus state and induce different forms of consensus, as
shown below.
The convergence of the system in (7.31) can be proved by exploiting the properties of non-negative
matrices. A nonnegative matrix is row (or column) stochastic if all its row (or column) sums are equal to
one. Furthermore if the graph associated to the network is strongly connected, i.e., the zero eigenvalue
associated to L has multiplicity one (see Appendix 2.07.9), W is called an irreducible matrix. An
irreducible stochastic matrix is primitive if it has only one eigenvalue with maximum modulus. Primitive
nonnegative matrices, often named Perron matrices, satisfy the Perron-Frobenius theorem [23].

2.07.3 Graphical Models and Consensus Algorithm
347
Theorem 1.
Let γ l and γ r, respectively, the left and right eigenvectors associated to the unit eigen-
value of the primitive nonnegative matrix W, i.e., Wγ r = γ r and γ T
l W = γ T
l with γ T
r γ l = 1, then
limk→∞Wk = γ rγ T
l .
Let us now apply to a sensor network modeled by the graph G, with adjacency matrix A, the distributed
consensus algorithm
xi[k + 1] = xi[k] −ϵ

j∈Ni
ai j(xi[k] −x j[k])
(7.35)
with 0 < ϵ < 1/dmax.
Interestingly, different forms of consensus can be achieved in a directed graph, depending on the
graph connectivity properties [17]:
a. If the graph is strongly connected, the dynamical system in (7.35) converges to a weighted consensus,
for any initial state vector x[0], i.e.,
lim
k→∞Wkx[0] = x⋆= 1 γ T
l x[0],
(7.36)
where γl(i) > 0, ∀i, and N
i=1 γl(i) = 1. In this case, since the graph is strongly connected, W is
an irreducible matrix. Then, applying Gershgorin theorem [23], it can be deduced that there exists a
single eigenvalue μ1(W) = 1 with maximum modulus. Then W is a primitive nonnegative matrix
and from Theorem 1 the convergence in (7.36) is straightforward. In this case, every node contributes
to the ﬁnal consensus value. Furthermore, the consensus value is a weighted combination of the
initial observations, where the weights are the entries of the left eigenvector associated to the null
eigenvalue of L (or the unit eigenvalue of W).
b. If the digraph is strongly connected and balanced, i.e., 1T L = 0 and L1 = 0, the systems achieves
an average consensus or x⋆= 11T
N x[0]. In fact, for balanced graphs, W is a double stochastic matrix
with γ l = γ r = 1/
√
N;
c. If the digraph G is weakly connected (WC), but not strongly connected, and it contains a forest
with K strongly connected root components, the graph splits in K disjoint clusters C1, . . . , CK ⊆
{1, . . . , N},5 and all the nodes pertaining to each cluster converge to the consensus values
x⋆
q =

i∈Ck γi xi[0]

i∈Ck γi
,
∀q ∈Ck,
k = 1, . . . , K.
(7.37)
In words, there is no single consensus, in this case, but there is a local consensus within each cluster.
Different clusters typically converge to different consensus values.
d. If the digraph G is composed of a single spanning tree, every node converges to the value assumed
by the root node.
As far as the convergence rate, instead, in [15] it has been shown for undirected connected graphs that the
dynamical system in (7.31) converges exponentially to the average consensus with a rate at least equal
5In general, the clusters C1, . . . , CK are not a partition of the set of nodes {1, · · · , N}.

348
CHAPTER 7 Distributed Detection and Estimation
to μ2(W) = 1 −ϵλ2(L) where μ2(W) is the second largest eigenvalue of the Perron matrix W. In fact
by deﬁning the disagreement vector δ = x −x⋆, it can be easily veriﬁed [15] that δ evolves according to
the disagreement dynamic given by δ[k +1] = Wδ[k]. Hence ψ[k] := δ[k]T δ[k] represents a candidate
Lyapunov function for the disagreement dynamics so that
ψ[k + 1] = δ[k + 1]T δ[k + 1] = ∥Wδ[k]∥2 ≤μ2(W)2∥δ[k]∥2 = μ2(W)2ψ[k]
(7.38)
with 0 < μ2(W) < 1 since W is a symmetric and primitive matrix. As a consequence the algorithm
converges exponentially to consensus with a rate at least equal to μ2(W).
2.07.3.2 Consensus algorithms over realistic channels
So far, we have recalled the basic properties of consensus algorithm assuming that the exchange of
information across the nodes occurs with no errors. In this section we study what happens to consensus
algorithms when the communications among the nodes are affected by quantization errors, noise, packet
drops, etc. The problem of consensus protocols affected by stochastic disturbance has been considered
in a series of previous papers [24–29]. In [24], the authors use a decreasing sequence of weights to prove
the convergence of consensus protocols to an agreement space in the presence of additive noise under
a ﬁxed network topology. The works in [25,26] consider consensus algorithms in the presence of link
failures, which are modeled as i.i.d. Laplacian matrices of a directed graph. The papers present necessary
and sufﬁcient conditions for consensus exploiting the ergodicity of products of stochastic matrices. A
distributed consensus algorithm in which the nodes utilize probabilistically quantized information to
communicate with each other was proposed in [27]. As a result, the expected value of the consensus is
equal to the average of the original sensor data. A stochastic approximation approach was followed in
[28], which considered a stochastic consensus problem in a strongly connected directed graph where
each agent has noisy measurements of its neighboring states. Finally, the study of a consensus pro-
tocol that is affected by both additive channel noise and a random topology was considered in [29].
The resulting algorithm relates to controlled Markov processes and the convergence analysis relies on
stochastic approximation techniques.
In the study of consensus mechanisms over realistic channels, we consider the following sources of
randomness:
1. Node positions: The ﬁrst randomness is related to the spatial positions of the nodes, which are in
general unknown. We model the spatial distribution of nodes as a random geometric graph composed
of N nodes. In graph theory, a random geometric graph (RGG) is a random undirected graph drawn
on a bounded region, eg. the unit disk, generated by:
a. Placing vertices at random uniformly and independently on the region,
b. Connecting two vertices, u, v if and only if the distance between them is inside a threshold
radius r0, i.e., d(u, v) ≤r0.
Several probabilistic results are known about RGG’s. In particular, as shown in [3], if N nodes are
placed in a disc of unit area in R2 and each node transmits with a power scaling with N as in (7.2),
the resulting network is asymptotically connected with probability one, as N →∞.

2.07.3 Graphical Models and Consensus Algorithm
349
2. Random link failures model: In a realistic communication scenario, the packets exchanged among
sensors may be received with errors, because of channel fading or noise. The retransmission of
erroneous packets can be incorporated into the system, but packet retransmission introduces a
nontrivial additional complexity in decentralized implementations and, most important, it introduces
an unknown delay and delay jitter. It is then of interest to examine simple protocols where erroneous
packets are simply dropped. Random packet dropping can be taken into account by modeling the
coefﬁcient ai j describing the network topology as random variables that assume the value 1 or 0, if
the packet is correctly delivered or not, respectively. In this case, the Laplacian varies with time as
a sequence of i.i.d. matrices {L[k]}, which can be written, without any loss of generality, as
L[k] = ¯L + ˜L[k],
(7.39)
where ¯L denotes the mean matrix and ˜L[k] are i.i.d. perturbations around the mean. We do not
make any assumptions about the link failure model. Although the link failures and the Laplacians are
independent over time, during the same iteration, the link failures can still be spatially correlated. It is
important to remark that we do not require the random instantiations G[k] of the graph be connected
for all k. We only require the graph to be connected on average. This condition is captured by
requiring λ2( ¯L) > 0.
3. Dithered quantization: We assume that each node encodes the message to be exchanged with the
other nodes using a uniform quantizer, with a ﬁnite number of bits nb, deﬁned by the following
vector mapping, q(·) : RL →QL,
q(y) = [b1, . . . , bL]T = y + eq(y),
(7.40)
where the entries of the vector y, the quantization step  > 0, and the error eq satisfy
(bm −1/2) ≤ym ≤(bm + 1/2),
1 ≤m ≤L,
(7.41)
−/21L ≤eq(y) ≤/21L,
for all y.
(7.42)
The quantization alphabet is
QL = {[b1, . . . , bL]T |bm ∈Z, ∀m}.
(7.43)
Conditioned on the input, the quantization error eq(y) is deterministic. This induces a correlation
among the quantization errors resulting at different nodes and different times, which may affect
the convergence properties of the distributed algorithm. To avoid undesired error correlations, we
introduce dithering, as in [30,31]. In particular, the dither added to randomize the quantization
effects satisﬁes a special condition, namely the Schuchman conditions, as in subtractively dithered
systems, [32]. Then, at every time instant k, adding to each component ym[k] a dither sequence
{dm[k]}k≥0 of i.i.d. uniformly distributed random variables on [−/2, /2) independent of the
input sequence, the resultant error sequence {em[k]}k≥0 becomes
em[k] = q(ym[k] + dm[k]) −(ym[k] + dm[k]).
(7.44)
The sequence {em[k]}k≥0 is now an i.i.d. sequence of uniformly distributed random variables on
[−/2, /2), which is independent of the input sequence.

350
CHAPTER 7 Distributed Detection and Estimation
The convergence of consensus algorithm in the presence of random disturbance can be proved by
exploiting results from supermartingale theory [33]. In an ideal communication case, by selecting the
step-size of the algorithm to be sufﬁciently small (smaller than 2/λN(L), where λN(L) is the maximum
eigenvalue of the Laplacian matrix of the graph), the discrete-time consensus algorithm will asymp-
totically converge to the agreement subspace. However, in a realistic communication scenario, the
links among the sensors may fail randomly and the exchanged data is corrupted by quantization noise.
Under these nonideal conditions, the consensus algorithm needs to be properly adjusted to guarantee
convergence. A discrete time consensus algorithm that accounts for random link failures and dithered
quantization noise can be written as:
xi[k + 1] = xi[k] + α[k]
N

j=1
ai j[k](q(x j[k] + di j[k]) −xi[k]),
i = 1, . . . , N,
(7.45)
where α[k] is apositiveiterationdependent step-size, and di j [k] is the dithered quantization vector. Now,
exploitingthefeatureofsubtractivelyditheredsystemsin(7.44),thepreviousexpressioncanberecastas:
xi[k + 1] = xi[k] + α[k]
N

j=1
ai j[k](x j[k] −xi[k] + di j[k] + ei j[k]),
i = 1, . . . , N.
(7.46)
Starting from some initial value, xi[0] ∈RL, each node generates via (7.46) a sequence of state vari-
ables, {xi[k]}k≥0. The value xi[k+1] at the ith node at time k+1 is a function of: its previous state xi[k]
and the quantized states correctly received at time k by the neighboring sensors. As described previously,
the data are subtractively dithered-quantized, so that the quantized data received by the ith sensor from
the jth sensor at time k is q(x j[k]+ di j[k]). It then follows that the quantization error ei j[k] is a random
vector, whose components are i.i.d., uniformly distributed on [−/2, /2), and independent of x j[k].
One way to guarantee convergence of the previous system is to use a positive iteration-dependent
step size α[k] satisfying [24,29]
lim
k→∞α[k] = 0,
∞

k=0
α[k] = ∞,
∞

k=0
α2[k] < ∞.
(7.47)
Exploiting results from stochastic approximation theory, this choice drives the noise variance to zero
while guaranteeing the convergence to the consensus subspace.
A numerical example is useful to show the robustness of consensus algorithm in the presence of link
failures and quantization noise. We consider a connected network composed of 20 nodes as depicted
on the left side of Figure 7.5. The initial value of the state variable at each node is randomly chosen
in the interval [0, 1). At the kth iteration of the updating rule (7.45), each node communicates to its
neighbors its current state, i.e., a scalar xi[k]. Because of fading and additive noise, a communication link
among two neighbors has a certain probability p to be established correctly. The values to be exchanged
are (dither) quantized with 6 bits. The iteration-dependent step size is chosen as α[k] = α0/k, with
α0 = 1.5/λN(L), in order to satisfy (7.47). The right side of Figure 7.5 shows the average behavior of
the disagreement among the sensors in the network, versus the iteration index, for different values of the
probability p to establish a communication link correctly. The result is averaged over 100 independent
realizations. The ideal case corresponds to p = 1 and it is shown as a benchmark. As we can notice

2.07.4 Distributed Estimation
351
0
0.2
0.4
0.6
0.8
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0
10
20
30
40
50
60
70
80
90
100
−0.5
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
5
Iteration index
Disagreement
p = 0.3
p = 0.5
p = 0.7
Ideal case
FIGURE 7.5
Network (left). Disagreement vs. time index (right), for different probabilities of correct packet reception.
from the right side of Figure 7.5, even in the presence of random disturbances, an agreement is always
reached by the network for any value of p. The only effect of the random link failures is to slow down
the convergence process, without altering the ﬁnal value of the global potential function. This proves
the robustness of the algorithm.
2.07.4 Distributed estimation
Having introduced all the tools necessary to study distributed estimation and detection mechanisms, let
us now start with the estimation problem. This problem has been the subject of an extensive literature,
see, e.g., [34–43]. Most of the algorithms proposed in these works propose a mix of local estimation
and consensus among neighbor nodes to improve upon the performance of the local estimators. In a ﬁrst
class of methods, like [35,36] for example, the nodes collect all the data ﬁrst, perform local estimation
and then interact iteratively with their neighbors. In alternative methods, the nodes keep interacting
with each other while collecting new measurements or, in general, receiving new information, like in
[37,38,42]. These two classes of methods can be seen as assigning different time scales to the local
estimation and consensus steps. Indeed, it can be proved that a proper combination of local estimation
and consensus can bring the whole network to a globally optimal estimate, provided that the graph
describing the interaction among the nodes is connected. This approach was pursued, for example in
[35], where the so called bridge nodes fulﬁlled the scope of enforcing local consensus. In the following,
we will show how alternative formulations of the globally optimal estimation problem naturally lead to
a different mix of the local estimation and the consensus steps, without the need to introduce any node
having a special role nor enforcing different time scales a priori.
Let us denote with θ ∈RM the parameter vector to be estimated. In some cases, there is no prior infor-
mation about θ. In other cases, θ is known to belong to a given set C: For instance, its entries are known

352
CHAPTER 7 Distributed Detection and Estimation
to be positive or to belong to a ﬁnite interval of known limits, and so on. In some applications, θ may be
the outcome of a random variable described by a known pdf p(θ). Let us denote by xi the measurement
vector collected by node i and by x := [xT
1 , . . . , xT
N]T the whole set of data collected by all the nodes.
In the two cases of interest, the estimation can be obtained as the solution of the following problems:
Arbitrary case
max
θ
pX;(x; θ)
(7.48)
s.t. θ ∈C
(7.49)
where pX;(x; θ) is the joint pdf of vector x, for a given arbitrary vector θ, or
Random case
max
θ
pX/(x/θ)p(θ),
(7.50)
where p(θ) is (known) prior pdf of the parameter vector and pX/(x/θ) is the pdf of x conditioned to θ.
In general, it is not necessary to reconstruct the whole joint pdf pX;(x; θ) (or pX/(x/θ)) to obtain
the optimal estimate. Let us consider, for example, the case where the pdf can be factorized as
pX;(x; θ) = g

T(x), θ

h(x),
(7.51)
where g(·, ·) depends on x only through T(x), whereas h(·) does not depend on θ. The function T(x)
is called a sufﬁcient statistic for θ [44]. In general, the sufﬁcient statistic T(x) is a vector, as it may be
constituted by a set of functions.
If (7.51) holds true, all is necessary to estimate θ is not really pX;(x; θ), but only g

T(x), θ

. This
means that any sensor able to evaluate T(x) through an interaction with the other sensors is able to ﬁnd
out the optimal parameter vector θ as the vector that maximizes g

T(x), θ

.
A simple (yet common) example is given by the so called exponential family of pdf
p(x; θ) = exp

A(θ)B(x) + C(x) + D(θ)

.
(7.52)
Examples of random variables described by this class include the Gaussian, Rayleigh, and exponential
pdf’s. Hence, this is a rather common model. Let us assume now that the observations xi collected by
different nodes are statistically independent and identically distributed (i.i.d.), according to (7.52). It is
easy to check, simply applying the deﬁnition in (7.51), that a sufﬁcient statistic in such a case is the
scalar function:
T (x) =
N

i=1
B(xi).
(7.53)
This structure suggests that a simple distributed way to enable every node in the network to estimate the
vector θ locally, without loss of optimality with respect to the centralized approach, is to run a consensus
algorithm, where the initial state of every node is set equal to B(xi). At convergence, if the network is
connected, every node has a state equal to the consensus value, i.e., T (x)/N. This enables every node
to implement the optimal estimation by simply interacting with its neighbors to achieve a consensus.
The only necessary condition for this simple method to work properly is that the network be connected.
This is indeed a very simple example illustrating how consensus can be a fundamental step in deriving

2.07.4 Distributed Estimation
353
an optimal estimation through a purely decentralized approach relying only upon the exchange of data
among neighbors.
In the next two sections, we will analyze in more details the purely distributed case (with no fusion
center) where the global estimation can be carried out in any node and the centralized case, where the
ﬁnal estimation is taken at the fusion center.
2.07.4.1 Decentralized observations with decentralized estimation
In the following we analyze different observation models and illustrate alternative distributed estimation
algorithms. We will start with the conditionally independent case and then we will generalize the
approach to a conditionally dependent model.
2.07.4.1.1
Conditionally independent observations
A case amenable for ﬁnding distributed solutions is given by the situations where the observations
collected by different sensors are conditionally independent. In such a case, the joint pdf pX;(x; θ)
can be factorized as follows
pX;(x; θ) =
N

i=1
pXi;(xi; θ),
(7.54)
where pXi;(xi; θ) is the pdf of the vector xi observed by node i. Taking the log of this expression, the
optimization problem can be cast, equivalently, as
max
θ
N

i=1
log pXi;(xi; θ).
(7.55)
Even if the objective function to be maximized is written as a sum of functions depending each on a local
observation vector, the solution of the previous problem still requires a centralized approach because
the vector θ to be estimated is common to all the terms. A possible way to ﬁnd a distributed solution
to the problem in (7.55) consists in introducing an instrumental common variable z and rewriting the
previous problem in the following form
min
θi
−
N

i=1
log pXi;(xi; θi)
s.t. θi = z,
i = 1, 2, . . . , N.
(7.56)
This is a constrained problem, whose Lagrangian is
L(θ, λ, z) :=
N

i=1

−log pXi;(xi; θi) + λT
i (θi −z)

,
(7.57)
where λi are the vectors whose entries are the Lagrange multipliers associated to the equality constraints
in (7.56). In many cases, it is useful to introduce the so called augmented Lagrangian [45]:
Lρ(θ, λ, z) :=
N

i=1

−log pXi;(xi; θi) + λT
i (θi −z) + ρ
2 ∥θi −z∥2
2

,
(7.58)

354
CHAPTER 7 Distributed Detection and Estimation
where ρ is a penalty parameter. Minimizing the augmented Lagrangian leads to the same solution as
minimizing the original Lagrangian because any feasible vector satisfying the linear constraint yields a
zero penalty. Nevertheless, there are some beneﬁts in working with the augmented Lagrangian, namely:
i) the objective function is differentiable under milder conditions than with the original Lagrangian;
ii) convergence can be achieved without requiring strict convexity of the objective function (see [45]
for more insight into the augmented Lagrangian method).
If the pdf’s involved in (7.58) are log-concave functions of θ, the problem in (7.58) is strongly convex
and then it admits a unique solution and there are efﬁcient algorithms to compute the solution. Here,
we are interested in deriving decentralized solutions.
A possible method to ﬁnd a distributed solution of the problem in (7.58) is the alternating direction
method of multipliers (ADMM) [45]. An excellent recent review of ADMM and its applications is [46].
The application of ADMM to distributed estimation problems was proposed in [35]. The method used
in [35] relied on the introduction of the so called bridge nodes. Here, we will describe methods that
do not require the introduction of any special class of nodes (in principle, every node has the same
functionality as any other node). This is useful to simplify the estimation method as well as network
design and management.
The ADMM algorithm applied to solve (7.58) works through the following steps:
θi[k + 1] = arg min
θi

−log pXi;(xi; θi) + λT
i [k](θi −z[k]) + ρ
2 ∥θi −z[k]∥2
2

,
z[k + 1] = arg min
z
N

i=1

λT
i [k](θi[k + 1] −z) + ρ
2 ∥θi[k + 1] −z∥2
2

,
λi[k + 1] = λi[k] + ρ

θi[k + 1] −z[k + 1]

.
(7.59)
The ﬁrst and second steps aim at minimizing the primal function (i.e., the augmented Lagrangian) over
the unknown variables θ and z, for a given value of the Lagrange multipliers’ vectors λi, as computed
in the previous iteration.
The third step is a dual variable update, whose goal is to maximize the dual function, as in the dual
ascent method. We recall that, in our case, the dual function is deﬁned as
g(λ) = infθ,zLρ(θ, λ, z).
(7.60)
In ADMM, the dual ascent step uses a gradient ascent approach to update λ in order to maximize g(λ),
for a given value of vectors θi and z, with the important difference that the step size used to compute
the update is exactly the penalty coefﬁcient ρ.
In our case, the second step can be computed in closed form as follows
θi[k + 1] = arg min
θi

−log pXi;(xi; θi) + λT
i [k](θi −z[k]) + ρ
2 ∥θi −z[k]∥2
2

,
(7.61)
z[k + 1] = 1
N
N

i=1

θi[k + 1] + 1
ρ λi[k]

,
(7.62)
λi[k + 1] = λi[k] + ρ

θi[k + 1] −z[k + 1]

.
(7.63)

2.07.4 Distributed Estimation
355
From this formulation, we can see that the ﬁrst and third steps can be run in parallel, over each node.
The only step that requires an exchange of values among the nodes is the second step that requires the
computation of an average value. But, as we know from previous section, the average value can be com-
puted through a distributed consensus algorithm. The only condition for the convergence of consensus
algorithm to the average value is that the graph representing the links among the nodes is connected.
The step in (7.62) can be further simpliﬁed as follows. Let us denote with ¯x the averaging operation
across the nodes, i.e.,
x := 1
N
N

i=1
xi.
(7.64)
Using this notation, the z-update can be written as
z[k + 1] = θ[k + 1] + 1
ρ λ[k].
(7.65)
Similarly, averaging over the λ-update yields
λ[k + 1] = λ[k] + ρ

θ[k + 1] −z[k + 1]

.
(7.66)
Substituting (7.65) in (7.66), it is easy to check that, after the ﬁrst iteration, λ[k + 1] = 0. Hence, using
z[k] = θ[k], the overall algorithm proceeds as indicated in Table 7.1.
The convergence criterion used in the steps of the algorithm is based on the relative absolute difference
attwosuccessiveiterations:Givenasequence y[k],thealgorithmstopswhen∥y[k+1]−y[k]∥/∥y[k]∥≤
ϵ, with ϵ a small positive value.
Equations 7.67–7.68 give rise to an interesting interpretation: the primal update (ﬁrst equation) aims
at implementing a local optimization, with a penalty related to the disagreement between the local
Table 7.1 Algorithm A.1
A.1
STEP 1: Set k = 0, ϵ equal to a small positive value and initialize θi [0], λi [0], ∀i, and z randomly;
STEP 2: Compute θi [1], ∀i using (7.61);
STEP 3: Run consensus over θi [1] and λi [0] to get θ[1] and λ[0];
STEP 4: Set z[1] = θ[1] + 1
ρ λ[0];
STEP 5: Compute λi [1], ∀i, using (7.63);
STEP 6: Set k = 1;
STEP 7: Repeat until convergence
θi [k + 1] = arg min
θi

−log pXi ;(xi ; θi ) + λT
i [k](θi −θ[k]) + ρ
2 ∥θi −θ[k]∥2
2

(7.67)
Run consensus over θi [k + 1] until convergence;
λi [k + 1] = λi [k] + ρ

θi [k + 1] −θ[k + 1]

(7.68)
Set k = k + 1, if convergence criterion is satisﬁed stop, otherwise go to step 7.

356
CHAPTER 7 Distributed Detection and Estimation
solution and the global one; the dual update (second equation) aims at driving all the local solutions to
converge to a common (consensus) value, which coincides with the globally optimal solution.
The straightforward implementation of (7.67) and (7.68) requires running, at each step k of the
ADMM algorithm, a consensus algorithm. A possible alternative approach can be envisaged by refor-
mulating the optimization problem as follows:
min
θi
⎧
⎨
⎩−
N

i=1
log pXi;(xi; θi) +
N

i=1

j∈Ni
λT
i j(θ j −θi) + ρ
2
N

i=1

j∈Ni
∥θ j −θi∥2
⎫
⎬
⎭
s.t.
θ j = θi; ∀j ∈Ni;
i = 1, 2, . . . , N,
(7.69)
where Ni denotes the set of node i’s neighbors. To make more clear the interaction among the nodes,
it is useful to introduce the graph notation, as in previous section. Using the adjacency matrix A, the
previous problem can be rewritten as follows:
min
θi
⎧
⎨
⎩−
N

i=1
log pXi;(xi; θi) +
N

i=1
N

j=1
ai jλT
i j(θ j −θi) + ρ
2
N

i=1
N

j=1
ai j∥θ j −θi∥2
⎫
⎬
⎭
(7.70)
s.t.
θ j = θi; ∀j ∈Ni;
i = 1, 2, . . . , N.
This formulation does not require the introduction of the instrumental variable z. We keep enforcing the
constraint that all the local estimates θi converge to the same value. However, the penalty is now formu-
lated as the disagreement between the local estimates. From consensus algorithm, we know that nulling
the disagreement is equivalent to forcing all the vectors θi to reach the same value if the graph describing
the interactions among the nodes is connected. Hence, if the network is connected, at convergence, the
disagreementgoestozeroandthereisnobiasresultingfromtheintroductionofthedisagreementpenalty.
The formulation in (7.70) is more amenable for an implementation that does not require, at any step
of the algorithm, the convergence of consensus algorithms. In fact, applying ADMM to the solution of
(7.70) yields the algorithm described in Table 7.2.
Some examples of applications are useful to grasp the main features of these algorithms.
Table 7.2 Algorithm A.2
A.2
STEP 1: Set k = 0, and initialize θi [0], λij [0], ∀i, j ∈N i ;
STEP 2: Repeat until convergence
θi [k + 1] = arg min
θi
⎧
⎨
⎩−
N

i=1
log pXi ;(xi ; θi ) +
N

i=1
N

j=1
aij λT
ij [k](θj [k] −θi )
+ ρ
2
N

i=1
N

j=1
aij ∥θj [k] −θi ∥2
⎫
⎬
⎭
(7.71)
λij [k + 1] = λij [k] + ρaij

θj [k + 1] −θi [k + 1]

(7.72)
Set k = k + 1, if convergence criterion is satisﬁed stop, otherwise go to step 2.

2.07.4 Distributed Estimation
357
2.07.4.1.2
Distributed ML estimation under Gaussian noise
Let us consider the common situation where the measured vector xi ∈RQ is related to the parameter
vector θ ∈RM, with Q ≥M, through a linear observation model, as:
xi = Aiθ + vi,
i = 1, . . . , N
(7.73)
where Ai ∈RQ×M and vi is a vector of jointly Gaussian random variables with zero mean and covariance
matrix Ci, i.e., vi ∼N(0, Ci).
In such a case, algorithm A.1 in (7.67) simpliﬁes as the ﬁrst step of (7.67) can be expressed in closed
form
θi[k + 1] =

AT
i C−1
i
Ai + ρ I
−1 
AT
i C−1
i
xi −λi[k] + ρθ[k]

,
λi[k + 1] = λi[k] + ρ

θi[k + 1] −θ[k + 1]

.
(7.74)
The two updates can be computed in parallel by all the nodes, after having computed the average values
through the consensus algorithm.
Alternatively, algorithm A.2 becomes
θi[k + 1] =
⎛
⎝AT
i C−1
i
Ai + 2ρ
N

j=1
ai j I
⎞
⎠
−1
×
⎛
⎝AT
i C−1
i
xi +
N

j=1
ai j(λi j[k] −λ ji[k]) + 2ρ
N

j=1
ai jθ j[k]
⎞
⎠,
λi j[k + 1] = λi j[k] + ρai j

θ j[k + 1] −θi[k + 1]

.
(7.75)
In this case, there is no need of running the consensus algorithm for every iteration. Some numerical
results are useful to compare the methods. As an example, we considered a connected network composed
of N = 10 sensors. We set ρ = 30 and assumed an observation vector of size Q = 30. In Figure 7.6
we report the estimates ˆθi,l, for l = 1, 2, versus the iteration index m, for the two algorithms A.1 (left
plot) and A.2 (right plot). The iteration index m includes also the iterations necessary for the consensus
algorithm to converge within a prescribed accuracy (in this case, we stopped the consensus algorithm as
soon as the absolute difference between two consecutive updates is below of 10−2 for all the nodes). In
both ﬁgures, we report, as a benchmark, the maximum likelihood estimate (horizontal x-marked line)
achievable by a centralized node that knows all the observation vectors and all the model parameters,
i.e., Ai, Ci, ∀i. From Figure 7.6, we can see that the estimates obtained with both methods converge to
the optimal ML estimates.
In the speciﬁc case where the observation model is as in (7.73), with additive Gaussian noise, and
the noise vectors pertaining to different sensors are mutually uncorrelated, the globally optimal ML
estimate is
ˆθ ML =
	 N

i=1
AT
i C−1
i
Ai
−1 	 N

i=1
AT
i C−1
i
xi

.
(7.76)

358
CHAPTER 7 Distributed Detection and Estimation
0
50
100
150
200
2
3
4
5
6
7
8
m
ˆθ
ˆθil[m]
0
50
100
150
200
2
3
4
5
6
7
8
m
il[m]
(a)
(b)
FIGURE 7.6
Per node parameter estimation versus the iteration index m using algorithms A.1 (left) and A.2 (right).
Table 7.3 Algorithm A.3
A.3
STEP 1: Set k = 0, and initialize θi [0] =

AT
i C−1
i
Ai
−1 
AT
i C−1
i
xi

;
STEP 2: Repeat until convergence
θi [k + 1] = θi [k] + ϵ

AT
i C−1
i
Ai
−1 N

j=1
aij

θj [k] −θi [k]

(7.77)
Set k = k + 1, if convergence criterion is satisﬁed stop, otherwise go to step 2.
This formula is a vector weighted sum of the observations. Recalling that consensus algorithms, if
properly initialized, can be made to converge to a weighted sum of the initial states, we can use the
consensus algorithm directly to compute the globally optimal ML estimate through a totally distributed
mechanism. In particular, in this case, the consensus algorithm proceeds as in Table 7.3.
Using again the basic properties of consensus algorithm, if the graph is connected and the step size
ϵ is sufﬁciently small, the iterations in 7.77 converge to the globally optimal estimate (7.76).
2.07.4.1.3
Distributed Bayesian estimation under Gaussian noise and
Laplacian prior
Let us consider now the case where the parameter vector is a random vector with known prior probability
density function. Following a Bayesian approach, as in (7.50), the practical difference is that in such

2.07.4 Distributed Estimation
359
a case the objective function must include a term depending on the prior probability. Let us consider,
for instance, the interesting case where the observation is Gaussian, as in the previous example, and the
prior pdf is Laplacian, i.e.,
p(θ) = μ exp (−μ∥θ∥1)
(7.78)
with μ > 0, where ∥x∥1 denotes the l1 norm of vector x. In this case, the problem to be solved is the
following
min
θ
! N

i=1
∥xi −Aiθ∥2
C−1
i
+ μ∥θ∥1
"
,
(7.79)
where ∥x∥2
A denotes the weighted l2 norm of x, i.e., ∥x∥2
A := xT Ax
2
.
Interestingly, this formulation coincides with the formulation resulting from having no prior pdf, but
incorporating an l1 norm in order to drive the solution towards a sparse vector. This is the so called
least-absolute shrinkage and selection operator (lasso) method [47]. A distributed algorithm to solve
a linear regression problem with sparsity constraint was proposed in [48]. Here we provide a similar
approach, with the important difference that, in each iteration, the update is computed in closed form.
A decentralized solution can be found by reformulating the problem as follows
min
θi
! N

i=1
∥xi −Aiθi∥2
C−1
i
+ ρ
2
N

i=1
∥θi −z∥2 + μ∥z∥1
"
,
s.t.
θi = z,
i = 1, . . . , N.
(7.80)
Using the ADMM approach, the algorithm proceeds through the following updates
θi[k + 1] =

AT
i C−1
i
Ai + ρ I
−1 
AT
i C−1
i
xi −λi[k] + ρz[k]

,
z[k + 1] = arg min
z
!
μ∥z∥1 + ρ
2
N

i=1
∥θi[k + 1] −z∥2 +
N

i=1
λT
i (θi[k + 1] −z)
"
λi[k + 1] = λi[k] + ρ

θi[k + 1] −z[k + 1]

.
(7.81)
The second equation can also be expressed in closed form. Moreover, deﬁning the vector threshold
function tμ(x) as the vector whose entries are obtained by applying the scalar thresholding function
tμ(x) to each element of vector x, where
tμ(x) =
⎧
⎨
⎩
x −μ,
x > μ
0,
−μ ≤x ≤μ
x + μ,
x < −μ
(7.82)
the overall algorithm is as in Table 7.4.
As a numerical example, in Figure 7.7 we report the behavior of the estimated variable obtained using
Algorithm A.4 versus the iteration index m, which includes the convergence times of two consensus
algorithms in the equation 7.84.

360
CHAPTER 7 Distributed Detection and Estimation
Table 7.4 Algorithm A.4
A.4
STEP 1: Set k = 0, and initialize θi [0], λi [0], ∀i, and z[0] randomly;
STEP 2: Repeat until convergence
θi [k + 1] =

AT
i C−1
i
Ai + ρI
−1 
AT
i C−1
i
xi −λi [k] + ρz [k]

(7.83)
Run consensus over θi [k + 1] and λi [k] to get θ[k + 1] and λ[k] until ϵ-convergence;
z [k + 1] =
1
ρN tμ

Nλ[k] + ρNθ[k + 1]

(7.84)
λi [k + 1] = λi [k] + ρ

θi [k + 1] −z[k + 1]

(7.85)
Set k = k + 1, if convergence criterion is satisﬁed stop, otherwise go to step 2.
0
50
100
150
200
250
300
350
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
m
µ = 10, ρ= 10
ˆθil[m]
FIGURE 7.7
Per node estimated variable versus the iteration index m for distributed Bayesian estimation using the ADMM
approach.
The example refers to a network of N = 10 nodes, using ρ = μ = 10. The horizontal x-marked line
represents the centralized optimal solution. The parameter vector of this example has two components,
one of which has been set to zero to test the capability to recover the sparsity. We can notice from
Figure 7.7 that, as expected, the algorithm converges to the globally optimal values.

2.07.4 Distributed Estimation
361
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0.3
0.32
0.34
0.36
0.38
0.4
0.42
0.44
η
E[|| ˆθ−θ||2]
ρ = 20
µ = 0, ˆθML
µ = 0
µ = 0.5
µ = 0.8
µ = 1
FIGURE 7.8
Mean square estimation error versus the fraction η of null entries, for different μ values.
To show the impact of the penalty coefﬁcient μ on the sparsity of the estimated vector, in Figure 7.8 we
have reported the average mean square estimation error versus the coefﬁcient η, deﬁned as the fraction of
zeros entries in the vector θ to be estimated, for different values of μ. It can be noted from Figure 7.8 that
for μ = 0 the optimal solution is independent by η and it coincides with the optimal (centralized) ML
solution. Furthermore, we can observe that, as μ and η increase, the average estimation error decreases
thanks to the recovering sparsity property of the ADMM approach with the lasso constraint.
2.07.4.1.4
Distributed recursive least square estimation with sparsity constraint
In some applications, the parameters to be estimated may be changing over time. In these cases, it is more
advisable to adopt recursive procedure rather than the batch approach followed until now. We show now
how to obtain a distributed recursive least square (RLS) estimation incorporating a sparsity constraint.
Let us assume a linear observation model
xi(l) = Ai(l)θ + vi(l),
(7.86)
where xi(l) denotes the observation taken by node i at time l, Ai(l) is a known, possibly time-
varying, mixing matrix and vi(l) is the observation noise, supposed to have zero mean and covariance
matrix Ci(l).

362
CHAPTER 7 Distributed Detection and Estimation
In RLS estimation with a sparsity constraint, the goal is to ﬁnd the parameter vector θ, at each time
instant n, that minimizes the following objective function
N

i=1
n

l=1
βn−l∥xi(l) −Ai(l)θ∥2
C−1
i
(l) + μ∥θ∥1,
(7.87)
where 0 < β ≤1 is a forgetting factor used to weight more the most recent observations with respect
to the older ones. The coefﬁcient μ weights the importance of the sparsity constraint.
Proceeding as in the previous examples, a distributed solution can be found by formulating the
problem, at each time n, as a constrained problem incorporating an instrumental variable z to force all
the nodes to converge to a common estimate. The problem can be made explicit as
min
θi
N

i=1
n

l=1
βn−l∥xi(l) −Ai(l)θi∥2
C−1
i
(l) + ρ
2
N

i=1
∥θi −z∥2 + μ∥z∥1,
s.t.
θi = z,
i = 1, . . . , N.
(7.88)
Again, the solution can be achieved by applying ADMM and the result is given by the algorithm
described in Table 7.5
As before, the only step requiring the interaction among the nodes is a consensus algorithm to be
run to compute the averages appearing in equation 7.89.
To test the convergence of Algorithm A.5, we considered a possible application to cooperative sensing
for cognitive radio. We assumed the presence of a macro base station transmitting using a multicarrier
scheme. We considered for simplicity of representation four channels, but the method can be easily
extended to a larger number of channels. The sensing nodes aim to recover the activity of the macro
transmitter, represented by a vector θ composed of four entries, one for each channel. To improve the
accuracy of the local estimation, the sensors cooperate with each other by running Algorithm A.5. At
some time, the activity level switches from on to off or viceversa. As an example, in Figure 7.9 we report
Table 7.5 Algorithm A.5
A.5
STEP 1: Set n = 0 and k = 0, and initialize θi [0, 0], λi [0, 0], ∀i, and z [0, 0] randomly;
STEP 2: Repeat until convergence over index k
θi [k + 1, n] =
⎛
⎝
n

l=1
βn−l AT
i (l)C−1
i
(l)Ai (l) + ρI
⎞
⎠
−1⎛
⎝
n

l=1
βn−l AT
i (l)C−1
i
(l)xi (l) −λi [k, n] + ρz [k, n]
⎞
⎠
Run consensus over θi [k + 1, n] and λi [k, n] to get θ[k + 1, n] and λ[k, n] until convergence;
z [k + 1, n] =
1
ρN tμ

Nλ[k, n] + ρNθ[k + 1, n]

(7.89)
λi [k + 1, n] = λi [k, n] + ρ

θi [k + 1, n] −z[k + 1, n]

Set k = k + 1, if convergence criterion is satisﬁed set n =n + 1 and go to step 2, otherwise go to step 2.

2.07.4 Distributed Estimation
363
0
10
20
30
40
50
60
70
80
90
100
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
n
ˆθ1[n]
0
10
20
30
40
50
60
70
80
90
100
−0.5
0
0.5
1
1.5
2
2.5
3
3.5
n
ˆθ2[n]
0
10
20
30
40
50
60
70
80
90
100
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
1.4
1.6
n
ˆθ3[n]
µ = 0
µ = 40
θ2
µ = 0
µ = 40
θ3
µ = 0
µ = 40
θ1
0
10
20
30
40
50
60
70
80
90
100
−0.5
0
0.5
1
1.5
2
2.5
n
ˆθ4[n]
µ = 0
µ = 40
θ4
FIGURE 7.9
Estimated parameters versus the number of current observations n for the RLS algorithm, assuming N = 10,
β = 0.6, and ρ = 40.
the four parameters to be estimated, indicated by the unmarked lines. At time n = 50, the parameters
switch to test the tracking capability of the proposed method.
In Figure 7.9 we draw also the estimated parameters ˆθl for l = 1, . . . , 4 versus the current observation
index n. We used β = 0.6, ρ = 40 and two values of the sparsity coefﬁcient: μ = 0 and μ = 40. We can
notice from Figure 7.9 that the method is able to track the true parameters. It is also interesting to see
that, as the penalty coefﬁcient μ increases, the zero coefﬁcients are estimated with greater accuracy.
Conversely, the positive coefﬁcients are recovered with a slightly larger bias.
To evaluate the impact of the forgetting factor β on the accuracy and tracking capability of the
distributed RLS method, in Figure 7.10 we reported the estimated parameters. using β = 0.6 and
β = 0.9, having set ρ = μ = 40. It can be noted that, as β increases, the larger memory of the
ﬁlter yields more accurate estimates. At the same time, having a larger memory implies slower time to
reaction to the parameter switch, as evidenced in Figure 7.10.

364
CHAPTER 7 Distributed Detection and Estimation
0
10
20
30
40
50
60
70
80
90
100
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
N = 10
n
ˆθ1[n]
β = 0 .6
β = 0 .9
θ1
0
10
20
30
40
50
60
70
80
90
100
−1
0
1
2
3
4
N = 10
n
ˆθ2[n]
β = 0 .6
β = 0 .9
θ2
FIGURE 7.10
Parameter estimation versus the number of observations n of the recursive least square estimation using the
ADMM approach, considering N = 10 and two different values of β.
For any given forgetting factor β, the only possibility to improve the estimation accuracy is to
have more nodes sensing a common macro base station. As an example, in Figure 7.11 we report the
behavior of the estimates obtained with different number of nodes, for a forgetting factor β = 0.6.
We can notice that, as expected, increasing the number of nodes, the estimation accuracy increases as
well. This reveals a trade-off between forgetting factor (time memory) and number of nodes involved
in cooperative sensing.
2.07.4.1.5
Distributed parameter estimation in spatially correlated observations
So far, we have analyzed the case of conditionally independent observations. Let us consider now the
case where the observation noise is spatially correlated. More speciﬁcally, we assume here the following
observation model, for each sensor
xi = θ + vi,
i = 1, . . . , N,
(7.90)
where the noise variables vi are jointly Gaussian with zero mean and covariance matrix C, or preci-
sion matrix A = C−1. Furthermore, we assume that v is a Gaussian Markov random ﬁeld, so that the
precision matrix is typically a sparse matrix. The joint pdf of the observation vector can then be written

2.07.4 Distributed Estimation
365
0
10
20
30
40
50
60
70
80
90
100
−0.2
0
0.2
0.4
0.6
0.8
1
1.2
ρ = 40, β = 0 .6
n
ˆθ1[n]
N = 10
N = 80
θ1
0
10
20
30
40
50
60
70
80
90
100
−1
0
1
2
3
4
ρ = 40, β = 0 .6
n
ˆθ2[n]
N = 10
N = 80
θ2
FIGURE 7.11
Parameter estimation versus the number of observations n of the recursive least square estimation using the
ADMM approach, β = 0.6, μ = 40, and two different values of N.
as in (7.17), i.e.,
p(x; θ) =

|A|
(2π)N exp
#
−1
2(x −θ1)T A(x −θ1)
$
:=

|A|
(2π)N exp

−V (x)

,
(7.91)
where V (x) can be rewritten as follows
V (x) =
N

i=1
φi(xi; θ)
(7.92)
with xi = [xi, {x} j∈Ni, j>i]T , and
φi(xi; θ) := 1
2aii(xi −θ)2 +

j∈Ni, j>i
ai j(x j −θ)(xi −θ).
(7.93)

366
CHAPTER 7 Distributed Detection and Estimation
As in the previous cases, also here a decentralized solution can be reached by formulating the problem
as the minimization of the augmented Lagrangian
Lρ(θ, λ, z) :=
N

i=1

φi(xi; θ) + λi(θi −z) + ρ
2 (θi −z)2
,
(7.94)
subject to θi = z. Applying the ADMM algorithm to this case, we get the following algorithm
θi[k + 1] = arg min
θ

φi(xi; θi) + λi(θi −z) + ρ
2

θi −z
2
,
(7.95)
z[k + 1] = 1
N
N

i=1

θi[k + 1] + 1
ρ λi[k]

,
λi[k + 1] = λi[k] + ρ

θi[k + 1] −z[k + 1]

.
It is important to notice that, in this case, even if the global problem concerning the minimization of
the augmented Lagrangian in (7.94) is certainly convex, the local problem in (7.95) is not necessarily
convex because there is no guarantee that the term φi(xi; θ) is a positive deﬁnite function. Nevertheless,
the quadratic penalty present in (7.95) can make every local problem in (7.95) convex. At the same time,
at convergence the penalty goes to zero and thus it does not induce any undesired bias on the ﬁnal result.
The ﬁrst step in (7.95) can be made explicit, so that the algorithm assumes the form described in
Table 7.6.
As an example, in Figure 7.12 we report the estimation versus the cumulative iteration index m that
includes the consensus steps and the iterations over k. The results refer to a connected network with
N = 5 nodes; ρ has been chosen equal to 10 to guarantee that every local problem is convex. It can
be noticed from Figure 7.12 that the distributed solution converges to the optimal centralized solution
(horizontal x-marked line).
Table 7.6 Algorithm A.6
A.6
STEP 1: Set k = 0, and initialize θi [0], λi [0], ∀i, and z [0] randomly;
STEP 2: Repeat until convergence
θi [k + 1] =
1
aii + ρ + 2 
j∈Ni ,j>i aij
⎛
⎝ρz [k] −λi [k] + aii xi +

j∈Ni ,j>i
aij (xi + xj )
⎞
⎠
(7.96)
Run consensus over θi [k + 1] and λi [k] to get θ[k + 1] and λ[k] until ϵ−convergence;
z [k + 1] = θ[k + 1] + 1
ρ λ[k]
(7.97)
λi [k + 1] = λi [k] + ρ

θi [k + 1] −z [k + 1]

(7.98)
Set k = k + 1, if convergence criterion is satisﬁed stop, otherwise go to step 2.

2.07.4 Distributed Estimation
367
0
50
100
150
200
250
300
350
400
450
500
−100
−80
−60
−40
−20
0
20
m
ˆθi[m]
N = 5, ρ= 10
FIGURE 7.12
Per node parameter estimation versus the iteration index m for spatially correlated observations using the
ADMM approach.
2.07.4.2 Decentralized observations with centralized estimation
In many cases, the observations are gathered in distributed form, through sensors deployed over a certain
area, but the decision (either estimation or detection) is carried out in a central fusion center. In this
section, we review some of the problems related to distributed estimation, with centralized decision.
In such a case, the measurements gathered by the sensors are sent to a fusion center through rate-
constrained physical channels. The question is how to design the quantization step in each sensor in
order to optimize some performance metric related to the estimation of the parameter of interest. Let us
start with an example, to introduce the basic issues.
Letusconsideranetworkof N sensors,eachobservingavalue xk containingadeterministicparameter
θ, corrupted by additive noise vk, i.e.,
xk = θ + vk,
k = 1, . . . , N.
(7.99)
The noise variables vk are supposed to be zero mean spatially uncorrelated random variables with
variance σ 2
k . Suppose that the sensors transmit their observations via some orthogonal multiple access
scheme to a control center which wishes to estimate the unknown signal θ by minimizing the estimation
mean square error (MSE) E[( ˆθ −θ)2]. In the ideal case, where the observations are unquantized and
received by the control center without distortion, the best linear unbiased estimator (BLUE) can be

368
CHAPTER 7 Distributed Detection and Estimation
performed by the control center and the estimate ˆθ is given by
ˆθ =
	 N

k=1
1
σ 2
k
−1
N

k=1
xk
σ 2
k
(7.100)
with MSE given by E[( ˆθ −θ)2] =
N
k=1
1
σ 2
k
−1
. This estimator coincides with the maximum
likelihood estimator when the noise variables are jointly Gaussian and uncorrelated.
Let us consider now the realistic case, where each sensor quantizes the observation xk to generate a
discrete message mk of nk bits. Assuming an error-free transmission, the fusion center must then pro-
vide an estimate ˆθ of the true parameter, based on the messages mk transmitted by all the nodes. More
speciﬁcally, assuming a uniform quantizer which generates unbiased message functions, the estimator
at the control center performs a linear combination of the received messages. Let us suppose that the
unknown signal to be estimated belongs to the range [−A, A] and each sensor uniformly divides the
range [−A, A] into 2nk intervals of length Wk = 2A/2nk rounding xk to the midpoint of these intervals.
In this case, the quantized value mk at the kth sensor can be written as mk = θ + vk + wk, where the
quantization noise wk is independent of vk. It can be proved that mk is an unbiased estimator of θ with
Var{mk} ≤δ2
k + σ 2
k ,
(7.101)
where δ2
k denotes an upper bound on the quantization noise variance and is given by
δ2
k = W 2
k
12 =
A2
3 · 22nk .
(7.102)
A linear unbiased estimator of θ is [49]
ˆθ =
	 N

k=1
1
σ 2
k + δ2
k
−1
N

k=1
mk
σ 2
k + δ2
k
.
(7.103)
This estimate yields an MSE upper bound
E
#
ˆθ −θ
2$
≤
	 N

k=1
1
σ 2
k + δ2
k
−1
.
(7.104)
As mentioned before, the previous strategy assumes that there are no transmission errors. This property
can be made as close as possible to reality by enforcing the transmission rate of sensor k to be strictly
less than the channel capacity from sensor k to the fusion center. If we denote by pk the transmit power
of sensor k, hk the channel coefﬁcient between sensor k and control node and N0 is the noise variance at
the control node receiver, the bound on transmit rate guaranteeing an arbitrarily small error probability is
nk ≤1
2 log
	
1 + pkh2
k
N0

.
(7.105)
The problem is then how to allocate power and bits over each channel in order to fulﬁll some optimality
criterion dictated by the estimation problem. This problem was tackled in [49] where it was proposed the

2.07.4 Distributed Estimation
369
minimization of the Euclidean norm of the transmit power vector under the constraint that the estimation
variance is upper bounded by a given quantity and that the number of bits per symbol is less than the
channel capacity. Here we formulate the problem as the minimization of the total transmit power under
the constraint that the ﬁnal MSE be upper bounded by a given quantity ϵ > 0. From (7.105), deﬁning
ak = h2
k
N0 , we can derive the number of quantization level as a function of the transmit power,6
22nk =

1 + pkak

.
(7.106)
Our aim is to minimize the sum of powers transmitted by all the sensors under the constraint
	 N

k=1
1
σ 2
k + δ2
k
−1
≤ϵ.
(7.107)
Denoting with p = [p1, . . . , pN] the power vector, the optimization problem can be formulated as
min
p
N

k=1
pk
s.t.
N

k=1
1
σ 2
k +
A2
3·22nk
≥1
ϵ
(7.108)
p ≥0,
wherenk isafunctionof pk,asin(7.105).Inpractice,thevaluesnk areinteger.However,searchingforthe
optimal integer values nk leads to an integer programming problem. To relax the problem, we assume that
thevariables nk arereal. Then,byusing(7.106),theoptimizationproblemin(7.108)canbeformulatedas
min
p
N

k=1
pk
s.t.
N

k=1
1
σ 2
k +
A2
3(1+pkak)
≥1
ϵ
(P).
(7.109)
p ≥0
Problem (P) is indeed a convex optimization problem and it is feasible if N
k=1
1
σ 2
k > 1
ϵ .
The optimal solution of the convex problem (P) can be found by imposing the KKT conditions of
(P), i.e.,
1 −μk −λ
3A2ak
[3σ 2
k (1 + pkak) + A2]2 = 0 ∀k = 1, . . . , N
0 ≤λ ⊥
N

k=1
3(1 + pkak)
3σ 2
k (1 + pkak) + A2 −1
ϵ ≥0
(7.110)
6We neglect here the discretization of nk, to simplify the problem and arrive at closed form expressions.

370
CHAPTER 7 Distributed Detection and Estimation
0 ≤μk ⊥pk ≥0 ∀k = 1, . . . , N
where λ and μk denote the Lagrangian multipliers associated to the N + 1 constraints. The solution for
the optimal powers turns out to be
p∗
k =
⎡
⎣1
σ 2
k

λA2
3ak
−1
ak
−
A2
3akσ 2
k
⎤
⎦
+
,
(7.111)
where (x)+ = max (0, x) and λ > 0 is found by imposing the MSE constraint to be valid with equality.
It is now useful to present some numerical results. To guarantee the existence of a solution, we set
the bound ϵ = βϵmin with β > 1 and ϵmin =
N
k=1
1
σ 2
k
−1
. In Figure 7.13 we report the sum of the
optimal transmit powers vs. β, for different SNR values. The number of sensors is N = 20. We can
notice that the minimum transmit power increases for smaller values of β, i.e., when we require the
realistic system to perform closer and closer to the ideal communication case.
In the bottom subplot of Figure 7.14 we report an example of optimal power allocation obtained by
solving the optimization problem (P), corresponding to the channel realization shown in the top subplot,
assuming a constant observation noise variance σ 2
k = 0.01. We can observe that the solution is that only
1
1.5
2
2.5
3
3.5
4
4.5
5
10 1
10 2
10 3
10 4
10 5
10 6
10 7
N= 20
β
Sum of optimal powers
SNR = 7[dB]
SNR = 17[dB]
SNR = 27[dB]
SNR = 37[dB]
FIGURE 7.13
Sum of the optimal powers for problem (P) versus β for several values of σ 2
k .

2.07.5 Distributed Detection
371
0
2
4
6
8
10
12
14
16
18
20
0
0.5
1
1.5
2
2.5
3
|hk|2
sensors
N = 20, β = 3,σ 2k = 10−2
0
2
4
6
8
10
12
14
16
18
20
0
500
1000
1500
2000
p ∗k
sensors
FIGURE 7.14
Optimal power allocation of the sensors for problem (P), ﬁxing the per-node observation noise variance.
the nodes with the best channels coefﬁcients are allowed to transmit. Finally, in Figure 7.15 we plot the
sum of the optimal transmit powers versus the number of sensors N, for different values of β. We can see
that, as N increases, a lower power is necessary to achieve the desired estimation variance, as expected.
2.07.5 Distributed detection
The distributed detection problem is in general more difﬁcult to handle than the estimation problem.
There is an extensive literature on distributed detection problem, but there is still a number of open
problems. According to decision theory, an ideal centralized detector having error-free access to all the
measurements collected by a set of nodes, should form the likelihood ratio and compare it with a suitable
threshold [5]. Denoting with H0 and H1 the two alternative hypotheses, i.e., absence or presence of
the event of interest, and with p(x1, . . . , xN; Hi) the joint probability density function of the whole
set of observed data, under the hypothesis Hi, many decision tests can be cast as threshold strategies
where the likelihood ratio (LR) is compared with a threshold γ , which depends on the decision crite-
rion. This is true, for example, for two important formulations leading to the Bayes approach and to the

372
CHAPTER 7 Distributed Detection and Estimation
10
1
10
2
101
10
2
103
104
N
Optimal power
β = 1.1
β = 1.3
β = 1.6
β = 2
FIGURE 7.15
Sum of optimal powers versus N for several values of β.
Neyman-Pearson criterion, the only difference between the two’s being the values assumed by the thresh-
old γ . The detection rule decides for H1 if the threshold is exceeded or for H0, otherwise. In formulas,
(x) := (x1, . . . , xN) = p(x1, . . . , xN; H1)
p(x1, . . . , xN; H0)
H1
⋛
H0
γ.
(7.112)
Ideally, with no communication constraints, every node should then send its observation vector xi, with
i = 1, . . . , N to the fusion center, which should then use all the received vectors to implement the LR
test, asin(7.112).Inreality,thereareintrinsiclimitationsdueto,namely:(a)theﬁnitenumberofbitswith
which every sensor has to encode the measurements before transmission; (b) the maximum latency with
which the decision has to be taken; (c) the ﬁnite capacity of the channel between sensors and fusion cen-
ter. The challenging problem is then how to devise an optimum decentralized detection strategy taking
into account the limitations imposed by the communication over realistic channels. The global problem,
in the most general setting, is still an open problem, but there are many works in the literature addressing
some speciﬁc cases. The interested reader may check the book [50] or the excellent tutorial reviews given
in [51–53]. The situation becomes more complicated when we take explicitly into account the capacity
bound imposed by the communication channel and we look for the number of bits to be used to quantize
the local observations before transmitting to the fusion center. This problem was addressed in [54,55],
where it was shown that binary quantization is optimal for the problem of detecting deterministic signals
in Gaussian noise and for detecting signals in Gaussian noise using a square-law detector. The interesting

2.07.5 Distributed Detection
373
indication, in these contexts, is that the gain offered by having more sensor nodes outperforms the bene-
ﬁts of getting more detailed (nonbinary) information from each sensor. A general framework to cast the
problem of decentralized detection is the one where the topology describing the exchange of information
among sensing nodes is not simply a tree, with all nodes sending data to a fusion center, but it is a graph.
Each node is assumed to transmit a ﬁnite-alphabet symbol to its neighbors and the problem is how to
ﬁnd out the encoding (quantization) rule on each node. A class of problems admitting a message passing
algorithm with provable convergence properties was proposed in [10]. The solution is a sort of distributed
fusion protocol, taking explicitly into account the limits on the communication resources. An interesting
and well motivated observation model is a correlated random ﬁeld, as in many applications the obser-
vations concern physical quantities, like temperature or pressure, for example, which being subject to
diffusion processes, are going to be spatially and temporally correlated. One of the ﬁrst works addressing
the detection of a known signal embedded in a correlated Gaussian noise was [56]. Using large deviations
theory, the authors of [57] study the impact of node density, assuming that observations become increas-
ingly correlated as sensors are in closer proximity of each other. More recently, the detection of a Gauss-
Markov Random ﬁeld (GMRF) with nearest-neighbor dependency was studied in [8]. Scaling laws for
the energy consumption of optimal and sub-optimal fusion policies were then presented in [9]. The prob-
lem of energy-efﬁcient routing of sensor observations from a Markov random ﬁeld was analyzed in [58].
A classiﬁcation of the various detection algorithms depends on the adopted criterion. A ﬁrst important
classiﬁcation is the following:
1. Global decision is taken at the fusion center
a. Nodes send data to FC; FC takes global decision
b. Nodes send local decisions to FC; FC fuses local decisions
2. Every node is able to take a global decision
a. Nodes exchange data with their neighbors
b. Nodes exchange local decisions with their neighbors.
In the ﬁrst case, the observation is distributed across the nodes, but the decision is centralized. This case
has received most of the attention. The interested reader may check, for example, the book [50] or the
tutorial reviews given in [51–53]. In the second case, also the decision is decentralized. This case has
been considered only relatively recently. Some references are, for example, [59–65].
An alternative classiﬁcation is between
1. Batch algorithms
2. Sequential algorithms.
In the ﬁrst case, the network collects a given amount of data along the time and space domains and then
it takes a decision. In the second case, the number of observations, either in time or in terms of number
of involved sensors, is not decided a priori, but it is updated at every new measurement. The network
stops collecting information only when some performance criterion is satisﬁed (typically, false alarm
and detection probability) [66–68].
One of the major difﬁculties in distributed detection comes from establishing the optimal decision
thresholds at local and global level. The main problem is how to optimize the local decisions, taking into

374
CHAPTER 7 Distributed Detection and Estimation
account that the ﬁnal decisions will be only the result of the interaction among the nodes. Taking a local
decision can be interpreted as a form of source coding. The simple (binary) hypothesis testing can be
seen in fact as a form of binary coding. Whenever the observations are conditionally independent, given
each hypothesis, the likelihood ratio test at the sensor nodes is indeed optimal [69]. However, ﬁnding the
optimal quantization levels is a difﬁcult task. Even when the observations are i.i.d., assuming identical
decision rules is very common and apparently well justiﬁed. Nevertheless there are counterexamples
showing that nonidentical decision rules are optimal [69]. Identical decision rules in the i.i.d. case turns
out to be optimal only asymptotically, as the number of nodes tends to inﬁnity [70].
A simple example may be useful to grasp some of the difﬁculties associated with distributed detection.
For this purpose, we brieﬂy recall the seminal work of Tenney and Sandell [71]. Let us consider two
sensors, each measuring a real quantity xi, with i = 1, 2. Based on its observation xi, sensor i decides
whether the phenomenon of interest is present or not. In the ﬁrst case, it sets the decision variable ui = 1,
otherwise, it sets ui = 0. The question is how to implement the decision strategy, according to some
optimality criterion. The approach proposed in [71] is a Bayesian approach, where the goal of each
sensor is to minimize the Bayes risk, which can be made explicit by introducing the cost coefﬁcients
and the observation probability model. Let us denote by Ci jk the cost of detector 1 deciding on Hi,
detector 2 deciding on H j, when the true hypothesis is Hk. Denoting by Pk the prior probability of event
Hk and by p(u1, u2, x1, x2, Hk) the joint pdf of having Hk, observing the pair (x1, x2) and deciding
for the pair (u1, u2), the average risk can be written as
R =

i, j,k
)
Ci jk p(u1, u2, x1, x2, Hk) dx1dx2
=

i, j,k
Pk
)
Ci jk p(u1, u2, x1, x2/Hk) dx1dx2
=

i, j,k
Pk
)
Ci jk p(u1, u2/x1, x2, Hk)p(x1, x2/Hk) dx1dx2.
(7.113)
In this case, each node observes only its own variable and takes a decision independently of the other
node. Hence, we can set
R =

i, j,k
Pk
)
Ci jk p(u1/x1)p(u2/x2)p(x1, x2/Hk) dx1dx2.
(7.114)
Expanding the right hand side by explicitly summing over index i, we get
R =

j,k
Pk
)
p(u2/x2)p(x1, x2/Hk)[C0 jk p(u1 = 0/x1) + C1 jk p(u1 = 1/x1)] dx1dx2.
(7.115)
Considering that p(u1 = 1/x1) = 1 −p(u1 = 0/x1) and ignoring all terms which do not contain u1,
we get
R =
)
p(u1 = 0/x1)

j,k
Pk
*)
p(u2/x2)p(x1, x2/Hk)[C0 jk −C1 jk] dx2
+
dx1 + const.
(7.116)

2.07.5 Distributed Detection
375
The average risk is minimized if p(u1 = 0/x1) is chosen as follows
p(u1 = 0/x1) =
*0,
if

j,k Pk
,
p(u2/x2)p(x1, x2/Hk)[C0 jk −C1 jk]dx2 ≥0
1,
otherwise.
(7.117)
This expression shows that the optimal local decision rule is a deterministic rule. After a few algebraic
manipulations, (7.117) can be rewritten, equivalently, as [50]
(x1) := p(x1/H1)
p(x1/H0)
H1
⋛
H0
P0

j
,
p(u2/x2)p(x2/x1, H0)[C1 j0 −C0 j0] dx2
P1

j
,
p(u2/x2)p(x2/x1, H1)[C0 j1 −C1 j1] dx2
,
(7.118)
where (x1) is the LR at node 1. Eq. (7.118) has the structure of a LRT. However, note that the threshold
on the right hand side of (7.118) depends on the observation x1, through the term p(x2/x1/H1), which
incorporates the statistical dependency between the observations x1 and x2. Hence, Eq. (7.118) is not a
proper LRT.
The situation simpliﬁes if the observations are conditionally independent, i.e., p(x2/x1/Hk) =
p(x2/H1). In such a case, the threshold t1 can be simpliﬁed into
t1 = P0
,
p(x2/H0){p(u2 = 0/x2)[C100 −C000] + p(u2 = 1/x2)[C110 −C010]}dx2
P1
,
p(x2/H1){p(u2 = 0/x2)[C001 −C101] + p(u2 = 1/x2)[C011 −C111]}dx2
.
(7.119)
Since p(u2 = 1/x2) = 1 −p(u2 = 0/x2), (7.119) can be rewritten as
t1 = P0
,
p(x2/H0){[C110 −C010] + p(u2 = 0/x2)[C100 −C000 + C010 −C110]}dx2
P1
,
p(x2/H1){[C011 −C111] + p(u2 = 0/x2)[C001 −C101 + C111 −C011]}dx2
.
(7.120)
Hence, the threshold t1 to be used at node 1 is a function of p(u2 = 0/x2), i.e., on the decision taken by
node 2. At the same time, the threshold t2 to be used by node 2 will depend on the decision rule followed
by node 1. This means that, even if the observations are conditionally independent and the decisions are
taken autonomously by the two nodes, the decisions are still coupled through the thresholds. This simple
example shows how the detection problem can be rather complicated, even under a very simple setting.
InthespecialcasewhereC000 = C111 = 0,C010 = C100 = C011 = C101 = 1,andC110 = C001 = 2,
i.e., there is no penalty if the decisions are correct, the penalty is 1, when there is one error, and the
penalty is 2 when there are two errors, the threshold simpliﬁes into
t1 = P0
P1
.
(7.121)
Hence, in this special case, the two thresholds are independent of each other and the two detectors
become independent of each other.
After having pointed out through a simple example some of the problems related to distributed detec-
tion, it is now time to consider in more detail the cases where the nodes send their (possibly encoded)
data to the FC or they take local decisions ﬁrst and send them to the FC. In both situations, there are two
extreme cases: (a) there is only one FC; (b) every node is a potential FC, as it is able to take a global
decision.

376
CHAPTER 7 Distributed Detection and Estimation
2.07.5.1 Nodes send data to decision center
Let us consider for simplicity the simple (binary) hypothesis testing problem. Given a set of vector
observations x := [x1, . . . , xN], where xi is the vector collected by node i, i = 1, . . . , N, the optimal
decision rule for the simple hypothesis testing problem, under a variety of optimality criteria, amounts
to compute the likelihood ratio (LR) 

x

and compare it with a threshold. In formulas,


x

:= 

x1, . . . , xN

= p(x1, . . . , xN; H1)
p(x1, . . . , xN; H0)
H1
⋛
H0
γ.
(7.122)
In words, the detector decides for H1 if the LR exceeds the threshold, otherwise it decides for H0.
In general, what changes the distributed detection problem from the standard centralized detection is
that the data are sent to the decision center after source encoding into a discrete alphabet. The simplest
form of encoding is quantization. But also taking local decisions can be interpreted as a form of binary
coding. Clearly, source coding is going to affect the detection performance. It is then useful to show,
through a simple example, how local quantization affects the ﬁnal detection performance and how we
can beneﬁt from the theoretical analysis to optimize the number of bits associated to the quantization
step in order to optimize performance of the detection scheme.
2.07.5.1.1
Centralized detection of deterministic signal embedded
in additive noise
Let us consider the detection of a deterministic (known) signal embedded in additive noise. In this
section, we consider the case where the decision is taken at a FC, after having collected the data sent
by the sensors. This case could refer for example to the detection of undesired resonance phenomena
in buildings, bridges, etc. The form of the resonance is known. However, the measurements taken by
the sensors are affected by noise and then it is of interest to check the performance as a function of the
signal to noise ratio.
The measurement vector is x = (x1, . . . , xN), where xi is the measurement taken by node i. Let us
denote as s the known deterministic signal. The observation can be modeled as
x ∼
*v + w
under H0
s + v + w
under H1 ,
(7.123)
wherev isthebackgroundnoise,whereasw isthequantizationnoise.WeassumethenoisetobeGaussian
with zero mean and (spatial) covariance matrix Cn, i.e., v ∼N(0, Cn). To simplify the mathematical
tractability, we consider a dithered quantization so that the quantization error can be modeled as a random
process statistically independent of noise. We may certainly assume that, after dithering, the quanti-
zation noise variables over different sensors are statistically independent. Hence, we can state that the
quantization noise vector w has zero mean and a diagonal covariance matrix Cq = diag(σ 2
q1, . . . , σ 2
qN).
If the amplitude of the useful signal spans the dynamic range [−A, A] and the number of bits used by
node i is ni, the quantum range is qi = 2A/2ni so that the quantization noise variance at node i is
σ 2
qi = (2A)2
12 22ni =
A2
3 22ni .
(7.124)
The overall noise has then a zero mean and covariance matrix C = Cn + Cq.

2.07.5 Distributed Detection
377
If the quantization noise is negligible, the Neyman-Pearson criterion applied to this case leads to the
following linear detector
T (x) = R{sH C−1x}
H1
⋛
H0
γ,
(7.125)
where R(x) denotes the real part of x, and the detection threshold γ is computed in order to guarantee
the desired false alarm probability Pf a. Unfortunately, since the quantization noise is not Gaussian,
the composite noise v + w is not Gaussian and then the detection rule in (7.125) is no longer optimal.
Nevertheless, the rule in (7.125) is still meaningful as it maximizes the signal to noise ratio (SNR).
Hence, it is of interest to look at the performance of this detector in the presence of quantization noise.
The exact computation of the detection probability is not easy, at least in closed form, because it requires
the computation of the pdf of T (x). Nevertheless, when the number of nodes is sufﬁciently high (an
order of a few tens can be sufﬁcient to get a good approximation), we can invoke the central limit theorem
to state that T (x) is approximately Gaussian. Using this approximation, the detection probability can
be written in closed form for any ﬁxed Pf a, following standard derivations (see, e.g., [5]), as
Pd = Q

Q−1 
Pf a

−

sH C−1s

= Q
#
Q−1 
Pf a

−
-
sH(Cn + Cq)−1s
$
.
(7.126)
This formula is useful to assess the detection probability as a function of the bits allocated to each trans-
mission. At the same time, we can also use (7.126) as a way to ﬁnd out the bit allocation that maximizes
the detection probability. This approach establishes an interesting link between the communication and
detection aspects. In practice, in fact, encoded data are transmitted over a ﬁnite capacity channel. Hence,
itisusefultorelatethenumberofquantizationbitsusedbyeachnodeandcapacityofthechannelbetween
that node and the FC. For simplicity, we consider the optimization problem under the assumption of
spatially uncorrelated noise, i.e., Cn = diag(σ 2
n1, . . . , σ 2
nN). The problem we wish to solve is the maxi-
mization of the detection probability, for a given false alarm rate and a maximum global transmit power.
To guarantee an arbitrarily low transmission error rate, we need to respect Shannon’s channel coding
theorem, so that the number of bits per symbol must be less than channel capacity. Denoting with pi the
power transmitted by user i and assuming ﬂat fading channel, with channel coefﬁcient h2
i , the capacity is
given by (7.105). From(7.126), maximizing Pd is equivalent to maximizing sH 
Cn + Cq
−1 s. Hence,
using (7.124), the maximum Pd, for a given Pf a and a given global transmit power PT , can be achieved
by ﬁnding the power vector p = (p1, . . . , pN) that solves the following constrained problem
max
p
N

i=1
|si|2

σ 2
ni +
A2
3(1 + ai pi)
−1
(7.127)
s.t.
N

i=1
pi ≤PT ; pi ≥0, i = 1, . . . , N.
(7.128)
It is straightforward to check that this is a convex problem. Imposing the Karush-Kuhn-Tucker condi-
tions, the optimal powers can be expressed in closed form as:
pi =
.
1
√
λ

s2
i A2
3aiσ 4
ni
−
A2
3aiσ 2
ni
−1
ai
/+
,
(7.129)

378
CHAPTER 7 Distributed Detection and Estimation
where the Lagrange multiplier λ associated to the sum-power constraint can be determined as the value
that makes N
i=1 pi = PT .
A numerical example is useful to grasp some of the properties of the proposed algorithm. Let
us consider a series of sensors placed along a bridge of length L. The purpose of the network is to
detect one possible spatial resonance, which we represent as the signal s(z) = A cos (πz/L), where
z ∈[−L/2, L/2] denotes the spatial coordinate. The sensors are uniformly spaced along the bridge,
at positions zi = (i −1)L/N, with i = 1, . . . , N. Every sensor measures a shift xi = s(zi) + vi,
affected by the error vi. To communicate its own measurement to the FC, every sensor has to quantize
the measurement ﬁrst. The optimal number of bits to be used by every sensor can be computed by
using the previous theory. In this case, in Figure 7.16 we report the detection probability vs. the sum
power PT available to the whole set of sensors, for different numbers N of sensors. As expected, as the
total transmit power increases, Pd increases because more bits per symbol can be transmitted and then
the quantization errors become negligible. It is also important to notice how, increasing the number of
sensors, the detection probability improves, for any given transmit power. Furthermore, in Figure 7.17
we can see the optimal per channel bit allocation (bottom), together with the channels proﬁles |hk|2
(top). Interestingly, we can see that the method allocates more bits in correspondence with the best
channels and the central elements of the array, where the useful signal is expected to have the largest
variations.
10−2
10−1
100
10
1
10
2
0.4
0.5
0.6
0.7
0.8
0.9
1
Pd
PT
N = 5
N = 7
N = 10
N = 15
N = 20
FIGURE 7.16
Detection probability vs. sum transmit power, for different number of sensors.

2.07.5 Distributed Detection
379
1
2
3
4
5
6
7
8
9
10
0
0.5
1
1.5
2
2.5
3
| hk |2
sensors
1
2
3
4
5
6
7
8
9
10
0
0.5
1
1.5
nk
sensors
FIGURE 7.17
Optimal bit allocation.
2.07.5.1.2
Decentralized detection under conditionally independent
observations
Let us consider now the case where the globally optimal decision can be taken, in principle, by any
node. To enable this possibility, every node must be able to implement the statistical test (7.122). If the
measurements collected by the sensors are conditionally independent, the logarithm of the likelihood
ratio can be written as
log (x1, . . . , xN) =
N

i=1
log i(xi) =
N

i=1
[log pXi (xi, H1) −log pXi (xi, H0)].
(7.130)
This formula shows that, in the conditionally independent case, running a consensus algorithm is suf-
ﬁcient to enable every node to compute the global LR. It is only required that every sensor initializes
its own state with the local log-LR log i(xi) and then runs the consensus iterations. If the network is
connected, every node will end up with the average value of the local LR’s. In practice, to send the local
LR, every node must quantize it ﬁrst. Then, we need to refer to the consensus algorithm in the presence of
quantization errors. However, we have already seen in Section 2.07.3.2 that the consensus iterations may

380
CHAPTER 7 Distributed Detection and Estimation
be properly modiﬁed to make the algorithm robust against a series of drawbacks coming from commu-
nications through realistic channels, as, eg., random packet drops and quantization. Hence, a consensus
algorithm, properly modiﬁed, can enable every node to compute the global LR with controllable error.
2.07.5.2 Nodes send local decisions to fusion center
Consider now the case where each node i takes a local decision, according to a locally optimal criterion,
and encodes the decision into the binary variable ui. Then, the node sends the variable ui to the fusion
center, which is asked to take a global decision on the basis of the vector u := (u1, . . . , uN) containing all
local decisions. Let us consider for simplicity the binary hypothesis test. This problem was considered
in [50] and we will now review the basic results. This problem is distinct from the case studied in
the previous section because here the local decision thresholds are optimized according to a detection
criterion, whereas in standard quantization the decision thresholds are not optimized.
Under both Bayesian and Neyman-Pearson (NP) formulations, the optimal test amounts to a likeli-
hood ratio test, based on u, i.e.,
p(u1, . . . , uN; H1)
p(u1, . . . , uN; H0) ≷η.
(7.131)
In the case of conditionally independent local decisions, the LRT converts into
N
i=1 p(ui; H1)
N
i=1 p(ui; H0)
:=
N

i=1
i(ui) ≷η.
(7.132)
Since each variable ui can only assume the values 0 or 1, we can group all the variables into two subsets:
the subset S0 containing all variables ui = 0 and the subset S1 containing all variables ui = 1, thus
yielding

i∈S0
p(ui = 0; H1)
p(ui = 0; H0)

i∈S1
p(ui = 1; H1)
p(ui = 1; H0) ≷η.
(7.133)
Denoting with PMi = p(ui = 0; H1), and PFi = p(ui = 1; H0), the probabilities of miss and the
probability of false alarm of node i, respectively, (7.133) can be rewritten as

i∈S0
PMi
1 −PFi

i∈S1
1 −PMi
PFi
≷η.
(7.134)
Taking the logarithm of both sides and reintroducing the variables ui, the fusion rule becomes
N

i=1
#
log
1 −PMi
PFi

ui + log

PMi
1 −PFi

(1 −ui)
$
≷log η
(7.135)
or, equivalently
N

i=1
log
#(1 −PMi)(1 −PFi)
PMi PFi
$
ui ≷log
.
η
N

i=1
1 −PFi
PMi
/
.
(7.136)

2.07.6 Beyond Consensus: Distributed Projection Algorithms
381
The optimal fusion rule is then a simple weighted sum of the local decisions, where the weights depend
on the reliabilities of the local decisions: Larger weights are assigned to the most reliable nodes.
If instead of having a single FC, we wish to enable every node to implement the decision fusion
rule described above, we can see that, again, running a consensus algorithm sufﬁces to reach the goal.
In fact, if each local state variable is initialized with a value xi[0] = log

(1−PMi)(1−PFi)
PMi PFi

ui, running
a consensus algorithm allows every node to know the function in (7.136). The only constraint is,
as always, network connectivity. The drawback of this simple approach is that running this sort of
consensus algorithm requires the transmission of real variables, rather than the binary variables ui.
In fact, even if the local decision ui is binary, the coefﬁcient multiplying ui is a real variable, which
needs to be quantized before transmission over a realistic channel. Again, the consensus algorithm can
be robustiﬁed against quantization errors by using dithered quantization and a decreasing step size, as
shown in 2.07.3.2. However, it is important to clarify that we cannot make any claim of optimality of this
kind of distributed decision. In principle, when the nodes exchange their decisions with the neighbors,
the decision thresholds should be adjusted in order to accommodate some optimality criterion. This is
indeed an interesting, yet still open, research topic.
2.07.6 Beyond consensus: distributed projection algorithms
In many applications, the ﬁeld to be reconstructed by a sensor network is typically a smooth function of
the spatial coordinates. This happens for example, in the reconstruction of the spatial distribution of the
power radiated by a set of transmitters. The problem is that local measurements may be corrupted by
local noise or fading effects. An important application of this scenario is given by cognitive networks.
In such a case, a secondary node would need to know the channel occupation across space, to ﬁnd out
unoccupied channels, within the area of interest. This requires some sort of spectrum sensing, but in a
localized area. The problem of sensing is that wireless propagation is typically affected by fading or
shadowing effects, so that a sensor in a shadowed location might indicate that a channel is unoccupied,
while this is not true. To avoid this kind of error, which would lead to undue channel occupation from
opportunistic users, it is useful to resort to cooperative sensing. In such a case, nearby nodes exchange
local measurements to counteract the effect of shadowing.
The problem with local averaging operations is that they should reduce the effect of fading, but with-
out destroying valuable spatial variations. In the following, we recall a distributed algorithm proposed
in [72] to recover a spatial map of a ﬁeld, using local weighted averages where the weights are chosen
so as to improve upon local noise or fading effects, but without destroying the spatial variation of the
useful signal.
Let us consider a network composed of N sensors located at positions (xi, yi), i = 1, . . . , N, and
denote the measurement collected by the ith sensor by g(xi, yi) = z(xi, yi) + vi, where z(xi, yi)
represents the useful ﬁeld while vi is the observation error. Let us also denote by uk(x, y), k = 1, . . . ,r,
a set of linearly independent spatial functions deﬁning a basis for the useful signal. The useful signal
can then be represented through the basis expansion model
z(xi, yi) =
r

k=1
skuk(xi, yi).
(7.137)

382
CHAPTER 7 Distributed Detection and Estimation
In vector notation, introducing the N-size column vector g := [(g(x1, y1), g(x2, y2), . . . , g(xN, yN)]T
and similarly for the vector z, we may write
g = z + v = Us + v,
(7.138)
where U is the N ×r matrix whose mth column is um = (um(xi, yi), . . . , um(xN, yN)), s = (s1, . . . , sr)
is an r-size vector of coefﬁcients and z = Us is the useful signal. The spatial smoothness of the useful
signal ﬁeld may be captured by choosing the functions uk(x, y) to be the low frequency components of
the Fourier basis or low-order 2 D polynomials. For instance, if the space under monitoring is a square
of side L, we may choose the set
{unm(x, y)} =
*
1, cos

2π nx + my
L

, sin

2π nx + my
L
+m=∞,n=∞
m=0,n=0;m+n̸=0
.
(7.139)
In practice, the dimension r of the useful signal subspace is typically much smaller than the dimension
N of the observation space, i.e., of the number of sensors. We can exploit this property to devise a
distributed denoising algorithm.
If we use a Minimum Mean Square Error (MMSE) strategy, the goal is to ﬁnd the useful signal vector
ˆs that minimizes the mean square error
E := E{∥g −U ˆs∥2}.
(7.140)
The solution is well known and is given by [44]:
ˆs = (UT U)−1UT g.
(7.141)
Our goal is actually to recover the vector z, rather than s. In such a case, the estimate of z is
ˆz = U(UT U)−1UT g.
(7.142)
The operation performed in (7.142) corresponds to projecting the observation vector onto the subspace
spanned by the columns of U. Assuming, without any loss of generality (w.l.o.g.), the columns of U to
be orthonormal, the projector simpliﬁes into
ˆz = UUT g.
(7.143)
The centralized solution to this problem is then very simple: The fusion center collects all the measure-
ments g(xi, yi), compute U and then recovers ˆz from (7.143).
The previous approach is well known. The interesting point is that the MMSE solution can be
achieved with a totally decentralized approach, where every sensor interacts only with its neighbors,
with no need to send any data to a fusion center. The proposed approach is based on a very simple
iterative procedure, where each node initializes a state variable with the local measurement, let us say
zi[0] = g(xi, yi), and then it updates its own state by taking a linear combination of its neighbors’
states, similarly with what happens with consensus algorithms, but with coefﬁcients computed in order
to solve the new problem.

2.07.6 Beyond Consensus: Distributed Projection Algorithms
383
More speciﬁcally, denoting by z[k], the N-size vector containing the states of all the nodes, at iteration
k, and by g the vector containing the initial measurements collected by all the nodes, the vector z[k]
evolves according to the following linear state equation:
z[k + 1] = Wz[k],
z[0] = g ∈RN,
(7.144)
where W ∈RN×N is typically a sparse (not necessarily symmetric) matrix. The network topology
is reﬂected into the sparsity of W. In particular, the number of nonzero entries of, let us say, the ith
row is equal to the number of neighbors of node i. In a WSN, the neighbors of a node are the nodes
falling within the coverage area of that node, i.e., within a circle centered on the location of the node,
with radius dictated by the transmit power of the node and by the power attenuation law. Our goal is to
ﬁnd the nonnull coefﬁcients of W that allow the convergence of z[k] to the vector ˆz given in (7.143).
In general, not every network topology guarantees the existence of a solution of this problem. In the
following, we will show that a solution exists only if each node has a number of neighbors greater than
the dimension r of the useful signal subspace.
Let us denote by PR(U) ∈RN×N the orthogonal projector onto the r-dimensional subspace of RN
spanned by the columns of (U), where R(·) denotes the range space operator and U ∈RN×r is a
full-column rank matrix, assumed, w.l.o.g., to be semi-unitary. System (7.144) converges to the desired
orthogonal projection of the initial value vector z[0] = g onto R(U), for any given g ∈RN, if and only if
lim
k→+∞z[k] =
lim
k→+∞Wk g = PR(U)g,
(7.145)
i.e.,
lim
k→+∞Wk = PR(U).
(7.146)
Resorting to basic algebraic properties of discrete-time systems, it is possible to derive immediately
some basic properties of W. In particular, denoting with OUD the Open Unit Disk, i.e., the set
{x ∈C : |x| < 1}, a matrix W is semistable if its spectrum spec(W) satisﬁes spec(W) ⊂OUD ∪{1}
and, if 1 ∈spec(W), then 1 is semisimple, i.e., its algebraic and geometric multiplicities coincide. If
W is semistable, then [73, p.447]
lim
k→+∞Wk = I −(I −W)♯(I −W),
(7.147)
where ♯denotes group generalized inverse [73, p.228]. Furthermore, setting, without loss of generality,
the matrix W in the form W = I −ϵL, (7.147) can be rewritten as
lim
k→+∞Wk = I −L♯L.
(7.148)
But I −L♯L is the projector onto the null-space of L. Hence, we can state the following:
Proposition 1.
Given the dynamical system in (7.144) and the projection matrix PR(U), the vector
PR(U)z[0] is globally asymptotically stable for any ﬁxed z[0] ∈RN, if and only if the following
conditions are satisﬁed:
i. L has a nullspace of dimension r, spanned by the columns of U;
ii. L and ϵ must be chosen so that W is semistable.
Alternatively, the previous conditions can be rewritten equivalently in the following form

384
CHAPTER 7 Distributed Detection and Estimation
Proposition 2.
Given the dynamical system in (7.144) and the projection matrix PR(U), the vector
PR(U)z[0] is globally asymptotically stable for any ﬁxed z[0] ∈RN, if and only if the following
conditions are satisﬁed:
WPR(U) = PR(U),
(C.1)
PR(U)W = PR(U),
(C.2)
ρ

W −PR(U)

< 1,
(C.3)
where ρ(·) denotes the spectral radius operator [23].
□
Remark 1.
Conditions C.1,C.2,C.3 have an intuitive interpretation. In particular, C.1 and C.2 state
that, if system (7.144) asymptotically converges, then it is guaranteed to converge to the desired value.
In fact, C.1 guarantees that the projection of vector z[k] onto R(U) is an invariant quantity for the
dynamical system, implying that the system in (7.144), during its evolution, keeps the component
PR(U)z[0] of z[0] unaltered. At the same time, C.2 makes PR(U)z[0] a ﬁxed point of matrix W and
thus a potential accumulation point for the sequence {z[k]}k. Both conditions C.1 and C.2 do not state
anything about the convergence of the dynamical system. This is guaranteed by C.3, which imposes
that all the modes associated to the eigenvectors orthogonal to R(U) are asymptotically vanishing.
Remark 2.
The conditions C.1,C.2,C.3 contain, as a special case, the convergence conditions of
average consensus algorithm. In fact, it is sufﬁcient to set in (7.145), r = 1 and U = u =
1
√
N 1N,
where 1N is the N-length vector of all ones. In such a case, C.1,C.2,C.3 can be restated as following:
the digraph associated to the network described by W must be strongly connected and balanced.
The previous conditions do not make any explicit reference to the sparsity of matrix W. However,
when we consider a sparse matrix, reﬂecting the network topology, additional conditions are necessary
to make sure that the previous conditions are satisﬁed. In other words, not every network topology is
able to guarantee the asymptotic projection onto a prescribed signal subspace. One basic question is
then what network topology is able to guarantee the convergence to a prescribed projector. We provide
now the conditions on the sparsity of W, or equivalently L, guaranteeing the desired convergence.
From condition (i) of Proposition 1, given the matrix U, L must satisfy the equation LU = 0. Let us
assume that every row of L has K nonzero entries and let us indicate with {i j1, . . . , i j K } the set of the
column indices corresponding to the nonzero entries of the jth row of L. Hence, every row of L must
satisfy the following equation
⎛
⎜⎜⎝
u1(i11), u1(i12), · · · u1(i1K )
u2(i21), u2(i22), · · · u2(i2K )
·
·
·
·
ur(ir1),
ur(ir2),
· · ·
ur(ir K )
⎞
⎟⎟⎠
⎛
⎜⎝
l j1
...
l j K
⎞
⎟⎠= 0.
(7.149)
To guarantee the existence of a nontrivial solution to (7.149), the matrix on the left hand side must
have a kernel of dimension at least one. This requires K to be strictly greater than r, the dimension of
the signal subspace. Since the number of nonzero entries of, let us say the jth, row of L is equal to
the number of neighbors of node j plus one (the coefﬁcient multiplying the state of node i itself), this
implies that the minimum number K of neighbors of each node must be at least equal to the dimension

2.07.7 Minimum Energy Consensus
385
r of the signal subspace. Of course this condition is necessary but not sufﬁcient. It is also necessary to
check that the sparse matrix L built with rows satisfying (7.149), with j = 1, . . . , N, had rank N −r.
This depends on the location of the nodes and on the speciﬁc choice of the orthogonal basis.
An example can be useful to illustrate the beneﬁts achievable with the proposed technique. We
consider the case where the observation is corrupted by a multiplicative, spatially uncorrelated, noise,
which models, for example a fading effect. Let us denote with P(xi, yi) = A(xi, yi)S(xi, yi) the
measurement carried out from node i, located in the point of coordinates (xi, yi), where S(xi, yi)
denotes the useful ﬁeld, whereas A(xi, yi) represents fading. We consider, for instance, a useful signal
composed by Ns = 4 transmitters and we assume a polynomial power attenuation, so that the useful
signal measured at the point of coordinates (x, y) is
S(x, y) =
Ns

i=1
Pi
1 + ((x −xi)2 + (y −yi)2)/σ 2 , x ∈
#
−L
2 , L
2
$
, y ∈
#
−L
2 , L
2
$
(7.150)
where Pi is the power emitted by source i, located at (xi, yi), and σ speciﬁes the power spatial spread.
Furthermore, fading is modeled as a spatially uncorrelated multiplicative noise. The sensor network is
composed of 2500 nodes uniformly distributed over a 2D grid. All the transmitters use the same power,
i.e., Pi = P in (7.150), and the noise has zero mean and variance σ 2
n = P.
In this case, it is useful to apply a homomorphic ﬁltering to the measured ﬁeld. In particular, we
take the log of the measurement, thus getting log (P(xi, yi)) = log (S(xi, yi)) + log (A(xi, yi)). To
smooth out the undesired effect of fading, we assume a signal model composed by the superposition
of 2D sinusoids, so that the columns of the matrix U in (7.138) are composed of signals of the form
sin (2π(mx + ny)/L), and cos (2π(mx + ny)/L), with m, n = 0, 1, . . .. We set the initial value of the
state of each node equal to log (P(xi, yi)) and we run the distributed projection algorithm described
above. After convergence, we simply take the exp of the result.
Figure 7.18 shows an example of application. In particular, the spatial behavior of the useful signal
power is shown in the top left plot, while the observation corrupted by fading is reported in the top right
ﬁgure. It is useful to consider that, in the example at hand, the useful signal would require a Fourier series
expansion with an inﬁnite number of terms to null the modeling error. Conversely, in our example, we
used two different orders, k = 10 and k = 20. The corresponding reconstructions are shown in the bot-
tom ﬁgures. From Figure 7.18 it is evident the capability of the proposed distributed approach to provide
a signiﬁcant attenuation of the fading phenomenon, without destroying valuable signal variations.
2.07.7 Minimum energy consensus
Although distributed algorithms to achieve consensus have received a lot of attention because of their
capability of reaching optimal decisions without the need of a fusion center, the price paid for this
simplicity is that consensus algorithms are inherently iterative. As a consequence the iterated exchange
of data among the nodes might cause an excessive energy consumption. Hence, to make consensus
algorithms really appealing in practical applications, it is necessary to minimize the energy consump-
tion necessary to reach consensus. The network topology plays a fundamental role in determining
the convergence rate [74]. As the network connectivity increases, so does the convergence rate. How-
ever, a highly connected network entails a high power consumption to guarantee reliable direct links
between the nodes. On the other hand, if the network is minimally connected, with only neighbor nodes

386
CHAPTER 7 Distributed Detection and Estimation
Ideal spatial field
10
20
30
40
50
5
10
15
20
25
30
35
40
45
50
Noisy observation
10
20
30
40
50
5
10
15
20
25
30
35
40
45
50
Reconstructed field (k=10)
10
20
30
40
50
5
10
15
20
25
30
35
40
45
50
Reconstructed field (k=20)
10
20
30
40
50
5
10
15
20
25
30
35
40
45
50
FIGURE 7.18
Example of ﬁeld reconstruction in the presence of fading: ideal spatial ﬁeld (top left); measured ﬁeld (top
right); ﬁeld reconstructed with order k = 10 (bottom left) and k = 20 (bottom right) [75].
connected to each other, a low power is spent to maintain the few short range links, but, at the same time,
a large convergence time is required. Since what really matters in a WSN is the overall energy spent to
achieve consensus, in [76,77] it was considered the problem of ﬁnding the optimal network topology
that minimizes the overall energy consumption, taking into account convergence time and transmit pow-
ers jointly. More speciﬁcally, in [77] it is proposed a method for optimizing the network topology and
the power allocation across every link in order to minimize the energy necessary to achieve consensus.
Two different types of networks are considered: a) deterministic topologies, where node positions are
arbitrary, but known; b) random geometries, where the unknown node locations are modeled as random
variables. We will now review the methodology used in both cases.

2.07.7 Minimum Energy Consensus
387
2.07.7.1 Optimization criterion
By considering only the power spent to enable wireless communications, the overall energy consumption
to reach consensus can be written as the product between the sum of the power Ptot necessary to establish
the communication links among the nodes and the number of iterations Nit necessary to achieve consen-
sus. The exchange of information among the nodes is supposed to take place in the presence of a slotted
system, with a medium access control (MAC) mechanism that prevents packet collisions. The number
of iterations can be approximated as Nit = Tc/Ts where Ts denotes the duration of a time slot unit and
Tc = −log (γ )
λ2(L)
is the convergence time deﬁned as the time necessary for the slowest mode of the dynamical system
(7.23) to be reduced by a factor γ ≪1. The total power spent by the network in each iteration is then
Ptot = 
i, j ai j pi j where the coefﬁcient pi j = p ji, i ̸= j denotes the power transmitted by node i to
node j, while the binary coefﬁcients ai j assess the presence (ai j = 1) of a link between nodes i and j or
not (ai j = 0). Our goal is to minimize the energy consumption expressed by the following metric
E = PtotNit = K
N
i=1
N
j=1ai j pi j
λ2(L(a))
,
(7.151)
where K incorporates all irrelevant constants, N is the number of sensors and L(a) is the Laplacian
matrix depending on the vector a = A(:) containing all the coefﬁcients ai j. More speciﬁcally, we aim
to ﬁnd the set of active links, i.e., the non-zero coefﬁcients ai j, and the powers pi j that minimize the
energy consumption (7.151), under the constraint of guaranteeing network connectivity, i.e., enforcing
λ2(L(a)) > 0. The problem can be formulated as follows [77]:
mina, p
N
i=1
N
j=1 ai j pi j
λ2(L(a))
s.t. ϵ ≤λ2(L(a)) [P.0]
ai j ∈{0, 1}
pi j ≥0 ∀i, j = 1, . . . , N
(7.152)
where ϵ is an arbitrarily small positive constant used to ensure network connectivity and p is the vector
with entries pi j. Since the topology coefﬁcients are binary variables, [P.0] is a combinatorial problem,
with complexity increasing with the size N of the network as 2N(N−1)/2. In [77] we have modiﬁed [P.0]
in order to convert it into a convex problem, with negligible performance losses. A ﬁrst simpliﬁcation
comes from observing that the coefﬁcients ai j and pi j are dependent of each other through the radio
propagation model so that the set of unknowns can be reduced to the set of powers pi j. More speciﬁcally,
by assuming ﬂat fading channel, we can assume that the power pRj received by node j when node i
transmits is given by
pRj =
pi j
1 + (ri j/r0)η ,
(7.153)
where ri j is the distance between nodes i and j, η is the path loss exponent, and the parameter r0
corresponds to the so called Fraunhofer distance. We have included in the denominator the unitary term
to avoid the unrealistic situation in which the received power could be greater than the transmitted one.
Given the propagation model (7.153), the relation between the power coefﬁcients pi j and the topology

388
CHAPTER 7 Distributed Detection and Estimation
coefﬁcients ai j is then
ai j =
!
1 if pi j > pmin

1 +
ri j
r0
η
0 otherwise
,
(7.154)
where pmin is the minimum power needed at the receiver side to establish a communication. In [77] we
have shown how to relax this relation in order to simplify the solution of the optimal topology control
problem considering both the deterministic and random topology.
2.07.7.2 Optimal topology and power allocation for arbitrary networks
In the case where the distances between the nodes are known, to ﬁnd the optimal solution of problem
[P.0] involves a combinatorial strategy that makes the problem numerically very hard to solve. In [77],
we have relaxed problem [P.0] so that, instead of requiring ai j to be binary, we assume ai j to be a real
variable belonging to the interval [0, 1]. This relaxation is the ﬁrst step to transform the previous problem
into a convex problem. More speciﬁcally, we have introduced the following relationship between the
coefﬁcients ai j and the distances ri j:
ai j =
1
1 + (ri j/rci j )α ,
(7.155)
where α is a positive coefﬁcient and rci j is the coverage radius, which depends on the transmit power.
According to (7.155), ai j is close to one when node j is within the coverage radius of node i, i.e.,
ri j ≪rci j , whereas ai j is close to zero, when ri j ≫rci j . The switching from zero to one can be made
steeper by increasing the value of α. In [77] we have found the coefﬁcients pi j as a function of ai j
pi j = q(ai j) = pmin + k1

ai j
1 −ai j
η/α
,
(7.156)
with k1 = pmin
rη
i j
rη
0 . Consequently, we can reduce the set of variables to the only power vector p and
problem [P.0] can be relaxed into the following problem:
min p
pT 1
λ2(L( p))
s.t.
ϵ ≤λ2(L( p)) [P.1].
(7.157)
pmin1 ≤p
The ﬁrst important result proved in [77] is that the problem [P.1] is a convex-concave fractional problem
if η ≥α, so that we can use one of the methods that solve quasi-convex optimization problems, see e.g.,
[78,79]. In [77] we have used the nonlinear parametric formulation proposed in [79]. Hence we have
further converted the convex-concave fractional problem [P.1] into the following equivalent parametric
problem in terms of vector a, i.e.,
mina
φ(a) −μλ2(L(a))
s.t.
ϵ ≤λ2(L(a)) [P.2].
(7.158)
0 ≤a < 1,
where φ(a) = N
i=1
N
j=1,i̸= j q(ai j) and μ controls the trade-off between total transmit power and
convergence time.

2.07.7 Minimum Energy Consensus
389
The optimization problem [P.2] is a convex parametric problem [77] and an optimal solution can be
found via efﬁcient numerical tools. Furthermore, using Dinkelbach’s algorithm [79], we are also able
to ﬁnd the optimal parameter μ in [P.2].
2.07.7.3 Numerical examples
Since our optimization procedure is based on a relaxation technique, we have evaluated the impact of
the relaxation on the ﬁnal topology and performance.
More speciﬁcally, the topology coefﬁcients ai j obtained by solving [P.2] are real variables belonging
to the interval [0, 1], so that, to obtain the network topology, it is necessary a quantization step to convert
them into binary values, 1 or 0, by comparing each ai j with a threshold ath. It has been shown that the
loss in terms of optimal energy due to the relaxation of the original problem is negligible. To evaluate the
impact of thresholding operation, in Figure 7.19 we show the topologies obtained by solving problem
−0.5
0
0.5
−0.4
−0.2
0
0.2
0.4
0.6
x
y
−0.5
0
0.5
−0.4
−0.2
0
0.2
0.4
0.6
x
y
−0.5
0
0.5
−0.4
−0.2
0
0.2
0.4
0.6
x
y
−0.5
0
0.5
−0.4
−0.2
0
0.2
0.4
0.6
x
y
(a)
(b)
(c)
(d)
FIGURE 7.19
Optimal topologies, for different threshold values and η = 6: (a) ath = 0.09; (b) ath = 0.05; (c) ath = 10−4;
(d) ath = 10−7.

390
CHAPTER 7 Distributed Detection and Estimation
2
2.5
3
3.5
4
4.5
5
5.5
6
6.5
7
10
2
10
3
10
4
η
Er
2
2.5
3
3.5
4
4.5
5
5.5
6
6.5
7
0
2
4
6
η
E[λ2(η)]
2
2.5
3
3.5
4
4.5
5
5.5
6
6.5
7
0.2
0.4
0.6
0.8
1
η
E
N
i=1
|Ni|/(N 2 −N)
(a)
(b)
(c)
FIGURE 7.20
Average value of (a) energy; (b) λ2(L); (c) fraction of active links vs. path loss η for ath = 0.09.
[P.2], for a network composed of N = 20 nodes, using different values of ath and assuming η = 6.
Comparing the four cases reported in Figure 7.19, we can note that for a large range of values of ath,
the ﬁnal topology is practically the same, while only for very low values of the threshold (i.e., case (d)),
we can observe a sensitive change of topology. This means that the relaxation method is robust against
the choice of the ﬁnal threshold.
The previous results pertain to a speciﬁc realization of the node locations. To provide results of
more general validity, in Figure 7.20, we report the average value of (a) the energy (Er) (b) λ2(L), and
(c) fraction of active links
N
i=1 |Ni|
N(N−1) , as a function of the path loss exponent η, setting ath = 0.09. From
Figure 7.20, we observe that when the attenuation is high (i.e., η is large), reducing the number of links
(making the topology sparser) is more important than reducing convergence time. Conversely, when
the attenuation is low (i.e., η is small), increasing network connectivity is more important than reducing
power consumption.

2.07.7 Minimum Energy Consensus
391
2.07.7.4 Minimization of the energy consumption over random
geometric graphs
Let us consider now the problem of minimizing the energy consumption for a sensor network modeled
as a random geometric graph. We will use the symbol G(N,r) to indicate an RGG composed of N
points, with coverage radius r.
In [74], it has been shown that the degree of an RGG G(N,r) of points uniformly distributed over
a two-dimensional unit torus7 is equal to
d(N) = πr2N
(7.159)
with high probability, i.e., with probability 1 −1/N 2, if the radius behaves as r0(N) in (7.2). This
implies that if the coverage radius is chosen so as to guarantee connectivity with high probability, an
RGG tends to behave, asymptotically, as a regular graph. In order to calculate the convergence rate we
have to derive the second eigenvalue of the Laplacian, L = D −A, where D is the degree matrix and
A is the adjacency matrix. From (7.159), D = πr2N I, so that we only need to calculate the second
largest eigenvalue of A. In Appendix A.2, we study the asymptotic behavior of the spectrum of A and
the result is that the second largest eigenvalue of L tends asymptotically to
λ2(L) = π Nr2 −Nr J1(2πr),
(7.160)
where r is the coverage radius of each node.
2.07.7.4.1
An analytic approach for minimizing the energy consumption
In [77] we studied the energy minimization problem for RGG’s, exploiting the previous analytic expres-
sions. In the random topology case, since the distances are unknown, we cannot optimize the power
associated with each link. However, we can seek the common transmit power that minimizes energy
consumption. Thus, in the random setting we assume a broadcast communication model, where each
node broadcasts the value to be shared with its neighbors. In the lack of any information about distances
among the nodes, we assume that each node uses the same transmit power. In this case, the network
topology can be modeled as a random graph model. In [80,81] it has been shown that the dynamical sys-
tem ˙x(t) = −Lx(t) converges to consensus almost surely, i.e., Pr {limt→∞x(t) = x∗1} = 1 assuming
that each node has a coverage radius so that the network is asymptotically connected with probability
one. Then the rate of convergence to consensus is given [80,81] by E[e−2Tsλ2(L)]. In [77] we proved
that the convergence rate can be approximated as
E[e−2Tsλ2] ≈e−2Ts E[λ2]
(7.161)
so that the energy spent to achieve consensus can now be expressed as
E = K
Np
2E[λ2(L(p))].
(7.162)
This is the performance metric we wish to minimize in the random scenario, with respect to the single
unknown p.
7A torus geometry is typically used to get rid of border effects.

392
CHAPTER 7 Distributed Detection and Estimation
In particular, using the asymptotic expression (7.160) for the algebraic connectivity, we can introduce
the following metric
E(r) = Npmin[1 + (r/r0)η]
Nπr2 −r N J1(2πr)
(7.163)
thatisaconvexfunctionofr,forr0(N) ≤r ≤0.5,wherer0(N),behavesasin(7.2)toensureconnectivity.
Numerical examples. In Figure 7.21, we compare the value of E(r) obtained by our theoretical approach
and by simulation, for various values of the path loss exponent η. The results are averaged over 100
independent realizations of random geometric graphs composed of N = 1000 nodes. For each η, we
indicate the pair of radius and energy providing minimum energy consumption by a circle (simulation)
or a star (theory). It can be noted that the theoretical derivations provide a very good prediction of the
performance achieved by simulation and, for each η, there is a coverage radius value that minimizes
energy consumption.
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
0.55
10 1
10 2
10 3
10 4
10 5
10 6
r
E(r)
N =1000
 
 
 η=6
η=5.2
η=4.2
η=3.2
η=2
FIGURE 7.21
Global energy consumption versus transmission radius for an RGG; theoretical values (solid) and simulation
results (dashed).

2.07.8 Matching Communication Network
393
2.07.8 Matching communication network topology
to statistical dependency graph
In Section 2.07.2.2, we saw that the topology of a sensor network observing a random ﬁeld should
depend on the structure of the graph describing the observed ﬁeld. In this section, we recall a method
proposed in [82,83] to design the topology of a wireless sensor network observing a Markov random
ﬁeld in order to match the structure of the dependency graph of the observed ﬁeld, under constraints on
the power used to ensure the sensor network connectivity. As in [82,83], our main task is to recover the
sparsity of the dependency graph and to replicate it at the sensor network level, under the constraint of
limiting the transmit power necessary to establish the link among the nodes. Also in this case, searching
for an optimal topology is a combinatorial problem. To avoid the computational burden of solving the
combinatorial problem, we propose an ad hoc relaxation technique that allows us to achieve the solution
through efﬁcient algorithms based on difference of convex problems.
Let us assume to have a network composed of N nodes, each one observing a spatial sample of
a Gaussian Markov Random Field. We denote by x := (x1, . . . , xN) the vector of the observations
collected by the N nodes and we assume that x has zero mean and covariance matrix C. The statistical
dependency among the random variables xi is well captured by the structure of the Markov graph whose
vertices correspond to the random variables and whose links denote statistical dependencies among the
variables. As discussed in 2.07.2.2 the main feature of a Markov graph is that it is sparse and there
is no link between two nodes if and only if their observations are statistically independent. Moreover,
if the random vector x is also Gaussian, with covariance matrix C, the sparsity of the Markov graph
is completely speciﬁed by the sparsity of the precision matrix, which is the inverse of the covariance
matrix, i.e., B := C−1. On the other hand, the topology of the WSN can also be described by a graph,
having adjacency matrix A such that ai j ̸= 0 only if there is a physical link between nodes i and j.
We use a simple propagation model such that there is a link between node i and j if the power received
by node j exceeds a minimum power pmin. The received power depends on the power pT (i, j) used by
node i to transmit to node j and on the distance ri j between nodes i and j through the equation
pR(i, j) = pT (i, j)
1 + rη
i j
,
(7.164)
where η is the path loss exponent.
As proposed in [82,83], our goal is to design the topology of the WSN, and hence its adjacency
matrix A, in order to match as well as possible the topology of the dependency graph, compatibly with
the power expenditure necessary to establish each link in the network. Without any power constraint, we
would choose A to be equal to B = C−1, so as to reproduce the same sparsity of the dependency graph.
Adding the power constraints, we will end up, in general, with a matrix A different from B. We measure
the difference between the two matrices A and B using the so called Burg divergence, deﬁned as
DB(A, B) := 1
2trace

AB−1 −I

−1
2 log ( det (AB−1)).
(7.165)
Even though the Burg divergence does not respect all the prerequisites to be a distance, it holds true
that DB(A, B) = 0, if and only if A = B, otherwise, the divergence is strictly positive. If the matrices
A and B are deﬁnite positive, the expression in (7.165) coincides with the Kullback-Leibler divergence

394
CHAPTER 7 Distributed Detection and Estimation
between the probability density function (pdf) of two Gaussian random vectors having zero mean and
precision matrices A and B or, equivalently, covariance matrices A−1 and C.
2.07.8.1 Encouraging sparsity by preserving total transmit power
One of the most important tasks in wireless sensor networks is to minimize the energy consumption
for reliable data transmission. This need can be accommodated by formulating the search for a sparse
topology incorporating a penalization for the presence of links among distant nodes. The ﬁrst strategy
we propose is named Sparsity with Minimum Power (SMP) consumption. We consider both cases where
the covariance matrix is perfectly known or estimated from the collected data.
Let us consider a wireless sensor network whose communication graph is a geometric graph, where
each node communicates only with the nodes lying within its coverage area of radius r. We assume,
initially, that the covariance matrix C of the GMRF is perfectly known. Our goal is to ﬁnd the optimal
adjacency matrix A that minimizes the divergence DB(A, B) given in (7.165), under the constraint of
limiting the transmit power necessary to maintain the links among the nodes of the WSN. This constraint
can be incorporated in our optimization problem by introducing a penalty term given by the sum of the
transmit powers over all active links, i.e.,
PN(A) =
N

i=1
N

j=1
j̸=i
pT (i, j)δ(ai j),
(7.166)
where pT (i, j) denotes the power used by node i to transmit to node j and
δ(ai j) =
*0 if ai j = 0
1 otherwise,
(7.167)
assuming that ai j is different from zero only if the power pR(i, j) received by node j when node i
transmits, as given in (7.164), exceeds a suitable minimum level pmin, i.e., if
pT (i, j) >

1 + rη
i j

pmin.
(7.168)
The optimization problem can then be formulated as
min
A∈SN
++
DB(A, B) + ρPN(A),
(7.169)
where SN
++ is the cone of deﬁnite positive symmetric N × N-dimensional matrices, while ρ ≥0 is the
penalty coefﬁcient introduced to control sparsity. In fact, increasing the penalty coefﬁcient, we assign
a higher weight to power consumption so that sparse structures are more likely to occur.
Problem (7.169) is indeed quite hard to solve as the penalty function is a nonconvex discrete function.
Optimization problems with a convex penalty have been largely considered in several signal processing
applications, for example in compressed sensing [84] where these problems are often formulated as a
penalized least-square problem in which sparsity is usually induced by adding a l1-norm penalty on the
coefﬁcients, as in Lasso algorithm [47].

2.07.8 Matching Communication Network
395
Indeed, non-convex penalty functions such as lq-norm, with q < 1, are even more effective to recover
sparsity than l1-norm. Actually, using the so called l0 norm would be even more effective to measure
sparsity, even though the l0 norm does not respect all requisites to be a norm.8 Here we adopt the so
called Zhang penalty function analyzed in [85], i.e.,
z(ai j) = min
|ai j|
ϵ , 1

=
* |ai j|
ϵ
if |ai j| ≤ϵ
1
otherwise,
(7.170)
where ϵ is an inﬁnitesimal positive constant. Hence, by assuming pT (i, j) = (1 + rη
i j)pmin, the second
term in (7.169) can be written as
PN(A) =
N

i=1
N

j=1
di jz(ai j) = trace[z(A), D]
(7.171)
where D is a N × N dimensional symmetric matrix with entries di j = (1 + rη
i j)pmin, dii = 0,
∀i, j = 1, . . . , N, while the matrix mapping z(A) is deﬁned applying the elementwise mapping
z(ai j) : R →R+ given in (7.170). The combinatorial problem in (7.169) can then be reformulated as
min
A∈SN
++
DB(A, B) + ρ trace[z(A)D].
(7.172)
Unfortunately the second term in (7.172), is not convex so that the problem we have to solve is a
nonconvex, nonsmooth optimization problem. Nevertheless, in [82,83] we reformulated this problem
as a difference of convex (DC) problem. Before proceeding, we simply illustrate how to extend our
approach to the case where the covariance matrix of the observed vector is not known but estimated from
thedata.Insuchacase,thematrix C in(7.172)issubstitutedbytheestimatedmatrix 2C,whoseentry 2
Ci j is
2
Ci j = 1
K
K

k=1
xi(k)x j(k),
(7.173)
where xi(k) is the observation collected by node i, at time k, with k = 1, . . . , K. The practical, relevant,
difference is that while the true precision matrix B is sparse by hypothesis, the inverse of 2C in general
is not sparse. Also in this case, encouraging sparsity in estimating the inverse of the covariance matrix
can be beneﬁcial to improve the quality of the estimation itself.9
The problem (7.172) can be reformulated as a Difference of Convex (DC) functions problem [86],
by decomposing the function z(ai j) as the difference of two convex functions z(ai j) = gv(ai j)−h(ai j)
with gv(ai j) = |ai j|
ϵ
and
h(ai j) =
*0
if |ai j| ≤ϵ
|ai j|
ϵ
−1 otherwise.
(7.174)
8The l0 norm of a vector x is deﬁned as the number of nonzero entries of x.
9Provided that the observed ﬁeld is a Markov ﬁeld.

396
CHAPTER 7 Distributed Detection and Estimation
Hence the optimization problem in (7.172) can be rewritten as
min
A∈SN
++
DB(A, B) + ρ trace[(gv(A) −h(A))D].
(7.175)
To solve this problem, we have used an iterative procedure, known as DC algorithm (DCA), based on
the duality of DC programming. The usefulness of using DCA is that its convergence has been proved
in [86] and it is simple to implement, as it iteratively solves a convex optimization problem. We refer
the reader to [82,83] for further analytical details.
2.07.8.2 Sparsiﬁcation and estimation of the precision matrix
In this section we illustrate an alternative sparsiﬁcation strategy that improves the estimate of the
precision matrix with respect to the SMP strategy. In this alternative formulation, the penalty term is
the sum of the absolute values of the entries of A, weighted with the corresponding per-link transmit
power consumption. In this way, although the power consumption should not be lower than the SMP
method, we expect a sparse topology with a more accurate estimate of the precision matrix. We call this
strategy Sparse Estimation Strategy (SES). The new problem is formulated as follows
min
A∈SN
++
DB(A, B) + ρ trace[|A|D]
(7.176)
and it can be converted into a convex deﬁnite positive problem. In particular, splitting the matrix A into
thedifferenceoftwononnegativematricesrepresentingitspositiveandnegativepart,i.e., A = A+−A−,
we can rewrite (7.176) as
min
A+,A−∈SN
DB(A+ −A−, B) + ρ trace[(A+ + A−)D]
s.t.
A+ −A−≻0
(7.177)
A+ ≥0
A−≥0.
This problem can be solved using standard numerical tools or by applying a projected gradient algo-
rithm [87].
2.07.8.3 Numerical results
In this section we report some simulation results considering a sensors network composed of N = 20
nodes, uniformly deployed over a unit area square and observing correlated data from a GMRF. We adopt
the Markov model proposed in [8], where the correlation between neighboring nodes is a decreasing
function of their distance and the entries of the covariance matrix can be derived in closed form. In
[82,83] we have shown that even though the problem is not convex, the numerical results seem to
indicate that the method always converges to the same value of the precision matrix entries, irrespective
of the initializations. In Figure 7.22 we report the ﬁnal optimal network topology referring to the case of
a matrix estimated from the data. In particular, the top left plot of Figure 7.22 shows the true dependency
graph and all other plots depict the network topologies obtained using the proposed SMP algorithm,

2.07.8 Matching Communication Network
397
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
True precision matrix
x
y
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
ρ = 0, Aop = C−1
x
y
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
ρ =0.001
x
y
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
ρ =0.004
x
y
FIGURE 7.22
Optimal links conﬁgurations for the SMP strategy using the data estimated covariance matrix 2C.
with different penalty coefﬁcients. More speciﬁcally, the network topologies shown in Figure 7.22 are
obtained by thresholding the values of the matrix Aop obtained through our SMP algorithm, i.e., the
coefﬁcients of matrix Aop are set to zero if |aop(i, j)| < 10−4. In the top right plot of Figure 7.22, it can
be noted that the precision matrix achieved with a null penalty can be quite dense because of estimation
errors. Nevertheless, it is interesting to observe that, as the penalty coefﬁcient increases, the proposed
method is not only able to recover the desired topology, but also to correct most of the errors due to
estimation. We can say that the introduction of the penalty induces a robustness against estimation errors.
Let us now compare the SMP method with the SES strategy, by considering a data estimated covariance
matrix in the divergence term and averaging the simulation results over 100 independent realizations
of the nodes deployment. Let us now evaluate the mismatch between the network topology and the

398
CHAPTER 7 Distributed Detection and Estimation
0
0.01
0.02
0.03
0.04
0.05
0.06
0.07
0.08
0.09
0.1
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
ρ
ηI
SES
SMP
= 0 .2
SMP
= 0 .4
FIGURE 7.23
Fraction of incorrect links versus ρ for the SMP and SES strategies.
dependency graph, as a function of the penalty coefﬁcient, obtained using the two proposed strategies.
We assess the mismatch by counting the number of links appearing in the network topology, which do
not appear in the dependency graph. To this end, Figure 7.23 shows the fraction of incorrect links ηI,
normalized to the total number of links NT = N(N −1)/2, versus ρ. More speciﬁcally, considering
the true and optimal precision matrices (At and Aop respectively), we can deﬁne ηI =
N
i=1
N
j=1, j>i qi j
NT
where qi j = 1 if δ(at(i, j)) and δ(aop(i, j)) are not equal, assuming δ(ai j) = 1 if ai j > 0 and zero
otherwise. From Figure 7.23, we can deduce that SES provides more correct links than SMP, as it
achieves lower values of ηI.
2.07.9 Conclusions and further developments
In this article we have provided a general framework to show how an efﬁcient design of a wireless sensor
network requires a joint combination of in-network processing and communication. In particular, we
have shown that inferring the structure of the graph describing the statistical dependencies among
the observed data can provide important information on how to build the sensor network topology

Appendix A
399
and how to design the ﬂow of information through the network. We have illustrated several possible
network architectures where the global decisions, either estimation or hypothesis testing, are taken by
a central node or in a totally decentralized way. In particular, various forms of consensus have been
shown to be instrumental to achieve globally optimal performance through local interactions only.
Consensus algorithms have then been generalized to more sophisticated signal processing techniques
able to provide a cartography of the observed ﬁeld. In a decentralized framework, the network topology
plays an important role in terms of convergence time as well as structure of the ﬁnal consensus value.
Considering that most sensor networks exchange information through a wireless channel, we have
addressed the problem of ﬁnding the network topology that minimizes the energy consumption required
to reach consensus. Finally, we have showed how to match the network topology to the Markov graph
describing the observed variables, under constraints imposed by the power consumption necessary to
establish direct links among the sensor nodes.
Even though the ﬁeld of distributed detection and estimation has accumulated an enormous amount
of research works, there are still many open problems, both in the theoretical as well as in the application
sides. In the following we make a short list of possible topics of future interest.
1. The general multi-terminal source/channel coding problem is still an open issue. The conventional
paradigm established by the source/channel coding separation theorem does not hold for the multi-
terminal case. This means that source coding should be studied jointly with channel coding.
2. Distributed decision establishes a strict link between statistical signal processing and graph theory.
In particular, the network topology plays a fundamental role in the design of an efﬁcient sensor net-
work.Inthischapter,wehaveshownsomesimpletechniquesaimedtomatchingthenetworktopology
to the statistical dependency graph of the observed variables, but signiﬁcant improvements may be
expected from cross-fertilization of methods from graph theory and statistical signal processing.
3. The design of fully decentralized detection algorithms has already received important contributions.
Nevertheless, there are many open issues concerning the reﬁnements of the local decision thresholds
as a function of both local observations and the decisions taken from neighbors. In a more general
setting, social learning is expected to play an important role in future sensor networks.
4. An efﬁcient design of wireless sensor networks requires a strict relation between radio resource
allocation and decision aspects, under physical constraints dictated by energy limitations or channel
noise and interference. Some preliminary results have been achieved in the many-to-one setting, but
the general many-to-many case needs to be thoroughly studied.
5. The application of wireless sensor networks to new ﬁelds may be easily expected. The important
remark is that, to improve the efﬁciency of the network at various levels, it is necessary to take the
application needs strictly into account in the network design. In other words, a cross-layer design
incorporating all layers from the application down to the physical layer is especially required in
sensor networks. Clearly, handling the complexity of the network will require some sort of layering,
but this layering will not necessarily be the same as in telecommunication networks, because the
requirements and constraints in the two ﬁelds are completely different.
Appendix A
In this appendix we brieﬂy review some important notations and basic concepts of graph theory that
have been adopted in the previous sections (for a more detailed introduction to this ﬁeld see [13]).

400
CHAPTER 7 Distributed Detection and Estimation
A.1 Algebraic graph theory
Given N nodes let us deﬁne a directed graph or digraph G = {V, E} as a set of nodes V = {vi}N
i=1 and a set
of edges or links E ⊆V ×V where the links ei j ∈E connect the ordered pair of nodes (vi, v j), with the
convention that the information ﬂows from v j to vi. In the case where a positive weight ai j is associated
to each edge, the digraph is called weighted. Let us assume that there are no loops, i.e., aii = 0.
The graph is called undirected if ei j ∈E ⇔e ji ∈E. The in-degree and out-degree of node vi are,
respectively, deﬁned as degin ≜N
j=1 ai j and degout ≜N
j=1 a ji. In the case of undirected graphs
degin = degout. Let Ni denote the set of neighbors of node i, so that |Ni| ≜degin(vi).
The node vi of a digraph is said to be balanced if and only if its in-degree and out-degree coincide,
while a digraph is called balanced if and only if all its nodes are balanced.
We recall now the basic properties of the matrices associated to a digraph, as they play a fundamental
role in the study of the connectivity of the network associated to the graph. Given a digraph G, we
introduce the following matrices associated with G: (1) The N × N adjacency matrix A whose entries
ai j are equal to the weight associated to the edge ei j, or equal to zero, otherwise; (2) the degree matrix D
which is the diagonal matrix whose diagonal entries are dii = degin(vi) = N
j=1 ai j; (3) the weighted
Laplacian matrix L, deﬁned as L = D −A whose entries are
ℓi j =
*degin(vi) if
j = i,
−ai j
if
j ̸= i.
(7.178)
According to this deﬁnition L has the following properties: (a) its diagonal elements are positive; (b)
it has zero row sum; (c) it is a diagonally row dominant matrix. It can be easily veriﬁed that L1 = 0,10
i.e., zero is an eigenvalue of L corresponding to a right eigenvector 1 in the Null{L} ⊇span{1}, and all
the other eigenvalues have positive real parts. Furthermore a digraph is balanced if and only if 1 is also
a left eigenvector of L associated with the zero eigenvalue or 1T L = 0T . Note that for undirected graph
the Laplacian matrix is a symmetric and then balanced matrix with non negative real eigenvalues.
The algebraic multiplicity of the zero eigenvalue of L is equal to the number of connected components
contained in G. For undirected graphs G is connected if and only if the algebraic multiplicity of the zero
eigenvalue is 1, or, equivalently, rank(L) = N −1 if and only if G is connected. Hence, if an undirected
graph is connected, the eigenvector associated with the zero eigenvalue is 1, and the second smallest
eigenvalue of L, denoted as λ2(L) and called algebraic connectivity [22] of G, is strictly positive.
A.1.1
Forms of connectivity for digraphs
Before to introduce several forms of graph connectivity [17] we have to deﬁne some useful concepts. A
strong path of a digraph G is a sequence of distinct nodes v1, v2, . . . , vp ∈V such that (v j−1, v j) ∈E,
for j = 2, . . . , p. If v1 ≡vp, the path is said to be closed. A weak path is a sequence of distinct nodes
v1, v2, . . . , vp ∈V such that either (v j−1, v j) ∈E or (v j, v j−1) ∈E, for j = 2, . . . , p. A closed
strong path is said a strong cycle. A digraph with N nodes is a directed tree if it has N −1 edges and
there exists a node, called the root node, which can reach all the other nodes through an unique strong
path. As a consequence a directed tree contains no cycles and every node, except the root, has one and
only one incoming edge. A digraph is a forest if it consists of one or more directed trees. A subgraph
10We denote by 1 and 0 the vectors of all ones or zeros, respectively.

Appendix A
401
Gs = {Vs, Es} of a digraph G, with Vs ⊆V and Es ⊆E, is a directed spanning tree (or a spanning forest)
if it is a directed tree (or a directed forest) and it has the same node set as G.
According to this deﬁnition we can deﬁne many forms of connectivity [17]: (a) a digraph is strongly
connected (SC) if any ordered pair of distinct nodes can be joined by a strong path; (b) a digraph is
quasi strongly connected (QSC) if, for every ordered pair of nodes vi and v j, there exists a node r that
can reach both vi and v j via a strong path; (c) a digraph is weakly connected (WC) if any ordered pair of
distinct nodes can be joined by a weak path; (d) a digraph is disconnected if it is not weakly connected.
Note that for undirected graphs, the above notions of connectivity are equivalent. Moreover, it is easy to
check that the quasi strong connectivity of a digraph is equivalent to the existence of a directed spanning
tree in the graph.
A.1.2
Connectivity study from the condensation digraph
When a digraph G is WC, it may still contain strongly connected subgraphs. A maximal subgraph of
G, which is also SC, is called a strongly connected component (SCC) of G [17,88]. Any digraph G can
be partitioned into SCCs, let us say Gk = {Vk, Ek} where Vk ⊆V and Ek ⊆E for k = 1, . . . ,r. The
connectivity properties of a digraph may be better studied by referring to its corresponding condensation
digraph.WemayreducetheoriginaldigraphG tothecondensationdigraphG∗= {V∗, E∗}byassociating
the node set Vk of each SCC Gk of G to a single distinct node v∗
k ∈V∗
k of G∗and introducing an edge in
G∗from v∗
i to v∗
j, if and only if there exists some edges from the SCC Gi and the SCC G j of the original
graph. An SCC that is reduced to the root of a directed spanning tree of the condensation digraph is called
the root SCC (RSCC). Looking at the condensation graph, we may identify the following topologies
of the original graph: (1) G is SC if and only if G∗is composed by a single node; (2) G is QSC if and
only if G∗contains a directed spanning tree; (3) if G is WC, then G∗contains either a spanning tree or
a (weakly) connected forest.
The multiplicity of the zero eigenvalue of L is equal to the minimum number of directed trees
contained in a directed spanning forest of G. Moreover, the zero eigenvalue of L is simple if and only
if G contains a spanning directed tree or, equivalently, G is QSC. If G is SC then L has a simple zero
eigenvalue and positive left-eigenvector associated to the zero eigenvalue. If G is QSC [17] with Q ≥1
strongly connected components Gi ≜{Vi, Ei} with Vi ⊆V, Ei ⊆E for i = 1, . . . , Q, |Vi| = ri and

i ri = N, numbered w.l.o.g. so that G1 coincides with the root SCC of G, then the left-eigenvector
γ = [γ1, . . . , γN]T of L associated to the zero eigenvalue has entries γi > 0 iff vi ∈V1 and zero
otherwise. If G1 is balanced then γ r1 = [γ1, . . . , γr1]T ∈span{1r1} where r1 ≜|V1|.
As a numerical example, in Figure 7.24 we report three network topologies: (a) a SC digraph; (b) a
QSC digraph with three SCCs; (c) a WC digraph with a two-trees forest. We have also depicted for
each digraph its decomposition into SCCs corresponding to the nodes of the associated condensation
digraph; RSCC denotes the root SCC. For each network topology, we have also reported the dynamical
evolution of the consensus algorithm in (7.23) versus time. It can be observed that the dynamical system
in Figure 7.24a achieves a global consensus since the underlying digraph is SC. For the QSC digraph
in Figure 7.24b, instead, there is a set of nodes in the RSCC component that is able to reach all other
nodes so that the dynamical system can achieve a global consensus. Finally, in Figure 7.24c, the system
cannot achieve a global consensus since there is no node that can reach all the others. Although we
can observe two disjoint clusters corresponding to the two RSCC components, the nodes of the SCC

402
CHAPTER 7 Distributed Detection and Estimation
1
2
3
9
11
4
8
10
7
6
5
0
10
20
30
40
50
60
30
35
40
45
50
55
60
65
iteration index
xi(t)
1
2
3
9
11
4
8
10
7
6
5
scc 1
scc 2
RSCC
0
10
20
30
40
50
60
25
30
35
40
45
50
55
60
65
70
iteration index
xi(t)
1
2
3
9
11
4
8
10
7
6
5
RSCC2
RSCC1
SCC
0
10
20
30
40
50
60
20
25
30
35
40
45
50
55
60
65
70
iteration index
xi(t)
RSCC1
RSCC2
(a)
(b)
(c)
FIGURE 7.24
Consensus for different network topologies: (a) SC digraph; (b) QSC digraph with three SCCs; (c) WC digraph
with a forest.

Appendix A
403
component (middle lines) are affected by the consensus in the two RSCC components but are not able
to inﬂuence them.
A.2 RGG adjacency matrix
A random graph is obtained by distributing N points randomly over the d-dimensional space Rd and
connecting the nodes according to a given rule. The graph topology is captured by the adjacency matrix
A which, in this case, is a random matrix. An important class of random matrices, is the so called
Euclidean Random Matrix (ERM) class, introduced in [89]. Given a set of N points located at positions
xi, i = 1, . . . , N, an N × N adjacency matrix A is an ERM if its generic (i, j) entry depends only
on the difference xi −x j, i.e., ai j = F(xi −x j), where F is a measurable mapping from Rd to R.
An important subclass of ERM is given by the adjacency matrices of the so called Random Geometric
Graphs (RGG). In such a case, the entries ai j of the adjacency matrix are either zero or one depending
only on the distance between nodes i and j, i.e.,
ai j = F(xi −x j) =
* 1 if ∥xi −x j∥≤r,
0 otherwise,
(7.179)
where r is the coverage radius. Next we discuss some important properties of the spectrum of the
adjacency matrix of a random geometric graph.
A.2.1
Spectrum of a random geometric graph
Assuming that the RGG G(N,r) is connected with high probability, we have derived in [77] an analytical
expression for the algebraic connectivity of the graph, i.e., the second eigenvalue of the symmetric
Laplacian, L = D −A, where D is the degree matrix and A is the adjacency matrix. From (7.159),
D = πr2N I, so that we only need to investigate the second largest eigenvalue of A. Hence, let us
start by studying the spectrum of A as discussed in [77]. In [90,91], it is shown that the eigenvalues
of the adjacency matrix tend to be concentrated, as the number of nodes tend to inﬁnity. In particular,
in [90] it is shown that the eigenvalues of the normalized adjacency matrix AN = A/N of an RGG
G(N,r), composed of points uniformly distributed over a unitary two-dimensional torus, tend to the
Fourier series coefﬁcients of the function F deﬁned in (7.179),
ˆF(z) =
)
r
exp (−2π j zT x)dx
(7.180)
almost surely, for all z = [z1, z2] ∈Z2, where r = {x = [x1, x2]T ∈R2 : ∥x∥≤r}. Using polar
coordinates, i.e., x1 = ρ sin θ and x2 = ρ cos θ, with 0 ≤ρ ≤r and 0 ≤θ ≤2π , we obtain
ˆF(z) =
) r
0
) 2π
0
exp (−2π jρ(z1 sin θ + z2 cos θ))ρdρdθ.
This integral can be computed in closed form. Setting z1 = A sin φ and z2 = A cos φ, we have
ˆF(A, φ) =
) r
0
) 2π−φ
−φ
exp (−2π jρ A cos (ξ))ρdρdξ

404
CHAPTER 7 Distributed Detection and Estimation
with ξ = θ −φ. Furthermore, using the integral expression for the Bessel function of the ﬁrst kind of
order k, Jk(x) =
1
2π
, π
−π exp ( jx sin (ξ) −jkξ)dξ, we get
ˆF(A, φ) = ˆF(A) = 2π
) r
0
J0(2πρ A)ρ dρ.
Finally, using the identity
, u
0 vJ0(v)dv = uJ1(u), we can make explicit the dependence of ˆF(A) on
the index pair [z1, z2]
ˆF(z1, z2) =
r
-
z2
1 + z2
2
J1

2πr
-
z2
1 + z2
2

.
(7.181)
This formula allows us to rank the eigenvalues of AN = A/N. In particular, we are interested in the
second largest eigenvalue of AN. Considering that the minimum coverage radius ensuring connectivity
behaves as r(N) ∼
-
log (N)
N
, i.e., it is a vanishing function of N, we can use the Taylor series expansion
of ˆF(z1, z2), for small r. Recalling that, for small x, J1(x) = x/2−x3/16+o(x5), we can approximate
the eigenvalues as
ˆF(z1, z2) = πr2 −π3(z2
1 + z2
2)r4
2
+ o(r6).
(7.182)
Thisexpansionshowsthat,atleastforsmallr,thelargesteigenvalueequalsπr2 andoccursat z1 = z2 = 0,
whereas the second largest eigenvalue corresponds to the cases (z1 = 1, z2 = 0) and (z1 = 0, z2 = 1).
More generally, we can check numerically that, for r ≤1/2 and A ≥1, the following inequalities hold
true:
πr2 ≥r J1(2πr) ≥r
A |J1(2πr A)| .
(7.183)
In summary, denoting the spectral radius of AN as ζ1(AN) = max1≤i≤N
|λi(N)|
N
, where {λi(N)}N
i=1
is the set of eigenvalues of A, it follows that
lim
N→∞ζ1(AN) = max
z∈Z2 | ˆF(z)| = ˆF(0, 0) = πr2,
(7.184)
while the second largest eigenvalue of AN, ζ2(AN), converges to
lim
N→∞ζ2(AN) = ˆF(1, 0) = ˆF(0, 1) = r J1(2πr).
(7.185)
We are now able to derive the asymptotic expression for the second largest eigenvalue of the nor-
malized Laplacian LN = DN −AN, where DN := D/N is the normalized degree matrix. Because of
the asymptotic property of the degree of an RGG, shown in (7.159), the second largest eigenvalue of
LN tends asymptotically to
λ2(LN) = πr2 −ζ2(AN).
(7.186)
Thus, the algebraic connectivity of the graph can be approximated, asymptotically, as
λ2(L) = π Nr2 −Nr J1(2πr).
(7.187)

References
405
References
[1] I.F. Akyildiz, W. Su, Y. Sankarasubramaniam, E. Cayirci, Wireless sensor networks: a survey, Comput.
Networks (2002) 393–422.
[2] A. Giridhar, P.R. Kumar, Toward a theory of in-network computation in wireless sensor networks, IEEE
Commun. Mag. (2006) 98–107.
[3] P. Gupta, P. Kumar, Critical power for asymptotic connectivity in wireless networks, in: W. McEneaney,
G. Yin, Q. Zhang (Eds.), Stochastic Analysis, Control, Optimization and Applications: A Volume in Honor
of W.H. Fleming, Boston, MA, Birkhauser, 1998.
[4] A. Giridhar, P.R. Kumar, Computing and communicating functions over sensor networks, IEEE J. Sel. Areas
Commun. (2005) 755–764.
[5] S.M. Kay, Fundamentals of Statistical Signal Processing, Detection Theory, vol II, Prentice-Hall PTR,
Englewood Cliffs, NJ, 1998.
[6] J. Whittaker, Graphical Models in Applied Multivariate Statistics, John Wiley & Sons, 1990.
[7] S.L. Lauritzen, Graphical Models, Oxford University Press, 1996.
[8] A. Anandkumar, L. Tong, A. Swami, Detection of GaussMarkov random ﬁelds with nearest-neighbor depen-
dency, IEEE Trans. Inform. Theory 55 (2009) 816–827.
[9] A. Anandkumar, J.E. Yukich, L. Tong, A. Swami, Energy scaling laws for distributed inference in random
fusion networks, IEEE J. Sel. Areas Commun. (2009) 1203–1217.
[10] O.P. Kreidl, A.S. Willsky, An efﬁcient message-passing algorithm for optimizing decentralized detection
networks, IEEE Trans. Autom. Contr. (2010) 563–578.
[11] M. Gastpar, Information-theoretic bounds on sensor network performance, in: A. Swami, Q. Zhao, Y.-W.
Hong, L. Tong (Eds), Wireless Sensor Networks—Signal Processing and Communications Perspectives, John
Wiley & Sons, 2007 (Chapter 2).
[12] T.M. Cover, J.A. Thomas, Elements of Information Theory, John Wiley & Sons, Hoboken, NJ, 2006.
[13] C. Godsil, G. Royle, Algebraic Graph Theory, Springer, New York, 2001.
[14] W. Ren, R.W. Beard, E.M. Atkins, Information consensus in multivehicle cooperative control: collective group
behavior through local interaction, IEEE Control Syst. Mag. 27 (2) (2007) 71–82.
[15] R. Olfati-Saber, J.A. Fax, R.M. Murray, Consensus and cooperation in networked multi-agent systems, Proc.
IEEE 95 (2007) 215–233.
[16] S. Barbarossa, G. Scutari, Decentralized maximum-likelihood estimation for sensor networks composed of
nonlinearly coupled dynamical systems, IEEE Trans. Signal Process. 55 (7) (2007) 3456–3470.
[17] G. Scutari, S. Barbarossa, L. Pescosolido, Distributed decision through self-synchronizing sensor networks
in the presence of propagation delays and asymmetric channels, IEEE Trans. Signal Process. 56 (4) (2008)
1667–1684.
[18] A. Jadbabaie, S. Morse, Coordination of groups of mobile autonomous agents using nearest neighbor rules,
IEEE Trans. Auto. Control 48 (2003) 988–1001.
[19] L. Xiao, S. Boyd, Fast linear iterations for distributed averaging, Syst. Control Lett. 53 (2004) 65–78.
[20] A. Nedi´c, Asuman Ozdaglar, Cooperative distributed multi-agent optimization, in: D.P. Palomar, Y.C. Eldar,
Convex Optimization in Signal Processing and Communications, Cambridge University Press, 2010.
[21] S. Sardellitti, M. Giona, S. Barbarossa, Fast distributed average consensus algorithms based on advection-
diffusion processes, IEEE Trans. Signal Process. 58 (2) (2010) 826–842.
[22] M. Fiedler, Algebraic connectivity of graphs, J. Czech. Math. 23 (1973) 298–305.
[23] R. Horn, C.R. Johnson, Matrix Analysis, Cambridge University Press, 1985.

406
CHAPTER 7 Distributed Detection and Estimation
[24] Y. Hatano, A.K. Das, M. Mesbahi, Agreement in presence of noise: pseudogradients on random geometric
networks, in: Proceedings of the IEEE Conference on Decision and Control (CDC), Seville, Spain, 2005,
pp. 6382–6387.
[25] A. Tahbaz Salehi, A. Jadbabaie, On consensus over random networks, in: Proceedings of the 44th Allerton
Conference, UIUC, Illinois, USA, 2006, 27–29.
[26] A. Tahbaz Salehi, A. Jadbabaie, Consensus over ergodic stationary graph processes, IEEE Trans. Automat.
Contr. 55 (1) (2010).
[27] T.C. Aysal, M. Coates, M. Rabbat, Distributed average consensus using probabilistic quantization, in: Pro-
ceedings of the IEEE/SP Workshop on Statistical Signal Processing Workshop (SSP), Maddison, Wisconsin,
USA, 2007, pp. 640–644.
[28] M. Huang, J. Manton, Stochastic approximation for consensus seeking: mean square and almost sure con-
vergence, in: Proceedings of the IEEE Conference on Decision and Control (CDC), New Orleans, LA, USA,
2007, pp. 306–311.
[29] S. Kar, J.M.F. Moura, Distributed consensus algorithms in sensor networks with imperfect communication:
link failures and channel noise, IEEE Trans. Signal Process. 57 (5) (2009) 355–369.
[30] S.P. Lipshitz, R.A. Wannamaker, J. Vanderkooy, Quantization and dither: a theoretical survey, J. Audio Eng.
Soc. 40 (1992) 355–375.
[31] R. Wannamaker, S. Lipshitz, J. Vanderkooy, J. Wright, A theory of nonsubtractive dither, IEEE Trans. Signal
Process. 48 (2) (2000) 499–516.
[32] L. Schuchman, Dither signals and their effect on quantization noise, IEEE Trans. Commun. Technol. COMM-
12 (1964) 162–165.
[33] B. Polyak, Introduction to Optimization, Optimization Software Inc., New York, 1987.
[34] S. Barbarossa, G. Scutari, Bio-inspired sensor network design: distributed decision through self-
synchronization, IEEE Signal Process. Mag. 24 (3) (2007) 26–35.
[35] I.D. Schizas, A. Ribeiro, G.B. Giannakis, Consensus in Ad Hoc WSNs with noisy links: Part I—Distributed
estimation of deterministic signals, IEEE Trans. Signal Process. 56 (2008) 350–364.
[36] I.D. Schizas, G.B. Giannakis, S.I. Roumeliotis, A. Ribeiro, Consensus in Ad Hoc WSNs With noisy links:
Part II—Distributed estimation and smoothing of random signals, IEEE Trans. Signal Process. 56 (2) (2008)
1650–1666.
[37] F. Cattivelli, C.G. Lopes, A.H. Sayed, Diffusion recursive least-squares for distributed estimation over adaptive
networks, IEEE Trans. Signal Process. 56 (5) (2008) 1865–1877.
[38] P. Braca, S. Marano, V. Matta, Enforcing consensus while monitoring the environment in wireless sensor
networks, IEEE Trans. Signal Process. 56 (7) (2008) 3375–3380.
[39] A.G. Dimakis, S. Kar, J.M.F. Moura, M.G. Rabbat, A. Scaglione, Gossip algorithms for distributed signal
processing, Proc. IEEE 98 (11) (2010) 1847–1864.
[40] A. Bertrand, M. Moonen, Consensus-based distributed total least squares estimation in Ad Hoc wireless sensor
networks, IEEE Trans. Signal Process. 59 (5) (2011) 2320–2330.
[41] L. Li, A. Scaglione, J.H. Manton, Distributed principal subspace estimation in wireless sensor networks, IEEE
J. Sel. Top. Signal Process. 5 (4) (2011) 725–738.
[42] S. Kar, J.M.F. Moura, K. Ramanan, Distributed parameter estimation in sensor networks: nonlinear observation
models and imperfect communication, IEEE Trans. Inform. Theory 58 (2012) 3575–3605.
[43] G. Mateos, I.D. Schizas, G.B. Giannakis, Distributed recursive least-squares for consensus-based in-network
adaptive estimation, IEEE Trans. Signal Process. 57 (11) (2009) 4583–4588.
[44] S.M. Kay, Fundamentals of Statistical Signal Processing, Estimation Theory, vol I, Prentice-Hall PTR,
Englewood Cliffs, NJ, 1993.
[45] D.P. Bertsekas, J.N. Tsitsiklis, Parallel and Distributed Computation: Numerical Methods, Athena Scientiﬁc,
Belmont, MA, 1989.

References
407
[46] S. Boyd, N. Parikh, E. Chu, Distributed Optimization and Statistical Learning Via the Alternating Direction
Method of Multipliers, Now Publishers, May 2011.
[47] R. Tibshirani, Regression Shrinkage and Selection via the Lasso, J. Roy. Stat. Soc. 58 (1996) 267–288.
[48] G. Mateos, J.A. Bazerque, G.B. Giannakis, Distributed sparse linear regression, IEEE Trans. Signal Process.
58 (2010) 5262–5276.
[49] J.J. Xiao, S. Cui, Z.Q. Luo, A.J. Goldsmith, Power scheduling of universal decentralized estimation in sensors
networks, IEEE Trans. Signal Process. 54 (2) (2006) 413–422.
[50] P.K. Varshney, Distributed Detection and Data Fusion, Springer-Verlag, New York, 1997.
[51] R. Viswanathan, P.K. Varshney, Distributed detection with multiple sensors: Part I—Fundamentals, Proc.
IEEE 85 (1997) 54–63.
[52] R.S. Blum, S.A. Kassam, H.V. Poor, Distributed detection with multiple sensors: Part II—Advanced topics,
Proc. IEEE 85 (1997) 64–79.
[53] J.F. Chamberland, V. Veeravalli, Wireless sensors in distributed detection applications, IEEE Signal Process
Mag. (2007) 16–25.
[54] J.F. Chamberland, V. Veeravalli, Decentralized detection in sensor networks, IEEE Trans. Signal Process.
(2003) 407–416.
[55] J.F. Chamberland, V. Veeravalli, Asymptotic results for decentralized detection in power constrained wireless
sensor networks, IEEE J. Sel. Areas Commun. (2004) 1007–1015.
[56] P. Willett, P.F. Swaszek, R.S. Blum, The good, bad, and ugly: distributed detection of a known signal in
dependent gaussian noise, IEEE Trans. Signal Process. (2000) 3266–3278.
[57] J.F. Chamberland, V. Veeravalli, How dense should a sensor network be for detection with correlated obser-
vations? IEEE Trans. Inform. Theory (2006) 5099–5106.
[58] A. Anandkumar, L. Tong, A. Swami, Energy efﬁcient routing for statistical inference of Markov random ﬁelds,
in: Proceedings of CISS 2007, Baltimore, 2007, pp. 643–648.
[59] M. Alanyali, V. Saligrama, O. Savas, S. Aeron, Distributed Bayesian hypothesis testing in sensor networks,
in: Proceedings of the American Control Conference, Boston, MA, vol. 6, 2004, pp. 5369–5374.
[60] V. Saligrama, M. Alanyali, O. Savas, Distributed detection in sensor networks with packet losses and ﬁnite
capacity links, IEEE Trans. Signal Process. 54 (11) (2006) 4118–4132.
[61] S.A. Aldosari, J.M.F. Moura, Topology of sensor networks in distributed detection, in: Proceedings of the
IEEE International Conference on Acoustic Speech Signal Processing (ICASSP), Toulouse, France, 2006,
pp. V1061–V1064.
[62] S. Kar, J.M.F. Moura, Consensus based detection in sensor networks: topology optimization under practical
constraints, Workshop Information Theory in Sensor Networks, Santa Fe, NM, 2007.
[63] D. Bajovic, D. Jakovetic, J. Xavier, B. Sinopoli, J.M.F. Moura, Distributed detection via gaussian running
consensus: large deviations asymptotic analysis, IEEE Trans. Signal Process. 59 (2011) 4381–4396.
[64] F. Cattivelli, A.H. Sayed, Distributed detection over adaptive networks using diffusion adaptation, IEEE Trans.
Signal Process. 59 (5) (2011) 1917–1932.
[65] L. Xiao, S. Boyd, S. Lall, A space-time diffusion scheme for peer-to-peer least-squares estimation, in: Pro-
ceedings of International Conference on Information Processing in Sensor Networks, Nashville, TN, 2006,
pp. 168–176.
[66] S. Marano, V. Matta, P. Willett, L. Tong, Cross-layer design of sequential detectors in sensor networks, IEEE
Trans. Signal Process. 54 (2006) 4105–4117.
[67] Y. Mei, Asymptotic optimality theory for decentralized sequential hypothesis testing in sensor networks, IEEE
Trans. Inform. Theory 54 (2008) 2072–2089.
[68] Sardellitti, S.; Barbarossa, S.; Pezzolo, L. Distributed double threshold spatial detection algorithms in wireless
sensor networks, in: Proceedings of the IEEE 10th Workshop on Signal Processing Advances in Wireless
Communication (SPAWC ’09), Perugia, Italy, 2009, pp. 51–55.

408
CHAPTER 7 Distributed Detection and Estimation
[69] J.N. Tsitsiklis, Decentralized detection, Adv. Stat. Signal Process. 2 (1993) 297–344.
[70] J.N. Tsitsiklis, Decentralized detection by a large number of sensors, Math. Control Signal Syst. 1 (2) (1988)
167–182.
[71] R.R. Tenney, N.R. Sandell, Jr., Detection with distributed sensors, IEEE Trans. Aerosp. Electron. Syst. 17
(1981) 98–101.
[72] S. Barbarossa, G. Scutari, T. Battisti, Distributed signal subspace projection algorithms with maximum con-
vergence rate for sensor networks with topological constraints, in: ICASSP 2009, 2009.
[73] D.S. Bernstein, Matrix Mathematics, Princeton University Press, 2005.
[74] S. Boyd, A. Ghosh, B. Prabhakar, D. Shah, Randomized gossip algorithms, IEEE Trans. Inform. Theory 52
(2006) 2508–2530.
[75] S. Barbarossa, G. Scutari, T. Battisti, Cooperative sensing for cognitive radio using decentralized projec-
tion algorithms, in: IEEE 10th Workshop on Signal Processing in Wireless Communication, SPAWC’ 09,
pp. 116–120.
[76] S. Sardellitti, S. Barbarossa, A. Swami, Average consensus with minimum energy consumption: optimal
topology and power allocation, in: Proceedings of the European Signal Processing Conference (EUSIPCO
2010), Aalborg, Denmark, 2010, pp. 189–193.
[77] S. Sardellitti, S. Barbarossa, A. Swami, Optimal topology control and power allocation for minimum energy
consumption in consensus networks, IEEE Trans. Signal Process. 60 (1) (2012) 383–399.
[78] A. Jeﬂea, A Parametric study for solving nonlinear fractional problems, An. St. Univ. Ovidius Constanta 11
(2003) 87–92.
[79] W. Dinkelbach, On nonlinear fractional programming, Manag. Sci. 13 (1967) 492–498.
[80] Y. Hatano, M. Mesbahi, Agreement over random networks, IEEE Trans. Automat. Contr. 50 (2005)
1867–1872.
[81] T.C. Aysal, K.E. Barner, Convergence of consensus models with stochastic disturbances, IEEE Trans. Inform.
Theory 56 (2010) 4101–4113.
[82] S. Sardellitti, S. Barbarossa, Energy preserving matching of sensor network topology to the statistical graphical
model of the observed ﬁeld, in: 17th International Conference on Digital Signal Processing (DSP), Corfu,
Greece, 2011.
[83] S. Barbarossa, S. Sardellitti, Energy Preserving Matching of Sensor Network Topology to Dependency Graph
of the Observed Field, IEEE Trans. Signal Process. (in press).
[84] D. Donoho, Compressive sensing, IEEE Trans. Inform. Theory 52 (2006) 1289–1306.
[85] G.Gasso,A.Rakotomamonjy,S.Canu,Recoveringsparsesignalswithacertainfamilyofnon-convexpenalties
and DC programming, IEEE Trans. Signal Process. 57 (2009) 4686–4698.
[86] P.D. Tao, L.T.H. An, A D.C. optimization algorithms for solving the trust-region subproblem, SIAM J. Optim.
8 (1998) 476–505.
[87] R. Zdunek, A. Cichocki, Fast nonnegative matrix factorization algorithms using projected gradient approaches
for large-scale problems, Comput. Intell. Neurosci. (2008).
[88] R.A. Brualdi, H.J. Ryser, Combinatorial Matrix Theory, Cambridge University Press, Cambridge, UK, 1991.
[89] M. Mezard, G. Parisi, A. Zee, Spectra of Euclidean random matrices, Nuclear Phys. B 559 (1999) 689–701.
[90] C. Bordenave, Eigenvalues of Euclidean Random Matrices, Random Structures and Algorithms, vol. 33, John
Wiley & Sons, NY, USA, December 2008, pp. 515–532.
[91] S. Rai, The Spectrum of a random geometric graph is concentrated, J. Theor. Probab. 20 (2007) 119–132.

8
CHAPTER
Signal Processing and Optimal
Resource Allocation for the
Interference Channel
Mingyi Hong and Zhi-Quan Luo
Department of Electrical and Computer Engineering, University of Minnesota, Minneapolis, MN 55455, USA
2.08.1 Introduction
2.08.1.1 Resource allocation in communication networks
Resource allocation is a fundamental task in the design and management of communication networks.
For example, in a wireless network, we must judiciously allocate transmission power, frequency bands,
time slots, and transmission waveforms/codes across multiple interfering links in order to achieve high
system performance while ensuring user fairness and quality of service (QoS). The same is true in wired
networks such as the Digital Subscriber Lines (DSL).
The importance of resource allocation can be attributed to its key role in mitigating multiuser inter-
ference. The latter is the main performance limiting factor for heterogeneous wireless networks where
the number of interfering macro/pico/femto base stations (BS) can be very large. In addition, resource
allocation provides an efﬁcient utilization of limited resources such as transmission power and com-
munication spectrum. These resources are not only scarce but also expensive. In fact, wireless system
operators typically spend billions of dollars to acquire licenses to operate certain frequency bands.
Moreover, the rising cost of electricity for them to operate the infrastructure has already surpassed
the salary cost to employees in some countries. Thus, from the system operator’s perspective, efﬁcient
spectrum/power utilization directly leads to high investment return and low operating cost (see e.g.,
[1,2]). The transmission power of a mobile terminal is another scarce resource. In this case, careful and
efﬁcient power allocation is the key to effectively prolong the battery life of mobile terminals.
Current cellular networks allocate orthogonal resources to users. For example, in a time-division
multiplex access (TDMA) or a frequency-division multiplex access (FDMA) network, users in the
same cell transmit in different time slots/frequency bands, and users in the neighboring cells transmit
using orthogonal frequency channels. Although the interference from neighboring cells is suppressed,
the overall spectrum efﬁciency is reduced, as each BS only utilizes a fraction of the available spectrum.
According to a number of recent studies [3,4] current spectrum allocation strategies are not efﬁcient,
as at any given time and location, much of the allocated spectrum appears idle and unused. Moreover,
users in cell edges still suffer from signiﬁcant interference from non-neighboring cells, or pico/femto
cells. In addition, for cell edge users the signal power from their own cells are typically quite weak. All
of these factors can adversely affect their service quality.
To improve the overall system performance as well as user fairness, future wireless standards [5]
advocate the notion of a heterogeneous network, in which low-power BSs and relay nodes are densely
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-396500-4.00008-9
© 2014 Elsevier Ltd. All rights reserved.
409

410
CHAPTER 8 Signal Processing and Optimal Resource Allocation
deployed to provide coverage for cell edge and indoor users. This new paradigm of network design brings
the transmitters and receivers closer to each other, thus is able to provide high link quality with low
transmission power [6,7]. Unfortunately, close proximity of many transmitters and receivers also intro-
duces substantial in-network interference, which, if not properly managed, may signiﬁcantly affect the
system performance. Physical layer techniques such as multiple input multiple output (MIMO) antenna
arrays and multiple cell coordination will be crucial for effective resource allocation and interference
management in heterogeneous networks.
An effective resource allocation scheme should allow not only ﬂexible coordination among BS
nodes but also sufﬁciently distributed implementation. Coordination is very effective for interference
mitigation among interfering nodes (e.g., Coordinated Multi-Point (CoMP)), but is also costly in terms
of signaling overhead. For example, CoMP requires full BS coordination as well as the sharing of
transmit data among all cooperating BSs. In contrast, a distributed resource allocation requires far less
signaling overhead and no data sharing, albeit at the cost of possible performance loss. For in-depth
discussions of various design issues in heterogenous networks, we recommend the recent articles and
books including [7–13].
In this article, we examine several design and complexity aspects of the optimal physical layer
resource allocation problem for a generic interference channel (IC). The latter is a natural model for
multi-user communication networks. In particular, we characterize the computational complexity, the
convexity as well as the duality of the optimal resource allocation problem. Moreover, we summa-
rize various existing algorithms for resource allocation and discuss their complexity and performance
tradeoff. We also mention various open research problems throughout the article.
2.08.1.2 Notation
Throughout, we use bold upper case letters to denote matrices, bold lower case letters to denote vectors,
and regular lower case letters to denote scalars. For a symmetric (or Hermitian) matrix X, the notation
X ⪰0 (or X ≻0) signiﬁes X is positive semi-deﬁnite (or deﬁnite). User indices are denoted by
subscripts, while frequency tone indices are denoted by superscripts. Zero mean normalized complex
Gaussian distributions are denoted by CN(0, I).
2.08.1.3 Interference channels
An interference channel (IC) represents a communication network in which multiple transmitters simul-
taneously transmit to their intended receivers in a common channel. See Figure 8.1 for a graphical illus-
tration of the IC. Due to the shared communication medium, each transmitter generates interference
to all the other receivers. The IC model can be used to study many practical communication systems.
The simplest example is a wireless ad hoc network in which transmitters and their intended receivers
are randomly placed. When all these nodes are equipped with multiple antenna arrays, the channel
becomes a MIMO IC. See Figure 8.2 for a graphical illustration of a 2-user MIMO IC. If each trans-
mitter and receiver pair communicates over multiple parallel subchannels, the resulting overall channel
model becomes a parallel IC. This parallel IC model can be used to describe communication networks
employing Orthogonal Frequency Division Multiple Access (OFDMA) where the available spectrum
is divided into multiple independent tones/channels. Networks of this kind include the DSL network or
the IEEE 802.11× networks.

2.08.1 Introduction
411
FIGURE 8.1
The Interference Channel model. The solid lines represent the direct channels, while the dotted lines repre-
sent the interfering channels.
FIGURE 8.2
Illustration of a 2-user multiple input multiple output (MIMO) interference channel.
Another practical network is the multi-cell heterogenous wireless network. In the downlink of such
network a set of interfering transmitters (BSs) simultaneously transmit to their respective groups of
receivers. This channel is hitherto referred as an interfering broadcast channel (IBC). The uplink of this
network can be modeled as an interfering multiple access channel (IMAC). See Figures 8.3 and 8.4
for graphical illustrations of these two channel models. Note that both IMAC and IBC reduce to an IC
when there is only a single user in each cell.
Our ensuing discussions will be focussed on these channel models. We will illustrate key compu-
tational challenges associated with optimal resource allocation and suggest various practical resource
allocation approaches to overcome them.

412
CHAPTER 8 Signal Processing and Optimal Resource Allocation
FIGURE 8.3
The Interfering Broadcast Channel model. The solid lines represent the direct channels, while the dotted
lines represent the interfering channels.
FIGURE 8.4
The Interfering Multiple Access Channel model. The solid lines represent the direct channels, while the
dotted lines represent the interfering channels.
2.08.1.4 System model
We now give mathematical description for three types of IC model—the scalar, parallel and MIMO IC
models. Let us assume that there are K transmitter and receive pairs in the system, and we refer to each
transceiver pair as a user. Let K = {1, . . . , K} denote the set of all the users.
2.08.1.4.1
Scalar IC model
In a scalar IC model each user transmits and receives a scalar signal. Let xk ∈C denote user k’s
transmitted signal, and let pk = |xk|2 denote its power. Let ¯pk denote user k’s power constraint:
pk ≤¯pk. Let zk ∼CN(0, 1) denote user k’s normalized complex Gaussian noise with unit variance.
Note that we have normalized the power of the noise to unity. Let Hlk ∈C denote the channel between

2.08.1 Introduction
413
transmitter l and receiver k. Then user k’s received signal yk ∈C can be expressed as
yk =
Hkkxk
  
user k′s intended signal
+

l̸=k
Hlkxl



multiuser interference
+zk.
(8.1)
The signal to interference plus noise ratio (SINR) for user k is deﬁned as
SINRk =
|Hkk|2 pk
1 + 
l̸=k |Hlk|2 pl
.
(8.2)
We denote the collection of all the users’ transmit powers as p = [p1, . . . , pK ]T .
2.08.1.4.2
Parallel IC model
In a parallel IC model, the spectrum is divided into N independent non-overlapping bands, each giving
rise to a parallel subchannel. Let N denote the set of all subchannels. Let xn
k ∈C denote the transmitted
signal of user k on channel n, and let pn
k = |xn
k |2 denote its power. We use ¯pk to denote user k’s power
budget so that N
n=1 pn
k ≤¯pk. Let Hn
lk ∈C denote the channel coefﬁcient between the transmitter of
user l and the receiver of user k on channel n. Let zn
k ∼CN(0, 1) denote the Gaussian channel noise.
The received signal of user k on subchannel n, denoted as yn
k ∈C, can be expressed as
yn
k =
Hn
kkxn
k
  
user ks intended signal
+

l̸=k
Hn
lkxn
l



multiuser interference
+zn
k.
(8.3)
We deﬁne the collection of user k’s transmit power as pk =

p1
k, . . . , pN
k
	T , and deﬁne all the users’
transmit powers as p =

pT
1 , . . . , pT
K
	T .
2.08.1.4.3
MIMO IC model
In a MIMO IC model the receivers and transmitters are equipped with Nr and Nt antennas, respectively.
Let xk ∈CNt and yk ∈CNr denote the transmitted and received signal of user k. Let Hlk ∈CNr×Nt
represent the channel gain coefﬁcient matrix between transmitter l and receiver k.
Suppose each user k transmits/receives dk data streams, and let sk ∈Cdk×1 and ˆsk ∈Cdk×1 denote
the transmitted symbols and the received estimated symbols, respectively. Assume that the data vector
sk is normalized so that E[sksH
k ] = I, and that the data signals for different users are independent from
each other. Throughout this article, we will focus on linear strategies in which users use beamformers to
transmit and receive data symbols. Let Vk ∈CNt×dk and Uk ∈CNr×dk denote the transmit and receive
beamformers, respectively. Let zk ∼CN(0, INr ) denote the normalized complex Gaussian noise vector
at receiver k, where INr is the Nr × Nr identity matrix. Then the transmitted and received signal for
user k can be expressed as
xk = Vksk,
(8.4)

414
CHAPTER 8 Signal Processing and Optimal Resource Allocation
yk =
Hkkxk
  
user ks intended signal
+

l̸=k
Hlkxl



multiuser interference
+zk,
(8.5)
ˆsk = UH
k yk.
(8.6)
Let Qk = E[xkxH
k ] denote the covariance matrix of the transmitted signal of user k. We assume that
each transmitter has an averaged total power budget of the form
Tr(Qk) ≤¯pk,
k = 1, . . . , K.
(8.7)
When we have a single stream per user, Vk and Uk reduce to vectors vk ∈CNt×1 and uk ∈CNr×1.
In this case the SINR for user k’s stream can be deﬁned as
SINRk =
|uH
k Hkkvk|2
∥uk∥2 + 
l̸=k |uH
k Hlkvl|2 .
(8.8)
Multiple Input Single Output (MISO) IC is a special case of MIMO IC in which the receivers only
have a single antenna. In this case each user can only transmit a single stream (dk = 1, sk ∈C), and the
beamforming matrix Vk reduces to a beamforming vector vk ∈CNt×1. The channel coefﬁcient matrix
Hkl becomes a row vector hkl, the received signal yk reduces to a scalar, which can be expressed as
yk =
hkkxk
  
user k’s intended signal
+

l̸=k
hlkxl



multiuser interference
+zk.
(8.9)
The SINR for each user k can be expressed as
SINRk =
|hkkvk|2
1 + 
l̸=k |hlkvl|2 .
(8.10)
The power budget constraint becomes
∥vk∥2 ≤¯pk,
k = 1, . . . , K.
(8.11)
2.08.2 Information-theoretic results
2.08.2.1 Capacity results for IC model
In this subsection we brieﬂy review some information theoretical results related to the capacity of the
interference channel.
Consider a single user point to point additive white Gaussian noise (AWGN) scalar channel in the
following form
y = Hx + z,
(8.12)
where x, y, H, z are the transmitted signal, the received signal, the channel coefﬁcient, and the Gaussian
noise, respectively. Assume that the noise is independently distributed as z ∼CN(0, 1), and that the

2.08.2 Information-Theoretic Results
415
signal has a power constraint |x|2 ≤¯p. An achievable transmission rate R for this channel is deﬁned
as the rate that can be transmitted and decoded with diminishing error probability. The capacity of a
channel C is the supremum of all achievable rates. Let us deﬁne the signal to noise ratio (SNR) of the
channel as SNR = ¯p|H|2, then the capacity of the Gaussian channel is given by
C(SNR) = log2 (1 + SNR) bit per transmission.
(8.13)
We refer the readers’ to the classic books such as Cover Thomas [14] and the online course for an
introductory treatment of information theory.
Now consider a 2-user interference channel
y1 = H11x1 + H21x2 + z1,
y2 = H22x2 + H12x1 + z2.
(8.14)
The capacity region of this channel is the set of all achievable rate pairs of user 1 and user 2. Unlike
the previous point to point channel, the complete characterization of the capacity region in this simplest
2-user IC case is an open problem in information theory. The largest achievable rate region for the
interference channel is the Han-Kobayashi region [15], and it is achieved using superposition coding
and interference subtraction. Recently, Etkin et al. [16] showed that this inner region is within one bit of
the capacity region for scalar ICs. The capacity of the scalar interference channel under strong or very
strong interference has been found in [15,17,18]. In particular, in the very strong interference case, i.e.,
|H21|2
|H11|2 ≥1 + ¯p1 and |H12|2
|H22|2 ≥1 + ¯p2, the capacity region is given as
Rk ≤log2 (1 + |Hkk|2 ¯pk),
k = 1, 2,
(8.15)
where Rk is the transmission rate for user k. This result indicates that in very strong interference case the
capacity is not reduced. The references [19,20] include recent results that establish the capacity region
for more general MIMO and parallel ICs in the strong interference case. However, for the general case
where the interference is moderate, the capacity region remains unknown.
The capacity of a communication channel can be approximated by the notion of degrees of freedom.
Recall that in the high SNR regime the capacity of a point to point link can be expressed as
C(SNR) = d log2 (SNR) + o( log2 (SNR)).
(8.16)
In this case we say the channel has d degrees of freedom. In a 2-user interference channel, the degrees of
freedom region can be characterized as follows. Let the sum transmit power across all the transmitters
be ρ, and let Rk(ρ) denote the transmission rate achievable for user k. Then the capacity region C(ρ) of
this 2-user channel is the set of all achievable rate tuples (R1(ρ), R2(ρ)). The degree of freedom region
D for this channel approximates the capacity region, and is deﬁned as (see [21])
D =

(d1, d2) ∈R2
+ : ∀(w1, w2) ∈R2
+, w1d1 + w2d2
≤lim
ρ→∞sup

sup
(R1(ρ),R2(ρ))∈C(ρ)
[w1R1(ρ) + w2R2(ρ)]
1
log2 (ρ)

.
(8.17)

416
CHAPTER 8 Signal Processing and Optimal Resource Allocation
The goal of resource allocation is to achieve the optimal performance established by information
theory, subject to resource budget constraints. Unfortunately, optimal strategies for achieving the infor-
mation theoretic limits are often unknown, too difﬁcult to compute or too complicated to implement
in practice. For practical considerations, we usually rely on simple transmit/receive strategies (such
as linear beamformers) for resource allocation, with the goal of attaining an approximate information
theoretic performance bound. The latter can be in terms of the degrees of freedom or some approximate
capacity bounds which we describe next.
2.08.2.2 Achievable rate regions when treating interference as noise
Due to the difﬁculties in characterizing the capacity region and the optimal transmit/receive strategy for
a general interference channel, many works in the literature study simpliﬁed transmit/receive strategies
and the corresponding achievable rate regions. One such simpliﬁcation, which is well motivated from
practical considerations, is to assume that low-complexity single user receivers are used and that the
multiuser interference is treated as additive noise. The authors of [22,23] show that treating interference
as noise in a Gaussian IC actually achieves the sum-rate channel capacity if the channel coefﬁcients
and power constraints satisfy certain conditions. These results serve as a theoretical justiﬁcation for this
simpliﬁcation. In the rest of this article we will treat interference as noise at the receivers. Let us ﬁrst
review some achievable rate region results for different IC models with this simpliﬁed assumption.
2.08.2.2.1
Deﬁnition of rate region
Consider the 2-user scalar IC (8.14). The users’ transmission powers are constrained by 0 ≤p1 ≤¯p1
and 0 ≤p2 ≤¯p2, respectively. The following rates are achievable when the users treat their respective
interference as noise
R1(p1, p2) = log2 (1 + SINR1),
R2(p1, p2) = log2 (1 + SINR2),
where the term SINRk has been deﬁned in (8.2). The directly achievable rate region R is deﬁned as the
union of the achievable rate tuples (R1(p1, p2), R2(p1, p2))
R = {(R1(p1, p2), R2(p1, p2)) : 0 ≤p1 ≤¯p1, 0 ≤p2 ≤¯p2}.
(8.18)
The directly achievable rate region represents the set of achievable rates when the transmitters are
not able to synchronize with each other [24]. If transmitter synchronization is possible, time-sharing
among the extreme points of the directly achievable rate region can be performed. In this case, the
achievable rate region becomes the convex hull of the directly achievable rate region (8.18). Sometimes
for convenience, we will refer the directly achievable rate regions simply as rate regions. The exact
meaning of the rate region should be clear from the corresponding context.
For a parallel IC model, user k’s achievable rate on channel n, Rn
k , can be expressed as
Rn
k (pn
1, . . . , pn
K ) = log2

1 +
|Hn
kk|2 pn
k
1 + 
l̸=k|Hn
lk|2 pn
l

.
(8.19)

2.08.2 Information-Theoretic Results
417
User k’s achievable sum rate is the sum of the rates achievable on all the channels
Rk =
N

n=1
Rn
k (pn
1, . . . , pn
K ).
(8.20)
The directly achievable rate region R in this case can be expressed as
R =

(R1, · · · , RK ) :
N

n=1
pn
k ≤¯pk, pk ≥0, ∀k ∈K

.
(8.21)
For a MIMO IC model, user k’s achievable rate when treating all other users’ interference as noise is
Rk(Q1, . . . , QK ) = log2 det
⎛
⎜⎝INr + HkkQkHH
kk
⎛
⎝INr +

l̸=k
HlkQlHH
lk
⎞
⎠
−1⎞
⎟⎠.
(8.22)
The directly achievable rate region R can be expressed as
R = {(R1, . . . , RK ) : Tr(Qk) ≤¯pk, Qk ⪰0, ∀k ∈K}.
(8.23)
2.08.2.2.2
Characterization of the directly achievable rate regions
Resource allocation requires a good understanding of the achievable rate regions. The (directly achiev-
able) rate regions of the 2-user and the more general K-user scalar IC have been recently characterized
in [25,26]. We brieﬂy elaborate the 2-user rate region and its properties. Let (p1, p2) denote a point
in the rate region with x, y coordinates representing R1(p1, p2) and R2(p1, p2), respectively. Let
¯p1 = ¯p2 = ¯p. Deﬁne two functions 1(p2) = ( ¯p, p2) and 2(p1) = (p1, ¯p). Then the boundary
of the 2-user rate region consists of the union of two axis and the following two curves
1(p2) = log2
⎛
⎝1 +
|H22|2
|H21|2 (|H11|2 ¯p −(2R1 −1))
(2R1 −1)(1 + |H12|2 ¯p)
⎞
⎠,
0 ≤p2 ≤¯p,
(8.24)
2(p1) = log2
⎛
⎝1 +
|H22|2 ¯p
1 + |H12|2
|H11|2 (1 + |H21|2 ¯p)(2R1 −1)
⎞
⎠,
0 ≤p1 ≤¯p.
(8.25)
Each of the above two curves consists of the set of rates achievable by one transmitter using its full
power, while the other transmitter sweeping over its range of transmit powers. The convexity of this
2-user directly achievable rate region is studied in [25]. The following two conditions are sufﬁcient to
guarantee the convexity of the directly achievable rate region
∂21(p2)
∂R2
1

p2
< 0,
∀0 ≤p2 ≤¯p,
(8.26)
∂22(p1)
∂R2
1

p1
< 0,
∀0 ≤p1 ≤¯p.
(8.27)

418
CHAPTER 8 Signal Processing and Optimal Resource Allocation
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
R1
R2
A
C
Rate Region Fronteir α=1
Rate Region Fronteir α=0.1
Rate Region Fronteir α=2
Φ1
Φ2
Time Sharing Region Boundary
α=1
Time Sharing Region Boundary
α=2
FIGURE 8.5
The rate regions for a 2-user IC with different interference conditions. ¯p1 = ¯p2 = 1, |H11|2 = |H22|2 = 1,
|H12|2 = |H21|2 = α. At point A and C, a single user transmits using full power. The solid lines are the
directly achievable rate frontier. The dotted lines represents the rate boundary that can be achieved by time
sharing. Note that the time sharing boundary for α = 0.1 is the same as the rate region frontier.
In particular, a necessary condition for (8.26) and (8.27) is
|H22|2|H12|2 ¯p(1 + |H21|2 ¯p) −|H11|2(1 + |H22| ¯p) < 0
(8.28)
which requires that the maximum possible interference to be sufﬁciently small. As the interference
increases, the directly achievable rate regions become nonconvex. Figure 8.5 shows the transition of
the directly achievable rate regions as well as the time-sharing regions when the interference levels
change from strong to weak. Clearly, when the interference is strong (α = 2 in this ﬁgure), orthogonal
transmission such as TDMA or FDMA is optimal.
The same authors also characterize the achievable rate regions for the general K-user case. However
the conditions for the convexity of the K-user regions are not available and deserve investigation. These
conditions can be useful in solving resource allocation problems for an interference network.
More generally, it remains an open problem to derive a complete characterization of the (directly
achievable) rate region for a parallel IC. The exact conditions for its convexity (or the lack of) are still
unknown, although it is clear that the rate region will be convex if the interference coefﬁcients are
sufﬁciently small.
Several efforts have been devoted to characterizing certain interesting points (such as sum-rate
optimal point) on the Pareto boundary of the rate region. Hayashi and Luo [27] have shown that in a

2.08.2 Information-Theoretic Results
419
parallel IC model with channel gains satisfying the following strong interference conditions
|Hn
lk|2
|Hn
kk|2 > 1
2,
and
|Hn
lk|2
|Hn
kk|2
|Hn
kl|2
|Hn
ll |2 > 1
4

1 +
1
C −1
2
,
∀n ∈N, (l, k) ∈K × K
(8.29)
where C ≥2 is the minimum number of subchannels used by any user, then the sum rate maximization
point can only be achieved using an FDMA strategy. In the special case of 2-user N channel model, the
following condition is sufﬁcient for the optimality of FDMA strategy
|Hn
12|2
|Hn
22|2
|Hn
21|2
|Hn
11|2 > 1
4

1 +
1
C −1
2
,
∀n ∈N.
(8.30)
The MIMO IC model is even more general than the parallel IC, hence its achievable rate region is
also difﬁcult to characterize. To see this, assuming that Nt = Nr = N; let all the channel matrices be
diagonal: Hlk = diag

[H1
lk, . . . , H N
lk ]

, (l, k) ∈K×K; let all the transmission covariances be diagonal
aswell:Qk = diag

[p1
k, . . . , pN
k ]

, k ∈K.Inthissimpliﬁedmodel,userk’stransmissionratereducesto
Rk(Q1, . . . , QK ) = log2 det
⎛
⎜⎝HkkQkHH
kk
⎛
⎝INr +

l̸=k
HlkQlHH
lk
⎞
⎠
−1
+ INr
⎞
⎟⎠
=
N

n=1
log2

1 +
pn
k |Hn
kk|2
1 + 
l̸=k|Hn
lk|2 pn
l

(8.31)
which is exactly the rate expression for the N channel K user parallel IC as expressed in (8.19) and (8.20).
Larsson and Jorswieck [28,29] have characterized the achievable rate region of a 2-user MISO IC.
In this case, user k’s achievable transmission rate reduces to
Rk(v1, . . . , vk) = log2 (1 + SINRk),
(8.32)
where the SINR for user k is deﬁned in (8.10).
Deﬁne the maximum-ratio transmission (MRT) and the zero forcing (ZF) beamformers for both
users as
vMRT
1
= ¯p1
hH
11
∥hH
11∥,
vMRT
2
= ¯p2
hH
22
∥hH
22∥,
vZF
1
= ¯p1
⊥
hH
12hH
11
∥⊥
hH
12hH
11∥, vZF
2
= ¯p2
⊥
hH
21hH
22
∥⊥
hH
21hH
22∥,
(8.33)
where ⊥
X represents the orthogonal projection onto the complement of the column space of X. The
authors show that any point on the Pareto boundary is achievable with the beamforming strategy
v1(λ1) = ¯p1
λ1vZF
1 + (1 −λ1)vMRT
1
∥λ1vZF
1 + (1 −λ1)vMRT
1
∥,
v2(λ2) = ¯p2
λ2vZF
2 + (1 −λ2)vMRT
2
∥λ2vZF
2 + (1 −λ2)vMRT
2
∥,
(8.34)

420
CHAPTER 8 Signal Processing and Optimal Resource Allocation
where 0 ≤λ1, λ2 ≤1. Intuitively, it is clear that v1(λ1), v2(λ2) should stay in the subspace spanned by
the channel vectors hH
11, hH
22. Since this subspace is spanned by the MRT and ZF beamformers, it is no
surprise that v1(λ1), v2(λ2) can be written as linear combinations of the MRT and ZF beamformers. The
novelty of (8.34) lies in the claim that the parameters λ1, λ2 are real numbers and lie in the interval [0, 1].
Similar to the characterization (8.24) and (8.25) for the rate region of a scalar IC, the characterization
(8.34) of optimal beamforming strategy can be used to computationally determine the rate region for a
2-user MISO IC.
In [30], the authors extend their 2-user MISO channel work to a general K-user MISO IC. In particular,
any point in the achievable rate region can be achieved using a set of beamformers {vk}N
k=1 that is
characterized by K 2 complex numbers {ϵkl}(k,l)∈K×K as
vk =
K

l=1
ϵklhH
kl ,
∀k ∈K,
∥vk∥2 = ¯pk,
∀k ∈K.
However, because of the large number of (complex) parameters involved, this characterization appears
less useful computationally in the determination of the rate region. We refer the readers to the web pages
of Jorswieck and Larsson for more details. We emphasize again that except for these limited results, the
structure of a general MIMO IC rate region is still unknown when the interference is treated as noise.
2.08.3 Optimal resource allocation in interference channel
As is evident from the discussions in Section 2.08.2, the most interesting points on the boundaries of
the rate regions can only be achieved by careful resource allocation. In this section we discuss optimal
resource allocation schemes for the general IC models. Such optimality is closely related to the choice
of a performance metric for the communication system under consideration.
2.08.3.1 Problem formulations
A communication system should provide users with QoS guarantees, and fairness through efﬁcient
resource utilization. Mathematically, the resource allocation problem can be formulated as the problem
of optimizing a certain system level utility function subject to resource budget constraints.
A popular family of utility functions is the so called “α-fair" utility functions, which can be
expressed as
U

{Rk}K
k=1

=
K

k=1
(Rk)1−α
1 −α ,
(8.35)
where Rk denotes the transmission rate of user k. As pointed out in [31], different choices of the param-
eter α give different priorities to user fairness and overall system performance. We list four commonly
used utility functions that belong to the family of α-fair utility functions:
a. The sum rate utility: U1

{Rk}K
k=1

= K
k=1Rk, obtained by setting α = 0;

2.08.3 Optimal Resource Allocation in Interference Channel
421
0
0.2
0.4
0.6
0.8
0
0.2
0.4
0.6
0.8
0
1
1
0.8
0.6
0.4
0.2
1
1
1.5
0.5
1
P1
P2
0.2
0.4
0.6
0.8
1
1.2
1.4
0
0.2
0.4
0.6
0.8
1
0
0
0.2
0.4
0.6
0.8
P1
P2
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
R1+R2
R1+R2
FIGURE 8.6
The sum rate utility for a 2-user scalar IC with different interference conditions. ¯p1 = ¯p2 = 1, |H11|2 =
|H22|2 = 1, |H12|2 = |H21|2 = α. In the left panel, α = 0.5. In the right panel, α = 5.
b. The proportional fair utility: U2

{Rk}K
k=1

= K
k=1 ln (Rk), obtained by letting α →1;
c. The harmonic-rate utility: U3

{Rk}K
k=1

=
K
k=1R−1
k
−1
, obtained by setting α = 2;
d. The min-rate utility (α →∞): U4

{Rk}K
k=1

= min1≤k≤K Rk, obtained by letting α →∞.
In terms of overall system performance, these utility functions can be ordered as
U1 ≥U2 ≥U3 ≥U4.
(8.36)
In terms of user fairness, the order is reversed. We note that except for the case in which the interference
is weak, these utility functions are nonconcave in general. For example, in Figure 8.6 we plot the sum rate
utility for a 2-user scalar IC in cases where the interference is either weak or strong. Moreover, in most
cases, it is not possible to represent these utility functions as concave ones via a nonlinear transformation.
See [32] for an impossibility result in scalar interference channel. This is consistent with the complexity
status (NP-hard) of the utility maximization problems [33–35] (see discussions in Section 2.08.3.2).
If we wish to ﬁnd a resource allocation scheme that maximizes the system level performance,
then we need to determine the conditions under which the system level problem is easy to solve.
Whenever such conditions are met, efﬁcient system level resource allocation decision can be carried out
by directly solving a convex optimization problem. Intuitively, when the crosstalk coefﬁcients are zero or
sufﬁciently small (low interference regime), the utility functions should be concave. It will be interesting
to analytically determine how small the crosstalk coefﬁcients need to be in order to preserve concavity.
From a practical perspective, the conditions for the concavity of the utility function (in terms of the
crosstalk coefﬁcients) are valuable because they can be used to ﬁnd high quality approximately optimal
resource allocation schemes. In particular, we can use these conditions to partition the users into small
groups within which the interference is less and resource allocation is easy. Different groups can be
put on orthogonal resource dimensions, because the groups cause too much interference to each other.
Ultimately a good resource allocation scheme in an interference limited network will likely involve a
hybrid scheme whereby some small groups of users share resources, while different groups are separated
from competition.

422
CHAPTER 8 Signal Processing and Optimal Resource Allocation
The lack of concavity (or more generally, the lack of concave reformulation/transformation) has
made it difﬁcult to numerically maximize these utility functions for resource allocation. To circum-
vent the computational difﬁculties, and to reduce the amount of channel state information required
for practical implementation, some researchers have proposed to use alternative utility functions for
resource allocation. For example, both the mean squared error (MSE) and the leakage power cost
functions have been proposed as potential substitutes for the rate-based utility functions listed above
[36–39]. Recently, a number of studies [32,40–42] have characterized a family of system utility func-
tions that, under appropriate transformations, admit concave representations. Such transformations
allow the associated utility maximization problems to be easily solvable. We refer the readers to
Holger Boche’s web page for details on this topic. Unfortunately these utility functions are not directly
related to individual users’ transmission rates, hence the solutions of the associated optimization prob-
lems tend to give suboptimal system performance (in terms of the users’ achievable rates). We shall not
further elaborate on these resource allocation approaches in this article. Instead, we will focus on the
use of above listed rate-based utility functions for resource allocation.
Let us describe several utility maximization problems to be considered in this article.
1. Utility maximization for the scalar IC model:
max
{pk}k
U

{Rk}K
k=1

(8.37)
s.t. Rk = log2

1 +
|Hkk|2 pk
1 + 
l̸=k|Hlk|2 pl

,
k = 1, . . . , K,
0 ≤pk ≤¯pk,
k = 1, . . . , K.
2. Utility maximization for the parallel IC model:
max
{pn
k }k,n
U

{Rk}K
k=1

(8.38)
s.t. Rk =
N

n=1
log2

1 +
|Hn
kk|2 pn
k
1 + 
l̸=k|Hn
lk|2 pn
l

,
k = 1, . . . , K,
N

n=1
pn
k ≤¯pk,
k = 1, . . . , K,
pn
k ≥0,
(k, n) ∈K × N.
3. Utility maximization for the MISO IC model:
max
{vk}k
U

{Rk}K
k=1

(8.39)
s.t. Rk = log2

1 +
|hkkvk|2
1 + 
l̸=k|hlkvl|2

,
k = 1, . . . , K,
∥vk∥2 ≤¯pk,
k = 1, . . . , K.

2.08.3 Optimal Resource Allocation in Interference Channel
423
4. Utility maximization for the MIMO IC model:
max
{Qk}k
U

{Rk}K
k=1

(8.40)
s.t. Rk = log2 det
⎛
⎜⎝HkkQkHH
kk
⎛
⎝INr +

l̸=k
HlkQlHH
lk
⎞
⎠
−1
+ INr
⎞
⎟⎠,
k = 1, . . . , K,
Tr(Qk) ≤¯pk,
Qk ⪰0, k = 1, . . . , K.
5. Utility maximization for the MIMO IC model (single stream per user):
max
{(uk,vk)}K
k=1
U

{Rk}K
k=1

(8.41)
s.t. Rk = log2

1 +
|uH
k Hkkvk|2
∥uk∥2 + 
l̸=k|uH
k Hlkvl|2

,
k = 1, . . . , K,
∥vk∥2 ≤¯pk,
k = 1, . . . , K.
A “dual” paradigm for the design of the resource allocation algorithm is to provide QoS guarantees
to all the users while minimizing the total power consumption. This formulation traditionally ﬁnds
its application in voice communication networks where it is desirable to maintain a minimum
communication rate (or SINR level) for each user in the system. Deﬁne {γk}K
k=1 as the set of SINR
targets. We list several QoS constrained min-power problem to be considered in this article.
6. Power minimization for the scalar IC model:
min
K

k=1
pk
(8.42)
s.t. SINRk ≥γk,
k = 1, . . . , K,
SINRk =
|Hkk|2 pk
1 + 
l̸=k|Hlk|2 pl
,
k = 1, . . . , K.
7. Power minimization for the MISO IC model:
min
{vk}K
k=1
K

k=1
∥vk∥2
(8.43)
s.t. SINRk ≥γk,
k = 1, . . . , K,
SINRk =
|hkkvk|2
1 + 
l̸=k|hlkvl|2 ,
k = 1, . . . , K.
8.
Power minimization for the MIMO IC model (single stream per user):
min
{(uk,vk)}K
k=1
K

k=1
∥vk∥2
(8.44)

424
CHAPTER 8 Signal Processing and Optimal Resource Allocation
s.t. SINRk ≥γk,
k = 1, . . . , K,
SINRk =
|uH
k Hkkvk|2
∥uk∥2 + 
l̸=k|uH
k Hlkvl|2 ,
k = 1, . . . , K.
A hybrid formulation combines the above two approaches. It aims to provide QoS guarantees
while at the same time maximizing a system level utility function. This hybrid formulation is useful
in data communication networks where besides the minimum rate constraints, it is preferable to
deliver high system throughput. We list two such formulations to be considered later in this article.
9. Hybrid formulation for the scalar IC model:
max U

{pk}K
k=1

(8.45)
s.t. SINRk ≥γk,
k = 1, . . . , K,
0 ≤pk ≤¯pk,
k = 1, . . . , K.
10. Hybrid formulation for the parallel IC model:
max
{pn
k }k,n
U

{Rk}K
k=1

(8.46)
s.t. Rk =
N

n=1
log2

1 +
Hn
kk
2 pn
k
1 + 
l̸=k
Hn
lk
2 pn
l

,
k = 1, . . . , K,
Rk ≥ζk,
k = 1, . . . , K,
N

n=1
pn
k ≤¯pk,
k = 1, . . . , K,
pn
k ≥0,
(k, n) ∈K × N
where {ζk}K
k=1 is a set of rate targets.
We note that for the latter two formulations, the minimum rate/SINR requirements provide fairness
to the users, while the optimization objectives are aimed at efﬁcient utilization of system resource (e.g.,
spectrum or power). For both of these two problems, the feasibility of the set of rate/SINR targets needs
to be carefully examined, as the rate/SINR requirements may not be simultaneously satisﬁable.
2.08.3.2 Complexity of the optimal resource allocation problems
The aforementioned optimal resource allocation problems are nonconvex. However, the lack of convex-
ity does not necessarily imply that the problem is difﬁcult to solve. In some cases, it may be possible
for a nonconvex problem to be appropriately transformed into an equivalent convex one and solved efﬁ-
ciently. A principled approach to characterize the intrinsic difﬁculty of an utility maximization problem
is by way of the computational complexity theory [43].
In the following, we summarize a number of recent studies on the computational complexity status
of these resource allocation problems. These complexity results suggest that in most cases solving the
utility maximization problems to global optimality is computationally intractable as the number of users
in the system increases.

2.08.3 Optimal Resource Allocation in Interference Channel
425
Table 8.1 Complexity Status of Utility Maximization Problems for the Parallel and MISO IC
Models [33,34]
Utility Function
Proportional
Harmonic
Problem Class
Sum Rate
Fair
Mean
Min-Rate
Parallel IC, K = 1, N arbitrary
Convex opt
Convex opt
Convex opt
Convex opt
Parallel IC, K ≥2 ﬁxed, N arbitrary
NP-hard
NP-hard
NP-hard
NP-hard
Parallel IC, N ≥2 ﬁxed, K arbitrary
NP-hard
NP-hard
NP-hard
NP-hard
Parallel IC, N = 1, K arbitrary
NP-hard
Convex opt
Convex Opt
LP
MISO IC, Nt ≥2, K arbitrary
NP-hard
NP-hard
NP-hard
Poly. time solvable
Table 8.2 Complexity Status of the Min-Rate Utility Maximization for the MIMO IC Model
[35,44,45]
Nt
Nr
Nt = 1
Nt = 2
Nt ≥3
Nr = 1
Poly. time solvable
Poly. time solvable
Poly. time solvable
Nr = 2
Poly. time solvable
NP-hard
NP-hard
Nr ≥3
Poly. time solvable
NP-hard
NP-hard
Table 8.1 lists the complexity status for resource allocation problems with speciﬁc utility functions
for the parallel and MISO IC models. Note that the scalar IC model is included as a special case.
Table 8.2 summarizes the complexity status for the minimum rate utility maximization problem and
the sum power minimization problem with the QoS constraint in MIMO IC model (i.e., problem (8.41)
with min-rate utility and problem (8.44)). Note that the results in Table 8.2 are based on the assumption
that all transmitters and receivers use linear beamformers and that each mobile receives a single data
stream.
Recall that the MIMO IC is a generalization of the Parallel IC (see Section 2.08.2.2). It follows that
the complexity results in Table 8.1 hold true for the MIMO IC model with an arbitrary number of data
streams per user. We refer the readers to the author’s web page for recent developments in the com-
plexity analysis as well as other resource allocation algorithms.
2.08.3.3 Algorithms for optimal resource allocation
Wenowdescribevariousutilitymaximizationbasedalgorithmsforresourceallocation.Thesealgorithms
will be grouped and discussed according to their main algorithmic features. Since the min-rate utility
function is non-differentiable, it requires a separate treatment that is different from the other utility
functions. We begin our discussion with resource allocation algorithms based on the min-rate utility
maximization.

426
CHAPTER 8 Signal Processing and Optimal Resource Allocation
2.08.3.3.1
Algorithms for min-rate maximization
Early works on resource allocation aimed to ﬁnd optimal transmission powers that can maximize the
min-SINR utility. In case of the scalar IC, this problem can be formulated as
max{pk}k∈K min
k∈K SINRk
(8.47)
s.t. pk ≥0,
∀k ∈K,
SINRk deﬁned in (8.2).
In [46–48], the authors studied the feasibility of this problem and proposed optimal power allocation
strategies for it. For randomly generated scalar interference channels, they showed that with probability
one, there exists a unique optimum value to the above problem. This optimal value, denoted as γ ∗, can
be expressed as
γ ∗=
1
ρ(Z) −1
(8.48)
where ρ(Z) represents the maximum eigenvalue of the matrix Z; Z ∈RK×K is a matrix with its (k,l)th
element deﬁned as [Z]k,l =
|Hlk|2
|Hkk|2 . Distributed power allocation algorithms for this problem were
also developed. For example, Foschini Miljanic [46] proposed an autonomous power control (APC)
algorithm that iteratively adjusts the users’ power levels as follows
|Hkk|2 p(t+1)
k
1 + 
l̸=k|Hlk|2 p(t)
l
=
|Hkk|2 p(t)
k
1 + 
l̸=k|Hlk|2 p(t)
l
−β(SINR(t)
k −γ ∗),
(8.49)
where β is a small positive constant and t is the iteration index. We refer the readers to [49] and the
web page of Hanly for further discussion of power control techniques for a scalar IC.
For a MISO IC model, the problem of ﬁnding optimal transmit beamformers for the maximization
of the min-SINR utility has been considered by Bengtsson Ottersten [50] and Wiesel et al. [51]. The
corresponding resource allocation problem can be equivalently formulated as
max{vk}k∈K γ
(8.50)
s.t. SINRk ≥γ,
k = 1, . . . , K,
∥vk∥2 ≤¯pk,
k = 1, . . . , K,
SINRk deﬁned in (8.10).
This optimization problem (8.50) is nonconvex, but can be relaxed to a semideﬁnite program (or SDP;
see [52] for an introduction to the related concepts and algorithms). Surprisingly, [50] established that
the SDP relaxation for (8.50) is tight; see the subsequent section “Algorithms for QoS Constrained
Power Minimization” for more discussions. Later, Wiesel et al. [51] further showed that this nonconvex
optimization problem can be solved via a sequence of second order cone programs (SOCP); see [52] for
the deﬁnition of SOCP. The key observation is that for a ﬁxed γ , checking the feasibility of (8.50) is an
SOCP, which can be solved efﬁciently by the standard interior point methods. Let γ ∗denote the optimal
objective for problem (8.50), this max-min SINR problem can be solved by a bisection technique:

2.08.3 Optimal Resource Allocation in Interference Channel
427
1. choose ϵ > 0 (termination parameter), γl and γu such that γ ∗lies in [γl, γu];
2. let γmid = (γl + γu)/2;
3. check the feasibility of problem (8.50) with γ = γmid. If feasible, let γl = γmid, otherwise set
γu = γmid;
4. terminate if γu −γl ≤ϵ; else go to step 2. and repeat.
More recently, the max-min fairness resource allocation problem has been considered by Liu et al. [44]
for the MIMO IC model. Unfortunately, the problem becomes NP-hard in this case (see Table 8.2).
Thejoint transceiver beamformer designfor themin-SINR maximizationproblem inaMIMO IC (i.e.,
problem (8.41) with min-rate utility) has recently been considered in [44]. As shown in Section 2.08.3.2,
this problem is in general NP-hard. Consequently, they proposed a low-complexity algorithm that
converges to a stationary point of this problem. A key observation is that when the receive beamformers
{uk}K
k=1 are ﬁxed, the considered problem can be written as
max
{vk}K
k=1
γ
(8.51)
s.t.
|uH
k Hkkvk|2
∥uk∥+ 
l̸=k |uH
k Hlkvl|2 ≥γ,
k = 1, . . . , K,
∥vk∥2 ≤¯pk,
k = 1, . . . , K
which has the same form as the MISO min-SINR problem in (8.50), and thus can be solved using
bisection and SOCP. As a result, the authors proposed to alternate between the following two steps to
solve the min-rate maximization problem:
1. for ﬁxed

u(t)
k
K
k=1, solve (8.51) via SOCP to obtain

v(t+1)
k
K
k=1;
2. for ﬁxed

v(t+1)
k
K
k=1, update

u(t+1)
k
K
k=1 to the minimum mean square error (MMSE)
receiver: u(t+1)
k
=
K
l=1 Hlkv(t+1)
l

Hlkv(t+1)
l
H
+ I
−1
Hkkv(t+1)
k
.
Unlike the MISO min-SINR case, only local optimal solutions can be found in the MIMO case. Extend-
ing the above algorithm to the MIMO IC/IBC/IMAC case with multiple data streams per user is not a
trivial task. For a MIMO IC model, the feasibility problem becomes
Rk = log2 det
⎛
⎜⎝HkkQkHH
kk
⎛
⎝INr +

l̸=k
HlkQlHH
lk
⎞
⎠
−1
+ INr
⎞
⎟⎠≥ζ,
k = 1, . . . , K,
Tr(Qk) ⪰0,
Tr(Qk) ≤¯pk,
k = 1, . . . , K.

428
CHAPTER 8 Signal Processing and Optimal Resource Allocation
This problem is nonconvex and there is no known convex reformulation for it. Finding efﬁcient and
preferably distributed algorithms for these channel models is a challenging problem which deserves
investigation.
2.08.3.3.2
Algorithms for weighted sum-utility maximization
In addition to the min-rate (min-SINR) utility, we can use other utility functions to allocate resources.
For instance, let {μk}K
k=1 denote a set of positive weights that represent the relative priorities of the
users in the system. Then the weighted sum-rate maximization (WSRM) problem for a parallel IC can
be formulated as
max
{pn
k }k,n
K

k=1
μk Rk
(8.52)
s.t. Rk =
N

n=1
log2

1 +
|Hn
kk|2 pn
k
1 + 
l̸=k |Hn
lk|2 pn
l

,
N

n=1
pn
k ≤¯pk,
pk ≥0, k = 1, . . . , K.
This simply corresponds to the problem (8.38) with K
k=1 μk Rk as the objective function. WSRM
is a central problem for physical layer resource allocation. Many sum-utility maximization problems
can be reduced to solving a sequence of WSRM problems for the single channel N = 1 case, see
[53]. Unfortunately, the complexity results in Section 2.08.3.2 indicate that WSRM is in general a hard
problemwhichcannotbesolvedtoglobaloptimalitybyapolynomialtimealgorithm(unlessNP = P).As
aresult,manyworksaredevotedtoﬁndinghighqualitylocallyoptimalsolutionsfortheWSRMproblem.
2.08.3.3.3
Algorithms based on Lagrangian dual decomposition
The linear additive structure of the power budget constraints in the weighted sum-utility maximization
problem (8.38) can be exploited by Lagrangian dualization. In particular, [54] (see also [34,53]) con-
sidered the Lagrangian dual relaxation of the utility maximization problem (8.38) for the parallel IC
model. Let us deﬁne the dual function of the primal problem (8.38) as
d(λ) =
max
{pn
k ≥0}k,n

U

{Rk}K
k=1

−
K

k=1
λk
 N

n=1
pn
k −¯pk

,
(8.53)
where λ = {λk ≥0}K
k=1 is the set of dual variables associated with the sum power constraints. Then the
dual problem of the utility maximization problem can be expressed as follows
min
λ
d(λ)
(8.54)
s.t. λk ≥0,
k = 1, . . . , K.
Denote the optimal objective values of the primal problem (8.38) and the dual problem (8.54) with N
channels as p∗
N and d∗
N, respectively. By the standard duality theory in optimization [55], we have that

2.08.3 Optimal Resource Allocation in Interference Channel
429
the duality gap d∗
N −p∗
N satisﬁes
d∗
N −p∗
N ≥0.
(8.55)
When the primal problem is convex, strong duality holds and the inequality becomes equality. When
restricted to the FDMA (Frequency Division Multiple Access) solutions, the Lagrangian dual problem
decomposes across tones and is efﬁciently solvable [27,53]. However, when the dual optimal solutions
are not unique, it is difﬁcult to construct a primal optimal solution for the problem (8.38). Luo and
Zhang [53] proposed to use an additional randomized step to generate a primal feasible solution from
the dual optimal solution.
When the primal problem is not restricted to the FDMA solutions, the Lagrangian dual function is
difﬁcult to compute, let alone optimize (see the complexity results in Section 2.08.3.2). Yu Liu [54]
proposed an iterative spectrum balancing (ISB) algorithm that alternates between the following two
steps to solve the WSRM problem (8.52):
1. given a λ ≥0, use a coordinate ascent strategy to approximately evaluate the dual function
until convergence;
2. update λ using the subgradient method or the ellipsoid method.
Due to the inexactness of step 1, this algorithm is not guaranteed to converge to a global optimal solution
of the WSRM problem (8.52).
A surprising observation in [54] is that when N (the number of channels) goes to inﬁnity, the duality
gap vanishes. Luo and Zhang [34,53] rigorously proved this result using Lyapunov theorem in functional
analysis. In particular, Lyapunov’s theorem implies that for the continuous formulation of the WSRM
problem (inﬁnite number of channels), the rate region is actually convex. With additional steps to
estimate of the approximation of Lebesque integrals, Luo and Zhang [53] showed that for some constant
L, an estimate of the duality gap is bounded by
0 ≤d∗
N −p∗
N ≤
L
√
N
.
(8.56)
Clearly the gap vanishes as N goes to inﬁnity. Using this estimate, Luo Zhang [53] further developed a
polynomial time approximation scheme to ﬁnd an optimal FDMA solution for the continuous version
of the WSRM problem (8.52).
Algorithms based on interference pricing
In a number of related works [56–59], the authors proposed a modiﬁed iterative water-ﬁlling (M-IWF)
algorithm that iteratively solves K subproblems. The subproblem related to user k can be expressed as
max
{pn
k }k,n
Rk −
N

n=1
pn
k T n
k ,
(8.57)
s.t.
N

n=1
pn
k ≤¯pk,
(8.58)
pn
k ≥0,
n ∈N,

430
CHAPTER 8 Signal Processing and Optimal Resource Allocation
where T n
k is deﬁned as
T n
k =

l̸=k

|Hn
kl|2

j̸=k|Hn
jl|2 pn
j + 1 −
|Hn
kl|2
K
j=1|Hn
jl|2 pn
j + 1

.
(8.59)
This term can be viewed as the interference price that user k needs to pay on channel n for the unit of
interference it causes to all other users in the system. In other words, the price T n
k corresponds to the
marginal decrease in the sum-rate utility per unit increase in interference power pn
k . If the interference
price is set to zero, then we are led to the standard iterative water-ﬁlling algorithm [60]. The M-IWF
algorithm works by iteratively performing the following steps:
1. ﬁx

T n,(t)
k

n,k, each user iteratively computes the optimal solution

pn,(t+1)
k

n,k to the convex
subproblem (8.57) until convergence;
2. update

T n,(t+1)
k

n,k according to (8.59) using

pn,(t+1)
k

n,k.
We note that the overall computational complexity of step 1 is O(T K N log N), where T is the total
number of iterations needed for convergence. It was conjectured that this algorithm converges at least to
a stationary point of the WSRM problem, but no formal proof was given. In [61], the authors successfully
established the convergence (to the stationary point) of this type of pricing algorithm under the condition
that the users act sequentially, i.e., in step 1 of M-IWF, only a single user solves its optimization
problem (8.57). They interpreted this sequential M-IWF as a successive linear approximation of the
WSRM problem, and showed that the term −N
n=1
K
k=1 pn
k T n
k is the ﬁrst order Taylor approximation
(up to an additive constant term) of 
l̸=k Rl, the nonconcave part of the objective function. With this
interpretation, the M-IWF algorithm can be seen as letting each user sequentially solve a partially
linearized version of the WSRM problem. Since the ﬁrst order Taylor approximation is a locally tight
approximation of the weighted sum-rate objective function, the weighted sum-rates computed by the
sequential M-IWF algorithm improve monotonically. Moreover, since the users update their power
allocations locally, the M-IWF algorithm can be implemented in a distributed manner as long as the
interference prices are exchanged among the users at each iteration. We shall refer to the sequential
modiﬁcation of the M-IWF as the multichannel distributed pricing (MDP) algorithm.
The interference pricing idea has been extended to the MISO IC in [62,63], and to the MIMO IC
with single stream per user in [64]. Ref. [65] considered interference pricing for the general MIMO IC
without the single data stream per user restriction. Similar to the parallel IC situation, the convergence
of the interference pricing algorithm for the MIMO IC has only been analyzed for the sequential user
update case. It will be interesting to see how the pricing technique (and its convergence proof) can
be extended to the MIMO IC/IBC/IMAC models with an arbitrary number of streams per user, while
allowing simultaneous user updates. A step in this direction was taken by Venturino et al. [66] which
extended the interference pricing technique to the MISO IBC model. Their algorithm (named Iterative
Coordinated BeamForming (ICBF)) calculates proper pricing coefﬁcients that enable each BS to update
their respective beamformers. Convergence was always observed in the simulation, but no formal proof
was given. A recent survey of various pricing techniques used in wireless networks can be found in
[67]. We also refer the readers to the web pages of Berryand Honig for other related works on this topic.

2.08.3 Optimal Resource Allocation in Interference Channel
431
Algorithms based on successive convex approximation
The MDP algorithm belongs to a class of algorithms called successive convex approximation (SCA).
The idea is to construct and maximize a series of (concave) lower bounds of the original WSRM problem,
so that a high quality solution can be obtained asymptotically. See Figure 8.7 for a graphical illustration
of how this class of algorithms work. In [68], an algorithm called Successive Convex Approximation
for Low complExity (SCALE) is proposed to improve the spectral efﬁciency of the DSL network. This
algorithm transforms the noncocave sum rate maximization problem into a series of convex problems
by utilizing the following lower bound
α log2(z) + β ≤log2(1 + z),
(8.60)
α =
z0
1 + z0
,
β = log2 (1 + z0) −
z0
1 + z0
log2 z0,
(8.61)
where the inequality (8.60) is tight at z = z0. This lower bound allows the WSRM problem to be
approximated by
max
{pn
k }k,n
K

k=1
μk
N

n=1
αn
k log2

|Hn
kk|2 pn
k
1 + 
l̸=k|Hn
lk|2 pn
l

+ βn
k
(8.62)
s.t.
N

n=1
pn
k ≤¯pk,
k = 1, . . . , K
pn
k ≥0,
(k, n) ∈K × N.
FIGURE 8.7
Graphical illustration of the family of algorithms using successive convex approximation. In this example,
x0 is the initial point. At x0, a (strictly) concave function gx0(x) is used to approximate the original non-
convex function F (x). The optimal solution of gx0(x), x1, is found by standard optimization technique. Then
the (strictly) concave function gx1(x) is constructed at the point x1. gx1(x) is then optimized to obtain the
point x2. Continue this process, a stationary solution of the original function F (x) can be found.

432
CHAPTER 8 Signal Processing and Optimal Resource Allocation
After a log transformation ˜pn
k = log2 (pn
k ), (k, n) ∈K×N, this relaxed problem turns out to be concave
in ˜pk
n. The SCALE algorithm alternates between the following two steps:
1. ﬁx


αn,(t)
k
, βn,(t)
k

k,n, solve (8.62) and obtain

pn,(t+1)
k

n,k;
2. update the parameters


αn,(t+1)
k
, βn,(t+1)
k

k,n according to (8.61) using

pn,(t+1)
k

n,k.
Step 1 can be solved either in a centralized fashion using Geometric Programming (GP) technique, or by
solving the dual problem of (8.62) in a distributed way. This algorithm is guaranteed to reach a stationary
point of the original sum rate maximization problem. We brieﬂy compare the major differences of the
MDP and SCALE algorithms in Table 8.3.
In [69], a different lower bound is proposed for the WSRM problem. Speciﬁcally, the authors decom-
pose the objective function as the difference of two concave functions of {pn
k }n,k (referred to as the “dc”
function)
K

k=1
N

n=1
log2

1 +
|Hn
kk|2 pn
k
1 + 
l̸=k |Hn
lk|2 pn
l

=
K

k=1
N

n=1
log2
⎛
⎝1 +

l̸=k
|Hn
lk|2 pn
l + |Hn
kk|2 pn
k
⎞
⎠
−
K

k=1
N

n=1
log2
⎛
⎝1 +

l̸=k
|Hn
lk|2 pn
l
⎞
⎠.
(8.63)
Similar to the steps of SCA introduced earlier, in each iteration of the algorithm, the second sum
is replaced with its linear lower bound, and the resulting concave maximization problem is solved.
Compared to the MDP algorithm which linearizes 
l̸=k Rl, this algorithm linearizes all the interference
terms in each iteration. As such, it linearizes more terms than the MDP algorithm per iteration.
A related algorithm has been proposed in the recent work [33] where the authors considered the
general utility maximization problem in MISO IC (i.e., problem formulation (8.39)). Besides providing
Table 8.3 Comparison of SCALE and MDP Algorithms
Properties
User update
Approximation
Computation
Schedule
Methods
per Iteration
Dual Updates
SCALE
Simultaneously
Concave approximation
Iterative
Subgradient
MDP
Sequentially
Linear approximation
Closed form
Bisection

2.08.3 Optimal Resource Allocation in Interference Channel
433
complexity results, the authors proposed an algorithm that is able to converge to local optimal solutions
for problem (8.39) with any smooth (twice continuously differentiable) utility functions. The basic
idea is to let the users cyclically update their beamformers using projected gradient ascent algorithm.
In particular, at iteration t, user k takes a gradient projection step to compute the direction d(t+1)
k
by
solving the following problem
max
dk
⟨∇vkU

v(t)
l
K
l=1

, dk⟩−1
2∥dk∥2
(8.64)
s.t. ∥dk + v(t)
k ∥2 ≤¯pk.
In contrast to the MDP and SCALE, the subproblem (8.64) linearizes the entire objective function of
(8.39) at the current point

v(t)
k

k∈K, and has an additional quadratic regularization term 1
2∥dk∥2. This
subproblem is a convex quadratic minimization problem over a ball. As such, it is easier to solve than the
corresponding subproblems of MDP and SCALE which are based on partial linearization of the original
WSRMobjectivefunction.Welistbelowthemainstepsofthiscycliccoordinateascent(CCA)algorithm:
1. select a user k ∈K and compute its gradient projection direction d(t+1)
k
by solving (8.64);
2. determine stepsize α(t+1)
k
for user k using a line search strategy;
3. update beamformer: v(t+1)
k
= v(t)
k + α(t+1)
k
d(t+1)
k
, and go to step 1.
The CCA algorithm only works in MISO IC case, and it is not clear how to extend it to the MIMO IC.
Algorithms based on weighted MMSE minimization
A different weighted sum-rate maximization approach was proposed in [70] for the MIMO broadcast
downlink channel, where the WSRM problem is transformed to an equivalent weighted sum MSE
minimization(WMMSE)problemwithsomespeciallychosenweightmatrices.Sincetheoptimalweight
matrices are generally unknown, the authors of [70] proposed an iterative algorithm that adaptively
chooses the weight matrices and updates the linear transmit/receive beamformers at each iteration. A
nonconvex cost function was constructed in [70] and shown to monotonically decrease as the algorithm
progresses. But the convergence of the iterates to a stationary point (or the global minimum) of the
cost function is not known. Later, a similar algorithm was proposed in [71] for the interference channel
where each user only transmits one data stream.
It turns out that this WMMSE based resource allocation approach can be extended signiﬁcantly
to handle the MIMO-IC and MIMO-IBC/IMAC models as well as general utility functions. In par-
ticular, the authors of [72,73] established a general equivalence result between the global (and local)
minimizers of the weighted sum-utility maximization problem (e.g., (8.40) and (8.52)) and a suitably
deﬁned weighed MMSE minimization problem. The latter can be effectively optimized by utilizing the
block coordinate descent technique, resulting in independent, closed form iterative update across the
transmitters and receivers. The resulting algorithm is named the WMMSE algorithm.
To gain some insight, let us consider the special case of a scalar IC system where the equivalence of
the WSRM problem (8.52) and a weighted sum MSE minimization can be seen more directly. Let v j, uk

434
CHAPTER 8 Signal Processing and Optimal Resource Allocation
denote the complex gains used by the transmitter j and receiver k respectively. Consider the following
weighted sum-MSE minimization problem
min
{wk,uk,vk}K
k=1
K

k=1
μk(wkek −log wk)
s.t.
|vk|2 ≤¯pk,
k = 1, 2, . . . , K,
(8.65)
where wk is a positive weight variable, and ek is the mean square estimation error
ek ≜|uk Hkkvk −1|2 +

j̸=k
|uk Hjkv j|2 + |uk|2.
To see the equivalence, we can check the ﬁrst order optimality condition to ﬁnd the optimal wk and uk
uopt
k
=
Hkkvk
K
j=1|Hjk|2|v j|2 + 1
,
wopt
k
= e−1
k ,
∀k = 1, 2, . . . , K.
(8.66)
Plugging these optimal values in (8.65) gives the following equivalent optimization problem
max
{vk}K
k=1
K

k=1
μk log

1 −
|Hkk|2|vk|2
K
j=1|Hjk|2|v j|2 + 1
−1
s.t.
|vk|2 ≤¯pk,
k = 1, 2, . . . , K,
which, upon a change of variable pk = |vk|2, is equivalent to
max
{pk}K
k=1
K

k=1
μk log

1 +
|Hkk|2 pk

j̸=k|Hjk|2 p j + 1

s.t.
pk ≤¯pk,
k = 1, 2, . . . , K.
This establishes the equivalence of the WMMSE problem (8.65) and the WSRM problem (8.52). More
importantly, the equivalence goes one step further: there is a one-to-one correspondence between the
local minimums of the two problems (see [72,73]).
The equivalence relation implies that maximizing the weighted sum-rate can be accomplished via
iterative weighted MSE minimization. The latter problem is in the space of (u, v, w) and is easier to
handle since optimizing each variable while holding the others ﬁxed is convex and easy (e.g., closed
form). This property has been exploited in [72,73] to design the WMMSE algorithm. In contrast, the
original sum-rate maximization problem (8.52) is in the space of p and is nonconvex, which makes the
iterative optimization process difﬁcult.
The general form of the WMMSE algorithm can handle any utility functions satisfying the following
conditions
(Separability)
U({Rk}K
k=1) =
K

k=1
uk(Rk),
(8.67)
(Concavity)
−uk(−log2 det (X)) strictly concave in X ≻0,
∀k ∈K,
(8.68)
(Differentiability)
uk(x) increasing and twice continuously differentiable in x,
∀k ∈K.
(8.69)

2.08.3 Optimal Resource Allocation in Interference Channel
435
In addition, it also handles a wide range of channel models, e.g., MIMO and parallel IC/IBC/IMAC.
It is well known that Rk = maxUk log2 det

E−1
k

Uk, {Vk}K
k=1

, where Ek is the mean square error
(MSE) matrix for user k. Deﬁne a set of new functions: ck(Ek) = −uk( −log det (Ek(Uk, {Vk}K
k=1))),
k = 1, . . . , K. Similar to the scalar IC case, the equivalence of the following two optimization problems
can be established
min
{(Uk,V)}K
k=1
K

k=1
ck(Ek)
(8.70)
s.t.
Tr

VkVH
k

≤¯pk,
k = 1, . . . , K,
min
{(Uk,Vk,Wk)}K
k=1
K

k=1
Tr

WH
k Ek

+ ck

φk(Wk)

−Tr

WHφk(Wk)

(8.71)
s.t.
Tr

VkVH
k

≤¯pk, k = 1, . . . , K,
where φk(Wk) is the inverse map of ▽ck(Ek). The WMMSE algorithm ﬁnds a stationary point of
the alternative problem (8.71). In particular, it alternately updates the three sets of variables {Uk}K
k=1,
{Vk}K
k=1, or {Wk}K
k=1 for problem (8.71), each time keeping two sets of variables ﬁxed. The WMMSE
algorithm for a MIMO IC is listed in the following table:
1. initialize {Vk}k∈K such that Tr

VkVH
k

= ¯pk;
2. repeat;
3. W′
k ←Wk, ∀k ∈K;
4. Uk ←

l∈K HlkVlVH
l HH
lk + I
−1 HkkVk, ∀k ∈K;
5. Wk ←

I −UH
kkHkkVk
−1 , ∀k ∈K;
6. Vk ←μk

l∈K μlHH
kl UlWlUH
l Hkl + λ∗
kI
−1 HH
kkUkWk, ∀k ∈K;
7. until

l∈K log det

Wl

−
l∈K log det

W′
l
 ≤ϵ.
We note that in Step 6, λ∗
k ≥0 is the Lagrangian multiplier for the constraint Tr

VkVH
k

≤Pk. This
multiplier can be found easily by bi-section method. Also, notice that all updates are in closed form
(except for λ∗
k) and can be performed simultaneously across users.
To compare the performance and the efﬁciency of various resource allocation methods, we consider a
simple simulation experiment involving a parallel-IC and a MIMO-IC. We ﬁrst specialize the WMMSE
algorithm to the parallel-IC scenario and compare it with SCALE and MDP algorithms described earlier.
To specialize the WMMSE algorithm for a parallel IC, let us restrict the transmit/receive matrices for
each user to be diagonal. That is, the beamforming directions are ﬁxed to be unit vectors and we only
optimize power loading factors on the parallel channels. Let vk ∈CN×1 denote the user k’s transmit
ﬁlter vector, with vn
k corresponding to the complex scaling coefﬁcient to be used for the data stream

436
CHAPTER 8 Signal Processing and Optimal Resource Allocation
on channel n. Similarly, the receive ﬁlter vector and the weight vector are denoted by uk, wk ∈CN×1
respectively. Then the WMMSE algorithm for the parallel IC channel can be described as:
1. Initialize {vk}k∈K such that 
n∈N vn
k = ¯pk;
2. repeat;
3. (wn
k)′ ←wn
k, ∀(n, k) ∈N × K;
4.
un
k ←

l∈K|Hn
lk|2|vn
l |2 + 1
−1 Hn
kkvn
k, ∀(n, k) ∈N × K;
5.
wn
k ←

1 −un
k Hn
kkvn
k
−1 , ∀(n, k) ∈N × K;
6.
vn
k ←μk
Hn
kkun
kwn
k

l∈Kμl|Hn
kl|2|un
l |2wn
l +λ∗
k , ∀(n, k) ∈N × K;
7. until

l∈K

n∈N log (wn
l ) −
l∈K

n∈N log

(wnl)′ ≤ϵ.
In the simulation, we set the weights {μk}k∈K all equal to 1, and set the maximum power ¯pk =
10SNR/10 for all the users. We set the stopping criteria as ϵ = 0.01 for all algorithms. The channel
coefﬁcients are generated from the complex Gaussian distribution CN(0, 1). For MIMO IC, all the
transmitters and receivers are assumed to have the same number of antennas.
We ﬁrst investigate the performance of SCALE, MDP and the parallel version of the WMMSE
algorithm for a parallel IC. Figure 8.8 illustrates the sum rate performance of different algorithms when
10
15
20
25
30
SNR
MDP
WMMSE
SCALE
K=20
K=10
Bit/Second/Hertz
2
3
4
5
6
7
8
9
10
11
12
5
FIGURE 8.8
Comparison of the averaged sum rate performance versus SNR of different algorithms in parallel IC.
K = [10, 20], N = 32. Each curve in the ﬁgure is averaged over 100 random channel realizations.

2.08.3 Optimal Resource Allocation in Interference Channel
437
10
5
0
10
20
30
40
50
60
70
80
90
100
15
20
25
30
35
40
Number of Users
MDP
WMMSE
SCALE
Average CPU Time (s)
FIGURE 8.9
Comparison of the averaged CPU time versus the number of users of different algorithms in parallel IC.
N = 32, SNR = 10. Each curve in the ﬁgure is averaged over 100 random channel realizations.
K = [10, 20] and N = 32. We see that these algorithms all have similar performance across all the
SNR values. Figure 8.9 shows the averaged CPU time comparison of these three algorithms under the
same termination criteria and the same accuracy for the search of Lagrangian variables. We observe
that the WMMSE requires much less computational time compared to the other two algorithms when
the number of users becomes large. Note that the ﬁrst step in the SCALE algorithm is implemented
using the subgradient and the ﬁxed point iterations suggested in [68, Section IV-A]. The stepsizes for
the subgradient method as well as the number of the ﬁxed point iterations need to be tuned appropriately
to ensure fast convergence.
Next we examine the performance of the WMMSE and the MIMO distributed pricing (MIMO-
DP) algorithm developed in [65] in the context of a MIMO-IC. Figure 8.10 illustrates the sum rate
performance of the two algorithms when K = [3, 10] and Nr = Nt = 3. Figure 8.11 shows the averaged
CPU time comparison of the two algorithms. We again observe that the WMMSE requires much less
computational time compared with the MIMO-DP algorithm when the number of users becomes large.
Different from many algorithms discussed earlier (e.g., CCA, MDP), the WMMSE algorithm allows
all transmitters/receivers to update their beamformers simultaneously. This feature leads to simple
implementation and fast convergence. It will be interesting to see how this algorithm can be further
extended to include other utility functions such as the min-rate utility, and to other formulations like
QoS constrained power minimization. Also, further research is needed to uncover the full algorithmic

438
CHAPTER 8 Signal Processing and Optimal Resource Allocation
10
15
20
25
30
SNR
WMMSE
MIMO−DP
K=10
K=3
10
20
25
30
35
40
45
50
15
Sum Rate (Bits per Channel Use)
FIGURE 8.10
Comparison of the averaged sum rate performance versus SNR of different algorithms in MIMO IC.
K = [3, 10], Nr = Nt = 3. Each curve in the ﬁgure is averaged over 100 random channel realizations.
10
5
0
20
40
60
80
100
120
140
160
180
15
20
25
30
Number of Users
WMMSE
MIMO−DP
CPU Time (s)
FIGURE 8.11
Comparison of the averaged CPU time versus the number of users of different algorithms in MIMO IC.
Nr = Nt = 3, SNR = 10. Each curve in the ﬁgure is averaged over 100 random channel realizations.

2.08.3 Optimal Resource Allocation in Interference Channel
439
potential of WMMSE algorithm for a wide range of applications including joint base station assignment,
power control, and beamforming.
Algorithms for cross layer resource allocation
We brieﬂy mention a few cross-layer resource allocation algorithms which require solving a weighted
sum-utility problem at each step. These algorithms jointly optimize physical layer as well as the media
access (MAC) layer resources to improve the overall system performance.
Recently, Yu et al. [74] considered the joint MAC layer scheduling and physical layer beamforming
and power control in a multicell OFDMA-MIMO network. The algorithm assigns the users to the BSs
according to their individual priority and channel status. The beamformers are updated using a MSE
duality results developed in [75,76] for multicell network. The transmit powers of the BSs are updated
by using the Newton’s method. In [77–79], the authors considered the WSRM problem in a multicell
downlink OFDMA wireless network. They proposed to let the BSs alternate between the following two
tasks to achieve high system throughput: (1) optimally schedule the users on each channel; (2) jointly
optimize their downlink transmit power using a physical layer resource allocation algorithm such as M-
IWF or SCALE. Razaviyayn et al. [80] proposed to adaptively group users into non-interfering groups,
and optimize the transceiver structure and the group membership jointly. Such grouping strategy results
in fair resource allocation, as cell-edge users with weak channels are protected from the strong users. A
generalized version of the WMMSE algorithm has been developed to perform such joint optimization.
In all these works the resulting resource allocation schemes achieved a weighted sum-utility that is
signiﬁcantly higher than what is possible with only performing physical layer beamforming/power
allocation.
Joint admission control and downlink beamforming is another example of cross layer resource
allocation. For a single cell MISO network, this problem has been considered in [81,82]. A related
problem is the joint BS selection and power control/beamforming problem. This problem has been
addressed in the traditional CDMA based network (see, e.g., [83–85]), in OFDMA networks (e.g., [86–
88]) and in a more general MIMO-HetNet in which all BSs operate on the same frequency bands [89,90].
An interesting research direction to pursue is to effectively incorporate these higher layer protocols to
boost the system performance for a MIMO and parallel IBC/IMAC network.
2.08.3.3.4
Algorithms for QoS constrained power minimization
For the scalar IC model, the QoS constrained min-power problem as formulated in (8.42) has been
considered in [83,85,91]. They derived conditions for the existence of a feasible power allocation given
a set of SINR targets. Deﬁne a K × K matrix A as follows
[A]k,l =

γk|Hlk|2
|Hkk|2 if l ̸= k,
0
otherwise.
(8.72)
If ρ(A) < 1, an optimal power allocation p = [p1, . . . , pK ]T can be found as follows
p = (IK −A)−1b,
(8.73)
where b =

γ1
|H11|2 , . . . ,
γK
|HK K |2
 T
. The convexity of the feasible SINR region for this problem has been
established in [92,93].

440
CHAPTER 8 Signal Processing and Optimal Resource Allocation
Alternatively, Yates [94] has provided a framework that allows the users to compute the optimal
solution of problem (8.42) distributedly by the following ﬁxed point iteration
p(t+1)
k
= γk

1 + 
l̸=k|Hlk|2 p(t)
l
|Hkk|2

,
k = 1, . . . , K.
(8.74)
This algorithm is shown to have linear rate of convergence, that is,
lim sup
t→∞
∥p(t+1) −p∗∥
∥p(t) −p∗∥
= c < 1,
(8.75)
where p∗is the optimal solution of the min-power problem, and c < 1 is some positive constant.
Recently Boche and Schubert [95] has proposed a different algorithm based on a Newton-type update
that exhibits even faster (super-linear) rate of convergence. This algorithm can be applied to more
general scenarios when the receivers are equipped with multiple antennas.
When the set of SINR targets cannot be supported by the system (that is, the problem (8.42) is
infeasible), the call admission control mechanism should be invoked. A couple of recent works [96,97]
have considered the problem of joint admission and power control arises in the QoS constrained power
minimization problem. See [98] for a survey on the general topic of call admission control.
For a MISO IC, Bengtsson Ottersten [50,99] considered the min-power transmit beamforming prob-
lem under QoS constraints (problem (8.43)). Deﬁne Vk = vkvH
k and Glk = hH
lk hlk, this problem can
be equivalently formulated as
min
{Vk}K
k=1
K

k=1
Tr(Vk)
(8.76)
s.t. Tr(GkkVk) −γk

l̸=k
Tr(GlkVl) = γk,
k = 1, . . . , K
rank(Vk) = 1, Vk ⪰0,
k = 1, · · · , K.
Relaxing the rank constraint, this problem is a convex semideﬁnite program and can be solved efﬁciently.
Interestingly, the authors showed that a rank-one solutions must exist for the relaxed problem, revealing
a certain hidden convexity in this problem. The following procedure can be used to construct a rank-1
solution from an optimal solution {V∗
k}K
k=1 of the relaxed problem:
1. Take ek ∈span(V∗
k);
2. Deﬁne η = [γ1, . . . , γK ]T ;
3. Deﬁne a matrix F with its elements as
[F]kl =
!−γkeH
l Gkkel
if l ̸= k,
eH
k Gkkek
otherwise ;
(8.77)
4. Find p = F−1η;
5. Obtain v∗
k = √[p]kek.

2.08.3 Optimal Resource Allocation in Interference Channel
441
The approach works for the IBC model as well. It can also be extended to include other resource
allocation options, such as admission control and base station assignment; see [84,100,101] for details.
2.08.3.3.5
Algorithms for hybrid formulations
For a scalar IC, Chiang et al. [102] proposed to use a technique called geometric programming (GP)
to ﬁnd an approximate solution to the WSRM problem with QoS constraint. They showed that after
approximating the rate function log(1 + SINRk) by log(SINRk), the WSRM problem becomes a GP
and can be solved efﬁciently. Moreover, with this approximation, the resource allocation problem falls
into the family of problems considered in [32,41], which can be transformed into equivalent convex
optimization problems. For this family of problems, fast and distributed algorithms based on certain
Newton-type iteration have been proposed in [103].
However, this approximation is not so useful in practice because (1) it is accurate only in high SINR
region; (2) it always leads to a solution for which all links are active. The latter feature is undesirable
because having all links active can be highly suboptimal when interference is strong. In fact, the main
difﬁculty with WSRM is precisely how to identify which links should be shut off, an important option
that is excluded by the GP approximation approach.
Recognizing such problems, the same authors further proposed in [102] a successive convex approx-
imation (GP-SCA) method that aims at ﬁnding a stationary solution to the original WSRM problem.
In particular, let elk(p) = |Hlk|2 pl, fk(p) = 1 + K
l=1 elk(p) and gk(p) = 1 + 
l̸=k |Hlk|2 pl, for
k = 1, . . . , K. Utilizing the arithmetic-geometric mean inequality, the users’ rate functions can be
lower-approximate as
log2 (1 + SINRk) = log2
 fk(p)
gk(p)

(8.78)
≥log2
⎛
⎜⎝
"K
l=1

elk(p)
αl
αl ×

1
β
β
gk(p)
⎞
⎟⎠,
(8.79)
where, αl = elk(ˆp)
fk(ˆp) , β =
1
fk(ˆp).
(8.80)
This lower bound is again concave (upon performing a log-transformation), and it is tight when p = ˆp.
The QoS constrained WSRM problem with the approximated objective (8.79) can be again solved by
a GP. A similar alternating procedure as the one we have introduced for the SCALE algorithm can be
used to compute a stationary solution to the WSRM problem with QoS constraint.
Algorithms based on global optimization
There are a number of attempts to ﬁnd globally optimal solution for the WSRM problem. However,
these algorithms are all based on implicit enumeration (not surprising in light of the complexity results
in Section 2.08.3.2). As a result, they can only solve small scale problems and are unlikely to be suitable
for implementation in practical applications. However, this does not mean that global optimization
algorithms for WSRM are useless. For one thing, they can be a valuable tool to benchmark various low-
complexity suboptimal approaches for resource allocation (e.g., those described earlier in this section).

442
CHAPTER 8 Signal Processing and Optimal Resource Allocation
For a scalar IC, Qian et al. [104] proposed to use an existing algorithm [105,106] for nonconvex
fractional programming to ﬁnd the global optimal solution for the hybrid problem (8.45). Speciﬁcally,
introducing a set of auxiliary variable {zk}K
k=1, the scalar WSRM problem with SINR constraint can be
formulated into the following equivalent form
maxz,p
K
#
k=1
(zk)wk
(8.81)
s.t.
0 ≤zk ≤fk(p)
gk(p),
0 ≤pk ≤¯pk, fk(p)
gk(p) ≥γk,
∀k ∈K.
This reformulated problem has a concave objective (upon a log transformation), and a nonconvex fea-
sible set G. The global optimization algorithm of [105,106] solves the reformulated problem via some
convex optimization problems over a sequence shrinking convex sets S1 ⊃S2 · · · ⊃G. The worst case
complexity of this algorithm is exponential.
Several other global optimization methods have been proposed to solve the utility maximization
problems for more general IC models. For example, [107–110] considered the parallel IC model, and
[111] treated the two user-MISO IC model. In particular, the algorithm proposed in [110] utilized the dc
structure (8.63) of the weighted sum rate function, and applied a branch-and-bound (BB) algorithm to
ﬁnd global optimal solution to the WSRM problem. Due to their exponentially increasing complexity,
these algorithms are only suitable for benchmarking resource allocation algorithm for networks with
relatively small number of links. For example, the work of [104,107] compared their global algorithms
for a small parallel IC with N = 4, K = 2, and a scalar IC with K up to 10.
An important open problem is how to develop efﬁcient algorithms (suitable for large networks) that
can ﬁnd (provably) tight upper bounds for the system performance.
2.08.3.3.6
Algorithms for robust resource allocation
All of the aforementioned resource management schemes require perfect channel state information
(CSI) at the transmitter side. However, in practice the CSI obtained at the transmitter is susceptible to
various sources of uncertainties such as quantization error, channel estimation error or channel aging.
These uncertainties may signiﬁcantly degrade the performance of resource allocation schemes that are
designed using perfect CSI. As a result, robust designs are needed for practical resource management.
Several recent contributions considered robust linear transmitter design in a MISO channel with a
single transmitter and multiple receivers. Let hk ∈CNt and ˆhk ∈CNt denote the true channel and
the estimated channel between the transmitter and the k-th receiver, respectively. Let Uk denote the
uncertainty set of channel hk, which is the set of possible values that hk may take after obtaining the
estimated channel ˆhk. Consider the following speciﬁc form of uncertainty set
Uk(k) =

hk|hk = ˆhk + k, ∥k∥≤δk

,
(8.82)

2.08.3 Optimal Resource Allocation in Interference Channel
443
where k is the vector of estimation error and δk is the uncertainty bound. One of the most popular
formulation of the robust design is the following QoS constrained min power problem
min
{vk}K
k=1
K

k=1
∥vk∥2
(8.83)
s.t.
|hkvk|2

l̸=k|hkvl|2 + 1 ≥γk,
∀hk ∈Uk(k),
k = 1, . . . , K.
This formulation aims at minimizing the total transmission power while ensuring that the SINR con-
straints are satisﬁed under all possible channel uncertainties. Deﬁne
V = [v1, . . . , vk]
hk = [Re{hk} Im{hk}]
V =
$Re{V}
Im{V}
−Im{V} Re{V}
%
vk =
$Re{vk}
−Im{vk}
%
.
In [112] problem (8.83) has been reformulated into the following semi-inﬁnite SOCP
min
V,t
t
(8.84)
s.t.
&&vec

v1, . . . , vK
	&& ≤t
&&
hkV, 1
	&& ≤
'
1 + γ −1
k
hkvk,
∀hk ∈Uk(k), k = 1, . . . , K.
(8.85)
This reformulation is a convex restriction to the original problem (8.83) in that the the complex
magnitude |hkvk| in the constraint is replaced by the lower bound equal to its real part Re(hkvk) = hkvk.
However, due to the presence of hk on both sides of the SOC constraint (8.85), this reformulated problem
is still difﬁcult to solve. A conservative design is then developed by assuming independent uncertainties
for hk on the left and right hand sides of each constraint in (8.85). With such an assumption, problem
(8.85) can be transformed to the following SDP problem and solved efﬁciently using standard interior
point method.
min
V,η,κ,t
t
(8.86)
s.t.
&&vec

v1, . . . , vK
	&& ≤t
⎡
⎢⎢⎣
κk −ηk
0

ˆhkV, 1
 
0
ηkI2Nt
δk[V, 0]

ˆhkV, 1
 T
δk[V, 0]T
κkI2K+1
⎤
⎥⎥⎦⪰0, k = 1, . . . , K
⎡
⎢⎣
'
1 + γ −1
k
ˆhkvk −κk
δk
'
1 + γ −1
k
vT
k
δk
'
1 + γ −1
k
vk
'
1 + γ −1
k
ˆhkvk −κk

I2Nt
⎤
⎥⎦⪰0, k = 1, . . . , K.

444
CHAPTER 8 Signal Processing and Optimal Resource Allocation
Instead of solving (8.84) by the SDP relaxation (8.86), Vucic and Boche [113] proposed to solve (8.84)
by: (1) directly applying the ellipsoid method from convex optimization and (2) approximating (8.84)
by a robust MSE constrained min power problem. Let uk ∈C denote the scalar receive ﬁlter used at
receiver k. Let ek denote the unit vector with its k-th element being 1. Deﬁne the MSE of the k-th user
as
MSEk

{vk, uk}K
k=1

= |uk|2

hkV −1
uk
ek
 
hkV −1
uk
ek
H
+ 1

.
(8.87)
The robust MSE constrained min power problem is given as
min
{vk,uk}K
k=1
K

k=1
∥vk∥2
(8.88)
s.t.
MSEk

{vk, uk}K
k=1

≤
1
1 + γk
, ∀hk ∈Uk(k), k = 1, . . . , K.
(8.89)
This problem is convex and can be equivalently formulated as an SDP problem and efﬁciently solved
by interior point methods. It is shown in [113] that both the ellipsoid method approach and the robust
MSE constrained reformulation approach achieve better performance than the SDP relaxation (8.86) in
terms of various system level performance measures.
As noted earlier, the original min power SINR constrained problem (8.83) is not equivalent to the
formulation (8.84), as the latter replaces the nonlinear term |hkvk| by a linear lower bound Re(hkvk) =
hkvk. Implicit in this reformulation is the additional requirement that Re(hkvk) is positive for all the
channels hk ∈Uk(δk). Recently, the authors of [114] showed that the direct SDP relaxation of the
original problem (8.83) is actually tight as long as the size of the uncertainty set is sufﬁciently small.
This implies that robust resource allocation for MISO channels can be solved to global optimality in
polynomial time, provided the channel uncertainty is small. More precisely, deﬁne Vk = vkvH
k , and
Xk = 1
γk Vk −
l̸=k Vl, the problem (8.83) can be equivalently reformulated as
min
{Vk,κk}K
k=1
K

k=1
Tr(Vk)
(8.90)
s.t.
κk ≥0, k = 1, . . . , K
$ Xk + κkI Xk ˆhH
k
ˆhkXH
k
ˆhkXH
k ˆhH
k −1 −κkδ2
k
%
⪰0, k = 1, . . . , K.
Vk ⪰0,
rank(Vk) = 1, k = 1, . . . , K.
When the rank constraints are dropped, this problem becomes the following SDP and can be efﬁciently
solved
min
{Vk,κk}K
k=1
K
k=1Tr(Vk)
s.t.
κk ≥0,
k = 1, . . . , K
$ Xk + κkI Xk ˆhH
k
ˆhkXH
k
ˆhkXH
k ˆhH
k −1 −κkδ2
k
%
⪰0, k = 1, . . . , K.
Vk ⪰0, k = 1, . . . , K.
(8.91)

2.08.4 Distributed Resource Allocation in Interference Channel
445
Let δ = [δ1, . . . , δK ]. Let Pδ denote the above SDP problem when the bounds on the uncertainty set is δ.
Let P∗(δ) denote the optimal value of the the problem Pδ. Suppose that for some choice of uncertainty
bounds ¯δ =
¯δ1, . . . , ¯δK
	T > 0, the problem P¯δ is strictly feasible. Deﬁne the set
(¯δ) =

δ
 δk ≤¯δk and δk <
.
γk
P∗¯δ
,
k = 1, . . . , K

.
(8.92)
Then, according to Song et al. [114], for any vector of uncertainty bounds δ ∈(¯δ), the problem Pδ is
feasible. Moreover, its optimal solution {V∗
k}K
k=1 satisﬁes rank (V∗
k) = 1, k = 1 . . . , K, and it must be
the optimal solution of the original problem (8.83).
Alternative system level objectives and constraints can be considered to result in different formu-
lations of the robust resource allocation problem. For example, Ref. [115] considered robust design
for both the averaged sum MSE minimization problem and the worst case sum MSE minimization
problem. Ref. [116] considered the worst case weighted sum rate maximization problem and min-rate
maximization problem. The authors of [117] considered the robust beamformer design in a cognitive
radio network in which there are additional requirements that the transmitter’s interference to the pri-
mary users should be kept under a prescribed level. However, most of the above cited works focus on
robust design in a single cell network with a single transmitter. The extensions to the general MIMO
IC/IBC/IMAC will be interesting.
To close this section, we summarize the properties of most of the algorithms discussed in this section
in Table 8.4. These algorithms usually admit certain forms of decentralized implementation, in which
the computational loads are distributed to different entities in the network. We emphasize that the per-
iteration computational complexity and the amount of message exchanges are important characteristics
for practical implementation of these distributed algorithms. Efﬁcient computation ensures real time
implementation,whilefewernumberofmessageexchangesperiterationimplieslesssignalingoverhead.
In Table 8.4, these characteristics are listed for each of the algorithms. We note that the computational
complexity and the required message exchanges are calculated on a per iteration basis, where in one
iteration each user k ∈K completes one update. Also note that in Table 8.4, the variable T in ICBF,
SCALE-Dual, and M-IWF represents the number of inner iterations needed; the variable ϵ in Bisection-
SOCP and SCALE-GP represents the required precision for their respective inner solutions; the variable
t in MAPEL represents the iteration index; the variable B in BB and ISB represents the maximum
number of transmitted bits allowed for each subchannel; the variable C in the BB algorithm represents
its computation overhead.
2.08.4 Distributed resource allocation in interference channel
Most of the algorithms introduced in the previous section are either centralized or require certain level
of user coordination. Such coordination may be costly in infrastructure based networks, and is often
infeasible for fully distributed networks. In this section we discuss fully distributed resource allocation
algorithms that require no user coordination.

446
CHAPTER 8 Signal Processing and Optimal Resource Allocation
Table 8.4 Comparisons of Resource Allocation Algorithms
Algorithm
Optimality
Complexity per
Convergence
Coordination
Message
Channel
Update
Problem
Iteration
Status
Level
Exchange
Model
Schedule
Formulation
APC [46]
Global
O(K )
Yes
Distributed
O(K )
Scalar IC
Sequential
Min SINR
BB [110]
Global
Lower bounded By
Yes
Centralized
N/A
Parallel IC
N/A
Sum rate
O((3 + B/2)
K 3 + 3K 2/2 + C)
Bisection-
Global
O

K 3.5N3.5
t
log

1
ϵ

Yes
Centralized
N/A
MISO IC
N/A
Min SINR
SOCP ([33])
CCA [33]
Local
O(Nt K 2)
Yes
Distributed
O(K 2)
MISO IC
Sequential
Smooth utility
ICBF [66]
Unknown
O(TK 2N3
t )
Unknown
Distributed
O(K 2)
MISO IC
Sequential
Sum rate
MISO
IBC/IMAC
ISB [54]
Unknown
O(BNK )
Unknown
Distributed
O(K 2N)
Parallel IC
Sequential
Sum rate
GP [102]
Unknown
O(K 3)
Yes
Centralized
N/A
Parallel IC
N/A
Mixed sum
(Scalar IC Case)
Scalar IC
rate
NFP ([106]) Global
Upper bounded By K t
Yes
Centralized
N/A
Parallel IC
N/A
Mixed sum
Scalar IC
rate
MDP [61]
Local
O(KN log N + K 2N)
Yes
Distributed
O(K 2N)
MISO IC
Sequential
Sum rate
(Parallel IC Case)
Parallel IC
MIMO-
Unknown
O(K 3(Nt N2r +
Unknown
Distributed
O(K 2N2r ) MIMO IC
Sequential
Sum rate
DP [65]
N2
t Nr ) + K 2N3r )
M-IWF [59]
Unknown
O(TKN log N + K 2N) Unknown
Distributed
O(K 2N)
Parallel IC
Simultaneous Sum rate
SCALE-
Local
O(TKN + NK 2)
Yes
Distributed
O(K 2N)
Parallel IC
Simultaneous Sum rate and
Dual [68]
min power
SCALE-
Local
O(K 4N4 log (KN/ϵ))
Yes
Centralized
N/A
Parallel IC
N/A
Sum rate and
GP [68]
min power
WMMSE-
Local
O(K 2(Nt N2r + N2
t
Yes
Distributed
O(K 2N2r ) MIMO IC
Simultaneous Utility satisfy
MIMO [73]
Nr + N3
t ) + KN3r )
MIMO
8.67–8.69
(MIMO IC Case)
IBC/IMAC
WMMSE-
Local
O(K 2N3)
Yes
Distributed
O(K 2N2) Parallel IC
Simultaneous Utility satisfy
Parallel [73]
(MIMO IC Case)
Parallel IBC/IMAC
8.67–8.69

2.08.4 Distributed Resource Allocation in Interference Channel
447
2.08.4.1 Game theoretical formulations
In scenarios where users cannot exchange information explicitly, it is no longer possible to allocate
resources using the maximizer of a system wide utility function. Instead, we need to rely on alternative
solution concepts for distributed resource allocation. One such concept that is particularly useful in our
context is the renowned notion of Nash equilibrium (NE) for a noncooperative game; see [118,119], and
the Yale Open Course online. In a noncooperative game, there are a number of players, each seeking to
maximize its own utility function by choosing a strategy from an individual strategy set. However, the
utility of one player depends on not only the strategy of its own, but also those of others in the system.
As a result, when players have conﬂicting utility functions, there is usually no joint player strategy that
will simultaneously maximize the utilities of all players. For such a noncooperative game, a NE solution
is deﬁned as a tuple of joint player strategies in which no single player can beneﬁt by changing its own
strategy unilaterally.
Mathematically, a K-person noncooperative game in the strategic form is a three tuple (K, χ, U),
in which K = {1, . . . , K} is the set of players of the game; χ = "K
k=1 χk is the joint strategic
space of all the players, with χk being player k’s individual strategy space; U = [U1, . . . ,UK ], where
Uk(xk, x−k) : χ →R is user k’s utility function. In the above deﬁnition we have used xk ∈χk to
denote player k’s strategy, x−k = {xl}l̸=k to denote the strategies of all remaining users. It is clear that
player k’s strategy depends on its own strategy xk ∈χk as well as those of others x−k ∈χ−k. A NE
of the game G is deﬁned as the set of joint strategies of all the players x∗∈χ such that the following
inequality is satisﬁed simultaneously for all players k ∈K
Uk(x∗
k, x∗
−k) ≥Uk(xk, x∗
−k), ∀xk ∈χk.
(8.93)
Clearly at a NE, the system is stable as none of the players has any intention to switch to a different
strategy. We deﬁne a best response function for each player in the game, as its best strategy when all
other players have their strategies ﬁxed
BRk(x−k) = arg max
xk∈χk Uk(xk, x−k).
(8.94)
Using this deﬁnition, a NE of the game G can be alternatively deﬁned as
x∗∈BRk(x∗
−k), ∀k = 1, . . . , K.
(8.95)
Figure8.12isanillustrationoftheNEpointofagamewith2-playerandafﬁnebestresponsefunctions.
This ﬁgure also shows how a sequence of best response may enable the players to approach the NE.
Let us illustrate the notion of NE in our 2-user scalar IC model (8.14). Suppose these two users are
the players of a game, and their strategy spaces are χk = {pk | 0 ≤pk ≤¯pk}, k = 1, 2. Assume
that the users’ utility functions are their maximum transmission rates deﬁned in (8.18). Thus, for this
example, user 1’s best response function admits a particular simple expression
BR1(p2) = arg
max
0≤p1≤¯p1
log2

1 +
|H11|2 p1
1 + |H21|2 p2

= ¯p1.
(8.96)

448
CHAPTER 8 Signal Processing and Optimal Resource Allocation
0.2
0
0
0.2
0.4
0.6
0.8
1
0.4
0.6
0.8
1
User 1’s Strategy
User 2’s Strategy
NE
User 1’s Best Response Function BR 1 (.)
User 2’s Best Response Function BR 2 (.)
B
C
FIGURE 8.12
Illustration of the Nash Equilibrium (NE) of a 2-user scalar game. This ﬁgure also shows the process of
a sequence of best responses that reach the NE. The function BRk(·) represents user k’s best response
function. Suppose both users initially choose 0. User 2 acts ﬁrst and chooses point A which is its best
response, User 1 acts next and chooses its best response point B. User 2 acts again and chooses point C.
Continuing iteratively in this fashion, the NE will be reached in the limit.
This says that regardless of user 2’s transmission strategy, user 1 will transmit with full power. The
same can be said about user 2. Consequently, the only NE of this game is the transmit power tuple
( ¯p1, ¯p2). Obviously, assuming that each user is indeed selﬁsh and they intend to maximize their
own utility, the NE point ( ¯p1, ¯p2) can be implemented without any explicit coordination between
the users. Now let us assess the efﬁciency of such power allocation scheme in terms of system sum
rate. In Figures 8.13 and 8.14, we plot the rate region boundary and the NE points for different inter-
ference levels. We see that when interference is low, the NE corresponds exactly to the maximum
sum rate point. However, when interference is strong, the NE scheme is inferior to the time sharing
scheme in which the users transmit with full power in an orthogonal and interference free fashion
(e.g., TDMA or FDMA). Nonetheless, it should be pointed out that the NE point can be reached
without user coordination, while the time sharing scheme requires the users to synchronize their
transmissions.
We refer the readers to the September 2009 issue of IEEE Signal Processing Magazinefor the
applications of game theory to wireless communication and signal processing.

2.08.4 Distributed Resource Allocation in Interference Channel
449
0.2
0
0
0.1
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
A
0.2
0.4
0.6
0.8
1
R1
C
Rate Region Frontier
NE
Point
R1
R2
FIGURE 8.13
An illustration of the efﬁciency of the NE for 2-user IC when the interference is weak. ¯p1 = ¯p2 = 1,
|H11|2 = |H22|2 = 1, |H12|2 = |H21|2 = 0.5, σ 2
1 = σ 2
2 = 1. At point A and C, a single user transmits using
full power; at the NE point, both users transmit using full power.
2.08.4.2 Distributed resource allocation for interference channels
Early works on distributed physical layer resource allocation in wireless networks largely deal with the
scalar IC models. Sarayda et al. [120,121] and Goodman and Mandayam [122] are among the ﬁrst to cast
the general scalar power control problem in a game theoretic framework. They proposed to quantify the
tradeoff between the users’ QoS requirements and energy consumption by a utility function in the form:
Uk(pk, p−k) = Rk f (SINRk)
pk
,
(8.97)
where Rk is user k’s ﬁxed transmission rate, and f (SINRk) is a function of user k’s SINR that char-
acterizes its bit error rate (BER). They showed that any NE point is inefﬁcient in the Pareto sense,
i.e., it is possible to increase the utility of some of the terminals without hurting any other terminal.
To improve the efﬁciency of the power control game, they proposed to charge the users with a price
that is proportional to their transmit powers. Speciﬁcally, each users’ utility function now becomes
Uk(pk, p−k) = Rk f (SINRk)/pk −αk pk, where αk is a positive scalar that can be appropriately chosen
by the system operator. They showed that this modiﬁed game always admits a NE, and proposed an
algorithm that allows the users to reach one of the NEs by adapting their transmit powers in the best

450
CHAPTER 8 Signal Processing and Optimal Resource Allocation
0.2
0.4
0.6
0.8
1
R
A
1
NE Point
C
Achievable Rates by Performing Time Sharing
0
0
0.1
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0.2
R2
FIGURE 8.14
An illustration of the inefﬁciency of the NE for 2-user IC when the interference is strong. ¯p1 = ¯p2 = 1,
|H11|2 = |H22|2 = 1, |H12|2 = |H21|2 = 2, σ 2
1 = σ 2
2 = 1. At point A and C, a single user transmits using
full power; at the NE point, both users transmit using full power.
response fashion. Meshkati et al. [123,124] extended the above works to the multi-carrier data network.
They deﬁned the utility function for each user as
Uk(pk, p−k) =
N
n=1Rn
k fk(SINRn
k)
N
n=1 pn
k
,
(8.98)
where the function fk(·) represents the BER of user k, and it incorporates the underlying structure of
different linear receivers. However, such multi-carrier power control game is more complicated than
the scalar power control game introduced early, and in certain network conﬁgurations it is possible that
no NE exists (see [123]).
An alternative approach in distributed power control is to directly optimize the individual users’
transmission rates. Consider a K-user N-channel parallel IC model. Assume that each user k ∈K is
interested in maximizing its transmission rate, and again assume that its total transmission power budget
is ¯pk. Then the users’ utility functions as well as their feasible spaces can be expressed as
Uk(pk, p−k) =
N

n=1
log2

1 +
|Hn
kk|2 pn
k
1 + 
l̸=k |Hn
lk|2 pn
l

,
k = 1, . . . , K,
(8.99)

2.08.4 Distributed Resource Allocation in Interference Channel
451
Channel Index n
Transmission
power Level
FIGURE 8.15
Illustration of the Water-Filling computation for user k.
χk =

pk

N

n=1
pn
k ≤¯pk,
pn
k ≥0,
n = 1, · · · , N

,
k = 1, . . . , K.
(8.100)
Fixing p−k, user k’s best response solution p∗
k is the classical water-ﬁlling (WF) solution
pn,∗
k
=

1
λk
−
1 + 
l̸=k|Hn
lk|2 pn
l
|Hn
kk|2
+
,
n = 1, . . . , N,
(8.101)
where λk ≥0 is the dual variable ensuring the sum power constraint, and the operator [x]+ = max{x, 0}.
Figure 8.15 illustrates the WF solution for user k. We note that in order to compute the WF solution, user
k needs to know the terms {1 + 
l̸=k |Hn
lk|2 pn
l }N
n=1, which is simply the set of noise-plus-interference
(NPI) levels on all its channels. They can be measured locally at its receiver. We refer to this game as
a WF game.
Yu et al. [60] is the ﬁrst to formulate the distributed power control problem as a WF game. The authors
proposed an iterative water-ﬁlling algorithm (IWFA) in which the following two steps are performed
iteratively:
1. each user k ∈K measures its NPI power {1 + 
l̸=k |Hn
lk|2 pn,(t)
l
}N
n=1;
2. each user k ∈K computes its power allocation p(t+1)
k
according to (8.101).

452
CHAPTER 8 Signal Processing and Optimal Resource Allocation
Variations of the IWFA algorithm allow the users to update using different schedules. The following
three update schemes have been proposed: (a) simultaneous update, in which all the users update their
power in each iteration, see [60,125]; (b) sequential update, in which a single user updates in each
iteration, see [125,126]; (c) asynchronous update, in which a random fraction of users update in each
iteration, and they are allowed to use outdated information in their computation, see [127]. Regardless
of the speciﬁc update schedule used, the IWFA algorithm is a distributed algorithm because only local
NPI measurements are needed for the users to perform their independent power update.
The properties of the WF game as well as the convergence conditions of the IWFA have been
extensively studied. The original work has only provided sufﬁcient conditions for the convergence of
the IWFA in a 2-user network. Subsequent works such as [125,126,128–130] generalized this result to
networks with arbitrary number of users. Luo and Pang [126] characterized the NE of the water-ﬁlling
game as the solution to the following afﬁne variational inequality (AVI)
(p′ −p)(1 + Mp) ≥0,
∀p′ ∈χ,
(8.102)
where M is a block partitioned matrix with its (i j)th block deﬁned as Mi j = diag

|H1
ji|2
|H1
ii|2 , . . . ,
|H N
ji |2
|H N
ii |2

.
Using the AVI characterization (8.102), they also showed that the sequential version of the IWFA
corresponds to the classical projection algorithm whose convergence to the unique NE of the water-
ﬁlling game is guaranteed if the following contraction condition is satisﬁed
ρ((I −ϒlow)−1ϒupp) < 1,
(8.103)
where ϒlow and ϒupp is the strictly lower and strictly upper triangular part of a K ×K matrix ϒ given by
[ϒ]q,r ≜
⎧
⎨
⎩
maxn
!
|Hn
rq|2
|Hnqq|2
2
if r ̸= q,
0
otherwise.
(8.104)
Also using the AVI characterization (8.102), the authors of [129,125] further proved that the condition
ρ(ϒ) < 1
(8.105)
is sufﬁcient for the convergence of the IWFA as well as the uniqueness of the NE. We refer the readers
to [131] for a detailed comparison of various conditions for the convergence of the IWFA. It is worth
noticing that all the sufﬁcient conditions for the convergence of IWFA require that the interference
among the users are weak. For example, a sufﬁcient condition for (8.105) is

l̸=k
|Hn
kl|2sk < |Hn
ll|2sl,
∀k ∈K, n ∈N,
(8.106)
where sk > 0, k = 1, . . . , K is a set of constant scalars. Intuitively, this condition says that at the
receiver of each user k ∈K, the power of the useful signal should be larger than the power of total
interference. When the interference is strong, IWFA diverges. Leshem and Zehavi [132] provided an
example in which all forms of IWFA diverge, regardless of their update schedules. We remark that

2.08.4 Distributed Resource Allocation in Interference Channel
453
extending the IWFA so that it converges in less stringent conditions that do not require the interference
to be weak is still an open problem. Without any algorithmic modiﬁcations, the standard IWFA is only
known to converge [126] when the crosstalk coefﬁcients are symmetric
|Hn
rq|2
|Hnqq|2 =
|Hn
qr|2
|Hnrr|2 ,
∀r ̸= q, ∀n,
regardless the interference levels.
The IWFA has been recently generalized to MIMO IC model. In the MIMO WF game, the strategy
of each user k ∈K is its transmission covariance matrix Qk. The rate utility function and strategy set
for user k can be expressed as
Uk(Qk, Q−k) = log2 det
⎛
⎜⎝HkkQkHH
kk
⎛
⎝INr +

l̸=k
HlkQlHH
lk
⎞
⎠
−1
+ INr
⎞
⎟⎠,
(8.107)
χk = {Qk : Tr(Qk) ≤¯pk, Qk ⪰0} .
(8.108)
In this case, each user k’s best response BRk(Q−k) is again a water-ﬁlling solution, see [133]. Arslan
et al. [134] suggested that in each iteration, the users’ covariance can be updated as
Q(t+1)
k
= αtQ(t)
k + (1 −αt)BRk(Qt
−k),
(8.109)
where {αt}∞
t=1 is a set of constants that satisfy αt ≥0, limt→∞αt = 0 and limt→∞
T
t=1 αt < ∞.
They claimed that their algorithm converges when the interference is weak, but no speciﬁc conditions
are given. This work has been generalized by Scutari et al. [131,135], in which rigorous conditions for
the convergence of the MIMO IWFA have been derived. In particular, consider a MIMO network in
which Nt = Nr and the direct link channel matrices {Hkk}K
k=1 are all nonsingular. Deﬁne a K × K
matrix S as
[S]q,r ≜

ρ

HH
rqH−H
qq H−1
qq Hrq

if r ̸= q,
0
otherwise.
(8.110)
Then the condition ρ(S) < 1 is sufﬁcient for the convergence of the sequential/simultaneous/
asynchronous MIMO IWFA. This condition is again a weak interference condition, and future work is
needed to extend the MIMO IWFA to work in networks without this restriction. We refer the readers to
web pages of Yu, Palomar, and Pangfor other works related to the WF games and IWFA.
The above parallel and MIMO WF games have been extended in several directions. A series of recent
works considered the robustness issue in a WF games. For instance, Gohary et al. [136] considered the
WF game in the presence of a jammer. Let us denote user 0 as the jammer and denote its transmission
power as p0 =

p1
0, . . . , pN
0
	T . The rate utility function of a normal user k (k ̸= 0) becomes
Uk(pk, p−k, p0) =
N

n=1
log2

1 +
|Hn
kk|2 pn
k
1 + 
l̸=k |Hn
lk|2 pn
l + |Hn
0k|2 pn
0

.
(8.111)

454
CHAPTER 8 Signal Processing and Optimal Resource Allocation
Suppose the jammer’s objective is to minimize the utility of the whole system. This can be reﬂected by
its utility function and the strategy set
U0(p0, p) = −
K

k=1
Uk(pk, p−k, p0),
(8.112)
χ0 =

p0 :
N

n=1
pn
0 ≤¯p0, pn
0 ≥0, ∀n ∈N

.
(8.113)
Gohary et al. [136] proposed a generalized IWFA (GIWFA) algorithm in which the normal users and
the jammer all selﬁshly maximize their respective utility functions. Notice that the selﬁsh maximization
problems are all convex. The convergence condition for the GIWFA is
ρ((I −ϒlow)−1ϒupp) ≤
1
1 + a −c < 1,
(8.114)
where the matrix ϒ is deﬁned in (8.104), and a > 0 and c > 0 are constants related to the system
parameters. Clearly this condition is more restrictive than those of the original IWFA, for example the
condition (8.103). This is partly because the presence of the jammer introduces uncertainty to the NPI
that each normal user experiences.
Uncertainty of the NPI is also caused by events such as sudden changes in the number of users in the
system or errors of interference measurement at the receivers. Setoodeh and Haykin [137] seek a formu-
lation that takes into consideration the worst case NPI errors. Let I n
k denote the power of NPI that user k
should have experienced on channel n if no measurement errors occur. Let 3I n
k = I n
k −I n
k be the mea-
sured NPI value, with I n
k representing the NPI uncertainty. Let Ik =

I n
1 , . . . , I n
K
	T and suppose
it is bounded, i.e., ∥Ik∥≤ϵk for some ϵk > 0. In this robust WF game, the objectives of the users are to
maximize their worst case transmission rate. In other words, user ks utility function can be expressed as
Uk(pk, p−k) =
min
∥Ik∥≤ϵk
N

n=1
log2

1 + |Hn
kk|2 pn
k
3I n
k + I n
k

.
(8.115)
This formulation trades performance in favor of robustness, thus the equilibrium solution obtained is
generally less efﬁcient than that of the original IWFA. In [138], an averaged version of IWFA was
proposed which converges when the error of the NPI Ik satisﬁes certain conditions. In [139], the
authors provided a probabilistically robust IWFA to deal with the quantization errors of the NPI at the
receiver of each user. In this algorithm, users allocate their powers to maximize their total rate for a
large fraction of the error realization.
Another thread of works such as [58,140–143] generalized the original WF game and the IWFA to
interfering cognitive radio networks (CRN). In a CRN, the secondary users (SUs) are allowed to use
the spectrum that is assigned to the primary users (PUs) as long as the SUs do not create excessive
interference to the primary network. Suppose the secondary network is a K-user N-channel parallel
IC. Let Q = {1, . . . , Q} denote the set of PUs in the network. Let |Gn
kq|2 denote the channel gain
from SU k to PU q on channel n. The following aggregated interference constraints are imposed on the

2.08.4 Distributed Resource Allocation in Interference Channel
455
secondary network (these constraints are also referred to as the interference temperature-constraints,
see [144,145])
K

k=1
|Gn
kq|2 pk ≤I n
q,
∀(q, n) ∈Q × N,
(8.116)
where I n
q represents the maximum aggregated interference allowed at the receiver of PU q on channel
n. The original WF algorithm needs to be properly modiﬁed to strictly enforce these interference
constraints in the equilibrium. Xie et al. [143] formulated the power allocation problem in this CRN as a
competitive market model. In this model, each channel has a ﬁctitious price per unit power, and the users
must purchase the transmission power on each channel to maximize their data rates. Scutari et al. [135,
146] systematically studied the WF game with interference constraints. For each primary user q, they
introduced a set of interference prices νq =

ν1
q, . . . , νN
q
 T
. Each SU is charged for their contribution
of total interference at PUs’ receiver. Speciﬁcally, a SU k’s utility function and feasible set is deﬁned as
Uk(pk, p−k, ν) = Rk(pk, p−k) −
Q

q=1
N

n=1
νn
q|Gn
kq|2 pn
k ,
(8.117)
χk =

pk :
N

n=1
pn
k ≤¯pk, pn
k ≥0, n = 1, . . . , N

,
(8.118)
where Rk(pk, p−k) is user k’s transmission rate. The NE of this interference-constrained WF game is
the tuple (ν∗, p∗) that satisﬁes the following conditions
p∗
k = max
pk∈χk Uk(pk, p∗
−k, ν∗),
K

k=1
|Gn
kq|2 pn,∗
k
≤I n
q, (q, n) ∈Q × N,
νn,∗
q

I n
q −
K

k=1
|Gn
kq|2 pn,∗
k

= 0, νn,∗
q
≥0, (q, n) ∈Q × N.
Scutari et al. [135,146] derived the conditions for the existence and uniqueness of the NE for this game.
Introduce a N × N matrix 4ϒ
[4ϒ]l,k ≜
⎧
⎨
⎩
−maxn∈N
!
|Hn
lk|2
|Hn
kk|2 ×
innr
n
lk
2
if k ̸= l,
1
otherwise,
(8.119)
where
innr
n
lk ≜1 + 
m∈K |Hn
km|2 ¯pk. Then the condition 4ϒ ⪰0 guarantees the uniqueness of the NE.
A set of distributed algorithms that alternately update the users’ power allocation and the interference
prices were proposed to reach the NE of this game. The MIMO generalization has been considered in
[147], whereby both the SUs and PUs are equipped with multiple antennas. Another extension [142]

456
CHAPTER 8 Signal Processing and Optimal Resource Allocation
considered the possibility that the SU-PU channels may be uncertain, and formulated a robust WF game
that ensures the SU-PU interference constraints are met even in the worst case channel conditions.
All the above mentioned WF games can be categorized as rate adaptive (RA) games, in which the
users selﬁshly maximize their own data rates. One drawback of the RA formulation is that individual
users have no QoS guarantees. Alternatively, a ﬁxed margin (FM) formulation allows each user to mini-
mize its transmission power while maintaining its QoS constraint. The FM formulation is more difﬁcult
to analyze due to the coupling of the users’ strategy spaces resulted from the QoS constraint. For the par-
allel IC model, the utility function and the strategy set for user k in a FM formulation can be expressed as
Uk(pk) = −
N

n=1
pn
k ,
(8.120)
χk(p−k) =
5
pk : Rk(pk, p−k) ≥ζk, pn
k ≥0, n ∈N
6
,
(8.121)
where ζk is the rate target for user k. The solution to the individual users’ utility maximization problems,
assuming the feasibility of the rate targets, is again a water-ﬁlling solution
pn,∗
k
=

λk −
1 + 
l̸=k |Hn
lk|2 pn
l
|Hn
kk|2
+
,
n = 1, . . . , N,
(8.122)
where λk is the water-level that is associated with user k’s rate constraint.
A NE of this FM game (which is usually referred to as the generalized NE due to the coupling of the
users’ strategy spaces) is deﬁned as a power vector p∗that satisﬁes
p∗
k ∈arg
max
pk∈χk(p∗
−k) Uk

pk, p∗
−k

,
k = 1, . . . , K.
(8.123)
Similar to the min-power QoS constrained formulation discussed in the previous section, the ﬁrst thing
we need to characterize for this FM game is the feasibility of a given set of rate targets. The following
condition is among many of those that have been derived in [148] which guarantee the existence of a
bounded power allocation achieving the given set of rate targets

l̸=k
|Hn
kl|2
|Hn
kk|2 <
1
exp{ζk} −1,
(n, k) ∈N × K.
(8.124)
This condition is again a weak interference condition. The following condition is sufﬁcient for the
uniqueness of the (generalized) NE of the FM game

l̸=k
max
n∈N

|Hn
kl|2
|Hn
kk|2

<
β
exp{ζl} −1,
k ∈K,
(8.125)
where β < 1 is related to the set of given rate targets. This condition is also sufﬁcient for the convergence
of a FM-IWFA in which the users sequentially or simultaneously update their power using the WF
solution. Algorithmic extension of this work to the CRN with interference constraints of the form

2.08.4 Distributed Resource Allocation in Interference Channel
457
0
1
2
3
4
5
6
0
1
2
3
4
5
6
R
R
1
2
Rate Boundary Achievable by
the SCALE Algorithm
NE of the WF game
FIGURE 8.16
Illustration of the inefﬁciency of the NE point for a WF game with K = 2, N = 32, and ¯p1 = ¯p2 = 1.
(8.116) has been considered recently in [149]. It remains to see how the FM games and their theoretical
properties (e.g., uniqueness of the NE, convergence of the FM-IWFA) can be extended to MIMO CRNs
with interference constraints.
We remark that the NE points of the various RA based WF games introduced in this section is
generally inefﬁcient, in the sense that the sum rate of the users is often smaller compared with that of the
socially optimal solutions.1 In Figure 8.16, we illustrate such inefﬁciency of the NE in a parallel IC with
K = 2, N = 32 and randomly generated channel coefﬁcients. We plot the NE point of the WF game as
well as the rate region boundary achieved by the SCALE algorithm. In order to improve the efﬁciency
of the NE, user coordination must be incorporated into the original WF game. The pricing algorithms
such as MDP, M-IWF or WMMSE introduced in the previous section are examples of such extensions.
In those algorithms, system efﬁciency is improved due to explicit message exchange and cooperation
among the users. Careful analysis is needed to identify the tradeoffs between the improvement of the
system sum rate and the signaling overhead. Evidently, when the total number of users in the system
is large, a complete cooperation of all users is too costly. An interesting problem is to decide how to
partition the users into collaborative groups in a way that strike an optimal tradeoff between system
performance and coordination overhead.
1However, note that in a MAC channel, which is a special case of the IC, the NEs are indeed efﬁcient. See [150]. In this case,
the sequential version of the IWFA converge to a joint strategy that maximizes the system sum rate.

458
CHAPTER 8 Signal Processing and Optimal Resource Allocation
2.08.5 Resource allocation via interference alignment
Theoretically, the optimal resource allocation for a MIMO interference channel is related to the char-
acterization of the capacity region of an interference channel, i.e., determining the set of rate tuples
that can be achieved by the users simultaneously. In spite of intensive research on this subject over the
past three decades, the capacity region of interference channels is still unknown (even for small number
of users). The lack of progress to characterize the capacity region of the MIMO interference channel
has motivated researchers to derive various approximations of the capacity region. For example, the
maximum total degrees of freedom (DoF) corresponds to the ﬁrst order approximation of sum-rate
capacity in the high SNR regime. Speciﬁcally, in a K-user interference channel, we deﬁne the degrees
of freedom region as the following [21]:
D =

(d1, d2, . . . , dK ) ∈RK
+
∀(w1, w2, . . . , wK ) ∈RK
+,
K

k=1
wkdk ≤lim sup
SNR→∞

sup
R∈C
1
log SNR
K

k=1
wk Rk

,
(8.126)
where C is the capacity region and Rk is the rate of user k. The total DoF in the system can be deﬁned
as the following:
η =
max
(d1,d2,...,dK )∈D d1 + d2 + . . . + dK .
(8.127)
Roughly speaking, the total DoF is the number of independent data streams that can be communicated
in the channel without interference.
For various channel models, the DoF region or the total DoF have been characterized recently. In
particular, for a point-to-point MIMO channel with M antennas at the transmitter and N antennas at the
receiver, the total DoF is η = min{M, N}. Different approaches such as SVD precoder or V-BLAST
can be used to achieve this DoF bound. For a 2-user MIMO fading interference channel with user k
equipped with Mk transmit antennas and Nk receive antennas (k = 1, 2), Jafar and Fakhereddin [151]
proves that the maximum total DoF is
η = min{M1 + M2, N1 + N2, max{M1, N2}, max{M2, N1}}.
(8.128)
Therefore, for the case of M1 = M2 = N1 = N2, the total DoF in the system is the same as the single
user case. In other words, we do not gain more DoF by increasing the number of users from one to
two. Interestingly, if generic channel extensions (drawn from a continuous probability distribution) are
allowed either across time or frequency, Cadambe and Jafar [21] showed that the total DoF is η = K M/2
for a K-user MIMO interference channel, where M is the number of transmit/receive antennas per user.
This surprising result implies that each user can effectively utilize half of the total system resources in
an interference-free manner by aligning the interference at all receivers.2 Moreover, this total DoF can
be achieved by using a carefully designed linear beamforming strategy.
2The idea of interference alignment was introduced in [152–154] and the terminology “interference alignment" was ﬁrst used
in [155].

2.08.5 Resource Allocation Via Interference Alignment
459
Mathematically, a linear beamforming strategy for a K-user MIMO IC can be described by the
transmit beamforming matrices {Vk}k∈K and the receive beamforming matrices {Uk}k∈K. The receiver
k estimates the transmitted data vector sk as follows
xk = Vksk,
ˆsk = UH
k yk,
(8.129)
where the power of the data vector sk ∈Rdk×1 is normalized such that E[sksH
k ] = I, and ˆsk is the
estimate of sk at the k-th receiver. The matrices Vk ∈CMk×dk and Uk ∈CNk×dk are the beamforming
matrices at the k-th transmitter and receiver respectively, where Mk (Nk) is the number of antennas
at transmitter k (respectively receiver k). Without channel extension, the linear interference alignment
conditions can be described by the following zero-forcing conditions [156,157]
UH
k H jkV j = 0,
k = 1, . . . , K, ∀j ̸= k,
(8.130)
rank

UH
k HkkVk

= dk,
k = 1, . . . , K.
(8.131)
The ﬁrst equation guarantees that all the interfering signals at receiver k lie in the subspace orthogonal
to Uk, while the second one assures that the signal subspace HkkVk has dimension dk and is linearly
independent of the interference subspace. Clearly, as the number of users K increases, the number
of constraints on the beamformers {Uk, Vk} increases quadratically in K, while the number of design
variables in {Uk, Vk} only increases linearly. This suggests the above interference alignment can not
have a solution unless K or dk is small.
If the interference alignment conditions (8.130) and (8.131) hold for some linear beamforming
matrices {Vk, Uk}k∈K, then transmitter k can use Vk to send dk independent data streams to receiver k
(per channel use) without any interference. Thus, dk represents the DoF achieved by the k-th transmit-
ter/receiver pair in the information theoretic sense of (8.126). In other words, the vector (d1, d2, . . . , dK )
in (8.130) and (8.131) represents the tuple of DoF achieved by linear interference alignment. Intuitively,
the larger the values of d1, d2, . . . , dK , the more difﬁcult it is to satisfy the interference alignment
conditions (8.130) and (8.131).
In principle, we can allocate resources by maximizing the total achievable DoF. In particular, for a
speciﬁc channel realization {Hkj}k, j∈K, we need to ﬁnd the beamforming matrices {Vk, Uk} to maximize
the total DoF while satisfying (8.130) and (8.131).
max
{Uk,Vk}K
k=1
K

k=1
dk
subject to UH
k HkjV j = 0,
k = 1, . . . , K, j ̸= k,
rank

UH
k HkkVk

= dk,
k = 1, . . . , K.
Unfortunately, according to Razaviyayn et al. [156], this problem is NP-hard. So we are led to ﬁnd subop-
timal solution for this problem. However, no efﬁcient algorithms have been developed to approximately
solve this problem at this point.
Instead of maximizing the total DoF, we can focus on a seemingly simpler problem: for a given
channel realization {Hkj}k, j∈K and a ﬁxed DoF tuple d = (d1, . . . , dK ), check if there exist linear

460
CHAPTER 8 Signal Processing and Optimal Resource Allocation
beamformers {Vk, Uk}k∈K satisfying the alignment conditions (8.130) and (8.131). Notice that the
conditions (8.130) and (8.131) are quadratic polynomial equations, which are difﬁcult to solve in
general. However, if we ﬁx either {Uk}k∈K or {Vk}k∈K, the quadratic equations become linear and can
be solved via the linear least squares. This suggests the following alternating directions method for
solving (8.130) and (8.131) (for a ﬁxed d):
1. Fix the transmit beamformers {Vk}k∈K. Each receiver k solves the following optimization
problem
min Tr

UH
k QkUk

s.t. UH
k Uk = Idk,
(8.132)
where Qk = 
j̸=k
p j
d j HkjV jVH
j HH
kj, with Ik = Tr

UH
k QkUk

being the total received inter-
ference power, and ¯p j being the power budget of jth transmitter.
2. Fix {Uk}k∈K and update the transmit beamformers {Vk}k∈K in a symmetric fashion as in
step 1 (by exchanging the roles of transmitter and receiver, and replacing the channel matrices
{Hk, j}k, j∈K by {HH
kj}kj∈K).
3. Repeat steps 1 and 2 until convergence.
Notice that the optimal solution U∗
k for (8.132) is given by the eigen-vectors of Qk corresponding to the
dk-smallest eigen-values. The above algorithm is proposed ﬁrst in [158] and later in [159], albeit from
a different perspective. Obviously, this algorithm cannot converge if the DoF vector d is not achievable.
However, even if d is achievable, there has been no formal analysis that shows this alternating direction
algorithm indeed will converge.
Thelackofformalconvergenceproofmaynotbesurprising.Infact,accordingto[156],evenchecking
the feasibility of (8.130) and (8.131) is NP-hard when each transmitter/receiver is equipped with at least
three antennas. Hence, for a given channel realization, assigning DoFs to the users in a manner that
ensures feasibility is not easy. However, when the number of antennas at each transmitter/receiver is at
most two, the problem of checking feasibility is polynomial time solvable ([156]).
Now let us turn our attention to the generic solvability of the interference alignment problem (8.130)
and (8.131). In other words, we focus on the existence of a beamforming solution to the quadratic
polynomial equations (8.130) and (8.131) when the channel matrices are randomly generated. To this
end, it is natural to count the number of scalar equations and the number of scalar variables in the
conditions (8.130) and (8.131). It is tempting to conjecture that there is an interference alignment
solution if and only if the number of constraints is no larger than the number of variables (see [157]).
Recently, Razaviyayn et al. [160] and Bresler et al. [161] have settled this conjecture completely in one
direction, and partially in the other direction. They derive a general condition, described below, that
must be satisﬁed by any DoF tuple (d1, d2, . . . , dK ) achievable through linear interference alignment.
Let us denote the polynomial equations in (8.131) by the index set
J ≜{(k, j) | 1 ≤k ̸= j ≤K}.
The following result ([160,161]) provides an upper bound on the total achievable DoF when no channel
extension is allowed. Consider a K-user ﬂat fading MIMO interference channel where the channel
matrices {Hi j}K
i, j=1 are generic (e.g., drawn from a continuous probability distribution). Assume no

2.08.5 Resource Allocation Via Interference Alignment
461
channel extension is allowed. Then any tuple of degrees of freedom (d1, d2, . . . , dK ) that is achievable
through linear interference alignment (8.130) and (8.131) must satisfy the following inequalities
min{Mk, Nk} ≥dk,
∀k,
(8.133)
max{Mk, N j} ≥dk + d j,
∀k, j, k ̸= j,
(8.134)

k:(k, j)∈I
(Mk −dk)dk +

j:(k, j)∈I
(N j −d j)d j ≥

(k, j)∈I
dkd j,
∀I ⊆J .
(8.135)
Roughly, the left hand side of (8.135) is equal to the number of independent scalar variables in (8.130)
and (8.131) and the right hand side of (8.135) corresponds to the number of constraints in (8.130). Thus,
the necessity of condition (8.135) for the existence of a feasible alignment scheme can be understood by
counting the dimensions. However, a formal proof of this condition requires the use of ﬁeld extension
theory ([160]). We remark that condition (8.135) can be used to bound the total DoF achievable in a
MIMO interference channel. In particular, the following upper bounds follow directly from condition
(8.135).
a. In the case of dk = d for all k, interference alignment is impossible unless
d ≤
1
K(K + 1)
K

k=1
(Mk + Nk).
b. In the case of Mk + Nk = M + N, interference alignment requires
 K

k=1
dk
2
+
K

k=1
d2
k ≤(M + N)
K

k=1
dk,
which further implies
K

k=1
dk < (M + N).
The principal assumption enabling the surprising result of [21] is that the channel extensions are
exponentially long in K 2 and are generic (e.g., drawn from a continuous probability distribution). If
no channel extensions are allowed, part (b) above shows that the total achievable DoF in a MIMO
interference channel is bounded by a constant M + N −1, regardless of how many users are present in
the system. While this bound is an improvement over the single user case which has a maximum DoF
of min{M, N}, it is signiﬁcantly weaker than the maximum achievable total DoF of K/2 for a diagonal
frequency selective (or time varying) interference channel with independent channel extensions. The
latter grows linearly with the number of users in the system [21].
If channel extensions are restricted to have a polynomial length or are not generic, the total DoF
for a MIMO interference channel is still largely unknown even for the Single-Input-Single-Output
(SISO) interference channel. This is an interesting open problem. For the 3-user special case, Ref. [162]
provided a characterization of the total achievable DoF as a function of the diversity.

462
CHAPTER 8 Signal Processing and Optimal Resource Allocation
Conversely, if all users have the same DoF d and the number of antennas Mk, Nk are divisible by
d for each k, then condition (8.135) for each subsystem of (8.130) and (8.131) is also sufﬁcient for
the feasibility of interference alignment for generic choice of channel coefﬁcients (e.g., drawn from a
continuous probability distribution). If in addition, Mk = M and Nk = N for all k and M, N are divisible
byd,thentheseresultsimplythatinterferencealignmentisachievableifandonlyif (M+N) ≥d(K +1).
Moreover, Bresler et al. [161] considered the symmetric case with Mk = Nk = M, dk = d for all k,
and proved that the feasibility of interference alignment in this case is equivalent to 2M ≥d(K + 1),
regardless of the divisibility of M by d. When K is odd and 2M = d(K + 1), then d divides M, so this
result and Theorem 2 are in agreement. However, the case when K is even is not covered by Theorem 2.
To summarize, the initial work [21] is exciting and suggests that it may be possible to allocate
resourcesinaMIMOICbasedonDoF.However,thecomplexityanddesignoftheinterferencealignment
schemes have presented several challenges to the practicality of this approach for resource allocation.
• For a given channel realization, to determine whether a given set of DoF tuple is achievable is
NP-hard (i.e., exponential effort is likely to be required for large number of users).
• Without channel extensions, the average DoF per user is shown to be at most 2M/(K + 1), which
is signiﬁcantly smaller than M/2 when there are a large number of independent channel extensions
(see [21]). Here M is the number of antennas at each transmitter and receive. Notice that the average
per user DoF of 2M/(K + 1) approximately doubles that of the orthogonal approaches (e.g. TDMA
or FDMA).
• It requires too many channel extensions to reap the DoF beneﬁt promised by Cadambe and Jafar [21].
• It requires full CSI, which can be difﬁcult for large networks.
• It often requires selecting a set of feasible DoFs for the users a priori, which is difﬁcult.
At this point, interference alignment appears most useful for a small system (e.g., 3–4 links) where a
closed form interference alignment solution exists [21], and when using no or a small number of channel
extensions. For a large network, direct maximization of the weighted sum-rate (or weighted sum utility
maximization) seems to offer more potential for resource allocation and interference mitigation. For
one thing, it requires the same amount of CSI, and yet can offer more sum-rate performance across
all SNR regime than that of interference alignment. Moreover, it does not require selecting a DoF for
each user in advance. As for future work, we suggest further investigation of the beneﬁts of interference
alignment for a small system with a few channel extensions.
Relevant Theory: Signal Processing Theory and Array Signal Processing
See Vol. 1, Chapter 3 Discrete-Time Signal and Systems
See Vol. 1, Chapter 12 Adaptive Filters
See Vol. 3, Chapter 19 Array Processing in the Face of Nonidealities
References
[1] M. Cave, C. Doyle, W. Webb, Essentials of Modern Spectrum Management, Cambridge University Press,
2007.
[2] A. Goldsmith, Wireless Communications, Combridge University Press, New York, 2005.

References
463
[3] FCC, Report of the spectrum efﬁciency working group, 2002. <http://www.fcc.gov/sptf/reports.html>.
[4] A. Sahai, M. Mishra, R. Tandra, K. Woyach, Cognitive radios for spectrum sharing, IEEE Signal Process.
Mag. (2009) 140–146.
[5] 3GPP, Evolved Universal Terrestrial Radio Access (EUTRA) and Evolved Universal Terrestrial Radio Access
Network (EUTRAN); overall description, (2011) 3GPP TS 36.300, V8.9.0.
[6] V. Chandrasekhar, J. Andrews, Femtocell networks: a survey. IEEE Commun. Mag. (2008) 59–67.
[7] A. Damnjanovic, J. Montojo, Y. Wei, T. Ji, T. Luo, M. Vajapeyam, T. Yoo, O. Song, D. Malladi, A survey
on 3GPP heterogeneous networks, IEEE Wireless Commun. 18 (2011) 10–21.
[8] G. Foschini, K. Karakayali, R. Valenzuela, Coordinating multiple antenna cellular networks to achieve
enormous spectral efﬁciency, IEE Proc. Commun. 153 (2006) 548–555.
[9] D. Gesbert, S. Hanly, H. Huang, S. Shamai, O. Simeone, W. Yu, Multi-cell MIMO cooperative networks: a
new look at interference, IEEE J. Sel. Areas Commun. 28 (2010) 1380–1408.
[10] D. Gesbert, S. Kiani, A. Gjendemsj, ien, G., Adaptation, coordination, and distributed resource allocation in
interference-limited wireless networks, Proc. IEEE 95 (2007) 2393–2409.
[11] F. Khan, LTE for 4G Mobile Broadband: Air Interface Technologies and Performance, Cambridge University
Press, 2009.
[12] D. Martín-Sacristán, J.F. Monserrat, J. Cabrejas-Peñuelas, D. Calabuig, S. Garrigas, N. Cardona, On the way
towards fourth-generation mobile: 3GPP LTE and LTE-advanced, EURASIP J. Wireless Commun. Networks
4 (1–4) (2009) 10.
[13] M. Sawahashi, Y. Kishiyama, A. Morimoto, D. Nishikawa, M. Tanno, Coordinated multipoint transmission/
reception techniques for LTE-advanced, IEEE Wireless Commun. 17 (2010) 26–34.
[14] T.M. Cover, J.A. Thomas, Elements of Information Theory, second ed., Wiley, 2005.
[15] T. Han, K. Kobayashi, A new achievable rate region for the interference channel, IEEE Trans. Inform. Theory
27 (1981) 49–60.
[16] R. Etkin, D. Tse, H. Wang, Gaussian interference channel capacity to within one bit, IEEE Trans. Inform.
Theory (2008).
[17] A.B. Carleial, A case where interference does not reduce capacity, IEEE Trans. Inform. Theory 21 (1975)
569–570.
[18] H. Sato, The capacity of the Gaussian interference channel under strong interference, IEEE Trans. Inform.
Theory 27 (1981) 49–60.
[19] S.T. Chung, J.M. Ciofﬁ, The capacity region of frequency selective Gaussian interference channel under
strong interference, IEEE Trans. Commun. 55 (2007) 1812–1821.
[20] X. Shang, B. Chen, G. Kramer, H. Poor, Capacity regions and sum-rate capacities of vector Gaussian
interference channels, IEEE Trans. Inform. Theory 56 (2010) 5030–5044.
[21] V. Cadambe, S. Jafar, Interference alignment and degrees of freedom of the k-user interference channel,
IEEE Trans. Inform. Theory 54 (2008) 3425–3441.
[22] X. Shang, B. Chen, G. Kramer, H. Poor, Noisy-interference sum-rate capacity of parallel Gaussian interfer-
ence channels, IEEE Trans. Inform. Theory 57 (2011) 210–226.
[23] X. Shang, G. Kramer, B. Chen, A new outer bound and the noisy-interference sum-rate capacity for Gaussian
interference channels, IEEE Trans. Inform. Theory 55 (2009) 689–699.
[24] J.Y.N. Hui, P.A. Humblet, The capacity region of the totally asynchronous multiple-access channel, IEEE
Trans. Inform. Theory 31 (1985) 207–216.
[25] M. Charafeddine, A. Paulraj, Maximum sum rates via analysis of 2-user interference channel achievable
rates region. in: 43rd Annual Conference on Information Sciences and Systems, 2009, pp. 170–174.
[26] M. Charafeddine, A. Sezgin, A. Paulraj, Rate region frontiers for n-user interference channel with interference
as noise, in: Proceddings of Annual Allerton Conference on Communications, Control and Computing, 2007.

464
CHAPTER 8 Signal Processing and Optimal Resource Allocation
[27] S. Hayashi, Z.-Q. Luo, Spectrum management for interference-limited multiuser communication systems,
IEEE Trans. Inform. Theory 55 (2009) 1153–1175.
[28] E.A. Jorswieck, E.G. Larsson, The MISO interference channel from a game-theoretic perspective: a combi-
nation of selﬁshness and altruism achieves pareto optimality, in: IEEE ICASSP, 2008, pp. 5364–5367.
[29] E. Larsson, E. Jorswieck, Competition versus cooperation on the MISO interference channel, IEEE J. Sel.
Areas Commun. 26 (2008) 1059–1069.
[30] E.A. Jorswieck, E.G. Larsson, D. Danev, Complete characterization of the pareto boundary for the MISO
interference channel, IEEE Trans. Signal Process. 56 (2008) 5292–5296.
[31] J. Mo, J. Walrand, Fair end-to-end window-based congestion control, IEEE/ACM Trans. Network. 8 (2000)
556–567.
[32] H. Boche, S. Naik, T. Alpcan, Characterization of convex and concave resource allocation problems in
interference coupled wireless systems, IEEE Trans. Signal Process. 59 (2011) 2382–2394.
[33] Y.-F. Liu, Y.-H. Dai, Z.-Q. Luo, Coordinated beamforming for MISO interference channel: complexity
analysis and efﬁcient algorithms, IEEE Trans. Signal Process. 59 (2011) 1142–1157.
[34] Z.-Q. Luo, S. Zhang, Dynamic spectrum management: complexity and duality, IEEE J. Sel. Top. Signal
Process. 2 (2008) 57–73.
[35] M. Razaviyayn, M. Hong, Z.-Q. Luo, Linear transceiver design for a MIMO interfering broadcast channel
achieving max-min fairness, in: 2011 Asilomar Conference on Signals, Systems, and Computers, 2011.
[36] Z.K.M. Ho, D. Gesbert, Balancing egoism and altruism on interference channel: the MIMO case, in: 2010
IEEE International Conference on Communications (ICC), 2010, pp. 1–5.
[37] M. Sadek, A. Tarighat, A. Sayed, A leakage-based precoding scheme for downlink multi-user mimo channels,
IEEE Trans. Wireless Commun. 6 (2007) 1711–1721.
[38] S. Shi, M. Schubert, H. Boche, Downlink mmse transceiver optimization for multiuser MIMO systems:
duality and sum-mse minimization, IEEE Trans. Signal Process. 55 (2007) 5436–5446.
[39] S. Ulukus, R. Yates, Iterative construction of optimum signature sequence sets in synchronous cdma systems,
IEEE Trans. Inform. Theory 47 (2001) 1989–1998.
[40] H. Boche, M. Schubert, A calculus for log-convex interference functions, IEEE Trans. Inform. Theory 54
(2008) 5469–5490.
[41] H. Boche, M. Schubert, A unifying approach to interference modeling for wireless networks, IEEE Trans.
Signal Process. 58 (2010) 3282–3297.
[42] S. Stanczak, M. Wiczanowski, H. Boche, Distributed utility-based power control: objectives and algorithms,
IEEE Trans. Signal Process. 55 (2007) 5058–5068.
[43] M.R. Garey, D.S. Johnson, Computers and Intractability: A guide to the Theory of NP-Completeness, W.H.
Freeman and Company, San Francisco, USA, 1979.
[44] Y.-F. Liu, Y.-H. Dai, Z.-Q. Luo, Max-min fairness linear transceiver design for a multi-user MIMO interfer-
ence channel, in: Proceedings of the International Conference on Communicaitons 2011, 2011.
[45] M. Razaviyayn, M. Hong, Z.-Q. Luo, Linear transceiver design for a MIMO interfering broadcast channel
achieving max-min fairness, accepted by Signal Processing, special issue on sensor array processing, 2013.
[46] G. Foschini, Z. Miljanic, A simple distributed autonomous power control algorithm and its convergence,
IEEE Trans. Veh. Technol. 42 (1993) 641–646.
[47] J. Zander, Distributed cochannel interference control in cellular radio systems, IEEE Trans. Veh. Technol.
41 (1992) 305–311.
[48] J. Zander, Performance of optimal transmitter power control in cellular system, IEEE Trans. Veh. Technol.
41 (1992) 57–63.
[49] S.V. Hanly, D. Tse, Power control and capacity of spread spectrum wireless networks, Automatica 35 (1999)
1987–2012.

References
465
[50] M. Bengtsson, B. Ottersten, Optimal and Suboptimal Transmit Beamforming, Handbook of Antennas in
Wireless Communications, CRC Press, 2001.
[51] A. Wiesel, Y.C. Eldar, S. Shamai(Shitz), Linear precoding via conic optimization for ﬁxed MIMO receivers,
IEEE Trans. Signal Process. 54 (2006) 161–176.
[52] Z.-Q. Luo, W. Yu, An introduction to convex optimization for communications and signal processing, IEEE
J. Sel. Areas Commun. 24 (2006) 1426–1438.
[53] Z.-Q. Luo, S. Zhang, Duality gap estimation and polynomial time approximation for optimal spectrum
management, IEEE Trans. Signal Process. 57 (2009) 2675–2689.
[54] W. Yu, R. Lui, Dual methods for nonconvex spectrum optimization of multicarrier systems, IEEE Trans.
Commun. 54 (2006) 1310–1322.
[55] S. Boyd, L. Vandenberghe, Convex Optimization, Cambridge University Press, 2004.
[56] J.W. Huang, R.A. Berry, M.L. Honig, Distributed interference compensation for wireless networks, IEEE J.
Sel. Area. Commun. 24 (2006).
[57] F. Wang, M. Krunz, S.G. Cui, Price-based spectrum management in cognitive radio networks, IEEE J. Sel.
Top. Signal Process. 2 (2008).
[58] Y. Wu, D.H.K. Tsang, 2008. Distributed multicahnnel power allocation algorithm for spectrum sharing
coginitive radio networks, in: WCNC Proceedings, Las Vagas, USA, 2008.
[59] W. Yu, Multiuser water-ﬁlling in the presence of crosstalk, in: Information Theory and Applications, Work-
shop 07, 2007.
[60] W. Yu, G. Ginis, J.M. Ciofﬁ, Distributed multiuser power control for digital subscriber lines, IEEE J. Sel.
Areas Commun. 20 (2002) 1105–1115.
[61] C. Shi, R.A. Berry, M.L. Honig, Monotonic convergence of distributed interference pricing in wireless
networks, in: Proceedings of the 2009 IEEE international conference on Symposium on Information Theory,
vol. 3, 2009, pp. 1619–1623.
[62] D.A. Schmidt, A. Grundinger, W. Utschick, M.L. Honig, Distributed precoder optimization for interfering
MISO channels, in: International ITG Workshop on Smart Antennas, 2008, pp. 285–290.
[63] C. Shi, R.A. Berry, M.L. Honig, Distributed interference pricing with MISO channels, in: 46th Annual
Allerton Conference on Communication, Control, and Computing, 2008, pp. 539–546.
[64] C. Shi, D.A. Schmidt, R.A. Berry, M.L. Honig, W. Utschick, Distributed interference pricing for the MIMO
interference channel, IEEE Int. Conf. Commun. (2009) 1–5.
[65] S.-J. Kim, G. Giannakis, Optimal resource allocation for MIMO Ad Hoc cognitive radio networks, in: 46th
Annual Allerton Conference on Communication, Control, and Computing, 2008, pp. 39–45.
[66] L. Venturino, N. Prasad, X. Wang, Coordinated linear beamforming in downlink multicell wireless networks,
IEEE Trans. Wireless Commun. 9 (2010) 1451–1461.
[67] D. Schmidt, C. Shi, R. Berry, M. Honig, W. Utschick, Distributed resource allocation schemes, IEEE Signal
Process. Mag. 26 (2009) 53–63.
[68] J. Papandriopoulos, J.S. Evans, SCALE: a low-complexity distributed protocol for spectrum balancing in
multiuser DSL networks, IEEE Trans. Inform. Theory 55 (2009).
[69] P. Tsiaﬂakis, M. Diehl, M. Moonen, Distributed spectrum management algorithms for multiuser DSL net-
works, IEEE Trans. Signal Process. 56 (2008) 4825–4843.
[70] S.S. Christensen, R. Agarwal, E.D. Carvalho, J.M. Ciofﬁ, Weighted sum-rate maximization using weighted
MMSE for MIMO-BC beamforming design, IEEE Trans. Wireless Commun. 7 (2008) 4792–4799.
[71] D. Schmidt, C. Shi, R.A. Berry, M.L. Honig, W. Utschick, Minimum mean squared error interference
alignment, in: Proceedings of Asilomar Conference, Paciﬁc Grove, CA, 2009.
[72] Q. Shi, M. Razaviyayn, Z.-Q. Luo, C. He, An iteratively weighted MMSE approach to distributed sum-
utility maximization for a MIMO interfering broadcast channel, in: 2011 IEEE International Conference on
Acoustics, Speech and, Signal Processing (ICASSP), 2011, pp. 3060–3063.

466
CHAPTER 8 Signal Processing and Optimal Resource Allocation
[73] Q. Shi, M. Razaviyayn, Z.-Q. Luo, C. He, An iteratively weighted MMSE approach to distributed sum-utility
maximization for a MIMO interfering broadcast channel, IEEE Trans. Signal Process. 59 (2011) 4331–4340.
[74] W. Yu, T. Kwon, C. Shin, Multicell coordination via joint scheduling beamforming and power spectrum
adaptation, in: Proceedings of IEEE International Conference on Computer Communication (INFOCOM),
2011.
[75] H. Dahrouj, W. Yu, Coordinated beamforming for multicell multi-antenna wireless systems, IEEE Trans.
Wireless Commun. 9 (2010) 1748–1759.
[76] B. Song, R. Cruz, B. Rao, Network duality for multiuser MIMO beamforming networks and applications,
IEEE Trans. Commun. 55 (2007) 618–630.
[77] J. Kim, D. Cho, A joint power and subchannel allocation scheme maximizing system capacity in dense
femtocell downlink systems, in: IEEE 20th International Symposium on Personal, Indoor and Mobile Radio
Communications, 2009, pp. 1381–1385.
[78] L. Venturino, N. Prasad, X. Wang, An improved iterative water-ﬁlling algorithm for multi-cell interference
mitigation in downlink OFDMA networks, in: ACSSC, 2007, pp. 1718–1722.
[79] L. Venturino, N. Prasad, X. Wang, Coordinated scheduling and power allocation in downlink multicell
OFDMA networks, IEEE Trans. Veh. Technol. 58 (2009) 2835–2848.
[80] M. Razaviyayn, H. Baligh, A. Callard, Z.-Q. Luo, Joint user grouping and transceiver design in a mimo
interfering broadcast channel, submitted to IEEE Transactions on Signal Processing for publication.
[81] E. Matskani, N. Sidiropoulos, Z.-Q. Luo, L. Tassiulas, Convex approximation techniques for joint multiuser
downlink beamforming and admission control, IEEE Trans. Wireless Commun. 7 (2008) 2682–2693.
[82] E. Matskani, N. Sidiropoulos, Z.-Q. Luo, L. Tassiulas, Efﬁcient batch and adaptive approximation algorithms
for joint multicast beamforming and admission control, IEEE Trans. Signal Process. 57 (2009) 4882–4894.
[83] S.V. Hanly, An algorithm for combined cell-site selection and power control to maximize cellular spread
spectrum capacity, IEEE J. Sel. Areas Commun. 13 (1995) 1332–1340.
[84] F. Rashid-Farrokhi, L. Tassiulas, K. Liu, Joint optimal power control and beamforming in wireless networks
using antenna arrays, IEEE Trans. Commun. 46 (1998) 1313–1324.
[85] R.D. Yates, C.Y. Huang, Integrated power control and base station assignment, IEEE Trans. Veh. Technol.
44 (1995) 1427–1432.
[86] L. Gao, X. Wang, G. Sun, Y. Xu, A game approach for cell selection and resource allocation in heterogeneous
wireless networks, in: The Proceeding of the SECON, 2011.
[87] M. Hong, A. Garcia, J. Barrera, Joint distributed AP selection and power allocation in cognitive radio
networks, in: The Proceedings of the IEEE INFOCOM, 2011.
[88] S.M. Perlaza, E.V. Belmega, S. Lasaulce, M. Debbah, On the base station selection and base station sharing
in self-conﬁguring networks, in: Proceedings of the Fourth International ICST Conference on Performance
Evaluation Methodologies and Tools, 2009, pp. 71:1–71:10.
[89] M. Hong, Z.-Q. Luo, Joint linear precoder optimization and base station selection for an uplink MIMO
network: a game theoretic approach. in: Proceedings of the IEEE ICASSP, 2012.
[90] M. Sanjabi, M. Razaviyayn, Z.-Q. Luo, Optimal joint base station assignment and downlink beamforming
for heterogeneous networks, in: 2012 IEEE ICASSP, 2012.
[91] S.V. Hanly, Information capacity of radio networks, Ph.D. Dissertation, Cambridge University, 1993.
[92] H. Boche, S. Stanczak, Convexity of some feasible qos regions and asymptotic behavior of the minimum
total power in cdma systems, IEEE Trans. Commun. 52 (2004) 2190–2197.
[93] S. Stanczak, H. Boche, On the convexity of feasible qos regions, IEEE Trans. Inform. Theory 53 (2007)
779–783.
[94] R.D. Yates, A framework for uplink power control in cellular radio systems, IEEE J. Sel. Areas Commun.
13 (1995) 1341–1347.

References
467
[95] H. Boche, M. Schubert, A superlinearly and globally convergent algorithm for power control and resource
allocation with general interference functions, IEEE/ACM Trans. Network. 16 (2008) 383–395.
[96] Y.-F. Liu, Y.-H. Dai, Z.-Q. Luo, Joint power and admission control via linear programming deﬂation, in:
Proceedings of the ICASSP, 2012.
[97] I. Mitliagkas, N. Sidiropoulos, A. Swami, Joint power and admission control for ad-hoc and cognitive
underlay networks: convex approximation and distributed implementation, IEEE Trans. Wireless Commun.
10 (2011) 4110–4121.
[98] M. Ahmed, Call admission control in wireless networks: a comprehensive survey, IEEE Commun. Survey
Tut. 7 (2005) 49–68.
[99] M. Bengtsson, B. Ottersten, Optimal downlink beamforming using semideﬁnite optimization. in: Proceedings
of the 37th Annual Allerton Conference, 1999.
[100] M. Bengtsson, Jointly optimal downlink beamforming and base station assignment, in: 2001 IEEE Interna-
tional Conference on Acoustics, Speech, and Signal Processing (ICASSP ’01), vol. 5, 2001, pp. 2961–2964.
[101] R. Stridh, M. Bengtsson, B. Ottersten, System evaluation of optimal downlink beamforming with congestion
control in wireless communication, IEEE Trans. Wireless Commun. 5 (2006) 743–751.
[102] M. Chiang, C.W. Tan, D.P. Palomar, D. O’Neill, D. Julian, Power control by geometric programming, IEEE
Trans. Wireless Commun. 6 (2007) 2640–2651.
[103] M. Wiczanowski, S. Stanczak, H. Boche, Providing quadratic convergence of decentralized power control
in wireless networks–the method of min-max functions, IEEE Trans. Signal Process. 56 (2008) 4053–4068.
[104] L. Qian, Y. Zhang, J. Huang, MAPEL: Achieving global optimality for a non-convex wireless power control
problem, IEEE Trans. Wireless Commun. 8 (2009) 1553–1563.
[105] J.B.G. Frenck, S. Schaible, Fractional Programming, Handbook of Generalized Convexity and Generalized
Monoticity, Springer, 2006, pp. 335–386.
[106] N.T.H. Phuong, H. Tuy, A uniﬁed monotonic approach to generalized linear fractional programming,
J. Global Optim. 26 (2003).
[107] L. Qian, Y. Zhang, Monotonic optimization for non-concave power control in multiuser multicarrier network
systems, in: Proceedings of IEEE International Conference on Computer, Communication (INFOCOM),
2009, pp. 172–181.
[108] C.W. Tan, M. Chiang, R. Srikant, Fast algorithms and performance bounds for sum rate maximization in
wireless networks, in: Proceedings of the IEEE International Conference on Computer Communication
(INFOCOM), 2009, pp. 1350–1358.
[109] C.W.Tan,S.Friedland,S.H.Low,Spectrummanagementinmultiusercognitivewirelessnetworks:optimality
and algorithm, IEEE J. Sel. Areas Commun. 29 (2011) 421–430.
[110] Y. Xu, T. Le-Ngoc, S. Panigrahi, Global concave minimization for optimal spectrum balancing in multi-user
DSL networks, IEEE Trans. Signal Process. 56 (2008) 2875–2885.
[111] E.A. Jorswieck, E.G. Larsson, Monotonic optimization framework for the two-user MISO interference
channel, IEEE Trans. Commun. 58 (2010) 2159–2168.
[112] M.B. Shenouda, T. Davidson, Convex conic formulations of robust downlink precoder designs with quality
of service constraints, IEEE J. Sel. Top. Signal Process. 1 (2007) 714–724.
[113] N. Vucic, H. Boche, Robust QoS-Constrained optimization of downlink multiuser MISO systems, IEEE
Trans. Signal Process. 57 (2009) 714–725.
[114] E. Song, Q. Shi, M. Sanjabi, R. Sun, Z.-Q. Luo, Robust SINR-constrained MISO downlink beamforming:
When is semideﬁnite programming relaxation tight? in: The Proceedings of IEEE International Conference
on Acoustics, Speech, and, Signal Processing (ICASSP), 2011, pp. 3096–3099.
[115] M.B. Shenouda, T. Davidson, On the design of linear transceivers for multiuser systems with channel uncer-
tainty, IEEE J. Sel. Areas Commun. 26 (2008) 1015–1024.

468
CHAPTER 8 Signal Processing and Optimal Resource Allocation
[116] A. Tajer, N. Prasad, X. Wang, Robust linear precoder design for multi-cell downlink transmission, IEEE
Trans. Signal Process. 59 (2011) 235–251.
[117] G. Zheng, K.-K. Wong, T.-S. Ng, Robust linear MIMO in the donwlink: a worst-case optimization with
ellipsoidal uncertainty regions, EURASIP J. Adv. Signal Process. 2008 (2008) 1–15.
[118] T. Basar, G. Olsder, Dynamic Noncooperative Game Theory, SIAM, 1999.
[119] M.J. Osborne, A. Rubinstein, A Course in Game Theory, MIT Press, 1994.
[120] C.U. Sarayda, N.B. Mandayam, D.J. Goodman, Pricing and power control in a multicell wireless data
network, IEEE J. Sel. Areas Commun. 19 (2001) 1883–1892.
[121] C.U. Sarayda, N.B. Mandayam, D.J. Goodman, Efﬁcient power control via pricing in wireless data network,
IEEE Trans. Commun. 50 (2002) 291–303.
[122] D. Goodman, N. Mandayam, Power control for wireless data, IEEE Personal Commun. 7 (2000) 48–54.
[123] F. Meshkati, M. Chiang, H.V. Poor, S.C. Schwartz, A game-theoretic approach to energy-efﬁcient power
control in multicarrier CDMA systems, IEEE J. Sel. Areas Commun. 24 (2006) 1115–1129.
[124] F. Meshkati, H. Poor, S. Schwartz, Energy-efﬁcient resource allocation in wireless networks, IEEE Signal
Process. Mag. 24 (2007) 58–68.
[125] G. Scutari, D.P. Palomar, S. Barbarossa, Optimal linear precoding strategies for wideband noncooperative
systems based on game theory—Part II: Algorithms, IEEE Trans. Signal Process. 56 (2008d).
[126] Z.-Q. Luo, J.-S. Pang, Analysis of iterative waterﬁlling algorithm for multiuser power contorl in digital
subscriber lines, EURASIP J. Appl. Signal Process. 2006 (2006) 1–10.
[127] G. Scutari, D.P. Palomar, S. Barbarossa, Asynchronous iterative water-ﬁlling for Gaussian frequency-
selective interference channels, IEEE Trans. Inform. Theory 54 (2008a).
[128] R. Cendrillon, J. Huang, M. Chiang, M. Moonen, Autonomous spectrum balancing for digital subscriber
lines, IEEE Trans. Signal Process. 55 (2007) 4241–4257.
[129] G. Scutari, D.P. Palomar, S. Barbarossa, Optimal linear precoding strategies for wideband noncooperative
systems based on game theory—Part I: Nash equilibria, IEEE Trans. Signal Process. 56 (2008c).
[130] K.W. Shum, K.K. Leung, C.W. Sung, Convergence of iterative waterﬁlling algorithm for Gaussian interfer-
ence channels, IEEE J. Sel. Areas Commun. 25 (2007) 1091–1100.
[131] G. Scutari, D.P. Palomar, S. Barbarossa, Competitive design of multiuser MIMO systems based on game
theory: a uniﬁed view, IEEE J. Sel. Areas Commun. 26 (2008b).
[132] A. Leshem, E. Zehavi, Game theory and the frequency selective interference channel, IEEE Signal Process.
Mag. 26 (2009).
[133] E. Telatar, Capacity of multi-antenna Gaussian channels, Eur. Trans. Telecommun. (1999) 585–596.
[134] G. Arslan, M. Demirkol, Y. Song, Equilibrium efﬁciency improvement in MIMO interference systems:
A decentralized stream control approach, IEEE Trans. Wireless Commun. 6 (2007) 2984–2993.
[135] G. Scutari, D.P. Palomar, J.-S. Pang, F. Facchinei, Flexible design of cognitive radio wireless systems: from
game theory to variational inequality theory, IEEE Signal Process. Mag. 26 (2009).
[136] R.H. Gohary, Y. Huang, Z.-Q. Luo, J.-S. Pang, Generallized iterative water-ﬁlling algorithm for distributed
power control in the presence of a jammer, IEEE Trans. Signal Process. 57 (2009) 2660–2674.
[137] P. Setoodeh, S. Haykin, Robust transmit power control for cognitive radio, Proc. IEEE (2009) 915–939.
[138] M. Hong, A. Garcia, Averaged iterative water-ﬁlling algorithm: robustness and convergence, IEEE Trans.
Signal Process. 59 (2011) 2448–2454.
[139] R.H. Gohary, T.J. Willink, Robust IWFA for open-spectrum communications, IEEE Trans. Signal Process.
57 (2009) 4964–4970.
[140] M. Hong, A. Garcia, Equilibrium pricing of interference in cognitive radio networks, IEEE Trans. Signal
Process. 59 (2011) 6058–6072.
[141] J.-S. Pang, G. Scutari, D. Palomar, F. Facchinei, Design of cognitive radio systems under temperature-
interference constraints: a variational inequality approach, IEEE Trans. Signal Process. 58 (2010) 3251–3271.

References
469
[142] J. Wang, G. Scutari, D. Palomar, Robust MIMO cognitive radio via game theory, IEEE Trans. Signal
Process. 59 (2011) 1183–1201.
[143] Y. Xie, B. Armbruster, Y. Ye, Dynamic spectrum management with the competitive market model, IEEE
Trans. Signal Process. 58 (2010) 2442–2446.
[144] FCC, In the matter of establishment of an interfernce temperature metric to quantify and management
interference and to expand available unlicensed operation in certain ﬁxed, mobile and satellite frequency
band, 2003, ET Docket No. 03-237.
[145] R. Zhang, Y.-C. Liang, S. Cui, Dynamic resource allocation in cognitive radio network, IEEE Signal Process.
Mag. (2010) 102–114.
[146] G. Scutari, D.P. Palomar, F. Facchinei, J.-S. Pang, Convex optimization, game theory, and variational
inequality theory, IEEE Signal Process. Mag. 27 (2010) 35–49.
[147] G. Scutari, D. Palomar, MIMO cognitive radio: a game theoretical approach, IEEE Trans. Signal Process.
58 (2010) 761–780.
[148] J.-.S. Pang, G. Scutari, F. Facchinei, C. Wang, Distributed power allocation with rate constraints in Gaussian
parallel interference channels, IEEE Trans. Inform. Thoery 54 (2008) 3471–3489.
[149] Y. Wu, D.H.K. Tsang, Distributed power allocation algorithm for spectrum sharing cognitive radio networks
with QOS guarantee, in: Proceedings of IEEE International Conference on Computer Communication
(INFOCOM), 2009.
[150] W. Yu, W. Rhee, S. Boyd, J.M. Ciofﬁ, Iterative water-ﬁlling for Gaussian vector multiple-access channels,
IEEE Trans. Inform. Theory 50 (2004) 145–152.
[151] S.A. Jafar, M. Fakhereddin, Degrees of freedom for the MIMO interference channel, IEEE Trans. Inform.
Theory (2007).
[152] Y. Birk, T. Kol, Informed-source coding-on-demand (ISCOD) over broadcast channels, in: Proceedings of
the IEEE International Conference on Computer Communications, San Francisco, CA, 1998, pp. 1257–264.
[153] S. Jafar, Degrees of freedom on the MIMO x channel-optimiality of the MMK scheme. Available from:
<Arxiv:cs.IT/0607099v2, 2006>.
[154] M. Maddah-Ali, A. Motahari, A. Khandani, Communication over MIMO x channels: Interference alignment,
decomposition, and performance analysis, IEEE Trans. Inform. Theory (2008).
[155] S. Jafar, S. Shamai, Degrees of freedom region for the MIMO X channel, IEEE Trans. Inform. Theory
(2008) 151–170.
[156] M. Razaviyayn, M. Boroujeni, Z.-Q. Luo, Linear transceiver design for interference alignment: complexity
and computation, IEEE Trans. Inform. Theory 58 (2012) 2896–2910.
[157] C.M. Yetis, T. Gou, S.A. Jafar, A.H. Kayran, On feasibility of interference alignment in MIMO interference
networks, IEEE Trans. Signal Process. 2010.
[158] K. Gomadam, V.R. Cadambe, S.A. Jafar, Approaching the capacity of wireless networks through distributed
interference alignment, in: Proceedings of the 2008 IEEE GLOBECOM, 2008.
[159] S. Peters, R. Heath, Interference alignment via alternating minimization, in: 2009 IEEE International Confer-
ence on Acoustics, Speech, and Signal Processing, 2001, Proceedings (ICASSP ’09), 2009, pp. 2445–2448.
[160] M. Razaviyayn, G. Lyubeznik, Z.-Q. Luo, On the degrees of freedom achievable through interference
alignment in a MIMO interference channel, IEEE Trans. Signal Process (in press).
[161] G. Bresler, D. Cartwright, D. Tse, Settling the feasibility of interference alignment for the MIMO interference
channel: the symmetric case, 2011. Available from: <Arxiv:1104.0888v1>.
[162] G. Bresler, D. Tse, Degrees-of-freedom for the 3-user gaussian interference channel as a function of channel
diversity, in: Proceedings of the Allerton Conference on Communication, Control, and Computing, Allerton,
IL, 2009.

9
CHAPTER
Advances in Spectrum Sensing
and Cross-Layer Design for
Cognitive Radio Networks1
Seung-Jun Kim*, Emiliano Dall’Anese*, Juan Andrés Bazerque*,
Ketan Rajawat†, and Georgios B. Giannakis*
*Department of ECE, University of Minnesota, Minneapolis, MN, USA
†Department of Electrical Engineering, Indian Institute of Technology, Kanpur, India
Nomenclature
(x, f )
power spectral density (PSD) at position x and frequency f
ϕ(x, f )
measured PSD at position x and frequency f
ˆ(x, f )
estimated PSD at position x and frequency f
s( f )
transmit-PSD of source s at frequency f
gxs→xr(t, f )
gain of the channel from position xs to position xr at time t and frequency f
θ
vector of basis expansion coefﬁcients for the PSD map
xr
position of the rth CR
Nr
number of CRs
Ng
number of grid points
Nb
number of known bases
θ g
the gth group of basis expansion coefﬁcients
N
number of samples
sx→xs
shadow fading of the channel from position x to position xs
ℓ(x, t)
spatial loss ﬁeld at position x and time t
2.09.1 Introduction
The cognitive radio (CR) paradigm endeavors to mitigate the scarcity of spectral resources for wireless
communication through intelligent sensing and agile resource allocation techniques [1,2]. The moti-
vating reason is that although most of the available spectrum has been licensed to primary users (PUs)
for exclusive usage, it is often signiﬁcantly underutilized depending on the time and the location that
communication takes place [3]. The CRs aim to learn the RF landscape, and identify the unused spectral
resources—often called “white space” or “spectrum holes”—in the time, frequency, and space domains
1This work was supported by QNRF grant NPRP 09-341-2-128.
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-396500-4.00009-0
© 2014 Elsevier Ltd. All rights reserved.
471

472
CHAPTER 9 Advances in Spectrum Sensing and Cross-Layer Design
through spectrum sensing. Based on the information obtained, judicious resource management is then
performed to communicate opportunistically without causing harmful interference to the licensed PU
systems.
The sensing task can be as basic as detecting the presence of PU signals in a given band at a given time.
It can become as sophisticated as estimating the channel gains, transmit-powers, modulation classes,
and PU locations, as well as learning their trafﬁc patterns. Deciding the PU presence is necessary for
the spectrum overlay scenario [4], in which the CRs identify completely unoccupied bands to transmit
on. Channel gains between CR transmitters and PU receivers are useful for interference control in the
spectrum underlay scenario, in which the CRs are allowed to share bands with the PUs, provided that
the interference experienced by the PUs is maintained below an acceptable level. The bottom line is
that the richer the information collected on the PU systems and the surrounding RF environment, the
more adaptable the CR operation can become via dynamic resource optimization.
Spectrum sensing is no easy task. The CRs often need to scan a huge swath of bandwidth in order
to identify spectrum holes [5]. In the prevalent case of no cooperation occurring between PU and
CR systems, the PU signals must be detected in a low signal-to-noise power ratio (SNR) regime.
The lack of dedicated training signals may render it difﬁcult for the CR systems to acquire the chan-
nels accurately. In fact, the CRs might not even have prior knowledge on the PU signal character-
istics, often limiting the options to using simple energy detectors (radiometers) [6]. Thus, obtaining
a decent detection performance can become quite challenging [7]. The difﬁculty is only aggravated
with the hidden terminal issues and strenuous propagation environments which may include fading and
shadowing [8].
These formidable challenges have invited intensive research in this area. At the physical layer, various
cooperativesensingschemeshavebeendevelopedtocopewiththehiddenterminalproblemsandcombat
fading through diversity combining of the samples taken by multiple CRs [9,10]. Cyclostationarity
detectors have been developed for improved sensing performance [11,12]. Various signal processing
and learning tools have been employed to effectively capture the RF environment in which the CR
network is deployed [13–15]. To minimize sensing delay while meeting the detection performance
targets, sequential detectors have been investigated [16,17]. Both parallel scanning of multiple bands
as well as serial search have been considered [18,19]. In the case of serial search, selecting the bands
to sense and coordinating the search along with the access among multiple CRs have attracted much
research toward designing the MAC layer tailored for CR sensing [20–22].
It is largely part of ongoing research how to effectively permeate the beneﬁts of enhanced cogni-
tion capability of the CRs to cross-layer network design and adaptation. Needless to say, this is of
critical importance for efﬁcient, reliable, quality-of-service-assuring operation of CR networks in the
presence of dynamics and uncertainties in the CR deployment [23]. It has been recognized that the
sensing algorithms must be designed with the cross-layer interaction in mind [24,25]. This tutorial
paper aims to survey some of the advances made in CR spectrum sensing, and also highlight the inter-
twined cross-layer resource management issues, hopefully providing with fruitful directions for future
research.
The organization of the rest of the paper is as follows. An overview of the physical layer sensing
techniques are provided in Section 2.09.2 with emphasis on the recent RF cartography approaches.
The MAC layer issues of sensing is brieﬂy reviewed in Section 2.09.3. The implications of sensing to
cross-layer design are illustrated in Section 2.09.4. Some conclusions are offered in Section 2.09.5.

2.09.2 Sensing at the Physical Layer
473
2.09.2 Sensing at the physical layer
Signal detection is the core element of CR sensing, with Neyman-Pearson (NP) hypothesis testing
offering the natural and most widely used framework. With the objective of deciding whether a PU is
present or white space is available, the CR acquires samples of the ambient RF signal x(t) and decides
between two hypotheses: H0 : x(t) = n(t) versus H1 : x(t) = s(t) + n(t), where n(t) denotes ambient
noiseands(t)aPUsignalpossiblyaffectedbymultipathandshadowfadingeffects.The energydetection
is widely used because it is simple and does not require knowledge about the PU system parameters [6].
The test statistic (TS) ST = T
t=1 x2(t) is modeled as χ2-distributed assuming that the noise variance
is known. In order to avoid self interference, multiple CRs competing for the same bands must schedule
quiet periods, that is, time intervals where CRs suspend transmission and perform detection [26].
Modulated signals are typically cyclostationary processes, that is, their correlation function
r(t, τ) := E{x(t)x∗(t −τ)} is periodic in t, which implies that its Fourier spectrum peaks at the cyclic
frequency corresponding to its period. Cyclostationarity detection capitalizes on this property to detect
a PU signal even in low SNR, since white noise yields zero correlation at nonzero lags regardless of
its power level [12]. Furthermore, cyclostationarity detectors can separate signals with different cyclic
frequencies, thus potentially not requiring quiet periods. These advantages come at the price of requiring
larger data records to attain comparable performance relative to energy detection, since cyclostationarity
detection entails sample estimates of the fourth-order moments.
Standard NP tests predeﬁne the number of samples to acquire as a function of prescribed test per-
formance, i.e., the probabilities of detection and false alarms. Sequential alternatives are available, in
which the TS is updated sample by sample [27]. Depending on how informative this TS is, three actions
are possible, namely, rejecting the null or the alternative hypotheses, or acquiring an additional sample.
For a speciﬁed test performance, the technique is proven to reduce the number of required samples in
average, although it may exceed the NP sample size on a bad realization.
In wideband sensing, the CRs often need to scan different bands in search for white space. These
bands can be tested independently by applying single-band detectors separately. In multi-band testing,
decision thresholds corresponding to different bands can be optimized jointly [19]. Accordingly, the test
performance is not prescribed but designed to maximize the aggregate CR throughput across frequency
bands. Increasing the thresholds increases the chance of CR transmissions, increasing the throughput.
It also increases the probability of miss detection. This probability is controlled by setting a price for
interfering with PUs, and prescribing an upper bound to the aggregate cost across bands that the CR can
afford [19]. A compressive sampling approach has also been proposed for inspecting all bands together
at sub-Nyquist sampling rates [28].
Collaboration among CRs adds spatial diversity to the sensing methods which is crucial for improved
detection of white spaces, since shadowing effects may lead a single CR to miss detection [8]. In particu-
lar, the hidden terminal problem can be mitigated by collaboration. Such a situation arises when a CR is
not in the range of a PU transmitter, but a PU receiver in-between falls in the range of the CR. In this setup,
the CR will miss the PU transmitter, infer white space, and start communicating, thus causing harmful
interference to the PU receiver. In addition to gaining spatial diversity, collaborative CRs can share
sensing resources with the potential to reduce sensing time or to improve detection performance [29].

474
CHAPTER 9 Advances in Spectrum Sensing and Cross-Layer Design
Cooperation protocols must be judiciously designed so that the overhead introduced for collaboration
does not outweigh the increase in the throughput of the opportunistic access [10]. Centralized CR
networks are often considered, with CRs communicating their TSs to a fusion center (FC), where these
are combined to yield a fused decision. Combining unquantized (i.e., soft) TSs serves as a guideline
for the design of optimal protocols [30,31]. However, quantization is important for striking a balance
in the data transmission-sensing trade-off. To this end, schemes combining quantized TSs have been
proposed, even with one-bit resolution [32].
Distributed processing offers an alternative to the FC-based cooperation. Information is shared among
neighboring CRs only, a preferable architecture for large networks since long-range communication to
an FC consumes excessive power and interferes with reports from all other CRs in the network. In
addition, decentralized networks are more robust since their operation is not dependent on a single
point of failure, and it is more ﬂexible since an entering CR only needs to discover its neighbors to start
operatingwithoutcompetingforaccesstotheFC.Theinformationsharedintheneighborhoodeventually
percolates across the entire network after a number of local communication steps, and approaches the
optimality of a centralized CR network [14].
Optimality here should be understood as achieving the prescribed test performance with minimal
number of samples, or maximizing the throughput. These criteria are “socially optimal” for the CR
network. Game theoretic approaches have also been proposed in which a single CR decides whether or
not to sense and collaborate in order to maximize its own throughput [33]. A CR might decide not to
sense and use its resources to transmit on available bands according to the sensing results of its peer
CRs. This strategy is not optimal if followed by all CRs as no white spaces are revealed, and then
individual CRs are compelled to sense the spectrum. A strategy is developed in [33] to achieve a stable
equilibrium point in which CRs balance sensing and transmission times.
Censoring offers a complementary approach to quantization when it comes to reducing the overhead.
SincecommunicatinglocalTSsconsumesenergyandbandwidth,theCRsareallowedtodosoonlywhen
ST is sufﬁciently informative. A two-threshold approach was proposed in [34], where the CRs transmit
ST only when it is below the lower threshold, or above the higher one. The thresholds are designed to
guarantee the prescribed test performance, considering the cost of sensing and TS transmission [34].
These multiple dimensions of the CR sensing problem are summarized in Figure 9.1, and overviewed
more extensively in the tutorial reference [35]. Recently, spectrum cartography opened a new dimen-
sion for CR sensing by analyzing the spectral opportunities not only in frequency but also in space
[13–15]. The underlying departure of these approaches relative to the conventional sensing algorithms
is that the PU’s band occupancy is no longer deemed the same regardless of location. Rather, spectrum
cartography sets the objective of revealing a map of the spectrum occupancy across space per frequency
band. Estimating spectrum maps is particularly relevant for wide-area ad hoc networks, where PU
transmissions typically reach only a small subset of CRs. Knowing the spectrum across space allows
remote CRs to reuse idle bands. It also enables the CRs to adapt their transmit-powers or positions to
minimally interfere with PUs [36]. Of course, more sophisticated sensing approaches demand higher
implementation complexity. While a viable alternative may be to formally allow the CRs and the PUs
collaborate, it is noted that the CR paradigm advocated here does not need to be conﬁned to the CR
networking per se, but may be instrumental to other complex wireless networking scenarios, where
distributed and autonomous cognition of the environment is useful [37]. The cartography approach is
described in more detail in the ensuing section.

2.09.2 Sensing at the Physical Layer
475
Energy
Cyclostationarity
Single-band
Multi-band
Fixed-sample size
Sequential
FC-based
Decentralized
Socially optimal
Game-theoretic
Soft-combined
Hard-combined
Censored
Uncensored
Space-invariant
Cartography
FIGURE 9.1
Aspects of collaborative CR sensing at the physical layer.
2.09.2.1 Sparsity-aware power spectrum cartography
A parametric approach to cooperative RF cartography is developed in [14] with the goal of mapping
out the ambient RF power levels in the geographical area A ⊆R2 of interest. The setup includes
Ns sources (PU transmitters) located at position vectors {xs ∈A}Ns
s=1, and Nr receivers (CRs) at
locations {xr ∈A}Nr
r=1. The transmit-power spectral density (PSD) of a source signal at position xs
is represented by a basis expansion as s( f ) = Nb
ν=1 θsνbν( f ), where {bν( f )}Nb
ν=1 is a collection of
known bases, and {θsν}Nb
ν=1 denotes the expansion coefﬁcients to be estimated per source s. Assuming
spatial uncorrelatedness of channels and sources, the PSD (xr, f ) measured at receiving CRs at
{xr}Nr
r=1 in the presence of white noise with respective variances {σ 2
r }Nr
r=1 is expressed as
(xr, f ) =
Ns

s=1
gxs→xr s( f ) + σ 2
r =
Ns

s=1
gxs→xr
Nb

ν=1
θsνbν( f ) + σ 2
r = bT
r ( f )θ + σ 2
r ,
(9.1)
where T denotes transposition; gxs→xr the average channel gain of the xs →xr link; θ the vector
formed by stacking the columns of the matrix with entries θsν; and br( f ) the vector constructed by
concatenating the columns of the matrix with (s, ν)-entry gxs→xr bν( f ). One possible choice for the
channel gains is to adopt an inverse polynomial path loss model so that gxs→xr is only a function of the
distance between xr and xs. Alternatively, estimates can be obtained from channel gain cartography,
which will be explained in Section 2.09.2.2.
Given PSD measurements {ϕ(xr, fn)}N−1
n=0 at N discrete frequencies per CR r, the goal is to estimate
the PSD maps ˆ(x, f ) ∀x ∈A, one per frequency f . From the linear model (9.1), this is possible
provided an estimate of θ becomes available.

476
CHAPTER 9 Advances in Spectrum Sensing and Cross-Layer Design
2.09.2.1.1
Compressed sensing approach
Let ϕr denote the N ×1 vector with the nth entry ϕrn := ϕ(xr, fn) representing the PSD measurement
obtained, e.g., by sample-average on periodograms. Deﬁning the estimation error vector er likewise,
one arrives at the local vector-matrix model per CR r
ϕr = Brθ + er,
r = 1, 2, . . . , Nr,
(9.2)
where matrix Br is formed to have rows {bT
r ( fn)}N
n=1, and the noise variance is absorbed in ϕr or θ
without loss of generality.
Cooperative PSD sensing is possible because θ is common to all Nr receiving CRs. This allows
estimation of θ in the linear regression model (9.2) using the nonnegative (NN), and thus non-linear,
LS criterion
min
θ≥0
Nr

r=1
∥ϕr −Brθ∥2,
(9.3)
where the nonnegativity constraints are naturally imposed to prevent negative PSD estimates.
With position vectors xs (and/or xr) unknown, even the model in (9.1) is nonlinear and the NN-LS
optimization in (9.3) is rendered non-convex with multiple local minima. To bypass this challenge, the
idea in [14] relies on a virtual grid of Ng candidate source locations as the one depicted in Figure 9.2.
Vectors xs are replaced by xg in Figure 9.2, which no longer describe the actual positions of the PUs,
but rather the grid points with known spatial coordinates where the PUs could be present. This virtual
grid model removes the model nonlinearity, while rendering (9.3) convex at the price of the increased
number of unknowns. Aided by the virtual grid, one can in principle obtain the PU locations that best
ﬁt the measurements via exhaustive search, provided that the number of PUs is known. (The number of
PUs may be determined from model complexity, e.g., using Akaike’s information-theoretic criterion.)
The exhaustive search is clearly undesirable because it incurs combinatorial complexity that grows
rapidly in the number of grid points. In fact, a dense grid may be preferred to achieve higher precision in
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
Tx
Tx
S1
S2
S3
S4
i = 25
i = 1
FIGURE 9.2
Virtual CR network grid.

2.09.2 Sensing at the Physical Layer
477
localizing the PUs. Recent advances in compressive sampling can mitigate this hurdle by exploiting the
sparsity present in θ [38–40]. Sparsity is manifested because individual transmissions typically occupy
only a small fraction of the possibly huge system bandwidth. Moreover, active PUs are present only at
a small fraction of candidate locations {xg}.
In particular, the least-absolute shrinkage and selection operator (Lasso) [40], also known as denois-
ing basis pursuit [39], amounts to augmenting (9.3) with the ℓ1 norm ∥θ∥1
:=
Ng
s=1
Nb
ν=1 |θsν|
weighted by a sparsity-tuning parameter λ1. After incorporating PSD-imposed nonnegativity con-
straints, the Lasso for PSD map estimation amounts to solving the following convex optimization
problem
ˆθ = arg min
θ≥0
Nr

r=1
ϕr −Brθ
2
2 + λ1∥θ∥1.
(9.4)
Clearly, the larger λ1 is chosen, the more entries of ˆθ will be shrunk to zero. The remaining non-zero
entries of ˆθ yield the positions and power of active transmitters, the bands used for transmission, and
eventually the entire PSD map ˆ(x, f ) ∀f and ∀x ∈A [cf. (9.1)].
2.09.2.1.2
Sparsity at group and coefﬁcient levels
A reﬁnement of the estimator in (9.4) is obtained by observing the hierarchical sparsity present in
θ: when a point xg is unoccupied by a PU transmitter, the entire basis expansion coefﬁcients θ g :=
[θg1, . . . , θgNb]T corresponding to this point would become zero. On this account, the regularizer in
(9.4) is augmented by adding the term λ2
Ng
g=1 ∥θ g∥2, which encourages sparsity at the group level
[41,42]. The ℓ1 penalty is preserved in order to promote sparsity at the single coefﬁcient level in the
surviving θ g, accounting for the sparsity in the frequency domain, yielding
ˆθ = arg min
θ⪰0
1
2
Nr

r=1
∥ϕr −Brθ∥2
2 + λ1∥θ∥1 + λ2
Ng

g=1
∥θ g∥2.
(9.5)
The group penalty encourages sparsity at the group level, either by shrinking to zero all variables within
a group, or by retaining them altogether. As λ2 is increased, more group estimates θ g become zero.
2.09.2.1.3
Uncertainty on the propagation model
Further enhancement was introduced in [41] to achieve robustness against perturbations in matrices Br.
Uncertainty in these matrices is due to: (i) errors in the estimates of {gxs→xr }; (ii) position offsets when
PUs are located between grid points; and (iii) approximation errors in basis expansion. The resultant
model mismatches are captured by an additive error matrix E, yielding a perturbed model ϕ = (B+E)θ,
where ϕ is obtained by stacking vectors ϕr, and B by stacking matrices Br. Under this new model, it
is pertinent to adopt a total LS formulation [41,43]
{ˆθ, ˆE} = arg min
E,θ⪰0
1
2∥ϕ −(B + E)θ∥2
2 + 1
2∥E∥2
F + λ1∥θ∥1 + λ2
Ng

g=1
∥θ g∥2.
(9.6)

478
CHAPTER 9 Advances in Spectrum Sensing and Cross-Layer Design
−30dB
−25dB
−20dB
−15dB
−10dB
−5dB
0dB
−30dB
−25dB
−20dB
−15dB
−10dB
−5dB
0dB
− 8.0
− 5.9
− 3.5
− 13.5
−30dB
−25dB
−20dB
−15dB
−10dB
−5dB
0dB
− 3.2
− 4.1
FIGURE 9.3
(Left) PSD map generated by two sources in 6 dB of log-normal shadowing aggregated across frequency;
(Center) estimate obtained from (9.5) with Nr = 50 and Ng = 100; (Right) robust estimate (9.6).
Figure 9.3 shows how (9.5) is capable of recovering the PSD maps across space under log-normal
shadowing, and how its robust version (9.6) is more effective on resolving sources located off the
grid points. Estimator (9.6) can still be limited by fading, which is not accounted for in the model.
A systematic method for identifying and rejecting such outliers can also be found in [41].
2.09.2.1.4
Nonparametric basis pursuit
A nonparametric basis pursuit method was applied to spectrum cartography in [44] and shown to offer a
valuable augmentation of the parametric path loss model considered so far. The basis expansion model
for the PSD maps is recast as
(x, f ) =
Nb

ν=1
gν(x)bν( f ),
(9.7)
where gν(x) collects the aggregate power from all sources at receiving point x. Without prescribing the
functional form of gν(x) a priori, these functions are interpolated from the available data.
To capture the smooth variation of (x, f ), the criterion for selecting gν(x) is regularized using the
so-termed thin-plate penalty [45, p. 30]. Functions {gν}Nb
ν=1 are estimated as
{ ˆgν}Nb
ν=1 := arg min
{gν∈S}
1
Nr N
Nr

r=1
N

n=1
⎛
⎝ϕrn −
Nb

ν=1
gν(xr)bν( fn)
⎞
⎠
2
+ λs
Nb

ν=1
	
R2
∇2gν(x)

2
F dx,
(9.8)
where ∥∇2gν∥F denotes the Frobenius norm of the Hessian of gν, and S the space of Sobolev functions,
for which the penalty is well deﬁned [46]. The parameter λs ≥0 controls the degree of smoothing.
Speciﬁcally, for λs = 0 the estimates in (9.8) correspond to rough functions interpolating the data;
while as λs →∞the estimates yield linear functions (i.e., ∇2 ˆgν(x) ≡02×2). A smoothing parameter
in-between these limiting values is selected using, e.g., the leave-one-out cross-validation approach;
see e.g., [47].

2.09.2 Sensing at the Physical Layer
479
The optimization problem (9.8) is variational in nature, and in principle requires searching over the
inﬁnite-dimensional function space S. Fortunately, it turns out that (9.8) admits closed-form, ﬁnite-
dimensional minimizers
ˆgν(x) =
Nr

r=1
βνr K(∥x −xr∥2) + αT
ν1x + αν0,
ν = 1, . . . , Nb,
(9.9)
where K(ρ) := ρ2 log (ρ),andβν := [βν1, . . . , βνNr ]T satisﬁesNr
r=1 βνr = 0,andNr
r=1 βνrxr = 0.
Optimal coefﬁcients c⋆
ν := [β⋆
ν1, . . . , β⋆
νNb, α⋆T
ν1 , α⋆
ν0] can be found by substituting (9.9) back into (9.8)
and solving it.
2.09.2.1.5
Group-Lasso on splines
An improved spline-based PSD estimator can be obtained by exploiting group sparsity to ﬁt unknown
spatial functions {gν}Nb
ν=1 using (9.7) with Nb ≫Nr N, possibly with an overcomplete set of bases
{bν}Nb
ν=1. The resultant model is particularly attractive when there is an inherent uncertainty on the PU
transmission parameters, such as the center frequency or the pulse shape including the roll-off factor.
Adaptive communication schemes frequently adjust such parameters [48, Ch. 9]. A sizable collection
of bases can effectively accommodate most of the possible cases, providing model robustness. Thus,
known bases are selected to describe frequency characteristics of the PSD map, while a variational
approach is employed to capture spatial dependencies.
In this context, the envisioned estimation method provides the CRs with capability of selecting a few
bases that better “explain” the actual transmitted signals. As a result, most functions gν are expected
to be identically zero; hence, there is an inherent form of sparsity present that can be exploited to
improve estimation. A major departure from the conventional basis pursuit [39] is that (9.7) entails
bases weighted by functions {gν} rather than scalars.
The proposed nonparametric basis pursuit method amounts to obtaining { ˆgν}Nb
ν=1 from ϕrn as
{ ˆgν}Nb
ν=1 := arg min
{gν∈S}
1
Nr N
Nr

r=1
N

n=1
⎛
⎝ϕrn −
Nb

ν=1
gν(xr)bν( fn)
⎞
⎠
2
+ λs
Nb

ν=1
	
R2
∇2gν(x)

2
F dx + μ
Nb

ν=1
[gν(x1), . . . , gν(xNr )]

2 .
(9.10)
Relative to (9.8), the cost in (9.10) is augmented with an additional regularization term weighted by
a tuning parameter μ ≥0. Clearly, if μ = 0, then (9.10) boils down to (9.8). To appreciate the role
of the new penalty term, note that the minimization of ∥[gν(x1), . . . , gν(xNr )]∥2 intuitively shrinks
all pointwise function values {gν(x1), . . . , gν(xNr )} to zero for sufﬁciently large μ. Interestingly, it is
shown in [44] that this sufﬁces to guarantee that ˆgν(x) ≡0 ∀x. This property is due to the fact that (9.9)
still holds as a ﬁnite-dimensional solution to (9.10).
Figure 9.4 exhibits the capability of this approach for recovering the PSD maps on the 6th and
11th channel of the PUs abiding by the IEEE 802.11 wireless LAN standard. Compared to (9.6), the

480
CHAPTER 9 Advances in Spectrum Sensing and Cross-Layer Design
−10dB
−8dB
−6dB
−4dB
−14dB
−12dB
−10dB
−8dB
FIGURE 9.4
(Top) Power distribution across space with g6(x) in the band of 2437 MHz; (Top-left) actual distribution;
(Top-right) estimated map from Nr = 100 CRs. (Bottom) Power distribution across space with g11(x) in the
band of 2462 MHz; actual distribution and estimated map.
nonparametric approach in (9.10) can cope with shadowing effects at the price of increasing the number
of CR sensors.
There are a number of practical issues in implementing the cartography algorithms. First, the PSD
cartography algorithms must be run in a time scale commensurate with the coherence times of the RF
emitter activities that the maps intend to capture. Typical implementation constraints would probably
render it infeasible to track packetized transmission bursts or very high mobility. On the other hand,
slowly varying RF landscape can be tracked based on the RF energy measurements accumulated over an
appropriate duration. Online versions of the cartography algorithms have been developed for such pur-
poses [14,44]. The subsequent subsection provides an alternative mapping idea, which may be useful in
tracing fast-varying PU activities. In addition to the robustness against channel uncertainties obtained via
the total LS approach described in Section 2.09.2.1.3, robustness of the PSD maps to the grid granularity
was considered [14]. Distributed synchronization as well as the position estimates of the CRs can be
acquiredviatheGPSorotheralgorithmsdevelopedinthecontextofwirelesssensornetworkingresearch.
2.09.2.2 Channel gain cartography
PSD cartography and PU localization algorithms are useful to identify regions that are “crowded” in
terms of RF interference, and hence to be avoided by CR transmission. On the other hand, a comple-
mentary channel gain cartography is necessary to address the interference management issues in the
spectrum underlay scenario. Channel coefﬁcients and interference levels are generally acquired on a
per-link basis by employing point-to-point training schemes. Although effective in conventional wire-
less networks, their application to the CR scenario is problematic due to the lack of cooperation between
CR and PU nodes.

2.09.2 Sensing at the Physical Layer
481
[m]
[m]
−60
−60
−60
−60
0
20
40
60
80
100 120 140 160 180 200
20
40
60
80
100
120
140
160
180
200
PU−rx 1
PU−rx 3
PU−tx
CR−tx
PU−rx 2
(a)
[m]
[m]
−60
−60
−60
−60
−60
−60
−60
20
40
60
80
100 120 140 160 180 200
20
40
60
80
100
120
140
160
180
200
CR−tx
PU−rx 1
PU−tx
PU−rx 3
PU−rx 2
(b)
FIGURE 9.5
Coverage region of a transmitter. (a) Using a path loss-only model. (b) True.
As a motivating example, consider the setup in Figure 9.5a, where a CR transmitter aims to spatially
reuse the frequency bands occupied by the PUs. As PU and CR systems do not generally cooperate,
the CR transmitter relies upon a simple path loss model to ensure PU protection; i.e., to guarantee
that the interference inﬂicted to PU receivers does not exceed a prescribed threshold [4,49], which is
set to −60 dB in Figure 9.5a. However, due to random shadowing and small-scale propagation effects,
employing a path loss-only model to calibrate the transmit-power may cause undesired disruption of PU
communications [50], as depicted in Figure 9.5b. On the other hand, when signiﬁcant signal attenuation
exists due to shadowing, the CR links can beneﬁt from it by raising the transmit-power levels. The key
here is cognition of the spatio-temporal evolution of propagation channels.
Toward this end, a novel approach was recently put forth in [15,51], where the concept of channel
gain map was introduced. For a CR node located at xr ∈A, the local channel gain (CG) map denoted
by gx→xr (t, f ) represents the CG of the link x →xr for an arbitrary position x ∈A, not necessarily
occupied by a CR node. Similarly, for an arbitrary location xs ∈A, where none of the CRs resides, the
global CG map collects the propagation coefﬁcient of link x →xs [51]; i.e., it contains CGs of links
disjoint from any of the CR-to-CR links. Omitting the map’s dependence on f for brevity (as separate
maps can be constructed for each f ), the CG gx→xs(t) can be decomposed into path loss, shadowing
and small-scale fading effects [52,53]. Averaging out small-scale fading [54], one obtains
Gx→xs(t) := 10 log10 gx→xs(t) = G0 −10α log10 (∥x −xs∥2) + sx→xs(t),
(9.11)
where G0 denotes the path gain per unit distance, α the path loss exponent, and sx→xs(t) the shadow
fading in dB at time t. Once G0 and α are known, the CG map gx→xs(t) can be obtained provided the
shadowing component can be predicted for every pair of points xs, x ∈A.
The steps in constructing CG maps are: (1) characterization of the correlation among channel coefﬁ-
cients over different wireless links; and (2) development of an appropriate statistical inference algorithm
leveraging the channel correlation to predict propagation gains of arbitrary links.

482
CHAPTER 9 Advances in Spectrum Sensing and Cross-Layer Design
2.09.2.2.1
Spatio-temporal channel correlation
The shadowing, created by attenuation and diffraction of propagating signals owing to obstructions, can
be accurately modeled as log-normal distributed [52,53]; thus, Gaussian-distributed when expressed
in dB. However, characterization of its correlation is challenging, especially when samples are taken
at different locations and time instants. Well-established correlation models for shadow fading are
available for cellular networks, in which mobile terminals are assumed to move with constant velocity
[55]. An extension involving one mobile and two base stations was proposed in [56], and multi-hop
relay scenarios were studied in [57]. An experimentally validated parametric model for nomadic as
well as mobile distributed channels was reported in [58]. The importance of shadowing in analyzing
performance of wireless ad hoc networks was pointed out in [59], where a spatial correlation model was
put forth to capture correlation of shadowing through a common “spatial loss” ﬁeld ℓ(x, t). Speciﬁcally,
shadow fading is modeled as
sx→xs(t) =
1
∥x −xs∥1/2
2
	 xs
x
ℓ(u, t)du.
(9.12)
To allow spatio-temporal tracking of propagation gains, the spatial correlation model of [59] was
judiciously extended to accommodate temporal variations in [51]. In particular, inspired by spatio-
temporal modeling approaches in geostatistics and environmental science [60,61], the dynamics of the
spatial loss ﬁeld are captured as
ℓ(x, t) = ¯ℓ(x, t) + ˜ℓ(x, t),
and ¯ℓ(x, t) =
	
A
w(x, u) ¯ℓ(u, t −1)du + η(x, t),
(9.13)
where ¯ℓ(x, t) is spatially and temporally colored with w(x, u) modeling the interaction between ℓ(x,
t −1) at position x at time t and ℓ(u, t −1) at position u at time (t −1); and ˜ℓ(x, t) and η(x, t) are
spatially colored yet temporally white zero-mean Gaussian stationary random ﬁelds. Plugging (9.13)
into (9.12) yields sx→xs(t) = ¯sx→xs(t) + ˜sx→xs(t), with the former spatially and temporally colored
and the latter spatially colored but temporally white.
From a signal processing perspective, it would be desirable to reduce the dimensionality of the state-
space model described by (9.13). One way to do it is through a basis expansion representation. Let
{ψk(·)}∞
k=1 be a set of complete prespeciﬁed orthonormal bases deﬁned on A. Then, ¯ℓ(x, t) and w(x, u)
can be approximated as ¯ℓ(x, t) = K
k=1 χk(t)ψk(x) and w(x, u) = K
k=1 βk(x)ψk(u), where {χk(t)}
and {βk(x)} are the basis expansion coefﬁcients. Upon substituting these into (9.13), and sampling at
locations {xr ∈A}Nr
r=1, a ﬁnite-dimensional state equation for ¯ℓ(x, t) is obtained as χ(t) = Tχ(t −
1) + Jη(t) with χ(t) := [χ1(t) . . . χK (t)]T denoting the state vector, and T and J determined from
{βk(·)} and {ψ(·)}. This leads to a ﬁnite-dimensional representation of ¯sx→xs(t) as well. Speciﬁcally,
upon deﬁning φxs→x,k := (∥xs −x∥)−1/2 
 x
xs ψk(u)du, ¯sx→xs(t) can be approximated as ¯sx→xs(t) ≈
φT
x→xsα(t), where φx→xs
:= [φx→xs,1 . . . φx→xs,K ]T depends only on the spatial coordinates xs
and x. Based on this spatio-temporal model for sx→xs(t), CG maps are constructed as follows.
2.09.2.2.2
CG map construction
Consider a network of Nr CRs {Un}Nr
n=1 at positions {xn}Nr
n=1 known to one another, which exchange
training signals in a time-division multiple-access (TDMA)-fashion to estimate their channel gains.

2.09.2 Sensing at the Physical Layer
483
Suppose that each CR Un can measure the received powers from the transmissions of the set Mn of
nodes, where Mn ⊂{U1, . . . ,UNr }\{Un}. With node U j ∈Mn transmitting its training sequence
over a given TDMA slot at time t, receiver Un can estimate gx j→xn(t) (and thus Gx j→xn(t) after
translating it to a dB scale) by measuring the received power. Subtracting the known deterministic path
loss from the path gain, a measurement ˘sx j→xn(t) of shadowing sx j→xn(t) is readily obtained. Let ˘sn(t)
denote the vector collecting {˘sx j→xn(t)} ∀U j ∈Mn. Then, by pooling measurements from all CRs to
a super-vector ˘s(t) := [˘sT
1 (t), . . . , ˘sT
Nr (t)]T , one can write
˘s(t) = 	α(t) + ˜s(t) + ϵ(t),
(9.14)
where 	 and ˜s(t) are constructed with rows {φT
x j→xn} and entries {˜sx j→xn(t)}, n = 1, . . . , Nr, respec-
tively; and ϵ(t) captures Gaussian-distributed measurement errors [54].
Based on the spatio-temporal model for ¯sx→xs(t), and the measurement Eq. (9.14), an adaptation of
the Kriged Kalman ﬁltering (KKF) to track the time-varying shadowing ﬁeld was proposed in [15,51].
KKF is a universal Kriging approach [62], where the spatio-temporal evolution of ¯sx→xs is tracked
via Kalman ﬁltering (KF) [60,61]. Then, the shadow fading map sx→xs(t) is obtained ∀xs, x, t by
complementing the trend estimate with an estimate of ˜sx→xs(t) obtained via Kriging interpolation [62].
Speciﬁcally, let ˆα(t|t) := E{α(t)|˘s1:t} be the minimum mean-square error (MMSE) estimate of α(t)
obtained via KF, given the accumulated data ˘s1:t := {˘s(τ)}t
τ=1. Further, let P(t|t) := cov{α(t)|˘s1:t)}
be the KF estimation error covariance matrix. Then, conditioned on ˘s1:t, the shadow fading process
sx→xs(t) for any xs, x ∈A, is Gaussian distributed with mean and variance given, respectively, by
ˆsx→xs(t) := E{sx→xs(t)|˘s1:t} = φT
x→xs ˆα(t|t) + cT
˜s (xs, x)−1[˘s(t) −	ˆα(t|t)],
(9.15a)
σ 2
x→xs(t) := var{sx→xs(t)|˘s1:t} = σ 2
˜s −cT
˜s (xs, x)−1c˜s(xs, x)
+

φT
x→xs −cT
˜s (xs, x)−1	

P(t|t)

φx→xs −	T −1c˜s(xs, x)

,
(9.15b)
where c˜s(xs, x) := E{˜s(t)˜sx→xs(t)}, and  := cov{˜s(t)}+cov{ϵ(t)}. The CG map estimate ˆGx→xs(t)
can now be constructed from ˆsx→xs(t) by adding back the deterministic path loss component; i.e.,
ˆGx→xs(t) = G0−10α log10 (∥x−xs∥2)+ˆsx→xs(t).Means of acquiringT, c˜s and canbefoundin[15].
Figure 9.6a shows the (true) CG map corresponding to a PU located at xs = (50, 120) m. Path loss
parameters are set to G0 = 0 and α = 3. Clearly, the CG map exhibits a peak at location xs; however,
due to the spatially inhomogeneous shadowing component
sx→xs(t), whose standard deviation is
approximately 10 dB, the overall CG map decays non-isotropically. Thus, estimating the shadowing
ﬁeld is essential for CR network operation and effective PU protection. To estimate the CG map, 20 CRs
uniformly distributed over a square area of 200 m × 200 m exchange signals to acquire propagation
gains; the communication range was set to 125 m. An estimated version of the map in Figure 9.6a is
depicted in Figure 9.6b. It can be seen that the KKF-based spatial interpolation can effectively predict
the shadow fading process (and hence the channel gains) even in locations where no measurements
were made. The error in reconstructing the map, evaluated over a grid of 36 evenly spaced locations
was 1.5 dB, signiﬁcantly lower than the standard deviation of the shadow fading. Figure 9.7 depicts
the root-mean-square-errors (RMSEs) of the KKF for variable communication range and number of
collaborating CRs. One can notice that the map estimation quality is maintained even when connectivity
of the CR network is sparse due to shorter communication ranges.

484
CHAPTER 9 Advances in Spectrum Sensing and Cross-Layer Design
−68
−66
−66
−66
−66
−66
−66
−66
−66
−66
−66
−66
−64
−64
−64
−64
−64
−64
−62
−62
−62
−62
−62
−60
−60
−60
−60
−60
−60
−60
−58
−58
−58
−58
−58
−58
−58
−56
−56
−56
−56
−56
−56
−54
−54
−54
−54
−54
−52
−52
−52
−52
−50
−50
−50
−48
−48
−48
−46
−46
−44
−44
−42
−42
−40
−40
−38
−38
−36
−34
−32
−30
−28
−26
−24
−22
−20
−18
−16
−14
−12
−8
−6
0
[m]
[m]
20
40
60
80
100
120
140
160
180
200
20
40
60
80
100
120
140
160
180
200
(a)
−70
−70
−70
−68
−68
−68
−68
−68
−68
−68
−68
−68
−68
−68
−66
−66
−66
−66
−66
−66
−66
−66
−66
−66
−66
−66
−66
−66
−66
−66
−66
−66
−64
−64
−64
−64
−64
−64
−64
−64
−64
−64
−64
−64
−64
−62
−62
−62
−62
−62
−62
−62
−62
−62
−60
−60
−60
−60
−60
−60
−60
−60
−60
−60
−60
−60
−60
−58
−58
−58
−58
−58
−58
−58
−58
−58
−58
−58
−56
−56
−56
−56
−56
−56
−56
−56
−56
−56
−54
−54
−54
−54
−54
−54
−54
−54
−54
−52
−52
−52
−52
−52
−52
−50
−50
−50
−50
−48
−48
−48
−48
−46
−46
−46
−44
−44
−44
−42
−42
−40
−40
−38
−38
−36
−36
−34
−32
−30
−28
−26
−24
−22
−20
−18
−16
−14
−12
−8
[m]
[m]
25
50
75
100
125
150
175
200
25
50
75
100
125
150
175
200
(b)
FIGURE 9.6
Global CG map. (a) True map. (b) Estimated map.
50
75
100
125
150
175
200
0
1
2
3
4
5
6
7
8
9
10
11
12
13
CRs’ communication range [m]
RMSE [dB]
Path loss−only model
KKF, 20 CRs
KKF, 40 CRs
FIGURE 9.7
Standard deviation of CG map estimation error.

2.09.2 Sensing at the Physical Layer
485
2.09.2.2.3
Coverage region estimation
Although sensing schemes can locate active PUs, particularly challenging is to acquire the locations
of “passive” PUs, which do not transmit but just listen. Nonetheless, those receivers still need to be
protected from interference under the PU-CR hierarchy [4]. To this end, the coverage region of the PUs
can be computed, where potential PU receivers can reside. This illustrates an application of the CG maps.
Let x(t) denote the average power in dB received at location x ∈A due to the transmission of a
PU located in xs signaling at power Ps
:= 10 log10 ps. Then, x(t) can be expressed as x(t) =
Ps + G0 −10α log10 ∥xs −x∥2 + sx→xs(t). Based on the estimated CG map, x(t) can be modeled as
Gaussian distributed with mean Ps + G0 −10α log10 ∥xs −x∥2 + ˆsx→xs(t) and variance σ 2
x→xs(t).
Since a PU receiver can reliably decode the desired message only if the received power exceeds a
certain threshold min (dB), one can compute the probability that a PU receiver at x can decode as
[48, Ch. 2]
Pcov
x (t) := Pr{x(t) ≥min} = Q
min −Ps −G0 + 10α log10 ∥xs −x∥2 −ˆsx→xs(t)
σx→xs(t)

,
(9.16)
where Q(·) is the standard Gaussian tail function. The coverage region of the device located in xs is
deﬁned as the set of locations in A, for which the coverage probability is no smaller than a threshold
ν [48, Ch. 2]; i.e., C(t) := {x ∈A|Pcov
x (t) ≥ν}. In the absence of CG map knowledge, CRs would
set ˆsxs→x(t) = 0; consequently, C would reduce to a time-invariant disc centered at xs; see Figure 9.8a
with min = −60 dB and ν = 0.4. On the contrary, the CG map can portray the coverage region more
0
50
100
150
200
0
20
40
60
80
100
120
140
160
180
200
[m]
[m]
0
20
40
60
80 100 120 140 160 180 200
0
20
40
60
80
100
120
140
160
180
200
[m]
[m]
(a)
(b)
FIGURE 9.8
Coverage region of a PU transmitter. (a) Path loss-only model. (b) With CG map.

486
CHAPTER 9 Advances in Spectrum Sensing and Cross-Layer Design
accurately as depicted in Figure 9.6b. The approach can also accommodate small-scale fading effects, as
the composite log-normal and Nakagami fading turns out to be well approximated as log-normal [63,64].
2.09.3 Sensing at the MAC layer
Spectrum sensing at the PHY layer is primarily concerned with detection of PU signals for the purpose
of identifying transmission opportunities and creating spatio-temporal RF maps. In practice however,
the PU spectrum is several times wider than the sensing bandwidth of a single CR transceiver. The goal
of MAC layer sensing is to schedule the sensing operations of CRs across bands so as to locate maximal
transmission opportunities. The MAC layer sensing problem is not trivial, as it involves balancing
resources between sensing and communication. If multiple CRs are present, the MAC sensing algorithm
must also take into account the possible contention among the CRs for medium access.
The design of MAC sensing algorithms is guided mainly by the rate at which the underlying spec-
trum occupancy changes. Slow temporal variations in the spectrum occupancy, as encountered in the
TV bands, allow for longer sensing intervals. Consequently, MAC sensing algorithms in these bands
simply search exhaustively through a wide range of frequencies before transmitting. On the other
hand, fast spectral variations, as in the cellular bands, allow for only a few bands to be sensed before
transmission. Therefore, the MAC sensing algorithms here need to utilize statistical inference to pre-
dict spectrum occupancy in order to better schedule sensing operations across bands. An alternative
approach would be to design the analog front end of the CRs suitable for wideband spectrum sens-
ing [65]. In this case, the trade-off between the complexity of the sensing hardware including the
analog-to-digital converters (ADCs) and the sensing accuracy must be carefully examined [66]. In the
sequel, the focus will be on the MAC sensing algorithms based on low-complexity narrowband sensing
hardware.
2.09.3.1 Wireless regional area networks
The IEEE 802.22 standard for wireless regional area networks (WRAN) speciﬁes a MAC sensing
protocol for CRs operating on the spectrum assigned to TV services (between 47 and 910 MHz) [26].
The sensing in IEEE 802.22 operates in two stages: a fast sensing stage involving rapid probes on
multiple bands, each lasting at most a millisecond; and a ﬁne sensing stage lasting 25 ms, on a speciﬁc
band determined by the outcome of the ﬁrst stage. The MAC layer also schedules in-band sensing for
determining if a PU starts transmitting before active CRs have completed their transmissions. Distributed
sensingisenabledbyschedulingperiodicquiet times(duringwhichallCRsmuststoptheirtransmissions
in order to sense) and exchange of band occupancy reports among CRs.
Since the presence of periodic quiet times interrupts CR transmissions, an alternative dynamic fre-
quency hopping mode has been proposed for CRs with multiple transceivers [67]. In this mode, a sensing
transceiver is used to identify out-of-band opportunities while concurrent CR transmission, thus elim-
inating the need for quiet times. Related works have dealt with other practical issues pertaining to the
coexistence of multiple CR networks, presence of hidden PU nodes [68], and co-channel interference
in multi-cell environments [69].

2.09.3 Sensing at the MAC Layer
487
2.09.3.2 Cellular networks: MAC sensing as an inference problem
As mentioned earlier, the two-stage sensing operation for WRANs is not feasible in cellular systems,
where band occupancy varies far more quickly. MAC sensing algorithms in this case employ statistical
inference methods by utilizing the observed history of spectrum occupancy. The ﬁrst step for MAC sens-
inginvolvesbandoccupancypredictionusingtime-seriesmodels,andisdescribedinthenextsubsection.
2.09.3.2.1
Band occupancy prediction
A binary time-series prediction approach has been proposed in [70]. Consider a synchronous time-
slotted PU network operating over N licensed bands. The PU network state at the MAC layer can
be speciﬁed by an N × 1 vector s(t) with entries sn(t) ∈{0(occupied), 1(idle)}, n = 1, . . . , N.
Given p samples s(t −p), . . . , s(t −1), logistic regression is used to predict the probability of band
occupancy at time t, i.e.,
Pr(sn(t) = 1) =
1
1 + exp ( −(an0 + p
j=1 anjsn(t −j) + vn(t)))
1 ≤n ≤N
(9.17)
with regression coefﬁcients {anj}p
j=0, intercepts (or offsets) an0, and noise term vn(t) for n = 1, . . . , N.
The coefﬁcients {anj}p
j=0 may be estimated by taking M observations per band, and maximizing the
log-likelihood function [71]
ˆan = arg max
an
M

m=p+1
snm log qnm(an) + (1 −snm) log (1 −qnm(an)) 1 ≤n ≤N,
(9.18)
where an stacks the terms {anj}p
j=0, and qnm(an) := 1/[1 + exp ( −an0 −p
j=1 anjsn(m −j))].
An alternative approach in this context is described in [72], that utilizes nonstationary autoregressive
time-series models. In this framework, PU packet arrivals (and subsequently the number of PU trans-
missions) for each band follow a non-homogeneous Poisson process {A(t), t ≥0} with time-varying
rate parameter λ(t). Packet arrivals within a time slot (t, t + Ts) may then be modeled by a Poisson
process with constant rate λℓ/Ts, where λℓ:=

 (ℓ+1)Ts
t=ℓTs
λ(t) dt. A seasonal autoregressive integrated
moving average (SARIMA) model is proposed in [72] to track the rates {λℓ}, which takes the form
λℓ= λℓ−1 + λℓ−24 −λℓ−25 + zℓ+ θzℓ−1 + zℓ−24 + θzℓ−25,
(9.19)
where Ts = 1 h, and zℓ∼N(0, σ 2) is an error term. The model parameters (θ, , σ 2) are estimated
using techniques described in [73]. In contrast to the logistic regression approach of [70], SARIMA
models allow nonparametric approaches for prediction of band occupancies, and handle trend and
seasonal nonstationarities.
In a nutshell, high-order time-series models enable prediction of spectrum occupancies, and can
be utilized for scheduling sensing operations across bands. However, since prediction must be carried
out per band, these models become highly inefﬁcient in terms of sensing overload and computational
complexity if the number of available bands is large. The next section details joint prediction and
scheduling MAC sensing algorithms that scale gracefully with the number of available bands.

488
CHAPTER 9 Advances in Spectrum Sensing and Cross-Layer Design
2.09.3.2.2
Band occupancy scheduling
Since sensing is performed only on a fraction of available bands, the algorithms described in this section
perform prediction based only on the observed spectrum occupancy history. One of the early MAC
sensing algorithms in this context was proposed in [22], where evolution of the PU state s(t) is assumed
to follow a Markov chain with known transition probabilities pi j := P(s(t) = i|s(t −1) = j), for all
i, j ∈{0, 1}2N , that stay constant for at least T time slots, and can be estimated as described in [74].
Each CR seeks to access the spectrum opportunities that arise when one or more of the bands are idle.
Owing to hardware constraints, a CR can only sense at most L1 ≤N bands, and access at most L2 ≤L1
bands. Consequently, at time slot t, the CR chooses a subset Bs(t) (with cardinality not exceeding L1)
of bands to sense, and a subset Ba(t) ⊆Bs(t) of bands to access, thus achieving a throughput of
R{Bs(t),Ba(t)}(t) :=

n∈Ba(t)
sn(t)βn,
(9.20)
where βn is the bandwidth of the nth band. The goal is to sequentially choose Bs(t) and Ba(t) to
maximize the total throughput achieved in T time slots, averaged over all possible state vectors {sn(t)}.
Since the network state is not directly observable by the CRs, beliefs λi(t) := Pr(s(t) = i|H(t))
are utilized to make the sensing and access decisions, using the observed spectrum availability history
H(t) := {sn(ℓ) ∀n ∈Bs(ℓ), 1 ≤ℓ≤t −1}. Collecting the beliefs in λ(t), a policy is deﬁned as the
function π(t) : λ(t) →{Bs(t), Ba(t)}. The optimal policy is given by
{π∗(t)}T
t=1 = arg max
{π(t)}T
t=1
E
 T
t=1
R{Bs(t),Ba(t)}(t)|H(1)

.
(9.21)
The problem of determining the optimal policy can now be solved using a partially observable Markov
decision process (POMDP) framework, as detailed in [22]. Note however that the size of the state
space of (9.21) is exponential in N, which makes this approach inefﬁcient for a large number of bands.
The state space and hence the problem size can be reduced to N if the bands are assumed to evolve
independently. The independence assumption decouples the problem into N sub-problems, each with
a two-state Markov chain as shown in [22,75]. The case of independently evolving bands can also be
related to the restless multi-armed bandit problem [76], which allows for sensing algorithms with even
lower complexity. Further works have extended the approach to include energy constraints [77], and
sensing imperfections [78]. To address the exponential complexity of the general POMDP approach,
the impact of using myopic policies is examined in [79]. These policies only maximize the expected
throughput over the next time slot, but are still optimal under certain conditions.
A similar problem is considered in [80], but a separate control channel is allowed for each CR. The
control channel is shown to enable better synchronization, alleviation of the hidden node problem, and
consequently improved spectrum utilization. A hardware constrained MAC design is pursued in [81],
which optimizes the sensing time while respecting hardware constraints such as single transceiver, par-
tial spectrum sensing and limited spectrum aggregation. The intuition is that sensing for longer periods
uncovers more suitable bands but leaves little time for communication. The optimal stopping time is
derived by employing a dynamic programming approach; a related example is described in detail in the
context of cross-layer sensing in Section 2.09.4.1.1. Extending the approach to consider heterogeneous

2.09.4 CR Sensing and Cross-Layer Design
489
bands with varying capacities, the problem of determining the optimal sensing order is investigated
in [21].
In an attempt to relax the time-slotted assumption in [22] and related works, a continuous-time
Markov chain approach has been proposed for modeling the band occupancy process [82]. In this case,
the state is deﬁned similarly as before, but a band stays in state i (busy/idle) for an exponentially
distributed time period (with rate λi or μi). The sensing operation may then be viewed as sampling the
state process s(t) in a periodic fashion. Speciﬁcally, the N bands are sensed in a round-robin fashion,
with exactly one sample per time slot (of duration Ts). After each sensing operation, the MAC layer
schedules a transmission on a selected band. It is shown in [83] that periodic sampling yields a discrete
time Markov chain of sampled state vectors, whose transition probabilities can be derived in closed
form. This allows for the transmission scheduling problem to be cast within the POMDP framework,
yielding an optimal medium access policy. The framework also allows for the inclusion of constraints on
the collision probabilities in a straightforward way [84]. A more general semi-Markov model has also
been proposed, where the busy/idle times have arbitrary distributions f 1
i (x) and f 0
i (x) [85]. Related
problems include the choice of sensing period [85], sensing order [86], and more generally the sensing
policy in time and frequency [87]. Finally, the sensing order and optimal sensing policy design for the
multiuser scenario have been considered in [88,89].
2.09.4 CR Sensing and cross-layer design
As is the case with most PHY/MAC functions in wireless communication systems, spectrum sensing is
not an isolated task that can be designed independently of other components in the CR system. It is impor-
tant when designing sensing algorithms to also take into account the overall system objectives. Further,
given the enhanced awareness of the RF environment in which the CRs operate, it is essential to adapt the
higher-layer tasks to the environment to maximize efﬁciency and the overall CR network performance.
As was mentioned in Section 2.09.3, there is a trade-off between sensing accuracy and network-wide
performance objectives such as throughput, delay, and reliability. Consider for example the trade-off
between sensing duration and throughput. As was explained in Section 2.09.2, the basic element of the
sensing device is the detector that discriminates the H1 hypothesis that says there is an ongoing PU
transmission, from the H0 hypothesis that says the spectrum is unoccupied. Since the sensing is done
typicallyinchallengingsituationssuchasatalowSNRandwithoutexplicitsupportfromthePUsystems,
typically a large number of samples must be collected for reliable detection. This inevitably increases
sensing time. On the other hand, only when the sensing is ﬁnished (and the medium is determined to
be idle), can the CR proceed to actual data transmission. Therefore, given that the total idle duration is
limited (as the PU can come back and transmit), the more time is devoted to sensing, the less time is left
for useful data transmission. Such a trade-off was studied in detail in [24] for ﬁxed sample size (FSS)
test-based sensing. A similar trade-off was investigated in the context of MAC layer design of sensing
algorithms in [81,90].
Even when the sensing duration is ﬁxed, there is trade-off between the probability of miss detec-
tion and the probability of false alarm, which affects the system objectives. To see this, one needs
to note that if the detector misses the presence of PUs, it is likely that the CR will proceed to data
transmission, causing interference to the licensed users. Thus, a low miss detection probability is

490
CHAPTER 9 Advances in Spectrum Sensing and Cross-Layer Design
desired, which in turn increases the false alarm probability. However, the false alarms result in wasted
opportunities for CR transmission, thus reducing system efﬁciency. This problem becomes only more
interesting when multiple bands must be sensed concurrently, as was explored in [18,19,91]; see also
[17,92–95] for sequential alternatives in this context. Some of these formulations will be reviewed in
Section 2.09.4.1.
An equally important issue is how to effectively tap into the signiﬁcantly improved awareness of
the RF environment obtained through the sensing and the RF cartography, for design and operation of
higher-layer networking protocols. Numerous challenges in this direction include distributed resource
optimization, quality-of-service management, and maintaining network robustness under uncertainty
[23,96,97]. In Section 2.09.4.2, a recently developed robust routing scheme exploiting the RF maps
will be showcased.
2.09.4.1 Joint sensing and resource optimization
While the FSS test-based sensing algorithms must ﬁx the number of samples used for detection before
actually “seeing” those samples, the sequential alternatives can decide on the ﬂy whether the samples
collected so far are informative enough for reliable detection, and continue taking samples if not.
For a binary hypothesis testing problem, sequential probability ratio test (SPRT) is a well-established
algorithm that minimizes the sample size on the average, for given detection and false alarm probability
speciﬁcations. It can be applied in a straightforward manner to the single-band sensing problem as
outlined in Section 2.09.2. A low complexity alternative based on energy detection was analyzed in
[95]. Next, the more challenging case of multi-band joint sensing is reviewed using the sequential
detection approaches.
2.09.4.1.1
Throughput-aware sequential sensing
Consider a CR receiver that scans M bands in parallel for transmission opportunities. Due to self-
interference issues, the radio is assumed to be half-duplex; i.e., it cannot sense on one band while
transmitting on another. Thus, a CR frame of duration T is divided into a sensing phase of duration nτ
(where τ is the sampling interval) and a data transmission phase of duration (T −nτ); see Figure 9.9.
Under the assumption that the spectrum occupancy of the PUs is independent across bands, binary
hypothesis tests need to be performed on each band m ∈{1, 2, . . . , M}. Denoting the samples obtained
at time n as {r(m)
n
}, one aims to discriminate the following two hypotheses for band m
H(m)
0
: r(m)
n
= z(m)
n
,
n ∈{1, . . . , N},
H(m)
1
: r(m)
n
= h(m)
n
s(m)
n
+ z(m)
n
,
n ∈{1, . . . , N},
(9.22)
where {h(m)
n
} denote the channel coefﬁcients, and {z(m)
n
} the noise. Adopting energy detection, the
observation at time n is deﬁned as y(m)
n
:= |r(m)
n
|2.
Let δ(m)
n
∈{1, 0} denote the permit-to-access decision for channel m, made after seeing up to the
nth sample; if it is equal to 1, the channel is deemed idle (i.e., H(m)
0
in effect), and 0 otherwise. Deﬁne
δn
:= [δ(1)
n
δ(2)
n
. . . δ(M)
n
]T . Denote also the PU occupancy over the M channels by H, whose mth
entry H(m) takes values from {H(m)
0
, H(m)
1
}. We wish to characterize the effective throughput that the

2.09.4 CR Sensing and Cross-Layer Design
491
τ
τ
FIGURE 9.9
CR frame structure.
CR can enjoy. Let R(m) denote the known rate that can be achieved when transmitting over channel m.
Then, if the CR stops sensing after n sampling intervals and proceeds to data transmission, the overall
throughput can be written as (1{·} denotes the indicator function)
f ′
n(H, δn) = T −nτ
T
M

m=1
R(m)1{H(m)
0
}δ(m)
n
,
n = 1, 2, . . . , N, Nτ ≤T .
(9.23)
From (9.23), the throughput-sensing trade-off is apparent: as the number of observed samples increases,
the factor T −nτ
T
diminishes, but more available bands may be correctly identiﬁed to yield a higher value
for the sum rate in (9.23).
Given the past observations Yn ≜[y1 y2 . . . yn], the goal is to obtain the average throughput-optimal
stopping policy n(Yn) ∈{S, ¯S} that determines whether to stop (“S”) or not stop (“ ¯S”) at each time n,
and the access policy δn(Yn) ∈{1, 0}M indicating whether each band may be used for data transmission
if the sensing stops at time n. In other words, the objective is to maximize the average throughput
EYN ,H
 N

n=1
1{n−1= ¯S,n=S} f ′
n(H, δn)

(9.24)
over the control policies {n(·)}N−1
n=1 and {δn(·)}N
n=1. Here, n−1 := [0 1 . . . n−1] with 0 ≡¯S,
and n−1 = ¯S is a shorthand for 0 = 1 = · · · = n−1 = ¯S. Note also that N ≡S by design, as
we are dealing with a ﬁnite horizon problem. The indicator function in (9.24) ensures that the reward
f ′
n(·) is evaluated only at the smallest time slot n∗satisfying n∗= S; for the rest of the time steps,
n < n∗and n > n∗, the summands are zero.

492
CHAPTER 9 Advances in Spectrum Sensing and Cross-Layer Design
On the other hand, the CR access policy must ensure a low probability of “collision” with the ongoing
PU transmissions due to miss detection. The “collision” probability P(m)
c
on band m can be written as
P(m)
c
=
N

n=1
Pr

n−1 = ¯S, n = S, δ(m)
n
= 1, |H(m)
1

(9.25)
which must be kept small; i.e., P(m)
c
≤¯β for all m with ¯β being a small positive threshold. Upon deﬁning
the so-called belief vector πn := [π(1)
n
. . . π(M)
n
]T with entries π(m)
n
:= Pr

H(m)
0
|y(m)
1
, . . . , y(m)
n

,
one can show that P(m)
c
can be equivalently expressed as [17]
P(m)
c
= EYN
 N

n=1
1{n−1= ¯S,n=S}δ(m)
n
1 −π(m)
n
1 −π(m)
0

.
(9.26)
Furthermore, by ﬁrst taking conditional expectation given YN, and then taking unconditioned expec-
tation, the average throughput in (9.24) can also be written as
EYN
 N

n=1
1{n−1= ¯S,n=S}
T −nτ
T
M

m=1
R(m)π(m)
n
δ(m)
n

.
(9.27)
It can be veriﬁed that maximizing (9.27) over {n(·)}N−1
n=1 and {δn(·)}N
n=1 subject to P(m)
c
≤¯β
for all m adheres to the constrained dynamic programming (DP) formalism [98]. The problem can be
tackled using Lagrange relaxation [99]. Interestingly, the optimal permit-to-access policy δ∗(m)
n
for each
band m is found to be a likelihood ratio test with the threshold depending on the Lagrange multiplier
associated with the band [17]. A reduced-complexity, basis regression-based suboptimal stopping policy
was also derived. It was seen that these policies could achieve a signiﬁcant portion of the genie-aided
policy (which non-causally possesses the information from the future observations), while signiﬁcantly
outperforming suboptimal 1-step look-ahead as well as the best FSS sensing schemes; see Figure 9.10.
2.09.4.1.2
Sequential sensing for real-time trafﬁc
Another interesting challenge is to transport real-time trafﬁc such as voice or video using CR networks.
Real-time trafﬁc often has stringent delay and minimum rate constraints. Thus, efﬁcient design of the
sensing algorithm is extremely important in this scenario. As a concrete paradigm, consider again the
multi-band CR sensing problem, but with an outage constraint on the requested minimum rate. Thus,
the goal is to minimize the sensing delay while ﬁnding enough number of idle bands that can support
the given minimum rate with high probability.
Since the DP-based approach may be intractable with the chance constraint, a more structured
approachwastakenin[93].Speciﬁcally,ratherthanformulatingarigorousDPproblemtoobtaintheopti-
mal access and stopping policies, a bank of SPRTs were used (one for each band) to sense the M bands in
parallel. Then, an optimization problem was formulated to solve for the thresholds of the SPRTs to mini-
mize the average sensing time while abiding by the minimum rate and the PU interference constraints. An
important catch in this approach is that the stopping times of the individual SPRTs may be different. To
mitigatethisissue,atractableobjectiveofminimizingthelargestaveragesensingtimeoverthebandswas
employed. To much practical appeal, the associated optimization problem turns out to be convex [93].

2.09.4 CR Sensing and Cross-Layer Design
493
−12
−9
−6
−3
0
3
6
0
10
20
30
40
50
60
70
80
90
100
Mean SNR (dB)
Percentage of genie−aided throughput achieved
genie−aided
regression−based
1−step look−ahead
optimized FSS
FIGURE 9.10
Ratio of achieved average throughput relative to the genie-aided throughput.
2.09.4.2 Cartography-enabled route optimization
Volatile wireless connectivity in CR scenarios can be robustiﬁed via optimizing network operations
leveraging spectrum sensing. Routing protocols for wireless networking hinge on the notion of network
connectivity graph to ﬁnd source-to-destination paths optimal in some sense [100]. The edge weights
in CR network graphs should reﬂect spatio-temporal PU spectrum occupancy statistics, network-wide
spectral opportunities, and propagation medium characteristics. Appropriate cross-layer design based
on such information is instrumental for efﬁcient resource allocation and for addressing end-to-end
quality-of-service demands.
Based on the output of the sensing task, link weights can be used to indicate the amount of spectral
resources available per CR-to-CR link [101]. Optimal source-to-destination paths can then be found
via Dijsktra or Bellman Ford algorithms. A two-phase approach combining static mesh routing with
per-packet dynamic routing is proposed in [102], where network nodes ﬁrst compute an expected route
cost as well as a set of candidate forwarding nodes, and then route packets via links with highest channel
quality. In [103], a routing scheme is developed to avoid network zones with no guarantees of stable CR
connectivity based on spatio-temporal statistics of the PU activities. The concept of coverage map is
leveraged in [104] to devise routing strategies supporting multiple classes of routes, and hence different
CR quality-of-service demands. The effects of random PU interference on CR links is accounted for in
[105], where the predicted capacity of each CR-to-CR link is exploited to compute the path that is most
likely to meet CR end-to-end requirements. An optimal cross-layer design problem was considered in

494
CHAPTER 9 Advances in Spectrum Sensing and Cross-Layer Design
[106] to compute not only optimal routes, but also physical and medium access parameters that dictate
the expected packet forwarding capabilities. In doing so, the statistics of propagation channels were
exploited, along with PU state information provided by spectrum sensing.
Following [106], consider a CR wireless network sharing spectral resources with an incumbent
PU system in an underlay setup [4] to route data packets to a sink node UNr+1. The dynamical and
stochastic nature of the propagation medium naturally suggests stochastic routing strategies [107,108],
in which each CR node Un decides per time slot whether to route packets toward a neighboring node
Ui with probability txn→xi ∈[0, 1]. To capture channel- and interference-induced uncertainty, let
rxn→xi ∈[0, 1] denote the probability that a packet transmitted from CR Un is correctly decoded
by Ui. As a result, the stochastic nature of data transport is captured by the pairwise packet delivery
probabilities {txn→xirxn→xi }.
A well-established criterion for successful packet reception is to require the signal-to-interference-
plus-noise ratio (SINR) to stay above a certain threshold [109], which is determined by the receiver
structure, transmit-power, modulation, and coding scheme. Recall that gxn→xi denotes the log-normal-
distributed propagation gain between Un and Ui, which accounts for both shadowing and Nakagami
fading [53,64]. Then, the SINR of link xn →xi can be expressed as
γxn→xi :=
pngxn→xi
σ 2
i + NS
S=1 πS
,
(9.28)
where σ 2
i stands for the receiver noise power at CR Ui, pn ∈(0, pmax
n
] the transmission power of
Un, and πS the received power from PU transmitter S = 1, . . . , NS. As CR and PU nodes do not
generally cooperate, interfering powers {πS} are not known. However, their statistics collected by
sensing algorithms and CG cartography [cf. (15)] can be used instead. Exploiting the Fenton-Wilkinson
method [110], the distribution of SINRs {γxn→xi } can be well approximated as log-normal, with mean
and variance of the ﬁrst- and the second-order moments of {gxn→xi } and {πS} provided by the CG maps
[63]. Let ¯γxn→xi denote the SINR threshold, and ¯xn→xi := 10 log10 ¯γxn→xi . Assume that CRs adopt
a random access strategy, and let μn and Ini denote the transmission probability of CR Un and the set
of nodes whose transmissions interfere with link Un →U j, respectively. Then, the probability that a
packet transmitted from the ith CR Un is correctly received by Ui can be expressed as
rxn→xi =

j∈Ini
(1 −μ j) · Pr{γxn→xi > ¯γxn→xi }
≈

j∈Ini
(1 −μ j) · Q
 ¯xn→xi −Pn −mxn→xi
σxn→xi

,
(9.29)
where Pn := 10 log10 pn; while mean and standard deviation of the dB-expressed SINR are denoted
by mxn→xi and σxn→xi , respectively.
Assume that exogenous packet arrivals at node Un are modeled as a stationary stochastic process
with average rate ρn ≥0. With λn denoting the average rate of packet departures from Un, and assuming
fully-backlogged queues per node [107,111], the exogenous trafﬁc rates {ρn} and {λn} abide by the ﬂow
conservation constraints
ρn = λn

i∈Nn→
txn→xirxn→xi −

j∈N→n
λ jtx j→xnrx j→xn,
(9.30)

2.09.4 CR Sensing and Cross-Layer Design
495
where Nn→
:=
{ j|rxn→x j > 0, j = 1, . . . , N + 1, j ̸= n} is the set of nodes that decode Un’s
transmissions with non-zero probability, and N→n := {i|rxi→xn > 0, i = 1, . . . , N, i ̸= n} the set
of nodes that route packets through Un. For queue stability, it sufﬁces to have 0 ≤λn ≤μn, for each
CR Un [112].
Tocompletetheformulation,consider NR PUreceivers,whoselocations{yR}havebeenestimatedvia
CG cartography [cf. (9.16)]. The interference caused to PU R is given by iR := 
n pngxn→yR, where
gxn→yR denotes the channel gain between CR Un and PU R. Approximate the channel gain gxn→yR as
log-normal [63], with mean and variance provided by the CG map of PU receiver R. Then, deﬁning
κ := 0.1 ln (10), the average interference experienced at the PU node R is given by
E{iyR} =
N

n=1
μneκ Pn+κ(G0−10α log10 ∥xn−yR∥2−sxr →yR )+ κ2
2 σ 2
n→R,
(9.31)
which must not exceed a predetermined threshold ιmax
R
.
Based on these developments, the statistical routing task is formulated as the following optimization
problem:
max
{Pn≤Pmax},{ρn≥0},{μn≥0},
{txn→xi ≥0},{λn≥0}
N

n=1
Un(ρn) −
N

n=1
Cn(Pn)
(9.32.a)
subject to ρn ≤λn

j∈Nn→
txn→x jrxn→x j −

i∈N→n
λitxi→xnrxi→xn
(9.32.b)

i∈N n→
txn→xi ≤1,
λn ≤μn −ϵ,
μn ≤1
(9.32.c)
E{iyR} ≤ιmax
R
(9.32.d)
with {ri→n} given by (9.29), ϵ ≪1 ensuring queue stability, and Un(ρn) and Cn(Pn) selected to be
concave and convex functions, respectively, representing the reward of rate ρn and the cost of power
Pn. Unfortunately, even without the interference constraint (9.32.d), problem (9.32) is nonconvex.
However, a successive convex approximation approach [113] can be employed to efﬁciently ﬁnd to a
Karush-Kuhn-Tucker optimal solution [106].
To illustrate the attractive features of the resultant routing protocol, consider the simple scenario
depicted in Figure 9.11, where Nr = 7 CR nodes route packets generated at U1 and U2 to the destination
U8. Two PU sources also transmit with power 0 dBW. The path loss coefﬁcients are set to G0 = 0, and
α = 3.5, and m = 1 is used for Nakagami-m fading. Log-normal shadowing is generated with mean
0 and standard deviation 6 dB. The maximum transmit-power for the CR system is Pmax
n
= 0 dBW,
the noise power 10−8, and the SINR threshold ¯n = −10 dB. The interference threshold is set to
−80 dBW, and the sum of exogenous rates was maximized. Figure 9.11a depicts the optimal routing
probabilities obtained by solving (9.32). It can be seen that due to the presence of PU links, there is a
tendency to route packets generated by U2 through links U4 →U6 and U6 →U7, rather than choosing
the shortest path U2 →U4 →U5 →U8. Conversely, packets generated by U1 are routed through U3
and U7 with high probability, which in this case coincides with the shortest path. As can be noticed
from Figure 9.11b, links to and from U4 and U5 manifest lower decoding capability compared to links
that are farther from the PU system. This is not only due to the detrimental effect of PU interference on

496
CHAPTER 9 Advances in Spectrum Sensing and Cross-Layer Design
0
20
40
60
80
100
0
20
40
60
80
100
[m]
[m]
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
PU−tx 1
PU−tx 2
U2
U1
U3
U4
U5
U6
U7
U8
PU−tx 2
PU−rx 1
Routing
  prob.
0
20
40
60
80
100
0
20
40
60
80
100
[m]
[m]
0.6
0.65
0.7
0.75
0.8
0.85
0.9
0.95
1 Channel
reliability
(a)
(b)
FIGURE 9.11
Cartography-enabled optimal statistical routing. (a) Routing probabilities. (b) Link reliabilities.
the SINRs, but also due to the fact that U4 and U5 are conﬁned to use a lower transmit-power in order
to protect PU receivers from harmful interference.
2.09.5 Conclusion
Spectrum sensing at the PHY and MAC layers of CR networks, as well as its cross-layer design and
application have been overviewed in this tutorial. At the PHY layer, the basic sensing task was to detect
the presence of PU transmitters, for which collaboration of multiple CRs was seen effective to alleviate
the challenges due to fading and shadowing effects. It has been also argued that a holistic character-
ization of the RF environment in which the CR network operates is of great importance for efﬁcient
and quality-assuring network design and adaptation. Various signal processing and learning techniques
were employed to develop RF cartography algorithms to capture the spatio-temporal-spectral RF envi-
ronment. At the MAC layer, the key issue was to schedule the per-band sensing operations over the wide
bandwidth using limited sensing resources, based on estimated trafﬁc patterns and accumulated sensing
history. Cross-layer issues in sensing aimed to strike an optimal trade-off between sensing accuracy and
system objectives. The rich cognition of the operating environment obtained via sensing holds a great
potential for robust and efﬁcient network operation, which can be realized through cross-layer design.
Glossary
Cognitive radio
an intelligent radio that can learn and adapt to the environment
Primary user
a radio system that possesses an exclusive license to use a given spectrum band
Neyman-Pearson
test
a hypothesis test that maximizes the detection probability while ensuring a given
false alarm probability

References
497
Physical (PHY)
layer
a layer in the networking protocol stack concerned with electrical or optical
interface to the communication medium
Medium access
control (MAC) layer
a layer in the networking protocol stack concerned with sharing a physical
connection among multiple communication entities
Cross-layer design
a design approach for networking protocols that takes into account interactions
among different layers in the protocol stack
Relevant Theory: Statistical Signal Processing
See Vol. 3, Chapter 6 Quickest Change Detection
References
[1] S.
Haykin,
Cognitive
radio:
brain-empowered
wireless
communications,
IEEE
J.
Sel.
Areas
Commun. 23 (2) (2005) 201–220.
[2] J. Mitola III, G.Q. Maguire Jr. Cognitive radio: making software radios more personal, IEEE Pers. Commun.
6 (4) (1999) 13–18.
[3] FCC Spectrum Policy Task Force, Report of the spectrum efﬁciency working group, November 2002,
<http://www.fcc.gov/sptf/reports.html>.
[4] Q. Zhao, B.M. Sadler, A survey of dynamic spectrum access, IEEE Signal Process. Mag. 24 (3) (2007)
79–89.
[5] Z. Tian, G.B. Giannakis, Compressed sensing for wideband cognitive radios, in: Proceedings of the IEEE
ICASSP Conference, vol. 4, Honolulu, HI, April 2007, pp. 1357–1360.
[6] P. Pawelczak, K. Nolan, L. Doyle, S.W. Oh, D. Cabric, Cognitive radio: ten years of experimentation and
development, IEEE Commun. Mag. 49 (3) (2011) 90–100.
[7] R. Tandra, A. Sahai, SNR walls for signal detection, IEEE J. Sel. Topics in Signal Process. 2(1) (2008) 4–17.
[8] J. Unnikrishnan, V.V. Veeravalli, Cooperative sensing for primary detection in cognitive radio. IEEE J. Sel.
Topics Signal Process. 2 (1) (2008) 18–27.
[9] G. Ganesan, Y. Li, Cooperative spectrum sensing in cognitive radio networks, in: Proceedings of the IEEE
DySPAN Conference, Baltimore, MD, November 2005, pp. 137–143.
[10] A. Ghasemi, E.S. Sousa, Spectrum sensing in cognitive radio networks: the cooperation-processing tradeoff,
Wireless Commun. Mobile Comput. 7 (9) (2007) 1049–1060.
[11] D. Cabric, S.M. Mishra, R.W. Brodersen, Implementation issues in spectrum sensing for cognitive radios,
in: Proceedings of the 38th Asilomar Conference on Signals, Systems and Computers, vol. 1, Paciﬁc Grove,
CA, March 2005, pp. 772–776.
[12] J. Lunden, V. Koivunen, A. Huttunen, H.V. Poor, Collaborative cyclostationary spectrum sensing for cognitive
radio systems, IEEE Trans. Sig. Proc. 57 (11) (2009) 4182–4195.
[13] A.B.H.Alaya-Feki,S.B.Jemaa,B.Sayrac,P.Houze,E.Moulines,Informedspectrumusageincognitiveradio
networks: interference cartography, in: Proceedings of the PIMRC Conference, Cannes, France, September
2008, pp. 1–5.
[14] J.A. Bazerque, G.B. Giannakis, Distributed spectrum sensing for cognitive radio networks by exploiting
sparsity, IEEE Trans. Signal Process. 58 (3) (2010) 1847–1862.
[15] S.-J. Kim, E. Dall’Anese, G.B. Giannakis, Cooperative spectrum sensing for cognitive radios using Kriged
Kalman ﬁltering, IEEE J. Sel. Topics Signal Process. 5 (2011) 24–36.

498
CHAPTER 9 Advances in Spectrum Sensing and Cross-Layer Design
[16] S. Chaudhari, V. Koivunen, H.V. Poor, Autocorrelation-based decentralized sequential detection of OFDM
signals in cognitive radios, IEEE Trans. Sig. Proc. 57 (7) (2009) 2690–2700.
[17] S.-J. Kim, G.B. Giannakis, Sequential and cooperative sensing for multi-channel cognitive radios, IEEE
Trans. Signal Process. 58 (8) (2010) 4239–4253.
[18] R. Fan, H. Jiang, Optimal multi-channel cooperative sensing in cognitive radio networks, IEEE Trans.
Wireless Commun. 9 (3) (2010) 1128–1138.
[19] Z. Quan, S. Cui, A.H. Sayed, H.V. Poor, Optimal multiband joint detection for spectrum sensing in cognitive
radio networks, IEEE Trans. Sig. Proc. 57 (3) (2009) 1128–1140.
[20] S. Ahmad, M. Liu, T. Javidi, Q. Zhao, B. Krishnamachari, Optimality of myopic sensing in multichannel
opportunistic access, IEEE Trans. Info. Theory 55 (9) (2009) 4040–4050.
[21] H.T. Cheng, W. Zhuang, Simple channel sensing order in cognitive radio networks, IEEE J. Sel. Areas
Commun. 29 (4) (2011) 676–688.
[22] Q. Zhao, L. Tong, A. Swami, Y. Chen, Decentralized cognitive MAC for opportunistic spectrum access in
ad hoc networks: a POMDP framework, IEEE J. Sel. Areas Commun. 25 (3) (2007) 589–600.
[23] H.-P. Shiang, M. van der Schaar, Distributed resource management in multihop cognitive radio networks for
delay-sensitive transmission, IEEE Trans. Veh. Technol. 58 (2) (2009) 941–953.
[24] Y.-C. Liang, Y. Zeng, E.C.Y. Peh, T. Hoang, Sensing-throughput tradeoff for cognitive radio networks, IEEE
Trans. Wireless Commun. 7 (4) (2008) 1326–1337.
[25] R. Wang, V.K.N. Lau, L. Lv, B. Chen, Joint cross-layer scheduling and spectrum sensing for OFDMA
cognitive radio systems, IEEE Trans. Wireless Commun. 8 (5) (2009) 2410–2416.
[26] C. Cordeiro, K. Challapali, D. Birru, N. Sai Shankar, IEEE 802.22: the ﬁrst worldwide wireless standard
based on cognitive radios, in: Proceedings of the 1st IEEE International Symposium on New Frontiers in
Dynamic Spectrum Access, Networks, November 2005, pp. 328–337.
[27] K.W. Choi, W.S. Jeon, D.G. Jeong, Sequential detection of cyclostationary signal for cognitive radio systems,
IEEE Trans. Wireless Commun. 8 (9) (2009) 4480–4485.
[28] F.Zeng,C.Li,Z.Tian,Distributedcompressivespectrumsensingincooperativemultihopcognitivenetworks,
IEEE J. Sel. Topics Signal Process 5 (1) (2011) 37–48.
[29] G. Ganesan, Ye Li, B. Bing, Shaoqian Li. Spatiotemporal sensing in cognitive radio networks, IEEE J. Sel.
Areas Commun. 26 (1) (2008) 5–12.
[30] J. Ma, G. Zhao, Y. Li, Soft combination and detection for cooperative spectrum sensing in cognitive radio
networks, IEEE Trans. Wireless Commun. 7 (11) (2008) 4502–4507.
[31] Z. Quan, S. Cui, A.H. Sayed, Optimal linear cooperation for spectrum sensing in cognitive radio networks,
IEEE J. Sel. Topics Sig. Proc. 2 (1) (2008) 28–40.
[32] W. Zhang, R. Mallik, K. Letaief, Optimization of cooperative spectrum sensing with energy detection in
cognitive radio networks, IEEE Trans. Wireless Commun. 8 (12) (2009) 5761–5766.
[33] B. Wang, K.J.R. Liu, T.C. Clancy, Evolutionary cooperative spectrum sensing game: how to collaborate?
IEEE Trans. Commun. 58 (3) (2010) 890–900.
[34] S. Maleki, A. Pandharipande, G. Leus, Energy-efﬁcient distributed spectrum sensing for cognitive sensor
networks, IEEE Sensors Journal 11 (3) (2011) 565–573.
[35] I.F. Akyildiz, B.F. Lo, R. Balakrishnan, Cooperative spectrum sensing in cognitive radio networks: a survey,
Elsevier Phys. Commun. 4 (1) (2011) 40–62.
[36] J. Wang, P. Urriza, Y. Han, D. Cabric, Weighted centroid localization algorithm: theoretical analysis and
distributed implementation, IEEE Trans. Wireless Commun. 10 (10) (2011) 3403–3413.
[37] S. Geirhofer, L. Tong, B.M. Sadler, A sensing-based cognitive coexistence method for interfering infrastruc-
ture and ad hoc systems, Wireless Commun. and Mobile Comput. 10 (1) (2010) 16–30.
[38] E.J. Candès, Y. Plan, Near-ideal model selection by l1 minimization, Ann. Stat. 37 (5A) (2009) 2145–2177.

References
499
[39] S.S. Chen, D.L. Donoho, M.A. Saunders, Atomic decomposition by basis pursuit, SIAM J. Sci. Comput. 20
(1) (1998) 33–61.
[40] R. Tibshirani, Regression shrinkage and selection via the lasso, J. Royal Stat. Soc. Ser. B, 58 (1) (1996)
267–288.
[41] E. Dall’Anese, J.A. Bazerque, G.B. Giannakis, Group sparse Lasso for cognitive network sensing robust to
model uncertainties and outliers, Elsevier Physical Commun. 5 (1) (2012) 161–172.
[42] M. Yuan, Y. Lin, Model selection and estimation in regression with grouped variables, J. Royal Stat. Soc. 68
(2006) 49–67.
[43] H. Zhu, G. Leus, G.B. Giannakis, Sparsity-cognizant total least-squares for perturbed compressive sampling,
IEEE Trans. Signal Process 59 (2011) 2002–2016.
[44] J.A. Bazerque, G. Mateos, G.B. Giannakis, Group-Lasso on splines for spectrum cartography, IEEE Trans.
Signal Process. 59 (10) (2011) 4648–4663.
[45] G. Wahba, Spline Models for Observational Data, SIAM, Philadelphia, 1990.
[46] J. Duchon, Splines Minimizing Rotation-Invariant Semi-norms in Sobolev Spaces, Springer-Verlag, Berlin,
1977.
[47] T. Hastie, R. Tibshirani, J. Friedman, The Elements of Statistical Learning, second ed., Springer-Verlag, New
York, NY, 2009.
[48] A. Goldsmith, Wireless Communications, Cambridge University Press, 2005.
[49] R. Zhang, On peak versus average interference power constraints for protecting primary users in cognitive
radio networks, IEEE Trans. Wireless Commun. 8 (4) (2009) 2112–2120.
[50] K. Kumaran, S.E. Golowich, S. Borst, Correlated shadow-fading in wireless networks and its effect on call
dropping, Wireless Networks 8 (1) (2002) 61–71.
[51] E. Dall’Anese, S.-J. Kim, G.B. Giannakis, Channel gain map tracking via distributed Kriging, IEEE Trans.
Veh. Technol. 60 (3) (2011) 1205–1211.
[52] T.S. Rappaport, Wireless Communications: Principles & Practice, Prentice Hall, 1996.
[53] G.L. Stüber, Principles of Mobile Communication, second ed., Kluwer Academic Publishers, Boston, MA,
2001.
[54] A. Goldsmith, L.J. Greenstain, G.J. Foschini, Error statistics of real-time power measurements in cellular
channels with multipath and shadowing, IEEE Trans. Veh. Technol. 43 (3) (1994) 439–446.
[55] M. Gudmundson, Correlation model for shadow fading in mobile radio systems, Elec. Lett. 27 (23) (1991)
2145–2146.
[56] F. Graziosi, F. Santucci, A general correlation model for shadow fading in mobile radio systems, IEEE
Commun. Lett. 6 (3) (2002) 102–104.
[57] Z. Wang, E.K. Tameh, A. Nix, Simulating correlated shadowing in mobile multihop relay/ad hoc networks,
Technical Report IEEE C802.16j-06/060, IEEE 802.16 Broadband Wireless Access Working Group, July
2006.
[58] C. Oestges, N. Czink, B. Bandemer, P. Castiglione, F. Kaltenberger, A.J. Paulraj, Experimental characteriza-
tion and modeling of outdoor-to-indoor and indoor-to-indoor distributed channels, IEEE Trans. Veh. Technol.
59 (2010) 2253–2265.
[59] P. Agrawal, N. Patwari, Correlated link shadow fading in multi-hop wireless network, IEEE Trans. Wireless
Commun. 8 (8) (2009) 4024–4036.
[60] K.V. Mardia, C. Goodall, E.J. Redfern, F.J. Alonso, The Kriged Kalman ﬁlter, Test 7 (2) (Dec. 1998) 217–285.
[61] C.K. Wikle, N. Cressie, A dimension-reduced approach to space-time Kalman ﬁltering, Biometrika 86 (4)
(1999) 815–829.
[62] B.D. Ripley, Spatial Statistics, John Wiley & Sons, 1981.
[63] E. Dall’Anese, S.-J. Kim, G.B. Giannakis, S. Pupolin, Power control for cognitive radio networks under
channel uncertainty, IEEE Trans. Wireless Commun. 10 (10) (2011) 3541–3551.

500
CHAPTER 9 Advances in Spectrum Sensing and Cross-Layer Design
[64] X. Hong, C.-X. Wang, J. Thompson. Interference modeling of cognitive radio networks, in: Proceedings of
the IEEE Vehicle Technology Conference, Singapore, May 2008, pp. 1851–1855.
[65] V. Blaschke, T. Renk, F.K. Jondral, A cognitive radio receiver supporting wide-band sensing, in: Proceedings
of the International Conference on Communication, Beijing, China, May 2008, pp. 499–503.
[66] B. Le, T.W. Rondeau, J.H. Reed, C.W. Bostian, Analog-to-digital converters, IEEE Signal Process. Mag. 22
(6) (2005) 69–77.
[67] W. Hu, D. Willkomm, M. Abusubaih, J. Gross, G. Vlantis, M. Gerla, A. Wolisz, Dynamic frequency hopping
communities for efﬁcient IEEE 802.22 operation, IEEE Commun. Mag. 45 (5) (2007) 80–87.
[68] S. Sengupta, S. Brahma, M. Chatterjee, N. Sai Shankar, Enhancements to cognitive radio based IEEE 802.22
air-interface, in: Proceedings of the IEEE ICC Conference, June 2007, pp. 5155–5160.
[69] D. Willkomm, M. Bohge, D. Hollos, J. Gross, A. Wolisz, Double hopping: a new approach for dynamic
frequency hopping in cognitive radio networks, in: Proceedings of the IEEE International Symposium on
Personal, Indoor and Mobile Radio Communication (PIMRC), September 2008, pp. 1–6.
[70] S. Yarkan, H. Arslan, Binary time series approach to spectrum prediction for cognitive radio, in: Proceedings
of the IEEE Vehicle Technology Conference, October 2007, pp. 1563–1567.
[71] M. Bishop, Pattern Recognition and Machine Learning, Springer-Verlag, New York, 2006.
[72] X. Li, S.A. Zekavat, Trafﬁc pattern prediction and performance investigation for cognitive radio systems, in:
Proceedings of the IEEE Wireless Communication and Networks Conference, April 2008, pp. 894–899.
[73] P.J. Brockwell, R.A. Davis, Introduction to Time Series and Forecasting, second ed., Springer-Verlag, New
York, 2006.
[74] X. Long, X. Gan, Y. Xu, J. Liu, M. Tao, An estimation algorithm of channel state transition probabilities for
cognitive radio systems. In Proceedings of the IEEE International Conference on Cognitive Radio Oriented
Wireless Network and Communication (CrownCom), May 2008, pp. 1–4.
[75] Q. Zhao, A. Swami, A decision-theoretic framework for opportunistic spectrum access, IEEE Wireless
Commun. 14 (4) (2007) 14–20.
[76] K. Liu, Q. Zhao, Indexability of restless bandit problems and optimality of Whittle index for dynamic
multichannel access, IEEE Trans. Info. Theory 56 (11) (2010) 5547–5567.
[77] A.T. Hoang, Y.-C. Liang, D. Wong, Y. Zeng, R. Zhang, Opportunistic spectrum access for energy-constrained
cognitive radios, IEEE Trans. Wireless Commun. 8 (3) (2009) 1206–1211.
[78] Y. Chen, Q. Zhao, A. Swami, Joint design and separation principle for opportunistic spectrum access in the
presence of sensing errors, IEEE Trans. Info. Theory 54 (5) (2008) 2053–2071.
[79] Q. Zhao, B. Krishnamachari, K. Liu, On myopic sensing for multi-channel opportunistic access: structure,
optimality, and performance, IEEE Trans. Wireless Commun. 7 (12) (2008) 5431–5440.
[80] J. Unnikrishnan, V.V. Veeravalli, Algorithms for dynamic spectrum access with learning for cognitive radio,
IEEE Trans. Signal Process. 58 (2) (2010) 750–760.
[81] J. Jia, Q. Zhang, X. Shen, HC-MAC: a hardware-constrained cognitive MAC for efﬁcient spectrum manage-
ment, IEEE J. Sel. Areas Commun. 26 (1) (2008) 106–117.
[82] S. Geirhofer, L. Tong, B.M. Sadler, Dynamic spectrum access in the time domain: modeling and exploiting
white space, IEEE Commun. Mag. 45 (5) (2007) 66–72.
[83] Q. Zhao, S. Geirhofer, L. Tong, B.M. Sadler, Opportunistic spectrum access via periodic channel sensing,
IEEE Trans. Signal Process 56 (2) (2008) 785–796.
[84] X. Li, Q. Zhao, X. Guan, L. Tong, Optimal cognitive access of Markovian channels under tight collision
constraints, IEEE J. Sel. Areas Commun. 29 (4) (2011) 746–756.
[85] H. Kim, K.G. Shin, Efﬁcient discovery of spectrum opportunities with MAC-layer sensing in cognitive radio
networks, IEEE Trans. Mob. Comput. 7 (5) (2008) 533–545.
[86] H. Kim, K.G. Shin, Fast discovery of spectrum opportunities in cognitive radio networks, in: Prof. of the
IEEE Symposium on New Frontiers in Dynamic Spectrum Access Networks, October 2008, pp. 1–12.

References
501
[87] S. Huang, X. Liu, Z. Ding, Optimal transmission strategies for dynamic spectrum access in cognitive radio
networks, IEEE Trans. Mob. Comput. 8 (12) (2009) 1636–1648.
[88] R. Fan, H. Jiang, Channel sensing-order setting in cognitive radio networks: a two-user case, IEEE Trans.
Veh. Technol. 58 (9) (2009) 4997–5008.
[89] L. Lai, H. El Gamal, H. Jiang, H.V. Poor, Cognitive medium access: exploration, exploitation, and competi-
tion, IEEE Trans. Mob. Comput. 10 (2) (2011) 239–253.
[90] H. Jiang, L. Lai, R. Fan, H.V. Poor, Optimal selection of channel sensing order in cognitive radio, IEEE
Trans. Wireless Commun. 8 (1) (2009) 297–307.
[91] Q. Zhao, J. Ye, When to quit for a new job: quickest detection of spectrum opportunities in multiple channels,
in: Proceedings of the MILCOM Conference, San Diego, CA, November 2008.
[92] S.-J. Kim, G.B. Giannakis, Rate-optimal and reduced-complexity sequential sensing algorithms for cognitive
OFDM radios, EURASIP J. Adv. Signal Process. (2009) p. 11 (Article ID 421540).
[93] S.-J. Kim, G. Li, G.B. Giannakis, Multi-band cognitive radio spectrum sensing for quality-of-service trafﬁc,
IEEE Trans. Wireless Commun. 10 (10) (2011) 3506–3515.
[94] N. Kundargi, A. Tewﬁk, Hierarchical sequential detection in the context of dynamic spectrum access for cog-
nitive radios, in: Proceedings of the International Conference on Electrical, Circuits and System, Marrakech,
Morocco, December 2007, pp. 514–517.
[95] Y. Xin, H. Zhang, S. Rangarajan, SSCT: a simple sequential spectrum sensing scheme for cognitive radio,
in: Proceedings of the GLOBECOM Conference, Honolulu, HI, November–December 2009, pp. 1–6.
[96] G. Cheng, W. Liu, Y. Li, W. Cheng, Spectrum aware on-demand routing in cognitive radio networks, in:
Proceedings of the IEEE DySPAN Conference, Dublin, Ireland, April 2007, pp. 571–574.
[97] Y. Shi, Y.T. Hou, A distributed optimization algorithm for multi-hop cognitive radio networks, in: Proceedings
of the IEEE INFOCOM Conference, Phoenix, AZ, April 2008, pp. 1292–1300.
[98] D.P. Bertsekas, Dynamic Programming and Optimal Control, vol. 1, second ed., Athena Scientiﬁc, Belmont,
MA, 2000.
[99] D.A. Casta non, Approximate dynamic programming for sensor management, in: Proceedings of the 36th
Conference on Decision and Control, vol. 2, San Diego, CA, December 1997, pp. 1202–1207.
[100] D. De Couto, D. Aguayo, J. Bicket, R. Morris, A high-throughput path metric for multi-hop wireless routing,
in: Proceedings of the International ACM Conference Mobile Computing, Networking, San Diego, CA,
September 2003, pp. 134–156.
[101] C. Xin, L. Ma, C.-C. Shen, A path-centric channel assignment framework for cognitive radio wireless
networks, Mobile Net. Appl. (Kluwer) 13 (5) (2008) 463–476.
[102] I. Pefkianakis, S.H.Y. Wong, S. Lu, SAMER: spectrum aware mesh routing in cognitive radio networks, in:
Proceedings of IEEE DySPAN, Chicago, IL, October 2008.
[103] A. Abbagnale, F. Cuomo, Gymkhana: a connectivity-based routing scheme for cognitive radio ad hoc net-
works, in: Proceedings of the IEEE INFOCOM, San Diego, CA, March 2010.
[104] K.R. Chowdhury, I.F. Akyildiz, CRP: a routing protocol for cognitive radio ad hoc networks, IEEE J. Sel.
Areas Commun. 29 (4) (2011) 794–802.
[105] H. Khalife, S. Ahuja, N. Malouch, M. M. Krunz, Probabilistic path selection in opportunistic cognitive radio
networks, in Proceedings of the IEEE Globe Telecom Conference, New Orleans, LA, December 2010.
[106] E. Dall’Anese, G.B. Giannakis, Statistical routing for multihop wireless cognitive networks, IEEE J. Sel.
Areas Commun. 30 (10) (2012) 1983–1993.
[107] A. Ribeiro, Z.-Q. Luo, N. Sidiropoulos, G.B. Giannakis, Modelling and optimization of stochastic rout-
ing for wireless multihop networks, in: Proceedings of the IEEE International Conference on Computer
Communication, Anchorage, AK, May 2007, pp. 1748–1756.
[108] A. Ribeiro, N. Sidiropoulos, G.B. Giannakis, Optimal distributed stochastic routing algorithms for wireless
multihop networks, IEEE Trans. Wireless Commun. 7 (11) (2008) 4261–4272.

502
CHAPTER 9 Advances in Spectrum Sensing and Cross-Layer Design
[109] M. Haenggi, On routing in random rayleigh fading networks, IEEE Trans. Wireless Commun. 4 (4) (2005)
1553–1562.
[110] L.F. Fenton, The sum of lognormal probability distributions in scatter transmission systems, IRE Trans.
Commun. Syst. 8 (1) (1960) 57–67.
[111] R. Rao, A. Ephremides, On the stability of interacting queues in a multi-access system, IEEE Trans. Info.
Theory 34 (1988) 918–930.
[112] R. Loynes, The stability of a queue with non-independent interarrival and service times, Math. Proc. Cam-
bridge Philosophical Society 58 (1962) 497–520.
[113] B.R. Marks, G.P. Wright, A general inner approximation algorithm for nonconvex mathematical programs,
Oper. Res. 26 (4) (1978) 681–683.

10
CHAPTER
Introduction to the Radar Signal
Processing Section
Fulvio Gini
Dipartimento di Ingegneria dell’Informazione, University of Pisa, Pisa, Italy
Signal processing for radar systems is a vast and fascinating discipline that concerns many different
techniques and ﬁelds of application. The complete Elsevier Reference includes this section along with
that on Array Signal Processing, which is intimately related to radar techniques. This section focuses
on the most recent and exciting ﬁndings on the applications of signal processing techniques in radar
systems, described in a tutorial manner, such that newcomers in the area can learn what is going on in
this always in progress ﬁeld of research. The basics and the new ﬁndings on array signal processing
techniques are covered in the Array Signal Processing section edited by Mats Viberg.
The history of radar started more than one hundred years ago, in 1904, when Christian Hülsmeyer
demonstrated the ﬁrst experimental radar in Cologne, Germany. Later, in 1920, Guglielmo Marconi also
observed the radio detection of targets in his experiments, but it was not until World War II that dynamic
development of radar began. It has since then evolved into an indispensable all-weather, long-range
sensor. Military and security applications have always been the main drivers of radar developments.
However, later on radar has become a key sensor for civil applications including air, maritime, and
ground trafﬁc control and the guidance of aircraft and vehicles on airport surfaces.
According to its acronym RAdio Detection And Ranging, the classical radar mission is to detect and
locate objects. With the advent of coherent pulse radar, velocity measurements have become possible by
exploitingtheDopplereffect.Todayspecializedradarsmeasureelevation,aidinweathermonitoring,and
help with target classiﬁcation. To ﬁnd an overview of basic radar concepts and radar signal processing
algorithms the interested reader can refer to [1].
One of the main problems in radar technology has always been the mitigation of echoes reverberating
from the environment surrounding the radar, named clutter. Since the clutter is one of the most limiting
factorfortheperformanceofaradarsystem,westartthissectionwithachapteronthestatisticalmodeling
and analysis of radar clutter data. The chapter titled “Radar Clutter Modeling and Analysis,” co-authored
by Maria S. Greco and Simon Watts, describes how sea, ground, and rain clutter processes have been
modeled to design optimal radar receivers. A number of families of statistical models are described in
the ﬁrst part of the chapter that can be used to ﬁt the observed amplitude statistics over a wide range of
conditions, including the log-normal, the Weibull, and, especially, the compound-Gaussian model. The
second part of the chapter describes the statistical analysis performed on different experimental sea and
land clutter data to test the ﬁt of theoretical models with real data using different radar parameters and
environmental conditions. The limitations of theoretical models in some conditions are also discussed.
Concerning the clutter power spectral density (PSD), many models have been proposed in the literature
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-396500-4.00010-7
© 2014 Elsevier Ltd. All rights reserved.
505

506
CHAPTER 10 Introduction to the Radar Signal Processing Section
in the last 50 years [2]. Greco and Watts summarize the most successful results concerning clutter PSD
modeling by describing the Autoregressive (AR), Gaussian, power law (PL), and exponential spectral
models and their ﬁt with real data. A deﬁnite conclusion on this complex matter cannot be reached, since
the study of clutter phenomenon is an always in progress research area. As radar systems improve, new
features of clutter and target scattering may be observed and new analyses are then necessary to develop
more accurate models of these characteristics and to improve the design of target detectors (see e.g., [3]).
A major advance, leading to a new quality of radar, is represented by the invention of array antennas.
One of the main advantages of array antennas is that they provide, in principle, spatial sampling of
the received wavefront, i.e., multichannel data acquisition [4]. This enables the use of different spatial
processing techniques according to the application, e.g., pattern shaping to suppress interference in
certain directions. Spatial and temporal processing can be made data dependent resulting in space-time
adaptive processing (STAP). STAP is one of the key topics in modern coherent radar. The practical
relevance of STAP lies in its ability to suppress clutter from airborne and space-based radar systems,
where, depending on angle and range, clutter is spread in Doppler frequency. Chapter 12 of this section,
“Space-Time Adaptive Processing for Radar,” is entirely devoted to STAP. William Melvin describes
a number of key aspects of STAP and a number of approaches to design optimal detectors. Several
major algorithms are summarized, including post-Doppler STAP, pre-Doppler STAP, and parametric
STAP. The author then characterizes the performance of various methods in homogeneous clutter using
the signal to interference plus noise ratio (SINR) loss as the performance metric. Then, he discusses
the challenges of STAP application in heterogeneous/nonstationary clutter. One section of this chapter
is devoted to the recent concept of knowledge-aided (KA), or knowledge-based (KB), sensor signal
processing. A KB radar exploits methods and techniques of artiﬁcial intelligence and uses a-priori
information collected from the environment to improve the performance of adaptive sensor systems.
Examples of a-priori information are geographic maps, digital elevation models, weather data, car trafﬁc
data, intelligence, e.m. data base, GIS, etc. More details on knowledge-based radar can be found in [5,6].
Finally, Melvin summarizes several STAP data collection programs, the characteristics of the various
radar systems, and the type of data collected.
A recent trend in multichannel radar development is represented by the multiple input-multiple output
(MIMO) radars. They are formed by several spatially separated transmitting, receiving, or transmitting-
receiving systems. The distinguished feature is represented by the capability of joint processing all
the received target information. Two kinds of MIMO radars have been considered, the MIMO radars
with colocated antennas and the MIMO radars with widely separated antennas. Most of the achieve-
ments about the ﬁrst kind of conﬁguration are described in [7]. As concerning the second type, sometime
called Multistatic Radar System (MSRS), the theoretical foundations can be found in [8], both for active
and passive radars. In Chapter 13, “MIMO Radar with Widely Separated Antennas—From Concepts
to Designs,” Qian He, Yang Yang, and Rick S. Blum summarize and discuss a large range of issues
related to the MIMO radar with widely separated antennas. Both coherent and noncoherent MIMO
radar performance in target localization and velocity estimation are investigated. Topics of realistic
values are covered, which include, for example, phase synchronization algorithm design for coherent
MIMO radar and MIMO radar waveform design for extended targets. The performance differences
between coherent and noncoherent MIMO radars in the application of joint target location and veloc-
ity estimation are investigated. Then, the authors derive the diversity gain for a MIMO radar system
adopting the Neyman-Pearson detection. Three phase synchronization approaches for coherent MIMO

Introduction to the Radar Signal Processing Section
507
radar, which includes the master-slave closed-loop method, the round-trip approach, and the broadcast
consensus based algorithm, are described and compared, and some issues that may arise in practice are
discussed. Finally, some waveform design schemes for MIMO radar with widely separated antennas
are described.
The transmitted waveform has a crucial role in determining the performance of a radar system. In
the well-known book by Levanon and Mozeson [9], classical (non-adaptive) techniques for waveform
design are described in depth. The more recent topics of waveform diversity and adaptive waveform
design are instead the subject of a recent book [10]. In Chapter 14, “Optimal Radar Waveform Design,”
Joseph R. Guerci describes how adaptivity on transmission can be achieved through waveform diversity
and how this may increase the detection and identiﬁcation performance of a radar system. The chapter
develops the basic theory of optimal transmit/receive design using a multi-input, multi-output (MIMO)
formulation that can account for all potential degrees of freedom (DOFs) such as waveform (fast-time),
angle, and polarization. Various applications and examples are provided to further illustrate the potential
impact of joint transmit/receive adaptivity.
The scope of radar post-processing involves estimating target parameters, such as range, Direction
of Arrival (DoA), and velocity, and form the tracks of all the detected targets. These parameters usually
represent the necessary information to automatically determine the identity (class) of the targets. The
following steps are typically the situation assessment and the response selection, according to the mis-
sion of the system. Situation Awareness is the crucial step for a reliable decision making process, which
resultsinanoutcomeleadingtotheselectionofasuitablecourseofactionamongseveralalternatives(see
[11] and references therein). Chapter 15, “Multitarget Multisensor Tracking,” co-authored by X. Chen,
R. Tharmarasa and T. Kirubarajan, introduces various multisensor-multitarget tracking architectures.
The authors discuss in detail estimators for spatial clutter intensity, ﬁlters for linear and nonlinear
systems, algorithms for data associations and multitarget-tracking, techniques used in centralized and
distributed track-to-track fusion. In addition, their quantitative and qualitative merits are discussed.
Various combinations of these algorithms provide a complete tracking framework for multisensor net-
works with application to civilian as well as military problems. For example, the tracking and fusion
techniques discussed in this chapter are applicable to ﬁelds like air trafﬁc control, air/ground/maritime
surveillance, mobile communication, transportation, video monitoring, and biomedical imaging/signal
processing. The tracker performance evaluation, including its guiding principle and several measures of
performance, is also discussed in this chapter. A challenging scenario with many closely spaced targets
is used to compare several multitarget tracking algorithms.
Radar systems where the transmitter and receiver are colocated, or the separation between the trans-
mitter and the receiver is small with respect to the target range, are called monostatic. Instead, when
the transmitter and receiver are largely separated, so that scattering phenomenology differs from the
monostatic case, we talk about bistatic radar systems. In Chapter 16, “Passive Bistatic Radar,” Hugh
Grifﬁths introduces the reader to those bistatic radar systems that make use of emissions from broadcast,
communications or radionavigation transmitters rather than a dedicated, cooperative radar transmitter.
Such systems have a number of potential advantages. The receiver is passive and so potentially unde-
tectable.Therearemanyilluminationsourcesthatcanbeused,manyofthemofhighpowerandfavorably
sited. The receiver of passive bistatic radar (PBR) can often be rather simple and low cost, and there is
no need for any license for the transmitter. However, since the waveforms are not explicitly designed
for radar use they may be far from optimum for radar purposes. It is therefore necessary to understand

508
CHAPTER 10 Introduction to the Radar Signal Processing Section
the effect of the waveform on the performance of the passive bistatic radar, so as to be able to choose the
most appropriate illuminator, and to process the waveform in the optimal way. This chapter describes
the properties of such sources, the processing techniques that are used, and the performance that may be
achieved. Grifﬁths ﬁnally concludes that applications to which PBR systems may be put need careful
thought. It is important to understand very thoroughly the relationship between the desired application
and the performance requirements that follow, and the properties of the illuminator source that might
be used, for example in terms of coverage, power level, bandwidth, integration time, and so on.
The multichannel system concept described in Chapter 12 is also applicable in cases where the spatial
samples are taken sequentially in time, e.g., during the ﬂight of an aircraft. This leads to synthetically
generated antenna apertures of very large dimension, resulting in extremely high resolution. Imaging
radars that use such a synthetic aperture (SAR) differ greatly from real aperture radars. They have been
developed since the 1970s as a new all-weather sensor for ground observation [1]. The main goal of
SAR is to achieve high resolution. Challenges to focus the synthetic array include mitigation of sensor
position errors, and handling of large bandwidth, among others. Combining both types of arrays, i.e.,
using an antenna array as a sensor of the synthetic array, results in new techniques to solve the focusing
problem. In addition, multichannel SAR offers new features, particularly the ability to detect moving
targets (GMTI, ground moving target indication), and interferometric SAR, which can provide 3-D
images of the terrain. Multichannel SAR for airborne or space-based remote sensing, both for military
and civilian applications, is one of the most dynamic developing radar technologies. Recently, radar
imaging techniques have also been developed for providing high quality imagery of enclosed structures.
Each remote sensing application area has driven different sensing modalities and imaging algorithm
development based upon propagation characteristics, sensor positioning, and safety issues. For example,
the recent technique of through-the-wall radar imaging (TWRI) makes use of electromagnetic waves
below the S-band to penetrate through building wall materials. The indoor scene can be illuminated from
each antenna, and be reconstructed using the data from the receive antennas. Due to the “see”-through
ability, TWRI has attracted much attention in the last decade and has found a variety of important
civilian and military applications.
In Chapter 17, “Through-the-Wall Radar Imaging: Theory and Applications,” Moeness Amin and
Fauzia Ahmad describe the recent algorithmic advances in TWRI. Firstly, they focus on the problem of
mitigating wall clutter. Front wall reﬂections are often stronger than target reﬂections, and they tend to
persist over a long duration of time. Therefore, weak and close by targets behind walls become obscured
and invisible in the image. Approaches based on both electromagnetic modeling and signal processing
are advocated to signiﬁcantly mitigate the front wall clutter. Then, the authors present an approach
to exploit the rich indoor multipath environment for improved behind-the-wall target detection and
localization. A change detection approach to moving target indication for through-the-wall applications
is also described. Both coherent and noncoherent change detection techniques are examined and their
performance compared using real data collected in a semi-controlled laboratory environment. The ﬁnal
part of the chapter is devoted to the application of the emerging compressive sensing techniques to
circumvent possible logistic difﬁculties in collecting measurements in time and space and provide fast
data acquisition and scene reconstruction for moving target indication.
One fundamental application of modern multichannel air- and spaceborne SAR sensor is ground
moving target indication. The aim of SAR GMTI is to detect moving targets on ground and to estimate
their positions, velocities, and moving directions. Although originated in the military ﬁeld, nowadays

Introduction to the Radar Signal Processing Section
509
GMTI also has gained relevance for civilian road trafﬁc monitoring to ensure the mobility and to increase
the safety of the road users. In Chapter 18, titled “Multi-channel SAR for Ground Moving Target
Indication,” Stefan V. Baumgartner and Gerhard Krieger provide a comprehensive tutorial for GMTI
with SAR systems. The SAR principle is explained and a single- and multi-channel moving point target
signal model is derived. The effects on SAR imagery caused by moving targets are addressed in detail.
The knowledge about these effects is essential for understanding the different parameter estimation
methods. The classical dual-channel techniques Along-Track Interferometry (ATI) and Displaced Phase
Center Antenna (DPCA) and their limitations are discussed in detail, since they are currently of special
importance for state-of-the-art spaceborne SAR-GMTI systems. A general GMTI processing chain is
also presented and basic Doppler parameter estimation methods introduced. Finally an outlook to future
trends, applications, and open problems is given.
The imaging mode when the radar is stationary and the target is moving, or when both platforms are
moving, is called inverse synthetic aperture radar (ISAR). Although the SAR and ISAR imaging modes
have quite a lot in common, there are some signiﬁcant differences that mark a line between them. In
Chapter 19, titled “Introduction to Inverse Synthetic Aperture Radar,” Marco Martorella introduces the
readers to the main concepts and algorithms relative to ISAR imaging. Speciﬁcally, the concept of high
resolution applied to radar is used to introduce ISAR imaging. A model-based approach is proposed as a
method to derive the ISAR processor. ISAR geometry and received signal modeling have been deﬁned.
Polarimetric and bistatic ISAR imaging are also discussed as they represent more recent advances in
ISAR imaging that are opening the doors to the use of ISAR when polarimetric radars are employed or
when the radar conﬁguration is multistatic. Examples are provided in a variety of scenarios.
The classical SAR imaging allows high resolution capability in 2-D, i.e., azimuth and range. The
resulting image represents only a “projection” along the elevation direction of the illuminated 3-D
scene backscattering properties over the azimuth slant-range plane. In Chapter 20, titled “SAR Inter-
ferometry and Tomography: Theory and Applications,” Gianfranco Fornaro and Vito Pascazio describe
the principles of SAR interferometry (InSAR) and SAR tomography (Tomo-SAR) for 3-D imaging.
Interferometric SAR provides a 3-D imaging of the sensed scene relying only on the use of the phase
difference between the signal acquired in at least two passes. However, InSAR implicitly assumes the
presence of only a single scattering mechanism, i.e., does not comply with a possible integration of
the scattering along the elevation direction. SAR Tomography is the extension of SAR Interferometry
to allow a full 3-D imaging. It simply synthesizes, as in the case of the azimuth direction where an
array is digitally formed, an array also in the elevation direction by exploiting the spatial multibaseline
acquisition. In this chapter, the authors describe the most innovative processing techniques, like perma-
nent scatterer interferometry, polarimetric-interferometry and tomography, and some examples of their
many applications, such as the monitoring of volcanoes, earthquakes, landslides, ice sheet motion, and
anthropogenic sources such as ground pumping of water and oil. The Differential SAR Interferomet-
ric (DInSAR) technique is also described in detail. In this case, multitemporal data are acquired over
repeat passes and processed to generate very accurate deformation time series and therefore to achieve
a regular monitoring of the deformation of the observed scene. DInSAR techniques also mitigate most
of the limitations of the standard single-interferogram approaches, such as temporal and geometric
decorrelation and the atmospheric phase delay and, unlike conventional InSAR, they allow increasing
the measurement accuracy from centimeter up to millimeter. Finally, a mention to the new technique
known as Polarimetric SAR Tomography is reported. Polarimetry offers a high potential for estimating

510
CHAPTER 10 Introduction to the Radar Signal Processing Section
physical characteristics of objects and environments. A detailed description of radar Polarimetry can
be found in Chapter 21, authored by Eric Pottier and Laurent Ferro-Famil.
Chapter 21, “Radar Polarimetry Basics and Selected Earth Remote Sensing Applications,” introduces
the readers to some characteristic techniques and applications of modern SAR Polarimetry. The ﬁrst
part presents some basics of SAR Polarimetry. The polarization of a wave is ﬁrst described in terms
of vector representations. Both coherent and incoherent polarimetric operators are then deﬁned and
their properties are investigated for different kinds of scatterers. Various polarimetric decomposition
techniques are presented. Their necessity and usefulness are discussed as well as their domain of appli-
cation. Finally a simple polarimetric classiﬁcation scheme, based on both physical interpretation and
statistical segmentation is described. The second section presents advanced decomposition techniques
and their applications to the estimation of physical quantities. The last part presents selected topics in
multidimensional polarimetric SAR signal processing. The dimensionality of polarimetric signal being
rather low, the use of other kinds of diversity is often required to solve an estimation problem. This part
shows how three different applications, Time-Frequency Representation (TFR) of complex environ-
ments, Pol-InSAR characterization of forested areas, and polarimetric SAR Tomography, are all based
on the modeling of the correlation properties of polarimetric signals acquired from different positions.
Finally, some current trends in SAR Polarimetry are discussed.
The last chapter, “Integrated Sensor Systems and Data Fusion for Homeland Protection,” is moti-
vated by the evidence that in the last few years technologies for identiﬁcation and authentication, border
security, and controlled access to critical infrastructures have become a very important concern to pre-
vent unexpected attacks. Both future military operations and civil needs require innovative powerful
sensors and sensor conﬁgurations that are able to change dynamically their behavior to overcome with
the changing priorities and requirement of the mission. Alfonso Farina, Luciana Ortenzi, Branko Ristic,
and Alex Skvortsov describe the most important issues related to an integrated system formed by a
network of sensors, not necessarily all radar sensors, even if the radar is still the fundamental sensor
in an integrated surveillance system. In particular, they address the application of data and information
fusion to the design of integrated systems in the Homeland Protection (HP) domain. Data fusion is
about combining, or fusing, data from different sources of information to provide knowledge that is not
evident from individual sources. It aims to enhance situation awareness and decision making through
the combination of information/data obtained by networks of homogeneous and/or heterogeneous sen-
sors. The systems are integrated, to mean that it is generally not sufﬁcient to study each subsystem in
isolation, they are different in purpose and require a multidisciplinary approach for their design and
analysis. In this chapter these aspects are investigated in depth for networks, respectively, of homoge-
neous and heterogeneous sensors with the description of real study cases applied to real world problems
of homeland protection. In particular the possibility of netting different sensors operating with differ-
ent characteristics of domain, coverage, frequency, and resolution allows a multiscale approach. This
approach is particularly suitable for the surveillance of wide areas such as national borders or critical
strategic regions.
What lies ahead? It comes as no surprise that we have yet to confront numerous fascinating technical
challenges. These are potential R&D topics for the next editions of this encyclopedia. Some of them
have only been “touched” in these chapters, e.g., advanced radar detection techniques for spiky non-
Gaussian clutter, knowledge-based radar, cognitive radar, application of compressive sensing in radar,
ground penetrating radar, automotive radar, etc. Until then, enjoy this outstanding collection of chapters.

References
511
With gratitude I want to acknowledge the extremely valuable work invested by the authors. They have
provided highly professional and timely contributions. I also want to express my sincere gratitude to the
referees whocarefullyreadandreviewedthesubmittedmanuscripts, therebyensuringahighstandardfor
this section. The referees for the chapters of this section are: Chris Baker, Alessio Benavoli, Paolo Braca,
Victor Chen, Stefano Coraluppi, Antonio De Maio, Jean Dezert, Joachim Ender, Stefano Fortunati, Scott
Hensley, Richard Klemm, Michael Leigsnering, Regis C.P. Marques, Ram M. Narayanan, Willie Nel,
Jean-Philippe Ovarlez, Riccardo Paladini, Matteo Pardini, Fred Posner, Branko Ristic, Luke Rosenberg,
Greg Showman, Francesco Soldovieri, Pietro Stinco, Keith Ward, Michael Wicks.
References
[1] Principles of Modern Radar: Basic Principles, M.A. Richards, J.A. Scheer, W.A. Holm (Eds.), SciTech Pub-
lishing, Raleigh, NC, 2010.
[2] J.B. Billingsley, Low-Angle Radar Land Clutter: Measurements and Empirical Models, William Andrew
Publishing, Inc., Norwich, NY, 2002.
[3] K.J. Sangston, F. Gini, M.V. Greco, A. Farina, Structures for optimal and suboptimal coherent radar detection
in compound gaussian clutter, IEEE Trans. Aerosp. Electron. Syst. 35 (2) (1999) 445–458.
[4] A. Farina, Antenna-Based Signal Processing Techniques for Radar Systems, Artech House Inc., Norwood,
MA, 1992.
[5] F. Gini, M. Rangaswamy (Eds.), Knowledge Based Radar Detection, Tracking and Classiﬁcation, John Wiley
& Sons, Inc., Hoboken, New Jersey, 2008.
[6] J.R. Guerci, Cognitive Radar: The Knowledge-Aided Fully Adaptive Approach, Artech House, Norwood,
MA, 2010.
[7] J. Li, P. Stoica (Eds.), MIMO Signal Processing, John Wiley & Sons, Inc., 2009.
[8] V.
Chernyak,
Fundamentals
of
Multisite
Radar
Systems,
Multistatic
Radars
and
Multiradar
Systems, Gordon and Breach Science Publishers, 1998 (Revised and Extended Translation from Russian
Edition, 1993).
[9] N. Levanon, E. Mozeson, Radar Signals, John Wiley & Sons (Interscience Div.), New York, 2004.
[10] F. Gini, A. De Maio, L.K. Patton (Eds.), Waveform Design and Diversity for Advanced Radar Systems, IET,
Radar Sonar and Navigation Series, vol. 22, 2012.
[11] S. Giompapa, F. Gini, A. Farina, A. Graziano, R. Croci, R. Di Stefano, Maritime border control multisensor
system, IEEE Aerosp. Electron. Syst. Mag. 24 (8) (2009) 9–15.

11
CHAPTER
Radar Clutter Modeling
and Analysis
Maria S. Greco* and Simon Watts†
*Department of Ingegneria dell’Informazione, University of Pisa, Pisa, Italy
†Thales UK, Crawley, West Sussex, UK
2.11.1 Introduction
Radars operating in an open environment will receive returns from many sources. In addition to reﬂec-
tions from objects of interest, usually known as targets, the radar signal will include backscatter from
the environment and other unwanted objects. These unwanted returns are usually called radar clutter.
Clutter signals that affect the radar performance are typically categorized in terms of backscatter from
the land, the sea and the atmosphere (particularly from precipitation). Other objects may also provide
unwanted reﬂections that can be called clutter. These include birds and insects, dust and man-made
objects such as buildings, pylons, roads and so on. In the ﬁeld of electronic warfare, the characteristics
of chaff [1] may also be described in the same way as some types of clutter. In the early days of radar,
unexplained backscatter signals were sometimes called “angels.” These are now mostly understood as
atmospheric effects or returns from birds. For example, so called “ring angels,” which appeared like
circular ripples on a pond when seen on a radar display, were found to be from starlings setting out from
their roosts in waves [2].
A radar system is required to process the returns from targets in the presence of unwanted clutter
(in addition to thermal noise that is always present in a radar receiver). The radar will usually need to
detect the presence of a target and its position (typically at least its range and bearing from the radar)
and perhaps to track it, if it is moving. The radar may also need to distinguish between different types
of targets, including target classiﬁcation and recognition [3]. In order to develop suitable processing
algorithms for these tasks, the radar designer needs to be able to characterize clutter returns, in order to
distinguish them from those of targets.
The characteristics of clutter are usually captured in terms of mathematical and numerical models.
These models are designed to describe the various aspects of clutter that affect the design and use of radar
systems. Models of clutter are used in all phases of the design cycle [4], including the following activities:
•
Requirements deﬁnition.
•
Predicting likely radar performance in different conditions.
•
Radar system and signal processing algorithm design.
•
Performance assessment and acceptance procedures for radar procurement.
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-396500-4.00011-9
© 2014 Elsevier Ltd. All rights reserved.
513

514
CHAPTER 11 Radar Clutter Modeling and Analysis
•
In-service tactics and training.
•
In-service upgrades.
A mathematical model only has full value to a radar designer if it can be related to characteristics
actually observed in a real radar. The ﬁdelity required will depend on the application. High-level simula-
tions may only require simple models, while models used for signal processing algorithm development
may need to be very detailed. In particular, a model needs to be able to reﬂect the speciﬁc conditions in
which the radar is being designed to operate. So, the parameter values of a mathematical model must be
related to environmental conditions (wind speed, wave height, rainfall rate, etc.) and terrain type (land
cultural features, rain or snow, etc.).
Throughout the following discussions of clutter modeling, the purposes and scope of the various
models must be clearly understood. While many of the models described here can represent what is
seen in a real radar with considerable ﬁdelity, models are rarely precisely the same as real life. Models
may be used to assist the design and assessment of radar systems, but the radar must still be able to
deal with variations of characteristics that may be outside the average levels predicted by a model. For
example, there are models that predict the average backscatter levels from the sea surface, as a function
of the wind speed and direction, sea state (wave height), radar frequency, grazing angle and so on. These
models predict very well the range of values that may be encountered over a wide range of conditions.
However, they cannot reliably be used to predict the exact levels of backscatter on a given trial, not least
because of the extreme difﬁculty of accurately measuring the prevailing conditions in the trial.
The study of clutter models is a continuing research topic. As radar systems improve, they are able
to undertake more detailed analysis of the returns from targets and clutter. This in turn demands more
detailed models of the returns, for example to characterize second order effects that had previously been
ignored. The ability of radars to use very wide pulse bandwidths (providing ﬁner range resolution),
higher stability waveforms (allowing more precise analysis of Doppler shifts), polarization diversity
and so on, all require improved clutter models to support their development. For example, the current
research and gaps in our understanding of sea clutter are reviewed in [5], where it is noted that improved
understanding is needed for the modeling of Doppler spectra. Previous radars have not routinely used
coherent models for detecting small targets on the sea surface but as technology improves and operational
requirements change, it is likely that pulse Doppler modes will be increasingly used. In addition, the
use of very wide waveform bandwidths means that often the returns from sea clutter appear very spiky,
with occasional large amplitude excursions against a lower clutter background. These sea clutter spikes
need to be characterized to distinguish them from small targets.
This tutorial describes the various ways in which clutter is modeled and introduces some of the
ways in which models are used in radar design. Section 2.11.2 introduces the characteristics of clutter
as observed by radars and the methods used to characterize them. While some progress can be made
in predicting clutter characteristics from the theory of electromagnetic scattering from rough surfaces,
most of the models used by radar designers are empirical, with mathematical models designed to ﬁt
observed characteristics. Section 2.11.2 also introduces the empirical models widely used by radar
designers, including the methods used to ﬁt observed data to models. Section 2.11.3 provides some
examples of the methods applied to develop models from the analysis of recorded data. One of the
uses of these models is in the simulation of clutter returns for use in Monte Carlo computer simulation
and for stimulating real hardware. Various methods for clutter simulation are therefore introduced in

2.11.2 Clutter Modeling
515
Section 2.11.4. Section 2.11.5 then summarizes how the models are applied in radar design and analysis,
including their use for performance prediction, the design of detection processing algorithms and in the
speciﬁcation and measurement of radar performance in the radar procurement process.
2.11.2 Clutter modeling
2.11.2.1 Generic clutter characteristics
There are various features of clutter that are of interest to a radar designer. These are usually characterized
using the following types of model:
•
The area reﬂectivity (normalized radar cross section) σ 0 for spatially distributed surface clutter.
•
The volume reﬂectivity, η, for volume distributed clutter, such as precipitation and chaff.
•
The amplitude distribution of clutter returns.
•
The Doppler spectrum of returns.
•
The spatial variation of clutter characteristics.
•
Polarization characteristics (the polarization scattering matrix).
•
Discrete features (sea clutter spikes, discrete land clutter features, etc.).
The mathematical models discussed here may include one or more of these features. The method-
ologies for these models are developed below. Speciﬁc empirical models for different types of clutter
are described in Sections 2.11.2.2–2.11.2.4.
2.11.2.1.1
Normalized clutter reﬂectivity, σ 0
A perfectly smooth and ﬂat conducting surface will act as a mirror, producing a coherent forward
reﬂection, with the angle of incidence equal to the angle of reﬂection. However, if the surface has some
roughness, the forward scatter component (called coherent or specular reﬂection) is reduced by diffuse,
non-coherent scattering in other directions. For monostatic radar, clutter is the diffuse backscatter in the
direction towards the radar. This is illustrated in Figure 11.1.
The magnitude of the backscattered signal is characterized by the normalized radar cross-section σ 0.
At some instance during the propagation of the pulse, a pulsed radar will illuminate a patch on the surface,
deﬁned (for low grazing angles) to a ﬁrst order by the pulse length, the antenna azimuth beamwidth and
the local grazing angle. The backscatter from land or sea is then modeled assuming multiple scatterers
distributed spatially uniformly over this clutter patch. This is illustrated in Figure 11.2.
The normalized clutter reﬂectivity, σ 0, is deﬁned as the total RCS, σ, of the scatterers in the illumi-
nated patch, normalized by the area, Ac, of the patch:
σ 0 = σ/Ac.
(11.1)
σ 0 is usually deﬁned in units of dB m2/m2 (dB relative to 1 m2 radar cross-section, per m2 of area).
Referring to Figure 11.2, the area of the clutter patch is given by
Ac = αρRθaz sec (φgr),
(11.2)
where θaz is the antenna azimuth beamwidth and φgr is the local grazing angle. The range resolution,
ρ, is related to the radar pulse bandwidth, B, by ρ =
c
2B , where c is the velocity of light. The factor α

516
CHAPTER 11 Radar Clutter Modeling and Analysis
specular
component
diffuse
component
rough surface
smooth
surface
specular reflection
θi=θr
θi
θr
radar
monostatic
backscatter
FIGURE 11.1
Reﬂection from smooth and rough surfaces.
R
Radar pulse
Elevation
φgr
R
Azimuth
h
ψ
Clutter patch
antenna
footprint
ρ
θel
θaz
R θaz
ρ secφgr
FIGURE 11.2
Clutter illuminated patch size.
accounts for the actual compressed pulse shape and the azimuth beamshape, including the range and
azimuth sidelobes. For a rectangular shaped pulse and beamshape, α = 1, while for a Gaussian-shaped
beam and rectangular pulse, α = 0.753.
The grazing angle is deﬁned in terms of the average local surface. For a nominally average ﬂat
surface, such as the sea, the grazing angle can be deﬁned in terms of the radar height and propagation
over a curved earth. In this case, the grazing angle, φgr, can be written as:
φgr = sin−1
 h
R +
h2
2reR −R
2re

,
(11.3)

2.11.2 Clutter Modeling
517
where h is the height (altitude) of the radar, re is the effective Earth’s radius and R is the slant range.
For routine calculations at sea level, re ≈4/3r, where r is the true earth radius. This allows for the
effects of atmospheric refraction for a typical refractive index proﬁle. The actual effective grazing
angle will depend on the local propagation and may be greatly changed under conditions of anomalous
propagation, such as a surface ducts [2]. Over land, the local grazing angle will often be dominated by
the terrain elevation and slope, which must be determined for speciﬁc cases.
The above expressions apply at low grazing angles, when the illuminated patch is deﬁned by the
azimuth beamwidth and pulse length. At high grazing angles, or for low bandwidth radars, the illumi-
nated patch may be deﬁned by the antenna azimuth and elevation beamwidths. Care should be taken if
the grazing angle varies signiﬁcantly over the illuminated patch, as σ 0 will not be constant.
2.11.2.1.2
Clutter volume reﬂectivity
A similar approach is taken for volume scattering. This is deﬁned in terms of the volume reﬂectivity, η:
η = σ/Vc
(11.4)
with units of dB m2/m3.
The illuminated volume, Vc, is given approximately by:
Vc = αρR2θazθel,
(11.5)
where θel is the one-way 3 dB elevation beamwidth. This is illustrated in Figure 11.3.
Clearly, this expression for the illuminated volume assumes that the volume scatterers fully ﬁll the
antenna beam and pulse length at a given range. If this is not the case, appropriate corrections must be
made. For example, a volume search radar may have a narrow azimuth beam and a broad elevation beam.
When illuminating rain, the rain ceiling may subtend a smaller angle than the upper edge of the beam.
2.11.2.1.3
Amplitude statistics
As illustrated in Figures 11.2 and 11.3, the return from clutter is usually assumed to comprise the
backscatter from multiple scatterers, uniformly spatially distributed over an area or volume.
θaz
θel
ρ
R
R θaz
R θel
Pencil beam
Radar pulse
FIGURE 11.3
Volume clutter illuminated cell size.

518
CHAPTER 11 Radar Clutter Modeling and Analysis
The scattered ﬁeld, y, can be written as the vector sum from N random scatterers:
y =

N
√σi exp

jφi

,
(11.6)
where σi is the radar cross-section of a single scatterer, φi is a phase term (related to the reﬂection
coefﬁcient and the relative range of each scatterer from the radar). Provided N ≫1, the probability
density function of the real and imaginary parts of y will be Gaussian, through the application of the
central limit theorem (CLT). The corresponding PDFs for the envelope and intensity of the signal will be:
p(r) = r
σ 2 exp

−r2
2σ 2

;
0 ≤r ≤∞,
p(z) =
1
2σ 2 exp
	
−z
2σ 2

;
0 ≤z ≤∞,
(11.7)
where r is |y|, z = r2, E{z} = 2σ 2.
This representation of clutter is applicable to spatially uniform clutter observed with low-resolution
radars (i.e., with a large clutter patch, so N ≫1). This may apply to sea clutter, observed at high grazing
angles and low resolution, or to, say, large ﬂat areas of monoculture on land, such as woods or ﬁelds.
In many cases this representation is too simplistic. For example, the clutter mean intensity, 2σ 2 above,
may vary from one clutter cell to another, even though each cell still comprises multiple scatterers as
in (11.6). Under these circumstances, the overall PDF will no longer have simple Gaussian statistics.
Figure 11.4 illustrates the difference between returns with a Rayleigh PDF compared with clutter with
strongly non-Gaussian statistics, modeled by a K distribution PDF, which is discussed below. A variation
2
4
6
2
4
6
0
1000
amplitude
range
(a)
(b)
FIGURE 11.4
Envelope of uncorrelated signals versus time; (a) Rayleigh noise, mean level 1; (b) K distributed clutter,
mean level 1, ν = 0.5.

2.11.2 Clutter Modeling
519
of the underlying mean intensity can be incorporated into the overall amplitude statistics by extending the
simple model for PDF to include a dependence on the local mean intensity, which we shall call τ. Now:
p(r|τ) = 2r
τ exp

−r2
τ

;
0 ≤r ≤∞.
(11.8)
The mean level τ is itself a random variable with PDF p(τ), so that the overall PDF can be written
p(r) =
 ∞
0
p(r|τ)p(τ)dτ;
0 ≤r ≤∞.
(11.9)
This way we obtain the so-called compound-Gaussian model. The use of this type of model to rep-
resent radar sea clutter was originally described in [6–8]. The compound K distribution form of the
model, discussed below, was originally formulated by Ward et al. [9,10]. There is further discussion
in [9–21], and references therein. According to this model, each sample of the complex envelope of
the sea clutter process is the product of two random variables: the texture and the speckle and can
be represented as y = √τx. The term x = xI + jxQ represents a stationary complex Gaussian pro-
cess, called speckle, which accounts for local backscattering; xI e xQ are the in-phase and quadrature
components of the speckle complex envelope x. They satisfy the property E {xI} = E

xQ

= 0 and
E

x2
I

= E

x2
Q

= 1/2, so that E

|x|2
= 1, i.e., the speckle complex samples have unit power. The
factor τ is a non-negative real random process, called texture that, as said, models the local clutter power.
The compound-Gaussian model can be derived also as an extension of the CLT, allowing the number
of scatterers N in Eq. (11.6) to be a random variable [16,22]. In the particular case in which the number
of scatterers is distributed following a negative binomial PDF, the texture can be shown to be a Gamma-
distributed random variable (r.v.), and the amplitude a K-distributed r.v. (see Eq. (11.10)).
The compound-Gaussian model counts among its particular cases some families of distribution that
are very popular in clutter modeling. The analytical expressions for these PDFs and their moments
m R(n) = E {rn} are reported below, where r = |y| denotes the clutter amplitude.
K-model (K):
Replacing in Eq. (11.9) the generic p(τ) with the Gamma PDF p(τ) =
1

(ν)

ν
μ
ν
τ ν−1 exp

−ν
μτ

u(τ), we obtain
PDF:
pR(r) =
√2ν/μ
2ν−1
(ν)

2ν
μ r
ν
Kν−1

2ν
μ r

u(r),
(11.10)
moments: m R(n) =
2μ
ν
 n
2 

ν + n
2



1 + n
2


(ν)
,
(11.11)
where 
(·) is the gamma function, Kν−1(·) is the modiﬁed Bessel function of the second kind, of order
ν −1, ν is the shape parameter, and μ is the mean.
Generalized K model with lognormal texture (LNT):
PDF:
pR(r) =
r
√
2πσ 2
 ∞
0
2
τ 2 exp

−r2
τ −
1
2σ 2
	
ln
 τ
2m

2
dτ,
(11.12)

520
CHAPTER 11 Radar Clutter Modeling and Analysis
moments: m R(n) =

2m
 n
2 

1 + n
2

exp
n2σ 2
8

,
(11.13)
where σ is the shape parameter, and m is the scale parameter. This model cal be obtained with the
lognormal texture PDF p(τ) =
1
τ
√
2πσ 2 exp

−1
2σ 2
	
ln τ −ln 2m
2

u(τ).
Generalized K model with generalized Gamma texture (GK):
Putting in Eq. (11.9) the generalized Gamma texture PDF p(τ) =
νb
μ
(ν)

τν
μ
νb−1
exp

−

ν
μτ
b
u(τ) we obtain
PDF:
pR(r) = 2br

(ν)
 ν
μ
νb  ∞
0
τ νb−2 exp

−r2
τ −
 ν
μτ
b
dτ,
(11.14)
moments: m R(n) =
μ
ν
 n
2 

ν + n
2b



1 + n
2


(ν)
,
(11.15)
Weibull model (W):
PDF:
pR(r) = c
bc rc−1 exp

−(r/b)c
u(r),
(11.16)
moments: m R(n) = bn
n
c + 1

,
(11.17)
where c is the shape parameter and b is the scale parameter. The Rayleigh PDF is a particular case of
the Weibull PDF for c = 2 [23]. Unfortunately, for the Weibull distribution, the PDF of the texture does
not have a closed form and it is a compound-Gaussian model only for c < 2 [12].
Other sources of variability in clutter give rise to non-Gaussian statistics. While compound distribu-
tions can give some insight into the physical model underlying the non-Gaussian behavior, it is often
sufﬁcient to ﬁnd an empirical ﬁt of the overall amplitude statistics to a generalized PDF. Other popular
distributions include the lognormal model, which does not belong to the compound-Gaussian family.
The expressions of PDF and the moments are given below.
Lognormal model (LN):
PDF:
pR(r) =
1
r
√
2πσ 2 exp

−1
2σ 2
	
ln r −ln δ
2

u(r),
(11.18)
moments: mR(n) = δn exp
	
n2σ 2/2

,
(11.19)
where σ is the shape parameter, and δ is the scale parameter and u(r) the unit step function. Unfortu-
nately, the LN model does not satisﬁes any of the compound-Gaussian properties [12].
The non-Gaussian PDFs K, W, and LN each have two parameters, a shape and a scale parameter, that
can be adjusted to ﬁt the observed data. The GK, conversely, has three parameters. Figures 11.5–11.7
illustrate examples of PDFs from different families.
The K and Weibull distributions are very similar, both including the Rayleigh distribution as part
of their family (c = 2 in the Weibull distribution and ν = ∞in the K distribution) and they are often
used for sea clutter modeling. The lognormal distribution gives PDFs with much longer tails (i.e., a

2.11.2 Clutter Modeling
521
0
1
2
3
4
0.0
0.5
1.0
1.5
2.0
c = 0.7
c = 1
c = 3
c = 2
p(r)
r
FIGURE 11.5
Weibull distribution, mean power = 1.
0
1
2
3
4
0
0.2
0.4
0.6
0.8
1.0
σ = 2
σ = 1
σ = 0.5
p(r)
r
FIGURE 11.6
Lognormal distribution, mean power = 1, m = 0.
0
1
2
3
4
0
0.5
1.0
1.5
2.0
ν = 0.2
ν = 1
ν = ∞
ν = 0.5
p(r)
r
FIGURE 11.7
K distribution, normalized to mean; mean power = 1.

522
CHAPTER 11 Radar Clutter Modeling and Analysis
higher probability of achieving larger amplitudes relative to the mean amplitude). This is often used for
modeling land clutter, when the presence of large discrete scatterers can give rise to long tails if they are
included in distributed clutter. A model that explicitly includes discrete spikes is the KA distribution,
which is described in detail in [24,25].
2.11.2.1.4
Doppler spectrum
The simple model for clutter scattering given by (11.6), does not include any variation over time. If the
individual clutter scatterers are moving radially with respect to the radar, the phase will vary with time,
so that
y(t) =

N
√σi exp

jφi(t)

.
(11.20)
Assuming random motion of the scatterers, the temporal variations of the return must be described in
terms of the autocorrelation function, ACF:
R(τ) = lim
T →∞
1
T

 T
−T
y(t)y(t + τ)dt
 .
(11.21)
The power spectrum of the returns can be related to the ACF from its Fourier transform (Weiner Khint-
chine theorem):
S(ω) =
 ∞
−∞
R(τ) exp

−jωτ

dτ,
(11.22)
where ω is the Doppler radian frequency and ω = 2π f , where f is the Doppler frequency.
The Doppler power spectrum (power spectral density PSD) is often modeled as having a Gaussian
shape:
SG( f ) = S 0G exp

−

f −m f
2
2σ 2
f

.
(11.23)
This is usually a mathematical convenience rather than any attempt at realism. Often the Doppler
spectrum will be strongly asymmetric and the mean Doppler shift, mf , may not be zero. Clearly for
land clutter mf is usually zero, but for rain and sea clutter in general mf
̸= 0 and will be dependent
on the wind speed and direction. Moreover, for sea clutter, as ﬁrst reported by Pidgeon at C-band
[26], and in X-band [27], the sea spectrum exhibits different peaks in the HH and VV polarizations
[28,25,10]. Generally the spectral component corresponding to the lower frequency peak relative to
the VV polarization, associated with the Bragg scattering component, is well described by the Gaussian
function (11.23). On the contrary, the HH polarization is characterized by a higher frequency peak
in the spectrum, maybe owing to the scattering from fast moving (faster than Bragg scatterers) and
short-life scatterers. In this polarization the clutter PSD is well described by the Lorentzian function
(autoregressive model of order 1)
SL( f ) =
S 0L

f −mf
2 + k
,
(11.24)
where the constant k depends on the mean lifetime of scatterers.

2.11.2 Clutter Modeling
523
platform velocity, v
antenna 
beamwidth 
θ3dB
v
v sin θ3dB/2
−v sin θ3dB/2
resolved components 
of clutter velocity
FIGURE 11.8
Resolved component of clutter velocity across antenna beam, due to platform motion.
In some practical situations the above-mentioned two models do not sufﬁce to ﬁt the real spectra
shape, especially for the HH polarization. In [28] the authors consider ﬁrst the scattering from fast-to-
intermediate scatterers (e.g., bound-Bragg waves, etc.) whose PSD is characterized by a convolution of
the Gaussian and Lorentzian proﬁles, resulting in the Voigtian function, and then a linear combination
of these three models to improve the ﬁtting.
Another simple model often used for both sea and land clutter PSD is the autoregressive (AR) one.
The rationale for adopting AR models for the radar echoes is to have a highly parameterized model
with a minimum number of parameters that can be easily estimated. Some examples can be found in
[29,30].
For moving platforms, the antenna motion with respect to the clutter will also modify the Doppler
spectrum. This is illustrated in Figure 11.8 for a side looking antenna, with one-way 3 dB beamwidth
θ3dB and platform velocity v. If the antenna has a Gaussian shape, the combined Doppler spectrum due
to platform motion and internal clutter motion will be approximately:
S( f ) = S0 exp
⎡
⎣−
f 2
2

0.6vθ3dB/λ
2 + 2σ 2
f
⎤
⎦.
(11.25)
Figure 11.9 shows an example of the Doppler spectrum of sea clutter as function of time, derived
from radar data collected by CSIR [31]. The radar was vertically polarized with a frequency of 9 GHz,
a pulse repetition frequency, fr, of 5 kHz and a range resolution of 15 m. The local grazing angle for
the data collected was approximately 1◦. The radar look direction was 165.5◦, with wind of 15 kts from
247◦and a wave direction of 135◦, signiﬁcant wave height 2.2 m. The raw data was then processed over
bursts of L = 512 samples with an FFT, using a −55 dB Dolph-Chebyshev weighting function in the
time domain. It can be seen that the clutter intensity varies in time in a periodic manner. The spectrum
width also varies with time, with occasional extreme Doppler excursions, such as seen around 27 s into
the time record, perhaps as the result of local wind gusting. Finally, the spectrum appears asymmetric in
shape, with a non-zero mean Doppler shift. These features highlight the complexity of the relationship
between the intensity modulation and the form of the spectrum, the former being dominated by the swell

524
CHAPTER 11 Radar Clutter Modeling and Analysis
20
10
0
500
-500
0
Doppler frequency, Hz
30
time (sec)
FIGURE 11.9
Sea clutter Doppler spectrogram.
structure in the sea surface and the latter being additionally affected by the local gusting of the wind
and the detailed scattering mechanism. This non-stationary behavior of sea clutter will be addressed
with more detail in Section 2.11.3.1.7. However, despite this complexity it should be noted that the
compound modulated Gaussian process is still applicable in the spectral domain and will affect the
performance of both coherent and non-coherent radars.
2.11.2.1.5
Polarization characteristics
It is observed that most clutter characteristics are very dependent on the polarization of the radar signal
and so an understanding of polarization is important.
A wave is said to be polarized if the direction of the electric, E, and magnetic, H, ﬁelds reside in a
ﬁxed plane. The plane in which the E vector moves is called the plane of polarization. The polarization
scattering matrix, S, describes the amplitude and relative phase of returns from different combinations
of polarizations on transmit and receive:
S =

√σH He jρH H
√σHV e jρV H
√σV He jρHV
√σV V e jρV V
 ,
 EH
EV

receive
= AS
 EH
EV

transmit
,
(11.26)
where:
σH H, RCS for Tx on H and Rx on H polarization;

2.11.2 Clutter Modeling
525
Table 11.1 Examples of Linear Polarization Scattering Matrices for Different Target Types
Sphere: S =

1
0
0
1

Dihedral at ψ◦: S =

cos 2ψ
sin 2ψ
sin 2ψ
−cos 2ψ

Dihedral at 0◦: S =

1
0
0
−1

Linear target at ψ◦: S =

cos2 ψ
1
2 sin 2ψ
1
2 sin 2ψ
sin2 ψ

Horizontal linear target: S =

1
0
0
0

Left hand helix: S =

1
j
j
−1

Right hand helix: S =

1
−j
−j
−1

σV V , RCS for Tx on V and Rx on V polarization;
σV H, RCS for Tx on V and Rx on H polarization;
ρ is the associated reﬂection phase.
For monostatic backscatter σHV = σV H and ρHV = ρV H.
The discussion above is for linear polarization and some examples of polarization scattering matri-
ces for different targets types are shown in Table 11.1. Similar matrices can be used to describe the
relationship for circular polarized signals (right or left handed) or any orthogonal coordinate system.
If the V and H components of the electric ﬁeld are in phase, linear polarization is obtained. In general,
an arbitrary phase between the V and H ﬁelds produces an elliptical polarization. The special case of a
π/2 phase shift gives circular polarization.
For circular polarization, left-hand polarization is deﬁned when EV = jE H on transmit; right-hand
polarization is deﬁned with EV = −jE H.
The circular-polarization scattering matrix is deﬁned as
 EL
ER

receive
=
 cLL
cRL
cRL
cRR
  EL
ER

transmit
,
(11.27)
while the linear-polarization has a scattering matrix given by
 EH
EV

receive
=
aH H
aVH
aHV
aVV
  EH
EV

transmit
.
(11.28)
The circular polarization RCS terms can then be related to the linear polarization RCS terms by:
σLL = k |cLL|2 = k

aHH −aV V
2
+ jaVH

2
,
σLR = k |cLR|2 = k

aHH + aV V
2

2
,
σRR = k |cRR|2 = k

aHH −aV V
2
−jaVH

2
.
(11.29)

526
CHAPTER 11 Radar Clutter Modeling and Analysis
Using the deﬁnitions above, it can be seen that for a sphere, where aHH
= aVV
= 1 and
aHV = aVH = 0:
σRR = σLL = 0,
σL R = σH H = σV V .
(11.30)
For this reason circular polarization is often used to reduce the return from rain clutter. Odd-bounce
scatterers such as spheres or trihedrals will reverse the hand of polarization on reﬂection and a perfect
sphere will have σRR = σLL = 0. Unfortunately, raindrops are not perfectly spherical but, even so, the
reﬂectivity of rain may be reduced by about 15 dB to as much as 30 dB, dependent on conditions.
Target signatures, such as high-resolution range proﬁles, may be quite different according to polar-
ization. For example using circular polarization, σRL will show odd bounce scatterers while σRR will
show even bounce scatterers.
2.11.2.1.6
Spatial correlation
The returns from spatially uniform clutter will have Gaussian amplitude statistics, as described in
Section 2.11.2.1.3. The magnitude of the return will change as the viewing geometry changes, such as
when the antenna beam scans in azimuth or the range from the radar is changed. For a square beam and
pulse shape (see Section 2.11.2.1.2), the returns from clutter patches spaced by more than one beamwidth
or one pulse length will be independent and uncorrelated. However, if the successive clutter patches
overlap spatially, then the returns will be correlated. A convenient measure of the spatial correlation of a
sequence of intensity samples, z(i) (i = 1 – N) is given by the estimation of the correlation coefﬁcient:
ρk =
N/2
i

z(i) −ˆm
 
z(i + k) −ˆm

N/2
i

z(i) −ˆm
2
,
(11.31)
where ˆm is an estimate of the mean intensity and k is the correlation lag (0 ≤k ≤N/2). For spatially
uniform clutter with Gaussian statistics and a fractional overlap of the beam or pulses between successive
samples of β (0 ≤β ≤1), then the correlation coefﬁcient of the clutter intensity is ρk = β2.
Spatial correlation of the clutter returns may also be observed if the local normalized reﬂectivity
is changing in a systematic way. One example of this is observed over the short term in sea clutter,
when the spatial variations caused by the sea swell or waves causes a related variation in the local mean
reﬂectivity. This is illustrated in Section 2.11.3.1. Some examples of the range proﬁles of the local mean
intensity of sea clutter and their corresponding range correlation coefﬁcients are shown in Figure 11.10.
2.11.2.1.7
Discrete scatterers
The models for spatially distributed clutter are very useful for representing the returns from rain and often
from land and sea, especially at high grazing angles. However, under some conditions the underlying
assumptions of spatially uniform scatterers is no longer valid. For example, at low grazing angles terrain
scattering may become very patchy and spiky, and is dominated by local high structures [32]. At higher
grazing angles a distributed clutter model for terrain becomes more useful, but there will often also be
a number of very large discrete scatterers in any scene, due to natural and man-made features. Barton
[33] has analyzed a number of results from the literature and suggests that discrete clutter echoes of
104 m2 RCS might have a typical density of 0.2/km2; 103 m2 RCS a density of 0.5/km2; and 102 m2

2.11.2 Clutter Modeling
527
25
50
75
100
125
150
175
200
1
2
3
4
5
6
25
50
75
100
125
150
175
200
1
2
3
4
5
6
25
50
75
100
125
150
175
200
1
2
3
4
5
6
10
20
30
40
50
60
0.2
0.4
0.6
0.8
1
Range samples, k
-0.4
-0.2
A, ν = 1
ρk
B, ν = 5
C,ν = 0.5
A
B
C
FIGURE 11.10
Recorded data exhibiting different spatial correlations. Reproduced with permission from [25], © The Insti-
tution of Engineering and Technology.
RCS a density of 2/km2. Discrete scatterers as large as 106 ; m2 RCS may be found. Long [34] suggest
a density of about 0.004/km2 for 106 m2 RCS and 0.04/km2 for 105 m2 RCS.
Sea clutter may also include discrete spikes that have distinctly different properties from the sur-
rounding clutter. In particular, specular scattering with HH polarization from the crests of incipient
breaking waves may give rise to very localized returns having a large RCS [25]. The KA distribution
[24,25] can be used to model discrete spikes that are added to the standard compound K distribution
model. The amplitude distribution of clutter spikes has also been investigated in [35] who used the KK
distribution to achieve a good ﬁt to the tail of the distribution of clutter-plus-noise data recorded at
medium grazing angles.
2.11.2.2 Sea clutter
Observations of radar sea clutter are usually associated with particular characteristics of the sea surface
and environment, such as sea waves, sea swell and wind speed. Sea waves are the interaction between the
wind and the sea surface. As the wind blows over the surface, waves are generated that increase in height
and wavelength over time. Eventually an equilibrium is reached when the energy dissipated in the waves

528
CHAPTER 11 Radar Clutter Modeling and Analysis
Table 11.2 Douglas Sea State
Douglas
Description
Wave Height
Wind Speed
Fetch
Duration
Sea State
h1/3 (ft)
Knots
(nmi)
(h)
1
Smooth
0–1
0–6
2
Slight
1–3
6–12
50
5
3
Moderate
3–5
12–15
120
20
4
Rough
5–8
15–20
150
23
5
Very rough
8–12
20–25
200
25
6
High
12–20
25–30
300
27
7
Very high
20–40
30–50
500
30
8
Precipitous
>40
>50
700
35
Table 11.3 Beaufort Wind Scale
Beaufort Number
Description
Wind Speed, Knots
Sea Conditions
0
Calm
<1
Calm (glassy)
1
Light air
1–3
Calm (rippled)
2
Light breeze
4–6
Smooth (wavelets)
3
Gentle breeze
7–10
Slight
4
Moderate breeze
11–16
Slight-moderate
5
Fresh breeze
17–21
Moderate
6
Strong breeze
22–27
Rough
7
Near gale
27–33
Rough-very rough
8
Gale
34–40
Very rough-high
9
Severe gale
41–47
High
10
Storm
48–55
Very high
11
Violent storm
56–63
Very high
12
Hurricane
>64
Phenomenal
matches the energy input by the wind. This allows an average wave height to be associated with a speciﬁc
wind speed, provided that the duration (the length of time that the wind has been blowing at a given
speed) and the fetch (the range extent over which the wind has been blowing) are known. Wave heights
are usually measured in terms of h1/3, the speciﬁc wave height, deﬁned at the average peak to trough
wave height of the highest one third of the waves. Ranges of signiﬁcant wave heights are associated with
different sea states, which can be associated with wind speed, as discussed above. Table 11.2 shows
the relationships for the Douglas sea state, which is usually used for radar sea clutter modeling. Wind
speed is usually characterized in terms of the Beaufort wind scale, which is shown in Table 11.3.

2.11.2 Clutter Modeling
529
It should be noted that assessing the environment in a particular trial is notoriously difﬁcult and the
sea state reported by observers can show a wide variation. Wave-rider buoys can be used to estimate
local wave heights but these can usually only gave a rough guide to likely clutter characteristics, which
depend on things such as the “wind friction velocity,” “ wave age” and so on. These issues are discussed
in detail in [25].
2.11.2.2.1
Theoretical and empirical models for sea clutter reﬂectivity
The radar backscatter from the sea is derived from a complex interaction between the incident electro-
magnetic waves and the sea surface. There are many theoretical models for backscatter, based on the
physics of scattering from rough surfaces and approximations to scattering mechanisms. The simplest
models attempt to represent the surface as many small segments, called facets, with orientations modu-
lated by the waves. Scattering from wind-driven ripples may be approximated by Bragg scattering. The
tilting of the ripples by longer sea waves changes the scattered power. This type of model, introduced
by Wright [36] and Bass et al. [37], is discussed in detail in [25] and can give good results at medium to
high grazing angles. However, at low grazing angles and high sea states the electromagnetic scattering
becomes much more complex, with multiple reﬂection paths and shadowing from adjacent waves. There
will also be breaking waves that can contribute considerably to the backscatter and are not modeled
by simple modulated Bragg scattering. Some progress has been made recently in the understanding of
electromagnetic scattering at low grazing angles [25]. However, the practical development of sea clutter
models still mainly relies on empirical measurements.
Figure 11.11 shows a typical plot of normalized clutter reﬂectivity, σ 0, for sea clutter as a function of
grazing angle, for VV and HH polarizations. At near vertical incidence, the backscatter is quasi-specular.
In this region, the backscatter varies inversely with surface roughness with maximum backscatter at
verticalincidenceforaperfectlysmoothsurface.Atmediumgrazinganglesthereﬂectivityshowsalower
dependence on grazing angle. This is often called the plateau region. Here the reﬂectivity is well modeled
20
40
60
80
-40
-30
-20
-10
0
10
grazing angle, degrees
dB m2/m2
V pol
H pol 
Interference region
(near grazing incidence) 
Plateau region
(diffuse scatter)
Quasi-specular region
(near vertical incidence)
reflectivity
FIGURE 11.11
Typical variation with grazing angle and polarization of sea clutter reﬂectivity at X-band (for a wind speed of
about 15 km). Reproduced with permission from [25], © The Institution of Engineering and Technology.

530
CHAPTER 11 Radar Clutter Modeling and Analysis
by the composite model. Below some critical angle (typically around 10◦grazing angle, dependent on
the roughness) it is found that the reﬂectivity reduces much more rapidly with smaller grazing angles.
This is known as the interference region, where propagation is strongly affected by multipath scattering
and shadowing. Also shown in Figure 11.11 is the dependence of the reﬂectivity on radar polarization.
In the plateau region, the backscatter for HH polarization is signiﬁcantly lower than for VV polarization.
This is evident of the signiﬁcantly different scattering mechanisms for VV and HH polarizations.
In addition to a dependence on polarization and grazing angle, it is found that the reﬂectivity is
strongly dependent on wind speed, which creates local surface roughness. This is often associated with
the sea state but it should be noted that a strong sea swell in the absence of local wind may have a low
reﬂectivity, while a strong wind may create a high reﬂectivity from a comparatively ﬂat sea. The reﬂectiv-
ity will also depend to some extent on radar frequency. Another important consideration is propagation
effects, suchasducting, whichcanchangethelocalgrazingangleofthesignalincidentontheseasurface.
Indeed, observation of variation of surface reﬂectivity may be used to infer the presence of ducts [38].
There are various empirical models for the normalized clutter reﬂectivity that are used by radar
designers. Tables of σ 0 for different radar frequencies, grazing angles and sea states and for V and
H polarizations are given in [1]. These values are the result of averaging measurements from many
experiments. It may be noted that they do not model the variation of reﬂectivity with wind direction.
Another useful model, known as the GIT model [39], was developed by workers at the Georgia
Institute of Technology in the 1970s. This model covers radar frequencies from 1 to 100 GHz and grazing
angles from 0.1 to 10◦. It is based on an underlying multipath model as well as more general trends
observed in experimental data sets. The normalized reﬂectivities modeled for H and V polarizations, σ 0
(H) and σ 0 (V), respectively, are given by the following expressions:
Radar frequency 1–10 GHz
σ 0(H) = 10 log
	
3.9×10−6λψ0.4GaGuGw

,
σ 0(V ) =
⎧
⎪⎪⎨
⎪⎪⎩
σ 0(H) −1.05 ln

ha + 0.015

+ 1.09 ln

λ

+1.27 ln

ψ + .0001

+ 9.70 (3–10 GHz),
σ 0(H) −1.73 ln

ha + 0.015

+ 3.76 ln

λ

+2.46 ln

ψ + .0001

+ 22.2 (below 3 GHz).
(11.32)
The adjustment factors are
Ga =
a4
1 + a4 ;
Gu = exp
	
0.2 cos φ(1 −2.8ψ)(λ + 0.015)−0.4
;
Gw =

1.94Uw

1 + Uw/15.4

q
with q = 1.1/(λ + 0.015)0.4
and a = (14.4λ + 5.5)ψha/λ.
Radar frequency 10–100 GHz
σ 0(H) = 10 log
	
5.78×10−6ψ0.547GaGuGw

,
σ 0(V ) = σ 0(H) −1.38 ln

ha

+ 3.43 ln (λ) + 1.31 ln (ψ) + 18.55.
(11.33)

2.11.2 Clutter Modeling
531
and the adjustment factors are
Ga =
a4
1 + a4 ;
Gu = exp
	
0.25 cos φ(1 −2.8ψ)λ−0.33
;
Gw =

1.94Uw

1 + Uw/15.4

q
with q = 1.93λ−0.04
and a = (14.4λ + 5.5)ψha/λ.
The units and symbols used here are:
σ 0(H), σ 0(V )
reﬂectivity for H and V polarizations, dBm2/m2
ha
average wave height, m (ha ∼= 4.52 × 10−3U 2.5
w )
λ
radar wavelength, m
Uw
wind velocity, m s−1
ψ
grazing angle, rad (0.1 ≤ψ ≤10◦)
φ
look direction relative to wind direction, rad
Radar performance is often speciﬁed in terms of sea state and a useful relationship between sea state,
s, and wind speed for a fully developed sea is:
Uw = 3.16s0.8.
(11.34)
Figures 11.12 and 11.13 show examples, using the GIT model, of σ 0(V ) and σ 0(H) as a function of
sea state and grazing angle, for the radar looking cross-wind and radar frequency 10 GHz (using Eq.
(11.32)).
It may be noted that the values of normalized reﬂectivity given by the GIT model are signiﬁcantly
different from some of the values given in [1], especially at low grazing angles. This is not surprising,
given that the models were derived from different data sets, and reﬂects the wide variation of values
that may be encountered for nominally similar conditions.
0.2
0.5
1
2
5
10
- 60
- 50
- 40
- 30
- 20
SS1
SS2
SS3
SS4
SS5
SS6
Grazing angle, degrees
σ°, dB m2/m2
FIGURE 11.12
GIT model: σ 0(V ) as a function of grazing angle for sea states 1–6, for the radar looking cross-wind and
radar frequency 10 GHz.

532
CHAPTER 11 Radar Clutter Modeling and Analysis
0.2
0.5
1
2
5
10
- 60
- 50
- 40
- 30
- 20
SS1
SS2
SS3
SS4
SS5
SS6
Grazing angle, degrees
σ , dB m2/m2
FIGURE 11.13
GIT model: σ 0(H) as a function of grazing angle for sea states 1–6, for the radar looking cross-wind and
radar frequency 10 GHz.
2.11.2.2.2
Sea clutter amplitude statistics
Observation of the returns from the sea surface has identiﬁed two distinct components of the ampli-
tude ﬂuctuations. The ﬁrst is a spatial variation, the texture, often associated with the sea swell. This
represents a spatial and longer-term temporal variation of the local mean clutter level. This compo-
nent de-correlates only slowly with time and is not affected by radar frequency agility. The second
is a speckle component, associated with scattering from multiple scatterers in a given range cell. The
speckle component de-correlates with time due to relative motion of the scatterers or due to changes in
radar frequency.
These characteristics are shown in Figures 11.14 and 11.15 [25], which show recordings of radar sea
clutter data, with a radar operating in X band (9 GHz), with a 1.2◦antenna beamwidth and 4.2 m range
resolution.
Figure 11.14 shows range-time intensity plots of returns for a range interval of 800 m and a period of
125 ms, with a PRF of 1 kHz. The radar range was 5 km and the grazing angle was 1.5◦. The upper part
of the ﬁgure shows ﬁxed frequency returns. At a given range the returns exhibit a correlation time of
∼10 ms. The underlying swell pattern is clearly visible. The lower ﬁgure shows frequency agile returns.
Now returns at each range are decorrelated from pulse to pulse but the swell pattern is not affected.
In Figure 11.15, the ﬂuctuating component (speckle) has been reduced by adding successive pulses.
After 60 s the polarization changes from VV to HH. The VV POL returns show a clear swell-like
component while the HH POL returns show short lived (∼1 s) clutter “spikes” which still appear to
be associated with the swell peaks. It may also be noted that the overall mean level of the HH returns
appears to be lower than that of the VV returns, evidence of a lower reﬂectivity, σ 0.
Using data of the type shown in Figure 11.15, it has been shown [10] that the distribution of the local
mean power ﬁts well to the Gamma distribution. The local scattering (at a given range in Figure 11.14)
has Gaussian statistics, resulting in the envelope of the overall return having the compound form of
the K distribution (11.10). An empirical model for the dependence of the shape parameter ν on radar,

2.11.2 Clutter Modeling
533
0
800m
range
0
125
time, ms
0
125
time, ms
FIGURE 11.14
Range-time intensity plots of sea clutter; upper plot shows returns from a ﬁxed frequency radar and lower plot
shows returns with pulse-to-pulse frequency agility. Reproduced with permission from [25], © The Institution
of Engineering and Technology.
environmental and geometric parameters has been developed through the analysis of experimental data
at X-band (9–10 GHz). The model is [25]:
log10 (ν) = 2
3 log10

φo
gr

+ 5
8 log10

Ac

−kpol −cos

2θsw

3
,
(11.35)
where
φo
gr is the grazing angle in degrees,
Ac is the radar resolved area, m2,
kpol is a polarization dependent parameter (1.39 for VV and 2.09 for HH), and
θsw is the aspect angle with respect to the swell direction.
(The last term is omitted if there is no swell).
There are no known comparable models for the shape parameters of the Weibull and Lognormal distri-
bution models.

534
CHAPTER 11 Radar Clutter Modeling and Analysis
0
60
120
0
600
range, m
time, (seconds)
V POL
H POL
FIGURE 11.15
Range-time intensity plot of sea clutter averaged over 250 successive pulses to reduce the speckle com-
ponent, revealing the underlying mean level. After 60 s, the radar was switched from vertical to horizontal
polarization. Reproduced with permission from [25], © The Institution of Engineering and Technology.
2.11.2.2.3
Sea clutter Doppler spectrum
The Doppler spectrum of sea clutter varies with environmental condition, just as do the values of σ 0
and the amplitude statistics. A useful simple low grazing angle model [40] for the shape of the average
clutter velocity spectrum upwind at a given wind speed Uw is a Gaussian shape with a mean velocity
of mv and standard deviation of σv given by (in m s−1)
m(V V )
v
= 0.25 + 0.13Uw,
m(H H)
v
= m(V V )
v
+ 0.185,
σv = m(V V )
v
,
(11.36)
where (VV) and (HH) denote the values for vertical and horizontal polarizations, respectively. This
model can be applied to Eq. (11.23) with mf = 2mv
λ
and σ f = 2σv
λ .
There are many observations from data that can be used to improve this simple model. As the
radar scans away from upwind, the mean velocity changes approximately proportionately with the
view direction component of the wind vector, while the standard deviation remains approximately
unchanged. The shape of the spectrum is skewed somewhat in the direction of the wind, and the shape
varies in a complicated manner as the local mean power in the compound K distribution changes
[41,42]. This is dependent on polarization and sea conditions. It causes the shape parameter of the
magnitude distributions in individual frequency ﬁlters (after Doppler radar processing) to vary with
frequency [10,42,43], thus causing difﬁculties for false alarm rate control in Pulsed Doppler and MTI
radar systems. More research is needed to develop quantitative models to characterize these effects.
2.11.2.3 Ground clutter
Land (or ground) clutter is the most difﬁcult to characterize of the common clutter categories. It can
rarely be described as spatially uniform except perhaps for local regions of woods, open ﬁelds or desert.

2.11.2 Clutter Modeling
535
Almost invariably there are abrupt changes in clutter due to natural or man-made boundaries (river banks,
hedges, edges of woods, etc.), signiﬁcant local variation in ground slope and many isolated discrete
scatterers (rocks, isolated trees, pylons, buildings). Urban environments are particularly complex, as
might be expected.
For modeling convenience and mathematical tractability ground clutter is often modeled quite simply
as uniformly distributed scatters over a “ﬂat” earth. Of course, amplitude statistics over large areas of
land are most unlikely to be described by single Gaussian statistics with a steady backscatter power. If
the backscatter coefﬁcient is taken as representing the global mean backscatter, amplitude distributions
such as the K-distribution or Log-Normal distribution are often used to ﬁt to measured data. More
detailed modeling of backscatter from land usually requires modeling of speciﬁc sites. An excellent
reference for a very detailed exposition of the nature and statistics of land clutter has been written in
[32]. Further useful sources of data are to be found in [2,33,44–47].
2.11.2.3.1
Empirical models of σ 0 for land clutter
Normalized clutter RCS, σ 0, at low grazing angles
At low grazing angles the returns from land clutter become very spiky. Shadowing due to terrain height
variations and cultural featuresbecome very marked. Under these conditions, it becomes very difﬁcult to
distinguish between spiky distributed clutter and discrete scatterers, whether man-made or natural. An
excellent source of empirical measurements is the work at the MIT Lincoln Laboratory by Billingsley
and others [32]. This has resulted in a very large database of land clutter data for a wide variety of terrain
at low grazing angles. Measurements were made at 42 sites across North America at frequencies ranging
from VHF (167 MHz) to X-band (9.2. GHz). Range resolutions of 150 m and either 36 m or 15 m were
used, with both vertical and horizontal polarizations. However, Billingsley reported that variations in
reﬂectivity due to polarization and resolution were small (1–2 dB). Because of the difﬁculty of deﬁning
the local grazing angle in uneven terrain, the depression angle from the radar was recorded, taking into
account the earth curvature but not the effect of local terrain slope. Billingsley reported that for very
low grazing angles, where masking occurs, the amplitude statistics can be represented by the Weibull
PDF. At higher grazing angles, with less masking, the clutter backscatter increases and for depression
angles above about 6◦the clutter can be represented by a Rayleigh PDF.
Another useful empirical model was developed at the Georgia Institute of Technology [48]. This
model provides an empirical ﬁt to clutter reﬂectivity for a range of different terrains and radar
frequencies:
σ 0 = 10 log
	
a(ψ + C)B
exp

−
D

1 + 0.1 σh
λ


,
(11.37)
where
ψ is the depression angle in degrees,
σh is the standard deviation of the surface roughness in cm,
λ is the radar wavelength,
A, B, C, and D are empirically derived constants.
Table 11.4 shows values of the parameters A, B, C, and D given in [48].

536
CHAPTER 11 Radar Clutter Modeling and Analysis
Table 11.4 Parameter Values for Land Clutter Mode [48]
Terrain Type
A
B
C
D
Frequency (GHz)
15
9.5
5
3
All
All
All
Soil, sand, and rocks
0.05
0.025
0.0096
0.0045
0.83
0.0013
2.3
Grass and crops
0.079
0.039
0.015
0.0071
1.5
0.012
0.0
Trees
0.019
0.003
0.0012
0.00054
0.64
0.002
0.0
Urban
2.0
2.0
0.779
0.362
1.8
0.015
0.0
Normalized clutter RCS—medium grazing angles
At medium grazing angles, more measurements of clutter are available, although ground truth is often
difﬁcult to obtain. It has been found that in the “plateau region” of backscatter (see Figure 11.11), the
clutter reﬂectivity is approximately proportional to the sine of the grazing angle, φgr (see Figure 11.2)
leading to clutter normalized RCS being deﬁned in terms of a parameter γ
γ =
σ ◦
sin

φgr
.
(11.38)
Typical values of γ have been reported by Barton [33], as summarized in Table 11.5.
Other empirical models for land clutter can be found in [46–49].
2.11.2.3.2
Empirical models of Doppler spectra for land clutter
Billingsley [32] has developed an empirical model for the Doppler spectrum of ground clutter. This is
discussed in detail in Section 2.11.3.2.
2.11.2.4 Rain clutter
Backscatter from rain and other precipitation, such as hail and snow, can have a signiﬁcant effect on
radar performance. In addition, for frequencies signiﬁcantly above 9 GHz the attenuation of the radar
signal can be considerable. A useful summary of the effects of precipitation and weather on radar is
given by Nathanson [1].
Table 11.5 Typical Values of γ for Different Types of Terrain
Terrain
Mean γ (dB m2/m2)
Mountains, urban
−5
Wooded hills
−10
Rolling hills
−12
Farmland, desert
−15
Flatland
−20

2.11.2 Clutter Modeling
537
As with other types of clutter, some progress has been made with theoretical modeling of electro-
magnetic scattering but in general radar designers resort to empirical models of precipitation clutter.
2.11.2.4.1
Atmospheric attenuation
A detailed description of the attenuation of radar signals by the atmosphere has been provided by Blake
[50]. Atmospheric attenuation varies with altitude, radar frequency and humidity. The references give
typical ﬁgures for attenuation through the whole troposphere, attenuation over paths at sea level and so
on. A simple rule of thumb for two-way atmospheric attenuation, α, at sea level for a frequency f GHz
is given by:
α = 10−2 f 0.3 dB/km two-way.
(11.39)
2.11.2.4.2
Rain attenuation
Rainfallisusuallyspeciﬁedintermsofarainfallrate,r,withthevaluesfordifferentlevelsofprecipitation
are given by Nathanson [1]:
Drizzle
r = 0.25 mm/h
Light Rain
r = 1.0 mm/h
Moderate Rain r = 4.0 mm/h
Heavy Rain
r = 16.0 mm/h
Excessive rain
r = 40.0 mm/h
Theattenuationthroughrainisdifﬁculttocalculatetheoretically,notleastbecauseconditions(humid-
ity, drop size distribution and so on) can vary considerably for a nominal rainfall rate. Rainfall rates
also vary with altitude and spatially across a given rainstorm. Again Nathanson [1] gives useful rules
of thumb. The diameter, D, of a rainstorm can be represented by
D = 41.60 −23.62 log10 (r) km
(11.40)
and if the rainfall rate at ground level is rs, the rate rh at height h km, is given by:
rh/rs = exp
	
−0.2 h2
.
(11.41)
The attenuation of two-way radar signals through rain is approximated by:
α = 3.7×10−4f 1.85
(dB/km)/(mm/h).
(11.42)
2.11.2.4.3
Theoretical and empirical model for rain reﬂectivity
Backscatter from rain can be modeled as scattering from multiple spheres. This is generally valid for
small raindrops and theoretical models can be used to predict reﬂectivity, within their limits of validity.
For higher rainfall rates (larger drops) these assumptions may no longer be valid and again the radar
designer will resort to empirical models. For Rayleigh scattering from spherical drops (π D/λ < 1),
the volume reﬂectivity can be expressed as [2]:
η =

N
π5|K|2D6
λ4
,
(11.43)

538
CHAPTER 11 Radar Clutter Modeling and Analysis
Table 11.6 Rainfall Reﬂectivity
Rainfall
Probability of
Reﬂectivity, η, (dB m2/m3)
Rate,
Occurrence
(mm/h)
in UK (%)
L-band,
S-band,
C band,
X-band,
Ku -band,
Ka-band,
1.25 GHz
3.0 GHz
5.6 GHz
9.3 GHz
24 GHz
35 GHz
0.25
5
−102
−91
−82
−64
−57
1
2.5
−107
−92
−81.5
−72
−54
−47
4
1
−97
−83
−72
−62
−46
−39
16
0.1
−73
−62
−53
−32
where D is the drop diameter, N is the number of drops, λ is the radar wavelength and K ≈0.95,
dependent on the dielectric constant and λ. It is found that
Z =

N
D6 ≈200r1.6
mm6/m3,
(11.44)
where r is the rainfall rate in mm/h.
Empirical values for rain reﬂectivity are given by Nathanson [1], Currie [48], and Skolnik [2]. As
an example, Table 11.6 shows some typical values of reﬂectivity given in [1]. Also shown in this table
are values for the probability of different rainfall rates occurring, which is useful information when
designing a radar for a particular application. The probabilities given in Table 11.6 are for the UK and
values for other areas of the world can be found in [1].
2.11.2.4.4
Rain Doppler spectrum
The spectrum of wind-driven rain is of particular interest to radar designers. For radar meteorologists
it provides detailed information on weather patterns. For weather avoidance radar on aircraft, Doppler
provides important information on wind shear and other dangerous conditions.
A good discussion of the Doppler spectrum of rain is given in [1] and this is summarized here. The
velocity spectrum and equivalent Doppler spectrum of rain clutter are conveniently modeled as having a
Gaussian shape, with a standard deviations σv m s−1 and σ f Hz (σ f = 2σv/λ), respectively. The spec-
trum of rain clutter is found to derive from various physical mechanisms, of which the principle ones are:
•
Wind shear, σshear, caused by the variation of wind speed with height.
•
Beam broadening, σbeam, caused by the variation in the radial velocity component of velocity across
the radar beam.
•
Turbulence, σturb, caused by turbulent atmospheric effects.
•
Fall velocity distribution, σfall, caused by variations in raindrop fall velocities.
On the assumption that these spectral components are independent, the total velocity spectrum width
can be given as:
σ 2
v = σ 2
beam + σ 2
turb + σ 2
fall + σ 2
shear.
(11.45)

2.11.3 Radar Clutter Analysis
539
Wind Velocity
Velocity Gradient
(wind shear)
θel
υ + Δυ
υ
FIGURE 11.16
Wind shear.
Figure 11.16 illustrates how wind shear contributes to variations in Doppler shift across the radar
beam. Wind shear causes a change in wind velocity with height, which can be approximated as a
constant velocity gradient with zero velocity at ground level. Across the elevation beam of a ground-
based antenna there will be a linear change of radial velocity, v, which for low elevation angles will
equal the difference in horizontal wind speeds. For a Gaussian shaped beam:
σshear = 0.6 kRθel,
(11.46)
where k is the shear gradient (typical value 4 m s−1 km−1), R is the range to the radar and θel is the
one-way 3 dB elevation beamwidth.
For altitudes up to about 3 km, σturb ≈1 m s−1. Beam broadening is due to tangential velocity
variation across the antenna in azimuth and
σbeam = 0.6v0θaz sin θr,
(11.47)
where v0 is the tangential wind velocity at the beam centre, θaz is the one-way antenna azimuth 3 dB
beamwidth, and θr is the azimuth angle relative to the wind direction at the beam centre. σbeam is usually
only a small component of the spectrum.
Finally, the distribution of vertical velocity amongst the raindrops will cause a spread in the velocity
spectrum. A typical spread of vertical velocities is about 1 m s−1 so that at an elevation angle φ we
have
σfall = 1.0 sin φ.
(11.48)
2.11.3 Radar clutter analysis
For the effective application of theoretical models as presented in the previous Sections it is necessary
to test their ﬁt with real data using different radar parameters and environmental conditions. We have
seen that a number of families of distributions can be used to ﬁt the observed amplitude statistics
over a wide range of conditions, including the log-normal, the Weibull and, especially, the compound-
Gaussian model. The main goal of this section is to describe the statistical analysis performed on
different experimental data of sea and land clutter, to comment on possible results and on the limitations
of theoretical models in some conditions.

540
CHAPTER 11 Radar Clutter Modeling and Analysis
2.11.3.1 Sea clutter
Most of the results shown in this paragraph on sea clutter relate to the statistical analysis performed on
the data recorded by IPIX radar during two campaigns, located in Dartmouth in 1993 and in Grimsby
in 1998 [15,41,51]. Further extensive work on the modeling of sea clutter and the associated methods
used for the statistical analysis of radar data are given in [25].
IPIX is an X-band (9.4 GHz) experimental instrumentation class radar, capable of dual polarized
and frequency agile operation. During the ﬁrst campaign, the radar site was located on a cliff facing the
Atlantic Ocean, at a height of 100 ft above mean sea level and had an open view of about 130◦. During
the second campaign it was on the shore of Lake Ontario, East of the “Place Polonaise” at Grimsby,
between Toronto and Niagara Falls Ontario, looking at Lake Ontario from a height of 20 m.
The data of Dartmouth are stored as 8 bits integers. For the second campaign, the radar was upgraded
to a dynamic range of 10 bits (instead of 8 bits), so that strong target and weak clutter signals could be
observedsimultaneouslywithoutclippingorlargequantizationerror.Therearealwayslike-polarizations,
HH and VV (Lpol) and cross-polarizations, HV and VH (Xpol), coherent reception, leading to a quadru-
plet of in-phase and quadrature values for Lpol and Xpol (see Table 11.7).
For the results shown in the following, the clutter data were collected during the Grimsby campaign.
Many ﬁles with different range resolutions and recorded in different days have been analyzed [51], but
here we summarize the results relating to only ﬁve ﬁles recorded on February 4, 1998 at about 22.30 h
(local time) as representative of most of the results obtained from all the processed data. Unfortunately,
there is no available information about the wind and wave observations for these datasets. The relevant
parameters are summarized in Tables 11.8a and 11.8b.
It is important to observe that in each ﬁle the range resolution is different, with data collected at 60 m,
30 m, 15 m, 9 m, and 3 m range resolution. The analysis here is aimed at highlighting the differences
in clutter characteristics due to the change in the resolution.
The IPIX receiver has two operational modes depending upon the selected RF pulse width (PW).
When the system was operating with PW ≥200 ns, a 5 MHz ﬁlter was used to limit the receiver
bandwidth to approximately 5 MHz. When PW < 200 ns this ﬁlter was by-passed, so the bandwidth of
Table 11.7 Characteristics of the IPIX Radar During the Grimsby Campaign
Transmitter
Receiver
Parabolic Dish Antenna
TWT peak power: 8 kW
Two receivers
Diameter: 2.4 m
Dual
frequency
simultaneous
transmission: 8.9–9.4 GHz
Outputs: Linear, I and Q
Pencil beam width (azimuth
resolution):1.1◦
H-V polarization, agile
Receiving polarizations: H-V
Antenna gain: 45.7 dB
Pulse width (PW): 20–5000 ns
(real) 5000 ns (expanded) 32 ns
(compressed)
Dataacquisition : Sample
rate from 0 to 50 MHz
Outputs: Linear, I and Q
Quantization:10 bit
Cross polarization isolation:
30 dB
PRF: from 0 to 20 kHz
Double polarization with cen-
tral feeder

2.11.3 Radar Clutter Analysis
541
Table 11.8a Characteristics of the Analyzed Files, Grimsby Campaign
Name of the
19980204_223753_
19980204_220849_
19980204_223220_
Data Set
ANTSTEP
ANTSTEP
ANTSTEP
Date, time of acquisition
02/04/1998 22:37:53
02/04/1998 22:08:49
02/04/1998 22:32:20
# Range cells
28
28
28
Start range
3201 m
3201 m
3201 m
Range resolution
60 m
30 m
15 m
Pulse width
400 ns
200 ns
100 ns
Total # sweep
60,000
60,000
60,000
Sample for cell
60,000
60,000
60,000
Sampled at 60 m
Sampled at 30 m
Sampled at 15 m
PRF
1 kHz
1 kHz
1 kHz
Frequency RF
9.39 GHz
9.39 GHz
9.39 GHz
Radar and wave geometry
N 
S
N 
S
N 
S
the receiver was about 50 MHz to match the minimum 20 ns pulse width. Therefore, for data collected
with PW < 200 ns, the receiver thermal noise level is about 10 dBs higher than for data collected with
PW ≥200 ns [52]. In the following ﬁgures the amplitude of the clutter is expressed in Volt (V).
2.11.3.1.1
Statistical models of clutter amplitude
As already said, many distributions are described in the literature to model the amplitude probability
density function (PDF) of high-resolution non-Gaussian clutter. Here we compare the empirical PDF
with lognormal (LN), Weibull (W), K, and Generalized K (GK) and Generalized K with lognormal
texture (LNT) PDFs whose expressions are given in Section 2.11.2.1.3.
The characteristic parameters of the theoretical PDFs can be estimated by the classical method
of moments (MoM) [53], which consists of equating experimental moments with the corresponding
theoretical moments. The estimated moments are given by:
ˆm R(n) = 1
NS
NS

i=1
|z(i)|n.
(11.49)
For the data at hand, Ns = 60, 000 samples have been processed for each range cell.

542
CHAPTER 11 Radar Clutter Modeling and Analysis
Table 11.8b Characteristics of the Analyzed Files, Grimsby Campaign
Name of the Data Set
19980204_224024_ANTSTEP
19980204_223506_ANTSTEP
Date, time of acquisition
02/04/1998 22:40:24
02/04/1998 22:35:06
#Range cells
28
27
Start range
3201 m
3321 m
Range resolution
9 m
3 m
Pulse width
60 ns
20 ns
Total # sweep
60,000
60,000
Sample for cell
60,000 Sampled at 9 m
60,000 Sampled at 3 m
PRF
1 kHz
1 kHz
Frequency RF
9.39 GHz
9.39 GHz
Radar and wave geometry
N 
S
N 
S
Range resolutions of 60 m, 30 m, and 15 m
The results of the statistical analysis by means of histograms and estimated moments reveal that the GK-
PDF yields a good ﬁt for both co- and cross-polarized data and for all the three resolutions. Therefore, the
analyzed clutter process can be accurately modeled by a compound-Gaussian process with Generalized
K-PDF, provided that the size of the range resolution cell is greater than or equal to 15 m (note that the
Gaussian model is a particular case of the Generalized K model).
In Figures 11.17 and 11.18, we report the histogram and the moments for the 15th range cell, VV
data, and 60 m range resolution. The numerical results for the other range cells and the two other range
resolutions are very similar [51].
In Table 11.9 we report the mean values of the parameters estimated for each theoretical PDF. The
results show that, for a resolution of 60 m, on the average, the HH component is spikier (¯c = 1.226)
than both VV (¯c = 1.293) and VH (¯c = 1.292) components.1 Moreover, the parameters estimated when
the range resolution is 30 m (Table 11.10) show that the data are spikier at 30 m range resolution than
at 60 m; this was found for all polarizations. The results show also that VV data (¯c = 1.094) and VH
data (¯c = 1.093) are spikier than HH data (¯c = 1.218).
For the range resolution of 15 m and for co-polarizations generally the GK-model provides a good
ﬁt to the data. The values of the estimated parameters conﬁrm that the clutter gets spikier when range
1Results for different polarizations can be compared with respect to the mean value (¯c) of the estimates ˆc of parameter c of
the Weibull distribution, because the meaning of this parameter is quite easy to understand.

2.11.3 Radar Clutter Analysis
543
0.1
1
10
100
0
0.01
0.02
0.03
0.04
0.05
0.06
0.07
0.08
Histo
W
LN
K
LNT
GK
PDF
Amplitude (V)
FIGURE 11.17
Clutter amplitude PDF, VV polarization, 15th range cell, 60 m.
1
10
100
1000
1
2
3
4
5
6
Data
W
LN
K
LNT
GK
Normalized Moments
Order
FIGURE 11.18
Normalized clutter moments, VV polarization, 15th range cell, 60 m

544
CHAPTER 11 Radar Clutter Modeling and Analysis
Table 11.9 Estimated Parameters, 60 m
Cell
W
LN
K
LNT
GK
ˆc
ˆb
ˆσ
ˆδ
ˆν
ˆμ
ˆσ 2
ˆm
ˆν
ˆμ
ˆb
VV -15th
1.391
0.014
0.652
0.010
1.331
1.268e−4
0.736
8.760e−5
5.500
2.798e−5
0.461
mean
1.293
0.021
0.695
0.015
1.119
4.718e−4
1.020
2.694e−4
20.57
2.604e−4
0.427
HH-15th
1.324
0.016
0.677
0.012
1.122
1.671e−4
0.867
1.083e−4
6.010
1.888e−5
0.408
mean
1.226
0.022
0.722
0.016
0.927
4.162e−4
1.133
2.210e−4
15.55
2.758e−4
0.428
HV -15th
1.386
0.014
0.654
0.011
1.316
1.321e−4
0.744
9.106e−5
5.341
3.123e−5
0.465
mean
1.292
0.021
0.695
0.016
1.117
4.179e−4
0.980
2.330e−4
19.70
2.734e−4
0.430

2.11.3 Radar Clutter Analysis
545
Table 11.10 Estimated Parameters, 30 m
Mean
W
LN
K
LNT
GK
ˆc
ˆb
ˆσ
ˆδ
ˆν
ˆμ
ˆσ 2
ˆm
ˆν
ˆμ
ˆb
VV
1.094
0.015
0.791
0.011
0.681
2.331e−4
1.573
1.033e−4
12.80
1.946e−4
0.436
HH
1.218
0.005
0.729
0.003
0.944
1.701e−5
1.182
8.966e−6
29.77
8.766e−6
0.335
HV
1.093
0.016
0.792
0.011
0.678
2.468e−4
1.577
1.094e−4
12.28
2.061e−4
0.437

546
CHAPTER 11 Radar Clutter Modeling and Analysis
Table 11.11 Estimated Parameters, 15 m
Mean
W
LN
K
LNT
GK
ˆc
ˆb
ˆσ
ˆδ
ˆν
ˆμ
ˆσ 2
ˆm
ˆν
ˆμ
ˆb
VV
0.933
0.029
0.895
0.021
0.466
0.001
2.309
3.450e−4
3.602
0.001
0.459
HH
0.874
0.024
0.935
0.017
0.383
9.364e−4
2.592
2.305e−4
3.281
9.979e−4
0.474
HV
1.018
0.011
0.840
0.008
0.592
1.424e−4
1.905
5.198e−5
3.845
1.078e−4
0.467

2.11.3 Radar Clutter Analysis
547
resolution increases (i.e., the size of the resolution cell decreases). We can also notice that on the average
HH data are spikier (¯c = 0.874) than VV data (¯c = 0.933) and VH data (¯c = 1.018); the same happens
for the 15 m resolution data (see Table 11.11).
Range resolutions of 9 m and 3 m
Examining the histograms obtained by analyzing the ﬁle at a resolution of 9 m, it is possible to see that
many cells of co-polarized data exhibit heavy-tails and none of the proposed models yields a good ﬁt
to the data. One of these cells is the ﬁfth, plotted in Figure 11.19 for VV and HH data. This problem
could be due to a non-Gaussian distribution of the speckle because of the very high range resolution.
On the contrary, in [51] it was observed that for cross-polarizations, the clutter process can still be
accurately modeled by a compound-Gaussian process with Generalized K-PDF. Again, the values of
the estimated parameters show that HH data have the spikiest behavior (HH: ¯c = 0.991, VV: ¯c = 1.099,
VH: ¯c = 1.175, see Table 11.12).
The results obtained for co-polarizations at a range resolution of 3 m do not show signiﬁcant differ-
ences with respect to the results obtained at 9 m. Conversely, the analysis for VH polarization presents
some difference. There are cells showing histograms with tails longer than the average length recorded
at lower resolutions; in this case the compound model cannot be used to model clutter data.
The estimates of the parameters are reported in Table 11.13. The results show again that HH data
(¯c = 1.307) are spikier than VV (¯c = 1.417) and VH (¯c = 1.542) data. With respect to the other
resolutions estimated values of ¯c are slightly higher, probably because of the effect of added thermal
noise.
10-2
10-1
100
101
102
0
0.1
0.2
0.3
0.4
0.5
0.6
Histo
W
LN
K
LNT
GK
PDF
Amplitude (V)
10-2
10-1
100
101
102
0
0.1
0.2
0.3
0.4
0.5
0.6
PDF
Amplitude (V)
FIGURE 11.19
Clutter amplitude PDF, VV (upper) and HH (lower) polarizations, ﬁfth range cell, 9 m.

548
CHAPTER 11 Radar Clutter Modeling and Analysis
Table 11.12 Estimated Parameters, 9 m
Cell
W
LN
K
LNT
GK
ˆc
ˆb
ˆσ
ˆδ
ˆν
ˆμ
ˆσ 2
ˆm
ˆν
ˆμ
ˆb
VV -5th
0.585
0.021
1.207
0.016
0.129
0.002
4.861
2.032e−04
0.216
0.005
0.638
mean
1.099
0.028
0.806
0.020
0.781
8.523e−4
1.732
3.261e−4
35.69
4.025e−4
0.227
HH-5th
0.548
0.015
1.261
0.011
0.108
0.002
5.395
1.041e−4
0.147
0.003
0.727
mean
0.991
0.021
0.868
0.015
0.564
5.852e−4
2.150
1.825e−4
22.59
3.777e−4
0.278
HV -5th
0.626
0.007
1.153
0.005
0.154
2.085e−4
4.352
2.367e−5
0.459
2.680e−4
0.478
mean
1.175
0.009
0.765
0.007
0.957
8.157e−5
1.461
3.578e−5
33.01
3.832e−5
0.259

2.11.3 Radar Clutter Analysis
549
Table 11.13 Estimated Parameters, 3 m
Mean
W
LN
K
LNT
GK
ˆc
ˆb
ˆσ
ˆδ
ˆν
ˆμ
ˆσ 2
ˆm
ˆν
ˆμ
ˆb
VV
1.417
0.038
0.668
0.028
2.621
0.001
0.889
6.470e−4
59.17
1.997e−6
0.148
HH
1.307
0.027
0.709
0.019
1.588
5.580e−4
1.118
3.071e−4
54.83
2.672e−6
0.139
HV
1.542
0.009
0.619
0.006
3.960
4.550e−5
0.608
3.284e−5
63.98
2.01e−10
0.148

550
CHAPTER 11 Radar Clutter Modeling and Analysis
Table 11.14 Probability of Type I Error (1 −α), KS Test, Seventh Range Cell, VV Data, 9 m
W
LN
K
GK
LNT
52%
0%
51%
33%
0%
Kolmogorov-Smirnoff (KS) goodness-of-ﬁt test
The statistical analysis of clutter amplitude can be completed by applying the Kolmogorov-Smirnoff
(KS) goodness-of-ﬁt test. This test is largely used to determine which distribution provides the best ﬁt
to the data. Unfortunately in some cases, it is not useful in distinguishing between different long-tailed
models, because it places an equal importance on all regions in the probability space. Therefore, in the
heaviest part of the PDF, i.e., the most affecting the results of the test, the “bell” area or the body of the
PDF, many of the tested PDF are very similar.
The test is characterized by the probability of Type I error α. The type-I error is the probability of
observing under H0 a sample outcome at least as extreme as the one observed and hence provides the
smallest level at which the observed sample statistic is signiﬁcant. [54]. Roughly speaking, α represents
the probability of having an error if we reject the null hypothesis (empirical distribution equal to theoret-
ical distribution). If this probability α is very low, say less than 1%, the hypothesis H0 can be rejected.
For resolutions of 60 m and 30 m, for all the tested models, the probability α is in the range of
95–99%. Some differences were found at higher resolutions. The results of the KS test for this cell are
summarized in Table 11.14. For resolution higher than 30 m (i.e., values <30 m), the KS test provides
the lowest probability of Type I error α generally for the LN distribution.
Summarizing, for low grazing angle and range resolution values >15 m, moments and histogram
analysis generally conﬁrm that the K and GK models provide a good ﬁt to the data for both like and
cross-polarizations (see also [55]). The HH data are spikier than VV for almost all the resolutions. For
range resolution values ≤15 m, the compound-Gaussian model starts failing and in some range cells
the data histogram shows long tails that are not well modeled with any of the tested PDFs.
2.11.3.1.2
Cumulant domain analysis
Toperformadditionalanalysisofthecompound-Gaussianmodelandtoinvestigatewhetherthedeviation
from the theoretical models in the highest two resolutions, i.e., 9 m and 3 m, may be due to the presence
of non-negligible thermal noise, we can apply the theory of cumulants2 [56]. It is widely known in the
literature that cumulants of order greater than two for a Gaussian process are identically zero [57,56].
Thus, if we consider the clutter process z(i) = y(i) + v(i), where v(i) is a Gaussian process and y(i)
is a non-Gaussian process, independent of v(i), we have:
cz
k(l1,...,lk−1) = cy
k (l1,...,lk−1) + cv
k(l1,...,lk−1) = cy
k (l1,...,lk−1),
for k > 2,
(11.50)
so the cumulants of y(i) can be derived from the cumulants of z(i), that is, the only contribution in
the cumulants of the overall process is that of the non-Gaussian component. In our case the in-phase
2For the deﬁnition of cumulants and their relation with the moments see [56]. Particularly, for real processes
x(n)cx
k

l1,...,lk−1

= E {x(n)x(n + l1), . . . , x(n + lk−1)}.

2.11.3 Radar Clutter Analysis
551
(I) and quadrature (Q) components of the thermal noise are zero-mean Gaussian processes, then only
non-Gaussian clutter contributes to the cumulants of order k > 2 of the observed complex data.
In [51] the authors estimated from the data the second, third, and ﬁfth order normalized cumulants
at zero-lags, i.e., for l1 = l2 = · · · = lk−1 = 0 whose deﬁnition is:
μk = cI
k(0, 0, . . . , 0)
(cI
2(0))k/2
= cQ
k (0, 0, . . . , 0)
(cQ
2 (0))k/2
,
(11.51)
where superscripts I and Q refer to the in-phase and quadrature components, i.e., the real and imaginary
parts of the complex data. Then the estimates have been compared with the (normalized) theoretical
cumulants of the compound-Gaussian model calculated at zero-lags. All the theoretical cumulants of
the compound-Gaussian model of odd order calculated at the origin are equal to zero since the PDF of
a complex compound-Gaussian process is symmetric with respect to the mean value (zero, in our case).
In Figures 11.20 and 11.21 we show the normalized cumulants μ3 and μ5 versus the second order
cumulant for the resolutions of 9 m and 3 m, respectively. The results show that at a range resolution
of 9 m the compound-Gaussian model is still accurate for VV and VH data because μ3 and μ5 are
close to zero. Conversely, the ﬁfth order cumulant for HH data shows a large deviation from zero in
most cells. At a range resolution of 3 m, for most cells and all polarizations, the estimated cumulants
deviate signiﬁcantly from zero. This is an indication that the thermal noise, whose contribution is null
in the cumulants of order higher than two, in these cases is not the cause of the deviation from the
compound-Gaussian family.
-1
-0.5
0
0.5
1
0
0.0005
0.001
0.0015
0.002
0.0025
0
0.0005
0.001
0.0015
0.002
0.0025
VV
HH
VH
Norm. 3rd order cumulant
Estimated 2nd order cumulant
-80
-60
-40
-20
0
20
40
60
80
Norm. 5th order cumulant
Estimated 2nd order cumulant
FIGURE 11.20
Normalized third and ﬁfth order cumulants versus second order cumulant, 9 m.

552
CHAPTER 11 Radar Clutter Modeling and Analysis
-1
-0.5
0
0.5
1
0
0.0005
0.001
0.0015
0.002
VV
HH
VH
Norm. 3rd order cumulant
Estimated 2nd order cumulant
-80
-60
-40
-20
0
20
40
60
80
0
0.0005
0.001
0.0015
0.002
VV
HH
VH
Norm. 5th order cumulant
Estimated 2nd order cumulant
FIGURE 11.21
Normalized third and ﬁfth order cumulants versus second order cumulant, 3 m.
2.11.3.1.3
Correlation analysis and power spectrum estimation
As said, the compound-Gaussian clutter model assumes the presence of two components, speckle and
texture, with very different correlation times (some milliseconds for the ﬁrst component and some
seconds for the second one, in X-band). If the two components are statistically independent the overall
autocorrelation function is the product of the autocorrelation functions of the two components [15,58]:
RY (m) = E

y(i)y∗(i + m)

= R√τ(m)RX(m) = 2R√τ(m)

RX I (m) + j RX I X Q(m)

,
(11.52)
(if the speckle is a complex-valued stationary circular process, then RX I (m) = RX Q(m)). In practice,
the decorrelation time of the coherent signal y(i) is equal to that of the faster component [15].
2.11.3.1.4
Estimation of the speckle autocorrelation and cross-correlation sequences
Since the texture can be considered constant over short time intervals, we can estimate the speckle
autocorrelation functions RX I (m) and RX I X Q(m) by using coherent signal samples from such short
intervals with or without overlapping.
ˆRX I (m) = 1
Nb
⎡
⎣
Nb

k=1
1
2N ˆτk
Re
#N−1−m

i=0
yk(i)y∗
k (i + m)
$⎤
⎦,
(11.53)

2.11.3 Radar Clutter Analysis
553
-1
-0,5
0
0,5
1
0
5
10
15
20
25
30
Re
Im 
Speckle corr. coeff.
Time (msec)
60 m
-1
-0,5
0
0,5
1
0
5
10
15
20
25
30
Re
Im
Speckle corr. coeff.
Time (msec)
3 m
FIGURE 11.22
Speckle correlation coefﬁcients, HH polarization ﬁrst range cell.
ˆRX I X Q(m) = 1
Nb
⎡
⎣
Nb

k=1
1
2N ˆτk
Im
#N−1−m

i=0
yk(i)y∗
k (i + m)
$⎤
⎦,
(11.54)
where Nb is the number of data bursts and ˆτk is the estimated value of the texture in the kth burst
ˆτk = N−1
i=0 |yk(i)|2/N where yk(i) = y((k −1)N + i).
Figure 11.22 shows two plots of the real and the imaginary parts of the speckle autocorrelation
function for 60 m and 3 m estimated with N = 128. This result provides a clear indication that for
all resolutions and all polarizations, the speckle correlation time is about 10 ms and the behavior is
oscillatory.
2.11.3.1.5
Estimation of the texture autocorrelation sequence
To check the validity of the hypothesis made on the correlation times of the two components, we can
estimate the texture autocorrelation sequence with the formula:
ˆRτ

Nm/2

= 1
Nb
Nb−|m|

k=1
ˆτk ˆτk+m,
(11.55)
and the texture covariance as
ˆCτ

Nm/2

= 1
Nb
Nb−|m|

k=1
ˆτk ˆτk+m −
⎡
⎣1
Nb
Nb

k=1
ˆτk
⎤
⎦
2
.
(11.56)

554
CHAPTER 11 Radar Clutter Modeling and Analysis
-0.2
0
0.2
0.4
0.6
0.8
1
0
5
10
15
20
HH
VV
Texture correlation coefficient
Time (sec)
FIGURE 11.23
Texture autocovariance function, ﬁrst cell, N = 128, 60 m.
-0.2
0
0.2
0.4
0.6
0.8
1
0
5
10
15
20
Texture Corr. Coeff.
Time (sec)
HH, 1st cell, 15 m
-0.2
0
0.2
0.4
0.6
0.8
1
0
5
10
15
20
Texture Corr. Coeff.
Time (sec)
VV, 8th cell, 3m
FIGURE 11.24
Texture autocovariance function.

2.11.3 Radar Clutter Analysis
555
It is useful to observe that with a 50% of overlap, we can estimate the texture correlation and
covariance every N/2 lags. In the ﬁgures we plot the texture correlation coefﬁcient, that is cτ

Nm/2

=
ˆCτ

Nm/2

/ ˆCτ(0), with N = 128.
Figures 11.23 and 11.24 show the texture correlation coefﬁcient. At the same resolutions and without
differences in the polarizations, the texture correlation time is on the order of seconds. Furthermore,
the texture presents periodicities with a period of 8 s at a range resolution of 60 m and of 3 s at a range
resolution of 30 m. The periodicity is particularly evident in the VV polarized data for the resolution of
60 m in all the analyzed ﬁles. These results show as well that, with increasing resolution, the texture
correlation time decreases, but still in the order of few seconds and the periodicities tend to disappear,
due to the strong contribution of the thermal noise (see Figure 11.24).
Figure 11.25 reports two examples of the average spectrogram in semi-logarithm scale calculated as
P(k) =
1
Nseq
Nseq

r=1
Pr(k) =
1
Nseq
Nseq

r=1
1
Nc

r Nc

i=(r−1)Nc+1
x(i)e−jkn

2
,
k = 1, 2, . . . , Nc,
(11.57)
10-6
10-5
10-4
10-3
10-2
-500 -400 -300 -200 -100
0
100
200
300
400
500
PSD
Frequency (Hz)
HH, 1st cell, 60 m
10-6
10-5
10-4
10-3
10-2
-500 -400 -300 -200 -100
0
100
200
300
400
500
PSD
Frequency (Hz)
VV, 8th cell, 3 m
FIGURE 11.25
Average power spectral density, PSD, CNR ∼= 24 dB and CNR ∼= 4 dB respectively.

556
CHAPTER 11 Radar Clutter Modeling and Analysis
where Nseq is the number of sequences in which the received vector for each cell has been divided, Nc
is the number of samples per sequence, k is the normalized frequency and Pr(k) is the kth sample of
the periodogram of the rth sequence.
In these results, the periodogram shows, for all the polarizations, for all the range resolutions, a peak
located around 150 Hz. Moreover, with a resolution of 60 m and 30 m, most of the analyzed cells show
a bimodal spectrum, particularly evident in HH polarization, and then a second peak near −150 Hz;
the power of the second peak is much lower than the power of the main one (see upper ﬁgure). From
the resolution of 15 m, the IPIX radar seems to add a frequency interfering line in the spectrum at
about −220 Hz (see lower ﬁgure). The line at 0 Hz is due to a residual of the continuous component.
It is evident that, as resolution increases, the thermal noise effect becomes very important. In fact, the
clutter-to noise ratio (CNR) decreases from ∼= 24 dB for a resolution of 60 m and VV data to less than
−5 dB for a resolution of 3 m and VH data. The CNR has been roughly estimated from the spectrum
ﬁgures reading the value of the noise ﬂoor from each ﬁgure and calculating the clutter power as the
difference between the overall disturbance power and the noise power. The values calculated for each
cell is reported in the ﬁgure captions.
2.11.3.1.6
Mean range texture autocovariance sequence
To conclude the correlation analysis, in order to highlight further differences due to the resolution, we
can also calculate the average range autocovariance function of the texture given by
ˆRτ(n) = 1
Nb
Nb

m=1
ˆRτm(n) =
1
NbNc
Nb

m=1
Nc−n

i=1

ˆτm(i) −¯τm
 
ˆτm(i + n) −¯τm

,
(11.58)
where ˆτm(i) is the estimate of the texture on the mth burst of the ith cell, Nc is the number of
illuminated cells, Nb is the number of bursts and ¯τm is the texture average value in the mth burst
¯τm = Nc
i=1 ˆτm(i)/Nc.
Since at 30 m range resolution the illuminated zone is different, we compare here only the results
found at 15 m, 9 m, and 3 m range resolutions.
Figure 11.26 shows the results obtained for VV and HH polarizations. From the ﬁgure it is evident
that with a resolution of 3 m, it is possible to highlight and resolve shorter-range periodicities that are
not visible in the other resolutions in all the polarizations.
2.11.3.1.7
Sea clutter non-stationarity: Bragg scattering and long waves
So far we have considered the sea clutter process as a stationary stochastic process. Actually this is not
true, and the behavior we have proved in the previous paragraphs holds true only “in average.” The
non-stationarity of the sea clutter is due to its nature and some explanation is needed. Sea clutter is
backscattered by a moving rough surface [59,60] characterized in terms of two fundamental types of
waves. The ﬁrst type is represented by capillary waves with wavelengths (λ) on the order of centimeters
or less, the second by the longer gravity waves (sea or swell) with wavelengths ranging from a few
hundred meters to less than a meter [59]. In deep water, for the capillary waves we have λ < 1.73 cm,
whereas for the gravity waves the wavelength is λ > 1.73 cm. Capillary waves are usually generated
by turbulent gusts of near surface wind and their restoring force is the surface tension. On the contrary,

2.11.3 Radar Clutter Analysis
557
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
-100
-50
0
50
100
15 m
9 m
3 m
Correlation coefficient
Range (m)
-0.4
-0.2
0
0.2
0.4
0.6
0.8
1
-100
-50
0
50
100
Correlation coefficient
Range (m)
FIGURE 11.26
Mean range texture auto-covariance, VV polarization and HH polarization.
swells are produced by stable winds and their restoring force is the gravity. Then, at any point on the
surface the waves are complex summations of the locally generated wind waves and waves that have
propagated in from other areas and different directions, resulting in a complex interaction [61].
To take into account the presence of different scales of roughness in the sea surface, Wright [36]
and Bass et al. [37] developed a two-scale model of the sea surface scattering in which the surface
height is partitioned into a large-scale displacement and a small-scale displacement. For this model, it
is assumed that over any patch of the surface that is large compared with small-scale lengths, but small
compared with large-scale lengths, the scattering can be modeled as ﬁrst-order Bragg scattering from
the small-scale structure. Thus, the effect of the large-scale structure is to change the distance between
the antenna and each point of the considered patch, by tilting the surface and advecting the small-scale
structure both vertically and horizontally. The effect of large-scale surface tilt is to introduce an effective
amplitude modulation of the small-scale scattering [62]. Conversely, the effect of the advection is to
inﬂuence the frequency content of the overall scattering.
The Bragg scattering is based on the principle that the return signals from scatterers that are half a
radar wavelength apart, measured along the line of sight from the radar, reinforce each other since they
are in phase [59]. The Bragg resonant length is λB = λ0/

2 cos θ0

where λ0 is the wavelength of the
radar signal and θ0 is the grazing angle. At microwave frequencies, the Bragg scattering is from capillary

558
CHAPTER 11 Radar Clutter Modeling and Analysis
waves and fD ∼= √g/(2πλB, where g is the acceleration of free fall. As a consequence, the capillary
waves approaching and receding in the radar line-of-sight direction give rise to two Bragg spectral lines
located at ± fD, at least in absence of other scattering phenomena and of the long waves. The magnitude
of these lines depends on the azimuth look direction of the radar relative to the wind direction [41].
In a real scenario, the Bragg scatterers are advected by the orbital velocity of the intermediate waves
(waves with wavelengths longer than the Bragg wavelength but shorter than the radar resolution cell)
and of the long waves (waves with wavelengths longer than the radar resolution cell). The sum of
the orbital velocities of the unresolved intermediate scale waves causes a spectral broadening around
the Bragg lines. For many ocean conditions, these orbital motions broaden the Bragg lines by more
than their separation, causing the lines to be unresolved, and generating only one Doppler peak. At
X-band frequencies, this is generally the case [61,63]. Therefore, according to the Bragg theory, long
waves that are resolved by high-resolution radars may be assumed to be constant over each illuminated
cell. Consequently, their effect on the Doppler spectrum is to shift the Doppler peak according to
the long wave orbital velocity. The orbital velocities are given by the simple harmonic motion V0 =
π f H = π H/T , where f is the frequency of the long gravity wave of period T and H is its height
from crest to trough. The contribution of the orbital velocity to the motion of the Bragg scatterers
is the horizontal component, that is VOR = V0 cos (2π f t −K x), where K is the wave number and
x the spatial position [64]. The velocities of the scatterers in the nodes, crests and troughs of the
waves are very different. Finally, an additional Doppler shift results from any surface currents present,
including wind drift. A formula often used to represent this drift is Dw = 0.03Uw, where Uw is the
wind speed. Therefore, by considering the contribution of orbital velocity, current velocity Vc and wind
drift, we can calculate the time-varying instantaneous Doppler shift as (see the picture in Figure 11.27)
fD = 2 cos θ0( ± C0 + VOR + Dw + Vc)/λ0 where C0 is the intrinsic phase speed of the Bragg wave
given by the wave dispersion relation. Due to the periodicity of VOR, fD should be periodic as well.
However, the Bragg scattering is not the only phenomenon determining the clutter return, particularly if
breaking waves are present on the sea surface as clearly showed in [65,66] but it is generally dominant
in down-wind VV data. Therefore, to see clearly the effect of the long waves on the sea return, we show
here in detail some results of the analyses carried out on down-wind VV data [41].
It is worth observing that in the modern statistical sea clutter literature, as already written, the
small-scale structure scattering of the two-scale model corresponds to the speckle ([11,12,15,55]). The
Long waves: VOR 
Current: VC 
Bragg waves: C0 
Wind drift: Dw 
FIGURE 11.27
Different contributions to the surface velocity.

2.11.3 Radar Clutter Analysis
559
variations of the local power, due to the amplitude modulation of the speckle introduced by the tilting
of the small-scale structure correspond to the texture. According to the compound-Gaussian model
the texture and the speckle are two independent processes, the speckle is stationary and the texture
amplitude modulates the speckle. However, as suggested by Haykin et al. [59], and as provided for by
the two-scale model, the relationship between slowly and rapidly time-varying processes is much more
complicated: the slowly varying swell motion does not only modulate the amplitude of the speckle, but
also its mean frequency (Doppler centroid) and its bandwidth [41].
In this section of this tutorial, evidence of the modulating effect of long waves on speckle backscat-
tering is veriﬁed through the analysis of experimental sea clutter data, collected in Dartmouth, Nova
Scotia, at Osborne Head Gunnery Range (OHGR), with the IPIX radar.
The effect of the long waves on the overall scattering has been already considered in literature, but
generally the analyses are theoretical or, when experimental, they consider only the average spectrum,
that is, the spectrum calculated on the entire data set [27,28,61,67]. This kind of analysis can be
exhaustive only when the radar resolution is low. In this case in fact, as explained in [67], the low-
resolution radar performs a spatial averaging over many waves and the radar cannot see the different
features of the waves passing through the resolution cell during the recording. Some evidence of the
long wave and breaking wave amplitude and frequency modulation on the time-varying spectrum of
real sea clutter is presented, for instance, in [59,64,68].
The sea clutter data shown here were collected at Osborne Head Gunnery Range (OHGR) with IPIX
radar during the Dartmouth campaign. The characteristics and acquisition conditions of the analyzed
ﬁle are summarized in Table 11.15. Data from all polarizations were processed, however, in this section
we describe in more details the experimental results relative to the VV polarized data of the ﬁle Starea4
recorded on the 7 November 1993 at 11:23 pm. This dataset was recorded in conditions particularly apt
to reveal the long wave modulating effects (that is our main interest here), both for the fully developed
sea state and for the radar downwind direction. During the time the data was collected, the Canadian
Forecast Service reported that the signiﬁcant wave height was of 2.23 m with an average period of 8.3 s.
The wind was blowing with a speed of 4–15 km/h since 8 pm of 6 November, coming to a relative calm
state (1–3 in the Beaufort scale) after it has been blowing with strong velocity (35–45 km/h) for the
previous 24 h. The wind direction was 280◦from the North since 10 am, and the azimuth angle was
ﬁxed at 134◦from the North (146◦of difference, approximately down-wind). Due to these conditions
in the VV data the Bragg scattering was dominant.
A statistical analysis performed on these data as described in the previous paragraphs, showed that
this clutter is GK distributed [41].
As already stated, the selection of the vertical polarization is justiﬁed because Bragg scattering
was dominant (in the recording conditions of ﬁle Starea4) and the effect of long-waves should be
clear and evident. Figure 11.28 shows the time evolution of the texture, estimated as ˆτ(l) =
(l+1)Lb/2
n=1+(l−1)Lb/2 |y(n)|2/Lb, where l = 1, 2, . . . , NB y(n), is the nth sample of the complex enve-
lope of the data, NB = 2047 is the number of bursts in which the entire sequence of the range cell data
has been divided, Lb = 128 is the number of samples in the lth burst (adjacent bursts have an overlap of
50%). It has been assumed (and veriﬁed) that the texture is constant within each short burst of 0.128 s.
The almost-periodic behavior of the texture is evident for both polarizations.
In the frequency domain, the presence of periodicity in the power, and then of an amplitude mod-
ulating effect of the swells, is evidenced by the time-varying spectrogram in Figure 11.29a, where the

560
CHAPTER 11 Radar Clutter Modeling and Analysis
Table 11.15 Operative Data from OHGR Database [69]. Weather Data from the Canadian
Forecast Service
Data Set Name
Starea4
Date, time of the acquisition
November 7, 1993, 11:23
# range cells
7
Start range
2574 m
Range resolution
30 m
Range acquisition window
210 m
Pulse width
200 ns
Range sample rate
10 MHz
Total # sweeps
262,144
Samples for cell
131,072
PRF (polarization agility)
2 kHz
RF frequency
9.39 GHz
Grazing angle
0.305◦
Azimuth angle (from N)
134◦
Wind direction (from N)
280◦
Approximate look direction
Down-wind
Wind speed
7 km/h (1.94 m s)
Signiﬁcant wave height
2.23 m
Signiﬁcant wave period
8.3 s
Sea state
Fully developed
10-5
10-4
10-3
10-2
10-1
0    10   20   30   40   50   60   70   80   90  100 110 120 130
VV Pol. 
HH Pol. 
Time [sec]
Texture
FIGURE 11.28
HH and VV polarized backscattering mean texture, versus the observation time interval. Dataset: Starea4 of
November 7, range cell 3.

2.11.3 Radar Clutter Analysis
561
1
2
3
4
5
6
7
8
9
10
11
x 10-4
Time [sec]
0
10
20
30
40
50
60
70
80
90
100
110
120
130
-200
-150
-100
-50
0
50
100
150
200
0.02
0.04
0.06
0.08
0.1
0.12
0.14
Time [sec]
Frequency [Hz]
Frequency [Hz]
0
10
20
30
40
50
60
70
80
90
100
110
120
130
-200
-150
-100
-50
0
50
100
150
200
(a)
(b)
FIGURE 11.29
(a, b) VV spectrogram and normalized spectrogram. Starea4 of November 7, range cell 3.
spectrogram is plotted in a linear colormap from blue to red in the frequency range −200 to 200 Hz,
where we have most of the sea clutter contribution (the variability of the sea spectrum was also visible
in Figure11.9. The plots in this ﬁgure were obtained by computing the FFT over a sliding window of
512 samples (0.512 s), weighed by a Hanning window, and with an overlap of 50%. The 512-points
FFT (NF = 512) provides the spectrogram in the frequency range −500 to 500 Hz. It is apparent
that the mean texture and spectrogram illustrate a common periodic trend with a period of about 10 s
that is comparable with those of the swells after projection on the radar line of sight. However, the
effect of long waves is not limited to an amplitude modulation. It involves also a periodic change in
the shape, bandwidth and maximum of the time-varying spectrum. This aspect is better revealed by
the normalized spectrogram reported in Figure 11.29b (the spectrogram in Figure 11.29a was not nor-
malized). The entire sequence of data has been again divided into NB = 2Ns/Lb −1 = 511 bursts
of Lb = 512 samples each, with an overlap between adjacent bursts of 50%. Individual spectra have
been calculated using a 512-point FFT and Hanning windowing, and then normalized with respect to
the local clutter power. The non-stationarity of the sea clutter related to the periodic spectral variations

562
CHAPTER 11 Radar Clutter Modeling and Analysis
is evident. These variations correspond to the changes of the frequency extent and of the Doppler peak
due to the frequency modulation induced by the long waves on the Bragg-wave scattering.
In order to measure the temporal variation of the backscattered Doppler spectra, we can measure the
Doppler centroid of the clutter spectrum and the rms (root mean square) bandwidth, deﬁned respec-
tively as
fC =
% +∞
−∞f S( f )d f
% +∞
−∞S( f )d f
, and BW =
&
'
'
(
% +∞
−∞

f −fC
2 S( f )d f
% +∞
−∞S( f )d f
,
(11.59)
where f is the frequency and S( f ) is the clutter PSD. The behavior of the Doppler centroid is investigated
instead of that of the PSD peak because it is generally more representative of the short-time spectrum
change, especially in the case of non-symmetric spectral shape. To estimate the time-varying centroid
and bandwidth we can calculate:
ˆfC(l) = 1
Q
NF/2−1

n=−NF/2
f (n)Pl(n),
and
ˆBW(l) =
&
'
'
'
( 1
Q
NF/2−1

n=−NF/2
	
f (n) −ˆfC

l

2
Pl(n),
l = 1, 2, · · · , NB
(11.60)
where f (n) = 1000n/NF Hz is the digital frequency, Pl(n) is the periodogram of the lth data burst (com-
posed of 512 samples) corresponding to f (n), computed on NF = 512 points and Q = NF/2−1
n=−NF/2 Pl(n).
Figure 11.30 shows the time evolution of the texture (on arbitrary scale and units, for ease of repre-
sentation), Doppler centroid, and bandwidth, obtained by processing the data from the third range cell.
They exhibit a common periodic trend with their own reciprocal delay. The Doppler centroid varies
-5 ·10
0
5 ·10
102
1.5 ·102
2 ·102
2.5 ·102
3 ·102
0
10
20
30
40
50
60
70
80
90 100 110 120 130
Normalized Texture
Doppler Centroid
Bandwidth
Time [sec]
Ferquency [Hz]
FIGURE 11.30
Time evolution of VV polarized backscattering mean texture, Doppler centroid and bandwidth. Dataset:
Starea4 of November 7, range cell 3, VV polarization.

2.11.3 Radar Clutter Analysis
563
between −50 Hz and 5 Hz, the bandwidth between 25 Hz and 225 Hz. We observe that the maxima in the
texture values are coincident with the minima of the bandwidth and vice versa. The spectral enlargement
could be due to the modulation induced by the long waves or the presence of thermal noise. The effect
of this noise in the spectral and temporal features of the received echo may be quite different depending
on the clutter-to-noise power ratio (CNR). In the analyzed ﬁle, the CNR ranges from about 80 dB when
the texture is maximum to about −5 dB when the texture is minimum [41]. In the latter case, the con-
tribution of the noise to the echo is strong. The Doppler centroid and the bandwidth follow the texture
behavior but with small delays of 2–3 s and 5 s respectively, i.e., about 1/4 and 1/2 of the swell period.
In order to quantify the relationship between texture, centroid and bandwidth, we can use their
cross-covariance functions (CCF). The CCF between the time-varying texture and the Doppler centroid
signals can be calculated as
CτC (m) =
NB−|m|
l=1

ˆτ(l) −ˆητ

·
	
ˆfC(l + m) −ˆηC

)
NB
l=1

ˆτ(l) −ˆητ
2 NB
l=1
	
ˆfC(l) −ˆηC

2 ,
m = −(NB −1), . . . , NB −1,
(11.61)
and for texture and bandwidth:
CτW (m) =
NB−|m|
l=1

ˆτ(l) −ˆητ

·
	
ˆBW(l + m) −ˆηw

)
NB
l=1

ˆτ(l) −ˆητ
2 NB
l=1
	
ˆBW(l) −ˆηw

2 ,
m = −(NB −1), . . . , NB −1,
(11.62)
where, ˆτ(l), ˆfC(l) and ˆBW(l) are the estimated texture, Doppler centroid and bandwidth, and
ˆητ =
1
NB
NB

l=1
ˆτ(l),
ˆηC =
1
NB
NB

l=1
ˆfC(l),
ˆηW =
1
NB
NB

l=1
ˆBW(l),
(11.63)
are their respective sample means. Figure 11.31a and b shows the plots of CτC(m) and CτW(m),
respectively. They show a behavior very similar to the cross-covariance functions between two truncated
sinusoids with a common period of about 10 s separated by a lag of about 2.5 s and 5 s, respectively.
In order to retrieve the actual frequency values of the common sinusoidal components, it is useful
to calculated the absolute value of the mutual PSDs, i.e., the absolute value of the Fourier transform of
CτC(m) and CτW(m). The results of this calculation are shown in Figure 11.32a and b. The information
on the frequency “similarity” of texture and centroid provided by these mutual PSDs is analogous to
that contained in the modulation transfer function (MTF) known to the geophysics community (see,
for instance, [62] and references therein). The peaks in the mutual PSD correspond to the frequencies
common to the two analyzed signals. This means, for instance, that the frequency component at fLW =
0.1 Hz is present in both texture and Doppler centroid signals and in both texture and bandwidth signals.
This fact is conﬁrmed by the normalized Fourier spectrum of texture, Doppler centroid and bandwidth
(calculated after sample mean removal). The curves are in Figure 11.33a–c. They conﬁrm the hypothesis
of a near line-shape Doppler spectrum with components located in correspondence with the long wave
frequency fLW = 0.1 Hz. Moreover, secondary components are present close to f ≈0 and, especially

564
CHAPTER 11 Radar Clutter Modeling and Analysis
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
-130
-90             -60            -30              0              30              60              90
130
-130
-90             -60            -30              0              30              60              90
130
Time Lag [sec]
Cross-Covariance (Tex., D.C.)
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
Time Lag [sec]
Cross-Covariance (Tex., B.W.)
(a)
(b)
FIGURE 11.31
(a, b) Cross-covariance between mean texture and Doppler centroid, and between mean texture and band-
width. Dataset: Starea4 of November 7, range cell 3, VV polarization.
for texture and bandwidth spectra, at f = 2 fLW. These results suggest that, at least when Bragg
scatteringisdominant,thelongwavesmodulatethespecklescatteringinamplitude,causingthevariation
of the local power, and in frequency, causing a periodic variation of the spectrum centroid and bandwidth.
2.11.3.1.8
AR model
As apparent, there are two goals related to clutter modeling. The ﬁrst is to provide further insight
into the physical and electromagnetic factors that play a role in forming the clutter signal. The sec-
ond is to produce a mathematical model, physically grounded, with which the clutter signal can be
generated and processed to test detection algorithms. In this section, we suggest the use of AR mod-
eling to describe the physical phenomenon of the long wave modulation analyzed in the previous
section. As known, the autoregressive models can ﬁt both Gaussian and non-Gaussian (as in our case)
processes [70, Chapter 4].
The model’s ability to describe a physical phenomenon is not the main constraint, its mathematical
tractability is also very important. In [41] the authors found that an AR model of the third order,
AR(3), allows these constrictions. As regards the tractability, the AR(3) model is deﬁned by seven real

2.11.3 Radar Clutter Analysis
565
0
10
20
30
40
50
-0.5       -0.4         -0.3         -0.2         -0.1            0            0.1          0.2           0.3         0.4          0.5
-0.5       -0.4         -0.3         -0.2         -0.1            0            0.1          0.2           0.3         0.4          0.5
Frequency [Hz]
Cross-PSD (Tex., D.C.)
0
10
20
30
40
50
Frequency [Hz]
Cross-PSD (Tex., B.W.)
(a)
(b)
FIGURE 11.32
(a, b) Absolute value of the normalized cross-spectrum between mean texture and Doppler centroid, and
between mean texture and bandwidth, respectively. Dataset: Starea4 of November 7, range cell 3, VV
polarization.
parameters, the complex value of its three poles and the ﬁnal prediction error. Moreover, an AR process
can be simply generated by properly ﬁltering white noise.
The normalized periodogram of the data was obtained by averaging the individual normalized Fourier
spectrarelatedtosingleslidingbursts.Theentiresequenceofdatahasbeendividedinto NB = 2Ns/Lb−
1 = 511 bursts of Lb = 512 samples each, with an overlap between adjacent bursts of 50%. Next,
individual Fourier spectra were calculated using a 512-point FFT and a Hanning window and then
normalized with respect to the local clutter power. As regards the AR spectrum, it was obtained by
processing all the range cell samples via Yule-Walker’s method [71]. In Figure 11.34 we report some
results for an AR(3) process. It seems that the AR(3) can describe the basic shape features such as
Doppler centroid and bandwidth.
This is conﬁrmed by Figure 11.35a and b that represent the time evolution of these quantities,
estimated both by the spectrogram and by the AR method. In particular, the estimated AR centroid is
given by
ˆfC,AR(l) =
1
QAR
NF/2−1

n=−NF/2
f (n)PAR,l(n),
l = 1, 2, . . . , NB,
(11.64)

566
CHAPTER 11 Radar Clutter Modeling and Analysis
0
4
7
11
14
18
21
25
Frequency [Hz]
Normalized Doppler Centroid PSD
0
4
7
11
14
18
21
25
Frequency [Hz]
Normalized Bandwidth PSD
0
4
7
11
14
18
21
25
-0.5          -0.4       -0.3        -0.2        -0.1          0          0.1         0.2         0.3        0.4          0.5
-0.5          -0.4       -0.3        -0.2        -0.1          0          0.1         0.2         0.3        0.4          0.5
-0.5          -0.4       -0.3        -0.2        -0.1          0          0.1         0.2         0.3        0.4          0.5
Frequency [Hz]
Normalized Texture PSD
(a)
(b)
(c)
FIGURE 11.33
(a–c) Normalized Power Spectral Density of the mean texture, Doppler centroid, and bandwidth, respectively.
Dataset: Starea4 of November 7, range cell 3, VV polarization.
while the estimated AR bandwidth is
ˆBAR
W (l) =
&
'
'
'
(
1
QAR
NF/2−1

n=−NF/2

f (n) −ˆf AR
C
2
PAR,l(n),
l = 1, 2, . . . , NB,
(11.65)

2.11.3 Radar Clutter Analysis
567
0
5 ·10-3
 10-2
1.5 ·10-2
2 ·10-2
2.5 ·10-2
3 ·10-2
3.5 ·10-2
4 ·10-2
-500
-300
-100
0
100
300
500
AR(3)
Periodogram
Frequency [Hz]
Normalized PSD
FIGURE 11.34
Normalized periodogram and AR(3) PSD. Dataset: Starea4 of November 7, range cell 3.
where f (n) = 1000n/NFHz is the digital frequency, PAR,l(n) is the AR spectrum computed by
processing the 512 samples of the lth data burst, via Yule-Walker’s method on NF = 512 points, and
QAR = NF/2−1
n=−NF/2 PAR,l(n). Figure 11.36a and b shows the Fourier spectrum of the AR(3)-centroid
and AR(3)-bandwidth. AR centroid and AR bandwidth still preserve the spectral components of the
corresponding quantities obtained by the Fourier analysis. Also, the time delay with respect to texture is
preserved, as shown by the cross-covariance (Figure 11.37a and b). Therefore, this analysis suggests that
AR(3) model is able to model the basic effects of long waves modulation on the capillary backscattering.
It is also of interest to investigate how its parameters vary. Figures 11.36a–c show the time evolution of
the two dominant AR poles and ﬁnal prediction error, together with texture. The elements of correlation
are evident. The dominant pole, with almost constant unitary modulus, has an instantaneous frequency
that varies with the same period of the texture. Also, the second pole follows the same periodic trend,
being almost constant when the signal is strongly reﬂected by the crest of a wave and noisy otherwise.
The third pole is dominated by noise, while the ﬁnal prediction error follows the texture trend.
From the results shown in the previous pages, it is apparent that there is not a unique optimum
amplitude and spectral model for the sea clutter in all the resolutions. The statistical parameters change
with time, range resolution, polarization, sea conditions. Generally the compound-Gaussian model
provides a good ﬁtting to the data but it shows some limits at the very high resolutions particularly for
HH data, which are almost always spikier than VV data. Moreover, the sea clutter cannot be considered
stationary on long periods of time. As particularly evident in X-band and VV pol, the long waves
modulate the sea scattering in amplitude and frequency, determining the temporal and spatial periodical
changes of the texture and of the bandwidth and Doppler centroid of the speckle spectrum.
2.11.3.2 Land clutter analysis: farmland area
The results of the analysis of ground clutter, reported in this section, mainly relate to the data recorded
with the MIT Lincoln Laboratory Phase One radar [29,32].

568
CHAPTER 11 Radar Clutter Modeling and Analysis
0
50
100
150
200
250
0
10
20
30
40
50
60
70
80
90 100 110 120 130
Periodogram
AR(3)
Time [sec]
Bandwidth [Hz]
-50
-40
-30
-20
-10
0
10
20
0
10
20
30
40
50
60
70
80
90 100 110 120 130
Periodogram
AR(3)
Time [sec]
Doppler Centroid  [Hz]
(a)
(b)
FIGURE 11.35
(a,b) Time evolution of the Doppler centroid and bandwidth, obtained from the Fourier and AR(3) estimated
spectra. Dataset: Starea4 of November 7, range cell 3, VV polarization.
The Phase One radar could operate in any one of ﬁve different radar bands (VHF, UHF, L-, S-, and
X-bands). The results of this section are for ground clutter data recorded at X-band. Results in all bands
are given in [32]. The overall radar system block diagram description can be found in [29].
The radar maintained coherence and stability sufﬁcient for 60 dB, two-pulse-canceller clutter atten-
uation in post-processing and also had uncoded pulsed waveforms, with two pulse lengths available in
each band to provide high and low range resolutions. Polarization was selectable as vertical or horizon-
tal, with transmit and receive antennas always co-polarized, i.e., the cross-polarized component in the
radar return signal could not be received. Frequency, polarization, and pulse length as well as spatial
extent in range and azimuth of the recording window, number of pulses, and pulse-repetition rate were
selectable by computer console for each recorded clutter experiment.

2.11.3 Radar Clutter Analysis
569
0
4
8
12
16
20
24
28
-0.5        -0.4        -0.3       -0.2        -0.1          0          0.1         0.2         0.3         0.4         0.5
-0.5        -0.4        -0.3       -0.2        -0.1          0          0.1         0.2         0.3         0.4         0.5
Frequency [Hz]
Norm. AR(3) Doppler Centroid PSD
0
4
7
11
14
18
21
25
Frequency [Hz]
Norm.  AR(3) Bandwidth PSD
(a)
(b)
FIGURE 11.36
(a,b) Normalized Fourier spectrum of the AR(3) Doppler centroid, and AR(3) bandwidth. Dataset: Starea4
of November 7, range cell 3.
The analyzed clutter data ﬁles described here were recorded at X-band at Wolseley, Saskatchewan,
located on the Canadian prairie at a latitude of 50.36◦N and a longitude of 103.150W. The illuminated
area was covered by agricultural crops (83%), deciduous trees (11%), lakes (4%), and rural farm
buildings (2%). The terrain was a sequence of gentle slopes (<10◦) with a relief of 25–150 ft.
The analyzed X-band (9.2 GHz) data are divided in two different sets. In the ﬁrst one (N007001.35)
the polarization is HH, in the second one (N007001.34) it is VV. Each set contains four range intervals
recorded in scan mode, and each range interval contains 316 range cells. The scan velocity was 2◦/s, i.e.,
about 2 beams/s. The emitted pulse repetition frequency (PRF) was 500 Hz, but only 1 out of 2 pulse
returns was recorded. The pulses were further coherently integrated in groups of 16, so the effective
PRF of the data from this experiment is 15.625 Hz. The data were stored in a 316 × 703 matrix, each
row for a ﬁxed range, each column for a ﬁxed azimuth. For each integrated pulse, 316 range samples
are provided at 10 MHz sampling rate. The data were collected one range interval after another in
“windshield-wiper” mode (see [29] for more details).

570
CHAPTER 11 Radar Clutter Modeling and Analysis
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
-120           -90             -60            -30              0
30
60              90
120
-120           -90             -60            -30              0
30
60              90
120
Time Lag [sec]
Cross-Cov.(Tex., AR(3) D.C.)
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
0.8
Time Lag [sec]
Cross-Cov. (Tex., AR(3) B.W.)
(a)
(b)
FIGURE 11.37
(a,b) Cross-covariance between mean texture and the AR(3) Doppler centroid, and between mean texture
and the AR(3) bandwidth. Dataset: Starea4 of November 7, range cell 3.
The radar depression angle decreased from about 1◦to 0.7◦across the ﬁrst range interval, and
further decreased to 0.5◦in the second interval, to 0.3◦in the third interval and to 0.2◦in the fourth
range interval. The azimuth beamwidth of the antenna was 0.018 rad at HH polarization and 0.019 rad
about 10 (i.e., at VV polarization). The nominal azimuth sampling interval was 0.128◦/pulse; thus for
each range cell the radar recorded seven to eight azimuth samples. The range resolution was 15 m (i.e.,
pulse length = 100 ns, which matches the 10 MHz sampling rate). The return from each pulse was
provided in I and Q format calibrated in units of radar cross section [32]. The analysis was performed
on the data after normalizing them with respect to the square root of the cell area. This normalization is
helpful in comparing results for statistical populations extended in range, as these Wolseley data. The
normalization makes the amplitude values of clutter returns independent of the distance.
In Figure 11.39a the 2D clutter map relative to the ﬁrst range interval of the VV polarized data is
reported. The data are plotted in logarithmic scale to span the grey-scale code (0–255). The black areas
of the image indicate regions of high radar reﬂectivity, usually from discrete vertical clutter sources,
such as buildings, fence lines, trees, and bushes, aligned along roads and ﬁeld borders; the white areas
indicate regions of relatively low reﬂectivity, such as ﬁeld surfaces. On the x-axis the 316 range samples
are reported from 1 km to 5.7 km, whereas on the y-axis the 703 azimuth samples are from 270◦to 360◦.

2.11.3 Radar Clutter Analysis
571
Figure 11.39b shows the same data as Figure 11.39a, but in a 3D format to highlight the presence of
spikes, well evident in this range interval. Wolseley is a generally open farmland site of low relief. At
open farmland sites like Wolseley, spatial clutter statistics are dominated by spatially localized, ﬁxed,
discrete scatterers that comprise all the vertical objects that occur on the landscape. These include the
isolated trees and small clusters of trees; agricultural ﬁeld boundaries and the vertical objects along
them such as fences and higher uncultivated vegetation (tall grass, shrubs); roads and the vertical
objects along them such as utility poles and wires; banks of streams and creeks; complexes of farm
buildings and farm machinery; other cultural artifacts such as water towers and radio towers; and, also,
locally high points in the microtopography itself. Such discrete objects cause strong spikes of clutter
distributed randomly over the agricultural ﬁeld surfaces, which themselves constitute a relatively weak,
area-extensive, backscattering medium. These spikes of clutter are observed in Figure 11.38b, where
the curvilinear patterns indicate ﬁeld and road boundaries on a predominantly north-south, east-west
grid. Such spikes are of extremely wide variation in amplitude and result in long tails in empirical clutter
spatial amplitude distribution applicable to such terrain.
The ﬁrst step of the analysis done on these data was the check of the Gaussianity of the I and Q
components. To this purpose the histograms of the I and Q components have been drawn, for each range
interval and for each polarization (VV and HH). The histogram has been compared with the Gaussian
PDF having the same mean and variance of the data. The dc offset of each channel has been estimated
from each of the four range intervals of 316 × 703 = 222,148 samples, and then subtracted from the data.
This analysis, performed on each range interval, has shown that I and Q PDFs deviate considerably from
Gaussianity; the clutter amplitude is therefore not Rayleigh distributed. This deviation is well evident
in Figure 11.40, where the histogram of the I component for the fourth range interval (VV polarization)
is compared with the Gaussian PDF having the same variance and zero-mean.
These results were conﬁrmed by estimating the skewnessand kurtosis,deﬁned, respectively, as
γ3(Z) =
E

(Z −E{Z})3
E3/2 
(Z −E{Z})2
and γ4(Z) = E

(Z −E{Z})4
E2 
(Z −E{Z})2 −3,
(11.66)
where E{Z} is the mean value of the random variable Z. The skewness characterizes the degree of
asymmetry of a distribution around its mean value. A positive value of skewness corresponds to a
distribution with an asymmetric tail extending on the right of the mean. A negative value of the skewness
corresponds to a distribution with an asymmetric tail extending on the left. The kurtosis measures the
relative peakedness or ﬂatness of a distribution. For a Gaussian PDF these two parameters are identically
zero, so they are a measure of the deviation from Gaussianity. The estimates of the skewness and kurtosis
from two range intervals are reported in Table 11.16.
The study of the data has been completed performing a statistical analysis similar to that performed
on the sea clutter data, comparing the histogram with some known distributions. The results show that
the data seem to ﬁt best the Weibull distribution for the ﬁrst and second range intervals, while for the
third and fourth range intervals the data show a behavior that is intermediate between Weibull and
log-normal [29]. The results of histogram analysis for the fourth range cell are reported in Figure 11.41
on a log-scale.
The same results were obtained for the VV data of the same site.

572
CHAPTER 11 Radar Clutter Modeling and Analysis
-400
-200
0
200
400
0
10
20
30
40
50
60
70
80
90 100 110 120 130
2nd Pole
Normalized Texture
Time [sec]
Pole Frequency [Hz]
0
5 ·10-5
 10-4
1.5 ·10-4
2 ·10-4
2.5 ·10-4
0
10
20
30
40
50
60
70
80
90 100 110 120 130
AR(3) Final Prediction Error
Normalized Texture
Time [sec]
-100
0
100
200
300
400
500
0
10
20
30
40
50
60
70
80
90 100 110 120 130
1st Pole
Normalized Texture
Time [sec]
Pole Frequency [Hz]
(a)
(b)
(c)
FIGURE 11.38
(a–c) AR(3) pole frequencies and ﬁnal prediction error, compared with the normalized texture.

2.11.3 Radar Clutter Analysis
573
316 
(5.7 Km)
1 
(1 Km)
range 
samples
1 (270°)
703 (360°)
azimuth 
samples
(a)
(b)
FIGURE 11.39
(a,b)2D clutter map, VV data, Wolseley site, 3D clutter map, VV data, Wolseley site.
2.11.3.2.1
Modiﬁed Kolmogorov-Smirnoff statistical test
The statistical analysis of data amplitude was concluded by applying a statistical hypothesis test as for
the sea clutter data. The KS goodness-of-ﬁt test has been largely used to determine which distribution
(Rayleigh, log-normal, Weibull, or K in our case) best ﬁts the data. Unfortunately, as already said for
sea clutter, in some cases it is not useful, because it places an equal importance on all regions in the
probability space. In practical radar applications a good ﬁt is important in the tail regions of the PDFs.

574
CHAPTER 11 Radar Clutter Modeling and Analysis
10
-4
10
-3
10
-2
10
-1
1
10
10
2
10
3
-0.05 -0.04 -0.03 -0.02 -0.01    0    0.01   0.02  0.03  0.04   0.05
histogram
Gauss
PDF
I component
VV polarization
4th range interval
FIGURE 11.40
Histogram of I component, Wolseley site.
Table 11.16 Standard Deviation, Skewness and Kurtosis, Wolseley site
HH I Comp
HH Q Comp
VV I Comp
VV Q Comp
First range interval
Std dev
0.00931
0.00924
0.0110
0.0107
Skewness
−0.22284
0.18859
−0.1199
0.2341
Kurtosis
260.929
257.923
277.728
271.549
Fourth range interval
Std dev
0.0081
0.0086
0.0111
0.0111
Skewness
0.0918
0.0522
0.078
−0.173
Kurtosis
115.346
111.309
131.982
133.314
The tails, in fact, contain the strong values (i.e., the spikes) that, considered as target returns by a
detector, can increase the FAR. Since good ﬁtting in the tails is mandatory for correct design of CFAR
processors, especially when low PFA values are required, the KS test is of limited use for clutter data
(as recognized also in [32]). To overcome this problem we can use a modiﬁed Kolmogorov-Smirnoff
(MKS) goodness-of-ﬁt test [29].
The idea is simple: apply the standard KS test by taking into account only the tail regions, i.e.,
by considering only the data above a given threshold AMKS and the modiﬁed theoretical PDFs
pZ,MKS(z) = pZ(z)u(z −λMKS) where u(·) is the unit step function. The standard two-sample KS test
veriﬁes whether the recorded data are distributed in accordance with a hypothetical PDF, as already said
for the sea clutter data. If the probability of type I is very low, for instance <1%, then this hypothesis

2.11.3 Radar Clutter Analysis
575
10-2
10-1
100
101
102
103
0
0.05
0.1
0.15
0.2
histogram
K
LN
Rayleigh
Weibull
PDF
Amplitude
HH polarization
4th range interval
FIGURE 11.41
Histogram analysis.
should be rejected [72]. By applying the standard two-sample test, which considers the entire deﬁnition
range of the random variable Z under investigation, the obtained probability of Type I error (α) is always
<1%, for all the distributions (Rayleigh, log-normal, Weibull, and K); thus, in the classical formulation,
the KS test is not useful with these data. This is due to the differences exhibited by the distributions in
the region of low values of Z. On the contrary, if we apply the MKS test setting the threshold AMKS
in the region (0.01,0.03), where the distributions are very similar (except for the Rayleigh), the result
for the probability of type I is always 100%. This means that, in this central region, the KS test cannot
distinguish between the different proposed models. But, as written above, we are mainly interested in
the tails of the distribution, so we can applied the MKS test with, for instance, λMKS = 0.03. In this
way we leave out of the analysis the central region of the PDF, corresponding to high values of PFA
(say, PFA = 10−2). The results are reported in Table 11.17.
Generally, the value of probability of error of type I, α, for Weibull PDF is higher than for the other
PDFs, so the good ﬁt of these ground clutter data to the Weibull model is conﬁrmed.
2.11.3.2.2
Windblown trees data
The same analysis of farmland data was performed in [73] on a different Phase One X-band ﬁle, namely
H067032.2, for which the data were measured from range cells containing windblown trees in contrast to
open farmland. The clutter data shown here were recorded at Katahdin Hill site by Lincoln Laboratory
personnel on 17 April 1985 [32]. The analyzed data set contains 30,720 samples per range cell, of
HH-polarization, with pulse repetition frequency (PRF) equal to 500 Hz, and therefore pulse repetition
interval (PRI) of T = 1/PRF = 2 ms. The return from each pulse is provided in in-phase and quadrature
format. Data were recorded from 76 contiguous range gates utilizing the Phase One X-band stationary
antenna in a ﬁxed azimuth position (235◦). These 76 range cells were located from 2.0 km to 3.1 km.
The radar depression angle was about 0.65◦and the azimuth beamwidth of the antenna was 0.018 rad.

576
CHAPTER 11 Radar Clutter Modeling and Analysis
Table 11.17 Results of MKS Test
Range Interval
α (Type I Error)
LN (%)
Weibull (%)
K (%)
1stHH
99
99
19
1stVV
6.4
96
4.2
2ndHH
1.4
96
31
2ndVV
14.6
99
3.3
3rdHH
11
87
1.3
3rdVV
62
55
<1
4thHH
84
97
1.5
4thVV
94
79
<1
The radar range resolution was 15 m. The illuminated area was tree covered, primarily with mixed
deciduous trees, but also with occasional pine and cedar. At the time of the experiments, the deciduous
trees did not yet have their leaves. During this experiment the wind was quite strong: 15–20 knots.
Details about how the data were collected can be found in [32]. The 3D power map of the clutter is
shown in Figure 11.42.
In this ﬁgure the presence of two regions, with different power values, is evident. The curves rep-
resenting the received power versus range exhibit a stepwise behavior. This is due to the transition
between agricultural ﬁelds/wetland (ﬁrst region) and windblown trees (second region). In our analysis
here we consider only single range cells from the second region. In Figure 11.43 the histogram of the
data relative only to the range cells 34–36 is compared with the Rayleigh PDF with the same variance.
The results obtained for the open farmland data (two data ﬁles N007001.34 and N007001.35) are
very different from these windblown trees data. This is partly due to the different land covers of the
illuminated areas, but also importantly, partly due to the forest data embodying temporal variations, not
spatial. The area relative to the H067032.3 data ﬁle was homogeneously tree covered, primarily with
mixed deciduous trees and with occasional pine and cedar. In the other two analyzed data ﬁles, the returns
came from a large spatial population of ﬁxed discrete sources on open farmland. This heterogeneity
introduces a considerable spread in the distributions as already noted in [32]. The differences are also
due to the way of recording the data: the windblown tree data are temporal statistics (variations in time
on a given range cell, or on few cells) recorded with ﬁxed antenna; the Wolseley farmland data are
spatial statistics, recorded with a scanning antenna on many range cells.
2.11.3.2.3
The experimentally-measured Doppler spectrum of ground clutter
The Katahdin Hill data are particularly interesting for the shape of the PSD.
A suitable analytic expression of the PSD of ground clutter, ptot( f ), back-scattered from regions
containing windblown vegetation [32], is
Ptot( f ) =
r
1 + r δ( f ) +
1
1 + r Pac( f ),
−∞< f < ∞
(11.67)

2.11.3 Radar Clutter Analysis
577
1
76
1
30720
Range cells 
Number of pulse 
repetition time intervals 
FIGURE 11.42
3D power map of the analyzed clutter data.
histograom
Rayleigh
Windblown tress
102
10
0
0.01
0.02
0.03
0.04
Amplitude
0.05
0.06
0.07
0.08
PDF
1
10-2
10-1
FIGURE 11.43
Data histogram, windblown trees.

578
CHAPTER 11 Radar Clutter Modeling and Analysis
where f is the Doppler frequency in Hz, r is the ratio of dc power to ac power in the spectrum, δ( f ) is
the Dirac delta function which represents the shape of the dc component in the spectrum and Pac( f )
represents the shape of the ac component of the spectrum, normalized such that
% ∞
−∞pac( f )d f = 1.
A phenomenological interpretation of this spectral shape was proposed in [74], where the exponential
spectrum is obtained as the limit power spectrum in the presence of a random number of ﬂuctuation
scales in the Doppler components of windblown vegetation. From the detailed analyses of the MIT-LL
measurements, it is apparent that the value of the dc/ac ratio r in Eq. (11.67) is strongly dependent on
both wind speed and radar frequency and generally follows the empirically-derived analytical expression
10 log10 (r) = −15.5 log10 (w) −12.1 log10 ( fo) + 63.2 where w is wind speed in miles/hour, and fo
is the radar carrier frequency in MHz. As described in [32], the MIT-LL measurements show a good ﬁt
to the model of Eq. (11.67) when the ac component of the spectrum is characterized by the two-sided
exponential spectral shape
Pac( f ) = λβ
4 e−λβ
2 | f |,
−∞< f < ∞,
(11.68)
where λ is the radar transmission wavelength and β is the exponential shape parameter. The value of β
is a function of the wind conditions such that the spectral width increases with increasing wind speed
(see Table 11.18); however, β is largely independent of radar carrier frequency over the range from VHF
to X-Band. An algebraic expression for β that incorporates the linear dependency of spectral width on
the logarithm of the wind speed w (mph) as observed in the data is β−1 =

log10 w −log10 (2/31.5)

·
(20 log10 3)−1.
The described equations and Table 11.18 constitute a simple but complete model for characterizing
the complex physical phenomenon of windblown clutter spectra over spectral dynamic ranges reaching
60–80 dB below zero-Doppler peaks, applicable over the range from VHF to X-band [32].
TheGaussianmodelforthewindblownclutterspectrum,whichwassupportedbyearlymeasurements
with very limited dynamic range, is given by
Pac( f ) =
1
√
2πσ
e−f 2
2σ2 ,
−∞< f < ∞,
(11.69)
where σ is the standard deviation of the Gaussian spectrum. The exponential model has wider tails
than the Gaussian model. For use with somewhat increased dynamic range, the other alternative pop-
ular spectral shape function Pac( f ) has been the power-law spectrum, which is characterized by two
Table 11.18 Exponential AC Shape Parameter β versus Wind Speed
Wind Conditions
Wind Speed (mph)
β (s/m) (Typical)
β (s/m) (Worst Case)
Light air
1–7
12
–
Breezy
7–15
8
–
Windy
15–30
5.7
5.2
Gale force
30–50
4.3
3.8

2.11.3 Radar Clutter Analysis
579
parameters, the shape parameter n, and the break-point Doppler frequency fc that determines where the
shape function is 3 dB below its peak zero-Doppler level:
Pac( f ) = n sin (π/n)
2π fc
1
1 + ( f / fc)n ,
−∞< f < ∞.
(11.70)
The MIT-LL measurements of much increased dynamic range clearly indicate that clutter spectral
shapes are indeed wider than Gaussian; but that observed rates of decay modeled as power-law at upper
levels of spectral power do not continue as power-law to lower levels of spectral power, but fall off
much faster at the lower levels. The tails of the exponential model show an intermediate rate of decay—
between the fast decay of the Gaussian model and the slow decay of the power-law model—that yields
a good ﬁt to the measured data.
For analyzing the PSD of windblown tree clutter, many data from various windblown-tree range cells
were processed. Here we report only the results from range cell #35 (second region) as representative
of results achieved by processing other range cells in the same region. The PSD has been ﬁrst estimated
non-parametrically, by using the modiﬁed periodogram method (Welch method) with the four-sample
Blackman-Harris window [73]:
w[n] =
3

i=0
ai( −1)i cos
2πn
N

,
n = 0, 1, . . . , N −1,
(11.71)
with coefﬁcients a0 = 0.40217, a1 = 0.49703, a2 = 0.09392, and a3 = 0.00183. The set of 30,720
data samples has been divided in L = 15 subsets {z(k)[n]}N−1
n=0 , with k = 1, 2, . . . , L, of N = 2048 samples
each and then the windowed periodogram calculated from each subset as follows
Pk( fi) =

N−1

n=0
w[n]z(k)[n]e−j2π fin

2
,
(11.72)
where fi = i/(NT ), for −N/2 ≤i ≤N/2 −1, and z(k)[n] = z(k)
I [n] + jz(k)
Q [n] is the nth complex
sample relative to the kth subset. To obtain the ﬁnal spectrum estimate, the K estimates are averaged as
s( fi) = (1/K) K
K=1 PK ( fi). Finally, the estimate is normalized such that the area is unity, i.e., divided
by the estimate of the total disturbance power PC+N = PC + PN. The disturbance power is estimated to
be ˆPC+N = 5.9276·10−4. The resulting curve is shown in Figure 11.44, labeled as “WP,” which stands
for weighted periodogram. Note that the PSD is plotted from −250 Hz to 250 Hz because the PRF is
500 Hz. It is quite evident in these ﬁgures that, for | f | > 100 Hz, thermal noise predominates over
clutter; thus we ﬁt the clutter PSD only over the frequency range [−100, 100]Hz. In [73] the authors used
the frequency bins in the range [−250, −100]∪[100, 250]Hz to estimate the clutter-to-noise power ratio
(CNR), which is obtained by solving the equation (5/3) 
i S( fi) = PN/PC+N = 1/(1 + C N R) with
respect to CNR, where PN is the thermal noise power, S( fi) denotes the normalized PSD estimate and the
sum is over all i’s such that | fi| ∈[100, 250] Hz. For the 35th range cell it results that C N R ∼= 33 dB.
To estimate the clutter PSD parameters, nonlinear least squares (NLLS) method [15] has been applied.
The NLLS method can be applied directly to either P( fk) or to its logarithm. In the second case, the

580
CHAPTER 11 Radar Clutter Modeling and Analysis
-250 -200 -150 -100 -50
250
200
150
100
50
0
Frequency (Hz)
10-4
10-5
10-6
10-7
1
PSD
10-1
10-2
10-3
WP
Exp
Gauss
PL2
PL3
FIGURE 11.44
Power spectral density, Log-NLLS method, 35th range cell.
estimates of the model parameters are derived by solving the following minimization problem:
θLog-NLLS = arg min
θ

i
log10Pac( fi, θ) −log10S( fi)
2,
| fi| < 100 Hz.
(11.73)
where θ is the vector of model parameters that have to be estimated. We refer to the method in (64)
as the NLLS method. For the Power Law model in Eq. (11.61), we consider the two cases n = 2 (PL2)
and n = 3 (PL3), and then we use the NLLS method to estimate the PSD parameters. In Figure 11.44
the various models obtained by the NLLS method are compared with the weighted periodogram. In
Table 11.19 we report the estimates of β, σ, and fc obtained by the NLLS method. The value of r is
always lower than 10−4, so the dc component in cell #35 is negligible. The best ﬁt is provided by the
exponential model.
The analysis of the land clutter shows that the clutter statistics are heavily site-dependent. As a matter
of fact the amplitude of the clutter at X- and L-band is Gaussian distributed for homogeneous clutter
as that of windblown trees, non-Gaussian distributed if backscattered by discrete sources as pylons,
fences, etc. Even the PSD depends on the sites, and, often, on the dynamic range of the radar as well.
Table 11.19 Estimates of the PSD Model Parameters, Log-NLLS Method
Cell #35
Exp
Gauss
PL2
PL3
β/σ/fc/fc
5.95 (2.3. Hz m)−1
23.63 Hz
1.02 Hz
6.33 Hz

2.11.4 Simulation Methods
581
2.11.4 Simulation methods
In circumstances where mathematical analysis is not possible because it is too complex, it is often
necessary to resort to numerical simulation of clutter returns. This data may be used in computer
simulation of signal processing. In addition, the testing and assessment of real hardware often requires
the processing of data in real time in the laboratory. This can sometimes be achieved with recorded data
but often it is necessary to use numerically simulated data.
When simulating clutter returns, the problem addressed here is that of the generation of random
variates with prescribed one and two point statistics (i.e., the probability density function, PDF, and
correlation function). The methods for generating this data will reﬂect the statistical models described
in Section 2.11.2.1.3.
2.11.4.1 Generating uncorrelated random numbers with a prescribed PDF
There are many well-proven techniques for generating very long sequences of random numbers uni-
formly distributed between 0 and 1. This data will form the basis of techniques for generating random
numbers with other PDFs.
The general solution for transforming data, x, with one PDF, P1(x), to data y with another PDF,
P2(y), is the memoryless non-linear transform (MNLT) is given by Tough and Ward [75]:
 ∞
x
P1

x′
dx′ =
 ∞
y
P2

y′
dy′.
(11.74)
Given a value for x, this equation is solved for y. A simple example is the generation of data, y, with
an exponential PDF, starting with random numbers, x, uniformly distributed between 0 and 1. Now:
NowP(y) = exp(−y);
y ≥0
and
 x
0
dx =
 y
0
exp

−y′
dy′ = 1 −exp

−y

,
y = −loge(1 −x).
(11.75)
As x and (1−x) have the same distribution, we can also write y = −loge (x). It follows that Rayleigh
variates can be generated as
y =
*
−loge(x).
(11.76)
This result then produces a simple method for generating Gaussian variates. Gaussian variates could
be obtained by solving Eq. (11.75) but this would be numerically difﬁcult. An easier method is to recall
that independent in-phase and quadrature Gaussian variates will have a Rayleigh distributed amplitude
and random phase, uniformly distributed over 0 to 2π. Then using two uniformly distributed random
numbers, x1 and x2, we can produce two independent Gaussian random numbers, y1 and y2, from:
y1 =
+
−loge

x1

cos

2πx2

;
y2 =
+
−loge

x1

sin

2πx2

.
(11.77)

582
CHAPTER 11 Radar Clutter Modeling and Analysis
These Gaussian variables will have a mean of 0 and variance of 0.5. The more general case of
variables with mean μ and variance σ 2 are obtained by using:
g = μ +
√
2σ 2y.
(11.78)
2.11.4.2 Generating correlated Gaussian random numbers
Gaussian random numbers with arbitrary autocorrelation functions can be generated by appropriate
ﬁltering. A simple ﬁlter example is the recurrence relation (AR process of order 1):
xn = ηxn−1 + βgn,
(11.79)
where the gn are zero mean, unit variance independent Gaussian numbers and η, β are constants (η < 1).
It can be easily shown [25] that:
E {xn} = ηnx0
and E

x2
n

= η2nx2
0 + β2 
1 −η2n
1 −η2
.
(11.80)
The terms in ηn represent transient terms in the ﬁlter output and go to zero as n →∞. The resultant
random numbers xn have a Gaussian PDF with zero mean and variance
β2
1−η2 . More importantly, they
will have an autocorrelation function:
E {xnxn+m} = η|m|E

x2
n

.
(11.81)
This method can be extended to more general ﬁlter functions. The ﬁltering may also be done using
an FFT. If we wish to generate random numbers with a power spectral density (Sω), we can generate
a batch of random Gaussian random numbers, gI + jgQ, representing complex data in the frequency
domain with a uniform power spectrum. This data is then weighted by the amplitude of the required
spectrum √S(ω) and the appropriate complex time domain sequence obtained by Fourier inversion.
2.11.4.3 Correlated non-Gaussian random numbers
Generating sequences of correlated random numbers with non-Gaussian PDFs is more complex. A
sequence of random variates with a given PDF can be correlated by ﬁltering, as above, but the resulting
data will in general have a different PDF. For a given ﬁlter function and PDF, empirical relationships can
sometimes be developed to approximately simulate the required characteristics [76,77]. An example of a
method for generating correlated Gamma distributed variates is given in [25]. Random Gamma variates
can be generated from random Gaussian variates by the MNLT (Memoryless Non-linear Transform)
method. If the Gaussian variates are correlated, the resulting PDF after the MNLT will be Gamma
distributed as required, but with a changed autocorrelation function, ACF. It has been found that if the
Gaussian process has an exponentially decaying ACF with decay time τG, then the resulting Gamma
variates, with shape parameter ν, will have a decay time τγ given by:
τG
τγ
= 1 + 0.15
ν0.7 .
(11.82)

2.11.4 Simulation Methods
583
A more general process has been developed by Tough and Ward [75] to produce correlated variates
with known PDF and ACF. This is illustrated here by the problem of generating correlated K distributed
random numbers. Starting with random Gamma distributed variates, g, random Gamma variates can be
produced by a MNLT so that

(ν, x)

(ν)
= 0.5 erfc

g/
√
2

,
x(g) = Qdist

0.5 erfc

g/
√
2

,
with E{x} = ν;
E{x} = ν(ν + 1),
(11.83)
where 
(ν) is a Gamma function, 
(ν, x) is an incomplete Gamma function and erfc() is the error
function complement.
Independent K distributed random numbers representing clutter intensity can be generated by mod-
ulating exponentially distributed variates by the Gamma variates. If correlated Gaussian variates are
used, the gamma variates will also be correlated. If the Gaussian variates have a normalized ACF (the
correlation coefﬁcient) given by
RG(m) = E {gngn+m}
E

g2n

(11.84)
then the normalized ACF of the Gamma variates is given by:
E {xnxn+m} = 1
2π
∞

n=0
RG(m)n
2nn!
 ∞
−∞
e−y2/2Hn

y/
√
2

Qdist

0.5 erfc

y/
√
2

dy
2
, (11.85)
where Hn(·) is a Hermite polynomial, deﬁned as
Hn(u) = ( −1)n exp

u2  d
du
n
exp

−u2
.
(11.86)
As an example, for ν = 0.5,
E {xnxn+m} ≈0.253 + 0.348 RG(m) + 0.140 RG(m)2 + 0.013 RG(m)3 + 0.000054 RG(m)4
+ 0.000174 RG(m)5 + 9.36 × 10−6 RG(m)6 + 8.87 × 10−6 RG(m)7.
(11.87)
Here E {xnxn+m} = E2{x} +

E

x2
−E2{x}

Rγ (m) = ν2 + Rγ (m)ν, where Rγ (m) is the
normalized ACF of the gamma variates. For ν ≫10, RG(m) ≈Rγ (m). As ν reduces, the relationship
becomes non-linear and this produces a limitation for negative values of Rγ (m). For example, for
ν = 0.5 and RG(m) = −1 it is found that Rγ (m) = −0.437, which means that Rγ (m) < −0.437
cannot be simulated. This is not usually a signiﬁcant limitation and this method is extremely powerful
for generating random numbers with a wide range of PDFs and ACFs.
Figure 11.45 shows a normalized ACF for data with ν = 0.5, showing the desired values and the
values achieved with a sample of simulated data. Figure 11.46 shows an example of a time series of
simulated correlated K distributed variates with this ACF.

584
CHAPTER 11 Radar Clutter Modeling and Analysis
10
20
30
40
50
60
-1
-0.5
0
0.5
1
Rγ(m)
m
FIGURE 11.45
Normalized ACF of correlated Gamma variates. Dashed line: original data; solid line: simulated data.
150
200
250
300
5
10
15
20
range
FIGURE 11.46
Correlated Gamma variates, with normalized ACF of Figure 11.45.
This method can readily be extended to two dimensions, as described in [25,75].
In some situations, particularly for detection purposes, we may be interested in generating many
independent vectors of correlated compound-Gaussian clutter. If the Time-on-Target (ToT) is short
(tens of ms) the texture can be considered a constant in each vector but randomly changing from one
vector to the other. In this case, the compound-Gaussian model degenerates into the Spherically Invariant
Random Process (SIRP), proposed by Conte and Longo [12] for modeling the radar sea clutter. The
samples of the SIRV constitutes a spherically invariant random vector (SIRV) whose PDF is given by
pZ(z) =
 ∞
0
1

2πτ
m |M|
exp

−zHM−1z
τ

pτ(τ)dτ,
(11.88)
where the vector z = [z(1)z(2) · · · z(m)]T is the vector we want to generate. Then the vector z we need
is the product between the texture real random variable τ and a speckle complex Gaussian vector x.
Conditionally to the texture, the covariance matrix of the vector z is the covariance matrix M of the

2.11.5 Use of Clutter Models in Radar Design and Analysis
585
speckle. The problem is then reduced to the generation of a Gaussian vector with a certain covariance
matrix M. To this purpose, we can use a linear ﬁlter as described at the beginning of this section
(sequential method), or a batch method based on the invariance property of the Gaussian processes with
respect to linear operations. Consider the vector x = Aw where w is a vector of independent identically
distributedcomplexGaussianrandomvariableswithzero-meanandunitvariance.Thecovariancematrix
of x is M = E

xxH
= AAH. There are many ways to ﬁnd a matrix A satisfying this relation. One of
them is the Cholesky decomposition that results in a lower triangular matrix A=L [78]. Summarizing,
to generate the vector z with must generate ﬁrst w, multiply it by the matrix A and then by the random
variable τ. The advantage of this method with respect to the sequential one is that it does not suffer the
problem of the transient term.
2.11.5 Use of clutter models in radar design and analysis
2.11.5.1 Performance prediction
One of the purposes of clutter models is to predict the performance of radar systems. This is typically
achieved by initial application of the radar equation to establish the relative power levels for a given
situation of returns from targets and clutter and thermal noise.
The basic radar equation for noise-limited target detection performance can be written as
S
N = PtGt
4π R2
σ
4π R2 Ar
1
L
C
pn
,
(11.89)
where
Pt
peak transmitter power, W
Gt
antenna gain on transmit
Gr
antenna gain on receive
σ
target RCS, m2
Ar
receive aperture, m2; Ar ≈Grλ2
4π
pn
noise power, W; pn = kT0Fn B
L
system losses
C
pulse compression gain; C ≈Bτ
k
:Boltzmann’s constant; k = 1.38 × 10−23 JK−1
T0
Standard noise temperature, 290K.
B
receiver bandwidth, Hz
Fn
receiver noise ﬁgure
τ
radar pulse length, s
The basic radar hardware and waveform parameters can be measured accurately in the factory. The
system losses will usually include the microwave losses in the radar hardware, which can be measured,
and the propagation losses, which usually cannot be measured but must be estimated from the prevailing
conditions and models. It is sometimes convenient to include signal processing “losses” in this term to

586
CHAPTER 11 Radar Clutter Modeling and Analysis
account for the non-ideal nature of subsequent signal processing compared with some idealized form
used to calculate performance analytically.
For a single pulse return, detection performance can be described in terms of the probability of false
alarm, Pfa, and probability of detection, Pd, following a detection threshold. For a square law detector,
Gaussian clutter and an idealized ﬁxed threshold detection threshold, t:
Pfa =
 ∞
t
1
pn
exp

−x
pn

dx = exp

−t
pn

.
(11.90)
For a Swerling Case 1 or Case 2 target ([79], exponential PDF), with mean power s
Pd =
 ∞
t
1
pn + s exp

−
x
pn + s

dx = exp

−
t/pn
1 + SN R

= exp

loge

Pfa

1 + SN R

,
(11.91)
where SN R = s/pn, the signal-to-noise ratio.
For other target models, equivalent PDFs of target-plus-noise must be derived. For example, a non-
fading target in noise results in a Rice PDF [33].
If the returns include clutter, then the clutter to noise ratio can be determined by replacing the target
RCS by that of the clutter return, σc. As described in Section 2.11.2.1.1, for surface distributed clutter,
σc = σ 0 Ac. Appropriate values of σ 0 are usually derived from empirical models, as described in Section
2.11.2.2.1 and 2.11.2.3.1. The values of Pfa and Pd must now be calculated for a return that includes
clutter-plus-noise. This requires a knowledge of the PDFs of the envelope of clutter-plus-noise and
target-plus-clutter-plus-noise, which can sometimes be difﬁcult to derive. For a known clutter PDF, the
PDF of clutter-plus-noise will generally have to be calculated numerically. In the particular case of the
compound K distribution model, the PDF of clutter-plus-noise can be deﬁned exactly [80]. Similarly,
the PDF of the envelope of target-plus-clutter-plus-noise is required to calculate Pd. Again, this can be
calculated for the compound K distribution model for a wide range of target fading models [25].
2.11.5.1.1
Signal processing and design of detectors
The radar equation provides a means of calculating the signal-to-clutter-plus-noise ratio, SCNR, and the
clutter-to-noise ratio, CNR, for a single pulse return. For many radar systems, the returns from several
successive pulses are integrated, to beneﬁt from more radar power on the target. These pulses may
sometimes be at different frequencies (frequency agility). In a typical example, during a dwell on a
target, a pulse Doppler radar may transmit a burst of pulses with a ﬁxed PRF and frequency, followed by
successive bursts at different PRFs and frequencies. Returns from trains of pulses are used in subsequent
signal processing to improve target detection and discrimination against clutter and noise.
To calculate Pfa and Pd following detection processing in the radar requires knowledge of the effect of
the processing on the amplitude statistics immediately prior to the ﬁnal detection threshold or decision.
For coherent processing with Doppler ﬁlter banks (typically achieved with an FFT over a ﬁxed frequency
burst of pulses), the Doppler spectra of target and clutter must be known to calculate the subsequent
SCNR and CNR in each Doppler ﬁlter. The outputs from each Doppler ﬁlter may then be detected and
then subsequent detections from successive bursts may be non-coherently integrated. Again the PDF of
the integrated signals must be calculated. In the case of clutter, it is very important to understand any

2.11.5 Use of Clutter Models in Radar Design and Analysis
587
correlation between the samples that are being integrated. Thermal noise will always be independent
from pulse to pulse. For clutter, the situation is more complex, with different components ﬂuctuating
at different rates. For example, pulse-to-pulse frequency agility can decorrelate the speckle component
of sea clutter [10], but the underlying mean level component is not affected and may effectively be
constant over a dwell. The target returns may also ﬂuctuate at different rates over a dwell. This type of
behavior is usually approximated by estimating the effective number of independent samples observed
over a dwell period. Again, for the compound K distribution model it is possible to model the effects
of pulse-to-pulse integration taking into account the effective number of independent samples of target,
thermal noise and the two clutter components, each of which may be different [25].
The design of optimum and suboptimum, adaptive and non-adaptive, coherent and non-coherent
detectors for detecting point-targets embedded in Gaussian disturbance is a mature and well understood
topic. There are many excellent books and papers addressing different aspect of the problem. Some
references are listed in [81]. Conversely, the detection of targets embedded in non-Gaussian clutter
is a less mature topic, even though there are many references published in the last 20 years (see for
instance [19,22,25,82–92] and references therein). The main problems that must be taken into account
are the estimation of the disturbance covariance matrix, the estimation of the parameters of the clutter
distribution [17,25,93–95], the non-stationarity of the clutter in the case of sea scattering [96] and the
site-dependence of the clutter in the case of ground scattering [97,98]. New radar systems must be able
to rapidly adapt to changing conditions. Knowledge or estimation of clutter conditions can assist with
the selection of both transmitted waveforms and detection algorithms.
2.11.5.2 The speciﬁcation and measurement of radar performance
Another important role for clutter models relates to the speciﬁcation and measurement of real radar
performance. This is discussed in detail in [4,25,99–101].
Modern radars, especially those that use adaptive processing, are extremely complex and their per-
formance is difﬁcult to specify. A customer needs to ensure that those features of the radar that will
deﬁne its ability to achieve the required operational capability are adequately speciﬁed. The ability to
do this is in turn dependent upon a detailed understanding of the likely radar performance in different
environmental and operational conditions. The supplier, however, needs to have a simple set of per-
formance criteria upon which to base the radar design. One way to bridge this gap is to use a model
that relates the basic performance of the radar to its behavior in complex operational environments. An
important component of such models is likely to be the behavior of radar clutter.
A typical radar life cycle involves the use of models by the customer, the supplier and the user at
various times. Table 11.20 shows a typical range of applications for models [4] during a radar’s life.
2.11.5.2.1
Clutter models for performance acceptance and trials analysis
An increasingly important role for models is for the analysis of radar trials and the acceptance by a
customer of a new radar into service.
Acceptance trials are an integral part of any radar development program. These are intended to
demonstrate to the customer that the radar provides the required functionality and is “ﬁt for purpose.”
It is also usually desired that trials be used to quantify the key performance parameters of the radar
(e.g., detection range against a given target type). However, in many cases the reliable measurement

588
CHAPTER 11 Radar Clutter Modeling and Analysis
Table 11.20 Applications of Clutter Models during the Life-Cycle of a Radar
Modelers
Life-Cycle Stages
Requirements for Clutter Models
Customer
Requirements deﬁnition
Generic performance modeling; High
level synthetic environment simulations
Customer and potential
suppliers
Modeling of potential
performance
Performance predictions of different
designs Comparison of competing
designs;
Supplier
System and algorithm
design
Performance prediction; Algorithm design
(insight from models); Algorithm
simulation Hardware and software
stimulation.
Customer and supplier
Performance assessment
and acceptance trials
Analysis of trials data; comparison of
trials results with performance
predictions
Radar user
In-service tactics and
training
Simulation and hardware stimulation
Customer, suppler and user
In-service upgrades
Performance predictions; Algorithm
simulation; synthetic environment
simulation
of performance on trials is very difﬁcult and may at the very least require many hours of trials. This
is particularly true for radars required to detect very small targets in difﬁcult clutter conditions or for
radars that are continuously adapting their parameters (such as signal processing, waveforms, antenna
beamshape, etc.) in response to changing environmental conditions. The customer may specify that a
target of given RCS must be detected at a certain range, in particular environmental conditions (rainfall
rate, sea state, etc.). Given an agreed set of models, such a situation could be modeled and provide
reasonably accurate estimates of performance, within the limitations of the models used. However,
measurement of these parameters in a trial can be very difﬁcult. Even the apparently simple task of
measuring the noise-limited detection range of a moving target is not straightforward [102]. If the
original requirement was, say, to detect a target in sea state 3, in 1mm/h of rain, the radar designer
would have to put a very large margin on expected trials results to allow for uncertainty in assessing
whether sea state three is present, what the rainfall rate was (at the target and over the intervening path),
combined with the large range of clutter characteristics, such as σ 0 associated with a given sea state.
Although the radar designer would be able to model performance for given clutter model parameters,
it would not usually be possible to relate these to the conditions actually prevailing on a trial.
One solution is to combine trials measurements with modeling and factory measurements. Factory
measurements can determine the basic radar parameters that determine noise-limited performance in,
say, clear air. Modeling can predict the expected mean performance for a wide range of target sizes
and clutter characteristics, which could never be tested in practical trials of reasonable duration. The
empirical models that are used in radar design have themselves been developed from many hours of trials
data, representing an average expected conditions that do not then have to be reproduced in acceptance

2.11.6 Conclusions
589
trials. Then on a trial, detection performance can be measured (detection range, for example) for the
target and environmental conditions applying on the trial. At the same time, the raw radar returns can be
recorded for subsequent analysis. This analysis can yield the actual target and clutter characteristics that
were present, provided that the radar noise-limited performance is suitably calibrated. These observed
characteristics can then be input to the performance prediction model with the results compared with
those actually achieved in the trial.
If raw radar data is recorded on a trial, it should also be possible to replay it through the radar signal
processing, to assess the effects of different detection algorithms. In addition, it may be possible to
inject synthetic targets, to further investigate detection performance.
This type of approach, combining trials with performance prediction modeling, can allow quantitative
assessment of performance that would be effectively impossible from trials alone (due to uncertainty
over the prevailing conditions and the time and cost of extensive trials). Of course, it is far from
straightforward to achieve. It implies the measurement of detection ranges and false alarms rates from
trials observations, and the estimation of clutter and target characteristics from recorded data. Each
of these measurements is subject to its own measurement errors and the combined results would have
to be analyzed in detail to assess the buyer and seller risks [25] associated with eventual equipment
acceptance or rejection. The analysis methods and also the underlying performance prediction model
must be agreed in detail between customer and supplier (preferably well in advance of any acceptance
trials actually take place).
2.11.6 Conclusions
Modeling and analysis of clutter, as described in this tutorial, is a very important and complex matter. The
characteristics of clutter depend on the environmental conditions, the viewing geometry and the radar
characteristics. In general, there are not unique empirical or theoretical models that exhibit a satisfactory
ﬁt to real data under all possible conditions. Nevertheless, we have shown some general trends focusing
particularly on sea and ground clutter recorded by high resolution pulsed radars. For low grazing angles
and high spatial resolution, sea clutter amplitude statistics are not Gaussian and the returns exhibit some
distinct amplitude peaks, called spikes, that can be confused by a radar system for targets. The spikyness
of sea clutter increases with resolution and is more evident in HH polarized data. A good and ﬂexible
statistical model for sea clutter is the compound-Gaussian model, which comprises among its particular
cases the popular Rayleigh, Weibull and K models. One of the advantages of the compound-Gaussian
model is its mathematical tractability that helps in designing optimum and suboptimum detectors and
the possibility of describing separately the amplitude PDF and the correlation characteristics. For sea
clutter, this family of distributions has been found to give a good ﬁt over a wide range of conditions,
although this model may sometimes fail at very high spatial resolutions. These models can also be used
successfully for ground clutter, especially when the ground clutter is scattered by discrete objects as
pylons, fences, tree trunks. In some scenarios, when the ground surface is covered by wind-blown trees
and vegetation, the clutter still exhibits Gaussian statistics, even at high resolutions.
Concerning the clutter spectrum, many models have been proposed in the literature in the last 50years.
We have presented some results with AR models, Gaussian, power law and exponential PSDs. Again,
there is not a unique optimum model for all the conditions. The AR model is very ﬂexible and shows a

590
CHAPTER 11 Radar Clutter Modeling and Analysis
good ﬁtting with sea clutter and ground clutter in some cases, but the exponential one seems to be the
best for windblown tree clutter recorded by high dynamic-range radars.
Finally, we cannot make a “ﬁnal point” or a deﬁnite conclusion on this complex matter because the
study of clutter models is a continuing research topic. As radar systems improve, new features of clutter
and target scattering may be observed and new analyses are then necessary to develop more accurate
models of these characteristics and to improve the design of target detectors.
Relevant Theory: Signal Processing Theory
See Vol. 1, Chapter 4 Random Signals and Stochastic Processes
References
[1] F.E. Nathanson, Radar Design Principles, McGraw Hill, 1969.
[2] M.I. Skolnik, Introduction to Radar Systems, third ed., McGraw Hill, 2001.
[3] P. Tait, Introduction to Radar Target Recognition, IET, 2006.
[4] K.D. Ward, S.Watts, Use of sea clutter models in radar design and development, IET Radar Sonar Navig. 4
(2) (2010) 146–157 (Special Issue on Radar Clutter).
[5] S. Watts, Radar sea clutter modelling—recent progress and future challenges, in: International Radar Con-
ference 2008, Adelaide, September 2008 (Invited Paper).
[6] J.M. Blythe, D.E. Rice, W.L. Attwood, The CFE clutter model, with application to automatic detection,
Marconi Rev. 32 (1969) 185–206.
[7] G.R. Valenzuela, M.B. Lang, On the statistics of sea clutter, NRL Report 7349, 1971.
[8] G.V. Trunk, Radar properties of non-Rayleigh sea clutter, IEEE Trans. AES 8 (1972) 196–204.
[9] K.D. Ward, Compound representation of high resolution sea clutter, Electron. Lett. 17 (1981) 561–563.
[10] K.D. Ward, C.J. Baker, S. Watts, Maritime surveillance radar Part 1: radar scattering from the ocean surface,
Proc. IEE 137 (2) (1990) 51–62 (part F).
[11] T.J. Barnard, D.D. Weiner, Non-Gaussian clutter modeling with generalized spherically invariant random
vectors, IEEE Trans. Signal Process. 44 (10) (1996).
[12] E. Conte, M. Longo, Characterisation of radar clutter as a spherically invariant random process, IEE Proc.-F
134 (2) (1987) 191–197.
[13] E. Conte, A. De Maio, C. Galdi, Statistical analysis of real clutter at different range resolutions, IEEE Trans.
Aerosp. Electron. Syst. 40 (3) (2004) 903–918.
[14] F.A. Fay, J. Clarke, R.S. Peters, Weibull distribution applied to sea-clutter, in: Proceedings of the IEE
Conference Radar ’77, London, UK, 1977.
[15] A. Farina, F. Gini, M. Greco, L. Verrazzani, High resolution sea clutter data: a statistical analysis of recorded
live data, IEE Proc.-F 144 (3) (1997) 121–130.
[16] E. Jakeman, P.N. Pusey, A model for non-Rayleigh sea echo, IEEE Trans. Antenna Propag. AP-24 (1976)
806–814.
[17] M. Rangaswamy, D.D. Weiner, A. Ozturk, Non-Gaussian vector identiﬁcation using spherically invariant
random processes, IEEE Trans. Aerosp. Electron. Syst. 29 (1) (1993) 111–124.
[18] M. Rangaswamy, D.D. Weiner, A. Ozturk, Computer generation of correlated non-Gaussian radar clutter,
IEEE Trans. Aerosp. Electron. Sys. 31 (1) (1995) 106–115.
[19] M. Rangaswamy, J.H. Michels, D.D. Weiner, Multichannel detection algorithm for correlated non-Gaussian
random processes based on innovations, IEEE Trans. Signal Process. 43 (8) (1995) 1915–1922.

References
591
[20] M. Rangaswamy, J.H. Michels, A parametric multichannel detection for correlated non-Gaussian random
processes, in: Proceedings of the National Radar Conference, Syracuse, NY, USA, May 1997, pp. 349–354.
[21] M. Rangaswamy, J.H. Michels, Adaptive signal processing in non-Gaussian noise backgrounds, in: Proceed-
ings of the Nineth IEEE-SSAP Workshop, Portland, OR, September 1998.
[22] K.J. Sangston, K.R. Gerlach, Coherent detection of radar targets in a non-Gaussian background, IEEE Trans.
Aerosp. Electron. Syst. 30 (2) (1994) 330–340.
[23] M. Sekine, Y. Mao, Weibull Radar Clutter, Peter Peregrinus Ltd., London 1990.
[24] D. Middleton, New physical-statistical methods and models for clutter and reverberation: the KA distribution
and related probability structures, IEEE J. Oceanic Eng. 24 (3) (1999) 261–284.
[25] K.D. Ward, R.J.A. Tough, S. Watts, Sea Clutter: Scattering, the K Distribution and Radar Performance,
Institution of Engineering and Technology, 2006.
[26] V.W. Pidgeon, Doppler dependence of radar sea return, J. Geophys. Res. 73 (1968) 1333–1341.
[27] P.H.Y. Lee, J.D. Barter, K.L. Beach, C.L. Hindman, B.M. Lake, H. Rungaldier, J.C. Shelton, A.B. Williams,
R.Yee, H.C. Yuen, X-band microwave backscattering from ocean waves, J. Geophys. Res. 100 (C2) (1995)
2591–2611.
[28] P.H.Y. Lee, J.D. Barter, K.L. Beach, E. Caponi, C.L. Hindman, B.M. Lake, H. Rungaldier, J.C. Shelton,
Power spectral lineshapes of microwave radiation backscattered from sea surfaces at small grazing angles,
lEE Proc. F 142 (5) (1995) 252–258.
[29] J.B. Billingsley, A. Farina, F. Gini, M. Greco, L. Verrazzani, Statistical analyses of measured radar ground
clutter data, IEEE Trans. Aerosp. Electron. Syst. 35 (2) (1999) 579–593.
[30] S. Haykin, A. Steinhardt, Adaptive Radar Detection and Estimation, Wiley, New York, 1992.
[31] CSIR, small boat detection research, <http://www.csir.co.za/smallboatdetection/>.
[32] J.B. Billingsley, Low-Angle Radar Land Clutter—Measurements and Empirical Models, William Andrew
Publishing, Norwich, NY, 2002.
[33] D.K. Barton, Radar System Analysis and Modeling, Artech House, 2005.
[34] W.H.D. Long, D. Mooney, W.A. Skillman, Pulse Doppler radar, in: M. Skolnik (Ed.), Radar Handbook,
second ed., McGraw Hill, New York 1990, pp. 17.11–17.16 (Chapter 17).
[35] L. Rosenberg, D.J. Crisp, N.J. Stacy, Analysis of the kk-distribution with medium grazing angle sea-clutter,
IET Proc. Radar Sonar Navig. 4 (2010) 209–222.
[36] J.W. Wright, A new model for sea clutter, IEEE Trans. AP 16 (1968) 217–223.
[37] F.G. Bass, I.M. Fuks, A.E. Kalmykov, I.E. Ostrovsky, A.D. Rosenberg, Very high frequency radiowave
scattering by a disturbed sea surface, IEEE Trans. Antenna Propag. AP-16 (1968) 554–568.
[38] P. Gerstoft, L.T. Rogers, L.J.Wagner, W.S. Hodgkiss, Estimation of radio refractivity structure using radar
clutter, in: 30th International Conference on Radar Meteorology, München Germany, 19–24 July 2001.
[39] M.M. Horst, F.B. Dyer, M.T. Tuley, Radar sea clutter model, in: IEEE International Conference Antennas
and Propagation, November 1978, pp. 6–10.
[40] L.B. Wetzel, Sea Clutter, in: M. Skolnik (Ed.), Radar Handbook, second ed., McGraw Hill, New York, 1990
(Chapter 13).
[41] M. Greco, F. Bordoni, F. Gini, X-band sea clutter non-stationarity: the inﬂuence of long waves, IEEE J.
Ocean Eng. 29 (2) (2004) 269–283 (Special Issue on Non-Rayleigh Reverberation and Clutter).
[42] S. Watts, A new method for the simulation of coherent sea clutter, in: IEEE International Conference,
RadarCon 2011, May 2011.
[43] M.A. Ritchie, K. Woodbridge, A.G. Stove, Analysis of sea clutter distribution variation with Doppler using
the compound K-distribution, in: International Conference on IEEE Radar 2010, May 2010, pp. 495–499.
[44] R.R. Boothe, The Weibull distribution applied to the ground clutter backscattering coefﬁcient, US Army
Missile Command, RE-TR-69-15, ADA691109, 1969.
[45] M.W. Long, Radar reﬂectivity of Land and Sea, third ed., Artech House, 2001.

592
CHAPTER 11 Radar Clutter Modeling and Analysis
[46] R.K. Moore, Ground echo, in: M. Skolnik (Ed.), Radar Handbook, third ed., McGraw Hill, New York, 2008
(Chapter 16).
[47] F.T. Ulaby, M.C. Dobson, Handbook of Radar Scattering Statistics for Terrain, Artech House, Norwood MA,
1989.
[48] N.C. Currie, Clutter characteristics and effects, in: J.L. Eaves, E.K. Ready (Eds.), Principles of Modern
Radar, Van Nostrand Reinhold, New York, 1987, pp. 281–340.
[49] W.C. Morchin, Airborne Early Warning Radar, Artech House, 1990.
[50] L.V. Blake, Prediction of radar range, in: M.Skolnik (Ed.), Radar Handbook, ﬁrst ed., McGraw Hill, 1970.
[51] M. Greco, F. Gini, M. Rangaswamy, Statistical analysis of real polarimetric clutter data at different range
resolutions, IEE Proc. Radar Sonar Navig. (2006).
[52] B. Currie, Private Communications, October 2003.
[53] S.M. Kay, Fundamentals of Statistical Signal Processing, Estimation Theory, vol. I, Prentice Hall, 1993.
[54] E.L. Lehmann, Testing Statistical Hypotheses, second ed., Springer texts in statistics, New York, 2010.
[55] T. Nohara, S. Haykin, Canadian East coast radar trials and the K-distribution, IEE Proc.-F F138 (2) (1991)
80–88.
[56] B. Sadler, G.B. Giannakis, K.S. Lii, Estimation and detection in the presence of non-Gaussian noise, IEEE
Signal Process. 42 (10) (1994) 2729–2741.
[57] F. Gini, A Cumulant-based adaptive technique for coherent radar detection in a mixture of K-distributed
clutter and Gaussian disturbance, IEEE Trans. Signal Process. 45 (6) (1997) 1507–1519.
[58] F. Gini, M. Greco, Texture modelling, estimation, and validation using measured sea clutter data, IEE Proc.
Radar Sonar Navig. 149 (3) (2002).
[59] S. Haykin, R. Bakker, B.W. Currie, Uncovering nonlinear dynamics—the case study of sea clutter, in:
Proceedings of the IEEE 90 (5) (2002) 860–881.
[60] G.R. Valenzula, Theories for the interaction of electromagnetic waves and oceanic waves—a review, bound,
Layer Meteorol. 13 (1–4) (1978) 61–65.
[61] W.J. Plant, W.C. Keller, Evidence of Bragg scattering in microwave Doppler spectra of sea return, J. Geophys.
Res. 95 (C9) (1990) 16299–16310.
[62] W.J. Plant, W.C. Keller, The two-scale radar wave probe and SAR imagery of the ocean, J. Geophys. Res.
88 (C14) (1983) 9776–9784.
[63] C.L. Rino, E. Eckert, A. Siegel, T. Webster, A. Ochadlick, M. Rankin, J. Davis, X-band low-grazing-angle
ocean backscatter obtained during LOGAN 1993, IEEE J. Oceanic Eng. 22 (1) (1997) 18–26.
[64] A.D. Rozenberg, D.C. Quigley, W.K. Melville, Laboratory study of polarized microwave scattering by surface
waves at grazing incidence: the inﬂuence of long waves, IEEE Trans. Geosci. Remote Sens. 34 (6) (1996)
1331–1342.
[65] D. Walker, Experimentally motivated model for low grazing angle radar Doppler spectra of the sea surface,
IEE Proc. Radar Sonar Navig. 147 (3) (2000) 114–120.
[66] D. Walker, Doppler modelling of radar sea clutter, IEE Proc. Radar Sonar Navig. 148 (2) (2001).
[67] D.B. Trizna, A model for Doppler peak spectral shift for low grazing angle sea scatter, IEEE J. Oceanic Eng.
10 (4) (1985) 368–375.
[68] A.T. Jessup, W.K. Melville, W.C. Keller, Breaking waves affecting microwave backscatter. 1. Detection and
veriﬁcation, J. Geophys. Res. 96 (C11) (1991) 20547–20559.
[69] A. Drosopoulos, Description of the OHGR database, Technical Note No. 94–14, Defence Research Estab-
lishment Ottawa, December 1994.
[70] S. Haykin, in: Simon Haykin (Ed.), Advances in Spectrum Analysis and Array Processing, vol. I, Prentice
Hall, Englewood Cliffs, NJ 07632, 1991.
[71] C.W. Therrien, Discrete Random Signals and Statistical Signal Processing, Prentice Hall, Englewood Cliffs,
NJ 07632, 1992.

References
593
[72] P.J. Kim, R.I.Jennrich, Tables of the exact sampling distribution of the two sample Kolmogorov-Smimoff
criterion (Dmn < m < n), in: H.L. Harter, D.B. Owen (Eds.), Selected Tables in Mathematical Statistics, vol.
I, Providence, RI: American Mathematical Society, 1973.
[73] M. Greco, F. Gini, A. Farina, J.B. Billingsley, Validation of windblown ground clutter spectral shape by
analysis of clutter cancellation in the presence of measured clutter data, IEEE Trans. Aerosp. Electron. Syst.
37 (2) (2001) 538–548.
[74] K.S. Chen, A.K. Fung, Frequency dependence of backscattered signals from forest components, IEE Pro-
ceedings, Pt. F 142 (6) (1995) 310–315.
[75] R.J.A. Tough, K.D. Ward, The correlation properties of gamma and other non-Gaussain processes generated
by memoryless nonlinear transformation, J. Phys. D. 32 (1999) 3075–3084.
[76] A. Farina, A. Russo, F.R. Studer, Coherent radar detection in log-normal clutter, IEE Proc.-F 133 (1) (1986)
39–54.
[77] A. Farina, A. Russo, F. Scannapieco, S. Barbarossa, Theory of radar detection in coherent Weibull clutter,
IEE Proc.-F 134 (2) (1987) 174–190.
[78] Gene H. Golub, Charles F. Van Loan, Matrix computations, third ed., Johns Hopkins University Press, 1996
(Section 4.2, ISBN: 0-8018-5414-8).
[79] P. Swerling, Probability of detection for ﬂuctuating targets, IRE Trans. IT-6 (1960) 269–308.
[80] S. Watts, Radar detection prediction for targets in both K-distributed sea clutter and thermal noise, IEEE
Trans. AES-23 (2) (1987) 40–45.
[81] F. Gini, A. Farina, M. Greco, Selected list of references on non-Gaussian radar detection, IEEE Trans. Aerosp.
Electron. Syst. 37 (1) (2001) 329–359.
[82] E. Conte, G. Ricci, Performance prediction in compound-Gaussian clutter, IEEE Trans. Aerosp. Electron.
Syst. 30 (2) (1994) 611–616.
[83] E. Conte, M. Lops, G. Ricci, Asymptotically optimum radar detection in compound-Gaussian clutter, IEEE
Trans. Aerosp. Electron. Syst. 31 (2) (1995) 617–625.
[84] E. Conte, A. De Maio, C. Galdi, Signal detection in compound-Gaussian noise: Neyman-Pearson and CFAR
detectors, IEEE Trans. Signal Process. 48 (2) (2000) 419–428.
[85] F. Gini, M.V. Greco, A. Farina, P. Lombardo, Optimum and mismatched detection against K-distributed plus
Gaussian clutter, IEEE Trans. Aerosp. Electron. Syst. 34 (3) (1998) 860–876.
[86] F. Gini, M. Greco, A suboptimum approach to adaptive coherent radar detection in compound-Gaussian
clutter, IEEE Trans. Aerosp. Electron. Syst. 35 (3) (1999) 1095–1104.
[87] F. Gini, M. Greco, A. Farina, Clairvoyant and adaptive signal detection in non-Gaussian clutter: a data-
dependent threshold interpretation, IEEE Trans. Signal Process. 47 (6) (1999) 1522–1531.
[88] S. Haykin, D.J. Thomson, Signal detection in nonstationary environment reformulated as an adaptive pattern
classiﬁcation problem, Proceedings of the IEEE 86 (11) (1998) 2325–2344.
[89] C.D. Richmond, Performance of a class of adaptive detection algorithms in non-homogeneous environment,
IEEE Trans. Signal Process. 48 (5) (2000) 1248–1262.
[90] K.J. Sangston, F. Gini, M. Greco, A. Farina, Structures for optimum and suboptimal coherent radar detection
in compound-Gaussian clutter, IEEE Trans. Aerosp. Electron. Syst. 35 (2) (1999) 445–458.
[91] K.J. Sangston, F. Gini, M. Greco, Coherent radar detection in heavy-tailed compound-Gaussian clutter, IEEE
Trans. Aerosp. Electron. Syst. 42 (1) (2012) 64–77.
[92] S. Watts, C.J. Baker, K.D. Ward, Maritime surveillance radar. Part 2: Detection performance prediction in
sea clutter, in: IEE Proceedings-F, vol. 137, April 1990, pp. 63–72.
[93] D.R. Iskander, A.M. Zoubir, Estimation of the parameters of the K-distribution using higher order and
fractional moments, IEEE Trans. Aerosp. Electron. Syst. 35 (4) (1999) 1453–1457.
[94] P. Lombardo, C.J. Oliver, Estimation of texture parameters in K-distributed clutter, IEE Proc. F 141 (4)
(1994) 196–204.

594
CHAPTER 11 Radar Clutter Modeling and Analysis
[95] R.S. Raghavan, A method for estimating parameters of K-distributed clutter, IEEE Trans. Aerosp. Electron.
Syst. 27 (2) (1991) 238–246.
[96] M. Greco, P.Stinco, F. Gini, M. Rangaswamy, Impact of sea clutter non-stationarity on disturbance covariance
matrix estimation and CFAR detector performance, IEEE Trans. Aerosp. Electron. Syst. 46 (3) (2010) 1502–
1513.
[97] H.D. Grifﬁths, Knowledge-based solutions as they apply to the general radar problem, in: Proceedings of
the RTO NATO Lecture Series 233 on Knowledge-Based Radar Signal and Data Processing, Rome, Italy,
6–7 November, 2003.
[98] M. Lops, Hybrid clutter-map/L-CFAR procedure for clutter rejection in nonhomogeneous environment, IEE
Proc.-F 143 (1996) 239–245.
[99] S. Watts, Speciﬁcation and measurement of performance for airborne maritime surveillance radars, in:
International Radar Conference 1999, Brest, 17–21 May, 1999 (Session 2.6).
[100] S. Watts, H.D. Grifﬁths, J.R. Holloway, A.M. Kinghorn, D.G. Money, D.J. Price, A.M. Whitehead, A.R.
Moore, M.A. Wood, D.J. Bannister, The speciﬁcation and measurement of radar performance, in: IEE
International Radar Conference 2002, 14–17 October 2002, IEE Publication No.490, pp. 542–546.
[101] S. Watts, H.D. Grifﬁths, J.R. Holloway, A.M. Kinghorn, D.G. Money, D.J. Price, A.M. Whitehead, A.R.
Moore, M.A. Wood, D.J. Bannister, The speciﬁcation and measurement of radar performance—future
research challenges, J. Defence Sci. 8 (2) (2003) 83–91.
[102] A.G. Stove, D.L. Hurd, Performance evaluation for modern radars, in: Proceedings of IEEE International
Radar Conference, Adelaide, September 2003, pp. 547–53 (paper 44).

12
CHAPTER
Space-Time Adaptive
Processing for Radar
William L. Melvin
Georgia Institute of Technology, Atlanta, GA, USA
2.12.1 Introduction
Space-time adaptive processing (STAP) is a two-dimensional, adaptive ﬁltering technique foundational
to modern radar system design and implementation. Generally, spatial sampling is given by the outputs
of an array of antenna elements (sometimes called “channels”); the Fourier transform of space yields
angle. There are essentially two time measurements in radar: fast-time and slow-time. Fast-time samples
correspond to outputs of the analog-to-digital converter abiding with the Nyquist rate for the reﬂected
radar waveform; the Fourier transform of fast-time is radio-frequency (RF), which relates to radar range.
The processor collects slow-time voltage samples at a given range realization from distinct, reﬂected,
pulsed transmissions; the Fourier transform of slow-time yields Doppler frequency. Depending on the
statistical properties of the interference source, either slow-time or fast-time is applicable. For example,
the adaptive suppression of ground clutter received by airborne or spaceborne radar requires joint
spatial and slow-time adaptivity since clutter returns appear correlated in the angle-Doppler domain,
but are uncorrelated in fast-time. Fast-time adaptive degrees of freedom play in role in wideband and
terrain-bounce interference mitigation in both aerospace and surface-based radar systems.
Suppose we consider adaptive mitigation of Doppler-spread ground clutter returns in further detail.
This problem arises in airborne and spaceborne radar systems searching for moving targets. The clut-
ter returns are generally much stronger than the target signal, in many cases by orders of magnitude,
thereby rendering detection in certain regions of the range-Doppler map virtually impossible using con-
ventional antenna beamforming and Doppler processing techniques. Spatial and Doppler beamforming
represent one-dimensional matched ﬁltering operations. The matched ﬁlter maximizes signal-to-noise
ratio (SNR), thereby maximizing probability of detection for a ﬁxed false alarm rate for uncorrelated,
circular Gaussian disturbance [1,2]. STAP is needed when clutter and radio frequency interference
(RFI)—colored noise—are present; the STAP applies a space-time weighting incorporating estimated
characteristics of the interference environment to asymptotically maximize signal-to-interference-plus-
noise ratio (SINR), a sufﬁcient condition to maximize the probability of detection for a ﬁxed false alarm
rate under the assumption the disturbance is circular Gaussian [3].
Fixed points on the Earth’s surface exhibit a Doppler frequency shift consistent with their angular
displacement from the platform velocity vector, vp. In turn, this angular displacement corresponds to
a speciﬁc angle of arrival at the antenna array. Thus, given a particular azimuth and elevation angle
in the antenna coordinate system, the clutter Doppler frequency is precisely speciﬁed, and vice versa.
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-396500-4.00012-0
© 2014 Elsevier Ltd. All rights reserved.
595

596
CHAPTER 12 Space-Time Adaptive Processing for Radar
The clutter angle-Doppler region of support is described as a ridge in airborne and spaceborne radar.
This ridge is a line in sidelooking radar, opens up into an ellipse for varying degrees of platform yaw, and
becomes a circle for the forward-looking array. Figure 12.1 provides example power spectral density
(PSD) and minimum variance distortionless response (MVDR) super-resolution plots of the clutter
angle-Doppler region of support for the side-looking array radar (SLAR), a forward-looking array radar
(FLAR), and an array with forty-ﬁve (45)◦of yaw. Typical radar parameters are used in this example
and will be described in further detail in subsequent sections.
The PSD plots are a result of classical, two-dimensional, Fourier analysis. Resolution is limited in
Fourier analysis by roughly the wavelength of the signal divided by the aperture length; to resolve more
closely spaced signals, either the wavelength must be decreased for a ﬁxed aperture size, or the physical
aperture must be increased for a ﬁxed wavelength. Super-resolution spectral estimators overcome the
diffraction limitations of Fourier-based methods, oftentimes providing resolution enhancement by a
factor of two to ﬁve, or even more. It turns out that STAP is intimately related to the MVDR spectrum,
as discussed in Section 2.12.2.2.2. Hence, STAP likewise exhibits super-resolution properties, enabling
it to detect slow moving targets buried in mainbeam clutter or targets closely spaced to other interference
sources.
As mentioned, STAP coherently combines spatial and temporal voltage samples from a particular
range realization using a data-dependent weighting to maximize SINR. The corresponding adaptive
ﬁlter frequency response exhibits sharp nulls along the clutter region of support while maximizing
the gain at another, speciﬁed angle-Doppler location where a potential target might exist. A target
with a Doppler frequency outside of the mainlobe clutter Doppler spread (given as the highest power,
circular region in the PSD) is called exoclutter, whilst targets within the mainlobe clutter spread are
endoclutter. The STAP frequency response null is the inverse of the super-resolution contour shown in
Figure 12.1. Hence, STAP itself exhibits super-resolution properties, providing detection performance
within the diffraction limits of the traditional space-time aperture. This important characteristic makes
STAP invaluable on airborne and spaceborne platforms, enabling drastic reduction in antenna aperture
length for a desired minimum detectable velocity (MDV). The asymptotic STAP frequency responses
for each of the PSDs in Figure 12.1 are given in Figure 12.2. (The asymptotic STAP response is optimal,
since this is the weighting that precisely maximizes SINR.) The ﬁlter is tuned to broadside and 400 Hz
Doppler.
The MDV is the lowest target range-rate where sufﬁcient SINR exists to permit a speciﬁed probability
of detection for an acceptable probability of false alarm. Conversely, the MDV occurs at those points
where the loss in SINR due to clutter is maximally acceptable. Figure 12.3 provides an example of the
loss in SINR due to clutter for the radar array conﬁguration of Figures 12.1 and 12.2. SINR loss will
be described further in Section 2.12.2. Noise-limited performance is at 0 dB. The depth of the loss null
is related to the clutter-to-noise ratio (CNR).
2.12.1.1 Historical overview
Historical overviews of STAP are given in [4,5]. Reed [4] describes the earlier history of adaptive
arrays, whilst Klemm [5] covers more contemporary developments in STAP. Additionally, Entzminger
et al. [6] discusses the history and future of Joint STARS and ground moving target indication (GMTI),
identifying the central role of STAP in the success of both.

2.12.1 Introduction
597
FIGURE 12.1
Clutter angle-Doppler region of support for three array conﬁgurations. (a) PSD (left) and super-resolution
clutter image (right) for side-looking array, (b) PSD (left) and super-resolution clutter image (right) for forward-
looking array, and (c) PSD (left) and super-resolution clutter image (right) for array with 45◦of yaw.

598
CHAPTER 12 Space-Time Adaptive Processing for Radar
FIGURE 12.2
Comparison of STAP frequency response for the three scenarios in Figure 12.1. (a) Side-looking array,
(b) forward-looking array, and (c) array with 45◦of yaw.

2.12.1 Introduction
599
FIGURE 12.3
Clairvoyant SINR loss for example radar scenarios.
Table 12.1 is an historical accounting of STAP from the author’s perspective, as well as information
derived from [4–6]. As such, it attempts to convey some key developments and general trends, but is
necessarily incomplete. (Note: references to speciﬁc works are provided throughout the remainder of
this text. Additionally, Klemm [5] provides an excellent, historical accounting and perspective, and is
highly recommended to the interested reader.)
2.12.1.2 Organization
We organize the remaining discussion as follows:
•
Section 2.12.2 describes basic concepts, include target detection; different space-time optimal ﬁlter
formulations, including the maximum SINR ﬁlter, the minimum variance beamformer, and the
generalized sidelobe canceler; the sample matrix inversion (SMI) approach to adaptive ﬁltering;
and, key performance metrics, such as SINR loss.
•
Section 2.12.3 discusses clutter, RFI, target, and receiver space-time signal models.
•
Section 2.12.4 discusses different adaptive ﬁlter topologies, including several reduced-rank methods,
reduced-dimension STAP, and parametric adaptive matched ﬁltering.
•
Section 2.12.5 describes the utility of STAP to clutter suppression in airborne radar, as an example.
This section also includes benchmark results for some of the algorithms discussed in Section 2.12.4.
•
Much of current STAP research focuses on extending textbook discussion to real-world application.
Section 2.12.6 describes various STAP challenges and research areas, including the impact of hetero-
geneous or nonstationary clutter on detection performance and mitigating techniques, application
to airborne bistatic and conformal array radar, and knowledge-aided STAP. Each of these chal-
lenge areas predominantly focuses on issues surrounding effective estimation of the interference
covariance matrix.

600
CHAPTER 12 Space-Time Adaptive Processing for Radar
Table 12.1 Some Signiﬁcant Events in the History of STAP
Year
Topic
1957
Paul Howells of General Electric, Syracuse (now Lockheed-Martin), develops technique to
electronically scan antenna null in direction of a jammer
1959
Howells receives US Patent, “Intermediate frequency side-lobe canceller”
1962
Howells and Sidney Applebaum successfully test ﬁve-loop side-lobe canceller
1963
Howells and Applebaum, at Syracuse University Research Corp. (then Syracuse Research
Corp., now SRC) investigate application of adaptive techniques to radar, including
OTHR and BMD radar
1965 (1976)
Applebaum publishes “Adaptive Arrays,” SURC TR-66–001, later available in IEEE
Transactions on Antennas and Propagation in 1976
1969
Lloyd Grifﬁths publishes an adaptive algorithm for wideband antennas in Proceedings of
the IEEE
1969
V. Anderson, H. Cox and N. Owsley separately publish works on adaptive arrays for sonar
1971
R.T. Compton describes the application of adaptive arrays for communications systems in
Ohio State University Quarterly Rept. 3234–1, December 1971
1972
O.L. Frost publishes an adaptive algorithm for antenna arrays incorporating constraints
1972
Howells and Applebaum investigate adaptive radar for Airborne Early Warning (AEW) radar
1973
Larry Brennan and Irving Reed publish the seminal paper, “Theory of adaptive radar,” in
IEEE Trans. AES
1974
Reed, John Mallett and Brennan publish a paper describing the Sample Matrix Inverse
(SMI) method for adaptive arrays in IEEE Transactions on Aerospace and Electronic
Systems
1976
“Adaptive antenna systems,” published by Bernard Widrow et al. in IEEE Proceedings
1980
R.A. Monzingo and T.W. Miller publish the book Adaptive Arrays
1983
Rule for calculating clutter subspace dimension proposed by Richard Klemm in IEE
Proceedings Part F, Vol 130, February 1983
1991
Joint STARS prototypes deploy to Gulf War using adaptive clutter suppression methods
(1978, Pave Mover was pre-cursor)
1992
Klemm proposes spatial transform techniques for dimensionality reduction in paper on
antenna design for STAP
1992
Real-time STAP implementation by Alfonso Farina et al.
1992
Bob DiPietro presents post-Doppler STAP algorithm at Asilomar Conference on Signals,
Systems and Computers
1994
Post-Doppler, beamspace method proposed by Wang and Cai in IEEE Transactions on
Aerospace and Electronic Systems
1994
Jim Ward of MIT Lincoln Lab describes STAP techniques in ESC-TR-94–109, Space-Time
Adaptive Processing for Airborne Radar
1995
Air Force Rome Laboratory (now Air Force Research Laboratory) and Westinghouse (now
Northrop Grumman) collect twenty-four channel airborne radar data for STAP research
and development under the Multichannel Airborne Radar Measurements (MCARM)
program
Continued

2.12.1 Introduction
601
Table 12.1 Continued
Year
Topic
1998
Richard Klemm publishes ﬁrst STAP text book, Space-Time Adaptive Processing:
Principles and Applications
1999
IEE Electronics and Communications Engineering Journal (ECEJ) Special Issue on STAP
(Klemm, Ed.)
1999
STAP techniques for space-based radar, by Rabideau and Kogon, presented at IEEE
Radar Conference
1999
3-D STAP for hot and cold clutter mitigation appears in IEEE Trans. AES by Techau,
Guerci, Slocumb and Grifﬁths
2000
Bistatic STAP techniques appear in literature (numerous authors)
2000
IEEE Transactions on Aerospace and Electronic Systems Special Section on STAP
(William Melvin, Ed.)
2002
DARPA’s Knowledge-Aided Sensor Signal Processing & Expert Reasoning (KASSPER)
commences under leadership of Joseph Guerci
2003
Guerci publishes the book Space-Time Adaptive Processing for Radar
2004
IEE publishers release the book The Applications of Space-Time Processing (Klemm, Ed.)
c. 2005
Multi-Input, Multi-Output (MIMO) adaptive systems (numerous authors)
2006
IEEE Transactions on Aerospace and Electronic Systems, Special Section on
Knowledge-Aided Signal and Data Processing (Melvin, Guerci, Ed.)
2009
Cognitive Radar (Guerci)
•
A description of some additional, practical issues in STAP implementation is given in Section 2.12.7,
including maximum likelihood angle estimation and adaptive matched ﬁlter normalization.
•
In Section 2.12.8 we brieﬂy discuss some multichannel radar data collection efforts.
•
Summary comments are given in Section 2.12.9, along with notation and acronym lists in the
appendices.
2.12.1.3 Key points
STAP is a key component of modern radar. Some important points are given below:
•
STAPisreallyacatch-allphraseforavarietyofweightcalculationschemesandadaptivearchitectures.
•
Radar terminology usually includes two time measurements: fast-time, corresponding to a sample
rate consistent with the analog-to-digital converter clock speed and effectively measuring range;
and, slow-time, where the pulse repetition interval (PRI) deﬁnes the sample rate and separating
targets and clutter in Doppler frequency is the primary motivation. Space and slow-time are used
to mitigate ground clutter returns in aerospace radar, whereas space and fast-time are used to cope
with wideband RFI or multipath signals in aerospace or surface radar systems.
•
Herein, we focus on space and slow-time adaptive processing for clutter suppression. The ideas dis-
cussed are easily extended to other radar degrees of freedom (DoFs), include fast-time, polarization,
and multiple passes.

602
CHAPTER 12 Space-Time Adaptive Processing for Radar
•
Implementation of the optimal processor requires precise knowledge of the null-hypothesis covari-
ance matrix and the target space-time steering vector. The adaptive ﬁlter is an approximation to
the optimal processor, since neither covariance matrix nor steering vector are known in practice.
There are two primary factors leading to differences between adaptive and optimal ﬁlter outputs:
covariance matrix estimation error and unknown array manifold due to amplitude and phase error as
a function of frequency. Adaptive SINR loss describes the impact of both of these errors on detection
performance potential.
•
Current STAP research focuses on coupling basic STAP theory, physics-based models, and the
realities of the real-world operating environment to construct practical detection architectures.
•
STAP is applied at the coherent processing interval (CPI) level, often typically prior to noncoherent—
or post-detection—integration. Maximizing SINR is always effective at improving detection perfor-
mance, since the separation between the null and alternative hypothesis output probability density
functions increases.
•
Inmanyrespects,STAPdevelopmentisinitsearlystages,atleastfromanimplementationperspective.
It has been only recently that embedded computing power has improved to the point where more
ﬂexible, real-time STAP implementation is feasible.
2.12.2 Basic concepts
In this section we discuss radar space-time detection and several approaches to calculate the optimal
space-time weight vector: the maximum SINR ﬁlter, the minimum variance beamformer, the generalized
sidelobe canceler, and use of the Rayleigh quotient and generalized eigen-analysis. We introduce the
sample matrix inverse adaptive ﬁlter as the most common of the various adaptive implementations used
in radar application. We also discuss several important STAP metrics, such as clairvoyant and adaptive
SINR loss and improvement factor.
2.12.2.1 Detection
Suppose we collect M spatial samples across the antenna array for range realization k and each of the
N received pulses. These voltages are organized in a vector as
xk =

xT
s/k(1) xT
s/k(2) · · · xT
s/k(N)
T
,
(12.1)
where xk ∈C N Mx1 is the space-time snapshot and xs/k(n) ∈C Mx1 is the spatial snapshot for the nth
pulse. Two hypotheses correspond to (12.1): the null hypothesis, H0, where only additive interference
and noise are present; and, the alternative hypothesis, H1, which includes target presence in addition
to the components of the null hypothesis. Deﬁning ck ∈C N Mx1 as the clutter space-time snapshot,
jk ∈C N Mx1 as the RFI space-time snapshot, nk ∈C N Mx1 as the uncorrelated noise space-time
snapshot, and tk ∈C NMx1 the target space-time snapshot, we have
H0 : xk = ck + jk + nk,
H1 : xk = ck + jk + nk + tk = xk/H0 + tk.
(12.2)

2.12.2 Basic Concepts
603
FIGURE 12.4
Receiver operating characteristic (ROC) curves for nonﬂuctuating and Swerling 1 targets (probability of false
alarm given in legend).
The radar detection problem is to decide, given xk, which of the two hypotheses is most probable. It
is shown in [3] that maximizing SINR is equivalent to maximizing probability of detection for a ﬁxed
false alarm rate when xk/H0 is jointly complex normal with zero mean and covariance matrix, Rk, viz.
xk/H0 ∼C N(0, Rk). We wish to combine the elements of xk using a linear, ﬁnite impulse response
(FIR) ﬁlter, and compare the scalar to a threshold, ηT , to decide which hypothesis is a best ﬁt,
yk = wH
k xk =
N M

m=1

wk
∗
m

xk
∗
m
H1
>
<
H0
ηT ,
(12.3)
where wk is the space-time weight vector.
Figure 12.4 shows probability of detection, Pd, as a function of output SINR for varying probability
of false alarm, Pf a. The curves correspond to nonﬂuctuating and Swerling 1 target types for P f a = 10−5
and Pf a = 10−6. As seen, Pd increases monotonically with SINR. Also, it is seen that for reasonably
high Pd we generally need higher SINR to detect a Swerling 1 target at the same rate as the nonﬂuctuating
target due to fading; the SINR difference between Swerling 1 and nonﬂuctating detection curves is called
ﬂuctuation loss.
2.12.2.2 Space-time ﬁlter formulations
2.12.2.2.1
Maximum SINR ﬁlter
A primary objective in STAP is to approximate as closely as possible the optimal weighting that
maximizes SINR. By attempting to maximize output SINR, the STAP maximizes the probability of

604
CHAPTER 12 Space-Time Adaptive Processing for Radar
detection for a ﬁxed false alarm rate, as discussed in the prior section. We now formulate the optimal
weight vector.
The target snapshot is of the form, tk = αT ss-t(φ, θ, fd), where αT is a complex gain term propor-
tional to the square root of the target cross section, ss-t(φ, θ, fd) is the space-time steering vector of
dimension NM-by-one, φ is azimuth, θ is elevation, and fd is Doppler frequency. In the nonﬂuctuating
target case, αT is a constant, whereas in the Swerling 1 case, αT ∼CN

0, σ 2
T

, where σ 2
T is the target
signal variance [1,7,8]. The space-time steering vector is the Kronecker product of the spatial steering
vector, ss(φ, θ) ∈C Mx1, and the temporal steering vector, st( fd) ∈C Nx1. Generally, the spatial steer-
ing vector describes the phase variation among the spatial antenna channels (of common size and gain)
to a signal with a direction of arrival of

φ, θ

, whereas the temporal steering vector describes the phase
variation over the slow-time aperture to a signal with a particular range-rate [9–11]. If the aperture in
either space or time is uniformly sampled, the corresponding steering vector will be Vandermonde.
The output SINR of the FIR ﬁlter with weight vector, wk, is the ratio of target power, PT , to
interference-plus-noise power, PI+N, given as
SINR =
PT
PI+N
=
E

yT y∗
T

E

yk/H0 y∗
k/H0
 =
E

wH
k tktH
k wk

E

wH
k xk/H0xH
k/H0wk
 =
wH
k RTwk
wH
k Rk/H0wk
.
(12.4)
Using the deﬁnition for tk gives, RT = E

tktH
k

= σ 2
T ss-t(φ, θ, fd)sH
s-t(φ, θ, fd), and the Schwarz
Inequality lets us write (12.4) as
SINR = σ 2
T
		 ˜wH ˜s
		2
˜wH ˜w ≤σ 2
T

˜wH ˜w
 
˜sH ˜s

˜wH ˜w
.
(12.5)
In this case, ˜w = R1/2
k/H0wk and ˜s = R−1/2
k/H0ss-t(φ, θ, fd). By inspection, we ﬁnd that the right side of
the inequality achieves the upper bound when ˜w = μ˜s, thereby providing the solution for the optimal
weight vector. Through substitution, it follows that
wk = μR−1
k/H0ss-t(φ, θ, fd)
(12.6)
for arbitrary scalar, μ, is the weighting that yields maximal output SINR. When the disturbance is
uncorrelated noise, Rk = σ 2
n IN M, where σ 2
n is the noise power; then, (12.6) becomes the space-time
matched ﬁlter, viz. wk = μss-t(φ, θ, fd).
Inserting the optimal weight vector, wk = μR−1
k/H0ss-t(φ, θ, fd), into (12.4) yields the maximum
output SINR,
SINRMax = σ 2
T sH
s-t(φ, θ, fd)R−1
k/H0ss-t(φ, θ, fd).
(12.7)
For simplicity, and without loss in meaning, in subsequent sections we use Rk = Rk/H0.
The maximum SINR weight vector has the following interpretation. If xk ∼CN(0, Rk), then ˜xk =
R−1/2
k
xk is the whitened data vector, where ˜xk ∼CN(0, IN M) and IN M is the NM-by-NM identity
matrix. This results because
E

˜xk ˜xH
k

= R−1/2
k
E

xkxH
k

R−1/2
k
= R−1/2
k
RkR−1/2
k
= INM.
(12.8)

2.12.2 Basic Concepts
605
Then, the ﬁlter employing the maximum SINR weight vector is seen as a cascade of whitening and
warped matched ﬁltering operations,
yk = wH
k xk =

sH
s-t(φ, θ, fd)R−1/2
k
 
R−1/2
k
xk

= ˜sH
s-t ˜xk,
(12.9)
where ˜ss-t = R−1/2
k
ss-t(φ, θ, fd) is the warped matched ﬁlter accounting for the linear transformation
of the target signal through the whitening process and ss-t(φ, θ, fd) is the original matched ﬁlter weight
vector.
2.12.2.2.2
Minimum variance beamformer
The minimum variance (MV) space-time beam former is another common formulation leading to the
adaptive processor [12,13]. The MV beamformer employs a weight vector yielding minimal output
power subject to a linear constraint on the desired target spatial and temporal response:
min
wk E

yk y∗
k

subject to wH
k ss-t(φ, θ, fd) = g,
(12.10)
where g is a complex scalar. We can determine the weight vector satisfying the problem statement in
(12.10) using the method of Lagrange. Thus, deﬁne the following cost function
J = wH
k Rkwk + Re

˜λ∗
wH
k ss-t(φ, θ, fd) −g

,
(12.11)
where ˜λ∗is a complex Lagrangian multiplier and E[yk y∗
k ] = E[wH
k xkxH
k wk] = wH
k Rkwk. Taking the
gradient of (12.11) with respect to the conjugate of the weights and setting to zero gives
∇J = Rkwk + ˜λ∗ss-t(φ, θ, fd) = 0.
(12.12)
Solving (12.12) for the weight vector yields
wk = −˜λ∗R−1
k ss-t(φ, θ, fd).
(12.13)
Next, we ﬁnd by applying the constraint in (12.10) that
wH
k ss-t(φ, θ, fd) = −˜λsH
s-t(φ, θ, fd)R−1
k ss-t(φ, θ, fd) = g.
(12.14)
Solving (12.14) for ˜λ then gives
˜λ =
−g
sH
s-t(φ, θ, fd)R−1
k ss-t(φ, θ, fd)
.
(12.15)
The minimum variance weight vector follows from (12.13) and (12.15) as
wk =
g∗R−1
k ss-t(φ, θ, fd)
sH
s-t(φ, θ, fd)R−1
k ss-t(φ, θ, fd)
.
(12.16)

606
CHAPTER 12 Space-Time Adaptive Processing for Radar
Equation (12.16) abides by the form wk = μR−1
k ss-t(φ, θ, fd), where
μ =
g∗
sH
s-t(φ, θ, fd)R−1
k ss-t(φ, θ, fd)
.
(12.17)
Hence, (12.16) likewise yields maximal SINR.
Setting g = 1 is known as the distortionless response, and the corresponding weight vector yields
the minimum variance distortionless response (MVDR) beamformer. The output power of the MVDR
beamformer is given as
PMVDR = wH
k Rkwk =
1
sH
s-t(φ, θ, fd)R−1
k ss-t(φ, θ, fd)
.
(12.18)
The MVDR spectrum, as given in Figure 12.1, follows from (12.18) by scanning the space-time steering
vector in the denominator over the angle and Doppler locations of interest.
2.12.2.2.3
Generalized sidelobe canceler
The GSLC is a formulation that conveniently converts the minimum variance constrained beamformer
described in the preceding section into an unconstrained form [12,14]. Many prefer the GSLC inter-
pretation of STAP over the whitening ﬁlter-warped matched ﬁlter interpretation of Section 2.12.2.2.1;
since the GSLC implements the MV beamformer for the single linear constraint [14], this structure
likewise can be shown to maximize output SINR.
Figure 12.5 provides a block diagram of the GSLC. The top leg of the GSLC generates a qui-
escent response by forming a beam at the angle and Doppler of interest. A blocking matrix, BG =
null(ss-t(φ, θ, fd)), prevents the target signal from entering the lower leg; essentially, the blocking
matrix forms a notch ﬁlter tuned to (φ, θ, fd). With the desired signal absent from the lower leg, the
processor tunes the weight vector to provide a minimal mean square error (MMSE) estimate of the
interference in the top leg. In the ﬁnal step, the processor differences the desired signal, do/k, with
the estimate from the lower leg, ˆdo/k, to form the ﬁlter output, yk = do/k −ˆdo/k. Ideally, any large
residual at the output corresponds to an actual target.
The desired signal is given as
do/k = sH
s-t(φ, θ, fd)xk.
(12.19)
k
x
( , , )
df
φ θ
s-t
s
/
o k
d
/
ˆ
o k
d
o/k
x
MMSE/k
w
/
k
o k
y
ε
=
G
B
−
+
FIGURE 12.5
GSLC block diagram.

2.12.2 Basic Concepts
607
The signal vector in the lower leg is
x0/k = BGxk;
BG ∈C(NM−1)x NM;
x0/k ∈C(N M−1)x1.
(12.20)
Forming the quiescent response of (12.19) uses a single degree of freedom (DoF), resulting in the
reduced dimensionality of x0/k. By weighting the signal vector in the lower leg, the GSLC forms a
MMSE estimate of do/k as
ˆdo/k = wH
MMSE/kx0/k,
(12.21)
where the MMSE weight vector follows from the well-known Wiener-Hopf equation [12,13],
wMMSE/k = R−1
x0/krx0/kd.
(12.22)
The lower leg covariance matrix is
Rx0/k = E

x0/kxH
0/k

= BGRkBH
G
(12.23)
whilst the cross-correlation between lower and upper legs is
rx0/kd = E

x0/kd∗
o/k

= BGRkss-t(φ, θ, fd).
(12.24)
The GSLC ﬁlter output is then
yk = εo/k = do/k −ˆdo/k = sH
s-t(φ, θ, fd)xk −wH
MMSE/kx0/k
=

sH
s-t(φ, θ, fd) −wH
MMSE/kBG

xk.
(12.25)
Comparing (12.25) and (12.3), we identify
wGSLC/k = ss-t(φ, θ, fd) −BH
GwMMSE/k.
(12.26)
We compute the output SINR as the ratio of output signal power to interference-plus-noise power, as
in (12.4). The signal-only output power of the GSLC is
PT = E

wH
GSLC/ktktH
k wGSLC/k

= E

sH
s-t(φ, θ, fd)tktH
k ss-t(φ, θ, fd)

= σ 2
T
			sH
s-t(φ, θ, fd)ss-t(φ, θ, fd)
			
2
= σ 2
T

NM
2 ,
(12.27)
and the output interference-plus-noise power is
PI+N = E

wH
GSLC/kxk/H0xH
k/H0wGSLC/k

= wH
GSLC/kRkwGSLC/k.
(12.28)
The ratio of (12.27) and (12.28) is
SINRGSLC =
σ 2
T N 2M2
wH
GSLC/kRkwGSLC/k
=
σ 2
T N 2M2
σ 2
d −rH
xo/kdR−1
xo/krxo/kd
,
(12.29)

608
CHAPTER 12 Space-Time Adaptive Processing for Radar
where σ 2
d = E

|do/k|2
= sH
s-t(φ, θ, fd)Rkss-t(φ, θ, fd). We arrive at the denominator in (12.29) by
using (12.22)–(12.24),
wH
GSLC/kRkwGSLC/k = sH
s-t(φ, θ, fd)Rkss-t(φ, θ, fd) −sH
s-t(φ, θ, fd)RkBH
GwMMSE/k
−wH
MMSE/kBGRkss-t(φ, θ, fd) + wH
MMSE/kBGRkBH
GwMMSE/k
= σ 2
d −rH
x0/kdwMMSE/k −wH
MMSE/krx0/kd + wH
MMSE/kRx0/kwMMSE/k
= σ 2
d −rH
x0/kdR−1
x0/krx0/kd.
(12.30)
2.12.2.2.4
Rayleigh quotient
The optimal weight vector in Section 2.12.2.2.1 maximizes SINR. As seen from (12.4), for weight
vector wk, SINR is given as the ratio of quadratics, SINR = wH
k RTwk/wH
k Rkwk. Thus, our problem is
to ﬁnd the weight vector that maximizes this function. In accord with [15], and similar to our discussion
in Section 2.12.2.2.1, SINR is written as
SINR =
˜wH

R−1/2
k
H
RT R−1/2
k

˜w
˜wH ˜w
,
(12.31)
where ˜w = R1/2
k wk. The weight vector, w0, that maximizes this Rayleigh quotient form is known to
be proportional to the eigenvector vmax associated with the largest eigenvalue λmax of the matrix in the
numerator [13],
˜w ∝vmax =
max
Eigenvector

R−1/2
k
H
RTR−1/2
k

=
max
Eigenvector

R−1/2
k
RTR−1/2
k

,
(12.32)
and so
w0 ∝R−1/2
k
vmax = R−1/2
k
max
Eigenvector

R−1/2
k
RTR−1/2
k

.
(12.33)
Take the case where RT = σ 2
T ss-t(φ, θ, fd)sH
s-t(φ, θ, fd), as previously introduced in Section 2.12.2.2.1.
The maximum eigenvector in (12.32) must abide by
σ 2
T R−1/2
k
ss-t(φ, θ, fd)sH
s-t(φ, θ, fd)R−1/2
k
vmax = λmaxvmax.
(12.34)
The solution for vmax in (12.34) is thus seen to be
vmax = R−1/2
k
ss-t(φ, θ, fd),
(12.35)
and so, as expected,
w0 ∝R−1/2
k
vmax = R−1/2
k
R−1/2
k
ss-t(φ, θ, fd) = R−1
k ss-t(φ, θ, fd).
(12.36)
(Note: inserting (12.35) in (12.34) gives R−1/2
k
ss-t(φ, θ, fd) times a scalar on each side of the equation,
thereby satisfying the eigen-relation.)

2.12.2 Basic Concepts
609
By plugging wk = w0 found in (12.33) into (12.4), it is straightforward to show that the maximum
SINR is equal to λmax. In this vein, using (12.35) in (12.34) gives
λmax = σ 2
T sH
s-t(φ, θ, fd)R−1/2
k
R−1/2
k
ss-t(φ, θ, fd) = σ 2
T sH
s-t(φ, θ, fd)R−1
k ss-t(φ, θ, fd),
(12.37)
which is the desired result and matches the expression given in (12.7).
2.12.2.2.5
Generalized eigen-analysis
The second approach, described in [13], begins by noting that the solution to maximizing SINR is
equivalent to ﬁnding the maximum eigenvalue and associated eigenvector for the generalized Eigen-
problem
RTwk = λRkwk.
(12.38)
This can be solved as an ordinary eigen-equation by writing it as

R−1
k RT

wk = λwk.
(12.39)
Then, the weight vector that maximizes (12.4) is proportional to the eigenvector vmax associated with
the largest eigenvalue λmax of R−1
k RT,
w0 ∝vmax =
max
Eigenvector

R−1
k RT

.
(12.40)
The maximum eigenvalue of R−1
k RT is the maximum achievable SINR in (12.4).
If we again consider the case where RT = σ 2
T ss-t(φ, θ, fd)sH
s-t(φ, θ, fd), the generalized eigen-
analysis equation of (12.39) becomes

σ 2
T R−1
k ss-t(φ, θ, fd)sH
s-t(φ, θ, fd)

wk = λwk,
(12.41)
which, we ﬁnd, is satisﬁed when wk = w0 = R−1
k ss-t(φ, θ, fd). Substituting this eigenvector, wk, into
(12.41) gives,

σ 2
T sH
s-t(φ, θ, fd)R−1
k ss-t(φ, θ, fd)

R−1
k ss-t(φ, θ, fd) = λmaxR−1
k ss-t(φ, θ, fd),
(12.42)
from which it is seen the maximum eigenvalue, λmax, is identical to the result in (12.37) and also the
same as the maximum SINR expression found in Section 2.12.2.2.1.
2.12.2.2.6
Summary
Table 12.2 summarizes the weight vector formulation given in the prior sections.
2.12.2.3 Sample matrix inversion
All of the previously described approaches to ﬁlter design presume the availability of the interference-
plus-noise covariance matrix for the kth realization, Rk, and perfectly known target space-time steering

610
CHAPTER 12 Space-Time Adaptive Processing for Radar
Table 12.2 Summary of Space-Time Filter Formulations
Formulation
Objective
Weight Vector
Maximum SINR ﬁlter
Maximize output SINR
wk = μR−1
k/H0ss-t(φ, θ, fd )
Minimum variance (MV)
beamformer
Minimize output power subject
to linear constraint
maintaining gain in the look
direction
wk =
R−1
k ss-t(φ,θ,fd )
sH
s-t(φ,θ,fd )R−1
k ss-t(φ,θ,fd )
Generalized sidelobe canceler
Convert constrained
beamformer formulation to
unconstrained form
wk = wGSLC/k = ss-t(φ, θ, fd )
−BH
GwMMSE/k
Rayleigh quotient
Maximize output SINR
wk ∝R−1
k/H0ss-t(φ, θ, fd )
Generalized eigen-analysis
Maximize output SINR
wk ∝R−1
k/H0ss-t(φ, θ, fd )
vector, ss-t(φ, θ, fd). In practice, neither Rk nor ss-t(φ, θ, fd) is known. The disturbance covari-
ance matrix, Rk, changes as look-angle, platform location, and platform attitude change. Errors in
ss-t(φ, θ, fd) are generally a result of straddling the precise target spatial or temporal frequency when
searching over angle and Doppler, as well as system hardware errors that most greatly affect the spatial
component, ss(φ, θ). These system errors generally manifest as spatially varying, complex gain errors
due to factors such as spatial variation in element gain patterns, varying line lengths, radome and airframe
interactions, etc.
A number of techniques are available to adapt the weight vector, including least means square
(LMS) and recursive least squares (RLS) formulations [12]. However, the sample matrix inversion
(SMI) method is by far the most popular choice for radar application for two primary reasons: (1)
convergence of the SMI approach depends only on the number of samples used to estimate the unknown
interference-plus-noise covariance matrix, regardless of environmental conditions as long as the data
are independent and identically distributed (IID), for a system of speciﬁed DoFs; and, (2) prior to
processing, radar systems generally collect their data in blocks, called coherent processing intervals
(CPIs), and so a batch processing strategy using SMI is fully acceptable. In the SMI approach, the
optimal weight vector,
wk = μR−1
k ss–t(φ, θ, fd),
(12.43)
is simply replaced with the adaptive weight vector,
ˆwk = ˆμ ˆR−1
k vs-t(φ, θ, fd),
(12.44)
where ˆμ is a scalar that often depends on estimated quantities, ˆRk is the interference-plus-noise covari-
ance matrix estimate, and vs-t(φ, θ, fd) is the hypothesized space-time steering vector. In the absence
of straddle error, system errors dominate the error between ss-t(φ, θ, fd) and vs-t(φ, θ, fd). Generally,
array errors are explicitly modeled as
ss-t(φ, θ, fd) = st( fd) ⊗

εs(φ, θ) ⊙ss(φ, θ)

,
(12.45)

2.12.2 Basic Concepts
611
where εs(φ, θ) is the spatially-varying error between the ideal and actual array manifold, and ⊗and ⊙
are Kronecker (tensor) and Hadamard (element-wise) products, respectively.
In practice, εs(φ, θ) is “calibrated out” of the system using a variety of techniques, including array
tuning on an antenna range or in situ using the clutter background and navigation data to estimate differ-
encesbetweenidealandactualmulti-channelantennaresponses[16].Correspondingly,thehypothesized
space-time steering vector is then
vs-t(φ, θ, fd) = vt( fd) ⊗

ˆεs(φ, θ) ⊙vs(φ, θ)

,
(12.46)
where ˆεs(φ, θ) ∈C Mx1 is an estimate of the array error vector, and vt( fd) and vs(φ, θ, fd) are otherwise
the hypothesized temporal and spatial steering vectors accounting for potential straddle. Temporal errors
due to system non-ideality are commonly very small for the typical STAP CPI, and thus usually are not
considered further.
The complex baseband, pulse compressed, space-time snapshots comprise the voltage vectors for
the pth CPI,
XCPI(p) =
 x1
x2
· · · xL

∈C NMxL.
(12.47)
A particular realization, xk, chosen from amongst the space-time vectors in (12.47) for ﬁltering and
detection thresholding is called the cell-under-test (CUT); multiple CUTs form the primary data set. The
remaining vectors in (12.47) are available to estimate the unknown interference-plus-noise covariance
matrix and are called training or secondary data. The primary data set can be as small as a single CUT
with several adjacent realizations serving as guard cells; the purpose of the guard cell region is to prevent
any target energy from leaking into the training interval. Let Lg be the number of guard cells on either
side of the primary data region. Then, deﬁne the training set as
XTrain(p) = {xm}m⊂1:κ;m̸=k−Lg:k+Lg .
(12.48)
It is shown in [17] that if the data vectors comprising the training interval—the columns of (12.48)—are
IID with respect to the null-hypothesis of the CUT, a maximum likelihood estimate for Rk is
ˆRk = 1
κ XTrain(p)XH
Train(p) = 1
κ
κ

m=1
xmxH
m.
(12.49)
A fundamental question centers on how many training samples, κ, lead to an acceptable covariance
matrix estimate. This matter was addressed in [17] and considered in further detail in Section 2.12.2.4.2.
2.12.2.4 Metrics
In radar, performance is generally measured according to the speciﬁc goals of the collection and pro-
cessing mode. In moving target indication (MTI) radar, probability of detection, Pd, and false alarm rate
(FAR)—or probability of false alarm, Pf a—are the primary measures of performance. As discussed in
Section 2.12.2.1, the probability of detection is a monotonic function of output SINR for a ﬁxed false
alarm rate. Thus, measures of SINR are key to understanding achievable system performance. Among
these measures, SINR loss metrics are preferable, since they characterize performance over certain
independent variables—usually range rate or Doppler frequency, as shown in Figure 12.3—and are not

612
CHAPTER 12 Space-Time Adaptive Processing for Radar
tied to a speciﬁc radar cross section, thus folding into traditional link budget analysis. Speciﬁcally, given
SNR calculated from the radar range equation [1,7,8] or measured in the ﬁeld, the output SINR is
SINR(φ, θ, fd) = SNR(φ, θ) ·
Q

m=1
Ls,m(φ, θ, fd),
(12.50)
where Ls,m(φ, θ, fd) is the mth SINR loss term and 0 ≤Ls,m(φ, θ, fd) ≤1. (N.b., the term “SINR
loss” is widely used, even though such losses are negative valued on a decibel scale. This oftentimes
contradicts typical radar systems engineering usage. However, the losses are numerator terms in the
full link calculation.) In general, SINR losses vary with angle and Doppler, since the interference PSD
likewise varies.
In imaging radar, terrain-to-noise ratio (TNR) is a primary metric and is a function of multiplicative
noise ratio and SINR loss. We focus our attention speciﬁcally on MTI radar, but the basic metrics are
adaptable.
2.12.2.4.1
Clairvoyant SINR loss
Clairvoyant SINR loss is the ratio of output SINR for a ﬁlter implementation, wk, where all parameters
are known precisely, to the maximum SNR. Clairvoyant SINR is given as
Ls,1 = SINR
SNR =

σ 2
T
		wH
k ss-t(φ,θ, fd)
		2
wH
k Rkwk


σ 2
T
σ 2n N M

= σ 2
n
N M
		wH
k ss-t(φ, θ, fd)
		2
wH
k Rkwk
.
(12.51)
A few cases are worth considering:
Case 1—Noise-Limited Condition: In this case, Rk = σ 2
n IN M, where σ 2
n is the noise power. Then, the
maximum SINR weight vector,
wk = μR−1
k ss-t(φ, θ, fd) →wk = ss-t(φ, θ, fd),
(12.52)
and so
Ls,1 = σ 2
n
NM
		sH
s-t(φ, θ, fd)ss-t(φ, θ, fd)
		2
σ 2n sH
s-t(φ, θ, fd)ss-t(φ, θ, fd) = 1.
(12.53)
As expected, the optimal weighting defaults to the matched ﬁlter and there is no loss relative to the
bound deﬁned by the uncorrelated noise.
Case 2—Color-Limited Condition, Matched Filter Weights: Clairvoyant loss characterizes the impact
of interference on detection performance. Consider the case where the weight vector is set to the space-
time matched ﬁlter, wk = ss-t(φ, θ, fd). The clairvoyant SINR loss follows from (12.51) as
Ls,1 = σ 2
n
NM
		sH
s-t(φ, θ, fd)ss-t(φ, θ, fd)
		2
sH
s-t(φ, θ, fd)Rkss-t(φ, θ, fd) =
σ 2
n NM
PSD(φ, θ, fd) ≤1,
(12.54)
where PSD(φ, θ, fd) = sH
s-t(φ, θ, fd)Rkss-t(φ, θ, fd) is the power spectral density (PSD), equal to
the two-dimensional Fourier transform of the space-time covariance matrix [12]; Figure 12.1 provides

2.12.2 Basic Concepts
613
exampleclutter-plus-noisePSD plots. Equation(12.54) shows the impact of interference on performance
relative to the noise-limited case. Since the PSD is diffraction-limited (the mainlobe is determined by the
size of the space-time aperture), (12.54) characterizes the performance impacts of using the deterministic
matched ﬁlter. At those angles and Doppler frequencies away from the clutter angle-Doppler region of
support, the clairvoyant SINR loss approaches the noise-limited case.
Case 3—Color-Limited Condition, Optimal Weights: Using the maximum SINR weight vector, wk =
μR−1
k ss-t(φ, θ, fd), in (12.51), gives
Ls,1 = σ 2
n
NM
			sH
s-t(φ, θ, fd)R−1
k ss-t(φ, θ, fd)
			
2
sH
s-t(φ, θ, fd)R−1
k ss-t(φ, θ, fd)
= σ 2
n
NM P−1
MVDR(φ, θ, fd),
(12.55)
where PMVDR(φ, θ, fd) is a sample of the MVDR spectrum given in (12.18). Considering the MVDR
plots in Figure 12.1, (12.55) suggests regions of loss conﬁned to the sharp, super-resolution contours of
the clutter MVDR response (note the inverse in (12.55)). For this reason, STAP is able to detect targets in
close proximity to the center of the clutter angle-Doppler region of support. In contrast, (12.54) suggests
that SINR loss extends to the full width of the diffraction-limited spectrum when using nonadaptive
weights. Figure 12.25, given in Section 2.12.5.3, compares SINR loss for adaptive and nonadaptive
solutions, conﬁrming these observations.
2.12.2.4.2
Adaptive SINR loss
Adaptive SINR loss is the ratio of the output SINR for the ﬁlter using estimated quantities, ˆwk, to the
optimal ﬁlter output, wk, where all parameters are clairvoyantly known, viz.
Ls,2 =

ˆwH
k RT ˆwk
ˆwH
k Rk ˆwk
 
wH
k RTwk
wH
k Rkwk

.
(12.56)
Observe that when ˆwk = wk, Ls,2 = 1. Moreover, 0 ≤Ls,2 ≤1, since wk yields the maximum output
SINR and so the denominator in (12.56) will always be greater than or equal to the numerator.
Substituting (12.43) and (12.44) into (12.56) yields
Ls,2( ˆRk) = (SINR| ˆwk( ˆRk))/(SINRMax),
(12.57)
where SINRMaxis given by (12.7). Assuming ˆwk uses (12.49) in its calculation, as (12.57) suggests, then
determining κ is critical. This important matter was addressed in [17], where it is shown that (12.57) is
Beta distributed, with mean value
E[Ls,2( ˆRk)] = (κ + 2 −NM)/(κ + 1).
(12.58)
Setting (12.58) equal to 0.5 (or, 3 dB of loss) and solving for κ yields
κ = 2NM −3.
(12.59)
It is popular to refer to the result in (12.59), where setting κ roughly equal to twice the processor’s DoFs
yields 3 dB of loss, as the Reed-Mallett-Brennan (RMB) rule after its originators. In practice, 3 dB of
loss is substantial, and so choosing κ to be at least ﬁve times the processor’s DoF is desirable.

614
CHAPTER 12 Space-Time Adaptive Processing for Radar
The IID assumption inherent in the calculation of (12.57) sets the bound on performance for the
adaptive processor given κ homogeneous training samples. We address the impact of non-IID clutter
conditions in further detail in Section 2.12.5.
2.12.2.4.3
Improvement factor
Improvement factor (IF) is given as the ratio of the output SINR to the input (element-level) SINR
[18,19]. IF is given as
IF =

σ 2
T
		wH
k ss-t(φ,θ, fd)
		2
wH
k Rkwk


σ 2
T
σ 2
I +σ 2n

=
			wH
k ss-t(φ, θ, fd)
			
2 (σ 2
I + σ 2
n )
wH
k Rkwk
,
(12.60)
where σ 2
I is the input (element-level) interference power.
Case 1—Noise-Limited Condition: In the noise-limited case, Rk = σ 2
n INM and σ 2
I = 0, and consider-
ing the matched ﬁlter, wk = ss-t(φ, θ, fd), then
IF = σ 2
n
		sH
s-t(φ, θ, fd)ss-t(φ, θ, fd)
		2
σ 2n sH
s-t(φ, θ, fd)ss-t(φ, θ, fd)
= NM.
(12.61)
As expected, the improvement factor equals the space-time integration gain in this instance.
Case 2—Clutter-Limited Condition, Matched Filter Weights: In the clutter-limited case, with wk =
ss-t(φ, θ, fd), the improvement factor is
IF =
			sH
s-t(φ, θ, fd)ss-t(φ, θ, fd)
			
2
σ 2
I + σ 2
n
sH
s-t(φ, θ, fd)Rkss-t(φ, θ, fd) = (NM)2
σ 2
I + σ 2
n
PSD(φ, θ, fd) ≤NM.
(12.62)
The presence of interference in the PSD degrades the improvement factor. If we let Rk = σ 2
n INM and
σ 2
I = 0 in (12.62), we arrive at (12.61).
Case 3—Clutter-Limited Condition, Optimal Weights: Using the maximum SINR weight vector, wk =
μR−1
k ss-t(φ, θ, fd), in (12.60), gives
IF = (σ 2
I + σ 2
n )
			sH
s-t(φ, θ, fd)R−1
k ss-t(φ, θ, fd)
			
2
sH
s-t(φ, θ, fd)R−1
k ss-t(φ, θ, fd)
= (σ 2
I + σ 2
n )P−1
MVDR(φ, θ, fd).
(12.63)
This expression indicates reduced improvement for those angle-Doppler locations aligning with the clut-
ter, and otherwise good performance in proximity to the clutter response owing to the super-resolution
characteristic of PMVDR(φ, θ, fd) (see Figure 12.1).
2.12.2.4.4
Optimal and adaptive ﬁlter patterns
The ﬁlter gain pattern follows directly by evaluating the ﬁlter response over the angles (or spatial
frequencies) and Doppler frequencies of interest. Deﬁne the space-time steering matrix,
S =
 ss-t(φ(1), θ(1), fd(1)) ss-t(φ(2), θ(1), fd(1)) · · · ss-t(φ(P), θ(U), fd(V ))
,
(12.64)

2.12.3 Signal Models
615
for all {φ(1), φ(2), . . . , φ(P)} , {θ(1), θ(2), . . . , θ(U)}, and { fd(1), fd(2), . . . , fd(V )}. The optimal
gain pattern is
go = 20 log10
			wH
k S
			 ,
(12.65)
where wk is the optimal weighting given by (12.43). The adaptive gain pattern follows similarly as
ga = 20 log10
			 ˆwH
k S
			
(12.66)
with (12.44) yielding ˆwk.
Example gain patterns corresponding to the clutter environments shown in Figure 12.1 are given in
Figure 12.2. This gain pattern corresponds to (12.65).
2.12.3 Signal models
In this section we consider basic space-time signal and covariance models.
2.12.3.1 Clutter
A plethora of reﬂected signals from the Earth’s surface comprise what is known as radar ground clutter.
Ground clutter is a primary impediment to the detection of moving targets. The clutter signal is pre-
dominantly made up of signal reﬂections from distributed objects, such as returns from soil, forests,
ﬁelds, etc. Discrete clutter sources are less frequently occurring and spatially distributed with a partic-
ular density as a function of RCS, leading to strong, point-like returns. Since clutter discrete returns
occur relatively infrequently, their suppression is more challenging and they tend to drive false alarm
rate. Many discrete returns result from manmade objects, like buildings, water towers, utility poles, etc.
Fence lines, train tracks, and power lines are examples of extended sources of discrete clutter.
We discuss basic distributed and discrete clutter models.
2.12.3.1.1
Distributed clutter
Distributed clutter returns result from the integrated response of all scatterers within the range resolution
cell. A model for distributed clutter involves discretizing the range resolution cell into ﬁne angle bins
called clutter patches. The location of the angle bin relative to the platform velocity vector determines
the clutter patch Doppler frequency. The clutter snapshot then follows as the sum of the returns from
each of the individual patches.
Figure 12.6 depicts the discretized clutter patch model for distributed clutter. The antenna gain varies
around the range resolution annulus on the Earth’s surface in accordance with the array normal and
steering direction. It is common to model the clutter complex voltage as a Gaussian random variable due
to the constructive and destructive sum of the returns from the sub-scatterers comprising each resolution
cell. The patch clutter-to-noise ratio (CNR) at the channel-level (assuming matched channels) is
CNRk(p) =
 PtGt(φp, θp)
4πr2
 
 σk,p
4πr2
 
gc(φp, θp)λ2
4πkBToBr FnLr f

Gsp,
(12.67)

616
CHAPTER 12 Space-Time Adaptive Processing for Radar
FIGURE 12.6
Illustration of space-time clutter patch calculation (after [9],© 2003 IEEE).
where Pt is the transmit power, Gt(φp, θp) is the transmit gain in the pth direction of interest, r is the
slant range, σk,p is the pth clutter patch radar cross section, gc(φp, θp) is the receive channel gain, λ
is the center wavelength, kB is Boltzman’s constant, To is standard operating temperature, Br is the
receiver bandwidth, Fn is noise ﬁgure, Lrf is RF system loss, and Gsp is signal processing gain (the
pulse compression ratio, in this case) [1,7,8]. The clutter RCS is a function of the patch reﬂectivity,
σ 0
k,p, and area, Ap, where the area is determined to be a fraction of the resolution cell,
σk,p = σ 0
k,p Ap.
(12.68)
The constant gamma model is a common choice used to model reﬂectivity and is given as σ 0
k,p =
γk,p sin (ψp), where γk,p is a normalized reﬂectivity term dependent on the terrain type and ψp is the
grazing angle to the clutter patch [20]. The clutter patch power then follows by multiplying (12.67) by
the receiver noise, σ 2
n . The clutter voltage for the kth range bin and pth patch voltage is then
vk(p) = ςk,pσn

CNRk(p),
(12.69)
where ς ∼CN(0, 1) [9–11,18,19]. (If the response is non-ﬂuctuating, as in the case of a clutter discrete
subsequently discussed, then ς is a complex scalar with unity magnitude and uniformly distributed
phase.)
The patch voltage in (12.69) varies over the space-time aperture: there is a phase change from
channel-to-channel due to direction of arrival, described by the spatial steering vector; and, a phase
change from pulse-to-pulse due to the change in range-rate between the clutter patch and the radar
platform, described by the temporal steering vector. The clutter space-time snapshot then follows by
summing the voltages over the P patches for each of Q range ambiguities, where q = 0 is the ﬁrst

2.12.3 Signal Models
617
(unambiguous) range return
ck =
Q

q=0
P

p=1
vk(p, q)ss-t(φp(q), θp(q), fd,p(q)).
(12.70)
It is common to assume each patch is statistically independent, in which case the clutter covariance
matrix corresponding to (12.70) is
Rc/k =
Q

q=0
P

p=1
σ 2
c,k(p, q)ss-t(φp(q), θp(q), fd,p(q))sH
s-t(φp(q), θp(q), fd,p(q)),
(12.71)
where σ 2
c,k(p, q) = E
|vk(p, q)|2
is the clutter patch power and follows from (12.69). Equations
(12.70) and (12.71) form the basic ground clutter models.
The clutter voltage decorrelates, mainly in time due to intrinsic clutter motion (ICM). Windswept
vegetation and moving water are two cases where ICM results. The two basic models describing clutter
temporal decorrelation include the Billingsley model [21] and the Gaussian model [7,10]. The Billings-
ley model is most common for overland surveillance; it allows a certain amount of the clutter power to
decorrelate, say due to leaves ﬂuctuating in the breeze, whilst some of the clutter power is persistent,
thus modeling the tree trunk, for example. The Billingsley model leads to an exponential autocorrela-
tion function. In contrast, the Gaussian power spectrum of [7] leads to a Gaussian autocorrelation; the
Gaussian model leads to complete decorrelation over a speciﬁed time interval and is most appropriate
in marine or riverine environments. Dispersion (group delay) across the array is the common source of
spatial decorrelation; a sinc autocorrelation model is commonly chosen to model this effect, since it is
the inverse transform of a rectangular function in the frequency domain [22,23].
Given the aforementioned discussion, deﬁne the length-NM space-time correlation taper as as-t =
at ⊗as, with correlation matrix As-t = E

as-taH
s-t

= At ⊗As. At is the temporal correlation matrix
and As is the spatial correlation matrix. The resulting clutter covariance matrix is
Rc/k =
Q

q=0
P

p=1
σ 2
c,k(p, q)As-t,k(p, q) ⊙ss-t(φp(q), θp(q), fd,p(q))sH
s-t(φp(q), θp(q), fd,p(q)).
(12.72)
Generating space-time clutter snapshots exhibiting the correlation described by As-t typically involves
shaping white noise by multiplying the matrix square root of At and As by random vectors of length N
or M, where the elements of each vector are uncorrelated, zero mean, unity variance Gaussian variates.
2.12.3.1.2
Discrete clutter
Clutter discretes are strong returns that occur relatively infrequently and correspond to stationary, point-
like objects, such as parked vehicles, utility poles, water towers, etc. Generally, the RCS of the clutter
discrete is large relative to the RCS of a typical, resolved clutter patch. In some cases, the discrete clutter
can appear extended, such as in the case of a fence line or train track.
Figure 12.7 shows an example of discrete-like returns in a spotlight synthetic aperture radar (SAR)
image of the Mojave Desert Airport. The hangar edges and fence lines, as well as some aircraft on
the tarmac, are evident in the ﬁgure. Figure 12.8 shows an exceedance plot characterizing the typical

618
CHAPTER 12 Space-Time Adaptive Processing for Radar
FIGURE 12.7
Spotlight SAR image of Mojave Desert Airport at 1 m resolution ([24],© 2004 IEEE).
FIGURE 12.8
Example exceedance plot showing the impact of discrete clutter on STAP performance.
impact of clutter discretes on detection performance. (EFA is a post-Doppler STAP method described in
Section 2.12.4 and AMF refers to a STAP normalization discussed in Section 2.12.7.) In a homoge-
neous environment, the output of the STAP is well-behaved and the cumulative distribution follows the
expectedexponentially-shapedexceedance;incontrast,withdiscretespresent,thetailsoftheexceedance
plot are extended, indicating a requirement to raise the detection threshold to maintain a constant false
alarm rate.

2.12.3 Signal Models
619
FIGURE 12.9
Example of clutter discrete seeding.
A plausible discrete model involves laying out the spatial locations of discrete clutter of varying
densities. One way to do this is to specify the density per km2 for a particular discrete RCS and employ
a Poisson distribution to identify the random clutter discrete locations. An example of a range-angle
seeding of discrete clutter of varying RCS from 20 dBsm to 60 dBsm is show in Figure 12.9.
Since discrete clutter is stationary, the angular position uniquely speciﬁes Doppler frequency. In other
words, clutter discretes reside along the angle-Doppler region of support corresponding to stationary
objects. As in the case of distributed clutter, the discrete-to-noise ratio (DNR) follows in a form similar
to (12.67) for the lth discrete at range, rl, and angle (φl, θl), as
DNR(l) =

PtGt(φl, θl)
4πr2
l
 
σd,l
4πr2
l
 
gc(φl, θl)λ2
4πkBToBr FnLr f

Gsp.
(12.73)
As the discrete is considered point-like, the RCS is taken as nonﬂuctuating, whereas the phase is
uniformly distributed. The corresponding discrete space-time snapshot is
cd(l; k(l)) = e j2πuσn

DNR(l)ss-t(φl, θl, fd,l),
(12.74)
where u is a uniformly-distributed random variable between [0, 1] and k(l) is the range realization for
the lth clutter discrete. The discrete clutter is additive. The corresponding covariance matrix for each
discrete is
Rcd(l; k(l)) = σ 2
n DNR(l)ss-t(φl, θl, fd,l)sH
s-t(φl, θl, fd,l).
(12.75)
2.12.3.2 Radio frequency interference
Typically, RFI appears as a noise-like, in-band signal source. The RFI can be intentional or not. In the
narrowband case, the kth spatial snapshot for the ith RFI source and nth pulse is
js/k(n; i) = ωk(nT )ss(φi, θi),
(12.76)

620
CHAPTER 12 Space-Time Adaptive Processing for Radar
where ωk(nT ) is an uncorrelated source and T is the PRI. The waveform, ωk(nT ), is generally uncor-
related at nonzero lags, viz.,
E

ωk(nT )ω∗
k(mT )

= σ 2
J,i δ((n −m)T)
(12.77)
but otherwise fully correlated for very short time lags corresponding to propagation across the multi-
channel array, as (12.76) indicates (thus, E

ωk(nT )ω∗
j(nT )

= 0, for k ̸= j, in the narrowband case).
The corresponding spatial covariance matrix is
Rs/RFI(i) = σ 2
J,iss(φi, θi)sH
s (φi, θi) ∈C Mx M.
(12.78)
As a result of (12.77), the space-time covariance matrix is
RRFI(i) = E
⎡
⎣
⎡
⎣
js/k(0; i)
...
js/k((N −1; i)T )
⎤
⎦
jH
s/k(0; i) · · · jH
s/k((N −1)T ; i) 
⎤
⎦= IN ⊗Rs/RFI(i) ∈C N Mx N M.
(12.79)
Thus, a spatial null is sufﬁcient to remove the narrow-band RFI, as no temporal correlation
is present.
Each RFI source is considered statistically independent, so that for J sources, jk = J
i=1jk(i), where
jk ∈C N Mx1 is the space-time snapshot and RRFI = J
i=1RRFI(i).
As the fractional bandwidth—the ratio of waveform bandwidth to center frequency—of the receive
signal increases, dispersion occurs. Dispersion leads to decorrelation of the RFI over the receive array;
in this case, a single RFI signal appears as multiple, closely spaced sources in angle [23]. In general, the
wideband RFI suppression case is handled similar to the narrowband case through the use of subband
ﬁltering or the use of fast-time taps. In the former case, the subbanding is commonly implemented using
polyphase ﬁltering, allowing the processor to implement the narrowband canceler in each subband prior
to recombining [25].
2.12.3.3 Receiver noise
Uncorrelated noise sources—such as receiver noise or sky noise—are modeled as a white Gaussian
noise (WGN) disturbance, nk =

βk(m, nT )

m=1:M,n=0:N, where m and n are channel and pulse
indices, respectively, and βk(m, nT ) ∼CN(0, σ 2
n ). The waveform samples are assumed uncorrelated
such that
Rn = σ 2
n IN M,
(12.80)
where σ 2
n is the channel noise power. This noise source is also uncorrelated, independent, and identically
distributed over the range dimension.
2.12.3.4 Target
The target snapshot is generally modeled using both Swerling 1 and Swerling 2 statistics [1,7,8]. Swer-
ling 1 and Swerling 2 targets each exhibit voltages corresponding to a circular Gaussian distribution; the
Gaussian nature of the voltage distribution models target fading effects. The target voltage is assumed

2.12.3 Signal Models
621
perfectly correlated within the CPI, in accord with the Swerling 1 model, and uncorrelated from CPI-to-
CPI according to the Swerling 2 target model. Frequency hopping from CPI-to-CPI is a common reason
for target voltage decorrelation and is used to minimize the impact of target fading on detection perfor-
mance. STAP is applied on a CPI basis, as it is a coherent signal processing technique, with noncoherent
addition (NCA) applied to the STAP output—from CPI-to-CPI—to mitigate target fading effects.
Using the Swerling 1 target model, the target snapshot at the kth range, Doppler frequency, fd,T , and
angle, (φT , θT ), is
tk = ςT σn
√
SNRss-t( fd,T , φT , θT ),
(12.81)
where ςT ∼CN(0, 1) and SNR is the single channel, single pulse signal-to-noise ratio. The random
variable, ςT , models targeting fading resulting from subscatterers adding in and out of phase. As
indicated, to handle fading, it is common to frequency hop from CPI-to-CPI, in which case target
voltages appear decorrelated (Swerling 2).
Nonﬂuctuating, point-target analysis employs (12.81) with ςT →e j2πu, where u is uniformly
distributed between [0, 1]. Sometimes the nonﬂuctuating target model is used in analysis. However, the
Swerling 2 model is the preferred choice, with the Swerling 1 model applicable at the ﬁxed frequency,
CPI-level.
2.12.3.5 The space-time snapshot
The space-time snapshot for realization, k, is given by (12.2) with the addition of clutter discretes, where
the possibility of the single target case is
H0 : xk = ck +
D

l=1
cd(l; k(l)) + jk + nk,
H1 : xk = xk/H0 + tk,
(12.82)
where D is the total number of discrete scatterers and the snapshot terms, cd(l; k(l)), are only added
when k = k(l). The null-hypothesis covariance matrix corresponding to (12.82) is
Rk = Rc,k +
D

l=1
Rcd(l; k(l)) +
J

i=1
Rj(i) + Rn,
(12.83)
where, as expected, Rcd(l; k(l)) is included only for those terms where k = k(l).
Itiscommontoenvisionthecollectionofspace-timesnapshotsorganizedasspace-timedatamatrices,
Xk = [ xs,k(1) xs,k(2) · · · xs,k(N)] ∈C Mx N.
(12.84)
The spatial snapshot for pulse, n, is denoted as xs,k(n) ∈C Mx1; it results by removing N length-M
segments from xk and stacking them side-by-side. The pictorial of (12.84) is given in Figure 12.10
and is known as the radar datacube. Generally, the STAP operates on each space-time data matrix, or
slice, of the cube in Figure 12.10, while using slices at other ranges (or realizations) for training. We
subsequently describe various adaptive implementations. (Note: space/fast-time processing uses slices
along the pulse/fast-time domain and can train over the pulse dimension. As previously mentioned, we
focus on space/slow-time adaptivity, but the basic formulations of the next section generally apply to
any appropriately formatted data with the corresponding restrictions of each method.)

622
CHAPTER 12 Space-Time Adaptive Processing for Radar
RX
RX
RX
RX
RX
A/D
A/D
A/D
A/D
A/D
RX
RX
RX
RX
RX
RX
RX
RX
RX
RX
A/D
A/D
A/D
A/D
A/D
1
e
v
i
e
c
e
R
b
u
S
-
y
a
rr
A
Pulse
Range Sample
N
M   
1
1
L
fast time
slow time
Pre-processing here
FIGURE 12.10
Radar datacube (after [9],© 2003 IEEE).
2.12.4 Adaptive ﬁlter implementations
Section 2.12.2.2 describes space-time ﬁlter formulations. As seen from the discussion, all solutions are
similar, involving space-time weightings of the form of a covariance inverse and a steering vector to
implement the matched ﬁlter.
We now discuss three basic paradigms to implement the weighting strategies discussed in Section
2.12.2.2: reduced-rank STAP (RR-STAP), reduced-dimension STAP (RD-STAP), and parametric STAP.
2.12.4.1 Reduced-rank STAP
As seen from (12.78), each narrowband RFI source is rank-one. Distributed clutter is oftentimes of rank
signiﬁcantly less than the dimensionality of xk, viz. rλ ≪dim (xk). Through empirical analysis, the
clutter rank for a sidelooking radar with minimal yaw is approximated as
rλ ≈

N + (M −1)
vpT
d/2

,
(12.85)
where vp is the platform along-track velocity and d is the separation between channels of a uniform
linear array (ULA) [10]. The expression in (12.85) is known as Brennan’s Rule; a related rule is given by
Klemm [26]. Brennan’s rule is closely related to the number of independent antenna channel positions
during the collection interval; redundancy in the measurements lowers the rank, and in fact leads to
coloration of the clutter return. The idea behind RR-STAP is to essentially project the interference
subspace—those eigenspaces corresponding to larger eigenvalues above the noise ﬂoor—out of the
space-time snapshot.
The eigendecomposition of the space-time covariance matrix yields
Rk =
N M

m=1
λk/mqk/mqH
k/m = Qk/Ik/IQH
k/I + Qk/Nk/NQH
k/N,
(12.86)

2.12.4 Adaptive Filter Implementations
623
where λk/m is the mth eigenvalue corresponding to eigenvector qk/m ∈C N Mx1, k/I = diag

λk/m
P
m=1
represents the interference subspace eigenvalues, and k/N = diag

λk/m
N M
m=P+1 characterizes the
noise subspace eigenvalues. The interference eigenvectors have the special property that each span the
collection of interference steering vectors. Moreover, Q = [Qk/I Qk/N] is unitary, so
Qk/IQH
k/I + Qk/NQH
k/N = IN M.
(12.87)
We can write the distributed clutter-plus-noise part of (12.83) in a generic, simpliﬁed form
Rk =
˜N

p=1
σ 2
s/pss-t(φp, θp, fd/p)sH
s-t(φp, θp, fd/p) + σ 2
n IN M,
(12.88)
where ˜N is the number of signal sources and σ 2
s/p is the power for the pth signal source. While this
simpliﬁed covariance form suggests a model for clutter-plus-noise, the subsequent results are extensible
to other correlated sources. Then, from (12.88),
Rkqk/m = λk/mqk/m =
˜N

p=1
σ 2
s/pγk/m,pss-t(φp, θp, fd/p) + σ 2
n qk/m,
(12.89)
where
γk/m,p = sH
s-t(φp, θp, fd/p)qk/m.
(12.90)
Solving (12.89) for the mth eigenvector, qk/m,
qk/m =
˜N

p=1

σ 2
s/pγk/m,p
λk/m −σ 2n

ss-t(φp, θp, fd/p) =
˜N

p=1
αk/m,pss-t(φp, θp, fd/p),
(12.91)
where in this case
αk/m,p = σ 2s/pγk/m,p
λk/m −σ 2n
.
(12.92)
Naturally, these equations are only valid for the dominant subspace, λk/m −σ 2
n > 0. Equation (12.91)
shows qk/m ∈span

ss-t(φp, θp, fd/p)
 ˜N
p=1

.
Also, it is known that any wide-sense stationary (WSS) process with zero mean and covariance
matrix, Rk, can be written as a linear combination of the eigenvectors of Rk, via what is known as the
Karhunen-Loève Transform (KLT),
xk =
N M

m=1
ak/mqk/m,
(12.93)
where ak/m = qH
k/mxk are the Karhunen- Loève (KL) coefﬁcients [12].
The prior expressions, (12.86)–(12.93), provide necessary mathematical background for our subse-
quent discussion on RR-STAP methods.

624
CHAPTER 12 Space-Time Adaptive Processing for Radar
Motivation for RR-STAP includes the following:
•
Clutter and jamming tend to be of low numerical rank and the processor explicitly removes only
those signal subspaces corresponding to interference.
•
The eigendecomposition maximally compresses the interference into the fewest basis vectors [12].
•
The RMB rule applies to the RR-STAP case, with rank replacing DoFs in the formulation, viz.
training over twice the rank yields roughly 3 dB loss on average [27].
In effect, RR-STAP is a weight calculation strategy. There are challenges implementing RR-STAP,
including high computational burden and difﬁculties in rank determination. Nevertheless, RR-STAP
methods hold meaningful insight and, in some cases, are useful in weight vector determination.
2.12.4.1.1
Adaptive beamformer pattern synthesis
It is shown in [28] that (12.43) can be written
wk = μR−1
k ss-t(φ, θ, fd) = μ
λ0

ss-t(φ, θ, fd) −
N M

m=1
λk/m −λ0
λk/m
ϑk/mqk/m

,
(12.94)
where λ0 = min

λk/m

∀m

is the noise-ﬂoor eigenvalue level and ϑk/m = qH
k/mss-t(φ, θ, fd) is the
projection of the mth eigenvector onto the quiescent pattern. As seen from (12.94), the STAP response
appears as a notching of the space-time beampattern given by ss-t(φ, θ, fd) by the weighted, interference
eigenvectors. When λk/m = λ0, no subtraction occurs, since the corresponding eigenvector lies in the
noise subspace.
Naturally, (12.94) applies to the SMI formulation of (12.44), and can provide robustness in the
presence of training sample support limitations if the interference rank is known (which is usually only
practical for strong interferers). Speciﬁcally, running the sum in (12.94) only over rλ ≪N M subspaces
leads to adaptive pattern robustness, since low sample support tends to predominantly perturb the noise
subspace; the perturbed noise subspace estimate leads to poor adaptive sidelobe performance when the
sum in (12.94) is run over all values of the index, m.
2.12.4.1.2
Principle components inverse
The idea behind principle components inverse (PCI) is to apply an orthogonal projection to xk, and then
apply a matched ﬁlter to the remaining transformed data [29]. The PCI formulation starts by writing
(12.94) applied to the data as
yk = μsH
s-t(φ, θ, fd)
λ0

IN M −
N M

m=1
λk/m −λ0
λk/m
qk/mqH
k/m

xk.
(12.95)
Then, for the P ≪N M eigenvalues where λm/k ≫λ0,
yk ≈sH
s-t(φ, θ, fd)
λ0

IN M −
P≪N M

m=1
qk/mqH
k/m

xk = sH
s-t(φ, θ, fd)
λ0
˜xk.
(12.96)

2.12.4 Adaptive Filter Implementations
625
We see that
˜xk =

IN M −
P≪N M

m=1
qk/mqH
k/m

xk
e.g.
= xk −ak/1qk/1 −ak/2qk/2,
(12.97)
where, for the case of P = 2 as an example, (12.97) shows the coherent removal of qk/1 and qk/2. The
term in brackets in (12.97) is called an orthogonal projection for this reason.
2.12.4.1.3
Eigencanceler
Haimovich [30] gives two different developments; one of these essentially leads to (12.96) via an
alternate route.
The minimum power eigencanceler (MPE) weighting results from
min
wk wH
k Rkwk such that QH
k/Iwk = 0 and CHwk = f,
(12.98)
where C is a constraint matrix and f is a desired response vector. The solution to (12.98) is shown in
[30] to be
wk/EC-MPE = Qk/N−1
k/NQH
k/NC

CHQk/N−1
k/NQH
k/NC
−1
f.
(12.99)
For the case where C = ss-t(φ, θ, fd) and f = g, (12.99) takes the form
wk/EC-MPE = μ0Qk/N−1
k/NQH
k/Nss-t(φ, θ, fd)
(12.100)
with μ0 =

sH
s-t(φ, θ, fd)Qk/N−1
k/NQH
k/Nss-t(φ, θ, fd)
−1
g a scalar. The weight vector in (12.100) lies
entirely in the noise subspace—as required by (12.98)—and will, by virtue of the orthonormal property
of the set of eigenvectors, annihilate the clutter subspace.
The minimum norm eigencanceler (MNE) is formulated as
min
wk wH
k wk subject to QH
k/Iwk = 0 and CHwk = f.
(12.101)
The MNE weight vector is then shown in [30] to be
wk/EC-MNE = Qk/NQH
k/NC

CHQk/NQH
k/NC
−1
f.
(12.102)
Again, for the case where C = ss-t(φ, θ, fd) and f = g, and using (12.87), we see (12.102) can be
written in the same form as PCI,
wk/EC-MNE = μ1

IN M −Qk/IQH
k/I

ss-t(φ, θ, fd)
(12.103)
with μ1 =

sH
s-t(φ, θ, fd)Qk/NQH
k/Nss-t(φ, θ, fd)
−1
g a scaling that replaces 1/λ0 in (12.96). Using
(12.87), the expression in (12.103) can be written
wk/EC-MNE = μ1Qk/NQH
k/Nss-t(φ, θ, fd),
(12.104)
which closely relates to the MPE solution in (12.100) with the inverse eigenvalue weighting given
by −1
k/N absent. It is known that limited training sample support leads to perturbed estimates of the
noise eigenvalues appearing along the diagonal of k/N. For this reason, the MNE provides robustness
relative to MPE when training data samples are lacking.

626
CHAPTER 12 Space-Time Adaptive Processing for Radar
2.12.4.1.4
Hung turner projection
The Hung Turner Projection (HTP) is applicable to RFI suppression [31]. While clutter mitigation is
paramount to our discussion, it is worth taking a moment to describe the HTP as a general tool in adaptive
ﬁlter implementation. Reducing computational burden associated with the eigendecomposition leading
to the eigenvalues and eigenvectors of the null-hypothesis covariance matrix is a primary goal.
The basic idea behind the HTP is to use the Gram-Schmidt method to characterize the interference
subspace. Speciﬁcally, suppose we identify J snapshots where J RFI sources are present,
xk = jk(1) + jk(2) + · · · + jk(J) + nk,
xk+1 = jk+1(1) + jk+1(2) + · · · + jk+1(J) + nk+1,
...
xk+J−1 = jk+J−1(1) + jk+J−1(2) + · · · + jk+J−1(J) + nk+J−1.
(12.105)
Next, the modiﬁed Gram-Schmidt technique is applied to (12.105) to generate the orthonormal basis,
{v1, v2, . . . , vJ}, where vm ∈span {j1, j2, . . . , jJ}. Then, in accord with [31], the HTP weight vector is
chosen as wHTP = ¯wo
Q/
  ¯wo
Q
  
2, with
¯wo
Q = ¯wQ −
J

m=1

vH
m ¯wQ

vm,
(12.106)
and where ¯wQ is the quiescent weight vector.
2.12.4.1.5
Diagonal loading
Diagonal loading involves adding a scaled diagonal matrix to the covariance matrix estimate of
(12.49) [32],
ˆRk = 1
K
K

m=1
xmxH
m + σ 2
DLINM = ˆQk ˆk ˆQH
k + σ 2
DL ˆQk ˆQH
k = ˆQk

ˆk + σ 2
DLIN M

ˆQH
k ,
(12.107)
where σ 2
DL is the diagonal loading level and ˆQk and ˆk follow from the decomposition of the covariance
matrixestimate.Itiscommontoset0.1σ 2
n < σ 2
DL < 10σ 2
n ,withσ 2
DL = σ 2
n mosttypical.Primarybeneﬁts
of diagonal loading include improved conditioning of the covariance matrix estimate (which improves
the numerical stability of inversion routines) and compression of the range corresponding to the smallest
eigenvalues. This latter beneﬁt leads to a reduction in spurious sidelobes of the adapted pattern at the
expense of null depth. Effectively, diagonal loading removes some of the adaptivity of the system to
better condition the ﬁlter’s sidelobe response.
While often considered ad hoc, it turns out diagonal loading is a component of the optimal solution
to the constrained optimization,
min
wk wH
k Rkwk such that wH
k ss-t(φ, θ, fd) = 1 and wH
k wk ≤β2.
(12.108)
The Lagrangian for (12.108) is readily found to be
Lc = wH
k Rkwk + λ1

wH
k ss-t(φ, θ, fd) −1

+ λ2

wH
k wk −β2
,
(12.109)

2.12.4 Adaptive Filter Implementations
627
where λ1 and λ2 are Lagrangian multipliers. Taking the gradient of (12.109) with respect to the conjugate
of the weight vector and setting the result to zero yields [13]
∇wH Lc = Rkwk + λ1ss-t(φ, θ, fd) + λ2wk = 0.
(12.110)
Solving for the weight vector gives
wk = −λ1

Rk + λ2IN M
−1 ss-t(φ, θ, fd).
(12.111)
Using the linear constraint, it is seen that
λ1 =
−1
sH
s-t(φ, θ, fd)

Rk + λ2IN M
−1 ss-t(φ, θ, fd)
.
(12.112)
The resulting weight vector is
wk =

Rk + λ2IN M
−1 ss-t(φ, θ, fd)
sH
s-t(φ, θ, fd)

Rk + λ2IN M
−1 ss-t(φ, θ, fd)
.
(12.113)
From (12.113) we see that diagonal loading plays a key role in the solution to the constrained optimiza-
tion. In this case, λ2 is the diagonal loading level, σ 2
DL, mentioned previously. If the loading level is set
to zero, (12.113) defaults to the distortionless MV beamformer solution.
2.12.4.1.6
Cross spectral metric
Consider the GSLC structure of Figure 12.5. A principal components approximation to Rxo/k is
Rxo/k ≈
P

m=1
λxo/k;mqxo/k;mqH
xo/k;m
(12.114)
with, ideally, P ≪N M, and where λxo/k;m and qxo/k;m represent the mth eigenvalue and eigenvector
of the GSLC lower leg covariance matrix. Then,
wMMSE-PC/k =
P

m=1
qH
xo/k;mrxo/kdo/H0
λxo/k;m

qxo/k;m.
(12.115)
The computational burden of the GSLC does not generally justify its use in practice. Improved sta-
tistical convergence is a potential advantage of the principal components decomposition of the GSLC
(PC-GSLC).
The cross spectral metric operates in a fashion similar to the PC-GSLC method, except now the
selection of the basis deﬁning the rank-reducing transformation is target signal-dependent [33]. The
error signal at the output of the GSLC follows as the difference between (12.19) and (12.21), viz.
εo/k = do/k −ˆdo/k.
(12.116)

628
CHAPTER 12 Space-Time Adaptive Processing for Radar
The corresponding MMSE is given as the expected value of the magnitude squared of (12.116),
E
		εo/k
		2
= E

εo/kε∗
o/k

= σ 2
do/H0 −rH
xo/kdo/H0R−1
xo/krxo/kdo/H0
= σ 2
do/H0 −rH
xo/kdo/H0
 N M

m=1
λ−1
xo/k;mqxo/k;mqH
xo/k;m

rxo/kdo/H0
= σ 2
do/H0 −
NM

m=1
λ−1
xo=k;m
			rH
xo/kdo/H0qxo/k;m
			
2
.
(12.117)
In this case, σ 2
do/H0 = E
		do/k
		2
, where no target signal energy is present in the upper leg (an
assumption that carries through in the calculation of the cross correlation vector, rxo/kdo/H0). When choos-
ingonlyPtermsinthesummationof(12.117),where P ≪N M,theprocessorattainsthelowestpossible
mean square error (MSE) by choosing subspaces with the largest cross-spectral metric terms, given as
CSMm =
			rH
xo/kdo/H0qxo/k;m
			
2
λxo/k;m
.
(12.118)
The target signal inﬂuences the selection via rxo/kdo/H0. Thus, the idea behind the CSM approach is to
select only those subspaces from Rxo/k that most greatly enhance performance.
A direct-form implementation of the CSM method is given in [34]. In this case, the objective involves
maximizing SINR by choosing the appropriate, signal-dependent, reduced-rank subspace (hence, the
analogous metric is called the SINR metric in [34]). Thus, decomposing output SINR in (12.7) using
the inverse of the eigendecomposition in (12.86) gives
SINRMax = σ 2
T sH
s-t(φ, θ, fd)
 N M

m=1
λ−1
k/mqk/mqH
k/m

ss-t(φ, θ, fd).
(12.119)
Maximizing SINR requires choosing the largest terms in (12.119) of the form,
CSMDFP;m =
		sH
s-t(φ, θ, fd)qk/m
		2
λk/m
,
(12.120)
where DFP signiﬁes “direct form processor” (i.e., the approach using a weight vector of the form given
in (12.43) or (12.44)). Thus, with limited sample support and uncertainty over the interference rank,
selecting the P ≪N M largest CSM terms of (12.120) leads to maximal output SINR. Commonly, then,
the CSM-DFP chooses the components in the noise subspace, but this is an artifact of the development
and not useful: terms with the smallest eigenvalues are generally chosen, with any signal-dependent
correlation meant to aid in selecting the most signiﬁcant terms lost in the formulation. To avoid this
scenario, [34] suggests choosing those terms maximally impacting the weight vector. In other words,
considering (12.94), selecting the P largest terms of
λk/m −λ0
λk/m
ϑk/mqk/m
(12.121)

2.12.4 Adaptive Filter Implementations
629
most greatlyimpacts theadaptiveprocess. Equation(12.121) is signal-dependent and forces the selection
to lie in the dominant subspace.
2.12.4.1.7
Multi-Stage Wiener Filter
The Multi-Stage Wiener Filter (MWF) is a truncated decomposition of the GSLC of Figure 12.5 [35]. Its
operation is best understood from the diagram in Figure 12.11, which shows a two-stage decomposition.
From this ﬁgure we see that the estimation stage is broken into a series of smaller problems, where the
weight vector is calculated as a scalar using the Wiener-Hopf equation [12,13] in each stage. The ﬁlter,
hi, is a normalized cross-correlation vector between its input, xi−1/k, and the output of the ﬁlter in the
preceding leg, di−1/k; the intent of choosing hi in this manner is to maximize the correlation between
the interference signal in each leg. Speciﬁcally,
hi =
rxi−1/kdi−1/k
  rxi−1/kdi−1/k
  
2
,
(12.122)
where rxi−1/kdi−1/k = E

xi−1/kd∗
i−1/k

. The blocking matrix, Bi, lies in the null space of hi (expect
for i = 0, where BG = B0 = null(ss-t(φ, θ, fd))) . The weights, wi, are scalars equal to the Wiener
weight minimizing the mean square error between di−1/k and ˆdi−1/k = w∗
i εi. In this ﬁgure, for the MWF
output to equal the GSLC output, the processor must calculate all quantities, including the vector weight,
wMWF,3 =

E

x2/kxH
2/k
−1
rx2/kd2/k. The MWF truncates the number of stages by simply dropping
the lower leg of the last stage, setting the vector weight to all zeros (i.e., wMWF,3 = 0) so that εNMWF =
dNMWF/k, where NMWF is the number of MWF stages. So, for NMWF = 2, ε2 = d2/k = hH
2 x1/k.
k
x
( , ,
)
df
φ θ
s-t
s
/
o k
d
/
ˆ
o k
d
o/k
x
/
k
o k
y
ε
=
G
B
1
h
1
B
2
h
2
B
+
MWF,3
w
*
2
w
*
1
w
+
2
ε
1
ε
1/k
d
2/k
d
1/k
x
2/k
x
o/k
x
/
ˆ
o k
d
−
MMSE/k
w
−
+
FIGURE 12.11
Multi-Stage Wiener Filter ﬂow diagram.

630
CHAPTER 12 Space-Time Adaptive Processing for Radar
In the adaptive version of the MWF, the processor replaces the known covariance matrices and
steering vectors with estimates. The quantities, hi, Bi, wi, and, naturally, εi, are all expressible as linear
transformations applied to Rk and ss-t(φ, θ, fd); in the adaptive ﬁlter, Rk →ˆRk and ss-t(φ, θ, fd) →
vs-t(φ, θ, fd). The implementation requires ﬁrst calculating and applying BG
=
B0
=
null(ss-t(φ, θ, fd)); next, the processor implements the ﬁrst stage, calculating h1, B1, and d1/k; with
these ﬁrst stage quantities in hand, the processor calculates the second stage quantities, h2, B2, and d2/k,
then third stage quantities, and so forth, working out to the last stage; then, as noted above, the error
signal in the last stage is set to εL = dL/k = hH
L xL−1/k, where i = L is the last stage; and, ﬁnally, the
scalar weights, wi, are solved from the outer (last) stage into the ﬁrst stage.
While the computational loading of the MWF is generally high, the target signal-dependent nature of
the stage decomposition identiﬁes the interference subspace most greatly impacting the MMSE through
the cross-correlation process, estimates it, and subtracts it out. This allows the MWF to converge towards
the optimal solution with minimal use of available training data.
2.12.4.2 Reduced-dimension STAP
Reduced-dimension STAP (RD-STAP) methods take advantage of the structure of the clutter angle-
Doppler region of support to minimize ﬁlter length, thus reducing computational burden and training
sample requirements. A taxonomy of RD-STAP methods, organized similarly to the discussion in [10],
is given in Figure 12.12.
RD-STAP methods apply deterministic, linear ﬁltering operations and dimensionality reduction
prior to adaptive ﬁltering. A linear transformation, T ∈C N Mx ˜P, where ˜P is the length of the reduced
SPACE-TIME
DATA
ANGLE-TIME
DATA
(BEAMSPACE
METHODS)
SPACE-DOPPLER
DATA
(POST-DOPPLER
METHODS)
ANGLE-DOPPLER
DATA
(POST-DOPPLER
BEAMSPACE
METHODS)
SPATIAL
FILTERING
DOPPLER
FILTERING
DOPPLER
FILTERING
SPATIAL
FILTERING
2-D
FILTERING
FIGURE 12.12
RD-STAP taxonomy.

2.12.4 Adaptive Filter Implementations
631
dimension, describes these deterministic operations. Starting with the space-time snapshot, xk, the
reduced-dimension snapshot is
˜xk = THxk ∈C ˜Px1.
(12.123)
Via this transformation, the null-hypothesis covariance matrix is
˜Rk = THRkT ∈C ˜Px ˜P
(12.124)
and the target steering vector becomes
˜sRD = THss-t(φ, θ, fd).
(12.125)
The corresponding optimal weighting follows from (12.43) as
˜wRD/k = ˜μ

THRkT
−1 
THss-t(φ, θ, fd)

.
(12.126)
The adaptive weighting usually follows by forming the sample covariance matrix of (12.49) from the
reduced-dimension data,
ˆ˜Rk = 1
˜κ
κ

m=1
THxmxH
mT,
(12.127)
forming its inverse, and using ˜vRD = THvs-t(φ, θ, fd) in place of (12.125), viz.
ˆwRD/k = ˆ˜μ ˆ˜R
−1
k ˜vRD.
(12.128)
In this case, ˆ˜μ is a scalar that usually depends on estimated quantities.
Motivations for RD-STAP include the following:
•
The clutter exhibits a highly structured angle-Doppler region of support, as shown in Figure 12.13.
In this ﬁgure, T1 and T2 are target locations and C1–C4 are clutter regions. Target T1 predominantly
competes with clutter located at C3, and a spatial null within the corresponding Doppler ﬁlter sufﬁces
to mitigate clutter. Clutter at other locations—such as at C1, C2, and C4—has no signiﬁcant bearing
on target detection. Alternately, target T2 is impacted by clutter in the region of C1 and C4; a
two-dimensional null, positioned in angle and Doppler, is needed to suppress mainlobe and near-in
sidelobe clutter.
•
The RMB rule of Section 2.12.2.4.2 applies to RD-STAP, with NM →˜P. It is not uncommon
to have 9 ≤˜P ≤50, whereas 500 ≤N M ≤5000 is reasonable. Thus, limited and potentially
heterogeneous or nonstationary training sample support is reduced by a factor of 10–100 or more.
•
The implicit inverse of the sample covariance matrix is O(N 3M3), being reduced to O( ˜P3) in the
RD-STAP case. For each halving of the processor’s DoFs, computational burden decreases by a
factor of eight. Real-time operation requires RD-STAP methods.

632
CHAPTER 12 Space-Time Adaptive Processing for Radar
2D 
Hanning 
Wt.
Transmit Direction
T1
T2
C1
C2
C3
C4
FIGURE 12.13
Description of RD-STAP beneﬁts.
2.12.4.2.1
Post-Doppler STAP
Of the various RD-STAP methods, post-Doppler STAP techniques are most popular. Post-Doppler STAP
is shown in the lower left and right of Figure 12.12, where the lower left box corresponds to the so-called
“channel space,” post-Doppler methods that operate on space-Doppler data, and the lower right box
characterizes the post-Doppler, (spatial) beamspace methods. The Extended Factored Algorithm (EFA)
is an example of a “channel space,” post-Doppler method [36]. In EFA, each channel is Doppler ﬁltered,
and then the adaptive weighting of (12.128) is applied to the transformed data vector,
˜xk = THxk
e.g.
=
fT
s,k(n −2) fT
s,k(n −1) fT
s,k(n) fT
s,k(n + 1) fT
s,k(n + 2)T ,
(12.129)
where fs,k(q) ∈C Mx1 is the spatial snapshot corresponding to the qth Doppler bin output (i.e., the
qth Doppler bin output from channel 1 through M stacked in a vector). Equation (12.129) shows, as an
example, the case of ﬁve adjacent Doppler bins. The EFA output for the kth range bin and nth Doppler
bin is then given by yEFA/k( fd) = ˆwH
RD/k ˜xk, where fd corresponds to the nth Doppler bin output.
Figure 12.14 depicts the EFA processing architecture, where wm,q is the EFA weight applied to the mth
channel and qth Doppler bin. This ﬁgure shows the case of processing three adjacent Doppler bins; EFA
typically employs three or ﬁve adjacent bins. The special case of one Doppler bin—where the processor
only generates a spatial null—is known as Factored Time-Space (FTS) [10].
Figure 12.15 describes EFA operation in the angle-Doppler domain. Each horizontal, rectangular box
corresponds to a Doppler ﬁlter extent. The circles correspond to null locations EFA is able to generate.
EFA can generate up to Nt M−1 nulls, where Nt is the number of temporal DoFs (the number of Doppler

2.12.4 Adaptive Filter Implementations
633
Doppler 
Processor
*
1,2
w
Doppler 
Processor
ADDER
Channel 1
Channel 2
*
1,1
w
*
1,3
w
*
2,2
w
*
2,1
w
*
2,3
w
Doppler 
Processor
Channel M
*
,2
M
w
*
,1
M
w
*
,3
M
w
EFA, ( )
k
d
y
f
FIGURE 12.14
Extended Factored Algorithm (EFA) implementation.
Doppler filters
T1
Null locations
FIGURE 12.15
EFA operation in the angle-Doppler domain.
bins used in the adaptive combiner). The target location, T1, is shown close to mainlobe clutter. Nulling
along the section of the clutter ridge in proximity to T1 is required for target detection. EFA is able
to effectively suppress the clutter local to the target position. Its performance benchmarks very close
to that of the space-time optimal solution, as will be shown in Section 2.12.5. FTS can generate up to
M −1 spatial nulls within the Doppler bin; as seen in this case, given the closeness of T1 to mainlobe
clutter, only nulling sidelobe clutter is insufﬁcient.
References [37,38] describe post-Doppler, (spatial) beamspace methods. The Joint Domain Local-
ized (JDL) algorithm generalizes EFA by applying a beamspace transformation prior to Doppler ﬁltering
in Figure 12.14. JDL then combines Ms spatial beams and Nt Doppler bins to suppress clutter, in a

634
CHAPTER 12 Space-Time Adaptive Processing for Radar
manner similar to a two-dimensional sidelobe canceler. For example, a common conﬁguration is Ms = 3
and Nt = 3; in this three beam conﬁguration, the processor uses the eight angle-Doppler beams sur-
rounding the center beam to estimate and coherently remove the clutter signal in this ninth angle-Doppler
direction of interest, thereby exploiting the structure of the clutter local to the target position. JDL perfor-
mance tends to benchmark well relative to the space-time optimal solution. A special case of JDL is given
in [38], where the Doppler ﬁltering is applied to sum and difference beams, and then “auxiliary” beams
about the sum beam and Doppler bin of interest are adapted to coherently remove the clutter signal. This
latter method has been called Sigma-Delta STAP. Reference [39] also includes germane discussion.
Additional post-Doppler STAP methods based on PRI designs are given in [10].
2.12.4.2.2
Pre-Doppler STAP
Pre-Doppler STAP—sometimes called adaptive displaced phase center antenna (ADPCA)—involves
processing overlapped sub-CPIs to mitigate clutter, then applying Doppler processing to the aggregated
output [10,40]. It has particular application in those situations where the clutter response decorrelates
during the course of the CPI, such as when the antenna array rotates. Figure 12.16 shows the pre-Doppler
STAP, or ADPCA, architecture for the three pulse case.
The corresponding ADPCA data snapshot for three pulses is simply
˜xk = THxk
e.g.
=
xT
s,k(n −1) xT
s,k(n) xT
s,k(n + 1) T .
(12.130)
Channel 1
Channel 2
Channel M
—1
z 
1
z—
*
1,
1
p
w
—
1
z—
1
z—
1
z—
1
z—
ADDER
Doppler 
Processor
*
1,p
w
*
1,
1
p
w
+
*
2,
1
p
w
—
*
2,p
w
*
2,
1
p
w
+
*
,
1
M p
w
—
*
,
M p
w
*
,
1
M p
w
+
FIGURE 12.16
Pre-Doppler STAP.

2.12.4 Adaptive Filter Implementations
635
The ADPCA weight vector is
ˆwadpca/k = ˆR−1
adpca/k
⎛
⎝
⎛
⎝
⎡
⎣
1
−2
1
⎤
⎦⊙
⎡
⎣
1
exp

j2π f1

exp

j2π2 f1

⎤
⎦
⎞
⎠⊗vs(φ, θ)
⎞
⎠
(12.131)
with f1 the peak clutter Doppler times the PRI. The 3M-by-3M ADPCA covariance matrix estimate,
ˆRadpca/k, is an approximation to
Radpca/k = E

˜xk ˜xk

,
(12.132)
where ˜xk is given in (12.130). The covariance inverse in the ADPCA weight vector provides a dynamic
response to whiten ground clutter returns. The steering vector term in parentheses suppresses mainlobe
clutter with the binominal weights, identiﬁed as [1 −2 1]T , while forming a beam in a speciﬁed
angular direction; the steering vector incorporates an additional linear phase variation over the temporal
pulses to steer the Doppler null in cases where clutter is not centered at 0 Hz.
The performance of ADPCA is generally not as good as post-Doppler STAP techniques, thus limiting
its use in practice. Performance benchmark results are given in Section 2.12.5.
2.12.4.3 Parametric adaptive matched ﬁlter
The parametric adaptive matched ﬁltering (PAMF) employs multichannel, linear prediction to estimate
the covariance matrix inverse [41]. We now discuss the PAMF based on [41,42].
Consider the LDU decomposition of the covariance matrix inverse,
R−1
k
=

A−1
k
H
D−1
k A−1
k ,
(12.133)
where Ak = L, AH
k = U, and Dk is diagonal. Since we are considering space-time data, a block LDU
decomposition is required. In this case, A−1
k
takes the form, for the example of M = 4 and N = 8,
A−1
k
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
I4
0
0
0
0
0
0
0
AH
1 (1)
I4
0
0
0
0
0
0
AH
2 (2) AH
2 (1)
I4
0
0
0
0
0
AH
3 (3) AH
3 (2) AH
3 (1)
I4
0
0
0
0
AH
4 (4) AH
4 (3) AH
4 (2) AH
4 (1)
I4
0
0
0
AH
5 (5) AH
5 (4) AH
5 (3) AH
5 (2) AH
5 (1)
I4
0
0
AH
6 (6) AH
6 (5) AH
6 (4) AH
6 (3) AH
6 (2) AH
6 (1)
I4
0
AH
7 (7) AH
7 (6) AH
7 (5) AH
7 (4) AH
7 (3) AH
7 (2) AH
7 (1) I4
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
(12.134)
where AH
p (n) are the 4-by-4 multi-channel linear prediction (MCLP) coefﬁcients for the p-order ﬁlter
and the nth lag, 0 is the 4-by-4 zero matrix, and the realization index, k, is dropped for notational

636
CHAPTER 12 Space-Time Adaptive Processing for Radar
convenience [42]. The matrix D−1
k
is
D−1
k
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
D0
0
0
0
0
0
0
0
0
D1
0
0
0
0
0
0
0
0
D2
0
0
0
0
0
0
0
0
D3
0
0
0
0
0
0
0
0
D4
0
0
0
0
0
0
0
0
D5
0
0
0
0
0
0
0
0
D6
0
0
0
0
0
0
0
0
D7
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
(12.135)
where Dp is the 4-by-4 inverse of the MCLP error for the p-order ﬁlter. As noted in [42], the MCLP
development, while not necessary, is useful and provides a framework to calculate AH
p (n) and Dp.
The PAMF uses the LDU decomposition to approximate R−1
k . For example, let the maximum MCLP
ﬁlter order P = 2, then
A−1
k
≈
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
AH
2 (2) AH
2 (1)
I4
0
0
0
0
0
0
AH
2 (2) AH
2 (1)
I4
0
0
0
0
0
0
AH
2 (2) AH
2 (1)
I4
0
0
0
0
0
0
AH
2 (2) AH
2 (1)
I4
0
0
0
0
0
0
AH
2 (2) AH
2 (1)
I4
0
0
0
0
0
0
AH
2 (2) AH
2 (1) I4
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
.
(12.136)
Extending the Wiener-Hopf equation to calculate the linear prediction coefﬁcients, AH
p (n), and
augmenting with the identity matrices shown in (12.136), gives an approximation to A−1
k . The lin-
ear prediction error terms are given as
D−1
k
≈
⎡
⎢⎢⎢⎢⎢⎢⎣
D2
0
0
0
0
0
0
D2
0
0
0
0
0
0
D2
0
0
0
0
0
0
D2
0
0
0
0
0
0
D2
0
0
0
0
0
0
D2
⎤
⎥⎥⎥⎥⎥⎥⎦
.
(12.137)
Generally, each of the diagonal blocks is inverted after solving for Dk = A−1
k Rk

A−1
k
H
. The approx-
imation to the covariance matrix inverse follows from (12.133).
2.12.4.4 Summary of adaptive ﬁlter implementations
Table 12.3 summarizes the adaptive ﬁlter implementations discussed in this section. Performance assess-
ment of a number of these methods is given in Section 2.12.5.2.

2.12.4 Adaptive Filter Implementations
637
Table 12.3 Summary of Adaptive Filter Implementations
Type
Method
Section
Comments
RR-STAP
Adaptive beam pattern
synthesis (principal
components)
2.12.4.1.1
Weight calculation approach, interprets
STAP as pattern synthesis, where
notches are incorporated into the
quiescent beam pattern based on
information in the dominant subspace.
Insightful view of STAP, not as practical
as other methods, especially due to high
computational burden associated with the
eigendecomposition
RR-STAP
Principal Components
Inverse (PCI)
2.12.4.1.2
Weight calculation approach, involves
forming a projection operation orthogonal
to the clutter and interference subspaces.
May be used with RD-STAP methods.
Computationally burdensome due to
eigendecomposition
RR-STAP
Eigencanceler
2.12.4.1.3
Two formulations, one leading to Principal
Components Inverse weight vector
solution
RR-STAP
Hung-Turner Projection
(HTP)
2.12.4.1.4
Uses Gram-Schmidt to approximate PCI
solution at much lower computational
cost. Developed for use with large
adaptive DoF systems. Best performance
against stronger interference sources
Other
Diagonal loading
2.12.4.1.5
Adds scaled diagonal matrix to covariance
matrix estimate, enhancing numerical
stability and mitigating spurious sidelobe
effects due to perturbed noise subspace
RR-STAP
Cross Spectral Metric
(CSM)
2.12.4.1.6
Signal-dependent approach to select
interference subspaces in weight
calculation most greatly enhancing output
SINR. Generally limited to the GSLC
architecture, which tends to greatly
increase computational burden and limits
practical application
Other
Multi-Stage Wiener Filter
(MWF)
2.12.4.1.7
Truncated decomposition of the GSLC
architecture, involves calculating a series
of scalar weights for each stage, with
each subsequent stage maximally
correlated with the “desired signal”
(residual interference) of the prior stage.
Very high computational burden relative
to competing methods
Continued

638
CHAPTER 12 Space-Time Adaptive Processing for Radar
Table 12.3 Continued
Type
Method
Section
Comments
RD-STAP
Extended Factored
Algorithm (EFA)
2.12.4.2.1
Post-Doppler, “element” space STAP.
Typically involves adaptive weighting
three to ﬁve adjacent Doppler bins and
all spatial channels to suppress clutter.
Efﬁcient, effective technique:
reasonable computational burden and
low training sample support
requirements
RD-STAP
Factored Time-Space
(FTS)
2.12.4.2.1
Special case of EFA when using only one
Doppler bin. Places a spatial null within
a given Doppler bin. Generally performs
poorly at low range rates, since it only
has spatially adaptive DoFs
RD-STAP
Joint-Domain Localized
(JDL)
2.12.4.2.1
Post-Doppler, beamspace STAP.
Essentially a two-dimensional, linear
prediction technique: employ
angle-Doppler beams surrounding the
target beam to estimate and coherently
remove competing interference. Low
computational burden and minimal
training sample support requirements
RD-STAP
Adaptive Displaced
Center Antenna
(ADPCA)
2.12.4.2.2
Pre-Doppler STAP method, involves
adaptively combining all spatial
channels and a small collection of
pulses from within the current CPI.
Adaptive canceler is applied to
overlapped segments of pulses from
the CPI. Collection of clutter canceled
outputs then fed through a Doppler ﬁlter
bank to achieve temporal integration
gain. Useful for situations where
interference may appear slightly
nonstationary over the CPI, such as in
the case with a rotating array.
Computational burden and training
sample requirements similar to EFA
Other
Parametric Adaptive
Matched Filter (PAMF)
2.12.4.3
Low order, multi-channel linear prediction
approach to estimate the covariance
matrix inverse. Computationally
efﬁcient. Model order selection is
generally ad hoc

2.12.5 Application
639
Table 12.4 Radar Simulation Parameters
Parameter
Value
Parameter
Value
Transmit frequency
L-Band (1240 MHz)
Aperture size
∼1.2 m width × 1 m height
Receiver bandwidth
0.8 MHz
Receive aperture
conﬁguration
11 channels conﬁgured as
a uniform linear array
Peak power
15 kW
Array attitude
Sidelooking, canted 5◦
down, 6.78◦yaw, 0◦roll
PRF
1984 Hz
Platform altitude
3000 m
CPI length
32 pulses
Platform velocity
100 m/s
Clutter model
−20 dB reﬂectivity,
Constant Gamma
Model
ICM
Gaussian, 0.25 m2/s2
2.12.5 Application
In this section we consider the application of STAP to the important problem of radar detection in clutter.
We employ the simulation models of Section 2.12.3 and some of the metrics from Section 2.12.2 to
characterize the interference, algorithm performance, and STAP improvement over the non-adaptive
processor.
Table 12.4 provides some of the parameters of the simulated, multi-channel radar system. Chosen
parameters are similar to those of the Multi-Channel Airborne Radar Measurements (MCARM) system
described in Section 2.12.8. Also, these are the same parameters used to generate Figures 12.1–12.3 in
Section 2.12.1.
2.12.5.1 Interference characteristics
Using the models described in Section 2.12.3, we simulate clutter and noise for an eleven channel, thirty-
two pulse airborne radar scenario. The clutter environment is homogeneous. Additional parameters are
given in Table 12.4 and are similar in nature to a MCARM data collection referenced in Section 2.12.8.
In this case, we simulated one CPI, where the aircraft experiences 6.78◦of yaw. We focus our attention
somewhat arbitrarily at a 32 km slant range for the analysis. Additionally, we simulated the eleven
channel uniform linear array without array amplitude and phase errors. The antenna is steered to broad
side: 0◦azimuth and 0◦elevation angle.
Figure 12.17 shows the PSD for this scenario. The PSD uses a Hanning weight in both space and time.
The slight offset in peak clutter Doppler frequency in the look-direction from 0 Hz is due to platform
yaw. The overall CNR is in the range of slightly greater than 50 dB. For comparison, Figure 12.18 shows
the MVDR spectrum, clearly outlining the clutter angle-Doppler region of support. (Note: while MVDR
provides units of power, it is widely known to be a poor estimator of the signal strength.) Figure 12.19
shows the eigenspectrum calculated using the known covariance matrix; the eigenspectrum displays the

640
CHAPTER 12 Space-Time Adaptive Processing for Radar
FIGURE 12.17
Power spectral density for sidelooking array radar example.
FIGURE 12.18
MVDR spectrum for sidelooking array radar example.
covariance matrix eigenvalues, sorted from largest to smallest. The noise eigenvalues are set to 0 dB,
and those values greater than the noise ﬂoor correspond to the clutter signal. The largest eigenvalue is
indicative of the CNR to within a few decibels, suggesting CNR in the range of 53–55 dB.
Considering the MVDR spectrum in Figure 12.18, we anticipate an optimal ﬁlter response that drives
a deep null along the clutter angle-Doppler region of support. Figure 12.20 shows the optimal space-time
ﬁlter response, steered to broadside and 400 Hz Doppler; the clutter null and peak gain is evident in the
ﬁgure.

2.12.5 Application
641
FIGURE 12.19
Eigenspectrum for example scenario.
FIGURE 12.20
Optimal space-time frequency response, steered to array broadside and 400 Hz Doppler frequency.
Finally, Figure 12.21 shows the clairvoyant (known covariance) SINR loss, Ls,1, over unambiguous
Doppler (−PRF/2 ≤fd ≤PRF/2) in the broadside direction. The loss cut shows the impact of clutter
on detection performance, with the null offset from 0 Hz due to the platform yaw. As seen from the ﬁgure,
the null depth is slightly greater than 50 dB, consistent with the mainlobe CNR and the eigenspectrum of
Figure 12.19. We will consider the performance of various STAP techniques relative to the clairvoyant
SINR loss curve momentarily.

642
CHAPTER 12 Space-Time Adaptive Processing for Radar
FIGURE 12.21
Clairvoyant SINR loss.
2.12.5.2 STAP algorithm performance
Based on the discussion in Section 2.12.4, we benchmark the performance of a number of STAP
techniques using the scenario from the prior section. Again, we focus on a slant range of 32 km. Also,
we consider clairvoyant loss, Ls,1. For the homogeneous clutter scenario considered herein, the adaptive
loss, Ls,2, precisely follows the RMB rule: using sample support equal to twice the processor’s DoF
yields, on average, 3 dB loss. The different techniques have different sample support requirements,
based on their adaptive DoFs. An exception in this case involves the PAMF; the PAMF implementation
averages over the pulse domain, and so can rely on less training data over range. However, this advantage
is not unique to the PAMF, and other methods can also average over pulses (like the ADPCA technique)
or employ smoothing techniques to effectively increase the sample support [43].
Figure 12.22 compares the clairvoyant SINR loss of EFA, FTS, and JDL to the bound provided by
the space-time optimal processor (STOP; the optimal space-time ﬁlter using the clairvoyant covariance
matrix). In this case, the processors are conﬁgured as follows:
•
FTS—uses all eleven channels and a Hanning weighting on the Doppler ﬁlters. Eleven adaptive
spatial DoFs.
•
EFA—uses all eleven spatial channels and three adjacent, Hanning-weighted Doppler ﬁlters. Thirty-
three adaptive space-Doppler DoFs.
•
JDL—uses three adjacent, uniform weighted spatial beams and three adjacent, Hanning-weighted
Doppler ﬁlters. Nine total adaptive angle-Doppler DoFs. The beam spacing is three degrees (a little
less than one-third of the full aperture 3 dB beamwidth).
From Figure 12.22, we ﬁnd that EFA and JDL provide excellent performance potential relative to
the achievable bound set by STOP. The FTS performance is disappointing, but not a surprise since this
algorithm does not adaptively combine any temporal DoFs. One then might conclude JDL to be a better
selection, since it only requires nine DoFs. However, the additional spatial DoFs afforded by EFA may

2.12.5 Application
643
FIGURE 12.22
Clairvoyant SINR loss for post-Doppler STAP techniques.
FIGURE 12.23
Clairvoyant SINR loss for pre-Doppler STAP and PAMF.
prove beneﬁcial when RFI or Doppler ambiguities are present. Thus, a number of analyses should take
place before ﬁnal algorithm selection.
Figure 12.23 duplicates the aforementioned analysis for pre-Doppler STAP (ADPCA) and the PAMF.
The processors are conﬁgured as follows:
•
ADPCA—uses three adjacent pulses and all spatial channels for cancellation, then Doppler ﬁl-
ters the resulting outputs using a Hanning weight. Thirty-three adaptive space-time DoFs. The

644
CHAPTER 12 Space-Time Adaptive Processing for Radar
FIGURE 12.24
Clairvoyant SINR loss for the MWF.
implementation steers the temporal gain response to center the temporal steering vector null at
−100 Hz, the center of mainlobe clutter.
•
PAMF—uses a fourth-order ﬁlter model. No weighting is used on the Doppler steering vector.
The clairvoyant SINR loss curves in Figure 12.23 indicate that both ADPCA and PAMF provide very
good performance, rivaling that of EFA and JDL in Figure 12.22.
As a last example, Figure 12.24 shows the benchmark performance of the MWF using three, six,
and twelve stages (K = 3, 6, 12). As seen from the ﬁgure, the performance for K = 3 or K = 6 is
poor, but very good capability is observed when K = 12. The computational loading of MWF, for the
implementation used by the author, is signiﬁcantly higher than the other methods examined.
2.12.5.3 STAP Comparison with nonadaptive solution
To conclude this section, we simply compare the performance of the space-time optimal ﬁlter to a
nonadaptive processing scheme involving beamforming and Doppler processing. The nonadaptive ﬁlter
implementation uses a Hanning temporal weight and uniform illumination spatially on receive. (Note:
the transmit illumination uses a 30 dB Taylor weighting.) As seen from Figure 12.25, the space-time
optimal ﬁlter provides a very signiﬁcant performance advantage over the nonadaptive processor, thereby
indicating the tremendous beneﬁts of STAP.
2.12.5.4 Application summary
In this section we considered a typical airborne radar example. Clutter and noise models from
Section 2.12.3 were used to simulate data snapshots and covariance matrices. The covariance matrices
were used to assess the performance potential of several STAP techniques discussed in Section 2.12.4.
From this analysis, we ﬁnd that a number of the methods perform similarly well relative to the achievable

2.12.6 Challenges
645
FIGURE 12.25
Comparison of the optimal and nonadaptive ﬁlter performance potential.
performance bound. We caution the reader, however, that many other practical matters drive algorithm
selection. Of the methods discussed, EFA often provides the best performance and greatest ﬂexibility
when considering a number of issues.
2.12.6 Challenges
Contemporary STAP research topics generally focus on challenges associated with covariance matrix
estimation or mitigating computational burden. In this section we provide commentary on the former.
2.12.6.1 Heterogeneous clutter
Real world clutter environments are heterogeneous, thus tacitly undermining the IID assumption central
to the development of (12.49) [44–46]. Heterogeneous clutter is a result of culturally-varying terrain
type. Examples include: variation in clutter amplitude or spectral spread due to a mixture of clutter types;
abrupt edges characteristic of clutter interfaces (e.g., between urban and rural regions); the presence of
target-like signals in the training data (TSD) [45]; and, stationary, manmade objects resulting in strong,
discrete responses. Each of the aforementioned effects is localized within the training set. Hence,
the estimate of (12.49) captures the average behavior of the training data, thus potentially appearing
mismatched to any particular cell under test. This mismatch translates to an erroneous, adaptive response
relative to the optimal condition. SINR loss or threshold bias results in such instances. References
[44–46] characterize in detail the nature of such system degradation.
As an example, distributed clutter is typically site-speciﬁc: the clutter reﬂectivity varies as a function
of range and angle due to changes in the terrain features. Equation (12.70) accommodates site-speciﬁc

646
CHAPTER 12 Space-Time Adaptive Processing for Radar
FIGURE 12.26
Comparison of measured (left) and simulated (right) multichannel UHF radar data (colorbar in decibels)
(after [47],© 2006 IEEE).
simulation by modifying the term, vk(p, q), through access of a database to determine the clutter
RCS, σk,p,q, in (12.67)–(12.69) (where the reference to the qth range ambiguity is added). Figure 12.26
compares actual andsite-speciﬁcsimulationof UHFradar datatakenintheDelaware-Maryland-Virginia
(Delmarva) Peninsula region; this region is dominated by rural clutter, bodies of water and rivers, and
also covered by a number of roadways. As seen from Figure 12.26, the range and cross-range (Doppler,
or angle) variation of the clutter response is evident and predictable. The clutter variation shown is one
source of heterogeneity leading to covariance matrix estimation error.
Table 12.5 provides a summary of various sources of heterogeneous clutter and their impact on
STAP performance. Of the effects listed, it is observed that target-like signals corrupting the secondary
(training) data (TSD) and clutter discretes tend to lead to the greatest performance loss.
A variety of techniques have been developed to enhance STAP detection performance given the
challenges of heterogeneous clutter. We summarize some of the available methods in Table 12.6. As
discussed in [47], the different approaches fall in one of two categories: indirect or direct. The indirect
methods attempt to manipulate the training set to improve the covariance matrix estimate, oftentimes
using knowledge of the platform motion or surrounding terrain or operating environment, whereas
the direct methods attempt to modify the ﬁlter response using models and ancillary information. Both
indirect and direct methods attempt to improve the instantaneous adaptive ﬁlter response to mini-
mize heterogeneous clutter residue at the ﬁlter output; in this manner, STAP performance in complex,
heterogeneous environments can approach that attainable in a homogeneous setting.
As an example of the degradation of heterogeneous interference effects, and the improvement poten-
tial of available STAP techniques, Figure 12.27 compares detection rates using MCARM Flight 5,
Acquisition 575 data using block training (bins 200–320) versus intelligent training and ﬁlter selec-
tion (ITFS, [47]), where maps facilitate training data excision in regions overlaying certain roadways.
As seen from the ﬁgure, TSD leads to excessive, additional loss in the lobed regions near ±20 m/s;

2.12.6 Challenges
647
Table 12.5 Summary of Heterogeneous Clutter and STAP Impact
Source
Description
Impact on STAP
Spatially-varying,
distributed clutter
RCS
Range-angle variation in clutter RCS
leads to varying power across
clutter angle-Doppler region of
support
Over- or undernulled clutter.
Overnulled clutter can lead to
signal cancellation, whereas
undernulling leads to clutter
residue and degraded SINR
Spatially-varying,
distributed clutter
spectral spread
Range-angle variation of intrinsic
clutter motion varies spectral
spread across clutter
angle-Doppler region of support
Training on regions where ICM is less
than that of the application region
leads to insufﬁcient null width and
an increase in clutter residual,
whereas regions with ICM less
than that present in the training set
experience suppression of low
speed targets
Clutter edges and
shadowing
Gross variation in clutter type (e.g.,
land-sea interface) or regions of
extended obscuration,
predominantly in the mainlobe
direction
Over- or undernulled clutter
Clutter discretes
Stationary objects with relatively large
RCS, often manmade objects such
as cars, utility poles, etc., also
includes extended discretes, such
as fence lines and train tracks
Increased false alarm rate, upward
threshold bias leading to increase
in missed detections
Target-like signals
Vehicles on roadways and within
airspace, predominantly through
the mainbeam
Signal cancellation due to nulling off
the clutter ridge in angle-Doppler
locations consistent with targets of
interest
removing a speciﬁc highway using ITFS—as noted in the ﬁgure’s legend—fully mitigates this loss,
raising the detection rate from roughly 55% to 98%.
2.12.6.2 Nonstationary clutter
STAP maximizes SINR by ﬁltering ground clutter in the angle-Doppler domain. Radar geometry deter-
mines the ﬁlter null location in this higher-dimensional space. When the null location varies over
range, the adaptive ﬁlter produces an incorrect frequency response. In the monostatic radar case, the
angle-Doppler region of support can exhibit range variation when the velocity vector and array normal
are non-orthogonal. This occurs for forward-looking arrays, or under conditions when the platform is
yawed [48,49].
In sidelooking array radar, the spatial frequency measured by a uniform linear array is proportional
to the corresponding Doppler frequency of a stationary clutter patch on the Earth’s surface. Speciﬁcally,

648
CHAPTER 12 Space-Time Adaptive Processing for Radar
Table 12.6 STAP Techniques to Mitigate the Impact of Heterogeneous Clutter on Detection
Performance
Technique
Description
Reference
Nonhomogeneity Detector (NHD)
Data-dependent screening measure, tests training
data for similarity to the average, selects
homogeneous training samples
[50–52]
Power Selected Training (PST)
Data-dependent screening measure, selects
training samples strongest in power to drive null
as deeply as possible
[53,54]
Power Comparable Training (PCT)
Data-dependent screening measure, sorts data
into tiles of similar power levels to match
training data to cell under test
[55]
Power Variable Training (PVT)
Scale the power of the estimated covariance
matrix’s dominant (clutter) subspace to match
the power level in the cell under test, requires
eigendecomposition
[56]
Map-aided training
Uses mapping data and distance measures to
screen training samples
[24,57]
Covariance matrix taper (CMT)
Purposely spreads the estimated clutter response
to increase null width
[58]
Subaperture smoothing
Exploits similar covariance structure among
sub-apertures of a uniformly sampled spatial or
temporal aperture to enhance the quantity of
homogeneous training samples
[43,59]
Nonlinear, nonadaptive STAP
Employs a model of the clutter covariance matrix to
suppress clutter
[60]
Color loading
Adds a scaled clutter covariance model to the
covariance matrix estimate to emphasize the
anticipated clutter response and enable
localized training
[61,62]
Discrete Matched Filter (DMF)
Coherently removes clutter discrete signals using a
modiﬁed version of the CLEAN algorithm
[47]
Signal and Clutter as Highly
Independent Structured Modes
(SCHISM)
Coherently removes distributed clutter returns
using a modiﬁed version of the CLEAN
algorithm
[63]
Adaptive Coherence Estimator
(ACE)
Incorporates a statistical measure of the
“whiteness” of the clutter residue in a particular
cell under test to suppress clutter discretes?
[64]
Knowledge-Aided Parametric
Covariance Estimation (KAPE)
Estimates parameters of a validated covariance
matrix model, including clutter amplitude,
spread, mainlobe centroid, and error
components of the array manifold
[16,65]

2.12.6 Challenges
649
FIGURE 12.27
Estimated detection probability improvement over Doppler frequency using KA training on MCARM data
(after [24],© 2004 IEEE).
normalized Doppler, ˜fd = fdT , can be written
˜fd = 2vpT
λ
cos φcone =
vpT
d/2

fs,
(12.138)
wherevp istheplatformvelocityinthedirectionorthogonaltothearraynormal,TisPRI,λiswavelength,
φcone istheconeanglemeasurementfromtheplatformcenterlinetotheclutterpatchlocation, dischannel
spacing, and fs is spatial frequency. Spatial frequency is given by
fs = d
λ cos φcone.
(12.139)
Physically, the clutter iso-Doppler contours and the array beam traces align, translating to angle-Doppler
behavior that is range invariant.
In the non-sidelooking radar case, the beam traces and iso-Dopplers of the ground clutter returns
misalign at some ranges, mainly those where the range divided by the altitude is less than ﬁve [18,19].
The variation of the clutter response through the training set leads to an adaptive ﬁlter response with
incorrect null placement, leading to increased clutter residue and degraded detection performance.
References [48,49] discuss effective compensation methods.
Range varying angle-Doppler loci further exacerbates culturally induced heterogeneous clutter
effects. For example, residue from clutter discretes further increase in the presence of adaptive ﬁlter
null migration associated with the non-stationary clutter mechanism described in this section.
2.12.6.3 Bistatic STAP
Bistatic STAP development received considerable attention in the early-to-mid 2000s. Airborne bistatic
radar involves a moving transmitter and receiver separated a considerable distance. The bistatic geometry

650
CHAPTER 12 Space-Time Adaptive Processing for Radar
Table 12.7 Summary of Bistatic STAP Methods
Bistatic STAP approach
Description
Reference
Localized processing
Simple strategy, attempts to choose training data in the
vicinity of the cell under test to minimize nonstationary
impacts
[66,67]
Time-varying weights
Employs truncated Taylor series expansion of the weight
vector, presumes linear evolution in the weight vector
elements over range
[68,69]
Doppler warping
Aligns a point of the clutter ridge for each bistatic range to a
designated reference point (e.g., 0 Hz Doppler) using a
range-varying, complex modulation prior to STAP
application
[49]
Higher-order Doppler
warping
Aligns sections of the clutter ridge to a reference ridge using
a range varying modulation, a multi-point extension of the
Doppler warping method prior to STAP application
[70]
Angle-Doppler
compensation
Aligns “spectral centers,” or regions of maximum
angle-Doppler return, over range using a complex,
range-varying, space-time modulation prior to STAP
application
[71]
Adaptive angle-Doppler
compensation
Derives key information on clutter range variation directly
from the data, applies a complex, space-time,
range-varying modulation to the data to algin dominant
clutter subspaces prior to STAP application
[72,73]
Registration of
“direction-Doppler
curves”
Uses curve ﬁtting methods to warp the power spectral density
of a given range sum to a reference prior to STAP
application
[74]
and independent motion between transmitter and receiver leads to signiﬁcant angle-Doppler variation
over range [75,72].
Table 12.7 summarizes a number of recently developed bistatic STAP techniques, including a descrip-
tion of the approach and germane references. As seen from the table, the methods generally fall in one
of three categories: localized processing (or training); data pre-warping, prior to STAP application;
and, time-varying weights. Several of the bistatic STAP methods in Table 12.7 have proven extraor-
dinarily effective, restoring performance to levels similar to that achievable in homogeneous clutter
environments.
2.12.6.4 Conformal array STAP
A conformal array’s shape is compliant with the contours of the radar bearing platform. For exam-
ple, Figure 12.28 depicts conformal antenna elements mounted to a chined nose cone; the short lines
emanating from each dot representing an antenna element indicate the surface normal.

2.12.7 Implementation
651
FIGURE 12.28
Example of conformal antenna elements mounted to a chined nose cone.
The curvature of the conformal array, coupled with the look-direction relative to the velocity vector,
results in a nonstationary clutter angle-Doppler response [76–78]. SINR loss resulting from the nonsta-
tionary clutter response rivals that seen in bistatic radar examples. Hersey et al. [76] discusses several
solutions to mitigate nonstationary clutter behavior based on adaptations of solutions developed for
bistatic STAP implementation, including localized processing, localized processing with time-varying
weights, angle-Doppler warping, and higher-order angle-Doppler warping. Additionally, Hersey et al.
[76] develops a method called equivalent uniform linear array transformation which attempts to resam-
ple the data to a linear conﬁguration. The conformal array STAP methods in [76] lead to signiﬁcant
performance enhancement.
2.12.7 Implementation
We discuss a generic, STAP-based, airborne radar detection architecture in this section. A ﬂow diagram
of the detection process is given in Figure 12.29.
STAP is applied at the CPI level. As a result of target fading, the MTI radar typically transmits bursts
of pulses at several different frequencies, where each burst comprises the CPI. Being a coherent signal
processing technique, STAP operates on each CPI as indicated in the ﬁgure, essentially generating
a range-Doppler map (RDM) at a receive angle consistent with the transmit direction: a space-time
snapshot for each range bin, xk, is processed using a space-time weighting steered to a given angle and
Doppler to yield a single pixel in the RDM, |yk|2. Each CPI is processed, generating aligned RDMs;
the alignment may require additional processing steps, such as motion compensation. Then, the RDMs

652
CHAPTER 12 Space-Time Adaptive Processing for Radar
STAP
Covariance
Estimate
Select STAP
Training
Data
Select STAP
Steering
Vector
PDI
Bearing & 
Doppler
Estimation
Multi-Channel
Array
Maximize output SINR!
k
x
k
y
0
0
0
1
1
0
0
0
0
0
0
0
0
0
0
0
CFAR
Select CFAR
Training
Data
Σ/k
y
1 CPI
FIGURE 12.29
Detection processing ﬂow.
at the different frequencies are noncoherently summed in a step called post-detection integration (PDI;
also called noncoherent addition, NCA). PDI boosts detection performance by taking advantage of
the purposeful decorrelation created by frequency hopping to avoid target fading that adversely affects
operation using a single coherent dwell. Frequency hopping forces the target to take on a Swerling 2
characteristic [1,7].
After PDI, a detection threshold is set using a constant false alarm rate (CFAR) algorithm; the CFAR
algorithm multiplies an estimate of the residual interference power by a threshold multiplier in an
attempt at achieving a constant false alarm rate [1]. Pixel values crossing the detection threshold are
declared targets. The signal processor then estimates the bearing and Doppler frequency of the threshold
crossing generally using a maximum likelihood estimator. The corresponding SINR, bearing, Doppler,
and range—among other potential characteristics—for each detection is then passed to an analyst or an
automatic tracker. Figure 12.29 is meant to show the basic processing steps; it is common to incorporate
additional functionality to cope with clutter heterogeneity or target motion through resolution cells, for
instance.
The selection of the scalar, ˆμ, in (12.44) is an important, practical consideration. It is common to
use the adaptive matched ﬁlter (AMF) normalization [79],
ˆμ =
1
'
vH
s-t(φ, θ, fd) ˆR−1
k vs-t(φ, θ, fd)
.
(12.140)
The AMF normalization sets the residual interference-plus-noise ﬂoor to unity as ˆRk →Rk, viz.
PI+N = ˆwH
k Rk ˆwk = vH
s-t(φ, θ, fd) ˆR−1
k Rk ˆR−1
k vs-t(φ, θ, fd)
'
vH
s-t(φ, θ, fd) ˆR−1
k vs-t(φ, θ, fd)
2 →1.
(12.141)
The AMF normalization accommodates variable training intervals and other segmentation of the weight
estimation and application over range, minimizing shifts in the mean, residual interference-plus-noise

2.12.7 Implementation
653
power that otherwise leads to threshold bias and increased false alarm rate. More speciﬁcally, assuming
the segmented interference-plus-noise environment is IID, the AMF normalization possesses CFAR
properties: as power ﬂuctuates from one weight application region to the next, the ﬁlter output is scaled
by the inverse of the residual interference-plus-noise power so that a ﬁxed detection threshold maintains
a constant false alarm rate. This is seen by examining the AMF decision statistic,
ηAMF =
			vH
s-t(φ, θ, fd) ˆR−1
k xk
			
2
vH
s-t(φ, θ, fd) ˆR−1
k vs-t(φ, θ, fd)
H1
>
<
H0
T1,
(12.142)
where T1 is a ﬁxed decision threshold. Moving the denominator of the decision statistic to the right,
(12.142) is interpreted as the square of the ﬁlter output (the numerator term) compared to a threshold
multiplier, T1, scaled by the residual interference-plus-noise output power. This is the conventional view
of CFAR in radar signal processing.
A virtually identical formulation of the AMF result is given in [80] and referred to as Modiﬁed
Sample Matrix Inversion (MSMI).
A maximum likelihood estimate for target bearing and Doppler integrates seamlessly with the archi-
tecture in Figure 12.29 and use of the AMF normalization. This can be seen by expressing the alternative
hypothesis of (12.2) as
xk = αss-t(p) + ntot; p =
⎡
⎣
φ
θ
fd
⎤
⎦,
(12.143)
where α is a complex constant, and ntot = ck + jk + nk is the interference-plus-noise (total noise)
vector. The objective is to estimate p with ˆp. Since ntot ∼CN(0, Rk), the joint probability density
function (pdf) is
p(xk|p) =
1
π M |Rk| exp

−(xk −αss-t(p))HR−1
k (xk −αss-t(p))

.
(12.144)
Given the likelihood function deﬁned by (12.144), we ﬁrst require an estimate for the complex constant.
Equation (12.144) is maximal when
Q(α, p) = (xk −αss-t(p))HR−1
k (xk −αss-t(p))
(12.145)
is minimal. Differentiating (12.145) and setting the result to zero yields
ˆα =
sH
s-t(p)R−1
k xk
sH
s-t(p)R−1
k ss-t(p)
.
(12.146)
Substituting (12.146) into (12.145) leads to
Q(ˆα, p) = xH
k R−1
k xk −
			xH
k R−1
k ss-t(p)
			
2
sH
s-t(p)R−1
k ss-t(p)
.
(12.147)

654
CHAPTER 12 Space-Time Adaptive Processing for Radar
Differentiating (12.147) with respect to p and setting the result to zero yields the maximum likelihood
estimate (MLE), ˆp. Consequently, the estimator is [81]
ˆp =
⎡
⎢⎣
ˆφ
ˆθ
ˆfd
⎤
⎥⎦=
arg max
p=

φ
θ
fd
T
⎛
⎜⎝
			sH
s-t(p)R−1
k xk
			
2
sH
s-t(p)R−1
k ss-t(p)
⎞
⎟⎠.
(12.148)
The MLE takes the form of an AMF normalized STAP cost surface and in practice vs-t replaces ss-t.
Implementing the estimator requires a very ﬁne grid search to ﬁnd the peak of the likelihood function (via
the MLE approach). The grid search—which essentially amounts to stepping the space-time steering
vector over potential target angles and Dopplers—is computationally burdensome and can be sub-
optimum. Speciﬁcally, if the step size is too large, the estimator can exhibit bias and increased variance.
For this reason, numerical approximations to the MLE, which exhibit good practical performance, are
commonly used.
When processing multiple CPIs, the MLE appears as the sum of the individual cost surfaces at each
frequency, where each cost surface takes the form of the term in parentheses in (12.148). An equivalent
development for the multistatic radar case is given in [82].
STAP remains computationally challenging to implement. The weight calculation generally takes
place in either the voltage domain using QR decomposition (QRD) or in the power domain using
Cholesky factorization. Calculating the weight vector using QRD in the voltage domain seems favorable,
since it essentially doubles the dynamic range in decibels over the power domain solution and avoids
explicitly forming outer products in the covariance estimation step. Cholesky factorization in the power
domain is also a common approach when considering all the details of real-time implementation on
speciﬁc computing devices.
2.12.8 STAP data collection programs
In this section we highlight some measured data collection programs.
2.12.8.1 Multichannel Airborne Radar Measurements (MCARM)
In the mid-1990s, the US Air Force Rome Laboratory (now the Air Force Research Laboratory) con-
tracted with Westinghouse Corporation (now Northrop Grumman) to build and ﬂy a multi-channel,
L-band radar under the Multi-Channel Airborne Radar Measurements (MCARM) Program [83]. The
MCARM program produced a meaningful collection of multi-channel radar data over a range of
clutter conditions to evaluate the performance potential of STAP and support continued technology
development.
The salient parameters of the MCARM system are given in Table 12.8. As seen from the table, the
system has relatively high peak power, an electrically modest aperture at L-band, relatively low range
resolution, and built-in features to calibrate the antenna and radio frequency front-end. Additionally,
as Figure 12.30 shows, MCARM has a highly ﬂexible array conﬁguration, supporting a range of study
options, including planar array conﬁguration, uniform linear array, and sum and difference channel
analyses. Figure 12.31 shows the region of the Eastern United States—the Delmarva Peninsula—where

2.12.8 STAP Data Collection Programs
655
Table 12.8 MCARM Nominal System Parameters
Parameter
Value
Parameter
Value
Transmit frequency L-band (1240 MHz)
Beamwidth
7.5◦, and 3× “blob” pattern
Bandwidth
1 MHz Transmit, 0.8 MHz
Receive
Array conﬁguration Most collections use 11-over-11
receive channels, plus sum
and difference (see ﬁgure)
Peak power
15 kW
Sample rate
5 MHz
Waveform
Linear frequency modulated
or gated RF
CPI length
Nominally 128 pulses
PRF
0.5 kHz, 2 kHz, 7 kHz
Other
Test manifold for channel
balance, range measured
steering vectors
Module 1
Module 0
Module 7
Module 5
Module 4
Module 3
Module 2
Module 6
Module 11
Module 10
Module 9
Module 8
Module 13
Module 15
Module 14
Module 12
Module 18
Module 17
Module 16
Module 19
Module 21
Module 20
Module 22
Module 23
Module 24
Module 25
Module 26
Module 27
Module 28
Module 29
Module 30
Module 31
Δ
Σ,
Rx
FIGURE 12.30
MCARM data collection system.

656
CHAPTER 12 Space-Time Adaptive Processing for Radar
575
580
586
598
Look-Direction
Rt. 9
Rt. 13
Hwy 301
FIGURE 12.31
CPI locations for several acquisitions during MCARM Flight 5.
several acquisitions were collected during MCARM Flight 5. As previously mentioned, this region is
relatively ﬂat, dominated by rural clutter and water, and covered by a number of roadways, including
several highways. Results from Acquisition 575, in particular, have been presented in a number of
papers, starting with [50].
It is known that some of the MCARM acquisitions were previously made publicly releasable, as
described in [84]. The Air Force Research Laboratory, Sensors Directorate, maintains the MCARM
database.
2.12.8.2 Naval Research Laboratory (NRL) database
The Naval Research Laboratory (NRL) Adaptive Array Flight Test Database is decribed in [85].
Table 12.9 provides some ﬂight test parameters. According to [85], the effort remarkably consisted of
over thirty ﬂights, collecting in excess of 2500 data ﬁles. Data were collected predominantly in the moun-
tainous regions of Virginia and West Virginia, with urban clutter data collected in the vicinity of Wash-
ington, DC, and rural clutter data collected in North Carolina, Georgia, Ohio, and Indiana. Sea clutter
data were collected over the Atlantic Ocean, east of Virginia, with some littoral clutter data also recorded.
Lee and Staudaher [85] indicates a database was constructed, with data formatted for MATLAB®
analysis, with the intent “that the database will provide the adaptive signal processing community with
a valuable tool for validating both existing and future adaptive algorithms.”
2.12.8.3 Mountaintop database
According to [86,87], the Mountaintop Program goal sought to advance airborne early warning radar
technology. Collection of surveillance radar clutter and jamming data from mountaintops at White Sands
Missile Range, New Mexico, and Paciﬁc Missile Range Facility, Hawaii, served as central objectives
in this effort. The Mountaintop radar, known as the Radar Surveillance Technology Experimental
Radar (RSTER), employed an inverse displaced phase center antenna (IDPCA) technique to give the

2.12.8 STAP Data Collection Programs
657
Table 12.9 NRL Adaptive Array Flight Test System Parameters (from [85])
Parameter
Value
Parameter
Value
Transmit frequency
UHF
Beamwidth
15.7◦azimuth, 80◦elevation
(16.5 dBi gain)
Bandwidth
2.6 MHz
Array conﬁguration
Eight channel, uniform linear
array
Peak power
In excess of 1 MW
Sample rate
5 MHz (separate in-phase and
quadrature channels)
Waveform
Unstated, presumably linear
frequency modulated or
gated RF
CPI length
3–18 pulses at low PRF, 34–66
pulses for high PRF
PRF
Typically 300 Hz or 750 Hz
Other
Test manifold for channel
balance
Table 12.10 Mountaintop RSTER Parameters (from [87,88])
Parameter
Value
Parameter
Value
Transmit frequency
UHF (400–500 MHz)
Beamwidth
9◦azimuth, 6◦elevation
Bandwidth
200 kHz
Array conﬁguration
14 channel uniform
linear array
Peak power
100 kW
Sample Rate
1 MHz [88]
Waveform
Linear frequency modulated [yy]
CPI length
16 pulses
PRF
250–1500 Hz
Other
Horizontally polarized,
relocatable
appearance of platform motion. RSTER parameters are given in Table 12.10. In IDPCA, the system
steps the transmit location to one (or three) of eighteen total transmit antenna columns.
According to [87], Mountaintop RSTER data are archived using the Common Research Environment
for STAP (CREST) database. Additionally, some data is accessible at the IEEE Signal Processing
Information Base at Rice University [88].
2.12.8.4 Knowledge-aided sensor signal processing and
expert reasoning (KASSPER) data
Improving the performance of STAP in complex clutter environments served as a primary aim of
the DARPA KASSPER Program [89]. Under this program, DARPA funded the creation of several
sets of synthetic, multichannel, multi-pulse, multi-range datacubes at X-band and L-band. The L-band
datacube—KASSPER datacube #1, or KDC #1—is publicly releasable and was provided to attendees
at the 2002 DARPA KASSPER Workshop [90]. Many of the L-band data parameters resemble those of

658
CHAPTER 12 Space-Time Adaptive Processing for Radar
FIGURE 12.32
MVDR spectra for KDC #1, range bins 102 (left) and 500 (right).
the MCARM system described in Table 12.8, the exception mainly being the use of an eleven channel
uniform linear array and typically fewer pulses in the CPI. Each of the KASSPER datacubes is a result
of high-ﬁdelity, site-speciﬁc clutter simulation. Dense moving targets are present in the data. A unique
aspect of the simulation is the availability of truth information, including known covariance matrices
on a range cell basis and target location data for some of the datasets (including the L-band datacube
and some of the X-band cases).
Figure 12.32 shows MVDR spectra for KDC #1 range bins 102 and 500, with pre-steering applied to
the antenna boresight. Additionally, the KASSPER datacubes included simulated antenna errors, with
the true error vector provided with the data sets; the two-dimensional MVDR spectra in Figure 12.32
employ knowledge of the precise array manifold.
2.12.9 Summary
This tutorial describes a number of key aspects of STAP. Naturally, it is challenging to fully cover all
the details of a topic so vast. Our goals for this effort are simpler: provide a concise, single reference to
augment the available text books, reports, and papers on this important subject and highlight some of
the more signiﬁcant developments within the research community.
In this tutorial, we describe a number of approaches to design optimal ﬁlters. Of the methods
described, all end up being closely related and ultimately maximize the probability of detection for
a ﬁxed probability of false alarm. We then discuss signal models for clutter, noise, radio frequency
interference and target. These models form the basis for STAP algorithm development and analysis.
STAP, as it turns out, refers to a collection of a number of practical techniques; we discuss several
major algorithm themes, include post-Doppler STAP, pre-Doppler STAP, and parametric STAP. We
further discuss a number of eigen- or subspace-based cancellation architectures, including Principle
Components Inverse, the cross spectral metric, and the Multi-Stage Wiener Filter.

Symbols and Notation
659
Using the simulation models and algorithm descriptions, we then characterize the performance of
the various methods using SINR loss, a key performance metric in the STAP community, using a
homogeneous clutter scenario. We ﬁnd that, for the approach taken, all but one of the methods provides
similarly good performance relative to the bound set by the optimal space-time ﬁlter.
Key challenges in the STAP research community center on modifying textbook principles to support
real-world application. Invariably, the accurate estimation of the unknown clutter covariance matrix and
implementing the adaptive ﬁlter in a real-time computing environment are driving considerations. In
this vein, we brieﬂy discuss the challenges of STAP application in heterogeneous clutter environments,
for bistatic or conformal array conﬁgurations, and in the presence of otherwise nonstationary clutter.
A number of concepts are concisely summarized in Section 2.12.7, where we describe the end-to-end
implementation of a basic MTI radar processor. STAP normalization and target parameter estimation is
considered in this section.
We conclude the discussion by summarizing several STAP data collection programs, the character-
istics of the various radar systems, and the type of data collected or generated.
Symbols and notation
We provide a key to some common notation used in this paper.
fs
spatial frequency
fd
Doppler frequency (Hz)
φ, θ
azimuth and elevation (rads)
φcone
cone angle (rads)
ψ
grazing angle (rads)
λ
wavelength (m)
M
number of channels
N
number of pulses
L
number of available range bins
T
pulse repetition interval (s)
σ 2
n
noise variance (w)
σ 2
T
target signal variance (w)
vp
platform velocity vector (m/s, m/s, m/s)
ss
spatial steering vector
vs
hypothesized spatial steering vector
st
temporal steering vector
vt
hypothesized temporal steering vector
ss-t
space-time steering vector
vs-t
hypothesized space-time steering vector
xs/k(n)
spatial data snapshot, kth range cell, nth pulse
xk
space-time data snapshot, kth range cell
ck
clutter space-time snapshot, kth range cell
jk
RFI space-time snapshot, kth range cell

660
CHAPTER 12 Space-Time Adaptive Processing for Radar
nk
uncorrelated noise space-time snapshot, kth range cell
tk
target space-time snapshot, kth range cell
Rk
null-hypothesis covariance matrix (kth range cell)
Rc/k
clutter covariance matrix
RRFI
RFI covariance matrix
Rn
receive noise covariance matrix
ˆRk
null-hypothesis covariance estimate, kth range cell
wk
space-time weight vector
ˆwk
adaptive space-time weight vector
Pd
probability of detection
Pf a
probability of false alarm.
Acronyms
Following is a list of common acronyms:
ADPCA
adaptive displaced phase center antenna
AMF
adaptive matched ﬁlter
CFAR
constant false alarm rate
CNR
clutter-to-noise ratio
CPI
coherent processing interval
CREST
Common Research Environment for STAP
CUT
cell-under-test
DNR
discrete-to-noise ratio
DoFs
degrees of freedom
FIR
ﬁnite impulse response
FLAR
forward-looking array radar
GLSC
generalized sidelobe canceler
GMTI
ground moving target indication
HTP
Hung-Turner projection
ICM
intrinsic clutter motion
IDPCA
inverse displaced phase center antenna processing
IF
improvement factor
IID
independent and identically distributed
JDL
joint domain localized
KASSPER
Knowledge-Aided Sensor Signal Processing and Expert Reasoning
MCARM
Multi-Channel Airborne Radar Measurements
MCLP
multichannel linear prediction
MDV
minimum detectable velocity
MLE
maximum likelihood estimate
MMSE
minimum mean square error
MSE
mean square error

References
661
MSMI
modiﬁed sample matrix inversion
MPE
minimum power eigencanceler
MNE
minimum norm eigencanceler
MTI
moving target indication
MV
minimum variance
MVDR
minimum variance distortionless response
MWF
multi-stage Wiener ﬁlter
NCA
noncoherent addition
pdf
probability density function
PDI
post-detection integration
PRI
pulse repetition interval
PSD
power spectral density
RDM
range-Doppler map
RFI
radio frequency interference
RD-STAP
reduced-dimension STAP
RR-STAP
reduced-rank STAP
RSTER
Radar Surveillance Technology Experimental Radar
SAR
synthetic aperture radar
SLAR
sidelooking array radar
SMI
sample matrix inversion
SNR
signal-to-noise ratio
SINR
signal-to-interference-plus-noise ratio
STAP
space-time adaptive processing
STOP
space-time optimal processing
TNR
target-to-noise ratio
TSD
targets in the secondary data
WGN
white Gaussian noise
WSS
wide-sense stationary
Relevant Theory: Statistical Signal Processing and Array Signal Processing
See Vol. 3, Chapter 5 Distributed Signal Detection
See Vol. 3, Chapter 19 Array Processing in the Face of Nonidealities
References
[1] M. Richards, et al. (Eds.), Principles of Modern Radar: Basic Principles, SciTech Publishing, Inc., North
Carolina, 2010.
[2] J.V. DiFranco, W.L. Rubin, Radar Detection, Artech-House, Dedham, MA, 1980.
[3] L.E. Brennan, I.S. Reed, Theory of adaptive radar, IEEE Trans. AES 9 (2) (1973) 237–252.
[4] I.S. Reed, A brief history of adaptive arrays, Sudbury/Wayland Lecture Series (Raytheon Div. Education),
Notes, 23 October 1985.

662
CHAPTER 12 Space-Time Adaptive Processing for Radar
[5] R. Klemm, Doppler properties of airborne clutter, in: Proceedings of the Research and Technology Orga-
nization, North Atlantic Treaty Organization (RTO-NATO) Lecture Series 228—Military Applications of
Space-Time Adaptive Processing, RTO-ENP-027, September 2002, pp. 2-1–2-24.
[6] J.N. Entzminger, C.A. Fowler, W.J. Kenneally, JointSTARS and GMTI: past, present and future, IEEE Trans.
AES 35 (2) (1999) 748–761.
[7] M.I. Skolnik, Introduction to Radar Systems, second ed., McGraw Hill, New York, NY, 1980.
[8] N. Levanon, Radar Principles, John Wiley & Sons, New York, 1988.
[9] W.L. Melvin, A STAP overview, in: Peter Willett (Ed.), IEEE AES Systems Magazine—Special Tutorials
Issue, 19 (1) (2004) 19–35.
[10] J. Ward, Space-Time Adaptive Processing for Airborne Radar, Lincoln Laboratory Technical Report,
ESC-TR-94-109, December 1994.
[11] J.R. Guerci, Space-Time Adaptive Processing for Radar, Artech House, Norwood, MA, 2003.
[12] S. Haykin, Adaptive Filter Theory, third ed., Prentice-Hall, Upper Saddle River, NJ, 1996.
[13] D.H. Johnson, D.E. Dudgeon, Array Signal Processing: Concepts and Techniques, Prentice-Hall, Englewood
Cliffs, NJ, 1993.
[14] L.J. Grifﬁths, C.W. Jim, An alternative approach to linearly constrained adaptive beamforming, IEEE Trans.
Antenn. Propag. 30 (1) (1982) 27–34.
[15] L.M. Novak, M.B. Sechtin, M.J. Cardullo, Studies of target detection algorithms that use polarimetric radar
data, IEEE Trans. AES 25 (2) (1989) 150–165.
[16] W.L. Melvin, G.A. Showman, Knowledge-aided parametric covariance estimation, IEEE Trans. AES (2006)
1021–1042.
[17] I.S. Reed, J.D. Mallett, L.E. Brennan, Rapid convergence rate in adaptive arrays, IEEE Trans. AES 10 (6)
(1974) 853–863.
[18] R. Klemm, Space-time adaptive processing: principles and applications, IEE Radar, Sonar, Navigation and
Avionics 9, IEE Press, 1998.
[19] R. Klemm, Principles of space-time adaptive processing, second ed., IEE Radar, Sonar, Navigation and
Avionics 12, IEE Press, UK, 2002. (Note: a 3rd edition of this text, published in 2006, is also available.)
[20] D. Barton, Land clutter models for radar design and analysis, Proc. IEEE 73 (2) (1985) 198–204.
[21] J.B. Billingsley, Low-Angle Radar Land Clutter: Measurements and Empirical Models, William Andrew
Publishing, Inc., 2002.
[22] R.J. Mailloux, Phased Array Antenna Handbook, Artech House, Boston, MA, 1994.
[23] M. Zatman, How narrow is narrowband? IEE Proc. Radar Sonar Navig. 145 (2) (1998) 85–91.
[24] W.L. Melvin, G.A. Showman, J.R. Guerci, A knowledge-aided GMTI detection architecture, in: Proceedings
of the 2004 IEEE Radar Conference, Philadelphia, PA, 26–29 April, 2004, ISBN: 0-7803-8235-8.
[25] D.V. Rabinkin, N.B. Pulsone, Subband-domain signal processing for radar array systems, in: Proceedings of
the SPIE Conference on Advanced Signal Processing Algorithms, Architectures, and Implementations IX,
Denver, CO., July 1999, pp. 174–187.
[26] R. Klemm, Adaptive clutter suppression for airborne phased array radar, Proc. IEE 130 (1) (1983) 125–132.
[27] C.H. Gierull, B. Balaji, Minimal sample support space-time adaptive processing with fast subspace techniques,
IEE Proc. Radar Sonar Navig. 149 (5) (2002) 209–220.
[28] W.F. Gabriel, Using spectral estimation techniques in adaptive processing antenna systems, IEEE Trans.
Antenn. Propag. 34 (3) (1986) 291–300.
[29] D.W. Tufts, I. Kirsteins, R. Kumaresan, Data-adaptive detection of a weak signal, IEEE Trans. AES 19 (2)
(1983) 313–316.
[30] A.M. Haimovich, The Eigencanceler: adaptive radar by eigenanalysis methods, IEEE Trans. AES 32 (2)
(1996) 532–542.

References
663
[31] E.K.L. Hung, R.M. Turner, A fast beamforming algorithm for large arrays, IEEE Trans. AES 19 (4) (1983)
598–607.
[32] B.D. Carlson, Covariance matrix estimation errors and diagonal loading in adaptive arrays, IEEE Trans. AES
24 (4) (1988) 397–401.
[33] J.R. Guerci, J.S. Goldstein, I.S. Reed, Optimal and adaptive reduced-rank STAP, IEEE Trans. AES 36 (2)
(2000) 647–661.
[34] S.D. Berger, B.M. Welsh, Selecting a reduced-rank transformation for STAP—a direct form perspective, IEEE
Trans. AES 35 (2) (1999) 722–729.
[35] J.S. Goldstein, I.S. Reed, P.A. Zulch, Multistage partially adaptive STAP CFAR detection algorithm, IEEE
Trans. AES 35 (2) (1999) 645–661.
[36] R.C. DiPietro, Extended factored space-time processing for airborne radar, in: Proceedings of the 26th
Asilomar Conference, Paciﬁc Grove, CA, October 1992, pp. 425–430.
[37] H. Wang, L. Cai, On adaptive spatial-temporal processing for airborne surveillance radar systems, IEEE Trans.
AES 30 (3) (1994) 660–670.
[38] R. Brown, M. Wicks, Y. Zhang, Q. Zhang, H. Wang, A space-time adaptive processing approach for improved
performance and affordability, in: Proceedings of the 1996 IEEE National Radar Conference, Ann Arbor,
Michigan, May 13–16, 1996, pp. 321–326.
[39] R. Klemm, Antenna design for airborne MTI, in: Proceedings of the Radar 92, October 1992, Brighton, UK,
pp. 296–299.
[40] R. Blum, W. Melvin, M. Wicks, An analysis of adaptive DPCA, in Proceedings of the 1996 IEEE National
Radar Conference, Ann Arbor, Michigan, May 13–16, 1996, pp. 303–308.
[41] J.R. Roman, M. Rangaswamy, D.W. Davis, Q. Zhang, B. Himed, J.H. Michels, Parametric adaptive matched
ﬁlter for airborne radar applications, IEEE Trans. AES 36 (2) (2000) 677–692.
[42] G.A. Showman, Personal communication, 13 July 2003.
[43] R.L. Fante, E.C. Barile, T.P. Guella, Clutter covariance smoothing by subaperture averaging, IEEE Trans.
AES 30 (3) (1994) 941–945.
[44] W.L. Melvin, Space-time adaptive radar performance in heterogeneous clutter, IEEE Trans. AES 36 (2) (2000)
621–633.
[45] W.L. Melvin, J.R. Guerci, Adaptive detection in dense target environments, in: Proceedings of the 2001 IEEE
Radar Conference, Atlanta, GA, 1–3 May 2001, pp. 187–192.
[46] W.L. Melvin, STAP in heterogeneous clutter environments, in: R. Klemm (Ed.), The Applications of Space-
Time Processing, IEE Radar, Sonar, Navigation and Avionics 9, IEE Press, 2004.
[47] W.L. Melvin, J.R. Guerci, Knowledge-aided sensor signal processing: a new paradigm for radar and other
sensors, IEEE Trans. AES (2006) 983–996.
[48] O. Kreyenkamp, R. Klemm, Doppler compensation in forward-looking STAP radar, IEE Proc. Radar Sonar
Navig. 148 (5) (2001) 252–258.
[49] G. Borsari, Mitigating effects on STAP processing caused by an inclined array, in: Proceedings of the 1998
IEEE Radar Conference, Dallas, Tx, May 1998, pp. 135–140.
[50] W.L. Melvin, M.C. Wicks, R.D. Brown, Assessment of multichannel airborne radar measurements for analysis
and design of space-time processing architectures and algorithms, in: Proceedings of the 1996 IEEE National
Radar Conference, Ann Arbor, Michigan, May 13–16, 1996, pp. 130–135.
[51] W.L. Melvin, M.C. Wicks, Improving practical space-time adaptive radar, in: Proceedings of the 1997 IEEE
National Radar Conference, Syracuse, New York, May 13–15, 1997, pp. 48–53.
[52] P. Chen, W.L. Melvin, M.C. Wicks, Screening among multivariate normal data, J. Multivariate Anal. 69 (1999)
10–29.

664
CHAPTER 12 Space-Time Adaptive Processing for Radar
[53] D.J. Rabideau, A.O. Steinhardt, Improving the performance of adaptive arrays in non-stationary environments
through data-adaptive training, in: Proceedings of the 30th Asilomar Conference, Paciﬁc Grove, CA, 3–6
November 1996, pp. 75–79.
[54] D.J. Rabideau, A.O. Steinhardt, Improved adaptive clutter cancellation through data-adaptive training, IEEE
Trans. Aerosp. Electron. Syst. 35 (3) (1999) 879–891.
[55] G.A. Showman, W.L. Melvin, Knowledge-aided discrete removal techniques, in: Proceedings of the 2005
DARPA ISIS/KASSPER Workshop, Las Vegas, NV, 22–24 February 2005, CD ROM.
[56] N. Pulsone, Improving ground moving target indication performance, in: Proceedings of the DARPA/AFRL
KASSPER Workshop, 14–16 April 2003, Las Vegas, NV, 2003.
[57] S.D. Berger, W.L. Melvin, G.A. Showman, Map-aided secondary data selection, in: Proceedings of the 2007
IEEE Radar Conference, Boston, MA, April 2007.
[58] J.R. Guerci, Theory and application of covariance matrix tapers for robust adaptive beamforming, IEEE Trans.
Signal Process. 47 (4) (1999) 977–985.
[59] S.U. Pillai, Y.L. Kim, J.R. Guerci, Generalized forward/backward subaperture smoothing techniques for
sample starved STAP, IEEE Trans. Signal Process. 48 (12) (2000) 3569–3574.
[60] A. Farina, P. Lombardo, M. Pirri, Nonlinear nonadaptive space-time processing for airborne early warning
radar, IEE Proc. Radar Sonar Navig. 145 (1) (1998) 9–18.
[61] J.S. Bergin, C.M. Teixeira, P.M.Techau, J.R. Guerci, STAP with knowledge-aided data pre-whitening, in:
Proceedings of the 2004 IEEE Radar Conference, April 2004, pp. 289–294.
[62] J.S. Bergin, C.M. Teixeria, P.M. Techau, J.R. Guerci, Space-time beamforming with knowledge-aided con-
straints, in: Proceedings of the 2003 Adaptive Sensor Array Processing Workshop, MIT Lincoln Laboratory,
Lexington, MA, March, 2003.
[63] G.R. Letgers, J.R. Guerci, Physics-based airborne GMTI radar signal processing, in: Proceedings of the 2004
IEEE Radar Conference, Philadelphia, PA, April 2004, pp. 283–288, ISBN: 0-7803-8234-X.
[64] C.D. Richmond, Statistical performance analysis of the adaptive sidelobe blanker detection algorithm, in:
Proceedings of the 31st Annual Asilomar Conference—Signal, Systems & Computers, Paciﬁc Grove, CA,
2–5 November 1997, pp. 872–876.
[65] W.L. Melvin, G.A. Showman, Knowledge-aided, physics-based signal processing for next-generation radar,
in: Proceedings of the Asilomar Conference on Signals, Systems, Computers, Paciﬁc Grove, CA, November
2007.
[66] W.L. Melvin, M.J. Callahan, M.C. Wicks, Adaptive clutter cancellation in bistatic radar, in: Proceedings of
the 34th Asilomar Conference, Paciﬁc Grove, CA, October 2000, pp. 1125–1130.
[67] B. Himed, J.H. Michels, Y. Zhang, Bistatic STAP performance analysis in radar applications, in: Proceedings
of the 2001 IEEE Radar Conference, Atlanta, GA, May 2001, pp. 198–203.
[68] S.D. Hayward, Adaptive beamforming for rapidly moving arrays, in: Proceedings of the CIE International
Conference on Radar, IEEE Press, Beijing, CN, 8–10 October 1996, pp. 480–483.
[69] S.M. Kogon, M.A. Zatman, Bistatic STAP for airborne radar systems, in: Proceedings of the IEEE SAM,
Lexington, MA, March 2000.
[70] F. Pearson, G. Borsari, Simulation and analysis of adaptive interference suppression for bistatic surveillance
radars, in: Proceedings of the 2001 ASAP Symposium, Lexington, MA, 13 March 2001.
[71] B. Himed, Y. Zhang, A. Hajjari, STAP with angle-Doppler compensation for bistatic airborne radars, in:
Proceedings of the 2002 IEEE Radar Conference, Long Beach, CA, 22–25 April 2002, ISBN: 0-7803-7358-8.
[72] W.L. Melvin, M.E. Davis, Adaptive cancellation method for geometry-induced non-stationary bistatic clutter
environments, IEEE Trans. AES (2007) 651–672.
[73] W.L. Melvin, B. Himed, M.E. Davis, Doubly-adaptive bistatic clutter ﬁltering, in Proceedings of the 2003
IEEE Radar Conference, Huntsville, AL, 5–8 May 2003, pp. 171–178.

References
665
[74] F.D. Lapierre, J.G. Verly, M. Van Droogenbroeck, New solutions to the problem of range dependence in
bistatic STAP radars, in: Proceedings of the 2003 IEEE Radar Conference, Huntsville, AL, 5–8 May 2003,
pp. 452–459.
[75] W.L. Melvin, Adaptive moving target indication, in: N. Willis, H. Grifﬁths (Eds.), Advances in Bistatic
Radar, Sci-Tech Publishing, 2007 (Chapter 11).
[76] R.K. Hersey, W.L. Melvin, J.H. McClellan, E. Culpepper, Adaptive ground clutter suppression for conformal
array radar systems, IET Radar Sonar Navig. 3 (4) (2009) 357–372.
[77] R.K. Hersey, W.L. Melvin, E. Culpepper, Adaptive ﬁltering for conformal array radar, in: Proceedings of the
IEEE Radar Conference, May 2008, Rome, Italy.
[78] R.K. Hersey, W.L. Melvin, J.H. McClellan, Clutter-limited detection performance of multi-channel conformal
arrays, Signal Process. 84 (2004) 1481–1500 (special issue on New Trends and Findings in Antenna Array
Processing for Radar).
[79] F.C. Robey, D.R. Fuhrman, E.J. Kelly, R. Nitzberg, A CFAR adaptive matched ﬁlter detector, IEEE Trans.
AES 28 (1) (1992) 208–216.
[80] W.S. Chen, I.S. Reed, A new CFAR detection test for radar, Digital Signal Processing, vol. 1, Academic
Press, 1991, pp. 198–214.
[81] R.C. Davis, L.E. Brennan, I.S. Reed, Angle estimation with adaptive arrays in external noise ﬁelds, IEEE
Trans. AES AES-12 (2) (1976) 179–186.
[82] W.L. Melvin, R. Hancock, M. Rangaswamy, J. Parker, Adaptive distributed radar, in: Proceedings of the 2009
International Radar Conference, Bordeaux, France, October 2009.
[83] D.K. Fenner, W.F. Hoover, Test results of a space-time adaptive processing system for airborne early warning
radar, in: Proceedings of the 1996 IEEE National Radar Conference, Ann Arbor, MI, 13–16 May 1996,
pp. 88–93.
[84] V. Cavo, MCARM/STAP Data Analysis, Final Technical Report, Air Force Research Laboratory, AFRL-SN-
RS-TR-1999-48, May, Volume One (of Two), 1999.
[85] F. Lee, F. Staudaher, The NRL adaptive array ﬂight test database, in: Proceedings of the IEEE Adaptive
Antenna Systems Symposium, 1992, pp. 101–104.
[86] G.W. Titi, An overview of the ARPA/Navy mountaintop program, in: Proceedings of the IEEE Adaptive
Antenna Systems Symposium, 1994.
[87] G.W. Titi and D.F. Marshall, The ARPA/Navy Mountaintop Program: adaptive signal prcessing for airborne
early warning radar, in: Proceedings of the 1996 IEEE International Conference on Acoustics, Speech, and
Signal Processing (ICASSP), vol. 2, pp. 1165–1168.
[88] <http://spib.rice.edu/spib/mtn_top.html>.
[89] J.R. Guerci, Knowledge-aided sensor signal processing and expert reasoning, in: Proceedings of the 2002
Knowledge-Aided Sensor Signal Processing and Expert Reasoning (KASSPER) Workshop, Washington,
DC, 3 April, 2002, CD ROM.
[90] J.S. Bergin, P.M. Techau, (Electronic data) Workshop datacube, in: Proceedings of the 2002 KASSPER
Conference, Washington, DC, 3 April 2002, CD ROM.

13
CHAPTER
MIMO Radar with Widely
Separated Antennas—From
Concepts to Designs
Qian He*, Yang Yang†, and Rick S. Blum†
*Department of Electronic Engineering, University of Electronic Science and Technology of China,
Chengdu, Sichuan, China
†Department of Electrical and Computer Engineering, Lehigh University,
Bethlehem, PA, USA
2.13.1 Introduction
Recent advances in wireless communications featuring the innovative multiple-input multiple-output
(MIMO) technology [1] have catalyzed a wave of interest in understanding and exploiting the concept
of MIMO radar, e.g., [2–7]. The similarity between MIMO communications and MIMO radar systems
that employ widely separated antennas is rather intriguing: in communications, MIMO systems combat
the fading effects of the multipath channel through its spatial diversity advantage; in radar, the complex
targets consisting of several scatterers resemble very much the multipath channel in wireless commu-
nications, and likewise, MIMO radar with widely separated antennas also offers the diversity gain. To
be more speciﬁc, a target’s radar cross section (RCS), which determines the amount of returned power,
varies greatly with respect to the considered aspect angle. Those variations can signiﬁcantly degrade
the ability of a conventional radar in detecting and estimating the target. MIMO radar with widely
separated antennas, whereas, through observing a target simultaneously from different (uncorrelated)
aspect angles, provide spatial diversity which can substantially countervail the ﬂuctuations in received
power.
Since the inception of MIMO radar in the early 2000s, a great deal of efforts have been devoted to
studying its performance potentials or developing a variety of application paradigms for it, e.g., [8–13].
However, note that MIMO radar systems studied in most of the literature can be roughly classiﬁed
into two categories. The ﬁrst category features the use of closely spaced antennas [3], i.e., the array
conﬁguration of these radars is close to that of the conventional phased array radar. But the utilization
of speciﬁc (e.g., orthogonal) transmit waveforms in this type of MIMO radar systems can render many
beneﬁts which are, otherwise, not achievable with the conventional phased array radars. The second
category, as surveyed in [4], takes advantage of multiple transmit signals as well. But it employs widely
separated antennas at both the transmit and receive ends, and thus enjoys the spatial diversity gain.
Among all these widely-separated-antenna cases are two cases that have received special attention:
one called coherent MIMO radar and the other called noncoherent MIMO radar [4]. The distinguishing
features are whether the target reﬂection model is coherent and whether the processing is coherent.
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-396500-4.00013-2
© 2014 Elsevier Ltd. All rights reserved.
667

668
CHAPTER 13 MIMO Radar with Widely Separated Antennas
For the case of coherent MIMO radar, the antennas are within a given target beamwidth1 which leads
to identical (coherent) reﬂection coefﬁcients, and a coherent processing approach is adopted. While for
the case of noncoherent MIMO radar, the antennas lie in different target beamwidths which leads to
distinct (noncoherent) reﬂection coefﬁcients, and a noncoherent processing approach is adopted. The
coherent processing requires phase synchronization of the oscillators employed at widely separated
antennas, while the noncoherent processing does not. In fact, phase synchronization embodies a major
difference between the operations of noncoherent MIMO radar and coherent MIMO radar, as will be
mathematically demonstrated later in this chapter.
Inthisdocument,wewillfocusontheMIMOradarwithwidelyseparatedantennas.Althoughfarfrom
being exhaustive, this document strives to summarize and discuss a large range of issues related to this
particular type of MIMO radar—both coherent and noncoherent processing approaches included. Topics
of interest encompass those with strong theoretical signiﬁcance, for example, performance evaluation
of both coherent and noncoherent MIMO radar in target localization and velocity estimation, study of
diversity gain for MIMO radar under the Neyman-Pearson (NP) criteria, etc. Topics of realistic values
are also covered, which include, for example, phase synchronization algorithm design for coherent
MIMO radar, and MIMO radar waveform design for extended targets. Through reviewing some state
of the art in this area, ranging from theoretical concepts to practical designs, this document is intended
to serve as an easy beginning as well as a handy reference for researchers who have interest in delving
into this ﬁeld. It is also expected to foster further discussions on those related research topics, and to
spur further research interest within this ﬁeld.
The remainder of this document is organized as follows. In Section 2.13.2, after a brief introduction
to the coherent MIMO radar, we derive the mean square error (MSE) of the maximum likelihood
(ML) estimate and the Cramer-Rao bound (CRB) for joint target location and velocity estimation, and
investigate the impact of static phase errors at the transmitters and receivers on the performance of
target localization. In Section 2.13.3, we turn our attention to noncoherent MIMO radar. Parallel to
the study for the coherent case, the joint estimation for target location and velocity using noncoherent
MIMO radar is presented, the MSE of the ML estimate is analyzed, and the CRB is calculated. Then,
the noncoherent MIMO radar ambiguity function (AF) is introduced. In Section 2.13.4, we discuss the
MSE performance differences between coherent and noncoherent MIMO radars in the application of
joint target location and velocity estimation. We demonstrate that the magnitude of these differences
decreases with an increase in the product of the number of transmit and receive antennas, when the
antennas for both coherent and noncoherent systems are properly placed. In Section 2.13.5, we derive
the diversity gain for a MIMO radar system adopting the Neyman-Pearson detection. The relationship
between the cumulative distribution function (cdf) of the reﬂection coefﬁcients, the cdf of the clutter-
plus-noise, and the signal space dimension of the transmitted waveforms is described. In Section 2.13.6,
we present three phase synchronization approaches for coherent MIMO radar, which include the master-
slave closed-loop method, the round-trip approach, and the broadcast consensus based algorithm. We
comparethesethreephasesynchronizationapproachesanddiscusssomeissuesthatmayariseinpractice.
In Section 2.13.7, we introduce some waveform design schemes for MIMO radar with widely separated
antennas. Finally we conclude this document with a summary in Section 2.13.8.
1If we model the target as an antenna, we can deﬁne a target beamwidth based on its size using standard antenna array
calculations.

2.13.2 Coherent MIMO Radar
669
2.13.2 Coherent MIMO radar
Before exposing readers to a variety of interesting issues related to the coherent MIMO radar, we ﬁrstly
introduce some settings that hold true for both the coherent and noncoherent MIMO radars, which
lays a common ground for the subsequent analysis. Let us consider a MIMO radar which is equipped
with M transmitters and N receivers. The positions of the kth, k = 1, . . . , M transmitter and the lth,
l = 1, . . . , N receiver are (xt
k, yt
k) and (xr
l , yr
l ) respectively, in a two-dimensional Cartesian coordinate
system. The lowpass equivalent of the signal transmitted from the kth transmitter is √E/Msk(t), where
E denotes the total transmitted energy, and the waveform is normalized such that
 ∞
−∞
|sk(t)|2dt = 1.
(13.1)
Assume a target, if present, is located at (x, y) and moving with velocity (vx, vy). The time delay τlk
and Doppler shift flk involved in the path from transmitter k to receiver l, via the target reﬂection, are
τlk =

(xt
k −x)2 + (yt
k −y)2 +

(xr
l −x)2 + (yr
l −y)2
c
= dt
k + dr
l
c
(13.2)
and
flk = vx(xt
k −x) + vy(yt
k −y)
λdt
k
+ vx(xr
l −x) + vy(yr
l −y)
λdr
l
,
(13.3)
where c is the speed of light, dt
k denotes the distance between the target and the kth transmitter, dr
l
denotes the distance between the target and the lth receiver, and λ = c/ fc represents the wavelength
of the carrier with frequency fc. In both the coherent and noncoherent MIMO radars we assume all
transmitter and receiver nodes have oscillators which are locked in frequency, possibly due to the use
of a beacon. For the coherent MIMO radar, we also assume these oscillators are locked in phase.
Throughout this chapter, we use the term coherent MIMO radar to refer to MIMO radar system
employing coherent processing of received signals obeying a coherent target reﬂection model. If we
model the target as an antenna then we can deﬁne an equivalent target beamwidth based on the target
size [2]. In a coherent MIMO radar system, the antennas are assumed to be all within the same target
beamwidth, as illustrated in Figure 13.1. In this case, the effective target reﬂection coefﬁcient is assumed
to be identical for each transmitter-target-receiver path (which gives a coherent target reﬂection model)
and is denoted by ζ = ζR + jζI. We assume ζ is unknown but deterministic. Thus, the received signal
at receiver l can be modeled as
rl(t) =

E
M ζ
M

k=1
sk(t −τlk)e−j2π fcτlk e j2π flkt + wl(t)
(13.4)
=

E
M ζuT
l 1M×1 + wl(t),
(13.5)
where wl(t) represents the clutter-plus-noise component at the lth receiver for any given time t, and
ul = [ul1, ul2, . . . , ulM]T
(13.6)

670
CHAPTER 13 MIMO Radar with Widely Separated Antennas
antenna 
target
FIGURE 13.1
A coherent MIMO radar system with all three antennas in the same target beamwidth.
in which the kth element
ulk = sk(t −τlk)e−j2π fcτlk e j2π flkt
represents the signal transmitted from transmitter k and received by receiver l. Collecting the time
delayed and Doppler shifted signals from all paths in an N × M N block diagonal matrix, we arrive at
U =
⎡
⎢⎢⎢⎣
uT
1
0 · · · 0
0 uT
2 · · · 0
...
...
...
...
0
0 · · · uT
N
⎤
⎥⎥⎥⎦.
(13.7)
Then, the signals received at all N antennas can be written as
r(t) = [r1(t),r2(t), . . . ,rN(t)]T =

E
M ζU1N M×1 + w(t),
(13.8)
where
w(t) = [w1(t), w2(t), . . . , wN(t)]T
(13.9)
represents the clutter-plus-noise vector, which is assumed to be a zero mean Gaussian random vector
that satisﬁes
E{w(t)wH(t −τ)} = Qδ(τ)
(13.10)
with Q assumed to be a known2 time invariant constant matrix that determines the clutter-plus-noise
covariance matrix at the output of the matched ﬁlters.
2.13.2.1 Joint location and velocity estimation
Let the signals observed by a MIMO radar system be
˜r(t) = [˜r1(t), ˜r2(t), . . . , ˜rN(t)]T ,
(13.11)
2If the covariance matrix Q is not known, one may need to estimate it using secondary data. The readers are referred to
literature on space-time adaptive processing (STAP) for more details [14].

2.13.2 Coherent MIMO Radar
671
which is a realization of the random vector r(t) in (13.8), we hope to jointly estimate the target location
and velocity in the maximum likelihood (ML) sense. As discussed in [15], the ML estimates of the
unknown parameters can be found by examining the corresponding log-likelihood ratio. Stack the
parameters of interest into a vector as follows:
θJ = [x, y, vx, vy]T
(13.12)
and deﬁne a bigger vector
J = [x, y, vx, vy, ζR, ζI ]T
(13.13)
to include all the unknown parameters involved. Using the signal model in (13.8), it can be derived that
the log-likelihood ratio with respect to J is given by [16]
LJ

J; ˜r(t)

= 2ℜ

E
M ζzH1N M×1

−E
M |ζ|211×N MV1N M×1 + C1,
(13.14)
where C1 is a constant independent of the parameters to be estimated,
V =
 ∞
−∞
UHQ−1U dt
(13.15)
and3
z =
 ∞
−∞
UHQ−1˜r(t)dt.
(13.16)
The vector z can be regarded as the output of a matched ﬁlter which considers the correlations allowed
in the given analysis. It can be shown that, for any value of θJ, the ML estimate of ζ (i.e., ζR and ζI)
is [16]
ˆζ ML = ˆζ RML + j ˆζ IML =
11×N Mz

E
M 11×N MV1N M×1
.
(13.17)
Then, substituting ζ = ˆζ ML in (13.14), it yields
LJ

θJ; ˜r(t), ˆζ ML

=
|11×N Mz|2
11×N MV1N M×1
+ C1.
(13.18)
Note that in (13.18) we changed the notation in the parenthesis to emphasize that, after we have the ML
estimate for ζ, the parameters which need to be estimated are the elements of θJ. Thus, the ML estimate
of the unknown parameter vector θJ can be expressed as
ˆθJ,ML = arg max
θJ
LJ

θJ; ˜r(t), ˆζ ML

= arg max
θJ
|11×N Mz|2
11×N MV1N M×1
.
(13.19)
3Note that in this chapter, the integral over time in equations, such as (13.15) and (13.16) operates on each element of the
corresponding matrix.

672
CHAPTER 13 MIMO Radar with Widely Separated Antennas
It is worth noting that the estimator (13.19) combines signals from different antennas in a coherent way,
but we skip the discussion for now and postpone the explanation after (13.22) until some simplifying
assumptions are introduced.
In the previous discussions, the clutter-plus-noise was assumed to be temporally white but possi-
bly spatially colored. In order to simplify the analysis, in the following, we introduce two additional
assumptions: orthogonal transmitted signals and spatially white clutter-plus-noise. Leveraging these
assumptions, we are able to simplify the problem to be tackled and provide a handful of analytical
results, which can not only characterize some typical behaviors of the system when these assumptions
are satisﬁed, but can as well render insight into the system behaviors for cases where these assumptions
do not hold. Since these analytical results are relatively easy to obtain and explain, we are also able to
shed light on the relationship between the system performance and a few important system parameters.
Due to the convenience afforded by these assumptions, we will use them repeatedly in the rest of this
chapter.
Assumption 1.
Assume the transmitted signals are approximately orthogonal
 ∞
−∞
sk(t)s∗
k′(t)dt ≈
1, if k = k′,
0, if k ̸= k′,
and maintain approximate orthogonality for time delays τk, τk′ and Doppler shifts fdk, fdk′ of interest
so that
 ∞
−∞
sk(t −τk)s∗
k′(t −τk′)e j2π( fdk−fdk′)t dt ≈
 1, k = k′,
0, k ̸= k′,
such that the signals contributed from different transmitters can be separated at each receiver. See
Appendix A.1 for further discussion.
Assumption 2.
The clutter-plus-noise corresponding to the lkth path wlk(t) is a temporally white
zero-mean complex Gaussian random process with E{wlk(t)w∗
lk(u)} = σ 2
wδ(t −u), where σw is a
constant and δ(t) is a unit impulse function. The clutter-plus-noise components are spatially white,
such that E{wlk(t)w∗
l′k′(u)} = 0 if l ̸= l′ or k ̸= k′.
Under Assumption 1, it can be obtained that
 ∞
−∞UHU dt = I. Assumption 2 leads to Q = σ 2
wI, which
can be regarded as a result of perfect whitening if the covariance matrix of w(t), called Q previously,
can be accurately estimated. Then, we have z =
 ∞
−∞UHr(t)dt and V = (1/σ 2
w)I.
Applying these results into (13.14), we get a simpliﬁed log-likelihood ratio
LJ

J; ˜r(t)

= 2
σ 2w

E
M ℜ

ζ
N

l=1
M

k=1
 ∞
−∞
r∗
lk(t)sk(t −τlk)e−j2π fcτlk e j2π flkt dt

−1
σ 2w
E
M |ζ|2N M + C1,
(13.20)
where ˜rlk(t) represents the observed signal corresponding to the received signal model for the lkth path
rlk(t) =

E
M ζsk(t −τlk)e−j2π fcτlk e j2π flkt + wl(t).
(13.21)

2.13.2 Coherent MIMO Radar
673
Likewise, applying the simpliﬁcation assumption to (13.19) gives the simpliﬁed ML estimate
ˆθ
coh
J,ML = arg max
θJ

N

l=1
M

k=1
e j2π fcτlk
 ∞
−∞
˜rlk(t)s∗
k (t −τlk)e−j2π flktdt

2
.
(13.22)
In the estimator in (13.22), phase shifts imposed on various paths have a measurable impact on the
estimation output via the term e j2π fcτlk. Intuitively, we want the terms inside the |·|2 to add together
in phase to maximize (13.22), so as to achieve high estimation performance. This is the motivation
for the coherent processing (see Appendix A.2 for a distinction between coherent and noncoherent
processing). To make the best use of the phase information, phase synchronization is required, so that
all transmitters and receivers employ a common phase reference. Some approaches for achieving phase
synchronization are described in Section 2.13.6. Note that under Assumptions 1 and 2, the coherent
processing is optimal for the coherent target reﬂection model in Figure 13.1.
The mean square error (MSE), the average squared difference between an estimate and the true value
of the parameter being estimated, is a useful metric for forecasting the performance of an estimator.
The MSE of any unbiased estimator is lower bounded by the Cramer-Rao bound (CRB). Since attaining
the MSE is often computationally expensive, the CRB that indicates the best MSE an estimator can
provide, serves as an important tool for evaluating the estimation performance and system conﬁguration.
In (13.22), we have derived the ML estimator for the coherent MIMO radar joint location and velocity
estimation problem. It is known that the ML estimator is asymptotically unbiased, and the MSE of the
ML estimate asymptotically approaches the CRB. Thus, we can derive the CRBs for the parameters of
interest to provide an approximate MSE of the corresponding ML estimates in the asymptotic region.
The Fisher information matrix (FIM) with respect to J can be derived from the log-likelihood function
in (13.20) as follows [15,17]
Jcoh(J) = E

∇J LJ

J; ˜r(t)
 
LJ

J; ˜r(t)
T 
= −E

∇J

∇J LJ

J; ˜r(t)
T 
.
Under Assumptions 1 and 2, according to the derivations provided in Appendix A.3, we obtain the FIM
as shown below:
Jcoh(J) = 8π2|ζ|2E
σ 2wM
M

k=1
N

l=1
JUL
coh
JUR
coh
JLL
coh
JLR
coh

,
(13.23)
where
JUL
coh =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
εc
ka2
lk + 2γ c
lkalkelk + ηc
lke2
lk

(εc
kalk + γ c
lkelk)blk+
(γ c
lkalk + ηc
lkelk)glk

(γ c
lkalk + ηc
lkelk)βlk (γ c
lkalk + ηc
lkelk)qlk

(εc
kalk + γ c
lkelk)blk+
(γ c
lkalk + ηc
lkelk)glk

εc
kb2
lk + 2γ c
lkblkglk + ηc
lkg2
lk (γ c
lkblk + ηc
lkglk)βlk (γ c
lkblk + ηc
lkglk)qlk
(γ c
lkalk + ηc
lkelk)βlk
(γ c
lkblk + ηc
lkglk)βlk
ηc
lkβ2
lk
ηc
lkβlkqlk
(γ c
lkalk + ηc
lkelk)qlk
(γ c
lkblk + ηc
lkglk)qlk
ηc
lkβlkqlk
ηc
lkq2
lk
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
,

674
CHAPTER 13 MIMO Radar with Widely Separated Antennas
JUR
coh =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
(alkαk −elklk)ζI
2π|ζ|2
(elklk −alkαk)ζR
2π|ζ|2
(blkαk −glklk)ζI
2π|ζ|2
(glklk −blkαk)ζR
2π|ζ|2
−βlklkζI
2π|ζ|2
βlklkζR
2π|ζ|2
−qlklkζI
2π|ζ|2
qlklkζR
2π|ζ|2
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
JLL
coh =
⎡
⎢⎢⎣
(alkαk −elklk)ζI
2π|ζ|2
(blkαk −glklk)ζI
2π|ζ|2
−βlklkζI
2π|ζ|2
−qlklkζI
2π|ζ|2
(elklk −alkαk)ζR
2π|ζ|2
(glklk −blkαk)ζR
2π|ζ|2
βlklkζR
2π|ζ|2
qlklkζR
2π|ζ|2
⎤
⎥⎥⎦,
JLR
coh =
⎡
⎢⎣
1
4π2|ζ|2
0
0
1
4π2|ζ|2
⎤
⎥⎦,
with the terms alk = ∂τlk/∂x, blk = ∂τlk/∂y, elk = ∂flk/∂x, glk = ∂flk/∂y, βlk = ∂flk/∂vx, qlk =
∂flk/∂vy determined by the target position and velocity, and the antenna positions. The terms εc
k, γ c
lk,
ηc
lk, αk, and lk in Jcoh(J) are dependent on the characteristics of the received waveforms
εc
k =
 ∞
−∞
f 2 |Sk( f )|2 d f −2 fc
 ∞
−∞
f |Sk( f )|2 d f + f 2
c ,
(13.24)
γ c
lk = 1
2π ℑ
 ∞
−∞
ts∗
k (t −τlk)∂sk(t −τlk)
∂τlk
dt

−fc
 ∞
−∞
t |sk(t −τlk)|2 dt,
(13.25)
ηc
lk =
 ∞
−∞
t2 |sk(t −τlk)|2 dt,
(13.26)
αk = fc −
 ∞
−∞
f |Sk( f )|2 d f ,
(13.27)
and
lk =
 ∞
−∞
t |sk(t −τlk)|2 dt,
(13.28)
where Sk( f ) represents the Fourier transform of sk(t). The CRBs for the estimates of the unknown
target locations and velocities are the ﬁrst four diagonal elements of the inverse of the FIM
CRBcoh
x
=

J−1
coh(J)

1,1 ,
CRBcoh
y
=

J−1
coh(J)

2,2 ,
CRBcoh
vx =

J−1
coh(J)

3,3 ,
CRBcoh
vy =

J−1
coh(J)

4,4 .
(13.29)

2.13.2 Coherent MIMO Radar
675
The CRBs can be used to optimize system conﬁgurations with respect to certain parameters. Collect
the parameters of interest (β1, β2, . . .) in a vector as β = [β1, β2, . . .]T . These parameters could be,
for example, the number of antennas, the antenna placement, the waveform parameters, and so forth.
Suppose we require the optimum system conﬁguration design to minimize a metric formed by the
weighted sum of the CRBs of the estimates of x, y, vx, and vy. Then, the value of β that optimizes this
metric can be expressed as
˜β = arg

min
β∈β

W1CRBcoh
x
+ W2CRBcoh
y
+ W3CRBcoh
vx + W4CRBcoh
vy

,
(13.30)
where Wi, i = 1, . . . , 4 are weighting factors and β represents the feasible set of β. Numerical
methods may be needed to solve this problem. A concrete example of ﬁnding the optimum antenna
placement for the MIMO radar velocity estimation is provided in [18], where only CRBcoh
vx and CRBcoh
vy
are involved and equal weighting is considered, and it is shown analytically that under certain conditions
only symmetrical placement can be optimum. Interested readers are referred to [18] for more details.
2.13.2.2 Coherent ambiguity function
Besides the CRB, the ambiguity function (AF) is another useful tool for evaluating the estimation
performance for radar systems. The performance of the ML estimate can be reﬂected by the shape of
the AF. Actually, the CRB describes the shape of the AF around its maximum and this information
inﬂuences the MSE in the high SCNR region or when M N is large. Other aspects of the AF, including
the existence of sidelobes which can not be captured by the CRB, also inﬂuence the MSE performance
in the low SCNR region when M N is not large.
UnderAssumptions1and2,wedeveloptheAFforcoherentMIMOradarsystem.Assumeastationary
target is present at the origin of the Cartesian coordinate system, causing time delay τ0lk and zero Doppler
shift to the signal transmitted over the lkth path. Thus, the clutter-plus-noise free received signal can be
expressed as
r0lk(t) =

E
M ζsk(t −τ0lk)e−j2π fcτ0lk,
(13.31)
where τ0lk can be obtained by substituting x = 0 and y = 0 into (13.2). Consider the log-likelihood
ratio in (13.20), which assumes the expected signals have arbitrary delay τlk and Doppler shift flk for
the lkth path, corresponding to a target at location (x, y) with velocity (vx, vy). Substituting the just
described clutter-plus-noise free received signals r0lk(t) for ˜rlk(t) in (13.20), we obtain
LJ

J; ˜r(t)

= 2E|ζ|2
σ 2wM ℜ
 N

l=1
M

k=1
 ∞
−∞
s∗
k (t)sk(t −τlk)e−j2π fcτlk e j2π flk(t+τ0lk) dt

+ ˜C1,
(13.32)
where τlk = τlk −τ0lk denotes the time difference for the lkth path. The quantity LJ

J; ˜r(t)

in
(13.32) measures the likelihood that a ML processor believes the target corresponds to path delays τlk
and Doppler shifts flk for k = 1, . . . , M and l = 1, . . . , N, when the actual path delays are τ0lk and
the actual Doppler shifts are zero. Of course, the parts of (13.32) that do not depend on the delays and
Doppler shifts are not important in this consideration. Here we lump them into the constant ˜C1. Further,

676
CHAPTER 13 MIMO Radar with Widely Separated Antennas
one can deﬁne any suitable normalized version of (13.32) to be the AF. In this way, it is clear that the AF
is closely related to the performance of a processor that computes ML estimates.4 Thus, let us deﬁne
the coherent AF as
χcoh(x, y, vx, vy) =
1
(M N)2

N

l=1
M

k=1
e−j2π fcτlk
 ∞
−∞
s∗
k (t)sk(t −τlk)e j2π flk(t+τ0lk) dt

2
,
(13.33)
where we have replaced the ℜ{·} with |·|2 to deﬁne the coherent MIMO radar AF following the lead
of Woodword [19], 1/(M N)2 is introduced as a normalization factor, and the τlk and flk in (13.33)
are functions of (x, y) and (x, y, vx, vy), respectively. An ideal AF has a single peak at (0, 0, 0, 0) and
is zero elsewhere, which is however, impossible to realize. In the real world, the AF always comes
with a non-zero width mainlobe and several sidelobes, and researchers endeavor to design a better
waveform/system with a narrow mainlobe and lower sidelobe peaks.
A coherent MIMO radar AF is studied in [20] and excellent properties are found through numerical
investigations.5 For some cases with a small number of antennas, advantages are discussed over nonco-
herent MIMO radar for target location estimation. The coherent AF provided in [20] can be considered
as a special case of (13.33) by letting τlk = τlk and flk = 0, such that the resulting coherent AF is
reduced to a function of (x, y). We refer interested readers to [20] for more details.
2.13.2.3 Localization with phase errors
The previous section talks about location and velocity estimation for MIMO radar with ideal coherent
processing, where the target reﬂections follow the coherent model shown in Figure 13.1 and the phase
is assumed to be perfectly aligned across sensors. However, the difﬁculty in realizing perfect phase
synchronization may bring problems for coherent MIMO radar. In this section, we investigate the
impact of phase errors (e.g., due to imperfect phase synchronization) on the estimation performance.
The focus will be on localization, so here we do not discuss the velocity estimation for simplicity.
Assuming frequency synchronization, possibly through reception of a beacon, and white clutter-plus-
noise, possibly due to estimating the covariance matrix and whitening the observations, we study the
impact of phase errors on the target localization performance for coherent MIMO radar with widely
dispersed antennas. We consider cases with sufﬁciently high SCNR such that the CRB provides accurate
performance estimates. The CRBs with phase errors are computed in a few example cases and compared
with the CRBs without phase errors. For these examples, using numerical results, we will show that at
sufﬁciently high SCNR, phase errors degrade performance by only a relatively small amount.
Let t
k and r
l denote the phase errors induced by the kth transmitter and the lth receiver, respec-
tively. Assume the phase errors are static (during the entire CPI) i.i.d. random variables with uniform
distribution t
k ∼U(−π, π) and r
l ∼U(−π, π), where 0 ≤ ≤1. Using (13.4) and further
4To be more precise, the relationship is built upon the facts that the CRB depends on the mainlobe of the AF, and that the
performance of the ML estimator tends to the CRB.
5Note that some of the open literature [21,22] may have different deﬁnitions for the MIMO radar AF.

2.13.2 Coherent MIMO Radar
677
taking account of the phase errors, the received signal model at the lth receiver can be expressed as
rl(t) =

E
M ζ e jr
l
M

k=1
e jt
ksk(t −τlk)e−j2π fcτlk + wl(t),
(13.34)
where ζ = ζR + jζI denotes the deterministic, unknown complex reﬂection coefﬁcient, sk(t) is the
transmitted signal at the kth transmitter, E is the total transmitted energy, and τlk = (dt
k + dr
l )/c denotes
the time delay between transmitter k and receiver l as per (13.2). The clutter-plus-noise wl(t) in (13.34)
is assumed to be white complex Gaussian with power spectral density (PSD) σ 2
w, which is assumed to
be independent for different l.
Collect parameters of interest in a vector as follows
θP = [x, y, ζR, ζI]T ,
(13.35)
which is assumed to be deterministic and unknown. The random phase errors, regarded as nuisance
parameters, are collected in an (N + M) vector
 = [t
1, . . . , t
M, r
1, . . . , r
N]T .
(13.36)
Based on the results in [23], it is easy to show that the likelihood ratio conditioned on the phase errors is
(θP; ˜r(t)|) = C2 exp {g}
(13.37)
with g deﬁned as
g = −1
σ 2w
N

l=1

T
˜rl(t) −ζ

E
M
M

k=1
e jlk e−j2π fcτlksk(t −τlk)

2
dt,
(13.38)
where ˜r(t) = [˜r1(t), ˜r2(t), . . . , ˜rN(t)]T represents the signal observed over the observation interval T ,
C2 is a constant not dependent on θP, and lk = r
l + t
k. If we remove the conditioning on the phase
errors by averaging them out, the likelihood ratio can be written as
(θP; ˜r(t)) = C2
 π
−π
· · ·
 π
−π
exp {g}
 
1
2π
!N+M
dt
1 · · · dr
N
(13.39)
which requires an (N + M) dimensional multiple integration.
Assume an estimator is employed to produce an unbiased estimate, ˆθP, of the parameters of interest
from the observed signal vector ˜r(t). Then the variances of these estimates are bounded from below by
the CRBs which are the diagonal elements of the inverse of the FIM. Following the derivation given in
[23] for a similar single antenna system without phase errors, the FIM is given by
J(θP) = −E

∇θP

∇θP ln (θP; ˜r(t))
T 
.
(13.40)
Since (θP; ˜r(t)) in (13.39) is explicitly a function of the time delays τlk, we introduce an alternative
parameter vector
ϑP = [τ11, τ12, . . . , τN M, ζR, ζI]T ,
(13.41)

678
CHAPTER 13 MIMO Radar with Widely Separated Antennas
which is a column vector with (N M +2) elements containing the time delays for every transmit-receive
path and the real and imaginary parts of the target complex reﬂectivity. Using the chain rule, we have
J(θP) =

∇θPϑT
P

J(ϑP)

∇θPϑT
P
T
.
(13.42)
The computations of J(ϑP) and ∇θPϑT
P are provided in Appendix A.4. Substituting J(ϑP) and ∇θPϑT
P
into (13.42) yields the expression for J(θP). Thus, for a MIMO radar with M transmit and N receive
antennas, assuming white complex Gaussian clutter-plus-noise and that the phase errors at the trans-
mitters and receivers are static (during the entire CPI) i.i.d. random variables with uniform distribution
in [−π, π], 0 ≤ ≤1, the CRB for the estimates of the target location X = (x, y) are the ﬁrst
two diagonal elements of the inverse of the FIM
CRBx =

J−1(θP)

1,1 ,
CRBy =

J−1(θP)

2,2 .
Example
Assume a target is present at (15, 17.5) m. Consider a MIMO radar with M = 2 transmitters located at
(−137.87, −24.31) kmand(129.33, 129.33) km,and N = 2receiverslocatedat(−31.26, −177.27) km
and (149.82, 86.50) km. The transmitted signals are orthogonal frequency spread signals [18]
sk(t) =

1
√
T exp ( j2πk ft)
0 < t < T ,
0
otherwise,
(13.43)
where k = 1, 2, the term T denotes the pulse duration, and f = fk+1 −fk ≥0 is the frequency
increment between sk(t) and sk+1(t). A single pulse is employed in the simulation. Assume the pulse
duration is 1 ms, the frequency increment is 0.1 MHz, and the carrier frequency is 1 GHz. The SCNR,
deﬁned as E|ζ|2/(Mσ 2
w), is ﬁxed at 20 dB. Letting  go from 0 to 1, we plot the CRBs with phase errors
(CRBpe) for the estimates of x and y in Figure 13.2. Note that the value of  describes the severity of the
phase errors, which are distributed uniformly in [−π, π]. The corresponding coherent (CRBcoh) and
noncoherent (CRBnc) CRBs without phase errors were plotted in the same ﬁgure using the results in [20].
The ﬁgure indicates that a certain amount of phase error is tolerable if we are willing to accept a certain
amount of loss. For a given acceptable loss, Figure 13.2 gives the tolerable phase errors. It is observed
that CRBpe approaches CRBcoh as  goes to zero, and deviates away from CRBcoh as  increases. In
the worst case ( = 1), CRBpe is approximately 40 times worse than CRBcoh, but is still approximately
106 times better than CRBnc. The degradation due to the loss of knowing phase is much smaller than the
degradation caused by using noncoherent processing. These results document that having noisy phase
measurements is different from, and better than, not having any phase measurements.
This is a representative example (we have tested other examples and obtained similar results) for cases
with small M and N. We noted that cases with large M and N will also exhibit very small degradations
due to phase errors since, as shown in [24], the noncoherent estimates must be perfect as M N →∞.

2.13.3 Noncoherent MIMO Radar
679
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
10
−6
10
−4
10
−2
10
0
10
2
10
4
Δ
CRB
CRBnc for x
CRBnc for y
CRBpe for x
CRBpe for y
CRBcoh for x
CRBcoh for y
FIGURE 13.2
CRB for target localization versus , where the phase errors are uniformly distributed in [−π, π].
2.13.3 Noncoherent MIMO radar
In the previous section, we discussed coherent MIMO radar with widely separated antennas, where
the target reﬂections follow a coherent model and coherent processing is employed. Now we deﬁne
a different system, called noncoherent MIMO radar, employing a noncoherent processing of received
signals obeying a noncoherent target reﬂection model. For noncoherent MIMO radar, the antennas
are separated widely enough such that they fall in different target beamwidths and the effective target
reﬂection coefﬁcients for different paths are distinct (which implies a noncoherent target reﬂection
model). An example of such a case is illustrated in Figure 13.3. Denote the complex Gaussian reﬂection
coefﬁcient for the lkth path by ζlk. The received signal at receive antenna l is modeled as
rl(t) =

E
M
M

k=1
ζlke j2π fcτlksk(t −τlk)e j2π flkt + wl(t)
=

E
M
M

k=1
ζlksk(t −τlk)e j2π flkt + wl(t),
(13.44)
where wl(t) denotes the noise at receiver l. The simpliﬁcation in going from the ﬁrst to the second line
in (13.44) follows since the distributions of ζlk and ζlke j2π fcτlk are identical. The vector that contains

680
CHAPTER 13 MIMO Radar with Widely Separated Antennas
antenna 
target
FIGURE 13.3
A noncoherent MIMO radar system with three antennas each lying in a different target beamwidth.
all the received signals can be expressed as
r(t) = [r1(t),r2(t), . . . ,rN(t)]T =

E
M Uζ + w(t),
(13.45)
where the clutter-plus-noise vector w(t) = [w1(t), w2(t), . . . , wN(t)]T is assumed to be zero mean
Gaussian and satisfy E{w(t)wH(t −τ)} = Qδ(τ). The reﬂection coefﬁcient vector
ζ =

ζ11, ζ12, . . . , ζN M
T
(13.46)
is a complex Gaussian random vector, where E{ζζ H} = R. Assume the matrices Q and R are both
known, possibly from the pre-processing stage (e.g., the detection stage) or an adaptive procedure.6 For
notational simplicity, we further assume that ζ has zero mean. The matrix U in (13.45) has the same
form as (13.7) with ul = [ul1, ul2, . . . , ulM]T . However, in this case, the ulk has a different deﬁnition,
which is given by
ulk = sk(t −τlk)e j2π flkt.
2.13.3.1 Joint location and velocity estimation
Similar to the discussion in Section 2.13.2.1, suppose the observed signal vector ˜r(t), a realization of
the r(t) in (13.45), is available. Our goal is to obtain the ML estimates of the target location and velocity
based on the knowledge of ˜r(t). Using the signal model in (13.45), the likelihood ratio with respect to
θJ = [x, y, vx, vy]T conditioned on the reﬂection coefﬁcient ζ can be derived
J

θJ; ˜r(t)|ζ

= C′
1 exp

E
M zHζ +

E
M ζ Hz −E
M ζ HVζ

,
(13.47)
6Assume the target has already been detected using a radar with a fairly coarse grid so we know the distances approximately,
and one can develop speciﬁc relative values for variances for the reﬂection coefﬁcients for different paths from transmit to
receive antennas based on this.

2.13.3 Noncoherent MIMO Radar
681
where C′
1 is a constant not dependent on θJ. In (13.47), V
=
 ∞
−∞UHQ−1U dt and z
=
 ∞
−∞UHQ−1˜r(t) dt, where the integral over time operates on each element of the corresponding matrix.
Employing the probability density function (pdf) of the reﬂection coefﬁcient
pζ(ζ) =
1
π N M det R exp

−ζ HR−1ζ

(13.48)
to average ζ out, we ﬁnd the likelihood ratio as a function of the unknown parameter θJ
J

θJ; ˜r(t)

=

ζ
J

θJ; ˜r(t)|ζ

pζ(ζ)dζ
= C′
2 det (X) exp
 E
M zHX−1z

,
(13.49)
where C′
2 is a constant not dependent on θJ,

ζ implies the multidimensional integral over all possible
values of ζ, and
X = E
M V + R−1.
(13.50)
In the calculations, we have assumed that the matrices Q, R, and X have full rank, and are hence
invertible. Note that the invertibility of R is reasonable for MIMO radar with widely spread antennas
and a target composed of a large number of scatters [5]. Further, due to thermal noise, Q is also likely
a full-rank matrix. From (13.49), the log-likelihood ratio can be expressed as
LJ

θJ; ˜r(t)

= ln J

θJ; ˜r(t)

= E
M zHX−1z + ln det (X) + ln C′
2.
(13.51)
Thus, the ML estimate of the unknown parameter vector θJ is
ˆθJ,ML = arg max
θJ
LJ(θJ; ˜r(t))
= arg max
θJ
 E
M zHX−1z + ln det (X)

.
(13.52)
Next we employ some simplifying assumptions,7 which are quite reasonable for cases with widely
spaced antennas, which simplify matters.
Assumption 3.
Assume that the reﬂection coefﬁcients for different paths ζlk, l = 1, . . . , N, k =
1, . . . , M areindependent,suchthatthecovariancematrixofζ = [ζ11, ζ12, . . . , ζN M]T isdiagonal,i.e.,
R = E

ζζ H
= diag

σ 2
11, σ 2
12, . . . , σ 2
N M

,
(13.53)
where σ 2
lk represents the variance of ζlk.
7In [24] the authors have simulated a few cases where such assumptions do not exist and found similar results.

682
CHAPTER 13 MIMO Radar with Widely Separated Antennas
Consider the case where Assumptions 1–3 hold true. Thus, Q = σ 2
wI, V = (1/σ 2
w)I, and the
log-likelihood ratio in (13.51) is reduced to
LJ

θJ; ˜r(t)

=
M

k=1
N

l=1
Llk

θJ; ˜rlk(t)

,
(13.54)
where
Llk

θJ; ˜rlk(t)

=
σ 2
lk E
(σ 2
lk E + σ 2wM)σ 2w

 ∞
−∞
˜rlk(t)s∗
k (t −τlk)e−j2π flktdt

2
+ C′
3.
(13.55)
In (13.55), C′
3 is a constant not dependent on θJ and ˜rlk(t) represents the observed signal corresponding
to the lkth path, which is modeled as
rlk(t) =

E
M ζlksk(t −τlk)e j2π flkt + wl(t).
(13.56)
Accordingly, the ML estimate can be reduced to
ˆθ
non
J,ML = arg max
θJ
 N

l=1
M

k=1
σ 2
lk E
(σ 2
lk E + σ 2wM)σ 2w

 ∞
−∞
˜rlk(t)s∗
k (t −τlk)e−j2π flktdt

2
.
(13.57)
Unlike (13.22), in the estimator from (13.57), the squared magnitude is taken before the summation.
Thus, these terms will always add in phase and so we do not need all transmitters and receivers to be
synchronized in phase. Therefore, this is a noncoherent processing (across sensors). Note that under
Assumptions 1–3, the noncoherent processing is optimal for the noncoherent target reﬂection model in
Figure 13.3.
Having obtained the ML estimate for the joint location and velocity estimation, let us introduce a
theorem that shows how the number of antennas affects the estimation performance.
Theorem 1.
For a MIMO radar equipped with M transmit and N receive antennas, under Assump-
tions 1–3 and assume that the observations follow the assumed model in (13.56), the ML estimate as
described in (13.57) converges almost surely to the true parameter value when M N is sufﬁciently large
ˆθ
non
J,ML
a.s.
→θa, as M N →∞.
(13.58)
It follows that the ML estimate is asymptotically (M N →∞) unbiased and its variance must asymp-
totically approach the CRB as M N →∞.
This theorem indicates that increasing the number of antennas properly can improve the estimation
performance of noncoherent MIMO radar. Interested readers are referred to [24] for a proof of this
theorem.
To evaluate the estimation performance of noncoherent MIMO radar, in the sequel, we develop the
CRBs for the joint location and velocity estimation assuming that Assumptions 1–3 hold true. The ﬁrst

2.13.3 Noncoherent MIMO Radar
683
step in obtaining the Cramer-Rao bound is to compute the FIM, which is a four-dimensional matrix
related to the second order derivatives of the log-likelihood ratio in (13.54) [15]
J(θJ) = −E

∇θJ

∇θJ LJ

θJ; ˜r(t)
T 
.
After lengthy algebraic manipulations, following the steps similar to those in Section 2.13.2, the expres-
sion of the FIM can be obtained as below [24]:
J(θJ) =
M

k=1
N

l=1
8π2σ 4
lk E2
(σ 2
lk E + σ 2wM)σ 2wM
⎡
⎢⎢⎣
εka2
lk + 2γlkalkelk + ηlke2
lk
(εkalk + γlkelk)blk + (γlkalk + ηlkelk)glk (γlkalk + ηlkelk)βlk (γlkalk + ηlkelk)qlk
(εkalk + γlkelk)blk + (γlkalk + ηlkelk)glk
εkb2
lk + 2γlkblkglk + ηlkg2
lk
(γlkblk + ηlkglk)βlk (γlkblk + ηlkglk)qlk
(γlkalk + ηlkelk)βlk
(γlkblk + ηlkglk)βlk
ηlkβ2
lk
ηlkβlkqlk
(γlkalk + ηlkelk)qlk
(γlkblk + ηlkglk)qlk
ηlkβlkqlk
ηlkq2
lk
⎤
⎥⎥⎦,
(13.59)
where alk ≡∂τlk/∂x, blk ≡∂τlk/∂y, elk ≡∂flk/∂x, glk ≡∂flk/∂y, βlk ≡∂flk/∂vx, qlk ≡
∂flk/∂vy,
εk =
 ∞
−∞
f 2 |Sk( f )|2 d f −

 ∞
−∞
f |Sk( f )|2 d f

2
,
(13.60)
γlk = 1
2π ℑ
 ∞
−∞
tsk(t −τlk)∂s∗
k (t −τlk)
∂τlk
dt

−
 ∞
−∞
f |Sk( f )|2 d f
 ∞
−∞
t |sk(t −τlk)|2 dt,
(13.61)
and
ηlk =
 ∞
−∞
t2 |sk(t −τlk)|2 dt −

 ∞
−∞
t |sk(t −τlk)|2 dt

2
,
(13.62)
with Sk( f ) representing the Fourier transform of sk(t). Thus, the Cramer-Rao bounds for the estimates
of the unknown parameters can be determined by the diagonal elements of the inverse of the FIM as
follows:
CRBnon
x
=

J−1(θJ)

1,1 ,
CRBnon
y
=

J−1(θJ)

2,2 ,
CRBnon
vx
=

J−1(θJ)

3,3 ,
CRBnon
vy =

J−1(θJ)

4,4 .
Note that for any non-singular FIM, a closed-form expression for the Cramer-Rao bound can be easily
obtained, since the analytical form of J−1(θJ) can be derived from (13.59) using Cramer’s rule.
Example
Consider a noncoherent MIMO radar that has M transmitters and N receivers. The distance between
each antenna and the origin is 7000 m. If the angles are measured with respect to the horizontal axis, then
the transmitters are assumed to be uniformly distributed in [0, 2π), where the angle of the kth transmitter

684
CHAPTER 13 MIMO Radar with Widely Separated Antennas
−5
0
5
10
15
20
25
30
35
10
−6
10
−4
10
−2
10
0
10
2
10
4
10
6
10
8
MSE
mle for x
mle for y
crb for x
crb for y
mle for vx
mle for vy
crb for vx
crb for vy
SCNR (dB) 
FIGURE 13.4
MSE versus SCNR for a noncoherent MIMO radar with 5 × 4 antennas uniformly placed in [0, 2π).
is ϕt
k = 2π(k −1)/M, k = 1, . . . , M. The receivers are also assumed to be uniformly distributed in
[0, 2π), where the angle of the lth receiver is ϕr
l = 2π(l −1)/N, l = 1, . . . , N. Assume the lowpass
equivalents of the transmitted waveforms are frequency spread single Gaussian pulse signals
sk(t) =
 2
T 2
!1/4
exp
 −πt2
T 2
+ j2πk ft
!
,
(13.63)
where T is proportional to the pulse width and f = fk+1 −fk ≥0 is the frequency increment between
sk(t) and sk+1(t). We choose T = 0.1, f = 500 kHz, and set the carrier frequency to fc = 1 GHz.
Suppose a target moving with velocity (50, 30) m/s is present at (150, 127.5) m. Assume the variance of
each target reﬂection is the same for every path so that σlk = σ. The SCNR is deﬁned as Eσ 2/(Mσ 2
w).
Under Assumptions 1–3, the CRB and the MSE curves of the joint ML estimates are plotted versus
SCNR in Figure 13.4 for the MIMO radar system with M = 5 transmitters and N = 4 receivers. It is
observed from the simulation results that the MSEs of the ML estimates approach the corresponding
CRBs as the SCNR becomes large. This is consistent with the theoretical asymptotic efﬁciency of ML
estimates and also corroborates the correctness of the derived CRBs presented earlier.
The curves for a noncoherent MIMO radar with M = 9 transmitters and N = 9 receivers are plotted
in Figure 13.5. Compared with Figure 13.4, it is seen that increasing the number of antennas decreases
the CRB uniformly and lowers the threshold (i.e., the SCNR at which the MSE curve changes slope
drastically, see arrows in the ﬁgure) to a smaller value. We also ﬁnd that these MSE curves get more

2.13.3 Noncoherent MIMO Radar
685
−5
0
5
10
15
20
25
30
35
10
−6
10
−4
10
−2
10
0
10
2
10
4
10
6
10
8
SNR (dB)
MSE
mle for x
mle for y
crb for x
crb for y
mle for vx
mle for vy
crb for vx
crb for vy
FIGURE 13.5
MSE versus SCNR for the 9×9 noncoherent MIMO radar with transmit antennas placed uniformly in [0, 2π)
and receive antennas also placed uniformly in [0, 2π).
favorable (closer to CRB in the asymptotic region) with more antennas. These results show that more
antennas means better performance in both asymptotic (large M N) and non-asymptotic cases.
More explorations on the noncoherent MIMO radar joint location and velocity estimation are pre-
sented in [24], which include the analyses on the threshold phenomenon, the impact of ﬁnite system
resources, the effects of changing antenna placement, the effects of employing different waveforms, and
the noncoherent ambiguity function. Extensions to several general cases, such as for dependent reﬂection
coefﬁcients, nonorthogonal signals, andfor spatiallycoloredclutter-plus-noise, arealsoprovidedin[24].
2.13.3.2 Noncoherent ambiguity function
Having studied the CRB, we now consider the ambiguity function (AF) for noncoherent MIMO radar.
Under Assumptions 1–3, the noncoherent AF has been developed in [24] in two different ways yielding
χnon(x, y, vx, vy) =
1
M N
M

k=1
N

l=1

 ∞
−∞
sk(t)s∗
k (t −τlk)e−j2π flkt dt

2
,
(13.64)
where τlk = τlk −τ0lk, with τ0lk determined by the antenna positions which can be obtained by
substituting (x, y) = (0, 0) into (13.2). Note that since the τlk and flk in (13.64) are functions of

686
CHAPTER 13 MIMO Radar with Widely Separated Antennas
(x, y) and (x, y, vx, vy), respectively, the AF is essentially a four-dimensional function with respect to
variables (x, y, vx, vy). Interested readers are referred to [24] for more detailed derivations.
Example
Consider a noncoherent MIMO radar system with M transmit and N receive antennas uniformly
placed in direction [0, 2π), where the look angles are ϕt
k = 2π(k −1)/M, k = 1, . . . , M and
ϕr
l = 2π(l −1)/N, l = 1, . . . , N. To make the AF a simple two-dimensional function that we can
plot and easily interpret, we assume the target only move along the y-axis such that (x, vx) = (0, 0).
Further assume that the monitored area is relatively small and all antennas are located sufﬁciently far
away, so that the τlk and flk can be approved to be approximately linearly related to y and vy through
τlk ≈y
c ( sin ϕt
k + sin ϕr
l ),
(13.65)
flk ≈vy
λ ( sin ϕt
k + sin ϕr
l ).
(13.66)
Thus, the noncoherent AF from (13.64) can be simpliﬁed to
χnon(y, vy) =
1
M N
M

k=1
N

l=1

 ∞
−∞
sk(t)s∗
k

t −y

sin ϕt
k + sin ϕr
l

/c

e−j2πvy

sin ϕt
k+sin ϕr
l

t/λ dt

2
.
(13.67)
Assume frequency spread single Gaussian pulse signals are used for transmission, whose complex
envelopes sk(t) are given in (13.63). Plugging sk(t) into (13.67), the simpliﬁed noncoherent AF for the
single Gaussian pulse can be obtained
χnon(y, vy) =
1
M N
M

k=1
N

l=1
e
−π

sin ϕt
k+sin ϕr
l
2
y2/(T 2c2)+T 2v2y/λ2
.
The AFs of noncoherent MIMO radar systems with different conﬁgurations are plotted in Figure 13.6.
The system considered in Figure 13.6a has 2 transmitters and 3 receivers, while the system considered
in Figure 13.6b has 5 transmitters and 4 receivers. Using the previously deﬁned simpliﬁed AF for
the speciﬁc examples under study, it can be seen that the mainlobe of AF becomes narrower as more
antennas are added. This is easier to read in the 0.5-level contour plots shown in Figure 13.6c. Narrower
AF means better resolution, thus the performance is improved by using more antennas in this example.
Assume frequency spread Gaussian pulse trains are used for transmission, thus the signal transmitted
from the kth transmitter is
sk(t) =
∞

n=−∞
z(t −nTr)g(t)e j2πk ft,
(13.68)
where Tr is the pulse repetition interval, z(t) the narrow Gaussian pulse with pulsewidth T , g(t)the
broad Gaussian envelope with pulsewidth Tb, and f the frequency increment. Plugging sk(t) into

2.13.3 Noncoherent MIMO Radar
687
y/c
vy
-0.2
-0.15
-0.1
-0.05
0
0.05
0.1
0.15
0.2
-200
-150
-100
-50
0
50
100
150
200
2 3
5 4
(c)
(b)
(a)
FIGURE 13.6
AF of noncoherent MIMO radar systems transmitting frequency spread single Gaussian pulse signals with
(a) 2 × 3, (b) 5 × 4 antennas, and their (c) 0.5-level contour, assuming that (x, vx) = (0, 0).
(13.67) gives the simpliﬁed noncoherent AF for the Gaussian pulse train
χnon(y, vy) =
1
M N
M

k=1
N

l=1

1
T 2r
∞

n=−∞
∞

m=−∞
exp

−π
 y
c

sin ϕt
k + sin ϕr
l

−nTr
2 1
T 2 −π
 m
Tr
!2
T 2
−
y2π
T 2
b c2

sin ϕt
k + sin ϕr
l
2 −π
 vy
λ

sin ϕt
k + sin ϕr
l

−m
Tr
!2
T 2
b

.
The AF for the noncoherent MIMO radar system with 5 transmitters and 4 receivers is plotted in
Figure 13.7a, while the AF for the noncoherent MIMO radar system with 9 transmitters and 9 receivers
is plotted in Figure 13.7b. We see that ambiguity sidelobes are created by the use of the Gaussian pulse
FIGURE 13.7
AF of noncoherent MIMO radar systems transmitting frequency spread Gaussian pulse trains with (a) 5 × 4
and (b) 9 × 9 antennas, assuming that (x, vx) = (0, 0).

688
CHAPTER 13 MIMO Radar with Widely Separated Antennas
train. Comparing Figure 13.7b to a, it is seen that when the number of antennas increases, the sidelobes
decease for the example considered here and our simpliﬁed AF. Again, these examples illustrate that
using more antennas can give a better AF for noncoherent MIMO radar.
2.13.4 Performance and complexity analysis for coherent
and noncoherent MIMO radar
In the previous sections, we have introduced the coherent and noncoherent MIMO radar systems and
investigatedtheirjointtargetlocationandvelocityestimationabilities.Thecharacteristicsofthecoherent
and noncoherent MIMO radar merit more discussions. As opposed to the noncoherent counterpart, the
coherent MIMO radar requires extra phase synchronization, which may not be very amenable to practical
implementation. Aiming to identify possible scenarios that enable us to replace the coherent MIMO
radar with the easier-to-implement noncoherent one but without inducing much loss in performance,
we devote this section to studying the MSE performance difference between these two approaches.
It was indicated in [11] that when target localization is the application of interest, signiﬁcant gains can
be obtained through the use of coherent MIMO radar, over noncoherent radar. Here we will demonstrate
that the magnitude of these gains decreases with an increase in the product of the number of transmit and
receive antennas. In particular, the performance of the noncoherent MIMO radar approaches that of the
coherent MIMO radar when the product of the number of transmit and receive antennas is sufﬁciently
large.
2.13.4.1 Normalized mean square error difference
Let θa = [θa,1, θa,2, . . .]T and ˆθ = [ ˆθ1, ˆθ2, . . .]T denote the actual and estimated value of the parameter
vector to be estimated θ = [θ1, θ2, . . .]T . Deﬁne the total MSE of the joint estimation as
MSE = E

i
Wi( ˆθi −θa,i)2

=

i
WiE

( ˆθi −θa,i)2
=

i
WiMSEi,
(13.69)
where W = [W1, W2, . . .]T deﬁnes a constant weighting vector with the same length as θ and MSEi =
E{( ˆθi −θa,i)2} represents the MSE corresponding to the ith component of θ (i.e., θi). Note here we
consider a weighted MSE that allows one to give extra priority to some components over others. Of
course, taking the weight as a constant vector is also possible, which gives equal weight to all the
components.
Theorem 1.
Consider a MIMO radar equipped with M separated transmit antennas and N separated
receive antennas for joint location and velocity estimation. Assume the coherent MIMO radar (13.22)
performs better (in the sense of leading to a smaller MSE) than the noncoherent MIMO radar (13.57)
for all M and N. Under Assumptions 1 and 2, the MSE of the ML estimate for the noncoherent MIMO
radar (MSEnon) gets as close as desired to that of the coherent MIMO radar (MSEcoh) for sufﬁciently
large M N.
For a detailed proof of the theorem, please refer to [16].

2.13.4 Performance and Complexity Analysis for Coherent and Noncoherent
689
Remark 1.
Theorem 1 implies that under the given assumptions, the noncoherent MIMO radar, which
has less stringent synchronization requirements, is generally more preferable than its coherent coun-
terpart for sufﬁciently large M N. Stated a different way: (1) If the noncoherent MIMO radar leads
to smaller MSE than the coherent MIMO radar, the noncoherent MIMO radar is preferred without
a doubt, since it performs better and has less stringent synchronization requirements; (2) otherwise,
if the coherent MIMO radar leads to smaller MSE than the noncoherent MIMO radar, as shown by
Theorem 1, one can add more antennas to compensate, so that at some large M N the MSE performance
of the noncoherent MIMO radar is sufﬁciently close to that of the coherent MIMO radar and thus the
noncoherent MIMO radar is good enough.
Based on the total MSEs of the joint estimation for the coherent and noncoherent MIMO radars,
assuming a known constant θa, we deﬁne the normalized difference of the root mean square errors
(NDRMSE) to evaluate the overall difference in the MSE of the coherent and noncoherent MIMO
radars as below
NDRMSE = (MSEnon)1/2 −(MSEcoh)1/2
( "
i Wiθ2
a,i)1/2
× 100%,
(13.70)
whereitisassumedthatθa ̸= 0.Ifθa = 0,thenwewoulduse[(MSEnon)1/2−(MSEcoh)1/2]directly.The
smaller the NDRMSE, the closer the MSE performance between the two estimators. For a predetermined
value of ϵ, which is chosen to satisfy particular requirements, the MSE performance of the noncoherent
MIMO radar is considered to be good enough if NDRMSE ≤ϵ%, and in such cases the noncoherent
MIMO radar is preferred for its less stringent synchronization requirements.
Particularly, in the joint location and velocity estimation problem discussed previously, θ =
[x, y, vx, vy]T , so we have
MSEnon = W1E

ˆθnon
x
−θa,x
2
+ W2E

ˆθnon
y
−θa,y
2
+ W3E

ˆθnon
vx
−θa,vx
2
+ W4E

ˆθnon
vy
−θa,vy
2
,
(13.71)
MSEcoh = W1E

ˆθcoh
x
−θa,x
2
+ W2E

ˆθcoh
y
−θa,y
2
+ W3E

ˆθcoh
vx
−θa,vx
2
+ W4E

ˆθcoh
vy −θa,vy
2
,
(13.72)
and
NDRMSE =
(MSEnon)1/2 −(MSEcoh)1/2
(W1θ2a,x + W2θ2a,y + W3θ2a,vx + W4θ2a,vy)1/2 × 100%,
(13.73)
where it is assumed that W = [W1, W2, W3, W4]T . Note that one can easily adjust for units by proper
selection of Wi. Later in the numerical examples, we employ Wi = 1 for all i.

690
CHAPTER 13 MIMO Radar with Widely Separated Antennas
2.13.4.2 Numerical examples
Example 1
Consider a MIMO radar that has M transmitters and N receivers. When employing the coherent MIMO
radar, the antennas are uniformly placed in [π/6, π/3], where ϕt
k = π(k −1)/[6(M −1)] + π/6 and
ϕr
l = π(l −1)/[6(N −1)] + π/6. In the example, Assumptions 1 and 2 are adopted. When employing
the noncoherent MIMO radar, the antennas are uniformly placed in direction [0, 2π), where the angle
of transmitter k with respect to the horizontal axis is ϕt
k = 2π(k −1)/M + π/8, k = 1, . . . , M and
the angle of receiver l is ϕr
l = 2π(l −1)/N, l = 1, . . . , N. Let  f = 500 kHz, such that  f > 5/T ,
and thus the transmitted signals are approximately orthogonal ([24]). Assume the SCNR is 20 dB.
Suppose the system resources employed were not considered, the energy assigned to each transmit
antenna was ﬁxed, so adding a transmit antenna implies an extra energy source and increased total
transmitted energy. In this case, the NDRMSEs are plotted versus M N with N (or M) going from
1 to 20 for a ﬁxed M = 4 (or N = 4) in Figure 13.8a. It is observed that increasing either M or
N decreases the NDRMSE, which makes the MSE performance of the noncoherent MIMO radar get
closer to that of the coherent MIMO radar. When the system resources employed are taken into account,
the situation becomes complicated. In such cases, the total transmitted energy is ﬁxed, so that adding
transmit antennas means splitting the energy over more antennas. Figure 13.8b shows such an example.
Under the energy constraint, the NDRMSEs are plotted versus M N with the other parameters set the
same as Figure 13.8a. It is observed that, when the total energy is ﬁxed, increasing the number of receive
antennas N always decreases NDRMSE, but this is not true when we increase the number of transmit
antennas M for a ﬁxed N. Increasing M ﬁrst decreases the NDRMSE (when M is small, e.g., M ≤4
in this example), but later increases the NDRMSE when M is large (e.g., M > 4 in this example). Here
0
10
20
30
40
50
60
70
80
1
2
3
4
5
6
7
8
9
10
MN (product of number of antennas)
(a)
(b)
NDRMSE %
M=4, N=1~20
N=4, M=1~20
0
10
20
30
40
50
60
70
80
2
3
4
5
6
7
8
9
10
11
12
MN (product of number of antennas)
NDRMSE %
M=4, N=1~20
N=4, M=1~20
FIGURE 13.8
NDRMSEs versus MN with an increasing N (or M) for a ﬁxed M (or N) for the joint estimation with (a)
unconstrained energy or (b) constrained energy. SCNR = 20 dB.

2.13.4 Performance and Complexity Analysis for Coherent and Noncoherent
691
we see the effects of spreading the energy too thinly between the transmit antennas. This occurs when
M is too large.
2.13.4.2.1
Example 2
Consider the same scenario in Figure 13.8, except that the antenna positions for the noncoherent
MIMO radar are different. Here the transmit antennas are assumed to be at (xt
k, 7000) m, xt
k =
10, 000(k −1)/(M −1) −3000, k = 1, . . . , M and the receive antennas are assumed to be at
(7000, yr
l ) m, yr
l
= 10, 000(l −1)/(N −1) −3000, l = 1, . . . , N. In this example, we ﬁx the
total number of antennas to M + N = 50. This is an approximate way to ﬁx the total system com-
plexity, since each added antenna implies the addition of several accompanying hardware components.
Further, counting system complexity through the total number of antennas used can obviate the need
for getting involved with details related to the hardware implementation. This is very useful in a high
level study like the one we undertake here.
When the energy is unconstrained, i.e., the transmit energy per transmit antenna is ﬁxed so that adding
a transmit antenna increases the total transmit energy, the RMSEis are plotted in Figure 13.9a. It is seen
that there is a symmetry between M and N, and the minima for both the coherent and noncoherent
MIMO radars occur at M = 25 = (M + N)/2, as expected. When the total energy is constrained,
i.e., adding a transmit antenna decreases the transmit energy per transmit antenna, the RMSEis are
20
40
10
20
30
40
50
60
70
M
RMSE
x, non
y, non
20
40
0.01
0.015
0.02
0.025
M
RMSE
x, coh
y, coh
20
40
0.05
0.1
0.15
0.2
0.25
0.3
0.35
M
RMSE
vx, non
vy, non
20
40
0.02
0.03
0.04
0.05
0.06
0.07
0.08
M
RMSE
vx, coh
vy, coh
20
40
100
200
300
400
500
600
M
RMSE
x, non
y, non
20
40
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
0.18
0.2
M
RMSE
x, coh
y, coh
20
40
0.5
1
1.5
2
2.5
3
M
RMSE
vx, non
vy, non
20
40
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
0.55
M
RMSE
vx, coh
vy, coh
(a)
(c)
(d)
(b)
0
10
20
30
40
50
2
4
6
8
10
12
14
16
18
20
22
M
NDRMSE %
0
10
20
30
40
50
0
20
40
60
80
100
120
140
160
180
M
NDRMSE %
 Unconstrained energy          
 Unconstrained energy          
Constrained energy
Constrained energy
FIGURE 13.9
RMSEi’s (in m for location and m/s for velocity) for the joint estimation of location and velocity with (a)
unconstrained energy or (b) constrained energy, and the corresponding NDRMSEs (c)–(d) versus M. M +N =
50. SCNR = 20 dB.

692
CHAPTER 13 MIMO Radar with Widely Separated Antennas
plotted in Figure 13.9b. It is seen that the effects of increasing M and N are asymmetric. For both the
coherent and noncoherent MIMO radars, M = 4 is the best, and further increasing M will degrade the
performance. The NDRMSEs for the unconstrained and constrained energy cases are plotted versus M
in Figure 13.9c and d, respectively. The best MSE performance occurs at M = (M + N)/2 for the
unconstrained case and for an M such that 1 < M < (M + N)/2 for the constrained case. In fact we
have tested other cases (different placements and ﬁxed M + N value) and obtained similar results.
The main point is that if we ﬁx the total energy and if we add too many transmit antennas then we
will spread the energy too thinly among the transmit antennas and this will lead to bad performance.
On the other hand, there are cases where we get gains from adding transmit antennas with ﬁxed total
energy, for example, when we do not spread the energy too thinly. Usually, it is better to use more than
one transmit antenna to obtain good performance. Further numerical investigations and discussions can
be found in [16].
2.13.5 Diversity gain for MIMO radar Neyman-Pearson signal detection
So far, the chapter has been about MIMO radar for estimation. In this section, we discuss the diversity
gain that a MIMO radar system can render in the context of target detection. Diversity gain is one
signiﬁcant advantage that MIMO radar systems employing separated antennas can bring forth when
compared with more traditional radar systems. When the Neyman-Pearson criterion is employed, for a
ﬁxed false alarm probability, diversity gain is deﬁned as the negative of the slope of the miss probability
versus SCNR for the high SCNR region when a logarithmic scale is employed for both axes. Assuming
linear decay of the miss probability for sufﬁciently large SCNR when such scales are employed, large
diversitygainimpliesgoodtargetdetectionperformanceforsufﬁcientlyhighSCNRandﬁxedprobability
of false alarm. If we have two detectors and one has larger diversity gain, then at some sufﬁciently large
SCNR, the detector with larger diversity gain must have smaller miss probability. Intuitively, diversity
gain tells us about the value of the information we get from multiple looks (from several antennas,
frequencies, or retransmissions, etc.).
2.13.5.1 Signal model
Consider a radar system that has M transmit and N receive antennas. The positions of the transmit
and receive antennas of the radar system are (xt
k, yt
k), k = 1, . . . , M and (xr
l , yr
l ), l = 1, . . . , N,
respectively. Denote the waveform transmitted by the kth antenna by sk(t), where sk(t) and sk′(t)
can be non-orthogonal for k ̸= k′, in the sense of [4]. Assume each waveform is normalized to give
transmitted power E. The radar will break up the monitored space into cells and sequentially probe each
cell for a target. Thus, our goal is to ﬁnd out whether a target is at a particular position or not. Assume a
target, if present, is composed of Q point scatterers, located at (xq, yq), q = 1, . . . , Q. The reﬂection
coefﬁcient, ζq for the qth scatterer, is assumed to be constant over the observation interval.
The clutter-plus-noise-free received signal at receive antenna l due to the transmission from transmit
antenna k and the reﬂection from the qth scatterer is modeled as [4]
rq
lk(t) =

E
M ζqsk

t −τ q
lk

e−j2π fcτq
lk,
(13.74)

2.13.5 Diversity Gain for MIMO Radar Neyman-Pearson Signal Detection
693
where
τ q
lk = (dq
tk + dq
rl)/c
denotes
the
time
delay
from
transmit
antenna
k
to
receive
antenna l due to the reﬂection from the qth scatterer, dq
tk = [(xt
k −xq)2 + (yt
k −yq)2]1/2, dq
rl =
[(xr
l −xq)2 + (yr
l −yq)2]1/2, and c is the speed of light. Assume the transmitted waveforms are rel-
atively narrow band, where the bandwidth of the waveforms is given such that they are not capable of
resolving individual scatterers [5]. Therefore,
sk

t −τ q
lk

≈sk

t −τ 0
lk

,
q = 1, . . . , Q,
(13.75)
where τ 0
lk denotes the time delay from a reﬂection off a scatterer located at the gravity center of the
scatterers (x0, y0). Then (13.74) can be written as
rq
lk(t) =

E
M ζqsk

t −τ 0
lk

e−j2π fcτq
lk.
(13.76)
Thus, the received signal at receive antenna l due to the propagation from all M transmit antennas and
all Q scatterers is given by
rl(t) =

E
M
Q

q=1
M

k=1
ζqsk

t −τ 0
lk

e−j2π fcτq
lk + wl(t),
(13.77)
where wl(t) denotes the clutter-plus-noise observed at the lth receiver.
2.13.5.2 Effect of signal space dimension on diversity gain
Suppose we attempt to implement the optimum receiver for the Gaussian reﬂection coefﬁcients and
Gaussian clutter-plus-noise case following (13.77), by ﬁrst projecting the received continuous-time
observations onto a basis that spans the space spanned by the ﬁrst term, the signal term, in (13.77).
Let the set of Ml orthonormal basis functions {φl1(t), φl2(t), . . . , φlMl(t)} span the Ml dimensional
space spanned by the ﬁrst term, the signal term, of (13.77). The expansion, in terms of this basis, of any
delayed signal term appearing in (13.77) can be expressed as
sk

t −τ 0
lk

=
Ml

i=1
slkiφli(t)
(13.78)
with the coefﬁcients deﬁned by
slki =
 ∞
−∞
sk

t −τ 0
lk

φli(t),
i = 1, . . . , Ml,
(13.79)
which are obtained by using (orthonormal basis)
 ∞
−∞
φli(t)φli′(t)dt =
1, i = i′,
0, otherwise,
(13.80)

694
CHAPTER 13 MIMO Radar with Widely Separated Antennas
after taking the inner product with φli(t) (right hand side of (13.79)) on both sides of (13.78). We note
that the largest possible value of Ml is M and this occurs when each of the delayed signal terms in
(13.77), the terms expanded in (13.78), are linearly independent. Now we can project the received signal
rl(t) in (13.77) onto this basis to obtain8
rli =
 ∞
−∞
rl(t)φli(t)dt
=

E
M
M

k=1
slki
Q

q=1
ζq e−j2π fcτq
lk + wli
=

E
M
M

k=1
slkiAlkζ + wli,
i = 1, . . . , Ml,
(13.81)
where Alk = [e−j2π fcτ 1
lk, . . . , e−j2π fcτ Q
lk ], and ζ = [ζ1, . . . , ζQ]T is a vector of reﬂection coefﬁcients
for those Q scatterers. Collecting the Ml outputs and letting rl = [rl1, . . . ,rlMl]T , we have
rl =

E
M
M

k=1
slkAlkζ + wl,
(13.82)
where
slk = [slk1, . . . , slkMl]T
(13.83)
and wl = [wl1, . . . , wlMl]T . Further, stacking the outputs across all the N receivers into a single vector
gives
r =

rT
1 , . . . , rT
N
T
= [r11,r12, . . . ,rN MN ]T
=

E
M Diag{S1, . . . , SN}Aζ + w
=

E
M CAζ + w,
(13.84)
where
C = Diag{S1, . . . , SN}
(13.85)
denotes a block diagonal matrix with submatrices S1, …, SN on its diagonal, and the size of each
submatrix
Sl =

sl1, . . . , slM

(13.86)
8Choosing an orthogonal set in a particular manner, say using the Karhunen-Loeve expansion [23], allows one to represent
the received continuous signals by a set of random variables that compose a sufﬁcient statistic for the target-absent versus
target-present hypothesis testing problem.

2.13.5 Diversity Gain for MIMO Radar Neyman-Pearson Signal Detection
695
is Ml × M; A =

AT
11, AT
12, . . . , AT
N M
T is an N M × Q matrix. Let
˜M = M1 + · · · + MN,
(13.87)
then the dimension of matrix C is given by ˜M × N M. The w = [wT
1 , . . . , wT
N]T in (13.84) is an
˜M × 1 clutter-plus-noise vector with covariance matrix Rw. Based on (13.84), we have the following
results which elaborate the diversity gain offered by MIMO radar systems employing non-orthogonal
waveforms.
Theorem 1.
Consider a MIMO radar system with M transmit and N receive antennas and observa-
tions following (13.77) with possibly nonGaussian clutter-plus-noise and reﬂection coefﬁcients. After
expanding the received signals using basis functions as per (13.81) and collecting the coefﬁcients as
per (13.84), the detection system can be described by a hypothesis testing problem as follows:
H1 : r =

E
M CAζ + w,
(13.88)
H0 : r = w.
Assume that a detector of the class of
T = rHDDHr = ∥DHr∥2 ≷H1
H0 δ.
(13.89)
is employed with an arbitrary D that meets ∥D∥< ∞and a positive ﬁnite threshold δ determined by
the required false alarm probability. Plug (13.88) under H1 into (13.89) and write the test statistic in
the form of
T = E
M ˜u + w,
(13.90)
to deﬁne ˜u and w. If the cumulative distribution function (cdf) of ˜u, denoted as F˜u(˜u), satisﬁes
F˜u(˜u) = ˜u pG + o

˜u p
,
as ˜u →0+
(13.91)
for some constant9 0 ≤p < ∞and nonzero constant G < ∞, and
E

√
δ ± ∥DHw∥

2p
< ∞
(13.92)
holds true, then the diversity gain achieved by this system is d = p.
Remark 2.
For the hypothesis testing problem in (13.88), if the clutter-plus-noise w is zero-mean
Gaussian with covariance matrix Rw and the reﬂection coefﬁcient ζ is zero-mean Gaussian with covari-
ance matrix R, then the detector in (13.89) is optimum for
D = R−1
w CAXH
1 ,
(13.93)
where X1 satisﬁes XH
1 X1 = [γ ′(CA)HR−1
w CA + R−1]−1 and γ ′ denotes the SCNR the detector is
designed for.
9The notation ˜u →0+ means ˜u approaches 0 from right. Note that in the cases where p = 0 we will get no diversity gain.

696
CHAPTER 13 MIMO Radar with Widely Separated Antennas
Theorem 2.
Consider a MIMO radar system with M transmit and N receive antennas attempting to
detect the presence of a target with Q scatterers. Assume observations following (13.77) with possibly
nonGaussianclutter-plus-noiseandreﬂectioncoefﬁcients.Afterexpandingthe Ml-dimensionalsignalat
the lth receive antenna, l = 1, . . . , N using basis functions as per (13.81) and collecting the coefﬁcients
as per (13.84), assume that a detector of the class of (13.89) is employed, which includes the optimum
detector for Gaussian clutter-plus-noise and reﬂections. Plug (13.88) under H1 into (13.89) and write
the test statistic in the form of
T = E
M
L

ℓ=1
˜uℓ+ w = E
M ˜u + w,
(13.94)
where ˜u = "L
ℓ=1 ˜uℓ, to deﬁne ˜uℓand w. If each ˜uℓfor ℓ= 1, . . . , L has a cdf F˜uℓ(˜uℓ) that satisﬁes
F˜uℓ(˜uℓ) = ˜u pℓ
ℓGℓ+ o

˜u pℓ
ℓ

, as ˜uℓ→0+,
(13.95)
for some constant 0 ≤pℓ< ∞and nonzero Gℓ< ∞, and (13.92) holds true, then the maximum
diversity gain is
d =
min

M1+···+MN ,Q, rank(D)


ℓ=1
pℓ.
(13.96)
This maximum diversity gain can be achieved under some conditions, for example statistically inde-
pendent ˜u1, . . . , ˜uL, rank(CA) = rank(D), and CA has full row or column rank.
For the special case of Gaussian reﬂection coefﬁcients (Gaussian signals), it is known from [25] that
pℓ= 1, so the diversity gain is given by d ≤min

M1 + · · · + MN, Q, rank(D)

. When the Gaussian
optimum detector is employed, it can be shown that rank(D) = rank(CA) ≤min (M1 + · · · + MN, Q),
which leads to a diversity gain d ≤min

M1 + · · · + MN, Q

. Further, suppose the dimension of the
space spanned by the target-reﬂected noise-free received waveforms at different receivers are the same
for all l, such that Ml = M′. Then the largest possible diversity gain described in Theorem 2 becomes
d = min{N M′, Q}.
Assuming the number of scatterers is very large such that Q ≫N M, Theorem 2 implies that to
achieve the largest possible diversity gain, "min

N M,rank(D)

ℓ=1
pℓ, the noise-free received waveforms,
due to target reﬂection, at the lth receiver must span the entire M dimensional space. If the clutter-plus-
noise free received waveforms span a lower dimension, say Ml < M, the diversity gain will be equal
to or smaller than "min

M1+···+MN ,rank(D)

ℓ=1
pℓ, which is less than "min

N M,rank(D)

ℓ=1
pℓin this case. In
other words, MIMO radars that employ either orthogonal waveforms or non-orthogonal waveforms can
provide the maximum achievable diversity gain, as long as the noise-free received waveforms, due to
target reﬂection, at each receiver span an M dimensional space.
Example 1
Consider a MIMO radar system that has M = 2 transmit antennas located at (xt
1, yt
1) = (2, −2) km
and (xt
2, yt
2) = (6, −4) km, and N = 2 receive antennas located at (xr
1, yr
1) = (8, 2) km and (xr
2, yr
2) =
(4, 0) km. The waveforms emitted from these two transmitters are s1(t) and s2(t) respectively. Gaussian
optimum detector is employed. Assume the Q scatterers constituting the target are uniformly distributed

2.13.5 Diversity Gain for MIMO Radar Neyman-Pearson Signal Detection
697
over [0.3, 1] × [9.4, 10.5] km2. Each scatterer has a statistically independent scattering coefﬁcient. In
each example, the probability of miss versus SCNR curve is obtained from 100, 000 Monte Carlo
simulations per SCNR, and the resulting diversity gains are compared with those calculated using the
corresponding theorem from the previous sections.
Assume the reﬂection coefﬁcients and the clutter-plus-noise are statistically independent complex
Gaussian with zero mean. Assume the noise-free received waveforms (due to target reﬂection) at each
receiver, s1(t −τ 0
l1) and s2(t −τ 0
l2), l = 1, 2, are normalized and orthogonal [4]. In this case, these
waveforms themselves are the orthonormal basis functions, φl1(t) = s1(t −τ 0
l1) and φl2(t) = s2(t −τ 0
l2),
such that Ml = 2, sl1 = [1, 0]T , and sl2 = [0, 1]T as per (13.83), and the Sl in (13.86) is a 2×2 identity
matrix, for l = 1, 2. Therefore the matrix C in (13.85) is a 4 × 4 identity matrix and M1 + M2 = 4.
Further, assume the number of scatterers is Q = 1500. When the probability of false alarm is ﬁxed at
PFA = 10−3, the probability of miss detection PM is plotted versus SCNR in the solid curve with points
marked with squares in Figure 13.10. It is seen that increasing SCNR by 10 dB decreases the PM by
four decades approximately. Thus, the slope of the miss probability versus SCNR, if plotted on a log-log
scale, is approximately d = 4. This agrees well with Theorem 2, where the maximum diversity gain is
d = min (M1 + M2, Q) = min (4, 1500) = 4, recalling that pℓ= 1 for Gaussian reﬂections. Note that
in this example N M = M1 + M2 = 4, the maximum diversity gain is achieved as expected, which is
guaranteed by the statistically independent reﬂections of the Q scatterers, according to the discussion
after Theorem 2.
0
2
4
6
8
10
12
14
16
18
20
10
−5
10
−4
10
−3
10
−2
10
−1
10
0
SCNR (dB)
PM
N=2,M=2,Q=1500,orth
N=2,M=2,Q=2,orth
N=2,M=2,Q=1500,iden
FIGURE 13.10
Probability of miss versus SCNR for three difference cases under the condition of Gaussian reﬂections and
Gaussian clutter-plus-noise.

698
CHAPTER 13 MIMO Radar with Widely Separated Antennas
In the second example, we assume the number of scatterers constituting the target is reduced to
Q = 2. The other parameters are kept unchanged. The PM versus SCNR is shown in the dotted curve
with points marked with circles in Figure 13.10. It is observed that increasing SCNR by 10 dB decreases
the PM by two decades approximately. The slope of the decrease of the miss probability versus SCNR
on a log-log scale is thereby d = 2. This also justiﬁes Theorem 2, where the maximum diversity gain
is d = min (M1 + M2, Q) = min (4, 2) = 2.
The third example considers the same scenario as the ﬁrst example, except that we assume the two
noise-free received waveforms at each receiver (due to target reﬂection) are identical, s1(t −τ 0
l1) =
s2(t −τ 0
l2), where l = 1, 2. Thus, Ml = 1, sl1 = 1 and sl2 = 1, and Sl = [1, 1]. Hence, the matrix C in
(13.85) is a 2×4 matrix, and M1 + M2 = 2. In this case, PM versus SCNR is plotted in the dashed curve
with points marked with triangles in Figure 13.10. It is seen that the diversity gain is approximately
d = 2. Again, Theorem 2 is justiﬁed, since the maximum diversity gain d = min (M1 + M2, Q) =
min (2, 1500) = 2. This example illustrates the importance of the signal space spanned by the received
waveforms.
Example 2
This numerical example illustrates the maximum diversity gains that can be achieved by the MIMO
radar system employing orthogonal waveforms and the traditional phased array radar system. We focus
on Gaussian signals and clutter-plus-noise. Employ the test in (13.89) with D = IN×M = I2×2 which we
0
2
4
6
8
10
12
14
16
18
20
10
−5
10
−4
10
−3
10
−2
10
−1
10
0
SCNR (dB)
PM
N=2,M=2,Q=1500,MIMO
N=2,M=2,Q=1500,phased array
FIGURE 13.11
Probability of miss versus SCNR for MIMO and phased array (SISO) systems.

2.13.6 Phase Synchronization for Coherent MIMO Radar
699
call noncoherent MIMO radar employing orthogonal waveforms (which maintain orthogonality after
each experiencing different delays) [2], and D = aH(θ) = [1, 1] which we call coherent processing.
The resulting PM versus SCNR curves are shown in Figure 13.11. It is found that, for the noncoherent
processing (solid curve with triangles), increasing SCNR by 10 dB approximately decreases the PM
by four decades, so that d = 4, which justiﬁes d = "N M
ℓ=1 pℓ= N M for the noncoherent MIMO
radar employing orthogonal waveforms. On the other hand, for the coherent processing (dashed curve
with diamonds) used in the phased array radar, increasing SCNR by 10 dB approximately decreases the
PM by one decade so that d = 1, which justiﬁes d = p1 = 1 for the phased array radar performing
beamforming.
For more theoretical analysis and numerical examples on non-Gaussian signals and non-Gaussian
clutter-plus-noise, please refer to [25].
2.13.6 Phase synchronization for coherent MIMO radar
In the previous sections, we have elucidated the characteristics of both coherent MIMO radar and non-
coherent MIMO radar. Regardless of which mode is employed, all the elements10 in MIMO radar need
to synchronize ﬁrstly in terms of, for example, time, frequency, or phase. In fact, phase synchronization
embodies a major difference between the operations of noncoherent MIMO radar and coherent MIMO
radar: the coherent approach requires phase synchronization between the separated antenna elements,
while the noncoherent counterpart does not. Note that in reality, MIMO radar elements are usually
operated with physically different local oscillators, and each of them suffers from statistically indepen-
dent phase offset, indicating that the phase of the carrier signal transmitted gets rotated by an unknown
amount. Such imperfection in phase coherence can have an unfavorable effect on the performance of
coherent MIMO radar, e.g., [26–29]. As a result, practical implementation of coherent MIMO radar
systems needs to cope with the fundamental challenge of ensuring a common notion of phase among all
the antennas, and calls for efﬁcient algorithms which can lead to good performance in terms of phase
coherence. Although the synchronization problem has been intensely studied in several closely related
contexts, for example, in traditional radar systems (see, e.g., [30–36]) and in wireless networks includ-
ing sensor networks (see e.g., [37–44]), work that is speciﬁcally targeted at attaining phase coherence,
or phase synchronization in coherent MIMO radar seems still fragmented.
In the sequel, we will brieﬂy discuss three different approaches that have been recently developed
by us in [45] to achieve phase coherence in coherent MIMO radar, namely, the master-slave closed-
loop algorithm, the round-trip algorithm, and the broadcast consensus based algorithm. These phase
synchronization algorithms range from centralized to distributed types, and include both non-iterative
and iterative methods. They are all time asynchronous algorithms, and do not require the establishment
of time synchronization in advance. In particular, the master-slave closed-loop algorithm and the round-
trip algorithm also require no a priori frequency synchronization. These algorithms are versatile and
practically implementable, and should cater to different needs arising as a result of different number of
MIMO radar elements, different sensor placements, as well as different operational preferences.
10In this section, we use the terms sensor, node, and element interchangely.

700
CHAPTER 13 MIMO Radar with Widely Separated Antennas
2.13.6.1 Master-slave closed-loop phase synchronization
The master-slave closed-loop approach is a very simple scheme. It employs a master-slave architecture
as illustrated in Figure 13.12, where sensor S1 is denoted as the master node, and Si, i = 2, . . . , K,
as slave nodes. All the slave sensors will then synchronize their local phase with that of the master
node. We assume no a priori establishment of time synchronization across all the radar elements, at
least not one with sufﬁcient accuracy to enable phase synchronization. Each radar element maintains its
own time using its own independent local oscillator, and is able to track the elapsed time using its local
clock with relative precision. As a result of the absence of a common time reference, the instantaneous
phase of each radar element can no longer be precisely determined by the local time at that element.
For simplicity, we assume all the radar elements have a similar notion of the length of a speciﬁed time
interval, e.g., T for a time slot. In practice, this can be achieved by using identical stable clocks across
all the radar elements. Moreover, we also assume no a priori frequency synchronization among these
nodes. But we assume all the radar elements are equipped with identical frequency and phase estimators.
For this master-slave architecture, there exist two basic variations, depending on how the master
element interacts with each of these slave elements. The ﬁrst one is the open-loop approach, in which
the master node broadcasts an unmodulated sinusoidal reference signal to all the slave nodes, and each of
these slave nodes will then use such a reference signal to estimate and correct its phase offset. In this way,
interaction between the master node and slave nodes is minimal. However, the absence of a common
time reference, as we pointed out earlier, makes it difﬁcult for each sensor to generate absolute phase
with respect to the true time. As a result, phase shift induced by the channel between the master node and
each slave node can not be disambiguated at each slave node, and hence cannot be compensated either.
So, this open-loop method may lead to inferior accuracy in phase synchronization. On the other hand,
suppose the channel phase information can be measured in a certain way and then fed back explicitly
to each slave node for appropriate phase compensation, the accuracy of phase synchronization can be
much improved. This is the basic idea behind the closed-loop approach, another type of master-slave
synchronization. However, note that a fundamental premise that lies underneath this approach is the
channel reciprocity, which is assumed in this work, meaning that the channel between a pair of sensors
remains the same for both forward and reverse directions.
1S
2
S
3
S
4
S
1
K
S
K
S
FIGURE 13.12
Master-slave architecture.

2.13.6 Phase Synchronization for Coherent MIMO Radar
701
In the following, we describe a speciﬁc time-slotted closed-loop phase synchronization algorithm. In
particular, we assume each slave element is assigned a speciﬁc time slot, during which they can exchange
information with the master element S1. We further assume each slave element knows the number (or
order) of the time slot assigned to it. This time-slotted closed-loop approach is then summarized as
follows:
1. S1 broadcasts an unmodulated beacon signal to all the slave elements.
2. Upon receiving the beacon signal, each slave sensor performs the following steps concurrently:
a. It estimates the frequency and phase of the received signal.
b. It begins to count the elapsed time using its own local clock, and waits for its time slot to come.
3. When the time slot for slave element Si starts according to its local clock, the following steps will
take place in a sequential order:
a. Si passes the received beacon signal back to S1, using the local phase and frequency estimates
generated from its observation.
b. Upon receiving the returned beacon signal from Si, S1 estimates the received phase, and com-
putes the phase difference relative to the originally transmitted reference signal. It divides the
phase difference by two, pre-compensates the phase offset, and then transmits the beacon signal
back to Si.
c. After receiving the reference signal, Si estimates the phase information and adjusts its carrier
phase accordingly.
As is evident from the above procedures, it is essential to estimate the pre-compensation phase offset
for each slave node when performing this closed-loop phase synchronization scheme. But since the
channel between the master node and each slave node may vary from time to time, though at a slow
rate, the value of the pre-compensation offset has to be estimated and updated in a periodic manner. A
detailed timing analysis and phase synchronization error analysis of this algorithm can be found in [45].
2.13.6.2 Round-trip phase synchronization
The round-trip phase synchronization algorithm, as detailed in [45], was inspired by the all-node-based
method proposed in [41] to globally synchronize the clocks in a sensor network, and the time-slotted
round-trip approach that was developed in [42] and further improved or modiﬁed in [43,44] to attain
carrier synchronization for distributed beamforming in multiuser wireless communication systems. The
above mentioned approaches, nevertheless, do not appear to be applicable to this MIMO radar phase
synchronization problem directly, even though a common feature shared by these approaches, that when
in operation, a reference signal or message traverses in loops through all the sensors, remains essential.
The round-trip phase synchronization scheme for coherent MIMO radar [45] employs an unmodu-
lated beacon signal to travel through all these radar elements in a round-trip manner. Each node will
record the phase information twice in order to compute the ﬁnal phase. The equivalence of the cumu-
lative phase shift at each sensor, a quantity that is directly related to the total propagation delay for
the round-trip circuit, is the fundamental idea behind this technique. This technique employs pretty
much the same assumptions as those in the master-slave closed-loop method. For example, this scheme

702
CHAPTER 13 MIMO Radar with Widely Separated Antennas
also assumes no a priori establishment of both time and frequency synchronization across all the radar
elements, and assumes the channel reciprocity. However, speciﬁc to this round-trip method, we further
assume that when one sensor transmits, the signal is only properly received by its intended receiver,
i.e., its downstream neighbor. This can be attained in practice, for example, by using directional trans-
missions or appropriate power control schemes at the transmitter (assuming each radar element loosely
knows its and its immediate neighbors’ locations). In what follows, we summarize this round-trip phase
synchronization algorithm. Its mathematical characterization, timing analysis, and error analysis can
be found in [45]:
1. Find a cycle which passes through all the radar elements. The radar elements are then labeled in
order as S1, S2, . . . , SK . Let S1 be the initiating element.
2. In time slot TS1, an unmodulated sinusoidal reference signal is transmitted from S1 to its downstream
neighbor S2. This reference signal is further passed along the cycle in a clockwise manner, as
illustrated by solid lines in Figure 13.13.
3. Upon receiving the reference signal, each radar element Si generates its local phase and frequency
estimates from the noisy observation. In time slot TSi, i = 2, . . . , K, which starts immediately
after the conclusion of the received signal, Si relays the received reference signal to the next node
in the cycle. S1 will be the downstream neighbor of SK .
4. After the initiating node S1 receives the signal from SK , it generates a phase estimate from its noisy
observation. Time slot TSK+1 starts right after the conclusion of the received signal, wherein S1
transmits the original unmodulated sinusoidal reference signal as in step (1) to sensor SK . This
signal is passed along the cycle in the counterclockwise direction, as shown by dashed lines in
Figure 13.13.
5. Upon receiving the signal transmitted from its upstream neighbor, each sensor Si generates its local
phase and frequency estimates from its observation, and calculates its ﬁnal phase based on its two-
time phase estimates. In time slot TS2K−i+2, Si relays the received signal to the next node in the
cycle, i.e., Si−1.
1S
K
S
1
K
S
1
iS
iS
1
iS
3
S
2
S
1st cycle
2nd cycle
FIGURE 13.13
Illustration of the round-trip phase synchronization method.

2.13.6 Phase Synchronization for Coherent MIMO Radar
703
6. Relay of the beacon signal ends after S1 ﬁnishes its receipt of the signal from S2. S1 generates a
phase estimate from its noisy observation, and then calculates its ﬁnal phase.
2.13.6.3 Broadcast consensus based phase synchronization
It can be easily seen that the aforedescribed master-slave closed-loop and round-trip phase synchroniza-
tion algorithms are not distributed in nature. Thus, both methods are not very robust against node failures.
As far as robustness and scalability is concerned, distributed algorithms have enormous advantages, and
may be more desirable for phase synchronization in coherent MIMO radar systems. The essence of these
algorithms is that one or more sensors can communicate information with its immediate neighbors in a
round, and the computation is distributed over all the sensors involved. In particular, when information
averaging is concerned, these distributed algorithms are usually referred to as distributed consensus
algorithms or gossip algorithms, e.g., [46–54]. Distributed consensus algorithms have been applied to
a variety of network-related scenarios. For example, they have been considered in [53,54] for clock or
time synchronization in wireless sensor networks.
Among the various distributed consensus algorithms, of particular note is the broadcast-based con-
sensus algorithm, which has been studied in [50,51] without considering the stochastic disturbances, and
more recently in [52] by taking non-zero-mean stochastic perturbations into account. Here we describe
a broadcast consensus based phase synchronization algorithm for coherent MIMO radar systems, which
was developed in [45], and is a direct extension of the work given in [52]. Similar to the aforedescribed
two phase synchronization approaches, this algorithm assumes no a priori time synchronization; thus,
there is no common time scale established among all these sensors. Each radar element is assumed to
operate according to its own local clock which ticks independently from others. Also, for the ease of
exposition, we assume the carrier frequency synchronization is already established, while noting that
this assumption can be also relaxed. Thus, when a sensor receives beacon signals from its neighbors, it
only needs to estimate the received phase.
In this algorithm, each element broadcasts a reference signal containing its local phase information to
all its immediate neighbors. Its neighbors then average their local phase with the received phase. Thus,
no global operations or information exchanges are required in the process. As an inherent characteristic,
this algorithm exploits the broadcast nature of the wireless communication environment, and obviates
the need for sophisticated underlying media access control mechanisms. To this end, we brieﬂy outline
this phase synchronization algorithm. Its mathematical characterization and analysis is furnished in
[45], which examines in detail how the propagation delays among neighboring sensors and the phase
errors induced by inaccurate local estimation affect the phase synchronization accuracy:
1. Sensor Si elects to broadcast an unmodulated reference signal.
2. Each neighbor of Si, upon receiving the broadcast reference signal, generates an estimate of the
received phase. If it is the ﬁrst time for Si to receive a broadcast reference signal, it updates its phase
with a weighted value of the phase estimate; otherwise, it updates its phase with a weighted average
of its current phase and the phase estimate.
3. The phase of each of the remaining sensors, including Si, remains unchanged.
4. This procedure continues, with each radar element having the same probability to broadcast in every
round.

704
CHAPTER 13 MIMO Radar with Widely Separated Antennas
Note that the absence of a common time reference implies that none of these sensors know the true
time, and as a result, they do not know the “true” initial phase of their local oscillator. Thus, when a
sensor receives a broadcast reference signal for the ﬁrst time, we choose to update its phase using only
the estimate of the received phase.
2.13.6.4 Discussion
As can be clearly seen, the master-slave closed-loop method is the simplest one among all these three
approaches. It, however, has the potential to lead to the best phase synchronization accuracy. This
is because there are only two (the least number) nodes which participate in each round of the phase
synchronization process, i.e., the master node and one slave node. Thus, the propagating accumulation
of each individual’s phase and frequency estimation errors is very limited, and is less of a concern. This,
in fact, is corroborated by a rigorous phase synchronization error analysis included in [45]. Moreover,
in this method, the phase offset induced by the propagation channel is explicitly compensated via
the closed-loop operation, which further improves the phase synchronization accuracy. Therefore, this
approach is particularly useful when a very precise phase synchronization is required. It is generally
applicable to situations where a relatively powerful centralized entity exists or can be identiﬁed, and
can be repeatedly used in systems having tree-like topologies or hierarchical structures. To complete
the whole phase synchronization process, a total of 2K −1 transmissions are needed, including the
broadcast transmission made by the master node.
Unlike the master-slave closed-loop method, both the round-trip and the broadcast consensus based
algorithms do not require a powerful master entity. However, the round-trip scheme does need a global
initiator to start the phase synchronization process. In theory, the global initiator can be any radar sensor
in the system. This round-trip method is able to synchronize all the radar sensors to the same mean carrier
phase, regardless of the topology of these sensors as long as a cycle traversing all these sensors can be
identiﬁed. But since sensors in the system participate in the phase synchronization process all together
in a cooperative fashion, this round-trip method may suffer from the propagating accumulation of each
individual’s phase and frequency estimation errors, as mathematically demonstrated in [45]. As a result,
this method may only be suitable to coherent MIMO radar systems with a limited number of sensors.
In other words, it does not scale very well. This round-trip method needs a total of 2Ktransmissions to
complete the phase synchronization process.
The broadcast consensus based method is distributed and localized in nature. It needs neither a
centralized entity nor a particular global initiator. It is scalable and applicable to coherent MIMO radar
systems composed of a large number of densely scattered sensors. It is also robust to sensor failures.
But unfortunately, as shown in [45], the functionality of this approach is highly dependent on, and
varies from topology to topology of the radar sensors. For arbitrary topologies, this approach may be
only useful when a coarse phase synchronization is required. Since this algorithm runs in an iterative
manner, it generally requires more transmissions than the other two approaches to complete the whole
synchronization process. Thus, it has to be implemented at a relaxed time constraint as opposed to a
stringent one.
Of further note is that in each of the presented phase synchronization algorithms, the propagation
delay for the channel between any pair of MIMO radar elements that are involved in the reference
signal exchange, can be critical in determining the resulting phase synchronization accuracy. A small

2.13.7 Waveform Design for MIMO Radar
705
uncertainty in the channel propagation delay, which may result from, for example, the ambiguity in the
location of certain radar elements or the mobile scatters and other propagation anomalies, can lead to
intolerable phase variations across some or all the radar elements. This is particularly true when high
frequency carriers are chosen as the reference signals. One way to alleviate this unfavorable effect is to
use relatively low carrier frequency. If the carrier frequency is low enough, the location uncertainty of
the MIMO radar elements will not play an important role. Another way is to recalibrate these sensors
periodically to track the channel changes. This may induce some extra overhead, but the accompanying
beneﬁts are in general well worth it. Besides, the variations of the propagation channels among all
these MIMO radar elements, though dependent on the speciﬁc operating environment, are usually very
slow; it takes a relatively long time to reach the point where the physical changes in the medium are so
pronounced that the resulting phase mismatch seriously deteriorates the performance of the coherent
processing, especially for applications such as target localization [11]. Therefore, very frequent phase
resynchronization may not be needed.
Another practical issue that merits attention is the phase dynamics or phase instability [55] in the
coherent MIMO radar system. Note that the oscillator phase noise [56] is always present, and is an
irreducible error which can affect the phase synchronization performance. To counter the effect of
phase noise in oscillators, periodic phase synchronization remains indispensable. How often the phase
synchronization procedure needs to be repeated, however, is dependent on, among other factors, the
aggregate impact of the phase noise across all the local oscillators on the phase synchronization accuracy,
as well as the phase accuracy or stability requirements of the coherent MIMO radar system and the
speciﬁc application. It is indicated in [34, p. 261] that the phase accuracy or stability requirements for
coherent processing by a monostatic or bistatic radar can range from less than one degree to many
tens of degrees of RF phase over a coherent processing interval, depending on the type and duration of
coherent processing. We conjecture that similar phase accuracy or stability requirements may hold as
well for coherent processing by a MIMO radar system.
2.13.7 Waveform design for MIMO radar
Most radar systems operate by radiating a speciﬁc electromagnetic signal into a region and detecting
the echo returned from the reﬂecting targets. The nature of the echo signal provides information about
the target, such as range, radial velocity, angular direction, size, shape and so on [57]. This signal is
usually referred to as the radar waveform, and plays a key role in the accuracy, resolution, and ambiguity
for radar in performing the above mentioned tasks [58]. For MIMO radar, it also relies on waveforms
to realize its excellent performance advantages. Thus, the design of appropriate waveforms for MIMO
radar has become a crucial task, which has attracted a lot of attention over the years. Recent work
on waveform design for MIMO radar (with both widely separated antennas and colocated antennas)
includes, among others, [9,12,59–74].
In this section, we will brieﬂy describe a speciﬁc waveform design scheme for MIMO radar with
widely separated antennas. This scheme was originally developed by us in [9], and further improved or
extended later in, for example [59,60]. It is primarily focused on optimizing MIMO radar’s performance
in information extraction and estimation of extended targets which are modeled using an impulse
response as in [75] (point targets are a special case). Assuming that the radar transmitter has some

706
CHAPTER 13 MIMO Radar with Widely Separated Antennas
knowledge (full or partial) of the target’s second-order statistics and that the transmitted power is
constrained, Yang and Blum [9] detail methods for ﬁnding waveform design strategies based on the
following two criteria: (1) maximizing the conditional mutual information (MI) between the random
target impulse response and the reﬂected radar waveforms; (2) minimizing the value of minimum
mean-square error (MMSE) in estimating the target impulse response. In this part, we will concisely
summarize some major results of [9], and shed some light on the waveform design problem for MIMO
radar.
2.13.7.1 Signal model and design criteria
Figure 13.14 illustrates a bistatic MIMO radar scenario, where the radar is equipped with P transmit
elements and Q receive elements. This model, appropriate for both bistatic and monostatic scenarios,
is a slight generalization of that in [2] for the case of extended targets. For simplicity we consider this
model in discrete-time and in baseband. For an extended target, the reﬂection from the signal sent from
the pth transmit element and captured at the qth receive element can be modeled using a ﬁnite impulse
response (FIR) linear system with order ν, whose impulse response is g(p,q)(l), l ∈[0, ν]. Then the
received waveform at the qth receive element and discrete-time k is given by
yq(k) =
P

p=1
ν

l=0
g(p,q)(l)x p(k −l) + nq(k),
(13.97)
where x p(k) is the waveform transmitted from the pth transmit element and nq(k) is the additive
complex Gaussian noise measured at the qth receive element.
Let L denote the length of the observed signal vector starting at an arbitrary discrete time k,
and assume that L > PM (typically L ≫PM). Denote g(p,q) = [g(p,q)(0), . . . , g(p,q)(ν)]T ,
Scatters
Transmit Array
P Elements
Q Elements
Receive Array
FIGURE 13.14
Illustration of MIMO radar for a bistatic radar scenario.

2.13.7 Waveform Design for MIMO Radar
707
yq = [yq(k), . . . , yq(k + L −1)]T and nq = [nq(k), . . . , nq(k + L −1)]T , then using the matrix-vector
notation (13.97) can be rewritten into
yq =
P

p=1
Xpg(p,q) + nq,
(13.98)
where Xp is an L × M(M = ν + 1) Toeplitz matrix which contains the waveforms transmitted from
the pth transmit element, i.e.,
Xp =
⎛
⎜⎝
x p(k)
· · ·
x p(k −ν)
...
...
...
x p(k + L −1) · · · x p(k + L −1 −ν)
⎞
⎟⎠.
(13.99)
We further deﬁne X = [X1, . . . , XP] and ¯gq = [(g(1,q))T , . . . , (g(P,q))T ]T , so that (13.98) could be
reformulated into
yq = X¯gq + nq.
(13.100)
By stacking the received waveforms across all the Q receive elements, we create ¯y = [y1T , . . . , ¯yT
Q]T .
Deﬁning X = IQ ⊗X, we ﬁnally obtain
¯y = X ¯g + ¯n,
(13.101)
where ¯g = [¯gT
1 , . . . , ¯gT
Q]T and ¯n = [n1T , . . . , nQT ]T .
To facilitate the ensuing analysis on the waveform design of MIMO radar for extended targets, the
model in (13.101) is assumed to have the following properties [9]:
Assumption 4.
The target impulse response vector ¯g is a Gaussian random vector with zero mean
and full rank covariance matrix  ¯g.
Assumption 5.
Components of the noise vector ¯n are assumed to be independently and identically
distributed (i.i.d) and complex Gaussian, with zero mean and variance σ 2
n .
Note that  ¯g can be diagonalized through its eigenvalue decomposition, i.e.,
 ¯g = U	UH,
(13.102)
where U is a unitary matrix whose columns are eigenvectors and 	 = diag{	11, . . . , 	PQM,PQM} is a
diagonal matrix with each diagonal entry given by a real and nonnegative eigenvalue.
Now let us introduce the design criteria. The ﬁrst one is the conditional mutual information (MI)
between ¯y and ¯g given the knowledge of X, which is hereafter referred to as MI. We have [76] (h(·)
denotes differential entropy)
I = I(¯y; ¯g|X) = h(¯y|X) −h(¯y|¯g, X).
(13.103)

708
CHAPTER 13 MIMO Radar with Widely Separated Antennas
Conditioned on X (equivalent to conditioning on X), we can easily ﬁnd that ¯y is Gaussian distributed
with zero mean and covariance (X ¯gX H + σ 2
n IQL). Using (13.103), the MI is [76]
I = log

det (X ¯gX H + σ 2
n IQL)

−log

det (σ 2
n IQL)

= log

det (σ −2
n X ¯gX H + IQL)

= log

det (σ −2
n  ¯gX HX + IPQM)

,
(13.104)
where (13.104) follows from
det (Ir + AB) = det (It + BA).
(13.105)
The design objective is to ﬁnd those X (transmitted waveform) that maximize the MI (I) between
the random target impulse response ¯g and the received (reﬂected) radar waveform ¯y under the con-
straint tr{X HX} ≤LQP0 which effectively limits the total transmit power. Therefore, the problem of
waveform design based on MI can be cast as:
max
X
det (σ −2
n  ¯gX HX + IPQM)
s.t. tr{X HX} ≤LQP0.
Next, let us consider the problem of radar waveform design from the viewpoint of estimation. It is
easy to verify that, conditioned on X, ¯g, and ¯y are jointly Gaussian distributed as
) ¯g
¯y
*
∼CN
 ) 0
0
*
,
)  ¯g
 ¯gX H
X ¯g
X ¯gX H + σ 2
n IQL
*!
.
The conditional distribution of ¯g given ¯y and X is also Gaussian, with conditional mean ˆμ¯g given by
(using Eqs. (IV.B.53) and (IV.B.55) on p. 156 of [17])
ˆμ¯g =  ¯gX H(X ¯gX H + σ 2
n IQL)−1¯y
=

X HX + σ 2
n −1
¯g
−1
X H ¯y
(13.106)
and conditional covariance matrix ˆ ¯g given by (using Eq. (IV.B.54) on pp. 156 of [17])
ˆ ¯g = E

(¯g −ˆμ¯g)(¯g −ˆμ¯g)H
=  ¯g − ¯gX H 
X ¯gX H + σ 2
n IQL
−1
X ¯g
=

σ −2
n X HX + −1
¯g
−1
,
(13.107)
where the matrix inversion lemma11 was employed in obtaining both (13.106) and (13.107).
11(A + BCD)−1 = A−1 −A−1B(DA−1B + C−1)−1DA−1.

2.13.7 Waveform Design for MIMO Radar
709
Let ˆ¯g denote the Bayes estimate of ¯g. When the cost function is deﬁned as ∥¯g −ˆ¯g∥2, the Bayes
estimate ˆ¯g will be a linear MMSE estimator [17] which is given by the conditional mean of ¯g given ¯y
(for a given value of X), i.e.,
ˆ¯g = ˆμ¯g =

X HX + σ 2
n −1
¯g
−1
X H ¯y.
(13.108)
In this case, the Bayes risk for a given X will be
ξ = E{∥¯g −ˆ¯g∥2} = tr{ ˆ ¯g}
= tr

σ −2
n X HX +  ¯g−1−1
.
(13.109)
The goal is then to ﬁnd those X that minimize the value of MMSE under a constraint on the total
transmit power of tr{X HX} ≤LQP0. Or equivalently, the problem of waveform design based on
MMSE estimation can be expressed as:
min
X tr{(σ −2
n X HX + −1
¯g )−1}
s.t. tr{X HX} ≤LQP0.
2.13.7.2 Optimal waveform design for MIMO radar
As mathematically demonstrated in [9], the maximum value of I will be achieved when the matrix
(σ −2
n  ¯gX HX + IPQM) is diagonal, and the minimum value of ξ will be attained when (σ −2
n X HX +
−1
¯g ) is diagonal, also. The following theorem summarizes the result of optimum X. A detailed proof
of this result can be found in [9].
Theorem 3.
Let Assumptions 4 and 5 hold true. Then, under the constraint tr{X HX} ≤LQP0,
only X that satisfy
X = 

diag
 
η −σ 2
n
	11
!+
, . . . ,
 
η −
σ 2
n
	PQM,PQM
!+1/2
UH,
(13.110)
can be optimum in the sense of either maximizing the MI or minimizing the MMSE. In (13.110), 	 and
U are deﬁned in (13.102); 
 is an LQ × PQM matrix with orthonormal columns; the scalar constant
η is chosen to satisfy
PQM

i=1
 
η −σ 2
n
	ii
!+
= LQP0.
The resulting maximum value of MI is
Imax =
PQM

i=1

log (σ −2
n 	iiη)
+
,

710
CHAPTER 13 MIMO Radar with Widely Separated Antennas
and the corresponding minimum value of MMSE is
ξmin =
PQM

i=1
	ii
(	iiσ −2
n η −1)+ + 1
.
Further, provided X = IQ ⊗X for some X, then any X satisfying (13.110) is optimum for both the
MI and MMSE criteria.
A review of Theorem 3 indicates that knowledge of the full matrix  ¯g is needed to perform an
eigenvalue decomposition. An asymptotic formulation has been developed in [9] which lessens the
required information to just a few samples of the PSD and would be much more suitable in practice.
The asymptotic approach employs one important assumption as shown below:
Assumption 6.
The covariance matrix  ¯g of ¯g has a Toeplitz structure.
Clearly this assumption is not very restrictive for single transmit and receive antenna cases, implying
that the target impulse response samples form a wide-sense stationary random process asymptotically.
For multiple transmit and receive antenna cases, this assumption implies that the statistics over space
are indistinguishable from the statistics over time. For the extreme cases of complete independence
or dependence over both space and time, the assumption is very reasonable, for example. However,
it is also straightforward to relax this assumption for multiple-antenna cases by employing a similar
asymptotic approximation as that described below. For a further discussion on this assumption, readers
are referred to [59].
It is shown in [77] that Toeplitz matrices can be approximated by their associated circulant matrices,
and asymptotically (in the dimension of these matrices), they are equivalent. The asymptotic equality
of two matrices implies that their eigenvalues and inverses (and certain products) behave similarly
[77]. Now, let us denote the (i, j)th entry of the covariance matrix  ¯g as  ¯g(i, j), then we have
 ¯g(i, j) = ri−j and r−k = r∗
k , where the sequence {rk; k = 0, ±1, . . . , ±(PQM −1)} is absolutely
summable, and its 2π-periodic truncated Fourier spectrum
f (ω) =
PQM−1

k=1−PQM
rke−jkω
is real valued, ﬁnite, and nonnegative, and represents the PSD of the random process ¯g when PQM
approaches inﬁnity. Then a circulant matrix ˜ ¯g that is asymptotically equivalent to  ¯g is [78]
˜ ¯g = FPQMVFH
PQM,
(13.111)
where FPQM is the PQM × PQM unitary discrete Fourier transform (DFT) matrix with its (k,l)th entry
given by
1
√PQM exp
−j2π(k −1)(l −1)
PQM

,
∀k, l ∈[1, PQM];

2.13.7 Waveform Design for MIMO Radar
711
and the diagonal matrix V contains samples of the PSD of ¯g along its diagonal, or equivalently
Vii = f

2π(i −1)/(PQM)

= r0 + 2 ℜ
⎧
⎨
⎩
PQM−1

k=1
rke−j2π(i−1)/(PQM)
⎫
⎬
⎭,
where i = 1, . . . , PQM.
Given the above asymptotic approximation, the waveform design problems posed earlier can be
resolved using standard optimization theory. For brevity, we summarize the results in the following
theorem. The proof can be found in [9].
Theorem 4.
Suppose Assumptions 4–6 hold true and perfect knowledge is available on the samples of
the target PSD (i.e., entries in the diagonal matrix V). Then under a constraint tr{X HX} ≤LQP0,
only a signaling matrix X that satisﬁes
T = X HX = FPQMD FH
PQM
(13.112)
can be asymptotically optimum in the sense of either maximizing the MI or minimizing the MMSE,
where we have
D = diag
 
η −σ 2
n
V 11
!+
, . . . ,
 
η −
σ 2
n
VPQM,PQM
!+
,
(13.113)
and the constant η is chosen to satisfy
PQM

i=1
 
η −σ 2
n
Vii
!+
= LQP0.
(13.114)
Further, any X from (13.112) is asymptotically optimum for both MI and MMSE.
In fact, Theorem 4 is simply a modiﬁcation of Theorem 3 for the asymptotic case. The essential
change is that FPQM replaces U and V replaces 	. Under such asymptotic approximation, the solution
for X can be explicitly written as
X = 

diag
 
η −σ 2
n
V11
!+
, . . . ,
 
η −
σ 2
n
VPQM,PQM
!+1/2
FH
PQM.
(13.115)
It is obvious that to produce X in (13.115), the full covariance matrix  ¯g is not needed, only samples
of the PSD for V are necessary. This is a more reasonable assumption in practice.
2.13.7.3 Discussion
Based on Theorem 3, it can be concluded that any X HX meeting the given power constraint which
maximizes MI will also minimize MMSE, and this X HX is unique for a given  ¯g. In fact, X HX can be
deemed as the covariance matrix of the transmitted waveforms. Meanwhile, it should be noted that the

712
CHAPTER 13 MIMO Radar with Widely Separated Antennas
solution expressed by (13.110) is a closed-form and general solution which does not require any level of
approximation. Its optimality is manifested in two ways. On the one hand, only X satisfying (13.110)
can be optimum in the sense of either maximizing the MI or minimizing the MMSE. On the other hand,
any X from (13.110) is optimum for both MI and MMSE provided such X satisﬁes X = IQ ⊗X.
In other words, the condition stipulated by (13.110) is only a necessary condition for X to attain the
optimality, but not a sufﬁcient one. This is because there may exist some cases where a solution X
satisﬁes (13.110) but does not have the desired Kronecker structure. Note for these cases, it can be
possible that the equivalence between the MI and the MMSE does not hold any more. However, in a
recently published paper [60], an iterative algorithm has been developed, which can identify waveform
solutions that not only optimize the performance criteria of interest (i.e., MI and MMSE), but have
a speciﬁc Kronecker structure. It is also found in [60] that waveform solutions generated through
this algorithm can lead to performance which is very close to, and almost indistinguishable from that
predicted by Theorem 3. Detailed information about this algorithm can be found in [60].
A close review of Theorem 4 reveals that for the asymptotic simpliﬁcation approach, exact knowledge
of the target PSD samples is required in the waveform design. This requirement appears rather demand-
ing, particulary in practical applications. In order to bring the waveform design even closer to practice
and deliver more applicable waveform solutions for MIMO radar, it is necessary to accommodate some
issues that may arise in reality, such as the uncertainty in the target’s statistics. In such a circumstance,
robust procedures, which can overcome those problems by incorporating modeling uncertainty into
the design from the outset [79], seem quite attractive. As a result, a minimax robust waveform design
problem for MIMO radar has been formulated and solved in [59], where a band model was adopted by
assuming the PSD lies in an uncertainty class of spectra bounded by known upper and lower bounds.
This band model might arise in practice, for example, if a conﬁdence band for the spectrum could be
determined via spectrum estimation, or the upper and lower bounds can be obtained simply by ﬁeld
measurement and modeling. It is shown in [59] that the resulting minimax robust waveforms can achieve
good performance for any PSD in the uncertainty class, and in particular, they can bound the worst-case
performance at an acceptable limit. One very interesting ﬁnding from the results in [59] is that the min-
imax robust waveforms for the MMSE criterion are generally different from those for the MI criterion,
which is in stark contrast to the results for the completely known PSD case. We direct interested readers
to [59] for more details.
2.13.8 Summary
In this document, we provided a review of some key topics related to MIMO radar with widely separated
antennas. This type of MIMO radar features two major conﬁgurations, one with all antennas within a
same target beamwidth and one with antennas placed in distinct target beamwidths, which, in turn, lead to
two different operation modes called coherent and noncoherent MIMO radars, respectively. In Sections
2.13.2 and 2.13.3, signal models for coherent and noncoherent MIMO radars were introduced for the
problem of joint target location and velocity estimation. Equations specifying the ML estimates were
derived for some general cases, which accommodate scenarios featuring, for example, nonorthogonal
transmitted waveforms, spatially colored clutter-plus-noise, and correlated reﬂection coefﬁcients. How-
ever, to provide further insight, we also considered some simpliﬁed cases, where orthogonal waveforms,

2.13.8 Summary
713
temporally and spatially white clutter-plus-noise, and independent reﬂections are assumed. The MSEs
of the ML estimates, the corresponding CRBs, and the coherent and noncoherent AFs were presented.
In Section 2.13.4, the performance and complexity issues for the coherent and noncoherent MIMO
radars were investigated. Although the coherent MIMO radar outperforms the noncoherent one in
general, it has more stringent operational requirement and incurs more implementation complexity.
Fortunately, our results indicate that for some cases, e.g., when M N is sufﬁciently large, we can
replace the coherent approach by its noncoherent counterpart, which, while reducing a great deal the
implementation complexity, induces very little loss of performance. As a result, if large M N can be
afforded in practice, the noncoherent MIMO radar is naturally preferred to the coherent one. The
NDRMSE was deﬁned in this section, and was used to compare the overall performance difference
between the coherent and noncoherent MIMO radars for joint parameter estimation. A sufﬁciently
small value of the parameter NDRMSE can serve as an indicator, suggesting the noncoherent MIMO
radar performs very well relative to the coherent one.
The diversity gains were analyzed for MIMO radar target detection under the Neyman-Pearson
criterion in Section 2.13.5. We showed that the maximum achievable diversity gain for a MIMO radar
system is determined by the number of transmit antennas, the number of scatterers that compose the
target, the dimension spanned by the clutter-plus-noise free received waveforms at each receiver, and
the cdf of the reﬂection coefﬁcients, while it is invariant to the clutter-plus-noise cdf, provided the
magnitude of the processed clutter-plus-noise has bounded moments up to a required order. It was
shown that for some cases of interest, the maximum diversity gain can be achieved. Further, properly
chosen nonorthogonal waveforms can achieve the same diversity gain as orthogonal waveforms.
In Section 2.13.6, we discussed three effective approaches to achieve phase synchronization in
coherent MIMO radar systems. The ﬁrst one is the master-slave closed-loop approach, which employs
a master-slave architecture. This method is very simple, and is suitable for ﬁne phase synchronization.
The second one is the round-trip algorithm, which employs an unmodulated beacon signal to travel
through all the radar elements in a round-trip manner. This method is applicable to arbitrary topologies
of the radar sensors as long as a cycle traversing all these sensors can be identiﬁed. The third one is
the broadcast consensus based algorithm, which is scalable, and is distributed and localized in nature.
Distinct as they are, these algorithms are all time asynchronous, and in particular, the master-slave
closed-loop algorithm and the round-trip algorithm also require no a priori frequency synchronization.
These algorithms should cater to different needs arising as a result of different number of MIMO radar
elements, different sensor placements, as well as different operational preferences.
Several MIMO radar waveform design methods were presented in Section 2.13.7. The discussed
methods capitalize on the knowledge of the covariance matrix of the extended target impulse response,
and optimize two criteria: maximization of the MI and minimization of the MMSE. For both design
criteria, a constraint on the transmitted power is imposed. The ﬁndings indicate that these two criteria are
equivalent in the sense that they lead to the same covariance matrix of the transmit waveforms, which is
a fundamental quantity specifying the waveform design. The optimum solution employs water-ﬁlling,
which allocates the transmitted power in proportion to the quality of the particular mode in question. In
particular, more transmitted waveform power is allocated to modes that have higher power, indicating
the presence of signiﬁcant target scattering, and modes with low power deserve excitation with lower
transmitted waveform power. In addition, an asymptotic formulation was also provided in Section 2.13.7,
which lessens the required knowledge about the target statistical model to just a few samples of the
PSD, and would be much more suitable in practice.

714
CHAPTER 13 MIMO Radar with Widely Separated Antennas
Notation
Throughout this chapter, we use bold upper case letters to denote matrices, and bold lower case letters
to signify column vectors. The deﬁnition of symbols used in this chapter are listed below:
E{·}
expectation with respect to all the random variables within the brackets
{·}H
conjugate transpose of the argument
{·}∗
conjugate of the argument
{·}T
transpose of the argument
(a)+
positive part of a, i.e., (a)+ = max[0, a]
|·|
absolute value of a complex number
∥·∥
Euclidean norm of the argument
ℜ{·}
real part of a complex number
ℑ{·}
imaginary part of a complex number
o(·)
little-o notation, i.e., Suppose x(u) and y(u) are both functions of a variable u,
then x(u) = o(y(u)) as u →a implies limu→a x(u)/y(u) = 0
δ(τ)
unit impulse function, i.e., δ(τ) = 1 if τ = 0 or 0 if τ ̸= 0
1a×b
all one matrix of size a × b
0a×b
zero matrix of size a × b
IK
identity matrix of size K × K
det{·}
determinant of a matrix
tr{·}
trace of a matrix
diag{a1, a2, . . .}
diagonal matrix with elements a1, a2, . . . on its diagonal
Diag{S1, S2, . . .}
block diagonal matrix with submatrices S1, S2, . . . on its diagonal
∇θ{·}
gradient of the argument with respect to θ
⊗
Kronecker product operator
Appendix
A.1 Frequency spread signals
In this appendix, we describe one class of signals which could be employed. Under appropriate assump-
tions, these signals approximately satisfy the conditions of Assumption 1 for orthogonal signals. We
discuss these assumptions. These assumptions essentially ignore small sidelobes in the Fourier transform
of these signals to approximate them with truncated (in frequency domain) signals.
Consider a set of pulsed sinusoidal signals12
sk(t) =

1
√
T exp ( j2πk f t) 0 < t < T ,
0
otherwise,
(A.1)
where k = 1, . . . , M, the term T denotes the signal time duration, and  f = fk+1 −fk ≥0 is the
frequency increment between sk(t) and sk+1(t). The approximate bandwidth of each signal is F = 1/T .
12Windowing can be applied in practice but we omit discussion of this well studied topic.

Appendix
715
Sk’( f )
'( )
kS
f
|k-k’| f
Sk(f)
( )
kS
f
f 
fk
fk’
1/T
1/ (T- τ kk’)
1/T
1/ (T- τ kk’)
Δ
Δ
Δ
FIGURE A.1
Frequency spectrum for transmitted signals (solid curves) and the effective parts of their time delayed
versions (dotted curves).
The spectrum of sk(t) and sk′(t), Sk( f ) and Sk′( f ), are shown in Figure A.1. Note that throughout this
appendix it is always assumed that k ̸= k′. According to Parseval’s theorem

T
sk(t)s∗
k′(t)dt =
 ∞
−∞
Sk( f )S∗
k′( f )d f .
(A.2)
Observing the spectrum, we see that when |k −k′| f ≫1
T , the main lobes of Sk( f ) and Sk′( f ) are
sufﬁciently separated so that Sk( f )S∗
k′( f ) ≈0 and (A.2) approximates 0, which makes sk(t) and sk′(t)
approximately orthogonal. Here we are ignoring contributions from small sidelobes which is similar to
truncating the signals in the frequency domain. As |k −k′| ≥1, if the frequency increment satisﬁes
 f ≫1
T ,
(A.3)
then any two signals from the signal set sk(t) (k = 1, . . . , M) are approximately orthogonal.
Assume that sk(t) and sk′(t) are time delayed by τk and τk′. The non-zero part of the delayed signal
sk(t −τk) occupies τk < t < τk + T , and the non-zero part of sk′(t −τk′) occupies τk′ < t < τk′ + T .
Hence, the time duration of the overlap between them is T −τkk′, where τkk′ = |τk −τk′| denotes the
time delay difference. Note that when τkk′ is greater than or approximates T , the overlap part of these
two signals vanishes, which implies (A.2) is close to 0 and the signals can be considered as orthogonal.
Therefore, it is possible for the two delayed signals to be non-orthogonal only if τkk′ ≪T , which
makes the following discussion necessary.
We denote the overlap interval as T. Thus

T
sk(t −τk)s∗
k′(t −τk′)dt =

T
sk(t −τk)s∗
k′(t −τk′)dt
=

T
˘sk(t)˘s∗
k′(t)dt,

716
CHAPTER 13 MIMO Radar with Widely Separated Antennas
where ˘sk(t) and ˘sk′(t) represent the overlapping parts of sk(t −τk) and sk′(t −τk′), the time duration
of which are both T −τkk′. More speciﬁcally, suppose τk′ < τk < τk′ + T , then we have
˘sk(t) = sk(t −τk),
τk < t < τk′ + T ,
˘sk′(t) = sk′(t −τk′),
τk < t < τk′ + T .
The spectrum of ˘sk(t) and ˘sk′(t), i.e., ˘Sk( f ) and ˘Sk′( f ), are plotted by dotted curves in Figure A.1. In
a similar way, for the time delayed signals, the orthogonality is approximately maintained if
|k −k′| f ≫
1
T −τkk′ .
(A.4)
Since |k −k′| ≥1, the inequality is maintained by requiring  f ≫
1
T −τkk′ . As τkk′ ≪T , the
condition becomes  f ≫1
T , which is the same as in (A.3). Hence, the requirement for (A.3) guarantees
(A.4). That is, if (A.3) is met, the time delayed signals are orthogonal.
Next, we further discuss the Doppler shift restriction for orthogonality. The effective time delayed and
Doppler shifted signals are given by ˜sk(t) = ˘sk(t)e j2π fdkt and ˜sk′(t) = ˘sk′(t)e j2π fdk′t. The frequency
spectrum of the effective time delayed signals ˘sk(t) and ˘sk′(t), i.e., ˘Sk( f ) and ˘Sk′( f ), are replotted in
Figure A.2 using solid curves, the center frequency of which are fk and fk′. After Doppler frequency
shift, the spectrum of the effective time delayed and Doppler shifted signals are ˜Sk( f ) = ˘Sk( f −fdk) and
˜Sk′( f ) = ˘Sk′( f −fdk′). They are shown in Figure A.2 using dashed curves. Thus, the center frequency
of the effective signal ˜sk(t) is fk + fdk, while the center frequency of ˜sk′(t) becomes fk′ + fdk′. Clearly,
provided
(k −k′) f + fdk −fdk′
 ≫
1
T −τkk′ , that is
fdk −fdk′ ≪(k′ −k) f −
1
T −τkk′
or
(A.5)
fdk −fdk′ ≫(k′ −k) f +
1
T −τkk′ ,
the overlapping part between Sk

f −fdk(v)

and S∗
k′

f −fdk′(v)

(k′ ̸= k) can be ignored. Thus
the orthogonality is well approximated. Note that since (A.4) is satisﬁed, we have |(k′ −k) f | ≫
|
1
T −τkk′ |. Hence the term
1
T −τkk′ in (A.5) can be ignored, resulting in fdk −fdk′ ≪(k′ −k) f or
fdk −fdk′ ≫(k′ −k) f .
It has been shown in [24] that, in the example case of target velocity estimation, the CRBs obtained
using untruncated signals under certain conditions that are of practical interest are extremely close to the
CRBs calculate by assuming ideal orthogonal signals. Interested readers are referred to [24] for detail.
A.2 Distinguishing coherent and noncoherent processing
In the MIMO radar context, the term coherent processing implies that the relative phase information
embedded in the signals traveling over the paths between different transmit and receive antennas will
be exploited (e.g., see (13.22)). Ultimately, this requires the oscillators in the up and down converters at
different transmit and receive antenna nodes to be locked in phase. This is not the case for noncoherent
processing where the relative phase information is not exploited (e.g., see (13.57)).

Appendix
717
| (k-k’) f+ fdk - fdk’|
(
)
k
d
S
f
f
−
( )
kS
f
k
S
f
k
( )
k′
(
)
k
d
S
f
f
′
′
−
f 
 fk+fdk
fk’+fdk’
fk
fk’
1/ (T- τkk’)
1/ (T- τkk’)
Δ
Δ
Δ
FIGURE A.2
Frequency spectrum for the time delayed equivalent signals (solid curves) and their Doppler shifted versions
(dotted curves).
To distinguish between the coherent and noncoherent processing, one can examine the output of the
processor (e.g., (13.22) or (13.57)), say denoted by P, as a function of a set of observations coming from
different spatial paths, say denoted by {˜r1, ˜r2, . . . , ˜rI} = {˜ri}I
i=1, where I represents the number of
available observations coming from different spatial paths. That is P = func

{˜ri}I
i=1

. If an arbitrary
constant13 phase set {i}I
i=1 is imposed on the observations coming from different spatial paths, but
the processing is insensitive to the phase shifts over the different paths, i.e., the output of the processor
P is not affected, such that
Pnon = func

{˜ri}I
i=1

= func
 
˜rie ji
I
i=1
!
(A.6)
then the processor is regarded as being noncoherent. Otherwise, if the output of the processor is affected
by the arbitrary phase set, such that
Pcoh = func

{˜ri}I
i=1

̸= func
 
˜rie ji
I
i=1
!
,
(A.7)
then the processor is regarded as being coherent.
The estimators ˆθ
coh
J,ML in (13.22) and ˆθ
non
J,ML in (13.57), which satisfy (A.7) and (A.6), are examples of
noncoherent and coherent processors respectively, where
ˆθ
coh
J,ML = func

{˜rlk(t)}(N,M)
(l,k)=(1,1)

̸= func
 
˜rlk(t)e jlk
(N,M)
(l,k)=(1,1)
!
and
ˆθ
non
J,ML = func

{˜rlk(t)}(N,M)
(l,k)=(1,1)

= func
 
˜rlk(t)e jlk
(N,M)
(l,k)=(1,1)
!
.
13Here we model the oscillator phase drift as varying slowly enough so as to be considered constant over any pulse train
interval. We deﬁne noncoherent processing approaches as those approaches that do not require phase locking between the
oscillators at all the different transmitter and receiver nodes.

718
CHAPTER 13 MIMO Radar with Widely Separated Antennas
A.3 FIM for coherent MIMO radar joint estimation
Considering that the log-likelihood ratio in (13.20) is explicitly a function of τlk and flk, but implicitly
as a function of J, we deﬁned a new parameter vector
ϑJ =

τ11, τ12, . . . , τN M, f11, f12, . . . , fN M, ζR, ζI
T .
(A.8)
Then, the FIM can be derived using the chain rule as
Jcoh(J) =

∇JϑT
J

J(ϑJ)

∇JϑT
J
T
.
(A.9)
We ﬁrst compute ∇JϑT
J and obtain
∇JϑT
J =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
∂τ11
∂x
∂τ12
∂x · · · ∂τN M
∂x
∂f11
∂x
∂f12
∂x
· · · ∂fN M
∂x
0 0
∂τ11
∂y
∂τ12
∂y · · · ∂τN M
∂y
∂f11
∂y
∂f12
∂y · · · ∂fN M
∂y
0 0
0
0
· · ·
0
∂f11
∂vx
∂f12
∂vx · · · ∂fN M
∂vx
0 0
0
0
· · ·
0
∂f11
∂vy
∂f12
∂vy · · · ∂fN M
∂vy
0 0
0
0
· · ·
0
0
0
· · ·
0
1 0
0
0
· · ·
0
0
0
· · ·
0
0 1
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
.
Partitioning ∇JϑT
J into a block matrix, we have
∇JϑT
J =
⎡
⎣
A B 0
0 D 0
0 0 I2
⎤
⎦,
where A, B, D are 2 × N M submatrices. The J(ϑJ) in (A.9) can be derived from (13.20) as
J(ϑJ) = −E

∇ϑJ

∇ϑJ LJ

J; ˜r(t)
T 
,
which is a 2(N M + 1) × 2(N M + 1) matrix. Write J(ϑJ) in the form of a block matrix
J(ϑJ) =
⎡
⎣
X
F
P
FH
Y K
PH KH Z
⎤
⎦,
where X, F, Y are N M × N M matrices. Carrying out the computation, we get
X = 8π2|ζ|2E
σ 2wM
IN ⊗diag
1
εc
1, εc
2, . . . , εc
M
2
,
(A.10)
F = 8π2|ζ|2E
σ 2wM
diag
1
γ c
11, γ c
12, . . . , γ c
N M
2
,
(A.11)

Appendix
719
Y = 8π2|ζ|2E
σ 2wM
diag
1
ηc
11, ηc
12, . . . , ηc
N M
2
,
(A.12)
P = 4π E
σ 2wM [ζI1N×1, −ζR1N×1] ⊗[α1, α2, . . . , αM]T ,
(A.13)
K = 4π E
σ 2wM [−ζI, ζR] ⊗[11, 12, . . . , N M]T ,
(A.14)
and
Z = 2E N
σ 2w
I2,
(A.15)
where the terms εc
k, γ c
lk, ηc
lk, αk, lk dependent on the characteristics of the received waveforms are
provided in (33.24)–(33.28). Thus, the FIM can be computed through
Jcoh(J) =
⎡
⎣
AXAT + BFHAT + AFBT + BYBT AFDT + BYDT AP + BK
DFHAT + DYBT
DYDT
DK
PHAT + KHBT
KHDT
Z
⎤
⎦.
(A.16)
After lengthy algebraic manipulations, the expression of the FIM can be obtained as shown in (13.23).
A.4 Calculating FIM for localization with phase errors
First, let us compute the i jth (1 ≤i, j ≤N M) element of the matrix. Referring to the vector in (13.41),
let i refer to the index of the element of ϑP corresponding to τlk, then let j refer to the index of the
element of ϑP corresponding to τl′k′

J(ϑP)

i, j = −Er(t);θP
)∂2 ln (θP; ˜r(t))
∂τlk∂τl′k′
*
,
(A.17)
where
∂2 ln (θP; ˜r(t))
∂τlk∂τl′k′
=
−1
2(θP; ˜r(t))
∂(θP; ˜r(t))
∂τlk
∂(θP; ˜r(t))
∂τl′k′
+
1
(θP; ˜r(t))
∂2(θP; ˜r(t))
∂τlk∂τl′k′
. (A.18)
The term (θP; ˜r(t)) in (A.18) is given in (13.39). Further
∂(θP; ˜r(t))
∂τlk
= C2E

exp {g} ∂g
∂τlk

,
(A.19)
where g is given in (13.38). Assuming an interchange of derivative and integral is valid,14 then
∂g
∂τlk
= 2
σ 2w

T
ℜ

hlζ ∗

E
M e−j ˜lk e j2π fcτlk
)
j2π fcs∗
k (t −τlk) + ∂s∗
k (t −τlk)
∂τlk
*
dt,
(A.20)
14The ℜ{·} means taking the real part of the quantity in the brackets.

720
CHAPTER 13 MIMO Radar with Widely Separated Antennas
where
hl ≡˜rl(t) −ζ

E
M
M

k=1
e j ˜lk e−j2π fcτlksk(t −τlk).
(A.21)
Finally, the remaining term in (A.18) is
∂2(θP; ˜r(t))
∂τlk∂τl′k′
= C2E

exp{g}
) ∂g
∂τl′k′
∂g
∂τlk
+
∂2g
∂τlk∂τl′k′
*
,
where for l ̸= l′, ∂2g/(∂τlk∂τl′k′) = 0, and for l = l′
∂2g
∂τlk∂τlk′ = −2|ζ|2E
σ 2wM

T
ℜ

e−j ˜lk e j2π fcτlk

e j ˜lk′ e−j2π fcτlk′
×
)
4π2 f 2
c sk′(t −τlk′)s∗
k (t −τlk) −j2π fcsk′(t −τlk′)∂s∗
k (t −τlk)
∂τlk
+ j2π fc
∂sk′(t −τlk′)
∂τlk′
s∗
k (t −τlk) + ∂sk′(t −τlk′)
∂τlk′
∂s∗
k (t −τlk)
∂τlk
*
+ ρkk′

dt,
where for k ̸= k′, ρkk′ = 0, and for k = k′
ρkk =
1
|ζ|2

M
E hlζ ∗

4π2 f 2
c s∗
k (t −τlk) −j4π fc
∂s∗
k (t −τlk)
∂τlk
−∂2s∗
k (t −τlk)
∂τ 2
lk

.
Now all terms in (A.18) have been obtained. Further taking the expectation Er(t);θP{·} with respect to
p(˜r(t); θP) gives (A.17). Next, we compute the elements related to the target complex reﬂectivity

J(ϑP)

N M+1,i =

J(ϑP)

i,N M+1 = −Er(t);θP
)∂2 ln (θP; ˜r(t))
∂τlk∂ζR
*
(A.22)
for i = 1, . . . , N M, where
∂2 ln (θP; ˜r(t))
∂τlk∂ζR
=
−1
2(θP; ˜r(t))
∂(θP; ˜r(t))
∂τlk
∂(θP; ˜r(t))
∂ζR
+
1
(θP; ˜r(t))
∂2(θP; ˜r(t))
∂τlk∂ζR
. (A.23)
The new terms introduced by (A.23) are
∂(θP; ˜r(t))
∂ζR
= C2E

exp{g} ∂g
∂ζR

,
(A.24)
where g is given in (13.38) and
∂g
∂ζR
= 2
σ 2w
N

l=1

T
ℜ

hl

E
M
M

k=1
e−j ˜lk e j2π fcτlks∗
k (t −τlk)

dt,
(A.25)

Appendix
721
and
∂2(θP; ˜r(t))
∂τlk∂ζR
= C2E

exp{g}
) ∂g
∂τlk
∂g
∂ζR
+
∂2g
∂τlk∂ζR
*
,
(A.26)
where g is given in (13.38), ∂g/∂τlk in (A.20), ∂g/∂ζR in (A.25), and
∂2g
∂τlk∂ζR
=
2E
σ 2wM

T
ℜ

e−j ˜lk e j2π fcτlk
)
j2π fcs∗
k (t −τlk) + ∂s∗
k (t −τlk)
∂τlk
*
×

M
E hl −ζ ∗
M

k=1
e j ˜lk e−j2π fcτlksk(t −τlk)

dt.
Plugging (13.39), (A.19), (A.24), (A.26) in (A.23) and taking expectation gives (A.22). Then, we
compute

J(ϑP)

N M+2,i =

J(ϑP)

i,N M+2 = −Er(t);θP
)∂2 ln (θP; ˜r(t))
∂τlk∂ζI
*
(A.27)
for i = 1, . . . , N M, where
∂2 ln (θP; ˜r(t))
∂τlk∂ζI
=
−1
2(θP; ˜r(t))
∂(θP; ˜r(t))
∂τlk
∂(θP; ˜r(t))
∂ζI
+
1
(θP; ˜r(t))
∂2(θP; ˜r(t))
∂τlk∂ζI
. (A.28)
The new terms introduced by (A.28) are
∂(θP; ˜r(t))
∂ζI
= C2E

exp{g} ∂g
∂ζI

,
(A.29)
where g is given in (13.38) and15
∂g
∂ζI
= 2
σ 2w
N

l=1

T
ℑ

jhl

E
M
M

k=1
e−j ˜lk e j2π fcτlks∗
k (t −τlk)

dt,
(A.30)
and
∂2(θP; ˜r(t))
∂τlk∂ζI
= C2E

exp{g}
) ∂g
∂τlk
∂g
∂ζI
+
∂2g
∂τlk∂ζI
*
,
(A.31)
where g is given in (13.38), ∂g/∂τlk in (A.20), ∂g/∂ζI in (A.30), and
∂2g
∂τlk∂ζI
=
2E
σ 2wM

T
ℑ

e−j ˜lk e j2π fcτlk
)
j2π fcs∗
k (t −τlk) + ∂s∗
k (t −τlk)
∂τlk
*
×

M
E hl + ζ ∗
M

k=1
e j ˜lk e−j2π fcτlksk(t −τlk)

dt.
15The ℑ{·} means taking the imaginary part of the quantity in the brackets.

722
CHAPTER 13 MIMO Radar with Widely Separated Antennas
Plugging (13.39), (A.19), (A.29), (A.31) in (A.28) and taking expectation gives (A.27). Next, we
compute

J(ϑP)

N M+1,N M+1 = −Er(t);θP

∂2 ln (θP; ˜r(t))
∂ζ 2
R

,
(A.32)
where
∂2 ln (θP; ˜r(t))
∂ζ 2
R
=
−1
2(θP; ˜r(t))
)∂(θP; ˜r(t))
∂ζR
*2
+
1
(θP; ˜r(t))
∂2(θP; ˜r(t))
∂ζ 2
R
.
(A.33)
The new term introduced by (A.33) is
∂2(θP; ˜r(t))
∂ζ 2
R
= C2E

exp{g}
 ∂g
∂ζR
!2
+ ∂2g
∂ζ 2
R

,
(A.34)
where g is given in (13.38), ∂g/∂ζR in (A.25), and
∂2g
∂ζ 2
R
= −2E
σ 2wM
N

l=1

T

M

k=1
e j ˜lk e−j2π fcτlksk(t −τlk)

2
dt.
Plugging (13.39), (A.24), (A.34) in (A.33) and taking expectation, we obtain (A.32). Similarly, we
compute

J(ϑP)

N M+2,N M+2 = −Er(t);θP

∂2 ln (θP; ˜r(t))
∂ζ 2
I

,
(A.35)
where
∂2 ln (θP; ˜r(t))
∂ζ 2
I
=
−1
2(θP; ˜r(t))
)∂(θP; ˜r(t))
∂ζI
*2
+
1
(θP; ˜r(t))
∂2(θP; ˜r(t))
∂ζ 2
I
.
(A.36)
The new term introduced by (A.36) is
∂2(θP; ˜r(t))
∂ζ 2
I
= C2E

exp{g}
 ∂g
∂ζI
!2
+ ∂2g
∂ζ 2
I

,
(A.37)
where g is given in (13.38), ∂g/∂ζI in (A.30) and
∂2g
∂ζ 2
I
= −2E
σ 2wM
N

l=1

T

M

k=1
e j ˜lk e−j2π fcτlksk(t −τlk)

2
dt.
Plugging (13.39), (A.29), (A.37) into (A.36) and taking expectation gives (A.35). Finally, we compute

J(ϑP)

N M+1,N M+2 =

J(ϑP)

N M+2,N M+1 = −Er(t);θP
)∂2 ln (θP; ˜r(t))
∂ζR∂ζI
*
,
(A.38)

References
723
where
∂2 ln (θP; ˜r(t))
∂ζR∂ζI
=
−1
2(θP; ˜r(t))
∂(θP; ˜r(t))
∂ζR
∂(θP; ˜r(t))
∂ζI
+
1
(θP; ˜r(t))
∂2(θP; ˜r(t))
∂ζR∂ζI
. (A.39)
The new term introduced by (A.39) is
∂2(θP; ˜r(t))
∂ζR∂ζI
= C2E

exp{g} ∂g
∂ζR
∂g
∂ζI

,
(A.40)
where g is given in (13.38), ∂g/∂ζR in (A.25), and ∂g/∂ζI in (A.30). Plugging (13.39), (A.24), (A.29),
(A.40) into (A.39) and taking expectation we obtain (A.38).
Now we compute the quantity
∇θPϑT
P =

(∇xϑT
P )T , (∇yϑT
P )T , (∇ζRϑT
P )T , (∇ζI ϑT
P )T T
,
using τlk and ϑP respectively given in (13.2) and (13.41)
∇θPϑT
P =
⎡
⎢⎢⎣
∂τ11
∂x
∂τ12
∂x . . . ∂τN M
∂x
0 0
∂τ11
∂y
∂τ12
∂y . . . ∂τN M
∂y
0 0
0
0
. . .
0
1 0
0
0
. . .
0
0 1
⎤
⎥⎥⎦,
(A.41)
where ∂τlk/∂x =

(x −xt
k)/dt
k + (x −xr
l )/dr
l

/c and ∂τlk/∂y =

(y −yt
k)/dt
k + (y −yr
l )/dr
l

/c.
Relevant Theory: Signal Processing Theory Statistical Signal Processing, and Array Signal Processing
See Vol. 1, Chapter 4 Random Signals and Stochastic Processes
See Vol. 1, Chapter 11 Parametric Estimation
See Vol. 3, Chapter 7 Geolocation—Maps, Measurements, Models, and Methods
See Vol. 3, Chapter 8 Performance Analysis and Bounds
See Vol. 3, Chapter 19 Array Processing in the Face of Nonidealities
References
[1] H. Bölcskei, A.J. Paulraj, Multiple-input multiple-output (MIMO) wireless systems, in: The Communications
Handbook, second ed., CRC Press, 2002, pp. 90.1–90.14.
[2] E. Fishler, A.M. Haimovich, R.S. Blum, L. Cimini, D. Chizhik, R. Valenzuela, Spatial diversity in radars—
models and detection performance, IEEE Trans. Signal Process. 54 (3) (2006) 823–838.
[3] J. Li, P. Stoica, MIMO radar with colocated antennas, IEEE Signal Process. Mag. 24 (5) (2007) 106–114.
[4] A.M. Haimovich, R.S. Blum, L. Cimini, MIMO radar with widely separated antennas, IEEE Signal Process.
Mag. (1) (2008) 116–129.
[5] R.S. Blum, Limiting case of a lack of rich scattering environment for MIMO radar diversity, IEEE Signal
Process. Lett. 16 (10) (2009) 901–904.
[6] T. Aittomaki, V. Koivunen, Performance of MIMO radar with angle diversity under Swerling scattering model,
IEEE J. Sel. Top. Signal Process. 4 (1) (2010) 101–114 (special issue on MIMO radar).

724
CHAPTER 13 MIMO Radar with Widely Separated Antennas
[7] E. Grossi, M. Lops, L. Venturino, Robust waveform design for MIMO radars, IEEE Trans. Signal Process. 59
(7) (2011) 3262–3271.
[8] M. Akcakaya, A. Nehorai, MIMO radar sensitivity analysis for target detection, IEEE Trans. Signal Process.
59 (7) (2011) 3241–3250.
[9] Y. Yang, R.S. Blum, MIMO radar waveform design based on mutual information and minimum mean-square
error estimation, IEEE Trans. Aerosp. Electron. Syst. 43 (2007) 330–343.
[10] Q. He, N.H. Lehmann, R.S. Blum, A.M. Haimovich, MIMO radar moving target detection in homogeneous
clutter, IEEE Trans. Aerosp. Electron. Syst. 46 (3) (2010) 1290–1301.
[11] H. Godrich, A.M. Haimovich, R.S. Blum, Target localization accuracy gain in MIMO radar based systems,
IEEE Trans. Inform. Theory 56 (6) (2010) 2783–2803.
[12] S. Sen, N. Nehorai, OFDM MIMO radar with mutual-information waveform design for low-grazing angle
tracking, IEEE Trans. Signal Process. 58 (6) (2010) 3152–3162.
[13] R. Niu, R.S. Blum, P.K. Varshney, A.L. Drozd, Target tracking in widely separated non-coherent multiple-
input multiple-output radar systems, in: Proceeding of the 43rd Asilomar Conference on Signals, Systems and
Computers, November 2009, pp. 1181–1185.
[14] M.L. Melvin, A STAP overview, IEEE Aerosp. Electron. Syst. Mag. 19 (1) (2004) 19–35.
[15] H.L. Van Trees, Detection, Estimation, and Modulation Theory III: Radar-Sonar Signal Processing and Gaus-
sian Signals in Noise, John Wiley & Sons Inc., 2001.
[16] Q. He, R.S. Blum, Noncoherent versus coherent MIMO radar: performance and simplicity analysis, Signal
Process. 92 (2012) 2454–2463.
[17] H.V. Poor, An Introduction to Signal Detection and Estimation, second ed., Springer-Verlag, New York, 1994.
[18] Q. He, R.S. Blum, H. Godrich, A.M. Haimovich, Target velocity estimation and antenna placement for MIMO
radar with widely separated antennas, IEEE J. Sel. Top. Signal Process. 4 (1) (2010) 79–100 (special issue on
MIMO radar).
[19] P.M. Woodward, Probability and Information Theory, with Applications to Radar, McGraw-Hill, New York,
1953.
[20] N. Lehmann, A.M. Haimovich, R.S. Blum, L. Cimini, High resolution capabilities of MIMO radar, in: Pro-
ceeding of the 40th Asilomar Conference on Signal, System and Computers, November 2006, pp. 25–30.
[21] G. San Antonio, D.R. Fuhrmann, F.C. Robey, MIMO radar ambiguity functions, IEEE J. Sel. Top. Signal
Process. 1 (1) (2007) 167–177.
[22] C. Chen, P.P. Vaidyanathan, MIMO radar ambiguity properties and optimization using frequency-hopping
waveforms, IEEE Trans. Signal Process. 56 (12) (2008) 5926–5936.
[23] H.L. Van Trees, Detection, Estimation, and Modulation Theory I, John Wiley & Sons Inc., 2001.
[24] Q. He, R.S. Blum, A.M. Haimovich, Noncoherent MIMO radar for location and velocity estimation: more
antennas means better performance, IEEE Trans. Signal Process. 58 (7) (2010) 3661–3680.
[25] Q. He, R.S. Blum, Diversity gain for MIMO Neyman-Pearson signal detection, IEEE Trans. Signal Process.
59 (3) (2011) 869–881.
[26] Q. He, R.S. Blum, Cramer-Rao bound for MIMO radar target localization with phase errors, IEEE Signal
Process. Lett. 17 (1) (2010) 83–86.
[27] H. Godrich, A.M. Haimovich, H.V. Poor, An analysis of phase synchronization mismatch sensitivity for coher-
ent MIMO radar systems, in: Proceedings of the IEEE International Workshop on Computational Advances
in Multi-Sensor Adaptive Processing, Aruba, Dutch Antilles, December 2009, pp. 153–156.
[28] H. Godrich, A.M. Haimovich, Localization performance of coherent MIMO radar systems subject to phase
synchronization errors, in: Proceedings of the 4th International Symposium on Communications, Control and
Signal Processing, Limassol, Cyprus, 3–5 March 2010.

References
725
[29] M. Akçakaya, A. Nehorai, MIMO Radar detection and adaptive design under a phase synchronization mis-
match, IEEE Trans. Signal Process. 58 (10) (2010) 4994–5005.
[30] V.V. Shakhguildyan, S.S. Sviridenko, Phase synchronization systems studies, IEEE Trans. Commun. COM-30
(10) (1982) 2260–2263.
[31] B.D. Steinberg, Phase synchronizing a nonrigid, distributed, transmit-receive radar antenna array, IEEE Trans.
Aerosp. Electron. Syst. AES-18 (5) (1982) 609–620.
[32] E.H. Attia, Phase synchronizing large antenna arrays using the spatial correlation properties of radar clutter,
Ph.D. Thesis, University of Pennsylvania, 1985.
[33] E.-A. Lee, C.N. Dorny, A broadcast reference technique for self-calibrating of large antenna phased arrays,
IEEE Trans. Antennas Propag. 37 (8) (1989) 1003–1010.
[34] N.J. Willis, Bistatic Radar, second ed., SciTech Publishing, 2005.
[35] P. Lopez-Dekker, J.J. Mallorqui, P. Serra-Morales, J. Sanz-Marcos, Phase synchronization and Doppler cen-
troid estimation in ﬁxed receiver bistatic SAR systems, IEEE Trans. Geosci. Remote Sens. 46 (11) (2008)
3459–3471.
[36] B.P. Ng, J.P. Lie, M.H. Er, A. Feng, A practical simple geometry and gain/phase calibration technique for
antenna array processing, IEEE Trans. Antennas Propag. 57 (7) (2009) 1963–1972.
[37] W.C. Lindsey, F. Ghazvinian, W.C. Hagmann, K. Dessouky, Network synchronization, Proc. IEEE 73 (10)
(1985) 1445–1467.
[38] B. Sundararaman, U. Buy, A.D. Kshemkalyani, Clock synchronization for wireless sensor networks: a survey,
Ad Hoc Networks 3 (3) (2005) 281–323.
[39] Y. Tu, G.J. Pottie, Coherent cooperative transmission from multiple adjacent antennas to a distant stationary
antenna through AWGN channels, in: Proceedings of the IEEE Vehicular Technology Conference, AL, Spring
2002, vol. 1, pp. 130–134.
[40] R. Mudumbai, G. Barriac, U. Madhow, On the feasibility of distributed beamforming in wireless networks,
IEEE Trans. Wireless Commun. 6 (4) (2007) 1–10.
[41] Q. Li, D. Rus, Global clock synchronization in sensor networks, in: Proceedings of the IEEE Conference on
Computer Communications, March 2004, pp. 564–574.
[42] D.R. Brown III, G. Prince, J.A. McNeill, A method for carrier frequency and phase synchronization of two
autonomous cooperative transmitters, in: Proceedings of the IEEE Workshop on Signal Processing Advances
in Wireless Communications, New York, June 2005, pp. 260–264.
[43] D.R. Brown III, H.V. Poor, Time-slotted round-trip carrier synchronization for distributed beamforming, IEEE
Trans. Signal Process. 56 (11) (2008) 5630–5643.
[44] Q. Wang, K. Ren, Time-slotted round-trip carrier synchronization in large-scale wireless networks, in: Pro-
ceedings of the IEEE International Conference on Communications, May 2008, pp. 5087–5091.
[45] Y. Yang, R.S. Blum, Phase synchronization for coherent MIMO radar: algorithms and their analysis, IEEE
Trans. Signal Process. 59 (11) (2011) 5538–5557.
[46] R. Olfati-Saber, J.A. Fax, R.M. Murray, Consensus and cooperation in networked multi-agent systems, Proc.
IEEE 95 (1) (2007) 215–233.
[47] L. Xiao, S. Boyd, Fast linear iterations for distributed averaging, System Control Lett. 53 (2004) 65–78.
[48] S. Boyd, A. Ghosh, B. Prabhakar, D. Shah, Randomized gossip algorithms, IEEE Trans. Inform. Theory 52
(2006) 2508–2530.
[49] L. Xiao, S. Boyd, S.-J. Kim, Distributed average consensus with least-mean-square deviation, J. Parallel Distr.
Comput. 67 (1) (2007) 33–46.
[50] F. Fagnani, S. Zampieri, Randomized consensus algorithms over large scale networks, IEEE J. Sel. Area
Commun. 26 (4) (2008) 634–649.

726
CHAPTER 13 MIMO Radar with Widely Separated Antennas
[51] T.C. Aysal, M.E. Yildiz, A.D. Sarwate, A. Scaglione, Broadcast gossip algorithms for consensus, IEEE Trans.
Signal Process. 57 (2009) 2748–2761.
[52] Y. Yang, R.S. Blum, Broadcast-based consensus with non-zero-mean stochastic perturbations, IEEE Trans.
Inform. Theory (2013), <http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber= 6459027>.
[53] L. Schenato, G. Gamba, A distributed consensus protocol for clock synchronization in wireless sensor network,
in: Proceedings of the 46th IEEE Conference on Decision and Control, New Orleans, LA, December 2007,
pp. 2289–2294.
[54] G. Xiong, S. Kishore, Analysis of distributed consensus time synchronization with Gaussian delay over
wireless sensor networks, EURASIP J. Wireless Commun. Network. 2009 (2009) 9 (Article ID 528161).
[55] J. Rutman, Characterization of phase and frequency instabilities in precision frequency sources: ﬁfteen years
of progress, Proc. IEEE 66 (9) (1978) 1048–1075.
[56] A. Demir, A. Mehrotra, J. Roychowdhury, Phase noise in oscillators: a unifying theory and numerical methods,
IEEE Trans. Circ. Syst. Fund. Theory Appl. 47 (5) (2000) 655–674.
[57] M.I. Skolnik (Ed.), Radar Handbook, second ed., McGraw-Hill, New York, 1990.
[58] N. Levanon, E. Mozeson, Radar Signals, John Wiley & Sons, New York, 2004.
[59] Y. Yang, R.S. Blum, Minimax robust MIMO radar waveform design, IEEE J. Sel. Top. Signal Process. 1
(2007) 147–155.
[60] Y. Yang, R.S. Blum, Z.S. He, D.R. Fuhrmann, MIMO radar waveform design via alternating projection, IEEE
Trans. Signal Process. 58 (3) (2010) 1140–1445.
[61] T. Naghibi, F. Behnia, MIMO radar waveform design in the presence of clutter, IEEE Trans. Aerosp. Electron.
Syst. 47 (2) (2011) 770–781.
[62] C-Y. Chen, P.P. Vaidyanathan, MIMO radar waveform optimization with prior information of the extended
target and clutter, IEEE Trans. Signal Process. 57 (9) (2009) 3533–3544.
[63] B. Tang, J. Tang, Y. Peng, MIMO radar waveform design in colored noise based on information theory, IEEE
Trans. Signal Process. 58 (9) (2010) 4684–4697.
[64] J. Zhang, H. Wang, X. Zhu, Adaptive waveform design for separated transmit/receive ULA-MIMO radar,
IEEE Trans. Signal Process. 58 (9) (2010) 4936–4942.
[65] A. De Maio, M. Lops, Design principles of MIMO radar detectors, IEEE Trans. Aerosp. Electron. Syst. 43
(3) (2007) 886–898.
[66] A. De Maio, M. Lops, L. Venturino, Diversity-integration tradeoffs in MIMO detection, IEEE Trans. Signal
Process. 56 (10) (2008) 5051–5061.
[67] D.R. Fuhrmann, G. San Antonio, Transmit beamforming for MIMO radar systems using signal cross-
correlation, IEEE Trans. Aerosp. Electron. Syst. 44 (1) (2008) 171–186.
[68] B. Friedlander, Waveform design for MIMO radars, IEEE Trans. Aerosp. Electron. Syst. 43 (3) (2007)
1227–1238.
[69] J. Li, P. Stoica, Y. Xie, On probing signal design for MIMO radar, IEEE Trans. Signal Process. 55 (8) (2007)
4151–4161.
[70] T. Naghibi, M. Namvara, F. Behniaa, Optimal and robust waveform design for MIMO radars in the presence
of clutter, IEEE Trans. Signal Process. 90 (4) (2010) 1103–1117.
[71] G.H. Jajamovich, M. Lops, X. Wang, Space-time coding for MIMO radar detection and ranging, IEEE Trans.
Signal Process. 58 (12) (2010) 6195–6206.
[72] A. Aubry, M. Lops, A.M. Tulino, L. Venturino, On MIMO detection under non-Gaussian target scattering,
IEEE Trans. Inform. Theory 56 (11) (2010) 5822–5838.
[73] X. Song, S. Zhou, P. Willett, Reducing the waveform cross correlation of MIMO radar with space-time coding,
IEEE Trans. Signal Process. 58 (8) (2010) 4213–4224.
[74] H. Wang, G. Liao, H. Liu, J. Li, H. Lv, Joint optimization of MIMO radar waveform and biased estimator
with prior information in the presence of clutter, EURASIP J. Adv. Signal Process. 2011 (2011) 15.

References
727
[75] M.R. Bell, Information theory and radar waveform design, IEEE Trans. Inform. Theory 39 (1993) 1578–1597.
[76] T.M. Cover, J.A. Thomas, Elements of Information Theory, John Wiley & Sons, New York, 1991.
[77] U. Grenander, G. Szegö, Toeplitz Forms and Their Applications, second ed., Chelsea Publishing Company,
New York, 1984.
[78] R.M. Gray, Toeplitz and Circulant Matrices: A Review, 2002. http://www.ee.stanford.edu/gray/toeplitz.pdf.
[79] S.A. Kassam, H.V. Poor, Robust techniques for signal processing: a survey, Proc. IEEE 73 (3) (1985) 433–481.

14
CHAPTER
Optimal Radar Waveform Design
Joseph R. Guerci
Guerci Consulting LLC, Vienna, VA, USA
Nomenclature
CN
N-dimensional complex vector space
s ∈CN
multidimensional transmit signal
HT ∈CM×N
multidimensional target transfer function (generally stochastic)
ys ∈CN
multidimensional received target “Echo”
n ∈CM
multidimensional complex additive receiver noise (zero mean)
R ∈CM×M
additive receiver noise covariance matrix
Hw = R−1/2
whitening ﬁlter
zs ∈CN
whitened target echo
E{·}
expectation operator
HT ∈CN×N
clutter channel transfer function (generally stochastic)
p(X|H)
conditional PDF
S(ω) ↔s(t)
fourier transform pair
λ
radar wavelength
2.14.1 Introduction
Adaptive processing has long been implemented in the receive chain of radar, beginning with auto-
matic gain control (AGC), cell-averaging constant false alarm rate (CA-CFAR) [1] and culminating in
today’s space-time adaptive processing (STAP) [2]. However, adaptivity in the transmit chain is virtually
nonexistent, save for mode adaptivity (such as switching in different nonadaptive waveforms such as
pulse repetition frequency (PRF) and bandwidth) and adaptive spectral notching to address narrowband
interference mitigation. Historically, the reasons for the lack of transmit adaptivity included:
•
Inability of radar hardware to transmit arbitrary waveforms (or more generally arbitrary space-time
waveforms).
•
Lack of sufﬁcient embedded computing to allow for real-time waveform adaptation.
•
As a result of the above, there is a lack of basic theory for optimal waveform design as a function of
the target-interference channel (except for very specialized cases).
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-396500-4.00014-4
© 2014 Elsevier Ltd. All rights reserved.
729

730
CHAPTER 14 Optimal Radar Waveform Design
However, as discussed in the abstract, the ﬁrst two obstacles are no longer the case. All that remains is to
revisit the basic radar theoretic problem and derive a new set of design equations allowing for transmit
adaptivity as a function of the target-interference channel.
This chapter develops the basic theory of optimal transmit/receive design using a multi-input, multi-
output (MIMO) formulation that can account for all potential degrees of freedom (DOFs) such as
waveform (fast-time), angle, and polarization. Various applications and examples are provided to further
illustrate the potential impact of joint transmit/receive adaptivity. The only mathematical prerequisites
for this material is a basic understanding of matrix algebra, basic optimization theory, and stochastic
processes.
2.14.2 Optimum transmit-receiver design for the additive colored
noise case: detection
Due to the ﬁnite bandwidth constraint for all real-world radars, there is no loss in generality in invoking
Shannon’s sampling theory [3]. This, in turn, allows for a matrix algebra formulation of the basic radar
interaction equations which both signiﬁcantly eases nomenclature and exposition (see below).
Consider the basic radar block diagram in Figure 14.1. A generally complex-valued and multidimen-
sional transmit signal, s ∈CN, (i.e., an N-dimensional multi-input (MI) signal), interacts with a target
denoted by the target transfer matrix HT ∈CM×N. The resulting M-dimensional multi-output (MO)
signal (echo), y ∈CM, is then received along with ACN n ∈CM, assumed to be zero mean, wide sense
stationary,withcorrespondingcomplexvaluedcovariance R ∈CM×M.Thevector-matrixformulationis
completely general inasmuch as any combination of spatial and temporal dimensions can be represented.
For example, the N-dimensional input vector s could represent the N complex (i.e., in-phase/
quadrature, or “ I and Q” [4]) samples of a single-channel transmit waveform s(t), that is,
s =
⎡
⎢⎢⎢⎣
s(τ1)
s(τ2)
...
s(τN)
⎤
⎥⎥⎥⎦.
(14.1)
The corresponding target transfer matrix, HT , would thus contain the corresponding samples of the
complex target impulse response, hT (t), which for the causal linear time-invariant (LTI) case would
have the form [3]
HT =
⎡
⎢⎢⎢⎢⎢⎣
h[0]
0
0
· · ·
0
h[1]
h[0]
0
· · ·
0
h[2]
h[1] h[0]
· · ·
0
...
...
...
h[N −1]
h[1] h

0
	
⎤
⎥⎥⎥⎥⎥⎦
.
(14.2)
Without loss of generality we have assumed uniform time sampling, that is, τk = (k −1)T , where T
is a suitably chosen sampling interval [5]. Note also that for convenience and a signiﬁcant reduction in
mathematical nomenclature overhead, N = M is used, (i.e., the same number of transmit and receive

2.14.2 Optimum Transmit-Receiver Design
731
DOFs). The reader is encouraged to, where desired, reinstate the inequality and conﬁrm that the under-
lying equations derived throughout this chapter have the same basic form except for differing vector
and matrix dimensionalities. Also it should be noted that in general HT is stochastic.
The formalism is readily extensible to the multiple-transmitter, multiple-receiver case. For example,
if there are three independent transmit/receive channels (e.g., an AESA), then the input vector s of
Figure 14.1 would have the form
s =
⎡
⎣
s1
s2
s3
⎤
⎦∈C3N,
(14.3)
where si ∈CNdenotes the samples (as in (14.1)) of the transmitted waveform out of the ith transmit
channel. The corresponding target transfer matrix would in general have the form
HT =
⎡
⎣
H11
H12
H13
H21
H22
H23
H31
H32
H33
⎤
⎦∈C3N×3N,
(14.4)
where the submatrix Hi, j ∈CN×N is the transfer matrix between the ith receive and jth transmit channels
for all time samples of the waveform. These examples make clear that the matrix-vector, input-output
formalism is completely universal and can accommodate whatever transmit/receive DOF conﬁguration
desired.
+
+
w
T
H
“Target”
Optimum
Receiver
Detection
Statistic
“Channel”
Targets, 
Jamming, Noise
.  .  .
.  .  .
Transmitter(s)
Receivers(s)
~
M
M M
R
×
∈
∈
n
M N
T
×
∈
H
N
∈
s
M
∈
y
Σ
M
∈
w
FIGURE 14.1
Fundamental multichannel radar block diagram for the ACN case. The objective is to design both the transmit
and receive functions to maximize the output SINR given the channel characteristics.

732
CHAPTER 14 Optimal Radar Waveform Design
w
H
s +
y
n
1
2
w
R
−
=
H
Whitening
Filter
s
n
w
s
w
H
H
=
+
+
z
z
z
y
n
sz
Matched
Filter
1
z
R−
=
w
y
Target 
Echo
FIGURE 14.2
The optimum (max SINR) receiver for the ACN case consists of a whitening ﬁlter followed by a white noise
matched ﬁlter.
Returning to Figure 14.1, we now wish to jointly optimize the transmit/receive functions to maximize
output SINR, which under the Gaussian assumption, would yield a sufﬁcient statistic that maximizes
the probability of detection for a prescribed false alarm rate [6]. We will ﬁnd it convenient to work
backward: to begin by optimizing the receiver as a function of the input and then ﬁnally optimizing the
input and thus the overall output SINR.
For any ﬁnite norm input s, the receiver that maximizes output SINR for the ACN case is the so-
called whitening (or colored noise) matched ﬁlter, as shown in Figure 14.2 [6]. Note that for the additive
Gaussian colored noise (AGCN) case, this receiver is also statistically optimum [6].
R ∈CN×N, which denotes the total interference covariance matrix associated with n, is further
assumed to be independent of s and Hermitian positive deﬁnite [7] (guaranteed in practice due to ever-
present receiver noise [6]), then the corresponding whitening ﬁlter shown in Figure 14.2 is given by [6]:
Hw = R−1
2 ,
(14.5)
where the superscript −1
2 denotes the “matrix square root inverse” [8].
The output of the linear whitening ﬁlter, z ∈CN, will consist of signal and noise components, zs, zn,
respectively, given by
z = zs + zn
= Hwys + Hwn
(14.6)
= HwHT s + Hwn,
where ys ∈CN denotes the target echo as shown in Figure 14.2 (i.e., the output of HT ).
Since the noise has been whitened via a linear—in this case full-rank—transformation [6]), the ﬁnal
receiver stage consists of a white noise matched ﬁlter of the form (to within a multiplicative scalar)
wz = zs ∈CN.
(14.7)

2.14.2 Optimum Transmit-Receiver Design
733
The corresponding output SNR is thus given by
SNRo =


w′
zzs


2
var

w′zzn

=


z′
szs


2
var

z′szn

=


z′
szs


2
E

z′sznz′nzs

(14.8)
=


z′
szs


2
z′s E

znz′n

zs
=


z′
szs


2
z′szs
=


z′
szs


 ,
where superscript “′” denotes complex conjugate transpose, and var(·) denotes the variance operator.
Note that due to the whitening operation E{znz′
n} = I.
In words, the output SNR is proportional to the energy in the whitened target echo. This fact is key to
optimizing the input function: Chose s (the input) to maximize the energy in the whitened target echo:
max
s


z′
szs


 .
(14.9)
Substituting zs = HwHT s into (14.9) yields the objective function that explicitly depends on the input
max
s


s′(H′H)s


 ,
(14.10)
where
H ≜HwHT .
(14.11)
Recognizing that (14.10) involves the magnitude of the inner product of two vectors s and (H′H)s,
we readily have from the Cauchy-Schwarz theorem [9] the condition that s must satisfy to yield a
maximum, namely, s must be collinear with (H′H)s:
(H′H)sopt = λmaxsopt.
(14.12)
In other words, the optimum input sopt must be an eigenvector of (H′H) with associated maximum
eigenvalue.
The previous set of input-output design equations represents the absolute optimum that any combi-
nation of transmit/receive operations can achieve and thus are fundamentally important in ascertaining
the value of advanced adaptive methods (e.g., adaptive waveforms, transmit/receive beamforming). Note

734
CHAPTER 14 Optimal Radar Waveform Design
Multipath
Channel
)
(t
n
)
(t
hMP
)
(
)
(
)
(
t
h
t
n
t
n
MP
MP
∗
=
White Noise
Colored Noise
White Noise
Source
Direct Path
Multipath
Multipath
FIGURE 14.3
Illustration of colored noise interference resulting from a broadband (i.e., white noise) source undergoing
strong discrete multipath reﬂections. The resulting signal can be approximated as white noise driving a ﬁnite
impulse response (FIR) ﬁlter.
also that (14.12) can be generalized to the case where the target response is random:
E{H′H}sopt = λmaxsopt.
(14.13)
In this case, sopt maximizes the expected value of the output SINR.
Next we illustrate the application of the previously given optimum design equations to the additive
colored noise problem arising from a broadband multipath interference source.
2.14.2.1 Application to broadband multipath interference
This application illustrates the optimum transmit/receive conﬁguration for maximizing output SINR
in the presence of colored noise interference arising from a multipath broadband noise source. More
speciﬁcally, for the single transmit/receive channel case, it derives the optimum transmit pulse modu-
lation (i.e., pulse shape/spectrum).
Figure 14.3 illustrates a nominally broadband white noise source undergoing a series of multipath
scatterings that in turn colors the noise spectrum [10]. Assuming (for simplicity) that the multipath
reﬂections are dominated by several discrete specular reﬂections, the resultant signal can be viewed as
the output of a causal tapped delay line ﬁlter (i.e., an FIR ﬁlter [3]) of the form
hmp[k] = α0δ[k] + α1δ[k −1] + · · · + αq−1δ[k −q −1]
(14.14)

2.14.2 Optimum Transmit-Receiver Design
735
that is driven by white noise. The corresponding input-output transfer Hmp ∈CN×N is thus given by
Hmp =
⎡
⎢⎢⎢⎢⎣
hmp[0]
0
· · ·
0
hmp[1]
hmp[0]
...
...
...
0
hmp[N −1]
· · ·
hmp[1] hmp[0]
⎤
⎥⎥⎥⎥⎦
.
(14.15)
In terms of the multipath transfer matrix, Hmp, the colored noise interference covariance matrix is
given by
E{nn′} = E

Hmpνν′H′
mp

= HmpE

νν′
H′
mp
(14.16)
= Hmp H′
mp
= R,
where the driving white noise source ν ∈CN is a zero mean complex vector random variable with an
identity covariance matrix:
E{νν′} = I.
(14.17)
Assuming a unity gain point target at the origin, that is, hT [k] = δ[k], yields a target transfer matrix
HT ∈C N×N given by
HT =
⎡
⎢⎢⎢⎢⎣
hT [0]
0
· · ·
0
hT [1]
hT [0]
...
...
...
0
hT [N −1]
· · ·
hT [1] hT [0]
⎤
⎥⎥⎥⎥⎦
= I.
(14.18)
While certainly a more complex (and thus realistic) target model could be assumed, we wish to focus
on the impact the colored noise has on shaping the optimum transmit pulse. We will introduce more
complex target response models in the target ID section.
Figure 14.4 shows the in-band interference spectrum for the case when α0 = 1, α2 = 0.9, α5 = 0.5,
α10 = 0.2, all other coefﬁcients are set to zero. The total number of fast-time (range bin) samples was
set to both a short-pulse case of N = 11 (Figure 14.4a) and a long-pulse case of N = 100 (Figure 14.4b).
Note that the multipath colors the otherwise ﬂat noise spectrum. Also displayed is the spectrum of a con-
ventional (and thus non-optimized) LFM pulse with a time-bandwidth product, βτ, of 5 (Figure 14.4a)
and 50 (Figure 14.4b), respectively [11,12].
Given R from (14.16), the corresponding whitening ﬁlter Hw is given by
Hw = R−1
2 .
(14.19)

736
CHAPTER 14 Optimal Radar Waveform Design
(a)
−20
−15
−10
−5
0
5
10
Frequency
Magnitude (dB)
Noise Spectrum
LFM (N=11)
Optimum (N=11)
−0.5
0
0.5
(b)
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
−20
−15
−10
−5
0
5
10
Frequency
Magnitude (dB)
Noise Spectrum
LFM (N=100)
Optimum (N=100)
FIGURE 14.4
Spectra of the colored noise interference along with conventional and optimal pulse modulations. (a) Short-
pulse case where total duration for the LFM and optimum pulse are set to 11 range bins (fast-time taps).
(b) Long-pulse case where total duration for the LFM and optimum pulse are set to 100 range bins. Note that
in both cases the optimum pulse attempts to anti-match to the colored noise spectrum under the frequency
resolution constraint set by the total pulse width.

2.14.3 Optimum Transmit-Receiver Design
737
Combining (14.19) with (14.18), the total composite channel transfer matrix H is thus given by
H = HwHT = Hw = R−1
2 .
(14.20)
Substituting (14.20) into (14.12) yields
R−1sopt = λsopt.
(14.21)
That is, the optimum transmit waveform is the maximum eigenvector associated with the inverse of the
interference covariance matrix.
Displayed in Figures 14.4a and 14.4b are the spectra of the optimum transmit pulses obtained by
solving (14.21) for the maximum eigenfunction-eigenvalue pair for the aforementioned short- and long-
pulse cases, respectively. Note how the optimum transmit spectrum naturally emphasizes portions of
the spectrum where the interference is weak—which is an intuitively satisfying result.
The SINR gain of the optimum short pulse, SINRopt, relative to that of a nonoptimized chirp pulse,
SINRLFM, is
SINRgain ≜SINRopt
SINRLFM
= 7.0 dB,
(14.22)
while for the long-pulse case
SINRgain ≜SINRopt
SINRLFM
= 24.1 dB.
(14.23)
The increase in SINR for the long-pulse case is to be expected since it has ﬁner spectral resolution
and can therefore more precisely shape the transmit modulation to “anti-match” the interference. Of
course, the unconstrained optimum pulse has certain practical deﬁciencies (e.g., poorer resolution, com-
pression sidelobes) compared with a conventional pulse. We will revisit these issues when constrained
optimization is introduced.
This application is similar in spirit to the spectral notching waveform design problem that arises
when strong co-channel narrowband interferers are present [13]. In this case it is desirable not only to
ﬁlter out the interference on receive but also to choose a transmit waveform that minimizes energy in
the co-channel bands. The reader is encouraged to experiment with different notched spectra and pulse
length assumptions and to apply (14.12) as indicated. Non-impulsive target models can also be readily
incorporated.
2.14.3 Optimum transmit-receiver design for the clutter case: detection
Radar clutter refers to all unwanted reﬂections emanating from anything other than the desired target
of interest [12]. It is thus a form of transmit-signal dependent interference, in contrast to the previously
considered ACN case. Unfortunately, the joint optimization of the transmit and receive functions for the
general additive colored noise plus clutter (signal-dependent noise) has been shown to result in a highly
nonlinear problem [14] (though efﬁcient iterative methods have been developed to solve these equations
[14]). In practice, however, there is often a natural “separation principle” between additive colored
noise (signal independent) and clutter (signal dependent). For example, narrowband electromagnetic

738
CHAPTER 14 Optimal Radar Waveform Design
+
+
T
H
Target
c
H
Clutter
N
∈
s
N N
T
×
∈
H
N
s ∈
y
s
c
+
y
n
N N
c
×
∈
H
N
c ∈
n
Σ
FIGURE 14.5
Radar signal block diagram for the clutter dominant case illustrating the direct dependency of the clutter
signal on the transmitted signal.
interference (EMI) resulting from co-channel interference might require fast-time receiver and transmit
spectral notching [13], leaving the slow-time or spatial DOF available for clutter suppression. Similarly,
adaptive beamforming for broadband jammer nulling can be separated from the clutter suppression
problem in a two-stage approach (see, e.g., [15]). We will thus concentrate in this section on the clutter
dominant case and focus solely on maximizing the output signal-to-clutter ratio (SCR).
Unlike the previous additive colored noise case, clutter (i.e., channel reverberations) is a form of
signal-dependent noise [16,17] since the clutter returns depend on the transmit signal characteristics
(e.g., transmit antenna pattern and strength, operating frequencies, bandwidths, polarization). Referring
to Figure 14.5, the corresponding SCR at the input to the receiver is given by
SCR = E{y′
T yT }
E{y′cyc}
= s′E

H′
T HT

s
s′E

H′cHc

s .
(14.24)
where Hc ∈C N×N denotes the clutter transfer matrix, which is generally taken to be stochastic.
Equation (14.24) is a generalized Rayleigh quotient [7] that is maximized when s is a solution to the
generalized eigenvalue problem
E{H′
T HT }s = λE{H′
cHc}s
(14.25)
with corresponding maximum eigenvalue. When E{H′
cHc} is positive deﬁnite, (14.25) can be converted
to an ordinary eigenvalue problem of the form we have already encountered, speciﬁcally,
E{H′
cHc}−1E{H′
T HT }s = λs.
(14.26)

2.14.3 Optimum Transmit-Receiver Design
739
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
0.5
−50
−40
−30
−20
−10
0
10
20
Normalized Frequency
Magnitude (dB)
Quiescent
Optimum
*
*
*
FIGURE 14.6
Illustration of proactive sidelobe target blanking on transmit achieved by maximizing the SCR. Note the
presence of nulls in the directions of competing targets while preserving the desired mainbeam response.
2.14.3.1 Application: sidelobe clutter discrete suppression
Consider a narrowband N = 16 element uniform linear array (ULA) with half-wavelength interele-
ment spacing with a boresight pointing quiescent pattern (see Figure 14.6) [18]. In addition to the
desired target at a normalized angle of ¯θ = 0 (array boresight), there are strong sidelobe targets at
¯θ1 = −0.3, ¯θ2 = +0.1, ¯θ3 = +0.25, where a normalized angle is deﬁned as
¯θ ≜d
λ sin θ.
(14.27)
In (14.27) d is the interelement spacing of the ULA, and λ is the operating wavelength (consistent units
and narrowband operation assumed).
The presence of these targets (possibly large clutter discretes) could have been previously detected,
thus making their AOAs known. Also, their strong sidelobes could potentially mask weaker mainlobe
targets. With this knowledge, it is desired to minimize any energy from these targets leaking into the
mainbeam detection of the target of interest by nulling on transmit, or placing transmit antenna pattern
nulls in the directions of the unwanted targets.
For the case at hand, the (m,n)th elements of the target and interferer transfer matrices are given,
respectively, by
[HT ]m,n = e jφ(const.),
(14.28)

740
CHAPTER 14 Optimal Radar Waveform Design
[Hc]m,n = α1e j2π(m−n) ¯θ1 + α2e j2π(m−n) ¯θ2 + α3e j2π(m−n) ¯θ3,
(14.29)
where ϕ is an overall bulk delay (two way propagation) that does not affect the solution to (14.25)
and will thus be subsequently ignored, and [Hc]m,n is the (m,n)th element of the clutter transfer matrix
and consists of the linear superposition of the three target returns resulting from transmitting a narrow-
band signal from the nth transmit element and receiving it on the mth receive element of a ULA that uses
the same array for transmit and receive [2,12]. Note that in practice there would be a random relative
phase between the signals in (14.29), which for convenience we have ignored but which can easily be
accommodated by taking the expected value of the kernel H′
cHc.
Solving (14.25) for the optimum eigenvector yields the transmit pattern that maximizes the SCR,
which is the pattern also displayed in Figure 14.6. The competing target amplitudes were set to 40 dB
relative to the desired target and 0 dB of diagonal loading was added to H′
cHc to improve numerical con-
ditioning and allow for its inversion. Although this is somewhat arbitrary, it does provide a mechanism
for controlling null depth, that in practice is limited by the amount of transmit channel mismatch [19].
Note the presence of transmit antenna pattern nulls in the directions of the competing targets as desired.
An important caveat to the above was the assumption of perfect knowledge of the transmit array
manifold—that is the assumption of a perfectly transmit calibrated AESA. This can only approximately
be the case in practice. Indeed knowledge of the receive array manifold, which is generally easier to
estimate on-the-ﬂy, is not equivalent to that of the transmit manifold (since slightly different electrical
pathways are taken). A MIMO method has been developed for transmit manifold calibration under the
DARPA ISAT program and can be found in [20].
2.14.3.2 Application: optimum pulse shaping for maximizing SCR
In this simple example, we rigorously verify an intuitively obvious result regarding pulse shape and
detecting a point target in uniform clutter: the best waveform for detecting a point target in distributed
i.i.d clutter is itself animpulse(i.e., awaveform withmaximal resolution), awell-knownresult rigorously
proven by Manasse [21] using a different method.
Consider a unity point target, arbitrarily chosen to be at the temporal origin. Its corresponding impulse
response and transfer matrix are respectively given by
hT [n] = δ[n]
(14.30)
and
HT = IN×N,
(14.31)
where IN×N denotes the N × N identity matrix. For uniformly distributed clutter, the corresponding
impulse response is of the form
hc[n] =
N−1

k=0
˜γkδ[n −k],
(14.32)

2.14.3 Optimum Transmit-Receiver Design
741
where ˜γi denotes the complex reﬂectivity random variable of the clutter contained in the ith range cell
(i.e., fast-time tap). The corresponding transfer matrix is given by
˜Hc =
⎡
⎢⎢⎢⎢⎢⎣
˜γ0
0
0
· · ·
0
˜γ1
˜γ0
˜γ2
˜γ1
˜γ0
...
...
˜γN−1
˜γN−2
˜γN−3
· · ·
˜γ0
⎤
⎥⎥⎥⎥⎥⎦
.
(14.33)
Assuming that the ˜γi values are i.i.d., we have
E

˜γ ∗
i ˜γ j

= Pcδ[i −j]
(14.34)
and thus
E

˜H′
c ˜Hc

i, j

=
0,
i ̸= j,
(N + 1 −i)Pc,
i = j,
(14.35)
where [ ]i, j denotes the (i, j)th element of the transfer matrix. Note that (14.35) is also diagonal (and thus
invertible), but with non-equal diagonal elements.
Finally, substituting (14.31) and (14.35) into (14.26) yields
E

˜H′
c ˜Hc
−1
s = λs,
(14.36)
where
E

˜H′
c ˜Hc
−1
= 1
Pc
⎡
⎢⎢⎢⎣
d1
0
· · ·
0
0
d2
...
0
· · · dN
⎤
⎥⎥⎥⎦
(14.37)
and
di ≜(N + i −1)−1.
(14.38)
It is readily veriﬁed that the solution to (14.36) yielding the maximum eigenvalue is given by
s =
⎡
⎢⎢⎢⎣
1
0
...
0
⎤
⎥⎥⎥⎦.
(14.39)
Thus the optimum pulse shape for detecting a point target is itself an impulse. This should be immediately
obvious since it is the shape that excites the range bin only with the target and zeros out all other range
bin returns that contain competing clutter.
Of course, transmitting a short pulse (much less an impulse) is problematic in the real world (e.g.,
creating extremely high peak power pulses) thus an approximation to a short pulse in the form of a
spread spectrum waveform (e.g., LFM) is often employed [11]. This example also makes clear that in

742
CHAPTER 14 Optimal Radar Waveform Design
Matched
Filter
#1
(Target 1)
Matched
Filter
#2
(Target 2)
Comparator
1
H
2
H<>
FIGURE 14.7
Optimal receiver structure for the binary (two-target) hypothesis testing AGN problem.
uniform random clutter nothing is gained by sophisticated pulse shaping for a point target other than
to maximize bandwidth (i.e., range resolution) [21]. The interested reader is referred to [22] for further
examples of optimizing other DOF (e.g., angle-Doppler) for the clutter mitigation problem.
Up to this point we have been focused on judiciously choosing the transmit/receive DOF to maximize
SINR or SCR (and thus ultimately detection). In the next section we will extend this framework to the
target identiﬁcation problem.
2.14.4 Optimizing the transmit-receive functions for target identiﬁcation
Consider the problem of determining target type when two possibilities exist (the multitarget case is
addressed later in this section). This can be cast as a classical binary hypothesis testing problem [6]:
(Target 1) H1 : y1 + n = HT1s + n,
(Target 2) H2 : y2 + n = HT2s + n,
(14.40)
where HT1, HT2 denote the target transfer matrices for targets 1 and 2, respectively. For the AGCN case,
the well-known optimum receiver decision structure consists of a bank of matched ﬁlters (generally
whitening matched ﬁlters), each tuned to a different target assumption, followed by comparator as
shown in Figure 14.7 [6]. Note that (14.40) presupposes that either Target 1 or 2 is present, but not both.
Also, it has been tacitly assumed that a binary detection test has been conducted to ensure that a target
is indeed present [6]. Alternatively, the null hypothesis (no target present) can be included in the test as
a separate hypothesis (see below).
Figure 14.8 illustrates the situation at hand. If Target-1 is present, the observed signal y1 + n will
tend to cluster about the #1 point in observation space—which could include any number of dimensions
relevant to the target ID problem (e.g., fast-time, angle, Doppler, polarization). The uncertainty sphere
(generally ellipsoid for ACN case) surrounding #1 in Figure 14.7 represents the 1-sigma probability
for the additive noise n—and similarly for #2. Clearly, if y1 and y2 are relatively well separated, the
probability of correct classiﬁcation is commensurately high.

2.14.4 Optimizing the Transmit-Receive Functions
743
1r
2r
3r
Received Signal
Observation Space
“Uncertainty Sphere”
due to Noise, Modeling
Errors, etc.
Target-2
Target-1
1y − y
Distance Metric:
y1
y2
2
FIGURE 14.8
Illustration of the two-target ID problem. The goal of the joint transmitter/receiver design is to maximally
separate the received signals in observation space, which in turn maximizes the probability of correct clas-
siﬁcation for the additive unimodal monotonic distributed noise case under fairly general conditions.
Signiﬁcantly, y1 and y2 depend on the transmit signal s, as shown in (14.40). Consequently, it should
be possible to select an s that maximizes the separation between y1 and y2, thereby maximizing the
probability of correct classiﬁcation under modest assumptions regarding the conditional probability
density functions (PDFs) (e.g., unimodality), that is,
max
s


d′d


 ,
(14.41)
where
d ≜y1 −y2
= HT1s −HT2s
= (HT1 −HT2)s
≜Hs.
(14.42)
and where
H≜HT1 −HT2.
(14.43)
Substituting (14.42) into (14.41) yields
max
s
|s′H′Hs|.
(14.44)

744
CHAPTER 14 Optimal Radar Waveform Design
1
y
2
y
d
1
(
|
)
p X H
2
(
|
)
p X H
FIGURE 14.9
Illustration of the impact of the separation metric d on the overlap of the conditional PDFs.
This is precisely of the form (14.10) and thus has a solution yielding maximum separation given by
(H′H)sopt = λmaxsopt.
(14.45)
It is noted that (14.45) has an interesting interpretation: sopt is that transmit input that maximally
separates the target responses and is thus the maximum eigenfunction of the transfer kernel H′H formed
by the difference between the target transfer matrices (i.e., (14.43)). Again if the composite target transfer
matrix is stochastic, H′H is replaced with its expected value E{H′H} in (14.45).
Conditions for strict statistical optimality of the above optimization can be established by examining
the properties of the conditional PDFs:
(Target 1) H1 : p(X|H1, d),
(Target 2) H2 : p(X|H2, d).
(14.46)
For the case when the two conditional PDFs differ due to a shift in their means (generally multidimen-
sional), an eminently reasonable assumption given the additive noise model of (14.40), the situation at
hand can be illustrated as in Figure 14.9. We see that maximizing ∥d∥minimizes the overlap of the
PDFs provided:
F(X, H1, H2, d2) ≥F(X, H1, H2, d1),
(14.47)
where
F(X, H1, H2, d) ≜
∞

−∞
· · ·
∞

−∞
|p(X|H1, d) −p(X|H2, d)| dx1 . . . dxN
(14.48)
with
∥d2∥≥∥d1∥.
(14.49)
Note that F(X, H1, H2, d) = 0 when d = 0. Clearly the class of multivariate Gaussian PDFs satisﬁes
the above. Interestingly, even non-Gaussian PDFs can satisfy the above such as the class of unimodal
distributions [23], and a broad class of elliptically contoured distributions [24]. This is in stark contrast to
receiver optimization where generally the Gaussian assumption is required to ensure strict optimality [6].
2.14.4.1 Application: two-target identiﬁcation example
Let h1[n] and h2[n] denote the impulse responses of targets #1 and #2, respectively (Figure 14.10).
Figure 14.11 shows two different (normalized) transmit waveforms—LFM and optimum (per (14.45))—
along with their corresponding normalized separation norms of 0.45 and 1, respectively, which

2.14.4 Optimizing the Transmit-Receive Functions
745
0
5
10
15
20
25
30
35
40
45
50
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Time
Normalized Voltage
Target 1
Target 2
FIGURE 14.10
Baseband target impulse responses utilized for the two-target identiﬁcation problem.
corresponds to 6.9 dB improvement in separation. To determine the relative probabilities of correct
classiﬁcation for the different transmit waveforms, one would ﬁrst need to set the SNR level, which
ﬁxes the conditional PDF herein assumed to be circular Gaussian, and then to measure the amount of
overlap to calculate the probability [6].
An examination of Figure 14.12 reveals the mechanism by which enhanced separation is achieved.
It shows the Fourier spectrum of H(ω) = HT1(ω) −HT2(ω), along with that of Sopt(ω). Note that
Sopt(ω) places more energy in spectral regions where H(ω) is large (i.e., spectral regions where the
difference between targets is large, which is again an intuitively appealing result).
While pulse modulation was used to illustrate the optimum transmit design equations, we could theo-
retically have used any transmit DOF (e.g., polarization). The choice clearly depends on the application
at hand.
2.14.4.2 Multi-target identiﬁcation case
Given L targets in general, we wish to ensure that the L-target response spheres are maximally separated
(an inverse sphere packing problem [25]). To accomplish this, we would like to jointly maximize the
norms of the set of separations {∥di j∥|i = 1 : L; j = i + 1 : L}:
max
s
L

i=1
L

j=i+1


d′i jdi j


.
(14.50)

746
CHAPTER 14 Optimal Radar Waveform Design
0
5
10
15
20
25
30
35
40
45
50
−0.25
−0.2
−0.15
−0.1
−0.05
0
0.05
0.1
0.15
0.2
0.25
Time
Normalized Voltage
Chirp
Optimum
chirp
0.45
d
opt
1
d
=
=
FIGURE 14.11
Transmit waveforms employed in the two-target identiﬁcation example.
Since, by deﬁnition, di j is given by
di j ≜

HTi −HTj

s ≜Hi js.
(14.51)
Equation (14.50) can be rewritten as
max
s
s′
⎛
⎝
L

i=1
L

j=i+1
H′
i j Hi j
⎞
⎠s ≜s′Ks.
(14.52)
Since K ∈C N×N is the sum of positive semideﬁnite matrices, it shares this same property, and thus
the optimum transmit input satisﬁes
Ksopt = λmaxsopt.
(14.53)
2.14.4.3 Application: multitarget ID
Figure 14.13 depicts the impulse responses of three different targets, two of which are the same as in
Section 2.14.4.1. Solving (14.52) and (14.53) yields an optimally separating waveform whose average
separation deﬁned by (14.50) is 1.0. This is compared with 0.47 for the LFM of Example 3.4, an
improvement of 6.5 dB, which is slightly less than the previous two-target example. As expected, the
optimum waveform signiﬁcantly outperforms the unoptimized pulse waveform such as the LFM.

2.14.5 Constrained Optimum Transmit-Receiver Radar
747
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
0.5
−50
−40
−30
−20
−10
0
10
20
Normalized Frequency
Magnitude (dB)
Difference Spectrum
Optimum Pulse Spectrum
FIGURE 14.12
Comparison of the two-target difference spectrum and the optimum pulse spectrum. Note that the optimum
pulse emphasizes parts of the spectrum where the two targets differ the most.
2.14.5 Constrained optimum transmit-receiver radar
Often there are a number of additional practical considerations (beyond ﬁnite norm) that may preclude
transmitting the unconstrained optimum solutions developed so far. We will thus consider two cases of
constrained optimization: linear and nonlinear—the latter is generally far more challenging and an area
of active research.
2.14.5.1 Case 1: Linear constraints
Consider the linearly constrained version of the input (transmitter) optimization problem:
max
{s}


s′H′Hs


(14.54)
subject to: Gs = 0,
(14.55)
where G ∈CQ×N. To avoid the overly constrained case, it is assumed that Q < N. For example, the
rows of G could represent steering vectors associated with known interferers such as unwanted targets
or clutter discretes to which we wish to apply transmit nulls.

748
CHAPTER 14 Optimal Radar Waveform Design
0
5
10
15
20
25
30
35
40
45
50
−1
−0.8
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Time
Normalized Voltage
Target 1
Target 2
Target 3
FIGURE 14.13
Target impulse responses used for the three-target identiﬁcation problem.
Equation (14.55) deﬁnes the feasible solution subspace for the constrained optimization problem.
It is straightforward to verify that the projection operator
P = I −G′(GG′)−1G
(14.56)
projects any x ∈CN into the feasible subspace [26]. Thus, we can ﬁrst apply the projection operator then
perform an unconstrained subspace optimization to obtain the solution to (14.54) and (14.55), that is,
max
s


s′P′H′HPs


 .
(14.57)
From (14.53) it is readily apparent that the constrained optimum transmit input satisﬁes
P′H′HPsopt = λmaxsopt.
(14.58)
2.14.5.1.1
Application: pre-nulling on transmit
If there are known AOAs for which it is desired not to transmit (e.g., unwanted targets, clutter discrete,
keep-out zones), it is possible to formulate a linearly constrained optimization accordingly.
Assume that there is a desired target at ¯θT as well as two keep-out angles (normalized) ¯θI1 and ¯θI2.
The corresponding elements of the target transfer matrix HT ∈CN×N, assuming an N-element ULA,
are thus given by
[HT ]m,n = e j2π(m−n) ¯θT ,
(14.59)
where [HT ]m,n denotes the (m,n)th element of the target transfer matrix.

2.14.5 Constrained Optimum Transmit-Receiver Radar
749
*
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
0.5
−90
−80
−70
−60
−50
−40
−30
−20
−10
0
10
Normalized Angle
Magnitude (dB)
*
FIGURE 14.14
Example of a linearly constrained optimization in which two interferers are removed via the projection
optimization approach.
The keep-out constraints have the form
0 = Gs
=
 s′
I1
s′
I2

s,
(14.60)
where
sIk =
⎡
⎢⎢⎢⎢⎣
1
e j2π ¯θIk
...
e j2π(N−1) ¯θIk
⎤
⎥⎥⎥⎥⎦
.
(14.61)
Figure 14.14 shows the resulting constrained optimum transmit pattern for the case where ¯θT = 0,
¯θI1 = −0.25, ¯θI2 = 0.4. As expected a peak is placed in the desired target direction with nulls simulta-
neously placed in the keep-out directions.

750
CHAPTER 14 Optimal Radar Waveform Design
LFM
:
s
s s
opt
S
0i
opt
ˆS
LFM
S
−
{
}
Ω =
<δ
FIGURE 14.15
Illustration of a constrained optimization in which the signal should lie within a subspace (in this case
convex) deﬁned to be close to a prescribed transmit input (in this case an LFM waveform). The optimum
relaxed projection is the point closest to the unconstrained optimum but still residing in the subspace.
2.14.5.2 Case 2: Nonlinear constraints
In practice other generally nonlinear constraints may arise. One family of such constraints relates to
the admissibility of transmit waveforms, such as the class of constant modulus and stepped frequency
waveforms [11], to name but a few.
For example, if it is desired to transmit a waveform that is nominally of the LFM type (or any other
prescribed type) but that is allowed to modestly deviate to better match the channel characteristics, then
the nonlinear constrained optimization has the form
max
s
|s′H′Hs|
(14.62)
subject to: ∥s −sLFM∥≤δ.
(14.63)
The previous and similar problems cannot generally be solved in closed form. However, approxi-
mate methods can yield satisfactory results, and we will consider two that are based on very different
approaches. These simpler methods could form the basis of more complex methods, such as seeding
nonlinear search methods.
2.14.5.2.1
Relaxed projection approach
Figure 14.15 depicts the constrained optimization problem in (14.62) and (14.63). It shows the general
situation in which the unconstrained optimum solution does not reside within the constrained (i.e.,
admissible) subspace . In this particular case, the admissible subspace is a convex set [27], deﬁned as
 = {s : ∥s −sLFM∥≤δ}.
(14.64)
From Figure 14.15 it is also immediately evident that the admissible waveform closest (in a normed
sense) to the unconstrained optimum sopt lies on the surface of  along the direction io, which is the

2.14.5 Constrained Optimum Transmit-Receiver Radar
751
unit norm vector that points from sLFM to sopt, i.e.,
io ≜
sopt −sLFM
∥sopt −sLFM∥.
(14.65)
Thus, the constrained waveform that is closest in norm to sopt is given by
ˆsopt = sLFM + δio.
(14.66)
Note that if δ is allowed to relax to the point where δ = ∥sopt −sLFM∥, then ˆsopt = sopt.
2.14.5.2.2
Application: relaxed projection example
Here an LFM similarity constraint is imposed on the multipath interference problem considered previ-
ously. Speciﬁcally, inFigure14.16, weplot theloss inSINR relativetotheunconstrainedlong-pulseopti-
mum solution previously obtained as a function of δ, which is varied between 0 ≤δ ≤∥sopt −sLFM∥.
Note that for this example improvement generally monotonically increases with increasing δ (except for
a very small region near the origin) and that sizeable SINR improvements can be achieved for relatively
modest values of the relaxation parameter. In other words, a waveform with LFM-like properties can
be constructed that still achieves signiﬁcant SINR performance gains relative to an unoptimized LFM.
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
–5
0
5
10
15
20
25
Normalized Delta
SINR Relative to LFM (dB)
FIGURE 14.16
Illustration of the relaxed projection method for constrained optimization. The plot shows the SINR improve-
ment relative to the unoptimized LFM waveform versus the normalized relaxation parameter δ. Note that for
even a modest relaxation of 20% a nearly 10 dB gain in performance is achieved.

752
CHAPTER 14 Optimal Radar Waveform Design
−20
−15
−10
−5
0
5
10
15
Frequency
Magnitude (dB)
LFM
Unconstrained Optimum
20% Relaxed Projection
−0.5
0
0.5
FIGURE 14.17
Comparison of the pulse spectra for the original LFM, unconstrained optimum, and 20% relaxed projection.
Note how the relaxed pulse retains LFM-like spectral characteristics (and thus enhanced resolution for
example) yet still achieves a 10 dB SINR improvement.
Figure 14.17 shows the spectra of the unoptimized LFM along with the unconstrained optimum and
the relaxed projection pulse with a 20% relaxation parameter. Note how the relaxed pulse is signiﬁcantly
closer to the original LFM spectrum yet still achieves nearly a 10 dB improvement in SINR relative to
the LFM waveform.
2.14.5.2.3
Constant modulus and the method of stationary phase
As has become apparent from the previous examples, spectral shaping plays a key role in achieving
matching gains. The stationary phase method has been applied to the problem of creating a nonlinear
frequencymodulated(NLFM)pulse(andthusconstantmodulusinthesensethatthemodulusofthebase-
band complex envelope is constant, i.e., |s(t)| = constant) with a prescribed magnitude spectrum [3,11].
Speciﬁcally, under fairly general conditions [3,11] it is possible to relate instantaneous frequency
ω of a NLFM waveform to time t [3,11]:
1
2π
ω

−∞
|S(ω)|2 dω = k
t
0
dt = kt,
(14.67)
t ∈[0, T ],

2.14.6 Open Issues and Problems
753
where |S(ω)| is the magnitude spectrum of the optimum pulse. Here we have assumed a constant
modulus for the NLFM waveform resulting in a integral that is simply proportional to time (see [3,11]
for the more general nonconstant modulus case) as well as a ﬁnite and causal pulse.
Solving for ω as a function of t in (14.67) yields the frequency modulation that will result in a
transmit pulse with a magnitude spectrum equal to |S(ω)|, to within numerical and other theoretical
limitations [3,11].
2.14.5.2.4
Application: NLFM to achieve constant modulus
Here we use the method of stationary phase to design a constant modulus NLFM pulse that matches the
magnitude spectrum of the optimum pulse derived for the multipath interference problem previously
considered.
Figure 14.18 shows the numerically obtained solution to (14.67) (i.e., ω versus t) along with the
optimum pulse spectrum (long-pulse case). Note that as one would intuit, the frequency modulation
dwells at frequencies where peaks in the optimum pulse spectrum occur and conversely note the regions
in which the modulation speeds up to avoid frequencies where the optimum pulse spectrum has nulls
or lower energy content.
The constant modulus NLFM waveform so constructed was able to achieve an output SINR that was
within 6.0 dB of optimum compared with a 24 dB loss using an LFM waveform of same energy and
duration.
It is natural to ask if a NLFM waveform with the same spectral magnitude as the optimum pulse (but
not necessarily the same phase) will enjoy some (if not all) of the matching gains. For the steady-state
case (inﬁnite time duration) this is indeed true, since from Parseval’s [3] theorem the output energy is
related to only the spectral magnitudes (i.e., without their phases) of the input pulse and channel transfer
function, that is,
1
2π
∞

−∞
|Y(ω)|2 dω = 1
2π
∞

−∞
|H(ω)|2|S(ω)|2 dω,
(14.68)
where Y(ω), H(ω), and S(ω) denote the Fourier transforms of the channel output, channel impulse
response, and input pulse, respectively. Note that the output energy in (14.68) depends on the spectral
magnitude of the input pulse (steady-state)—not the phase. Thus, in theory an NLFM waveform that
exactly matches the optimum pulse magnitude spectrum will achieve the same matching gains in the
steady-state limit (inﬁnite pulse duration) for all square integrable (ﬁnite norm) functions.
2.14.6 Open issues and problems
Perhaps amongst the foremost challenges is the development of robust and effective adaptive methods
that can accurately estimate the full dimensional transmit-receive channel in real-time and solve for
the optimum transmit-receive conﬁguration—no mean feat. A basic outline of methods that include
traditional sample statistics methods, orthogonal MIMO waveform concepts for channel probing, and
knowledge-aided (KA) methods for leveraging any and all prior and/or externally available channel
information can be found in [22] (and references cited therein).

754
CHAPTER 14 Optimal Radar Waveform Design
−20
−15
−10
−5
0
5
10
15
Frequency
Magnitude (dB)
−0.5
0
0.5
−0.5
0.5 -
-
0.0 -
0.0
|
T
Optimum Pulse Spectrum
t
Instantaneous 
Frequency 
(Normalized)
ω
FIGURE 14.18
Illustration of the use of the method of stationary phase to create a constant modulus NLFM pulse whose
spectral magnitude matches that of the optimum pulse. The NLFM pulse was able to achieve an output
SINR that was within 6.0 dB of the optimum compared with a 24 dB loss using an LFM waveform of same
energy and duration.

2.14.7 Conclusions and Future Trends
755
Even if real-time channel characterization methods can be developed, the issue of solving a generally
constrained multidimensional transmit-receive waveform optimization problem remains. Here again it
is desired to develop a set of efﬁcient and reliable algorithms amenable to real-time implementation.
Fortunately, steady advances in HPEC ensure that ever more increasing real-time compute power should
be available.
2.14.7 Conclusions and future trends
In this chapter, the fundamental theory for joint optimization of the transmit and receive functions was
developed from ﬁrst principles and applied to the maximization of SINR, SCR, and correct classiﬁcation
for the target ID problem. Constrained optimization was introduced to address additional requirements
that often arise in practice, such as the use of constant modulus waveforms to maximize transmitter
efﬁciency. However, many theoretical and practical issues remain before the new ﬁeld of adaptive
transmit technology can be fully exploited.
As mentioned above, many challenges remain in realizing the full potential of joint transmit-receive
optimization. Consequently, much of the current research trends in this area are focused on:
•
Real-time methods for accurate multidimensional channel characterization.
•
Robust and efﬁcient algorithms for solving the generally constrained transmit-receive design
equations.
•
Leveraging of knowledge-aided (KA) methods such as those developed under the DARPA/AFRL
KASSPER project [28,29].
•
Combining other waveform diversity concepts with adaptive transmit-receive optimization to allow
for enhanced multi-functionality.
Glossary
MIMO
A system with multiple inputs and outputs. In radar it refers to multiple transmit
and receive DoFs (usually multiple antennas for example)
SINR
Signal-to-interference-plus-noise ratio. A measure of signal strength relative to
all sources of interference (clutter, jamming, receiver noise, etc.)
Colored Noise
A random (noise) process that has a non-identity matrix covariance matrix (usu-
ally involving non-zero off diagonal terms)
Whitening Filter
The ﬁrst stage in an optimum matched ﬁlter receiver when the additive noise has
some correlation. The ﬁlter “whitens” the noise spectrum, which is then followed
by a standard matched ﬁlter
Cauchy-Schwarz
theorem
In its simplest form, a theorem that states that the dot product of two vectors is
maximum when they are co-linear
Multipath
Electromagnetic propagation through a non-line-of-sight (NLOS) channel
FIR Filter
Finite impulse response ﬁlter. A discrete time LTI tapped delay line ﬁlter
LFM
Linear frequency modulation. A type of radar waveform whose instantaneous
frequency varies linearly with time over a prescribed bandwidth

756
CHAPTER 14 Optimal Radar Waveform Design
Radar Clutter
Radar echo returns from objects other than the desired target(s). Ground reﬂec-
tions is the most common form of clutter
SCR
Signal-to-clutter ratio. A relative measure of signal strength to clutter power
Signal Dependent
Noise
Interference whose statistics depend on the radar’s transmissions
Constant Modulus
Refers to a class of waveforms whose complex envelope (modulation) has a
constant modulus, i.e., |s(t)| = 1
NLFM
Nonlinear FM. A class of constant modulus waveform whose instantaneous fre-
quency changes in a non-linear fashion
Acronyms
Acronyms that are commonly used in this chapter include the following:
ACN
additive colored noise
AESA
active electronically scanned array
AOA
angle-of-arrival
CA-CFAR
cell-averaging constant false alarm ratio
CNR
clutter-to-noise ratio
DOFs
degrees-of-freedom
FIR
ﬁnite impulse response
GMTI
ground moving target indication
KA
knowledge-aided
KASSPER
knowledge-aided sensor signal processing and expert reasoning
LFM
linear frequency modulation
PDF
probability density function
PRF
pulse repetition frequency
Rx
receiver
SAR
synthetic aperture radar
SCR
signal-to-clutter ratio
SINR
signal-to-interference-plus-noise ratio
SNR
signal-to-noise ratio
STAP
space-time adaptive processing
Tx
transmitter
ULA
uniform linear array
Relevant Theory: Signal Processing Theory
See Vol. 1, Chapter 2 Continuous-Time Signals and Systems
See Vol. 1, Chapter 3 Discrete-Time Signals and Systems
See Vol. 1, Chapter 4 Random Signals and Stochastic Processes
See Vol. 1, Chapter 12 Adaptive Filters

References
757
References
[1] J.L. Lawson, G.E. Uhlenbeck, Threshold signals, in: MIT Radiation Laboratory Series, vol. 24, McGraw-Hill,
New York, 1950.
[2] J.R. Guerci, Space-Time Adaptive Processing for Radar, Artech House, Norwood, MA, 2003.
[3] A. Papoulis, Signal Analysis, McGraw-Hill, New York, 1984.
[4] D.K. Barton, Modern Radar System Analysis, Artech House, Norwood, MA, 1988.
[5] A. Papoulis, Circuits and Systems: A Modern Approach, Holt, Rinehart and Winston, New York, 1980.
[6] H.L.V. Trees, Detection, Estimation and Modulation Theory, Part I, Wiley, New York, 1968.
[7] R.A. Horn, C.R. Johnson, Matrix Analysis, Cambridge University Press, Cambridge (England), New York,
1990.
[8] G. Strang, Introduction to Linear Algebra, Wellesley Cambridge Press, 2003.
[9] D.A. Pierre, Optimization Theory With Applications, Courier Dover Publications, 1986.
[10] J.R. Guerci, S.U. Pillai, Theory and application of optimum transmit-receive radar, in: The Record of the
IEEE 2000 International Radar Conference, 2000, pp. 705–710.
[11] C.E. Cook, M. Bernfeld, Radar Signals, Academic Press New York, 1967.
[12] M.A. Richards, Fundamentals of Radar Signal Processing, McGraw-Hill, 2005.
[13] M.J. Lindenfeld, Sparse frequency transmit-and-receive waveform design, IEEE Trans. Aerosp. Electron.
Syst. 40 (2004) 851–861.
[14] S.U. Pillai et al., Optimal transmit-receiver design in the presence of signal-dependent interference and channel
noise, IEEE Trans. Inform. Theory 46 (2000) 577–584.
[15] D.J. Rabideau, Closed loop multistage adaptive beamforming, in: Conference Record of the 33rd Asilomar
Conference on Signals, Systems and Computers, 1999, pp. 98–102.
[16] H.L. Van Trees, E. Detection, Modulation Theory, Part II, John Wiley and Sons, New York, 1971.
[17] H.L.V. Trees, Detection, Estimation, and Modulation Theory: Radar-Sonar Signal Processing and Gaussian
Signals in Noise, Krieger Publishing Co., Inc., 1992.
[18] S. Pillai, C. Burns, Array Signal Processing, Springer-Verlag, New York, 1989.
[19] R.A. Monzingo, T.W. Miller, Introduction to Adaptive Arrays, SciTech Publishing, 2003.
[20] J. Guerci, E. Jaska, ISAT—innovative space-based-radar antenna technology, in: IEEE International Sympo-
sium on Phased Array Systems and Technology, 2003, pp. 45–51.
[21] R. Manasse, The Use of Pulse Coding to Discriminate Against Clutter, vol. AD0260230, Defense Technical
Information Center (DTIC), June 7, 1961.
[22] J.R. Guerci, Cognitive Radar: The Knowledge-Aided Fully Adaptive Approach, Artech House, Norwood,
MA, 2010.
[23] I.A. Ibragimov, On the composition of unimodal distributions, Theory Probab. Appl. 1 (1956) 255.
[24] K.T. Fang, Y.T. Zhang, Generalized Multivariate Analysis, Science Press, Beijing, 1990.
[25] W.Y. Hsiang, On the sphere packing problem and the proof of Kepler’s conjecture, Int. J. Math. 4 (1993)
739–831.
[26] W. Gander et al., A constrained eigenvalue problem, Linear Algebra Appl. 114 (1989) 815–839.
[27] D.C. Youla, H. Webb, Image restoration by the method of convex projections: Part 1. Theory, IEEE Trans.
Med. Imag. 1 (1982) 81–94.
[28] F. Gini, M. Rangaswamy (Eds.), Knowledge Based Radar Detection, Tracking and Classiﬁcation Adaptive
and Learning Systems for Signal Processing, Communications and Control Series, Wiley-IEEE Press, New
York, 2008.
[29] J.R. Guerci, E.J. Baranoski, Knowledge-aided adaptive radar at DARPA: an overview, IEEE Signal Process.
Mag. 23 (2006) 41–50.

15
CHAPTER
Multitarget Multisensor Tracking
X. Chen, R. Tharmarasa, and T. Kirubarajan
ECE Department, McMaster University, Hamilton, Ontario, Canada
3.15.1 Introduction
Multisensor-multitargettrackingisanemergingtechnologyinwhichmeasurementsfromseveralsensors
are combined such that resulting tracks are signiﬁcantly better than that obtained when these devices
operateindividually.Recentadvancesinsensortechnologies,signalprocessingtechniquesandimproved
processor capabilities make it possible for large amounts of data to be fused in real-time. These technical
advancements allow the use of many sophisticated algorithms and robust mathematical techniques in
multisensor-multitarget tracking. Furthermore, multisensor-multitarget tracking has received signiﬁcant
attentionformilitaryapplications.Suchapplicationsinvolveawiderangeofexpertiseincludingﬁltering,
tracking initialization and maintenance, data association, and performance evaluation.
Three major types of architecture, namely, centralized, distributed and decentralized, are commonly
used in multisensor-multitarget tracking applications [9,62,92,126]. In the centralized architecture,
there are several sensors monitoring the region of interest with only one fusion center. All sensors
report their measurements to the fusion center. It is the fusion center’s responsibility to process all
acquired measurements and update the tracks. The single sensor-multitarget tracking problem can be
considered as a special case of the centralized architecture, where only one sensor is deployed to observe
the region of interest. In the distributed multisensor-multitarget tracking architecture, there are several
fusion centers. One of them is the Central Fusion Center (CFC) and the remaining ones are Local
Fusion Centers (LFCs). Measurements generated by the sensors are ﬁrst processed by the LFCs and
local tracks are updated inside each LFC. Then, local tracks from each LFC are reported to the CFC
and the track-to-track fusion is accomplished by the CFC to form the global track set. In decentralized
tracking architecture, each fusion center (FC) can be considered as a combination of LFC and CFC.
Each FC is connected with several sensors and measurements reported by those sensors are used to
update the track state inside the FC. Furthermore, each FC will also do track-to-track fusion whenever
it receives additional information from its neighboring FCs. Usually, without a major modiﬁcation, the
algorithms developed for the distributed tracking architecture can be used to handle the decentralized
tracking architecture. Regardless whether the sensor measurements are processed in the centralized or
the distributed architecture, the data of each sensor has to be converted to a common coordinate system
before multisensor-multitarget tracking, i.e., sensor registration and data alignment [39,54,74].
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-396500-4.00015-6
© 2014 Elsevier Ltd. All rights reserved.
759

760
CHAPTER 15 Multitarget Multisensor Tracking
Filtering plays a vital role in multitarget tracking by obtaining the state estimate from the measure-
ments received from one or more sensors. Tracking ﬁlters [10,31] can be broadly categorized as either
linear or nonlinear. The Kalman ﬁlter [10,53] is a widely known recursive ﬁlter that is most suited for
linear Gaussian systems. However, most systems are inherently nonlinear. The extensions of Kalman
ﬁlter, such as extended Kalman ﬁlter (EKF) [10] and unscented Kalman ﬁlter (UKF) [52,105,128]
are applicable to nonlinear systems. Both EKF and UKF are restricted in that the resulting probability
densities are approximated as Gaussian. When the system is nonlinear and non-Gaussian, particle ﬁlters
(or sequential Monte Carlo methods) [3,33,38,100] provide better estimates than many other ﬁltering
algorithms. In general, a tracking ﬁlter requires a model for target dynamics, and a model mismatch
would diminish the performance of the ﬁlter. Thus, different models may be required to describe the
target dynamics accurately at different times, especially in the case of maneuvering targets, whose
kinematic models may evolve in a time-varying manner. Multiple model tracking algorithms such as
the Interacting Multiple Model (IMM) [1,10,14–16,18] estimator, which contains a bank of models
matched to different modes of possible target dynamics, would perform better in such situations.
Data association [9,13,113] is an essential component in multisensor-multitarget tracking due to the
uncertainty in the data origin. Data association refers to the methodology of correctly associating the
measurements to tracks, measurements to measurements [58,106] or tracks to tracks [2,6,8,9,19,22,
127], depending on the fusion architecture. To address data association, a number of techniques have
been developed and two widely used are single-frame assignment algorithm [11,95] and the multi-frame
assignment algorithm [11,17,27,32,59,63,95].
Many algorithms have been proposed for the single sensor-multitarget tracking problem, such as
the Probability Data Association (PDA) algorithm and the Joint Probability Data Association (JPDA)
algorithm [9], the Multiple Hypotheses Tracking (MHT) algorithm [12], and the Probability Hypothesis
Density (PHD) ﬁlter [78]. In PDA and JPDA algorithms, for each scan the track-to-measurement
association events are enumerated and combined probabilistically, while in the MHT algorithm the
track-to-measurement association history over several scans are enumerated and updated. In PHD ﬁlter,
the track-to-measurement association events are not explicitly constructed. Although these algorithms
are originally proposed to handle the single sensor-multitarget tracking problem, they are also widely
used as the backbone for the multisensor-multitarget tracking.
In many scenarios, after the signal detection process, clutter points provided by the sensor (e.g.,
sonar, infrared sensor, radar) are not distributed uniformly in the surveillance region as assumed by
most tracking algorithms. On the other hand, in order to obtain accurate results, the target tracking ﬁlter
requires information about clutter’s spatial intensity. Thus, nonhomogeneous clutter spatial intensity has
to be estimated from the measurement set and the tracking ﬁlter’s output. Also, in order to take advantage
of existing tracking algorithms, it is desirable for the clutter estimation method to be integrated into the
tracker itself.
Performance evaluation is very important for multisensor-multitarget tracking problem, especially
when the performance of different tracking algorithms needs to be compared. Many measures of per-
formance have been proposed in multisensor-multitarget tracking literatures. These measures can be
divided into two different classes: sensor-related measures and tracker-related measures [40]. Sensor-
related measures are independent of the tracking algorithm, therefore, most of them are not useful for
the performance evaluation of multiple trackers. One exception is the Posterior Cramér-Rao Lower
Bound (PCRLB) of tracking [10,44,46], which provides a minimum bound of any tracking estimation.

3.15.2 Formulation of Multisensor-Multitarget Tracking Problems
761
On the other hand, tracker-related measures have been widely used in the tracker performance evalua-
tion. For general multitarget tracking problem, tracker-related measures have been deﬁned in terms of
cardinality, time and accuracy measures [66,103]. To evaluate a general multitarget tracking problem, a
combination of tracker-related measures should be used, because as shown in [29], it has been observed
that the tracker may have provided inaccurate results while some measures show correct and satisfactory
performances.
In this chapter, various multisensor-multitarget tracking architectures, estimators for spatial clut-
ter intensity, ﬁlters for linear and nonlinear systems, algorithms for data associations and multitarget
tracking, techniques used in centralized and distributed track-to-track fusion are discussed in detail. In
addition,theirquantitativeandqualitativemeritsarediscussed.Variouscombinationsofthesealgorithms
will provide a complete tracking framework for multisensor networks with application to civilian as
well as military problems. For example, the tracking and fusion techniques discussed here are applicable
to ﬁelds like air trafﬁc control, air/ground/maritime surveillance, mobile communication, transporta-
tion, video monitoring and biomedical imaging/signal processing. The tracker performance evaluation,
including its guiding principle and several measures of performance, is also discussed in this chapter. A
challenging scenario with many closely-spaced targets is used to compare several multitarget tracking
algorithms.
3.15.2 Formulation of multisensor-multitarget tracking problems
In a multisensor surveillance systems, several sensors such as radar, infrared (IR), and sonar, report
their measurements to the tracker at regular intervals of time (scans or data frames). However, not all
measurements are originated from the targets of interest; some measurements may come from physical
background objects such as clutter, and others may be generated by thermal noise. In other words, there
is a measurement origin ambiguity. Furthermore, in some scans, the target of interest does not produce
any measurements at all (i.e., the probability of detection is less than unity). The objective of a typical
multisensor-multitarget tracking system is to ﬁrst partition all sensors’ measurements into sets, such
that all observations in one set are produced by the same object (i.e., data-association process); then
the measurements corresponding to the same object are processed in order to estimate the state of the
object (i.e., ﬁltering process) [9,12].
To handle the multisensor-multitarget tracking problem, usually the Bayesian approach is applied.
In the Bayesian approach, the ﬁnal goal is to construct the posterior probability density function (pdf)
of the multitarget state given all the received measurements so far. Since this pdf contains all available
statistical information, it is the complete solution to the multisensor-multitarget tracking problem. In
principle, given a cost function, it is always possible to obtain the optimal estimate under the given
cost function from the posterior probability. Note that, the state of the multitarget system should be a
combination of the number of the targets and the state of each target, because in a real scenario both of
them are random and unknown [78,120].
To distinguish the target-originated measurements from the clutter and estimate the state of the
multitarget system, the following three models, namely, the target dynamic model, the sensor model,
and the clutter model are crucial for all multisensor-multitarget tracking systems.

762
CHAPTER 15 Multitarget Multisensor Tracking
3.15.2.1 Target dynamic models
Target dynamic model, which is also known as system model, describes the evolution of the state with
time, and is given by
x(k + 1) = f (k, x(k)) + G(k)v(k),
(15.1)
where f is, in general, a nonlinear function, x(k) is the state of the target, and v(k) is the process noise,
which is usually assumed to be Gaussian. The covariance of the process noise multiplied by the gain
G(k)v(k) is
Q(k) = G(k)q(k)G(k)′.
(15.2)
The following models are widely used by the multitarget tracker as the target dynamic model: [10]
•
Constant velocity:
The state vector in one generic coordinate is
x = [ ξ
˙ξ ]′.
(15.3)
The F and G in one generic coordinate are
F =
 1
T
0
1

,
(15.4)
G =

T 2/2
T

.
(15.5)
The process noise standard deviation σv is
σv = wv Amax,
(15.6)
where wv is the scaling factor and Amax is the maximum acceleration.
•
Constant acceleration:
The state vector in one generic coordinate is
x = [ ξ
˙ξ
¨ξ ]′.
(15.7)
The F and G in one generic coordinate are
F =
⎡
⎣
1
T
T 2/2
0
1
T
0
0
1
⎤
⎦,
(15.8)
G =
⎡
⎣
T 2/2
T
1
⎤
⎦.
(15.9)
The process noise standard deviation σv is
σv = wv JmaxT ,
(15.10)
where Jmax is the maximum jerk.

3.15.2 Formulation of Multisensor-Multitarget Tracking Problems
763
•
Coordinated turn:
The state vector is
x = [ ξ
˙ξ
η
˙η ω ]′.
(15.11)
The F and G are
F =
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
1
sin (ωT )
ω
0
−(1−cos (ωT ))
ω
0
0
cos (ωT )
0
−sin (ωT )
0
0
(1−cos (ωT ))
ω
1
sin (ωT )
ω
0
0
sin (ωT )
0
cos (ωT )
0
0
0
0
0
1
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
,
(15.12)
G =
⎡
⎢⎢⎢⎢⎢⎢⎣
T 2
2
0
0
T
0
0
0
T 2
2
0
0
T
0
0
0
T
⎤
⎥⎥⎥⎥⎥⎥⎦
.
(15.13)
The process noise standard deviations σvv and σvw are
σvv = wvv Amax,
(15.14)
σvw = wvwTmax,
(15.15)
where wvv and wvw are the scaling factors for velocity and turn rate, respectively, Tmax is the
maximum turn rate change in unit time.
3.15.2.2 Sensor models
Sensor model, which is also known as measurement model, is a model relating the noisy measurements
to the state and given by
z(k) = h(k, x(k)) + w(k),
(15.16)
where h is, in general, nonlinear functions, x(k) is the state of the target, z(k) is the measurement vector,
and w(k) is the measurement noise at measurement time k, which is usually assumed to be Gaussian.
The following measurement models are typical for the multisensor-multitarget tracking system:
•
x-position
h = x.
(15.17)
•
y-position
h = y.
(15.18)
•
z-position
h = z.
(15.19)

764
CHAPTER 15 Multitarget Multisensor Tracking
•
Range, r
h =

(x −xs)2 + (y −ys)2 + (z −zs)2.
(15.20)
For 2D tracking, the terms related to z must be deleted.
•
Range rate, ˙r
h = ((x −xs)˙x + (y −ys) ˙y + (z −zs)˙z)/r.
(15.21)
For 2D tracking, the terms related to z must be deleted.
•
Azimuth, θ
h = atan
 y −ys
x −xs

.
(15.22)
•
Azimuth-north θn
h = atan
x −xs
y −ys

.
(15.23)
•
Elevation γ
h = atan

z −zs

(x −xs)2 + (y −ys)2

.
(15.24)
•
Elevation-vertical, γv
h = atan

(x −xs)2 + (y −ys)2
z −zs

.
(15.25)
•
Bi-static range, rb
h =

(x −xr)2 + (y −yr)2 +

(x −xt)2 + (y −yt)2.
(15.26)
•
Bi-static range rate, ˙rb
h = (x −xr)
Rr
˙x + (y −yr)
Rr
˙y + (x −xt)
Rt
˙x + (y −yt)
Rt
˙y.
(15.27)
In (15.27),
Rr =

(x −xr)2 + (y −yr)2, Rt =

(x −xt)2 + (y −yt)2
3.15.2.3 A clutter model
For a sensor with N resolution cells, sometimes detections will be declared in those cells that are pointed
to a region without any targets of interest. The detection, which is not produced by any targets of interest,
is know as a false alarm (i.e., clutter). Assume:
•
The events of detection in each cell is independent of each other.
•
The probability of false alarm is equal to pFA in each cell and pFA ≪1.
•
The number of the resolution cells is large, such that pFA · N > 1.

3.15.2 Formulation of Multisensor-Multitarget Tracking Problems
765
Then the probability mass function (pmf) of the number of false alarm in these N resolution cells,
μFA(m), is approximately following the Poisson distribution [9]
μFA(m) = exp {−N · pFA}

N · pFA
m
m!
.
(15.28)
Furthermore, the spatial distribution of the false alarm is uniform based on the above three assumptions.
Thus, if the granularity due to the size of the resolution cells can be neglected, the pdf of a false
measurement, i.e., the clutter spatial intensity normalized by the expected number of clutter in the
measurement space, is [9]
¯λFA = p(z|z is a false alarm) = 1
V ,
(15.29)
where V represents the volume of the sensor’s measurement space. The un-normalized clutter spatial
intensity is
λFA = N · pFA
V
.
(15.30)
3.15.2.4 Spatial clutter intensity estimation
Many target tracking algorithms assume that the clutter background is known or at least homogeneous.
However, in real tracking problems, the distribution of clutter is often unknown and spatially non-
homogeneous. Thus, there is usually a mismatch between the true spatial distribution of clutter points
and the spatial distribution model used in the tracking ﬁlter. This mismatch may result in a high false
track acceptance rate or a long delay of track initialization. Therefore, it is desirable for the tracking
ﬁlter to estimate the spatial intensity of clutter from the measurement set. Also, due to the fact that
target-originated measurement points and clutter points are indistinguishable before data association in
the tracker, the output of tracking ﬁlter should also be used in order to get an unbiased estimate of clutter
spatial intensity. Furthermore, estimation methods for clutter spatial distribution should be compatible
with the existing target tracking algorithms, otherwise their application range would be limited.
One way to estimate clutter spatial intensity is to assume that clutter points are uniformly distributed
in the validation gate and then use the sample spatial intensity as the estimate of clutter’s spatial
intensity [9]. However, this method is based on the current measurement set alone and its performance
relies on the volume of validation gate. For example, if the gate is so small that there are only a few
measurements falling in it, the estimate of clutter’s spatial intensity may suffer from a large variance;
on the other hand, if the gate is too large, then the uniform distribution assumption of clutter points
may no longer hold. Also, this estimation method is biased, since it does not take into account target-
originated measurements in the gate. In [67], in order to obtain an unbiased estimator of clutter’s spatial
intensity, “track perceivability,” the probability that the target exists at the current time given all previous
measurement [68], was used to handle target-originated measurements in the current measurement set.
In [43,87], the surveillance region was divided into sectors and clutter points in each sector were
assumed to follow Poisson point processes. Based on the Poisson point processes assumption, three
clutterspatialintensityestimatorswerediscussed:theﬁrstonewasbasedonthenumberofmeasurements
falling in each sector, the second was based on each sector’s nearest neighbor measurement distance,
which is equal to the distance from the center of the sector to its nearest measurement point, while

766
CHAPTER 15 Multitarget Multisensor Tracking
the third was based on the inter-arrival time between two consecutive measurements falling in the
same sector. In all three estimators, after obtaining the clutter intensity estimate based on the current
measurement set, a time-averaging ﬁlter was used to smooth the clutter intensity estimate over time.
In [81,82], it was assumed that there are several unknown targets, called clutter generators, in a space
which is disjoint from both the state space and the measurement space. All clutter points are generated
by the clutter generator and an approximated Bayesian estimation method for the density of the clutter
generator and the clutter is proposed. However, the proposed method is intractable and no practical
implementation method was given in [81,82].
In [23], based on Poisson point processes, two methods for joint non-homogeneous clutter back-
ground estimation and multitarget tracking were presented. In that paper, non-homogeneous Poisson
point processes, whose intensity function are assumed to be a mixture of Gaussian functions, were
used to model clutter points. Based on this model, a recursive maximum likelihood method and an
approximated Bayesian method using Normal-Wishart conjugate prior-posterior pair were proposed to
estimate the non-homogeneous clutter spatial intensity. Both clutter estimation methods were integrated
into the Probability Hypothesis Density (PHD) ﬁlter, which itself also uses the Poisson point process
assumption. The mean and the covariance of each Gaussian function were estimated and used to cal-
culate the clutter density in the update equation of the PHD ﬁlter. Simulation results showed that both
methods were able to improve the performance of the PHD ﬁlter in the presence of slowly time varying
non-homogeneous clutter background.
3.15.3 Filters
Filtering is the estimation of the state of a dynamic system from noisy data, based on the predeﬁned target
dynamic model and the sensor model. In recursive ﬁltering, the received measurements are processed
sequentially rather than as a batch so that it is neither necessary to store the complete measurement set
nor to reprocess existing measurement if a new measurement becomes available. The Bayesian recursive
ﬁlter is widely used in the multisensor-multitarget tracking area and such a ﬁlter consists of two stages:
prediction and update.
The prediction stage uses the system model to predict the state pdf forward from one measurement
time to the next. Suppose that the required pdf p(x(k)|Zk) at measurement time k is available, where
Zk = [z(1), z(2), . . . , z(k)]. The prediction stage involves using the system model (15.1) to obtain the
prior pdf of the state at measurement time k + 1
p(x(k + 1)|Zk) =

p(x(k + 1)|x(k))p(x(k)|Zk)dx(k).
(15.31)
The update stage uses the latest measurement z(k + 1) to update the prior via Bayes’ formula
p(x(k + 1)|Zk+1) = p(z(k + 1)|x(k + 1))p(x(k + 1)|Zk)
p(z(k + 1)|Zk)
.
(15.32)
The above recursive propagation of the posterior density is only a conceptual solution. Analytical
formulas of the posterior density exist only in a restrictive set of cases.

3.15.3 Filters
767
3.15.3.1 Kalman ﬁlter
The Kalman ﬁlter assumes that the state and measurement models are linear, i.e., f (k, x(k)) =
F(k)x(k); h(k, x(k)) = H(k)x(k). Also, in the Kalman ﬁlter, the initial state error and all the noises
entering into the system are assumed to be Gaussian, i.e., ν(k) is white and Gaussian with zero mean
and covariance Q(k), and ω(k) is white and Gaussian with zero mean and covariance R(k). Under the
above assumptions, if p(x(k)|Zk) is Gaussian, it can be proved that p(x(k +1)|Zk+1) is also Gaussian,
which can be parameterized by a mean and covariance [10].
The Kalman ﬁlter algorithm consists of the following recursive relationship [10]:
ˆx(k + 1|k) = F(k)ˆx(k|k),
(15.33)
P(k + 1|k) = F(k)P(k|k)F(k)′ + Q(k),
(15.34)
ˆz(k + 1|k) = H(k + 1)ˆx(k + 1|k),
(15.35)
S(k + 1) = H(k + 1)P(k + 1|k)H(k + 1)′ + R(k + 1),
(15.36)
ˆx(k + 1|k + 1) = ˆx(k + 1|k) + W(k + 1)(z(k + 1) −ˆz(k + 1|k)),
(15.37)
P(k + 1|k + 1) = P(k + 1|k) −W(k + 1)S(k + 1)W(k + 1)′,
(15.38)
where
W(k + 1) = P(k + 1|k)H(k + 1)′S(k + 1)−1.
(15.39)
The Kalman ﬁlter is the optimal solution to the tracking problem if the above assumptions hold
because it provides the posterior probability density of targets state.
3.15.3.2 Extended Kalman ﬁlter (EKF)
While the Kalman ﬁlter assumes linearity, most of the real world problems are nonlinear. The extended
Kalman ﬁlter is a suboptimal state estimation algorithm for nonlinear systems. In EKF, local lineariza-
tions of the equations are used to describe the nonlinearity,
F(k) = d f (k)
dx

x=ˆx(k|k)
,
(15.40)

H(k) = dh(k + 1)
dx

x=ˆx(k+1|k)
.
(15.41)
The EKF assumes that p(x(k)|Zk) can be approximated by a Gaussian. Then the equations of the
Kalman ﬁlter can be used with this approximation and the linearized functions, except the state and
measurement prediction are performed using the original nonlinear functions
ˆx(k + 1|k) = f (k, ˆx(k|k)),
(15.42)
ˆz(k + 1|k) = h(k + 1, ˆx(k + 1|k)).
(15.43)
The above is a ﬁrst-order EKF based on the ﬁrst-order series expansion of the nonlinearities. There
are several error reduction methods to improve the performance of the EKF [10]. One of them is
using the second-order series expansion of the nonlinearities, i.e., higher-order EKFs, but the additional

768
CHAPTER 15 Multitarget Multisensor Tracking
complexity and little or no beneﬁt has prohibited its widespread use. For continuous-time nonlinear
systems, numerical integration on the continuous-time stochastic differential equation of the state from
k to k + 1 can be used to obtain a better predicted state. The third approach to improve the EKF is using
an iteration to compute the updated state as a maximum a posterior (MAP) estimate, rather than an
approximate conditional mean. This type of EKF is called the Iterated extended Kalman ﬁlter (IEKF).
The iteration used by the IEKF amounts to relinearize the measurement equation around the updated
state rather than relying only on the predicted state. If the measurement model fully observes the state,
then the IEKF is able to handle the non-linear measurement model better than the EKF [61].
3.15.3.3 Unscented Kalman ﬁlter (UKF)
When the state transition and observation models are highly nonlinear, the EKF may perform poorly.
The unscented Kalman ﬁlter does not approximate the nonlinear functions of state and measurement
models as required by the EKF. Instead, the UKF uses a deterministic sampling technique known as the
unscented transform to pick a minimal set of sample points called sigma points around the mean. Here,
the propagated mean and covariance are calculated from the transformed samples [52]. In some UKF
implementations, the state random variable is augmented as the concatenation of the original state and
noise variables [123]. The steps of UKF are described below.
3.15.3.3.1
Sigma point generation
The state vector ˆx(k) with mean ˆx(k|k) and covariance P(k|k) is approximated by 2n + 1 weighted
sigma points, where n is the dimension of the state vector, as
χ0(k|k) = ˆx(k|k),
w0 =
κ
(n + κ),
(15.44)
χi(k|k) = ˆx(k|k) +

(n + κ)P(k|k)

i ,
wi =
1
2(n + κ),
(15.45)
χi+n(k|k) = ˆx(k|k) −

(n + κ)P(k|k)

i ,
wi+n =
1
2(n + κ),
(15.46)
where wi is the weight associated with the ith point, κ is a scaling parameter, i = 1, 2, . . . , n, and
(√(n + κ)P(k|k))i is the ith row or column of the matrix square root of (n + κ)P(k|k).
3.15.3.3.2
Recursion
1. Find the predicted target state ˆx(k + 1|k) and corresponding covariance P(k + 1|k):
a. Transform the Sigma points using the system model
χi(k + 1|k) = f (k, χi(k|k)).
(15.47)
b. Find the predicted mean
ˆx(k + 1|k) =
2n

i=0
wiχi(k + 1|k).
(15.48)

3.15.3 Filters
769
c. Find the predicted covariance
P(k + 1|k) = Q(k) +
2n

i=0
wi[χi(k + 1|k) −ˆx(k + 1|k)][χi(k + 1|k) −ˆx(k + 1|k)]′.
(15.49)
2. Find the predicted measurement ˆz(k + 1|k) and the corresponding covariance S(k + 1):
a. Regenerate the Sigma points χi(k + 1|k) using the mean ˆx(k + 1|k) and covariance P(k + 1|k)
in order to incorporate the effect of Q(k). If Q(k) is zero, the resulting χi(k + 1|k) will be the
same as in (15.47). If the process noise is correlated with the state, then the noise vector must
be stacked with the state vector ˆx(k|k) before generating the sigma points [52].
b. Find the predicted measurement mean ˆz(k + 1|k)
ˆz(k + 1|k) =
2n

i=0
wiϕi(k + 1|k),
(15.50)
where
ϕi(k + 1|k) = h(k, χi(k + 1|k)).
(15.51)
c. Find the innovation covariance S(k + 1) and gain W(k + 1)
S(k + 1) = R(k + 1) +
2n

i=0
wi[ϕi(k + 1|k) −ˆz(k + 1|k)][ϕi(k + 1|k) −ˆz(k + 1|k)]′,
W(k + 1) =
2n

i=0
wi[χi(k + 1|k) −ˆx(k + 1|k)][ϕi(k + 1|k) −ˆz(k + 1|k)]′S(k + 1)−1.
(15.52)
3. Update the state ˆx(k + 1|k + 1) and corresponding covariance P(k + 1|k + 1) using (15.37) and
(15.38), respectively.
3.15.3.4 Particle ﬁlter
If the true density is substantially non-Gaussian, then a Gaussian model as in the case of the Kalman ﬁlter
will not yield accurate estimates. In such cases, particle ﬁlters will yield an improvement in performance
in comparison to the EKF or UKF. The particle ﬁlter provides a mechanism for representing the density,
p(x(k)|Zk) of the state vector x(k) at time epoch k as a set of random samples {x p(k) : p = 1, . . . , m},
with associated weights {w p(k) : p = 1, . . . , m}. That is, the particle ﬁlter attempts to represent an
arbitrary density function using a ﬁnite number of points, instead of a pair of mean vector and covariance
matrix that is sufﬁcient for Gaussian distributions. Several variations of particle ﬁlters are available and
the reader is referred to [3] for detailed description. The Sampling Importance Resampling (SIR) type
particle ﬁlter, which is arguably the most common technique to implement particle ﬁlters, is discussed
below. In general, the particles are sampled either from the prior density or likelihood function. Taking

770
CHAPTER 15 Multitarget Multisensor Tracking
the prior as the importance density, the method of SIR is used to produce a set of equally weighted
particles that approximates p(x(k)|Zk), i.e.,
p(x(k)|Zk) ≈1
m
m

p=1
δ(x(k) −x p(k)),
(15.53)
where δ(·) is the Dirac Delta function. The prediction and update steps of the particle ﬁlter recursion
are given below.
Prediction: Take each existing sample, x p(k) and generate a sample x∗p(k + 1) ∼p(x(k + 1)|x p(k)),
using the system model. The set {x∗p(k + 1) : p = 1, . . . , m} provides an approximation of the prior,
p(x(k + 1)|Zk), at time k + 1.
Update: At each measurement epoch, to account for the fact that the samples, x∗p(k + 1) are not drawn
from p(x(k + 1)|Zk+1), the weights are modiﬁed using the principle of importance sampling. When
using the prior as the importance density, it can be shown that the weights are given by
w p(k + 1) ∝p(z(k + 1)|x(k + 1) = x∗p(k + 1), Zk).
(15.54)
A common problem with the above recursion is the degeneracy phenomenon, whereby the particle
set quickly collapses to just a single particle. To overcome this problem a regularization can be imposed
via reselection as follows.
Reselection: Resample (with replacement) from {x∗p(k + 1) : p = 1, . . . , m}, using the weights,
{w∗p(k + 1) : p = 1, . . . , m}, to generate a new sample, {x p(k + 1) : p = 1, . . . , m}, then set
w p(k + 1) = 1/m for p = 1, . . . , m.
The mean of the posterior distribution is used to estimate, x(k +1|k +1) of the target state, x(k +1),
i.e.,
ˆxk+1 ≈1
m
m

p=1
x p(k + 1).
(15.55)
The accuracy of the particle ﬁlter based estimate (15.53) depends on the number of particles employed.
A more accurate state estimates can be obtained at the expense of extra computation. The extension of
particle ﬁlters allows them to be applicable to multitarget tracking problems [60].
3.15.3.5 Interacting multiple-model estimator
Tracking maneuvering targets is a very important task for almost all practical systems. Several schemes
and methods have been proposed to track maneuvering targets [69–73]. One of widely used method
is the Multiple Mode (MM) approach [10]. In MM approach, the target system is assumed to follow
one of predetermined models (or mods) and a number of ﬁlters operate in parallel. Thus, the system
has both continuous uncertainties brought by the noise, and discrete uncertainties brought by the model
uncertainty. Starting from the prior distribution of the target state and the prior probability that the
system is in a particular mode, the goal of the MM approach is to obtain the posterior distribution of
the target state and posterior mode probability.
Depending on whether mode jumping is allowed, there are static MM estimator and dynamic MM
estimator. In static MM algorithms, it is assumed that there is no model switching from one mode to
another during the whole estimation process and this assumption is not realistic for many real scenarios.

3.15.3 Filters
771
On the other hand, in dynamic MM algorithms, the target is allowed to switch from one mode to another
according to a Markov chain. Optimal dynamic MM estimator is infeasible since it needs to carry
all the mode sequence hypotheses and the total number of the mode sequence hypotheses increases
exponentially with time. To get a feasible dynamic MM suboptimal estimator, the mode sequences that
only differ in “older” modes are combined and the mode sequences are kept to depth n in the Generalized
Pseudo-Bayesian (GPB) approaches [9,10]. A GPB algorithm of depth n (GPBn) requires N n
r ﬁlters in
its bank, where Nr is the number of models.
The Interacting Multiple Model (IMM) estimator [9,10,15,16], which mixes the mode sequence
hypotheses with depth 1 at the beginning of each ﬁltering cycle, requires only Nr number of ﬁlters to
operate in parallel, (i.e., same as GBP1 estimator) but is able to perform nearly as well as GPB2. Thus, the
IMM estimator is very cost-efﬁcient. The main contributor for the cost-efﬁciency of the IMM estimator
is the “mixing/interaction" between its “mode-matched" base state ﬁltering modules at the beginning
of each cycle. It has been shown in [7], the same feature is exactly what the IMM has in common with
the optimal estimator for dynamic MM systems. Besides its cost-efﬁciency, another advantage of the
IMM estimator is that it does not require maneuver detection decision as in the case of Variable State
Dimension (VSD) ﬁlter [10] algorithms and undergoes a soft switching between models based on the
updated mode probabilities.
3.15.3.5.1
Modeling assumptions in dynamic multiple model approach
Base state model:
x(k) = f (k, M(k), x(k −1)) + G(k, M(k))v(k),
(15.56)
z(k) = h(k, M(k), x(k)) + w(k, M(k)),
(15.57)
where M(k) denotes the mode in effect during the sampling period ending at k.
Mode (“model state”)—among the possible r modes:
M(k) ∈{M j}r
j=1.
(15.58)
The structure of the system and/or the statistics of the noises can differ from mode to mode:
f (M j) = f j,
(15.59)
G(k, M(k))v(k) ∼N(u j, Q j).
(15.60)
Mode jump process: Markov chain with known transition probabilities
P{M(k) = M j|M(k −1) = Mi} = pi j.
(15.61)
3.15.3.5.2
The IMM estimation algorithm
•
Interaction: Mixing of the previous cycle mode-conditioned state estimates and covariance, using
the mixing probabilities μi| j, to initialize the current cycle of each mode-conditioned ﬁlter. For ﬁlter
j, there is:

772
CHAPTER 15 Multitarget Multisensor Tracking
ˆx0 j(k −1|k −1) =
r

i=1
ˆxi(k −1|k −1)μi| j(k −1|k −1),
(15.62)
P0 j(k −1|k −1) =
r

i=1
μi| j(k −1|k −1){Pi(k −1|k −1)
+ [ˆxi(k −1|k −1) −ˆx0 j(k −1|k −1)]
· [ˆxi(k −1|k −1) −ˆx0 j(k −1|k −1)]′},
(15.63)
where
μi| j = 1
¯c j
pi jμi(k −1),
(15.64)
¯c j =
r

i=1
pi jμi(k −1),
(15.65)
•
Mode-conditioned ﬁltering: Calculation of the state estimates and covariances conditioned on a
mode being in effect. The KF matched to M j(k) (ﬁlter j) uses z(k) to yield ˆx j(k|k) and P j(k|k).
Likelihood function corresponding to ﬁlter j is  j(k) = N[z(k); ˆz j(k|k −1), Sj(k)].
•
Probability evaluation: Computation of the mixing and the updated mode probabilities. For the
mode probabilities of the jth mode ( j = 1, . . . ,r)
μ j(k) = 1
c  j(k)¯c j,
(15.66)
c =
r

j=1
 j(k)¯c j.
(15.67)
•
Overall state estimate and covariance (for output only): Combination of the latest mode-conditioned
state estimates and covariances
ˆx(k|k) =
r

j=1
ˆx j(k|k)μ j(k),
(15.68)
P(k|k) =
r

j=1
μ j(k){P j(k|k) + [ˆx j(k|k) −ˆx(k|k)][ˆx j(k|k) −ˆx(k|k)]′}.
(15.69)
The IMM estimation algorithm has a modular structure.
Fornon-maneuveringtargets,unnecessarilyusingmultiple-modelalgorithmsisnotoptimalbecause
it might diminish the performance level of the tracker and increase the computational load. A multiple-
model approach is only necessary for targets with high maneuverability. Typically, the decision to
use a multiple-model estimator should be based on the maneuvering index [10], which quantiﬁes the
maneuverability of the target in terms of the process noise, sensor measurement noise and sensor revisit
interval. In [56], a study was presented to compare the IMM estimator with the Kalman ﬁlter based on
the maneuvering index.

3.15.4 Filter Initialization
773
3.15.4 Filter initialization
Track initiation is an essential component of all tracking algorithms. Two major types of initialization
techniques, namely, the Single-Point (SP) method and the Two-Point-Difference (TPD) method, are
commonly used in multisensor-multitarget tracking applications [9,10,84].
3.15.4.1 Single-point track initialization
In SP track initialization, every detection (measurement), which is unassociated to any track, is an
“initiator.” The unassociated measurement is ﬁrst converted into Cartesian space through the unbiased
conversion method [10] and then a tentative track is declared. In SP algorithm, the position component
of the tentative track is initialized using the position component of the converted measurement and the
velocity components is set to zero. To compensate the zero velocity assumption made for the tentative
track, when initializing the covariance matrix of the tentative track, the maximum possible speed of the
target is often used as the standard deviation of the velocity component of the tentative track. For the
position component, the variance of the converted measurement is used. Furthermore, for the newly
declared tentative track, its velocity and position along different coordinates are usually assumed to be
independent. A Kalman ﬁlter is then used for subsequent processing of the tentative track.
3.15.4.2 Two-point difference track initialization
In TPD track initialization, every unassociated detection (measurement) is also an “initiator,” but does
not immediately yield a tentative track. At the sampling time (scan or frame) following the detection of an
initiator, a gate is set up around the initiator based on the assumed maximum and minimum target speed
as well as the measurement noise intensities. Thus, it is reasonable to assume that if the initiator is from a
target, then the measurement from that target in the second scan (if detected) will fall inside the gate with
nearly unity probability. A tentative track will be declared only if there is at least one detection falling
in the gate. Since now each tentative track has two measurements, a straight line extrapolation is used to
obtain its speed and the covariance matrix. A Kalman ﬁlter is then used for the subsequent processing.
3.15.4.3 Issues related to track initialization
It has been demonstrated numerically that the SP method has a smaller mean square error matrix than
the TPD method for a 3D radar target tracking problem. Also, it has been analytically shown that, if
the process noise approaches zero and the maximum speed of a target used to initialize the velocity
variance approaches inﬁnity, then the SP algorithm reduces to the TPD algorithm [84].
In many multi-sensor multitarget tracking algorithms, the track initialization and the track main-
tenance phases are treated as two independent (and consecutive) stages. However, in a real tracking
problems, targets can enter and leave the surveillance region at any time. As a result, track initia-
tion has to be considered at every sampling time. That is, track initialization occurs even after the
ﬁrst few scan. Similarly, the fact that track maintenance stage has been activated does not obvi-
ate the need for further track initiations. Both have to be carried out simultaneously throughout the
entire tracking interval. Because of this, the track initialization module needs to take into account the

774
CHAPTER 15 Multitarget Multisensor Tracking
number, states and qualities of the established tracks being retained by the track maintenance mod-
ule. Otherwise, spurious tracks and track seduction will ensue, damaging the overall quality of the
tracker [42].
3.15.5 Data association
InSection3.15.3,ithasbeenimplicitlyassumedthatthereisnomeasurementoriginambiguity.However,
thecruxofthemultitargetproblemistocarryouttheassociationprocessformeasurementswhoseorigins
are uncertain due to
•
random false alarms in the detection process,
•
clutter due to spurious reﬂectors or radiators near the target of interest,
•
interfering targets,
•
decoys and countermeasures.
Furthermore,theprobabilityofobtainingameasurementfromatarget—thetargetdetectionprobability—
is usually less than unity.
Dataassociationproblemsmaybecategorizedaccordingtothepairsofinformationthatareassociated
together:
•
measurement-to-track association—track maintenance or updating,
•
measurement-to-measurement association—parallel updating for centralized tracking,
•
track-to-track association—track fusion (for distributed or decentralized tracking).
In this subsection, measurement-to-track association and measurement-to-measurement association
techniques are discussed. The track-to-track association is discussed in Section 3.15.9.
3.15.5.0.1
Measurement-to-track association
A multidimensional gate is set up in the measurement space around the predicted measurement in order
to avoid searching for the measurement from the target of interest in the entire measurement space. A
measurement in the gate, while not guaranteed to have originated from the target the gate pertains to,
is a valid association candidate. Thus the name validation region or association region. If there is more
than one measurement in the gate, this leads to an association uncertainty.
Figure 15.1a and b illustrates the gating for two well-separated and closely-spaced targets respec-
tively. In the ﬁgures, “•” indicates the expected measurement and the “∗” indicates the received mea-
surement.
If the true measurement conditioned on the past is normally (Gaussian) distributed with its probability
density function given by
p(z(k + 1)|Zk) = N[z(k + 1); ˆz(k + 1|k), S(k + 1)],
(15.70)
then the true measurement will be in the following region:
V(k + 1, γ ) = {z : [z −ˆz(k + 1|k)]′S(k + 1)−1[z −ˆz(k + 1|k)] < γ }
(15.71)
with probability determined by the gate threshold γ . The region deﬁned by (15.71) is called gate or
validation region.

3.15.5 Data Association
775
•
•
*
*
*
*
*
*
z1
z3
z6
z7
z5
z4
2
ˆz
1ˆz
*
*
*
*
z2
z8
z9
z10
(a)
(b)
•
•
*
*
*
*
*
*
*
z1
z3
z6
z7
z5
z2
z4
2
ˆz
1ˆz
FIGURE 15.1
Validation regions. (a) Well-separated targets. (b) Closely-spaced targets.
Some well-known approaches for data association in the presence of well-separated targets, where
no measurement origin uncertainties exist are discussed below.
Nearest Neighbor (NN): This is the simplest possible approach and uses the measurement nearest to
the predicted measurement, assuming that the nearest one is the correct one. The nearest measurement
to the predicted measurement is determined according to the distance measure (norm of the innovation
squared),
D(z) = [z −ˆz(k + 1|k)]′S(k + 1)−1[z −ˆz(k + 1|k)].
(15.72)
Strongest Neighbor (SN): Select the strongest measurement (in terms of signal intensity) among the
validated ones—this assumes that signal intensity information is available.
2-D Assignment: This technique is also known as the Global Nearest Neighbor (GNN) method. The
fundamental idea behind 2-D assignment is that the measurements from the scan list M(k) at time k
are deemed to have come from the tracks in list T (k −1) at time k −1. To ﬁnd the best match between
M(k) and T (k −1), a constrained global optimization problem has to be solved. The optimization is
carried out to minimize the “cost” of associating the measurements in M(k) to tracks predicted from
T (k −1).
To present the 2-D assignment, deﬁne a binary assignment variable a(k, m, n) such that
a(k, m, n) =
1 measurement zm(tmk) is assigned to track T n(k −1),
0 otherwise,
(15.73)
where tmk is the time stamp of the mth measurement from scan or frame k.
A set of complete assignments, which consists of the associations of all the measurements in M(k)
and the tracks in T (k −1), is denoted by a(k), i.e.,
a(k) = {a(k, m, n); m = 0, 1, . . . , M(k); n = 0, 1, . . . , N(k −1)},
(15.74)
where M(k) and N(k −1) are the cardinalities of the measurement and track sets, respectively. The
indices m = 0 and n = 0 correspond to the non-existent (or “dummy”) measurement and track.

776
CHAPTER 15 Multitarget Multisensor Tracking
The “dummy” notation is used to formulate the assignment problem in a uniform manner, where the
non-association possibilities are also considered, making it computer-solvable.
The objective of the assignment is to ﬁnd the optimal assignment a∗(k), which minimizes the global
cost of association
C(k|a(k)) =
M(k)

m=0
N(k−1)

n=0
a(k, m, n) c(k, m, n),
(15.75)
where c(k, m, n) is the cost of the assignment a(k, m, n). That is,
a∗(k) = arg min
a(k) C(k|a(k)).
(15.76)
The costs c(k, m, n) are the negative of the logarithm of the dimensionless likelihood ratio of the
measurement-to-track associations, namely,
c(k, m, n) = −ln (k, m, n),
(15.77)
where
(k, m, n) =
⎧
⎨
⎩
PD p

νn
m(tmk)

/λe
m > 0, n > 0,
1
m > 0, n = 0,
(1 −PD)
m = 0, n > 0
(15.78)
are the following likelihood ratios:
1. that measurement m > 0 came from track n for n > 0 with the association likelihood function
being the probability density function of the corresponding innovation, p

νn
m(k)

versus from an
extraneous source whose spatial density is λe,
2. that measurement m > 0 came from none of the tracks (i.e., from the dummy track n = 0) versus
from an extraneous source. Note that, if measurement m > 0 came from none of the tracks, then
that measurement must be generated by an extraneous source, Thus, the likelihood ratio must be
unity in this case,
3. that the measurement from track n is not in M(k), i.e., track n is associated with the dummy
measurement—thecostofnotassociatinganymeasurementtoatrackamountstothemissprobability
1 −PD, where the nominal target detection probability is denoted by PD.
The 2-D assignment is subject to the following constraints.
Validation: A measurement is assigned only to one of the tracks that validated it.
One-to-one constraint: Each track is assigned at most one measurement. The only exception is the
dummy track (n = 0), which can be associated with any number of measurements. Similarly, a mea-
surement is assigned to at most one track. The dummy measurement (m = 0) can be assigned to multiple
tracks.
Non-empty association: The association cannot be empty, i.e., the dummy measurement cannot be
assigned to the dummy track.
The modiﬁed auction algorithm can solve the above constrained optimization problem and that
algorithm runs in quasi-polynomial time [94,95].
Multidimensional (S-D) Assignments: In 2-D assignment only the latest scan is used and information
about target evolution through multiple scans is lost. Also it is not possible to change an association later

3.15.5 Data Association
777
in light of subsequent measurements. A data-association algorithm may perform better when a number
of past scans are utilized. This corresponds to multidimensional assignment for data association. In S-D
assignment the latest S −1 scans of measurements are associated with the established track list (from
time k −S + 1, where k is the current time, i.e., with a sliding window of time depth S −1) in order to
update the tracks.
Similarly to the 2-D assignment, deﬁne a binary assignment variable a

k, {ms}k
s=k−S+2 , n

such that
a(k, {ms}k
s=k−S+2, n) =
⎧
⎨
⎩
1 measurements zmk−S+2(tmk−S+2), . . . , zmk(tmk) are assigned
to track T n(k −S + 1),
0 otherwise,
,(15.79)
which is the general version of (15.73). The cost associated with (15.79) is denoted as
c(k, {ms}k
s=k−S+2, n) = −ln (k, {ms}k
s=k−S+2, n)
(15.80)
and (k, {ms}k
s=k−S+2, n) is the likelihood ratio that the S-1-tuple of measurements, which is given by
zmk−S+2(tmk−S+2), . . . , zmk(tmk), originated from the target represented by track T n(k −S + 1) versus
some measurements zmk−S+2(tmk−S+2), . . . , zmk(tmk) being extraneous.
The objective of the S-D assignment is to ﬁnd the S-tuples of measurement-to-track associations
a

k, {ms}S−1
s=1 , n

, which minimize the global cost of association given by
C(k|a) =
N(k−S+1)

n=0
M(k−S+2)

mk−S+2=0
M(k−S+3)

mk−S+3=0
· · ·
M(k)

mk=0
a

k, {ms}k
s=k−S+2, n) c(k, {ms}k
s=k−S+2, n

,
(15.81)
where M(k) is the number of measurements in scan k and a is the complete set of associations analogous
to that deﬁned in (15.74) for the 2-D assignment. The association likelihoods are given by


k, {ms}k
s=k−S+2 , n

=
 k
s=k−S+2

1 −PD
1−u(ms) 
PD p

νn
ms(s)

λe
u(ms)
n > 0,
1
n = 0,
(15.82)
where u(m) is a binary function such that
u(m) =
1 m > 0,
0 m = 0,
(15.83)
and p

νn
ms(s)

is the ﬁlter-calculated innovation pdf if the (kinematic) measurement zms(tms ) is asso-
ciated with track T n(k −S + 1) continued with the (kinematic) measurements zmk−S+2(tmk−S+2), . . . ,
zmk(tmk).
The association costs are given to the generalized S-D assignment algorithm, which uses Lagrangian
relaxation, as described in [32,95] to solve the assignment problem in quasi-polynomial time.
The feasibility constraints are similar to those from the 2-D assignment.

778
CHAPTER 15 Multitarget Multisensor Tracking
3.15.5.0.2
Measurement-to-measurement association
Measurement-to-measurement association is the most important step in the parallel updating scheme
for the centralized tracking. Without any major modiﬁcation, multidimensional (S-D) Assignments and
2-D Assignment technique are commonly used for measurement-to-measurement association. A good
example of using S-D assignment technique to solve the measurement-to-measurement association
problem in a multisensor-multitarget tracking problem is given in [9].
3.15.6 Multitarget tracking algorithms
Three widely used multitarget tracking algorithms, namely, the Probabilistic Data Association (PDA)
and Joint Probabilistic Data Association (JPDA) algorithm, the Multiple Hypothesis Tracker (MHT)
algorithm, and the Probability Hypothesis Density (PHD) algorithm, are discussed in this section.
3.15.6.1 Probabilistic data association (PDA) and joint probabilistic data
association (JPDA)
PDA algorithm is a Bayesian approach that probabilistically associates all the validated measurements
to the target of interest [9]. The state update equation of the PDA ﬁlter is
ˆx(k|k) = ˆx(k|k −1) + W(k)ν(k),
(15.84)
where
ν(k) =
m(k)

i=1
βi(k)νi(k),
(15.85)
νi(k) =

zi(k) −ˆz(k|k −1)

,
(15.86)
m(k) is the number of validated measurements and
βi(k) = {θi(k)|Zk}
(15.87)
is the conditional probability of the event that the ith validated measurement is correct.
The covariance associated with the updated state is
P(k|k) = β0(k)P(k|k −1) + [1 −β0(k)]Pc(k|k) +  P(k),
(15.88)
where β0(k) is the conditional probability of the event that none of the measurements is correct and the
covariance of the state updated with the correct measurement is
Pc(k|k) = P(k|k −1) −W(k)S(k)W(k)′
(15.89)
In equation (15.89), the gain matrix W(k) and the innovation matrix S(k) are calculated using the
standard Kalman ﬁlter equation (15.36), (15.39). The spread of the innovations term in (15.88) is
 P(k) = W(k)
⎡
⎣
m(k)

i=1
βi(k)νi(k)νi(k)′ −ν(k)ν(k)′
⎤
⎦W(k)′.
(15.90)

3.15.6 Multitarget Tracking Algorithms
779
The association of measurements in a multitarget environment with closely-spaced targets must be
done while simultaneously considering all the targets. Thus, the Joint Probabilistic Data Association
(JPDA) is proposed as an extension of the PDA method to handle the scenario with closely-spaced
targets [9]. For a known number of targets, JPDA evaluates the measurement-to-target association
events probabilities (for the latest set of measurements) and combines them into the corresponding state
estimates.
The JPDA algorithm includes the following steps:
•
A validation matrix that indicates all the possible sources of each measurement is set up.
•
From the validation matrix, all the feasible joint association events are constructed by the JPDA
tracker according to the following two rules:
• One measurement must be originated from one target or a false alarm.
• One target can only generate one measurement at most.
•
The probabilities of these joint events are evaluated according to the following assumptions:
• Target-originated measurements are Gaussian distributed around the predicted location of the
corresponding target’s measurement.
• False alarms are distributed in the surveillance region according to a Poisson point process model.
•
Marginal (individual measurement-to-target) association probabilities are obtained from the joint
association probabilities.
•
The target states are estimated by separate (uncoupled) PDA ﬁlters using these marginal probabilities.
An extension of the PDA algorithm, the Integrated Probabilistic Data Association (IPDA) algorithm
is proposed in [85]. The main idea behind IPDA tracker is to introduce the track existence probability,
a measure of the quality of the track, to the PDA algorithm. Like PDA tracker, IPDA track can only be
used to track well-separated targets in clutter. To handle the multitarget environment with closely-spaced
targets, the Joint Integrated Probabilistic Data Association (JIPDA) tracker is proposed in [86], which
is actually a JPDA with the track existence probability.
3.15.6.2 Multiple Hypothesis Tracker (MHT)
Multiple Hypothesis Tracking (MHT) is an efﬁcient algorithm for tracking multitargets in a cluttered
environment. The algorithm is capable of initiating tracks, accounting false or missing reports, and
processing sets of dependent reports. As each measurement is received, probabilities are calculated for
the hypotheses that the measurement came from previously existing target, or from a new target, or that
the measurement is a false alarm. Target states are estimated from each such data-association hypothesis
with a certain ﬁlter (e.g., Kalman Filter). As more measurements are received, the probabilities of joint
hypotheses are calculated recursively using all available information such as the density of unknown
target λN, the density of false targets λFA and the probability of detection PD. This branching technique
allows the correlation of a measurement with its source based on subsequent, as well as previous, data.
To keep the number of hypotheses reasonable, unlikely hypotheses are eliminated and hypotheses with
similar target estimates are combined. To minimize computational requirements, clustering and pruning
techniques are embedded in the MHT tracker. Note that MHT strictly follows the one-to-one assumption

780
CHAPTER 15 Multitarget Multisensor Tracking
between measurements and targets. There are two types of implementation for MHT, the hypothesis-
oriented MHT (HOMHT), which is also known as the measurement-oriented MHT (MOMHT), and the
track-oriented MHT (TOMHT).
3.15.6.2.1
Hypothesis-oriented MHT (HOMHT)
In HOMHT, hypotheses are composed of sets of compatible tracks. Multiple tracks are compatible
if they have no measurement in common. At every scan, each hypothesis carried over from the pre-
vious scan (i.e., parent hypothesis) is expanded into a set of new hypotheses (i.e., offspring hypoth-
esis) by considering all possible track-to-measurement associations for the tracks within the parent
hypothesis [9]. The HOMHT includes the following steps:
•
Initialization: The measurements received at the ﬁrst scan {z1(1), z2(1), . . . , zm(1)(1)} have two pos-
sible origination: (1) new target with probability
λN
λN +λFA ; (2) false alarm with probability
λFA
λN +λFA .
Therefore, the total number of possible hypotheses is 2m(1) where m(k) is the number of measure-
ments received at scan k. The probability of each hypothesis is proportional to
P(H j(1)|Z(1)) = λn
N · λ f
FA,
(15.91)
where n and f denote the number of measurements that are assigned as new targets and the number
of measurements that are assigned as false alarms give the jth valid hypothesis H j(1). Then, select
the top K hypotheses based on their probabilities P(H j(1)|Z(1)). These K hypotheses {H j(1)}K
j=1
are parent hypotheses for the next scan, and their probabilities are normalized at the end of this scan.
•
Update of hypotheses: In this step, every parent hypothesis will be used to generate a set of offspring
hypotheses. The collection of all the offspring hypotheses forms the current set of hypotheses. Then,
top K hypotheses will be selected from the current set of hypotheses, and their probabilities will be
normalized.
•
Prune hypotheses: It is infeasible to keep all the hypotheses because the number of hypotheses
grows exponentially. Several pruning techniques are embedded to the HOMHT tracker to maintain
the number of hypotheses in a suitable level. The ﬁrst pruning method removes hypothesis whose
probability is less than a predeﬁned threshold β. The second pruning method keeps only the top K
hypotheses with the greatest probabilities. The third method discards the set of hypotheses with the
smallest probabilities such that the total probability of discarded hypotheses does not exceed a user
deﬁned threshold γ . For example, the probabilities of all the current hypotheses are [p1, p2, . . . , pn].
Assume that p1 ≥p2 ≥· · · ≥pn and !n
i=1 pi = 1. Then, the third method removes the ( j + 1)th
to nth hypotheses where ! j
i=1 pi ≥(1 −γ ) and ! j−1
i=1 pi < (1 −γ ).
•
Track management: In HOMHT tracker, two kinds of track management systems are available.
The ﬁrst is based on m/n logic and the second relies on track qualities. Note that, the HOMHT
tracker does not probabilistically combine the update states, which are calculated conditioning on
the measurement-to-track association events. Thus the equations that used in JIPDA tracker can
not be applied here. One method to compute the track quality in the MHT framework is proposed
in [88].
•
Find the best hypothesis and output: The last step of a HOMHT loop for a scan is to ﬁnd the best
current hypothesis and then output it to the user.

3.15.6 Multitarget Tracking Algorithms
781
3.15.6.2.2
Track oriented MHT (TOMHT)
The track-oriented MHT constructs a target tree for each potential (or postulated) target according to
the measurements, and the branches represent the different measurements with which the target may be
associated. A trace of successive branches from the root to a leaf of the tree represents a potential mea-
surement history generated by the target. Conventionally, the target trees are referred to as track hypothe-
ses, and a collection of compatible tracks is referred to as global hypothesis. Unlike the HOMHT in
which three possible originalities of measurement are considered, usually the TOMHT treats a measure-
ment as either originated from an existing target or a new one [13]. The TOMHT includes the following
steps:
•
Initialize tree: The target trees are initialized on the receipt of the ﬁrst set of measurements. The root
of each tree is a measurement.
•
Build tree: In this step, the set of trees of previous scan are updated. More speciﬁcally, (1) the depth
of each previous tree is increased by one and each branch grows to several new branches to account
for all possible target-to-measurement associations; (2) each measurement also is used to initiate a
new target tree where the measurement is the root of the tree. In addition, the compatibility relation
has to be updated in order to ﬁnd the global hypothesis.
•
Track management: The track management techniques used for TOMHT are the same as that used
for HOMHT.
•
Track level pruning: The purpose of this step is to remove the branches of low probabilities so that
the computation load for ﬁnding the global hypothesis is remained in a reasonable level. Two pruning
methods can be embedded into the HOMHT: (1) limit the number of branches per tree below Bmax,
which is deﬁned by user as the maximum number of branches per tree; (2) discard the branches
whose probability is lower than a predeﬁned threshold pmin.
•
Find clusters: All the branches, i.e., the node or potential track, belong to the same target tree are
within the same cluster because they share the same root. Therefore, the clustering procedure for
TOMHT is done in the tree-to-measurement level. The algorithm and code for HOMHT clustering
can be reused for TOMHT by just replacing the track by tree and measurement associated with track
by measurements associated with target tree.
•
Find global hypothesis: This step is used to ﬁnd the best global hypothesis, which is a collec-
tion of compatible trees from all the target trees. Enumeration is the basic method for ﬁnding
the best global hypothesis. In enumeration method, all valid global hypotheses are constructed
and then the best one is chosen according to the costs of hypotheses. However, the total number
of valid global hypotheses grows exponentially with respect to the number of trees. For exam-
ple, assume that 10 trees exist and there are 20 branches for each tree. Then, the total number
of global hypotheses is 2010. Although some of the invalid hypotheses will be removed from this
2010 hypotheses, the remaining part is still a large amount. Therefore, the pruning method must
be used to limit the number of valid hypotheses and then an approximate best global hypothesis is
found.
Due to the requirement of node compatibility (or track compatibility), one and only one branch must
be selected per tree to form a possible valid global hypothesis. Note that the selection of dummy node
means no track is selected from this tree in the global hypothesis.

782
CHAPTER 15 Multitarget Multisensor Tracking
3.15.6.3 Probability hypothesis density (PHD) method
In tracking multiple targets, if the number of targets is unknown and varying with time, it is not
possible to compare states with different dimensions using ordinary Bayesian statistics. However, the
problem can be addressed using Finite Set Statistics (FISST) [75] to incorporate comparisons of states
of different dimensions. FISST facilitates the construction of “multitarget densities” from multiple
target transition functions into computing set derivatives of belief-mass functions [75], which makes
it possible to combine states of different dimensions. The main practical difﬁculty with this approach
is that the dimension of state space becomes large when many targets are present, which increases the
computational load exponentially with the number of targets. Since the PHD is deﬁned over the state
space of one target in contrast to the full posterior distribution, which is deﬁned over the state space of
all the targets, the computation cost of propagating the PHD over time is much lower than propagating
the full posterior density. A comparison in terms of computation and estimation accuracy of multitarget
ﬁltering using FISST particle ﬁlter and PHD particle ﬁlter is given in [112].
Assume a sensor has monitored an area since time 1 and at time k, the measurement set
Zk = {z1, z2, . . . , zm} is provided by that sensor. From time 1 to time k, the union of all available
measurement sets from that sensor are Z1:k = [Z1, Z2, . . . , Zk]. By deﬁnition, the PHD Dk|k(xk|Z1:k),
with argument single-target state vector xk and all available measurement sets up to time step k, is
the density whose integral on any region S of the state space is the expected number of targets Nk|k
contained in S. That is,
Nk|k =

S
Dk|k(xk|Z1:k)dxk.
(15.92)
Since this property uniquely characterizes the PHD and since the ﬁrst order statistical moment of the
full target posterior distribution possesses this property, the ﬁrst order statistical moment of the full
target posterior is indeed the PHD. The ﬁrst moment of the full target posterior or the PHD, given all
the measurement sets Z1:k up to time step k, is given by [76]
Dk|k(xk|Z1:k) =

Xk∋xk
fk|k(Xk|Z1:k)δXk,
(15.93)
where Xk is the multitarget state. The approximate expected target states are given by the local maxima
of the PHD. The following section demonstrates the prediction and update steps of one cycle of the
PHD ﬁlter.
Prediction: In a general scenario of interest, there are target disappearances, target spawning and entry
of new targets. We denote the probability that a target with state xk−1 at time step (k −1) will survive
at time step k by ek|k−1(xk−1), the PHD of spawned targets at time step k from a target with state xk−1
by bk|k−1(xk|xk−1) and the PHD of newborn spontaneous targets at time step k by γk(xk). Then, the
predicted PHD is given by
Dk|k−1(xk|Z1:k−1) = γk(xk) +
 
ek|k−1(xk−1) fk|k−1(xk|xk−1)
+ bk|k−1(xk|xk−1)

Dk−1|k−1(xk−1|Z1:k−1)dxk−1,
(15.94)
where fk|k−1(xk|xk−1) denotes the single-target Markov transition density. The prediction Eq. (15.94)
is lossless since there are no approximations.

3.15.7 Architectures of Multisensor-Multitarget Tracking
783
Update: The predicted PHD can be updated with measurement set Zk at time step k to get the posterior
PHD. Assume that the number of false alarms is Poisson-distributed with the average number λFA
and that the probability density of the spatial distribution of false alarms is cFA(zk). Let the detection
probability of a target with state xk at time step k be pD(xk). Then, the updated PHD at time step k is
given by
Dk|k(xk|Z1:k) ∼=
⎡
⎣
zk∈Zk
pD(xk) fk|k(zk|xk)
λFAcFA(zk) + ψk(zk|Z1:k−1) + (1 −pD(xk))
⎤
⎦Dk|k−1(xk|Z1:k−1),
(15.95)
where the likelihood function ψ(·) is given by
ψk(zk|Z1:k−1) =

pD(xk) fk|k(zk|xk)Dk|k−1(xk|Z1:k−1)dxk
(15.96)
and fk|k(zk|xk) denotes the single-sensor/single-target likelihood. The update Eq. (15.95) is not lossless
sincetoderiveaclosed-formulafortheupdatestep,itisnecessarytoassumethatthepredictedmultitarget
target state f (Xk|Z1:k−1) is approximately a Poisson point process, where the physical distribution of
targets is independent and identically distributed (I.I.D.) with a single probability density g(x) and
the target number follows a Poisson distribution. The PHD ﬁlter can be implemented thorough the
sequential Monte Carlo method [120] or the Gaussian mixture method [121].
A generalization of PHD ﬁlter, so called Cardinalized PHD (CPHD) ﬁlter is proposed in [79]. Besides
the target PHD function, the CPHD ﬁlter also propagates the entirely probability distribution on target
number. The core difference between the CPHD ﬁlter and the PHD ﬁlter is that in the CPHD ﬁlter, it
is assumed that the predicted multitarget target state f (Xk|Z1:k−1) is approximately an I.I.D. cluster
point process, where the physical distribution of targets is still I.I.D. with a single probability density
g(x) but the target number now can follow any arbitrary distribution p(n). A polynomial running time
implementation of the CPHD ﬁler using the Gaussian mixture technique has been proposed in [122].
Both the PHD ﬁlter in [78] and the CPHD ﬁlter in [79] are unable to maintain the track identity.
They only provide identity-free estimates of target states and hence no temporal association of estimates
over time. Thus, to use the PHD ﬁlter or the CPHD ﬁlter as a multitarget tracker, a separate module is
required to handle the temporal association for state estimates of individual targets. If the PHD ﬁlter or
the CPHD ﬁlter is implemented thorough the Gaussian mixture technique, then by adding unique tag to
each Gaussian component, an association of state estimates to targets over time can be achieved [91].
The multisensor versions of the PHD and CPHD ﬁlters are possible-but also computationally
intractable [78]. For example, it has been veriﬁed in [80] that the measurement-update formula for
a two-sensor PHD ﬁlter requires a summation over all binary partitions of the current two-sensor mea-
surement set. A computationally tractable approximated multisensor PHD and CPHD ﬁlter has been
proposed in [83].
3.15.7 Architectures of multisensor-multitarget tracking
Three major types of architecture, namely, centralized, distributed, and decentralized, are commonly
used in multisensor-multitarget tracking applications [9,62,126]. Here, it is assumed that the data of

784
CHAPTER 15 Multitarget Multisensor Tracking
           Node
S
S
S
S
Environment
    Central Fusion
(a)
(b)
(c)
S
S
S
S
    Central Fusion
Environment
LFC
LFC
           Center
FC
FC
FC
FC
FC
FC
FC
FC
FC
FIGURE 15.2
Common fusion architectures. (a) Centralized. (b) Distributed. (c) Decentralized.
each sensor has already been converted to a common coordinate system, regardless whether the sensor
measurements are processed in the centralized or the distributed architecture.
Centralized Tracking: In the centralized architecture, Figure 15.2a, several sensors are monitoring
the region of interest to detect and track the targets therein. All sensors generate measurements at
each revisit time and report those measurements to the Central Fusion Center (CFC). It in turn fuses
all the acquired measurements and updates the tracks. This is the optimal architecture in terms of
tracking performance. However, in a large surveillance region with many sensors, this architecture may
not be feasible because of limited resources, e.g., communication bandwidth and computation power.
To further improve the reliability and the performance of the centralized architecture, one can use the
replicated centralized architecture [24]. In the replicated centralized architecture, there are multiple
CFCs operating independently and each sensor reports its measurements to all CFCs. In other words,
each CFC processes data from all sensors and there is no communication among CFCs. This architecture
has high performance and reliability because the multiple CFCs process the same data. However, it also
has higher communication and processing costs.
Two well known schemes used by the CFC to incorporate measurements from multiple sensors are
sequential updating and parallel updating:
•
In the sequential updating scheme, the updating is carried out with the measurement of one sensor
at a time. The posterior state estimate obtained from the measurements reported by the kth sensor is
used as the prior information when the measurements from the k + 1th sensor is processed. For one
speciﬁc senor, those techniques commonly used in the single sensor-multitarget tracking problem,
like one/two point initialization, multi-frame data association, and Kalman ﬁltering, are applied.
•
In the parallel updating scheme, the measurements from the various sensors are ﬁrst associated to
yield “supermeasurements,” then these supermeasurements are processed by the CFC as if they
were reported by a single sensor. In other words, after the measurement association procedure, the
multisensor-multitarget tracking problem has been converted to a single sensor-multitarget tracking
problem in the parallel updating scheme.

3.15.7 Architectures of Multisensor-Multitarget Tracking
785
In the two schemes mentioned above, usually it has been assumed that the sensors are synchronized.
In real scenarios, the sensors are seldom perfectly synchronized and too many asynchronous sensors
will reduce the optimality of the centralized tracking architecture.
Distributed Tracking: In order to avoid the heavy communication and computational requirement of
centralized fusion, distributed or hierarchical architecture, shown in Figure 15.2b, is used alternatively
[126]. In this architecture, sensors are connected to Local Fusion Centers (LFCs) and LFCs are in turn
connected to a CFC. Each LFC updates its local tracks based on the measurements obtained from the
local sensors and sends its tracks state information to CFC. Then, the CFC performs the track-to-track
fusion and may send back the updated tracks to the LFCs, if the feedback path is available.
There are two crucial questions in this type of architecture. The CFC needs to decide whether local
tracks from different LFCs represent the same target, i.e., the problem of track-to-track association.
Furthermore, because of the common process noise or the common prior, the local state estimates for
the same target from different LFCs are not independent anymore. Thus, the dependency between the
local tracks for the same target from different LFCs has to be handled optimally in the track-track
fusion. First, the cross-covariance between the local tracks has to be estimated and then the covariance
of the fused track has to be increased correspondingly. Note that, even the above two questions are
solved optimally, the distributed tracking architecture is still suboptimal compared to the centralized
architecture, because the optimal fusion of the state estimates of local tracks can not provide the same
performance as the optimal fusion of the entire data set [9].
To optimally handle the dependency between the local tracks for the same target, the computational
cost may be large and the required information may take up too much communication bandwidth,
especially when there are many LFCs. Thus, several suboptimal methods are proposed to handle the
dependency between the local tracks for the same target. One suboptimal way is using the corresponding
tracklets of the local tracks in the CFC for the track-track fusion. A tracklet is a track specially calculated
from the local track such that its errors are not cross-correlated with the errors of any other data in the
system for the same target [34,35]. Another suboptimal methods is the covariance intersection technique,
which takes a convex combination of the estimate of the mean and the information matrix (i.e., the inverse
of the covariance matrix) of the local tracks. The covariance intersection method actually provides an
estimate of the upper bound of the covariance matrix of the optimally fused track [25,51].
Decentralizedtracking:WhenthereisnoCFCthatcancommunicatewithallLFCsinalargesurveillance
region, neither centralized nor distributed tracking is possible. In such cases, an alternative called
decentralized architecture, shown in Figure 15.2c, is used. Decentralized architecture is composed of
multiple Fusion Centers (FCs) and no CFC [126]. Here, each FC gets the measurements from one or
more sensors that are connected to it, and uses those measurements to update its tracks. In addition,
tracks are also updated whenever an FC gets additional information from its neighbors. Note that even
though many FCs are available, each FC can communicate only with its neighbors; the FCs within
the communication distance every few measurement time steps. There is no common communication
facility in decentralized tracking network, i.e., FC cannot broadcast results and communication must be
kept on a strictly neighbor-to-neighbor basis [36]. In decentralized tracking architecture, each FC can
be considered as a combination of LFC and CFC, because it updates the track state using measurements
from connected sensors and it also does track-track fusion whenever neighboring FCs report their track
states. Usually, the algorithms developed for the distributed tracking architecture can be used here
without any major modiﬁcation.

786
CHAPTER 15 Multitarget Multisensor Tracking
Sensor Registration: The beneﬁts afforded by the integration of data from multiple sensors are greatly
diminished if sensor biases are present. In practical systems, sensor states are not precisely speciﬁed
with respect to some common coordinate system and measurements may be subjected to pointing errors,
calibration errors or computational errors. As a result, knowledge about sensor location or attitude may
not be accurate. Without this knowledge, there may be severe degradation in the performance of data
association, ﬁltering and fusion, leading to eventual loss of track quality. Thus, sensor registration and
data alignment is the ﬁrst step in the fusion process. In sensor registration [5], the bias is estimated
and the resulting values are used to debias measurements prior to fusion. Assume that local tracks for
the same target from different sensors have already been associated, then to estimate the bias vector,
the classical approach is to augment the system state to include the bias vector as part of the state and
implement an augmented state Kalman ﬁlter (ASKF) [39,54,74]. However, under some circumstances,
the prior track-to-track association may be unnecessary for the sensor registration process [64].
3.15.8 Centralized tracking
It is assumed that there are NS sensors. The measurement from sensor j at time k is
z(k, j) = H(k, j)x(k) + w(k, j),
j = 1, . . . , NS.
(15.97)
The measurement noise sequences are zero mean, white, independent of the process noise and indepen-
dent from sensor to sensor with covariances R(k, j). If NS = 1, the above problem becomes a single
sensor-multitarget tracking problem. Two widely used techniques to incorporate multiple sensors are
sequential updating technique and parallel updating technique.
3.15.8.1 Sequential updating
In sequential updating scheme, the state update is carried out with the measurement of one sensor at a
time.
Start the recursion from the predicted state and covariance denoted by
ˆx(k|k, 0) = ˆx(k|k −1),
(15.98)
P(k|k, 0) = P(k|k −1).
(15.99)
The updates with the measurements at time k are
ˆx(k|k, j) = ˆx(k|k, j −1) + W(k, j)(z(k, j) −H(k, j)ˆx(k|k, j −1)),
j = 1, . . . , NS,
P(k|k, j) = P(k|k, j −1) −W(k, j)S(k, j)W(k, j)′,
j = 1, . . . , NS,
(15.100)
where
S(k, j) = H(k, j)P(k|k, j −1)H(k, j)′ + R(k, j),
(15.101)
W(k, j) = P(k|k, j −1)H(k, j)′S(k, j)−1.
(15.102)

3.15.8 Centralized Tracking
787
The above update scheme shows that, the update step for the jth sensor is almost same as that for
the single sensor-multitarget tracking problem. The only difference is that the posterior track state
estimates, ˆx(k|k, j −1), P(k|k, j −1), which are obtained after the processing of the j −1th sensor’s
measurements, is used as the predicted track state ˆx(k|k −1, j), P(k|k −1, j) for the jth sensor.
For linear measurements, the order of updating in the sequential procedure is immaterial. For non-
linear measurements however, measurement from the most accurate sensor should be updated ﬁrst so
as to reduce subsequent linearization errors.
3.15.8.2 Parallel updating
In parallel updating scheme, measurements generated by the same target from each sensor are associ-
ated, and simultaneously stacked and updated. After the measurement-to-measurement association pro-
cess, the multisensor-multitarget tracking problems has been converted into a single sensor-multitarget
tracking problem with the following measurement model:
z(k) =
⎡
⎢⎣
z(k, 1)
...
z(k, NS)
⎤
⎥⎦= H(k)x(k) + w(k),
(15.103)
where
H(k) =
⎡
⎢⎣
H(k, 1)
...
H(k, NS)
⎤
⎥⎦,
w(k) =
⎡
⎢⎣
w(k, 1)
...
w(k, NS)
⎤
⎥⎦,
and
E[w(k)w(k)T ] = R(k) = diag[R(k, j)].
(15.104)
The most important step of the parallel updating is the measurement-to-measurement association.
If S lists of measurements are obtained from S synchronous sensors, then the goal is to group the
measurements that could have originated from the same (unknown) target. In one commonly used
approach, each feasible S-tuple of measurement Zi1i2...iS, consisting one measurement from each sensor,
is assigned a cost (typically, a likelihood ratio similar to (15.80)) and then the set of S-tuples that
minimizes the global cost is found. This optimization can be formulated as a multidimensional (S-D)
assignment as described in Section 3.15.5.1.
The unknown target state, which is necessary to ﬁnd the assignment cost, is replaced by its Maximum
Likelihood (ML) estimate:
Xu = arg max
X
p(Zi1i2...iS|X).
(15.105)
Note that, if the type of measurements does not have a full observability, then the S-tuple in the
association needs to have a certain minimum number of measurements from a target in order for the
state of the target to be observable.

788
CHAPTER 15 Multitarget Multisensor Tracking
3.15.9 Distributed tracking
In a distributed or decentralized conﬁguration, each fusion center has a number of tracks. One crucial
question is how to handle the dependency between different local tracks generated by the same target.
There are three sources for the cross correlation between any track pairs for the same target [35]:
1. Common prior information. When the same meaningful prior information is used to initialize new
tracks for the same target among different Local Fusion Center (LFC) or the Central Fusion Center
(CFC), those tracks will be cross-correlated.
2. Updated tracks including duplicate measurement sequence. Considering a multisensor-multitarget
problem with two LFCs and one CFC. For target T , LFC i, i = {1, 2} has formed its local track
xT (k)(i) only based on its own measurement set {z(i)(1), . . . , z(i)(k)}, respectively. At the end of
time k, a global track xT (k)G for T has been built inside the CFC by fusing xT (k)(1), xt(k)(2).
At the end of time k + m, the CFC fuses local track xT (k + m)(i) and the predicted global track
xT (k +m|k)G. However, xT (k +m|k)G, which is predicted from xT (k)G, and xT (k +m)(i), which
is estimated from measurement sequence {z(i)(1), . . . , z(i)(k +m)}, both contain the information in
measurement sequence {z(i)(1), . . . , z(i)(k)}, so xT (k + m|k)G and xt(k + m)(i) are correlated.
3. Common process noise. If target is maneuvering or the state model used by trackers includes the
process noise, then those measurements from the same target will be correlated because they contain
the same process noise component.
Thus, if the target is strictly moving with a constant velocity, no process noise is used in LFCs and
CFC, each LFC form its tracks strictly based on its own measurement sets (i.e., no feedback from the
CFC to the LFC), and the CFC is restarted whenever a new or updated local track was available (i.e.,
memoryless fusion center), then there will not be any cross-correlation between any track pairs for the
same target.
One useful tool to explain and analyze the information dependence due to communication is infor-
mation graph [26,62]. Information events, such as observation by a sensor at a given time or fusion by a
FC at a speciﬁc time, are represented by the nodes of the graph. The ﬂow of information is represented
by a directed link between the nodes. Thus, a node that is a common predecessor to two nodes contains
the common information of those two nodes and the common information of any two or more nodes can
be found out by identifying their common predecessors. Information graph is especially useful when
the communication structure among FCs is complicated since in this case the identiﬁcation of common
information may not be easy.
3.15.9.1 Cross-covariance of the estimation errors
The dependency between the local state estimation errors for the same target is characterized by the
cross-covariances of the local estimation errors, so it is important to estimate the cross-covariance
between local track pair [9].
Assume sensors are synchronized, then the recursion for the cross-covariance between local track i
and j is given by

3.15.9 Distributed Tracking
789
Pi j(k|k) = [I −W i(k)Hi(k)]
"
F(k −1)Pi j(k −1|k −1)F(k −1)′
+ Q(k −1)
#
[I −W j(k)H j(k)]
′.
(15.106)
This is a linear recursion and its initial condition is assuming the initial errors to be uncorrelated, i.e.,
Pi j(0|0) = 0 (no meaningful prior information). This is a reasonable assumption in view of the fact
that the initial estimates are usually based on the initial measurements, which are assumed to have
independent errors.
Assume the difference of the estimates of local track i and j is
ˆi j(k) = ˆxi(k|k) −ˆx j(k|k)
(15.107)
then its corresponding covariance is
E
$
ˆi j(k) ˆi j(k)T %
= Pi(k|k) + P j(k|k) −Pi j(k|k) −Pi j(k|k).
(15.108)
The above equations indicate that the effect of the dependency between the estimation error is to reduce
the covariance of the difference of the estimates of local track i and j, because the common process
noise and the common prior reduces the positive correlation between the estimation errors. In addition,
the dependency between the local tracks from the same target leads to a larger covariance of the fused
estimate state than in the case of independent errors. The above calculation of the cross-correlation is
optimal only when it has been done synchronously.
3.15.9.2 Association for tracks with dependent errors
In this algorithm, the problem of associating tracks represented by their local estimates and covariances
from S fusion centers is considered [8].
Consider the assignment formulation for track-to-track association from S fusion centers. Assume
fusion center Si has a list of Ni tracks. Deﬁne a binary assignment variable χi1i2···iS as
χi1i2···iS =
1 tracks i1, i2, . . . , iS are from the same target,
0 otherwise.
(15.109)
A subset of indices {i1, i2, . . . , iS} could be zero in the assignment variable meaning that no track
will be from the target in the corresponding list of the fusion centers.
The S-Dassignmentformulationﬁndsthemostlikelyhypothesisbysolvingthefollowingconstrained
optimization.
min
χi1i2···iS
N1

i1=0
N2

i2=0
· · ·
NS

iS=0
ci1i2···iSχi1i2···iS
(15.110)
subject to the constraints
N2

i2=0
· · ·
NS

iS=0
χ ji1i2...iS = 1,
j = 1, 2, . . . , N1
(15.111)
N1

i1=0
N3

i3=0
· · ·
NS

iS=0
χi1 ji3···iS = 1,
j = 1, 2, . . ., N2
(15.112)

790
CHAPTER 15 Multitarget Multisensor Tracking
...
(15.113)
N1

i1=0
· · ·
NS−1

iS−1=0
χi1i2···iS−1 j = 1,
j = 1, 2, . . ., NS
(15.114)
and
χi1i2···iS ∈{0, 1},
i1 = 1, . . . , N1,
i2 = 1, . . . , N2,
iS = 1, . . . , NS.
(15.115)
In (15.110) the assignment cost is
ci1i2···iS = −log λi1i2···iS
(15.116)
where λi1i2···iS is the likelihood ratio of the track association hypothesis vs. all tracks from extraneous
targets. The following equation can be used to calculate λi1i2···iS
λi1,i2···iS = V M−1N[ˆxSi ; 0, PSi ]
⎡
⎣&
s∈Si
PDs
⎤
⎦
⎡
⎣
&
s∈{1,2,...S}\Si
1 −PDs
⎤
⎦
(15.117)
where 1/V is the diffuse pdf of track density, Si = { j|i j > 0, j = 1 : . . . , S} = {s1, . . ., sM}, M is the
number of elements in Si and
ˆxSi =
"
ˆx
is2
s2 −ˆx
is1
s1 , . . . , ˆx
isM
sM −ˆx
is1
s1
#T
(15.118)
and PSi is its covariance matrix. From (15.108), the diagonal blocks in PSi are
(PSi ) j−1, j−1 = P
is1
s1 + P
is j
s j −P
is1is j
s1,s j −

P
is1is j
s1,s j
′
j = 2, . . ., M
(15.119)
and off-diagonal blocks are
(PSi ) j−1,g−1 = P
is1
s1 −P
is1is j
s1,s j −

P
is1is j
s1,s j
′
+ P
is j isq
s j,sg
j, g = 2, . . ., M.
(15.120)
The Maximum Likelihood (ML) estimate of the track states obtained by fusing the set of tracks
{is1, . . ., isM } is given by
xfused
Si
=

E′ ¯P−1
Si E
−1
E′ ¯PSi ¯xSi ,
(15.121)
where E =

Inx Inx · · ·Inx

is (M × nx)×nx matrix and nx is the dimension of the state vector. Also,
¯xSi =
"
ˆx
is1
s1 , . . ., ˆx
isM
sM
#
,
(15.122)

3.15.9 Distributed Tracking
791
¯PSi =
⎡
⎢⎢⎢⎢⎢⎣
P
is1
s1
P
is1is2
s1,s2
· · · P
is1isM
s1,sM
P
is2is1
s2,s1
P
is2
s2
. . . P
is2isM
s2,sM
...
...
...
...
P
is2is1
sM,s1 P
isM is2
sM,s2 · · ·
P
isM
sM
⎤
⎥⎥⎥⎥⎥⎦
.
(15.123)
The covariance matrix of the fused track is given by
Pfused
Si
=

E′ ¯P−1
Si E
−1
.
(15.124)
3.15.9.3 Tracklet fusion
A tracklet is a track computed so that its state estimation error is not cross-correlated with the state
estimation errors of any other data in the system for the same target. There are two types of methods to
build tracklet [35]:
1. Form a tracklet by decorrelating a local track.
2. Form a tracklet directly from a sequence of measurements.
Both of them ignore the cross correlation caused by the common process noise. Furthermore, as being
pointed out in [35], only the tracklet-from-track type of methods can be used to decorrelate the cross
correlation from the common prior information. Thus, in this chapter, only the tracklet-from-track
type of methods are discussed. In the following, ˆx j
n|m and P j
n|m represent the predicted track state and
covariance matrix in the jth LFC. ˆx j
n and P j
n represent the posterior track state and covariance matrix
in the jth LFC. Fn|m is the state transfer matrix from the mth scan to the nth scan.
There are three methods falling in tracklet-from-track category [35]:
1. Inverse Kalman ﬁlter (Frenkel’s Method No. 1). It outputs u j
n for a local track ˆx j
n from LFC j at
time n, given that the local track was previously reported by the same LFC to the CFC at frame m.
Tracklet u j
n and its covariance are calculated by:
P j
n|m = FT
n|m P j
m Fn|m,
(15.125)
A j
n = P j
n|m
"
P j
n|m −P j
n
#−1
,
(15.126)
ˆx j
n|m = FT
n|m ˆxm,
(15.127)
u j
n = ˆx j
n|m + A j
n
"
ˆx j
n −ˆx j
n|m
#
,
(15.128)
U j
n = A j
n P j
n .
(15.129)

792
CHAPTER 15 Multitarget Multisensor Tracking
The input to the CFC is u j
n, the equivalent measurement, and U j
n , its corresponding measurement
error covariance matrix. The equivalent measurement equation matrix H for u j
n in the CFC is an
identity matrix. The global track estimate ˆxG
m has to be predicted to frame n. This method cannot be
used if there is only one measurement in the tracklet interval n −m.
2. Tracklet with decorrelated state estimate (Frenkel’s Method No. 2). It outputs y j
n for a local track
ˆx j
n from LFC j at time n, given that the track data was previously reported by the same LFC to the
CFC at frame m. Tracklet y j
n and its covariance are calculated by:
P j
n|m = FT
n|m P j
m Fn|m,
(15.130)
ˆx j
n|m = FT
n|m ˆxm,
(15.131)
C j
n = P j
n
"
P j
n|m
#−1
,
(15.132)
B j
n = I −C j
n,
(15.133)
y j
n = ˆx j
n −C j
n ˆx j
n|m,
(15.134)
Y j
n = B j
n P j
n .
(15.135)
The input to the CFC is y j
n and its corresponding covariance matrix Y j
n . The equivalent measurement
equation matrix H for y j
n in the CFC is B j
n . Still, the estimate of global track ˆxG
m has to be predicted
to n. This method can be used even when there is only one measurement in the tracklet interval
n −m.
3. Inverse information ﬁlter [9,36,104]. It outputs y j
n for a local track ˆx j
n from local tracker j at time
n, given that the track data was previously sent by the same LFC to the CFC at frame m. Tracklet
y j
n and its covariance are calculated by:
P j
n|m = FT
n|m P j
m Fn|m,
(15.136)
ˆx j
n|m = FT
n|m ˆxm,
(15.137)
y j
n =

P j
n
−1
ˆxn −

Pn|m
−1 ˆxn|m,
(15.138)
Y j
n =

P j
n
−1
−

P j
n|m
−1
.
(15.139)
The input to the CFC is y j
n and its corresponding covariance matrix Y j
n. Note, to use y j
n and Y j
n
directly, the CFC should run the information ﬁlter (i.e., inverse Kalman ﬁlter).

3.15.9 Distributed Tracking
793
Since the received tracklets are assumed to be independent of each other and independent of the local
tracks, tracklets association problem can be solved by using an S-D association technique, where the
set of tracklets are treated as the set of measurements with independent measurement noise.
3.15.9.4 Covariance intersection
When cross-correlation between two estimations is unknown and hard to calculate, a sub-optimal
information fusion algorithm, called Covariance Intersection (CI) algorithm, is proposed in [51]. It
takes a convex combination of the estimation of the mean and the information matrix (the inverse of the
covariance matrix) and can provide a consistent fused estimate. Here the consistency for the estimate
ˆx, ˆPx of unknown state x is deﬁned as:
ˆPx −E[(ˆx −x)(ˆx −x)T ] ≥0
(15.140)
Assume there are two independent sensors, a and b, to observe one target. Each sensor is equipped
with a Kalman ﬁlter and based on its measurement sequence, at time k, two consistent estimate of
target state ˆx(k)a, ˆP(k)a, ˆx(k)b, ˆP(k)b are obtained from sensor a and sensor b, respectively. Now the
information from ˆx(k)a, ˆP(k)a, ˆx(k)b, ˆP(k)b, has to be fused to get ˆx f (k), ˆPf (k), a better estimation
of target state. Furthermore, ˆx f (k), ˆPf (k) has to be consistent.
In the CI algorithm, a linear convex combination formula is used to fuse ˆx(k)a, ˆP(k)a and ˆx(k)b,
ˆP(k)b:
ˆPf (k)−1 = w ˆPa(k)−1 + (1 −w) ˆPb(k)−1
(15.141)
ˆPf (k)−1 ˆx f (k) = w ˆPa(k)−1 ˆxa(k) + (1 −w) ˆPb(k)−1 ˆxb(k)
(15.142)
where w ∈[0, 1] is determined by minimizing the trace or the determinant of ˆPf (k). In both cases,
the cost function is convex respect to w and the semideﬁnite convex programming technique can be
used to solve this minimization problem. To avoid the time consuming optimization procedure in the
CI algorithm, two fast algorithms to calculate the weight w has been proposed in [37,89].
The intuition behind the CI algorithm comes from the geometric interpretation of covariance matrixes
ˆP(k)a, ˆP(k)b and ˆP(k) f . Just as shown in Fig. 1 of [51], no matter what the cross-correlation between
ˆx(k)a and ˆx(k)b is, the theoretical optimal ˆPf (k) always lies within the intersection of two ellipsoids
that represent ˆP(k)a, ˆP(k)b respectively. Thus, if the fused covariance matrix, ˆP(k) f , encloses the
intersection region, it must be consistent even if there is no knowledge about the cross-correlation
ˆP(k)ab. Actually, the fused covariance from (15.142) can be thought as a Gaussian approximation of
the actual covariance intersection. Obviously, the tighter the updated covariance encloses the intersection
region, the greater the amount of information which can be used. The consistent of the fused covariance
has guaranteed that the estimation is non-divergent.
From the intuition behind the CI algorithm, it is clear that a signiﬁcant drawback of the CI algorithm
in [51] is that it will inevitably over estimate the fused covariance matrix and will lead to unnecessary
loss in its calculated fusion accuracy. As pointed out in [25], if all local trackers give the same covariance
matrix estimations, i.e., ˆP1 = · · · = ˆPn = ˆP, then there is PC I = ˆP no matter how many estimates have
been fused. In other words, under this circumstance, the error bound provided by PC I does not represent
any possible reduction in the uncertainty of the fused estimate. This phenomenon has been explained

794
CHAPTER 15 Multitarget Multisensor Tracking
in [25] using the set estimation theory. Based on the unknown but bounded set estimation theory, a
tighter bound for the fused covariance matrix is given in [25]. There, given two local tracker’s estimation
ˆx1, ˆP1, ˆx2, ˆP2, it assumes that the unknown target state x lies inside two ellipsoids (ˆx1, ˆP1), (ˆx2, ˆP2),
respectively, and the ellipsoid is deﬁned as
(ˆxi, ˆPi) = {x : (x −ˆxi) ˆP−1
i
(x −ˆxi) ≤1}
(15.143)
Given (ˆx1, ˆP1), (ˆx2, ˆP2), x can only be in their intersection area, which may not be ellipsoid.
However, a bounding ellipsoid for this intersection, which satisfy (w) ⊃{(ˆx1, ˆP1) ' (ˆx2, ˆP2)},
can be deﬁned as
(w) = {x : w(x −ˆx1) ˆP−1
1 (x −ˆx1) + (1 −w)(x −ˆx2) ˆP−1
2 (x −ˆx2) ≤1}
(15.144)
where w ∈[0, 1]. With some algebra simpliﬁcation, the above formula comes into:
(x −xC I )′[(1 −α2)PC I ]−1(x −xC I ) ≤1
(15.145)
in which xC I , PC I follows (15.141), (15.142), respectively and α is given by:
α2 = (ˆx1 −ˆx2)′(w−1 ˆP1 + (1 −w)−1 ˆP2)−1(ˆx1 −ˆx2)
(15.146)
Thus, the fused covariance matrix has been shrink from PC I to (1 −α2)PC I .
3.15.10 Performance evaluation
In this section, the Posterior Cramér-Rao Lower Bound (PCRLB) of tracking [10,44,46,47,115], which
provides a minimum bound of any tracking estimation, and several tracker-related metrics, which
measure the performance of multitarget trackers in cardinality, time and accuracy [40,66,103], are
discussed.
3.15.10.1 Posterior Cramér-Rao Lower Bound (PCRLB)
3.15.10.1.1
Background
Let Xk be an unknown and random state vector, and let Xk(Zk) be an unbiased estimate of Xk based
on the measurement data, Zk. The PCRLB, which is deﬁned to be the inverse of the Fisher Information
Matrix (FIM), J(k) [117], then gives a lower bound of the error covariance matrix, i.e.,
C(k) ≜E
(
[Xk(Zk) −Xk][Xk(Zk) −Xk]′)
≥J(k)−1,
(15.147)
where E denotes expectation over (Xk, Zk) and [·]′ denotes the transpose. The inequality in (15.147)
means that C(k) −J(k)−1 is a positive semi-deﬁnite matrix.
A recursive formula for the evaluation of the posterior FIM, J(k), is given by [116]:
J(k + 1) = D22
k −D21
k

J(k) + D11
k
−1D12
k
*
+,
-
JX(k+1)
+JZ(k + 1),
(15.148)

3.15.10 Performance Evaluation
795
where
D11
k
= E
$
−Xk
Xk ln p(Xk+1|Xk)
%
,
(15.149)
D12
k
= E
$
−Xk+1
Xk
ln p(Xk+1|Xk)
%
,
(15.150)
D21
k
=

D12
k
′,
(15.151)
D22
k
= E
$
−Xk+1
Xk+1 ln p(Xk+1|Xk)
%
,
(15.152)
JZ(k + 1) = E
$
−Xk+1
Xk+1 ln p(Zk+1|Xk+1)
%
,
(15.153)
and β
α is a second-order partial derivative operator whose (i, j)th term is given by
β
α(i, j) =
∂2
∂α(i)∂β( j),
(15.154)
α(i) and β(i) are the ith components of vectors α and β, respectively. In the above, Zk+1 =
[Zk+1(1), Zk+1(2), . . . , Zk+1(n)], where Zk+1(i) is the measurement vector at sensor i at sampling
time k + 1 and n is the number of sensors utilized at sampling time k + 1.
3.15.10.1.2
Dynamic system contribution to the PCRLB
Let the state vector at time k, obtained by stacking the state vectors of all targets, be denoted by
Xk =

X1
k, X2
k, . . . , X T
k
′, where Xt
k is the state vector of target t and T is the total number of targets
in the surveillance region. If we assume that targets are moving independently and the state equation of
each target is linear, then the overall state equation is given by
Xk+1 = Fk Xk + νk,
(15.155)
where
Fk = diag

F1
k , F2
k , . . . , FT
k

,
(15.156)
νk =
"
ν1
k , ν2
k , . . . , νT
k
#′
.
(15.157)
In the above, Ft
k is the state transition matrix and νt
k is the process noise of target t. If νt
k is Gaussian
with zero mean and covariance t
k, then the covariance matrix of νk, k, is given by
k = diag

1
k, 2
k, . . . , T
k

.
(15.158)
It can be shown that in the case of linear, Gaussian dynamics (e.g., [101]) we have
D11
k
= F′
k−1
k Fk,
(15.159)
D12
k
= −F′
k−1
k ,
(15.160)
D22
k
= −1
k .
(15.161)

796
CHAPTER 15 Multitarget Multisensor Tracking
Using the Matrix Inversion Lemma and (15.159)–(15.161), there is
JX(k) =
"
k−1 + Fk−1J(k −1)−1F′
k−1
#−1
.
(15.162)
The matrix JX(k) gives the prior information regarding the target states at time k.
Besides process noise, sometimes the dynamic model uncertainty also contributes to the PCRLB,
especially in the case of maneuvering targets, whose kinematics model may evolve in a time-varying
manner. Thus, it is necessary to consider the PCRLB for a ﬁltering problem with multiple switching
dynamic models and additive Gaussian noise. Some related works can be found in [48,109].
3.15.10.1.3
Measurement contribution to the PCRLB
The measurement contribution to the PCRLB is given by JZ(k). Consider the general case in which
there is measurement origin uncertainty, with measurements originating from one of the targets or from
clutter. The jth measurement at the ith sensor is given by
Zk( j, i) =
 hi
k(Xt
k) + ωi
k( j) if originated from target t,
υi
k( j)
if false alarm,
(15.163)
where hi
k is (in general) a nonlinear function, ωi
k( j) is a zero mean Gaussian random variable with covari-
ance k and υi
k( j) is uniformly distributed across the surveillance region A (with hyper-volume, V ).
The probability mass function of the number of false alarms, μFA(m), which is Poisson-distributed with
mean λV , is given by
μFA(m) = e−λV (λV )m
m!
,
(15.164)
where m is the number of false alarms and λ is the spatial density of the false alarms.
When multiple targets are present, the association between the measurements and the targets is
not known and must be considered in the PCRLB calculation. The following assumptions are made
regarding the measurements:
•
Each measurement can be generated by one of the targets or the clutter.
•
Each target can produce zero or one measurement at any one time.
If sensors have independent measurement processes, JZ can be written as [114]
JZ(k) =
n

i=1
JZi (k),
(15.165)
where
JZi (k) =
∞

mk(i)=0
p(mk(i))JZi (mk(i), k),
(15.166)
JZi (mk(i), k) = E
$
−Xk
Xk ln p(Zk(i)|Xk, mk(i)) |mk(i)
%
.
(15.167)

3.15.10 Performance Evaluation
797
Intheaboveequations,n isthenumberofsensorsusedattimek andmk(i)isthenumberofmeasurements
at sensor i at time k.
The probability of receiving mk(i) measurements, p(mk(i)), from sensor i is given by
p(mk(i)) =
min (T ,mk(i))

d=0
⎛
⎜⎝μFA(mk(i) −d)

Di
k
 T&
t=1

Pt
D(i)
Di
k(t) 
1 −Pt
D(i)
(1−Di
k(t))
⎞
⎟⎠,
(15.168)
where Di
k is the detection vector that indicates which targets are detected at sensor i (at time k).1 The
total number of targets that are detected is d, i.e., !T
t=1 Di
k(t) = d. Pt
D(i) is the probability of detection
of target t by sensor i.
The probability density function of the measurement Zk(i) conditioned on Xk and mk(i) is given
by [49]
p(Zk(i)|Xk, mk(i)) =

ak(i)
p(Zk(i)|Xk, mk(i), ak(i))p(ak(i)|mk(i)),
(15.169)
where ak(i) is the association vector that indicates which measurement originated from which target.
Each element ak( j, i) of ak(i) is a random variable that takes a value in [0, 1, . . . , T ], with 0 indicating a
false alarm. ak( j, i) = t indicates that the measurement j originates from target t. If the targets are well
separated in the measurement space, there is no measurement origin uncertainty in terms of targets and
any one measurement can be originated from a known target or clutter [114]. However, if the targets are
closely-spaced or cross one another, it is hard to ﬁnd the association vector and all possible associations
must be considered in the calculation of measurement information JZ(k).
It has been shown in [115] that (t1, t2)th block of JZi (k) is given as follows:

JZi (k)

t1t2 = E
$
Hi
k
′
t1

Qi
k

t1t2−1
k

Hi
k

t2 |Xk
%
,
(15.170)
where

Hi
k

t(α, β) = ∂hi
k(α, Xt
k)
∂Xt
k(β)
,
(15.171)

Qi
k

t1t2 =
∞

mk(i)=0
p(mk(i))

Qi
k(mk(i))

t1t2,
(15.172)
and

Hi
k

t (α, β) denotes the (α, β)th element of matrix

Hi
k

t. Qi
k is the Information Reduction Matrix
(IRM) for sensor i and

Qi
k

t1t2 is the (t1, t2)th block of the IRM.

Qi
k(mk(i))

t1t2 is also given in
[115]. No closed form analytical solution exists for the IRM Qi
k, which must then be calculated using
a numerical integration technique.
1Di
k(t) takes the value 1 if target t is detected and 0 otherwise.

798
CHAPTER 15 Multitarget Multisensor Tracking
3.15.10.2 Tracker-related measures for performance evaluation
Generally, a tracker-related measure is deﬁned as a function getting T , L, and M as inputs and providing
some measures that evaluate the quality of the tracking algorithm. Here, T is deﬁned as the collection
of all tracks, L is the total information of truth, and M is the set of all measurements. The following
categories are considered for the tracker-related measures [40]:
•
Tracker-dependent:
These measures are developed for individual types of trackers. For example, performance measures
have been specially deﬁned for IMM ﬁlters [65,124], for assignment based tracking algorithms [46],
for dynamic programming [50], MHT trackers [20] and IPDA algorithm [125]. This group of metrics
is also called algorithm based metrics because they are deﬁned for a speciﬁc type of tracking and
ﬁltering method, or a speciﬁc application, and may not be applicable to other tracking methods.
•
Tracker-independent:
These types of measures can be applied to every tracker. Various categories can be again deﬁned
based on the availability of truths and tracks. When truths and tracks are both available, a large class
of performance metrics can be deﬁned after ﬁnding an association between the estimated tracks and
available truths. In real scenarios, sometimes truths are not available. In this case, statistical tests are
done on the estimated tracking results to check the consistency of the estimates. The type of metrics
is also called algorithm free metrics.
In this subsection, only the tracker-independent metrics are reviewed, because only these type of the
tracker-related measures can be applied to every tracking algorithms. Different categories of algorithm
free metrics may be deﬁned based on the availability of truths and tracking results as
• Available truths and tracks:
This is the most popular and applicable case in performance evaluation when the goal is to evaluate
tracking results with the known truths. There are three classes of metrics summarized as follows:
• Track Cardinality Measures:
This metric measures numerical characteristics of obtained results. For example, the number of
conﬁrmed tracks associated with truths, and number of missed and false tracks can be considered
as cardinality measures. The major limitation of these measures is that they do not provide any
information about the performance of individual tracks, such as the consistency of track and the
accuracy of estimation. Also, no information is available about the time characteristics of the
estimated tracks.
• Time (Durational) Measures:
Time performance of estimated tracks is evaluated by this class of metrics. These performance
measures provide information about the persistency of a track. For example, track probability
of detection is represented as a metric evaluating the detection ability of a tracker in estimating
every truth. Unlike cardinality measures, time metrics can provide more useful information about
the duration or persistency of estimated tracks.
• Accuracy Measures:
This is the most common measure evaluating the closeness of estimated values to the truths.
Several measures can be deﬁned based on the type of distance between the set of truths and tracks.
For example, the root mean squared error (RMSE) of target estimation is the most common

3.15.11 Simulations—A Multiple Closely-Spaced Target Scenario
799
criterion used in the literature in which a traditional Mahanabolis distance is derived to compute
the error. Some other measures might be also deﬁned based on other types of distances.
To evaluate the quality of the tracking algorithm in track cardinality and state accuracy jointly,
the Optimal Subpattern Assignment (OSPA) metric has been proposed in [107]. The OSPA metric
in [107] is the summation of two terms, one term measures the cardinality error when the number
of tracks is not equal to the number of truth while the other term gives the localization error.
However, the track’s label is not considered in [107], so the OSPA metric in [107] is unable to
measure the track labeling error or the track identity swap. To take into consideration that each
track normally has a label and identity, an extension of the OSPA metric has been proposed in
[102]. Furthermore, by replacing the criterion from minimizing the RMSE to minimizing the
mean OSPA, a new type of multitarget ﬁlters, the set-JPDA ﬁlter and the set-MHT algorithm,
have been proposed in [30,110].
• Available tracks and unknown truths:
This case is very common in real scenarios when there is no information about truths. In this
situation, the consistency of tracking results may be checked. The innovation of tracking is used
as the main source of information and, then, common statistical tests may be made on the received
information. There are also other scoring metrics deﬁned in [21].
Above performance evaluation is mainly discussed for a single sensor case. For a multiple sensor
problem, performance measures may be found separately for each sensor and, afterwards, a ﬁnal metric
is extracted by fusing individual measures. This method is used for the distributed tracking methods
when sensors estimate the state of targets independently. For the centralized case [4], the multiple sensor
can be treated as a single sensor case with a group of unique estimates for targets of interest. The measure
of performance is then found for the estimated states [4].
3.15.11 Simulations—a multiple closely-spaced target scenario
In this subsection, several tracker-related measures of performance are applied to a simulated scenario
in order to demonstrate the application of several multitarget tracking algorithms [40]. The following
tracking algorithms are applied in this subsection:
•
Interactive Multiple Model-Hypothesis-Oriented Multiple Hypothesis Tracker (IMM-HOMHT)
[12].
•
Interactive Multiple Model-Track Oriented Multiple Hypothesis Tracker (IMM-TOMHT) [12].
•
Multiple Model-Gaussian Mixture Probability Hypothesis Density Filter (IMM-GM-PHD) [93].
•
Multiple Model-Cardinalized Gaussian Mixture Probability Hypothesis Density Filter (IMM-GM-
CPHD).
•
Interactive Multiple Model-SD Assignment (IMM-SD) [97].
•
Interactive Multiple Model-Joint Integrated Probability Data Association (IMM-JIPDA) [119].
•
Interactive Multiple Model-2D Assignment (IMM-SD-2D) [97].
Parameters of every tracker are adjusted according to the scenario used for the simulation. An EKF
algorithm is used in the ﬁltering stage of all algorithms. Three different types of motion models are

800
CHAPTER 15 Multitarget Multisensor Tracking
used for the IMM ﬁlter: the Constant Velocity (CV) model, the Constant Acceleration (CA) model and
the Constant Turn (CT) [10] model. Although it is possible that every tracker uses its own selection
of motion models, in order to provide a good comparison here the same models are used as IMM
modes in every trackers. In order to deal with time varying number of targets, m/n logic and track
quality methods are used to initialize new-born targets and delete dead ones [4]. The values of m and
n depend on the scenario and tracking algorithm. Except JIPDA algorithm and PHD ﬁlters that utilize
quality-based method for track management, other methods use m/n logic. Once the estimated tracks
are obtained, the tracking results as well as the truths are both used to calculate performance metrics.
For the PHD and the CPHD ﬁlter, unique tag is attached to each Gaussian component and a JIPDA type
algorithm is used for the track management. For the TOMHT, an enumeration based algorithm is used
to approximately search the best global hypothesis. Table 15.1 summarizes the general parameters that
are common among all scenarios.
A challenging multiple target scenario is used in this section in order to evaluate the performance of
trackers in dealing with closely-spaced targets [55].
Parameters of the simulated scenario are described as follows:
•
Sensors and scenario parameters:
A single sensor is used to generate the measurements of targets. Measurements are gathered in
terms of range and bearing [10]. The variance of the range and bearing measurements are chosen
to be σr = 1.96 × 10−4 (nmi) and σθ = 1 × 10−3 (rad), respectively. Parameters of the underlying
scenario are presented in Table 15.2.
Table 15.1 Common Parameters of Scenarios
Parameter
Description
NMCMC
Number of Monte Carlo runs
NK
Number of scans
NT
Total number of truths
Xs = [xmax
s
y max
s
xmin
s
y min
s
]′
Coverage area of surveillance region
Rmax
Maximum accessible range
PD
Sensor probability of detection
PFA
Probability of false alarm
[m/n]init
[m/n] logic for conﬁrm or delete
[m/n]maint
[m/n] logic for keep or delete
Pq
dc
Deleting conﬁrmed tracks threshold (quality-based)
Pq
dt
Deleting tentative tracks threshold (quality-based)
Pq
c
Track conﬁrmation threshold (quality-based)
Pq
t
Tentative track threshold (quality-based)

3.15.11 Simulations—A Multiple Closely-Spaced Target Scenario
801
Table 15.2 Parameters of the Scenario with Closely-Spaced Targets
Parameter
Value
NMCMC
50
NK
121
NT
10
Xs
[−400 200−400 400] (nmi)
PD
.8
PFA
10−4
•
Target parameters:
Figure 15.3 shows the generated trajectories of targets in the surveillance region. It can be observed
that although all targets are well-separated initially, most of them approach each other in the subse-
quent scans. In other words, there are several crossing targets in this scenario that makes the tracking
problem challenging. Due to the non-maneuvering movement of targets, a CV model is used to
characterize the motion of every target.
•
Trackers:
Table 15.3 presents common parameters for all trackers. Note that PHD algorithm uses quality-
based method for track management where {Pq
dc, Pq
dt, Pq
c , Pq
t } are chosen to be {.005, .01, .8, .25}.
Also, IMM-JIPDA tracker utilizes a quality-based approach for track management with Pq
t = .1,
Pq
c = .9, Pq
dc = .0001, and pq
dt = .001 as the parameters.
The tracking results as well as available truths are used to calculate performance metrics.
Figure 15.4 shows the performance evaluator, which is designed by the ETF Lab, ECE Department,
McMaster University, and this performance evaluator is used in the chapter to calculate and present
metrics. Metrics have been classiﬁed into time, cardinality and accuracy measures.
For graphical interpretations, the results of three metrics are shown in Figures 15.5–15.7. For
the precise deﬁnition of each metric, please refer to [40]. Also, the average results are presented in
Tables 15.4–15.6 for the analysis over every individual tracker. In all tables, T1 to T6 stand for IMM-
SD, IMM-JIPDA, IMM-HOMHT, IMM-TOMHT, IMM-GM-PHD, IMM-GM-CPHD, respectively. It
can be seen that all trackers achieve, relatively the same detection performance in terms of track prob-
ability of detection. From Figure 15.6, it can be concluded that all targets have been well detected by
trackers because measure of completeness shows a value very close to one for all trackers. Note that,
there is no dense clutter area in this scenario. Therefore, the average number of false tracks shows a
small value for all trackers. Nevertheless, the main difﬁculty of this scenario is the presence of crossing
and closely-spaced targets that may affect the continuity measure and number of breaks and swaps.
As the Table 15.4 shows, MHT trackers provide the lowest measure of continuity. It can be seen that
IMM-HOMHT generates the most number of breaks in tracks leading to the lowest continuity measure.
IMM-JIPDA tracker provides results with acceptable number of breaks even though there are many
swaps in the estimated tracks that results in representing IMM-JIPDA as the third-worst tracker in terms
of the continuity measure. These results show that, when using the parameters listed in Table 15.3, MHT
and JIPDA trackers cannot provide satisfactory results compared to SD and PHD trackers, becuase the

802
CHAPTER 15 Multitarget Multisensor Tracking
−200
−150
−100
−50
0
50
50
100
150
200
250
300
350
X (m)
Y (m)
T1
T2
T3
T4
T5
T6
T7
T8
T9
T10
Crossing Region
FIGURE 15.3
Simulated trajectories for closely-spaced target scenario.
Table 15.3 Parameters of Trackers
Parameter
IMM-SD
IMM-HOMHT
IMM-TOMHT
IMM-GM-PHD
IMM-GM-CPHD
IMM-JIPDA
[m/n]init
[3, 4]
[3, 4]
[3, 4]
NAN
NAN
NAN
[m/n]maint
[1, 5]
[1, 5]
[1, 5]
NAN
NAN
NAN
vmax
.6 (m/s)
.6 (m/s)
.6 (m/s)
20 (m/s)
20 (m/s)
20 (m/s)
amax
.02 (m/s2)
.5 (m/s2)
.5 (m/s2)
1 (m/s2)
1 (m/s2)
.5 (m/s2)
v θmax
π
200 (rad/s)
π
20 (rad/s)
π
20 (rad/s)
π
5 (rad/s)
π
5 (rad/s)
π
5 (rad/s)
PG
.99
.75
.75
NAN
NAN
.99
probability of breaks and swaps gets higher due to the presence of closely-spaced targets. Also, the
tables show the superiority of IMM-SD tracker in terms of the majority of metrics over other trackers.
As a conclusion, it can be observed that, with parameters listed in Table 15.3, IMM-SD tracker has
been able to provide the most accurate results with the least number of breaks and swaps in the tested
tracks. MHT and JIPDA cannot track available targets continually although the detection capability
of trackers are still comparable with other trackers. PHD ﬁlters stand between the best tracker and
MHT and JIPDA trackers with satisfactory detection and continuity measures. It should be noted that

3.15.11 Simulations—A Multiple Closely-Spaced Target Scenario
803
FIGURE 15.4
Performance evaluator.
6.08
6.1
6.12
6.14
6.16
6.18
6.2
6.22
6.24
x 104
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
Time (s)
Number of False Tracks
IMM_SD
IMM_JIPDA
IMM_HOMHT
IMM_TOMHT
IMM_GM_PHD
IMM_GM_CPHD
FIGURE 15.5
Average number of false tracks for the closely-spaced targets scenario.

804
CHAPTER 15 Multitarget Multisensor Tracking
6.08
6.1
6.12
6.14
6.16
6.18
6.2
6.22
6.24
x 104
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Time (s)
Measure of Completeness
IMM_SD
IMM_JIPDA
IMM_HOMHT
IMM_TOMHT
IMM_GM_PHD
IMM_GM_CPHD
FIGURE 15.6
Measure of completeness for the closely-spaced targets scenario.
6.08
6.1
6.12
6.14
6.16
6.18
6.2
6.22
6.24
x 104
0.8
1
1.2
1.4
1.6
1.8
2
2.2
2.4
2.6
Time (s)
Position RMSE (nmi)
Target 1 and IMM_SD
Target 2 and IMM_SD
Target 3 and IMM_SD
Target 4 and IMM_SD
Target 5 and IMM_SD
Target 6 and IMM_SD
FIGURE 15.7
Position RMSE for the closely-spaced targets scenario.

3.15.11 Simulations—A Multiple Closely-Spaced Target Scenario
805
Table 15.4 Cardinality Performance Metrics for the Closely-Spaced Targets Scenario
Metric
T1
T2
T3
T4
T5
T6
Measure of completeness
0.973
0.969
0.966
0.967
0.962
0.962
Average number of breaks in tracks
0.5
0.22
6.06
3.86
0.88
0.88
Average number of swaps in tracks
2.02
4.76
3.14
2.62
3.16
3.16
Rate of false alarm
0.00077
0.00054
0.009
0.018
0.0012
0.0012
Average number of false tracks
0.0093
0.0065
0.111
0.214
0.014
0.014
Average number of missed tracks
0.264
0.31
0.344
0.333
0.379
0.379
Average number of spurious tracks
0.003
0.0028
0.086
0.197
0.01
0.01
Average number of valid tracks
9.73
9.69
9.66
9.667
9.62
9.62
Track continuity (%)
88.98
79.44
67.05
74.49
82.13
82.13
Table 15.5 Time Performance Metrics for the Closely-Spaced Targets Scenario
Metric
Unit
T1
T2
T3
T4
T5
T6
Rate of false alarm
1/s
0.00078
0.00054
0.0092
0.018
0.0012
0.0012
Redundant track ratio
NU
0.983
0.983
0.975
0.965
0.974
0.974
Track probability of detection
NU
0.973
0.969
0.966
0.967
0.962
0.962
Track fragmentation
1/s
0.772
1.92
4.042
1.934
1.344
1.344
Conﬁrmed tracks latency (MAX)
s
72
72
72
72
84
84
Conﬁrmed tracks latency (Average)
s
36
44.4
42
42
55.2
55.2
Tracks deletion latency (MAX)
s
0
0
0
0
0
0
Tracks deletion latency (Average)
s
0
0
0
0
0
0
Tentative tracks latency (MAX)
s
48
60
48
48
72
72
Tentative tracks latency (Average)
s
6
27.6
15.6
15.6
39.6
39.6
Total execution time
s
53.621
51.967
47.459
128.555
32.541
32.725
theoretically the IMM-SD tracker can be considered as an implementation of IMM-TOMHT and both
two trackers should provide the same performance. However, the simulation results show that the
IMM-SD tracker works better than the IMM-TOMHT. One explanation is that the global optimal
hypothesis is obtained thorough the enumeration in the current IMM-TOMHT tracker, so there is no
guarantee that the hypothesis found by the current IMM-TOMHT is the real optimal one. On the other
hand, in IMM-SD tracker, Lagrange Relaxation method is used to get an approximated optimal global
hypothesis.

806
CHAPTER 15 Multitarget Multisensor Tracking
Table 15.6 Accuracy Performance Metrics for the Closely-Spaced Targets Scenario
Metric
Unit
T1
T2
T3
T4
T5
T6
Root mean squared error (position)
m
1.133
1.172
1.36
1.285
1.178
1.178
Root mean squared error (velocity)
m/s
0.0906
0.0891
0.0904
0.0905
0.0907
0.0907
Average euclidean error (Position)
m
0.838
0.871
0.973
0.927
0.865
0.865
Average euclidean error (velocity)
m/s
0.0895
0.088
0.0892
0.0893
0.0898
0.0897
Average harmonic error (position)
m
0.239
0.257
0.2706
0.259
0.246
0.246
Average harmonic error (velocity)
m/s
0.0867
0.0852
0.086
0.0864
0.0874
0.0874
Average geometric error (position)
m
0.533
0.556
0.602
0.578
0.547
0.547
Average geometric error (velocity)
m/s
0.0883
0.0868
0.0878
0.088
0.0887
0.0887
Bayesian estimation error quotient
NU
0.432
0.436
0.482
0.464
0.443
0.443
Estimate measurement error ratio
NU
0.00131
0.00131
0.0013
NAN
NAN
Normalized estimation error squared
NU
114.43
107.78
109.55
109.15
112.96
112.96
3.15.12 Summary
In this chapter, various ﬁlters, data-association techniques, multitarget tracking algorithms, multisensor-
multitarget architectures and measures of performance were discussed in detail for the multisensor-
multitarget tracking problem. Various combinations of these algorithms provide a complete tracking
and fusion framework for multisensor networks with application to civilian as well as military problems.
For example, the tracking and fusion techniques discussed here are applicable to ﬁelds like air trafﬁc
control, air/ground/maritime surveillance, mobile communication, transportation, video monitoring and
biomedical imaging/signal processing. Using a scenario with many closely-spaced targets, it was also
shown that the algorithms discussed here are all capable of handling the challenging multitarget tracking
problem.
Relevant Theory: Signal Processing Theory and Machine Learning
See Vol. 1, Chapter 4 Random Signals and Stochastic Processes
See Vol. 1, Chapter 11 Parametric Estimation
See Vol. 1, Chapter 12 Adaptive Filters
See Vol. 1, Chapter 19 A Tutorial Introduction to Monte Carlo Methods, Markov Chain Monte Carlo
and Particle Filtering
References
[1] G.A. Ackerson, K.S. Fu, On state estimation in switching environments, IEEE Trans. Automat. Control 15
(1) (1970) 10–17.
[2] A.T.Alouani,J.E.Gray,D.H.McCabe,Theoryof distributedestimationusingmultipleasynchronous sensors,
IEEE Trans. Aerosp. Electron. Syst. 41 (2) (2005) 717–722.

References
807
[3] M.S. Arulampalam, S. Maskell, N. Gordon, T. Clapp, A tutorial on particle ﬁlters for online nonlinear/non-
Gaussian Bayesian tracking, IEEE Trans. Signal Process. 50 (2) (2002) 174–188.
[4] Y. Bar-Shalom, W.D. Blair, Multitarget/Multisensor Tracking: Applications and Advances, Artech House,
October 2000.
[5] Y. Bar-Shalom, Airborne GMTI radar position bias estimation using static-rotator targets of opportunity,
IEEE Trans. Aerosp. Electron. Syst. 37 (2) (2001) 695–699.
[6] Y. Bar-Shalom,Dimensionless scorefunction for multiple hypothesis tracking, IEEE Trans. Aerosp. Electron.
Syst. 43 (1) (2007) 392–400.
[7] Y. Bar-Shalom, S. Challa, H.A.P. Blom, IMM estimator versus optimal estimator for hybrid systems, IEEE
Trans. Aerosp. Electron. Syst. 41 (3) (2005) 986–991.
[8] Y. Bar-Shalom, H. Chen, Multisensor track-to-track association for tracks with dependent errors, J. Adv.
Inform. Fusion 1 (1) (2006) 3–14.
[9] Y. Bar-Shalom, P. Willett, X. Tian, Tracking and Data Fusion: A Handbook of Algorithm, YBS Publishing,
Storrs, CT, 2011.
[10] Y. Bar-Shalom, X.R. Li, T. Kirubarajan, Estimation with Applications to Tracking and Navigation, Wiley,
2001.
[11] Y. Bar-Shalom, T. Kirubarajan, C. Gokberk, Tracking with classiﬁcation-aided multiframe data association,
IEEE Trans. Aerosp. Electron. Syst. 41 (3) (2005) 868–878.
[12] S.S. Blackman, Multiple hypothesis tracking for multiple target tracking, IEEE Aerosp. Electron. Syst. Mag.
19 (1, Part 2) (2004) 5–18.
[13] S. S. Blackman, R. Popoli, Design and Analysis of Modern Tracking Systems, Artech House, 1999.
[14] W.D. Blair, G.A. Watson, T. Kirubarajan, Y. Bar-Shalom, Benchmark for radar resource allocation and
tracking in the presence of ECM, IEEE Trans. Aerosp. Electron. Syst. 34 (4) (1998) 1097–1114.
[15] H.A.P. Blom, A sophisticated tracking algorithm for ATC surveillance data, in: Proceedings of the Interna-
tional Radar Conference, Paris, May 1984, pp. 393–398.
[16] H.A.P.
Blom,
Y.
Bar-Shalom,
The
interacting
multiple
model
algorithm
for
systems
with
Markovian switching coefﬁcients, IEEE Trans. Automat. Control 33 (8) (1988) 780–783.
[17] A. Capponi, H.W. De Waard, A mean track approach applied to the multidimensional assignment problem,
IEEE Trans. Aerosp. Electron. Syst. 43 (2) (2007) 450–471.
[18] C.B. Chang, M. Athans, State estimation for discrete system with switching parameters, IEEE Trans. Aerosp.
Electron. Syst. 14 (3) (1978) 418–425.
[19] H. Chen, T. Kirubarajan, Y. Bar-Shalom, Performance limits of track-to-track fusion versus centralized
estimation: theory and application, IEEE Trans. Aerosp. Electron. Syst. 39 (2) (2003) 386–400.
[20] K.C. Chang, S. Mori, C.Y. Chong, Evaluating a multiple-hypothesis multitarget tracking algorithm, IEEE
Trans. Aerosp. Electron. Syst. 30 (2) (1994) 578–590.
[21] K.C. Chang, X. Zhao, A greedy assignment algorithm and its performance evaluation, in: Proceedings of
American Control Conference, Seattle, USA, June 1995.
[22] K.C. Chang, R.K. Saha, Y. Bar-Shalom, On optimal track-to-track fusion, IEEE Trans. Aerosp. Electron.
Syst. 33 (4) (1997) 1271–1276.
[23] X. Chen, R. Tharmarasa, M. Pelletier, T. Kirubarajan, Integrated clutter estimation and tar-
get tracking using Poisson point processes, IEEE Trans. Aerosp. Electron. Syst. 48 (2) (2012)
1210–1235.
[24] C.Y. Chong, Distributed architectures for data fusion, in: Proceedings of the First International Conference
on Information Fusion, Las Vegas, NV, August 1998.
[25] C.Y. Chong, S. Mori, Convex combination and covariance intersection algorithms in distributed fusion, in:
Proceedings of the Fourth International Conference on Information Fusion, Montreal, QC, Canada, August
2001.

808
CHAPTER 15 Multitarget Multisensor Tracking
[26] C.Y. Chong, S. Mori, Distributed fusion and communication management for target identiﬁcation, in: Pro-
ceedings of the Eighth International Conference on Information Fusion, Philadelphia, PA, July 2005.
[27] M.R. Chummun, T. Kirubarajan, K.R. Pattipati, Y. Bar-Shalom, Fast data association using multidimensional
assignment with clustering, IEEE Trans. Aerosp. Electron. Syst. 37 (3) (2001) 898–913.
[28] C.I. Coman, T. Kreitmair, Evaluation of the tracking process in ground surveillance applications, in: Pro-
ceedings of the Sixth European Radar Conference, Rome, Italy, September 2009.
[29] S. Coraluppi, D. Grimmett, P. de Theije, Benchmark evaluation of multistatic trackers, in: Proceedings of
the Sixth International Conference on Information Fusion, Florance, Italy, July 2006.
[30] D.F. Crouse, P. Willett, L. Svensson, D. Svensson, M. Guerriero, The set MHT, in: Proceedings of the 14th
International Conference on Information Fusion, Chicago, IL, July 2011.
[31] F. Daum, Nonlinear ﬁlters: beyond the Kalman ﬁlter, IEEE Aerosp. Electron. Syst. Mag. 20 (8, Part 2) (2005)
57–69.
[32] S. Deb, M. Yeddanapudi, K.R. Pattipati, Y. Bar-Shalom, A generalized S-dimensional assignment for
multisensor-multitarget state estimation, IEEE Trans. Aerosp. Electron. Syst. 33 (2) (1997) 523–538.
[33] A. Doucet, N. de Freitas, N. Gordon, Sequential Monte Carlo Methods in Practice, Springer-Verlag, New
York, 2001.
[34] O.E. Drummond, A hybrid sensor fusion algorithm architecture and tracklets, in: Proceedings of SPIE
Conference on Signal and Data Processing of Small Targets, San Diego, CA, vol. 3163, July 1997, pp.
485–502.
[35] O.E. Drummond, Track and tracklet fusion ﬁltering using data from distributed sensors, in: Proceedings of
Estimation, Tracking and Fusion: A Tribute to Yaakov Bar-Shalom, Monterey, CA, May 2001, pp. 167–186.
[36] H. Durrant-Whyte, M. Stevens, Data fusion in decentralised sensing networks, in: Proceedings of the Fourth
International Conference on Information Fusion, Montreal, QC, Canada, August 2001.
[37] D. Fränken, A. Hüpper, Improved fast covariance intersection for distributed data fusion, in: Proceedings of
the Seventh International Conference on Information Fusion, Stockholm, Sweden, July 2005.
[38] N.J. Gordon, D.J. Salmond, A.F.M. Smith, Novel approach to nonlinear/non-Gaussian Bayesian state esti-
mation, IEE Proc. Radar Signal Process. 140 (2) (1993) 107–113.
[39] N.J. Gordon, B. Ristic, M. Robinson, Performance bounds for recursive sensor registration, in: Proceedings
of the Sixth International Conference on Information Fusion, Cairns, Australia, July 2003.
[40] A.A. Gorji, R. Tharmarasa, T. Kirubarajan, Performance measures for multiple target tracking problems, in:
Proceedings of 14th International Conference on Information Fusion, Chicago, US, July 2011.
[41] D. Grimmett, S. Coraluppi, B.R. La Cour, C.G. Hempel, T. Lang, P.A.M. de Theije, P. Willett, MSTWG
multistatic tracker evaluation using simulated scenario data sets, in: Proceedings of the 11th International
Conference on Information Fusion, Cologne, Germany, September 2008.
[42] K. Harishan, R. Tharmarasa, T. Kirubarajan, T. Thayaparan, Automatic track initialization and maintenance
in heavy clutter using integrated JPDA and ML-PDA algorithms, in: Proceedings of SPIE Conference on
Signal and Data Processing of Small Targets, San Diego, CA, vol. 8137, September 2011.
[43] T. Hanselmann, D. Mu˘sicki, M. Palaniswami, Adaptive target tracking in slowly changing clutter, in: Pro-
ceedings of the Ninth International Conference on Information Fusion, Florence, Italy, July 2006.
[44] M.L. Hernandez, A.D. Marrs, N.J. Gordon, S.R. Maskell, C.M. Reed, Cramér-Rao bounds for non-linear
ﬁltering with measurement origin uncertainty, in: Proceedings of the Fifth International Conference on
Information Fusion, Annapolis, USA, 2002.
[45] M.L. Hernandez, T. Kirubarajan, Y. Bar-Shalom, Multisensor resource deployment using posterior Cramér-
Rao bounds, IEEE Trans. Aerosp. Electron. Syst. 40 (2) (2004) 399–416.
[46] M.L. Hernandez, B. Ristic, A. Farina, L. Timmoneri, A comparison of two Cramér-Rao lower bounds for
nonlinear ﬁltering with Pd < 1, IEEE Trans. Signal Process. 52 (9) (2004) 2361–2370.

References
809
[47] M.L.
Hernandez,
A.
Farina,
B.
Ristic,
A
PCRLB
for
tracking
in
cluttered
environments:
measurement sequence conditioning approach, IEEE Trans. Aerosp. Electron. Syst. 42 (2) (2006) 680–704.
[48] M.L. Hernandez, B. Ristic, A. Farina, T. Sathyan, T. Kirubarajan, Performance measure for Markovian
switching systems using best-ﬁtting Gaussian distributions, IEEE Trans. Aerosp. Electron. Syst. 44 (2)
(2008) 724–747.
[49] C. Hue, J.P. Le Cadre, P. Pérez, Performance analysis of two sequential Monte Carlo methods and poste-
rior Cramér-Rao bounds for multitarget tracking, in: Proceedings of the Fifth International Conference on
Information Fusion, Annapolis, MD, vol. 1, July 2002, pp. 464–473.
[50] L.A. Johnston, V. Krishnamurthy, Performance evaluation of a dynamic programming track before detect
algorithm, IEEE Trans. Aerosp. Electron. Syst. 38 (1) (2002) 228–242.
[51] S.S. Julier, J.K. Uhlmann, A non-divergent estimation algorithm in the presence of unknown correlations,
in: Proceedings of American Control Conference, Albuquerque, New Mexico, June 1997.
[52] S.J. Julier, J.K. Uhlmann, A new extension of the Kalman ﬁlter to nonlinear systems, in: Proceedings of
SPIE Conference on Signal Processing, Sensor Fusion and Target Recognition VI, Orlando, FL, vol. 3068,
April 1997, pp. 182–193.
[53] R.E. Kalman, A new approach to linear ﬁltering and prediction problems, Trans. ASME — J. Basic Eng. 82
(1960) 34–45.
[54] K. Kastella, B. Yeary, T. Zadra, R. Brouillard, E. Frangione, Bias modeling and estimation for GMTI
applications, in: Proceedings of the Third International Conference on Information Fusion, Paris, France,
July 2000.
[55] T. Kirubarajan, Y. Bar-Shalom, R. McAllister, R. Schutz, B. Engelberg, Multitarget tracking using an IMM
estimator with debiased E-2C measurements for AEW systems, in: Proceedings of the Second International
Conference on Information Fusion, Sunnyvale, CA, July 1999.
[56] T. Kirubarajan, Y. Bar-Shalom, Kalman ﬁlter versus IMM estimator: when do we need the latter? IEEE
Trans. Aerosp. Electron. Syst. 39 (4) (2003) 1452–1457.
[57] T. Kirubarajan, Y. Bar-Shalom, Probabilistic data association techniques for target tracking in clutter, Proc.
IEEE 92 (3) (2004) 536–557.
[58] T. Kirubarajan, Y. Bar-Shalom, D. Lerro, Bearings-only tracking of maneuvering targets using a batch-
recursive estimator, IEEE Trans. Aerosp. Electron. Syst. 37 (3) (2001) 770–780.
[59] T.
Kirubarajan,
H.
Wang,
Y.
Bar-Shalom,
K.R.
Pattipati,
Efﬁcient
multisensor
fusion
using
multidimensional data association, IEEE Trans. Aerosp. Electron. Syst. 37 (2) (2001) 386–400.
[60] C. Kreucher, K. Kastella, A.O. Hero III, Multitarget tracking using the joint multitarget probability density,
IEEE Trans. Aerosp. Electron. Syst. 41 (4) (2005) 1396–1414.
[61] T. Lefebvre, H. Bruyninckx, J. De Schutter, Kalman ﬁlters for non-linear systems: a comparison of perfor-
mance, Int. J. Control 77 (2004) 639–653.
[62] M.E. Liggins, C.Y. Chong, I. Kadar, M.G. Alford, V. Vannicola, S. Thomopoulos, Distributed fusion archi-
tectures and algorithms for target tracking, Proc. IEEE 85 (1) (1997) 95–107.
[63] L. Lin, Y. Bar-Shalom, T. Kirubarajan, New assignment-based data association for tracking move-stop-move
targets, IEEE Trans. Aerosp. Electron. Syst. 40 (2) (2004) 714–725.
[64] X. Lin, T. Kirubarajan, Y. Bar-Shalom, Multisensor bias estimation with local tracks without a priori associ-
ation, in: Proceedings of SPIE Conference on Signal and Data Processing of Small Targets, San Diego, CA,
vol. 5204, August 2003.
[65] X.R. Li, Y. Bar-shalom, Performance prediction of interacting multiple model algorithm, IEEE Trans. Aerosp.
Electron. Syst. 29 (3) (1993).
[66] X.R. Li, Z. Zhao, Evaluation of estimation algorithms. Part I: Incomprehensive measures of performance,
IEEE Trans. Aerosp. Electron. Syst. 42 (5) (2006) 1340–1358.

810
CHAPTER 15 Multitarget Multisensor Tracking
[67] X.R. Li, N. Li, Integrated real-time estimation of clutter density for tracking, IEEE Trans. Signal Process.
48 (10) (2000) 2797–2805.
[68] N. Li, X.R. Li, Target perceivability and its applications, IEEE Trans. Signal Process. 49 (11) (2001) 2588–
2604.
[69] X.R. Li, V. Jilkov, Survey of maneuvering target tracking. Part III. Measurement models, in: Proceedings of
SPIE Conference on Signal and Data Processing of Small Targets, San Diego, CA, vol. 4473, July 2001.
[70] X.R. Li, V. Jilkov, Survey of maneuvering target tracking. Part IV. Decision-based methods, in: Proceedings
of SPIE Conference on Signal and Data Processing of Small Targets, Orlando, FL, vol. 4728, April 2002.
[71] X.R. Li, V. Jilkov, Survey of maneuvering target tracking. Part I. Dynamic models, IEEE Trans. Aerosp.
Electron. Syst. 39 (4) (2003) 1333–1364.
[72] X.R. Li, V. Jilkov, Survey of maneuvering target tracking. Part V. Multiple-model methods, IEEE Trans.
Aerosp. Electron. Syst. 41 (4) (2005) 1255–1321.
[73] X.R. Li, V. Jilkov, Survey of maneuvering target tracking. Part II. Motion models of ballistic and space
targets, IEEE Trans. Aerosp. Electron. Syst. 46 (1) (2010) 96–119.
[74] X. Lin, Y. Bar-Shalom, T. Kirubarajan, Multisensor multitarget bias estimation for general asynchronous
sensors, IEEE Trans. Aerosp. Electron. Syst. 41 (3) (2005) 899–921.
[75] R. Mahler, An Introduction to Multisensor-Multitarget Statistics and its Application, Lockheed Martin Tech-
nical Monograph, 2000.
[76] R. Mahler, Multi-target moments and their application to multi-target tracking, in: Proceedings of the Work-
shop on Estimation, Tracking and Fusion: A Tribute to Yaakov Bar-Shalom, Monterey, CA, 2001, pp.
134–166.
[77] R. Mahler, Random set theory for target tracking and identiﬁcation, in: D.L. Hall, J. Lindas (Eds.), Handbook
of Multisensor Data Fusion, CRC Press, Boca Raton, FL, 2002 (Chapter 14).
[78] R. Mahler, Multitarget bayes ﬁltering via ﬁrst-order multitarget moments, IEEE Trans. Aerosp. Electron.
Syst. 39 (4) (2003) 1152–1178.
[79] R. Mahler, PHD ﬁlter of higher order in target number, IEEE Trans. Aerosp. Electron. Syst. 43 (4) (2007)
1523–1541.
[80] R. Mahler, The multisensor PHD ﬁlter: I. General solution via multitarget calculus, in: Proceedings of SPIE
Conference on Signal Processing, Sensor Fusion and Target Recognition XVIII, Orlando, FL, vol. 7336,
April 2009.
[81] R. Mahler, CPHD and PHD ﬁlters for unknown backgrounds. I: Dynamic data clustering, in: Proceedings of
SPIE Conference on Sensors and Systems for Space Applications III, Orlando, FL, USA, vol. 7330, 2009.
[82] R. Mahler, CPHD and PHD ﬁlters for unknown backgrounds. II: Multitarget ﬁltering in dynamic clutter, in:
Proceedings of SPIE Conference on Sensors and Systems for Space Applications III, Orlando, FL, USA,
vol. 7330, 2009.
[83] R.Mahler,ApproximatemultisensorCPHDandPHDﬁlters,in:Proceedingsof10thInternationalConference
on Information Fusion, Edinburgh, UK, July 2010.
[84] M. Mallick, B.L. Scala, Comparison of single-point and two-point difference track initiation algorithms
using position measurements, Acta Automat. Sinica 34 (3) (2008) 258–265.
[85] D. Mušicki, R. Evans, S. Stankovic, Integrated probabilistic data association, IEEE Trans. Automat. Control
39 (6) (1994) 1237–1241.
[86] D. Mušicki, R. Evans, Joint integrated probabilistic data association: JIPDA, IEEE Trans. Aerosp. Electron.
Syst. 40 (3) (2004) 1093–1099.
[87] D. Mušicki, S. Suvorova, M. Morelande, B. Mora, Clutter map and target tracking, in: Proceedings of Eighth
International Conference on Information Fusion, Wyndham Philadelphia, PA, USA, July 2005, pp. 69–76.
[88] D. Mušicki, R. Evans, Multiscan multitarget tracking in clutter with integrated track splitting ﬁlter, IEEE
Trans. Aerosp. Electron. Syst. 45 (4) (2009) 1432–1447.

References
811
[89] W. Niehsen, Information fusion based on fast covariance intersection ﬁltering, in: Proceedings of the Fifth
International Conference on Information Fusion, Annapolis, Washington DC Area, July 2002.
[90] N. Okello, B. Ristic, Maximum likelihood registration for multiple dissimilar sensors, IEEE Trans. Aerosp.
Electron. Syst. 39 (3) (2003) 1074–1083.
[91] K. Panta, D.E. Clarak, B.N. Vo, Data association and track management for the Gaussian mixture probability
hypothesis density ﬁlter, IEEE Trans. Aerosp. Electron. Syst. 45 (3) (2009) 1003–1016.
[92] G.W. Pulford, Taxonomy of multiple target tracking methods, Proc. IEE Radar Sonar Navig. 152 (5) (2005)
291–304.
[93] S.A. Pasha, B.N. Vo, W.K. Ma, A Gaussian mixture PHD ﬁlter for jump Markov system models, IEEE Trans.
Aerosp. Electron. Syst. 45 (3) (2009) 919–936.
[94] K.R. Pattipati, S. Deb, Y. Bar-Shalom, R.B. Washburn, A new relaxation algorithm and passive sensor data
association, IEEE Trans. Automat. Control 37 (2) (1992) 198–213.
[95] K.R. Pattipati, T. Kirubarajan, R.L. Popp, Survey of assignment techniques for multitarget tracking, in: Pro-
ceedings of the Workshop on Estimation, Tracking, and Fusion: A Tribute to Yaakov Bar-Shalom, Monterey,
CA, May 2001.
[96] R.L. Popp, K.R. Pattipati, Y. Bar-Shalom, Dynamically adaptable m-best 2D assignment and multi-level
parallelization, IEEE Trans. Aerosp. Electron. Syst. 35 (4) (1999) 1145–1160.
[97] R.L. Popp, T. Kirubarajan, K.R. Pattipati, Survey of assignment techniques for multitarget tracking, in: Y.
Bar-Shalom, W.D. Blair (Eds.), Multitarget/Multisensor Tracking: Applications and Advances III, Artech
House, 2000 (Chapter 2 ).
[98] K. Punithakumar, T. Kirubarajan, A. Sinha, Multiple-model probability hypothesis density ﬁlter for tracking
maneuvering targets, IEEE Trans. Aerosp. Electron. Syst. 44 (1) (2008) 87–98.
[99] K. Panta, V. Ba-Ngu, S. Singh, Novel data association schemes for the probability hypothesis density ﬁlter,
IEEE Trans. Aerosp. Electron. Syst. 43 (2) (2007) 556–570.
[100] B. Ristic, S. Arulampalam, N. Gordon, Beyond the Kalman Filter: Particle Filters for Tracking Applications,
Artech House Publishers, 2004.
[101] B. Ristic, S. Zollo, S. Arulampalam, Performance bounds for maneuvering target tracking using asyn-
chronous multi-platform angle-only measurements, in: Proceedings of the Fourth International Conference
on Information Fusion, Montreal, Quebec, August 2001.
[102] B. Ristic, B.-N. Vo, D. Clark, B.-T. Vo, A metric for performance evaluation of multi-target tracking algo-
rithms, IEEE Trans. Signal Process. 59 (7) (2011) 3452–3457.
[103] R. Rothrock, O.E. Drummond, Performance metrics for multiple-sensor, multiple-target tracking, in: Pro-
ceedings of SPIE Conference on Signal and Data Processing of Small Targets, Orlando, USA, July 2000.
[104] M. Ridley, E. Nettleton, S. Sukkarieh, H. Durrant-Whyte, Tracking in decentralised air-ground sensing, in:
Proceedings of the Fifth International Conference on Information Fusion, Annapolis, MD, August 2002.
[105] S. Sarkka, On unscented Kalman ﬁltering for state estimation of continuous-time nonlinear systems, IEEE
Trans. Automat. Control 52 (9) (2007) 1631–1641.
[106] T. Sathyan, A. Sinha, T. Kirubarajan, Computationally efﬁcient assignment-based algorithms for data associ-
ation for tracking with angle-only sensors, in: Proceedings of SPIE Conference on Signal and Data Processing
of Small Targets, San Diego, CA, vol. 6699, August 2007.
[107] D. Schuhmacher, B.-T. Vo, B.-N. Vo, A consistent metric for performance evaluation of multi-object ﬁlters,
IEEE Trans. Signal Process. 56 (8) (2008) 3447–3457.
[108] D. Schuhmacher, B.-T. Vo, B.-N. Vo, On performance evaluation of multi-object ﬁlters, in: Proceedings of
the 13th International Conference on Information Fusion, Edinburgh, Scotland, July 2010.
[109] L. Svensson, On Bayesian Cramér-Rao bound for Markovian switching systems, IEEE Trans. Signal Process.
58 (9) (2010) 4507–4516.
[110] L. Svensson, D. Svensson, M. Guerriero, P. Willett, Set JPDA ﬁlter for multitarget tracking, IEEE Trans.
Signal Process 59 (10) (2011) 4677–4691.

812
CHAPTER 15 Multitarget Multisensor Tracking
[111] P.J. Shea, T. Zadra, D. Klamer, E. Frangione, R. Brouilard, K. Kastella, Precision tracking of ground targets,
in: Proceedings of IEEE Aerospace Conference, Big Sky, MT, March 2000.
[112] H. Sidenbladh, Multi-target particle ﬁltering for the probability hypothesis density, in: Proceedings of the
Sixth International Conference on Information Fusion, vol. 2, July 2003, pp. 800–806.
[113] D.Smith,S.Singh,Approachestomultisensordatafusionintargettracking:asurvey,IEEETrans.Knowledge
Data Eng. 18 (12) (2006) 1696–1710.
[114] R. Tharmarasa, T. Kirubarajan, M.L. Hernandez, Large-scale optimal sensor array management for multi-
target tracking, IEEE Trans. Syst. Man Cybernet. 37 (5) (2007) 803–814.
[115] R. Tharmarasa, T. Kirubarajan, M.L. Hernandez, A. Sinha, PCRLB-based multisensor array management
for multitarget tracking, IEEE Trans. Aerosp. Electron. Syst. 43 (2) (2007) 539–555.
[116] P. Tichavsky, C.H. Muravchik, A. Nehorai, Posterior Cramér-Rao bounds for discrete-time nonlinear ﬁltering,
IEEE Trans. Signal Process. 46 (5) (1998) 1386–1396.
[117] H. Van Trees, Detection, Estimation and Modulation Theory, vol. I, Wiley, New York, 1968.
[118] B.A. van Doorn, H.A.P. Blom, Systematic error estimation, in multisensor fusion systems, in: Proceedings
of SPIE Conference on Signal and Data Processing of Small Targets, Orlando, FL, April 1993.
[119] J. Vermaak, S.J. Godsill, P. Perez, Monte Carlo ﬁltering for multi-target tracking and data association, IEEE
Trans. Aerosp. Electron. Syst. 41 (1) (2005) 309–322.
[120] B.-N. Vo, S. Singh, A. Doucet, Sequential Monte Carlo implementation of the PHD ﬁlter for multi-target
tracking, in: Proceedings of the Sixth International Conference on Information Fusion, vol. 2, July 2003, pp.
792–799.
[121] B.-N. Vo, W.K. Ma, The Gaussian mixture probability hypothesis density ﬁlter, IEEE Trans. Aerosp. Electron.
Syst. 54 (11) (2006) 4091–4104.
[122] B.-T. Vo, B.-N. Vo, A. Cantoni, Analytic implementations of the cardinalized probability hypothesis density
ﬁlter, IEEE Trans. Aerosp. Electron. Syst. 55 (7) (2007) 3553–3567.
[123] E.A. Wan, R. van der Merwe, The unscented Kalman ﬁlter, for nonlinear estimation, in: Proceedings of
IEEE, Adaptive Systems for Signal Processing, Communications, and Control Symposium, Alberta, Canada,
October 2000.
[124] H. Wang, T. Kirubarajan, Y. Bar-Shalom, Precision large scale air trafﬁc surveillance using an IMM estimator
with assignment, IEEE Trans. Aerosp. Electron. Syst. 35 (1) (1999) 255–266.
[125] X. Wang, D. Musicki, Evaluation of IPDA type ﬁlters with a low elevation sea-surface target tracking, in:
Proceedings of the Sixth International Conference on Information Fusion, Queensland, Australia, May 2003.
[126] N. Xiong, P. Svensson, Multi-sensor management for information fusion: issues and approaches, Inform.
Fusion 3 (1) (2002) 163–186.
[127] H. You, Z. Jingwei, New track correlation algorithms in a multisensor data fusion system, IEEE Trans.
Aerosp. Electron. Syst. 42 (4) (2006) 1359–1371.
[128] R. Zhan, J. Wan, Iterated unscented Kalman ﬁlter for passive target tracking, IEEE Trans. Aerosp. Electron.
Syst. 43 (3) (2007) 1155–1163.

16
CHAPTER
Passive Bistatic Radar
Hugh Grifﬁths
University College London, London, UK
Nomenclature
Principal symbols
A
target silhouette area (m2)
AR
radial component of target acceleration (m s−2)
a
target dimension (m)
B
receiver effective bandwidth (Hz)
b
target dimension (m)
c
scale parameter of compound K-distribution clutter model
F
receiver effective noise ﬁgure (dB)
Ft
pattern propagation factor for transmitter-to-target path
fD
Doppler shift of received echo (Hz)
G p
processing gain (dB)
Gr
receive antenna gain (dBi)
Gt
transmit antenna gain (dBi)
k
Boltzmann’s constant (1.38 × 10−23 J K−1)
L
bistatic baseline (m)
N
number of expected targets
Pd
probability of detection
Pdirect
direct signal power (W)
Pn
receiver noise power (W)
Pr
received target echo power (W)
Pt
transmit power (W)
RT
transmitter-to-target range (m)
RR
target-to-receiver range (m)
s(t)
transmitted signal
T
update interval (s)
T0
noise reference temperature, 290 K
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-396500-4.00016-8
© 2014 Elsevier Ltd. All rights reserved.
813

814
CHAPTER 16 Passive Bistatic Radar
TR
range delay (s)
v
target velocity (m s−1)
wi,k
particle weight
(xi yi)
particle location
(˙xi ˙yi)
particle velocity
β
bistatic angle
δ
angle of target velocity with respect to bistatic bisector
θ1
elevation angle of transmitter
θ2
elevation angle of receiver
θB
angular width of forward scatter
θR
angle of arrival of received echo
λ
wavelength (m)
v
shape parameter of compound K-distribution clutter model
σB
target bistatic radar cross section (m2)
σ ◦
B
bistatic scattering coefﬁcient (m2/m2)
σFS
forward scatter radar cross section (m2)
ξ
particle vector

power density at target (Wm−2)
	
output of matched ﬁlter
2.16.1 Introduction
Passive bistatic radar (PBR) is the name given to a bistatic radar system that makes use of emissions from
broadcast, communications or radionavigation transmitters rather than a dedicated, co-operative radar
transmitter. The history of the subject goes back a long way; some of the very ﬁrst radar experiments
(such as the famous Daventry Experiment in 1935 [2]) were of this kind, and in fact the “ghosting”
effect on analog television receivers due to aircraft targets, which is a manifestation of PBR, was noticed
as early as 1938 [3].
The term passive bistatic radar deserves some explanation. Other terms that have been used include
PassiveCoherentLocation(PCL),ParasiticRadar,PassiveRadar,PassiveCovertRadar,andPiggyback
Radar.Fordifferentreasonsnoneoftheseseemscompletelysatisfactory,sowehaveusedpassivebistatic
radar throughout.
To complete the deﬁnitions, a hitchhiker is a bistatic radar which uses an existing monostatic radar
as a transmitter of opportunity. There are some signiﬁcant differences from passive bistatic radars, since
the signals are usually pulsed and the transmit radiation pattern is usually directional, and scanning in
azimuth. Nevertheless, some of the systems described in this chapter will be examples of hitchhikers
rather than strictly passive bistatic radars.
Modern interest in the subject dates back to the 1980s, when a number of systems based on UHF
television or VHF FM radio transmissions were built and evaluated [4,5]. Since then interest has grown
steadily, as evidenced by the increasing number of publications in research journals and at conferences.

2.16.1 Introduction
815
The subject has been especially suitable for research by university groups, since the hardware required
for an experimental system is simple and low cost, and there are no licensing issues because the
transmitter sources already exist. As well as this, such sources tend to be high power and sited to give
wide coverage. PBR may also allow VHF and UHF frequencies to be used which are not normally
available for radar, and where in a defense context there may be an advantage against stealthy targets
compared to conventional microwave radar frequencies. Finally, provided the receiver antennas are
inconspicuous the system is completely covert, and so it is difﬁcult to deploy countermeasures against
PBR receivers, since if the location of the receiver is not known any jamming has to be spread over a
range of angles, diluting its effectiveness.
PBR can be thought of as ﬁtting into the overall subject of Waveform Diversity, since the waveforms
of broadcast, communications and radionavigation sources are not explicitly designed for radar use
and so may be far from optimum for radar purposes. It is therefore necessary to understand the effect
of the waveform on the performance of the passive bistatic radar, so as to be able to choose the most
appropriate illuminator, and to process the waveform in the optimal way [6,7].
As well as waveform selection and processing, current areas of research include the development of
processing techniques to exploit digital modulation formats, which are replacing analog modulation in
many applications and in many countries. Also, it is found that the signal and interference environment,
especially in cities, where the density of transmitters is high, is severe in terms of the number and level
of signals. This means that appropriate processing techniques are required to suppress this background
to a level sufﬁcient to allow target detection. Finally, advances are being made in tracking algorithms,
and in radar imaging. These themes are investigated further in the sections that follow.
Despite the attractions noted above, there have been rather few applications where PBR has been
able to demonstrate sufﬁcient advantage to justify practical deployment. Most applications, though not
all, have been concerned with air surveillance.
Some applications where PBR may be able to demonstrate an advantage include low-cost scientiﬁc
measurements of the ionosphere [8,9], planets [10], wind [11,12], or thunderstorms [13]. PBR has also
been proposed as a gap ﬁller where coverage of conventional air surveillance radars is compromised,
for example by wind turbines [14]. Two commercial PBR systems that have been built are Lockheed
Martin’s Silent SentryTM [15] and Thales’s HA-100 Homeland Alerter [82]. Nevertheless, the challenge
to PBR systems remains to identify and exploit applications where there is a clear advantage in terms
of performance and/or cost.
Furthermore, the electromagnetic spectrum represents a ﬁnite resource with many different appli-
cations, of which radar is only one, competing for frequency allocation. The only thing that can be
said with certainty is that this problem of spectrum congestion will only get worse. So there is great
motivation and scope for techniques which use the spectrum in a more intelligent and adaptive manner
[16], and PBR represents one such technique. In that sense PBR has been described as “green radar,”
since it does not generate any electromagnetic pollution. It may ultimately be that broadcast and com-
munications signals may be devised also to optimize their performance as PBR illuminators, as well as
for their primary purpose.
This chapter assumes familiarity with basic signal waveform and processing theory. Suitable back-
ground may be found in Refs. [17–19]. More detailed information on bistatic radar in general may be
found in Refs. [20–24].

816
CHAPTER 16 Passive Bistatic Radar
2.16.2 Bistatic radar
Bistatic radar is deﬁned as a radar in which the transmitter and receiver are at separate locations, sufﬁ-
ciently separated that the properties are signiﬁcantly different to those of a monostatic radar. This section
provides a review of these properties. Many are a consequence of the bistatic geometry [25], which is
shown in plane form in Figure 16.1. The transmitter and receiver are separated by a distance L, known
as the bistatic baseline. The angle at the target subtended by the transmitter and receiver is the bistatic
angle, β. The range from the transmitter to the target is RT and the range from the target to the receiver
is RR. The target direction at the transmitter and receiver, measured with respect to North, are given by
θT and θR respectively. The target velocity is v, in a direction which makes an angle δ with respect to
the bisector of the bistatic angle.
Usually the locations of the transmitter and receiver, and hence the baseline L, are known and the
quantities that can be measured for a given target at the receiver are (i) the difference in delay between
receipt of the direct signal from the transmitter and the target echo, which provides the bistatic range
sum (RT + RR), (ii) the direction of arrival of the target echo θR, and (iii) the Doppler shift fD of the
target echo. The range of the target from the receiver can be deduced from
RR =

RT + RR
2 −L2
2

RT + RR + L sin θR

(16.1)
FIGURE 16.1
Bistatic radar geometry.

2.16.3 Bistatic Radar Equation
817
The Doppler shift fD is given by the rate of change of the bistatic range sum
fD = 1
λ
d
dt

RT + RR

(16.2)
In the simplest case where the transmitter and receiver are both stationary and only the target is moving
dRT
dt
= v cos

δ −β
2

and
dRR
dt
= v cos

δ + β
2

(16.3)
so that
fD = 2v
λ

cos δ cos β
2

(16.4)
It can be seen that at the point at which the target is crossing the baseline, β = 180◦and so fD = 0.
This can be appreciated since for such a target the transmitter-to-target range is changing in an equal
and opposite way to the target-to-receiver range. Furthermore, the echo arrives at the receiver at the
same instant as the direct signal from the transmitter, irrespective of the location of the target on the
baseline. This means that for a target on the baseline the bistatic radar provides neither range nor Doppler
information. Nevertheless, this conﬁguration, which is known as forward scatter, has some attractive
properties in respect of target RCS enhancement. These are explained in Section 2.16.4.
2.16.3 Bistatic radar equation
In its simplest form the radar equation for a bistatic radar is derived in the same way as that for a
monostatic radar:
Pr
Pn
= PtGt
4π R2
T
· σB ·
1
4π R2
R
· Grλ2
4π
·
1
kT0BF
(16.5)
in which Pr is the received target echo power; Pn is the receiver noise power; Pt is the transmit power;
Gt is the transmit antenna gain; RT is the transmitter-to-target range; σB is the target bistatic radar cross
section; RR is the target-to-receiver range; Gr is the receive antenna gain; λ is the signal wavelength;
k is Boltzmann’s constant = 1.38 × 10−23 J K−1; T0 is the noise reference temperature, 290 K; B is the
receiver effective bandwidth; and F is the receiver effective noise ﬁgure.
This basic equation can be modiﬁed to include the effect of losses, the pattern propagation factors
associated with the transmitter-to-target and target-to-receiver paths, and of integration gain.
We can note that the numerator includes the transmit and receive antenna gains individually, and that
the denominator includes the factor 1/R2
T R2
R. This latter factor means that, for omnidirectional transmit
and receive antenna patterns, contours of constant signal-to-noise ratio are deﬁned by RT RR = const,
which are Ovals of Cassini, but when directional antenna patterns are used the contours are weighted
accordingly and no longer have the same shape. The 1/R2
T R2
R factor also means that the signal-to-noise
ratio has a minimum value when RT = RR (i.e., when the target is equidistant from the transmitter and
receiver) and is maximum when the target is either close to the transmitter or close to the receiver.

818
CHAPTER 16 Passive Bistatic Radar
2.16.4 Target signatures
One of the advantages sometimes ascribed to bistatic radar is that it may offer a counter-stealth capability,
since targets that are shaped and/or treated to minimize their monostatic radar cross section (RCS) may
nevertheless have higher bistatic RCS. This is not easy to verify, both because bistatic measurements
of targets are difﬁcult to make [26], and because the values—certainly those of military targets—are
likely to be classiﬁed.
One of the few sets of published measurements [27] shows the RCS at X-band of three small ship
targetsasafunctionofbistaticangle.Here,theratioofbistatictomonostaticRCSfallsoffwithincreasing
bistatic angle, so that as β approaches 45◦the RCS is of order 10 dB below the monostatic value. This
may be explained by the fact that such targets are likely to include pronounced right-angled features
which will form dihedral or trihedral corner reﬂectors. These will give strong monostatic scattering, but
somewhat weaker bistatic scattering.
Targets without such dihedral features will show different behavior. Early theoretical work on bistatic
electromagnetic scattering from targets led to the bistatic equivalence theorem [28], which states that
the bistatic RCS of a given target at a bistatic angle β will be the same as the monostatic RCS measured
at the bisector of the bistatic angle, and scaled in frequency by the factor cos β/2. This depends on a
number of assumptions: (i) the target is sufﬁciently smooth, (ii) there is no shadowing of one part of
the target by another, and (iii) retroreﬂectors persist as a function of angle. In practice these conditions
are not always met, so the theorem should be used with some care, particularly for complex targets and
at large values of β.
Enhancement of bistatic target RCS at frequencies where the dimensions of target features are
comparable to the radar wavelength (typically at VHF or HF frequencies for aircraft targets) will occur,
just as with monostatic signatures. This resonance effect occurs when contributions from different
scatterers comprising the target (such as the nose, cockpit, tailplane, engine intakes, etc. of an aircraft)
add in phase at a particular radar frequency and geometry.
2.16.4.1 Forward scatter
There is, however, one mechanism by which the bistatic RCS of a target may be enhanced substantially,
which is the forward scatter geometry introduced at the end of Section 2.16.2. The enhancement in RCS
can be understood by making reference to Babinet’s Principle from physical optics [29]. Suppose that
an inﬁnite screen is placed between the transmitter and receiver, so that the signal received is zero. Now
suppose that a target-shaped hole is cut in the screen, between the transmitter and receiver. Babinet’s
Principle states that the signal that would be diffracted through the target-shaped hole must be equal and
opposite to the signal diffracted around the target, since the two contributions must add to zero (Figure
16.2).
Determination of the signal diffracted through an aperture of a given size and shape is a standard elec-
tromagnetics problem, and for simple shapes the results are well known. For example, for a rectangular
aperture of sides a and b, the pattern in each plane has a sinc shape with main lobes whose angular
widths are
λ
a
and
λ
b
(radians)
(16.6)

2.16.4 Target Signatures
819
and the peak scattered signal corresponds to a forward scatter RCS of
σFS = 4πa2b2
λ2
(16.7)
Figure 16.3 plots these quantities as a function of frequency for an idealized small aircraft target for
which a =10 m and b=1 m and hence A=10 m2.
In comparing this with the monostatic RCS (which for a small aircraft might be of the order of
0 dBm2), it is seen that the forward scatter RCS can be several tens of dB higher, particularly at
FIGURE 16.2
Babinet’s Principle applied to determine the forward scatter radar signature of a target.
FIGURE 16.3
Forward scatter RCS σFS and angular width of scatter θB for an idealized small aircraft target with A = 10 m2
and d =10 m.

820
CHAPTER 16 Passive Bistatic Radar
FIGURE 16.4
(a) Iso-phase contours. Each contour represents an additional wavelength in the transmitter-target-receiver
path; (b) Doppler history of forward scatter echoes from a target crossing the baseline between transmitter
and receiver.
microwavefrequencies,althoughthescatterisconcentratedinafairlynarrowbeam.Atlowerfrequencies
the forward scatter RCS is lower, but the scattered energy is spread over a wider range of angles, which
might be preferable for the purpose of detection. This suggests that the optimum frequency range to
exploit this phenomenon will be at VHF or UHF, which are precisely the bands in which many high-
power PBR Illumination sources are to be found. However, while forward scatter may provide very
good target detection performance, target localization will be poor. This point is developed in Section
2.16.6 in the context of the ambiguity function for bistatic radar. Finally, we can note that the clutter
power will in general be large in forward scatter, both because of the large clutter cell area and because
the backscatter coefﬁcient will be large.
The variation of Doppler frequency as a target crosses the baseline can be visualized by imagining
a set of elliptical iso-range (or equivalently, iso-phase) contours, with transmitter and receiver as the
two focal points, and with each contour corresponding to an extra wavelength in the transmitter-target-
receiver path (Figure 16.4). Each time the target crosses one of these iso-phase contours the bistatic echo
will undergo one cycle of Doppler shift. The red1 lines indicate the angular width λ/a of the scattering,
so the Doppler variation of the forward-scattered target echo will be detectable at the receiver while the
position of the target lies between the two limits shown.
As an example of this, the embedded audio clip is of the signal from a palm-sized VHF FM radio
receiver located at the author’s home in Camden Town, just to the north of the center of London, listening
to the 93.5 MHz BBC Radio 4 transmission from Wrotham, to the south-east of London at a range of
approximately 50 km (Figure 16.5).
As the ﬂight paths of aircraft on their way to land at Heathrow airport to the west of London pass over
the bistatic baseline formed by the VHF transmitter and the receiver, the Doppler shift of the target echo
will follow this form, and the net received signal is the sum of the direct signal and the Doppler-shifted
forward scatter echo. This gives a characteristic beat frequency signature, lasting for several seconds
and passing through zero as the target crosses the bistatic baseline (Figure 16.3b). This phenomenon is
1For interpretation of color in Figure 16.4, the reader is referred to the web version of this book.

2.16.5 Bistatic Radar Clutter
821
FIGURE 16.5
Forward scatter geometry used for the experiment of the audio recording. Click the audio clip 1 to hear this
transmission.
readily observed with simple receiving equipment; indeed the “ghosting” effect that may be observed
on analog television receivers due to strong multipath or aircraft targets, referred to in the opening
paragraph of this chapter, is another manifestation. It is usually regarded as a nuisance, but of course to
us it forms the basis of a radar.
2.16.5 Bistatic radar clutter
A knowledge of the properties of radar clutter, in terms of the mean reﬂectivity (σ ◦), the higher-order
(statistical) properties, and the Doppler spectrum, is necessary for performance prediction, comparative
performance assessment, design of detection processing, and measurement of performance for accep-
tance. Bistatic radar clutter depends on all of the same parameters as monostatic clutter, both of the
radar (frequency, incidence angle, polarization, resolution cell size, etc.) and of the surface, but also all
of those associated with the bistatic geometry [30]. In PBR, just as with conventional radar, clutter will
provide a limit to the detection sensitivity, and this point is developed further in the discussion of the
signal and interference environment in PBR.
Figure 16.6 shows the bistatic geometry and deﬁnes the associated angles. The incidence and scat-
tering angles are θ1 and θ2 respectively. In some treatments θ1 is denoted as θi and θ2 as θs; however, the
meaning of the two angles can be interchanged without changing the result because of the reciprocity
theorem of electromagnetics. β is the bistatic angle, related to θ1 and θ2 by
β = cos−1 
sin θ1 sin θ2 −cos θ1 cos θ2 cos φ

(16.8)
and which is zero for the monostatic case and 180◦for forward scattering. φ = 0◦or 180◦corresponds
to the special case referred to as in-plane scattering; the general case of φ ̸= 0◦or 180◦is referred to as
out-of-plane scattering.

822
CHAPTER 16 Passive Bistatic Radar
FIGURE 16.6
Bistatic clutter geometry.
Probably the best summary of present knowledge is the chapter by Weiner [31], which lists nine
bistatic clutter measurement campaigns from the past 40 years, of which ﬁve include sea clutter, and
only one of which used out-of-plane geometries. Domville [32] reported the results of an extensive set
of trials in the UK in the mid-1960s of X-band radar scattering from a range of different surface types
(sea, urban land, rural land, forest, semi-desert). These used an aircraft-borne CW transmitter and a
receiver in a second aircraft. An example of these results is shown in Figure 16.7, corresponding to
horizontally polarized in-plane scattering from the sea with a 20 kt wind, plotting the mean bistatic
scattering coefﬁcient σ ◦
B in terms of the incidence and reﬂection angles. Thus θ2 = θ1 corresponds to
monostatic scattering; θ2 = (180◦−θ1) corresponds to specular scattering (the “specular ridge”) with
a maximum at grazing incidence (forward scatter).
Yates investigated the difference in statistical distributions of simultaneously-acquired monostatic
and bistatic X-band SAR imagery of land scenes [33]. She used the compound K-distribution model [34],
which models the clutter as Rayleigh-distributed speckle modulated by a gamma-distributed texture.
This has been found to give a good representation of the properties of high-resolution low grazing angle
sea clutter, as well as high-resolution land clutter, and even high-resolution sonar scattering from the
seabed. The usual form of the distribution is:
f (x) =
4c
(ν)(cx)ν Kν−1(2cx)
(16.9)
in which c is a scale parameter, ν is a shape parameter and Kν( · ) is the modiﬁed Bessel function of
the third kind of order ν. The value of the shape parameter is a measure of the length of the tail of the
distribution or degree of “spikiness” of the clutter, such that a low value of ν (<1) indicates spiky clutter.
For ν = ∞the distribution reduces to Rayleigh.
Her results showed that the K-distribution gave a good ﬁt to the measured data, but more importantly,
that the shape parameter ν was consistently higher for the bistatic imagery than for the monostatic
imagery—in other words, that the distribution corresponding to the bistatic clutter was shorter-tailed.

2.16.6 PBR Waveforms
823
FIGURE 16.7
Measured dependence of in-plane bistatic scattering coefﬁcient of X-band sea clutter at HH polarization on
angles θ1 and θ2 (adapted from [32]).
A physical explanation for this is that the target scene contains dihedral or trihedral features, such as
those formed by horizontal ground and vertical building walls or tree trunks or stalks of vegetation,
which give strong monostatic scatter but weaker bistatic scatter.
Recent measurements of the statistical properties of simultaneously-acquired monostatic and bistatic
S-band sea clutter have shown essentially similar behavior [35,36]. This suggests that there should be an
advantage in using the bistatic geometry for the detection of small targets against a clutter background.
In the examples measured in this work the improvement in detection sensitivity is a function of the
bistatic geometry, but in some conﬁgurations can be more than 6 dB. Thus in any practical application
it will be important to choose the appropriate bistatic geometry in order to best exploit this effect, which
has been termed clutter diversity.
Clearly there is a great deal more work to be done to explore and understand these effects as a function
of all of the parameters: frequency, bistatic geometry, polarization, resolution and surface properties,
and hence to develop reliable models.
2.16.6 PBR waveforms
A key feature of PBR is that the waveforms of the signals are not explicitly designed for radar purposes,
and therefore that their performance when used for PBR may be far from optimal. It is important,

824
CHAPTER 16 Passive Bistatic Radar
therefore, to understand the nature of the wide range of waveforms that may be used for PBR, so as
to be able to choose the most suitable ones and to process them in the most appropriate way. The
classical tool for analyzing and displaying waveform properties is the ambiguity function, introduced
by Woodward [18] in the early 1950s:
|ψ(TR, fD)|2 =

 ∞
−∞
st(t)s∗
t (t + TR) exp

j2π fDt
	
dt

2
(16.10)
The ambiguity function is the square magnitude of the output from a ﬁlter matched to the signal st(t),
and represents the point target response of the radar as a function of delay TR and Doppler shift fD.
Aplotofthis(theambiguitydiagram)showstheresolution,sidelobepattern,andpresenceofambiguities
in range and in Doppler in an elegant and easily-visualized manner.
In the case of bistatic radar it has already been noted that the range and Doppler resolution for a
target on or close to the bistatic baseline are degraded, no matter what the waveform. Thus it can be
seen that the ambiguity function for a bistatic radar depends not only on the waveform properties, but
also on the location of the target with respect to the transmitter and receiver. This was analyzed by Tsao
et al. [37], who also explained the effect by pointing out that the simple linear relationships between
target range and echo delay and between target velocity and Doppler shift that exist for a monostatic
radar no longer hold for a bistatic radar, and hence that the ambiguity function has to be expressed as
a function of more variables than just TR and fD. They express the ambiguity function for a bistatic
radar as:
ψ

RRH, RRa, VH, Va, θR, L
2
=

 ∞
−∞
st

t −τa

RRa · θR, L

s∗
t

t + τR

RRH, θR, L

× exp

j2π fDH

RRH, VH, θR, L

−2π fDa

RRa, Va, θR, L

t
	
dt

2
(16.11)
where RRH and RRa are the hypothesized and actual ranges (delays) from the receiver to the tar-
get, VH and Va are the hypothesized and actual target radial velocities with respect to the receiver,
fDH and fDa are the hypothesized and actual Doppler frequencies, and θR and L are as deﬁned in
Figure 16.1.
To illustrate this effect, Figure 16.8 shows the ambiguity function for four different target locations
and directions of motion. The waveform in each case consists of a short sequence of three rectangular
pulses. In Figure 16.8a the target is on the baseline approaching the receiver and the ambiguity function
is essentially the same as for the monostatic conﬁguration. In Figure 16.8b the target approaches the
baseline obliquely, but the ambiguity function is little altered. In Figure 16.8c the target approaches
the baseline from a perpendicular direction, which broadens the main peak and alters the position of
the sidelobes in the ambiguity function. Finally in Figure 16.8d the target crosses the baseline, at which
point there is effectively no resolution in either range or Doppler.
As well as the distortion of the ambiguity function due to the bistatic geometry, we also need to
consider the form and variation of the ambiguity function due to the waveform itself. Several workers
have investigated the performance of the waveforms of different PBR sources by digitizing off-air

2.16.6 PBR Waveforms
825
FIGURE 16.8
Bistatic ambiguity functions for a sequence of three rectangular pulses and for four different target locations
and directions of motion.
samples of the signals and computing and plotting their (monostatic) ambiguity functions [38–40].
Of course, these results represent a best case, since the range and Doppler resolution may be degraded
if the bistatic geometry is less favorable. Some interesting and important points emerge from this.
Firstly, if there are periodic features associated with the modulation, there are corresponding ambi-
guities. As an example of this, in the PAL analog TV format used in the UK the picture information is
encoded as 625 successive lines, each of 64 µs duration in two interlaced scans at a 25 Hz rate, with
a 5.5 µs sync pulse at the beginning of each line. Because of the sync pulses and because in general
there will be strong correlation between adjacent lines of a TV picture, there will be pronounced bistatic
range ambiguities at multiples of 9.6 km, corresponding to the 64 µs line repetition period. Other analog

826
CHAPTER 16 Passive Bistatic Radar
modulation formats that have been used in other countries, such as NTSC (in the USA) and SECAM
(in France) are broadly similar.
Secondly, it is found that for analog modulation formats the ambiguity performance depends sig-
niﬁcantly on the instantaneous program content. For example, with FM radio the ambiguity function
depends strongly on whether the modulation is speech or music, and even on the type of music. With
speech, during pauses between words the bandwidth of the modulated signal is narrow and hence the
range resolution is poor. With music that has a high spectral content the bandwidth of the modulated
signal is broad and hence the range resolution rather better, so (for example) a cacophony of rock music
is likely to be better for PBR purposes than speech or music from a solo instrument. Thus in general
PBR signals with analog modulation have an ambiguity performance that is time-varying.
In contrast, digital modulation formats such as DAB and DVB give a signal spectrum that is ﬂatter and
more noise-like, and which does not depend on instantaneous program content, so the ambiguity perfor-
mance does not vary with time and does not depend on the program content, and better approximates to
the thumbtack ideal. In many countries analog television and radio are being phased out and replaced by
their digital counterparts. In the USA, for example, analog television was discontinued in 2009. France
switched off all analog services on 29 November, 2011, to be followed by Japan on 31 March, 2012.
Some examples of the measured ambiguity functions are shown in Figure 16.9. Figure 16.9a shows
the ambiguity function of a VHF FM radio station with speech modulation (BBC Radio 4). The peak
and the sidelobe structure are well deﬁned, although the peak is relatively broad, as a consequence of
the low spectral content of the modulation. Figure 16.9b shows the equivalent result for a station with
fast-tempo jazz music modulation (Jazz FM). The peak and the sidelobe structure are correspondingly
sharper because of the higher spectral content of the modulation. In both cases, the ﬂoor of the ambiguity
function is down by a factor of (Bτ)1/2, rather than by (Bτ), which would be expected for coherent
waveforms. Figure 16.9c–e shows typical ambiguity functions for digital transmissions (DAB, DBV-
TV, and GSM, respectively). These functions are more favorable for PBR purposes than signals with
analog modulation, such as Figure 16.9a and b since the peak of the ambiguity function is narrower and
the sidelobes are lower. Also, they are time-invariant and do not depend on the program content.
A subtlety associated with some digital transmissions is the use of single frequency networks. Here,
all transmitters in a given network use the same frequency, with Coded Orthogonal Frequency Division
Multiplexing (COFDM) modulation, and each information block is preceded by a guard interval of
duration greater than the maximum expected multipath delay [42].
Radio and television broadcast transmitters are in general high-powered and favorably-sited to give
wide coverage. In practice the transmit power used by broadcast transmitters has to take into account
the fact that the antennas of domestic receivers may be inefﬁcient and/or poorly-sited, so the transmitter
power will be several tens of dB greater than would be needed for a dedicated, optimized link. As an
example, the highest-power analog television transmitters in the UK have an EIRP of 1 MW, with the
antenna on a tower as much as 330 m high, which is itself generally located on top of a high hill.
There is a huge variety of sources that may be used as PBR illuminators. In addition to the analog
and digital radio and television transmitters mentioned above, we can add cellphone basestations, HF
short-wave broadcast transmitters, WiFi and WiMAX transmitters and various satellite-borne sources
in a variety of different orbit patterns. Table 16.1 gives a list (which is by no means exhaustive), showing
for each the form of modulation and evaluating the power density  = PtGt/(4π R2
T ) at representative
values of transmitter-to-target range.

2.16.7 The Signal and Interference Environment
827
FIGURE 16.9
Measured ambiguity functions from (a) VHF FM BBC Radio 4 (speech), (b) VHF FM Jazz FM (fast-tempo
jazz music), (c) Digital Audio Broadcast (DAB) at 222.4 MHz, (d) Digital Video Broadcasting (DVB-T) at
505 MHz, and GSM900 at 944.6 MHz.
2.16.7 The signal and interference environment [43]
It has already been remarked in Section 2.16.5 that the direct signal, multipath (i.e., clutter) and interfer-
ence may limit the detection performance of a passive bistatic radar, especially in an urban environment.

828
CHAPTER 16 Passive Bistatic Radar
Table 16.1 Summary of Typical Parameters of PBR Illuminators of Opportunity (from [41])
Transmission
Frequency
Modulation,
Pt Gt
Power Densitya
Bandwidth
 = Pt Gt
4πR2
T
HF broadcast
10–30 MHz
DSB AM, 9 kHz
50 MW
−67 to −53 dBW/m2
at RT = 1000 km
VHF FM
88–108 MHz
FM, 50 kHz
250 kW
−57 dBW/m2
at RT = 100 km
Analog TV
∼550 MHz
PAL, SECAM, NTSC
1 MW
−51 dBW/m2
5.5 MHz
at RT = 100 km
DAB
∼220 MHz
digital, OFDM
10 kW
−71 dBW/m2
220 kHz
at RT = 100 km
Digital TV
∼750 MHz
digital, 6 MHz
8 kW
−71 dBW/m2
at RT = 100 km
Cellphone
900 MHz,
GMSK,
10 W
−81 dBW/m2
base station
1.8 GHz
FDMA/TDMA/FDD
at RT = 10 km
(GSM)
200 kHz
Cellphone
2 GHz
CDMA, 5 MHz
10 W
−81 dBW/m2
base station
at RT = 10 km
(3G)
WiFi
2.4 GHz
DSSS/OFDM,
100 mW
−41 dBW/m2b
802.11
5 MHz
at RT = 10 m
WiMAX
2.4 GHz
QAM, 20 MHz
20 W
−88 dBW/m2
802.16
at RT = 10 km
GNSS
L-band
CDMA, FDMA
200 W
−134 dBW/m2
1–10 MHz
at Earth’s surface
DBS TV
Ku-band
analog and digital
55 dBW
−107 dBW/m2
11–12 GHz
at Earth’s surface
Satellite
5.3 GHz
chirp pulse, 15 MHz
68 MW
−55 dBW/m2
SARc
at Earth’s surface
a Assuming free-space line-of-sight propagation.
b Would be subject to additional attenuation due to propagation through walls.
c Parameters from ASAR instrument carried by ESA’s ENVISAT satellite.

2.16.7 The Signal and Interference Environment
829
In a similar way to Eq. (16.5), the ratio of the direct signal (DSI) from the transmitter at the PBR
receiver to the thermal noise level is given by
Pdirect
Pn
= PtGt
4π L2 · Grλ2
4π
·
1
kT0BF
(16.12)
under the assumption of free-space line-of-sight propagation.
Inserting typical values shows that this ratio may easily be as much as 100 dB, or even more, and
this direct signal will be compounded by multipath versions of the same signal, other co-channel
transmissions, broadband noise from sources such as computers or imperfectly-suppressed vehicle
ignition, and out-of-band emissions from other transmitters (the spectral mask speciﬁcation for such
transmitters extends down typically to −60 dB; at this level the out-of-band emissions have no effect
on reception by conventional FM radio receivers). The signal and interference environment is shown
schematically in Figure 16.10, plotted as a function of frequency and of direction ( −1 ≤sin θ ≤+1).
The environment may also be non-stationary, since some of the reﬂections may come from moving
vehicles or other clutter sources. The problem of detecting target echoes against such a background has
been likened to “listening for a whisper in a cocktail party” [44].
Figure 16.11 provides another illustration of the same phenomenon. This shows noise levels in a
50 kHz bandwidth in the FM radio band from 95 to 100 MHz, measured from the 11th ﬂoor of a
building at UCL in central London. Figure 16.11a shows thermal noise level (approximately −115 dBm)
corresponding to a 5 dB receiver noise ﬁgure, obtained with the antenna input terminated in a 50 
load. Figure 16.11b shows the equivalent spectrum when a vertically-polarized dipole is connected. It
is offset vertically by 10 dB with respect to Figure 16.11a to allow a proper side-by-side comparison
between the signal levels. In this case the strongest direct signals are some 85 dB above thermal noise.
FIGURE 16.10
The signal and interference environment at the PBR receiver.

830
CHAPTER 16 Passive Bistatic Radar
FIGURE 16.11
Noise levels in a passive radar receiver in FM radio band: (a) thermal noise in 50 kHz bandwidth corresponding
to 5 dB receiver noise ﬁgure; top of screen = −50 dBm (b) signal and noise levels measured from 10th ﬂoor
of UCL in Central London on vertically-polarized dipole antenna; top of screen = −40 dBm.
2.16.7.1 Suppression techniques
A range of techniques may be used to attempt to suppress these signals and interference. First, and most
attractive because of effectiveness, simplicity, and cost, is to site the receive antenna so that it is physi-
cally shielded from the direct path signal, using topography, buildings or shrouds. This technique alone
can often provide adequate suppression, but in turn limits the receive antenna’s ﬁeld of view (FOV). In
some cases, this trade-off is entirely acceptable. For air surveillance, terrain blockage of the receiver’s
FOV is nearly always unacceptable, especially for low-altitude surveillance. However, judicious siting
of the receive antenna in some geometries can still provide acceptable physical shielding. The classic
example is to site the receiver (a) between the transmitter and the surveillance region with the transmitter
looking over the receiver’s shoulder and (b) with a large building or other structure located directly
behind the receiver, i.e., along the baseline, to shield the direct path. As an extreme example, in the case
of the Manastash Ridge Radar [8,9] the receiver was located remotely, behind a mountain range and at
a distance of 150 km from the transmitter, which provided more than adequate suppression of the direct
transmitter signal.
Asecondtechniqueisspatialcancellationofthedirectpathsignal.Anarrayantennaatthereceivercan
be conﬁgured to steer a null at the direct path signal, and null depths of several tens of dB are achievable.
Inspection of Figure 16.10 shows that radiation pattern nulls should ideally be broadband (in direction
and depth) so that multiple signals from a given transmitter may be suppressed by a single null. Of course,
an adaptive antenna and its associated signal processing introduces signiﬁcant complexity, and, to some
extent, negates one of the claimed advantages of PBR—that the receiver is simple and cheap.
A third approach is to use a transversal ﬁlter equaliser method to suppress multipath in a similar
way to that used in mobile communications. Two architectures that have been used with success for
this purpose have been described by Howland et al. [46] and by Colone et al. [47]. The former uses

2.16.7 The Signal and Interference Environment
831
FIGURE 16.12
Two-stage adaptive noise canceller used by Howland [46]. The ﬁrst stage (a) is an adaptive M-stage lattice
predictor with prediction order M = 50, equivalent to the Gram-Schmidt algorithm, and the second (b) is
equivalent to a multiple regression ﬁlter.
a two-stage adaptive noise canceller, of which the ﬁrst stage is an adaptive M-stage lattice predictor,
with prediction order M = 50, and the second an adaptive tapped delay line (Figure 16.12). The ﬁrst is
equivalent to the Gram-Schmidt algorithm and the second to a multiple regression ﬁlter. This approach
was able to suppress the direct path interference by approximately 75 dB.
The approach of Colone et al. [47] may be understood by visualizing the signal and multipath envi-
ronment in the range-Doppler plane (as in Figure 16.14). It is assumed that a clean reference version of
the direct signal is obtained via a separate antenna and receiver which is free of multipath. The algorithm
successively nulls the multipath signals via appropriately-weighted and delayed versions of the direct
signal. In the example given the algorithm was halted when 60 dB of cancellation had been achieved.
Filtering techniques based on canceling the direct signal and its multipath using a reference version
of the direct signal will, of course, not be able to suppress other co-channel transmissions or noise
sources. In practice a combination of techniques will be necessary, and even then it is unlikely to be
possible to suppress the multipath and interference right down to the level of receiver thermal noise, so
this will need to be taken into account in performance prediction calculations. Furthermore, to reduce
the dynamic range of the signal to be digitized, it may be helpful to employ a stage of analog adaptive
null steering, of the type described in [48], prior to digitization.
2.16.7.2 Performance prediction
As an example of such a performance prediction, the bistatic radar equation (16.5) can be written in the
form
(RR)max =

σBGrλ2LG p

4π
2 
S/N

min kT0BF
1/2
(16.13)
where the appropriate value of  is used according to the illuminator source and the transmitter-to-
target range, (S/N)min is the minimum signal-to-noise ratio for adequate probability of detection, and

832
CHAPTER 16 Passive Bistatic Radar
Gp is the processing gain. The maximum value of this is set by the maximum time Tmax for which the
target echo remains coherent, which in turn depends on the extent to which the target is maneuvering or
accelerating. A rule of thumb value for this time, obtained by setting the change in one-way pathlength
due to the radial component of target acceleration AR to be equal to half a wavelength, is
ART 2
max
2
= λ
2
(16.14)
hence
Tmax =
 λ
AR
1/2
(16.15)
For a VHF FM radio waveform of bandwidth 50 kHz and an integration time of 1 s, this gives G p =
47 dB. Adopting a suitable value of F (perhaps 25 dB) to take account of the ﬁnite suppression of the
direct signal, multipath and other signals, and inserting appropriate values for , σB and for Gr, allows
contours of detection sensitivity to be plotted, and an example of this is shown in Figure 16.13. These
have the “Ovals of Cassini” form discussed in Section 2.16.3.
It can be seen that aircraft targets of this kind should be detectable at ranges well in excess of 100 km,
and results have been reported in the literature from several practical systems [45,49,50] which conﬁrm
this.Anexampleshowingaircraftdetectionsofcivilianaircrafttargetsatslightlycloserranges,presented
in terms of bistatic range—Doppler plots, is shown in Figure 16.14.
FIGURE 16.13
Predicted detection range performance of a VHF FM-based PBR receiver system, with Pt = 250 kW,
σB =100 m2, F =25 dB [49].

2.16.7 The Signal and Interference Environment
833
(a)
(b)
(c)
FIGURE 16.14
2-D bistatic range-Doppler display plots for the BBC 91.3 MHz Wrotham FM transmitter. (a)–(c) show three
successive 1 s blocks of data [52].

834
CHAPTER 16 Passive Bistatic Radar
FIGURE 16.15
Triangulation using three transmit-receive pairs. The differential range at each transmitter-receiver pair
deﬁnes an ellipse, and the target is located at the point where the three ellipses intersect.
2.16.7.3 Multilateration and tracking
In practice the processing required to form reliable tracks of multiple targets is more difﬁcult, at least
partly due to the dependence of the ambiguity function on instantaneous modulation (for analog trans-
missions) and on bistatic geometry. Use of multiple transmitters and/or receivers can be useful, since
for a given target the dependence of ambiguity functions on instantaneous modulation and on geometry
is deterministic, so the transmissions that give inadequate ambiguity performance can be ignored.
2.16.7.3.1
Multilateration
Figure 16.15 shows how multilateration can be used to determine the location of a target. In this example
there is a single receiver and three transmitters, all with omnidirectional antennas. Each transmitter-
receiver pair provides a measurement of bistatic range from the time difference of arrival (TDOA) of
the echo signal with respect to the direct signal. Each of these deﬁnes an ellipse, and the three ellipses
intersect at various points, of which only one is the true target location. The false locations (which have
been termed “Casper’s ghosts” [53]) need to be identiﬁed and excised (a process known, inevitably,
as “ghostbusting”).
2.16.7.3.2
Extended Kalman ﬁlter (EKF) tracking
Differential range is not the only information available at the bistatic receiver. In principle, Doppler shift
and direction of arrival (DOA) of each target echo may also be measured, so these pieces of information
can be exploited as well. One of the early PBR experiments by Howland [5] making use of the vision
carrier of analog television transmissions, used a single receiver to measure Doppler and DOA (but not
differential range). This approach has been termed narrowband PBR, since the detection bandwidth is
narrow (and hence the sensitivity is improved) and only small a portion of the total signal spectrum is
used. The receiver was located at Pershore, UK, and the transmitter was at Crystal Palace in the south
of London, at a range of some 150 km from Pershore. The Doppler and DOA measurements were input
to an extended Kalman ﬁlter (EKF) algorithm to form tracks of the detected targets.

2.16.7 The Signal and Interference Environment
835
The conversion of Doppler and DOA measurements into target state estimates was improved by
initializing the process with a genetic algorithm. Howland found that while nearly all high-altitude
targets were detected, only about one third could be tracked, with the remaining two thirds either lost in
the CFAR and initial Kalman ﬁltering, or having ambiguous or adequately-accurate bearing estimates,
which underlines the difﬁculty of target tracking with PBR, especially if only a single transmit-receive
pair is used.
2.16.7.3.3
Probability hypothesis density (PHD) ﬁltering and tracking
Tobias and Lanterman [54] tackled the problem of ghost excision and target state estimation using the
probability hypothesis density (PHD) approach, which was originally developed by Mahler [55]. The
PHD is deﬁned as being any function that, when integrated over any given area, speciﬁes the expected
number of targets present in the area.
They use the particle ﬁlter implementation of the update equations in which the PHD is represented
by a collection of particles and their corresponding weights. Using the same notation as [54], at time-step
k each particle in the ﬁlter is a vector of the form
ξi =
 xi yi ˙xi ˙yi
	T
(16.16)
and has a weight wi,k, where (xi yi) specify the location of the particle and (˙xi ˙yi) specify its velocity
components. As per the deﬁning property of the PHD,
˜N = E[no. of targets] =

Nk|k
	
nearest integer ,
(16.17)
where
Nk|k =

i
wi,k
(16.18)
Speciﬁcally, the PHD is expected to (a) automatically estimate the number of targets, (b) resolve ghost
targets, and (c) fuse sensor (i.e., bistatic transmit-receive pair) data without the need for any explicit
report-to-track association [56].
Results were presented from a simulation using three bistatic transmit-receive pairs measuring ﬁrst
range and then range/Doppler on two aircraft targets ﬂying in the Washington DC area. The transmitters
were three local VHF FM stations and the receiver was based on that used by Lockheed Martin’s Silent
SentryTM, located 30–50 km from the transmitters. The simulations assumed adequate target visibility,
overlapping coverage, and no multipath, and calculated SNRs ranged from 12.2 dB to 32.5 dB.
In its simplest form, the simulation began by independently and randomly assigning the particles’
two-dimensional position and velocity components to fall within the FOV of each transmit-receive pair.
Particle weights were initially set to zero. These particles were then propagated forward in one-second
steps. Birth particles with random positions and velocities were added at each time step to model new
targets. One new target and hence one birth particle was assumed to appear at each step. The PHD
then assigned (and updated) particle weights wi,k+1 at each time step by incorporating range/Doppler
observations, calculated probability of detection, Poisson-distributed false alarms, and a single-target
likelihood function. Finally, the expected number of targets in the FOV was calculated by means of
Eq. (16.18). The locations of the N expected targets were found by extracting the N highest peaks from
the PHD represented by these weights.

836
CHAPTER 16 Passive Bistatic Radar
The results of these preliminary simulations were described as “encouraging.” It was observed that
in areas of low SNR the number of targets was overestimated. Subsequently an improved method was
developed which removed the need to restrict particles to areas of high SNR, though at the expense of
greater computational load [56]. This also had the effect of reducing the number of particles needed
from a few thousand to a few hundred.
2.16.8 Applications
In this section, a presentation of practical applications of PBR is provided. We start by acknowledging
that although PBR is a vibrant and lively subject with a steady stream of new publications in research
journals and at conferences, there have been rather few applications in which PBR systems have been
operationally deployed, as distinct from experimental demonstration.
2.16.8.1 Low-cost scientiﬁc measurements
The principal applications in which PBR has been deployed thus far have been for low-cost scientiﬁc
remote sensing measurements. As a general comment, radar remote sensing relies on a model to relate
the desired remotely-sensed quantity to some parameter of the radar echo. The model may be the result
of rigorous electromagnetic scattering calculations, or empirical measurements, or a mixture of the two.
An example of this is the relationship in a satellite-borne radar altimeter between the duration of the
leading edge of the echo from the ocean surface and the wave height. This will work best when the
relationship between the remotely-sensed quantity and the parameter of the radar echo is maintained
over a wide dynamic range, and certainly the relationship must be monotonic. The extra degrees of
freedom associated with the bistatic geometry may offer a better chance of ﬁnding a regime where such
a relationship exists.
2.16.8.1.1
The Manastash Ridge Radar
As has already been mentioned, examples of low-cost remote sensing applications have included mea-
surements of the ionosphere, planets, wind or thunderstorms. The ﬁrst of these was developed and
demonstrated by Sahr and his co-workers at the University of Washington, Seattle, in a system known
as the Manastash Ridge Radar (MRR), as a means of studying turbulence in the ionosphere. Although
dedicated monostatic radars have been successfully used for this application, PBR has the advantages
(especially for a university group) of simplicity and low cost, as well as avoiding the complication and
safety issues associated with a dedicated transmitter. Furthermore, frequencies around 100 MHz (using
VHF FM broadcast transmissions) are very suitable for this purpose. Two noteworthy features were
the separation of the receiver behind a range of mountains to suppress the direct signal in the receiver
(already identiﬁed as an issue in Section 2.16.7), and the use of GPS and the Internet for timing and
data transfer. These resulted in a low-cost but high-performance system.
The resulting data products approximate those from the current monostatic radars, in terms of ﬁne
range, time, and Doppler resolution. Ground clutter and aircraft (at shorter range), and meteor trails are
also routinely detected. The data was made available in the form of range-Doppler plots (out to ranges
of 1200 km) every half hour via the Internet. A photograph of the receiver, and an example of the data
product, are shown in Figure 16.16a and b respectively.

2.16.8 Applications
837
FIGURE 16.16
(a) PBR receiver for the Manastash Ridge Radar; (b) example of the data product, made available on the
Internet every 30 min, and consisting of 10 s of data sampled every 4 min.
2.16.8.1.2
Bistatic adjunct to weather radar
A second such application is a bistatic adjunct to the NEXRAD meteorological radars in the
USA to measure the vector wind ﬁeld [12,57]. This approach has the following advantages and disad-
vantages compared to the conventional dual- or multiple-Doppler method using two or more monostatic
radars:
Advantages:
(1) Simultaneous measurement of all Doppler velocities in individual weather volumes, thus min-
imizing storm evolution-induced errors, and (2) less expensive and simpler installation by using
only one transmitter and scanning antenna. The network can also be used for (3) hail detection by
comparing the intensity of obliquely (bistatically) scattered energy to Rayleigh scattering predic-
tions and (4) rapid scanning of localized weather, which typically requires multiple monostatic
weather radars.
Disadvantages:
(1) Less sensitivity to weak weather returns due to the low-gain receiving antenna; (2) less sen-
sitivity to weather returns near ground level when using horizontal transmit polarization, which
are used by many Doppler weather radars; (3) more sensitivity to contamination from transmitter
sidelobes (i.e., direct path breakthrough) and to secondary scattering from weather echoes via
transmit antenna sidelobe illumination, both due to the broad-beam receiving antenna; and (4)

838
CHAPTER 16 Passive Bistatic Radar
increased measurement errors by about a factor of 2 when operating at large oblique scattering
angles. Contamination is acceptable in most situations and can be reduced by using higher-gain
antennas when necessary. The lower sensitivity and increased errors can be offset with more BNR
sites, which represents a practical solution due to their low cost.
Between 1993 (when the ﬁrst BNR prototype was introduced) and 2002, nine sets of BNRs have been
sold and deployed at monostatic Doppler weather radar sites for research, testing, and operation: one
in the United Kingdom, one in Canada, one in Germany, two in Japan, and four in the United States.
2.16.8.1.3
Ocean remote sensing using GPS signals
A third application is the use of GPS satellite signals scattered from the ocean surface to measure surface
winds [58]. The power density at the target (Table 16.1) from such illumination sources is low, but since
the phenomena being sensed vary on relatively long timescales, long integration times can be used.
This idea was ﬁrst put forward, along with some preliminary experimental measurements with an
aircraft-borne receiver, by Garrison et al. [59], and came from a realization that the scattered multipath
GPS signal from the sea surface that for conventional GPS purposes is a nuisance actually contains
useful information about the sea surface roughness, and hence the wind speed (yet another example of
the principle that “one person’s interference is another person’s signal”). Speciﬁcally, the width of the
cross-correlation function between the scattered signal and the locally generated PRN code provides a
measure of the surface wind speed. Subsequent work [60,61] has carried out more detailed experiments,
comparing the results with other satellite remote sensing data and with surface truth measurements from
buoys, and conﬁrmed the viability of the technique as a simple, low-cost approach to ocean remote
sensing. Of course, signals from the Russian GLONASS and the European GALILEO systems are
equally usable in this application.
2.16.8.2 Border or perimeter surveillance
Forward scatter fences based on PBR illuminators may be used for border or perimeter surveillance, to
detect intruders or smugglers, or for maritime surveillance, for example for harbor protection, ﬁsheries
protection or counter-piracy. Success here will depend on the availability of illuminating sources with
appropriate coverage, and suitable locations for receivers (whether on land or at sea), as well as under-
standing the forward scatter signature of maritime targets and of sea clutter. It will exploit the signiﬁcant
enhancement of target RCS that occurs in forward scatter, but will also need to take account of the high
clutter level in forward scatter, so the performance is likely to be clutter-limited rather than noise-limited.
It may also be desirable to attempt to exploit the micro-Doppler signature of targets, so as to be
able to distinguish between different types of target (for example, between a human and an animal,
between a human that is walking and one that is running, or between a human carrying a weapon and
one without) on the basis of the Doppler modulation due to the swinging motion of arms and legs [62]. In
the same way, a tracked vehicle may be distinguished from a wheeled one. The poor Doppler resolution
associated with the forward scatter geometry means that this technique is not compatible with forward
scatter, but for other geometries it may well be usable. Greneker [63] has demonstrated a PBR system
based on HDTV signals around 548 MHz, with a bandwidth of 6 MHz, and detected and characterized
the micro-Doppler signatures of a walking human target and of an accelerating vehicle.

2.16.8 Applications
839
2.16.8.3 Air surveillance
Air surveillance has already been mentioned as a potential application of PBR, and examples of exper-
imental results from a number of systems have been shown above. These generally exploit high-power
analog or digital broadcast transmissions, which have appropriate power and coverage [46,50–52],
Some other results of this kind were presented as early as 1995 by Koch and Westphal, who used
transmissions from GPS satellites to detect a variety of air targets including military and civil aircraft, an
anti-tank missile, and the MIR Space Station [64,65]. As with remote sensing applications using GPS
signals, the power density at the target is comparatively low. The range from the GPS satellite to the target
is of order 20,000 km, and the signal level at the input to a GPS receiver is of order −160 dBW. However,
the experiments exploited long integration times (several seconds, giving 60–70 dB of processing gain)
and the substantial enhancement of target RCS in forward scatter (Figure 16.3) to compensate.
2.16.8.4 Airborne PBR
Another potentially valuable set of applications comes if the PBR receiver is located in an aircraft. This
might allow (for example) airborne early warning (AEW) or detection of ground vehicle targets. Some
ﬁrst results from a system of this kind, developed by Woodbridge and co-workers at University College
London (UCL) have been reported in [66,67].
For these experiments a two-channel VHF receiver was mounted in a Piper PA 28-181 light aircraft
with simple dipole antennas for the reference channel and signal channels taped to the inside of the
window (Figure 16.17), ﬂying from Shoreham airport on the south coast of England. An issue with such a
system is that the receivers will certainly be line-of-sight to the transmitters, so the degree of suppression
of the direct signal in the radar receiver may need to be even higher than for a terrestrial system.
Figure 16.18 shows the results of detection of civil aircraft targets using VHF FM transmitters at
Wrotham, Crystal Palace, Guildford and Oxford, giving in each case (from the differential TDOA) an
ellipse on which the target must lie. The target velocity vector is also computed from the measured
Doppler shift and the known velocity of the aircraft carrying the receiver, and these are shown around
the locus of the ellipses. This information can be used to resolve the correct target location—in other
words to excise the ghosts—since it can be seen that the velocity vectors agree at one intersection point
but not the other.
Although these results must be regarded as preliminary, they indicate the potential of the idea and
point the way for further work.
2.16.8.5 PBR imaging
PBR may also be used as the basis for bistatic radar imaging. The synthetic aperture may be formed by
a moving transmitter or a moving receiver, or if both transmitter and receiver are ﬁxed, by the motion of
the target itself (bistatic ISAR). Bistatic images and High Resolution Range Proﬁles (HRRPs) may be
used in target classiﬁcation and Non-Cooperative Target Recognition (NCTR) processing, just as with
monostatic imaging.
There have been a number of experiments using satellite-borne illuminators of opportunity as the
basis for bistatic SAR. The azimuth resolution of such a system may be derived in the same way as
for a monostatic SAR, recognizing that the phase history of the sequence of echoes is determined by

840
CHAPTER 16 Passive Bistatic Radar
FIGURE 16.17
Airborne PBR experiments: (a) Piper PA 28-181 aircraft, (b) receiver system, (c) antennas (photos: James
Brown).
the change in transmitter-to-target path (if the receiver is stationary) or target-to-receiver path (if the
transmitter is stationary) rather than the two-way path in a monostatic SAR. Thus in general the azimuth
resolution is a factor 2 coarser than the equivalent monostatic SAR.
An example of an image obtained in a system of this kind is shown in Figure 16.19. The illuminator
in this case is the European Space Agency’s ASAR synthetic aperture radar carried by the ENVISAT
satellite, whose principal parameters are given in Table 16.2.
The receiver system consisted of two channels: one pointed upwards for the direct signal from
the satellite and one for the echoes from the target scene [68,69]. The antenna used for the target
scene channel was a 1.2 m diameter parabolic dish, which gave a gain of approximately 35 dBi and
a beamwidth of approximately 3.5◦(which limits the angular ﬁeld of view in the image). The image
shows that short-range imaging of this kind is certainly feasible, but the practical applicability is limited
by the satellite orbit, such that the target scene is illuminated for approximately 1 s with a repeat interval
of the order of days.
2.16.8.6 Short-range surveillance using WiFi and WiMAX
Another class of signal that has received signiﬁcant attention for short-range surveillance using PBR
are the wireless transmissions for WiFi Local Area Networks (LANs)—IEEE Std 802.11 [70–72] and

2.16.8 Applications
841
FIGURE 16.18
Results from trials with UCL aircraft-borne PBR receiver. The ambiguities associated with the intersection
of the differential range ellipses may be resolved using the target velocity vectors.
WiMAX Metropolitan Area Networks (MANs)—IEEE Std 802.16 [73–75]. The WiFi standard is low-
power and short-range, intended primarily for indoor use, and therefore potentially usable for surveil-
lance within buildings or for short-range outdoor applications; the WiMAX standard provides broader
coverage (up to several tens of km) so may be useful for applications such as port or harbor surveillance.
The overall IEEE 802.11 WiFi standard uses either Direct Sequence Spread Spectrum (DSSS) or
Orthogonal Frequency Division Multiplexing (OFDM). The 802.11b and 802.11g standards operate in
the 2.4 GHz band, while 802.11a uses the 5 GHz band. The transmitters tend to use dynamic power
management according to the number of users, but a maximum value for the transmit power might be
100 mW.
A typical ambiguity function, showing cuts at zero range and zero Doppler, is given in Figure 16.20.
It can be seen that the ambiguity function is well behaved. The range resolution is of the order of 30 m

842
CHAPTER 16 Passive Bistatic Radar
FIGURE 16.19
Experimental results from satellite bistatic experiments: imaged targets overlaid on aerial photograph (upper);
corresponding map data (lower).

2.16.8 Applications
843
Table 16.2 Principal Parameters of ASAR Radar and ENVISAT Satellite
Frequency
5.331 GHz
Antenna
320-element electronically-scanned array, 10 m × 1.3 m
Transmit power
1365 W
PRF
1650–2100 Hz
Pulse bandwidth
Up to 15 MHz
Pulse length
20 µs
Polarization
VV or HH
Swath width
Up to 100 km
Orbit
Low Earth Orbit (LEO)
Sun-synchronous, 800 km mean altitude,
1, 3, or 35-day repeat cycle
FIGURE 16.20
Ambiguity function for WiFi 802.11b preamble/header signal, and cuts at zero range and zero Doppler [76].

844
CHAPTER 16 Passive Bistatic Radar
Table 16.3 Experimental Parameters
Transmit power
+6 dBm
transmit antenna gain
0 dBi
Receive antenna gain
18 dBi
Wavelength
0.123 m
Target RCS
Variable
Transmitter-to-target range
2.2 m
Target-to-receiver range
1–4 m
Total losses
11 dB
Effective bandwidth
11 MHz
Receiver noise Figure
3 dB
which is rather coarse for indoor applications, but the Doppler resolution can be quite good, particularly
if long integration times are used, suggesting that micro-Doppler information on echoes from moving
targets, such as walking humans, may be extracted and exploited.
The ﬁrst reported example of such a system is in [70], using an 802.11 wireless network transmitter
as the illumination source in a simple short-range conﬁguration in an indoor environment. Table 16.3
shows some of the operating parameters of the system.
The results show power levels consistent with a simple application of the bistatic radar equation.
This form of system, and in particular the type of waveform transmissions and their radar properties,
have been analyzed in more detail in [76]. Here the WiFi transmission sequence has been found to be
quite sophisticated and dependent on the user environment, but is dominated by the Direct Sequence
Spread Spectrum (DSSS) and Orthogonal Frequency Division Multiplexing (OFDM) signals. Ambi-
guity function analysis of the DSSS based WiFi signal shows that range and Doppler performance is
comparable with that expected from theoretical predictions. Detection of moving human targets was
demonstrated for the ﬁrst time. This work shows that this technique has considerable promise for a low
cost and widely deployable short-range detection and tracking system.
In [72] the passive bistatic WiFi radar approach is explored further to determine performance limits,
by examining the detection of targets in a dense clutter background. Through-wall detections of person-
nel targets moving at differing velocities within an indoor environment were presented for the ﬁrst time
in this publication. Figure 16.21 shows the geometry employed. As an example, Figure 16.22 shows a
“raw” range Doppler map integrated over a time interval of 300 ms in which a target is circled against
quite a dense clutter background. The target is corroborated with ground truth and provides a sound
basis for subsequent detection and tracking. The complexity of the clutter environment with multiple
reﬂections occurring in both the direct and indirect channels can be appreciated. Overall these papers
demonstrate that it is feasible to use WiFi transmissions to make passive bistatic radar systems that can
be used over short ranges in both indoor and outdoor scenarios.
As indicated in Section 2.16.6, the “big brother” to WiFi, WiMAX has considerably higher transmis-
sion power levels (perhaps 20 W compared to 100 mW) and represents a potentially attractive alternative
to DAB and DVB. In the UK there are currently two bands licensed at 3.5 and 3.6 GHz. The band-
width is variable from 1.25 MHz to 20 MHz and hence higher range resolutions than WiFi are possible.

2.16.8 Applications
845
FIGURE 16.21
Schematic of the indoor dense clutter WiFi radar experimental set up.
FIGURE 16.22
“Raw” range Doppler map integrated over a time span of 300 ms in which a target is circled against quite
a dense clutter background.

846
CHAPTER 16 Passive Bistatic Radar
This means that imaging techniques start to be more readily addressable, although, to date, application
has concentrated on detection.
In [75] Chetty et al. have considered the use of WiMAX transmissions in the problem of providing
maritime radar surveillance. Their study shows that a 4000 m2 target should be detected out to a range
of 45 km with a transmitter-to-receiver baseline of between 10 and 32 km. This level of coverage is
suitable for busy commercial maritime areas such as that covered by the Port of London. Range and
Doppler resolution are calculated to be 5 m and 3.5 Hz respectively which is consistent with parameters
appropriate for the detection of marine vessels. They conclude by recommending ﬁeld trials of an
experimental system.
2.16.8.7 PBR using HF skywave signals
A ﬁnal application is long-range surveillance using over-the-horizon (OTH) HF signals. Skywaves can
propagate over very long distances around the curvature of the Earth by means of a series of reﬂections
and refractions occurring successively between the Earth’s surface and reﬂecting layers in the ionosphere
(the D-layer at a height of about 60 km, the E-layer at about 100 km and the F-layer from 250 to 400 km).
The range provided by one propagation hop is typically from about 1000 km to 3000 km, although it
can be as great as 4000 km. Surface wave propagation occurs near the ground for short distances, up to
100 km over land and 300 km over the sea. Attenuation of the wave is a function of the antenna height,
polarization, frequency, and surface type. Also, this surface wave decays with distance more rapidly
than the normal inverse square law of line-of-sight propagation [77].
Such frequencies are used for long-range communication (though less so now than in their heyday in
the twentieth century), for HF broadcast, and for HF OTH radar. The ionosphere is a region of ionized
gas (plasma) that surrounds the Earth at a height of 50–2000 km. The ionization is a consequence of
solar UV and X-ray radiation, and hence is a function of the time of day (since the ions recombine
during darkness), season of the year (since there are more hours of daylight during summer) and of
solar activity, which varies on a period of approximately 11 years, known as the sunspot cycle. The
distribution of ionization is modiﬁed by the Earth’s magnetic ﬁeld, generally enhancing and raising
the ion content near the equator. The coverage therefore depends on all of these factors, and (most
importantly) on frequency, so it is necessary to choose the correct frequency to provide the desired
coverage at any given date and time of day.
In general, HF broadcast signals will be of low bandwidth (for example, a DSB AM broadcast
signal will typically have a bandwidth of about 12 kHz, corresponding to a radar range resolution of
12.5 km. Also, although HF transmitters may use physically large antennas, their beamwidths at such
low frequencies are relatively broad, and their footprints at such long ranges are correspondingly broad.
The resolution both in range and in azimuth, when such signals are used for radar purposes, is therefore
coarse. Another consequence of the low radar frequency is that the Doppler shift for a given target
velocity is lower than would be the case at higher radar frequencies.
As with other forms of broadcast signals used for PBR, digital modulation formats, such as the Digital
Radio Mondiale (DRM) standard, gives better performance that analog signals, since their ambiguity
performance is constant with time and does not depend on the program material [78].
Bistatic radar experiments have been conducted using HF OTH radars (such as the Australian JORN
network [83] or the US ROTHR (AN/TPS-71) systems [84] in Virginia, Puerto Rico, and Texas) as

2.16.9 Open Issues and Problems
847
illumination sources, for applications such as detection of air and maritime targets. The geometry
employed here is usually with the receiver close to the target scene, and receiving both the direct
(sky-wave) signal from the transmitter and the target echoes.
Another variation is to use HF radio broadcast signals (such as the BBC’s World Service or the US
Voice of America) as the illumination source. A website [85] shows results obtained from some amateur
radio experiments in which a communications receiver listens to a CW carrier from a transmitter at a
frequency of about 26 MHz and at a range from the receiver of approximately 100 km. The audio
output from the receiver is digitized and displayed in the form of a spectrogram (frequency vs time).
Typical results show the carrier over a period of several minutes, as well as Doppler-shifted echoes from
aircraft undergoing particular maneuvers. The author of the website states that this processing is very
straightforward and urges: “do try this at home”; the cost of the hardware (essentially just a radio receiver
and a PC) is low and the software to perform the processing can be downloaded from the website.
Lesturgie and Poullin [79] have published results of experiments using an HF broadcast signal in
Kiev, Ukraine and a receiver located either on a ship or on the shore, detecting aircraft targets at ranges
typically from 50 to 200 km.
All of these results indicate that PBR using HF skywave illuminators has considerable potential for
target detection and tracking, at ranges much greater than achieved by conventional radars.
2.16.9 Open issues and problems
We provide here a list of open issues and problems, in addition to those already alluded to above.
2.16.9.1 Identifying applications
As noted in the introduction to this chapter, one of the key open issues with PBR is to identify appropriate
applications in which there is a demonstrable advantage over conventional approaches in terms of
performance and/or cost. To those listed in the introduction and in the previous section we might add
use as an adjunct to ATC (Air Trafﬁc Control) radar in regions where coverage is poor. This is under
active investigation, but it has yet to be shown to be 100% reliable.
2.16.9.2 Detection of and countermeasures against PBR
One of the claimed advantages of PBR in a defense/security context is that it is potentially completely
covert. As long as the receive antennas are inconspicuous, an adversary will have no indication that a
PBR system has been deployed. Turning that on its head, there will be no indication that a PBR system
may have been deployed by an adversary against our own assets. A British WW2 intelligence document
[80] describing the German Klein Heidelberg bistatic radar [81], which used the British Chain Home
radar transmissions as its illumination source, considers countermeasures against a bistatic radar of this
kind, and lists four possibilities:
i. Physical attack of the receiver (if its location is known);
ii. Turn off, or otherwise interrupt the transmitter;
iii. Alter the form of the transmitted signal to make synchronization more difﬁcult;

848
CHAPTER 16 Passive Bistatic Radar
iv. Use a repeater jammer to generate multiple false targets which will overload and confuse the
detection and tracking processing.
Nearly 70 years later, these approaches seem just as relevant.
2.16.9.3 Characterization of bistatic radar clutter
It has already been remarked that bistatic radar clutter is poorly understood, both in terms of its mean
reﬂectivity and of its statistical properties. There is therefore great scope for conducting trials to make
measurements of bistatic radar clutter, as a function of surface type (sea, land, etc.) and conditions
(wave height, wind speed, etc.), bistatic geometry, frequency and polarization, resolution, and hence
for developing models both for the mean clutter RCS and for the amplitude statistics, as a function of
these parameters. The experimental data should also be useful in developing a better understanding of
the physical scattering mechanisms involved.
In the case of PBR, and particularly for urban environments, it should be possible to use the wealth of
data and analysis that has been gathered of mobile radio multipath propagation to model the properties
of PBR clutter. This should in turn allow improved direct signal and multipath suppression algorithms
to be designed and evaluated.
2.16.10 Conclusions and future trends
This chapter has attempted to provide an account of the fundamentals of passive bistatic radar. We
can conclude that the subject has come a long way since the ﬁrst modern experiments in the early
1980s—andcertainlysincetheﬁrst radar experiments usingbroadcast signals morethan50 years prior to
that. We have seen that PBR offers the potential of covert operation with simple and low-cost equipment
and with no need for a transmitting licence, and the ability to use parts of the EM spectrum that are not
normally available for radar use. The wide variety of broadcast, communications and radionavigation
sources, and their excellent spatial coverage and (in many cases) high power gives great scope for PBR.
In common with all bistatic radars it may allow advantage to be taken of mechanisms such as forward
scatter which signiﬁcantly enhance the radar signature of targets. The fact that PBR systems can be
simple and low cost has meant that they have been very suitable for research by university groups, and
there have been numerous publications on the subject.
Against this must be balanced the fact that the waveforms that are used for PBR are not designed
explicitly for radar, so their performance in radar applications is not optimal. Care must therefore be
taken to understand how best to choose which transmissions to use and how best to process them. It
is found that analog modulation formats tend to give time-varying ambiguity performance, but more
modern digital modulation formats are much better in this respect. In addition, as with all bistatic radars,
the ambiguity performance is a function of the bistatic geometry, so for targets on or close to the bistatic
baseline the range and Doppler resolution are both poor, no matter what the waveform.
Since most PBR modulation sources are continuous and high-powered, and operate in bands that are
already congested, the level of direct signal and other noise sources is inevitably high, and considerable
signal processing effort has to be expended to suppress these signals to allow the target echoes to be
reliably detected.

Acronyms
849
The applications to which PBR systems may be put therefore need careful thought. It is no good
claiming to do “almost as well” as conventional radar approaches. It is important to understand very
thoroughly the relationship between the desired application (surveillance, remote sensing, etc.) and
the performance requirements that follow, and the properties of the illuminator source that might be
used—for example, in terms of coverage (spatial and temporal), power level, bandwidth (resolution),
integration time (scene stationarity) and so on.
Amongst the applications identiﬁed, ones which show particular promise are:
• Scientiﬁc measurements (remote sensing) where long integration times can be employed.
• Border or perimeter surveillance (perhaps exploiting forward scatter) and/or protection of critical
assets.
• Gap ﬁlling in areas where operation of conventional sensors is incomplete.
We may also comment that because the ambiguity functions of PBR illuminators depend fundamen-
tally on bistatic geometry, there will always be regions where the performance of a bistatic sensor is
compromised. It makes sense, therefore, to think in multistatic terms rather than purely bistatic.
Finally, given the ever-greater degree of spectral congestion, it may make sense in future deliberately
to design the waveforms used for broadcast, communications and radionavigation purposes so that their
performance in PBR applications is in some sense optimized, as well as for their primary purpose. The
ability of modern digital signal processing to generate precise, wideband waveforms and to vary them
adaptively is key to this. Professor Mike Inggs has coined the term “commensal” (literally, “sharing the
same table”) for this approach.
Acronyms
Commonly used acronyms:
AM
Amplitude Modulation
ASAR
Advanced Synthetic Aperture Radar
ATC
Air Trafﬁc Control
BBC
British Broadcasting Corporation
BNR
Bistatic Network Radar
CDMA
Code Division Multiple Access
CFAR
Constant False Alarm Rate
DAB
Digital Audio Broadcasting
DBS
Direct Broadcast Satellite
DOA
Direction of Arrival
DRM
Digital Radio Mondiale
DSB
Double Sideband
DSI
Direct Signal Interference
DSSS
Direct Sequence Spread Spectrum
DVB
Digital Video Broadcasting
EIRP
Effective Isotropic Radiated Power

850
CHAPTER 16 Passive Bistatic Radar
EKF
Extended Kalman Filter
ESA
European Space Agency
FDMA
Frequency Division Multiple Access
FM
Frequency Modulation
FOV
Field of View
GLONASS
GLObal’naya NAvigatsionnaya Sputnikovaya Sistema
GMSK
Gaussian Minimum-Shift Keying
GNSS
Global Navigation Satellite Systems
GPS
Global Positioning System
GSM
Groupe Spéciale Mobile; Global System for Mobile Communications
HDTV
High Deﬁnition Television
HF
High Frequency
HRRP
High Resolution Range Proﬁle
ISAR
Inverse Synthetic Aperture Radar
JORN
Jindalee Operational Radar Network
LAN
Local Area Network
LEO
Low Earth Orbit
MAN
Metropolitan Area Network
MRR
Manastash Ridge Radar
NCTR
Non-Cooperative Target Recognition
NEXRAD
Next Generation Radar
NTSC
National Television System Committee
OFDM
Orthogonal Frequency Division Multiplexing
OTH
Over-The-Horizon
PAL
Phase Alternating Line
PBR
Passive Bistatic Radar
PCL
Passive Coherent Location
PHD
Probability Hypothesis Density
PRN
Pseudo Random Noise
QAM
Quadrature Amplitude Modulation
RCS
Radar Cross Section
ROTHR
Relocatable Over-The-Horizon Radar
SAR
Synthetic Aperture Radar
SECAM
Séquentiel Couleur à Mémoire
SNR
Signal-to-Noise Ratio
TDMA
Time Division Multiple Access
TDOA
Time Difference Of Arrival
UCL
University College London
UHF
Ultra High Frequency
UV
Ultra Violet
VHF
Very High Frequency
WiMAX
Worldwide Interoperability for Microwave Access

References
851
Glossary
Bistatic radar
a radar using antennas for transmission and reception at sufﬁciently different
locations that the angles or ranges to the target are signiﬁcantly different [1]
Clutter diversity
exploitation of the variation of clutter properties as a function of bistatic geom-
etry, so as to be able to choose the optimum bistatic radar geometry to best
exploit the variation of target and clutter behavior so as to obtain optimal
detection performance
Forward scatter
a bistatic radar conﬁguration in which the target lies on or close to the baseline
between the transmitter and receiver
Illuminator of
opportunity
a transmitter source whose primary purpose is not part of a bistatic radar, but
which is used, opportunistically, by a bistatic radar as its transmitter
Passive bistatic radar
(PBR)
a set of techniques using broadcast, communications or radionavigation sig-
nals as illumination sources rather than using a dedicated radar transmitter.
Other terms that have been used include passive coherent location (PCL), pas-
sive and covert radar (PCR), covert radar, non-cooperative radar, broadcast
radar, parasitic radar, and opportunistic radar [1]
Waveform diversity
adaptivity of the radar waveform to dynamically optimize the radar perfor-
mance for the particular scenario and tasks. May also exploit adaptivity in
other domains, including the antenna radiation pattern (both on transmit and
receive), time domain, frequency domain, coding domain and polarization
domain [1]
Supplementary data
Supplementary data associated with this article can be found, in the online version, at http://dx.doi.org/
10.1016/B978-0-12-411597-2.00016-3.
Acknowledgments
I express my thanks to all of the people from whom I have learned about bistatic radar, and who have helped
by providing results and by their discussion and constructive criticism. In particular I would like to mention (in
alphabetical order) Chris Baker, James Brown, Mike Cherniakov, Mike Inggs, Krzysztof Kulpa, Aaron Lanterman,
Daniel O’Hagan, John Sahr, Simon Watts, Keith Ward, Aric Whitewood, Nick Willis and Karl Woodbridge. Their
inspiration and help has been enormously appreciated.
References
[1] IEEE Standard Radar Deﬁnitions, IEEE Std-2008, 26 March 2008.
[2] R.A. Watson-Watt, Three Steps to Victory, Odhams Press, London, 1957, pp. 107–117 (Chapter 20).

852
CHAPTER 16 Passive Bistatic Radar
[3] Science News Letter, April 23, 1938.
[4] H.D. Grifﬁths, N.R.W. Long, Television-based bistatic radar, IEE Proc. Pt.-F, 133 (7) (1986) 649–657.
[5] P.E. Howland, Target tracking using television-based bistatic radar, IEE Proc. Radar Sonar Navig. 146 (3)
(1999) 166–174.
[6] C.J. Baker, H.D. Grifﬁths, I. Papoutsis, Passive coherent radar systems – Part II: Waveform properties, IEE
Proc. Radar Sonar Navig. 152 (3) (2005) 160–168.
[7] M.C. Wicks, E.L. Mokole, S.D. Blunt, R.S. Schneible, V.J. Amuso (Eds.), Principles of Waveform Diversity
and Design, SciTech Publishing Inc., Raleigh, NC, 2010.
[8] J.D. Sahr, F.D. Lind, The Manastash Ridge radar: a passive bistatic radar for upper atmospheric radio science,
Radio Sci. 32 (6) (1997) 2345–2358.
[9] J.D. Sahr, Passive radar observation of ionospheric turbulence, in: N.J. Willis, H.D. Grifﬁths (Eds.), Advances
in Bistatic Radar, SciTech, Raleigh, NC, 2007 (Chapter 10).
[10] R.A. Simpson, Spacecraft studies of planetary surfaces using bistatic radar, IEEE Trans. Geosci. Remote Sens.
31 (2) (1993) 465–482.
[11] J. Wurman, M. Randall, C.L. Frush, E. Loew, C.L. Holloway, Design of a bistatic dual-Doppler radar for
retrieving vector winds using one transmitter and a remote low-gain passive receiver, Proc. IEEE 82 (12)
(1994) 1861–1871.
[12] S. Satoh, J. Wurman, Accuracy of wind ﬁelds observed by a bistatic Doppler radar network, J. Ocean. Atmos.
Technol. 20 (2003) 1077–1091.
[13] E.F. Greneker, J.L. Geisheimer, The use of passive radar for mapping lightning channels in a thunderstorm,
in: IEEE Radar Conference, Huntsville, AL, USA, 5–8 May 2003, pp. 28–33.
[14] D.J. Bannister, Radar in-ﬁll for Greater Wash area: feasibility study ﬁnal report, Department for Business,
Enterprise and Regulatory Reform, UK, 31 August 2007.
[15] J. Baniak, G. Baker, A.M. Cunningham, L. Martin, Silent Sentry passive surveillance, Aviation Week and
Space Technology, 7 June 1999.
[16] H.D. Grifﬁths, L. Cohen, S. Watts, E. Mokole, C.J. Baker, M.C. Wicks, S.D. Blunt, Radar spectrum manage-
ment and engineering issues: regulatory and technical approaches, IEEE Proc.
[17] H.L. Van Trees, Detection, Modulation and Estimation Theory, Parts I, II, III, and IV, Wiley, 2001.
[18] P.M. Woodward, Probability and Information Theory, with Applications to Radar, Pergamon Press, 1953;
Reprinted by Artech House, 1980.
[19] F. Le Chevalier, Principles of Radar and Sonar Signal Processing, Artech House, 2002.
[20] V.S. Chernyak, Fundamentals of Multisite Radar Systems: Multistatic Radars and Multiradar Systems, Gordon
& Breach, 1998.
[21] N.J.Bistatic Willis, Radar, second ed., Technology Service Corp., Silver Spring, MD, 1995, corrected and
republished by SciTech Publishing, Inc, Raleigh, NC, 2005.
[22] N.J. Willis, H.D. Grifﬁths, Advances in Bistatic Radar, SciTech Publishing Inc., Raleigh, NC, 2007.
[23] N.J. Willis, Bistatic Radar, in: M.I. Skolnik (Ed.), Radar Handbook, third ed., McGraw-Hill, 2008 (Chapter 23).
[24] M. Cherniakov (Ed.), Bistatic Radar: Principles and Practice, (2007) and Bistatic Radar: Emerging
Technology, Wiley, 2008.
[25] M.C. Jackson, The geometry of bistatic radar systems, IEE Proc. Pt. F. 133 (7) (1986) 604–612.
[26] G.W. Ewell, Bistatic radar cross section measurements, in: N.C. Currie (Ed.), Techniques of Radar Reﬂectivity
Measurement, Artech House, 1989 (Chapter 7).
[27] G.W. Ewell, S.P. Zehner, Bistatic radar cross section of ship targets, IEEE J. Ocean. Eng. OE-5 (4) (1980)
211–215.
[28] R.E. Kell, On the derivation of bistatic RCS from monostatic measurements, Proc. IEEE 53 (1965) 983–988.
[29] M. Born, E. Wolf, Principles of Optics, sixth ed., Pergamon Press, 1980, p. 559.

References
853
[30] H.D. Grifﬁths, W.A. Al-Ashwal, K.D. Ward, R.J.A. Tough, C.J. Baker, K. Woodbridge, Measurement and
modelling of bistatic radar sea clutter, IET Radar Sonar Navig. 4 (2) (2010) 280–292.
[31] M. Weiner, Clutter, in: N.J. Willis, H.D. Grifﬁths (Eds.), Advances in Bistatic Radar Scitech Inc., Raleigh,
NC, 2008 (Chapter 9).
[32] A.R. Domville, The bistatic reﬂection from land and sea of X-band radio waves, GEC (Electronics) Ltd.,
Memo SLM 1802 , Stanmore, England, July 1967.
[33] G.A. Yates, Bistatic Synthetic Aperture Radar, PhD Thesis, University College London, January 2005.
[34] K.D. Ward, R.J.A. Tough, S. Watts, Sea Clutter: Scattering, the K-Distribution and Radar Performance, IET,
London, 2006.
[35] W.A. Al-Ashwal, C.J. Baker, A. Balleri, H.D. Grifﬁths, R. Harmanny, M. Inggs, W.J. Miceli, M. Ritchie,
J.S. Sandenbergh, A. Stove, R.J.A. Tough, K.D. Ward, S. Watts, K. Woodbridge, Statistical analysis of simul-
taneous monostatic and bistatic sea clutter at low grazing angles, Electron. Lett. 47 (10) (2011) 621–622.
[36] W.A. Al-Ashwal, C.J. Baker, A. Balleri, H.D. Grifﬁths, R. Harmanny, M. Inggs, W.J. Miceli, M. Ritchie,
J.S. Sandenbergh, A. Stove, R.J.A. Tough, K.D. Ward, S. Watts, K. Woodbridge, Measurements of bistatic
radar sea clutter, in: IEEE Radar Conference 2011, Kansas City, MO, 23–27 May 2011, pp. 217–221.
[37] T. Tsao, M. Slamani, P. Varshney, D. Weiner, H. Schwarzlander, S. Borek, Ambiguity function for a bistatic
radar, IEEE Trans. Aerosp. Electron. Syst. 33 (3) (1997) 1041–1051.
[38] M.A. Ringer, G.J. Frazer, Waveform analysis of transmissions of opportunity for passive radar, Proc.
ISSPA’99, Brisbane, Australia, 22–25 August 1999, pp. 511–514.
[39] H.D. Grifﬁths, C.J. Baker, H. Ghaleb, R. Ramakrishnan, E. Willman, Measurement and analysis of ambiguity
functions of off-air signals for passive coherent location, Electron. Lett. 39 (13) (2003) 1005–1007.
[40] C.J. Baker, H.D. Grifﬁths, I. Papoutsis, Passive coherent radar systems – Part II: Waveform properties, IEE
Proc. Radar Sonar Navig. 152 (3) (2005) 160–168.
[41] H.D. Grifﬁths, C.J. Baker, Passive Bistatic Radar, in: W. Melvin (Ed.), Principles of Modern Radar SciTech
Publishing Inc., vol. 3 Raleigh, NC, (Chapter 11) (in press).
[42] D. Poullin, Passive detection using digital broadcasters (DAB, DVB) with COFDM modulation, IEE Proc.
Radar Sonar Navig. 152 (3) (2005) 143–152.
[43] H.D. Grifﬁths, C.J. Baker, The signal and interference environment in passive bistatic radar information, in:
Decision and Control Symposium, Adelaide, February 2007, pp. 12–14.
[44] A. Farina, A. De Maio, T. Volpi, Waveform diversity: past, present and future, NATO Lecture Series SET-119
Waveform Diversity for Advanced Radar Systems, 2006.
[45] S. Haykin, Communication Systems, fourth ed., John Wiley, New York, 2001.
[46] P.E. Howland, D. Maksimiuk, G. Reitsma, FM radio based bistatic radar, IEE Proc. Radar Sonar Navig.
152 (3) (2005) 107–115.
[47] F. Colone, R. Cardinali, P. Lombardo, Cancellation of clutter and multipath in passive radar using a sequential
approach, in: IEEE Radar Conference, Verona, NY, USA, 24–27 April 2006, pp. 393–399.
[48] H.D. Grifﬁths, A four-element VHF adaptive array processor, in: 2nd IEE International Conference on
Antennas and Propagation, York, IEE Conference Publication No. 195, Part I, 13–16 April 1981, pp. 185–189.
[49] H.D. Grifﬁths, C.J. Baker, Passive Coherent Radar systems – Part I: Performance prediction, IEE Proc. Radar
Sonar Navig. 152 (3) (2005) 153–159.
[50] A.P. Andrews, HDTV-based passive radar, in: AOC 4th Multinational PCR Conference, Syracuse, NY,
6 October, 2005.
[51] D. O’Hagan, Passive bistatic radar performance using FM radio illuminators of opportunity, PhD Thesis,
University College London, March 2009.
[52] C.J. Coleman, R.A. Watson, H. Yardley, A practical bistatic passive radar system for use with DAB and DRM
illuminators, in: Proceedings International Conference RADAR 2008, Adelaide, Australia, 2–5 September
2008, pp. 1–7.

854
CHAPTER 16 Passive Bistatic Radar
[53] J.M. Caspers, Bistatic and Multistatic Radar, in: M.I. Skolnik (Ed.), Radar Handbook, ﬁrst ed., McGraw-Hill,
New York, 1970 (Chapter 36).
[54] M. Tobias, A.D. Lanterman, Probability hypothesis density-based multitarget tracking with bistatic range
and Doppler observations, IEE Proc. Radar Sonar Navig. 152 (3) (2005) 195–205.
[55] R.P.S. Mahler, Multitarget Bayes ﬁltering via ﬁrst-order multitarget moments, IEEE Trans. Aerosp. Electron.
Syst. 39 (4) (2003) 1152–1178.
[56] M. Tobias, Probability hypothesis densities for multitarget, multisensor tracking with application to passive
radar, PhD thesis, Georgia Institute of Technology, 2006.
[57] J. Wurman, Wind Measurements, in: N.J. Willis, H.D. Grifﬁths, (Eds.), Advances in Bistatic Radar, SciTech
Publishing Inc., Raleigh, NC, 2007 (Chapter 8).
[58] J.L. Garrison, A. Komjathy, V.U. Zavorotny, S.J. Katzberg, Wind speed measurement using forward scattered
GPS signals, IEEE Trans. Geosci. Remote Sens. 40 (1) (2002) 50–65.
[59] J.L. Garrison, S.J. Katzberg, M.I. Hill, Effect of sea roughness on bistatically scattered range coded signals
from the global positioning system, Geophys. Res. Lett., 25 (13) (1998) 2257–2260.
[60] Y. Huiazu, J.L. Garrison, G. Heckler, V.U. Zavorotny, Stochastic voltage model and experimental measurement
of ocean-scattered GPS signal statistics, IEEE Trans. Geosci. Remote Sens. 42 (10) (2004) 2160–2169.
[61] J.L. Garrison, J.K. Voo, S.H. Yueh, M.S. Grant, A.G. Fore, J.S. Haase, Estimation of sea surface roughness
effects in microwave radiometric measurements of salinity using reﬂected Global Navigation Satellite System
signals, IEEE Geosci. Remote Sens. Lett. 8 (6) (2011) 1170–1174.
[62] V.C. Chen, The Micro-Doppler Effect in Radar, Artech House, 2011.
[63] E.F. Greneker, Detection and tracking of humans and vehicle targets using high deﬁnition television signals
in urban areas, Proc. SPIE (2007).
[64] V. Koch, R. Westphal, A new approach to a multistatic passive radar sensor for air defense, in: IEEE
International Radar Conference RADAR 1995, Washington, DC, IEEE Conf. Publ. No. 95CH3571-0, 8–11
May 1995, pp. 22–28.
[65] V. Koch, R. Westphal, New approach to a multistatic passive radar sensor for air/space defense, IEEE AES
Mag. 10 (11) (1995) 24–32.
[66] J. Brown, K. Woodbridge, A.G. Stove, S. Watts, Air target detection using airborne passive bistatic radar,
Electron. Lett. 46 (20) (2010) 1396–1397.
[67] J. Brown, H.D. Grifﬁths, A.G. Stove, S. Watts, K. Woodbridge, Passive bistatic radar location experiments
from an airborne platform, IEEE AES Mag. (in press).
[68] A.P. Whitewood, Bistatic radar using a spaceborne illuminator, PhD thesis, University College London, June
2006.
[69] A. Whitewood, C.J. Baker, H.D. Grifﬁths, Bistatic radar using a spaceborne illuminator, in: Proceedings IET
International Conference RADAR 2007, Edinburgh, 15–18 October 2007, pp. 1–5.
[70] H. Guo, S. Coetzee, D. Mason, K. Woodbridge, C.J. Baker, Passive radar detection using wireless networks,
in: IET Radar Conference RADAR 2007, Edinburgh, 15–18 September 2007, pp. 1–4.
[71] F. Colone, K. Woodbridge, H. Guo, D. Mason, C.J. Baker, Ambiguity function analysis of wireless LAN
transmissions for passive radar, IEEE Trans. Aerosp. Electron. Syst. 47 (1) (2011) 240–264.
[72] K. Chetty, G. Smith, H. Guo, K. Woodbridge, Target detection in high clutter using passive bistatic WiFi
radar, in: IEEE Radar Conference, Pasadena, CA, USA, 4–8 May 2009, pp. 1–5.
[73] Q. Wang, Y. Lu, C. Hou, Evaluation of WiMAX transmission for passive radar applications, Microw. Opt.
Technol. Lett. 52 (7) (2010) 1507–1509.
[74] F. Colone, P. Falcone, P. Lombardo, Ambiguity function analysis of WiMAX transmissions for passive radar,
in: IEEE International Radar Conference RADAR 2010, Washington, DC, 10–14 May 2010, pp. 689–694.
[75] K. Chetty, K. Woodbridge, H. Guo, G.E. Smith, Passive bistatic WiMAX radar for marine surveillance, in:
IEEE International Radar Conference RADAR 2010, Washington, DC, 10–14 May 2010.

References
855
[76] H. Guo, K. Woodbridge, C.J. Baker, Evaluation of WiFi beacon transmissions for wireless based passive
radar, in: IEEE Radar Conference, Rome, Italy, 1–6 May 2008, pp. 26–30.
[77] J.M. Headrick, J.F. Thompson, Applications of high-frequency radar, Radio Sci. 33 (4) (1998) 1045–1054.
[78] J.M. Thomas, H.D. Grifﬁths, C.J. Baker, Ambiguity function analysis of digital radio mondiale signals for
HF passive bistatic radar, Electron. Lett. 42 (25) (2006) 1482–1483.
[79] M. Lesturgie, D. Poullin, Frequency allocation in radar: solutions and compromise for low frequency band,
in: SEE International Radar Conference RADAR 99, Paris, France, 18–20 May 1999.
[80] Air Scientiﬁc Intelligence Interim Report, Heidelberg, A.D.I. (Science), IIE/79/22, Public Records Ofﬁce,
Kew, London, 24 November 1944.
[81] H.D. Grifﬁths, N.J. Willis, Klein Heidelberg – the ﬁrst modern bistatic radar system, IEEE Trans. Aerosp.
Electron. Syst. 46 (4) (2010) 1571–1588.
Websites
[82] <http://www.air-defense.net/forum/index.php?topic=11376.0>.
[83] <http://www.defence.gov.au/dmo/esd/jp2025/jp2025.cfm>.
[84] <http://www.raytheon.com/capabilities/products/stellent/groups/public/documents/legacy_site/
cms01_049201.pdf>.
[85] <http://www.qsl.net/g3cwi/doppler.htm>.

17
CHAPTER
Through-the-Wall Radar Imaging:
Theory and Applications
Moeness G. Amin* and Fauzia Ahmad†
*Center for Advanced Communications, Villanova University, Villanova, PA, USA
†Radar Imaging Lab, Center for Advanced Communications, Villanova University,
Villanova, PA, USA
2.17.1 Introduction
The ﬁeld of remote sensing has developed a range of interesting imaging approaches for a variety of
applications. Through-the-wall sensing is a relatively new area that addresses the desire to see inside
buildings for various purposes, including determining the room layouts, discerning the building intent
and nature of activities, locating the occupants, and even identifying and classifying objects within
the building. Through-the-wall sensing is highly desired by police, ﬁre and rescue, emergency relief
workers, and military operations. Accurate sensing and imaging can allow a police force to obtain an
accurate description of a building in a hostage crisis, or allow ﬁreﬁghters to locate people trapped inside
a burning structure. In essence, the goals of through-the-wall sensing technology are to provide vision
into otherwise obscured areas [1].
Each remote sensing application area has driven different sensing modalities and imaging algorithm
development based upon propagation characteristics, sensor positioning, and safety issues. Traditional
optical, radar, and sonar image processing all begin with basic wave physics equations to provide
focusing to individual points. In many radar applications, for example, data sampled from many sensors
are mathematically integrated to provide equivalent focusing using free-space propagation assumptions.
Free-space imaging is commonly seen in synthetic aperture radar (SAR) techniques since atmospheric
distortions are often negligible and can be safely ignored in ﬁrst-order calculations [2].
Conventional imaging approaches exploit the wave equation to compute the expected phase at each
point in space and time over which the data are collected. The complex phase front is similar to the
spatial representation of the wavefront captured by a hologram [3]. The complex returns can then
be compared against the predicted returns from points in the imaging target space to focus on each
point in that space. The focusing is analogous to image reconstruction in holography, where a spatial
pattern is projected back into the originating target image space. In true free-space conditions, this
focusing approach represents a mathematically accurate way to perform imaging. More sophisticated
approaches extend beyond free-space assumptions to allow for more complicated propagation effects,
such as adaptive optics [4], atmospheric correction for radar [2], and matched ﬁeld processing for sonar
[5]. Correction approaches range from simple wavefront calibration to more sophisticated volumetric
propagation corrections.
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-396500-4.00017-X
© 2014 Elsevier Ltd. All rights reserved.
857

858
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
Free-space propagation does not apply to several applications where transmission through scattering
media is encountered, including many modern imaging approaches such as geophysical sensing, medical
imaging, and more recently through-the-wall imaging and sensing. In these applications, propagating
signals diffract through a volume. As examples, geophysical imaging techniques generally measure
seismic propagation through the earth to look for discontinuities that are often indicators of oil, gas,
water, or mineral deposits [6]. In medical imaging, ultrasound tomographic approaches account for
propagation through different tissue classes [7].
Non-freespace scattering applications are more representative of the through-the-wall sensing prob-
lem, albeit each has its own distinct challenges and approaches [1]. In geophysical and medical appli-
cations, the propagation medium is discontinuous but still respectively ﬁlls the sensing volume of the
earth and tissue. To better propagate into the volume, sensors are placed in direct contact with the
medium (e.g., seismometers for geophysical sensing, ultrasound transducers for medical imaging). In
through-the-wall sensing, there are many air-material interfaces that dramatically change the wavefront.
Through-the-wall sensors may be placed against the front walls or located some distance away from the
structure. In either case, attenuation is largely seen only in the building materials and contents rather
than in the large volumes of air that occupy most of the space outside or within a building. The rich
through- the-wall scattering environment makes volumetric tomographic imaging approaches most rel-
evant for through-the-wall sensing. Rather than using free-space focusing assumptions, correcting for
propagation effects may greatly improve the imaging solution [8–10].
Through-the-wall sensing is best motivated by examining the applications primarily driving its devel-
opment. Through-the-wall sensing grew from the application of ground-penetrating radar systems to
walls, with speciﬁc applications documented in the literature since the late 1990s showing abilities to
sense beyond a single wall from near range [11–25]. Applications can be divided based upon whether
information is sought on motions within a structure or on imaging the structure and its stationary
contents.
The need to detect motion is highly desired in situations like ﬁreﬁghters ﬁnding a child in a burning
building or law enforcement ofﬁcers locating hostages and their captors. Such applications can resort
to Doppler discrimination of movement from background clutter [26–31]. Motion detection and local-
ization can be decomposed into zero (0-D), one (1-D), two (2-D), or three-dimensional (3-D) systems.
A 0-D system is simply a motion detector and will report any motion in the scene. Such systems may
be useful to detect whether a room is occupied or not, often useful in monitoring applications such as
security systems or intruder detection. Interior motion may be ample information for a ﬁreﬁghter to
decide whether to enter a room or building. Since range or angle is not required, 0-D systems may use
continuous wave (CW) tones as waveforms. While such systems have exquisite sensitivity, it is difﬁcult
to conﬁne the sensitivity to desired areas, so care must be taken to prevent undesired detections beyond
the intended range or even from the system operator himself due to multipath reﬂections. 0-D systems
are not particularly useful in cases where other moving individuals may be within the sensor ﬁeld of
view.
One-dimensional systems provide a range to a target but not an angle. The extra dimension provides
the ability to separate and possibly discriminate multiple targets. The range information can help bound
whether a detection is in the adjacent room, or perhaps deeper within the building. The systems can obvi-
ously gate out detections from ranges beyond the ranges of interest, and may more easily discriminate

2.17.1 Introduction
859
desired target motion from the motion of the operator. The systems often consist of a single receiving
antenna in addition to a transmitting antenna (although sometimes a single antenna can be used for both
functions). Motion of the operator can be gated out in range, or a reference antenna pointed towards
the radar operator can be used for cancellation. Ranging is historically one of the principle reasons for
the development of radar technology, but the short stand-off ranges of most through-the-wall systems
provide some particular challenges. Three methods are often employed to obtain target range, namely,
ultrawideband pulses [22,32–36], dual frequencies [28,37–39], or stepped CW [11,20].
Two-dimensional systems provide a slice through the scene in the range and angle dimensions
[11,22,23]. The 2-D representation provides better localization of the mover, at the expense of a larger
antenna array whose elements are collinear. 2-D systems will be subject to layover of objects, meaning
that objects out of plane will appear to be rotated to the imaging plane, which can lead to distortion of
the ﬁeld of view. 3-D systems attempt to represent a volumetric representation of the ﬁeld of view in the
range, azimuth, and elevation dimensions [40]. The third dimension avoids the layover issue of targets
being projected into a 2-D plane; at the expense of a 2-D array and higher processing requirements.
Potentially, the third dimension can provide additional localization for identiﬁcation of targets. Height
information may allow discrimination between people and animals such as household pets, since radar
cross-section alone can be unreliable in the presence of through-the-wall multipath and other issues.
The ultimate goal is higher resolution for even better moving target classiﬁcation. Both 2-D and 3-D
processing techniques have generally used either multilateration [8,17] or SAR techniques [41,42] using
either ultrawideband pulses or stepped CW radars to localize features in the scene.
Imaging of structural features and contents of buildings requires at least 2-D (and preferably 3-D)
systems. It cannot rely on Doppler processing for separation of desired features, so multilateration
or SAR approaches have been the most commonly used approaches. The general idea behind multi-
lateration is to correlate range measurements from multiple sensors to speciﬁc points in the image.
With sufﬁcient spatial diversity from a large set of transmit/receive combinations, speciﬁc reﬂection
points will start to integrate above the background interference. However, ambiguities will arise as the
number of reﬂection points increases which can provide an over-determined system relative to the trans-
mit/receive signal pairs which can detract from image quality. SAR-based systems can be thought of as
a coherent extension of the multilateration concept. Instead of incoherent combinations of range returns
from multiple transmit/receive pairs, coherent algorithms are used to provide a complex matched ﬁlter
to speciﬁc points in the target space. SAR algorithms are well established for stand-off imaging appli-
cations [2]. Stand-off applications generally assume free-space propagation to each point in the target
scene, although platform motion compensation and atmospheric effects are removed with autofocusing
algorithms.
Most of the SAR and multilateration techniques usually neglect propagation distortions such as those
encountered by signals passing through walls and objects. Distortions degrade the performance and can
lead to ambiguities in target and wall localizations. Free-space assumptions no longer apply after the
electromagnetic waves propagate through the ﬁrst wall. As a result, free-space approximations may
carry imaging systems through to the ﬁrst wall, but propagation effects will then affect further imaging
results. Shadowing, attenuation, multipath, reﬂection, refraction, diffraction, and dispersion, all play a
role in how the signals will propagate after the ﬁrst interface. Without factoring in propagation effects,
imaging of contents within buildings will be severely impacted. As such, image formation methods,

860
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
array processing techniques, target detection, image sharpening, and clutter and multipath identiﬁcation
and rejection paradigms must work in concert and be reexamined in view of the nature and speciﬁcities
of the underlying sensing problem.
A common occurrence of incorrect localization is objects outside the building being illuminated by
the reﬂection off the ﬁrst wall and subsequently creating an ambiguous image visible inside the building.
Moreover, the strong front wall reﬂection causes nearby indoor weak targets to go undetected. Multipath
propagation introduces ghosts or false targets in the image. Uncompensated refraction through walls
can lead to localization or focusing errors, leading to offsets and blurring of imaged targets [41,43–45].
Bragg scattering off repeating structural elements, such as rebar in concrete walls or repetitive voids
in concrete block walls, can cause image ambiguities and modulation of subsequent wavefronts. Some
of the wall propagation effects can be compensated for using image-focusing techniques incorporating
proper wavefront corrections [41,44]. SAR techniques and tomographic algorithms, speciﬁcally tailored
for through-the-wall imaging, are capable of making some of the adjustments for wave propagation
through solid materials. While such approaches are well suited for shadowing, attenuation, and refraction
effects, they do not account for multipath, Bragg scattering, as well as strong reﬂections from the
front wall.
In this chapter, we consider the recent algorithmic advances that address some of the aforementioned
unique challenges in through-the-wall sensing operations. More speciﬁcally, Section 2.17.2 deals with
techniques for the mitigation of the wall clutter. Front wall reﬂections are often stronger than target
reﬂections, and they tend to persist over a long duration of time. Therefore, weak and close by targets
behind walls become obscured and invisible in the image. Approaches based on both electromagnetic
modeling and signal processing are advocated to signiﬁcantly mitigate the front wall clutter. Section
2.17.3 presents an approach to exploit the rich indoor multipath environment for improved target detec-
tion. It uses a ray tracing model to implement a multipath exploitation algorithm, which maps each
multipath ghost to its corresponding true target location. In doing so, the algorithm improves the radar
system performance by aiding in ameliorating the false positives in the original SAR image as well as
increasing the SNR at the target locations, culminating in enhanced behind the wall target detection
and localization. Section 2.17.4 discusses a change detection approach to moving target indication for
through-the-wall applications. Change detection is used to mitigate the heavy clutter that is caused by
strong reﬂections from exterior and interior walls. Both coherent and noncoherent change detection tech-
niques are examined and their performance is compared using real data collected in a semi-controlled
laboratory environment. Section 2.17.5 deals with fast data acquisition schemes to provide timely
actionable intelligence in through-the-wall operations. The demand for high degree of situational aware-
ness to be provided by through-the-wall radar systems requires the use of wideband signals and large
antenna arrays. As a result, large amounts of data are generated, which presents challenges in both
data acquisition and processing. The emerging ﬁeld of compressive sensing is employed to provide the
means to circumvent possible logistic difﬁculties in collecting measurements in time and space and
provide fast data acquisition and scene reconstruction for moving target indication.
It is noted that the chapter provides a signal processing perspective to through-the-wall radar imaging.
Outside the scope of this chapter, there has been signiﬁcant work performed for TWRI applications in the
areasofantennaandsystemdesign[36,46–48],wallattenuationanddispersion[49–51],electromagnetic
modeling [52–55], inverse scattering approaches [24,56,57], and polarization exploitation [58–60].

2.17.2 Wall Clutter Mitigation
861
The progress reported in this chapter is substantial and noteworthy. However, many challenging
scenarios and situations remain unresolved using the current techniques and, as such, further research
and development is required. However, with the advent of technology that brings about better hardware
and improved system architectures, opportunities for handling more complex building scenarios will
deﬁnitely increase.
2.17.2 Wall clutter mitigation
Scattering from the exterior front wall is typically stronger than that from targets of interest, such as a
human or a riﬂe, which have relatively small radar cross sections (RCS). This makes imaging of station-
ary targets behind walls difﬁcult and challenging. The problem is further compounded when targets are
in close vicinity of walls of either a high dielectric constant or with layered structures. In particular, hol-
low cinder block walls contain an air-gap void within the cinder block with disparate dielectric constants.
This establishes a periodic structure resonance cavity that traps electromagnetic (EM) modes. The con-
sequence of this layered composite structure on radar target imaging is to introduce long time constant
relaxations on target detections in radar range proﬁles. Therefore, weak and close by targets behind
walls become obscured and sometimes totally invisible in the image. Thus, wall reﬂections should be
suppressed, or signiﬁcantly mitigated, prior to applying image formation methods. One of the simple but
effective methods is based on background subtraction. If the received signals can be approximated as the
superposition of the wall and the target reﬂections, then subtracting the raw complex data without target
(empty scene) from that with the target would remove the wall contributions and eliminate its potential
overwhelming signature in the image. Availability of the empty scene, however, is not possible in many
applications, and one must resort to other means to deal with strong and persistent wall reﬂections.
In the past few years, a number of approaches have been proposed to mitigate the front wall returns
and effectively increase the signal-to-clutter ratio. For example, the wall reﬂections can be gated out, the
corresponding parameters can be estimated, and then used to model and subtract the wall contributions
from the received data [44]. This wall-dependent technique is effective, but its performance is subject
to wall estimation and modeling errors. Another method is proposed in [42], which employs three
parallel antenna arrays at different heights. The difference between the received signals at two different
arrays is used for imaging. Due to the receiver symmetry with respect to the transmitter, a simple
subtraction of the radar returns leads to wall reﬂection attenuation and image improvement. However,
this technique requires two additional arrays and the effect of the subtraction operation on the target
reﬂection is unknown and cannot be controlled. In [54], the walls reﬂections are eliminated by operating
the imaging radar in cross-polarization as the cross-polarization returns from a planar interface such as
the wall surface are theoretically zero, unlike the returns from humans. However, the cross-polarization
returns from the targets behind walls are often very weak compared to their co-polarization counterparts,
and as such, the radar performance may be limited by noise.
An eigen-structure technique is developed in [61] to decompose the received radar signal into three
subspaces: clutter (including the front wall), target, and noise. Singular value decomposition (SVD
is applied on the data matrix to extract the target signatures. SVD has also been used as a wall clut-
ter reduction method for TWRI in [62,63]. Another approach for wall clutter mitigation is based on
spatial ﬁltering. It utilizes the strong similarity between wall EM responses, as viewed by different

862
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
antennasalongtheentirephysicalorsynthesizedarrayaperture,isproposedin[64].Theideaisthatunder
monostaticradaroperation,thewallreturnsapproximatelyassumeequalvaluesandidenticalsignalchar-
acteristics across the array elements, provided that the extent of the wall is much greater than the antenna
beamwidth. On the other hand, returns from targets with limited spatial extent, such as humans, vary from
sensor to sensor. The dc component corresponding to the constant-type return, which is typical of walls,
can be signiﬁcantly reduced while preserving the target returns by applying an appropriate spatial ﬁlter
alongthearrayaxis. However,caremustbeexercisedinthechoiceofthespatialﬁltersothatitscharacter-
istics cause minimum distortion to the target returns. The spatial-domain preprocessing scheme is anal-
ogous, in its objective, to the moving target indication (MTI) clutter ﬁlter operation in the time domain.
In this section, we present in details two of the aforementioned methods, namely, the wall parameter
estimation method and the spatial ﬁltering technique. For the spatial ﬁltering technique, we consider
two different types of ﬁlters, namely, moving average subtraction ﬁlter and the inﬁnite impulse response
notch ﬁlter, and compare their effects on the target image.
2.17.2.1 Spatial ﬁltering
2.17.2.1.1
Characteristic of the wall reﬂection
Assume a synthetic aperture radar (SAR) is used in which a single antenna at one location transmits
and receives the radar signal, then moves to the next location, and repeats the same operation along the
axis parallel to the wall. Assume N antenna locations. With the wall reﬂection, the received signal at
the νth antenna due to a single point target of complex reﬂectivity σ is given by
z(n, t) = sw(t −τw) + σs(t −τn),
(17.1)
where sw(t) is the signal reﬂected from the wall, τw is the two-way traveling time of the signal from the
nth sensor to the wall, s(t) is the transmitted signal convolved with the two-way transmission transfer
function of the wall, and τn is the two-way traveling time between the nth antenna and the target. Note
that σ is assumed to be independent of frequency and τw does not vary with the sensor location since
the wall is parallel to the array. Furthermore, if the wall is homogeneous and much larger than the
beamwidth of the antenna, the wall reﬂection sw(t) will be the same for all antenna locations. This
implies that the ﬁrst term in (17.1) assumes the same value across the array aperture. When the wall
is not parallel to the array axis, τw should be calculated for each sensor location. Compensations for
signal attenuations due to differences in the two-way traveling distances for different antenna positions
should be performed prior to ﬁltering.
Unlike τw, the time delay τn in (17.1) changes with each antenna location, since the signal path from
the antenna to the target is different. For t = t0 and σ = 1, the received signal is
z(n, t0) = sw(t0 −τw) + s(t0 −τn)
(17.2)
for n = 0, 1, . . . , N −1. Since the time t is ﬁxed, the received signal is now a function of n via the
variable τn. We can rewrite (17.2) as a discrete function of n such that
zt0(n) = vt0 + ut0[n],
(17.3)
where vt0 = sw(t0 −τw) and ut0[n] = s(t0 −τn). Since the delay τn is not linear in n, ut0[n] for
n = 0, 1, . . . , N −1 is a nonuniformly sampled version of s(t). Figure 17.1a shows the signals received

2.17.2 Wall Clutter Mitigation
863
t
0t
0
1
2
3
4
5
6
7
n = 0
1
2
3
4
5
6
7
n
0t
t =
y
d
d
d
δ
tx
c
n
R
1
−
c
n
R
2
−
c
n
R
Target
cn
1
cn +
1
cn −
2
cn −
(a)
(b)
FIGURE 17.1
Received signals using SAR data collection scheme. (a) Array signal at t = t0. (b) Range between antenna
locations and the target.
by the N antennas at a given time instant. For example, suppose that the ncth sensor is the closest to the
target (see Figure 17.1b). If the wall diffraction is negligible, then
Rnc−m =

x2t + (δd + md)2 =

(x2t + δd2) + 2md δd + (md)2
=

R2nc + 2md δd + (md)2,
(17.4)
where m = |n −nc|. In most cases, the target’s range Rnc is much larger than the antenna spacing d.
Then, R2
nc ≫2md δd + (md)2. Using Taylor series expansion, we can approximate (17.4) as,
Rnc−m ≈Rnc

1 + 1
2
2md δd + (md)2
R2nc

.
(17.5)
Therefore,
Rnc−m −Rnc ≈1
2
2md δd + (md)2
Rnc
.
(17.6)
The received signal at t = τnc is given by
z(n, τnc) = sw(τnc −τw) + s(τnc −τn) ≈vτnc + s

−2md δd + (md)2
Rncc

.
(17.7)

864
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
The spatial frequency transform of (17.7) is given by
Z(κ, τnc) =
N−1

n=0
z(n, τnc)e−jκn ≈vτnc · δ(κ) + Sτnc (κ),
(17.8)
where κ denotes the spatial frequency, and Sτnc (κ) is the target spatial signature at t = τnc such as
Sτnc (κ) =
N−1

n=0
s

−2md δd + (md)2
Rncc

e−jκn.
(17.9)
The above analysis shows that separating wall reﬂections from target reﬂections amounts to basically
separating constant (zero-frequency signal) from nonconstant valued signals across antennas, which can
be performed by applying a proper spatial ﬁlter.
2.17.2.1.2
Target spatial signature
In the previous section, it is shown that the target signal across the antennas at a ﬁxed time (ﬁxed
down-range) is a nonuniformly sampled version of the target reﬂection. In order to minimize the effect
of the wall removal, which is done by spatial ﬁltering, on the target signal, it is necessary to ﬁnd the
target spatial frequency bandwidth as viewed by the array aperture. This is a critical factor in designing
the proposed spatial ﬁlters for the purpose of wall reﬂection removal. The target spatial frequency
bandwidth depends on the target downrange, as shown in (17.9), and is also inversely proportional to
the extent of the target signal return along the array. At any given time, the latter depends on the array
length, target down range, and the target signal temporal duration.
Considering a point target, which reﬂects the radar signal without modiﬁcation, the target spatial
signature can be analytically computed. The minimum bandwidth occurs when the extent of the target
return is maximum. Two different cases can be identiﬁed depending on the target location in cross-range
relative to the edge of the array. Figure 17.2a shows the target signal return in the time-space domain
when the target is located within the array aperture, whereas Figure 17.2b shows the case in which the
target is outside the array aperture. In these ﬁgures, L represents the array length, τ is the signal temporal
duration, and R is the target range. Consider the case of Figure 17.2a, where l0 is the cross-range of the
target location from the edge of the array. Without loss of generality, assume that l0 is larger than or equal
to L/2. The maximum width of the target return across the array for the case of Figure 17.2a is [64]
μ ≈

2Rδr + min{

2Rδr, L −l0}
(17.10)
and for the case of Figure 17.2b,
μ =

q2
2 + 2Wδr −q2.
(17.11)
In the above equations, δr is the radar down-range resolution and
W =

R2 + q2
2.
(17.12)
The maximum width is achieved when the target is located along the centerline of the array
μmax = min{2

2Rδr, L}.
(17.13)

2.17.2 Wall Clutter Mitigation
865
1q
L
2q
C
R /
2
τ
C
R /
2 ′
Time
0l
1q
L
2q
C
R /
2
τ
2
/
R
C
′′
Time
2
/
R
C
′
(a)
(b)
FIGURE 17.2
Target return signal in the time-space domain. (a) Target is within the array aperture. (b) Target is outside
the array aperture.
Deﬁne μ/
√
2 as the effective width. Then, the maximum effective width is
μmax,eff = min{2

Rδr, L}
(17.14)
and the corresponding minimum frequency bandwidth is given by
κB,min =
1
μmax,eff
.
(17.15)
Note that κB,min decreases as R increases. This implies that the spatial ﬁlter should have a narrower
stopband to process the more distant target.
2.17.2.1.3
Moving average wall removal
Moving Average (MA) ﬁlter background subtraction is a noncausal Finite impulse response (FIR)
ﬁlter, which notches out the zero spatial frequency component. The MA subtraction method has been
effectively used for removal of the ground reﬂections in ground penetrating radar [65]. The effect of the
MA on the target image can be viewed in the context of the corresponding change in the point spread
function (PSF). With the transmitted signal chosen as a stepped-frequency waveform consisting of Q
narrowband signals, let z(n, fq) be the signal received at the nth antenna at frequency fq. Let ˜z(n, fq)
be the signal after MA subtraction. That is
˜z(n, fq) = z(n, fq) −¯z( fq),
(17.16)

866
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
where ¯z( fq) is the MA of z(n, fq) such as
¯z( fq) =
1
2D + 1
m=n+D

m=n−D
z(m, fq),
(17.17)
where 2D + 1 is the ﬁlter length. When the sum is taken over the entire length of the array, the moving
average becomes just an average over the entire aperture and 2D + 1 = N. The klth pixel value of the
image obtained by applying delay-and-sum (DS) beamforming to the received data z(n, fq) is given by
b(k,l) =
N−1

n=0
Q−1

q=0
z(n, fq) exp{ j2π fqτn,(k,l)},
(17.18)
where τn,(k,l) is the two-way traveling time, through the air and the wall, between the nth antenna and
the klth pixel location. The new DS beamforming image after ﬁltering is given by
˜b(k,l) =
N−1

n=0
Q−1

q=0
˜z(n, fq) exp{ j2π fqτn,(k,l)}
= b(k,l) −
N−1

n=0
Q−1

q=0
¯z( fq) exp{ j2πfqτn,(k,l)}.
(17.19)
The second term in the above equation is due to the average subtraction. This additional term depends
on the signal waveform, target location, and the antenna positions, implying that the effect of average
subtraction varies according to these parameters. The PSF is the DS image of a point source as a function
of the down-range and the cross-range. Figure 17.3a shows the image of the second term in (17.19)
when a point target is located 6 m away from the center of a 3 m long antenna array. In this case, the
maximum value is about 0.13 (The maximum value in PSF is one). The signal is a step-frequency
waveform covering the 2–3 GHz band with 5 MHz steps. It is noted that the magnitude of this image
assumes a high value over a large cross-range area, whereas the down-range spread of the function is
small. Figure 17.3b is the PSF without spatial ﬁltering. The modiﬁed PSF of the spatial ﬁltered signal,
which is the difference between Figure 17.3a and b, is shown in Figure 17.3c. We observe that the size
of the mainlobe of the modiﬁed PSF remains unchanged with about 0.8 dB loss in the maximum value.
However, the sidelobes are higher compared to the original PSF. Although the average subtraction seems
to work well in this simulation, the limits of using this subtraction method when handling the distant
targets can be shown as follows.
The discrete Fourier transform of ˜z( fq) is
˜Z(κ, fq) =
N−1

n=0
˜z(n, fq) exp{−j2πκn/N} =
N−1

n=0
(z(n, fq) −¯z( fq)) exp{−j2πκn/N}
= Z(κ, fq) −¯z( fq)
N−1

n=0
exp{−j2πκn/N} = Z(κ, fq) −N ¯z( fq)δ[κ].
(17.20)

2.17.2 Wall Clutter Mitigation
867
Cross−range, meter
Down−range, meter
 
 
−0.5
0
0.5
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
0.5
0.02
0.04
0.06
0.08
0.1
0.12
Cross−range, meter
Down−range, meter
 
 
−0.5
0
0.5
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
0.5
−30
−25
−20
−15
−10
−5
0
Cross−range, meter
Down−range, meter
 
 
−0.5
0
0.5
−0.5
−0.4
−0.3
−0.2
−0.1
0
0.1
0.2
0.3
0.4
0.5
−30
−25
−20
−15
−10
−5
0
(a)
(b)
(c)
FIGURE 17.3
Modiﬁcation in the PSF due to MA subtraction. (a) Second term in (17.19). (b) PSF without ﬁltering. (c) PSF
after MA subtraction.
Note that
Z(κ, fq)
		
κ=0 =
N−1

n=0
z(n, fq) =N ¯z( fq).
(17.21)
Therefore,
˜Z(κ, fq) =

 Z(κ, fq) κ ̸= 0,
0
κ = 0.
(17.22)
As shown above, the subtraction removes the single spatial frequency component (κ = 0) without
changing other components. The actual spatial frequency band that is ﬁltered out is always 1/dN = 1/L,

868
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
where L is the array length. When μmax,eff is equal to L, the target bandwidth is 1/L. In this case, most
of the target signal return will be removed by the process of the average subtraction. The range at which
μmax,eff = L is
RL = L2
4δr
.
(17.23)
For example, for L = 2 m and δr = 0.075 m (2 GHz bandwidth), RL is equal to 13.33 m, implying
that when the target’s down-range is larger than 13.33 m, the MA subtraction method will eliminate
most of the target signature, which is undesirable. Thus, the MA subtraction is simple but produces
spatial ﬁlter characteristics, which may not be applicable to all wall types and target locations.
2.17.2.1.4
Notch ﬁltering
Zero-phasespatialIIRﬁlters,suchasnotchﬁlters,aregoodcandidatesforwallcluttermitigation.TheIIR
ﬁlter provides a ﬂexible design. It overcomes the problem of the ﬁxed MA (average) ﬁlter characteristics
that could be unsuitable for various wall and target types and locations. Although the IIR ﬁlter spatial
extent is truncated because of the ﬁnite number of antennas, the ﬁlter is still capable of delivering good
wall suppression performance without a signiﬁcant change in the target signal when the number of
antennas is moderate. A simple IIR notch ﬁlter that rejects zero frequency component is given by
HNF(ω) = 1 −e−jω
1 −αe−jω .
(17.24)
Thepositiveparameterα(<1)determinesthewidthoftheﬁlternotch.Figure17.4showsthefrequency
response of the ﬁlter for various values of α and that of MA subtraction with 67 antenna locations. Note
the difference between the notch ﬁlters and MA. The notch ﬁlter does not have ripples and can change
its stopband depending on the parameter α. In the underlying problem, ω is the spatial frequency and
the parameter α provides a compromise between wall suppression and target signal conservation. This
ﬂexibility is an advantage of the notch ﬁltering over MA subtraction method. As shown in the ﬁgure,
as α moves closer to one, the stopband becomes narrower such that most of the signal except dc will
pass through the ﬁltering.
The spatial spectrum of wall reﬂections may have a nonzero width due to unstable antenna path and
local inhomogeneities. In this case, a wider ﬁlter stopband should be applied to remove most of the wall
reﬂections around dc, but it would also reduce the target reﬂection. Therefore, the spatial ﬁlter should
be adjusted to the environment. It is noted that the frequency spectrum of the target reﬂection depends
on the range to the target, the transmitted waveform, and the distance between antenna locations. These
parameters determine the sampling point of the received signal and, subsequently, the spatial frequency
characteristics of the target. If the sampled target signal does not have a dc component, it will not be
severely affected by the spatial ﬁlter and, as such, the target image after notch ﬁltering will approximately
remain unaltered. It is noted that the desire to have the target spatial spectrum least attenuated by the
spatial ﬁltering could play an important role in designing signal waveforms for TWRI.
The ﬁlter zero-phase property, which is required for a focused image formation, can be achieved by
applying the notch ﬁlter twice in the forward and backward directions [66]. By two-way ﬁltering, group
delay can be removed. One way to avoid the loss of the target signal returns by ﬁltering, particularly if
these returns vary slowly across the array aperture antennas, is to increase the delay between antenna

2.17.2 Wall Clutter Mitigation
869
0
0.2
0.4
0.6
0.8
−30
−25
−20
−15
−10
−5
0
5
10
Normalized Frequency (×π rad/sample)
Magnitude (dB)
 
 
α=0.9
α=0.8
α=0.7
MA subtraction
DLC
FIGURE 17.4
Frequency response of the notch ﬁlter for various α, DLC with two pulses, and MA subtraction with 67
antennas.
outputs. This is true whether the MA, the notch ﬁlter, or any other ﬁlter is employed. The increased
delay can be achieved by down sampling of sensors without making the sensor spacing too large to
cause aliasing. When the antenna positions are down sampled by M, there will be M different sets with
N/M antennas. These M sets are ﬁltered independently and the results are used by the delay and sum
beamforming. Figure 17.5 shows the diagram of notch ﬁlter processing. The downsampled signal wm,t
for n = 0, 1, . . . , (N/M) −1 and m = 0, 1, . . . , M −1
wm,t[n] = z(nM + m −1, t).
(17.25)
TheeffectiveﬁlterlengthoftheIIRﬁltershouldbeconsideredwhendownsamplingsincethelengthof
the downsampled signal is now N/M. A highly truncated IIR will lead to undesired ﬁlter characteristics.
2.17.2.1.5
Imaging results
A through-the-wall SAR system was set up in the Radar Imaging Lab at Villanova University. A line
array of length 1.2446 m with 0.0187 m inter-element spacing was synthesized, parallel to a 0.14 m
thick solid concrete wall, at a standoff distance of 1.01m. The back and the side walls of the room were
covered with RF absorbing material to reduce clutter. A stepped-frequency signal covering 1–3 GHz
band with 2.75 MHz frequency step was employed. A vertical dihedral was used as the target and was
placed 3.04m away on other side of the front wall. The size of each face of the dihedral is 0.39m by
0.28 m. The empty scene without the dihedral target present was also measured for comparison.

870
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
)
,0
(
t
z
)
,1( t
z
)
,2
(
t
z
)
,1
(
t
N
z
−
…
…
M
↓
)
(ω
NF
H
)
(ω
NF
H
)
(ω
NF
H
)
(ω
NF
H
M
↑
(1, )
z
t
(2, )
z
t
(
1, )
z N
t
−
˜
…
]
[
,0 n
w t
]
[
,1 n
w t
]
[
,2 n
w t
]
[
,1 n
w
t
M −
(0, )
z
t
˜
˜
˜
FIGURE 17.5
Block diagram of notch ﬁltering.
First, we examine the validity of the wall EM return assumption that the spatial ﬁltering approach
is based on. Figure 17.6a shows the signal reﬂected from the concrete wall. It clearly shows the ﬁrst
few reﬂections from the wall and as expected, the wall return assumes almost constant values across
the antenna positions. In order to quantify the performance of the images, we apply the target-to-clutter
ratio (TCR) which is commonly adopted in SAR image evaluations [67,68]. TCR is similar to the MTI
improvement factor, except that the latter is for the time-domain, whereas TCR is for the image domain.
TCR is calculated as
TCR = 20 log10
⎛
⎝
max
(k,l)∈At
|b(k,l)|
1
Nc

(k,l)∈Ac |b(k,l)|
⎞
⎠,
(17.26)
where At is the target area, Ac is the clutter area, and Nc is the number of pixels in the clutter area.
TCR, in essence, is the ratio between the maximum pixel value of the target to the average pixel value
in the clutter region. The clutter region is the area where no target is present and the wall reﬂection is
severe. The clutter area is manually selected in close vicinity to the wall where wall reﬂections are most
pronounced. The rectangles depicted in the ﬁgures represent the clutter area and the target area in our
example. Figure 17.6b shows the image without any preprocessing and the target is masked by the wall
response. Figure 17.6c shows the result of applying background subtraction, and the target is clearly
visible. Figure 17.7a and b demonstrates that the spatial ﬁltering approach is effective in reducing the
wall reﬂections without signiﬁcantly compromising the target image. Figure 17.7a shows the DS image
after MA subtraction, and Figure 17.7b shows the DS image after the notch ﬁltering. TCRs in these
ﬁgures are 2.2 dB (with wall), 26.2 dB (background subtraction), 13.4 dB (notch ﬁltering), and 15.3 dB
(MA subtraction). The background subtracted image provides the highest TCR, while MA subtraction
and notch ﬁltering provide comparable performance.

2.17.2 Wall Clutter Mitigation
871
20
40
60
1
1.5
2
−0.015
−0.01
−0.005
0
0.005
0.01
Antenna number
Range, meter
Cross−range, meter
Down−range,meter
 
 
−1
−0.5
0
0.5
1
0.5
1
1.5
2
2.5
3
3.5
4
−25
−20
−15
−10
−5
0
Cross−range, meter
Down−range,meter
 
 
−1
−0.5
0
0.5
1
0.5
1
1.5
2
2.5
3
3.5
4
−25
−20
−15
−10
−5
0
(a)
(b)
(c)
FIGURE 17.6
(a) Wall reﬂections of the solid concrete wall in time domain across the antenna positions. (b) DS image with
wall reﬂections. (c) DS image with background subtraction.
2.17.2.2 Wall parameter estimation, modeling, and subtraction
2.17.2.2.1
Approach
In this approach, the effect of the wall on EM wave propagation is achieved through three steps. The
wall parameters are accurately estimated. Then, the reﬂected signal from the wall is properly modeled.
Finally, the modeled signal is subtracted from the measured signal.
Building walls, such as brick, adobe, and poured concrete walls, can be modeled by homogeneous
dielectric slabs. Using the geometric optics approach, the reﬂection coefﬁcient γ for vertically and

872
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
Cross−range, meter
Down−range,meter
 
 
−1
−0.5
0
0.5
1
0.5
1
1.5
2
2.5
3
3.5
4
−30
−25
−20
−15
−10
−5
0
Cross−range, meter
Down−range,meter
 
 
−1
−0.5
0
0.5
1
0.5
1
1.5
2
2.5
3
3.5
4
−30
−25
−20
−15
−10
−5
0
(a)
(b)
FIGURE 17.7
DS images for solid concrete wall. (a) MA subtraction. (b) Spatial notch ﬁltering.
horizontally polarized incident waves through the wall is given by [44,69]
γ = R01 + R10e j2k1xd
1 + R01R10e j2k1xd ,
R10 = −R01 = 1 −p10
1 + p10
,
(17.27)
where p10 = k0x/k1x for horizontal polarization and p10 = εrk0x/k1x for vertical polarization of the
incident ﬁelds. In (17.27), εr is the relative dielectric constant, d is the thickness of the wall, and k0x and
k1x are the normal components of the propagation constants in air and in the dielectric, respectively.
The expressions for the vertical/transverse magnetic and horizontal/transverse electric unit vectors are
given in [69].
The wall parameters can be estimated from the time-domain backscatter at a given location [44,70].
Basically, the response of the wall is gated from the total backscatter signal and transferred to the
frequency domain. The mean-squared error between the calculated reﬂection coefﬁcient γ of (17.27)
and the measured reﬂection coefﬁcient γm given by
δ =
1
N f
N f

n=1
|γm( fn)−γ ( fn)|2
(17.28)
is computed, and its minimum is searched for the wall thickness and permittivity [44,71]. In (17.28),
N f is the number of frequency points and fn is the nth frequency.
The estimated wall parameters are then used to compute the wall EM reﬂection. This could be accom-
plished either numerically using EM modeling software, or in case of far-ﬁeld conditions, analytically
using the following expression [44]
Ew
r (kn) = Gλ
8π
e j2knx0
x0
(θi = 0, kn),
(17.29)

2.17.2 Wall Clutter Mitigation
873
where x0 is the standoff distance of the radar from the wall, λ is the wavelength, G is the antenna gain,
kn = 2π fn/c is the nth wave constant, c is the speed of light in free space, and (θi = 0, kn) is the
reﬂectivity matrix from the wall at normal incidence angle and is given by,
 =
γv
0
0
γh

.
(17.30)
In (17.30), the subscripts “v” and “h,” respectively, denote the vertical and horizontal polarization
and γv/h is given by (17.27). This estimated wall reﬂection should be coherently subtracted from the
total received signal in order to isolate the signature of the target on the other side of the wall.
The isolated target return can then be processed to generate an image of the scene. The effects of the
wall transmissivity on the target image are the following: (1) dislocation of the target from its actual
position in range and (2) signiﬁcant degradation in cross-range resolution [41,44]. To compensate for
the effects of transmission through the wall, a compensation factor proportional to the inverse of the
squared of the wall transmittivity can be used in the conventional free-space image formation methods.
In cases where transmissivity is low and the signal is noisy, division by a small noise-affected number
may cause signiﬁcant distortion. In such cases, one may use only the phase of transmission coefﬁcients
as a compensation factor [44].
2.17.2.2.2
Imaging results
An experimental study was conducted at the Radiation Laboratory in University of Michigan. The mea-
surement setup consists of an HP8753D vector network analyzer, two double ridge horn antennas with
operational frequency range of 1–18 GHz, an XY table along with a control unit, and a personal computer.
The vertically aligned antennas, one for transmission and the other for reception, are mounted on a ver-
tical wooden rod (along the z-axis), which is attached to the carriage of the XY table. A 2.37m × 1.77m
wall composed of poured concrete blocks is made on top of a layer of cinder blocks inside the laboratory.
The underlying cinder block layer is used to line up the antennas in height at approximately the middle
of the concrete block wall. Figure 17.8a shows the side view of the measurement setup. A small trihedral
corner reﬂector with pentagonal panel geometry is used as a point target behind the wall, as shown in
Figure 17.8b. The back corner of the trihedral (scattering phase center) is at x = −0.71 m and at the same
height as that of the receiver antenna, i.e., 1.28 m above the ground plane. The transmitting antenna is
attached about 0.25 m below the receiving antenna on the wooden rod. The antennas are moved along
a scan line of length 95.88 cm, parallel to the wall, with a spacing of 2.04 cm. The apertures of both
antennas are about 0.45 m away from the wall. The frequency of operation is from 1 to 2.5 GHz and
the frequency step is 12.5 MHz. It is noted that the antennas are in the far-ﬁeld region of the target.
An image is ﬁrst constructed under assumption of free-space propagation by using the total received
signal, and is shown in Figure 17.9a. Here, in addition to the target, the wall is also imaged, primarily
as two parallel lines showing the front and back boundaries. Since backscatter from the wall is very
strong, the sidelobes generated by image formation spill over into desired image domain, which is man-
ifested as multiple lines parallel to the wall surfaces. Also, the target appears blurred and its location
is biased. Figure 17.9b shows the image after the estimate, model, and subtract approach was applied.
The wall thickness and the permittivity were estimated using (17.28) as 20 cm and 5.7 + j0.6, respec-
tively. The wall reﬂection was computed using (17.29) and subtracted from the total received signal,

874
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
(a)
(b)
FIGURE 17.8
(a) Side view of the measurement setup. (b) Trihedral target.
and the resulting signal was used for image formation. For comparison, the signal prior to wall return
subtraction was used for imaging wherein compensation for the effect of transmission through the wall
was applied and is shown in Figure 17.9c. Although the imaged target is at the correct location and is
refocused in Figure 17.9c, existence of the wall sidelobes in the image is still evident. By comparing
Figure 17.9b and c, a substantial improvement in clutter rejection is observed after subtraction of the
modeled wall return.
2.17.3 Multipath exploitation
The existence of targets inside a room or in an enclosed structure introduces multipath in the radar
return, which results in false targets or ghosts in the radar images. These ghosts lie on or near the
vicinity of the back and side walls, leading to a cluttered image with several false positives. Without
a reasonable through-the-wall multipath model, it becomes difﬁcult to associate a ghost to a particular
target. Identifying the nature of the targets in the image and tagging the ghosts with their respective
target according to a developed multipath model, although important to reduce false alarms, is not the
ﬁnal goal of a high-performance through-the-wall imaging system. Since each multipath provides some
information about the target, it becomes prudent to utilize the multipath rather than ignoring it, once
identiﬁed. The utilization or exploitation of the multipath to one’s advantage represents a paradigm shift
when compared to the classical approach of either ignoring or mitigating it.
For through-the-wall radar imaging applications, the existence of multipath has been recently demon-
strated for stationary targets in [52,72,73]. In [72], the authors use distributed fusion to remove the false

2.17.3 Multipath Exploitation
875
(a)
(b)
(c)
FIGURE 17.9
(a) Image of the trihedral behind wall using full received data and free-space image formation. (b) Image
of trihedral after estimated wall return subtraction and wall compensation. (c) Image of trihedral after wall
compensation.
targets caused either from multipath or target interactions for stationary scenes after suitable image
registration. In [52], time reversal techniques are used to alleviate ghosts and clutter from the target
scene and in [73], a synthetic aperture radar (SAR) based image of a human inside a room is shown
along with possible multipath ghosts. However, no more rigorous multipath modeling and analysis are
presented in the aforementioned references [52,72,73] and the references therein.
In this section, we derive a model for the multipath in an enclosed room of four walls. The model
considers propagation through a front wall and specular reﬂections at interior walls. A SAR sys-
tem is considered and stationary or slow moving targets are assumed. Although the multipath model

876
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
presented deals with walls, reﬂections from the ceiling and ﬂoor can be readily handled. We demonstrate
analytically that the multipath as seen by each sensor is displaced, and, therefore, we derive the actual
focusing positions of the multipath ghosts in downrange and crossrange. The multipath model permits
an implementation of a multipath exploitation algorithm, which associates as well as maps each target
ghost back to its corresponding true target location. In so doing, the exploitation algorithm improves
the radar system performance by ameliorating the false positives in the original SAR image as well as
increasing the signal-to-clutter ratio (SCR) at the target locations, culminating in enhanced behind the
wall target detection and localization. It is noted that the exploitation algorithm only maps back target-
wall interactions; target-target interactions are left untreated. The multipath exploitation algorithm is
inspired by the work in [74], wherein the shadowed regions of a target are revealed via its multipath
returns. The difference, however, is that we are not striving to reveal the shadowed regions of the target.
In our case, we deal with targets with arbitrary dielectric constants, and wish to associate and map each
multipath to its true target location.
2.17.3.1 Image formation algorithm
In this section, we describe the through-the-wall delay-and-sum beamforming approach [40,41,75,76].
We consider a SAR system in which a single antenna at one location transmits a wideband signal and
receives the radar return, and then moves to the next location and repeats the same operation along
the axis parallel to the front wall. Assume N monostatic antenna locations. The setup is as depicted in
Figure 17.10. Consider a single point target, located at xt = [xt, yt]T . At each antenna location, the
radar transmits a pulsed waveform s(t), where “t” indexes the time within the pulse, and measures the
reﬂected signal. The target return at the nth antenna location is given by,
rn(t) = T 2
n (xt)a(xt)s(t −2τn(xt)),
(17.31)
where a(xt) represents the target reﬂectivity, Tn(xt) is the complex amplitude associated with the one-
way propagation through a dielectric wall for the nth antenna location [77], and τn(xt) represents the
one-way through-the-wall propagation delay from the nth antenna location to the target.
The scene of interest comprises several pixels indexed by the downrange and the crossrange. The
complex composite return from the kth pixel location xk is obtained by applying time delays to the N
FIGURE 17.10
Through-the-wall synthetic aperture radar model.

2.17.3 Multipath Exploitation
877
received signals, followed by weighting and summing the results. That is,
r(t, xk) =
N−1

n=0
wnrn(t + 2τn(xk)).
(17.32)
The signal r(t, xk) is passed through a matched ﬁlter, with impulse response h(t) = s∗(−t). The
complex amplitude assumed by the pixel xk in the image I(·) is obtained by sampling the matched ﬁlter
output at time t = 0,
I(xk) = {r(t, xk) ∗h(t)}|t=0,
(17.33)
where “∗” denotes the convolution operation. Equations (17.32) and (17.33) describe the standard
beamforming approach in through-the-wall radar imaging. It is noted that if the imaged pixel is in the
vicinity of or at the true target location, then the complex amplitude in (17.33) assumes a high value as
given by the system’s point spread function. The process described in (17.32) and (17.33) is carried out
for all pixels in the scene of interest to generate the image of the scene.
The beamforming approach as described above is pertinent to a point target in a two-dimensional
(2D) scene. Extensions to three-dimensional (3D) scenes and spatially extended targets are discussed
in [40,78]. It is noted that, in the above beamforming description, we have not considered the multipath
returns; neither have we addressed the speciﬁcities of calculating the delays, τn(·), which will be
treated in detail in the following sections. Without loss of generality, we now assume that the weights
wn = 1, ∀n and the target has unit reﬂectivity.
2.17.3.2 Multipath model
ConsideraroomundersurveillanceusingaSARsystem. Aprioriknowledgeoftheroomlayout,i.e.,wall
locationsandmaterialproperties,isassumed.Thescenebeingobservedrelativetothenthsensorlocation
is as shown in Figure 17.11. The origin is marked as point “O” in the ﬁgure, and the standard convention
FIGURE 17.11
Multipath model.

878
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
for the positive x- and y- axes is assumed. The nth sensor location is given by Rn = [−Dxn, 0]T . The
front wall has a thickness d1 and dielectric constant ε1. For notational simplicity, the back and the side
walls are also assumed to have ε1 as the dielectric constant. The side walls, labeled as wall-1 and wall-3,
have a length D1, whereas the front wall and the back wall (wall-2) have a length D2. The target is station-
ary and at location A = [−xt, yt]T . The standoff distance from the front wall is constant for each sensor
location constituting the synthetic aperture, and is denoted as Dy. In the ﬁgure, we consider the direct
path, referred to as path-A, and three additional paths, namely, paths-B, C, and D, which correspond to
single-bounce multipath. In general, there exist other paths which can contribute to the multipath returns;
these include multiple bounces from the back and side walls as well as paths that include multiple reﬂec-
tions within each of the four walls themselves. Examples of the former and the latter are provided in
Figure 17.12. Such paths are deﬁned as higher-order multipath. Hence, in Figure 17.11, we have consid-
ered only ﬁrst-order multipath. It is noted that higher-order multipath are in general weaker compared to
the ﬁrst-order multipath due to the secondary reﬂections and refractions at the various air-wall interfaces
and high attenuation in the wall material. Therefore, we choose to exclude these paths from the model.
The walls are assumed smooth with specular reﬂections. The smoothness assumption is valid, since
for through-the-wall radars, the wavelength of operation is much larger than the roughness of the walls.
Specular reﬂections are a direct consequence of the wall smoothness, and necessitate that the angle
of incidence be equal to the angle of reﬂection. Note that, in general, the back and side walls may
each be of a different material (interior or exterior grade), and thus may assume different values for
the wall thickness and dielectric constant. If interior reﬂections inside these walls are considered, then
the thickness of these walls is required [52,73,74]. However, since we have ignored such higher-order
paths, we only require the dielectric constant of the back and side walls to be known. As the EM wave
propagates through the front wall, it bends at the medium discontinuity as dictated by Snell’s law,
i.e., each of the paths, as seen in Figure 17.11, has an associated angle of incidence and an angle of
refraction. For example, the angles of incidence and refraction for path-B are denoted as ψ(n)
i B and ψ(n)
r B ,
respectively. Similar nomenclature follows for the remaining paths.
FIGURE 17.12
Other higher order paths.

2.17.3 Multipath Exploitation
879
Let the reﬂection points on wall-1, 2, and 3 be denoted by Bn, Cn, and Dn, with respective position
vectors Bn = [0, yBn]T , Cn = [−xCn, D1+Dy]T , and Dn = [−D2, yDn]T . It is clear that these position
vectorsaredependentonthesensorlocation. Theone-waypathdelaysforthefourpaths, withtheantenna
at the nth location, are denoted by τ (n)
p , p ∈{A, B, C, D}, and can be derived from the geometry as
τ (n)
A
= (d1
√ε1 sec(ψ(n)
r A ) + (yt −d1) sec(ψ(n)
i A ))/c,
τ (n)
B
= (d1
√ε1 sec(ψ(n)
r B ) + (yBn −d1) sec(ψ(n)
i B ) + xtcosec(ψ(n)
i B ))/c,
τ (n)
C
= (d1(√ε1 sec(ψ(n)
rC ) −sec(ψ(n)
iC )) + (2D1 + 2Dy −yt) sec(ψ(n)
iC ))/c,
τ (n)
D
= (d1
√ε1 sec(ψ(n)
r D ) + (yDn −d1) sec(ψ(n)
i D ) + (D2 −xt)cosec(ψ(n)
i D ))/c,
(17.34)
with c being the speed of light and the coordinates of Bn, Cn, and Dn given by
yBn = yt −xt cot(ψ(n)
i B ),
xCn = xt + (D1 + Dy −yt) tan (ψ(n)
iC ),
yDn = yt −(D2 −xt) cot (ψ(n)
i B ).
(17.35)
Equations (17.34) and (17.35) depend on the angles of incidence and refraction. Since the standoff
distance is a known constant, by projecting the various paths to the x-axis, we obtain the following
equations, which are useful in calculating the various angles.
d1 tan(ψ(n)
r A ) + (yt −d1) tan(ψ(n)
i A ) −Dxn + xt = 0,
d1 tan(ψ(n)
r B ) + (yBn −d1) tan(ψ(n)
i B ) −Dxn = 0,
(2D1 + 2Dy −yt) tan(ψ(n)
iC ) + d1( tan(ψ(n)
rC ) −tan(ψ(n)
iC )) −Dxn + xt = 0,
(17.36)
d1 tan(ψ(n)
r D ) + (yDn −d1) tan(ψ(n)
i D ) −D2 + Dxn = 0.
The angles of refraction can be determined from Snell’s law as,
ψ(n)
rp = sin−1

sin(ψ(n)
ip )
√ε1

, p ∈{A, B, C, D}.
(17.37)
Substituting the angles of refraction from (17.37) in (17.36), and using (17.35), we obtain a set of
equations that can be solved numerically for the angles of incidence by using the Newton method. The
angles of refraction can then be obtained using (17.37).
We are now in a position to write the radar signal return from the single target scene as a superposition
of the direct path and the multipath returns. For the nth sensor location, we obtain
rn(t) =

p∈{A,B,C,D}
T 2
pns(t −2τ (n)
p ) +

(p,q)∈{A,B,C,D}
p̸=q
TpnTqns(t −τ (n)
p
−τ (n)
q ),
(17.38)
where Tpn is the complex amplitude associated with reﬂection and transmission coefﬁcients for the
one-way propagation along path-p, and depends on the angles of incidence, the angles of refraction, and

880
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
dielectric properties of the walls [77]. In (17.38), the ﬁrst summation captures the two-way returns along
the direct path and each multipath. More speciﬁcally, the signal propagates along a particular path-p, p ∈
{A, B, C, D}, reaches the target and retraces the same path back to the radar, i.e., path-p. The multipath
returns due to the combination paths are captured by the second summation, i.e., the wave initially
travels to the target via path-p and returns to the radar through a different path-q, q ∈{A, B, C, D}.
From Figure 17.11 and (17.35), we observe that the coordinates of the points of reﬂection at the back
and side walls are sensor dependent, implying that the multipath presents itself at different locations to
the different sensors. Location of the multipath as seen by each sensor and the actual focusing position
of the resulting ghost in the image are discussed next.
2.17.3.2.1
Multipath locations
For simplicity of analysis, consider the scenario in Figure 17.11, but without the front wall. We ﬁrst focus
on the multipath originating from wall-1, i.e., the signal traveling to the target via path-A, and following
path-B back to the radar or vice versa. The goal is to ﬁnd the location of the multipath corresponding
to the above combination path as seen by each of theN sensors. Let the point Pw1
n , represented by the
vector [−xw1
tn , yw1
tn ]T , denote the multipath location as seen by the nth sensor. The superscript “w1”
stresses that the multipath is associated with the reﬂection at wall-1 and the subscript “t” indicates that
the multipath is due to the target located at [−xt, yt]T . Reﬂecting path-B about wall-1 yields an alternate
radar-target geometry, as shown in Figure 17.13. We obtain the virtual target denoted by point A1 with
coordinates [xt, yt]T such that the distance ABn = A1Bn, which implies that
ARn + ABn + Bn Rn = ARn + A1Rn.
(17.39)
In other words, the combination path comprising of path-A and path-B has the same length as path-A
and the path connecting the nth sensor to the virtual target at A1. Due to the monostatic nature of the
radar system, this combination path appears to the nth sensor as the traditional two way path of length
2Rn Pw1
n . Therefore, we have
Rn Pw1
n
= ARn + A1Rn
2
.
(17.40)
FIGURE 17.13
The equivalence between the bistatic and monostatic geometries.

2.17.3 Multipath Exploitation
881
Additionally, we obtain the virtual radar at R1
n = [Dxn, 0]T on the other side of the wall, as shown
in Figure 17.13. Considering Figure 17.13, it is readily observed that the ﬁrst order multipath has the
same time delay as a bistatic conﬁguration, comprising the radar and the virtual radar. That is, in terms
of range, we have
Rn A + Rn A1 = Rn A1 + R1
n A1,
(17.41)
where Rn A1+ R1
n A1 represents the bistatic conﬁguration. In the bistatic case, the constant range contour
corresponding to the multipath is an ellipse, which has foci at the radar and virtual radar and passes
through the target and the virtual target locations. On the other hand, the monostatic measurement
scenario described by (17.40) has a circular constant range contour, centered at the radar. Since the two
measurements are equivalent, the location of the multipath corresponds to the point of intersection of
the bistatic elliptical and the monostatic circular constant range contours. The equations for the ellipse
and circle are given by
(xw1
tn )2
(Rn Pw1
n )2 +
(yw1
tn )2
(Rn Pw1
n )2 −D2xn
= 1,
(xw1
tn + Dxn)2 + (yw1
tn )2 = (Rn Pw1
n )2.
(17.42)
Solving (17.42) for an intersection point, we can readily see that xw1
tn = 0 is the only solution. In
other words, regardless of the location of the target, its ﬁrst-order multipath always falls on the wall.
The y-coordinate of Pw1
n
can then be derived as
yw1
tn = ±

(ARn + A1Rn)2
4
−D2xn.
(17.43)
In (17.43), the positive y-coordinate is the desired value as the other solution lies behind the radar.
It is clear from (17.43) that the multipath location is sensor dependent. Therefore, the locations of the
target multipath corresponding to the various sensor positions will be displaced from one another. In
the presence of the front wall, the multipath remains on the wall, but the equations for the ellipse and
circle are different than that presented in (17.42). Hence, for the scenario comprising of the front-wall
and wall-1, the multipath appears on wall-1, with its y-coordinate given by
yw1
tn =

cτ (n)
A
+ cτ (n)
B
2
+ d1( sec(ψ(n)w1
it
) −√ε1 sec(ψ(n)w1
rt
)

cos(ψ(n)w1
rt
),
(17.44)
where ψ(n)w1
it
and ψ(n)w1
rt
are, respectively, the angles of incidence and refraction for the ghost. The
solution in (17.44) depends on the angle ψ(n)w1
it
, which can be obtained by solving
d1 tan(ψ(n)w1
rt
) +

cτ (n)
A
+ cτ (n)
B
2
+ d1
√ε1 sec(ψ(n)w1
rt
)

sin(ψ(n)w1
it
) −Dx = 0,
ψ(n)w1
rt
= sin−1

sin (ψ(n)w1
it
)
√ε1

.
(17.45)

882
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
So far, we have considered the multipath corresponding to wall-1; there exist two other multipath
returns tagged to the remaining walls, namely, wall-2, and wall-3. We can readily show, using similar
analysis, that the multipath associated with wall-2 appears on wall-2, i.e., yw2
tn
= Dy + D1, at an
x-coordinate given by
xw2
tn = −sin (ψ(n)w2
it
) ×

d1(√ε1 sec(ψ(n)w2
rt
) −tan(ψ(n)w2
rt
)cosec(ψ(n)w2
it
))
+Dxcosec(ψ(n)w2
it
) −cτ (n)
A +cτ (n)
C
2

.
(17.46)
The angles in the above equation are determined by solving the equations,
d1 sec(ψ(n)w2
it
) + (D1 −d1) sec(ψ(n)w2
it
) + d1
√ε1 sec (ψ(n)w2
rt
) −cτ (n)
A
+ cτ (n)
C
2
= 0,
ψ(n)w2
rt
= sin−1

sin (ψ(n)w2
it
)
√ε1

.
(17.47)
Likewise, the multipath associated with wall-3 appears at wall-3, i.e., xw3
tn = −D2, and at a y-coordinate
given by,
yw3
tn =

cτ (n)
A
+ cτ (n)
D
2
+ d1( sec(ψ(n)w3
it
) −√ε1 sec(ψ(n)w3
rt
))

cos(ψ(n)w3
rt
).
(17.48)
The respective angles can be obtained by solving,
d1 tan(ψ(n)w3
rt
) +

cτ (n)
A
+ cτ (n)
D
2
+ d1
√ε1 sec(ψ(n)w3
rt
)

sin(ψ(n)w3
it
) −D2 + Dx = 0,
ψ(n)w3
rt
= sin−1

sin (ψ(n)w3
it
)
√ε1

.
(17.49)
From the above equations, it is again observed that the N sensors view the multipath, resulting from
the combination paths associated with a particular wall, at different locations on that wall. That is, the
multipath maybe regarded as a moving target. As a result, when applying beamforming, the multipath
ghost appears at a different pixel in the vicinity of the true multipath locations. We note that the multipath
ghost will lie inside the room except when the target is near the corners of the room. In this case, as the
multipath corresponding to the N sensors may appear along an extrapolation of the wall, the multipath
ghost may appear outside the room. We further note that the virtual target corresponds to two-way
propagation along the single-bounce multipath, and is readily seen to lie outside the room perimeter.
The multipath focusing pixel analysis for the combination paths is discussed next.
2.17.3.2.2
Multipath focusing analysis
Consider Figure 17.14, which shows the multipath locations w.r.t to walls-1–3, and the focusing pixels
w.r.t to these walls. Consider the multipath locations associated with wall-1; further assume that the
focused multipath ghost appears at a pixel location given by
xw1
t
= [−x1 + xw1
t1 , y1 + yw1
t1 ]T ,
(17.50)

2.17.3 Multipath Exploitation
883
FIGURE 17.14
Multipath locations and imaged location of multipath ghosts.
where xw1
t1 = [−xw1
t1 , yw1
t1 ]T is the true multipath location corresponding to the ﬁrst sensor position.
Using a ﬁrst order Taylor series expansion, which is valid under conditions of a small aperture [79] and
when the ghost is in the vicinity of the true multipath locations, we obtain the difference in propagation
path length between the multipath ghost location and the true multipath location w.r.t the ﬁrst sensor
position as
ςw1
1
= x1
Dx1 −Dy tan(ψ(1)w1
it
) −d1 tan(ψ(1)w1
rt
) −xw1
t1

(Dx1 −Dy tan(ψ(1)w1
it
) −d1 tan(ψ(1)w1
rt
) −xw1
t1 )2 + (yw1
t1 −Dy −d1)2
+ y1
yw1
t1 −Dy −d1

(Dx1 −Dy tan(ψ(1)w1
it
) −d1 tan(ψ(1)w1
rt
) −xw1
t1 )2 + (yw1
t1 −Dy −d1)2
.
(17.51)
Following the analysis in [79], (17.51) can be expressed as
ςw1
1
= x1 sin(ψ(1)w1
it
) + y1 cos(ψ(1)w1
it
).
(17.52)
In general, for the nth sensor, we have
ςw1
n
= x1 sin(ψ(n)w1
it
) + (y1 −(yw1
tn −yw1
t1 ) cos(ψ(n)w1
it
),
n = 1, . . . , N.
(17.53)
For the multipath to focus at the location xw1
t , we must have,
ςw1
n
= 0,
for n = 1, . . . , N.
(17.54)

884
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
This yields a least squares (LS) formulation, given by
A1e1 = b1, e1 = [x1, y1]T , A1 := [ aw1
1
aw1
2 ]T ,
aw1
1
= [sin(ψ(1)w1
it
), . . . , sin(ψ(N)w1
it
)]T , aw1
2
= [cos(ψ(1)w1
it
), . . . , cos(ψ(N)w1
it
)]T ,
(17.55)
b1 := [0, yw1
t2 −yw1
t1 , . . . , yw1
t N −yw1
t1 ]T ◦aw1
2 ,
where “◦” denotes the Hadamard or element-wise product. The solution of (17.56) is readily obtained
by (AT
1 A1)−1b1.
Now, considering the multipath w.r.t wall-2, we have the following LS formulation for the focused
ghost pixel.
A2e2 = b2, e2 = [x2, y2]T , A2 := [ aw2
1
aw2
2 ]T ,
aw2
1
= [sin(ψ(1)w2
it
), . . . , sin(ψ(N)w2
it
)]T , aw2
2
= [cos (ψ(1)w2
it
), . . . , cos (ψ(N)w2
it
)]T ,
(17.56)
b2 := [0, yw2
t2 −yw2
t1 , . . . , yw2
t N −yw2
t1 ]T ◦aw2
2 .
Similarly, for the multipath from wall-3, we have
A3e3 = b3, e3 = [x3, y3]T ,
A3 := [ aw3
1
aw3
2 ]T ,
aw3
1
= [sin (ψ(1)w3
it
), . . . , sin (ψ(N)w3
it
)]T ,
aw3
2
= [cos (ψ(1)w3
it
), . . . , cos (ψ(N)w3
it
)]T ,
(17.57)
b3 := [0, yw3
t2 −yw3
t1 , . . . , yw3
t N −yw3
t1 ]T ◦aw3
2 .
The formulations in (17.56)–(17.58) assume that the sensor position increases from left to right. In
other words, sensor-1 is at the far left of the array whereas sensor-N is at the far right.
FIGURE 17.15
Multipath exploitation principle.

2.17.3 Multipath Exploitation
885
2.17.3.3 Multipath exploitation algorithm
Noting that the multipath ghosts exist due to the presence of the target, we state our objective as follows.
Given the beamformed image {I(xk)}K
k=1, our aim is to associate each multipath ghost with the respective
target via the model developed in Section 2.17.3.2. The principle is captured in Figure 17.15, which
consists of two targets and six false positives or multipath ghosts. We desire to associate and map these
ghosts to their respective true target locations. The main advantages of such an association or mapping
are reduction in false positives in the original beamformed image, and an increase in the SCR at the true
target coordinates. Note that the ﬁrst advantage is directly implied in Figure 17.15, whereas the second
advantage is explained as follows.
For ease of exposition, the technique is explained considering the focused multipath ghost from wall-
1 only. The technique for exploiting all the ghosts w.r.t to all three walls is enumerated subsequently.
Consider an arbitrary pixel location x = [x, y]T , whose focused multipath ghost w.r.t wall-1 presents
itself at location xw1 = [xw1, yw1]T . Consider an intermediate image, I1(x), wherein the association and
mapping of the focused multipath ghosts is performed using simple 2D weighting functions. That is,
I1(x) ∈CK =
K

k=1
I(xk)1(xw1, xk, σ 2)2(x, xk, σ 2),
1(xw1, xk, σ 2) := exp

−|xw1 −xk|2/σ 2
, 2(x, xk, σ 2) := 1 −exp

−|x −xk|2/σ 2
,
(17.58)
where 1(·) and 2(·) are the weighting functions and σ 2 is an arbitrary variance. The weighting
functions are related to the two dimensional real Gaussian distributions. A natural improvement, albeit
not pursued here, is to let the variance in the y-direction to be equal to the system’s range resolution, the
variance in the x-direction to be equal to the system’s crossrange resolution, and introducing a correlation
which is a function of the actual ghost location. This would ensure that the ensuing weighting functions
are rotated and sheared to match the system’s point spread function, nevertheless at a higher computa-
tional cost. The role of 1(·) and 2(·) is explained as follows. Consider the weighting function 1(·); if
the pixel xk is in the vicinity of the focused multipath ghost pixel xw1 associated with the target location x,
then 1(·) assumes a large value. On the other hand, if xk is not in the vicinity of xw1, then 1(·) assumes
a low value. Since an exponential function is used, the weights are always between 0 and 1, the lower
bound being theoretically unachievable. The vicinity is obviously controlled by the variance parameter,
σ 2. From our extensive simulations, we found that a lower variance must be chosen for smaller dimen-
sion rooms. For small rooms, it is logical to assume that the ghosts and higher order multipath are located
quite close to one another. Therefore, it becomes prudent to be conservative in selecting the variances.
Large variances for smaller rooms lead to false mappings. Thus, variance selection for the problem at
hand must be guided by the actual dimensions of the room being imaged. The weighting function 2(·)
rejects pixel locations at and in the vicinity of the imaged pixel, i.e., the location corresponding to the
assumed true target location xk = x. This is required because, although the focus point is singular, but
due to the system’s point spread function, some of the energy is spread to the neighboring pixels.
From our extensive simulations, we found that as the original image I(·) is complex-valued, summing
or integrating across the multipath pixels may result in destructive interference yielding a poor SCR.
This loss of SCR is against our principle of multipath exploitation. To alleviate this problem, we use

886
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
the intensity of the original beamformed image in (17.58) as
I1(x) ∈RK =
K

k=1
|I(xk)|21(xw1, xk, σ 2)2(x, xk, σ 2),
(17.59)
which implies an incoherent summation. Now considering the ghosts w.r.t the three walls, we can readily
see that (17.59) is modiﬁed as
I1(x) =
w3

wi=w1
K

k=1
|I(xk)|21(xwi , xk, σ 2)2(x, xk, σ 2).
(17.60)
Image I1(·) will have no intensity at and near the vicinity of the focused multipath pixels. Hence,
consider the following composite image obtained by simple pixel-wise multiplication.
I f (x) = I1(x) × |I(x)|2.
(17.61)
The effect of pixel-wise multiplication in (17.61) is as follows. The image I1(·) will have deep nulls at
the hypothesized ghosts locations, whereas a large peak at the true target location. Thus, (17.61) is essen-
tially a masking operation, nulling the ghosts in the original image I(·), and simultaneously enhancing
the energy at the true target location. Hence, the composite image I f (·) will alleviate the false positives,
i.e., the multipath ghosts and increase the intensity of the true target pixel. In the approach described, the
multipathghostlocationsarereadilyobtainedusingthemultipathfocusinganalysisinSection2.17.3.2.2.
It is noted that, in practice, different targets may exhibit signiﬁcantly weaker bistatic radar cross
sections (RCS) relative to their monostatic RCS. Accordingly, some or maybe all of the target ghosts may
go unnoticed. In this case, the proposed multipath exploitation approach will not prove beneﬁcial as there
may not be any increase in the target SCR. Also, consider a scenario where one target presents itself at one
of the other target’s focused multipath ghost. Since multipath is unexploited in the original beamformed
image, we would declare the presence of the target at the pixel in question. On the other hand, the
proposed approach will map this target and of course the collocated multipath ghost back to the other
target’s location causing the second target to go undetected. The question then arises whether one should
ignore the multipath ghosts and consider them as true targets or instead exploit the multipath ghosts.
The former has an unreasonably high false alarm rate, whereas the latter yields poor target detection for
the considered scenario, which, although rare, can occur in practice. However, noting that indoor targets
of interest are typically in motion, it is reasonable to assume that a genuine target would not persist on a
multipath ghost throughout the surveillance period. Hence, multipath exploitation should be preferred.
Another scenario of interest is when the direct path to the target is blocked. In that case, although the
ghosts will be mapped to the true target coordinates in the image I1(·), the masking operation in (17.61)
will cause the target to still go undetected as the original image I(·) will have a null at the target location.
2.17.3.4 Experimental results
A through-the-wall SAR system was set up in the Radar Imaging Lab at Villanova University.
A stepped-frequency signal with 696 steps covering the 1–3 GHz frequency band was used. This pro-
vides a range resolution of 0.15 m and a maximum unambiguous range of 40 m. The room dimensions

2.17.3 Multipath Exploitation
887
FIGURE 17.16
Scene Layout.
FIGURE 17.17
Single target experiment: (a) original, (b) after multipath exploitation.
are D1 = 5.09m and D2 = 3.78m. The side walls and part of the ﬂoor were covered with RF absorbers
and only multipath due to the back wall was considered. The front wall is made of 0.15m thick solid
concrete blocks with a dielectric constant of 7.66. The synthetic aperture consisted of an 81-element
monostatic linear array with an inter-element spacing of 2.22cm. The standoff distance of the array
from the front wall is 1.53m. The experimental set up is depicted in Figure 17.16.
Two different experiments were conducted. In the ﬁrst experiment, a 0.35m diameter metal sphere,
labeled as “Target 1” in Figure 17.16, was used as a target. The second experiment consisted of

888
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
FIGURE 17.18
Two target experiment: (a) original, (b) after multipath exploitation.
two targets, the ﬁrst being the sphere used in the single target case, while the second, labeled as
“Target 2” in Figure 17.16, was a smaller metallic sphere of 0.2032 m diameter. An empty scene mea-
surement without the targets present in the scene was also made and was coherently subtracted from the
target scene data to reduce the clutter. The beamformed image corresponding to the single target scene
is depicted in Figure 17.17a; both the target and the ghost are clearly visible in the image. In addition,
other target-room interactions, such as those resulting from multiple bounces within the front wall, can
be observed. The result after multipath exploitation is provided in Figure 17.17b. The variance of the
weighting functions in the exploitation algorithm was chosen to be equal to the system’s range reso-
lution. We observe that as expected, the ghost has been correctly mapped back to the target, while the
other target-room interactions are left as is in the exploited image. Figure 17.18a shows the beamformed
image corresponding to the two target scene. Both targets as well as the two ghosts with respect to the
back wall are clearly seen. The multipath exploited image is provided in Figure 17.18b, in which one
can see that the ghosts have been mapped back to the target locations. We note that, similar to the single
target case, the other target-room and target-target interactions are retained in Figure 17.18b.
2.17.4 Change detection based MTI approach
Detection of humans is one of the most important objectives in urban sensing and through-the-wall radar
technology[13,14,27,73,80–82]. Humansbelongtotheclassofanimateobjectswhicharecharacterized
by motion of the limbs, breathing, and heartbeat. These features separate animate and inanimate objects
and allow the detection of targets of interest to proceed based on changes in the phase of the scattered
radar signals over successive probing and data observations.

2.17.4 Change Detection Based MTI Approach
889
Change detection techniques have been recently used to detect moving targets in the presence of
heavy clutter that is caused by strong reﬂections from exterior and interior walls. In the case of moving
targets, the subtraction of two consecutive or non-consecutive data frames or images enjoys the same
beneﬁts as the background subtraction process for the case of stationary targets. That is, it results in
effective removal of all wall returns and non-target clutter. The subtraction operation performed for
either case of stationary or moving targets is referred to as Change Detection (CD). The length of the
time period elapsing between the two datasets to be subtracted may differ for the two cases. While the
stationary scene permits long time periods, the moving target case necessitates short periods. When
operating on data frames, both operations can be described by what is known as delay line cancelers
(DLC) [83].
It is known that moving target indication (MTI) processing applies clutter ﬁlters to remove radar
returns scattered from stationary objects. Delay line cancelers can be designed such that their frequency
responses place a notch at DC and concurrently meet other desirable passband and stopband ﬁlter
characteristics [83]. Doppler ﬁlter banks typically follow the delay line canceler, and provide beneﬁts
of signal separations, radial velocity measurements, and noise reduction [83]. It is important to note
that for urban sensing environments, changes in the backscattered signal phase due to motion do not
necessarily lend themselves to Doppler frequency shifts. The human motion can be abrupt and highly
nonstationary, producing a time-dependent phase whose rate of change may fail to translate into a
single shift or multi-component sinusoids that can be captured by different Doppler ﬁlters. Instead,
the corresponding wide spectrum of human motions becomes non-localizable and can span the entire
radar frequency band. In lieu of Doppler ﬁlters, time-frequency processing can be applied to reveal
the instantaneous frequency signatures, as it is the case with Human gait. Human gait classiﬁcation
and biometric radar have been discussed in [30,84–87]. However, apart from regularized motions,
such as walking and running, time-frequency Doppler signal representations are very complex and
difﬁcult to interpret, especially when dealing with non-homogeneous walls. Therefore, the application
of Doppler and Microdoppler ﬁlters for indoor target surveillance may not signiﬁcantly add to target
motion detection that is already achieved by delay line cancelers.
Change detection in through-the-wall radar imaging was ﬁrst discussed concurrently in [88] and
[89]. In [88], the Synchronous Impulse Reconstruction (SIRE) radar system, operating in the frequency
band of 300 MHz–3 GHz and employing a multi transmit/receive design, was used for MTI. The change
detection approach discussed in [88] subtracts the down range proﬁles over consecutive data frames,
emulating a derivative operator. It was shown that the SIRE successfully detects a human target moving
within an enclosed structure. On the other hand, change detection was applied in [89] in the context of
background subtraction to detect stationary targets using data acquired during interrogations of a scene
at two different time instants. Image intensity subtraction was employed and examples based on ray
tracing data covering 0.7–3.1 GHz frequency range were provided. More recently [90], applied change
detection for slow-moving target detection in through-the-wall radar imaging (TWRI) by subtracting
the image intensity corresponding to different data frames, followed by a zero threshold operation
to suppress the reference image. Examples of target detection in [90] included both EM modeling
data and real experiments. Change detection using ﬁrst- and second-order motion detection images for
TWRI application were discussed in [91,92]. The former has better sensitivity to motion, whereas the
latter provides better signal-to-noise ratio (SNR). Experimental data, reported in [91,92] using four
antennas and a signal bandwidth of 500 MHz–1 GHz, demonstrated that change detection techniques

890
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
are capable of detecting walking human and simulated human breathing using machine motion. Moving
target indicator ﬁltering was also used in [93] for detection of humans in motion inside buildings. An
ultrawideband frequency-modulated continuous-wave radar with an extended frequency sweep from
0.5 to 8 GHz was used in the differential mode to track human motion behind a brick wall.
In this section, we examine change detection formulation and performance when clutter removal is
performed either coherently or noncoherently. Rather than operating on successive pulses, delay line
canceler equivalences are applied to different data frames for each range bin (or equivalently different
complex amplitude images for each pixel) (coherent CD) or different intensity images for each pixel
(noncoherent CD). The frames can be consecutive, dealing with targets exhibiting sudden short motions,
or nonconsecutive with relatively long time difference, for the case in which the target changes its range
gate position.
2.17.4.1 Signal model
We develop the signal model for wideband operation with multiple transmitters and receivers under
coherent integration. Sequential use of the transmitters with simultaneous reception at all receivers is
assumed. It is noted that time-multiplexing of the transmitters is a viable option for coherent radar
operation in through-the-wall radar sensing applications. This is due to the following two main reasons:
(a) Ground-based urban imaging radar systems are typically vehicle portable, which restricts the avail-
able real estate for deploying multiple antennas on the same platform; this, combined with the important
constraint of low cost, results in deployment of far more receivers than wideband transmitters, and
(b) Indoor targets of interest, such as humans, move at low velocities. As a result, the time required to
collect one data frame with sequential use of the transmitters is small enough so that the target remains
stationary during the measurement. The sequential transmit operation is a salient feature of two known
through-the-wall radar imaging systems; one is built by the Army Research Lab [82,88], and the other
by the Defense Research and Development Canada [48].
Consider an imaging radar with an M-element linear transmit array and an N-element linear receive
array. Let s(t) be the wideband signal used for interrogating the scene. The signal duration Ts is assumed
to be less than the pulse repetition interval Tr. Assuming coherent integration of K pulses, the coherent
integration interval becomes K Tr. For the case of a single point target of reﬂectivity σp, located at
xp = (x p, yp), the kth emitted pulse with the mth transmitter active is received at the nth receiver in
the form
zmn(t, k) = σps(t −mK Tr −kTr −τp,mn),
(17.62)
where τp,mn is the propagation delay for the signal to travel between the mth transmitter, the target at
xp, and the nth receiver. For through-the-wall propagation, τp,mn will comprise the components corre-
sponding to traveling distances before, through, and after the wall [40]. The term mK Tr in Eq. (17.62)
indicates the additional time required for data collection when the mth transmitter becomes active in
a sequential order. We assume that the transmitters transmit their pulses in contiguous time intervals,
each of length K Tr. It is further assumed that we deal with targets of constant radar cross section (RCS)
over the range of the used frequencies and target aspect angles. The received signal is passed through
a ﬁlter matched to the transmit waveform and the output can be expressed as
zM F
mn (t, k) = zmn(t, k)∗h(t) =
 Tr
0
h(u)zmn(t −u, k)du,
(17.63)

2.17.4 Change Detection Based MTI Approach
891
where h(t) = s∗(−t). With K pulses coherently integrated, we obtain
zC I
mn(t) =
K−1

k=0
zM F
mn (t, k).
(17.64)
In order to generate an image of the scene being interrogated, the MN outputs corresponding to the oper-
ation of M transmitters and N receivers are processed as follows. The region of interest is divided into a
ﬁnite number of pixels in x and y, where x and y represent the crossrange and downrange, respectively.
The composite signal corresponding to the pixel, located at xq = (xq, yq), is obtained by summing time
delayed versions of the MN ﬁltered signals,
zq(t) =
M−1

m=0
N−1

n=0
zC I
mn(t + τq,mn),
(17.65)
where τq,mn is the focusing delay applied to the matched ﬁltered output of the nth receiver with the mth
transmitter active. It is noted that additional weighting can be applied during the summation operations
of (17.65) to control the sidelobe level of the transmit-receive array pattern of the imaging radar system.
Substituting (17.62)–(17.64) in (17.65) yields
zq(t) =
M−1

m=0
N−1

n=0
K−1

k=0
 Tr
0
h(u)zmn(t + τq,mn −u, k)du.
(17.66)
The complex amplitude image value I(xq) for the pixel at xq is obtained by sampling the signal zq(t)
at time t = 0. That is,
I(xq) = zq(t)
		
t=0 .
(17.67)
The process described by (17.65)–(17.67) is repeated for all pixels in the image to generate the compos-
ite image of the scene. The general case of multiple targets can be obtained by superposition of target
reﬂections [40,41].
2.17.4.2 Change detection
In its simplest form, the MTI processing is achieved by using the radar images corresponding to two data
frames, which may be consecutive or separated by one or more data frames. Due to time multiplexing
of transmitters, a data frame length T f is equal to M coherent integration intervals, i.e., T f = MK Tr.
Let

I (t)(xq)
Q−1
q=0 and

I (t+LT f )(xq)
Q−1
q=0 be the radar images corresponding to the data collected over
the two frames, where Q is the number of pixels in each image and L denotes the number of frames
between the two acquisitions. It is noted that L = 1 represents the case when the two acquisitions are
performed over consecutive frames. The timing interval for each data frame is assumed to be a fraction
of a second so that the moving target appears stationary during data collection.
Change detection can be performed in two ways, namely, coherent CD and noncoherent CD [88–
92]. In the former approach, complex amplitude image values corresponding to the two data frames are
subtracted on a pixel by pixel basis. The latter approach involves subtraction of image pixel intensity

892
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
FIGURE 17.19
Block diagram of the data domain CD approach, equivalent to complex amplitude image subtraction
(coherent CD).
values corresponding to different data frames, followed by a zero threshold operation to suppress the
reference image. For the coherent approach, the motion detection image can be expressed as follows,
(xq) = I (t+LT f )(xq) −I (t)(xq),
q = 0, 1, . . . , Q −1.
(17.68)
Using (17.66) and (17.67), we can rewrite (17.68) as
(xq) =
M−1

m=0
N−1

n=0
K−1

k=0
 Tr
0
h(u)δzmn(t + τq,mn −u, k)du
					
t=0
,
(17.69)
where
δzmn(t, k) = zmn(t−LMK Tr, k)−zmn(t, k) = zmn(t, k)∗[δ(t−LMK Tr −kTr)−δ(t−kTr)] (17.70)
and zmn(t, k) is deﬁned in (17.62). From (17.68)–(17.70), we observe that the subtraction of complex
amplitude image values for each pixel amounts to subtraction of the received data corresponding to the
two frames for each range bin, followed by image formation. Equation (17.70) provides the equivalent
delay line canceler representation for change detection directly in the data domain. A block diagram of
the data domain CD algorithm implementation is provided Figure 17.19. Note that the windowing oper-
ation in the ﬁgure ensures application of the algorithm over data frames of length T f .The block diagram
of Figure 17.19 is a two-frame delay line canceler, reminiscent of the commonly used two-pulse DLC
for clutter ﬁlter in range-Doppler radars [83]. More frames can be used in CD leading to multiple frames
delay line canceler, which is similar to three- or higher-pulse DLC. However, unlike range-Doppler radar
systems, in which higher order clutter ﬁlters provide ﬂexibility in trading off clutter suppression with
Dopplerfrequencymagnitude,therearenoclearadvantagesofusingmultipleframesinCDfortheunder-
lying problem. Hunt suggested averaging multiple frames, only to emphasize the stationary targets [92].
The noncoherent CD approach involving intensity images is depicted in Figure 17.20. In this case,
the intensity images corresponding to the two data frames are ﬁrst computed. Then, a difference image
is generated by a pixel by pixel subtraction of the intensity images as
(xq) = |I (t+LT f )(xq)|2 −|I (t)(xq)|2,
q = 0, 1, . . . , Q −1.
(17.71)

2.17.4 Change Detection Based MTI Approach
893
FIGURE 17.20
Block diagram of the noncoherent change detection approach.
The ﬁnal motion detection image is obtained by a zero threshold operation
TH(xq) =

(xq), if (xq) ≥0,
0,
otherwise.
(17.72)
This threshold results in the target appearing in the ﬁnal motion detection image only at the position
it was occupying during acquisition of the second (test) data frame, since the target image at position
corresponding to the ﬁrst (reference) data frame appears as a negative value after intensity subtraction
and is thus removed. It is noted that, unlike the complex amplitude image subtraction, there is no
equivalent data domain representation for the intensity image subtraction or noncoherent CD approach
due to the nonlinearity of the modulus function in (17.71). However, the delay line canceler framework
can still be applied. The image intensity at each pixel can be viewed as a nonlinear function of the data in
the respective frame, and the subtraction, implied by the DLC, is performed between two corresponding
pixels separated by one or multiple frames.
The aforementioned change detection schemes, though presented for motion detection, can also be
applied for detection of stationary targets in the presence of clutter and noise [89]. If a target-free
background image of the scene being interrogated is available (feasible when the radar system is being
used for long term surveillance), it can be subtracted (complex amplitude or intensity pixel subtraction)
from an image of the same scene acquired at a later time that may contain a target of interest, thus
rendering background subtraction as a special case of change detection.
2.17.4.3 Experimental results
A wideband through-the-wall imaging radar system was set up in the Radar Imaging Lab at Villanova
University. A stepped-frequency CW signal, consisting of 101 frequency steps of size 10 MHz, covering
1.5–2.5 GHz band was chosen for imaging. The bandwidth of 1 GHz provides a range resolution of
15cm and the 10 MHz frequency step allows 15m unambiguous range, which is roughly three times the
length of the room being imaged. An Agilent network analyzer, model ENA 5071B, was used for signal
synthesis and data collection. A horn antenna, model ETS-Lindgren 3164-04, with an operational
bandwidth from 0.7 to 6 GHz, was mounted on a Field Probe Scanner to synthesize an 11-element
uniform receive line array with an inter-element spacing of 7.5cm. Two horn antennas (model ETS-
Lindgren 3164-04), mounted on tripods and placed slightly above and on either side of the receive array,

894
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
FIGURE 17.21
Layout of the scene and target trajectory.
were used as transmitters. Each transmitter was spaced 3.75 cm away from the nearest receiver. Thus,
for the system used, M = 2 and N = 11. A 10 ft × 8 ft wall segment was constructed utilizing 0.14 m
thick solid concrete blocks with a dielectric constant of 7.66. The receive array was at a standoff distance
of 1.05m from the wall, whereas the transmitters were positioned 1.33m in downrange from the wall.
In order to illustrate the performance of change detection under complex and intensity image delay
line cancelers, we consider the following experiment. A human walks away from the front wall in an
empty room, following a straight line path. Since simultaneous data cannot be collected at all receive
locations due to the synthetic nature of the receive aperture, eight different target positions were consid-
ered, separated by 15 cm, along the trajectory, as illustrated in Figure 17.21. Data was collected for all
eight positions, with the target stationary at each position, using time multiplexing of the transmitters.
At each position, coherent integration was performed over 16 measurements. That is, K = 16 for the
experiment.
We ﬁrst consider the case where the person moves from position 3 to position 4. That is, the two acqui-
sitions are performed over consecutive frames and L = 1. Figure 17.22a and b show the beamformed
images using the data corresponding to positions 3 and 4, respectively. Both images show strong reﬂec-
tions from the front wall, rendering target returns hard to detect in either image. Figure 17.23a shows
the result of coherent change detection wherein the complex radar image of Figure 17.22a is subtracted
from the complex image of Figure 17.22b. We observe that all stationary background including the
front wall has been eliminated from the image, and the target undergoing motion has been detected.
Since the target appears in two consecutive range cells, no clear target displacement is observed and the
target image appears blurred. The corresponding noncoherent CD results under intensity image DLC
are presented in Figure 17.23b. We observe that the intensity image DLC removes most of the imaged
target in the case of consecutive range cell acquisitions. Moreover, due to the nonlinearity of the mod-
ulus function, the stationary background in the image is in general different for each data acquisition,
thereby causing the background to be only partially canceled out under intensity image DLC [90]. As
a result, stronger artifacts than those of the complex image DLC can be clearly observed. The ability

2.17.4 Change Detection Based MTI Approach
895
FIGURE 17.22
Beamformed images for the target at position (a) 3 and (b) 4 (consecutive range cells).
FIGURE 17.23
Images after change detection under (a) coherent CD and (b) noncoherent CD for the human walking from
position 3 to position 4.
to detect the target in the change detected image is, therefore, reduced under intensity image DLC as
compared to complex image DLC.
Next, we investigate the performance of the various schemes under large target displacement between
consecutive acquisitions. Consider the case where the person moves from position 1 to position 4.
In this case, L = 3. Figure 17.24a shows the result of coherent change detection. Since the target

896
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
FIGURE 17.24
Images after change detection under (a) coherent CD and (b) noncoherent CD for the human walking from
position 1 to position 4.
undergoes large range migration, the moving target presents itself as two targets in the image. The nonco-
herent
change
detection
results
for
the
large
target
displacement
case
are
presented
in
Figure 17.24b. We observe that the intensity image DLC retains the target at position 4 and removes the
target at position 1. However, similar to the small target displacement case, the artifacts resulting from
the background not being totally canceled out render target detection difﬁcult.
2.17.5 Compressive sensing approach to moving target indication for
urban sensing
The most desirable goal of a through-the-wall radar system is to provide situational awareness in a fast
and reliable manner. This goal is primarily challenged due to increasing demands on the radar system
to deliver high resolution images in both range and cross-range, which requires use of wideband signals
and large array apertures, respectively. In addition, the presence of multipath and clutter can signiﬁcantly
contaminate the radar data and compromise the main intent of providing enhanced system capabilities
for imaging of building interiors and tracking of targets behind walls.
Most radar data acquisition systems acquire samples in frequency (or time) and space, and then apply
compression to reduce the amount of stored information. This approach has three inherent inefﬁciencies.
First, as the demands for high resolution and more accurate information increase, so does the number
of data samples to be recorded, stored, and subsequently processed. Second, there are signiﬁcant data
redundancies not exploited by the traditional sampling process. Third, it is wasteful to acquire and
process data samples that will be discarded later. Further, in radar imaging systems, whether using time
or stepped-frequency based pulsing, along data collection leads to image degradation. This is because,

2.17.5 Compressive Sensing Approach to Moving Target Indication for Urban Sensing
897
unless all objects in the scene are stationary during the entire data collection operations, image smearing
of targets would occur.
Compressive sensing (CS) is a very effective technique for scene reconstruction from a relatively
small number of data samples without compromising the imaging quality [94–98]. In general, the min-
imum number of data samples or sampling rate that is required for scene image formation is governed
by the Nyquist theorem. However, when the scene is sparse, compressed sensing provides very efﬁcient
sampling, thereby signiﬁcantly decreasing the required volume of data collected. Towards the objective
of providing persistent surveillance in urban environments, such techniques will yield reduced cost, sim-
pliﬁed hardware, and efﬁcient sensing operations that allow super-resolution imaging of sparse behind-
the-wall scenes. CS has been successfully applied to TWRI of moving and stationary targets [97,99].
In this section, we exploit full beneﬁts of the compressive sensing to aid in fast data acquisition in
wideband through-the-wall radar imaging systems for moving target detection and localization. Change
detection is ﬁrst used for removal of stationary background (clutter and stationary targets). Since the
removal of stationary background via change detection converts a populated scene into a sparse scene of
moving targets, reduction in data volume is then pursued under the framework of compressive sensing.
2.17.5.1 Signal model
Assume that there are N antenna locations constituting the synthetic aperture and a stepped-frequency
signal of M narrowband signals. The signal received at the nth antenna location with the mth frequency
is given by,
y(n, m) =
P−1

p=0
σp exp ( −j2π fmτn,p) + B(n, m),
(17.73)
where σp is the reﬂection coefﬁcient of the pth moving target, τn,p is the two-way propagation delay for
the signal to travel from the nth antenna to the pth moving target, and B(n, m) represents the contribution
of the stationary background. For free-space propagation, τn,p is proportional to the Cartesian distance
between the nth antenna and the pth target, whereas in the presence of the wall, it contains contributions
from paths in air and through the wall [100].
The MTI processing is achieved by collecting multiple data intervals over a period of time and
buffering the corresponding stepped-frequency data measured at each antenna location [101]. Let I
be the number of collected data intervals and y(i)(n, m), n = 1, . . . , N, m = 1, . . . , M, deﬁne the
measured stepped-frequency dataset for the ith interval. It is noted that the timing interval for each
dataset is a fraction of a second so that the moving target appears stationary during data collection.
Change detection is applied to the measured datasets as follows,
(i)(n, m) = y(i+1)(n, m) −y(i)(n, m),
(17.74)
where i = 1, . . . , I −1, forming the set of difference signals
{(1)(n, m), (2)(n, m), . . . , (I−1)(n, m)}.
(17.75)

898
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
Using (17.73) and (17.74), the ith difference signal can be expressed as
(i)(n, m) =
P−1

p=0

σpexp

−j2π fmτ

i+1

n,p

−exp

−j2π fmτ

i

n,p

(17.76)
The component of the radar return from the stationary background is the same over the ith and (i + 1)th
time intervals, and is thus removed from the difference signal. For moving targets, two situations may
arise. In the ﬁrst case, the target undergoes large range migration, whereas in the second case, the target
undergoes small range migration, i.e., moves into the next range cell. In the ﬁrst case, as seen from
(17.76), the moving target will present itself as two targets, whereas in the second case, the target will
appear as spread. We will focus on the former situation in this chapter.
2.17.5.2 Compressive sensing for MTI
Consider the ith difference dataset. For notational simplicity, we drop the superscript “(i).” Let n be
the M ×1 difference signal vector corresponding to the nth antenna location. For large range migration,
an equivalent signal representation with Q = 2P targets can be used. Thus, with the region of interest
divided into L pixels, the relationship between the difference signal n and the pixel locations can be
expressed as [96,97]
n = Ans,
(17.77)
where
n = [(n, 0)(n, 1) · · · (n, M −1)]T , [An]ml = exp ( −j2π fmτn,l),
[s]l =

 ˜σq, τn,l = τn,q,
0,
τn,l ̸= τn,q.
(17.78)
In (17.78), ˜σq is the reﬂectivity of the qth target and τn,l(τn,q) is the two-way signal traveling time
between the nth antenna location and lth pixel’s (qth target’s) location. The An matrix is similar to the
Fourier matrix which relates the frequency and time representations [97].
Given ¯n for n = 1, . . . , N, which is a K( < M) dimensional vector consisting of elements
randomly chosen from n, we can recover s by solving the following equation:
ˆs = arg min
s
∥s∥l1 subject to
 ¯As −¯

l2 < δ,
(17.79)
where δ represents the tolerance error, and
¯A = [ ¯A0 ¯A1 . . . ¯AN−1]T ,
¯ = [ ¯0 ¯1 . . . ¯N−1]T ,
¯n = [(n, i0)(n, i1) · · · (n, iK−1)]T ,
[ ¯An]ml = [An]ikl.
(17.80)
In the above equation, ¯ and ¯A represent respective concatenations of ¯n and ¯An, and ik
∈[0, 1, . . . , M −1] for k = 0, . . . , K −1, are the indices of the randomly measured frequencies.
A stable solution of the sparse signal recovery problem in (17.79) is guaranteed provided that ¯A
satisﬁes the Restricted Isometry Property (RIP), which states that all subsets of r columns taken from

2.17.5 Compressive Sensing Approach to Moving Target Indication for Urban Sensing
899
¯A are, in fact, nearly orthogonal, r being the sparsity of the signal ¯ [102]. In practice, it is difﬁcult to
check this property. Other related measures on the matrix ¯A, such as mutual coherence, are often used
to guarantee stable recovery through l1-minimization [102]. Mutual coherence of the columns of ¯A can
be viewed as the largest off-diagonal entry of the Gram matrix ¯AH ¯A, where the columns of ¯A have
been normalized. The matrix ¯A is considered to be incoherent if the value of the mutual coherence is
small. For stepped-frequency systems, the coherence between the columns of ¯A is reduced by randomly
distributing the selected frequency bins over the entire frequency band [96,97,103].
Selecting a proper tolerance error δ is also very important for stable recovery of the scene being
imaged. The tolerance error can be chosen using the cross-validation strategy [96,104], which does not
FIGURE 17.25
Data collection for (a) compressed sensing along frequency only, (b) conventional high-resolution radar, and
(c) compressive sensing along both antennas and frequency. The ﬁlled rectangles indicate the measured
data samples.

900
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
require any knowledge or estimates of the noise statistics. This method depends on separating the data
measurements into estimation and cross-validation sets. The CS method is applied to the estimation
dataset with an initial selection of δ and the method’s result is tested on the cross-validation dataset.
As the algorithm iterates, the prediction performance in the cross-validation set increases. When the
method starts to overﬁt the estimation dataset, which means estimating part of the noise, performance
in the cross-validation set decreases. Further decrease in δ is not beneﬁcial and the algorithm should be
terminated. The cross-validation based algorithm consists of the following steps, where the subscript
“E” denotes the estimation set, and “CV” the cross-validation set:
i. Initialize: Set δ =
 ¯CV

l2 and i = 1.
ii. Estimate: Solve (17.79) to estimate the target locations ˆs(i) with the estimation data set ¯AE, ¯E.
iii. Cross-validate: If
 ¯CV −¯ACV ˆs(i))

l2 < δ, then set δ =
 ¯CV −¯ACV ˆs(i))

l2, increment i and
iterate from Step ii. Otherwise, terminate the iteration.
Equations (17.79) and (17.80) represent one strategy that can be adopted for compressive sensing
based MTI approach, wherein frequencies are chosen randomly for all the antenna locations constituting
the array aperture. Figure 17.25a depicts the data collection scheme for the employed CS imaging
strategy,whereinthehorizontalaxisisthefrequency,theverticalaxisrepresentstheantennaposition,and
the dark boxes represent the sampled data. For comparison, the data collection scheme for conventional
high-resolution radar is also provided in Figure 17.25b, which reiterates that all the frequency bins are
transmitted and received at all antenna locations. Equations (17.79) and (17.80) can also be extended
so that random measurements include both antennas and frequencies [96,97]. That is, a few frequency
bins are collected at few antenna locations, as shown in Figure 17.25c.
2.17.5.3 Experimental results
A wideband SAR system was set up in the Radar Imaging Lab at Villanova University. A stepped-
frequency CW signal, consisting of 201 frequency steps of size 10 MHz, covering 1–3 GHz band was
chosen for imaging. An Agilent network analyzer, model ENA 5071B, was used for signal synthesis and
data collection. A horn antenna, model ETS-Lindgren 3164-04, with an operational bandwidth from 0.7
to 6 GHz, was mounted on a Field Probe Scanner to synthesize a 41-element uniform linear array with
an inter-element spacing of 3.745 cm, as shown in Figure 17.26a. A 3.05 m × 2.44 m wall segment was
constructed utilizing 0.14 m thick solid concrete blocks with a dielectric constant of 7.66. The array was
at a standoff distance of 1.06 m from the wall. A 5 Gallon jug ﬁlled with salt water (emulating a human)
was used as the target, as shown in Figure 17.26b. In order to emulate a moving target, two datasets
were collected with the target at two different positions. Since simultaneous data cannot be collected at
all antenna locations due to the synthetic nature of the array aperture, data were collected for the two
positions, with the target stationary at each position. The target positions were selected as (0.8,1.83) m
and (0.25,2.2) m, so as to emulate large range migration of the target between the two measurements.
The region to be imaged is chosen to be 4.8 m × 5.3 m centered in the middle of the scene beyond
the wall and divided into 33 × 57 pixels in crossrange and downrange. Figure 17.27a shows the result
of change detection wherein the full dataset (201 × 41 samples) corresponding to target position 1 is
subtracted from that for position 2, followed by conventional image formation. We observe that all
background returns have been eliminated from the image and the target undergoing motion has been

2.17.6 Applications
901
detected. Moreover, as expected, the target has presented itself at the two locations corresponding to
positions 1 and 2.
For the CS approach, instead of measuring all 201 frequencies, we use a random subset of 7 fre-
quencies only at each of the 41 antenna locations. According to CS theory, an r-sparse L-dimensional
signal can be recovered from O(r log (L)) measurements [95]. Considering the system resolution and
for the salt water jug extent of 0.27 m and 0.27 m in crossrange and downrange, respectively, each target
will approximately occupy only 6 out of 1881 image pixels. For the large range migration case under
consideration, the 41 × 7 measured data points well exceed this requirement ((2 × 6) log (1881)) ≈90).
The CS reconstructed image is shown in Figure 17.27b. For comparison, the beamformed image with the
same reduced random dataset as CS is provided in Figure 17.27c. From Figure 17.27b, we observe that
the CS approach localizes the target at positions 1 and 2 accurately. On the other hand, as seen in Figure
17.27c, beamforming with the reduced dataset has degraded image quality with signiﬁcantly more false
targets. A similar experiment without the absorbers on the side and back walls was conducted and shown
to reduce the sparsity of the scene due to the presence of “ghosts.” The latter stems from the target-wall
reﬂections and multipath returns. Compressive sensing can still be effective in localizing the target and
its ghosts, but requires an increase in the number of data samples compared to the case of “no ghosts.”
2.17.6 Applications
Through-the-wall radar imaging has a variety of applications in both civil and military paradigms. It has
been successfully sought out for surveillance and reconnaissance in urban environments, requiring not
only the layout of the building, including types and locations of walls, but also detection and localization
of both moving and stationary targets within enclosed structures [1,80,105]. This technology can also
be used in rescue missions, searching for ﬁre, earthquakes, and avalanche victims and survivors, behind-
FIGURE 17.26
(a) Wideband SAR system, (b) scene layout.

902
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
FIGURE 17.27
Change detection results using data from position 1 and position 2. (a) Beamforming with full difference
dataset; (b) CS result with limited difference dataset; (c) beamforming with limited difference dataset.
the-wall detection and surveillance of suspected criminals and outlaws, and by law enforcement ofﬁcers
for locating hostages and their captors [20,106].
2.17.7 Open issues and problems
There are many challenges still facing the TWRI technology. Imaging of stationary scenes using SAR
is considered more difﬁcult than MTI for moving targets. The difﬁculty arises from false positives and

2.17.8 Data Sets
903
ghosts, both are products of multipath. Further, when targets are close to walls, imaging algorithms may
not be able to separate targets from wall responses, as they both tend to merge. Another important TWRI
goal is target classiﬁcation. The relatively limited bandwidth does not lead to sufﬁcient resolution of key
scatterers, rendering the target image as a cluster of contagious high value pixels, a situation that does not
lend itself to effective feature extraction. Classiﬁcations of Human gait take advantage of the motion of
the limbs and their respective microDoppler signatures. When performed behind walls, these signatures
blur and it can be difﬁcult to achieve low classiﬁcation errors. Complex buildings, made of multiple
ﬂoors, each with populated scenes present the ultimate challenge of TWRI technology, speciﬁcally with
long standoff distances whether it is associated with ground-based or airborne systems. The latter, due
to covertness and operation logistics, is becoming the cornerstone of recent research and development
in this area, especially for defense applications [107].
2.17.8 Data sets
The Center for Advanced Communications at Villanova University has conducted several through-the-
wall imaging experiments and collected a variety of datasets in a laboratory environment. The datasets
include full-polarization free-space and through-the-wall collections under semi-controlled conditions
with a stepped-frequency radar system. Targets consist of both calibrated reﬂectors (dihedrals, trihedrals,
and spheres) as well as a number of common indoor objects (phone, computer, tables, chair, ﬁling cabi-
net). In addition, a jug of saline solution is also used as a target to crudely approximate a human. These
datasets are available for download at the following website: http://www.villanova.edu/engineering/
centers/cac/twri.htm.
2.17.9 Conclusions
In this chapter, we presented recent algorithmic advances in through-the-wall radar imaging. First,
considering ground-based EM sensing, we discussed two methods, namely, spatial ﬁltering and EM
modeling based solution, for mitigating the front wall return prior to application of the image formation
methods. The spatial ﬁltering technique builds on the strong correlation of wall EM responses across
antenna array elements to reduce constant-type return that is typical of walls in monostatic illuminations.
The spatial ﬁlter, thus, allows the follow-on beamforming to unmask and image behind-the-wall targets
that have limited spatial extent, such as humans, compared to walls without the need for a priori
knowledge of the wall characteristics. A simple IIR notch ﬁlter with ﬂexible design was compared with
the ﬁxed design MA subtraction ﬁltering, commonly used in GPR. On the other hand, the EM modeling
approach is wall-dependent and relies on accurate estimation of the wall parameters for suppression of
the wall return. Extraction of the wall parameters and coherent subtraction of the modeled wall reﬂection
was shown to signiﬁcantly improve the signal-to- wall-clutter ratio.
Second, an approach to exploit the rich indoor multipath environment for improved target detection
was described. A ray tracing approach was used to derive a multipath model, considering reﬂections
inside an enclosed room comprising four homogeneous walls. Using the model, it was demonstrated
analytically that the multipath corresponding to each sensor appeared on the wall but changes position
from one sensor to another. Hence, a least squares technique was used to estimate its actual focusing

904
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
location in both downrange and crossrange. The model was utilized to develop a multipath exploitation
technique which associates multipath ghosts with their respective targets and maps them to their true
target locations. This technique reduced the false positives in the original beamformed image as well
as increased the signal-to-noise ratio at the true target locations.
Third, we discussed a change detection approach to moving target indication for through-the-wall
applications. Change detection was used to mitigate the heavy clutter that is caused by strong reﬂec-
tions from exterior and interior walls. Both coherent and noncoherent change detection techniques were
examined and their performance was compared under both consecutive and non-consecutive acquisi-
tions. For non-consecutive acquisitions, the coherent CD scheme showed two sets of imaged targets
corresponding to the positions of a single target at the two data acquisitions, whereas the noncoherent
CD retained only one set of imaged targets, though with signiﬁcantly more artifacts. For consecutive
acquisitions, the coherent change detection provided better performance than the noncoherent CD,
which removed most of the imaged target during the zero-thresholding step.
Finally, we identiﬁed and localized moving targets behind walls and inside enclosed structures using
an approach that combines sparsity-driven radar imaging and moving target indication. The removal of
stationary background via change detection resulted in a sparse scene of moving targets, thereby inviting
application of compressed sensing techniques for fast data acquisition. Using stepped-frequency based
radar imaging, it was demonstrated that a sizable reduction in the number of frequency samples was
provided by compressive sensing without degradation in system performance.
Relevant Theory: Radar Signal Processing and Statistical Signal Processing
See this Volume, Chapter 10 Introduction: Radar Signal Processing
See Vol. 3, Chapter 6 Quickest Change Detection
References
[1] E. Baranoski, Through-wall imaging: historical perspective and future directions, J. Franklin Inst. 345 (6)
(2008) 556–569.
[2] J.C. Curlander, R.N. McDonough, Synthetic Aperture Radar-Systems and Signal Processing, Wiley,
New York, 1991.
[3] J.W. Goodman, Introduction to Fourier Optics, McGraw-Hill, New York, 1996.
[4] R.K. Tyson, Principles of Adaptive Optics, second ed., Academic Press, Boston, MA, 1998, p. 1998.
[5] R.J. Vaccaro, The past, present, and the future of underwater acoustic signal processing, IEEE Signal Proc.
Mag. 15 (4) (1998) 21–51.
[6] E.A. Robinson, S. Treitel, Geophysical Signal Analysis, Englewood Cliffs, NJ, Prentice-Hall, 1980.
[7] A.C. Kak, M. Slaney, Principles of Computerized Tomographic Imaging, IEEE Press, New York, 1988.
[8] F. Ahmad, M.G. Amin, Noncoherent approach to through-the-wall radar localization, IEEE Trans. Aerosp.
Electron. Syst. 42 (4) (2006) 1405–1419.
[9] F. Ahmad, M.G. Amin, A noncoherent radar system approach for through-the-wall imaging, in: Proceed-
ings of the SPIE—Sensors, and Command, Control, Communications, and Intelligence Technologies IV
Conference, Orlando, FL, vol. 5778, 2005, pp. 196–207.
[10] F. Ahmad, M.G. Amin, Performance of autofocusing schemes for single target and populated scenes behind
unknown walls, in: Proceedings of the SPIE—Radar Sensor Technology XI, Orlando, FL, April 2007, vol.
6547, 2007.

References
905
[11] F. Ahmad, G. Frazer, S.A. Kassam, M.G. Amin, Design and implementation of near-ﬁeld, wideband synthetic
aperture beamformers, IEEE Trans. Aerosp. Electron. Syst. 40 (1) (2004) 206–220.
[12] F. Ahmad, M.G. Amin, P.D. Zemany, Performance analysis of dual-frequency CW radars for motion detection
and ranging in urban sensing applications, in: Proceedings of SPIE—Radar Sensor Technology XI, Orlando,
FL, April 2007, vol. 6547, 2007.
[13] M.G. Amin (Ed.), Special Issue on Advances in Indoor Radar Imaging, J. Franklin Inst. 345 (6) (2008)
556–722.
[14] M. Amin, K. Sarabandi (Eds.), Special Issue on Remote Sensing of Building Interior, IEEE Trans. Geosci.
Remote Sens. 47(5) (2009) 1270–1420.
[15] S.E. Borek, An overview of through the wall surveillance for homeland security, in: Proceedings of the 34th,
Applied Imagery and Pattern Recognition, Workshop 6, October 2005, pp. 19–21.
[16] D.G. Falconer, R.W. Ficklin, K.G. Konolige, Robot-mounted through-wall radar for detecting, locating,
and identifying building occupants, in: Proceedings of the IEEE International Conference on Robotics and
Automation, 2000, pp. 1868–1875.
[17] D.D. Ferris Jr., N.C. Currie, A survey of current technologies for through-the-wall surveillance (TWS),
in: Proceedings of the SPIE—Sensors, C31 Information, and Training Technologies for Law Enforcement,
Boston, MA, November 1998, vol. 3577, pp 62–72.
[18] R.J. Fontana, Recent system applications of short-pulse ultra-wideband (UWB) technology, in: IEEE Trans.
Microwave Theory Tech. 52 (9) (2004).
[19] L.M. Frazier, Surveillance through walls and other opaque materials, in: Proceedings of the IEEE National
Radar Conference 1996, 1996, pp. 27–31.
[20] E.F. Greneker, RADAR ﬂashlight for through-the-wall detection of humans, in: Proceedings of the SPIE—
Targets Backgrounds: Characterization and Representation IV, vol. 3375, 1998, 280–285.
[21] A.R. Hunt, Image formation through walls using a distributed radar sensor network, in: Proceedings
of the SPIE—Laser Physics, Photonics, Spectroscopy and Molecular Modeling V, vol. 5778, 2005,
pp. 169–174.
[22] S. Nag, M.A. Barnes, T. Payment, G. Holladay, An ultra-wideband through-the-wall radar for detecting the
motion of people in real time, in: Proceedings of the SPIE—Radar Sensor Technology and Data Visualization,
Orlando, FL, April 2002, vol. 4744, 2002, pp. 48–57.
[23] L.P. Song, C. Yu, Q.H. Liu, Through-wall imaging (TWI) by radar: 2-D tomographic results and analyses,
IEEE Trans. Geosci. Remote Sens. 43 (12) (2005) 2793–2798.
[24] F. Soldovieri, R. Solimene, Through-wall imaging via a linear inverse scattering algorithm, IEEE Geosci.
Remote Sens. Lett. 4 (4) (2007) 513–517.
[25] F. Soldovieri, F. Ahmad, R. Solimene, Validation of microwave tomographic inverse scattering approach via
through-the-wall experiments in semi-controlled conditions, IEEE Geosci. Remote Sens. Lett. 8 (1) (2011)
123–127.
[26] L.M. Frazier, Motion detection radar (MDR) for law enforcement, IEEE Potentials 16 (5) (2004) 3079–3082.
[27] S.S. Ram, H. Ling, Through-wall tracking of human movers using joint Doppler and array processing, IEEE
Geosci. Remote Sens. Lett. 5 (3) (2008) 537–541.
[28] P. Setlur, F. Ahmad, M.G. Amin, P.D. Zemany, Experiments on through-the-wall motion detection and rang-
ing, in: Proceedings of the SPIE—Command, Control, Communications, and Intelligence (C3I) Technologies
for Homeland Security and Homeland Defense VI, Orlando, FL, April 2007, vol. 6538, 2007.
[29] P. Setlur, M.G. Amin, T. Thayaparan, Micro-doppler signal estimation for vibrating and rotating targets,
in: Proceedings of the Eighth International Symposium on Signal Processing and its Applications, Sydney,
Australia, August 2005, 2005.
[30] T. Thayaparan, L. Stankovic, I. Djurovic, Micro-doppler human signature detection and its application to
gait recognition and indoor imaging, J. Franklin Inst. 345 (6) (2008) 700–722.

906
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
[31] P. Setlur, F. Ahmad, M.G. Amin, Analysis of Micro-Doppler signals using linear FM basis decomposition,
in: Proceedings of the SPIE Symposium on Defense and Security, Radar Sensor Technology X Conference,
Vol. 6210, Orlando, FL, April 2006.
[32] C.P. Lai, R.M. Narayanan, Ultrawideband random noise radar design for through-wall surveillance, IEEE
Trans. Aerosp. Electron. Syst. 46 (4) (2010) 1716–1730.
[33] K. Lukin, V. Konovalov, Through wall detection and recognition of human beings using noise radar sensors,
in: Proceedings of the NATO RTO SET Symposium on Target Identiﬁcation and Recognition Using RF
Systems, Oslo, Norway, October 2004, P15.1–P15.12.
[34] T.E. McEwan, Ultra-Wideband Radar Motion Sensor, US Patent 5,361,070, 1994.
[35] V. Venkatasubramanian, H. Leung, Chaos UWB radar for through-the-wall imaging, IEEE Trans. Image
Process. 18 (6) (2009) 1255–1265.
[36] Y. Yang, A.E. Fathy, Development and implementation of a real-time see-through-wall radar system based
on FPGA, IEEE Trans. Geosci. Remote Sens. 47 (5) (2009) 1270–1280.
[37] F. Ahmad, M.G. Amin, P.D. Zemany, Dual-frequency radars for target localization in urban sensing, IEEE
Trans. Aerosp. Electron. Syst. 45 (4) (2009).
[38] F. Ahmad, M.G. Amin, P. Setlur, Through-the-wall target localization using dual-frequency CW radars,
in: Proceedings of the SPIE—Sensors, and Command, Control, Communications, and Intelligence (C3I)
Technologies Conference, Orlando, FL, April 2006, vol. 6201, 2006.
[39] Y. Zhang, M.G. Amin, F. Ahmad, Time-frequency analysis for the localization of multiple moving targets
using dual-frequency radars, IEEE Signal Process. Lett. 15 (2008) 777–780.
[40] F. Ahmad, Y. Zhang, M. Amin, Three-dimensional wideband beamforming for imaging through a single
wall, IEEE Geosci. Remote Sens. Lett. 5 (2) (2008) 176–179.
[41] F. Ahmad, M.G. Amin, S.A. Kassam, Synthetic aperture beamformer for imaging through a dielectric wall,
IEEE Trans. Aerosp. Electron. Syst. 41 (1) (2005) 271–283.
[42] M. Dehmollaian, M. Thiel, K. Sarabandi, Through-the-wall imaging using differential SAR, IEEE Trans.
Geosci. Remote Sens. 47(5) (2009) 1289–1296.
[43] F. Ahmad, M.G. Amin, G. Mandapati, Autofocusing of through-the-wall radar imagery under unknown wall
characteristics, IEEE Trans. Image Process. 16 (7) (2007) 1785–1795.
[44] M. Dehmollaian, K. Sarabandi, Refocusing through building walls using synthetic aperture radar, IEEE
Trans. Geosci. Remote Sens. 46 (6) (2008) 1589–1599.
[45] Y. Yoon, M.G. Amin, F. Ahmad, MVDR beamforming for through-the-wall radar imaging, IEEE Trans.
Aerosp. Electron. Syst. 47 (1) (2011) 347–366.
[46] G. Barrie, J. Tunaley, An Analysis of Through- and in-the-Wall UWB Impulse Radar: System Design Con-
siderations, Technical Memorandum TM 2003-134, Defence Research and Development Canada (DRDC),
2003.
[47] V.R. Komanduri, A. Hoorfar, N. Engheta, Low-proﬁle array design considerations for through-the-wall
microwave imaging applications, in: Proceedings of the IEEE International AP-S Symposium, Washington
DC, July 2005.
[48] P. Sévigny et al., Concept of operation and preliminary experimental results of the DRDC through-wall SAR
system, in: Proceedings of the SPIE—Radar Sensor Technology XIV, Orlando, FL, April 2010, vol. 7669,
2010, pp. 766907-1–766907-11.
[49] E.F. Greneker, E.O. Rausch, Wall characterization for through-the-wall radar applications, in: Proceedings
of the SPIE—Radar Sensor Technology XII Conference, Orlando, FL, April 2008, vol. 6947.
[50] A. Muqaibel, Ahmad Safaai-Jazi, Characterization of wall dispersive and attenuative effects on UWB radar
signals, J. Franklin Inst. 345 (2008) 640–658.

References
907
[51] C. Thajudeen, A. Hoorfar, F. Ahmad, T. Dogaru, Measured complex permittivity of walls with different
hydration levels and the effect on power estimation of TWRI target returns, Prog. Electromagn. Res. B 30
(2011) 177–199.
[52] R.J. Burkholder, Electromagnetic models for exploiting multi-path propagation in through-wall radar imag-
ing, in: Proceedings of the International Conference on Electromagnetics in Advanced Applications, IEEE,
Torino, Italy, 2008, pp. 572–575.
[53] P.C. Chang, R.J. Burkholder, J.L. Volakis, R.J. Marhefka, Y. Bayram, High-frequency EM characterization
of through-wall building imaging, IEEE Trans. Geosci. Remote Sens. 47 (5) (2009) 1375–1387.
[54] T. Dogaru, C. Le, SAR images of rooms and buildings based on FDTD computer models, IEEE Trans.
Geosci. Remote Sens. 47 (5) (2009) 1388–1401.
[55] M. Thiel, K. Sarabandi, Ultrawideband multi-static scattering analysis of human movement within buildings
for thepurposeof stand-off detectionandlocalization, IEEE Trans. Antenn. Propag. 59 (4) (2011) 1261–1268.
[56] M. Dehmollaian, K. Sarabandi, An approximate solution of scattering from reinforced concrete walls using
an analytic 1-D periodic Green’s function, IEEE Trans. Antenn. Prop. 56 (8) (2008) 2681–2690.
[57] R. Solimene, F. Ahmad, F. Soldovieri, A novel CS-SVD strategy to perform data reduction in linear inverse
scattering problems, IEEE Geosci. Remote Sens. Lett. 9 (5) (2012) 881–885.
[58] T. Dogaru, C. Le, Through-the-Wall Small Weapon Detection Based on Polarimetric Radar Techniques, US
ARL Technical Report ARL-TR-5041, Adelphi, MD, 2009.
[59] K.M. Yemelyanov, N. Engheta, A. Hoorfar, J.A. McVay, Adaptive polarization contrast techniques for
through-wall microwave imaging applications, IEEE Trans. Geosci. Remote Sens. 47 (5) (2009) 1362–1374.
[60] W. Zhang, A. Hoorfar, C. Thajudeen, F. Ahmad, Full polarimetric beamforming algorithm for
through-the-wall radar imaging, Radio Sci. 46 (RS0E16) (2010), http://dx.doi.org/10.1029/2010RS
004631.
[61] F.H.C. Tivive, A. Bouzerdoum, M.G. Amin, An SVD-based approach for mitigating wall reﬂections in
through-the-wall radar imaging, in: Proceedings of the IEEE Radar Conference, Kansas City, MO, May
23–27, 2011, 2011, pp. 519–524.
[62] R. Chandra, A.N. Gaikwad, D. Singh, M.J. Nigam, An approach to remove the clutter and detect the target
for ultra-wideband through wall imaging, J. Geophys. Eng. 5 (4) (2008) 412–419.
[63] P.K. Verma, A.N. Gaikwad, D. Singh, M.J. Nigam, Analysis of clutter reduction techniques for through wall
imaging in UWB range, Prog. Electromagn. Res. B 17 (2009) 29–48.
[64] Y.-S. Yoon, M.G. Amin, Spatial ﬁltering for wall-clutter mitigation in through-the-wall radar imaging, IEEE
Trans. Geosci. Remote Sens. 47 (9) (2009) 3192–3208.
[65] H. Brunzell, Detection of shallowly buried objects using impulse radar, IEEE Trans. Geosci. Remote Sens.
37 (2) (1999) 875–886.
[66] F. Gustaffson, Determining the initial states in forward-backward ﬁltering, IEEE Trans. Signal Process. 44
(4) (1996) 988–992.
[67] M. Çetin, W. Karl, D. Castañon, Evaluation of a regularized SAR imaging technique based on recognition-
oriented features, in: Proceedings of the SPIE—Algorithms for SAR Imagery VII, Orlando, FL, April 2000,
vol. 4053, pp. 40–51.
[68] M. Dehmollaian, K. Sarabandi, Analytical, numerical, and experimental methods for through-the-wall radar
imaging, in: Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing,
Las Vegas, NV, April 2008, 2008, pp. 5181–5184.
[69] J.A. Kong, Electromagnetic Wave Theory, EMW Publishing, Cambridge, MA, 2000.
[70] C. Thajudeen, A. Hoorfar, A Comparative study of wall parameter estimation and mitigation techniques, in:
Proceedings of the USNC/URSI Meeting, Toronto, Canada, July 2010, 2010.

908
CHAPTER 17 Through-the-Wall Radar Imaging: Theory and Applications
[71] J. Zhang, Y. Huang, Extraction of dielectric properties of building materials from free-space time-domain
measurement, in: Proceedings of High Frequency Postgraduate Student Colloquium, September 1999, 1999,
pp. 127–132.
[72] F. Ahmad, M.G. Amin, Multi-location wideband synthetic aperture imaging for urban sensing applications,
J. Franklin Inst. 345 (6) (2008) 618–639.
[73] T. Dogaru, C. Le, Validation of Xpatch Computer Models for Human Body Radar Signature, US ARL
Technical Report ARL-TR-4403, Adelphi, MD, 2008.
[74] S. Kidera, T. Sakamoto, T. Sato, Experimental study of shadow region imaging algorithm with multiple
scattered waves for UWB radars, Prog. Electromagn. Res. 5 (4) (2009) 393–296.
[75] G. Alli, D. DiFilippo, Beamforming for through-the-wall radar imaging, in: M.G. Amin (Ed.), Through-the-
Wall Radar Imaging, CRC Press, Boca Raton, FL, 2010, pp. 81–120.
[76] M.G. Amin, F. Ahmad, Wideband synthetic aperture beamforming for through-the-wall imaging, IEEE
Signal Process. Mag. 25 (4) (2008) 110–113.
[77] P. Setlur, M.G. Amin, F. Ahmad, Multipath model and exploitation in through-the-wall and urban radar
sensing, IEEE Trans. Geosci. Remote Sens. 49 (10) (2011) 4021–4034.
[78] Y.-S. Yoon, M.G. Amin, High-resolution through-the-wall radar imaging using beamspace MUSIC, IEEE
Trans. Antenn. Propag. 56 (6) (2008) 1763–1774.
[79] G. Wang, M.G. Amin, Y. Zhang, A new approach for target locations in the presence of wall ambiguity,
IEEE Trans. Aerosp. and Electron. Syst. 42 (1) (2006) 301–315.
[80] M.G. Amin (Ed.), Through-the-Wall Radar Imaging, CRC Press, Boca Raton, FL, 2010.
[81] C.P. Lai, R.M. Narayanan, Through-wall imaging and characterization of human activity using ultrawideband
(UWB) random noiseradar, in: Proceedings of theSPIE Sensors andC3I Technologies for HomelandSecurity
and Homeland Defense, Orlando, FL, May 2005, vol. 5778, 2005, pp. 186–195.
[82] A. Martone, K. Ranney, R. Innocenti, Through-the-wall detection of slow-moving personnel, in: Proceedings
of the SPIERadar Sensor Technology XIII, Orlando, FL, April 13–17, 2009, vol. 7308, 2009, pp. 73080Q1–
73080Q12.
[83] M. Skolnik, Introduction to Radar Systems, third ed., McGraw Hill, New York, 2001, p. 2001.
[84] R.M. Narayanan, M.C. Shastry, P.H. Chen, M. Levi, Through-the-wall detection of stationary human targets
using Doppler radar, Prog. Electromagn. Res. B 20 (2010) 147–166.
[85] I. Orovic, S. Stankovic, M. Amin, A new approach for classiﬁcation of human gait based on time-frequency
feature representations, Signal Process. 91 (6) (2011) 1448–1456.
[86] S.S. Ram, Y. Li, A. Lin, H. Ling, Doppler-based detection and tracking of humans in indoor environments,
J. Franklin Inst. 345 (6) (2008) 679–699.
[87] D. Tahmoush, J. Silvious, Stride rate in radar micro-doppler images, in: Proceedings of the IEEE Inter-
national Conference on Systems, Man, and Cybernetics, San Antonio, TX, October 11–14, 2009, 2009,
pp. 4218–4223.
[88] K. Ranney et al. Recent MTI experiments using ARL’s synchronous impulse reconstruction (SIRE) radar,
in: Proceedings of the SPIE—Radar Sensor Technology XII, Orlando, FL, April 2008, vol. 6947, 2008,
pp. 694708-1–694708-9.
[89] J. Moulton, S.A. Kassam, F. Ahmad, M.G. Amin, K. Yemelyanov, Target and change detection in synthetic
aperture radar sensing of urban structures, in: Proceedings of the IEEE Radar Conference, Rome, Italy, May
26–30, 2008.
[90] F. Soldovieri, R. Solimene, R. Pierri, A simple strategy to detect changes in through the wall imaging, Prog.
Electromagn. Res. M7 (2009) 1–13.
[91] A.R. Hunt, Use of a frequency-hopping radar for imaging and motion detection through walls, IEEE Trans.
Geosci. Remote Sens. 47 (5) (2009) 1402–1408.

References
909
[92] Y.D. Zhang, A. Hunt, Image and localization of behind-the-wall targets using collocated and distributed
apertures, in: M.G. Amin (Ed.), Through-the-Wall Radar Imaging, CRC Press, Boca Raton, FL, 2010,
pp. 121–156 (Chapter 4).
[93] N. Maaref, P. Millot, C. Pichot, O. Picon, A study of UWB FM-CW Radar for the detection of human beings
in motion inside a building, IEEE Trans. Geosci. Remote Sens. 47 (5) (2009) 1297–1300.
[94] F. Ahmad (Ed.), Compressive Sensing, in: Proceedings of SPIE, vol. 8365, SPIE, Bellingham, WA, 2012.
[95] E. Candes, J. Romberg, T. Tao, Stable signal recovery from incomplete and inaccurate measurements, Com-
mun. Pure Appl. Math. 59 (2006) 1207–1223.
[96] A. Gurbuz, J. McClellan, W. Scott, A compressive sensing data acquisition and imaging method for stepped
frequency GPR, IEEE Trans. Signal Process. 57 (7) (2009) 2640–2650.
[97] Y.-S. Yoon, M.G. Amin, Compressed sensing technique for high-resolution radar imaging, in: Proceedings
of the SPIE, Orlando, FL, April 2008, vol. 6968, 2008, pp. 69681A-1–69681A-10.
[98] D. Donoho, M. Elad, V. Temlyakov, Stable recovery of sparse overcomplete representations in the presence
of noise, IEEE Trans. Inform. Theory 52 (1) (2006) 6–18.
[99] F. Ahmad, M. Amin, Compressive urban sensing, SPIE Newsroom, Published Online: 27 September 2012,
http://dx.doi.org/10.1117/2.1201209.004413, <http://spie.org/x90448.xml>, 2012.
[100] G. Wang, M.G. Amin, Imaging through unknown walls using different standoff distances, IEEE Trans. Signal
Process. 54 (10) (2006) 4015–4025.
[101] A. Martone, K. Ranney, R. Innocenti, Automatic through the wall detection of moving targets using low-
frequency ultra-wideband radar, in: Proceedings of the IEEE International Radar Conference, Washington
D.C., May 2010, 2010, pp. 39–43.
[102] L.C. Potter, E. Ertin, J.T. Parker, M. Cetin, Sparsity and compressed sensing in radar imaging, Proc. IEEE
98 (6) (2010) 1006–1020.
[103] Q. Huang, L. Qu, B. Wu, G. Fang, UWB through-wall imaging based on compressive sensing, IEEE Trans.
Geosci. Remote Sens. 48 (3) (2010) 1408–1415.
[104] P. Boufounos, M.F. Duarte, R.G. Baraniuk, Sparse signal reconstruction from noisy compressive mea-
surements using cross-validation, in: Proceedings of the 2007 IEEE 14th Workshop on Statistical Signal
Processing, 2007.
[105] M. Farwell et al., Sense through the wall system development and design considerations, J. Franklin Inst.
345 (6) (2008) 570–591.
[106] M. Pieraccini, G. Luzi, D. Dei, L. Pieri, C. Atzeni, Detection of breathing and heartbeat through snow using
a microwave transceiver, IEEE Geosci. Remote Sens. Lett. 5 (1) (2008) 57–59.
[107] E. Ertin, R.L. Moses, Through-the-wall SAR attributed scattering center feature estimation, IEEE Trans.
Geosci. Remote Sens. 47 (5) (2009) 1338–1348.

18
CHAPTER
Multi-Channel SAR for Ground
Moving Target Indication
Stefan V. Baumgartner and Gerhard Krieger
German Aerospace Center (DLR), Microwaves and Radar Institute, Oberpfaffenhofen, Germany
Nomenclature
∗
complex conjugated
a
acceleration magnitude of the target (m/s2)
Ai
complex coefﬁcient containing free-space attenuation, backscattering coefﬁcient, and
two-way antenna pattern weighting
ax
along-track acceleration (m/s2)
ay
across-track acceleration (m/s2)
BC
bandwidth of the clutter Doppler spectrum (Hz)
Br
bandwidth of the transmitted pulse (Hz)
c
clutter vector in time domain
C
clutter in Doppler domain
c0
speed of light in vacuum (m/s)
d
multi-channel steering vector
da
physical along-track antenna separation (m)
dpc
effective along-track phase center separation (m)
fa
Doppler or azimuth frequency (Hz)
fC(x)
probability density function of cluster-plus-noise
fDC
Doppler shift of the moving target signal (Hz)
fDC,st
Doppler shift of the stationary target signal (Hz)
fT(x)
probability density function of target-plus-noise
H
reference function or matched ﬁlter in frequency domain
H
vector complex conjugate transposition; Hermitian transpose
h
reference function or matched ﬁlter in time domain
ha
azimuth reference function of the matched ﬁlter in time domain
Ha
azimuth reference function of the matched ﬁlter in Doppler domain
ha,st
azimuth reference function for a stationary signal in time domain
hr
range reference function in time domain
I
compressed signal or impulse response function (IRF)
j
imaginary unit
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-396500-4.00018-1
© 2014 Elsevier Ltd. All rights reserved.
911

912
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
K
total number of training cells
k
training cell number/index
ka
Doppler slope of the moving target signal (Hz/s)
ka,st
Doppler slope of the stationary world matched ﬁlter or stationary signal (Hz/s)
kr
slope of the range chirp in range-frequency domain (Hz/s)
kφ
slope of the unregistered ATI phase in time domain (rad/s)
L
antenna length or height (m)
La
antenna length in azimuth direction (m)
LSA
length of the synthetic aperture (m)
m
receiving channel number/ index
M
total number of receiving channels
mc
constant for scaling purposes
n
noise vector
n
temporal sample number/index
N
integer number or total number of azimuth samples
N
Noise in Doppler domain
Pd
probability of detection
Pfa
probability of false alarm; false alarm rate
PRF
pulse repetition frequency (Hz)
PRFmin,3 dB
minimum required pulse repetition frequency (Hz)
q
quadratic Doppler coefﬁcient (Hz/s2)
Q
multi-channel signal interference (= clutter + noise) in Doppler domain
r
range or slant range (m)
r0
minimum range (m)
r10
range at time t = 0 (m)
rect[.]
rectangular function
rp
position vector of the antenna phase center in Cartesian {x, y, z} coordinate system
(m)
RW
clutter covariance matrix
rst
range to a stationary target (m)
rt
position vector of the target in Cartesian {x,y,z} coordinate system (m)
s
azimuth signal in baseband
s
multi-channel signal vector of dimension M N × 1 (M = number of antennas, N =
number of temporal samples)
S
multi-channel signal matrix of dimension M × N (M = number of antennas, N =
number of temporal samples
sATI
ATI signal
sDPCA
DPCA signal
si
azimuth signal in baseband received by channel i
si,reg
co-registered or aligned baseband signal received by channel i
Skϕ
phase ramp in Doppler; needed for co-registration
sRX
received signal
sRX,b
received signal in baseband
sTX
transmitted pulse or waveform

Nomenclature
913
sTX,b
transmitted pulse or waveform in baseband
t
azimuth or slow time (s)
T
sample interval, T = 1/PRF (s)
T
vector or matrix transposition
tFr
fractional time of fractional Fourier transform
TSA
synthetic aperture time (s)
U
input signal in frequency domain
u
input signal
ut
directional cosine; measured fom the azimuth-axis (x-axis
v0
velocity magnitude of the target at t = 0 (m/s)
vx0
along-track velocity of the target at t = 0 (m/s)
vy0
across-track velocity of the target at t = 0 (m/s)
vp
platform velocity (m/s)
vr0
line-of-sight velocity (m/s)
vr0,blind
line-of-sight blind velocity (m/s)
vr0,max
maximum line-of-sight velocity (m/s)
w
weight vector
wr
envelope of the pulse
x
x-axis, along-track or azimuth direction (m)
x0
along-track position of the target at time t = 0 (m)
xt
azimuth or along-track position of the target (m)
y
y-axis or across-track direction (m)
yout
signal after ﬁltering
y0
across-track position of the target at time t = 0 (m)
yp
across-track position of the platform (m)
yt
across-track position of the target (m)
z
z-axis or altitude (m)
z
space-time snapshot of the noise and clutter contaminated multi-channel signal
Z
measured multi-channel signal in Doppler domain
z0
altitude of the target at time t = 0 (m)
z p
altitude of the platform (m)
zt
altitude of the target (m)
α
moving angle of the target or road angle (rad)
αFr
rotation angle of the fractional Fourier transform
αFr,opt
optimum rotation angle of the fractional Fourier transform giving the highest SCNR
 fa
Doppler bandwidth of the moving target signal (Hz)
r
residual range cell migration (m)
rblur
spread of the blur in range direction (m)
t
time difference corresponding to along-track baseline (s)
timg,0
azimuth time corresponding to azimuth imaging position of signal (s)
timg,1
azimuth time corresponding to azimuth imaging position of ﬁrst ambiguity (s)
tshift
time difference relevant for co-registration (s)
x
along-track difference (m)

914
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
xblur
spread of the blur in azimuth direction (m)
ximg,0
along-track or azimuth displacement (m)
φ
ATI phase (rad)
δ3dB
spatial resolution given by the one-way 3 dB antenna beamwidth (m)
δa
azimuth resolution of the SAR image (m)
δr
range resolution of the SAR image (m)
δr(t)
range difference (m)
δϕ
phase error of aliased clutter signals (rad)
γSNR
complex correlation coefﬁcient
θ3 dB
one-way 3 dB antenna beamwidth (rad)
θ3 dB,a
one-way 3 dB antenna beamwidth in azimuth (rad)
θD
depression angle of the antenna (rad)
θi
incidence angle of the radar pulse (rad)
ϕa
phase of azimuth signal (rad)
ϕi
phase of azimuth signal of channel i (rad)
ϕi,reg
phase of co-registered azimuth signal of channel i (rad)
λ
radar wavelength (m)
σr0
standard deviation of the line-of-sight velocity (m/s)
σximg
standard deviation of the azimuth position (m)
σφ
standard deviation of the ATI phase (rad)
τ
“range time” or “fast time” (s)
τp
pulse duration (s)
ψ
squint angle (rad)
ψDOA
direction-of-arrival angle (rad)
2.18.1 Introduction
Moving target indication (MTI) originated in the military ﬁeld with the aim to detected approaching
sea and air targets. Originally, stationary radar stations with a rotating antenna installed on the earth’s
surface were used for this task. The signal processing was, at least from today’s point of view, quite
simple: the range measured by the traveling time of the transmitted and backscattered pulse, and the
information about the angular position of the radar antenna were used for determining the position of
the detected target. The achievable angular resolution was limited by the antenna beamwidth. For plane
antennas the one-way 3 dB beamwidth is given as [1]
θ3dB ∼= 0.886 · λ
L ,
(18.1)
where λ is the radar wavelength and L the antenna length or height, depending if the beamwidth in
azimuth or elevation shall be computed. It is obvious that a longer antenna has a smaller beamwidth
which results in an improved spatial resolution
δθ3dB ∼= θ3dB · r = 0.886 · λ
L · r,
(18.2)

2.18.1 Introduction
915
L
r
resolution cell
3dB
r
Short antenna
3dB
antenna beam
Long antenna
L
r
resolution cell
3dB
r
3dB
antenna beam
FIGURE 18.1
Inﬂuence of the antenna length L on the beamwidth θ3dB and on the achievable spatial resolution δθ3dB.
where r is the distance or range between the antenna phase center and the target. The relationships given
in (18.1) and (18.2) are visualized in Figure 18.1. From the spatial resolution point of view large antennas
are preferred for classical MTI. The achievable range resolution δr is determined by the transmitted
pulse waveform. It is independent of the beamwidth and discussed later in Section 2.18.2.3.
With more modern pulse Doppler MTI radars the Doppler shifts of the backscattered target signals
were exploited for deciding if a target was moving or not (the signal backscattered from a moving target
in contrast to a stationary target is shifted in Doppler due to its range change during the illumination
time). For suppressing unwanted radar echos (= clutter) backscattered from stationary or slowly moving
unwanted targets (buildings, hills, trees, sea, rain, etc.) a notch around zero Doppler frequency or more
sophisticated Doppler ﬁlter banks were used [2].
In the context with ﬂying radar platforms additionally to MTI the notation GMTI can be found in the
literature. GMTI stands for “ground moving target indication” and is strictly speaking a special case of
MTI. GMTI focuses on targets moving on the earth’s surface (land and ocean).
The implementation of GMTI capabilities to radars ﬂying at high altitude is more sophisticated since
the platform carrying the radar system moves by itself. This motion causes a spread of the clutter Doppler
spectrum so that especially signals backscattered from slowly moving targets are masked and, hence,
cannot be detected. For side-looking radars where the antenna beam points perpendicular to the ﬂight
direction the bandwidth of the unwanted clutter Doppler spectrum (in the following denoted as clutter
bandwidth BC) is proportional to the platform velocity as well as to the azimuth antenna beamwidth
θ3dB,a [1]:
BC ∼= θ3dB,a · 2vp
λ
= 0.886 · 2vp
La
,
(18.3)
where La is the length of a ﬂat antenna in azimuth or ﬂight direction and vp is the velocity of the radar
platform. Since the velocity vp of a given platform is more or less ﬁxed, at the beginning for GMTI

916
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
large stabilised antennas (i.e., large antenna lengths La) with narrow beams and low sidelobe levels
were used to narrow down the clutter bandwidth. Thus, in the classical single-channel GMTI case where
only one antenna is available, the GMTI detection performance is mainly limited by the antenna length.
Single-channel GMTI is restricted either to fast moving targets whose Doppler shifted signals lie outside
the clutter bandwidth, or to targets with high reﬂectivity or radar cross section (RCS), resulting in high
signal-to-clutter-plus-noise ratios (SCNRs) so that even a velocity independent detection is possible [4].
In contrast to pure GMTI systems air- and spaceborne synthetic aperture radar (SAR) systems were
primarily developed for imaging the stationary world but not for detecting moving targets [1]. To achieve
high resolution with a SAR system a long illumination time and, hence, a small antenna with a wide
azimuth beam is required. The best achievable azimuth resolution of a SAR system operated in the so
called stripmap mode is given as
δa ∼= La
2 .
(18.4)
The resolution is independent of the range (that’s one of the reasons why with spaceborne SAR systems
high resolution can be achieved). The smaller the azimuth antenna length La, the better is the resolution.
However, just this requirement is in contradiction with the need for large antennas and narrow beams for
classical single-channel GMTI (remember that the shorter the antenna, the larger the clutter bandwidth
given in (18.3) and the worse the detection capability of slowly moving targets embedded in the clutter).
The desired signal for SAR imaging, i.e., the radar echos from the stationary non-moving scene which
shall be imaged, can be considered as unwanted clutter for GMTI.
Owing to the nature of conventional SAR processing moving targets in general are depicted blurred
and displaced from their actual positions [5]. The reason is the additional Doppler shift of moving
target signals. Two examples are shown in Figure 18.2 where a slowly moving ship and a moving
train are imaged. The so called “ship-of-the-wake” or “train-of-the-track” effects (i.e., the azimuth
displacements of the targets) can clearly be recognized. The magnitude of the displacement depends
on the target velocity. If for instance a typical imaging geometry of the German TerraSAR-X satellite
[6] ﬂying at an altitude of 514 km is considered, a comparatively slowly moving ship with a velocity
of 30 km/h is displaced up to 600 m. The displacement of fast road vehicles traveling with 130 km/h
v0 … Velocity
Δx … Azimuth
Displacement
Δx
Train
Track
FIGURE 18.2
TerraSAR-X images of a moving ship in the Strait of Gibraltar (left) and a moving train near Wolgograd, Russia
(right). The azimuth displacements can clearly be recognized.

2.18.1 Introduction
917
may be already in the order of 2500 m. A suitable GMTI algorithm should not only be able to detect
the “displaced” moving targets, but also to estimate their true (non-displaced) geographical positions,
their velocities and moving directions.
For adding GMTI capabilities to SAR systems without preventing high resolution imaging appro-
priate techniques for suppressing the clutter are necessary. This can be achieved by implementing more
than one receiving antenna or receiving channel. The signals received by multiple antennas, which are
arranged in ﬂight direction and which are separated by a certain baseline, can be combined in different
ways: once for suppressing the clutter and so enabling the detection of even slowly moving targets, and
once for estimating the motion and position parameters of the targets.
The question how many receiving antennas are needed can brieﬂy be answered: for suppressing the
clutter at least two receiving antennas separated by a certain baseline in azimuth or ﬂight direction are
necessary. A third antenna allows for a more robust estimation of the moving target’s true position and
motion parameters. Additional antennas incorporate further degrees of freedom which for instance can
be used for suppressing jammers [7]. This may be of importance for military applications. However,
more than three antennas not necessarily improve the detection and parameter estimation performance
signiﬁcantly [8].
Today, GMTI is no longer limited to military applications. A SAR-GMTI system ﬂying at high
altitude can also be used for civilian wide area trafﬁc monitoring, which has evolved into an important
research topic during the last years [9–12]. Real-time trafﬁc monitoring data for instance are used by
trafﬁc monitoring centers for ensuring the mobility and safety of the road users. Nowadays these data
are mainly collected operationally from stationary sensors mounted along the major roads. Outside
of these roads still a severe data lack exists, which even in short-term cannot fully be stuffed by the
additional use of ﬂoating car data [13] and signaling information generated by the phone network.
However, SAR-GMTI systems might be used in near future to ﬁll these information gaps, especially if
the information is required on a non-regular basis as in the case of major events and catastrophes.
Modern SAR-GMTI systems are expected to have at least the following capabilities:
•
Detection of even slowly moving targets with low reﬂectivity (low RCS) against a strong clutter
interference.
•
Estimation of the moving targets’ true geographical positions.
•
Estimation of the moving targets’ velocities and driving directions.
Furthermore, especially for military applications, it may also be required to
•
Have real-time capability.
•
Track the moving targets during the (increased) observation time.
•
Refocus the “blurred” images of extended moving targets (an extended target is a target occupy-
ing more than one SAR resolution cell) like ships and larger land vehicles to high resolution for
recognition purposes.
It has to be pointed out here that the latter three points will not be treated in this tutorial. Information
about target tracking can e.g., be found in [14]. Refocusing of extended moving targets can be performed
with inverse SAR (ISAR) imaging techniques. Adequate information and references can be found in
[15–17] and also in the ISAR chapter of the ELSEVIER e-reference.

918
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
Principally two groups of multi-channel GMTI algorithms can be discriminated. The ﬁrst group is
based on the classical dual-channel techniques along-track interferometry (ATI) and displaced phase
center antenna (DPCA). State-of-the-art spaceborne SAR systems limited to two physical receiving
(RX) channels such as the German TerraSAR-X [6] and the Canadian RADARSAT-2 apply these
GMTI techniques successfully. Thus, a special focus on these classical techniques is given in this
tutorial. The second group is based on space-time adaptive processing (STAP) techniques for which
a separate tutorial/chapter can be found in the ELSEVIER e-reference. For that reason only a short
introduction to STAP is given in Sections 2.18.6.2.2 and 2.18.8.
For understanding the following sections of the tutorial the reader shall be familiar with the basic
principles of SAR imaging. Good extended tutorials on SAR can for instance be found in [1] and in
the SAR chapter of the ELSEVIER e-reference. As mathematical background mainly linear algebra
(vectors and matrices), the understanding of the convolution and the Fourier transform and its inverse
are required.
The remainder of this tutorial is organized as follows: in Section 2.18.2 the SAR principle is
explained before in Section 2.18.3 the moving target single- and multi-channel signal model is derived.
The effects caused by moving target signals are discussed in Section 2.18.4. They are fundamental
for understanding the parameter estimation principles discussed afterwards. The classical dual-channel
techniques are presented in detail in Section 2.18.5. In Section 2.18.6 the general GMTI processing
chain is discussed and in Section 2.18.7 the basic Doppler parameter estimation methods are intro-
duced. A short introduction to STAP is given in Section 2.18.8 before the tutorial is concluded with
Section 2.18.9.
2.18.2 Synthetic aperture radar principle
For the following investigations a ﬂat earth surface and a straight ﬂight path of the SAR platform parallel
to the earth surface are assumed. Although SAR and GMTI are not restricted to these assumptions (e.g.,
for spaceborne SAR-GMTI curved orbits have to be considered [18]), the explanations and equations
given in the tutorial can be simpliﬁed to a certain degree and presented in a way better understandable
by the interested reader who is not a SAR expert.
2.18.2.1 SAR acquisition geometry and operation
A SAR instrument consists of a pulsed transmitter, at least of one antenna which is used both for
transmitting and receiving, and of a phase coherent receiver [1]. The typical side-looking imaging
geometry of a SAR system is shown in Figure 18.3.
The platform carrying the radar instrument moves at constant altitude with constant velocity vp
parallel to the x-axis. The moving direction of the radar is also denoted as along-track or azimuth
direction. The antenna is mounted in a way so that the antenna beam with a certain depression angle
θD points perpendicular to the azimuth direction towards the ground (the system in Figure 18.3 is left-
looking with respect to the ﬂight path). An area on ground with a certain swath width is illuminated
by the beam. The radar is periodically emitting radar pulses of duration τp with the so called Pulse
Repetition Frequency (PRF). The PRF typically is in the order of several 100 Hz (airborne systems)
to several 1000 Hz (spaceborne systems). The pulses are backscattered from the illuminated area on

2.18.2 Synthetic Aperture Radar Principle
919
y
x
z
antenna
illuminated
area
stationary
point target
antenna beam
z
y
h
swath
width
antenna
D
D … depression angle
i … incidence angle
r … slant-range
x … along-track, azimuth
y … across-track, ground-range
z … altitude
r
i
swath
pulse
FIGURE 18.3
SAR acquisition geometry.
ground, coherently received, down converted, digitized and stored in the mass memory of the SAR
instrument. SAR processing is carried out afterwards, either onboard the platform or on ground after
downloading the data.
What the SAR measures are the backscattered signal energy and the time interval between the emitted
and received pulses. The pulse travel time is proportional to the two-way range, i.e., the range from
the antenna phase center to the target and back. A side-looking geometry is necessary so that for each
measured slant range r the corresponding ground range or across-track position y can be computed
unambiguously (cf. Figure 18.3).
The SAR principle is based on a movement of the sensor with respect to the illuminated targets on
ground. Due to the motion of the platform the range r between the platform and a speciﬁc stationary
point target on ground changes as shown in Figure 18.4. This range change causes a Doppler frequency
shift of the received signal which during SAR processing is exploited for synthesizing a large antenna
along azimuth direction, resulting in a narrow synthetic azimuth beam width and, hence, in high azimuth
resolution.
Due to the importance for GMTI processing discussed later, in the following the range and Doppler
histories of the signal backscattered from a particular non-moving point target are derived.
The position of the antenna phase center located at the moving SAR platform with respect to the
origin of the Cartesian {x, y, z} coordinate system can be written as (see also sketch in Figure 18.5)
rp(t) =
⎡
⎢⎣
xp(t)
yp
zp
⎤
⎥⎦=
⎡
⎢⎣
vp t
0
zp
⎤
⎥⎦,
(18.5)

920
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
azimuth x
range r
azimuth x
Doppler frequency fa
stationary
target
stationary
target
r0
r(x)
ka
FIGURE 18.4
Range (top) and Doppler frequency history (bottom) of a stationary point target.
y
x
z
antenna
0
rt
stationary point target
rp
rt - rp
FIGURE 18.5
SAR acquisition geometry with point target and platform position vectors rt and rp.
where vp is the constant platform velocity and t the time. At time t = 0 the platform is at altitude
zp above the origin of the Cartesian coordinate system. Let now the position of a certain non-moving
“stationary” target be

2.18.2 Synthetic Aperture Radar Principle
921
rt(t) =
⎡
⎣
xt
yt
zt
⎤
⎦=
⎡
⎣
x0
y0
z0
⎤
⎦.
(18.6)
The indices “0” indicate time independent parameters. The distance between the antenna and the target
can simply be computed as
r(t) = ∥rt −rp∥=

(xt −xp)2 + (yt −yp)2 + (zt −zp)2,
(18.7)
where ∥·∥denotes the L2 norm. For describing the SAR principle in common literature it is often
assumed, without restriction of generality, that xt = x0 = 0 so that at t = 0 the point target is broadside
the SAR platform. The minimum range r0 at t = 0 in this case can be written as
r0 =

y2
0 + (zt −zp)2,
(18.8)
so that (18.7) simpliﬁes to
r(t) =

r2
0 + x2p =

r2
0 + (vpt)2 ∼= r0 +
v2
p
2r0
t2.
(18.9)
The quadratic approximation given after the “∼=” sign is obtained by a second-order Taylor expansion
about t = 0. The time t is proportional to the azimuth position of the platform xp:
t = xp
vp
.
(18.10)
2.18.2.2 Stationary point target signal model
One single pulse transmitted by the SAR system can be expressed as
sTX(τ) = sTX,b(τ) · exp
	
j2π
λ c0τ

,
(18.11)
where sTX,b(τ) represents the pulse waveform in baseband, τ is the so called “fast time,” j is the
imaginary unit, λ is the radar wavelength given by the carrier frequency and c0 denotes the speed of
light in vacuum. Conventionally in SAR a linear frequency modulated (LFM) waveform, a so called
“range chirp,” with a certain bandwidth Br and a certain duration τp (in the order of microseconds) is
transmitted (although SAR is not limited to such waveforms). The range chirp in baseband is given as
sTX,b(τ) = wr(τ) · exp
	
jπ Br
τp
τ 2

= wr(τ) · exp[jπkrτ 2],
(18.12)
where kr denotes the chirp slope and wr the envelope. The signal received from a point-like target is
then a delayed and attenuated copy of the transmitted signal which can be written as
sRX(τ) = A · sTX

τ −2r(τ)
c0

.
(18.13)

922
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
The free-space attenuation, the backscattering coefﬁcient, the elevation and the azimuth angles to the
target as well as the weighting of the two-way antenna pattern are covered by the coefﬁcient A. After
coherent down-conversion to baseband using, e.g., a phase preserving quadrature demodulator, the
received signal is given as
sRX,b(τ) = A · sTX

τ −2r(τ)
c0

· exp
⎡
⎢⎢⎣−j 2π
λ 2r(τ)



=−ϕa(τ)
⎤
⎥⎥⎦.
(18.14)
This signal can be separated into two parts:
1. The transmitted and delayed waveform sTX whose delay is given by the two-way path 2 r(τ) between
the antenna and the target.
2. An exponential term with phase ϕa representing the azimuth modulation of the signal, which is
independent of the transmitted waveform.
The raw data signal given in (18.14) in its one-dimensional representation is in fact stored in a
two-dimensional arrangement in the mass memory of the radar system according to the range and
azimuth dimension. To get a better insight in this storage procedure one can make use of the start-stop-
approximation. It assumes that the antenna and, hence, the SAR platform is motionless when a pulse is
emitted and the scattered signal received. Afterwards the antenna moves to its next sending/receiving
position along the ﬂight track. This approximation can be made since the pulse travel time is much
smaller than the time needed for the antenna to move to the next position. In range dimension the
signal is sampled when the antenna is “motionless.” The range sampling frequency is determined by
the analog-digital converter. For a complex signal this sampling frequency has to be at least as large as
the chirp bandwidth Br so that the Nyquist criterion is not violated. In azimuth dimension the sampling
frequency and, hence, the imaginary antenna “stops” are determined by the PRF.
The signal can therefore be written in a two-dimensional form as
sRX,b(τ, t) = A · sTX

τ −2r(τ)
c0

· exp
	
j4π
λ r(t)

,
(18.15)
where τ is the “fast time” representing the range direction and t is the “slow time” representing the
azimuth direction.
Due to the importance for GMTI we will put the main focus on the azimuth signal
s(t) = A · exp
	
−j4π
λ r(t)

· rect
	 t
TSA

= A · exp[jϕa(t)] · rect
	 t
TSA

,
(18.16)
where the rectangular function rect[.], deﬁned e.g., in [3], is introduced for pointing out that the signal
duration is limited by the illumination time TSA given by the azimuth beamwidth of the antenna pattern.
A small azimuth antenna length results in a wide beam (see also (18.1) and long illumination or synthetic
aperture time, respectively. For typical airborne systems this time is in the order of several seconds, for

2.18.2 Synthetic Aperture Radar Principle
923
state-of-the-art spaceborne systems around one second or smaller. The longer this time, the better is the
achievable azimuth resolution after SAR processing.
The phase ϕa within the exponential term can according to (18.9) also be approximated using a
second-order Taylor expansion, so that
ϕa(t) = −4π
λ r(t) ∼= −4π
λ

r0 +
v2
p
2r0
t2

.
(18.17)
The azimuth phase modulation furthermore can be interpreted as azimuth frequency or Doppler fre-
quency variation fa if the time derivative is taken in the following way:
fa(t) = 1
2π · ∂ϕa(t)
∂t
.
(18.18)
If for the phase ϕa the quadratic approximation given in the second part of (18.17) is inserted, the linear
approximation of the Doppler frequency history is obtained:
fa(t) ∼= −
2v2
p
λr0
t = ka,stt.
(18.19)
It is obvious that the azimuth signal in the ﬁrst approximation has the shape of a LFM signal with ka,st
denoting the signal’s azimuth chirp slope or Doppler slope (see also Figure 18.4 bottom).
2.18.2.3 Pulse compression and image formation
As mentioned in the previous section, the transmitted pulse typically has a time duration in the order of
a few microseconds, whereas the illumination time of a particular point target is in the order of seconds.
Thus, for achieving a high range and azimuth resolution pulse compression has to be employed. Pulse
compression generally can be performed by convolving an uncompressed input signal u(t) with a proper
reference function h(t). The pulse compressed signal I(t) in its general form is then given as
I(t) = u(t) ∗h(t) =
 +∞
−∞
u(τ)h(t −τ)dτ,
(18.20)
where ∗denotes convolution.
The optimal ﬁlter theory says that for signals embedded in white Gaussian noise the best signal-to-
noise ratio (SNR) after convolution is achieved if the reference function h(t) is the complex conjugated
and time reverted version of the “expected” input signal u(t):
h(t) = mc · u∗(−t),
(18.21)
where mc is a constant which may be used for scaling purposes and ∗denotes the complex conjugation. If
the reference function is constructed in this way, it is denoted as “Matched Filter” [19]. The resolution
improvement by applying a matched ﬁlter is sketched in Figure 18.6. The comparatively long input
signal u(t) after matched ﬁltering is compressed to a pulse I(t) of short duration. The time resolution
and, hence, the spatial resolution is signiﬁcantly improved compared to the input signal.

924
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
Matched Filter
h(t)
u(t)
I(t)
FIGURE 18.6
Pulse compression with a matched ﬁlter.
azimuth
range
raw data
azimuth
range
range compressed
azimuth
range
RCMC data
azimuth
range
azimuth compressed
FIGURE 18.7
Simpliﬁed SAR processing steps for a single non-moving point target.
It is known that a cyclic convolution in time domain corresponds to a simple multiplication in
frequency domain. For that reason the convolution in (18.20) can equivalently be written as
I(t) = u(t) ∗h(t) = F−1{F{u(t)} · F{h(t)}} = F−1{U( f ) · H( f )},
(18.22)
where F and F−1 denote the Fourier and inverse Fourier transforms, respectively, and U( f ) and H( f )
are the frequency domain representations of u(t) and h(t), respectively.
SAR processing or SAR image formation, within the GMTI community often denoted as “Stationary
World Matched Filtering,” can be described brieﬂy by the following three steps:
1. Range compression: A pulse compression along range dimension is performed. For the range chirp
in (18.12) the reference function is
hr(t) = exp[−jπkrt2].
(18.23)
2. Range cell migration correction (RCMC): The curvature of the range history is eliminated (see third
image from left in Figure 18.7).
3. Azimuth compression: A pulse compression along azimuth is performed. For the azimuth signal in
(18.16) the reference function is
ha,st(t) = exp
	
j4π
λ r(−t)

∼= exp

−jπka,stt2
,
(18.24)
where the approximation after the “∼=” sign is obtained by inserting the Taylor expansion from (18.17)
into (18.16), substituting ka,st = (−2v2
p)/(λr0) and dropping the constant phase term (−4π/λ)r0
which is unimportant for pulse compression.

2.18.3 Moving Point Target Signal Model
925
FIGURE 18.8
Impulse response function of a stationary point target (left: cut along azimuth direction; middle: two-
dimensional representation; right: three-dimensional representation; system parameters: vp = 7300 m/s,
y0 = 514 km, r10 = 726.9 km, Br = 150 MHz, PRF = 3000 Hz, λ = 0.0311 m, TSA = 0.64 s).
After performing these three steps a focused SAR image is obtained. These steps are visualized for
a single point target in Figure 18.7. Details on state-of-the-art SAR processing algorithms and on the
RCMC can e.g., be found in [3,20].
The focused image of a single point target is also denoted as impulse response function (IRF). The
simulated IRF of a perfectly focused stationary point target is shown in Figure 18.8.
The IRF has the shape of a two-dimensional sinc function. The geometric resolution is determined
by the 3 dB width of the IRF. The best achievable azimuth resolution is given in (18.4). If as transmitted
waveform the LFM pulse given in (18.12) with a rectangular envelope wr is used, the best achievable
range resolution is [3]
δr ∼= c0
2Br
.
(18.25)
The larger the chirp bandwidth Br, the better is the range resolution.
Due to the nature of SAR processing, the IRF of any target (independent whether it is moving or not)
always is imaged at the position where the Doppler frequency of its uncompressed azimuth signal is
zero. For a stationary target this position corresponds to the minimum range r0 and to the actual azimuth
position xt. In contrast a moving point target, which is discussed in the next section, is displaced in
azimuth and to a little extend in range, depending on the motion parameters. For investigating the
displacements and additional effects the azimuth and range axis of the IRF plots shown in Figure 18.8,
and in some of the Figures provided later in Section 2.18.4, are labeled as azimuth shift and range shift,
respectively. The origins of the axes are centered around the positions xt and r0. This has the advantage
that the displacement quantities easily can be read off.
2.18.3 Moving point target signal model
The obvious difference between a stationary and a moving point target is the position on ground, which
varies over time depending on the target’s motion parameters. This time varying position difference

926
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
results in a change of the range and Doppler histories and furthermore in some peculiar effects observable
in the SAR images. For developing and understanding the fundamental moving target detection and
parameter estimation principles and algorithms discussed later, it is ﬁrst necessary to discuss suitable
moving point target signal models. In the next two sections a single-channel as well as a multi-channel
signal model are derived.
2.18.3.1 Single-channel signal model
In many of the publications related to GMTI a target in linear motion with constant acceleration during
the observation time is assumed. This is especially for short observation times a valid assumption.
Furthermore, it is assumed that the target does not change its altitude, i.e., that it does not move in
z-direction. This is reasonable since the slopes of common roads only may cause a z-velocity component
negligibly small compared to the large x- and y-components. The general acquisition geometry to
consider is similar to that sketched in Figure 18.5, apart from the “stationary point target” which has to
be replaced by a “moving point target.”
Under the afore mentioned assumption of linear motion the position of the moving point target (i.e.,
the motion equation) can in contrast to the stationary point target in (18.6) be written as
rt(t) =
⎡
⎣
xt(t)
yt(t)
zt
⎤
⎦=
⎡
⎢⎣
x0 + vx0t + 1
2axt2
y0 + vy0t + 1
2ayt2
z0
⎤
⎥⎦=
⎡
⎣
x0 + v0 cos α · t + 1
2a cos α · t2
y0 + v0 sin αt + 1
2a sin α · t2
z0
⎤
⎦,
(18.26)
where x0, y0, and z0 are the positions at t = 0, vx0 and vy0 are the along-track and across-track
velocity components at t = 0, and ax and ay are the constant along-track and across-track acceleration
components. If the target moves during the illumination time along a straight line its position can also
be expressed using the moving direction or road angle α and the velocity and acceleration magnitudes
v0 and a (see right part of (18.26)). In this case the velocity and acceleration magnitudes are given as
v0 =

v2
x0 + v2
y0 and a =

a2x + a2y. The moving direction α is measured counter-clockwise from the
x-axis towards the y-axis as depicted in Figure 18.9.
Even an acceleration change ˙a might be considered in the motion equations [21–23]. However,
changing accelerations are neglected in this tutorial. They only play a signiﬁcant role at long illumination
times in the order of several seconds and for ISAR imaging purposes.
The position vector of the platform is the same as in (18.5). The range history r(t) = ∥rt −rp∥of
the moving target can then be written as
r(t) =

x0 + vx0t + 1
2axt2 −vpt
2
+

y0 + vy0t + 1
2ayt2
2
+ (z0 + zp)2.
(18.27)
An analytical treatment of this expression is difﬁcult because of the square root. For investigating effects
on SAR imagery caused by moving targets it is appropriate to use the third-order Taylor expansion of
the range history about t = 0 which is given as

2.18.3 Moving Point Target Signal Model
927
vp
x
y
z
moving
target
(xt,yt,zt)
(xp,yp,zp)
vp
x
y
z
moving
target
(xt,yt,zt)
(xp,yp,zp)
(t)
FIGURE 18.9
Target moving along a straight road section (left: non-squinted acquisition geometry; right: squinted acqui-
sition geometry; the squint angle ψ(t) is measured from broadside direction in the slant range plane and its
positive counting direction is clockwise).
r(t) ∼= r10 + 1
r10

y0vy0 + x0(vx0 −vp)

t
+
1
2r10

x0ax + (vx0 −vp)2 + v2
y0 + y0ay −1
r2
10
[x0(vx0 −vp) + y0vy0]2

t2
+
1
2r10
⎧
⎪⎪⎨
⎪⎪⎩
ax(vx0 −vp) + vy0ay

1 −y2
0
r2
10

−x0
r2
10
(vx0 −vp)3

1 +
x0ax + y0ay + v2
y0
(vx0 −vp)2
 
−y0
r2
10
[x0ax + (vx0 −vp)2 + v2
y0]
⎫
⎪⎪⎬
⎪⎪⎭
t3,
(18.28)
where the terms in the order of 1/r4
10 have been dropped. The range between the antenna and the target
at t = 0 is represented by r10. In contrast to r0 in (18.8) the range r10 corresponds not to the range of
closest approach since now the target is in motion and in the most general case not located at broadside
position at t = 0 (i.e., x0 ̸= 0):
r10 =

x2
0 + y2
0 + (zt −zp)2.
(18.29)
With x0 ̸= 0 either a target track not centered in the azimuth beam or a squinted geometry as depicted
in Figure 18.9 on the right can be considered. The target position x0 at time t = 0 in this case can be

928
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
expressed in terms of the squint angle ψ of the antenna beam: x0 = r10 sin ψ. If the squint angle ψ is
zero the antenna points perpendicular to the ﬂight path so that x0 = 0. A squint angle is either caused
by a platform yaw due to crosswind or due to antenna beam steering. Typical squint angles caused by
platform yaw are in the order of a few degrees. Thus, the x0/r2
10 terms in (18.28) as well as the x0ax term
have no signiﬁcant contribution and therefore can be neglected. Also the y0/r2
10 term can be dropped
so that the range equation for the moving target simpliﬁes to
r(t) ∼= r10 + 1
r10
{y0vy0 + x0(vx0 −vp)}t
+
1
2r10

(vx0 −vp)2 + v2
y0

1 −y2
0
r2
10

+ y0ay

t2
+
1
2r10

ax(vx0 −vp) + vy0ay

1 −y2
0
r2
10

t3.
(18.30)
The azimuth phase of the moving target signal in the monostatic case (one common transmit (TX) and
receiving (RX) antenna) is given by ϕa = −4π
λ r(t). The third-order Taylor expansion of the moving
target’s Doppler frequency computed with (18.18) is then
fa ∼= −2
λr10
{y0vy0 + x0(vx0 −vp)}



fDC
−2
λr10

(vx0 −vp)2 + v2
y0

1 −y2
0
r2
10

+ y0ay




ka
t
−3
λr10

ax(vx0 −vp) + vy0ay

1 −y2
0
r2
10




q
t2
= fDC + kat + qt2,
(18.31)
where fDC denotes the Doppler shift, ka the Doppler slope and q the quadratic Doppler coefﬁcient.
By comparing (18.31) with (18.30) the approximated range history also can be expressed in terms
of Doppler parameters:
r(t) ∼= r10 −λ
2 fDCt −λ
4kat2 −λ
6qt3.
(18.32)
Using this range approximation the single-channel moving target azimuth signal can be written as
s(t) = A(t) · exp
	
−j4π
λ r(t)

· rect
	 t
TSA

∼= A(t) · exp
	
j

2π fDCt + πkat2 + 2
3πqt3

· rect
	 t
TSA

,
(18.33)
where the constant phase determined by r10 due to its unimportance has been dropped.

2.18.3 Moving Point Target Signal Model
929
DOA(t)
RX2
RX3
RX M
vp
TX/RX1
x
y
z
x(t)
(t)
da
da
FIGURE 18.10
Multi-channel SAR geometry with uniformly distributed antennas.
2.18.3.2 Multi-channel signal model
So far the range and Doppler histories of a moving target signal have been derived for the single-
channel (monostatic) case where a common antenna is used for both TX and RX of the radar pulses.
Now a system with M antennas is considered, where each antenna is separated from its neighbor in the
along-track direction by a certain along-track baseline da as depicted in Figure 18.10.
The ﬁrst antenna is used for TX and RX, antenna 2 and all others for receive only. Following the
derivation in [23] the ranges rm(t), m ∈{1, 2, . . . , M}, for da ≪r can be written as
r1(t) = r(t),
r2(t) ∼= r1(t) + δr(t),
rm(t) ∼= r1(t) + (m −1) · δr(t).
(18.34)
The range difference δr(t) is given by [24]
δr(t) = da cos ψDOA(t) = da
x(t)
r1(t)
(18.35)
∼= da
	 x0
r10
+ vx0 −vp
r10
t

,
where cos ψDOA = cos (π/2 −ψ) is the directional cosine measured from the x-axis. The expression
after the “∼=” sign is the result of a ﬁrst-order Taylor expansion. The multi-channel azimuth signals

930
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
corresponding to the ranges in (18.34) are then
s1(t) = A1(t) · exp
	
−j2π
λ 2r1(t)

· rect
	 t
TSA

,
s2(t) = A2(t) · exp
	
−j2π
λ (2r1(t) + δr(t))

· rect
	 t
TSA

,
sm(t) = Am(t) · exp
	
−j2π
λ (2r1(t) + (m −1) · δr(t))

· rect
	 t
TSA

.
(18.36)
For the classical GMTI techniques ATI and DPCA treated in Section 2.18.5, the multi-channel azimuth
signals in (18.36) need to be aligned or co-registered with the fore channel (=RX1) so that the antenna
phase centers are at the same spatial location at different times. Thus, a shift of the signals is necessary.
For co-registeringwiththesignal s1(t)thesignals2(t)needstobeshiftedbyt, andsm(t)by(m−1)·t.
For bistatic operation (only the fore antenna transmits, all others receive) the effective phase center
separation is dpc = da/2 so that the time difference can be written as
t = dpc
vp
= da
2vp
.
(18.37)
The co-registered signals are then (to keep the equations shorter the rect[.] functions have been
omitted in the following)
s2,reg(t) = A2(t + t) · exp
	
−j2π
λ (2r1(t + t) + δr(t + t))

,
sm,reg(t) = Am(t + (m −1) · t)
· exp
	
−j2π
λ (2r1(t + (m −1) · t) + (m −1) · δr(t + (m −1) · t))

.
(18.38)
It can be shown that the range difference δr(t + (m −1) · t) can be approximated as
δr(t + (m −1) · t) ∼= δr(t) + vx0 −vp
r10
da · (m −1) · t
(18.39)
and the range r1(t + (m −1) · t) also can be written as [24]
r1(t + (m −1) · t) ∼= r1(t) + h(t, t),
(18.40)
with
h(t, t) = −λ
2 fDC · (m −1) · t −λ
2ka · (m −1) · t ·
	
t + 1
2 · (m −1) · t

.
(18.41)
In practice all azimuth signals are sampled with a frequency given by the PRF. The sampling interval
corresponds to T = 1/PRF so that e.g., the time discrete representation of the signals in (18.36) can be
written as
sm[n] = sm(nT ),
−N
2 ≤n < N
2 −1, n ∈Z,
(18.42)

2.18.4 Effects on SAR Imagery
931
where N is the total number of azimuth samples. The received discrete azimuth signals (either un-
registered or co-registered) can also be collected in a data matrix given as
S =
⎛
⎜⎜⎜⎝
s1[n]
s2[n]
...
sM[n]
⎞
⎟⎟⎟⎠=
⎛
⎜⎜⎜⎝
s11
s12
· · ·
s1N
s21
s22
· · ·
s2N
...
...
· · ·
...
sM1
sM2
· · · sM N
⎞
⎟⎟⎟⎠,
∈CM×N,
(18.43)
where M is the total number of receiving channels. Vectorizing (18.42) by stacking each succeeding
column beneath the other yields
s = [s11, s21, . . . , sM1, . . . , s1N, . . . , sM N]T ,
∈CM N×1,
(18.44)
where T means vector transposition.
2.18.4 Effects on SAR imagery
The ﬁrst who has investigated the GMTI capabilities of SAR was Raney. In his fundamental paper from
1971 he already investigated the basic effects on SAR imagery caused by moving targets [5]. He found
that a target motion parallel to the ﬂight path of the radar results in a defocusing of the IRF and, hence,
in a decreased peak amplitude and in a decreased signal-to-clutter-plus-noise ratio (SCNR). A motion
perpendicular to the ﬂight path causes an azimuth displacement of the target image proportional to the
target’s across-track velocity. The understanding of these effects is fundamental for deriving appropriate
moving target motion and position parameter estimation methods.
In the following sections the range cell migration, the residual range cell migration and the major
effects caused by moving targets are discussed. As a starting point it is assumed that the signals are
already range compressed in a perfect manner.
2.18.4.1 Residual range cell migration
Depending on the motion parameters the range histories of a moving target (18.30) and a station-
ary target (18.7) located at the same position at t = 0 are quite different. Examples are shown in
Figure 18.11, where the range history of a moving target signal1 (red) is compared with that of a
stationary target (blue).
If the target travels in across-track direction with a certain across-track velocity vy0 the range history
is shifted in azimuth by t and in range by r (Figure 18.11, left). The curvature itself is not changed
signiﬁcantly.
When the target travels in along-track direction or accelerates in across-track direction
(Figure 18.11, right) the curvature is changed but the range history is not shifted. The range curva-
ture change is equivalent to a quadratic phase error which after conventional SAR processing results in
a blurred IRF.
1For interpretation of color in Figure 18.11, the reader is referred to the web version of this book.

932
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
TSA
r
t
vy0 > 0
t
vx0 > 0
ay < 0
t
r(t) – r10
r(t) – r10
FIGURE 18.11
Inﬂuence of some motion parameters on the range history (left: inﬂuence of across-track velocity; right:
inﬂuence of along-track velocity and across-track acceleration; the range history of the moving target signal
is depicted in red color and the circle marks the moving target position after SAR focusing). (For interpretation
of the references to color in this ﬁgure legend, the reader is referred to the web version of this book.)
A SAR processor performs a RCMC adapted only for stationary targets as depicted in the third
image from the left in Figure 18.7. This RCMC is conventionally performed in the frequency domain
[20]. For computing the residual range cell migration of the moving target signals it is necessary to
express the range history as a function of Doppler frequency. The relation between time and Doppler
frequency may be easily obtained from (18.31) if the quadratic Doppler coefﬁcient q is neglected (for
small illumination times the introduced error is negligibly small):
t = fa −fDC
ka
.
(18.45)
By inserting this relationship in (18.32) the quadratic approximation of the moving target range history
as a function of Doppler frequency is obtained:
r( fa) ∼= r10 + λ f 2
DC
4ka
−λ
4ka
f 2
a .
(18.46)
For a stationary target located at the same position as the moving target at time t = 0 the quadratic
approximation is
rst( fa) ∼= r10 +
λ f 2
DC,st
4ka,st
−
λ
4ka,st
f 2
a ∼= r0 −
λ
4ka,st
f 2
a ,
(18.47)
where fDC,st and ka,st are the Doppler parameters of the stationary target. These are obtained from
(18.31) by setting the motion parameters vx0, vy0, ax, and ay to zero so that
fDC,st = 2x0
λr10
vp
(18.48)
and
ka,st = −
2v2
p
λr10
.
(18.49)
For a non-squinted acquisition geometry fDC,st and, hence, x0 are zero.

2.18.4 Effects on SAR Imagery
933
Since the SAR processor only performs the RCMC correctly for stationary targets a residual range
cell migration r( fa) remains for moving target signals. Its quadratic approximation is given as
r( fa) = r( fa) −rst( fa) ∼= λ
4

f 2
DC
ka
−
f 2
DC,st
ka,st

+ λ
4
 1
ka,st
−1
ka

f 2
a
for | fa| ≤PRF
2 .
(18.50)
This expression is only valid for signals which are not aliased in Doppler. The residual range cell
migration is the reason why the IRF of the moving target also may be blurred in range direction after
azimuth compression. A detailed explanation on the range blur is given in Section 2.18.4.2.
An example for the residual range migration for an airborne system is shown in Figure 18.12.
The results show that for targets accelerating in along-track direction (Figure 18.12, third image
from the left) and for targets moving with constant velocity in across-track direction (second image
from the right) almost no residual range cell migration exists. Thus, the major part of the signal energy
is distributed along a single azimuth line. Such signals can easily be extracted from the range-compressed
and RCMC data array for parameter estimation purposes discussed later.
A couple of years ago the so called “Keystone Transform” has been introduced with the aim to remove
the linear range cell migration of the moving target signals, independent of their motion parameters
[25]. However, the ﬁnal result is the same as obtained by a conventional SAR processor based on chirp
scaling [20] with omitted azimuth compression: the linear range cell migration of moving target signals
is removed. Thus, if anyhow SAR processing is carried out the application of the Keystone transform
is not necessary.
If the Doppler parameters fDC and ka of a particular moving target signal are known (e.g., after
estimation using proper techniques) a RCMC adapted to this target can be performed. An example is
shown in Figure 18.13, where the same signals as for Figure 18.12 are used. In this case almost no
ax= 0.5 m/s²
vx0= 100 km/h
vy0= 50 km/h
vy0= 50 km/h
vx0= 100 km/h
stationary
ay= 0.5 m/s²
range
azimuth
FIGURE 18.12
Simulated range compressed data after conventional RCMC adapted for stationary targets (simulation param-
eters: vp = 90 m/s, h = |z0 −zp| = 2200 m, r10 = 3810 m, λ = 0.0312 m, PRF = 2500 Hz, Br =
100 MHz).

934
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
ax= 0.5 m/s²
vx0 = 100 km/h
vy0= 50 km/h
vy0= 50 km/h
vx0 = 100 km/h
ay= 0.5 m/s²
stationary
range
azimuth
FIGURE 18.13
Simulated range compressed data after RCMC adapted for each target’s Doppler parameters (simulation
parameters: vp = 90 m/s, h = |z0 −zp| = 2200 m, r10 = 3810 m, λ = 0.0312 m, PRF = 2500
Hz, Br = 100 MHz).
residual range cell migration for the moving target signal remains. However, each moving target signal
has different Doppler parameters and therefore requires the application of a different adapted RCMC
which requires high computational power.
With the proper moving target parameters additionally an adapted azimuth matched ﬁlter can be
constructed so that a perfectly focused moving target image is obtained [26].
2.18.4.2 Along-track velocity
Equation (18.31) can be used for investigating the effects on the Doppler history. The major effect
caused by the along-track velocity vx0 is a change of the Doppler slope ka with respect to the stationary
target as sketched in Figure 18.14. Here BC is the clutter bandwidth and TSA is the illumination time.
The Doppler slope change is equivalent to a change of the quadratic part of the range history. After
azimuth compression using the SWMF with Doppler slope ka,st the mismatch ka,st −ka corresponds
to a quadratic phase error in time domain. The IRF of the moving target is therefore defocused in the
azimuth direction as shown in Figure 18.15. Unfortunately no analytical description of the defocused
IRF exists.
The spread of the blur in azimuth direction can be approximated as
xblur ∼=
****1 −ka
ka,st
**** · TSAvp =
********
1 −
(vx0 −vp)2 + v2
y0

1 −y2
0
r2
10

+ y0ay
v2p
********
· TSAvp.
(18.51)

2.18.4 Effects on SAR Imagery
935
t
fa
+PRF / 2
-PRF / 2
BC
TSA
stationary
target
SWMF
ka
vx0 > 0
ay < 0
t
fa
+PRF / 2
-PRF / 2
BC
TSA
FIGURE 18.14
Doppler history of a stationary target and a SWMF (left), and of a target moving either in along-track direction
or accelerating in across-track direction (right). The Doppler history of the stationary target is shown in blue
and of the moving target in red color. (For interpretation of the references to color in this ﬁgure legend, the
reader is referred to the web version of this book.)
FIGURE 18.15
Impulse response function of a simulated point target moving with constant velocity of vx0 = 50 km/h
in along-track direction, focused with SWMF (left: cut along azimuth; right: 2D representation; system
parameters: vp = 7300 m/s, y0 = 514 km, r10 = 726.9 km, Br = 150 MHz, PRF = 3000 Hz, λ =
0.0311 m).
If the target only has an along-track velocity component (all other motion parameters are zero) for a
system with vp ≫vx0 (i.e., a spaceborne system) the simpler equation
xblur ∼= 2TSAvx0
(18.52)
can be used [27]. This equation shows that the moving target is smeared by twice the distance it has
moved in the along-track direction during the illumination time TSA. The backscattered signal energy

936
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
is distributed over a larger area. With increasing vx0 the signal amplitude decreases as shown in Figure
18.15 left. A decreased signal amplitude leads to a decreased SCNR and a lower probability of detection.
The target’s IRF additionally may be blurred in range due to the residual range cell migration.
For targets with fDC = 0 (i.e., zero across-track velocity component) the spread of the blur in range
direction can be computed using (18.50) and the relation BC ∼= ka,st · TSA (non-squinted acquisition
geometry assumed so that x0 = 0 and fDC,st = 0):
rblur ∼= 2
****r

fa = BC
2
**** = λ
8 ·
****
1
ka,st
−1
ka
**** · B2
C = λ
8 ·
*****ka,st −k2
a,st
ka
***** · T 2
SA.
(18.53)
After inserting the Doppler parameters given in (18.31) and (18.49) as result
rblur ∼=
v2
p
4r10
·
*****1 −
v2
p
(vx0 −vp)2 + y0ay
***** · T 2
SA
(18.54)
is obtained. Especially for airborne systems the range blur may become signiﬁcant. Let us assume for
instance a system with vp = 90 m/s, y0 = 2200 m,r10 = 3810 m and an extremely long illumination
time TSA = 6s. In this case the range blur of the IRF of a target moving in along-track direction
with 100 km/h (all other motion parameters are assumed to be zero) is 21 m. However, for spaceborne
systems with vp ≪vx0 and v2
p ≪y0ay the range blur given in (18.53) and (18.54) can be neglected,
especially under the aspect that the typical illumination time is in the order of one second.
The relation between the range blur, the residual range cell migration and the motion parameters
clearly can be recognized by looking again at Figure 18.12. Especially the across-track acceleration
and the along-track velocity are the dominant motion parameters responsible for the quadratic phase
errors (i.e., the mismatch with the Doppler slope of the SWMF) and, hence, for the residual range cell
migration and the azimuth and range blur.
2.18.4.3 Across-track velocity
The major effect caused by the across-track velocity vy0 is a change of the Doppler shift fDC given
in (18.31). A secondary effect is a slight change of the Doppler slope ka. In Figure 18.16 the Doppler
history of a target moving in across-track direction is sketched. After SAR processing using the SWMF
all targets, independent if stationary or moving, are imaged at the positions corresponding to their zero
Doppler frequencies. For the moving target signal in Figure 18.16 this may either be the position marked
with timg,0 or timg,1(timg,1 corresponds to the position of an ambiguity that is caused by an aliasing
of the signal sampled by the PRF).
The azimuth time timg,0 where the target is imaged can be computed by setting (18.31) to zero
and substituting ka with ka,st for taking into account the Doppler slope of the SWMF. If only the
quadratic approximation is used (the cubic coefﬁcientqin (18.31) has been dropped since its contribution
compared to the Doppler shift and Doppler slope is negligibly small) the following imaging time is
obtained:
timg,0 = −fDC
ka,st
for | fDC| ≤PRF
2 .
(18.55)

2.18.4 Effects on SAR Imagery
937
t
fa
+PRF / 2
-PRF / 2
BC
TSA
timg,0
timg,1
vy0 < 0
fDC
t
fa
+PRF / 2
-PRF / 2
BC
TSA
fDC
FIGURE 18.16
Doppler histories of a target moving in across-track direction (in red) and of the SWMF (in blue) (For inter-
pretation of the references to color in this ﬁgure legend, the reader is referred to the web version of this
book.).
The imaging time corresponds to an along-track or azimuth displacement of
ximg,0 = −fDC
ka,st
vp.
(18.56)
For a non-squinted acquisition geometry (i.e., x0 = 0) the equation simpliﬁes to
ximg,0 ∼= −y0
vy0
vp
= −r10
vr0
vp
,
(18.57)
where vr0, denoted as line-of-sight velocity, is the projection of the across-track velocity to the slant range
direction. The relationship between the line-of-sight and the across-track velocity for a non-squinted
geometry is given as
vr0 = y0
r10
vy0 = vy0 sin θi,
(18.58)
with θi being the incidence angle.
The target is displaced in the ﬂying direction (i.e., ximg,0 > 0) if it moves towards the radar (i.e.,
vy0 < 0). It is displaced in opposite direction (i.e., ximg,0 < 0) if it moves away from the radar (i.e.,
vy0 > 0). In Figure 18.17 an IRF of a simulated point target moving with a constant velocity of 50 km/h
in across-track direction is shown. It has a large azimuth displacement of about −978 m. Additionally
the IRF is slightly shifted by −0.66 m in range direction (right image).
The reason for the range displacement is the residual range cell migration. It can be computed with
(18.50) by taking into account the fact that the major part of moving target’s signal energy is located
around fDC:
rimg,0 ∼= r( fa = fDC) = λ
4 · f 2
DC −f 2DC,st
ka,st
for | fDC| ≤PRF
2 .
(18.59)

938
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
FIGURE 18.17
Impulse response function of a simulated point target moving with constant velocity vy0 = 50 km/h in across-
track direction, focused with SWMF (left: cut along azimuth; right: 2D representation; system parameters:
vp = 7300 m/s, y0 = 514 km, r10 = 726.9 km, Br = 150 MHz, PRF = 3000 Hz, λ = 0.0311 m).
For a non-squinted acquisition geometry (i.e., x0 = 0 and fDC,st = 0) the simpliﬁed expression
rimg,0 ∼= −r10
v2
r0
2v2p
= −y2
0
r10
v2
y0
2v2p
(18.60)
can be used. The range displacement is always negative. Thus, a target with a non-zero across-track
velocitycomponentisalwaysdisplacedtowardstheradar.Therangedisplacementsaresmallifcompared
to the azimuth displacements, especially for spaceborne systems. For instance, a fast target moving
with a line-of-sight velocity of 100 km/h is displaced by only −5 m (typical low-earth orbit platform
parameters r10 = 700 km and vp = 7300 m/s assumed). For airborne systems the displacement is
larger. Here the same target is displaced by −143 m (r10 = 3000 m and vp = 90 m/s assumed).
As shown in Figure 18.17 the target’s IRF is severely displaced in azimuth but it is well focused.
The slightly decreased peak amplitude is caused by the reduced spectral overlap of the SWMF with
the moving target signal. The SWMF acts as a bandpass ﬁlter. Its Doppler bandwidth is conventionally
limited to the clutter bandwidth BC given in (18.3). The reason for that is that the clutter for SAR imaging
is the wanted signal. Everything outside the clutter bandwidth is uninteresting and therefore is ﬁltered
out. The extreme case is shown on the right side of Figure 18.16. Here no spectral overlap between
the moving target signal shown in red and the bandwidth BC of the SWMF exists. As a consequence,
fast moving targets are often not visible in conventional processed SAR images. To enable imaging
and detection of fast moving targets the processing bandwidth of the SWMF has to be increased to the
maximum possible bandwidth determined by the PRF. This is an important point to remember.
DuetotheDopplershiftapartofthesignalenergymaybebackfolded(i.e.,aliased)sothatambiguities
of the IRF appear at certain positions in the SAR image. On the left side of Figure 18.16, the primary
IRF containing most of the signal energy is imaged at position timg,0 whereas the ambiguity is imaged

2.18.4 Effects on SAR Imagery
939
Doppler History
stationary target
moving target
Ambiguity
Max. = 0.05
Real Signal from GMT
Max. = 0.43
FIGURE 18.18
Impulse response of a simulated point target moving with high velocity in across-track direction with
vy0 = 150 km/h (left: Doppler history; middle: primary impulse response containing most of the energy;
right: ﬁrst ambiguity (note the different scale); system parameters: vp = 7300 m/s, y0 = 514 km, r10 =
726.9 km, Br = 150 MHz, PRF = 3000 Hz, λ = 0.0311 m).
at timg,1. To compute also the ambiguous target positions (18.56) can be extended to
ximg,N ∼= N · PRF −fDC
ka,st
vp,
for N ∈Z.
(18.61)
An example of an ambiguous signal is shown in Figure 18.18.
To keep the ambiguities at a low level commonly a high PRF should be chosen. To ensure that at
least half of the signal energy of a point target lies within the PRF band its Doppler shift has to be
smaller than | fDC| ≤PRF/2. Using this requirement with (18.31) and again assuming for simplicity a
non-squinted geometry (i.e., x0 = 0) the upper bound for the across-track velocity is
|vy0| ≤λr10
y0
PRF
4 .
(18.62)
This bound ensures that at least half of the signal energy is unambiguously available. The equation can
be considered as a criterion for selecting the minimum required PRF of a SAR-GMTI system depending
on the highest “expected” target across-track velocity:
PRFmin,3 dB = 4y0
λr10
|vy0,max|.
(18.63)
For targets with fDC ≫0 (i.e., for targets moving with a certain across-track velocity) the spread of the
range blur can be approximated as (x0 = 0 and fDC,st = 0 assumed)
rblur ∼=
****r

fa = fDC −BC
2

−r

fa = fDC + BC
2
**** = λ
2 ·
****1 −ka,st
ka
**** · fDC · TSA. (18.64)

940
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
t
fa
+PRF / 2
-PRF / 2
BC
TSA
ax > 0
FIGURE 18.19
Doppler history of a target accelerating in along-track direction.
With the inserted Doppler parameters given in (18.31) this results in
rblur ∼= y0
r10
·
********
1 −
v2
p
(vx0 −vp)2 + vy0

1 −y2
0
r2
10

+ y0ay
********
· |vy0| · TSA.
(18.65)
If for instance an airborne system with vp = 90 m/s, y0 = 2200 m, r10 = 3111 m, and TSA = 6 s
would be used the IRF of a target moving in across-track direction with 50 km/h (all other motion
parameters are assumed to be zero) has a range blur of 0.05 m. For state-of-the-art airborne SAR systems
this is below the achievable range resolution and therefore can be neglected. However, if aside of the
across-track velocity of 50 km/h also an along-track velocity component of 100 km/h is considered, the
range blur increases to 52 m.
2.18.4.4 Along-track acceleration
The major effect of the along-track acceleration ax is a change of the quadratic coefﬁcient q in (18.31)
which causes a deﬂection of the Doppler history as sketched in Figure 18.19.
After azimuth compression the IRF of the moving target has a decreased peak amplitude and shows
non-symmetric (unbalanced) sidelobes. The strength of this effect depends mainly on the synthetic
aperture time TSA. The longer this time the larger are the third-order phase errors in time domain and
the more severe the effect. An example for an airborne system is shown in Figure 18.20.
For spaceborne SAR systems with typical illumination times below one second the effects caused
by the along-track acceleration are negligibly small.

2.18.4 Effects on SAR Imagery
941
FIGURE 18.20
Impulse response functions of a simulated point target accelerating in along-track direction, focused with
SWMF (left: the bandwidth of the SWMF was 100 Hz corresponding to an integration time of about 1 s; right:
bandwidth of 600 Hz corresponding to about 6 s integration time; system parameters: vp = 90 m/s, y0 =
3500 m, r10 = 4950 m, Br = 100 MHz, PRF = 1000 Hz, λ = 0.0311 m).
2.18.4.5 Across-track acceleration
The across-track acceleration ay causes a similar major effect as the along-track velocity vy0: a change
of the Doppler slope ka given in (18.31) (see also Figure 18.14). This results again in a blurred IRF with
decreased peak amplitude. The IRF looks similar as the response shown in Figure 18.15 and is therefore
not separately depicted. The azimuth blur caused by the across-track acceleration can be derived with
(18.51). If all other target motion parameters are zero it is given as
xblur ∼= y0
vp
ayTSA
(18.66)
Even an allegedly small acceleration my cause a azimuth blur in the order of several meters. For an
airborne system with y0 = 2200 m, r10 = 3111 m, vp = 90 m/s, and TSA = 6 s an acceleration
of 0.1 m/s2 results in an azimuth blur of approximately 15 m. For a spaceborne system with y0 =
514 km, r10 = 729 km, vp = 90 m/s, and TSA = 0.64 s the azimuth blur is 4.5 m. Neither for airborne
nor for high resolution spaceborne SAR systems this effect should be neglected. By measuring the
spread of the azimuth blur of the moving target’s IRF the effects caused by across-track accelerations
and along-track velocities cannot be separated.
Additionally to the azimuth blur the IRF is also blurred in range. The range blur caused by the
across-track acceleration can be computed with (18.54). Using the same parameters for an airborne and
spaceborne system as before, the range blurs caused by an acceleration of 0.1 m/s2 are 0.6 m and 7 mm.
Thus, at least for the spaceborne system, the range blur can be neglected.
2.18.4.6 Summary of effects
The effects treated so far caused by moving targets on SAR imagery are summarized in Table 18.1. The
knowledge of these effects and their origins are fundamental for developing suitable GMTI systems and
algorithms [9].

942
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
Table 18.1 Major Effects on SAR Imagery Caused by Moving Targets [9]
Motion parameter
Major effects on SAR imagery/IRF
System/GMTI algorithm aspects
Across-track velocity
•
Shift of Doppler frequency leads to azimuth
displacement of moving vehicles, since in
common SAR processing all vehicles are
imaged at their corresponding zero Doppler
positions
•
Small shift of impulse response in range
•
Decrease of peak amplitude since the spectral
overlap between the moving vehicle’s Doppler
history and the Doppler history of the SWMF
decreases with higher across-track velocities
•
To avoid ambiguities due to Doppler aliasing
(= backfolding), the PRF has to be increased
•
For a non-squinted SAR acquisition geometry
the Doppler shift is only determined by the
across-track velocity ⇒if the Doppler shift can
be estimated also the across-track velocity can
be computed
•
During SAR processing the full Doppler
bandwidth given by the PRF has to be
considered, otherwise fast moving targets will
be ﬁltered and will not appear in the SAR
image
Along-track velocity
•
Change of Doppler slope and hence azimuth
and range defocusing of impulse response due
to mismatch with Doppler slope of SWMF and
residual range cell migration
•
The Doppler slope can be estimated with
proper methods but along-track velocity and
across-track acceleration cannot be separated
using only the Doppler slope information
Across-track acceleration
•
Causes same effect as along-track velocity
Along-track acceleration
•
Deﬂection of Doppler history; this leads to
unbalanced sidelobes of the impulse response
function and to a decrease of peak amplitude.
•
At systems with high platform velocities and
short observation times (typical spaceborne
systems) this effect can be ignored

2.18.5 Classical Dual-Channel Techniques
943
2.18.5 Classical dual-channel techniques
In the following two sections the classical dual-channel techniques are discussed. They principally can
be applied on raw data, range compressed data and fully focused data.
2.18.5.1 Along-track interferometry
For along-track interferometry (ATI) two receiving antennas displaced in azimuth direction by a certain
baseline da are necessary. The receiving antennas can either be mounted on the same platform or
on separate platforms ﬂying in formation along the same track (separate platforms allow for larger
baselines). Anyhow, each antenna observes the scene from the same point in space at slightly different
times t1 and t2. During the time lag t = t2 −t1 the signals from stationary targets remain the same
whereas the signals from targets moving in range direction experience a phase shift φ. This phase shift
is called ATI phase. It is proportional to the line-of-sight velocity of the moving target. The time lag t
has to be sufﬁciently short to avoid the effect of temporal decorrelation caused by slight changes in the
scene (e.g., due to wind) between the acquisitions of an interferometric image pair. The ﬁrst application
of ATI was oceanography where it was used to measure tidal currents with a velocity estimation accuracy
in the order of several cm/s [28].
The ATI principle is sketched in Figure 18.21. At time t1 the target is observed by the fore antenna
at range r1. At time t2 it is observed by the aft antenna at a different range r2. The range difference
r(t) = r2(t +t)−r1(t) is proportional to the ATI phase. The ATI signal is computed by multiplying
the signal of the fore antenna with the complex conjugate and co-registered signal of the aft antenna
(remember the co-registered multi-channel signals given in (18.38):
sATI(t) = s1(t) · s∗
2,reg(t) = A1(t) · A∗
2,reg(t) · exp
⎧
⎪⎨
⎪⎩
j
⎛
⎜⎝ϕ1(t) −ϕ2,reg



=φ(t)
(t)
⎞
⎟⎠
⎫
⎪⎬
⎪⎭
.
(18.67)
If both channels are well calibrated and the RCS of the target does not change between both observations
the complex coefﬁcients A1 and A2,reg. are identical (i.e., same phases and amplitudes), so that the ATI
phase may be computed as:
ϕ(t) = arg{sATI(t)} = ϕ1(t) −ϕ2,reg(t).
(18.68)
The phases of both signals are given as
ϕ1(t) = −4π
λ r1(t),
ϕ2,reg(t) = −4π
λ r2(t + t) = −4π
λ r2,reg(t),
(18.69)
with t = dpc/vp where dpc is the antenna phase center separation in along-track direction (= effective
along-track baseline). If both antennas receive and transmit independently (= monostatic operation) the
phase center separation corresponds to the physical antenna separation, i.e., dpc = da. In case of bistatic

944
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
vp
t
baseline da
vp
t1
r1
vr0
x (azimuth)
FORE
AFT
vp
t
baseline da
vp
x (azimuth)
t1
r1
t2
r2
vr0
r
FORE
AFT
time t1
time t2
FIGURE 18.21
Along-track interferometry principle.
operation where only the fore antenna is used for transmission but both antennas for signal reception
the effective along-track baseline reduces to half the physical distance, i.e., dpc = da/2.
By inserting (18.69) in (18.68) the ATI phase may be written as
φ(t) = 4π
λ [r2,reg(t) −r1(t)] = 4π
λ r(t).
(18.70)
If the target moves with constant line-of-sight velocity vr0 the ATI phase of the target at broadside
position for monostatic operation in the simplest case can be approximated as (the squint angle and all

2.18.5 Classical Dual-Channel Techniques
945
other motion parameters of the target are assumed to be zero) [28]
φ ∼= 4π
λ vr0t.
(18.71)
If the line-of-sight velocity is computed from the measured ATI phase blind velocities and ambiguities
may occur. The reason is that the ATI phase can only be measured in fractions of 2π. A blind velocity
occurs if the measured ATI phase becomes zero. This is the case for
φ = N · 2π,
for N ∈Z.
(18.72)
The blind velocities can be computed by inserting (18.71) in the previous equation:
vr0,blind =
λ
2t N.
(18.73)
If the target moves with a blind velocity its ATI phase cannot be discriminated from the ATI phase of a
stationary target and, hence, it cannot be detected in the interferogram.
An ambiguity occurs if the ATI phase is equal or larger than π. In this case neither the motion direction
(away or towards the radar) nor the velocity can be determined unambiguously. The maximum line-of-
sight velocity causing no ambiguities is given as (again derived with (18.71))
|vr0,max| <
λ
4t .
(18.74)
The maximum line-of-sight velocity can be increased by using larger radar wavelengths λ or smaller
time lags t (i.e., smaller baselines).
In Figure 18.22 a polar plot of an azimuth line of interest containing a moving target signal is shown.
The azimuth line was focused with the SWMF before the polar plot was generated. Several dots in the
polar plot belong to the target since it spans multiple resolution cells. It also can be seen that the target
dots have slightly different phases. The reason is that the target is not perfectly focused (remember the
potential mismatch of the Doppler slope of the target and the SWMF). Furthermore, since ATI performs
no clutter suppression also the clutter contribution disturbing the ATI phase clearly can be recognized.
As a consequence the ATI phases of moving target signals are biased towards zero so that velocities are
generally underestimated. For low SCNR values this bias is more signiﬁcant.
Even if there is no temporal decorrelation and if the clutter would be suppressed somehow prior to
ATI phase computation, the minimum detectable velocity (MDV) and the accuracy of the line-of-sight
velocity estimate is limited by the thermal receiver noise. The receiver noise in both RX channels causes
a phase decorrelation which results in a noisy estimate of the ATI phase. The amplitude of the complex
correlation coefﬁcient due to thermal receiver noise between both channels is given as [29]
|γSNR| =
1
1 + SNR−1 ,
(18.75)
where SNR is the signal-to-noise ratio after SAR focusing (i.e., after pulse compression). The standard
deviation of the ATI phase for point-like scatterers for values of γSNR close to one can be approximated
as [30,31]

946
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
clutter
moving target
FIGURE 18.22
Polar plot of ATI phases of an extracted azimuth line containing a moving target signal. The data was acquired
with DLR’s airborne sensor E-SAR.
σφ ∼=

1 −γ 2
SNR
2γ 2
SNR
.
(18.76)
This equation can be considered as a lower bound of the ATI phase standard deviation. For extended
objects (i.e., targets larger than a single SAR resolution cell) the standard deviation is larger but it can
be reduced to a certain degree by ATI phase averaging (=multi-looking).
The lower bound of the standard deviation of the line-of-sight velocity computed with (18.71) and
(18.75) can be expressed as
σvr0 =
****
λ
4πt
**** σφ.
(18.77)
The standard deviation of the azimuth position computed using (18.56) is then
σximg =
****−r10
vp
**** σvr0 =
****−
λr10
4πvpt
**** σφ.
(18.78)
By having a closer look at (18.77) and (18.78) it is obvious that the standard deviation can be
decreased by increasing the time lag t and, hence, the antenna phase center separation dpc. However,
it has to be kept in mind that by increasing t the maximum unambiguously detectable line-of-sight
velocity in (18.74) and the blind velocities in (18.73) decrease. Techniques for phase unwrapping are
necessary if the motion and position parameters of faster moving targets shall be estimated with high
accuracy. Promising candidates are for instance multi-baseline ATI techniques [32,33]. Ambiguities
might also be resolved if the range cell migration of the target is exploited for a rough line-of-sight

2.18.5 Classical Dual-Channel Techniques
947
Airborne
Spaceborne
FIGURE 18.23
Standard deviations of the estimates of line-of-sight velocity and azimuth position for an exemplary air-
borne (left) and spaceborne (right) SAR acquisition geometry (airborne parameters: λ = 3.12 cm, r10 =
3111 m, vp = 90 m/s; spaceborne parameters: λ = 3.12 cm, r10 = 726.9 km, vp = 7450 m/s).
velocity estimation which afterwards is reﬁned with the information obtained from the ATI phase [21].
For large time lags, temporal decorrelation may also have a negative inﬂuence, but this aspect is not
treated here.
Figure 18.23 shows the standard deviations of the line-of-sight velocity and the azimuth position for
exemplary airborne and spaceborne acquisition geometries. It is obvious that with airborne systems even
with small baselines in the fraction of a meter good estimation results can be achieved. For spaceborne
systems comparatively large baselines are required to push down the standard deviations and, hence,
to improve the parameter estimation accuracy. However, the size and weight of SAR satellites are
limited by launcher restrictions. For instance, the German TerraSAR-X satellite has an antenna length
of 4.8 m which can be split into two RX sub-apertures of 2.4 m each. In bistatic operation (i.e., TX
with full antenna and RX with both halves simultaneously) the phase center separation or the effective
along-track baseline, respectively, is only 1.2 m. For high SNR values of 20 dB the azimuth position
estimation accuracy is in the order of 150 m. The accuracy decreases to 490 m if the SNR decreases
to 10 dB. Compared to airborne systems, state-of-the-art spaceborne systems generally achieve worse

948
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
position and motion parameter estimation accuracies. The two main reasons are the too short baselines
and the worse SNR values.
For an in-depth ATI performance analysis also the clutter contribution has to be considered [34,
35]. However, for understanding the basic ATI principles and performance limitations the previous
explanations are sufﬁcient.
In reality a moving target seldom has only a line-of-sight velocity component with all other motion
components being zero as assumed in the derivation of (18.71). Although ATI is primarily sensitive to the
line-of-sight velocity vr0 also the other motion components contribute to the ATI phase. Unfortunately
there exists no analytical description for the ATI signal focused with a SWMF. However, if the Doppler
slope of the matched ﬁlter used for azimuth compression is adapted to the Doppler slope ka of the
target an analytical solution exists (matched ﬁlters adapted to target motion’s parameters are discussed
in Section 2.18.7.1). In case of a non-squinted geometry (i.e., x0 = 0 and fDC,st = 0) the ATI phase of
the peak of the refocused target signal is given as [23]
φ(t = timg,0) = πday0
λr10
·
	 1
vp
+ 2(vx0 −vp)
λr10ka

· vy0.
(18.79)
The ATI phase depends not only on the across-track velocity vy0 but also on the along-track velocity
vx0. This has to be taken into account for accurate parameter estimation.
2.18.5.2 Displaced phase center antenna technique
The displaced phase center antenna (DPCA) technique is one of the simplest clutter suppression tech-
niques in radar [36]. The antenna conﬁguration is exactly the same as in ATI: at least two receiving
antennas are needed (see also Figure 18.21). The only difference is the signal processing. Instead of a
complex conjugate multiplication the co-registered signal received by the aft antenna is subtracted from
the signal received by the fore antenna for obtaining the DPCA signal
sDPCA(t) = s1(t) −s2,reg(t).
(18.80)
Signals from stationary targets are canceled since they are identical in both successive observations.
Targets moving with sufﬁcient line-of-sight velocity cause a certain phase shift and, thus, will not be
canceled. As a consequence even slowly moving targets otherwise masked by the clutter can be detected
in the “clutter-suppressed” DPCA image. If the clutter is homogeneous DPCA can be considered as the
optimal linear ﬁlter for target detection [37]. Although DPCA originally was developed for dual-channel
systems, it also can be used with more than two channels [38–40].
In older literature it is often stated that the so called “DPCA Condition” has to be fulﬁlled. That
means that the PRF has to be selected in a way that the spatial location of the fore antenna phase center
when an echo is received is the same as the location of the aft antenna phase center when the next echo
is received:
PRF = 1
t .
(18.81)
Nowadays this restriction is relaxed. By modern signal processing techniques co-registration can
be performed with sub-sample accuracy using interpolation or resampling, respectively. Often the
co-registration is done by applying a phase ramp on the signal after transforming it via an FFT to

2.18.5 Classical Dual-Channel Techniques
949
the Doppler domain (remember the displacement law of the Fourier transform). The phase ramp to be
applied in Doppler domain for co-registration along azimuth generally is given as
Skϕ( fa) = exp (−j2π fat).
(18.82)
This leads to accurate co-registration results as long as the Nyquist sample theorem is fulﬁlled for both
clutter and moving target signals. In other words, a sufﬁciently high PRF is required for avoiding aliasing
of signals in Doppler. However, if the PRF is too low the aliased clutter signals after co-registration
have a constant phase error [18]. A coarse co-registration without interpolation can be done by shifting
the data by an integer amount of samples. The time in (18.82) for ﬁne co-registration with sub-sample
accuracy can then be decreased to tshift(tshift < t). The constant phase error derived in [18] in this
case can be written as
δϕ = ±2π · tshift · PRF.
(18.83)
Due to this constant phase error aliased clutter might be mistaken as false moving targets. Especially
for spaceborne systems the Doppler bandwidth is large compared to the PRF so that Doppler aliasing
cannot be excluded. It generally is more severe than in airborne systems. Therefore, for spaceborne
systems it is advisable to meet the DPCA condition in (18.81) as accurate as possible so that no phase
ramp in Doppler for ﬁne-co-registration needs to be applied. In this case tshift is zero and the phase
error in (18.83) vanishes.
For achieving a good detection performance it is essential that the receiving channels are well
calibrated. For calibration the “Adaptive 2D Channel Balancing” method originally proposed by Ender
[7] has established itself in the GMTI community. The method operates in the 2D frequency domain.
The channel transfer functions are adapted to a reference channel, conventionally the fore channel.
The method is not limited to two channels. Also co-registration is performed between the channels
since any phase ramps in frequency domain are removed [41]. In Figure 18.24 an example with three
moving targets is shown. It can be seen that after channel balancing (right column) the SCNR as well
as the correlation coefﬁcient γSNR is increased. Even targets with lower RCS are clearly visible in the
balanced DPCA image. Theoretically the clutter can be suppressed down to noise level. The application
of a channel balancing method is absolutely crucial, especially for airborne GMTI algorithms based on
classical ATI and DPCA.
If the channels are well calibrated so that A1(t) ∼= A2,reg.(t), the DPCA signal can also be expressed
as
SDPCA(t) = 2|A1(t)|·
****sin ϕ1(t) −ϕ2,reg(t)
2
****·exp
+
j
ϕ1(t) + ϕ2,reg.(t)
2
+ ϕA1(t) + π
2
,
, (18.84)
where ϕA1(t) is the phase of the complex coefﬁcient A1(t). For detecting a moving target the magnitude
of the DPCA signal is of interest:
|sDPCA(t)| = 2|A1(t)| ·
****sin ϕ1(t) −ϕ2,reg(t)
2
**** .
(18.85)
If the target moves with constant line-of-sight velocity vr0 (all other motion parameters are zero) the
DPCA magnitude can be approximated as
|sDPCA(t)| ∼= 2|A1(t)| ·
****sin
2π
λ vr0t
**** .
(18.86)

950
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
DPCA Unbalanced
DPCA Balanced
1
2
3
SAR Image
SNR
0.878
SNR
0.914
range
azimuth
range
azimuth
range
azimuth
2D Representation
3D Representation
FIGURE 18.24
Clutter suppression capabilities of unbalanced DPCA and balanced DPCA (left column: single-channel air-
borne SAR image containing three targets moving in range direction; middle: DPCA image generated from
unbalanced two-channel data; right: DPCA image generated from balanced data).
It is obvious that the DPCA magnitude drops to zero if the sine becomes zero. This is the case if
the target moves with a blind velocity given in (18.73). Thus, neither with ATI nor with DPCA targets
moving with blind velocities can be detected.
2.18.6 General GMTI processing chain
In this section the general GMTI processing chain is presented and discussed. Figure 18.25 shows
a simpliﬁed ﬂow chart containing the typical GMTI processing steps. At the very ﬁrst beginning the
acquired radar data in their raw form are necessary as input. These data somehow need to be preprocessed
before the “GMTI Kernel” can be applied.
The “GMTI Kernel” represents a general GMTI algorithm with the processing steps: clutter sup-
pression, detection, signal extraction, and parameter estimation. Principally every state-of-the-art GMTI
algorithm consists of these steps. However, the steps are not always clearly separable and the step order
may be different. Especially “Signal Extraction” sometimes is not necessary.
In the following sections the different steps are explained.

2.18.6 General GMTI Processing Chain
951
Acquired with single-or multi-channel 
air- or spaceborne sensor
Different dual- and multi-channel 
techniques (e.g. DPCA and STAP)
Comparison to a certain threshold
“Cut out” signal for further investigations
Doppler parameters / motion / position
Symbol or ISAR image overlayed on 
conventional SAR image 
Range-compression (+ RCMC)
Calibration / channel balancing
GMTI Kernel
RAW Data
Preprocessing
Clutter Suppression
Detection
Parameter Estimation
Visualization
Signal Extraction
-steps often not separable
-different step order possible
-signal extraction not always
necessary
FIGURE 18.25
Simpliﬁed ﬂow chart of general GMTI processing steps.
2.18.6.1 Preprocessing
As input for a SAR-GMTI processor single- or multi-channel raw data acquired with air- or spaceborne
sensors are used. These data need to be preprocessed (step 2 in Figure 18.25) before the “GMTI Kernel”
can be applied. Depending on the particular GMTI algorithm to be used in the “GMTI Kernel” several
preprocessing options are conceivable (no claim to completeness):
•
Range compression.
•
Range compression with RCMC.
•
Conventional SAR processing.
•
Motion adapted SAR processing.
2.18.6.1.1
Range compression
The acquired data are only compressed in range, no RCMC and no azimuth compression is carried out.
This kind of preprocessing is used especially for airborne GMTI algorithms based on STAP [4,37].
Most of these algorithms use only short integration times so that range cell migration can be neglected.
Large SNR values are required since due to the low sample support the compression gain obtained by
coherent integration is limited. However, with state-of-the-art airborne systems this is not a problem in
contrast to spaceborne systems which have to cope with comparatively low SNR values.

952
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
2.18.6.1.2
Range compression with RCMC
The data are range compressed and a RCMC is performed. The RCMC may either be adapted to
stationary targets, as done during conventional SAR processing, or in an iterative way to some of the
moving target’s motion parameters. A detailed discussion on RCMC and residual range cell migration
was already given in Section 2.18.4.1 and shall not be repeated here.
2.18.6.1.3
Conventional SAR processing
The data are processed with a conventional SAR processor, e.g., a Range/Doppler [3] or a Chirp Scaling
Processor [20]. The full Doppler bandwidth given by the PRF has to be considered to avoid ﬁltering of
signal energy of fast moving targets (cf. Section 2.18.4.3).
2.18.6.1.4
Motion adapted SAR processing
The data are processed iteratively using different assumptions of target’s motion parameters. This kind
of preprocessing requires high computational power. However, the advantage is that high SCNR values
may be achieved. This especially is crucial for spaceborne systems which generally suffer from low
SNR and SCNR values (cf. Section 2.18.5.1).
2.18.6.2 Clutter suppression
Most of the multi-channel GMTI algorithms found in the literature use either DPCA or STAP techniques
for clutter suppression.
2.18.6.2.1
DPCA
Dual-channel algorithms mainly use the DPCA technique discussed in Section 2.18.5.2 for clutter
suppression. This technique can also be used if more than two RX channels are available [38,39]. For
instance several clutter suppressed image pairs can be generated using DPCA. The ATI phase between
these image pairs is then less inﬂuenced by clutter [42]. This improves the moving target parameter
estimation accuracy signiﬁcantly. In the ideal case the clutter is suppressed down to noise level so that
the curves shown in Figure 18.23 apply for the velocity and position estimation accuracy.
In the general case the clutter ﬁltered signal yout is obtained by a linear combination of the received
multi-channel signal or space-time snapshot z with the clutter ﬁlter or weight vector w
yout = wHz,
(18.87)
where H denotes complex conjugate transposition (i.e., Hermitian transpose) [43]. The clutter and noise
contaminated space-time snapshot z has the same array structure as the multi-channel signal vector s
given in (18.44). The dimension is M N × 1, where M is the number of receiving antennas and N the
number of considered temporal samples.
If multi-channel DPCA using M antennas shall be applied for clutter suppression, the weight vector
is given as [43]
w =
	 d1
−d2

,
(18.88)

2.18.6 General GMTI Processing Chain
953
where d1 and d2 are the M-dimensional spatial-only steering vectors for the ﬁrst and second pulses (i.e.,
N = 2), respectively. The steering vectors are then
d1 =
⎡
⎢⎢⎢⎣
0
1
...
1
⎤
⎥⎥⎥⎦(1st element off),
d2 =
⎡
⎢⎢⎢⎣
1
...
1
0
⎤
⎥⎥⎥⎦(Mth element off).
(18.89)
It has to be noted that in this case the DPCA condition has to be fulﬁlled. The data must not be co-
registered. The output of the clutter ﬁlter is a scalar if only two temporal samples are used. To ﬁlter an
entire azimuth line the ﬁlter has to be applied successively, each time using two temporal samples.
2.18.6.2.2
Adaptive clutter suppression
In the multi-channel case adaptive clutter ﬁltering can be performed by multiplying the acquired and
preprocessed multi-channel signal with the inverse of the clutter covariance matrix and a steering vector
[4,37]. The adaptive weight vector is formed in the following way
w = R−1
W d,
(18.90)
where RW is the clutter covariance matrix of dimension M N × M N and d is the steering vector.
The clutter covariance matrix itself can either be computed analytically using the known system,
antenna and geometry parameters or, more powerfully, be estimated from the real data (it is then called
“Empirical Clutter Covariance Matrix” or “Sample Clutter Covariance Matrix”). In the latter case the
clutter covariance matrix is “adapted” to the real “clutter” data. The processing is then called “Space-
Time Adaptive Processing (STAP)” (see also Section 2.18.9). The empirical clutter covariance matrix
can be computed by averaging training data which shall not contain moving target signals [4]:
-RW = 1
K
K
.
k=1
zkzH
k ,
(18.91)
where zk is the M N × 1 vector of training data from training cell k, and K is the total number of used
training cells. The averaging for instance could be performed over range as exemplarily sketched in
Figure 18.26. To exclude potential moving target signals a guard zone should be used [43,44].
If again two successive temporal samples (N = 2) and as steering vector
d =
	 d1
d2

(18.92)
are used, then the clutter suppression method is called “Adaptive DPCA” (ADPCA) [44].
2.18.6.3 Detection
Conventionally moving targets are detected on a pixel by pixel basis. A threshold is set to discriminate
between one of the two hypotheses H0 (moving target signal not present) and H1 (moving target signal
present):

954
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
azimuth
range
cell under test
guard cells
guard cells
K /2 training cells
K /2 training cells
FIGURE 18.26
Use of training data for computing the empirical clutter covariance matrix.
H0 : z = c + n,
H1 : z = s + c + n,
(18.93)
where z denotes the vector of the received data, c is the clutter vector and n the noise vector.
Generally a so called “Constant False Alarm Rate (CFAR)” detector is envisaged. The threshold is
computed in a way that the percentage of the image pixels which lie above the threshold is constant.
For computation the clutter statistics have to be known precisely.
If the probability density function (PDF) of the clutter is known, the false alarm rate or the probability
of a false alarm is obtained by integrating the PDF:
Pfa = 1 −
 sth
−∞
fC(x)dx =
 ∞
sth
fC(x)dx
(18.94)
where sth is the threshold and fC(x) the PDF of the clutter metric to be tested (e.g., the clutter DPCA
amplitude, the clutter ATI phase, the clutter ATI phase combined with the clutter ATI amplitude, etc.).
If a certain false alarm rate is desired this equation needs to be solved for the threshold sth. Depending
on fC(x) an analytical solution is not always possible so that numerical methods may be necessary.
The probability of detection can be expressed as
Pd =
 ∞
sth
fT(x)dx,
(18.95)
where fT(x) is the target plus interference PDF.
Analytical descriptions of the PDFs of the clutter multi-look ATI phase and ATI amplitude can be
found in [34]. In that paper different clutter types are modeled and veriﬁed with real data. A discrimi-
nation between homogeneous (Gaussian), heterogeneous (non-Gaussian) and extremely heterogeneous
clutter is made. A novel polynomial PDF called p-distribution is introduced. This PDF matches the real
data much more accurately, particularly for heterogeneous composite terrain. All clutter parameters

2.18.6 General GMTI Processing Chain
955
pixel under test
guard zone
clutter statistics
(
CFAR) 
FIGURE 18.27
Principle for estimating the clutter statistics for the pixel under test.
for determining the detection thresholds are estimated from the real data. Further detection metrics are
discussed in [45]. Here also a so called “Hyperbolic Detector” well suited for heterogeneous terrain
such as urban areas is introduced.
For estimating the clutter statistics from the real data the moving target itself has to be excluded. This
can be achieved by introducing a guard zone around the pixel under test as depicted in Figure 18.27.
The clutter statistics is then estimated from the data surrounding the guard zone. The purpose of the
guard zone is to exclude that moving target signal components disturb the clutter and, hence, lead to a
wrong clutter PDF estimate. The size of the guard zone shall be chosen in accordance with the expected
sizes of the moving vehicles to be detected. If the guard zone is too small or if a lot of targets move close
together, the clutter PDF estimate is biased and the false alarm rate will not remain constant anymore.
For studying and comparing the performance of different detector types as quality measures the
probability of detection Pd versus varying SCR and Pd versus Pfa can be used [46]. The latter quality
measure is known as receiver operating characteristics (ROC) of a detector. Since the exact PDF of the
target signal is generally unknown, it is conventionally assumed to be either deterministic or Gaussian
distributed.
2.18.6.4 Signal extraction
Once a moving target has been detected it is of interest to estimate its motion and position parameters.
For that purpose the moving target signal may be extracted from the data. An extraction also may be
required if for instance the target image shall be refocused to high resolution using ISAR imaging
techniques [15–17]. In the following two practicable extraction methods are discussed.
2.18.6.4.1
Range history tracking
The principle is depicted in Figure 18.28 on the left. The method operates on range compressed data
where the clutter already has been canceled. Each pixel corresponding to the clutter suppressed moving
target signal has to be detected (the detected pixels are represented by the pink squares in the image).
The aligned pixels represent the moving target azimuth signal s(t) which afterwards can be passed to

956
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
Range Compressed 
Data
range
azimuth
range
azimuth
azimuth lines containing 
moving target signals
Range Compressed
Data After RCMC
aliased part
of signal 2
signal 1
moving target signal
FIGURE 18.28
Moving target signals in the range compressed SAR data array (left: range compressed data without RCMC;
right: range compressed data after conventional RCMC for stationary targets).
the parameter estimation stage. The range history tracking method was introduced in [47]. A detailed
description of the “tracking” algorithm is given in [21].
The method has the advantage that even signals backfolded in Doppler can be tracked and that
information about the shape of the range history is obtained (remember in particular the inﬂuence of the
across-track velocity on the range history shape discussed in Section 2.18.4.1). The disadvantage is that
the clutter suppressed signal must have high SCNR values to be detectable on a pixel-by-pixel basis.
This restricts the application to airborne GMTI. Tracking might also become problematic if several
targets with overlapping range histories are in the data array.
2.18.6.4.2
Extraction of azimuth lines
The principle of the azimuth line extraction method is sketched in Figure 18.28 on the right. The data
have to be range compressed and also the range cell migration has to be corrected, at least with respect
to stationary targets. Depending on the motion parameters and on the range pixel spacing (which is
determined by the range sampling rate) a major part of the signal energy may be distributed along a
single azimuth line (see also discussion on residual range cell migration in Section 2.18.4.1). Thus, by
extracting the proper azimuth line the signal s(t) is obtained. The method can also be applied prior to
the detection step. Then all azimuth lines of the data are successively extracted. Afterwards detection
and parameter estimation are carried out using different methods discussed later.
From signals backfolded in Doppler only a part of the signal energy can be recovered. The “aliased
part” is lost if the RCMC was adapted for stationary targets (cf. Figure 18.28, right). Successive prepro-
cessing with different motion adapted RCMC may help to catch more signal energy and avoid aliasing
[39,48]. Anyhow, the simple extraction of azimuth lines is a very fast method which also works for
signals with low SCNR as in the case of spaceborne GMTI. Furthermore, even multi-target scenarios

2.18.6 General GMTI Processing Chain
957
(i.e., if more than one moving target signal is contained in the extracted azimuth line) can be resolved by
using e.g., a matched ﬁlter bank or the fractional Fourier transform discussed later in Sections 2.18.7.1
and 2.18.7.2, respectively.
Also from fully focused SAR images the azimuth lines can be extracted. However, before applying
a matched ﬁlter bank the azimuth compression has to be removed (this can simply be done by adapting
the reference function of the matched ﬁlter).
2.18.6.5 Parameter estimation
In (18.31) it is shown that the target’s motion parameters are related to the Doppler parameters shift
fDC, slope ka, and quadratic coefﬁcient q. Thus, motion parameter estimation can be reduced to Doppler
parameter estimation. From the known Doppler parameters the position and motion parameters of
the moving target can be computed. The intention of this section is to show how this computation is
principally performed by different state-of-the-art GMTI algorithms. In the following it is supposed that
the Doppler slope ka and shift fDC already have been estimated. Basic Doppler parameter estimation
methods are discussed afterwards in Section 2.18.7.
It is also supposed that the radar parameters and the acquisition geometry are known accurately so
that the parameters y0,r10, and λ need not to be estimated. This is a valid assumption, particularly if the
range is large compared to a potential range displacement rimg,0 (i.e., r10 ≫rimg,0). Additionally
a non-squinted acquisition geometry is assumed (i.e., x0 = 0 and fDC,st = 0).
2.18.6.5.1
Across-track velocity
The relation between the Doppler shift and the across-track velocity is given in (18.31). In case of a
non-squinted acquisition geometry the simple relationship
fDC = −2y0
λr10
vy0
(18.96)
applies. However, in practice the across-velocity is computed from the estimated ATI phase φ. In the
simplest case the relationship given in (18.71) is used so that the across-track velocity computes to
vy0 ∼=
λr10
4π y0t φ.
(18.97)
To mitigate the inﬂuence of clutter and to keep the estimation bias at a low level the moving target’s IRF
should be refocused before estimating the ATI phase (refocusing increases the SCNR). More robust
algorithms exploit three RX channels for ATI phase estimation as sketched in Figure 18.29. They
generate two DPCA images: the ﬁrst by subtracting channel 2 from 1, and the second by subtracting
channel 3 from 2. The corresponding clutter suppressed ATI signal is then obtained by
sATI(t) = sDPCA,12(t) · s∗
DPCA,23,reg(t).
(18.98)
This has the advantage that the clutter is suppressed theoretically down to noise level so that in the best
case the performance limits depicted in Figure 18.23 can be reached.

958
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
TX/RX1
RX2
RX3
DPCA
DPCA
ATI
da
da
FIGURE 18.29
Principle of the DPCA-ATI technique.
One promising state-of-the-art GMTI algorithm which additionally uses the fractional Fourier
transform (explained in detail in Section 2.18.7.2) for target refocusing and additional parameter estima-
tion is presented in [35]. An extension to spaceborne geometries can be found in [18]. Here also different
transmit and receiver aperture switching strategies for generating additional receiving channels with
larger baselines are discussed. Especially for spaceborne systems larger baselines are of importance for
improving the parameter estimation accuracy.
2.18.6.5.2
Along-track velocity
Remember (18.31) where it is shown that the Doppler slope ka depends on the along-track velocity vx0,
the across-track acceleration ay and on the across-track velocity vy0 in the following way:
ka = −2
λr10

(vx0 −vp)2 + v2
y0

1 −y2
0
r2
10

+ y0ay

.
(18.99)
Under the assumption that the across-track velocity vy0 can be estimated with ATI still two unknowns
remain: vx0 and ay. Without further information the two unknowns cannot be computed. This is just
the crux of many GMTI algorithms which exploit only the Doppler slope. Since the required additional
information cannot be gained accelerations are assumed to be negligibly small. They are simply set to
zero. The along-track velocity is derived by rearranging (18.99)
vx0 = vp −
/
0
0
1−λr10
2 ka −v2
y0

1 −y2
0
r2
10

−y0ay,
(18.100)
where incorrectly the term y0ay is ignored by many GMTI algorithms. However, this assumption is in
reality only valid if an across-track motion can be excluded a priori. Thus, the target must move only
in along-track direction for avoiding estimation errors.
In [49] it is shown that the typical standard deviation of the acceleration of a common passenger car is
in the order of 0.5 m/s2. For TerraSAR-X a comparatively small across-track acceleration of 0.25 m/s2

2.18.6 General GMTI Processing Chain
959
would lead, if neglected in (18.100), to an along-track velocity estimation error of −32 km/h. This
demonstrates clearly that accelerations should not be neglected if highly accurate velocity parameter
estimates are desired.
In the literature so far only two algorithms can be found which take into account the accelerations
for parameter estimation. Both of them don’t use the estimated Doppler slope for along-track velocity
estimation. They use a different measure not inﬂuenced by across-track accelerations.
The algorithm in [50] was developed for a single-channel SAR but can principally also be used
in the multi-channel case. It exploits the fact that the effective synthetic aperture time and, hence, the
Doppler bandwidth varies with the moving target’s along-track velocity. Thus, by estimating the Doppler
bandwidth of the extracted moving target signal the along-track velocity can be computed without the
negative inﬂuence of accelerations in the following way:
vx0 = vp −LSA|ka|
 fa
,
(18.101)
where LSA is the length of the synthetic aperture for a stationary target located at the same range, and
 fa is the estimated Doppler bandwidth of the moving target signal. The drawback of the algorithm
is that it only works properly for strong point-like targets with a RCS that is independent of the aspect
angle. Furthermore, the whole target signal energy has to be collected since otherwise the Doppler
bandwidth cannot be estimated accurately.
In [24] the ATI phase history of range compressed moving target signals between two or more
receiving channels which are not co-registered is exploited. The slope of the ATI phase history is given as
kφ = 2π(vx0 −vp)
λr10
da.
(18.102)
It is not inﬂuenced by accelerations. Thus, by estimating the slope the along-track velocity vx0 can be
computed as
vx0 = vp + λr10
2πda
kφ.
(18.103)
The method is suitable for airborne systems where the SNR is generally much higher than in satellite
systems. A good performance can be achieved for signals with SCNR values larger than 10 dB.
Both methods discussed before require large SCNR values to achieve a good along-track velocity
estimation accuracy. Therefore they are not well suited for spaceborne systems. They should always be
used supplementary to methods exploiting the Doppler slope.
2.18.6.5.3
Accelerations
The estimation of target accelerations is generally of minor interest. The reason why accelerations are
still of importance is that they may improve the velocity estimation accuracy.
The across-track acceleration can be computed by rearranging (18.99):
ay = −1
y0

λr10
2 ka + (vx0 −vp)2 + v2
y0

1 −y2
0
r2
10
 
.
(18.104)

960
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
The along-track acceleration principally can be computed by rearranging the equation of the quadratic
Doppler coefﬁcient which is given as:
q = −3
λr10

ax(vx0 −vp) + vy0ay

1 −y2
0
r2
10

.
(18.105)
However, for estimating q longobservationtimes arenecessary. At short observationtimes qis negligibly
small and cannot be estimated precisely (cf. also Section 2.18.4.4 where the effect caused by the along-
track acceleration is discussed).
2.18.6.5.4
True target position
As discussed in Section 2.18.4.3 a target moving in across-track direction appears displaced from its
actual position in the SAR image. It is displaced in azimuth as well as in range direction.
It is shown in (18.57) that the along-track displacement is directly related to the across-track velocity
vy0 in the following way:
ximg,0 ∼= −y0
vy0
vp
.
(18.106)
Thus, once the across-track velocity is estimated (e.g., with ATI) the azimuth displacement can be
computed. The same is valid for the range displacement given in (18.60).
Another interesting dual-channel method for estimating the broadside position, which corresponds
to the true target position in the non-squinted case, is presented in [51]. Here again the ATI phase history
of range compressed signals which are not co-registered is exploited. The distances between the target
and the fore and the aft antenna phase centers are exactly equal if the target is located broadside. Thus,
by estimating the zero crossing of the ATI phase history the broadside position and, hence, the true
target position can be computed. Since the ATI phase history is strongly inﬂuence by clutter bandpass
ﬁltering in the fractional Fourier domain is performed. The effectiveness of this ﬁltering is illustrated
in Figure 18.30 (the zero crossing is at t = 9.6 s). The method can also be used with more than
two channels by additionally using DPCA for clutter suppression [24]. Also the ATI phase slope for
computing the along-track velocity can be estimated as discussed in Section 2.18.6.5.2.
A third method for estimating the true target positions are displacement based algorithms. These
algorithms require the incorporation of a priori knowledge about the road network. The along-track
displacement ximg,0 can then simply be measured: it is the distance between the position where the
target is imaged and the road axis (cf. Figure 18.31). For a spaceborne system the range displacement
rimg,0 is only in the order of a few meters and therefore can be neglected (cf. Section 2.18.4.3).
The along-track displacement estimation accuracy is mainly related to the position accuracy of the
road axis and the road width. From the estimated displacement easily the across-track velocity can be
derived:
vy0 ∼= −vp
y0
ximg,0.
(18.107)
Since also the road angle α is available from the road database the along-track velocity can be computed
as vx0 = vy0/ tan α. The across-track acceleration is obtained with (18.104) after the Doppler slope
ka has been estimated. For computing the along-track acceleration again the road angle can be used so
that ax = ay/ tan α. Although all important motion parameters can be derived the displacement based

2.18.6 General GMTI Processing Chain
961
FIGURE 18.30
Unregistered ATI phase history (blue: without clutter suppression; yellow: clutter suppressed using bandpass
ﬁltering in fractional Fourier domain) [24] (For interpretation of the references to color in this ﬁgure legend,
the reader is referred to the web version of this book.)
x img,0
r img,0
r10
true target position
@ t = 0
vp
FIGURE 18.31
Azimuth and range displacement of a moving target.
algorithms have one major disadvantage: problems may arise if a lot of adjacent roads are located in
the scene. Then the detected targets under circumstances cannot be assigned to the correct roads.
An operational trafﬁc monitoring algorithm for TerraSAR-X based on the displacement technique
is presented in [11,52].

962
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
range
azimuth
FIGURE 18.32
Single-channel SAR image with three detected moving targets (location: airﬁeld in Memmingen, Germany;
data acquired with DLR’s E-SAR sensor) [53].
2.18.6.6 Visualization
Finally, the detected target can be visualized. Often a symbol representing the moving target is overlaid
on the corresponding SAR image on its estimated position. For instance, the symbol may be an arrow
pointing into the estimated moving direction and the color of this symbol may correspond to the velocity.
An example for such a visualization is shown in Figure 18.32.
Another elegant possibility for visualization is Google Earth. The parameters of the detected moving
targets are written into a Keyhole Markup Language (KML) ﬁle. Also links to target symbols and SAR
images can be incorporated easily. The KML ﬁle can then be visualized with Google Earth as shown in
Figure 18.33.
Furthermore, additional information about the detected target can be provided in an interactive way.
The user or operator can click on the moving target symbols to open a window. This window may contain
more information about the detected target. Also data from additional data sources can be incorporated
and fused with the SAR data. For instance, the estimated parameters of detected ships could be fused
with “ground truth” data obtained from the automatic identiﬁcation system (AIS) [54]. An example is
depicted in Figure 18.34. Such ground truth data can also be used for evaluating the parameter estimation
accuracy of GMTI algorithms.
2.18.7 Doppler parameter estimation: basic methods
The intention of this section is to introduce the fundamental and most promising Doppler parameter
estimation methods which are used in state-of-the-art GMTI algorithms. Most of these methods can
even be used for both target detection and parameter estimation in one step.

2.18.7 Doppler Parameter Estimation: Basic Methods
963
FIGURE 18.33
SAR image and detected moving targets as Google Earth overlay (location: near Chiemsee, Germany; scene
size 6.0 × 1.9 km2; data acquired with DLR’s F-SAR sensor). Some of the slower moving targets are false
detections.
For estimating the Doppler shift fDC which is mainly related to the across-track velocity the ATI
technique discussed in Sections 2.18.5.1 and 2.18.6.5.1 can be used. The Doppler slope ka for instance
can be estimated by using a matched ﬁlter bank, the fractional Fourier transform or the Wigner-Ville
distribution in combination with the Radon transform. Due to their importance they are discussed in
detail.
In the following explanations for simplicity the single-channel moving point target signal model
is used. However, the application of the presented detection and parameter estimation methods is not
limited to the single-channel case. The methods also can be applied on clutter suppressed multi-channel
signals almost without restrictions.
2.18.7.1 Matched ﬁlter bank
The basic principle of a matched ﬁlter was discussed in Section 2.18.2.3. It was shown that a signal can
be focused by performing a convolution with a proper reference function. Also a moving target signal
can perfectly be focused if the proper reference function is applied [21]. The proper azimuth reference
function for focusing the moving target signal is given as
ha(t) ∼= exp
	
−j

−2π fDCt + πkat2 −2
3πqt3

.
(18.108)
However, the Doppler parameters fDC, ka, and q are unknown in advance. They need to be estimated.
This can be done by convolving the range compressed moving target signal successively with different
azimuth reference functions. For each of these functions different Doppler parameter are assumed.
The estimated Doppler parameters ˆfDC, ˆka, and ˆq are obtained from the reference function that after
convolution results in the highest peak value of the IRF. The successive convolution with different

964
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
FIGURE 18.34
Google Earth image of the Strait of Gibraltar overlaid with the KML ﬁle obtained from the TerraSAR-X/TanDEM-
X large along-track baseline GMTI processor [55]. The color coded symbols (color is velocity dependent)
mark the estimated “true” geographical positions of the automatically detected ships, also the displaced
ship images in white color are visible.
reference functions is called “Matched Filter Bank” and can be considered as a maximum likelihood
estimator for the Doppler or motion parameters [56].
Principally the moving target signal has to be extracted from the range compressed data array before
the matched ﬁlter bank can be applied [47]. For this task the range history tracking method presented
in Section 2.18.6.4.1 can be used for example. However, as a brute force method also two-dimensional
matched ﬁlters can be constructed taking additionally into account the range history of the target signal.
Each (pre-detected) pixel of the range compressed data array has then to be convolved with a set of
two-dimensional matched ﬁlters. One can conceive that this method has a high computational load and is
rather time consuming. However, the method may be of importance for spaceborne systems which suffer
from low SNR values. The advantages are the higher compression gain and the possibility to estimate

2.18.7 Doppler Parameter Estimation: Basic Methods
965
the parameters from fast moving targets aliased in Doppler [57]. The minimum PRF requirement given
in (18.62) is not applicable in this case. A lower PRF resulting in less range ambiguities can be used.
Additionally, the swath width (cf. Figure 18.3) of the SAR system can be increased [1] by lowering the
PRF.
The moving target signal can also be extracted “by chance” using the method discussed in Section
2.18.6.4.2. With this method successive azimuth lines are extracted. The disadvantage is that no direct
information about the range history is preserved. In this case the matched ﬁlter bank is not very sensitive
to the Doppler shift fDC. However, the Doppler shift or equivalently the across-track velocity can be
estimated using ATI. If additionally the quadratic coefﬁcient q is neglected (it only has a signiﬁcant
contribution at large observation times) a much simpler azimuth reference function can be used:
ha(t) = exp[−jπkat2].
(18.109)
The equivalent in Doppler domain is given as
Ha( fa) ∼= exp
	
jπ 1
ka
f 2
a

.
(18.110)
IthastobekeptinmindthatwiththisreferencefunctiononlytheDopplerslope ˆka ofthemovingtarget
signal can be estimated. After focusing with this reference function the target still appears displaced
from its actual position.
An example of the application of a matched ﬁlter bank on real dual-channel airborne data is shown
in Figure 18.35. On the left side a SAR image containing four targets moving on a runway with
different along-track velocities is shown. Target 2 moved with 10 km/h. The azimuth line containing
“Target 2” was extracted from the clutter suppressed DPCA image and the azimuth compression was
removed. Afterwards the matched ﬁlter bank was applied. The matched ﬁlter bank output, denoted as
“Matched Filter Map,” is shown on the right, once in its two-dimensional representation and once in
its 3D representation. The target is represented by the focused peak. The peak position corresponds to
a certain estimated Doppler slope and to a certain azimuth position. In the example the target moved
only in along-track direction (vy0 = 0 and ay = 0) so that with (18.100) the along-track velocity vx0
can be computed easily (the negative sign in the image is due to the antiparallel motion with respect to
the ﬂight path).
As already explained, the application of the matched ﬁlter bank is not limited to azimuth lines
containing only one moving target signal. In fact a multi-target scenario can be resolved as shown in the
example depicted in Figure 18.36. Here an azimuth line of interest containing a part of the Autobahn
A8 near Chiemsee, Germany, where several targets have moved was extracted. In the SAR image on the
left the targets are severely blurred in azimuth and cannot be recognized and separated. However, in the
matched ﬁlter map of the DPCA signal each target appears as a focused peak at a certain azimuth and
Doppler slope position. Thus, a matched ﬁlter bank not only can be used for parameter estimation, but
also for target detection and target separation. It can deal with multi-component LFM signals. Target
detection in the matched ﬁler map either can be performed by applying a certain amplitude threshold
or by comparing the sharpness of the peaks with analytical sharpness functions [27].

966
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
moving target
DPCA Matched Filter Map
azimuth
along-track velocity
10 km/h (DGPS)
Target 2
Single-Channel E-SAR Image
range
azimuth
vx0
-10 km/h
Pos. 
5600
Pos. 
5600
FIGURE 18.35
Application of a matched ﬁlter bank on an extracted azimuth line (left: single-channel SAR image acquired
with DLR’s E-SAR sensor [58]; top right: 2D representation of the matched ﬁlter bank output; bottom: 3D
representation of the output).
2.18.7.2 Fractional Fourier transform
The fractional Fourier transform (FrFT) is a linear operator (no cross-terms in case of multi-component
LFM signals) and can be considered as a generalization (or rotation with rotation angle αFr) of the
conventional Fourier transform [59]. The FrFT has found many applications like swept-frequency
ﬁlters, time-variant ﬁltering and multiplexing, pattern recognition and the study of time-frequency
distributions. It is also known, that the Radon transform [60] of the Wigner spectrum is equal to the
magnitude square of the fractional Fourier transform. Filtering in the fractional Fourier domain, rather
than in the ordinary Fourier domain, allows one to decrease the mean square error in the estimate of a
distorted and noisy signal [61].
The principle of the FrFT is sketched in Figure 18.37. After application of the FrFT the signal energy
in the fractional Fourier domain is integrated along the fractional time axis tFr. For LFM signals the
application of the FrFT with the optimum rotation angle αFr,opt (in this case the fractional time axis
tFr is parallel to time-frequency history of the LFM signal) results in a sharp spectrum with maximum
peak amplitude. Due to this behavior, which for LFM signals is equivalent to pulse compression and
matched ﬁltering, the FrFT is also attractive for SAR-GMTI [62].

2.18.7 Doppler Parameter Estimation: Basic Methods
967
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
azimuth
along-track velocity
(Doppler slope)
Detail 17
Detail 19
Detail 20
Detail 21
Detail 22
Detail 16
range
azimuth
azimuth 
line of 
interest
FIGURE 18.36
Single-channel SAR image acquired with E-SAR with marked azimuth line of interest (left) and corresponding
DPCA matched ﬁlter bank output (right).
Conventional FT
Fractional FT
Fr
fa
fa
fa
s(t)
s(t)
FIGURE 18.37
Comparison between conventional Fourier transform (left) and Fractional Fourier transform (right) for a LFM
signal s(t).
The application of the FrFT for estimating the Doppler slope ka is quite similar to the matched
ﬁlter bank approach. Instead of applying different matched ﬁlters for focusing now the FrFT is applied
successively on the extracted range compressed data whereby each time a different rotation angle αFr
is used. The rotation angle corresponds to the Doppler slope in the following way [35]:

968
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
αFr = acot

ka
N
PRF2

= atan

−PRF2
kaN

,
(18.111)
where the ratio between the number of samples N and the PRF is used for normalization purposes. The
estimate of the Doppler slope ˆka is then computed with this equation using the optimum rotation angle
αFr,opt which maximizes the peak amplitude of the spectrum.
As with the matched ﬁlter bank also the FrFT can cope with multi-component LFM signals as shown
in Figure 18.38. On the top the “Fractional Spectra Map” is depicted. This map is obtained by successive
Fractional Spectra Map
|Amplitude|²
Target 1
Target 2
Target 3
Target 1
Target 2
Target 3
FIGURE 18.38
Fractional spectra map (top) containing three simulated moving target signals with different Doppler slopes
embedded in white Gaussian noise. At the bottom the cuts along the optimum rotation angle αFr,opt for each
of the signals are shown.

2.18.7 Doppler Parameter Estimation: Basic Methods
969
filter
window
spectrum
of chirp
FrFT
with
Fr,opt
FrFT
with
-
Fr,opt
center
bandpass
Time-Frequency
Representation
Fractional Spectrum
Disturbed Azimuth Signal in Time 
Domain (SNR 
-10 dB)
Fractional Spectrum
Time-Frequency
Representation of Filtered Signal
Filtered Azimuth Signal in Time 
Domain
FIGURE 18.39
Bandpass ﬁltering in the fractional Fourier domain.
application of the fractional Fourier transform with different rotation angles. At the bottom for each of
the three moving target signals the spectrum obtained by using the optimum rotation angle is shown.
In contrast to the matched ﬁlter bank the application of the FrFT has higher computational cost but
also some advantages. For instance, bandpass ﬁltering can be applied directly in the fractional Fourier
domain as depicted in Figure 18.39. By this orthogonal interferences can be ﬁltered out and multi-
component LFM signals can be separated from each other and extracted from the data. After applying
the inverse FrFT on the bandpass ﬁltered signal using -αFr,opt as rotation angle, the clutter and noise
suppressed moving target signal is obtained in the time domain.
2.18.7.3 Time-frequency analysis
One application of time-frequency (TF) analysis in the ﬁeld of GMTI is the estimation of the instan-
taneous Doppler frequency fa of the moving target signal. From the estimated instantaneous Doppler
frequency (cf. (18.18)) the phase history ϕa of the range compressed moving target signal can be com-
puted by integration [63]:
ϕa(t) = 2π
 t
t′=t0
fa(t′)dt′ + ϕ(t0),
(18.112)
where ϕ(t0) is an unimportant constant phase term. With the estimated phase a proper reference function
ha(t) can be constructed. With this reference function even targets in non-linear motion can be properly

970
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
antenna pattern,
RCS, clutter, residual 
range cell migration
magnitude shape
DPCA Pseudo Wigner-Ville Distribution
time (azimuth)
Doppler frequency
10 km/h (DGPS)
Target 2
Single-Channel E-SAR Image
ka
-100 Hz/s
vx0
-9.93 km/h
range
azimuth
FIGURE 18.40
Application of the Pseudo Wigner-Ville Distribution (PWVD) on an extracted azimuth line (left: single-channel
SAR image; top right: time–frequency map as output from the PWVD; bottom right: 3D representation of
the output).
focused. Thus, the application of the reference function can already be considered as a simpliﬁed ISAR
imaging method.
Before the phase history can be computed with (18.112) it is necessary to estimate the Doppler
frequency fa. For this purpose a suitable TF transform has to be applied on the range compressed
moving target signal. Probably the best known linear TF transform is the short-time Fourier transform.
As disadvantage a trade-off between time and frequency resolution has to be made: either a small time
or a small frequency resolution can be obtained. It is impossible to get both simultaneously. In contrast
the Wigner-Ville distribution (WVD) is the TF distribution having the best time-frequency resolution
[64,65]. However, since it is a quadratic TF transform cross-terms and interferences may occur if the
WVD is applied on multi-component LFM signals. To avoid these issues or to keep at least the negative
inﬂuences at a low level, clutter suppression and signal separation has to be performed prior to its use,
e.g., by applying DPCA and range history tracking. In [17] it is shown how the Pseudo Wigner-Ville
Distribution (PWVD) can be used for Doppler parameter estimation and ISAR imaging.
In Figure 18.40 an example is shown where the PWVD is used for estimating the Doppler slope ka
of the moving target signal. The PWVD was applied on the same data set used in Section 2.18.7.1 for
the explanation of the matched ﬁlter bank principle.

2.18.8 Space-Time Adaptive Processing
971
3D
View
1
2
Target 1
Target 2
Target 2
Target 1
2
1
Target 1
Target 2
range
azimuth
Target 1
Target 2
Pseudo Wigner-Ville Distr.
Pseudo Wigner-Ville Distr.
Single-Channel E-SAR Image
Radon Transform
Azimuth
Line
FIGURE 18.41
Application of the Radon transform on the Pseudo Wigner-Ville Distribution of moving target signals (left:
single-channel SAR image with azimuth line containing two moving targets; top middle and right: PWVD of
the azimuth line; bottom right and middle: result of the Radon transform).
2.18.7.4 Radon transform
Also the Radon transform [60] applied on the TF representation (i.e., the Wigner-Ville spectrum) of the
moving target signal can be used for target detection and Doppler slope estimation [66]. An example is
shown in Figure 18.41. However, nowadays algorithms relying on the Radon transform of the Wigner-
Ville spectrum are replaced increasingly by algorithms using the fractional Fourier transform.
2.18.8 Space-time adaptive processing
The intention of this section is to provide a short introduction to space-time adaptive processing (STAP).
A comprehensive tutorial is given in the STAP chapter of the ELSEVIER e-reference. Further reading
can be found in [4,37,43,67].
STAP is a two-dimensional ﬁltering technique. It operates in the angle-Doppler plain sketched exem-
plarily in Figure 18.42. The clutter suppression is performed by beamformers that take into account
the space-time nature of the received signals. With the beamforms nulls in the angle-Doppler beam-
pattern can be placed. Doppler histories and angular directions of moving target signals are no longer

972
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
Normalized Angle
Angle Projection
(1-D spatial clutter distribution)
Target
White Noise
Jammer
2-D Clutter Power
Spectral Density
Space-
Frequency
Filter
FIGURE 18.42
Angle-Doppler plane.
rigidly coupled. The optimum beamformer or weight vector, respectively, is given in (18.90) in Section
2.18.6.2.2. The difference to adaptive clutter suppression treated in Section 2.18.6.2.2 is that the steer-
ing vector d can be adapted to certain signal properties for parameter estimation purposes. However,
most of the state-of-the-art STAP algorithms only estimate the line-of-sight velocity vr0 (related to the
Doppler shift fDC) and the direction-of-arrival angle ψDOA, from which the true target position can be
computed. The target’s along-track velocity vx0 is not estimated.
2.18.8.1 Joint domain STAP
Originally STAP was designed to operate in the time domain (note that the data must not be
co-registered). STAP processing operates on the radar data cube depicted on the right in Figure 18.43.
The data cube is convenient for visualizing subsequent space-time processing although the radar pro-
cesser does not store the data in the format shown in the ﬁgure [68]. Each data cube corresponds to a
single coherent processing interval (CPI).
The page of the data cube corresponding to the kth range cell is
Z =
⎛
⎜⎜⎜⎝
[Z]11
[Z]12
. . .
[Z]1N
[Z]21
[Z]22
. . .
[Z]2N
...
...
. . .
...
[Z]M1
[Z]M2
. . . [Z]M N
⎞
⎟⎟⎟⎠,
Z ∈CM×N,
(18.113)

2.18.8 Space-Time Adaptive Processing
973
1
ADC
w1
*
z1
2
ADC
w2
*
z2
3
ADC
w3
*
z3
M
ADC
wM
*
zM
+
yout = wHz
da
da
s
Uniform Linear Array
Beamformer
N … number of temporal samples
M … number of receiving antennas
L
… number of range samples
RW ... clutter-plus-noise covariance matrix
The Radar Data Cube
1
N
M
1
Pulse
slow time
1
L
RX Sub-Array
kth range cell
Optimum weighting vector: w = RW
-1d
FIGURE 18.43
Uniform linear array beamformer (left) and radar data cube (right).
where M is the number of RX channels and N is the number of temporal samples per RX channel. The
matrix in previous equation can be vectorized by stacking each succeeding column one beneath the
other. This yields the space-time snapshot for the kth range cell, i.e.,
z = [z11, . . . , zM1, . . . , z1N, . . . , zM N]2 = [zT
1, . . . , zT
N]T,
z ∈CM N×1,
(18.114)
where the elements [Z]mn are abbreviated as zmn. The space-time snapshot in general is composed of
z = s + c + n,
(18.115)
where s denotes the moving target signal, c the clutter and n the uncorrelated component due to thermal
receiver noise or sky noise. The multi-channel signal for STAP often is modeled as [8]
s(u(t)) = ae−j 4π
λ r(t)Dt(u(t))
⎡
⎢⎢⎢⎢⎣
Dr,1(u(t))e j 2π
λ u(t)x1
Dr,2(u(t))e j 2π
λ u(t)x2
...
Dr,M(u(t))e j 2π
λ u(t)xM
⎤
⎥⎥⎥⎥⎦
= ae−j 4π
λ r(t)Dt(u)d(u),
(18.116)
where a is a complex amplitude describing the reﬂectivity of the scatterer, r(t) denotes the range to
the antenna array center, Dt(u) and Dr,m(u) are the transmit and receive antenna characteristics of the

974
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
mth channel, xm and denotes the antenna phase center positions in azimuth direction with respect to
the array origin, and u(t) is the directional cosine. It is assumed that the antenna array center origin is
freely chosen at the center of the array, so that 2
m xm = 0. The common phase multiplier e−j 4π
λ r(t)
represents the conventional azimuth chirp used for classical SAR imaging via azimuth compression or
matched ﬁltering.
The space-time processor linearly combines the elements of the space-time snapshot by applying a
weight vector. As result at the output of the space-time processor a scalar is obtained
yout = wHz,
(18.117)
where H denotes conjugate transposition and w is the complex weight vector of dimension M N ×1. The
optimal weight vector maximizes the output SCNR and takes, under the assumption of homogeneous
Gaussian clutter, the form
w = R−1
W d,
(18.118)
where RW is the interference covariance matrix of dimension M N × M N and d is the steering vector
of dimension M N×1.
In practice both RW and d are unknown and need to be estimated. Thus, instead of (18.118) an
estimate of the weight vector in the form of
-w = -R−1
W v,
-w ∈CM N×1,
(18.119)
is applied, where -RW is an estimate of RW and v is a surrogate for d. This approach is known as sample
matrix inversion (SMI). It is common to compute the covariance matrix estimate as
-RW = 1
K
K
.
k=1
zkzH
k ,
-RW ∈CM N×M N,
(18.120)
where zk of dimension M N × 1 are known as secondary training data. Conventionally K data ranges
are used for training (i.e., the averaging is performed along range). To avoid target self-whitening the
cell under test as well as cells where already a target has been detected should be excluded from the
data.
2.18.8.2 Post-doppler STAP
Since the classical STAP is computationally inefﬁcient and additionally requires a large number of
training cells, STAP algorithms needing lower computational power and less training cells have been
developed.
With a linear transformation the space-time snapshot z can be projected into a lower dimensional
subspace (= Reduced-Dimension STAP) [68]:
˜z = THz,
T ∈CM N×J,
(18.121)
where T is the transformation matrix, ˜z has dimension J ×1 with J ≪M N. The transformation matrix
T is independent of the data. In contrast to the joint-domain STAP the computational burden for matrix

2.18.8 Space-Time Adaptive Processing
975
inversion drops from O(N 3M3) to O(J 3). The transformation of the steering vector and the optimal
weight vector are given as ˜d = THd and ˜w = 3R−1
W ˜d, respectively. The estimate of the covariance matrix
again can be computed in the same manner as before, but now using the transformed data ˜z instead of z.
The adaptive weight vector using the estimated covariance matrix and a surrogate of the steering vector
is given as -3w = -3R
−1
W ˜v.
A practically implementable and efﬁcient Reduced-Dimension STAP algorithm is Post-Doppler
STAP [4]. The space-time snapshot given in (18.114) is transformed to Doppler domain before STAP
processing takes place. For the period where target and clutter remain in the same range-Doppler
resolution cell, the measured space-time snapshot can be expressed by the random vector [4,8]
Z(ut, fa) = as(ut, fa) + C( fa) + N( fa),
Z ∈CM×1,
(18.122)
where a is a complex constant comprising the target’s RCS among others and C + N is the clutter-plus-
noise interference.
The optimum detection for one range-Doppler resolution cell, under the assumption of homogeneous
Gaussian clutter, is achieved by comparing [4]
Topt(z) =
***dH(ut, fa)R−1
W ( fa)z( fa)
***
2
(18.123)
to a threshold. Clutter suppression is performed by multiplying each Doppler frequency bin fa of
the signal vector z (i.e., the space-time snapshot transformed to Doppler domain) with the inverse of
the clutter-plus-noise covariance matrix R−1
W ( fa). A target match (i.e., matched ﬁltering) is performed
afterwards by multiplying the intermediate result with the complex conjugated and transposed steering
vector dH (i.e., the expected moving target signal). With this matched ﬁltering operation the Doppler
shift fDC (which is proportional to the line-of-sight velocity vr0, cf. (18.31)) and the direction-of-arrival
angle ψDOA of the moving target signal (from which the true azimuth position can be computed).
The clutter covariance matrix for each Doppler frequency bin can be estimated from the data by
performing averaging in range:
-RW( fa) = 1
k
k
.
k=1
z(rk, fa)zH(rk, fa),
-RW( fa) ∈CM×M.
(18.124)
The resulting detection performance in the optimum case is directly proportional to the remaining output
SCNR of the optimum ﬁlter given as
SCNR(ut, vr0) = |a|2dH(ut, vr0)R−1
W (ut, vr0)d(ut, vr0).
(18.125)
It can be used for analyzing the detection performance of a given system design [4,8]. Maximizing the
SCNR results in a maximized probability of detection Pd for a ﬁxed false alarm rate Pfa.
A visualization example of the SCNR is given in Figure 18.44. Here ut and vr0 are substituted by
the direction-of-arrival angle ψDOA and the Doppler shift fDC.

976
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
FIGURE 18.44
SCNR (in dB) as a function of Doppler frequency and direction-of-arrival angle.
Under assumption of homogeneous Gaussian clutter and non-ﬂuctuating target RCS (Swerling-0
case) the probability of detection can be computed analytically as [68]
Pd =
 ∞
βT
x exp
	
−(x2 + a2)
2

I0(αx)dx
= 1 −
 βT
0
x exp
	
−(x2 + a2)
2

I0(αx)dx,
(18.126)
where I0(·) is the modiﬁed zero-order Bessel function of the ﬁrst kind and α2 is given as
α2 = 2 · SCNR.
(18.127)
The normalized detection threshold βT calculates to
βT =
4
−2 ln Pfa.
(18.128)
where Pfa is the desired false alarm rate.
The probability of detection for a given false alarm rate can either be plotted as a function of SCNR,
or, more relevant in the ﬁeld of GMTI, as a function of line-of-sight velocity. An example is shown
in Figure 18.45. The minimum detectable velocity (MDV) can directly be read off. For achieving a
probability of detection of 0.9 for given SNR and CNR values of 20 dB, the MDVs are approx. 1 m/s
(=3.6 km/h) and 1.5 m/s (=5.4 km/h) for false alarm rates of 10−5 and 10−9, respectively.
Most STAP techniques where developed to be used with multi-channel airborne systems. Airborne
STAP techniques have in contrast to spaceborne techniques the following advantages:
– High SNR values so that only a small amount of temporal samples has to be considered (at state-of-the
art airborne systems 64–256 azimuth samples of each RX channel are used).

2.18.8 Space-Time Adaptive Processing
977
FIGURE 18.45
Probability of detection for an exemplary system with assumed values of SNR = CNR = 20 dB as a function
of line-of-sight velocity for two different false alarm rates.
– Due to the small amount of samples quadratic and higher order phase terms of the moving target
signals can be neglected (but that also implies that the motion parameters normally causing these
quadratic and higher order phase terms cannot be estimated with the methods presented in Sections
2.18.6.5 and 2.18.7) so that in most cases a simple FFT is sufﬁcient for focusing without applying a
matched ﬁlter bank.
– Due to the small amount of samples the range cell migration can be neglected.
The successful application of STAP techniques on multi-channel spaceborne systems is more chal-
lenging. Since spaceborne systems suffer from low SNR signiﬁcantly more temporal samples of the
moving target signal need to be integrated coherently for ending up with a sufﬁcient target detection
performance. Thus, especially for systems with high range resolution, the range cell migration of the
target signal has to be taken into account (cf. Section 2.18.4.1) and a matched ﬁlter bank has to be
applied (cf. Section 2.18.7.1). Promising novel techniques are the ISTAP (imaging STAP) and EDPCA
(extended DPCA) techniques introduced recently in [39,40].
2.18.8.3 EDPCA
The Extended Displaced Phase Center Antenna Technique (EDPCA) is an extension of the DPCA and
ATI methods to three or more channels [39,40]. The ﬂow chart of the algorithm is shown in Figure 18.46.
The SAR compression ﬁlter is matched to the moving target parameters for maximizing target’s SNR.
For this task, the application of a bank of SAR processing ﬁlters is necessary. That means that for each
of the M complex SAR images several times an adapted range cell migration correction and azimuth
compression has to be performed. The number of necessary iterations depends on the range resolution
and the accepted loss in SCNR compared to the optimum case.
The clutter cancellation ﬁlter is either derived from the estimated clutter-plus-noise covariance matrix
or pre-computed using the known system, instrument and geometry parameters. EDPCA is partially
adaptive and can be used with an arbitrary number of RX channels.

978
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
The empirical clutter-plus-noise covariance matrix is estimated by averaging the measured data
vector over Nr range cells and Na azimuth cells (note that EDPCA operates in contrast to Post-Doppler
STAP on fully compressed data) [69]
-RE(ϑ) =
1
Nr Na
Rmax
.
r=Rmin
Tmax
.
T =Tmin
ZE(r, T , ϑs)ZH
E(r, T , ϑs)
∈CM×M,
(18.129)
where in the parameter vector ϑs all moving target parameters (i.e., along-track, across-track or line-of-
sight velocity) used for adapted SAR are condensed. The clutter-plus-noise covariance matrix is only of
dimension M × M (M = number of RX channels) and is thus invertible with low computational power
(∼= O(M3)).
For achieving a good performance the clutter-plus-noise covariance matrix should be estimated for
each image pixel under test. A large number of range and azimuth cells should be used for averaging.
The pixel under test and a guard zone should be excluded from training. Already detected targets should
also be excluded.
The normalized test statistics is given as [69]
TEDPCA(r, T , ϑs) =
***dH
E(ϑs)R−1
E (ϑs)ZE(ϑs)
***
2
dH
E(ϑs)R−1
E (ϑs)dE(ϑs)
≥ηE,
(18.130)
where dE is the steering vector and ηE is a CFAR threshold.
What is not shown in the ﬂow chart in Figure 18.46 is a clustering stage, where several pixel-based
detections of the same target are clustered to only one physical target.
2.18.8.4 ISTAP
Imaging space-time adaptive processing (ISTAP) is a combination of Post-Doppler STAP and SAR
[39,40]. As with Post-Doppler STAP clutter cancellation is performed in the Doppler domain. However,
there is no segmentation into short coherent processing intervals so that all the data are coherently
processed. Thus, high SCNR values can be achieved so that the ISTAP technique is well suited for
spaceborne systems.
The ﬂow chart of ISTAP is shown in Figure 18.47. As with EDPCA the SAR compression ﬁlter
is matched to the moving target parameters for maximizing the target SNR. Again a bank of SAR
processing ﬁlters is necessary. However, ISTAP requires less computational power since the clutter-
plus-noise covariance needs only to be estimated once and not for every iteration. Furthermore, also
clutter cancellation needs to be performed only once.
The empirical Doppler-dependent clutter-plus-noise covariance matrix is estimated by averaging the
measured data vector over Nr range cells, identical to conventional Post-Doppler STAP [70]:
-RI( fa) = 1
Nr
Rmax
.
r=Rmin
ZI(r, fa)ZH
I (r, fa)
∈CM×M.
(18.131)
Again, the clutter-plus-noise covariance matrix is only of dimension M × M and is thus invertible
with low computational power (∼=O(M3)).

2.18.9 Conclusion and Future Trends
979
range
azimuth
RX 1
range
azimuth
RX 2
range
azimuth
RX M
Pre-Processing: - Range compression
- Co-Registration
- Calibration
range
azimuth
RX 1
range
azimuth
RX 2
range
azimuth
RX M
Range cell migration correction
Azimuth compression
range
azimuth
RX 1
range
azimuth
RX 2
range
azimuth
RX M
Covariance matrix estimation and clutter cancellation 
range
azimuth
CFAR detection + target parameter estimation
repeat for different vx0,vy0
FIGURE 18.46
Processing chain for EDPCA.
The clutter-plus-noise covariance matrix needs to be estimated for each Doppler bin.
The normalized test statistics for ISTAP is given as [70]
TISTAP(r, T , ϑs) =
***
5
Ha( fa, ϑs)dH
I ( fa, ϑs)R−1
I ( fa)ZI( fa, ϑs)d fa
***
2
5
dH
I ( fa, ϑs)R−1
I ( fa)dI( fa, ϑs)d fa
≥ηI,
(18.132)
where Ha is the SAR transfer function (only the Doppler slope is considered but not the shift) which
maximizestheSNRofthetargetwithparameterϑs, dI isthesteeringvectorandηI istheCFARthreshold.
2.18.9 Conclusion and future trends
A tutorial for GMTI with multi-channel SAR systems was provided. The SAR principle was explained
and a single- and multi-channel moving point target signal model was derived. A special focus was laid
on the effects caused by moving target signals in the SAR images. The knowledge about these effects
is essential for understanding the different parameter estimation methods. The classical dual-channel
techniques ATI and DPCA and their limitations were discussed in detail, since they are currently of

980
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
range
azimuth
RX 1
range
azimuth
RX 2
range
azimuth
RX M
Pre-Processing:-Range compression
-Remove aperture switch. time delay
-Calibration
range
Doppler
RX 1
range
Doppler
RX 2
range
Doppler
RX M
Covariance matrix estimation and clutter cancellation
range
Doppler
RX 1
range
Doppler
RX 2
range
Doppler
RX M
Beam forming
Range cell migration correction
Azimuth Compression
range
azimuth
CFAR detection + target parameter estimation
repeat for different vx0,vy0
FIGURE 18.47
Processing chain for ISTAP.
special importance for state-of-the-art spaceborne SAR-GMTI systems. A general GMTI processing
chain was presented and basic Doppler parameter estimation methods were introduced. Also a short
introduction to STAP, which is covered in detail by a separate chapter in the ELSEVIER e-reference,
was given.
The ongoing research in GMTI can be summarized as:
•
Improvement of the target detection performance and the reduction of false alarms.
•
Accurate and robust SAR-GMTI algorithms for spaceborne SAR-MTI systems.
•
Improvement of the position and motion parameter estimation performance. This is of special impor-
tance for spaceborne SAR-GMTI where due to low SNR and SCNR values large estimation errors
may arise. First promising techniques are ISTAP and EDPCA introduced in [39,40]. A different
method requiring a large along-track baseline was presented in [71].
•
Reduction of the system complexity and processing time. This is of special importance for affordable
real-time systems to be used for civilian trafﬁc monitoring. A suitable technique which also can be
combined with classical STAP was introduced in [72].
•
Trend to shorter wavelengths (e.g., Ka-band with wavelengths in the order of 8 mm): this allows for
smaller instruments enabling both high resolution and good GMTI performance.

2.18.9 Conclusion and Future Trends
981
Table 18.2 Summary of GMTI Algorithms
Estimation accuracy
Clutter
Along-track
Across-track
Prob. of
Comput.
Algorithm
Cancell.
Adaptive
# RX Ch.
Position
velocity
velocity
detect.
load
Single-
channel
(general)
No
No
1
Very low
Good
Very low
Very low
Low/ Medium
Matched
ﬁlter
bank
No
No
≥1
No
Good
No
Low
Medium
Fractional
fourier
transform
Yes
No
≥1
No
Good
No
Low
Medium
DPCA
Good
No
2
No
No
No
Good
Low
ATI
No
No
2
Low
No
Low
Good
Low
DPCA-ATI
Good
No
≥3
Good
Good
Good
Good
Medium
Post-doppler
STAP
Very good
Yes
≥2
Good
No
Good
Good
Medium
EDPCA
Very good
Partially
≥2
Good
Good
Good
Very good
Highest
ISTAP
Very good
Yes
≥2
Very good
Good
Very good
Very good
High

982
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
•
Low PRF GMTI algorithms which can be used together with high-resolution wide swath (HRWS)
SAR imaging.
2.18.9.1 Summary of algorithms
In Table 18.2 a summary of the algorithms treated in this tutorial is given. Also the parameter estimation
accuracy and the required computational load are assessed in a qualitative way.
Applications:
– Detection and parameter estimation of moving targets in the military ﬁeld.
– Civilian trafﬁc monitoring of road vehicles and ships.
Open Issues and Problems:
– Accurate estimation of moving target’s along-track velocity, especially without the negative inﬂuence
of accelerations.
– Improvement of the moving target parameter estimation accuracy of spaceborne GMTI algorithms.
– Reduction of false alarms.
Glossary
ATI
along-track interferometry; the phase differences of the signals received by two anten-
nas separated in along-track or ﬂight direction are measured. The phase difference is
related to moving target parameters.
Clutter
unwanted radar echos; for GMTI echos from the stationary background scene are
considered as clutter
DPCA
displaced phase center antenna; similar antenna arrangement as with ATI but instead
of the phases the amplitudes are evaluated. Commonly DPCA is used for suppressing
the clutter, i.e., the signals of stationary targets.
IRF
impulse response function; focused signal of a point target
(G)MTI
(ground) moving target indication; the detection of targets moving on ground and the
estimation of their geographical positions, their velocities and moving directions.
SAR
synthetic aperture radar; a side-looking imaging radar system exploiting the Doppler
effect due to platform motion for imaging
SCR
signal-to-clutter ratio
SCNR
signal-to-clutter-plus-noise ratio
SNR
signal-to-noise ratio
STAP
space-time adaptive processing
SWMF
stationary world matched ﬁlter; a two-dimensional ﬁlter used for SAR processing;
every conventional SAR processor is considered as a SWMF in this tutorial

References
983
Relevant Theory: Signal Processing Theory and Array Signal Processing
See Vol. 1, Chapter 3 Discrete-Time Signals and Systems
See Vol. 1, Chapter 12 Adaptive Filters
See Vol. 3, Chapter 19 Array Processing in the Face of Nonidealities
References
[1] K. Tomiyasu, Tutorial review of synthetic-aperture radar SAR with applications to imaging of the ocean
surface, Proc. IEEE 66 (1978) 563–583.
[2] M.I. Skolnik (Ed.), Radar Handbook, second ed., McGraw-Hill, 1990.
[3] I.G. Cumming, F.H. Wong, Digital Signal Processing of Synthetic Aperture Radar: Algorithms and Imple-
mentation, Artech House, 2005.
[4] J.H.G. Ender, Space-time processing for multichannel synthetic aperture radar, Electron. Commun. Eng. J.
11 (1999) 29–38.
[5] R.K. Raney, Synthetic aperture imaging radar and moving targets, IEEE Trans. Aerosp. Electro. Syst. AES-7
(3) (1971) 499–505.
[6] R. Werninghaus, S. Buckreuss, The terraSAR-X mission and system design, IEEE Trans. Geosci. Remote
Sens. 48 (2) (2010) 606–614.
[7] J.H.G. Ender, The airborne experimental multi-channel SAR system AER-II, in: 1st European Conference
on Synthetic Aperture Radar (EUSAR), Königswinter, Germany, March 1996, pp. 49–52.
[8] J.H.G. Ender, C.H. Gierull, D. Cerutti-Maori, Improved space-based moving target indication via alternate
transmission and receiver switching, IEEE Trans. Geosci. Remote Sens. 46 (12) (2008) 3960–3974.
[9] K. Bethke, S. Baumgartner, M. Gabele, D. Hounam, E. Kemptner, D. Klement, G. Krieger, R. Erxleben,
Air-and spaceborne monitoring of road trafﬁc using SAR moving target indication—Project TRAMRAD,
ISPRS J. Photogramm. Remote Sens. 61 (3–4) (2006) 243–259.
[10] D. Cerutti-Maori, J. Klare, A.R. Brenner, J.G.H. Ender, Wide area trafﬁc monitoring with the SAR/GMTI
system PAMIR, Trans. Geosci. Remote Sens. 46 (10) (2008) 3019–3030.
[11] S. Suchandt, H. Runge, H. Breit, U. Steinbrecher, A. Kotenkov, U. Balss, Automatic extraction of trafﬁc ﬂows
using terraSAR-X along-track interferometry, IEEE Trans. Geosci. Remote Sens. 48 (2) (2010) 807–819.
[12] S.V. Baumgartner, G. Krieger, Real-time road trafﬁc monitoring using a fast a priori knowledge based SAR-
GMTI Algorithm, in: IEEE International Geoscience and Remote Sensing Symposium (IGARSS), Honolulu,
Hawaii, USA, July 2010.
[13] (2012, March) Floating car data. <http://en.wikipedia.org/wiki/Floating_car_data>.
[14] W. Koch, R. Klemm, Ground target tracking with stap radar, IEE Proc. -Radar Sonar Navig. 148 (3) (2001)
173–185.
[15] V. Chen, H. Ling, Time-Frequency Transforms for Radar Imaging and Signal Analysis, Artech House
Publishers, 2002.
[16] P. Berens, U. Gebhardt, J. Holzner, ISAR imaging of ground moving vehicles using PAMIR data, in: Inter-
national Radar Conference—Surveillance for a Safer World (RADAR), Bordeaux, France, October 2009,
pp. 1–5.
[17] W. Rieck, Zeit-Frequenz-Signal-Analyse für Radaranwendungen mit synthetischer Apertur (SAR), Ph.D.
Dissertation, Rheinisch-Westfälische Technische Hochschule Aachen, 1997.
[18] S. Chiu, M.V. Dragosevic, Moving target indication via RADARSAT-2 multichannel synthetic aperture radar,
EURASIP J. Adv. Signal Process. 2010 (2010).

984
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
[19] J.C. Curlander, R.N. McDonough, Synthetic Aperture Radar: Systems and Signal Processing, Wiley-
Interscience, New York, 1991.
[20] A. Moreira, J. Mittermayer, R. Scheiber, Extended chirp scaling algorithm for air- and spaceborne SAR
data processing in stripmap and scanSAR imaging modes, IEEE Trans. Geosci. Remote Sens. 34 (5) (1996)
1123–1136.
[21] J.J. Sharma, The Inﬂuence of Target Acceleration on Dual-Channel SAR-GMTI (Synthetic Aperture Radar
Ground Moving Target Indication) Data, University of Calgary, Calgary, Alberta, Canada, Master Thesis,
October 2004.
[22] J.J. Sharma, C.H. Gierull, M.J. Collins, Compensating the effects of target acceleration in dual-channel
SAR-GMTI, IEE Proc. Radar Sonar Navig. 153 (1) (2006) 53–62.
[23] J.J. Sharma, The inﬂuence of target acceleration on velocity estimation in dual-channel SAR-GMTI, IEEE
Trans. Geosci. Remote Sens. 44 (1) (2006) 134–147.
[24] S. Baumgartner, G. Krieger, Acceleration-independent along-track velocity estimation of moving targets,
IET Radar Sonar Navig. 4 (3) (2010) 474–487.
[25] R.P. Perry, R.C. DiPietro, R.L. Fante, SAR imaging of moving targets, IEEE Aerosp. Electron. Syst. 35 (1)
(1999) 188–200.
[26] J. Jao, Theory of synthetic aperture radar imaging of a moving target, IEEE Trans. Geosci. Remote Sens. 39
(9) (2001) 1984–1992.
[27] F. Meyer, S. Hinz, A. Laika, R. Bamler, A-priori information driven detection of moving objects for trafﬁc
monitoring by sar, in: Proc. IEEE Int. Geosci. Remote Sens. Symp. IGARSS ’05, vol. 4, 2005, pp. 2932–2936.
[28] R.M. Goldstein, H.A. Zebker, Interferometric radar measurements of ocean surface currents, Nature 328
(1987) 707–709.
[29] H.A. Zebker, J. Villasenor, Decorrelation in interferometric radar echoes, IEEE Trans. Geosci. Remote Sens.
30 (5) (1992) 950–959.
[30] E. Rodriguez, J.M. Martin, Theory and design of interferometric synthetic aperture radars, IEE Proc. F Radar
Signal Process. 139 (2) (1992) 147–159.
[31] D. Just, R. Bamler, Phase statistics of interferograms with applications to synthetic aperture radar, Appl.
Optics 33 (20) (1994) 4361–4368.
[32] A. Budillon, G. Ferraiuolo, V. Pascazio, G. Schirinzi, Multichannel SAR interferometry via classical and
bayesian estimation techniques, EURASIP J. Appl. Signal Process. 2005 (20) (2005)3180–3193.
[33] A. Budillon, V. Pascazio, G. Schirinzi, Estimation of radial velocity of moving targets by along-track inter-
ferometric sar systems, IEEE Geosci. Remote Sens. Lett. 5 (3) (2008) 349–353.
[34] C.H. Gierull, Statistical analysis of multilook SAR interferograms for CFAR detection of ground moving
targets, IEEE Trans. Geosci. Remote Sens. 42 (4) (2004) 691–701.
[35] S. Chiu, Application of fractional fourier transform to moving target indication via along-track interferometry,
EURASIP J. Appl. Signal Process. 20 (2005) 3293–3303.
[36] F.R. Dickey, M.M. Sante, Final report on anti-clutter techniques, General Electric Co., Heavy Military
Electron. Dept., Syracuse, NY, Rep. No. R65EMH37, 1953.
[37] R. Klemm, Space-Time Adaptive Processing: Principles and Applications, IEE, UK, 1998.
[38] P. Lombardo, F. Colone, D. Pastina, Monitoring and surveillance potentialities obtained by splitting the
antenna of the COSMO-SkyMed SAR into multiple sub-apertures, IEE Proc. Radar Sonar Navig. 153 (2)
(2006) 104–116.
[39] D. Cerutti-Maori, I. Sikaneta, Optimum GMTI processing for space-based SAR/ GMTI systems—theoretical
deviation, in: European Conference on Synthetic Aperture Radar (EUSAR), Aachen, Germany, June 2010,
pp. 1–4.

References
985
[40] D. Cerutti-Maori, I. Sikaneta, Optimum GMTI processing for space-based SAR/ GMTI systems—simulation
results, in: European Conference on Synthetic Aperture Radar (EUSAR), Aachen, Germany, June 2010, pp.
1–4.
[41] C.H. Gierull, Digital Channel Balancing of Along-Track Interferometric SAR Data, Defence R&D Canada,
Ottawa, Canada, Technical Memorandum DRDC Ottawa TM 2003–024, March 2003.
[42] S. Chiu, C. Gierull, A. Durak, Clutter effects on ground moving targets’ interferometric phase, in: IEEE
Geoscience and Remote Sensing Symposium (IGARSS), vol. 4, Seoul, Korea, July 2005, pp. 2928–2931.
[43] J.R. Guerci, Space-Time Adaptive Processing for Radar, Artech House, 2003.
[44] C.P. Banahan, D. Perks, C. Baker, K. Woodbridge, GMTI clutter cancellation using real non-ideal data, IET
Radar Sonar Navig. 4 (2) (2010) 302–314.
[45] I.C. Sikaneta, J.-Y. Chouinard, Eigendecomposition of the multi-channel covariance matrix with applications
to SAR-GMTI, Signal Process. 84 (9) (2004) 1501–1535.
[46] C.H. Gierull, Moving Target Detection with Along-Track SAR Interferometry, Defence RD Canada–Ottawa,
Tech. Rep. DRDC Ottawa TR 2002–084, August 2002.
[47] C.H. Gierull, I.C. Sikaneta, Raw data based two-aperture SAR ground moving target indication, in: IEEE
Internation Geoscience and Remote Sensing Symposium (IGARSS), Toulouse, France, vol. 2, July 2003,
pp. 1032–1034.
[48] S.V. Baumgartner, G. Krieger, SAR trafﬁc monitoring using time-frequency analysis for detection and param-
eter estimation, in: IEEE International Geoscience and Remote Sensing Symposium (IGARSS), Boston,
USA, vol. 2, July 2008, pp. II-25–II-28.
[49] S.V. Baumgartner, M. Gabele, G. Krieger, K.-H. Bethke, S. Zuev, Trafﬁc monitoring with SAR: implica-
tions of target acceleration, in: 6th European Conference on Synthetic Aperture Radar (EUSAR), Dresden,
Germany, May 2006.
[50] F. Zhou, R. Wu, M. Xing, Z. Bao, Approach for single channel SAR ground moving target imaging and
motion parameter estimation, IET Radar Sonar Navig. 1 (1) (2007) 59–66.
[51] C.H. Gierull, Azimuth positioning of moving targets in two-channel SAR by direction-of-arrival estimation,
Electron. Lett. 40 (21) (2004) 1380–1381.
[52] F. Meyer, S. Hinz, A. Laika, D. Weihing, R. Bamler, Performance analysis of the TerraSAR-X trafﬁc moni-
toring concept, ISPRS J. Photogramm. Remote Sens. 61 (3–4) (2006) 225–242.
[53] S. Baumgartner, G. Krieger, Acceleration independent along-track velocity estimation of moving targets, in:
7th European Conference on Synthetic Aperture Radar (EUSAR), Friedrichshafen, Germany, vol. 4, June,
2008, pp. 207–210.
[54] AutomaticIdentiﬁcationSystem,June2011. <http://en.wikipedia.org/wiki/Automatic_Identiﬁcation_System>.
[55] S.V. Baumgartner, G. Krieger, Large along-track baseline SAR-GMTI: ﬁrst results with the TerraSAR-
X/TanDEM-X satellite constellation, in: Proceedings of the IEEE International Geoscience and Remote
Sensing Symposium (IGARSS), Vancouver, Canada, July 2011, pp. 1319–1322.
[56] S. Barbarossa, Detection and imaging of moving objects with synthetic aperture radar -Part 1: Optimal
detection and parameter estimation theory, IEE Proc. F 139 (1) (1992) 79–88.
[57] M. Gabele, I. Sikaneta, Motion parameter estimation of Doppler-Ambiguous moving targets in SAR-GMTI,
in: International Radar Symposium (IRS), Cologne, Germany, September 2007.
[58] R. Scheiber, P. Prats, M. Nannini, K. Macedo, C. Andres, J. Fischer, R. Horn, Advances in airborne SAR
interferometryusingtheexperimentalSARsystemofDLR,in:EuropeanMicrowaveWeek(EuMW),Horizon
House, Munich, Germany, October 2007, pp. 91–94.
[59] L.B. Almeida, The fractional Fourier transform and time-frequency representations, IEEE Trans. Signal
Process. 42 (11) (1994) 3084–3091.

986
CHAPTER 18 Multi-Channel SAR for Ground Moving Target Indication
[60] J. Radon, Über die Bestimmung von Funktionen durch ihre Integralwerte längs gewisser Mannigfaltigkeiten,
Berichte Sächsische Akademie der Wissenschaften, Leipzig, Mathematisch-Physikalische Klasse 69 (1917)
262–277.
[61] A. Kutay, H. Ozaktas, O. Ankan, L. Onural, Optimal ﬁltering in fractional Fourier domains, IEEE Trans.
Signal Process. 45 (5) (1997) 1129–1143.
[62] H.-B. Sun, G.S. Liu, H. Gu, W.-M. Su, Application of the fractional Fourier Transform to moving target
detection in airborne SAR, IEEE Trans. Aerosp. Electron. Syst. 38 (4) (2002) 1416–1424.
[63] S. Barbarossa, A. Farina, Detection and imaging of moving objects with synthetic aperture radar. 2. Joint
time-frequency analysis by Wigner-Ville distribution, IEE Proc. F. 139 (1) (1992) 89–97.
[64] T.A.C.M. Claasen, W.F.G. Mecklenbräuker, The Wigner distributiona tool for time-frequency signal analysis,
Part I: Continuous-time signals, Philips J. Res. 35 (3) (1980) 217–250.
[65] T.A.C.M. Claasen, W.F.G. Mecklenbräuker, The Wigner distributiona tool for time-frequency signal analysis,
Part II: Discrete time signals, Philips J. Res. 35 (4–5) (1980) 276–300.
[66] J.C. Wood, D.T. Barry, Radon transformation of time-frequency distributions for analysis of multicomponent
signals, IEEE Trans. Signal Process. 42 (11) (1994) 3166–3177.
[67] S. Barbarossa, A. Farina, Space-time-frequency processing of synthetic aperture radar signals, IEEE Trans.
Aerosp. Electron. Syst. 30 (2) (1994) 341–358.
[68] W.L. Melvin, A STAP overview, IEEE A&E Syst. Mag. 19 (1) (2004) 19–35.
[69] D. Cerutti-Maori, I. Sikaneta, A generalization of DPCA processing for multi-channel SAR/GMTI radars,
IEEE Trans. Geosci. Remote Sens. 51 (1) (2013) 560–572.
[70] D. Cerutti-Maori, I. Sikaneta, C.H. Gierull, Optimum SAR/GMTI processing and its application to the
radar satellite RADARSAT-2 for trafﬁc monitoring, IEEE Trans. Geosci. Remote Sens. (50) (10) (2012)
3868–3881.
[71] S.V. Baumgartner, G. Krieger, K.-H. Bethke, A Large along-track baseline approach for ground moving target
indication using TanDEM-X, in: International Radar Symposium (IRS), Cologne, Germany, September 2007.
[72] S.V. Baumgartner, G. Krieger, Fast GMTI Algorithm for trafﬁc monitoring based on a priori knowledge,
IEEE Trans. Geosci. Remote Sens. 50 (11) (2012) 4626–4641.

19
CHAPTER
Introduction to Inverse Synthetic
Aperture Radar
Marco Martorella
Dipartimento di Ingegneria dell’Informazione, University of Pisa, Pisa, Italy
CNIT—Radar and Surveillance Systems (RaSS) National Laboratory, Pisa, Italy
2.19.1 Introduction
Radar Imaging refers to the ability to form images of natural or man-made objects using Electro-
Magnetic echo location. As will become clearer later, coherent radars may have suitable speciﬁcations
that allow implementation of special features using speciﬁc signal processing. We may argue that, given
a suitable coherent radar, radar imaging can be provided by adding some “special” signal processing
to the received signal. Conventional radar images are typically represented as two-dimensional (2D)
images where a mapping function transforms the three-dimensional (3D) world into a 2D image. An
obvious comparison could be formulated with photographic images, as these are also the result of some
mapping from the 3D world into a 2D photographic image. However, there are several differences that
may be pointed out in regards of the type of mapping and image features. Radar images, as well as other
type of images (e.g., photographic, infra-red, X-ray images) are usually characterized by means of some
quality measurements, such as geometrical and radiometric resolution and signal-to-noise (SNR) ratio.
Pushed by the need to form high quality radar images that can be used in applications such as
automatic target recognition and classiﬁcation, researchers have designed a variety of radar imaging
processors. In this tutorial we will introduce the fundamental concepts at the base of radar imaging and
we will provide an overview of the most commonly used radar imaging techniques. Examples will be
also used throughout this chapter to clarify concepts and to show some radar imaging results.
2.19.2 Historical overview
We have to distinguish two starting points when considering the origins of radar imaging: one for
Synthetic Aperture Radar (SAR) and one for Inverse Synthetic Aperture Radar (ISAR). Although the
two approaches to radar imaging have quite a lot in common, there are some signiﬁcant differences that
mark a line between them. As mentioned in [1], the SAR concept was conceived in 1951 by Carl Wiley,
although the ﬁrst operational system (classiﬁed) was built in 1957 by the Willow Run Laboratories of
the University of Michigan for the US Department of Defense (DoD). Unclassiﬁed SAR systems were
successfully built by NASA in the 1960s. The ﬁrst spaceborne SAR system, SEASAT-A, was launched
in 1978. Although this spaceborne system was speciﬁcally designed for oceanographic purposes, it also
produced important results in other ﬁelds, such as in ice and land studies. The results obtained with
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-396500-4.00019-3
© 2014 Elsevier Ltd. All rights reserved.
987

988
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
SEASAT-A demonstrated the importance of radar imaging for the observation of the earth. Since then,
several spaceborne SAR systems have been launched that provide improved resolution, wider coverage
and faster revisit times. Several airborne SAR system have also been developed to overcome limitations
of spaceborne SAR systems, such as cost, revisiting time and resolution. After the ﬁrst experiments on
the 1960s operated by the NASA, other important missions have been accomplished, such as the SIR-A,
SIR-B and SIR-C missions, which ﬂew in 1981, 1984, and 1994, respectively. The history of ISAR began
later, when Walker and Aushermann, with their pioneering work [2,3] introduced the concept of radar
imaging of rotating objects with ﬁxed antennas. The main insight in their work was to exploit Doppler
information generated by the rotation of an object to separate echoes returning from different parts of the
object along a cross-range axis. Such Doppler separation, together with the time-delay separation (along
the radar range), produces a two-dimensional (2D) image, which can be mapped onto an image plane.
2.19.3 High resolution radar and radar imaging
The deﬁnition of an image as given by the IEEE is “a spatial distribution of a physical property such
as radiation, electric charge, conductivity, or reﬂectivity, mapped from another distribution of either
the same or another physical property.” Narrowing this deﬁnition to a radar image, we may deﬁne a
radar image as “a spatial distribution of the electromagnetic (EM) reﬂectivity of an object mapped from
a distribution of currents on the object’s surface.” The latter concept of mapping an object’s current
distribution onto an image of the object’s reﬂectivity function derives from the fact that a radar is able
to capture echoes of e.m. energy irradiated by the radar itself and backscattered from the object. The
backscattering effect is produced by the object because the incident e.m. ﬁeld induces a set of currents
on the object’s surface, which in turns produces a scattered e.m. ﬁeld that (in part) propagates back to
the radar. If a radar image has ﬁne resolution, the object’s reﬂectivity may be observed in ﬁne detail
with the result that it would be possible to spatially separate reﬂectivity contributions from different
parts of the object. It is quite intuitive that the ﬁner the resolution the more the detail that may be visible
in the image. A desirable radar imaging system would provide ﬁner resolution to allow characterizing
smaller and smaller scale objects.
Although 3D radar imaging is nowadays possible, we will consider the more usual concept of 2D
radar images. Therefore, we will be conscious that the mapping function that links the object of interest
with its image is mathematically representable with a function f : C3 →C2, where the symbol C
represents the set of complex numbers, as radar images are represented by complex numbers (I & Q or
magnitude and phase).
Radar images, as will be clearer later, are typically represented in cartesian coordinates, where one
axis is aligned with the radar range direction and the other with the cross-range direction (otherwise
indicated as azimuth direction). It is worth pointing out that the range direction is uniquely identiﬁed
by the orientation of the radar antenna (typically coincident with the antenna maximum gain direction).
In a 3D world, there are an inﬁnite number of directions that are orthogonal to the range direction,
therefore, the concept of cross-range direction becomes highly ambiguous if some constraints are not
applied that uniquely deﬁne such a direction. Nevertheless, a radar image will be identiﬁed as a mapping
of some physical quantity that is deﬁned in a 3D coordinate system onto a plane identiﬁed by the range
direction and a cross-range direction, which, as it will be clearer later, will depend on the radar-target
geometry and dynamics.

2.19.3 High Resolution Radar and Radar Imaging
989
Nevertheless, in order to enable radar imaging capabilities in a radar, sufﬁciently ﬁne resolution must
be achievable in both the range and cross-range directions. A desirable radar image will show ﬁne and
possibly similar resolution in both axes.
2.19.3.1 Resolution
The resolution is the minimum distance between two quantities at which a measurement system is said
to be able to distinguish two separate contributions. This general deﬁnition may be applied to all sorts
of measurements and the resolution may be expressed in terms of a speciﬁc measurement unit, e.g.,
meters for spatial resolution, Hertz for frequency resolution, and so on.
By applying the general deﬁnition of resolution to radar, this can be deﬁned a little more speciﬁcally as
the minimum distance along a given direction between two point-like scatterers of equal magnitude such
that the two scatterers can be distinguished by the radar. This concept is further explained in Figure 19.1.
The two scatterers may be distinguished if the two received echoes are sufﬁciently separated such that
a signal processing is able to detect both contributions separately. According to Rayleigh criterion, the
minimum distance that allows separating two echoes is equal to the echo half-power width.
Traditionally, in radar, we talk about range resolution to indicate the ability of the radar to distinguish
scatterers along the range direction. The same concept applies to azimuth and elevation resolution in
the azimuth and elevation planes.
We will now pay special attention to the Doppler resolution. The Doppler resolution is the ability of
the radar to distinguish two point-like scatterers where each scatterer produces a Doppler component due
to their radial motion with respect to the radar. The principle behind the Doppler frequency generation
can be explained in simple terms in the radar case. With reference to Figure 19.2, let a point like target
move with a given velocity v with respect to the radar. Therefore, the radar-target distance can be
approximated with the linear function R(t) = R0 + vRt. Assuming that a radar transmits a pure tone
sT (t) = A cos (2π f0t), the received signal can be written by taking into account the round-trip delay
and an amplitude attenuation:
sR(t) = B cos [2π f0(t −τ(t))],
(19.1)
where
τ(t) = 2
c R(t) = 2
c (R0 + vRt)
(19.2)
FIGURE 19.1
Radar resolution.

990
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
FIGURE 19.2
Doppler frequency.
and B < A. By substituting (19.2) in (19.1) we obtain
sR(t) = B cos [2π( f0 + fD)t + ϕ0],
where ϕ0 = −4π R0
λ
with λ =
c
f0 and the Doppler frequency can be deﬁned as fD = −2vR
λ , where vR
is the scatterer’s radial velocity and λ is the radar wavelength. The radar Doppler resolution, as will be
clear later, becomes important it is directly related to the cross-range resolution in Inverse Synthetic
Aperture Radar (ISAR) systems.
In radar imaging, the concept of resolution applies to range and cross-range, as they represent the
two coordinates in a radar image. Therefore, we can deﬁne the concept of radar image resolution as a
pair of values that indicate the range and cross-range resolution in the image.
In the following subsections, the concepts of range and cross-range resolution will be detailed and
methods for obtaining high range and cross-range resolution will be addressed.
2.19.3.2 High range resolution
In pulsed radar where the phase is not measured (or used), the range resolution is typically associated
with the transmitted pulse duration. In fact, as a ﬁrst approximation, a signal echo due to an ideal
scatterer, persists for a time interval equal to the length of the transmitted pulse. Therefore, we should
expect to be able to detect a second ideal scatterer when the echo of the ﬁrst scatterer vanishes, leading
to an expression for the range resolution equal to r = cT
2 , where T is the pulse duration [4]. Such
a concept is roughly represented in Figure 19.1, where the echoes relative to two ideal scatterers are
partly overlapped. It becomes evident that a minimum distance between two ideal scatterers exists, below

2.19.3 High Resolution Radar and Radar Imaging
991
which, the two echoes are largely overlapped and therefore the two contributions are not distinguishable
anylonger. Asﬁnitebandwidthsignalshaveinﬁnitedurationpulses, wewillusethedeﬁnitionofduration
at the point where peak power has reduced by 3 dB, which is consistent with the Rayleigh criterion.
In practice, all radar systems employ a matched ﬁlter, which ensures that a maximum SNR is obtained
at the ﬁlter output. It must be recalled that a matched ﬁlter produces the transmitted signal autocorrelation
function at its output when an echo is present at its input. The autocorrelation function has the following
properties:
1. It is the Fourier Transform of the Energy Spectral Density (ESD),
2. Bτ = 1,
where B is the transmitted signal bandwidth and τ is the relation signal duration at the output of the
matched ﬁlter.
The second property, which represents the uncertainty relationship of a Fourier Transform pair (in
this case, it is given by the autocorrelation and the ESD), indicates that to obtain short duration pulses
at the output of the matched ﬁlter wide bandwidth signals should be transmitted.
Although, short duration pulses provide a straightforward way to increase the bandwidth, this should
be discouraged as it has the drawback of reducing the transmitted energy (and hence the system sen-
sitivity), unless higher peak power pulses are used in transmission to compensate. Typically, phase
modulations are used to increase the signal bandwidth rather than amplitude modulation since they are
able to effectively increase the signal bandwidth without having to decrease the pulse duration, e.g.,
linear frequency modulated signals (or chirp signals) are typical phase modulated signals.
If we agree that two echoes relative to two separate scatterers can be distinguished only if the echoes
are separated by a delay equal to the pulse duration at the output of the matched ﬁlter (τ), then we can
say that the range resolution is related to the transmitted signal bandwidth by means of the following
expression:
R = c
2τ = c
2B .
(19.3)
The effect of using wide bandwidth transmitted signals in conjunction with a matched ﬁlter is called
pulse compression and it is a standard way to proceed to enable higher range resolution. The term pulse
compression comes from the simple fact that the duration of the pulse at the matched ﬁlter output is
shortened by a factor ρ = T
τ , namely compression factor, with respect the duration of the transmitted
pulse (T). As an example, if we want to achieve a range resolution of 1 m, we have to generate a signal
with a bandwidth of 150 MHz, independently of its duration, which corresponds to a non-modulated
signal of 1.5 ns of duration.
A side effect of the pulse compression is the presence of sidelobes in the compressed signal. Sidelobes
are unwanted signal peaks that may mask other echoes and they must be suppressed or attenuated as
much as possible. A performance indicator in terms of sidelobes is the Side Lobe Level (SLL), which
is deﬁned as ratio between the pulse peak and the highest sidelobe peak. For an unweighted signal, the
SLL is typically around −13 dB.
Both analog and digital modulations are typically used to obtain wide bandwidth waveforms. Chirp
signals are the most commonly used among analog modulations as they are easy to generate and they
show desired characteristics in terms of SLL and robustness to noise and Doppler effect. Alternatively,

992
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
FIGURE 19.3
Pulse compression—Chirp signal—Uncompressed (transmitted) pulse on the left and Compressed pulse
(Matched ﬁlter output) on the right.
Barker and pseudo-random digital codes can be used to generate digital phase modulated signals, which
have similar characteristics to those of chirp signals. The big advantage of pulse compression is that
high resolution can be achieved by transmitting long pulses, therefore maintaining high sensitivity at
long ranges.
An example of pulse compression is provided in Figure 19.3, where a chirp signal is considered as
transmitted signal.
2.19.3.3 High cross-range resolution
The ability to resolve scatterers in a cross-range direction is related to the angular separation in the same
direction. Traditionally, azimuth and elevation resolution were achieved by building wide antennas
since, approximately, the angular resolution is inversely proportional to the antenna size. For example,
the angular resolution of a rectangular antenna can approximately be calculated as follows:
αx ≃λ
Lx
,
(19.4)
where λ is the radar wavelength, Lx is the size of the antenna along a given cross-range direction (usually
named as azimuth and elevation) and αx is the angular resolution along the same cross-range direction
(expressed in radians). Although it is directly related to system parameters, speciﬁcally the antenna size
and the radar wavelength, the angular resolution is not sufﬁcient to provide high resolution needed for
radar imaging. The main reasons are that:
•
it refers to an angular domain and not a spatial domain (images should be scaled in spatial coordinates
and not angular coordinates),

2.19.4 Inverse Synthetic Aperture Radar
993
•
the cross-range resolution, which can be calculated from the angular resolution as shown in (19.5),
becomes range (R) dependent
δx = Rαx = Rλ
Lx
.
(19.5)
At long ranges, the cross-range resolution may become coarse, even in the case of ﬁne angular
resolution. To give an example, if we consider a distance R = 104 m, a wavelength λ = 3 cm and an
antenna size Lx = 3 m, the cross-range resolution would be equal to δx = 100 m. Conversely, if we
wanted to obtain a cross-range resolution equal to 1 m at a distance of 10 km, we would have to build
a 300 m wide antenna.
It is evident that this problem cannot be solved by building very wide antennas as there are practical
limits to that. Another solution could be to build an antenna array, which may relax the previous problem.
Nevertheless, at very long ranges the problem would still be too hard to solve. Inverse Synthetic Aperture
Radar provides a solution to this problem enabling high cross-range resolution as if a wide aperture had
been used. This concept will be detailed in the next section.
2.19.4 Inverse synthetic aperture radar
The concept of Inverse Synthetic Aperture Radar will be introduced in a modern way. Rather than
traditionally considering an ISAR system as a conﬁguration where the radar is static and on object
moves with respect to it, we will migrate from the SAR concept and geometry.
2.19.4.1 From SAR to ISAR
As pointed out in Section 2.19.3, real aperture antennas or antenna arrays do not provide a viable
solution for radar imaging systems. Nevertheless, high cross-range resolution can only be enabled if an
antenna aperture can be formed. The ﬁrst idea of SAR was conceived by thinking of a single element that
moves along a given trajectory, therefore providing the means for forming a virtual array in a given time
interval. Such concept is depicted in Figure 19.4, where a synthetic array formation is compared with
a real array. As the formation of the synthetic aperture is not instantaneous, any equivalence between
the synthetic aperture and a real array can be stated only if the illuminated scene is static during the
synthetic aperture formation (from t1 to tN). If such an assumption can be made, there would be no
physical difference between the signal acquired by a synthetic aperture radar and a real aperture radar
(which makes use of a real array). The condition under which the effect of the element motion can be
neglected is known as the stop & go assumption, which implies that the transmission of the signal and the
reception of its echo occur instantaneously at a particular position. Obviously, this assumption cannot
be perfectly matched unless the platform that carries the radar stops every time a pulse is transmitted and
received before moving to the next position. Nevertheless, in practical scenarios, such an assumption
can be considered satisﬁed since the round trip delay (the time for the e.m. wave to propagate from the
radar to the illuminated scene and back) is short enough to neglect the element offset created by the
platform motion during such a time interval.
Attention should now be paid to the “relative motion” that there is between the platform and the target,
as such a motion is not necessarily produced by a moving platform that carries the radar. Relatively
speaking, if the sensor is stationary and the target moves with respect to it inducing a relative motion,

994
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
FIGURE 19.4
Synthetic aperture—virtual array.
a synthetic aperture would be created at the same way. To strengthen this concept, one could argue that
the cases of stationary target and moving platform and the case of stationary platform and moving target
can only be stated once the reference system has been chosen. In fact, by placing the reference system
on the target, the ﬁrst case is enabled whereas, by placing the reference system on the radar, the latter is
obtained. According with this last view, the differences between synthetic aperture and inverse synthetic
aperture would only depend on where the reference system is positioned. Such a concept is depicted in
Figure 19.5 where a Spot-light SAR conﬁguration is transformed into an ISAR conﬁguration by moving
the reference system from the target to the radar.
Conversely, the same concept may be argued by starting with a controlled ISAR conﬁguration such
as that of a turntable experiment. In a turntable conﬁguration, the antenna is ﬁxed on the ground
(typically mounted on a turret) and the target is positioned on a turntable, which rotates as the radar
takes measurements of the target. By moving the reference system from the radar to the target, a circular
SAR geometry can be enabled, as depicted in Figure 19.6.
In truth, a subtle but signiﬁcant detail exists that substantially deﬁnes the difference between SAR
and ISAR. Such a detail is the cooperation of the illuminated target. To better explain this concept,
one may place the reference system on the target. If such a target moves (with unknown motions) with

2.19.4 Inverse Synthetic Aperture Radar
995
FIGURE 19.5
From Spot-light SAR to ISAR.
FIGURE 19.6
From ISAR to circular SAR.
respect to the radar, the synthetic aperture formed during the CPI differs from the expected one (which is
formed by controlled platform motion). Any SAR image formation that follows would be then based on
the erroneously predicted synthetic aperture and therefore would lead to defocused images. A pictorial
example is shown in Figure 19.7.
2.19.4.2 Geometry
Figure 19.8 shows the ISAR Geometry. The reference system Tξ is embedded in the radar with the axis ξ2
oriented along the line of sight (LOS). Without losing generality, it is assumed that the target moves along
a trajectory that intersects the axis ξ2 at the central instant t = 0. The target rotation due to the translation

996
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
FIGURE 19.7
Synthetic array formed by a non-cooperative target.
motion is denoted as the translational rotation vector tr(t). In practical conditions, external forces pro-
duce angular motions that are represented by the angular rotation vector a(t), which is applied to the
centerOofthetarget(fromnowon“pointO”).Thesumofthesetworotationvectorsyieldsthetotalangu-
lar rotation vector T (t). The projection of T (t) on the plane orthogonal to the LOS is called effective
rotation vector eff(t), which is the rotation vector component that contributes to the target aspect angle
variation. The imaging plane (x1, x2) is orthogonal to the effective rotation vector and is represented
in Figure 19.8 (this will be demonstrated in Section 2.19.5). The time varying coordinate system Tx is
chosen so to have the x2 axis oriented along the LOS, the x3 axis along the effective rotation vector and
the origin in the point “O” at time t = 0. With this choice, the x1 and the x2 axes become the cross-range
and range coordinates of the imaging plane, respectively. It is worth noting that, in general, the imaging
plane (x1, x2) is time-varying because the effective rotation vector varies with respect to the time.
2.19.4.3 Signal modeling
A convenient way to represent the received signal when dealing with ISAR processing is by using a
time-frequency format. In this representation, the frequency coordinate is represented by the variable f,
whereas the time coordinate is represented by the variable t. When written in these terms, the received
signal can be seen as a time varying signal spectrum, where the time variance is typically introduced by
the target relative motions and not by the transmitter (unless time-varying modulations are used, e.g.,
in adaptive systems).
Therefore, the complex base-band received signal, in free space conditions, can be written in a
time-frequency format as follows:
SR( f , t) = W( f , t)

ξ(x) exp

−j 4π f
c
R(t)

dx,
(19.6)

2.19.4 Inverse Synthetic Aperture Radar
997
FIGURE 19.8
ISAR geometry.
where
W( f , t) = rect
 t
t

rect
 f −f0
B

,
(19.7)
andwhere f0 representsthecarrierfrequency,Bisthetransmittedsignalbandwidth,t istheobservation
time, c is the speed of light in vacuum, R(t) is the distance between the radar and the generic pointxon the
target and ξ(x) is the target reﬂectivity function. Function rect (·) yields 1 when |·| < 0.5 and 0 otherwise.

998
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
2.19.4.4 Image formation
ISAR image formation was initially introduced in two pioneering works [2,3], where a Range-Doppler
approach was presented to describe how an e.m. image could be formed by exploiting a target’s rotation
with respect to a radar. Since then, several ISAR image reconstruction techniques have been presented
to form well focussed and high resolution images. Most of the techniques presented in the literature
are based on a two-step approach. A ﬁrst step is taken to eliminate the target’s radial motion (often
addressed with the term autofocus) and a second step is applied to the motion compensated data which
aims at forming the image. In the following subsections, the problem of radial motion compensation
is ﬁrstly addressed and a few techniques are presented that implement this step and then image for-
mation techniques are presented that make use of the classical Fourier approach and Time-Frequency
Transforms (TFTs).
2.19.4.4.1
Radial motion compensation
The straight-iso-range approximation can be applied when the target is much smaller than the radar-
target distance. In practice this is equivalent to effectively approximating the radar-target distance as
follows:
R(t) ≃R0(t) + xT · iLoS(t),
(19.8)
where R0(t) is the residual from point “O” to the radar at the time t, x is the column vector that identiﬁes
a scatterer on the target and iLoS is the column unit vector that identiﬁes the radar Line of Sight. To
further clarify this concept, the reader may refer to Figure 19.9.
By substituting (19.8) into (19.6) we obtain the expression in (19.9)
SR( f , t) = W( f , t) exp

−j 4π f
c
R0(t)
 
ξ(x) exp

−j 4π f
c
xT · iLoS(t)

dx.
(19.9)
The radial motion compensation aims at eliminating the phase modulation produced by the phase
term outside the integral, namely
φ0(t) = exp

−j 4π f
c
R0(t)

.
(19.10)
FIGURE 19.9
Straight iso-range approximation.

2.19.4 Inverse Synthetic Aperture Radar
999
In ISAR applications the target is typically non-cooperative, therefore, the term in (19.10) is not
known a priori. The direct consequence is that such a motion compensation must be performed blindly.
Techniques used in ISAR imaging to perform this task are usually referred to as autofocusing techniques,
as they aim at focusing ISAR images by trying to compensate for the phase modulation introduced by
φ0(t), which typically provoke an image defocusing effect.
After perfect radial motion compensation, the compensated signal can be written as follows:
SC( f , t) = W( f , t)

ξ(x) exp

−j 4π f
c
xT · iLoS

dx.
(19.11)
2.19.4.4.2
Range-doppler image formation
We will now concentrate on the phase term inside the integral in (19.11). It is worth noting that the scalar
product in the phase term is actually the radial coordinate x2(t). After radial motion compensation, any
scatterer’s radial coordinate variation (x2(t)) would be generated by the target’s rotation with respect
to point “O.” It is worth pointing out that only a component of the target’s rotation vector produces
an effective target’s aspect angle variation. To explain this concept a bit more clearly let the target’s
rotation vector be represented by the sum of two components, one aligned with the radar LoS and the
other orthogonal to it. This can be expressed mathematically as follows:
T = LoS + eff.
(19.12)
We will now demonstrate that the component aligned wit the radar LoS (LoS) does not produce any
range variation for any of the target’s scatterers.
To demonstrate this concept, we will refer to Figure 19.10, where a radar is depicted together with a
target with an arbitrary scatterer that rotates with respect to a reference system deﬁned by three cartesian
FIGURE 19.10
Effective rotation vector.

1000
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
coordinates (x1, x2, x3). By assuming that the radar-target distance is much greater than the size of the
target (same assumption made for the straight iso-range approximation), and that the radar is aligned
with the x2 axis, we can write the differential equation systems that rules the rotational motion of a rigid
body given a rotation vector ω(t)
˙x(t) = T × x(t)
with the initial condition x(0) = x0. Therefore, radar-target distance changes can be measured as
changes along the LoS direction (x2 axis), which can be calculated as follows:
˙x2(t) = T3x1(t) −T1x3(t),
which indicates that the rotation vector component along the LoS (x2 axis) does not produce and
target-radar distance changes.
This means that the radar is actually blind to any motion induced by rotation vector component
aligned with the LoS. The effective target rotation vector is the orthogonal component that produces
scatterer’s range variations. Therefore, variations will be observed in the image plane, which means
that only the coordinates (x1, x2) will play a role. More speciﬁcally, the effective rotation vector causes
radial variations that are the result of a rotation around the effective rotation axis. The effect on the
compensated signal phase can mathematically be expressed as follows:
SC( f , t) = W( f , t)

ξ(x) exp

−j 4π f
c

x1 sin

efft

+ x2 cos

efft

dx.
(19.13)
We can now demonstrate that when the effective rotation vector can be considered constant within
an observation time τ, the ISAR image can be interpreted as the image of the target’s projection
onto a plane, namely the Image Projection Plane (IPP). This can be done by simply manipulating the
Eq. (19.13), as follows:
SC( f , t) = W( f , t)

ξ′(x1, x2) exp

−j 4π f
c

x1 sin

efft

+ x2 cos

efft

dx1 dx2, (19.14)
where
ξ′(x1, x2) =

ξ(x)dx3
(19.15)
is the target’s reﬂectivity function projected onto the image plane.
When small aspect angles are spanned, the signal in (19.13) can be approximated with the following:
SC( f , t) ≃W( f , t)

ξ′(x1, x2) exp

−j 4π f
c

x1efft + x2

dx1 dx2.
(19.16)
After making the following substitutions:
ν = 2 f
c effx1,
η = 2
c x2.
(19.17)

2.19.5 ISAR Image Evaluation
1001
Equation (19.16) can be rewritten as follows:
SC( f , t) ≃K W( f , t)

ξ′(η, ν) exp

−j2π

νt + f η

dη dτ.
(19.18)
It should be pointed out that the compensated signal in (19.18) can be read as a windowed Fourier
Transform (FT) of the target’s projected reﬂectivity function.
Therefore, an image of the projected reﬂectivity function ξ′(η, ν) can be obtained by simply applying
an Inverse Fourier Transform (IFT) to the compensated signal. The result can be written as follows:
IC(η, ν) = 2D-IFT

SC( f , t)

= K w(η, ν) ⊗⊗ξ′(η, ν).
(19.19)
A direct interpretation of the result in (19.19) suggests that the target’s ISAR image obtained by
applying a 2D-IFT to the radial motion compensated signal is a ﬁltered version of the target’s reﬂectivity
function projected onto the ISAR image plane.
2.19.5 ISAR image evaluation
The interpretation of an ISAR image is not as straightforward as that of a SAR image. This is the direct
consequence of the target of interest being non-cooperative. Speciﬁcally, the following issues must be
considered to give a correct interpretation of an ISAR image:
•
the cross-range coordinate is represented in the Doppler frequency domain and not in spatial coor-
dinates,
•
the IPP, and therefore the target projection shown in the image, is not known a priori,
•
the imaging system response, namely the Point Spread Function (PSF) ,is not known a priori and
cannot be entirely controlled,
•
the cross-range resolution is not known a priori and it is not a controllable parameter.
Each of these aspects is analyzed in the following subsections.
2.19.5.1 ISAR image coordinates
The coordinates η and ν, which appear in (19.19) can be interpreted as the delay-time and Doppler
coordinates. This is a direct consequence of the substitutions that were made in (19.17). In fact the
coordinate η is the exact calculation of the round-trip delay relative to a scatterer located in the range
coordinate x2, whereas the coordinate ν can be interpreted as the Doppler frequency generated by a
scatterer with a radial velocity equal to vr = effx1.
As ISAR images are typically used for target’s classiﬁcation and recognition, a desired output
would be an ISAR image represented in terms of spatial coordinates (x1, x2). An operation of coor-
dinate scaling would involve an inversion of the eqs. in (19.17). Such an operation will be detailed in
Section 2.19.9.
Theoretically, we may rewrite the result in (19.19) in terms of spatial coordinates, as follows:
IC(x1, x2) = K w(x1, x2) ⊗⊗ξ′(x1, x2).
(19.20)

1002
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
2.19.5.2 Additional considerations on the image projection plane and
limitations of the use of the RD technique
As demonstrated in Eqs. (19.14) and (19.15), the function that maps the target’s 3D complex reﬂec-
tivity function onto the 2D image domain is a projection along the target’s effective rotation vector.
Nevertheless, it should be pointed out that such a result is valid under the following assumptions:
•
far ﬁeld (validity of the straight iso-range approximation),
•
constant target’s rotation vector.
With reference to the geometry described in Section 2.19.4.2, it should be noted that the range position
in the ISAR image only depends on the x2 coordinate whereas the Doppler position only depends on the
x1 coordinate. The dependance of the range position in the ISAR image on the x2 coordinate is the direct
consequence of the choice of the reference system Tx, which has the x2 axis aligned with the radar range
coordinate ξ2. The dependance of the Doppler coordinate on the x1 axis is demonstrated in (19.17), where
a linear relationship holds between the two quantities. It is then evident that the x3 coordinate does not
affect either the range or the Doppler position of a scatterer in the ISAR image. This can be interpreted
in the following terms: two scatterers that are located in two positions such that they only differ by the
third coordinate, namely x3, are mapped onto the same range and Doppler. Therefore, their contributions
are coherently summed. By extending this concept, we can say that a range-Doppler bin in an ISAR
image will show a complex intensity that is the result of a sum of all contributions from those scatterers
that have the same coordinates in terms of (x1, x2) and differ for their x3 coordinate. This is equivalent
to saying that the target is projected onto the (x1, x2)-plane, which can be interpreted as the IPP.
It is worth pointing out that such a result is critical when interpreting ISAR images, in facts:
•
ISAR images are images of the target’s projection onto a plane (IPP),
•
the IPP is not known a priori and therefore, the interpretation of the ISAR image is consequentially
difﬁcult.
2.19.5.3 Point spread function
ISAR image quality can be assessed by deﬁning the PSF. The PSF is the image of an ideal point-like
scatterer located in a generic position x. Therefore, we can easily calculate the ISAR image PSF when
the RD is used to form the image. This can be done mathematically as follows:
PSF(x1, x2) = K w(x1, x2) ⊗⊗Aδ(x1 −x10, x2 −x20) = K ′w(x1 −x10, x2 −x20).
(19.21)
It should be noted that
•
the PSF is space-invariant: an ideal scatterer is imaged in the same way independently of its position,
•
the image geometrical resolution only depends on the characteristics of the window W( f , t).
2.19.5.4 ISAR image resolution
The ISAR image resolution can be obtained by analyzing the PSF. In order to analyze the PSF in terms of
spatial coordinates we will rewrite (19.14) by introducing the concept of spatial frequency coordinates.

2.19.5 ISAR Image Evaluation
1003
Mathematically, this can be done as follows:
SC( f , t) ≃W( f , t)

ξ′(x1, x2) exp

−j2π

x1X1 + x2X2

dx1 dx2,
where
X1 = 2 f
c sin (efft),
X2 = 2 f
c cos (efft).
(19.22)
In particular, in the case of small aspect angle variations, i.e., when efft ≪1, |t| < t
2 , the polar
domain described by the parametric functions in (19.22) can be approximated by a rectangular domain,
as shown in Figure 19.11. Under the same assumption, the spatial frequency coordinates deﬁned in
(19.22) can be = approximated with the following:
X1 = 2 f0
c efft,
X2 = 2 f
c .
(19.23)
It is worth noting that for X1 the frequency f has been substituted by the central frequency f0, as a
result of the approximation of the polar domain by a rectangular window, which intersects the angular
sector at the coordinate X2 = 2 f0
c . It should also be noted that this approximation is the one that leads to
the minimum error, as it can be inferred by examining Figure 19.11 where the two polar and rectangular
windows are superposed.
X1
X2
FIGURE 19.11
Fourier domain—rectangular approximation.

1004
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
By considering the rectangular approximation, we can rewrite the acquisition window W( f , t) in
terms of spatial frequencies. This can be done mathematically by substituting (19.23) into (19.7) as
follows:
W(X1, X2) = rect
	
X1
2 f0efft
c

rect
	
X2 −X20
2B
c

,
(19.24)
where X20 = 2 f0
c .
The PSF can be obtained by calculating the IFT of (19.24), as follows:
w(x1, x2) = Ksinc
 x1
δx1

sinc
 x2
δx2

,
where
δx1 =
c
2 f0efft ,
δx2 =
c
2B .
are the cross-range and range resolution respectively. The following remarks can be made.
•
The range resolution depends on the transmitted signal bandwidth. The direct consequence of this is
that the range resolution can be directly controlled (by setting the desired bandwidth B) or, at least,
it can be calculated. Therefore, it can be considered as a known parameter.
•
The cross-range resolution depends on the target’s motions. This results in a parameter that is not
controllable which means that it cannot be deﬁned by setting one or more radar parameters. For the
same reason, the cross-range resolution is an unknown parameter.
•
An ISAR imaging system performance in terms of resolution cannot be predicted unless the target’s
motions are known. This uncertainty may reﬂect onto uncertainties in the performance of classiﬁers
based on ISAR images.
It must be pointed out that the uncertainty about the cross-range resolution is exactly the same
problem of cross-range scaling. A technique for estimating the effective rotation vector magnitude will
be presented in Section 2.19.9, where a technique will be presented that aims to solve this problem.
2.19.6 Examples of ISAR images
Depending on the type of targets to be imaged, ISAR systems and platform may change to allow covering
areas of interest and improving performance. For instance, ISAR imaging of sea vessels is often carried
out by means of coastal radars, airborne radars and also by spaceborne radar, whereas, images of aircraft
are more likely to be obtained by means of ground-based radar. Some speciﬁc ISAR imaging systems
are also employed to image spaceborne objects, such as the Fraunhofer TIRA system. An example
of a sea vessel ISAR image obtained by processing data collected by an airborne radar is shown in
Figure 19.12, together with an aerial picture of the same target. It is interesting to note some important
features, such as the ship’s cranes, which may be used by a classiﬁer to recognize the type of target.
Another example of an aircraft ISAR image is shown in Figure 19.13. This ISAR image was obtained
by processing data collected by a ground based radar located near an airport. The target, a Boeing 737

2.19.6 Examples of ISAR Images
1005
Aerial photo of the target
FIGURE 19.12
Airborne radar imaging of a moving sea vessel (bulk loader).

1006
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
FIGURE 19.13
Ground-based radar imaging of a ﬂying aircraft (Boeing 737).

2.19.7 Image Autofocus
1007
was taking off during the acquisition. Also in this case features such as length and wing-span may be
used to classify this target. The last example is about a spaceborne SAR image of a non-cooperative sea
vessel together with the same target’s image obtained by using an ISAR processor. It is worth noting
that the SAR processor is unable to focus the target as this is moving with respect to the rest of the
illuminated scene (see Figure 19.14).
2.19.7 Image autofocus
Radial motion compensation is accomplished by means of a step in the ISAR processing chain that is
typically termed image autofocus. This operation is accomplished by removing the phase term φ0(t)
(see Eq. (19.10)). When no external data are available, the motion compensation must be performed
only by using the radar received signal. For this speciﬁc reason, the image focusing process is called
ISAR image autofocus. In many years of research in the ﬁeld of ISAR autofocus, several techniques
have been developed, each of them showing pros and cons. Autofocus algorithms can be classiﬁed as
parametric and non-parametric [5]. Parametric methods need a parametric model of the radar received
signal, whereas non-parametric techniques do not make use of any model. Two parametric and two of
the non-parametric techniques are detailed in the following subsections.
2.19.7.1 ICBA
The autofocus technique adopted here is the Image Contrast Based Autofocus (ICBA) algorithm [6].
The ICBA is a parametric technique and it is based on Image Contrast (IC) maximization. The idea
behind this approach is based on the simple concept that an image will more focussed when the value
of the IC is larger.
The autofocus technique aims at removing the term R0(t) due to the target’s residual translational
motion. For a relatively short observation time interval t and relatively smooth target motions, the
radar-target residual distance can be expressed by means of an Nth order polynomial, as deﬁned in
(19.25). It is worth pointing out that a smooth target motion does not imply that the target undergoes
slow motions but that the function that represents the target’s motion is a continuous and differentiable
function
R0(t) =
N

n=0
1
n!αntn.
(19.25)
In Eq. (19.25), αn are the focusing parameters, which can be denoted by means of a vector format,
namely α. The estimation of R0(t) resorts to the estimation of the target radial motion parameters. By
naming the radial motion model with R0(α, t), the radial motion compensation problem can be recast
as an optimization problem where the Image Contrast (IC) is maximized with respect to the unknown
vector α, as deﬁned in (19.26)
ˆα = arg max
α
{IC(α)} ,
(19.26)

1008
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
FIGURE 19.14
Spaceborne SAR and ISAR images of a moving sea vessel—ISAR imaging is required to focus non-cooperative
moving targets.

2.19.7 Image Autofocus
1009
where
IC(α) =

A

I(η, ν, α) −A

I(η, ν, α)
2
A

I(η, ν, α)

,
(19.27)
and where A[·] indicates an average operation over the variables η and ν, I(η, ν, α) can be deﬁned as
the ISAR image magnitude or intensity (power) after compensating the target’s translational motion by
using α as focusing parameters. This can be expressed mathematically as follows:
I(η, ν, α) =
2D-IFT

SR( f , t) exp

j 4π f
c
R0(α, t)

p
,
(19.28)
where p = 1 in the case of image magnitude and p = 2 in the case of image intensity.
The optimization problem can be solved numerically by using classical methods, such as the Nelder-
Mead [7] or more recent Genetic Algorithms (GA) [8].
2.19.7.2 IEBA
An approach similar to the one proposed in Section 2.19.7.1 can be devised by substituting the IC with
the Image Entropy (IE). As for the IC, the IE is a good indicator of the image focus. Unlike the IC, the
IE has small values when the image is well focussed whereas it reaches large values when an image is
not well focussed. The mathematical expression that may be used to calculate the IE follows in (19.29):
I E(α) = −

ln (I

η, ν, α)

I(η, ν, α)dη dν,
(19.29)
where I(η, ν, α) =
I(η,ν,α)
A

I(η,ν,α)
.
2.19.7.3 DSA
The Dominant Scatterer Autofocus (DSA), also known as Hot Spot (HS), is a two-stage technique: the
ﬁrst is to set up a rough alignment of all the proﬁles, before applying a form of phase compensation
in the second step. The principles for this technique were obtained by delving into two other areas of
research, namely time delay estimation [9] and adaptive beamforming [10]. A brief overview of the
algorithm follows, whilst a more complete description may be found in [11].
After measuring and storing the complex envelopes of the echo samples, high resolution range
proﬁles can be generated. Let sR(η, t) be a range proﬁle acquired at time t. A cross-correlation and shift
operation can be performed between successive range proﬁles in order to obtain a rough range proﬁle
alignment. Let us refer to the roughly aligned proﬁles as:
s1(η, t) = A(η, t) exp[ jφi(η, t)],
(19.30)
where τ indicates a range cell and t is the slow time.
A search along the range coordinate is then performed in order to ﬁnd a dominant and stable scatterer.
The range cell where such a scatterer is found is called the reference range η0
s0(t) = A(η0, t) exp[ jφ0(t)],
A(η0, t) ≃A.
(19.31)

1010
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
The value of η0 is found by measuring the normalized echo variance in each range cell, and is
determined to be the range for which the variance value is a minimum. This approach relies on the
assumption that a dominant scatterer with large radar cross-section exists and therefore, the measured
phase can be attributed to the phase generated by one point scatterer.
The next step is to perform a phase conjugation using the phase history of s0(t). In particular, by
applying it to the range cell data corresponding to η0, the following result is obtained:
s2(t) = A0(η0, t) ≃A.
(19.32)
By applying the same operation to all other range cells motion compensation is achieved:
sC(η, t) = A(η, t) exp { j[φ(η, t) −φ0(t)]} .
(19.33)
This algorithm is known as the Minimum Variance Algorithm (MVA) or the dominant scatterer
algorithm (DSA) due to the criterion used to choose the reference range cell. A more robust version of
this algorithm, which combines the echoes from several reference range cells, will be now considered.
Called the multiple scatterer algorithm (MSA) [11], this modiﬁed algorithm essentially averages the
phase differences of M reference scatterers (after unwrapping) to provide the phase correction. Typically
three reference range bins (M = 3) are sufﬁcient to produce focussed images.
This concept is translated into mathematical details as follows. Let the mth reference cell be repre-
sented as:
sm(ηm, t) = A(ηm, t) exp[ jφm(t)],
Am(t) ≃A
(19.34)
and let M be the number of selected range cells. Therefore, the estimation of the phase history φ0(t)
can be obtained by averaging the phase histories of the selected range cells, as shown in Eq. (19.35)
φ0(t) = 1
M
M

m=1
φm(t).
(19.35)
Phase conjugation is then carried out as before (c.f. Eqs. (19.32) and (19.33)). The DSA algorithm is
summarized in Figure 19.15.
2.19.7.4 PGA
The extension of the original DSA proposed in [11] leads to a general question about how much
information remains in those range cells that are discarded after selecting the MV range cell that could
FIGURE 19.15
DSA algorithm ﬂow chart.

2.19.7 Image Autofocus
1011
FIGURE 19.16
PGA ﬂow chart.
be still used to improve the phase error estimation. An answer to this question may be found in the
solution proposed by Jakowatz et al. [12], namely the Phase Gradient Algorithm (PGA).
The PGA algorithm substitutes the phase conjugation approach used in the DSA with a solution based
on a Maximum Likelihood estimator. The ML approach theoretically uses the information contained in
all range cells, although in practice, the reduction in those range cells where the SNR is high enough
improves the PGA performance.
As shown in Figure 19.16, a Range-Doppler ISAR image is formed with the roughly aligned range
proﬁles.Thepeakvalueineachrangecell,whichissupposedtobethereturnfromadominantscatterer,is
ﬁrstly found along the Doppler coordinate and then center-shifted and windowed in the Doppler domain
(Low-pass ﬁlter). Each range cell is then transformed back via an Inverse Fourier Transform (IFT) to
obtain phase shifted and ﬁltered time histories. This operation corresponds to isolating a scatterer contri-
bution and zero-Doppler forcing, which can be interpreted as a way to remove scatterer’s radial motion.
Let an arbitrary kth range cell time history be represented as in (19.36), where two consecutive
samples are considered.
g(k, m −1) = a(k) exp[ jφ(m −1)] + n(k, m −1),
g(k, m) = a(k) exp[ jφ(m)] + n(k, m),
(19.36)
where k indicates the range cell number, m indicates the mth time sample, a(k) is the amplitude, which
is assumed to be constant for two consecutive samples, φ(m) is the phase at time m and n(k, m) is an
additive white Gaussian noise sample.
The phase gradient between two consecutive samples can be deﬁned as
φ = φ(m) −φ(m −1).
(19.37)
The PGA aims to estimate the phase gradient expressed in (19.37) by using the ML approach. The
theoretical derivation of the ML estimator and its performance are detailed in [12]. The solution is
shown in (19.38)
 ˆφ(m) = ∠
	 N

k=1
g(k, m)g∗(k, m −1)

,
(19.38)

1012
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
FIGURE 19.17
ISAR images formed by applying autofocusing algorithms: (upper-left) DSA, (upper-right) PGA, (bottom-left)
IEBA, (bottom-right) ICBA.
where N is the number of range cells used to estimate the phase error and where the symbol ∠(·) indicates
the phase of a complex number. The phase correction term can be then calculated by integrating the
estimated phase gradient, as follows:
ˆφ(m) =
m

n=2
 ˆφ(n),
ˆφ(0) = 0.
(19.39)
Examples of the application of the DSA, PGA, IEBA and ICBA to a ship target are shown in
Figure 19.17. Results show that all techniques are able to correctly focus the ISAR image although
small differences can be noticed among the images.

2.19.8 Time-Windowing
1013
2.19.8 Time-windowing
As already stated, the RD technique can be successfully applied when the effective rotation vector does
not change signiﬁcantly during the CPI. However, the target’s own motion may induce a non-uniform
target’s rotation vector. In order to minimize target’s rotation variations, the CPI can be controlled via
a time-windowing approach. Typically, an operator would deﬁne a ﬁxed time window length (CPI) and
would process the entire dataset by sliding the window and forming ISAR images. The same operator
would then select the ISAR images that would be suitable for target classiﬁcation or recognition. One of
the most important requirements for such images is a good level of focus, as the target’s details would
then be sharper than in defocused images. Short CPIs are more likely to provide well focussed images
although the resolution may be poor due to a small total aspect angle variation. On the other hand,
long CPIs are more likely to provide wider aspect angle variations, although they would increase the
chance that the target’s effective rotation vector would be time-varying and therefore produce defocused
images. It is quite evident that a trade-off must be identiﬁed to obtain an optimal result that would be
based on obtaining both a high resolution and a well focussed image (See Video Files 1, 2, 3).
The technique described here is an automatic time-windowing technique, originally proposed in
[13]. Speciﬁcally, the time window position across the data and its length are automatically chosen in
order to obtain one or more images with the highest focus. To better explain this concept, we will refer
to Figure 19.18 where the data is referred to as distributed along the time axis and a temporal window
is deﬁned by two parameters, namely τ and t.
The criterion used to deﬁne the highest focused image is based on the IC. Basically, the IC is used as
an indicator of the image focus, which is assumed to be a maximum when the position (τ) and length
(t) identify a time window that selects a data subset where the condition of constant rotation vector
and resolution are optimal. It is worth highlighting that the criterion of optimality here adopted is based
on best image focus.
t
τj
j
ISAR Processor
ISAR image
τi
Δt
i
Δt
FIGURE 19.18
Time-windowing concept.

1014
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
Therefore, the optimal time window position and length are obtained by maximizing the IC with
respect to the couple (τ, t). Therefore, the following optimization problem can be formulated
(τopt, topt) = arg max
(τ,t)

IC(τ, t)

,
(19.40)
where the IC(τ, t) is obtained by redeﬁning (19.27) with respect the two new time variables.
It must be noticed that the variables (τ, t) are discrete variables as the data in input to an ISAR
processor is digitised. Therefore, the problem in (19.40) is a discrete optimization problem. Speciﬁcally,
such a problem can be classiﬁed as a non-linear Knapsack Problem [14]. The solution proposed in [13]
is based on a double linear search, which can be brieﬂy deﬁned as follows:
1. Maximization of the contrast with respect to τ for a given guess t(in). Let τopt be the solution of
such maximization.
2. Optimization with respect to t with τ = τopt.
This procedure is depicted in Figure 19.19 for the sake of clarity.
The justiﬁcation of this procedure is heuristic. It can be observed both in simulated and real ISAR data
ofseveraltypesoftargetsthatthepositionoftheoptimaltime-windowisquiteindependentofthewindow
length. This means that the IC peak position along the τ axis does not change by changing the window
length. Physically, this can be explained by the fact that the target’s own motion will be characterized
by regular motions at given times and less regular motions at other times. The reader may think of a
ship that undergoes pitch and roll due to the sea surface waves. A regular motion may be disturbed by
an incoming wave and generate complex motions which cause the rotation vector to rapidly change.
An example is provided in Figure 19.20 where the IC is calculated by moving four ﬁxed length
windows along the time axis τ. It can be noticed that the position of the peaks is practically the same
for all the four windows.
As an example, we apply the technique of optimal time-windowing to an ISAR dataset of and airplane,
namely a boeing 737. The results are shown in Figure 19.21, where three images are displayed. The ﬁrst
image (Figure 19.21a) is obtained by processing a short CPI dataset (t = 0.41 s). It is quite evident
that, although the image is well focussed, the resolution is poor. The second image (Figure 19.21b)
shows the case of long CPI (t = 3.27 s). The result shows potential ﬁner resolution but at the same
time a strong defocusing effect produced by the target’s rotation vector time-variance. The third image
(Figure 19.21c) shows the result obtained by automatically selecting the optimal time-window, which
resulted in a value of the CPI equal to t = 0.87 s. The conclusion is that the image produced by
means of the automatic optimal time window selection shows ﬁne details due to a ﬁne resolution whilst
retaining a good level of image focus.
FIGURE 19.19
Optimal time window estimator.

2.19.9 Image Scaling
1015
FIGURE 19.20
IC as a function of time by using four different time window lengths.
Often, a sequence of ISAR images is used for classifying or recognizing a target, as the information
about the target increases when the number of images used increases. A direct consequence of the use
of multiple images, especially in the case of highly maneuvering or oscillating targets, is the change in
the IPP, which leads to different target projections. This typically leads to a better indication about the
geometrical features of the target, which can then be used for classiﬁcation purposes. To this purpose,
it would be desirable to obtain a number of well focussed ISAR images out of a long target observation
time. An extension of the time-windowing approach that provides multiple well-focussed images can be
obtained by selecting multiple peaks from the maximum peak locator and iteratively ﬁnd optimal time
window length for each of the selected peaks. The implementation of this extension is straightforward
and is not worth describing in details.
2.19.9 Image scaling
Inverse Synthetic Aperture Radar generates two dimensional, high resolution images of targets in the
time delay—Doppler domain. In order to determine the size of the target, it is required to have fully
scaled image. The range scaling can be performed by using the well known relationship r = cη/2,
where r is the slant range coordinate and η is the time delay. On the other hand, cross range scaling
requires the estimation of the modulus of the target effective rotation vector.

1016
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
FIGURE 19.21
ISAR image obtained by processing (a) a short CPI dataset (0.41 s), (b) a long CPI dataset (3.27 s), (c) the
optimal CPI (0.87 s).

2.19.9 Image Scaling
1017
In this subsection, we will illustrate an algorithm that is based on the assumption of quasi-constant
target rotation [15]. When the target’s rotation vector can be assumed constant within the CPI, the chirp
rate produced by the scattering centers can be related to the modulus of the target’s effective rotation
vector by means of an analytical expression. Therefore, each scattering center carries information about
the modulus of the target’s rotation vector through its chirp rate.
To demonstrate this, we will consider the radial motion compensated signal in (19.14). The phase
term inside the integral function can be approximated with a second order Taylor polynomial, as follows:
ϕ( f , t; x1, x2) = −4π f
c

x2 + x1efft −1
2 x22
efft2

.
(19.41)
It should be noted that the phase in (19.41), represents the phase of a chirp signal, where the second
order term coefﬁcient is usually referred to as chirp rate. The echo of an ideal scatterer located in
(¯x1, ¯x2), with ﬁnite reﬂectivity function ¯ξ(¯x1, ¯x2)δ(x1 −¯x1, x2 −¯x2) can be written by approximating
its phase with the expression in (19.41), as follows:
SC( f , t; ¯x1, ¯x2) = W( f , t)¯ξ(¯x1, ¯x2) exp

−j 4π f
c

¯x2 + ¯x1efft −1
2 ¯x22
efft2

.
(19.42)
The range compressed proﬁle can e obtained by applying a FT to the signal in (19.42) along the
coordinate f. This can be mathematically expressed as follows:
Rp(η, t; ¯x1, ¯x2) = B ¯ξ(¯x1, ¯x2)sinc

B

η −2
c ¯x2

rect
 t
t

exp

−j 4π f0
c

¯x2 + ¯x1efft −1
2 ¯x22
efft2

.
(19.43)
If a method for perfectly estimating the chirp rate of a given scatterer was directly available, the
following equation could be written:
m = 2 f0
c x22
eff.
(19.44)
Therefore, as the scatterer’s range coordinate x2 can be readily obtained by measuring the delay-time
η, the effective rotation vector can be obtained by inverting Eq. (19.44), as follows:
eff =

c
2 f0x2
m.
(19.45)
In practice, a scatterer’s chirp rate, as well as its range, must be estimated from the received data.
Therefore, the estimation of the effective rotation vector magnitude would in general be affected by an
error.
Techniques for estimating target’s scattering center chirp rates have been proposed that make use of
atomic decomposition [16], CLEAN technique [17,18] and based on the IC method proposed in [15].
To make the estimation more accurate and robust the chirp rates of a number of target’s scatterers
can be measured together with their ranges. The problem of estimating the effective rotation vector

1018
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
magnitude is then transformed into a problem of estimating the slope of a straight line that ﬁts the
scatterplot generated by the set of range and chirp rate estimates. One way of solving this problem is to
apply a LSE approach [19]. The mathematical problem can be set as follows:
mk = ax2k + ϵk,
(19.46)
where a = 2 f0
c 2
eff and mk, x2k, and ϵk are the chirp rate estimate, the range estimate and the estimation
error for the kth scatterer, respectively. The LSE problem and its solution for the estimation of a is given
in (19.47)
ˆa = arg min
a
N

k=1
ϵ2
k = N N
k=1 ˆmkx2k −N
k=1 ˆmk
N
k=1 x2k
N N
k=1 x2
2k −
N
k=1 x2k
2
.
(19.47)
An example is provided in Figure 19.22, where the range vs chirp rate scatterplot is shown for a
large ship. The linear relationship between range and chirp rate, theoretically predicted by Eq. (19.46),
is quite evident.
The fully scaled ISAR image of the ship is shown in Figure 19.23. The full representation of the
ISAR image in spatial coordinates allows measuring important features, e.g., ship’s length, directly
from the ISAR picture.
To conclude this section, we provide a few remarks regarding effective applicability of this cross-
range scaling technique. First of all, as any other cross-range scaling technique, its application is effective
only if a constant effective rotation vector applies during the CPI. In fact, such a condition is necessary
to establish a linear relationship between Doppler and cross-range coordinates. Moreover, in the speciﬁc
case of the technique discussed in this section, a well focussed image must be produced in order to
make sure that quadratic phases are associated with single scatterer’s motions. The number of scattering
centers also play an important role as the accuracy of the effective rotation vector estimation generally
improves when the number of independent scattering centers increases.
FIGURE 19.22
Range vs. chirp rate scatterplot.

2.19.10 Time-Frequency Image Formation
1019
FIGURE 19.23
Fully scaled ISAR image.
2.19.10 Time-frequency image formation
The RD technique is based on the assumption that the Doppler frequency of each scatterer, relative
to point O, is constant during the observation time. This hypothesis is usually valid for low spatial
resolution (of the order of one meter) and when the target does not undergo fast maneuvers and/or is
affected by signiﬁcant oscillating motions, such as pitch, roll and yaw (typical of sea vessels). When
very high spatial resolutions are required (of the order of ten centimeters), typically, a longer integration
time is needed and the Doppler frequency associated with each scatterer becomes time-varying. The
situation is also aggravated when the target maneuvers or when it undergoes angular motions, as in
the case of ships. In these cases, the target’s rotation vector is not constant and the RD technique fails
because of the spreading effects due to the time-varying frequency of each scatterer’s contribution. To
solve this problem, the Fourier approach employed by the RD technique is replaced by Time Frequency
Transforms (TFTs), which are suitable for the analysis of non-stationary signals.
Speciﬁcally, bilinear TFTs, such as those described by the Cohen’s class [20], prove effective when
dealing with ISAR signals, which, up to some extent, can be approximated with chirp-like signals
(second order phase terms).
Pioneering work in this sense was delivered by Victor Chen, which is mainly collected in [21],
although more work in this area followed [22,23]. In this subsection, we will recall the work done in
[23], as it aims to analytically derive the ISAR image PSF in when using bilinear TFTs. The PSF is
derived in the case of Wigner-Ville transform, which is the basic Cohen’s class TFT. The derivation in
the case of all the other TFTs can be obtained by simply ﬁltering the data in the adjunct Fourier domain,
which is the Ambiguity Function domain, as demonstrated in [20].
InordertoderivethePSF,wewillconsiderthesignalmodelin(19.42),wherethemotioncompensated
received signal relative to a single ideal scatterer located in the coordinates (¯x1, ¯x2) is considered. It is

1020
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
worth noting that a simple RD approach would lead to a smeared image reconstruction along the
cross-range (Doppler) coordinate, due to the presence of a quadratic phase (chirp term).
The Cohen’s class generic TFT can be analytically expressed as follows:
CTFT(t, ν) =

K(θ, τ)s∗
u −τ
2

s

u + τ
2

· exp (−jθt) exp (−j2πντ) exp (−jθu)du dτ dθ,
(19.48)
where, s(t) is the signal to be transformed and K(θ, τ) is the transform kernel, which deﬁnes any
speciﬁc bilinear TFT belonging to the Cohen’s class.
The Wigner-Ville (WV) is a particular TFT that can be obtained from the Cohen’s class by posing
K(θ, τ) = 1. The WV is analytically expressed in (19.49)
WV(t, ν) =

s∗
u −τ
2

s

u + τ
2

exp (−j2πντ)dτ.
(19.49)
After applying (19.49) to the range compressed signal in (19.43) we obtain a data cube where for
each range cell a time-frequency representation of the data is obtained. With respect to the Fourier
Transform, this approach has the advantage of capturing the time-varying signal spectrum. From an
ISAR imaging perspective, it is important to note that for each time instant t, an ISAR image can be
obtained in the time-delay (η) and Doppler (ν) domain. The ISAR image obtained for the time instant
t = 0 is shown in (19.50)
ITFT(η, ν) = IT FT (η, t, ν)|t=0
=
B ¯ξ(¯x1, ¯x2)sinc

B

η −2
c ¯x2

2
exp (−j2π f0η)sinc

2t

ν −2 f0
c eff ¯x1

.
(19.50)
By looking at the analytical expression in (19.50), it is worth pointing out that
•
the effect of chirp-like terms is completely canceled out as an effect of the application of a bilinear
transform, which has the ability of canceling all even terms, including the quadratic term,
•
the bilinear transform produces a square value in the sinc function along the delay-time coordinate,
•
the Doppler resolution is halved with respect to the Fourier approach.
As a side effect, cross-terms are typically introduced by bilinear transforms, therefore resulting in fake
target’s scatterer images. This effect could be very detrimental in target recognition by means of ISAR
images as false scatterers may appear in critical positions. Speciﬁc transform kernels K(θ, τ) have
the property of removing or attenuating the cross-terms. Nevertheless, a trade-off between cross-terms
removal and Doppler resolution loss must be found in the selection of the kernel function. A suitable
kernel function can be designed as a product of two single variable functions, as follows:
K(θ, τ) = F(θ)G(τ),
(19.51)
where F(θ) and G(τ) may be two weighting windows, such as Hamming, Kaiser, and so on. The shape
parameters in such weighting functions can be determined based on the required level of cross-term
suppression and Doppler resolution loss [23]. The choice of the kernel function such as expressed
in (19.51) leads to the deﬁnition of the Smoothed Pseudo Wigner Ville (SPWV), which is typically

2.19.11 Polarimetric ISAR (Pol-ISAR)
1021
FIGURE 19.24
ISAR image obtained by applying the Wigner-Ville TFT.
implemented in ISAR applications as it provides a ﬂexible solution to the problem of cross-terms and
resolution.
An example of the application of weighting windows is shown in Figures 19.24 and 19.25, where
the results obtained by applying the WV and the SPWV are shown. In particular, the SPWV is applied
by selecting a Kaiser window with shape parameter equal to K = 3. The readed should easily note
that cross-terms present in Figure 19.24 tend to disappear in Figure 19.25, although the resolution tend
to get worse. A trade-off between cross-terms reduction and resolution loss must always be taken into
account when using TFT applied to ISAR imaging.
2.19.11 Polarimetric ISAR (Pol-ISAR)
Firstly a brief introduction on polarimetric SAR systems will be given to provide some motivations for
using polarimetric radar imaging. As polarimetric radar imaging systems are necessarily more expensive
to build than traditional single polarization radar imaging system, their reason to exist must be supported

1022
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
FIGURE 19.25
ISAR image obtained by applying the SPWV.
by an increase in performance or in their ability to overcome physical limitations of single polarization
sensors.
2.19.11.1 Polarimetric SAR imaging
Polarimetric Synthetic Aperture Radar (Pol-SAR) has been widely used for classifying imaged areas.
More speciﬁcally, Polarimetric Synthetic Aperture Radar (Pol-SAR) systems are used in land, ice and
ocean remote sensing to obtain extra information about scattering mechanisms that can be exploited
for extracting physical parameters of interest [24–26] as well as in target classiﬁcation applications
[27–32]. Pol-SAR systems can be realized by exploiting fully polarimetric radars. A fully polarimetric
radar is able to measure a scattering matrix rather than a reﬂectivity function, as in the case of single
polarization radar. The canonical representation of the scattering matrix is as follows:
S =
 SHH SHV
SVH SVV

,
(19.52)
where each term Si j is the scattering coefﬁcient obtained by transmitting polarization i and by receiving
polarization j, where i and j may be horizontal (H) or vertical (V) polarization. Since a generic target

2.19.11 Polarimetric ISAR (Pol-ISAR)
1023
responds differently depending on which polarization is used in transmission and reception, the infor-
mation contained in a scattering matrix is more complete than that contained in a single polarization
scattering coefﬁcient. The fully polarimetric information contained in the scattering matrix may be
used to estimate physical parameters from PolSAR images, which cannot be estimated with a single
polarization radar.
A PolSAR image can be interpreted as the result of a multichannel SAR system where the number of
available channels is equal to four, one for each element of the scattering matrix. The result, is that for
each image pixel, a complex four-element vector is available that can be seen as a polarimetric signature
of the imaged area represented by the same pixel.
PolSAR image formation does not differ from single polarization SAR image formation as all four
images must be formed by using the same processing. In this way, the geometrical co-registration
among all channels is automatically sorted out. Nevertheless, some improvement in the image auto-
focus processing can be attained by optimally processing all polarimetric data, as it will be shown in
Section 2.19.11.2.
As the image formation does not require extra attention with respect to single polarization SAR,
most of the effort has been spent in ﬁnding an optimal use of the polarimetric information contained
in a PolSAR image. For this reason, several polarimetric decomposition have been introduced that aim
at helping to extract useful information that may be used to estimate physical parameters of interest. A
direct information that can be inferred from the fully polarimetric signature relates to the target’s shape.
Therefore, having a polarimetric signature for each image scatterer, allows identifying shapes with a
resolution that can be equal to the SAR image resolution. This allows separating signal components
that are the result of different types of scattering that originate from different scatterer’s shapes.
Under the validity of the reciprocity theorem, which corresponds to the physical condition of recip-
rocal media, it can be demonstrated that a fully polarimetric signal can be represented by means of
three orthogonal complex vectors (three dimensional complex base). Generally, PolSAR images are
represented by coding each decomposed polarimetric channel with a color. A typical color base is the
Red-Green-Blue (RGB).
The polarimetric decompositions that have been introduced can be categorized into two groups:
Coherent Decomposition (CD) and Incoherent Decomposition (ID). CDs are employed in those cases
where the imaged target is characterized by coherent scattering. This typically happens when single
dominant scatterers are present in a resolution cell. In this case, the scattering matrix S in (19.52)
is able to completely chacterize the scattering mechanism. On the other hand, IDs are employed to
characterized incoherent scattering, which is typical of distributed scatterers. This is the case of the
presence of a number of non-dominant scatterers in a resolution cell. The most used CDs are the
Pauli’s decomposition [33], the Krogager’s decomposition [34] and the Cameron’s decomposition [27],
whereas the most commonly used IDs are the Huynen’s Phenomenological decomposition [35], the
Cloude-Pottier decomposition [36] and the Freeman’s decomposition [37]. A comprehensive tutorial
on PolSAR imaging is available at [http://earth.eo.esa.int/polsarpro/tutorial.html].
2.19.11.2 Polarimetric ISAR imaging
As in the case of SAR, fully polarimetric radar can be exploited to obtain polarimetric ISAR imagery,
with the aim of improving target classiﬁcation and recognition performance. The ﬁrst idea to exploit

1024
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
fully polarimetric information in ISAR imaging was developed in [38], where the ISAR image autofocus
is improved by introducing full polarization in the derivation of the autofocus technique. Two algorithms
from the class of parametric autofocusing techniques, namely the Image Contrast Based Autofocusing
(ICBA) and Image Entropy Based Autofocusing (IEBA) [6,39–44] have been extended by introducing
the full polarimetric information contained in the received data. The Image Contrast (IC) and the Image
Entropy (IE) represent two ways of measuring the focus of an ISAR image. In the case of a single
polarization ISAR system, the success of maximizing the IC or minimizing the IE, which is also used
to achieve motion compensation, depends on the polarization used by the system. Evidently, speciﬁc
scatterers may produce a more stable signal return in a given polarization. Often, in SAR applications,
the HH and VV co-polarization channels offer a higher SNR with respect to the cross-polarizations
(cross-pol) HV and VH. Nevertheless, in ISAR applications, such a priori knowledge cannot be taken
for granted. In any case, the availability of all polarizations provides the basis for optimizing the
autofocusing algorithm with respect to the polarimetric space.
Polarimetric radars may also maximize the Signal to Noise Ratio (SNR) with respect to the polariza-
tion space in order to improve detection performance [45]. The concept of increasing the performance
by ﬁnding an optimal polarization can be extended to the ISAR image autofocus problem. Similarly
to the maximization of the SNR with respect to the radar polarization, one may argue that a polariza-
tion exists that maximizes the image focus. This insight can be justiﬁed by considering that the image
focus strongly depends on the time invariance of the scatterer contributions. Moreover, the Doppler
components for each scatterer are generally modulated due to several causes. Among such causes, are
target-radar dynamics, modulation induced by scatterer scintillation and the effect of noise. These causes
can be reduced by exploiting full polarization. In fact, both the SNR and the modulation effects induced
by scatterers when illuminated from different aspect angles can be jointly reduced by ﬁnding the opti-
mal polarization. The deﬁnition of such an optimality criterion will be deﬁned in Section 2.19.11.2.3.
To set the scene, we ﬁrstly introduce the signal model and calculate the polarimetric ISAR image PSF
in the next subsection.
2.19.11.2.1
Signal model
The polarimetric matrix of the received signal, in free space conditions, can be written in the time-
frequency domain by extending the signal model deﬁned in [6]:
SR( f , t) = W( f , t) exp

−j 4π f
c
R0(t)

·

Target
ξ(x) exp

−j 4π f
c

xT · iLoS(t)

dx.
(19.53)
The polarimetric matrix of the received signal can be expressed as
SR( f , t) =

SHH
R ( f , t) SHV
R ( f , t)
SVH
R ( f , t) SVV
R ( f , t)

and the scattering matrix
ξ(x) =
 ξHH(x) ξHV(x)
ξVH(x) ξVV(x)

.

2.19.11 Polarimetric ISAR (Pol-ISAR)
1025
Before proceeding, it is convenient to use a different notation, as detailed in [33], and exploit the
characteristics of isotropic media that are encountered in ISAR applications. Therefore, the polarimetric
data that represents the received signal can be written according to Pauli’s decomposition:
SR =
1
√
2

SVV
R
+ SHH
R , SVV
R
−SHH
R , 2SHV
R
T
,
(19.54)
where the dependence on (f,t) is omitted for notation simplicity.
The same decomposition applies for the target scattering matrix. Therefore, the scattering vector
obtained from the scattering matrix is
ξ(x) =

ξVV(x) + ξHH(x), ξVV(x) −ξHH(x), 2ξHV(x)

.
(19.55)
Thus, the received signal can be seen as a vector in a complex three-dimensional polarimetric space.
All possible projections can be obtained by means of an internal product between the received signal
vector and a generic polarization vector p:
S(p)
R
= SR · p,
(19.56)
where vector p can be expressed according to the decomposition introduced by Cloude and
Papathanassiou in [46]:
p =
1
√
2

pVV + pHH, pVV −pHH, 2pHV
=
⎡
⎣
cos α exp ( jϕ)
sin α cos β exp ( jδ)
sin α sin β exp ( jγ )
⎤
⎦,
(19.57)
where:
•
α is the scatterer’s internal degree of freedom, which ranges in the interval [0, 90]◦. The meaning of
such an angle is related to the scattering properties of the target, e.g., for an ideal dipole the value
of α is equal to 45◦(see Figure 19.26).
•
β represents a physical rotation of the scatterer on the plane perpendicular to the e.m. wave propa-
gation direction.
•
ϕ, δ, γ are the scatterer phases of the three polarimetric components.
It is worth noting that such a representation is meant to highlight the physical properties of the
scattering mechanism induced by a given scatterer. Therefore, by deﬁning the unit vector p, it is possible
to deﬁne a speciﬁc polarization that resonates with a scatterer with given physical properties. Moreover,
the decomposition proposed in [46] provides, among other polarimetric decompositions, a suitable
domain for IC max and/or IE min search. Nevertheless, other types of decomposition could also be used
for the same purpose.
2.19.11.2.2
Image formation
The deﬁnition of the steps that lead to the image formation will be carried out without including the
noise contribution, which will be added subsequently for performance analysis. It is worth pointing out
that this is as a standard procedure in SAR/ISAR processing.

1026
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
FIGURE 19.26
Interpretation of the internal degree of freedom α.
Motion compensation consists of removing the phase term exp

−j 4π f
c R0(t)

due to the radial
movement of the focusing point O. The noiseless received signal after perfect motion compensation
can be written as follows:
S(p)
C ( f , t) = W( f , t)

V
ξ(p)(x) exp

−j 4π f
c

xT · iLoS(t)

dx,
(19.58)
where ζ (p)(z) = ζ(z) · p.
It is worth pointing out that the signal in (19.58) is a scalar signal and therefore, it has the same
characteristics of the single polarization signal expressed in (19.11). Therefore, ISAR image formation
can be carried out exactly at the same way as is done for single polarization ISAR. The Pol-ISAR image
can be written as:
I (p)
C (η, ν) = 2D −I FT

S(p)
C ( f , t)

= K w(η, ν) ⊗⊗ξ′(p)(η, ν).
2.19.11.2.3
Polarimetric autofocus
The idea of jointly processing all polarimetric channels for obtaining highly focussed ISAR images
was ﬁrstly introduced in [47]. Such an insight relied on the concept of enhancing the image focus
by maximizing the IC over the joint space of the focusing parameters α and of the polarization p. In
formula:
(ˆαIC, ˆpIC) = arg max
α,p {IC(α, p)},
(19.59)
where
IC(α, p) =

A

I (p)(η, ν, α) −A

I (p)(η, ν, α)
 2
A

I (p)(η, ν, α)
 
(19.60)
and where ξ =

α1, . . . , αN

, with αi the model polynomial coefﬁcients.

2.19.11 Polarimetric ISAR (Pol-ISAR)
1027
Equation (19.60) represents the new image contrast function deﬁned in the joint domain and where
A(·) is the mean operator. It is worth noting that the IC can be interpreted as a normalized standard
deviation. Therefore, higher values of the IC mean sharper images.
In the same way, image focus can be enhanced by minimizing the Image Entropy (IE), as follows:
(ˆαIE, ˆpIE) = arg min
α,p {IE(α, p)} ,
(19.61)
where
IE(α, p) =

ln[I (p)(η, ν, α)]I (p)(η, ν, α)dν dη,
(19.62)
I (p)(η, ν, α) =
|I (p)(η, ν, α)|2
A[|I (p)(η, ν, α)|2].
(19.63)
2.19.11.2.4
Initialisation
In order to proceed with the application of the Pol-ICBA and Pol-IEBA to the fully polarimetric ISAR
data, a solution for the initial polarization vector must also be provided. The problem can be solved by
means of the following algorithm:
1. The polarization vector that provides the maximum SNR is obtained by solving the optimization
problem stated by Eq. (19.64).
ˆpM = arg max
p
⎛
⎜⎝
$$ S(p)
R ( f , t)

2
d f dt
$$ N (p)
R ( f , t)

2
d f dt
⎞
⎟⎠.
(19.64)
The SNR can be assumed maximum when the signal energy reaches its maximum, provided that the
noise level is the same in all the polarization channels (basically when the noise level in the H and V
receiving channels are the same). Therefore, Eq. (19.64) can be simpliﬁed as follows:
ˆpM = arg max
p
 S(p)
R ( f , t)

2
d f dt

(19.65)
An initial guess for the focusing parameter vector ξ can be obtained by applying the Radon Transform
and by running a one-dimensional optimization problem (see [6,8]). Speciﬁcally, the scalar ICBA and
IEBA must be applied to the received signal with polarization ˆpM as found at step 1:

ˆα(ˆpM)
IC

= arg max
α

IC(α, ˆpM)
 
,
(19.66)

ˆα(ˆpM)
IE

= arg min
α

IE(α, ˆpM)
 
,
(19.67)
where IC(α, ˆpM) and IE(α, ˆpM) can be obtained from (19.60) and (19.62)
Therefore, the initial guess can be formed by adjoining the polarization vector ˆpM to the focusing
parameter vector ˆα(ˆpM)
IE
, which can be expressed as

ˆα(ˆpM)
IE
, ˆpM

.

1028
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
Max SNR
Scalar
ICBA
Fully 
polarimetric
ICBA
FIGURE 19.27
Polarimetric ICBA ﬂow chart.
2.19.11.2.5
Optimization
Once the initial guess is estimated, the optimization problems as stated in (19.59) and (19.61) can be
solved iteratively by using numerical methods for maximum (or minimum) search. Several methods
for solving optimization problems have been proposed in the literature. Such methods can be grouped
into deterministic and statistical methods. The ﬁrst type, which will be adopted in this paper, make use
of the characteristics of the cost function, such as gradient, hessian, etc. to determine the next step in
order to converge to the local maximum or minimum. In this case, convergence to the global maximum
(minimum) must be ensured by a suitable choice of the initial guess. The method used here is the
simplex method, proposed by Nelder and Mead in [7]. Nevertheless, other solutions may be obtained
by using statistical methods, such as Genetic Algorithms (GA) [8]. For the sake of clarity the algorithm
ﬂow chart is shown in Figure 19.27.
2.19.11.2.6
Most focussed ISAR image
The proposed algorithm also provides the most focused ISAR image. The polarization ˆpIC, which
maximizes (19.59) or equivalently, the polarization ˆpIE, which minimizes (19.61), are obtained as
part of the solution of the optimization problems. Therefore, ISAR images obtained by processing the
received data in polarizations ˆpIC and ˆpIE represent the best focused images according to the IC and IE
focus indicators, respectively.
Results relative to the use of polarimetric ISAR image autofocus are provided in Figure 19.28. Specif-
ically, the VV polarization ISAR image obtained by means of Pol-ICBA (in Figure 19.28a is compared
with the ISAR image obtained by applying a single polarization ICBA algorithm (in Figure 19.28b).
It is quite evident that the image obtained by using the Pol-ICBA is sharper than that obtained with
the single polarization ICBA. For the sake of completeness, also the ISAR image projected onto the
polarization that maximizes the IC is shown in Figure 19.28c. A section cut along the cross-range in

2.19.11 Polarimetric ISAR (Pol-ISAR)
1029
Range (m)
Doppler Frequency (Hz)
0
5
10
15
20
−300
−200
−100
0
100
200
300
−16
−14
−12
−10
−8
−6
−4
−2
x 10
−4
Range (m)
Doppler Frequency (Hz)
0
5
10
15
20
−300
−200
−100
0
100
200
300
−11
−10
−9
−8
−7
−6
−5
−4
−3
−2
−1
x 10
−4
Range (m)
Doppler Frequency (Hz)
0
5
10
15
20
−300
−200
−100
0
100
200
300
−3.5
−3
−2.5
−2
−1.5
−1
−0.5
x 10
−3
(b) 
(a) 
(c) 
FIGURE 19.28
Pol-ISAR images obtained by applying (a) Pol-ICBA (VV-Channel), (b) single polarization ICBA (VV-Channel),
(c) Pol-ICBA (polarimetric channel that maximizes the IC).

1030
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
−140
−120
−100
−80
−60
−40
−20
0
20
40
0
0.5
1
1.5
2
2.5
3
3.5
x 10
−3
Doppler Frequency (Hz)
Single Pol
Full Pol
Best Pol
FIGURE 19.29
Cross-range sections obtained from Figure 19.28.
correspondence of a scatterer’s peak further demonstrate that there is a SNR ratio increase due to a
better image focus, as shown in Figure 19.29.
2.19.12 Bistatic radar imaging
A renewed interest in bistatic radar, with speciﬁc attention to bistatic radar imaging has led the research
effort to the development and implementation of Bistatic Synthetic Aperture Radar (BiSAR) and Bistatic
Inverse Synthetic Aperture Radar (B-ISAR) systems.
Bistatic SAR algorithms have been proposed in the literature to solve the problem of the bistatic
radar geometry. The main idea behind those algorithms has been that of extending monostatic SAR
processing techniques to the bistatic case. Such extensions are practically obtained by rewriting the
received signal phase model in order to account for the bistatic geometry. Some BiSAR algorithms can
be found in [48–52].
Some more details will be provided in Section 2.19.12.1 concerning B-ISAR, in order to demonstrate
the usability of monostatic ISAR processors in bistatic geometries.

2.19.12 Bistatic Radar Imaging
1031
2.19.12.1 Bistatic ISAR
There are a number of reasons why bistatic radar imaging may be of interest in non-cooperative target
imaging applications. The main ones are summarized below:
•
Geometrical limitations of monostatic ISAR: In order to obtain ISAR images with a signiﬁcant
Doppler spread, it is necessary that the target changes its aspect angle with respect to the radar
during the Coherent Processing Interval (CPI). This produces a set of geometrical cases where even
if the target is moving with respect to the radar, an ISAR image cannot be obtained. A simple case
is given by a target moving along the radar’s Line of Sight (LOS). In this case the target aspect
angle does not change in time and hence an ISAR image cannot be produced. This case is important
because a a target moving directly towards a radar may be hostile.
•
ISAR imaging of stealthy targets: Military targets may be constructed to minimize the energy
backscattered towards the radar. This makes them almost invisible to a radar. One approach to
achieve this is by reﬂecting the electromagnetic energy towards directions other than that of the
radar. Therefore, stealthyness usually refers only to monostatic radars. The use of a bistatic radar
may enable the detection and therefore the imaging of stealthy targets.
•
Exploitation of bistatic SAR systems: A number of bistatic SAR experiments have been conducted
in the recent years to prove the effectiveness of bistatic radar imaging. The data collected by bistatic
SAR systems could be processed as bistatic ISAR data and therefore, non-cooperative targets could
be imaged by using a bistatic ISAR processor.
•
Multistatic ISAR imaging: Multistatic ISAR imaging may be achieved by using one or more transmit-
ters and a number of receivers. To maximize the gain out of such conﬁgurations, each receiver would
beneﬁt from acquiring the signal transmitted by other transmitters. This enables several bistatic con-
ﬁgurations where the transmitters and the receivers are not co-located. In order to fully understand
multistatic conﬁgurations, the bistatic conﬁguration must be studied ﬁrst.
•
Passive ISAR imaging: There is an increasing interest in the passive radar ﬁeld, as existing illumi-
nators of opportunity can be used to detect and track targets. Although with limited bistatic range
resolution, it has been recently demonstrated that Passive ISAR (P-ISAR) imaging can be enabled
by exploiting modern digital broadcast communications [53].
Although several techniques for image reconstruction have been proposed for BiSAR that provide
effective tools for radar imaging of static scenes, they do not apply to the ISAR case targets of interest
are non-cooperative moving objects. Nevertheless, ISAR imaging usually aims to provide images of
relatively small targets when compared to SAR images, where the imaged area can reach the size of
hundreds of square kilometers. This advantage of ISAR with respect to SAR allows consideration of
the use of monostatic ISAR processors even when the geometry is bistatic. In this subsection, the limits
of applicability of a monostatic ISAR processor to a bistatic ISAR conﬁguration are analzsed. The
analysis here is limited to the case of no synchronization errors. The effect of synchronization errors
on a bistatic ISAR (B-ISAR) have been analyzed in [54]. A well established method for analyzing
radar imaging systems is the calculation of the Point Spread Function (PSF) which in our case will be
addressed as bistatic ISAR image PSF. It will be shown that the bistatic ISAR image PSF depends on the
bistatic angle, which introduces distortions in the bistatic ISAR image. The PSF of an imaging system
also depends on the image formation processing adopted. Radial motion compensation followed by a

1032
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
FIGURE 19.30
Bistatic geometry.
Range-Doppler technique will be considered as the ISAR image formation method, as it represents the
standard procedure for obtaining ISAR images.
In this section the terminology and theory for Bistatic ISAR imaging is introduced. The geometry
of the problem is illustrated in Figure 19.30.
The bistatic conﬁguration produces an almost geometrically equivalent monostatic conﬁguration
which can be seen as a virtual transmitting/receiving element that lies at the bisector between the
transmitter and the receiver. Such an equivalence and its limitation will be the subject of the next
subsections.
2.19.12.1.1
Signal modeling
After motion compensation, as for the monostatic case (19.6), the received signal, can be written in a
time-frequency format as follows:
SR( f , t) = W( f , t)

V
ξ(x) exp (−jϕ(x, f , t))dx,
(19.68)

2.19.12 Bistatic Radar Imaging
1033
where ξ(x) represents, in this case, a bistatic reﬂectivity function and where the phase term (ϕ(x, f , t)),
which takes into account the bistatic conﬁguration, can be written as follows:
ϕ(x, f , t) = 4π f
c

RA(t) + RB(t) + x · iA(t) + x · iB(t)

= 4π f
c

R0(t) + K(t)x · iBEM(t)

,
(19.69)
where
R0(t) = RA(t) + RB(t)
2
,
(19.70)
iBEM(t) iA(t) + iB(t)
|iA(t) + iB(t)|,
(19.71)
K(t) =

iA(t) + iB(t)
2
 ,
(19.72)
and where RA(t) and RB(t) are the distances between point O on the target and the transmitter and the
receiver, respectively, iA(t) and iB(t) are the unit vectors that indicate the LOS for the transmitter and
the receiver, and x is the vector that locates a generic point on the target.
An analysis of the effects of the bistatic geometry on the ISAR image Point Spread Function (PSF)
follows.
2.19.12.1.2
PSF of the bistatic ISAR image
The term K(t) carries information about the change in time of the bistatic geometry. However, what
signiﬁcantly affects the ISAR image PSF is the change of the bistatic angle during the coherent inte-
gration time. In this section the ISAR image PSF will be derived for the bistatic case, and the distortion
introduced by the bistatic geometry will be related to the bistatic angle variation.
In deriving the PSF, two assumptions are made that will allow e application of the Range Doppler
technique when reconstructing the ISAR image (following motion compensation). These two assump-
tions are: (1) the far ﬁeld condition and (2) a short integration time. These assumptions avoid the need for
consideration of non-constant target rotation vectors and the use of polar reformatting, and are generally
satisﬁed in typical ISAR scenarios where the resolutions required are not exceptionally high.
When the target rotation vector is constant, the received signal backscattered by a single ideal scatterer
located at a generic point may be rewritten (after motion compensation) in the following way:
SR( f , t) = W( f , t)

ξ′(x1, x2) exp (−jϕ(x10, x20, f , t))dx1 dx2,
(19.73)
where the phase ϕ(x10, x20, f , t) may be written as:
ϕ(x10, x20, f , t) = 4π f
c

K(t)(x10 sin efft + x20 cos efft)

.
(19.74)
In Eqs. (19.73) and (19.74), (x10, x20) are the coordinates of a generic scatterer on the target with
respect to a reference system centered on the target itself (see Figure 19.30). Note: the third coordinate
(x30) does not appear in Eqs. (19.73) and (19.74), as in the monostatic case.

1034
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
Under Assumptions (1) and (2) the bistatic angle changes are relatively small, even when a target
covers relatively large distances within the integration time. As a result of this, the bistatic angle can be
approximated by a ﬁrst order Taylor (Maclaurin) polynomial:
θ(t) ∼= θ(0) + ˙θ(0)t,
(19.75)
where −Tobs/2 ≤t ≤Tobs/2 and ˙θ = dθ
dt .
Therefore, the term K(t) can also be approximated with a ﬁrst order Taylor (Maclaurin) polynomial,
and by using Eq. (19.72) the following equation may be obtained:
K(t) ∼= K(0) + ˙K(0)t = cos
θ(0)
2

−
˙θ(0)
2
sin
θ(0)
2

t = K0 + K1t.
(19.76)
Therefore, Eq. (19.74) becomes:
ϕ(x10, x20, f , t) = 4π f
c

(K0 + K1t) · (x10 sin efft + x20 cos efft)

.
(19.77)
For small integration angles (short integration time hypothesis) the sinusoids can be approximated by
means of linear terms, as follows:
ϕ(x10, x20, f , t) ≈4π f
c

(K0 + K1t)efftx10

+ 4π f
c

(K0 + K1t)x20

.
(19.78)
An ISAR image reconstruction consists of:
1. Radial motion compensation.
2. Image formation.
When performing the radial motion compensation, any of the available techniques may be used. In
fact, the phase term 4π f
c

RA(t)+RB(t)
2

may be removed as in monostatic conﬁgurations. This is because
the term K(t) does not affect the target radial motion compensation.
After motion compensation, the image formation (by means of the RD technique) makes use of two
Fourier Transforms (FT): one along the frequency coordinate f (range compression) and one along the
time coordinate t (cross-range image formation). In order to obtain the PSF of the bistatic ISAR system,
we calculate the two FTs analytically.
2.19.12.1.3
Range compression
The range compression is obtained by Fourier transforming equation (19.73) along the variable f.
S′
R(η, t) =

W( f , t)δ(x1 −x10, x2 −x20) exp (−jϕ(x10, x20, f , t)) exp (−j2π f η)dx1 dx2 d f
= exp

−j 4π f0
c
(K0 + K1t)efftx10

δ

η −2
c (K0 + K1t)x20

⊗η W ′(η, t),
(19.79)

2.19.12 Bistatic Radar Imaging
1035
where
W ′(η, t) = FT

W( f , t)

= B exp ( −j2π f0η)rect
 t
t

sinc

Bη

and ⊗η is the convolution operator over the variable η.
Two effects are induced by the bistatic geometry:
1. the range position x2 is scaled by a factor K0;
2. a range migration is induced by the bistatic angle variation within the integration time.
Whilst the ﬁrst effect can be corrected a posteriori by rescaling the range coordinate, the second effect
can be signiﬁcantly detrimental. If range migration occurs, the position of one scatterer can be moved
from one range cell to another during the integration time, thereby resulting in a distortion of the PSF.
In order to avoid range migration the following equation must be satisﬁed:
|K1| tx M
20 < r.
(19.80)
In Eq. (19.80), r is the range resolution of the radar and x M
20 is the scatterer with maximum distance
from the target’s zero range (focusing center). By substituting the expression of K1 in (19.80) and
by expressing the limitation with respect to the bistatic angle variation, the following relationship is
obtained:
 ˙θ(0)
 <
2r
tx M
20
sin

θ(0)
2

.
(19.81)
When the constraint (19.81) is satisﬁed, Eq. (19.79) can be rewritten as follows:
S′
R(τ, t) = exp (−j 4π f0
c

K0 + K1t)efftx10

× δ

η −2
c K0x20

⊗τ W ′(η, t).
(19.82)
2.19.12.1.4
Cross-range image formation
Cross-range image formation is achieved by FT (19.82) along the coordinate t. The result is a complex
image in the time-delay (range) and Doppler domains.
PSF(η, ν) =

exp

−j 4π f0
c

K0 + K1t

efftx10

δ

η −2
c K0x20

⊗τ
× W ′(η, t) exp (−j2πtν)dt
= CH

ν, α0, α1

δ

η −2
c K0x20

⊗η ⊗νw(η, ν),
(19.83)
where
w(η, ν) = Bt exp (−j2π f0η)sinc

tν

sinc

Bη

,
(19.84)
CH

ν, α0, α1

= FT

ch

t, α0, α1
 
,
(19.85)

1036
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
ch

t, α0, α1

= exp

−j2π

α0t + α1t2
,
(19.86)
α0 = 2 f0effx10
c
cos
θ(0)
2

,
(19.87)
α1 = −2 f0effx10
c
sin
θ(0)
2
 ˙θ(0)
2 ,
(19.88)
and ⊗ν is the convolution operator over the variable ν.
Therefore the PSF of Eq. 19.83 can be rewritten as:
PSF(η, ν) = CH

ν, α0, α1

⊗ν w

η −2
c K0x20, ν

.
(19.89)
It is worth recalling that a convolution between an inﬁnite duration chirp and a sinc function is
equivalent to a FT of a ﬁnite duration chirp, where the parameter of the sinc function is equivalent to
the duration of the chirp.
As can be seen from Eqs. (19.86–19.88), the chirp rate depends on the position of the scatterer along
the cross-range direction. By following [55] as a rule of thumb for negating the chirp effect (when a RD
technique is used), the chirp rate must satisfy the following relationship:
|α1| <
1
t2 .
(19.90)
By substituting Eq. (19.90) into (19.88), and by expressing it with respect to ˙θ(0), a rule for deter-
mining the maximum bistatic angle variation is obtained
 ˙θ(0)
 <

c
f0t2effx M
10 sin

θ(0)
2


.
(19.91)
Bistatic ISAR scenarios which do not satisfy the constraint in (19.91) are likely to provoke image
distortion. Nevertheless, such scenarios are particular ones where the ISAR system is pushed to the
limit.
An example of strong bistatic angle variations is shown to highlight the distortion effects that may be
encountered when the constraint in (19.91) is not satisﬁed. The geometry considered in this simulation
is depicted in Figure 19.31, where the target moves along a rectilinear trajectory that is almost aligned
with the BEM LoS. In this case the bistatic angle changes are the most severe. The image displayed
in Figure 19.32 is obtained by applying the monostatic ISAR processor to the data generated with the
bistatic geometry depicted in Figure 19.31. A non-distorted image is also produced by considering a
monostatic radar located in the position of the BEM element and displayed in Figure 19.33. From a
comparison between the two images it is possible to appreciate the distortion effects.

2.19.12 Bistatic Radar Imaging
1037
FIGURE 19.31
Simulated bistatic geometry.
FIGURE 19.32
Distorted B-ISAR image.

1038
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
FIGURE 19.33
Non-distorted BEM ISAR image.
2.19.13 Conclusion
The main concepts and algorithms relative to ISAR imaging have been treated in this tutorial. Specif-
ically, the concept of high resolution applied to radar has been used to introduce ISAR imaging. A
model based approach has been proposed as a method to derive the ISAR processor. Speciﬁcally, ISAR
geometry and received signal modeling have been deﬁned. Some physical and mathematical details
have been included in this tutorial with the purpose of helping the reader understanding concepts on one
side and providing the basis for implementing basic ISAR imaging algorithms. Polarimetric and bistatic
ISAR imaging have also been discussed as they represent more recent advances in ISAR imaging that
are opening the doors to the use of ISAR when polarimetric radars are employed or when the radar
conﬁguration is not monostatic (bistatic and multistatic). Examples have also been shown in a variety
of scenarios.
Acronyms
2D
two-dimensional
3D
three-dimensional
BiSAR
bistatic SAR
B-ISAR
bistatic ISAR
CD
coherent decomposition
CPI
coherent processing interval

2.19.13 Conclusion
1039
CTFT
Cohen’s class time frequency transformsar = synthetic aperture radar
DSA
dominant scatterer autofocus
EM
electro-magnetic
ESD
energy spectral density
FT
Fourier transform
GA
genetic algorithm
HS
hot spot
IC
image contrast
ICBA
image contrast based autofocus
ID
incoherent decomposition
IE
image entropy
IEBA
image entropy based autofocus
IFT
inverse Fourier transform
IPP
image projection plane
ISAR
inverse synthetic aperture radar
LoS
radar line of sight
ML
maximum likelihood
MVA
minimum variance algorithm
PGA
phase gradient algorithm
P-ISAR
passive ISAR
Pol-ISAR
polarimetric ISAR
Pol-SAR
polarimetric SAR
PSF
point spread function
RD
range-doppler
SLL
side lobe level
SNR
signal-to-noise ratio
TFT
time-frequency-transform
WV
Wigner-Ville (time frequency transform)
Supplementary data
Supplementarydataassociatedwiththisarticlecanbefound,intheonlineversion,at http://dx.doi.org/10.
1016/B978-0-12-411597-2.00019-9.
Acknowledgment
Special thanks go to DSTO for releasing data that has been processed to form the ISAR images displayed in this
chapter.
Relevant Theory: Signal Processing Theory, Statistical Signal Processing, and Array Signal Processing
See Vol.1, Chapter 2 Continuous-Time Signals and Systems
See Vol. 1, Chapter 3 Discrete-Time Signals and Systems
See Vol. 1, Chapter 9 Discrete Multi-Scale Transforms in Signal Processing

1040
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
See Vol. 3, Chapter 3 Non-Stationary Signal Analysis Time-Frequency Approach
See Vol. 3, Chapter 19 Array Processing in the Face of Nonidealities
References
[1] G. Franceschetti, R. Lanari, Synthetic Aperture Radar Processing, CRC Press, 1999.
[2] J.L. Walker, Range-doppler imaging of rotating objects, IEEE Trans. Aerosp. Electron. Syst. 16 (1980) 23–52.
[3] D.A. Ausherman, A. Kozma, J.L. Walker, H.M. Jones, E.C. Poggio, Developments in radar imaging, IEEE
Trans. Aerosp. Electron. Syst. 20 (1984) 363–400.
[4] M.A. Richards, J.A. Scheer, W.A. Holm, Principles of Modern Radar, Scitech Publishing, 2010.
[5] F. Berizzi, M. Martorella, B. Haywood, E.D. Mese, S. Bruscoli, A survey on ISAR autofocusing techniques,
in: Proceedings of the IEEE ICIP 2004, Singapore, 2004.
[6] M. Martorella, F. Berizzi, B. Haywood, A contrast maximization based technique for 2D ISAR autofocusing,
IEE Proc. Radar Sonar Navig. 152 (4) (2005) 253–262.
[7] J. Lagarias, J.A. Reeds, M.H. Wright, P.E. Wright, Convergence properties of the nelder-mead simplex method
in low dimensions, SIAM J. Optim. 9 (1998) 112–147.
[8] M. Martorella, F. Berizzi, S. Bruscoli, Use of genetic algorithms for contrast maximization and entropy
minimization in ISAR autofocusing, J. Appl. Signal Process. 2006 (2006) 1–11 (special issue on Inverse
Synthetic Aperture Radar).
[9] G.C. Carter, Time delay estimation for passive sonar signal processing, IEEE Trans. Acoust. Speech Signal
Process. 29 (1981) 463–470.
[10] B.D. Steimberg, Radar imaging from a distorted array: the radio camera algorithm and experiments, IEEE
Trans. Antennas Propag. 29 (1981) 740–748.
[11] B. Haywood, R.J. Evans, Motion compensation for ISAR imaging, in: Proceedings of ASSPA 89, Adelaide,
Australia, 1989, pp. 113–117.
[12] C.V. Jakowatz, D.E. Wahl, P.H. Eichel, D.C. Ghiglia, Spotlight-Mode Synthetic Aperture Radar: A Signal
Processing Approach, Springer, 1996.
[13] M. Martorella, F. Berizzi, Time windowing for highly focused ISAR image reconstruction, IEEE Trans.
Aerosp. Electron. Syst. 41 (2005) 992–1007.
[14] R.G. Parker, Discrete Optimisation, Academic Press, 1988.
[15] M. Martorella, A novel approach for ISAR image cross-range scaling, IEEE Trans. Aerosp. Electron. Syst.
44 (1) (2008) 281–294.
[16] O. Yeste-Ojeda, J. Grajal, G. Lopez-Risueno, Atomic decomposition for radar applications, IEEE Trans.
Aerosp. Electron. Syst. 44 (2008) 187–200.
[17] J.Tsao,B.Steinberg,Reductionofsidelobeandspeckleartifactsinmicrowaveimaging:theCLEANtechnique,
IEEE Trans. Antennas Propag. 36 (1988) 543–556.
[18] M. Martorella, N. Acito, F. Berizzi, Statistical clean technique for ISAR imaging, IEEE Trans. Geosci. Remote
Sens. 45 (11) (2007) 3552–3560.
[19] S.M. Kay, Fundamentals of statistical signal processing: estimation theory, Signal Processing, Prentice Hall,
1993.
[20] L. Cohen, Time-frequency distributions—a review, IEEE Proc. 77 (7) (1989) 941–980.
[21] V. Chen, Time-Frequency Transforms for Radar Imaging and Signal Analysis, Artech House, 2002.
[22] T. Thayaparan, L. Stankovic, C. Wernik, M. Dakovic, Real-time motion compensation, image formation and
image enhancement of moving targets in ISAR and SAR using S-method based approach, IET Signal Process.
2 (2008) 247–264.

References
1041
[23] F. Berizzi, E. Mese, M. Diani, M. Martorella, High-resolution ISAR imaging of maneuvering targets by means
of the range instantaneous doppler technique: modeling and performance analysis, IEEE Trans. Image Process.
10 (2001) 1880–1890.
[24] S. Cloude, E. Pottier, An entropy based classiﬁcation scheme for land applications of polarimetric SAR, IEEE
Trans. Geosci. Remote Sens. 35 (1997) 68–78.
[25] S. Jiancheng, J. Dozier, An entropy based classiﬁcation scheme for land applications of polarimetric SAR,
IEEE Trans. Geosci. Remote Sens. 33 (1995) 905–914.
[26] M. Migliaccio, A. Gambardella, M. Tranfaglia, SAR polarimetry to observe oil spills, IEEE Trans. Geosci.
Remote Sens. 45 (2007) 506–511.
[27] W.L. Cameron, N.N. Youssef, L.K. Leung, Simulated polarimetric signatures of primitive geometrical shapes,
IEEE Trans. Geosci. Remote Sens. 34 (3) (1996) 793–803.
[28] R. Touzi, F. Charbonneau, Characterization of target symmetric scattering using polarimetric SARs, IEEE
Trans. Geosci. Remote Sens. 40 (11) (2002) 2507–2516.
[29] R. Touzi, F. Charbonneau, Characterization of target symmetric scattering using polarimetric SARs, IEEE
Trans. Geosci. Remote Sens. 42 (10) (2004) 2039–2045.
[30] W.L. Cameron, H. Rais, Conservative polarimetric scatterers and their role in incorrect extensions of the
Cameron decomposition, IEEE Trans. Geosci. Remote Sens. 44 (12) (2006) 3506–3516.
[31] M. Martorella, E. Giusti, A. Capria, F. Berizzi, B. Bates, Automatic target recognition by means of polarimetric
ISAR images and neural networks, IEEE Trans. Geosci. Remote Sens. 47 (2009) 3786–3794.
[32] M. Martorella, E. Giusti, L. Demi, Z. Zhou, A. Cacciamano, F. Berizzi, B. Bates, Target recognition by means
of polarimetric ISAR images, IEEE Trans. Aerosp. Electron. Syst. 47 (2011) 225–239.
[33] S.R. Cloude, E. Pottier, A review of target decomposition theorems in radar polarimetry, IEEE Trans. Geosci.
Remote Sens. 34 (2) (1996) 498–518.
[34] E. Krogager, New decomposition of the radar target scattering matrix, Electron. Lett. 26 (18) (1990)
1525–1526.
[35] J.R. Huynen, Measurement of the target scattering matrix, Proc. IEEE 53 (2) (1965) 936–946.
[36] S.R. Cloude, The characterization of polarization effect in EM scattering, PhD dissertation, Univ. Birmingham,
Fac. Eng., Birmingham, UK, 1986.
[37] A. Freeman, S.T. Durden, A three component scattering model for polarimetric SAR data, IEEE Trans. Geosci.
Remote Sens. 36 (3) (1998) 963–973.
[38] M. Martorella, J. Palmer, F. Berizzi, B. Haywood, B. Bates, Polarimetric ISAR autofocusing, IET Signal
Process. 2 (3) (2008) 312–324.
[39] L. Xi, L. Gousui, J. Ni, Autofocusing of ISAR images based on entropy minimization, IEEE Trans. Aerosp.
Electron. Syst. 35 (1999) 1240–1252.
[40] F. Berizzi, G. Corsini, Autofocusing of inverse synthetic aperture radar images using contrast optimization,
IEEE Trans. Aerosp. Electron. Syst. 32 (1996) 1185–1191.
[41] J.R. Fienup, J.J. Miller, Aberration correction by maximising generalised sharpness metrics, J. Opt. Soc. Am.
A 20 (2003) 609–620.
[42] M. Iwamoto, T. Fujisaka, M. Kondoh, Autofocusing algorithm of inverse synthetic aperture radar using
entropy, Electron. Commun. Jpn. 83 (1999) 97–106.
[43] R. Morrison, M.N. Do, D.C. Munson Jr, SAR image autofocus by sharpness optimisation: a theoretical study,
IEEE Trans. Image Process. 16 (2007) 2309–2321.
[44] R. Morrison, D.C. Munson Jr., An experiemntal study of a new entropy-based SAR autofocusing technique,
in: Proceedings of 2002 International Conference on Image Processing, vol. 2, 2002, pp. 441–444.
[45] L.M. Novak, Studies of target detection algorithms that use polarimetric radar data, IEEE Trans. Aerosp.
Electron. Syst. 25 (1989) 150–165.

1042
CHAPTER 19 Introduction to Inverse Synthetic Aperture Radar
[46] S.R. Cloude, K.P. Papathanassiou, Polarimetric SAR interferometry, IEEE Trans. Geosci. Remote Sens. 36
(5) (1998) 1551–1565.
[47] M. Martorella, L. Cantini, F. Berizzi, B. Haywood, E. Dalle Mese, Optimised image autofocusing for polari-
metric ISAR, in: Proceedings of the Eusipco Conference 2006, 22–25 April 2002, Florence, Italy, Hindawi,
2006.
[48] H. Nies, O. Loffeld, K. Natroshvili, Analysis and focusing of bistatic airborne SAR data, IEEE Trans. Geosci.
Remote Sens. 45 (2007) 3342–3349.
[49] M. Soumekh, Bistatic synthetic aperture radar inversion with application in dynamic object imaging, IEEE
Trans. Signal Process. 39 (9) (1991) 2044–2055.
[50] M. Soumekh, Synthetic Aperture Radar Signal Processing with MATLAB Algorithms, Wiley, 1999.
[51] J.H.G. Ender, I. Walterscheid, A.R. Brenner, New aspects of bistatic SAR: processing and experiments,
in: IEEE IGARSS Proceedings of International Geoscience and Remote Sensing Symposium (IGARSS),
Anchorage, AK, United States, vol. 3, Institute of Electrical and Electronics Engineers Inc., Piscataway, NJ,
United States, 2004, pp. 1758–1762.
[52] D. D’Aria, A.M. Guarnieri, F. Rocca, Focusing bistatic synthetic aperture radar using dip move out, IEEE
Trans. Geosci. Remote Sens. 42 (7) (2004) 1362–1376.
[53] D. Olivadese, M. Martorella, E. Giusti, D. Petri, F. Berizzi, Passive ISAR with dvb-t signal, in: Proceedings
of the EUSAR 2012, 2012.
[54] M. Martorella, Bistatic ISAR image formation in presence of bistatic angle changes and phase synchronization
errors, in: Proceedings of the EUSAR 2008 Conference, Friedrichshafen, Germany, 2008.
[55] F. Berizzi, E. Dalle Mese, Sea-wave fractal spectrum for SAR remote sensing, IEE Proc. Radar Sonar Navig.
148 (2) (2001) 56–66.

20
CHAPTER
SAR Interferometry and
Tomography: Theory and
Applications
Gianfranco Fornaro* and Vito Pascazio†,‡
*Istituto per il Rilevamento Elettromagnetico Ambientale (IREA),
Consiglio Nazionale delle Ricerche (CNR), Napoli, Italy
†Dipartimento di Ingegneria, Università degli Studi di Napoli Parthenope, Napoli, Italy
‡Laboratorio Nazionale di Comunicazioni Multimediali, CNIT Complesso Universitario di
Monte S. Angelo, Ediﬁcio Centri Comuni, Napoli, Italy
2.20.1 Introduction
During the 19th century, the theory of electromagnetic ﬁelds became a ﬁrmly established science:
Maxwell’s equations accurately described the propagation of the ﬁelds, Marconi’s wireless experiments
demonstrated the possibility of wireless communication at large distances. Nevertheless, even since that
early time it was evident that electromagnetic waves could be not only used for communication but also
to obtain information, or better to “sense” the environment and the objects without being in contact with
them.
Remote sensing is today well established and intensively used for acquiring information about the
Earth’s surface [1]: among the most used remote sensing systems, active microwave sensors and par-
ticularly Synthetic Aperture Radar (SAR) have gained an increasing interest from both a scientiﬁc and
industrial viewpoint. This success is a consequence of the capability of the sensor to operate indepen-
dently of an external illumination source (day and night) and practically in almost any meteorological
condition.
2.20.1.1 Microwave high resolution imaging
Active sensors make use of radars, typically installed on spacecraft, or on aircraft, or even on ground.
They transmit a coherent (i.e., well controlled at the level of a single oscillation) signal and record the
echoes scattered back to the sensor from the observed area. Accordingly, they are independent from any
external illumination sources: this peculiarity, together with the fact that they work at wavelength that
are, differently from optical and infrared sensors, almost immune to the presence of clouds and fog,
provide the system with the possibility to operate day and night and also in adverse weather conditions.
Modern SAR sensors transmit signals whose bandwidth is of the order of tens/hundreds MHz, thus
leading to spatial resolution along the range (typically called across track direction) of the order of
meters or fraction of meter.
Forcomparableopticalapertureandantennasize,thespatialresolutionalongtheﬂighttrackofimages
acquired by microwave sensors should be several order of magnitude worse than the optical images.
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-396500-4.00020-X
© 2014 Elsevier Ltd. All rights reserved.
1043

1044
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
This drawback is however overcome by the possibility to synthesize a very large antenna (of the order of
few kilometers) by moving a much smaller real antenna along a straight trajectory corresponding to the
platform ﬂight track. This possibility, ﬁrst postulated by Wiley [2] with the Doppler beam sharpening
concept, is a direct consequence of the coherent nature of the system.
The operation of synthesizing a large antenna is today carried out typically off-line, after the
downlink to a ground station, via a digital processing operation, usually referred to as SAR focus-
ing operation, that, coherently combine on a 2D domain the echoes received from the radar at different
positions. The obtained images are characterized by a resolution along the direction of array synthesis
(typically referred to as along track direction) of the order of the length of the physical antenna dimen-
sion, independently from the wavelength and the height of the platform. Depending on the operative
mode (scan, strip, and spot-mode) and on the fact that the platform can be disturbed during its motion
by turbulences as in the airborne case, this operation can be in some cases more problematic.
SAR images are complex entities where the intensity basically measures the energy backscattered
by the ground targets toward the sensor, which depends on the geometric (shape, roughness, and slope)
and on physical (conductivity and permittivity) properties of the observed scene.
SAR sensors provide information about the observed scene complementary to that provided by
optical systems. SAR images are nowadays used in many areas of interest: In glaciology they are
used for glaciers monitoring and snow mapping, in agriculture for crop classiﬁcation and soil moisture
monitoring, in forestry for biomass estimation, etc. They are also used in environment monitoring for
the detection of oil spills, ﬂooding, as well as to monitor the urban growth or moving targets.
The
technique
that
has
opened
probably
the
widest
range
of
application
is
SAR
Interferometry [3,4].
As in any electromagnetic coherent system the phase information is related to the travelled path,
that is the distance target-sensor (range). Radar measurements therefore embed the information of
distances with extreme high accuracy, on the order of wavelength fraction: due to the randomness of
the scattering mechanism this information can be however extracted only as a relative measurement
between different images. SAR Interferometry (InSAR) is a technique that, by exploiting at least two
SAR images acquired from slightly different angles, allows retrieving the topography of the observed
scene. A single SAR image provides measurement of measure the backscattering scene property only
on a 2D domain, i.e., by performing a projection onto the plane containing the ﬂight direction and the
radar line of sight. Similarly to the human eyes system, height sensitivity can be achieved by combining
two images of the same area acquired from two slightly different positions. The key principle of SAR
interferometry is the use of the phase difference between SAR images for the accurate measurement of
the distances of a target from two sensors displaced in location in order to create a parallax.
The two images can be acquired simultaneously if two antenna are present at the same time on
the platform (single-pass interferometry) or through different passes of the same antenna (repeat-pass
interferometry). In the latter case changes of the scene backscattering properties and variations of the
phase delay contribution from the atmosphere may strongly impair the accuracy of the results. The
accuracy of the topography estimation depends on the component orthogonal to the line of sight of the
antenna vector separation commonly referred to as (spatial) baseline: for this reason this technique is
also referred to as across-track interferometry.
As an alternative to topographic mapping, when the two antennas are present on the same platform and
are separated along the ﬂight direction, they acquire images repeated with a revisit of a few milliseconds.

2.20.1 Introduction
1045
This is the case of the along-track interferometry which allows monitoring fast movements of targets
on the ground. Applications concern for example the estimations of ocean currents or moving detection
and velocity estimation [5].
An interesting extension of across and along-track InSAR is the Differential SAR Interferometry
(DInSAR): by exploiting phase difference of images acquired at times (epochs), separated typically by
some days, it allows accurately monitoring slow displacements over the epoch sequence. Differential
interferometric data can be acquired by radar observations separated in time either from a single radar
on one platform (e.g., ERS-1, JERS-1, ENIVSAT, TerraSAR-X) or from multiple radars on different
platforms provided the radar have similar radar operating a viewing parameters (e.g., Cosmo Skymed
constellation). Since the precision of radar in estimating distance is in the order of fraction of wavelength,
DInSAR can estimate movements with sub-centimetric accuracy using L-, C-, or X-Band radars.
Majorapplicationsofthistechniqueregardthenaturalhazardandsecurityarea.Besides,byexploiting
archives of past images multipass techniques are also extremely useful to provide a past monitoring.
Interferometry applications have dramatically increased the use of microwave remote sensing for the
environment monitoring: This is also testiﬁed by the growing interest of the major international space
agencies in the development and launch of spaceborne SAR sensors satellites. The twin satellites ERS-1
and ERS-2 [6] of the European Space Agency (ESA), operative since 1992 and 1996, respectively, each
one with a revisiting time of 35 days each, were characterized by the possibility to acquire a pairs of
tandem images, i.e., interferometric images separated by only one day. ERS sensors from nineties to
the ﬁrst decade of 2000 were the very ﬁrst systems used for the operative demonstration and routinely
application of interferometry. Their acquisitions have been deeply exploited for years to develop most
of the interferometric processing algorithm currently used and to demonstrate the potentials of the
application of SAR Interferometry in several natural risk areas. Recently, the Italian Cosmo Skymed
[7] and German TerraSAR-X [8] missions improved the quality of SAR product by providing images
with spatial resolution up to one meter. Together with its twin satellite TanDEM-X, TerraSAR-X is
going to provide the most accurate Digital Elevation Model (DEM), i.e., the topography, of the Earth
on a global scale with a relative accuracy of 2 m for slope lower than 20◦and 4 m for higher slopes
with a spatial grid of 12 m. From the other side, the Italian COSMO-Skymed mission [7] is, worldwide,
the unique constellation of more than two SAR sensors exploited also for civilian applications. It is
composed of four medium-size satellites, each one equipped with an X-band high-resolution SAR
system, allowing acquiring images on the same area every 4 days on average, thus both reducing the
effects of decorrelation and allowing a more frequent imaging which is useful for interferometric
application to cases of emergency.
Polarimetry [9–16] and Polarimetric SAR interferometry [17,18] and are techniques that use
multi-polarization channels to extract further information on the scattering mechanism. Polarimetric
information allows separating different scattering mechanisms. Whereas SAR polarimetry is a technique
that use single antenna data, Polarimetric SAR interferometry use data acquired by two antennas.
The former has a wide use in the ﬁeld of classiﬁcation, the latter allows generating interferograms
corresponding to different scattering mechanisms and has an area of application in the ﬁeld of forest
height retrieval and biomass estimation.
The advances in the SAR hardware has allowed to reach very high imaging resolutions at microwaves
on the order of a meter and has in parallel stimulated the development of advanced processing techniques
able to extract from the data the highest possible information content.

1046
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
One of the most important and recent innovations in SAR processing is associated with the exten-
sion of the imaging process form a 2D domain to a multi-dimensional domain. The so-called SAR
Tomography has been among the ﬁrst examples giving to SAR the ability of reconstructing images
of the backscattering property of the scene also along the direction (elevation) orthogonal to the two
classical dimension (azimuth and range). The key aspect of this technique is the possibility to synthesize,
similarly to the ﬂight direction (azimuth) an array also along the “height” direction to sharpen and steer
the beam in such a way to measure the backscattering characteristics of the scene along the elevation
direction and hence to generate full 3D images.
SAR Tomography allows vertically proﬁling (3D imaging) the backscattering to detect targets which
interfere in the same pixel of a single SAR image and even monitoring, with the extension of the imaging
properties to the time direction (4D Imaging), their individual deformation. Beside the application to a
distributed scenario such as forest where the scattering is distributed along the height, the tomographic
technique also provide signiﬁcant advances in the application to the imaging and monitoring of in areas
characterized by an high density of scatterers, such as urban areas, opening the possibility to achieve
dense imaging and monitoring of single buildings and individual structures from the space, for the ﬁrst
time comparable to what obtainable with in situ systems like laser scanner [19,20].
Polarimetric SAR tomography [21–24] takes beneﬁts of both polarimetry and tomography: by
accessing the multibaseline information on different polarization channels, it allows retrieving scat-
tering proﬁles along the elevation direction associated with different scattering mechanisms such as
single bounce, double bounce and volume scattering. This work concentrates on the development of
SAR interferometry (including multipass Differential SAR Interferometry) and Tomography for 3D
reconstruction and target deformation monitoring.
2.20.2 Basics concepts in SAR imaging and SAR interferometry
2.20.2.1 High resolution image formation
Among the several parameter characterizing an image, resolution plays certainly a major role. In the
radar case the resolution along the range coordinate depends on the system bandwidth [25,26]. Large
bandwidths are obtained, with simpliﬁed (i.e., low peak power) hardware, by transmitting long duration
linear frequency modulated (chirp) pulses which are, after echo reception, compressed (typically on the
ground) via correlation techniques: this operation is commonly referred to as range pulse-compression
or range focusing (see Figure 20.1).
The transmitted chirp pulse has the following expression:
s(t) = rect
 t
τ

e jπαtt2,
(20.1)
wherein rect[·] is the window function, τ is the pulse duration, and αt is the Chirp rate (Hz2). The
correlation of the response of a target at range r with the transmitted pulse replica provides the expression
of the range impulse response function (IRF), also known as range Point Spread Function (PRF):
ˆγ (t) = s

t −2r
c

∗s∗(−t) ∼= B sinc(Bt),
(20.2)

2.20.2 Basics Concepts in SAR Imaging and SAR Interferometry
1047
CORRELATOR
FIGURE 20.1
System geometry in the range direction.
with c being the light-speed and B = αtτ the bandwidth of the transmitted pulse. The (3 dB) range
resolution is numerically given by [27]
δr ∼= 0.88 c
2B .
(20.3)
Such a resolution value is also referred to as slant range resolution to highlight that it refers to the
line-of-sight (LOS) direction. Scaling factors derived by standard trigonometry should be applied to
achieve the resolution along the main scene direction, for instance along the direction corresponding to
the projection of range onto the local cartographic reference system usually referred to as ground range
resolution:
δy ∼=
δr
sin (α −β),
(20.4)
where α is the so-called incident angle, deﬁned as the angle between the radar LOS and the local normal
to the surface at the point of the reﬂection on the ground (see Figure 20.2), and β is the terrain slope.
The ground range resolution is, of course, coarser than the slant range resolution.
Note that in the absence of terrain slope, the incidence angle is equal to the angle θ (known as look
angle and deﬁned with respect to the nadir direction) only when the Earth curvature can be neglected,
i.e., as in the case of airborne sensors operating at low altitude.
In case of ﬂat ground and if the SAR antenna beamwidth in the range direction is not too big, as
usually occur for instance for new generation X-band SAR sensors, the ground resolution is almost
constant along the footprint. Differently, in case of non-ﬂat ground, as shown in Figure 20.3, the ground
resolution can change signiﬁcantly, as effect of topography, giving rise to the well known effects of
foreshortening, layover, and shadowing. Under conditions of foreshortening different resolution cells
can contain contribution of very different, in terms of dimension, ground areas (see Figure 20.3b).
Layover is beyond the limit case just described: in this case, points more distant in the ground can appear

1048
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
α
δr
δy
SAR 
Antenna
ϑ
Ground
β
FIGURE 20.2
SAR range resolution. δr is the slant range resolution, δy is the ground range resolution, ϑis the look angle,
α is the incidence angle, and β is the local terrain slope. In absence of topography (β = 0), it results that
α + ϑ = π/2.
closer to the SAR radar sensor, and are mapped erroneously in the SAR image (see Figure 20.3c). Such
effect is very common in mountainous areas with steep slopes, and in urban areas [4]. The shadowing
effect occurs when ground area are masked by reliefs, as in Figure 20.3d. In this last case, a slant range
resolution cell does not map any ground area (the ground area BC in Figure 20.3d is not seen from the
SAR antenna). The above presented distortion effects makes that SAR images of mountain and urban
areas can look very different from optical images, as an effect of geometrical distortions.
In the azimuth direction the focusing operation is necessary to synthesize a long antenna with higher
resolution capabilities, that is for achieving the beam sharpening.
With reference to Figure 20.4 where the system imaging geometry represented in the ﬂight direction,
the system “senses” the scene by transmitting pulses at regular time instants, regulated by the pulse
repetition frequency. The echoes collected in each position may be coherently processed in such a way
to synthesize (digitally) an antenna whose dimension is equal to the footprint (X) of the real antenna
[25,28]:
X = λ
L r,
(20.5)
where λ is the wavelength, L is the azimuth length of the real antenna, and r is the range of the target
(range). Note that λ/L is the angular aperture of the real SAR antenna in the azimuth direction. The

2.20.2 Basics Concepts in SAR Imaging and SAR Interferometry
1049
Image Plane
Image Plane
SAR 
Antenna
Image Plane
Image Plane
SAR 
Antenna
SAR 
Antenna
A’ B’
C’
A’
B’
C’
A’ B’
C’
A’
B’
C’
A
B
C
A
B
C
A
B
C
B
C
B
A
Foreshortening
Shadowing
Layover
SAR 
Antenna
(a)
(b)
(c)
(d)
FIGURE 20.3
SAR distortion effects: (a) normal conditions, (b) foreshortening, (c) layover, and (d) shadowing.
ﬁnal resolution of the image, provided by the synthetic antenna is [25]:
δaz ∼= 0.88 λ
2X r ∼= 0.88 L
2 ,
(20.6)
where the resolution gain factor 2 in the ﬁrst equality is associated with the capability of the array to
transmit and receive the radiation from each position of the real antenna during the synthetic antenna
formation.
The time interval in which the scatterer is illuminated is referred to as integration time: for a standard
operating mode, as that illustrated in Figure 20.4 (referred to as stripmap mode), it is trivially given by
the ratio between the real antenna footprint and the platform velocity (v).
A dual approach used for the computation of the azimuth resolution of the focused image is pro-
vided by the so called Doppler analysis which states that when either transmitters or receiver are
subject to a uniform motion, the received radiation is subject to a frequency shift (called Doppler shift)

1050
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
synthesized antenna
azimuth 
real
antenna
beam
FIGURE 20.4
System geometry in the azimuth direction. The movement of the platform allows to synthesize a larger
antenna thus achieving a sharpening of the beam of the real antenna.
equal 2v · ˆr/λ, with v being the velocity vector (in our case of the platform) and ˆr being the versor
of the receiving radiation (in our case the direction locating the scatterer from the platform). It is
therefore clear that, during the integration interval, the echo from the target sweeps an interval from
v · ˆr

min = −v sin[λ/(2L)] ∼= −vλ/(2L) to v · ˆr

max = v sin[λ/(2L)] ∼= vλ/(2L), which corresponds
to a Doppler frequency interval from 2v · ˆr/λ

min ∼= −v/L to 2v · ˆr/λ

max ∼= v/L. Accordingly, the
Doppler bandwidth amounts to:
Bd = 2 v
L .
(20.7)
Such a bandwidth is able to provide pulses with time duration equals L/(2v), which corresponds a spatial
extent of about L/2. Unfortunately, the relative motion between the sensor and the target introduces
also linear (phase) distortions as well as motion through resolution cell. Therefore, to provide short
duration pulses the phase distortions affecting the available bandwidth must be compensated at the
azimuth focusing level with the use of ﬁlters which are intrinsically 2D and also space variant only (for
rectilinear tracks) with the range. The SAR focusing topic is out of the scope of this work, readers can
refer to [25,28].
2.20.2.2 Operational modes
The classical operational mode of a SAR system considers the antenna pointing with a ﬁxed offset from
the ﬂight direction, non-necessary orthogonal (i.e., broadside) pointing: this is referred to as Stripmap
mode to highlight the fact that the scene is illuminated along a strip. The stripmap imaging mode
geometry is depicted in Figures 20.4 and 20.5a.
In this way the integration time for forming the image of a target is, as discussed in the previous
section, limited by the ratio between the real antenna azimuth footprint dimension and the platform
velocity. This poses a limitation on the maximum achievable resolution. Another limitation of this
imaging mode is associated with the coverage of the imaged strip in the slant range direction, which is

2.20.2 Basics Concepts in SAR Imaging and SAR Interferometry
1051
(a)
(b)
FIGURE 20.5
Stipmap (a) and Spotlight (b) operational modes.
in this case provided by the ground range extent of the real antenna footprint [25]. Slant range coverage
and imaging resolution can be traded-off by operating a beam steering during the acquisition. Beside
the classical stripmap mode, the two most known operational mode are spotlight and scan mode.
In the Spotlight mode the antenna beam is steered backward with respect to the antenna ﬂight
direction in such a way to collect data from a ﬁxed area on ground on a longer (compared with the
classical stripmap mode) ﬂight segment [26,29,30]. The spotlight imaging mode geometry is depicted
in Figure 20.5b.
In particular with respect to the stripmap mode (Figure 20.5) where the beam orientation is ﬁxed, in
the spotlight mode what is ﬁxed is the illuminated area: this spotlight conﬁguration is usually referred
to as staring spotlight mode. A conﬁguration that allow obtaining illumination interval and hence
resolutions between the stripmap and staring spotlight mode is the so called sliding spotlight in which
the angular beam steering rate is reduced in such a way to allow the footprint to slide on the ground
[31,32]. With respect to the staring spotlight, the resolution loss is compensated by an increase of the
azimuth coverage.
A mode complementary to the spotlight is the ScanSAR mode [33] whose geometry is shown in
Figure 20.6. In this case the antenna is steered in the range direction to increase the range coverage.

1052
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
FIGURE 20.6
ScanSAR operational mode.
During the aperture synthesis in azimuth, the beam is regularly steered in range to sweep among a ﬁxed
number (typically 2–4) of adjacent range subswaths. The sweep mechanism is carried out in such a way
to avoid gaps along the azimuth direction over the subswaths, i.e., to avoid the presence of areas which
are not illuminated in the azimuth direction. The data collected in an illumination sub-interval for a
generic subswath is called burst. In the stripmap case each target is imaged from the whole antenna
beam and therefore the radiometric accuracy is preserved, that is homogenous area are imaged in a
(average) constant backscattering level. In the ScanSAR case, as the target is seen only from a, or from
a few small portions of the azimuth beam during the burst acquisition, not only we have a reduction of
the azimuth resolution (this is the price for the increase in the range cover), but also different areas can
be seen by different portions of the azimuth antenna beam. The latter effect produces radiometric losses
seen as stripes along the azimuth (scalloping): homogenous area are imaged in a variable backscattering
level. A mitigation of the scalloping problem is achieved by the adopting a TOPS (literally reverse of
SPOT) acquisition mode [34]. In this case, in addition to the range steering, a steering in azimuth, with
a forward rotation (i.e., opposite to that of the SPOT mode), is carried out to allow the azimuth beam to
run forward, faster that the platform, in such a way that almost all scatterers in azimuth are imaged by
the highest possible beam portion.
The azimuth resolution for the different modes can be evaluated by referring to the Doppler band-
width, evaluated in (20.7), which can be written as a product of the Doppler rate fM and the integration
time Tint:
Bd = fMTint.
(20.8)

2.20.3 SAR Interferometry
1053
Equation (20.8) follows directly from the fact that the signal collected along the azimuth direction (slow
time) is with a good approximation a linear frequency modulated pulse; the associated Doppler rate fM
equals:
fM = 2v2
λr .
(20.9)
In the Stripmap case the integration time is ﬁxed by the real antenna beamwidth:
Tint = λ
L r 1
v.
(20.10)
By substituting Eqs. (20.10) and (20.9) in Eq. (20.8), Eq. (20.7) is obtained. In the Scansar and Spotlight
cases, due to the range or azimuth antenna sweep, the integration time is ﬁxed to a value which is lower
and higher than the limit in (20.10), respectively, in order to select the wanted azimuth resolution.
It is important to point out also that, while in the Stripmap case the spectral properties of the received
signal are time invariant along the azimuth, in the case of Scansar and Spotlight acquisition, due to the
antenna steering, the spectral properties show an azimuth space variance. For instance, in the spotlight
mode, and particularly in the sliding spotlight conﬁguration, due to the difference between the platform
and footprint velocity, the angular view of the system to the scene is azimuth dependent and accordingly,
the received Doppler bandwidth is progressively translated from positive to negative frequencies. All
these aspects must be accounted during post processing, such as for instance image resampling and/or
image ﬁltering as in the case of SAR interferometry [35].
2.20.3 SAR interferometry
SAR image is a 2D complex signal, resulting from the coherent processing of raw data acquired from
the synthetic antenna [26]. The amplitude of the SAR images represents the reﬂectivity of the ground
area under view while the phase of the SAR images is randomly distributed [26,36]. In addition to
electromagnetic scattering properties of the targets, the latter embeds also very important geometrical
measurements.
Such information can be extracted exploiting two [37–39] (or more than two [40–42] SAR complex
images in the framework of SAR interferometry. In particular, the term SAR Interferometry (InSAR) is
referred to all methods that employ at least two complex SAR images, exploiting mainly their phases,
in order to derive more information about a ground scene respect to the information provided by a
single SAR image. The additional information is provided when at least one among the key acquisition
parameters of the SAR system is different from acquisition to acquisition.
There exist two possible main conﬁgurations of SAR Interferometry: across track interferometry [38]
and along track interferometry [43]. In the across track conﬁguration, two (or more) SAR sensors ﬂy
on two parallel ﬂight lines and look at the ground from slightly different look angles. In the along-track
conﬁguration, two (or more) sensors ﬂy on the same path, looking the scene from the same position
but with a very small temporal gap. The across track InSAR conﬁguration allows recovering the height
proﬁle of the ground area under observation, while the InSAR along track conﬁguration is mainly used
for measurement of fast displacements such as ocean currents [44] and for moving target detection and
velocity estimation [45,46].

1054
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
In all interferometric processing the starting point are the SAR complex images, that can be obtained
by means of a two dimensional (2D) processing of the raw data acquired from the SAR sensors [47]. The
SAR complex images z(x,r) are representative of the reﬂectivity of the ground scene, in the sense that
they are 2D discrete complex signals of the azimuth (x) and range (r) coordinates, where each sample
(an image pixel) embeds the mean reﬂectivity characteristics of a sampling cell of the ground scene.
2.20.3.1 Across-track SAR interferometry for measuring the surface topography
The regular and controlled oscillation of coherent radiation used in SAR systems allows determining
with high accuracy the variations of the propagation distance: such a basic property is the key principle
of interferometric techniques.
A single SAR image provides measurement about the backscattering scene property along two
directions: The target range (i.e., the distance of the target from the illumination track) and the position
of the target along the track (the azimuth direction). Hence, no information is provided on the angle
under which the target is imaged (look angle). Knowledge of the latter information completes the set
of coordinates in a cylindrical reference system with the axis coincident with the track, thus allowing a
full localization of the scatterers in 3D and therefore an estimation of topography.
Similar to the mechanism used in human visual system for the determination of the depth, SAR
interferometry is a technique that exploits the parallax in the view of the scene to allows extending
the capability of a single SAR system to the reconstruction of the scene elevation proﬁle: as SAR is
sensitive to distance whereas the visual system is sensitive to angles, the mechanism is indeed slightly
different.
Figure 20.7 shows the geometry of a basic (two-antenna) interferometric acquisition in the plane
orthogonal to the ﬂight track: it is clear that by measuring the range of the target with a single (master)
SAR system (say the blue line) it is not possible to uniquely localize the position of the scatterer because
at the same range would be located all of the points distributed on a equi-range curve (the blue1 one) in
the elevation beam (dash line).
By using a second (slave) antenna that images the scene from a different look angle the system is
able to measure also the range from a second location [48]: there is then only one point (the intersection
of the two equi-range, i.e., blue and red lines in Figure 20.7) that obey to the distance measurements
pair. The larger the separation between the two antennas, the sharper the crossing and hence the higher
the height accuracy. As in the visual system the 3D sensitivity is given by the difference in the location
of the object in the two images at the different eyes [37], the accuracy of the stereometric system in
Figure 20.7 is related to the variation of the distance of the target from one to the other antenna (range
difference). To provide sufﬁcient accuracy in such a range variation, SAR interferometry uses the phase
difference between the two SAR images: the path difference is hence measured to an accuracy which
is a fraction of the wavelength (centimeters at microwaves).
Speciﬁcally, the terms that plays the key role in the determination of the height is the path difference
δr. In particular, at large distances it can be shown that the (variation of) the path difference (with respect
to a reference point for instance located on a plane) is [37,39]:
δr ∼= δϑ
h
sin ϑ =
b⊥
r sin ϑ h,
(20.11)
1For interpretation of color in Figures 20.7 and 20.12 the reader is referred to the web version of this book.

2.20.3 SAR Interferometry
1055
Reference plane 
A1
h
A2
FIGURE 20.7
Interferometric geometry.
where (see Figure 20.7) δϑ is the variation of the look angle between the master and slave antenna,
b⊥is the orthogonal baseline component, that is the component orthogonal to the (master) line of sight
of the vector (baseline) connecting the two satellites, and ϑ is the incidence angle, that is the angle
between the vertical direction related to the target and the direction of the incoming radiation (line of
sight). It is however important to note that Eq. (20.11) represent a simpliﬁcation of the true scenario
which is useful to understand the key principles of across-track interferometry. In the reality, the height
is referred to a geographic or cartographic reference system and determined by measuring δr and by
knowing the orbital state vectors [49].
In SAR interferometry the path difference is measured to accuracy of the order of the wavelength by
using the phase difference signal:
ϕ12 = 4π
λ

r2 −r1

= 4π
λ δr ∼= 4π
λ
b⊥
r sin ϑ h.
(20.12)
For application to topographic mapping the two interferometric images can, or better should be acquired
at the same time by two antennas on the same platform (bistatic system). This is because changes in
the scattering properties, as well as differences in the propagation phase delay through the atmosphere
strongly impact the quality of the retrieved DEM. In the case of the Shuttle Radar Topography Mission
(SRTM) in 2001 an extensible boom 60 m long was mounted on-board the Shuttle to separate the slave
from the master antenna available in the fuselage [50]. The German TanDEM-X mission of 2010 is
instead the ﬁrst example of a bistatic system composed by two twin satellites (TerrSAR-X and Tandem-
X) orbiting in a close (500 m one behind the other) formation [51].
2.20.3.2 Statistical characterization of across-track SAR interferometric signals
As mentioned before, an Across Track SAR interferometric (InSAR) system is used to reconstruct earth
topography, providing high precision Digital Elevation Model (DEM) of Earth surface. The geometry

1056
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
of an InSAR system has already been shown in Figure 20.7, where two SAR systems look at the scene
from two slightly different tracks. As already introduced, the distance b between the two SAR tracks is
called baseline, its component orthogonal to the look direction b⊥is the orthogonal baseline, while its
component parallel to the look direction (to the slant range) b|| is the parallel baseline.
In order to understand how an InSAR system works, consider the distance r1 between the ﬁrst SAR
antenna A1 and a point target T on the ground, and the distance r2 between the second SAR antenna A2
and the same point target T, as shown in Figure 20.7, while ϑ1 and ϑ2 denote the angles at which the
two antennas look at the point target on the ground (slightly different from each other).
Consider now the two complex (envelope of the) images Z1(n, m) and Z2(n, m) obtained processing
raw data collected by the two SAR sensors, where (n,m) are the discrete coordinates corresponding to
the continuous azimuth and range coordinates (x,r). Such images can be considered as random processes
whose expression is [52]:
Zk(n, m) = ρ(n, m)e jϕρ(n,m)e j 4π
λ rk(n,m)Xk(n, m),
k = 1, 2,
(20.13)
where ρ(n, m)e jϕρ(n,m) is the complex envelope of the (deterministic) ground reﬂectivity function
(which, in ﬁrst approximation, can been assumed to be constant with the antenna position k = 1, 2, since,
as commented above, the view angles change only slightly from one position to another), [4πrk(n, m)/λ]
are phase factors related to the different propagation paths between the two antenna positions and the
point target, and
Xk(n, m) = Ak e jk(n,m),
k = 1, 2
(20.14)
is the random process representing the multiplicative speckle noise at the kth antenna, typical of any
coherent system, which is commonly assumed to be a complex Gaussian correlated process with zero
mean and unit variance [53]. Of course, Zk(n, m) are also random processes.
As result of the SAR signal model given by (20.13) and (20.14), the phase of a SAR image pixel
(n,m) is given by three main contributions:
•
a ﬁrst term ϕρ, representing the phase shift induced by the scattering mechanism; it is deterministic,
and it is the same for the two antennas;
•
a second term [4πrk/λ], representing the phase shift due to the different propagation; it is determin-
istic, and it is depends on the antenna;
•
a third term k, induced by the coherent nature of the SAR processing; it is random, and it is depends
on the antenna.
Other phase terms related to geometrical uncertainties, to random propagation effects, or to the changes
of the scattering mechanism between the two SAR image acquisitions (for instance, due to the time
delay between the two acquisitions) can be also present in Eq. (20.13).
After a processing called image registration which aims to locate the response of a target in the
azimuth range pixel in the two images same pixel [37,54], the two SAR images Z1 and Z2 are used to
build the so-called multi-look SAR interferogram:
12 = arg
	 NL

n=1
Z(n)
1 Z∗(n)
2

,
(20.15)

2.20.3 SAR Interferometry
1057
where arg(·) denotes the principal value of the phase, NL is the number of looks [26], and the explicit
dependence on (n,m) has been understood (the same will be made in the following). Equation (20.15)
represents, for homogeneous targets, the Maximum Likelihood Estimator (MLE) of the interferometric
phase [39]. In the following, we will consider the single look case, with NL = 1.
From (20.12) and (20.13), it is easy to show that the interferometric phases are related to the observed
scene height proﬁle through the well known mapping [3,53]:
12 =
4π
λ δr + 12

2π
= ⟨ϕ12 + 12⟩2π,
(20.16)
where ⟨·⟩2π denotes the modulo 2π operation and
12 = arg

X1X∗
2

= ⟨1 −2⟩2π
(20.17)
is the decorrelation phase noise related to the phase differences of the speckle. In Eq. (20.16) it has been
assumed, as commented before, that the scattering phase term ϕρ, is constant in the two SAR images,
so their differences vanishes.
The problem to be solved in across track InSAR consists of estimating the height values h(n, m),
starting from the measured (then, noisy) wrapped phases 12(n, m). Such problem is worldwide known
as phase-unwrapping problem, as it amounts to ﬁnd the unwrapped phase ˆ12 (not constrained to belong
to the interval [0,2π)) corresponding to the measured wrapped phase 12 (constrained to belong to the
interval [0,2π)) [55]:
ˆ12 ∼= 12 + 2iπ,
i = . . . , −2, −1, 0, 1, 2, . . .
(20.18)
The unwrapped phase will be proportional to an estimate of the height h, according to the model given
by Eq. (20.12):
ˆ12 =
4πb⊥
λr sin ϑ
ˆh = α12 ˆh.
(20.19)
Once that the phase unwrapping problem (20.18) has been solved, an estimate of the height proﬁle can
be obtained from Eq. (20.19).
Equation (20.19) shows how much sensitive is the unwrapped phase with the height. Considering a
ﬁxed geometry for the satellite (or airplane) carrying the SAR antennas (R0 and ϑ are ﬁxed), it is easy
to understand that the larger the orthogonal baseline and the larger the frequency, the more sensitive
is the SAR interferometer. In other words, if we want to measure the height proﬁle h, it could seem
more convenient to use a larger baseline and a higher frequency, because for a given variance of the
phase noise, the corresponding height variance (inaccuracy) decreases (see Eq. (20.19)). However, an
increase of the baseline value may contributes to decorrelate the two speckle phase contributions (1
and 2), thus increasing the interferometric phase noise (geometrical or spatial decorrelation) [56,57].
For a distributed scattering the correlation between the two speckle contributions decreases linearly
with the increase of the baseline [37,39], for a point scatterer the decorrelation disappear because such
targets are not affected by speckle. The difference between such two scattering mechanisms inﬂuences
also the multipass interferometric processing chains (see Section 2.20.4). In any case an increase in the
baseline impact also the degree of complexity of the phase unwrapping step described in the following
sections.

1058
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
Before describing in the following sub-section part the several methods that have been proposed in
the scientiﬁc literature to solve the phase unwrapping problem [42,58–63], it is important to describe
the random nature of the SAR complex signal and of the SAR phase terms.
Consider the random terms Xk, k = 1, 2 given by (20.14), representing the multiplicative speckle
noise present in the SAR complex signals Zk, k = 1, 2 given by (20.13). Such random terms can
be modeled as zero mean, mutually correlated Gaussian complex variables with unit variance, which
assume uncorrelated values in adjacent pixels, and have real and imaginary parts mutually uncorrelated
[52]. By understanding the dependence on range and azimuth discrete co-ordinates n and m, for the
sake of simplicity of notation, we can consider the vector:
X =
 Xc1
Xc2
Xs1
Xs2
T ,
(20.20)
whose (real valued) elements Xck and Xsk, with k = 1,2, denoting the cosine and sine components of
the speckle signal Xk, are zero mean Gaussian random variables. The assumed statistical model implies
that [52]:
a. Xci and Xsk are independent ∀i, k: E[Xci Xsk] = E[Xci]E[Xsk] = 0;
b. the cross-correlation between Xci and Xck is equal to the cross-correlation between Xsi and
Xsk, ∀i, k: E[Xci Xck] = E[Xsi Xsk].
Note that the Xci, Xsk independence is true if the speckle band-pass spectrum is Hermitian respect to
the central frequency, assumption which can be considered always satisﬁed since the speckle vector X
is related to the complex envelope of a modulated real signal [64]. Moreover, from the assumption (b),
it stems that E

X2
ck

= E

X2
sk

, k = 1, 2.
In these assumptions, the probability density function of the vector X is given by [65]:
fX(x) =
1
(2π)3 |C|1/2 exp

−1
2xT C−1x

,
(20.21)
where x =

xc1
xc2
xs1
xs2
T , and C is the covariance matrix given by:
C =
⎡
⎢⎢⎣
1
γ12
0
0
γ12
1
0
0
0
0
1
γ12
0
0
γ12
1
⎤
⎥⎥⎦,
(20.22)
where γ12 is the correlation coefﬁcient of Xc1 and Xc2, which by virtue of assumption (b) assume the
same value of the correlation coefﬁcient of Xs1 and Xs2, given by:
γ12 =
E

Xc1Xc2


E

X2
c1

E

X2
c2
1/2 =
E

Xs1Xs2


E

X2
s1

E

X2
s2
1/2 ,
(20.23)
where E[·] denotes expectation. Note that in Eq. (20.23) the terms present at the denominator are equal to
one, as they represent the unit variance of the considered processes, so that their explicit presence should

2.20.3 SAR Interferometry
1059
not be necessary. Nonetheless, we use such deﬁnition, as it is valid also in the case of not-normalized
processes.
We note that, according to the assumptions (a) and (b), γ12 given by (20.23) is equal to the interfero-
metric coherence usually employed in InSAR systems [57], deﬁned starting from complex signals [3]:
η12 =
E

X1X∗
2


E
|X1|2
E
|X2|21/2 =
E

Xc1Xc2


E

X2
c1

E

X2
c2
1/2 = γ12,
ηC,12 =
E

Z1Z∗
2


E
|Z1|2
E
|Z2|21/2 =
E

X1X∗
2


E
|X1|2
E
|X2|21/2 e j 4π
λ (r1−r2)
= η12 e j 4π
λ (r1−r2) = γ12 e j 4π
λ (r1−r2).
(20.24)
Note that ﬁrst result of Eq. (20.24) (η12 = γ21) implies that the coherence η12 of the (complex) speckle
noise is real valued, due to the above assumptions (a) and (b). Note also that the module of the coher-
ence ηC,12 of the complex received signals Z1 and Z2 is, in module, equal to the coherence η12 of the
(complex) speckle noise.
Starting from Eq. (20.21), it is possible to derive, by a change of variable from Cartesian to polar
(from X to A1, A2, 1, 2), and following integration with respect to A1 and A2, the pdf of the
single-look speckle phase difference 12 = (1 −2) [53]:
f12

ω12

= 1
2π
1 −|γ12|2
1 −|γ12|2 cos2 
ω12

×

1 + |γ12| cos

ω12

cos−1 
−|γ12| cos

ω12


1 −|γ12|2 cos2 
ω12
1/2

,
ω12 ∈

−π, π

, (20.25)
where the dependence of phase difference ω12 and γ12 on (n,m) has been, as before, understood.
The coherence coefﬁcient γ12 is inﬂuenced by all factors that cause differences between the two
complex speckle images X1 and X2. The larger these differences, the smaller the coherence coefﬁ-
cient’s value. A coherence reduction can be induced by actual physical changes occurring between the
acquisition times of the two data sets (temporal decorrelation) and/or by changes of the ground reﬂec-
tivity when it is seen from different angles (spatial decorrelation) [57]. Note that also the coherence is
a function of the ground coordinate pair (n,m), so that it may change across the image.
The plot of the speckle phase difference pdf (20.25) for different values of the coherence coefﬁcient
is given in Figure 20.8. It has to be noted that the pdf become less picked by reducing the coherence
value. The smaller the coherence value, the larger the variance of the speckle phase noise.
The joint pdf f12(ψ12; h) of the interferometric phases can be obtained from the joint pdf of the
speckle noise phase f12(ω12) given by Eq. (20.25) and plotted in Figure 20.8, exploiting the random
variable transformation given by Eq. (20.16), which leads to:
f12

ψ12; h

= f12

ψ12 −α12h

,
(20.26)
where the dependence of phase difference ψ12, h, and γ12 on (n,m) has been again understood. The
pdf’s (20.26) have the same shape of pdf of Eq. (20.25), but they are centered on the value α12h.

1060
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
-3
-2
-1
0
1
2
3
0
0.2
0.4
0.6
0.8
1
=0.1 
=0.3 
=0.5 
=0.7 
=0.9 
γ
γ
γ
γ
γ
fΩ( )
ω
ω
FIGURE 20.8
Interferometric phase pdf plotted for different coherence values (0.01, 0.1, 0.25, 0.5, 0.7, and 0.9).
Such pdf family, that as it can be noted is parametrized by the height h, will be used as starting point
of some of the phase unwrapping methods described in the following section.
The pdf (20.26) of the interferometric phase is strongly inﬂuenced by the coherence. Such parameter
can be written as the product of four main contributions [3,39,57]:
γ = γSNRγGγZγT ,
(20.27)
where γSNR represents the inﬂuence of thermal noise in the receiver, γG represents the decorrelation
effects due to the different SAR view acquisition angles, depending upon the spatial baseline, γZ
represents the decorrelation effects due to volume scattering mechanisms, and γT represents the so
called temporal decorrelation effects [3,4].
The ﬁrst factor in Eq. (20.27) can be computed starting from the circular Gaussian and independent
nature of thermal noise and is given by:
γSNR =
1
√1 + 1/SNR1
√1 + 1/SNR2
,
(20.28)
where SNR1 and SNR2 are the signal to noise ratio on the two receiving SAR interferometric antennas
[4,53,57].
The second factor in Eq. (20.27) is the so-called geometric coherence, also referred to as angular or
baseline coherence; it is present for all scattering situations, it depends on the system parameters and on
the overall observation geometry, including the different SAR view acquisition angles, and depending
upon the spatial baseline.

2.20.3 SAR Interferometry
1061
Geometric coherence values can be easily computed, in case of ﬂat terrain, and for a white scattering
process, leading to [3]:
γG =

1 −b⊥
bc

for |b⊥| ≤bc,
0
elsewhere,
(20.29)
where b⊥is the orthogonal baseline and bc is the orthogonal critical baseline given by:
bc =
λr
2δr cot

ϑ −β
,
(20.30)
where all symbols in Eq. (20.30) have been previously introduced.
Geometric decorrelation effects, for ﬂat terrain geometry, can be explained also from the so-called
spectral shift effect [55]. This interpretation allows also to derive a ﬁltering strategy of the interferometric
channels aimed at mitigating such decorrelation. Such proper processing is also called “common band
ﬁltering” [55,66], because requires to process, to maximize the geometric coherence value, the common
(overlapped) part of the spectrum of the two interferometric signals. The larger the baseline, the larger
the terrain slope, the less the common part of the two spectra, and the larger the decorrelation effects.
For a non-ﬂat topography the approach in [67] can be adopted. For the ERS and ASAR-ENVISAT
sensors, the critical baseline is of about 1100 m for β = 0, while for the last generations high resolution
systems such as COSMO-Skymed and TerraSAR-X, this value is signiﬁcantly enlarged. Therefore, for
these new generation sensors, thanks to fact that the distribution of the baseline values is bounded by an
“orbital tubes” signiﬁcantly smaller than the critical baseline, such common band ﬁltering is typically
not required.
Similar effects can be induced also in the azimuth direction by the presence of variations of the
azimuth antenna pointing [67]. This effect can be critical in some acquisition modes where antenna
steering is present, such as in ScanSAR and Spotlight modes. Also in this case, the larger the acquisition
geometric diversity, the less the spectra overlapping, and the larger the decorrelation effects.
The third factor in Eq. (20.27) γc, is the volume coherence, it is due to volume scattering, and it is
the effect induced by the scattering layer to increase the size projected range cell, and consequently, to
decrease the correlation distance. As in the case of γG, it is dependent on the spatial baseline.
The last factor in Eq. (20.27) γT represents the so called temporal decorrelation [57] due to the
instability of scattering mechanisms in the two different acquisition times, as the structure of the scatterer
can change in the meantime between the two acquisitions. Such effect can be very important when the
two SAR images are acquired at distance of several days or months in the case of vegetated or agricultural
areas, or in presence of different climatic conditions.
2.20.3.3 The differential SAR interferometry technique for measuring
displacements
Differential Interferometry (DInSAR) is a particular conﬁguration of SAR interferometry. The reference
geometry is the same of the classical InSAR case, but the target on the ground is allowed to move,
displacing of say d, between the two successive passes (see Figure 20.9).
In the following, for sake of simplicity, we indicate deterministic and stochastic terms all with non-
capital symbols: the nature is speciﬁed whenever ambiguous. In this case, the interferometric phase is

1062
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
d
δrd
FIGURE 20.9
Differential interferometric geometry.
composed by three main factors:
ϕ = 4π
λ δr = 4π
λ δrd + ϕz + ϕa + ϕn,
(20.31)
where δrd is the measured range variation that, in the far ﬁeld observation approximation, is equal to
the component of the displacement along the line of sight, ϕz is the phase contribution corresponding
to the target height as in Eq. (20.12), ϕa is a stochastic term associated with the variation, between the
two passes, of the wave propagation delay through the atmosphere, ϕn is the phase noise which in this
case includes also the temporal decorrelation effects in addition to the decorrelation noise due to the
speckle (ω in Section 2.20.3.2). In the cases in which the topographic contribution is limited, that is
if the baseline is negligible and/or an external DEM is available to compute and cancel out ϕz from
Eq. (20.31), and in the case of a predominance of the deformation component and/or limited effects of
atmosphere, displacements can be measured to accuracy which are on the order of the wavelength. By
using this classical two passes DInSAR conﬁguration in the past Scientists have been able to capture
the surface deformation ﬁeld generated by major earthquakes, or highlight deformation associated with
volcanic activities.
The idea of mapping ground deformation via the interference of signals acquired by SAR systems
was demonstrated for airborne systems in [43] and for the very ﬁrst time using real data from the
European Remote Sensing Satellite (ERS) in keystone experiments by [68], for ice-stream velocity
measures in Antarctica, and by [69] for the co-seismic deformation ﬁeld generated by the Landers
earthquake (CA-USA). The Landers result received cover of Nature (vol. 364, 8 July 1993, Issue No.
6433) with a title “The image of an Earthquake” that translates the importance of the achievements and
of the DInSAR technology with reference to application to seismic and to geo-hazards in general.
Today, with the availability of many SAR sensors with interferometric capabilities orbiting around
the Earth, co-seismic, i.e., before and after main seismic events (see Figure 20.10), DInSAR data are
almost analyzed routinely by scientists to study the displacements induced by known and unknown
geological faults that are the causes of catastrophic events all over the world.

2.20.3 SAR Interferometry
1063
FIGURE 20.10
Co-seismic interferogram of the Bam earthquake obtained by a combination of Envisat Advanced Synthetic
Aperture Radar (ASAR) Wide Swath Mode (WSM) image with an Image Mode (IM) image.
Polimi/Poliba.
An example of measurement of DInSAR co-seismic displacement is reported to provide an idea of the
powerfulness of this technology with reference to the 6.6 Mw Iran earthquake in 2003 that stroke the city
of Bam. The image Figure 20.10, shows the co-seismic interferogram obtained by interferometric com-
bination of the SCANSAR (Wide Swath Mode) acquisition of September 24th, 2003 and the STRIPMAP
(Image Mode) acquisition of December 3rd, 2003: each color-cycle correspond to 1.55 cm in the line
of sight. The coherence of the data and therefore the quality of the interferogram is very high due to the
arid nature of the region: each color-cycle correspond to 2.8 cm displacement in the line of sight.
A key factor in such application is associated with the revisiting time. The retired satellites ERS-1,
ERS-2, and ENVISAT of the Europen Space Agency have been the satellites on which repeat pass
interferometry has been experimented for the very ﬁrst time. These satellites were characterized in the
normal operational situation by a strip width of approximately 100 Km EW and a revisiting time (i.e., the
time necessary to repeat approximately the same orbit) of 35 days. The revisiting time poses a limitation
to the minimum number of days necessary to generate an interferogram. The new generation of sensors
operating at slightly lower orbits with respect to ERS and ENVISAT, such as TerraSAR-X and Tandem-
X allows reducing the revisiting time to 11 days. The Italian COSMO-SkyMed (CSK) constellation is a
constellation formed by four SAR satellites that acquires data for interferometric use, regardless of the
speciﬁc satellite. This peculiarity allows CSK to provide the highest maximum revisit rate of an area
of interest, that is one acquisition every 4 days (on average) for the whole constellation, instead of one
acquisition every 16 days for a single satellite. CSK and TerraSAR-X provide spatial resolution (between
1×1 and 3×3 m2) one order of magnitude better than the previous available C-Band satellite SAR data.
ThesesystemsoperatesinX-bandandarecharacterizedbyhigherspatialresolutionwithrespecttothe
past ESA C-Band satellites; the counterpart of these advantages are however the reduced swath coverage
which in the classical stripmap imaging mode reduces to 40 Km in the EW direction. An example of co-
seismic interferogram obtained with a 8 days temporal baseline form COSMO-Skymed data is discussed
in the following. On 6 April, 2009 the MW 6.3 L’Aquila earthquake occurred in the Central Apennines

1064
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
FIGURE 20.11
Co-seismic interferogram of 6 April 2009 6.0 Mw l’Aquila earthquake in Italy. COSMO-Skymed acquisitions
of 4 April 2009 and 12 April 2009.
(Italy) causing extensive damage to the town of L’Aquila and killing 300 inhabitants. The event epicenter
was located few kilometers southwest of the town of L’Aquila, the main shock nucleated at a depth
of ≈9 km, was preceded by a preseismic sequence with the largest shock having a ML 4 magnitude,
and was followed by a vigorous aftershock sequence. In Figure 20.11 it is shown the interferogram
evaluated by the CSK pair of April 4th and April 12th: the activated fault is located NW-SE emerging
to the right of the dense fringes area: each color-cycle correspond to 1.55 cm in the line of sight.
Since then, many experiments showed the potentiality of the technique in detecting deformation phe-
nomena not only associated with earthquakes [70] but also in volcanic areas [71,72] and of glaciers [73].
However, in order to fully exploit the potentiality of the SAR technology in order to measure defor-
mation with a centimetric/millimetric accuracy two or few images are typically not sufﬁcient. At such
accuracy level the presence of the atmospheric component and additional disturbing contributions such
as orbital inaccuracies cannot be in fact neglected. For sake of simplicity we indicate still with ϕ the

2.20.3 SAR Interferometry
1065
differential interferometric phase obtained after the subtraction of the contribution associated with the
DEM (differential interferogram). We have therefore:
ϕ = 4π
λ δr = 4π
λ δrd + ϕz + ϕa + ϕo + ϕn,
(20.32)
where ϕo is associated with orbital inaccuracies which affect the computation of the phase contribution
associated with the topography (baseline error): as for Eq. (20.31), the noise term is associated with
the noise contributions such as decorrelation of the response not only due to variation of the speckle
contribution due to the angular imaging diversity (spatial baseline decorrelation), but also to changes of
the backscattering response over the time (temporal decorrelation). Availability of on board GPS systems
allows signiﬁcantly mitigating the effects of orbital errors; for airborne systems which are subject to
trajectory deviations due to turbulence the GPS must be integrated with accurate inertial navigation
systems. Due to the DEM subtraction ϕz is now the residual target height, i.e., the height of the target
with respect to the reference DEM. Accordingly, to have the possibility to achieve measurement of
small deformation components, use of accurate external DEM as well as small baseline separations, is
mandatory. In any case the atmospheric component plays a major role because it causes the presence
of errors which are spatially correlated and therefore may be mixed with possible deformations.
The atmospheric contribution is typically separated in two components: a turbulent component
which is associated with the air inhomogeneity and that causes a spatial variation of the Atmospheric
Phase Delay (APD) and a stratiﬁed component which is associated with the vertical stratiﬁcation of
the atmosphere. Both these terms occur in the lower part of the atmosphere, the troposphere, whereas
contribution in the upper part of the atmosphere mainly show contributions which are very low spatial
variable and can be misinterpreted as orbital inaccuracies. The former is commonly referred to as
wet component and is dependent on the relative humidity, the latter, also referred to as hydrostatic
or improperly as dry component, is responsible of a contribution which is highly correlated with the
topography and therefore almost negligible on quasi ﬂat areas. A model that describes the statistical
behavior of the turbulent component is due to Kolmogorov. In this case the turbulence is assumed
spatially stationary and isotropic. The refractivity index, i.e., the excess in parts per million of the
reﬂectivity index with respect to the vacuum, that provided the increase in the path difference due to the
crossing of the atmosphere can be modeled in terms of the variogram, i.e., the variance of the difference
of the refractivity contributions between two points. For separations below the order of a kilometer, the
variance of the difference of the refractivity between two points small and decreasing with a power of
2/3 of the distance. A more thoughtful characterization and analysis of the tropospheric contribution
can be found in [74].
The temporal correlation of the atmosphere is however typically low: this means that APD contribu-
tions over different epochs can be averaged together to diminish it contribution on the path difference.
Therefore to measure small (up to millimeter per year) displacements and to handle the problem of
monitoring at high resolution ground scatterers, techniques based on the use of several images acquired
over the same scene have been developed. In fact, by exploiting a higher dimensional acquisition space,
the “phase ﬁrms” of the different components such as DEM error, displacement, and APD can be
deterministically or stochastically characterized and estimated directly from the received data. This
topic is treated in more details in Section 2.20.5.

1066
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
FIGURE 20.12
Phase unwrapping problem in 1D: example of the effects of wrapping.
2.20.3.4 Phase unwrapping
Unwrapping aims at reconstructing an unrestricted (absolute2) signal starting from a measured wrapped
signal version restricted a reference interval. In the case of interferometry, the phase is intrinsically
wrapped in the (−π, π) interval being extracted from complex values. Accordingly, we have:
ψ = ⟨ϕ⟩2π =

ϕ + π

mod 2π

−π,
(20.33)
where ψ and ϕ are the restricted (wrapped) and unrestricted (absolute) phase. Phase unwrapping is a
step necessary to reconstruct a phase signal ˆϕ which is an estimate of ϕ.
Figure 20.12 reports an example in a 1D case: phase unwrapping aims to estimate the absolute phase
(shown in blue) starting from the measured restricted phase (shown in red).
It should also be noted that the term “absolute” phase in the interferometric context is typically used
to refer to the phase corresponding to δr which has been corrected by an offset to account for the correct
number of global cycles which are lost due to the wrapping operator and for the timing errors. In SAR
interferometry such an offset is commonly evaluated after phase unwrapping by using one or more
reference points with a known topography.
The problem of unwrapping is ambiguous as it admits in principle inﬁnitely many solutions (the
wrapped phase can be itself a possible absolute phase), and a reasonable solution can be obtained by
imposing a certain degree of continuity: the absolute phase in Figure 20.12 is, among all possible abso-
lute phase functions corresponding to the measured wrapped phase, the continuous one. Unfortunately,
2The term “absolute” is in the phase unwrapping context related to the restriction operator and does not concern the absolute
value operator.

2.20.3 SAR Interferometry
1067
in real cases, in addition to the noise, the problem is further complicated by the presence of a ﬁnite sam-
pling rate, see the measured red diamond samples in Figure 20.12 and the absolute black star samples
corresponding to the absolute phase. Moreover, the actual solution could be locally not continuous.
In the following, some popular approaches to solve the phase unwrapping problem and to recover
the height proﬁle of the ground scene will be described.
2.20.3.4.1
Residue cut algorithms for PhU
Residue cut [75], also known as branch-cut algorithms have been a workhorse for the PhU for many
years prior to the advent of more effective solutions based on Least Square and optimizations based on
Linear Programming algorithms. The starting point of this approach is the estimation of the absolute
phase variations along arcs ϕ wrapped phase variation ψ. In particular it results that
u = ⟨ψ⟩2π = ⟨ϕ⟩2π
|ϕ| < π

=
ϕ,
(20.34)
where  f = f

n −1

−f (n) and where the ﬁrst equality is taken as the deﬁnition of u that is of
wrapped variation of the wrapped phase. Equation (20.34) states that, by wrapping the variation from
sample to sample of the measured wrapped phase an estimate of the absolute phase variations can be
retrieved provided that the latter is limited to the restriction interval, i.e., within the (−π, π) interval.
Followingthestageofestimationoftheabsolutephasedifferences,anintegrationstepoftheestimated
variations must be implemented to pass from ϕ to ϕ. Possible errors on a phase variation estimate,
either due to an intrinsic variation of the absolute phase or to a missing wrapping jump due to the noise,
propagates in all the subsequent samples during the integration process.
A way to control such errors is by measuring redundant variations: in the 1D case this is only possible
if we measure the variations over non adjacent samples: this operation is however critical because of
the higher probability to variations of the absolute phase larger than π, thus impacting the validity of
the approximation in Eq. (20.34). Fortunately, the 2D case allows having higher redundancy degree
of even limiting the measurement of spatial variations over adjacent samples [76].
The basic idea of the residue cut algorithm is to follow elementary closed circuits deﬁned on the
set of image pixel and check for the presence of inconsistencies in the estimate of the absolute phase
variation.
Following the stage of estimation of the absolute phase differences, the algorithm proceeds with the
integration of the estimated variations but carries out a consistency check on the loops. By referring to
Figure 20.13, we refer for simplicity to two elementary loops: the triangular shape of the circuits is a
choice that is typically carried out when the phase unwrapping has to be carried out on a sparse grid.
Assuming for instance an anticlockwise direction of the loops, it is clear that if the estimates of the true
phase variation are correct, i.e., corresponding to the absolute phase we have:
u1 + u2 + u3 = ϕ1 + ϕ2 + ϕ3 = 0,
u5 + u3 −u4 = ϕ5 + ϕ3 −ϕ4 = 0.
(20.35)
If, however, due to the wrapping operator in (20.34), at least one of the estimate is affected by errors,
say u3 for which we have that u3 = ϕ3 −2π then the closed loops on the left in Eq. (20.35) do not

1068
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
u5
u3
u2
u1
u4
FIGURE 20.13
The integration of the estimated ablsolute phase differences over closed paths.
FIGURE 20.14
Representation of the phase and phase variations on elementary closed loops for the phase unwrapping on
a regular 2D grid.
sum up to zero:
u1 + u2 + u3 = ϕ1 + ϕ2 + ϕ3 = 2π,
u5 + u3 −u4 = ϕ5 + ϕ3 −ϕ4 = −2π.
(20.36)
In this situation, it is the loops are said to be affected by residues. It is clear that due to a choice of
the loop orientation, residues appear always in pair. The line connecting the two residues, which are
supposed to be located at the center of the loops, is referred to as cut and intersects the wrong absolute
phase estimate: this phase variation is eliminated during the ﬁnal integration patch covering all pixels.
2.20.3.4.2
Least squares and Green’s solution to PhU problem
We refer, for sake of simplicity, to a regular 2D grid (see Figure 20.14): it is possible to measure the
horizontal ux(i,j) and vertical uy(i,j) variations between adjacent samples, leading to the measurement
from the wrapped phase values of a 2D ﬁeld u = ux ˆx+uyˆy, with ux

i, j

=
 
ψ

i + 1, j

−ψ

i, j
!
2π
and uy

i, j

=
 
ψ

i, j + 1

−ψ

i, j
!
2π, that represents an estimate of the gradient of the absolute
phase.
As already explained in the previous section, the variation ﬁeld should be zero curl, ∇× u = 0.
Obviously, due to the 2π (multiple) errors that affect the variation ﬁeld u, this condition is not always

2.20.3 SAR Interferometry
1069
satisﬁed and therefore the result of the process of integration of the spatial variations to retrieve the
unwrapped phase is dependent on the speciﬁc path. Instead of using circulation over elementary square
paths to locate the presence of vortex (residues) and to trace cuts between opposite residues to avoid the
integration path crossing areas over which summation over closed path is not zero, Least Squares and
Green’s algorithm try to ﬁnd a solution that carries out a global integration in such a way to mitigate
the error propagation.
Il particular the Least Squares approach looks for ϕ such that ∇ϕ is the “closest” (in some norm) to
u; more speciﬁcally:
ϕ = arg min ∥∇ϕ −u∥Lk
(20.37)
with typically k = 0, 1, 2. The least square solution (k = 2) can be easily achieved by solving the
Poisson equation [62,77]:
∇2ϕ

r

= ∇· u

r

,
(20.38)
for any r internal to the domain of interest (say S), with the following boundary condition:
∇ϕ

r

· ˆn

r

= 0,
(20.39)
for any r on the boundary (say C), ˆn

r

being the normal unit vector on the boundary curve.
An effective iterative implementation on a regular 2D grid can be achieved by iterating on each
(internal) pixel the following equation:
4ϕ

i, j

= ϕ

i −1, j

+ ux

i −1, j

+ ϕ

i, j −1

+ uy

i, j −1

+ ϕ

i + 1, j

−ux

i, j

+ ϕ

i, j + 1

−uy

i, j

.
(20.40)
assuming left and right values of the unknown to be corresponding to the current and previous iteration,
respectively. The iterative solution of (20.40) is appealing because it can be extended also to a sparse
2D grid via the use of triangulations.
Iterative algorithms might be however time demanding depending on the size of the processed
image: a more time-effective solution for a regular 2D grid is provided by frequency domain analysis.
In particular, by using the Green’s function formulation it can be shown that the solution to (20.38) and
(20.39) on a surface S with boundary C can be explicitly written as:
ϕ

r′
= −
" "
S
dS∇g

r′ −r

· ∇ϕ

r

+
#
C
dcϕ

r
 ∂g

r′ −r

∂n
,
(20.41)
wherein ∇ϕ is approximated (in the discrete space case) with the variations measured from the wrapped
data u and where g(r) is the free-space Green solution of the Laplace equation, i.e., :
∇2g

r

= δ

r

,
(20.42)
that is
g

r

= 1
2π ln |r| .
(20.43)
The solution in (20.41) is attractive because it allows to investigate analytically the spreading of errors
related to the errors related to the substitution of the true gradient with the measured gradient, i.e.,
∇ϕ ∼= u [61].
The Green solution requires, on the other hand, the knowledge of the true phase on the border, this
problem can be solved by adopting an iterative scheme in which starting from ϕ = 0, ϕ(r) is evaluated in

1070
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
all the points, including the boundary C. In the case of sparse grid of measurements where the boundary
may be characterized by multiple curves, it is preferable to use the FD approximation to the differential
equation.
2.20.3.4.3
Minimum cost ﬂow solution to PhU problem
In both methods, FD approximation and Green, the solution do not honour the data, in the sense that
ϕ is a multiple of 2π because the Least Square solution intrinsically diffuse possible error in u over
different pixels to achieve a global square minimum. Methods like the Minimum Discontinuity (MD)
[78] and Minimum Cost Flow (MCF) allow “honouring” the data, by directly search in a discrete space
the 2π multiple correction. The MD approach seeks for the 2πk ﬁeld that provides ϕ = ψ + 2πk,
with ψ collecting all the measured wrapped phase on the selected (full or sparse) grid, showing the
minimum discontinuity between adjacent points. The MCF algorithm [60,79], operates in a similar way
by seeking for the ﬁeld of integers k of correction to u (with minimum norm) such that the corrected
variation ﬁeld on a network deﬁned over the set of available pixel is characterized by a null rotational
component, i.e., it solves the problem:
⎧
⎪⎨
⎪⎩
ˆk = arg min
k
J

k

,
J

k

= ∥k∥L p ,
subject to ∇×

u + 2πk

= 0 on all closed loop,
(20.44)
where L p is the (typically weighted) LP norm.
The case p = 1 is chosen for the capability to limit the number of points in which the correction is
carried out, and at the same time allows using very efﬁcient Linear Programming solvers [60].
More speciﬁcally typically a triangulation is carried out to deﬁne a network over the sparse grid
of pixels selected according to a sufﬁcient level of coherence. Letting NaS be number of arcs of the
network, the objective function to minimize is written as:
J

k

=
NaS

j=1
w

j
 k j
,
(20.45)
where w( j) is the weight associated with the jth arc, the PhU amounts to solve the following problem
⎧
⎪⎪⎨
⎪⎪⎩
ˆk j = arg min
k j
NaS
(
j=1
w

j
 k j
,
subject to 2π (
j∈Cl
k j = −(
j∈Cl
u

j

for all out of L loops
(20.46)
with k j integer, and being Cl the generic elementary closed loop. Such a problem can be recast in a
linear form as described in Ref. [60]. In particular the following change of variables is implemented:

k+
j = max
)
0, k j
*
k−
j = −min
)
0, k j
*
j = 1, . . . , NaS,
(20.47)
thus leading to the following expression for the unknown vector and the objective function, respectively:
k j = k+
j −k−
j .
(20.48)

2.20.4 Multibaseline SAR Interferometry
1071
Therefore the problem (20.46) can be recast in the more feasible form:
⎧
⎪⎪⎨
⎪⎪⎩
+
ˆk+
j , ˆk−
j , j = 1, . . . , NaS
,
= arg min
	
NaS
(
j=1
w( j)k+
j −w

j

k−
j

,
subject to 2π (
j∈Cl
k+ 
j

−2π (
j∈Cl
k−( j) = −(
j∈Cl
u( j) for all l out of L loops,
(20.49)
whichisnowlinearwithrespecttotheallthe(positiveinteger)unknownk+
j andk−
j .Itisatypicalproblem
ofIntegerLinearProgramming(ILP)solvablewithcomputationallyefﬁcienttechniques[60,79].Thanks
to the particular structure of the network, which is based on a triangulation, the ILP problem in (20.49)
can be cast as a problem of ﬂow optimization problem for which very efﬁcient MCF solvers can be
used. For all j, after that the integers k+
j and k−
j are estimated, k j is evaluated via (20.48) and used to
correct the estimate of the variation over the arc of the network, u j, spatial integration (which is no
more dependent on the integration path) is applied to retrieve the unwrapped interferogram.
Reference [76] provides a complete comparison between the above PhU approaches.
2.20.4 Multibaseline SAR interferometry
The statistical approaches developed to solve the problem of Phase Unwrapping and SAR interferometry
are based on the exploitation of the statistical model of the SAR interferometric signal [42]. The
statistical techniques are in general based on the use of more than two SAR complex images (at least
two interferograms) [40–42,80–82], and are often referred as multi-channel SAR Interferometry.
The basis geometry of a multi-channel SAR system is reported in Figure 20.15.
First consider the dual channel case (classical SAR Interferometry). As it has been shown in the
previous sections, the actual measured values of the interferometric phase 12 differ from the nominal
ones by virtue of phase noise effects, as modeled by pdf described by Eq. (20.26). Once the data (12)
has been observed, Eq. (20.26) can be seen as a function of the unknown parameter h, providing the
single-interferogram likelihood function.
The plot of the likelihood function (Eq. (20.26) as function of h) for a given measured value of the
interferometric phase 12, and consequently of h, is shown in Figure 20.16, for two different coherence
values (γ = 0.8 for the solid line, γ = 0.4 for the dotted line). It shows very clearly that the likelihood
function, due to its periodic nature (the period is α12/2π), exhibits an inﬁnite number of global maxima.
Note also that the effect of different coherence values (the smaller the coherence value, the larger the
variance of the pdf of the data) is to change the amplitude and the curvature of the likelihood function.
The Maximum Likelihood solution of the Single Interferogram InSAR problem is given by:
ˆhML(n, m) = arg max
h
f12

ψ12(n, m); h(n, m)

.
(20.50)
Problem (20.50) admits the following inﬁnite solutions [40,42,83]:
ˆhML = ψ12
α12
± k 2π
α12
,
k = 0, 1, 2, . . . ,
(20.51)
as a direct consequence of the periodic nature of the likelihood function.

1072
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
Flight track 2 
r1 
Antenna 1 
Antenna 2 
Flight track 1  
b2 
r
h
T
2 
Antenna 3 
r3 
 
b1 
Flight track 3 
FIGURE 20.15
Interferometric SAR multi-channel geometry.
FIGURE 20.16
Single-interferogram likelihood function for different coherence values (γ = 0.8 for the solid line, γ = 0.4
for the dotted line).
In order to resolve this ambiguity, we can introduce additional independent phase measures. Sup-
pose we have multiple measures of wrapped phase 1i, i = 2,…,N, obtained in N different acquisition
conditions. Different wrapped phase values can be obtained, for instance, from SAR raw data acquisi-
tion from Nb different ﬂight track (baseline-diversity) as it is shown in Figure 20.15, or in Nb sensor

2.20.4 Multibaseline SAR Interferometry
1073
bands (frequency-diversity). For example, in the SIR-C/X-SAR mission X-, C-, and L-band data were
acquired (Nb = 3), while in the SRTM mission X- and C-band data were acquired (Nb = 2) [50]. Each
band could also be divided into sub-bands, so that Nr ≥Nb sets of data at different frequencies could
be available [42,80]. The band partition can be operated both along the range frequency band and the
azimuth frequency band [42].
Hence, the different wrapped phases are given by:
1i(n, m) =
 4π
λ

r1 −ri

+ 1i(n, m)
!
2π,
1i(n, m) = arg

X1(n, m)X∗
i (n, m)

= ⟨1(n, m) −i(n, m)⟩2π,
(20.52)
where i is the random process representing the phase of speckle noise at the ith antenna or in the ith
band.
The choice of the number and kind of wrapped phase data sets, is a crucial points. A proper choice
of the different ﬂight tracks (hence, of the baselines), and/or of the different bands and sub-bands could
allow to obtaining statistically independent wrapped phase data sets, as explained in Ref. [56,83]. In such
case, the likelihood function relative to the single data set 1i(n,m) is given by Eq. (20.26), evaluated
at γ = γ1i and α = α1i:
f1i

ψ1i; h

= 1
2π
1 −|γ1i|2
1 −|γ1i|2 cos2 
ψ1i −α1ih


1 + |γ1i| cos

ψ1i −α1ih

cos−1 
−|γ1i| cos

ψ1i −α1ih


1 −|γ1i|2 cos2 
ψ1i −α1ih
1/2

,
(20.53)
where the dependence on (n,m) has been understood, and, in the case of N statistically independent
wrapped phase data sets, the overall multi-interferogram likelihood function will be given by:
Fm

; h

=
N
-
i=2
f1i (ψ1i; h),
(20.54)
where  = [ψ11(n, m)ψ12(n, m) · · · ψ1N(n, m)]T is the measured wrapped phase data vector. Note
that we have a wrapped phase data vector for each position (n,m) on the ground. The plot of Eq. (20.54)
for a given height value (h = 300 m) for three values of the measured interferometric phases (suppose to
consider four SAR image channels and then three interferograms), and for γ1i = 0.8, i = 1,2,3, is shown
in Figure 20.17. Note that the multiplication of the three single-interferogram likelihood functions,
allows to avoid multiple global maxima present in each single-interferogram likelihood function, at
least in the range of interest for h [83].
The ML estimate can be obtained by ﬁnding the unique value of h that maximize, for each position
(n,m), the multi-interferogram likelihood function:
ˆh(N)
ML = arg max
h
Fm

; h

.
(20.55)
The uniqueness results shown above can, in principle, also be obtained using only two interferograms:
it sufﬁces that the ratio between the period of the two single-interferogram likelihood functions is

1074
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
0
100
200
300
400
500
600
0
0.02
0.04
0.06
0.08
0.1
0.12
0.14
0.16
quota [m]
3 Frequencies Likelihood Function
FIGURE 20.17
Multiple-interferogram likelihood function.
not rational, so that the overall double-frequency likelihood function is not periodic [84]. Hence, in
the multi-interferogram case, the likelihood function will exhibit a single global maximum (the ML
estimate).
In order to correctly implement (20.53) and (20.54), accurate knowledge of the single-interferogram
likelihood functions is very important. While it can be easily obtained in the frequency-diversity case
(frequencies are known with a very high precision), the same is not true for the baseline-diversity case,
where baselines are known only to the precision of the inertial navigation systems, which are usually
not able to achieve the required accuracy of fraction of wavelengths. A second difference is related
to the fact that the different image pairs used to obtain the different wrapped phase values to be used
in (20.53) are acquired in such a way that the independence of the wrapped phase values is seldom
satisﬁed, so that model (20.54) is not valid. In this case, the determination of the multi-interferogram
likelihood function would require joint statistical characterization of the different interferograms.
In Ref. [52], the joint pdf for the general case of correlated interferograms has been derived. The
model given by Eqs. (20.13) and (20.14) can be generalized to the case of k = 1, 2, . . ., K, K ≥2
complex images Zk(n, m).
With reference to the case of K = 3, whose geometry is shown in Figure 20.15, the interferometric
phases, obtained by beating two of the three images given by Eq. (20.13) for k = 1, 2, 3, are:
ψ12 = arg

Z1Z∗
2

,
ψ13 = arg

Z1Z∗
3

,
ψ23 = arg

Z2Z∗
3

.
(20.56)
Generalizing results of Eqs. (20.16) and (20.17), the interferometric phases can be related to the observed
scene height proﬁle through:
ψik =
4π
λ

r j −rk

+  jk

2π
,
i, k = 1, 2, 3,
(20.57)

2.20.4 Multibaseline SAR Interferometry
1075
(a)
(b)
−π
0
π
π 
0 
−π 
0.05
0.1
0.15
−π
0
π
π  
0 
−π 
0.05
0.1
0.15
ω13
ω13
ω12
ω12
FIGURE 20.18
Second order pdf of dual baseline phase interferograms with B12 = 307 m, B13 = 637 m, and γ0 = 0.8:
(a) statistically dependent interferograms; (b) statistically independent interferograms.
where, also in this case,
Xk = Ake jk,
k = 1, 2, 3,
ik = arg

Xi X∗
k

= ⟨i −k⟩2π
.
(20.58)
Note that the three interferometric phases in Eqs. 20.56 and 20.57 are not independent each other, as
each of them is univocally determined when the other two are known (f.i. 23 = ⟨13−12⟩2π). Hence,
it sufﬁces to consider only two of them. It is usually convenient considering the two interferograms
obtained by referring the phase to the same master antenna, f.i. the antenna 1, then getting 12 and 13.
Also in this more general multi-channel case, generalizing results relevant to two channels [52], it
is possible to derive a closed form for the pdf f12,13(ω12, ω13) of the interferometric speckle phase
differences 12 = (1 −2) and 13 = (1 −3) [52]. Such pdf is completely symmetric respect
to the interferometric phase values ω12 = ω1 −ω2, ω13 = ω1 −ω3, and ω23 = ω13 −ω12 = ω2 −ω3,
as shown in Ref. [52].
The 2D representation of pdf f12,13 is shown in Figure 20.18a, obtained with the values B12 =
307 m and B13 = 637 m (B23 = B13 −B23 = 330 m), where the images coherence values have been
computed according to the ﬁrst order spatial decorrelation model introduced in Eq. (20.29), assuming
γ0 = 0.8, and consequently γ12 = 0.57, γ13 = 0.33, and γ23 = 0.55. We can notice the typical
behavior met for a couple of correlated random variables. The joint pdfthat would be obtained with
independent interferograms, for the same parameters values used for the pdf of Figure 20.18a, is shown
for comparison in Figure 20.18b.
The 2D representation of the joint pdf f12,13 for different baseline values (B12 = 111 m, B13 =
937 m, and B23 = B13−B23 = 826 m), for γ0 = 0.8, and for the corresponding coherence values γ12 =
0.72, γ13 = 0.11, and γ23 = 0.19, is reported in Figure 20.19a. The joint pdf that would be obtained
with independent interferograms, for the same parameters values used for the pdf of Figure 20.19a,
is shown for comparison in Figure 20.19b. Note that the difference between pdfs of Figure 20.19a
and b is less pronounced that the one between pdfs of Figure 20.18a and b, since in this case the

1076
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
(a)
(b)
−π
0
π
π 
0 
−π 
−π
0
π
π  
0 
−π 
ω13
ω13
ω12
ω12
0.02
0.04
0.06
0.08
0.1
0.12
0.02
0.04
0.06
0.08
0.1
0.12
FIGURE 20.19
Second order pdf of dual baseline phase interferograms with B12 = 111 m, B13 = 937 m, and γ0 = 0.8:
(a) statistically dependent interferograms; (b) statistically independent interferograms.
statistical independence assumption is approximately met, because two of the three coherence values are
very low.
Also in this case the interferometric phases pdf can be obtained through a change of variables,
generalizing what described for one variable in Eq. (20.26):
f12,13(ψ12, ψ13; h) = f12,13(ψ12 −α12h, ψ13 −α13h).
(20.59)
The differences evidenced in Figures 20.18 and 20.19 for the speckle phases, with and without correla-
tion, result also in the case of the interferometric phases 12 and 13. In some conditions, the differences
between the two cases pdfs can be more pronounced, in other less. Of course, in case of signiﬁcantly
correlated interferograms, the height estimation according (20.55) by using the joint pdf of independent
interferograms (Eq. (20.54) in place of (20.59)) would lead to larger estimation errors both in terms
of quadratic errors and bias, especially when the two joint pdfs assumes very different shapes [85].
Equation (20.59), which can be easily generalized to the case of more than two interferograms [52], is
very general, and reduce to (20.54) in the case of independent (and hence, uncorrelated) interferograms.
Use of pdf (20.59) in place of (20.54) allows to obtain better results in terms of accuracy (Bias and
Cramer-Rao Lower Bounds) of the reconstructed ground height proﬁles [52,85].
2.20.4.1 Bayesian statistical solution to PhU problem
To solve the problem of the estimation of the ground elevation proﬁle also Bayesian statistical techniques
have been proposed [86–88]. In the framework of such techniques, in particular if a Maximum a
Posteriori (MAP) estimation scheme is adopted, an a-priori joint pdf of the unknown height proﬁle has
to be introduced. It is based on the use of Markov Random Fields (MRF) as a-priori statistical term
modeling pixels contextual statistical information in the 2D unknown height proﬁle to be reconstructed.
The MRF allows to describe the local spatial interaction between couples of pixels, through a set of
model parameters (hyperparameters) which can be tuned following unsupervised procedures.

2.20.4 Multibaseline SAR Interferometry
1077
Consider a discrete (lexicographically ordered) two-dimensional (2D) points lattice L = {k, k =
1, . . . ., Np}, where Np is the number of pixels of the SAR image, and let h = [h1 h2 . . . hNp]T the
corresponding ground elevation values. Consider now an InSAR system, and let ψkn the wrapped phase
values (single sample of a discrete interferogram) measured at the lattice point k and at nth interferogram.
The wrapped phase values ψkn relative to the position k can be structured and ordered in the following
way: let ψk = [ψk1 ψk2 . . . ψkN]T be the vector of the wrapped phases measured in k position at the N
different interferograms, and ψ = [ψT
1 ψT
2 . . . ψT
Np]T be the vector collecting all available wrapped
phase values. Then, h is the vector of the unknown height values, and ψ the vector of the all available
data (multi-interferogram).
The MAP estimation can be formulated as:
ˆhMAP = arg max
h
fPost

h |ψ

= arg max
h
ln fψ

ψ |h

gH

h; σ

,
(20.60)
where fPost(h|ψ) is the a posteriori joint pdf of the unknown image, fψ(ψ|h) is the Bayesian likelihood
function [89], and gH(h, ψ) is the a-priori pdf of the unknown image.
The Bayesian likelihood function can be easily obtained by Eq. (20.59):
fψ

ψ|h

=
Np
-
k=1
fψk(ψk|h),
(20.61)
where the statistical independence of the interferograms in the different ground positions k = 1, . . . , Np
has been exploited. The Bayesian likelihood functions are formally equal to the likelihood function that
can be obtained in the classical statistical case; in the Bayesian framework, differently from the classical
one, the unknown image is seen as a sample of a random vector H.
The a-priori pdf gH(·) is usually deﬁned in such a way to express a-priori information about the
unknownimage,assigninghighprobabilitytoparticularpixelsconﬁgurations.IntheSARinterferometry
case, being the unknown image representative of the ground elevation map of a geographic area, a strong
contextual pixel information is very likely to be. In particular, it can be assumed that the unknown
image can be modeled as a Markov Random Field (MRF) [90], a general image model able to represent
contextual pixel information extending the 1-D Markov property to the 2-D case, whose corresponding
joint pdf is given by a Gibbs distribution:
gH

h; σ

=
1
Z

σ
 exp

−E

h, σ

=
1
Z

σ
 exp
⎡
⎣−
Np

k=1

j∈Nk
U

hk, h j, σkj

⎤
⎦,
(20.62)
where Z(σ) =
.
exp{−E(h; σ)}dh is the so-called partition function (a constant factor needed to
normalize the integral of the pdf to one), E(·) is the energy function, U(·) is the potential function
between hk and h j, Nk is the neighbourhood system of kth pixel [91] (usually, the eight pixels around
the kth one), σ is the hyperparameter vector, and σkj are the hyperparameters. With such deﬁnition,
the Gibbs-MRF model in Eq. (20.62), by means of the hyperparameters, well adapts to describe the
image local nature, leading to a powerful and general model, well-suited to represent a very wide class
of height proﬁles. The hyperparameter values are not know, of course, and they have to be estimated
from the available interferometric data ψ data.

1078
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
The solution procedure essentially consists of two steps: ML estimation (σ) of the hyperparameter
vector σ and MAP estimation (ˆhMAP) of the actual realization of height proﬁle process H.
This approach can work very well [87], even if the method is always limited by the coherence value
and by the corresponding number of available independent acquisitions of the same scene. The lower
are the coherence values over the entire image, the larger is the total number N of needed interferograms
to obtain good quality reconstructions.
Performance of the Bayesian method can signiﬁcantly outperform the one relevant to classic
approaches [85,92] depending on the capability to estimate the a-priori model of the unknowns.
2.20.4.2 Graph cuts solution to PhU problem
Statistical approaches, especially the Bayesian ones, have proved to be effective dealing with noisy data
and big discontinuities. However these algorithms can be time consuming and computationally heavy
due to the a-priori model (estimation of hyperparamenters) and to the optimization step. It is possible
to overcome these limits by introducing a fast and efﬁcient (in term of global optimization) algorithm
to unwrap the interferometric phase in the multichannel conﬁguration [85].
To reduce the computational time needed to unwrap the multichannel interferometric phase, two
aspects can be taken in consideration: ﬁrst, a non-local a-priori energy function, the Total Variation
(TV) model [93], and secondly an optimization algorithm based on graph cuts, Ishikawa algorithm [94],
have been exploited.
The a-priori energy corresponding to the TV model can be written as follows:
E

h, σ

= σ
Np

K=1

j∈Nk
hk −h j
.
(20.63)
Note that in this expression, σ is a scalar, making model in Eq. (20.63) a non local one, differently from
the Bayesian model (20.62) presented in the previous section. This choice is done in order to make the
algorithm faster. A non local a-priori model avoids the estimation of local hyperparameters σkj, as only
one parameter σ for the whole image has to be estimated.
Between the existing non local a-priori energy models, TV has been chosen, due to its main advan-
tage: TV does not penalize discontinuities in the image while simultaneously not penalizing smooth
functions either [93].
Given the TV a-priori energy model (20.63), the MAP estimation can be obtained from the mini-
mization of the following function:
ˆhMAP = arg max
h
fPost

h|ψ

= arg min
h
⎛
⎝−ln fψ(ψ|h) + σ
Np

K=1

j∈Nk
hk −h j

⎞
⎠.
(20.64)
In order to minimize this energy function, graph-cut based optimization algorithms are used. Graph-
cut optimization [95,96] is successful because the exact minimum or an approximate minimum with
certain guaranties of quality can be found. Compared to the classical optimization algorithm, it provides
comparable results with much less computational time and compared to the deterministic algorithm ICM
[90], it avoids the risk of being trapped in local minima solution which can be far from the global one.

2.20.4 Multibaseline SAR Interferometry
1079
FIGURE 20.20
(a)
Example
of
a
graph
construction
and
of
a
cut
on
it
(dashed
line);
(b)
Ishikawa
Graph
Construction—On the axes there are the pixels and the labels; data edges are depicted as black arrows;
constraint edges are represented by horizontal arrows and penalty edges are depicted as dotted arrows;
(c) Ishikawa edges weights—Representation of the edges for a vertex.
Let us, ﬁrst, deﬁne a graph and a graph-cut problem. Suppose G = (V, E) is a directed graph with non
negative edge weights, where V is the set of vertexes and E the set of edges. This graph has two special
vertexes (terminals) called the source s and the sink t. A s-t-cut C = {S,T} is deﬁned as a partition of the
vertexes into two disjoint sets S and T such that s ∈S and t ∈T. A cost of this cut is deﬁned as the sum
of weights of all edges that go from S to T. Figure 20.20a shows a simple graph made of four vertexes,
two vertexes (x,y) plus the sink and the source (t,s). The edges are the links between the vertexes. An
example of a cut is represented with the dashed line.
The minimum s-t-cut problem is to ﬁnd a cut C with the smallest cost. This problem is exactly
equivalent to its dual problem, which consists in computing the maximum ﬂow from the source to the
sink. Between the several algorithms proposed to solve the maximum ﬂow problem, the one proposed
in [97] turns to be the most adapted to computer vision problems.
To solve the MAP unwrapping problem, which means ﬁnd the value of h that minimizes (20.64) the
optimization procedure proposed by Ishikawa is implemented [94]. The interesting aspect of Ishikawa
algorithm is that under some hypothesis on the energy to be minimized and if the graph is correctly
constructed, the algorithm provides the global optimum of the considered energy.
Two hypothesis are at the base of Ishikawa algorithm: convexity of the a-priori energy and a linear
order on the label set. Using the TV model the ﬁrst hypothesis is satisﬁed. For the second hypothesis,
in the case of phase unwrapping, the labels are the height of the image pixels. The heights are supposed
to be represented as integers in the range {0,1,2,..,L−1}, where L is the size of the label sets. This
condition satisﬁes the second hypothesis necessary for the Ishikawa graph construction.
Ishikawa method is based on computing a minimum cut in a particular graph. Ishikawa graph
G = (V,E) contains Np × L nodes (Np is the size of the image and L is the size of the label set)
denoted by {vk,l}, plus two special nodes s and t. For each pixel k, we associate L nodes, that represent
all the possible heights that the pixel k can take. The construction of Ishikawa graph, in case of a 1D
image for legibility, is shown in Figure 20.20b.
Ishikawa graph contains three families of edges E = ED ∪EC ∪EI. ED is a set of directed edges
called data edges (black arrows of Figure 20.20b). It represents the data energy term. EC is a set of

1080
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
directed edges called penalty edges (dotted arrows of Figure 20.20b). It ensures that only one data edge
is in the minimum cut for each pixel k. Finally, EI is a set of constraint edges between all neighbor
pixels (horizontal arrows in Figure 20.20b). It represents the a-priori energy term.
To better understand how to set the edges weight for the multichannel phase unwrapping problem let
us consider Figure 20.20c. The vertex vk,l is the vertex identiﬁed by the pixel k and the label l. The cost
of the edges in Ishikawa graph are reported in Eq. (20.66). For more details on the graph construction
see [94].
c

vk,l, vk,l+1

= −ln fψ

ψk|hk = l

,
c

s, vk,0

= ∞,
c

vk,L, t

= −ln fψ

ψk|hk = L −1

,
(20.65)
c

vk,l+1, vk,l

= ∞,
c

vk−1,l, vk,l

= 1.
Constructing the Ishikawa graph as shown and ﬁnding the cut with a minimum cost on this particular
graph allows to ﬁnd the exact (global) optimum solution for the multichannel phase unwrapping problem
given by Eq. (20.64). The main disadvantage of Ishikawa method is related to the memory load. In fact,
the algorithm stores the whole graph and then performs the cut. This can be a problem when the size of
the images largely increase.
Before using Ishikawa algorithm, the hyperparameter σ has to estimated. The hyperparameter σ
depends both on data energy and on a-priori energy term. A method to perform the hyperparameter
parameter is the analysis of the so called L-curve. To ﬁnd automatically the corner of the L-curve, the
triangular method described in [98] can be used, providing good results in limited time.
2.20.5 Multipass interferometry
Advanced differential SAR interferometric (A-DInSAR) techniques process multitemporal data,
acquired over repeat passes, to generate very accurate deformation time series and therefore to achieve
a regular monitoring of the deformation of the observed scene. A-DInSAR techniques also mitigate
most of the limitations of the standard single-interferogram approaches, such as temporal and geomet-
ric decorrelation and the atmospheric phase delay and, unlike conventional Interferometry, they allow
increasing the measurement accuracy from centimeter up to millimeter. These techniques also improve
standard approaches both in terms of deformation modeling capabilities and quality measurements.
We refer to the geometry depicted in Figure 20.21, where we assume that the satellite is collecting
the data at time instants t1, t2, . . . , tN, with baselines b1, b2, . . . , bN, with respect to a reference image.
Let ϕ be the vector that collect the phase measurements, ϕ1, ϕ2, . . . , ϕN. The following data model
is assumed:
ϕ = 4π
λ

ξs + d

+ ϕa + ϕo + ϕn,
(20.66)
where ξ is a vector of a-dimensional parameters that collect the angular variations corresponding to
the baseline distribution ξi = bi/r, d is the vector collecting the displacements at the different times,

2.20.5 Multipass Interferometry
1081
FIGURE 20.21
Multipass interferometric geometry.
ϕa, ϕo, and ϕn are respectively the unwanted vectors collecting the APD, also known as Atmospheric
Phase Screen (APS) [74], the orbit errors and the noise, which, in this case, includes also the temporal
decorrelation effects in addition to the spatial decorrelation contribution due to the speckle. Note that
the elevations can be related to the target height z as s = h/sin (ϑ).
The ﬁnal aim of multipass DinSAR techniques is to reconstruct d, and especially for some speciﬁc
applications to estimate s to correctly localize the target to which the displacements refer. In doing
this the cancellation of the unwanted disturbance terms is carried out by using a proper modeling, of
deterministic nature (such as for instance the baseline dependent term related to the target elevation
and the orbit error which show a predictable spatial variability) and stochastic models, such as for the
characterization and ﬁltering of the atmospheric component.
Some remarks are now in order. First of all the phase of each single SAR image depends on the phase
of the backscattering coefﬁcient that, for distributed scatterers, can be strongly variable from pixel to
pixel. Therefore interferograms must be formed in such a way to mitigate, as much as possible the effects
of the backscattering coefﬁcient. Secondly, the interferograms are extracted by complex numbers and
therefore the phase values are wrapped, i.e., they are determined only on a basic interval of 2π size.
With regards to the process of determining the set of interferogram to be used for the displacement
estimation process, there are essentially two alternative options: the (temporal) Persistent Scatterers
Interferometry (PSI) and the (spatial) Coherent Scatterers Interferometry (CSI) approaches. Almost all
implementations of these class of approaches makes use of the model in Eq. (20.66).
The main difference between the two approaches is the basic assumption underlying the typology of
the scattering which impacts the strategy followed in the interferogram generation and in the scale of
analysis.
In the PSI case the interferometric analysis is carried out at the highest possible spatial resolution,
the set of interferograms is generated with respect to the master image without taking any care to
avoid large spatial and temporal baselines. This strategy is chosen in PSI because the technique is
aimed at monitoring the deformation of dominant scatterers, i.e., of scatterers showing a persistency
of the scattering mechanism over the time. Many natural reﬂectors, typically present over man-made

1082
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
structures, satisfy this requirement. In the PSI approach the use of large spatial baselines are functional
to the achievement of a high accuracy in the estimation of the target elevation which provides a high
accuracy in the localization of ground scatterers and therefore in the identiﬁcation of the scatterers
subject to possible deformations.
Most of PSI algorithms rely on the use of simpliﬁed version of the model in (20.66) in which the
deformation is assumed to be linear i.e., d = dL = vt,where v is the deformation mean velocity and t
is the vector collecting the time instants.
In this case the phase vector ϕ is expressed as:
ϕ = 4π
λ

ξs + vt

+ ϕn.
(20.67)
From Eqs. (20.66) and (20.67) it is evident that, besides the linear deformation approximation, other
two assumptions are fundamental: that is the possibility to neglect the atmospheric contribution and
the orbital inaccuracy. While the latter assumption does not play a critical role because the orbital
errors are rather accurately modeled as spatial (azimuth-range) planar phase contributions that can be
accurately estimated and compensated directly on the measured complex data in wide areas, neglecting
the atmospheric phase pattern is a main issue. One possibility to handle the atmospheric contribution
is by exploiting its the spatial correlation properties, speciﬁcally the fact that contributions on a scale
of a few hundreds of meters are strongly correlated as explained in Section 2.20.3.3. Accordingly, this
contribution can be estimated on a coarse grid and subtracted from the data. In the case of the original
Persistent Scatterers algorithm of [99,100], the grid of pixels used for the estimation of the atmospheric
phase pattern is selected by measuring the amplitude dispersion index, which is a proxy of the phase
stability.
Following this compensation each pixel is investigated for the presence of scatterers with “persistent”
properties, i.e., a parameter that describes the ﬁt between the model and the real phase is considered:
C

s, v

= 1
N


i=1,...,N
e jϕi−j 4π
λ

ξis+tiv


n
.
(20.68)
Equation (20.68) provides a normalized (in the [0,1] interval) measure, of the temporal (i.e., persistent)
coherence property of scatterers: s (scatterer elevation) and v (velocity) are unknowns that are determined
via a maximization

ˆs, ˆv

= arg max C

s, v

.
(20.69)
It is interesting to note that by letting:
yϕ =

e jϕ1
e jϕ2
· · ·
e jϕN 
,
(20.70)
where ϕ j is the jth component of ϕ.
Now, introducing:
a

s, v

=
3
e j 4π
λ

ξ1s+t1v

e j 4π
λ

ξ2s+t2v

· · ·
e j 4π
λ

ξN s+tN v
 4
,
(20.71)
where ξ j is the jth component of ξ, and t j is the jth component of t.

2.20.5 Multipass Interferometry
1083
Then Eq. (20.68) can be rewritten as:
C = 1
N
yH
ϕ a

s, v
 = 1
N
aH 
s, v

yϕyH
ϕ a

s, v

−1/2
.
(20.72)
This equation highlights the fact that the PS approach uses indeed with unitary weighting all the inter-
ferograms yϕyH
ϕ , and therefore the whole information available in the data is used in the determination
of the target height and velocity.
Since the proposal of the PS technology, many other PSI techniques have been proposed: SPN
[101], PSI-GENESIS [102], IPTA [103], SPINUA [104]. In most of the cases they differ essentially in
the selection of the sparse grid over which the interferometric analysis is carried put. A solution that
extensively use the model in (20.67) is the Persistent Scatterers Pairs (PSP) algorithm [105]. In this
case the mitigation of the atmospheric contribution is carried out by considering the phase variation
over spatial arcs: the atmospheric contribution as well as non-linear effects spatially slowly variable
are automatically canceled provided that the length of the arc is sufﬁciently small. In the PSP case, the
selection of the sparse grid of analysis is carried out by moving from a reference starting point to the
adjacent points using the spatial arcs and the model in (20.67).
The capability of SAR to monitor deformation phenomenon up to centimeters by compensating
topography and atmospheric disturbances via processing of stacks of data was for the ﬁrst time provided
by the group of Politecnico of Milan with the persistent scattereres technique. The examples included
in the seminal papers [99,100] that demonstrated for the very ﬁrst time the possibility to monitor
demonstration with millimeter per year accuracy of to the Pomona (CA-USA). Among the ﬁrst examples
of application of the Persistent Scatterers is the monitoring of the Etna volcano (see Figure 20.22).
Currently Multipass DInSAR techniques, such as small baseline and persistent scatterers are applied
to monitor deformation phenomena associated in seismogenetic areas [106], landslides [107], areas
affected by underground excavation or water level changes [108] gas pumping and storage, etc. over
wide areas.
An example of application of PSI on a national scale is provided in Figure 20.23.
Multipass DinSAR techniques allows also image and monitor ground scatterers with high spatial
resolution. Persistent Scatterers Interferometry (PSI) techniques exploits all the available acquisitions
in such a way to improve the performances with respect to this speciﬁc case.
PSI approach are designed to monitor deformation of dominant scatterers. PSI may however loose
the capability of monitoring scatterers which shows non negligible temporal or spatial decorrelation:
such scatterers are corresponding to areas in which the scattering is not concentrated in a dominant
point but rather is distributed over the resolution cell.
Techniques complementary to PSI that uses only interferograms showing a sufﬁcient high degree
of spatial coherence [109–111], in this work referred to as coherent stacking interferometric (CSI)
techniques, aims to overcome the problems of PSI related to distributed scattering.
In fact, following the lines of the classical (single-pair) DInSAR analysis, CSI techniques carry
out an analysis of multilook interferograms: the multilook operation, i.e., a spatial averaging which is
carried out by exploiting the hypothesis that the scattering is distributed, allows on one side accessing a
measure of quality of the signal in each interferogram, i.e., the spatial coherence, and on the other side
it allows increasing the signal phase quality though the averaging operation.

1084
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
FIGURE 20.22
The persistent scattereres technique applied to the monitoring of the Etna volcano in the period 1995–1999,
colorbar is saturated in the range (−30,30) mm/yr.
Tele-Rilevamento Europa (T.R.E. s.r.l.) and Politecnico of Milano.
The ﬁrst interferometric stacking technique proposed in the literature has been the Small BAseline
Subset (SBAS) technique [109]. This technique makes use of a limitation on the spatial and temporal
baselines to control the temporal and geometric (also known as angular) decorrelation phenomena which
is more critical in the presence of distributed scattering.
As described in Section 2.20.3.2 geometrical decorrelation is a phenomenon which is associated with
the fact that even small variations of the radar line of sight direction in the elevation direction induced by
the orbital separation (spatial baseline decorrelation) and/or aspect angle (induced by doppler centroid
vatiation); temporal decorrelation is due to changes over the time of the scattering. The SBAS technique
uses only interferograms generated by choosing thresholds on the spatial and temporal baselines, that
is the spatial orbital and temporal separations, respectively, and on the Doppler centroid difference
(for systems suffering of large variation of the Doppler centroid) thus limiting the effects of angular
and temporal decorrelation. Mathematically, letting  ¯ϕ =
 ¯ϕ1,  ¯ϕ2,
· · ·
 ¯ϕM

the vector that
collects the M (multilook) interferograms values in a generic pixel, we have:
 ¯ϕ = A ¯ϕ,
(20.73)

2.20.5 Multipass Interferometry
1085
FIGURE 20.23
Result of the PST project funded by the Italian Ministery of the Environment for monitoring the displacements
in Italy via the Persistent Scatterers Interferometry technique. Data of the ESA ERS-1 and ERS-2 satellites.
TREuropa.
where ¯ϕ is the multilook version of ϕ and A is a M ×N matrix (M > N) incidence matrix that describes
the structure of the interferogram stack used in the processing: it is dependent on the pairing of the
acquisitions in the interferogram generation. Equation (20.73) refers to the absolute phase values: hence
the set of interferogram is unwrapped, (commonly via the Minimum Cost Flow algorithm [58–60,79])
and then (20.73) is inverted pixel by pixel to retrieve the phase signal over the stack of acquisitions.
The SBAS approach, by using the Singular Value Decomposition [112] technique allows also han-
dling the case in which, due to the limitations on the baselines, the acquisitions are grouped in different
independent subsets leading to the case of ill-conditioning of the matrix A in (20.73). This latter fea-
ture allows also performing a “semi-coherent” combination of data of different sensors (f.i. ERS and
ENVISAT), i.e., the combination of sets of coherent data for which are incoherent each other.
It is worth pointing out that the system in (20.73) is intrinsically invertible for each pixel up to a
constant: typically this constant is set in such a way to have a null deformation at time t1. Moreover, as
eachinterferogramisknownuptoaconstantphasevalue,thesolutionof(20.73)forallpixelsisknownup

1086
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
to the deformation of a known point which must be set, as in classical leveling technology, as a reference
point. After the inversion the deformation time series are separated from atmospheric contribution by
using (20.66): in particular the deformation mean velocity and the residual topography are estimated
by assuming for ¯ϕ the model in (20.67). The linear motion and topography errors are subtracted from
the data and the residuals are then ﬁltered to separate the non-linear deformation component from the
APD contribution: this separation relies on the assumption that the deformations are typically correlated
spatially and temporally (slow deformations) whereas the atmosphere is spatially correlated but almost
independent from epoch to epoch. The latter assumption is certainly valid for the turbulent component
of the APD whereas it may be critical in case of dense temporal sampling (i.e., low revisiting time) for
the stratiﬁed contribution (depending on the topography) which exhibit seasonal dependencies.
Differently from the SBAS approach where typically a degree of redundancy is imposed at the
interferogram generation level to control the presence of possible unwrapping errors, the CPT technique
usesaMinimumSpanningThree[113]strategytoconnecttheacquisitionstack,andthereforetogenerate
the interferograms. Another special feature of the CPT approach is related to the implementation of a step
which allows, via modeling, to retrieve the linear deformation component and DEM error contribution
prior to extraction of the non-linear component. In this sense the technique is very similar to the ESD
approach proposed in [114].
The A-DinSAR techniques working at lower resolution, such as SBAS and CPT, allows to easily
implement a two-stage, low-resolution and high-resolution, interferometric processing strategy for the
evaluation of the deformation over at small and a high scale, respectively.
In other words, once the atmospheric phase component and the non-linear deformation are extracted,
they are subtracted from the original data corresponding to each acquisition at full resolution. Such data
can be used in conjunction with the model in (20.67) to perform, as in standard PSI, the estimation of
the deformation at full resolution. It is worth noting that, due to the fact that the increase of resolution is
aimed at analyzing dominant scatterers, it is not convenient at this stage the introductions of limitation on
the baselines. Moreover, whereas common band ﬁltering may be beneﬁcial to counteract the geometrical
decorrelation effect in case of distributed scattering, for the full resolution analysis tuned to dominant
scattering such ﬁltering can be deleterious because in this case it cannot be assumed that spectral
components of the scattering mechanism are still independent.
A possibility that provides improved performances in the full resolution analysis is given by the
use of imaging techniques. Based on a tomographic processing, multidimensional SAR imaging use
both the amplitude and phase values of the received signal to perform a full resolution analysis that
allows increasing the detection performances of persistent scatterers, as well as the estimation of their
associated parameters, i.e., the velocity and the elevation. Furthermore, by analyzing the scattering
distribution in the elevation/velocity plane, they allows identifying and separating the contributions of
scatterers which are interfering in the same pixel. The interference of scatterers is particularly critical
in the case of complex scenarios such as urban areas, in which the phenomenon of layover affect all
the vertical structures. These topics are the subject of the SAR Tomography and Differential SAR
Tomography techniques which are discussed in details later on.
Figure 20.24 provides an example of application of the SBAS based approach to the monitoring
of wide areas [115]. Many deformation phenomena corresponding to natural hazard are evident (the
Campi Flegrei caldera subsidence in Naples, the Colli Albani uplift in the south of Rome, etc.). Besides
providing the measurement of deformation associated with progressive and regular hazard sources, such
as subsidence due to water pumping, regular volcanic activities, etc., the multipass SAR technique is

2.20.5 Multipass Interferometry
1087
FIGURE 20.24
Example of a wide area monitoring using by combining the results of 3 ERS-Envisat frames from Naples to
Rome.
also particularly important in the post crisis phase. The recent literature includes many examples of
application of the multipass DInSAR technique to the monitoring of post-seismic deformation. One
of the most effective example of monitoring of post-seismic deformation is provided by the CSK
constellation with reference to the l’Aquila earthquake. Starting from April 6th, 2009 date the CSK
constellation (at that time operative with three satellites) was capable in six months to acquire different
dataset with a rate that, for the best dataset, was the highest possible, i.e., about 1 acquisition each 5 days
on average.

1088
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
Figure 20.25 shows the image corresponding to the mean post-seismic velocity: the red spot shows
the deformation in correspondence of the Paganica San Demetrio fault. The time series also shows very
clearly the typical exponentially decreasing post-seismic deformations.
Particularly relevant are the effects of uplift which are observed on the mountainous areas in the North
and South area. Such effects are an evidence of the effects of the non-turbulent (stratiﬁed) component
of the troposphere corresponding to the hydrostatic path delay, and show a seasonally variability. It is
worth to note that the reduction of the wavelength with respect to C-Band data X-Band systems such
as COSMO/SKYMED and TerraSAR-X, on one side provides a higher sensitivity to deformation, on
the other side it introduces an ampliﬁcation of the range variation component associated with ADP.
The tropospheric component under investigation cannot be ﬁltered via a simple approach based on
the temporal independence of APD, as done in the classical multitemporal interferometric processing
scheme described above. Such effects, whose compensation is of main importance for the application
in emergencies situations (in which typically a few acquisitions are available), can be handled either
by using external tropospheric delay measurements, provided for instance by GPS networks, of by
subtracting from the interferograms the components highly correlated to the topography: the latter
solution may be critical in cases in which the deformation signal is itself correlated with the topography
(for instance, volcanoes inﬂation).
A ﬁnal example of application of multitemporal DInSAR analysis is provided by the use of PSI on
data acquired by the last generation, high resolution satellites. In Figure 20.26 it is shown the result of PSI
applied to four ascending and descending tracks acquired by the TerraSAR-X system operating in the
spotlight mode over the Berlin station. The ﬁgure provides the measurement of deformation caused by
thermal dilations. At certain positions along the rail track, there is a 180◦phase change. At these locations
rail expansion joints are installed and the rail tracks dilate horizontally and in opposite directions.
2.20.5.1 Multipass phase unwrapping
As already stated in Section 2.20.4, Phase Unwrapping is necessary to extract the APD component and
to estimate the non-linear deformation signal at either small or large scale: PhU is by far the most critical
step of any A-DInSAR technique.
Most of PhU algorithms have been developed in the context of SAR Interferometry, and make use
of the pixel-to-pixels spatial variations. One of the most used algorithm is the Minimum Cost Flow
(MCF) PhU [60,79]: it is based on the use of triangulations deﬁned on the sparse grid of useful pixels
and the PhU is cast as the problem to minimize the L1 norm of a vector that corrects the measured phase
differences subject to the zero-curl (i.e., non rotational) constraint, that is the constraint that forces to
zero the circulation of the unwrapped phase differences on all the triangles. Very efﬁcient MCF solvers
are available in the framework of network-ﬂow algorithms [60].
The MCF technique, typically exploited for the unwrapping of single interferograms, has been also
extensively used in the multitemporal DInSAR context where commonly several interferograms must be
unwrapped. More speciﬁcally, phase unwrapping of DInSAR data stacks is carried out by independently
unwrapping each interferogram with the MCF optimization approach (single-step PhU).
The single-step PhU discards any relationship between the different interferograms, which are indeed
all related to the same wanted signals; particularly it neglects the typical inherent redundant nature of
the interferogram stack.

2.20.5 Multipass Interferometry
1089
FIGURE 20.25
Post-seismic deformation monitoring over the l’Aquila area. Upper image: post-seismic mean deformation
velocity. Lower image: comparison between GPS (black stars) and SAR measurements (red diamonds) [116].
(For interpretation of the references to color in this ﬁgure legend, the reader is referred to the web version
of this book.)

1090
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
FIGURE 20.26
Geocoded persistent scatterers obtained from a fusion of 4 different stacks (ascending & descending) of
TerraSAR-X high resolution spotlight data [117]. Colors represent estimated amplitudes of seasonal defor-
mation in west-eastern direction in the interval [+7, −7] mm.
DLR and Technical University of Munich (TUM), Germany.
To overcome this limitation, the single-step PhU has been recently integrated with Model Based
(MB) phase unwrapping algorithm that exploits the model in (20.67) also at the phase unwrapping stage.
More speciﬁcally, starting from the measured interferograms, the MB PhU estimates the variations of
the topography (ˆs) and deformation mean velocity (ˆv) over the set of spatial arcs deﬁned on a grid
of reliable pixels, i.e., with a coherence degree [118] which is above a threshold for a ﬁxed percentage
of the total number of interferograms:

ˆs j, ˆv j

= arg max
s j,v j
1
N


i=1,...,NaS
e jψi−j 4π
λ

ξis j+tiv j


,
(20.74)
where ψi is the variation of the wrapped phase measured on the jth (out of NaS) spatial arc.
The set of all measured topography and deformation mean velocity deformation mean velocity, ˆs j
and ˆv j, are then spatially integrated (generally in a Least-Square sense) over the network associated
with the spatial arcs to retrieve the topography and deformation mean velocity at the pixel level. The
phase signal corresponding to the signal component model is subtracted from each interferogram to
ease the subsequent un-modeled unwrapping step, generally carried out with the application of the MCF
algorithm applied independently to the each of the available interferograms [115,119].

2.20.5 Multipass Interferometry
1091
FIGURE 20.27
Example of triangulation in the acquisition (spatial and temporal baseline) domain.
Recently new algorithms has been proposed to improve the un-modeled PhU stage by exploiting the
redundant nature of the interferograms [120–122].
A ﬁrst contribution along this line is the two step PhU algorithm [122], where the use of a triangu-
lation is in the spatial temporal baseline domain, see Figure 20.27, is used: each point represents an
acquisition and arcs represents the interferograms. For each spatial arc, the interferometric measure-
ments available in all the interferograms provide an estimate of the phase variations over the acquisition
arcs in Figure 20.27. It is clear therefore that such phase variations must sum up to zero over closed
circuits and therefore an MCF step can be therefore carried out in the acquisition domain to provide
corrections of the phase variation over the selected spatial arc in each interferograms which are used
for the subsequent MCF PhU implemented, as usual, in the spatial domain.
This two-step approach has the advantage to use the redundancy of the available interferograms,
phase summation of interferograms over close loop should be zero, but imply a rigid scheme in the
interferogram generation. The use of a triangulation does not allow ﬁxing a limit to the baseline separa-
tion,asusuallydoneintheSBASapproach,becausethemaximumbaselineisdeﬁnedbythetriangulation
scheme.
A solution to tackle problem is obtained by address the PhU problem in a generalized framework
which makes use of the over-determined nature of the operator that relates the phase differences to the
absolute phase values, [119]. More speciﬁcally, by referring to Figure 20.28 where a 3D representation of
the stack of acquisition is shown, we let l and n indicating the pixel and the acquisition, respectively, and j

1092
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
FIGURE 20.28
3D structure of the data corresponding to a multi-temporal multi-baseline acquisition data set: any horizontal
layer corresponds to the spatial grid of a single acquisition. Vertical arcs are interferometric phase values in
a pixel whereas horizontal arcs are spatial variations of interferometric phase.
the spatial arc. It is possible to deﬁne two operators implementing a differentiation along the acquisition
(i.e., the interferogram generation) and along the space (spatial variation). A generic estimation of the
absolute phase variation over the mth interferogram obtained by wrapping the difference of the inter-
ferogram phase values at the end point of a spatial arc can be seen as a result of a double differentiation
(along the acquisitions and along the space) of the phase values:
um

j
 ∼= ϕn2(l2) −ϕn1(l2) −ϕn2(l1) + ϕn1(l1),
(20.75)
where n1 and n2 are the indexes of the acquisitions of the mth interferogram on the jth spatial arc, l1 and
l2 are the indexes of the acquisitions of the jth arc. Collecting all the measurements um and unknowns
ϕn for any spatial arc and interferogram in the vectors u and ϕ. Accordingly the following linear system
can be written:
u + 2πk = ASBϕ,
(20.76)
where ASB is the matrix (typically with a number of rows larger than the number of columns due to the
redundant selection of interferograms) that computes the differences at the right hand side of (20.75)
along the acquisitions and space for all the interferograms (acquisition arcs) and spatial arcs; k is the
vector of unknown 2π multiples. From (20.76) it is evident that errors in the measurement of u move
the vector out of the range of the operator ASB, R{ASB}, and therefore the vector k must be selected
as the vector that brings u in R{ASB}. It is natural, as in the minimum cost ﬂow approach to look
for a correction vector k to be with integer values and with a convenient weighted minimum norm. An
effective, and less computational demanding approach, is by exploiting the null-space matrix associated

2.20.6 SAR Tomography
1093
with ASB, i.e., the matrix Z whose rows are the vectors of the null space of ASB, N{ASB}, i.e., such
that ZASB = 0. By applying Z to the (20.76) we determine the a set of equations involving only the
measurement u and the unknown vector k of 2π multiples. It is worth noting that in case triangulations
are carried out in both the space and baseline domain Z is the matrix that evaluates the circulations over
the elementary triangles. In conclusion, the vector k is determined by solving the following optimization
problem:
⎧
⎪⎪⎨
⎪⎪⎩
ˆk = arg min
k
J

k

,
J

k

= ∥k∥L p ,
subject to Z

u + 2πk

= 0
(20.77)
where Z is the Left Null Space matrix associated with ASB.
The null-space approach is characterized by the desirable feature of being an approach in which the
degree and the typology of redundancy of the measured interferometric phase variations (double differ-
ences) shall not follow any speciﬁc constraint, such as the triangulation scheme in the baseline domain
used in [122] that imposes a critical constraint on the generation of interferograms. This characteristic
allow to freely generate the set of interferograms.
2.20.6 SAR tomography
TheclassicalSARimagingallowshighresolutioncapabilityin2D,i.e.,azimuthandrange.Nevertheless,
the reality is 3D and, either due to the coupling of the intrinsic side-looking geometry and the vertical
structureofthetargets,ortothepenetrationoftheradiationbelowtheimagedsurface,theresultingimage
represents only a “projection” along the elevation direction of the illuminated 3D scene backscattering
properties over the azimuth slant-range plane.
SAR tomography aims to achieving a 3D reconstruction by using the imaging diversity along the
elevation direction (orthogonal to the azimuth and range plane) of (spatial) multibaseline acquisitions.
In particular, as it is difﬁcult and economically disadvantageous using several satellites to provide
multibaseline acquisitions from spaceborne, SAR Tomography is typically implemented by using data
corresponding to multiple passes of a single antenna SAR system over the same area. It is worth pointing
out that 3D imaging capability is already available with interferometric SAR systems, relying only on
the use of the phase difference between the signal acquired in at least two passes. However, InSAR
implicitly assumes the presence of only a single scattering mechanism, i.e., do not comply with a
possible integration (overlay) of the scattering along the elevation direction.
SAR Tomography is the extension of SAR interferometry to allow a full 3D imaging: it simply
synthesize, as in the case of the azimuth direction where a array is (digitally) formed, an array also in
the elevation direction by exploiting the different baselines available over repeated passes.
Most appreciable differences with respect to the azimuth synthesis is that passes are unevenly spaced
in elevation and that the number of baselines is sensibly lower than the number of echoes collected
in azimuth direction. The overall effect is a generally poor elevation resolution and the presence of
signiﬁcant distortions associated with possible excessive non-uniformity of passes.
Let us consider a multi-pass conﬁguration exploiting N images acquired along N different orbits,
not necessarily co-planar and not uniformly-spaced (see Figure 20.29). We denote with Pn denote the
nth orbit locations, bn, n = 1,…,N the orthogonal baselines of the nth orbit measured with respect a

1094
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
z
s
ϑ
1
b
P1
P2
P3
P4
P5
r
y
A
B
C
ρr
O
FIGURE 20.29
Multi-Pass SAR geometry in the range-elevation (r, s) plane (case N = 5).
reference “master” orbit (P3 in Figure 20.29), and ϑ is the look angle. A ground height proﬁle with
three point scatterers (A, B, and C) lying in the same range-azimuth resolution cell is depicted.
Letting hn be the signal in a ﬁxed azimuth and range pixel at the generic nth antenna, we have
[123–125]:
hn =
"
γ (s)e−j 4π
λ rn(s)ds,
(20.78)
where rn(s) is the distance of the scatterer at elevation s from the nth antenna. The phase term is supposed
to be not affected by APD component because the acquisitions are supposed to be simultaneous. In case
of repeat pass acquisitions, the APD must be compensated. Moreover, in the latter case it is assumed
that the target does not exhibit any deformation: this assumption will be relaxed for the description of
the differential tomography.
The data are processed by via deramping, i.e., the distance rn(0) of a reference elevation point (0
in Figure 20.29) is subtracted from the data at each antenna: expanding rn(s) −rn(0) and absorbing
s-dependent terms in γ (s), we have:
gn = hne j 4π
λ rn(s) =
"
γ (s)e j2πξnsds = FT

γ (s)

ξn ,
(20.79)
where the integral is limited to an interval of typically from few meters to hundreds of meters, and where:
ξn = 2bn
λr .
(20.80)
Equation (20.79) shows that the received data at the different antennas, in any ﬁxed azimuth and range
position, are samples of the Fourier Transform (FT) of the reﬂectivity function along the elevation direc-
tionatthefrequenciesdescribedbyEq. (20.80),andfollowsthe(LOSorthogonalcomponentof)baseline
distribution. SAR tomography processing aims at processing the data vector gT = [g1, g2, . . . , gN]
in such a way to achieve a reconstruction of the backscattering distribution γ (s). This is carried out by

2.20.6 SAR Tomography
1095
inverting a discretized version of (20.79) at Ms elevation samples (bins) s1, s2, . . . , sMs:
g =
a

s1

a

s2

· · ·
a

sMs

γ = Aγ ,
(20.81)
where vector γ T = [γ1
γ2
. . .
γMs]. Equation (20.81) provides the discrete model to be inverted
in the framework of SAR tomography. Many solutions are available [124,126,127]
2.20.6.1 Linear non-adaptive inversion for SAR tomography
A simple way to invert Eq. (20.81) and to recover the backscattering distribution is by applying the
beamforming, i.e.,:
ˆγ = AHg,
(20.82)
that is:
ˆγn = aH 
sn

g.
(20.83)
Note that the reconstruction of the backscattering sample ˆγn is achieved via a ﬁlter a(sn) which does
not depend on the data (non-adaptive inversion).
Another possibility is offered by the Singular Value Decomposition (SVD) analysis of the operator
in Eq. (20.79), i.e., by the SVD decomposition of the matrix A in the discrete case. In this latter case the
assumption on the support can lead to a slight degree of super-resolution with respect to the Rayleigh
resolution limit for elevation, given by:
ρs =
λr
2

bmax −bmin
,
(20.84)
where bmax and bmin are the maximum and minimum of {bn, n = 1, . . . , N}. The corresponding height
resolution is given by:
ρz = ρs sin ϑ.
(20.85)
SVD decomposition provides the following fundamental equations pair:
g =
N

k=0
σkukvH
k γ ,
(20.86)
γ =
N

k=0
σ −1
k
vkuH
k g,
(20.87)
where uk(N ×1 vector) and vk(Ms ×1 vector) are the left (data) and right (unknown) singular vectors of
A and σk are the singular values. Note that we have assumed Ms ≥N, i.e., a sampling of the elevation
interval in a number of points which is larger than the number of acquisitions thus translating in a
underdetermined characteristic of the matrix A.
Equations (20.86) and (20.87) represent the fundamental result of the SVD analysis: in particulars
Eq. (20.86) states that in principle all the different vectors uk concur in the composition of the observed
vector g; their contributions are however weighted by the singular values. Accordingly, low singular

1096
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
values σk indicates that the component along the corresponding data singular vector is attenuated by
the imaging operator in the data formation and should be carefully treated when reconstructing the
unknown via Eq. (20.87) because this data component may be overwhelmed by the unavoidable noise.
As a result, typically the reconstruction in Eq. (20.87) is limited to the data and unknown singular
vector pairs corresponding to signiﬁcant singular values; the associated inversion scheme is referred to
as Truncated SVD (TSVD). In the case in which the acquisitions are uniformly spaced with a separation
of b⊥if the output sampling is chosen verifying the Nyquistic conditions, i.e., s = λr/

2Nb⊥

= ρs,
i.e., N samples in the Nyquist interval

−a, a

with a = λr/

4b⊥

it can be shown that the operator A in
(20.81) is a Discrete Fourier Transform (DFT) matrix that is characterized by constant singular values.
In such a case σk = σand therefore the direct and inverse operator in (20.86) and (20.87) becomes
Hermitian conjugate pairs. In cases in which s < λr/

2Nb⊥

the singular values shows a decay
which translate the presence of a redundancy in the acquired spectral samples that can be exploited to
increase the resolution of the reconstruction below the Rayleigh limit in (20.84).
In other words, by progressively restricting the elevation ROI with respect to Nρs, a smooth decay in
the singular values is observed. For a reduction factor F < 1, if the noise is small enough, the truncation
can be arrested to a number of singular values which is larger than FN: in this condition a degree of
super resolution is achieved [124].
In addition to the super-resolution degree, the SVD decomposition allows also to reduce the level of
sidelobes with respect to a reconstruction carried out by simple Beamforming.
2.20.6.2 Linear adaptive inversion for SAR tomography
A more general expression for the evaluation of ˆγn is given by:
ˆγn = f H
n g,
(20.88)
where f H
n is the ﬁlter for the estimation of γn = γ (sn). Letting Cg = E

ggH
, that is the data covariance
matrix, a solution obtained mutatis mutandis from the spectral estimation theory such that:
ˆf n = arg min
f n
E
3f H
n g
24
= arg min
f n
f H
n Cgf n,
subject to f H
n a

sn

= 1,
(20.89)
i.e., a solution that achieves the minimum output power, subject to unitary gain at the ‘frequency’ (sn)
of interest (Capon ﬁlter), is provided by [128]:
f n =
C−1
g a

sn

aH 
sn

C−1
g a

sn
.
(20.90)
Substituting (20.90) in (20.88) provides:
E
 ˆγ

si
2 =
1
aH 
si

C−1
g a

si
.
(20.91)
It is interesting to note that Cg = I, white data spectrum, leads to f n = a(sn)/N. The advantage of the
Capon ﬁler is the achievement of higher super-resolution for line spectra (i.e., concentrated scatterers

2.20.6 SAR Tomography
1097
along s) compared to the SVD. However a disadvantage of the Capon ﬁlter is the need to estimate the
data Covariance matrix. This estimation is carried out via spatial averaging, and operation known in the
SAR processing as multi-look:
Cg = 1
L
L

l=1
g

l

gH 
l

,
(20.92)
where g(l) is the data vector in the lth pixel located close to the pixels in which the tomographic
processing aims to provide an estimate of the backscattering distribution.
Note that this operation inevitably leads to a loss of azimuth-range resolution. Note also that the
reconstruction of the backscattering sample ˆγn is in this case data dependent (adaptive inversion).
An example of reconstruction of a 3D SAR image on real data is provided in Figure 20.30: in this
case the results are the ﬁrst one obtained by using spaceborne SAR data, speciﬁcally data acquired
FIGURE 20.30
3D reconstruction of the San Paolo stadium in Naples via SVD. Left most column: elevation sections obtained
by applying the SVD to the single look data. Second column: SVD with three looks. Third column Capon with
ﬁve looks. In all cases the height scale is reported. Right column: azimuth range (averaged) image: the white
horizontal lines indicate the position of the sections with the range.

1098
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
by the ERS sensor [124]. In the ﬁrst three columns the reconstructions obtained by SVD and Capon
are reported. In particular six sections in the azimuth-elevation plane (i.e., at constant slant range) of
the San Paolo stadium in Naples are shows: the locations of the constant range are indicated by the
horizontal white line in the last column showing the classical azimuth-range representation. It is evident
the capability of the tomographic technique to capture the 3D shape of the structure. It is also evident
for the Capon approach that the increase in the height resolution is paid in terms of spatial (azimuth
and/or range) resolution losses.
2.20.6.3 Compressive sensing inversion for SAR tomography
A recent approach to solve the SAR tomography problem is based on Compressive Sensing [123,126,
129]. Compressive Sensing CS is a model-based framework for data acquisition and signal recovery
based on the premise that a signal having a sparse representation in one basis, can be reconstructed from
a small number of measurements collected in a second basis, that is incoherent with the ﬁrst [130]. In
our case sparseness requires a small number of stable targets in the same range-azimuth resolution cell
[123].
In SAR Tomography, this approaches is particularly effective [123,131] because on data acquired
high frequency systems (C- or X-band sensors), the scattering in the same range-azimuth cell along the
elevation occurs typically on a few concentrated scattering points, as shown in Figure 20.29.
Considering the tomographic model (20.81), the matrix A in the context of CS is called the mea-
surement matrix [130]. As already commented before, the inversion of Eq. (20.81) is equivalent to an
inverse FFT operation, and would provide an estimate of the reﬂectivity function with a nominal 3-dB
elevation resolution given by Eq. (20.84).
In practical cases, the orbits are usually not uniformly spaced and the number N of the available
acquisitions is generally much lower than the number of unknown samples Ms. As mentioned before
in Section 7.1, truncated SVD (TSVD) can be used [125] for the inversion of (20.52). An alternative
technique is based on Compressive Sampling [126]. It exploits the sparsity property of the unknown
vector γ and allows obtaining very satisfactory reconstructions, even when a reduced number of acqui-
sitions, almost randomly spaced within the overall elevation aperture, is available. Moreover, increased
resolutions can be obtained adopting CS.
In the considered sparsity hypothesis, the sampled reﬂectivity function can be written as:
γ = α,
(20.93)
where  is the sparsity matrix and α is a sparse Ms-dimensional vector. It has to be noted that in this
case, by choosing sampling points to represent the unknown scattering distribution, and considering the
circumstance that such function is sparse just in the domain of spatial samples (see also Figure 20.29,
where only K = 3 scattering contributions are present in the whole scattering distribution along the
elevation), the matrix  becomes the identity matrix [123].
An estimate of the vector α can be found solving the L1-norm minimization problem [130]:
ˆα = arg min ∥α∥1 subject to g = Aα.
(20.94)
The optimization problem in (20.94) is valid for the noiseless case. In the more realistic case, some
noise is present in addition on the measurements:
g = Aα + w
(20.95)

2.20.6 SAR Tomography
1099
with w a complex Gaussian vector with zero mean and uncorrelated elements. In this case, the solution
can be found by solving the linear programming problem [132]:
ˆα = arg min ∥α∥1 subject to ∥Aα = g∥2 ≤ε,
(20.96)
where ε is a small positive number.
For discussing the super resolution issue, we can refer to the case of high signal to noise ratio, so that
the maximum resolution that can be achieved depends only on the acquisition conﬁguration and not on
the noise level. The presence of an higher noise level can only degrade the evaluated performance.
In practical cases N < Ms, so that Eq. (20.81) expresses an underdetermined system, which will
admit a not-unique solution. Anyway, CS theory [130,132] ensures that if it is satisﬁed an incoherency
property between A and , it is indeed possible to recover the K largest components αi of α from the
N measurements provided that the following inequality is satisﬁed:
N ≥Cμ2 
A, 

K Ms

log Ms
4 ,
(20.97)
where C is a small constant depending on the measurement and sparsity matrixes A and , which
can be empirically estimated by numerical simulations, K denotes the number of non-zero coefﬁcients
of α, and μ

A, 

is the mutual coherence between the measurement basis A and the representation
(sparsity) basis , deﬁned in Ref. [132].
As far as the improvement or resolution, in Ref. [133] it has been shown that the elevation resolution
(null-to-null) which can be obtained adopting a CS approach is given by:
ρsCS = ρs/ηsup,
(20.98)
where ρs is the standard Fourier techniques elevation resolution and ηsup is the super-resolution factor
(greater than one).
For a ﬁxed number of acquisitions N, extension of illuminated scene in the elevation direction S, a
number of scatterers K, and for a given standard resolution ρs, there is an upper limit for the super-
resolution factor given by [133]:
ηsup = exp
5 N
CK
1/46
ρs
2S .
(20.99)
Combining Eqs. (20.98) and (20.99), a limit to the maximum resolution can be expressed as:
ρsCS = 2S exp
5
−
 N
CK
1/46
,
N ≤Ms.
(20.100)
Equations (20.99) and (20.100) provide the super-resolution limits of the CS approach applied to SAR
tomography.
Some experiments about the performance of the Compressive Sensing approach to solve the tomo-
graphic problem in terms of resolution capabilities, are presented in Ref. [123], with reference to sim-
ulated data using COSMO-Skymed system parameters (see Table 20.1), and to the real data acquired
by the sensors ERS1–2, over the city of Naples, between 1998 and 2001.

1100
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
Table 20.1 COSMO-Skymed System Parameters
COSMO-Skymed Parameters
Wavelength
0.031 m
View angle
23◦
Range distance
670 km
Ground range resolution
3 m
Azimuth resolution
3 m
The simulated observed scene is composed of two stable and coherent scatterers located in the same
range-azimuth resolution cell at different elevations and responding with the same radar cross section.
In the simulation presented in Figure 20.31, it has been assumed that the SAR signals are acquired
along multiple passes with a total orthogonal baseline span (bmax −bmin) = 567 m. The theoretical
resolution in the elevation direction is given, according to Eq. (20.84), by ρs = 36.6 m. Assuming that
the elevation extension of the ground scene is S = 200 m, the orbit spacing in the elevation direction
corresponding to the Nyquist sampling rate is equal to 52 m [133].
Two scatterers at the elevation values s1=7 m and s2 = 14 m are considered, so that they cannot be
resolved using standard FFT based techniques, since their distance is below the system conﬁguration
resolution. Moreover,N = 9 orbits with orthogonal baselines −271 m, −238 m, −154 m, −68 m, 0 m,
64 m, 118 m, 209 m, 295 m, are considered, and the acquired signals have been corrupted with additive
Gaussian noise, whose average power is 30 dB below the signal power.
FIGURE 20.31
TCS interpolated and normalized reﬂectivity proﬁle (black) of two scatterers at s1 = 7 m and s2 = 14 m
obtained from nine orbits with ηsup = 6, compared with the TSVD reconstructed proﬁle (blue) (For inter-
pretation of the references to color in this ﬁgure legend, the reader is referred to the web version of this
book.)

2.20.6 SAR Tomography
1101
FIGURE 20.32
Stadium San Paolo in Naples (ITALY).
The elevation proﬁle obtained by the CS approach starting from the nine available acquisitions and
with ηsup = 6, corresponding to the upper limit for the resolution ρsCS = 5 m is shown in Figure 20.3
(black line) where it is compared with the TSVD reconstruction (blue line), this latter able to achieve
conventional “Fourier” resolutions.
In the real data experiment, 15 passes, whose orthogonal baselines span a total baseline ST = 893 m,
are used. The resulting theoretical 3 dB elevation resolution is ρs = 26.6 m, which corresponds to a
height resolution ρz = 10.39 m. The tomographic processing of the four azimuth-height constant range
sections, indicated with four segments in the ortophoto image shown in Figure 20.32, are focused and
shown in Figure 20.33 using CS (left) and TSVD (right). For the CS reconstruction, a super-resolution
factor η = 3, corresponding to elevation and height resolutions of 8.87 m and 3.49 m, has been assumed.
Also in this case, the sections of the San Paolo stadium in Naples in elevation (i.e., at constant slant
range) shows, at different slant ranges, the capability of the technique to capture the 3D shape of the
structure. A resolution improvement of the CS method with respect to the TSVD one is evident.
2.20.6.4 Performance comparison of SAR tomography methods
In the previous sections four SAR tomography approaches were described: Beamforming and TSVD,
which attain an elevation resolution related and limited by the overall baseline span (see Eq. (20.84)),
Capon, which allows super-resolution along the elevation direction, but requires the use of looks and
therefore a loss of resolution, and Compressive Sensing based techniques, which exploits the sparsity
of the scattering proﬁle in elevation, and allows a strong improvement in elevation resolution.
The four method are compared with a data set simulating an observed scene composed by three
stable and coherent scatterers, located in the same range-azimuth resolution cell at different elevations,

1102
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
FIGURE 20.33
Azimuth height sections of tomographic reconstruction over the San Paolo stadium in Naples (ITALY),
obtained with TCS (left) and TSVD (right). (Blue) section A, (Red) section B, (Green) section C, (Purple)
section D of Figure 20.32. Credit: Univ. Napoli Parthenope; © IEEE. (For interpretation of the references to
color in this ﬁgure legend, the reader is referred to the web version of this book.)

2.20.7 4D Imaging
1103
and responding with the same radar cross section. More precisely the three scatterers are located at the
height values z1 = −6.83 m, z2 = 0 m, and z3 = 6.83 m.
In the simulation presented in Figure 20.34, it has been assumed that the SAR signals are acquired
along 30 multiple passes with a total orthogonal baseline span (bmax −bmin) = 1066 m and therefore
a mean baseline separation of 36.7 m: such a baseline distribution has been selected according to a
real dataset of the Envisat satellite. According to Eq. (20.84), the theoretical resolution in the elevation
direction is given by ρs = 22.3 m, corresponding to a height resolution ρz = 8.7 m. The three targets
have been therefore located in two resolution cells (in eleation). A total of 15 independent looks have
been generated by superimposing to the complex scatterer reﬂectivity a uniform phase independent
from look to look. Moreover, the acquired signals have been corrupted with additive Gaussian noise,
whose average power is 10 dB below the signal power.
The elevation interval 2a corresponding to the mean baseline is 645 m: this interval has been restricted
with a reduction factor given by F = 1/3, thus leading to an investigated interval of 215 m.
The reconstruction of the height proﬁle obtained by the CS, SVD and Beamforming tomographic
approaches, starting from the 30 available acquisitions have been generated separately for all the avail-
able looks. The result for a particular look are shown in Figure 20.34a; all approaches are able to
recover correctly the presence of three scatterer present in the proﬁle and to resolve them from each
other although the super-resolution capability of the CS based approach appear to be very evident. Due
to the particular realization of the noise the scatterers separation is slightly overestimated and therefore
the three targets are easily visible also from the Beamforming and SVD algorithms: the latter has slightly
better performances on the resolution and on the sidelobe ratio.
Beamforming, SVD, and Capon were applied to the multilook data: the result are shown in
Figure 20.34b. On one hand it is evident that on average the Beamforming and SVD are not able to resolve
thescatterers,althoughtheSVDprovidegenerallybetterperformanceswithrespecttotheBeamforming,
particularly on the sidelobe ratio. On the other hand, it is evident that in this case the Capon provide bet-
ter resolution capability with respect to the other two processing approaches, by resolving the presence
of the three distinct scatterers which are also located at the three correct heights. In any case differently
from the CS the super-resolution degree is paid by the necessity to have different looks. A more detailed
analysis of the performances of the CS tomography in terms of resolution degree can be found in [129].
2.20.7 4D Imaging
The 3D SAR focusing technique, also known as SAR Tomography allows to proﬁle the scattering
distribution along the elevation direction. Differential SAR Tomography, also referred to as 4D (3D
space + velocity) SAR imaging (focusing) is a natural extension of SAR Tomography to targets that
exhibit displacements. It allows measuring the scattering distribution in an elevation–velocity (EV)
plane, also known as tomo-doppler plane: locations of peaks in the EV plane allows identifying and
measuring elevation and velocity of scatterers, even interfering in the same resolution cell. The original
idea in [134] is framed in the statistical context and makes use of multilook data to estimate the data
covariance matrix and then to apply adaptive (non-linear) estimation, namely Capon ﬁltering to achieve
superresolution and sidelobe reduction.

1104
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
-40
-30
-20
-10
0
10
20
30
40
-30
-25
-20
-15
-10
-5
0
height [m]
dB
SVD
BF
CS
-40
-30
-20
-10
0
10
20
30
40
-20
-15
-10
-5
0
height [m]
dB
SVD
BF
Capon
(a)
(b)
FIGURE 20.34
Results of SAR tomography on simulated data. (a) Reconstructions obtained by Beamforming, SVD and
Compressive Sensing on single look data. (b) Results of Beamforming, SVD and Capon for multilook data.

2.20.7 4D Imaging
1105
Again referring to 0 (the deramping reference point) we let the scatterer located at elevation s to have
a deformation in the line of sight equal to d(s, tn), much smaller than the resolution cell; accordingly, in
place of Eq. (20.79) we have the following direct model for the signal collected at the generic antenna
following the deramping step:
gn =
"
γ (s)e j2πξns+ j 4π
λ d

s,tn

ds.
(20.101)
Moreover, the Fourier expansion of the second exponential term with respect to tn provides [114]:
e j 4π
λ d

s,tn

=
"
a(s, v)e j2πηnvdv,
(20.102)
with:
ηn = 2tn
λ .
(20.103)
Accordingly, Eq. (20.101) becomes:
gn =
""
γ

s, v

e j2πξns+ j2πηnvdv ds,
(20.104)
where γ (s, v) = γ (s)a(s, v).
Equation (20.104) shows that the received data are samples of the 2D Fourier Transform of the
scattering distribution in the EV plane: as in the 3D case it can be inverted to estimate the backscattering
distribution in the EV plane.
It is worth to note that, according to Eq. (20.102), v assumes the meaning of a spectral velocity. In
analogy to the concept of instantaneous and spectral frequency in frequency modulation, there is strictly
speaking no relation between v and the instantaneous temporal velocity. An exception is represented
by the case in which the targets exhibit a linear temporal deformation; in this case instantaneous and
spectral velocities are equal. However, under quite general conditions [135] the spectral support and
the instantaneous frequency variation interval turn out to be equal. Accordingly, the appearance of
focused energy in v in the elevation-velocity plane indicates the presence of scatterers with regular
phase variation that can be exploited to monitor the scatterer.
MultiD (3D and 4D) focusing technique relies on the assumption that the data stack is accurately
calibrated in amplitude and phase. While amplitude calibration can be easily carried out either via the
use of auxiliary information provided with the data, or via simple equalization of the power on selected
uniform areas or stable strong scatterers; phase calibration may be a much more complex issue due to
the presence of decorrelation phenomena, APD variation and non linear deformation: the latter allows
higher focusing of peaks corresponding to persistent scatterers in the EV plane.
The phase calibration step, designed to remove the atmospheric phase and low resolution (back-
ground) deformation from the signal data stack, a easy solution is by using a low resolution (small
scale) processing with SBAS based interferometry approaches, to estimate and compensate for APD
variation and possible non linear deformation.
Finally, a key problem associated with Multi-D imaging is the detection of scatterers that maintain
persistent scattering characteristics over the time. Following the key idea of the Persistent Scatterers

1106
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
(PS) technique, in classical PSI techniques this step is carried out in a sequence of two stages. In the
ﬁrst the so called Persistent Scatterers Candidates [99,100] are selected by analyzing the stability of the
amplitude response, i.e., by up-threshold, in each pixel, of the ratio between the standard deviation and
the mean of the amplitude response, named amplitude dispersion index:
DA =
√
N
+(N
n=1
|gn| −E
|gn|2,1/2
(N
n=1 |gn|
.
(20.105)
The amplitude dispersion index is close to zero over targets showing a high stable backscattering and is
proxy of the phase stability. PSC are used in PSI techniques to carry the phase calibration of the data,
i.e., the estimation and removal of the Atmospheric Phase Delay (APD) contribution. In the second
step, the detection of Persistent Scatterers is reﬁned by down-threshold of the temporal coherence index
in Eq. (20.68): all pixels that show a temporal coherence above the threshold are selected as PS and
topography and motion parameters are provided.
In Multi-D SAR imaging the amplitude information is directly involved in the formation of the
elevation proﬁle (3D imaging) or elevation-velocity image. As far as dominant scatterers are concerned,
a detector (the Generalized Maximum Likelihood Ratio Test, brieﬂy GLRT) [136] which is derived from
an optimal detection scheme (the Neuman-Pearson criterion) which maximizes the detection probability
for a ﬁxed false alarm probability is provided by [137]:
max
5 aHg

∥a∥∥g∥
6
>
< T ,
(20.106)
where the maximum has to be considered over s for the 3D case, or (s,v) for the 4D case, and T is a
threshold belonging to the interval (0,1), set accordingly to the desired false alarm probability.
It is instructive to note that in the PS case, the test is obtained by letting g = yϕ, i.e., by eliminating
from the data the amplitude information. It has been shown that, for a ﬁxed false alarm probability, the
tomographic based test allows achieving typically a gain of 1 dB in the detection of dominant scatterers
[137]. Note that Eq. (20.105) is based on the selection of the peaks of the (normalized) tomographic
response (a = a

s

for 3D, a = a

s, v

for 4D) achieved by simply applying a beamforming inversion
scheme, i.e., by multiplying by the data by the transpose conjugate the direct matrix.
Also in terms of accuracy of the estimated mean deformation velocity and residual topography
contributions the adoption of the detection scheme based on tomographic processing provides improve-
ments. In Figure 20.35 it is shown a comparison, in terms of scatter plot of the estimated elevation for
a tomographic processing (top) and for a PSI estimation.
Further studies have been carried out for the development of detections schemes able to perform
a higher order analysis to detect and separate the contribution of scatterers interfering in the same
resolution cell [138–141].
An example of the results obtained via 4D imaging are shown in Figure 20.36: in this case the dataset
was acquired by the ERS sensor the city of over Rome. All detected single and double scatterers where
geolocalized: due to the geolocalization process, scatterers located at different elevations and interfering
in the same azimuth-range pixels are projected at two different ground positions, see Figure 20.37.
The detected single scatters (shown in the uppermost image) show the presence of deformations
affecting the downtown of Rome [142]. In the two images on the left, a zoom on the results of single

2.20.7 4D Imaging
1107
−100
0
100
−2
−1
0
1
2
elevation [m]
velocity [cm/year]
SNR=−6dB
ML Estimates (44)
−100
0
100
−2
−1
0
1
2
elevation [m]
velocity [cm/year]
SNR=4dB
−100
0
100
−2
−1
0
1
2
elevation [m]
velocity [cm/year]
SNR=−6dB
MICC−based Estimates (46)
−100
0
100
−2
−1
0
1
2
elevation [m]
velocity [cm/year]
SNR=4dB
−100
0
100
−2
−1
0
1
2
elevation [m]
velocity [cm/year]
SNR=−2dB
−100
0
100
−2
−1
0
1
2
elevation [m]
velocity [cm/year]
SNR=−2dB
FIGURE 20.35
Scatter plots of the Tomographic (top) and PSI-based (bottom) stimators for mean deformation velocity and
topography for different values of the SNR.
and double scatterers are shown to demonstrate the capability of the detected double scatterers in 4D
imaging to provide important information in an area were layover impacts the monitoring capabilities,
see the railway tracks. The right plots shows the capability of 4D imaging to separate time series from
interfering scatterers.
Even when only a dominant scattering mechanism, it has been shown that the use of both amplitude
and phase information in MDI allows to improve the performance in terms of dominant persistent
scatterers detection with respect to classical PSI that uses only phase information [137].
In the following the result of a MDI processing of a set of 25 TerraSAR-X (TSX) spotlight data
acquired over ascending orbits over the city of Las Vegas, Nevada, USA is shown [19]: in this case the

1108
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
FIGURE 20.36
Example of separation of scatterers interfering in the same azimuth range pixel via multi-dimensional imaging
and determination of velocity and time series. Top image: estimated velocity of dominant scatterers in the
area of Rome. Bottom left: zoom on in an area exhibiting deformation due to alluvial deposits of the Tevere
river: representation of dominant (upper image) and double (down image) scatterers. Right images: time
series extracted by the double scatterers analysis.

2.20.7 4D Imaging
1109
ground range 
FIGURE 20.37
Graphical explanation of the mechanism of projection onto the ground range showing that two different scat-
terers located at the same range and resolved by the tomographic technique are located at different positions.
FIGURE 20.38
Example of reconstruction at full resolution of the Mirage Hotel in Las Vegas, USA obtained by processing
1 m resolution spotlight data with a 4D imaging approach. Credit IREA-CNR and DLR, © IEEE.
improvement of resolution from 5 m × 20 m of ERS to 1 m × 1 m of TerraSAR-X makes the layover
of buildings much more evident.
In particular, in Figure 20.38 it is shown the reconstruction of the Mirage Hotel obtained by detecting
persistent scatterers on a 1st order (single scatterers) and 2nd order (double scatterers interfering in the
same pixel) analysis. The possibility to synthesize a ﬁne beam also in the elevation direction provide
the TerraSAR-X sensor with the capability of reconstructing the building in 3D. In Figure 20.39 it is
shown the result of the multidimensional analysis, speciﬁcally the topography for the single and double
scatterers: the mid and right images shows the capability of the tomographic based processing of solving
the layover and hence separating the contribution of the two layers of the ground and façade interfering
due to the mechanism of folding of the vertical building toward the left (near range). The measured

1110
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
FIGURE 20.39
Detected scatterers for the formation of image in Figure 20.38. From left to right, single scatterers, lower
layer of double scatterers and top layer of double scatterers. Credit IREA-CNR and DLR, © IEEE.
FIGURE 20.40
Results on the Bellagio hotel for the Las Vegas dataset: single scatterers (left), single and double scatterers
(right). Colors are associated with the estimated topography.
deformations show essentially only the presence of thermal dilations for the roof area. Another example
of the effectiveness of multi-dimensional imaging is provided in Figure 20.40 for the Bellagio hotel.
The image on the right shows the ﬁnal set of detected single and double scatterers and the results,
especially on the upper façade of the building where interference with the ground is much critical,
shows a signiﬁcant improvement in the reconstruction of the building structure.
2.20.8 Conclusion
This review work has addressed the topics related to SAR interferometry and SAR Tomography. For
the ﬁrst topic we have described in details both from a deterministic and stochastic viewpoint the single

References
1111
and multibaseline interferometric technique for the estimation of the topographic height. Furthermore,
the differential interferometry technique has been addressed for the description of the possibility to
accurately monitor small deformation of the Earth surface, especially with reference to the application to
volcanic and seismic risk. Persistent scatterers interferometry, the differential interferometry technique
that has for the ﬁrst time shown the possibility to accurately monitor deformation, ﬁnds it “killer
application” to monitoring of man-made structures and has been also addressed. Furthermore whole
sections have been devoted to SAR tomography, also known as multi-dimensional imaging, which
is a technique based on an imaging approach and extends the concepts of interferometry. By using
the amplitude and phase information collected over multi-baseline multipass data it provides the best
technology currently used for the imaging and monitoring of urban areas and infrastructures. SAR
tomography is also applied for volume scattering proﬁling with application to forest mapping [125],
particularly in conjunction with polarimetry with a technique known as Polarimetric SAR Tomography.
In this review work we have limited our analysis to surface scattering single polarization: Further
description of SAR Tomography and Polarimetric SAR tomography can be found in [21,22,143]. Finally
application examples including results obtained with the recent very high resolution SAR sensors have
been provided to give the reader the possibility to have information about the current applicability,
potential and limits of the coherent SAR processing.
Acknowledgments
The Authors wish to thank the anonymous Reviewers for their comments which contributed to improve the quality of
the paper, and Prof. Gilda Schirinzi, Prof. Alessandra Budillon, Prof. Giampaolo Ferraioli, and Dr. Fabio Baselice,
of the Università di Napoli Parthenope, Italy, and Dr. Diego Reale of IREA-CNR, Napoli, Italy, for the valuable
discussions about the main topics of the paper. Moreover, the Authors wish to thank Prof. Richard Bamler of DLR
and Technical University of Munich, Germany, and Dr. Michael Eineider of DLR, Germany, and Dr. Alessandro
Ferretti, of Telerilevamento Europa (TRE), Italy, for providing some of the images included in this paper. The
Authors wish to thank also Prof. Fabrizio Lombardini of University of Pisa for providing the Capon results relevant
to the San Paolo Stadium data set, and Dr. Nicola D’Agostino of the Istituto Nazionale di Geoﬁsica e Vulcanologia
for providing the GPS data used in Figure 20.25.
References
[1] A. Moreira, P. Prats-Iraola, M. Younis, G. Krieger, I. Hajnsek, K.P. Papathanassiou, A tutorial on synthetic
aperture radar, IEEE Geosci. Rem. Sens. Mag. 1 (1) (2013) 6–43.
[2] C.A. Wiley, Synthetic aperture radars: a paradigm for technology evolution, IEEE Trans. Aerosp. Electron.
Syst. 21 (3) (1985) 440–443.
[3] R. Bamler, P. Hartl, Synthetic aperture radar interferometry, Inverse Probl. 14 (1998) R1–R54.
[4] P.A. Rosen, S. Hensley, I.R. Joughin, F.K. Li, S.N. Madser, E. Rodriguez, R.M. Goldstein, Synthetic aperture
radar interferometry, Proc. IEEE 88 (3) (2000) 333–382.
[5] R. Romeiser, H. Breit, M. Eineder, H. Runge, P. Flament, K. de Jong, J. Vogelzang, Current measurements
by SAR along-track interferometry from a Space Shuttle, IEEE Trans. Geosci. Remote Sens. 43 (10) (1995)
2315–2324.
[6] ERS. <https://earth.esa.int/web/guest/missions/esa-operational-eo-missions/ers>.

1112
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
[7] CSK. <http://www.asi.it/en/activity/earth_observation/cosmoskymed>.
[8] TerraSAR. Available from: <http://www.dlr.de/dlr/en/desktopdefault.aspx/tabid-10377/565_read-436/>.
[9] J.S. Lee, E. Pottier, Polarimetric Radar Imaging: From Basics to Applications, CRC Press, 2009.
[10] S.R. Cloude, E. Pottier, A review of target decomposition theorems in radar polarimetry, IEEE Trans. Geosci.
Remote Sens. 34 (2) (1996) 498–518.
[11] S.R. Cloude, E. Pottier, An entropy-based classiﬁcation scheme for land applications of polarimetric SAR,
IEEE Trans. Geosci. Remote Sens. 35 (1) (1997) 68–78.
[12] A. Freeman, S.T. Durden., A three-component scattering model for polarimetric SAR data, IEEE Trans.
Geosci. Remote Sens. 36 (3) (1998) 963–973.
[13] R. Touzi, W.M Boerner, J.S Lee, E. Lueneburg, A review of polarimetry in the context of synthetic aperture
radar: concepts and information extraction, Can. J. Remote Sens. 30 (3) (2004) 380–407.
[14] T. Le Toan, A. Beaudoin, D. Guyon., Relating forest biomass to SAR data. IEEE Trans. Geosci. Remote
Sens. 30 (2) (1992) 403–411.
[15] I. Hajnsek, E. Pottier, and S. Claude., Inversion of surface parameters from polarimetric SAR, IEEE Trans.
Geosci. Remote Sens. 41 (4) (2003) 727–744.
[16] I. Hajnsek, T. Jagdhuber, H. Shon, and K. P. Papathanassiou, Potential of estimating soil moisture under
vegetation cover by means of PolSAR, IEEE Trans. Geosci. Remote Sens. 42 (2) (2009) 442–454.
[17] S.R. Cloude, K. Papathanassiou, Polarimetric SAR interferometry, IEEE Trans. Geosci. Remote Sens.
36 (4) (1998) 1551–1565.
[18] K.P. Papathanassiou, S.R. Cloude, Single-baseline polarimetric SAR interferometry, IEEE Trans. Geosci.
Remote Sens. 39 (6) (2001) 2352–2363.
[19] D. Reale, G. Fornaro, A. Pauciullo, X. Zhu, R. Bamler, Tomographic imaging and monitoring of buildings
with very high resolution SAR data, IEEE Geosci. Remote Sens. Lett. 8 (4) (2011) 661–665.
[20] G. Fornaro, A. Pauciullo, D. Reale, X. Zhu, R. Bamler, SAR tomography: an advanced tool for 4D spaceborne
radar scanning with application to imaging and monitoring of cities and single Buildings, IEEE Geosci.
Remote Sens. Newslett. (2012) 10–18.
[21] S. Tebaldini, Single and multipolarimetric SAR tomography of forested areas: a parametric approach, IEEE
Trans. Geosci. Remote Sens. 48 (5) (2010) 2375–2387.
[22] S. Tebaldini, F. Rocca, Multibaseline polarimetric SAR tomography of a boreal forest at P- and L-Bands,
IEEE Trans. Geosci. Remote Sens. 50 (1) (2012) 232–246.
[23] S.R. Cloude, Polarization coherence tomography, Radio Sci. 41 (4) (2006) <http://dx.doi.org/10.1029/2005R
S003436>.
[24] S.R. Cloude, Dual-baseline coherence tomography, IEEE Geosci. Remote Sens. Lett. 4 (1) (2007) 127–131.
[25] J.C. Curlander, R.N. McDonough, Synthetic Aperture Radar: Systems and Signal Processing, Wiley-
Interscience, 1991.
[26] C. Elachi, Spaceborne Radar Remote Sensing: Applications and Techniques, IEEE, 1988.
[27] M.R. Ducoff, B.W. Titjen, Pulse Compression Radar, in: M. Skolnik (Ed.), Radar Handbook, third ed.,
McGraw-Hill Professional, 2008, ISBN 978-0071485470 (Chapter 8).
[28] I.G. Cumming, F.H. Wong, Digital Processing of Synthetic Aperture Radar Data: Algorithms And Imple-
mentation, Artech House Remote Sensing Library, 2005.
[29] W.G. Carrara, R.M. Majewski, R.S. Goodman, Spotlight Synthetic Aperture Radar: Signal Processing Algo-
rithms, Artech House Remote Sensing Library, 1995.
[30] L. Mittermayer, A. Moreira, O. Loffeld, Spotlight SAR data processing using the frequency scaling algorithm,
IEEE Trans. Geosci. Remote Sens. 37 (5) (1999) 2198–2214.
[31] P. Prats, R. Scheiber, J. Mittermayer, A. Meta, A. Moreira, Processing of sliding spotlight and TOPS SAR
data using baseband azimuth scaling, IEEE Trans. Geosci. Remote Sens. 48 (2) (2010) 770–780.

References
1113
[32] R. Lanari, S. Zoffoli, E. Sansosti, G. Fornaro, F. Seraﬁno, A new approach for hybrid stripmap/spotlight
SAR data focusing, IEE Proc. Radar Sonar Navig. 148 (2001) 363–372.
[33] R. Bamler, M. Eineider, ScanSAR processing using standard high precision SAR algorithms, IEEE Trans.
Geosci. Remote Sens. 34 (1) (1996) 212–218.
[34] F. De Zan, A. Monti Guarnieri, TOPSAR: Terrain observation by progressive scans, IEEE Trans. Geosci.
Remote Sens. 44 (9) (2006) 2352–2360.
[35] M. Eineder, N. Adam, R. Bamler, N. Yague-Martinez, H. Breit, Spaceborne spotlight SAR interferometry
with terraSAR-X, IEEE Trans. Geosci. Remote Sens. 47 (5) (2009) 1524–1535.
[36] F.T. Ulaby, R.K. Moore, A. Fung, Microwave Remote Sensing: Active and Passive, Radar Remote Sensing
and Surface Scattering and Emission Theory, vol. II, Artech House Publishers, 1986.
[37] G. Franceschetti, G. Fornaro, Synthetic aperture radar interferometry, in: G. Franceschetti, R. Lanari (Eds.),
Synthetic Aperture Radar Processing, CRC Press, 1999, 167–223.
[38] A.K. Gabriel, R.M. Goldstein, Crossed orbit interferometry: theory and experimental results from SIR-B,
Int. J. Remote Sens. 9 (1988) 857–872.
[39] E. Rodriguez, J.M. Martin, Theory and design of interferometric synthetic aperture radars, Proc. Inst. Elect.
Eng. Part. F 139 (1992) 147–159.
[40] A. Ferretti, C. Prati, F. Rocca, Multibaseline DEM reconstruction: the wavelet approach, IEEE Trans. Geosci.
Remote Sens. 37 (1999) 705–715.
[41] F. Lombardini, Optimum absolute phase retrieval in a three-element SAR interferometer, Electron. Lett. 34
(1998) 1522–1524.
[42] V. Pascazio, G. Schirinzi, Estimation of terrain elevation by multi-frequency interferometric wide band SAR
Data, IEEE Signal Process. Lett. 8 (2001) 7–9.
[43] R.M. Goldstein, H.A. Zebker, Interferometric radar measurements of ocean surface currents, Nature (1987)
707–709.
[44] R. Romeiser, H. Breit, M. Eineder, H. Runge, P. Flament, K. de Jong, J. Vogelzang, Current measurements
by SAR along-track interferometry from a space shuttle, IEEE Trans. Geosci. Remote Sens. 43 (10) (2005)
2315–2324.
[45] A. Budillon, V. Pascazio, G. Schirinzi, Estimation of radial velocity of moving targets by along-track inter-
ferometric SAR systems, IEEE Geosci. Rem. Sens. Lett. 5 (3) (2008) 349–353.
[46] A. Budillon, V. Pascazio, G. Schirinzi, Multi-channel along-track interferometric SAR systems: moving
targets detection and velocity estimation, Int. J. Navig. Obs. Q3 (2008) 1–16.
[47] G. Franceschetti, R. Lanari, V. Pascazio, G. Schirinzi, WASAR: a Wide angle SAR processor, IEE Proc. F
139 (2) (1992) 107–114.
[48] L.C. Graham, Synthetic interferometer for topographic mapping, Proc. IEEE 62 (1974) 763–768.
[49] O. Hellwick, H. Ebner, Geocoding SAR interferograms by least squares adjustment, J. Photogramm. Remote
Sens. 55 (4) (2000) 277–288.
[50] J.J. Van Zyl, The shuttle radar topography mission (SRTM): a breakthrough in remote sensing of topography,
Acta Astronaut. 48 (5–12) (2001) 559–565.
[51] G. Krieger, A. Moreira, H. Fiedler, I. Hajnsek, M. Werner, M. Younis, M. Zink, TanDEM-X: a satel-
lite formation for high-resolution SAR interferometry, IEEE Trans. Geosci. Remote Sens. 45 (11) (2007)
3317–3341.
[52] M. Lucido, F. Meglio, V. Pascazio, G. Schirinzi, Closed form evaluation of the second order statistical
distribution of the interferometric phases in dual-baseline SAR systems, IEEE Trans. Signal Proc. 58 (3)
(2010) 1698–1707.
[53] D. Just, R. Bamler, phase statistics of interferograms with applications to synthetic aperture radar, App. Opt.
33 (20) (1994) 4361–4368.

1114
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
[54] G. Fornaro, G. Franceschetti, Image registration in interferometric SAR processing, IEE Proc. Radar. Sonar
Navig. 142 (1995) 313–320.
[55] F. Gatelli, Guarnieri A. Monti, F. Parizzi, P. Pasquali, C. Prati, F. Rocca, The wave-number shift in SAR
interferometry, IEEE Trans. Geosci. Remote Sens. 32 (1994) 855–865.
[56] G. Ferraiuolo, F. Meglio, V. Pascazio, G. Schirinzi, DEM reconstruction accuracy in multi-channel SAR
interferometry, IEEE Trans. Geosci. Rem. Sens. 47 (1) (2009) 191–201.
[57] S.H.A. Zebker, J. Villasenor, Decorrelation in interferometric radar echoes, IEEE Trans. Geosci. Remote
Sens. 30 (1992) 950–959.
[58] C.W. Chen, H.A. Zebker, Two-dimensional phase unwrapping with use of statistical models for cost functions
in nonlinear optimization, J. Opt. Soc. Am. A 18 (2001) 338–351.
[59] C.W. Chen, H.A. Zebker, Phase unwrapping for large SAR interferograms: statistical segmentation and
generalized network models, IEEE Trans. Geosci. Remote Sens. 40 (8) (2002) 1709–1719.
[60] M. Costantini, A novel phase unwrapping method based on network programming, IEEE Trans. Geosci.
Remote Sens. 36 (3) (1998) 813–821.
[61] G. Fornaro, G. Franceschetti, R. Lanari, Interferometric SAR phase unwrapping using Green’s formulation,
IEEE Trans. Geosci. Remote Sens. 34 (3) (1996) 720–727.
[62] D.C. Ghiglia, L.A. Romero, Robust two-dimensional weighted and unweighted phase unwrapping that uses
fast transforms and iterative methods, J. Opt. Soc. Amer. A 11 (1) (1994) 107–117.
[63] R.M. Goldstein, H.A. Zebker, C.L. Werner, Satellite radar interferometry: two-dimensional phase unwrap-
ping, Radio Sci. 23 (4) (1998) 713–720.
[64] J.G. Proakis, M. Salehi, Communication Systems Engineering, second ed., Prentice Hall, 2001.
[65] W.B. Davenport, W.L. Root, An Introduction to the Theory of Random Signal and Noise, IEEE Communi-
cations Society Press, 1987.
[66] C. Prati, F. Rocca, Improving Slant-Range Resolution with Multiple SAR Surveys, IEEE Trans, Aerosp.
Electron. Syst. 29 (1993) 135–44.
[67] G. Fornaro, Monti A. Guarnieri, Minimum mean square error space-varying ﬁltering of interferometric SAR
data, IEEE Trans. Geosci. Remote Sens. 40 (2002) 11–21.
[68] R.M. Goldstein, H. Engelhardt, B. Kamb, R.M. Froclich, Satellite RADAR interferometry for monitoring
ice-sheet motion—application to an Antarctic ice stream, Science 262 (5139) (1993) 1525–1530.
[69] D. Massonnet, M. Rossi, C. Carmona, F. Adragna, G. Peltzer, K. Feigl, T. Rabaute, The displacement ﬁeld
of the Landers earthquake mapped by radar interferometry, Nature 364 (6433) (1993) 138–142.
[70] G. Peltzer, P.A. Rosen, Surface displacement of the 17 May 1993 Eureka valley, California, Earthquake
observed by SAR interferometry, Science 268 (1995) 1333–1336.
[71] R. Lanari, P. Lundgren, E. Sansosti, Dynamic deformation of etna volcano observed by satellite radar inter-
ferometry, Geophy. Res. Lett. 25 (10) (1998) 1541–1544.
[72] D. Massonnet, P. Briole, A. Arnaud, Deﬂation of Mount Etna monitored by spaceborne radar interferometry,
Nature 375 (1995) 567–570.
[73] E. Rignot, Fast recession of a west antartic glacier, Science 281 (1998) 549–551.
[74] R.F. Hanssen, Radar Interferometry: Data Interpretation and Error Analysis (Remote Sensing and Digital
Image Processing), Springer, 2001.
[75] R.M. Goldsteing, H.A. Zebker, C.L. Werner, Satellite radar interferometry: two dimensional phase unwrap-
ping, Radio Sci. 23 (4) (1998) 713–720.
[76] D.C. Ghiglia, M.D. Pritt, Two-Dimensional Phase Unwrapping: Theory, Algorithms, and Software, Wiley-
Interscience, 1998.
[77] D.C. Ghiglia, L.A. Romero, Minimum L p-norm two-dimensional phase unwrapping, J. Opt. Soc. Amer. A
13 (1996) 1999–2007.

References
1115
[78] T.J. Flynn, Two-dimensional phase unwrapping with minimum weighted discontinuity, J. Opt. Soc. Am. A
14 (1997) 2692–2701.
[79] M. Costantini, P.A. Rosen, A Generalized Phase Unwrapping Approach for Sparse Data, in: Proc. Int. Geosci.
Remote Sens. Symp. (IGARSS 1999) Hamburg, Germany, 1999, pp. 267–269.
[80] R. Bamler, M. Eineider, Accuracy of differential shift estimation by correlation and split-bandwidth inter-
ferometry for wideband and delta-k SAR systems, IEEE Geosci. Remote Sens. Lett. 2 (2) (2005) 151–155.
[81] G. Fornaro, A. Pauciullo, E. Sansosti, Phase difference-based multichannel phase unwrapping, IEEE Trans.
Image Proc. 14 (2005) 960–972.
[82] G. Fornaro, A. Monti Guarnieri, A. Pauciullo, F. De-Zan, Maximum likelihood multi-baseline SAR inter-
ferometry, IEE Proc. Radar Sonar Navigat. 153 (2006) 279–288.
[83] V. Pascazio, G. Schirinzi, Multi-frequency InSAR height reconstruction through maximum likelihood esti-
mation of local planes parameters, IEEE Trans. Image Process. 11 (2002) 1478–1489.
[84] W.Xu,E.Chang,L.Kwoh,H.Lim,W.Cheng,Phase-unwrappingofSARinterferogramwithmulti-frequency
or multi-baseline, in: Proc. Int. Geosci. Remote Sens. Symp. (IGARSS 1994), Pasadena, USA, 1994,
pp. 730–732.
[85] G. Ferraioli, A. Shabou, F. Tupin, V. Pascazio, Multichannel phase unwrapping with graph-cuts, IEEE Geosci.
Remote Sens. Lett. 6 (3) (2009) 562–566.
[86] J. Dias, J. Leitao, The zπm algorithm: a method for interferometric image reconstruction in SAR/SAS, IEEE
Trans. Image Process. 11 (2002) 408–422.
[87] G. Ferraiuolo, V. Pascazio, G. Schirinzi, Maximum a posteriori estimation of Height proﬁles in InSAR
imaging, IEEE Geosci. Remote Sens. Lett. 1 (2004) 66–70.
[88] G. Nico, G. Palubinskas, M. Datcu, Bayesian approach to phase unwrapping: theoretical study, IEEE Trans.
Signal Process. 48 (2000) 2545–2556.
[89] S.M. Kay, Fundamentals of Statistical Signal Processing: Estimation Theory, Prentice Hall, 1993.
[90] S.Z. Li, Markov Random Field Modelling in Computer Vision, Springer, Computer Science Workbench,
2001.
[91] S. Geman, D. Geman, Stochastic relaxation, Gibbs’ distributions, and Bayesian restoration of images, IEEE
Trans. Pattern Anal. Mach. Intell. 6 (1984) 721–741.
[92] A. Shabou, F. Baselice, G. Ferraioli, Urban digital elevation model reconstruction using very high resolution
multi-channel InSAR data, IEEE Trans. Geosci. Remote Sens. 50 (2012) 4748–4758.
[93] L.I. Rudin, S. Osher, E. Fatemi, Nonlinear total variation based noise removal algorithms, Physica D 60
(1–4) (1992) 259–268.
[94] H. Ishikawa, Exact optimization for markov random ﬁelds with convex priors, IEEE Trans. Pattern Anal.
Mach. Intell. 25 (2003) 1333–1336.
[95] Y. Boykov, O. Veksler, R. Zabih, Fast approximate energy minimization via graph cuts, IEEE Trans. Pattern
Anal. Mach. Intell. 23 (11) (2001) 1222–1239.
[96] V. Kolmogorov, R. Zabih, Multi-camera scene reconstruction via graph cuts, in: Proceedings of the 7th
European Conference on Computer Vision, 3, 2002, 82–96.
[97] Y. Boykov, V. Kolmogorov, An experimental comparison of min-cut/max-ﬂow algorithms for energy min-
imization in vision, Energy Minimization Methods in Computer Vision and Pattern Recognition (2001)
359–374.
[98] J. Castellanos, S. Gomez, V. Guerra, The triangle method for ﬁnding the corner of the L-curve, Appl. Numer.
Math. 43 (4) (2002) 359–373.
[99] A. Ferretti, C. Prati, F. Rocca, Nonlinear subsidence rate estimation using permanent scatterers in differential
SAR interferometry, IEEE Trans. Geosci. Remote Sens. 38 (2000) 2202–2212.
[100] A. Ferretti, C. Prati, F. Rocca, Permanent scatterers in SAR interferometry, IEEE Trans. Geosci. Remote
Sens. 39 (1) (2001) 8–20.

1116
CHAPTER 20 SAR Interferometry and Tomography: Theory and Applications
[101] M. Crosetto,E.Biescas,J.Duro,J.Closa,A.Arnaud, Generation of advanced ERS and envisat interferometric
SAR products using the stable point network technique, Photogramm. Eng. 74 (4) (2008) 443–451.
[102] N. Adam, B. Kampes, M. Eineder, J. Worawattanamateekul, M. Kircher, in: The Development of a Scientiﬁc
Permanent Scatterer System, ISPRS Hannover Workshop, Hannover, Germany, 2003.
[103] C. Werner, U. Wegmuller, T. Strozzi, A. Wiesmann, Interferometric point target analysis for deformation
mapping, in: Proc. Int. Geosci. Remote Sens. Symp., (IGARSS 2003), Toulouse, France, 2003.
[104] F. Bovenga, R. Nutricato, A. Reﬁce, J. Wasowski, Application of multi-temporal differential interferometry
to slope instability detection in Urban/Peri-Urban areas, Eng. Geol. 88 (2006) 219–240.
[105] M. Costantini, S. Falco, F. Malvarosa, F. Minati, F. Trillo (2009), Method of persistent scatterers pairs (PSP)
and high resolution SAR interferometry, in: Proc. Int. Geosci. Remote Sensing Symp. (IGARSS 2009)
Cape Town, South Africa, 2009.
[106] A. Hooper, P. Segall, H. Zebker, Persistent scatterer InSAR for crustal deformation analysis with application
to volcán Alcedo, Galàpagos, J. Geophys. Res. 112 (2007) B07407.
[107] G.E. Hilley, R. Burgmann, A. Ferretti, F. Novali, F. Rocca, Dynamics of Slow-Moving Landslides from
Permanent Scatterer Analysis, Science 304 (5679) (2004) 1952–1955.
[108] G. Herrera, J.C. Davalillo, J. Mulas, G. Cooksley, O. Monserrat, V. Pancioli, Mapping and monitoring
geomorphological processes in mountainous areas using PSI data: central pyrenees case study, Nat. Hazard
Earth Syst. Sci. 9 (2009) 1587–1598.
[109] P. Berardino, G. Fornaro, R. Lanari, E. Sansosti, A new algorithm for surface deformation monitoring
based on small baseline differential SAR interferograms, IEEE Trans. Geosci. Remote Sens. 40 (11) (2002)
2375–2383.
[110] P. Blanco-Sanchez, J. Mallorqui, S. Duque, D. Monnells, The Coherent pixels technique (CPT): an advanced
DInSAR technique for nonlinear deformation monitoring, Pure Appl. Geophys. 165 (6) (2008) 1167–1193.
[111] O. Mora, J. Mallorqui, A. Broquetas, Linear and non-linear terrain deformation maps from a reduced set of
interferometric SAR images, IEEE Trans. Geosci. Remote Sens. 41 (10) (2003) 2243–2253.
[112] G.H. Golub, C.F. Van Loan, Matrix Computations, Johns Hopkins University Press, 1996.
[113] A. Reﬁce, F. Bovenga, R. Nutricato, MST-based stepwise connection strategies for multipass Radar data, with
application to coregistration and equalization, IEEE Trans. Geosci. Remote Sens. 44 (8) (2006) 2029–2040.
[114] G. Fornaro, D. Reale, F. Seraﬁno, Four-dimensional SAR imaging for height estimation and monitoring of
single and double scatterers, IEEE Trans. Geosci. Remote Sens. 47 (1) (2009) 224–237.
[115] G. Fornaro, A. Pauciullo, F. Seraﬁno, Deformation monitoring over large areas with multipass differential
sar interferometry: a new approach based on the use of spatial differences, Int. J. Remote Sens. 30 (6) (2009)
1455–1478.
[116] N. D’Agostino, D. Cheloni, G. Fornaro, R. Giuliani, D. Reale, Space-time distribution of afterslip following
the 2009 L’Aquila earthquake, J. Geophys. Res. 117 (2012) B02402, doi: <http://dx.doi.org/10.1029/
2011JB008523>.
[117] S. Gernhardt, R. Bamler, Deformation monitoring of single buildings using meter-resolution SAR data in
PSI, ISPRS J. Photogramm. Remote Sens. (2012) (in print).
[118] R. Touzi, A. Lopes, J. Bruniquel, P.W. Vachon, Coherence estimation for SAR imagery, IEEE Trans. Geosci.
Remote Sens. 37 (1999) 135–149.
[119] G. Fornaro, A. Pauciullo, D. Reale, A null-space method for the phase unwrapping of multi-temporal sar
interferometric stacks, IEEE Trans. Geosci. Remote Sens. 49 (6) (2011) 2323–2334.
[120] P. Agram, H.Zebker, Edgelist phaseunwrapping algorithm for time-series InSAR analysis, J. Opt. Soc. Am. A
27 (3) (2010) 605–612.
[121] M. Costantini, F. Malvarosa, F. Minati, A general formulation for robust and efﬁcient integration of ﬁnite
differences and phase unwrapping on sparse multidimensional domains, in: ESA Fringe 2009 Workshop,
Frascati, Italy, 2009.

References
1117
[122] A. Pepe, L. Lanari, On the extension of the minimum cost ﬂow algorithm for phase unwrapping of multi-
temporal differential SAR interferograms, IEEE Trans. Geosci. Remote Sens. 44 (9) (2006) 2374–2383.
[123] A. Budillon, A. Evangelista, G. Schirinzi, Three-dimensional SAR focusing from multipass signals using
compressive sampling, IEEE Trans. Geosci. Remote Sens. 49(1) (2011) 488–499.
[124] G. Fornaro, F. Lombardini, F. Seraﬁno, Three-dimensional multipass SAR focusing: experiments with long-
term spaceborne data, IEEE Trans. Geosci. Remote Sens. 43 (4) (2005) 702–714.
[125] A. Reigber, A. Moreira, First demonstration of airborne SAR tomography using multibaseline L-band data,
IEEE Trans. Geosci. Remote Sens. 38 (5) (2000) 2142–2152.
[126] A. Budillon, A. Evangelista, G. Schirinzi, SAR Tomography from Sparse Samples, in: Proc. IEEE Int. Geosci.
Remote Sens. Symp. (IGARSS 2009), 2009, pp. IV-865–IV-868.
[127] F. Gini, F. Lombardini, Multibaseline cross-track SAR interferometry: a signal processing perspective, IEEE
Aerosp. Electron. Sys. Mag. 20 (8) (2005) 71–93.
[128] F. Lombardini, M. Montanari, F. Gini, Reﬂectivity estimation for multibaseline interferometric radar imaging
of layover extended sources, IEEE Trans. Signal Process. 51 (2003) 1508–1519.
[129] X.X. Zhu, R. Bamler, Super-resolution power and robustness of compressive sensing for spectral estimation
with application to spaceborne tomographic SAR, IEEE Trans. Geosci. Remote Sens. 50 (1) (2012) 247–258.
[130] E.J. Candes, M.B. Wakin, An introduction to compressive sampling, IEEE Signal Process. Mag. 25 (2)
(2008) 21–30.
[131] X.X.Zhu,R.Bamler,Demonstrationofsuper-resolutionfortomographicSARimaginginurbanenvironment,
IEEE Trans. Geosci. Remote Sens. (2012), <http://dx.doi.org/10.1109/TGRS.2011.2177843>.
[132] E.J. Candes, T. Tao, The Dantzig selector: statistical estimation when p is much larger than n Ann. Statist.
35 (6) (2007) 2313–2351.
[133] A. Budillon, G. Schirinzi, Artifact Reduction in SAR Compressive Sampling Tomography, in: Proc. Int.
Geosci. Remote Sens. Symp. 2011 (IGARSS 2011) (2011) 2700–2703.
[134] F. Lombardini, Differential tomography: a new framework for SAR interferometry, IEEE Trans. Geosci.
Remote Sens. 43 (1) (2005) 37–44.
[135] A.B. Carlson, P.B. Crilly, Communication Systems, ﬁfth ed., Mc Graw Hill Higher Education, 2009.
[136] S.M. Kay, Fundamentals of Statistical Signal Processing: Detection Theory, Prentice Hall, 1998.
[137] A. De Maio, G. Fornaro, A. Pauciullo, Detection of single scatterers in multdimensional SAR imaging, IEEE
Trans. Geosci. Remote Sens. 47 (7) (2009) 2284–2997.
[138] A. Pauciullo, D. Reale, A. De Maio, G. Fornaro, Detection of double scatterers in SAR tomography, IEEE
Trans. Geosci. Remote Sens. 50 (9) (2012) 3567–3586.
[139] X. Zhu, R. Bamler, Very high resolution spaceborne SAR tomography in urban environment, IEEE Trans.
Geosci. Remote Sens. 48 (12) (2010) 4296–4308.
[140] F. Lombardini, M. Pardini, Multiple scatterers identiﬁcation in complex scenarios with adaptive differential
tomography, in: Proceedings of the International Geoscience and Remote Sensing Symposium, Cape Town,
South Africa, July 2009.
[141] F. Lombardini, F. Gini, Model order selection in multibaseline interferometric radar systems, EURASIP J.
Adv. Signal Proc. 2005 (20) (2005), 3206–3219.
[142] G. Fornaro, F. Seraﬁno, D. Reale, 4-D SAR imaging: the case study of Rome, IEEE Geosci. Remote Sens.
Lett. 7 (2010) 236–240.
[143] S.R. Cloude, Dual-baseline Coherence Tomography, IEEE Geosci. Remote Sens. Lett. 4 (1) (2007) 127–131.

21
CHAPTER
Radar Polarimetry Basics and
Selected Earth Remote Sensing
Applications
Laurent Ferro-Famil and Eric Pottier
IETR, University of Rennes 1, Rennes, France
2.21.1 Introduction
Polarimetry (Polar: polarization, Metry: measure) is the science of acquiring, processing, and analyzing
the polarization state of an electromagnetic ﬁeld [1]. SAR polarimetry is concerned with the utilization
of polarimetry in radar remote sensing applications, whose objectives are to remotely detect and char-
acterize objects and environments. Due to its wide coverage, high resolution, and very low sensitivity
to weather conditions, Synthetic Aperture Radar (SAR) is by itself a unique tool for studying large
areas in a very short amount of time. The combination of SAR with polarimetric diversity has shown to
greatly improve the characterization capabilities with respect to scalar systems. Polarization permits to
increase the observation space but most of all, to relate the amplitude and phase of reﬂected signal to the
electromagnetic properties, shape, orientation, structure … of observed objects, i.e., polarimetry offers
a high potential for estimating physical characteristics of objects and environments.
2.21.1.1 Historical overview of radar polarimetry
Studies on wave polarization were ﬁrst led in optics and adapted to radar during the 1940s. During
three decades, scientists like Sinclair [2,3], Kennaugh [4] Deschamps [5] … developed theoretical tools
needed to handle coherent vector signals and techniques that used polarization as a way to discriminate
radarreturnsortoidentifyobjectsaccordingtospeciﬁcpolarimetricbehaviors.Duringthe1970sHuynen
[6] deeply modiﬁed the way to process polarimetric quantities, by combining rigorous techniques, based
on mathematical and signal processing concepts, with phenomenology, which considers polarimetric
information as a whole, rather than a sum of contributions. He identiﬁed structural aspects of polarimetric
returns, that could be related to basic properties of observed objects, like their shapes, orientations
… Some parts of this work were used and extended during the 1980s by Boerner [1] in the frame
of electromagnetic inverse problems, and by Cloude [7] who was preparing a new formalism that
would, once again, strongly increase the possibilities of analysis of polarimetric measurements. The
ﬁrst airborne AIRSAR polarimetric SAR campaign, led in 1988 by the JPL highly promoted SAR
polarimetry.
The 1990s were an auspicious decade for SAR polarimetry, and modern pioneers, like Freeman
[8,9], Van Zyl [10] and their colleagues from JPL, Lee [11] and his research team, from the ONR/NRL,
Cloude and Pottier [12,13], the DLR HR department in Germany, Yamaguchi [14] in Japan and many
others produced and stimulated a large amount of high quality scientiﬁc work. During this period,
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-396500-4.00021-1
© 2014 Elsevier Ltd. All rights reserved.
1119

1120
CHAPTER 21 Radar Polarimetry Basics
clear and rigorous polarimetric formalism and operators were deﬁned under the supervision of Boerner,
original polarimetric decomposition schemes and interpretations were introduced, speciﬁc statistical
techniques were adapted from the signal processing community to develop speciﬁc detection, estimation
and classiﬁcation techniques. Several polarimetric airborne sensors were developed and occasional
space shuttle missions were ﬂown, that provided data sets over which scientists could compare their
approaches.
At the end of the 1990s, Cloude and Papathassiou investigated a new diversity mode combining
polarimetry with interferometry [15] that provide information about the elevation of a scatterer. They
found out that polarimetric SAR interferometry (PolinSAR) was particularly well adapted to the char-
acterization of volumetric environments, like forest or other kinds of vegetated environments. This
discovery opened a new era for polarimetric remote sensing, since when they are used separately
polarimetry and interferometry might not be well adapted for such an application, depending on density
properties of the observed medium. Most of the developments in SAR polarimetry performed during
the 1990s were oriented towards a qualitative characterization of polarimetric scattering, i.e., the main
objectives concerned the understanding and accurate description of scattering rather than its utiliza-
tion for estimating physical quantities. Due to a much easier access to polarimetric SAR data, current
challenges involve more systematic approaches whose objectives concern the quantitative estimation
of physical parameters.
2.21.1.2 Organization of the work
The main objective of this chapter is to provide a brief and, unfortunately, restrictive panorama of some
characteristic techniques and applications of modern SAR polarimetry. This chapter is organized into
three main parts introducing ﬁrst basic deﬁnitions, representations and processing concepts of radar
polarimetry. The second section is dedicated to more advanced processing techniques oriented towards
speciﬁc applications like volumetric media characterization, soil moisture estimation … The last part
of the chapter shows how polarimetry can be combined with other kinds of signal diversity, like Time-
Frequency, interferometry, in order to signiﬁcantly increase the amount of information as well as the
possibilities of characterization and estimation of complex scattering phenomena.
The ﬁrst part presents some basics of SAR polarimetry, i.e., a summary of the work done by our
colleagues mentioned above. It is intended for beginners in polarimetry or scientists who wish to clarify
some speciﬁc principles, notations or basic concepts in radar polarimetry. The polarization of a wave is
ﬁrst described in terms of vector representations. From the general expression of a plane wave electric
ﬁeld is presented the concept of polarization ellipse which perfectly describes the polarimetric properties
of a wave. It is then shown that a two-element Jones vector can be deﬁned to parametrize this ellipse
and that simple Special Unitary operators can be used to represent a wave in any arbitrary polarization
basis. Once a wave is acquired in a polarization basis, i.e., with a given set of receiving antennas,
mathematical tools may be used to compute the signal that would be delivered by any arbitrary set of
receiving antennas, i.e., without actually measuring the signal for each arbitrary set. It is then shown that
for given acquisition conditions, the polarimetric properties of a scatterer can be represented under the
formofa(2×2)coherentscatteringmatrix.Theconceptofchangeofpolarizationbasisisextendedtothis
kind of representation and the structure of this matrix is given for different kinds of canonical scatterers,
i.e., helix, plane, dipole … Over distributed environments, Synthetic Aperture Radar (SAR) images are

2.21.2 SAR Polarimetry Basics
1121
known to be affected by the speckle effect. Similarly to the scalar case, speckled polarimetric responses
cannot be reliably characterized using single-look representations, i.e., from the coherent scattering
matrix. Incoherent second order representations, i.e., speciﬁc polarimetric covariance matrices, are
then introduced and characterized. It is then shown that polarimetric decomposition techniques are
needed to provide an interpretation of the polarimetric scattering response of a medium from second
order quantities. Such decomposition approaches may be based on scattering models or use speciﬁc
mathematical properties, in order to extract and characterize canonical scattering behaviors from a
distributed averaged representation. The necessity and usefulness, as well as the domain of application,
ofseveraldecompositiontechniquesarediscussed.Finallymultivariatestatistics,adaptedtopolarimetric
quantities are introduced and applied to the classiﬁcation and segmentation of polarimetric SAR images.
The second section presents advanced decomposition techniques and their application to the estima-
tion of physical quantities. The proposed approaches are all directly based on the basics introduced in
the ﬁrst part that are improved or adapted to speciﬁc situations using physical interpretation and simple
mathematics. Different model based techniques are introduced that aim to characterize a volumetric
medium lying over a natural soil. Several hypotheses or levels of adaptivity lead to different interpre-
tations and solutions. It is also shown that polarimetry may be efﬁciently used to roughly estimate the
azimuthal topography of a scene or to introduce physical considerations into a statistical segmentation
process. Finally, early studies on soil moisture and roughness estimation from speciﬁc polarimetric
indicators are presented. This part illustrates the fact that SAR polarimetry is an interactive multi-
disciplinary subject open to a wide range of scientists and engineers wishing to investigate physical
phenomena using interesting mathematical tools.
The last part presents selected topics in multidimensional polarimetric SAR signal processing. The
dimensionality of polarimetric signal being rather low, the use of other kinds of diversity is often required
to solve an estimation problem. This part shows how three different applications, Time-Frequency char-
acterization of complex environments, Pol-inSAR characterization of forested areas and polarimetric
SAR tomography, i.e., polarimetric 3-D imaging, rely on the same physical considerations. All these
techniques are based on the modeling of the correlation properties of polarimetric signals acquired
from different positions, which may vary with the position at which is performed the acquisition, the
considered polarization channel and the nature of the observed object or medium.
2.21.2 SAR polarimetry basics
2.21.2.1 Polarimetric scattering: formalism, descriptors, and operators
2.21.2.1.1
Polarization of a monochromatic plane wave
2.21.2.1.1.1
Polarization ellipse
The polarization of a wave is studied here in the particular case of constant amplitude monochromatic
plane waves [16] propagating in a homogeneous, loss less medium, free of charges, with a celerity c.
This wave is perfectly deﬁned by its electric ﬁeld, E(r, t), where r and t represent spatial and time
coordinates, respectively. Without any loss of generality, the electric ﬁeld may be represented in an
orthogonal basis (ˆx, ˆy, ˆz) deﬁned so that the direction of propagation is aligned with one of the basis

1122
CHAPTER 21 Radar Polarimetry Basics
(
)
(
)
(
)
(
)
(
)
(a)
(b)
FIGURE 21.1
Spatial trajectories of (a) horizontally and (b) circularly polarized planes waves.
axes, ˆk = ˆz, with ˆk = k/||k|| and k the wave vector. The expression of the electric is given by
E(z, t) =
⎡
⎣
Ex(z, t)
Ey(z, t)
0
⎤
⎦=
⎡
⎣
E0x cos (ωt −kz + δx)
E0y cos (ωt −kz + δy)
0
⎤
⎦.
(21.1)
Due to the planar shape of the wave, the electric ﬁeld is composed of two orthogonal sinusoidal
signals, oriented along directions ˆx and ˆy, that are orthogonal to the direction of propagation ˆz. The term
ωt −kz, related to the space-time duality of propagating waves being common to both components, the
polarimetric properties of E(z, t) are deﬁned by the amplitude and phase of each component, E0x , E0y,
and δx, δy [17]. As shown in Figure 21.1, for a ﬁxed temporal coordinate, t0, the spatial evolution of a
plane monochromatic wave follows a helical trajectory along the z axis, whose characteristics depend
on the amplitude and phase terms of (21.1).
Three-dimensional helical curves being difﬁcult to represent and to analyze, one generally makes
use of the space-time duality in (21.1), i.e., shifts in time and space are equivalent, to characterize the
polarization of the wave in the time domain, at a ﬁxed position, z = z0 [17]. As time evolves, the
wave propagates through the equi-phase plane, orthogonal to the direction of propagation and located
at coordinate z0 and describes a characteristic elliptical locus as shown in Figure 21.2.
The nature of the wave temporal trajectory may be determined from the following parametric relation
between the components of E(z0, t):
E2
x(z0, t)
E2
0x
−2 Ex(z0, t)Ey(z0, t)
E0x E0y
cos (δy −δx) +
E2
y(z0, t)
E2
0y
= sin (δy −δx).
(21.2)

2.21.2 SAR Polarimetry Basics
1123
(
)
(
)
(
)
(
)
φ
τ
φ
τ
(a)
(b)
FIGURE 21.2
(a) propagation of the electric ﬁeld through an orthogonal plane at z = z0 (b) parametrized polarization
ellipse.
The expression in (21.2) is the equation of an ellipse, called the polarization ellipse that describes
the wave polarization, and may be characterized using three parameters as shown in Figure 21.2.
•
A is called the ellipse amplitude and is determined from the ellipse axis as:
A =

E2
0x + E2
0y.
(21.3)
•
φ is the ellipse orientation and is deﬁned as the angle between the ellipse major axis and ˆx:
tan (2φ) = 2
E0x E0y
E0x
2 + E0y
2 | cos (δy −δx)|,
φ ∈

−π
2 , π
2

.
(21.4)
•
τ the ellipse aperture, also called ellipticity, deﬁned as:
| sin 2τ| = 2
E0x E0y
E0x
2 + E0y
2 | sin (δy −δx)|,
|τ| ∈

0, π
4

.
(21.5)

1124
CHAPTER 21 Radar Polarimetry Basics
(a)
(b)
FIGURE 21.3
Deﬁnition of the sense of rotation along the polarization ellipse (a) left handed rotation (b) right handed
rotation.
As time goes, the electric ﬁeld vector E(z0, t) rotates in the (x, y) plane to describe the polarization
ellipse. By convention, the sense of rotation is determined while looking in the direction of propagation
is associated to the sign of τ. A right hand rotation corresponds to ∂ξ(t)
∂t
> 0 ⇒τ < 0 whereas a left
hand rotation is characterized by ∂ξ(t)
∂t
< 0, ⇒τ < 0. Figure 21.3 provides a graphical description of
the rotation sense convention [16,18].
Three types of polarizations can be speciﬁed:
•
Linear polarization: δ = δy −δx = 0.
The electric ﬁeld is a sine wave lying on a plane oriented with an angle φ with respect to the ˆx axis,
with:
E(z0, t) =

E2
0x + E2
0y
⎡
⎣
cos φ
sin φ
0
⎤
⎦cos (ωt0 −kz + δx)
and the polarization ellipse reduces to a line segment.
•
Circular polarization: δ = δy −δx = π
2 + kπ and E0x = E0y.
In this case, the wave rotates circularly around the ˆz axis as shown in Figure 21.1, and has a constant
modulus |E(z, t)|2 = E0x 2 + E0y2. The polarization ellipse is then a circle.
•
Elliptic polarization: In this case, wave describes a helical trajectory around the ˆz axis.
The polarimetric quantities introduced in this section have been deﬁned under a speciﬁc and arbitrary
convention, that may be associated to the way a ﬁxed antenna measures a ﬁeld: the wave is observed
at a ﬁxed position, z0, as time goes. One could have chosen another approach: observing the wave at
a ﬁxed time t0, for a varying position along the ˆz axis. Such an approach would have led to different
expressions for the polarimetric parameters, since derivatives of the phase term in (21.1) with respect
to z and t have opposed signs. This fact is taken into account when deﬁning the change of polarimetric

2.21.2 SAR Polarimetry Basics
1125
Table 21.1 Unitary Jones Vectors and Associated Polarization Ellipse Parameters for Some
Canonical Polarization States
Polarization State
u(x,y)
φ
τ
Horizontal (H)
uH =
	
1
0

0
0
Vertical (V)
uV =
	
0
1

π/2
0
Linear +45
u+45 =
1
√
2
	
1
1

π/4
0
Linear −45
u−45 =
1
√
2
	
1
−1

−π/4
0
Left circular
uL =
1
√
2
	
1
j

[−π/2, . . . , π/2]
π/4
Right circular
uR =
1
√
2
	
1
−j

[−π/2, . . . , π/2]
−π/4
basis for a scattering matrix (21.32). Readers interested by this aspect are invited to look at previous
reference works [1,16,17,19].
2.21.2.1.1.2
Jones vector
In the case of a constant amplitude monochromatic plane wave, the space-time expression of the electric
ﬁeld given in (21.1) is redundant and may be simpliﬁed using complex notations. The Jones vector, E,
which completely describes the wave polarization is obtained from the complex envelope of the ﬁeld as:
E = E(z)|z=0 =
 E0x e jδx
E0ye jδy

,
(21.6)
where E(z) is the time-independent complex envelope of the electric ﬁeld, and is obtained from its real
expression as E(z, t) = ℜ(E(z)e jωt). The deﬁnitions of a polarization state from the polarization ellipse
descriptors or from a Jones vector are equivalent. A Jones vector can be formulated as a two-dimensional
complex vector function of the polarization ellipse characteristics as follows [16]:
E = A e jα
 cos φ cos τ −j sin φ sin τ
sin φ cos τ + j cos φ sin τ

= A e jα
cos φ
−sin φ
sin φ
cos φ
  cos τ
j sin τ

,
(21.7)
where α is an absolute phase term.
Some examples of Jones vectors and polarization ellipse parameters are given in Table 21.1.

1126
CHAPTER 21 Radar Polarimetry Basics
Jones vectors may also be written using particular matrix operators belonging tho the group of special
unitary (2 × 2) matrices, SU(2). Such a group is called a Lie group and is generated through the matrix
exponentiation of a, generally non unique, set of matrix generators. Readers interested by this topic are
referred to [20]. The deﬁnition of the generators using the Pauli matrix leads to three SU(2) operators,
that may be viewed as complex rotation matrices, given by [7]:
U2(φ) =
cos φ
−sin φ
sin φ
cos φ

,
U2(τ) =
 cos τ
j sin τ
j sin τ
cos τ

,
U2(α) =
e+ jα
0
0
e−jα

.
(21.8)
As special unitary matrices, these operators verify U−1
2
= U†
2 and |U2| = 1 where † stands for the
transpose conjugate operator and |U| is the determinant of U. From the deﬁnition given in (21.7), a
Jones vector E(x,y), describing a general elliptical polarization state in the Cartesian basis, may be
expressed using SU(2) operators as [1]:
E(x,y) = A
 cos φ
−sin φ
sin φ
cos φ
  cos τ
j sin
j sin τ
cos τ
  e+ jα
0
0
e−jα
  1
0

= A U2(φ) U2(τ) U2(α) x
= A U2(φ, τ, α) x,
(21.9)
where x = uH corresponds to the unit Jones vector associated to the horizontal polarization state.
2.21.2.1.1.3
Change of polarization basis
One of the main advantages of radar polarimetry, linked to the vector nature of polarization, resides in the
fact that a target response acquired in a polarization basis, may be expressed in any basis using a simple
mathematical transformation, without any additional measurements. An orthonormal polarization basis
is composed of two unitary norm Jones vectors, u and u⊥, whose hermitian scalar product is null:
u†u⊥= 0 with u†u = u†
⊥u⊥= 1.
(21.10)
For a given Jones vector, u, there exist an inﬁnite number of orthogonal unitary vectors satisfying
(21.10). The SU(2) formalism introduced in the former paragraph may then be used to pick a unique
solution. Both vectors may be deﬁned from their ellipse parameters in the (ˆx, ˆy) basis:
u = U2(φ, τ, α)x and u⊥= U2(φ⊥, τ⊥, α⊥)x.
(21.11)
The orthogonality is then introduced by rewriting u⊥as a function of y = [0, 1]T , the second element
of the Cartesian basis:
u⊥= U2(φ⊥, τ⊥, α⊥)x = U2(φ, τ, α)y.
(21.12)
It is thus straightforward to remark that the orthogonality condition implies that u and u⊥are associated
with ellipse parameters satisfying:
φ⊥= φ + π
2 ,
τ⊥= −τ,
α⊥= −α.
(21.13)

2.21.2 SAR Polarimetry Basics
1127
A Jones vector, E(x,y) = Exx + Eyy expressed in the Cartesian (x, y) basis, transforms to E(u,u⊥) =
Euu + Eu⊥u⊥in the orthonormal (u, u⊥) polarimetric basis, by the way of a SU(2) transformation.
The coordinates Eu and Eu⊥can be determined according to the following expression
E(u,u⊥) = Euu + Eu⊥u⊥
⇒E(x,y) = EuU2(φ, τ, α)x + Eu⊥U2(φ, τ, α)y = Exx + Eyy.
(21.14)
It then follows:
 Eu
Eu⊥

= U2(φ, τ, α)−1
 Ex
Ey

⇒E(u,u⊥) = U2(x,y)→(u,u⊥)E(x,y)
(21.15)
with U2(x,y)→(u,u⊥) = U2(φ, τ, α)−1 = U2( −α)U2( −τ)U2( −φ).
To summarize, the special unitary SU(2) matrix, corresponding to any elliptical basis change, is
deﬁned by:
U2(φ, τ, α) = U2(α)U2(τ)U2(φ) =
1

1 + |ρ|2
 1
−ρ∗
ρ
1
  e+ jξ
0
0
e−jξ

,
(21.16)
where α, φ, τ correspond to the three geometric parameters of the polarization ellipse described by the
ﬁrst or principal Jones vector of the new basis. This special unitary SU(2) basis change matrix can
also be described using the parameters ρ and ξ which correspond to the polarization ratio of the ﬁrst or
principal Jones vector of the new basis and are given by [16]:
ρ = tan φ + j tan τ
1 −j tan φ tan τ
and ξ = α −atan( tan φ tan τ).
(21.17)
2.21.2.1.2
Polarimetric scattering descriptors
2.21.2.1.2.1
Radar measurements with full polarimetric diversity
A synopsis of radar acquisitions operated with a polarization diversity on receive only is shown in
Figure 21.4. An electric ﬁeld with a given polarization state, ET ∝u is transmitted and the received
signal is measured over both elements of the polarization basis (u, u⊥):
ET ∝u
→
ER = Euuu + Eu⊥uu⊥.
(21.18)
The response of the object may then be represented in any arbitrary polarization basis at the reception
using SU(2) transformations introduced earlier. This kind of acquisition requires twice the amount of
storageofasingle-polarizationmeasurementandchangestoparticularpolarizationbasesatthereception
may be used to detect or characterize scatterers with a particular scattering behavior. Nevertheless, such
a diversity is incomplete, since the received information depends on the emitted wave polarization.
As shown in Figure 21.5, a measurement with full polarimetric diversity requires to emit two signals
with orthogonal polarization states:
ET ∝u
→
ERu = Euuu + Eu⊥uu⊥,
ET ∝u⊥
→
ERu⊥= Euu⊥u + Eu⊥u⊥u⊥.
(21.19)

1128
CHAPTER 21 Radar Polarimetry Basics
FIGURE 21.4
Synopsis of a radar operating with a polarization diversity of receive.
FIGURE 21.5
Synopsis of a radar operating with full polarization diversity.
This kind of acquisition requires four times the amount of storage of a single-polarization measure-
ment and twice the amount of emitted pulses, but particular polarization bases may be tuned at both
emission and reception to adapt polarization to the features of a measured scatterer in an optimal way.
All the measured complex amplitudes Epq, with p, q = u or u⊥, may be gathered into a (2 ×2) matrix,
S, called scattering matrix.
S ∝
ERuERu⊥

=
 Euu
Euu⊥
Eu⊥u
Eu⊥u⊥

.
(21.20)

2.21.2 SAR Polarimetry Basics
1129
2.21.2.1.2.2
Scattering matrix and target vector
As a reﬂection occurs over an object, the incident and scattered Jones vectors of these ﬁelds are related
by a (2 × 2) complex scattering matrix, S , as:
Es = e−jkr
r
S Ei = e−jkr
r
 S11
S12
S21
S22

Ei,
(21.21)
where S is named scattering matrix and the Si j, are the so-called complex scattering coefﬁcients or
complex scattering amplitudes. The diagonals elements of the scattering matrix receive the name of
co-pol terms, since they relate the same polarization for the incident and the scattered ﬁelds. The off-
diagonal elements are known as cross-pol terms as they relate orthogonal polarization states. Finally,
the term e−jkr
r
accounts for propagation effects both in amplitude and phase. The relation expressed in
(21.21) relies on plane wave assumptions for both the incident and scattered ﬁelds. The elements of the
scattering matrix can be related with the radar cross section of a given target as follows:
σqp = 4π
Sqp
2 .
(21.22)
The scattering matrix is generally measured in the cartesian HV basis, i.e., u = ˆx and u⊥= ˆy.
Moreover, in the monostatic backscattering case, where the transmitting and receiving antennas are
located at the same position, placed at the same location, the role of the transmitting and the receiving
antennas can be interchanged, in case of a reciprocal propagation medium, and the scattering matrix is
symmetric, i.e., S = ST . In such a case, the S may be written in the HV basis as:
Sxy =
 SH H
SHV
SHV
SV V

=
 |SH H|e jφH H
|SHV |e jφHV
|SHV |e jφHV
|SV V |e jφV V

.
(21.23)
The elements SH H and SV V produce the power return in the co-polarized channels and the elements SHV
and SV H produce the power return in the cross-polarized channels. The structure of the scattering matrix
may be further simpliﬁed by getting rid of an absolute phase term that reveal useful for interferometric
applications but does not bring any polarimetric information. This reference phase term is generally
taken as the argument of the HH channel scattering term, but any other choice could be used. The
resulting relative scattering matrix is the given by:
Sxy rel = e−jφH H Sxy =

|SH H|
|SHV |e j(φHV −φH H )
|SHV |e j(φHV −φH H )
|SV V |e j(φV V −φH H )

.
(21.24)
In consequence, in the monostatic case, the fully polarimetric response of a scatterer can be characterized
by 5 real parameters (5 degrees of freedom): 3 amplitudes and 2 relative phases. The total scattered
power, in the case of a polarimetric radar system is called the Span, and is deﬁned as the L2 norm of S:
Span = tr

SS∗T 
= |S11|2 + 2|S12|2 + |S22|2,
(21.25)
where tr(A) is the trace of A.

1130
CHAPTER 21 Radar Polarimetry Basics
Initsoriginalform,theclassical (2×2)coherentSinclairmatrixSisnotwelladaptedtomanipulations
requiredbymodernsignalprocessingtechniques.Inordertoovercomethislimitation,targetorscattering
vectors have been deﬁned from linear combinations of the elements of S. Among the inﬁnite number
of possibilities, two representations are generally preferred, the Pauli target vector, k = kP, obtained
from a projection onto the Pauli matrix set, and the lexicographic one, kL, deﬁned as:
k = kP =
1
√
2
 SH H + SV V
SH H −SV V
2SHV
T
(21.26)
and
kL =

SH H
√
2SHV
SV V
T .
(21.27)
The norms of these scattering vectors equal the Span of the S matrix
||k||2 = ||kL||2 = |SH H|2 + 2|SHV |2 + |SV V |2 = Span(S)
(21.28)
and the Pauli and lexicographic vectors correspond through a (3 × 3) special unitary matrix, U3(L→P)
k = U3(L→P)kL
with U3(L→P) =
1
√
2
⎡
⎣
1
0
1
1
0
−1
0
√
2
0
⎤
⎦.
(21.29)
2.21.2.1.2.3
Change of polarization basis
Consider a monostatic back-scattering S(x,y) matrix deﬁned in the Cartesian (x,y) basis [17,18], with:
Es
(x,y) = S(x,y)Ei
(x,y).
(21.30)
As introduced earlier, the incident Jones vector, Ei
(x,y) expressed in the Cartesian (x,y) basis, transforms
to Ei
(u,u⊥) in the orthonormal (u,u⊥) polarimetric basis, by the way of a SU(2) transformation:
Ei
(u,u⊥) = U(x,y)→(u,u⊥)Ei
(x,y)
(21.31)
with U(x,y)→(u,u⊥) = U2(φ, τ, α)−1, whose parameters are obtained from the expression of u in the
(x,y) basis. In order to apply the same polarimetric basis change to the scattered Jones vector ES
(x,y),
one has to take into account that, in the monostatic case, the incident and scattered Jones vector represent
ﬁelds propagating in opposite directions, i.e., ks = −ki, by an additional complex conjugation on the
SU(2)operatorappliedontothescatteredJonesvector[16].Injecting(21.31)into(21.30)andcomparing
the result to Es
(u,u⊥) = S(u,u⊥)Ei
(u,u⊥), the monostatic back-scattering matrix S(u,u⊥) expressed in the
in the orthonormal (u,u⊥) polarimetric basis is then given by:
S(u,u⊥) = U∗
(x,y)→(u,u⊥)S(x,y)U−1
(x,y)→(u,u⊥)
= U2(φ, τ, α)T S(x,y)U2(φ, τ, α)
.
(21.32)

2.21.2 SAR Polarimetry Basics
1131
The transformation expressed in Eq. (21.32) is named a con-similarity transformation and allows syn-
thesizing the monostatic back-scattering matrix S in any elliptical polarization basis when measured in
the Cartesian (x,y) basis.
The change of basis may of (21.32) may be adapted to target vectors using (3 × 3) special unitary
matrices. Despite the fact that there is no noticeable relation between SU(2) and SU(3) matrix groups,
one may derive corresponding operators by identifying (21.32) with the deﬁnition of a target vector. In
the case of scattering vectors deﬁned in the Pauli basis, the SU(2) −SU(3) correspondence, may be
deﬁned as:
U2(φ) =
 cos φ
−sin φ
sin φ
cos φ

⇒U3T (2φ) =
⎡
⎣
1
0
0
0
cos 2φ
sin 2φ
0 −sin 2φ
cos 2φ
⎤
⎦,
U2(τ) =
 cos τ
j sin τ
j sin τ
cos τ

⇒U3T (2τ) =
⎡
⎣
cos 2τ
0
j sin 2τ
0
1
0
j sin 2τ
0
cos 2τ
⎤
⎦,
(21.33)
U2(α) =
 e+ jα
0
0
e−jα

⇒U3T (2α) =
⎡
⎣
cos 2α
j sin 2α
0
j sin 2α
cos 2α
0
0
0
1
⎤
⎦.
The monostatic target vector k(x,y) expressed in the Cartesian (x,y) basis transforms to k(u,u⊥),
expressed in the orthonormal ((u,u⊥) polarimetric basis by the way of a Special Unitary transfor-
mation given by [20]:
k(u,u⊥) = U3T (2φ, 2τ, 2α) k(x,y).
(21.34)
2.21.2.1.2.4
Canonical scattering mechanisms
A real target always presents a complex scattering response as a consequence of its complex geometrical
structureanditsreﬂectivityproperties.Consequently,theinterpretationofthisresponseisratherdifﬁcult.
This section lists some elementary targets presenting canonical scattering mechanisms characterized by
S expressed in three canonical orthogonal polarimetric bases:
•
Cartesian polarization basis (h, v) where h stands for the horizontal polarization and v for the vertical
polarization.
•
Linear rotated basis (a, a⊥) where a indicates the linear polarization at 45◦and a⊥the orthogonal
linear polarization at −45◦.
•
Circular polarization basis (l, l⊥) where l refers to the left circular polarization and l⊥= r to the
orthogonal left circular polarization or equivalent to the right circular polarization.
The shapes of the different canonical scatterers are illustrated in Figure 21.6.
Sphere, ﬂat plate, trihedral. Scatteringmatricesofasphere,aplaneoratrihedralinthethreepolarization
basis:
Cartesian
Linear rotated
Circular
basis (h, v)
basis (a, a⊥)
basis (l, l⊥)
S =
 1 0
0 1

S =
 1 0
0 1

S =
 0
j
j
0

.

1132
CHAPTER 21 Radar Polarimetry Basics
ˆ v t
ˆ h t
ˆ v t
ˆ h t
ˆ v t
ˆ h t
ˆ v t
ˆ h t
ˆ h tˆ h t
ˆ v t
ˆ h t
ˆ v t
ˆ h t
ˆ v t
ˆ h t
ˆ v t
ˆ h t
l
φ
ˆ v t
ˆ h t
(a)
(b)
(c)
(d)
(e)
(f)
FIGURE 21.6
Canonical scatterers (a) left helix, (b) right helix, (c) dihedral, (d) trihedral, (e) horizontal dipole, (f) oriented
dipole with angle φ.
Horizontal dipole. Scattering matrices of a dipole along the horizontal axis in the three polarization
basis:
Cartesian
Linear rotated
Circular
basis (h, v)
basis (a, a⊥)
basis (l, l⊥)
S =
 1 0
0 0

S = 1
2
 1
−1
−1
1

S = 1
2
 1
−j
−j
1

.
Oriented dipole. Scattering matrices of a dipole oriented with an angle φ in the three polarization
basis:
Cartesian
Linear rotated
Circular
basis (h, v)
basis (a, a⊥)
basis (l, l⊥)
S =
 cos2 φ
1
2 sin 2φ
1
2 sin 2φ
sin2 φ

S =

1+sin 2φ
2
1
2 −cos2 φ
1
2 −cos2 φ
1−sin 2φ
2

S = 1
2
e j2φ
−j
−j
e−j2φ

.

2.21.2 SAR Polarimetry Basics
1133
Dihedral. Scattering matrices of a horizontal dihedral in the three polarization basis:
Cartesian
Linear rotated
Circular
basis (h, v)
basis (a, a⊥)
basis (l, l⊥)
S =
 1
0
0 −1

S =
 0
−1
−1
0

S =
 1 0
0 1

.
Scattering matrices of a dihedral oriented with an angle φ in the three polarization basis:
Cartesian
Linear rotated
Circular
basis (h, v)
basis (a, a⊥)
basis (l, l⊥)
S =
 cos 2φ
sin 2φ
sin 2φ
−cos2 φ

S =
 sin 2φ
−cos 2φ
−cos 2φ
−sin 2φ

S =
e j2φ
0
0
e−j2φ

.
Right helix. Scattering matrices of a right helix oriented with an angle φ in the three polarization basis:
Cartesian
Linear rotated
Circular
basis (h, v)
basis (a, a⊥)
basis (l, l⊥)
S = e−j2φ
2
 1
−j
−j
−1

S = e−j2φ
2
−j
−1
1
j

S =
 0
0
0 −e−j2φ

.
Left helix. Scattering matrices of a left helix oriented with an angle φ in the three polarization basis:
Cartesian
Linear rotated
Circular
basis (h, v)
basis (a, a⊥)
basis (l, l⊥)
S = e−j2φ
2
 1
j
j
−1

S = e−j2φ
2
 j
−1
−1 −j

S =

e−j2φ
0
0
0

.
Color-coded polarimetric images are displayed for three different polarimetric bases on Figure 21.7
that can be easily interpreted in terms of canonical scattering mechanisms
2.21.2.1.3
Second order incoherent representations
2.21.2.1.3.1
Single polarization SAR: intensity
SAR imaging and the speckle effect. The objective of Synthetic Aperture Radar imaging is to provide
a high resolution map of the reﬂectivity of a scene. This technique based on the use of both spatial
and frequency diversity. The response of the scene to signals having a large bandwidth is measured
from different positions along an acquisition track. Signals are generally focused using a 2-D matched
ﬁlter that uses both spectral and spatial diversities to create a 2-D azimuth-range image, s(x,r), with
improved resolutions in both directions (Figure 21.46). The signal focused at coordinates (x,r), may
be represented as a 2-D convolution [21]:
s(x,r) =

ac(x′,r′)e−j2kr′h(x −x′,r −r′)dv′ + n(x,r),
(21.35)

1134
CHAPTER 21 Radar Polarimetry Basics
FIGURE 21.7
Optical and color-coded polarimetric SAR images for three different polarimetric bases of the San-Francisco
bay. Data acquired by the NASA/JPL AirSAR sensor.
where ac(x,r) represents the density of coherent reﬂectivity of the scene, i.e., its normalized coefﬁcient
of reﬂection and h(x,r) is the 2-D impulse response of the SAR acquisition-processing chain, that
steers the resolution properties of the image. The term n(x,r) corresponds to additive noise induced
by the acquisition system and may be omitted in the following for the sake of simplicity. Two extreme
cases, illustrated in Figure 21.8, may be commented:

2.21.2 SAR Polarimetry Basics
1135
(b)
(a)
FIGURE 21.8
(a) deterministic (b) random SAR scenes.
•
The resolution cell under observation contains a dominant point-like scatterer with a strong response
plus some negligible, clutter contributions. In this case, the coherent reﬂectivity density and the SAR
response are given by
ac(x,r) = A e jφ0δ(x −x0,r −r0) + ϵ ≈A e jφ0δ(x −x0,r −r0)
⇒s(x,r) ≈A e jφ0e−j2kr0h(x −x0,r −r0).
(21.36)
•
The resolution cell under observation contains a large number of independent scatterers, uniformly
distributed, with random amplitude and phase and having equivalent reﬂectivities. In this case, the
coherent reﬂectivity is a continuum of independent, random, contributions.
E(ac(x,r)a∗
c (x′,r; )) = σδ(x −x′,r′).
(21.37)
According to (21.35) the SAR response is the sum of all the contributions from scatterers located
in the resolution cell. As it shown in Figure 21.9, in the case of a point-like scatterer with a strong
response, the SAR response follows a quasi deterministic behavior dominated by a main contribution.
In the case of numerous equally uniformly distributed contributions, SAR focusing may be associated
to a random walk in the complex plane, and the resulting SAR response is a random variable.

1136
CHAPTER 21 Radar Polarimetry Basics
(a)
(b)
FIGURE 21.9
Two realizations of the coherent summation over resolutions containing (a) a dominant deterministic scatterer
(b) uniformly distributed random scatterers.
Over homogeneous, untextured, areas where a SAR resolution cell contains a large number of
independent contributions, the SAR response has a highly random behavior, i.e., the amplitude and
phase resulting from the random walk described in Figure 21.9 varies considerably from one resolution
cell to the other, due to slight changes in the geometric or radiometric conﬁgurations of the elementary
scatterers. This effect, known as speckle, is inherent to the use of a coherent imaging system and should
not me misinterpreted as noise. Speckle is a physical phenomenon that confers SAR data a random
behavior. Over areas having a homogeneous scattering behavior, the central limit theorem applies, and
the SAR response is well modeled by the following product model
s =
√
Iη
⇒
s(l) =
√
Iη(l),
(21.38)
where I is the intensity of the response and may be related to σ in (21.37), the reﬂectivity of the observed
medium. The parameter l represents the index of a realization of the complex random variable η ∈C
whose ﬁrst and second moments are [22]
E(η(l)) = 0, var(η(l)) = E(|η(l)|2) = 1 and E(η(l)η(m)∗) = δm−l.
(21.39)
The speckle component is generally assumed to follow a centered complex normal distribution,
η ∼NC(0, 1), with independent real ηr and imaginary ηi parts, i.e., with a uniform phase distri-
bution and identical normal distributions, NR(0, 1
2), for its real and imaginary parts.

2.21.2 SAR Polarimetry Basics
1137
From (21.38), the probability density function (pdf) of s = x + jy is given by
fx,y(x, y) = fx(x) fy(y) = 1
π I e−x2+y2
I
⇒
fs(s) = 1
π I e−|s|2
I
(21.40)
which may be rewritten as s ∼NC(0, I). The pdfs of the argument and squared modulus of s are
farg (s)(φ) = 1
2π
and
f|s|2(ρ2) = 1
I e−ρ2
I .
(21.41)
It may be observed that, due to its uniform distribution, arg (s) cannot be used to characterize the
observed environment, while |s|2, the Maximum Likelihood (ML) estimate of I, shows an important
variability, since E(|s|2) = I and var(|s|2) = I 2, i.e., the standard deviation of the positive quantity
|s|2 is equal to its mean!
Second order estimates using multilooking. A solution to obtain more stable statistical estimates
consists in considering L simultaneously several independent realizations, or looks, of s, {s(l)}L
l=1. The
joint pdf of these L independent looks is [22]
f (s(1) . . . s(L)) =
L

l=1
fs(l)(s(l)) =
1
π L I L e−1
I
L
l=1 |s(l)|2 =
1
π L I L e−L I
I ,
(21.42)
where I = 1
L
L
l=1 |s(l)|2, the L-look sample intensity is the ML estimate of I and its statistics are
given by
f (I) =
L LI L−1
(L −1)!I L e−L I
I
with
E(I) = I, var(I) = I
N .
(21.43)
As illustrated, the use of a sufﬁciently high number of looks, L, permits to signiﬁcantly reduce the
standard deviation of the estimate I, i.e., I may be considered as a reliable estimate of the true
intensity I.
Speckle ﬁltering. Insummary,aSARresponses mayhaveverydifferentstatisticalbehaviors,depending
on the kind of scatterer under observation. Over distributed environments, composed of a continuum
of randomly distributed scatterers, the focused SAR signal, consisting of a coherent sum of a large
number of independent random contributions, is affected by the speckle phenomenon characterized by
a highly random aspect. The resulting SAR signal is modeled as product of an amplitude term,
√
I,
related to the average scattering intensity of the illuminated medium, and of a random component,
η following a circular complex normal distribution (central limit theorem) and playing the role of a
speckle generator. Due to the high variability of both its phase and amplitude, s cannot be directly used
to characterize the scattering properties of the illuminated medium in a reliable way. Instead, several
independent realizations of the SAR signal, s(l) with l = 1, . . . , L, may be used to build an incoherent
representation, i.e., that does not depend on the uniformly distributed phase of s, called the sample
intensity and deﬁned as I =
1
L
L
l=1 |s(l)|2, which is the ML estimate of the true intensity I over
homogeneous environments.
The optimality of the sample intensity requires that the L samples s(l) belong to the same distribution,
given in (21.40). Among the many ways to create L samples of a SAR response, the approach generally

1138
CHAPTER 21 Radar Polarimetry Basics
(a)
(b)
(c)
I
1
L
L
I i
FIGURE 21.10
Intensities of images acquired by the DLR ESAR sensor at l band over Oberpfaffenhofen (a) single look,
(b) (7 × 7) boxcar ﬁltered, (c) (7 × 7) Lee ﬁltered.
used in practice consists in selecting responses over resolution cells located in the azimuth-range vicinity
of the cell under study. Under the hypothesis of a local stationary scattering behavior, this techniques
permits to obtained identically distributed independent looks. Numerous studies have been led on the
problem of efﬁcient and accurate speckle ﬁltering [11,23]. An example using a simple (N × N) sliding
box and a more reﬁned Lee ﬁlter [18], is given in Figure 21.10.
2.21.2.1.3.2
Dual polarization SAR: wave covariance matrix
Similarly to single-polarization acquisitions, measurements over several polarimetric channels may be
affected by speckle. In this case, Jones vectors E =
 Ex
Ey
T may be characterized using their ﬁrst
and second order moments
E(E) = 0,
J = E(EE†) = E
 Ex E∗
x
Ex E∗
x
Ey E∗
x
Ey E∗
y

=

Ix
Ix Iyρ
Ix Iyρ∗
Iy

.
(21.44)
The (2 × 2) wave covariance matrix, J, contains the information about the second orders moments of
E, Its diagonal elements provide the intensity for each polarimetric channel, whereas the normalized
cross-correlation factor indicates the stability of the measured ellipse parameters, along the direction
of observation (time or space). If |ρ| = 1 the components of the measured Jones vectors samples, E(l),
are maximally correlated, i.e., E(l) ∝E ∀l. Oppositely, if |ρ| = 0 the uncorrelated components of
the measured Jones vectors are very differently affected by speckle, denoting large variations of the
polarimetric properties over the different samples E(l). A speckled Jones vector follows a complex
multivariate normal distribution, E(l) ∼NC(0, J), whose expression is given by [22]
fE(E(l)) =
1
π2|J|e−E†(l)J−1E(l) =
1
π2|J|e−tr(J−1E(l)E†(l)).
(21.45)

2.21.2 SAR Polarimetry Basics
1139
Similarly to the single-polarization case, the variance of the second order estimates may be reduced
using L independent looks.
f ({E(l)}L
l=1) =
1
π2L|J|L e−tr(J−1 L
l=1 E(l)E†(l)) =
1
π2L|J|L e−L tr(J−1J),
(21.46)
whereJ = 1
L
L
l=1 E(l)E†(l)) is the L-look ML estimate of J, and follows a Wishart complex pdf [18]
f (J) = L2L|J|L−2
˜2(L)|J|L e−L tr(J−1J),
(21.47)
where ˜2(L) is the complex Gamma function.
In order to characterize the variability of the received Jones vector samples, an indicator, called
degree of polarization has been deﬁned:
DoP =

1 −4 |J|
tr(J)2 .
(21.48)
A received wave is said to be fully polarized if DoP = 1, i.e., |ρ| = 1. For depolarized waves, DoP = 0
corresponds to completely uncorrelated Jones vectors, with |ρ| = 0, and whose parameters vary in such
a random way that the backscattered intensity is equally distributed over the polarimetric channels, and
J is proportional to the identity matrix. Between these two extreme cases lies the general case of partial
polarization, with 0 < DoP < 1. It is however important to note that the elements of the wave covariance
matrix J depend on the choice of the polarization basis. Let J(x,y) the wave covariance matrix expressed
in the Cartesian (x, y) basis, transforms to J(u,u⊥) in the orthogonal (u, u⊥) polarimetric basis, by the
way of a Special Unitary similarity transformation as [16]:
J(u,u⊥) = E(E(u,u⊥)E†
(u,u⊥))
= U(x,y)→(u,u⊥)E(E(x,y)E†
(x,y))U†
(x,y)→(u,u⊥)
= U(x,y)→(u,u⊥)J(x,y)U†
(x,y)→(u,u⊥),
(21.49)
where U2(x,y)→(u,u⊥) corresponds to the elliptical basis transformation SU(2) matrix. The trace and
determinant of a Hermitian matrix being invariant under unitary similarity transformations, the wave
degree of polarization (DoP) is independent of the polarization basis chosen to represent the covariance
matrix.
2.21.2.1.3.3
Fully polarimetric SAR: coherency or covariance matrices
Data statistics. In order to easily compute and exploit second order statistics, the elements of speckle-
affected scattering matrix samples, S(l) are re-arranged into target vectors, k(l) or kL(l), introduced in
(21.26) and (21.27). The ﬁrst and second order moments of these vectors are given by
E(k) = E(kL) = 0,
T = E(kk†),
and C = E(kLk†
L),
(21.50)

1140
CHAPTER 21 Radar Polarimetry Basics
where the (3 × 3) covariance matrices, T and C are called coherency and covariance matrices and are
related through a SU(3) transformation:
k = U3(L→P)kL
⇒
T = U3(L→P)CU†
3(L→P).
(21.51)
For a fully developed speckle, when the distributed scattering mentioned previously are satisﬁed, a
target vector follows a complex normal pdf:
fk(k(l)) =
1
π3|T|e−k†(l)T−1k(l) =
1
π3|T|e−tr(T−1k(l)k†(l)).
(21.52)
The joint pdf of L independent realizations is given by
f ({k(l)}L
l=1) =
1
π3L|T|L e−tr(T−1 L
l=1 k(l)k†(l)) =
1
π3L|T|L e−L tr(T−1T),
(21.53)
where T = 1
L
L
l=1 k(l)k†(l)) is the L-look ML estimate of T, and follows a Wishart complex pdf
f (T) = L3L|T|L−2
˜2(L)|T|L e−L tr(T−1T),
(21.54)
where ˜3(L) is the complex Gamma function. Similar expressions may be obtained for the lexicographic
deﬁnition, by replacing k with kL and T with C.
Properties of the coherency and covariance matrices. Developed as well as parametrized expressions
of T and C are given hereafter.
The coherency matrix may be written as:
T = 1
2E
⎛
⎝
⎡
⎣
|Sxx + Syy|2
(Sxx + Syy)(Sxx −Syy)∗
2(Sxx + Syy)S∗
xy
(Sxx −Syy)(Sxx + Syy)∗
|Sxx −Syy|2
2(Sxx −Syy)S∗
xy
2Sxy(Sxx + Syy)∗
2Sxy(Sxx −Syy)∗
4|Sxy|2
⎤
⎦
⎞
⎠
=
⎡
⎣
2A0
C −j D
H + jG
C + j D
B0 + B
E + j F
H −jG
E −j F
B0 −B
⎤
⎦,
(21.55)
where A0, B0, B, C, D, E, F, G, H are 9 real coefﬁcients, called Huynen parameters, used by
Huynen [6] to characterize second order polarimetric representations. The covariance matrix C may be
expressed as
C = E
⎛
⎝
⎡
⎣
|SX X|2
√
2SX X S∗
XY
SX X S∗
YY
√
2SXY S∗
X X
2|SXY |2
√
2SXY S∗
YY
SYY S∗
X X
√
2SYY S∗
XY
|SYY |2
⎤
⎦
⎞
⎠
= σ
⎡
⎣
1
β
√
δ
ρ√γ
β∗√
δ
δ
ε√γ δ
ρ∗√γ
ε∗√γ δ
γ
⎤
⎦,
(21.56)

2.21.2 SAR Polarimetry Basics
1141
FIGURE 21.11
Geometrical conﬁguration of (a) azimuthal symmetry, (b) rotation symmetry, (c) reﬂection symmetry.
where σ, δ, γ are real parameters and β, ρ, ϵ are complex and form a 9-element set of real coefﬁcients.
Coherency and covariance matrices may be represented in any arbitrary polarimetric basis using a
Special Unitary similarity transformation:
T(u,u⊥) = E(k(u,u⊥)k†
(u,u⊥))
= UT (x,y)→(u,u⊥)E(k(x,y)k†
(x,y))U†
T (x,y)→(u,u⊥)
= UT (x,y)→(u,u⊥)T(x,y)U†
T (x,y)→(u,u⊥)
(21.57)
where UT (x,y)→(u,u⊥) is an elliptical basis transformation SU(3) matrix adapted to the coherency
matrix formalism. For covariances matrices equivalent representations may be obtained by combining
UT (x,y)→(u,u⊥) with U3(L→P).
Coherency and covariance matrices have speciﬁc structures [12] over media showing particular sym-
metry properties shown in Figure 21.11. Some media exhibit reﬂection symmetry when the distribution
of the polarimetric responses is symmetric with respect to the plane of incidence. Such a behavior
is mainly observed over horizontal natural environments and is characterized by a lack of correlation
between co- and cross-polarization channels, i.e., E(ShhS∗
hv) = E(SvvS∗
hv) = 0. Other media may
have covariance matrices that remain invariant by rotation around the radar line of sight, i.e., invariant
under transformation through the U3(2φ) SU(3) operator. Finally, media exhibiting both reﬂection and
rotation symmetries are said to be azimuth symmetric. Such a response is generally encountered over
dense volumetric environments.
The speciﬁc shapes of the coherency and covariance matrices corresponding to the three different
scattering symmetry conﬁgurations are:
•
Reﬂection symmetry case:
T =
⎡
⎣
a
b
0
b∗
c
0
0
0 d
⎤
⎦
⇔
C =
⎡
⎣
α
0 β
0
δ
0
β∗
0 γ
⎤
⎦.
(21.58)

1142
CHAPTER 21 Radar Polarimetry Basics
•
Rotation symmetry case:
T =
⎡
⎣
a
0
0
0
b
c
0
c∗
b
⎤
⎦
⇔
C =
⎡
⎣
α
β
δ
β∗
α −δ
−β∗
δ
−β
α
⎤
⎦.
(21.59)
•
Azimuthal symmetry case:
T =
⎡
⎣
a
0 0
0
b
0
0
0 b
⎤
⎦
⇔
C =
⎡
⎣
α
0
β
0
α −β
0
β
0
α
⎤
⎦.
(21.60)
2.21.2.2 Polarimetric decomposition techniques
2.21.2.2.1
Necessity of polarimetric decompositions
As it has been shown previously, polarimetric scattering behaviors may be analyzed by comparing
relative scattering matrices, Srel, to canonical scattering mechanisms, i.e., plate, dipole, helix …
The use of second order incoherent polarimetric representations does not represent a limitation since
a relative scattering matrix can be reconstructed from the hermitian external product of a target vector:
S(l) ≡k(l)
⇒
Srel(l) ≡k(l)k†(l).
(21.61)
Nevertheless, incoherent averaging involved in the speckle ﬁltering stage may perturb signiﬁcantly the
identiﬁcation of a polarimetric scattering mechanism from a coherency matrix. The only conﬁguration
for which it is possible to establish a unique relation between Srel and T may be expressed as:
k(l) = α(l)k0
⇒
T = E(kk†) = A k0k†
0 ≡Srel0
(21.62)
In such a case, speckle only affects the Span of the polarimetric responses, relative phases and amplitudes
remain unaffected and polarimetric scattering is said to be deterministic.
Other more likely conﬁgurations may be considered. that involve several independent, and hence in
the Gaussian case uncorrelated, scattering mechanisms occurring within each resolution cell:
k(l) =
Ns

n=1
kn(l)
E(kn(l)k†
m(l)) = Tnδn−m
⎫
⎪⎬
⎪⎭
⇒
T = E(kk†) =
Ns
"
n=1
Tn ̸= Srel.
(21.63)
In this very frequently encountered case, a coherency matrix cannot be related to a single relative
scattering matrix.
2.21.2.2.1.1
Concept of distributed coherency matrix
A coherency matrix is said to be distributed if it cannot be related to a single relative scattering matrix
[12]. This property may be revealed using various approaches. First one may consider the decomposition
of a coherency matrix onto its eigenvector basis:
T = VV† =
3
"
i=1
λiviv†
i
with V =
v1
v2
v3

,  = diag(λ1, λ2, λ3),
(21.64)

2.21.2 SAR Polarimetry Basics
1143
where V is composed or orthogonal eigenvectors, i.e.,V−1 = V†, and the real eigenvalues may be sorted
as λ1 ≥λ2 ≥λ3 ≥0. It is obvious in (21.64) that if T has a unitary rank, i.e., λ2 = λ3 = 0, then a
unique relative scattering matrix may be associated to λ1v1v†
1. For other conﬁgurations, a simpliﬁcation
of the eigenstructure in (21.64), i.e., a selection of dominant terms, may be a way to reconstruct a
representative equivalent deterministic polarimetric scattering mechanism.
The concept of Degrees of Freedom (DoF) may also be used to illustrated the concept of distributed
coherency matrix. A coherency matrix may be represented using normalized correlation coefﬁcients as
follows:
T =
⎡
⎣
√T11
0
0
0
√T22
0
0
0
√T33
⎤
⎦
⎡
⎣
1
ρ12
ρ13
ρ∗
12
1
ρ23
ρ∗
13
ρ∗
23
1
⎤
⎦
⎡
⎣
√T11
0
0
0
√T22
0
0
0
√T33
⎤
⎦.
(21.65)
A “pure” coherency matrix, i.e., composed of a single scattering mechanism, possesses the following
properties:
T = λ1v1v†
1
with |ρi j| = 1, ρ23 = ρ∗
12ρ13
⇒T ≡{T11, T22, T33, arg (ρ12), arg (ρ13)}
(21.66)
Then DoF(T) = 5 = DoF(Srel).
For a distributed matrix, a similar approach gives
T =
3
"
i=1
λiviv†
i
with |ρi j| ≤1, ρ23 = ρ23
⇒T ≡{T11, T22, T33, |ρ12|, |ρ13|, |ρ23|, arg (ρ12), arg (ρ13), arg (ρ23)}.
(21.67)
Then DoF(T) = 9 > DoF(Srel) = 5.
2.21.2.2.1.2
Types of polarimetric decomposition techniques
The main objective of polarimetric decomposition techniques is to characterize a polarimetric response
using one or a set of scattering mechanisms. Four main types of decompositions may be considered:
•
The coherent decomposition techniques: they operate over scattering matrices S in order to express
to express it as a combination of components corresponding to canonical scattering mechanisms.
Such an approach is valid only over deterministic environments whose response is not affected by
speckle. For distributed responses, coherent decomposition results may be meaningless.
•
The incoherent decompositions based on dichotomy: the objective is to rewrite a coherency matrix
under the form of a pure response plus a remaining term, T = T0 + Trem. This dichotomy is driven
by physical considerations.
•
The decompositions based on the eigenvector decomposition of T.
•
Those based on a scattering model that aim to identify speciﬁc full-rank scattering mechanisms
from T.

1144
CHAPTER 21 Radar Polarimetry Basics
2.21.2.2.2
Some eigenvector based decomposition technique
An important class of decomposition techniques is based on the eigenvector decomposition of the
coherency matrix recalled hereafter:
T = VV† =
3
"
i=1
λiviv†
i
with V =
 v1
v2
v3

,  = diag(λ1, λ2, λ3),
(21.68)
where V is a SU(3) operator. The real eigenvalues may be sorted as λ1 ≥λ2 ≥λ3 ≥0 and are
independent of the polarization basis used to represent T. The decomposition leads to three scattering
mechanisms, that are orthogonal and hence uncorrelated. The weight of each contribution of each
deterministic mechanism to the global distributed scattering is speciﬁed by the eigenvalue λi, whereas
the type of scattering is related to the unitary eigenvector vi. If only one eigenvalue is nonzero then the
unitary rank coherency matrix T corresponds to a pure target and can be related to a single scattering
matrix. On the other hand, if all eigenvalues are equal, the coherency matrix is composed of three
orthogonal scattering mechanisms with equal amplitudes, the target is said to be random and there is no
correlated polarized structure at all. Between these two extremes, there exists the case of partial targets
where the coherency matrix has non-null and non-equal eigenvalues. The analysis of its polarimetric
properties requires a study of the eigenvalues distribution as well as a characterization of each scattering
mechanism of the expansion.
2.21.2.2.2.1
Cloude dominant scattering mechanism decomposition
Cloude was the ﬁrst to consider eigenvector-based decomposition [24], a well-known technique in signal
processing.Thedominantdominantscatteringmechanismisassociatedtotheeigenvectorcorresponding
to the largest eigenvalue
Srel ≡λ1v1 = k1.
(21.69)
The resulting target vector may be rewritten using Huynen parameters [6] as
k1 =
1
√2A0
⎡
⎣
2A0
C + j D
C −j D
⎤
⎦=
⎡
⎣
√2A0
√B0 + Be+ j atan(D/C)
√B0 −Be−j atan(G/H)
⎤
⎦.
(21.70)
This polarimetric parametrization of the target vector k1 involves the ﬁt of a combination of three
simple scattering mechanisms: surface scattering, dihedral scattering and volume scattering, which are
characterized from the three components of the target vector such as:
•
Surface scattering: A0 ≫B0 + B, B0 −B.
•
Dihedral scattering: B0 + B ≫A0, B0 −B.
•
Volume scattering: B0 −B ≫A0, B0 + B.
The polarimetric color-coded images built using the ﬁrst eigenvector only is displayed in Figure 21.12
and is compared to the original Pauli basis image.

2.21.2 SAR Polarimetry Basics
1145
(a)
(b)
|HH+VV|
|HH–VV|
|HV|
FIGURE 21.12
Polarimetric color-coded images in the Pauli basis (a) after Cloude decomposition (b) original image.
2.21.2.2.2.2
The H/A/¯α decomposition
Mean scattering mechanism. The dominant scattering mechanism approach mentioned above remains
valid when λ1 ≫λ2, λ3, but may lead to a signiﬁcant loss of information when the importance secondary
mechanisms cannot be neglected. An alternative technique has been proposed for extracting average
parameters that is based on a particular parametrization of the eigenvectors and that account for the
magnitude (eigenvalue) of each scattering mechanism (eigenvector) in order to deﬁne an average pure
scattering mechanism [12,13].
Each unitary eigenvector of T is parametrized using four angular parameters and an arbitrary absolute
phase:
vi = e jφi 
cos αi
sin αi cos βie jδi
sin αi sin βie jγi T .
(21.71)
The eigenvector matrix may then be written as:
V =
⎡
⎣
cos α1e jφ1
cos α2e jφ2
cos α3e jφ3
sin α1 cos β1e j(δ1+φ1)
sin α2 cos β2e j(δ2+φ2)
sin α3 cos β3e j(δ3+φ3)
sin α1 sin β1e j(γ1+φ1)
sin α2 sin β2e j(γ2+φ2)
sin α3 sin β3e j(γ3+φ3)
⎤
⎦.
(21.72)
The parametrization of a V matrix is made so as to enable a probabilistic interpretation of the
scattering process. Considering the eigenvector decomposition as a statistical model of the polarimetric
response under the form of a 3 symbol Bernoulli process i.e., the response is modeled as the sum of three
uncorrelated S matrices, represented by the columns of the V matrix, occurringwithpseudo-probabilities

1146
CHAPTER 21 Radar Polarimetry Basics
pi, given by:
pi =
λi
3
i=1 λi
=
λi
Span
with
3
"
i=1
pi = 1,
(21.73)
i.e., pi represents the fraction of the Span that weights the ith scattering mechanism. The mean pure
scattering mechanism is extracted under the form of unitary target vector v0 , made of mean scattering
parameters:
v0 = e jφ
⎡
⎣
cos ¯α
sin ¯α cos ¯βe j ¯δ
sin ¯α sin ¯βe j ¯γ
⎤
⎦,
(21.74)
where φ is physically equivalent to an absolute phase and where mean parameters are obtained as:
¯α =
3
"
i=1
Piαi, ¯β =
3
"
i=1
Piβi, ¯δ =
3
"
i=1
Piδi, ¯γ =
3
"
i=1
Piγi.
(21.75)
A mean target vector is the deﬁned as [12,13]:
k0 =

¯λv0 =

¯λ e jφ
⎡
⎣
cos ¯α
sin ¯α cos ¯βe j ¯δ
sin ¯α sin ¯βe j ¯γ
⎤
⎦,
(21.76)
where the parameter ¯λ corresponds to the mean target power (Span) and is deﬁned by:
¯λ =
3
"
i=1
piλi.
(21.77)
The reconstructed mean scattering mechanism may then be associated to a unique scattering matrix
and in order to be characterized. The polarimetric color-coded images built using the mean parameters
is displayed in Figure 21.13 and is compared to the original Pauli basis image.
Decomposition parameters. The decomposition parameters are related to underlying physical scattering
mechanisms and hence may be used to associate observables with physical properties of the medium.
The parameter ¯α is roll invariant, i.e., remains constant under any rotation around the radar line of sight,
and is an indicator of the nature of the scattering mechanism [12]. The three others parameters ( ¯β, ¯γ ,
and ¯δ) can be used to deﬁne the orientation of the observed object [18].
The useful range of the parameter ¯α corresponds to a continuous change from surface scattering
in the geometrical optics limit ¯α = 0◦through surface scattering under physical optics to the Bragg
surface model, encompassing dipole scattering or single scattering by a cloud of anisotropic particles
¯α = 45◦, moving into double bounce scattering mechanisms between two dielectric surfaces and ﬁnally
reaching dihedral scatter from metallic surfaces ¯α = 90◦.

2.21.2 SAR Polarimetry Basics
1147
(a)
(b)
|HH+VV|
|HH–VV|
|HV|
FIGURE 21.13
Polarimetric color-coded images in the Pauli basis (a) after reconstruction of a mean scattering mechanism
(b) original image.
The image in Figure 21.14 shows that the ¯α parameter is related directly to underlying average
physical scattering mechanism, and hence may be used to associate observables with physical properties
of the medium. Low value occurs over the ocean region, indicative of dominant single scattering ¯α = 0◦.
Urban area and parkland areas consist of medium and high parameter values (45◦< ¯α < 90◦).
The set of eigenvalues can be completely deﬁned by the Span (sum of the eigenvalues) and two
parameters: the polarimetric entropy, which an indicator of the randomness of the polarimetric scatter-
ing phenomenon and the anisotropy, that indicates the relative importance of secondary mechanisms.
It was shown previously that for a unitary rank coherency matrix, i.e., λ2 = λ3 = 0, the scattering
is deterministic and T may be associated to a single scattering matrix, whereas if all eigenvalues are
identical (λ1 = λ2 = λ3) then the averaged coherency T3 matrix represents a completely uncorrelated,
non-polarized random scattering structure. In between these two extreme behaviors, the case of dis-
tributed or partially polarized scatterers prevails. In order to deﬁne the degree of statistical disorder of
each distinct scatter type within the ensemble, the polarimetric entropy H, provides an efﬁcient and
suitable basis-invariant parameter, and is given by [12,13]:
H = −
N
"
i=1
pi log3 (pi) with 0 ≤H ≤1.
(21.78)
For a low entropy value, H < 0.3, then the observed medium may be considered as weakly depolarizing
and the dominant scattering mechanism may be recovered, using the eigenvector corresponding to the
largest eigenvalue, and the other components may be neglected. However, if the entropy is high, this

1148
CHAPTER 21 Radar Polarimetry Basics
FIGURE 21.14
H/A/α decomposition parameters (a) original Pauli image, (b) ¯α, (c) H, (d) A.
approximation is not valid anymore and a mean scattering mechanism may be extracted. When H = 1, T
is proportional to the identity matrix, the polarization information is a white noise process.
The image in Figure 21.14 shows that low entropy scattering occurs over the ocean (scattering by a
slightly rough surface). High entropy occurs over the parkland areas. At this resolution, the urban area

2.21.2 SAR Polarimetry Basics
1149
consists of a mixture of low and high entropy processes, which are due to the different street/building
classes that are aligned along the radar look direction, or aligned somewhat off bore sight, or 45◦aligned.
Another eigenvalue parameter, deﬁned as the polarimetric anisotropy A can be introduced to com-
pletely describe the set of eigenvalues [18]:
A = λ2 −λ3
λ2 + λ3
with 0 ≤A ≤1.
(21.79)
The polarimetric anisotropy A, shown in Figure 21.14, is complementary to the polarimetric entropy H
and measures the relative importance of the second and the third eigenvalues of the eigendecomposition.
From a practical point of view, the anisotropy A can be employed as a source of discrimination mainly
when H > 0.7. The reason is that for lower entropy values, the second and third eigenvalues are
highly affected by noise. Consequently, the anisotropy A is also very noisy. Inherent of the spatial
averaging, however, the entropy H increases, and the number of distinguishable classes identiﬁable
from polarimetric observations reduces. As example, an entropy H = 0.9 can correspond to two limit
types of scattering process with associated eigenvalues spectra given by (λ1 = 1, λ2 = 0.4, λ3 = 0.3)
and (λ1 = 1, λ2 = 1, λ3 = 0.3).
2.21.2.2.3
The model based Freeman-Durden decomposition
The Freeman-Durden decomposition [9] is a technique for ﬁtting a physically based three-component
scattering mechanism model to polarimetric SAR observations. The involved mechanisms are volu-
metric scattering from a cloud of randomly oriented dipoles, even- or double-bounce reﬂection from a
pair of orthogonal surfaces with different dielectric constants, and surface scattering from a moderately
rough surface. This composite scattering model is used to describe the polarimetric backscattering of
natural environments.
The ﬁrst component of the Freeman-Durden decomposition consists of a slightly rough surface
scattering response modeled as:
S =
 Rhh
0
0
Rvv

⇒
Cs = fs
⎡
⎣
|β|2
0 β
0
0
0
β∗
0
1
⎤
⎦
with
fs = |Rvv|2, β = Rhh
Rvv
,
(21.80)
where the reﬂection coefﬁcients depend on the chosen scattering model.
The double-bounce scattering component, representing successive reﬂections on a ground and on a tree
trunk for instance, is modeled as:
S =
 e j2γhh RThh RGhh
0
0
e j2γvv RTvv RGvv

⇒
Cd = fd
⎡
⎣
|α|2
0 α
0
0
0
α∗
0
1
⎤
⎦
with
fd = |RTvv RGvv|2, α = e j2(γhh−γvv) RThh RGhh
RTvv RGvv
,
(21.81)

1150
CHAPTER 21 Radar Polarimetry Basics
where RT and RG represent forward reﬂection coefﬁcient on the trunk and ground, respectively, and
the exponential terms account for path propagation effects. The volume scattering from a forest canopy
is modeled as the contribution from a cloud of randomly oriented cylinder-like scatterers.
S =
a
0
0
b

⇒
Cv =
lim
a or b→0
1
2π
 2π
0
UC(φ)
⎡
⎣
|a|2
0 ab∗
0
0
0
a∗b
0 |b|2
⎤
⎦U†
C(φ)dφ
⇒Cv = fv
8
⎡
⎣
3 0 1
0 2 0
1 0 3
⎤
⎦,
(21.82)
where fv corresponds to the contribution of the volume scattering component. Assuming that the
volume, double-bounce, and surface scatter components are uncorrelated, the total second-order statis-
tics are the sum of the above statistics for the individual mechanisms. Thus, the model for the total
backscattering is:
C = Cs + Cd + Cv =
⎡
⎢⎣
fs|β|2 + fd|α|2 + 3 fv
8
0
fsβ + fdα + fv
8
0
fv
4
0
fsβ∗+ fdα∗+ fv
8
0
fs2 + fd + 3 fv
8
⎤
⎥⎦.
(21.83)
This model gives four equations in ﬁve unknowns. However, after having subtracted the volume contri-
bution, a test on the sign of the real part of E(ShhS∗
vv) may be used to determine which of the single and
double bounce contributions is the dominant. If this term is positive, surface scattering is considered
as dominant and the parameter α is set to −1, whereas β is set to +1 otherwise. The Freeman-Durden
decomposition is illustrated in Figure 21.15. The Freeman-Durden model-ﬁtting approach is based
on physical considerations and not purely on mathematical concepts. Nevertheless it presents some
limitations:
•
Reﬂection symmetry is assumed, i.e., co- and cross-polarization channels are assumed to be uncor-
related.
•
Single and double bounce reﬂections cannot be fully estimated simultaneously, i.e., some of their
parameters are ﬁxed
2.21.2.3 A simple polarimetric classiﬁcation scheme
2.21.2.3.1
Unsupervised classiﬁcation in the 3-D H/A/ ¯α space
2.21.2.3.1.1
H/¯α classiﬁcation
In 1997, Cloude and Pottier [13] proposed an unsupervised classiﬁcation scheme based on the use of
the two-dimensional H/¯α plane, where all random scattering mechanisms can be represented. The key
idea is that entropy arises as a natural measure of the inherent reversibility of the scattering data and
that the ¯α angle can be used to identify the underlying average scattering mechanisms. The H/¯α plane
is sub-divided into nine basic zones characteristic of classes of different scattering behavior, in order
to separate the data into basic scattering mechanisms, as shown in Figure 21.16. The location of the
boundaries within the feasible combinations of H and ¯α values is set based on the general properties
of the scattering mechanisms. There is of course some degree of arbitrariness on the setting of these

2.21.2 SAR Polarimetry Basics
1151
(a)
(b)
|HH+VV|
|HH–VV|
|HV|
s
P
v
P
d
P
FIGURE 21.15
Polarimetric color-coded images (a) after the Freeman-Durden decomposition (b) original image in the Pauli
basis.
FIGURE 21.16
H/¯α segmentation plane.

1152
CHAPTER 21 Radar Polarimetry Basics
boundaries which are not dependent on a particular data set. In Figure 21.16, nine zones are speciﬁed,
related to speciﬁc scattering characteristics that can be measured via the coherency T3 matrix:
•
Zone 9: Low Entropy Surface Scatter
In this zone occur low entropy scattering processes with ¯α values less than 42.5◦. These include GO
(Geometrical Optics) and PO (Physical Optics) surface scattering—Physical surfaces such as water
at L and P-Bands, sea-ice at L-Band, as well as very smooth land surfaces, all fall into this category.
•
Zone 8: Low Entropy Dipole Scattering
In this zone occur strongly correlated mechanisms which have a large imbalance between SH H
and SV V in amplitude. An isolated dipole scatterer would appear here, as would scattering from
vegetation with strongly correlated orientation of anisotropic scattering elements. The width of this
zone is determined by the ability of the Radar to measure the SH H/SV V ratio i.e., on the quality of
the calibration.
•
Zone 7: Low Entropy Multiple Scattering Events
This zone corresponds to low entropy double, or even, bounce scattering events, such as provided
by isolated dielectric and metallic dihedral scatterers. These are characterized by ¯α values superior
to 47.5◦.
•
Zone 6: Medium Entropy Surface Scatter
This zone reﬂects the increase in entropy H due to changes in surface roughness and due to canopy
propagation effects. In surface scattering theory the entropy H of low frequency theories like Bragg
scatter is zero. Likewise, the entropy of high frequency theories like GO is also zero. However,
in between these two extremes, there is an increase in entropy H due to the physics of secondary
wave propagation and scattering mechanisms. Thus as the roughness/correlation length of a surface
changes, its entropy H will increase. Further, a surface cover comprising oblate ellipsoidal scatterers
(leafs or disks for example) will generate an entropy 0.6 < H < 0.7.
•
Zone 5: Medium Entropy Vegetation Scattering
Here again we have moderate entropy H but with a dominant dipole type scattering mechanism. The
increased entropy H is due to a central statistical distribution of orientation angle. Such a zone would
include scattering from vegetated surfaces with anisotropic scatterers and moderate correlation of
scatterer orientations.
•
Zone 4: Medium Entropy Multiple Scattering
This zone accounts for dihedral scattering with moderate entropy H. This occurs for example in
forestry applications, where double bounce mechanisms occur at P and L bands following prop-
agation through a canopy. The effect of the canopy is to increase the entropy H of the scattering
process. This class is typical for urban areas, where dense packing of localized scattering centers can
generate moderate entropy H with low order multiple scattering dominant. The boundary between
zones 4, 5, 6, and 1, 2, 3, is set as H = 0.9. This is chosen on the basis of the upper limit for surface,
volume, and dihedral scattering before random distributions apply.
•
Zone 3: High Entropy Surface Scatter
This class is a non-feasible region in the H/¯α plane.
•
Zone 2: High Entropy Vegetation Scattering
Highentropyvolumescatteringariseswhen ¯α = 45◦and H > 0.9.Thiscanariseforsinglescattering
from a cloud of anisotropic needle like particles or from multiple scattering from a cloud of low

2.21.2 SAR Polarimetry Basics
1153
FIGURE 21.17
Classiﬁcation of the San Francisco bay image in the H/¯α plane (a) pixel density (b) classiﬁcation results.
loss symmetric particles. In both cases, however, the entropy H lies above 0.9, where the feasible
region of H/¯α plane is rapidly shrinking. Scattering from forest canopies lies in this region, as
does the scattering from some types of vegetated surfaces with random highly anisotropic scattering
elements. The extreme behavior in this class is random noise i.e., no polarization dependence, a
point which lies at the extreme right of Zone 2.
•
Zone 1: High Entropy Multiple Scattering
In the H > 0.9 region, it is still possible to distinguish double bounce mechanisms in a high entropy
environment. Again such mechanisms can be observed in forestry applications or over vegetation
having well developed branch and crown structure.
The distribution of the San Francisco Bay PolSAR data on the H/¯α plane is shown in Figure 21.17.
This segmentation of the H/¯α plane is offered merely to illustrate a simple unsupervised classiﬁ-
cation strategy and to emphasize the geometrical segmentation of physical scattering processes. The
corresponding result is shown in Figure 21.17. It is this key feature which makes this an unsupervised,
measurement-data-independent approach to the scatter feature classiﬁcation problem.
2.21.2.3.1.2
Including the polarimetric anisotropy A
Inherent of the spatial averaging, the entropy H may increase, and the number of distinguishable classes
identiﬁable from polarimetric observations is reduced. For example, the feasible region of the H/¯α plane
is rapidly shrinking for high values of entropy (H > 0.7), where parameter reaches the limited value
of 60◦.

1154
CHAPTER 21 Radar Polarimetry Basics
FIGURE 21.18
Pixel density in the H/A/¯α space over the San Francisco bay image.
This remark is conﬁrmed by the analysis of the distribution of the San Francisco Bay PolSAR data
in the extended and complemented three-dimensional H/A/¯α space, as shown in Figure 21.18. This
representation shows that it is possible to discriminate new classes using the anisotropy value.
For example, it is now possible to notice that there exists in the Low Entropy Surface Scattering area
(Z9) a second class associated with a high anisotropy value and which corresponds to the presence of
a second physical mechanism which is not negligible.
Identical remarks can be made concerning the Medium Entropy Vegetation Scattering area (Z5) and
the Medium Entropy Multiple Scattering area (Z4). Due to the spread of the PolSAR data along the
anisotropy axis, it is now possible to improve the capability to distinguish different types of scattering
process which have quite the same high entropy value:
•
High entropy and low anisotropy correspond to random scattering.
•
High entropy and high anisotropy correspond to the presence of two scattering mechanisms with
the same probability.
It is thus possible to sub-divide each plane of the H/A/¯α space into basic zones characteristic of
classes of different scattering behavior, in order to separate the data into basic scattering mechanisms.
There still exists some degree of arbitrariness on the setting of these boundaries which are not dependent
on a particular data set.

2.21.2 SAR Polarimetry Basics
1155
The corresponding result is shown in Figure 21.18 for each plane of the H/A/¯α space.
In order to extend the classiﬁcation scheme and to improve the capability to distinguish different
types of scattering process, it is proposed to use some combinations between entropy (H) and anisotropy
(A) information, as shown in Figure 21.19. The (.∗) operation represents the element by element
multiplication of two matrices.
The examination of the different ﬁgures corresponding to the different combinations between entropy
(H) and anisotropy (A) images leads to the following interesting remarks:
1. The (1−H)(1−A) image corresponds to the presence of a single dominant scattering process (low
entropy and low anisotropy with λ2 ≈λ3 ≈0).
2. The H(1 −A) image characterizes a random scattering process (high entropy and low anisotropy
with λ2 ≈λ3 ≈λ1).
3. The H A image relates to the presence of two scattering mechanisms with the same probability (high
entropy and high anisotropy with λ3 ≈0).
4. The (1 −H)A image corresponds to the presence of two scattering mechanisms with a dominant
process (low to medium entropy) and a second one with medium probability (high anisotropy with
λ3 ≈0).
From the analysis of the different images shown in Figure 21.20 and from the distribution of the
San Francisco Bay PolSAR data in the H/A/¯α classiﬁcation space shown in Figure 21.18, it can be
concluded that these three parameters have to be considered now as key parameters in the polarimetric
analysis and/or inversion of PolSAR data.
The information contained in these three roll-invariant parameters extracted from the local estimate
of the coherency T matrix, corresponds to the type of scattering process which occurs within the pixel to
be classiﬁed (combination of entropy H and anisotropy A) and to the corresponding physical scattering
mechanism (¯α parameter).
2.21.2.3.2
Unsupervised statistical segmentation using Wishart statistics
2.21.2.3.2.1
Principles of the k-mean segmentation technique
The segmentation of a SAR image over a ﬁxed number of clusters aims to assign, in an optimal way, a
SAR image pixel, p, to one of the M possible clusters, {C1, . . . , CM} according to a SAR observable, x.
A solution is provided by Bayes optimal decision rule using the a posteriori probability of the different
clusters
Decide p ∈Ci if P(Ci|x) > P(C j|x) ∀j ̸= i.
(21.84)
A pixel is assigned to the most probable cluster conditionally to the observation of x over the pixel under
consideration. The risk, or probability of error, related to this decision is obtained from the a posteriori
probabilities of the unselected clusters:
P(error|x) =
"
j̸=i
P(C j|x).
(21.85)

1156
CHAPTER 21 Radar Polarimetry Basics
FIGURE 21.19
Classiﬁcation results in the (a) H/¯α (b) H/A (c) A/¯α planes over the San Francisco bay image.
It is obvious, that assigning a pixel to the cluster with the highest a posteriori probability minimizes the
conditional error probability. The total error probability is then computed using
P(error) =

P(error|x) fx(x)dx.
(21.86)
The set of a posteriori probabilities generally being uneasy to derive, one prefers then to express such
quantities using the Bayes rule
P(Ci|x) fx(x) = fx(x|Ci)P(Ci),
(21.87)
where fx(x|Ci) is the likelihood of cluster Ci with respect to x. Inserting this expression in (21.84), the
expression of the optimal decision rule becomes
Decide p ∈Ci if fx(x|Ci)P(Ci) > fx(x|C j)P(C j) ∀j ̸= i.
(21.88)

2.21.2 SAR Polarimetry Basics
1157
FIGURE 21.20
H and A combinations.

1158
CHAPTER 21 Radar Polarimetry Basics
Additionally, if the prior probabilities are unknown, or supposed to be equal, (21.88) may written as a
maximum likelihood decision rule:
Decide p ∈Ci if fx(x|Ci) > fx(x|C j) ∀j ̸= i.
(21.89)
The likelihood of a cluster, fx(x|Ci), can be estimated from the statistical parameters of the samples
it contains, and an optimal solution to the unsupervised segmentation problem consists in distributing
the pixels of an image over the set of M clusters so as to maximize the global likelihood deﬁned as
the product of all individual likelihood functions. A rigorous resolution requires to test all the possible
combinations and to select the one corresponding to the maximum joint likelihood value. This optimal
solution cannot be applied due to the unrealistic computational load it involves. Alternative solutions
based on sub-optimal iterative optimization procedures are generally preferred. The k-means procedure
is an iterative optimization algorithm described by the synopsis of Figure 21.21. The algorithms begins
with the initialization of the image pixel distribution over the N clusters. This distribution may be
done in a random way or according to user speciﬁcations. Once all pixels are assigned, the different
cluster centers are computed according to the processed data type. Each pixel is then assigned to the
closest cluster according to a distance measure. The convergence of the algorithm is then tested using
stability metrics. If a termination criterion is met, the segmentation stops, otherwise a new iteration
starts over from the class center computation step. The k-means algorithm aims to optimize a global
function by iteratively optimizing local expressions. It is known that this type of techniques may get
stuck into locally stable states and fail to determine the optimal pixel distribution. The initialization of
FIGURE 21.21
Synopsis of the k-means algorithm.

2.21.2 SAR Polarimetry Basics
1159
the pixel distribution into N classes is then a critical stage of such a segmentation algorithm. An adequate
initialization permits a fast convergence and provides correctly segmented clusters. The convergence
of the algorithm is evaluated by testing a condition of termination, that may be based on an estimate of
the classiﬁcation quality, or consist in a maximum number of iterations or in a sufﬁciently low number
of pixels that are differently classiﬁed from one iteration to the other.
2.21.2.3.2.2
Unsupervised H/A/¯α segmentation
The k-means clustering algorithm may be adapted to the segmentation of T or C polarimetric represen-
tations using the Wishart pdf of L-look sample matrix estimates expressed in (21.54):
fT(T|Ti) = L3L|T|L−2
˜2(L)|Ti|L e−Ltr(T−1
i
T)
(21.90)
with
T = 1
L
L
"
l=1
k(l)k(l)†
and Ti = 1
Ni
Ni
"
n=1
T(n) ∈Ci.
(21.91)
The ML decision rule may be simpliﬁed as:
fT(T|Ti) > fT(T|T j)
≡
d(T, Ti) < d(T, T j)
(21.92)
with d(T, Ti) a statistical proximity, and not distance, between the sample matrix T and the estimate
of the class center coherency matrix Ti, deﬁned as
d(T, Ti) = log |Ti| + tr(T−1
i T).
(21.93)
The particularity of the identiﬁcation procedure based on H and ¯α, introduced earlier, resides in the esti-
mation of the type of observed media from a physical interpretation of canonical scattering mechanisms
using robust indicators. Nevertheless, the analysis of natural scenes using this unsupervised approach
may reach some limitations:
•
The arbitrarily ﬁxed linear decision boundaries in the H −¯α plane may not ﬁt data distribution. A
natural cluster corresponding to similar targets may lie across a frontier in the decision plane. In this
case, pixels with very similar characteristics may be assigned, in an almost random way, to different
classes due slightly different locations in the H −¯α.
•
Even if the computation of H and ¯α requires fully polarimetric data, these two parameters do not
represent the whole polarimetric information. The use of other indicators such as the Span or speciﬁc
correlations coefﬁcients may improve the classiﬁcation results in a signiﬁcant way.
Segmentation procedures based on the whole coherency matrix statistics permit to overcome the lim-
itations mentioned above. Nevertheless, it is shown in the following, that the physical interpretation
of the scattering phenomenon permits to enhance in a signiﬁcant way the performance of statistical
segmentation schemes. The unsupervised segmentation scheme mentioned above is initialized in an
efﬁcient way with the results of the unsupervised identiﬁcation of a scattering mechanism, using H
and ¯α. This initialization provides 8 stable initial clusters relating to the underlying physical scattering

1160
CHAPTER 21 Radar Polarimetry Basics
C1
C2
C3
C4
C5
C6
C7
C8
||HH+VV|
|HH–VV|
|HV|
FIGURE 21.22
Wishart H −¯α segmentation results into eight classes.
+
→
>
X
X
⇒
⇒
α
FIGURE 21.23
Synopsis of the H −A −¯α segmentation.

2.21.2 SAR Polarimetry Basics
1161
mechanisms. An important improvement in the segmentation accuracy can be observed in the image
presented in Figure 21.22. The main kinds of natural media are clearly discriminated by the Wishart H/¯α
segmentation scheme. This unsupervised classiﬁcation algorithm modiﬁes the decision boundaries in
an adaptive way to better ﬁt the natural distribution of the scattering mechanisms and takes into account
information related to the back-scattered power. The ML Wishart segmentation may be further improved
by explicitly including the anisotropy information during the segmentation procedure. As mentioned
previously, the anisotropy indicates the relative importance of secondary mechanisms obtained from
the expansion of a coherency matrix. This polarimetric indicator is particularly useful to discriminate
scattering mechanisms with different eigenvalue distributions but with similar intermediate entropy
values. In such cases, a high anisotropy value indicates two dominant scattering mechanisms with
equal probability and a less signiﬁcant third mechanism, while a low anisotropy value corresponds
to a dominant ﬁrst scattering mechanism and two non-negligible secondary mechanisms with equal
importance. Among the different approaches tested, the best way to introduce the anisotropy information
in the classiﬁcation algorithm consists in implementing two successive segmentation procedures as
shown in Figure 21.23.
Polarimetric data are ﬁrst segmented according to the algorithm presented in the former paragraph.
Once this procedure has converged, the eight resulting clusters are split into 16 ones by comparing
the anisotropy of each pixel to a threshold ﬁxed to 0.5. The 16 segments are then used to initialize a
second Wishart ML segmentation procedure. The segmentation results presented in Figure 21.24 show
an enhanced description of the San Francisco scene. The introduction of the anisotropy in the clustering
C1
C9
C10
C11
C12
C13
C14
C15
C16
C2
C3
C4
C5
C6
C7
C8
|HH+VV|
|HH–VV|
|HV|
FIGURE 21.24
Wishart H −A −¯α segmentation results into 16 classes.

1162
CHAPTER 21 Radar Polarimetry Basics
process permits to split large segments into smaller clusters discriminating small disparities in a reﬁned
way. The Wishart H/A/¯α classiﬁcation scheme gathers into segments pixels with similar statistical
properties, but does not provide any information concerning the nature of the scattering mechanism
associated to each cluster.
2.21.3 Advanced polarimetric decomposition techniques and
some of their applications
2.21.3.1 Advanced decomposition techniques
2.21.3.1.1
The Yamaguchi 4-component decomposition
As seen previously, the 3-component scattering power model proposed by Freeman and Durden [9]
can be successfully applied to decompose SAR observations under the reﬂection symmetry condition.
However, it can be possible to ﬁnd some areas in a SAR image for which the reﬂection symmetry condi-
tion does not hold. Based on the 3-component scattering model approach, Yamaguchi et al. proposed a
4-component scattering model by introducing an additional term corresponding to non-reﬂection sym-
metric cases [25]. In order to accommodate the decomposition scheme for the more general scattering
case encountered in complicated geometric scattering structures, the fourth component introduced is
equivalent to a helix scattering power. This helix scattering power term, that corresponds to responses
having correlated co- and cross-polarization channels, and appears overs heterogeneous areas (compli-
cated shape targets or man-made structures) whereas it is quasi null over almost all natural environments.
The scattering matrices, corresponding to a left-helix target or to a right-helix target, have the form:
SL H = 1
2
 1
j
j
−1

and SRH = 1
2
 1
−j
−j
−1

(21.94)
and the corresponding covariance matrices are given by:
CL H = fc
4
⎡
⎣
1
−j
√
2
−1
j
√
2
2
−j
√
2
−1
j
√
2
−1
⎤
⎦
and SRH = fc
4
⎡
⎣
1
j
√
2
−1
−j
√
2
2
j
√
2
−1
−j
√
2
−1
⎤
⎦,
(21.95)
where fc corresponds to the contribution of the helix scattering component.
The second important contribution proposed by Yamaguchi et al. in the 4-component decomposi-
tion model approach, concerns the modiﬁcation of the volume scattering matrix in the decomposition
according to the relative backscattering magnitudes of E(|Shh|2) versus E(|Svv|2) [25]. In the theoretical
modeling of volume scattering, a cloud of randomly oriented dipoles is implemented with a probability
function being uniform for the orientation angles. However, for vegetated areas where vertical structure
seems to be rather dominant, the scattering from tree trunks and branches displays a non-uniform angle
distribution. The proposed new angle pdf is given by:
fφ(φ) = cos φ
2
for |θ| < π
2
and null otherwise.
(21.96)

2.21.3 Advanced Polarimetric Decomposition Techniques
1163
Assuming a cloud of randomly oriented, very thin horizontal cylinder-like scatterers, i.e., b →0 in
(21.82), the volume scattering covariance matrix is given by:
Cvh = fv
15
⎡
⎣
8 0 2
0 4 0
2 0 3
⎤
⎦.
(21.97)
Assuming now a cloud of randomly oriented, very thin vertical cylinder-like scatterers, i.e., a →0 in
(21.82), the volume scattering covariance matrix is given by:
Cvv = fv
15
⎡
⎣
3 0 2
0 4 0
2 0 8
⎤
⎦.
(21.98)
The asymmetric form of the two volume scattering covariance matrices is of considerable use since
it can be adjusted to the measured data according to the ratio C R = 10 log10 (E(|Shh|2)/E(|Svv|2)).
Depending on the scene co-polarization ratio, the appropriate volume scattering covariance matrix is
chosen according to the following rules
C R < −2d B ⇒Cvh,
−2d B ≤C R < +2d B ⇒CvFreeman,
(21.99)
+2d B ≤C R ⇒Cvv,
Assuming that the volume, double-bounce, surface, and helix scatter components are uncorrelated, the
total second-order statistics are the sum of the above statistics for the individual mechanisms. Thus, the
model for the total backscatter is:
C = Cs + Cd + Clh/rh + Cv
(21.100)
Figure 21.25 shows the algorithm for the four-component scattering power decomposition. The Yam-
aguchi decomposition is intended to apply to non-reﬂection symmetry case, the scheme automatically
includes the reﬂection symmetry condition, thus proposing a decomposition scheme for the more general
scattering case encountered in complicated geometric scattering structures. The Yamaguchi decompo-
sition is illustrated in Figure 21.26.
2.21.3.1.2
The Freeman 2-component decomposition
In 2007, Freeman has proposed a new and original 2-component scattering model to polarimetric SAR
observations of forests [26]. The selected mechanisms are canopy scatter from a reciprocal medium with
reﬂection symmetry and a ground scatter term representing either a double-bounce scatter from a pair
of orthogonal surfaces with different dielectric constants (ground-trunk interaction) or a Bragg scatter
from a moderately rough surface, which is seen through a layer of vertically oriented scatterers [26].
The volume scattering from a forest canopy is modeled as the contribution from a cloud of randomly
oriented cylinder-like scatterers. The second-order statistics covariance matrix Cv for scatterers from a

1164
CHAPTER 21 Radar Polarimetry Basics
FIGURE 21.25
Algorithm of the four-component decomposition (Courtesy of Prof. Yoshio Yamaguchi).
reciprocal medium with reﬂection symmetry is given by:
Cv = fv
⎡
⎣
1
0
ρ
0
1 −ρ
0
ρ
0
1
⎤
⎦,
(21.101)

2.21.3 Advanced Polarimetric Decomposition Techniques
1165
(a)
(b)
|HH+VV|
|HH–VV|
|HV|
Ps
v
P
d
P
FIGURE 21.26
Polarimetric color-coded images (a) after the Yamaguchi decomposition and (b) original image in the Pauli
basis.
where ρ ≤1. The second scattering mechanism, called ground, corresponds to double-bounce scattering
or surface scattering or a combination of both. The resulting covariance matrix is given by:
Cg = fg
⎡
⎣
1
0
α
0
0
0
α∗
0 |α|2
⎤
⎦.
(21.102)
The model for the total backscattering is:
C = Cg + Cv.
(21.103)
In contrast to the Freeman-Durden 3-component decomposition, the new Freeman 2-component decom-
position presents an equal number of input and output parameters and thus can be easily solved without
any a priori assumption [26]. The Freeman 2-component decomposition is illustrated in Figure 21.27.
2.21.3.1.3
A 2-Component decomposition with improved volume description
This decomposition, proposed in [27], is based on an improved description of volume scattering and is
included in a global Pol-inSAR (SAR polarimetric interferometry) characterization approach.
Similarly to the Freeman and Durden, Freeman II and Yamaguchi decompositions, a volume is
described as a cloud of anisotropic particles, whose scattering matrix is given as:
S = RT (ψ)
a
0
0
b

R(ψ) = ART (ψ)
 1 + δ∗
0
0
1 −δ∗

R(ψ),
(21.104)

1166
CHAPTER 21 Radar Polarimetry Basics
(a)
(b)
−40 dB
0 dB
FIGURE 21.27
Images of the span of the (a) Ground (b) Double Bounce contributions of the Freeman decomposition.
where R(ψ) is a SU(2) operator accounting for a rotation around the radar line of sight and δ is the
particle scattering anisotropy, deﬁned as:
δ =
a −b
a + b
∗
.
(21.105)
The particle orientation angles ψ in the polarization plane shown in Figure 21.28 are assumed to
follow a unimodal circular distribution and to be independent from other vegetation characteristics.
Under the central limit theorem condition, given a large number of scatterers, the orientations of these
scatterers are normally distributed and follow the circular normal distribution (also known as the von
Mises distribution) which is the circular analog of the Gaussian distribution
fψ(ψ) = eκ cos (2(ψ −˜ψ))
π I0(κ)
,
(21.106)
where κ is the degree of concentration, analogous to the inverse of the standard deviation, ˜ψ ∈
[−π/2, π/2], is the mean particle orientation angle, and I0() is the modiﬁed Bessel function of order 0.
For the sake of interpretation, the normalized degree of orientation randomness τ is introduced as
τ = I0(κ)e−κ.
(21.107)

2.21.3 Advanced Polarimetric Decomposition Techniques
1167
FIGURE 21.28
Particle orientation: mean orientation ˜ψ and the orientation of an individual particle ψ = ˜ψ + ψ.
FIGURE 21.29
Schematic representation of the effective shapes and orientations of particles in the LOS for different degrees
of particle scattering anisotropy δ and orientation randomness τ.
The physical meaning of δ and τ is illustrated on Figure 21.29
The particle scattering anisotropy, δ, characterizes the effective shape of the average particle in
dependence of the particle and background permittivities and tilt angle distribution [27]. Assuming

1168
CHAPTER 21 Radar Polarimetry Basics
simple spheroidal particles, one can relate δ to the effective particle shapes: As |δ| →0, the average
effective particle shape approaches an isotropic sphere/disk, whereas, as |δ| →1, the effective shape
tends toward a dipole. If the phases of the scattering coefﬁcients a and b are similar, then δ is a function
only of their moduli. Then, in the line-of-sight (LOS) direction, the particle axis of symmetry tends to
be horizontal if ℜ(δ) > 0 and vertical if ℜ(δ) < 0, with respect to the polarization basis of the particle
scattering amplitude matrix. As τ →0, the volume becomes strongly aligned in the preferred orientation
direction, whereas, for τ →1, the particle orientations become completely random. The degree of
orientation randomness becomes meaningless for (effectively) isotropic scatterers, i.e., when δ = 0.
The effective volume coherency matrix is the given by
Tv = R( ˜ψ)
 + π
2
−π
2
fψ(ψ)TvdψR(ψ)†
(21.108)
which may be rewritten as [27]
Tv = R( ˜ψ)
⎡
⎣
1
gcδ
0
gcδ∗
1+g
2 |δ|2
0
0
0
1−g
2 |δ|2
⎤
⎦R(ψ)†,
(21.109)
where g = I2(κ)/I0(κ) and gc = I1(κ)/I0(κ). The ground contribution is given by a general reﬂection
symmetric matrix
Tg =
⎡
⎣
1
β
0
β∗
β22
0
0
0
β33
⎤
⎦
(21.110)
and the global response is modeled as
T = fvTv + fgTg.
(21.111)
ThegeneralityofthisapproachcomparedtoFreemanandYamaguchionesandillustratedinFigure21.30
is related to the very high number of parameters used to describe the ground and volumes contributions.
Such an approach can be unambiguously applied, using the NNED approach [28] described in next
section, or when the volume and ground component can be separated using multiple polarimetric and
interferometric data sets for instance [27].
2.21.3.1.4
Another adaptive model-based decomposition
Similarly to the former approach, this decomposition technique, presented in [29], describes a natural
volume as a cloud of anisotropic scatterers. The distribution chosen to model the orientation of the
particles is a nth order squared cosine distribution:
fψ(ψ, ˜ψ, n) =
cos2n (ψ −˜ψ)
% 2π
0
cos2n (ψ −˜ψ)
.
(21.112)
As illustrated in Figure 21.31, such a function may be used to represent distributions ranging from
deterministic, with n →+∞, to uniform, n = 0 [29,30]. Similarly to the former decomposition, an

2.21.3 Advanced Polarimetric Decomposition Techniques
1169
FIGURE 21.30
Normalized volume coherency matrix elements (a) |T (1, 2)|, |T (2, 2)|, |T (3, 3)| as functions of the degree
of orientation randomness τ and the particle scattering anisotropy |δ|. The blue point, the red line, and the
green point correspond to the parameter ranges of the Freeman Durden, the Freeman II, and the Yamaguchi
models, respectively (For interpretation of the references to color in this ﬁgure legend, the reader is referred
to the web version of this book.).
FIGURE 21.31
Various pdfs in terms of randomness that can be modeled by a squared cosine distribution.
indicator of the degree of randomness of the particle orientation can be derived as:
τ(n) =
&
'
'
(π2
12 +
n−1
"
k=0
n!n!
k!(2n −k)!
( −1)n−k
n −k
.
(21.113)

1170
CHAPTER 21 Radar Polarimetry Basics
FIGURE 21.32
NASA/JPL AIRSAR L-band image over the Black Forest, dotted lines specify the direction of topographic
change. A urban area is outlined by the dotted circle. From [29].
Using fψ(ψ, ˜ψ, n),thecovariancematrixofananisotropicdipolewithmeanorientation ˜ψ isgivenby
Cv( ˜ψ, n) = Cα +
2n
n + 1Cβ(2 ˜ψ) +
n(n −1)
(n + 1)(n + 2)Cγ (4 ˜ψ),
(21.114)
where Cα is the volume component of the Freeman approach, and Cβ, Cγ are other constant matrices.
The global covariance matrix is composed of a set of canonical contributions
C = fvCv( ˜ψ, n) + fdCd + fsCs + Crem,
(21.115)
where Crem is a remaining element that account for terms that do not ﬁt the multi-component model
and Cd, Cs are identical to the corresponding terms of the Freeman decomposition. The parameters of
the volume component are then estimated using a Non Negative Eigenvalue Decomposition approach
[28]. For each set of parameters ( ˜ψ, n) under test, fv is estimated as the maximal real value so that
C′
rem = C −fvCv( ˜ψ, n) ≥0,
(21.116)
where C′
rem ≥0 means that C′
rem is positive semi deﬁnite, i.e., the eigenvalues of C′
rem are non-negative.
The optimal ( fv, ˜ψ, n) is the one for which the remaining polarimetric span tr(C′
rem) is minimal [29].
Single and double bounce contributions are then estimated for the optimal C′
rem matrix in (21.116). The
effectiveness of this approach is demonstrated on Figures 21.32–21.34, where the span of the global
remaining term Crem of (21.115) is used as an indicator of the quality of the decomposition.

2.21.3 Advanced Polarimetric Decomposition Techniques
1171
NNED (cos2)
NNED (unifrom)
Adaptive
−40 dB
0 dB
FIGURE 21.33
Span(Crem)/Span(C) (top) C-band, (middle) L-band, and (bottom) P-band. Results obtained using NNED and
two distributions: (Left) Cosine-squared and (center) uniform distributions. From [29].
2.21.3.1.5
An efﬁcient eigenvector based decomposition
The eigenvector based polarimetric decomposition technique proposed by Cloude and Pottier has been
widely used for remote sensing applications and tested over various kinds of scenes. The most used
parameters of the decomposition are those related to the set of eigenvalues, H and A, as well as ¯α,

1172
CHAPTER 21 Radar Polarimetry Basics
Volume
Double-bounce
Surface
0
1
FIGURE 21.34
Normalized (Left) Volume, (center) double-bounce, and (right) surface components for the (top) C-band,
(middle) L-band, and (bottom) P-band Black Forest images. Dotted lines in red specify (upper) river and
(lower) road. From [29] (For interpretation of the references to color in this ﬁgure legend, the reader is
referred to the web version of this book.).

2.21.3 Advanced Polarimetric Decomposition Techniques
1173
the indicator of the nature of polarimetric scattering. Nevertheless this approach reaches some
limitations [31]:
•
The deﬁnition of a mean equivalent scattering mechanism through the averaging of angular param-
eters may involve important biases, [32].
•
Among the four angular parameters used to describe an eigenvector, α is the only roll-invariant. As
a consequence all the remain parameters are affected by azimuthal rotations that might be induced
by the topography of a scene.
A new approach, presented in [31], proposes an original solutions to both limitations.
2.21.3.1.5.1
Target vector in the circular basis
Target vectors in the Pauli and circular bases are given by
kP = 1
2
⎡
⎣
Shh + Svv
Shh −Svv
2Shv
⎤
⎦
kC =
⎡
⎣
Sll
√
2Sll⊥
Sl⊥l⊥
⎤
⎦= 1
2
⎡
⎣
Shh −Svv + j2Shv
j
√
2(Shh + Svv)
Svv −Shh + j2Shv
⎤
⎦.
(21.117)
In the circular basis, a rotation around the radar line of sight may be represented as
kC(ψ) = R(ψ)kC
with R(ψ) =
⎡
⎣
e j2ψ
0
0
0
1
0
0
0 e j2ψ
⎤
⎦,
(21.118)
where R(ψ) is a SU(3) operator. This expression shows that, in the circular basis, azimuthal rotation
only affects symmetrically the phase of two elements, whereas it mixes up terms in the Pauli basis.
In the circular basis, any target vector may be represented using a set of 4 SU(3) operators [31]:
kC(ψ) = R(ψ)R(ϒ)R(βC)R(α)
⎡
⎣
1
0
0
⎤
⎦=
⎡
⎢⎣
sin (α) cos (βC)e j(−4
3 ϒ−2ψ)
cos (α)e j( 8
3 ϒ)
−sin (α) sin (βC)e j(−4
3 ϒ+2ψ)
⎤
⎥⎦,
(21.119)
where the parameters may be interpreted as follows [31]
•
ψ = arg ( −Sl⊥łperpS∗
ll)/4 measures the rotation around the LOS of the scattering vector in term of
the circular co-polarization phase difference. A disoriented scattering vector, i.e., whose parameters
do not depend on the azimuthal orientation, may be obtained by compensating ψ according to:
kCψ=0 = R( −ψ)kC(ψ).
(21.120)
•
ϒ = arg (kCψ=0(2)k1
Cψ=0(2))/4 is the phase difference between co- and cross-polarization channels
of kCψ=0. This parameters permits to discriminate anisotropic objects like dipoles and quarter waves.
It is worth noting that ϒ becomes becomes meaningless for α = 0 or π/2
•
α = αP is the original angle deﬁned by Cloude and Pottier [12].

1174
CHAPTER 21 Radar Polarimetry Basics
•
βC = acos(|kC(1)|/ sin (α)||kC||) ̸= βP, introduced by Corr and Rodrigues in 2002, is the degree
of imbalance between the co-polarized coefﬁcients of the circular polarization scattering vector
representing the scattering of left-right helices. Unlike βP, βC is ψ-invariant.
•
Hel = sin2 (α)( cos2 (βC) −cos2 (βC)) ∈[−1, 1], is the helicity parameter and corresponds to the
normalized energetic difference between circular co-polarized returns and may be used to estimate
the left-right degree of asymmetry of the target vector.
2.21.3.1.5.2
Parametrization using the exact number of degrees of freedom
The eigendecomposition of a coherency matrix is recalled here:
T = VV† =
3
"
i=1
λiviv†
i
with V =
v1
v2
v3

,  = diag(λ1, λ2, λ3).
(21.121)
The parametrization of an eigenvector proposed by Cloude and Pottier is:
vi = e jφi 
cos αi
sin αi cos βie jδi
sin αi sin βie jγi T .
(21.122)
Ignoring absolute phase terms, the Number of Parameters (NoP) of such a parametrization may be
compared to the number of Degrees of Freedom of a general coherency matrix:
NoP(V) = 4, NoP() = 3 ⇒NoP(VV†) = 15 and DoP(T) = 9.
(21.123)
In order to overcome this profusion of parameters, Cloude and Pottier proposed to average parameters.
Another approach is proposed in [31] that uses a minimal number of parameters. The polarimetric
covariance matrix in the circular basis may be expressed as:
CC = E(kCk†
C) = VCCV†
C.
(21.124)
Parametrizing the ﬁrst eigenvector as shown above, one obtains
vC1 =
⎡
⎢⎣
sin (α1) cos (βC1)e j(−4
3 ϒ1−2ψ1)
cos (α1)e j( 8
3 ϒ1)
−sin (α1) sin (βC1)e j(−4
3 ϒ1+2ψ1)
⎤
⎥⎦
(21.125)
which can be rewritten as
⎡
⎣
1
0
0
⎤
⎦= R4( −α1)R3( −βC1)R2( −ϒ1)R1( −ψ1)vC1 = R−1
1−4(ψ1, ϒ1, βC1, α1)vC1.
(21.126)
Using the orthogonality condition between the ﬁrst and second eigenvectors, one obtains
v†
C1vC2 = 0
⇒
⎡
⎣
0
a
b
⎤
⎦= R−1
1−4(ψ1, ϒ1, βC1, α1)vC2.
(21.127)

2.21.3 Advanced Polarimetric Decomposition Techniques
1175
The second eigenvector may then be described using only two additional parameters, ξ and ϵ
⎡
⎣
0
1
0
⎤
⎦= R−1
5−6(ξ, ϵ)R−1
1−4(ψ1, ϒ1, βC1, α1)uC2
(21.128)
and then, by deﬁnition
⎡
⎣
0
0
1
⎤
⎦= R−1
1−6(ψ1, ϒ1, βC1, α1, ξ, ϵ)uC3,
(21.129)
where [31]
•
ϵ = acos|a| = acos

cos α2
sin α1

measures the predictability of α2 knowing α1.
•
ξ = 1
4 arg (ab∗) describes the direction of the second and third eigenvectors in term of real rotation.
This may be more sensitive to the impact of noise and target ﬂuctuations.
The number of parameters needed to describe the eigendecomposition is given by:
NoP(vC1) = 4, NoP(vC2) = 2, NoP(vC3) = 0 ⇒NoP(VCCV†
C) = 9 = DoP(T).
(21.130)
This decomposition is applied to a C-band data set acquired by the DDRE EMISAR sensor. Images
of the main parameters are given on Figure 21.36 and compared to the usual H/A/¯α indicators in
Figure 21.35.
2.21.3.2 Advanced characterization of scattering mechanisms
2.21.3.2.1
Estimation of azimuthal orientation
Rotation around the radar line of sight plays an important role in SAR polarimetry. In a series of
publications, Lee and his colleagues [33–35] developed an original technique to estimate the azimuthal
component of the topography of scene using polarimetric SAR data, and applied it for characterizing
different natural environments. As it has been mentioned previously, the circular Right-Left polarimetric
basis is particularly adapted to the estimation of azimuthal rotation. The expressions of a target vector
in the circular basis, before and after rotation are recalled here:
krl =
⎡
⎣
Srr
√
2Srl
Sll
⎤
⎦= 1
2
⎡
⎣
Shh −Svv + j2Shv
j(Shh + Svv)
Svv −Shh + j2Shv
⎤
⎦krl(ψ) =
⎡
⎣
Srre−j2ψ
√
2Srl
Slle j2ψ
⎤
⎦.
(21.131)
The covariance matrix of the oriented vector, Crl = E(krl(ψ)k†
rl(ψ)), may be expressed as a function
of Crl = E(krlk†
rl) as
Crl(ψ) =
⎡
⎣
Crl(1, 1)
Crl(1, 2)e−j2ψ
Crl(1, 3)e−j4ψ
Crl(2, 1)e+ j2ψ
Crl(2, 2)
Crl(2, 3)e−j2ψ
Crl(3, 1)e+ j4ψ
Crl(3, 2)e+ j2ψ
Crl(3, 3)
⎤
⎦.
(21.132)

1176
CHAPTER 21 Radar Polarimetry Basics
FIGURE 21.35
Classic ψ-invariant H −A −¯α parameters characterizing the area around Nyborg port.
This expression shows that the rotation angle may be extracted from three coefﬁcients of Crl(ψ).
Unfortunately, the correlation terms Crl(1, 2), Crl(1, 3), Crl(2, 3) are in general complex, and unrelated
phase terms may signiﬁcantly perturb the estimation of ψ. However, horizontal natural environments
generally satisfy the hypothesis of reﬂection symmetry, i.e., E(ShhS∗
hv) = E(SvvS∗
hv) = 0. In such a
case, Crl(1, 3) ∈R, and ψ can be estimated from the argument of Crl(ψ)(1, 3) [34]. Figure 21.37

2.21.3 Advanced Polarimetric Decomposition Techniques
1177
FIGURE 21.36
Main parameters of the eigendecomposition proposed in [31].

1178
CHAPTER 21 Radar Polarimetry Basics
|HH+VV|, |HV|+|VH|, |HH+VV|
(a)
(b)
(c)
FIGURE 21.37
(a) polarization orientation angles over Camp Roberts, CA, USA at Land, (b) angle computed from a C band
DEM, (c) C band DEM. From [34].
compares azimuthal slopes estimated using a single polarimetric image at L band, to those derived from
a C band DEM.
A similar technique was applied to characterize current-induced sea topography at P band,
Figure 21.38.
2.21.3.2.2
A statistical segmentation that preserves scattering mechanisms
The statistical Wishart segmentation scheme mentioned previously permits to cluster into compact
groupspixelshavingsimilarstatisticalpolarimetricbehavior. Inpractice,thisclassiﬁerishighlysensitive

2.21.3 Advanced Polarimetric Decomposition Techniques
1179
NORTH
FLIGHT
RANGE
91
89
88
0
2
4
6
8
10
12
90
92
RIV cape
Hanlopen
ORIENTATION ANGLE - [Degress]
AZIMUTH DISTANCE - [km]
P - BAND POLARIMETRIC SAR CUNNENT- FRONT DETECTION
(a)
(b)
FIGURE 21.38
(a) Orientation angle image computed at P band over the Gulf stream (b) a proﬁle. From [33].
to the intensity driven polarimetric span [32,36]. In consequence, small variations of polarimetric
parameters between media having similar spans may be ignored pixels having different scattering
behaviors may be affected to the same class. In order to overcome this problem, a scattering mechanism
preserving segmentation [36] illustrated in Figure 21.39 can be applied.
Pixels are ﬁrst separated according to their scattering mechanism using the Freeman decomposi-
tion. each group is then separately segmented using a Wishart segmentation. Results are shown in
Figure 21.40.

1180
CHAPTER 21 Radar Polarimetry Basics
FIGURE 21.39
Synopsis of scattering mechanism preserving classiﬁer.

2.21.3 Advanced Polarimetric Decomposition Techniques
1181
FIGURE 21.40
Classiﬁcation results over San Francisco.
2.21.3.3 Characterization of soils using polarimetric decomposition techniques
Polarimetric scattering being highly sensitive to the geometry and electromagnetic properties of a
medium, polarimetric SAR data have been intensively used for estimating the moisture and roughness of
soils. Some of the techniques proposed in the literature are directly based on polarimetric decomposition
techniques.

1182
CHAPTER 21 Radar Polarimetry Basics
(a)
(b)
FIGURE 21.41
(a) H −¯α Entropy/Alpha (b) A −¯α diagrams for different local incidence angles and different values of ψ.

2.21.3 Advanced Polarimetric Decomposition Techniques
1183
2.21.3.4 A methods using H, A, and ¯α and the SPM model
This work, based on the H/A/¯α decomposition has been presented in [37] and is based on the use of
the Small Perturbation surface scattering Model (SPM) [38]. At order 1, this model permits to simulate
the polarimetric response of a slightly rough surface:
TSPM(kσ, W, θ, ϵ) = m2
s(kσ, W)T0(θ, ϵ),
(21.133)
where k stands for the carrier wavenumber, σ represents the standard of the rough surface heights, W
is the stationary surface spectrum, θ is the local angle of incidence, ϵ is the surface dielectric constant,
and T0 is a reﬂection symmetric coherency matrix. Due to the restriction of the model to the ﬁrst
order, roughness and dielectric properties can be easily separated, since roughness only affects the
polarimetric span whereas the rest of polarimetric information parameters, T0 in (21.133), depends on
the incidence angle and dielectric constant only. At order 1, the cross-polarization is null, E(|Shv|2) and
the co-polarization channel are perfectly correlated. As a consequence, the entropy of TSPM is very close
to 1 and does not ﬁt observations at L or C bands. In order to overcome this limitation, it is proposed in
[37] to introduce depolarization within the SPM model by artiﬁcially rotating TSPM around the radar
line of sight:
T(ψ) =
 + π
2
−π
2
R(ψ)TSPM(kσ, W, θ, ϵ)R†(ψ) fψ(ψ)dψ,
(21.134)
where fψ(ψ) is a uniform pdf centered around 0 and whose width equals ψ.
The eigendecomposition of Cloude and Pottier is then applied to T(ψ) to produce
H(ψ), ¯α(ψ), A(ψ). Simulated values presented in Figure 21.41 show that and H(ψ), ¯α(ψ)
may be used to estimate the dielectric constant, whereas the A(ψ) is not correlated with α. A look-up
table procedure is used in [37] to estimate ϵ as the value that minimizes the distance between measured
and simulated H, ¯α values, whereas an empirical relation, A = 1 −kσ, is used to estimate the surface
roughness. A polynomial relation mv = fpol(ϵ) is used to convert dielectric permittivity to volumetric
moisture content. Results obtained using L band acquisitions over two sites are given in Figure 21.42.
2.21.3.5 A method using reﬂection symmetry and the IEM model
Another technique, introduced in [39,40], proposes an alternative approach, based on the IEM surface
scattering model [41] and on the analytical computation of the eigenvalues on a reﬂection symmetric
coherency matrix:
2.21.3.5.1
The SERD and the DERD parameters
Two eigenvalue-based parameters, the Single bounce Eigenvalue Relative Difference (SERD) and the
Double bounce Eigenvalue Relative Difference (SERD) have been introduced in [39,40] to characterize
natural media. Both parameters are derived from the eigenvalues of a coherency T considering the
reﬂection symmetry hypothesis:
T = 1
2E
⎛
⎝
⎡
⎣
|Shh + Svv|2
(Shh + Svv(Shh −Svv)∗
0
(Shh −Svv)(SH H + Svv)∗
|Shh −Svv|2
0
0
0
4|Shh|2
⎤
⎦
⎞
⎠.
(21.135)

1184
CHAPTER 21 Radar Polarimetry Basics
(a)
(c)
(d)
(b)
FIGURE 21.42
Estimation results at L band (a) roughness without additive noise ﬁltering, (b) roughness with additive noise
ﬁltering, (c) dielectric constant (d) volumetric soil moisture content.
In such a case, it is possible to derive the analytical expressions of the corresponding unsorted (NOS)
eigenvalues given by [39,40]:
λ1NOS = E(|Shh|2 + |Svv|2) +

E(|Shh|2 −|Svv|2)2 + 4E(|ShhSvv∗|2)
2
,
λ2NOS = E(|Shh|2 + |Svv|2) −

E(|Shh|2 −|Svv|2)2 + 4E(|ShhSvv∗|2)
2
,
(21.136)
λ3NOS = 2E(|Shv|2).
The ﬁrst and second eigenvalues depend on the co-polarized backscattering coefﬁcients and on the
correlation between the vertical and horizontal channels (ρhhvv). In this case, the relation λ1NOS > λ2NOS

2.21.3 Advanced Polarimetric Decomposition Techniques
1185
always holds. The third eigenvalue corresponds to cross-polarized channel and is related to multiple
scattering for rough surfaces. One may remark that the entropy remains invariant against any permutation
within the set of eigenvalues.
In order to determine the scattering mechanisms, an analysis is led on the angles extracted from
the ﬁrst two eigenvectors u1 and u2, associated to λ1NOS and λ2NOS, respectively. The corresponding α
angles verify the following property
α1 + α2 = π
2
⇒
⎧
⎨
⎩
α1 ≤π
4 ⇔SB, α2 > π
4 ⇔DB
or
α1 > π
4 ⇔DB, α2 ≤π
4 ⇔SB,
(21.137)
where SB stands for Single Bounce reﬂection and DB for Double Bounce reﬂection. The two eigenvalue-
based parameters called the Single bounce Eigenvalue Relative Difference (SERD) and the Double
bounce Eigenvalue Relative Difference (SERD) are built up to compare the relative importance of the
different scattering mechanisms and are deﬁned as:
SERD = λS −λ3NOS
λS + λ3NOS
,
DERD = λD −λ3NOS
λD + λ3NOS
,
(21.138)
where λS and λD are the two eigenvalues respectively associated to the single bounce and to the double
bounce scattering mechanisms. Due to the lack of sorting, SERD and DERD, cover a wider range than
the anisotropy, SERD, DERD ∈[−1, 1], and are associated to speciﬁc scattering mechanisms.
The DERD parameter can be compared with the anisotropy A, whereas the SERD parameter reveals
useful with large entropy, in order to determine the nature and the importance of the different scattering
mechanisms.
2.21.3.5.2
Roughness and moisture retrieval
In order to characterize natural surfaces, the Integral Equation Model (IEM) is employed to derive a
polarimetric coherency matrix [39,40]. This model natural accounts for depolarization and produce
general reﬂection symmetric second order representations. Using this model, the DERD parameter can
be compared to the polarimetric anisotropy A that is usually employed as a surface roughness descriptor
[37]. Figure 21.43 shows, both parameters variations versus the roughness indicator kσ obtained using
the IEM model for various dielectric constants, ϵ, where k is radar wave number and σ is the surface
root mean square height.
The DERD parameter is similar to the anisotropy A for small roughness values, but presents a
different behavior for high frequencies. These parameters are very sensitive to surface roughness relative
to frequency, whereas the dependence on the dielectric constant ε is less signiﬁcant. For each dielectric
constant ε value, one anisotropy A value corresponds to two different values of kσ, thus introducing
an ambiguity for surface roughness extraction, whereas the DERD is strictly monotonic with kσ. An
important difference between these two parameters is that the dynamic range of the DERD parameter
is larger [−1; +1] than the anisotropy range [0; +1]. It follows that the DERD parameter has now to

1186
CHAPTER 21 Radar Polarimetry Basics
FIGURE 21.43
Values of A and DERD simulated using the IEM and various surface conditions.
FIGURE 21.44
Values of A and DERD obtained from data sets acquired by the JRC, for different roughness conditions.
be considered as a better surface roughness discriminator. Similar conclusions can be done on indoor
measurements realized at the European JRC laboratory [40] and depicted in Figure 21.44.
In order to avoid a bias on the mean ¯α [REF] that needs to be compensated using the entropy, only
αSB is used to retrieve ϵ by comparison with simulated αSBIEM values. Results obtained over the test
site of Alling are shown in Figure 21.45.

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1187
200
400
600
200
400
600
800
1000
1200
1400
1600
1800
2000
0
5
10
15
20
25
30
35
800
1000
200
400
600
800
1000
200
400
600
800
1000
1200
1400
1600
1800
2000
0
5
10
15
20
25
30
35
LOW ε values
High ε values
Ground truth measurements
Retrieved dielectric constant
FIGURE 21.45
Dielectric constant estimation results obtained over the Alling test site using data acquired at L band the
DLR ESAR sensor, Note that αIEM has been corrected by a constant over the whole image.
2.21.4 Selected topics in multidimensional polarimetric SAR
signal processing
2.21.4.1 Coherent Time-Frequency characterization of complex
polarimetric features
Conventional SAR image analysis and geophysical parameter retrieval techniques from strip-map (SAR)
datagenerallyassumethatscenesareformedofstaticscatterersobservedinthedirectionperpendicularto
the ﬂight track and at a ﬁxed frequency, equal to the emitted signal carrier’s one. When imaging complex
objects and media, potential variations of the signal measured during the SAR acquisition may strongly
affect feature estimates derived from the resulting SAR data and may lead to erroneous interpretations.
It is well known [42] that perturbations induced by the motion of a scatterer may highly modify its
SAR response in terms of reﬂectivity, spatial localization and focusing. Static objects with anisotropic
geometrical structures or having a frequency selective response may show a varying electromagnetic
behavior as they are illuminated from different positions or at different frequency components during
SAR integration. The resulting SAR response being well described by the spatial convolution of an
conventional scene SAR image with speciﬁc functions accounting for each effect, non ideal features
can be easily detected and characterized in the spectral domain.
Thissectionpresentsdifferenttechniquesfordetectingscatterershavingavaryingresponseduringthe
SAR acquisition and characterizing the underlying physical phenomenon that generates these variations.

1188
CHAPTER 21 Radar Polarimetry Basics
These approaches are based on speciﬁc coherent Time-Frequency (TF) decompositions that analyze the
response of scatterers by locally estimating the spectral content of their SAR response. These TF
techniques can be applied on already focused SAR images and not only on raw SAR signal, and were
designed in order to deal with already focused SAR images and not only raw SAR signals and to perform
a two-dimensional (2D) rangeazimuth coherent and revertible analysis, i.e., the original SAR image can
be reconstructed from local spectral estimates. A physical interpretation of the spectral decomposition
in the azimuth and range directions as well as the use of polarimetric SAR data permit to characterize
the backscattering properties complex media in a reﬁned way compared to classical techniques and
estimate some of their physical features.
2.21.4.1.1
Principles of coherent Time-Frequency analysis of SAR data
2.21.4.1.1.1
SAR image spectral content
As depicted in Figure 21.46, a SAR measurement consists in repeatedly emitting a signal, se(t), in the
across track direction and receiving the echo from the observed scene, sr(x, t), at different locations x
along the acquisition track. A scatterer P0 located at coordinates (x0, y0, 0) is observed for different val-
ues of the azimuth look angle,φ, deﬁned by tan (φ) = (x−x0)/d0(x), deﬁned d0(x) =

r2
0 + (x −x0)2
being the varying radar-scatterer distance. The range of the azimuth angle is deﬁned by the antenna
aperture, whereas the emitted signal is characterized by a bandpass spectrum centered around a carrier
frequency fc, with bandwidth B f .
FIGURE 21.46
Geometrical conﬁguration of a SAR acquisition. Repeated emission-reception of signals, with a rectangular
antenna aperture (left). Observation of a scatterer P0 from different positions along the acquisition track,
with corresponding azimuth look angles.

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1189
x^
^
r^
ω
ω
2π
a
ω
2π
r
ω
2π
λ
2 =
φ
wavefront
FIGURE 21.47
Decomposition of a plane wave propagating along ˆω into azimuth and range components. A spherical wave
may be represented as a sum of plane waves with varying azimuth orientation φ.
After base-band conversion, the received signal can be focused to produce a 2-D coherent image
in the azimuth-range domain, s(x,r), that represents a reconstruction of the coherent reﬂectivity of
the scene. Under simplifying assumptions and considering ideal acquisition conditions [21], a coherent
SAR image may be formulated as convolution of the scene coherent reﬂectivity, r(x,r) and the SAR
2-D impulse response, h(x,r) and may be represented in both spatial and spectral domains as:
s(x,r) = r(x,r) ⊗h(x,r) ≡S(ωa, ωr) = R(ωa, ωr)H(ωa, ωr),
(21.139)
where S(ωa, ωr) =
% +∞
−∞
% +∞
−∞s(x,r)e−jωax e−jωrr dx dr is the 2-D Fourier transform of the SAR
image s(x,r) and ⊗represents the convolution operator. The spectral coordinates (ωa, ωr), representing
two-way wavenumbers in range and azimuth, are illustrated in Figure 21.47 and can be formulated
as [43]:
ωa = ω sin φ,
ωr = ω cos φ −ωc,
(21.140)
where ω is the emitted signal wavenumber and can be related to the electrical frequency using, f ∈
fc +

−B f
2 , B f
2

, through the wave propagation velocity, c, as ω = 4π f
c .
For an ideal scene, whose reﬂectivity is uniformly distributed over the spectral domain, the resolutions
of the SAR image are driven by the impulse response of the SAR system and are given by
δx = 2π
ωa
=
c
4 fc sin (φ/2)
and δr = 2π
ωr
=
c
2B f
,
(21.141)
where φ stands for the processed azimuthal aperture, whose maximal value is set by the acquisition
antenna characteristics.
It is worth noting that the direct relation between a SAR image and the reﬂectivity of scene in
(21.139), as well as the physical meaning of the spectral coordinates in (21.140) are valid when dealing
with coherent Single Look Complex (SLC) SAR data sets, i.e., each pixel of the SAR image corresponds
to a complex number whose modulus is proportional to the focused reﬂectivity and whose absolute phase
depends on the observed medium as well as on the measurement phase history. Transforming an SLC

1190
CHAPTER 21 Radar Polarimetry Basics
image to an incoherent one, like an intensity image I(x,r) = |s(x,r)|2, involves an irremediable loss
of information and interpretation.
2.21.4.1.1.2
Time frequency decomposition
The T-F decompositions technique selected here is based on the use of a 2-D windowed Fourier trans-
form, or 2-D Gabor transform. This kind of transformation permits to decompose a two-dimensional
signal, s(l), with l = [x, y]T a 2-D location, into different spectral components, using a convolution
with an analyzing function g(l), as follows [44]:
s(l0; ω0) =

s(l)g(l −l0) exp (−jωT
0 (l −l0))dl,
(21.142)
where ω0 = [ωx, ωy]T indicates a position in frequency, and s(l0; ω0) represents the decomposition
result around the spatial and frequency locations l0 and ω0. The application of a Fourier transform to
(21.142) shows that the spectrum of s(l0; ω0) is given by the product of the original signal spectrum
and the transform of the analyzing function g shifted around the frequency vector ω0:
S(ω; ω0) = S(ω)G(ω −ω0).
(21.143)
It is clear from Eqs. (21.142) and (21.143) that this time frequency approach may be used to characterize,
in the spatial domain, behaviors corresponding to particular spectral components of the signal under
analysis, selected by the analyzing function g. Among the wide variety of existing TF analysis methods,
the simple atomic decomposition selected in this study presents some interesting properties. It is linear,
and hence preserves the coherence and energy of signals, it is not affected by artifacts related to cross-
terms and may be inverted, i.e., depending on the analyzing function g, s(l) may be reconstructed from
a set of TF samples s(l; ω0), provided that some sampling conditions in spatial and spectral domains are
satisﬁed. The resolutions of the analysis in space and frequency are not independent, and their product
is ﬁxed by the Heisenberg-Gabor uncertainty relation, given in 1-D by [44]
δl δω = ug.
(21.144)
This relation speciﬁes that the space-frequency resolution product equals a constant ug, determined
by g. An analyzing function with an excessively narrow spectral bandwidth would involve an excellent
spectral resolution but might then lead to a meaningless analysis in the space domain owing to a bad
localization, i.e., increasing the description ability of the analysis in one domain worsens its accuracy
in the dual one. The nature of the analyzing function is generally chosen so as to preserve resolution
while maintaining sufﬁciently low side-lobe amplitudes in the space domain.
2.21.4.1.1.3
Time-Frequency decomposition of SAR images
The timefrequency approach presented here deals with processed SAR images, denoted s(l) with l =
[x,r]T , rather than raw data. This type of data is better accessible to common users and is generally
processed through compensation procedures to reduce the effects of acquisition errors. In practice the
simple SAR image model given in (21.139) needs to be completed in order to account for additional
weighting terms, mainly due to the antenna pattern and side-lobe reduction functions, as [45]
S(ω) = R(ω)H(ω)W(ω)
(21.145)

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1191
FIGURE 21.48
Synopsis of the proposed Time-Frequency decomposition of a mono-dimensional.
with ω = [ωa, ωr]T . The synopsis of the TF decomposition based on the spectral deﬁnition on (21.143)
is given in Figure 21.48.
The ﬁrst step consists of correcting for potential spectral imbalances, represented by W(ω) in Eq.
(21.145), in the original, full-resolution SAR image. This can be achieved by calculating average image
spectra in range and azimuth and then multiplying the full-resolution spectrum S(ω) by the inverse
of the estimated 2-D weighting function. The TF decomposition is then conducted by multiplying the
corrected spectrum by the Fourier transform of the analyzing function and going back to the spatial
domain. The resulting still focused SAR image s(l; ω0) has a lower resolution than the original SAR
data and depicts the scene behavior over the 2D frequency domain located in the neighborhood of ω0.
As it might be observed in (21.145), the use of processed data limits the spectral exploration range to
the one of the reference function used for raw data processing and focusing. In order to emphasize the
physical interpretation of coherent SAR image analysis, one may simplify the wavenumber expressions
given in (21.140) using narrow beamwidth and bandwidth approximations
ωa ≈ωc sin φ,
ωr ≈ω −ωc.
(21.146)
Time-Frequency decomposition in the azimuth direction consists of deriving a set of images containing
different parts of the SAR Doppler spectrum with a reduced resolution, but corresponding to different
azimuth look angles. This kind of analysis can be applied to detect objects or media with anisotropic
behaviors, like scatterers with complex geometrical structures, human- made objects, or natural media
having periodic structures in the case of agricultural areas, or linear alignments of strong scatterers
[45]. In the range direction, TF analysis permits to compare the response of a scene observed at dif-
ferent frequencies, contained within the emitted signal spectral domain, and can be used to detect and
characterize media with frequency-sensitive responses, like resonating spherical or cylindrical objects,
periodic structures, or coupled scatterers with interfering characteristics.
Polarimetric SLC SAR images can be easily decomposed by applying the presented approach inde-
pendently over each polarization channel. Usual polarimetric representations may then be reconstructed

1192
CHAPTER 21 Radar Polarimetry Basics
to study the polarimetric behavior of a scene around speciﬁc spectral locations.
k(ω0) =
1
√
2
⎡
⎣
Shh(ω0) + Svv(ω0)
Shh(ω0) −Svv(ω0)
2Shv(ω0)
⎤
⎦
and T(ω0) = E[k(ω0)kH(ω0)],
(21.147)
where spatial locations, l, have been omitted.
2.21.4.1.2
Characterization of natural environments with non-stationary polarimetric
SAR responses
2.21.4.1.2.1
Discrimination of non-stationary POLSAR responses
Discrete Time-Frequency decomposition in range and azimuth. As shown in (21.147), the timefre-
quency decomposition can be applied around any frequency location inscribed within the rangeazimuth
frequency range deﬁned by the SAR transfer function H(ω). Nevertheless, it is often useful to ﬁrst
process the analysis around a limited (discrete) set of frequency locations to appreciate the global
behavior of the scene under observation and emphasize changes from one subspectral image to another
by minimizing their correlation, The polarimetric SAR data set under study has been acquired by the
DLR E-SAR sensor, at L band, over the Alling test site in Germany. The original image resolution is
2 m in range and 1 m in azimuth, corresponding to an azimuthal variation of the look angle of approx-
imately 7.5◦and a chirp bandwidth of 75 MHz. Figure 21.49 shows the full- resolution span image
corresponding to the total polarimetric backscattered power. The considered scene is mainly composed
of agricultural ﬁelds and forest. An urban area is located at the bottom left corner of the image.
range direction
azimuth direction
FIGURE 21.49
Full resolution span image of the Alling test site.

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1193
FIGURE 21.50
Polarimetric parameters at full resolution (center) and after 1-D TF analysis in the azimuth (left) and range
(right) directions.
The decomposition in the azimuth direction is performed using independent subspectra and keeping
the range resolution to its original value. Figure 21.50 shows results obtained over an area corresponding
to plowed ﬁelds. Images of the span, H, and α parameters are represented for different azimuthal look
angles and for the full-resolution case. It can be observed in Figure 21.50 that large variations in the
scattering mechanism nature, α, and degree of randomness, H, occur while the azimuth look angle
changes. For particular azimuth look angles, some ﬁelds show a sudden change of behavior: the span
reaches a maximum value, whereas the polarimetric indicators H and α are characterized by low values.
The stripes in the span image, indicating that coherent constructive and destructive interferences occur
within the pixels, are characteristic for Bragg resonant scattering over periodic surfaces [45].
Other types of media may also have nonstationary polarimetric features during the azimuthal inte-
gration. It was observed that some point targets and linear structures, such as diffracting edges or
road berms, have signiﬁcant backscattering pattern variations as the look angle changes. In particular,
metallic link fencing was found to present a scattering mechanism ranging from single-bounce up to
double-bounce scattering, depending on the SAR azimuthal look angle. In general, nonstationary targets
have strongly anisotropic shapes, or facets acting like directional scatterers, involving changes in the
underlying scattering mechanism and in the total backscattered power.

1194
CHAPTER 21 Radar Polarimetry Basics
In contrast, forested areas have a stationary behavior during the SAR integration. Backscattering
from forested areas at L band is known to be dominated by volume diffusion, which corresponds
to the scattering over randomly distributed anisotropic constituents. The coherent integration of the
randomly scattered waves leads to a response that is characterized by a high intensity and low degree
of polarization, but with isotropic behavior.
Detection of non-stationary polarimetric TF behaviors. Each pixel of the SAR scene is associated with a
set of R independent target vectors, k(ωi) with i = 1, . . . , R, derived from independent range-azimuth
subspectra, i.e., subspectra selected using non-overlapping functions G(ωi). Under the classical speckle
affected scattering hypothesis, these target vectors follow independent complex Gaussian multivariate
distributions, f (k(ωi)) = NC(0, i). The stationary aspect of the scattering behavior of each pixel
may then be studied by comparing the second order statistics of k(ωi) for different spectral locations,
i.e., by testing the following hypothesis:
H : 1 = · · · R = .
(21.148)
As it is shown in [46] this hypothesis can be tested easily using sample coherency matrices obtained
from ni independent realizations or looks of each TF target vector, k(ωi) :
Ti = 1
ni
ni
"
l=1
kl(ωi)kH
l (ωi)
f (Ti|i) = WC(ni, i).
(21.149)
The TF stationary behavior of k(ωi) is evaluated by means of a Maximum Likelihood (ML) ratio, ,
built from the R independent sample coherency matrices as follows:
 = max p(T1, . . . , TR|H true)
max p(T1, . . . , TR|H false) =
max p(T1|, . . . , TR|)
max1,...,R p(T1|1, . . . , TR|R).
(21.150)
Replacing the likelihoods in (21.150) by their expression and the expectations by their ML estimates,
on gets the following simple expression [45]
 =
,R
i=1 det (Ti)ni
det (Tt)nt
with Tt = 1
nt
R
"
i=1
niTi and nt =
R
"
i=1
ni.
(21.151)
The hypothesis is accepted and the pixel under test is considered to have a stationary polarimetric
TF behavior, with an arbitrarily chosen probability of false alarm Pf a, if  > cβ, where the relation
between the threshold value and the probability of false alarm, Pf a(cβ) = β, has been derived in [45].
The ML ratio and nonstationary pixel map shown in Figure 21.51 indicate that an important number of
pixels have a nonstationary behavior during the duration of the SAR acquisition. Most of the varying
scatterers belong to agricultural ﬁelds affected by Bragg resonance. Complex targets and diffracting
edges, whose scattering characteristics highly depend on the observation position, are discriminated
over built-up areas and linear alignment of scatterers.
The ML ratio based detection approach may be further developed to determine nonstationary scatter-
ing behavior position in the range Doppler spectrum by comparing the contributions of each subspectrum

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1195
FIGURE 21.51
Discrimination of non-stationary scatterers. Image of the ML ratio in log-scale (left), non-stationary pixel map
(right). Non stationary pixels are represented in white (For interpretation of the references to color in this
ﬁgure legend, the reader is referred to the web version of this book.).
FIGURE 21.52
Spectral location of the less stationary component among 12 range-azimuth subspectra for each nonstation-
ary pixel.
image in the global ML ratio information [45]. It can be observed from the localization results displayed
in Figure 21.52 on many ﬁelds affected by Bragg resonance that some groups of pixels, belonging to
the same ﬁeld, have a maximum anisotropic behavior in different subapertures. This is a consequence
of the sliding effects of Bragg resonance on periodic structures, that is described in the next section.

1196
CHAPTER 21 Radar Polarimetry Basics
FIGURE 21.53
Example of randomly perturbed periodic surface (left) and its associated backscattering coefﬁcient, at
L-band, with B = 10 cm, P = 1 m, ϵ = 9, and σh = 1 mm.
2.21.4.1.2.2
Analysis of Bragg resonant scattering over natural soils using a
polarimetric 2-D TF continuous decomposition
In the scene under examination, Bragg resonance over agricultural ﬁelds is an important source of polari-
metric variations. Bragg resonance is due to the coherent summation of simultaneously
constructive contributions from a set of scatterers and is likely to happen during the observation of
periodic surfaces or randomly irregular surfaces with a strong periodic component, as described in 1-D
in Figure 21.53 A random surface, h(x, y), with a quasi-periodic component in the y direction, can be
described as
h(x, y) = B cos
2π
P

+ ψ(x, y),
(21.152)
where P and B are the spatial period and amplitude, respectively, of the periodic component of h(x, y),
and the random perturbation term, ψ(x, y), corresponds to an isotropic stationary random rough surface.
This component is fully described by σh, the standard deviation of its zero mean Gaussian height
probability density function, and ϕψ , its correlation function. The Bragg resonance condition can be
written as a function of the incident wavelength, λ, as
ωy = n 2π
P
or
sin θ0 cos φ0 = nλ
2P ,
(21.153)
where ωy = ω sin θ0 corresponds to the local amplitude of the ground wave vector at the, n is an
unknown integer number indicating the mode of the resonance, θ0 is the local angle of incidence and
φ0 the azimuthal angular difference between the observation position and the normal to the rows of the
periodic surface. In the case of SAR measurements, φ0 can be decomposed as φ0 = φt + φ, where φt
represents the orientation of the surface with respect to the normal to the SAR platform ﬂight track,
and φ with the angle of observation in the azimuthal spectrum, as deﬁned in (21.140). Yueh et al.
[47] developed several approaches to model the scattering of electromagnetic waves from randomly

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1197
perturbed periodic surfaces. Their study reports that the inﬂuence of the resonating modes on the total
backscattering response varies signiﬁcantly with the surface parameters. As it can be seen in Figure
21.53, for a large surface correlation length, lc, and for low values of the azimuth orientation angle, φ0,
almost all the intensity peaks corresponding to different resonance modes can be discriminated. As lc
increases, the scattering pattern becomes smoother and only a few dominant resonance peaks can be
observed. In the presence of resonance, the co-polarization returns SH H and SV V have almost identical
values, characterized by a high intensity. As the resonant effect decreases, i.e., for high values of φ0, these
polarimetric channels have distinct responses, with a signiﬁcantly reduced amplitude. According to the
resonance condition enounced in (21.153) similar anisotropic ﬁelds with different locations in range,
θ0, or differently oriented, i.e., with different φt values may resonate at different azimuthal frequencies.
If the resonance conditions cannot be satisﬁed for any azimuthal angle within the antenna aperture or
if the surface scattering characteristics do not show a resonance peak, they also might not resonate at
all [48].
Moreover, some ﬁelds may have parts resonating at different positions in the azimuthal frequency
domain due to the joint dependence of the resonance condition on the incidence and azimuth angles, as
seen in (21.153). This phenomenon is illustrated in Figure 21.54, where the location of a resonance peak
is plotted as a function of the range and azimuth frequencies. As the azimuthal look angle, φ, varies, the
set of incidence angles θ0 satisfying Eq. (21.153) changes, leading to the apparition of sliding resonating
stripes in the ( frg, faz). The width of the resonating stripes is ﬁxed by the width of the analyzing function
in the azimuth and range directions, (gωr, gωa) or equivalently (g f , gφ).
A range-azimuth continuous Time-Frequency analysis is performed over three points (P1, P2, P3),
located at different range positions inside a plowed ﬁeld [48]. As depicted in Figure 21.55, results can
FIGURE 21.54
Location of resonance peaks in the (frg , faz) plane. The solid line indicates the location of a resonance peak
for a periodic surface characterized by P = 0.6 m and observed at L band. Gray areas indicate the location
of potential resonance areas for each range-azimuth sub-spectrum.

1198
CHAPTER 21 Radar Polarimetry Basics
FIGURE 21.55
Location of test points P1, P2, and P3 and range azimuth frequency representation plane (left) and repre-
sentation of polarimetric characteristics in this domain.
be represented, for each point, in the rangeazimuth frequency plane. The results of the timefrequency
analysis, as shown in Figure 21.55, demonstrate that all three points under investigation do not have
a stationary range and azimuth scattering behavior. Some (ωr, ωa) couples show high span values
corresponding to low H and α. These observations agree with the predictions of the scattering model
developed by Yueh et al. [47]. As the surface resonates, the co-polarization signals tend to be similar,
involving a low α value, typical for surface reﬂection. This scattering mechanism is weighted by a strong
intensity and dominates secondary intensities, potentially corresponding to multiple scattering terms,
and results in a very low entropy value. This nonstationary behavior was found to have a preponderant
inﬂuence on the polarimetric properties of resonating ﬁeld at full resolution. Here, α and H values are
signiﬁcantlylowerthanthoseforsimilarﬁeldsthatremainedunaffectedbyBraggresonance.Theoblique
resonating stripes, shown in the different range frequency planes in Figure 21.55, illustrate well the
dependence of the resonance condition on both range and azimuth frequencies, as shown in Figure 21.54.
It can also be observed that as the incidence angle increases, from P1 to P3, the oblique resonating
stripe slides from low azimuth frequencies to higher ones. This displacement of the resonance locations
is due to the dependence of the Bragg condition on the incidence angle and corroborates the analysis of
the Bragg resonance as presented in Figure 21.54. Polarimetric indicators of pixels that do not belong
to resonating stripes are unaffected by the Bragg resonance and have values similar to those observed
over stationary ﬁelds.
2.21.4.1.3
TF polarimetric characterization of speciﬁc scatterers
2.21.4.1.3.1
Detection of point-like scatterers using the Internal Hermitian Product
(IHP)
This approach, developed by Souyris et al. [49], was the ﬁrst of a series or works on coherent TF analysis
that fully exploit the physical nature of SAR signal together with polarimetric diversity. Its objective is to
assess the joint use of the magnitude and the phase of a SAR polarimetric image for point target detection

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1199
and analysis. The detection principle is based on the fact that scattering by point like scatterers is a
coherent process, i.e., during the SAR integration waves follow a specular path. Their T-F response, after
an adequate phase compensation should ideally be constant, in practice remain coherent. Over speckle
affected environments, scattering is due to wave diffusion by a large number of scatterers in a random and
spatially uncorrelated way. In consequence their spectral response should show a low level of correlation.
Single polarization IHP. A natural way to detect the presence of a correlated signal, i.e., a target,
embedded in uncorrelated noise, i.e., the clutter, is to compute the normalized correlation between two
samples:
ρTF =
E(s(ω1)s∗(ω2))

E(|s(ω1)|2)E(|s(ω2)|2)
.
(21.154)
In an ideal conﬁguration, s(ω) = t + c(ω), where t represents the ideally constant target response and
c(ω) the uncorrelated clutter contribution E(c(ω1)c(ω2)∗) if the samples originate from independent
spectra. In this case the TF normalized correlation writes
ρTF =
|t|2
|t|2 + σ 2c
=
1
1 + SCR−1
with SCR = |t|2
σ 2c
.
(21.155)
where it was assumed that the variance of the clutter response σ 2
c was constant over the spectral domain.
The correlation is than a function of the Signal to Clutter power Ratio (SCR), i.e., when a coherent
object with a strong responses is illuminated, it can be detected by thresholding |ρTF|. As reported in
[49], such an approach may lead to poor result if the SCR is not high enough and another approach is
proposed, based on the IHP, deﬁned as
IHP = E(s(ω1)s∗(ω2)).
(21.156)
It is simply the un-normalized correlation between two signal samples. As it is shown on Figure 21.56
this approach permits to improve the contrast between a target and its background. One may argue that
FIGURE 21.56
(a) original L-band SAR image acquired by the ONERA/RAMSES sensor at L band, (b) 2-look IHP image,
and (c) 3-D view of the upper part of the image, (d) 3-D view of the upper part of the IHP image. From [49].

1200
CHAPTER 21 Radar Polarimetry Basics
such an approach may be more associated to strong scatterer selection, based on their TF coherence
properties, rather than detection, since the amplitude IHP is not normalized.
Polarimetric IHP. The IHP concept is exported to the polarimetric case [49] using the deﬁnition of the
polarimetric correlation used in polarimetric SAR interferometry (POL-inSAR) [15]
IHP(w) = E(sw(ω1)s∗
w(ω2))
(21.157)
where sw(ω) = w†k(ω), k(ω) =

Shh(ω)
√
2Shv(ω)
Svv(ω)
T and w is a projection unitary vector
that permits to select one or a linear combination of polarization channels. This vector is then tuned
over the space of unitary 3-element complex vectors to ﬁnd the optimal value, ωopt, that maximizes
|IHP(w)|. The polarimetric properties of the target response are then given by kt = ωopt that may be
processed through classical decomposition techniques to obtain speciﬁc polarimetric indicators. An
example of application to polarimetric SAR data is given in Figure 21.57.
2.21.4.1.3.2
Detection of coherent scatterers and their polarimetric characteristics
Persistent Scatterers (PS), whose response remain constant along time, are of particular interest for
differential interferometry applications to subsidence monitoring [50]. Since it is likely that scatterers
having stable TF responses, i.e., when observed from different positions and different frequencies,
remain stable in time too, studies were led to investigate which types of constructions or objects actually
behave as Coherent Scatterers.
2.21.4.1.3.3
CS detection based on TF entropy
In [51] the normalized correlation approach of (21.154) is compared to a new stability indicator, the TF
entropy, HTF. Unlike (21.154), this indicator can handle more than two samples at a time. The signal of
a given polarization channel is sampled at R different spectral locations, over independent or slightly
overlapping spectral domains to create a TF signal vector, sTF and estimate its (R × R) covariance
matrix, CTF:
sTF =
 s(ω1), . . . , s(ωR)T
CTF = E(sTFs†
TF).
(21.158)
Similarly to the single-image polarimetric case, a TF entropy can be computed as [51]
HTF = −
R
"
i=1
pi logR (pi) with
pi =
λTFi
R
i=1 λTFi
,
(21.159)
where λTFi is the ith eigenvalue of CTF. If different TF samples are maximally correlated, the TF entropy
equals 0, whereas for totally uncorrelated signals having the same amplitude, HTF tends toward 1. The
analysis conducted over the city of Dresden indicates that many CS can be found over all the polarimetric
channels (Figures 21.58 and 21.59). In the central part of the image is located the city center of Dresden,
whereas in the central upper part a park with forested and vegetated areas can be recognized. Note that
individual buildings and building blocks oriented parallel to the azimuth direction are characterized
by a strong dihedral component, while buildings/blocks that have an orientation angle with respect to

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1201
(a)
(b)
(c)
(d)
FIGURE 21.57
Polarimetric 2L-IHP. (Red circle) Test over point targets. (Red square) Test over speckle. (a) ONERA/RAMSES
polarimetric SAR scene (5-m resolution, L-band) Red is HH. Green is HV. Blue is VV. (b) 2L-IHP, polarization
HH. (c) POL-2L-IHP of the SAR scene. (d) Detected target analysis. Red indicates a dominant odd number
of reﬂections. Green a dipole-like scattering. Blue a dominant double-bounce effects. From [49] (For inter-
pretation of the references to color in this ﬁgure legend, the reader is referred to the web version of this
book.).

1202
CHAPTER 21 Radar Polarimetry Basics
HH–VV
RGB-coding
HH+VV
2HV
(a)
(b)
FIGURE 21.58
(a) Color-coded polarimetric image of Dresden. (b) Detected coherent scatterers (in red) in HH polarization,
superimposed to the intensity image. From [51] (For interpretation of the references to color in this ﬁgure
legend, the reader is referred to the web version of this book.).
azimuth ﬂight direction are characterized by a strong cross-polarized scattering component. One may
note the position of the CSs in the region of the park (in the walking promenades and on the central
place within the park) and in the dense urbanized areas (on the corners of buildings, along the streets,
and on the two bridges over the Elbe River).
The detected CS are characterized, in general, by high amplitudes, and low polarimetric entropy
values. Their majority has a man-made character, a fact that predicts a relative high temporal stabil-
ity. Because of their strong polarized behavior polarimetric acquisition diversity increases signiﬁcantly
the performance of CSs detection. Indeed for the Dresden data set the number of detected CSs by
using fully polarimetric data, and an optimization similar to (21.157), is by a factor up to ten higher

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1203
HV
HH
RGB-coding
Range
VV
FIGURE 21.59
(Left) Detected CSs in lexicographic polarimetric basis. (Central upper) Details of the park region. (Central
lower) Details of a dense urban area. (Right upper) Ikonos image of the Groer Garten Park. (Right lower)
Ikonos image of the dense urban area. From [51].
compared to the number of CSs detected by using single-polarization data. The fact that the major-
ity of the CSs is not depolarizing, and can be described by its scattering matrix, makes polarimetric
information essential for the characterization, interpretation, and information extraction from individual
CSs [51].
2.21.4.1.3.4
CS detection based on multiple criteria
In [52], a study of High Resolution X-band images is conducted over urban structures. The stability of
the TF responses using a feature vector containing the coefﬁcient of variation of the signal intensity, the
TF entropy and gradient-based indicators of the stability of the continuous TF response. A statistical
analysis of this feature vector is led to discriminate scatters having a coherent or unstable behavior
in frequency, in azimuth or in both directions. A polarimetric analysis is led over speciﬁc objects. At
such a high resolution, the TF behavior of objects could be used for their recognition using automatic
techniques. An illustration is given in Figure 21.60.

1204
CHAPTER 21 Radar Polarimetry Basics
(a)
(b)
(d)
(c)
FIGURE 21.60
Examples of target point classiﬁcation. Resolution 10 cm. (Red) Frequency invariant. (Purple) Range variant.
(Green) Azimuth variant. (Gray levels) 2-D variant. (a) Resonant in range (ladder). (b) Frequency invariant
(trihedral). (c) Azimuth variant (building corner). (d) Classiﬁcation on the entire scene. From [52] (For
interpretation of the references to color in this ﬁgure legend, the reader is referred to the web version of this
book.).
2.21.4.1.4
Polarimetric Time-Frequency characterization of a dense urban area
2.21.4.1.4.1
Polarimetric Time-Frequency features
Figure 21.61 shows a color-coded polarimetric SAR image of the city of Dresden acquired by DLR’s
E-SAR sensor data at L-band. The scene is mainly composed of built-up areas including vegetation
spots. A forest and a park can be seen on the left part of the image and a river with smooth banks is
located on the right part.

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1205
azimuth direction
range direction
FIGURE 21.61
Color coded image of the Dresden test site (Pauli basis).
Polarimetric properties of media are generally investigated through a decomposition of second order
multivariate polarimetric representations. The resulting parameters provide information on the media
geometrical structure and on the underlying scattering mechanisms. Two parameters, obtained from the
well known eigenvector-based decomposition introduced in [13] are displayed in Figure 21.62.
The entropy image shown in Figure 21.62 reveals that the polarimetric behavior of most of the scene
is highly random. Over urban areas, the polarimetric response is composed of a large number of different
polarimetric contributions originating from complex building structures as wall as from surrounding
vegetation. The resulting high entropy involves that an interpretation of polarimetric indicators may not
be relevant. Over buildings aligned with the ﬂight track direction, the entropy has intermediate values
and the α parameter reveals the presence of dominant single and double bounce reﬂexions. Buildings
which do not face the radar track are characterized by a strong cross-polarization component and high
entropy and can hardly be discriminated from vegetated areas.
Figure 21.63 presents a continuous TF analysis in the azimuth direction of three different media: a
building facing the radar, an oriented building, and a forested area. The SPAN, corresponding to the
sum of the intensities in all polarimetric channels, and the polarimetric α angle are computed for the
different media at each frequency location and mean values are then estimated over pixels belonging to
the object.
A non stationary behavior is clearly visible in Figure 21.63 with a sudden a large variation of both
SPAN and α levels with the observation angle in azimuth φ. This anisotropic behavior is due to the
highly directional patterns of coherent scattering mechanisms which may occur as the radar faces a large

1206
CHAPTER 21 Radar Polarimetry Basics
0
10
20
30
40
50
60
70
80
90
0.1
0
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
FIGURE 21.62
Polarimetric parameter images, α (left) and H (right).
Span (dB)
Span (dB)
Span (dB)
Building
Building
Forest
φ
φ
α
φ
build ∈
∇
φ
φ
build ∈
∇
−15
−20
−25
−30
−5
−10
−15
−20
−25
−4
0
−5
−10
−15
−2
2
4
70
65
60
55
50
0
(°)
φ
−4
−2
2
4
0
(°)
φ
−4
−2
2
4
0
(°)
(°)
α
70
65
60
55
50
(°)
α
60
55
50
45
40
(°)
FIGURE 21.63
Continuous TF analysis in the azimuth direction (SPAN in red, α in blue) (For interpretation of the references
to color in this ﬁgure legend, the reader is referred to the web version of this book.).

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1207
artiﬁcial structure, such as a building [53]. This particular effect can only be observed if the building
orientation with respect to the radar ﬂight track falls within the processed antenna azimuth aperture.
Onthecontrary,orientedbuildingsandvegetatedareas,likeforestpatches,showstationarybehaviors.
TheidentiﬁcationofbuildingsfromtheirTFresponsethusrequiresanadditionalcriteriontocomplement
the stationarity information. It is known that man-made objects are likely to have a coherent response,
whereas natural media may be considered as random. The discrimination of such responses can be
achieved by studying the coherence of the backscattered polarimetric signal in the Time-Frequency
domain and requires the use of an adequate TF polarimetric SAR (PolSAR) signal model.
2.21.4.1.4.2
PolSAR TF signal modeling and analysis
PolSAR data TF model. The proposed TF signal model [54] is given by the following expression, where
the spatial coordinates, l, have be omitted:
s(ω) = t(ω) + c(ω).
(21.160)
The signal s(ω) contains the full coherent polarimetric polarization information and can be associated
to a well-known scattering vector [13]:
k(ω) =
1
√
2

Shh(ω) + Svv(ω), Shh(ω) + Svv(ω), 2Shv(ω)
T ,
(21.161)
where Spq(ω) represents an element of the (2 × 2) scattering matrix S sampled at the frequency
coordinates ω.
The signal described in (21.160) is composed of two contributions:
•
The term t(ω) is highly coherent and can be associated to a deterministic or almost deterministic
target response. Depending on the structure of the observed object, the response can remain constant
during the SAR acquisition, or can be non-stationary if the backscattering behavior is sensitive to
the azimuth angle of observation or illumination frequency.
•
The second term, c(ω), represents the response of distributed environments. It is uncorrelated, but
may follow a non-stationary behavior in particular cases, e.g., vegetated terrains with a strong
topography, very dense environments whose response results from the sum of a large number of
uncorrelated contributions.
This composite model may be tested using s(ω) second order statistics:
•
The coherence of s(ω) can be used to determine the dominant component within the pixel under
consideration. A high value indicates that t(ω) is the most important term in (21.160), and a low
one corresponds to scattering from an incoherent, distributed, medium.
•
The stability of the dominant component can then be tested by studying the stationarity of the
variance of s(ω).
Second order statistics. Due to the signal high dimensionality, usual scalar tools are not well adapted to
the study of second-order TF polarimetric statistics. A polarimetric TF target vector is built by gathering

1208
CHAPTER 21 Radar Polarimetry Basics
the PolSAR information sampled at R spectral coordinates ωi, i = 1, . . . , R.
kTF =

kT (ω1), . . . , kT (ωR)
T
.
(21.162)
The sampling coordinates, ωi, and the frequency domain resolution of the analyzing function g are
chosen so that the R sub-spectra do not overlap and span the whole full resolution spectrum [48]. A
polarimetric TF sample covariance matrix, TTF-Pol, is then computed as follows
TTF-Pol =
-
kTFkTF†.
=
⎡
⎢⎣
T11
· · ·
T1R
...
...
...
TR1
· · · TRR
⎤
⎥⎦,
where Tij =
-
k(ωi)k(ω j)†.
.
(21.163)
Non-stationary pixel discrimination. Stationarity is assessed by testing the ﬂuctuations of the variance
of the signal at the different spectral locations [46,48]. In the polarimetric case, the signal sample
variance is given by a (3 × 3) polarimetric coherency matrix, i.e., by the diagonal terms of the TTF-Pol
matrix: {Tii}i=1,...,R. The polarimetric TF response is considered as stationary if the sample Tii matrices,
assumed to follow independent complex Wishart distributions Tii ∼WC(ni, ii) with ni looks, have
the same expectation . The corresponding hypothesis is given by:
H0 : 11 = · · · = RR = .
(21.164)
The corresponding Maximum Likelihood (ML) ratio is:
 =
max L(, . . . , )
maxii L(11, . . . , RR).
(21.165)
The likelihood terms in (21.165) are maximized by replacing the expectation matrices by the ML
estimates and the hypothesis is tested using the resulting ML test [45], which takes the following form:
 =
,R
i=1 |Ti|ni
|Tt|nt
,
(21.166)
where Tt =
R
i=1 niTii
R
i=1 ni
and nt =
R
"
i=1
ni.
Figure 21.64 presents a log-image of the  parameter on the Dresden test site, obtained with four
spectral coordinates in the azimuth direction over the Dresden test site.
The  parameter reach high values over natural areas indicating a stationary spectral behavior.
Over buildings,  decreases, pointing out the invalidity of the stationary hypothesis over such objects.
Highly anisotropic pixels, such as those corresponding to the wall-ground dihedral reﬂection or specular
reﬂectionfromorientedroofsareclearlyidentiﬁedinFigure21.64 duetotheirverylowstationaryaspect.

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1209
Λ
Λ
Λ
TF
TF
TF
(
(
(
(
(
(
hh+vv
hh−vv
hv
ΛTF−Pol
FIGURE 21.64
Non stationary TF behavior indicator, TF, computed separately for different polarimetric channels (left)
simultaneously using the whole polarimetric information (right).
Coherent pixel discrimination. In [51], the eigenvalues of a single-polarization covariance matrix have
been used to derive a coherency indicator. These eigenvalues carry information on the correlation
structure, but are also sensitive to potential PolSAR ﬂuctuations due to non-stationarity. A solution has
been proposed in order to overcome this limitation and to jointly use all the polarimetric channels [54].
Under the hypothesis of uncorrelated spectral responses, the off-diagonal terms of the TF covariance
matrix verify:
H0 : i j = 0 ∀i ̸= j.
(21.167)
The corresponding ML ratio is given by:
 = maxii L(11, . . . , RR)
maxTF L(TF)
=
|TTF|ni
,R
i=1 |Tii|ni .
(21.168)
This ML ratio expression can be rewritten as:
 =
 ˜TTF

ni
(21.169)
with
˜TTF-Pol =
⎡
⎢⎢⎢⎢⎣
I
12 · · · 1R
12†
I
...
...
...
...
1R† · · · · · ·
I
⎤
⎥⎥⎥⎥⎦
,
(21.170)
where ij = Tii−1/2TijTjj−1/2.

1210
CHAPTER 21 Radar Polarimetry Basics
1
0
ρTF
ρTF
ρTF
ρTF
(
(
(
(
(
(
hh+vv
hh−vv
hv
−Pol
FIGURE 21.65
TF coherence indicator, ρTF, computed separately for different polarimetric channels (left) simultaneously
using the whole polarimetric information (right).
The normalized covariance matrix, ˜TTF-Pol results from the whitening of the TF polarimetric covari-
ance matrix by the separate polarimetric information at each frequency location. This representation
is then insensitive to spectral polarimetric intensity variations and is characterized by its off-diagonal
matrices ij which can be viewed as an extension of the scalar normalized correlation coefﬁcient to the
polarimetric case. The ML ratio in (21.168) is a function of the eigenvalues of ˜TTF-Pol, which reﬂect
the correlation structure: ﬂat for decorrelated responses ( ˜TTF-Pol →Id), heterogeneous for correlated
ones. Taking into account ˜TTF-Pol peculiar form, a correlation indicator, named TF-Pol coherence, can
be deﬁned as [54]:
ρTF-Pol = 1 −
 ˜TTF-Pol

1
3R .
(21.171)
Figure 21.65 presents an image of ρTF-Pol over the Dresden test site, computed from four spectral
locations in the azimuth direction.
As expected, the TF-Pol coherence is high over buildings due to the presence of strong coherent
reﬂectors. It can be also noticed that buildings are identiﬁed independently of their orientation.
2.21.4.1.4.3
PolSAR TF analysis
PolSAR TF classiﬁcation. The stationarity and coherence indicators derived above can be merged to
classify the scene. Both ρTF-Pol and  parameters are thresholded and combined into four classes. The
application of the fusion strategy over the Dresden site is shown in Figure 21.66.
The resulting map permits a good estimation of building locations. A physical interpretation can be
given for each of the four classes:

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1211
stationarity
natural media
numerous
anisotropic responses
high
low
high
low
coherence
isotropic
strong scatterers
anisotropic
artificial structures
FIGURE 21.66
TF polarimetric classiﬁcation. Classiﬁcation scheme (left) results obtained over Dresden (right).
•
Coherent and stationary pixels (white class): The t term in (21.160) is dominant and constant
during the SAR acquisition. This kind of behavior corresponds to strong scatterers with an isotropic
response, like oriented buildings, lamp-posts, ….
•
Coherent and non stationary pixels (yellow class): The t contribution dominates but varies during
the measure, causing ﬂuctuation of the signal with the azimuth angle of observation. This anisotropic
effect is characteristic of buildings facing the radar track, whose response is affected by a strong and
highly directive pattern, mainly due double bounce reﬂections or specular single bounce reﬂection
over roofs tilted toward the radar.
•
Incoherent and stationarity pixels (green class): The uncorrelated component c dominates and has
stable second order statistics. This class corresponds to natural environments (forests, ﬁelds, grass
areas, …) of distributed artiﬁcial media such as roads, roof tops, terraces, …
•
Incoherent and non-stationary pixels (red class): This class indicates the presence of complex
scattering contributions, which change during the SAR integration, and sum-up in an incoherent
way, like in layover areas.
TF cleaning of PolSAR data. As it was shown in Figure 21.62, the full resolution PolSAR information
can hardly be used to analyze the scene geophysical properties due to a very high entropy inherent
to the study of dense environments. The proposed PolSAR TF analysis technique can also be used
to improve in a signiﬁcant way the interpretation of polarimetric indicators. The most coherent TF
scattering mechanisms is described by the ﬁrst eigenvector of ˜TTF-Pol, which can be transformed back
to the H-V polarimetric basis using a matrix P, satisfying ˜TTF-Pol = PTTF-PolP†. From this eigenvector,
one can extract an αTF parameter which shows a much more contrasted and relevant information than

1212
CHAPTER 21 Radar Polarimetry Basics
π
π
⎯
⎯
2
0
α
α
full res
1−TF
α1−TF
α1−TF <
>
/4
π
α1−TF <
>
/4
Optical image
Pauli image
TF classes
FIGURE 21.67
Application of the classiﬁcation scheme to building characterization: over the whole image (top), over the
an isolated building (bottom).
the original full resolution parameter α. Figure 21.67 shows different images of a building of the scene.
A comparison between the T-F classiﬁcation results and the optical image reveals that both the double
bounce reﬂexion is considered as a non-stationary and coherent scattering mechanism, whereas the
roof layover is seen as non-stationary and uncorrelated, due to the superposition of the roof and ground
contributions. A thresholding of αTF with respect to π/4, permits to easily separate these two different
mechanisms and could be used to get a rough estimate of the building height. Such an information might
be useful to interferometric phase unwrapping algorithms which generally face ambiguity issues over
urban areas.
2.21.4.2 Analysis of volumetric media using polarimetric SAR interferometry
2.21.4.2.1
A brief introduction to SAR interferometry
2.21.4.2.1.1
Relation between interferometric phase and the height of a scatterer
The geometrical conﬁguration of an interferometric acquisition, depicted in Figure 21.68, shows two
sensors, located at slightly different positions, that measure the coherent SAR response of a scatterer.
The relative positions of the sensors is measured by the baseline B ≪H and the angle α. After focusing

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1213
z
S1
B
S2
θ
α
H
r1
2r
h
y
FIGURE 21.68
Basic geometrical conﬁguration of an interferometric SAR acquisition.
of the SAR signals and co-registration of the SAR images, the response of the scatterer is given by
si = |aci | exp

−j 4π
λc
ri + jφobj i

i = 1, 2,
(21.172)
where φobj i represents the absolute and unknown phase of the reponse of each object. For a small
baseline and if the acquisitions are made within a sufﬁciently short amount of time, the amplitude and
phase of the object responses may be considered identical, |ac1| = |ac2|, φobj 1 = φobj 2. In this case,
the interferometric phase difference, or interferogram, is given by
φ12 = arg (s1s∗
2) = −4π
λc
r12.
(21.173)
This interferometric phase being proportional to the path difference, r12, it is sensitive to both the ele-
vation of the scatterer with respect to a reference plane and to the range distance r1. A local linearization
permits to isolate the elevation-dependent part ϕtopo:
r12 ≈r12(r1) + r12(z) ⇒φ12 ≈ϕfe(r) + ϕtopo(z),
(21.174)
where ϕfe(r) can be computed from the geometrical conﬁguration and hence compensated and ϕtopo(r1)
is given by
ϕtopo(z) = kzz
with kz = 4π B cos (θ −α)
λr1 sin θ
.
(21.175)
One may note that the estimation of the interferometric phase as the argument of a complex expo-
nential may imply a wrapping due to the limited domain of deﬁnition of the arg operator. As a
consequence
kzz ∈R but ϕtopo(z) ∈[−π, π].
(21.176)

1214
CHAPTER 21 Radar Polarimetry Basics
This ambiguity can generally be overcome using phase unwrapping techniques.
2.21.4.2.1.2
Interferometric coherence
Over homogeneous distributed environments, the acquired are random variables whose statistics may
be studied using the 2-element vector, s =
s1
s2
T , following a complex normal distribution, s ∼
NC(0, C), where the covariance matrix C may be written as
C = E(ss†) = E
|s1|2
s1s∗
2
s∗
1s2
|s2|2

=

I1
√I1I2γ
√I1I2γ ∗
I2

,
(21.177)
where
γ =
E(s1s∗
2)

E(|s1|2)E(|s2|2)
(21.178)
is called the interferometric coherence and may be used to estimate the interferometric phase φ12 =
ϕ = arg (γ ). Using L independent realizations, or looks, of s, ML estimates may be computed as [21,22]
C = 1
L
L
"
l=1
s(l)s†(l) γ =
C(1, 2)
C(1, 2)C(2, 2)
ϕ = arg (γ ).
(21.179)
In addition to the need of a large number of looks, L, a good estimate of the interferometric phase
requires a large value of the modulus of the coherence, since var(ϕ) →0 when |γ | →1 and var(ϕ )
reaches a maximum as |γ | →0.
The coherence may be modeled as a product of a large number of contributions, as, for instance:
γ = γSNR γproc γtemp γgeom γz
with |γi| ≤1.
(21.180)
Each element represent a potential source of decorrelation between the acquired signals, due to the
presence of additive noise, errors during the acquisition, processing and referencing of the signals,
to changes of the scenes between the acquisitions, to spectral shifts induced by acquisition geome-
try and to vertical decorrelation induced by the presence of a volumic medium. Very few of these
can be compensated a posteriori and each of them may inﬂuence the phase estimation accuracy
since
|γ | ≤min
i
|γi|.
(21.181)
2.21.4.2.1.3
The random volume over ground model for a single polarization channel
The last term of the coherence decomposition in (21.180) is related to the structure of the observed
medium through an integral relation [15,55–58]
γz =
% +∞
−∞f (z)e jkzz dz
% +∞
−∞f (z)dz
,
(21.182)

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1215
z 0 + h v
θ
z 0
h v
FIGURE 21.69
Synopsis of a RVOG.
where f (z) represents the equivalent density of coherent reﬂectivity in the elevation direction. The
interferometric coherence may then be used to guess some characteristics of the vertical structure of
the observed volume, provided that the other terms in (21.180) are known or compensated. In order to
estimate the possibilities of such an approach, one may use a simple model of a homogeneous Random
semi-transparent Volume lying over a Ground consisting of a rough surface, the RVOG model, depicted
in Figure 21.69 [56,58].
The volume is assumed to be made of particles having the same reﬂectivity Avdz and the same
constant extinction properties. i.e.,
d fv(z) = −κe
cos θ fv(z)dz
and
fv(z0 + hv) = A
(21.183)
then
/
fv(z) = Ae−2 κe
cos θ (z0+hv−z), ∀z ∈[z0, z0 + hv],
0 otherwise,
(21.184)
where the factor 2 account for round-trip attenuation. The ground reﬂectivity distribution is then given by
fg(z) = fv(z0)σgδ(z −z0).
(21.185)
The intensities backscattered by the ground and the volume are given by
Ig =
 +∞
−∞
fg(z)dz = fv(z0)σg
and
Iv =
 +∞
−∞
fvol(z)dz.
(21.186)
The general unresolved expression of the coherence is then
γz =
% +∞
−∞( fv(z) + fg)e jkzz dz
% +∞
−∞fv(z) + fg(z)dz
=
% z0+hv
z0
fv(z)e jkzzdz + Ig e jkzz0
Iv + Ig
.
(21.187)

1216
CHAPTER 21 Radar Polarimetry Basics
In order to provide a physical interpretation for expression (21.187), cases with different levels of
complexity can be investigated.
Case 0: Transparent volume. In this extremely simple case, the volume response is null, i.e., Iv = κe =
0. The coherence
γz = e jkzz0 = e jφ0
(21.188)
has a unitary modulus and its argument provides the elevation of the ground.
Case 1: Lossless volume and no ground. The extinction of waves when they travel through the volume
is null, κe = 0 and the ground reﬂectivity is null, Ig = 0. In this case γz represents the coherence
behavior of the volume only
fv(z) = A
→
γz = γv0 = e jφ0 e jkz hv
2 sinc
kzhv
2

.
(21.189)
The coherence argument indicates exactly the absolute elevation of the center of the volume, whereas
its modulus depends on its width hv. This case is illustrated in Figure 21.70.
k
h
⏐  ⏐
v
z
=0.3
z
γ
FIGURE 21.70
|γz| for κe = Ig = 0.

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1217
FIGURE 21.71
|γz| for κe ̸= 0 and Ig = 0.
Case 2: Volume with constant linear extinction and no ground. The extinction κe is constant over the
volume and the ground reﬂectivity is null, Ig = 0. The expression of the coherence is
γz = γv =
% z0+hv
z0
ep1z dz
% z0+hv
z0
epz dz
= e jφ0 p
p1
ep1hv −1
ephv −1
with
p = 2κe
cos θ , p1 = p + jkz.
(21.190)
The magnitude and phase behaviors of γv are illustrated in Figure 21.71 for different values of extinction.
For a quasi-null extinction, the coherence magnitude has a sinc-like shape and the phase center is located
at the center of the volume. As the extinction increases, the magnitude pattern becomes ﬂatter and close
to 1 ∀hv when κe is large. The phase center moves then towards the higher interface of the volume.
This behavior is due to the fact that as κe increases the wave penetration depth inside the volume
decreases and the particles that participate more to the scattering phenomenon are those located near
the upper interface. For reduced penetration depths, the decorrelation induced by the numerator of
(21.190) becomes negligible.
Case 3: Volume with constant linear extinction and ground. The extinction κe is constant over the
volume and the ground reﬂectivity is non null. The expression of the coherence is [55,56,58]
γz =
% z0+hv
z0
ep1z dz + Ige jφ0
% z0+hv
z0
epz dz + Ig
= γv + μ e jφ0
1 + μ
with μ = Ig
Iv
,
(21.191)
where μ, called the ground to volume intensity ratio, can be considered as a key parameter of the RVOG
coherence which steers the coherence γz between to extreme behaviors, γz →γv for μ →0 and
γz →e jφ0 μ →+∞. For intermediate values a single coherence term is not sufﬁcient for analyzing
the RVOG model.

1218
CHAPTER 21 Radar Polarimetry Basics
2.21.4.2.2
Pol-inSAR representations
Polarimetric and interferometric signals consist of two polarimetric target vectors, k1, k2, acquired
from slightly different positions. As it has been mentioned for polarimetric TF signal processing, the
computation of the correlation between multivariate signals requires to use projectors. The Pol-inSAR
coherence has then been deﬁned by Cloude and Papathanassiou as:
γ (w1, w2) =
E(s1s∗
2)

E(|s1|2)E(|s2|2)
with si = w†
i ki, arg (w†
1w2) = 0
(21.192)
and w is a projection unitary vector that permits to select one or a linear combination of polarization
channels. This coherence can be obtained from the (6 × 6) POL-inSAR coherency matrix, deﬁned as:
k6 =
 k1
k2

⇒T6 = E(k6k†
6) =
 T11
T12
T†
12
T22

with Ti j = E(kik†
j).
(21.193)
The coherence can then be expressed as
γ (w1, w2) =
w†
1T12w2

w†
1T11w1w†
2T22w2
.
(21.194)
Cloude and Papthanassiou have found the projections deﬁning the optimal scattering mechanisms that
maximize |γ (w1, w2)| [15]. Nevertheless using different projection vectors w1 ̸= w2 is, in general not
recommended. Indeed the phase and magnitude of coherences computed between different polarimetric
channels depend on the interferometric conﬁguration, but also on the polarimetric correlation within
each separate image. In general, the POL-inSAR coherence is simpliﬁed to
γ (w, w) = γ (w) =
w†T12w

w†T11ww†T22w
.
(21.195)
2.21.4.2.3
Polarimetric RVOG model
The principles of a polarimetric solution to the RVOG model are given in Figure 21.72.
The objective is to isolate speciﬁc polarimetric scattering mechanisms wg and wv that null Iv or
Ig, respectively. In an ideal world, γz(wg) = e jφ0 and γz(wv) = γv, and a priori knowledge on the
domain of variation of κe permits to estimate hv with a reasonable precision. In general, such RVOG
polarimetric eigen-mechanisms do not exist, i.e., Iv(w), Ig(w) > 0, ∀w. An original solution, proposed
in [58], is summarized in the following. It is based on the hypothesis that the reﬂectivity and extinction
within the volume do not depend on polarization:
Iv(w) = Iv ∀w and κe(w) = κe ∀w.
(21.196)
This hypothesis correspond to a azimuthal symmetric form for the coherency matrix an is then reason-
able for a dense volume of uniformly oriented particles. Under this hypothesis, the only polarization-
dependent parameter is the response of the ground Ig(w). The polarimeric version of the coherence

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1219
FIGURE 21.72
Ideal and realistic scattering conﬁguration over a volumetric natural environment (Courtesy of Dr. Kostas
Papthanassiou).
given in (21.191) can be expressed as:
γz(w) = γv + μ(w)e jφ0
1 + μ(w)
with μ(w) = Ig(w)
Iv
.
(21.197)
This relation can be written under the following form
γz(w) = e jφ0 + L(w)(γv −e jφ0) with 0 ≤L(w) =
1
1 + μ(w) ≤1
(21.198)
which is the parametric equation of a line segment, between e jφ0 and γv in the complex plane. This
means that when the RVOG model is valid, complex coherences obtained for arbitrary polarimetric
projection vectors are located on a line segment in the complex plane, as illustrated on Figure 21.73.
2.21.4.2.4
Estimation of the height of a RVOG using POL-inSAR data
2.21.4.2.4.1
Vegetation bias removal
In practice the ground to volume intensity ratio μ(w) never reaches the limits of its domain of deﬁnition
0, +∞, i.e., Lmin ≤L ≤Lmax. For a ground contribution with a sufﬁciently low entropy, there exist a
scattering mechanism, typically HV, so that Ig(wv) ≪Ig(wv) and in this case γz(wv) ≈γv. Due to the
lack of polarization selectivity of volume scattering, the extremity of the line segment corresponding to
Lmin cannot be used to estimate the ground elevation. Cloude and Papathanassiou proposed to overcome
this problem by extrapolating the line segment until it intercepts the unitary circle, since the RVOG
model for a transparent medium, γz = γg = e jφ0 →|γg| = 1. This physical interpretation permits to
reduce an important elevation bias linked with the completely depolarized volume response.

1220
CHAPTER 21 Radar Polarimetry Basics
FIGURE 21.73
RVOG line segment within the complex unitary circle.
2.21.4.2.4.2
Practical vegetation height estimation
In [55], Cloude proposes a theoretically sub-optimal but practically robust method to estimate the height
of a volume from POL-inSAR data sets.
Line segment. From a L-look sample Pol-inSAR coherency matrix, estimate the line parameters, e.g.,
γm and γM in Figure 21.73. It is recommended to use the analytical expressions provided in [59] instead
of a least-square ﬁt based on sample coherences generated from (21.195) and a set of pre-deﬁned or
random projection vectors. Indeed the approach in [59] is immediate and corresponds to the generation
of an inﬁnite number of coherences.
Volume and ground coherences. This can be done by selecting one of the segment extremity γm and
γM as γv, e.g., one may chose the one closer to γ (hv). Extrapolate the other extremity of the segment
to the unitary circle in order to determine φ0.
Estimate the height assuming an inﬁnite extinction. As mentioned earlier, for an inﬁnite extinction
value, the phase center of γv correspond to the upper interface of the volume. Then
h∞= arg (γv) −
φ0
kz
.
(21.199)
It is unlikely that κe = ∞, so h∞will indeed correspond to a phase center located within the volume.
This value might underestimate the true volume height.
Estimate the height assuming an null extinction. For a null extinction, the volume coherence magnitude
as a sinc-like shape. The corresponding height might be estimated as
h0 = 2sinc−1(|γv|)
kz
.
(21.200)

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1221
It is also unlikely that κe = 0, i.e., that the phase center is at its lowest possible elevation. This value
might underestimate the true volume height.
Empirical linear combination. The ﬁnal height estimate is
hv = h∞+ ϵ h0.
(21.201)
Recommended ϵ value: 0.4
This semi-empirical approach reveals more robust than a theoretically more correct one, since it
combines uses separate estimates based on the modulus and phase of γv, linearly combines estimates
with opposed biases and does not use numerical values of the extinction that main cause severe artifacts.
Examples of results obtained over forested areas using polarimetric and interferometric SAR processing
are given in Figures 21.74 and 21.75.
SAR Image / HV
3D forest height
FIGURE 21.74
Forest height estimates over Oberpfaffenhofen, Germany, obtained from POL-inSAR data acquired at L band
by the DLR ESAR sensor. Courtesy of Dr. Kostas Papathanassiou.

1222
CHAPTER 21 Radar Polarimetry Basics
ESAR / Test Site : Fichtelgebirge,
Azimut
L-bandHH
FIGURE 21.75
Forest height and biomass estimates over Fichtelgebirge, Germany obtained at L band. Courtesy of Dr. Kostas
Papathanassiou.
2.21.4.3 Analysis of volumetric media using polarimetric SAR tomography
2.21.4.3.1
Basics of SAR Tomographic imaging
SAR tomographic imaging, using Multi-Baseline Interferometry (MB-InSAR), is based on the acqui-
sition of M SAR signals along slightly shifted trajectories ti, as illustrated on Figure 21.76. Each
pair of trajectories is separated by a baseline. After focusing, compensating and georeferencing the
acquired signals, M 2-D SAR images are obtained, si(x,r), where x represents the azimuth location
and r =

x2 + y2 + z2, the proximal distance of a given point.
As shown on Figure 21.76, due to its intrinsic cylindrical ambiguity, classical 2-D SAR imaging is
not well adapted to the characterization of volumic media. For a given focusing position (x0,r0) , the
focused SAR results from the coherent integration of the reﬂectivity density a(x,r, ν) of the considered
medium.
si(x0,r0) =

C(x0,r0)
a(x,r, z)e jkzi z dz
i = 1, . . . , M,
(21.202)
where C(x0,r0) represents one resolution cell with a cylindrical slice layer shape, whose upper and
lower limits are deﬁned by the observed volumic media. The resolution cell limits are given by:
|x −x0| < δx
2 ,
|r −r0| < δr
2 ,
zvmin < z < zvmax
(21.203)
with δx and δr the SAR resolution in azimuth and distance respectively.

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1223
FIGURE 21.76
Geometrical conﬁguration of an MB-InSAR measurement (a), SAR and TomSAR resolutions cells (b).
The formulation in (21.202) assumes that a(x,r, z) is is a function of the elevation position only,
i.e., δx and δr are have sufﬁciently low values and variations in these directions within a resolution
cell may be neglected. The vertical wavenumber, kzi accounts for variations of the interferometric
phase from one image to the other and can be calculated from the geometric conﬁguration of the
acquisition. The purpose of Tomographic SAR (TomSAR) imaging, illustrated on Figure 21.76, is to
improve the vertical resolution of the SAR measurement in order to estimate the volumic density of
the reﬂectivity |a(x,r, z)|2 in a more accurate way. To do so, the M acquired SAR signals si(x0,r0),
obtainedfordifferentnumbersofverticalwaveskzi areusedintheframeofaclassicalproblemofspectral
estimation, for which a series of solutions can be applied [60,61]. Using Multi-Baseline Polarimetric
Interferometry (MB-PolInSAR), Polarimetric Tomographic SAR (PolTomSAR) imaging can provide
the observed medium more precise localization and more detailed physical features. The ﬁrst airborne
TOMSAR experiment was conducted by the DLR using their ESAR sensor at L band over the test site
of Oberpfaffenhofen [62]. The data set consist of 14 SAR images acquired over quasi-parallel tracks
within a short period of time. This study revealed the fantastic power analysis of the combination of
3-D imaging with SAR. Some results of this work are presented in Figure 21.76 where it is shown
that tomography can be used to reliably locate scatterers in elevation, estimate building heights and
image forest canopies. Tomograms performed over different polarimetric channels can be combined to
appreciate the 3-D polarimetric behavior of the media under observation.
Recently, other studies were performed to characterized natural volumetric media, i.e., forested areas,
using SAR tomography combined with polarization diversity [63–65]. Similarly to the RVOG model
mentioned above, the POLTOMSAR reponse of a forest is assumed to be made of two main components
related to the ground and volume contribution. A speciﬁc Kronecker structure is then used to extract
the vertical and polarimetric features of both components from a set of polarimetric images. Despite its
mathematical exactness, the estimated components are affected by an ambiguity and several solutions

1224
CHAPTER 21 Radar Polarimetry Basics
are possible. Fortunately, both the spatial and polarimetric domains covered by these possible solutions
shrinks considerably as the number of images increases, i.e., as vertical resolution improves. One may
note that this ambiguous aspect is common to all POL-inSAR techniques for such an application.
Examples of tomograms obtained over volumetric environments are shown in Figures 21.77 and 21.78.
fir trees
buildings cars
corner-
reflector
FIGURE 21.77
First airborne tomographic SAR experiment: HH SAR image at L band of the DLR buildings and surroundings
(top) HH intensity tomogram estimated over a linear path indicated on the SAR image (middle) Color coded
tomogram obtained from estimates performed over the Pauli basis polarimetric channels (bottom). Courtesy
of Dr. Andreas Reigber.

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1225
FIGURE 21.78
Polarimetric SAR tomograms of a boreal forest performed at L (left) and P (right) over data acquired by the
DLR within the BioSAR campaign. From top to bottom are represented different solutions that all ﬁt very
well with the H100 height obtained through LIDAR measurements and denoted by the green line. Courtesy
of Dr. Stefano Tebaldini.
2.21.4.3.2
Tomographic signal models
Glossary of Notation
AT
=
the transpose of the matrix A,
A†
=
the conjugate transpose of A,
tr(A)
=
the trace of A ∈Cm×m,
A ⊙B
=
the Hadamard product of A, B ∈Cm×n, deﬁned by [A ⊙B]i j = [A]i j[B]i j,
A ⊗B
=
the Kronecker product of A ∈Cm×n and B ∈Cp×q,
||A||2
W
=
tr(AWA†), the weighted Frobenius norm of A ∈Cm×n,
1(m×n)
=
the (m × n) matrix of ones,
E()
=
the expectation operator,
N(m, )
=
complex gaussian distribution with mean m and covariance matrix ,
θ
=
arg maxθ f (θ) is the maximizing argument of f (θ),
θ
=
arg maxθ,loc f (θ) ∈Cn×1 contains the values of θ corresponding to the n
largest local maxima of f (θ).

1226
CHAPTER 21 Radar Polarimetry Basics
2.21.4.3.2.1
TomSAR signal models
Considering an azimuth-range resolution cell that contains ns backscattering contributions from scat-
terers located at different heights and assuming no decorrelation between the different acquisitions, the
received data vector, y ∈CM×1, can be formulated as follows:
y(l) =
ns
"
i=1
si a(zi) + n(l) = A(z)s + n(l),
(21.204)
where l = 1, . . . , L indicates one of the L independent realizations of the signal acquisition, also called
looks. The source signal vector, s = [s1, . . . , sns]T , contains the unknown complex reﬂection coefﬁcient
of the ns scatterers, and n ∈CM×1 represents the complex additive noise, assumed to be Gaussianly dis-
tributed with zero mean variance σ 2
n , and to be white in time and space with, i.e., n ∼N(0, σ 2
n I(M×M))
and E(n(l)n†(k)) = σ 2
n I(M×M)δl,k. The steering vector a(z) contains the interferometric phase infor-
mation associated to a source located at the elevation position z above the reference focusing plane and
is given by:
a(z) = [1, exp ( jkz2z), . . . , exp ( jkzM z)]T ,
(21.205)
where kz j = 4π
λ
B⊥j
r1 sin θ is the two-way vertical wavenumber between the master and the jth acquisition
tracks. The corresponding perpendicular baseline B⊥j is aligned with the cross-range direction. The
carrier wavelength is represented by λ, whereas θ stands for the incidence angle and r1 is the slant range
distance between the master track and the scatterer. The steering matrix A(z) consists of ns steering
vectors corresponding each to a backscattering source:
A(z) = [a(z1), . . . , a(zns)]
(21.206)
with z = [z1, . . . , zns]T , the vector of unknown source heights.
Considering now interferometric decorrelation between different acquisitions, the initial model in
(21.204) may be reformulated as a sum of contributions from random sources [60]:
y(l) =
ns
"
i=1
xi(l) ⊙a(zi) + n(l),
(21.207)
where xi ∈CM×1 accounts for both the reﬂection coefﬁcient of the ith source,si and its potential
variations between the interferometric acquisitions or over the L realizations. Depending on the type of
scatterer under observation, the source signal xi possesses varying statistical properties. The resulting
composite signal y(l) may then follow different scattering behaviors [66].
•
Distributed scatterers: The media are characterized by a scattering response having a random behav-
ior conferred by the speckle effect. Under some assumptions summarized in [67]. the scattered signal
may be modeled using a multiplicative random term following a centered complex gaussian distri-
bution with unitary variance
xi(l) = sixui (l) ∈CM×1
with xui (l) ∼N(0, Ci),
(21.208)

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1227
where xui (l) represents the multiplicative speckle term and si is the complex response of the ith
scatterer, its reﬂectivity being given by σi = |si|2. The (M × M) covariance matrix Ci describes the
interferometric coherence and, for a well calibrated acquisition system, contains unitary diagonal
elements, whereas off-diagonal terms depend on the acquisition conditions This kind of source signal
is well adapted to the modeling of scattering over natural environments, like rough surfaces, ground
and volumetric environments.
•
Deterministic scatterers: The backscattered source signal is frozen over all the observations and
presents no decorrelation between the different acquisitions. For a well calibrated system, its form
is given by
xi(l) = sixci (l) ∈CM×1
with xci (l) = 1(M×1).
(21.209)
This behavior is generally related to specular scattering mechanisms and can be observed over
coherent scatterers like calibrators, facets facing the radar, double-bounce reﬂections over dihedral-
like objects having smooth surfaces (like ground-trunk interactions and double bounce reﬂections
between an object and the ground), or may be linked to resonant behaviors over quasi-periodic
media [48].
•
Hybrid scatterers: Consist of a mixture of coherent and distributed scatterers [48]. In such cases,
a hybrid MB-InSAR signal model, introduced by Sauer et al. [68], may be used to describe the
received signal, as it includes both deterministic and distributed contributions:
y(l) = yc(l) + yu(l)
= ns1
i=1 sixci (l) ⊙a(zi) + ns2
i=1 sixui (l) ⊙a(zi) + n(l).
(21.210)
This type of signals can be frequently encountered when dealing with intermediate-resolution SAR
images.
2.21.4.3.2.2
PolTomSAR signal model
The polarimetric response of a scatterer is fully described by its (2 × 2) complex scattering matrix S.
The scattering matrix can be vectorized using, for instance, the Pauli basis matrix set {
 p}p=1,...,3 [12],
in order to build a target vector v
v =
1
√
2
[Shh + Svv, Shh −Svv, 2Shv] = s k,
(21.211)
where σ = |s|2 = v†v represents the polarimetric span [12] of the scatterer response, and k =
[k1, k2, k3]T ∈C3×1 represents a unitary polarimetric target vector, i.e., k†k = 1. In an MB-PolInSAR
conﬁguration, the array response may be represented by re-arranging the M acquired polarimetric
signals, v j with j = 1, . . . , M the track index, under the form of a 3M element vector, yP, composed
of 3 MB-inSAR components, each related to a polarization channel:
yP = [yT
1 , yT
2 , yT
3 ]T ∈C3M×1,
(21.212)
where yp ∈C3M×1, with p = 1, 2, or, 3, represents the MB-InSAR response for the pth polarimetric
channel, i.e., [yp] j = [v j]p. Using this convention of representation, the polarimetric steering vector

1228
CHAPTER 21 Radar Polarimetry Basics
and steering matrix are given by:
a(zi, ki) = ki ⊗a(zi),
A(z, K) = [a(z1, k1), . . . , a(zD, kD)],
(21.213)
whereki isthepolarimetrictargetvectoroftheithsourceandK = [k1, . . . , kns].Apolarimetricsteering
vector can be deﬁned using ﬁve real coefﬁcients given by the elevation, z and the real and imaginary
parts of two complex numbers deﬁning a unitary 3-element polarimetric complex vector whose absolute
phase is arbitrary. Similarly to the Single Polarization (SP) expression given in (21.204), the received
MB-PolInSAR signal yP(l) may be formulated as
yP(l) = A(z, K)s(l) + n(l) ∈C3M×1,
(21.214)
where similarly to the SP case, s(l) ∈Cns×1 represents a realization of the complex amplitude of the ith
source. Diverse model assumptions given for SP signals, can be similarly used for PolTomSAR signals.
2.21.4.3.3
Tomographic focusing techniques
Theobjectiveoftomographicfocusingistoestimatethereﬂectivity,scatteringvector,andheightσ, ki, zi
of each source using the acquired data sets. The source characteristics can be estimated from the covari-
ance matrix of the received signal R = E(yy†). In practice, for a locally Gaussian statistical behavior,
a maximum likelihood estimate of R may be computed from L independent locations surrounding the
pixel under analysis, as
R = 1
L
L
"
l=1
y(l)y†(l).
(21.215)
Under the hypothesis of a uniform true reﬂectivity and for a sufﬁcient number of looks, L, R may be
used instead of R to perform tomography. The number of sources, ns, is in general unknown and needs
to be estimated from the measured data. Some commonly used Model Order (MO) selection techniques
based on statistical approaches, e.g., ITC, MDL, AIC [69–71], may be used to determine ˆns. Once ns
is determined, the eigenstructure matrices can be estimated from the sample covariance matrix
R = EssE†
s + EnnE†
n,
(21.216)
where Es and En are respectively estimated signal and noise subspaces.
2.21.4.3.3.1
Single polarization tomography
Using MB-InSAR data sets acquired for a given polarization channel, Single Polarization (SP) tomog-
raphy can be derived from the data covariance matrix R using classical mono-dimensional estimators
like Beamforming, Capon and MUSIC estimator as well as multi-dimensional methods like maximum
likelihood estimators and weighted subspace ﬁtting approaches.

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1229
Mono-dimensional estimators. These approaches determinez, an estimate of the elevation of the scat-
terers under observation, as the coordinates of the ˆns largest local maxima of an continuous objective
function P(z):
z = arg max
z,loc P(z).
(21.217)
For the classical Beamformer and Capon spectral estimation techniques, the objective function is given
by the continuous estimate of the reﬂectivity, PB,C(z) = ˆσB,C(z), deﬁned as
ˆσB(z) = a†(z)Ra(z)
M2
,
ˆσC(z) =
1
a†(z)R−1a(z).
(21.218)
Once the set of scatterer elevation,z, is estimated using (21.217), the corresponding reﬂectivities can
be obtained from (21.218). The selection of discrete sources from peaks of the reﬂectivity spectrum
confers to the Beamformer and Capon estimation techniques an important sensitivity to the acquisition
conﬁguration, and in particular to the presence of spurious sidelobes related to an irregular baseline
sampling. The Beamformer is known to show a low resolution and may then overlook some closely
spaced scatterers, whereas Capon’s technique possesses an improved resolution but a reduced radio-
metric accuracy.
MUSIC is a subspace based mono-dimensional technique, whose objective function is a measure of
the orthogonality between a steering vector a(z) and the estimated noise subspace En and is given by:
PM(z) =
1
a†(z)EnE†
na(z)
.
(21.219)
Oncez, is determined by inserting (21.219) in (21.217), a Least-Square (LS) estimate of the complex
reﬂectivity vectors can be obtained [60,61].
Nonparametric approaches like Beamforming and Capon, are generally used to globally appreciate
the structure of a volumetric medium and the main trends of the continuous reﬂectivity distribution
in elevation. For the analysis of discrete spectral components, they may fail to discriminate closely
spaced scatterers due either to their limited resolution, or to the presence of side lobes that may induce
an erroneous estimation of the source location. MUSIC generally presents better performances for the
analysis of discrete sources, related to a better resolution. Nevertheless, like all parametric methods,
MUSIC is sensitive to data modeling errors, and in particular those related to the estimated number
of sources ˆns. Moreover, MUSIC is known to work well in the case of uncorrelated scatterers, but its
performance may degrade signiﬁcantly in the presence of correlated scatterers since the source signal
covariance matrix tends to be singular [72]. One of the main advantages of such techniques resides in
the low numerical complexity of the mono-dimensional optimization described in (21.217).
Multi-dimensional estimators. Maximumlikelihood(ML)estimatorsaremulti-dimensionaltechniques,
generally given by
(z,σ, ˆσ 2
n ) = arg max L(z, σ, σ 2
n )
(21.220)

1230
CHAPTER 21 Radar Polarimetry Basics
with the likelihood function L(z, σ, σ 2
n ). In the case of distributed scatterers, the Stochastic ML (SML)
can be derived [73]:
z = arg min log |PARPA + ˆσ 2
n P⊥
A|,
ˆσ 2
n =
1
M −ˆns
tr{P⊥
AR},
(21.221)
where P⊥
A = (I(M×M)−A(z)(A†(z)A(z))−1A†(z)) represents the orthogonal projector on the null space
of A(z). Considering deterministic scatterers, the cost function (21.220) results in the Deterministic ML
(DML) estimator[74]
z = arg min tr{P⊥
AR}.
(21.222)
Weighted Noise subspace ﬁtting (NSF) estimator is derived by ﬁtting the estimated noise subspace
En with A(z) in the weighted LS sense as follows:
QNSF(z) = ||E†
nA(z)||2
W = tr(A†(z)EnE†
nA(z)W),
(21.223)
whereas the weighted Signal Subspace Fitting (SSF) cost function is given by:
QSSF(z) = ||Es −A(z)T||2
W = tr(P⊥
A(z)EsWE†
s),
(21.224)
where the ﬁtting matrix T is replaced by its LS estimate T = (A†(z)A(z))−1A†(z)Es. Both cost
functions may be used to estimate the elevation of the scatters using a ns-dimensional minimization:
zWSF = arg max
z
QWSF(z),
(21.225)
where the sufﬁx WSF indicates ones of the methods, NSF or SSF, mentioned above. It has been shown
in [75], that any hermitian positive semi deﬁnite weighting matrix W yields consistent parameter
estimates. In particular, a consistent estimate of W permits to obtain minimum variance estimates,
which asymptotically reach the Cramr-Rao lower bound [73]. Such a value is given for each case:
WSSFopt = (s −ˆσ 2
n I(ns×ns))2−1
s ,
WNSFopt = A†(z)EsWSSFoptE†
sA(z).
(21.226)
Compared with the mono-dimensional ones, multi-dimensional methods ML estimators are more
robust, leading to global optima, but at an expensive computational cost. Regarding weighted subspace
ﬁtting techniques, the appropriate selection of certain weighting matrices can provide these estimators
an optimal estimation accuracy as ML techniques at a reduced computational cost.
Numerical examples. In order to demonstrate the performance of the aforementioned tomographic
estimators, two scatterers are assumed to locate at h1 = 0 m and h2 = 4 m, acquired respectively by a
multibaseline conﬁguration with M = 5 acquisitions. The baselines are assumed to be evenly distributed
and between each successive acquisitions, the difference of vertical wavenumbers is supposed to be
kz = 0.1. Assuming these two scatterers with equal reﬂectivity, the covariance matrix of source
signals is given by
Rx =
1
ρ
ρ∗1


2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1231
and SNR = 20 dB. Varying the correlation factor ρ, Rx can respectively represent the source covariance
matrix of coherent (ρ = 1), distributed (ρ = 0), and hybrid scatterers (0 < ρ < 1). In order to study the
vertical resolution, these estimators are used in the height estimation of uncorrelated signals (ρ = 0) with
varying the height difference of two scatterers h = |h1 −h2|. Figure 21.79a shows when h < 2 m,
MUSIC estimator degrades signiﬁcantly due to closely spaced scatterers. SSF and NSF estimators both
provide very good resolution with h = 0.4 m. Whereas, Capon’s method can provide a good height
estimate when h > 4 m. Now simulating a 256-look sample data covariance matrix with varying ρ
from 0 to 0.99, RMSE of the estimated h2 is plotted with respect to the correlation factor ρ in Figure
21.79b. The NSF estimator provides the most accurate estimate for uncorrelated or partially correlated
signals (ρ < 0.95), while the SSF estimator copes well with highly correlated signals (ρ ≥0.95).
MUSIC cannot deal with highly correlated sources due to the quasi-singularity of Rx.
2.21.4.3.3.2
Fully polarimetric tomography
Fully Polarimetric (FP) tomography is implemented by jointly using fully polarimetric data sets acquired
in a Polarimetric MB-InSAR conﬁguration. It is a useful tool to extract both the scatterer’s vertical
location and its scattering mechanism. Similar to the SP case, the FP tomography is derived from the
data covariance matrix RP = 1
L
L
l=1
(yP(l)y†
P(l)) using some mono-dimensional and multi-dimensional
FP spectral estimators.
Mono-dimensional estimators. The elevation and scattering mechanisms of the different scatterers are
estimated as the coordinates of the ˆns largest local maxima of a polarimetric objective function P(z, k).
z, K = arg max
z,k,loc P(z, k).
(21.227)
Similarly to the SP case, the Beamformer and Capon objective functions are given by continuous
estimates of the reﬂectivity PB,C(z, k) = ˆσB,C(z, k), with
ˆσB(z, k) = a†(z, k)RPa(z, k)
M2
,
ˆσC(z, k) =
1
a†(z, k)R−1
P a(z, k)
.
(21.228)
The direct local maximization of the FP objective function in (21.227) would require searching solutions
in a 5-D argument space. Rewriting the polarimetric steering vector as
a(zi, ki) = (I(3×3) ⊗a(zi))ki = Ba(zi)ki
(21.229)
permits to formulate reduce the search dimension to one, since
PB(z) = max
k
PB(z, k) = λmax(B†
a(z)RPBa(z))
M2
,
PC(z) = max
k
PC(z, k) =
1
λmin(B†
a(z)R−1
P Ba(z))
,
(21.230)

1232
CHAPTER 21 Radar Polarimetry Basics
0
0.5
1
1.5
2
2.5
3
3.5
4
4.5
10 −2
10−1
10 0
10 1
Δ h
RMSE[m]
RMSE[m]
Capon
MUSIC
NSF
SSF
(a)
(b)
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
10−2
10−1
10 0
10 1
ρ
Capon
MUSIC
NSF
SSF
FIGURE 21.79
MB-InSAR: height estimation. RMSE of h estimation VS (a) height difference when ρ = 0 (b) source
correlation ρ.

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1233
where λmin,max(M) represents the minimum and maximum eigenvalue of the positive semi-deﬁnite
matrix M. Once the ˆns elevations, are determined from the local maxima of (21.230), the corresponding
scattering mechanisms can be estimated from:
kBi = emax(B†
a(ˆzi)RPBa(ˆzi)),
kCi = emin(B†
a(ˆzi)R−1
P Ba(ˆzi)),
(21.231)
where emin,max(M) indicates the eigenvector of M associated with λmin,max(M), respectively. A similar
approach may be applied to concentrate the FP MUSIC objective function:
PM(z) = max
k
PM(z, k) =
1
λmin(B†
a(z)EnE†
nBa(z))
,
kMi = emin(B†
a(ˆzi)EnE†
nBa(ˆzi)),
(21.232)
where En represent here the eigenvectors of RP spanning its noise space. The reﬂectivity of the sources
can be estimated, using a L-look polarimetric LS approach.
These estimators are considered as mono-dimensional, since the estimation of the elevation and the
scattering mechanism is jointly realized by eigendecomposition. Such methods are computationally
efﬁcient but may reach some of the limitations mentioned in the SP case.
Multi-dimensional estimators. The ML estimators are formulated in the FP case using the polarimetric
steering matrix A(z, K), represented by:
•
FP-DML: ˆz, ˆK = arg max tr{PA(z, K)RP}.
•
FP-SML: ˆz, ˆK = arg min | PA(z, K)RPPA(z, K) + ˆσ 2
n P⊥
A (z, K) |.
To directly optimize the FP ML estimators, the estimation of ˆns optimal elevations ˆzi and target vectors
ki, requires an optimization over a 5ˆns-dimensional space, and implies an excessive computational
burden.
Polarimetric WSF estimators are given by:
•
FP-SSF: (ˆz, ˆK) = arg min tr{P⊥
A(z, K) ˆEsWSSFopt ˆE†
s}.
•
FP-NSF: (ˆz, ˆK) = arg min tr{A†(z, K) ˆEn ˆE†
nA(z, K)WNSFopt}.
Directly minimizing the FP-SSF estimator also suffers 5ˆns computational cost, but the FP-NSF esti-
mator can maintain the computational cost as the SP case, using an analytic solution proposed in [66].
Compared with SP tomography, polarimetric tomography can provide more accurate localization of
scatterers in the vertical direction due to the polarization diversity. The observed media can be further
characterized in terms of both vertical location and scattering mechanism.
Numerical examples. Under the same baseline conﬁguration as the SP case in Section (2.21.4.3.3.1),
a 256-look sample covariance matrix is derived from received fully polarimetric data sets in the MB-
PolInSAR conﬁguration, which contains both height and polarimetric information. Assuming the above
two scatterers with the canonical surface scattering, i.e., k1 = k2 = [1, 0, 0]T , Figure 21.80a shows
RMSE of height estimation w.r.t. ρ: FP-Capon estimator still cannot accurately separate two scatterers
due to a limited resolution; FP-NSF estimator provides the most precise height estimate; FP-MUSIC
estimator degrades its performance for highly correlated scatterers. To study the role that polarization

1234
CHAPTER 21 Radar Polarimetry Basics
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
10 −2
10 −1
10 0
10 1
ρ
RMSE[m]
Capon
MUSIC
NSF
(a)
(b)
0
10
20
30
40
50
60
70
80
90
10 −2
10 −1
10 0
ζ
RMSE[m]
Capon
MUSIC
NSF
FIGURE 21.80
MB-PolInSAR height estimation. RMSE of h estimation VS (a) source correlation and (b) polarization
difference ζ (ρ = 0).

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1235
diversity plays in source separation, we denote Polarization Difference Angle ζ with cos ζ =
k†
1k2
√
|k1|2|k2|2 .
We keep the same surface scattering for the scatterer at 0 m and vary the scattering mechanism of
the scatterer at 4 m to increase the polarization difference angle. As shown in Figure 21.80b, with ζ
increasing, polarization diversity between two scatterers improves the height resolution, especially for
FP-Capon estimator which reaches the same resolution as MUSIC when ζ > 60◦. FP-NSF estimator
performs best over all the polarization difference angle.
2.21.4.3.4
Applications
Using MB-PolInSAR data sets, TomSAR and PolTomSAR techniques are applied to retrieve the distri-
bution of the backscattered power in the vertical direction, leading to 3-D images of observed scenes.
These techniques permit to analyze volumic structures like forests, sand, snow, ice, etc. Some examples
are given to illustrate the potentials of tomographic techniques in the applications of urban, forestry
remote sensing and underfoliage imaging.
2.21.4.3.4.1
Urban remote sensing
High-resolution (HR) tomographic techniques are applied to analyze dense urban areas in terms of
scatterers’ heights and their scattering mechanisms. Diverse scattering patterns can be encountered over
dense urban environments, such as double bounce reﬂection at the wall-ground interaction, surface
scattering from the roof and the ground, volumic scattering or a mixture of several scattering patterns.
Conventional tomographic estimators may reach some limitations. The proposed model-adaptive FP-
NSF estimator in [66,76] illustrates an undeniable performance using L-band intermediate-resolution
dualbaseline FP data sets acquired over Dresden, Germany, by the DLR ESAR sensor. Over a test line,
the α tomograms obtained by FP-MUSIC and FP-NSF estimators with model order equal to 2 are shown
in Figure 21.81. The heights of buildings are validated against LIDAR data as shown in [77]. FP-MUSIC
FIGURE 21.81
α tomograms (ns = 2). Black line: LIDAR data. (a) FP-MUSIC and (b) FP-NSF (For interpretation of the
references to color in this ﬁgure legend, the reader is referred to the web version of this book.).

1236
CHAPTER 21 Radar Polarimetry Basics
FIGURE 21.82
3-D reconstruction over an urban zone of Dresden using FP-NSF estimator (ns = 2). (a) Google map, (b)
height map, and (c) α map.
FIGURE 21.83
Tree top heights and underlying ground topography by TomSAR approaches. Black line: Lidar proﬁles. Gray
line: estimated proﬁles by TomSAR. Vertical: height (m). Horizontal: azimuth (bin) (a) HH, (b) VV, (c) HV,
and (d) FP (For interpretation of the references to color in this ﬁgure legend, the reader is referred to the
web version of this book.).
estimator suffers spurious sidelobes (blue1 circle), whereas FP-NSF estimator illustrates precisely the
vertical proﬁle of buildings without any sidelobe. The 3-D reconstructions of an urban zone are depicted
in Figure 21.82.
1For interpretation of color in Figures 21.66, 21.82, 21.83 the reader is referred to the web version of this book.

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1237
FIGURE 21.84
Estimated ground topography and tree top heights (HH) in ground range (a) lidar zg , (b) Estimated zg ,
(c) lidar ztop, and (d) Estimated ztop.
2.21.4.3.4.2
Forestry remote sensing
In the forest scenario, the canopy consists of a large number of elementary scatterers distributed in the
vertical direction and is characterized by a continuous spectrum, whereas the ground is an impenetrable
medium that possesses an isolated localized phase center and is characterized by a discrete spectrum.
So the vertical distribution of backscattered power from forested areas leads to a mixed spectrum. The
performance of conventional tomographic estimators may degrade due to their lack of adaptation to the
type of spectrum. A novel hybrid tomographic approach is proposed to deal with the mixed spectrum and
provides robust estimates for both tree top heights ztop and the underlying ground topography zg [77].

1238
CHAPTER 21 Radar Polarimetry Basics
FIGURE 21.85
α Tomograms. Circle: truck. Vertical axis: height (m). Horizontal axis: azimuth (bin). (a) FP-Capon, (b) FP-
MUSIC, and (c) FP-NSF.
Using P-band data sets (including 6 tracks) acquired over a test area of Paracou, French Guiana, by
the ONERA SETHI sensor, the tree top and the ground elevation over an azimuth cut are estimated by
the hybrid spectral approach (in gray) and the corresponding Lidar proﬁles (in black) are drawn over the
normalized Capon tomograms in Figure 21.83. It can be observed that the estimated proﬁles coincide
well with the Lidar ones. The ground elevation is precisely estimated using HH data sets, but still

2.21.4 Selected Topics in Multidimensional Polarimetric SAR Signal Processing
1239
FIGURE 21.86
3-D visualization of under-foliage objects. (a) SSF and (b) FP-NSF.
overestimated in VV and HV polarization. The forest top heights are well-estimated over all polarization
channels. Using FP data sets, the results are similar to those obtained by HH data. Using HH data sets,
Figure 21.84 depicts the estimated ztop and zg over a test zone as well as the corresponding Lidar data in
ground range. Globally, the estimated ztop and zg match well with the Lidar ones in terms of texture and
heights, except for some overestimated areas due to topographic effects that may inﬂuence scattering
responses.
2.21.4.3.4.3
Underfoliage imaging
For the study of under-foliage imaging, Capon’s method has been applied to extract the shape of objects
and canopy proﬁle [78], but considering the complex structure of such objects, HR approaches are
requiredtodiscriminatetheircloselyspacedscatteringfeaturesintheverticaldirection.Theperformance
of these spectral analysis techniques is conditioned by the statistical nature of the scattering response
of the observed objects, as it has been shown in [79,80]. Under-foliage objects may be described by
a deterministic response embedded within a speckle affected environment and hence associated to a
series of complex scattering centers. To distinguish under-foliage objects, Figure 21.85 illustrates the
α tomograms over a test line with a truck beneath the canopy [81], using L-band PolInSAR data sets
acquired over Dornstetten, Germany. The 3-D tomogram of the area, performed over azimuth bins and
for varying range positions using the SP-SSF approach. Limiting the reconstruction height to 4 m above
the terrain permits to isolate the under-foliage truck response (Figure 21.86a). Its reconstructed shape is
similar to the uncovered one, with a reﬂectivity slightly higher (about 5 dB more) than the surrounding
environment one. Complementary to distinct the objects in reﬂectivity, a 3-D reconstruction using FP-
NSF estimator, permits to visualize the corresponding scattering pattern by α value. To better visualize
the underlying truck response, the height is limited to 4 m above the ground and the reﬂectivity is
limited to values inferior to 43 dB (Figure 21.86b). It shows that the truck outside the forest has a
strong double bounce reﬂection at the ground-truck interaction, and the shape of the truck beneath the

1240
CHAPTER 21 Radar Polarimetry Basics
canopy is a precisely reconstructed with an α value about 45◦due to the sidelobe effect from the canopy.
Using PolTomSAR techniques, the under-foliage truck can be well described both in terms of shape
and scattering pattern.
2.21.5 Conclusion and trends
As it has been mentioned in the introduction of this chapter, SAR polarimetry is a multi-disciplinary sub-
ject, with well-established theoretical foundations and tight connections with applied electromagnetism,
multivariate signal processing, . . .
Polarization diversity is particularly well adapted to SAR remote sensing since it provides both, a
dimension over which one may ﬁlter out undesirable responses (or select responses of interest), and a
very good way to characterize physical parameters of objects or media. Speciﬁc estimation techniques,
adapted to the random nature of radar signals, have been developed to provide in an unsupervised way
features that correspond to canonical scattering behaviors which can be efﬁciently used to determine a
wide range of physical properties.
A comparison of a polarimetric color-coded SAR image with a single polarization one permits
to realize that fully polarimetric measurements bring a lot more information and hence shall reveal
much more useful. The most famous and widely used applications of SAR polarimetry mainly concern
qualitative approaches, i.e., whose output parameter is not the estimate of the value of a physical
parameter. Indeed, numerous polarization-based methods have been developed for object, or natural
matter (like snow, water, . . .), or structure detection, environment classiﬁcation and mapping in general,
hazard monitoring, vegetation observation, . . . For such applications, radar polarimetry provides very
efﬁcient tools that require among the smallest levels of supervision, i.e., that can be implemented in a
quasi automatic way within badly known environments.
Concerning quantitative approaches, the situation is slightly different. For some applications related
to parameters that can be well separated by polarimetry, e.g., azimuthal orientation, or whose level of
robustness may be estimated from the signal itself, radar polarimetry is a much valuable measuring
approach. For some others, a reliable estimation may reveal difﬁcult depending on the environment
of the measure. For known conditions, a solution among the wide range offered by polarimetry can
generally be found. In the opposite case, radar polarimetry may become a victim of the qualities of
polarization. Polarization is widely used as diversity mode due to its good sensitivity to many of the
electromagnetic properties of observed media. Estimating one particular parameter among the large
number of other factors that modify the polarization of a wave and for a wide range of conﬁgurations
can be problematic. Polarimetric measurements present a low dimensionality, 9 at most, while they
do not possess any intrinsic structure, i.e., a target vector may be represented by an amplitude and a
unitary vector. For applications, like those based on coherent spatial diversity, clutter echoes have low
rank, whereas in the polarimetric case the clutter may occupy an important part of the eigen-space if
the observed echos do not have sufﬁciently similar characteristics.
Current trends in SAR polarimetry correspond to different possible solutions considered to maintain
polarimetry robustness to a high level even in particularly unfavorable conﬁgurations. Some solu-
tions use external information provided by other types of sensors, like hyperspectral or other types of
measurements.

References
1241
Other particularly efﬁcient solutions rely on incoherent diversity modes, based on the use of several
spectral bands (carriers frequencies) or incidence angles or acquisition dates . . . This solution is strongly
encouraged by the development of space-borne sensors delivering time series of data sets.
Finally coherent diversity modes, mainly based on spatial diversity using two (interferometry) or
more (tomography) images have shown spectacular results. In particular, forest structure estimation
using single or multi-baseline POL-inSAR acquisitions can give very good results when polarimetric
only measurements are quasi-useless.
Anyway, one should avoid doing predictions about the future of radar polarimetry, since the historical
review given in the introduction clearly mentions that radar polarimetry is regularly deeply modiﬁed by
a surprising discovery!
This is why we really enjoy this research ﬁeld.
References
[1] W.M. Boerner, Inverse methods in electromagnetic imaging, in: Wolfgang M. Boerner et al. (Ed.), Nato
Advanced Research Workshop on Inverse Methods in Electromagnetic Imaging, vol. 1–2, Reidel, Bad wind-
sheim, Germany, Holland, Dordrecht, 1983.
[2] G. Sinclair, Modiﬁcation of the radar target equation for arbitrary targets and arbitrary polarization, Technical
Report Report 302–19, The Ohio State University Research Foundation, Antenna Laboratory, 1948.
[3] S. Sinclair, The transmission and reception of elliptically polarized waves, Proc. IRE 38 (2) (1950) 148–151.
[4] E.M. Kennaugh, Effects of the type of polarization on echo characteristics, Technical Report 381–1 394–24,
Antenna Laboratory, The Ohio State University Research Foundation, 1949.
[5] G.A. Deschamps, Geometrical representation of the polarization of a plane electromagnetic wave, Proc. IRE
39 (5) (1951) 540–544. ************
[6] J. Huynen, Phenomenological theory of radar targets, PhD Thesis, Drukkerij Bronder-Offset NV, 1970.
[7] S.R. Cloude, Group theory and polarisation algebra, OPTIK 75 (1986) 26–36.
[8] A. Freeman, Sar calibration: an overview, IEEE Trans. Geosci. Remote Sens. 30 (6) (1992) 1107–1121.
[9] A. Freeman, S. Durden, A three-component scattering model for polarimetric sar data, IEEE Trans. Geosci.
Remote Sens. 36 (3) (1998) 963–973.
[10] J. van Zyl, Unsupervised classiﬁcation of scattering behavior using radar polarimetry data, IEEE Trans.
Geosci. Remote Sens. 27 (1) (1989) 36–45.
[11] J.S. Lee, L. Jurkevich, P. Dewaele, P. Wambacq, A. Oosterlinck, Speckle ﬁltering of sar images: a review,
Remote Sens. Rev. 8 (1994) 313–340.
[12] S. Cloude, E. Pottier, A review of target decomposition theorems in radar polarimetry, IEEE Trans. Geosci.
Remote Sens. 34 (2) (1996) 498–518.
[13] S. Cloude, E. Pottier, An entropy based classiﬁcation scheme for land applications of polarimetric sar, IEEE
Trans. Geosci. Remote Sens. 35 (1) (1997) 68–78.
[14] Y. Yamaguchi, W.-M. Boerner, H. Eom, M. Sengoku, S. Motooka, T. Abe, On characteristic polarization
states in the cross-polarized radar channel, IEEE Trans. Geosci. Remote Sens. 30 (5) (1992) 1078–1080.
[15] S. Cloude, K. Papathanassiou, Polarimetric sar interferometry, IEEE Trans. Geosci. Remote Sens. 36 (5)
(1998) 1551–1565.
[16] E. Lueneburg, Direct and Inverse Electromagnetic Scattering, Pittman Research Notes in Mathematic Series
361, Addison Wesley Longman, Harlow, UK, 1996 (Chapter Radar polarimetry: A revision of basc concepts).
[17] A. Kostinski, W. Boerner, On foundations of radar polarimetry, IEEE Trans. Antennas Propag 34 (12) (1986)
1395–1404.

1242
CHAPTER 21 Radar Polarimetry Basics
[18] J.S. Lee, E. Pottier, Polarimetric Radar Imaging: From Basics to Applications, CRC Press, 2008.
[19] E. Lueneburg, Principles of radar polarimetry, Proc. IEICE Trans. Electron. Theory 10 (1995) 1339–1345.
[20] S. Cloude, Lie groups in electromagnetic wave propagation and scattering, J. Electromagnet. Waves Appl. 6
(8) (1992) 947–974.
[21] R. Bamler, P. Hartl, Synthetic aperture radar interferometry, Inverse probl. 14 (4) (1998).
[22] J.-S. Lee, K. Hoppel, S. Mango, A. Miller, Intensity and phase statistics of multilook polarimetric and
interferometric sar imagery, IEEE Trans. Geosci. Remote Sens. 32 (5) (1994) 1017–1028.
[23] R. Touzi, A review of speckle ﬁltering in the context of estimation theory, IEEE Trans. Geosci. Remote Sens.
40 (11) (2002) 2392–2404.
[24] S.R.Cloude,Polarimetry:thecharacterizationofpolarizationeffectsinEMscattering,PhDThesis,University
of Birmingham, England, 1986.
[25] Y. Yamaguchi, T. Moriyama, M. Ishido, H. Yamada, Four-component scattering model for polarimetric sar
image decomposition, IEEE Trans. Geosci. Remote Sens. 43 (8) (2005) 1699–1706.
[26] A. Freeman, Fitting a two-component scattering model to polarimetric sar data from forests, IEEE Trans.
Geosci. Remote Sens. 45 (8) (2007) 2583–2592.
[27] M. Neumann, L. Ferro-Famil, A. Reigber, Estimation of forest structure, ground, and canopy layer charac-
teristics from multibaseline polarimetric interferometric sar data, IEEE Trans. Geosci. Remote Sens. 48 (3)
(2009) 1086–1104.
[28] J. van Zyl, M. Arii, Y. Kim, Model-based decomposition of polarimetric sar covariance matrices constrained
for nonnegative eigenvalues, IEEE Trans. Geosci. Remote Sens. 49 (9) (2011) 3452–3459.
[29] M. Arii, J. van Zyl, Y. Kim, Adaptive model-based decomposition of polarimetric sar covariance matrices,
IEEE Trans. Geosci. Remote Sens. 49 (3) (2011) 1104–1113.
[30] M. Arii, J. van Zyl, Y. Kim, A general characterization for polarimetric scattering from vegetation canopies,
IEEE Trans. Geosci. Remote Sens. 48 (9) (2010) 3349–3357.
[31] R. Paladini, L. Ferro-Famil, E. Pottier, M. Martorella, F. Berizzi, E. Dalle Mese, Lossless and sufﬁcient
psi-invariant decomposition of random reciprocal target, IEEE Trans. Geosci. Remote Sens. 99 (2012)
1–15.
[32] L. Ferro-Famil, E. Pottier, J.S. Lee, Unsupervised Classiﬁcation of Natural Scenes form Polarimetric Inter-
ferometric SAR data, World Scientiﬁc Publishing, Frontiers of Remote Sensing Information Processing,
2003, pp. 105–137.
[33] J.-S. Lee, R. Jansen, D. Schuler, T. Ainsworth, G. Marmorino, S. Chubb, Polarimetric analysis and modeling
of multifrequency sar signatures from gulf stream fronts, IEEE J. Oceanic Eng. 23 (4) (1998) 322–333.
[34] J.-S. Lee, D. Schuler, T. Ainsworth, E. Krogager, D. Kasilingam, W.-M. Boerner, On the estimation of radar
polarization orientation shifts induced by terrain slopes, IEEE Trans. Geosci. Remote Sens. 40 (1) (2002)
30–41.
[35] D. Schuler, J.-S. Lee, G. De Grandi, Measurement of topography using polarimetric sar images, IEEE Trans.
Geosci. Remote Sens. 34 (5) (1996) 1266–1277.
[36] J.S. Lee, M.R. Grunes, E. Pottier, L. Ferro-Famil, Unsupervised terrain classiﬁcation preserving polarimetric
scattering characteristics, IEEE Trans. Geosci. Remote Sens. 42 (4) (2004) 722–731.
[37] I. Hajnsek, E. Pottier, S. Cloude, Inversion of surface parameters from polarimetric sar, IEEE Trans. Geosci.
Remote Sens. 41 (4) (2003) 727–744.
[38] A. Fung, Microwave Scattering and Emission Models and Their Applications, Artech House Remote Sensing
Library, Artech House, 1994. <http://books.google.fr/book s?id=MHxtQgAACAAJ>.
[39] S. Allain, L. Ferro-Famil, E. Pottier, Relevant polarimetric parameters for surface parameter retrieval using
multi-frequency sar data, in: Proceedings of the Fourth International Symposium on Retrieval of Bio- and
Geophysical Parameters from SAR Data for Land Applications, 2004.

References
1243
[40] S. Allain, C.L. Martinez, L. Ferro-Famil, E. Pottier, New eigenvalue-based parameters for natural media
characterization, in: Proceedings of the IGARSS, 2005.
[41] K. Chen, T.-D. Wu, L. Tsang, Q. Li, J. Shi, A. Fung, Emission of rough surfaces calculated by the integral
equation method with comparison to three-dimensional moment method simulations, IEEE Trans. Geosci.
Remote Sens. 41 (1) (2003) 90–101.
[42] P. Leducq, L. Ferro-Famil, E. Pottier, Matching-pursuit-based analysis of moving objects in polarimetric sar
images, IEEE Geosci. Remote Sens. Lett. 5 (2) (2008) 123–127.
[43] F. Gatelli, A. Guamieri, F. Parizzi, P. Pasquali, C. Prati, F. Rocca, The wavenumber shift in sar interferometry,
IEEE Trans. Geosci. Remote Sens. 32 (4) (1994) 855–865.
[44] P. Flandrin, Time-Frequency/Time-Scale Analysis, Academic Press, London, 1999, (Wavelet Anlysis Appl.).
[45] L. Ferro-Famil, W.M. Boerner, E. Pottier, A. Reigber, Analysis of sar response anisotropic behavior using
sub-aperture polarimetric data, in: Proceedings of the POLINSAR, 2003.
[46] L. Ferro-Famil, A. Reigber, E. Pottier, W.M. Boerner, Scene characterization using subaperture polarimetric
sar data, IEEE Trans. Geosci. Remote Sens. 41 (10) (2003) 2264–2276.
[47] A. Yueh, R.T. Shin, J.A. Kong, Scattering from randomly perturbed periodic and quasiperiodic surfaces,
Prog. Electromagnet. Res. 1 (1988) 297–358.
[48] L. Ferro-Famil, A. Reigber, E. Pottier, Nonstationary natural media analysis from polarimetric sar data using
a two-dimensional time-frequency decomposition approach, Can. J. Remote Sens. 31 (1) (2005) 20–29.
[49] J.-C. Souyris, C. Henry, F. Adragna, On the use of complex sar image spectral analysis for target detection:
assessment of polarimetry, IEEE Trans. Geosci. Remote Sens. 41 (12) (2003) 2725–2734.
[50] A. Ferretti, C. Prati, F. Rocca, Permanent scatterers in sar interferometry, IEEE Trans. Geosci. Remote Sens.
39 (1) (2001) 8–20.
[51] R. Schneider, K. Papathanassiou, I. Hajnsek, A. Moreira, Polarimetric and interferometric characterization
of coherent scatterers in urban areas, IEEE Trans. Geosci. Remote Sens. 44 (4) (2006) 971–984.
[52] M. Spigai, C. Tison, J.-C. Souyris, Time-frequency analysis in high-resolution sar imagery, IEEE Trans.
Geosci. Remote Sens. 49 (7) (2011) 2699–2711.
[53] G. Franceschetti, A. Iodice, D. Riccio, G. Ruello, Sar raw signal simulation for urban structures, IEEE Trans.
Geosci. Remote Sens. 41 (9) (2003) 1986–1995.
[54] L. Ferro-Famil, E. Pottier, Urban area remote sensing from l- band polsar data using time-frequency tech-
niques, in: Proceedings Urban Conference 2007.
[55] S. Cloude, Polarization coherence tomography, Radio Sci. 41 (4) (2006) RS4017.
[56] S. Cloude, K. Papathanassiou, Three-stage inversion process for polarimetric sar interferometry, IEE Proc.
Radar Sonar Navig. 150 (3) (2003) 125–134.
[57] S.R. Cloude, Polarisation Applications in Remote Sensing, Oxford University Press, 2009.
[58] K. Papathanassiou, S. Cloude, Single-baseline polarimetric sar interferometry, IEEE Trans. Geosci. Remote
Sens. 39 (11) (2001) 2352–2363.
[59] L. Ferro-Famil, M. Neumann, Y. Huang, Robust estimation of multi-baseline pol-insar parameters for the
analysis of natural environments, in: Proceedings of the EUSAR, 2010.
[60] F. Gini, F. Lombardini, Multibaseline cross-track sar interferometry: a signal processing perspective, IEEE
Aerosp. Electron. Syst. Mag. 20 (8) (2005) 71–93.
[61] P. Stoica, R. Moses, Spectral Analysis of Signals, Prentice Hall, Upper Saddle River, NJ, 2005.
[62] A. Reigber, A. Moreira, First demonstration of airborne sar tomography using multibaseline l-band data,
IEEE Trans. Geosci. Remote Sens. 38 (5) (2000) 2142–2152.
[63] S. Tebaldini, Algebraic synthesis of forest scenarios from multibaseline polinsar data, IEEE Trans. Geosci.
Remote Sens. 47 (12) (2009) 4132–4142.
[64] S. Tebaldini, Single and multipolarimetric sar tomography of forested areas: a parametric approach, IEEE
Trans. Geosci. Remote Sens. 48 (5) (2010) 2375–2387.

1244
CHAPTER 21 Radar Polarimetry Basics
[65] S. Tebaldini, F. Rocca, Multibaseline polarimetric sar tomography of a boreal forest at p- and l-bands, IEEE
Trans. Geosci. Remote Sens. 50 (1) (2012) 232–246.
[66] Y. Huang, L. Ferro-Famil, A. Reigber, Under-foliage object imaging using sar tomography and polarimetric
spectral estimators, IEEE Trans. Geosci. Remote Sens. 99 (2011) 1–13.
[67] F. Gini, F. Lombardini, M. Montanari, Layover solution in multibaseline sar interferometry, IEEE Trans.
Aerosp. Electron. Syst. 38 (4) (2002) 1344–1356.
[68] S. Sauer, L. Ferro-Famil, E. Pottier, A. Reigber, Physical parameter extraction over urban areas using l-band
polsar data and interferometric baseline diversity, in: IEEE International Geoscience and Remote Sensing
Symposium IGARSS 2007, 2007, pp. 1–5.
[69] M. Wax, T. Kailath, Detection of signals by information theoretic criteria, IEEE Trans. Acoust. Speech Signal
Process. 33 (2) (1985).
[70] M. Wax, I. Ziskind, Detection of the number of coherent signals by the mdl principle, IEEE Trans. Acoust.
Speech Signal Process. 37 (8) (1989) 1190–1196.
[71] M. Wax, I. Ziskind, Detection and localization of multiple sources via the stochastic signal model, IEEE
Trans. Signal Process. 39 (11) (1991) 2450–2456.
[72] P. Stoica, K. Sharman, Maximum likelihood methods for direction-of-arrival estimation, IEEE Trans. Acoust.
Speech Signal Process. 38 (7) (1990) 1132–1143.
[73] B. Ottersten, M. Viberg, P. Stoica, A. Nehorai, Radar array processing, in: Exact and Large Sample Approx-
imations of Maximum Likelihood Techniques for Parameter Estimation and Detection in Array Processing,
Springer-Verlag, 1993, pp. 99–151.
[74] P. Stoica, B. Ottersten, M. Viberg, R. Moses, Maximum likelihood array processing for stochastic coherent
sources, IEEE Trans. Signal Process. 44 (1) (1996) 96–105.
[75] M. Viberg, B. Ottersten, Sensor array processing based on subspace ﬁtting, IEEE Trans. Signal Process. 39
(5) (1991) 1110–1121.
[76] Y. Huang, L. Ferro-Famil, 3d characterization of buildings in a dense urban environment using l-band pol-
insar data with irregular baselines, in: Proceedings of the IGARSS, 2009.
[77] Y. Huang, L. Ferro-Famil, C. Lardeux, Polarimetric sar tomography of tropical forest at p-band, in: Proceed-
ings of the IGARSS, 2011.
[78] M. Nannini, R. Scheiber, R. Horn, Imaging of targets beneath foliage with sar tomography, in: Proceedings
of the EUSAR, 2008.
[79] Y. Huang, L. Ferro-Famil, Building height estimation using multibaseline l-band sar data and polarimetric
subspace ﬁtting methods, in: Proceedings of the POLINSAR, 2009.
[80] P. Stoica, A. Nehorai, Performance study of conditional and unconditional direction-of-arrival estimation,
IEEE Trans. Acoust. Speech Signal Process. 38 (10) (1990) 1783–1795.
[81] Y. Huang, L. Ferro-Famil, A. Reigber, Under foliage object imaging using sar tomography and polarimetric
spectral estimators, in: Proceedings of the EUSAR, 2010.

22
CHAPTER
Integrated Sensor Systems
and Data Fusion for Homeland
Protection
Alfonso Farina*, Luciana Ortenzi*, Branko Ristic†, and Alex Skvortsov†
*SELEX Electronic Systems, Rome, Italy
†DSTO, Melbourne, Vic. 3207, Australia
2.22.1 Introduction
As stated by John Naisbitt in his bestseller “Megatrends” [1], published in 1982, about the new trends
and directions transforming our lives: “We are drowning in information but starved for knowledge.
This level of information is clearly impossible to be handled by present means. Uncontrolled and
unorganized information is no longer a resource in an information society, instead it becomes the
enemy.” This successful sentence can be taken as a statement of the problem of information fusion:
how can knowledge, awareness and decision making capability be achieved starting from the available
information?
This chapter is intended as an attempt to technical and mathematical answer to the previous question;
in particular it addresses the application of data and information fusion to the design of integrated
systems in the Homeland Protection (HP) domain. HP refers to the broad civilian and military effort
produced by a Country to protect its territory—including citizens, assets and activities which are vital
and fundamental for its growth and prosperity—against internal and external hazards and to reduce its
vulnerability to attacks, whatever their origin, as well as natural disasters. HP is therefore a wide and
complex domain: systems in this domain are large, to mean that size and scope of such systems are
conspicuous and that system boundaries may not be easy to identify; systems are integrated, to mean
that it is generally not sufﬁcient to study each subsystem in isolation; systems are different in purpose
and require a multidisciplinary approach for their design and analysis.
The design and analysis of such systems devoted to operate in such scenarios are necessarily
required to provide data and information fusion in the most general sense. Information fusion is about
combining, or fusing, information from different sources to provide knowledge that is not evident
from individual sources. Numerous real world problems beneﬁt from the combination of heteroge-
neous information sources, for instance, as depicted in Figure 22.1, multi-sensor data fusion is nat-
urally performed by animals and humans to access more accurately the surrounding environment
and to identify threats or food, thereby improving their chances of survival. The ﬁeld of informa-
tion fusion is commonly characterized as multidisciplinary research area and includes and/or over-
laps with a number of other areas. The information fusion at sensor level includes signal process-
ing; at data level data processing; at meta-data level it overlaps with knowledge representation and,
ﬁnally, at the decision level it involves the decision making capability. Data fusion has been deﬁned
in [2] as “the process of combining evidence to support intelligence generation.” Mainly the methods
Academic Press Library in Signal Processing. http://dx.doi.org/10.1016/B978-0-12-396500-4.00022-3
© 2014 Elsevier Ltd. All rights reserved.
1245

1246
CHAPTER 22 Integrated Sensor Systems and Data Fusion
FIGURE 22.1
Why information fusion. (Kindly provided by Dr. A. Benavoli—IDSIA, Istituto Dalle Molle di Studi
sull’Intelligenza Artiﬁciale, Switzerland.)
employed to achieve this scope can be divided into two general classes: quantitative and qualitative.
The former are based on numerical techniques, the latter ones are based on symbolic representation of
information.
Examples of quantitative methods can be found in stochastic estimation theory, that aim to estimate
the state of a system, using all available information, and to characterize the fusion uncertainty in the
framework of probability theory. Most of the algorithms developed for quantitative fusion are based on
Bayes ﬁlter [3], as Kalman ﬁlter [4], information ﬁlter [5] and neural networks. The application of these
algorithms is employed usually to perform multi-target and multi-sensor tracking. The new generation
methods, applying a qualitative approach, are based on a symbolic representation of information. They
are, of course, based on mathematical models and their output is numeric, however they can be employed
to model qualitative information (e.g., fuzzy). They include expert systems, heuristic, behavioral and
structural modeling. Qualitative methods are based on artiﬁcial intelligence techniques, such fuzzy logic
[6], Dempster-Shafer theory [7,8] Dezert-Smarandache theory [9,10] and rules based-methods.
The ﬁrst data fusion algorithms employed in real systems in the radar ﬁeld go back to the early
seventies, when they had been developed for multi-radar tracking (MRT) for netted sensors. It was
late 1970s, beginning 1980s when these new algorithms and the corresponding means to mitigate
unavoidable sources of errors due to practical world (e.g., the time synchronization, the radar alignment
to the North, the inaccurate knowledge of coordinates of radar sites) were provided. Probably one of
the ﬁrst MRT system for Air Trafﬁc Control (ATC) ever installed was the system operating in the center
and South of Italy [11]. When the competence on tracking was so mature, it was collected in a brand
new book on radar data processing [12,13], translated also in Russian and Chinese.
Later in 1990s further advancements were done in the ﬁeld of multi-sensor fusion for Airborne Early
Warning (AEW) systems, setting up an algorithm suite to track targets on the basis of the data provided
by surveillance radar, an Identiﬁcation Friend or Foe (IFF), an Electronic Support Measurement (ESM)

2.22.1 Introduction
1247
anddatalinks.Afterconceivingalsoalgorithmstotracktargetsonthebasisoftheangleandidentiﬁcation
measurements provided by ESM on a moving platform, data fusion of active and passive tracks was
provided [14–17].
Nowadays concepts have been developed and spread to be applied to very complex systems with
the aim to achieve the highest level of intelligence as possible and hopefully to support decision.
Data fusion is aimed to enhance situation awareness and decision making through the combination of
information/dataobtainedbynetworksofhomogeneousand/orheterogeneoussensors.Asensornetwork
presents advantages over a single sensor under different points of views, as it supplies both redundant and
complementary information. Redundant information is exploited to make the system robust to the failure
in order that a malfunction of an entity of the system means only a degradation of the performances,
rather than the complete failure of the system, since information about the same environment can be
obtained from different sources. More robustness can be achieved also with respect to interferences,
both intentional and unintentional, due to frequency and spatial diversity of the sensors. Complementary
information build up a more complete picture of the observed system; for example sensors are dislocated
over large regions providing diverse viewing angles of observed phenomenon and different technologies
can be employed in the same application to provide improved system performance.
A large number of different applications, algorithms and architectures have been developed exploiting
these advantages. Several examples can be found in robotics, military applications, Homeland Protection
and management of large and complex critical infrastructures. Although the speciﬁc nature of each
problem is different, the ﬁnal goal, from the point of view of the sensed information, is always the same:
using all the available data to better understand the investigated phenomena. The aim of this chapter
is to give an overview of the several approaches that can be followed to design and analyze systems
for Homeland Protection. Different fusion architectures can be drawn on the basis of the employed
algorithms; according to this approach, three general categories can be identiﬁed in the literature [18,19]:
centralized, hierarchical, and decentralized/netcentric.
The traditional architecture is centralized: in this framework several sensing devices are connected
to a central component, the fusion node. For example, in the case of a sensor network employed for
the surveillance of an area, usually the information trafﬁc goes from the sensor nodes to a single
sink node called information fusion center. According to the information received from the sensors,
the fusion center monitors the area where the sensors are deployed and decides the actions to take.
Conceptually, the algorithms employed in this case are relatively simple and the resource allocation is
straightforward because the central component has an overall view of the whole system. This kind of
architecture presents several drawbacks: high computational load, the possibility of catastrophic failure
when the fusion node goes down and the lack of ﬂexibility to changes of the system and sensor entities.
Therefore this approach is still valid if the number of sensors, whose information is fused, independently
of the width of the area to be monitored, is limited and also the relationship and interconnections among
sensors are limited too.
In hierarchical architectures, there are several fusion nodes, where intermediate fusion processes
are performed, and an ending central fusion node. The principle of a hierarchy is to reduce the com-
munications and computational loads of centralized systems by distributing data fusion tasks among a
hierarchy of sensor entities. However in a hierarchy there is still a central component acting as a fusion
center. Entities constituting local fusion center, locally process information and send it to the cen-
tral fusion node. This approach is commonly used in robotics and surveillance applications. Although
this architecture reduces the computational and communication loads, there are still some drawbacks

1248
CHAPTER 22 Integrated Sensor Systems and Data Fusion
connected to the centralized model. In addition to these problems, there are some disadvantages related
to the resource allocation balancing and the vulnerability to communication bottlenecks.
In certain cases the traditional data fusion algorithms may still be valid; however, in some cases
the great variety of sub-systems and the complexity of interconnections may require new approaches.
Most of the drawbacks of centralized and hierarchical architectures can be overcame by decentralized
architectures. The trend in surveillance today is towards Network Centric Operation (NCO) [20]. The
vision for NCO is to provide seamless access to timely information to all operators (e.g., soldier, ofﬁcer)
and decision-makers at every echelon in the military hierarchy. The goal is to enable all elements,
including individual infantry soldiers, ground vehicles, command centers, aircraft and naval vessels, to
share the collected information and to combine it into a coherent, accurate picture of the battleﬁeld.
The same approach can be followed in the organization of a sensor network. In recent years the
decreasing sensor cost and the development of telecommunication technology have made possible the
deployment of networks with a huge number of sensors; in this case the use of information fusion centers
is unpractical. Consequently a new class of sensor networks, whose way of functioning is called network
centric, has emerged. These networks do not have a fusion center and their functioning is based on the
information exchange between near-by sensors. Under this approach the information can be considered
as a property of the network rather than of the own sensor. This solution is strongly advocated for its
robustness and ease of implementation, but it might suffer when the number of sensors grows very
much. It has a broad range of potential applications in the ﬁeld of Homeland Protection: surveillance of
habitat and environmental monitoring, structural monitoring (e.g., bridges), contaminants, smart roads,
intruder detection, battleﬁeld. It is complementary to the classical surveillance with few large-costly
sensors hierarchically organized.
The network of numerous sensors and communication nodes (for instance: peer to peer networks)
may have link topology varying with time due to natural interferences, electromagnetic propagation
masked by the terrain surface, meteorological conditions, dust and smoke which might be present in
the environment, allowing therefore modularity, robustness and ﬂexibility. These networks should be
designed to be resilient to Electronic Counter Measures (ECM), cyber attacks and should be able to
manage increasing and highly variable ﬂow of data. The satisfaction of such demanding requirements,
maintaining however the limitation of resources such as energy, bandwidth and node complexity, can
be achieved borrowing from biological systems several mechanism. For example bio-inspired sensor
networks employ decentralized decisions through the self-synchronization mechanism observed in
naturethatallowsforcingeverysinglenodeofthenetworktoreachthegloballyoptimaldecision,without
the need of any fusion center. However there are also drawbacks associated to these architectures: in
fully decentralized systems, communication issues are more complex and depend on the topology of
the network; generally, communication overheads are higher than in centralized systems.
In this chapter these aspects will be investigated in depth for networks respectively of homogeneous
and heterogeneous sensors with the description of real study cases applied to real world problems
of Homeland Protection. In particular the possibility of netting different sensors operating with dif-
ferent characteristics of domain, coverage, frequency and resolution allows a multi-scale1 approach.
1In engineering, mathematics, physics, meteorology and computer science, multi scale modeling is the ﬁeld of solving
physical problems which have important features at multiple scales, particularly multiple spatial and (or) temporal scales.
(http://en.wikipedia.org/wiki/Multiscale_modeling).

2.22.2 The Problem of Homeland Protection
1249
This approach is particularly suitable for the surveillance of wide areas such as national borders or
critical strategic regions.
The chapter is organized as follows: Section 2.22.2 illustrates the Homeland Protection domain and
highlights some of the characteristics of systems in this speciﬁc domain; Section 2.22.3 brieﬂy reviews
the development of data fusion and gives references to new emerging trends in the domain of high
level data fusion. Section 2.22.4 gives a broad and very general description of the basic categories of
intelligence that are the source of data and information employed to perform the fusion process. The
Sections 2.22.5 and 2.22.6 tackle different aspects related to homogeneous sensor networks. The former
proposes several issues from a theoretical point of view, illustrating, next to traditional approaches,
the new trends of Collaborative Signal and Information Processing (CSIP), self-organizing and self-
synchronizing sensor network; Section 2.22.5 proposes also some remarks about real applications and
the need to rethink some mathematical algorithms to overcome the network centric approach. The latter,
Section 2.22.6, proposes three real study cases where the novel approaches give signiﬁcant results.
Likewise Section 2.22.7 tackles the aspects related to heterogeneous sensor networks, dealing with the
problems of deployment, behavior assignment and coordination of the different sensors. Also in this
case a special attention is focused on the mathematical issues related to these new approaches. Real
applications of this kind of sensor networks are described in Sections 2.22.8 and 2.22.9, respectively for
the border control problem and the forecasting and estimation of an epidemics. Finally Section 2.22.9,
with the concluding remarks, follows.
2.22.2 The Problem of homeland protection
The diagram of Figure 22.2 provides a decomposition of the Homeland Protection domain: the two
main sub-domains are Homeland Defense (HD) and Homeland Security (HS) [21].
HD includes the typical duties and support systems of military joint forces and single armed forces.
Usually HD systems are strictly military, are employed by military personnel only, satisfy speciﬁc
technical requirements, operational needs and environmental scenarios, and in most cases are designed
to face only military threats. The new trend aims to employ military surveillance systems in combined
military and civil operations, especially to face terrorism [22]. The military domain has also been swept
in recent years by the NCO paradigm; NCO predicates a tighter coupling among forces, especially in the
cognitive domain, to achieve synchronization, agility and decision superiority and it is a strong driver
in the transformation from a platform-centric force to a network-centric force [20].
HS is a very broad and complex domain that requires coordinated action among national and local
governments, private sector and concerned citizens across a country; it covers issues such as crisis
management, border control, critical infrastructure protection and transportation security [23,24]. Crisis
management is the ability of identifying and assessing a crisis, planning a response, and acting to resolve
the crisis situation. Border control aims to build a smart protection belt all around a country to counter
terrorism and illegal activities; yet it is not resolutive due to the difﬁculty of controlling the country
boundaries along their full and variegated extension, the non necessarily physical nature of attacks in the
current information age, and the threats which often arise internally to the country itself. HS includes
also land security that is particularly critical because of its complexity and strategic importance; the
security of critical assets, such as electric power plants, communication infrastructures, strategic areas
and railway networks, must be ensured continuously in space and time [25–27]. The most recent terrorist

1250
CHAPTER 22 Integrated Sensor Systems and Data Fusion
FIGURE 22.2
Homeland Protection domain. (From [21], reprinted with permission.)
attacks have shown the vulnerability of national critical infrastructures [28] and have made the world
aware of the possibility of large-scale terrorist offensive actions against civil society: the September
11th, 2001 attack on the World Trade center in New York City is the most dramatic example of this
new terrorism. The main emphasis has been put on the terrorist threat, but what emerges is the fragility
and vulnerability of modern society to both deliberate threats and natural disasters. Figure 22.3 shows a
SyntheticApertureRadar(SAR)imagecollectedbyasatelliteoftheItalianCosmoSkyMedconstellation
of the area of the Fukushima nuclear plant hit in 2011 by the tsunami.
The HP domain includes also the protection from deliberate attacks against the commercial activities
of a Country led also out of the national territory, comprehensive also of the territorial waters and
Exclusive Economic Zone (EEZ). Seaborne piracy against transport vessels remains a signiﬁcant issue
(with estimated worldwide losses of US$13–16 billion per year), particularly in the waters between the
Red Sea and Indian Ocean, off the Somali coast, and also in the Strait of Malacca and Singapore, which
are navigated by over 50,000 commercial ships a year [29,30].
The globalization, the pervasiveness of information technologies and the transformation of the indus-
trial sector and civil society have created new vulnerabilities in the system as a whole, but all this has
happened without a corresponding effort to increase its robustness and security. As an example, single
infrastructure networks have grown over the years independently, creating autonomous “vertical” sys-
tems with limited points of contact; around year 2000, as a consequence of the change of trend in the

2.22.2 The Problem of Homeland Protection
1251
FIGURE 22.3
A CosmoSkyMed SAR image of Fukushima nuclear plant zone after the tsunami 2011 showing the ﬂooded
areas. (Courtesy of E-geos, a Telespazio Company.)
socio-techno scenario, the infrastructures have begun to share services and thus to create interconnected
and interdependent systems. Nowadays infrastructures are interconnected and mutually dependent in
a complex way: a phenomenon that affects one infrastructure can have a direct or indirect impact on
other infrastructures, spreading on a wide geographical area and affecting several sectors of the citizen
life. This is schematically represented in Figure 22.4 [31,32].
Beside the physical protection of territory, citizens, critical assets and activities, the security of
information and computer systems is one the greatest challenges for a Country. Information and com-
munication technologies have enhanced the efﬁciency and the comfort of the civil society on one hand,
but added complexity and vulnerability on the other hand. The cyber security consists in ensuring
the protection of information and property from hackers, corruption, or natural disaster, maintaining
however the information and property accessible and productive to its intended users. This problem is
pervasive in nearly all the systems supporting a nation: ﬁnancial, energy, healthcare and transportation.
The new trend toward the mobile communications is revealing a new cyber vulnerability, for instance
the sheer mass of mobile endpoints gives more protection to hackers leading a cyber attack starting
from a mobile. Therefore, the mobile infrastructure is becoming a critical infrastructure as well [33].
Nowadays the challenge is to understand this new scenario and to address the use of new and efﬁcient
algorithms for the information fusion in the domain of large integrated systems [34]. To integrate
such heterogeneous information the necessity emerges to develop new algorithms of data fusion and
information fusion to achieve an operational picture. In such scenario, where the attack can be lead
with unconventional manners, information of heterogeneous sources, despite appearing uncorrelated,

1252
CHAPTER 22 Integrated Sensor Systems and Data Fusion
FIGURE 22.4
Interdependencies between present infrastructures. (From [31], reprinted with permission.)
can be related and hence exploited by its fusion. Therefore particular attention is due to the information
sources; Section 2.22.4 is devoted to this aspect of the problem, giving an overview of the sensors and
the systems that traditionally provide information.
2.22.3 Deﬁnitions and background
Before addressing in more detail the topic of data fusion applied to the domain of Homeland Protection,
it is useful to brieﬂy review the evolution of data fusion and, more recently, the deﬁnition of the new
paradigms and the introduction to high-level data fusion and information fusion.
A deﬁnition of data fusion is provided in [35]: “Data fusion is a process that combines data and knowl-
edge from different sources with the aim of maximizing the useful information content, for improved
reliability or discriminant capability, while minimizing the quantity of data ultimately retained.” Another
deﬁnition is provided by the Joint Directors of Laboratories (JDL) Data Fusion Subpanel (DFS) which,
in its latest revision of its data fusion model, Steinberg and Bowman [36] settle with the following
short deﬁnition: “Data fusion is the process of combining data or information to estimate or predict
entity states.” Due to its generality, the deﬁnition of JDL encompasses the previous one. One aspect
of the data fusion process, which is not included in the ﬁrst deﬁnition and is implicit in the second,
is process reﬁnement, i.e., the improving of data fusion process and data acquisition. Many authors,

2.22.3 Deﬁnitions and Background
1253
recognize process reﬁnement and data fusion to be so closely coupled that process reﬁnement should
be considered to be a part of the data fusion process. This is not a new technique in itself, rather a
framework for incorporating reasoning and learning with perceived information into systems, utilizing
both traditional and new areas of research. These areas include decision theory, management of uncer-
tainty, digital signal processing, and computer science. The data fusion process comprises techniques
for data reduction, data association, resource management, and fusion of uncertain, incomplete, and
contradictory information.
In 1986, an effort to standardize the terminology related to data fusion began and the JDL data
fusion working group was established. The result of that effort was the conception of a process model
for data fusion and a data fusion lexicon. The so-called JDL fusion model [37] is a functional model,
developed to overcome potential confusion in the community and to improve communications among
military researchers and system developers. The model provides a common frame of reference for
fusion discussions and to facilitate understanding and recognizing the problems where data fusion is
applicable. The ﬁrst issue of the model, dated 1988, provided four fusion levels:
•
level 1: Object reﬁnement,
•
level 2: Situation reﬁnement,
•
level 3: Threat reﬁnement,
•
level 4: Process reﬁnement.
In 1998 Steinberg et al. [38] revised and expanded the JDL model to broaden the functional
model and related taxonomy beyond the original military focus. They introduced a level 0 to the
model for estimation and prediction of signal/object observable states on the basis of pixel/signal-level
data association and characterization. They also suggested renaming and re-interpretation of level 2
and level 3 to focus on understanding the external world beyond military situation and threat focus.
Figure 22.5 reports a block diagram representing this functional model. Although originally developed
for military applications, the model is generally applicable. Furthermore, the model does not assume its
functions to be automated, they could equally well be maintained by human labor. Hence, the model is
both general and ﬂexible. The revised JDL model levels specify logical separations in the data fusion
process and divide information into different levels of abstraction depending on the kind of information
they produce, where the lower levels yield more speciﬁc, and the higher more general, information. The
model is divided into the following ﬁve levels [18]:
•
Level 0—sub-object assessment: the pre-detection activities such as pixel or signal processing, spatial
or temporal registration is present. Level 0 deals with the estimation and prediction of signal/object
observable states on the basis of pixel/signal level data association and characterization.
•
Level 1—object assessment: is concerned with estimation and prediction of target locations, behav-
ior or identity. In this level, which is sometimes referred to as multi-sensor data fusion or multi-
sensor integration, data is combined to assign dynamic features (e.g., velocity) as well as static
(e.g., identity) to objects, hence adding semantic labels to data. This level includes techniques for
data association and management of objects (including creation and deletion of hypothesized objects,
and state updates of the same). Level 1 addresses the following functions: data alignment, data/object
correlation, object positional/kinematic/attribute estimation, object identity estimation.

1254
CHAPTER 22 Integrated Sensor Systems and Data Fusion
FIGURE 22.5
JDL model. (From [40], reprinted with permission.)
•
Level 2—situation assessment: investigates the relations among entities such as force structure
and communication roles. This level involves aggregation of level 1 entities into high-level, more
abstract entities, and relations between entities. An entity in this level might be a pattern of connected
objects of level 1 entities. Input data are assessed with respect to the environment, relationship among
level 1 entities, and entity patterns in space and time. Level 2 addresses the following functions:
object aggregation, contextual interpretation/fusion, event/activity aggregation, multi-perspective
assessment.
•
Level 3—impact assessment: outlines sets of possible courses of action and the effect on the cur-
rent situation. The impact assessment, which is sometimes called signiﬁcance estimation or threat
reﬁnement, estimates and predicts the combined effects of system control plans and the entities of
level 2 (possibly including estimated or predicted plans of other environment agents) on system
objectives. Level 3 addresses the following functions: estimate/aggregate force capabilities, predict
enemy intent, identify threat opportunities, estimate implications, multi perspective assessment.
•
Level 4—process reﬁnement: is an element of Resource Management used to close the loop by
re-tasking resources to support the objectives of the mission. Process reﬁnement evaluates the per-
formance of the data fusion process during its operation and encompasses everything that reﬁnes
it, e.g., acquisition of more relevant data, selection of more suitable fusion algorithms, optimization
of resource usage with respect to, for instance, electrical power consumption. Process reﬁnement
is sometimes called process adaption to emphasize that it is dynamic and should be able to evolve
with respect both its internal properties and the surrounding environment. The function of this level

2.22.3 Deﬁnitions and Background
1255
FIGURE 22.6
JDL model including level 5. (From [40], reprinted with permission.)
is in some literature handled by a so called meta-manager or meta-controller. It is also rewarding
to compare level 4 fusion to the concept of covert attention in biological vision which involves,
e.g., sifting through an abundance of visual information and selecting properties to extract. Level
4 addresses the following functions: evaluation (real-time control/long term improvement), fusion
control, source requirements, mission management.
The 1998 revised JDL fusion model recognized the original Process Reﬁnement level 4 function
as a Resource Management function. In 2002, a level 5 was added [39,40], named User Reﬁnement,
into the JDL model to support a user’s trust, workload, attention, and situation awareness. Mainly the
level 5 was added to distinguish between machine-process reﬁnement and user reﬁnement of either
human control action or the user’s cognitive model. In many cases the data fusion process is focused
on the machine point of view, however a full advantage can be taken by considering also the human
factor, not only as a qualiﬁed expert to reﬁne the fusion process, but also as a costumer for whom the
fusion system is designed. Figure 22.6, taken from [40], shows the JDL fusion model including also the
level 5.
Later in [41] also a level 6, Mission Management, was added; this level tackles the adaptive deter-
mination of spatial-temporal control of assets (e.g., airspace operations) and route planning and goal
determination to support team decision making and actions (e.g., theater operations) over social, eco-
nomic, and political constraints.
Figure 22.7 shows a multi-sensor data fusion architecture with a representation of the levels involved
into each process of data fusion. Level 0 and level 1 concern the combination of data from different

1256
CHAPTER 22 Integrated Sensor Systems and Data Fusion
FIGURE 22.7
Data fusion architecture.
sensors, level 2 and level 3 are often referred to as information fusion. Under the proposed partitioning
scheme, the same entity can simultaneously be the subject of level 0, 1, 2, and 3 fusion processes. Entity
features can be estimated from one or more entity signal observations (e.g., pixel intensities, emitter
pulse streams) via a level 0 data preparation/association/estimation process. The identity, location,
track and activity state of an entity (whether it be a man, a vehicle, or a military formation) can be
estimated on the basis of attributes inferred from one or more observations; i.e., via a level 1 data
preparation/association/estimation process. The same entity’s compositional or relational state (e.g., its
role within a larger structure and its relations with other elements of that structure) can be inferred
via level 2 processes. Thus, a single entity—anything with internal structure, whether man, machine,
or mechanized infantry brigade—can be treated either as an individual, subject to level 1 observation
and state estimation—or as a “situation,” subject to compositional analysis via level 2 entity/entity
association and aggregate state estimation. The impact of a signal, entity, or situation on the user goal
or mission can then be predicted based upon an association of these to alternative courses of action for
each entity via a level 3 process.
There are also other fusion models developed on the basis of different perspectives, including a
purely computational and a human information processing. In the following an overview of different
models [42].
The DIKW (Data Information Knowledge and Wisdom) [43] hierarchy organizes data, information,
knowledge, and wisdom in layers with an increasing level of abstraction and addition of knowledge,

2.22.3 Deﬁnitions and Background
1257
starting from the bottommost data layer. The hierarchy can be considered alike the JDL data fusion
model because both start from raw transactional data to yield knowledge at an increasing level of
abstraction.
The JDL model and many other computational models do not simulate the complex human cognitive
process that leads to “become aware,” because they do not model the fusion process from a human
perspective. In 1988, Endsley deﬁned the situation awareness as “the perception of the elements in the
environment within a volume of time and space, the comprehension of their meaning, and the projection
of their state in the near future” [44]. In [45,46] he identiﬁed three levels of situation awareness,
namely perception, comprehension, and projection, parallel to the corresponding levels in the JDL
model. Therefore the levels in the JDL model can be considered as processes producing results to
help a human operator became aware of the situation. In [47] in addition to this three different aspects
identiﬁed by Endsley, the model included also “intention” (i.e., the understanding of own options
and courses of action relative to own goals) and “metacognition” (i.e., accounting for how reliable own
situation awareness is likely to be). These levels summarize the fact that situation awareness requires the
understanding of information, events, and the impact of own actions on own goals and objectives. This
process involves several capabilities as learning, detection of anomalies, prediction of future behaviors,
managing uncertainty, and analysis of heterogeneous sources.
The OODA (Observe-Orient-Decide-Act) loop, developed by Boyd in 1987 [48], is one of the ﬁrst
C4I (Command, Control, Communications, Computers, and Intelligence) architectures and it represents
the classic decision-support mechanism in military information operations. Because decision-support
systems for situational awareness are tightly coupled with fusion systems, the OODA loop has also been
used for sensor fusion [49]. Observations in OODA refer to scanning the environment and gathering
information from it; orientation is the use of the information to form a mental image of the circumstances;
decision is considering options and selecting a subsequent course of action; and action refers to carrying
out the conceived decision. Bedworth and O’Brien [50] report a comparison of the OODA loop to the
levels of the JDL model.
The human information processing can be modeled by the Rasmussen model [51,52]. It is composed
of three layers, namely skill-based, rule-based, and knowledge-based processing. The input of the
process is a perception (e.g., the detection of a target by a sensor) and the output is an action. An
example of result at the ﬁrst level may be represented by the automatic identiﬁcation of a tank by
processing of row sensors data; at the next level an enemy unit composition can be indentiﬁed on the
basis of its number and relative locations. Knowledge-based behavior represents the most complex
cognitive processing used to handle novel, complex, situations where no routine or rule is available to
manage situations. An example of this type of processing may be the interpretation of unusual behavior,
and the consequent generation of a course of actions based on enemy unit size and behavior.
The Generic Error modeling System (GEMS) [53] is an extension of Rasmussen’s approach, which
describes the competencies needed by workers to perform their roles in complex systems. GEMS
describes three major categories of errors: skill-based slips and lapses, rule-based mistakes, and
knowledge-based mistakes.
Table 22.1, from [42], shows a correspondence, and not a comparison, among levels and layers of
various models presented before. This table is intended as a guide to identify the components of a data
fusion architecture, where the separation between the columns is not so sharp. Notice that the JDL
model does not explicitly model into a level the action consequent to the threat assessment. The action

1258
CHAPTER 22 Integrated Sensor Systems and Data Fusion
Table 22.1 Comparison Among Fusion Models (From [42], Reprinted with Permission)
JDL Data
Level 1 =
Level 2 =
Level 3 =
Action
Level 4 =
Fusion Model
Object
Situation
Threat
(Not Explicit In
Process
Assessment
Assessment
Assessment
The JDL Model)
Reﬁnement
Knowledge
pyramid
Data
Information and
knowledge
Knowledge
Wisdom
n/a
Situation
awareness
Perception
Comprehension
Projection
Decision
n/a
OODA loop
Observe
Orient
Decide
Act
n/a
Information
processing
hierarchy
Skill/rule-based
processing
Rule/knowledge-
based
processing
Rule/knowledge-
based
processing
n/a
n/a
level, with the sense of a reaction is only in part included in the process reﬁnement level 4, for this
reason the column “action” has been inserted in the table, to allow a more clear correspondence with
the other models that explicitly account for the reaction. The JDL model is the one that allows the most
global view of the data fusion process from an operative perspective: there is not any correspondence
of the other models with JDL level 4.
2.22.4 The information sources
This section gives a broad and very general description of the basic categories of intelligence that are
the source of data/information employed to perform the fusion process. The USAF (United States Air
Force) in 1998 ﬁrst and the ODNA (Ofﬁce of Directors of National Intelligence) later in 2008 described
in their studies that there are six basic intelligence categories [54,55]:
•
Signals Intelligence (SIGINT),
•
Imagery Intelligence (IMINT),
•
Measurement and Signature Intelligence (MASINT),
•
Human Intelligence (HUMINT),
•
Open-Source Intelligence (OSINT),
•
Geospatial Intelligence (GEOINT).
In addition, there is also Scientiﬁc and Technical (S&T) Intelligence resulting from the analysis of
foreign scientiﬁc and technical information. In the following is an overview of the categories.
SIGINT is achieved by the interception/detection of electromagnetic (em) emissions. SIGINT
includes Electronic Intelligence (ELINT) and Communications Intelligence (COMINT). The former
derives from the processing and analysis of em radiation emitted from emitters, in most of cases radars,
not employed for communications, other than nuclear detonations or radioactive sources. An emitter
may be related closely to a speciﬁc threat. The information that can be achieved by a typical ESM (Elec-
tronic Support Measures) device consists of an estimate of the emitter category, location, with a certain
accuracy, and various electronic attributes, such as frequency and pulse duration. This information can

2.22.5 Homogeneous Sensor Networks
1259
be employed in a high-level fusion process. COMINT derives from the processing and analysis of
intercepted communications from emitters. The communications may be encrypted and they may be of
several forms such as voice, e-mail, fax and the like.
IMINT is obtained by sensors working in several bandwidths which are able to produce a view of the
scenario or of the speciﬁc target: electro/optical sensors, infrared, radar (e.g., Synthetic Aperture Radar
(SAR) and Inverse SAR (ISAR), and Moving Target Indicator (MTI)), laser, laser radar (LADAR), and
multi-spectral sensors. Each sensor has a unique capability. Some work in all weather conditions, some
may work also in night conditions, and some produce high-quality images with detectable signatures.
MASINT is obtained by the collection and the analysis of several and heterogeneous sensors and
instruments usually working in different regions or domains of the em spectrum, such as infrared or mag-
netic ﬁelds. MASINT includes Radar Intelligence (RADINT), Nuclear Intelligence (NUCINT), Laser
Intelligence (LASINT), and Chemical and Biological Intelligence (CBINT). RADINT, for example,
is a specialized form of ELINT, which categorizes and locates as active or passive collection of energy
reﬂected from a target.
HUMINT is the collection of information derived by the human contact. Information of interest might
include target name, size, location, time, movement, and intent. HUMINT typically includes structured
text (e.g., tables, lists), annotated imagery, and free text (e.g., sentences, paragraphs). HUMINT provides
comprehension of adversary actions, capability and capacity, plans and intentions, decisions, research
goals and strategies.
OSINT is publicly available information appearing either in print or in electronic form including
radio, television, newspapers, journals, the Internet, commercial databases, videos, graphics, and draw-
ings. OSINT can be considered as a complement to the other intelligence categories and can be used
to ﬁll gaps and improve accuracy and conﬁdence in classiﬁed information. A special mentioning is for
the Internet, that, with its blogs, e-mails, videos, messages and mobile systems, favors an ever greater
interaction between users. Moreover notice that there is a little overall planning in the development of
the World Wide Web, but rather a myriad of initiatives by individuals of small groups. Government
have always tried to use telephone tapping, surveillance, ﬁles, i.e., intelligence. Now this is possible on
a different scale given the technical possibilities offered by satellites, mobile, phones, credit cards man-
agement systems, information storage, etc. From the topological point of view, Internet is a scale-free
complex network with a power-law of the distribution of the nodes [56]; this technical remark should
be considered in the data exploitation analysis.
GEOINT is the analysis and the visual representation of the activities on the earth related to the
security achieved by the sensors (radar, optical, IR, multispectral) deployed in the space. The information
related to GEOINT is obtained through an integration of imagery, imagery intelligence, and geospatial
information.
2.22.5 Homogeneous sensor networks
Stand-alone sensors usually provide a fragmentary view of a complex situation of interest. A signiﬁcant
enhancement of performance can therefore be accomplished by a combination of networked sensors
in the close vicinity to the region of interest. Using efﬁcient methods of centralized or decentralized

1260
CHAPTER 22 Integrated Sensor Systems and Data Fusion
multiple sensor fusion, the quality of the produced situation picture can signiﬁcantly be improved. In
practice, improvements with respect to the following aspects are of interest:
•
production of accurate and continuous tracks (e.g., objects, persons, single vehicles, group objects),
•
system reaction rates (e.g., track extraction, detection of target maneuvers, track monitoring),
•
sustainment of reconnaissance capabilities in case of either system or network failures (e.g., graceful
degradation),
•
system robustness against jamming and deception,
•
compensation of degradation effects (e.g., sensor misalignment, limited sensor resolution),
•
robustness against sub-optimal real-time realizations of sensor data fusion algorithms,
•
processing of eventually delayed sensor data (e.g., out-of sequence measurements).
In the following, several sections tackle different aspects related to homogeneous sensor networks.
2.22.5.1 Sensor conﬁguration
Sensor fusion networks can be categorized according to the type of sensor conﬁguration. Durrant-Whyte
distinguishes three types of sensor conﬁguration as schematized in Figure 22.8 [57,58].
FIGURE 22.8
Sensors conﬁguration (from [57], reprinted with permission).

2.22.5 Homogeneous Sensor Networks
1261
Competitive sensor data fusion: Sensors are conﬁgured competitive if each sensor delivers independent
measurements of the same property. Sensor data represent the same attribute, and the fusion is to
reduce uncertainty and resolve conﬂicts. Competitive sensor conﬁguration is also called a redundant
conﬁguration. Sensors S1 and S2 in Figure 22.8 represent a competitive conﬁguration, where both
sensors redundantly observe the same property of an object in the environment space.
Complementary sensor data fusion: A sensor conﬁguration is called complementary if the sensors do not
directly depend on each other, but can be combined to give a more complete image of the phenomenon
under observation. Fusion of the sensor data provides an overall and complete model. Examples for a
complementary conﬁguration is the employment of multiple cameras each observing disjoint parts of a
room, or using multiple spectrum signatures to identify a land cover type, or using different waveform
to identify an aircraft type. Sensor S2 and S3 in Figure 22.8 represent a complementary conﬁguration,
since each sensor observes a different part of the environment space.
In both competitive and complementary sensor conﬁgurations, there is an improvement of the accu-
racy of the target characteristics estimation consequent to the data fusion. In their seminal work H.
Cramer and C.R. Rao found how to compute the best theoretical accuracy that can be achieved by an
estimator. The lower bound of accuracy, i.e., the mean square error of any unbiased estimator, is given by
the inverse of the so-called Fisher Information Matrix (FIM). The computation of the CRLB (Cramer-
Rao Lower Bound) applies to problems involving the maximum likelihood estimation of unknown
constant parameters from noisy measurements [59]. The best achievable improvement of target loca-
tion and track accuracy can be quantiﬁed by the reduction of the CRLB consequent to the track fusion. In
[60] this computation is reported in case of fusion of data from two sensors with an ideal unitary detec-
tion probability. In [61,62] the same computation has been proposed in case of detection probability
less than one and false alarm probability higher than zero.
Cooperative sensor data fusion: A cooperative sensor network uses the information provided by two
independent sensors to derive information that would not be available from the single sensors. An
example for a cooperative sensor conﬁguration is stereoscopic vision: by combining two-dimensional
images from two cameras at slightly different viewpoints a three-dimensional image of the observed
scene is derived. Cooperative sensor fusion is the most difﬁcult to design, because the resulting data are
sensitive to inaccuracies in all individual participating sensors. Thus, in contrast to competitive fusion,
cooperative sensor fusion generally decreases accuracy and reliability. Sensor S4 and S5 in Figure 22.8
represent a cooperative conﬁguration. Both sensors observe the same object, but the measurements are
used to form an emerging view on object C that could not have been derived from the measurements of
S4 or S5 alone.
These three categories of sensor conﬁguration are not mutually exclusive. Many applications imple-
ment aspects of more than one of the three types. An example for such a hybrid architecture is the
application of multiple cameras that monitor a given area. In regions covered by two or more cameras
the sensor conﬁguration can be competitive or cooperative. For regions observed by only one camera
the sensor conﬁguration is complementary.
2.22.5.2 Classical approach to surveillance
Sensor networks have countless applications, for example, we mention the sensor networks used in
computer science and telecommunications, in biology, where they can be used to monitor the behavior
of animal species such as birds or ﬁshes, and in habitat monitoring, where they can be used to provide

1262
CHAPTER 22 Integrated Sensor Systems and Data Fusion
real-time rainfall and water level information used to evaluate the possibility of ﬂooding. In the ﬁeld of
Homeland Protection one of the main task to be assigned to a sensor network is the surveillance with its
most general signiﬁcance. Automatic surveillance is a process of monitoring the behavior of selected
objects (targets and/or anomalies) inside a speciﬁc area by means of sensors. A target generally consists
of an object (e.g., a tank close to a land border or a rubber approaching to the coast) whose presence
and characteristics can be detected and estimated by the sensor; an anomaly consists in a non usual
behavior (e.g., a jeep moving off-road, the increasing of the radioactivity level within an area) that can
be revealed by the sensor. Sensors typically provide the following functions:
•
detection of a targets or anomalies inside the surveillance area,
•
estimation of target position or the anomaly localization and extension,
•
monitoring of the target kinematic (tracking) or of the anomaly behaviors,
•
classiﬁcation and/or recognition of the targets.
To perform the previous functions, the sensors can be organized on the bases of several approaches.
The classical approach to surveillance of wide areas is based on the use of a single or few sensors
with long range capabilities. The signal received by the single sensor is processed by means of suitable
digital signal processing subsystems. In this case the sensors are costly, with adequate computation
and communication capabilities. Sensors are normally located in properly selected sites, to mitigate
terrain masking problems; nevertheless, they provide different performance depending on the location
of target inside the surveillance area. Typical sensors are radars (ground-based, air-borne, ship-borne or
space-based), infrared or TV cameras, seismic, acoustical, radioactive sensors. Usually in this kind of
networks, as represented in Figure 22.9, the information trafﬁc goes from the sensor nodes to a single
Sensor 1
Sensor 2
Sensor N
DATA FUSION
(object 
localization and 
tracking)
SENSOR 
MANAGEMENT 
and RESOURCE 
ALLOCATION 
Communication channel
State estimate
and accuracy
Predictive information
FIGURE 22.9
Block-diagram for optimal system resource management in a sensor network.

2.22.5 Homogeneous Sensor Networks
1263
sink node called information fusion center that performs the target localization and tracking. According
to the information received from the sensors the fusion center monitors the area where the sensors are
deployed and decides, on the basis of the state estimates and their accuracy (e.g., a covariance matrix
for a Kalman ﬁlter or a particle cloud for a particle ﬁlter) the actions to take.
In [63] an example of high-performance radar netted for Homeland Security application with a
centralized data fusion process is described. The same classical approach is presented in [64] where this
kind of sensor network is employed for natural resource management and bird air strike hazard (BASH)
applications.
However if an intruder reaches and neutralizes the fusion center, the communication between the
network nodes are interrupted and the whole network is exposed to the risk of becoming useless as a
network even if the individual sensors may still be all working.
2.22.5.3 Collaborative signal and information processing (CSIP)
Nowadays, a novel approach to the automatic surveillance has been adopted; it is based on the use
of many sensors with short range capabilities, low costs, and limited computation and communication
capabilities. In case of a huge number of sensors, the use of information fusion centers is unpractical
and their functioning is based on the information exchange between “near-by” sensors. The sensors
can be distributed in ﬁxed positions of the territory, but they could also be deployed adaptively to
the change of the scenario. There are several approaches: they can be randomly distributed inside the
surveillance area and if the number of sensors is high, the performance of the surveillance system can
be considered independent of the location of the targets; then the signal received by each sensor is
processed using the computational capabilities of a sub-portion of the sensor system and employed to
re-organize dynamically the network. Sensors may be agile in a variety of ways, e.g., the ability to
reposition, point an antenna, choose sensing mode, or waveform. Notice that the number of potential
tasking of the network grows exponentially with the number of sensors. The goal of sensor management
in a large network is to choose actions for individual sensors dynamically so as to maximize overall
network utility. This process is called Collaborative Signal and Information Processing (CSIP) [65].
One of the central issues for CSIP to address is energy-constrained dynamic sensor collaboration:
how to dynamically determine who should sense, what needs to be sensed, and who the information
must be passed onto. This kind of processing system allows a limitation in the consumption of power.
Applying a surveillance strategy which accounts for the target tracking accuracy and the sensor random
location, only a limited number of sensors are awake and follow/anticipate the target movement; thus,
the network self-organizes to detect and track the target, allowing an efﬁcient performance from the
energetic point of view with limited sensor prime power and with a reduced number of sensors working
in the whole network. For example in [66], instead of requesting data from all the sensors, the fusion
center iteratively selects sensors for the target localization: ﬁrst a small number of anchor sensors send
their data to the fusion center to obtain a coarse location estimate, then, at each step a few non-anchor
sensors are activated to send their data to the fusion center to reﬁne the location estimate iteratively.
Moreover the possibility to actively probe certain nodes allows to disambiguate multiple interpretations
of an event.
In [67] the techniques of information-driven dynamic sensor collaboration is introduced. In this case
an information utility measurement is deﬁned as the statistical entropy and it is exploited to evaluate the

1264
CHAPTER 22 Integrated Sensor Systems and Data Fusion
beneﬁts in employing part of the network that consequently is re-organized. Other cost/utility functions
can be employed as criteria to dynamically re-organize the sensor network as described in [68,69].
Several analytical efforts have been done to evaluate the performance of such networks in terms of
tracking accuracy. As usual the CRLB has been taken as reference of the best achievable accuracy;
in particular a new concept of conditional PCRLB (Posterior Cramer Rao Lower Bound) is proposed
and derived in [70]. This quantity is dependent on the actual observation data up to the current time,
and is implicitly dependent on the underlying system state. Therefore, it is adaptive to the particular
realization of the underlying system state and provides a more accurate and effective online indication
of the estimation performance than the unconditional PCRLB. In [71,72] the PCRLB is proposed as a
criterion to dynamically select a subset of sensors over time within the network to optimize the tracking
performance in terms of mean square error. In [73] the same criterion is proposed as a framework for
the systematic management of multiple sensors in presence of clutter.
2.22.5.4 Self-Organizing Sensor Networks
Self-organization can be deﬁned as the spontaneous set-up of a globally coherent pattern out of local
interactions among initially independent components. Sensors are randomly spread out over a two
dimensional surveillance area. In a self-organized system, its elements affect only close elements;
distant parts of the system are basically unaffected. The control is distributed, i.e., all the elements
contribute to the fulﬁllment of the task. The system is relatively insensitive to perturbations or errors,
and have a strong capacity to restore itself. Initially independent components form a coherent whole
able to efﬁciently fulﬁll a particular function [74]. Flocks of birds, shoals of ﬁsh, swarms of bees are
examples of self-organizing systems; they move together in an elegantly synchronized manner without
a leader which coordinates them and decides their movement. It has been shown that ﬂocks of birds self-
organize into V-formations when they need to travel long distances to save energy, by taking advantage
of the upwash generated by the neighboring birds. Cattivelli and Sayed [75] propose a model for the
upwash generated by a ﬂying bird, and shows that a ﬂock of birds is able to self-organize into a V-
formation as if every bird processes spatial and network information by means of an adaptive diffusive
process. This result has interesting implications. First, a simple diffusion algorithm is able to account for
self-organization of birds. Second, according to the model, that birds can self-organize on the basis of
the upwash generated by the other birds. Third, some information is necessarily shared among birds to
reach the optimal ﬂight formation. The paper also proposes a modiﬁcation to the algorithm that allows
birds to organize, starting from a V-formation, into a U-formation, leading to an equalization effect,
where every bird in the ﬂock observes approximately the same upwash. The same algorithm based on
birds ﬂight is extended in [76] to the problem of distributed detection, where a set of sensors/nodes
is required to decide between two hypotheses on the basis of the collected measurements. Each node
makes individual real-time decisions and communicates only with its immediate neighbors, in order that
any fusion center is not necessary. The proposed distributed detection algorithms are based on diffusion
strategies described in [77–79] and their performance is evaluated by means of classical probabilities
of detection and false alarms.
These diffusion detection schemes are attractive in the context of wireless and sensor networks thanks
to their intrinsic adaptability, scalability, improved robustness to node and link failure as compared to
centralized schemes, and their potential to save energy and communication resources.

2.22.5 Homogeneous Sensor Networks
1265
2.22.5.5 Self-synchronization mechanism applied to sensor network
Several studies have shown how a simple self-synchronization mechanism, borrowed from biological
systems, can form the basic tool for achieving globally optimal distribution decisions in a wireless
sensor network with no need for a fusion center. Self-synchronization is a phenomenon ﬁrst observed
between pendulum clocks (hooked to the same wooden beam) by Christian Huygens in 1658. Since
then, self-synchronization has been observed in a myriad of natural phenomena, from ﬂashing ﬁreﬂies
in South East Asia to singing crickets, from cardiac peacemaker or neuron cells to menstrual cycles of
women living in strict contact with each other [80]. The goal of these studies is to ﬁnd a strategy of
interaction among the sensors/nodes that could allow them to reach globally optimal decisions in terms
of a “consensus” value in a totally decentralized manner. Distributed consensus algorithms are indeed
techniques largely studied in distributed computing [81,82]. The approaches suggested in [83,84] give a
form of consensus achieved through self-synchronization that may result critical in wide-area networks,
where propagation delays might induce an ambiguity problem. This problem is overcome in [85–87]
where also a model of the network and of the sensors is proposed. Each of the N nodes composing the
network is equipped with four basic components: (1) a transducer that senses the physical parameter
of interest yi (e.g., temperature, concentration of contaminants, radiation, etc.); (2) a local processing
unit that provides a function gi(yi) of the measurements; (3) a dynamical system, initialized with the
local measurements, whose state xi(t) evolves as a function of its own measurement gi(yi) and of the
state of nearby sensors; (4) a radio interface that makes possible the interactions among the sensors.
The criterion to reach a consensus value is the asymptotical convergence toward a common value of all
the derivatives of the state, for any set of initial conditions and for any set of bounded. This condition
makes the convergence to the ﬁnal consensus independent of the network graph topology. However
the topology has an impact on several aspects: the overall energy necessary to achieve the consensus
and the convergence time. In general there exists a trade-off between the local power transmitted by
a each sensor and the converge time depending on the algebraic connectivity of the network graph, as
shown in [88]. In the practical applications these aspects cannot be neglected; for instance, the design
of a network should account for the precision to achieve, and the time to get the consensus value at the
given precision, versus such constraints as the energy limitations of the sensors. A global overview of
the problem is given in [89].
2.22.5.6 From theory to real application problems
Moving from the functional model to a working implementation in a real environment involves a number
of design considerations: including what information sources to use and what fusion architecture to
employ, communication protocols, etc.
Admittedly, the fusion of data is decoupled from the actual number of information sources and,
hence, does not require necessarily multiple sensors: the fusion, in fact, may be performed also on a
temporal sequence of data that was generated by a single information source (e.g., a fusion algorithm
may be applied to a sequence of images produced by a single camera sensor). However, employing a
number of sensors provides many advantages as well explained in the previous Sections. Unsurprisingly,
there are also difﬁculties associated with the use of multiple sensors.
A missed sensor registration may cause a failure in the correct association between signals or features
of different measurements. This problem and the similar data association problem are very important

1266
CHAPTER 22 Integrated Sensor Systems and Data Fusion
and apply also to single sensor data processing. To perform data registration, the relative locations of
the sensors, the relationship between their coordinate systems, and any timing errors need to be known,
or estimated, and accounted for otherwise a mismatch between the compiled picture and the truth may
result. An overstated conﬁdence in the accuracy of the fused output, and inconsistencies between track
databases, such as multiple tracks that correspond to a single target may appear. A missed registration
can result from location and orientation errors of the sensor relative to the supporting platform, or of
the platform relative to the Earth, such as a bearing measurement with an incorrect North alignment.
Errors may be present in data time stamping, and numerical errors may occur in transforming data
from one coordinate system to another. Automatic sensor registration can correct for these problems
by estimating the bias in the measurements along with the kinematics of the target. However, the
errors in sensor registration need to be known and accounted for [90]. In [91] a maximum likelihood
(EML) algorithm for registration is presented using a recursive two-step optimization that involves a
modiﬁed Gauss-Newton procedure to ensure fast convergence. In [92] a novel joint sensor association,
registration, and fusion is performed exploiting the expectation–maximization algorithm incorporated
with the linear Kalman ﬁlter (KF) to give simultaneous state and parameter estimates. The same approach
can be followed also with non linear ﬁltering techniques as the Extended KF (EKF) and the Unscented
KF (UKF) as proposed in [93], where also the performance is evaluated by means of the PCRLB.
Next to the spatial sensor registration also the temporal alignment cannot be neglected. For instance,
a critical aspect of a sensor network is its vulnerability to temporary node sleeping, due to duty-cycling
for battery recharge, permanent failures, or even intentional attacks.
Other realistic problems, such as conﬂicting information and noise model assumptions, may enable
the use of some fusion techniques. Noisy input data sometimes yield conﬂicting observations, a problem
that has to be addressed and which does not arise in single sensor data processing. The administration
of multiple sensors have to be coordinated and information must be shared between them.
2.22.5.7 Rethinking mathematical algorithms for net-centric approaches
Most of the optimization algorithms have been developed in a centralized framework, i.e., they have
been conceived to perform centralized data fusion process. In the last years the trend is to employ
network centric approaches, and the mathematical optimization algorithms must be able to support this
approach. In the following an example of the adaptation of a “centralized-conceived” algorithm to the
new trend is presented.
Consider the following minimization problem to solve:
min

x,y,z

∈ℜ3 f

x, y, z

= αx2 + βy2 + γ z2 + 2δxy + 2εxz + 2ηyz,
(22.1)
whereα, β, γ, δ, ε, η arerealpositivevaluesandthefunction f

x, y, z

= w ≥0 representsanellipsoid
function, whose axes do not coincide with the reference frame axes if δ
̸= 0, ε
̸= 0, η
̸= 0.
The problem of Eq. (22.1) can be solved by the steepest descent method in a centralized fusion process
frame, hence it will be named “centralized steepest descent.” The centralized steepest descent method
when used to solve minimization problems is an iterative procedure that, beginning from an initial
guess, updates at every iteration the current approximation of the solution of the function to minimize
with a step in the direction of the gradient of the own function. In a network centric approach it may

2.22.5 Homogeneous Sensor Networks
1267
Data Fusion
centralnode
AGENT 
1
(X)
AGENT 
2
(Y)
AGENT 
3
(Z)
time 1
time 1
time 2
time 3
(a)
(b)
FIGURE 22.10
(a) centralized data fusion process model; (b) network centric data fusion process model.
be solved by the application of the Jacobi method2 usually employed for the iterative solution of linear
system equation.
Consider three agents (namely agent 1, 2, and 3) controlling the three variables x, y, and z. In the
centralized data fusion process, represented in Figure 22.10a, the communication between the three
agents is completely performed at the same instant of time; in the network centric case this does not
happen. Consider the model of Figure 22.10b with the following communication scheme:
– agent 1 communicates to agent 2,
– agent 2 communicates agent 3,
– agent 3 communicates to agent 1;
moreover the communications among agents is not instantaneous, but they succeeds in time.
The method of the centralized steepest descent applied to the function f (x, y, z), given a starting
point (x0, y0, z0), is based on the following iterations:
xk+1 = xk −h(2αxk + 2δyk + 2εzk),
yk+1 = yk −h(2βyk + 2δxk + 2ηzk),
zk+1 = zk −h(2γ zk + 2εxk + 2ηyk),
(22.2)
where k = 0, 1, . . ., and h ≥0 represents the step employed in the steepest descent method.
2The Jacobi method is an algorithm for determining the solutions of a system of linear equations with largest absolute values
in each row and column dominated by the diagonal element. Each diagonal element is solved for, and an approximate value
pluggedin.Theprocessistheniterateduntilitconverges.Thisalgorithmisastripped-downversionoftheJacobitransformation
method of matrix diagonalization. The method is named after German mathematician Carl Gustav Jakob Jacobi [96].

1268
CHAPTER 22 Integrated Sensor Systems and Data Fusion
A network centric steepest descent method can be derived by the communication scheme represented
in Figure 22.10b and described below. Given the starting point (x0, y0, z0), the following iterations can
be done:
xk+1 = xk −h(2αxk + 2δyk + 2εzk),
yk+1 = yk,
zk+1 = zk,
xk+1 = xk+1,
yk+2 = yk+1 −h(2βyk+1 + 2δxk+1 + 2ηzk+1),
zk+1 = zk+1,
xk+3 = xk+2,
yk+3 = yk+2,
zk+3 = zk+2 −h(2γ zk+2 + 2εxk+2 + 2ηyk+2),
(22.3)
where k = 0, 3, 6, . . . and h ≥0 represents the step employed in the steepest descent method.
Figure 22.11 shows the comparison of the two methods for the previous model. Note that the three
agents in the net-centric approach are those looking at the function to be minimized along the x, y,
and z axes respectively. The black square and the red diamond in the curves represent respectively the
starting point of the iteration and the ﬁnal position. The black solid line shows the trajectory described
by the variables (x, y, z) obtained by the application of the centralized steepest descent method; the
red solid line shows the behavior of the variables obtained by the net-centric steepest descent method.
Note that the red line approaches the minimum by moving along the x, y, and z axes separately. The
ellipsoids of Figure 22.11 represent the iso-level surfaces of the objective function. Notice that the
telecommunication network modeled for the net-centric steepest descent determines the usual Jacobi
iteration employed for the solution of linear systems associated to minimization problems [94–96]. In
the following Section 2.22.6.1 this approach is applied to reach the optimal deployment of a sensor
network.
2.22.6 Real study cases: novel approaches to sensor networks
This section proposes several study cases of sensor networks employing novel approaches. Section
2.22.6.1 proposes an optimization method, projected in the network centric frame, to obtain the optimal
deployment of a cooperative sensor network; Section 2.22.6.2 describes how to employ the so-called
bio-inspired models of dynamic sensor collaboration in a chemical sensor network to detect a chemical
pollutant; ﬁnally Section 2.22.6.3 gives a description of the typical problem of detection of radioactive
sources.
2.22.6.1 A cooperative sensor network: optimal deployment and functioning
This section presents a mathematical model for the deployment of a sensor network, for the creation of
consensus values from the noisy data measured and a statistical methodology to detect local anomalies

2.22.6 Real Study Cases: Novel Approaches to Sensor Networks
1269
Starting point 
Convergence point
Centralized steepest descent
Net-centric steepest descent
FIGURE 22.11
Comparison between the trajectories computed by the centralized and the network centric steepest descent.
in these data. A local anomaly in the data is associated to the presence of an intruder. The model of
sensor network presented here is characterized by the absence of a fusion center. In other words the
deployment, the construction of the consensus values, and the detection of local anomalies in the data
are the result of local interactions between sensors. Nevertheless the local interactions will lead to global
solution of the considered problem. This is an example of model of a network centric sensor network.
The sensors are assumed to be identical and they measure a quantity pertinent to the properties of the
area to survey able to reveal the presence of an intruder. In the proposed study case the sensors are able
to measure the temperature of the territory in the position or in the “area” where they are located; in
absence of anomalies there is a uniform temperature on the territory where the sensors are deployed. The
sensor measures are noisy and can be considered synchronous. This measurement process is repeated
periodically in time with a given frequency. From these measures a “consensus” temperature is deduced,
pertinently to the territory where the sensors are deployed and an estimate of the magnitude of the noise
contained in the data. Finally using these consensus values as reference values local anomalies are

1270
CHAPTER 22 Integrated Sensor Systems and Data Fusion
FIGURE 22.12
Territory of the city of Urbino (Italy) selected for the study case.
detected by the individual sensors. In the following we give some analytical details of the consensus
method [97].
Let  be a bounded connected polygonal domain in two dimensional real Euclidean space R2. The
domain  represents the territory where the sensor network must be deployed; in our case the downtown
part of the Italian city of Urbino, shown in Figure 22.12. Let ∥·∥denote the Euclidean norm of in R2.
Consider N sensors s1, s2, . . . , sN, located respectively, in the points ξ1, ξ2, . . . , ξ N ∈, assumed to be
distinct. To the sensor network deployed in the points ξ1, ξ2, . . . , ξ N corresponds a graph whose nodes
are the sensors location and whose edges join the sensors able to communicate between themselves. This
graph is assumed to be connected and can be imagined as laid on the territory. The assumption that the
graph is connected is equivalent to assuming that the sensors constitute a network. For i = 1, 2, . . . , N,
a polygonal region i ⊂ is associated to each sensor si; this region is deﬁned by the condition that
the points belonging to i are closest to the sensor si, that is they are closest to ξi, than to any other of
the remaining sensors s jlocated in ξ j, j ̸= i, j = 1, 2, . . . , N. It follows:
i =

x ∈ : i = arg min

f ( j) =
x −ξ j


, j = 1, 2, . . . , N

,
i = 1, 2, . . . , N.
(22.4)
When for a given x ∈ the minimizer of the function f ( j) =
x −ξ j
 , j = 1, 2, . . . , N is not
unique we attribute x to i, where i is the smallest index between the indices that are minimizers of the
function f.
The collection of subsets {1, 2, . . . , N} deﬁned in Eq. (22.4) and further speciﬁed by the con-
dition above is a partition of  and it is a Voronoi partition of  associated to the Voronoi centers
ξ1, ξ2, . . . , ξ N, as represented in Figure 22.13 [98], where the sets 1, 2, . . . , N are the Voronoi
cells. The sensor si is located in ξi, with ξi ∈i, i = 1, 2, . . . , N, and monitors the sub-region
i of . Note that there is a Voronoi partition of  associated to each choice of the Voronoi centers

2.22.6 Real Study Cases: Novel Approaches to Sensor Networks
1271
FIGURE 22.13
(a) Voronoi partition of ; (b) optimal Voronoi partition of .
ξ1, ξ2, . . . , ξ N, that, completed with the graph that deﬁnes the communication between the sensors,
constitute a deployment of the sensors s1, s2, . . . , sN on the territory .
After the deﬁnition of a Voronoi partition of , we want to determine the optimal one with respect
to a pre-speciﬁed criterion, that in this study case is the fact that the Voronoi centers ξ1, ξ2, . . . , ξ N
should coincide (as much as possible) with the centers of mass of the corresponding Voronoi cells
1, 2, . . . , N. This property translates in mathematical terms the request that the sensors are well
distributed on the territory. That is what is called optimal Voronoi partition, i.e., the Voronoi partition
associated to the Voronoi centers whose coordinates ξ∗
1, ξ∗
2, . . . , ξ∗
N are the solution of the following
problem:
min
ξ1,ξ2,...,ξ N
F(ξ1, ξ2, . . . , ξ N) =
N
	
j=1
B j −ξ j

2
(22.5)
subject to the constraints:
ξi ̸=ξ j,
i ̸= j, i, j =1, 2, . . . , N,
(22.6)
where B j is the center of mass of the Voronoi cell  j, j = 1, 2, . . . , N. Moreover we require:
F(ξ∗
1, ξ∗
2, . . . , ξ∗
N) = 0.
(22.7)
That is the Voronoi centers and the centers of mass of the Voronoi cells coincide. Note that in
general B j depends on ξ1, ξ2, . . . , ξ N and that the function F(ξ1, ξ2, . . . , ξ N) is in general a non
linear function of ξ1, ξ2, . . . , ξ N. The solution of the problem expressed in Eqs. (22.5)–(22.7) after
having speciﬁed the communications between the sensors is the optimal deployment, represented in
Figures 22.13b and 22.14. When the condition of Eq. (22.7) cannot be satisﬁed, we may accept the
available solution of Eqs. (22.5) and(22.6) as location of the Voronoi centers corresponding to the
optimal deployment. Note that in general the solution of problem expressed in Eqs. (22.5)–(22.7) is
not unique and it can be solved by the application of the steepest descent concept, revised in a network
centric frame as shown conceptually in Section 2.22.5.7 [94]. This method can be used to solve the
problem of Eq. (22.5) with an iterative procedure, that beginning from an initial guess, updates at every
iteration the current approximation of the solution with a step in the direction of the gradient of the

1272
CHAPTER 22 Integrated Sensor Systems and Data Fusion
FIGURE 22.14
Graph associated to the optimal Voronoi partition of  shown in Figure 22.13b.
function F(ξ1, ξ2, . . . , ξ N). Moreover the steepest descent method must be adapted to the presence of
the constraints of Eq. (22.6), of the condition of Eq. (22.7) and to the requirement that its implementation
must lead to a network centric solution of the deployment problem. For sake of brevity, how to impose
Eq. (22.6) will not be discussed here, however a treatment of constraints in the continuous analog of the
steepest descent algorithm can be found in [99]. Note also that the solutions of Eqs. (22.5) and (22.6)
that are of interest are usually interior points of the constraints (6). That is the constraint issue usually is
not relevant in the solution of Eqs. (22.5) and (22.6). Similarly we will not pay attention to condition of
Eq. (22.7). In fact with respect to Eq. (22.7), we will simply verify if the solution of the optimization
problem determined by the steepest descent method satisﬁes Eq. (22.7). Let us concentrate our attention
ontheissueofbuildinganetworkcentricimplementationofthecontinuousanalogofthesteepestdescent
method to solve Eq. (22.5). Assume that the sensor si knows only the position of its neighbor sensors,
that is of the sensors that belong to a disk with center ξi and radius r > 0, i = 1, 2, . . . , N. Later we will
show how to choose r. The solution of the optimization problem of Eq. (22.5) is found approximating
the solution of the system of differential equations:
˙ξi = −∇ξi F(ξ1, ξ2, . . . , ξ N),
λ1 > 0, i = 1, 2, . . . , N,
(22.8)
where λ1denotes a real parameter, with the solution of the “network centric” system differential
equations:
˙ξi = −∇ξi Fi(ξ1, ξ2, . . . , ξ N),
λ1 > 0, i = 1, 2, . . . , N
(22.9)
with
Fi =
	
j∈Li
 ˜Bi, j −ξ j

2
,
i = 1, 2, . . . , N,
(22.10)
where
Li =

ξ j, j = 1, 2, . . . , N : ξ j is neighbor to ξi

,
i = 1, 2, . . . , N
(22.11)
and ˜Bi, j being the center of mass of the Voronoi cell ˜i, j obtained computing the Voronoi partition of
 associated to the Voronoi centers ξ j, j ∈Li, i = 1, 2, . . . , N. Assume that r > 0 is large enough to

2.22.6 Real Study Cases: Novel Approaches to Sensor Networks
1273
guarantee that ξ j is neighbor of ξi when the distance between  j and i is zero, i, j = 1, 2, . . . , N.
Note that with this assumption we have ˜Bi,i = Bi, i = 1, 2, . . . , N. In Eqs. (22.8) and (22.9) the dot
denotes the differentiation with respect to λ1. We observe that Eq. (22.8) is known as the steepest descent
differential equation. The continuous analog of the steepest descent method consists in obtaining the
solution of the optimization problem of Eq. (22.5) computing the asymptotic value as λ1 goes to inﬁnity
of a solution of Eq. (22.8) equipped when λ1 = 0 with a suitable initial condition. This asymptotic
value hopefully is a point that solves Eq. (22.5) and satisﬁes Eqs. (22.6) and (22.7).
Note that the function Fi depends only on ξ j, j ∈Li, that is can be computed in the location ξi
using only information available in ξi, i = 1, 2, . . . , N. Approximating the gradient of F with the
appropriate pieces of the gradients of the function Fi, i = 1, 2, . . . , N, and using Eq. (22.9) instead
than Eq. (22.8) we can ﬁnd an approximation of the solution of Eq. (22.5) integrating numerically the
initial value problem for Eq. (22.9). Note that the solution for the ith differential equation of Eq. (22.9)
is computed in the location ξi, i = 1, 2, . . . , N. This approximation of the solution of Eq. (22.5) is
obtained using only local information so that it is “network centric.” When the asymptotic value as λ1
goes to inﬁnity, the solution of Eq. (22.9) coincides with an asymptotic value of a solution of Eq. (22.8),
solving numerically Eq. (22.9), we can obtain in a network centric manner a solution of Eq. (22.5). The
choices of the optimal Voronoi partition and of the steepest descent method to determine it, are only one
of the many other legitimate choices. In Figure 22.13 the polygonal region shown represents , for N
= 20 and for i = 1, 2, . . . , 20, denoting with the full circle the position of the center of mass Bi of the
subset i and with the empty circle the position of the sensors ξi. The Figure 22.13a shows the Voronoi
partition of the domain , associated to 20 Voronoi centers ξ1, ξ2, . . . , ξ20 and the corresponding
centers of mass B1, B2, . . . , B20 of the associated Voronoi cells 1, 2, . . . , 20. Note that in Figure
22.13a we have ξi ̸= Bi, i = 1, 2, . . . , 20. The Figure 22.13b shows an optimal Voronoi partition. Note
that in Figure 22.13b we have ξi = Bi, i = 1, 2, . . . , 20. The Voronoi partition shown in Figure 22.13b
satisﬁes Eqs. (22.5)–(22.7). The centers of Figure 22.13b have been obtained integrating numerically,
using the explicit Euler method in Eq. (22.9), equipped with the initial condition given by the centers
shown in Figure 22.13a. In Figure 22.14 we show the graph associated to the optimal Voronoi partition
of  shown in Figure 22.13b. The graph is obtained joining with branches the Voronoi centers that are
(distinct) neighbors. In Figure 22.13 and Figure 22.14 we have chosen r = k

area


1/2, where k is
a parameter that can be changed during the optimization procedure used to solve Eqs. (22.5)–(22.7).
Remind that we have assumed that the graph G associated to the optimal deployment is connected
(see Figures 22.14 and 22.13b). Moreover we remind that, since there is not a fusion center, each node
of the graph G does not know the positions of all the remaining nodes of the graph, in fact it knows only
the positions of its neighbor nodes. Let L be the Laplacian matrix associated to G [100]. The matrix L is
a symmetric positive semi-deﬁnite N × N matrix. Let x(λ2) = (x1(λ2), x2(λ2), . . . , xN(λ2))T , λ2 >
0, be a real N dimensional vector depending on the real parameter λ2. The superscript (·)T means
transposed. We consider the system of ordinary differential equations:
˙x(λ2) = −Lx(λ2),
λ2 > 0
(22.12)
equipped with the initial conditions:
x(0) = α,
(22.13)

1274
CHAPTER 22 Integrated Sensor Systems and Data Fusion
where Lx denotes the usual matrix vector multiplication, α = (α1, α2, . . . , αN)T is a known initial
condition and the dot denotes differentiation with respect to λ2. Since G is connected we have:
lim
λ2→+∞xi(λ2) = 1
N
N
	
j=1
α j,
i = 1, 2, . . . , N,
(22.14)
where x(λ2), λ2 > 0, is the solution of Eqs. (22.12) and (22.13). This result follows easily from the
spectral properties of L [100]. Note also that the right hand side of Eq. (22.14) is the “average” of the
initial condition α. Note that Eq. (22.12) can be interpreted as the “heat equation” on the graph G, that
the problem of Eqs. (22.12) and (22.13) can be seen as an initial value problem for the heat equation on
G and that Eq. (22.14) can be understood as the approach to an asymptotic equilibrium “temperature” in
an “heat transfer” problem. We assume that during the monitoring phase the sensor measures a physical
quantity, such as, for example, the temperature, of the region i where it is located. The sensors are
identical, the measures made by the sensors are synchronous, repeated periodically in time and of course
they are noisy. Moreover they are assumed to be independent. A ﬁrst set of measures is taken by the
sensors at time t = t0 and is collected in the vector β0 = (β0,1, β0,2, . . . , β0,N,)T , where β0,i is the
measure done by the sensor si. The set of measure β0 will be used to obtain the “consensus” value β0
of the quantity monitored in  at time t = t0. We choose:
β0 = 1
N
N
	
i=1
β0,i.
(22.15)
Remind that the sensor si located in ξi knows β0,i and communicates with the sensors s j located in
ξ j, j ∈Li, i = 1, 2, . . . , N. In order to provide to the sensor si, the consensus value β0 in a network
centric manner we proceed as follow: we choose α = β0 in Eq. (22.13) and we integrate numerically the
initial value problem of Eqs. (22.12) and (22.13) using the explicit Euler method to obtain a numerical
approximation of limλ2→+∞x(λ2). Note that the ith differential equation of Eq. (22.12) is integrated
in the location ξi, and that using the explicit Euler method this can be done using only information
available in the location ξi. Note that the analytic solution of Eqs. (22.12) and (22.13) is not “network
centric” but its approximation with the explicit Euler method is “network centric.” In the former case
to achieve the solution each node should know the whole graph, i.e., all the nodes. The ith node is not
able to achieve the solution exploiting only the information in its posses: in this sense the solution is not
“network centric.” Otherwise, exploiting the Euler approximation of the exponential of a matrix, the
whole knowledge of the graph is not necessary: in this sense a “network centric” solution is achieved.
Once obtained β0we consider the following vector:
γ 0 =
N
N −1

(β0,1 −β0)2, (β0,2 −β0)2, . . . , (β0,N −β0)2T
.
(22.16)
Then we choose α = γ 0 in Eq. (22.13) and we integrate Eqs. (22.12) and (22.13) with the explicit
Euler method as done above. In this way we obtain asymptotically a numerical approximation of
γ 0where:
γ 0 =
N
N −1
N
	
i=1
(β0,i −β0)2.
(22.17)

2.22.6 Real Study Cases: Novel Approaches to Sensor Networks
1275
This approximation of γ 0 is provided to each sensor in a network centric manner. Note that γ 0 is an
estimate of the magnitude of the noise contained in the data; in fact γ 0 is the “sample” variance of the
measures β0,i made by the sensor at time t = t0. The approximation of β0 and γ 0 obtained integrating
numerically Eqs. (22.12) and (22.13) are the consensus values. These values are “global” values (that
is they depend on all the measures made by the sensor network at time t = t0) and have been provided
to each sensor in a network centric manner (that is using only “local” interactions between sensors).
The sensor si repeats periodically in time the measure of the quantity of interest and after a given
time interval has as its disposal a set of measures that can be compared with the consensus values β0
and γ 0 to detect (local) anomalies. Let us assume that the set of measures made by the sensor si is a
sample taken from a set of independent identically distributed Gaussian random variables of mean μi
and variance σ 2
i . In these hypotheses the Student t-test and the Chi-square test [101] are the elementary
statistical tools that must be used to compare μi and σ 2
i (that are unknown) to β0 and γ 0. The result
of this comparison is the detection of local anomalies. A (statistical) signiﬁcance is associated to the
detected anomalies. The statistical tests used are based on the assumption that the measures come from
a set of independent identically distributed Gaussian random variables. Note that the estimators β0 and
γ 0 can be used in more general circumstances.
2.22.6.2 Modeling and performance analysis of a network of chemical
sensors with dynamic collaboration
Typically the challenge in the deployment of an operational wireless sensor network (WSN) resides in
establishing the balance between its operational requirements (e.g., minimal detection threshold, the size
of surveillance region, detection time, the rate of false negatives, etc.) and the available resources (e.g.,
energy supply, number of sensors, communication range, ﬁxed detection threshold of individual sensors,
limited budget for the cost of hardware, maintenance, etc.) [102]. The issue of resource constraints
is particularly important for a network of chemical sensors, because modern chemical sensors are
equipped with air-sampling units (fans), which turn on when the sensor is active. Operating a fan
requires a signiﬁcant amount of energy as well as a frequent replacement of some consumable items
(i.e., cartridges, ﬁlters). This leads to the critical requirement in the design of a WSN to reduce the
active (air-sampling) time of its individual sensors.
One attractive way to achieve the described balance between the requirements and the constraints of
WSN is to exploit the idea of dynamic sensor collaboration (DSC) [103,104]. The DSC implies that
a sensor in the network should be invoked (or activated) only when the network will gain information
by its activation [104]. For each individual sensor this information gain can be evaluated against other
performance criteria of the sensor system, such as the detection delay or the detection threshold, to ﬁnd
an optimal solution in given circumstances. However, the DSC-based algorithms involve continuous
estimation of the state of each sensor in the network and usually require extensive computer simulations
[103,104]. These simulations may become unpractical as the number of sensors in the network increases.
Furthermore, the simulations can provide the numerical values for optimal network parameters only for
a speciﬁc scenario.
This motivates the development of another simple and analytic approach to the problem of net-
work analysis and design. The main idea is to phenomenologically employ the so-called bio-inspired

1276
CHAPTER 22 Integrated Sensor Systems and Data Fusion
(epidemiology, population dynamics) or physics inspired (percolation and graph theory) models of DSC
in the sensor network in order to describe the dynamics of collaboration as a single entity [105–110].
From a formal point of view, the equations of bio inspired models of DSC are the ones of the “mean-
ﬁeld” theory, meaning that instead of working with dynamic equations for each individual sensor we
use only a small number of equations for the “averaged” sensor state (i.e., passive, active, faulty, etc.),
regardless of the actual number of sensors in the system.
The analytic approach can lead to the valuable insights into the performance of the proposed sensor
network system by providing simple analytical expressions to calculate the vital network parameters,
such as the detection threshold, robustness, responsiveness and stability and their functional relation-
ships.
The ﬂuctuations in concentration C of the pollutant are modeled by the probability density function
(pdf) with the mean C0 as a parameter [111]:
ρ(C|C0) = (1 −ω)δ(C) + ω2(γ −1)
C0(γ −2)

1 +
ωC
(γ −2)C0
−γ
.
(22.18)
Here the value γ = 26/3 can be chosen to make it compliant with the theory of tracer dispersion in
Kolmogorov turbulence [111], but it may vary with meteorological conditions. The parameter ω, which
models the tracer intermittency in the turbulent ﬂow, can be in the range [0, 1], with ω = 1 corresponding
to the non-intermittent case. In general it also depends on the sensor position within a chemical plume,
thus 0.95 < ω < 0.98 near the plume centroid and may drop to 0.3 < ω < 0.5 near the plume edge. For
ω ̸= 0, the pdf ρ of Eq. (22.18) has a delta impulse in zero, meaning that the measured concentration
in the presence of intermittency can be zero on some occasions. It can be easily shown that the pdf of
Eq. (22.18) integrates to unity, so it is appropriately normalized.
Depending on the values of parameters γ, ω, Eq. (22.18) allows simulation of pollutant distributions
with the different correlation structure (e.g., intermittent and strongly non-Gaussian) corresponding
to the rich variety of possible regimes of turbulent mixing occurring in the ambient environment;
Figure 22.15 shows two examples of the same WSN operating in two different correlation structures of
the chemical tracer.
We adopt a binary model of a chemical sensor, with reading V speciﬁed as:
V =
1,
C ≥C∗,
0,
C < C∗,
(22.19)
where C∗is the threshold (an internal characteristic of the sensor). It can be shown [112] that the
probability of detection of an individual sensor embedded in the environmental model described by Eq.
(22.18) is given by:
p = 1 −F(C∗|C),
(22.20)
where
F(C|C0) = 1 −ω

1 +

1
γ −2
 C
C0
1−γ
(22.21)
is the cumulative distribution function corresponding to pdf of Eq. (22.18), see [113].

2.22.6 Real Study Cases: Novel Approaches to Sensor Networks
1277
FIGURE 22.15
Examples of WSN network operating in the tracer ﬁled with different correlation structure [117]. (reprinted
with permission.)
Suppose that N chemical sensors are uniformly distributed over the surveillance domain of area S
and adopt the following network protocol for dynamic collaboration. Each sensor can be only in one
of the two states: active and passive. The sensor can be activated only by a message it receives from
another sensor. Once activated, the sensor remains in the active state during an interval of time τ∗; then
it “dies out” (becomes passive). While being in the active state, the sensor senses the environment and if
the chemical tracer is detected, it broadcasts a (single) message. The broadcast capability of the sensor
is characterized by its communication range r∗. This network with the described dynamic collaboration
can be modeled using the epidemic SIS model (susceptible-infected-susceptible) [114]:
dN+
dt
= αN+N−−N+
τ∗
,
dN−
dt
= −αN+N−+ N+
τ∗
,
(22.22)
where N+, N−denote the number of active and passive sensors, respectively. The nonlinear terms on
the right hand side of Eq. (22.22) are responsible for the interaction between the sensors; parameter α
is a measure of this interaction. The number of sensor is assumed constant, hence we have an additional
equation: N+ + N−= N. Since the parameter alpha describes the intensity of social interaction in a
community [114] we can propose that:
α ∝m · p
Nτ∗
,
(22.23)
where m is the number of contacts made by the activated (“infected”) sensor during its infectious period
τ∗(i.e., the number of sensors that received the wake-up message from an alerting sensor). In our case
m = π · r2
∗· N/S. Then we have:
α = G π · r2
∗· p
Sτ∗
,
(22.24)

1278
CHAPTER 22 Integrated Sensor Systems and Data Fusion
where G is a calibration constant. In order to simplify notation we will further assume that G is
absorbed in the deﬁnition of r∗. Equation (22.22) combined with N+ + N−= N can be reduced to one
equation for y = N+:
dy
dt = α · y · (N −y) + y
τ∗
= y · (b −α · y),
(22.25)
where b = αN −1/τ∗. By simple change of variables z = αy/b, this equation can be reduced to the
standard logistic equation [115,116]:
dz
dt = bz(1 −z).
(22.26)
The solution of the logistic equation is well-known:
z(t) =
z0
(1 −z0) exp (−bt) + z0
,
(22.27)
where z0 = z(0). Observe that the WSN will be able to detect the presence of a pollutant only if b > 0,
because then z →1 as t →∞independent of z0. In this case, after a certain transition interval, the
WSN will reach a new steady state with:
N+
N = 1 −θ, N−
N = θ, θ =
1
ατ∗N .
(22.28)
From (22.27) and using the expression for b stated above, the activation time (transition interval) is
given by:
τ ≈1
b =
τ∗
ατ∗N −1.
(22.29)
From Eq. (22.29) it follows that the key requirement for the network to be operational b > 0 is that
ατ∗N > 1, that is:
R0 = p · N · π · r2
∗/S > 1,
(22.30)
where R0 is a well-known parameter in epidemiology, referred to as the basic reproductive number
[114]. Observe that R0 is independent of τ∗; however, according to Eq. (22.29) the response time of the
WSN is strongly dependent on τ∗.
It remains to specify q, the number of sensors that should initially be active for the described WSN
with dynamic collaboration to be effective. The initial condition is simply q · p > 1, that is on average
q > 1/p. Eqs. (22.28)–(22.30) are important analytic results. For a given level of mean pollutant
concentration C0 and meteorological conditions (γ, ω), these expressions provide a simple yet rigorous
way to estimate how a change in network and sensor parameters (i.e., N, C∗, τ∗) will affect the network
performance (i.e., N+, τ).
The examples of agent-based simulation of “information epidemic” in WSN, which satisﬁes the
threshold condition of Eq. (22.30) is presented in Figure 22.16. We can observe that by change of
the conﬁguration parameters of WSN we can vary the activation time and the saturation limit of the
detection system. Further development of the theoretical framework presented in this section can be
found in [117–120].

2.22.6 Real Study Cases: Novel Approaches to Sensor Networks
1279
FIGURE 22.16
Examples of Information Epidemic in WSN of chemical sensors for different values of parameters ω in
Eq. (22.18). (Black, blue, green and red lines correspond to ω = 1, 0.95, 0.5, 03, respectively.) (For inter-
pretation of the references to color in this ﬁgure legend, the reader is referred to the web version of this
book.)
2.22.6.3 Detection and localization of radioactive point sources
with experimental veriﬁcation
Recently there has been an increased interest in detection and localization of radioactive material
[121–125]. Radioactive waste material is relatively easy to obtain with numerous accidents involving
its loss or theft reported. The danger is that a terrorist group may acquire some radiological material and
use it to build a dirty-bomb. The dirty bomb would consist of waste by products from nuclear reactors
wrapped in conventional explosives, which upon detonation would expel deadly radioactive particles
into the environment. The ability to rapidly detect and localize radioactive sources is important in order
to disable and isolate the potential threat in emergency situations.
This section is concerned with radiological materials that emit gamma rays. The probability that a
gamma radiation detector registers z ∈N counts (N being the set of natural numbers including zero) in
τ seconds, from a source that emits on average μ counts per second is [126]:
P(z; λ) = λz
z! e−λ,
(22.31)
where λ = μτ is the mean and variance of the Poisson distribution. The measurements of radiation
ﬁeld are assumed to be made using a network of low-cost Geiger-Müller (GM) counters as sensors.
In general, the problem of detection and localization of point sources or radioactive sources can be
solved using either controllable or uncontrollable sensors. Controllable sensors can move and vary the
radiation exposure time [127,128]. In this Section we will focus on uncontrollable sensors, placed at
known locations with constant and known exposure times.

1280
CHAPTER 22 Integrated Sensor Systems and Data Fusion
Assume that r ≥0 sources (r is unknown) are present in the area of interest. Furthermore, the
assumption is that the area is ﬂat without obstacles (“open ﬁeld”). Each source i = 1, 2, . . . ,r is
parameterized by its 2D location (xi, yi) and its equivalent strength αi (a single parameter which takes
into account the activity of the source, the value of gamma energy per integration and scaling factors
involved, see [129]). Thus the parameter vector of source i is ϑi =

xi yi αi
T , while the total parameter
vector is a stacked vector: ϑ =

ϑT
1 · · · ϑT
r
T . Suppose a network of GM counters is deployed in the
ﬁeld of interest. Let GM counter j = 1, . . . , m, located at

ξ j ζ j

, reports its count z j every τ seconds.
Assuming that each GM counter has a uniform directional response and that attenuation of gamma
radiation due to air can be neglected, the joint density of the measurement vector z =

z1 · · · zm
T ,
conditional on the parameter vector ϑ and the knowledge that r sources are present, can be modeled
as [129]:
l(z|ϑ) =
m

j=1
P(z j; λ j(ϑ)).
(22.32)
Here λ j(ϑ) is the mean radiation count at sensor j:
λ j(ϑ) = λb +
r
	
i=1
αi
d2
i j
(22.33)
with
d2
i j =

(xi −ξ j)2 + (yi −ζ j)2
(22.34)
being the distance between the source i and sensor j, and λb the average count due to the background
radiation (assumed known). The problem for the network of GM counters is to estimate the number of
sources r and the parameter vector for each source ϑi, i = 1, . . . ,r. In this section we will present the
experimental results obtained using real data and a Bayesian estimation algorithm combined with the
minimum description length (MDL) for source number estimation.
A radiological ﬁeld trial was conducted on a large, ﬂat, and open area without any obstacles at the
PuckapunyalairﬁeldsiteinVictoria,Australia.ThemeasurementswerecollectedusingtheDSTOs3 Low
Cost Advanced Airborne Radiological Survey (LCAARS) survey system which consists of an AN/PDR-
77radiationsurveymeterequippedwithanRS232interfacemodule,agammaprobeandsoftwarewritten
inVisualBasicrunningonalaptopcomputer.ThegammaprobecontainstwoGMtubestocoverbothlow
and high ranges of dose rates. It was capable of measuring gamma radiation dose rates from background
to 9.99 Sv/h4 without saturating [130] with a fairly ﬂat response [131]. Three radiation sources were
used in the ﬁeld trial: source 1 was a cesium sources (137Cs) with ϑ1 =

11 m 10 m 9105 µSv/h
T,
source 2 was also a cesium source with ϑ2 =

3 m 50 m 1868 µSv/h
T , and source 3 was a cobalt
3The Defense Science and Technology Organisation (DSTO) is part of Australia’s Department of Defense. DSTO is the
Australian Government’s lead agency charged with applying science and technology to protect and defend Australia and its
national interests (http://www.dsto.defence.gov.au/).
4Sievert/Plank constant: the Sievert (symbol: Sv) is the International System of Units derived unit of dose equivalent radiation.
It attempts to quantitatively evaluate the biological effects of ionizing radiation as opposed to just the absorbed dose of radiation
energy, which is measured in gray.

2.22.6 Real Study Cases: Novel Approaches to Sensor Networks
1281
FIGURE 22.17
Aerial image of the experimental site with the local coordinate system. (green points indicate the locations
of three sources; red circles indicate the zones with dangerous levels of radiation.) (For interpretation of the
references to color in this ﬁgure legend, the reader is referred to the web version of this book.)
source (60Co) with ϑ3 =

41m 5m 467 µSv/h
T . The aerial image of the experimental site with the
location of sources and the local Cartesian coordinate system is shown in Figure 22.17. Four data sets
were collected during the ﬁeld trails in the presence of r sources, with respectively r = 0, 1, 2, 3 [132].
Data sets with r > 0 sources contains 50 count measurements in each measurement point.
Estimation of parameter vector ϑ, under the assumption that r is known, was carried out using the
Bayesian importance sampling technique known as the progressive correction [125,133]. This technique
assumes that prior distribution of ϑ, denoted p0(ϑ), is available. The information contained in the
measurement vector z is combined with the prior to give the posterior pdf: p(ϑ|z) ∝l(z|ϑ) · p0(ϑ).
The minimum mean squared error estimate of ϑ is then the posterior expectation:
ˆϑ = E(ϑ|z) =

ϑ · p

ϑ|z

· dϑ.
(22.35)
The problem is that the posterior pdf and hence the posterior expectation of Eq. (22.35) cannot be
found analytically for the described problem. Instead, an approximation of Eq. (22.35) is computed via
the importance sampling: it involves drawing Np samples of the parameter vector from an importance
density and approximating the integral by a weighted sum of the samples. This is carried out in a few
stages, each stage drawing samples from a “target distribution” which is gradually approaching the true

1282
CHAPTER 22 Integrated Sensor Systems and Data Fusion
posterior. The “target distribution” at stage s = 1, . . . , S is constructed as:
ps(ϑ|z) ∝l(z|ϑ)Gs · p0(ϑ),
(22.36)
where Gs = s
l=1 γl with γ ∈[0, 1) and GS = S
l=1 γl = 1. An adaptive scheme for the computation
of S and factors γ1, γ2, . . . , γS is given in [125,133]. Assume that a random sample

ϑn
s−1
Np
n=1 from
ps−1(ϑ|z) is available and one wants to generate the samples or particles from ps(ϑ|z). The progressive
correction algorithm steps are then as follows [125]:
1. compute Gs = Gs−1 + γs;
2. compute not-normalized weight of each sample as: wn
s = l(z|ϑ)γs, for n = 1, . . . , Np;
3. normalize weights;
4. perform re-sampling of particles [134];
5. carry out Markov chain Monte Carlo (MCMC) move step for each particle [134].
The procedure is repeated for every stage s < S until Gs < 1. The initial set of particles is drawn
from the prior density p0(ϑ). The ﬁnal estimate in Eq. (22.35) is approximated as
ˆϑ = 1
Np
Np
	
n=1
ϑn
S.
(22.37)
The number of sources was estimated using the MDL algorithm [59], which will choose
r ∈{1, 2, . . . ,rmax} that will maximize the following quantity:
βr = logl(z| ˆϑ(r)) −1
2 log
J( ˆϑ(r))
 ,
(22.38)
where ˆϑ(r) is the estimate obtained under the assumption that r sources are present and
J(ϑ) = −E

∇ϑ∇T
ϑ logl(z|ϑ)

(22.39)
is the Fisher Information Matrix. It can be shown that
J(ϑ) =
m
	
j=1

∇ϑλ j(ϑ)
 
∇ϑλ j(ϑ)
T
λ j(ϑ)
(22.40)
with
∂λ j(ϑ)
∂xi
= 2αi(ξ j −xi)/d4
i j,
∂λ j(ϑ)
∂yi
= 2αi(ζ j −yi)/d4
i j,
(22.41)
∂λ j(ϑ)
∂αi
= d−2
i j .

2.22.6 Real Study Cases: Novel Approaches to Sensor Networks
1283
FIGURE 22.18
The output of progressive correction algorithm after (a) s = 2 and (b) s = 11 stages: data set 3 with r = 3
sources present (indicated by red stars). (For interpretation of the references to color in this ﬁgure legend,
the reader is referred to the web version of this book.)
TheinverseoftheFIMgivesustheCRLB,whichrepresentsthetheoreticallowerboundforestimation
error covariance [135]. Figure 22.18 shows the output of the progressive correction algorithm for data
set 3 (with three sources present) after (a) s = 2 and (b) s = 11 stages of processing. The red stars
indicate the locations of three sources. The green line shows the initial polygon A for the location of
sources. The prior density for sampling the initial set of particles for source i = 1, . . . ,r is:
p0(ϑi) = UA(xi, yi) · κ.ν(αi),
(22.42)
where UA(xi, yi) stands for uniform distribution over the polygon A and κ.ν(αi) is the gamma
distribution with parameters κ = 1.5 and ν = 8000. From Figure 22.18 we observe how the pro-
gressive correction algorithm localiszs the three sources fairly accurately.
As we mentioned earlier, 50 count measurements have been collected by each sensor. This allows
us to ﬁnd the root mean square (rms) estimation error using each snapshot of measurement data from
all sensors. Table 22.2 shows the resulting rms errors versus the theoretical CRLB.
The theoretical CRLB was computed using the idealized measurement model as stated by
Eqs. (22.32)–(22.34). Considering that this measurement model was very crude with a number of
factors neglected (e.g., uniform directional response, neglected air attenuation, perfect knowledge of
sensor locations, known and constant average background radiation, etc.), the agreement between the
theoretical bound and the RMS estimation errors in Table 22.2 is remarkable. The experimental results
in this table effectively verify the measurement model as well as the estimation algorithm.

1284
CHAPTER 22 Integrated Sensor Systems and Data Fusion
Table 22.2 RMS Error of Progressive Correction Algorithm Versus the Theoretical Bound for
Data Set 3 (r = 3)
√
CRLB
RMS Error
x1 (m)
0.35
0.62
y1 (m)
0.46
0.57
α1 (µSv/h)
85
160
x2 (m)
1.12
2.6
y2 (m)
0.57
1.46
α2 (µSv/h)
63
195
x3 (m)
0.20
1.27
y3 (m)
2.66
1.22
α3 (μSv/h)
39
95
Table 22.3 Estimation of the Number of Sources Using the Progressive Correction in the MDL
Algorithm
Test
True
Est. ˆr
Data Set
r
0
1
2
3
Backgr.
0
50
0
0
0
Test 1
1
0
48
2
0
Test 2
2
0
0
49
1
Test 3
3
0
0
6
44
Results for estimation of r are shown in Table 22.3. The table lists the number of runs (out of 50)
that resulted in r ∈{0, 1, 2, 3}. It can be observed that the number of sources is estimated correctly in
the majority of cases.
More results of experimental data processing can be found in [131,132]. In a recent study [136] it
was found that by using all 50 snapshots of measurement data for estimation by progressive correction,
results in a posterior pdf which is very narrow but does not include the true source positions. This
indicates that the measurement model is not perfect, which is not surprising considering that it is based
on many approximations. In situations where the measurement likelihood is not exact, it is necessary
to introduce a degree of caution to make the estimation more robust. In the framework of progressive
correction this can be achieved by GS = S
l=1 γl < 1. In this way the measurement likelihood
is effectively approximated by a fuzzy membership function which has a theoretical justiﬁcation in
random set theory [137, Chapter 7].
If one wants to relax the assumption that radioactive sources are point sources, the problem becomes
the one of radiation ﬁeld estimation. This is an inverse problem, difﬁcult to solve in general. By modeling
the radiation ﬁeld by a Gaussian mixture, however, the problem becomes tractable and some recent
results are reported in [138].

2.22.7 Heterogeneous Multi-Sensor Network Management
1285
2.22.7 Heterogeneous multi-sensor network management
Multi-sensormanagementconcernswiththecontrolofenvironmentperceptionactivitiesbymanagingor
coordinating the usage of multiple heterogeneous sensor resources. Multi-sensor systems are becoming
increasingly important in a variety of military and civilian applications. Since a single sensor generally
can only perceive limited partial information about the environment, multiple similar and/or dissimilar
sensors are required to provide sufﬁcient local pictures with different focus and from different viewpoints
in an integrated manner. As viewed, information from heterogeneous sensors can be combined using
data fusion algorithms to obtain synergistic observation effects. Thus the beneﬁt of multi-sensors system
are to broaden perception and enhance awareness of the state of the world compared to what could be
acquired by a single sensor system. The increased sophistication of sensor assets along with the large
amounts of data to be processed has pushed the information acquisition problem far beyond what can
be handled by human operator. This motivates the emerging interest in research into automatic and
semi-automatic management of sensor resources for improving overall perception performance beyond
basic fusion of data.
Multi-sensor management is formally described as a system or process that seeks to manage or
coordinate the usage of a suite of sensors or measurement devices in a dynamic, uncertain environment,
to improve the performance of data fusion and ultimately that of perception.
The basic objective of sensor management is to select the right sensors to do the right service on
the right object at the right time. Sensor management, aiming at improving data fusion performance
by controlling sensor behavior, plays the role of level 4 functions in JDL model presented in Section
2.22.3.Mainlythesameconsiderationsmadeforhomogeneoussensornetworksarestillvalid:thecriteria
followed to manage the network remains the same, however there is an increasing of complexity due to
the diversity of the sensors. In the following Sections the problems related to multi-sensor management
are divided into three main categories i.e., sensor deployment, sensor behavior assignment, and sensor
coordination.
2.22.7.1 Sensor deployment
Sensor deployment is a critical issue for intelligence collection in an uncertain dynamic environment.
It concerns with making decisions about when, where, and how many sensing resources need to be
deployed in reaction to the state of the environment and its changes.
Sensor placement needs special attention in sensor deployment. It consists of positioning multiple
sensorssimultaneouslyinoptimalornearoptimallocationstosupportsurveillancetaskswhennecessary.
Typically it is desired to locate sensors within a particular region determined by tactical situations to
optimize a certain criterion usually expressed in terms of global detection probability, quality of tracks,
etc. This problem can be formulated as one of constrained optimization of a set of parameters. It is
subject to constraints due to the following factors:
•
sensors are usually restricted to speciﬁed regions due to tactical considerations;
•
critical restrictions may be imposed on relative positions of adjacent sensors to enable their mutual
communication when sensors are arranged as distributed assets in a decentralized network (e.g.,
net-centric approach);

1286
CHAPTER 22 Integrated Sensor Systems and Data Fusion
•
the amount of sensing resources that can be positioned in a given period is limited due to logistical
restrictions.
In simple cases, decisions on sensor placement are to be made with respect to a well-prescribed
and stationary environment. An example of a stationary problem is the placing of radars to minimize
the terrain screening effect in detection of an aircraft approaching a ﬁxed site. Another example is
the arrangement of a network of intelligence gathering assets in a speciﬁed region to target another
well-deﬁned area. In the above scenarios, mathematical or physical models such as terrain models,
propagation models, etc. are commonly available and they are used as the basis for evaluation of sensor
placement decisions. Paper [139] presents a study for ﬁnding a solution to the placement of territorial
resources for multi-purpose telecommunication services considering also the restrictions imposed by
the orography of the territory itself. To solve this problem genetic algorithms5 are used to identify sites
to place the resources for the optimal coverage of a given area. The used algorithm has demonstrated
to be able to ﬁnd optimal solutions in a variety of considered situations.
More challenging are those situations in which the environment is dynamic and sensors must repeat-
edly be repositioned to be able to reﬁne and update the state estimation of moving targets in real time.
Typical situations where reactive sensor placement is required are, for instance, submarine tracking by
means of passive sonobuoys in an anti-submarine warfare scenario; locating moving transmitters using
ESM (Electronic Support Measures) receivers; tracking of tanks on land by dropping passive acoustic
sensors.
2.22.7.2 Sensor behavior assignment
The basic purpose of sensor management is to adapt sensor behavior to dynamic environments. By
sensor behavior assignment is meant efﬁcient determination and planning of sensor functions and usage
according to changing situation awareness or mission requirements. Two crucial points are involved.
Firstly the decisions about the set of observation tasks (referred to as system-level tasks) that the sensor
system is supposed to accomplish currently or in the near future, on the basis of the current/predicted
situation as well as the given mission goal. Secondly the planning and scheduling of actions of the
deployed sensors to best accomplish the proposed observation tasks and their objectives.
Owing to limited sensing resources, it is prevalent in real applications that available sensors are not
able to serve all desired tasks and achieve all their associated objectives simultaneously. Therefore a
reasonable compromise between conﬂicting demands is sought. Intuitively, more urgent or important
tasks should be given higher priority in their competition for resources. Thus a scheme is required to
prioritize observation tasks. Information about task priority can be very useful in scheduling of sensor
actions and for negotiation between sensors in a decentralized paradigm.
To focus on this class of problems, let us consider a scenario including a number of targets as well
as multiple sensors, which are capable of focusing on different objects with different modes for target
tracking and/or classiﬁcation. The ﬁrst step for the sensor management system should be to utilize
evidences gathered to decide objects of interest and to prioritize which objects to look at in the time
5Genetic algorithm (GA) is a search heuristic that mimics the process of natural evolution. This heuristic is routinely used
to generate useful solutions to optimization and search problems. GA belongs to the larger class of evolutionary algorithms
(EA), which generate solutions to optimization problems using techniques inspired by natural evolution, such as inheritance,
mutation, selection, and crossover [140].

2.22.7 Heterogeneous Multi-Sensor Network Management
1287
following. Subsequently, in the second step, different sensors together with their modes are allocated
across the interesting objects to achieve best situation awareness. In fact, owing to the constraints on
sensors and computational resources, it is in general not possible to measure all targets of interest
with all sensors in a single time interval. Also, improvement of the accuracy on one object may lead
to degradation of performance on another object. What is required is a suitable compromise among
different targets.
2.22.7.3 Sensor coordination in a decentralized sensor network
As stated in the previous Sections, there are two general ways to integrate a set of sensors into a sensor
network. One is the centra1ized paradigm, where all actions of all sensors are decided by a central
mechanism. The other alternative is to treat sensors in the network as distributed intelligent agents with
some degree of autonomy. In such a decentralized architecture, bi-directional communication between
sensors is enabled, so that communication bottlenecks possibly existing in a centralized network can
be avoided. A major research objective of decentralized sensor management is to establish cooperative
behavior between sensors with no or little external supervision. In a decentralized sensor network sce-
nario a local view perceived from a sensor can be shared by some members of the sensor community.
Intuitively, a local picture from one sensor can be used to direct the attention of other sensors or transfer
tasks such as target tracking from one sensor to another. An interesting question is how participating
sensors can autonomously coordinate their movements and sensing actions, on grounds of shared infor-
mation, to develop an optimal global awareness of the environment with parsimonious consumption of
time and resources.
As for homogeneous sensor network, the CSIP approach can be exploited [141,142]: the network
consists of different kinds of sensors, randomly distributed inside the surveillance area and if the
number of sensors is high, the performance of the surveillance system can be considered independent
of the location of the targets. Each sensor has a different functioning level. A ﬁrst level sensor, with
small sensing and communication capabilities may provide only detection information; a second level
sensor may provide detection and localization information, with medium sensing and communication
capabilities. Finally a third level sensor may provide tracking information and may be able to perform
target recognition and classiﬁcation. Usually the number of low level sensors exceeds the number of
higher level sensors and only close sensors exchange data.
In [143] the network consists of two types of sensors: simple and complex as represented in
Figure 22.19a. The simple ones have only the capability of sensing their coverage area with a reduced
computation capabilities and they transmit data to complex sensors. The information they provide may
be encoded, for example, by a “1” if sensor detects something crossing its coverage area and by a “0”
otherwise. Complex sensors, instead, have computation capabilities; they are able to locate the target
by applying sophisticated algorithms (e.g., in [143] the maximum likelihood estimation algorithm is
applied). The topology simulated in [143], constituted by 80 simple sensors and 20 complex sensors, is
represented in Figure 22.19b: the sensors are indicated by circles; the complex sensors are connected
by the solid lines, simple and complex sensor by dashed lines. Figure 22.20 shows the number of
active sensors during the target tracking: the theoretical value and the simulated value are compared.
It is evident that in a self-organizing conﬁguration the number of active sensors is optimized with the
consequent advantage of saving of power.

1288
CHAPTER 22 Integrated Sensor Systems and Data Fusion
FIGURE 22.19
(a) Network architecture scheme; (b) deployment of simple and complex nodes simulated in [143]. (Reprinted
with permission.)
An adaptive self-conﬁguring system consists of a collection of independent randomly located sensors
that,carryingaheadlocalinteractions,estimatethepositionofthetargetwithoutacentralizedcontrolunit
that coordinates their communication. It is fault tolerant and adapts to changing conditions. Furthermore,
it is able to self-conﬁguring, i.e., there is not an external entity that conﬁgures the network. Finally,
the task is performed efﬁciently, i.e., it guarantees both a reasonably long network life and good target
tracking performances. From local interactions, sensors form an efﬁcient system that follows the target,
i.e., local communication leads to a self-organizing network that exploits the features of the theories
of random graphs and of self-organizing systems. The most natural way to approach random network
topology is by means of the theory of random graphs [144,145]. The theory of random graphs allows,
for instance, to compute an upper bound to the estimated number of active sensors at each time step.
2.22.7.4 A mathematical issue for multi-sensor networks
When the fusion of heterogeneous signals is performed, there is a formal problem to solve. The signal
received by the different sensors may be statistically dependent because of the complex intermodal
interactions; usually the statistical dependence is either ignored or not adequately considered. Usually
the multiple hypotheses testing theory is based on the statistical independence of the received signals,
in our case this condition is not maintained, therefore techniques as the “copula probability theory” may
be useful.
In probability theory and statistics, a copula can be used to describe the dependence between random
variables [146]. The cumulative distribution function of a random vector can be written in terms of

2.22.7 Heterogeneous Multi-Sensor Network Management
1289
FIGURE 22.20
Average number of active sensors as function of the step number of the algorithm; simulation and theoretical
values. (From [143], reprinted with permission.)
marginal distribution functions and a copula. The marginal distribution functions describe the marginal
distribution of each component of the random vector and the copula describes the dependence struc-
ture between the components. Copulas are popular in statistical applications as they allow one to
easily model and estimate the distribution of random vectors by estimating marginal distributions and
copula separately. The Sklar’s theorem ensures that the joint cumulative distribution function (cdf)
FZ(z1, z2, . . . , zN) of random variables Z1, Z2, . . . , Z N are joined by a copula function C(·) to the
respective marginal distributions FZ1(z1), FZ2(z2), . . . , FZN (zN) as [147]:
FZ(z1, z2, . . . , zN) = C(FZ1(z1), FZ2(z2), . . . , FZN (zN)).
(22.43)
Further, if the marginals are continuous, C(·) is unique. By the differentiation of the joint cdf, the
joint pdf is obtained:
f (z1, z2, . . . , zN) =
 N

i=1
f (zi)

c(FZ1(z1), FZ2(z2), . . . , FZN (zN)).
(22.44)
The copula density c(·), function of the N marginals from the N sensors, represents a correction term
of the independent product of densities of Eq. (22.44).

1290
CHAPTER 22 Integrated Sensor Systems and Data Fusion
Processing heterogeneous data set is not straightforward as they may not be commensurate. In
addition, the signals may also exhibit statistical dependence due to overlapping ﬁelds of view. In [148]
the authors propose a copula-based solution to incorporate statistical dependence between disparate
sources of information. The important problem of identifying the best copula for binary classiﬁcation
problems is also addressed and a copula based test-statistic, able to decouples marginals and dependency
information, is developed.
2.22.8 Border control problem via electronic fence
This section tackles the problem of the surveillance of the borders of a nation. The region of interest, in
general, may be very wide consisting even of thousands of kilometers of coastline and land border line,
and millions of square kilometers. Such a system must face threats such as drug trafﬁcking, intrusions
(man, vehicles and airplanes), illegal immigration, smuggling, human trafﬁcking, arms smuggling,
unauthorized deforestation, terrorist activities over the military defense of the borders in order to ensure
the territorial defense and the national sovereignty in the areas close to the border line. In the following
Sections an overview of the range of possibilities and solutions in the design of the surveillance asset
and data fusion process of such systems devoted to border control is given.
2.22.8.1 Multi-scale approach
The size of the region, the nature of the border and the complexity of the scenario require the provision
of different pictures of the region with different ﬁeld of view at different resolution and time scales,
suggesting a multi-sensor/multi-scale approach integrated in a hierarchical architecture of the whole
system. Typically a global ﬁeld of view of the whole region is necessary at the higher Command
and Control (C2) level to capture the overall situation. A higher level of resolution and refresh rate
is necessary at the lower and local level to analyze and control in depth each single zone of a region.
Therefore the surveillance segment may be structured according to a multilayer architecture where layers
realize different trade-offs in terms of ﬁeld of view and granularity and refresh time. The surveillance
segment comprises several types of sensors, each one characterized by different achievable resolution,
ﬁeld of view, and revisiting time. A pictorial sketch of the surveillance architecture is depicted in
Figure 22.21 for a notional country: sensors on board of satellites are expected to provide a global
coverage of the monitored area at medium resolution with a low refresh rate, typically in the order
of several hours or days; a higher resolution data and a higher refresh rate, in the order of seconds
or tens of seconds, is provided by ground sensors on limited areas; airborne sensors (e.g., Unmanned
Air Vehicle, UAV) will provide data on remote areas with good resolution data and short deployment
time.
All data collected by the sensors are exploited by the fusion engine, highlighted in the ﬁgure. It
is responsible to track and classify relevant entities present in the scenario and to provide a high
quality representation of the situation. Also the data fusion process supports this multi-scale approach
performing a distributed and network-centric processing at the various levels of the architecture, in
accordance with available communication bandwidth and latency.

2.22.8 Border Control Problem via Electronic Fence
1291
FIGURE 22.21
Pictorial of the surveillance architecture.
2.22.8.2 The electronic fence
The surveillance of critical perimeters is one of the most important issues in Homeland defense and
Homeland Protection systems. The ground surveillance needs are relevant to border protection appli-
cations, but include also local area protection, such as critical infrastructure, military/civilian posts.
During the last 10 years special attention has been focused on the realization of so-called “electronic
fence” for perimeter/border control and several developments have been carried out to demonstrate
the efﬁciency of such systems. However several problems occurred when the electronic fences became
operational, showing lacks in the practical use by the operators (i.e., high number of false alarms,
loss of/slow communication links) together with the problem of the high funding required for the
whole system. One example is described in [149], that requires now a total different approach for the
surveillance of a wide national border (>500 km).
In the following an overview of the problems and solutions related to the implementation of an
electronic fence is presented. The major components are:

1292
CHAPTER 22 Integrated Sensor Systems and Data Fusion
•
Sensors: they may be either active or passive, radar networks or heterogeneous sensor networks,
(e.g., passive IR—infrared, seismic, acoustic, electro-optic—E/O, etc.).
•
Communication network: necessary to data exchange, may be subdivided into sub-networks if nec-
essary.
•
Fusion engines: they perform data collection, data fusion and classiﬁcation; this capability can be
spread across the layers that compose the electronic fence (i.e., in the master stations, but also in the
C2 centers).
Depending on the geographical deployment of the protection system, the data are then exchanged
with C2 centers, both at local level and wide area (i.e., national) level. In Figure 22.22 an example of
an electronic fence architecture is depicted. In this case a wide area to be controlled, such as a border
of a nation, has been considered; the subnets are geographically distributed along the boundaries. The
architecture has the advantage to be modular and scalable and it can be organized with different level
C2 centers (local, regional, national), depending also on the size of the considered boundaries. Each
subnet is able to ensure the data exchange among the sensors. An overview of the sensors that can be
employed in an electronic fence is presented.
FIGURE 22.22
Example of electronic fence architecture.

2.22.8 Border Control Problem via Electronic Fence
1293
2.22.8.2.1
Sensors
Ground-based sensors
Microwave (X, Ku, Ka band) ground based radars are widely used to perform the monitoring of open
wide areas. The monitoring of walking people and vehicles for ground applications, and of small sized
boat for sea and river applications are relevant. The detection ranges varies from 2 km to 10 km for
people, and from 5 km to 20 km for vehicles. Aerial targets (e.g., helicopters, low level aircraft) are
also detected. Depending on the technology used these radars can be subdivided into the following two
categories:
•
Incoherent: they are low cost devices, FMCW (Frequency Modulated Continuous Wave) or pulsed
(often a magnetron is used as most of the navigational radars), where the detection of the moving
targets is based on inter-clutter visibility. Resolutions are typically of few meters or tenths of meters
both in range and cross-range.
•
Coherent: they are solid state transmitter based, FMCW or pulse compressed, where the detection of
the moving targets is based on sub-clutter visibility. The MTD (Moving Target Detection) ﬁltering,
even if the radar is working at X-band, requires low scan rates (in the order of 1–3 RPM—Round
Per Minute) to allow high Doppler frequency resolution (0.2–0.5 m/s) to resolve slow moving target
also in presence of strong clutter [150].
Airborne sensors
The attention is for sensors able to operate in critical environments and many studies have been per-
formed, in this direction, mainly using aerial platforms equipped with SAR. The aircraft equipped with
sensors are used for wide areas where ground based sensors are not suitable or cannot be installed, such
as in forest or jungle. However the use of airborne platforms to perform surveillance, are limited to
missions “on spot” because it is not practical or cost/effective for continuous surveillance. The radar
sensor can be mounted on manned or unmanned aircraft, usually equipped with electro-optic devices,
and they can be used to monitor areas of several tenths of kilometer length. Other solutions take into
account the installation of the radar either on a tethered aerostat or on a hovering helicopter. GMTI
(Ground Moving Target Indication) from a stationary platform has been demonstrated.
FOliage PENetrating (FOPEN) radar
Fixed radars for border control are usually in X and Ku band, but, because of the attenuation they suffer
from foliage, they cannot be used for FOPEN applications. The ability of traditional microwave radars in
operating in an environment with dense foliage is severely limited by foliage backscatter and attenuation
of microwave frequencies through foliage [151]. As attenuation falls with increasing wavelength, lower
frequencies such as those in the VHF and UHF bands (30–1000 MHz) may be suitable for FOPEN
radar applications [152–155]. FOPEN SAR (Synthetic Aperture Radar) systems started to be used in
the early 1990s. They are usually mounted on manned or unmanned aircraft and mainly address illegal
activity control and search-and-rescue operations. The focus is now for ground based systems and/or
sensors with capabilities to detect walking personnel and moving vehicles [156]. Logistic constraints
drive the technology to very low power devices, that are able to operate for several months or years,
without maintenance. Another important issue is, together with a good probability of detection, the low

1294
CHAPTER 22 Integrated Sensor Systems and Data Fusion
false alarm probability, that is requested to be lowered up to 1 false alarm per day, or lower, even in
presence of speciﬁc weather conditions (rain, wind) and/or local seasonal fauna.
A special attention is due to the effect of environment. In dense foliage environments the main clutter
effects are the backscatter and the attenuation.
Backscatter: The ﬁxed clutter returns can have a zero Doppler component raising up to 60–70 dB above
the noise level with spectra amplitude and shape without large variations with frequency, but depending
mainly on the wind strength [150]. Considering the measurements reported in [150] of the backscatter
Doppler spectra, in order to perform efﬁcient clutter rejection, two values of thresholds can be used:
i.e., 1 m/s in case of light air, 2 m/s in case of windy/gale.
Attenuation: The attenuation depends mainly on the frequency used and the radar beam grazing angle,
even if small variations are reported with different polarizations [153]. Many studies have been carried
out for SAR application and several studies report data for attenuation measured directly at ground level
[151,153,154,157]. The total attenuation, taking in account the major effects of the environment for a
ground radar, can be summarized as follows:
Lt = Lr LhL f ,
(22.45)
where:
•
Lr =
1

4π R22 is the attenuation due to distance R,
•
Lh = (4π hthr
λR )4 is the attenuation due to the ground reﬂection at the heights of the antenna (hr) and
the target (ht), for the wavelength λ,
•
L f is the attenuation due to the foliage: it depends on the distance, the polarization and the forest
type. It depends also on the distribution of the trees and the diameter of the masts, that can limit the
line of sight, together with the height and density of lower canopy level.
The main requirements/constraints addressed are the range of the detections, which is reduced by
the attenuation due to foliage and the low antenna height, that is usually limited to 1–2 m for logistic
purposes. Also the power consumption must be kept at minimum level, also considering that photovoltaic
cells are not suitable for installation on the ground in the forest. As a consequence the emitted power
must be kept at a level of several mW. Camouﬂage and anti-tamper are often required. Very low cost
is a mandatory requirement. Low Probability of Intercept (LPI) capabilities are necessary. Walking
personnel and moving vehicles should be detected.
Even if the FOPEN radars are referred to the forest environment, the sensor described above
is suitable to operate also in different installations, considering, for example, riverside or sea har-
bor protection applications. In these cases the different environmental conditions allow to achieve
better radar performances. In addition, several other constraints (for example the management of
transmitted power) can be mitigated by the use of photovoltaic cells and/or different antenna
installations.
In Figures 22.23 and 22.24 some outputs of the target detected by the UHF radar are shown. The
information are displayed on range-Doppler maps, that are suitable to be read by a trained operator,
giving information on the radial speed and, with a medium–high resolution in range, it helps the operator
in the targets discrimination and alarm recognition.

2.22.8 Border Control Problem via Electronic Fence
1295
FIGURE 22.23
UHF radar range-Doppler map: walking people.
FIGURE 22.24
UHF radar range-Doppler map: vehicles.

1296
CHAPTER 22 Integrated Sensor Systems and Data Fusion
FIGURE 22.25
An example of positioning of UGPS in operative ﬁeld.
Other sensors
In this section we consider the Unattended Ground Passive Sensors (UGPS) and Electro-Optic (EO) to
detect moving people or vehicles.
UGPS. They are used in case of small areas or critical infrastructure perimeter surveillance. They
give alarms in presence of target in the operational range and, in some cases, can give a pre-classiﬁcation
of the target detected. The range of each sensor is usually limited to 10 m, but the latest technologies
promise to reach detection ranges up to 50 m. They have very small dimension (less than 1 l volume)
and low weight (less than 1 kg); they can be rapidly installed on rough ground or roads. Figure 22.25
gives an example of positioning of UGPS in an operative ﬁeld. They are of following basic types:
•
seismic: to detect seismic movement produced by vehicles wheels or people walking,
•
acoustic: to detect vehicle engine noise,
•
infrared: to detect differences in thermal data from the environment due to the infrared signature of
people and vehicles,
•
magnetic: to detect magnetic ﬁled variation produced by vehicles.
Electro-Optic: They are widely used for surveillance, and many signal processing techniques assist
the operator for target detection alerts.
They can be ﬁxed or rotating covering up to 360◦in azimuth. For the night vision infrared EO are
used, either passive or active, and they can reach a visibility of several kilometers in range. The EO
are normally used stand alone or connected with radar sensor to help the operator for classiﬁcation and
identiﬁcation of the detected targets. For example, with active infrared the operator can read (up to 2 km
far from the camera) the license plate of a vehicle previously detected and tracked by the radar.
2.22.8.2.2
Sensor network
The sensors operate in cluster, and they are connected via a low power RF link, operating at UHF or
L/S bands. The data of the unmanned radars can be combined with the data of other UGPS sensors

2.22.8 Border Control Problem via Electronic Fence
1297
C2 and 
operator
console
FIGURE 22.26
Unattended ground radar network.
(infrared, acoustic, seismic), or connected to an existing network, to perform a more reliable detection
system.
In Figure 22.26 an example of sensor network is reported. As shown, adjacent sensor nodes are
connected together and the information are sent, to the master station, via the short range radio link; the
master station performs data fusion and medium range connection with the other master stations, or the
C2 center. In case of long range connection the master stations are connected via radio link repeaters
or satellite connections.
Special care must be taken to avoid interactions among the sensors, where two or more sensors share
the same visibility area. Mutual interferences can be avoided using different frequencies and/or different
timing for the transmitted waveform and also orthogonally coded waveforms.
The data transfer among the nodes is performed using the radio link between adjacent nodes. In case
of linear geometric distribution the data grow up linearly with the number of nodes in the subnet; as
a consequence the number of nodes in the subnet is limited by the maximum data rate of the single
connection link.
The linear electronic fence can be composed of two or more parallel sections to allow redundancy
in case of failure or loss of visibility of one or more sensors.
An example of electronic fence is shown in Figure 22.27. In this case different environment conditions
have been considered (riverside, forest, manmade buildings, and obstacles) and a network of FOPEN
unattended ground radar sensors is used.
2.22.8.2.3
Fusion engine
The fusion engine allows to fuse heterogeneous sensor data at multiple levels to perform tracking and
classiﬁcation of relevant entities present in the scenario and to provide a high quality representation of
the situation together with cartographic layers and sensed images of the terrain. Figure 22.28 provides
an example of architecture for the fusion engine.

1298
CHAPTER 22 Integrated Sensor Systems and Data Fusion
FIGURE 22.27
Border surveillance: a notional case.
FIGURE 22.28
Fusion engine architecture.
The tracking function processes the raw data provided by sensors and generates a set of tracks, repre-
sentative of the real entities present in the scenario. A track typically carries the following information:
a timestamp, position coordinates, velocity components, uncertainty on the kinematic components
as expressed through the covariance matrix and additional attributes such as class/type and identity.
In consideration of the potentially huge geographic extension of the system and of the importance

2.22.8 Border Control Problem via Electronic Fence
1299
to optimize the deployment of sensors as well as communication and processing power resources, a
distributed tracking architecture is necessary. At the ﬁrst level of the tracking architecture each sensor
produces its own “local” tracks, in order to make available to the fusion engine a ﬁltered informa-
tion. Then a second level tracking combines local tracks originating from different sources into system
tracks. This solution distributes the computational load on the peripheral nodes and reduces consider-
ably the communication trafﬁc which must be transmitted from the local level to the higher echelons;
this is extremely important in consideration of the reduced bandwidth generally available between the
peripheral elements and the center of the system.
In this step of the process, information of different nature can be fused producing a unique high
quality information. Radar tracks can be fused with multiple images acquired by SAR and optical
sensors, even if acquired at different resolutions, to achieve an improved representation of the scene
with respect to the one achievable by processing data sets separately, in particular in terms of detection
and false alarm probabilities when dealing with small targets (i.e., targets that occupy only few pixels
of the image) [158–162]. The cartographic layers, superimposed with SAR or optical images, allow to
put into context all the available information and support the fusion process (e.g., target tracking for
ground vehicles especially during maneuvers).
Another output of the fusion engine is the classiﬁcation of the tracked targets and entities of the
scenario, i.e., the attribution of a class to the track under examination, hence supporting the capability
to achieve a situation awareness.
From an operational point of view, the fusion engine can be considered as the responsible of producing
a multi-resolution and multi-layer COP (Common Operating Picture), whose deﬁnition, as provided
by [163], is the following: “A single identical display of relevant information shared by more than
one command that facilitates collaborative planning and assists all echelons to achieve situational
awareness.” The COP therefore provides to the operators at the different levels the capability to view
each time a well-suited map, both in terms of proper scale (with respect to the scale of the observed
situation) as well as in terms of number and type of information, according to the situation under
analysis. This characteristic allows the system to properly support the operator without overloading him
with unimportant information and keep him focused on events and information that might be related
with his goal in terms of spatial, temporal, and logic correlation.
In the following the main constituents of the fusion engine are described.
Local tracking
The local tracking function processes the measurements provided by the sensor and produces a local
track for each of the observed targets present in the surveillance region. The task of the tracking function
at the local level is therefore of using the measurements made available by the sensor to estimate the
number of targets and their kinematic components [164–166]. Local tracks provide position and velocity
estimates at a given time, together with an indication of track quality; the track may also include other
attributes relative to track classiﬁcation, derived directly from radar measurements, from other sensors
(EO/IR, UGPS, UAV) or assigned by a human operator.
In the scenario of a generic land border may be necessary to form low altitude tracks, surface tracks
and ground tracks. Tracking of ground targets is especially critical due to the characteristics of the
ground environment and of ground targets. The main criticality may be the masking effect due to terrain
orography and vegetation. Another interesting feature of the ground environment is the presence of areas,

1300
CHAPTER 22 Integrated Sensor Systems and Data Fusion
mainly roads, where the probability of ﬁnding targets is higher, and areas such as off-road where the
presence of targets is less probable. Distinguishing features of ground targets are high maneuverability
and move-stop-move dynamics.
Even a well trained operator would be unable to select the correct hypothesis when a ground target
is maneuvering since available information is insufﬁcient. In these situations the best strategy is to
defer the ﬁnal decision until more data is available. To take into account these difﬁculties, the tracking
function must be designed so as to handle several concurrent hypotheses and to make ﬁnal decisions
with a deferred logic [167–169], i.e., when more data is available which allows to make a ﬁnal decision
with sufﬁcient conﬁdence. The choice of hypotheses is also dependent on the environment and on the
target type. The management of multiple hypotheses is then the capability of the function to consider
at each time instant a set of hypotheses, such as:
•
the target is proceeding regularly/is maneuvering on road;
•
the target is moving/maneuvering off-road;
•
the target has stopped, etc.
The tracking function assigns a score to each hypothesis and identiﬁes the most probable; the function
keeps alive for some time not only the most likely hypothesis but also a set of alternative hypotheses
which represent different kinematic evolutions of the target. Figure 22.29 shows an example of the set
of hypotheses generated by the function: each hypothesis is relative to a path in the tree from time t0
to time t3 and the single branches may be relative to the choice of a speciﬁc dynamic model and/or a
speciﬁc correlation hypothesis with a measurement in the set. For example in the path highlighted in
red it is assumed that the target trajectory in the interval t0–t3 is described by the dynamic model m1;
the other branches are relative to alternative hypotheses where it is assumed for example that the target
has maneuvered (m2) or stopped (m3), etc. As new information is acquired, the probability of each
hypothesis is updated according to new information; hypothesis which initially have a low score may
gain credibility and vice versa. This characteristic, i.e., defer the decision until the available information
is considered sufﬁcient, allows to resolve most critical situations.
To take into account terrain and geographic information, the tracking solution leverages also context
information provided by the GIS (Geographic Information System) in accordance with logics of terrain
FIGURE 22.29
Set of hypotheses generated for a track.

2.22.8 Border Control Problem via Electronic Fence
1301
(a)
(b)
FIGURE 22.30
(a) Terrain aided tracking; (b) road aided tracking.
and road aided tracking. Digital Terrain Elevation Data (DTED) are also used to perform accurate
projections of the tracks on the terrain and to identify zones where the target trajectory will be masked
by obstacles and thus improve track continuity and the estimate of track kinematic parameters (e.g.,
maximum target velocity given the terrain type). The following Figure 22.30 shows, for instance, how
environmental knowledge can be exploited to improve the tracking function [170,171]. Figure 22.30a
shows a landscape covered by forests and crossed by a network of paths; due to the nature of the
environment, targets especially if motorized, will preferentially move along the track, avoiding off-road
areas more difﬁcult to traverse. The blue line represents the trajectory of a track which moves along a
winding path in the forest. Figure 22.30b on the other side shows how information relative to roads and
viability in general can be exploited to improve the tracking performance. When the track approaches
a bifurcation or a crossing, different hypotheses are generated to take into account possible target
trajectories, such as on-road, off-road and also move-stop motion. More speciﬁcally the adoption of
techniques such as road aided tracking is speciﬁcally important since it allows to improve the accuracy
in the estimation of target kinematic parameters and therefore to make longer term projections. Finally
weather information is exploited to further improve the tracking processing by feeding in information
about areas where target detection is less probable (e.g., ﬂooded areas) and expected target velocity is low
given the past days weather conditions (e.g., heavy rain is expected to result in limited target velocity).
Classiﬁcation
The classiﬁcation function allows attributing a class to the track under examination, i.e., to determine
its belonging to a class of targets. Target classiﬁcation is extremely important since it helps to determine
target identity and its threat level. Part of the classiﬁcation process is the non-cooperative target recog-
nition (NCTR), in order to avoid fratricide and to allow proper allocation of defensive means against
the threat. In a coastal scenario NCTR capabilities are needed against ships, potentially involved in
terrorism, illegal immigration or contraband operations, in order to assess and prioritize threats and to
provide the appropriate response.
Sensors such as radar, EO/IR, may provide useful information for classiﬁcation. In the radar case, the
NCTR technology facilitates the identiﬁcation of non-co-operative targets by transmitting wide band
signals and by processing the radar echoes in a suitable multidimensional domain; e.g., time-frequency
and range-angle. In the former case the target is discriminated on the basis of the jet engine or the

1302
CHAPTER 22 Integrated Sensor Systems and Data Fusion
FIGURE 22.31
A snapshot of ISAR (Inverse SAR) signal processing, a proﬁle of a ship along range and cross-range.
helicopter rotor modulations of the echo [172–175]; in the latter case the target is discriminated on the
basis of the measured two-dimensional radar image obtained by ISAR techniques [176–178] (Figure
22.31 shows a snapshot of the radar image of a ship).
The automatic classiﬁcation, that the radar is capable of providing by means of these processing
techniques, is used directly within the tracking function, to support the plot-track correlation process and
to attribute a class to the track. The classiﬁcation process allows therefore determining the class to which
the track belongs (such as pedestrians, vehicles, convoys, helicopters, and small low altitude aircrafts)
and performing cueing to other sensors (e.g., EO/IR sensors, high resolution radars) or demanding a
patrolling mission (e.g., a mission with UAV).
While data provided by sensors are needed to perform the classiﬁcation processing, once the target
has been assigned to a class, this information can be exploited at sensor level to achieve better accuracy
in the performed processing (e.g., target classiﬁcation can be used to reﬁne kinematic target parameters
used in the tracking processing).
The range-Doppler information can be furthermore employed to produce a confusion matrix useful
for target classiﬁcation. The confusion matrix expresses the a posteriori probability that a target has
been classiﬁed correctly among a ﬁnite number of classes that have been a priori established. References
[21,179] give an example of the use of confusion matrix in the classiﬁcation issue.
2.22.9 Estimation and forecasting of an epidemic
Epidemics can impose serious challenges on societies in modern times. The poor health of general
population due to a disease causes hardship and pain but also negative trends in the economy through

2.22.9 Estimation and Forecasting of an Epidemic
1303
absenteeism from work, missed business opportunities, etc. The ongoing epidemics of AIDS (Acquired
Immune Deﬁciency Syndrome), tuberculosis and the recent outbreaks of SARS (Severe Acute Respi-
ratory Syndrome) and H1N1 (swine ﬂu) provide some revealing examples.
In the absence of an effective cure against an infectious disease, the best approach to mitigate
its malicious or natural epidemic outbreak resides in the development of a capability for its early
detection and prediction of its further development [180]. This enables typical countermeasures, such
as the quarantine, vaccination, medical treatment, to be much more effective and less costly [181,182].
Therefore this issue can be approached as a surveillance problem in the context of Homeland Protection.
Syndromic surveillance is referred to as a systematic collection, analysis, and interpretation of public
health data for the purpose of early detection of an epidemic outbreak and the mobilization of a rapid
response [180,182]. The key idea is to detect an epidemic outbreak using early symptoms, well before
the clinical or laboratory data result in a deﬁnite diagnosis. The rationale is that a spread of an infectious
disease is usually associated with the measurable changes in the social behavior, which can be measured
by non-medical means. Recent studies [183–185] have demonstrated that these non-medical sources of
syndromic data streams, such as the absenteeism from work/school, the pharmaceutical sales, internet
queries, twitter messages, and alike, can enable one to draw important conclusions regarding the epi-
demic state in the community. The “Google Flu” project [186] (ﬂu-related searches in Google) is a well
publicized example of this approach.
The algorithms for syndromic surveillance and have recently attracted signiﬁcant attention by scien-
tists and practitioners; there is a vast amount of literature devoted to this topic (for more comprehensive
review see [180,182] and references therein). In general, all algorithms applied in this area can be
divided into two main groups, the data mining methods and the information fusion (also known as data
assimilation) methods. Data mining is primarily concerned with the extraction of patterns from massive
amounts of raw data without using dynamic models of the underlying process (i.e., epidemic spread)
[183,185]. Information fusion algorithms, on the contrary, strongly rely of mathematical models: in
this case, the dynamic model of an epidemic outbreak and the measurement model of a particular syn-
dromic data stream [187,188]. Naturally, the accuracy of information fusion algorithms is signiﬁcantly
determined by the ﬁdelity of the underlying models.
This section presents a study of a recursive information fusion algorithm for syndromic surveillance,
formulated in the Bayesian context of stochastic nonlinear ﬁltering and solved using a particle ﬁlter
[134]. While a similar work has been considered earlier, see [189–192], this section introduces two
novelties. First, in order to overcome the limitations of the standard “compartment” model of epidemic
spread (the “well-mixed” approximation) we employ a more ﬂexible alternative, see [193,194]. The
adopted epidemic model has the explicit parameter of “mixing efﬁciency” (or level of social interac-
tion) and is therefore more appropriate to represent a variety of social interactions in a small community
(e.g., self-isolation and panic). An advantage of the adopted epidemiological model is also that it
enables to estimate the scaling law of the noise level with respect to the population size of a com-
munity. Second, a more ﬂexible model of syndromic measurements, validated with data sets available
in the literature [183,186], is adopted in the section. This measurement model is robust in the sense
that some of its parameters are speciﬁed imprecisely, as interval values. The optimal sequential esti-
mator (ﬁlter) and predictor are then formulated in the Bayesian framework and solved using a particle
ﬁlter.

1304
CHAPTER 22 Integrated Sensor Systems and Data Fusion
2.22.9.1 Modeling
To describe the dynamics of an epidemic outbreak we employ the generalized SIR (Susceptible, Infec-
tious and Recovered) epidemic model with stochastic ﬂuctuations [195–197]. According to this model,
the population of a community can be divided into three interacting groups: susceptible, infectious and
recovered. Let the number of susceptible, infectious and recovered be denoted by S, I, and R, respectively,
so that S + I + R = P, where P is the total population size. The dynamic model of epidemic progression
in time can be then expressed by two stochastic differential equations subject to the “conservation” law
for the population:
ds
dt = −α · i · sν + σqξ,
di
dt = α · i · sν −β · i −σqξ + σβζ,
(22.46)
r = 1 −s −i,
where s = S/P, i = I/P, r = R/P, and ξ, ζare two uncorrelated white Gaussian noise processes,
both with zero mean and unit variance. The terms σqξ and σβζ are introduced into Eq. (22.47) to capture
the demographic noise (random variations in the contact rate α and in the recovery time β) [197,198].
Parameter ν in Eq. (22.47) is the population mixing parameter, which for a homogeneous population
equals 1. In the presence of an epidemic, however, ν may vary as people change their daily habits to
reduce the risk of infection (e.g., panic, self-isolation). In general, model parameters α, β, ν can be
assumed to be partially known as interval values. In order to insure P {s, i,r ∈[0, 1]} ≈1, standard
deviations σq, σβ need to satisfy [199]:
σq ≈
√α
P ,
σβ ≈
√β
P .
(22.47)
Assuming that non-medical syndromic data are available for estimation and forecasting of the epi-
demic, we adopt a measurement model veriﬁed by [185,186], where a power law relationship holds for
the odds-ratio between the observable syndrome z j and the (normalized) number of infected people i:
z j
1 −z j
∝

i
1 −i
ς j
,
j = 1, . . . , Nz.
(22.48)
The power law exponent ς j in Eq. (22.48) is in general syndrome speciﬁc. Since at the initial stages
of an epidemic (which is of main interest for early detection and forecasting) we have: i ≪1 and
z j ≪1, Eq. (22.48) can be reduced to a simple power-law model:
z j = b j · iς j + τ j,
(22.49)
where b j is a constant and τ j is introduced to model the random nature of measurement noise. It
is assumed that τ j is uncorrelated to other syndromes and dynamic noises ξ,ζ. Since z j ≥0 (e.g.,
number of Google searches), the noise term τ j associated with syndrome j should be modeled by a
random variable that provides strictly non-negative realizations. For this purpose we adopt the log-
normal distribution, that is τ j = σ jη j, with η j ∼ln N(0, 1) and N(0, 1) being the standard Gaussian
distribution.

2.22.9 Estimation and Forecasting of an Epidemic
1305
Parameters b j, σ j, ς j typically are not known, but with a representative data set of observations the
model of Eq. (22.49) can be easily calibrated (see for example the results of the linear regression ﬁts in
[186]). The data ﬁt reported in [183] suggests that ς j may be close to unity, although it is difﬁcult to
precisely specify its value because of signiﬁcant scattering of data points). To cater for this uncertainty,
we assume that ς j can take any value in an interval, ς ∈

ς1, ς2

around ς = 1. Unfortunately [185,186]
do not report any speciﬁc values of ﬁtting parameters, so we use in this study some heuristic values for
b j, σ j in our simulations.
The problem now is to estimate the (normalized) number of infected i, and susceptible s at time t,
using syndromic observations z j of Eq. (22.49), collected up to time t. Let x denote the state vector to
be estimated; it includes i and s, but also the imprecisely known epidemic model parameters α, β and
ν. The formal Bayesian solution is given in the form of the posterior pdf p(xt|z1:t), where xt is the state
vector at time t and z1:t denotes all observations up to time t. Using the posterior p(xt|z1:t), one can
predict the progress of the epidemic using the dynamic model of Eq. (22.47).
2.22.9.2 Sequential Bayesian solution
For the purpose of computer implementation, ﬁrst we need a discrete-time approximation of dynamic
model of Eq. (22.47). The state vector is adopted as: x =

i s α β ν
T , where T is the matrix transpose.
Using Euler’s method with small integration interval δ, the nonlinear differential equations in Eq. (22.47)
can be approximated as
xk+1 ≈fk(xk) + wk,
(22.50)
where k = tk/δ is the discrete-time index and
fk(x) =
⎡
⎢⎢⎢⎢⎣
x[1] + δ · x[1] · (x[3] · x[2]x[5] −x[4])
x[2] −δ · x[3] · x[1] · x[2]x[5]
x[3]
x[4]
x[5]
⎤
⎥⎥⎥⎥⎦
(22.51)
is the transition function; here x[i] denotes the ith component of vector x. Discrete-time process noise
wk in Eq. (22.50) is assumed to be zero-mean white Gaussian with diagonal covariance matrix Q, which
according to Eq. (22.47) can be expressed as Q = diag[(α + β)δ2/P2, αδ2/P2, 0, 0, 0].
The optimal Bayes ﬁlter is typically presented in two steps, prediction and update. Suppose the
posterior pdf at time tk is given by p(xk Z|1:k). Then the prediction step computes the pdf predicted to
time tm = tk + δ as [194]:
p(xm|z1:k) =

π(xm|xk)p(xk|z1:k)dxk,
(22.52)
where π(xm|xk) is the transitional density. According to Eq. (22.50), we can write π(xm|xk) =
N( fk(xk), Q). The prediction step is carried out many times with tiny sampling intervals δ until observa-
tion z j,k+1 about syndrome j becomes available at tk+1. The predicted pdf at tk+1 is denoted p(xk+1|z1:k).
In the standard Bayesian estimation framework, the predicted pdf is updated using measurement
z j,k+1 by multiplication with the measurement likelihood function [200]. According to Eq. (22.49), the
likelihood function in this case is g(z j,k+1|xk) = ln N(h(xk+1; ς j), σ 2
j ), where h(x; ς) = b j · x

1
ς.

1306
CHAPTER 22 Integrated Sensor Systems and Data Fusion
The standard Bayesian approach, however, cannot be applied because h(x; ς) deﬁned in this way is not
a function: ς is effectively an inﬁnite set (an interval) and therefore h(x; ς) is one-to-many mapping.
An elegant solution to the imprecise measurement transformation is available in the framework
of random set theory [137]. In this approach h(x; ς) + τ is modeled by a random set x and the
likelihood function represents the probability: ˜g(z|x) = Pr {z ∈x}, and is referred to as the generalized
likelihood. More details and a theoretical justiﬁcation of this approach can be found in [201]. The Bayes
update using syndromic measurement z j,k+1 is now deﬁned as [137]:
p(xk+1|z1:k+1) =
˜g

z|xk+1

· p

xk+1|z1:k

 
˜g

z|xk+1

· p

xk+1|z1:k

dxk+1
.
(22.53)
For the measurement model Eq. (22.49) with additive Gaussian noise, the generalized likelihood has
an analytic expression [201]:
˜g(z j|x) = ϕ

z; x, σ 2
j

−ϕ

z; x, σ 2
j

,
(22.54)
where x = min{h(x; ς), h(x; ς)}, x = max{h(x; ς), h(x; ς)} deﬁne the limits of the set and
ϕ(u; μ, P) =
 u
−∞ln N(y; μ, P)dy is the cumulative log-normal distribution. The recursions of the
Bayes ﬁlter start with an initial pdf (at time tk = 0), denoted p(x0), which is assumed known.
0
20
40
60
80
100
120
0
100
200
300
400
500
600
700
800
900
Time [days]
Number of infected
SIR model
experimental
FIGURE 22.32
Experimental data set: the solid blue line represents the number of infected people over time (obtained
by agent based simulation); the dashed red line is the ﬁtted non-homogeneous mixing SIR model. (For
interpretation of the references to color in this ﬁgure legend, the reader is referred to the web version of
this book.)

2.22.9 Estimation and Forecasting of an Epidemic
1307
The proposed Bayesian estimator cannot be solved in the closed form. Instead we developed an
approximate solution based on the particle ﬁlter (PF) [134,202]. The PF approximates the posterior pdf
p(xk|z1:k) by a weighted random samples; details can be found in [134,202]. The only difference here
is that importance weight computation is based on the generalized likelihood function.
2.22.9.3 Numerical results
Epidemic forecasting will be demonstrated using an experimental data set obtained using a large-scale
agent based simulation model [203,204] of a virtual town of P = 5000 inhabitants, created in accordance
with the Australian Census Bureau data. The agent based model is rather complex (takes a long time to
run) and incorporates a typical age/gender breakdown, family-household-workplace habits, including
the realistic day-to-day people contacts for a disease spread. The blue line in Figure 22.32 shows the
number of people of this town infected by a ﬁctitious disease, reported once per day during a period of
154 days (only ﬁrst 120 days shown). The dashed red line represents the adopted SIR model ﬁt, using
the entire batch of 154 data points and integration interval δ = 0.0052 days, with no process noise, i.e.,
wk = 0 in Eq. (22.50). The estimated model parameters are: ˆα = 0.2399, ˆβ = 0.1066, ˆν = 1.2042.
1500
0.2
0.25
0.3
0.35
0.4
0.45
0.5
0
500
1000
α
1000
0.1
0.105
0.11
0.115
0.12
0.125
0.13
0.135
0.14
0
500
β
600
ν
0.95
1
1.05
1.1
1.15
1.2
1.25
1.3
0
200
400
ν
FIGURE 22.33
Histograms of particle ﬁlter estimated values of epidemic model parameters after processing 25 days of
syndromic measurements. Red vertical lines indicate the true values. (For interpretation of the references to
color in this ﬁgure legend, the reader is referred to the web version of this book.)

1308
CHAPTER 22 Integrated Sensor Systems and Data Fusion
0
20
40
60
80
100
120
0
0.05
0.1
0.15
0.2
0.25
0.3
TIME [days]
Proportion of infected (I / P)
FIGURE 22.34
Prediction results for a random sample of 100 particles (gray lines); the red line is the experimental curve
from Figure 22.32. (For interpretation of the references to color in this ﬁgure legend, the reader is referred
to the web version of this book.)
These estimates were obtained using the importance sampling technique of progressive correction
[202]. Figure 22.32 serves to verify that the adopted non-homogeneous mixing SIR model, although
very simple and fast to run, is remarkably accurate in explaining the data obtained from a very complex
simulation system.
The true number of infected people in forecasting simulations is chosen to be the output of the
agent based population model, shown by the solid blue line in Figure 22.32. The measurements are
generated synthetically in accordance with Eq. (22.49) and discussions above, using the following
parameters: ς = 1.05, b j = 0.25, σ j = 0.01, for all j = 1, 2, 3, 4 monitored syndromes. Independent
measurements concerning all Nz = 4 syndromes are assumed available on a daily basis during the ﬁrst
25 days. The problem is to perform the estimation sequentially as the measurements become available
until the day number 25, and at that point of time to forecast the number of infected people as a function
of time.
The initial pdf for the state vector was chosen as p(x0) = p(i0)p(s0)p(α0)p(β0)p(ν0) with
p(i0) = N[0,1](z j,1/b j, σ 2
j ),
p(s0) = N[0,1](1 −z j,1/b j, σ 2
j ), p(α0) = U[0.18, 0.5],
p(β0) =
U[0.1, 0.143],
p(ν0) = U[0.95, 1.3], where N[a,b](μ, P) and U[a, b] denote the truncated Gaussian
distribution, restricted to [a, b], and uniform distribution, respectively. The imprecise measurement
parameter is adopted as ς ∈[1.03, 1.07], while its true value The number of particles is set to 10,000.
Figure 22.33 shows the histograms of particle ﬁlter estimated values of α, β, and ν, after processing
25 days of syndromic data (i.e., in total 100 measurements). The histograms in this ﬁgure reveals that the

2.22.10 Conclusion
1309
uncertainty in parameters α and β has been substantially reduced after processing the data (compared
with the initial p(α0) and p(β0)). The uncertainty in ν, on the other hand, has not been reduced,
indicating that this parameter cannot be estimated from syndromic data. While this is unfortunate, it
does not appear to be a serious problem in forecasting the epidemic mainly because the prior on ν in
practice is fairly tight ( ν ≈1). This is conﬁrmed in Figure 22.34 which shows a sample of 100 overlaid
predicted epidemic curves (gray lines) based on the estimate of i, s, α, β, ν obtained after 25 days.
Figure 22.34 indicates that the forecast of the peak of the epidemic is fairly accurate, while the forecast
of the size of the peak is more uncertain. Most importantly, however, the true epidemic curve (solid red
line) appears to be always enveloped by the prediction curves. More experimental results can be found
in [199].
2.22.10 Conclusions
Integrated sensor systems and data fusion have been the main focus of this chapter. The discussed matter
has been subdivided in nine sections which have covered a long trip starting from the description of the
Homeland Protection problem, to the illustration of a wide spectrum of information sources (sensors and
the like), to the netting of such sensors (both homogeneous and heterogeneous), with a broad range of
practical applications: cooperative sensing to defend a urban territory, network of cooperative chemical
sensors, detection and localization of radioactive point sources, use of so-called electronic fence to
protect long borderlines of a territory, up to the estimation and forecasting of an epidemic. This work,
an unofﬁcial collaboration between experts from industry, research centers and academia, has brought
together a wide spectrum of competences scientiﬁc, technical/technological/systemic and on the ﬁeld.
List of Acronyms
AEW
Airborne Early Warning
AIDS
Acquired Immune Deﬁciency Syndrome
AJP
Allied Joint Publication
ATC
Air Trafﬁc Control
BASH
Bird Air Strike Hazard
C2
Command and Control
C4I
Command, Control, Communications, Computers, and Intelligence
CBINT
Chemical and Biological Intelligence
cdf
Cumulative distribution function
COMINT
Communications Intelligence
COP
Common Operating Picture
CRLB
Cramer-Rao Lower Bound
CSIP
Collaborative Signal and Information Processing
CTR
Cooperative Target Recognition
DFS
Data Fusion Subpanel

1310
CHAPTER 22 Integrated Sensor Systems and Data Fusion
DIKW
Data Information Knowledge and Wisdom)
DSC
Dynamic Sensor Collaboration
DSTO
Defense Science and Technology Organisation
DTED
Digital Terrain Elevation Data
EA
Evolutionary Algorithms
ECM
Electronic Counter Measures
EEZ
Exclusive Economic Zone
EKF
Extended KF
ELINT
Electronic Intelligence
EML
Exact Maximum Likelihood
EO
Electro-Optical
ESM
Electronic Support Measurement
ESM
Electronic Support Measures
FIM
Fisher Information Matrix
FMCW
Frequency Modulated Continuous Wave
FOPEN
Foliage PENetration
GA
Genetic Algorithm
GEMS
Generic Error modeling System
GEOINT
Geospatial Intelligence
GIS
Geographic Information System
GM
Geiger-Müller
GMTI
Ground Moving Target Indicator
HAP
High Altitude Platform
HD
Homeland Defense
HP
Homeland Protection
HS
Homeland Security
HUMINT
Human Intelligence
IFF
Identiﬁcation Friend or Foe
IMINT
Imagery Intelligence
IR
Infra Red
ISAR
Inverse SAR
JDL
Joint Directors of Laboratories
KF
Kalman Filter
LADAR
Laser Radar
LASINT
Laser Intelligence
LPI
Low Probability of Intercept
MASINT
Measurement and Signature Intelligence
MCMC
Markov Chain Monte Carlo
MDL
Minimum Description Length
MRT
Multi-Radar Tracking
MTD
Moving Target Detector
MTI
Moving Target Indicator
NCO
Network Centric Operation

References
1311
NCTR
Non-Cooperative Target Recognition
NUCINT
Nuclear Intelligence
ODNA
Ofﬁce of Directors of National Intelligence
OODA
Observe-Orient-Decide-Act)
OSINT
Open-Source Intelligence
PCRLB
Posterior cramer rao lower bound
pdf
Probability density function
PF
Particle Filter
RADINT
Radar Intelligence
RPM
Route Per Minute
SAR
Synthetic Aperture Radar
SARS
Severe Acute Respiratory Syndrome
SIR
Susceptible Infectious Recovered
SIGINT
Signals Intelligence
TV
Television
UAV
Unmanned Air Vehicle
UGPS
Unattended Ground Passive Sensor
UHF
Ultra High Frequency
UKF
Unscented KF
USAF
United States Air Force
VHF
Very High Frequency
WSN
Wireless Sensor Network
Acknowledgments
The ﬁrst two authors wish to warmly thank Prof F. Zirilli (Univ. of Rome) for his contribution to Section 2.22.6.1,
Dr. S. Gallone (SELEX Sistemi Integrati) for contributing to Section 2.22.8.2 and Dr. A. Graziano (SELEX Sistemi
Integrati) for the continuous and fruitful cooperation on the many topics described in the Chapter for years.
References
[1] J. Naisbitt, Megatrends, GCP, 1982.
[2] R.T. Antony, Principles of Data Fusion Automation, Artech House, 1995.
[3] A. Doucet, N. de Freitas, N. Gordon (Eds.), Sequential Monte Carlo Methods in Practice, Springer Verlag,
New York, 2001.
[4] R.E. Kalman, A new approach to linear ﬁltering and prediction problems, Trans. ASME – J. Basic Eng. 82
(1960) 35–45.
[5] A.G.O. Mutambara, Decentralized Estimation and Control for Multi-Sensor Systems, CRC Press, 1998.
[6] G.J. Klir, Y. Bo, Fuzzy Logic: Theory and Applications, Prentice Hall PTR, 1995.
[7] A.P. Dempster, A generalization of Bayesian inference, J. Roy. Stat. Soc. 30 (1968) 205–247.
[8] G. Shafer, A Mathematical Theory of Evidence, Princeton University Press, 1976.

1312
CHAPTER 22 Integrated Sensor Systems and Data Fusion
[9] F. Smarandache, J. Dezert (Eds.), Advances and Applications of DSmT for Information Fusion, vol. 1,
American Research Press, 2004.
[10] F. Smarandache, J. Dezert (Eds.), Advances and Applications of DSmT for Information Fusion, vol. 2,
American Research Press, 2004.
[11] A. Farina, S. Pardini, Introduction to multiradar tracking system, Rivista Tecnica Selenia 8 (1) (1982) 14–26.
[12] A. Farina, F.A. Studer, Radar data processing, in: P. Bowron (Ed.), Introduction and Tracking, vol. I,
Researches Studies Press, John Wiley, England, 1985 (Translated in Russian—Radio I Sviaz-, Moscow,
1993—and in Chinese—China Defense Publishing House in 1988).
[13] A. Farina, F.A. Studer, Data Processing, in: P. Bowron (Ed.), Advanced Topics and Applications, vol. 2,
Researches Studies Press, John Wiley, England, 1986 (Translated in Chinese—China Defence Publishing
House in 1992).
[14] A. Farina, Target tracking with bearings-only measurements, Signal Process. 78 (1) (1999) 81–78.
[15] A. Farina, R. Miglioli, Association between active and passive tracks for airborne sensors, Signal Process.
69 (3) (1998) 209–217.
[16] A. Farina, B. La Scala, Methods for association of active and passive tracks for airborne sensors, in: Int.
Symp. Radar, IRS98, Munich, Germany, September 15–17, 1998, pp. 735–744.
[17] B. La Scala, A. Farina, Choosing a track association method, Inform. Fusion J. 3 (2) (2002) 119–133.
[18] E. Waltz, J. Llinas, Multisensor Data Fusion, Artech House, Norwood, MA, 1990.
[19] D. Hall, Mathematical Techniques in Multisensory Data Fusion, Artech House, Norwood, MA, 1992.
[20] D.S. Alberts, J. Garstka, F.P. Stein, Network Centric Warfare: Developing and Leveraging Information
Superiority, National Defence Press, USA, 1999.
[21] A. Farina, A. Graziano, L. Ortenzi, E. Spinogatti, The role of modelling and simulation (M and S) in the
analysis of integrated systems for homeland protection, in: G. Franceschetti, M. Grossi (Eds.), Homeland
Security Technology Challenges, From Sensing and Encrypting to Mining and Modelling, Artech House,
2008 (Chapter 9).
[22] C.J. Skinner, S. Cochrane, M. Field, R. Johnston, Defence Against Terrorism: The Evolution of military
Surveillance Systems into Effective Counter Terrorism Systems Suitable for Use in Combined Military
Civil Environments, Dream or Reality? NATO Panel Systems, Concepts and Integration (SCI) Methods and
Technologies for Defence Against Terrorism, London, UK, October 25–27, 2004.
[23] US Ofﬁce of Homeland Security: National Strategy for Homeland Security, Washington, DC, July 2002.
<http://www.whitehouse.gov/homeland/book/nat_strat_hls.pdf>.
[24] U.S. Environmental Protection Agency: Strategic Plan for Homeland Security, Washington, DC, September
2002. <http://www.epa.gov/epahome/downloads/epa_homeland_security_strategic_plan.pdf>.
[25] J. Moteff, C. Copeland, J, Fischer, Critical Infrastructure: What Makes an Infrastructure Critical? Report for
Congress RL31556, The Library of Congress, August 2002. <www.fas.org/irp/crs/RL31556.pdf>.
[26] US Government, The National Strategy for the Physical Protection of Critical Infrastructure and Key Assets,
The White House, Washington, DC, February 2003.
[27] S. Bologna, R. Setola, The need to improve local self-awareness in CIP/CIIP, in: Proceeding of 1st IEEE Int.
Workshop on CIP (IWCIP 2005), Darmstadt, Germany, November 3–4, 2005, pp. 84–89.
[28] S. Rinaldi, J. Peerenboom, T. Kelly, Identifying, understanding and analyzing critical infrastructure interde-
pendencies, IEEE Control Syst. Mag. 21 (6) (2001) 11–25.
[29] <http://www.icc-ccs.org/piracy-reporting-centre>.
[30] Archive of International Maritime Bureau Piracy and Armed Robbery Reports, IMB Publications, 2008.
[31] A. Farina, S. Giompapa, A. Graziano, Analysis of emerging phenomena in large complex systems, in:
Franceschetti G, Grossi M (Eds.), Homeland Security–Facets: Threats, Countermeasures, and the Privacy
Issue, Artech House, 2011 (Chapter 4).

References
1313
[32] R. Zimmerman, Decision making and the vulnerability of interdependent critical infrastructure, in: Proceed-
ing of the IEEE Conference on Systems, Man and Cybernetics 2004, The Hague, The Netherlands, October
10–13, 2004, pp. 4059–4063.
[33] R. Setola, S. Geretshuber, Critical information infrastructure security, in: Third International Workshop
CRITIS, Frascati (Rome), Italy, October 2008, pp. 13–15.
[34] S.T. Smith, A. Silberfarb, S. Philips, E.K. Kao, C. Anderson, Network discovery using wide-area surveillance
data, in: Proceedings of IEEE Conference on Information Fusion 2011, Lexington, MA, USA, July 5–8, 2011,
pp. 1–8.
[35] A. Starr, M. Desforges, Strategies in data fusion–sorting through the tool box, in: Bedworth, O’Brien (Eds.),
Proceedings of EuroFusion98 International Conference on Data Fusion, 1998, pp. 85–90.
[36] A.N. Steinberg, C.L. Bowman, A systems engineering approach for implementing data fusion systems, in:
D.L. Hall, J. Llinas (Eds.), Handbook of Multisensor Data Fusion, CRC Press, London, 2001.
[37] F.E. White, A model for data fusion, in: Proceedings of the 1st National Symposium on Sensor Fusion, vol.
2, Chicago, USA, 1988, pp. 143–158.
[38] A.N. Steinberg, C.L. Bowman, F.E. White, Revisions to the JDL data fusions models, in: Proceedings of the
3rd NATO/IRIS Conference, Quebec City, Canada, 1998.
[39] E. Blasch, S. Plano, JDL Level 5 fusion model: user reﬁnement issues and applications in group tracking,
in: Proceedings of the SPIE Signal Processing Sensor Fusion Target Recognition XI, vol. 4729, 2002,
pp. 270–279.
[40] E. Blasch, S. Plano, Level 5: user reﬁnement to aid the fusion process, in: Proceedings of the SPIE, Mul-
tisensor, Multisource Information Fusion: Architectures, Algorithms, and Applications, vol. 5099, 2003,
pp. 288–297.
[41] E. Blasch, S. Plano, DFIG Level 5: user reﬁnement issues supporting situational assessment reasoning,
in: Proceedings of 8th International Conference on Information Fusion, Philadelphia, USA, July, 2005,
pp. 25–29.
[42] Subrata Das, High-Level Data Fusion, Artech House, 2008.
[43] J. Rowley, The wisdom hierarchy: representations of the DIKW hierarchy, J. Inform. Sci. 33 (2) (2007)
163–180.
[44] M.R. Endsley, Design and evaluation for situation awareness enhancement, in: Proceedings of the 32nd
Annual Meeting of the Human Factors Society, 1988, pp. 97–101.
[45] M.R. Endsley, Toward a theory of situation awareness in dynamic systems, Human Factors 37 (1) (1995)
32–64.
[46] M.R. Endsley, Measurement of situation awareness in dynamic systems, Human Factors 37 (1) (1995) 65–84.
[47] P.P. Perla, M. Markowitz, A.A. Noﬁ, C. Weuve, J. Loughran, M. Stahl, Gaming and shared situation aware-
ness, Alexandria, Virginia, Centre for Naval Analyses, 2000.
[48] J.R. Boyd, A Discourse on Winning and Losing, Unpublished Set of Brieﬁng Slides, Air University Library,
Maxwell AFB, AL, USA, May, 1987.
[49] T. Bass, Intrusion detection systems and multisensor data fusion: creating cyberspace situational awareness,
Commun. ACM 43 (4) (2000) 99–105.
[50] M.D. Bedworth, J. O’Brien, The omnibus model: a new architecture for data fusion? IEEE Trans. Aerosp.
Electron. Syst. 15 (4) (1999) 30–36.
[51] J. Rasmussen, Skills, rules and knowledge: signals, signs and symbolism, and other distinctions in human
performance models, IEEE Trans. Syst. Man Cybern. 12 (1983) 257–266.
[52] J. Rasmussen, Information Processing and Human Machine Interaction: An Approach to Cognitive Engi-
neering, North Holland, NY, 1986.
[53] J. Reason, Human Error, Cambridge University Press, Cambridge, UK, 1990.

1314
CHAPTER 22 Integrated Sensor Systems and Data Fusion
[54] USAF (United States Air Force): Air Force Pamphlet 14–210, Intelligence, USAF Intelligence Targeting
Guide, Department of Defense, USA, 1998.
[55] ODNI (Ofﬁce of Director of National Intelligence): How Do We Collect Intelligence? USA, 2008.
<http://www.dni.gov/who_what/what_collection.htm>.
[56] D. Krioukov, F. Papadopoulos, F. Vahdat, M. Boguna, Curvature and temperature of complex networks,
Phys. Rev. E 80 (2009) 035101(R).
[57] H.F. Durrant-Whyte, Sensor models and multi-sensor integration, Int. J. Robot. Res. 7 (6) (1988) 97–113.
[58] W. Elmenreich, Sensor fusion in time-triggered systems, PhD Thesis, Institut für Technische Informatik,
Vienna University of Technology, 2002.
[59] S.M. Kay, Statistical Signal Processing: Detection Theory, Prentice Hall, 1998.
[60] A. Farina, B. Ristic, L. Timmoneri, Cramer-Rao bound for nonlinear ﬁltering with Pd < 1 and its application
to target tracking, IEEE Trans. Signal Process. 50 (8) (2002) 1916–1924.
[61] M. Hernandez, B. Ristic, A. Farina, L. Timmoneri, A comparison of two Cramer-Rao bounds for non-linear
ﬁltering with Pd < 1, IEEE Trans. Signal Process. 52 (9) (2004) 2361–2370.
[62] A. Farina, B. Ristic, S. Immediata, L. Timmoneri, CRLB with Pd < 1 fused tracks, Fusion 2005, in: Pro-
ceedings of the 7th International Conference on Information Fusion, Philadelphia, USA, July 25–28, 2005,
pp. 191–196.
[63] T.J. Nohara, P. Weber, G. Jones, A. Ukrainec, A. Premji, Affordable high-performance radar networks for
homeland security applications, RADAR ’08, in: Proceedings of IEEE International Radar Conference,
Rome, Italy, May 26–30, 2008, pp. 1–6.
[64] T.J. Nohara, P. Weber, A. Premji, C. Krasnor, S. Gauthereaux, M. Brand, G. Key, Affordable avian radar
surveillance systems for natural resource management and BASH applications, RADAR 2005, in: Proceed-
ings of IEEE International Radar Conference, Arlington, Virginia, USA, May 9–12, 2005, pp. 10–15.
[65] Proceedings of 2nd Workshop on Cognitive Information Processing, Elba Island, Tuscany, Italy, June 14–16,
2010.
[66] Masazade, R. Niu, P.K. Varshney, M. Keskinoz, Energy aware iterative source localization for wireless sensor
networks, IEEE Trans. Signal Process. 58(9) (2010) 4824–4835.
[67] Feng Zhao, Jaewon Shin, J. Reich, Information-driven dynamic sensor collaboration, IEEE Signal Process.
Mag. 19 (2) (2002) 61–72.
[68] C.M. Kreucher, A.O. Hero, K.D. Kastella, M.R. Morelande, An information-based approach to sensor man-
agement in large dynamic networks, Proc. IEEE 95 (5) (2007) 978–999.
[69] J.L. Williams, J.W. Fisher, A.S. Willsky, Approximate dynamic programming for communication-
constrained sensor network management, IEEE Trans. Signal Process. 55 (8) (2007) 4300–4311.
[70] L. Zuo, R. Niu, P.K. Varshney, Conditional posterior Cramér–Rao lower bounds for nonlinear sequential
Bayesian estimation, IEEE Trans. Signal Process. 59 (1) (2001) 1–14.
[71] L. Zuo, R. Niu, P.K. Varshney, Posterior CRLB based sensor selection for target tracking in sensor net-
works, ICASSP 2007, in: IEEE International Conference on Acoustic Speech and Signal Processing, vol. 2,
Honolulu, Hawaii, April 15–20, 2007, pp. II-1041–II-1044.
[72] L. Zuo, R. Niu, P.K. Varshney, A sensor selection approach for target tracking in sensor networks with
quantized measurements, in: IEEE International Conference on Acoustic Speech and Signal Processing,
ICASSP 2008, Las Vegas, Nevada, USA, March 30–April 4, 2008, pp. 2521–2524.
[73] M.L. Hernandez, T. Kirubarajan, Y. Bar-Shalom, Multi-sensor resource deployment using posterior Cramer-
Rao bounds, IEEE Trans. Aerosp. Electron. Syst. 40 (2) (2004) 399–416.
[74] T.C. Collier, C. Taylor, Self-organization in sensor networks, J. Parall. Distr. Comput. 64 (7) (2004) 866–873.
[75] F.S. Cattivelli, A.H. Sayed, Modelling bird ﬂight formations using diffusion adaptation, IEEE Trans. Signal
Process. 59 (5) (2011) 2038–2051.

References
1315
[76] F.S. Cattivelli, A.H. Sayed, Distributed detection over adaptive networks using diffusion adaptation, IEEE
Trans. Signal Process. 59 (5) (2011) 1917–1932.
[77] C.G. Lopes, A.H. Sayed, Diffusion least-mean squares over adaptive networks: formulation and performance
analysis, IEEE Trans. Signal Process. 56 (7) (2008) 3122–3136.
[78] F.S. Cattivelli, A.H. Sayed, Diffusion LMS strategies for distributed estimation, IEEE Trans. Signal Process.
58 (3) (2010) 1035–1048.
[79] F.S. Cattivelli, C.G. Lopes, A.H. Sayed, Diffusion recursive least-squares for distributed estimation over
adaptive networks, IEEE Trans. Signal Process. 56 (5) (2008) 1865–1877.
[80] A. Pikovsky, M. Rosenblum, J. Kurths, Synchronization – A Universal Concept in Non Linear Sciences,
Cambridge University Press, Cambridge, UK, 2001.
[81] N.A. Lynch, Distributed Algorithms, Morgan-Kaufmann, San Mateo, CA, 1997.
[82] R. Olfati-Saber, J.S. Shamma, Consensus ﬁlters for sensor networks and distributed sensor fusion, in:
Proceeding of the Joint IEEE Conference On Decision and Control and the European Control Conf., Seville,
Spain, December 15, 2005, pp. 6698–6703.
[83] Y.W. Hong, L.F. Cheow, A. Scaglione, A simple method to reach detection consensus in massively
distributed sensor networks, in: Proceedings of International Symposium on Information Technology, ISIT
2004, Chicago, USA, July 2004, p. 250.
[84] D. Lucarelli, I.J. Wang, Decentralized synchronic protocols with nearest neighbor communication, in: Pro-
ceedings of the 2nd International Conference on Embedded Networked Sensor System, SenSys 2004, Bal-
timore, USA, November 3–5, 2004, pp. 62–68.
[85] S. Barbarossa, Self-organizing sensor networks with information propagation based on mutual coupling of
dynamic systems, in: Proceedings of International Workshop on Ad-hoc Wireless Network 2005, IWWAN
2005, London, UK, May 23–26, 2005.
[86] S. Barbarossa, G. Scutari, Decentralized maximum likelihood estimation for sensor networks composed of
nonlinearly coupled dynamical systems, IEEE Trans. Signal Process. 55 (7-I) (2007) 3456–3470.
[87] G. Scutari, S. Barbarossa, L. Pescosolido, Distributed decision through self-synchronizing sensor networks
in presence of propagation delays and asymmetric channels, IEEE Trans. Signal Process. 56 (4) (2008)
1667–1684.
[88] S. Barbarossa, G. Scutari, A. Swami, Achieving consensus in self-organizing wireless sensor networks, the
impact of network topology on energy consumption, in: Proceedings of ICASSP 2007, vol. 2, Honolulu,
Hawaii, April 15–20, 2007, pp. 841–844.
[89] S. Barbarossa, G. Scutari, Bio-inspired sensor network design, IEEE Signal Process. Mag. 24 (3) (2007)
26–35.
[90] S. Fortunati, F. Gini, M.S. Greco, A. Farina, A. Graziano, S. Giompapa, Least squares estimation and Cramér-
Rao type lower bounds for relative sensor registration process, IEEE Trans. Signal Process. 59 (3) (2011)
1075–1087.
[91] Yifeng Zhou, H. Leung, P.C. Yip, An exact maximum likelihood registration algorithm for data fusion, IEEE
Trans. Signal Process. 45 (6) (1997) 1560–1573.
[92] Zhenhua Li, Siyue Chen, H. Leung, E. Bosse, Joint data association, registration, and fusion using EM-KF,
IEEE Trans. Aerosp. Electron. Syst. 46 (2) (2010) 496–507.
[93] Siyue Chen, H. Leung, E. Bosse, A maximum likelihood approach to joint registration, association and
fusion for multi-sensor multi-target tracking, in: Proceedings of 12th International Conference on Information
Fusion, FUSION 2009, Seattle, USA, July 6–9, 2009, pp. 686–693.
[94] S. Herzel, M.C. Recchioni, F. Zirilli, A quadratically convergent method for linear programming, Linear
Algebra Appl. 152 (1991) 255–289.
[95] N. Karmarkar, A new polynomial time algorithm in linear programming, Combinatorica 4 (1984) 373–395.
[96] L. Hageman, D. Young, Applied Iterative Methods, Academic Press, New York, 1981.

1316
CHAPTER 22 Integrated Sensor Systems and Data Fusion
[97] A. Farina, A. Graziano, F. Mariani, F. Zirilli, A cooperative sensor network: optimal deployment and func-
tioning, RAIRO Oper. Res. 44 (4) (2009) 379–388 (special issue COGIS).
[98] F. Aurenhammer, Voronoi diagrams–a survey of a fundamental geometric data structure, ACM Comput.
Surv. 23 (3) (1991) 345–405.
[99] J.A. Snyman, Practical Mathematical Optimization: An Introduction to Basic Optimization Theory and
Classical and New Gradient-Based Algorithms, Springer, Cambridge, Massachusetts, USA, 2005.
[100] F.R. Chung, Spectral Graph Theory, American Mathematical Society, Providence, USA, CBMS 92, 1997.
[101] M.H. DeGroot, M.J. Schervish, Probability and Statistics, Pearson Addison Wesley, New York, 2002.
[102] C.S. Raghavendra, K.M. Sivalingam, Taieb Znati, Wireless Sensor Networks, Springer, USA, 2005.
[103] E. Ertin, J.W. Fisher, L.C. Potter, Maximum mutual information principle for dynamic sensor query problems,
Lect. Notes Comput. Sci. Inform. Process. Sensor Networks 2634 (2003) 91–104.
[104] F. Zhao, J. Shin, J. Reich, Information-driven dynamic sensor collaboration for tracking applications, IEEE
Signal Process. Mag. 19 (2) (2002) 61–72.
[105] J. Mathieu, G. Hwang, J. Dunyak, The State of the Art and the State of the Practice: Transferring Insights from
Complex Biological Systems to the Exploitation of Netted Sensors in Command and Control Enterprises,
MITRE Technical Papers, MITRE Corporation, USA, July 2006.
[106] A. Khelil, C. Becker, J. Tian, K. Rothermel, An epidemic model for information diffusion in MANETs, in:
Proceedings of the 5th ACM International Workshop on Modeling Analysis and Simulation of Wireless and
Mobile Systems, MSWiM 2002, Atlanta, Georgia, USA, September 28, 2002, pp. 54–60.
[107] P. De, Y. Liu, S.K. Das, An epidemic theoretic framework for evaluating broadcast protocols in wireless
sensor networks, , in: Proceedings of the 4th IEEE International Conference on Mobile Ad-hoc and Sensor
Systems, MASS 2007, Pisa, Italy, October 8–11, 2007, pp. 1–9.
[108] B. Ristic, A. Skvortsov, M. Morelande, Predicting the progress and the peak of an epidemics, in: Proceedings
of IEEE International Conference on Acoustics, Speech and Signal Processing 2009, ICASSP 2009, Taiwan,
April 19–24, 2009, pp. 513–516.
[109] A. Dekker, A. Skvortsov, Topological issues in sensor networks. in: MODSIM 2009: 2009 MSSANZ Inter-
national Congress on Modelling and Simulation, Cairns, Australia, July 13–17, 2009, pp. 952–958.
[110] S. Eubank, Anil Kumar VS, Marathe M: Epidemiology and wireless communication: tight analogy or loose
metaphor? Lect. Notes Comput. Sci. Bio-Inspir. Comput. Commun. 5151 (2008) 91–104.
[111] V. Bisignanesi, M.S. Borgas, Models for integrated pest management with chemicals in atmospheric surface
layers, Ecol. Modell. 201 (1) (2007) 2–10.
[112] A. Skvortsov, B. Ristic, M. Morelande, Networks of chemical sensors: a simple mathematical model for
optimisation study, in: 5th International Conference on Intelligent Sensors, Sensor Networks and Information
Processing, ISSNIP 2009, Melbourne, Australia, December 7–10, 2009, pp. 385–390.
[113] A. Gunatilaka, B. Ristic, A. Skvortsov, M. Morelande, Parameter estimation of a continuous chemical plume
source, in: IEEE 11th International Conference on Information Fusion, FUSION 2008, Cologne, Germany,
June 30–July 3, 2008, pp. 1–8.
[114] J.D. Murray, Mathematical Biology, vols. 8–12, Springer, USA, 2002.
[115] P.F. Verhulst, Recherches mathématiques sur la loi d’accroissement de la population, Nouv. mém. de
l’Academie Royale des Sci. et Belles-Lettres de Bruxelles 18 (1845) 1–41.
[116] Weisstein EW, Logistic Equation, MathWorld-A Wolfram Web Resource. <http://mathworld.wolfram.com/
LogisticEquation.html>.
[117] C. Mendis, A. Gunatilaka, A. Skvortsov, S. Karunasekera, The effect of correlation of chemical tracers
on chemical sensor network performance, in: Proceedings of 6th International Conference on Intelligent
Sensors, Sensor Networks and Information Processing, ISSNIP 2010, Brisbane, Australia, December 7–10,
2010, pp. 103–108.

References
1317
[118] A. Skvortsov, B. Ristic, Modelling and performance analysis of a network of chemical sensors with dynamic
collaboration, Int. J. Distr. Sensor Networks 2012 (2012) (article ID65231).
[119] S. Karunasekera, C. Mendis, A. Skvortsov, A. Gunatilaka, A decentralized dynamic sensor activation protocol
for chemical sensor networks, in: Proceedings of the 9th IEEE Symposium on Network Computing and
Applications, Cambridge, MA, USA, July 15–17, 2010, pp. 218–223.
[120] S. Karunasekera, J. Beaton, A. Dimech, A. Skvortsov, A. Gunatilaka, A distributed e-research tool for
evaluating source backtracking algorithms, in: Proceedings of IEEE 6th International Conference on e-
Science, Brisbane, Australia, December 7–10, 2010, pp. 17–24.
[121] R.J. Nemzek, J.S. Dreicer, D.C. Torney, T.T. Warnock, Distributed sensor networks for detection of mobile
radioactive sources, IEEE Trans. Nucl. Sci. 51 (4) (2004) 1693–1700.
[122] S.M. Brennan, A.M. Mielke, D.C. Torney, Radioactive source detection by sensor networks, IEEE Trans.
Nucl. Sci. 52 (3) (2005) 813–819.
[123] A.V. Klimenko, W.C. Priedhorsky, N.W. Hengartner, K.N. Borozin, Efﬁcient strategies for low-level nuclear
searches, IEEE Trans. Nucl. Sci. 53 (3) (2006) 1435–1442.
[124] A. Sundaresan, P.K. Varshney, N.S.V. Rao, Distributed detection of a nuclear radioactive source using fusion
of correlated decisions, in: Proceedings of IEEE International Conference on Information Fusion, FUSION
2007, Quebec, Canada, July 9–12, 2007, pp. 1–8.
[125] M.R. Morelande, B. Ristic, Radiological source detection and localisation using Bayesian techniques, IEEE
Trans. Signal Process. 57 (11) (2009) 4220–4231.
[126] N. Tsoulfanidis, Measurement and Detection of Radiation, Taylor and Francis, Washington, DC, 1995.
[127] R.A. Cortez, X. Papageorgiou, H.G. Tanner, A.V. Klimenko, K.N. Borozdin, R. Limia, W.C. Priedhorsky,
Smart radiation sensor management, IEEE Robot. Autom. Mag. 15 (3) (2008) 85–93.
[128] B. Ristic, M.R. Morelande, A. Gunatilaka, Information driven search for point sources of gamma radiation,
Signal Process. 90 (4) (2010) 1225–1239.
[129] A. Martin, S.A. Harbison, An Introduction to Radiation Protection, Chapman and Hall, 1987.
[130] AN/PDR-77 User’s Guide, Canberra Industries Inc., CT, USA.
[131] A. Gunatilaka, B. Ristic, LCAARS radiological ﬁeld trial and validation of source localisation algorithms,
DSTO Tech. Report, DSTO-TR-1988, 2009.
[132] A. Gunatilaka, B. Ristic, M.R. Morelande, Experimental veriﬁcation of algorithms for detection and esti-
mation of radioactive sources, in: Proceedings of 13th International Conference on Information Fusion,
FUSION 2010, Edinburgh, UK, July 26–29, 2010, pp. 1–8.
[133] C. Musso, N. Oudjane, F. LeGland, Improving regularised particle ﬁlters, in: N. Doucet, N. DeFreitas,
N.J. Gordon (Eds.), Sequential Monte Carlo methods in Practice, Springer-Verlag, New York, 2001.
[134] B. Ristic, S. Arulampalam, Beyond the Kalman Filter, Artech House, Gordon N, 2004.
[135] H.L. Van Trees, Detection, Estimation, and Modulation Theory (Part I), John Wiley and Sons, 1968.
[136] E. Yee, A. Gunatilaka, Comparison of two approaches for detection and estimation of radioactive sources,
Applied Mathematics, Ristic B, 2011.
[137] R. Mahler, Statistical Multi-Source Multi-Target Information Fusion, Artech House, 2007.
[138] M.R. Morelande, A. Skvortsov, Radiation ﬁeld estimation using a Gaussian mixture, in: Proceedings
of 12th International Conference on Information Fusion, FUSION 2009, Seattle, USA, July 6–9, 2009,
pp. 2247–2254.
[139] D. Cacciani, F. Garzia, A. Neri, R. Cusani, Optimal territorial placement for multi-purpose wireless service
using genetic algorithms, Wireless Eng. Technol. 2 (3) (2011) 184–195.
[140] D.E. Goldberg, Genetic Algorithms, Addison-Wesley, 1989.
[141] IEEE Signal Processing Magazine, Special Issue on Collaborative Processing, IEEE Press, March 2002.

1318
CHAPTER 22 Integrated Sensor Systems and Data Fusion
[142] R. Niu, P. Varshney, M. Moore, D. Klamer, Decision fusion in a wireless sensor network with a large number
of sensors, in: Proceedings of 7th IEEE International Conference on Information Fusion, FUSION 2004,
Stockholm, Sweden, June 28–July 1, 2004.
[143] A. Farina, G. Golino, A. Capponi, C. Pilotto, Surveillance by means of a random sensor network: a hetero-
geneous sensor approach, in: Proceedings of the 8th IEEE International Conference on Information Fusion,
FUSION 2005, vol. 2, Philadelphia, USA, July, 2005, pp. 25–28.
[144] R. Diestel, Graph Theory, Graduate Texts in Mathematics, Springer, 1997.
[145] B. Bollobas, Modern Graph Theory, Graduate Texts in Mathematics, vol. 184, Springer, 1998.
[146] R.B. Nelsen, An Introduction to Copulas, Springer, New York, 1999.
[147] A. Sklar, Fonctions de répartition à n dimensions et leurs marges, Publications de l’Institut de Statistique de
l’Université de Paris 8 (1959) 229–231.
[148] S.G. Iyengar, Varshney PK, T. Darmala, A parametric copula-based framework for hypothesis testing using
heterogeneous data, IEEE Trans. Signal Process. 59 (5) (2001) 2308–2319.
[149] R.N. Charette, The virual fence’s long good-bye, IEEE Spectr. (2011).
[150] J.B. Billingsley, Low-Angle Radar Land Clutter, SciTech. Pub. Inc., New York, 2001.
[151] B.T. Binder, M.F. Toups, S. Ayasli, E.M. Adams, SAR Foliage Penetration Phenomenology of Tropical Rain
Forest and Northern US Forest, in: Proceeding of IEEE International Radar Conference 1995, Washington
DC, USA, May 8–11, 1995, pp. 158–163.
[152] Y. Lu, Y. Cheng, W. Liu, H.W. Seah, H.L. Chan, L.C. Tai’, M. Lesturgie, P. Borderies, R. Guern, Low
frequency radar phenomenology study in equatorial vegetation – preliminary results, in: Proceeding of IEEE
Radar Conference 2002, October 15–17, 2002, pp. 70.
[153] M.E. Davis, Developments in foliage penetration radar, in: Proceeding of IEEE Radar Conference 2010,
Washington DC, USA, May 10–14, 2010, pp. 1233.
[154] M.N. Roy, S. Swamp, S.K. Tewari, Radio wave propagation through rain forests of India, IEEE Trans.
Antennas Propag. 38 (4) (April 1990) 433–449.
[155] M.E. Davis, Foliage Penetration Radar: Detection and Characterization of Objects Under Trees, SciTech.
Pub. Inc., New York, 2011.
[156] S. Gallone, FOPEN radar for UGS applications, in: Proceeding of CIE International Conference on Radar,
Chengdu, China, October 24–27, 2011.
[157] <http://www.cosmo-skymed.it/>.
[158] M. Costantini, A. Farina, F. Zirilli, The fusion of different resolution radar images: a new formalism invited
paper, Proc. IEEE 85 (1) (1997) 139–146 (special issue on Data Fusion).
[159] A.M. Signorini, A. Farina, G. Zappa, Application of multi-scale estimation algorithm to SAR images fusion,
in: Proceedings of International Symposium on Radar, IRS98, Munich, Germany, September 15–17, 1998,
pp. 1341–1352.
[160] G. Simone, C. Morabito, A. Farina, Radar image fusion by multiscale Kalman ﬁlter, in: Proceedings of
3rd IEEE International Conference on Fusion, FUSION 2000, Paris, France, July 10–13, 2000, pp. WeD3.
10–WeD3.17.
[161] G. Simone, C. Morabito, A. Farina, Multifrequency and multiresolution fusion of SAR images for remote
sensing applications, Fusion 2001, Montreal, Canada, August 2001, pp. 7–10.
[162] G. Simone, A. Farina, F.C. Morabito, S.B. Serpico, L. Bruzzone, Image fusion techniques for remote sensing
applications, Inform. Fusion 3 (1) (2002) 3–15.
[163] US Department of Defence Dictionary of Military Terms, USA, 2010. <http://www.dtic.mil/doctrine/dod_
dictionary/>
[164] Y. Bar-Shalom, X.R. Li, Estimation and Tracking: Principles, Techniques, and Software, Artech House,
1993.
[165] S.S. Blackman, R. Popoli, Design and Analysis of Modern Tracking Systems, Artech House, 1999.

References
1319
[166] Y. Bar-Shalom, X.R. Li, Kirubarajan T, Estimation with Applications to Tracking and Navigation, John
Wiley and Sons, 2004.
[167] A. Graziano, A. Farina, R. Miglioli, deFeo M: IMMJPDA vs., MHT and Kalman ﬁlter with NN correlation
performance comparison, IEE Proc. Radar Sonar Naviga. 144 (2) (1997) 49–56.
[168] W.G. Bath, Use of multiple hypothesis in radar tracking, Presented at Radar ’92, John Hopkins Applied
Physics Laboratory, USA, pp. 90–93.
[169] M. Hernandez, A. Benavoli, A. Graziano, A. Farina, F. Morelande, Performance measure and MHT for
tracking move-stop-move targets with MTI sensors, IEEE Trans. Aerosp. Electron. Syst. 47 (1) (2011)
996–1025.
[170] A. Farina, G. Golino, L. Ferrante, Constrained tracking ﬁlters for A-SMGCS, in: Proceedings of 6th Interna-
tional Conference on Information Fusion, FUSION 2003, Cairns, Queensland, Australia, July 8–11, 2003,
pp. 414–421.
[171] G. Golino, A. Farina, Track-plot correlation in A-SMGCS using the target images by a surface movement
radar, in: Proceedings of 7th International Conference on Information Fusion, FUSION 2004, Stockholm,
Sweden, June 28–July 1, 2004, pp. 999–1005.
[172] A. Di Lallo, A. Farina, L. Timmoneri, T. Volpi, Bi-dimensional analysis of simulated herm (helicopter
rotor modulation) and jem (jet engine modulation) radar signals for target recognition, in: Proceeding of
1st International Conference on Waveform Diversity and Design, WDDC 2004, Edinburgh, UK, November
8–10, 2004.
[173] S. Palumbo, S. Barbarossa, A. Farina, M.R. Toma, Classiﬁcation techniques of radar signals backscattered
by helicopter blades, in: Proceeding of International Symposium on Digital Signal Processing, ISDSP96,
London, UK, July 23–24, 1996, pp. 44–50.
[174] (a) A. Farina, F. Gini, A matched subspace approach to CFAR detection of hovering helicopters, in: Interna-
tional Symposium on Radar, IRS98, Munich, Germany, September 15–17, 1998, pp. 597–606; (b) F. Gini,
A. Farina, Matched subspace CFAR detection of hovering helicopters, IEEE Trans. Aerosp. Electron. Syst.
35 (4) 1293–1305.
[175] M.N. Saidi, K. Daoudi, A. Khenchaf, B. Hoeltzener, D. Aboutajdine, Automatic target recognition of aircraft
models based on ISAR images, in: Proceeding of IEEE International, IGARSS 2009, Cape Town, South,
Africa, July 12–17, 2009, pp. IV-685–IV-688.
[176] D. Pastina, C. Spina, Multi-feature based automatic recognition of ship targets in ISAR images, in: Proceeding
of IEEE International Radar Conference, Radar08, Rome, Italy, May 26–30, 2008, pp. 1–6.
[177] D. Pastina, C. Spina, Multi-frame data fusion techniques for ATR of ship targets from multiple ISAR images,
Proceeding of European Radar Conference, EuRAD 2009, Rome, Italy, September 30–October 2, 2009,
pp. 409–412.
[178] S. Giompapa, A. Farina, F. Gini, A. Graziano, R. Croci, R. Di Stefano, Naval target classiﬁcation based on
the confusion matrix, in: Proceeding of IEEE Aerospace Conference 2008, Big Sky, Montana, USA, March
1–8, 2008, pp. 1–9.
[179] M. Wagner, A. Moore, Aryel R, Handbook of Biosurveillance, Elsevier, 2006.
[180] J. Walden, E.H. Kaplan, Estimating time and size of bioterror attack, Emerg. Infect. Dis.10 (7) (2004)
1202–1205.
[181] A.G. Wilson, G.D. Wilson, D.H. Olwell, Statistical Methods in Counterterrorism: Aame Theory, Modelling,
Syndromic Surveillance, and Biometric Authentication, Springer, 2006.
[182] Eysenbach, Infodemiology: tracking ﬂu-related searches on the web for syndromic surveillance, in: Proceed-
ings of Symposium of American College Medical Informatics Association 2006, AMIA 2006, Washington,
DC, USA, November 11–15, 2006, pp. 244–248.
[183] N.M. Schuster, M.A. Rogers, Using search engine query data to track pharmaceutical utilization: a study of
statin, Am. J. Manag. Care 16 (8) (2010) e215–e219.

1320
CHAPTER 22 Integrated Sensor Systems and Data Fusion
[184] A. Culotta, Detecting inﬂuenza outbreaks by analyzing twitter messages, in: Proceedings of Conference on
Knowledge Discovery and Data Mining 2010, Washington, DC, USA, July 2010, pp. 25–28.
[185] J. Ginsberg, M.H. Mohebbi, R.S. Patel1, L. Brammer, M.S. Smolinski, L. Brilliant, Detecting inﬂuenza
epidemics using search engine query data, Nature 457 (2009) 1012–1015.
[186] B. Cazelles, N.P. Chau, Using the Kalman ﬁlter and dynamic models to assess the changing HIV/AIDS
epidemic, Math. Biosci. 140 (2) (1997) 131–154.
[187] J. Mandela, J.D. Beezleya, L. Cobba, A. Krishnamurthya, Data driven computing by the morphing fast
Fourier transform ensemble Kalman ﬁlter in epidemic spread simulations, Proc. Comput. Sci. 1 (1) (2010)
1221–1229.
[188] C. Jégat, F. Carrat, C. Lajaunie, H. Wackernagel, Early detection and assessment of epidemics by particle
ﬁltering, in: A. Soares, M.J. Pereira, R. Dimitrakopoulos (Eds.), geoENV VI Geostatistics for Environmental
Applications, vol. 15, Springer, 2008, pp. 23–35.
[189] J.B.S. Ong, M.I.C. Chen, A.R. Cook, H.C. Lee, V.J. Lee, R.T.P. Lin, P.A. Tambyah, L.G. Goh, Real-time
epidemic monitoring and forecasting of H1N1-2009 using inﬂuenza-like illness from general practice and
family doctor clinics in Singapore, PLoS ONE 5 (4) (2010) e10036.
[190] B. Ristic, A. Skvortsov, M. Morelande, Predicting the progress and the peak of an epidemic, in: Proceedings of
IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2009, Taipei, Taiwan,
April 19–24, 2009, pp. 513–516.
[191] A. Skvortsov, B. Ristic, C. Woodruff, Predicting an epidemic based on syndromic surveillance, in: Proceed-
ings of 13th International Conference on Information Fusion, FUSION 2010, Edinburgh, UK, July 26–29,
2010, pp. 1–8.
[192] P.D. Stroud, S.J. Sydoriak, J.M. Riese, J.P. Smith, S.M. Mniszewski, P.R. Romero, Semiempirical power-law
scaling of new infection rate to model epidemic dynamics with inhomogeneous mixing, Math. Biosci. 203
(2006) 301–318.
[193] A.S. Novozhilov, On the spread of epidemics in a closed heterogeneous population, Math. Biosci. 215 (2)
(2008) 177–185.
[194] R.M. Anderson, R.M. May, Population biology of infectious diseases: Part 1, Nature 280 (1979) 361–367.
[195] D.J. Daley, J. Gani, Epidemic Modelling, Cambridge University Press, 1996.
[196] C.E. Dangerﬁeld, J.V. Ross, M.J. Keeling, Integrating stochasticity and network structure into an epidemic
model, J. Roy. Soc. Interf. 6 (38) (2009) 761–774.
[197] O.A. van Herwaarden, J. Grasman, Stochastic epidemics: major outbreaks and the duration of the endemic
period, J. Math. Biol. 33 (4) (1995) 581–601.
[198] A. Skvortsov, B. Ristic, Monitoring and prediction of an epidemic outbreak using syndromic observations,
Math. Biosci 240 (2012) 12–19.
[199] A.H. Jazwinski, Stochastic Processes and Filtering Theory, Academic Press, 1970.
[200] B. Ristic, Bayesian estimation with imprecise likelihoods: random set approach, IEEE Signal Process. Lett.
18 (7) (2011) 395–398.
[201] M.S. Arulampalam, S. Maskell, N. Gordon, T. Clapp, A tutorial on particle ﬁlters for nonlinear/non-Gaussian
Bayesian tracking, IEEE Trans. Signal Process. 50 (2) (2002) 174–188.
[202] A. Skvortsov, R. Connell, P. Dawson, R. Gailis, Epidemic modelling: validation of agent based simulation
by using simple mathematical models, in: International Congress on Modelling and Simulation, MODSIM
2007, Christchurch, New Zealand, December 10–13, 2007, pp. 657–662.
[203] A. Skvortsov, R. Connell, P. Dawson, R. Gailis, Epidemic spread modelling: alignment of agent-based
simulation with a simple mathematical model, in: Proceedings of International Conference on Bioinformatics
and Computational Biology, BIOCOMP 2007, Las Vegas, USA, June 25–28, 2007, pp. 487–890.
[204] N. Oudjane, C. Musso, Progressive correction for regularized particle ﬁlters, in: Proceedings of 3rd Inter-
national Conference on Information Fusion, FUSION 2000, Paris, France, vol. 2, July 10–13, 2000,
pp. WEB5.26–WEB5.33.

1321
A
ACMA. See Algebraic Constant Modulus Algorithms (ACMA)
Across-track interferometry, 1044
Across-track SAR interferometry
statistical characterization of, 1055
surface topography, measuring, 1054
Across-track velocity
parameter estimation, 957
SAR imaging, 936
Active constellation extension (ACE), 242–243
Adaptive beamformer pattern synthesis, 624
Adaptive channel estimation, 118–119
Adaptive filter implementations
reduced-dimension STAP (RD-STAP), 630
post-Doppler STAP, 632
pre-Doppler STAP, 634
reduced-rank STAP, 622
adaptive beamformer pattern synthesis, 624
cross spectral metric, 627
diagonal loading, 626
eigencanceler, 625
Hung Turner Projection (HTP), 626
Multi-StageWiener Filter (MWF), 629
principle components inverse (PCI), 624
Adaptive precoding, 314
Adaptive SINR loss, 613
Adaptive SISOf nonlinear Kalman equalizer, 122
ADC. See Analog to digital conversion (ADC)
Additive colored noise case, 730
Additive Gaussian colored noise (AGCN), 732
Additive noise, 182
Additive white Gaussian noise (AWGN), 190–191, 414–415
Advanced polarimetric decomposition techniques, 1162
adaptive model-based decomposition, 1168
2-component decomposition, improved volume  
description, 1165
efficient eigenvector based decomposition, 1171
Yamaguchi 4-component decomposition, 1162
Airborne Early Warning (AEW) systems, 1246–1247
Algebraic Constant Modulus Algorithms (ACMA), 138–140
Algebraic graph theory, 85, 343–344, 400
Algorithms, for optimal resource allocation, 425
Along-track acceleration
SAR imaging, 940
Along-track interferometry (ATI), 943–948, 1044–1045
Along-track velocity
parameter estimation, 958–959
SAR imaging, 934–936
Alternating direction method of multipliers (ADMM), 354
Alternating projection timing estimator (APTE), 76–77
Ambiguity function (AF), 668, 675
Analog to digital conversion (ADC), 9
APC algorithm. See Autonomous power control (APC) algorithm
a-priori distribution, 12
Arbitrary networks, optimal topology and power  
allocation for, 388
Architectures, multitarget multisensor tracking, 783
AR models. See Autoregressive (AR) models
ASKF. See Augmented state Kalman filter (ASKF)
Attenuation, 846, 1294
Augmented state Kalman filter (ASKF), 786
Autonomous power control (APC) algorithm, 426
Autoregressive (AR) models, 98, 140–141, 564
AWGN channel. See Additive white Gaussian noise (AWGN)
B
Backscatter, 1294
Band occupancy prediction, 487
Band occupancy scheduling, 488
Barankin Bound (BB), 28–29
Basis expansion models (BEMs), 99, 126
Bayesian and Neyman-Pearson (NP) formulations, 380–381
Bayesian approach, 358–359, 761
BB. See Barankin Bound (BB)
Beaufort Wind Scale, 528
BEMs. See Basis expansion models (BEMs)
Benett Equality, 144
BER. See Bit-error-rate (BER)
BICM. See Bit-Interleaved Coded Modulation (BICM)
Bio-inspired approaches, 85
Bistatic ambiguity functions, 825
Bistatic challenges, 649
Bistatic ISAR, 1031
cross-range image formation, 1035
PSF of, 1033
range compression, 1034
signal modeling, 1032
Bistatic radar, 816
geometry, 816
radar equation, 817
Bistatic radar clutter, 821, 848
characterization of, 848
geometry, 822
Bistatic radar imaging, 1030
bistatic ISAR, 1031–1032
Index

1322
Index
Bit-error-rate (BER), 14–15, 192
Bit-Interleaved Coded Modulation (BICM), 121,  
192, 449–450
Blind channel estimation, 104
combined channel and symbol estimation, 104
methods of moments, 106
Blind signal separation, 5
Blind Source Separation (BSS)
additive noise, 182
for communication signals, 136
convolutive mixtures, 171, 173
generalities on, 135
instantaneous mixtures, 148
non-circular sources, case of, 182
non-stationarity, exploiting the, 182
organisation of paper, 138
signals, 141
simulation, 180
Block-adaptive channel estimation, 118
Border control problem via electronic fence, 1290
electronic fence, 1291–1292
multi-scale approach, 1290
Bragg scatterers, 522
Bragg scattering and long waves, 556
Broadband multipath interference, 734
Broadcast consensus based phase synchronization, 703
BSS. See Blind Source Separation (BSS)
C
Canonical scatterers, 1131–1132
Canonical scattering mechanisms, 1131
Carrier frequency offset (CFO), 25, 38, 57, 250, 252
Cartesian polarization basis, canonical scattering  
mechanisms, 1131
Cartography-enabled route optimization, 493
CAS. See Subband carrier allocation scheme (CAS)
Cauchy-Schwarz theorem, 733
CCRB derivations, 45
CE-BEM. See Complex exponential basis expansion  
model (CE-BEM)
Cellular networks, 487
Central fusion center (CFC), 767
Centralized data fusion process model, 1267
Centralized tracking, 784
Central limit theorem (CLT), 234, 518, 1137
CFC. See Central fusion center (CFC)
CFO. See Carrier frequency offset (CFO)
CG map construction, 482
Change detection based MTI approach, 888
change detection, 891
experimental results, 893
signal model, 890
Channel estimation
blind channel estimation, 104
MIMO channel estimation, 108
semi-blind approaches, 107
superimposed training-based approaches, 107
training-based channel estimation, 103
Channel gain cartography, 480
CG map construction, 482
coverage region estimation, 485
spatio-temporal channel correlation, 482
Channel gain map, 481
Channel impulse response (CIR), 53, 200–201
Channel matrix structure, 301
Channel models
MIMO channels, 102
time-invariant channels, 100
time-variant (doubly selective) channels, 96
Channel state information (CSI), 116, 278, 442
Chemical sensors networks, dynamic collaboration, 1275
Circular polarization, 1124
Circular polarization basis, canonical scattering  
mechanisms, 1131
Circular-polarization scattering matrix, 525–526
Clairvoyant SINR loss, 612
Classical dual-channel techniques, 943
along-track interferometry (ATI), 943–944
displaced phase center antenna (DPCA) technique, 948, 950
Clock characteristics, compariosn of, 82
Clock drift, 81–82
Clutter
discrete clutter, 617
distributed clutter, 615
Clutter diversity, 823
Clutter modeling, 505–506, 764
amplitude statistics, 517
clutter volume reflectivity, 517
discrete scatterers, 526
Doppler spectrum, 522
normalized clutter reflectivity, 515
polarization characteristics, 524
spatial correlation, 526
Clutter suppression, GMTI, 952
adaptive clutter suppression, 953
DPCA technique, 952
Clutter volume reflectivity, 517
Coarse synchronization methods, 58
Code-aided synchronization, 46
Code-division multiple-access (CDMA) receiver, 195–196
Coded–OFDM, 217–218
Coding gain, 221–222
Cognitive radio applications, 276
Cognitive radio networks (CRN), 454–456, 474

1323
Index
Cognitive radio sensing and cross-layer design, 489
cartography-enabled route optimization, 493
joint sensing and resource optimization, 490
real-time traffic, sequential sensing for, 492
throughput-aware sequential sensing, 490
Coherency and covariance matrices, 1139
Coherent ambiguity function, 675
Coherent and non stationary pixels (yellow class), 1211
Coherent and stationary pixels (white class), 1211
Coherent decomposition techniques, 1143
Coherent MIMO radar, 669
Coherent processing, 672–673
Coherent time-frequency characterization, 1187
SAR image spectral content, 1188–1190
time frequency decomposition, 1190–1191
Collaborative signal and information processing (CSIP), 1263
Column-wise diagonally dominant (CWDD), 301–302
Communication network, 1292
Communication networks, resource allocation, 409
Competitive sensor data fusion, 1261
Complementary sensor data fusion, 1261
Complex exponential basis expansion model (CE-BEM), 99
Complex scattering coefficients, 1129
Compound-Gaussian model, 505–506, 519
Compressed sensing approach, 476
Compressive sensing approach, 896
experimental results, 900–901
signal model, 897–898
Computational complexity theory, 424
Conditional-CCRB, 43
Conformal array, 650
Consensus algorithm, 343–344, 348
over realistic channels, 348
Consensus-type approaches, 85
Constant acceleration, 762
Constant velocity, 762
Control Time Protocol (CTP), 82
Conventional SAR processing, 952
Convolutive mixtures
case of sparse channels, 171
frequency-domain approaches, 176
global BSS approaches, 175
identifying the symbols, algebraic methods, 173
iterative BSS, general cyclo-stationary, 178
iterative BSS, stationary case, 176
MA/AR structures (stationary data), 174
subpace methods (cyclo-stationary data), 174
temporal approaches, 175
Cooperative sensor data fusion, 1261
Cooperative sensor network, optimal deployment and  
functioning, 1268
Cost function, 22, 27, 34
Covariance Intersection (CI) algorithm, 764
Coverage region estimation, 485
CP. See Cyclic prefix (CP)
CP-OFDM. See Cyclic-prefix OFDM (CP-OFDM)
CP philosophy, 211
Cramer-Rao bound (CRB), 10, 18, 42, 673–674
CRB. See Cramer-Rao bound (CRB)
CRN. See Cognitive radio networks (CRN)
Cross-covariance, of estimation errors, 761
Cross-layer design
cellular networks, 487
channel gain cartography, 480
CR sensing and cross-layer design, 489
MAC layer, 486
physical layer, 473
sparsity-aware power spectrum cartography, 475
wireless regional area networks (WRAN), 486
CSI. See Channel state information (CSI)
CSI information, 276
CSIP. See Collaborative signal and information processing
CTP. See Control Time Protocol (CTP)
CWDD. See Column-wise diagonally dominant (CWDD)
Cyclic prefix (CP), 50
Cyclic-prefix OFDM (CP-OFDM), 204
vector-matrix representation of, 209
Cyclo-correlation function, 143–144
Cyclostationarity detection, 473
Cyclostationarity tool, 37
D
DA approach. See Data-aided approach
2-D assignment, measurement-to-track association, 776
Data-aided (DA) approach, 17–18
Data collection programs, 654
knowledge-aided sensor signal processing and expert  
reasoning (KASSPER) data, 657
mountaintop database, 656
multichannel airborne radar measurements (MCARM), 654
naval research laboratory (NRL) database, 656
Data fusion, 510, 1245–1246, 1253
Data Information Knowledge and Wisdom  
(DIKW), 1256–1257
Data uploading, 333–336
Decentralized observations with centralized estimation, 367
Decentralized observations with decentralized estimation, 353
conditionally independent observations, 353
distributed Bayesian estimation under Gaussian noise and 
Laplacian prior, 358
distributed ML estimation under Gaussian noise, 357
distributed recursive least square estimation with sparsity 
constraint, 361
spatially correlated observations, 364

1324
Index
Decentralized sensor network, sensor coordination in, 1287–1288
Decentralized tracking, 785
Decision center
conditionally independent observations, 379
nodes send data to, 376
signal embedded in additive noise, 376
Decision-Directed (DD) mode, 24–25
Decision feedback equalization, 111
Decision feedback equalizer, 323
Degree of polarization (DoP), 1139
Degrees of Freedom (DoF), 415, 458, 1143
Degrees of freedom region, 415
Delay-Doppler spread function, 96
Deployment of simple and complex nodes, 1288
DERD. See Double bounce Eigenvalue Relative Difference
Deterministic maximum likelihood estimation, 105–106
Deterministic scatterers, 1227
DFT. See Discrete Fourier transform (DFT)
DFT-based implementation, OFDM, 198
Difference of convex (DC) problem, 395
Differential SAR Interferometry (DInSAR), 1061
Digital audio broadcasting (DAB), 199
Digital Terrain Elevation Data (DTED), 1300–1301
Dihedral scattering, 1144
Dihedral, scattering matrices, 1133
DIKW. See Data Information Knowledge and Wisdom
DInSAR. See Differential SAR Interferometry
Directly achievable rate regions, 417
Discrete cosine transform (DCT) matrix, 220–221
Discrete Fourier transform (DFT), 176, 187–188, 299, 1053
Discrete Karhunen-Loève (DKL), 255–257
Discrete prolate spheroidal BEM (DPS-BEM), 99–100
Discrete scatterers, 526
Displaced phase center antenna (DPCA) technique, 948, 950
Distributed Bayesian estimation under Gaussian noise and 
Laplacian prior, 358
Distributed coherency matrix, 1142
Distributed ML estimation under Gaussian noise, 357
Distributed projection algorithms, 381
Distributed resource allocation, interference channel, 445
Distributed scatterers, 1226–1227
Distributed tracking, 785
Dithered quantization, 349
Dolph-Chebyshev weighting function, 523–524
Dominant scatterer autofocus, ISAR, 1009
Doppler effects, 12, 99, 262–263
Doppler parameter estimation, 962
fractional Fourier transform (FrFT), 966
matched filter bank, 963
radon transform, 971
Doppler spectrum, 522, 534, 536
Double bounce Eigenvalue Relative Difference (DERD), 1183
Douglas Sea State, 528
DPS-BEM. See Discrete prolate spheroidal BEM (DPS-BEM)
4D SAR imaging, 1103
DSC. See Dynamic sensor collaboration
DTED. See Digital Terrain Elevation Data
Dual polarization SAR, 1138
Dynamic sensor collaboration (DSC), 1275
E
EDPCA. See Extended displaced phase center antenna technique
Efficient eigenvector based decomposition, 1171–1173
parametrization using number of degrees of 
freedom,1174–1175
target vector, circular basis, 1173
Eigenvector based decomposition technique, 1144
cloude dominant scattering mechanism decomposition, 
1144–1145
H/A/α decomposition, 1145
Eigenvector decomposition, 174–175, 1143
EKF. See Extended Kalman filter (EKF)
Ellipse amplitude, 1123
Ellipse aperture, 1123
Ellipse orientation, 1123
Ellipticity, 1123
Elliptic polarization, 1124
EM algorithm. See Expectation-Maximization (EM) algorithm
Energy detection, 473
Epidemics, estimation and forecasting, 1302
modeling, 1304
numerical results, 1307–1309
sequential Bayesian solution, 1305
Equal-gain combining (EGC), 230–231
Equalization
decision feedback equalization, 111
linear equalization, 108
maximum likelihood sequence detection, 113
turbo equalization, 114
Equation error, 106
ESPRIT algorithm. See Estimation of signal parameters via 
rotational invariance technique (ESPRIT) algorithm
Estimation of signal parameters via rotational invariance  
technique (ESPRIT) algorithm, 72–73
Euclidean Random Matrix (ERM), 403
Euler’s totient function, 221–222
Expectation-Maximization (EM) algorithm, 33
Extended displaced phase center antenna technique (EDPCA), 977
Extended Kalman filter (EKF), 767, 834
F
Far end crosstalk (FEXT), 298
FCs. See Fusion centers (FCs)

1325
Index
FECs. See Forward Error Correcting codes (FECs)
FEXT. See Far end crosstalk (FEXT)
Filter-bank multicarrier (FBMC), 277
FIM. See Fisher information matrix (FIM)
Fine synchronization methods, 65
Finite Set Statistics (FISST), 782
First-order statistics based methods, 63
First scheme, DA phase and CFO, 20
Fisher information matrix (FIM), 43–44, 673–674
for coherent MIMO radar joint estimation, 718
for localization with phase errors, 719
FISST. See Finite Set Statistics (FISST)
Fitting error, 106
Flat fading channel, synchronization in
code-aided synchronization, 46
CRB, 42
DA case, 18
DA phase and CFO estimation, 25
DA timing estimation, 21
NDA case, 31
NDA ML phase and CFO estimator, 33
NDA ML timing estimator, 32
sub-optimal estimators, 36
Flat plate, scattering matrices, 1131
FOliage PENetrating (FOPEN) radar, 1293
Forestry remote sensing, 1237–1239
Forward Error Correcting codes (FECs), 219
Fourier series expansion, 37
Fourier transform, 55–56, 144, 189
Fractional Fourier transform (FrFT), 966
Freeman-Durden decomposition, 1149–1150
Free-space propagation, 858
Frequency division multiplexing, 193
concept of, 194
Frequency-selective multipath channels, 200
Frequency spread signals, 714
FrFT. See Fractional Fourier transform
Fully polarimetric SAR, 1139
Fully polarimetric tomography
mono-dimensional estimators, 1231–1233
multi-dimensional estimators, 1233
numerical examples, 1233–1235
Fundamental information-theoretical issues, 341
Fusion centers (FCs), 785
nodes send local decisions to, 380
Fusion engines, 1297–1298
classification function, 1301
local tracking function, 1299
G
Game theoretical formulations, 447
Game theoretic approaches, 474
Gamma texture (GK), 520
Gaussian amplitude statistics, 526
Gaussian-GCRB, 43
Gaussian Markov Random Field (GMRF), 339
Gaussian noise, 13, 412–413
Gaussian process, 11, 234, 550–551
Gaussian statistics, 518–519
Gauss-Markov Random field (GMRF), 371–373
GCRB derivations, 45
GDFE. See Generalized decision feedback equalizer (GDFE)
GEMS. See Generic Error modeling System
General GMTI processing chain, 950
clutter suppression, 952
detection, 953
parameter estimation, 957
preprocessing, 951
signal extraction, 955
visualization, 962
Generalizations, BSS methods, 162
Generalized decision feedback equalizer (GDFE), 323
Generalized eigen-analysis, 609
Generalized sidelobe canceler, 606
Generic Error modeling System (GEMS), 1257
GEOINT. See Geospatial Intelligence
Geometric Programming (GP) technique, 432
Geospatial Intelligence (GEOINT), 1258–1259
Global BSS, stationary mixture, 158
first result, 159
generalization: notion of contrast function, 160
JADE, 161
GMRF. See Gaussian Markov Random Field (GMRF)
GP technique. See Geometric Programming (GP) technique
Graphical models and consensus algorithm, 343
Ground clutter
Doppler spectra for land clutter, 536
land clutter, 535
Ground moving target indication (GMTI), 508–509
Group and coefficient levels, sparsity, 477
Grouped linear precoding (GLP), 222
H
H/A/α decomposition
decomposition parameters, 1146–1149
mean scattering mechanism, 1145–1146
Han-Kobayashi region, 415
Heterogeneous clutter, 645
Heterogeneous multi-sensor network management, 1285
Hidden Markov Model (HMM), 104–105
High entropy multiple scattering, 1153
High entropy vegetation scattering, 1152
High resolution image formation, 1046

1326
Index
High resolution radar and radar imaging, 988
high cross-range resolution, 992
high range resolution, 990
resolution, 989
Homeland Protection (HP), 1249
HOMHT. See Hypothesis-oriented MHT (HOMHT)
Homogeneous sensor networks, 1259–1260
sensor configuration, 1260
Horizontal dipole, scattering matrices, 1132
HP. See Homeland Protection
HTP. See Hung Turner Projection (HTP)
Human Intelligence (HUMINT), 1258–1259
HUMINT. See Human Intelligence
Hung Turner Projection (HTP), 626
Huynen parameters, 1140–1141
Hybrid scatterers, 1227
Hypothesis-oriented MHT (HOMHT), 780
I
IBI. See Inter-block interference (IBI)
ICBF. See Iterative Coordinated BeamForming (ICBF)
ICI. See Inter-carrier interference (ICI)
IF. See Improvement factor (IF)
IHP. See Internal Hermitian Product
ILSP. See Iterative Least Square with Projection (ILSP)
Image autofocus, ISAR, 1007
dominant scatterer autofocus (DSA), 1009
IEBA, 1009
image contrast based autofocus (ICBA) algorithm, 1007
PGA, 1010–1011
Image contrast based autofocus (ICBA) algorithm, 1007
Image formation, ISAR, 998
radial motion compensation, 998
range-doppler image formation, 999
Imagery Intelligence (IMINT), 1258–1259
Image scaling, ISAR, 1015
Imaging space-time adaptive processing (ISTAP), 978
IMINT. See Imagery Intelligence
Impact assessment, 1254
Improvement factor (IF), 614, 870
Impulse response function (IRF), 1046–1047
Incoherent and non-stationary pixels (red class), 1211
Incoherent and stationarity pixels (green class), 1211
Incoherent decompositions, 1143
Information fusion, 1255–1256
Information sources, 1258
Information-theoretic results, 414
Instantaneous mixtures, 146–147
algebraic methods, 149
deflation step, 157
extensions, 158
global BSS, 158
improving the deflation, 157
indeterminacies, 149
iterative BSS, 151
practical aspects, 155
second-order based identification, 150
theoretical considerations, 152
Integrated sensor systems, 510
Integration time, 1049
Interacting multiple-model estimator, 770
Inter-block interference (IBI), 50, 202
Inter-carrier interference (ICI), 55–56, 197–198
Interference alignment, 458
Interference channel (IC), 6, 410
capacity results for, 414
distributed resource allocation in, 445, 449
optimal resource allocation in, 420
algorithms for, 425
comparisons of, 445
complexity of, 424
hybrid formulations, algorithms for, 441
lagrangian dual decomposition, 428
min-rate maximization, algorithms for, 426
problem formulations, 420
QoS constrained power minimization, 439
robust resource allocation, algorithms for, 442
weighted sum-utility maximization, 428
system model, 412
Interfering broadcast channel (IBC), 411–412
Interfering multiple access channel (IMAC), 411
Internal Hermitian Product (IHP), 1198–1199
polarimetric, 1200
single polarization, 1199–1200
Inter-Symbol Interference (ISI), 11
Inverse DFT (IDFT), 199
Inverse synthetic aperture radar (ISAR), 509
geometry, 995–997
high resolution radar and radar imaging, 988
historical overview, 987–988
image formation, 998
SAR to ISAR, 995
signal modeling, 996
IRF. See Impulse response function
ISAR. See Inverse synthetic aperture radar
ISAR image evaluation, 1001
image coordinates, 1001
image projection plane, 1002
image resolution, 1002
images, examples of, 1004–1007
point spread function, 1002
ISB algorithm. See Iterative spectrum balancing (ISB) 
algorithm
ISTAP. See Imaging space-time adaptive processing

1327
Index
Iterative BSS, general cyclo-stationary case
global BSS, 168
semi-analytical considerations, 169
Iterative Coordinated BeamForming (ICBF), 430
Iterative Least Square with Projection (ILSP), 138–140, 149
Iterative spectrum balancing (ISB) algorithm, 429
J
JADE algorithm. See Joint Approximate Diagonalization of 
Eigenmatrices (JADE) algorithm
Joint Approximate Diagonalization of Eigenmatrices (JADE) 
algorithm, 138–140
Joint Directors of Laboratories (JDL) fusion model,  
1253–1255, 1257–1258 
Joint domain space-time adaptive processing, 972
Joint location and velocity estimation, 670, 680
Joint probabilistic data association (JPDA), 778
Joint sensing and resource optimization, 490
Joint separating methods, 138–140
Jones vector, 1125
JPDA. See Joint probabilistic data association (JPDA)
K
Kalman detector, 109
Kalman filter, 109–110, 767
Karush-Kuhn-Tucker optimal solution, 495
KASSPER data. See Knowledge-aided sensor signal processing 
and expert reasoning (KASSPER) data
k-mean segmentation technique, 1155, 1158
Knowledge-aided (KA) methods, 753
Knowledge-aided sensor signal processing and expert  
reasoning (KASSPER) data, 657
Kriged Kalman filtering (KKF), 483
Kronecker delta function, 103
Kronecker index, 13–14
L
Lagrangian dual function, 429
Laplacian matrix, 344
Lasso algorithm, 394
Least-absolute shrinkage and selection operator (lasso)  
method, 359
Left helix, scattering matrices, 1133
LFC. See Local fusion center (LFC)
Lightweight Tree-based Synchronization (LTS), 82
Likelihood function, 102
Linear constraints, 747
pre-nulling on transmit, 748
Linear equalization, 108
Linearly precoded-OFDM (LP-OFDM), 219
Linear polarization, 1124
Linear precoding
partial ZF precoding, 312
reduced complexity ZF, 309
word length for ZF, 311
zero forcing precoder, 307
Linear precoding (LP) matrix, 219–220
Linear receiver, 322
Linear rotated basis, canonical scattering mechanisms, 1131
Linear time-varying (LTV)
channel equalization, 253
channel estimation, 255
Line-of-sight (LOS), 1046–1047
Local fusion center (LFC), 767, 785, 1247–1248
Lorentzian function, 522
Low-cost scientific measurements, 836
bistatic adjunct to weather radar, 837
Manastash Ridge Radar (MRR), 836
ocean remote sensing using gps signals, 838
Low entropy dipole scattering, 1152
Low entropy multiple scattering events, 1152
Low entropy surface scatter, 1152
LP-OFDM. See Linearly precoded-OFDM (LP-OFDM)
LTI channels for OFDM, 243
LTS. See Lightweight Tree-based Synchronization (LTS)
LTV. See Linear time-varying (LTV)
Lyapunov theorem, 429
M
MAI. See Multiple-access interference (MAI)
Manastash Ridge Radar (MRR), 836
MANET. See Mobile ad-hoc networks (MANET)
Markov observations, 337–338
MASINT. See Measurement and Signature Intelligence
Master-slave closed-loop phase synchronization, 700
Matching communication network topology, 393
numerical results, 396
precision matrix, 396
preserving total transmit power, encouraging sparsity by, 394
Maximum likelihood sequence detection (MLSD), 113
Maximum ratio combining (MRC), 230–231
Maximum SINR filter, 603
MCARM. See Multichannel airborne radar measurements 
(MCARM)
Measurement and Signature Intelligence (MASINT), 
1258–1259
Medium access control (MAC) protocol, 332
Medium entropy multiple scattering, 1152
Medium entropy surface scatter, 1152

1328
Index
Medium entropy vegetation scattering, 1152
MHT. See Multiple hypothesis tracker (MHT)
Microwave high resolution imaging, 1043
MIMO. See Multiple-input multiple-output (MIMO)
Minimum energy consensus, 385
analytic approach, 391
arbitrary networks, optimal topology and power  
allocation for, 388
numerical examples, 389
optimization criterion, 387
random geometric graphs, 391
Minimum variance beamformer, 605
MLSD. See Maximum likelihood sequence detection (MLSD)
Mobile ad-hoc networks (MANET), 10
Mode-conditioned filtering, 772
Mode jump process, 771
Modified-MCRB, 43–44
Monochromatic plane wave, polarization of, 1121
Motion adapted SAR processing, 952
Mountaintop database, 656
Moving point target signal model, 925–926
multi-channel signal model, 929
single-channel signal model, 926
Moving target indication (MTI), 914–915, 925
Moving target indication (MTI) radar, 611–612
adaptive SINR loss, 613
Clairvoyant SINR loss, 612
improvement factor (IF), 614
optimal and adaptive filter patterns, 614
MTI radar. See Moving target indication (MTI) radar
Multi-band testing, 473
Multibaseline SAR interferometry, 1071
Multicarrier CDMA (MC-CDMA), 225
Multicarrier communications in nonlinear systems, 233
Multicarrier (MC) communication system, 193
Multichannel airborne radar measurements (MCARM), 654
Multichannel SAR, 508
Multi-channel signal model, 929
Multidimensional polarimetric SAR signal processing, 1187
Multipass interferometry, 1080
multipass phase unwrapping, 1088
Multipath exploitation, 874
experimental results, 886
image formation algorithm, 876
multipath exploitation algorithm, 885
multipath model, 877
Multipath exploitation principle, 884
Multipath model, 877
multipath focusing analysis, 882–884
multipath locations, 880
Multiple-access interference (MAI), 49, 230–231
Multiple hypothesis tracker (MHT), 779
hypothesis-oriented MHT (HOMHT), 780
track oriented MHT (TOMHT), 781
Multiple-input multiple-output (MIMO)
channel estimation, 108
channels, 102
coherent MIMO radar, 669
coherent ambiguity function, 675
joint location and velocity estimation, 670
phase errors, localization with, 676
distinguishing coherent and noncoherent processing, 716
equalization for, 276
FIM, for coherent MIMO radar joint estimation, 718
FIM, for localization with phase errors, 719
frequency spread signals, 714
IC model, 413, 423–424
Neyman-Pearson signal detection, 692
signal model, 692
signal space dimension, 693
noncoherent MIMO radar, 679
joint location and velocity estimation, 680
noncoherent ambiguity function, 685
performance and complexity analysis for, 688
normalized mean square error difference, 688
numerical examples, 690
phase synchronization for, 699
broadcast consensus based phase synchronization, 703
master-slave closed-loop phase synchronization, 700
round-trip phase synchronization, 701
radars, 506–507
technologies, 5
waveform design for, 705
optimal waveform design for, 709
signal model and design criteria, 706
Multiple input single output (MISO), 414
Multiple Mode (MM) approach, 770–771
Multi-sensor data fusion, 1253
Multisensor integration, 1253
Multi-sensor networks, mathematical issue for, 1288
Multisensor tracking, 507
Multi-StageWiener Filter (MWF), 629
Multistatic radar, 506–507
Multitarget multisensor tracking
architectures of, 783
centralized tracking, 786
parallel updating, 787
sequential updating, 786
data association
measurement-to-measurement association, 778
measurement-to-track association, 774
distributed tracking
covariance intersection, 764
cross-covariance of the estimation errors, 761
with dependent errors, 762
tracklet fusion, 763

1329
Index
filter initialization, 773
issues related to track initialization, 773
single-point track initialization, 773
two-point difference track initialization, 773
filters, 766
extended Kalman filter (EKF), 767
interacting multiple-model estimator, 770
Kalman filter, 767
particle filter, 769
unscented Kalman filter (UKF), 768
formulation of, 761
clutter model, 764
sensor models, 763
spatial clutter intensity estimation, 765
target dynamic models, 762
multitarget tracking algorithms, 778
joint probabilistic data association (JPDA), 778
multiple hypothesis tracker (MHT), 779
probabilistic data association (PDA), 778
probability hypothesis density (PHD) method, 782
performance evaluation, 794
Posterior Cramér-Rao Lower Bound (PCRLB) of tracking, 794
simulations, 799
tracker-related measures, 798
Multi-terminal source/channel coding problem, 399
Multiuser multicarrier systems
versus CDMA, 232
equalization and data recovery for, 228
Multiuser synchronization
with generalized CAS, 74
with interleaved CAS, 71
subband CAS, 70
uplink OFDMA systems, 77
uplink signal model and synchronization policy, 68
MWF. See Multi-StageWiener Filter (MWF)
N
Naval research laboratory (NRL) database, 656
NDA approach. See Non-data-aided (NDA) approach
Near end crosstalk (NEXT), 298
Network architecture scheme, 1288
Network centric data fusion process model, 1267
Network Centric Operation (NCO), 1248
Network synchronization
clock models, 81
distributed clock sync, 85
pairwise synchronization, 83
protocols, 82
unilateral synchronization, 83
Network Time Protocol (NTP), 83
NEXT. See Near end crosstalk (NEXT)
Neyman-Pearson (NP) hypothesis testing, 473
Neyman-Pearson (NP) signal detection, 692
Node positions, 348
Noise, achievable rate regions, 416
Non-Circularity tool, 37
Non-circular sources, case of, 182
Noncoherent ambiguity function, 685
Noncoherent MIMO radar, 679
Non-data-aided (NDA) approach, 18
Non-flat fading channels, synchronization for
carrier frequency offsets, 57
coarse synchronization methods, 58
downlink OFDMA, 57
fine synchronization methods, 65
OFDM transmission, 52
signal model and preliminaries, 50
simulation results for downlink OFDMA systems, 66
SIR versus fractional carrier frequency offset, 58
subcarrier allocation strategies, 51
timing errors, 55
Nonlinear constraints
constant modulus and the method of stationary phase, 752
NLFM to achieve constant modulus, 753
relaxed projection approach, 750
relaxed projection example, 751
Nonlinear frequencymodulated (NLFM) pulse, 752
to achieve constant modulus, 753
Nonlinear precoding, 304
Nonparametric basis pursuit method, 478
Non-stationarity, exploiting the, 182
Nonstationary clutter, 647
Non-stationary polarimetric SAR responses, 1192
Bragg resonant scattering, 1196–1198
discrete time-frequency decomposition, range and azimuth, 
1192–1194
TF behaviors detection, 1194–1196
NRL database. See Naval research laboratory (NRL) database
NTP. See Network Time Protocol (NTP)
Nyquist filter, 13–14
Nyquist raised-cosine filter, 136
Nyquist rate, 100–101
Nyquist-Shannon sampling theorem, 196, 198–199
O
Observation model, impact of, 336
Observe-Orient-Decide-Act (OODA) loop, 1257
Ocean remote sensing, GPS signals, 838
OFDM. See Orthogonal frequency-division  
multiplexing (OFDM)
OFDMA. See Orthogonal frequency-division multiple access 
(OFDMA)

1330
Index
OHGR. See Osborne Head Gunnery Range (OHGR)
Open-Source Intelligence (OSINT), 1258–1259
Operational modes, SAR system, 1050
scanSAR mode, 1051–1052
spotlight mode, 1051
staring spotlight mode, 1051
stripmap mode, 1050
Optical Network Unit (ONU), 297–298
Optimal and adaptive filter patterns, 614
Optimal radar waveform design
additive colored noise case, 730
broadband multipath interference, 734
clutter case, 737
optimum pulse shaping for maximizing SCR, 740
sidelobe clutter discrete suppression, 739
constrained optimum transmit-receiver radar, 747
linear constraints, 747
nonlinear constraints, 750
open issues and problems, 753
transmit-receive functions, for target identification, 742
multitarget ID, 746
multi-target identification case, 745
two-target identification example, 744
Optimal receiver structure, 14
Optimal resource allocation problems, 424
Optimal Voronoi partition, 1272
Optimal waveform design, 709
ORC. See Orthogonal restoring combining (ORC)
Oriented dipole, scattering matrices, 1132
Orthogonal frequency-division multiple access (OFDMA), 49, 410
downlink OFDMA representation, 59
downlink OFDMA transmission, 53, 57
simulation results for, 66, 77
uplink representation, 69
Orthogonal frequency-division multiplexing (OFDM), 5, 49
bit and power-loading, 269
coded, 218
cognitive radio applications, 276
CSI information, 276
filter-bank multicarrier (FBMC), 277
in frequency-selective multipath channels, 200
linearly precoded-OFDM, 219
LTI channels for, 243
mathematical background, 189
MIMO, 276
and multicarrier communications in nonlinear systems, 233
multiuser multicarrier systems, 224
operational principle, 51
path to, 193
practical guidelines and commercial standards, 260
principle, 196
rapidly time-varying channels, 248
relay communications, 277
single carrier background, 189
symbol error rate (SER) performance analysis, 214
time and frequency synchronization, 263
time-varying channel estimation, 276
transmission, 52
underwater communications, 276
vector-matrix representation for, 207
Orthogonal multiplexing principle, 194
Orthogonal restoring combining (ORC), 230–231
Osborne Head Gunnery Range (OHGR), 559
OSINT. See Open-Source Intelligence
Outlook, 6
Overlap-and-add (OLA) approach, 217–218
P
Pairwise-error probability (PEP), 215
PAMF. See Parametric adaptive matched filtering (PAMF)
PAPRs. See Peak-to-average power ratios (PAPRs)
Parallel IC model, 413, 424
Parameter estimation, 957
accelerations, 959–960
across-track velocity, 957–958
along-track velocity, 958–959
true target position, 960–961
Parametric adaptive matched filtering (PAMF), 635
Parseval’s identity, 22–23
Partial transmit sequences (PTS), 242
Particle filter, 769
Particle orientation, 1167
Passive bistatic radar (PBR)
airborne PBR, 839–840
applications, 836
border/perimeter surveillance, 838
HF skywave signals, 846
imaging, 839
issues and problems, 847
countermeasures and detection of, 847
identifying applications, 847
Low-cost scientific measurements, 836
short-range surveillance, WiFi and WiMAX, 840
waveforms, 823
See also Bistatic radar
Passive radar, 506–507
Pauli target vector, 1130
PBR. See Passive bistatic radar
PCI. See Principle components inverse (PCI)
PCRLB. See Posterior Cramér-Rao Lower Bound (PCRLB)
PDA. See Probabilistic data association (PDA)
Peak-to-average power ratio (PAPR)
reduction methods, 241
Peak-to-average power ratios (PAPRs), 50, 241

1331
Index
Perron-Frobenius theorem, 346
Perron matrices, 346
Phase synchronization for MIMO, 699
Phase unwrapping, 1066
Bayesian statistical solution to, 1076
graph cuts solution to, 1078
minimum cost flow solution, 1070
residue cut algorithms for, 1067
PHD. See Probability hypothesis density (PHD)
PLL scheme, 31
Point Spread Function (PRF), 865–866, 1002, 1046–1047
Poisson point processes, 765–766
Polarimetric anisotropy, 1149
Polarimetric decomposition techniques, 1142
eigenvector based decomposition technique, 1144
necessity of polarimetric decompositions, 1142
types of, 1143
Polarimetric decomposition techniques, soil  
characterization, 1181
H, A, and α  and the Small Perturbation surface scattering 
Model (SPM) model, 1183
reflection symmetry and Integral Equation Model (IEM) 
model, 1183
Polarimetric diversity, 1127–1128
Polarimetric ISAR (Pol-ISAR), 1021, 1023
image formation, 1025
initialisation, 1027
most focussed ISAR image, 1028
optimization, 1028
polarimetric autofocus, 1026
polarimetric ISAR imaging, 1023–1024
polarimetric SAR imaging, 1022
signal model, 1024
Polarimetric SAR imaging, 1022
Polarimetric SAR interferometry, 1045
Polarimetric SAR interferometry (PolinSAR), 1120
Polarimetric SAR tomography, 1046, 1222
basics of, 1222
tomographic focusing techniques, 1228
tomographic signal models, 1225
Polarimetric scattering, 1121
Polarimetric scattering descriptors, 1127
Polarimetric time-frequency characterization, 1204
Polarimetry, 1119
Polarization (SAR), 1119
Polarization basis change, 1126, 1130
Polarization characteristics, 524
Polarization ellipse, 1121, 1123
Polarizations, types of, 1124
PolSAR TF analysis, 1210
classification, 1210–1211
TF cleaning of PolSAR data, 1211
PolSAR TF signal modeling, 1204, 1207
coherent pixel discrimination, 1209–1210
non-stationary pixel discrimination, 1208–1209
second order statistics, 1207–1208
Possible architectures, 342
Post-doppler STAP, 974
Posterior Cramér-Rao Lower Bound (PCRLB), 760–761, 1264
tracking of, 794
Practical vegetation height estimation, 1220
Precision matrix, 396
Precoding
CSI at transmitter, 117
for MIMO channels, 117
for SISO channels, 116
Preprocessing, GMTI Kernel
conventional SAR processing, 952
motion adapted SAR processing, 952
range compression with RCMC, 952
Preserving total transmit power, encouraging sparsity by, 394
PRF. See Point Spread Function
Principle components inverse (PCI), 624
Probabilistic data association (PDA), 778
Probability density function (pdf), 1137
Probability evaluation, 772
Probability hypothesis density (PHD)
filter, 766
method, 782
Probability hypothesis density (PHD) filtering and  
tracking, 835
Process refinement, 1254
Progressive correction algorithm, 1283
Propagation model, 477
Pure coherency matrix, 1143
Q
QoS. See Quality of service (QoS)
Quality of service (QoS), 49, 409, 439
R
Radar, 507–508
Radar clutter, 505–506
Radar clutter analysis
land clutter analysis, farmland area, 567
sea clutter, 540
Radar clutter modeling and analysis
clutter modeling, 515
radar clutter analysis, 539
radar design and analysis, 585
simulation methods, 581
Radar design and analysis, 585
performance acceptance and trials analysis, 587

1332
Index
Radar design and analysis (Continued)
performance prediction, 585
radar performance, specification and measurement of, 587
signal processing and design of detectors, 586
Radar polarimetry, 510
organization of work, 1120
overview of, 1119
polarimetric SAR interferometry (PolinSAR), 1120
Radar signal processing, 505
Radioactive point sources, 1279
Radio frequency interference, 619
Rain clutter
atmospheric attenuation, 537
rain attenuation, 537
rain Doppler spectrum, 538
theoretical and empirical model for, 537
Random Geometric Graphs (RGG)
adjacency matrix, 403
spectrum of, 403
Random link failuresmodel, 349
Range compression with RCMC, 952
Rapidly time-varying channels, 248
carrier frequency offset (CFO), 252
LTV channel equalization, 253
LTV channel estimation, 255
Rate region, definition of, 416
Rayleigh flat-fading channel, 218
Rayleigh quotient, 608
RBS. See Reference Broadcast Systems (RBS)
RD-STAP. See Reduced-dimension STAP (RD-STAP)
Received signals
assumptions on channels, 148
models of sampled data, 146
Receiver noise, 620
Receiver structure, 121–122
Reduced-dimension STAP (RD-STAP), 630
Reduced-rank STAP, 622
Reference Broadcast Systems (RBS), 82
Reflection symmetry and Integral Equation Model (IEM) model
roughness and moisture retrieval, 1185–1186
SERD and the DERD parameters, 1183–1185
Relaxed projection approach, 750
Reliable coherent digital communication systems, 9–10
Residual range cell migration
SAR imaging, 931
Resource allocation
in communication networks, 409
directly achievable rate regions, 417
information-theoretic results, 414
interference channel (IC), 410, 420, 445
MIMO IC model, 413
multiple input multiple output (MIMO), 411
notation, 410
parallel IC model, 413
rate region, definition of, 416
scalar IC model, 412
via interference alignment, 458
Rethinking mathematical algorithms, net-centric  
approaches, 1266
RF cartography, 472, 490
Right helix, scattering matrices, 1133
Roll-off factor, 143
Round-trip phase synchronization, 701
Round trip time (RTT), 82–83
Row-wise diagonally dominant (RWDD), 304
RTT. See Round trip time (RTT)
RWDD. See Row-wise diagonally dominant (RWDD)
S
Sample matrix inversion, 609, 974
SAR imaging
across-track velocity, 936
along-track acceleration, 940
along-track velocity, 934
basics concepts, 1046
effects on, 931
effects, summary of, 941
residual range cell migration, 931
SAR interferometry, 1054, 1212
basics concepts, 1046
interferometric coherence, 1214
interferometric phase and height of scatterer, 1212
polarimetric RVOG model, 1218–1219
Pol-inSAR representations, 1218
single polarization channel, random volume over ground 
model, 1214
SAR interferometry (InSAR), 509–510
SAR response, 1135–1136
SAR tomography, 1093
compressive sensing inversion for, 1098
linear adaptive inversion for, 1096
linear non-adaptive inversion for, 1095
methods, performance comparison of, 1101
SAR tomography (Tomo-SAR), 509–510
SCA. See Successive convex approximation (SCA)
Scalar IC model, 412, 423–424
SCALE. See Successive Convex Approximation for Low  
complexity (SCALE)
S&C and S&S estimators, 62–63
Scattering matrix, 1129
Scattering mechanisms characterization, 1175
azimuthal orientation, 1175–1178
statistical Wishart segmentation, 1178–1179
Schmidl and Cox (S&C) algorithm, 59–61

1333
Index
SCNR. See Signal-to-clutter-plus-noise ratio
Sea clutter, 527
amplitude statistics, 532
AR model, 564
Bragg scattering and long waves, 556
clutter amplitude, statistical models of, 541
correlation analysis and power spectrum estimation, 552
cumulant domain analysis, 550
Doppler spectrum, 534
mean range texture autocovariance sequence, 556
speckle autocorrelation and cross-correlation sequences, 552
texture autocorrelation sequence, 553
theoretical and empirical models for, 529
Second-Order Blind Identification (SOBI) algorithm, 138–140
Second order cone programs (SOCP), 426
Second order incoherent representations, 1133
Second-order statistics based methods, 59
Second scheme, DA phase and CFO, 20
Self-organizing sensor networks, 1264
Self-synchronization mechanism, 1265
Semi-blind approaches, 107
Sensor behavior assignment, 1286–1287
Sensor deployment, 1285–1286
Sensor models, 763
Sensor network, 1296–1297
Sensor networks, study cases of, 1268
Sensor registration, 786, 1265–1266
Sensors, 1292–1293
airborne sensors, 1293
electro-optic (EO), 1296
FOliage PENetrating (FOPEN) radar, 1293
ground-based sensors, 1293
and scenario parameters, 800
unattended ground passive sensors (UGPS), 1296
Sequential alternatives, 473
SERD. See Single bounce Eigenvalue Relative Difference
SER performance analysis. See Symbol error rate  
performance analysis
Shi and Serpedin (S&S) timing estimator, 61–62
SIGINT. See Signals Intelligence
Signal and interference environment, 827, 829
multilateration and tracking, 834
performance prediction, 831
suppression techniques, 830
Signal extraction
azimuth lines, extraction of, 956
range history tracking, 955
Signal models
and design criteria, 706
receiver noise, 620
Signal processing and communications
blind signal separation, 5
channel estimation, equalization, precoding, and tracking, 4
contents and contributors, 4
history, 3
OFDM and multicarrier signal processing, 5
and optimal resource allocation, 6
outlook, 6
spectrum sensing and cross-layer design for cognitive radio 
networks, 6
synchronization, 4
vectored multichannel VDSL, 5
wireless sensor networks, 5
Signals
cyclo-stationarity of source, 143
received signals, 145
source signals, 142
Signals Intelligence (SIGINT), 1258–1259
Signal-to-clutter-plus-noise ratio (SCNR), 975–976
Signal-to-clutter ratio (SCR), 737–738
Signal-to-noise ratio (SNR), 13, 414–415, 595, 889–890
SIMO Channel Estimation, 107
Simple polarimetric classification scheme, 1150
H/α classification, 1150–1152
polarimetric anisotropy, 1153
Simulation methods, 180
correlated non-Gaussian random numbers, 582
generating correlated Gaussian random numbers, 582
generating uncorrelated random numbers, 581
Single bounce Eigenvalue Relative Difference (SERD), 1183
Single carrier background, 189
Single-channel signal model, 926
Single-input multi-output (SIMO) systems, 109
Single-input single-output (SISO) systems, 100–101, 109
Single polarization SAR, 1133
Single polarization tomography, 1228
mono-dimensional estimators, 1229
multi-dimensional estimators, 1229–1230
numerical examples, 1230–1231
SISO channel estimation, 106
Situation assessment, 1254
SNR. See Signal-to-noise ratio (SNR)
SOBI algorithm. See Second-Order Blind Identification (SOBI) 
algorithm
SOCP. See Second order cone programs (SOCP)
Space-time adaptive processing (STAP), 971
adaptive filter implementations, 622
application, 639
algorithm performance, 642
interference characteristics, 639
with nonadaptive solution, 644
summary, 644
basic concepts, 602
challenges
bistatic, 649
conformal array, 650

1334
Index
Space-time adaptive processing (Continued)
heterogeneous clutter, 645
nonstationary clutter, 647
data collection programs, 654
detection, 602
extended displaced phase center antenna technique 
(EDPCA), 977
imaging space-time adaptive processing (ISTAP), 978
implementation, 651
joint domain, 972
metrics, 611
post-doppler, 974
sample matrix inversion, 609
signal models, 615
clutter, 615
radio frequency interference, 619
receiver noise, 620
space-time snapshot, 621
target, 620
space-time filter formulations, 603
Space-time filter formulations, 603
generalized eigen-analysis, 609
generalized sidelobe canceler, 606
maximum SINR filter, 603
minimum variance beamformer, 605
Rayleigh quotient, 608
Space-time snapshot, 621
Sparsity-aware power spectrum cartography, 475
compressed sensing approach, 476
group and coefficient levels, sparsity, 477
nonparametric basis pursuit, 478
propagation model, 477
splines, group-lasso on, 479
Spatial clutter intensity estimation, 765
Spatial filtering, 862
imaging results, 869–870
moving average wall removal, 865
notch filtering, 868
target spatial signature, 864
wall reflection, characteristic of, 862
Spatio-temporal channel correlation, 482
Speckle effect, 1120–1121, 1133–1134
Speckle filtering, 1137
Spectrum sensing, 486
Sphere, scattering matrices, 1131
Splines, group-lasso on, 479
STAP. See Space-time adaptive processing; Space-time  
adaptive processing (STAP)
Stationary and mutually independent, 151
Stationary point target signal model, 921
Statistically independent observations, 336
Stochastic maximum likelihood estimation, 104–105
Stochastic-SCRB, 42–43
Straight-iso-range approximation, 998
Strongly connected component (SCC), 401
Structure of adaptive soft-input soft-output equalizer, 123–124
Subband carrier allocation scheme (CAS), 51–52
generalized CAS, 74
interleaved CAS, 71
synchronization with, 70
Subcarrier allocation strategies, 51–52
Sub-object assessment, 1253
Sub-optimal estimators, 36
Suboptimal linear equalization, 218
Successive convex approximation (SCA), 431–432
Successive Convex Approximation for Low complexity 
(SCALE), 431–432
Superimposed training-based approaches, 107
Surface scattering, 1144
Surveillance architecture, 1291
Surveillance, classical approach to, 1261
Symbol error rate (SER) performance analysis, 214
Synchronization, 4
flat fading channel, 11
multiuser synchronization, 68
network synchronization, 79
non-flat fading channels, 49
Synthetic aperture radar (SAR) imaging, 1133–1134
Synthetic aperture radar (SAR) polarimetry, 1119–1120
basics, 1121
organization of work, 1120
polarimetric decomposition techniques, 1142
polarimetric scattering, 1121
Synthetic aperture radar principle, 918
acquisition geometry and operation, 918
pulse compression and image formation, 923
stationary point target signal model, 921
T
Tapped delay line model, 96
Target dynamic models, 762
Target parameters, 801
Target signatures, 818
forward scatter, 818
Target vector, 1129
TCRB derivations, 44
Telecommunication signals. See Signals
TF polarimetric characterization, 1198
CS detection based on multiple criteria, 1203
CS detection based on TF entropy, 1200
point-like scatterers, Internal Hermitian Product (IHP), 1198
Theory to real application problems, 1265
Threat refinement, 1254
Through-the-wall radar imaging

1335
Index
change detection based MTI approach, 888
compressive sensing approach, 896
data sets, 903
issues and problems, 902–903
multipath exploitation, 874
wall clutter mitigation, 861
wall parameter estimation/modeling, and subtraction, 871
Through-the-wall radar imaging (TWRI), 508, 889–890
Through-the-wall sensing, 857–858
Through-the-wall synthetic aperture radar model, 876
Time and frequency synchronization, OFDM, 263
Time-division multiple-access (TDMA)-fashion, 409, 482
Time-frequency image formation, 1019
Time-variant (doubly selective) channels
autoregressive (AR) models, 98
basis expansion models (BEMs), 99
tapped delay line model, 96
Time-varying channel estimation, 276
Time-windowing, 1013
Timing estimation, 37
Timing-sync Protocol for Sensor Networks (TPSN), 82
Tiny/Mini-Sync (TMS) protocol, 82
TMS protocol. See Tiny/Mini-Sync (TMS) protocol
Toeplitz convolution matrix, 207–208
TOMHT. See Track oriented MHT (TOMHT)
Tomographic focusing techniques, 1228
fully polarimetric tomography, 1231
single polarization tomography, 1228
Tomographic signal models
PolTomSAR signal model, 1227
TomSAR signal models, 1253–1255
Tone injection (TI), 242–243
Tone reservation (TR), 242
TPSN. See Timing-sync Protocol for Sensor Networks (TPSN)
Trackers, 801
Tracking
adaptive channel estimation
for slowly varying channels, 118
via subblock tracking, 119
block-adaptive channel estimation using CE-BEM, 118
symbol-adaptive joint channel estimation and  
data detection, 120
Tracklet fusion, 763
Track oriented MHT (TOMHT), 781
Training-based channel estimation, 103
Trihedral, scattering matrices, 1131
True target position, 960
True-TCRB, 42–43
Turbo equalization, 125–128
for doubly-selective channels, 115
principle of, 114
using EKF and CE-BEM, 121
Turbo-synchronization, 47
TWRI. See Through-the-wall radar imaging (TWRI)
Typical telecommunication (TLC) network, 332
U
UGPS. See Unattended ground passive sensors
UKF. See Unscented Kalman filter (UKF)
Unattended ground passive sensors (UGPS), 1296
Unconditional-UCRB, 42–43
Underfoliage imaging, 1239
Underwater communications, 276
Uniform linear array (ULA), 622, 739
Unilateral synchronization, 83
Unscented Kalman filter (UKF), 768
recursion, 768
sigma point generation, 768
Unsupervised H/A/α segmentation, 1159–1163
Urban remote sensing, 1235
V
Vectored multichannel VDSL
channel matrix structure, 301
downstream transmission, 304
linear precoding, 307
nonlinear precoding, 304
system model, 297
upstream transmission, 322
decision feedback equalizer, 323
linear receiver, 322
Vector-matrix representation, OFDM
of CP-OFDM, 209
CP philosophy, 211
of ZP-OFDM, 212
Vegetation bias removal, 1219
Volume scattering, 1144
W
Wall clutter mitigation, 861
spatial filtering, 862
wall parameter estimation/modeling, and  
subtraction, 871
Wall parameter estimation/modeling, and subtraction, 871
approach, 871
imaging results, 873
Water-filling (WF) principle, 270–271
Wave covariance matrix, 1138–1139
Waveform design, 506–507, 705
Waveforms, passive bistatic radar (PBR), 823
Wave polarization, 1125
Wave temporal trajectory, 1122

1336
Index
Werner channel model, 312
Wide-sense stationary uncorrelated scattering (WSSUS)  
channel, 96, 98
Wireless local area networks (WLANs), 102
Wireless personal area networks (WPANs), 102
Wireless regional area networks (WRAN), 486
Wireless sensor networks (WSN), 5, 10, 1275
computing while communicating, 332
distributed detection, 371
distributed estimation, 351
distributed projection algorithms, 381
fundamental information-theoretical issues, 341
general framework, 332
graphical models and consensus algorithm, 343
Markov observations, 337
matching communication network topology, 393
minimum energy consensus, 385
observation model, impact of, 336
possible architectures, 342
statistically independent observations, 336
Wishart statistics, unsupervised statistical segmentation, 1155
WLANs. See Wireless local area networks (WLANs)
WPANs. See Wireless personal area networks (WPANs)
WRAN. See Wireless regional area networks (WRAN)
WSN. See Wireless sensor networks (WSN)
WSSUS channel. See Wide-sense stationary uncorrelated  
scattering (WSSUS) channel
Y
Yule-Walker equation, 98
Z
Zero forcing precoder, 307
Zero-mean Gaussian vector, 207
Zero-padded OFDM (ZP-OFDM), 202
detection for, 218
vector-matrix representation of, 212
Ziv-Zakaï Bound (ZZB), 28–29
ZP-OFDM. See Zero-padded OFDM (ZP-OFDM)
ZZB. See Ziv-Zakaï Bound (ZZB)

