
Computational Mathematics
This textbook is a comprehensive introduction to computational mathematics and scientific 
computing suitable for undergraduate and postgraduate courses. It presents both practical and 
theoretical aspects of the subject, as well as advantages and pitfalls of classical numerical meth-
ods alongside with computer code and experiments in Python. Each chapter closes with modern 
applications in physics, engineering, and computer science. 
Features:
• 
No previous experience in Python is required. 
• 
Includes simplified computer code for fast-paced learning and transferable skills de-
velopment. 
• 
Includes practical problems ideal for project assignments and distance learning. 
• 
Presents both intuitive and rigorous faces of modern scientific computing. 
• 
Provides an introduction to neural networks and machine learning.
Dimitrios Mitsotakis received a PhD in Mathematics in 2007 from the University of Ath-
ens. His experience with high-performance computing started while at the Edinburgh Parallel 
Computing Center at the University of Edinburgh. Dimitrios worked at the University Paris-
Sud as a Marie Curie fellow, at the University of Minnesota as an associate postdoc and at the 
University of California, Merced as a Visiting Assistant Professor. Dimitrios is currently an 
associate professor/reader at the School of Mathematics and Statistics of Victoria University 
of Wellington. He has published his work in journals of numerical analysis and in more general 
audience journals in physics, coastal engineering, waves sciences, and in scientific computing. 
He develops numerical methods for the solution of equations for water waves, and he studies 
real-world applications such as the generation of tsunamis. Some of his main contributions are 
in the theory and numerical analysis of Boussinesq systems for nonlinear and dispersive water 
waves.

Advances in Applied Mathematics 
Series Editors:  
Daniel Zwillinger 
Quadratic Programming with Computer Programs 
Michael J. Best
Introduction to Radar Analysis 
Bassem R. Mahafza
CRC Standard Mathematical Tables and Formulas, 33rd Edition 
Edited by Daniel Zwillinger
The Second-Order Adjoint Sensitivity Analysis Methodology 
Dan Gabriel Cacuci
Operations Research 
A Practical Introduction, Second Edition 
Michael Carter, Camille C. Price, Ghaith Rabadi
Handbook of Mellin Transforms 
Yu. A. Brychkov, O. I. Marichev, N. V. Savischenko
Advanced Mathematical Modeling with Technology 
William P. Fox, Robert E. Burks
Introduction to Quantum Control and Dynamics 
Domenico D’Alessandro
Handbook of Radar Signal Analysis 
Bassem R. Mahafza, Scott C. Winton, Atef Z. Elsherbeni
Separation of Variables and Exact Solutions to Nonlinear PDEs 
Andrei D. Polyanin, Alexei I. Zhurov
Boundary Value Problems on Time Scales, Volume I 
Svetlin Georgiev, Khaled Zennir
Boundary Value Problems on Time Scales, Volume II 
Svetlin Georgiev, Khaled Zennir
Observability and Mathematics
Fluid Mechanics, Solutions of Navier-Stokes Equations, and Modeling 
Boris Khots
Handbook of Differential Equations, Fourth Edition 
Daniel Zwillinger, Vladimir Dobrushkin
Experimental Statistics and Data Analysis for Mechanical and Aerospace Engineers 
James Middleton
Advanced Engineering Mathematics with MATLAB, Fifth Edition 
Dean G. Duffy
Handbook of Fractional Calculus for Engineering and Science 
Harendra Singh, H. M. Srivastava, Juan J Nieto
Advanced Engineering Mathematics 
A Second Course with MATLAB 
Dean G. Duffy
Quantum Computation 
A Mathematical Foundation for Computer Scientists, Physicists, and Mathematicians 
Helmut Bez and Tony Croft
Computational Mathematics 
An Introduction to Numerical Analysis and Scientific Computing with Python 
Dimitrios Mitsotakis
https://www.routledge.com/Advances-in-Applied-Mathematics/book-series/CRCADVAPPMTH?pd=published,forthcom
ing&pg=1&pp=12&so=pub&view=list

Computational Mathematics
An Introduction to Numerical Analysis 
and Scientific Computing with Python
Dimitrios Mitsotakis

Designed cover image: https://exhibitions.lib.cam.ac.uk/linesofthought/artifacts/newton-by-kneller/
Sir Godfrey Kneller, Bart. Portrait of Sir Isaac Newton, 1689; oil on canvas
First edition published 2023
by CRC Press
6000 Broken Sound Parkway NW, Suite 300, Boca Raton, FL 33487-2742
and by CRC Press
4 Park Square, Milton Park, Abingdon, Oxon, OX14 4RN
CRC Press is an imprint of Taylor & Francis Group, LLC
© 2023 Dimitrios Mitsotakis  
Reasonable efforts have been made to publish reliable data and information, but the author and publisher cannot as-
sume responsibility for the validity of all materials or the consequences of their use. The authors and publishers have 
attempted to trace the copyright holders of all material reproduced in this publication and apologize to copyright holders 
if permission to publish in this form has not been obtained. If any copyright material has not been acknowledged, please 
write and let us know so we may rectify in any future reprint.
Except as permitted under U.S. Copyright Law, no part of this book may be reprinted, reproduced, transmitted, or 
utilized in any form by any electronic, mechanical, or other means, now known or hereafter invented, including pho-
tocopying, microfilming, and recording, or in any information storage or retrieval system, without written permission 
from the publishers.
For permission to photocopy or use material electronically from this work, access www.copyright.com or contact the 
Copyright Clearance Center, Inc. (CCC), 222 Rosewood Drive, Danvers, MA 01923, 978-750-8400. For works that are 
not available on CCC, please contact mpkbookspermissions@tandf.co.uk
Trademark notice: Product or corporate names may be trademarks or registered trademarks and are used only for iden-
tification and explanation without intent to infringe.
ISBN: 978-1-032-26239-0 (hbk)
ISBN: 978-1-032-26240-6 (pbk)	
ISBN: 978-1-003-28729-2 (ebk)
DOI: 10.1201/9781003287292
Typeset in CMR10 
by KnowledgeWorks Global Ltd.
Publisher’s note: This book has been prepared from camera-ready copy provided by the authors.
Access the Support Material: [https://www.routledge.com/9781032262390]  

Dedicated to my family

Taylor & Francis 
Taylor & Francis Group 
http://taylorandfrancis.com 

“[...] he knew the difference between knowing the name of
something and knowing something [...]”
by Ritchard P. Feynman talking about his father and the notion
of deep understanding [40]

Taylor & Francis 
Taylor & Francis Group 
http://taylorandfrancis.com 

Contents
Preface
xv
I
Introduction to Scientific Computing with Python
1
1
Introduction to Python
3
1.1
Basic Python . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
1.1.1
Python, numbers and variables . . . . . . . . . . . . . . . . . . . . .
3
1.1.2
Basic mathematical operations . . . . . . . . . . . . . . . . . . . . .
5
1.1.3
Mathematical functions and constants . . . . . . . . . . . . . . . . .
7
1.1.4
Powers of 10 and scientific notation
. . . . . . . . . . . . . . . . . .
9
1.2
Assignment Operators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9
1.3
Strings, Tuples, Dictionaries and Lists . . . . . . . . . . . . . . . . . . . . .
10
1.3.1
Strings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
10
1.3.2
Tuples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
1.3.3
Dictionaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12
1.3.4
Lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
13
1.3.5
Lists of lists . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
15
1.4
Flow Control . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16
1.4.1
for loops . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16
1.4.2
Useful applications . . . . . . . . . . . . . . . . . . . . . . . . . . . .
18
1.4.3
Boolean type of variables
. . . . . . . . . . . . . . . . . . . . . . . .
21
1.4.4
while loops . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
21
1.4.5
Decisions and the if statement . . . . . . . . . . . . . . . . . . . . .
23
1.4.6
Error control and exceptions
. . . . . . . . . . . . . . . . . . . . . .
24
1.4.7
The command break . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
1.5
Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
26
1.6
Classes
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
29
1.7
Accessing Data Files . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
31
1.8
Further Reading
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
32
Chapter Highlights
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
33
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
2
Matrices and Python
37
2.1
Review of Matrices
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
2.1.1
Matrix properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
38
2.1.2
Special matrices
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
40
2.2
The NumPy Module . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
42
2.2.1
Matrices and arrays
. . . . . . . . . . . . . . . . . . . . . . . . . . .
42
2.2.2
Slicing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
44
2.2.3
Special matrices, methods and properties
. . . . . . . . . . . . . . .
46
2.2.4
Matrix assignment . . . . . . . . . . . . . . . . . . . . . . . . . . . .
49
2.2.5
Matrix addition and scalar multiplication . . . . . . . . . . . . . . .
50
vii

viii
Contents
2.2.6
Vectorized algorithms
. . . . . . . . . . . . . . . . . . . . . . . . . .
52
2.2.7
Performance of algorithms . . . . . . . . . . . . . . . . . . . . . . . .
53
2.2.8
Matrix multiplication
. . . . . . . . . . . . . . . . . . . . . . . . . .
54
2.2.9
Inverse of a matrix . . . . . . . . . . . . . . . . . . . . . . . . . . . .
60
2.2.10 Determinant of a matrix . . . . . . . . . . . . . . . . . . . . . . . . .
61
2.2.11 Linear systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
62
2.2.12 Eigenvalues and eigenvectors
. . . . . . . . . . . . . . . . . . . . . .
64
2.3
The SciPy Module . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
66
2.3.1
Systems with banded matrices
. . . . . . . . . . . . . . . . . . . . .
66
2.3.2
Systems with positive definite, banded matrices . . . . . . . . . . . .
69
2.3.3
Systems with other special matrices
. . . . . . . . . . . . . . . . . .
73
2.4
Drawing Graphs with MatPlotLib
. . . . . . . . . . . . . . . . . . . . . . .
75
2.4.1
Plotting one-dimensional arrays . . . . . . . . . . . . . . . . . . . . .
75
2.5
Further Reading
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
80
Chapter Highlights
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
81
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
82
3
Scientific Computing
87
3.1
Computer Arithmetic and Sources of Error
. . . . . . . . . . . . . . . . . .
87
3.1.1
Catastrophic cancelation . . . . . . . . . . . . . . . . . . . . . . . . .
88
3.1.2
The machine precision . . . . . . . . . . . . . . . . . . . . . . . . . .
89
3.2
Normalized Scientific Notation
. . . . . . . . . . . . . . . . . . . . . . . . .
90
3.2.1
Floats in Python . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
92
3.3
Rounding and Chopping
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
92
3.3.1
Absolute and relative errors . . . . . . . . . . . . . . . . . . . . . . .
93
3.3.2
Loss of significance (again)
. . . . . . . . . . . . . . . . . . . . . . .
94
3.3.3
Algorithms and stability . . . . . . . . . . . . . . . . . . . . . . . . .
94
3.3.4
Approximations of π . . . . . . . . . . . . . . . . . . . . . . . . . . .
95
3.4
Further Reading
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
99
Chapter Highlights
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
100
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
101
4
Calculus Facts
105
4.1
Sequences and Convergence . . . . . . . . . . . . . . . . . . . . . . . . . . .
105
4.2
Continuous Functions
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
107
4.2.1
Bolzano’s intermediate value theorem
. . . . . . . . . . . . . . . . .
109
4.3
Differentiation
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
110
4.3.1
Important theorems from differential calculus . . . . . . . . . . . . .
112
4.3.2
Taylor polynomials . . . . . . . . . . . . . . . . . . . . . . . . . . . .
113
4.3.3
The big-O notation . . . . . . . . . . . . . . . . . . . . . . . . . . . .
115
4.4
Integration
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
115
4.4.1
Approximating integrals . . . . . . . . . . . . . . . . . . . . . . . . .
116
4.4.2
Important theorems of integral calculus
. . . . . . . . . . . . . . . .
117
4.4.3
The remainder in Taylor polynomials . . . . . . . . . . . . . . . . . .
118
4.5
Further Reading
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
119
Chapter Highlights
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
120
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
121

Contents
ix
II
Introduction to Computational Mathematics
125
5
Roots of Equations
127
5.1
Bisection Method
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
127
5.1.1
Derivation and implementation . . . . . . . . . . . . . . . . . . . . .
127
5.1.2
Proof of convergence . . . . . . . . . . . . . . . . . . . . . . . . . . .
130
5.1.3
Rate of convergence
. . . . . . . . . . . . . . . . . . . . . . . . . . .
131
5.2
Fixed-Point Methods
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
134
5.2.1
Derivation and implementation . . . . . . . . . . . . . . . . . . . . .
135
5.2.2
Theoretical considerations . . . . . . . . . . . . . . . . . . . . . . . .
139
5.2.3
Convergence of fixed-point methods
. . . . . . . . . . . . . . . . . .
140
5.3
Newton’s Method
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
141
5.3.1
Derivation and implementation . . . . . . . . . . . . . . . . . . . . .
141
5.3.2
Rate of convergence
. . . . . . . . . . . . . . . . . . . . . . . . . . .
145
5.4
Secant Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
147
5.4.1
Derivation and implementation . . . . . . . . . . . . . . . . . . . . .
148
5.4.2
Rate of convergence
. . . . . . . . . . . . . . . . . . . . . . . . . . .
151
5.5
Other Methods and Generalizations
. . . . . . . . . . . . . . . . . . . . . .
156
5.5.1
Stopping criteria . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
156
5.5.2
Steffensen’s method
. . . . . . . . . . . . . . . . . . . . . . . . . . .
156
5.5.3
Aitken’s delta-squared process
. . . . . . . . . . . . . . . . . . . . .
157
5.5.4
Multiple roots
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
157
5.5.5
High-order methods
. . . . . . . . . . . . . . . . . . . . . . . . . . .
158
5.5.6
Systems of equations . . . . . . . . . . . . . . . . . . . . . . . . . . .
158
5.6
The Module scipy.optimize
. . . . . . . . . . . . . . . . . . . . . . . . .
160
5.6.1
Bisection method . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
160
5.6.2
Fixed-point methods . . . . . . . . . . . . . . . . . . . . . . . . . . .
161
5.6.3
Newton and secant methods . . . . . . . . . . . . . . . . . . . . . . .
162
5.6.4
A hybrid method . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
164
5.6.5
Application in astrophysics
. . . . . . . . . . . . . . . . . . . . . . .
165
5.7
Further Reading
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
167
Chapter Highlights
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
168
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
169
6
Interpolation and Approximation
175
6.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
175
6.2
Lagrange Interpolation
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
177
6.2.1
Naive construction of the interpolant . . . . . . . . . . . . . . . . . .
177
6.2.2
Lagrange polynomials . . . . . . . . . . . . . . . . . . . . . . . . . .
180
6.2.3
Failure of Lagrange interpolation . . . . . . . . . . . . . . . . . . . .
185
6.2.4
Error analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
185
6.2.5
Newton’s representation with divided differences . . . . . . . . . . .
188
6.2.6
More on divided differences . . . . . . . . . . . . . . . . . . . . . . .
192
6.3
Hermite Interpolation
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
195
6.3.1
Computation of the Hermite interpolant . . . . . . . . . . . . . . . .
196
6.3.2
Error analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
198
6.3.3
Implementation details . . . . . . . . . . . . . . . . . . . . . . . . . .
200
6.4
Spline Interpolation
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
200
6.4.1
Continuous piecewise linear interpolation
. . . . . . . . . . . . . . .
202
6.4.2
Some theoretical considerations . . . . . . . . . . . . . . . . . . . . .
205
6.4.3
Error analysis of piecewise linear interpolation
. . . . . . . . . . . .
205

x
Contents
6.4.4
Cubic spline interpolation . . . . . . . . . . . . . . . . . . . . . . . .
207
6.4.5
An algorithm for cubic splines
. . . . . . . . . . . . . . . . . . . . .
208
6.4.6
Theoretical considerations and error analysis
. . . . . . . . . . . . .
213
6.4.7
B-splines
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
217
6.5
Method of Least Squares
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
222
6.5.1
Linear least squares
. . . . . . . . . . . . . . . . . . . . . . . . . . .
222
6.5.2
Polynomial fit . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
225
6.5.3
Non-polynomial fit . . . . . . . . . . . . . . . . . . . . . . . . . . . .
227
6.6
The Module scipy.interpolate
. . . . . . . . . . . . . . . . . . . . . . .
229
6.6.1
Lagrange interpolation . . . . . . . . . . . . . . . . . . . . . . . . . .
229
6.6.2
Cubic spline interpolation . . . . . . . . . . . . . . . . . . . . . . . .
230
6.6.3
Computations with B-splines . . . . . . . . . . . . . . . . . . . . . .
232
6.6.4
General purpose interpolation and the function interp1d . . . . . .
234
6.6.5
Interpolation in two dimensions . . . . . . . . . . . . . . . . . . . . .
235
6.6.6
Application in image processing . . . . . . . . . . . . . . . . . . . . .
238
6.7
Further Reading
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
241
Chapter Highlights
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
242
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
243
7
Numerical Integration
247
7.1
Introduction to Numerical Quadrature and Midpoint Rule
. . . . . . . . .
247
7.2
Newton-Cotes Quadrature Rules
. . . . . . . . . . . . . . . . . . . . . . . .
249
7.2.1
Trapezoidal rule
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
251
7.2.2
Error estimate of the trapezoidal rule
. . . . . . . . . . . . . . . . .
251
7.2.3
Composite trapezoidal rule
. . . . . . . . . . . . . . . . . . . . . . .
252
7.2.4
Error estimate of the composite trapezoidal rule
. . . . . . . . . . .
254
7.2.5
Simpson’s rule
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
254
7.2.6
Composite Simpson’s rule . . . . . . . . . . . . . . . . . . . . . . . .
255
7.2.7
Error of Simpson’s rule
. . . . . . . . . . . . . . . . . . . . . . . . .
256
7.2.8
Degree of exactness
. . . . . . . . . . . . . . . . . . . . . . . . . . .
257
7.3
Gaussian Quadrature Rules . . . . . . . . . . . . . . . . . . . . . . . . . . .
258
7.3.1
Choice of nodes and weights . . . . . . . . . . . . . . . . . . . . . . .
259
7.3.2
Gauss-Legendre quadrature rules . . . . . . . . . . . . . . . . . . . .
260
7.3.3
Gaussian quadrature on general intervals
. . . . . . . . . . . . . . .
262
7.3.4
Error analysis of the Gaussian quadrature . . . . . . . . . . . . . . .
264
7.4
The Module scipy.integrate . . . . . . . . . . . . . . . . . . . . . . . . .
265
7.4.1
Trapezoidal rule
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
265
7.4.2
Simpson’s rule
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
266
7.4.3
Gaussian quadrature . . . . . . . . . . . . . . . . . . . . . . . . . . .
267
7.4.4
Application in classical mechanics
. . . . . . . . . . . . . . . . . . .
268
7.5
Further Reading
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
269
Chapter Highlights
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
270
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
271
8
Numerical Differentiation and Applications to Differential Equations
275
8.1
Numerical Differentiation
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
275
8.1.1
First-order accurate finite difference approximations . . . . . . . . .
275
8.1.2
Second-order accurate finite difference approximations . . . . . . . .
277
8.1.3
Error estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
278
8.1.4
Approximation of second-order derivatives . . . . . . . . . . . . . . .
279
8.1.5
Richardson’s extrapolation
. . . . . . . . . . . . . . . . . . . . . . .
280

Contents
xi
8.2
Applications to Ordinary Differential Equations
. . . . . . . . . . . . . . .
282
8.2.1
First-order ordinary differential equations . . . . . . . . . . . . . . .
282
8.2.2
Euler method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
283
8.2.3
Alternative derivation and error estimates . . . . . . . . . . . . . . .
286
8.2.4
Implicit variants of Euler’s method . . . . . . . . . . . . . . . . . . .
290
8.2.5
Improved Euler method . . . . . . . . . . . . . . . . . . . . . . . . .
291
8.2.6
The notion of stability . . . . . . . . . . . . . . . . . . . . . . . . . .
293
8.3
Runge-Kutta Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
295
8.3.1
Explicit Runge-Kutta methods . . . . . . . . . . . . . . . . . . . . .
295
8.3.2
Implicit and diagonally implicit Runge-Kutta methods . . . . . . . .
298
8.3.3
Adaptive Runge-Kutta methods
. . . . . . . . . . . . . . . . . . . .
301
8.4
The Module scipy.integrate Again
. . . . . . . . . . . . . . . . . . . . .
303
8.4.1
Generic integration of initial value problems . . . . . . . . . . . . . .
303
8.4.2
Systems of ordinary differential equations . . . . . . . . . . . . . . .
306
8.4.3
Application in epidemiology . . . . . . . . . . . . . . . . . . . . . . .
307
8.5
Further Reading
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
309
Chapter Highlights
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
310
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
311
9
Numerical Linear Algebra
317
9.1
Numerical Solution of Linear Systems
. . . . . . . . . . . . . . . . . . . . .
317
9.1.1
Algorithm for the naive Gaussian elimination . . . . . . . . . . . . .
320
9.1.2
LU factorization . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
323
9.1.3
Implementation of LU factorization
. . . . . . . . . . . . . . . . . .
327
9.2
Pivoting Strategies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
329
9.2.1
Gaussian elimination with partial pivoting . . . . . . . . . . . . . . .
331
9.2.2
LU factorization with pivoting
. . . . . . . . . . . . . . . . . . . . .
333
9.3
Condition Number of a Matrix
. . . . . . . . . . . . . . . . . . . . . . . . .
337
9.3.1
Vector and matrix norms
. . . . . . . . . . . . . . . . . . . . . . . .
337
9.3.2
Theoretical properties of matrix norms . . . . . . . . . . . . . . . . .
341
9.3.3
Condition number
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
343
9.4
Other Matrix Computations
. . . . . . . . . . . . . . . . . . . . . . . . . .
345
9.4.1
Computation of inverse matrix . . . . . . . . . . . . . . . . . . . . .
346
9.4.2
Computation of determinants . . . . . . . . . . . . . . . . . . . . . .
347
9.5
Symmetric Matrices
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
348
9.5.1
LDLT factorization
. . . . . . . . . . . . . . . . . . . . . . . . . . .
348
9.5.2
Cholesky factorization . . . . . . . . . . . . . . . . . . . . . . . . . .
349
9.6
The Module scipy.linalg Again
. . . . . . . . . . . . . . . . . . . . . . .
352
9.6.1
LU factorization . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
352
9.6.2
Cholesky factorization . . . . . . . . . . . . . . . . . . . . . . . . . .
354
9.7
Iterative Methods
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
355
9.7.1
Derivation of iterative methods . . . . . . . . . . . . . . . . . . . . .
355
9.7.2
Classical iterative methods – Jacobi and Gauss-Seidel methods . . .
356
9.7.3
Convergence of iterative methods . . . . . . . . . . . . . . . . . . . .
360
9.7.4
Sparse matrices in Python and the module scipy.sparse . . . . . .
362
9.7.5
Sparse Gauss-Seidel implementation . . . . . . . . . . . . . . . . . .
365
9.7.6
Sparse linear systems and the module scipy.sparce . . . . . . . . .
367
9.7.7
Application in electric circuits . . . . . . . . . . . . . . . . . . . . . .
369
9.8
Further Reading
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
372
Chapter Highlights
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
373
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
374

xii
Contents
III
Advanced Topics
381
10 Best Approximations
383
10.1 Vector Spaces, Norms and Approximations
. . . . . . . . . . . . . . . . . .
383
10.1.1 Vector spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
383
10.1.2 Inner products and norms . . . . . . . . . . . . . . . . . . . . . . . .
384
10.1.3 Best approximations . . . . . . . . . . . . . . . . . . . . . . . . . . .
386
10.2 Linear Least Squares
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
388
10.2.1 Theoretical properties of linear least squares
. . . . . . . . . . . . .
389
10.2.2 Solution of linear least squares problem
. . . . . . . . . . . . . . . .
390
10.2.3 Linear least squares problem in Python
. . . . . . . . . . . . . . . .
391
10.3 Gram-Schmidt Orthonormalization
. . . . . . . . . . . . . . . . . . . . . .
393
10.3.1 Numerical implementation . . . . . . . . . . . . . . . . . . . . . . . .
395
10.4 QR Factorization
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
397
10.4.1 Linear least squares using QR factorization . . . . . . . . . . . . . .
397
10.4.2 Computation of range . . . . . . . . . . . . . . . . . . . . . . . . . .
398
10.4.3 Householder matrices and QR factorization . . . . . . . . . . . . . .
398
10.4.4 Python implementation and orthonormalization . . . . . . . . . . . .
400
10.5 Singular Value Decomposition
. . . . . . . . . . . . . . . . . . . . . . . . .
401
10.5.1 Derivation of SVD . . . . . . . . . . . . . . . . . . . . . . . . . . . .
402
10.5.2 Theoretical considerations . . . . . . . . . . . . . . . . . . . . . . . .
404
10.5.3 Pseudoinverse and SVD . . . . . . . . . . . . . . . . . . . . . . . . .
406
10.5.4 Linear least squares problem and SVD . . . . . . . . . . . . . . . . .
407
10.5.5 Singular value decomposition in Python . . . . . . . . . . . . . . . .
407
10.5.6 Application in image compression . . . . . . . . . . . . . . . . . . . .
409
10.6 Further Reading
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
411
Chapter Highlights
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
412
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
413
11 Unconstrained Optimization and Neural Networks
417
11.1 Gradient Methods for Unconstrained Optimization . . . . . . . . . . . . . .
417
11.1.1 Estimation of convergence . . . . . . . . . . . . . . . . . . . . . . . .
420
11.1.2 Method of steepest descent
. . . . . . . . . . . . . . . . . . . . . . .
423
11.1.3 Solving linear systems using optimization . . . . . . . . . . . . . . .
426
11.1.4 Theoretical considerations . . . . . . . . . . . . . . . . . . . . . . . .
428
11.2 Conjugate Gradient Method
. . . . . . . . . . . . . . . . . . . . . . . . . .
431
11.2.1 Conjugate gradient method and linear systems . . . . . . . . . . . .
432
11.2.2 Convergence and preconditioning . . . . . . . . . . . . . . . . . . . .
434
11.2.3 Extensions to nonlinear systems
. . . . . . . . . . . . . . . . . . . .
435
11.3 Newton’s Method in Optimization
. . . . . . . . . . . . . . . . . . . . . . .
438
11.3.1 Newton’s iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . .
438
11.3.2 Quasi-Newton methods
. . . . . . . . . . . . . . . . . . . . . . . . .
439
11.3.3 Nonlinear optimization and the module scipy.optimize
. . . . . .
441
11.3.4 The Gauss-Newton approximation . . . . . . . . . . . . . . . . . . .
442
11.3.5 The Levenberg-Marquardt modification
. . . . . . . . . . . . . . . .
443
11.4 Introduction to Neural Networks . . . . . . . . . . . . . . . . . . . . . . . .
444
11.4.1 A simple neural network . . . . . . . . . . . . . . . . . . . . . . . . .
444
11.4.2 Activation functions . . . . . . . . . . . . . . . . . . . . . . . . . . .
448
11.4.3 General feedforward neural networks . . . . . . . . . . . . . . . . . .
449
11.4.4 Machine learning and the module sklearn
. . . . . . . . . . . . . .
453
11.4.5 Application in image recognition . . . . . . . . . . . . . . . . . . . .
458

Contents
xiii
11.5 Further Reading
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
460
Chapter Highlights
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
461
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
462
12 Eigenvalue Problems
467
12.1 Eigenvalues and Eigenvectors . . . . . . . . . . . . . . . . . . . . . . . . . .
467
12.1.1 Basic properties
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
467
12.1.2 Diagonalization of a matrix and the Jordan normal form . . . . . . .
468
12.1.3 Other properties . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
469
12.1.4 First estimation of eigenvalues using Gerschgorin disks . . . . . . . .
471
12.2 Numerical Approximation of Eigenvalues and Eigenvectors
. . . . . . . . .
472
12.2.1 Power method
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
472
12.2.2 Inverse power method . . . . . . . . . . . . . . . . . . . . . . . . . .
475
12.2.3 Shifted inverse power method . . . . . . . . . . . . . . . . . . . . . .
477
12.2.4 Basic QR iteration . . . . . . . . . . . . . . . . . . . . . . . . . . . .
477
12.2.5 Application in computer networks
. . . . . . . . . . . . . . . . . . .
479
12.3 Further Reading
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
482
Chapter Highlights
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
483
Exercises
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
484
Appendix A Computing Jordan Normal Forms
487
Bibliography
493
Index
501

Taylor & Francis 
Taylor & Francis Group 
http://taylorandfrancis.com 

Preface
This book is an introduction to some of the methods of computational mathematics. Com-
putational mathematics (also known as numerical analysis or numerical mathematics) is a
branch of applied mathematics dedicated to the development and justification of methods
and algorithms for solving scientific problems using computers. Methods of computational
mathematics have been designed to solve problems that can be described with mathemat-
ical equations. Many branches of science, including physics, engineering and finance rely
on computational mathematics. The reason is simple: Scientific problems usually cannot be
solved without computers. Alongside with the rest of applied mathematics, computational
mathematics has become a key tool for understanding our complicated world. If we could
describe applied mathematics as a circle starting with the statement of a scientific problem
and its mathematical description, then computational mathematics as part of that circle
would provide approximate solutions to the problem using scientifically sound numerical
methods. A schematic representation of the processes in the circle of applied mathematics
is depicted in Figure 1. Topics in the last three bubbles are introduced in this book and
consist of the derivation and justification of numerical methods and numerical simulations.
The main purpose of this book is to present how some numerical analysis methods work in
theory and in practice.
The ultimate goal of this book though is to help students develop skills and learn clas-
sical and modern tools for solving mathematical problems using computers. However, in
order to be able to understand the mathematical notions, numerical methods and proofs of
this book, the reader should be equipped with basic knowledge in computer programming,
basic calculus and linear algebra. Important methods and theories required for a complete
and modern course in numerical analysis are to be found in this book. For the sake of com-
pleteness, I have included a few highly technical proofs among the basic proofs to justify
the robustness of methods. The end of a proof is indicated by the symbol □. Technical
proofs can be passed over by the reader who is not interested in the theoretical justification
of numerical methods. In terms of typesetting, bold letters denote vectors and matrices,
while regular letters have been used for scalar numbers. Most of the numerical methods are
accompanied by their algorithms in pseudo-language and their implementation in Python.
Therefore, it is our wish that this book will serve as both an introduction to Python and as
a reference book to numerical analysis. Several applications can be found at the end of each
chapter and in the exercises. These applications illustrate the use of numerical methods in
practical problems of computer science, physics and machine learning.
The choice of programming language for scientific computations is a rather difficult task.
One may choose among classical programming languages such as C/C++ and Fortran, or
languages such as Python, Julia and MATLAB®. In this book, we present all the material
in Python. Python is a free programming language with a wide variety of extensions. These
include extensions to data science and machine learning, as well as more traditional areas,
such as the numerical solution of differential equations. Python comes with functions for
almost every method we present in this book, which makes Python a great pedagogical tool.
The computer code you will find in this book is written in such a simple way that experts
in Python will find my coding style very naive. However, I believe that this style helps
xv

xvi
Preface
students to learn programming. Each programmer can follow their own programming style or
standards, like those suggested by the official “style guide for Python code” PEP. To ensure
the validity of our code, we produced the output presented in this book with PythonTex
[106]. In the text, we also test the majority of methods and codes using the so-called method
of manufactured solutions. Specifically, we present experiments using simple problems with
known solutions, and we verify experimentally the properties and accuracy of the numerical
solutions. This is a common practice for experimental justification of numerical methods.
The book is organized into three parts. The first part contains a presentation of tools that
we use to develop and study numerical methods. Chapters 1 and 2 briefly introduce Python,
NumPy and SciPy and are dedicated to readers without previous experience in Python or
those who want to refresh basic knowledge. Chapter 2 serves as a revision of linear algebra
matters. It also introduces advanced methods, such as methods for special matrices. Chapter
3 is recommended to readers who are not familiar with floating point arithmetic and its
consequences. The first part closes with a brief review of absolutely necessary mathematical
notions and calculus tools to develop and justify numerical methods.
In the second part, we present the theory and implementation details of important and
commonly used numerical methods in science. More precisely, Chapter 5 presents methods
for the approximation of roots of nonlinear equations such as the bisection and Newton’s
method. Chapter 6 is dedicated to generating approximations of datasets, a procedure
known as interpolation from known to unknown. It contains an introduction to the widely
used method of regression (least squares approximation), which is one of the main ingredi-
ents of modern machine learning. Chapters 7 and 8 focus on two basic problems of infinites-
imal calculus, namely differentiation and integration. Applications to ordinary differential
equations are also presented. Chapter 9 is an introduction to numerical linear algebra and
presents fundamental methods for linear systems.
The third part contains more advanced numerical methods. Some of them can be char-
acterized as the pillars of scientific machine learning and neural networks. These include the
Singular Value Decomposition and nonlinear optimization methods. We attempted to pro-
vide a practical point of view of the subject and an exposition of its theoretical background
as well. This part usually cannot be covered in introductory courses and is usually found in
more advanced classes. To emphasize the applicability of the field of numerical analysis to
other scientific fields, such as the currently emerged field of machine learning, we present
a brief introduction to artificial neural networks as well as eigenvalue problems and a very
interesting application used by internet search engines.
I have to admit that this book cannot replace classical books of numerical analysis, and
we encourage readers to read as many books as they can in the field. The phrase hominem
unius libri timeo, meaning “I fear the person of a single book”, applies to science as well.
For this reason, in each chapter, we give references for further reading. Although I tried
to include all the well-known classical books in each field, I am sure that I have forgotten
to include some and apologize for that. My intention as always is to go back to the text
and correct my mistakes, which can be from typographical to more serious mistakes such
as failure to include important information. I close this paragraph by underlining the fact
that whenever we write computer code, it unavoidably contains errors (bugs), and requires
significant amount of time and effort to find them and correct them. I wish the readers
good luck, and hope you enjoy learning computational mathematics. Finally, I would like to
thank my friend, Ramsey Margolis, for his support, advice and help while I was writing this
book. I would like also to express my gratitude to my teachers and colleagues for teaching
me science over the years.
D. E. M.

Preface
xvii
Scientific problem
Derivation of
mathematical equations
Mathematical justification
of equations
Derivation of effective
numerical methods
Mathematical and
experimental justification
of numerical methods
Numerical simulations
FIGURE 1
A schematic representation of applied mathematics as described by Prof. G. Birkhoff and
transferred to me by two of his students (Professors J. Bona and V. Dougalis). See also [65]
for more details; Computational mathematics deals with the last three topics.

Taylor & Francis 
Taylor & Francis Group 
http://taylorandfrancis.com 

Part I
Introduction to Scientific
Computing with Python

Taylor & Francis 
Taylor & Francis Group 
http://taylorandfrancis.com 

1
Introduction to Python
Well, to begin with, we mention that G. Forsyth [42] pointed out that for the purposes of
scientific computing, a “math book isn’t enough”. In order to get the real essence of scientific
computing and numerical analysis, some coding and experimentation are important. For
this reason, we present the material of this book using Python as a modern and flexible
programming language. This chapter is a brief introduction to Python and is dedicated to
readers without previous experience. Special emphasis is given to mathematical applications
of repetitive processes using for loops and to logical if statements. We also show how to
write functions. We suggest to use Jupyter notebooks to test your code and run the examples
of this book. For an extended description of Python, we refer to specialized books on the
subject. A limited list of references can be found at the end of this chapter.
1.1
Basic Python
Python, as a modern programming language, is an interpreter that can be used as a cal-
culator to perform instantly complicated operations, as opposed to compilers that require
compilation of the computer code. We can perform the operation 1 + 1 in a Jupyter note-
book just by typing 1+1 and pressing shift+return. Notice that when we write a computer
command or code, we use fonts that resemble a typewriter. In the following paragraphs, we
explore some basic capabilities of Python.
1.1.1
Python, numbers and variables
0 Python plays the role of an instant interpreter between the programmer and the computer.
The programmer gives commands to the computer via Python language. Python commands
give directions to the computer system on how to perform operations. The most commonly
used first example in programming is: Display on the screen of the computer the phrase
Hello world!. This can be done easily by typing print(’Hello world!’) in our Jupyter
notebook and then pressing shift+return (or in some keyboards is shift+enter). For
example type the following command:
1
print('Hello world!')
Hello world!
Since we know how to display messages on the computer screen, we move to actual
computations. We should not forget that computer systems were first developed to execute
operations with numbers. For this reason, the fundamental element of any programming
language, including Python, is numbers. Numbers in Python can belong to different sets,
like the number sets we know from mathematics. Python practically has (almost) three main
DOI: 10.1201/9781003287292-1
3

4
Introduction to Python
sets of numbers. We used the word almost because there are many numbers missing from
computer arithmetic. Python understands integer, real and complex numbers. We usually
call the real numbers in Python floats or floating point numbers for reasons we will
discuss later.
The main differences between integer, real and complex values are the following: a real
number should contain a dot and/or a decimal part (for example 1.21), and the complex
number is defined from its real and imaginary parts, while the imaginary unit is denoted
by j. For example, we write 2 + 3i in Python as 2.0+3.0j.

Note that number 3 in Python is different from number 3. or 3.0. Although
integers and floats (floating point numbers) are different numbers, we can mix them
and perform operations with all of them, usually without problems. However, it is
advisable to use the dot whenever you consider floating point numbers.
Unfortunately, computers have a finite memory and understanding. They only know
some integer, real and complex numbers. Computer number systems are subsets of mathe-
matical number systems. There is a maximum integer value that we can use, which usually
depends on the computer system. We put this issue aside for the moment and continue with
how to deal with these numbers in practice.
If we type 1+1 in Python, we will get 2. It is true that we will have the result, but we
cannot use this result further. It is in fact forgotten by the computer immediately after it
is computed. If we want to keep a number in computer memory for future reference, we
need to ask computer for a storage place. The storage places in computer programming are
called variables. We store numbers (and other values) in variables. A variable is an object
that has a name, like variables in mathematics. We can have a variable with name x, and
we can store values in this variable just by typing x=2 or x=1+1.
We can name a variable with any name we want. Variable names should not contain
spaces or symbols that are reserved for operations. We can use the underscore symbol
.
Thus, we can use variables with names x, x , x, or we can use more descriptive names such
as number of students. We can store in the variable number of students the number of
students of a class. This can be done in Python by typing number of students = 50 and
pressing shift+return. If we want later on to see (access) the number of students in the
specific class, we can write the command print(number of students). Python will print
the number 50 on the screen of the computer. We can even change the number of students
to 40 by typing number of students = 40. The variable values can be changed just by
assigning a new value to the name of the variable.
1
number_of_students = 50
2
print( number_of_students )
3
number_of_students = 40
4
print( number_of_students )
50
40
Variables can store integer, real and complex numbers for future reference. We can
also store other things such as matrices, or text (which we usually call string and are
alpharithmetic sequences of letters, digits and symbols). To keep things simple, we consider
only integer, real and complex numbers and variables for the moment. We can identify the

Basic Python
5
type of a variable with the function type. For the variable x = 1.9 we can type type(x)
to find what is its kind. The type of this variable is float, which is equivalent to real.
1
x = 1.9
2
print( type(x) )
<class 'float'>
To provide more information related to a variable, we can use the print command to
display the value of a variable combined with the appropriate explanatory text (string).
Using the previous example, we can print the number of students using the more informative
output command
print( 'The number of students =', number_of_students )
This will print next to the value of the variable number of students the text (string) The
number of students = . This can make the communication between computer and human
easier.
Another option is not to assign a value of a variable in the program, but instead to
use the keyboard to enter the value we want. Python can read a value for a variable from
our computer keyboard via the function input. The format of the function input is the
following
variable = input( string )
This function will print the string on the screen, and the program will pause until we type
a value for the variable variable and hit the return/enter key. This value will be stored
in the variable variable in the computer memory. We rewrite the previous example using
the new features for input and output:
1
number_of_students = input( 'Enter the number of students' )
2
print( 'The number of students = ', number_of_students )
In these lines of code, line 1 will pause the execution of the program, and the computer
will wait for us to enter (type using the keyboard) the value we want to be stored in the
variable number of students. Then line 2 prints the same value with the explanation of
what that number is.
1.1.2
Basic mathematical operations
Now that we know about numbers and variables in Python, we continue with mathematical
operations between them. The simplest example of an arithmetic operation is the addition
of two numbers. We can perform very simple calculations such as 1 + 2 by just typing 1+2
in a Jupyter notebook and pressing shift+return.
1
1 + 2
3
Obviously, the arithmetic operator + indicates the sum of two numbers, and as we will
see later, it can add other objects such as matrices. The complete list of Python arithmetic
operators on numbers is presented in Table 1.1.

6
Introduction to Python
TABLE 1.1
Arithmetic operators in Python.
+
Addition
x+y
-
Subtraction
x-y
*
Multiplication
x*y
/
Division (float)
x/y
//
Division (floor)
x//y
%
Modulus (or remainder of division)
x%y
**
Raise to power
x**y
Float division results from the division between the numbers (or variables) x and y and
is a real number. The result of the floor division is the integer quotient between two numbers
or variables. We test the arithmetic operators using integers with the following code:
1
2
# Examples of Arithmetic Operators
3
x = 11
4
y = 2
5
# Addition of numbers
6
add = x + y
7
# Subtraction of numbers
8
sub = x - y
9
# Multiplication of numbers
10
mul = x * y
11
# Division (float) of numbers
12
div1 = x / y
13
# Division (floor) of numbers
14
div2 = x // y
15
# Modulo of both numbers
16
mod = x % y
17
# Raise to power
18
pow = x ** y
19
# print results
20
print( 'add = ', add )
21
print( 'sub = ', sub )
22
print( 'mul = ', mul )
23
print( 'div1 = ', div1 )
24
print( 'div2 = ', div2 )
25
print( 'mod = ', mod )
26
print( 'pow = ', pow )
add =
13
sub =
9
mul =
22
div1 =
5.5
div2 =
5
mod =
1
pow =
121

Basic Python
7
In the previous example, the commands and text following the symbol # are comments
and are not taken into account by Python. We use comments to make our codes readable
and also keep helpful notes for future reference. Observe that we can include helpful text in
the print command using quotes ’ or ". The text with the quotes is called alpharithmetic
or string.
The priority of the operations is the same as the operations priority we use in math-
ematics. Python first executes operations in parentheses (square and curly brackets are
reserved for other purposes), then exponents, then multiplications and divisions, and finally
additions and subtractions. We test the operations priority using the following commands
where we compute the variables a, b, c in one line of code using the separation operator ;
1
a = 1 + 2 * 3; b = (1 + 2) * 3; c = 2**2 * 3
2
print(a,b,c)
7 9 12
We can verify the result by doing the same thing with pen and paper:
a = 1 + 2 · 3 = 1 + 6 = 7, b = (1 + 2) · 3 = 3 · 3 = 9, c = 22 · 3 = 4 · 3 = 12 .
Another example of the arithmetic operations is the following: Suppose that there are
50 students registered for a course, number of students = 50. Later, 5 students drop the
course. The updated number of students is the old number of students minus 5. This in
python can be computed as easy as
1
number_of_students = 50
2
number_of_students = number_of_students - 5
3
print(number_of_students)
45
Initially number of students = 50. Then we assign to the variable with name number -
of students the result of the operation number of students - 5. Although we use the
same name on both sides of the relation, the result stored in the variable with name number -
of students has been updated to 45.

If we want to increase the value of the variable x by 1 the syntax is x = x +
1. If we want to decrease the value of the variable x by 3 the syntax is x = x -
3. We type x = 2 * x to double its value or x = x/3.0 to divide by 3. All these
expressions are not equations but assignments. The operator = assigns the value of
the right-hand side to the variable on left-hand side.
1.1.3
Mathematical functions and constants
It is common in scientific computations to use various mathematical functions and constants.
Suppose that we need to compute the value of the expression sin(π/5). Fortunately, the
most commonly used mathematical functions, including the sin function, are implemented
in Python. These are part of specialized libraries (files containing computer code) called
modules. There are many different Python modules. Mathematical functions can be found
in the module math as well as in the module numpy. The module numpy will be a subject of
later section, so for the moment we focus on the module math.

8
Introduction to Python
For efficiency reasons, modules are not loaded automatically. We can load an entire
module (library of functions) using the command
import module_name
where module name is the name of the module we want to load on computer’s memory. As
a result, all the names of functions, constants, and other objects, contained in the imported
module will be loaded into the memory. For example, we can write import math to load the
names of the functions included in the module math. If we need to use a specific function,
then we call the name of the module “dot” the name of the function like in the following
lines of code:
1
import math
2
print(math.sin(math.pi/5))
0.5877852522924731
In this example, math.sin is the sin function, and math.pi is the number π = 3.14 · · · .
The result shows that sin(π/5) ≈0.5877.
You might think that it is a waste of time to write the “math.” every time you want to
call a function, and this is reasonable. Sometimes, although it is not recommended, we can
import a whole module (not just function names), in such a way that we do not need to
specify the module again. This can be done by using the command from math import *.
After that we can use the sin function without writing math.sin.
1
from math import *
2
print(sin(pi/5))
0.5877852522924731
The method we just mentioned is not recommended. The reason we should avoid using
the last statement is because it makes the code slow, and in cases where we import more
than one module, it can happen that different functions can be implemented under the same
name in different modules. In such case, there will be a confusion on what function and
from what module we are using. For this reason, we import modules by giving them short
nicknames. This is also more convenient in terms of typing. For example, we can import the
module math with the nickname mt in the following way:
1
import math as mt
2
print( mt.sin(mt.pi/5) )
0.5877852522924731
As another example of how to use the math module, we consider an approximation of π
using the formula π = 4 arctan(1):
1
import math as mt
2
print( 4.0*mt.atan(1.0) )
3.141592653589793

Assignment Operators
9
Since we only used the function atan from the math module we can import only that
function by writing from math import atan. The complete code is the following:
1
from math import atan
2
print( 4.0*atan(1.0) )
3.141592653589793
Of course, in Python we do not really need to estimate the value of π as it is already in
various modules. On the other hand, in classical programming languages such as FORTRAN
and C we use the previous formula for the definition of π.
If you are curious to see how many different functions and constants you have at your
disposal in the math module, try typing the command dir(math) in a Jupyter notebook.
1
import math
2
dir(math)
This will show you on your screen the contents of the math module.
1.1.4
Powers of 10 and scientific notation
Sometimes you will need to type a very small number or a very large number. For example,
consider the number 0.0000015 = 1.5×10−6. It is convenient to represent such small numbers
using powers of 10. For this reason, we can use the so-called scientific notation. When we
want to type a number a×10b in scientific notation we write a e b, so the number 1.5×10−2
can be written as 1.5e-2. Another example is 2 × 109. In this case, because there are no
decimal digits we can write 2.e9 or just 2e9.
It is worth mentioning that very small floating point numbers, such as 1.e-15 or less can
be thought of good approximations of 0 when working with scales of order of 1 or greater.
In order to see this, perform the following peculiar calculation in Python:
1
print(1.0+1.e-16)
1.0
In this case, the addition of a tiny number such as 10−16 to 1 returns 1. This is mathe-
matically wrong, but it makes sense in computer arithmetic. More information about this
phenomenon can be found in Chapter 3 along with a more detailed description of scientific
notation.
1.2
Assignment Operators
We have already discussed that the sign = is used to assign a value to a variable. If we write
x = x + 1, it means that the value of x will be replaced by the result of the operation x
+ 1. This can also be thought of as the operation that increases the value of x by 1. In
Python we can perform this operation by using the specialized operator +=. For example,
we can write x += 1 instead of x = x + 1. We can use this operator to increase the value
of the variable x by any number. The command x += 2 is equivalent to x = x + 2 and will
increase the value of x by 2.

10
Introduction to Python
TABLE 1.2
Assignment operators in Python.
Operator
Use
Equivalent to
=
x = y
x = y
+=
x += y
x = x + y
-=
x -= y
x = x - y
*=
x *= y
x = x * y
/=
x /= y
x = x / y
%=
x %= y
x = x % y
**=
x **= y
x = x ** y
We can perform all sorts of operations to assign new values to a variable in a similar
way. If we want to multiply the value of variable x by 2, we can write
x *= 2, which is the
same as x = x * 2. The operators =, +=, *= are called assignment operators. A complete
list of assignment operators can be found in Table 1.2.
1.3
Strings, Tuples, Dictionaries and Lists
Here, we introduce some commonly used data structures. These structures are the following:
Strings that resemble text messages, tuples, which can combine more than one variable of
different types, and lists, which can be seen as vectors or sequences of similar objects.
1.3.1
Strings
A string (or alpharithmetic) is a sequence of characters (letters, numbers and symbols)
enclosed in single or double quotes. We can use strings when we want to display messages
on the screen. We have already seen how to print on the screen the message Hello world!
and we repeat it here to point out that the sentence Hello world! has been formed as a
string in single quotes:
1
print( 'Hello world!' )
Hello world!
We can also store strings in variables. For example, we can set my name = ’James’ and
my lastname = ’Bond’. We can also add strings and concatenate them like
full_name = my_name + ' ' + my_lastname
where we add after the variable my name a space and then the variable my lastname forming
the full name.
1
my_name = 'James'
2
my_lastname = 'Bond'
3
full_name = my_name + ' ' + my_lastname
4
print( full_name )
James Bond

Strings, Tuples, Dictionaries and Lists
11
We use the operator + to add strings although in this case the result is to merge the
different strings.
The string stored in the variable my name consists of 5 characters. Basically, it is stored
character by character, and we can access any character we want as it is an ordered array of
characters. For example, we can access the third letter of my name by using the command
print(my name[2]). We use the index 2 in order to print the third letter because in Python
counting starts from 0.
Starting counting from 0, we can write the full name using the slice operator (:) like my -
name[:]. Similarly, we can access the first 5 characters with the command my name[0:5].
This will access the entries of my name with index from 0 to 5, excluding 5. This is because
in Python the last index after the slice operator does not count. When we start from 0
we do not need to write it. So the previous command can be written as my name[:5]. We
can also start from any other entry in the particular sequence. For example, if we want to
print the entries after the third one we can type my name[3:]. This will print the fourth
my name[3] and fifth my name[4] letters (since we start counting from 0).
1
my_name = 'James'
2
print( my_name[:] )
3
print( my_name[0:5] )
4
print( my_name[:5] )
5
print( my_name[3:] )
James
James
James
es
In the same way, we can access any character or part of the string we want. We will analyze
further the slice operator when we discuss lists.

In Python we start counting from 0. The slice operator : can be used as follows
start:stop where start is the value from which we start counting and stop-1 is
where we want to stop. We say that Python is not inclusive. Python accesses the
entire array when we use the slice operator : without specifying where to start and
where to stop. If we don’t provide the value start then this is taken 0. If we do not
provide the value stop, then the counter will reach the last entry.
1.3.2
Tuples
A tuple is a sequence of (not necessarily same) objects separated with commas. For clarity,
tuples are usually enclosed in parentheses. For example, a tuple can be the combination
2,’Hi’ or (2,’Hi’), where its first entry is the number 2 and its second entry is ’Hi’.
Tuples can be useful when we want to return more than one object in a function. We can
access the entries of a tuple stored in a variable by using the location of the entry starting
from location 0. If we store the previous tuple in the variable x typing x = (2,’Hi’), then
we can access its first entry by typing x[0] and its second entry by typing x[1] without
forgetting that we always start counting from 0.

12
Introduction to Python
1
x = ( 2, 'Hi' )
2
print( x[0] )
3
print( x[1] )
2
Hi
We can also have tuples that contain a single object. Tuples are unchangeable objects.
Once we create a tuple we can either replace it with a new one or we can delete it using the
command del but we cannot change its values.
We can access a range of entries in a tuple by using the slice operator :. For example
we can access all its elements just by typing x[:]. To access the entries from the position
1 to 4 we write x[1:5]. We will discuss the slice operator in more detail below.
1.3.3
Dictionaries
A dictionary in Python is a data structure that creates references (keys) to some given
values. It is pretty much the same as what we know as dictionary. We use curly brackets to
define it and colon : to separate the key from its value.
For example, we can define a dictionary with name variables to store the variables
x = 0, y = 1 and z = 2
1
variables = { \
2
"x": 0, \
3
"y": 1, \
4
"z": 2 \
5
}
The backslash operator \ in the previous example stands for line break. Although it is
not required since the variables are contained in curly brackets, we still use line breaks in
order to write the code in a clear way. The code continues in the next line avoiding any
tabs or spaces.
We can access the key of a dictionary by using the name of the dictionary and the key
name inside square brackets. For example we can access the value of the variable x by typing
variables["x"].
1
print( variables["x"] )
0
We can change the value of a key in a dictionary by setting the key of the dictionary
variable equal to the new value:
1
variables["y"] = 10
2
print( variables["y"] )
10
Although dictionaries have many capabilities, we only mention the most fundamental,
because in this book we will not make any use of them.

Strings, Tuples, Dictionaries and Lists
13
1.3.4
Lists
A list is a data structure that resembles a vector and contains data linked as in a chain. Lists
can change size by adding entries anywhere we like. The list can contain only objects of the
same type (i.e. numbers only, or strings only, etc.). The different entries are separated by
commas and they are enclosed in square brackets. For example, we create the list (variable)
with name list and entries [5, 3, 7] as simple as list = [5, 3, 7]. If we want to
access an entry of a list, we ask for the specific entry (coordinate) starting counting from 0.
For example, the first entry of the list list is the entry list[0]. So we have the following
example:
1
list = [5, 3, 7]
2
print(list[0])
3
print(list[1])
4
print(list[2])
5
3
7
A list is a periodic structure, in the sense that we can access the last entry of a list by
calling its entry located before the first entry. This means that we can access the last entry
of a list by writing list[-1]. In the previous example this will give
1
list = [5, 3, 7]
2
print(list[-1])
7
We can easily make changes to an entry of a list by using the right index in the list. For
example, we can change the entry list[1] by just typing list[1] = 9
1
list[1] = 9
2
print(list)
[5, 9, 7]
We can add a new entry at the end of a list using the member function append which
takes as an argument the new entry. We call this function a member because it is part of
the structure list. For example, we can add the new value 10 at the end of the list list
using the command list.append(10).
1
list.append(10)
2
print(list)
[5, 9, 7, 10]
The length of a list can be found using the command len(list). This command uses
the function len with argument the name of a list, in our case list. Functions in Python
execute a certain procedure given some input arguments and return a result (like in any
other programming language). In the following example, we introduce a new list with the
name grades that contains the grades of a student. We store also the length of the list in
variable n.

14
Introduction to Python
1
grades = [9.0, 6.7, 8.5, 7.6, 9.8, 7.0]
2
n = len(grades)
3
print(n)
6
We can add new entries to the end of the list using the operator + avoiding the function
append as follows
1
grades = grades + [6.2, 8.2, 5.9]
2
print(grades)
[9.0, 6.7, 8.5, 7.6, 9.8, 7.0, 6.2, 8.2, 5.9]
The slice operator : can be used again in order to extract certain parts of a list. For
example, if we want to extract the entries 3, 4 and 5 (i.e. the entries grades[2], grades[3]
and grades[4]) we type
1
print(grades[2:5])
[8.5, 7.6, 9.8]
Observe that the slice operator includes the index value 5, indicating that we will go up
to index 4. In order to extract all values starting from the beginning of list grades until a
certain index (let’s say index 3) we can write grades[:4] without specifying the starting
index. Of course it is not wrong to write grades[0:4]. To extract all the values from index
4 until the end of the list we type grades[4:]. In general, the slice operator used to extract
multiple entries from lists and matrices. For example, start:stop:step will return the
values from start until stop-1 with step step. The default value of start is 0, for stop
is the end of the list, and for step is 1.
Copying one list variable to a new one needs some attention. If we use the command
list1 = list2, then the new variable list1 will be practically the same with list2. Thus,
when we make changes to any of these two lists, we modify the other one as well. In other
words we create an alias of the list2 with name list1. For example, consider the list2 =
[9, 6, 8, 7, 9, 7] and we modify the entry list2[1]. This alters both lists list1 and
list2.
1
list2 = [9, 6, 8, 7, 9, 7]
2
list1 = list2
3
list2[1] = 10
4
print(list1)
5
print(list2)
[9, 10, 8, 7, 9, 7]
[9, 10, 8, 7, 9, 7]
If we want to create a new unrelated copy of list2 with the name list1, then we need
to type list1 = list2[:].

Strings, Tuples, Dictionaries and Lists
15
1
list2 = [9, 6, 8, 7, 9, 7]
2
list1 = list2[:]
3
list2[1] = 10
4
print(list1)
5
print(list2)
[9, 6, 8, 7, 9, 7]
[9, 10, 8, 7, 9, 7]
Adding two lists results in a new list by concatenating the two lists. For example, if we
want to concatenate list1 and list2 and create a new one with the name list3, we need
to type list3 = list1 + list2.
1
list1 = [9, 6, 8, 7]
2
list2 = [1, 2, 3]
3
list3 = list1 + list2
4
print(list3)
[9, 6, 8, 7, 1, 2, 3]
Multiplying a list with a positive integer number will create a new list that will repeat
the list as many times as is the value of the multiplier. For example
1
list1 = [1, 2, 3]
2
list2 = 3*list1
3
print(list2)
[1, 2, 3, 1, 2, 3, 1, 2, 3]
Next we present a way to represent matrices as we know them from mathematics, using
lists of lists.
1.3.5
Lists of lists
Python does not have a built-in type for matrices. However, we can think of a matrix in
Python as a list of lists. The entries of this list (matrix) represent the matrix rows and are
lists. For example, the matrix
A =
1
2
3
4

,
is represented in Python as A = [[1,2],[3,4]].
1
A = [[1,2],[3,4]]
2
print(A)
[[1, 2], [3, 4]]
In linear algebra we usually refer to the entries aij of the matrix A using indices i =
1, 2, . . . and j = 1, 2, . . .. In the previous example the entry a11 = 1 and the entry a12 = 2.
The indices in Python start from 0 though. This means that in order to access the entry
a12 of A we need to access the entry of the Pythonic matrix located at the 0th row and 1st
column, indicating the row and the column in square brackets by typing A[0][1].

16
Introduction to Python
1
a12 = A[0][1]
2
print(a12)
2
Since we deal with lists of lists, multiplication with a scalar will result in a new matrix
(list) with different dimensions, which is not useful when we want to perform efficient matrix
computations. For scientific computations with matrices we use a different data structure
called array. This data structure is similar to the Pythonic list of lists but is equipped
with the usual linear algebra properties and operations. For this reason, we focus on matrix
computations using arrays. Arrays are provided by the module NumPy and will be subject
of later section.
1.4
Flow Control
In the previous sections we studied data structures including lists and matrices that may
contain thousands or millions of entries. Sometimes we need to access all of them one by
one. This sounds impossible. On the other hand, these procedures can be automated by
defining a repetitive process known as loop.
At other times we want to access an entry of a matrix when a specific condition holds. For
example, assume we want to use an entry only if the entry is not 0. This logical comparison
can be implemented within a logic control (boolean) statement.
1.4.1
for loops
Suppose we need to execute a specific command repeatedly for several times. For example,
let’s say that we want to print the text Hello world! three times. This can be done using
a for loop. A for loop starts with the word for followed by a variable index that takes
values in a specific order. The command ends with the slice operator “:”. This indicates
that the code beginning with a tab (four spaces) in lines that follow, will be executed every
time the loop is executed. The variable index usually is declared to belong in a specific list.
Then each command in the for loop will be executed once for each value of the variable in
the specified list. The general for loop would look like this:
for variable in list:
block of commands

Python is space-sensitive language and different blocks of code can be distin-
guished using tabs (4 spaces).
So in our case, to print three times the text Hello world! we will use a variable i as
a counter, which will take values from the list [0, 1, 2]. This can be implemented in the
following lines:
1
for i in [0, 1, 2]:
2
print('Hello world!')

Flow Control
17
Hello world!
Hello world!
Hello world!
It doesn’t really matter what the values in the list are since we don’t use the variable i
in any calculation. This list could have been [3, 5, 10] or any other list with three entries.
We can use the values of variable i by just using the variable in our code. For example, let’s
repeat the same loop but with printing the value of i instead of the string Hello world!.
1
for i in [0, 1, 2]:
2
print(i)
0
1
2
Another example that demonstrates the same thing but instead of using a list with
numbers we use a list with strings is the following
1
for animal in ['cat', 'dog', 'bird']:
2
print(animal)
cat
dog
bird
If we want to repeat a process 1000 times, it will not be convenient to use the list
[0,1,...,999] with values from 0 to 999. In this case, we can use the function range. The
function range creates a sequence of values from a start value start, up to a value stop-1
and they differ by step. The syntax of the function range is the following:
range([start ,] stop [,step])
The arguments in square brackets indicate optional arguments. When we omit the start
value the default value is 0. When we omit the step value the default value is 1. For example,
the command range(100) and range(0,100,1) will do the same thing: They will generate
a list with entries from 0 to 99 with step 1.

In Python when we indicate a stop value in the range function, (like in slices),
then this value is not used and the process ends at the value stop-1.
In our last example, if we want to print the values i from 0 to 2 we need to use the
function range(3), since this command will return the values 0, 1 and 2.
1
for i in range(3):
2
print(i)
0
1
2

18
Introduction to Python
Python for loops can be combined with an else clause, offering more functionality
compared to other programming languages. The else clause is executed when the for loop
is completed normally, which means it was not interrupted by a break command. For more
information on this Python for/else feature, we refer to more specialized texts on Python.
1.4.2
Useful applications
Here we discuss some useful applications that can be used in different circumstances. These
applications require techniques and methods we have learned so far.
Computing the sum of several numbers
Suppose we want to compute the sum of the first 100 positive integers. Mathematically
speaking this is the sum = 1 + 2 + 3 + · · · + 100 = P100
i=1 i. In order to compute this
sum we need a variable to store the result. We call this variable sum. Since we have to
add a lot of numbers, it is better to use a for loop over the numbers we need to add.
Initially, the variable sum has the value 0. At every loop we add the corresponding number
to the sum variable. This algorithm can be described using a pseudo-language like the one in
Algorithm 1.
Algorithm 1 Summation of many numbers
sum = 0
for i = 1 : n do
sum = sum + i
end for
This is the first numerical algorithm we present in this book using a pseudo-language.
When we present algorithms we tend to use natural indices instead of Python indices. So in
this algorithm when we write i = 1 : n it means that i takes all values from 1 to n with step
1. The general format of this iteration will be i = start : stop : step. An implementation of
this algorithm in Python can be the following:
1
sum = 0
2
for i in range(1,101):
3
sum = sum + i
4
print(sum)
5050
The command sum = sum + i can be replaced by the command sum += i. We could
have also started with sum = 1 instead of 0 and then add to this variable all the numbers
from 2 to 100. The result would have been the same using one addition less1.
Creating a uniform grid
A typical example that we will consider many times in the future, especially when we deal
with discrete problems (or formulations) instead of continuous is the following: Assume that
we have an interval [a, b] of the real line and that we want to divide it into N subintervals
1Every operation we perform in Python takes time and in lengthy calculations economy of operations
can be crucial.

Flow Control
19
FIGURE 1.1
A uniform grid of an interval [a, b].
[xi, xi+1] such that [a, b] = ∪N−1
i=0 [xi, xi+1]. This requires to take N + 1 points xi for i =
0, 1, . . . , N such that
a = x0 < x1 < x2 < · · · < xN−1 < xN = b .
The points xi are called nodes or grid points and they form a partition (usually called grid
or mesh) of the interval [a, b]. The distance between two nodes is usually denoted by hi or
∆xi and is defined as
hi = xi+1 −xi .
The maximum distance h = maxi{hi} is called gridsize or stepsize. If hi = h for all values
of i, then the grid is called uniform. If the grid is uniform then each subinterval [xi, xi+1]
of the interval [a, b] has the same length h = b−a
N . In this case
xi+1 = xi + h
for
i = 0, 1, . . . , N .
A uniform grid is presented in Figure 1.1.
You may wonder why we need to generate partitions of intervals of real numbers. The
answer is that when we perform scientific computations we cannot compute a solution or
function everywhere in an interval. Instead, we compute the values of the function or the
quantity only to a finite set of points x0, x1, . . . , xN in the interval [a, b]. This set of points
will be the grid.
Let us now use Python to create a uniform grid in the interval [0, 1] with 5 nodes (N = 4
intervals). Each subinterval will have length h = (1 −0)/4 = 0.25 and so the nodes will be
{x0, x1, x2, x3, x4} = {0, 0.25, 0.5, 0.75, 1} .
In order to create the grid we need a for loop to create the end-point xi+1 of each interval
[xi, xi+1] and will store it in a list called mesh. We initialize the list mesh with the value of
x0 = 0.0.
1
a = 0.0; b = 1.0;
2
N = 4 # the number of subintervals
3
h = (b-a)/float(N) # the grid-size
4
x = 0.0 # the starting node
5
mesh = [x] # initialization of the mesh list
6
for i in range(N):
7
x = x + h
8
mesh.append(x)
9
print(mesh)
[0, 0.25, 0.5, 0.75, 1.0]
In the previous code, line 1 defines the endpoints of the interval [a, b] and line 2 the
number of subintervals. In line 3 we use the formula h = (b −a)/N to define the uniform
stepsize. Observe that we divide by the number float(N) instead of N to avoid the conver-
sion of the result into integer, which can result to the number 0. Perhaps we didn’t need

20
Introduction to Python
to do this but it is a good practice to convert integers into floats using the function float
whenever possible to avoid bugs. In the for loop of lines 6–8 we create the grid using the
formula xi+1 = xi + h and we append our list mesh with the new value xi+1.
It is to be noted here that the variable x initially had the value 0.0 (line 4). Then,
during the first iteration of the for loop, the value x became x+h, which is 0 + 0.25 = 0.25.
This means that the initial value 0 has been replaced by 0.25 and entered at the end of the
list mesh. During the second iteration of the for loop the value of x is replaced again by
the result of the operation x+h, which is now 0.25 + 0.25 = 0.5. And in the rest of the loops
the code will compute the nodes 0.75 and 1.0.
Nested loops
Sometimes we need to use a for loop inside another for loop. For example let’s try to
access all the entries of the matrix
A =


11
12
13
21
22
23
31
32
33

.
In this case, working with rows, we need first to access the entries 11, 12, 13 of the first
row, then the entries 21, 22, 23 of the second row and finally the entries 31, 32, 33 of the
third row. So we need a for loop for each row and while we are working with a specific
row, we need a second loop for each column. This can be implemented using a nested loop
as follows:
1
A = [[11, 12, 13], \
2
[21, 22, 23], \
3
[31, 32, 33]]
4
# The \ at the end of each row indicate a line break
5
# and the code continues in the next line
6
for i in range(3):
7
for j in range(3):
8
print( A[i][j] )
11
12
13
21
22
23
31
32
33
In the definition of the Pythonic matrix A we use the symbol “\” to indicate an explicit
line break. The code continues in the next line avoiding possible tabs or spaces. This is
not really necessary when introducing matrices or arrays. In general splitting brackets and
parentheses do not require the explicit line break symbol “\”, and we will try to avoid the
use of the line break character in the rest of this book.
In this example the for loop of line 6 starts with the row i=0. Then, Python executes
the for loop of line 7 with fixed row i=0, where j takes the values 0, 1 and 2. (Remember
that the range function starts from 0 and never uses the value we set for upper bound).

Flow Control
21
So it will print the entries A[0][0], A[0][1], A[0][2]. When the second for loop finishes,
Python returns back to the first loop which hasn’t finished yet for i to take the value 1.
Now, for i=1, Python will execute again the second loop from the beginning, giving to j the
values 0, 1 and 2 and printing the entries A[1][0], A[1][1], A[1][2]. When the second
for loop finishes again, Python will return back to first for loop which hasn’t finished yet
as it remains to give to the variable i the value 2. For i=2, Python will execute the second
for for the last time (as i cannot take the value 3) and will print the last row A[2][0],
A[2][1], A[2][2].
Nested loops are common in Python and the syntax is based again on tabs (or 4 spaces).
If the first loop starts at some point of the code, the second loop needs to start 4 spaces (or
a tab) after the first loop. Common mistakes in the syntax of loops are either to forget the
slice operator (colon) or to use the wrong number of spaces under the for statement.
1.4.3
Boolean type of variables
So far we have encountered types of variables such as integers, floats, strings, lists, tuples
etc., but there are even more types. A very useful type of variables is the boolean (logical).
These variables can take the values True or False only. Assigning values to a boolean
variable is like assigning the value 1 if it is True or 0 if it is False. Boolean variables can
tell us if a statement is true or false. To understand how this can be done, consider the
logical statement 1 < 2. This statement is true since we know that 1 is less than 2. For
Python, this is a boolean operation, and the result is true. In order to see that, we store the
result in the variable a (boolean) by typing
a = 1<2
or
a = (1<2)
and we print it.
1
a = 1<2
2
print(a)
True
The result is True as expected.
There are several boolean operations. It is worth stressing again that the operator =
doesn’t mean equation or equality but assignment as it assigns to the variable on the left
side whatever is the result on the right side of the operator =. In order to check if two
variables are equal we use the operator ==. To check whether they are not equal we use the
operator !=. For example let us check if 1 = 1. This can be done by typing 1==1, or 1!=1.
The first operation gives the result True since 1 = 1 indeed. The second operation gives the
result False since the statement 1 ̸= 1 is false.
1
print(1==1)
2
print(1!=1)
True
False
A complete list of boolean operators in Python is presented in Table 1.3.
1.4.4
while loops
Now we are ready to discuss another kind of repetitive loop which can do a similar job to
for loop. This is the while loop. A while loop executes the code block contained in its
loop as long as a specified condition is True. The syntax of a while loop is the following:

22
Introduction to Python
TABLE 1.3
Boolean operators in Python
<
Less than
x < y
>
Greater than
x > y
==
Equal to
x == y
!=
Not equal to
x != y
<=
Less than or equal to
x <= y
>=
Greater than or equal to
x >= y
while condition:
block of commands
where condition can be a boolean variable or a logical expression. In the following code,
we create an infinite loop by keeping the condition always true.
1
cond = True
2
counter = 0
3
while cond:
4
print(counter)
5
counter +=1
In this example the variable cond will always remain true and the code will print the variable
counter starting from 0. This is the simplest example of a while loop.
Another example is the following. Let’s say that we want to print 1, 2, 3 on the screen.
This can be done by using a variable i with initial value 1 and then print all values of i
while they are less than or equal to 3. Inside the loop we need to increase the value of i
every time we print its value.
1
i=1
2
while i <= 3:
3
print(i)
4
i = i + 1
1
2
3
In the previous code, initially we set the variable i to be 1. Then, Python checks if i ≤3.
If this is True, then Python executes the block of commands within the specific loop, and
then it returns back to the while statement to check again whether i ≤3. During the first
loop Python prints the value of i, which is 1, and increases its value by 1. So the variable
i becomes 2. Python then checks again if the value i ≤3 is True or False. If it is True,
Python executes the block of code in the loop again, and repeats the same cycle until the
value of the variable i becomes i > 3 i.e. 4 since, here, i is an integer.
It should be noted that if the condition is always True then Python executes the
specific loop forever until we interrupt the execution. This is a typical bug when we use
while loops.

Flow Control
23
1.4.5
Decisions and the if statement
Sometimes, the flow of our code needs to change depending on the result of a boolean
(logical) operation. For example, assume we want to divide 10 by a variable x. If x = 0
we know that this is impossible. For this reason, we need to use an if statement. This is
formulated as follows
if condition:
block of commands
And here is an example where we consider the division of 10 by a variable x
1
x = int ( input('Give me x = ') )
2
if x != 0:
3
print(10/x)
In this case, our program will perform the division if x ̸= 0 only, while x is given from
the input. But, if we give x = 0, then our code does nothing. If we want to exhaust all
possible scenarios, we need to use another if statement with the case x = 0. For example,
we could tell Python to print an error message if x = 0. This can be done with the elif
or/and the else statements. The command elif is an abbreviation of else if and we need
to provide a new condition. On the other hand, with the else statement, there is no need
to provide any additional condition as this statement will be executed if all the previous
statements are False. In general, we can combine the if statement with elif and else.
The general if statement can be formulated as:
if condition1:
block of commands
elif condition2:
block of commands
else:
block of commands
where the blocks elif and else are optional. Observe that the else statement has no
condition since it is satisfied if the condition1 and condition2 are both False.
The complete code for the example with the division would be:
1
x = int ( input('Give me x = ') )
2
if x != 0:
3
print(10/x)
4
else:
5
print('Division impossible')
The division can be performed if x ̸= 0, otherwise the code prints the message Division
impossible.
It should be noted that if Python encounters a division by zero the execution of the
code will be terminated with an error message ZeroDivisionError: division by zero.
To illustrate the if clause better, consider the computation of the sign of a number
without using the built-in function sign. In this example, the input to the code is the
number stored in variable x. If this number is positive, x > 0, then the sign is +1, else if it
is negative, x < 0, then the sign is −1, and if x = 0, then the sign is 0. The Python code
should look like this:

24
Introduction to Python
1
x = int ( input('Give me x = ') )
2
if x > 0:
3
print('sign(x) = +1')
4
elif x < 0:
5
print('sign(x) = -1')
6
else:
7
print('sign(x) = 0')
Sometimes, we need more than one condition to be satisfied at the same time. For
example let’s say that we want to check if the value of a variable x is in the interval [0, 10],
or in other words if x ≥0 and x ≤10 at the same time. This can be expressed in Python
using the boolean operator and, and is as follows
1
x = int ( input('Give me x = ') )
2
if x >= 0 and x<=10 :
3
print('x is in the interval [0,10]')
4
else:
5
print('x is not in the interval [0,10]')
If we want to check whether the value x is outside the interval [0, 10] we can check if
x < 0 or x > 10 as these conditions cannot be true at the same time. This can be done
using the boolean operator or as follows
1
x = int ( input('Give me x = ') )
2
if x < 0 or x > 10 :
3
print('x is outside from the interval [0,10]')
4
else:
5
print('x is in the interval [0,10]')
Another way to check whether the value of x is in [0, 10] is to check if the value is not
outside the interval [0, 10] using the boolean operator not as follows
1
x = int ( input('Give me x = ') )
2
if not(x < 0 or x > 10) :
3
print('x is in the interval [0,10]')
4
else:
5
print('x is outside from the interval [0,10]')
The not operator acts like a function: it takes as an argument a boolean (True or False)
and returns the opposite value.
1.4.6
Error control and exceptions
In the previous section we discussed the case where we wanted to divide a number by a
variable x. We decided to use an if statement to avoid division by zero. This is because in
the event of a division by zero, the execution of the code might stop with an error message.
Problematic situations like the one we just mentioned can be avoided using the try and
except statements, instead of if statements. The syntax of the try and except statements
is the following

Flow Control
25
try:
block of commands
except error:
block of commands
The keyword error can be the name of the expected error, like ZeroDivisionError, or it
can be omitted. The code with the division by variable x can be written without the use of
the if statement in the following way:
1
x = 0
2
try:
3
print(10/x)
4
except:
5
print('The division is impossible')
6
x = 2
7
try:
8
print(10/x)
9
except:
10
print('The division is impossible')
The division is impossible
5.0
With the try and except statements we were able to perform the division 10/0 without
terminating the execution of the code and continue with the division 10/2. If we hadn’t used
this technique the code would have been stopped when the division 10/0 was performed
with the error ZeroDivisionError. We make use of the try and except statements in
Chapter 9 in the implementation of Cholesky algorithm.
Similar to the try and except statements is the command assert. This command is
formed as
assert expression
where expression can be a boolean statement. If this boolean statement is False, then the
execution of the code will be interrupted with an error message. If the expression is True,
then the assert statement has no effect in the execution of the code. The assert statement
can be useful for debugging purposes. Next, we discuss how to interrupt the execution of a
for loop.
1.4.7
The command break
The command break is used to terminate the execution of a for or while loop before the
termination condition is satisfied. This is usually required when an exception during the
loop process happens. The following example demonstrates the use of the command break
through a simple example. We use a for loop to iterate the variable i from 0 to 9. We
interrupt the for loop using a break statement when i becomes 5.
1
for i in range(10):
2
print(i)
3
if i == 5:
4
break

26
Introduction to Python
0
1
2
3
4
5
In this example we observe that although the for loop indicates that the variable i
can take values up to 9, the loop is terminated when i becomes 5 because of the break
command.
1.5
Functions
Functions are useful when we need to repeat a certain number of statements for several
times. In particular, we include code that we want to use repeatedly in discrete blocks of
code forming functions. These functions take some input and return some output. We can
use them by calling their name and without caring about their content. Python functions
can be thought of as factories where we give them some input variables, the function will
process them, and finally will return the result in the output. The general notion of a Python
function is not far from the general notion of a mathematical function. In mathematics we
define a function as y = f(x) where f is the name of the function, x is the input and y
is the output. Similarly, in Python we define a function first by using the keyword def to
indicate that we will define a function. Then we specify the name of the function and the
input. If the input consists of more than one variable we separate them with commas. We
close the line of the definition with the slice operator : and a block of code with the process
follows. The result of the function is usually indicated at the very end of the function with
the keyword return. We can return multiple variables or multiple values with the return
statement. The general structure of a function is the following:
def function_name(variable1, variable2,...):
block of commands
return result_values
As a first example we define a function that we will call double. This function will take
as input a variable x, and will return the product 2x.
1
def double(x):
2
y = 2 * x
3
return y
We could have omitted the definition of the variable y by just putting the operation
next to the return statement like:
1
def double(x):
2
return 2 * x
We can call this function now anywhere in our code just by using its name and a valid
argument x. The result can be stored in a new variable, or it can be printed on the screen:

Functions
27
1
x = 3
2
r = double(x)
3
print(double(x))
6
We now define a function that we call div10. This function will take as input a variable
x and will return the result of the division 10/x if x ̸= 0.
1
def div10(x):
2
if x!=0:
3
return 10/x
4
else:
5
print('Division impossible')
We can now define a sign function to return the sign of an input variable x
1
def sign(x):
2
if x > 0:
3
return +1
4
elif x < 0:
5
return -1
6
else:
7
return 0
Sometimes, we can give default value to one or all input variables. For example, if
we want to compute the maximum between two variables without using Python’s built-in
function max we define the function:
1
def max(x, y = 0):
2
if x >= y:
3
return x
4
else:
5
return y
Here, the default value for the variable y is 0 but we can change it by providing a different
input:
1
print( max( -1 ) )
2
print( max( 2, 5 ) )
3
print( max( x=2, y=5 ) )
4
a=2; b=5;
5
print( max( a, b ) )
0
5
5
5
Note that spaces between the different characters in the input don’t matter. The first
function call max(-1) assigns the value −1 to the variable x. Then it compares x = −1 with

28
Introduction to Python
the default value y = 0 since there is no input for y. The rest of the function calls assign
the value 2 to the variable x and the value 5 to the variable y with several different ways.
We note that for the first two calls of the function max, the only variables being used are
those included in the function. These are called local variables. For the last function calls
we define two additional variables a and b. These new variables, for example the variable a
and b are called global and are copied to the local functions variables x and y respectively.
The local function variables x and y will be erased after the function call. Even if we make
changes to the local variables this does not affect the actual global variables.
To see this we define a function that swaps the values between two variables. We employ
a new variable temp to store the value of x. Then we replace the value of x to the value of
y by setting x=y. At this stage, the value of x has been stored in the value of temp and the
value of y has been stored in x. Then we set y=temp to get the value of x.
1
def swap(x, y):
2
temp = x
3
x = y
4
y = temp
5
print('local variables: x = ',x , 'y = ', y)
6
return x, y
7
x = 2; y = 3;
8
swap(x, y)
9
print('global variables: x = ',x , 'y = ', y)
local variables: x =
3 y =
2
global variables: x =
2 y =
3
After the call of the function swap (line 8) we observe that the global variables x and
y are unchanged, while the function was expected to change their values. If in addition we
print the local variables x and y inside the function swap we will see that these variables
have been changed internally although externally they remain unchanged.
We can extend the scope of a local variable by using the commands global and
nonlocal. The global statement can be used to indicate that particular variables can
be used globally in the code even if they are defined in the scope of a function, while
the nonlocal statement indicates that particular variables can be extended outside of the
block of code that they are defined but they are bounded there. The command nonlocal
is meaningful when we define a function inside a function.

In Python, the variables defined inside a function are local variables. Local
variables cannot be seen (or used) outside the function.
Finally, we discuss an alternative way to define functions in one line of code using the
Python lambda statement. This can be useful for functions with simple formula. If we want
to define a function with formula f(x) this can be done by typing
f = lambda x: f(x)
Let’s say that we want to define a function with formula f(x) = x+1. This can be done
by typing f = lambda x : x + 1. To compute, for example the value f(1), we just type
f(1). This will return 2.

Classes
29
1
f = lambda x : x + 1
2
print(f(1))
2
The general description of a lambda function is the following
name of function = lambda arguments : formula
and is an alternative and fast way to introduce simple functions in our codes.
Recursive functions
A recursive function is a function that calls itself. One such example is the function that
returns the Fibonacci sequence of numbers
0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233, . . . .
Let’s denote F(n) the function that returns the n-th Fibonacci number. Then obviously
F(0) = 0 and F(1) = 1. The recursive function that returns all the rest of the Fibonacci
numbers is
F(n) = F(n −1) + F(n −2)
for
n = 2, 3, . . . .
Such a function can be implemented very easily with the following code.
1
def Fibonacci(n):
2
if ( n==0 ):
3
return 0
4
elif ( n==1 ):
5
return 1
6
else:
7
return Fibonacci(n-1)+Fibonacci(n-2)
8
# Print the first 14 Fibonacci numbers
9
for i in range(14):
10
print( Fibonacci(i) )
This will print the numbers 0, 1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144, 233.
Recursive function calls are usually inefficient and its use is not recommended unless
there are no alternatives.
1.6
Classes
Python is an object-oriented programming language. As such, it gives us the option to
create our own objects. These objects are called classes. Objects can have their own new
name. They can also have properties and methods. A new class can be defined as
class Name:
block of code

30
Introduction to Python
where the block of code describes the various properties of the object with name Name.
Let’s take this simple example. Assume that we want to create a new object to describe
vectors (x, y). Vectors are characterized by their x and y coordinates. Assume also that we
would like to record their magnitude (norm). For example we can have a vector a = (3, 1)
with magnitude ∥a∥=
√
32 + 12 =
√
10 and we want all these information to be stored in a
single variable. Similarly, we will need a second vector b = (2, 5). We will use a class object
with name vector. This new class will contain three new variables such as the variables x,
y and norm:
1
class vector:
2
x = 0.0
3
y = 0.0
4
norm = 0.0
With the previous code we have created a class with three data members (x, y and norm).
The three data members have all default value 0 (zero vector). If we want to consider our
first vector we type
1
a = vector()
2
a.x = 3.0
3
a.y = 1.0
4
a.norm = np.sqrt(10.0)
This will create the variable a with the data of our first vector. Then we can create
similarly a second variable with the second vector b:
1
b = vector()
2
b.x = 1.0
3
b.y = 5.0
4
b.norm = np.sqrt(26.0)
We can access the data of vector a by just printing its members:
1
print(b.x)
2
print(b.y)
3
print(b.norm)
1.0
5.0
5.0990195135927845
This was the simplest example of a class. Classes can also contain functions. The most
common function is the function
init . The function
init
initializes the class and
can be seen as a constructor. We can create a new vector using the function init that can
take as input all the members of the class. Our previous example can then be extended as
follows
1
class vector:
2
def __init__(self, a, b, c):
3
self.x = a
4
self.y = b
5
self.norm = c

Accessing Data Files
31
which means that we can now define a new vector such as
1
a = vector(3.0, 1.0, np.sqrt(10.0))
2
print(a.x)
3
print(a.y)
4
print(a.norm)
3.0
1.0
3.1622776601683795
There are other interesting properties of classes such as the inheritance but are out of
the scope of this book and we omit them.
1.7
Accessing Data Files
When we deal with large amount of data we usually need to store them in data files and
not in lists or arrays. This is due to memory limitations. Here we present how to access text
(txt) files with data. We can access a txt file by first identifying and opening the file using
the Python function open. This has the general function call
f = open(filename, mode)
where filename is a string with the name of the file, and mode is one of the following strings:
r when we want to open a file just for reading, w to open a file by deleting its contents and
writing new data, a to open the file by keeping existing data and append the file with
writing new data at the end it. One can formulate combinations of these modes using the
+ symbol. For example, we can use the mode r+ to read and write without creating a file.
The function open returns a file object f. This object is equipped with the methods read,
readline and write to read and write data. It also has the method close to close the file
and interrupt any access to it.
Reading the first 5 characters from a file we just write f.read(5). Text files have line
breaks indicated by the invisible character ‘\n’ at the end. If we want to read a whole line,
then we can use the command f.readline().
To write data into a text file is somewhat more complicated, especially if you want to
write numbers because the method write accepts as input only strings. So if you want to
store a variable, then you need to convert the variable into string using the command str.
You can use the operator + if you want to add additional text.
As a simple example, we open a file with name test.txt for writing the numbers 0 to
4. To write the new data we use the mode w and the method write as follows
1
f = open("test.txt", "w")
2
for i in range(5):
3
f.write(str(i)+'\n')
4
f.close()
Every time we want to write a new line we use the symbol ‘\n’ at the end of the input of
the command write. Otherwise, all input numbers will appear in one line. To write two
columns of data i and j, we can use the command f.write(stri(i)+’ ’+stri(j)) to
merge the numbers i, j with a space between them.

32
Introduction to Python
1.8
Further Reading
There are many books and online resources which aim at teaching Python, including the
official documentation of Python, NumPy, SciPy and MatPlotLib. We do not provide online
references as these may change, but we do encourage the interested reader to explore these
options. References [84, 87] consist of a complete introduction to programming in Python.
This list is not restricted to those references though and among the online books there is
a huge variety of books written for teaching Python. Books [88, 136] specialize in Python
for data science and they also contain information about Jupyter. The books [78, 79, 50]
serve as introductory textbooks to computational methods with Python and contain an
introduction to Python and its numerical analysis modules.

Chapter Highlights
 Python is an interpreter of computer code, it translates and executes our code
instantly.
 Python detects the type of a variable automatically. The basic types are
integer, float, string.
 The variable a = 1 is different from the variable b = 1.0 as the first is integer
and the second is float.
 Number of the form a × 10b can be written using scientific notation as a e b.
For example, we write 1.5e-4 instead of 1.5 × 10−4.
 The priority of operations in Python is the same as the priority of operations in
mathematics.
 The operator = indicates assignment and not equation. The command x=2
assigns the value 2 in the variable x.
 The indices in matrices and lists start from 0.
 There is no structure for matrices in Python and they can be represented as
lists of lists. In this book we will use NumPy arrays to represent matrices.
 The slice operator is used to extract multiple entries from lists and matrices.
For example, start:stop:step will return the values from start until stop-1
with step step.
 The same with the function range, which is formed as range(start, stop,
step) will return the values from start to stop-1 with increment step. If we
omit the step this implies that step = 1.
 For repetitive processes we use the commands for and while.
 We can control the execution of our code and take decisions using the
command if followed by a boolean expression.
 Blocks of codes that perform certain procedures can be included in functions.
 Functions usually accept some input that is stored in local variables and return
some output.
 Python has a wealth of functions for many applications. Libraries that contain
functions and other objects are called modules.
 Mathematical functions and constants can be accessed from the math module.
Later we will introduce more sophisticated modules for mathematical problems
such as the modules NumPy and SciPy.
 We will not use the math module but the modules NumPy and SciPy instead.
33

Exercises
1. Write a Python program to take as input the user’s first and last name and prints them
in reverse order with a space in between.
2. Write a Python program to compute the volume of a sphere with radius 4.
3. Write a Python program to count the appearance of number 4 in a given list.
4. Write a Python program to check whether a specified value is contained in a list of integer
values.
5. Write a Python program to compute an approximation of number π using the formula
π = 4 arctan(1) and floating point numbers. Then compute the difference between your
π and the pi of the math module.
6. Write a Python program to find out whether a given number (given by the user) is even
or odd, and print out an appropriate message.
7. Write a Python program to add three given integers. However, if two values are equal
sum will be zero.
8. Write a Python program to add two given integers. However, if the sum is between 15
and 20, it will return 20.
9. Write a Python program that will return true if two given integer values are equal or
their sum or difference is 5.
10. Write a Python program that will print all the even numbers from 1 to 100 and will
compute their sum.
11. Write a Python program to find those numbers which are divisible by 7 and multiple of
5, between 1500 and 2700 (both included).
12. Write a Python program to count the number of even and odd numbers in a list of
numbers.
13. Write a Python program to create the multiplication table (from 1 to 10) of a number.
14. Write a Python program to count the number of even and odd numbers from a series of
numbers. Try the list [1, 2, 3, 4, 5, 6, 7, 8, 9].
15. Write a Python program which takes two digits m (row) and n (column) as input and
generates a two-dimensional array (list of lists). The value of the entry of the i-th row
and j-th column of the array should be i · j.
16. Write a Python program to check if a triangle is equilateral, isosceles or scalene.
17. Write a Python function to compute the circumference and the area of a circle of a given
radius. The function must accept as input the radius of the circle and will return both
the circumference and the area.
18. Write a Python function that accepts an integer n as input and returns the value of
n + n2 + n3.
34

19. Write a Python function to compute the distance
d =
p
(x1 −x2)2 + (y1 −y2)2 ,
between the points (x1, y1) and (x2, y2). All numbers including the result must be floating
point numbers.
20. Write a Python function that will create a uniform grid of a given interval (a, b) using
N subintervals. The function must accept the limits a and b of the interval (a, b) and
the number of the subintervals N and will return a list with all the nodes of the uniform
grid.
21. Write a Python program to construct the following pattern, using nested for loops.
*
* *
* * *
* * * *
* * * * *
* * * *
* * *
* *
*
35

Taylor & Francis 
Taylor & Francis Group 
http://taylorandfrancis.com 

2
Matrices and Python
Without exaggeration, most of the methods we use to solve approximately problems in
physical sciences lead to linear algebra problems. Even approximations to solutions of non-
linear equations can be found solving linear equations. Before we start exploring numerical
methods, it will be useful to review some material from the field of linear algebra. We will
introduce the modules NumPy and SciPy and we will start performing scientific computa-
tions with them. We will learn how to draw simple graphs on the screen of our computer
using the module MatPlotLib. It is not by chance that we say “one picture is worth a thou-
sand words”. Graphs are used for debugging, to derive conclusions, make observations, and
also for presentation purposes. We start with a revision of matrices and their properties.
2.1
Review of Matrices
An n × m (n by m) matrix is a rectangular array of elements with n rows and m columns.
Not only are the values of the elements important, but their position in the array is as well.
We usually denote an n × m matrix by a capital bold letter such as A. The entries of the
matrix are denoted by the lowercase letter of the matrix with two indices to indicate the
number of row and the number of column (coordinates) where the entry is located in
the array. A general entry of a matrix A is denoted by aij, and corresponds to the entry
at the intersection of the i-th row and j-th column of matrix A. Schematically, this can be
seen as
A = [aij] =





a11
a12
· · ·
a1m
a21
a22
· · ·
a2m
...
...
...
an1
an2
· · ·
anm




.
If m = n then the matrix is called square matrix. A matrix with only one column is called
column vector and it is the n × 1 matrix
b =





b1
b2
...
bn




,
while a matrix with only one row is called row vector and it is the 1 × n matrix
b =
 b1, b2, . . . , bn

.
It is noted that −A denotes the matrix whose entries are −aij. Sometimes we write A ∈
Rn×m to indicate that A is n×m matrix with real coefficients. If the coefficients are allowed
to be complex, then we write A ∈Cn×m.
DOI: 10.1201/9781003287292-2
37

38
Matrices and Python
2.1.1
Matrix properties
Matrices are useful. The main reason is because we can perform operations with them, such
as addition, multiplication etc. Here we review basic matrix properties.
Matrix equality
Two matrices A and B are equal if they have the same number of rows and columns, say
n × m, and if aij = bij for each i = 1, 2, . . . , n and j = 1, 2, . . . , m.
Addition of matrices
If A and B are both n × m matrices, then the sum of A and B, denoted by A + B, is an
n × m matrix C whose entries are aij + bij, for each i = 1, 2, . . . , n and j = 1, 2, . . . , m.
C = A + B ⇐⇒cij = aij + bij .
This means that for each i and j, the entry cij = aij + bij. If
A =


1
2
0
3
2
2
0
3
−4


and B =


2
4
−1
0
−4
1
1
2
6

,
then
A + B =


1
2
0
3
2
2
0
3
−4

+


2
4
−1
0
−4
1
1
2
6

=


1 + 2
2 + 4
0 + (−1)
3 + 0
2 + (−4)
2 + 1
0 + 1
3 + 2
−4 + 6


=


3
6
−1
3
−2
3
1
5
2

.
Scalar multiplication
We can multiply a matrix with a scalar (number). If we have a number λ (complex or real),
the product λA is a new matrix B with entries bij = λaij for all indices i, j. We can
multiply the previous matrix A by 2 and this is
B = 2A = 2


1
2
0
3
2
2
0
3
−4

=


2 · 1
2 · 2
2 · 0
2 · 3
2 · 2
2 · 2
2 · 0
2 · 3
2 · (−4)

=


2
4
0
6
4
4
0
6
−8

.
Matrix multiplication
Multiplication between two matrices is not as simple as the multiplication between a scalar
and a matrix. An n × p matrix A = [aij] can be multiplied with a p × m matrix B = [bij].
Note that the number of columns of A must agree with the number of rows of B. Then the
product AB = [(ab)ij] is the n × m matrix with entries
(ab)ij =
p
X
k=1
aikbkj,
for
i = 1, 2, . . . , n
and
j = 1, 2, . . . , m .
Due to the restriction on the matrix dimensions, and also because of the definition of
matrix multiplication, the commutative property is not true and in general
AB ̸= BA .

Review of Matrices
39
For example, if A is a 2 × 2 matrix and B a 2 × 3 matrix
A =
1
2
3
4

and B =
5
6
7
8
9
10

,
then the product C = AB will be the 2 × 3 matrix
C =
1
2
3
4
 5
6
7
8
9
10

=
1 · 5 + 2 · 8
1 · 6 + 2 · 9
1 · 7 + 2 · 10
3 · 5 + 4 · 8
3 · 6 + 4 · 9
3 · 7 + 4 · 10

=
 5 + 16
6 + 18
7 + 20
15 + 32
18 + 36
21 + 40

=

21
24
27
47
54
61

.
We cannot perform the multiplication BA for these matrices because the dimensions do not
agree. This procedure is often called naive multiplication. Other more efficient algorithms
for matrix multiplication exist, some of which we discuss in Section 2.2.8.
Zero and identity matrix
The zero matrix 0 is a matrix with all entries zero. For example, the 3 × 3 zero matrix is
0 =


0
0
0
0
0
0
0
0
0

.
An identity matrix is a square n × n matrix with entries on its main (principal) diagonal
to be 1 while all the off-diagonal entries are zero, i.e. aij = 1 if i = j and aij = 0 if i ̸= j.
An identity matrix is usually denoted by I. For example, the 3 × 3 identity matrix is the
matrix
I =


1
0
0
0
1
0
0
0
1

.
The properties of matrix addition and scalar multiplication do not differ from those for
real numbers. We summarize the most basic properties below.
 A + B = B + A (commutative property)
 (A + B) + C = A + (B + C) (associative property)
 A + 0 = 0 + A = A (zero element)
 A + (−A) = −A + A = 0 (opposite matrices)
 λ(A + B) = λA + λB (distributive property)
 (λ + µ)A = λA + µA (distributive property)
 λ(µA) = (λµ)A
 1 A = A 1 = A
We will explore matrix multiplication later with some detail.

40
Matrices and Python
2.1.2
Special matrices
Matrices with special structure can lead to efficient algorithms. Matrices with many zero
entries are special matrices called sparse. We tend to work only with the nonzero entries of
sparse matrices to save memory and increase the speed of computations. Here we present
some important examples.
Diagonal matrices
A diagonal matrix D is a square matrix with dij = 0 if i ̸= j. For example, the identity
matrix is a diagonal matrix. Another example is the matrix
D =


1
0
0
0
2
0
0
0
3

.
Banded matrices
There are cases where the main diagonal of a matrix, along with several other diagonals are
not zero. Such matrices can be seen as a collection of non-zero diagonals and are usually
referred to as band (or banded) matrices. A band matrix A is a matrix where aij = 0 if
j < i −l or j > i + u for some l, u ≥0. The quantities u and l are called upper and
lower bandwidth; l is the number of non-zero diagonals below the main diagonal, and u
the number of non-zero diagonals above the main diagonal. The bandwidth of a matrix is
defined as the number p = l +u+1, which is the number of its non-zero diagonals including
the main diagonal.
According to the previous definition, an n × n full matrix can be treated as banded
matrix with bandwidth equal to its 2n −1 diagonals. To make the notion of band matrix
useful, we usually treat a matrix as band matrix if its bandwidth is reasonably small. For
example, a band matrix with l = 1, u = 2 and total bandwidth p = 4 can be written as








a11
a12
a13
0
0
0
a21
a22
a23
a24
0
0
0
a32
a33
a34
a35
0
0
0
a43
a44
a45
a46
0
0
0
a54
a55
a56
0
0
0
0
a65
a66








.
It should be noted that:
 a band matrix with l = u = 0 is a diagonal matrix
 a band matrix with l = u = 1 is a tridiagonal matrix
 a band matrix with l = u = 2 is a pentadiagonal matrix, and so on.
Such matrices occur in many circumstances, and for this reason, special algorithms and
storage schemes have been introduced.
Triangular matrices
Other special matrices are the following:
 Upper triangular n × n matrix U, where for each j = 1, 2, . . . , n the entries uij = 0, for
all i > j.

Review of Matrices
41
 Lower triangular n × n matrix L, where for each j = 1, 2, . . . , n the entries lij = 0, for
all i < j.
A 3 × 3 lower triangular matrix has the form


a11
0
0
a21
a22
0
a31
a32
a33

,
while a 3 × 3 upper triangular matrix has the form


a11
a12
a13
0
a22
a23
0
0
a33

.
Triangular matrices are useful because we don’t need to store their zero entries.
Symmetric matrices
Consider a matrix A = [aij]. We define its transpose matrix AT , the matrix which has rows
the columns of A. We can write AT = [aji]. For example, if
A =


1
2
3
4
5
6
7
8
9


then AT =


1
4
7
2
5
8
3
6
9

.
In general if
A = [aij] =





a11
a12
· · ·
a1m
a21
a22
· · ·
a2m
...
...
...
an1
an2
· · ·
anm




,
then
AT = [aji] =





a11
a21
· · ·
an1
a12
a22
· · ·
an2
...
...
...
a1m
a2m
· · ·
anm




.
The following properties involving the transpose of a matrix hold whenever the operation
is possible:
 (AT )T = A
 (A + B)T = AT + BT
 (AB)T = BT AT
A square matrix A is called symmetric if A = AT . This means that the rows of matrix A
are the same with its columns. Thus, square matrices can only be symmetric. For example,
A =


1
2
3
2
5
6
3
6
9


and AT =


1
2
3
2
5
6
3
6
9

.
Symmetric matrices are also convenient for matrix computations since we need to store only
their upper or lower triangular part.

42
Matrices and Python
In Python we can define and use matrices with the help of Python’s modules NumPy
and SciPy1. Both are libraries for general purpose scientific computations, [58, 138]. We
start with a brief introduction to NumPy.
2.2
The NumPy Module
We have already discussed the math module and the lists of lists to represent matrices. In
practice, though, we use other modules with more efficient data structures and functions. In
particular, we use the numpy and scipy modules for all our scientific computations. To plot
graphs we use the matplotlib module. We start with a description of the numpy module.
NumPy is a Python module that defines a number of data structures and functions
specialized for scientific computing. Like every other module, we need to import its functions
in the beginning of our code. This can be done with one of the following commands:
# Use only one of the following
import numpy
import numpy as np
from numpy import *
from numpy import function
If we use the first command import numpy then when we call a function, let’s say the
sine function sin evaluated for x, we need to write numpy.sin(x). We can avoid writing the
name of the module if we use the second command import numpy as np where we choose
to use the alias np instead of the word numpy. In this case, we need to write np.sin(x).
We use the third command from numpy import *, when we do not want to specify the
module in a function call as we import everything from the specific module. We do not
recommend the third statement as Python imports every single function and method from
NumPy. This can cause confusion. For example, if we import both scipy and numpy, then
we will be unsure which version of sine function we use since both have the same function.

We usually import the module numpy in the beginning of our code. Most com-
monly, NumPy is imported via the command import numpy as np. This is what
we will use in this book.
One of NumPy’s most important data structures is the n-dimensional array ndarray,
which we introduce immediately.
2.2.1
Matrices and arrays
Since most scientific computations require matrices and vectors (one-dimensional matrices)
NumPy provides with an efficient way of matrix representation. We can define n-dimensional
matrices using the NumPy data structure (function) ndarray. If the matrix is a usual two-
dimensional n × m matrix, then the data structure is just array. In this book we will use
only one- and two-dimensional matrices (with small exceptions) so we will use only the
function array.
1NumPy stands for “Numerical Python” while SciPy for “Scientific Python”.

The NumPy Module
43
A NumPy array is very similar to a list of lists and is actually constructed by a list of
lists. We can define the simple 3 × 2 matrix
A =


1
2
3
4
5
6


using the function np.array and appropriate list of lists as input. The output will be a new
array.
1
import numpy as np
2
3
A = np.array( [[1, 2], [3, 4], [5, 6]] )
4
print(A)
[[1 2]
[3 4]
[5 6]]
Each row has two entries (one for each column), which is why we typed the matrix as a
list with three entries, the three rows of the matrix. Although, the array A in the previous
example looks like a Python list of lists, it is not exactly the same. A NumPy array is a
proper matrix with proper multiplication while the plain Python list of lists is not.
Natural vs Python indices
Usually, the row and column indices in the representation A = [aij] take the values i =
1, 2, . . . and j = 1, 2, . . . . Using these indices, the entry a12 corresponds to the entry located
at the first row and second column of the previous matrix and is 2. We will call indices that
start from 1 and go up to n natural indices. In Python (and also in NumPy) indices start
from 0. The entry a12 of the previous matrix A can be accessed through the (0, 1) entry
of the array A by using the command A[0, 1]. These indices are called Python indices.
This distinction is important as numerical algorithms in the literature are usually presented
using natural indices.
1
print("a(1,2) = ", A[0,1])
a(1,2) =
2
To modify the value of the entry a22 into 10 we type A[1,1] = 10.
1
A[1,1]=10
2
print(A)
[[ 1
2]
[ 3 10]
[ 5
6]]

44
Matrices and Python
Similarly, we modify the (0, 1) entry of our array by adding 1 just performing the oper-
ation
1
A[0,1] = A[0,1] + 1
2
3
print(A)
[[1 3]
[3 4]
[5 6]]

Python indices start from 0 contrary to the natural indices that start from 1.
This means that if a natural index takes values up to N, then the corresponding
Python index will go up to N −1.
2.2.2
Slicing
The slice operator : can be used to extract parts of a NumPy array. We can extract the
first column (column with Python index 0) of the previous array just by setting the row of
A to be the operator “:” like A[:,0]:
1
A = np.array( [[1, 2], [3, 4], [5, 6]] )
2
print(A[:,0])
3
print(type(A[:,0]))
[1 3 5]
<class 'numpy.ndarray'>
In this example we also used the function type which returns the data structure (or object)
type of the input variable (in our case the variable A[:,0]). We observe that although the
result looks like a list, it was extracted as a NumPy array. Storing the first column into a
new vector a we get
1
a = A[:,0]
2
print(a)
3
print(type(a))
[1 3 5]
<class 'numpy.ndarray'>
In the same way, we can extract rows instead of columns. For example, to extract the
second row of A (row with Python index 1) we type
1
print(A[1,:])
[3 4]

The NumPy Module
45
We can even extract blocks of a matrix using the slice operator. This can be done by
specifying the indices we want to extract. Note that the slice operator “:” by itself means
that we extract everything, while in the form start:stop means that we want to extract the
entries with index from the start value until stop-1. For example, consider the following
3 × 3 matrix
B =


1
2
3
4
5
6
7
8
9

,
for which we extract the 2 × 2 block consisting of the first 2 columns and 2 rows
C =

1
2
4
5

,
using the following lines of code
1
B = np.array( [[1, 2, 3],
2
[4, 5, 6],
3
[7, 8, 9]] )
4
C = B[0:1, 0:1]
5
print(C)
[[1 2]
[4 5]]
The definition of the array B uses three lines and the command np.array has been
split. In Python we can split into multiple rows a piece of code that is included between
brackets (parentheses, square brackets etc.). Otherwise, we need to use the indication of
line break “\” at the end of each line.

Python is not inclusive language and as such the slice operator “:” when used
like start:stop means that the index takes the value start until stop-1. The
general use of the slice operator is start:stop:step where step is the index jump.
When the step is 1, then it can be omitted.
An alternative way to define matrices in Python is with the use of the NumPy class
matrix. matrix objects inherit all the properties of the ndarray and can be used exactly
like the arrays, but with some advantages. Namely, we can perform matrix multiplication
with matrix objects by using the * operator while we cannot with array objects. In this
book we will refrain from using matrix objects, though, and we will stick with arrays.
Vectors and arrays
So far we have considered vectors and matrices using two-dimensional NumPy arrays. For
example, we consider the vector a = (1, 2, 3) as a 1 × 3 matrix:
1
a = np.array( [[1, 2, 3]] )
2
print(a.shape)
(1, 3)

46
Matrices and Python
Note that the command a.shape returns the actual size of an array. On the other hand,
sometimes we need to use (or a function will return) vectors instead of arrays. Here we call
vectors (row or column) arrays with shape (n,) instead of (n,1) or (1,n). This can be
done by using single square brackets instead of double in the definition of an array:
1
a = np.array( [1, 2, 3] )
2
print(a.shape)
(3,)
We can retrieve the entries of a one-dimensional vector by using a single index:
1
print(a[1])
2
In the unfortunate event where the shape of an array creates a problem, especially when
it involves calls of functions that require single or double index for arrays, we can use the
command reshape. The new shape is provided as a single integer or a tuple in the arguments
of this function. The tuple can have −1 as dimension indicating that this has the dimension
inferred from the length of the original array:
1
b = a.reshape((1,3))
2
c = a.reshape((1,-1))
3
print('b=', b)
4
print(b.shape)
5
print('c=', c)
6
print(c.shape)
b= [[1 2 3]]
(1, 3)
c= [[1 2 3]]
(1, 3)
The reshape function practically doesn’t change the data buffer. Instead, it creates a
new view of the array.
2.2.3
Special matrices, methods and properties
We discussed special matrices in the first section of this chapter. Python offers functions
and methods (attributes) to increase the efficiency of our programs, especially when we deal
with special matrices. Here, we go over some special matrices, how to create them, and how
to retrieve basic properties of NumPy arrays in general.
The zero matrix
It is sometimes useful to create automatically an n × m matrix with all entries zero. This
can be done with the NumPy function zeros( (n,m) ) that takes input a tuple with the
matrix dimensions.

The NumPy Module
47
1
A = np.zeros( (3,4) )
2
print(A)
[[0. 0. 0. 0.]
[0. 0. 0. 0.]
[0. 0. 0. 0.]]
This matrix is called the 3 × 4 zero matrix (3 by 4 zero matrix). The dimensions of a
matrix can be retrieved using the function shape of a NumPy array, which returns a tuple
with the number of rows and columns of the array. Other useful methods that return useful
information are the attributes ndim and size. The attribute ndim returns the dimensionality
of the matrix, for example, whether the array is 2-dimensional or 3-dimensional array (we
don’t discuss 3-dimensional arrays in this book). The attribute size returns the number of
entries of the array.
1
print(np.shape(A))
2
print(A.ndim)
3
print(A.size)
(3, 4)
2
12
The identity matrix
Another special matrix of interest is the identity matrix, which is the square matrix (has
the same number of rows and columns) with all entries zero except for the entries of the
main diagonal, which are aii = 1 for all i.
This matrix can be created with the NumPy function eye(dimension). For example,
we create a 3 × 3 identity matrix by typing
1
I = np.eye(3)
2
print(I)
[[1. 0. 0.]
[0. 1. 0.]
[0. 0. 1.]]
NumPy can also create an n × m matrix full of ones easily with the function ones(
(n,m) ). The dimensions of the array are provided with a tuple.
1
A = np.ones( (3,2) )
2
print(A)
[[1. 1.]
[1. 1.]
[1. 1.]]

48
Matrices and Python
Functions like zeros, eye and ones are common array constructors that can reserve
memory for matrix computations. Note that all the arrays created in the previous examples
have real numbers as entries. We can specify the type of a matrix, for example whether the
values are integers, real or complex, by using the keyword dtype. For example, in order to
create a 3 × 3 identity matrix with integer entries we can write ones(3, dtype=int). (In
some versions of Python we can neglect the keyword dtype=.)
1
I = numpy.eye(3, dtype=int)
2
print(I)
[[1 0 0]
[0 1 0]
[0 0 1]]
Triangular matrices
A triangular matrix is a square matrix with zero all its entries above or below the main
diagonal. For example a 3 × 3 lower triangular matrix has the form


a11
0
0
a21
a22
0
a31
a32
a33

,
while an upper triangular matrix has the form


a11
a12
a13
0
a22
a23
0
0
a33

.
In order to extract the lower triangular part of a matrix A we can use the NumPy
function tril and for the upper triangular part the function triu. For example, if
A =


1
2
3
4
5
6
7
8
9

,
then we can extract the upper and lower triangular parts of this matrix by typing
1
A = np.array( [[1, 2, 3],
2
[4, 5, 6],
3
[7, 8, 9]] )
4
L = np.tril(A)
5
U = np.triu(A)
6
print('A = '); print(A)
7
print('L = '); print(L)
8
print('U = '); print(U)
A =
[[1 2 3]
[4 5 6]
[7 8 9]]
L =

The NumPy Module
49
[[1 0 0]
[4 5 0]
[7 8 9]]
U =
[[1 2 3]
[0 5 6]
[0 0 9]]
Extracting the upper and lower triangular parts is a very useful operation especially
when we deal with matrix factorizations as we shall see later.
Matrix transpose
For the same matrix A, it is easy to generate its transpose matrix AT using the NumPy
function transpose. For example, we can type
1
A = np.array( [[1, 2, 3],
2
[4, 5, 6],
3
[7, 8, 9]] )
4
B = np.transpose(A)
5
print(B)
[[1 4 7]
[2 5 8]
[3 6 9]]
We will discuss other special matrices, such as banded matrices later in this chapter.
2.2.4
Matrix assignment
Python provides efficient tools to perform matrix operations. A tricky subject is the matrix
assignment (i.e. how to make two matrices equal). If we set two NumPy arrays A and B
equal, B = A, then the two matrices become practically identical. When we say identical we
mean that when we modify one of them then we modify the other one as well. For example,
1
A = np.array( [[1, 2, 3],
2
[4, 5, 6],
3
[7, 8, 9]] )
4
B = A
5
A[0,0]=10
6
B[1,1]=20
7
print(A)
8
print(B)
[[10
2
3]
[ 4 20
6]
[ 7
8
9]]
[[10
2
3]
[ 4 20
6]
[ 7
8
9]]

50
Matrices and Python
In this example we see that by modifying A we modify B at the same time, and vice versa.
If we need to create a new unrelated copy of A, we need to use the attribute copy(). For
example, we need to type B=A.copy().
1
A = np.array( [[1, 2, 3],
2
[4, 5, 6],
3
[7, 8, 9]] )
4
B = A.copy()
5
A[0,0]=10
6
B[1,1]=20
7
print(A)
8
print(B)
[[10
2
3]
[ 4
5
6]
[ 7
8
9]]
[[ 1
2
3]
[ 4 20
6]
[ 7
8
9]]
Now we see that modifying entries of A we don’t modify the matrix B. Also modifying
the matrix B we leave A unchanged.

Setting two NumPy arrays to be equal A = B is not just an assignment of the
matrix B to A. Any changes applied to A will affect B and vice versa. To create an
unrelated copy of a NumPy array we can use the copy() attribute A = B.copy().
This will create an independent copy of B and changes in A will not affect B.
2.2.5
Matrix addition and scalar multiplication
Matrix addition can be performed between two or more NumPy arrays (matrices) in a very
simple and straightforward manner. If we have two matrices A and B, then we can find
their sum C = A + B just by typing C=A+B. If we want to add more than two matrices we
can still write D=A+B+C.
1
A = np.array( [[1, 2, 3],
2
[4, 5, 6],
3
[7, 8, 9]] )
4
B = np.array( [[9, 8, 7],
5
[6, 5, 4],
6
[3, 2, 1]] )
7
C = A + B
8
print(C)
[[10 10 10]
[10 10 10]
[10 10 10]]

The NumPy Module
51
The matrix C is a new matrix and is unrelated to A and B. In the same way we can
subtract, multiply a matrix with a scalar etc. For example, we can write
1
D = A - B
2
E = 2.0 * A
3
F = C / 2.0
4
G = A - 3.0*F
5
print(D)
6
print(E)
7
print(F)
8
print(G)
[[-8 -6 -4]
[-2
0
2]
[ 4
6
8]]
[[ 2.
4.
6.]
[ 8. 10. 12.]
[14. 16. 18.]]
[[5. 5. 5.]
[5. 5. 5.]
[5. 5. 5.]]
[[-14. -13. -12.]
[-11. -10.
-9.]
[ -8.
-7.
-6.]]
The command on line 1 performs the subtraction A −B, the command on line 2 performs
the scalar multiplication 2A, the command on line 3 the scalar multiplication 1/2 C, and
the command on line 4 performs the operation A −3F .
In order to practice our programming skills we can perform manually the addition of
two matrices by writing a simple function add which will take as input the matrices A
and B and will return the sum C = A + B. Apart from practicing and demonstrating the
definition of matrix addition, the reason for writing this simple function is to implement
practically the algorithm cij = aij + bij for all i, j (see Algorithm 2) in Python.
Algorithm 2 Matrix addition
for i = 1 : n do
for j = 1 : m do
C(i, j) = A(i, j) + B(i, j)
end for
end for
Remember that when we present algorithms in this book we usually use natural indices
instead of Pythonic ones. For example, when we write i = 1 : n this means that i takes all
values from 1 to n with step 1. The general format of this iteration will be i = start : stop :
step. In pseudo-language we denote matrix entries aij by A(i, j) to distinguish them from
Pythonic arrays and to comply with standard notation for example introduced in [48]. The
implementation of Algorithm 2 in Python can be the following:
1
def add(A,B):
2
(n, m) = np.shape(A)

52
Matrices and Python
3
C = np.empty((n,m))
4
for i in range(n):
5
for j in range(m):
6
C[i,j] = A[i,j] + B[i,j]
7
return C
In this function we first extract the shape of the n × m matrix A. Suppose that A and B
have the same shape. We reserve the memory for the matrix C using the function empty
of NumPy because otherwise we will receive an error message. As an exercise try to modify
the function to check that the shapes are the same. We go over the n rows and m columns
using a nested for loop and perform the addition element by element. Testing our new
function add using the previous matrices A and B we compute the exact same result with
the simple operation C=A+B:
1
A = numpy.array( [[1, 2, 3],
2
[4, 5, 6],
3
[7, 8, 9]] )
4
B = numpy.array( [[9, 8, 7],
5
[6, 5, 4],
6
[3, 2, 1]] )
7
C = add(A,B)
8
print(C)
[[10. 10. 10.]
[10. 10. 10.]
[10. 10. 10.]]
2.2.6
Vectorized algorithms
Modern scientific computing suggests that we avoid the use of for loops over arrays’ entries,
especially in interpreter programming languages such as Python. The reason is that every
time Python tries to access an entry of an array, it searches for the location of the entry
in the computer memory (RAM), and this is time-consuming. Algorithms that perform
operations with blocks of (or entire) matrices are faster than those performing element-wise
operations. Such algorithms are called vectorized algorithms or algorithms implemented in
vector format.
Algorithm 3 Matrix addition in vector format
for i = 1 : n do
C(i, :) = A(i, :) + B(i, :)
end for
Modifying Algorithm 2 so as to perform the same operations using entire columns, and
instead of adding entries we add columns in Algorithm 3, it turns out that the vectorized
algorithm is much faster. The implementation of Algorithm 3 into a new function addv
could be the following:
1
def addv(A,B):
2
(n, m) = np.shape(A)
3
C = np.empty((n,m))

The NumPy Module
53
4
for i in range(n):
5
C[i,:] = A[i,:] + B[i,:]
6
return C
We can test our function to see that is working as before.
1
A = np.array( [[1, 2, 3],
2
[4, 5, 6],
3
[7, 8, 9]] )
4
B = np.array( [[9, 8, 7],
5
[6, 5, 4],
6
[3, 2, 1]] )
7
C = addv(A,B)
8
print(C)
[[10. 10. 10.]
[10. 10. 10.]
[10. 10. 10.]]
In the next section we measure and compare the efficacy of the vectorized and naive addition
algorithms.
2.2.7
Performance of algorithms
We compare the performance of the previous methods to add matrices (NumPy addition,
add and addv functions) by measuring the time required separately by each method. To
measure the elapsed time we use the module time and the function time(). The first time we
call the function time() initiates a “stopwatch” and we store the initial time in a variable,
let’s say tstart. The second call of the function time() stops the “stopwatch”. We store
the final time in a different variable, let’s say tend. The elapsed time in seconds is then
tend-tstart.
Because 3 × 3 matrices are small enough to show any possible differences between vec-
torized and naive algorithms, we measure the times for adding large 100 × 100 matrices
generated randomly using the NymPy function rand of the submodule random. The com-
mand rand(n,m) of the module numpy.random generates an n×m random matrix with real
values in the interval [0, 1].
1
import time
2
A = np.random.rand(100,100)
3
B = np.random.rand(100,100)
4
t0 = time.time()
5
C = A+B
6
t1 = time.time()
7
print('Python', t0-t1, 'seconds')
8
t0 = time.time()
9
C = add(A,B)
10
t1 = time.time()
11
print('add', t0-t1, 'seconds')
12
t0 = time.time()
13
C = addv(A,B)

54
Matrices and Python
14
t1 = time.time()
15
print('addv', t0-t1, 'seconds')
Python 0.0021219253540039062 seconds
add 0.3293418884277344 seconds
addv 0.0029468536376953125 seconds
What we see is that the fastest method is the default NumPy array addition. The function
addv which implements the addition in vector format is faster than the naive addition
add. An alternative to the function time is the function time ns that returns the time in
nanoseconds. This can be useful for small problems or when accuracy of the elapsed time
is very important.
Matrix addition can be implemented using vector format in rows instead of columns.
The algorithm and its implementation are very similar to Algorithm 3 and the function
addv, and we leave it as an exercise for the reader.

For efficient implementation of matrix operations in Python it is better to use
vector format of algorithms using entire columns, rows or blocks instead of individual
entries of matrices. If there is a Python implementation of the same algorithm, then
this is usually the fastest implementation as it is precompiled, optimized, and maybe
written in other programming languages.
2.2.8
Matrix multiplication
Multiplication is perhaps the most difficult and expensive operation between matrices. Re-
call that we can multiply matrices A and B if the number of columns in A is the same with
the number of rows in B. For example, if A is n × m, then B must be m × p matrix. The
matrix product of A and B, denoted by AB, is an n × p matrix C whose entries cij are
cij =
m
X
k=1
aikbkj = ai1b1j + ai2b2j + · · · + aimbmj .
In order to compute the entry cij of the product matrix we use the i-th row of A and
the j-th column of B. These must have the same length. We multiply the entries aik with
the corresponding entries bkj for k = 1, 2, . . . , m, and then we add all these products to
form the entry cij. In other words, we compute the inner product of the i-th row of A
with the j-th column of B. See also the example on Section 2.1. We call this algorithm
of matrix multiplication the naive multiplication since this is perhaps the least efficient
implementation one can use. Practically, we need to implement a sum over the products
aikbkj. We have already discussed the algorithm for the computation of a sum in Algorithm
1. The algorithm for the naive matrix multiplication can be described in Algorithm 4. In
this algorithm the entry C(i, j) of matrix C plays the role of the variable sum in Algorithm
1. The loop over the variable k is the loop for the computation of the sum. The outer nested
loops over the variables i and j are for the computation of all entries cij.
We implement Algorithm 4 in a new function called mult and we test it using the
matrices
A =

1
2
3
4

and
B =

5
6
7
8
9
10

.

The NumPy Module
55
Algorithm 4 Naive matrix multiplication - ijk implementation
for i = 1 : n do
for j = 1 : p do
C(i, j) = 0
for k = 1 : m do
C(i, j) = C(i, j) + A(i, k) · B(k, j)
end for
end for
end for
In this function, we set the matrix C initially equal to zero to reserve memory for the result.
1
def mult(A,B):
2
(n, m) = np.shape(A)
3
(m, p) = np.shape(B)
4
C = np.zeros((n, p))
5
for i in range(n):
6
for j in range(p):
7
for k in range(m):
8
C[i,j] = C[i,j] + A[i,k]*B[k,j]
9
return C
10
11
A = np.array( [[1, 2],
12
[3, 4]] )
13
B = np.array( [[5, 6, 7],
14
[8, 9, 10]] )
15
C = mult(A,B)
16
print(C)
[[21. 24. 27.]
[47. 54. 61.]]
Algorithm 4 is the ijk implementation of matrix multiplication in the sense that the
nested loops are formed in the natural order (first for i, then for j and then for k). This
order is not important, though, and we can take the loops in any order we prefer. For
example, we can take the loop first for i, then for k and then for j. This observation leads
to a better implementation of matrix multiplication in Algorithm 5. Observe that the entry
Algorithm 5 Naive matrix multiplication - ikj implementation
for i = 1 : n do
for k = 1 : m do
tmp = A(i, k)
for j = 1 : p do
C(i, j) = C(i, j) + tmp · B(k, j)
end for
end for
end for
A(i, k) is always the same in the inner loop, which is a loop for j. Thus instead of letting
Python search in memory to find the entry A(i, k) for each j we bring this value in the cache

56
Matrices and Python
memory of the computer (which is closer to the processor and thus faster) by assigning it
to a variable tmp as it is demonstrated in Algorithm 5.
The ikj implementation of the naive matrix multiplication is very similar to the ijk
implementation and is presented here:
1
def mult(A,B):
2
(n, m) = np.shape(A)
3
(m, p) = np.shape(B)
4
C = np.zeros((n, p))
5
for i in range(n):
6
for k in range(m):
7
tmp = A[i,k]
8
for j in range(p):
9
C[i,j] = C[i,j] + tmp*B[k,j]
10
return C
Although the ikj implementation is somewhat faster than the ijk implementation of
the naive matrix multiplication, referring to the comments of the previous section, the
algorithm still uses individual entries of the matrices. In order to improve the naive matrix
multiplication we need to observe the deeper structure of this algorithm and think in terms
of rows and columns instead of entries.
To do so, we come back to the first comment about matrix multiplication. In order to
compute the entry cij of C we multiply all the entries of the i-th row of the matrix A with
the corresponding entries of the j-th column of the matrix B. This means that to perform
a matrix-matrix multiplication we multiply row with column vectors.
Consider matrix A written as a column vector with entries row vectors, and matrix B as
a row vector with entries column vectors. Denoting the rows of A by aT
i for i = 1, 2, . . . , n
and columns of B by bj for j = 1, 2, . . . , p, i.e.
aT
i =
 ai1
ai2
· · ·
aim

and bj =





b1j
b2j
...
bmj




,
then
A =











aT
1
−
aT
2
−
...
−
aT
n











and
B =
 b1
|
b2
|
· · ·
|
bn

.
In this format, the cij entry of the product C can be written as cij = aT
i · bj; that is,
cij =
 ai1
ai2
· · ·
aim

·





b1j
b2j
...
bmj





This is the usual inner product of vectors. This product practically replaces the sum over
the variable k. To use the vector format, we go back to Algorithm 4 and replace the loop

The NumPy Module
57
over the variable k with the product of the i-th row of A with the j-th column of B devising
Algorithm 6.
Algorithm 6 Matrix multiplication in vector form
for i = 1 : n do
for j = 1 : p do
C(i, j) = A(i, :) · B(:, j)
end for
end for
The inner product of two vectors is implemented in NumPy with the function inner
and so the Python implementation of the Algorithm 6 can be the following
1
def multv(A,B):
2
(n, m) = np.shape(A)
3
(m, p) = np.shape(B)
4
C = np.zeros((n, p))
5
for i in range(n):
6
for j in range(p):
7
C[i,j] = np.inner(A[i,:],B[:,j])
8
return C
9
10
A = np.array( [[1, 2],
11
[3, 4]] )
12
B = np.array( [[5, 6, 7],
13
[8, 9, 10]] )
14
C = multv(A,B)
15
print(C)
[[21. 24. 27.]
[47. 54. 61.]]
Now that we have discussed basic algorithms for matrix multiplication, we will examine
the NumPy implementation of matrix multiplication. The operator * with NumPy arrays
does not perform an actual matrix multiplication. It performs an element by element multi-
plication between two arrays. On the other hand, the operator @ performs the usual matrix
multiplication. For example,
1
A = np.array( [[1, 2],
2
[3, 4]] )
3
B = np.array( [[5, 6],
4
[7, 8]] )
5
C = A * B
6
print('C='); print(C)
7
D = A @ B
8
print('D='); print(D)
C=
[[ 5 12]
[21 32]]

58
Matrices and Python
D=
[[19 22]
[43 50]]
Matrix multiplication with NumPy arrays can be also performed using the NumPy
function dot. We can multiply two matrices A and B by typing np.dot(A,B). In our
previous example we can have:
1
A = np.array( [[1, 2],
2
[3, 4]] )
3
B = np.array( [[5, 6, 7],
4
[8, 9, 10]] )
5
C = np.dot(A,B)
6
print(C)
[[21 24 27]
[47 54 61]]
The operator * can be used for matrix multiplication only with NumPy matrices. NumPy
matrix is a data structure that inherits all the properties and methods from NumPy array
and perhaps are more convenient, but there is always a possibility of problematic function
calls. For this reason, we use mainly NumPy arrays instead.
1
A = np.matrix( [[1, 2],
2
[3, 4]] )
3
B = np.matrix( [[5, 6, 7],
4
[8, 9, 10]] )
5
C = A*B
6
print(C)
[[21 24 27]
[47 54 61]]
For the sake of completeness, we briefly state here some of the properties of matrix
multiplication. Let A be an n × m matrix, B an m × k matrix, C a k × p matrix, D be an
m × k matrix and λ real number, then the following properties hold true:
 A(BC) = (AB)C
 A(B + D) = AB + AD
 λ(AB) = (λA)B = A(λB)
 A · I = A · I = A
When the matrix products AB and BA are both defined, their results might be dif-
ferent. Sometimes they do not even have the same shape (see for example the previous
multiplication where the product BA is not defined at all).

The NumPy Module
59
Multiplying triangular matrices
Assume that A and B are two n × n upper triangular matrices. In such a case, aik = 0
when i > k and bkj = 0 when k > j. Recall that the multiplication AB is a matrix C with
cij =
m
X
k=1
aikbkj .
(2.1)
Thus, multiplying the two upper triangular matrices, the sum in formula (2.1) is not zero
only when i ≤k and k ≤j at the same time. These two conditions are simultaneously
satisfied only when i ≤j, and thus for i > j we get cij = 0, and the resulting matrix is
upper triangular. Similar, the product of two lower triangular matrices is a lower triangular
matrix. As we will see later, this property is very useful in matrix decomposition techniques.

The product of two upper triangular matrices is an upper triangular matrix,
and the product of two lower triangular matrices is a lower triangular matrix.
Powers
We saw that the result of the operator * used with NumPy arrays returns the element-by-
element product of A and B and not their actual matrix product unless the matrices are
defined as NumPy matrices. Because such operators are very useful, the module NumPy
provides with a similar function for raising the entries of matrices to a specified power.
This is the function power which is formulated as power(A,p) to compute the matrix with
entries ap
ij.
1
A = np.array( [[1, 2],
2
[3, 4]] )
3
B = np.power(A,2)
4
print(B)
[[ 1
4]
[ 9 16]]
To compute the actual power of a matrix Ap = A · A · · · A NumPy is equipped with
the additional function matrix power in the submodule linalg. We will make use of the
submodule linalg extensively in this book and we will use the standard alias npl instead
of numpy.linalg. So, in order to compute the power A2 of the previous matrix we can type
1
import numpy.linalg as npl
2
3
A = np.array( [[1, 2],
4
[3, 4]] )
5
B = npl.matrix_power(A,2)
6
print(B)
[[ 7 10]
[15 22]]
which is the same with the product A · A.

60
Matrices and Python
1
A = np.array( [[1, 2],
2
[3, 4]] )
3
B = np.dot(A,A)
4
print(B)
[[ 7 10]
[15 22]]
2.2.9
Inverse of a matrix
An n × n matrix A is said to be nonsingular (or invertible) if there exists an n × n matrix
denoted by A−1 such that A · A−1 = A−1 · A = I. The matrix A−1 is called the inverse
of A. A matrix that has no inverse is called singular (or noninvertible).
For any nonsingular n × n matrix A we have the following properties for the matrix
itself and its inverse:
 A−1 is unique
 A−1 is nonsingular and (A−1)−1 = A
 If B is also a nonsingular n × n matrix, then (AB)−1 = B−1A−1
 If A−1 exists, then (A−1)T = (AT )−1
Finding the inverse of a matrix A could give the solution to the linear system Ax = b,
since after multiplying with the matrix A−1 on both sides of the linear system, we obtain
A−1Ax = A−1b
Ix = A−1b
and thus the solution x = A−1b. Unfortunately, the computation of the inverse matrix is a
difficult and slow procedure. As we shall see later in this book, we can solve this problem
using efficient numerical algorithms. For the moment, we limit the discussion on Python’s
capabilities.
Computation of the inverse of a matrix A can be performed using the function
numpy.linalg.inv that takes as input a NumPy array and returns its inverse. For ex-
ample,
1
A = np.array( [[1, 2],
2
[3, 4]] )
3
Ainv = npl.inv(A)
4
print(Ainv)
[[-2.
1. ]
[ 1.5 -0.5]]
Line 3 in the previous code is responsible for the computation of the inverse of A. In order
to verify that the result is correct perform the multiplications A · A−1 and A−1 · A and
verify that the result is the identity matrix I. Do not forget that bugs in computer codes
are unavoidable!

The NumPy Module
61
Inverse of triangular matrix
As an application we explore the inverse of triangular matrices. Assume that L is an in-
vertible lower triangular matrix. Write
L−1 =
 y1
y2
· · ·
yn

,
where yi is n × 1 column vector for all i. Then we have that
LL−1 = I =
 e1
e2
· · ·
en

,
where ei are the n × 1 unit vectors with 1 on their i-th entry and 0 elsewhere. Then,
 e1
· · ·
en

= LL−1 = L
 y1
y2
· · ·
yn

=
 Ly1
Ly2
· · ·
Lyn

,
which implies that Lyi = ei, for all i = 1, 2, . . . , n. Note that ei has zeros above its i-th
row and because L is lower triangular, then yi has only zeros above the i-th row. Since
L−1 =
 y1
· · ·
yn

we deduce that L−1 is lower triangular too. To understand better
why this is the case, try a simple 3 × 3 matrix and assume L−1 is not a lower triangular
matrix.
This is also true for upper triangular matrices but we leave the proof for exercise.
2.2.10
Determinant of a matrix
The determinant of a matrix is a useful quantity for matrix computations. For example, it
is known that a matrix A is invertible if – and only if – its determinant is not zero. We
usually denote the determinant of a square matrix A by det(A), but it is common to use
also the notation |A|.
If A = [a] is a 1 × 1 matrix, then det(A) = a. The determinant of a 2 × 2 matrix is
det
a
b
c
d

= ad −bc .
If A is an n×n matrix with n > 2, then the determinant can be computed by choosing a
row or a column of A and computing the cofactors Aij = (−1)i+jMij, where Mij denotes
the determinant of the (n −1) × (n −1) submatrix of A that can be obtained by ignoring
the i-th row and j-th column of the original matrix A. Then the determinant of A can be
computed as
det(A) =
n
X
j=1
aijAij =
n
X
j=1
(−1)i+jaijMij ,
if we choose to analyze the determinant using the row i or by
det(A) =
n
X
i=1
aijAij =
n
X
i=1
(−1)i+jaijMij ,
if we use the column j.
For example, if
A =




1
4
2
3
0
1
4
4
−1
0
1
0
2
0
4
1



,

62
Matrices and Python
in order to compute the det(A), it is easier to use the second column because it has two
zeros:
det(A) = a12A12 + a22A22 + a32A32 + a42A42 = 4A12 + 1A22 .
Eliminating the first row and the second column and subsequently the second row and the
second column we obtain the analysis in cofactors:
det(A) = −4 · det


0
4
4
−1
1
0
2
4
1

+ det


1
2
3
−1
1
0
2
4
1


= −4

−4 det
−1
0
2
1

+ 4 det
−1
1
2
4

+

3 det
−1
1
2
4

+ det
 1
2
−1
1

= 80 −15 = 65 .
A determinant of a matrix can be computed approximately using the function det of
the module numpy.linalg. For example,
1
import numpy as np
2
from numpy.linalg import det
3
A = np.array( [[ 1, 4, 2, 3],
4
[ 0, 1, 4, 4],
5
[-1, 0, 1, 0],
6
[ 2, 0, 4, 1]] )
7
print(det(A))
64.99999999999999
where we verify our theoretical computations.
Unfortunately, the computation of a determinant is very slow, and the method discussed
before with the cofactors is perhaps the slowest algorithm for such problems. There are
efficient algorithms for the computation of determinants but we discuss them later in this
book. Next, we proceed with the numerical solution of systems of linear equations.
2.2.11
Linear systems
The most commonly encountered problem in scientific computations is the solution of sys-
tems of linear equations (simultaneous equations). A general system with n unknowns and
n linear equations can be written in the form
a11 x1 + a12 x2 + · · · + a1n xn = b1 ,
a21 x1 + a22 x2 + · · · + a2n xn = b2 ,
...
an1 x1 + an2 x2 + · · · + ann xn = bn .
In this notation, the coefficients aij, for i, j = 1, 2, . . . , n, and bj for j = 1, 2, . . . , n are all
given. On the other hand we need to determine the unknowns x1, x2, . . . , xn.

The NumPy Module
63
In computer systems we express a linear system using matrices and vectors. This can be
done by writing all the coefficients of the system into an n × n matrix
A =





a11
a12
· · ·
a1n
a21
a22
· · ·
a2n
...
...
...
an1
an2
· · ·
ann




,
and by expressing the right-hand side of the system as an n-dimensional column vector
b =





b1
b2
...
bn




.
Then the linear system can be written using matrix-vector product in the form
Ax = b ,
where x is the unknown vector with entries the unknowns x1, x2, . . . , xn. Usually we store
the coefficients of A and b in appropriate NumPy arrays, let’s say A and b. The easiest way
to solve a linear system of equations defined by the arrays A and b is by using the function
solve(A,b) of the module numpy.linalg. This function accepts as input the arrays A and
b and returns the solution of the system in an array x. For example, consider the following
system of linear equations
2x1
−x2
= 1
−x1
+3x2
−x3
= 1
−x2
+3x3
−x4
= 1
−x3
+2x4
= 1







,
which can be written in matrix form Ax = b with
A =




2
−1
0
0
−1
3
−1
0
0
−1
3
−1
0
0
−1
2




and
b =




1
1
1
1



.
It can be easily verified that the specific system has the exact solution x = (1, 1, 1, 1)T .
This is, for example, because each entry of the right hand side b is the sum of the entries
of the corresponding row of matrix A
bi =
n
X
j=1
aij,
i = 1, 2, . . . , n .
Moreover, the matrix A is tridiagonal and symmetric. It has even more nice properties that
we will explore in later chapters.
One of the first methods we learn in linear algebra courses in order to solve linear
systems is Cramer’s rule. Cramer’s rule is an explicit formula for the solution of a linear
system Ax = b. Let Ai be the matrix formed by replacing the i-th column of A by the
right-hand side vector b. Then the components xi of the solution x = (x1, x2, . . . , xn)T are
given by the formulas
xi = det(Ai)
det(A) ,
i = 1, 2, . . . , n .

64
Matrices and Python
It is clear that if det(A) = 0, then we cannot form any solution x, which is expected in the
case singular matrix A.
To solve numerically a system of linear equations Ax = b we use NumPy and its function
solve. For example, to solve the previous linear system we type
1
from numpy.linalg import solve
2
A = np.array( [[ 2.0, -1.0,
0.0 , 0.0],
3
[-1.0,
3.0, -1.0,
0.0],
4
[ 0.0, -1.0,
3.0, -1.0],
5
[ 0.0,
0.0 ,-1.0,
2.0]] )
6
b = np.ones((4,1))
7
x = solve(A,b)
8
print(x)
[[1.]
[1.]
[1.]
[1.]]
We were careful with the floating point numbers in the definition of our NumPy arrays
to avoid confusion with integer entries that can cause problems with division. This might
not be so important in this example, but in general using integers instead of floating point
numbers could cause serious errors in our codes. So, it is advisable to use always floating
point numbers when we expect the result to be real. Moreover, note that we could have
used b=np.ones(4) resulting to a row vector solution instead of column vector.
To solve a linear system in the following sections, we use the numpy.linalg.solve
function as black box. We explain the most popular numerical methods for solving linear
systems in Chapter 9.
2.2.12
Eigenvalues and eigenvectors
An eigenvalue λ of a square matrix A is a number (real or complex) that makes the matrix
A −λI singular (not invertible). This means that the eigenvalues of a matrix A are the
roots of the equation det(A−λI) = 0. The determinant det(A−λI) is always a polynomial
and it is called the characteristic polynomial.
Let us for example consider the matrix
A =

1
1
2
3

.
The eigenvalues of A are the roots of the equation
0 = det(A −λI) = det

0
1
−2
−3

−λ

1
0
0
1

= det

0
1
−2
−3

−

λ
0
0
λ

= det
−λ
1
−2
−3 −λ

= −λ(−3 −λ) + 2 = λ2 + 3λ + 2
= (λ + 1)(λ + 2) .
Thus, A has two eigenvalues λ1 = −1 and λ2 = −2.
For the eigenvalues of matrix A, the matrix A −λI is singular and the system of
equations (A −λI)x = 0 can have an infinite number of solutions. (Otherwise, the matrix

The NumPy Module
65
A −λI would have been invertible with unique solution the vector x = 0.) The non-trivial
solutions x ̸= 0 of (A −λI)x = 0 are called eigenvectors (or sometimes right eigenvectors).
Getting back to our examples, for the eigenvalue λ1 = −1, the corresponding eigenvectors
will satisfy the system
(A −λ1I)x = 0 .
To solve this system, we write it in the form
 1
1
−2
−2
 x1
x2

= 0 ,
and then write explicitly the simultaneous equations, which in this case are
x1 + x2 = 0 ,
−2x1 −2x2 = 0 .
We observe that the two equations are identical since we can multiply the first equation
with −2 to obtain the second one. For this reason, we have only one equation with two
unknowns, and thus infinite number of solutions. Here, we set x1 = k ∈R and so x2 = −k.
Thus, the solution is the vector
x = k
 1
−1

,
for any k ∈R. The eigenvector e1 associated with the eigenvalue λ1 is a vector for any
particular choice of the parameter k. For example, taking k = 1, the eigenvector can be
e1 =
 1
−1

.
The modulus of the eigenvector e1 is ∥e1∥=
p
12 + (−1)2 =
√
2 ≈1.4142. Taking k =
1/∥e1∥we obtain the eigenvector
e1 =

0.70710678
−0.4472136

.
Therefore, the new eigenvector e1 has modulus 1, and we say that is normalized. Similarly,
the eigenvector e2 associated with the eigenvalue λ2 is the vector
e2 =
 1
−2

,
which after normalization becomes
e2 =
−0.70710678
0.89442719

.
We can compute the eigenvalues and eigenvectors of a matrix A in Python using
the NumPy function numpy.linalg.eig. The general call of this function is eig(A) for
a NumPy array A and returns an array w with columns the eigenvalues of the matrix,
each one repeated according to its multiplicity, and an array v representing the matrix
V =
 e1
e2
· · ·
en

with columns ei the normalized eigenvectors (with modulus 1). So
the eigenvector i, which corresponds to the eigenvalue w[i] is the column v[:,i].
Back to our example, we can verify easily that our previous computations were all
correct:

66
Matrices and Python
1
from numpy.linalg import eig
2
A = np.array([[0, 1],[-2, -3]]) # Define the matrix
3
# Compute eigenvalues and eigenvectors
4
(w, v) = eig(A)
5
print('w='); print(w)
6
print('v='); print(v)
w=
[-1. -2.]
v=
[[ 0.70710678 -0.4472136 ]
[-0.70710678
0.89442719]]
Observe that the eigenvalues computed with the previous code are the same with the
theoretically estimated eigenvalues.
When we do not need the eigenvectors of A but only its eigenvalues, then we can
use the function numpy.linalg.eigvals by typing eigvals(A). The function eigvals
returns only an array w with the eigenvalues of A. Specialized functions for the computation
of eigenvalues and eigenvectors of symmetric (Hermitian) matrices are also provided by
the module numpy.linalg such as the numpy.linalg.eigh and numpy.linalg.eigvalsh
functions. Specialized algorithms for special matrices are preferred over generic alternatives
because of their advantages. More detailed description of eigenvalues and eigenvectors is
presented in Chapter 12.
2.3
The SciPy Module
The SciPy module is a library of functions, methods and data structures for scientific
computations that goes side-by-side with NumPy. We will learn how to use SciPy in op-
timization, integration, interpolation and other fields. In this chapter, we discuss some of
the capabilities of SciPy for linear algebra problems. The SciPy module for linear algebra
is the scipy.linalg. It has the same name with NumPy and practically contains all the
functions of NumPy and some extensions. It is based on Atlas, Lapack and Blas libraries,
which are all written in Fortran and C programming languages.
Since scipy.linalg is a superset of numpy.linalg we can use all the previous methods
we learned using SciPy. In addition, we will learn how SciPy can handle banded matrices
and other special matrices.
2.3.1
Systems with banded matrices
A banded system of equations is a linear system where its coefficients form a banded matrix.
For example, the system Ax = b (that we have already seen before) with matrices
A =




2
−1
0
0
−1
3
−1
0
0
−1
3
−1
0
0
−1
2




and
b =




1
1
1
1



,
is a banded system. In practical applications, the resulting linear systems are much bigger,
with thousands or millions of entries. This suggest issues with storage capacity. Because

The SciPy Module
67
these systems contain many zeros, we prefer to store only their non-zero entries. Banded
matrices can even be considered as sparse matrices if let’s say more than half of their entries
are zero. There are many ways to store a sparse matrix efficiently but here we discuss only
the case of a band storage.
Consider a 5×5 general banded matrix with four diagonals (with entries not necessarily
non-zero):
A =






a11
a12
0
0
0
a21
a22
a23
0
0
a31
a32
a33
a34
0
0
a42
a43
a44
a45
0
0
a53
a54
a55






.
This matrix has the following non-zero diagonals: the main diagonal, one diagonal above
the main diagonal, and two diagonals below the main diagonal. We want to store only these
diagonals (even if they contain some zeros). This can be done by storing the diagonals in
the rows of a new matrix Ab. Since here we have four diagonals, the matrix Ab must be
4 × 5 (4 rows for the 4 diagonals). The number of columns will be the same as A.
Ab =




∗
a12
a23
a34
a45
a11
a22
a33
a44
a55
a21
a32
a43
a54
∗
a31
a42
a53
∗
∗



.
The entries marked with ∗in the upper left and lower right corners of Ab need not be set,
or can be zero.
Let l denotes the number of non-zero diagonals below the main diagonal (lower band-
width) and u the number of non-zero diagonals above the main diagonal (upper bandwidth).
The total number of non-zero diagonals in A will be p = l + u + 1, since we need to take
into account the main diagonal as well. In our example we have l = 2 and u = 1, so p = 4
as the number of rows in Ab. Moreover, we have that
Ab(u + 1 + i −j, j) = A(i, j)
for
j = 1, . . . , n ,
max(1, j −u) ≤i ≤min(n, j + l) .
Note that the indices here are natural indices and not Pythonic indices. To implement such
an algorithm we need to modify the indices appropriately. Since we have two indices to vary
(i and j) we first start with j in range(n), which assigns to j the numbers from 0 to n-1
(1 less than the natural values).
Furthermore, we need to transform the i index into Python index. The natural values
will be from max(1, j −u) to min(n, j + l). Since j is a Python index, to make it natural
we need to add 1 and compute these two values in natural coordinates. So we compute
the maximum max(1, j −u) as M = max(1,j+1-u) where we take j+1 instead of j. We
compute the minimum min(n, j + l) as m = min(n,j+1+l), again taking j+1 instead of
j. In this way, we compute the maximum and minimum in natural coordinates. Then we
need to iterate over i. This can be done with the command for i in range(M-1,m): in
analogy of i = max(1, j −u), . . . , min(n, j + l). The reason why we take M-1 is because we
computed M in natural coordinates, so we need to transform it into Python index. We keep
m unchanged since the range function returns values up to m-1, and so there is no need to
change it. The Python code can be the following:
1
import numpy as np
2
A = np.array( [[ 11, 12,
0,
0,
0],
3
[ 21, 22, 23,
0,
0],

68
Matrices and Python
4
[ 31, 32, 33, 34,
0],
5
[
0, 42, 43, 44, 45],
6
[
0,
0, 53, 54, 55]] )
7
(n,n) = A.shape
# Get the dimensions of A
8
Ab = np.zeros((4,5))
# Reserve the appropriate space
9
# Define the lower and upper bandwidth
10
l = 2
11
u = 1
12
for j in range(n):
# Convert the matrix into banded format
13
M = max(1, j+1-u)
14
m = min(n, j+1+l)
15
for i in range(M-1,m):
16
Ab[u+i-j,j] = A[i,j]
17
print(Ab)
[[ 0. 12. 23. 34. 45.]
[11. 22. 33. 44. 55.]
[21. 32. 43. 54.
0.]
[31. 42. 53.
0.
0.]]
In order to make the correct assignment Ab(u + 1 + i −j, j) = A(i, j), we need to keep
in mind that the Python indices i and j differ from the natural indices i and j by 1. So, in
order to use the row index u+1+i−j in Python instead of using i we use i+1 and instead
of j we use j+1. This results in the natural (not Pythonic) index u+1+i+1-j-1. Then we
subtract 1 to convert the result into a Python index. So, we need to take u+1+i+1-j-1-1,
which is equal to u+i-j as a Python index for the computation of the index u + 1 + i −j.
While this is not the most efficient way to implement such transformation, it serves well
the purpose of understanding the transformation between natural and Python indices. In
our previous example we have (l,u)=(2,1).
Consider now the linear system Ax = b with the banded matrix A and right hand side
b = (23, 66, 130, 174, 162)T ,
which has the exact solution
x = (1, 1, 1, 1, 1)T .
To verify the validity of this statement observe that the entries of the right hand side b are
the sums of the entries of the corresponding rows of A. This can happen when you multiply
A with the vector x. We can solve such a system efficiently using the SciPy function solve -
banded from the module scipy.linalg. This function can be used in the form solve -
banded((l,u),Ab,b) where (l,u) are the lower and upper bandwidths, respectively, Ab
the matrix A stored in banded format, and b the right-hand side.
1
import numpy as np
2
from scipy.linalg import solve_banded
3
Ab = np.array( [[ 0, 12, 23, 34, 45],
4
[11, 22, 33, 44, 55],
5
[21, 32, 43, 54,
0],
6
[31, 42, 53,
0,
0]] )
7
b = np.array( [[23], [66], [130], [174], [162]] )
8
l = 2

The SciPy Module
69
9
u = 1
10
x = solve_banded((l,u), Ab, b)
11
print(x)
[[1.]
[1.]
[1.]
[1.]
[1.]]
A dense matrix (a matrix with mainly nonzero entries) can be considered as a band
matrix with l + u + 1 = n. This means that the methods described in this section can be
applied to dense matrices as well although it is not recommended.
2.3.2
Systems with positive definite, banded matrices
Positive definite matrices form another special category of matrices. An n × n matrix A is
positive definite if
xT A x > 0 ,
for all n-dimension vectors x ̸= 0. For example, consider the following matrix
A =


2
−1
0
−1
2
−1
0
−1
2

,
that may usually be seen in applications with differential equations. Obviously, the partic-
ular matrix A is symmetric. In order to prove that A is positive definite, take x ∈R3 any
three-dimensional vector. Then,
xT A x =
 x1
x2
x3



2
−1
0
−1
2
−1
0
−1
2




x1
x2
x3


=
 x1
x2
x3



2x1 −x2
−x1 + 2x2 −x3
−x2 + 2x3


= 2x2
1 −2x1x2 + 2x2
2 −2x2x3 + 2x2
3 .
Rearranging the terms in the last equality we have
xT A x = x2
1 + (x1 −x2)2 + (x2 −x3)2 + x2
3 ≥0 .
More precisely, xT A x > 0, unless x1 = x2 = x3 = 0. Therefore, the specific matrix A is
positive definite.
Remark 2.1. An n × n matrix A with xT A x ≥0 for all x ∈Rn is called positive
semidefinite.
Positive definite matrices have some favorable properties. In general, if A is a symmetric
n × n positive definite matrix, then:
 A is invertible,

70
Matrices and Python
 aii > 0, for each i = 1, 2, . . . , n,2

max
1≤k,j≤n |akj| ≤max
1≤i≤n |aii|,
 (aij)2<aiiajj, for each i ̸= j.
There are some theoretical tests to verify if an n×n symmetric matrix is positive definite
based on the following simple properties:
(i) a symmetric matrix A is positive definite if and only if all of its eigenvalues are positive,
(ii) a symmetric matrix A is positive definite if its leading principal minors are all positive.
Recall that eigenvalues λ are the roots of the characteristic polynomial det(A −λI) = 0,
while the k-th leading principal minor of a matrix is the determinant of its upper-left k × k
block.
Consider again the matrix of the previous example
A =


2
−1
0
−1
2
−1
0
−1
2

.
The leading principal minors are
det (A1) = det(2) = 2 > 0 ,
det (A2) = det

2
−1
−1
2

= 4 −1 = 3 > 0 ,
and
det (A3) = det


2
−1
0
−1
2
−1
0
−1
2

= 2 det
 2
−1
−1
2

−(−1) det
−1
−1
0
2

= 2(4 −1) + (−2 + 0) = 4 > 0 ,
and thus the matrix A is positive definite.
Although applications usually involve symmetric, positive definite matrices, the notion
of positive definiteness can be extended to non-symmetric matrices, but the situation is more
complicated. A non-symmetric, positive definite matrix can have complex eigenvalues. For
example, the matrix
A =
 1
1
−1
1

,
has eigenvalues 1±i. On the other hand, the eigenvalues of a non-symmetric, positive definite
matrix have always positive real part. This ensures the invertibility of the non-symmetric
matrix but the properties we mentioned previously are not valid anymore.
Testing whether a large matrix is positive definite or not can be very difficult. Luckily,
there are special numerical methods to solve linear systems efficiently that rely heavily on the
fact that the coefficient matrix is positive definite and symmetric. Failure of these methods
to solve a system imply that the matrix is not positive definite. Such methods can serve
as efficient testing tools for positive definite matrices. Perhaps the most commonly used
2To see that aii > 0 for positive definite matrices it suffices to take x the unit vector with xj = 1 for
j = i and xj = 0 for j ̸= i.

The SciPy Module
71
method for solving systems with positive definite and symmetric matrices is the Cholesky
method. We will analyze this method later. For the moment we consider a more general
method from SciPy.
The module scipy.linalg is equipped with the function solveh banded to solve sys-
tems with symmetric and positive definite matrices. The particular method is very efficient
for banded systems but we can use it even for dense (full) systems by taking the bandwidth
l+u+1 = n. The matrices we deal with here are symmetric with l = u, so we set p = l = u.
Since this function is designed for positive definite matrices that are symmetric, we
need only to store the upper or the lower triangular part of the matrix. By avoiding stor-
ing unnecessary data we can save space in computer memory. We will call this particular
symmetric storage scheme symmetric band storage scheme. We demonstrate the symmetric
band storage for the following symmetric matrix
A =






a11
a12
a13
a21
a22
a23
a24
a31
a32
a33
a34
a35
a42
a43
a44
a45
a53
a54
a55






,
with aij = aji. In this case, we store the lower triangular part of A. In particular, we store
the main diagonal and the nonzero diagonals bellow the main diagonal in the rows of a
matrix Ab such as
Ab =


a11
a22
a33
a44
a55
a21
a32
a43
a54
∗
a31
a42
a53
∗
∗

.
Then
Ab(1 + i −j, j) = A(i, j),
for
j = 1, . . . , n ,
j ≤i ≤min(n, j + p) .
In this notation ∗symbolizes empty or zero entry. This band storage generalizes the band
storage format we introduced in Section 2.3.1.
Similarly, if we decide to store the upper triangular part of A, we store the main diagonal
and all the nonzero diagonals above the main diagonal in the rows of a matrix Ab such that
Ab =


∗
∗
a13
a24
a35
∗
a12
a23
a34
a45
a11
a22
a33
a44
a55

,
and in this case
Ab(p + 1 + i −j, j) = A(i, j),
for
j = 1, . . . , n ,
max(1, j −p) ≤i ≤j .
In order to implement this matrix transformation, we work in a similar way to the
previous section. We consider only the case where we store the lower triangular part, and
leave the other case as an exercise. We take the matrix
A =






2
−1
0
0
0
−1
2
−1
0
0
0
−1
2
−1
0
0
0
−1
2
−1
0
0
0
−1
2






.

72
Matrices and Python
This matrix consists of three diagonals in total. The lower part has one nonzero diagonal
(p = 1) and taking into account the main diagonal, the matrix Ab will be a 2 × 5 matrix.
The implementation of this case can be in analogy to the band storage scheme as follows:
1
A = np.array( [[
2, -1,
0,
0,
0],
2
[ -1,
2, -1,
0,
0],
3
[
0, -1,
2, -1,
0],
4
[
0,
0, -1,
2, -1],
5
[
0,
0,
0, -1,
2]] )
6
(n,n) = A.shape
7
Ab = np.zeros((2,5))
8
p = 1
9
for j in range(n):
10
m = min(n, j+1+p)
11
for i in range(j,m):
12
Ab[i-j,j] = A[i,j]
13
print(Ab)
[[ 2.
2.
2.
2.
2.]
[-1. -1. -1. -1.
0.]]
Again, here we perform transformations from natural to Python indices as described in
Section 2.3.1. The minimum min(n, j+1+p) is the same as before, but here we changed
the l into p, and the index 1 + i −j is transformed to Python index by first transforming
the Python indices i, j into natural indices by taking i+1 and j+1 and then subtracting 1
from the result to transform the whole index into Python, like 1+(i+1)-(j+1)-1=i-j.
We consider now the linear system Ax = b with right-hand side b = (1, 0, 0, 0, 1)T that
has exact solution x = (1, 1, 1, 1, 1)T . If we use the upper triangular part of A, in order to
solve this system using the module scipy.linalg we need to call the function solveh -
banded(Ab, b). We have the option to use the lower triangular part (instead of the upper).
In that case we can use the same function but with the option lower=True, and so the call
of the function will be solveh banded(Ab, b, lower=True).
1
from scipy.linalg import solveh_banded
2
Ab = np.array( [[
2,
2,
2,
2,
2],
3
[ -1, -1, -1, -1,
0]] )
4
b = np.array( [[1], [0], [0], [0], [1]] )
5
x = solveh_banded(Ab, b, lower=True)
6
print(x)
[[1.]
[1.]
[1.]
[1.]
[1.]]
The function solveh banded works also for complex matrices (whose entries are com-
plex numbers). For complex matrices, the symmetric matrix is not exactly what we usually
need in applications. Instead of just symmetry we need the matrix to be equal to its con-
jugate transposed matrix, denoted by AH = AT . Such a matrix is called Hermitian. So, a
Hermitian matrix A is such that A = AH, or element-wise aij = ¯aji for all i, j, where the
bar denotes the complex conjugate of complex numbers.

The SciPy Module
73
2.3.3
Systems with other special matrices
The module scipy.linalg provides also functions to solve linear systems with other special
matrices. Here we mention some of these special cases.
Triangular systems
We frequently transform linear systems of equations into systems that have a lower or upper
triangular form. For example, when we perform Gaussian elimination we obtain a linear
system with upper triangular coefficient matrix. With SciPy we can solve such triangular
systems efficiently using the function solve triangular of scipy.linalg. The general
syntax of this function is the following:
solve_triangular(a,b,trans,lower,unit_diagonal,ovewrite_b,check_finite)
where
a:
Is a triangular matrix
b:
Is the right hand side of the system Ax = b
trans: Can be one of the values 0,1,2, with 0 for the solution of the system Ax = b, 1 for
the system AT x = b and 2 for the system AHx = b. (Optional with default value
trans=0)
lower: Is a boolean variable which indicates the use of the upper triangular part of matrix
A. If lower is True then the function uses the lower triangular part of matrix A.
(Optional with default value lower=False)
unit diagonal: Is a boolean variable. If it is True then the diagonal elements of A are
taken to be 1. (Optional with default value unit diagonal=False)
overwrite b: Is a boolean variable. If it is True then the function allows to overwrite data
in b. (Optional with default value overwrite b=False)
check finite: Is a boolean variable that allows to check if the input matrices contain only
finite numbers. (Optional with default values check finite=True)
Toeplitz systems
A Toeplitz matrix is a matrix in which each diagonal has the same value. For example,
A =






a
b
c
d
e
f
a
b
c
d
g
f
a
b
c
h
g
f
a
b
i
h
g
f
a






.
If we know the first row and first column of a Toeplitz matrix, then we can reconstruct the
full matrix. A Toeplitz system is a system with a Toeplitz matrix. The module scipy.linalg
contains the function solve toeplitz that allows us to solve such systems, and we only
need to provide the first column and/or the first row of the matrix. If we provide only the
first column, then the first row is assumed to be the complex conjugate of the first column
(r = cH, with c the first column and r the first row). The general call of the function
solve toeplitz is the following

74
Matrices and Python
solve_toeplitz(c_or_cr, b, check_finite)
where
c or cr: Can be the first column c or the tuple (c,r) that contains the first column and
the first row
b:
Is the right-hand side as usual
check finite: Is a boolean that allows to check if the input matrices contain only numbers
and not NaN or Infinity. (Optional with default values True)
Next we look at the special case of circulant systems.
Circulant systems
A circulant system is a system with a circulant matrix. A circulant matrix is a special
Toeplitz matrix where each row is a rotation of the previous row by one position to the
right. An example of circulant matrix is the following
A =






a
b
c
d
e
e
a
b
c
d
d
e
a
b
c
c
d
e
a
b
b
c
d
e
a






.
For circulant matrices we only need the first column (or row) since the rest of the columns
(or rows) are just simple periodic shifts of the first column (or row). In Python we can
generate a circulant matrix easily using the first column of the matrix and the function
scipy.linalg.circulant. For example, to construct the matrix
A =


2
3
4
4
2
3
3
4
2

,
we can simply type the following commands
1
from scipy.linalg import circulant
2
c = np.array([2, 4, 3])
3
A = circulant(c)
4
print(A)
[[2 3 4]
[4 2 3]
[3 4 2]]
We can solve circulant systems without generating the whole matrix but just using its
first column with the help of the scipy.linalg function
solve_circulant(c, b, singular, tol, caxis, baxis, outaxis)
where
c:
Is the first column c of the circulant matrix

Drawing Graphs with MatPlotLib
75
b:
Is the right hand side as usual
singular: Is a string variable that controls how a near singular circulant matrix should
be handled. If singular is "raise" and the circulant matrix is near singular, then
an error message will be returned. If singular is "lstsq", then the least squares
solution is returned. We will discuss the least squares later in this book. (Optional
with default value singular="raise")
tol: Is a real number, and serves as a tolerance related to the singularity of the matrix.
If the circulant matrix has an eigenvalue less than this tolerance, then the matrix is
consider to be near singular. (Optional with default value tol=None)
caxis: When c has dimension greater than 1, it is viewed as a collection of circulant vectors.
In this case, caxis is the axis of c that holds the vectors of circulant coefficients.
(Optional with default value caxis=-1)
baxis: When b has dimension greater than 1, it is viewed as a collection of vectors. In this
case, baxis is the axis of b that holds the right-hand side vectors. (Optional with
default value baxis=0)
outaxis: When c or b are multidimensional, the returned value is also multidimensional.
In this case, outaxis is the axis of the result that holds the solution vectors. (Optional
with default value outaxis=0)
The function solve circulant returns only the solution of the circulant system in an
array x. For example, if we want to solve the system with the matrix A generated using
c = (2, 4, 3)T and right-hand side b = (10, 10, 10)T we write
1
from scipy.linalg import solve_circulant
2
c = np.array([2, 4, 3])
3
b = np.array([10, 10, 10])
4
x = solve_circulant(c, b)
5
print(x)
[1, 1, 1]
2.4
Drawing Graphs with MatPlotLib
It is not by chance that we use the phrase one picture is worth a thousand words; and it
is very often where thousands of lines of code, theories, and many hours of hard work can
all be hidden behind a graph. The most common tool for sketching graphs (plotting) with
Python is the MatPlotLib package. In this section, we cover a few of the basic approaches
to plotting figures. If you are interested in learning more about MatPlotLib or to see how
you might create a particular plot check out the documentation of MatPlotLib for more
information.
2.4.1
Plotting one-dimensional arrays
When we want to sketch a graph we define an x-axis and a y-axis. In Python we can sketch
graphs in the same way but with the difference that the data cannot be continuous. Also the

76
Matrices and Python
graph will consist of pixels. The main idea is to use a set x values and the corresponding set
of y values. Python draws the points (x, y) on the screen in appropriate coordinate system.
Then it joins them with straight lines and create a “continuous line”. If we provide many
points (xi, yi) and the distances between them are small, then the impression given is that
of a smooth continuous graph.
We first explore the simplest case where we need to represent graphically a set of points
(xi, yi), for i = 1, 2, . . . , N. These points can be experimental data of some kind. To plot such
points on the screen we need to import the module matplotlib.pyplot, which provides
with the functions plot and show among other commands. The last function is used at
the end of our code when we are ready to plot the graph on the screen. The function plot
takes as input the arrays x and y to plot the points (xi, yi) and other arguments, such as
the color of the graph, the size etc. We usually import the module pyplot with the alias
textttplt. Here, we will explore only some simple plotting options, while the entire spectrum
of choices can be found online.
Let’s say that we want to plot the points (−1, −1), (0, 0) and (1, 1). We define our arrays
x, y, and plot the results using the following commands:
1
import matplotlib.pyplot as plt
2
3
x = np.array([-1, 0, 1])
4
y = x.copy()
5
plt.plot(x,y,'o')
6
plt.show()
−1.00 −0.75 −0.50 −0.25
0.00
0.25
0.50
0.75
1.00
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
In this code we use the command plot(x,y,’o’). The symbol o is used to depict the points
with filled circles. If we use the command plot(x,y), then the points will be connected with
straight line segments and the result will be a piecewise continuous line. It is also noted
that in order for Python to display the graph on the screen we need to type the command
show(). There are exceptions, though, in some environments where the show() command
is not required.
Instead of using circles, we can use triangles and we can also use a different color instead
of the default one. For example, if we want to use red triangles, then we can use the command
plot(x,y,’rv’), where the letter r specifies the red color and the letter v the triangular
shape. The most commonly used markers and colors are presented in Tables 2.1 and 2.2.
Assume now that we want to sketch the graph of a function f(x). Python, like any other
programming language, can plot only a finite set of points that can be joined with straight
lines to give an impression of a curved line. For the same reason computers can only handle
bounded intervals. We consider the interval [a, b]. We also consider a finite number of nodes
x0 < x1 < · · · < xN in [a, b]. After computing the values of the function f(x) at the points

Drawing Graphs with MatPlotLib
77
TABLE 2.1
Commonly used markers
Symbol
Marker
Symbol
Marker
.
point
s
square
o
circle
p
pentagon
v
triangle down
*
star
^
triangle up
x
x
<
triangle left
D
diamond
>
triangle right
d
thin diamond
TABLE 2.2
Commonly used colors
Symbol
Color
Symbol
Color
b
blue
m
magenta
g
green
y
yellow
r
red
k
black
c
cyan
w
white
xi, i.e. we compute the values yi = f(xi), we can plot the points (xi, f(xi)), for i = 0, . . . , N
on the screen using MatPlotLib as we did in the previous example.
In order to generate the points xi we create a uniform grid for the interval [a, b], using,
for example, the methodology presented in Section 1.4.2. In particular, we create N equidis-
tributed points xi in [a, b] such that xi+1 = xi + h with h = (b −a)/N. If the values a, b
and N are given then we can use the NumPy function linspace(a,b,N). This generates
a one-dimensional array of N nodes xi such that xi+1 = xi + h with h = (b −a)/(N −1).
For example, the command linspace(0.0, 1.0, 5) will create the one-dimension NumPy
array with 5 entries (0, 0.25, 0.5, 0.75, 1) and h = 0.25. Note that the grid will contain the
end-points a, b. If we need to exclude the end-points from our grid, we can use the optional
argument endpoint=False in the linspace function. If the values a, b and h are given,
then we can use the NumPy function arange(a,b+h,h) to generate similarly a uniform grid
in the interval [a, b] with stepsize h. Observe that in the function arange we use the right
endpoint increased by h. This is because the function arange is not inclusive and will not
include the value b in the grid unless we extend the endpoint by h.
1
a = 0.0
2
b = 1.0
3
N = 5 #Number of points
4
h = (b-a)/(N-1)
5
x = np.linspace( a, b, N )
6
print(x)
7
x = np.arange( a, b + h, h )
8
print(x)
[0.
0.25 0.5
0.75 1.
]
[0.
0.25 0.5
0.75 1.
]

78
Matrices and Python
After we generate the points xi, we need to compute the corresponding points f(xi) and
plot the points on the screen. The computation of the points f(xi) can be done instanta-
neously by typing f(x) with x being the array containing the mesh-points xi. To plot the
points on the screen we need to import the module matplotlib.pyplot which provides
with the functions plot and show.
In the following example, we plot the function f(x) = sin(x) in the interval [0, 2π] using
20 points.
1
x = np.linspace( 0, 2*np.pi, 20 )
2
y = np.sin(x)
3
plt.plot(x, y)
4
plt.xlabel('$x$')
5
plt.ylabel('$y$')
6
plt.title('$y=sin(x)$')
7
plt.xlim([0, 2*np.pi])
8
plt.ylim([-1.1, 1.1])
9
plt.show()
0
1
2
3
4
5
6
x
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
y
y = sin(x)
In this example we don’t specify the symbol of the points and Python connects all the points
with straight line segments forming on the screen the graph of a piecewise linear function.
We also specify the titles of the x and y axes using the functions xlabel and ylabel, the title
of the graph with the function title and the limits of the plotted axes using the function
xlim and ylim. Observe that in the title and for the axes labels we use the symbol $. By
doing this Python interprets the text with LATEX and can handle mathematical formulas
better. We also use the option rotation=0 for the label of the y-axis in order to align the
label vertically and not horizontally.
We can use different styles for lines such as broken or dotted line. A list with most
commonly used line styles is presented in Table 2.3.
TABLE 2.3
Commonly used line styles
Symbol
Line style
-
solid
--
dashed
-.
dash-dot
:
dotted

Drawing Graphs with MatPlotLib
79
We can also combine points with lines. For example, we can plot the points with cir-
cles connected with lines using the command plot(x,y,’o-’). In principle, we can use
combinations of color, symbol and line from Tables 2.1–2.3. In the following example, we
demonstrate the use of some different combinations of line styles to plot various plots in the
same graph.
1
x = np.linspace( 0, 2*np.pi, 20 )
2
y1 = np.sin(x)
3
y2 = np.cos(x)
4
y3 = np.sin(x/2.0)
5
plt.plot(x,y1,'o-',x,y2,'rd:',x,y3,'k-.')
6
plt.xlabel('x')
7
plt.ylabel('y', rotation = 0)
8
plt.title('y=sin(x)')
9
plt.xlim([0, 2*np.pi])
10
plt.ylim([-1.1, 1.1])
11
plt.show()
0
1
2
3
4
5
6
x
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
y
It should be noted that MatPlotLib has many more capabilities for sophisticated and com-
plicated graphs. Alternative to pyplot is the module pylab of MatPlotLib which results
in high quality figures, but we will stop here as we will not need anything more for the
purposes of this book.
We close this chapter with a summary of the most commonly used import abbreviations
for Python modules in this book (Table 2.4).
TABLE 2.4
Commonly used import abbreviations for various Python modules
Module
Abbreviation
Import
numpy
np
import numpy as np
numpy.linalg
npl
import numpy.linalg as npl
scipy
sp
import scipy as sp
scipy.linalg
spl
import scipy.linalg as spl
scipy.sparse
sps
import scipy.linalg as sps
scipy.optimize
spo
import scipy.optimize as spo
scipy.interpolate
spi
import scipy.interpolate as spi
matplotlib.pyplot
plt
import matplotlib.pyplot as plt

80
Matrices and Python
2.5
Further Reading
For a complete reference on matrices and linear algebra refer to the introductory books to
linear algebra written by Gilbert Strang [128, 129]. A modern introduction to linear algebra
and its tools to data science can be found in [130]. Another textbook that we suggest as
an introduction to linear algebra is the book by David Poole [105], which also includes
interesting applications of linear algebra in various fields. A complete and quite advanced
exploration in linear algebra can be found in [67]. The book [48] consist of a complete guide
for numerical methods in linear algebra. Specialized books on numerical algorithms for
linear algebra include the classics [48, 47]. As NumPy, SciPy and MatPlotLib are the core
modules for scientific computing and computational mathematics there are several books
that explain the use of these modules. The book [72] is an extensive introduction to these
modules for scientific computations. For a quick introduction to SciPy and NumPy we also
refer to [16].

Chapter Highlights
 We can represent matrices using NumPy arrays. A NumPy array is created
using the command numpy.array( [[1, 2], [3, 4]] ) where the matrix is
given as a list with entries the rows of the matrix. All entries and all rows are
separated with commas.
 The (i, j) entry of an array can be accessed by writing A[i,j].
 A mathematical index i that takes values i = 1, 2, . . . , n is called natural index,
while the index i that takes values i = 0, 1, . . . , n −1 is called Python index.
 Mathematical algorithms are usually given with natural indices and we need to
convert them to algorithms with Python indices.
 We can perform any matrix operation using the usual operators but the matrix
multiplication can be computed using the function dot or the operator @. The *
operator is used to perform entry by entry multiplication.
 We can access blocks of a matrix using the slice : operator. For example the
first row of a matrix let’s say A can be extracted as A[0,:].
 The identity matrix is numpy.eye(n). The zero n × m matrix is
numpy.zeros((n,m)).
 To create an unrelated copy B of a matrix A we use the function B=A.copy().
 The module numpy.linalg contains useful functions for the computation of
determinants, inverses, eigenvalues and eigenvectors, and for the solution of
linear systems.
 To raise each entry of a matrix in a power p we can use the NumPy function
power.
 To raise a matrix in a power of p we can use the function matrix power of the
module linalg of NumPy.
 We can solve a linear system Ax = b defined by the matrices A and b just using
the function solve of the module numpy.linalg simply by typing
x=solve(A,b). The last command returns the approximation of the solution x
in the NumPy array x.
 Banded matrices and other special matrices can be handled efficiently using the
module SciPy.
 We can measure the performance of our code using the function time of
module time.
 The product of lower(upper)-triangular matrices is lower(upper)-triangular
matrix.
 The inverse of a lower(upper)-triangular matrix is lower(upper)-triangular
matrix.
 We can plot graphs of functions using the module matplotlib.pyplot and the
function plot.
81

Exercises
1. Write a Pyhton program using NumPy to:
(a) Create a 3 × 3 matrix with values ranging from 1 to 9.
(b) Create a null vector of size 5 and update third entry to 1.
(c) Create a 7 × 7 array with 1 on the first and last rows and columns and 0 elsewhere.
(d) Create a 8 × 8 matrix and fill it with a checkerboard pattern.
(e) Create a 10 × 10 empty and a 10 × 10 full matrix.
(f) Find and return the number of entries of the last created array.
(g) Create an 8 × 8 array with ones on a diagonal and zeros elsewhere.
(h) Create a 5 × 5 matrix with row values ranging from 0 to 4.
(i) Compute the multiplication of two random 10 × 10 matrices.
(j) Compute the determinant of a random 100 × 100 square array.
2. Consider the matrix
A =


1
2
3
0
1
4
5
6
0

.
Using NumPy module
(a) Compute the determinant of A
(b) Compute the inverse matrix of A if it exists
(c) Work out the results without using computers
(d) Compute the eigenvalues and the respective eigenvectors
3. Consider the vectors x = (0.1, 1.3, −1.5, 0, 12.3). Try to write your own implementations
using for loops in Python (use Python functions only for question (v)) for the following
problems:
(a) Compute the sum s1 = P5
i=1 xi
(b) Compute the sum s2 = P5
i=1 xi
i
(c) Compute the maximum absolute value M = max{|xi|, i = 1, 2, . . . , 5}
(d) Compute the minimum absolute value m = min{|xi|, i = 1, 2, . . . , 5}
(e) Compare with the functions sum, max and min of NumPy.
4. Write the commands for each of the following operations:
(a) Create a row vector x of 5 equally spaced elements between 2 and 3.
(b) Add 1 to the second element
(c) Create a second row vector y of the same dimension with elements equal to the
successive even integers starting with 4.
(d) Create the matrix A, whose first row is equal to x, whose second row is a line of
ones, and whose third row is equal to y.
(e) Define a row vector z, whose elements are equal to the mean value of the columns
of A.
82

5. Create two matrices A and B:
A =
1
2
4
−1

and
B =
 4
−2
−6
3

(a) Compute the matrices C1 = A + B and C2 = A −B.
(b) Compute the matrix products D1 = A · B and D2 = B · A.
(c) Using element by element operations, compute the matrix F whose elements are
obtained as follows: Fij = Bij + AijB1/3
ij .
(d) Are A and B singular? If not, then compute their inverse.
(e) Compute the eigenvalues of B. Comment in light of your previous answer.
6. Create two column vectors x and y of 100 elements with random values between −10
and 10. To create a random vector of N random values between a and b you can use the
following command y = a + (b-a)*rand(N).
(a) Write a function mydot(x,y) computing the dot (inner) product between x and y.
(b) Compute the dot product using your function. Compare the results with the results
of the functions inner(x,y) and dot(x,y).
7. Consider two vector x = (x1, x2, . . . , xN)T and y = (y0, y1, . . . , yN)T .
(a) Write a Python function that returns the following double sum
s =
N
X
i=1
i
X
j=1
xiyj .
(b) Calculate the number of multiplications and additions required in the computation
for general N.
(c) Modify the previous formula appropriately to reduce the number of floating point
operations.
8. Consider the matrix
A =







1
2
3
· · ·
n −1
n
2
3
4
· · ·
n
1
3
4
5
· · ·
1
2
...
...
...
...
...
...
n
1
2
· · ·
n −2
n −1







.
(a) Show that
det(A) = (−1)n(n−1)/2 (n + 1)nn−1
2
.
(b) Write a Python function that generates matrix A for any value n.
(c) Verify the formula for its determinant using the Python function det(A).
9. Consider the linear system Ax = b with
A =




3
2
1
0
−3
−2
7
1
3
2
−1
5
0
1
2
3




and
b =




6
3
9
6



.
83

(a) Solve the system above using the NumPy function solve.
(b) Write a Python function that stores its matrix A in a banded form.
(c) Using the SciPy function solve banded solve the system Ax = b.
(d) Which of the two methods is faster?
10. Consider the linear system Ax = b with
A =






3
−1
0
0
−1
−1
3
−1
0
0
0
−1
3
−1
0
0
0
−1
3
−1
−1
0
0
−1
3






,
and
b =






1
1
1
1
1






.
Such systems occur in numerical integration of differential equations with periodic bound-
ary conditions. Taking advantage of their special structure we construct a fast and mem-
ory efficient numerical method for its numerical solution.
(a) Solve the system Ax = b using the NumPy functions solve and solve circulant.
(b) Consider the matrix ¯
A = [¯aij] with entries all the entries of the main band of A.
This means that ¯aij = aij for i = 1, . . . , 5 and j such that |i −j| ≤1 otherwise
¯aij = 0. Find vectors u, v ∈R5 such that ¯
A = A + uvT . Choose u and v such that
vT ¯
A−1u ̸= 1.
(c) Prove that the matrix A = ¯
A −uvT is invertible, with inverse
A−1 = ¯
A−1 + α( ¯
A−1u)(vT ¯
A−1) ,
where
α =
1
1 −vT ¯
A−1u .
(d) Implement the following algorithm to solve the linear system Ax = b
 Solve the banded linear system ¯
A¯x = b using the function solve banded
 Solve the banded linear system ¯
Ay = u using the function solve banded
 Solve the banded linear system ¯
AT z = v using the function solve banded
 Compute the numbers
α =
1
1 −vT y
and
β = zT b .
 Compute the solution x = ¯x + αβy.
 Verify that Ax −b ≈0.
(e) Compare the efficiency of all the methods you used.
[The previous algorithm is known as Sherman-Morrison-Woodbury algorithm. For more
information please see Chapter 9 and [73]]
11. Consider the matrix
A =


1
0
0
2
3
0
4
5
6

.
With the help of NumPy and SciPy:
84

(a) compute the determinant of A. Recall that the determinant of a triangular matrix
is the product of the main diagonal entries.
(b) compute the inverse matrix of A if it exists.
(c) solve the linear system Ax = b with b = (1, 5, 15)T .
12. Consider the 100 × 100 circulant matrix A with first row
c =
 3
−1
0
· · ·
0
−1
.
(a) Using SciPy generate the appropriate matrix A.
(b) Using NumPy functions compute the eigenvalues of A.
(c) Why A is invertible?
(d) Using Python generate appropriate right-hand side b such that the solution of the
corresponding system Ax = b has xi = 1 for i = 1, 2, . . . , 100.
(e) Solve the linear system Ax = b using the function solve circulant of SciPy.
(f) Solve the same linear system using the function solve of NumPy.
(g) Compare the efficiency of the two methods using the function time of the module
time, and explain what are the advantages of each method.
13. Consider the vector x = (0, 0.01, 0.02, . . . , 1)T with values from 0 to 1 with distance 0.01,
i.e. xi = xi−1 + 0.01.
(a) Write down the Python commands that will plot the graphs of the following func-
tions:
i. log(1 + √x),
ii. ex+x2,
iii. arccos(x),
iv.
q
1 + ln2(x),
v. tan2(x) −1.
(We denote by log the logarithm with base 10 and ln the one with base e.)
(b) Explain why in some cases we receive error messages. Try to correct the graphs so
that no error messages occur.
85

Taylor & Francis 
Taylor & Francis Group 
http://taylorandfrancis.com 

3
Scientific Computing
Most algorithms in this book aim to approximate solutions of mathematical problems. The
word approximation automatically infers to the introduction of errors. This is because any
approximate value may differ from the actual solution of the problem. Another source of
error is the finite precision arithmetic of computers. This is an unavoidable form of error
in scientific computing. In this chapter, we will focus on those errors that occur from the
representation of real numbers in a computer system.
3.1
Computer Arithmetic and Sources of Error
One example of approximation is the computation of π = 3.14 · · · , which is an irrational
number with infinite many digits. Such a number cannot be stored in the memory of a
computer due to its infinite size. But this is not the only case. There are many real numbers
missing from computer arithmetic, and this is one of the main sources of errors in computer
simulations. Because of these errors (in addition to other errors we will discuss later) the
approximations are not always very accurate.
A disturbing example of finite precision arithmetic is the result of the operation 1.1+0.1.
We all know that this is equal to 1.2. By typing in Python 1.1+0.1==1.2 we receive the
unexpected answer False.
1
1.1 + 0.1 == 1.2
False
The question arising from this example is what could the result of that operation be?
What we get in this case is not far away from being 1.2 but definitely is not exactly that.
1
print(1.1 + 0.1)
1.2000000000000002
Although this is unbelievable, in reality the computer is missing one of the exact numbers
involved in the previous computation or the operation itself can lead to small errors. If we
count the number of digits in this result, these are sixteen. This is not by chance. It is
true that we are usually confident to about the first 15 digits of the representation of a real
number of O(1) in a standard computer system (with the currently standard double precision
arithmetic). There are cases where better precision can be achieved but this requires more
resources. The errors occurring because of floating-point arithmetic are known as floating-
point errors. The first fact related to this problem is that there is no continuity in computer
number systems. This means that between floating-point numbers there are gaps.
DOI: 10.1201/9781003287292-3
87

88
Scientific Computing
Another source of error is the approximation of the original problem like the approx-
imation of mathematical formulas. Sometimes the approximation of a problem is called
discretization, especially if it involves transition from continuum to discrete level. These er-
rors are known to as discretization or truncation errors. For example, suppose that we want
to approximate the base of natural logarithms e. We know that the exponential function ex
can be expressed as the infinite sum (Taylor series1):
ex =
∞
X
k=0
xk
k! ,
where k! = 1 · 2 · 3 · · · k is the factorial of k. In order to compute an approximation of e we
take x = 1, and we approximate the infinite sum by the sum of the first five terms. Because
the rest of the terms become smaller and smaller as k grows, discarding them will lead to
a reasonably accurate approximation. After dropping the terms with k > 4 we obtain the
approximation
e ≈1 + 1 + 1
2 + 1
6 + 1
24 ≈2.7083 .
The actual value of e with 5 digits is 2.7183, and thus the discretization error has the
magnitude O(0.01). Taking more terms into account we can compute the same number
with better accuracy and thus smaller error.
We will discuss this kind of errors in later chapters for various numerical methods. In
this chapter, we focus only on floating-point errors due to the finite precision arithmetic
of computer systems. We continue with another example of floating-point error known as
catastrophic cancelation.

There are two main sources of error in scientific computing: Floating-point errors
that are introduced by the computer arithmetic; and discretization errors that occur
when we approximate the exact problem by a problem that computers can solve.
Both errors are important, but usually discretization errors are larger in magnitude
than floating-point errors.
3.1.1
Catastrophic cancelation
Catastrophic cancelation is the phenomenon where the subtraction of two almost equal
numbers leads to a large error due to the finite precision arithmetic. In order to demonstrate
this phenomenon we consider the function
f(x) = 1 −cos(x)
x2
.
This function is not defined at x = 0 but using de L’Hospital’s rule we obtain the limit
lim
x→0
1 −cos(x)
x2
= lim
x→0
(1 −cos(x))′
(x2)′
= lim
x→0
sin(x)
2x
= lim
x→0
cos(x)
2
= 1
2 .
Let’s pretend that we don’t know the answer and we want to use Python to estimate the
limit. In order to do so we consider the values x = xi = 10−i ≈0 for i = 5, . . . , 11, and we
record the corresponding values f(xi). According to the theoretical estimation of the limit,
these values should converge to 0.5.
1A revision of this subject can be found in the next chapter

Computer Arithmetic and Sources of Error
89
1
import numpy
2
f = lambda x:
(1 - numpy.cos(x))/x**2
3
x = numpy.linspace(-5, 5, 100)
4
y = f(x)
5
xi = (1.e-5, 1.e-6, 1.e-7, 1.e-8, 1.e-9, 1.e-10, 1.e-11)
6
for x in xi:
7
print('f(',x,')','=',f(x))
f( 1e-05 ) = 0.5000000413701854
f( 1e-06 ) = 0.5000444502911705
f( 1e-07 ) = 0.4996003610813205
f( 1e-08 ) = 0.0
f( 1e-09 ) = 0.0
f( 1e-10 ) = 0.0
f( 1e-11 ) = 0.0
The solution should have been
lim
x→0 f(x) = 0.5 .
In the beginning, the convergence looks correct, but after a while we get the impression that
the limit is 0. We cannot get an accurate computation due to the phenomenon of catas-
trophic cancelation (also known as loss of significance). The explanation is the following:
The difference 1 −cos(x) for very small values of x is very close to 0. This difference will
become very fast so small that the computer will approximate it by 0. The division of this
0 by the small value of x2 will result again in a 0 and not to the expected value of 0.5.
To understand the cause of this problem, first keep in mind that computers can only
store a finite number of decimal digits. Assume that our machine can store in its memory
only 10 floating-point digits (decimal digits) and consider the number:
a = 0.12345678901234567890 .
A floating-point representation of this number in our machine would be
b = 0.1234567890 .
Now perform the calculation
a −b = 0.00000000001234567890 .
However, on the 10-digit floating-point machine, this last number can be considered by the
machine as 0. This leads to loss of significance, because if we divide a −b by any small
number the result will be zero anyway.
3.1.2
The machine precision
Another unexpected phenomenon in computer arithmetic is the non-uniqueness of 0. We
all know that 0 + 1 = 1. In computer systems there are numbers other than 0 where their
addition with the number 1 will result in 1. The smallest number x such that x + 1 ̸= 1 is
called the machine epsilon (also known as unit roundoff ) and is denoted here by EPS. All
numbers x between 0 and EPS, (0 ≤x < EPS) satisfy x + 1 = 1.

90
Scientific Computing
In order to approximate the machine epsilon we usually start with x = 1 and we divide
continuously by 2 until we find x > 0 such that x + 1 = 1. Then we choose the number 2x
as an approximation of the machine epsilon. Algorithm 7 describes this process.
Algorithm 7 Computation of machine epsilon
Set x = 1.0
while x + 1.0 ̸= 1.0 do
x = x/2.0
end while
Set EPS = 2.0 · x
A Python implementation of the previous algorithm can be the following:
1
x = 1.0
2
while (1.0 + x != 1.0):
3
x = x / 2.0
4
EPS = 2.0*x
5
print('EPS = ', EPS)
6
print('x = ', x)
EPS =
2.220446049250313e-16
x =
1.1102230246251565e-16
Practically, we computed the number 1.1102230246251565e-16, so that if we add it to
1.0 we get 1.0. For this reason, when we work with scaled problems, we expect our results
to have an error of order 10−16 at least.
Between any two consecutive floating-point numbers there is always an empty gap (with-
out any floating-point number)2. The machine epsilon approximates the distance between
1.0 and the next floating point number. The gap between consecutive floating-point num-
bers is increasing with their magnitude. You can verify this by modifying the previous code
to find the number x that added to 1000 equals 1000. We computed x ≈6 × 10−14. This is
another reason why we use scaled equations in mathematical modeling. For example, it is
more convenient (and safer) to use scaled distances instead of meters for the equations of
planetary motion3.

When we perform operations with numbers close to 1.0, any other floating
point number less than the machine epsilon 2.22e-16 can be considered to be 0. This
introduces to our estimates a floating-point error of the order 10−16. The accuracy
is reduced even more when we use numbers larger than 1.0
3.2
Normalized Scientific Notation
Normalized scientific notation is the notation we use to represent real numbers in a computer
system. In normalized scientific notation the first digit is always zero while we shift the
2Contrary to computer arithmetic, in the real arithmetic there is always a real number between any two
real numbers.
3To minimize floating point errors we scale the equations of planetary motion using the distance between
the Sun and the Earth. This distance is 1 Astronomical Unit (AU).

Normalized Scientific Notation
91
decimal point. Appropriate powers of 10 are supplied so that all digits are located to the
right of the decimal point. For example, the number −123.456 is written in normalized
scientific notation as −0.123456 × 103.
More precisely, a number in scientific notation is written in the form
x = ±r × bn ,
where
b =
the base of the system (for example 10 or 2)
r =
the mantissa, a number in the range 1
b ≤r ≤1
n =
the exponent, an integer
Although most computer systems use b = 2 as the base of their number system, in the
examples used in this book we assume b = 10 for simplicity. We denote the lower and upper
limits of exponent n by L and U, respectively. That is L ≤n ≤U. When the exponent
n exceeds the limits, we say that an overflow (or underflow) occurs. The underflow region
practically is a gap between the largest negative floating-point number and the smallest
positive floating-point number.
As an example, consider a system with b = 10, L = −1, U = 2 and the numbers a = 12.3
and b = 34.5, then
a × b = 424.35 = 0.42435 × 103 .
In this case, the exponent is 3 > U and we have overflow. An overflowed number in various
programming languages is represented by NaN (or Inf). The abbreviation NaN stands for the
expression Not a Number while the Inf means infinity. On the other hand, an underflowed
number is represented by a signed zero, i.e. +0.0 or -0.0 depending on whether it is positive
or negative.
In finite precision arithmetic, the mantissa consists of a finite number of digits (known
as significant digits or figures). Therefore, we write the mantissa
r = 0.d1d2 · · · dt ,
where t is the precision. For example, consider the number x = 3.141596. In this scientific
notation we can write x = 0.3141596 × 101 with t = 7.
Modern computers usually use the binary system to store numbers in memory with
binary digits (bits) and are characterized by the following floating-point arithmetic systems:
 Single-precision floating-point arithmetic consists of 32-bit long numbers stored
in a bit pattern b1b2 · · · b9b10 · · · b32, which is interpreted as the real number
(−1)b1 × 2(b2b3···b9)2 × 2−127 × (1.b10b11 · · · b32)2 .
 Double-precision floating-point arithmetic consists of 64-bit long numbers stored
in a bit pattern b1b2 · · · b9b10 · · · b64, which is interpreted as the real number
(−1)b1 × 2(b2b3···b12)2 × 2−1023 × (1.b13b14 · · · b64)2 .
We prefer to use double-precision instead of single-precision floating-point arithmetic
because we can store decimal digits, and the results are more accurate; catastrophic cance-
lation can be avoided, while an overflow or an underflow is less likely to happen. Python by
default considers double-precision floating-point numbers unless otherwise specified.

92
Scientific Computing
3.2.1
Floats in Python
The module NumPy provides the function numpy.finfo which contains all the extreme
values for floating point numbers (double-precision numbers). For example, in my computer
system I got the following results:
1
from numpy import finfo
2
print(finfo(float))
Machine parameters for float64
---------------------------------------------------------------
precision =
15
resolution = 1.0000000000000001e-15
machep =
-52
eps =
2.2204460492503131e-16
negep =
-53
epsneg =
1.1102230246251565e-16
minexp =
-1022
tiny =
2.2250738585072014e-308
maxexp =
1024
max =
1.7976931348623157e+308
nexp =
11
min =
-max
---------------------------------------------------------------
This means the following:
 There is no unique 0.0 stored in our machine. The smallest floating point number is
tiny = 2.2250738585072014e-308.
 When we see in our display the number 0.0 or -0.0 this can be any number between
the -tiny and tiny numbers. This phenomenon is called underflow.
 If we compute any number greater than max = 1.7976931348623157e+308 or less than
min = -1.7976931348623157e+308 we say that we get an overflow and modern pro-
gramming languages represent these numbers by inf or -inf respectively.
3.3
Rounding and Chopping
If we enter in our code a number with more digits than the respective computer precision
t, then the computer will approximate this number with a new one. This new number
will be stored in the memory of the computer for future reference. There are two ways to
approximate a number. One is by chopping where only the first t digits are stored (if the
precision of the specific computer is t) ignoring the rest. The other one is by rounding where
the last digit dt is rounded up if dt+1 ≥b/2, while is rounded down if dt+1 < b/2, where
b is the base of the number system we use. This rounding process in the decimal system
happens when dt+1 ≥5 or dt+1 < 5.
We denote the stored number (the floating-point representation of a real number x) with
fl(x). For example, consider the number x = 3.141596 in a system with
b = 10, t = 3, L = −10, U = 10 .
In this particular case the result is fl(x) = 3.14 with both ways of representation. If we
take precision t = 5, then using rounding gives
fl(x) = 3.1416 ,

Rounding and Chopping
93
while using chopping results in
fl(x) = 3.1415 .
This is related with the floating-point errors that we have discussed so far. In order to
quantify errors in computations we introduce specific formulas.
3.3.1
Absolute and relative errors
Whenever approximations occur there is an implied error in the computations. In order to
estimate the errors in the various computations we introduce the notion of absolute and
relative error defined by the following formulas
Absolute Error = |x −fl(x)| ,
and
Relative Error = |x −fl(x)|
|x|
,
x ̸= 0 ,
where fl(x) stands for the floating point approximation of x. The absolute error depends on
the magnitude of x. This means that larger numbers will have different error than smaller
numbers, while the relative error is scaled and it does not depend on the magnitude.
For example, suppose that the numbers x = 0.51, y = 1.73 have the floating-point
representations fl(x) = 0.50 and fl(y) = 1.72, respectively. The absolute error is
|x −fl(x)| = |y −fl(y)| = 0.01 ,
while the relative errors are
|x −fl(x)|
|x|
= 0.0196
and
|y −fl(y)|
|y|
= 0.0058 .
This shows that y can be represented more accurately in the floating-point representation
compared to x.
In general, given a true value of a quantity f and an approximation ¯f we define the
absolute error as
e = |f −¯f| ,
and the relative error as
r = e
|f| = |f −¯f|
|f|
.
The relative error is the absolute error scaled by the exact quantity f. In computations
where the actual quantity is unknown, we can scale by the numerical approximation if we
are sure that the latter is accurate enough.

The most common error representations between an actual quantity and its
approximation are the absolute and relative errors. The relative error is the absolute
error scaled by the exact value (or sometimes by the numerical approximation) and
it is usually more useful compared to the absolute error.

94
Scientific Computing
3.3.2
Loss of significance (again)
The subtraction between two numbers that are close together (or between very large num-
bers) can lead to large errors. Consider for example a computer with numerical base b = 10
and with five-digit mantissa. Also consider the numbers
x = 0.543616731
and
y = 0.543504564 ,
and their difference
x −y = 0.000112167 .
Because of the precision t = 5 using chopping we have
fl(x) = 0.54361
and
fl(y) = 0.54350 ,
and
fl(x) −fl(y) = 0.00011 .
The relative error is then

x −y −(fl(x) −fl(y))
x −y
 =

0.000112167 −0.00011
0.000112167
 ≈2 × 10−2 .
This error is very large, especially if we consider that the numbers have 3 digits correct.
This unexpected reduction of the significant digits in a computation is known as loss of
significance.
3.3.3
Algorithms and stability
In mathematics and computer science an algorithm is a step-by-step procedure for calcu-
lations. More precisely, an algorithm is an effective method expressed as a finite list of
well-defined instructions. Algorithms are characterized as stable or unstable. An algorithm
is stable if small changes in the initial data lead to small changes in the final results. If
an algorithm is not stable, then it is called unstable. Some algorithms are stable only for
certain choices of data and are called conditionally stable.
Floating-point arithmetic will always induce small errors in computations and in data,
thus stable algorithms are preferred. An unstable algorithm with these small errors will lead
to untrustworthy results.
In the example of Section 3.1.1 we attempted to compute the limit
lim
x→0
1 −cos(x)
x2
,
and we observed that the computation of the function f(x) for x close to 0 lead to wrong
results. The problem was caused by the subtraction of two almost equal numbers. Specifi-
cally, the difference 1 −cos(x) in the formula of f(x) for tiny values of x was approximated
by 0.
We can overcome this difficulty by modifying the formula of the function to avoid the
subtraction between 1 and cos(x). For example, using some trigonometry we can write
f(x) = 1 −cos(x)
x2
= (1 −cos(x))(1 + cos(x))
x2(1 + cos(x))
=
1 −cos2(x)
x2(1 + cos(x)) =
sin2(x)
x2(1 + cos(x)) .
The new formula for the function f(x) can be used in our previous Python code to obtain
a more accurate result.

Rounding and Chopping
95
1
f = lambda x:
np.sin(x)**2/(x**2*(1+np.cos(x)))
2
x = np.linspace(-5, 5, 100)
3
y = f(x)
4
xi = (1.e-5, 1.e-6, 1.e-7, 1.e-8, 1.e-9, 1.e-10,1.e-11)
5
for x in xi:
6
print('f(',x,')','=',f(x))
f( 1e-05 ) = 0.4999999999958333
f( 1e-06 ) = 0.4999999999999583
f( 1e-07 ) = 0.4999999999999995
f( 1e-08 ) = 0.5
f( 1e-09 ) = 0.5
f( 1e-10 ) = 0.5
f( 1e-11 ) = 0.5
The technique we used to make the previous computation stable can be used also when-
ever we encounter differences of almost equal numbers. For example, if x > y ≥1 and
we want to compute the difference √x −√y accurately, especially when we suspect that
x ≈y ≈1, we can compute the fraction
√x −√y =
x −y
√x + √y ,
which can be more stable. This is because x −y is larger than √x −√y. We will use such
a trick in the following section to find stable approximations of π.
3.3.4
Approximations of π
We have seen that we can have accurate approximations of π by using the NumPy number
pi or the formula π = 4 arctan(1). In this section we present two different algorithms
for the approximation of π one of which is Archimedes algorithm from his work ‘On the
Measurement of a Circle’. Archimedes algorithm is based on the approximation of a unit
circle by inscribed regular polygons. Recall, that a unit circle has radius 1 and circumference
2π.
First, consider a regular polygon with 2n sides inscribed in a unit circle. Each side of
this polygon has length s = 2 sin(ϕn/2), where ϕn = π/2n−1 is the central angle. This can
be seen in Figure 3.1. The circumference of such polygon is Cn = 2ns or more precisely
Cn = 2n+1 sin π
2n ,
n = 1, 2, . . . .
We set yn = Cn/2 to be half of the polygon circumference. This is
yn = 2n sin π
2n ,
n = 1, 2, . . . .
(3.1)
Obviously, y1 = 2. We also note that
yn+1 = 2n+1 sin
π
2n+1 .
Using the trigonometric identity sin x = [(1 −cos(2x))/2]1/2, we get
yn+1 = 2n+1
1 −cos(π/2n)
2
1/2
.

96
Scientific Computing
FIGURE 3.1
Approximation of a unit circle by regular polygons.
Using the identity sin2 x + cos2 x = 1 into the last identity leads to the formula
yn+1 = 2n+1

1 −
q
1 −sin2(π/2n)
2


1/2
.
Moreover, using the formula (3.1) for yn we obtain
yn+1 = 2n+1
r
1
2

1 −
p
1 −(2−nyn)2

,
which accompanied by the initial approximation y1 = 2 forms a recursive sequence of
approximations of π. This sequence approximates π since yn is half of the perimeter of the
polygon. The recursive sequence can be implemented in an algorithm such as Algorithm 8.
Algorithm 8 Unstable algorithm for the approximation of π
Set y = 2.0
for n = 1, 2, . . . , 30 do
Compute
y = 2n+1
r
1
2

1 −
p
1 −(2−ny)2

end for
Return y as an approximation of π
The recursive sequence contains two subtractions indicating instabilities. Implementing
Algorithm 8 our fears become reality after the 27th iteration.

Rounding and Chopping
97
1
yn = 2.0
2
for n in range(1,31):
3
yn=2.0**(n+1) * np.sqrt(0.5*(1.0-np.sqrt(1.0-(2.0**(-n)*yn)**2)))
4
print(n, yn)
1 2.8284271247461903
2 3.0614674589207187
3 3.121445152258053
4 3.1365484905459406
5 3.140331156954739
6 3.141277250932757
7 3.1415138011441455
8 3.1415729403678827
9 3.141587725279961
10 3.141591421504635
11 3.141592345611077
12 3.1415925765450043
13 3.1415926334632482
14 3.141592654807589
15 3.1415926453212153
16 3.1415926073757197
17 3.1415929109396727
18 3.141594125195191
19 3.1415965537048196
20 3.1415965537048196
21 3.1416742650217575
22 3.1418296818892015
23 3.142451272494134
24 3.142451272494134
25 3.1622776601683795
26 3.1622776601683795
27 3.4641016151377544
28 4.0
29 0.0
30 0.0
The sequence seems to approximate π up to y24. Then the computation becomes unstable
and returns 0 due to loss of significance.
To avoid the subtraction of almost equal numbers a, b ≥1 we can use the identity
(a −b)(a + b) = a2 −b2 with a = 1 and b =
p
1 −(2−nyn)2 to obtain
1 −
p
1 −(2−nyn)2 =
2−2ny2
n
1 +
p
1 −(2−nyn)2 .
This transforms the recursive sequence to
yn+1 =
s
2
1 +
p
1 −(2−nyn)2 yn ,
where again y1 = 2. Implementing the new recursive iteration we obtain a stable algorithm.

98
Scientific Computing
1
import numpy as np
2
yn = 2.0
3
for n in range(1,31):
4
yn=np.sqrt(2.0/(1.0+np.sqrt(1.0-(2.0**(-n)*yn)**2)))*yn
5
print(n, yn)
1 2.8284271247461903
2 3.0614674589207187
3 3.121445152258053
4 3.1365484905459398
5 3.1403311569547534
6 3.1412772509327733
7 3.1415138011443013
8 3.1415729403670913
9 3.1415877252771596
10 3.1415914215111997
11 3.1415923455701176
12 3.1415925765848725
13 3.141592634338563
14 3.141592648776985
15 3.1415926523865907
16 3.1415926532889924
17 3.141592653514593
18 3.141592653570993
19 3.1415926535850933
20 3.141592653588618
21 3.141592653589499
22 3.1415926535897194
23 3.1415926535897745
24 3.1415926535897882
25 3.141592653589792
26 3.1415926535897927
27 3.1415926535897927
28 3.1415926535897927
29 3.1415926535897927
30 3.1415926535897927
This new approximation converges to π and appears to be stable. The original
Archimedes’ algorithm for the approximation of π is stable and very elegant as well. Archi-
medes’ algorithm consists of the following steps:
x0 =
√
3,
y0 = 2 ,
xn+1 = xn + yn,
yn+1 =
p
1 + (xn+1)2
for n = 0, 1, · · · ,
where yn converges to π as n →∞. Algorithm 9 presents Archimedes’ algorithm.
In the previous implementations we computed 30 iterations. On the other hand, we
can use different stopping criteria. If convergence is our goal, then we can perform as many
iterations as it is required until the difference between two results is very small. The distance
between the result yn+1 and yn can be computed via the difference en = |yn+1 −yn|.
For a convergent sequence yn this difference becomes small as n increases. To stop the
execution of a code we choose a tolerance TOL (usually something like 10−10 depending

Further Reading
99
Algorithm 9 Archimedes algorithm for the approximation of π
Set x =
√
3 and y = 2.0
for n = 1, . . . , 30 do
Compute x = x + y and y =
√
1 + x2
end for
Return y as an approximation of π
on the problem) to compare with the difference en. Then we can execute the algorithm
until |yn+1 −yn| < TOL. When this difference becomes less than TOL indicates that the
sequence is converging and it is unlikely to obtain better results with more iterations.
This stopping criterion though has a risk. If the sequence is not convergent, then the
difference |yn+1 −yn| might never become less than TOL and our code will never stop. For
this reason, we usually count the number of iterations using a counter, let’s say iter and
we never allow them to exceed a limit of MAXIT iterations. Taking into account the new
stopping criteria, we present Archimedes algorithm in Algorithm 10.
Algorithm 10 Archimedes algorithm for the approximation of π (Again)
Set the tolerances TOL = 10−10 and MAXIT = 100
Set x =
√
3 and y = 2.0
Set e = y, and iter = 0
while |e| ≥TOL and iter < MAXIT do
Set e = y
Compute x = x + y and y =
√
1 + x2
iter = iter + 1
e = e −y
end while
Return y as an approximation of π
Note that the variable e takes initially the old value of y in the beginning of the while
loop, and then we subtract from it the new value of y at the end of the loop. In the end
we use absolute value to compute the distance between old and new approximations. We
leave the implementation of Archimedes’ algorithm as an exercise for the reader. We also
recommend to test and change the given code as much as you can.
3.4
Further Reading
A classical and influential work in scientific computing and its pitfalls is a paper by Forsythe
with title “Pitfalls in computation, or why a math book isn’t enough”, [42]. This also justifies
why we present computer experiments side by side with proofs and theorems in this book.
For a complete discussion of the theory of floating-point numbers, we refer to the classical
works of Goldberg [46], Higham [64] and Wilkinson [141]. All classical, introductory books
on numerical analysis and scientific computing contain extensive introductions to floating-
point arithmetic and sources of errors. We indicatively refer to some classical books on
numerical analysis [43, 25, 26, 27, 70]. An excelent book dedicated on scientific computations
with finite precision arithmetic is [20]. Other modern textbooks on numerical analysis with
similar material include but not limited to [57, 18, 22, 76, 89, 90, 108, 132].

Chapter Highlights
 Real numbers are represented in computer systems by floating-point numbers.
 Floating-point numbers are stored in memory in the form ±r × 10n where
r = 0.d1d2 · · · dt is the mantissa, di the significant digits and t the precision.
 In scientific notation, a number ±r × 10n is written as ±r e n where e
represents the base 10. For example, 1.23456=0.123456e1.
 Floating-point numbers consist of finite number of digits and are isolated in the
sense that there are gaps between them.
 The distance between 1 and the next floating point number is called machine
epsilon EPS and it is approximately 2.22e-16. Usually, this is the minimum
expected error in computations for scaled problems.
 Operations involving small numbers of magnitude less than the machine epsilon
need extra care. Sometimes numbers smaller than the machine epsilon can be
considered as approximations to 0.
 Any number in the interval between the smallest positive and the largest
negative floating-point numbers is represented by 0.0 or -0.0 depending if it is
positive or negative. This problem is known as underflow.
 Any number larger than the largest possible floating-point number is
represented by inf or NaN. This problem is known as overflow.
 The absolute error between f and its approximation ¯f is the absolute distance
e = |f −¯f|.
 The relative error between f and its approximation ¯f is its absolute error
normalized by the exact value f, r = |f −¯f|/|f|.
 The difference between two numbers of the same size can cause large errors.
This phenomenon is known as catastrophic cancelation.
 To avoid catastrophic cancelation, we modify formulas and algorithms to avoid
subtraction of two almost equal numbers.
 The results of a stable algorithm will not contain large amount of error given
small errors in the input data. This is important because input data will always
contain small errors due to finite precision arithmetic.
 Small changes in the input of unstable algorithms can result in large errors.
 We can improve unstable algorithms using algebraic or trigonometric identities.
 Other sources of error include the approximation of mathematical formulas.
These errors are known as discretization errors.
100

Exercises
1. Construct representations of the following expressions that are stable when the compu-
tations are performed with finite precision arithmetic:
(a) 1 −cos(x), for |x| ≪1.
(b) ex−y, x, y large numbers.
(c) log(x) −log(y), for x, y > 0.
(d) sin(1 + x) −sin(1), for |x| ≪1.
[The symbol ≪means “much smaller than”.]
2. Consider the functions
f(x) = 1 −cos(x)
sin2(x)
and
g(x) =
1
1 + cos(x) .
(a) Show that f(x) = g(x).
(b) Show that
lim
x→0 f(x) = lim
x→0 g(x) = 1
2 .
(c) Write a Python code to compute the values of f(x) and g(x) for
x = 100, 10−1, 10−2, . . . , 10−11 .
(d) Explain why the values are not the same.
3. Consider the quadratic equation
ax2 + bx + c = 0 ,
with a = 1, b = 912 and c = −3.
(a) Show this quadratic equations has two roots and compute the roots using the for-
mula
x± = −b ±
√
b2 −4ac
2a
.
(b) Observe none of the roots is equal to 0.
(c) Write a Python code to compute the roots of this equation.
(d) Explain why the x+ computed by python is 0.
(e) Show that we can rewrite the solution x+ in the form
x+ =
−2c
b +
√
b2 −4ac
.
(f) Compute again the roots of the quadratic equation using the new formula and
observe that the results are better. Explain why this is the case.
4. Using Python compute the absolute and relative errors between the exact value of x and
its approximation ˜x:
101

(a) x = π, ˜x = 355/113.
(b) x =
√
2, ˜x = 1.41421.
(c) x = e, ˜x = 2.718.
(d) x = π, ˜x = 4 arctan(1).
(e) x = π/4, ˜x = 1 −1/3 + 1/5 −1/7 + 1/9.
5. Consider the formula for the binomial coefficient
a
b

=
a!
b!(a −b)! ,
where the factorial n! = 1 · 2 · · · n.
(a) Write a Python function that returns the binomial coefficient of two integers a, b.
(b) Find the maximum value of a a you can use in your code without getting an over-
flow?
(c) Show that the binomial coefficient can be computed also using the formula
a
b

= a
b · a −1
b −1 · · · a −b + 1
1
.
(d) Write a new Python function to compute the binomial coefficient using the second
formula.
(e) Find again the maximum value a you can use in your new function without getting
an overflow.
6. Consider the function
f(x) = ln(1 −x)
x
.
(a) Show that limit
lim
x→0 f(x) = 1 .
(b) Plot the function f in the interval [−0.5, 0.5] using the module MatPlotLib.
(c) Magnify the plot around 0 using the interval [−5×10−10, 5×10−10]. Can you extract
any safe conclusion related to the limit of the function f for x →0 using the specific
magnification?
(d) Explain why there is such an inconsistency between the theory and the graph.
(e) Try to modify the function appropriately so as to make the computation of f(0)
stable.
7. Consider x and y two floating-point numbers with x ≈y.
(a) What is the relative error of the operation x −y.
(b) What formula would you use for the computation of the quantity (x −y)2: (x −y) ·
(x −y) or x2 + y2 −2xy?
(c) What formula would you use for the computation of the quantity x2 −y2: (x −y) ·
(x + y) or x · x −y · y?
(d) Compute the relative error of the expressions of the last two questions.
102

8. In Section 1.5 we introduced the Fibonacci sequence using a recursive function. An
alternative formula for the Fibonacci sequence is
F(n) =
1
√
5
" 
1 +
√
5
2
!n
−
 
1 −
√
5
2
!n#
,
(3.2)
where the fraction (1 +
√
5)/2 is known as the golden ratio.
(a) Write a function to compute any term of the Fibonacci sequence using the formula
(3.2).
(b) Use your function to compute the term F(100) and F(1000).
(c) Compare the previous results with the results obtained with the Fibonacci function
of Section 1.5.
(d) Describe the advantages and disadvantages of each method?
103

Taylor & Francis 
Taylor & Francis Group 
http://taylorandfrancis.com 

4
Calculus Facts
We have already used Python to solve calculus problems such as the estimation of limits of
functions. The notions and theory of calculus are of fundamental importance for computa-
tional mathematics. Calculus provided with basic problems and tools for the development of
numerical algorithms. For example, finding the value of a definite integral can be extremely
difficult or even impossible task. Meanwhile tools like Taylor polynomials used extensively
to analyze basic numerical methods. Calculus is interconnected with computational math-
ematics, and in this chapter, we review briefly some of its most important notions and
theorems.
4.1
Sequences and Convergence
Part of this book deals with functions and numbers. Numbers in principle form sets (col-
lections of numbers). If a number a is in a set A we write a ∈A. On the other hand, if a
number is not in A, then we write a ̸∈A. If a number belongs to two sets A and B at the
same time, then we write a ∈A∩B. If a belongs to the set A or B or to both but we aren’t
sure, we write a ∈A ∪B. The basic sets of numbers are namely the following:
 The set of natural numbers: N = {0, 1, 2, 3, . . . }
 The set of integer numbers: Z = {· · · , −3, −2, −1, 0, 1, 2, 3, . . . }
 The set of rational numbers: Q = {p/q : p, q ∈Z, q ̸= 0}
 The set of irrational numbers: I = {x : x ̸∈Q}
 The set of real numbers: R = Q ∪I
Usually the indices lie in the set of natural numbers N while the rest of the numbers,
including floating point numbers, will be considered in R with the exception of complex
numbers. Complex numbers are usually denoted by z = a + ib where a, b ∈R and i is the
imaginary unit (with the property i2 = −1). If z is a complex number, then we write z ∈C.
The complex conjugate of z = a + ib will be denoted by ¯z = a −ib.
Sometimes, we will not consider a whole set A but a subset B of A. Such an inclusion
is denoted as B ⊂A and is a set again. If B ⊂A, then B does not necessarily contain all
members of A. In some sense, B is included in A and perhaps is smaller. Useful examples of
subsets of R are the intervals. For example, the interval [a, b] contains all the real numbers
x between a and b including a and b. Such an interval is called closed interval. In other
words, all the real numbers x such that a ≤x ≤b are included in the set [a, b]. Notice
that we used square brackets since the endpoints a and b are included. If we don’t want to
include the endpoints of an interval, then we write (a, b), which means that if x ∈(a, b),
then a < x < b, and the interval is called open. We can also have combinations of open and
closed intervals, such as the interval [a, b) with numbers x such that a ≤x < b.
DOI: 10.1201/9781003287292-4
105

106
Calculus Facts
Very often in computational mathematics we construct sequences of approximations
an. A sequence is an enumerated collection of numbers a0, a1, a2, . . . , and is denoted as
{an}n∈N. The values of sequence may be real an ∈R, while the indices are natural numbers.
Sometimes, in some computations of an+1 we will use approximations of an. Methods that
generate sequences of approximations are called iterative methods.
To give an example of an iterative method we will consider again the ancient method of
Archimedes for the computation of π. Archimedes approximated π by the area of regular
polygons inscribed in a unit circle (see also Section 3.3.4). The area of a regular polygon
inscribed in a unit circle is
an = n
2 sin
 π
2n

,
where n is the number of equal sides of the regular polygon. As we increase the number
of sides we get a larger polygon that covers more of the area of the unit circle. By taking
n = 3, 4, . . . we find approximations an of π, and we say that we generated a sequence of
approximations. If we continue this process by increasing the index n for ever we finally
construct the unit circle. This infinite process describes the notion of convergence.
Suppose that we have a method to generate a sequence of numbers {an}n∈N that con-
verges to a. This means that the values of an approximate a for large values of n, and if we
take the index n to be huge (close to infinity) then we practically get the exact value of a.
We write this as
lim
n→∞an = a ,
and we say that the sequence an converges to a. Sometimes we just write an →a as n →∞.
In practice, we can compute only a finite number of iterations/approximations. The
sequence {an}n∈N approximates the exact solution, let’s say a, and for some n < ∞the
distance |an −a| defines the error in the approximation. Specifically, we defined the absolute
error
|en| = |an −a| ,
and is the distance between the exact value a and the approximation an. Since an →a,
then the distance between an and a is decreasing until it is eliminated at infinity. In the
end, we have that |an −a| →0 as n →∞, and therefore |en| →0. Ideally, in our iterative
methods we want the error to go to zero as n grows so we can trust the approximations.
As an example, consider the sequence of numbers
an = 1 + 1
n .
When n →∞we have that 1/n →0 becomes very small and thus an →1 or else |an−1| →0
as n →∞. Taking n = 10 we observe that a10 = 1 + 10−1 = 1.1 ≈1, while the error
|e10| = |1.1 −1| = 0.1. Taking n even larger we can have smaller error |en|.
The formal definition of convergence deals with the error |en|. In formal mathematical
language we say that for (any) small number ε > 0, there is an index (that might depend
on ε) say N = N(ε), such that the error |an −a| < ε for all values of n > N. This means
that we can make the error as small as we want (of order ε) by choosing appropriately large
values of the index n > N.

Continuous Functions
107

Usually iterative methods generate a sequence ak, k = 0, 1, 2, . . . of approxi-
mations of the exact solution a. We prefer this sequence to converge to the exact
solution. Then for any reasonably large value of k we will have ak ≈a. We will
use similar notation to refer to sequences of vectors. We will denote a sequence of
n-dimensional vector by a(k) = (a(k)
1 , a(k)
2 , . . . , a(k)
n )T , with k = 0, 1, 2, . . . . In this
notation, the bold letter indicates a vector, while the superscript index indicates the
k-th term of an infinite sequence of vectors.
4.2
Continuous Functions
In applications we tend to use functions to describe quantities and unknowns. Functions
are mappings from one set to another. A function of a single variable f(x) takes values
x from one set A known to as the domain of f, and returns values y = f(x) in a set B,
which is called range of f. The set A can be an interval or a combination of intervals. To
emphasize that f is a map from A to B we write f : A →B. For example, the function
f(x) = log(x) is defined for x > 0. So the domain of log(x) is the interval (0, +∞). The
range of the logarithm is the whole real line R. Another interesting example with a very
similar domain is the function f(x) = √x. The domain of the √x is the set [0, +∞) as it
is defined for x = 0 but not for negative numbers (and we exclude complex numbers). Its
range, though, is the same set as its domain [0, +∞).
A root of a function f(x) is a number x∗in the domain of f such that f(x∗) = 0. For
example, the function f(x) = x2 −1 has two roots x∗= 1 and x∗= −1. Assume that
we have an iterative method that generates a sequence xn of approximations of the root
x∗= 1 and that this sequence eventually converges to x∗. This means that xn →x∗. Since
f(x∗) = 0 we prefer for the approximations f(xn) ≈0, or in other words f(xn) →f(x∗) = 0
as xn →x∗. This property is a consequence of the continuity of the function and generalizes
the notion of limit from sequences to functions.
We generalize the notion of limit to a variable x. We say that x approaches x0 ∈R if
the distance between x and x0 becomes very small or is eliminated, and we write x →x0.
There are also two ways to approach x0: From the left x →x0−, which means the x < x0
or from the right x →x0+, which means that x > x0. We can consider a general approach
when the values x can approach x0 from both sides. This is the meaning of x →x0.
Consider a function f(x) with domain A and a value x0 ∈A. The function f(x) is called
continuous at x0 if
lim
x→x0 f(x) = f(x0) ,
which means that if we take values of x close to x0, then the values of f(x) are close to the
values of f(x0). This guarantees that the graph of f is a continuous line and there is no
discontinuity at x0. We can think of discontinuities as jumps in the graph of a discontinuous
function. The function
f(x) =
 1,
x = 0
0,
x ̸= 0
,
has a jump at x = 0. In this trivial case f(0) = 1 but for x ̸= 0, f(x) = 0 and so no matter
how we approach 0 we will always have f(x) = 0 but not the value 1 = f(0). This can be
expressed as
lim
x→0 f(x) = lim
x→0 0 = 0 ̸= 1 = f(0) .

108
Calculus Facts
A function which is continuous at every point in an interval (a, b) is said to be continuous
in (a, b). All continuous functions form a set. The set of continuous functions in an interval
I is denoted by C(I). For example, the set of continuous functions on (a, b) is denoted by
C(a, b). If the interval I is a closed interval [a, b] then we will write C[a, b].
Going back to our example with the root x∗of f(x) we mention an important conse-
quence of continuity that serves the purposes of computational mathematics. This is that
instead of x we can choose a sequence xn that converges to x∗, and if f is continuous, then
lim
n→∞f(xn) = f(x∗), which means that f(xn) ≈f(x∗) = 0 for large values of n.
The formal definition of a continuous function is based on the notion of limit (and
approximation). Specifically, a function f(x) is continuous at a point x0 if for every number
ε > 0, we can find a number (that might depend on ε) δ > 0 such that for all values of x
δ-close to x0, i.e. |x−x0| < δ, the values of f(x) are ε-close to f(x0), i.e. |f(x)−f(x0)| < ε.
This formal definition of continuity guarantees that the values of the function f(x)
become arbitrarily close to f(x0) for values of x very close to x0, but says nothing on how
much the values of f(x) vary.
A Lipschitz continuous function is a continuous function that has a specific way to vary:
A function f(x) is Lipschitz continuous if for all x, y in the domain of f, there exists a
constant L > 0 such that
|f(x) −f(y)| < L|x −y| .
This means that the distance between two values f(x) and f(y) cannot be very different
than the difference between x and y.
Obviously, a Lipschitz continuous function is a continuous function, which in addition
cannot vary arbitrarily. If in addition 0 < L < 1, then the function is called contraction and
has more favorable properties. For example, we can find x∗such that x∗= f(x∗). The point
x∗is called fixed point of f and as we will see later it can be very important for numerical
computations.

Lipschitz continuous functions are continuous functions that do not vary rapidly.
The smoothness of their variations depends on the Lipschitz constant L > 0. If L < 1
this means that the function varies very smoothly and is called contraction.
To see why the notion of Lipschitz continuity is related with the variations of the function
f consider the ratio
|f(x) −f(y)|
|x −y|
< L .
Taking y very close to x, we practically set the slope of the secant line to the graph of f at
the point x to be less than L (see Figure 4.1).
As an example of Lipschitz continuous function consider the function f(x) = x2 in the
interval I = [−1, 1]. For x, y ∈[−1, 1] we have |x + y| ≤2 since in the worst case scenario
x = y = 1. Therefore,
|f(x) −f(y)| = |x2 −y2|
= |(x −y)(x + y)|
≤2|x −y| .
Thus, f(x) = x2 is Lipschitz continuous function in [−1, 1] with Lipschitz constant L = 21.
The Lipschitz constant is not unique since one can take any constant L ≥2 as a Lipschitz
1Functions that are Lipschitz continuous only in a subinterval of its domain are called locally Lipschitz
continuous functions.

Continuous Functions
109
FIGURE 4.1
Slope of a secant of a Lipschitz continuous function.
constant. Also the bounds of the Lipschitz constant depends on the interval I. Finally we
note that the particular function is not a contraction in I.
4.2.1
Bolzano’s intermediate value theorem
Before start solving a problem it is very useful to know that the problem has a solution. In
computational mathematics we wouldn’t care about the exact solution of a problem since
we compute approximations. We do care enough though to know that there is a solution
and ideally that the solution is unique. Let’s say that we want to compute the root of the
function f(x) = x2+1. Obviously there is no real root since the function f is always positive
f(x) ≥1 > 0 for all values of x ∈R. So there is no point to search for real solutions even
numerically.
Another observation to root finding methods is that if f(x) is continuous and changes
sign, then it must have a root. Of course there are cases like the function f(x) = x2 where it
is positive and never becomes negative. Nevertheless, we will consider for the moment only
functions that change sign. A necessary condition for a function that changes sign to have
a root, is the function to be continuous. Otherwise the function can move from negative
values to positive by jumping the x-axis without having a root. Bolzano’s intermediate value
theorem describes this situation.
Theorem 4.1 (Bolzano’s theorem). If a function f(x) satisfies the following conditions:
 f is continuous in [a, b]
 f(a) · f(b) < 0
then, there exists at least one solution x∗∈(a, b) of the equation f(x) = 0.
The condition f(a) · f(b) < 0 means that sign(f(a)) ̸= sign(f(b)), and thus the graph of
the continuous function f(x) crosses the x-axis necessarily at a point between a and b. The
specific situation is illustrated in Figure 4.2.

110
Calculus Facts
FIGURE 4.2
Illustration of Bolzano’s theorem.
It is worth mentioning that Bolzano’s theorem requires f to be continuous in a closed
interval [a, b] while the root is in the open interval (a, b). The last observation is a conse-
quence of the fact that f(a) · f(b) < 0 strictly. If one of the values f(a) or f(b) is 0, then
we don’t need to search for a root as the root would be either a or b and f(a) · f(b) = 0.
Bolzano’s theorem is a special case of the so-called intermediate value theorem for contin-
uous functions. The intermediate value theorem states that if a function f(x) is continuous
in the interval [a, b] and s is a value between f(a) and f(b), then there is a value x0 ∈(a, b)
such that f(x0) = s. Bolzano’s theorem is actually a special case of the intermediate value
theorem with s = 0.
As an example consider the function f(x) = x3. The particular function is continuous
in [−1, 1]. Moreover f(−1) = −1 and f(1) = 1. Therefore, f(−1) · f(1) < 0 and thus there
is at least one root x∗∈[−1, 1]. The obvious root is x∗= 0.
4.3
Differentiation
Continuity is an important property of functions, but quite often we require the functions
to be smooth. By saying smooth we mean that a function will be continuous while its
graphs has no corners. If the graph of f has no corners, then we will be able to draw a
unique tangent line at any point of its graph. Smoothness is equivalent to the existence of
derivatives.
Let f be a function defined in an open interval (a, b) containing a point x0. The function
f is called differentiable at x0 if the limit
f ′(x0) = lim
x→x0
f(x) −f(x0)
x −x0
,

Differentiation
111
FIGURE 4.3
The tangent line of a differentiable function.
exists. The number f ′(x0) is called the derivative of f at x0. A function that has derivative
at each point in an interval (a, b) is called differentiable on (a, b). Differentiable functions in
the interval I form the set C1(I). If a function is differentiable in (a, b) we write f ∈C1(a, b).
If a function is differentiable at x0, then the function is smooth enough to define a unique
tangent line passing through the point (x0, f(x0)). The derivative of a function f ′(x0) is
the slope of the tangent line at x0. Therefore, the tangent line passing through the point
(x0, f(x0)) can be described by the formula y = f ′(x0)x + b, where b is the point of y-axis
that the line is passing through (see Figure 4.3).
The tangent line in Figure 4.3 coincides with the function f at (x0, f(x0)). Around that
point f(x) is very close to the tangent line. This gives us an idea of approximation. In
particular, we could use this tangent line to approximate f(x) around that point. As we go
away from that point, this approximation may not be as good, but the limit in the definition
of the derivative insures a good approximation at least close to (x0, f(x0)).
Higher order derivatives of a function f such as the second derivative f ′′(x) are defined
as the derivatives of the derivatives. This means, for example, that a twice differentiable
function has a smooth derivative as well. If a function is twice differentiable in the interval
(a, b), then we write f ∈C2(a, b). The more times a function is differentiable the smoother
it is. Ideally, we would prefer the functions to have derivatives of all orders. If a function f
has the derivatives of all orders defined in the interval (a, b), then we write f ∈C∞(a, b). In
computational mathematics, when we try to solve problems, we assume certain smoothness
that will allow us to find unique solutions and estimate approximation errors. However, we
can use our methods for less smooth functions but with no guarantee of the quality of the
results.
Derivatives are also important for other reasons. Many scientific and engineering prob-
lems are related with derivatives. The reason is that the practical meaning of a deriva-
tive is the same with that of the rate of change. For example, in physics the acceleration
a(t) of an object is the rate of change of its velocity v(t), and mathematically speaking
a(t) = v′(t). Here, the independent variable t represents time. Sometimes, in order to show
clearly the variable in which we differentiate, we write the derivative using the Leibniz
notation v′(t) = d
dtv(t).

112
Calculus Facts
FIGURE 4.4
The tangent line at a maximum point of a function.
Positive acceleration implies increase in speed while negative acceleration implies de-
crease in speed. In general if f(x) is differentiable and f ′(x) > 0, then f(x) is increasing
(i.e. if x1 < x2 then f(x1) < f(x2)) while if f ′(x) < 0, then f(x) is decreasing (i.e. if x1 < x2
then f(x1) > f(x2)).
4.3.1
Important theorems from differential calculus
Optimization is a branch of computational mathematics that deals mainly with the com-
putations of extreme values (extrema) of functions. Extrema of a function f(x) are, for
example, the maximum and the minimum values of f(x). A (local) maximum of a function
is a point (c, f(c)) such that f(x) ≤f(c) for all values of x in a neighborhood of c. A (local)
minimum of a function is a point (c, f(c)) such that f(x) ≥f(c) for every value x in a
neighborhood of c. If f(x) is differentiable, then the derivative is zero f ′(c) = 0 at the point
c of extremum (maximum or minimum). Zero derivative indicates that the tangent line is
parallel to the x-axis as its slope is zero. In Figure 4.4, we show the geometric interpretation
of this fact for a point of maximum at (c, f(c)).
A very useful theorem for theoretical and practical situations is Rolle’s theorem. Rolle’s
theorem guarantees the existence of a maximum or minimum for a smooth function.
Theorem 4.2 (Rolle’s theorem). Suppose that f is continuous in [a, b] and differentiable
on (a, b). If f(a) = f(b), then there exists a number c ∈(a, b) such that f ′(c) = 0.
Note that Rolle’s theorem doesn’t specify if the point (c, f(c)) is a maximum or mini-
mum. It is only guaranteed an extremum point such that f(x) ≤f(c) or f(x) ≥f(c) locally
around the point c. The situation of Rolle’s theorem is depicted in Figure 4.4.
Another important theorem is the Mean Value Theorem of differential calculus:
Theorem 4.3 (Mean Value Theorem). If f is continuous in [a, b] and differentiable in
(a, b), then there exists a number c ∈(a, b) such that
f ′(c) = f(b) −f(a)
b −a
.
The mean value theorem of differential calculus can be viewed in two different ways, an
algebraic and a geometric: It relates the difference quotient (f(b) −f(a))/(b −a) with the
derivative of a function, and on the other hand states that the slope of the secant passing
through the points (a, f(a)) and (b, f(b)) is the same as the slope of some tangent line to
the graph of the function f(x). This geometric interpretation is presented in Figure 4.5.

Diﬀerentiation
113
ii
FIGURE 4.5
Geometric interpretation of the mean value theorem of diﬀerential calculus.
4.3.2
Taylor polynomials
Smooth functions in C∞(a, b) can be represented by Taylor series. Speciﬁcally, if f(x) is
inﬁnite many times continuously diﬀerentiable around a point x = c in the interval (a, b),
then the Taylor series of f(x) around x = c is the inﬁnite sum
f(x) = f(c) + f ′(c)(x −c) + f ′′(c)
2
(x −c)2 + · · · ,
which can be written in compact form as
f(x) =
∞

k=0
f (k)(c)
k!
(x −c)k ,
where f (k) denotes the k-th derivative of f, and k! = 1 · 2 · · · k.
Some commonly used Taylor series (sometimes also referred to as Taylor expansions) for
c = 0 are the following:
ex = 1 + x + x2
2! + x3
3! + · · · =
∞

n=0
xn
n! ,
sin(x) = x −x3
3! + x5
5! −· · · =
∞

n=0
(−1)n
(2n + 1)!x2n+1 ,
cos(x) = 1 −x2
2! + x4
4! −· · · =
∞

n=0
(−1)n
(2n)! x2n .
Since computers can only compute ﬁnite sums, we may wish to approximate smooth
functions using polynomials. Polynomials are also easy to integrate and diﬀerentiate. One
way to ﬁnd good approximations of functions is by using Taylor’s polynomials. Consider a
smooth function f ∈Cn+1[a, b] and let c ∈[a, b], then the Taylor polynomial of degree n is
the ﬁnite sum
Pn(x) = f(c) + f ′(c)(x −c) + f ′′(c)
2!
(x −c)2 + · · · + f (n)(c)
n!
(x −c)n .
(4.1)

114
Calculus Facts
Obviously, this finite sum is not exactly equal to f(x). These polynomials coincide with
the function f(x) at the point x = c and it is Pn(c) = f(c). Moreover, the polynomial Pn(x)
is very close to the function f(x) for x near c. This means that Pn(x) approximates the
function f(x). As x is moving away from c, unfortunately, the polynomial Pn(x) will not
necessarily remain close to f(x).
The difference between Pn(x) and f(x) is known as the residual or truncation error or
remainder of the Taylor polynomial and it is
f(x) −Pn(x) = Rn(x) ,
with
Rn(x) = f (n+1)(ξ)
(n + 1)! (x −c)n+1 ,
for some ξ ∈[a, b].
Equivalently, we can write the function
f(x) = Pn(x) + Rn(x) ,
where Pn(x) is the truncated Taylor series
Pn(x) =
n
X
k=0
f (k)(c)
k!
(x −c)k ,
and Rn(x) the residual of the truncation. The residual is expected to be small for x near c.
Here we present two examples of Taylor polynomials:
 Taylor’s approximation for n = 1 is f(x) ≈f(c) + f ′(c)(x −c).
 Taylor’s approximation for n = 2 is f(x) ≈f(c) + f ′(c)(x −c) + f ′′(c)
2! (x −c).
In some applications we need to approximate a function f around a point x but not far
away from x. For example, assume that we want to compute the polynomial at the point
x + h where h is very small (h ≪1). In these cases we consider the Taylor polynomial (4.1)
with x + h instead of x and x instead of c so that
f(x + h) = f(x) + f ′(x)h + f ′′(x)
2!
h2 + f ′′′(x)
3!
h3 + · · · + f (n)(x)
n!
hn + Rn(ξ) ,
where
Rn(ξ) = f (n+1)(ξ)
(n + 1)! hn+1 .
Since we assumed that h is small, if in addition the (n + 1)-th derivative of f is bounded
by a constant for all values of x around c, i.e. |f n+1(x)| ≤M, then we have
|Rn(x)| ≤Chn+1 ,
where C = M/(n + 1)!.
Note that this formula reveals information about the approximation error. If for example
the discretization step is h, then the error of the approximation of f by Pn is of order hn+1.
Therefore, if h ≪1 and M small enough for sufficiently large n, then we expect the error
to be small.

Integration
115
4.3.3
The big-O notation
The truncation error of the Taylor polynomial of degree n in the previous section was
|Rn(x)| ≤Chn+1 where C is a constant that depends on f(x). In order to emphasize the
order of this residual, which is n + 1 and not the fact that it can be less than hn+1 we often
use the big-O notation by writing Rn(x) = O(hn+1). In general we write
f(x) = O(g(x))
when
x ∈I
if and only if
|f(x)| ≤M|g(x)|
when
x ∈I
where
M > 0,
and we say that f is of order g.
In practice we use Big-O notation to say something about the size of the terms we
discard or an error.
4.4
Integration
Assume that we have an object located at a point x0 = a on the x-axis. This object is
moving horizontally due to the action of a force f(x). The final destination of this object
is a point xN = b. Between the points x0 and xN, there are other points x1, . . . , xN−1 such
that
x0 < x1 < · · · < xN−1 < xN .
We know from classical physics that the work W produced by constant force f(x) from
point x0 to point x1 is the product of the force times the length of the interval [x0, x1]. This
is W0 = f(x)·(x1−x0) for x ∈[x0, x1]. Assume that the force changes to a different constant
when the object reaches the point x1 and remains constant until the object reaches x2. The
new work done by the force is now W1 = f(x) · (x2 −x1) for x ∈[x1, x2]. This process is
repeated until the object reaches its final destination xN = b. So the force is constant on
every interval (xi−1, xi) for i = 1, 2, . . . , N, and the work produced by the force f in each
of these intervals is Wi = f(xi−1) · ∆xi with ∆xi = xi −xi−1 for i = 1, 2, . . . , N. The total
work produced by the force is the sum
W =
N
X
i=1
Wi =
N
X
i=1
f(xi−1)∆xi .
In Figure 4.6, the y-axis represents the force f(x), while x-axis the displacement. The
graph of the function y = f(x) is a piecewise constant line, and the work produced in each
interval (xi−1, xi) is equal to the area of the rectangle formed by the graph of f in the
interval (xi−1, xi) and the interval (xi−1, xi). Since the force is constant in every interval
(xi−1, xi) we can take any value zi ∈(xi−1, xi) and write the total work in the form
W =
N
X
i=1
f(zi)∆xi .
If the force changes continuously, this means that the lengths of the intervals must tend
to 0, and mathematically speaking we need to take ∆xi →0 in the previous sum. This limit
is the integral
W =
lim
∆xi→0
N
X
i=1
f(zi)∆xi =
Z b
a
f(x) dx .

116
Calculus Facts
FIGURE 4.6
The work done by a force constant in each interval (xi−1, xi).
FIGURE 4.7
Integral as the area below a function f(x).
Since each rectangle with sides f(zi) and ∆xi has area equal to the work Wi, we conclude
that the total work done by f(x) is the area described by the function f(x), the x-axis and
the lines x = a and x = b as shown in Figure 4.7.
The Riemann integral of a function f defined on the interval [a, b], if it exists, is the
limit
Z b
a
f(x) dx =
lim
∆xi→0
N
X
i=1
f(zi)∆xi ,
where the numbers x0, x1, . . . , xN satisfy a = x0 ≤x1 ≤· · · ≤xN = b, with ∆xi = xi−xi−1
for each i = 1, 2, . . . , N, and zi is arbitrarily chosen in the interval [xi−1, xi]. A function
with a finite integral is called integrable. Note that all continuous functions are integrable,
which means that their integral is defined and is finite. The function f(x) inside an integral
is called integrant.
4.4.1
Approximating integrals
Looking at the example with the force in Figure 4.6, we can derive easily a simple way to
approximate a definite integral over an interval [a, b]. What we need to do first is create a
grid a = x0 < x1 < · · · < xN−1 < xN = b. As a second step, we approximate the integral

Integration
117
of function f(x) in each interval Ii = (xi−1, xi). In order to approximate an integral in
Ii we approximate the function f(x) by a constant line over the interval Ii. This gives a
reasonable approximation as long as we take the length of the interval ∆xi very small.
For example, we can take f(x) ≈f(zi) for x ∈(xi−1, xi), where zi can be taken to be an
endpoint of Ii, for example zi = xi or even the midpoint zi = (xi + xi−1)/2. The last choice
will lead to an approximation formula known as the midpoint rule. Because the origin of
numerical methods for the approximation of integrals is in the approximation of their area
by rectangles, we call these numerical methods quadrature rules. Note also that the grid
a = x0 < x1 < · · · < xN−1 < xN = b can be uniform in the sense that all the points are
equidistributed in the interval [a, b] and ∆x = xi −xi−1 = (b −a)/N, for all i = 1, 2, . . . , N.
As an example of the midpoint rule we consider the integral
I =
Z 1
0
x dx = 1
2 .
In order to approximate this integral, consider a uniform grid with 5 nodes
{x0, x1, x2, x3, x4} = {0, 0.25, 0.5, 0.75, 1} ,
and step ∆x = 0.25. The midpoints are the points
{z1, z2, z3, z4} = {0.125, 0.375, 0.625, 0.875} .
Then the integral can be approximated by
I ≈
4
X
i=1
f(zi)∆x = ∆x · (f(0.125) + f(0.375) + f(0.625) + f(0.875))
= 0.25 · (0.125 + 0.375 + 0.625 + 0.875) = 0.5 .
We observe that although we approximated the integral using such a simple method, the
result was equal to the exact value of the integral. This can happen when we approximate
integrals of polynomials but this is not true in general. We will study such methods in detail
in Chapter 7.
4.4.2
Important theorems of integral calculus
A fundamental property of integrals is the following: We can split an integral over an interval
[a, b] into two or more integrals on subintervals of [a, b] and then add the values to calculate
the total integral. For example, if we want to compute the integral on the interval [a, b], we
take a value c ∈(a, b) and we split the interval into two intervals [a, b] = [a, c] ∪[c, b]. Then,
Z b
a
f(x) dx =
Z c
a
f(x) dx +
Z b
c
f(x) dx .
This property will be very helpful in increasing the accuracy of our computations later in
Chapter 7.
For theoretical purposes we state here some very important theorems of integral calculus.
Theorem 4.4 (Fundamental theorem of calculus). If f ′(x) is continuous on [a, b], then
Z b
a
f ′(x) dx = f(b) −f(a) .

118
Calculus Facts
The fundamental theorem of calculus is the main tool we use to compute the value
of integrals when we know the derivative of the integrant. A direct consequence of the
fundamental theorem of calculus is the formula of integration by parts, which for any f, g ∈
C1(a, b) can take the form
Z b
a
f(x)g′(x) dx = f(b)g(b) −f(a)g(a) −
Z b
a
f ′(x)g(x) dx .
Integrals with variable limits are differentiable functions. It is easy to compute their
derivatives using the following theorem:
Theorem 4.5. If f ∈C[a, b], then the function
g(x) =
Z x
a
f(t) dt ,
for x ∈[a, b] is a continuous function on [a, b], differentiable on (a, b) and
g′(x) = f(x) .
Finally, let’s look at the Mean Value Theorem of integral calculus which again is useful
for theoretical calculations.
Theorem 4.6 (Mean value theorem of integral calculus). Let f ∈C[a, b], then there exists
c ∈(a, b) such that the average value of f(x) in the interval [a, b] is
f(c) =
1
b −a
Z b
a
f(x) dx .
4.4.3
The remainder in Taylor polynomials
We have already seen that for a smooth function f(x) and for x near a value c
f(x) = Pn(x) + Rn(x) ,
where Pn(x) is the Taylor polynomial of degree n
Pn(x) =
n
X
i=0
f (n)(c)
n!
(x −c)n ,
and Rn(x) the remainder to be discarded
Rn(x) = f (n+1)(ξ)
(n + 1)! (x −c)n+1
for some ξ ∈[a, b] .
The remainder can be computed alternatively with the help of integrals. For a value x close
to c, we can write the functions f(x) as
f(x) = f(c) +
Z x
c
f ′(t) dt .

Further Reading
119
Integrating by parts yields
f(x) = f(c) +
Z x
c
f ′(t) dt = f(c) + [(t −x)f ′(t)]x
t=c −
Z x
c
(t −x)f ′′(t) dt
= f(c) + (x −c)f ′(c) −
Z x
c
(t −x)f ′′(t) dt .
In this way, we obtained the first order Taylor polynomial
P1(x) = f(c) + (x −c)f ′(c) ,
and the remainder
R1(x) = −
Z x
c
(t −x)f ′′(t) dt .
Repeating the same process we can get the second order Taylor polynomial
f(x) = f(c) + (x −c)f ′(c) −
Z x
c
(t −x)f ′′(t) dt
= f(c) −
(t −x)2
2
f ′′(t)
x
t=c
+
Z x
c
(t −x)2
2
f ′′′(t) dt
= f(c) + (x −c)f ′(c) + (x −c)2
2
f ′′(c) +
Z x
c
(t −x)2
2
f ′′′(t) dt .
Continuing this process, we see eventually that
f(x) = f(c) + (x −c)f ′(c) + · · · + (x −c)n
n!
f (n)(c) + Rn(x) ,
(4.2)
where the remainder Rn(x) is given by the formula
Rn(x) =
Z x
c
(x −t)n
n!
f (n+1)(t) dt .
This formula will be proven very useful in theoretical computations.
4.5
Further Reading
As this chapter is a refresher of calculus, it does not contain details and examples, even
though calculus takes up most of the subjects of this book. For reviewing calculus we suggest
textbooks such as [122, 126] or the classical books [3, 4]. For a deeper understanding of
calculus and for more formal exploration of analysis, we refer to [133, 134] and the references
therein.

Chapter Highlights
 The space of continuous functions in [a, b] is denoted by C[a, b].
 The space of n-times continuously differentiable functions in (a, b) is denoted
by Cn(a, b).
 Bolzano’s theorem states that if f(x) is continuous in [a, b] and changes sign in
[a, b], then there is at least one root of the equation f(x) = 0 in (a, b).
 Smooth functions can be approximated around a point x = c using the Taylor
polynomial Pn(x) of degree n with
Pn(x) =
n
X
i=0
f (n)(c)
n!
(x −c)n .
 A Taylor polynomial approximates a function f(x) in the sense that
f(x) −Pn(x) = Rn(x) where Rn(x) being the residual (or error). A Taylor
polynomial coincides with the function f(x) at the point x = c, i.e.
f(c) = Pn(c). The error between Pn and f increases as the distance between x
and c increases.
 The residual of the n-degree Taylor polynomial is given by the formula
Rn(x) = f (n+1)(ξ)
(n + 1)! (x −c)n+1
for some ξ ∈[a, b].
 An integral of a function f over an interval [a, b] can be thought of as the area
included by the function f, the x-axis and the lines x = a and x = b.
 An integral can be approximated if we subdivide the interval [a, b] using a grid
a = x0 < x1 < · · · < xN = b, approximate the function in each of the
subintervals [xi−1, xi], i = 1, 2, . . . , N by a constants, and compute the
respective integrals.
 An integral on an interval [a, b] = [a, c] ∪[c, b] can be expressed as the sum of
two integrals
Z b
a
f(x) dx =
Z c
a
f(x) dx +
Z b
c
f(x) dx .
 The mean-value of an integral is the value
f(c) =
1
b −a
Z b
a
f(x) dx ,
for some value c ∈(a, b).
 The integral representation for the residual of an n-degree Taylor polynomial is
Rn(x) =
Z x
c
(x −t)n
n!
f (n+1)(t) dt .
120

Exercises
1. Prove that the equation sin(x) = 2−2x has at least one solution in the interval (π/6, π/4).
2. Prove that the equation x −e−x = 0 has a unique solution x∗∈[0, 1].
3. If a function f is continuous in [a, b] and f(a) ̸= f(b), then show that there is at least
one x∗∈(a, b) such that
f(x∗) = f(a) + f(b)
2
.
4. Consider the function
f(x) =

ax2+3bx−5
x−1
,
x ̸= 1
7,
x = 1
.
Find the values of a, b ∈R so as f is continuous.
5. Consider the function
f(x) =
 3x2 −a2x,
x < 1
5x + a −4,
x ≥1
.
Find the values of a so as f is differentiable at x = 1.
6. Show that if a function f is differentiable at x = 0 and
lim
x→0
f(x)
x
= 4 ,
then f ′(0) = 4.
7. Find the equation of the tangent line to the graph at (x0, f(x0)) when f(x) = 2x3 and
x0 = −1.
8. Prove that the equation 3x5 −x3 + a = 0 has at most one root in the interval (−1, 1) for
any value of a.
9. Show that Rolle’s theorem apply to the function f(x) = x sin(x). Then prove that the
equation tan(x) = −x has at least one root in the interval (0, π).
10. Prove that
(a)
2 −e
2 < ln 2 < 2
e ,
(b)
cos 5π
18 < 1
2 + π
√
3
36
.
11. Prove that
(a)
x −1
x
≤ln x ≤x −1
for all x ∈(0, +∞) ,
(b)
lim
x→1
ln x
x −1 = 1 .
121

12. If two functions f and g satisfy the system of differential equations
(
f ′(x) = g(x),
g′(x) = −f(x),
for all x ∈R ,
then show that the function f 2(x) + g2(x) is constant.
13. Consider the function f(x) =
ex
x+1.
(a) Find the intervals of monotonicity of f(x).
(b) Find the minimum and maximum values of f(x).
(c) Prove that ex ≥x + 1 for all x ∈R.
14. Prove that for any two continuous functions in the interval [a, b]:
(a) If f(x) ≥0 for all x ∈[a, b] then
Z b
a
f(x) dx ≥0 .
(b) If f(x) ≤g(x) for all x ∈[a, b] then
Z b
a
f(x) dx ≤
Z b
a
g(x) dx .
(c)

Z b
a
f(x) dx
 ≤
Z b
a
|f(x)| dx .
15. Prove that
1 −1
e ≤
Z e
1
1
x dx ≤e −1 .
16. Prove that for all x ∈R
Z x
0
|z| dz = 1
2x|x| .
17. If g is a continuous function in R, and
f(x) =
Z 2x+1
x
g(t) dt ,
show that f ′(x) = 2g(2x + 1) −g(x).
18. The power series of sin x is
sin x = x −x3
3! + x5
5! −x7
7! + · · · .
The following Python function uses these power series to compute the value of sin x for
some x
122

def powersin(x):
# POWERSIN. Power series for sin(x)
# POWERSIN(x) tries to compute sin(x)
# from a power series
s = 0
t = x
n = 1
while (s+t != s):
s = s + t
t = -x**2/((n+1)*(n+2))*t
n = n + 2
return s
(a) What causes the while loop to terminate?
(b) Answer the following questions for x = π/2, 11π/2, 21π/2, and 31π/2:
(i) How accurate is the computed result?
(ii) How many terms are required?
(iii) What is the largest term (in magnitude) in the series?
(c) What do you conclude about the use of floating-point arithmetic and power series
to evaluate functions?
19. The power series for the function arctan(x) is
arctan(x) =
∞
X
i=1
(−1)i+1 x2i−1
2i −1 .
(a) Show that π = 4 arctan(1).
(b) Using the power series of arctan(x) find value N so as the sum
sN =
N
X
i=1
(−1)i+1 x2i−1
2i −1 ,
approximates the value of π/4 with absolute error
|sN −π/4| < 10−3 .
(c) Write a Python function to compute an approximation of π using appropriate power
series of arctan(x).
20. Consider the sequence defined recursively, as follows:
x1 = 2,
x2 = 1,
xn = 2xn−1 −1
2xn−2 .
(a) Write a Python script to compute the value to which the sequence
yn =
xn
(1 +
√
2/2)n ,
converges.
123

(b) We say that a sequence {an} converges to a limit ℓwith rate (or order) r if there is
a fixed number r such that
lim
n→∞
|an+1 −ℓ|
|an −ℓ|r = C,
where C is constant. If the previous relation holds for any value r > 0, then we say
that the sequence converges exponentially. If r = 1, then we say that the sequence
converges linearly, and if r = 2 we say that the sequence converges quadratically.
Find (numerically) the type of convergence (linear, quadratic, exponential) of the
sequence {yn}, as accurately as possible.
(c) Find the exact answers to the above questions.
[Hint: Show first that xn = c1(1 +
√
2/2)n + c2(1 −
√
2/2)n satisfy the recursive relation
for xn. Then find the values of c1 and c2 using the initial conditions. Finally, substitute
into yn and compute the limit.]
21. Consider the sequence {yn} with
yn = 2n tan π
2n ,
n = 2, 3, . . . .
(a) Prove that yn is decreasing, and lim
n→∞yn = π.
(b) Give a geometric explanation of the previous result.
(c) Prove that {yn} can be expressed in terms of the recursive sequence
( y2 = 4 ,
yn+1 = 22n+1
√
1+(2−nyn)2−1
yn
,
n = 2, 3, . . . .
(d) Explain why the previous formula is unstable in finite precision arithmetic.
(e) Find an alternative, stable algorithm for the computation of the terms yn using
only addition/subtraction, multiplication/division and square roots.
[Hint: See Section 3.3.4, and use the identity tan(2x) = 2 tan x/(1 −tan2 x)]
22. Assume that we want to compute members of the sequence
yn =
Z 1
0
xn
x + c dx,
n = 0, 1, 2, . . . ,
where c > 1 is a very large constant.
(a) Compute the term y0.
(b) Prove that the sequence yn is decreasing, and that lim
n→∞yn = 0.
(c) Prove that for all n ≥1
yn =
n−1
X
k=0
(−1)k
n
k

ck (1 + c)n−k −cn−k
n −k
+ (−c)n log 1 + c
c
.
(d) Will the previous formula lead into a stable method to compute the sequence yn?
124

Part II
Introduction to Computational
Mathematics

Taylor & Francis 
Taylor & Francis Group 
http://taylorandfrancis.com 

5
Roots of Equations
Scientific problems often lead to algebraic equations of the form
f(x) = 0 .
A solution of such an equation is defined as a value x∗that satisfies f(x∗) = 0. Unfortunately,
we can solve analytically only linear and certain nonlinear equations, while most of the
equations we deal in real-world problems are complicated and cannot be solved analytically.
For example, try to solve the simple equation cos(x) −x = 0. In this chapter, we focus
on numerical methods for the approximation of solutions of general equations f(x) = 0.
Specifically, we study the bisection, Newton-Raphson, and secant methods. We study the
convergence of these methods, and how to implement and use them in Python.
5.1
Bisection Method
Suppose that f(x) has a root x∗in the interval [a, b]. Thus, x∗∈[a, b] is a solution to
the equation f(x) = 0. The most basic numerical method to approximate this root is the
bisection method1. This method is always convergent, although a bit slow.
5.1.1
Derivation and implementation
The bisection method is based on Bolzano’s (intermediate value) theorem (Theorem 4.1)
and can be applied only to continuous functions that change sign in the interval [a, b].
Because no further smoothness is required, the bisection method is used for its simplicity.
Bolzano’s theorem states that a continuous function f with
f(a) · f(b) < 0 ,
has a root x∗∈(a, b). The midpoint
x0 = a + b
2
,
of the interval [a, b] can be close to this root (see Figure 5.1). We will use the midpoint x0
as a rough first estimation of the root x∗, and nobody stops us from trying to find a better
approximation.
Since we introduced a new point x0 = a+b
2 , we can split the initial interval [a, b] into
two new intervals [a, x0] and [x0, b], and repeat the same process in either [a, x0] or [x0, b]
1Bisection method is an example of a one-dimensional search method, [23]. Another example of search
method is the method of false position (see Algorithm 16) and the golden section search method. More
information for the last one can be found in Chapter 11.
DOI: 10.1201/9781003287292-5
127

128
Roots of Equations
FIGURE 5.1
Approximation of the root x∗by the midpoint of the interval [a, b].
depending on where the root x∗is located. For example, in Figure 5.1 the root x∗is located
in the interval [a, x0]. We have that in this interval f(a) · f(x0) < 0 since f(a) < 0 and
f(x0) > 0. Therefore, we can take an improved approximation x1 of the root x∗to be the
midpoint x1 = a+x0
2
of the new interval [a, x0]. We can repeat this process until we are
satisfied with the accuracy of the approximation.
In order to make this process more suitable for computer implementations and theoreti-
cal estimates, we redefine our interval [a, b] at every iteration by calling the working interval
[a, b]. After the first iteration, the new interval [a, x0] is denoted again [a, b]. Then we set
again x1 = a+b
2 . In particular, we set b = x0 so as the new interval [a, b] coincides with the
interval [a, x0], and we forget the previous interval. Repeating this process we generate a
sequence of approximations xk ≈x∗, each of which is a midpoint of an interval.
Since we repeat this process until certain accuracy has achieved, we need to agree on a
tolerance for the accuracy. Usually, we are not aware of the exact solution x∗, so we cannot
estimate the error |x∗−xk|. For this reason, we terminate the process when two subsequent
approximations are very close to each other. This means that after setting a tolerance TOL
for the accuracy we check whether
|xk −xk−1| < TOL ,
is satisfied. An alternative stopping criterion could also be the magnitude of the value
|f(xk)|. The smallest this value is, the closer to the root we should be. Here, and for the
bisection method, we will consider as a measure of convergence the length of the interval
[a, b] from which the last midpoint occurred. Usually, we take the tolerance to be a small
number of order O(10−5) or O(10−10) depending on how accurate we need the result. If we
take a small tolerance, then the process might require a lot of iterations. The algorithm of
this repetitive process can be described with the Algorithm 11. We encourage the interested
reader to modify the stopping criteria and test other options.
Algorithm 11 defines a sequence of approximations xk. For each k we repeat the same
iteration process. Such method is characterized as iterative method. To avoid the possibility

Bisection Method
129
Algorithm 11 Bisection method
Set a tolerance TOL for accuracy
Initialize the interval [a, b]
Set k = 0
Check if f(a) · f(b) < 0 (if not then quit)
while |b −a| > TOL do
Set xk = (a + b)/2 (the new approximation)
Check in which interval [a, xk] or [xk, b] the function changes sign
if f(xk) · f(a) < 0 then
b = xk
else if f(xk) · f(b) < 0 then
a = xk
else
Break the loop because f(xk) = 0
end if
k = k + 1
end while
Return the approximation of the root x∗
that an iterative method iterates for ever, we count the number of iterations performed and
we allow only a certain maximum number of them. This can be done within the while loop
by adding an additional stopping criterion: The number of iterations cannot exceed a certain
number. This may increase the number of inputs in our function but it ensures a smooth
iterative procedure. We continue with the implementation of this method in Python.
1
def bisection(f, a, b, tol = 1.e-6):
2
iteration = 0 #initialize counter iteration
3
if (f(a) * f(b) < 0.0): # check if there is a root
4
while ((b-a) > tol): # check if the end-points converge
5
iteration = iteration + 1
6
x = (a + b)/2
7
if (f(a) * f(x) < 0.0):
8
b = x
9
elif (f(x) * f(b) < 0.0):
10
a = x
11
else:
12
break
13
print(iteration, x)
14
else:
15
print('failure')
16
return x
17
# returns the midpoint of the final interval
In this code we record the number of iterations using the variable iteration. This
counter is increased by 1 every time the while loop is being executed. We can define the
maximum number of iterations allowed maxit, and replace the while statement with
the statement while ((b-a) > tol and iterations < maxit):. This will ensure that
the code will not perform too many iterations. The variable maxit can be as large as 100
or larger. We leave such a modification of the code as an exercise for the reader.

130
Roots of Equations
In what follows we test our method and its implementation. Here we choose the nonlinear
equation
ln x + x = 0 ,
in the interval [0.1, 1].
1
import numpy as np
2
def f(x):
3
y = np.log(x) + x
4
return y
5
a = 0.1
6
b = 1.0
7
tol = 1.e-4
8
x = bisection(f, a, b, tol)
9
print('The approximate solution x is: ', x)
10
print('And the value f(x) is: ', f(x))
1 0.55
2 0.775
3 0.6625000000000001
4 0.6062500000000001
5 0.578125
6 0.5640625
7 0.57109375
8 0.567578125
9 0.5658203125000001
10 0.5666992187500001
11 0.567138671875
12 0.5673583984375
13 0.56724853515625
14 0.567193603515625
The approximate solution x is:
0.567193603515625
And the value f(x) is:
0.0001390223881425623
This code prints the iteration number and the midpoint at every step. It is noted that
in addition to the approximation xk of the root x∗at the end, we compute the value of the
function f(xk) ≈f(x∗) = 0. It was required 14 iterations until the length of the interval
[a, b] becomes less than 10−4. Because our tolerance was TOL = 10−4, the value f(x∗) we
found has only 4 significant digits correct. We can increase the accuracy of the method by
choosing smaller value for the tolerance TOL.

In line 1 of the previous code we called NumPy with the acronym np. We will
not repeat this command, however, it is necessary for all the rest of the chapter.
5.1.2
Proof of convergence
When we design a numerical method we want to know if the generated approximations
converge to the correct solution, and how fast. We say that the method converges in the
sense that the limit of the error converges to zero as the number of the iterations increases
lim
k→∞|ek| = 0 .

Bisection Method
131
The approximation error |ek| is defined as
|ek| = |x∗−xk| ,
and is the distance between the exact solution x∗and the approximate solution xk. For the
bisection method we have the following proposition:
Proposition 5.1. If f ∈C[a, b] and f(a) · f(b) < 0, then the sequence {xk}k∈N generated
by the bisection method either converges to the root x∗of the equation f(x) = 0 as k →∞
(we write xk →x∗as k →∞), or there is k = N such that xk = x∗. Moreover, the
approximation error is estimated to be
|x∗−xk| ≤b −a
2k+1 ,
k = 0, 1, 2, . . . .
Proof. In order to prove the convergence of the bisection method we modify for convenience
our algorithm by setting a0 = a and b0 = b the initial endpoints of the interval [a, b] and
let Ii = [ai, bi], i = 1, 2, . . . denote the intervals constructed by the bisection method.
Observing that the length of the interval [ak, bk] is half of the length of [ak−1, bk−1] we have
bk −ak = bk−1 −ak−1
2
= bk−2 −ak−2
4
= · · · = b −a
2k
,
and
xk = ak + bk
2
,
while
x∗∈[ak, bk] .
The approximation error is
|ek| = |x∗−xk| ≤bk −ak
2
= b −a
2k+1 .
Taking the limit k →∞we get
lim
k→∞|ek| ≤lim
k→∞
b −a
2k+1 = 0 ,
and therefore we conclude that the sequence xk produced by the bisection method always
converges to the exact root x∗.

The major advantage of the bisection method is that always converges to a
solution and for this reason is often used to provide a good initial approximation for
a more efficient procedure. Moreover, it can be used when the function f(x) is just
continuous.
5.1.3
Rate of convergence
After verifying that the numerical method converges, it is useful to know how fast the gener-
ated sequence of approximations xk converges to the solution x∗. The speed of convergence
is described by the convergence rate or rate of convergence. The rate of convergence for a

132
Roots of Equations
sequence of errors |ek| = |x∗−xk| is the number r ≥1 for which there is a constant C > 0
such that
lim
k→∞
|ek+1|
|ek|r = C .
In order to understand the practical meaning of this limit, think of the error |ek| < 1 to
be small. Then, |ek|r should be much less than |ek| for r > 1. This can be expressed as
|ek|r ≪|ek|, for r > 1. Thus the error of the next iteration will be much smaller than
the error of the previous one and the magnitude will be determined by the exponent r.
Specifically, we will have |ek+1| ≈C|ek|r ≪|ek|.
The case r = 1 requires C < 1, otherwise there is no guarantee that the new error will
be smaller than the previous one. To see this, assume that we perform k iterations of an
iterative method. In practice, we want the error |ek| = |x∗−xk| to decrease so that
|ek+1| = C|ek| ,
which implies
|ek+1| = C|ek| = C2|ek−1| = · · · = Ck|e1| .
For this reason, we need C < 1, otherwise the method will diverge as k →∞.
When r = 1 we say that the method converges linearly, when r = 2 quadratically and so
on. For the bisection method we proved linear convergence in Proposition 5.1 with C = 1/2
and |ek+1| ≤
1
2|ek|. Thus the method converges with rate at least 1. We say “at least”
because it can happen to converge either instantaneously or in general faster than 1 as the
less equal sign suggests. In general, if |ek+1| ≤C|ek|r, then the rate of convergence is at
least of order r meaning that r is the worst case.
When we cannot compute a theoretical estimate for the convergence rate of a numerical
method, or if we want to verify our theoretical estimate, we often find approximations
of the convergence rate experimentally. In order to compute experimentally the rate of
convergence, we compute the errors for three subsequent iterations, let’s say e1, e2, e3. Then
we assume that
|e2| = C|e1|r ,
|e3| = C|e2|r .
Dividing the previous equations we have
|e2|
|e3| =
|e1|
|e2|
r
.
We then solve for r to obtain a formula for approximating the rate of convergence
r =
log |e2|
|e3|
log |e1|
|e2|
.
We use the natural logarithm but sometimes the use of the logarithm with base 10 can
be more informative. Moreover, the experimental estimation of the rate of convergence
requires the knowledge of the exact solution. For this reason, we usually choose a problem
with known solution for testing purposes. This methodology is sometimes called the method
of manufactured solutions.
As an example, we compute the convergence rate for the bisection method numerically
by modifying the previous code.

Bisection Method
133
1
def bisection_rates(f, a, b, tol = 1.e-6):
2
iteration = 0
3
if (f(a) * f(b) < 0.0):
4
e1 = abs(b-a) #initialize e1 arbitrarily
5
e2 = e1*2 #initialize e2
arbitrarily
6
e3 = e1 #initialize e3 arbitrarily
7
while ((b-a)>tol):
8
e1 = e2
9
e2 = e3
10
iteration = iteration + 1
11
x = (a + b)/2
12
if (f(a) * f(x) < 0.0):
13
b = x
14
elif (f(x) * f(b) < 0.0):
15
a = x
16
else:
17
break
18
e3 = np.abs(b-a)
19
rate = np.log(e2/e3)/np.log(e1/e2)
20
print('iteration = ', iteration, 'rate =', rate)
21
else:
22
print('failure')
23
24
return x
25
26
def f(x):
27
y = np.log(x) + x
28
return y
29
30
a = 0.1
31
b = 1.0
32
tol = 1.e-4
33
34
x = bisection_rates(f, a, b, tol)
iteration =
1 rate = 1.0000000000000002
iteration =
2 rate = 0.9999999999999997
iteration =
3 rate = 0.9999999999999993
iteration =
4 rate = 1.0000000000000007
iteration =
5 rate = 1.0000000000000029
iteration =
6 rate = 0.9999999999999971
iteration =
7 rate = 1.0000000000000115
iteration =
8 rate = 0.9999999999999657
iteration =
9 rate = 1.0000000000000682
iteration =
10 rate = 0.9999999999999545
iteration =
11 rate = 0.9999999999998177
iteration =
12 rate = 1.0000000000001823
iteration =
13 rate = 1.0000000000007292
iteration =
14 rate = 0.9999999999992709

134
Roots of Equations
For this particular example the estimated convergence rate is 1. This is a strong indi-
cation that the method converges with rate 1. Note that we do not expect the convergence
rate to be correct from the very first iteration since the values e1, e2, e3 have arbitrary
values.

The convergence of the bisection method can be quite slow and so it may require
a lot of iterations k until the error |x∗−xk| becomes sufficiently small. The bound
of the error |ek| is halved at every step. It is also possible that a good intermediate
approximation may be inadvertently discarded.
Estimation of the number of iterations
Due to the simplicity of bisection method, it is easy to estimate the maximum number of
iterations required in order to achieve a prescribed accuracy. Assume that we want to find
an approximation xk to the root x∗with accuracy at least ε, in the sense that |ek| < ε.
From Proposition 5.1 we have that |ek| ≤(b −a)/2k+1. To ensure that |ek| < ε, we set
b −a
2k+1 < ε .
We solve the last inequality in terms of k and we find that we need at least
k > log(b −a) −log(2ε)
log(2)
,
iterations to achieve the desired accuracy.
For example, consider the initial interval [0, 1] (independent of the equation we solve)
and ε = 10−4. The bisection method requires
k > log(1) −log(2 · 10−4)
log(2)
≈12.29 .
We conclude that the bisection method requires k = 13, which is to say 14 iterations. This
is because we start counting the approximations xk from k = 0.
5.2
Fixed-Point Methods
The bisection method has guaranteed convergence. However it uses almost no information
about f(x) beyond its sign. As an alternative to the bisection method we derive other
methods, known to as fixed-point methods that can converge faster.
The basic idea behind fixed-point methods is the following: Every equation f(x) = 0
can be written in the form x = g(x). We can do this in many different ways. For example,
we can write the equation sin(x) + 1 = 0 as
x = x + sin(x) + 1
or
x = −x sin(x) .
In the first case the function g(x) = x + sin(x) + 1, while in the second case is g(x) =
−x sin(x). Rewriting the original equation f(x) = 0 in the form x = g(x) will result in a
different numerical method with different convergence properties. This is because we will
seek the value x∗such that x∗= g(x∗) instead of seeking the value x∗such that f(x∗) = 0.

Fixed-Point Methods
135
FIGURE 5.2
Geometric interpretation of fixed point x∗= g(x∗).
We saw earlier that the value x∗satisfying f(x∗) = 0 is called root of the function f(x).
The value x∗that satisfies the relation x∗= g(x∗) is called fixed point of g. For this reason,
iterative methods we will derive in this book for finding fixed points of functions are called
fixed-point methods.

A point x∗such that x∗= g(x∗) is called fixed point of g. A fixed-point method
is an iterative method for the approximation of fixed points.
5.2.1
Derivation and implementation
The idea behind fixed-point methods is simple. Since a fixed point x∗satisfies x∗= g(x∗),
this implies that the point (x∗, x∗) = (x∗, g(x∗)) is the point of intersection of the graphs
of y = x and y = g(x). This is depicted in Figure 5.2.
Given an equation f(x) = 0 we first define an appropriate function g(x), and rewrite
our equation as x = g(x). Since there is no unique way to do this, it is a matter of luck
as to whether our method is good or not. In the next section we will see a way to derive a
fixed-point method that excels in terms of speed of convergence, and thus in accuracy.
Given the fixed-point equation x = g(x), we start with an initial guess x0 of the fixed
point x∗. Yes, an initial guess! We can choose (almost) anything we like. We wrote almost
because it is always better to start with a value which is close to the exact solution x∗. If
we have no idea how to make an initial, rough estimate, we can use the bisection method
for a few iterations to find the initial guess x0. Then the fixed-point method continues with
improvements
xk+1 = g(xk)
for
k = 0, 1, 2, . . . .
The algorithm of a generic fixed-point method is described in Algorithm 12.
In practice, similarly to the bisection method, we usually do not store in memory every
approximation in the sequence xk but only the last approximation. Therefore, the implemen-
tation of Algorithm 12 differs slightly from the algorithm itself. In addition to the standard
tolerance for the error, as a stopping criterion we also record the total number of iterations.

136
Roots of Equations
Algorithm 12 Generic fixed-point method
Set a tolerance TOL for the accuracy
Set k = 0
Initialize xk
Set Error = TOL + 1
while Error > TOL do
Compute xk+1 = g(xk)
Error = |xk+1 −xk|
Increase the counter k = k + 1
end while
Return the approximation of the root x∗
1
def fixedpoint(g, x0, tol = 1.e-6, maxit = 100):
2
# g = the function g(x)
3
# x0 = the initial guess of the fixed point x=g(x)
4
# tol = tolerance for the absolute error
5
#
of two subsequent approximations
6
# maxit = maximum number of iterations allowed
7
err = 1.0
8
iteration = 0
9
xk = x0
10
while (error > tol and iteration < maxit):
11
iteration = iteration + 1
12
error = xk
13
xk = g(xk)
14
error= np.abs(error - xk)
15
print ('iteration =', iteration, ', x =', xk)
16
return xk
To test the code, we consider the equation f(x) = 0 with f(x) = x2 −x −1. This
equation has two roots but we are interested in the root x∗= (1 +
√
5)/2, which is known
to as the golden ratio. We can formulate the function g(x) of the fixed-point equation in
many ways. One choice could be the following: We first solve for x2 the original equation
x2 −x −1 = 0 to find x2 = x + 1, and we take the square root to get the fixed-point
equation x = ±√x + 1. Then we choose g(x) = √x + 1, so the fixed-point iteration will be
xk+1 = √xk + 1 for k = 0, 1, 2, . . . . As initial guess of the fixed point we take x0 = 0.
1
def f(x):
2
y = x**2-x-1.0
3
return y
4
def g(x):
5
y = np.sqrt(x+1.0)
6
return y
7
tol = 1.e-4
8
maxit = 50
9
x0 = 0.0
10
x = fixedpoint(g, x0, tol, maxit)
11
print('The approximate solution x is: ', x)
12
print('And the value f(x) is: ', f(x))

Fixed-Point Methods
137
FIGURE 5.3
Geometric representation of the first few iterations xk+1 = g(xk) with x0 = 0 and g(x) =
√x + 1.
iteration = 1 , x = 1.0
iteration = 2 , x = 1.4142135623730951
iteration = 3 , x = 1.5537739740300374
iteration = 4 , x = 1.5980531824786175
iteration = 5 , x = 1.6118477541252516
iteration = 6 , x = 1.616121206508117
iteration = 7 , x = 1.6174427985273905
iteration = 8 , x = 1.617851290609675
iteration = 9 , x = 1.6179775309347393
iteration = 10 , x = 1.6180165422314876
The approximate solution x is:
1.6180165422314876
And the value f(x) is:
-3.9011296748103774e-05
Although we specified the maximum number of iterations to be maxit = 50, the method
converged in 10 iterations within the desired tolerance 10−4.
It is worth discussing in some detail how fixed point methods work geometrically. Start-
ing with the initial guess x0 = 0 we compute the value g(x0), and we set x1 = g(x0).
Practically, we project the point y1 = g(x0) to the straight line y = x by taking x1 = y1.
We continue with the value x1. We compute the value g(x1) and we set y2 = g(x1). We
project again onto the straight line y = x so as x2 = y2, and so on. This is depicted
graphically in Figure 5.3.
Since the equation x = g(x) is not a unique fixed-point representation of the equation
f(x) = 0, we can proceed with a different choice of g(x). Consider again the equation
x2 −x −1 = 0, but now after solving for x2, divide by x to obtain the fixed-point equation
x = 1 + 1
x, with g(x) = 1 + 1
x. For the new fixed-point method we take x0 = 1 to be the
initial guess and we obtain the following results:
1
def g(x):
2
y = 1.0+1.0/x
3
return y
4
tol = 1.e-4
5
maxit = 50

138
Roots of Equations
FIGURE 5.4
Geometric representation of the first few iterations xk+1 = g(xk) with x0 = 1 and g(x) =
1 + 1
x.
6
x0 = 1.0
7
x = fixedpoint(g, x0, tol, maxit)
8
print('The approximate solution x is: ', x)
9
print('And the value f(x) is: ', f(x))
iteration = 1 , x = 2.0
iteration = 2 , x = 1.5
iteration = 3 , x = 1.6666666666666665
iteration = 4 , x = 1.6
iteration = 5 , x = 1.625
iteration = 6 , x = 1.6153846153846154
iteration = 7 , x = 1.619047619047619
iteration = 8 , x = 1.6176470588235294
iteration = 9 , x = 1.6181818181818182
iteration = 10 , x = 1.6179775280898876
iteration = 11 , x = 1.6180555555555556
The approximate solution x is:
1.6180555555555556
And the value f(x) is:
4.822530864223573e-05
We observe that the different function g(x) requires more iterations to converge within
the prescribed accuracy. The geometric interpretation of this new iteration can be seen in
Figure 5.4. Here the projections form a helix. Without being important for the convergence,
it gives an idea of the geometric pattern of the convergence. Specifically, it shows that the
convergence depends not only on the initial condition but also on the shape of the graph of
the function g(x).
Trying different choices for the function g(x) we can get completely different behavior.
For example, taking g(x) = x2 −1 and starting with x0 = 1 the fixed-point iteration never
converges. Specifically, it falls in a square pattern where x2k = 0 and x2k+1 = −1 for
k = 0, 1, 2, . . . . By taking g(x) = x −x2−x−1
2x−1
on the other hand the fixed-point method

Fixed-Point Methods
139
converges in only 5 iterations. The last option is a special case that can be derived following
a methodology known as Newton’s method. We study Newton’s method later in detail.
5.2.2
Theoretical considerations
One question that arose from the previous experiments is the following: What properties
of the function g(x) can influence the convergence of a fixed-point method? The answer to
this question is given in Proposition 5.2.
Proposition 5.2 (Existence of a fixed point). Every continuous function g(x) : [a, b] →
[a, b] has at least one fixed point in the interval [a, b].
Proof. The fact that g(x) : [a, b] →[a, b] implies that the image of g is g([a, b]) ⊂[a, b]. If
g(a) = a or g(b) = b, then the existence of a fixed point is obvious. Suppose that g(a) ̸= a
and g(b) ̸= b. Then we have only one choice: g(a) > a and g(b) < b. We define the function
h(x) = g(x) −x. The function h(x) is continuous in [a, b], and, moreover, because of our
hypothesis we have h(a) = g(a) −a > 0 and h(b) = g(b) −b < 0. Hence, from Bolzano’s
theorem, there is at least one point x∗∈(a, b) such that h(x∗) = 0 and thus x∗= g(x∗).
Another interesting question is whether the previous fixed point is unique, or not. This is
important to know so that we can be sure that our method converges to the desirable root.
In order to prove the uniqueness of the fixed point, we need to assume further regularity
for the function g(x). Specifically, we need to assume that g(x) is Lipschitz continuous
function, and in particular a contraction. For simplicity we will relax this requirement to
|g′(x)| ≤K < 1 for all x ∈[a, b].
Proposition 5.3 (Uniqueness of a fixed point). If g ∈C1[a, b], i.e. g is continuously
differentiable function, and g(x) ∈[a, b] for x ∈[a, b] and let also
|g′(x)| ≤K < 1,
for all x ∈[a, b] ,
then the function g has a unique fixed point.
Proof. The existence of fixed point has been proven in Proposition 5.2. To prove the unique-
ness of the fixed point we assume (for contradiction) that there are two fixed points x∗and
x∗∗in [a, b] such that x∗̸= x∗∗. By the Mean Value Theorem of differential calculus (see
Theorem 4.3) there exists ξ ∈(x∗, x∗∗) such that
g′(ξ) = g(x∗) −g(x∗∗)
x∗−x∗∗
.
Since |g′(x)| ≤K < 1 for all x ∈[a, b], we have that
|x∗−x∗∗| = |g(x∗) −g(x∗∗)| = |g′(ξ)||x∗−x∗∗| < |x∗−x∗∗| ,
(5.1)
which is a contradiction. Therefore, the hypothesis of two fixed points is wrong, and thus
the fixed point is unique.
To illustrate the applicability of the previous propositions, consider the function g(x) =
x2−1
3
in the interval [−1, 1]. It is easy to verify that g(x) ∈[−1, 1] for all values x ∈[−1, 1].
Moreover, g(x) is differentiable and
|g′(x)| =

2x
3
 ≤2
3 < 1 ,

140
Roots of Equations
for all x ∈(−1, 1). We conclude then that the function g(x) has a unique fixed point in the
interval (−1, 1).
Note that the requirement for differentiability and for the derivative to be |g′(x)| <
K < 1 can be replaced by the assumption that the function g is a contraction (Lipschitz
continuous with constant K < 1). Then for all values of x and y there is a constant 0 < K <
1 such that |g(x) −g(y)| < K|x −y| and inequality (5.1) can be replaced by the inequality
|x∗−x∗∗| = |g(x∗) −g(x∗∗)| < K|x∗−x∗∗| < |x∗−x∗∗| .
The rest of the proof need no modifications. To review Lipschitz continuous functions see
Section 4.2.
5.2.3
Convergence of fixed-point methods
A fixed-point method xk+1 = g(xk) for k = 0, 1, 2, . . . with an initial guess x0 and ap-
propriate function g(x) can generate a sequence of approximations to the solution of the
fixed-point equation x∗= g(x∗). We saw that the condition |g′(x)| ≤K < 1 (or if g is a
contraction) guarantees the uniqueness of the fixed point. Under the same condition the
fixed-point method generates a convergent sequence to the fixed point x∗. The following
proposition gives a sufficient condition for the convergence of the generic fixed-point method.
Proposition 5.4. Let g(x) has a fixed point x∗and is such that
|g′(x)| ≤K < 1 .
Then the sequence {xk}k∈N generated by the fixed-point method xk+1 = g(xk) converges to
x∗for any given initial guess x0 in the domain of the function g.
Proof. In order to prove convergence we consider the error
ek = xk −x∗,
(5.2)
and we show that the sequence ek tends to zero as k →∞.
From (5.2) we have that xk = x∗+ ek and xk+1 = x∗+ ek+1. Since xk+1 = g(xk) for
k = 0, 1, 2, . . . , we have that
x∗+ ek+1 = g(x∗+ ek) .
With the help of the Mean Value Theorem of differential calculus and the hypothesis
|g′(x)| ≤K < 1 we get
|ek+1| = |xk+1 −x∗|
= |g(xk) −g(x∗)|
= |g′(ck)| |xk −x∗|
[ for some ck between xk and x∗]
≤K|xk −x∗|
= K|ek| .
Thus,
|ek+1| ≤K|ek| ≤K2|ek−1| ≤· · · ≤Kk|e0| .
Taking the limits k →∞in the above inequality leads to
lim
k→∞|ek+1| ≤lim
k→∞Kk|e0| = 0 ,
since K < 1. This means that the error converges to zero and thus the iteration converges
to x∗.

Newton’s Method
141
The condition |g′(x)| < K < 1 was used only after the Mean Value Theorem to show
that
|g(xk) −g(x∗)| = |g′(ck)| |xk −x∗| ≤K|xk −x∗| .
The middle step can be omitted without modifying the proof essentially if we assume that
g is a contraction. Specifically, if |g(x) −g(y)| ≤K|x −y| for 0 < K < 1 and for all x, y,
then we have the same result without assuming that g is differentiable. Notice also that in
the proof of the Proposition 5.4 the constant ck is between xk and x∗, and since xk →x∗
then ck →x∗. Thus, if g′ is continuous, then g′(ck) →g′(x∗). This yields
lim
k→∞
|ek+1|
|ek|
= |g′(x∗)| .
We observe that if g′(x∗) = 0, then it is expected that the method converges with r > 1.

It is impossible to describe the convergence rate of a generic fixed-point method
since it depends on the choice of g(x). To estimate experimentally the convergence
rate of a generic fixed-point method, we can use the numerical procedure described
in Section 5.1.3. In the next section we describe a fixed-point method with quadratic
convergence rate.
5.3
Newton’s Method
Newton’s method (also known as the Newton-Raphson method named after Sir Isaac New-
ton (1662–1726) and Joseph Raphson (1668–1712)) is a particular fixed-point method with
quadratic convergence rate. Newton’s method is considered one of the most efficient iterative
methods for the approximation of roots of functions. The success of this method is based
on the fact that the tangent line of f at some point (xk, f(xk)) is a good approximation of
f(x) around that point2. So instead of computing the exact zero of f(x) we compute the
root of its tangent line. This idea is depicted in Figure 5.5.
5.3.1
Derivation and implementation
Newton’s method is a fixed-point method. For this reason, we start again with an initial
guess x0 close to the actual root x∗. Then we set up a sequence of approximations {xk}k∈N
to the root x∗by approximating the function f using its tangent line. Assume that we have
computed the approximation xk for some k ∈N, and that the function f is differentiable.
The tangent line to the function f(x) at the point (xk, f(xk)) is described by the equation
y = f ′(xk)x + b ,
(5.3)
where b has to be found. We can find the constant b using the fact that the tangent line
passes through the point (xk, f(xk)). Specifically, substituting x = xk and y = f(xk) in
(5.3) yields f(xk) = f ′(xk)xk + b. Solving the last equation for b we get
b = f(xk) −f ′(xk)xk .
2The approximation of f(x) by its tangent is also called linearization.

142
Roots of Equations
FIGURE 5.5
Geometric interpretation of Newton’s method. The function f and its tangent at (xk, f(xk)).
Substituting b into (5.3) we obtain the equation for the tangent line y = f ′(xk)x + f(xk) −
f ′(xk)xk. Rearranging the terms in the last formula we have
y = f ′(xk)(x −xk) + f(xk) .
(5.4)
Now we can approximate the root of the function f with the root of its tangent line.
Denote the root of the tangent line by xk+1 such as
0 = f ′(xk)(xk+1 −xk) + f(xk) .
The root of the tangent line xk+1 is our new approximation to x∗. Solving the last equation
for the new approximation xk+1 we obtain the iteration
xk+1 = xk −f(xk)
f ′(xk) ,
(5.5)
known to as Newton’s iteration. Newton’s iteration is a fixed-point iteration xk+1 = g(xk)
with
g(x) = x −f(x)
f ′(x) .
The form of this function leads also to the idea of a more general class of fixed-point methods
(relaxation methods) based on functions g of the form g(x) = x −M(x) · f(x) where M(x)
can be any appropriate function leading to convergence of the iterative method, [132].
Alternative derivation
The previous derivation is based on our geometric intuition. Here we derive the same method
using a more formal derivation which also gives us an idea of the error in the approximation.
This alternative derivation is based on Taylor’s polynomials.
Let xk be an approximation of the root x∗. The Taylor polynomial of degree one about
the current Newton iteration xk is
f(x) = f(xk) + f ′(xk)(x −xk) + O((x −xk)2) ,
where the O((x −xk)2) denotes terms of the specific order. Since x is near xk these terms
will not be important. Evaluating the first order Taylor polynomial at x = x∗we get
f(x∗) = f(xk) + f ′(xk)(x∗−xk) + O(e2
k) ,

Newton’s Method
143
where ek = x∗−xk. Since x∗is the exact root of the function f(x) we have f(x∗) = 0, and
thus
0 = f(xk) + f ′(xk)(x∗−xk) + O(e2
k) .
(5.6)
From this formula we conclude that the anticipated error is expected to be of O(e2
k), which
is of second order. Discarding the error term and solving equation (5.6) in terms of x∗we
get
x∗≈xk −f(xk)
f ′(xk) .
Setting the right-hand side of the previous formula equal to xk+1 yields again the Newton
iteration
xk+1 = xk −f(xk)
f ′(xk) .
A complete algorithm of Newton’s method is presented in Algorithm 13.
Algorithm 13 Newton’s method
Set a tolerance TOL for the accuracy
Set the maximum number of iterations MAXIT
Set k = 0
Initialize xk and Error = TOL + 1
while Error > TOL and k < MAXIT do
if f ′(xk) ̸= 0 then
Compute xk+1 = xk −f(xk)
f ′(xk)
Error = |xk+1 −xk|
Increase the counter k = k + 1
end if
end while
Return the approximation of the root x∗
Newton’s method requires the knowledge and the computation of the derivative f ′ at
each step, and this can cause delays. It also requires division by f ′(xk). For this reason,
every time we perform the division we need to check if the derivative is zero or not. Because
of floating point errors, instead of checking whether f ′(xk) ̸= 0 it is better practice to check
whether f ′(xk) is greater than a tolerance. For example, we usually check if |f ′(xk)| > ε
for some very small value ε. The parameter ε can be chosen quite small such as 10−10.
Alternatively, we can check if |f ′(xk)| is close to zero using the NumPy function isclose
where again we need to provide a tolerance. More information about this function can be
found online.
To keep the algorithm simple we do not verify if the derivative becomes zero. This task
is left as an exercise for the reader. An implementation of the previous algorithm in Python
can be the following
1
def newton(f, df, x0, tol = 1.e-6, maxit = 100):
2
# f = the function f(x)
3
# df = the derivative of f(x)
4
# x0 = the initial guess of the solution
5
# tol = tolerance for the absolute error
6
# maxit = maximum number of iterations
7
err = 1.0
8
iteration = 0

144
Roots of Equations
9
xk = x0
10
while (err > tol and iteration < maxit):
11
iteration = iteration + 1
12
err = xk # store previous approximation to err
13
xk = xk - f(xk)/df(xk) # Newton's iteration
14
err = np.abs(err - xk) # compute the new error
15
print(iteration, xk)
16
return xk
We test our new method for the equation
ln x + x = 0 .
This is the same equation we used to test the bisection method before. The difference here
is that we do not need to specify any initial interval but an initial guess of x∗. We take the
value x0 = 1 as an initial guess. In this case, f(x) = ln x + x and f ′(x) = 1
x + 1.
1
def f(x):
2
y = np.log(x) + x
3
return y
4
def df(x):
5
y = 1.0 / x + 1.0
6
return y
7
tol = 1.e-4
8
maxit = 50
9
x0 = 1.0
10
x = newton(f, df, x0, tol, maxit)
11
print('The aproximate solution is: ', x)
12
print('And the error is: ', f(x))
1 0.5
2 0.5643823935199818
3 0.5671389877150601
4 0.5671432903993691
The approximate solution x is:
0.5671432903993691
And the value f(x) is:
-2.877842408821607e-11
Observe that even if the tolerance tol=1.e-4 was the same as in the bisection method,
Newton’s method converged to a better approximation with only 4 iterations! This is an in-
dication (in accordance with the derivation of the method) that the method is quadratically
convergent.
We have already noted that Newton’s method is a fixed-point method with
g(x) = x −f(x)
f ′(x) .
If f is twice-differentiable in a neighborhood of the root x∗, then we have
g′(x) = 1 −(f ′(x))2 −f(x) f ′′(x)
(f ′(x))2
= f(x) f ′′(x)
(f ′(x))2
.

Newton’s Method
145
Thus, if f ′(x∗) ̸= 0, then g′(x∗) = 0, and according to the remarks in Section 5.2.3 we
expect the convergence rate to be r > 1. We prove that the convergence rate is indeed
r = 2.

Newton’s method is a particular fixed-point method that is expected to converge
with rate of order 2. Downsides of Newton’s method include the requirement of the
derivative f ′(xk) at every iteration. If f is not differentiable, Newton’s method cannot
be applied.
5.3.2
Rate of convergence
In this section we prove that Newton’s method converges with quadratic rate. We saw that
Newton’s method is a fixed-point method of the form
xk+1 = g(xk)
with
g(x) = x −f(x)
f ′(x) .
Denoting the errors of two successive iterations by
ek+1 = xk+1 −x∗
and
ek = xk −x∗,
we have that
xk+1 = x∗+ ek+1
and
xk = x∗+ ek .
Substitution into xk+1 = g(xk) and using Taylor’s expansion yields
x∗+ ek+1 = g(x∗+ ek) = g(x∗) + g′(x∗)ek + g′′(ξ)
2!
e2
k ,
where ξ is between xk and xk+1. Because x∗and g(x∗) are canceled out we obtain
ek+1 = g′(x∗)ek + g′′(ξ)
2!
e2
k .
(5.7)
We saw that
g′(x) = 1 −(f ′(x))2 −f(x)f ′′(x)
(f ′(x))2
= f(x)f ′′(x)
(f ′(x))2
,
which evaluated at x = x∗becomes
g′(x∗) = f(x∗)f ′′(x∗)
f ′(x∗)2
= 0 ,
since f(x∗) = 0 by definition (assuming f ′′(x∗) and f ′(x∗) are behaved appropriately). The
expansion (5.7) simplifies to
ek+1 = g′′(ξ)
2!
e2
k,
and thus
|ek+1| =

g′′(ξ)
2!
 |ek|2.
Newton’s method is therefore quadratically convergent where the constant g′′(ξ)
2
is controlled
by the second derivative of g. The requirement for the function g to be twice differentiable
is not necessary. It suffices that f is twice continuously differentiable to establish conver-
gence of Newton’s method with appropriate initial guess. This can be seen in the following
theorem.

146
Roots of Equations
Theorem 5.5. Let f be twice continuously differentiable function and x∗a simple root of
f. That is f(x∗) = 0 and f ′(x∗) ̸= 0. Then, there is a closed interval [a, b] such that the
sequence {xk}k∈N of Newton’s iterations given by the recursive formula
xk+1 = xk −f(xk)
f ′(xk) ,
converges to the root x∗for any initial guess x0 ∈[a, b]. Moreover, the convergence is
quadratic with
lim
k→∞
ek+1
e2
k
= f ′′(x∗)
2f ′(x∗) ,
where ek = xk −x∗and ek+1 = xk+1 −x∗.
Proof. First we prove the convergence with the relaxed assumptions required by the theo-
rem. Since f is twice continuously differentiable, then the function g(x) = x −f(x)/f ′(x)
is just continuously differentiable with g′(x∗) = 0. Since g′(x∗) = 0 we can find a closed
interval [a, b] that contains x∗∈[a, b] by choosing a and b to be very close to x∗if necessary
such that
max
x∈[a,b] |g′(x)| ≤K < 1 .
From Proposition 5.4 we have that the sequence xk+1 = g(xk) converges to x∗, with error
ek = xk −x∗→0 as k →∞.
Now we are ready to estimate the convergence rate of Newton’s iterations. Since f is
twice continuously differentiable we have the following Taylor expansions for the function
f and its derivative
f(xk) = f(x∗) + (xk −x∗)f ′(x∗) + (xk −x∗)2
2
f ′′(ck) ,
f ′(xk) = f ′(x∗) + (xk −x∗)f ′′(dk) ,
where ck and dk between xk and x∗. Substituting these expansions into the Newton iteration
xk+1 = xk −f(xk)/f ′(xk) we get
xk+1 = xk −ekf ′(x∗) + 1
2e2
kf ′′(ck)
f ′(x∗) + ekf ′′(dk)
,
which can be written as
xk+1 −x∗= xk −x∗−ekf ′(x∗) + 1
2e2
kf ′′(ck)
f ′(x∗) + ekf ′′(dk)
.
Using the notation ek = xk −x∗, we write the previous relationship in the form
ek+1 = ek −ekf ′(x∗) + 1
2e2
kf ′′(ck)
f ′(x∗) + ekf ′′(dk)
= e2
kf ′′(dk) + 1
2e2
kf ′′(ck)
f ′(x∗) + ekf ′′(dk)
.
Dividing both sides by e2
k we obtain
ek+1
e2
k
= f ′′(dk) −1
2f ′′(ck)
f ′(x∗) + ekf ′′(dk) .
Taking the limit as k →∞we have
lim
k→∞
ek+1
e2
k
= f ′′(x∗)
2f ′(x∗) ,
because ck →x∗and dk →x∗since ck and dk are between xk and x∗.

Secant Method
147
FIGURE 5.6
An example of Newton’s method failure.
The existence of a particular interval [a, b] from which we can choose initial guess accord-
ing to Theorem 5.5 is very important. For example, let’s consider the function f(x) = xe−x2,
which has the root x∗= 0. Starting with the initial guess x0 = 1/2, Newton’s method fails
to converge as it leads to an infinite loop generating a sequence of repeating approximations
x2k = 1/2 and x2k+1 = −1/2 for all k = 0, 1, 2, . . . . Starting with any value x0 larger than
1/2 (or smaller than −1/2) results in a divergent sequence because the initial guess is far
away from the exact root. On the contrary, starting with any value x0 with |x0| < 1/2 the
method converges rapidly.
This particular case of convergence failure is depicted in Figure 5.6. It is observed that
starting from x0 = ±0.5, the tangent lines are parallel and they return to the same point
at every iteration. If we don’t implement a stopping criterion for the maximum number of
iterations, the code would never stop. Another case where Newton’s method can fail is in
the same example when we choose x0 = ±1/
√
2. In this case, we have that f ′(x0) = 0, and
thus the tangent line is parallel to the x-axis.
In all these unfortunate situations we need to choose a different value x0 closer to the
value x∗. Initial guesses, lying closer to x∗, can be obtained with a few iterations of the
bisection method.

To ensure Newton’s method convergence choose an initial guess close to the
exact root x∗where f ′(x0) ̸= 0. Such initial guess can be obtained using the bisection
method.
5.4
Secant Method
One of the main disadvantages of Newton’s method is the involvement of the derivative f ′(x)
in its recursive formula. This can be a significant drawback especially when we solve large
systems of nonlinear equations. In order to overcome this requirement we can substitute the
first derivative with an appropriate approximation of it, leading to a different fixed-point
method. One such method is the secant method.

148
Roots of Equations
5.4.1
Derivation and implementation
The secant method relies on the modification of Newton’s method using a particular ap-
proximation of the first derivative f ′(xk). Assume that we know at least two approximations
of the root x∗, namely xk−1 and xk. The Taylor polynomial of degree one about xk for the
function f(x) is
f(x) = f(xk) + f ′(xk)(x −xk) + O((x −xk)2) .
Evaluating this polynomial at x = xk−1 yields
f(xk−1) = f(xk) + f ′(xk)(xk−1 −xk) + O((xk −xk−1)2) .
Solving for the first derivative f ′(xk) we get that
f ′(xk) = f(xk) −f(xk−1)
xk −xk−1
+ O(xk −xk−1) .
Discarding the residual in the last equation, we obtain the approximation of the first deriva-
tive
f ′(xk) ≈f(xk) −f(xk−1)
xk −xk−1
.
(5.8)
Such a formula is called finite difference approximation of the first derivative. The specific
approximation can be quite accurate when the values xk−1 and xk are very close. This can
be seen from the residual, which is O(xk −xk−1). Alternatively, the same approximation
can be obtained by the definition of the first derivative
f ′(xk) = lim
x→xk
f(x) −f(xk)
x −xk
.
From this definition, if we choose x = xk−1 very close to xk, we get the same approximation
as before.
Substituting the approximation of the derivative (5.8) into Newton’s iteration (5.5)
xk+1 = xk −f(xk)
f ′(xk), we obtain
xk+1 = xk −
f(xk)
f(xk)−f(xk−1)
xk−xk−1
,
or in a more compact form
xk+1 = xk −
xk −xk−1
f(xk) −f(xk−1)f(xk) .
(5.9)
This can be written also as
xk+1 = f(xk)xk−1 −f(xk−1)xk
f(xk) −f(xk−1)
,
for k = 0, 1, 2, . . . .
There is one small issue: In order to compute the first improved approximation x1 of the
root x∗we need two initial guesses of the root x∗, namely x−1 and x0 with x−1 ̸= x0. If we
have only one guess for the value x0, then we can take the second guess to be x−1 = x0±∆x
for a small value ∆x.
The secant method is a relaxation-type method of the form xk+1
=
xk −
M(xk, xk−1)f(xk). The main difference between the secant method and Newton’s method

Secant Method
149
FIGURE 5.7
Geometric interpretation of the secant method.
is that the secant method approximates the root with the point of intersection between the
x-axis and a secant line with slope f(xk)−f(xk−1)
xk−xk−1
. This is depicted in Figure 5.7.
The algorithm for the secant method is summarized in Algorithm 14.
Algorithm 14 Secant method
Set a tolerance TOL for the accuracy
Set the maximum number of iterations MAXIT
Initialize xk−1 and xk and set k = 0
Set Error = |xk −xk−1|
while Error > TOL and k < MAXIT do
Compute new xk+1 = xk −
xk−xk−1
f(xk)−f(xk−1)f(xk)
Set Error = |xk+1 −xk|
Increase the counter k = k + 1
end while
Return the approximation xk of the root x∗
In this algorithm we assume that the values xk−1 ̸= xk. In some examples, the initial
guesses are computed using bisection or other methods and so we should not worry about
their choice. To keep things simple here, we consider the initial guesses manually.
The algorithm for the secant method can be implemented in Python as follows
1
def secant(f, x1, x2, tol = 1.e-6, maxit = 100):
2
# f = the function f(x)
3
# x1 = an initial guess of the solution
4
# x2 = another initial guess of the solution
5
# tol = tolerance for the absolute error
6
# maxit = maximum number of iterations
7
err = 1.0
8
iteration = 0
9
while (err > tol and iteration < maxit):
10
xk = x1
11
xk1 = x2

150
Roots of Equations
12
iteration = iteration + 1
13
err = xk1
14
xk1 = xk - (xk-xk1)/(f(xk)-f(xk1))*f(xk)
15
err = np.abs(err - xk1)
16
x1 = x2
17
x2 = xk1
18
print(iteration, xk1)
19
return xk1
Testing this new method for the equation
ln x + x = 0 ,
with initial guesses x−1 = 1 and x0 = 2, we obtain the following results:
1
def f(x):
2
y = np.log(x) + x
3
return y
4
tol = 1.e-4
5
maxit = 50
6
x1 = 1.0
7
x2 = 2.0
8
x = secant(f, x1, x2, tol, maxit)
9
print('The approximate solution is: ', x)
10
print('And the error is: ', f(x))
1 0.40938389085035876
2 0.651575386390747
3 0.5751035382227284
4 0.5667851889083253
5 0.5671448866112347
6 0.5671432907314143
The approximate solution x is:
0.5671432907314143
And the value f(x) is:
8.887366398369068e-10
Observe that the secant method required 6 iterations to satisfy the same stopping criteria
with Newton’s method. This indicates that the secant method is slower than Newton’s
method. This is indeed the price we pay for approximating the derivative f ′(xk) using a
finite difference quotient. The secant method converges with convergence rate r ≈1.62,
which is smaller than Newton’s method convergence rate but still greater than 1. This fact
makes the secant method appealing.

The secant method is based on Newton’s iteration with the difference that the
first derivative is approximated by a finite difference quotient. The price we pay for
using the finite difference approximation to the derivative is a few extra iterations
for convergence. The convergence rate of the secant method is equal to the golden
ratio r = 1.6180 · · · .

Secant Method
151
5.4.2
Rate of convergence
Proving convergence for the secant method is a difficult task. For this reason, first we
estimate the convergence rate and then we proceed with a formal proof of convergence.
Because the formal proof is too technical you can skip it and proceed with an experimental
verification of the convergence rate as described in Section 5.1.3.
In order to estimate the rate of convergence of the secant method we define the errors
ek−1 = xk−1 −x∗, ek = xk −x∗and ek+1 = xk+1 −x∗. We will show that
lim
k→∞
|ek+1|
|ek|r = C ,
where r = (1 +
√
5)/2 and C > 0 constant.
Starting with the error ek+1 we have that
ek+1 = xk+1 −x∗
= xk −
xk −xk−1
f(xk) −f(xk−1)f(xk) −x∗
= ek −
xk −xk−1
f(xk) −f(xk−1)f(xk)
=
xk −xk−1
f(xk) −f(xk−1)
f(xk) −f(xk−1)
xk −xk−1
ek −f(xk)

=
xk −xk−1
f(xk) −f(xk−1)
f(xk) −f(xk−1)
xk −xk−1
−f(xk)
ek

ek
=
xk −xk−1
f(xk) −f(xk−1)
"
f(xk) −f(xk−1) −f(xk)
ek (xk −xk−1)
xk −xk−1
#
ek
=
xk −xk−1
f(xk) −f(xk−1)
"
f(xk) −f(xk−1) −f(xk)
ek (xk −x∗+ x∗−xk−1)
xk −xk−1
#
ek
=
xk −xk−1
f(xk) −f(xk−1)
"
f(xk) −f(xk−1) −f(xk)
ek (ek −ek−1)
xk −xk−1
#
ek
=
xk −xk−1
f(xk) −f(xk−1)
"
−f(xk−1) + f(xk)
ek ek−1
xk −xk−1
#
ek ,
or equivalently,
ek+1 =
xk −xk−1
f(xk) −f(xk−1)


f(xk)
ek
−f(xk−1)
ek−1
xk −xk−1

ekek−1 .
(5.10)
Now we simplify the fractions in the previous relation. The second order Taylor expansion
of f(xk) about x∗is
f(xk) = f(ek + x∗) = f(x∗) + ekf ′(x∗) + 1
2e2
kf ′′(x∗) + O(e3
k) .
Since f(x∗) = 0 we have that f(xk) = ekf ′(x∗) + 1
2e2
kf ′′(x∗) + O(e3
k). After discarding the
residual and dividing by ek we get
f(xk)
ek
≈f ′(x∗) + 1
2ekf ′′(x∗) .
(5.11)

152
Roots of Equations
Similarly we have that
f(xk−1)
ek−1
≈f ′(x∗) + 1
2ek−1f ′′(x∗) .
(5.12)
Eliminating the term f ′(x∗) from the relations (5.11) and (5.12) yields
f(xk)
ek
−f(xk−1)
ek−1
≈1
2(ek −ek−1)f ′′(x∗) .
Since ek −ek−1 = xk −x∗−xk−1 + x∗= xk −xk−1 we get
f(xk)
ek
−f(xk−1)
ek−1
xk −xk−1
≈1
2f ′′(x∗) .
(5.13)
For the first ratio in (5.10) we have that
xk −xk−1
f(xk) −f(xk−1) ≈
1
f ′(x∗) .
(5.14)
Substituting (5.13) and (5.14) into (5.10) we get
ek+1 ≈1
2
f ′′(x∗)
f ′(x∗) ekek−1 ,
(5.15)
and thus
|ek+1| ≈C|ek||ek−1| ,
(5.16)
with
C = 1
2
|f ′′(x∗)|
|f ′(x∗)| .
If f ′′(x∗) ̸= 0 and f ′(x∗) ̸= 0, then C > 0. If the rate of convergence is r > 1, then dividing
both sides of (5.16) by |ek|r gives
|ek+1|
|ek|r ≈C|ek|1−r|ek−1| = C

|ek|
|ek−1|r
α
,
(5.17)
where the last equality holds for α = 1 −r and α = −1/r. Thus, 1 −r = −1/r and so
r2 −r −1 = 0, which has root r > 1,
r = 1 +
√
5
2
≈1.62 .
Therefore, if we knew that the sequence yk = |ek+1|
|ek|r converges to some constant C > 0 then
we get the desired convergence
lim
k→∞
|ek+1|
|ek|r = C ,
with rate is r = (1 +
√
5)/2.
The number r = (1 +
√
5)/2 is called the golden ratio and is known since the era of
Euclid. A ratio r between two positive numbers a > b > 0 is called golden ratio if it is
r = a
b = a + b
a
.
In other words, if a and b are lengths in which we split a straight line with a > b > 0, then
the ratio r = a/b is called golden if it is equal to the ratio between the length of the whole
line a + b and the largest length a.

Secant Method
153
Proof of convergence
While the previous estimation is very enlightening it does not suggest a formal proof of
convergence. On the other hand, it is crucial to know that our numerical method converges
to the correct solution. In order to have a complete theory for the secant method we proceed
with its rigorous proof of convergence. First we present a lemma which makes the proof a
little easier. This lemma estimates the difference between a function f and its secant passing
through two points of f.
Lemma 5.6. If f ∈C2[a, b], xk−1, xk ∈[a, b], xk−1 ̸= xk and there is a polynomial p ∈P1
of degree at most one such that p(xk−1) = f(xk−1) and p(xk) = f(xk), then for all x ∈[a, b]
there is a ξ ∈J := (min{x, xk−1, xk}, max{x, xk−1, xk}) such that
f(x) −p(x) = (xk−1 −x)(xk −x)
2
f ′′(ξ) .
Proof. For x = xk−1 and x = xk the lemma is obviously true since for such values of x we
have f(x) −p(x) = 0. For x ∈[a, b] with x ̸= xk−1, xk, we define the function h : [a, b] →R
such as
h(t) = f(t) −p(t) −
f(x) −p(x)
(xk−1 −x)(xk −x)(xk−1 −t)(xk −t) .
We observe that h ∈C2[a, b] and h(xk−1) = h(xk) = h(x) = 0. According to Rolle’s
Theorem (Theorem 4.2) the second derivative h′′(t) has at least one root ξ in the interval
J. Since p is a linear polynomial, p′′(t) = 0 and thus
h′′(t) = f ′′(t) −2
f(x) −p(x)
(xk−1 −x)(xk −x) ,
which implies
0 = h′′(ξ) = f ′′(ξ) −2
f(x) −p(x)
(xk−1 −x)(xk −x) .
Solving for f(x) −p(x) we get the relationship
f(x) −p(x) = (xk−1 −x)(xk −x)
2
f ′′(ξ) ,
and this completes the proof.
Now we state the theorem of convergence of the secant method.
Theorem 5.7. If f ∈C2(a, b) with a simple root x∗such that f ′(x∗) ̸= 0 and f ′′(x∗) ̸= 0,
then there is an interval I, which contains the root x∗, such that for x−1, x0 ∈I, with
x−1 ̸= x0, the sequence {xk}k∈N generated by the secant method
xk+1 = xk −
xk −xk−1
f(xk) −f(xk−1)f(xk) ,
(5.18)
for k = 0, 1, . . . , converges to x∗as k →∞with rate the golden ratio r = (1 +
√
5)/2.
Proof. We first define the polynomial
p(x) := f(xk) −f(xk) −f(xk−1)
xk −xk−1
(xk −x) .
(5.19)

154
Roots of Equations
We observe that p(xk) = f(xk) and also p(xk−1) = f(xk−1). Taking x = xk+1 in
(5.19) and using (5.18) we can verify that p(xk+1) = 0. From Lemma 5.6 there is a
ξk ∈(min{x, xk−1, xk}, max{x, xk−1, xk}) for any k = 0, 1, 2, . . . such that
f(x∗) −p(x∗) = (xk−1 −x∗)(xk −x∗)
2
f ′′(ξk) .
Since f(x∗) = 0 and p(xk+1) = 0 we rewrite the previous relations as
p(x∗) −p(xk+1) = −(xk−1 −x∗)(xk −x∗)
2
f ′′(ξk) .
(5.20)
We subtracted p(xk+1) because
p(x∗) −p(xk+1) = f(xk) −f(xk) −f(xk−1)
xk −xk−1
(xk −x∗)−
−

f(xk) −f(xk) −f(xk−1)
xk −xk−1
(xk −xk+1)

= −f(xk) −f(xk−1)
xk −xk−1
[(xk −x∗) −(xk −xk+1)]
= f(xk) −f(xk−1)
xk −xk−1
(xk+1 −x∗) ,
and thus (5.20) becomes
(xk+1 −x∗)f(xk) −f(xk−1)
xk −xk−1
= −(xk−1 −x∗)(xk −x∗)
2
f ′′(ξk) ,
or in other words
ek+1 = −1
2
f ′′(ξk)
xk−xk−1
f(xk)−f(xk−1)
ekek−1 .
From the Mean Value Theorem of differential calculus (see Theorem 4.3), we deduce that
for all k = 0, 1, . . . there is a ζk ∈(min{xk−1, xk}, max{xk−1, xk}) such that
f(xk) −f(xk−1)
xk −xk−1
= f ′(ζk) .
Since f ′(x∗) ̸= 0, f ′ ∈C[a, b], and xk−1, xk are close to x∗, then f ′(ζk) ̸= 0. Therefore, we
have that
ek+1 = −1
2
f ′′(ξk)
f ′(ζk) ekek−1 .
Since we want to estimate the rate of the absolute error we get
|ek+1| = 1
2
|f ′′(ξk)|
|f ′(ζk)| |ek||ek−1| .
(5.21)
Observe that there is 0 < δ < 1 such that
1
2 max
x,y∈I

f ′′(x)
f ′(y)
 ≤c
δ ,

Secant Method
155
for all x, y ∈I = [x∗−δ, x∗+ δ] with c < 1. Then, for x−1, x0 ∈I, (5.21) implies that
|e1| = |x1 −x∗| < δ and thus x2 ∈I. Similarly we conclude that xk ∈I for all k = 1, 2, . . . .
Moreover, from (5.21) we have that
|ek+1| ≤c|ek| ≤ck|e0| ,
and since c < 1 we get that xk →x∗as k →∞. Since ξk and ζk are in between xk−1 and
xk it holds also that ξk →x∗, ζk →x∗and therefore the sequence
Ck = 1
2

f ′′(ξk)
f ′(ζk)

converges to
C = 1
2

f ′′(x∗)
f ′(x∗)
 .
Moreover, we can write (5.21) in the form |ek+1| = Ck|ek||ek−1| , with lim
k→∞Ck = C .
As in (5.17), if r is the rate of convergence, then
|ek+1|
|ek|r = Ck

|ek|
|ek−1|r
−1/r
,
(5.22)
with r = (1 +
√
5)/2. Denoting the sequence yk =
|ek|
|ek−1|r , we rewrite (5.22) yk+1 = Ckyq
k,
with q = −1/r. We prove that the sequence {yk}k∈N converges with limk→∞yk = ℓ̸= 0. In
fact we have
yk+1 = CkCq
k−1Cq2
k−2 · · · Cqk
0 yqk+1
0
,
or after setting ck = Ck/C,
yk+1 = C1+q+···qkckcq
k−1cq2
k−2 · · · cqk
0 yqk+1
0
.
Because |q| = 1/r < 1 and 1 −r = q = −1/r, we have
C1+q+···qkckcq
k−1cq2
k−2 · · · cqk
0 = C
1−qk+1
1−q
→C
1
1−q = C
1
r , as k →∞,
and
lim
k→∞yqk+1
0
= y0
0 = 1 .
Denoting s = |q| < 1 then we have
log

ckcq
k−1cq2
k−2 · · · cqk
0
 =
log ck + q log ck−1 + · · · + qk log c0

≤| log ck| + s| log ck−1| + · · · + sk| log c0| .
For ε > 0, let K > 0 such that | log ck| < ε for k ≥K. Then
log

ckcq
k−1cq2
k−2 · · · cqk
0
 ≤ε(1 + s + s2 + · · · sk−K) + sk−K+1 max
i
log |ci| ,
from which we conclude that
lim
k→∞

ckcr
k−1 · · · crk
0

= 1 .
Thus
lim
k→∞yk = C
1
r = ℓ,
and this completes the proof.

156
Roots of Equations
5.5
Other Methods and Generalizations
So far we have discussed three classical numerical methods for the approximation of simple
roots of functions. However, there are problems where we need to compute roots of mul-
tiplicity m > 1 or solve systems of nonlinear equations. These issues among many others
require further investigation. Here we present briefly extensions to some of the previous
methods and how to deal with more general problems.
5.5.1
Stopping criteria
All iterative methods we studied in this chapter generate sequences of approximations xk.
In practice we need to terminate the iterations when the value of xk is close to the root x∗.
Because we do not usually know the exact value of x∗we are not able to measure the error
|xk −x∗|. On the other hand, if the sequence {xk}k∈N converges to x∗, then for values of
k > K for some K ∈N the error |xk −x∗| < ε becomes small. This inequality yields
|xk+1 −xk| = |xk+1 −x∗+ x∗−xk| ≤|xk+1 −x∗| + |xk −x∗| < 2ε ,
for k > K. If the difference |xk −x∗| is small, then the difference |xk+1 −xk| is small
too. Thus, instead of checking whether the error |xk −x∗| is small, we check whether the
difference between subsequent approximations |xk+1 −xk| is small. In some cases, it is more
reliable to estimate the relative error |xk+1 −xk|/|xk| instead of the absolute error.
Because of all these, we consider tolerance TOL > 0, and at every iteration step we check
whether |xk+1−xk| < TOL. Depending on the required accuracy, we give appropriate values
to the tolerance TOL, for example, something between 10−5 to 10−15.
As we discussed earlier, there is a possibility of a failure in convergence due to an
unfortunate initial guess x0. It is then useful to include an additional stopping criterion
that restricts the total number of iterations. In the unfortunate event where the maximum
number of iterations has been reached, we can terminate the program with an error message.
The error message can indicate failure in achieving the required accuracy described by the
tolerance TOL within the prescribed number of iterations.
5.5.2
Steffensen’s method
Steffensen’s method is a modification of Newton’s method that bypasses the use of the first
derivative f ′. The advantage of Steffensen’s method compared to the secant method is that
the convergence is quadratic. The Steffensen iteration is
xk+1 = xk −f(xk)
h(xk) ,
with
h(x) = f(x + f(x))
f(x)
−1 .
In order to see the equivalence with Newton’s method we take the Taylor expansion of the
term f(xk + f(xk)), which is
f(xk + f(xk)) = f(xk) + f ′(xk)f(xk) + O
 f 2(xk)

,
and thus
h(xk) = f(xk + f(xk))
f(xk)
−1 ≈f ′(xk) .

Other Methods and Generalizations
157
The function h is practically the average value for the slope of f in the interval [xk, xk +
f(xk)]. Taking into account that as xk approximates the root x∗, then the value f(xk)
becomes very small, and this approximation is very close to the actual slope of the tangent
f ′(xk). The requirement for the Steffensen iteration to converge is that −1 < f ′(x∗) < 0,
which is also the major disadvantage of this method. For other methods that overcome the
barrier of the first derivative please see the exercises at the end of this chapter.
5.5.3
Aitken’s delta-squared process
Aitken’s delta-squared process, also known as the Aitken extrapolation, is a technique to
accelerate the convergence of an iterative method. This technique requires the computation
of three approximations xk, xk+1 and xk+2 of the exact solution x∗. Then, assuming that
xk+1 −x∗
xk −x∗
≈xk+2 −x∗
xk+1 −x∗,
we have that
(xk+1 −x∗)2 ≈(xk+2 −x∗)(xk −x∗) ,
and solving for x∗we get
x∗≈xk+2xk −(xk+1)2
xk+2 −2xk+1 + xk
or equivalently
x∗≈xk −
(xk+1 −xk)2
xk+2 −2xk+1 + xk
.
Setting
xk+3 = xk −
(xk+1 −xk)2
xk+2 −2xk+1 + xk
,
and without using the actual iterative method, we derived an improved approximation. For
this reason, Aitken’s delta-squared process can be used with any of the previously mentioned
numerical methods.
It is worth mentioning that Aitken’s process can lead to Steffensen’s method. Suppose
we know an approximate solution xk of the equation f(x) = 0. Also, assume we write the
last equation as x = g(x). Then, we define xk+1 = g(xk), xk+2 = g(xk+1) as usual, and we
redefine the iteration xk+1 using Aitken’s delta squared method as
xk+1 = xk −
(xk+1 −xk)2
xk+2 −2xk+1 + xk
= xk −
(g(xk) −xk)2
g(g(xk)) −2g(xk) + xk
,
for k = 0, 1, 2, . . . . It remains to choose appropriate function g. By taking the naive fixed-
point function g(x) = x + f(x) in the previous iteration and after simplifying same terms
we obtain
xk+1 = xk −
[f(xk)]2
f(xk + f(xk)) −f(xk) ,
which is exactly the Steffensen method. Therefore, the Steffensen method can be considered
a generic fixed-point method that is similar to Aitken’s delta-squared process.
5.5.4
Multiple roots
So far we assumed that x∗is a simple root of the equation f(x) = 0. This means that
we required f(x∗) = 0 and f ′(x∗) ̸= 0. We say that the root x∗has multiplicity m if
f(x∗) = f ′(x∗) = · · · = f (m−1)(x∗) = 0 and f (m)(x∗) ̸= 0. In such a case, the convergence
of Newton’s method is not quadratic. When we search for roots with multiplicity m > 1 we

158
Roots of Equations
need to modify the formula (5.5) appropriately in order to achieve quadratic convergence
rate.
The modification of Newton’s method is based on the following observation: If x∗is
a root of f(x) with multiplicity m, then f(x) = (x −x∗)mh(x), where h(x) is a function
with no root. The function F(x) =
mp
f(x) has the simple root x∗and thus, according to
Theorem 5.5, we can apply Newton’s method with quadratic convergence rate. Applying
Newton’s method to the function F(x) we get
xk+1 = xk −F(xk)
F ′(xk) = xk −
mp
f(xk)
m√
f(xk)
mf(xk) f ′(xk)
,
which can be simplified to the following modification of Newton’s method
xk+1 = xk −m f(xk)
f ′(xk) .
The modified Newton’s method has similar convergence properties with the classical New-
ton’s method and of course quadratic convergence rate.
5.5.5
High-order methods
It is possible to construct fixed-point methods that converge with cubic rate. One such
example is Halley’s method. The derivation of Halley’s method is based on the observation
that the functions f(x) and F(x) = f(x)/
p
|f ′(x)| have the same simple roots. Instead of
using Newton’s method applied to the function f(x) we can use Newton’s method for the
function F(x). This can be written as
xk+1 = xk −F(xk)
F ′(xk) ,
which can be simplified into the iteration
xk+1 = xk −
2f(xk)f ′(xk)
2[f ′(xk)]2 −f(xk)f ′′(xk) .
This method converges faster than the classical Newton iteration. However, it requires
in addition to the first derivative, the second derivative of f. Newton’s method usually
converges very fast even with quadratic convergence, and taking into account the increased
complexity of Halley’s method, it is nevertheless preferable to use the simple Newton’s
method.
5.5.6
Systems of equations
Suppose that we want to find the solution (x∗, y∗) of the system of simultaneous equations

x −y3 = 1
sin(x) + y = 1
.
(5.23)
Each equation corresponds to a curve on the xy−plane. The solution (x∗, y∗) is the point
of intersection of these curves.
For simplicity, we consider the vector x = (x, y)T and we write our system in the form
F (x) = 0, where F : R2 →R2 is
F (x) =
f1(x, y)
f2(x, y)

.

Other Methods and Generalizations
159
In our case, with only two unknowns, we can write (5.23) in the form F (x) = 0, with
F (x) =
 x −y3 −1
sin(x) + y −1

.
Most of the iterative methods discussed in this chapter can be also applied to systems.
The easiest way to solve such a system is by using the generic fixed-point method. We rewrite
the system as a fixed-point equation x = G(x), where x is now a vector and G a vector
function. The corresponding fixed-point method is x(k+1) = G(x(k)) for k = 0, 1, 2, . . . and
a given initial guess x(0).
In our example a straightforward fixed-point system is
 x = y3 + 1
y = −sin(x) + 1
.
The fixed-point method can be written as
 xk+1 = (yk)3 + 1
yk+1 = −sin(xk) + 1
,
for let’s say (x0, y0) = (0, 0). Note that the iteration index is now appeared as a superscript
to avoid confusion with vector coordinates.
Newton’s method is a little bit more complicated, but is again based on Taylor polyno-
mial for multivariable functions. The Taylor polynomial of degree one for a function F (x)
is the vector function P1(x) such that
F (x) ≈P1(x) = F (x(k)) + DF (x(k))(x −x(k)) ,
where
DF (x) =
 ∂f1
∂x
∂f1
∂y
∂f2
∂x
∂f2
∂y
!
,
is the Jacobian matrix. Here, x = (x, y)T and x(k) = (xk, yk)T . The Jacobian matrix
represents the derivative of a vector function. Taking x = x∗= (x∗, y∗)T in Taylor’s
polynomial we get
0 ≈F (x(k)) + DF (x(k))(x∗−x(k)) .
Solving the last equation for x∗we get the linear system
DF (x(k))x∗≈DF (x(k))x(k) −F (x(k)) .
We solve this linear system by multiplying both sides with the inverse of the Jacobian
matrix to obtain
x∗≈x(k) −[DF (x(k))]−1F (x(k)) .
The new approximation of the solution x∗= (x∗, y∗)T is then defined
x(k+1) = x(k) −[DF (x(k))]−1F (x(k)) ,
for k = 0, 1, 2, . . . with a given initial guess x(0). Newton’s iteration can be expressed in a
more analytical form as
xk+1
yk+1

=
xk
yk

−[DF (xk, yk)]−1F (xk, yk) .

160
Roots of Equations
It is noted that Newton’s method applied to a system of equations requires the computation
of the inverse of the Jacobian matrix or equivalently the solution of a linear system with
matrix DF (x(k)).
In our example
F (x) =
 x −y3 −1
sin(x) + y −1

with Jacobian matrix DF (x) =

1
−3y2
cos(x)
1

.
The inverse of the Jacobian matrix is
[DF (x)]−1 =
1
1 + 3y2 cos(x)

1
3y2
−cos(x)
1

.
Then Newton’s method can be formulated as
xk+1
yk+1

=
xk
yk

−
1
1 + 3y2
k cos(xk)

1
3y2
k
−cos(xk)
1
 
xk −y3
k −1
sin(xk) + yk −1

,
for let’s say (x0, y0) = (0, 0). After performing the matrix-vector multiplication and simpli-
fying same terms, we can write the Newton iteration in the form
xk+1 = xk −xk −1 + y2
k(2yk −3) + 3y2
k sin(xk)
1 + 3y2
k cos(xk)
,
yk+1 = yk −yk −1 + (1 −xk −y3
k) cos(xk) + sin(xk)
1 + 3y2
k cos(xk)
,
for k
=
0, 1, 2, . . .
with (x0, y0)
=
(0, 0). The solution to this system is x∗
≈
(1.00382207, 0.160754)T .
5.6
The Module scipy.optimize
In this chapter, we studied to some extent four numerical methods for solving approxi-
mately equations of the form f(x) = 0. In particular, we studied the bisection, fixed-point,
Newton’s and secant methods. Python provides implementations of all these methods in the
module scipy.optimize of SciPy. The module is called optimize because the field of op-
timization in computational mathematics includes the approximation of roots of functions.
For example, in optimization we can compute the minimum of a function f(x) by solving
the equation of f ′(x) = 0. The bisection method is implemented in the function bisect,
the fixed-point method in the function fixed point and the Newton and secant methods
are implemented in the function newton. (The names of the functions and their variables
that we present here are in accordance to the original names of the SciPy functions.)
5.6.1
Bisection method
The function scipy.optimize.bisect implements the bisection method. A basic call of
this function is
bisect(f, a, b, args, xtol, rtol, maxiter, full_output, disp)
where

The Module scipy.optimize
161
f:
The name of the function f(x)
a and b: The end-points of the interval [a, b] where the root of f is located
args: A tuple with additional arguments and parameters for the functions f. (Optional
with default value args=())
xtol and rtol: The absolute and relative error tolerances for the termination of the
method. (Optional with default values xtol = 2.e −12 and rtol = 8.88e −16)
maxiter: An integer with the maximum number of iterations allowed. (Optional with
default value maxiter=100)
full output: Is a boolean variable determining the output. If full output=False, then
the function returns only the approximation of the root. If full output=True, then
the function returns as output additional information about the convergence of the
method. (Optional with default value is full output=False)
disp: If it is True, then the function displays messages in case of possible error. (Optional
with default value disp=True)
The important input arguments are the function f, the end-points a and b of the initial
interval [a, b], the parameters xtol and rtol for the absolute and relative error tolerances
and the maximum number of iterations maxiter. The argument args takes extra arguments
for the function f if there are any. This allows to apply the bisection method on a specific
argument of a multivariable function.
On the output of the function bisect we receive the approximation of the solution
x0 and the object (class) r containing information about the convergence. For example
r.converged is True if the method converged.
We demonstrate the usage of this function for the same example we used before, which
is the equation ln x + x = 0 in the interval [0.1, 1]
1
import scipy.optimize as spo
2
def f(x):
3
y = np.log(x)+x
4
return y
5
a = 0.1
6
b = 1.0
7
tol = 1.e-4
8
x = spo.bisect(f, a, b, () , tol)
9
print('The approximate solution x is: ', x)
10
print('And the value f(x) is: ', f(x))
The approximate solution x is:
0.567193603515625
And the value f(x) is:
0.0001390223881425623
We observe that the SciPy function and our implementation give the same results. Of
course, the SciPy implementation has more capabilities and is faster as it is precompiled.
5.6.2
Fixed-point methods
The function scipy.optimize.fixed point implements the fixed-point iteration for the
numerical solution of the equation x = g(x). A basic call of the function is

162
Roots of Equations
fixed_point(func, x0, args, xtol, maxiter, method)
with arguments
func: The name of the function g(x)
x0:
The initial guess x0 of the root x∗
args: A tuple with additional arguments and parameters for the functions f. (Optional
with default value args=())
xtol: The absolute error tolerance. (Optional with default value is xtol = 1.e −08)
maxiter: The
maximum
number
of
iterations.
(Optional
with
default
values
is
maxiter=500)
method: Is a string determining the method. If method=’iteration’ then the function uses
the general fixed-point iteration xk+1 = g(xk), while if method=’del2’ then the func-
tion uses the Steffensen’s method with Aitken’s delta-squared process. For more in-
formation see Sections 5.5.2 and 5.5.3. (Optional with default value method=’del2’)
The method returns only the approximation of the root x∗in the output. In order to
demonstrate the use of the fixed point function we consider the equation x2 −x −1 = 0
with the initial guess x0 = 0 and g(x) = √x + 1.
1
import scipy.optimize as spo
2
def f(x):
3
y = x**2-x-1.0
4
return y
5
def g(x):
6
y = np.sqrt(x+1.0)
7
return y
8
x0 = 1.0
9
tol = 1.e-4
10
maxit = 50
11
x = spo.fixed_point(g, x0, (), tol, maxit)
12
print('The approximate solution x is: ', x)
13
print('And the value f(x) is: ', f(x))
The approximate solution x is:
1.6180339887498991
And the value f(x) is:
9.547918011776346e-15
We observe that the accuracy is better with Steffensen’s method. Unfortunately, the
specific function does not return the number of iterations required for the method to satisfy
the prescribed stopping criterion. On the other hand, the use of Aitken’s extrapolation
method allows expectations for fast convergence.
5.6.3
Newton and secant methods
Newton’s and secant methods are implemented in the function scipy.optimize.newton.
A basic call of this function is

The Module scipy.optimize
163
newton(func, x0, fprime, args, tol, maxiter, fprime2,
x1, rtol, full_output, disp)
where here
func: The name of the function f(x)
x0:
The initial guess x0 of the root x∗
fprime: The name of the first derivative f ′(x). If we provide fprime = None, then the
secant method is used instead of Newton’s method. (Optional with default value
fprime=None)
args: A tuple with additional arguments and parameters for the function f. (Optional
with default value args=())
tol: The absolute error tolerance. (Optional with default value xtol = 1.48e −08)
maxiter: The maximum number of iterations. (Optional with default values maxiter=50)
fprime2: Is a callable function for the second order derivative of f. When fprime2 is
provided, then the function uses Halley’s method of Section 5.5.5. (Optional with
default value fprime2=None for the secant method or Newton’s method)
x1:
A second guess of the root for use with secant method. (Optional with default value
x1=None)
rtol: The relative error tolerance. (Optional with default value rtol = 0.0)
full output: Boolean input. If False then the function returns the root. If True then
the function returns the tuple (x,r) where x is the root and r a class with further
information. (Optional with default value False)
disp: Boolean input that specifies the level of communication. (Optional with default value
xtol = 1.48e −08)
In order to demonstrate the usage of this function we consider the example with f(x) =
ln(x) + x and initial guess x0 = 1.
1
import scipy.optimize as spo
2
def f(x):
3
y = np.log(x)+x
4
return y
5
def df(x):
6
y = 1.0/x+1.0
7
return y
8
x0 = 1.0
9
x = spo.newton(f, x0, df, tol=1.e-4, maxiter=50)
10
print('The approximate solution x is: ', x)
11
print('And the value f(x) is: ', f(x))
The approximate solution x is:
0.5671432903993691
And the value f(x) is:
-2.877842408821607e-11
Newton’s method is faster and more accurate compared to the one obtained by the
bisection method. It is noted that when the solution is printed on the screen it does not
contain all the significant digits computed by the method, and the full answer can be
displayed by using a formatted print command.

164
Roots of Equations
5.6.4
A hybrid method
There is a general purpose Python function that combines various methods for fast and
guaranteed convergence, independent of the initial guess x0 or the properties of the function
f. This function is the scipy.optimize.fsolve, which is a wrapper of specific algorithms
implemented in Fortran’s library minpack, [91]. This function can be used also to solve
systems of equations. If the derivative of f (or Jacobian matrix for systems) is not specified
in the input arguments, the method computes good approximations by using similar finite-
difference approximations like those we used in the derivation of the secant method.
The basic call of this function is:
fsolve(func, x0, args, fprime, full_output, col_deriv,
xtol, maxfev, band, epsfcn, factor, diag)
The necessary input arguments are the following
func: The function f
x0:
The initial guess x0
The rest of the input arguments are optional and similar to the function newton.
fprime: A function to compute the Jacobian of func with derivatives across rows. (Op-
tional with default value fprime=None)
xtol: Floating point variable determining the tolerance for terminating the algorithm.
(Optional with default value xtol=1.49012e-08)
full output: Specifies if we want the method to display detailed information about the
convergence of the method. (Optional with default value full output=FALSE)
col deriv: Specifies whether the Jacobian matrix/function computes derivatives using
columns. This results in faster implementation as there is no need to use of the
transpose of matrices. (Optional with default value col deriv=FALSE)
maxfev: Is the maximum number of calls of f. (Optional with default value is maxfev=0.
This means that 100*(N+1) is the maximum number, where N is the number of the
entries in x0)
band: Specifies whether the Jacobian matrix is a band matrix by providing the number
of sub- and super-diagonals within the band in a tuple. This argument can be used
only if we do not provide the derivative (Jacobian) of the function (fprime=None).
(Optional with default value is band=None)
epsfcn: Defines a suitable length for the forward-difference approximation of the derivative
(or Jacobian matrix). Again we can use this argument if we do not provide the exact
derivative of the function f. (Optional with default value epsfcn=None)
factor: Is a number in the interval (0.1, 100) and determines the initial step bound. (Op-
tional with default value factor=100)
diag: Is a sequence of N positive entries that serve as scale factors for the variables.
(Optional with default value diag=None)
The function fsolve returns as output the approximate solution x and optionally a
dictionary with the following keys

The Module scipy.optimize
165
nfev and njeb: The number of function and Jacobian calls respectively
fvec: The value func(x)
fjac and r: Are matrices where their product is equal to the approximation of the Jacobian
matrix
qtf: Is the product transpose(fjac)*fvec
ier: Is 1 if the method converged to the solution, otherwise the last key:
mesg: Returns a string with the cause of the failure
We demonstrate here the use of the function fsolve in our standard example:
1
import scipy.optimize as spo
2
def f(x):
3
y = np.log(x)+x
4
return y
5
def df(x):
6
y = 1.0/x+1.0
7
return y
8
x0 = 1.0
9
x = spo.fsolve(f, x0, fprime=df, xtol=1.e-4)
10
print('The approximate solution x is: ', x)
11
print('And the value f(x) is: ', f(x))
The approximate solution x is:
[0.56714329]
And the value f(x) is:
[3.4803842e-09]
The results are similar to the results obtained with the previous methods. The advantage
of fzero is its convergence and applicability to systems of nonlinear equations. For an
algorithm of a hybrid method that combines the bisection method with Newton’s method,
we refer to Algorithm 15 in the exercises.
5.6.5
Application in astrophysics
Nonlinear equations occur naturally in many physical applications. An example of a well-
known nonlinear equation in astrophysics is Kepler’s equation. The famous German as-
tronomer and mathematician Johannes Kepler (1571–1630) described planetary orbits
around the Sun with great accuracy. Kepler also stated that planetary orbits should be
ellipses with the Sun located at one of the two foci. Figure 5.8 presents an idealized orbit,
where the ellipse has eccentricity e =
p
1 −b2/a2, semi-major axis a and semi-minor axis
b. The angle θ as shown in Figure 5.8 is the eccentric anomaly. (The angle ϕ is called the
true anomaly). If angle ψ is the mean anomaly defined as ψ = ν t, where ν = 2π/T is the
mean angular velocity, and t is the time since perihelion (point A), then Kepler’s equation
is the (fixed point) equation
θ = ψ + e sin θ .
Because ψ is a function of time t, Kepler’s equation determines the eccentric anomaly and
therefore we can compute the position of a planet as a function of time. If we compute the
eccentric anomaly θ for a given time t, then we can compute the true anomaly ϕ by solving
the equation
(1 −e) tan2 ϕ
2 = (1 + e) tan2 θ
2 .

166
Roots of Equations
Planet
Sun
FIGURE 5.8
Planetary orbit and its anomalies.
Moreover, the heliocentric distance r between the planet and the Sun can be estimated
using the formula
r = a(1 −e cos θ) .
Given the parameters e and ψ, we compute the eccentric anomaly θ by solving directly
the fixed point equation θ = g(θ) where g(θ) = ψ+e sin θ. For example, for a planetary orbit
of eccentricity e = 10−6 (almost circular orbit) and mean anomaly ψ = π/6, we take as
initial guess of the eccentric anomaly θ0 = ψ, which is not very far from the true value. As we
can see in the following code, using the function fixed point of module scipy.optimize
we obtain the solution 0.5235992755987319.
1
import numpy as np
2
import scipy.optimize as spo
3
def g(theta):
4
e = 1.e-6
5
psi = np.pi/6.0
6
return psi+e*np.sin(theta)
7
theta0 = np.pi/6.0
8
theta = spo.fixed_point(g, theta0)
9
print('eccentric anomaly=', theta)
eccentric anomaly = 0.5235992755987319
We obtain similar results when we use the other functions of scipy.optimize for solving
the equation f(θ) = 0 where f(θ) = θ −g(θ). Note that Newton’s iteration can be written
explicitly in this case as
θk+1 = θk + ψ + e sin θk −θk
1 −e cos θk
,
k = 0, 1, 2, . . . .
We leave the implementation of this method as well as the use of the other Python functions
of the module scipy.optimize as an exercise for the reader.

Further Reading
167
5.7
Further Reading
The numerical solution of nonlinear equations is discussed in all classic numerical analysis
textbooks [18, 22, 76, 108, 109, 120, 26, 27, 25, 70, 132, 7, 89, 90, 57, 66, 116]. More
detailed analysis of the methods can be found in advanced textbooks such as [127, 1, 34,
94, 125] including proofs of convergence and error estimates. Books specialized on iterative
methods and their convergence include [5, 6, 96]. Because of the influence of this topic in
unconstrained optimization and other fields of sciences, there are several specialized books
focused on the numerical solution of nonlinear equations. One such book is the classical
book [95].

Chapter Highlights
 In this chapter, we studied numerical methods for the approximation of roots of
functions by solving the equation f(x) = 0.
 The simplest method for approximating roots of functions is the bisection
method. The bisection method is based on Bolzano’s theorem and requires only
the function f to be continuous and to change sign around the root.
 The bisection method always converges with a convergence rate at least 1.
 It is always preferable to have methods that converge with a rate grater than 1.
 Fixed point methods are based on the transformation of the equation f(x) = 0
into a fixed point equation x = g(x). This can be done in many different ways.
The generic fixed point method defines an iteration xk+1 = g(xk) and requires
an initial guess x0 of the root x∗.
 The convergence rate of fixed point methods depends on the choice of function
g.
 Newton’s method is a particular case of fixed point method with
g(x) = x −f(x)
f ′(x) .
 Newton’s method converges quadratically but requires the knowledge of the
derivative f ′(x) and a good initial guess x0 of the root x∗.
 Secant method is based on Newton’s method but uses a finite difference
approximation of the derivative.
 The convergence rate of secant method is equal to the golden ratio
r = (1 +
√
5)/2.
 To avoid infinite iterations in the case of convergence failure we usually use
stopping criteria such as |xk+1 −xk| < TOL and k to be less than a maximum
number of iterations.
 Steffensen’s method is a modified Newton’s method that converges
quadratically without the need of the first derivative.
 Steffensen’s method converges only when −1 < f ′(x∗) < 0.
 Aitken’s method can be used instead to improve the accuracy of an iterative
method.
 Fixed point methods such as Newton’s method can be generalized for systems
of equations.
 The module scipy.optimize contains implementations of most of the
numerical methods discussed in this chapter, including the bisection, fixed
point, Newton and secant methods.
168

Exercises
1. Consider the function
f(x) = x3 −x −1 .
(a) Prove that the equation f(x) = 0 has a unique solution in the interval [1, 2].
(b) Estimate the root of this equation using the bisection method with 3 iterations.
(c) How many iterations of the bisection method do you need in order to approximate
the exact solution with error of order 10−6?
2. In this problem consider the bisection method.
(a) Write a Python function that computes an approximation of the solution x∗of the
equation f(x) = 0 in the interval [a, b] using the bisection method. For a stopping
criterion use the following: If |xk+1 −xk| ≤TOL for the first time, then return xk+1
as approximation of the root x∗. Allow the code to do only KMAX iterations.
(b) Test your code by finding an approximate solution to the equation ln(x) + x = 0 in
the interval [0.1, 1].
(c) Compare
your
results
with
those
obtained
using
the
function
bisect
of
scipy.optimize.
3. Consider the function
f(x) = x3 + x −1 .
(a) Prove that the equation f(x) = 0 has a unique solution x∗in the interval (0, 1).
(b) Estimate the root of this equation using the bisection method with 3 iterations.
(c) How many iterations of the bisection method do you need in order to approximate
the exact solution with error of the order 10−6?
(d) Write Newton’s method for the approximation of the solution x∗.
(e) Perform using pen and paper 3 iterations of Newton’s method and compare with
the result of bisection method.
(f) Prove that the sequence xk generated by Newton’s method converges to x∗for any
x0 ∈R and that
lim
k→∞
xk+1 −x∗
(xk −x∗)2 =
3x∗
3(x∗)2 + 1 .
(g) Interpret the last question in terms of discretization errors and convergence rates.
4. Consider the function
f(x) = x2 −2 .
(a) Prove that if x0 >
√
2, then the sequence
xk+1 = 1
2xk + 1
xk
,
k = 0, 1, . . . ,
converges to
√
2.
169

(b) Observe that if 0 < x0 <
√
2, then x1 >
√
2. What happens to the convergence of
the sequence xk if x0 ∈(0,
√
2]?
(c) What if x0 ≤0?
5. Consider the function
f(x) = xex+2 + 2 .
(a) Prove that the equation f(x) = 0 has exactly two roots x∗∈(−1, 0) and x∗∗= −2.
(b) Prove that the sequence xk generated by Newton’s method for the equation f(x) = 0
converges to the root x∗only if x0 > −1.
(c) What happens when x0 ≤1?
6. Let g : R →R a function such that g(x∗) = x∗for some x∗∈R. In addition assume that
g′(x∗) = g′′(x∗) = · · · = g(p−1)(x∗) = 0
and
g(p)(x∗) ̸= 0 .
(a) Prove that the fixed point iteration xk+1 = g(xk) converges to the fixed point x∗.
(b) Show that the fixed point iteration converges with order p, in the sense that
lim
k→∞
xk+1 −x∗
(xk −x∗)p = 1
p!g(p)(x∗) .
7. In this problem consider Newton’s method.
(a) Write a Python function that computes an approximation of the root x∗of the
equation f(x) = 0 using Newton’s method. Specifically the code shall compute the
terms xk of the sequence
xk+1 = xk −f(xk)
f ′(xk),
k = 0, 1, 2, . . . ,
where x0 is a given initial guess (or approximation) of the root x∗. For a stopping
criterion use the following: If |xk+1 −xk| ≤TOL for the first time, then return xk+1
as approximation of the root x∗. Allow the code to do only KMAX iterations.
At every step k, the code should print on screen the values k, xk, f(xk) and |xk+1 −
xk|. If the number of performed iterations reaches the maximum allowed number
without satisfying the stopping criterion, then the code shall print on screen an
error message, for example: “Failure: Algorithm failed to converge using only KMAX
iterations”.
(b) Test your code by finding an approximate solution to the equation ln(x) + x = 0
with an initial guess of your choice.
8. Consider the function
f(x) = arctan(2(x −1)) −ln |x| .
(a) Plot (using Python) the graph of f(x) and describe the intervals of monotonicity.
What conclusions can be derived about the solutions of the equation f(x) = 0.
(b) Prove by analytical means (using calculus), that the equation f(x) = 0 has exactly
four real roots ρ1 < ρ2 < ρ3 < ρ4. [Hint: Use Bonzano’s theorem in appropriate
intervals selected. Then use the monotonicity of the function f in each of these
intervals to show uniqueness of roots.]
170

(c) Find approximations of the roots using the codes of Problems 2 and 7, with input
parameters x0, TOL and KMAX of your choice (try x0 values close to the real roots).
(d) Compare the results and the CPU times elapsed with the results obtained by using
the Python functions bisect, newton and fsolve of scipy.optimize module.
What do you observe?
(e) Finally, take TOL=1.e-6, KMAX=50 and execute your implementation of Newton’s
method with x0 = −1, 0.65, 0.7, 1.7, 1.8, 1.9, 5 and 10. Comment on the results.
9. The following algorithm for approximating roots combines the bisection method with
Newton’s method to ensure the convergence even when Newton’s method fails to con-
verge.
Algorithm 15 A hybrid Newton-bisection method
Choose an interval [a, b] such that f(a)f(b) ≤0
Compute initial approximation x0 of the root using bisection method.
for i = 1, 2, . . . do
Compute xi using Newton’s method and xi−1
If xi ̸∈[a, b], set xi = (a + b)/2 (from bisection)
Check for convergence
If f(a)f(xi) ≤0 set b = xi, else set a = xi
end for
(a) Implement
this
algorithm
in
a
Python
function.
Call
your
new
function
hybridNewton and use the following specifications:
def
hybridNewton(a,b,tol,maxit,f,df):
# Input:
# a, b = The endpoints of the interval
# tol = The required tolerance
# maxit = Maximum number of iterations
# f, df = The function and its derivative
# Output:
# xstar = approximation of root
# niter = number of iterations for convergence
# ierr =
#
0, the method converged
#
1, df returned zero value
#
2, maximum number of iterations has been reached
return xstar,niter,ierr
(b) Use this function with input parameters of your choice to find approximations of
the roots of Problem 8.
10. Consider the secant method.
(a) Write a Python function using the same criteria as in Problem 7 that will compute
an approximation of a solution x∗of an equation f(x) = 0 using the secant method.
(b) Estimate the rate of convergence using the equation x(ex/2 + 1) = 0, x0 = 2.5 and
the exact root x∗= 0. Confirm that the convergence rate is equal to the golden
ratio r = (1 +
√
5)/2 ≈1.62.
171

11. Consider the Halley iteration defined as
xk+1 = xk −
2f(xk)f ′(xk)
2[f ′(xk)]2 −f(xk)f ′′(xk),
k = 0, 1, . . . ,
and the method defined by the iteration
xk+1 = xk −2f(xk)[f ′(xk)]2 + [f(xk)]2f ′′(xk)
2[f ′(xk)]3
,
k = 0, 1, . . . ,
for the numerical solution of a equation f(x) = 0. Consider also appropriate initial guess
x0 for the exact root x∗.
(a) Write Python functions implementing the two methods.
(b) Study the convergence of both methods by finding experimentally the convergence
rates.
(c) For each method describe necessary conditions that guarantee cubic order conver-
gence rates.
12. Consider the function
f(x) =
3x
x2 −2x + 4 .
(a) Using the module matplotlib plot the graph of f(x) in the interval [−10, 10].
(b) Compute the maximum and minimum values of f(x) using functions from
scipy.optimize.
(c) Study the monotonicity intervals of f(x) with the help of calculus.
(d) Verify the numerical results by solving theoretically the equation f ′(x) = 0.
13. Galileo Galilei performed several experiments from the leaning tower of Pisa to under-
stand the free fall of objects and the effects of gravity. Experiments showed that the air
resistance Fd(t) is proportional to the speed v(t) of a falling object, where t denotes time
in seconds. Specifically, we assume that
Fd(t) = b · v(t) ,
where b is the air resistance coefficient. Since the air resistance increases as the speed
of the falling object increases, eventually, the gravitational force becomes equal to the
air resistance and the object falls at a constant speed V . The speed V is known to as
the terminal speed. Applying Newton’s second law of motion to the falling object with
terminal speed we have that Fd = mg, and thus we compute the terminal speed
V = mg
b
,
where g ≈9.81 m/s2 is the acceleration due to gravity. We can also estimate the velocity
of the falling object as a function of time given by
v(t) = V ·

1 −e−b
m t
.
Consider the free fall of three objects with masses m1 = 0.1 kg, m2 = 1 kg and m3 = 3 kg
from the top of the tower of Pisa. Assume that the coefficients of air resistance for the
three objects are b1 = 1 kg/s, b2 = 0.8 kg/s and b3 = 0.5 kg/s, respectively.
172

(a) Given that the height of Pisa’s tower is h0 = 55.86 m, show by integrating the
formula for the velocity that the height of the falling object measured from the
ground is given by the formula
h(t) = h0 −V t + V m
b

1 −e−b
m t
.
(b) Use the module scipy.optimize to estimate the time it takes for the objects to
fall to the ground.
(c) Compute the falling time in the absence of air resistance, and comment on the effect
of air resistance to the free fall of these objects.
14. Consider the following generalization of the Bisection method called the method of false
position or sometimes Regula Falsi as described in Algorithm 16.
Algorithm 16 Method of false position
Set a tolerance TOL for accuracy
Initialize the interval [a, b]
Set k = 0
Check if f(a) · f(b) < 0 (if not then quit)
while |b −a| > TOL do
Set xk = bf(a)−af(b)
f(a)−f(b)
(the new approximation)
Check in which interval [a, xk] or [xk, b] the function changes sign
if f(xk) · f(a) < 0 then
b = xk
else if f(xk) · f(b) < 0 then
a = xk
else
Break the loop because f(xk) = 0
end if
k = k + 1
end while
Return the approximation of the root x∗
(a) Observe that this algorithm combines the bisection method and another method.
Describe what other method is combined and why this is promising.
(b) Implement the method of false position in Python.
(c) Describe your expectations for the convergence of this method.
(d) Use your computer code to approximate the root x∗= 0 of the function f(x) =
2x3 −4x2 + 3x in [−1, 1]. Describe the convergence of the method of false position
in this case and compare with the bisection method.
15. In this problem you will need to use complex number arithmetic. Assume that the equa-
tion f(x) = 0 has a unique solution in [a, b], and that f ∈C3[a, b].
(a) Let 0 < h ≪1 be a small number. Using appropriate Taylor expansion show that
for any x in the domain of f we have
f ′(x) = Im(f(x + ih))/h + O(h2) ,
where i is the imaginary unit such that i2 = −1.
173

(b) Since f ′(x) ≈Im(f(x + ih))/h, consider the following modification of Newton’s
method with complex step
xk+1 = xk −h
f(xk)
Im(f(xk + ih)),
k = 0, 1, 2, . . . ,
with given x0. Implement this complex-step Newton’s method.
(c) Assume that
lim
k→∞
|xk+1 −x∗|
|xk −x∗|r = C ,
where x∗is such that f(x∗) = 0. This means that the convergence rate of the new
method is r. Estimate the convergence rate r using the equation x(ex/2 + 1) = 0
and x0 = 2.5. For implementation purposes you can use the default value h = 10−10
but you can try even smaller such as h = 10−20 or even smaller.
(d) Study the influence of the parameter h in the convergence rate.
[The approximation of the derivative in this problem is known to as the complex-step
derivative approximation and works for even tiny values of h > 0. For more information,
we refer to the publications [123, 85] and the problems of Chapter 8]
174

6
Interpolation and Approximation
Suppose that we are in possession of data points (x0, y0), (x1, y1), . . . , (xN, yN) representing
measurements of a physical quantity y at location x, but we need an estimate of the quantity
yp at some point xp other than x0, x1, . . . , xN. To formulate a mathematical problem we
assume that the given data obey to a function y = f(x), in the sense that yi = f(xi) for
i = 0, 1, . . . , N. Of course, we do not know the formula f(x). The question is whether we can
compute an approximation of f(x) at some x ̸= xi, i = 0, 1, . . . , N. To tackle such problems
we usually use interpolation. Interpolation is a method of constructing a function whose
graph passes through a specified set of points. When the data are too noisy to interpolate
with smooth functions, we proceed with approximating the dataset. Specifically, we generate
a function whose graph is close to the data points without necessarily passing through them.
Such a method is the least squares approximation (also known as regression). This chapter
is an introduction to interpolation and approximation.
6.1
Introduction
In some applications there is a finite set of data points (xi, yi) = (xi, f(xi)), i = 0, 1, . . . , N
of an unknown function f(x), and we require an estimate of this function at a different
point. For example, assume that we have the population of a city for the years x0 = 2000,
x1 = 2002 and x2 = 2004, which is y0 = 12, 900, y1 = 13, 400 and y2 = 13, 800 respectively,
and we need to estimate the population of the city for the year 2001. In this problem the
unknown function f(x) describes the population of a city at a year x. To find an approximate
value for f(2001), we compute appropriate polynomial P(x) that satisfies P(xi) = yi. If this
polynomial approximates the function f(x), then we can estimate the unknown quantity
by computing the value P(2001) ≈f(2001). Sometimes, it is beneficial to use sophisticated
interpolants P(x), such as piecewise polynomial functions, but for the moment we consider
simple polynomials.
When the graph of the polynomial P(x) passes through the given (xi, yi) for all val-
ues of i, we say that P(x) interpolates the points (xi, yi). The polynomial P(x) is called
interpolant. The procedure to estimate the values (x, y) other than (xi, yi) using P(x)
is called interpolation. The points xi are called nodes (also known as sites or knots). A
set of nodes {x0, x1, . . . , xN} is called grid or mesh. In principle, interpolation is when
min xi ≤x ≤max xi otherwise we call it extrapolation even if we use the same methods.
If the polynomial does not necessarily interpolate the points (xi, yi), then we speak about
approximation in general. Figure 6.1 shows the idea of interpolation. Observe that the in-
terpolating polynomial P(x) approximates the function f(x) quite well for x ∈[x0, x3] and
diverges for values of x outside the interval [x0, x3]. This phenomenon can be a problem
especially if the dataset consists of only a few points. The situation can be different when
there are more data points to interpolate or in cases of sophisticated interpolation methods.
DOI: 10.1201/9781003287292-6
175

176
Interpolation and Approximation
FIGURE 6.1
The notion of polynomial interpolation for the function f(x) = x + sin(x) with four nodes
(N=3).
The reason for using polynomials to approximate functions is because of the Weierstrass
Approximation Theorem. This theorem guarantees that every continuous function can be
approximated arbitrarily well by a polynomial. Mathematically speaking this can be stated
as:
Theorem 6.1 (Weierstrass Approximation Theorem). For any function f ∈C[a, b], and
for each ε > 0, there is a polynomial P(x), such that |f(x) −P(x)| < ε for all x ∈[a, b]. 1
Any linear combination of two polynomials is a polynomial again of the same degree at
most. For this reason, we say that the polynomials of degree N form a linear space denoted
by PN.
Interpolation and approximation can be useful in problems such as data fitting and
function approximation, as well as in other numerical methods, including root finding, opti-
mization, numerical integration and differentiation. In this chapter, we discuss interpolation
methods such as the Lagrange, Hermite and Spline interpolation. We will close this chapter
by discussing the method of least squares for approximating datasets.

Interpolation is the procedure of finding a function (usually a polynomial or a
piecewise polynomial function) with graph passing through some data points. When
the data are very noisy, we usually approximate them using different procedures,
such as the method of least squares.
1A proof of Weierstrass Approximation Theorem requires advanced tools of mathematical analysis and
can be found, for example, in [81].

Lagrange Interpolation
177
6.2
Lagrange Interpolation
Suppose that we have N + 1 values y0, y1, . . . , yN and x0, x1, . . . , xN such that yi = f(xi)
for i = 0, 1, . . . , N, and that f is a smooth function. Recall that smooth functions are
differentiable functions. The procedure of finding a unique polynomial PN(x) of degree N
such that p(xi) = yi, for i = 0, 1, . . . , N is called Lagrange interpolation. The polynomial we
obtain with Lagrange interpolation is called Lagrange interpolating polynomial or in short
Lagrange interpolant named after the French mathematician Joseph-Louis Lagrange (1736–
1813). Such an interpolant is depicted in Figure 6.1 where f(x) = x + sin(x) and N = 3.
We first present a naive construction of Lagrange interpolating polynomials.
6.2.1
Naive construction of the interpolant
Consider first the simplest case with only two points (x0, y0) and (x1, y1). In this case, there
is a unique straight line P1(x) passing through these points. Define
P1(x) = a0 + a1x ,
(6.1)
the interpolation polynomial with unknown coefficients a0 and a1. To find the coefficients
a0 and a1 we use the fact that P1(x) interpolates the points (xi, yi), i = 0, 1, which is the
same to say that
y0 = P1(x0) = a0 + a1x0
and
y1 = P(x1) = a0 + a1x1 .
Both equations form the system
(
y0 = a0 + a1x0
y1 = a0 + a1x1
.
Solving this system (simultaneous equations) we obtain the coefficients
a1 = y1 −y0
x1 −x0
and
a0 = y0 −y1 −y0
x1 −x0
x0 .
Substituting a0 and a1 into (6.1) we obtain the formula of P1(x) as
P1(x) = y1 −y0
x1 −x0
x + y0 −y1 −y0
x1 −x0
x0 = y1 −y0
x1 −x0
(x −x0) + y0 .
This is the linear Lagrange interpolant, and its construction requires two points (N = 1).
Moving one step further, we consider three points (x0, y0), (x1, y1) and (x2, y2). Since
we have three points, the interpolating polynomial should be a quadratic polynomial of the
form P2(x) = a0 + a1x + a2x2 with y0 = P2(x0), y1 = P2(x1) and y2 = P2(x2). These
equations form the following system of simultaneous equations





y0 = a0 + a1x0 + a2x2
0
y1 = a0 + a1x1 + a2x2
1
y2 = a0 + a1x2 + a2x2
2
.
(6.2)

178
Interpolation and Approximation
To solve this system for a0, a1 and a2 it is not as easy unless we use techniques from linear
algebra. For example, we can use the NumPy module and its functions. System (6.2) can
be written in matrix form as


1
x0
x2
0
1
x1
x2
1
1
x2
x2
2




a0
a1
a2

=


y0
y1
y2

.
The matrix
V =


1
x0
x2
0
1
x1
x2
1
1
x2
x2
2

,
is a 3 × 3 Vandermonde matrix. We write the previous system in matrix form as V a = y,
with
y =


y0
y1
y2

,
a =


a0
a1
a2

.
This procedure can be generalized for N + 1 distinct points (xi, yi), i = 0, 1, 2, . . . , N
with xi ̸= xj if i ̸= j. Then the coefficients of the polynomial of degree N
PN(x) = a0 + a1x + a2x2 + · · · + aNxN ,
can be found by solving the analogous (N +1)×(N +1) system of linear equations V a = y
with V the Vandermonde matrix
V =





1
x0
x2
0
· · ·
xN
0
1
x1
x2
1
· · ·
xN
1
...
...
...
...
1
xN
x2
N
· · ·
xN
N




.
The determinant of the Vandermonde matrix is
det(V ) =
Y
0≤i<j≤N
(xj −xi) ,
which is det(V ) ̸= 0 since the points xi are distinct, i.e. xi ̸= xj for i ̸= j. Thus, V is invert-
ible, and the linear system V a = y has a unique solution a = V −1y = (a0, a1, . . . , aN)T .

For N + 1 points (xi, yi) there is always a unique interpolating polynomial PN
of degree N such that yi = PN(xi).
There are two main disadvantages in solving linear systems with Vandermonde matrix.
The first is that Vandermonde matrices are dense. Thus, in the case of large amount of
data solving the corresponding dense linear system will be a very slow procedure. The other
drawback is that computations with Vandermonde matrices are very sensitive to floating
point errors. Matrices that are sensitive to floating point errors are called ill-conditioned,
and we should be very careful when we use them. More information about the condition of
matrices can be found in Chapter 9.
In Python we can construct Vandermonde matrices in any dimension using the NumPy
function

Lagrange Interpolation
179
numpy.vander(x, N, increasing)
where N is the dimension of the vector x, and the argument increasing specifies the
form of the Vandermonde matrix. When increasing=True, then the entries of the cor-
responding matrix start from 1, otherwise they start from xN
i . In our case we need N=None
and increasing=True. The linear system V a = y can be solved using the function
numpy.linalg.solve. This can be quite safe since the function solve takes into account
the condition of matrices and performs appropriate techniques to minimize floating point
errors.
As an example we consider the points (0, 1), (0.5, −1), (1, 2) and (1.5, 1.5). Since we have
four points we can construct the unique cubic interpolating polynomial (N = 3). We store
the values xi in a vector x and the values yi in a vector y. We construct the Vandermonde
matrix and solve the corresponding linear system using the function solve.
1
import numpy as np
2
import numpy.linalg as npl
3
import matplotlib.pyplot as plt
4
5
# interpolation data (x,y)
6
x = np.array([0.0, 0.5, 1.0, 1.5])
7
y = np.array([1.0, -1.0, 2.0, 1.5])
8
# assembly of Vandermonde matrix V
9
V = np.vander(x, increasing=True)
10
# solution of linear system Va=y
11
a = npl.solve(V,y)
12
# define more points for plotting
13
xx = np.linspace(0.0,1.5,100)
14
# evaluate the interpolating polynomial at xx
15
p = a[0]+a[1]*xx+a[2]*xx**2+a[3]*xx**3
16
plt.plot(xx,p)
17
plt.plot(x,y,'o')
18
plt.xlabel('x'); plt.ylabel('y'); plt.show()
0.0
0.2
0.4
0.6
0.8
1.0
1.2
1.4
x
−1.5
−1.0
−0.5
0.0
0.5
1.0
1.5
2.0
2.5
y
The 6th and 7th lines of this code define the vectors x and y with the data (xi, yi). The
9th line performs the assembly of the Vandermonde matrix V and the 11th line solves the

180
Interpolation and Approximation
corresponding system V a = y. In order to plot the resulting polynomial we define a fine
mesh of 100 points (line 13) and we store these points in the variable xx. We evaluate the
cubic polynomial p at the points xx (line 15). Finally, we plot the polynomial p over the
points xx (line 16) and we draw the data points (xi, yi) using circles (line 17).
We observe that the cubic polynomial interpolates all the four points. Also if we want
to evaluate the polynomial P3(x) at any value x we can do it easily since we have already
computed the coefficients a0, a1, a2 and a3.
Imagine we have the experimental data (xi, yi) for i = 0, 1, . . . 9, 999. The Vandermonde
matrix will be 10, 000 × 10, 000 dense with 100, 000, 000 entries. This dense matrix is very
large and thus the solution of the system V a = y will be a slow process. The same is true
for the evaluation of the interpolating polynomial since it involves a very large and perhaps
unstable sum. In order to construct the interpolating polynomial efficiently, we make use of
some alternative basis functions, in place of the naive monomial basis {1, x, x2, . . . , xN}.
6.2.2
Lagrange polynomials
Given N + 1 points (x0, y0), (x1, y1), . . . , (xN, yN) with xi ̸= xj for i ̸= j, the interpolating
polynomial PN(x) can be written as
PN(x) =
N
X
i=0
aixi .
(6.3)
This is a linear combination of the monomial basis functions 1, x, x2, . . . , xN with unknown
coefficients ai. An alternative way of expressing the same polynomial using different basis
functions is by rewriting the polynomial in the form
PN(x) =
N
X
i=0
yiℓi(x) ,
(6.4)
where the coefficients are the given interpolating data. Of course, we need to find the basis
function ℓi(x). This is the Lagrange representation of the interpolating polynomial.
Since PN(xi) = yi for all values of i we have that
yi = PN(xi) =
N
X
i=0
yiℓi(xi) = y0ℓ0(xi) + · · · + yiℓi(xi) + · · · + yNℓN(xi) .
This implies that ℓi(xj) = δij, where
δij =
 0,
if i ̸= j
1,
if i = j
,
is the Kronecker delta.
Because of that, the polynomials ℓi(x) are of the form
ℓi(x) = C
N
Y
j=0
j̸=i
(x −xj) ,
for some constant C. The constant C can be found from the relation ℓi(xi) = 1. We have
ℓi(xi) = C
N
Y
j=0
j̸=i
(xi −xj) = 1 ,

Lagrange Interpolation
181
which implies
C =
N
Y
j=0
j̸=i
1
xi −xj
=
1
(xi −x0)(xi −x1) · · · (xi −xi−1)(xi −xi+1) · · · (xi −xN) .
Subsequently we have that
ℓi(x) = x −x0
xi −x0
x −x1
xi −x1
· · · x −xi−1
xi −xi−1
x −xi+1
xi −xi+1
· · · x −xN
xi −xN
=
N
Y
j=0
j̸=i
x −xj
xi −xj
.
The polynomials ℓi(x) are called Lagrange polynomials.
If we write
QN+1(x) =
N
Y
j=0
(x −xj)
then
Q′
N+1(xi) =
N
Y
j=0
j̸=i
(xi −xj) ,
then we have the alternative formulas for the Lagrange polynomials and the corresponding
interpolating polynomial
ℓi(x) =
QN+1(x)
(x −xi)Q′
N+1(xi)
and
PN(x) =
N
X
i=0
yiℓi(x) .
(6.5)

An advantage of the interpolating polynomial written in the Lagrange form is
that there is no need for the computation of the coefficients ai as long as we have
the Lagrange basis functions evaluated at points x.
For example, if N = 1 and given the two distinct points (x0, y0) and (x1, y1), the
Lagrange polynomials are
ℓ0(x) = x −x1
x0 −x1
and
ℓ1(x) = x −x0
x1 −x0
.
The polynomial P1(x) is given by the formula
P1(x) = ℓ0(x) · y0 + ℓ1(x) · y1 = x −x1
x0 −x1
· y0 + x −x0
x1 −x0
· y1 .
We could work similarly to compute the quadratic polynomial P2(x) with three distinct
points. However, it is easier to write a Python program to do it for us. Let us write a
Python function first to compute the N +1 Lagrange polynomials. Since each polynomial is
a product, the implementation requires a nested loop. The procedure for the computation
of the Lagrange polynomials is presented in Algorithm 17.

182
Interpolation and Approximation
Algorithm 17 Evaluation of Lagrange polynomials
Given a point z and the nodes x0, x1, . . . , xN
for i = 0 : N do
for j = 0 : N do
if i ̸= j then
ℓi = ℓi · z−xj
xi−xj
end if
end for
end for
Return the values of the polynomials ℓi at the point z
The previous algorithm works even if z is a vector. We implement Algorithm 17 in
the function lagrange basis. Suppose that we want to compute the values PN(zk) of the
Lagrange interpolant at m points zk for k = 0, 1, 2, . . . , m −1. We store all these points zk
in a one-dimensional array z. We also store the data points xi in an array called x. Then,
for each i = 0, 1, 2, . . . , N we compute the i-th Lagrange polynomial as a product of the
form
ℓi(x) =
N
Y
j=0
j̸=i
x −xj
xi −xj
.
(6.6)
The amount of points xi is equal to the number of Lagrange basis functions ℓi and we store
this number in the variable n, which is practically equal to N + 1. After computing the m
values of the Lagrange polynomial ℓi(zk) for k = 0, 1, . . . , m −1, we store them in the i-th
row of an array called basis. In the end, each row i of the array basis will contain the m
values of the polynomial ℓi(zk).
1
def lagrange_basis(z, x):
2
# Compute the Lagrange basis l_i(z)
3
# given the nodes x_i stored in vector x
4
n = len(x)
5
m = len(z)
6
basis = np.ones((n, m))
7
for i in range(n):
8
for j in range(n):
9
if i != j:
10
basis[i,:] *= (z-x[j])/(x[i]-x[j])
11
return basis
The 4th line of this code defines the number of Lagrange polynomials required for the
interpolation. The 5th line defines the amount m of the points on which we want to evaluate
the interpolating polynomial. In the 6th line we reserve the memory for the n × m array
basis. Finally, using the loop of line 7 we compute the polynomials ℓi at the m points.
Using the loop of line 8 we compute the product over j. The function lagrange basis
returns an array with the values of the required basis functions ℓi at all points z.
Since the interpolating polynomial of degree N is given by the formula
PN(x) =
N
X
i=0
yiℓi(x) ,

Lagrange Interpolation
183
we write one more function called lagrange interpolant that evaluates the interpolating
polynomial at the given m points stored in the array z. In this function we need the values
of yi in addition to the values xi. It is noted that the values zi are only needed for the
computation of the Lagrange polynomials, while the values yi are only needed for the
computation of the value of the interpolant. The values yi are stored in the one-dimensional
array y. Again, since we want to compute the interpolant at m different values zk, we store
the values PN(zk) for all k in a one-dimensions array P.
1
def lagrange_interpolant(z, x, y):
2
#Compute the interpolant using Lagrange polynomials
3
n = len(x)
4
m = len(z)
5
P = np.zeros(m)
6
basis = lagrange_basis(z, x)
7
for i in range(n):
8
P += basis[i,:] * y[i]
9
return P
The actual computation of the values of the polynomial PN is implemented in line 8,
where yi is the y[i] and the values ℓi(zk) are the entries of the vector basis[i,:].
As an example, consider the function f(x) = 1
x. We will compute the Lagrange inter-
polating polynomial using the points x0 = 1, x1 = 1.5 and x2 = 4. Note that for Lagrange
interpolation there is no requirement for uniformly distributed points xi. Here, N = 2 and
therefore the unique polynomial will be quadratic. We first compute the Lagrange polyno-
mials
ℓ0(x) =
(x −x1)(x −x2)
(x0 −x1)(x0 −x2) = (x −1.5)(x −4)
(1 −1.5)(1 −4) = 2
3x2 −11
3 x + 4 ,
ℓ1(x) =
(x −x0)(x −x2)
(x1 −x0)(x1 −x2) =
(x −1)(x −4)
(1.5 −1)(1.5 −4) = −4
5x2 + 4x −16
5 ,
ℓ2(x) =
(x −x0)(x −x1)
(x2 −x0)(x2 −x1) = (x −1)(x −1.5)
(4 −1)(4 −1.5) = 2
15x2 −1
3x + 1
5 .
Moreover, y0 = f(x0) = 1, y1 = f(x1) = 2
3 and y2 = f(x2) = 1
4. The interpolating
polynomial is
P2(x) =
N
X
i=0
yiℓi(x) = 1 · ℓ0(x) + 2
3ℓ1(x) + 1
4ℓ2(x) = 1
6x2 −13
12x + 23
12 .
The same interpolating polynomial can be computed using the naive interpolation
method but this requires the solution of a linear system with Vandermonde matrix, which
we avoid using the Lagrange polynomials.
Now we compute the interpolating polynomial using our previous functions. We compute
the Lagrange polynomials first and then the interpolating polynomial in the interval [1, 4],
using 100 points zi. These points are generated by using the function linspace(1, 4,
100). Then we define the arrays x and y to interpolate, and we generate the values of the
interpolating polynomial using the function lagrange interpolant. The results are plotted
with the help of matplotlib. We also add a legend for the first time in order to distinguish
the interpolating polynomial, the data points and the actual function.

184
Interpolation and Approximation
1
def f(x):
2
return 1.0/x
3
# define points for creating plot
4
z = np.linspace(1, 4, 100)
5
# define data points and store them in x and y
6
x = np.array([1, 1.5, 4])
7
y = f(x)
8
# compute Lagrange interpolant and store it to yz
9
yz = lagrange_interpolant(z, x, y)
10
# plot the results
11
plt.plot(z,yz,'-')
12
plt.plot(x,y,'o')
13
plt.plot(z,f(z),'-.')
14
plt.legend(["$P_2(x)$","data","$f(x)$"])
15
plt.xlabel('x'); plt.ylabel('y'); plt.show()
1.0
1.5
2.0
2.5
3.0
3.5
4.0
x
0.2
0.4
0.6
0.8
1.0
y
P2(x)
data
f(x)
The interpolating polynomial coincides with f(x) at the points (xi, yi). However, there is
a notable difference between the graphs of the function and its interpolant. We can achieve
better approximation using interpolating polynomials of higher degree N. For example, if
we consider the interpolating polynomial P4 by taking 5 points (xi, yi) the interpolating
polynomial is almost identical to the function f(x), as shown in the following figure.
1.0
1.5
2.0
2.5
3.0
3.5
4.0
x
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
y
P4(x)
data
f(x)

Lagrange Interpolation
185
Taking higher degree interpolating polynomials the situation will not be always better.
A counter example is the well-known Runge’s example.
6.2.3
Failure of Lagrange interpolation
The function
f(x) =
1
1 + 25x2 ,
is known as the Runge function. Surprisingly, the Lagrange interpolation fails for this func-
tion, in the sense that the interpolant cannot be as close to f(x) as we would like to be, [111].
The shape of Runge’s function is like a Gaussian bell but it decays with a polynomial rate.
We will interpolate this function in the interval [−1, 1] using 10 and 15 points. Using N = 9
we observe that the interpolating polynomial oscillates around Runge’s function. With the
hope that the approximation will be improved we take N = 15. To our surprise, we observe
that the polynomial P14 is far away from f, especially for x closer to the endpoints ±1.
The explanation of this phenomenon lies in the error of polynomial interpolation. As
in the case of Taylor polynomials, the error of the Lagrange interpolation depends on the
magnitude of the N + 1-th derivative of f. If this derivative is large, then the interpolation
error will also be large. And in the case of Runge’s function, the magnitude of the derivatives
of f is increasing with N. This means that the higher the degree of the interpolating
polynomial, the larger the interpolation error.
A remedy to this problem is to use a non-uniform grid of nodes. A standard example of
such nodes are the Chebyshev nodes
xk = cos
 2k + 1
2(N + 1)π

,
k = 0, 1, . . . , N .

Runge’s phenomenon demonstrates the fact that high degree polynomials are
in general not suitable for interpolation problems.
The reader who is interested in the error analysis of polynomial interpolation can proceed
with the next section. Otherwise, we consider efficient and more stable ways of computing
the interpolating polynomial in Section 6.2.5. We also discuss the interpolation with piece-
wise polynomial functions, which solves Runge’s phenomenon in Section 6.3.
6.2.4
Error analysis
Thus far, we have proved the existence of a unique interpolating polynomial as a conse-
quence of Vandermonde matrix properties. We have also seen that there are cases where
the Lagrange interpolation can fail. Here we estimate the error between the interpolating
polynomial and function f, and explain why Lagrange interpolation can fail.
We easily understand the distance between two numbers to be the absolute value of their
difference. The distance between two functions (polynomials are functions too) is harder to
conceptualize. We measure the distance between functions using appropriate norms. A norm
generalizes the notion of absolute value and is denoted by ∥·∥instead of |·| which we reserve
for absolute values. So the distance between two functions f and g will be the norm ∥f −g∥
and is a positive number (or 0 if the two functions are identically the same).
In particular, a norm is a positive function ∥· ∥: S →[0, ∞), where S is a space of
functions like C(a, b). A norm should also satisfy the following properties: For all f, g ∈S
and all a ∈R,

186
Interpolation and Approximation
 ∥f∥≥0
 If ∥f∥= 0 then f(x) = 0 for all x in the domain of f
 ∥f + g∥≤∥f∥+ ∥g∥
 ∥af∥= |a|∥f∥
Here we consider the ∥f∥∞= max
a≤x≤b|f(x)| which satisfies all the previous properties and is
known as the L∞-norm. If we compute the L∞-norm of the difference of two functions
∥f −g∥∞= max
a≤x≤b |f(x) −g(x)| ,
we practically compute the maximum vertical distance between the two functions. This
norm is also called the uniform or maximum norm.
Among other norms for functions we use very often the L2-norm
∥f∥2 =
 Z b
a
|f(x)|2 dx
!1/2
.
The last one again is a positive number and measures the square root of the area of the
function |f(x)|2. Taking again the difference of two functions ∥f −g∥2 we compute the
square root of the area of the function |f(x)−g(x)|2. If the two functions are close together,
then the area of the difference squared will be small2.
We proceed now with the estimation of the interpolation error. This is practically equiv-
alent with estimating the remainder of the interpolating polynomial.
Theorem 6.2. Let N ∈N, f ∈CN+1[a, b] and the nodes x0, . . . , xN ∈[a, b]. Then, for the
Lagrange interpolating polynomial PN(x) of the function f(x) there is ξ ∈(a, b) such that
f(x) −PN(x) = f N+1(ξ)
(N + 1)!
N
Y
i=0
(x −xi)
for all x ∈[a, b] ,
and
∥f −PN∥∞≤max
a≤x≤b

N
Y
i=0
(x −xi)

∥f (N+1)∥∞
(N + 1)!
,
where
∥g∥∞= max
a≤x≤b |g(x)| .
Proof. For x ∈{x0, . . . , xN} the result is obvious since f(xi) −p(xi) = 0. Let x ̸= xi and
let
QN+1(x) =
N
Y
i=0
(x −xi) .
We define the function
h(t) := f(t) −PN(t) −f(x) −PN(x)
QN+1(x)
QN+1(t) ,
with t ∈[a, b]. Obviously, h ∈CN+1[a, b]. For t = xi we have
h(xi) = f(xi) −PN(xi) = 0,
i = 0, . . . , N ,
2The absolute value in the definition of the L2-norm is required only if f is a complex function.

Lagrange Interpolation
187
and for t = x we have
h(x) = f(x) −PN(x) −f(x) −PN(x)
QN+1(x)
QN+1(x) = 0 .
This means that h(t) has at least N + 2 distinct roots in [a, b], namely, xi, for i = 0, . . . , N
and x. According to Rolle’s Theorem 4.2, h′ has at least N + 1 roots in (a, b), and so h′′
has at least n roots, e.t.c. and h(N+1) has at least one root ξ ∈(a, b). Then, for t ∈[a, b]
h(N+1)(t) = f (N+1)(t) −f(x) −PN(x)
QN+1(x)
(N + 1)! ,
and so
0 = f (N+1)(ξ) −f(x) −PN(x)
QN+1(x)
(N + 1)! .
Solving for f(x) −PN(x) yields
f(x) −PN(x) = f (N+1)(ξ)
(N + 1)!
N
Y
i=0
(x −xi) ,
(6.7)
for all x ∈[a, b].
Taking the maximum of |f(x) −PN(x)| in (6.7) we see that
∥f −PN∥∞≤max
a≤x≤b

N
Y
i=0
(x −xi)

∥f (N+1)∥∞
(N + 1)!
,
which gives an upper bound for the interpolation error in the L∞-norm.
What we have practically showed is the following: Let f(x) ∈CN+1[a, b], then
f(x) = PN(x) + RN(x) ,
where PN(x) is the interpolating polynomial and
RN(x) = f (N+1)(ξ)
(N + 1)! QN+1(x)
with
ξ ∈(a, b) ,
with
QN+1(x) =
N
Y
i=0
(x −xi) = (x −x0)(x −x1) · · · (x −xN) ,
is the remainder. It is worth mentioning the following observations:
 For Taylor polynomials QN+1(x) = (x−x0)N+1 and the error vanishes only at the point
x0.
 For Lagrange interpolating polynomials the error vanishes at all nodes xi, i =
0, 1, . . . , N.
 To minimize RN(x) requires minimizing |Q(x)| for x ∈[a, b].
The reason for possible bad performance of the Lagrange interpolation is the high-order
derivatives in the formula of the error RN(x). In Runge’s example the high-order derivatives
are large near the boundaries of the interval [−1, 1], which results to large errors in the
approximation.

188
Interpolation and Approximation
6.2.5
Newton’s representation with divided differences
The representation of the interpolating polynomial using Lagrange polynomials is very
convenient especially for theoretical considerations. On the other hand, the computation of
Lagrange polynomials can be proved inefficient in practice. For this reason, we will present
an alternative representation of the same interpolating polynomial using Newton’s form.3
Suppose that PN(x) is the Lagrange polynomial of degree N interpolating f(x) at the
nodes x0, x1, . . . , xN. Newton’s form for writting the polynomial PN is
PN(x) = a0 + a1(x −x0) + a2(x −x0)(x −x1) + · · · + aN(x −x0) · · · (x −xN−1) ,
where a0, a1, . . . , aN have to be computed. Note that these coefficients are different from
the coefficients of the polynomial in the naive interpolation.
The main idea is to write
PN(x) = PN−1(x) + qN(x) ,
where PN−1(x) is the Lagrange interpolating polynomial of degree N −1, and qN(x) a
polynomial of degree N. Apparently, qN(x) = aN(x −x0) · · · (x −xN−1). This form has the
advantage that we can add nodes without the need of computing the whole interpolating
polynomial from the beginning. Newton’s form of polynomials leads to the efficient evalua-
tion of polynomials. To see how we can evaluate these polynomials efficiently in Newton’s
form consider a polynomial of degree 3 written as
P3(x) = a0 + a1(x −x0) + a2(x −x0)(x −x1) + a3(x −x0)(x −x1)(x −x2)
= a0 + (x −x0){a1 + (x −x1)[a2 + a3(x −x2)]} .
This can be evaluated with the following recursive relations
p0(x) = a3 ,
p1(x) = a2 + (x −x2)p0(x) ,
p2(x) = a1 + (x −x1)p1(x) ,
p3(x) = a0 + (x −x0)p2(x) ,
and finally P3(x) = p3(x).
The recursive relation for any value of N is
p0(x) = aN ,
pk(x) = aN−k + (x −xN−k)pk−1(x), k = 1, 2, . . . , N .
Given the coefficients a0, a1, . . . , aN the evaluation of a polynomial in its Newton’s form at
the point x can be summarized in Algorithm 18.
Algorithm 18 Evaluation of a polynomial in its Newton’s form
Given the point z and the nodes x0, x1, . . . , xN
Initialize p = aN
for k = 1 : N do
p = aN−k + (z −xN−k)p
end for
On return the variable p contains the value PN(z)
3This should not be confused with Newton’s method as it is totally irrelevant. The name comes from
the way we write the polynomial and which is due to Newton again!

Lagrange Interpolation
189
The implementation of Algorithm 18 in Python can be carried out in the following way:
1
def poly_evaluation(a,x,z):
2
#Evaluation of the polynomial with coefficients a at the points z
3
N = len(x) - 1 #Degree of polynomial
4
p = a[N]
5
for k in range(1,N+1):
6
p = a[N-k] + (z - x[N-k])*p
7
return p
Efficient evaluation of the coefficients
The remaining issue in Newton’s form of interpolation is to determine the coefficients ai
for i = 0, 1, . . . , N. Since the graph of the interpolation polynomial PN passes through the
data (xi, yi) we have
yi = PN(xi), i = 0, 1, . . . , N .
This implies that
y0 = a0 ,
y1 = a0 + a1(x1 −x0) ,
y2 = a0 + a1(x2 −x0) + a2(x2 −x0)(x2 −x1) ,
...
yN = a0 + a1(xN −x0) + · · · + aN(xN −x0)(xN −x1) · · · (xN −xN−1) ,
and in general
yk =
k
X
i=0
ai
i−1
Y
j=0
(xk −xj),
for k = 0, 1, . . . , N .
Note that
yk = Pk−1(xk) + ak Qk(xk)
where
Qk(x) =
k−1
Y
j=0
(x −xj) .
Solving for ak we have
ak = yk −Pk−1(xk)
Qk(xk)
,
k = 0, 1, . . . , N .
Because yk = Pk(xk) = f(xk) we have
ak = f(xk) −Pk−1(xk)
Qk(xk)
,
k = 0, 1, . . . , N .
More analytically, we have
a0 = y0 = f(x0) ,
and
a1 = y1 −a0
x1 −x0
= y1 −y0
x1 −x0
= f(x1) −f(x0)
x1 −x0
,

190
Interpolation and Approximation
TABLE 6.1
Divided differences tableau for the computation of the coefficients of the
Newton’s polynomial
xi
f(xi)
1-st order
2-nd order
3-rd order
· · ·
N-th order
x0
y0
x1
y1
∆1y1
x2
y2
∆1y2
∆2y2
x3
y3
∆1y3
∆2y3
∆3y3
...
...
...
...
...
...
xN
yN
∆1yN
∆2yN
∆3yN
· · ·
∆NyN
a2 = y2 −a0 −a1(x2 −x0)
(x2 −x0)(x2 −x1)
=
f(x2)−f(x0)
x2−x0
−f(x1)−f(x0)
x1−x0
x2 −x1
,
...
The fractions of the form f(xi)−f(xj)
xi−xj
, appearing in the right-hand sides of these formulas
are called divided differences. Divided differences approximate derivatives of a function
f. In particular, a1 seems to approximate the first derivative of f at some point and the
coefficient a2 the second derivative of f at some other point. It is very common also to denote
ak = f[x0, x1, . . . , xk] to highlight the dependence of the coefficient on the nodes xi. At this
stage, in order to simplify notation, we will denote the divided difference approximations of
the first order derivatives by ∆1yi, the divided difference approximation of the second order
derivatives by ∆2yi and that of the N-th order by ∆Nyi and are given by the formulas
∆1yi = yi −y0
xi −x0
,
i = 1, 2, . . . , N ,
∆2yi = ∆yi −∆y1
xi −x1
,
i = 2, . . . , N ,
∆3yi = ∆2yi −∆2y2
xi −x2
,
i = 3, . . . , N ,
...
∆Nyi = ∆N−1yi −∆N−1yi−1
xi −xi−1
,
i = N .
It is convenient to arrange all the divided differences in the columns of a tableau like the
one in Table 6.1. In such a tableau the coefficients ai are the diagonal entries ∆iyi shown
in boxes.
For example, consider the data
xi
1
2
4
5
yi
1
4
16
25
In this case, the interpolating polynomial is of degree at most 3 (since N = 3) and it can
be written in Newton’s form as
P3(x) = a0 + a1(x −x0) + a2(x −x0)(x −x1) + a3(x −x0)(x −x1)(x −x2) .

Lagrange Interpolation
191
TABLE 6.2
Example of divided differences tableau
xi
f(xi)
1-st order
2-nd order
3-rd order
1
1
2
4
3
4
16
5
1
5
25
6
1
0
To find the coefficients a0, a1, a2, a3 we fill in the divided differences Table 6.2 and we
conclude that the interpolating polynomial is actually the quadratic polynomial
P2(x) = 1 + 3(x −1) + 1(x −1)(x −2) + 0(x −1)(x −2)(x −4) = x2 .
Algorithm 19 Interpolating polynomial coefficients using divided differences
Given the data (xi, yi), i = 0, 1, . . . , N
for i = 0 : N do
ai = yi = f(xi)
end for
for k = 1 : N do
for j = k : N do
aj = (aj −ak−1)/(xj −xk−1)
end for
end for
The algorithm for the computation of the coefficients ai using divided differences is
summarized in Algorithm 19. In this algorithm we store only the diagonal entries of Ta-
ble 6.3. Initially the coefficient a0 is the correct polynomial coefficient. In the next step we
compute the first order divided differences, and we store them in the entries a1, a2, . . . , an
where a1 is the correct coefficient for the interpolating polynomial. We continue in the same
way modifying in each step only the coefficients that they are not correct. Assuming that
the interpolating data (xi, yi) are stored in the arrays (vectors) x and y, the implementa-
tion of this algorithm in Python can be straightforward and is presented in the function
poly coeffs.
1
def poly_coeffs(x, y):
2
n = len(x)
3
a = y.copy()
4
for k in range(1,n):
5
a[k:n] = (a[k:n] - a[k-1])/(x[k:n] - x[k-1])
6
return a
The interpolating polynomial in Newton’s form can be written as
PN(x) =
N
X
i=0
ai
i−1
Y
j=0
(x −xj) .
This form has been implemented in the function poly evaluation. In order to test our
code we can try to interpolate Runge’s function to obtain the same results as before.

192
Interpolation and Approximation
1
def f(x):
2
return 1.0 / (1.0 + 25.0 * x**2)
3
# z are the points we use to plot the interpolating polynomial
4
z = np.linspace(-1, 1, 100)
5
x = np.linspace(-1, 1, 10)
6
y = f(x)
7
a = poly_coeffs(x, y)
8
# yz are the values of the interpolating polynomial at z
9
yz = poly_evaluation(a,x,z)
10
plt.plot(z,yz,'-')
11
plt.plot(x,y,'o')
12
plt.plot(z,f(z),'-.')
13
plt.legend(["$P_9(x)$","data","$f(x)$"])
14
plt.xlabel('x'); plt.ylabel('y'); plt.show()
An advantage of Newton’s form for the interpolating polynomial is that we can add an
extra point in the interpolation data without evaluating the polynomial from the beginning.
We simply add an extra term in the polynomial formula. Moreover, the evaluation of the
polynomial is faster, which is important especially in high-order interpolation. Although
there are big advantages in the use of Newton’s form, there is no way to overcome Runge’s
problem due to the interpolation error.
6.2.6
More on divided differences
In this section we present an alternative divided differences algorithm for the computa-
tion of the coefficients of the interpolating polynomial in Newton’s form. We saw that the
interpolating polynomial PN(x) written in Newton’s form is
PN(x) = a0 + a1(x −x0) + a2(x −x0)(x −x1) + · · · + aN(x −x0) · · · (x −xN−1)
= PN−1(x) + aN QN(x) ,
where
QN(x) = (x −x0) · · · (x −xN−1) .
As a consequence of (6.5), the polynomial coefficients ak can be computed using finite
differences via the formula
ak =
k
X
i=0
yi
Q′
N+1(xi) .
These coefficients can be written as
a0 = y0 = f(x0) ,
and
a1 = y1 −a0
x1 −x0
= y1 −y0
x1 −x0
= f(x1) −f(x0)
x1 −x0
,
a2 = y2 −a0 −a1(x2 −x0)
(x2 −x0)(x2 −x1)
=
f(x2)−f(x0)
x2−x0
−f(x1)−f(x0)
x1−x0
x2 −x1
,
...

Lagrange Interpolation
193
Rearranging the fractions appeared in a2 we can write it as
a2 =
f(x2)−f(x0)
x2−x0
−f(x1)−f(x0)
x1−x0
x2 −x1
=
f(x2)−f(x1)
x2−x0
+ f(x1)−f(x0)
x2−x0
−f(x1)−f(x0)
x1−x0
x2 −x1
=
f(x2)−f(x1)
x2−x0
x2 −x1
+
[f(x1) −f(x0)](x2 −x1)
(x2 −x0)(x2 −x1)(x1 −x0) ,
thus
a2 =
f(x2)−f(x1)
x2−x1
−f(x1)−f(x0)
x1−x0
x2 −x0
.
Similarly, we can modify the rest of the formulas to obtain a new formulation for our
interpolation algorithm. Specifically, the coefficients ai can be defined as
ai = f[x0, x1, . . . , xi] ,
where
f[x0, x1, . . . , xi] = f[x1, x2, . . . , xi] −f[x0, x1, . . . , xi−1]
xi −x0
,
xi ̸= x0 ,
and
f[xi, xi+1, . . . , xj] = f[xi+1, xi+2, . . . , xj] −f[xi, xi+1, . . . , xj−1]
xj −xi
,
xi ̸= xj .
(6.8)
In this notation we have that
f[xi] = f(xi) ,
f[xi, xi+1] = f[xi+1] −f[xi]
xi+1 −xi
,
f[xi, xi+1, xi+2] = f[xi+1, xi+2] −f[xi, xi+1]
xi+2 −xi
,
· · ·
while f[x0, x1, . . . , xi] is the coefficient ai of the interpolating polynomial Pi. Furthermore,
f[x1, x2, . . . , xi] is the coefficient of the term xi−1 of the polynomial of degree less than or
equal to i −1 that interpolates f at x1, x2, . . . , xi.
In this book we define the divided differences with one of their properties:
Definition 6.3. For x0 ≤x1 ≤· · · ≤xN, the divided differences of a smooth function f
are defined as
f[xi, xi+1, . . . , xj] =
(
f[xi+1,...,xj]−f[xi,...,xj−1]
xj−xi
,
xi ̸= xj
f (j−i)(xi)
(j−i)!
,
xi = xj
.
In this definition we have included the case xi = xj, which will be useful later for
the Hermite interpolation. There are other more general definitions but here, and at the
particular stage of this book, we focus on the computational part of this technique. Needless
to say, Newton’s form of polynomials is in general very useful for theoretical purposes as
well.

194
Interpolation and Approximation
TABLE 6.3
Divided differences tableau for the computation of the coefficients of Newton’s polynomial
xi
f(xi)
1st order
2nd order
3rd order
4th order
x0
y0 = f[x0]
f[x0, x1]
x1
y1 = f[x1]
f[x0, x1, x2]
f[x1, x2]
f[x0, x1, x2, x3]
x2
y2 = f[x2]
f[x1, x2, x3]
f[x0, x1, x2, x3, x4]
f[x2, x3]
f[x1, x2, x3, x4]
x3
y2 = f[x3]
f[x2, x3, x4]
f[x3, x4]
x4
y3 = f[x4]
It is not hard to see that the first three divided differences a0, a1 and a2 are given by
the formulas
f[x0] = f(x0) ,
f[x0, x1] = f(x1) −f[x0]
x1 −x0
,
f[x0, x1, x2] = f(x2) −f[x0] −f[x0, x1](x2 −x0)
(x2 −x0)(x2 −x1)
.
Using this traditional notation, Newton’s form of the interpolating polynomial is written in
the form
PN(x) =
N
X
i=0

f[x0, x1, . . . , xi]
i−1
Y
j=0
(x −xj)

.
For example, if we consider the case with only 2 nodes (N = 1), the linear polynomial
interpolating the points (x0, f(x0)) and (x1, f(x1)) is
P1(x) = f[x0] + f[x0, x1](x −x0) .
This is the secant of f passing through the two interpolation points
P1(x) = f(x0) + f(x1) −f(x0)
x1 −x0
(x −x0) .
It is also noted that if f(x) is continuously differentiable function, then
lim
xi+1→xi f[xi, xi+1] =
lim
xi→xi+1
f(xi+1) −f(xi)
xi+1 −xi
= f ′(xi) .
If f(x) is polynomial of degree at most k, then f[xi, . . . , xi+k] = 0.
Because of this new formulation it is convenient to rearrange Table 6.1 to a new Table
6.3, where the coefficients of the interpolating polynomial are the same as before but there
are differences in the other entries.
For example, if we consider the data of Table 6.2, the new divided differences tableau
is presented in Table 6.4. This is different from Table 6.1 but the interpolating polynomial
remains the same as the diagonal entries are identically the same.

Hermite Interpolation
195
TABLE 6.4
Example of divided difference method
xi
f(xi)
1st order
2nd order
3rd order
1
1
3
2
4
1
6
0
4
16
1
9
5
25
The algorithm for the computation of the coefficients of the divided difference table in
the last form can be written as follows: Since we are interested only in the computation of
the diagonal entries ai, we apply formula (6.8) directly to obtain the Algorithm 20.
Algorithm 20 Divided differences coefficients
Given the data (xi, yi), i = 0, 1, . . . , N
for i = 0 : N do
Set ai = yi = f(xi)
end for
for j = 1 : N do
for i = n : j : −1 do
ai = (ai −ai−1)/(xi+j −xi)
end for
end for
The notation in the loop conditions i = a : b : c of the previous pseudo-code means
that a is the starting value, b is the stop value and c is the step. The implementation of
Algorithm (20) is straightforward and is left as an exercise for the reader.
In this notation, the polynomial PN(x) is then
PN(x) =
N
X
i=0
ai
i−1
Y
j=0
(x −xj) .
Having developed most of the ideas of polynomial interpolation, we move on with another
interpolation method that takes into account the smoothness of f.
6.3
Hermite Interpolation
Assume that we have at our disposal in addition to data (xi, yi), for i = 0, 1, . . . , N with
yi = f(xi), all the values of the derivative f ′(xi) at the nodes xi. This means that in addition
to (xi, yi) we have at our disposal the data (xi, y′
i) where y′
i = f ′(xi), for i = 0, 1, . . . , N.
Particularly, in this case, we have 2N + 2 data that we can use to find an interpolating
polynomial of degree 2N + 1 with 2N + 2 coefficients. The new polynomial will interpolate
the values P2N+1(xi) = f(xi) and P ′
2N+1(xi) = f ′(xi) for i = 0, 1, . . . , N. This extension of
the Lagrange interpolation that respects the derivative of the function at the nodes is called
Hermite interpolation and was introduced by Charles Hermite (1822–1901). In the sequel
we denote the Hermite interpolation polynomial by H2N+1 instead of P2N+1 to distinguish
it from the Lagrange interpolant.

196
Interpolation and Approximation
6.3.1
Computation of the Hermite interpolant
In Hermite interpolation is rather convenient to write the interpolating polynomial in the
form
H2N+1(x) =
N
X
i=0
[αi(x)f(xi) + βi(x)f ′(xi)] .
(6.9)
In order for H2N+1 to interpolate the points (xi, yi) we need
αi(xj) = δij,
and
βi(xj) = 0 .
(6.10)
Furthermore, in order for the derivative of the polynomial to interpolate the data (xi, y′
i)
we need
α′
i(xj) = 0,
and
β′
i(xj) = δij .
(6.11)
Thus, we expect that the unique Hermite polynomial H2N+1(x) will satisfy the constraints
(6.10)–(6.11). In order to construct the coefficients αi and βi we make use of the usual
Lagrange polynomials
ℓi(x) =
N
Y
j=0
j̸=i
x −xj
xi −xj
,
that satisfy ℓi(xj) = ℓ2
i (xj) = δij. The degree of the polynomial ℓi(x) is N, implying that
the degree of ℓ2
i (x) is 2N. Thus, in order for the degree of αi(x) and βi(x) to be 2N + 1,
we write
αi(x) = ri(x)ℓ2
i (x),
βi(x) = si(x)ℓ2
i (x) ,
where ri(x) and si(x) should be both linear polynomials. Using (6.10) we have
δij = αi(xj) = ri(xj)ℓ2
i (xj) = ri(xj)δij ,
and thus
ri(xi) = 1 .
(6.12)
Similarly, using (6.11) we have
0 = α′
i(xj) = r′
i(xj)ℓ2
i (xj) + 2ri(xj)ℓi(xj)ℓ′
i(xj) = r′
i(xj)δij + 2ri(xj)δijℓ′
i(xj) ,
which implies
r′
i(xi) = −2ℓ′
i(xi) .
(6.13)
Writing ri(x) = ax + b (since it is a linear polynomial) we compute the coefficients a and b
through (6.12) and (6.13) as
a = −2ℓ′
i(xi),
b = 1 + 2ℓ′
i(xi)xi .
Therefore, we obtain
αi(x) = [1 −2ℓ′
i(xi)(x −xi)]ℓ2
i (x) .
(6.14)
Similarly, from (6.10) we obtain si(xi) = 0 and from (6.11) that s′
i(xj) = 1, which implies
immediately that
si(x) = x −xi ,
and thus
βi(x) = (x −xi)ℓ2
i (x) .
(6.15)

Hermite Interpolation
197

Given N + 1 nodes x0 < x1 < · · · < xN and the values f(xi) and f ′(xi) for
i = 0, 1, . . . , N, the Hermite interpolating polynomial is the polynomial
H2N+1(x) =
N
X
i=0
[αi(x)f(xi) + βi(x)f ′(xi)] ,
where αi and βi are given in terms of the Lagrange polynomials as
αi(x) = [1 −2ℓ′
i(xi)(x −xi)]ℓ2
i (x)
and
βi(x) = (x −xi)ℓ2
i (x) .
Here we present an implementation of the previous formulas. In order to compute the
polynomials ℓi(x) we use the NumPy function numpy.poly1d, which given the polynomial
coefficients in decreasing powers returns a polynomial function. We then compute the first
derivative of this function with the function numpy.polyder.
1
def Hermite(x,y,z):
2
# x, y: are the interpolating data
3
# z: values to the interpolant
4
N = len(x)
5
p = np.poly1d([0]) # initialize p
6
for i in range(N):
7
#derive L_k
8
L = np.poly1d([1])
9
for j in range(N):
10
if j!=i:
11
L = L*np.poly1d([1.0/(x[i]-x[j]), - x[j]/(x[i]-x[j])])
12
#Derivative of the Lagrange polynomials
13
dL = np.polyder(L)
14
#Computation of the functions alpha
15
alpha = (np.poly1d([1])-2*dL(x[i])*np.poly1d([1,-x[i]]))*L**2
16
#Computation of the functions beta
17
beta = np.poly1d([1,-x[i]])*L**2
18
p = p + alpha*y[i]+beta*z[i]
19
return p
The drawback of the Hermite interpolation is that it does not provide a solution to
Runge’s phenomenon. For example, using the previous implementation we compute the
Hermite polynomial with N = 9 for Runge’s function:
1
def f(x):
2
return 1.0/(1+25*x**2)
3
def df(x):
4
return -2*25*x/(1+25*x**2)**2
5
xi = np.linspace(-1,1,10)
6
yi = f(xi)
7
zi = df(xi)
8
x = np.linspace(-1,1,300)
9
y = f(x)
10
p = Hermite(xi,yi,zi)
11
y1 = p(x)

198
Interpolation and Approximation
12
plt.plot(x, y1, label="$H_{19}(x)$")
13
plt.plot(xi, yi, 'o', label='data')
14
plt.plot(x, y, '-.',label='$f(x)$')
15
plt.xlabel('$x$')
16
plt.ylabel('$y$',rotation=0)
17
plt.xlim(-1, 1)
18
plt.legend(loc='upper left', ncol=1)
19
plt.show()
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
x
−2.0
−1.5
−1.0
−0.5
0.0
0.5
1.0
y
H19(x)
data
f(x)
Comparing the result of the Hermite interpolation with Figure 6.2 we observe that the
Hermite interpolation is worse closer to the endpoints of the interval [−1, 1].
6.3.2
Error analysis
Now that we know what the Hermite interpolating polynomial is, it is rather useful to know
its accuracy in approximating functions. The following result will appear quite useful later
for theoretical estimate of the error of a particular method of numerical integration, the
so-called Gaussian quadrature.
−1.00 −0.75 −0.50 −0.25
0.00
0.25
0.50
0.75
1.00
x
−0.2
0.0
0.2
0.4
0.6
0.8
1.0
y
Interpolation of Runge's function
P9(x)
data
f(x)
−1.00 −0.75 −0.50 −0.25
0.00
0.25
0.50
0.75
1.00
x
−1
0
1
2
3
4
5
6
7
y
Interpolation of Runge's function
P14(x)
data
f(x)
FIGURE 6.2
Lagrange interpolation of Runge’s function with N = 9 and N = 14.

Hermite Interpolation
199
Theorem 6.4. Let N ∈N, f ∈C2N+2[a, b] . If H2N+1 is the Hermite interpolant of f(x)
at the nodes x0, . . . , xN ∈[a, b], then for all x ∈[a, b] there is a ξ = ξ(x) ∈(a, b) such that
f(x) −H2N+1(x) = f 2N+2(ξ)
(2N + 2)!
N
Y
i=0
(x −xi)2 .
Proof. If x is one of x0, x1, . . . , xN, then the result is obvious since f(xi) = H2N+1(xi) for
all i.
Let x ̸= xi and
Q(x) =
N
Y
i=0
(x −xi)2 .
We define the function
h(t) := f(t) −H2N+1(t) −f(x) −H2N+1(x)
Q(x)
Q(t) ,
with t ∈[a, b]. Obviously, h ∈C2N+2[a, b]. Moreover, we have
h(xi) = f(xi) −H2N+1(xi) = 0,
i = 0, . . . , N ,
and for t = x we have
h(x) = f(x) −H2N+1(x) −f(x) −H2N+1(x)
Q(x)
Q(x) = 0 .
This means that h(t) satisfies
h(x0) = h(x1) = · · · = h(xj) = h(x) = h(xj+1) = · · · = h(xN) = 0 .
Therefore, because of Role’s Theorem 4.2, there are ξ0, ξ1, . . . , ξN,
x0 < ξ0 < x1 < ξ1 < · · · < xj < ξj < x < ξj+1 < xj+1 < · · · < ξN < xN ,
such that
h′(ξi) = 0,
i = 0, . . . , N .
The fact that P ′
2N+1(xi) = f ′(xi) for i = 0, . . . , N implies h′(xi) = 0. Thus, the function
h′ has 2N + 2 roots. Similarly, h′′ has at least 2N + 1 roots, h′′′ has at least 2N roots and
finally for h(2N+2) we have that there is at least one ξ ∈(a, b) (which obviously depends on
x) such that h(2N+2)(ξ) = 0. But,
h(2N+2)(t) = f (2N+2)(t) −f(x) −H2N+1(x)
Q(x)
(2N + 2)! ,
and for t = ξ we get
0 = f (2N+2)(ξ) −f(x) −H2N+1(x)
Q(x)
(2N + 2)! .
Solving the last equation for f(x) −H2N+1(x) we obtain the error formula
f(x) −H2N+1(x) = f 2N+2(ξ)
(2N + 2)!Q(x) ,
which is the desired error formula.

200
Interpolation and Approximation

Notice the differences between the two very similar Theorems 6.2 and 6.4. The
error still depends on high-order derivatives of f(x), but now the convergence as
N →∞is quadratic. Even if the convergence is quadratic, the presence of high-
order derivatives can lead to large errors. For this reason Hermite interpolation is
not the solution to Runge’s problem.
6.3.3
Implementation details
Given the data (xi, f(xi)) and (xi, f ′(xi)) for i = 0, 1, . . . , N, the Hermite interpolation
polynomial can be computed using divided differences and Newton’s form of polynomials.
Specifically, we can construct a table with the divided differences this time using the fact
that f[x0, x0] = f ′(x0), f[x1, x1] = f ′(x1) etc. The idea is very similar to the Lagrange
interpolation. The difference is that we use the data f ′(xi) and the fact that we can write
the Hermite interpolating polynomial in the form
H2N+1(x) =
2N+1
X
i=0
f[z0, z1, . . . , zi]
i−1
Y
j=0
(x −zj) ,
where the nodes z0, z1, . . . , z2N+1 are defined such that z2i = z2i+1 = xi, for i = 0, 1, . . . , N.
Since z2i = z2i+1 = xi, for each i we have that f[z2i, z2i+1] = f ′(z2i) = f ′(xi). The complete
explanation of this property of the Hermite interpolating polynomial can be found in [107].
If we have for example the three triplets (xi, yi, y′
i), for i = 0, 1, 2, then we construct
Table 6.5 similar to Table 6.3 using the zi values instead of the xi values. It is therefore
straightforward to extend the algorithms and codes of Section 6.2.5 to compute the Hermite
interpolation polynomial, and thus we leave it as an exercise for the reader.
The Hermite interpolation can also be extended to higher order polynomials provided
data for high order derivatives of the function f. The extension of the Hermite interpolation
in the case where certain derivatives have specified values at specified points is known as
Hermite-Birkhoff interpolation, [10].

While Hermite interpolation does not solve Runge’s phenomenon, it can be more
accurate than the Lagrange interpolation. The error of the Hermite interpolation
depends on the values of high-order derivatives of f(x). Lagrange interpolation is
preferable because of its simplicity.
6.4
Spline Interpolation
One way to overcome the problems of Lagrange interpolation is by using spline interpolation.
Spline interpolation is the interpolation of data using piecewise polynomial functions instead
of one uniform polynomial. For this reason, spline interpolation is also known as piecewise-
polynomial interpolation. The root of the word spline is the same as that of the word splint,
which was originally a narrow piece of wood that could be used to join two boards. Later,
the word was used to refer to a tool consisting of a long flexible piece of metal that could be

Spline Interpolation
201
TABLE 6.5
Divided differences tableau for the computation of the coefficients of the Hermite polynomial
xi
f(xi)
1st order
2nd order
3rd order
4th order
5th order
z0 = x0
f[z0] = f(x0)
f[z0, z1] = f ′(x0)
z1 = x0
f[z1] = f(x0)
f[z0, z1, z2]
f[z1, z2]
f[z0, z1, z2, z3]
z2 = x1
f[z2] = f(x1)
f[z1, z2, z3]
f[z0, z1, z2, z3, z4]
f[z2, z3] = f ′(x1)
f[z1, z2, z3, z4]
f[z0, z1, z2, z3, z4, z5]
z3 = x1
f[z3] = f(x1)
f[z2, z3, z4]
f[z1, z2, z3, z4, z5]
f[z3, z4]
f[z2, z3, z4, z5]
z4 = x2
f[z4] = f(x2)
f[z3, z4, z5]
f[z4, z5] = f ′(x2)
z5 = x2
f[z5] = f(x2)

202
Interpolation and Approximation
used to draw smooth curves by forcing the tool to pass through specified points and tracing
along the curve.
The simplest piecewise-polynomial approximation is the piecewise linear interpolation
in which we connect the set of data points
{(x0, f(x0)), (x1, f(x1)), . . . , (xN, f(xN))} ,
with straight lines.
6.4.1
Continuous piecewise linear interpolation
Piecewise linear interpolation, also known as linear spline interpolation, is basically the
method we use to plot a function using the plot command of matplotlib. Instead of
sketching a graph of the actual function f(x), we first generate a grid of nodes x0, x1, . . . , xN,
and then we compute the values f(x0), f(x1), . . . , f(xN). In other words, we generate a set
of data points {xi, f(xi)} and we ask Python to make a plot using these points. The Python
code in such a case can be the following:
1
x = np.linspace(0, 2.0*np.pi, 10)
2
y = np.sin(x)
3
plt.plot(x,y,'o-')
4
plt.xlabel('$x$'); plt.ylabel('$y$',rotation=0); plt.show()
0
1
2
3
4
5
6
x
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
y
Python plots the function sin(x) using 10 nodes by connecting the points {xi, f(xi)} with
line segments. This piecewise linear function is in practical terms a linear interpolating
spline.

The resulting linear interpolating spline is continuous everywhere but not dif-
ferentiable at the nodes xi. In some circumstances we define a derivative of such
piecewise polynomial function as a discontinuous function.
In the case of splines there is no interpolating polynomial. Instead, there is an interpo-
lating function, which in the case of linear splines consists of different linear polynomials
for each interval [xi, xi+1]. Specifically, the line-segment that connects the points (xi, f(xi))

Spline Interpolation
203
and (xi+1, f(xi+1)) is given by the formula
si(x) = xi+1 −x
xi+1 −xi
f(xi) +
x −xi
xi+1 −xi
f(xi+1) ,
(6.16)
for x ∈[xi, xi+1]. It is easy to see that si(xi) = f(xi) and si(xi+1) = f(xi+1). A piecewise
linear function is assembled by linear functions si on each interval [xi, xi+1], with i =
0, . . . , N. A piecewise linear interpolant is a piecewise linear function that interpolates points
(xi, f(xi)), i = 0, 1, . . . , N. This is a function such as
Pl(x) =







s0(x),
x ∈[x0, x1)
s1(x),
x ∈[x1, x2)
· · ·
sN−1,
x ∈[xN−1, xN]
,
where si(x) is given by the formula (6.16).
Instead of computing all the linear functions si(x), it is more convenient to follow the
same technique we used in the case of the Lagrange interpolation and express the interpo-
lating function as a linear combination of some basis functions ϕi(x):
Pl(x) =
N
X
i=0
ciϕi(x) .
Let a = x0 < x1 < x2 < · · · < xN = b a partition of [a, b] and yi = f(xi), i = 0, . . . , N given
points. The functions
ϕi(x) =





x−xi−1
xi−xi−1 ,
xi−1 ≤x ≤xi
xi+1−x
xi+1−xi ,
xi ≤x ≤xi+1
0,
x ∈¯I −(xi−1, xi+1)
,
(6.17)
for i = 1, . . . , N −1,
ϕ0(x) =

x1−x
x1−x0 ,
x0 ≤x ≤x1
0,
x ∈¯I −(x0, x1)
,
(6.18)
and
ϕN(x) =

x−xN−1
xN−xN−1 ,
xN−1 ≤x ≤xN
0,
x ∈¯I −(xN−1, xN)
,
(6.19)
are the basis functions of the space of piecewise linear functions in which our new inter-
polants lie. The shape of ϕi(x) is depicted in Figure 6.3. These basis functions are also
known to as hat functions because of their shape. They are also called linear B-splines.
Observe that each basis function ϕi(x) for i = 1, 2, . . . , N −1 is positive in only two inter-
vals [xi−1, xi] ∪[xi, xi+1] and zero anywhere else. Because of that, we say that they have
support [xi−1, xi] ∪[xi, xi+1]. The two basis functions at the boundary intervals need to
have support only one interval though. It is also important to note that the basis functions
satisfy ϕi(xi) = 1 and ϕi(xj) = 0 if j ̸= i. For this reason, we say that the basis functions
ϕi(x) are normalized.
Having defined the basis functions of the space of piecewise linear functions S1, we write
the piecewise linear interpolant as linear combination of the basis functions
Pl(x) =
N
X
i=0
f(xi)ϕi(x) .

204
Interpolation and Approximation
FIGURE 6.3
Linear spline basis functions with maximum value 1.
Since ϕi(xj) = 0 if i ̸= j and ϕi(xi) = 1 we have that Pl(xi) = f(xi). It is noted that Pl(x)
is piecewise linear and continuous function in [a, b]. We will denote the space of continuous
piecewise linear functions by
S1 = {f : f ∈C[a, b], f is linear polynomial on each (xi, xi+1), 0 ≤i ≤N −1} .
NumPy implementation
The piecewise linear interpolant can be computed easily using the function numpy.interp.
The general call of this function is
interp(x, xp, fp, left, right, period)
where
x:
An array with the x values at which we evaluate the interpolant
xp:
An array with the values xi, i = 0, . . . , N
fp:
An array with the values yi = f(xi), i = 0, . . . , N
left: Value to return if x<xp[0]. (Optional with default value None)
right: Value to return if x>xp[-1]. (Optional with default value None)
period: The period of the x values when f is periodic. In this case, the parameters left
and right are ignored. (Optional with default value None)
The data (xi, f(xi)) or (xi, yi) must be stored in two arrays xp and fp. The points where
we evaluate the interpolant are stored in an array x. The function interp returns the values
of the interpolant at the nodes x stored in an array y.
As an example, we consider again the function f(x) = sin(x) in the interval [0, 2π]. We
take N = 9 points (xi, f(xi)), i = 0, 1, . . . , N and we compute the linear spline interpolant
evaluated on 50 points zj, j = 0, 1, . . . , 49.
1
# define the interpolation points
2
xp = np.linspace(0, 2*np.pi, 10)
3
yp = np.sin(xp)
4
# define the points for ploting
5
x = np.linspace(0, 2*np.pi, 50)
6
# generate the linear spline
7
y = np.interp(x, xp, yp)
8
# plot spline vs data
9
plt.plot(x, y, '-x', label='$S_l(x)$')

Spline Interpolation
205
10
plt.plot(xp, yp, 'o', label='data')
11
plt.xlabel('$x$')
12
plt.ylabel('$y$',rotation=0)
13
plt.legend(loc='upper right', ncol=1)
0
1
2
3
4
5
6
x
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
y
Sl(x)
data
This figure is identical with the figure we generated by just ploting the same function
using 10 nodes. With the interpolant, of course, we are able to compute approximation to
sin(x) at any intermediate point x in [0, 2π]. Piecewise linear interpolation solves Runge’s
phenomenon. Specifically, the interpolant consists of straight lines connecting the interpo-
lation points (xi, yi) and it cannot oscillate around Runge’s function.
6.4.2
Some theoretical considerations
In piecewise linear interpolation, the function f(x) is being interpolated by the function
Pℓ(x) = PN
i=0 f(xi)ϕi(x) at the points (xi, f(xi)), for i = 0, 1, . . . , N. In this notation
ϕi(x) is the i-th basis function of the space of piecewise linear functions S1 given by the
formulas (6.17)-(6.19). Therefore, the function Pl belongs to the space S1, since it is a linear
combination of its basis functions. In order to see that the set {ϕi} spans the space S1, we
need some elements from linear algebra.
Proposition 6.5. The functions ϕi(x), i = 0, 1, . . . , N span the space S1
Proof. First observe that ϕi ∈S1. Moreover, if PN
i=0 ciϕi(x) = 0 for all x ∈[a, b], then it
is true that PN
i=0 ciϕi(xj) = 0 for j = 0, 1, . . . , N. This implies cj = 0. Thus, ϕi(x) are
linearly independent functions. Notice that every piecewise linear function ϕ(x) ∈S1 can
be written as
ϕ(x) =
N
X
i=0
ciϕi(x) ,
with ci = ϕi(xi), which means that the functions ϕi span the space S1, and the proof is
complete.
6.4.3
Error analysis of piecewise linear interpolation
The question, again, is how well the piecewise linear function Pl approximates f(x). In
order to make things rigorous, we consider a grid of nodes a = x0 < x1 < · · · < xN = b.

206
Interpolation and Approximation
The distance between two nodes xi, xi+1 is denoted by hi = xi+1 −xi, for i = 0, . . . , N −1.
We denote by h the maximum such distance, h = maxi hi. Then, the maximum distance
between f and its interpolant Pl is O(h2). For this reason, we will use the L∞-norm. This
result is explained in the following theorem:
Theorem 6.6. If f ∈C2[a, b] and given the partition a = x0 < x1 < · · · < xN = b, then
∥f −Pl∥∞≤Ch2 ,
where C > 0 is a constant independent of the choice of xi.
Proof. Since we work with the maximum-norm we will search for the distance |f(x)−Pl(x)|
at a point x ∈[a, b]. Assume that x ∈[xi, xi+1] for some i. Since Pl is a linear polynomial in
[xi, xi+1] that interpolates f(x) at the points xi and xi+1, it coincides with the P2 Lagrange
interpolant for these points. By Theorem 6.2 we have that x ∈[xi, xi+1]
f(x) −Pl(x) = f ′′(ξ)
2
(x −xi)(x −xi+1) ,
where ξ ∈(xi, xi+1). Taking absolute values on both sides of this relation we have
|f(x) −Pl(x)| = 1
2|f ′′(ξ)| |x −xi| |x −xi+1|
≤1
2 max |f ′′(x)| |xi+1 −xi| |xi −xi+1|
= Ch2 ,
where C = 1
2∥f ′′∥∞. Since the last inequality holds for all x, then we conclude that the
max |f(x) −Pl(x)| satisfy the same inequality.
The estimated constant C in this proof is not the smallest constant we can have in
the particular estimate. We can obtain a better estimate of C (implying smaller error) by
assuming (without loss of generality) that x is closer to xi+1. In such case we have that
|f(x) −Pl(x)| = 1
2|f ′′(ξ)| |x −xi| |x −xi+1|
= 1
2 max |f ′′(x)| |x −xi+1 + xi+1 −xi| |x −xi+1|
≤1
2 max |f ′′(x)|(|x −xi+1| + |xi+1 −xi|)|x −xi+1|
= 1
2 max |f ′′(x)|(|x −xi+1|2 + |xi+1 −xi| |x −xi+1|)
≤1
2 max |f ′′(x)|
|xi −xi+1|2
4
+ |xi+1 −xi|2
2

= 1
8 max |f ′′(x)|h2
i
≤Ch2 .
Therefore, the actual constant is C = 1
8∥f ′′∥∞.
We conclude that if the second derivative f ′′(x) is bounded, then the piecewise linear
interpolant Pl(x) converges to f(x) as h →0 for all x ∈[a, b].

Spline Interpolation
207
6.4.4
Cubic spline interpolation
Studying the accuracy of piecewise-linear interpolation we showed that the distance between
a function f and its linear spline interpolant is O(h2) with h = maxi |xi+1 −xi|. However,
the piecewise linear interpolant is not differentiable. Sometimes, we require the interpolant
to be smooth, and perhaps more accurate than the piecewise linear interpolant. In such
cases we can use higher order piecewise polynomial interpolation, such as quadratic, cubic,
quartic, quintic, etc.
Because the methodology for the construction of quadratic, cubic and other higher-
order splines is the same, we study here the construction of a cubic spline. A cubic spline
is a continuous piecewise cubic interpolant. A general cubic polynomial of the form a0 +
a1x + a2x2 + a3x3 involves four constants. This fact gives us flexibility to ensure that
the interpolant is continuously differentiable and it has a continuous second derivative.
The construction of cubic splines does not, however, assume that the derivatives of the
interpolant agree with those of the approximated function, even at the nodes.
Given a function f defined on [a, b] and a set of nodes a = x0 < x1 < · · · < xN = b, a
cubic spline interpolant Pc of f is a function equal to a different cubic polynomial Si(x) in
each interval [xi, xi+1] for every i = 0, 1, . . . , N −1. Such a function can be expressed with
the following formula of multiple cases (piecewise function)
Pc(x) =







S0(x),
x ∈[x0, x1) ,
S1(x),
x ∈[x1, x2) ,
· · ·
SN−1(x),
x ∈[xN−1, xN] .
Since we require Pc(x) to be twice continuously differentiable, the cubic polynomials Si
need to satisfy the following conditions:
(i) Si(xi) = f(xi) and Si(xi+1) = f(xi+1) for each i = 0, 1, . . . , N −1 (interpolates the
data)
(ii) Si+1(xi+1) = Si(xi+1) for each i = 0, 1, . . . , N −2 (is continuous)
(iii) S′
i+1(xi+1) = S′
i(xi+1) for each i = 0, 1, . . . , N −2 (has continuous first derivative)
(iv) S′′
i+1(xi+1) = S′′
i (xi+1) for each i = 0, 1, . . . , N −2 (has continuous second derivative)
Unfortunately, the continuity argument can only be used for the internal nodes and
not for the boundary nodes. In order to be able to estimate all the coefficients, including
those corresponding to boundary nodes, we impose boundary conditions. The most popular
boundary conditions are the following:
(a) P ′′
c (x0) = P ′′
c (xN) = 0 (natural (or free) boundary)
(b) P ′
c(x0) = f ′(x0) and P ′
c(xN) = f ′(xN) (clamped boundary)
(c) P ′′′
c (x) is continuous at x1 and xN−1 (“not-a-knot” boundary)
(d) Pc(x0) = Pc(xN) (Periodic boundary)
When natural boundary conditions are employed, we call the interpolating spline natural
spline. The natural boundary conditions do not require any knowledge of the function f on
the boundary. On the other hand, they impose conditions on the second derivatives of the
interpolating spline at the boundary. These conditions are not essential for the shape of the
function near the boundary, however, they introduce additional error. Clamped boundary

208
Interpolation and Approximation
conditions lead to more accurate approximations because they include more information
about f(x). However, for this type of boundary condition, it is necessary to have either the
values of f ′(x) at the endpoints or an accurate approximation to those values. Finally, the
“not-a-knot” condition does not imply any essential condition on the boundary, which is
ideal when there is no information regarding the behavior of f(x) at the endpoints x0 and
xN.
One of the simplest examples for understanding the procedures behind cubic spline
interpolation is the following: Assume that we want to find a natural spline that interpolates
the set of points (1, 2), (2, 3) and (4, 6) in the interval [1, 4]. In this case, N = 3 and thus
the spline consists of two (N −1 = 2) polynomials: The first in the interval [1, 2] can be
written as
S0(x) = a0 + a1(x −1) + a2(x −1)2 + a3(x −1)3 ,
and the other in the interval [2, 4] as
S1(x) = b0 + b1(x −2) + b2(x −2)2 + b3(x −2)3 .
The polynomials S0 and S1 is written in such a way so as to minimize the computations
later. In principle it is not required to express the polynomials in this form.
Therefore, there are 8 constants to be determined a0, a1, a2, a3 and b0, b1, b2, b3. To de-
termine 8 unknowns requires 8 conditions: The first 4 conditions come from the fact that
the spline must agree with the data at the nodes. Hence, from the conditions S0(1) = f(1),
S0(2) = f(2) = S1(2), S1(3) = f(3) we get
2 = f(1) = a0 ,
(6.20)
3 = f(2) = a0 + a1 + a2 + a3 ,
(6.21)
3 = f(2) = b0 ,
(6.22)
6 = f(4) = b0 + 2b1 + 4b2 + 8b3 .
(6.23)
There are 2 conditions from the continuity of spline’s first and second derivatives at the
internal nodes, (S′
0(2) = S′
1(2) and S′′
0 (2) = S′′
1 (2)):
S′
0(2) = S′
1(2) ⇒a1 + 2a2 + 3a3 = b1 ,
(6.24)
S′′
0 (2) = S′′
1 (2) ⇒2a2 + 6a3 = 2b2 .
(6.25)
The last conditions come from the natural boundary conditions:
S′′
0 (1) = 0 ⇒2a2 = 0 ,
(6.26)
S′′
1 (3) = 0 ⇒2b2 + 6b3 = 0 .
(6.27)
Equations (6.20)–(6.27) form a system of 8 equations for the 8 unknown coefficients. Solving
the corresponding 8 × 8 linear system is hard without the help of a computer. We obtained
the coefficients a0 = 2, a1 = 0, a2 = 1/3, a3 = 2/3, b0 = 3, b1 = 1, b2 = −1/3 and b3 = 7/24.
So the spline function can be written as
Pc(x) =
 2 + 1
3(x −1)2 + 2
4(x −1)3, for x ∈[1, 2]
3 + (x −2) −1
3(x −2)2 + 7
24(x −2)3, for x ∈[2, 4]
.
6.4.5
An algorithm for cubic splines
The steps we followed in the previous example to find the coefficients of the cubic polynomi-
als Si can be followed systematically to formulate an algorithm for computing cubic splines

Spline Interpolation
209
with various boundary conditions. Here we will focus on the case of clamped boundary
conditions. The algorithms for other boundary conditions can be formulated similarly with
small adaptations.
Let x0 < x1 < · · · < xN be a grid of an interval [a, b] and f continuously differentiable
function. We consider the problem of finding the cubic spline interpolant Pc(x) so as to be a
cubic polynomial Si(x) in each interval [xi, xi+1] for i = 0, 1, . . . , N −1. The function Pc(x)
interpolates f in the sense Pc(xi) = f(xi), and satisfies the clamped boundary conditions
P ′
c(x0) = f ′(x0) and P ′
c(xN) = f ′(xN). For convenience we will denote f(xi) = yi and
P ′′
c (xi) = zi. The values zi are known as the moments of f(x), and currently are unknown.
Because Pc(x) is a cubic polynomial in each interval [xi, xi+1], we have that P ′′
c (x) is
a linear polynomial in each [xi, xi+1] and takes the values zi and zi+1 at the endpoints xi
and xi+1, respectively. Thus, for x ∈[xi, xi+1] we have
P ′′
c (x) = S′′
i (x) = zi+1
hi
(x −xi) + zi
hi
(xi+1 −x),
x ∈[xi, xi+1] ,
(6.28)
where hi = xi+1 −xi for i = 0, 1, . . . , N −1. If we integrate the formula (6.28) twice we
obtain Si(x) as
Pc(x) = Si(x) = zi+1
6hi
(x −xi)3 + zi
6hi
(xi+1 −x)3 + cix + di,
x ∈[xi, xi+1] ,
where ci, di are integration constants. We can write the last equation in a more convenient
form as
Si(x) = zi+1
6hi
(x −xi)3 + zi
6hi
(xi+1 −x)3 + Ci(x −xi) + Di(xi+1 −x) ,
where Ci and Di are constants. We specify the constants Ci, Di using the interpolation
conditions
Si(xi) = yi
and
Si(xi+1) = yi+1 ,
and we write Si(x) in the form
Si(x) = zi+1
6hi (x−xi)3+ zi
6hi (xi+1−x)3+
yi+1
hi
−hi
6 zi+1

(x−xi)+
 yi
hi −hi
6 zi

(xi+1−x) , (6.29)
for x ∈[xi, xi+1]. Given the moments zi, we can use (6.29) to evaluate the cubic spline
Pc(x) for any x ∈[a, b]. For the N intervals [xi, xi+1], i = 0, . . . , N −1 we define N cubic
polynomials S0, S1, . . . SN−1 and N + 1 unknowns z0, z1, . . . , zN to be specified.
To specify the zi’s we need to consider the continuity of S′(x) at the interior nodes xi,
i = 1, . . . , N −1. Specifically, we have the equations
S′
i−1(xi) = S′
i(xi),
for
i = 1, 2, . . . , N −1 .
We compute the derivative Si using (6.29) as
P ′
c(x) = S′
i(x) = zi+1
2hi
(x −xi)2 −zi
2hi
(xi+1 −x)2 + yi+1 −yi
hi
−hi
6 (zi+1 −zi) ,
(6.30)
for x ∈[xi, xi+1]. This yields
P ′
c(xi) = Si(xi) = −hi
6 zi+1 −hi
3 zi + bi ,
and also
P ′
c(xi) = Si−1(xi) = hi−1
6
zi + hi−1
3
zi−1 + bi−1 ,

210
Interpolation and Approximation
where
bi = 1
hi
(yi+1 −yi) .
Taking into account the continuity of P ′
c(x) at every internal node xi, we set Si(xi) =
Si−1(xi) in the last relationships to obtain the equations for the unknown moments
hi−1
hi−1 + hi
zi−1 + 2zi +
hi
hi−1 + hi
zi+1 = 6 bi −bi−1
hi−1 + hi
,
(6.31)
for i = 1, 2, . . . , N −1. These are N −1 equations for N +1 unknowns. In order to construct
the two remaining equations required for a nonsingular system, we use the boundary con-
ditions P ′
c(x0) = f ′(x0) and P ′
c(xN) = f ′(xN). By taking x = x0 (and i = 0) and x = xN
(and i = N −1) in (6.30) we obtain the additional equations
2z0 + z1 = 6b0 −f ′(x0)
h0
,
(6.32)
and
zN−1 + 2zN = 6bN−1 −f ′(xN)
hN−1
.
(6.33)
We define
ui =
hi
hi−1 + hi
,
li =
hi−1
hi−1 + hi
,
i = 1, 2, . . . , N −1 ,
and u0 = 1 and lN = 1, and also
vi = 6 bi −bi−1
hi−1 + hi
,
i = 1, 2, . . . , N −1 ,
and v0 = 6 b0−f ′(x0)
h0
and vN = 6 bN−1−f ′(xN)
hN−1
, and ci = 2 for i = 0, 1, . . . , N. Then we write
equations (6.31), (6.32) and (6.33) in a form of (N + 1) × (N + 1) tridiagonal system of
equations Az = v









c0
u0
l1
c1
u1
l2
c2
u2
...
...
...
lN−1
cN−1
uN−1
lN
cN


















z0
z1
z2
...
zN−1
zN









=









v0
v1
v2
...
vN−1
vN









,
(6.34)
which is to be solved for zi. Note that sometimes we write A = tridiag(l, c, u) to denote
a tridiagonal matrix with sub-diagonal l = (l1, . . . , lN)T , main diagonal c = (c0, . . . , cN)T
and super-diagonal u = (u0, . . . , uN−1)T .
The first and last rows of the system Az = v are the only rows to be affected by the
boundary conditions. For this reason, we only need to modify these particular rows in case
of different boundary conditions. For example, in the case of natural boundary conditions
we need to take c0 = cN = 1, u0 = lN = 0 and v0 = vN = 0.
The solution of a linear system with tridiagonal matrix A can be achieved efficiently
using the tridiagonal version of the LU decomposition, forward and backward substitution
Algorithms 37, 38 and 39 of Chapter 9. Because this is material we will study later, we will

Spline Interpolation
211
Algorithm 21 Computation of the moments for clamped cubic splines
Given the points y0, y1, . . . , yN at the nodes x0, x1, . . . , xN and the boundary terms f ′(x0)
and f ′(xN), compute the coefficients of the tridiagonal system (6.34)
for i = 0 : N −1 do
hi = xi+1 −xi
bi = (yi+1 −yi)/hi
end for
u0 = 1, c0 = 2, v0 = 6(b0 −f ′(x0))/h0
for k = 1 : N −1 do
ci = 2
ui = hi/(hi−1 + hi)
li = hi−1/(hi−1 + hi)
vi = 6(bi −bi−1)/(hi−1 + hi)
end for
lN = 1, cN = 2, vN = 6(bn−1 −f ′(xN))/hN−1
Form the triadiagonal matrix A = tridiag(l, c, u)
Solve the linear system Az = v
use the generic NumPy function solve instead. The interested reader could employ banded
matrix techniques of Section 2.3.1.
The algorithm for the computation of the moments z0, z1, . . . , zN for cubic splines with
clamped boundary conditions is summarized in Algorithm 21.
For the implementation of Algorithm 21 we will use the function diags of the module
scipy.sparse. The particular function can create a NumPy array from its diagonals. Be-
cause the result will be a sparse matrix, we use the member function todense to convert
the matrix to a usual NumPy array. We will discuss sparse matrices in Chapter 9. The rest
of the implementation is included in the function MyCubicSpline.
1
import numpy as np
2
import numpy.linalg as npl
3
import scipy.sparse as sps
4
5
def MyCubicSpline(x, y, dy0, dyN):
6
# Returns the moments of f given the data x, y
7
# dy0 is the derivative at the left boundary
8
# dyN is the derivative at the right boundary
9
n = len(x)
10
c = np.zeros(n); v = np.zeros(n); u = np.zeros(n-1)
11
l = np.zeros(n-1); b = np.zeros(n-1); h = np.zeros(n-1)
12
for i in range(n-1):
13
h[i] = x[i+1] - x[i]
14
b[i] = (y[i+1]-y[i])/h[i]
15
u[0] = 1.0
16
v[0] = 6.0*(b[0]-dy0)/h[0]
17
c[0] = 2.0
18
for i in range(1,n-1):
19
c[i] = 2.0
20
u[i] = h[i]/(h[i-1] + h[i])
21
l[i-1] = h[i-1]/(h[i-1] + h[i])
22
v[i] = 6.0*(b[i]-b[i-1])/(h[i-1] + h[i])

212
Interpolation and Approximation
23
l[n-2] = 1.0
24
c[n-1] = 2.0
25
v[n-1] = 6.0*(b[n-2]-dyN)/h[n-2]
26
diagonals = [c, l, u]
27
A = sps.diags(diagonals, [0, -1, 1]).todense()
28
z = npl.solve(A,v)
29
return z
To evaluate the cubic spline interpolant Pc(x) at any point x given its moments zi we
can use the formula
Si(x) = Ai + Bi(x −xi) + Ci(x −xi)2 + Di(x −xi)3 ,
(6.35)
where
Ai = Si(xi),
Bi = S′
i(xi),
Ci = 1
2S′′
i (xi) .
The value Di can be found using the continuity of the second derivative S′′
i (xi+1) =
S′′
i+1(xi+1). Therefore,
Ai = yi,
Bi = −hi
6 zi+1 −hi
3 zi + 1
hi
(yi+1 −yi),
Ci = zi
2 ,
Di =
1
6hi
(zi+1 −zi),
which for i = 0, 1, 2, . . . , N −1, and x ∈[xi, xi+1] we can write formula (6.35) in nested
form as
Si(x) = yi + (x −xi)

Bi + (x −xi)
zi
2 + 1
6hi
(x −xi)(zi+1 −zi)

.
(6.36)
The algorithm for the evaluation of Pc(x) using (6.36) and the computed moments from
Algorithm 21 can be summarized in Algorithm 22. In this algorithm the loop condition
i = a : b : c means that the value a is the starting value, b is the stop value and c is the
step.
Algorithm 22 Evaluation of the clamped cubic spline given its moments
Given the moments z1, . . . , zN and a point x
Find the value of i for which x ∈[xi, xi+1] is true
for i = N −1 : 0 : −1 do
if x ≥xi then
Break
end if
end for
h = xi+1 −xi
B = −hzi+1/6 −hzi/3 + (yi+1 −yi)/h
Implement Formula (6.36) starting with the most inner brackets
y = zi/2 + (x −xi)(zi+1 −zi)/6h
y = B + (x −xi)y
y = yi + (x −xi)y
Variable y contains the value of the spline evaluated at x

Spline Interpolation
213
The implementation of Algorithm 22 in Python can be as follows:
1
def EvalCubicSpline(x, y, z, xx):
2
# Returns the cubic spline evaluated at xx
3
# z = the moments of the cubic spline
4
# xx = the vector with values of x on which we want the cubic spline
5
n = len(x)
6
m = len(xx)
7
yy = np.zeros(m)
8
for j in range(m):
9
xvalue = xx[j]
10
# First detect the index i
11
for i in range(n-2, -1, -1):
12
if (xvalue - x[i] >= 0.0):
13
break
14
# Implement formula (6.36)
15
h = x[i+1] - x[i]
16
B = -h*z[i+1]/6.0-h*z[i]/3.0+(y[i+1]-y[i])/h
17
tmp =z[i]/2.0+(xvalue-x[i])*(z[i+1]-z[i])/6.0/h
18
tmp = B+(xvalue-x[i])*tmp
19
yy[j] = y[i] + (xvalue - x[i])*tmp
20
return yy
To test the functions MyCubicSpline and EvalCubicSpline we can use the following
script which results in the same figure as before and it is omitted.
1
def f(x):
2
return 1.0/(1+25*x**2)
3
def df(x):
4
return -2*25*x/(1+25*x**2)**2
5
x = np.linspace(-1,1,9)
6
y = f(x)
7
z = df(x)
8
xx = np.linspace(-1,1,300)
9
yy = f(xx)
10
ss = MyCubicSpline(x, y, z[0], z[-1])
11
zz=EvalCubicSpline(x, y, ss, xx)
12
plt.plot(xx,yy,xx,zz,x,y,'o')
We proceed with the analysis of the error for the cubic spline interpolation and other
theoretical considerations following closely the theory presented in [127].
6.4.6
Theoretical considerations and error analysis
In addition to its practical significance, Algorithm 22 provides a method to prove that there
is a unique natural cubic spline that interpolates a function f at a given set of nodes. In
particular, by showing that A in (6.34) is invertible we show that there is a unique solution
of the system Az = v for the moments zi, and thus the cubic spline is uniquely determined
(since it can be constructed from these values).

214
Interpolation and Approximation
In order to see that A is invertible, we first prove the following lemma:
Lemma 6.7. The solution of the linear system Az = v satisfies
max
i
|zi| ≤max
i
|vi| .
Proof. Let k be the index for which we have |zk| = maxi |zi|. The k-th equation of the
system Az = v is then
lkzk−1 + ckzk + ukzk+1 = vk .
Because
ui =
hi
hi−1 + hi
and
li =
hi−1
hi−1 + hi
,
we have that ui + li = 1, which implies uk + lk = 1. Then,
|vk| ≥2|zk| −lk|zk−1| −uk|zk+1|
≥2|zk| −lk|zk| −uk|zk|
= (2 −lk −uk)|zk|
= |zk| .
On the other hand, we have that maxi |vi| ≥|vk|, and thus maxi |vi| ≥|zk| = maxi |zi|
which completes the proof.
Lemma 6.7 implies that the solution of the system Az = v is unique, and thus A is
invertible. To see this assume for contradiction that A is singular. This means that there
exists z ̸= 0 such that Az = 0. By Lemma 6.7 we have that 0 < maxi |zi| ≤0, which
is impossible. Therefore, there is a unique cubic spline with clamped boundary conditions
interpolating N +1 data (xi, yi), i = 0, 1, . . . , N. Similar results hold for the other boundary
conditions too. We continue with the error estimation in the case of clamped cubic spline
interpolation.
Let the function f specifying the data points yi = f(xi), i = 0, 1, . . . , N is a smooth
function in C4[a, b]. In the case of clamped spline interpolation, we can estimate the error
between the interpolant and function f which is of optimal order. First we show optimal
order approximation of the second derivatives. For this reason, we consider the system
Az = v (6.34) and we denote by zf the vector of the second derivatives of f evaluated at
the nodes xi
zf =





f ′′(x0)
f ′′(x1)
...
f ′′(xN)




.
We also define the residual vector
r = Az −Azf .
Recall, that the vector z contains the moments P ′′
c (xi). We estimate the maximum difference
of the second derivatives at the nodes maxi |P ′′
c (xi)−f ′′(xi)|. For convenience we introduce
the norm notation ∥z −zf∥∞= maxi |zi −zf i|, where the quantity ∥· ∥∞is the usual
maximum vector norm. (We discuss matrix norms in more detail in Chapter 9). As in
Theorem 6.6, we define the grid-size h = maxi hi where hi = |xi+1 −xi|. Once again the
proof relies on Taylor’s expansions of function f and its derivatives.

Spline Interpolation
215
Proposition 6.8. Let f ∈C4[a, b] with maxx |f (4)(x)| ≤L for some L > 0. Then the
following optimal error estimate holds
max
i
|P ′′
c (xi) −f ′′(xi)| ≤Ch2 ,
where C = 3
4L.
Proof. Using the residual r = Az −Azf we obtain
r0 = c0z0 + u0z1 −c0f ′′(x0) −u0f ′′(x1)
= v0 −2f ′′(x0) −f ′′(x1)
(since c0 = 2, u0 = 1)
= 6
h0
y1 −y0
h0
−f ′(x0)

−2f ′′(x0) −f ′′(x1) .
Since x1 = x0 +h0 the Taylor expansion of f(x1) and f ′′(x1) around x0 yields the existence
of ξ1 and ξ2 in [x0, x1] such that
r0 = 6
h0

f ′(x0) + h0
2 f ′′(x0) + h2
0
6 f ′′′(x0) + h3
0
24f (4)(ξi) −f ′(x0)

−2f ′′(x0) −

f ′′(x0) + h0f ′′′(x0) + h2
0
2 f (4)(ξ2)

= h2
0
4 f (4)(ξ1) −h2
0
2 f (4)(ξ2) .
Taking the absolute value in the last relation we obtain |r0| ≤Ch2, with C = 3
4L. Similarly,
we obtain |rN| ≤Ch2, since the other boundary terms are almost identical. For the internal
nodes xi, i = 1, . . . , N −1 we have
ri = vi −lif ′′(xi−1) −cif ′′(xi) −uif ′′(xi+1)
= 6 bi −bi−1
hi−1 + hi
−
hi−1
hi−1 + hi
f ′′(xi+1) −2f ′′(xi) −
hi
hi−1 + hi
f ′′(xi+1)
=
6
hi−1 + hi
f(xi+1) −f(xi)
hi
−f(xi) −f(xi−1)
hi−1

−
hi−1
hi−1 + hi
f ′′(xi+1) −2f ′′(xi) −
hi
hi−1 + hi
f ′′(xi+1) .
Since xi−1 = xi −hi and xi+1 = xi + hi, Taylor’s expansions of f ′ and f ′′ around xi yields
that there are ξ1, ξ2, ξ3, ξ4 ∈[xi−1, xi+1] such that
ri =
1
hi−1 + hi

6

f ′(xi) + hi
2 f ′′(xi) + h2
i
6 f ′′′(xi) + h3
i
24f (4)(ξ1)
−f ′(xi) + hi−1
2
f ′′(xi) −h2
i−1
6
f ′′′(xi) + h3
i−1
24 f (4)(ξ2)

−hi−1

f ′′(xi) −hi−1f ′′(xi) + h2
i−1
2
f (4)(ξ3)

−2f ′′(xi)(hi−1 + hi) −hi

f ′′(xi) + hif ′′′(xi) + h2
i
2 f (4)(ξ4)

=
1
hi−1 + hi
h3
i
4 f (4)(ξ1) + h3
i−1
4
f (4)(ξ2) −h3
i−1
2
f (4)(ξ3) −h3
i
2 f (4)(ξ4)

.

216
Interpolation and Approximation
Taking again absolute values in the previous formulas we obtain |ri| ≤Ch2 with C = 3
4L.
Thus, the maximum over i satisfies
∥r∥∞= max
i
|ri| ≤Ch2 .
Since A(z−zf) = r, using Lemma 6.7 we have ∥z−zf∥∞≤∥r∥∞and the result follows.
The previous theorem states that the second derivative of the cubic spline at the nodes
approximates the second derivative of the function f evaluated at the same nodes. Their
maximum difference is of order h2. This means that if we take h →0 the error becomes 0.
Thus, we have convergence of the second derivatives at the nodes. Because the convergence is
quadratic (since the error is O(h2)), we say that the convergence is optimal. This is because
we expect that the approximation of a function by polynomials of degree r will result to
errors of O(hr+1). In our case, the second derivative of the cubic spline is a piecewise linear
function. The error of O(h2) follows the optimal error rule. We prove next that the error
between the other derivatives are also optimal.
Theorem 6.9. Let f ∈C4[a, b] and maxx |f (4)(x)| ≤L for some L > 0. If in addition
h
hi ≤K, for i = 0, 1, . . . , N −1, then there exists a constant C = C(k, K, L) > 0 such that
|f (k)(x) −P (k)
c
(x)| ≤Ch4−k,
k = 0, 1, 2, 3 .
Proof. We first prove the error estimate when k = 3. Let x ∈[xi, xi+1] for some i =
0, 1, . . . , N −1. Then from (6.28) we have
f ′′′(x) −P ′′′
c (x) = zi+1 −zi
hi
−f ′′′(x)
= zi+1 −f ′′(xi+1)
hi
−zi −f ′′(i)
hi
+
+ f ′′(xi+1) −f ′′(x) −[f ′′(xi) −f ′′(x)]
hi
−f ′′′(x) .
Using Proposition 6.8 and the Taylor expansion of f ′′ around x we conclude that there are
ξ1, ξ2 ∈[xi, xi+1] such that
|f ′′′(x) −P ′′′
c (x)| ≤3
2Lh2
hi
+ 1
hi
(xi+1 −x)f ′′′(x)
+ (xi+1 −x)2
2
f (4)(ξ1) −(xi −x)f ′′′(x) −(xi −x)2
2
f (4)(ξ2) −hif ′′′(x)

≤3
2Lh2
hi
+ L
2
h2
hi
≤Ch ,
where C = 2KL. In the case k = 2, we consider x ∈(a, b) and we choose the xi, which is
the closest node to x. For the specific node we will have |xi −x| ≤h
2 . From the fundamental
theorem of calculus (see Theorem 4.4) we have
f ′′(x) −P ′′
c (x) = f ′′(xi) −P ′′
c (xi) +
Z x
xi
(f ′′′(s) −P ′′′
c (s)) ds .

Spline Interpolation
217
Using Proposition 6.8 we can estimate an upper bound for the error in the second derivatives
at the nodes, while the integrant at the right-hand side can be bounded using the previous
estimate to obtain
|f ′′(x) −P ′′
c (x)| ≤|f ′′(xi) −P ′′
c (xi)| +
Z x
xi
|f ′′′(s) −P ′′′
c (s)| ds
≤3
4Lh2 + KLh2
≤Ch2 ,
where C = 7
4KL.
We consider now the case k = 1. Because of the boundary conditions we have that
f ′(x0) = P ′
c(x0) and f ′(xN) = P ′
c(xN). We thus define ξ0 = x0 and ξN+1 = xN. Since
f(xi) = Pc(xi) for all i = 0, 1, . . . , N we can deduce from Rolle’s theorem in each interval
[xi, xi+1], i = 0, 1, . . . , N that there is a ξi+1 ∈(xi, xi+1) such that f ′(ξi) = P ′
c(ξi) for
i = 1, . . . , N. Thus, we have N + 2 points ξi such that
f ′(ξi) = P ′
c(ξi), i = 0, 1, . . . , N + 1 .
If now x ∈[a, b] we choose ξi such that |x −ξi| ≤h. Without loss of generality we assume
ξi < x where the proof is the same as if x < ξi. Then since
f ′(x) −P ′
c(x) =
Z x
ξi
(f ′′(s) −P ′′
c (s)) ds ,
we have
|f ′(x) −P ′
c(x)| ≤
Z x
ξi
|f ′′(s) −P ′′
c (s)| ds
≤Ch2|x −ξi|
≤Ch3 ,
with C = 7
4KL.
Finally, in the case k = 0 we have
f(x) −Pc(x) =
Z x
xi
(f ′(s) −P ′
c(s)) ds ,
and thus |f(x) −Pc(x)| ≤Ch4, which completes the proof.
6.4.7
B-splines
Given a set of N + 1 nodes x0 < x1 < · · · < xN, we defined the space of continuous
piecewise linear functions S1 with basis functions ϕi(x), i = 0, 1, . . . , N and the linear spline
interpolant
P1(x) =
N
X
i=0
f(xi)ϕi(x) ,
(6.37)
where ϕi(x) are the hat functions defined in (6.17)–(6.19). This representation is very con-
venient and it does not practically require to impose any boundary conditions. This idea
can be generalized for the general spline space of piecewise polynomial functions of degree
m. Let a = x0 < x1 < · · · < xN = b a grid of the interval [a, b]. We define the space of
piecewise polynomial functions of degree m to be the linear space
Sm = {f ∈Cm−1[a, b] : f ∈Pm[xi, xi+1] for i = 0, 1, . . . , N −1} .

218
Interpolation and Approximation
The elements of Sm are called splines of degree m (order m + 1). We denote the basis
functions of the space Sm by Bm
j (x), where m is the polynomial degree and j a counter
running over the basis functions (usually from 0 to M −1). The basis functions Bm
j (x)
are called B-splines as an abbreviation of the phrase “basis splines”. Using the previous
notation we have that B1
j(x) = ϕj(x), with support [xj−1, xj] ∪[xj, xj+1]. For the space S1
we also have N + 1 basis functions, indicating that the dimension of the space is N + 1.
Because of these simple properties of the B-splines B1
j we are able to represent the linear
spline interpolant in the form (6.37).
For m > 1 the situation is more complicated compared to the case m = 1. For example,
the dimension of the space (the number of basis functions) is greater than the number of
nodes, and thus the coefficients aj in a representation of the interpolant
Pm(x) =
M−1
X
j=0
ajBm
j (x) ,
with M = dim(Sm), are not necessarily equal to f(xj). In general the dimension of the
space Sm is N + m. This is, briefly, because a spline is a polynomial of degree m in each of
the N intervals [xi, xi+1]. Each polynomial has m + 1 coefficients and thus we have in total
N(m+1) coefficients (degrees of freedom). On the other hand, the continuity of derivatives
of order 0, . . . , m−1 at the N −1 internal nodes yields (N −1)m constraints. The remaining
degrees of freedom are N(m + 1) −(N −1)m = N + m set a requirement for equal number
of basis functions.
There is a systematic way to generate the basis functions of the splines space Sm recur-
sively, and we describe it in the sequel. For the sake of simplicity, we will do it in the case
of uniform grid using convolutions. The convolution of two functions f, g is the function
f ∗g defined by the integral
(f ∗g)(x) =
Z ∞
−∞
f(y)g(x −y) dy .
The cardinal B-spline of degree 0 is the (characteristic) function
φ0(x) =

1,
if x ∈[−1/2, 1/2)
0,
otherwise
.
(6.38)
For the notation of the cardinal splines we use the letter φ, which is different from ϕ used
before for the basis functions of the space S1. We define the cardinal B-spline of degree m
as the convolution
φm(x) = [φ0 ∗φ0 ∗φ0 ∗. . . ∗φ0
|
{z
}
m−times
](x) = [φm−1 ∗φ0](x) .
Thus,
φm(x) = [φm−1 ∗φ0](x) =
Z ∞
−∞
φm−1(y)φ0(x −y) dy
=
Z ∞
−∞
φm−1(x −y)φ0(y) dy =
Z 1/2
−1/2
φm−1(x −y) dy ,
which after change of integration variable we obtain the recursive formula
φm(x) =
Z x+1/2
x−1/2
φm−1(z) dz .
(6.39)

Spline Interpolation
219
FIGURE 6.4
Cubic B-spline B3
j generated by convolution.
All the cardinal B-splines are symmetric about the origin. To see this take
φm(−x) =
Z x+1/2
x−1/2
φm−1(z) dz
= −
Z x−1/2
x+1/2
φm−1(−ζ) dζ
=
Z x+1/2
x−1/2
φm−1(ζ) dζ
= φm(x) .
We can compute the derivatives of cardinal B-splines recursively with the formula
d
dxφm(x) = d
dx
Z x+1/2
x−1/2
φm−1(z) dz = φm−1 (x + 1/2) −φm−1 (x −1/2) .
The linear, quadratic, cubic, quartic and quintic cardinal B-splines obtained using the re-
cursive formula (6.39) are presented in Table 6.6.
We define the nodes (also known as augmented knots)
· · · < t−2 < t−1 < t0 < t1 < t2 < · · · ,
where here we assume that tj+1 −tj = h > 0. The B-spline of degree m centered at the
knot tj can be found after appropriate translation of the cardinal B-spline. In particular,
we define the B-spline of degree m as
Bm
j (x) =



φm

x−tj
h

,
m = 2k + 1
φm

x−tj
h
−1
2

,
m = 2k
, k = 0, 1, 2, . . . .
The graph of a B-spline B3
j is presented in Figure 6.4. We observe that B3
j(tj) = 1,
B3
j(tj−1) = B3
j(tj+1) = 1/4 and B3
j(tj−2) = B3
j(tj+2) = 0.
The B-splines of a general set of knots can be defined recursively by the Cox and de
Boor recursion formula [31]. In particular, if · · · ≤t−2 ≤t−1 ≤t0 ≤t1 ≤t2 ≤· · · , where we
have extended the knots t0 and tN to the left and right, then the recursive relation defining
the i-th B-spline of degree m, Bm
i
is
B0
i (x) =
 1,
if x ∈[ti, ti+1)
0,
otherwise
,
Bk
i (x) =
x −ti
ti+k−1 −ti
Bk−1
i
(x) +
ti+k −x
ti+k −ti+1
Bk−1
i+1 (x), for k = 1, 2, . . . , m ,
(6.40)

220
Interpolation and Approximation
TABLE 6.6
Cardinal B-splines up to degree 5
φ0(x) =
 1
|x| ≤1/2
0
|x| > 1/2
φ1(x) =



1 + x,
−1 ≤x ≤0
1 −x,
0 ≤x ≤1
0,
otherwise
φ2(x) =









1
3
 2x2 + 6x + 9
2

,
−3/2 ≤x ≤−1/2
4
3
  3
4 −x2
,
−1/2 ≤x ≤1/2
1
3
 2x2 −6x + 9
2

,
1/2 ≤x ≤3/2
0,
otherwise
φ3(x) =















1
4 (x + 2)3 ,
−2 ≤x ≤−1
1
4
 4 −6x2 −3x3
,
−1 ≤x ≤0
1
4
 4 −6x2 + 3x3
,
0 ≤x ≤1
1
4 (2 −x)3 ,
1 ≤x ≤2
0,
otherwise
φ4(x) =





















8
115
  5
2 + x
4 ,
−5
2 ≤x ≤−3
2
2
115
 55 −20x −120x2 −80x3 −16x4
,
−3
2 ≤x ≤−1
2
1
115
 115 −120x2 + 48x4
,
−1
2 ≤x ≤1
2
2
115
 55 + 20x −120x2 + 80x3 −16x4
,
1
2 ≤x ≤3
2
8
115
  5
2 + x
4 ,
3
2 ≤x ≤5
2
0,
otherwise
φ5(x) =

























1
66 (3 + x)5 ,
−3 ≤x ≤−2
1
66
 51 −75x −210x2 −150x3 −45x4 −5x5
,
−2 ≤x ≤−1
1
33
 33 −30x2 + 15x4 + 5x5
,
−1 ≤x ≤0
1
33
 33 −30x2 + 15x4 −5x5
,
0 ≤x ≤1
1
66
 51 + 75x −210x2 + 150x3 −45x4 + 5x5
,
1 ≤x ≤2
1
66 (3 −x)5 ,
2 ≤x ≤3
0,
otherwise
Note that this formula works even with repeated knots. We also use knots ti instead of xi
because some of the B-splines will be centered around points ti that are outside our domain.
Contrary to the recursive formula (6.39), the Cox-de Boor formula will not necessarily
produce normalized functions, but these can be normalized later if it is required.
Assume now that we want to compute the piecewise polynomial interpolant Pm(x) such
that Pm(xi) = yi for i = 0, . . . , N + m −1 given the B-splines Bm
i . It is noted that in this
case, the number of nodes must agree with the dimension of the space of splines. These
points form N + m equations with N + m unknown coefficients
Pm(xi) =
N+m−1
X
j=0
ajBm
j (xi) = yi,
i = 0, 1, 2, . . . , N + m −1 ,
which can be written as a system of equations in the form Aa = y, where Aij = Bm
j−1(xi−1).
Due to the fact that Bm
i (x) ̸= 0 if x ∈[xi, xi+m], the system will be sparse and can be solved
easily.

Spline Interpolation
221
In the following code, we implement the Cox-de Boor recursive formula and we compute
the cubic B-splines of the space S3 when N = 10, thus we compute N + m = 13 B-
Splines. Aall the B-splines generated by the following code have maximum 2/3 and are not
normalized.
1
# Define the B-splines using the Cox-de Boor recursive formula
2
def B(x, k, i, t):
3
if k == 0:
4
return 1.0 if t[i] < x <= t[i+1]
else 0.0
5
else:
6
c1 = (x - t[i])/(t[i+k] - t[i]) * B(x, k-1, i, t)
7
c2 = (t[i+k+1] - x)/(t[i+k+1] - t[i+1]) * B(x, k-1, i+1, t)
8
return c1 + c2
9
# Create uniform grid of nodes in [a,b]
10
a = -1.0; b = 1.0;
11
N=10
12
x = np.linspace(a,b,N+1)
13
#Compute all the cubic B-splines
14
m = 3
15
# Create uniform grid of knots
16
t = np.zeros(N+2*m+1)
17
for i in range(N+2*m+1):
18
if i<=m:
19
t[i] = x[0]-(m-i)*(x[1]-x[0])
20
elif i>=N+m+1:
21
t[i] = x[N]+(i-N-m)*(x[1]-x[0])
22
else:
23
t[i] = x[i-m]
24
# Plot the cubic B-splines
25
nn = 101
26
xx = np.linspace(a+1.e-10,b-1.e-10,nn)
27
yy = np.zeros(nn)
28
for j in range(N+m):
29
for i in range (nn):
30
yy[i]=B(xx[i], m, j, t)
31
plt.plot(xx,yy)
32
plt.xlabel('$x$'); plt.ylabel('$y$',rotation=0); plt.show()
−1.00 −0.75 −0.50 −0.25
0.00
0.25
0.50
0.75
1.00
x
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
y

222
Interpolation and Approximation
FIGURE 6.5
Least squares approximation of a dataset.

The convolution formula for B-splines is related to the Cox-de Boor formula
only for uniform grids. For non-uniform grids the basis functions will not be the
same.
6.5
Method of Least Squares
We close this chapter with a different approach in approximation. Sometimes, the data
points do not follow the graph of a smooth function, or they can be very “noisy”, such as
the data depicted in Figure 6.5. In such a case we prefer to approximate the data rather
than interpolate them. The simplest approximation can be constructed using a straight line.
In general, the approximation can be constructed using any function that can approximate
the data reasonably well, and the method is known as the method of least squares. Figure
6.5 presents the situations where a dataset is quite noisy and chaotic but follows a certain
pattern. The result of the least squares approximation is the function f(x) represented by a
continuous line that approximates the data points without interpolating them. The method
for constructing such a smooth approximate function relies on the minimization of the error
between the function and data. First we present the simple case of linear least squares.
6.5.1
Linear least squares
Suppose that we need to approximate some data (x0, y0), (x1, y1), . . . , (xN, yN) by a straight
line of the form
y = ax + b .
The coefficients a and b have to be determined in such a way that the graph of the line is
very close to these points.
If the point (xi, yi) lies on the graph of the line y = ax + b, then axi + b −yi = 0.
Otherwise, the error between the point (xi, yi) and the line can be defined as |axi + b −yi|.
If this is the case for all points (xi, yi) with i = 0, 1, . . . , N, then the total absolute error of

Method of Least Squares
223
all N + 1 points will be
N
X
i=0
|axi + b −yi| .
We want to find the values of the coefficients a and b to minimize such an error. We know
from the first derivative test of calculus that the minimum of a smooth function is among
its critical points; these can be the roots of its first derivatives. The way we defined the
error as the absolute value of a function, we cannot use the first derivative test easily. For
this reason, we will use the square of the absolute errors. This is the sum of the squared
errors
S(a, b) =
N
X
i=0
(axi + b −yi)2 .
An extremum of this function is at a point where the partial derivatives are both zero
∂
∂aS(a, b) = 0
and
∂
∂bS(a, b) = 0 .
These conditions lead to the following two equations
N
X
i=0
2(axi + b −yi)xi = 0
and
N
X
i=0
2(axi + b −yi) = 0 .
Rearranging these equations we get the so-called normal equations













 N
X
i=0
x2
i
!
a +
 N
X
i=0
xi
!
b =
N
X
i=0
yixi ,
 N
X
i=0
xi
!
a + (N + 1) b =
N
X
i=0
yi ,
(6.41)
where we used the fact that PN
i=0 i = N + 1. System (6.41) is a 2 × 2 system of linear
equations with unknowns the coefficients a and b. Denoting
p =
N
X
i=0
xi,
q =
N
X
i=0
yi,
r =
N
X
i=0
yixi,
s =
N
X
i=0
x2
i ,
we write the system (6.41) in matrix-vector form as
s
p
p
N + 1
 a
b

=
r
q

.
Using Cramer’s rule (of Section 2.2.11) to solve it we compute the determinant
D = det
s
p
p
N + 1

= (N + 1)s −p2 ,
and then the solution becomes
a = 1
D det
r
p
q
N + 1

= [(N + 1)r −pq]/D
and
b = 1
D det
s
r
p
q

= [sq −pr]/D .
Given the data points (xi, yi) for i = 0, 1, . . . , N, we can express the previous process known
as linear least squares (also known as linear regression) in the simple Algorithm 23.

224
Interpolation and Approximation
Algorithm 23 Linear least squares method
Set p = PN
i=0 xi, q = PN
i=0 yi, r = PN
i=0 yixi, s = PN
i=0 x2
i , D = (N + 1)s −p2
Compute a = [(N + 1)r −pq]/D
Compute b = [sq −pr]/D
Here is a simple implementation of a function that given the data x and y and a set of
points stored in the variable xx returns the points yy such that yy=a*xx+b.
1
def linear_least_squares(x, y, xx):
2
# returns the vector yy with the linear least squares
3
# approximation of the input data (x,y)
4
N = len(x)
5
p = np.sum(x)
6
q = np.sum(y)
7
r = np.sum(np.multiply(x,y))
8
s = np.sum(np.square(x))
9
D = (N+1)*s-p**2
10
a = [(N+1)*r - p*q]/D
11
b = [s*q - p*r]/D
12
yy = a*xx + b
13
return yy
In order to test our code we generate some random data aligned with the line y = 2x+1.
To generate a random vector with ten entries we use the NumPy function random.rand.
1
x = np.linspace(-1,2,10)
2
y = 2.0*x+1.0+np.random.rand(10)
3
xx = np.linspace(-1,2,20)
4
yy = linear_least_squares(x, y, xx)
5
plt.plot(xx,yy,'-',x,y,'o')
6
plt.xlabel('$x$')
7
plt.ylabel('$y$',rotation=0)
8
plt.show()
−1.0
−0.5
0.0
0.5
1.0
1.5
2.0
x
0
1
2
3
4
5
y
Printing the variables a and b you will observe that the resulting linear least squares ap-
proximation can be different from the line y = 2x + 1. This is because the points have been

Method of Least Squares
225
perturbed randomly and thus a different line minimizes the squared distance between the
points and the line.
6.5.2
Polynomial fit
The linear least squares method can generate approximations to data aligned with a straight
line. Usually, we observe this by plotting the data points in a graph. If our intuition says that
the data points (xi, yi) are aligned with a non-linear curve, then we need to use a different
method. Eventually, the method of linear least squares can be generalized to polynomials
of degree m
Pm(x) =
m
X
k=0
akxk .
The way to derive a linear system of equations with the unknown polynomial coefficients
follows the exact same methodology we used to derive the 2 × 2 linear system in the case
of linear least squares problem. For example, we define the error function
S(a0, . . . , am) =
N
X
i=0
|Pm(xi) −yi|2 =
N
X
i=0
[(a0 + a1xi + · · · + amxm
i ) −yi]2
=
N
X
i=0
" m
X
k=0
akxk
i −yi
#2
.
The critical points of the error function S can be found by estimating the roots of the partial
derivatives
∂
∂ai
S(a0, a1, . . . , am) = 0,
for
i = 0, 1, . . . , m .
These equations can be written as
∂
∂a0
S(a0, a1, . . . , am) = 2
N
X
i=0
 m
X
k=0
akxk
i −yi
!
= 0 ,
∂
∂a1
S(a0, a1, . . . , am) = 2
N
X
i=0
 m
X
k=0
akxk
i −yi
!
xi = 0 ,
∂
∂a2
S(a0, a1, . . . , am) = 2
N
X
i=0
 m
X
k=0
akxk
i −yi
!
x2
i = 0 ,
...
∂
∂am
S(a0, a1, . . . , am) = 2
N
X
i=0
 m
X
k=0
akxk
i −yi
!
xm
i = 0 .
The resulting linear system is of order m+1. Specifically, the coefficients aj, j = 0, 1, . . . , m
can be found by solving the linear system
Az = b ,
where z = (a0, a1, . . . , am)T ,
A =





N
P xi
P x2
i
· · ·
P xm
i
P xi
P x2
i
P x3
i
· · ·
P xm+1
i
...
...
...
...
...
P xm−1
i
P xm
i
P xm+1
i
· · ·
P x2m
i





and
b =





P yi
P xiyi
...
P xm
i yi




.

226
Interpolation and Approximation
The solution of this linear system is not trivial, but in our implementation we solve it using
the function numpy.linalg.solve(A,b). The implementation of this method can be the
following
1
def poly_least_squares(x, y, xx, m):
2
# Computes the least squares approximation of degree m
3
# for the data points (x,y) evaluated at xx
4
N = len(x)
5
A = np.zeros((m+1,m+1))
6
b = np.zeros(m+1)
7
s = np.zeros(2*m+1)
8
# Assembly of A and b
9
for i in range(N):
10
temp = y[i]
11
for j in range(m+1):
12
b[j] = b[j] + temp
13
temp = temp*x[i]
14
temp = 1.0
15
for j in range(2*m+1):
16
s[j] = s[j] + temp
17
temp = temp*x[i]
18
for i in range(m+1):
19
for j in range(m+1):
20
A[i,j] = s[i+j]
21
z = np.linalg.solve(A,b)
22
# Evaluation of the polynomial at the nodes xx
23
p = z[m]
24
for j in range(m):
25
p = p*xx+z[m-j-1]
26
return p
We test our code by generating some random data aligned with the line y = 2x2 + 1. Check
that the least squares approximation is a polynomial close to y = 2x2 + 1.
1
x = np.linspace(-1,2,10)
2
y = 2.0*np.square(x)+1.0+np.random.rand(10)
3
xx = np.linspace(-1,2,20)
4
yy = poly_least_squares(x, y, xx, 2)
5
plt.plot(xx,yy,'-',x,y,'o')
6
plt.xlabel('$x$'); plt.ylabel('$y$',rotation=0); plt.show()

Method of Least Squares
227
−1.0
−0.5
0.0
0.5
1.0
1.5
2.0
x
2
4
6
8
10
y
6.5.3
Non-polynomial fit
Sometimes, the data follow a law that isn’t necessarily close to a polynomial. For example,
their values might decay exponentially fast. This means that we would prefer to find a
function of the form
f(x) = AeBx ,
to approximate our data. This problem can be transformed to a linear one by using the
points (xi, ln yi) instead of (xi, yi). In order to see that, consider the function
F(x) = ln f(x) = ln A + Bx ,
for which we need to minimize the residuals
Ri = ln yi −F(xi) = ln yi −(ln A + Bxi) .
Setting zi = ln yi the least squares problem is now the problem of minimization of the
function
S(a, b) =
N
X
i=0
(axi + b −zi)2 ,
with a = B and b = ln A.
As an example we consider a dataset aligned with the line y = 3e2x.
1
x = np.linspace(0,2,10)
2
y = 3.0*np.exp(2.0*x)+0.1*np.random.rand(10)
3
z = np.log(y)
4
xx = np.linspace(0,2,20)
5
zz = linear_least_squares(x, z, xx)
6
yy = np.exp(zz)
7
plt.plot(xx,yy,'-',x,y,'o')
8
plt.xlabel('$x$')
9
plt.ylabel('$y$',rotation=0)
10
plt.show()

228
Interpolation and Approximation
0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
2.00
x
0
25
50
75
100
125
150
175
y
NumPy implementation
The least squares method is implemented in Python with the function numpy.polyfit
that the error function S(a0, a1, . . . , am) and returns the coefficients of the approximating
polynomial. Then the function numpy.poly1d can be used to obtain the polynomial as a
callable function capable to be evaluated at any point x. The basic call of the function
polyfit is
polyfit(x, y, deg, rcond, full, w, cov)
where
x:
The x-coordinates of the dataset we want to approximate
y:
The y-coordinates of the dataset we want to approximate
deg: The degree of the fitting polynomial
rcond: It is called relative condition number of the fit. Singular values smaller than this
number, relative to the largest singular value (eigenvalues of the matrix AT A) will
be ignored. For more information please see Chapter 10. (Optional with default value
rcond=None)
full: This is a boolean variable that determines the return value. When it is False the
function returns only the coefficients of the polynomial. When it is True the function
returns diagnostic information. (Optional with default value full=False
w:
Is an array with the weights to apply to the y-coordinates of the sample points.
(Optional with default value w=None)
cov: Is a boolean variables that returns an estimate of the covariance matrix of the ap-
proximation for statistical analysis. (Optional with default values cov=False)
The function polyfit returns an array p with the coefficients of the polynomial start-
ing with the highest coefficient. Other returning variables are the residuals, rank,
singular values and rcond that are returned only if the parameter full=True. We do
not present the use of these parameters here as they require knowledge of more advanced
techniques of numerical analysis that we haven’t discussed yet. One can return to the details
of this function after studying the material of Chapter 10.

The Module scipy.interpolate
229
In order to compute the values of a polynomial at various values x we can use the function
numpy.poly1d. The general call of this function is poly1d(p, r, variable) where p can
be the output polynomial coefficients of the function polyfit, r is a boolean variable related
with the computations of the roots of the polynomial, and variable is a string used when
printing the polynomial p, and its default value is None.
An example of usage of the functions polyfit and poly1d is listed below, where we
consider the case y = 2x + 1 again.
1
x = np.linspace(-1,2,10)
2
y = 2.0*np.square(x)+1.0+np.random.rand(10)
3
xx = np.linspace(-1,2,20)
4
yy = np.polyfit(x, y, 2)
5
zz = np.poly1d(yy)
6
plt.plot(xx,zz(xx),'-',x,y,'o')
7
plt.xlabel('$x$'); plt.ylabel('$y$',rotation=0); plt.show()
The specific code returns very similar results to our code for linear least squares approxi-
mations.
We will revisit the topic of the least squares problem later in this book when we explore
relevant methods and present theoretical developments of approximation theory in Chapter
10.
6.6
The Module scipy.interpolate
SciPy provides the module interpolate with the implementation of several algorithms for
interpolation problems. Here we present relevant routines for Lagrange and spline interpo-
lation and their extensions in two dimensions, as well as an application in image processing.
6.6.1
Lagrange interpolation
The Lagrange interpolation is implemented in the function scipy.interpolate.lagrange.
The lagrange function computes the Lagrange interpolation polynomial of the given data
(xi, yi), for i = 0, 1, . . . , N. The general call of this function is lagrange(x,w) where x
is an array containing the values xi (the array x in our code) and w an array with the
corresponding values yi (the array y in our code). The function lagrange returns the
polynomial PN as a function which can be evaluated at any point z.
1
import scipy.interpolate as spi
2
3
def f(x):
4
return 1.0 / (1.0 + 25.0 * x**2)
5
# We evaluate the interpolant at the points z
6
z = numpy.linspace(-1, 1, 100)
7
# We use the data x,y
8
x = numpy.linspace(-1, 1, 10)
9
y = f(x)
10
# We compute the Lagrange polynomial p
11
p = spi.lagrange(x, y)

230
Interpolation and Approximation
12
# We compare the graphs of the data and the interpolant
13
plt.plot(z,p(z),'-')
14
plt.plot(x,y,'o')
15
plt.plot(z,f(z),'-.')
16
plt.legend(["$P_9(z)$","data","$f(z)$"])
17
plt.xlabel('x'); plt.ylabel('y'); plt.show()
The results again will be the same as before and are omitted. The only important fact
to note here is that using SciPy we can compute the interpolating polynomial with only
one line of code.
6.6.2
Cubic spline interpolation
The cubic spline interpolant can be computed in Python with the function CubicSpline of
the module scipy.interpolate. For example, if we want to interpolate the points (xi, yi)
stored in the variables x and y, then we can simple call the function
cs = CubicSpline(x, y)
where the cs is the cubic spline function evaluated with “not-a-knot” boundary conditions,
the default boundary conditions. We can evaluate the cubic spline at any point (or array)
xx by typing cs(xx). We can also compute the derivatives of the cubic spline using cs(xx,
1), cs(xx, 2), cs(xx, 3) for the first, second and third order derivatives respectively. The
general call of the function CubicSpline is the following:
CubicSpline(x, y, axis, bc_type, extrapolate)
where here
x:
An array with the values xi, i = 0, . . . , N
y:
An array with the values yi, i = 0, . . . , N
axis: Axis along which y is assumed to be varying (if there are more than one indices).
(Optional with default value 0)
bc type: Can be one of the following options:
 ’not-a-knot’,
 ’periodic’,
 ’clamped’,
 ’natural’.
It can also be a 2-tuple such as bc type=((order,value),(order,value)) where
the first argument order is the order of the derivative at the boundary, and the
second argument is its value. (Optional with default value ’not-a-not’)
extrapolate: A boolean variable that determines whether to extrapolate to points outside
the interval [x0, xN]. It can also take the values ’periodic’ or None. (Optional with
default value None)

The Module scipy.interpolate
231
Here is an example where we interpolate the function f(x) = sin(x) using 10 points in
[0, 2π]. In this code we compute the cubic spline along with its derivatives and we plot the
results.
1
x = np.linspace(0.0, 2.0*np.pi, 10); y = np.sin(x)
2
cs = spi.CubicSpline(x, y)
3
xx = np.arange(0.0, 2*np.pi, 0.1)
4
plt.plot(x, y, 'o', label='data')
5
plt.plot(xx, cs(xx), label="$S$")
6
plt.plot(xx, cs(xx, 1), label="$S'$")
7
plt.plot(xx, cs(xx, 2), label="$S''$")
8
plt.plot(xx, cs(xx, 3), label="$S'''$")
9
plt.xlim(0, 2.0*np.pi); plt.legend(loc='lower left', ncol=2)
10
plt.xlabel('$x$'); plt.ylabel('$y$',rotation=0); plt.show()
0
1
2
3
4
5
6
x
−1.0
−0.5
0.0
0.5
1.0
y
data
S
S′
S′′
S′′′
Observe that the third derivative of the cubic spline is a piecewise constant function but it
was plotted as a piecewise linear function.
We already mentioned that the function CubicSpline returns a function as an object.
The specific object (class) called PPoly is accompanied by additional methods. For example,
if we store a cubic spline in a variable cs as before, then we can get its derivative as a new
function using the method cs.derivative(nu), where nu is the order of the derivative.
This method returns just a piecewise polynomial object (PPoly). Similarly, one can obtain
an antiderivative using the method cs.antiderivative(nu). We can compute a definite
integral of a cubic spline over an interval [a, b] just by typing cs.integrate(a,b). The
function integrate can also has an additional argument extrapolation (which is None by
default) with which we can specify whether to extrapolate the spline or not similarly to the
function call CubicSpline.
Runge’s example revisited
As we saw before, the Lagrange interpolation fails to accurately approximate Runge’s func-
tion
f(x) =
1
1 + 25x2 .
We try again Runge’s example using cubic spline interpolation.

232
Interpolation and Approximation
1
def f(x):
2
return 1.0 / (1.0 + 25.0 * x**2)
3
num_points = 10
4
x = np.linspace(-1, 1, num_points)
5
y = f(x)
6
cs = spi.CubicSpline(x, y)
7
xx = np.linspace(-1, 1, 100)
8
plt.plot(x, y, 'o', label='data')
9
plt.plot(xx, f(xx), label='true')
10
plt.plot(xx, cs(xx), label='Spline')
11
plt.xlim(-1, 1)
12
plt.legend(loc='upper left', ncol=1)
13
plt.xlabel('$x$'); plt.ylabel('$y$',rotation=0); plt.show()
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
x
0.0
0.2
0.4
0.6
0.8
1.0
y
data
true
Spline
This time the cubic spline approximates Runge’s function without problems. We encourage
the reader to experiment with the specific example and try Runge’s example with more and
less nodes, and compare with analogous results using Lagrange interpolation.
6.6.3
Computations with B-splines
We can compute the B-spline representation of an interpolant in Python using the function
splrep of the module scipy.interpolate. The general call of the function splrep is the
following:
splrep(x, y, w, xb, xe, k, task, s, t,full_output, per, quite)
where here
x:
An array with the values xi, i = 0, . . . , N
y:
An array with the values yi, i = 0, . . . , N
w:
A rank-1 array of weights with the same length as x and y for least squares fit.
(Optional with default value None)
xb, xe: Floating point numbers that determine the endpoints of the interpolation interval.
(Optional with default values ’None’)

The Module scipy.interpolate
233
k:
The degree of the spline. (Optional with default value 3)
task: A value between 1 for a subsequent call of the function with a new value of the
smoothing factor s, 0 for evaluations of the spline coefficients using the specified
smoothing factor s and −1 for weighted least squares approximation. (Optional with
default value 0)
s:
A smoothing factor. (Optional with default value None)
t:
The nodes needed for task=-1. (Optional with default value None)
full output: If non-zero, then the function returns optional output. (Optional with de-
fault value 0)
per: If non-zero then the data points are considered periodic. (Optional with default value
0)
quite: A non-zero value suppress messages. (Optional with default value 1)
The function returns a tuple tck=(t,c,k) where t is a vector with nodes, c a vector with
the spline coefficients ai, and k the degree of the spline. Optional arguments returned such
as fp with the weighted sum of squared residuals of the spline approximation, ier as a flag
of convergence, and msg a message corresponding to the ier flag.
After computing the spline coefficients ai into the array c we can evaluate the spline func-
tion at any point x we want using the function splev of the module scipy.interpolate.
The general call of the function splev is the following:
splev(x, tck, der, ext)
where
x:
An array with the points x at which we need the values of the spline
tck: The tuple tck received in the output of splrep.
der: The order of the derivative to be computed less than or equal to k. (Optional with
default value 0)
ext: Controls the value returned for elements of x not in the interval defined by the node
sequence. (Optional with default values ’0’)
The function returns the values of the spline y.
As an example we consider again the Runge function and the following code:
1
def f(x):
2
return 1.0/(1+25*x**2)
3
x = np.linspace(-1.0, 1.0, 10)
4
y = f(x)
5
spl = spi.splrep(x, y)
6
z = np.linspace(-1.0, 1.0, 200)
7
yz = spi.splev(z, spl)
8
yyz = f(z)
9
print(spl[2])
10
plt.plot(x, y, 'o', label='data')
11
plt.plot(z, yyz, label='true')

234
Interpolation and Approximation
12
plt.plot(z, yz, label='Spline')
13
plt.xlim(-1, 1)
14
plt.legend(loc='upper left', ncol=1)
15
plt.xlabel('$x$')
16
plt.ylabel('$y$',rotation=0)
17
plt.show()
The result of this code is identical with the results obtained in Section 6.6.2. By printing
also the value spl[2] we verify that the degree of the spline is 3.
6.6.4
General purpose interpolation and the function interp1d
There is a general purpose Python function that can be used with various different methods
of interpolation. This is the function interp1d of the module scipy.interpolate. The
general call of the function interp1d is
interp1d(x, y, kind, axis, copy, bounds_error, fill_value, assume_sorted)
where
x:
A one-dimensional array with the values xi
y:
An n-dimensional array with length equal to the length of x containing the data yi
kind: String specifying the kind of interpolation and it takes values linear, nearest,
nearest-up, zero, slinear, quadratic, cubic, previous, and next. (Optional with
default value ’linear’)
axis: Specifies the axis of y along which to interpolate. (Optional with default value -1)
copy: Is a boolean variable which specifies if the variables x,y will be copied internally or
not. (Optional with default value True)
bounds error: Is a boolean variable which should be True when we use the function for ex-
trapolation to compute data outside the region defined by the data (xi, yi). (Optional
with default value None)
fill value: This is the value to be used for points outside the interpolation domain. It can
also take the value "extrapolate". If this is None then nearest-neighbor extrapolation
is used. (Optional with default value NaN)
assume sorted: It determines whether the values of x are sorted or not. If they are not
sorted (False) then the algorithm will sort them first. (Optional with default value
False)
The interp1d function returns a class that can be used as an interpolation function for com-
putations. As a simple example we consider again the interpolation of a data set produced
using Runge’s function in [−1, 1].
1
def f(x):
2
return 1.0/(1+25*x**2)
3
x = np.linspace(-1,1,10)
4
y = f(x)
5
p = spi.interp1d(x, y, kind = 'cubic' )

The Module scipy.interpolate
235
6
z = np.linspace(-1,1,100)
7
plt.plot(x, y, 'o', label='data')
8
plt.plot(z, f(z), label='true')
9
plt.plot(z, p(z), label='interpolant')
10
plt.xlim(-1, 1)
11
plt.legend(loc='upper left', ncol=1)
12
plt.xlabel('$x$'); plt.ylabel('$y$',rotation=0); plt.show()
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
x
0.0
0.2
0.4
0.6
0.8
1.0
y
data
true
Spline
Using cubic spline interpolation with the function intrp1d we obtain the same results
as in Section 6.6.2. We let the interested reader to experiment with the different kinds of
interpolation methods offered with the function interp1d.
6.6.5
Interpolation in two dimensions
Two-dimensional interpolation is the interpolation of data points (xi, yi, zi) for i =
0, 1, . . . , N by a polynomial z = P(x, y) in two dimensions. Suppose that there is a function
f such that zi = f(xi, yi) for all i = 0, 1, . . . , N. This case is more complicated compared to
the one-dimensional problem as the data points (xi, yi) can be scattered randomly in the
xy-plane forming a non-uniform and unstructured grid of points. It is often the case that
these data points can form a triangular grid like the one in Figure 6.6.
For the sake of simplicity, we consider only rectangular domains [a, b] × [c, d] and rect-
angular grids. Such grids consist of points (xi, yj), i = 0, 1, . . . , N, j = 0, 1, . . . , M with
xi+1 = xi + ∆x for i = 0, 1, . . . , N −1 and yj+1 = yj + ∆y for j = 0, 1, . . . , M −1. An
example of a rectangular grid is depicted in Figure 6.6. For any of the previous grids we can
apply Lagrange as well as Spline interpolation. We define the Lagrange polynomials for a
rectangular grid as
ℓi(x) =
N
Y
k̸=i,k=0
x −xk
xi −xk
,
for
i = 0, 1, . . . , N ,
and
¯ℓj(y) =
M
Y
k̸=j,k=0
y −yk
yj −yk
,
for
j = 0, 1, . . . , M .

236
Interpolation and Approximation
0.0
0.2
0.4
0.6
0.8
1.0
x
0.2
0.4
0.6
0.8
1.0
y
0
1
2
3
4
5
x
0.0
0.5
1.0
1.5
2.0
2.5
3.0
y
FIGURE 6.6
Examples of planar grids: unstructured triangular grid (left) versus structured rectangular
grid (right).
The Lagrange interpolant of the data (xi, yj, f(xi, yj)) is the function
P(x, y) =
N
X
i=0
M
X
j=0
f(xi, yj)ℓi(x)¯ℓj(y) .
Bivariate spline functions can be defined as tensor products of one-dimensional splines. Let
ϕi(x) and ¯ϕj(y) be the spine basis functions in x and y coordinates, respectively. Then, the
spline interpolant is the function
S(x, y) =
˜
N
X
i=0
˜
M
X
j=0
ci,jϕi(x)¯ϕj(y) ,
where of course ci,j are equal to f(xi, yj) only if the ¯ϕj and ¯ϕj are linear B-splines, and
˜N,
˜
M are the dimensions of the corresponding one-dimensional spline spaces. For more
information about tensor product of splines, we refer to [117].
The module scipy.interpolate has the function interp2d which can interpolate data
points (xi, yi, zi) using spline interpolation in two dimensions. This function is a generaliza-
tion of interp1d and its general call is the following:
interp2d(x, y, z, kind, copy, bounds_error, fill_value)
where
x,y,z: Arrays of values for the data points (xi, yi, zi). In general, these arrays can be 1D
with the values (xi, yi, zi)
kind: String specifying the kind of spline interpolation. It takes values linear, cubic and
quintic. (Optional with default value ’linear’)
copy: Is a boolean variable which specifies whether the variables x,y,z will be copied
internally or not. (Optional with default value True)
bounds error: Is a boolean variable which should be True when we use the function for
extrapolation purposes. (Optional with default value ’False’)
fill value: Is the value to be used for points outside the interpolation domain. If this
is None, then nearest-neighbor extrapolation is used. (Optional with default value
None)

The Module scipy.interpolate
237
The function returns a class that can be used as a spline function for computations. The
minimum number of data points required for the spline interpolation is (k + 1)2 with k = 1
for linear, k = 3 for cubic and k = 5 for quintic interpolation. Alternatives to the function
interp2d are the functions RectBivariateSpline for splines on rectangular grids and
BivariateSpline.
As an example we consider the interpolation of the Gaussian function f(x, y) =
e−(x2+y2). First we plot the particular function on the rectangular domain [−2, 2] × [−2, 2]
using the method plot surface of MatPlotLib. The function plot surface requires the
transformation of the arrays x and y into two-dimensional rectangular grid arrays on which
Zij = f(Xij, Yij). We generate the one-dimensional grids using the function arange as ex-
plained in Section 1.4.2. Given the one-dimensional grids stored in the array x and y we
generate the two-dimensional representations using the NumPy function meshgrid as X, Y
= np. meshgrid(x,y). Then we can generate the surface z = f(x, y) using the function
plot surface(X,Y,Z,cmap) where Z=f(X,Y) and cmap defines the colormap we want to
use. Executing the following code we observe that this function is like a Gaussian bell that
decreases exponentially fast to 0 as x and y move away from the origin.
1
def f(x,y):
2
z = np.exp(-(x**2+y**2))
3
return z
4
# Specify that the graph is three-dimensional
5
fig = plt.figure()
6
ax = plt.axes(projection='3d')
7
# Generate the data
8
x = np.arange(-2, 2, 0.1)
9
y = np.arange(-2, 2, 0.1)
10
X, Y = np.meshgrid(x, y)
11
Z = f(X,Y)
12
# Plot the surface.
13
surf = ax.plot_surface(X, Y, Z, cmap='viridis')
14
plt.show()
−2.0−1.5−1.0−0.50.0 0.5 1.0 1.5 2.0
−2.0
−1.5
−1.0
−0.5
0.00.51.01.52.0
0.2
0.4
0.6
0.8
1.0
For the purposes of this example, we assume that we know the values of the function f
on a sparse 10 × 10 grid of points of the domain [−2, 2] × [−2, 2]. We interpolate the coarse
10×10 data in a dense 100×100 grid using the function interp2d. We will plot the original
and interpolated data side by side. In the following code, we use the function subplots to
plot two graphs side by side and also the function pcolormesh to plot the projection of the

238
Interpolation and Approximation
surface generated by the data on the xy-plane. The function subplots create a grid of plots
with nrows rows and ncols columns. It also returns a figure fig and a class axes which
determines the location of figures in the grid.
1
#define the function f
2
def f(x,y):
3
z = np.exp(-(x**2+y**2))
4
return z
5
# generate one-dimensional grids
6
x = np.linspace(-2, 2, 10)
7
y = x.copy()
8
z = f(x,y)
9
# generate two-dimensional grid arrays
10
X, Y = np.meshgrid(x, y)
11
Z = f(X,Y)
12
# interpolate the coarse data
13
z2 = spi.interp2d(x, y, Z, kind='cubic')
14
# evaluated the interpolant on dense grid
15
xx = np.linspace(-2, 2, 100)
16
yy = np.linspace(-2, 2, 100)
17
XX, YY = np.meshgrid(xx, yy)
18
ZZ = z2(xx,yy)
19
# plot the original and interpolated data
20
fig, axes = plt.subplots(nrows=1, ncols=2)
21
axes[0].pcolormesh(X, Y, Z)
22
axes[1].pcolormesh(XX, YY, ZZ)
23
plt.show()
−2
−1
0
1
2
−2.0
−1.5
−1.0
−0.5
0.0
0.5
1.0
1.5
2.0
−2
−1
0
1
2
−2.0
−1.5
−1.0
−0.5
0.0
0.5
1.0
1.5
2.0
We observe that interpolating coarse data to dense data using cubic spline interpolation
we obtain a smooth result. This has an immediate consequence in image processing which
we present in the next section.
6.6.6
Application in image processing
Among the straightforward applications of interpolation from known data to unknown there
are many applications in practical problems and especially in computer graphics and image

The Module scipy.interpolate
239
processing. Here we present an application in image processing. Specifically, we show how
we can improve the resolution of an image using spline interpolation.
Suppose that we have a digital photograph stored in our computer as a digital color
image. A digital color image is an arranged set of pixels. Each pixel has each own color
which can be represented by its values of the intensity of the basic colors red, green and
blue (RGB). The color of each pixel is defined by a tuple of the form (R, G, B) where R
stands for Red, G for Green and B for Blue. The colors can take values from 0 to 255 and
usually are integer values. The value 0 indicates the complete absence of a specific color.
For example, the blue color in the RGB scale will be (0, 0, 255).
In this application we read a low resolution digital photograph of Lenna4. We assume
that this photograph is stored in the file Lenna.jpg. In Python we can read an image using
the command imread of the module imageio. The imread function in the following code
reads the digital image stored in the file Lenna.jpg and stores it into the rectangular array
lenna. Then we normalize its values and we store it in the array photo1. Practically, the
matrix is a rectangular array with values the intensity of red, green and blue colors on each
cell. In order to improve the resolution of this image, we will consider a denser grid (larger
matrix) with the interpolated red, green and blue intensities.
After we have loaded the image in the computer memory, we print the shape of the array
lenna. This matrix is 128×128×3. This means that the picture consists of 128×128 pixels,
with RGB values stored in three slices of the matrix photo1. Since we are working with
functions, we consider the domain [0, 128]×[0, 128] and the grids in x and y axes with space
∆x = ∆y = 1. For the interpolation we generate a denser grid with ∆x = ∆y = 0.1. We
can display the photo using the three dimensional array photo1 and the command imshow
of MatPlotLib.
After we separate the three colors using three different arrays, we interpolate the red,
green, blue intensities using the function interp2d over a dense grid. We store the interpo-
lated values in the arrays better red, better green and better blue. We combine these
arrays into a single array called photo2. The code of this application follows:
1
import matplotlib.pyplot as plt
2
import imageio
3
import numpy as np
4
import scipy.interpolate as spi
5
6
# read the picture from file lena.jpg
7
lenna = imageio.imread("Lenna.jpg");
8
print(lenna.shape)
9
# scale the values to be between 0.0 and 1.0
10
photo1 = lenna.copy()/255.0
11
# get the intensity of red, green, blue
12
red = photo1[:,:,0]
13
green = photo1[:,:,1]
14
blue = photo1[:,:,2]
15
n = len(red)
16
# generate x and y coordinates
17
x = np.arange(0.0,n,1.0)
4Lenna is a standard test image used in computer science to demonstrate image processing techniques
since 1973. It is a picture of the Swedish model Lena Fors´en, shot by photographer Dwin Hooker.

240
Interpolation and Approximation
18
y = x.copy()
19
# interpolated the red, green and blue intensities
20
better_red = spi.interp2d(x,y,red,kind='cubic')
21
better_green = spi.interp2d(x,y,green,kind='cubic')
22
better_blue = spi.interp2d(x,y,blue,kind='cubic')
23
# generate dense xx and yy coordinates
24
xx = np.arange(0.0,128.0,0.1)
25
yy = xx.copy()
26
row=len(xx)
27
col=len(yy)
28
# create array photo2 for the high-resolution picture
29
photo2 = np.zeros((row, col, 3))
30
# interpolate the data
31
photo2[:,:,0] = better_red(xx,yy)
32
photo2[:,:,1] = better_green(xx,yy)
33
photo2[:,:,2] = better_blue(xx,yy)
34
f, axs = plt.subplots(1,2,figsize=(15,15))
35
axs[0].imshow(photo1)
36
axs[1].imshow(photo2)
37
# choose a square of your choice such as [50,80]x[50,80]
38
zoom1 = photo1[50:80,50:80,:]
39
zoom2 = photo2[500:801,500:801,:]
40
# compare the different data
41
f, axs = plt.subplots(1,2,figsize=(15,15))
42
axs[0].imshow(zoom1)
43
axs[1].imshow(zoom2)
44
plt.show()

Further Reading
241
Magnifying the two images around the region [50, 80] × [50, 80] of the original image
we observe that using interpolation we have improved the original resolution by smoothing
out rough edges. It is noted that cubic splines smooth out oscillations and increase the
regularity of the interpolating data (see Exercise 9 for a proof of this property). For this
reason, using cubic splines especially in image processing we can obtain smoother images
compared to the original one.
6.7
Further Reading
The theory of interpolation and least squares approximation is covered in all classic text-
books [25, 70, 76, 22, 26, 7, 108, 116]. In this book, we followed [127] in the development
of the theory of splines. Specialized books on interpolation are, among many, the following
[107, 31, 117, 118] while a practical introduction to two-dimensional interpolation can be
found in [119]. A dedicated book to least squares problems is the book [12].

Chapter Highlights
 Interpolation is the procedure of finding a function (usually a polynomial or a
piecewise polynomial function) with graph passing through a given set of
points.
 Given N + 1 points (xi, yi) the Lagrange interpolation is the set of methods for
determining the unique polynomial PN(x) of degree N such that PN(xi) = yi.
 The Lagrange interpolating polynomial can be written as
PN(x) =
N
X
i=0
yiℓi(x) ,
where ℓi(x) are the Lagrange polynomial basis functions.
 An efficient way for the computation and evaluation of the Lagrange
interpolation is via Newton’s form for a representation of an interpolating
polynomial.
 Lagrange interpolation fails when the magnitude of high-order derivatives is
large. An example of such failure is Runge’s function.
 If in addition to the interpolation data yi = PN(xi) we have the values of the
first derivative, then Lagrange interpolation is generalized to the Hermite
interpolation.
 Hermite interpolation might be more accurate compared to Lagrange
interpolation, but it cannot solve the problem with Runge’s function.
 Piecewise polynomial interpolation is the solution to Runge’s problem.
 Spline is a piecewise polynomial function. A linear spline is a piecewise linear
function and thus not differentiable at the nodes. A cubic spline is a piecewise
cubic function, which is twice continuously differentiable.
 B-splines can be computed using recursive algorithms. One such algorithm is
the Cox-de Boor algorithm.
 Cubic spline interpolation requires knowledge of the behavior of the
interpolating polynomial at the boundary.
 Cubic splines are characterized by a smoothing property. For this reason, cubic
splines are used in image processing.
 When the data points are too “noisy” we approximate them by a function or a
polynomial without requiring interpolation.
 One such method is the method of least squares, which is based on the
minimization of the error function
S =
N
X
i=0
|yi −P(xi)|2 .
242

Exercises
1. Given the data f(0) = 1, f(1) = 3 and f(3) = 5:
(a) Approximate the value f(2) using an appropriate interpolating polynomial written
in Lagrange’s form.
(b) Approximate the same value using Newton’s divided difference formula.
(c) Construct interpolating cubic spline and approximate the value f(2).
2. Let xi, i = 1, 2, . . . , n + 1 different nodes and let yi ∈R, i = 1, 2, . . . , n + 1. The
interpolating polynomial is written in Newton’s form as:
pn(x) = a1 + a2(x −x1) + a3(x −x1)(x −x2) + · · · + an+1(x −x1) · · · (x −xn+1),
where the coefficients ai, i = 1, . . . , n+1 can be computed using the following algorithm:
Algorithm 24 Newton’s polynomial
ai = yi, i = 1, 2, . . . , n + 1
for k = 2 : n + 1 do
for i = 1 : k −1 do
ak = (ak −ai)/(xk −xi)
end for
end for
If the coefficients ai, i = 1, . . . , n + 1 are known, then the value of the interpolating
polynomial at the point z can be computed using Horner’s formula:
Algorithm 25 Horner’s formula
s = an+1
for i = n : −1 : 1 do
s = ai + (z −xi)s
end for
pn(z) = s
(a) Write Python functions coefs and evalp implementing the previously described
algorithms for the coefficients of the interpolating polynomial and its evaluation
at values z using Horner’s formula. Write a function newtinterp with input ar-
guments (x, y, z), where (xi, yi), i = 1, . . . , n + 1, the interpolation data points
and z = [z1, . . . , zm] the vector with the m points at which we want to evaluate
the interpolating polynomial. This will compute the coefficients of the interpolating
polynomial ai using your function coefs and will return the values ui = pn(zi),
i = 1, 2, . . . , m using your function evalp.
(b) Consider the function f(x) = sin x, x ∈[0, 2π], and a uniform partition of [0, 2π]
with 6 points xi, i = 1, . . . , 6. Using your function newtinterp.m compute the
interpolating polynomial p5, that interpolates function f at the nodes xi, at 101
equidistributed points zi ∈[0, 2π].
(c) Verify your results and compare them with those obtained by using the Python
functions polyfit, polyval and CubicSpline.
243

3. Consider the following data:
ti
1991
1996
2001
2006
2011
2016
yi
3, 516, 000
3, 762, 300
3, 916, 200
4, 209, 100
4, 399, 400
4, 747, 200
where yi is the population of New Zealand in the year ti.
(a) Complete the divided difference tableau and compute by hand the Newton’s form
of the interpolating polynomial of the given data.
(b) Using the function newtinterp of Problem 2, compute the interpolating polynomial
p ∈P5, that interpolates the values (ti, yi).
(c) Compare the numerical solution with your theoretical computations.
(d) Estimate the population of New Zealand for all the years between 1991 until 2016.
(e) Compare the results using the appropriate Python function with a cubic spline.
(f) Using your interpolating polynomial find an approximation of the population of
New Zealand for the years 2018 and 2034.
(g) Repeat the computations with integer values ti and yi instead of floats. What do
you observe?
4. Let
f(x) =
1
1 + 25x2 , −1 ≤x ≤1.
(a) Using your function newtinterp compute the interpolating polynomial p ∈Pn,
which interpolates the points (xi, f(xi)), i = 1, 2, . . . , N + 1 of a uniform partition
of [−1, 1] for N = 5, 10, 20, 100. Let zi, i = 1, 2, . . . , 201, equidistributed points of
[−1, 1]. Plot your interpolants and comment on the results.
(b) Compute the values of the interpolating polynomial p(zi) and compare the results
with the Python cubic spline function. Comment on the accuracy of the two meth-
ods.
5. Consider the polynomial f(x) = x5 +x4 in the interval [−2, 2]. Using five equidistributed
nodes in [−2, 2]:
(a) Compute the Lagrange interpolating polynomial.
(b) Compute the cubic spline interpolant with natural boundary conditions.
(c) Compute the cubic spline interpolant with clamped boundary conditions.
(d) Sketch the graphs of the function and the three approximating functions and com-
pare the results.
6. Consider the function
f(x) =

0,
x ∈[0, 1] ,
(x −1)4,
x ∈(1, 2] .
(a) Find the coefficients a, b, c, d in the following piecewise and continuously differen-
tiable polynomial function
p(x) =

0,
x ∈[0, 1] ,
a + b(x −1) + c(x −1)2 + d(x −1)2,
x ∈(1, 2] .
in order to interpolate the function f such as
p(0) = f(0), p′(0) = f ′(0), p(1) = f(1), p(2) = f(2), p′(2) = f ′(2) .
244

(b) Compute the cubic spline interpolant with clamped boundary conditions at the
nodes {0, 1, 2}.
(c) Modify the definition of the Hermite interpolating polynomial to interpolate the
specific function f at the same nodes.
(d) Sketch the graphs of the function f and its approximations.
7. Consider the function f(x) = cos(kπx) for x ∈[0, 1] and k ∈N.
(a) Estimate the maximum norm of the error in the Lagrange interpolation for uniform
grid of N nodes.
(b) What is the relationship between k and N so as the error converges to 0 while
k, N →∞?
(c) Estimate the maximum norm of the error of the linear spline interpolant for the
same grid.
(d) Find again the relationship between k and N so as the error converges to 0 while
k, N →∞.
(e) In the case where k = 500, which method would you prefer to use for the interpo-
lation problem in order to get an error less than 10−2?
8. A F1 car is racing in the Albert Park Circuit for the Australian Grand Prix. The particu-
lar circuit has length 5.303 km. The lap times in minutes:seconds and the corresponding
recorded speeds in km/h are given in the following table:
Time (minutes : seconds)
0 : 0.000
1 : 30.245
1 : 25.533
1 : 20.259
1 : 22.453
Lap
0
4
8
12
16
Speed (km/h)
212
236
255
224
240
(a) Use Lagrange interpolation to predict the location of the car when t = 3 : 50.000.
(b) Repeat the calculation using Hermite interpolation.
(c) Use the derivative of the Hermite interpolant to estimate whether the car ever
exceeds the speed of 255 km/h.
(d) Predict the maximum speed of the car.
9. Let f ∈C2[a, b] and Pc(x) the cubic spline interpolant with clamped boundary conditions
of the function f at the nodes xi, i = 0, 1, . . . , N of [a, b].
(a) Prove that
Z b
a
(f ′′(x) −P ′′
c (x)) P ′′
c (x) dx = 0 .
(b) Prove that
Z b
a
(P ′′
c (x))2 dx ≤
Z b
a
(f ′′(x))2 dx .
(c) Explain the geometric interpretation of the previous results and explain why it is
called the cubic spline smoothness theorem.
10. Consider the following dataset:
xi
0.0
0.1
0.2
0.3
0.4
0.5
0.6
yi
2.8
2.9
2.7
2.4
2.3
2.1
1.8
245

(a) Compute a piecewise linear interpolant for the points (xi, yi) using appropriate
Python function.
(b) Compute the linear least squares approximation of the same set of points using
appropriate Python function.
(c) Sketch the graph of the dataset and the approximations and comment on the results.
11. Consider the (nonlinear) function f(x) = √x in [0, 1].
(a) Generalize the linear least squares method to approximate data that follow the
nonlinear rule f(x).
(b) Write Python function to implement the specific nonlinear least squares method.
(c) Generate a set of points (xi, yi), i = 0, 1, . . . , 9 using random perturbations of the
points (xi, f(xi)), i = 0, 1, . . . , 9 and test your computer code.
12. Consider the function f(x) = 1/(x2 + 1) in the interval [0, 1].
(a) Compute the Lagrange interpolant P2(x) on a uniform grid with 3 nodes without
the help of Python.
(b) Compute the linear spline (piecewise linear interpolant) S1(x) using the same grid.
(c) Approximate the integrals like
Z 1
0
f(x) dx ≈
Z 1
0
P2(x) dx ,
and
Z 1
0
f(x) dx ≈
Z 1
0
S1(x) dx .
(d) Which method gives more accurate results?
13. Consider the function f(x) = 1/(x2 + 2) in the interval [−10, 10].
(a) Use Lagrange interpolation to compute the values f(0) and f(9.76) using
10, 11, 20, 21, 100 and 101 nodes.
(b) Use linear and cubic spline interpolation to approximate the same value and using
the same grids.
(c) Compare your results with results obtained using the Python function interp1d.
14. Consider the function f(x, y) = 1/(x2 + y2 + 1) in the interval [−5, 5] × [−5, 5].
(a) Write a Python program to implement the two-dimensional Lagrange interpolation
using rectangular grids as described in Section 6.6.5.
(b) Use your code to compute the Lagrange interpolant and estimate the values f(0, 0),
f(4.76, 0) and f(4.76, 4, 76) using 100 and 101 nodes.
(c) Compare your results with results obtained using the Python function interp2d
using linear, cubic and quintic spline interpolation.
(d) Use appropriate functions from the module MatPlotLib to present the results.
246

7
Numerical Integration
Integrals of functions often appear in applications as well as in various computations. For
example, the energy of a system is usually expressed as an integral. The issue is that most
integrals do not have closed form solutions. For instance, the integral
Z b
a
p
1 + cos2(x) dx ,
is a case where its computation is extremely hard if not impossible. In such cases we need
automated methods to approximate integrals. In this chapter, we discuss numerical methods
for the approximation of definite integrals of single-variable functions. Numerical integra-
tion is also known as quadrature and the approximate formulas for the integrals are called
quadrature rules.
7.1
Introduction to Numerical Quadrature and Midpoint Rule
Quadrature is based on the approximation of an integral
I[f] =
Z b
a
f(x) dx ,
by a finite sum IN of the form
IN[f] =
N
X
i=0
wif(zi) .
The constants wi are called quadrature weights while the zi’s are the quadrature points or
nodes. Usually, a quadrature rule is specified by the points zi and a particular set of weights
wi. Ideally, we would like the quadrature to converge to the exact integral as the number
of quadrature points tends to infinity
lim
N→∞IN[f] = I[f] .
The roots of numerical integration can be found in the definition of definite integral:
Given a continuous function f(x) and a partition of the interval [a, b] with {xi}N+1
i=0
such
that a = x0 < x1 < · · · < xN+1 = b we choose zi ∈[xi, xi+1] for i = 0, 1, . . . , N. Then, we
define the Riemann integral as
Z b
a
f(x) dx = lim
N→∞
N
X
i=0
(xi+1 −xi)f(zi) .
DOI: 10.1201/9781003287292-7
247

248
Numerical Integration
FIGURE 7.1
The midpoint rule.
Choosing a large value of N we approximate the integral with a finite sum such as
Z b
a
f(x) dx ≈
N
X
i=0
(xi+1 −xi)f(zi) .
This definition suggests that the weights are wi = xi+1 −xi and the nodes zi, and leads to
a number of quadrature rules based on how we choose the values zi ∈[xi, xi+1].
The simplest of all quadrature rules is the midpoint rule with one interval [a, b] = [x0, x1].
We take the point z0 to be the midpoint z0 = a+b
2 . This quadrature rule approximates the
area prescribed by the graph of f, the lines x = a, x = b and the x-axis with the area of the
parallelogram with sides z0 and x1 −x0. This is depicted in Figure 7.1. The approximate
formula of an integral I[f] is given by
I[f] ≈I0[f] = w0f(z0) = (b −a)f
a + b
2

.
When we use only one interval, N = 1, the error between the exact value of the integral
and its approximation can be significantly large, especially when the interval [a, b] is large.
For this reason, we divide the interval [a, b] into N subintervals of the form [xi, xi+1] for
i = 0, 1, . . . , N, such that a = x0 < x1 < · · · < xN+1 = b. For the sake of simplicity we
assume that the intervals [xi, xi+1] have uniform length h = xi+1 −xi. The integral I[f]
can be written as
I[f] =
Z b
a
f(x) dx =
N
X
i=0
Z xi+1
xi
f(x) dx .
We now apply the midpoint rule to the smaller intervals [xi, xi+1]. We choose zi to be the
midpoint of the interval [xi, xi+1], that is
zi = xi + xi+1
2
.
The application of midpoint rule in each of these intervals gives
Z xi+1
xi
f(x) dx ≈(xi+1 −xi)f
xi + xi+1
2

= hf
xi + xi+1
2

,

Newton-Cotes Quadrature Rules
249
which leads to the composite midpoint rule
IN[f] =
N
X
i=0
(xi+1 −xi)f
xi + xi+1
2

= h
N
X
i=0
f
xi + xi+1
2

.
This suggests that given a subdivision a = x0 < x1 < · · · < xN+1 = b of [a, b], the weights of
the midpoint rule are wi = (xi+1 −xi) = h and the quadrature nodes are zi = (xi +xi+1)/2.

When we divide an interval of integration [a, b] into subintervals [xi, xi+1] and
we apply a quadrature rule on each subinterval, the resulting quadrature rule is
called composite rule.
In order to illustrate the use of the midpoint rule for the approximation of integrals we
consider the integral
Z 2π
0
sin(x) dx = [−cos(x)]2π
0
= 0 ,
and we apply the midpoint rule with 10 quadrature nodes in the following Python code:
1
f = lambda x: np.sin(x)
2
N = 10 # intervals
3
a = 0.0; b= 2.0*np.pi; h=(b-a)/N
4
x = np.linspace(a, b, N+1)
5
z = (x[1:] + x[:-1]) / 2.0
6
w = h*np.ones_like(z)
7
quad = np.inner(w, f(z))
8
print('Result =', quad)
Result = -2.7755575615628914e-16
Line 4 contains the definition of a partition of [a, b], line 5 the definition of the quadrature
nodes using the midpoints of each interval [xi, xi+1], and line 6 the definition of the weights
wi. The operation zi = (xi+1 + xi)/2 could have been introduced in a for loop but we used
the vectorized form z=(x[1:]+x[:-1])/2.0 instead. An alternative way to vectorize this
operation is by using the indices explicitly using the command z=(x[1:N]+x[0:N-1])/2.0.
Note that the midpoint rule has been used widely in many situations due to its simplicity. We
continue with two different classes of quadrature rules, namely the Newton-Cotes and the
Gaussian quadrature rules. These are among the most sophisticated classes of quadrature
and are the most popular in practice. These methods have been introduced by Sir Isaac
Newton (1642–1726), Roger Cotes (1682–1716) and Johann Carl Friedrich Gauss (1777–
1855), respectively (since the integrand is a polynomial, see Figure 7.2).
7.2
Newton-Cotes Quadrature Rules
Newton-Cotes rules are based on the approximation of the integrant f(x) by an interpolating
polynomial. The integral of f is then approximated by the integral of the interpolating
polynomial, which we can compute exactly.

250
Numerical Integration
FIGURE 7.2
Illustration of the interpolating polynomial at the quadrature nodes zi.
Using N + 1 equally-spaced points a = x0 < x1 < . . . < xN = b, the quadrature nodes
are defined as zi = xi for i = 0, 1, . . . , N. This situation is depicted in Figure 7.2. We
evaluate f(x) at these points and take the interpolating polynomial
PN(x) =
N
X
i=0
f(zi)ℓi(x)
where
ℓi(x) =
N
Y
j=0
j̸=i
x −xj
xi −xj
.
The quadrature formula for IN[f], which approximates I[f], is defined as
IN[f] =
Z b
a
PN(x) dx =
Z b
a
N
X
i=0
f(zi)ℓi(x) dx =
N
X
i=0
"
f(zi)
Z b
a
ℓi(x) dx
#
=
N
X
i=0
wif(zi) ,
where the weights are given as
wi =
Z b
a
ℓi(x) dx,
i = 0, 1, . . . , N .
The general Newton-Cotes quadrature rule has the form
IN[f] =
N
X
i=0
wif(zi) .
(7.1)
A classical example for numerical quadrature is the trapezoidal rule. In the trapezoidal
rule only two quadrature nodes are needed. These are the endpoints of the interval [a, b],
z0 = x0 = a and z1 = x1 = b, and the linear interpolant P1(x).

Newton-Cotes quadrature rules are based on the idea of approximating an in-
tegral of a function f(x) by the integral of an interpolating polynomial of f(x).

Newton-Cotes Quadrature Rules
251
FIGURE 7.3
The trapezoidal rule.
7.2.1
Trapezoidal rule
The trapezoidal rule uses linear polynomials (i.e. N = 1) to approximate the function f(x).
For N = 1 we have
ℓ0(x) = x −x1
x0 −x1
= −x −b
h
and
ℓ1(x) = x −x0
x0 −x1
= x −a
h
,
where h = b −a is the length of the interval [a, b]. In this case, we have
w0 =
Z b
a
ℓ0(x) dx = 1
h
Z b
a
(x −b) dx = 1
2h(b −a)2 = h
2 ,
and
w1 =
Z b
a
ℓ1(x) dx = 1
h
Z b
a
(x −a) dx = 1
2h(b −a)2 = h
2 .
Substitution of the weights wi into the formula (7.1) yealds
I1[f] = h
2 [f(a) + f(b)] .
(7.2)
After approximating the function f(x) with a linear interpolant, the integral is approximated
by the area enclosed inside the trapezium formed by the linear interpolant, and the lines
y = 0, x = a and x = b (see Figure 7.3). Recall that the area of a trapezium is given by the
formula Area = [(large base)+(small base)]× (height)
2
. This is the same with formula (7.2).

The trapezoidal rule requires only two quadrature nodes and approximates the
actual integral by the area of the trapezium bounded by the straight line joining the
two endpoints, the x-axis and the lines x = a and x = b.
7.2.2
Error estimate of the trapezoidal rule
To find out the accuracy of the trapezoidal rule, we define the error between the exact and
approximate values of an integral as
E1[f] = I[f] −I1[f] .

252
Numerical Integration
The subscript 1 indicates that we use only one interval to approximate the integral, viz.
[a, b]. Using the formulas for I[f] and I1[f] we have
E1[f] = I[f] −I1[f] =
Z b
a
f(x) dx −
Z b
a
P1(x) dx =
Z b
a
(f(x) −P1(x)) dx ,
where P1 is the first order Lagrange interpolating polynomial of (a, f(a)) and (b, f(b)). From
the formula of the interpolation error (6.7) we have that
f(x) −P1(x) = f ′′(ξ)
2!
(x −x0)(x −x1) ,
for some ξ ∈(x0, x1) = (a, b). Thus,
E1[f] = 1
2!
Z b
a
(x −x0)(x −x1)f ′′(ξ) dx = 1
2f ′′(ξ)
Z b
a
(x −a)(x −b) dx
= −1
12(b −a)3f ′′(ξ) .
(7.3)
Taking the absolute value of the error E1[f] we obtain
|E1[f]| =

1
12(b −a)3f ′′(ξ)
 = 1
12(b −a)3 |f ′′(ξ)| ≤Ch3 ,
where h = b −a and C =
1
12 max |f ′′(ξ)| .
The shaded area in Figure 7.3 represents the area of the trapezium. We observe that
when the length of the interval [a, b] is large (for example if h > 1) then the interpolation
error can be quite large since it is proportional to the length h3.

Integrating in large intervals [a, b] with h = b −a > 1 requires composite rules
for high accuracy. Composite rules rely on the use of a grid of points a = x0 < x1 <
· · · < xN = b to define a partition of [a, b].
7.2.3
Composite trapezoidal rule
To increase the accuracy in computations we use the composite trapezoidal rule. Consider
a uniform partition of [a, b] with nodes x0 = a < x1 < · · · < xN = b. We integrate using the
property
Z b
a
f(x) dx =
N−1
X
i=0
Z xi+1
xi
f(x) dx .
To derive the composite trapezoidal rule, we apply the trapezoidal rule in each interval
[xi, xi+1]. In particular, we have
Z xi+1
xi
f(x) dx ≈h
2 [f(xi) + f(xi+1)] ,
where h = xi+1 −xi, for i = 0, 1, 2, . . . , N −1. Hence, the composite trapezoidal rule can
be written as
IN[f] =
N−1
X
i=0
h
2 [f(xi) + f(xi+1)]
= h
2 [f(x0) + 2f(x1) + 2f(x2) + · · · + 2f(xN−1) + f(xN)] .
(7.4)

Newton-Cotes Quadrature Rules
253
FIGURE 7.4
The composite trapezoidal rule.
Figure 7.4 shows the approximation of the integral with the composite trapezoidal rule. The
composite trapezoidal rule can be viewed as the exact integration of the piecewise linear
interpolant of f(x) at the nodes xi, i = 0, 1, . . . , N.
Implementation of the composite trapezoidal rule in Python is easy as well. The follow-
ing Python function computes an approximation of the integral of f from a to b using N
subintervals.
1
def trapezoidal(f, a, b, N):
2
# Composite trapezoidal rule with N subintervals
3
x = np.linspace(a, b, N+1)
4
y = f(x)
5
h = (b - a)/N
6
# First add the internal nodes
7
sum = 0.0
8
for i in range(1,N):
9
sum += 2.0*y[i]
10
# Add the two boundary nodes
11
sum = 0.5*h*(f(a) + sum + f(b))
12
return sum
In the function trapezoidal we first define the N +1 quadrature nodes in the variable x.
We compute the interpolation points y=f(x) and we define a stepsize h. Then we compute
the sum over all the internal nodes in a for loop. The command of line 11 computes the
result taking into account the contribution of the boundary nodes. It is left as an exercise
for the reader to replace the for loop of the previous code using the NumPy function sum.
To test the function trapezoidal we estimate the integral
Z π/2
0
sin(x) dx = 1 .
For testing purposes we use N = 10 subintervals.
1
f = lambda x: np.sin(x)
2
trapezoidal(f, 0.0, np.pi/2.0, 10)
0.9979429863543572
We observe that the result is correct up to two decimal digits or in other words the
error is O(10−2). This is because h = 2π/10 ≤C · 10−1 for some constant C > 0. On the

254
Numerical Integration
other hand, the error of the composite trapezoidal rule is expected to be O(h2). The error
is estimated analytically in the next section.

The composite trapezoidal rule is more efficient than the standard trapezoidal
rule in large intervals, and can be used even for general functions f.
7.2.4
Error estimate of the composite trapezoidal rule
Denote h = xi+1 −xi. Then the truncation error Ei[f] in each interval [xi, xi+1] is given by
the formula (7.3) as
Ei[f] = −h3
12f ′′(ξi) ,
with ξi ∈(xi, xi+1). The truncation error of a composite rule is the sum of the individual
truncation errors of the simple rule applied in each interval [xi, xi+1]
EN[f] =
N−1
X
i=0
Ei[f] = −h3
12
N−1
X
i=0
f ′′(ξi) .
(7.5)
Applying the intermediate value theorem to the second derivative and the fact that
min
a≤x≤b f ′′(x) ≤1
N
N−1
X
i=0
f ′′(ξi) ≤max
a≤x≤b f ′′(x) ,
we conclude that there is a ξ ∈(a, b) such that
f ′′(ξ) = 1
N
N−1
X
i=0
f ′′(ξi) .
Thus,
N−1
X
i=0
f ′′(ξi) = Nf ′′(ξ) = b −a
h
f ′′(ξ) .
From (7.5) we obtain
EN[f] = −(b −a)h2
12
f ′′(ξ) ≤Ch2 ,
where h = xi+1 −xi. This means that the error EN[f] →0 as N →∞, and the error of the
composite trapezoidal rule is O(h2). Thus, the numerical approximation converges to the
exact value of the integral as N →∞,
lim
N→∞IN[f] = I[f] .
7.2.5
Simpson’s rule
Simpson’s rule (named after Thomas Simpson (1710–1761) and also known as the 1/3 rule)
is a Newton-Cotes rule for the quadratic interpolation polynomial P2(x). So for Simpson’s
rule we have to use 3 nodes and N = 2.

Newton-Cotes Quadrature Rules
255
We take x0 = a, x1 = (a + b)/2 and x2 = b, and also zi = xi for i = 0, 1, 2. The length
of each interval [xi, xi+1] is h = (b −a)/2. The quadratic Lagrange basis functions given by
the formula (6.6) are
ℓ0(x) =
(x −x1)(x −x2)
(x0 −x1)(x0 −x2),
ℓ1(x) =
(x −x0)(x −x2)
(x1 −x0)(x1 −x2),
ℓ2(x) =
(x −x0)(x −x1)
(x2 −x0)(x2 −x1) .
The integration of these functions is easier if we introduce a variable ξ = x −x1 with origin
at x1. In the new variable, the coordinates of the nodes are ξ0 = −h, ξ1 = 0 and ξ2 = h.
The quadrature weights become
wi =
Z b
a
ℓi(x) dx =
Z h
−h
ℓi(ξ) dξ,
for
i = 0, 1, 2 .
Specifically, we have
w0 =
Z h
−h
(ξ −0)(ξ −h)
(−h)(−2h) dξ =
1
2h2
Z h
−h
(ξ2 −hξ)dξ = h
3 ,
w1 =
Z h
−h
(ξ + h)(ξ −h)
(h)(−h)
dξ = −1
h2
Z h
−h
(ξ2 −h2)dξ = 4h
3 ,
and
w2 =
Z h
−h
(ξ + h)(ξ −0)
(2h)(h)
dξ =
1
2h2
Z h
−h
(ξ2 + hξ)dξ = h
3 .
Thus, Simpson’s rule for the approximation of an integral is
I2[f] =
2
X
i=0
wif(zi) = h
3

f(a) + 4f
a + b
2

+ f(b)

.
Similarly to the trapezoidal rule, Simpson’s rule can be inaccurate if the length h of the
interval [a, b] is large. For this reason, we consider the composite Simpson’s rule by di-
viding the interval [a, b] into smaller intervals and applying Simpson’s rule in each of the
subintervals.
7.2.6
Composite Simpson’s rule
Let N = 2m be an even number. We define h = (b −a)/N and xi = a + ih for i =
0, 1, . . . , N. Because Simpson’s rule has three nodes, we consider the intervals [x2k, x2k+2]
for k = 0, 1, . . . , N
2 −1. Then the integral I[f] can be written as
Z b
a
f(x) dx =
N/2−1
X
k=0
Z x2k+2
x2k
f(x) dx .
We apply Simpson’s rule in the intervals [x0, x2], [x2, x4], . . . , [xN−2, xN] to obtain
Z x2k+2
x2k
f(x) dx ≈h
3 [f(x2k) + 4f(x2k+1) + f(x2k+2)] .
The composite Simpson’s rule is given by the sum
IN[f] =
N/2−1
X
k=0
h
3 [f(x2k) + 4f(x2k+1) + f(x2k+2)]
= h
3 [f(x0) + 4f(x1) + 2f(x2) + 4f(x3) + · · · + 2f(xN−2) + 4f(xN−1) + f(xN)] .

256
Numerical Integration

Note that the composite Simpson’s rule requires N = 2m to be an even number.
The implementation of Simpson’s rule in Python is very similar to the implementation
of the trapezoidal rule. The difference is that the values of the integrant evaluated at the
internal quadrature nodes xi for i = 1, 2, . . . N −1 are multiplied by 2 when i is odd and
by 4 when i is even. For this reason, an implementation of the composite Simpson rule
could compute the two sums in two different for loops. In our implementation we avoid
the use of for loops and we just use a vectorized algorithm. In particular we store all the
values f(xi) in a vector s. We then multiply first all the entries by 2 except for the first
and the last entries (line 6). Then we multiply all the even entries again by 2 so as to form
the coefficients 4 (line 7). Finally we compute the sum and we multiply by h/3 in the last
command of the code.
1
def Simpson(f, a, b, N):
2
# Composite Simpson rule with N subintervals
3
h = (b - a)/float(N)
4
x=np.linspace(a, b, N + 1)
5
s = f(x)
6
s[1:N]=2*s[1:N]
7
s[1:N:2]=2*s[1:N:2]
8
return h/3.0*np.sum(s)
Testing the code for the same integral as in the case of the trapezoidal rule
Z π/2
0
sin(x) dx = 1 ,
using N = 10 intervals we observe that Simpson’s method is more accurate compared to
the trapezoidal rule.
1
f = lambda x: np.sin(x)
2
Simpson(f, 0.0, np.pi/2.0, 10)
1.0000033922209004
The result is correct with 5 decimal digits indicating that the composite Simpson rule
is accurate with error of order h4.
7.2.7
Error of Simpson’s rule
Similar to the trapezoidal rule error, the error of Simpson’s rule will be
E2[f] =
Z b
a
[f(x) −P2(x)] dx ,
where P2 is the unique interpolating polynomial of the function f(x) at the nodes x0 = a,
x1 and x2 = b. Thus,
E2[f] = −1
24
Z b
a
(x −a)

x −a + b
2
2
(b −x) f (4)(ξ(x)) dx ,

Newton-Cotes Quadrature Rules
257
where due to the continuity of the function f (4)(x) we have
E2[f] = −1
24f (4)(ξ1)
Z b
a
(x −a)

x −a + b
2
2
(b −x) dx ,
with ξ1 ∈(a, b). Thus, if f ∈C4[a, b], there is a ξ ∈(a, b) such that
E2[f] = −(b −a)5
24 · 180 f (4)(ξ) .
Working similarly for the composite Simpson’s rule we obtain
EN[f] =
Z b
a
f(x)dx −IN[f]
= −
1
24 · 180

(x2 −x0)5f(4)(ξ0) + (x4 −x2)5f(4)(ξ1) + · · · + (xN −xN−2)5f(4)(ξN/2−1)
	
= −
1
24 · 180(2h)5
N/2−1
X
k=0
f (4)(ξi) = −24h4
24 · 180(2h)
N/2−1
X
k=0
f (4)(ξi)
= −h4
180(Nh) 2
N
N/2−1
X
k=0
f (4)(ξi) = −h4
180(b −a)f (4)(ξ) ,
with ξk ∈(x2k, x2k+2), for k = 0, 1, . . . , N/2 −1. The existence of ξ ∈(a, b) for which
f (4)(ξ) = 2
N
N/2−1
X
k=0
f (4)(ξi) ,
is guaranteed by the intermediate value theorem and the assumption f ∈C4[a, b]. Therefore,
for all f ∈C4[a, b] there is a ξ ∈(a, b) such that
EN[f] = −b −a
180 h4f (4)(ξ) .

Simpson’s rule is fifth order accurate while its composite rule is fourth order.
Interestingly we have gained two orders of accuracy from Trapezoidal rule by in-
creasing the degree of the polynomial only by one degree!
7.2.8
Degree of exactness
The degree of exactness of a quadrature rule IN[f] is the largest degree of polynomial for
which the quadrature rule can integrate without making any error. In other words the degree
of exactness is the integer n such that the quadrature error E[xk] = 0 for all k = 0, 1, . . . , n
and E[xn+1] ̸= 0. Since the integral is a linear operator we conclude that a quadrature rule
of degree of exactness n can integrate exactly (up to the machine precision) polynomials of
maximum degree n.
Obviously the trapezoidal rule has degree of exactness 1. Although Simpson’s rule was
designed to be exact for polynomials of degree 2, it happens to be exact also for polynomials
of degree 3. In order to see this, we compute the errors
E[f] =
Z b
a
f(x) dx −b −a
6

f(a) + 4f
a + b
2

+ f(b)

,

258
Numerical Integration
for f(x) = 1, x, x2 and x3:
E[1] = (b −a) −b −a
6
(1 + 4 + 1) = 0 ,
E[x] = 1
2[x2]b
a −b −a
6

a + 4a + b
2
+ b

= 1
2(b2 −a2) −(b −a)(b + a)
2
= 0 ,
E[x2] = 1
3[x3]b
a −b −a
6

a2 + 4(a + b)2
4
+ b2

= 1
3(b3 −a3) −b −a
3
(a2 + ab + b2)
= 1
3
 b3 −a3 −(a2b + ab2 + b3 −a3 −a2b −ab2)

= 0 ,
E[x3] = 1
4[x4]b
a −b −a
6

a3 + 4(a + b)3
8
+ b3

= 1
4(b4 −a4) −b −a
6

a3 + a3 + 3a3b + 3ab2 + b3
2
+ b3

= 1
4(b4 −a4) −b −a
6
· 3
2(a3 + a2b + ab2 + b3)
= 0 .
The conclusion is implied by the fact that E[1] = E[x] = E[x2] = E[x3] = 0 while E[x4] =
(a −b)5/120 ̸= 0. Thus, the degree of exactness for Simpson’s rule is 3.

The knowledge of the degree of exactness of a quadrature rule helps in choosing
appropriate quadrature for the exact computation of integrals involving polynomials.
7.3
Gaussian Quadrature Rules
Various Newton-Cotes formulas have been derived by integrating interpolating polynomials.
The error term in the interpolating polynomial of degree N involves the (N + 1)-th order
derivative of the function being approximated. So simple Newton-Cotes formulas with N +1
nodes are expected to be exact for polynomials of degree at least N.
In this section we study Gaussian quadrature rules. Gaussian rules have been designed
to be simple and integrate exactly polynomials of degree greater than N. The key ingredient
in Gaussian quadrature is the choice of the quadrature nodes, which are not equally spaced
and do not include the end-points of the integration interval. In the approximation of an
integral using the general quadrature formula
Z b
a
f(x) dx ≈
N
X
i=0
wif(zi) ,
(7.6)
the nodes z0, z1, . . . , zN in the interval [a, b] and coefficients w0, w1, . . . , wN, need to be
chosen appropriately. This means that a quadrature rule can be defined by determining
these 2(N + 1) parameters. The coefficients w0, w1, . . . , wN in the approximation formula

Gaussian Quadrature Rules
259
(7.6) can take any value, and the nodes z0, z1, . . . , zN are restricted only by the fact that
they must lie in the interval of integration [a, b]. We will determine all these parameters
such that the resulting method integrates exactly polynomials of degree 2N + 1. The space
of polynomials of degree 2N + 1 can be generated by the 2(N + 1) monomials xi, for
i = 0, 1, . . . , 2N + 1, and this fact will help us to determine the 2(N + 1) parameters of the
quadrature.
7.3.1
Choice of nodes and weights
For simplicity and convenience we will consider the interval [a, b] = [−1, 1]. Suppose that
we want to approximate the integral
Z 1
−1
f(x) dx ,
using formula (7.6) for N = 1. In this case, we need to determine the weights w0, w1, and
the nodes z0, z1 so that the integration formula w0f(z0) + w1f(z1) is exact whenever f(x)
is a polynomial of degree 2N + 1 = 2 · 1 + 1 = 3 or less. This means that we need
Z 1
−1
f(x) dx = w0f(z0) + w1f(z1) ,
(7.7)
for polynomial functions
f(x) = a0 + a1x + a2x2 + a3x3 ,
for some constants a0, a1, a2 and a3. Due to the linearity of the integral we have
Z  a0 + a1x + a2x2 + a3x3
dx = a0
Z
1 dx + a1
Z
x dx + a2
Z
x2 dx + a3
Z
x3 dx .
Thus, it suffices to show that the quadrature rule is exact when f(x) is 1, x, x2 and x3.
Then the formula will be exact for any linear combination of these monomials. Applying
the quadrature formula (7.7) to these monomials we observe that the parameters w0, w1,
z0, and z1 satisfy the equations
w0 · 1 + w1 · 1 =
Z 1
−1
dx = 2 ,
w0 · z0 + w1 · z1 =
Z 1
−1
x dx = 0 ,
w0 · z2
0 + w1 · z2
1 =
Z 1
−1
x2 dx = 2
3 ,
w0 · z3
0 + w1 · z3
1 =
Z 1
−1
x3 dx = 0 .
Solving the above system of four equations with four unknowns, we find the unique solution
w0 = 1,
w1 = 1,
z0 = −
√
3
3 ,
and
z1 =
√
3
3
.
Substituting into the integral formula (7.7), we obtain the quadrature formula
Z 1
−1
f(x) dx ≈f
 
−
√
3
3
!
+ f
 √
3
3
!
.

260
Numerical Integration
By construction, this quadrature rule is exact for polynomials of degree at most 3 and thus
it has degree of exactness 3.
The question now is whether there is a generic way to determine the nodes and weights of
the Gaussian quadrature for any value of N. In fact, there are many ways to determine the
parameters of Gaussian quadrature. In the next section we present one such method based
on the Legendre polynomials. Because of its construction this quadrature rule is known to
as the Gauss-Legendre quadrature.
7.3.2
Gauss-Legendre quadrature rules
In this section, we present how to find simple quadrature formulas that integrate exactly
polynomials of degree 2N +1. In particular, we consider a special class of methods based on
the Legendre polynomials. Legendre polynomials are named after Adrian-Marie Legendre
(1752–1833) and are solutions to Legendre’s differential equation
d
dx

(1 −x2) d
dxPn(x)

+ n(n + 1)Pn(x) = 0 ,
and they form a basis for the set of polynomials of degree 2N + 1
{P0(x), P1(x), . . . , Pn(x), . . .} .
Legendre polynomials can also be defined recursively by the formula
(n + 1)Pn+1(x) = (2n + 1)xPn(x) −nPn−1(x)
for n = 1, 2, . . . ,
with P0(x) = 1 and P1(x) = x. Their most important property is that they are “orthogonal”
in the sense that
Z 1
−1
Pm(x)Pn(x) dx =
2
2n + 1δmn ,
where
δmn =
 1,
if m = n
0,
if m ̸= n
,
denotes the Kronecker delta.
The first five normalized Legendre polynomials are
P0(x) = 1,
P1(x) = x,
P2(x) = x2 −1
3 ,
P3(x) = x3 −3
5x,
and
P4(x) = x4 −6
7x2 + 3
35 .
The roots of these polynomials are distinct and lie in the interval (−1, 1). Moreover, they
are symmetric around the origin. In our case, the roots of the (N + 1)-th degree Legen-
dre polynomial are taken to be the nodes z0, z1, . . . , zN and these produce the quadrature
formula that is exact for any polynomial of degree at most 2N + 1.
If z0, z1, . . . , zN are the roots of the (N + 1)-th Legendre polynomial PN+1(x), then the
weights wi for i = 0, 1, . . . , N are defined by
wi =
Z 1
−1
N
Y
j=0
j̸=i
x −zj
zi −zj
dx .
(7.8)

Gaussian Quadrature Rules
261
We first show that using these nodes and weights for the Gaussian quadrature the formula
N
X
i=0
wif(zi) ,
is exact for polynomials of degree 2N +1. This fact is summarized in the following theorem:
Theorem 7.1. For any polynomial P(x) of degree at most 2N + 1, we have
Z 1
−1
P(x) dx =
N
X
i=0
wiP(zi) ,
where zi are the roots of the (N + 1)-th Legendre polynomial and the weights wi are given
by (7.8).
Proof. Initially we prove this result for polynomials P(x) of degree less than or equal to
N. The Lagrange polynomial that interpolates the polynomial P(x) at the nodes zi, i =
0, 1, . . . , N is
P(x) =
N
X
i=0
P(zi)ℓi(x) =
N
X
i=0
N
Y
j=0
j̸=i
x −zj
zi −zj
P(zi) .
This representation of the polynomial P(x) using Lagrange polynomial basis functions
is exact due to the uniqueness of the interpolating polynomial. Integrating the last formula
yields
Z 1
−1
P(x) dx =
Z 1
−1


N
X
i=0
N
Y
j=0
j̸=i
x −zj
zi −zj
P(zi)

dx =
N
X
i=0


Z 1
−1
N
Y
j=1
j̸=i
x −zj
zi −zj
dx

P(zi)
=
N
X
i=0
wiP(zi) .
Hence the quadrature is exact for polynomials of degree less than or equal to N.
For polynomials P(x) of degree at least N +1 but less than or equal to 2N +1, the long
division of P(x) by the (N + 1)-th Legendre polynomial PN+1(x) will have quotient Q(x)
and residual R(x) of degree less than or equal to N. This long division can be written as
P(x) = Q(x)PN+1(x) + R(x) ,
and implies that if zi is a root of PN+1(x), then P(zi) = R(zi). Since the degree of the poly-
nomial Q(x) is less than N +1, then the orthogonality property of the Legendre polynomials
implies
Z 1
−1
Q(x)PN+1(x) dx = 0 ,
which means that the integral of P(x) depends only on the residual R(x). On the other
hand, since R(x) is a polynomial of degree less than or equal to N, we have
Z 1
−1
R(x) dx =
N
X
i=0
wiR(zi) .

262
Numerical Integration
TABLE 7.1
Gaussian nodes and weights for N = 0, 1, 2, 3, 4
N
zi
wi
0
0
2
1
±
q
1
3
1
2
±
q
3
5
5
9
0
8
9
3
±
r
3
7 −2
7
q
6
5
18+
√
30
36
±
r
3
7 + 2
7
q
6
5
18−
√
30
36
4
0
128
225
± 1
3
r
5 −2
q
10
7
322+13
√
70
900
± 1
3
r
5 + 2
q
10
7
322−13
√
70
900
So we conclude that
Z 1
−1
P(x) dx =
Z 1
−1
[Q(x)PN+1(x) + R(x)] dx =
Z 1
−1
R(x) dx =
N
X
i=0
wiR(zi)
=
N
X
i=0
wiP(zi) ,
which shows that the Gauss-Legendre quadrature is exact for polynomials of degree at most
2N + 1.
In order to implement the Gauss-Legendre quadrature we need to know the roots of the
Legendre polynomials and the respective weights. These nodes and weights are not easy to
be determined analytically. Table 7.1 presents the nodes and weights of Gauss-Legendre qu-
adrature for N = 1, 2, 3 and 4. For large values of N we usually employ numerical methods
for their computation.
7.3.3
Gaussian quadrature on general intervals
While we developed the Gaussian quadrature in the interval [−1, 1], it is usually required to
approximate integrals over general intervals [a, b]. This can be done by changing the variable
of integration x. Specifically, the general integral
Z b
a
f(x) dx ,
can be transformed into an integral over [−1, 1] by utilizing the change of variables
t = 2x −a −b
b −a
or equivalently
x = b −a
2
t + a + b
2
.

Gaussian Quadrature Rules
263
This change of variable transforms the original integral into
Z b
a
f(x) dx =
Z 1
−1
f
b −a
2
t + a + b
2

· b −a
2
dt .
Approximating the last integral using the Gaussian quadrature gives
Z b
a
f(x) dx ≈b −a
2
N
X
i=0
wif
b −a
2
ti + a + b
2

.
(7.9)

To derive composite Gaussian quadrature formulas we divide the interval [a, b]
into sub-intervals [xi, xi+1] and we apply Gaussian quadrature in each subinterval.
It is worth mentioning that the midpoint rule can be derived as the Gauss-Legendre rule
with N = 0. This is a direct consequence of (7.9) for N = 0, and with values w0 = 2 and
x0 = 0 from the Table 7.1.
An implementation of a Gauss-Legendre quadrature rule with N = 2 can be the follow-
ing:
1
def GaussLegendre3(f, a, b):
2
# Implementation of Gauss-Legendre quadrature with
3
# 3 nodes in general interval [a, b]
4
N = 2
5
# define quadrature weights and nodes
6
w = np.array([5.0/9.0, 8.0/9.0, 5.0/9.0])
7
z = np.array([-np.sqrt(3.0/5.0), 0.0, np.sqrt(3.0/5.0)])
8
# implement formula (7.9)
9
c1 = (b-a)/2.0
10
c2 = (a+b)/2.0
11
s = c1*np.inner(w, f( c1*z + c2 ))
12
return s
In order to test this function we consider the approximation of the integral
Z 1
−1
ex cos x dx ,
using Gauss-Legendre quadrature with N = 3. Doing the computations analytically we have
Z 1
−1
ex cos x dx ≈0.¯5e0.774596692 cos(0.774596692) + 0.¯8 cos 0
+ 0.¯5e−0.774596692 cos(−0.774596692)
= 1.9333904 .
One can evaluate the exact value of the previous integral using integration by parts. In
particular, its exact value is [(1+e2) sin(1)−(1−e2) cos(1)]/2e ≈1.9334214. So the absolute
error of the Gauss-Legendre quadrature in this case is about 3.2 × 10−5. Using our function
we get the following result:

264
Numerical Integration
1
f = lambda x: 0.5*np.exp(x/2.0)*np.cos(x/2.0)
2
GaussLegendre3(f, -2.0, 2.0)
1.9333904692642978
This result agrees with our theoretical computation. If we need to use more nodes and
especially if N ≥4, then we need to approximate the quadrature nodes and weights using
appropriate computational techniques. For example, the quadrature nodes can be approxi-
mated using Newton’s method applied to the Legendre polynomials, while the computation
of the quadrature weights can be implemented using the composite trapezoidal or Simpson
rule.
Approximations of the Gauss-Legendre quadrature nodes and weights can be obtained
in Python using the function leggauss of the module numpy.polynomial.lagendre. The
simple call leggauss(degree) will return two one-dimensional arrays x and y containing
the nodes and weights for the Gauss-Legendre quadrature with N points, respectively. The
parameter degree should be equal to N + 1.
7.3.4
Error analysis of the Gaussian quadrature
The orthogonality property of Legendre polynomials was found to be very useful in the con-
struction of a Gaussian quadrature rule. Here we consider general orthogonal polynomials
of degree at most N + 1 (instead of the Legendre polynomials) and a Gaussian quadrature
rule with N + 1 nodes. In what follows, we estimate the error between the actual integral
and the result of the quadrature. In general, we can derive Gaussian quadrature rules us-
ing any kind of orthogonal polynomials, and thus the proof here applies to every Gaussian
quadrature rule.
Theorem 7.2. Consider a function f ∈C2N+2[a, b] and the quadrature nodes z0, z1, . . . , zN
in [a, b]. Then for the Gaussian quadrature rule
IN[f] =
N
X
i=0
wif(zi) ,
the following error estimate holds true:
I[f] −IN[f] = f (2N+2)(ζ)
(2N + 2)!
Z b
a
Q2(x) dx ,
where
Q(x) =
N
Y
i=0
(x −zi) ,
and ζ ∈(a, b).
Proof. In this proof we will make use of the Hermite interpolation polynomial H2N+1. From
Theorem 6.4 we know that the error between f(x) and its Hermite interpolant H2N+1(x)
at the nodes z0, z1, . . . , zN is
f(x) −H2N+1(x) = f (2N+2)(ξ(x))
(2N + 2)!
Q2(x) .

The Module scipy.integrate
265
Since the Gaussian quadrature with N + 1 nodes is exact for polynomials of degree at most
2N + 1, then
Z b
a
H2N+1 dx = IN[H2N+1] = IN[f] .
The last equality is a consequence of the fact the f(zi) = H2N+1(zi) since H2N+1 interpo-
lates f at zi.
Integrating the error formula between f and H2N+1 we have that
Z b
a
f(x) dx −IN[f] =
Z b
a
[f(x) −H2N+1] dx = f (2N+2)(ζ)
(2N + 2)!
Z b
a
Q2(x) dx .
The last equality follows from the mean value theorem of integral calculus (Theorem 4.6),
and the proof is complete.
This theorem ensures the convergence of the Gaussian quadrature to the correct integral,
in the sense that
lim
N→∞IN[f] =
Z b
a
f(x) dx .
It also indicates that the error in the Gaussian quadrature is proportional to [(2N + 2)!]−1,
which can be remarkably small.
Remark 7.3. All the analysis and the derivations of this chapter can be generalized to the
case of weighted integrals of the form
Z b
a
ω(x)f(x) dx ,
which can be found in various applications.
7.4
The Module scipy.integrate
Each of the quadrature rules we have discussed so far is implemented in the module
scipy.integrate.
7.4.1
Trapezoidal rule
The composite trapezoidal rule is implemented in the module scipy.integrate with the
function trapezoid. The general call of the function trapezoid is the following:
trapezoid(y, x, dx, axis)
where
y:
An array with the values yi = f(xi), i = 0, . . . , N
x:
An array with the nodes xi, i = 0, . . . , N. (Optional with default value None)
dx:
Spacing of quadrature nodes along axis of y only when x=None. (Optional with default
value 1.0)
axis: Axis along which to integrate. (Optional with default value -1)

266
Numerical Integration
For example, we show here the use of the function trapezoid for the integral
Z π/2
0
sin(x) dx .
After we create a grid of N +1 points xi and the values f(xi) we call the function trapezoid
in its simplest form.
1
from scipy.integrate import trapezoid
2
f = lambda x: np.sin(x)
3
x = np.linspace(0.0, np.pi/2.0, 11)
4
y = f(x)
5
print( trapezoid(y,x) )
0.9979429863543573
Observe that the command linspace generates 11 quadrature nodes which means that
N = 10, and the result is identical with our implementation.
7.4.2
Simpson’s rule
Composite Simpson’s rule is implemented in the module scipy.integrate with the function
simpson. This function’s general call is almost the same with that of the function trapezoid
with the difference that in this case, we need to specify how to treat the case, where N is
odd number. The general call of the function simpson is the following:
simpson(y, x, dx, axis, even)
where
y:
An array with the values yi = f(xi), i = 0, . . . , N
x:
An array with the nodes xi, i = 0, . . . , N. (Optional with default value None)
dx:
Spacing of quadrature nodes along axis of y only when x=None. (Optional with default
value 1)
axis: Axis along which to integrate. (Optional with default value -1)
even: A string that specifies how to treat the case if N is not even. It can take the value
’first’ to use Simpson’s rule for the first N −2 intervals and the trapezoidal rule
on the last interval, and ’last’ so as to use trapezoidal rule on the first interval
and Simpson’s rule for the rest of the intervals, and avg to return the average of the
previous two case. (Optional with default value ’avg’)
For example, we present here the use of the function simpson using the same integral
as before
Z π/2
0
sin(x) dx .
After we create a grid of odd number of points xi (N even) and the values f(xi), we call
the function simpson in its simplest form.

The Module scipy.integrate
267
1
from scipy.integrate import simpson
2
f = lambda x: np.sin(x)
3
x = np.linspace(0.0, np.pi/2.0, 11)
4
y = f(x)
5
print( simpson(y,x) )
1.0000033922209006
The result is identical with our implementation, and the accuracy is better than the accuracy
of the trapezoidal rule with the same number of quadrature nodes.
7.4.3
Gaussian quadrature
A Gaussian quadrature rule is implemented in SciPy in the function fixed quad of the
module scipy.integrate. The general call of the function fixed quad is
fixed_quad(func,a,b,args,n)
where func is the integrant, a and b are the integration limits, args is an optional argument
with default value None containing additional arguments needed in the function func, if
any. Finally, the argument n is again optional with default value 5 and is the order of
the quadrature rule (i.e. n= N + 1). The previous example can be implemented using the
function fixed quad in the following way:
1
from scipy.integrate import fixed_quad
2
f = lambda x: 0.5*np.exp(x/2.0)*np.cos(x/2.0)
3
print( fixed_quad(f,-2.0,2.0,n=3) )
(1.9333904692642971, None)
We observe that the function returns the approximate value of the integral (which agrees
with our previous computations) and also a second result (None) which consists of statistical
information if there are any.
SciPy has also general purpose routines that can control the error, such as the functions
quads and quadrature. The function quadrature is an adaptive Gaussian quadrature rule.
The basic call of the function quadrature is
quadrature(func,a,b,args,tol,rtol,maxiter,vec_func,miniter)
where
func: Is the name of the function f(x)
a and b: The end-points of the interval [a, b]
args: Additional arguments and parameters for the functions f. (Optional with default
value args=())
xtol and rtol: The absolute and relevant error tolerances for the termination of the
method. (Options with default value for both tolerances 1.49e −8)
maxiter: The maximum order of Gaussian quadrature. (Optional with default value
maxiter=50)

268
Numerical Integration
FIGURE 7.5
Object moves under the influence of the force f(x).
vec funct: Boolean variable which is True or False if func is a multivariable function.
(Optional with default value vec func=True)
miniter: Is the minimum order of the Gaussian quadrature. (Optional with default value
is miniter)
The function quadrature returns the approximation of the integral and the difference
between the last two estimates. For example, the approximation of the integral
Z 1
−1
ex cos x dx
can be done using the following code
1
from scipy.integrate import quadrature
2
f = lambda x: 0.5*np.exp(x/2.0)*np.cos(x/2.0)
3
print( quadrature(f,-2.0,2.0,tol=1.e-15,maxiter=100) )
(1.933421496299271, 9.692333602373537e-10)
We observe that the last two estimates of the integral differ by an amount of O(10−10).

Adaptive quadrature rules are useful in cases where the integrant function con-
sists of different scales or varies irregularly in different areas of the integration in-
terval.
The module scipy.integrate also contains general purpose functions for the evalua-
tion of definite integrals in one, two and general multiple dimensions. The functions quad,
dblquad, tplquad and nquad can be used for the computation of integrals with one, two,
three or multiple variables respectively.
7.4.4
Application in classical mechanics
Work in physics measures the energy transfer during the motion of an object under the
influence of external force and it is measured in Joules (J) (1 Joule = 1 Newton · meter).
For example, the object in Figure 7.5 changes location x due to a force f(x). The work done
by the force f(x) to move the object from the location x0 to xN is
W =
Z xN
x0
f(x) dx ,
and is practically the area enclosed by the graph of the function f(x), the x-axis and the
lines x = x0 and x = xN. Assume that N = 14. We measure the force applied to the object
of Figure 7.5 at the locations x0, x1, . . . , x15 and we report its magnitude in Table 7.2.

Further Reading
269
TABLE 7.2
The magnitude of the force f(xi) measured in Newtons at the locations xi, i =
0, 1, . . . , 15 measured in meters
xi
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
1.1
1.2
1.3
1.4
f(xi)
0.0
0.45
1.45
2.3
3.1
3.1
3.1
2.5
1.1
1.1
1.1
0.8
0.6
0.3
0.0
The most straightforward way to estimate the work done by such a force is by ap-
proximating the work integral using the composite trapezoidal rule. Here, we employ the
function trapezoid of the module scipy.integrate with quadrature nodes the values xi
for i = 0, 1, . . . , 15.
1
from scipy.integrate import trapezoid
2
import numpy as np
3
4
x = np.arange(0.0,1.5,0.1)
5
y = np.array([0.0, 0.45, 1.45, 2.3, 3.1, 3.1, 3.1,
6
2.5, 1.1, 1.1, 1.1, 0.8, 0.6, 0.3, 0.0])
7
print( trapezoid(y,x) )
2.1
Using the previous code we obtained the result which is 2.1 J. If we want to use different
quadrature nodes, then we must first interpolate the data, and then integrate the inter-
polant. If for example we take the cubic spline interpolant, then we could use Gaussian
quadrature such as the formula (7.7) in each interval. Because the interpolant is a cubic
polynomial in each interval, the result of Gaussian quadrature with at least two nodes will
contain only the interpolation error.
7.5
Further Reading
Numerical quadrature is a topic contained in every textbook related to numerical analysis
[25, 70, 76, 22, 26, 7, 127, 108]. Specialized books on numerical integration includes the
classical book by Davis and Rabinowitz [30], and other more recent books such as [14, 38].
A specialized book on Gaussian quadrature is [131]. Modern computer codes for adaptive
quadrature rules are usually based on the techniques described in [101]. An interesting
book, especially for postgraduate students, is that by Stewart [124], which is structured in
individual lectures.

Chapter Highlights
 Quadrature or numerical integration is the approximation of integrals by finite
sums of the form
Z b
a
f(x) dx ≈
N
X
i=0
wif(zi) ,
where zi are called quadrature nodes and wi weights.
 The simplest quadrature rule is the midpoint method with N = 0, wi = b −a
and zi = (a + b)/2.
 Composite quadrature rules are obtained if we divide the integration domain
into multiple subintervals and apply the respective quadrature rule in each of
these subintervals.
 The weights and nodes of the composite midpoint rule given a grid
a = x0 < x1 < · · · < xN = b are defined as zi = (xi + xi+1)/2 and
wi = xi+1 −xi, respectively.
 Newton-Cotes quadrature rules come from the integration of an interpolating
polynomial of f at the N + 1 nodes xi, i = 0, 1, . . . , N. When N = 1 the
method is called trapezoidal rule, and when N = 2 Simpson’s rule.
 The error of the trapezoidal rule is O(h3) and the respective error of Simpson’s
rule is O(h5) with h = b −a. The composite rules have errors of order one less
than the simple rules.
 The estimation of the discretization error in a numerical method can provide a
proof of its convergence.
 Composite Simpson’s rule requires N = 2m to be even number.
 The degree of exactness is the largest degree of polynomial for which the
quadrature rule can integrate exactly.
 The degree of exactness of Newton-Cotes rules with N + 1 nodes is at least N.
 Gaussian quadrature rules with N + 1 nodes have degree of exactness 2N + 1,
and error O([(2N + 2)!]−1).
 Gauss-Legendre rule employs the N + 1 zeros of the (N + 1)-th Legendre
polynomial z0, z1, . . . , zN as nodes and weights given by the formula (7.8).
 The midpoint rule can be considered as a Gauss-Legendre rule with N = 0.
Thus, it has degree of exactness 1.
 Usually the nodes and weights of Gauss-Legendre rule are computed
numerically.
 The module scipy.integrate contains the implementation of all classical
quadrature rules as well as general purpose automatic integration routines.
270

Exercises
1. Consider the integrals
I1 =
Z 1
0
x2 dx,
I2 =
Z 1
0
x2e−x dx,
and
I3 =
Z e+1
e
1
x ln x dx .
(a) Compute approximations (without the help of Python) of the following integrals
using the Midpoint, Trapezoidal and Simpson rules.
(b) Compute the exact values of the integral I1, I2 and I3.
(c) In each case estimate the errors between your approximations and the exact values,
and compare with the formula of Section 7.2.2.
(d) Verify the results using appropriate Python functions.
2. Consider the integral
I[f] =
Z b
a
f(x) dx .
(a) Using Lagrange polynomial interpolation on appropriate grids derive the follow-
ing Newton-Cotes-type quadrature rules known to as Adams-Bashforth-Moulton
quadrature formulas:
Q1[f] = h
24[55f(a) −59f(a −h) + 37f(a −2h) −9f(a −3h)] ,
Q2[f] = h
24[9f(a + h) + 19f(a) −5f(a −h) + f(a −2h)] .
(b) Write Python programs to implement the quadrature rules Q1 and Q2.
(c) Estimate experimentally the degree of exactness of these formulas.
(d) Describe their advantages and disadvantages compared to other Newton-Cotes
methods.
(e) Use these formulas to estimate the integrals of Problem 1.
3. Write a Python function with name midpointquad and arguments as in the following
code to implement the composite midpoint rule:
def midpointquad(func, a, b, n):
# quad = midpointquad(func, a, b, n)
# comments
return quad
where func indicates the name of a function, a and b are the lower and upper limits of
integration, and n is the number of points (not the number of intervals).
(a) Debug your midpointquad routine by computing the integral
R 1
0 2x dx = 1. Even
if you use only one interval (n=2) you should get the exact answer because the
midpoint rule integrates linear functions exactly.
271

(b) Use your midpoint routine to estimate the integral of Runge’s function, f(x) =
1/(1 + x2) over the interval [−5, 5]. The exact answer is 2 arctan(5). Fill in the
following table, using scientific notation for the error values so you can see the
pattern.
n
h
Midpoint Result
Error
11
1.0
101
0.1
1001
0.01
10001
0.001
(c) Estimate experimentally the order of accuracy (an integer power of h). This can be
done by the errors and the values of h of the previous question.
(d) Study the degree of exactness of the midpoint rule by computing the integrals of
the following polynomials using the single interval [0, 1] and n = 2.
func
Midpoint Result
Error
1
2x
3x2
4x3
(e) For some methods, but not all, the degree of exactness is one less than the order of
accuracy. Is that the case for the midpoint rule?
4. Implement the trapezoidal and Simpson’s rules and repeat the study of the previous
problem.
5. Implement the Gauss-Legendre Quadrature rule with N nodes. For the computation of
the quadrature nodes and weights of the Gauss-Legendre quadrature rule use the Python
function leggauss of the module numpy.polynomial.legendre.
(a) Debug your function by showing that its exactness is at least 1 for N = 1 using the
integral
R 1
0 2x dx = 1.
(b) Fill in the following table by computing with your code the integrals over [0, 1] of
the indicated integrands.
f
Error for N = 2
Error for N = 3
3x2
4x3
5x4
6x5
7x6
Degree
(c) Compute accuracy estimates of the integral of Runge’s function in the interval
[−5, 5]. Recall that the exact answer is 2 arctan(5). Fill in the following table with
the computed errors:
N
Gauss-Legendre Result
Error
3
7
11
15
6. Consider the (rectangular) quadrature rule defined for any f ∈C[a, b] by
I[f] = (b −a)f(a) ,
272

with error
E[f] =
Z b
a
f(x) dx −I[f] .
(a) Prove that the quadrature rule I[f] integrates exactly polynomials of degree 0. In
other words prove that E[p] = 0 for all p ∈P0.
(b) Prove that for f ∈C1[a, b] there is a ξ ∈(a, b) such that
E[f] = (b −a)2
2
f ′(ξ) .
(c) Let N ∈N, h = (b−a)/N and xi = a+ih, i = 0, 1, . . . , N. Prove that for f ∈C1[a, b]
there is a ξ ∈(a, b) such that
Z b
a
f(x) dx −
N−1
X
i=0
f(xi) = b −a
2
hf ′(ξ) .
7. Let f ∈C1[a, b]. Consider the quadrature rule
I[f] = (b −a)f(a) + (b −a)2
2
f ′(a) ,
with error
E[f] =
Z b
a
f(x) dx −I[f] .
(a) Prove that the quadrature rule I[f] integrates exactly polynomials of degree less
than or equal to 1. In other words prove that E[p] = 0 for all p ∈P1.
(b) Prove that for f ∈C2[a, b] there is a ξ ∈(a, b) such that
E[f] = (b −a)3
6
f ′′(ξ) .
(c) If N ∈N, h = (b−a)/N and xi = a+ih, i = 0, 1, . . . , N. Prove that for f ∈C2[a, b]
there is a ξ ∈(a, b) such that
Z b
a
f(x) dx −
N−1
X
i=0

hf(xi) + h2
2 f ′(xi)

= b −a
6
h2f ′′(ξ) .
8. Consider a function f on [a, b] and a partition {x0, x1, x2} such that x0 = a, x1 = a + h
and x2 = b with h = (b −a)/3. We approximate the integral
Z b
a
f(x) dx ,
using the quadrature rule defined by
I[f] = 9
4hf(x1) + 3
4hf(x2) .
(a) Find the degree of exactness of I[f].
(b) Apply this formula to estimate the integral
Z 1
0
x2e−x dx .
273

(c) Estimate the error between the numerical and the exact solution and compare with
Simpson’s rule.
9. Consider f ∈C1[a, b] and a uniform grid of nodes xi, i = 0, 1, . . . , N. Define the composite
quadrature rule
IN[f] = h
"
1
2f(x0) +
N−1
X
i=1
f(xi) + 1
2f(xN)
#
−h2
12 [f ′(xN) −f ′(x0)] ,
with h = (b −a)/N.
(a) Derive a quadrature rule with one interval which applied to each interval [xi, xi+1]
leads to the composite rule IN[f].
(b) Prove that for f ∈C4[a, b] there is ξ ∈(a, b) such that
Z b
a
f(x) dx −IN[f] = b −a
720 h4f (4)(ξ) .
10. Gaussian quadrature can be used to approximate integrals of functions that suffer from
singularities at the endpoints of the integration domain. Verify that Gaussian quadrature
can compute the following singular integrals
(a)
R 1
0
log(1−x)
x
dx = −π2
6 ,
(b)
R 1
0
log(1+x)
x
dx = −π2
12 ,
(c)
R 1
0
log(1+x2)
x
dx = −π2
24 .
11. A car is traveling on a straight road for 20sec with speeds recorded at the time instances
t0, t1, . . . , tN as in the following table:
ti
0.0
4.5
6.1
8.4
10.0
12.7
15.3
17.2
18.8
20.0
v(ti)
0.0
12.0
31.3
55.1
51.0
45.2
23.2
12.6
5.8
0.0
The speeds v(ti) are in km/h while the times ti in seconds.
(a) Determine the distance covered by the car using the data of the previous table.
(b) Determine the average speed of the car.
(c) Compute a cubic spline interpolant and use it to find the total distance covered by
the car. Employ adaptive quadrature.
274

8
Numerical Differentiation and Applications to
Differential Equations
There are many numerical methods as well as applications that rely on the approxima-
tion of derivatives. For example, the Secant method required the approximation of the first
derivative for the approximation of roots of functions. Approximation of derivatives is of
significant importance also for the derivation of efficient methods for the numerical solution
of differential equations. In this chapter, we turn our attention to the numerical approxima-
tion of derivatives in a systematic way. We also discuss applications of the approximation
of solutions of ordinary differential equations. We close this chapter with an application in
epidemiology.
8.1
Numerical Differentiation
Recall that the derivative can be defined by any of the following limits
f ′(x0) = lim
x→x0
f(x) −f(x0)
x −x0
,
f ′(x0) = lim
h→0
f(x0 + h) −f(x0)
h
,
f ′(x0) = lim
h→0
f(x0) −f(x0 −h)
h
.
Using these limits we can obtain even more formulas for the first derivative. For example,
adding the last two limits and dividing by 2 we obtain the formula
f ′(x0) = lim
h→0
f(x0 + h) −f(x0 −h)
2h
.
The derivative f ′(x0) is the slope of the tangent line of f(x) passing through the point
(x0, f(x0)). Each limit in the previous definitions of the first derivative is the limit of the
slope of a secant as h →0. Since the derivative f ′(x0) is a limit of approximating secant
slopes, a first way to find an approximation for f ′(x0) is to choose a small value for the
parameter h and evaluate the fraction without the limit for the particular value of h.
8.1.1
First-order accurate finite difference approximations
In the formula
f ′(x0) = lim
h→0
f(x0 + h) −f(x0)
h
,
DOI: 10.1201/9781003287292-8
275

276
Numerical Differentiation and Applications to Differential Equations
FIGURE 8.1
Finite difference approximations of the first derivative.
we take h to be sufficiently small that x0 + h ≈x0. For such h we expect that
f ′(x0) ≈f(x0 + h) −f(x0)
h
.
This difference quotient is known to as the forward finite difference approximation of the
derivative f ′(x0) and is denoted by
Dff(x0) = f(x0 + h) −f(x0)
h
.
(8.1)
This is the slope of the secant crossing the graph of f at the points (x0, f(x0)) and (x0 +
h, f(x0 + h)) and is presented in Figure 8.1.
For example, consider the function f(x) = x sin(x) and assume that we want to find an
approximation of the derivative f ′(π/2). The derivative of f(x) is f ′(x) = sin(x)+x cos(x),
and thus f ′(π/2) = 1. We approximate this derivative using the formula (8.1) with h = 0.01
and x0 = π/2. This can be implemented in Python in the following way:
1
def f(x):
2
y = x*np.sin(x)
3
return y
4
x0 = np.pi/2
5
h = 0.01
6
# approximation of the derivative using (8.1)
7
derivative = ( f(x0+h) - f(x0) ) / h
8
print('df(x) =',derivative, 'Error =',np.abs(derivative-1.0))
df(x) = 0.992096084232319 Error = 0.007903915767681013
Our first observation is that the discretization error should be O(h): Using h = 0.01 we
obtain an approximation of the derivative with two decimal digits correct f ′(x0) ≈0.99.
This is an indication of first order convergence rate. By taking smaller values of h we can
achieve better accuracy.
Similarly, fixing 0 < h < 1 in the limit
f ′(x0) = lim
h→0
f(x0) −f(x0 −h)
h
,
we obtain the finite difference approximation
f ′(x0) ≈f(x0) −f(x0 −h)
h
.

Numerical Differentiation
277
This approximation is called backward difference approximation and it is denoted by
Dbf(x0) = f(x0) −f(x0 −h)
h
.
(8.2)
This formula can be implemented with the following simple code
1
x0 = np.pi/2
2
h = 0.01
3
# approximation of the derivative using (8.2)
4
derivative = ( f(x0) - f(x0-h) ) / h
5
print('df(x) =',derivative, 'Error =',np.abs(derivative-1.0))
df(x) = 1.0078039166010244 Error = 0.007803916601024419
This result has the same accuracy as the forward finite difference approximation indicating
that the backward finite difference approximation is again first-order accurate.
8.1.2
Second-order accurate finite difference approximations
Consider the following formulas for the first derivative
f ′(x0) = lim
h→0
f(x0 + h) −f(x0)
h
and
f ′(x0) = lim
h→0
f(x0) −f(x0 −h)
h
.
Adding these two expression we get
2f ′(x0) = lim
h→0
f(x0 + h) −f(x0 −h)
h
,
and dividing by 2 yields
f ′(x0) = lim
h→0
f(x0 + h) −f(x0 −h)
2h
.
Taking 0 < h < 1 we obtain the central finite difference approximation
f ′(x0) ≈f(x0 + h) −f(x0 −h)
2h
.
This approximation of the first derivative will be denoted by
Dcf(x0) = f(x0 + h) −f(x0 −h)
2h
.
An implementation of the central finite difference approximation in Python for the same
f as before can be the following
1
x0 = np.pi/2
2
h = 0.01
3
derivative = (f(x0+h) - f(x0-h))/(2.0*h)
4
print('df(x) =',derivative, 'Error =',np.abs(derivative-1.0))
df(x) = 0.9999500004166717 Error = 4.999958332829735e-05

278
Numerical Differentiation and Applications to Differential Equations
Observe here that contrary to the forward and backward finite differences, the central
finite difference approximation is more accurate; the error is O(h2) since it has four digits
correct.

Forward and backward differences to the first derivative are first-order accurate,
while the central difference approximation has order of accuracy 2.
8.1.3
Error estimation
In order to derive finite difference formulas in rigorous way and at the same time estimate
their accuracy1 we use Taylor polynomials.
Forward finite difference approximation
Suppose that f has bounded second derivative and 0 < h < 1 is fixed. We consider the
first-order Taylor expansion
f(x0 + h) = f(x0) + hf ′(x0) + h2
2! f ′′(c) ,
where c ∈(x0, x0 + h). Solving for the first derivative we obtain
f ′(x0) = f(x0 + h) −f(x0)
h
+ h
2 f ′′(c) .
Let |f ′′(c)| ≤2C for some constant C > 0, then
f ′(x0) = f(x0 + h) −f(x0)
h
+ O(h) .
(8.3)
Discarding the terms of O(h) we obtain the forward difference approximation
Dff(x0) = f(x0 + h) −f(x0)
h
.
Rearranging (8.3) we deduce that there is a constant C > 0 such that
|f ′(x0) −Dff(x0)| ≤Ch .
This means that the forward finite difference formula has first-order convergence rate O(h),
and if we take the limit h →0, then the approximation Dff(x0) →f ′(x0) linearly.
Backward finite difference approximation
Similarly, for the derivation of the backward finite difference formula and the estimation of
its convergence rate we consider the Taylor polynomial
f(x0 −h) = f(x0) −hf ′(x0) + h2
2! f ′′(c) ,
1Numerical accuracy and convergence rate are equivalent notions.

Numerical Differentiation
279
where c ∈(x0 −h, x0). Solving again for the first derivative we obtain
f ′(x0) = f(x0) −f(x0 −h)
h
+ h
2 f ′′(c) ,
or in other words
f ′(x0) = Dbf(x0) + O(h) .
This means that
|f ′(x0) −Dbf(x0)| ≤Ch ,
for some C > 0, and thus the convergence is linear in this case as well.
Central finite difference approximation
In order to derive a second-order finite difference approximation to f ′(x0) we consider the
following second-order Taylor expansions
f(x0 + h) = f(x0) + hf ′(x0) + h2
2! f ′′(x0) + h3
3! f ′′′(c1) ,
and
f(x0 −h) = f(x0) −hf ′(x0) + h2
2! f ′′(x0) −h3
3! f ′′′(c2) ,
where c1, c2 in the intervals (x0, x0 +h) and (x0 −h, x0), respectively. We can now eliminate
the second derivatives by subtracting the two Taylor polynomials to obtain
f(x0 + h) −f(x0 −h) = 2hf ′(x0) + h3
6 (f ′′′(c1) + f ′′′(c2)) .
Solving for the first derivative we obtain
f ′(x0) = f(x0 + h) −f(x0 −h)
2h
+ h2
3 (f ′′′(c1) + f ′′′(c2)) .
Let |f ′′′(x)| ≤3C/2 for some positive constant C > 0 and for all x in the domain of f.
Then,
f ′(x0) = f(x0 + h) −f(x0 −h)
2h
+ O(h2) .
This means that absolute error is
|f ′(x0) −Dcf(x0)| ≤Ch2 ,
for some C > 0, and the convergence is quadratic.
8.1.4
Approximation of second-order derivatives
In order to approximate high-order derivatives by finite differences, we follow the exact
same procedure as in the case of first derivatives. Suppose that we want to approximate the
second derivative f ′′(x0). We consider the following third-order Taylor polynomials
f(x0 + h) = f(x0) + hf ′(x0) + h2
2! f ′′(x0) + h3
3! f ′′′(x) + h4
4! f (4)(c1) ,
and
f(x0 −h) = f(x0) −hf ′(x0) + h2
2! f ′′(x0) −h3
3! f ′′′(x) + h4
4! f (4)(c2) ,

280
Numerical Differentiation and Applications to Differential Equations
where c1, c2 in the intervals (x0, x0 + h) and (x0 −h, x0). Since we want to find the second
derivative, we add these Taylor expansions to simplify the first and third derivatives
f(x0 + h) + f(x0 −h) = 2f(x0) + h2f ′′(x0) + h4
24(f (4)(c1) + f (4)(c2)) .
Solving the last relationship for f ′′(x0) we have
f ′′(x0) = f(x0 + h) −2f(x0) + f(x0 −h)
h2
−h2
24(f (4)(c1) + f (4)(c2)) .
Let |f (4)(x)| ≤12C for some constant C > 0. Thus,
f ′′(x0) = f(x0 + h) −2f(x0) + f(x0 −h)
h2
+ O(h2) .
The particular finite difference approximation is denoted by D2 and
D2f(x0) = f(x0 + h) −2f(x0) + f(x0 −h)
h2
.
We conclude that there is C > 0 such that
|f ′′(x0) −D2f(x)| < Ch2 ,
and thus D2f(x0) is 2nd order accurate.
As an example we consider the function f(x) = x sin(x) and x0 = π/2. Now f ′′(x) =
2 cos(x) −x sin(x) which implies f ′′(π/2) = −π/2. An implementation in Python could be
1
x0 = np.pi/2
2
h = 0.01
3
d2f = (f(x0+h) - 2.0*f(x0) + f(x0-h))/(h**2)
4
print('d2f(x) =',derivative2, 'Error =',np.abs(d2f-(-np.pi/2)))
d2f(x) = -1.5707832368705432 Error = 1.3089924353337778e-05
In this example we see once again that the practice can verify the theory since for
h = 0.01 we get an error of O(h2).

Finite difference approximations of any order and for any derivative can be
obtained using appropriate combinations of Taylor expansions.
8.1.5
Richardson’s extrapolation
We can derive high-order, accurate approximations of the derivatives using high-order Taylor
polynomials, like in the case of central finite difference formula for the first derivative.
On the other hand, there is a general methodology that can improve the accuracy of an
approximation. This methodology is known to as the Richardson extrapolation.
Assume that we want to compute a quantity D and d(h) is an approximation of D with
error E(h),
D = d(h) + E(h) .

Numerical Differentiation
281
The error function is expected to be E(h) = Chp for some power p. For example, if D =
f ′(x0) and d(h) = (f(x0 + h) −f(x0))/h, then E(h) = Ch for some constant C.
The idea of Richardson’s extrapolation is based on the elimination of the error E(h) by
taking two different values of the parameter h, namely h1 and h2. Then we have
D = d(h1) + Chp
1 ,
and
D = d(h2) + Chp
2 ,
where we included the error terms to obtain the exact value of the quantity D. Eliminating
the constant C we obtain a new formula for the quantity D
D = (h1/h2)pd(h2) −d(h1)
(h1/h2)p −1
,
which is exact, and if we take for simplicity h2 = h1/2 we obtain
D = 2pd(h1/2) −d(h1)
2p −1
.
In the case of forward finite differences with p = 1, h1 = h and h2 = h/2 we have
d(h/2) = f(x0 + h/2) −f(x0)
h/2
,
and therefore
D = f ′(x0) ≈
2 f(x0+h/2)−f(x0)
h/2
−f(x0+h)−f(x0)
h
2 −1
= 4f(x0 + h/2) −f(x0 + h) −3f(x0)
h
.
Implementing the Richardson extrapolation for the forward difference approximation of
the first derivative in Python we can estimate the error of the new method.
1
x0 = np.pi/2
2
h = 0.01
3
d1 = (f(x0+h) - f(x0))/h
4
d2 = (f(x0+h/2.0) - f(x0))/(h/2.0)
5
derivative = 2.0*d2-d1
6
print('df(x) =',derivative, 'Error =',np.abs(derivative-1.0))
df(x) = 1.000024950548184 Error = 2.4950548183966248e-05
We observe that the result has been improved, and practically we approximated the
derivative with second-order accuracy. On the other hand, we didn’t obtain the exact value
of the derivative. The reason is that the error E(h) is not exactly Chp but |E(h)| ≤Chp.
More precisely, the error is E(h) = c1hp + c2hp+1 + · · · . Richardson’s extrapolation method
eliminates only the error term c1hp while the rest of the terms remain intact. For this reason,
the error after proceeding with Richardson’s extrapolation is expected to be O(hp+1). To
verify the inequality in the error formula, estimate numerically the error of the forward,
backward and central finite differences for the function f(x) = sin(x) and x = π.

282
Numerical Differentiation and Applications to Differential Equations

Richardson extrapolation can improve the accuracy of numerical methods. We
saw how we can improve finite difference formulas but one can repeat the same
procedure to improve quadrature formulas too. The resulting quadrature formulas
are called Romberg integration formulas.
8.2
Applications to Ordinary Differential Equations
In this section we introduce fundamental techniques for the numerical approximation of
solutions of ordinary differential equations. Ordinary differential equations are equations
where the unknowns are functions and the equations themselves contain derivatives of the
unknown functions. One idea is to employ finite difference methods to transform differential
equations into algebraic equations which can be solved numerically.
8.2.1
First-order ordinary differential equations
Because this section serves as an introduction to the numerical solution of differential equa-
tions we consider only first-order scalar differential equations posed in a finite interval.
Moreover, we consider initial values of the unknown quantities that serve as current states
of the problem described by the differential equation. This is because differential equations
are the manifestation of deterministic problems and, given the current state of a physical
system, we should be able to determine uniquely any future state of the system by solv-
ing the corresponding differential equations. An ordinary differential equation along with
appropriate initial values is called initial value problem.
A general initial value problem for first-order ordinary differential equations can be
written as
d
dty(t) = f(t, y(t)),
a ≤t ≤b,
y(a) = y0 ,
(8.4)
where the independent variable is denoted by t since it usually represents time. It is reason-
able to assume that we know the initial value2 of the unknown quantity y(t) at the present
time y(a) = y0, and that we want to predict its value in latter time.

The major difficulty in solving ordinary differential equations is the presence of
the derivative of the unknown function. We will try to eliminate this derivative, and
approximate the continuous problem with a discrete.
The function f(t, y) is a function of two independent variables and is very important
for the solution of the problem. The regularity of this function specifies the solvability and
usefulness of the initial value problem. Specifically, it is meaningful to solve initial value
problems that have a unique solution, in the interval [a, b]. If the initial value problem has
no solution, then there is no point in searching for approximate solutions; or if the solution
is not unique, then we will not be able to speak with great certainty about any future
prediction. For problems with a unique solution given some initial data we say that are
well-posed in the Hadamard sense or that respect Newton’s principle of determinacy.
2This can be an actual measurement.

Applications to Ordinary Differential Equations
283
We know from the theory of ordinary differential equations that if f(t, y) is continuous,
f ∈C([a, b] × R) and satisfies a Lipschitz condition in terms of y uniformly in t, then for
any given initial value y0 ∈R the initial value problem (8.4) has a unique solution.
The Lipschitz condition is perhaps something that can generate some difficulties if you
are not familiar with the definition. In Section 4.2 we saw that a function f satisfies a
Lipschitz conditions if there is a constant L ≥0 such that for all t ∈[a, b] and y1, y2 ∈R
then |f(t, y1) −f(t, y2)| ≤L|y1 −y2|. This condition is satisfied by differentiable functions
with bounded derivative. For example, any function f(t, y) with
 ∂
∂yf(t, y)
 ≤M satisfies a
Lipschitz condition with L = M. In this book, we will consider smooth enough functions
such that the respective initial value problem can be solved uniquely, and the focus will be
on the numerical discretization of the differential equations. For more information on the
theory of ordinary differential equations, we refer to [11].
8.2.2
Euler method
The Euler method is perhaps the simplest numerical method for the solution of initial value
problems of first-order ordinary differential equations studied by Leonard Euler (1707–1783).
Assume that we are looking for approximations to the solution y(t) of the initial-value
problem
d
dty(t) = f(t, y(t)),
a ≤t ≤b,
y(a) = y0 .
The function y(t) is a differentiable function, obviously, since the differential equation in-
volves its first derivative. This means that y(t) is smooth and is defined for all values of
t ∈[a, b]. To simplify the problem, we try to find approximations to y(t) not for every value
of t ∈[a, b] but for a finite (discrete) set of nodes t0, t1, . . . , tN in the interval [a, b]. These
nodes are known as grid points or mesh points. Once the approximate solution is obtained
at the grid points, we can estimate the solution at any node other than ti via interpolation.
Setup of a uniform mesh
We first make the assumption that the grid points a = t0 < t1 < · · · < tN = b are distributed
uniformly throughout the interval [a, b]. This condition is ensured by choosing a positive
integer N and selecting the common distance between the nodes to be
h = b −a
N
= ti+1 −ti .
This distance is called stepsize or timestep. The grid points then can be given by the formula
ti = a + i · h,
for each i = 0, 1, 2, . . . , N .
Discretization of the differential equation
The main difficulty when solving differential equations is that these equations contain deriva-
tives of the unknown function y(t). In the particular case of a first-order differential equation
we only have a first derivative. For example, let’s say that we take the differential equation
at the node ti,
d
dty(ti) = f(ti, y(ti)) .
(8.5)
We simplify the problem by substituting the derivative dy(ti)/dt with an approximation at
ti using forward finite differences
d
dty(ti) ≈y(ti+1) −y(ti)
ti+1 −ti
= y(ti+1) −y(ti)
h
.

284
Numerical Differentiation and Applications to Differential Equations
Substituting the previous approximation of the derivative into the differential equation (8.5)
leads to the algebraic approximation
y(ti+1) −y(ti)
h
≈f(ti, y(ti)) .
For i = 0 we have that y(t1) ≈y0 + hf(t0, y0). Let us denote
y1 = y0 + hf(t0, y0) ,
so we have y(t1) ≈y1 and
y1 −y0
h
= f(t0, y0) .
We will denote the approximation of the value y(ti) by yi ≈y(ti). Suppose that we have
computed the approximation yi for some i > 0. The next step is to find the new approxi-
mation yi+1 ≈y(ti+1). The previous approximations suggest that the ordinary differential
equation at t = ti can be approximated by the finite difference formula
yi+1 −yi
h
= f(ti, yi) .
(8.6)
Thus, the solution at the next step y(ti+1) ≈yi+1 can be obtained by solving (8.6) with
respect to yi+1
yi+1 = yi + hf(ti, yi),
for i = 0, 1, . . . , N −1 ,
y0 = given .
(8.7)
This forms an algorithm for the approximations yi ≈y(ti), i = 1, 2, . . . , N. Given now the
initial condition y(t0) = y0, we can compute the approximation of y(t1)
y(t1) ≈y1 = y0 + hf(t0, y0) ,
and then given y1 we can compute the approximation of y(t2)
y(t2) ≈y2 = y1 + hf(t1, y1) ,
and so on. In this way we compute the approximations y0, y1, . . . , yN at the grid points
t0, t1, . . . , tN, respectively. This method of finding approximations to the solution y(t) using
the formula yi+1 = yi + hf(ti, yi) is known to as the Euler method.
As an example, we apply Euler’s method to approximate the solution of the initial value
problem
y′ = y,
0 ≤t ≤2,
y(0) = 1 ,
at t = 2 with stepsize h = 0.5. In this problem f(t, y) = y. When the function f does not
depend explicitly on t, like this case here, we say that the ordinary differential equation
is autonomous. Euler’s method for the specific initial value problem is written as yi+1 =
yi + hf(ti, yi) = yi + hyi or better yi+1 = 1.5yi for i = 0, 1, . . . N with N = 2/0.5 = 4. So,
given the initial condition y(0) = y0 = 1 we have
y(0.5) ≈y1 = 1.5y0 = 1.5 · 1 = 1.5,
y(1) ≈y2 = 1.5y1 = 2.25
y(1.5) ≈y3 = 1.5y2 = 3.375,
y(2) ≈y4 = 1.5y3 = 5.0625 .
It is easy to verify that the exact solution to this problem is y(t) = et. So the exact solution
at t = 2 is y(2) ≈7.389 while the value we found using Euler’s method is 5.0625. Our
approximation obviously is not accurate but this is the tribute we pay for using such a
large stepsize h = 0.5. With the help of a computer we can take much smaller stepsize h

Applications to Ordinary Differential Equations
285
and obtain more accurate approximations. We proceed with an implementation of Euler’s
method. We define the function f(t,y) for the function f(t, y) and also the function euler
that implements Euler’s method with input arguments the time instances ti, i = 0, 1, . . . , N
in a vector t, the function f and the initial condition y0. The function euler returns the
solution vector y with the approximation of the solution at the time instances ti.
1
def f(t, y):
2
return y
3
def euler(t, f, y0):
4
n = len(t)
5
y = np.zeros(n)
6
h = (t[-1]-t[0])/(n-1)
7
y[0]=y0
8
for i in range(n-1):
9
y[i+1] = y[i]+h*f(t[i], y[i])
10
return y
11
a = 0.0; b = 2.0; N = 20
12
t = np.linspace(a, b, N+1)
13
y0 = 1.0
14
y = euler(t,f,y0)
15
# Plot the results
16
fig = plt.figure()
17
axes = fig.add_subplot(1, 1, 1)
18
axes.plot(t, y, '-o', label="Euler")
19
axes.plot(t, np.exp(t), '-d', label="Exact solution")
20
axes.set_xlabel("t"); axes.set_ylabel("y"); axes.legend(loc=2); plt.show()
0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
2.00
t
1
2
3
4
5
6
7
y
Euler
Exact solution
In this code we took N = 20 nodes. We observe that the value y(2) is approximated
better now with the value y20 = 6.7275. By taking N = 200 we obtain even better results.
In the graph produced by MatPlotLib we observe that the error in the approximations of
yi increases with the time ti. There is a simple explanation behind this phenomenon which
we explain below.
To interpret Euler’s method geometrically note that for the first step
y1 = y0 + hy′(t0) ,

286
Numerical Differentiation and Applications to Differential Equations
FIGURE 8.2
Computation of the approximations yi on the tangent lines to y(ti) translated to the points
(ti, yi).
since f(t0, y0) = f(t0, y(t0)) = y′(t0). This means that y1 lies on the tangent line of y at t0.
Continuing like that, the value yi+1 lies on the tangent line at ti but translated to the point
(ti, yi). And so, the distance between yi and y(ti+1) is increasing with t as it is depicted in
Figure 8.2.
8.2.3
Alternative derivation and error estimates
Following the same methodology for the derivation of Euler’s method as in the derivation
of finite difference approximations of derivatives, we estimate the error and also show the
convergence of the numerical solution as the stepsize h tends to 0.
Suppose that y(t) is the unique solution of the initial-value problem
d
dty(t) = f(t, y),
a ≤t ≤b,
y(a) = y0 .
Moreover, assume that y ∈C2[a, b]. Then the Taylor expansion of the solution y(ti+1)
around ti for each i = 0, 1, 2, . . . , N −1 is
y(ti+1) = y(ti) + (ti+1 −ti)y′(ti) + (ti+1 −ti)2
2
y′′(ξi) ,
for some ξi ∈(ti, ti+1). Because h = ti+1 −ti, we have
y(ti+1) = y(ti) + hy′(ti) + h2
2 y′′(ξi) .
(8.8)
Discarding the residual of Taylor’s polynomial and denoting the approximation yi ≈y(ti)
we define
yi+1 = yi + hf(ti, yi)
for i = 0, 1, . . . , N −1 ,
(8.9)
where y0 is the given initial value y(t0).

Applications to Ordinary Differential Equations
287
Local truncation error (or one-step error)
Local truncation error is the error in the computation of the numerical solution yi+1 at
ti+1 as if the solution at the previous step ti was known and equal to the exact solution
yi = y(ti). We denote the local truncation error of the i-th step with τi.
Suppose that y(ti) is given, then the approximation of y(ti+1) by yi+1 with Euler’s
method is
yi+1 = y(ti) + h · f(ti, y(ti)) .
(8.10)
The local truncation error is defined as
τi = y(ti+1) −yi+1 ,
(8.11)
where yi+1 is defined recursively by (8.9). Substituting (8.10) into (8.11) we obtain the
expression for the local truncation error
τi = y(ti+1) −[y(ti) + h · f(ti, y(ti))] .
Let |y′′(t)| ≤M for all t ∈[a, b]. The Taylor expansion of y(ti+1) = y(ti + h) around ti
implies
τi = y(ti) + hy′(ti) + h2
2 y′′(ξi) −[y(ti) + hy′(ti)] = h2
2 y′′(ξi) ,
where ξi ∈(ti, ti+1). Taking absolute values on both sides of the last relation, and using the
bound |y′′(t)| ≤M for t ∈[a, b] we obtain
|τi| ≤Mh2/2 .
This means that the local truncation error is of order h2, which seems very satisfactory at
first glance. On the other hand, we always compute the solution at ti+1 using an approxi-
mation yi rather than the exact solution y(ti) (except for i = 0). Thus, the actual error at
every step will be larger as it accumulates local errors from the previous steps. The actual
error is called global error.
Global error estimation
In order to find an estimate of the global error we need two lemmata. The first lemma
expresses the fact that the exponential growth is larger than the polynomial one.
Lemma 8.1. For all x ≥−1 and any positive integer m, we have:
0 ≤(1 + x)m ≤emx .
Proof. Using Taylor’s expansion (see Section 4.3.2) with f(x) = ex, c = 0 and n = 1 we
have
ex = 1 + x + 1
2x2eξ ,
where ξ is between x and 0. Thus,
0 ≤1 + x ≤1 + x + 1
2x2eξ = ex ,
and because 1 + x ≥0, we obtain
0 ≤(1 + x)m ≤(ex)m = emx .

288
Numerical Differentiation and Applications to Differential Equations
The second lemma is actually a summation formula of a geometric sum. The global error
is practically a geometric sum formed by the local errors. For this reason, we use the next
summation formula to find the global error in closed form.
Lemma 8.2 (Geometric sum). The following summation formula holds for any i ∈N and
s ∈R:
i
X
j=0
(1 + s)j = 1 −(1 + s)i+1
1 −(1 + s)
= (1 + s)i+1 −1
s
.
Proof. Let r = 1 + s, then we have
S = 1 + r + r2 + . . . + ri ,
which after multiplication with r gives
S · r = r + r2 + . . . + ri+1 .
Subtracting the previous expressions we have
S · r −S = ri+1 −1 ,
and solving for S we obtain the summation formula
S = ri+1 −1
r −1
= (1 + s)i+1 −1
s
.
We are ready now to prove a global error estimate.
Theorem 8.3 (Error estimate for Euler’s method). Suppose that f(t, y) is continuous and
satisfies a Lipschitz condition with Lipschitz constant L on
D = { (t, y)| a ≤t ≤b
and
−∞< y < ∞} .
Moreover, assume that there is a constant M > 0 such that
|y′′(t)| ≤M,
for all
t ∈[a, b] ,
where y(t) denotes the unique solution of the initial-value problem
y′ = f(t, y),
a ≤t ≤b,
y(a) = y0 .
Let y0, y1, . . . , yN be the approximations obtained by Euler’s method for some integer N > 0.
Then for each i = 0, 1, 2, . . . , N −1,
|y(ti+1) −yi+1| ≤hM
2L
h
eL(ti+1−a) −1
i
.
Proof. We will estimate the difference |y(ti+1)−yi+1|. Taking Taylor’s expansion to y(ti+1)
we have that for i = 0, 1, 2, . . . , N −1,
y(ti+1) = y(ti) + h · f(ti, y(ti)) + h2
2 y′′(ξi) ,
where ξ ∈(ti, ti+1). On the other hand, Euler’s method gives
yi+1 = yi + h · f(ti, yi) .

Applications to Ordinary Differential Equations
289
Subtracting the last two equations we have
y(ti+1) −yi+1 = y(ti) −yi + h · [f(ti, y(ti)) −f(ti, yi)] + h2
2 y′′(ξi) .
Taking absolute values on both sides yields
|y(ti+1) −yi+1| ≤|y(ti) −yi| + h · |f(ti, y(ti)) −f(ti, yi)| + h2
2 |y′′(ξi)| .
Since f satisfies a Lipschitz condition in the second variable with constant L, and |y′′(t)| ≤
M we have
|y(ti+1) −yi+1| ≤(1 + hL)|y(ti) −yi| + h2M
2
≤(1 + hL)2|y(ti−1) −yi−1| + (1 + (1 + hL))h2M
2
...
≤(1 + hL)i+1|y(0) −y0| + (1 + (1 + hL) + (1 + hL)2 + . . . + (1 + hL)i)h2M
2
= (1 + hL)i+1 −1
hL
h2M
2
.
Using Lemma 8.1 (and in particular the inequality (1 + hL)i ≤ehLi) we have
|y(ti+1) −yi+1| ≤eLh(i+1) −1
hL
h2M
2
.
Since ti+1 = a + (i + 1)h, we have that h(i + 1) = ti+1 −a and thus, the last inequality can
be written as
|y(ti+1) −yi+1| ≤hM
2L
h
e(ti+1−a)L −1
i
,
for each i = 0, 1, 2, . . . , N −1, which is the desired estimate.
In order to find the error estimate in the previous theorem, we assumed that the solution
y(t) has bounded second derivative |y′′(t)| ≤M. In fact this is not unreasonable. Since y
is a solution of a differential equation, we can estimate the second derivative by taking the
first derivative on both sides of the differential equation y′ = f(t, y) to obtain
y′′ = d
dt(y′) = d
dtf(t, y(t)) = ft + fy · f .
(8.12)
One of the main reasons for studying the error estimates is to have a theoretical jus-
tification for the convergence of the numerical solution to the exact solution. This means
that when the discretization parameter h tends to zero, then the numerical solution tends
to the exact solution. The error estimate also provides with information about the speed of
convergence. The speed of convergence (like in Newton’s method and so forth) is described
again by the rate of convergence. In Theorem 8.3 we proved that |y(ti) −yi| ≤Ch for some
constant C (independent of h). This implies that the numerical solution converges to the
exact solution since
lim
h→0 |y(ti) −yi| ≤lim
h→0 Ch = 0 ,
and that the convergence is linear. In principle, we cannot be excited about a method that
converges linearly. A higher-order alternative shall be derived in the following section.

290
Numerical Differentiation and Applications to Differential Equations
8.2.4
Implicit variants of Euler’s method
Given the approximation yi, we can compute the approximation yi+1 using Euler’s method
explicitly by the formula yi+1 = yi + hf(ti, yi). For this reason, Euler’s method is charac-
terized as explicit3. In general, numerical methods of the form yi+1 = F(yi) for i = 0, 1, . . .
are called explicit. Numerical methods that require the solution of a system of the form
yi+1 = F(yi+1), for i = 0, 1, . . . are called implicit methods. Implicit methods perform bet-
ter than the explicit ones, especially when the solution of the differential equation varies
rapidly in small periods of time. Problems with such behavior of their solution are called
stiff. An example of implicit method is the implicit Euler method. The implicit Euler method
can be derived from the differential equation
y′(ti+1) = f(ti+1, y(ti+1)) ,
using the backward finite difference approximation to the first derivative4
y′(ti+1) ≈y(ti+1) −y(ti)
h
.
This leads to the definition of the implicit Euler method
yi+1 = yi + hf(ti, yi+1)
for i = 0, 1, . . . , N −1 ,
y0 = given .
(8.13)
If f(t, y) is a nonlinear function in terms of y, then we cannot solve explicitly the recursive
relation of (8.13) with respect to yi+1. Equation (8.13) can be seen as a fixed point equation
yi+1 = F(yi+1), where techniques of Chapter 5 can be applied. We are able to solve the
problem explicitly in the special case where the function f(t, y) is linear in terms of y.
For example, if y′ = y, the implicit Euler method is
yi+1 = yi + hyi+1 ,
which after solving for yi+1 gives the explicit solution
yi+1 =
1
1 −hyi,
i = 0, 1, 2, . . . , N .
Another implicit Euler-type method is the trapezoidal method. Also known as the Crank-
Nicolson method, the implicit trapezoidal method can be derived as follows: First integrate
the differential equation y′(t) = f(t, y(t)) on the interval [ti, ti+1] to obtain
y(ti+1) = y(ti) +
Z ti+1
ti
f(t, y(t)) dt .
(8.14)
We then use the trapezoidal quadrature rule (see Section 7.2.1) to approximate the integral
on the right-hand side of (8.14). This approximation yields the formula
yi+1 = yi + h
2 [f(ti, yi) + f(ti+1, yi+1)] ,
where again yi+1 is an approximation of y(ti+1). The trapezoidal method stands between
the explicit and implicit Euler’s methods, and has order of convergence O(h2), while the
implicit Euler method has O(h).
3The explicit Euler method is also known to as the forward Euler method.
4The implicit Euler method is also known to as the backward Euler method.

Applications to Ordinary Differential Equations
291
8.2.5
Improved Euler method
The improved Euler method, is also known as Heun’s method (named after Karl Heun 1859–
1929). It can be seen as an extension of Euler’s method to achieve second-order convergence
rate. To make this somewhat clearer, we first present the improved Euler method. Given the
initial value problem y′ = f(t, y) with y(0) = y0, and the mesh y0 < y1 < · · · < yN, then the
approximations yi of the values y(ti) with the improved Euler method can be determined
using the formulas
˜yi+1 = yi + hf(ti, yi) ,
yi+1 = yi + h
2 (f(ti, yi) + f(ti+1, ˜yi+1)) ,
for i = 0, 1, . . . , N −1 .
The first step of the improved Euler method is Euler’s method and serves as an intermediate
stage to obtain an initial approximation of the solution. The second step uses the approxi-
mation ˜yi+1 in the trapezoidal rule to obtain an improved approximation yi+1 explicitly.
The derivation of the improved Euler method might sound impossible at first glance.
The truth is that it can be derived using Taylor’s expansions (like what we did so far to
eliminate derivatives), and also the estimate (8.12) for the second derivative, y′′ = ft+fy ·f.
Consider the general first-order ordinary differential equation
y′(t) = f(t, y(t)) ,
and the Taylor expansion
y(t + h) = y(t) + hy′(t) + h2
2 y′′(t) + O(h3) .
The first derivative in this expansion can be replaced by the right-hand side of the differential
equation, and the second derivative is obtained by (8.12). Therefore, the Taylor expansion
becomes
y(t + h) = y(t) + hf(t, y) + h2
2 [ft(t, y) + fy(t, y)f(t, y)] + O(h3)
= y(t) + h
2 f(t, y) + h
2 [f(t, y) + hft(t, y) + hfy(t, y)f(t, y)] + O(h3) .
Recalling the multivariate Taylor expansion
f(t + h, y + k) = f(t, y) + hft(t, y) + fy(t, y)k + . . . ,
we see that the quantity in the square brackets can be interpreted as
f(t + h, y + hf(t, y)) = f(t, y) + hft(t, y) + hfy(t, y)f(t, y) + O(h2) .
Therefore, we get
y(t + h) = y(t) + h
2 f(t, y) + h
2 f(t + h, y + hf(t, y)) + O(h3) .
If we take t = ti and discard the high-order terms, then we get
yi+1 = yi + h
2 f(ti, yi) + h
2 f(ti+1, yi + hf(ti, yi)) .
(8.15)
Setting ˜yi+1 = yi + hf(ti, yi) we have
yi+1 = yi + h
2 f(ti, yi) + h
2 f(ti+1, ˜yi+1) .

292
Numerical Differentiation and Applications to Differential Equations
An alternative way to formulate the improved Euler method is by setting k1 = f(ti, yi)
and k2 = f(ti +h, yi +hk1). Then for given y0 = y(t0), the formula (8.15) can be written as
yi+1 = yi + h
1
2k1 + 1
2k2

for i = 0, 1, . . . ,
where
k1 = f(ti, yi) ,
k2 = f(ti + h, yi + hk1) .
The values k1 and k2 are called intermediate stages. In order to compute the solution yi+1
we need to compute first the two intermediate stages k1 and k2. The improved Euler method
is a particular example of a class of numerical methods known as Runge-Kutta methods.
From the previous derivation we see that the local error is O(h3). Thus, the global error
is expected to be O(h2). We proceed now with the implementation of the numerical method
and a computational demonstration of its accuracy. In the following implementation, we
modify the function euler by adding the new intermediate step ˜yi+1 in the variable z.
1
def f(t, y):
2
return y
3
def improved_euler(t, f, y0):
4
n = len(t)
5
y = np.zeros(n)
6
h = (t[-1]-t[0])/(n-1)
7
y[0]=y0
8
for i in range(n-1):
9
k1 = f(t[i], y[i])
10
k2 = f(t[i+1], y[i] + h*k1)
11
y[i+1] = y[i] + 0.5*h*(k1+k2)
12
return y
13
a = 0.0; b = 2.0; N = 10
14
t = np.linspace(a, b, N+1)
15
y0 = 1.0
16
y = improved_euler(t, f, y0)
17
# Plot the results
18
fig = plt.figure()
19
axes = fig.add_subplot(1, 1, 1)
20
axes.plot(t, y, '-o', label="Improved Euler")
21
axes.plot(t, np.exp(t), '-d', label="Exact solution")
22
axes.set_xlabel("t"); axes.set_ylabel("y"); axes.legend(loc=2); plt.show()

Applications to Ordinary Differential Equations
293
0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
2.00
t
1
2
3
4
5
6
7
y
Improved Euler
Exact solution
In this code we used only 10 nodes for the computations (stepsize h = 0.2) and we observe
in the output plot that the exact and numerical solution almost coincide. This is the benefit
of using high-order methods as we achieve faster convergence and the required stepsize can
be taken large.

The higher the order of convergence of a numerical method, the faster the
method converges. This leads to better approximations with larger stepsizes. We say
that such methods are efficient.
8.2.6
The notion of stability
When it comes to the use of numerical methods for the approximation of solutions of
differential equations one common problem is the choice of the stepsize h. In principle,
we want to take h as large as possible without having any discount in the accuracy of
the solution. By taking h quite large sometimes can lead to unpleasant surprises5. In such
situations, we need to take the value of h smaller and try again. There is a question that
arises whether or not we can have an indication of how small we can take the stepsize h
before we start spending time trying to solve our problem.
Let’s see first a problematic situation. Consider the very simple ordinary differential
equation
y′(t) = λy(t),
λ < 0 ,
with initial condition y(0) = 1. The exact solution of this problem is the function y(t) = eλt.
Let’s try using our code, the case with λ = −10 and with N = 5. In this case, the stepsize
h = 0.4 which is large.
1
def f(t, y):
2
return -10.0*y
3
a = 0.0; b = 2.0; N = 5
4
h = (b-a)/N
5
t = np.linspace(a, b, N+1)
6
y0 = 1.0
7
y = euler(t, f, y0)
8
# Plot the results
5The numerical solution converges as h →0. If h > 0 is large enough the error might be surprisingly
large

294
Numerical Differentiation and Applications to Differential Equations
9
fig = plt.figure()
10
axes = fig.add_subplot(1, 1, 1)
11
axes.plot(t, y, '-o', label="Euler")
12
axes.plot(t, np.exp(-10*t), '-d', label="Exact solution")
13
axes.set_xlabel("t"); axes.set_ylabel("y"); axes.legend(loc=2); plt.show()
0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
2.00
t
−250
−200
−150
−100
−50
0
50
y
Euler
Exact solution
We observe that by taking h = 0.4 the Euler method diverges from the exact solution
of the problem. More precisely, we observe that the solution grows with time instead of
converging to 0 as it should. By taking h = 0.1 (N = 20) we see in the graph that the
numerical solution converges to 0 very quickly. Not that we should be totally happy about
this result, but at least the solution seems to converge. Taking even smaller values of h we
observe convergence eventually.
0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
2.00
t
0.0
0.2
0.4
0.6
0.8
1.0
y
Euler
Exact solution
To understand why this is happening, we apply Euler’s method to the equation y′(t) =
λy(t) for λ < 0. This gives yn+1 = yn + hλyn, or even better
yn+1 = (1 + hλ)yn,
n = 0, 1, 2, . . . ,
and
y0 = 1 .
It can easily be seen that the previous recursive sequence can be expressed explicitly as
yn = (1 + hλ)n,
n = 0, 1, . . . .

Runge-Kutta Methods
295
So, we have that
|yn| →0,
if |1 + hλ| < 1 ,
|yn| = 1,
if |1 + hλ| = 1 ,
|yn| →∞,
if |1 + hλ| > 1 .
Therefore, for stability we need |1 + hλ| < 1. Solving this inequality for hλ yields
−2 < hλ < 2. Since h > 0 and λ < 0, we need hλ ∈(−2, 0) or else h < −2/λ for stability.
In our previous example where λ = −10 this means h < 0.2 and this explains the unwanted
behavior for h = 0.4 > 0.2.

Stability depends always on the initial-value problem. An unconditionally stable
method has no restrictions in the choice of the stepsize h. If conditions apply in the
stepsize in order to achieve meaningful solutions, then we say that the method has
stability restrictions.
Applying the implicit Euler method to the same problem, we have that
yn+1 = yn + hλyn+1,
n = 0, 1, 2, . . . ,
and
y0 = 1
which yields
yn+1 =
yn
1 −hλ,
n = 0, 1, 2, . . . ,
and
y0 = 1 .
This recursive relation leads to the analytical formula of the numerical solution
yn =
1
(1 −hλ)−n ,
n = 0, 1, 2, . . . .
For λ < 0 the quantity 1 −hλ > 1. Therefore, |yn| →0 for all values of h. This means
that the implicit Euler method is unconditionally stable. Such methods, without stability
limitations on h, are called A-stable methods. Usually, implicit methods are A-stable.
8.3
Runge-Kutta Methods
So far, we have studied numerical methods for the solution of ordinary differential equations
as a consequence of the approximation of the first derivative with finite differences. This
lead us to the formulation of a method that belongs in, perhaps, the most important class of
numerical methods for ordinary differential equations, the so-called Runge-Kutta methods.
Runge-Kutta methods where first introduced by Carl Runge (1856-1927) and Martin Kutta
(1867-1944), while the more recent contributions of John Butcher evolved these methods in
their current form. Runge-Kutta methods can be derived following many different method-
ologies and also by approximating integrals with numerical quadrature. As an introduction
to this topic, we present briefly explicit, implicit and adaptive Runge-Kutta methods.
8.3.1
Explicit Runge-Kutta methods
Consider the initial value problem in the interval [0, T]
y′(t) = f(t, y(t)),
t ∈(0, T] ,
y(0) = y0 ,

296
Numerical Differentiation and Applications to Differential Equations
and a uniform partition 0 = t0 < t1 < · · · < tN = T of the interval [0, T] with stepsize
h = T/N. The improved Euler method, described by the formula
yi+1 = yi + h
1
2k1 + 1
2k2

,
i = 0, 1, . . . ,
where
k1 = f(ti, yi) ,
k2 = f(ti + h, yi + hk1) .
is a specific example of a general class of methods known to as Runge-Kutta methods.
Runge-Kutta methods for the numerical solution of ordinary differential equations usually
consist of multiple stages ki. For example, the most commonly used Runge-Kutta method
with four stages can be described as follows,
yi+1 = yi + h
1
6k1 + 1
3k2 + 1
3k3 + 1
6k4

,
i = 0, 1, . . . , N −1 ,
where
k1 = f(ti, yi) ,
k2 = f

ti + h
2 , yi + k1
2

,
k3 = f

ti + h
2 , yi + k2
2

,
k4 = f(ti + h, yi + k3) .
This method is known to as the classical, explicit four-stage and fourth order Runge-Kutta
method. It is called explicit because the computation of any intermediate stage ki requires
the knowledge of previous stages only. (Otherwise the method is called implicit.) It is a
four-stage method because it consists of four intermediate stages ki, for i = 1, 2, 3, 4, and
fourth-order because the global error can be proved to be |y(ti) −yi| = O(h4).
All Runge-Kutta methods can be formulated in the same way. The general explicit
Runge-Kutta method with s intermediate stages is the following:
yi+1 = yi + h
s
X
j=1
bjkj,
i = 0, 1, . . . ,
where
k1 = f(ti, yi) ,
k2 = f(ti + c2h, yi + h(a21k1)) ,
k3 = f(ti + c3h, yi + h(a31k1 + a32k2)) ,
...
ks = f(ti + csh, yi + h(as1k1 + as2k2 + · · · + as,s−1ks−1)) ,
for appropriate coefficients aij, bi, ci, for i, j = 1, 2, . . . , s. The choice of these parameters
determine uniquely the Runge-Kutta method. Note that in the previous definition c1 = 0
and aij = 0 for all j ≥i. Thus, the parameters aij, bi and ci form the lower triangular
matrix
A =








0
0
· · ·
0
a21
0
0
a31
a32
...
...
...
...
0
as1
as2
· · ·
as,s−1








,

Runge-Kutta Methods
297
TABLE 8.1
Butcher tableau for the general explicit Runge-
Kutta method with s stages
c
A
bT
=
0
c2
a21
c3
a31
a32
...
...
...
cs
as1
as2
· · ·
as,s−1
b1
b2
· · ·
bs−1
bs
and the vectors
b =





b1
b2
...
bs





and
c =







0
c2
c3
...
cs







.
As we will see later, A is a lower triangular matrix only for explicit Runge-Kutta methods,
where the computation of each new step requires only the knowledge of the previous steps.
We usually do not write the 0’s in the upper triangular part of matrix A but we leave their
places empty. In principle, any consistent Runge-Kutta method must satisfy the condition
i−1
X
j=1
aij = ci
for
i = 2, 3, . . . , s .
This information is usually incorporated in a table known as Butcher tableau, which is
described in Table 8.1.
Interpreting the previous tables, if we want to compute the solution yi+1 ≈y(ti+1) given
the solution yi ≈y(ti) using an explicit Runge-Kutta method with s intermediate stages
we need first to compute the intermediate stages
kℓ= f

ti + cℓh, yi + h
ℓ−1
X
j=1
aℓ,jkj

,
ℓ= 1, 2, . . . , s ,
(8.16)
and then the approximation of the solution at t = ti+1 given by
yi+1 = yi + h
s
X
j=1
bjkj,
i = 0, 1, . . . .
(8.17)
The computation of kℓin (8.16) requires all the intermediate stages k1, k2, . . . , kℓ−1.

The computation of an intermediate stage kℓof any explicit Runge-Kutta
method with s stages requires the knowledge of the previous stages kj for j < ℓ.
Thus, in the worst case scenario, in order to compute the intermediate stages we
need to solve a linear system. If the matrix A in the Butcher tableau consists of one
diagonal only, then the linear system can be solved in a trivial way as the resulting
equations will be decoupled.

298
Numerical Differentiation and Applications to Differential Equations
TABLE 8.2
Butcher tableau for the Euler
method
0
0
1
TABLE 8.3
Butcher tableau for the improved
Euler method
0
1
1
1/2
1/2
TABLE 8.4
Butcher
tableau
for
second-
order methods with two stages
0
α
α
1 −1/2α
1/2α
Examples of explicit Runge-Kutta methods
The first example is the Euler method which can be described by the tableau in Table 8.2.
According to the general formulas (8.16)–(8.21) the Euler method is the following 1-stage
Runge-Kutta method
k1 = f(ti, yi),
yi+1 = yi + hk1,
i = 0, 1, 2, . . . .
(8.18)
A second example is the improved Euler method with two stages. The method as it was
described in Section 8.2.5 is the following two-stage method
k1 = f(ti, yi),
k2 = f(ti + h, yi + hk1),
yi+1 = yi + h
1
2k1 + 1
2k2

,
i = 0, 1, 2, . . . ,
(8.19)
and thus the corresponding Butcher tableau is given in Table 8.3. The improved Euler
method is not the only second-order Runge-Kutta method with two stages. All methods
described by the tableau of Table 8.4 are also second-order accurate.
The last example we provide in Table 8.5 is the classical four-stage, fourth-order Runge-
Kutta method, which is perhaps the most popular explicit Runge-Kutta method.
8.3.2
Implicit and diagonally implicit Runge-Kutta methods
As previously discussed, the matrix A is strictly lower triangular for all explicit Runge-
Kutta methods. One result of this property is that the computation of an intermediate

Runge-Kutta Methods
299
TABLE 8.5
Butcher tableau classical four-stage
fourth-order Runge-Kutta method
0
1/2
1/2
1/2
0
1/2
1
0
0
1
1/6
1/3
1/3
1/6
TABLE 8.6
Butcher tableau for the general Runge-Kutta
method with s stages
c
A
bT
=
c1
a11
a12
· · ·
a1s
c2
a21
a21
· · ·
a2s
...
...
...
...
...
cs
as1
as2
· · ·
ass
b1
b2
· · ·
bs
stage requires only the knowledge of the previous intermediates stages. On the other hand,
the most general Runge-Kutta method is described by the tableau of Table 8.6 with full
matrix A.
This tableau corresponds to the general implicit Runge-Kutta method with s stages
kℓ= f

ti + cℓh, yi + h
s
X
j=1
aℓ,jkj

,
ℓ= 1, 2, . . . , s ,
(8.20)
and the corresponding formula for the approximate solution at t = ti+1
yi+1 = yi + h
s
X
j=1
bjkj,
i = 0, 1, . . . .
(8.21)
It is easy to see that for the computation of the stage kℓthe knowledge of all the previous
and the future stages is required. This formulates an s-dimensional nonlinear system of
equations which can be solved using Newton’s or any other fixed point method. If A is
lower triangular but with non-zero diagonal entries, then the method is called diagonally
implicit Runge-Kutta method (DIRK). A DIRK method does not require the solution of a
nonlinear system but only scalar nonlinear equations for the computation of each stage kℓ.
Examples of implicit Runge-Kutta methods
The simplest implicit Runge-Kutta method is the implicit Euler method, which is described
by the tableau of Table 8.7. Although it is implicit method, it can be seen also as diagonally
implicit since there is only one stage. This unique intermediate stage is
k1 = f(ti + h, yi + hk1) ,
(8.22)

300
Numerical Differentiation and Applications to Differential Equations
TABLE 8.7
Butcher tableau for the im-
plicit Euler method
1
1
1
TABLE 8.8
Butcher tableau for the two-stage, fourth-order
Gauss-Legendre Runge-Kutta method
1
2 −1
6
√
3
1
4
1
4 −1
6
√
3
1
2 + 1
6
√
3
1
4 + 1
6
√
3
1
4
1
2 + 1
2
√
3
1
2 −1
2
√
3
which is a nonlinear equation formulated directly as a fixed point equation with fixed point
the unknown intermediate stage k1. For the computation of the unknown k1 we can intro-
duce the iteration
k(p+1)
1
= f

ti + h, yi + hk(p)
1

,
p = 0, 1, 2, . . . ,
with a given initial guess k(0)
1 . The value of the initial guess k(0)
1
could be the value f(ti, yi),
which is the intermediate stage of the Euler method. After computing the intermediate
stage k1, we compute the actual approximation of the solution
yi+1 = yi + hk1 .
(8.23)
This main step of the implicit Euler method is the same as the main step of the explicit
Euler method but they differ in the value of k1.
Other very important implicit Runge-Kutta methods are the so-called Gauss-Legendre
methods which can be derived using Gaussian quadrature. Among the many advantages
of Gauss-Legendre Runge-Kutta methods is their accuracy of s-stage methods, which is
2s. Thus, we can achieve fourth order accuracy by using only two stages. The two-stage,
fourth-order Gauss-Legendre Runge-Kutta method is given by the Butcher tableau of Table
8.8.
Formulating the intermediate stages using the Table 8.8 we observe that the equations
for k1 and k2 are
k1 = f(ti + c1h, yi + h(a11k1 + a12k2)) ,
k2 = f(ti + c2h, yi + h(a21k1 + a22k2)) ,
(8.24)
and they form a nonlinear system of two equations with two unknowns (k1, k2). The methods
of Section 5.5.6 can be applied for the solution of this system, or the following simple fixed
point iteration also known to as the Gauss-Seidel method for nonlinear systems: Given the
initial guesses k(0)
1 , k(0)
2 , we approximate the values of k1 and k2 by the iterations
k(p+1)
1
= f(ti + c1h, yi + h(a11k(p)
1
+ a12k(p)
2 )),
k(p+1)
2
= f(ti + c2h, yi + h(a21k(p+1)
1
+ a22k(p)
2 )),
p = 0, 1, 2, . . . .
(8.25)
Because of its simplicity, the specific iterative method can converge very slowly or it may not
converge at all. In case of divergence, the use of Newton-type methods can be unavoidable.

Runge-Kutta Methods
301
Using the approximations of k1 and k2 the main step of the two-stage, fourth-order Runge-
Kutta method is then
yi+1 = yi + h(b1k1 + b2k2) ,
(8.26)
which has not practical implications in its computation.
8.3.3
Adaptive Runge-Kutta methods
So far, we have considered uniform partition of the temporal interval of numerical integration
using fixed h = (b −a)/N = ti+1 −ti for all i = 0, 1, . . . . On the other hand, especially in
cases where the time integration of a differential equation is time-consuming, it would have
been preferable to consider a variable stepsize so as to improve the speed of the computations
without compromising their accuracy. Here, we present a technique of using explicit Runge-
Kutta methods with variable stepsize hi. One can use also implicit Runge-Kutta methods
in a similar manner. The technique is based on the application of two different Runge-Kutta
methods. For economy, we choose methods with the same matrix A and vector c in their
Butcher tableaux, while we keep the vector b different. In principle, we use Runge-Kutta
methods with different order of accuracy. The idea is to pretend that the solution of the high-
order method yi is very accurate (like being exact) and compare it with the one obtained
using the low-order method y∗
i . If the error between the two approximations yi and y∗
i of the
same solution at ti is greater than a prescribed tolerance, then we repeat the computation
of the specific step with smaller h. Consider two s-stage Runge-Kutta methods, let’s say,
given by the tableaux
c
A
bT
and
c
A
(b∗)T
.
Usually, we write the two Runge-Kutta methods in a combined Tableau as in Table 8.9.
Since the matrices A and c are common for both methods, the intermediate stages are
the same, and they are computed once for both methods using the formula (8.16)
kℓ= f

ti + cℓh, yi + h
ℓ−1
X
j=1
aℓ,jkj

,
ℓ= 1, 2, . . . , s .
(8.27)
Because the vectors b and b∗are different, the two methods will result in two different
approximations to the solution
yi+1 = yi + h
s
X
j=1
bjkj
and
y∗
i+1 = yi + h
s
X
j=1
b∗
jkj .
(8.28)
The absolute error between the two solutions is then
ei = |yi+1 −y∗
i+1| = h

s
X
j=1
(bj −b∗
j)kj

.
(8.29)
If the error ei is greater than a prescribed tolerance, then we repeat the computation for
the step i by using stepsize h equal to the half of the previous stepsize.
The algorithm for a general adaptive Runge-Kutta method with s stages is summarized
in Algorithm 26. In that algorithm, we assume that we want to solve the problem y′ = f(t, y)
in the temporal interval [a, b] with y(a) = y0. We assume also that A, c, b and b∗of the
Runge-Kutta method are all given.

302
Numerical Differentiation and Applications to Differential Equations
TABLE 8.9
Butcher tableau for the general explicit adaptive Runge-
Kutta with s stages
c
A
bT
(b∗)T
=
0
c2
a21
c3
a31
a32
...
...
...
cs
as1
as2
· · ·
as,s−1
b1
b2
· · ·
bs−1
bs
b∗
1
b∗
2
· · ·
b∗
s−1
b∗
s
Algorithm 26 Adaptive Runge-Kutta method
Initialize the stepsize h < b −a and time ti = 0
Set y(a) = y0
while ti < b do
error = 1
while error > TOL do
Set h = h/2
for l = 1 : s do
Compute the intermediate stages
kl = f

ti + clh, yi + h
l−1
X
j=1
Aljkj


end for
Compute
yi+1 = yi + h
s
X
j=1
bjkj
and
y∗
i+1 = yi + h
s
X
j=1
b∗
jkj ,
Compute the error = |yi+1 −y∗
i+1|
end while
Set ti = ti + h
end while
The simplest example of an adaptive Runge-Kutta method is the combination of the
Euler and improved Euler methods given by the tableau in Table 8.10. In this case, the
Euler method is of order 1 while the improved Euler method of order 2, and that is why we
call it RK12.
The most popular adaptive Runge-Kutta method is the Runge-Kutta-Fehlberg method
of order 5 given by the Table 8.11 This method was introduced by Erwin Fehlberg (1911-
1990) and is of order 5 since one of the methods is of order 4 and the other of order 5. This
particular method is referred to as RK45, and can be found implemented in every scientific
package dedicated to the numerical solution of ordinary differential equations, including
SciPy.

The Module scipy.integrate Again
303
TABLE 8.10
Butcher tableau for the adaptive
Runge-Kutta 12 method
0
1
1
1/2
1/2
1
0
TABLE 8.11
Butcher tableau for the RK45, Runge-Kutta-Fehlberg method of order 5
0
1/4
1/4
3/8
3/32
9/32
12/13
1932/2197
−7200/2197
7296/2197
1
439/216
−8
3680/513
−845/4104
1/2
−8/27
2
−3544/2565
1859/4104
−11/40
16/135
0
6656/12825
28561/56430
−9/50
2/55
25/216
0
1408/2565
2197/4104
−1/5
0
TABLE 8.12
Butcher tableau for the RK Radau IIA method of
order 5
2
5 −
√
6
10
11
45 −7
√
6
360
37
225 −169
√
6
1800
−
2
225 +
√
6
75
2
5 +
√
6
10
37
225 + 169
√
6
1800
11
45 + 7
√
6
360
−
2
225 −
√
6
75
1
4
9 −
√
6
36
4
9 +
√
6
36
1
9
4
9 −
√
6
36
4
9 +
√
6
36
1
9
8.4
The Module scipy.integrate Again
Several functions for the numerical solution of general initial value problems of ordinary
differential equations are available in scipy.integrate module of SciPy. Specifically, among
the many solvers of the module integrate one can find the explicit Runge-Kutta-Fehlberg
methods 23 and 45 implemented in the functions RK23 and RK45, and the implicit Radau
IIA method of order 5 with the tableau as in Table 8.12, implemented in the function
Radau. In general, Radau methods with s stages have order of convergence 2s −1 and are
very effective when applied to stiff equations. All these methods can also be called via the
function solve ivp which we present next.
8.4.1
Generic integration of initial value problems
We present here the generic function solve ivp for the numerical solution of initial-value
problems of ordinary differential equations. This function is designed to integrate numeri-
cally initial value problems of scalar and systems of ordinary differential equations of the

304
Numerical Differentiation and Applications to Differential Equations
form
y′(t) = f(t, y),
t ∈(a, b] ,
y(a) = y0 .
The general call of this function is the following:
solve_ivp(fun, t_span, y0, method, t_eval, args, options)
where the variables hidden in the options parameter can be ignored as all of them are
optional and can be used in sophisticated problems. The most useful parameters for the
purposes of this book are the following:
fun: Is the name of the function f(t, y)
t span: The end-points of the interval [a, b]. Is a tuple (t0,tf) defining the (temporal)
interval of integration (t0, tf). The solver starts with t=t0 and ends with the compu-
tation of the solution at t=tf
y0:
Is the initial condition which can be an one-dimensional array
method: Is the preferred numerical method. It can take the values RK45, RK23, DOP853 and
for stiff problems suggested values are Radau, BDF and LSODA. (Optional with default
value method=RK45)
t eval: An array with values of the times ti on which we want the solution to be computed.
(Optional with default value t eval=None)
args: If the function f has additional arguments such as f(t, y, a, b, c), then we pass the
extra arguments in the tuple args=(a,b,c). (Optional with default value args=None)
The additional options are summarized below:
dense output: Is a boolean variable to specify whether to compute a continuous solution
or not. (Optional with default value dense output=False)
vectorized: Is a boolean variable that specifies if the function fun is implemented in a
vectorized fashion. (Optional with default value vectorized=False)
first step: Is a float that specifies initial stepsize h. (Optional with default value first -
step=None)
max step: Is a float that specifies the maximum allowed stepsize. (Optional with default
value max step=np.inf)
rtol and atol: Are floats or arrays specifying the relative and absolute tolerances. (Op-
tional with default values rtol=1.e-3 and atol=1.e-6)
jac: Is the Jacobian matrix necessary for the methods Radau, BDF and LSODA. When None
then appropriate finite difference approximation is considered. (Optional with default
value jac=None)
jac sparsity: Is an array like variable or a sparse matrix or None. This variable specifies
a sparsity structure of the n×n Jacobian matrix for a finite difference approximation.
If None then the Jacobian matrix is considered dense. Sparse matrix usually has more
zero than non-zero entries. This variable is not supported by the LSODA method.
(Optional with default value jac sparsity=None).

The Module scipy.integrate Again
305
lband and uband: These are integer variables specifying the bandwidth of the Jacobian for
the LSODA method. If None then the matrix is considered full. (Optional with default
value None)
min step: Is a float specifying the minimum allowed stepsize for the LSODA method. (Op-
tional with default value 0)
And the function returns a class with the members the following variables:
t:
Is an array containing the times at which the solution is computed
y:
Is an array with the values of the approximated solution at t
sol: Is an instance of a class containing the solution as in the previous argument unless
the argument dense output was set to False where the return value is None
t events: Contains for each event type a list of arrays at which an event of that type event
was detected. It is None if the a events was None
t events: A list of arrays (or None) containing for each value of t events, the correspond-
ing values of the solution. None is returned if the value of events is None
nfev: The number of evaluations of the right-hand side
njev: The number of evaluations of the Jacobian
nlu: The number of the LU decompositions required
status: Is −1 if the integration failed, 0 if the solver successfully computed the solution
for the prescribed time interval, and 1 if a termination event occurred
message: Is a string with a description of the termination reason
success: Is a boolean variable which is True if the status is greater or equal to zero
In order to demonstrate the usage of the function solve ivp we consider again the initial
value problem
y′(t) = y(t),
t ∈(0, 2] ,
y(0) = 1 ,
and we approximate its solution using the method RK45. For accurate results we consider
the tolerance rtol=1.e-6.
1
from scipy.integrate import solve_ivp
2
3
def f(t, y):
4
return y
5
a = 0.0; b = 2.0
6
tspan = [a, b]
7
y0 = [1.0]
8
sol = solve_ivp(f, tspan, y0, 'RK45', rtol=1.e-6)
9
# Plot the results
10
fig = plt.figure()
11
axes = fig.add_subplot(1, 1, 1)
12
axes.plot(sol.t, sol.y[0], '-o', label="RK45")
13
axes.plot(sol.t, np.exp(sol.t), '-d', label="Exact solution")
14
axes.set_xlabel("t"); axes.set_ylabel("y"); axes.legend(loc=2); plt.show()

306
Numerical Differentiation and Applications to Differential Equations
0.00
0.25
0.50
0.75
1.00
1.25
1.50
1.75
2.00
t
1
2
3
4
5
6
7
y
RK45
Exact solution
In order to plot the solution obtained by the function solve ivp, we use the member
sol.y[0]. The [0] is necessary since the variable y is at least a two-dimensional array but
we need to plot only a one-dimensional array. The numerical and exact solutions agree as
expected and it is impossible to observe differences within the scale of the specific graph.
8.4.2
Systems of ordinary differential equations
All the aforementioned numerical methods can be generalized for systems of ordinary differ-
ential equations in a straightforward manner. For simplicity, consider the following coupled
system with two equations and two unknowns y1(t) and y2(t)
(
y′
1(t) = f1(t, y1(t), y2(t))
y′
2(t) = f2(t, y1(t), y2(t)) ,
t ∈(a, b] ,
(8.30)
with initial conditions y1(a) = y0
1 and y2(a) = y0
2. The system (8.30), like any other system
of ordinary differential equations, can be written in vector form
y′(t) = f(t, y(t)),
t ∈(a, b] ,
y(a) = y0 ,
(8.31)
where y0 = (y0
1, y0
2),
y(t) =
y1(t)
y2(t)

and
f(t, y(t)) =
f1(t, y1(t), y2(t))
f2(t, y1(t), y2(t))

.
The application of the numerical methods to (8.31) follows the same formalism as in the case
of scalar equations. For example, given a uniform, temporal grid a = t0 < t1 < · · · < tN = b
the recursive algorithm of Euler’s method for system (8.31) is
yi+1 = yi + h f(t, yi),
i = 0, 1, . . . , N −1 ,
y0 = given ,
(8.32)
which is the same as the algorithm (8.7) with the difference that here instead of computing
scalar variables we compute vectors yi = (yi
1, yi
2) for the approximations yi
1 ≈y1(ti) and
yi
2 ≈y2(ti). One may want to write Euler’s method without using vectors. In such case
Euler’s method is written as
yi+1
1
= yi
1 + hf1(ti, yi
1, yi
2) ,
yi+1
2
= yi
2 + hf2(ti, yi
1, yi
2) ,
y0
1, y0
2 = given .
(8.33)

The Module scipy.integrate Again
307
In each step, each equation of (8.33) provides with a new approximation for each of the two
variables y1, y2 separately, while the vector form (8.32) will provide a vector containing the
same approximations of y1, y2.
The function solve ivp as one may observe from its description it can solve also systems
of ordinary differential equations. For more information, we refer the interested reader to
more specialized books on the subject. Some of them are listed in the further reading section.
8.4.3
Application in epidemiology
As an application of the previous derivations we present a mathematical model that de-
scribes to some extend the spread of an infectious disease such as the common flu or the
virus COVID-19 (SARS-CoV-2) in a population of N individuals. The particular model
consists of three ordinary differential equations and is known as compartmental model in
epidemiology, because the population is assigned to compartments with labels. In the simple
case we study here, we consider three compartments with labels S, I and R representing
the number of Susceptible, Infectious and Recovered parts of the population. This model is
called SIR model to emphasize the three different compartments.
In the SIR model, t is the elapsed time in days, S(t) is the number of susceptible indi-
viduals, I(t) is the number of infectious individuals that can infect susceptible individuals,
and R(t) is the number of recovered individuals that they are either immunized or deceased.
For sure the recovered population cannot get infected again. When, the susceptible individ-
uals S(t) come in contact with an infectious individual, then they become infectious. In our
simple example, we assume that the population remains constant, which can be translated
in mathematical language into
S(t) + I(t) + R(t) = constant = N .
If β is the average number of contacts per person per time, then the transition rate
between susceptible S and infectious I individuals is expressed as
S′ = −β
N SI .
The transition rate between infectious I and immunized R individuals is assumed to be
proportional to the number of infectious individuals, and in particular
R′ = γI ,
where γ = 1/D where D is the average time period in which an individual is infectious.
The requirement of the constancy of the population S + I + R = N leads to the law
S′ + I′ + R′ = 0 ,
which gives us the third ordinary differential equation
I′ = β
N SI −γI .
Defining the solution vector y(t) = (S(t), I(t), R(t))T , we write the SIR model as a
system
y′ = f(t, y)
where
f(t, y) =


−β
N SI ,
β
N SI −γI
γI

.
(8.34)

308
Numerical Differentiation and Applications to Differential Equations
Susceptible
Infectious
Recovered
FIGURE 8.3
Schematic representation of the simplest SIR model.
The relation between the unknowns S, I and R is depicted schematically in Figure 8.3.
Note that the third equation is not necessary for the computation of the quantities S
and I as the first two equations are not coupled with the third. The reason for keeping it
into the equations is for simplicity, because otherwise we would need to solve this equation
separately after the computation of the unknowns S and I.
The system (8.34) is nonlinear, and in order to solve it we will use the function solve -
ivp of the module scipy.integrate. To test our code we consider the population of an
isolated country with N = 4, 000, 000, and an infectious disease that is characterized by the
parameters β = 0.350 and γ = 0.035. As initial conditions to our initial-value problem we
consider S(0) = N −1, I(0) = 1 and R(0) = 0, in the sense that initially there is one case
of an infection in the whole population.
1
# Define the right-hand side and input parameters
2
def f(t, y, beta, gamma, N):
3
z = np.zeros(3)
4
z[0]=-beta/N * y[0] * y[1]
5
z[1]= beta/N * y[0] * y[1] - gamma * y[1]
6
z[2]= gamma * y[1]
7
return z
8
beta = 0.35; gamma = 0.035
9
N = 4.e+6; a = 0.0; b = 200.0; tspan = [a, b]
10
y0 = [N-1, 1, 0]
11
args1=(beta, gamma, N)
12
# Solve the ODE
13
sol1 = solve_ivp(f, tspan, y0, 'RK45', args=args1, rtol=1.e-6)
14
# Plot the results
15
fig = plt.figure()
16
axes = fig.add_subplot(1, 1, 1)
17
axes.plot(sol1.t, sol1.y[0], label="S(t)")
18
axes.plot(sol1.t, sol1.y[1], label="I(t)")
19
axes.plot(sol1.t, sol1.y[2], label="R(t)")
20
axes.set_xlabel("t"); axes.set_ylabel("y"); axes.legend(loc=1); plt.show()

Further Reading
309
0
25
50
75
100
125
150
175
200
t
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0
y
1e6
S(t)
I(t)
R(t)
Using the simplified SIR model (8.34), and with the particular parameters, we can
predict that the population will be immunized by the disease in less than a year. Additional
parameters and factors must be considered for accurate predictions. An improvement of the
SIR model known as SIRD model is presented in the exercises.
8.5
Further Reading
The approximation of derivatives with finite differences is covered by almost all classic
textbooks in numerical analysis [25, 70, 76, 22, 26, 7, 108, 127]. A list of specialized books
on finite differences and on the numerical solution of differential equations includes the
following [44, 19, 121, 51, 36, 71, 55, 56, 54, 114, 83, 2, 82, 39]. An introduction to the
mathematical modeling of infectious diseases can be found in [15, 61].

Chapter Highlights
 First derivatives can be approximated using forward, backward and central
finite differences.
 The forward and backward finite differences are first-order accurate with error
O(h). The central finite difference approximation of the first derivative is
second-order accurate with error O(h2).
 Finite difference formulas can be obtained using Taylor expansions of functions
around appropriately chosen points.
 We can approximate second-order derivatives with finite differences such as
f ′′(x0) ≈f(x0 + h) −2f(x0) + f(x0 −h)
h2
,
which is second-order accurate with error O(h2).
 Given an approximation formula that depends on h, one can obtain improved
approximations using Richardson’s extrapolation.
 Given an initial value problem y′(t) = f(t, y(t)), t ∈(a, b] with initial condition
y(a) = y0, a numerical approximation yi ≈y(ti) at the nodes
a = t0 < t1 < · · · < tN = b with uniform distance h = ti+1 −ti can be
computed using Euler’s method
yi+1 = yi + hf(ti, yi),
i = 0, 1, . . . , N −1 .
 The local truncation error is defined as the error between the approximate
solution yi+1 and the exact solution of the differential equation y(ti+1) when
yi = y(ti) is exact.
 The global error is the error between the numerical solution yi+1 and the exact
solution y(ti+1).
 The local error in Euler’s method is O(h2) while the global error is O(h).
 More sophisticated methods such as Runge-Kutta methods can result in more
accurate numerical approximations of ordinary differential equations.
 If the solution of the differential equation varies rapidly, then the system is
characterized as stiff.
 We usually solve stiff ordinary differential equations using implicit numerical
methods.
 Mathematical modeling of infectious diseases relies on ordinary differential
equations. The SIR model is a simple compartmental model that describes the
spread of an infectious disease.
 An SIR model divides the population in three compartments, Susceptible (S),
Infectious (I) and Recovered (R) individuals and is a coupled system of three
first order ordinary differential equations.
310

Exercises
1. Consider a smooth function f(x) defined on R and x0 ∈R.
(a) Using appropriate Taylor expansions of the function f and a parameter h, find a
finite difference approximation of the first derivative f ′(x0) in the form
f ′(x0) ≈f(x0 −2h) −8f(x0 −h) + 8f(x0 + h) + f(x0 + 2h)
12h
.
(b) Determine the order of accuracy of your finite difference approximation.
2. Consider a smooth function f(x) defined on R and x0 ∈R.
(a) Using appropriate Taylor expansions of the function f and a parameter h, find a
finite difference approximation of the first derivative f ′(x0) in the form
f ′(x0) ≈3f(x0) −4f(x0 −h) + f(x0 −2h)
2h
.
(b) Determine the order of accuracy of your finite difference approximation.
(c) Derive the same formula using Richardson’s extrapolation method and the backward
finite difference approximation of first order.
3. Consider a smooth function f(x) defined on R and x0 ∈R.
(a) Using appropriate Taylor expansions of the function f and a parameter h, find a
finite difference approximation of the first derivative f ′(x0) in the form
f ′(x0) ≈−3f(x0) + 4f(x0 + h) −f(x0 + 2h)
2h
.
(b) Determine the order of accuracy of your finite difference approximation.
(c) Derive the same formula using Richardson’s extrapolation method and the forward
finite difference approximation of first order.
4. Consider the function f(x) = sin(πx) and the values h = 0.2, 0.1, 0.05, 0.01, 0.005, 0.001,
0.0005, 0.0001.
(a) Write a Python program to approximate the derivative f ′(x0) for x0 = 0.4 with
central, forward and backward differences for all values of the parameter h.
(b) In addition to the previous approximations consider the finite difference approxi-
mation
Dℓf(x0) = f(x0 −2h) −8f(x0 −h) + 8f(x0 + h) −f(x0 + 2h)
12h
,
(c) Let p be the convergence rate of such that |Dℓf(x0) −f ′(x0)| ≤Chp. Estimate
numerically the convergence rate p for each of the previous finite difference ap-
proximations: Consider a given function f(x) and values h = h1, h2, . . . hn with
hi+1 < hi. Compute the approximation Dℓf(x) of the derivative f ′(x) and then
compute the error Ei = |f ′(x) −Dℓf(x)| for each hi. This error must be Ei = Chp
i .
Dividing the values Ei and Ei+1 we compute the fraction
Ei/Ei+1 = (hi/hi+1)p
311

and then with the help of logarithms we solve for p to obtain
p = log(Ei/Ei+1)
log(hi/hi+1) .
Estimate the convergence rate p with x0 = 0.4 and x0 = 1.0.
(d) Repeat the previous question to estimate the convergence rate of the forward, back-
ward and central finite differences.
(e) What do you observe?
5. Repeat the procedure of the previous question to approximate the second derivative of
the function f(x) = sin(πx) at x0 = 0.4 using the finite difference approximation
f ′′(x0) ≈f(x0 + h) −2f(x0) + f(x0 −h)
h2
.
6. Consider a finite difference approximation of the first derivative f ′(x0) of the form
f ′(x0) ≈a f(x0) + b f(x0 + h) + c f(x0 + 2h) ,
for a small value of h. We say that a finite difference formula is exact for polynomials
p(x) for degree r if the previous approximation is exact
p′(x0) = a p(x0) + b p(x0 + h) + c p(x0 + 2h) .
(a) Show that the previous finite difference approximation is exact for quadratic poly-
nomials if and only if it is exact for the monomials 1, x and x2.
(b) Find the values a, b and c so that the specific finite difference approximation is exact
for quadratic polynomials.
7. In this problem you will practice complex number arithmetic in Python. Consider a real
function f ∈C3[a, b] and assume that we want to approximate the derivative f ′(x0)
with high accuracy. For this reason, we consider the small step parameter hi = 10−i for
i = 1, 2, . . . , 300.
(a) Given 0 < h < 1 define an approximation of the first derivative to be
Dif(x0) = Im[f(x0 + ih)]
h
,
where i denotes the imaginary unit, and Im is the imaginary part of a complex
number. Prove that there is a ξ ∈[a, b] such that for x0 ∈[a, b]
|f ′(x0) −Dif(x0)| ≤|f (3)(ξ)|
6
h2 .
(b) Write a Python function to implement the approximate formula Dif of the first
derivative.
(c) Consider the function
f(x) =
ex
sin3 x + cos3 x ,
and its derivative f ′(x). Compute the approximations of f ′(1.5) for all values of
h = hi, i = 1, 2, . . . , 300 and plot a graph of the error as a function of h. Determine
what is the optimal value hi which can be used in this method.
312

(d) For the same values of h, compute the central approximation of the derivative Dcf
and compare the errors. Determine again what is the optimal value hi that can be
used in the central difference formula.
(e) Explain the differences between the two methods, and also the various phenomena
you observe.
[The approximation of the derivative in this problem is known to as the complex-step
derivative approximation. For more information, we refer to the publications [123, 85]]
8. Write the composite trapezoidal rule for the integration of a function f(x) over an interval
[a, b] as
I[f] = IN[f] + EN[f] ,
where I[f] is the exact value of the integral, IN[f] is the quadrature rule and EN[f] is
the error given by the formula
EN[f] = −(b −a)h2
12
f ′′(ξ) ,
where h = (b −a)/N.
(a) Using Richardson’s extrapolation consider two values N1 and N2 such that N1 =
2N2 and eliminate the error to obtain the Romberg’s quadrature formula
I[f] = 4
3IN2[f] −1
3IN1[f] .
(b) Implement this improved quadrature formula in a Python function and test your
code using the integral
Z 1
0
e−x2 dx = √π/2 .
(c) Estimate by numerical means the order of convergence of Romberg’s quadrature
formula.
9. This exercise is based on the work [52]. Let x, h ∈R, and
g(x) =
Z h
−h
tf(t + x) dt ,
with f ∈C4[x −h, x + h].
(a) Using Simpson’s rule show that
Z h
−h
tf(t + x) dt = h
3 [−hf(x −h) + hf(x + h)] + O(h5) .
(b) Using the central finite difference approximation formula
f ′(x) = f(x + h) −f(x −h)
2h
+ O(h2) ,
show that
f ′(x) ≈
3
2h3
Z h
−h
tf(x + t) dt ,
and estimate the error in the approximation.
313

(c) Write a Python code to approximate the function g(x) for x ∈[−1, 1] when f(x) =
ex2 implementing the previous approximations.
(d) Show that
Z h
−h
tf(t + x) dt = h2
Z 1
−1
uf(hu + x) du .
(e) Use Gauss-Legendre quadrature to approximate the same function g(x) as before.
10. Consider the initial value problem

d
dty(t) = f(t, y(t)),
a ≤t ≤b ,
y(a) = y0 ,
(8.35)
(a) Prove that the initial value problem with f(t, y) = y and y0 = 1 admits the exact
solution y(t) = et.
(b) Write a function Euler implementing Euler’s method to solve the specific initial-
value problem. The function should require as input the function f, the endpoints
a and b, the initial condition y0 and the temporal stepsize ∆t. It will return the
approximation of the solution at the points of the temporal partition in a vector y.
(c) Write similar functions to implement the improved and implicit Euler methods.
(d) Estimate the convergence rates of these methods experimentally. For this reason,
consider different values Ni and stepsize h = h1, h2, . . . , hn with hi+1 < hi, such
that hi = (b −a)/Ni. Compute the solution at tNi = b for all values of hi and also
the errors Ei = |yNi −y(tNi)|. Estimate the convergence rate using the formula
p = log(Ei/Ei+1)
log(hi/hi+1) .
11. For the initial value problem (8.35) consider a uniform grid a = t0 < t1 < · · · < tN = b
with h = ti+1−ti, and the trapezoidal method for the computation of the approximations
yi ≈y(ti):
yi+1 = yi + h
2 [f(ti+1, yi+1) + f(ti, yi)] ,
i = 0, 1, . . . , N −1 .
(a) Implement this method in Python to solve the problem with f(t, y) = y in [0, 2]
and y0 = 1.
(b) Estimate experimentally the convergence rate of the specific numerical method.
(c) Formulate the trapezoidal method as a Runge-Kutta method.
(d) Study the stability of the trapezoidal method and compare with that of implicit
Euler’s method.
(e) Devise an algorithm using Newton’s method for the solution of the resulting non-
linear equation in the trapezoidal method and compare with the improved Euler
(Heun) method.
12. Consider the initial value problem for the following system of ordinary differential equa-
tions
(
y′
1(t) = −y2(t) ,
y′
2(t) = y1(t) ,
t ≥0 ,
given that y1(0) = 1,
y2(0) = 0.
314

(a) Show that the following conservation of energy holds
(y1(t))2 + (y2(t))2 = 1,
for all
t ≥0 .
(b) Write the approximations (yi
1, yi
2), i = 1, 2, . . . of (explicit) Euler’s method and
show that (yi
1)2 + (yi
2)2 →∞as i →∞.
(c) Show that the analogous approximations (yi
1, yi
2) of the trapezoidal method (of the
Exercise 11) with constant stepsize h respects the conservation of energy (yi
1)2 +
(yi
2)2 = 1 for all i ≥1. This is an example of a symplectic method that preserves
quadratic invariants.
(d) What is the conservation properties of implicit Euler’s method for the same prob-
lem?
(e) Use the function solve ivp to solve the particular system experimenting with the
available methods for non-stiff problems. In all cases comment on the conservation
properties of these methods.
13. A metallic rod of length L = 1 m is heated by a heating source located at its center of
gravity. The endpoints of the rod are kept at 0◦C. If u(x) denotes the temperature of
the rod at location x, then it satisfies the ordinary differential equation
−u′′(x) + u(x) = (4π2 + 1) sin(2πx) ,
which accompanied with the boundary conditions
u(0) = u(1) = 0 ,
forms a two-point boundary-value problem.
(a) To find approximations to this problem first consider a uniform grid of the interval
[0, 1] of points xi+1 = xi + h for i = 0, 1, . . . , N −1 with x0 = 0 and h = 1/N. Then
using the second order formula for the second derivative
u′′(xi) ≈u(xi−1) −2u(xi) + u(xi+1)
h2
,
and given that u(x0) = u(xN) = 0 derive a linear systems of equations Au = b
where
u =
 U1
U2
· · ·
UN−1
T ,
for the approximation Ui ≈u(xi).
(b) Write a Python function to solve this problem and perform experiments with various
values of N.
(c) Verify that the function u(x) = sin(2πx) satisfies the two-point boundary value
problem.
(d) Compute maximum error between the numerical and analytical solution at the
nodes xi such as
EN = max
0≤i≤N |Ui −u(xi)| .
(e) Estimate the convergence rate and show that EN ≤Ch2 for some constant C > 0
independent of h.
315

14. A significant drawback of the simple SIR model is that we consider the deceased individ-
uals as recovered. An extension of SIR model that distinguishes the two cases is called
SIRD model and includes an additional compartment D for the deceased individuals.
The SIRD system reads
S′ = −β
N IS ,
I′ = β
N IS −γI −µI ,
R′ = γI ,
D′ = µI ,
(8.36)
where β, γ, µ are the infection, recovered and deceased rates, respectively.
(a) Write a computer code in Python that solves system (8.36).
(b) Using β = 0.35, γ = 0.035 and µ = 0.1 and the initial conditions
(S, I, R, D) = (N, 1, 0, 0) ,
solve system (8.36) and predict the death rate of the diseased in a population of
N = 4, 000, 000 individuals.
(c) Try different parameters β and µ to minimize the death rate.
316

9
Numerical Linear Algebra
Numerical linear algebra is the branch of numerical analysis that focuses on the development
of methods and algorithms for solving problems with matrices such as the solution of linear
systems. It is perhaps the most useful branch of numerical analysis since the solution of
linear systems is a major issue in most engineering applications. It is remarkable that even
the solution of nonlinear systems of equations may require the solution of linear systems.
For example, as we saw in Section 5.5.6, Newton’s method for nonlinear systems requires
the solution of a linear system of equations at every iteration. In this chapter, we will limit
the presentation to some direct and iterative methods for the numerical solution of linear
systems. We start with the most popular and basic method, the Gaussian elimination.
9.1
Numerical Solution of Linear Systems
A general system of linear equations (simultaneous equations) can be expressed as
a11 x1 + a12 x2 + · · · + a1n xn = b1 ,
a21 x1 + a22 x2 + · · · + a2n xn = b2 ,
...
an1 x1 + an2 x2 + · · · + ann xn = bn .
The constant coefficients aij for each i, j = 1, 2, . . . , n, and bj for each j = 1, 2, . . . , n of this
system are assumed to be given, and we need to find the unknowns x1, x2, . . . , xn. Computer
languages, though, have not been equipped with structures to store a linear system other
than matrices and vectors. Fortunately, a linear system can be expressed in matrix-vector
form Ax = b where
A =





a11
a12
· · ·
a1n
a21
a22
· · ·
a2n
...
...
...
an1
an2
· · ·
ann




,
is the coefficient matrix, x =
 x1
x2
· · ·
xn
T is the solution of the linear system, and
the vector b =
 b1
b2
· · ·
bn
T is the right-hand side.
In order to develop a numerical method to solve linear systems we must first revise the
method of Gaussian1 elimination. Gaussian elimination (also known as forward elimination
or row reduction) is a direct method used to transform a linear system into an upper triangu-
lar system, in the sense that the resulting coefficient matrix A is upper triangular. A direct
1The Gaussian elimination method is named after the German mathematician and physicist Johann Carl
Friedrich Gauss (1777–1855)
DOI: 10.1201/9781003287292-9
317

318
Numerical Linear Algebra
method is a numerical method to compute the exact solution (not an approximation like
Newton’s method) when exact arithmetic is being used. On the contrary, iterative methods
(such as Newton’s method) generate an approximation to the solution of the linear system.
Performing Gaussian elimination to a linear system Ax = b with a non-singular matrix
A, (det(A) ̸= 0), we transform the system into a new system Ux = c where
U =





u11
u12
· · ·
u1n
0
u22
· · ·
u2n
...
...
...
0
0
· · ·
unn




,
with uii ̸= 0 for i = 1, 2, . . . , n. The new system Ux = c apparently has the same solution as
the system Ax = b regardless that U is not the same as A. It is noted that the right-hand
side b is also transformed in a new right-hand side c. In the end, we can solve the system
Ux = c easily using backward substitution. The best way to understand this method is
with an example, but first we present the methodology in its full generality. Therefore, we
first describe the steps of the Gaussian elimination applied to the following linear system
of equations
E1 :
a11 x1 + a12 x2 + · · · + a1n xn = b1 ,
E2 :
a21 x1 + a22 x2 + · · · + a2n xn = b2 ,
...
En :
an1 x1 + an2 x2 + · · · + ann xn = bn ,
where we denote the i-th equation by Ei for simplicity.
Gaussian elimination is based on three linear operations that lead to equivalent systems
of equations, in the sense that the resulting system has the same solution as the original
one. We call these operations basic. These basic operations are the following:
 We can multiply any equation with a non-zero number. For example, equation Ei can
be multiplied by any non-zero constant λ with the resulting equation used in place of
Ei. This operation is denoted (λEi) →(Ei).
 We can add a multiple of one equation to another equation. For example, equation Ej
can be multiplied with any constant λ and added to equation Ei. This operation is
denoted (Ei + λEj) →(Ei).
 We can swap two equations. For example, equation Ei and Ej can exchange places in
the system. This operation is denoted (Ei) ↔(Ej).
We use the basic operations to eliminate columns and transform the coefficients of the
low-trangular part of the original system into zeros. In particular, we use these operations
to eliminate all the entries aij with j < i, i.e. all the entries under the main diagonal of
the corresponding coefficient matrix. For example, in order to eliminate the entry a21 we
need to multiply the first equation with a21/a11 and subtract the result from the second
equation. The resulting equation replaces the second equation E2 and we say that we have
eliminated the entry a21. This operation is expressed as
(E2 −(a21/a11) E1) →(E2) .
For example, consider the linear system
E1 :
x1
+x2
=
2 ,
E2 :
2x1
+x2
−x3
=
2 ,
E3 :
3x1
−x2
−x3
=
1 .

Numerical Solution of Linear Systems
319
First we use equation E1 to eliminate the unknown x1 from equations E2 and E3 by per-
forming the basic operations
(E2 −2E1) →(E2) ,
(E3 −3E1) →(E3) .
The first operation eliminates the unknown x1 from equation E2, and the second from
equation E3. This step will eliminate only the coefficients of the unknown x1 stored in the
first column of the coefficient matrix A. This leads to the equivalent new system
E1 :
x1
+x2
=
2
E2 :
−x2
−x3
=
−2
E3 :
−4x2
−x3
=
−5
(9.1)
After eliminating the first column we do not use E1 again to avoid destroying what we
have achieved so far. Subsequently, E2 is used to eliminate the unknown x2 from E3 by
performing the basic operation
(E3 −4E2) →(E3) ,
to obtain the equivalent system
E1 :
x1
+x2
=
2
E2 :
−x2
−x3
=
−2
E3 :
3x3
=
3
(9.2)
After applying the permitted linear transformations, the new system is in the form of an
upper triangular system. The later system of equations is written in triangular (or reduced)
form and can be solved for the unknowns by a backward substitution process: We solve the
equation E3 for x3 dividing by 3 to obtain x3 = 1. Then we substitute the solution x3 = 1
into E2 and we solve for x2 to obtain x2 = 1. We substitute the values of x2 and x3 into E1
and solve for x1 = 1. The solution vector we found is the vector
x =


1
1
1

.
By performing all the previous linear transformations to the original linear system we didn’t
alter the unknowns xi, and the solution we found is the correct one.

Observe that each entry of the right-hand side of the previous linear system is
the sum of the coefficients of the corresponding equation. Such a linear system has
solution 1 for each unknown. To see this consider its matrix-vector form and think
of the multiplication Ax with x a vector full of ones.
The same linear transformations, and therefore Gaussian elimination, can be applied to
the coefficient matrix A and the right hand side b of the linear system. This is important
because the implementation of any linear algebra algorithm in any programming language
will involve matrices and not linear equations. For theoretical purposes, and when we work
with pen and paper, we usually combine the coefficient matrix A and right-hand side b
together into the augmented matrix (A|b). This is done by merging the right-hand side to
a new (n + 1)-th column in the matrix A separated with a vertical line. For example, the
augmented matrix of the previous linear system is the matrix
(A|b)
=


1
1
0
2
2
1
−1
2
3
−1
−1
1

.

320
Numerical Linear Algebra
When we apply the linear transformations to the augmented matrix, we use the rows of the
augmented matrix instead of equations. For this reason, we call the basic operations of the
Gaussian elimination row operations. If the i-th row of the augmented matrix is denoted by
Ri, then the basic row operations to eliminate the first column in the previous example will
be
(R2 −2R1) →(R2) ,
(R3 −3R1) →(R3) .
The resulting augmented matrix (with eliminated first column) will contain the coefficients
of the reduced linear system (9.1)


1
1
0
2
0
−1
−1
−2
0
−4
−1
−5

.
The corresponding row operations for eliminating the second column of the new augmented
matrix will be
(R3 −4R2) →(R3) ,
and the reduced augmented matrix that describes system (9.2) will be


1
1
0
2
0
−1
−1
−2
0
0
3
3

.
We can denote the last matrix by (U|c) to indicate that A and b have been transformed
to an upper triangular matrix U and new right-hand side vector c.
Now we need to perform back substitution to the (transformed) upper triangular system
Ux = c to compute the unknown values xi. This can be done by writing the system Ux = c
in equations form
x1
+x2
=
2
−x2
−x3
=
−2
3x3
=
3
and then first solve the last equation x3 which gives x3 = 1. Solving the second equation
for x2 using x3 = 1 we obtain x2 = 1 and finally solving the first equations for x1 we obtain
x1 = 1.
9.1.1
Algorithm for the naive Gaussian elimination
Suppose that we store the coefficients of a linear system into a matrix A and vector b. The
previous elimination procedure can be formulated in the following steps: For eliminating
the k-th column for k = 1, . . . , n −1 (the n-th column is used to compute xn and is not
eliminated) we define the multipliers
mik = aik
akk
for
i = k + 1, . . . , n ,
and we perform the substitutions
aij ←aij −mikakj,
j = k, . . . , n,
bi ←bi −mikbk,
for
i = k + 1, . . . , n ,
where we modify the entries of A instead of using a new matrix U, and the same with vector
c, which is stored in vector b. This can save memory space, especially when the matrices are

Numerical Solution of Linear Systems
321
large. These steps are summarized using vectorized format in Algorithm 27. The multipliers
mik in Algorithm 27 are stored in a matrix M. This is not necessary though and one can
use a simple variable to store the individual multipliers locally in memory unless they are
required for later use. We will see that these multipliers can play an important role in
computations.
Algorithm 27 Naive Gaussian elimination
Given the arrays A and b the solution x replaces b
for k = 1 : n −1 do
for i = k + 1 : n do
M(i, k) = A(i, k)/A(k, k)
A(i, k : n) = A(i, k : n) −M(i, k) · A(k, k : n)
b(i) = b(i) −M(i, k) · b(k)
end for
end for
In order to formulate the backward substitution for upper triangular systems, we write
the reduced system Ux = c in equations form
a11x1 + a12x2 + · · · + ak1xk + · · · + an1xn = b1 ,
...
ak,kxk + ak,k+1xk+1 + · · · + aknxn = bk ,
...
annxn = bn .
The back substitution can be performed first by solving the last equation of the reduced
system for xn
xn = bn
ann
,
and then by computing the rest of the unknowns in a for loop using the formula
xk =
1
akk

bk −
n
X
j=k+1
akjxj


for
k = n −1, n −2, . . . , 1 .
The last formula can be derived by solving the k-th equation for xk. For the computation
of xk we only used the value bk for the current k. Since we do not use previous values bk−1,
then we can replace them with the values xk for memory economy. Taking into account this
observation we summarize the backward substitution in Algorithm 28.
Algorithm 28 Backward substitution for solving upper triangular systems
Given an upper triangular array A, the right-hand side b is replaced by the solution x
b(n) = b(n)/A(n, n)
for k = n −1 : 1 : −1 do
b(k) = (b(k) −A(k, k + 1 : n) · b(k + 1 : n)) / A(k, k)
end for

322
Numerical Linear Algebra

We use backward substitution to solve upper triangular systems. The corre-
sponding algorithm for lower triangular systems is called forward substitution. The
forward substitution algorithm is presented in detail in Algorithm 30.
We combine Algorithms 27 and 28 in a Python function Gauss elimination. Note that
algorithms are usually presented with natural indices while the implementation takes into
account the Python indexing conventions. Taking as input the arrays A and b, the function
Gauss elimination returns the solution of the corresponding linear system stored in the
variable b.
1
def Gauss_elimination(A,b):
2
n = len(b)
3
# Gaussian elimination
4
for k in range(n-1):
5
for i in range(k+1,n):
6
if A[k,k]!=0.0:
7
mik=A[i,k]/A[k,k]
8
A[i,k+1:n] = A[i,k+1:n] - mik * A[k,k+1:n]
9
b[i] = b[i] - mik * b[k]
10
# backward substitution
11
for k in range(n-1,-1,-1):
12
b[k] = (b[k]-np.dot(A[k,k+1:n],b[k+1:n]))/A[k,k]
13
return b
We test our code in solving the linear system Ax = b of the previous section. Because the
function Gauss elimination alters the arrays A and b we call it with arguments A.copy()
and b.copy(), respectively. This will leave the arrays A and b unaltered for further use,
while inside the function new unrelated copies will be modified. In other situations we would
prefer to overate A and b for memory economy.
1
A = np.array([[ 1., 1., 0.],
2
[ 2., 1.,-1.],
3
[ 3.,-1.,-1.]])
4
b = np.array([ 2., 2., 1.])
5
x = Gauss_elimination( A.copy(), b.copy() )
6
print(x)
[1. 1. 1.]
It is worth mentioning that there are variants of Gaussian elimination for banded or
tridiagonal systems. An example of a tridiagonal algorithm can be found in the exercises.
Operations count
In Algorithm 27 we first compute the multipliers. Every time we compute a multiplier we
perform one division, and thus in total we need
n−1
X
k=1
(n −k) =
n−1
X
k=1
k = n(n −1)
2
,

Numerical Solution of Linear Systems
323
TABLE 9.1
Operations count for the Gaussian elimination and back substitution
Gaussian elimination
Multiplications
Additions
Divisions
Multipliers
n(n−1)
2
n −1
Elimination of A
n(n−1)(2n−1)
6
n(n−1)(2n−1)
6
Elimination of b
n(n−1)
2
n(n−1)
2
Back Substitution
n(n−1)
2
n(n−1)
2
n
Total
n(n−1)(n+4)
3
n(n−1)(2n+5)
6
2n −1
divisions. Because the denominator akk is common in n −k multipliers for k = 1, . . . , n −1,
it is faster to first compute the ratios 1/akk and then multiply them with aik. Thus, we can
have (n −1) divisions and n(n −1)/2 multiplications.
The second stage of the elimination algorithm requires
n−1
X
k=1
(n −k)2 =
n−1
X
k=1
k2 = n(n −1)(2n −1)
6
,
multiplications and the same amount of additions/subtractions. This is because of the three
nested loops. The computations of the right-hand sides bi are included in two nested loops.
Therefore, we require
n−1
X
k=1
(n −k) =
n−1
X
k=1
k = n(n −1)
2
,
multiplications and the same amount of additions (subtractions), as in the case of the
computation of multipliers.
The last stage of Gaussian elimination consists of the back substitution Algorithm 28,
which has two nested loops. The total number of multiplications is n(n −1)/2 with n
divisions and n(n −1)/2 subtractions. In the divisions we include also the computations of
the value bn, which is outside of the for loop.
The total number of the operations required by the Gaussian elimination and back
substitution is summarized in Table 9.1.

The total number of operations for a dense n × n matrix is O(n3). From these
operations O(n2) operations is the back substitution indicating that the most signif-
icant load is on the elimination process. Cramer’s rule for the solution of the same
linear system would require O((n + 1)!) operations. Therefore, Gaussian elimination
is considered one of the most efficient algorithms for the solution of general linear
systems.
9.1.2
LU factorization
Assume that we want to solve n linear systems with multiple right hand sides b but the
same matrix A. This situation is not rare. If we knew the various vectors b a priori, then we
could adjust the Algorithms 27 and 28 to perform elimination and back substitution with
matrix b instead of vector. But in the case where the various vectors b are not known from
the beginning, then we need to perform Gauss elimination on matrix A multiple times.
This doesn’t sound really efficient! We will spend O(n3) operations every time we call the
elimination function to perform the same thing. For this reason, we usually use the so-called

324
Numerical Linear Algebra
LU factorization (or decomposition). In general, factorizations of matrices help improving
the efficiency of algorithms as well as to understand matrix properties.
The LU factorization is an algorithm that factorizes a matrix A into a product of two
matrices using the elimination procedure. In particular, the result of the LU factorization
is a lower triangular matrix L and an upper triangular matrix U such that A = LU. In the
LU factorization the matrix U is the usual upper triangular matrix we receive as output
of the Gauss elimination, and L is lower triangular with the multipliers mik in its entries.
Below we show how we factorize A into a product LU.
To construct the LU factorization algorithm, we express every step k = 1, . . . , n −1 of
the elimination algorithm as
a(k+1)
ij
= a(k)
ij −mika(k)
kj ,
for
i = k, . . . , n,
j = k + 1, . . . , n ,
where the multipliers mik are defined as
mik = a(k)
ik
a(k)
kk
,
for
i = k + 1, . . . , n ,
and we do not compute the right-hand side entries bi. Here a(1)
ij = aij. We define the upper
triangular matrix U via
uij = a(n)
ij
for
i = 1, . . . , n
and
j = i, . . . , n ,
and zero elsewhere. This is the usual upper triangular matrix we construct with Gauss
elimination. The lower triangular matrix L is used to store the multipliers mik in its lower
triangular part
L =







1
0
0
· · ·
0
0
m21
1
0
· · ·
0
0
m31
m32
1
· · ·
0
0
...
...
...
...
...
mn1
mn2
mn3
· · ·
mn,n−1
1







.
The matrices L and U defined via the elimination process form a multiplicative factorization
of A = LU.

Performing the steps of Gaussian elimination we can derive the LU factorization
of a matrix A. Matrix L is a lower triangular matrix with 1 in the principal diagonal
and the multipliers stored in its lower triangular part lij = mij for j = 1, . . . , n −1
and i = j + 1, . . . , n. Matrix U is the usual upper triangular matrix resulting in the
Gaussian elimination. A lower (or upper) triangular matrix with ones in the main
diagonal is called unit lower (or upper) triangular matrix.
Now that we know how to write A as a product LU, we repeat the method of solving
a linear system of the form Ax = b given its LU factorization:
 Suppose that the factorization A = LU, where L and U are given lower and upper
triangular matrices, respectively.
 We can solve the system Ax = b for x as many times as we want by using the following
two steps:
– Set y = Ux and solve the lower triangular system Ly = b for y using forward
substitution. Since L is triangular, determining y requires only O(n2) operations.

Numerical Solution of Linear Systems
325
– Once y is known, solve the upper triangular system Ux = y using back substitu-
tion. This requires only an additional O(n2) operations to determine the solution
x.
 The number of operations needed to solve the system Ax = b using its LU factorization2
is reduced from O(n3) to O(n2).
For example, let us compute the LU factorization for the matrix A and solve the linear
system Ax = b where
A =


1
1
0
2
1
−1
3
−1
−1


and
b =


2
2
1

.
The Gaussian elimination consists of the row operations
(R2 −2R1) →(R2),
(R3 −3R1) →(R3),
(R3 −4R2) →(R3) .
The multipliers mij are stored in a matrix L, which combined with the upper triangular
matrix U produced by the Gaussian elimination comprise the LU factorization of A with
L =


1
0
0
2
1
0
3
4
1


and
U =


1
1
0
0
−1
−1
0
0
3

.
For economy in computer memory we can store matrices L and U in the entries of
matrix A excluding the main diagonal of matrix L which has only 1. For example, we can
store the previous matrices L and U in A as
A = (L U) =


1
1
0
2
−1
−1
3
4
3

.
To find the solution of the original system Ax = b, we first use forward substitution to
solve the system Ly = b


1
0
0
2
1
0
3
4
1




y1
y2
y3

=


2
2
1

.
Solving the first row for y1 and then moving to the second row for y2 and so on we have
y1 = 2 ,
2y1 + y2 = 2 ⇒y2 = 2 −2y1 = −2 ,
3y1 + 4y2 + y3 = 1 ⇒y3 = 1 −3y1 −4y2 = 3 .
Finally, we solve system Ux = y for the solution x. The system Ux = y can be written as


1
1
0
0
−1
−1
0
0
3




x1
x2
x3

=


2
−2
3

.
Using backward substitution we obtain x3 = 1, x2 = 1 and x1 = 1.
2Of course to obtain the LU factorization it requires O(n3) operations but we do it only once and for
all right-hand sides b.

326
Numerical Linear Algebra
LU factorization expressed with matrices
If we use the previous algorithm with input
A =


1
1
0
2
1
−1
3
−1
−1

,
this gives
L =


1
0
0
2
1
0
3
4
1


and
U =


1
1
0
0
−1
−1
0
0
3

.
We show how to express the LU factorization using matrices. We start with the elimination
of the first column. We store the multipliers with minus sign in its first column of a matrix
M1 with 1 in the main diagonal and 0 elsewhere
M1 =


1
0
0
−2
1
0
−3
0
1

.
Then the product M1A describes the elimination of the first column
M1A =


1
4
0
0
−1
−1
0
−4
−1

.
Likewise, we store the multipliers we used to eliminate the second column in a matrix M2
M2 =


1
0
0
0
1
0
0
−4
1

.
Then the matrix M2(M1A) describes the elimination of the second column of the matrix
M1A, which is the second stage of the Gaussian elimination with
M2(M1A) =


1
1
0
0
−1
−1
0
0
3

.
Now is obvious that U = M2M1A and L = (M2M1)−1 = M −1
1 M −1
2 . That is
M −1
1
=


1
0
0
2
1
0
3
0
1


and
M −1
2
=


1
0
0
0
1
0
0
4
1

,
and therefore
L = M −1
1 M −1
2
=


1
0
0
2
1
0
3
4
1

.
Taking this into consideration we have the following theorem:
Theorem 9.1 (Existence and uniqueness of LU factorization). If an upper triangular
matrix U can be found by Gaussian elimination from a matrix A without encountering
zero diagonal elements, then A has a unique LU factorization A = LU, where L is a low
triangular matrix with ones in the main diagonal.

Numerical Solution of Linear Systems
327
Proof. The Gaussian elimination is expressed as
U = Mn−1Mn−2 · · · M1A ,
where Mi is lower triangular matrix with ones in its main diagonal for all i = 1, . . . , n −1.
All these matrices Mi are invertible since all their diagonal entries of Mi are nonzero, and
thus det(Mi) = 1. Therefore, the matrix A can be written as
A = M −1
1 M −1
2
· · · M −1
n−1U = LU ,
which shows the existence of LU decomposition. To prove that this is unique, we assume
that there are two different LU decompositions of A
A = L1U1 = L2U2 .
Separating the lower and upper triangular matrices we have that L−1
2 L1 = U2U −1
1 . Since
the left-hand side is lower triangular and the right-hand side upper triangular (see Sections
2.2.8 and 2.2.9), we conclude that both products are equal to a diagonal matrix, let’s say D.
Moreover, the matrix D must be the n × n identity matrix I because the product L−1
2 L1
must have all the entries of the main diagonal equal to 1. We conclude that
L−1
2 L1 = U2U −1
1
= I ,
or equivalently that L1 = L2 and U1 = U2.
While this procedure can be generalized for any matrix A, apart from theoretical pur-
poses it serves no other purpose, and thus we move on with the implementation of the LU
factorization algorithm.
9.1.3
Implementation of LU factorization
The implementation of the LU factorization follows the same steps with the Gaussian
elimination of Algorithm 27 and is summarized in Algorithm 29.
Algorithm 29 LU factorization of a matrix A
for k = 1 : n −1 do
for i = k + 1 : n do
if A(k, k) ̸= 0 then
mik = A(i, k)/A(k, k)
A(i, k : n) = A(i, k : n) −mik · A(k, k : n)
A(i, k) = mik
end if
end for
end for
During the elimination process the upper triangular matrix U replaces the upper trian-
gular part of A, while the multipliers are stored in the lower triangular part. Specifically, in
the following implementation of the LU factorization we receive in the output the matrix
A = (L U) =


u11
u12
u13
l21
u22
u23
l31
l32
u33

.

328
Numerical Linear Algebra
This matrix contains the upper triangular matrix U and the lower triangular matrix L but
not the principal diagonal of L, which we know anyway that consists of ones.
The implementation of Algorithm 29 in Python could be the following:
1
def LU(A):
2
# LU factorization of matrix A
3
n = len(A)
4
for k in range(n-1):
5
for i in range(k+1,n):
6
if A[k,k] != 0.0:
7
mik = A[i,k]/A[k,k]
8
A[i,k+1:n] = A[i,k+1:n] - mik*A[k,k+1:n]
9
A[i,k] = mik
10
return A
Solving linear systems with LU factorization
We continue with the implementation of the algorithm for the solution of a linear system
Ax = b given the LU factorization of A. As we discussed before, in order to solve a system
Ax = b given that A = LU, we set Ux = y. Then, we first solve the system Ly = b
and then the system Ux = y. The solution of the system Ux = y is solved with backward
substitution (Algorithm 28).
The system Ly = b can be solved easily using forward substitution. We first write the
system Ly = b in the form of equations
l11y1 = b1 ,
l21y1 + l22y2 = b2 ,
...
lk1y1 + lk2y2 + · · · + lk,k−1yk−1 + lkkyk = bk ,
...
ln1y1 + ln2y2 + · · · + ln,k−1yk−1 + · · · + ln,n−1yn−1 + lnnyn = bn ,
Solving the k-th equation for yk yields the formula of forward substitution:
yk =

bk −
k−1
X
j=1
lkjyj

/lkk,
k = 1, 2, . . . , n .
The algorithm for the forward substitution for a general lower triangular matrix L is
summarized in Algorithm 30.
Algorithm 30 Forward substitution for solving lower triangular systems
Given the lower triangular array L, the right-hand side b of the system Ly = b the
solution y replaces b
b(1) = b(1)/L(1, 1)
for k = 2 : n do
b(k) = (b(k) −L(k, 1 : k −1) · b(1 : k −1)) / L(k, k)
end for

Pivoting Strategies
329
In practical implementations matrix L is stored in the lower triangular part of A, while
U in the upper triangular part of A. The diagonal entries lkk of L can be ignored because
they are all 1. A code for the solution of the system Ly = b is the following:
1
def solveLU(A,b):
2
# Solution of the linear system LUx=b
3
# matrix A contains the LU factorization of A
4
n = len(A)
5
# Solve the low triangular system Ly=b, note that L_ii = 1.0
6
for k in range(1,n):
7
b[k] = b[k] - np.dot(A[k,0:k],b[0:k])
8
# Solve the upper triangular system Ux=b
9
b[n-1] = b[n-1]/A[n-1,n-1]
10
for k in range(n-2,-1,-1):
11
b[k] = (b[k] - np.dot(A[k,k+1:n],b[k+1:n]))/A[k,k]
12
return b
In the next piece of code we use the above functions to generate the LU factorization of
the matrix
A =


1
1
0
2
1
−1
3
−1
−1

,
and then solve two systems with different right-hand sides b1 = (2, 2, 1)T and b2 = (4, 4, 2)T .
This is done by performing the LU factorization once and then forward and backward
substitutions twice for the solution of the two systems LUx = b1 and LUx = b2.
1
A = np.array([[ 1., 1., 0.],
2
[ 2., 1.,-1.],
3
[ 3.,-1.,-1.]])
4
b1 = np.array([ 2., 2., 1.])
5
b2 = np.array([ 4., 4., 2.])
6
# Perform LU factorization once
7
A = LU(A)
8
# Solve the first system using forward/backward substitution
9
x1 = solveLU(A,b1)
10
print(x1)
11
#Solve the second system using forward/backward substitution
12
x2 = solveLU(A,b2)
13
print(x2)
[1. 1. 1.]
[2. 2. 2.]
9.2
Pivoting Strategies
In the previous discussions we assumed that the diagonal entries a(k)
kk in the elimination of A
are not zero. Thus, we were able to compute the multipliers without issues. These diagonal
entries are called pivots and play an important role in achieving stable and accurate results

330
Numerical Linear Algebra
in Gaussian elimination. There are cases where the naive Gaussian elimination fails because
A is nearly singular (nearly non-invertible with a tiny determinant) or A is such that
floating point arithmetic leads to wrong solutions3. For example consider a linear system
with one of the matrices
A1 =

0
1
1
1

or
A2 =

10−17
1
1
1

.
In the case of A1 since a11 = 0 we cannot perform even the first step of the Gaussian
elimination. In the second case, let us try to solve using our Gauss elimination function
the system A2x = b with b = (1, 2)T . The specific system has exact solution x ≈(1, 1),
but our code returns x=[0., 1.], which contains a huge error of O(1).
1
A = np.array([[ 1.e-17, 1.],
2
[ 1., 1.]])
3
b = np.array([ 1., 2.])
4
x = Gauss_elimination(A,b)
5
print(x)
[0. 1.]
To correct these problems we change the order of the equations. In the case of the
system A2x = b instead of solving the original system we can solve the system where the
first equation becomes second, and the second first

1
1
10−17
1
 x1
x2

=
2
1

,
1
A = np.array([[ 1., 1.],
2
[ 1.e-17, 1.]])
3
b = np.array([ 2., 1.])
4
x = Gauss_elimination(A,b)
5
print(x)
[1. 1.]
Observe that after changing the order of the rows in the matrix A2 and vector b the solution
is more accurate. This is the way to solve systems with matrix A1 as well. This technique
is called pivoting and is described briefly in the next section.

Gaussian elimination is an unstable algorithm in the sense that small perturba-
tion of the data (entries of A or b) can lead to a totally different solution. Thus, it
is very dangerous to perform the naive Gaussian elimination algorithm when we use
computers because of errors due to finite precision arithmetic. On the other hand,
the forward and backward substitution algorithms are stable [64].
3For more information see [42].

Pivoting Strategies
331
9.2.1
Gaussian elimination with partial pivoting
The simplest pivoting strategy at stage k of the Gaussian elimination is to select the entry
of the k-th column of the augmented matrix with the largest absolute value below the main
diagonal (let’s say p-th row), and swap rows k and p. This can be described algorithmically
as: At stage k of the outer loop of the Gaussian elimination
 We determine the smallest p ≥k such that
|apk| = max
k≤i≤n |aik|
 Interchange rows k and p
(Rk) ↔(Rp)
No interchange of columns is used in this case. This is the reason that the specific pivoting
strategy is called partial pivoting. There is a column pivoting strategy where we proceed as
in the row pivoting but interchanging columns instead.
A Python code in vector form for swapping rows fast can be implemented as follows,
1
def rowSwap(v,i,j):
2
if len(v.shape) == 1:
3
v[i],v[j] = v[j],v[i]
4
else:
5
v[[i,j],:] = v[[j,i],:]
A modification of the Gaussian elimination with partial pivoting in Python can be the
following:
1
def pGauss_elimination(A,b,tol=1.0e-15):
2
n = len(b)
3
for k in range(n-1):
4
# swap rows if necessary
5
p = np.argmax(np.abs(A[k:n,k])) + k
6
if np.abs(A[p,k]) < tol:
7
error.err('singular matrix has been detected')
8
if p != k:
9
rowSwap(b,k,p)
10
rowSwap(A,k,p)
11
# perform Gauss elimination
12
for i in range(k+1,n):
13
if A[k,k] != 0.0:
14
mik = A[i,k]/A[k,k]
15
A[i,k+1:n] = A[i,k+1:n] - mik*A[k,k+1:n]
16
b[i] = b[i] - mik*b[k]
17
# check if the matrix is singular
18
if np.abs(A[n-1,n-1]) < tol:
19
error.err('singular matrix has been detected')
20
# perform backward substitution
21
b[n-1] = b[n-1]/A[n-1,n-1]
22
for k in range(n-2,-1,-1):
23
b[k] = (b[k] -np.dot(A[k,k+1:n],b[k+1:n]))/A[k,k]
24
return b

332
Numerical Linear Algebra
Note that the previous algorithm uses a tolerance tol to detect tiny entries on the main
diagonal. Now using the Gaussian elimination with partial pivoting to the system A1x = b
with b = (1, 2)T we get
1
A = np.array([[ 0., 1.],
2
[ 1., 1.]])
3
b = np.array([ 1., 2.])
4
x = pGauss_elimination(A,b)
5
print(x)
[1. 1.]
This is the correct answer, and the row interchange happened automatically inside the
function pGauss elimination.
Scaled partial pivoting
In addition to partial pivoting there is a scaled partial pivoting (or scaled-column pivoting)
algorithm. Scaled partial pivoting is needed when equations and unknowns are scaled dif-
ferently. An example is the previous system with matrix A2. In this case, you may select
row pivots relative to the scale factors:
 Before factorization select scale factors
si = max
1≤j≤n |aij|,
i = 1, . . . , n
 At stage i of the factorization, select p such that

apk
sp
 = max
k≤i≤n

aik
si

 Interchange rows k and p
(Rk) ↔(Rp).
We leave the implementation of this as an exercise to the reader. This can also be found
in the book [78]. In addition to partial pivoting, the complete pivoting technique can be
considered as the ultimate pivoting technique.
Complete pivoting
Complete pivoting is a more exhaustive procedure and less common than partial pivoting,
in which the largest entry of the entire unreduced matrix is transferred into a pivoting
position. In this case, we perform interchanges in columns and rows during the elimination
process. This can be described briefly by the following steps: Choose row r and column c
as follows:
 Find r, c such as
|arc| =
max
i≤k,l≤n |akl|
 Interchange rows i and r and columns i and c

Complete pivoting technique is avoided in practice because it can slow down
the elimination process. On the other hand, partial pivoting is so common that it is
a default procedure in Gaussian elimination and LU factorization.

Pivoting Strategies
333
9.2.2
LU factorization with pivoting
Further to the failure of Gaussian elimination due to problematic pivots, LU factorization
fails in the same way due to its equivalence with the Gaussian elimination. For this reason,
we incorporate partial pivoting in the LU factorization too. First we define permutation
matrices to express row (or column) interchanges. A permutation matrix P is an identity
matrix with its rows or columns interchanged. Multiplication of a matrix A with a permu-
tation matrix P is equivalent with interchanging rows (or columns) of A. For example, if
we want to interchange rows 1 and 3 of a matrix
A =


a11
a12
a13
a21
a22
a23
a31
a32
a33

,
then we can multiply A with the permutation matrix
P =


0
0
1
0
1
0
1
0
0

,
obtained from the identity matrix by swapping the first and third rows. This is
P A =


0
0
1
0
1
0
1
0
0

·


a11
a12
a13
a21
a22
a23
a31
a32
a33

=


a31
a32
a33
a21
a22
a23
a11
a12
a13

.

A permutation matrix is a row-permutation of the identity matrix, and P −1 =
P T .
The Gaussian elimination algorithm was modified appropriately (with minor changes)
to accomodate pivoting techniques. Based on the following theorem we can do the same
with the LU factorization.
Theorem 9.2. For any n × n matrix A of rank n, there is a reordering of rows such that
P A = LU ,
where P is a permutation matrix that reorders the rows of A.
We demonstrate the LU factorization with partial pivoting for the matrix
A =


3
17
10
2
4
−2
6
18
−12

.
As it is required by the partial pivoting technique, we choose for the first step the entry of
the first column with the largest magnitude. We thus need to swap rows 1 and 3 since the
entry with the maximum magnitude in first column is the entry 6. This row interchange
can be represented by the matrix
P1 =


0
0
1
0
1
0
1
0
0

.

334
Numerical Linear Algebra
Thus, we eliminate initially the first column of matrix
P1A =


0
0
1
0
1
0
1
0
0

·


3
17
10
2
4
−2
6
18
−12

=


6
18
−12
2
4
−2
3
17
10

,
using the row operations (R2 −1/3 R1) →(R2) and (R3 −1/2 R1) →(R3) to obtain the
reduced matrix A(1) = M1P1A where
A(1) =


6
18
−12
0
−2
2
0
8
16


and
M1 =


1
0
0
−1/3
1
0
−1/2
0
1

.
Next, we need to eliminate the second column of this matrix, but using partial pivoting we
perform the interchange of rows 2 and 3 described by the permutation matrix
P2 =


1
0
0
0
0
1
0
1
0

.
We perform the elimination of the second column of the matrix
P2A(1) =


1
0
0
0
0
1
0
1
0

·


6
18
−12
0
8
16
0
−2
2

,
using the row operation (R3 + 1/4 R2) →(R3) to obtain at the end of the procedure
A(2) = M2P2A(1) where
A(2) =


6
18
−12
0
8
16
0
0
6


and
M2 =


1
0
0
0
1
0
0
1/4
1

.
If we write M = M2P2M1P1, then U = A(2) = MA and the LU factorization with
partial pivoting returns the matrices
L =


1
0
0
1/2
1
0
1/3
−1/4
1


and
U =


6
18
−12
0
8
16
0
0
6

.
Taking
P = P2P1 =


0
0
1
1
0
0
0
1
0

,
we have the factorization P A = LU


0
0
1
1
0
0
0
1
0




3
17
10
2
4
−2
6
18
−12

=


1
0
0
1/2
1
0
1/3
−1/4
1




6
18
−12
0
8
16
0
0
6

.
In general, L contains the permutations of the rows and is the matrix
L = P (Mn−1Pn−1 · · · M2P2M1P1)−1 ,
where
P = Pn−1 · · · P2P1 .

Pivoting Strategies
335

The matrices L and U in the P A = LU factorization with pivoting are not
the same as in the A = LU factorization without pivoting.
It is important to keep a record of the row interchanges in order to formulate the
permutation matrix P . The permutation matrix P is sparse and it is not good practice
to store its zero entries. In practice we store only the interchanges using a vector perm.
Initially, the vector perm is (0, 1, 2, . . . , n)T (in Python indices). Whenever two rows are
interchanged, the corresponding interchange is also carried out in the vector perm. Thus,
the vector perm contains the order in which the original rows have been rearranged. This
information is passed on to the solution phase (solveLU), by rearranging the entries of the
constant vector in the same order before proceeding to forward and backward substitutions.
The algorithm of the LU factorization with partial pivoting is summarized in Algorithm
31
Algorithm 31 LU factorization with partial pivoting
Given the array A
for k = 1 : n −1 do
Find p such that |A(p, k)| = maxk≤p≤n |A(k : n, k)|
Swap rows A(k, :) ↔A(p, :)
Swap rows perm(k) ↔perm(p)
for i = k + 1 : n do
if A(i, k) ̸= 0 then
mik = A(i, k)/A(k, k)
A(i, k + 1 : n) = A(i, k + 1, n) −mik · A(k, k + 1 : n)
A(i, k) = mik
end if
end for
end for
The implementation of the LU factorization with partial pivoting in Python is the same
as the Gaussian elimination with partial pivoting with the only difference that we keep a
record of the permutations.
1
def LUpivot(A,tol=1.0e-15):
2
n = len(A)
3
# define permutation vector
4
perm = np.array(range(n))
5
for k in range(0,n-1):
6
# perform row interchange if necessary
7
p = np.argmax(np.abs(A[k:n,k])) + k
8
if np.abs(A[p,k]) < tol:
9
error.err('singular matrix has been detected')
10
if p != k:
11
swapRows(A,k,p)
12
swapRows(perm,k,p)
13
# perform Gauss elimination
14
for i in range(k+1,n):
15
if A[i,k] != 0.0:

336
Numerical Linear Algebra
16
mik = A[i,k]/A[k,k]
17
A[i,k+1:n] = A[i,k+1:n] - mik*A[k,k+1:n]
18
A[i,k] = mik
19
return A, perm
In order to solve a linear system Ax = b using LU factorization with partial pivoting,
we multiply both sides of the system with P to obtain LUx = P b since P A = LU. Then
we perform the usual steps of forward and backward substitution to the vector P b instead
of b. The implementation could be the following:
1
def solveLUpivot(A,b,perm):
2
n = len(A)
3
# Store right-hand side in solution vector x
4
x = b.copy()
5
for i in range(n):
6
x[i]=b[perm[i]]
7
# Forward-backward substitution
8
for k in range(1,n):
9
x[k] = x[k] - np.dot(A[k,0:k],x[0:k])
10
x[n-1] = x[n-1]/A[n-1,n-1]
11
for k in range(n-2,-1,-1):
12
x[k] = (x[k] - np.dot(A[k,k+1:n],x[k+1:n]))/A[k,k]
13
return x
Testing these programs using the system Ax = b with
A =


3
17
10
2
4
−2
6
18
−12


and
b =


30
4
12

,
we have:
1
A = np.array([[ 3., 17., 10.],
2
[ 2., 4.,-2.],
3
[ 6.,18.,-12.]])
4
b = np.array([ 30., 4., 12.])
5
[A,perm] = LUPivot(A)
6
x = solveLUpivot(A,b,perm)
7
print(x)
[1. 1. 1.]
In order to verify the result we perform some extra computations to retrieve the matrices
P , L and U from the output of our functions.
1
# construct lower triangular matrix L
2
L = np.tril(A,-1)+np.eye(3)
3
# construct upper triangular matrix U
4
U = np.triu(A)
5
# construct permutation matrix P
6
P = np.eye(3)
7
P = P[perm,:]

Condition Number of a Matrix
337
8
print('P='); print(P)
9
print('L='); print(L)
10
print('U='); print(U)
P=
[[0. 0. 1.]
[1. 0. 0.]
[0. 1. 0.]]
L=
[[ 1.
0.
0.
]
[ 0.5
1.
0.
]
[ 0.33333333 -0.25
1.
]]
U=
[[
6.
18. -12.]
[
0.
8.
16.]
[
0.
0.
6.]]
Observe that the output agrees with the example presented above.
9.3
Condition Number of a Matrix
We saw that Gaussian elimination can be unstable for some linear systems due to finite
precision arithmetic. It would have been very useful if we had a tool to detect matrices that
can lead to failure of Gaussian elimination. The sensitivity on matrices to small errors can
be expressed with the condition number of a matrix. We first define rigorously the notion
of norm to compare vectors and matrices.
9.3.1
Vector and matrix norms
A vector norm is a function that maps vectors to positive real numbers. A norm of a vector
x usually is denoted by ∥x∥, and it can be interpreted as the length of x. Formally, a vector
norm is the mapping ∥· ∥: Rn(or Cn) →R and satisfies the following properties:
1. ∥x∥≥0, x ∈Rn, (∥x∥= 0 ⇔x = 0)
2. ∥x + y∥≤∥x∥+ ∥y∥, x, y ∈Rn (Triangle inequality)
3. ∥ax∥= |a|∥x∥for a ∈R, x ∈Rn
The most common norms are the ℓ1-norm, ℓ2-norm and ℓ∞-norm defined as
∥x∥1 = |x1| + · · · + |xn|,
(ℓ1-norm)
∥x∥2 =
p
|x1|2 + · · · + |xn|2,
(ℓ2-norm)
∥x∥∞= max
1≤i≤n |xi|,
(ℓ∞-norm)
where the absolute value is used when the vectors have complex entries (xi ∈C).

338
Numerical Linear Algebra
FIGURE 9.1
Measuring distances in Manhattan.
Sometimes, we find it useful to use the more general norm (ℓp-norm)
∥x∥p =
 n
X
i=1
|xi|p
!1/p
,
p > 1 ,
which for p = ∞is ∥x∥∞= lim
p→∞∥x∥p. The ∥x∥2 is usually referred to as the Euclidean
norm.
To understand the difference between the various norms we present in Figure 9.1 a top
view of a hypothetical city, let’s say Manhattan with the squares representing buildings.
Suppose that we want to move from point A to point B. The distance between A and B
is measured by the ℓ2-norm ∥x∥2 and is the modulus of the vector x depicted with broken
line. This distance though is not an accurate estimate of the distance we need to cover. On
the contrary, the distance we need to travel is the distance from A to C and from C to
B. This distance is the ℓ1-norm ∥x∥1 = |x1| + |x2|. So norms measure distances in various
topologies. Distances measured with different norms have the same order of magnitude and
thus the choice of a norm will depend on the application4.
Norms estimate also distances between vectors by their difference ∥a −b∥. This is very
useful computation as, for example, in the computation of an approximation ˜x of a vector
x, the norm of their difference ∥x −˜x∥or even the normalized quotient ∥x −˜x∥/∥x∥gives
us information about the error or the relative error.
Some vector norms are related to the inner product between vectors. The inner (or dot)
product of two vectors is defined as the product of a row with a column vector xT · y.
(Sometimes we will omit the dot in the notation like we do in matrix multiplication.) In
linear algebra we usually consider vectors as column vectors. So the inner product of the
vectors x, y ∈Rn is the sum of the products of their entries
xT · y =
n
X
i=1
xiyi .
In this book, the inner product will be denoted by ⟨x, y⟩= xT · y to emphasize the rela-
tionship between x and y. It is easy to see that
xT · x = ⟨x, x⟩= ∥x∥2
2 ,
4In finite-dimensional spaces.

Condition Number of a Matrix
339
which implies
∥x∥2 =
p
⟨x, x⟩.
If the vectors x and y are complex, then the definition of the transpose requires to take the
complex conjugates of the entries of the respective vector. In particular, the inner product
is defined as
⟨x, y⟩=
n
X
i=1
¯xiyi .
Perhaps, the most useful inequality between norms and inner products is the Cauchy-
Schwarz inequality5
|⟨x, y⟩| ≤∥x∥2 ∥y∥2 ,
which holds true for any two complex vectors x and y. More precisely, we have the following
theorem:
Theorem 9.3 (Cauchy-Schwarz inequality). Any vectors x, y ∈Cn satisfy the inequality
|⟨x, y⟩| ≤∥x∥2 ∥y∥2 .
Proof. Obviously, for x = 0 or y = 0 the Cauchy-Schwarz inequality holds as an equality
(0 = 0). For non-zero vectors x and y we see that for all θ ∈R we have
0 ≤
n
X
i=1
(θ|xi| + |yi|)2 = θ2
n
X
i=1
|xi|2 + 2θ
n
X
i=1
|xi||yi| +
n
X
i=1
|yi|2 .
(9.3)
The right hand side of this inequality is a quadratic polynomial for θ. The coefficient of the
quadratic term θ2 is positive since
n
X
i=1
|xi|2 > 0 .
Since the quadratic polynomial in (9.3) is always positive, its discriminant D must be D ≤0.
Using this observation, we have
0 ≥D = 4
 n
X
i=1
|xi||yi|
!2
−4
 n
X
i=1
|xi|2
!  n
X
i=1
|yi|2
!
,
which gives
 n
X
i=1
| ¯xiyi|
!2
≤
 n
X
i=1
|xi|2
!  n
X
i=1
|yi|2
!
.
Taking square root on both sides of this inequality and using the triangle inequality |x+y| ≤
|x| + |y| we have

n
X
i=1
¯xiyi
 ≤
 n
X
i=1
|xi|2
!1/2  n
X
i=1
|yi|2
!1/2
,
which is the Cauchy-Schwarz inequality |⟨x, y⟩| ≤∥x∥2∥y∥2.
5Also called Cauchy-Schwarz-Bunyakovsky inequality named after Baron Augustin-Louis Cauchy (1789–
1857), Karl Hermann Amandus Schwarz (1843–1921) and Viktor Yakovlevich Bunyakovsky (1804–1889).

340
Numerical Linear Algebra
We mentioned the triangle inequality for the absolute value of the sum of two numbers
|x+y| ≤|x|+|y|. The exact same inequality holds for vectors and norms and it is the second
property in the definition of a norm. It is left to the reader to verify that all the previously
mentioned norms satisfy the norm properties 1–3. We only show here the triangle inequality
for the Euclidean norm
∥x + y∥2 ≤∥x∥2 + ∥y∥2 .
To see why this is true, we write the norm of the sum as an inner product
∥x + y∥2
2 = ⟨x + y, x + y⟩,
and analyze the inner product as
∥x + y∥2
2 = ⟨x + y, x + y⟩
= ⟨x, x⟩+ ⟨x, y⟩+ ⟨y, x⟩+ ⟨y, y⟩
= ∥x∥2
2 + 2⟨x, y⟩+ ∥y∥2
2
≤∥x∥2
2 + 2∥x∥2∥y∥2 + ∥y∥2
2
= (∥x∥2 + ∥y∥2)2 .
Thus,
∥x + y∥2
2 ≤(∥x∥2 + ∥y∥2)2 .
After taking the square root in the last inequality we obtain the triangle inequality ∥x +
y∥2 ≤∥x∥2 + ∥y∥2.
In analogy to vector norms we define matrix norms ∥· ∥: Rn,n →R as a mapping that
satisfies the following properties
 ∥A∥≥0, A ∈Rn,n, (∥A∥= 0 ⇔A = 0)
 ∥A + B∥≤∥A∥+ ∥B∥, A, B ∈Rn,n
 ∥cA∥= |c|∥A∥for c ∈R, A ∈Rn,n
 ∥AB∥≤∥A∥∥B∥, A, B ∈Rn,n
and again, matrix norms determine the size of a matrix.
Note that the triangle inequality of matrix norms is inherited from vector norms. It is
not hard to see that
|∥A∥−∥B∥| ≤∥A −B∥≤∥A∥+ ∥B∥.
For example, the right inequality follows directly from the triangle inequality of ∥A∥=
∥A −B + B∥≤∥A −B∥+ ∥B∥. While the left, again as a consequence of triangle
inequality, can be derived from ∥A −B∥= ∥A + (−B)∥≤∥A∥+ ∥−B∥= ∥A∥+ ∥B∥.
The most commonly used matrix norms are those induced by vector norms. Such norms
are called natural norms and are defined as
∥A∥= max
x̸=0
∥Ax∥
∥x∥
= max
∥Ax∥
∥x∥, x ̸= 0

.
Since ∥A∥is the maximum of all quantities ∥Ax∥/∥x∥for all x ̸= 0, it is implied that
∥A∥≥∥Ax∥
∥x∥
for all x ̸= 0 .

Condition Number of a Matrix
341
Thus, for x ̸= 0 and any square matrix A we have
∥Ax∥≤∥A∥∥x∥.
It is noted that the definition of matrix norm includes complex vectors x ∈Cn. Also if x = 0
the last inequality holds as equality. The most important matrix norms are the following:
∥A∥1 =
max
j=1,...,n
n
X
i=1
|aij|,
(ℓ1-norm)
∥A∥2 =
p
ρ(AT A),
(ℓ2-norm)
∥A∥∞=
max
i=1,...,n
n
X
j=1
|aij|,
(ℓ∞-norm)
∥A∥F =
v
u
u
t
n
X
j=1
n
X
i=1
|aij|2,
(Frobenius norm)
The norm ∥A∥F is called the Frobenius norm of A and is named after the German
mathematician Ferdinand Georg Frobenius (1849–1917). In the definition of the norm ∥A∥2,
the ρ(A) denotes the spectral radius of A, which is the maximum in magnitude eigenvalue
of A
ρ(A) = max{|λ1|, |λ2|, . . . , |λk|} ,
with det(A −λiI) = 0.
9.3.2
Theoretical properties of matrix norms
Here we present a few theoretical properties of matrix norms. Their proofs require some
advanced knowledge of linear algebra, and for the sake of completeness are included here.
In general, any two matrix or vector norms ∥· ∥1 and ∥· ∥2 are equivalent, in the sense
that there are constact C1, C2 > 0 such that C1∥· ∥2 ≤∥· ∥1 ≤C2∥· ∥2. Also all natural
norms are related to the spectral radius. More precisely there is no way a matrix norm can
become smaller than the spectral radius of A:
Theorem 9.4. For any natural matrix norm ∥· ∥and n × n complex matrix A we have
ρ(A) ≤∥A∥.
Proof. Let λ ∈C be an eigenvalue of the matrix A, and x ̸= 0 the corresponding eigen-
vector. This means that Ax = λx. Taking the norm of both sides of the last relation we
get
∥Ax∥= ∥λx∥.
Since ∥· ∥is assumed to be natural, we have ∥Ax∥≤∥A∥∥x∥, and thus
∥λx∥= ∥Ax∥≤∥A∥∥x∥.
But ∥λx∥= |λ|∥x∥from the norm properties, and so
|λ|∥x∥≤∥A∥∥x∥.
Since ∥x∥> 0 we simplify the last inequality into |λ| ≤∥A∥and since λ was arbitrary, this
holds for the maximum absolute value of eigenvalues ρ(A) ≤∥A∥.
The inverse inequality is not true, but what one can prove is that the spectral radius of
a matrix can be an estimate of its norm:

342
Numerical Linear Algebra
Theorem 9.5. For any n × n (complex) matrix A and for all ϵ > 0, there is a natural
norm ∥· ∥such that ∥A∥≤ρ(A) + ϵ.
Proof. The proof requires the Jordan normal form6 of matrix A. So let A = P JP −1, with
J = diag(J1, J2, . . . , Jp) the Jordan normal form of A. We define the matrix
˜
J = D−1JD ,
where D = diag(1, ϵ, ϵ2, . . . , ϵn−1). The matrix ˜
J has the exact same structure as J with
blocks
˜
Ji =







λi
ϵ
0
· · ·
0
0
0
λi
ϵ
· · ·
0
0
...
...
...
...
...
...
0
0
0
· · ·
λi
ϵ
0
0
0
· · ·
0
λi







,
for all the i blocks. Thus, ∥˜
J∥∞≤|λi| + ϵ, and thus ∥˜
J∥∞≤ρ( ˜
J) + ϵ. From the definitions
of J and ˜
J we have
˜
J = D−1JD = D−1P −1AP D = (P D)−1A(P D) = T −1AT ,
where T = P D. Since D = diag(1, ϵ, . . . , ϵn−1), the columns of T are the columns of P
multiplied with 1, ϵ, . . . , ϵn−1.
Let ∥A∥be the matrix norm of A defined using the vector norm ∥x∥= ∥T −1x∥∞. Then
∥A∥=
max
x∈Cn,∥x∥=1 ∥Ax∥
=
max
x∈Cn,∥T −1x∥∞=1 ∥T −1Ax∥∞
=
max
T −1x∈Cn,∥T −1x∥∞=1 ∥T −1AT (T −1x)∥∞
=
max
T −1x∈Cn,∥T −1x∥∞=1 ∥˜
J(T −1x)∥∞
= ∥˜
J∥∞
≤ρ(A) + ϵ ,
which completes the proof.
Finally, we present a theorem of John von Neumann (1903–1957), which we will find
useful in estimates and proofs later in this book.
Theorem 9.6 (Neumann). If for an n × n complex matrix A and for any natural norm is
∥A∥< 1, then:
(i) The matrix I −A is invertible, which means that the inverse (I −A)−1 exists, and
(ii)
1
1+∥A∥≤∥(I −A)−1∥≤
1
1−∥A∥.
Proof. We prove the first part of the theorem using a contradiction. If I−A wasn’t invertible,
then the linear system (I −A)x = 0 would have a solution x ̸= 0. For that x we would also
have x = Ax. Taking norms on both sides of x = Ax we have ∥x∥= ∥Ax∥≤∥A∥∥x∥.
Since x ̸= 0 we have that ∥x∥> 0, and thus we have ∥A∥≥1, which is a contradiction
since we assumed that ∥A∥< 1. Hence, the matrix I −A is invertible.
6A discussion of the Jordan normal form can be found in Chapter 12 and in the Appendix.

Condition Number of a Matrix
343
In order to prove the second part of the theorem we make use of part (i). Since the
matrix I −A is invertible we have
I = (I −A)−1(I −A) = (I −A)−1 −(I −A)−1A .
Taking norms on both sides of the previous relation we have
1 = ∥I∥= ∥(I −A)−1 −(I −A)−1A∥.
(9.4)
On the other hand we have that
∥(I −A)−1∥−∥(I −A)−1∥∥A∥≤∥(I −A)−1 −(I −A)−1A∥
≤∥(I −A)−1∥+ ∥(I −A)−1∥∥A∥,
or better
∥(I −A)−1∥(1 −∥A∥) ≤∥(I −A)−1 −(I −A)−1A∥≤∥(I −A)−1∥(1 + ∥A∥) .
Hence,
1 ≤∥(I −A)−1∥(1 + ∥A∥) ,
which gives
1
1 + ∥A∥≤∥(I −A)−1∥.
(9.5)
From (9.4) we also have
1 ≥
∥(I −A)−1∥−∥(I −A)−1A∥
≥
∥(I −A)−1∥−∥(I −A)−1∥∥A∥
≥
∥(I −A)−1∥(1 −∥A∥) ,
which gives (since ∥A∥< 1)
1
1 −∥A∥≤∥(I −A)−1∥.
(9.6)
Combining (9.5) and (9.6) we have that
1
1 + ∥A∥≤∥(I −A)−1∥≤
1
1 −∥A∥,
which completes the proof.
After having a deep insight of matrix and vector norms, we continue with the condition
number of a matrix. The condition number gives us an estimate of how close a matrix is to
be singular by numerical means.
9.3.3
Condition number
For any natural norm, the condition number of A is the number
cond(A) = ∥A∥· ∥A−1∥.
Suppose that we want to solve a system
Ax = b .
(9.7)

344
Numerical Linear Algebra
To see how this number can determine the sensitivity of the solution x on A we make the
following three assumptions: (i) We store A in memory using exact arithmetic; (ii) We store
b with finite precision as b∗= b + δb instead of b, where δb is the error-vector; (iii) We
execute the Gaussian elimination with exact arithmetic.
Because of the error in the storage of vector b, we compute the solution x∗= x + δx
instead of x by solving exactly the system
Ax∗= b∗.
(9.8)
Subtracting systems (9.7) and (9.8) we get the equation for the error δx
A δx = δb ,
which implies
δx = A−1 δb .
Taking norms in the last equation we obtain
∥δx∥≤∥A−1∥∥δb∥.
(9.9)
Since b = Ax, taking norms on both sides and using the definition of matrix norm we
obtain ∥b∥≤∥A∥∥x∥, which is equivalent to
∥x∥≥∥b∥
∥A∥.
(9.10)
Dividing (9.9) by (9.10) we obtain the formula for the relative error
∥δx∥
∥x∥≤∥A∥· ∥A−1∥∥δb∥
∥b∥.
Equivalently, we write the formula of the relative error as
∥δx∥
∥x∥≤cond(A)∥δb∥
∥b∥,
where cond(A) = ∥A∥· ∥A−1∥is the condition number of A.
Since the relative error ∥δx∥/∥x∥is proportional to the condition number, we conclude
that matrices with large condition number might lead to a solution with large relative error.
In such cases we definitely need to use Gaussian elimination with pivoting.
Since I = A · A−1, by taking any natural matrix norm we have
1 = ∥I∥= ∥AA−1∥≤∥A∥∥A−1∥,
which yields
cond(A) ≥1 .
This means that the best matrix for Gaussian elimination is the one with cond(A) = 1. The
condition number of the identity matrix I is cond(I) = 1. Some times we write condp(A) =
∥A∥p∥A−1∥p.
The condition number can be computed numerically using NumPy and the function
cond of the module linalg. The general call of the function cond is

Other Matrix Computations
345
cond(A,p)
where A is the matrix we search for its condition number and p corresponds to the ℓp-norm.
By default p=None for computations with the ℓ2-norm. Other values can be ’fro’ for the
Frobenious, inf for the infinity, 1 for the ℓ1-norm and 2 for the ℓ2 norm. NumPy defines also
the norms -inf, -1 and -2, which we will not use here but the interested reader can look
them up in the NumPy online reference for more information. The function cond returns
the condition of matrix A. Here we consider a very simple example demonstration of the use
of the function cond.
1
from numpy.linalg import cond
2
A = np.array([[1, 0, -1], [0, 1, 0], [1, 0, 1]])
3
cond(A)
4
cond(A, np.inf)
5
cond(A, 1)
6
cond(A, 2)
1.4142135623730951
2.0
2.0
1.4142135623730951
The specific condition number is not large. An ill-conditioned matrix usually has con-
dition number greater than 100. An example of ill-conditioned matrices are the so-called
Hilbert matrices with entries
aij =
1
i + j −1 .
Trying for example the 3 × 3 matrix
A =


1
1/2
1/3
1/2
1/3
1/4
1/3
1/4
1/5

,
we compute cond2(A) ≈524. Such matrices occur in least square problems (polynomial
regression) of Section 6.5.
9.4
Other Matrix Computations
The Gaussian elimination and LU factorization are very useful algorithms, not only for
the solution of linear systems. We can employ these methods to perform other difficult
computations such as the computation of inverse or determinant of a matrix. The compu-
tation of a determinant using the definition is extremely expensive. So expensive that it
is almost impossible to compute the determinant of an 100 × 100 matrix into reasonable
timeframes. This fact makes methods such as Cramer’s rule useless for the solution of large
linear systems.

346
Numerical Linear Algebra
9.4.1
Computation of inverse matrix
If A−1 is the inverse of an n × n matrix A, then A A−1 = A−1 A = I. We denote by
xi the i-th column of A−1 and by bi the i-th column of the identity matrix I, i.e. bi =
(0, 0, . . . , 1, . . . , 0)T . Observe that
A xi = bi .
Therefore, by solving the system Axi = bi for xi we compute the i-th column of A−1.
This means that in order to compute all the columns of A−1 we need to solve n linear
systems. In practice, we compute the inverse matrix of A applying Gaussian elimination to
the augmented matrix
(A|I) ,
and backward substitution n times; or we compute the LU factorization once and apply
Forward and Backward Substitution n times.
For example, in order to find the inverse of the matrix
A =


1
2
−1
2
1
0
−1
1
2

,
we consider the augmented matrix
A =


1
2
−1
1
0
0
2
1
0
0
1
0
−1
1
2
0
0
1

.
First, performing (R2 −2R1) →(R2) and (R3 + R1) →(R3) we get


1
2
−1
1
0
0
0
−3
2
−2
1
0
0
3
1
1
0
1

,
which after the operation (R3 + R2) →(R3) gives the reduced form


1
2
−1
1
0
0
0
−3
2
−2
1
0
0
0
3
−1
1
1

.
Backward substitution is performed on each of the three augmented matrices


1
2
−1
1
0
−3
2
−2
0
0
3
−1

,


1
2
−1
0
0
−3
2
1
0
0
3
1

,


1
2
−1
0
0
−3
2
0
0
0
3
1

,
to obtain the solutions
b1 =


−2/9
4/9
−1/3

,
b2 =


5/9
−1/9
1/3

,
b3 =


−1/9
2/9
1/3

.
The matrix A−1 is
A−1 = B =


−2
9
5
9
−1
9
4
9
−1
9
2
9
−1
3
1
3
1
3

.
The numerical computation of the inverse of a matrix in NumPy can be done using the
function inv of the module linalg. For example

Other Matrix Computations
347
1
import numpy.linalg as npl
2
A = np.array([[1., 2.], [3., 4.]])
3
ainv = npl.inv(A)
4
print(Ainv)
5
print(np.dot(A, Ainv))
[[-2.
1. ]
[ 1.5 -0.5]]
[[1.00000000e+00 1.11022302e-16]
[0.00000000e+00 1.00000000e+00]]
9.4.2
Computation of determinants
The computation of the determinant of an n × n matrix A using the methodology with the
cofactors and the minors (see Section 2.2.10) requires O(n!) floating point operations. Such
a computation is perhaps impossible for large values of n. We bypass this obstacle with the
help of LU factorization.
Assume that the LU factorization of the matrix A is given in the form P A = LU. Then
det(A) = det(P −1) det(L) det(U) .
Any permutation matrix P factors as a product of S row-interchanging elementary per-
mutation matrices Pi, each having determinant −1, and thus det(P −1) = (−1)S. The
determinants det(L) = Qn
i=1 lii and det(U) = Qn
i=1 uii since L and U are lower triangular
and upper triangular, respectively. For the proofs of all these properties, we refer to basic
linear algebra books such as [105]. Therefore,
det(A) = (−1)S
 n
Y
i=1
lii
!  n
Y
i=1
uii
!
,
where S is the number of row interchanges. Because the matrix L has only 1 in its main
diagonal
n
Y
i=1
lii = 1 .
We conclude that the determinant det(A) can be computed with the product
det(A) = (−1)S
 n
Y
i=1
uii
!
.
In Section 9.2.2 we saw that the LU factorization of the matrix
A =


3
17
10
2
4
−2
6
18
−12

,
is the following


0
0
1
1
0
0
0
1
0




3
17
10
2
4
−2
6
18
−12

=


1
0
0
1/2
1
0
1/3
−1/4
1




6
18
−12
0
8
16
0
0
6

.
In this case, S = 2 and thus, the determinant of the matrix A is det(A) = 6×8×6 = 288. In
Python we can compute the determinant of a matrix using the function det of the module
numpy.linalg.

348
Numerical Linear Algebra
9.5
Symmetric Matrices
It happens very often in applications that the matrix A is symmetric. If A is symmetric,
then we can store half of A, i.e. only its lower triangular part, and save computer memory. If
in addition A is positive definite, then we could make the LU factorization faster and stable.
In particular, if A is symmetric and positive definite, then there is a factorization of the
form HHT . This factorization is called Cholesky decomposition named after Andr´e-Louis
Cholesky (1875–1918). Recall that a matrix A is positive definite if
xT A x > 0 ,
for all n-dimensional vectors x ̸= 0.
As we saw in Section 2.3.2, the process of verifying the positive definiteness of A can
be very difficult. There are a few, helpful facts in the verification process. First of all, a
symmetric matrix A is positive definite if and only if the Gaussian elimination without
row interchanges can be performed on the linear system Ax = b with all pivot elements
positive. The computations involving a positive definite matrix A are stable with respect to
the growth factor of round-off errors. Moreover, any symmetric matrix A is positive definite
if and only if A can be written in the form HHT , where H is lower triangular with non-
zero diagonal entries. But first let’s see the result of the LU decomposition of symmetric
matrices.
9.5.1
LDLT factorization
The LDLT factorization of a matrix A can be carried out if A is symmetric and has an
ordinary LU factorization A = LU, with L unit lower triangular, and is the decomposition
of A into a product LDLT where D is diagonal7. First we extract the main diagonal of U
and we write U = DU1 where U1 is unit upper triangular. As a result, we write the LU
decomposition of A as A = LDU1. This is known as Crout decomposition named after
Prescott Durand Crout (1907–1984). Due to the symmetry of A, we have that U1 = LT
which makes the LDLT factorization a special case of Crout decomposition. To see this, we
start with
LU = A = AT = (LU)T = U T LT .
Since L is unit lower triangular, it is invertible, and we can write U = L−1U T LT . Then
U(LT )−1 = L−1U T . However, since the product of lower triangular matrices is lower
triangular and the product of upper triangular matrices is upper triangular, the right side
of this equation is lower triangular and the left side is upper triangular (see Section 2.2.8).
Thus, both sides must be equal to a diagonal matrix, say, D. The equation U(LT )−1 = D
implies
U = DLT ,
and thus
A = LU = LDLT .
For example, let
A =




4
3
2
1
3
3
2
1
2
2
2
1
1
1
1
1



.
7If A is complex Hermitian, then the particular factorization is written as A = LDLH

Symmetric Matrices
349
The LU factorization of A will be
A =




1
0
0
0
3
4
1
0
0
1
2
2
3
1
0
1
4
1
3
1
2
1








4
3
2
1
0
3
4
1
2
1
4
0
0
2
3
1
3
0
0
0
1
2



= LU .
Extracting the diagonal entries from U and place them into a diagonal matrix D yields
U =




4
0
0
0
0
3
4
0
0
0
0
2
3
0
0
0
0
1
2








1
3
4
1
2
1
4
0
1
2
3
1
3
0
0
1
1
2
0
0
0
1



= DLT .
Clearly we have A = LDLT .
9.5.2
Cholesky factorization
If A is symmetric and positive definite, then we can write A in the form
A = HHT ,
where H is lower triangular matrix (without necessarily ones in the main diagonal). This
is the Cholesky factorization of symmetric and positive definite matrix.
We can acquire the Cholesky factorization from the LDLT factorization of A. First,
write A = LDLT . The diagonal matrix D can be written as a product of diagonal matrices
D = D1/2D1/2 where
D1/2 = diag(
p
d11,
p
d22, . . . ,
p
dnn) .
Then, we have
A = LD1/2D1/2LT = LD1/2(LD1/2)T .
By setting H = LD1/2 we obtain the Cholesky factorization A = HHT . The positivity of
the diagonal entries of D is guaranteed by the positivity of A (see Section 2.3.2).
For a 3 × 3 matrix A we have


a11
a12
a13
a21
a22
a23
a31
a32
a33

=


h11
0
0
h21
h22
0
h31
h32
h33




h11
h21
h31
0
h22
h32
0
0
h33

.
After performing the multiplication on the right-hand side we get


a11
a12
a13
a21
a22
a23
a31
a32
a33

=


h2
11
h11h21
h11h31
h11h21
h2
21 + h2
22
h21h31 + h22h32
h11h31
h21h31 + h22h32
h2
31 + h2
32 + h2
33

.
Using matrix equality, and solving for h11, h21, h31 using the first row, for h22, h32 using
the second and for h33 using the third we obtain
h11 = √a11
h21 = a21/h11
h31 = a31/h11
h22 =
q
a32 −h2
21

350
Numerical Linear Algebra
h32 = (a32 −h21h31)/h22
and finally
h33 =
q
a33 −h2
31 −h2
32
Following the same procedure for an n × n matrix we obtain a reduction algorithm: If
H =
h11
0
ˆh
ˆ
H

,
A =
a11
ˆa
ˆaT
ˆ
A

,
then writing HHT = A leads to
h11 = √a11 ,
ˆ
H ˆ
HT = ˆ
A −ˆhˆhT .
The last equation implies that for i = 1, 2, . . . , n
hii =
v
u
u
taii −
i−1
X
k=1
h2
ik
and
hji =
 
aji −
i−1
X
k=1
hikhjk
!
/hjj
for j = i + 1, . . . , n .
This procedure is summarized in Algorithm 32.
Algorithm 32 Cholesky factorization of symmetric and positive definite matrix A
for i = 1 : n do
H(i, i) =
q
A(i, i) −Pi−1
k=1 H2(i, k)
for j = i + 1 : n do
H(j, i) =

A(j, i) −Pi−1
k=1 H(j, k)H(i, k)

/H(i, i)
end for
end for
For example, let
A =


4
−1
1
−1
4.25
2.75
1
2.75
3.5


Following the Algorithm 32 or alternatively solving the equations A = HHT we obtain
h11 = √a11 =
√
4 = 2 ,
h21 = a21/h11 = −1/2 = −0.5 ,
h31 = a31/h11 = 1/2 = 0.5 ,
h22 =
q
a22 −h2
21 =
√
4.25 −0.25 =
√
4 = 2 ,
h32 = (a32 −h21h31)/h22 = (2.75 + 0.25)/2 = 1.5 ,
h33 =
q
a33 −h2
31 −h2
32 =
√
3.5 −0.25 −2.25 = 1 .
Thus, A has the Cholesky factorization
A = HHT =


2
0
0
−0.5
2
0
0.5
1.5
1




2
−0.5
0.5
0
2
1.5
0
0
1

.

Symmetric Matrices
351
Solving linear systems using Cholesky factorization
After having a symmetric and positive definite matrix A factorized in HHT , we can employ
forward and backward substitution to solve any linear system of the form Ax = b. We first
solve the system Hy = b and then the system HT x = b. This is exactly what we did in
the LU factorization, with the only difference that instead of U we will have here HT , and
in the forward substitution we need to divide by the diagonal entries hii.
Here we present an implementation of Cholesky factorization algorithm with forward
and backward substitution.
1
def Cholesky(A):
2
n = len(A)
3
for i in range(n):
4
try:
5
A[i,i]=np.sqrt(A[i,i] - np.dot(A[i,0:i],A[i,0:i]))
6
except ValueError:
7
error.err('Matrix is not positive definite')
8
for j in range(i+1,n):
9
A[j,i] = (A[j,i]-np.dot(A[j,0:i],A[i,0:i]))/A[i,i]
10
for k in range(1,n):
11
A[0:k,k]=0.0
12
return A
13
def solveCholesky(H,b):
14
n = len(b)
15
# Solve Hy=b
16
for k in range(n):
17
b[k] = (b[k] - np.dot(H[k,0:k],b[0:k]))/H[k,k]
18
# Solve H^T x =y
19
for k in range(n-1,-1,-1):
20
b[k] = (b[k] - np.dot(H[k+1:n,k],b[k+1:n]))/H[k,k]
21
return b
Trying our code with the matrix
A =


4
−1
1
−1
4.25
2.75
1
2.75
3.5

,
and to the linear system Ax = b with b = (4, 6, 7.25)T we get the right answer, as expected.
1
A = np.array([[4.0, -1.0, 1.0],
2
[-1.0, 4.25, 2.75],
3
[1.0, 2.75, 3.5]])
4
H = Cholesky(A)
5
print(H)
6
b = np.array([4.0, 6.0, 7.25])
7
x = solveCholesky(H,b)
8
print(x)
[[ 2.
0.
0. ]
[-0.5
2.
0. ]
[ 0.5
1.5
1. ]]
[1. 1. 1.]

352
Numerical Linear Algebra
We close with the remark that the Cholesky factorization algorithm is always stable. It
also requires O(n3/3) floating point operations. Taking into consideration the stability of
the forward and backward substitution algorithms, Cholesky factorization leads to a safe
method for the numerical solution of linear systems with symmetric and positive definite
matrices.

Cholesky factorization A = HHT works for symmetric and positive definite
matrices. The failure of this method is a proof that a matrix A is not positive definite,
and can be used as a test of positive definiteness. To check if a matrix is symmetric
is usually an easy task, for example, by checking whether A = AT or not.
9.6
The Module scipy.linalg Again
We have already discussed several functions for solving linear systems using the module
scipy.linalg in Chapter 2. Here we discuss the implementations of the LU, LDLT and
Cholesky factorizations in SciPy.
9.6.1
LU factorization
The easiest way to obtain the LU factorization of a matrix A is by using its SciPy imple-
mentation, which is the function scipy.linalg.lu. The general call of the function lu is
lu(a, permute_l, overwrite_a, check_finite)
where here
a:
Is the matrix A and is the only argument required to obtain its LU factorization
permute l: Is a boolean variable in order to perform the multiplication P L. (Optional with
default value False)
overwrite a: Is a boolean variable in order to overwrite A with the matrices L and U.
(Optional with default value False)
check finite: Is a boolean variable in order to check that the input matrix contains only
finite numbers. (Optional with default value True)
The output of the function lu is the three matrix P , L and U as it is shown in the following
example:
1
import scipy.linalg as spl
2
A = np.array([[ 3., 17., 10.],
3
[ 2., 4.,-2.],
4
[ 6.,18.,-12.]])
5
(P,L,U) = spl.lu(A)
6
print(P)
7
print(L)
8
print(U)

The Module scipy.linalg Again
353
[[0. 1. 0.]
[0. 0. 1.]
[1. 0. 0.]]
[[ 1.
0.
0.
]
[ 0.5
1.
0.
]
[ 0.33333333 -0.25
1.
]]
[[
6.
18. -12.]
[
0.
8.
16.]
[
0.
0.
6.]]
A similar function of the module scipy.linalg is the function lu factor. This func-
tion’s general call is:
lu_factor(a, overwrite_a, check_finite)
with arguments as described in lu function reference. The difference here is that the function
returns the LU factorization in one matrix lu like our function LUpivot and the permutation
matrix perm. The advantage of using the lu factor instead of the function lu is that one
can use its output to solve a linear system Ax = b using the scipy.linalg function lu -
solve. The general call of the lu solve function is
lu_solve(lu_and_piv, b, trans, overwrite_b, check_finite)
with input arguments
lu and piv: The tuple (lu, piv) received in the output of lu factor.
b:
The right-hand side b of the linear system Ax = b.
trans: An integer in the set {0,1,2}. For 0 the function solves the system Ax = b, for 1 the
system AT x = b and for 2 the system AHx = b. (Optional with default value 0)
overwrite b: Is a boolean variable in order to overwrite b with the solution x. (Optional
with default value False)
check finite: Is a boolean variable in order to check that the input matrix contains only
finite numbers. (Optional with default value True)
The function lu solve returns only the solution x.
As an example, we consider again in the following code the system Ax = b with
A =


3
17
10
2
4
−2
6
18
−12


and
b =


30
4
12

.
1
A = np.array([[ 3., 17., 10.],
2
[ 2., 4.,-2.],
3
[ 6.,18.,-12.]])
4
b = np.array([30., 4., 12.])
5
(LU,P) = spl.lu_factor(A)
6
x = spl.lu_solve((LU,P),b)
7
print(x)
[1. 1. 1.]

354
Numerical Linear Algebra
9.6.2
Cholesky factorization
There are two implementations of the Cholesky factorization in Python. One is in module
numpy.linalg and the other in scipy.linalg. Both functions have the same name, which is
cholesky and require as input a symmetric and positive definite matrix A, while they return
the lower triangular matrix H. The SciPy version accepts some other optional arguments
and returns either the lower triangular matrix H or the upper triangular matrix HT . Here
we present the usage of the NumPy version of Cholesky factorization for the same, simple
example we discussed in our implementation.
Having the Cholesky factorization A = HHT , it is easy to solve any system of the form
Ax = b. Since HHT x = b we set y = HT x, so we solve for y the system Hy = b first,
and then the system HT x = y for x. In order to solve the triangular systems Hy = b
and HT x = y we can use the function solve triangular of scipy.linalg (see Section
2.3.3). Utilizing this function for the lower triangular matrix H we need to use the option
lower=True. In this way we can solve the system of the previous example using Python
with the following commands:
1
A = np.array([[4.0, -1.0, 1.0],
2
[-1.0, 4.25, 2.75],
3
[1.0, 2.75, 3.5]])
4
b = np.array([4.0, 6.0, 7.25])
5
H = spl.cholesky(A)
6
print(H)
7
# We use the option lower=True since H is lower triangular matrix
8
y = spl.solve_triangular(H, b, lower=True)
9
# We use the option trans=1 to solve the system H^Tx=y
10
x = spl.solve_triangular(H, y, trans=1, lower=True)
11
print(x)
[[ 2.
0.
0. ]
[-0.5
2.
0. ]
[ 0.5
1.5
1. ]]
[1. 1. 1.]
In SciPy one can also find an implementation of Cholesky algorithm for banded ma-
trices. This algorithm is discussed in the Exercises with some detail. Moreover, there is
the function cho factor which can be used in combination with the function cho solve
to solve linear systems. One can obtain first the cholesky factorization using the command
c=cho factor(A) and then obtain the solution by writing x=cho solve(c,b). The tupple
c contains a triangular matrix and a boolean variable that specifies whether the output
matrix is lower or upper triangular.
Similarly, the LDLT factorization can also be obtained using pivoting techniques. This
is implemented in the module scipy.linalg in the function ldl. This can take as input
a symmetric matrix A to return the arrays lu, d and perm, where lu is the (possibly)
permuted upper LT or lower triangular L matrix, d is the diagonal matrix D and perm
is the permutation matrix used during the factorization algorithm. We continue with a
different class of numerical methods for the numerical solution of large and sparse systems
of linear equations known to as iterative methods.

Iterative Methods
355
9.7
Iterative Methods
In previous sections we studied direct methods for dense linear systems. Direct methods
find the exact solution when exact arithmetic is being used. In this section we discuss
iterative methods for the numerical solution of sparse linear systems. These methods are
used to compute an approximation to the unknown solution in a finite number of iterations.
Iterative methods must converge to the exact solution in the limit of infinite iterations. The
philosophy of these methods is exactly the same as the methods we studied for the solution
of nonlinear equations. Like in Newton’s methods, we start with an initial guess of the
solution and the method estimates an approximation in a few iterations. Iterative methods
perform better for large and sparse matrices. Direct methods are more often preferable for
small and dense matrices. Also, direct methods can be our choice when it is hard to achieve
convergence with iterative methods due to matrix properties.
But let’s see first how we can derive iterative methods for linear systems. Perhaps the
easiest way is to start with a system Ax = b and write it as a fixed point equation in the
form
x = x −Ax + b = (I −A)x + b .
The iteration x(k+1) = (I −A)x(k) + b along with an initial guess x(0) define a sequence of
approximations x(k), k = 0, 1, 2, . . . . The superscript index in the notation x(k) indicates the
iteration, while the i-th entry of the vector x(k) is denoted by x(k)
i
. This iterative method,
perhaps the simplest of all, works well only in a few cases, unfortunately. For this reason,
other methods have been derived based on a more sophisticated methodology.
9.7.1
Derivation of iterative methods
Let
Ax = b ,
(9.11)
be a linear system of equations with large and sparse matrix A. In order to derive an iterative
method, and with the experience we have from fixed point methods, we will rewrite system
(9.11) in the form x = G(x). Then the implied iterative method will x(k+1) = G(x(k)),
with x(0) an initial guess. To construct G, we first split A into
A = M −N ,
(9.12)
where M and N can be anything leading to an efficient method. (Our first example can be
seen as the method with M = I and N = −I −A). We will discuss examples of M and
N later in this chapter but for the moment we consider general M and N, with invertible
M. After splitting A = M −N we write the system Ax = b as
(M −N)x = b
and then
Mx = Nx + b .
With the assumption that M is invertible, we write the last equation as
x = T x + c ,
where
T = M −1N
and
c = M −1b .
In other words, we transformed the equation Ax = b into the fixed point equation x =
T x + c. We define the fixed point iteration in the same manner as in Chapter 5 to be
x(k+1) = T x(k) + c ,

356
Numerical Linear Algebra
or more generally
Mx(k+1) = Nx(k) + b .
(9.13)
The reason for keeping the equation in the form (9.13) is because, sometimes, it is easier to
extract the equations from the matrix form without using the inverse M −1.

Note that the index of the iteration k is a superscript x(k) instead of subscript
xk. This is because x is now a vector.
9.7.2
Classical iterative methods – Jacobi and Gauss-Seidel methods
Three classical iterative methods are the Jacobi, Gauss-Seidel and Successive-Over-
Relaxation (SOR) methods. The last one is treated in the Exercises. The classical iterative
methods are based on the splitting
A = D −L −U ,
where D is diagonal, L lower triangular and U upper triangular matrices such that
D =






a11
0
· · ·
0
0
a22
...
0
...
...
...
0
0
· · ·
0
ann






,
L =






0
0 · · ·
· · ·
0
−a21
...
...
...
...
...
...
−an1
· · ·
−an,n−1
0






,
and
U =






0
−a12
· · ·
−a1n
...
...
...
...
...
...
...
−an−1,n
0
· · ·
0
0






.
The matrices L and U have nothing in common with the LU factorization. They are usually
denoted by the same letters because they are lower and upper triangular matrices.
The Jacobi method
The Jacobi method is the simplest iterative method. We choose for the splitting of A =
M −N the matrices
M = D
and
N = L + U .
Then the fixed point method Mx(k+1) = Nx(k) + b is written as
Dx(k+1) = (L + U)x(k) + b .
The choice of the matrix M = D is not by chance of course. Since our method relies on
the inversion of M, we prefer M to be easily invertible, and there is no matrix more easily
invertible than a diagonal matrix. After inverting the diagonal matrix D, we have the Jacobi
method written in vector form
x(k+1) = D−1(L + U)x(k) + D−1b,
k = 0, 1, 2, . . . .
(9.14)

Iterative Methods
357
Writing each equation of the Jacobi iteration (9.14) explicitly, we have for each entry of
x(k+1) that
x(k+1)
i
=



bi −
n
X
j=1
j̸=i
aijx(k)
j




.
aii,
i = 1, . . . , n .
(9.15)
From (9.15) we immediately deduce that we need aii ̸= 0, for i = 1, 2, . . . , n. If A is
nonsingular but one of the values aii is 0, then reordering of the equations can be performed
so that no aii is zero.
We start iterating using an initial guess x(0). This can be any arbitrarily chosen vector.
The question is when we should stop iterating, as we cannot wait to reach the exact solution
in the limit k →∞. In the case of iterative methods for scalar equations, we could terminate
the iterations when the difference of two successive approximations |xk+1 −xk| become less
than a prescribed tolerance. In the case of systems where x(k) are vectors we need to use
norms in order to compute the difference of two successive approximations. So we can record
the quantity ∥x(k+1) −x(k)∥for some vector-norm ∥· ∥or even better use the normalized
error
∥x(k) −x(k−1)∥
∥x(k)∥
,
and compare with a prescribed tolerance.
The speed of convergence cannot be determined a priori, but we can increase it by
rearranging the equations of the system. Rearranging the equations of a system can be
described by a transformation of matrices M, N and vector b. We can increase the speed
of the Jacobi method by rearranging the matrix M = D so that the diagonal entries aii
are large. The technique of modifying the matrix M in order to improve the speed of
convergence is called preconditioning.
The implementation of the Jacobi method in Python can be straightforward using either
(9.14) or (9.15). In order to compute each entry x(k+1)
i
from (9.15) we only need the previous
iteration x(k)
i
for the same index i. If we had a high-performance computer with multiple
processors, then we could compute each entry in parallel. Perhaps, the Jacobi method is
the simplest example of a numerical method that can be parallelized trivially.
Here we present an implementation of the Jacobi method using the matrix-vector form
(9.14).
1
def jacobi(A, b, x, tol = 1.e-5, maxit = 100):
2
d = np.copy(np.diag(A))
3
np.fill_diagonal(A,0.0)
4
err = 1.0
5
iters = 0
6
while (err > tol and iters < maxit):
7
iters += 1
8
xnew = (b - np.dot(A,x)) / d
9
err = npl.norm(xnew-x,np.inf)
10
x = np.copy(xnew)
11
print('iterations required for convergence:', iters)
12
return x
The function jacobi takes as input the matrix A, vector b and initial guess x along with
the tolerance tol and the maximum number of iterations maxit that we allow to happen.
In the end, the function returns the approximation x and prints the number of iterations

358
Numerical Linear Algebra
required by the Jacobi method to meet the stopping criteria. In order to compute the norm
of the difference of two successive approximations, we use the module numpy.linalg and
the function norm. Here we use the ∥·∥∞but one can use any norm due to their equivalence.
We test the code for a system Ax = b with matrix
A =


2
−1
0
−1
3
−1
0
−1
2

,
and vector b = (1, 8, −5)T , which has exact solution x = (2, 3, −1)T . As initial guess we
take the vector x(0) = (0, 0, 0)T .
1
A = np.array([[2.0, -1.0,
0.0],
2
[-1.0, 3.0, -1.0],
3
[0.0, -1.0,
2.0]])
4
b = np.array([1.0, 8.0, -5.0])
5
x = np.zeros(3)
6
x = jacobi(A, b, x, 1.e-5, 100)
7
print(x)
iterations required for convergence: 24
[ 1.99999906
2.99999435 -1.00000094]
We observe that the solution is correct within the tolerance 10−5 and the solution has
at least 5 correct digits.
The Gauss-Seidel method
We continue with the second classical iterative method, the Gauss-Seidel method. The
Gauss-Seidel method uses the same splitting for the matrix A = M −N = D −L −U as
the Jacobi method, but instead of choosing M to be diagonal we choose M to be the lower
triangular matrix M = D −L. Therefore, N is the upper triangular matrix N = U. The
fixed point equation then becomes
(D −L)x = Ux + b ,
and the Gauss-Seidel iteration is defined as
(D −L)x(k+1) = Ux(k) + b,
k = 0, 1, 2, . . . .
(9.16)
In order to solve for the next iteration x(k+1) given the approximation x(k) we either need
to invert a lower triangular matrix or perform the forward substitution. After the inversion
of the matrix D −L, the k + 1 iteration can be written in the form
x(k+1) = (D −L)−1Ux(k) + (D −L)−1b .
(9.17)
Performing forward substitution to the system (9.16) we obtain
x(k+1)
i
=

bi −
i−1
X
j=1
aijx(k+1)
j
−
n
X
j=i+1
aijx(k)
j


.
aii.
i = 1, . . . , n .
(9.18)
Gauss-Seidel and Jacobi methods have many similarities, and big differences as well. The
Gauss-Seidel method requires that aii ̸= 0, for each i = 1, 2, . . . , n. Also, the speed of

Iterative Methods
359
propagation depends on the magnitude of these values. In Gauss-Seidel method all the
most recent available coordinates contribute in acquiring the next coordinate in the vector
x(k+1), while in Jacobi method only the coordinates of the previous steps are used. So
in order to compute x(k+1)
i
we need to use all the previously computed values x(k+1)
j
for
j = 1, 2, . . . , i −1. Commenting finally on the speed of convergence of the Gauss-Seidel
method we note that it is expected in general to converge faster than the Jacobi method.
The implementation of the Gauss-Seidel method in matrix-vector format is straightfor-
ward. In order to extract from A the matrix M = D −L we use the NumPy function tril,
which extracts the lower triangular part of a matrix including its main diagonal. The matrix
M is inverted and using (9.17) we compute the new approximation from the previous one.
1
def gauss_seidel(A, b, x, tol = 1.e-5, maxit = 100):
2
n = len(b)
3
err = 1.0
4
iters = 0
5
# Initialize the solution with the initial guess
6
xnew = np.zeros_like(x)
7
# Extract the lower triangular part of A
8
M = np.tril(A)
9
# Construct the upper triangular part of A
10
U = A - M
11
while (err > tol and iters < maxit):
12
iters += 1
13
# Compute the new approximation
14
xnew = np.dot(npl.inv(M), b - np.dot(U, x))
15
# Estimate convergence
16
err = npl.norm(xnew-x,np.inf)
17
x = np.copy(xnew)
18
print('iterations required for convergence:', iters)
19
return x
Testing the code for the same system as we did in the case of the Jacobi method we
compute the same solution.
1
A = np.array([[2.0, -1.0,
0.0],
2
[-1.0, 3.0, -1.0],
3
[0.0, -1.0,
2.0]])
4
b = np.array([1.0, 8.0, -5.0])
5
x = np.zeros(3)
6
x = gauss_seidel(A, b, x, 1.e-5, 100)
7
print(x)
iterations required for convergence: 11
[ 1.99999577
2.99999718 -1.00000141]
What we observe though is that the Gauss-Seidel method converges in less iterations than
the Jacobi method. Gauss-Seidel required only 11 iterations, which compared with the 24
iterations of the Jacobi method is a significant improvement. It is important to note that
the inversion of the matrix M is a drawback of the previous implementation since inverting
matrices is a slow procedure. An alternative, and perhaps more efficient implementation of
the Gauss-Seidel method, can be based on formula (9.18). Here, the two sums in (9.18) are

360
Numerical Linear Algebra
stored in the variables s1 and s2 and under the assumption aii ̸= 0 the new iteration is
computed via (9.18).
1
def gauss_seidel(A, b, x, tol = 1.e-5, maxit = 100):
2
n = len(b)
3
err = 1.0
4
iters = 0
5
xnew = np.zeros_like(x)
6
while (err > tol and iters < maxit):
7
iters += 1
8
for i in range(n):
9
s1 = np.dot(A[i, :i], xnew[:i])
10
s2 = np.dot(A[i, i + 1:], x[i + 1:])
11
xnew[i] = (b[i] - s1 - s2) / A[i, i]
12
err = npl.norm(xnew-x,np.inf)
13
x = np.copy(xnew)
14
print('iterations required for convergence', iters)
15
return x
The results obtained using the last function are identically the same as before. It is
noted that NumPy arrays are mutable. For this reason, it is required to copy the parts of
an array to a different one in order to extract the upper and lower triangular parts of A.
The convergence of these two classical methods is the subject of the next section.
9.7.3
Convergence of iterative methods
So far, we derived iterative methods of the form
Mx(k+1) = Nx(k) + b,
k = 0, 1, 2, . . . ,
that converge to the solution of the system
Mx = Nx + b .
Subtracting these two equations we get the relationship
M(x(k+1) −x) = N(x(k) −x) ,
or better
x(k+1) −x = G(x(k) −x) ,
where
G = M −1N .
The matrix G is called the iteration matrix.
If ∥G∥< 1 for any natural norm ∥· ∥, then the error converges to 0. In order to see this
consider the error
x(k) −x = G(x(k−1) −x) = G2(x(k−2) −x) = · · · = Gk(x(0) −x) .
This yields ∥x(k) −x∥≤∥Gk∥∥x(0) −x∥. The convergence of the error ∥x(k) −x∥→0
as k →∞is equivalent with the fact that ∥Gk∥→0 as k →0 for any natural norm. This
can happen if ∥G∥< 1 since then ∥Gk∥≤∥G∥k →0. This is also equivalent to ρ(G) < 1

Iterative Methods
361
where ρ(G) is the spectral radius of G. To see this assume that ρ(G) < 1. Recall that from
Theorem 9.5 we have ∥G∥≤ρ(G) + ϵ for all ϵ > 0. If we choose ϵ = (1 −ρ(G))/2, then,
∥G∥≤ρ(G) + ϵ = ρ(G)/2 + 1/2 < 1 ,
since ρ(G) < 1. Inversely, if ∥G∥< 1, then the inequality ρ(G) ≤∥G∥of Theorem 9.4
implies that ρ(G) < 1.
In order for the Jacobi and Gauss-Seidel methods to converge, it can be shown that
A must be strictly row diagonally dominant matrix. A matrix A is strictly row diagonally
dominant if the values of the diagonal entries are greater than the sum of the off-diagonal
entries in the same row. This means
|aii| >
n
X
j=1
j̸=i
|aij|,
1 ≤i ≤n .
(9.19)
For example, the matrix that we used to test our code
A =


2
−1
0
−1
3
−1
0
−1
2

,
is strictly diagonally dominant, and therefore both classical iterative methods converge.
In what follows, we assume that A is strictly row diagonally dominant, and we prove
the convergence of the Jacobi and Gauss-Seidel iteration. If the inequality in (9.19) is not
strict, then A is just called row diagonally dominant.
Convergence of the Jacobi iteration
Denoting the iteration matrix for the Jacobi method by GJ = D−1(L + U), we observe
that
GJ =





0
−a12/a11
· · ·
−a1n/a11
−a21/a22
0
· · ·
−a2n/a22
...
...
...
...
−an1/ann
−an2/ann
· · ·
0




.
However, we have
∥GJ∥∞= max
i
n
X
j=1
j̸=i
−aij
aii
 = max
i
Pn
j=1, j̸=i |aij|
|aii|
< 1 ,
where the last inequality follows from the fact that A is strictly diagonally dominant matrix
and the inequality (9.19). Therefore, the Jacobi iteration is convergent.
Convergence of the Gauss-Seidel iteration
Denote the Gauss-Seidel iteration matrix by GGS = (D −L)−1U. Let λ be an eigenvalue
of GGS with corresponding eigenvector x such that GGSx = λx. Substituting GGS in the
last equation we obtain (D −L)−1Ux = λx which implies that
Ux = (D −L)λx ,
and thus
−
n
X
j=i+1
aijxj = λ
i
X
j=1
aijxj,
i = 1, . . . , n ,

362
Numerical Linear Algebra
or more conveniently
λaiixi = −λ
i−1
X
j=1
aijxj −
n
X
j=i+1
aijxj,
i = 1, . . . , n .
If xk is the entry of x with the largest magnitude, which is equal to 1, then taking absolute
values in the previous relation we have
|λ||akk| ≤|λ|
k−1
X
j=1
|akj| · |xj| +
n
X
j=k+1
|akj| · |xj| .
Solving for |λ| we obtain
|λ| ≤
Pn
j=k+1 |akj|
|akk| −Pk−1
j=1 |akj|
.
Since A is strictly row diagonally dominant we have
|akk| >
n
X
j=1
j̸=i
|akj| ,
which can be written equivalently
|akk| −
k−1
X
j=1
|akj| >
n
X
j=k+1
|akj| .
We conclude that |λ| < 1 and since λ was an arbitrary eigenvalue of GGS we have that the
spectral radius ρ(GGS) < 1. Therefore, after the discussion of Section 9.7.3 we conclude
that the Gauss-Seidel iteration converges.

The classical iterative methods converge when the matrix A is also strictly
column diagonally dominant. They also converge when A is symmetric and positive
definite. For more general matrices we usually use other more sophisticated methods.
9.7.4
Sparse matrices in Python and the module scipy.sparse
Often in applications the resulting matrices are sparse. A matrix is sparse if it has most of
its entries zero. An example of a sparse matrix is the tridiagonal matrix
A =







2
−1
0
· · ·
0
−1
2
−1
· · ·
0
0
...
...
...
0
0
· · ·
−1
2
−1
0
· · ·
0
−1
2







.
Large and sparse matrices can be stored much easier than dense matrices. This can be done
by storing only the non-zero entries in special data structures. We discussed the case of
band matrices in Section 2.3.1. Here we continue the discussion for more general sparse
matrices. SciPy provides tools to handle sparse matrices with the module sparse. There
are seven different types of sparse matrix storage schemes available in Python, which are
listed below:

Iterative Methods
363
bsr matrix: Block Sparse Row matrix
coo matrix: Coordinate format matrix
csc matrix: Compressed sparse column matrix
csr matrix: Compressed sparse row matrix
dia matrix: Sparse matrix with diagonal storage
dok matrix: Dictionary of keys based sparse matrix
lil matrix: Row-based linked list sparse matrix
We will not analyze all these formats here, but we suggest the interested reader to search
online for more information.
Here is an example of sparse storage using the coo matrix format. The non-zero entries
aij ̸= 0 are stored in a one-dimensional array, while the corresponding indices i, j are stored
in two different arrays. Consider the tridiagonal matrix
S =




2
−1
0
0
−1
2
−1
0
0
−1
2
−1
0
0
−1
2



.
We can store this matrix in sparse format using the following commands:
1
from scipy import sparse
2
A = np.array([[ 2.0,-1.0, 0.0, 0.0],
3
[-1.0, 2.0,-1.0, 0.0],
4
[ 0.0,-1.0, 2.0,-1.0],
5
[ 0.0, 0.0,-1.0, 2.0]])
6
S = sparse.coo_matrix(S)
7
print(S)
(0, 0) 2.0
(0, 1) -1.0
(1, 0) -1.0
(1, 1) 2.0
(1, 2) -1.0
(2, 1) -1.0
(2, 2) 2.0
(2, 3) -1.0
(3, 2) -1.0
(3, 3) 2.0
Python stores in S only the non-zero entries and their indices. In order to extract the
non-zero entries and their indices in separate arrays we can use the function find().
1
(I,J,V)=sparse.find(S)
2
print(I,J,V)
[0 1 0 1 2 1 2 3 2 3]
[0 0 1 1 1 2 2 2 3 3]
[ 2. -1. -1.
2. -1. -1.
2. -1. -1.
2.]

364
Numerical Linear Algebra
The coordinate representation of sparse matrices is easy and convenient. We can refer
to each non-zero entry aij by writing V[I[i-1],J[j-1]].
Compressed Sparse Row format
A more sophisticated and very popular sparse storage format that also leads to efficient im-
plementations of sparse matrix computations is the Compressed Sparse Row (CSR) format,
[77]. In CSR format, all the non-zero entries of an n × m matrix A are stored row-wise in
an array A.data while the indices are not stored as coordinates but in an implicit way:
First we define the array A.indptr with length equal to n+1. Its entries serve as counters
to non-zero entries of A. Specifically, starting from 0, the i entry of this array is equal to
the number of the non-zero entries encountered up to the i-1 row of A. Consequently, the
difference A.indptr[i+1]-A.indptr[i] is equal to the number of non-zero entries in the
row i. For example, consider the matrix
A =




10
20
0
0
0
0
0
30
0
40
0
0
0
0
50
60
70
0
0
0
0
0
0
80




with 8 non-zero entries. The CSR format is the following
A.data = [10 20 30 40 50 60 70 80]
A.indptr = [0 2 4 7 8]
Moreover, we define the array A.indices of size equal to the size of A.data. The entries
of A.indices specify the columns where the corresponding entries of A.data are located.
The column indices of row i of A are stored in A.indices[A.indptr[i]:A.indptr[i+1]].
Their corresponding values are kept in A.data[A.indptr[i]:A.indptr[i+1]].
A.indices = [0 1 1 3 2 3 4 5]
This means for example that the first row (i=0) has
A.indptr[1]-A.indptr[0]=2-0=2
nonzero entries and these are located at the columns
A.indices[0]=0
and
A.indices[1]=1
and these are
A.data[0]=10
and
A.data[1]=20.
The second row (i=1) has
A.indptr[2]-A.indptr[1]=4-2=2
non-zero entries located at the columns
A.indices[2]=1
and
A.indices[3]=3
and these are
A.data[2]=30
and
A.data[3]=40.
The third row (i=2) has
A.indptr[3]-A.indptr[2]=7-4=3
non-zero entries located at the columns
A.indices[4]=2,
A.indices[5]=3
and
A.indices[6]=4
and these are
A.data[4]=50,
A.data[5]=60
and
A.data[6]=70.
Finally, the fourth row (i=3) has
A.indptr[4]-A.indptr[3]=8-7=1
non-zero entries located at the column
A.indices[7]=5
and this is A.data[7]=80.

Iterative Methods
365
In Python we can get the CSR format easily using the sparse.csr matrix function as
it is demonstrated in the following example.
1
import numpy as np
2
3
A = np.array([[10, 20,
0,
0,
0,
0],
4
[ 0, 30,
0, 40,
0,
0],
5
[ 0,
0, 50, 60, 70,
0],
6
[ 0,
0,
0,
0,
0, 80]])
7
S = sparse.csr_matrix(A)
8
print(S.data[:])
9
print(S.indptr[:])
10
print(S.indices[:])
[10 20 30 40 50 60 70 80]
[0 2 4 7 8]
[0 1 1 3 2 3 4 5]
It is noted that in addition to the CSR format, there is also the Compressed Sparse
Column (CSC) format, which does exactly the same job with the CSR but for the columns
of the sparse matrix. It happens that Python implementations work faster with the CSC
format than the CSR.
9.7.5
Sparse Gauss-Seidel implementation
We remind that the Gauss-Seidel method for the approximation of the solution of the
system Ax = b is defined by the iteration x(n+1) = Gx(n) + c where G = (D −L)−1U
and c = (D −L)−1b.
We first present a naive implementation of the method for sparse matrices, where we
just store the matrix A into the CSR sparse format in Python. We consider the matrix
A = tridiag(−1, 2, −1), which can be written analytically
A =




2
−1
0
0
−1
2
−1
0
0
−1
2
−1
0
0
−1
2



,
and the vector b = (1, 0, 0, 1). Then the system Ax = b has the unique solution x =
(1, 1, 1, 1). We get the CSR format of A as before.
1
A = np.array([[ 2.0,-1.0, 0.0, 0.0],
2
[-1.0, 2.0,-1.0, 0.0],
3
[ 0.0,-1.0, 2.0,-1.0],
4
[ 0.0, 0.0,-1.0, 2.0]])
5
S = sparse.csr_matrix(A)
6
x = np.ones(4)
7
b = S.dot(x)
In this code we create the right-hand side using the command b = S.dot(x) which
performs sparse matrix vector multiplication. This multiplication takes into account the
sparsity of A and is faster than the full matrix multiplication. In the following code, we
present an implementation of the Gauss-Seidel method for sparse matrices.

366
Numerical Linear Algebra
1
def sp_gauss_seidel(S, b, x, tol = 1.e-5, maxit = 100):
2
n = len(b)
3
xnew = np.zeros_like(x) # create new vector
4
D = sparse.spdiags(S, 0, n, n, format = 'csc')
5
L = sparse.tril(S, 0, format = 'csc')
6
U = sparse.triu(S, 1, format = 'csc')
7
G = -(sparse.linalg.inv(L)).dot(U)
8
c = (sparse.linalg.inv(L)).dot(b)
9
iters = 0
10
err = 1.0
11
while (err > tol and iters < maxit):
12
iters += 1
13
xnew = G*x + c
14
err = npl.norm(xnew-x, np.inf)
15
x = xnew
16
print('iterations required for convergence:', iters)
17
return x
In the previous implementation we formed the iterations using the default sparse matrix
multiplication. For example, we compute the matrix G just by multiplying the inverse of
the sparse matrix D −L which we store in the array L with the sparse matrix U, which is
stored in the array U, by using the command G = -(sparse.linalg.inv(L)).dot(U). Sim-
ilarly, we compute the vector c with the command c = (sparse.linalg.inv(L)).dot(b).
Basically, this is the main ingredient for efficient implementation of iterative methods: The
multiplication of two matrices and the matrix vector multiplication. Finally, we test our
code taking as initial guess the vector x(0) = (0, 0, 0, 0)T .
1
x = np.zeros(len(b))
2
x, niters = sp_gauss_seidel(S, b, x, tol = 1.e-5, maxit = 100)
3
print(x)
iterations required for convergence: 27
[0.99998763 0.9999838
0.9999869
0.99999345]
Avoiding inverse matrix
A sophisticated implementation of Gauss-Seidel method should avoid the computation of
the inverse of D −L, and make use of the indices of the non-zero entries only. In order to
implement the Gauss-Seidel method efficiently, we consider writing the method in vector
format: Let Ai be the i-th row of A. The two sums in the formula
x(k+1)
i
=

bi −
i−1
X
j=1
aijx(k+1)
j
−
n
X
j=i+1
aijx(k)
j

/aii ,
can be represented as the regular vector product of Ai with the vector
z(k) = (x(k+1)
1
, . . . , x(k+1)
i−1
, 0, x(k)
i+1, . . . , x(k)
n )T .
Subsequently, the Gauss-Seidel iteration takes the form
x(k+1)
i
=

bi −Aiz(k)
/aii .

Iterative Methods
367
The implementation of this technique can be the following:
1
def sp_gauss_seidel(S, b, x, tol = 1.e-5, maxit = 100):
2
n = len(b)
3
err = 1.0
4
iters = 0
5
D = S.diagonal()
6
xnew = np.zeros_like(x)
7
while (err > tol and iters < maxit):
8
iters += 1
9
for i in range(n):
10
rowstart = S.indptr[i]
11
rowend = S.indptr[i+1]
12
z = np.copy(x)
13
z[:i] = xnew[:i]
14
z[i]=0.0
15
s = np.dot(S.data[rowstart:rowend], z[S.indices[rowstart:rowend]])
16
xnew[i] = (b[i] - s) / D[i]
17
err = np.linalg.norm(xnew-x,np.inf)
18
x = np.copy(xnew)
19
print('iterations required for convergence:', iters)
20
return x
Testing the code using the same matrices as before we get
1
A = np.array([[ 2.0,-1.0, 0.0, 0.0],
2
[-1.0, 2.0,-1.0, 0.0],
3
[ 0.0,-1.0, 2.0,-1.0],
4
[ 0.0, 0.0,-1.0, 2.0]])
5
S = sparse.coo_matrix(A)
6
x = np.ones(4)
7
S = S.tocsr()
8
b = S.dot(x)
9
x = np.zeros(len(b))
10
x = sp_gauss_seidel(S, b, x, tol = 1.e-5, maxit = 100)
11
print(x)
iterations required for convergence: 27
[0.99998763 0.9999838
0.9999869
0.99999345]
We observe that the more sophisticated implementation gives exactly the same results
as before. The difference is based on the speed only, and the reason for presenting it here is
for pedagogical reasons as Python offers ready-to-use sparse solvers as we shall see later.
9.7.6
Sparse linear systems and the module scipy.sparce
SciPy offers an efficient sparse matrix multiplication. In order to construct a sparse linear
system with exact solution x = (1, 1, 1, 1)T we consider first transforming the matrix A into
CSC or CSR format. Then we can solve the system of equations Sx = b given that S is
in sparse format using the function spsolve of scipy.sparse.linalg. The simplest use of
the function spsolve requires the sparse matrix S and the right-hand side vector b, while
the general call is

368
Numerical Linear Algebra
spsolve(A, b, permc_spec, use_umfpack)
where
A:
Is an array or sparse matrix that will be converted into CSC or CSR format. The
algorithm behind spsolve is faster when matrix A is given in CSC format.
b:
The right-hand side b of the linear system Ax = b.
permc spec: Is a string variable that specifies how to permute the columns of the coefficient
matrix for sparsity preservation. It can take the values NATURAL for natural ordering;
MMD ATA for minimum degree ordering on AT A; MMD AT PLUS A for minimum degree
ordering on the structure of AT +A; and COLAMD, which is an approximate minimum
degree column ordering [45] (Optional with default value COLAMD)
use umfpack: A boolean variable determining whether to use the umfpack for the solution
of the system. Umfpack is a widely used library for the numerical solution of linear
systems written in C programming language. (Optional with default value True)
The function returns just the solution vector x. In the following example, we demonstrate
the simplest use of the function spsolve.
1
from scipy import sparse
2
from scipy.sparse import linalg
3
import numpy as np
4
5
A = np.array([[ 2.0,-1.0, 0.0, 0.0],
6
[-1.0, 2.0,-1.0, 0.0],
7
[ 0.0,-1.0, 2.0,-1.0],
8
[ 0.0, 0.0,-1.0, 2.0]])
9
S= sparse.csc_matrix(A)
10
x = np.ones(4)
11
b = S.dot(x)
12
x = linalg.spsolve(S,b)
13
print(x)
[1. 1. 1. 1.]
Sometimes, it is useful to know where the non-zero entries are located in a sparse matrix
A and if they follow a certain pattern. We can visualize the non-zero structure of a matrix
using the MatPlotLib function spy of the module matplotlib.pyplot, and inspect the
pattern of a matrix. For example, we can see the tridiagonal structure of the previous
matrix with the following commands:
1
plt.spy(S)
2
plt.show()

Iterative Methods
369
0
1
2
3
0
1
2
3
We proceed now with a more precise definition of sparsity. Let N be the total number
of entries of a matrix A. If Nz is the number of zero entries, then we define the sparsity
index of A to be the number
Is = Nz
N .
Obviously, Is ∈[0, 1]. A dense matrix will have sparsity index closer to 1, while the smaller
the number Is is, the sparser the matrix A is. The sparsest matrix will be the zero matrix
with Is = 0.
In Python, we can find the number of non-zero entries of an array A using the function
count non-zero(A) of NumPy. Similarly, the SciPy method S.count non-zero() returns
the number of the non-zero entries of a sparse matrix in CSR format. The last command
is equivalent to count non-zero(S.toarray()) command. In general we can return to a
dense format (or NumPy array) either by using the method toarray() or the method
todense(). The first command returns an array while the former returns a matrix. For
example, we can find the non-zero entries of the previous matrix S as follows.
1
A = np.array([[ 2.0,-1.0, 0.0, 0.0],
2
[-1.0, 2.0,-1.0, 0.0],
3
[ 0.0,-1.0, 2.0,-1.0],
4
[ 0.0, 0.0,-1.0, 2.0]])
5
S = sparse.csr_matrix(A)
6
print(S.count_non-zero())
7
print(np.count_non-zero(S.toarray()))
The result is in both cases 10 as it is expected. Since the sparsity index requires the
number of zero entries Nz, we can compute the sparsity index of S using the formula
1
Is = 1.0-S.count_non-zero()/np.size(S.toarray())
which returns 0.375.
9.7.7
Application in electric circuits
Here we study simple electric circuits consisting of closed connections of batteries, resistors
and wires. The presence of a battery in a circuit generates a flow of electrons current. The
current flows out of the positive terminal of the battery and flows back into the negative
terminal. In the battery representation (see Table 9.2) the positive terminal is the longer
vertical bar.

370
Numerical Linear Algebra
TABLE 9.2
Basic elements of an electrical circuit.
battery
resistor
I0
I1
I2
(a) First law: I1 −I2 −I3 = 0
V1
I
R1
R2
(b) Second law: V1 −V2 −V3 = 0
FIGURE 9.2
Kirchhoff’s laws.
Other devices that are connected to the batteries, such as motors, lightbulbs and heating
coils, generate an opposing force to the flow. For this reason, we call them resistances. The
resistance is a measure of that opposing force.
An electric current is denoted by I and is measured in Amperes (A), a resistance by R
and is measured in Ohms (Ω) and an electrical potential difference (voltage) by V and is
measured in Volts (V ). These three quantities are related with Ohm’s law which determines
the amount of power need to make the current flow through a resistor. This fundamental
law of electricity states that the voltage drop V across a resistor R is V = I · R.
In addition to Ohm’s law, for any electric circuit we have two more conservation laws
known as Kirchhoff’s laws. The first law, which is called current law, states that the sum of
the currents flowing into a node is equal to the sum of the currents flowing out of the same
node. An example of the current law is presented in Figure 9.2 where a current I1 is split
into I2 and I3 at the particular node with I1 = I2 + I3.
The second law states that the sum of the voltage drops around any circuit is equal
to the total voltage around the circuit. This means that the directed sum of the voltages
(potential differences) around a closed loop should be zero. In Figure 9.2, the voltage of the
battery V1 should be equal to the sum of the voltages of the two resistors V2 + V3. Due to
Ohm’s law V2 = I · R1 and V3 = I · R2. Thus, we have that V1 = I · (R1 + R2).
To demonstrate the application of linear systems to electric circuits we compute all the
electric currents running through the circuit shown in Figure 9.3. This particular circuit
consists of three loops (indicated in the figure with an arc) and four junctions (indicated in
the figure with a dot).
Using Kirchhoff’s first law at the three junctions E1, E2, E3, we obtain the following
three equations:
E1 :
I0
−I1
−I4
=
0 ,
E2 :
I1
−I2
−I3
=
0 ,
E3 :
I3
+I4
−I5
=
0 .

Iterative Methods
371
10 V
I0
E1
I1
2 Ω
E2
1 Ω
I2
I0
2 Ω
I3
E3
2 Ω
I5
1 Ω
I4
E4
E6
E5
FIGURE 9.3
An electric circuit.
Applying Kirchhoff’s voltage law at the three closed loops E4, E5, E6, we obtain the fol-
lowing three equations:
E4 :
I4
+2I5
=
10 ,
E5 :
2I1
+2I3
−I4
=
0 ,
E6 :
I2
−2I3
−2I5
=
0 .
For the 6 unknowns Ii, i = 0, 1, . . . , 5 we obtained 6 equations. Our choice of six equations
form the system Ax = b with
A =








1
−1
0
0
−1
0
0
1
−1
−1
0
0
0
0
0
1
1
−1
0
0
0
0
1
2
0
2
0
2
−1
0
0
0
1
−2
0
−2








,
x =








I0
I1
I2
I3
I4
I5








and
b =








0
0
0
10
0
0








,
where A is sparse with more than half of its entries zero. With the help of the function
spsolve we compute the solution x = (7, 3, 4, −1, 4, 3). Similarly, we could use the function
solve of numpy.linalg to solve the system Ax = b and obtain the same result.
1
A = np.array([[ 1.0,-1.0, 0.0, 0.0,-1.0, 0.0],
2
[ 0.0, 1.0,-1.0,-1.0, 0.0, 0.0],
3
[ 0.0, 0.0, 0.0, 1.0, 1.0,-1.0],
4
[ 0.0, 0.0, 0.0, 0.0, 1.0, 2.0],
5
[ 0.0, 2.0, 0.0, 2.0,-1.0, 0.0],
6
[ 0.0, 0.0, 1.0,-2.0, 0.0,-2.0]])
7
b = np.array([0, 0, 0, 10, 0, 0])
8
S = sparse.csc_matrix(A)
9
I = linalg.spsolve(S,b)
10
print('I =', I)
I = [ 7.
3.
4. -1.
4.
3.]

372
Numerical Linear Algebra
9.8
Further Reading
Methods of numerical linear algebra are covered in all classical textbooks of numerical
analysis and computational mathematics due to their significance in natural sciences.
Specialized book with algorithms focusing more on direct methods but with all the de-
tails, intuition and modern techniques is the book [48]. It is noted that the style of
some of the algorithms and methods presented in our book have been influenced sub-
stantially by [48]. A list of books covering extensively topics of numerical linear algebra
includes [135, 29, 45, 24, 8, 32, 69, 37, 35]. Books with focus on iterative methods include
[112, 137, 142, 75, 53, 96, 77]. There are also important books on numerical algorithms
designed for high-performance computing [47].

Chapter Highlights
 There are two basic groups of numerical methods aiming to solve systems of
linear equations, namely direct and iterative methods. Direct methods are
usually more efficient for solving systems represented by dense matrices,
contrary to iterative methods which are ideal for large and sparse matrices.
 The most general direct method is the Gaussian elimination, which is applied
in matrix form using row operations.
 Gaussian elimination leads to the LU factorization of a matrix A.
 The LU factorization of A is a product of a lower triangular matrix L with ones
in the main diagonal and an upper triangular matrix U such that A = LU.
 Having the A = LU factorization we can solve the system Ax = b by
considering the system LUx = b. We first solve the system Ly = b for y
(forward substitution) and then we solve for x the system Ux = y (backward
substitution).
 Floating point arithmetic can lead to failure of Gaussian elimination and thus
to the LU factorization. A remedy for this problem is the interchange of rows
(or columns, or both) using pivoting techniques. The interchange in rows of A
can be represented by a permutation matrix P and the LU factorization can be
written as P A = LU.
 The matrices L and U in the P A = LU factorization with pivoting are not
the same as in the A = LU factorization without pivoting.
 Solving a system Ax = b with LU factorization and pivoting leads to the
solution of the equivalent system P Ax = P b. Then we solve the system
LUx = P b as before.
 The sensitivity of a matrix A to small perturbations can be determined with
the help of the condition number defined as cond(A) = ∥A−1∥∥A∥.
 The LU factorization of a matrix A can be used to compute efficaciously its
inverse A−1 matrix and its determinant det(A).
 The LU factorization of a symmetric matrix leads to the LDLT factorization,
where U = DLT .
 Symmetric and positive definite matrices can be written in the form
A = HHT where H is a lower triangular matrix. This factorization of a
matrix A is known as Cholesky factorization.
 Cholesky factorization can be used as a test for positive definiteness of matrices.
 Two classical iterative methods for the solution of large, sparse systems of
equations are the Jacobi and Gauss-Seidel methods with similar properties and
implementation. Gauss-Seidel converges faster than Jacobi but Jacobi can be
implemented in parallel computers in a trivial way.
373

Exercises
1. Consider the matrices
A =


2
−1
0
−1
2
−1
0
−1
2

,
B =




4
−1
−1
0
−1
4
0
−1
−1
0
4
−1
0
−1
−1
4



,
C =




1
0
2
1
0
4
8
10
2
8
29
22
1
10
22
42



.
(a) Use Gaussian elimination to solve the systems
Ax = a,
Bx = b,
Cx = c ,
where
a = (2, 1, 0)T ,
b = (6, 1, 1, 1)T ,
c = (4, 22, 61, 75)T .
(b) Determine the LU factorization of A, B, C.
(c) Use the LU factorization to solve the systems Ax = a, Bx = b and Cx = c.
2. Consider the matrix
A =


0
1
2
2
−2
1
5
3
1

.
(a) Compute the LU factorization of A using partial pivoting.
(b) Compute the determinant det(A) using the fact that P A = LU.
(c) Compute the inverse of A using the P A = LU factorization of A.
3. Consider the matrix
A =




1
0
2
1
0
4
8
10
2
8
29
22
1
10
22
42



.
(a) Compute the LDLT factorization of A.
(b) Prove that A is positive definite matrix.
(c) Compute the Cholesky factorization of A.
4. Consider a real n × n symmetric and positive definite matrix A.
(a) Prove that the matrix αA + βzzT is symmetric and positive definite for all α > 0,
β ≥0 and z ∈Rn.
(b) Using the previous result, prove that the matrix
B =





α + β
β
· · ·
β
β
α + β
· · ·
β
...
...
...
...
β
β
· · ·
α + β




,
is symmetric and positive definite.
374

(c) Prove that the matrix
C =


3
1
1
1
3
1
1
1
3

,
is symmetric and positive definite.
(d) Compute the Cholesky factorization of C.
5. Let ∥· ∥be a norm in Rn and A invertible n × n matrix. Prove the following:
(a) If Ax = b, (A + δA)(x + δx) = b and ∥A−1∥∥δA∥< 1, then A + δA is invertible
and
∥δx∥
∥x∥≤
cond(A)
1 −∥A−1∥∥δA∥
∥δA∥
∥A∥.
(b) If Ax = b, (A + δA)(x + δx) = b + δb and ∥A−1∥∥δA∥< 1, then A + δA is
invertible and
∥δx∥
∥x∥≤
cond(A)
1 −∥A−1∥∥δA∥
∥δA∥
∥A∥+ ∥δb∥
∥b∥

.
6. Let n = 1000. Construct in Python the n × n banded matrix A
A = pentadiag(1, −4, 6, −4, 1) .
The specific matrix is a symmetric, banded, matrix consisting of 5 diagonals. The main
diagonal consists of 6 only while the other four diagonals have −4 and 1, respectively.
This matrix has lower and upper bandwidth p = 2, which means that it has two non-
zero diagonals above and two below the main diagonals. The total number of non-zero
diagonals is 2 · p + 1 = 5.
Taking advantage of the properties of this matrix we can extend the Cholesky fac-
torization algorithm for banded matrices. Given a symmetric, positive definite matrix
A ∈Rn,n with bandwidth p, the following Algorithm 33 computes a lower triangu-
lar matrix H with lower bandwidth p such that A = HHT . For all i ≥j, H(i, j)
overwrites A(i, j).
To solve a system Ax = b with banded, symmetric and positive definite matrix A we
modify the forward and backward substitution algorithms appropriately to Algorithms
34 and 35.
Algorithm 33 Band Cholesky
for j = 1 : n do
for k = max(1, j −p) : j −1 do
λ = min(k + p, n)
A(j : λ, j) = A(j : λ, j) −A(j, k) · A(j : λ, k)
end for
λ = min(j + p, n)
A(j : λ, j) = A(j : λ, j)/
p
A(j, j)
end for
(a) Compute the number of non-zero entries of A
(b) Prove that A is positive definite.
(c) Use the function cholesky implementing Algorithm 32 to find the Cholesky factor-
ization of A.
375

Algorithm 34 Forward Substitution
for j = 1 : n do
b(j) = b(j)/A(j, j)
b(j + 1 : min(j + p, n)) = b(j + 1 : min(j + p, n)) −A(j + 1 : min(j + p, n), j) · b(j)
end for
Algorithm 35 Backward Substitution
for j = n : −1 : 1 do
b(j) = b(j)/A(j, j)
b(max(1, j −p) : j −1) = b(max(1, j −p) : j −1) −A(j, max(1, j −p) : j −1)T · b(j)
end for
(d) Write a function bandcholesky implementing the banded Cholesky factorization
given by Algorithm 33. Use your function to factorize the matrix A.
(e) Compare your functions with Python function numpy.linalg.cholesky.
(f) Write functions solve and bandsolve to solve the linear system Ax = b with
bi =
n
X
j=1
aij .
To verify the accuracy of the results, compute the norm of the error ∥˜x−x∥2 where ˜x
is the numerical solution and x the exact solution with xi = 1 for all i = 1, 2, . . . , n.
(g) Improve your code by using symmetric band storage. Specifically, taking advantage
of the symmetry and the banded structure of A, store the main diagonal and all
the left diagonals in the rows of a new p × n (dense) matrix Ab using the formula:
Ab(1 + i −j, j) = A(i, j),
for
j ≤i ≤min(n, j + p).
For example, when n = 5 and p = 2 the matrix A is being stored in the 3×5 matrix
Ab:
A =






a11
a12
a13
a21
a22
a23
a24
a31
a32
a33
a34
a35
a42
a43
a44
a45
a53
a54
a55






,
Ab =


a11
a22
a33
a44
a55
a21
a32
a43
a54
∗
a31
a42
a53
∗
∗

.
For more information about the specific band-storage format see Section 2.3.1.
(h) Explore the options of the function cholesky banded of the module scipy.linalg
and use it to get the Cholesky factorization of the particular matrix A. Compare
with the previous results.
(i) Compare the efficiency of all these methods. Among other indicators present the
CPU time required for each implementation. For more information on how to mea-
sure the performance of your code see Section 2.2.7.
7. Consider the linear system Ax = b with
A =


2
−1
0
−1
2
−1
0
−1
2


and
b =


3
−5
5

.
376

(a) Show that the sequences of approximations generated by the Jacobi and Gauss-
Seidel methods converge to the exact solution.
(b) Use the functions jacobi and gauss seidel of Section 9.7.2 to solve the linear
system Ax = b and compare the results. As initial guess for the solution of the
system consider the vector x(0) = (1, 1, 1)T .
(c) Use the function sp gauss seidel of Section 9.7.5 to solve the linear system Ax = b
using the same initial guess of the solution as before.
(d) Write a new function sp jacobi implementing the Jacobi method for matrices
stored is CSR format and solve the linear system Ax = b using the same initial
guess of the solution as before. Compare the results with the previous methods.
8. Let n = 1000. Consider the linear system Ax = b with
bi =
n
X
j=1
aij ,
and the n × n matrix A = pentadiag(1, −4, 6, −4, 1).
(a) Show that A is row diagonally dominant matrix.
(b) Store matrix A is dense format and use the naive Jacobi and Gauss-Seidel methods
to solve the linear system Ax = b.
(c) Store matrix A in CSR format.
(d) Solve the linear system using the function spsolve of module scipy.linalg.
(e) Compare the results in terms of efficiency and performance. For this reason, use the
norm of your preference.
9. (Successive Over-Relaxation) In order to improve the Jacobi and Gauss-Seidel meth-
ods for the numerical solution of a system Ax = b we consider an extrapolation
(relaxation) technique. Let ω ∈R. Then the system Ax = b is written in the follow-
ing way:
Ax = b
ωAx = ωb
ω(D −L −U)x = ωb
(D −D + ωD −ωL −ωU)x = ωb
(D −(1 −ω)D −ωL −ωU)x = ωb
We define the iteration
(D −ωL)x(k+1) = [(1 −ω)D + ωU]x(k) + ωb .
The last method is written:
x(k+1) = Lωx(k) + cω,
k = 0, 1, 2, . . . ,
where Lω = (D −ωL)−1[(1 −ω)D + ωU] and cω = ω(D −ωL)−1. This method is
known as the Successive Over-Relaxation (SOR) method and it is known to converge
to general matrices as long as ω ∈(0, 2). Evaluating the SOR method yields that each
entry of x(k+1) is given by the formula
x(k+1)
i
= (1 −ω)x(k)
i
+ ω

bi −
i−1
X
j=1
aijx(k+1)
j
−
n
X
j=i+1
aijx(k)
j

/aii,
i = 1, . . . , n .
377

(a) Write a Python function implementing efficiently the SOR method for general ω ∈
(0, 2). Then solve the linear system with the same matrix A as before for various
values of ω. Try to implement the SOR method for sparse matrices using the csr
format.
(b) Consider the optimal value ω0 to be the value of ω for which the SOR method
converges with the least iterations. Find an approximation of the optimal value of
the relaxation parameter ω0 ∈(0, 2) by solving the system Ax = b for the values
ωi = 0.1, 0.2, . . . , 1.9.
(c) Compare the convergence of the three methods (Jacobi, Gauss-Seidel and SOR with
the optimal ω).
10. (Sherman-Morrison-Woodbury algorithm for banded matrices) Consider an n×n ma-
trix A with entries aij ̸= 0 only when
 i ≤nk and j ≥n −nk + 1, or
 i ≥n −nk + 1 and j ≤nk, or
 |i −j| ≤na
where 2na + 1 + 2nk < n and nk ≤na. Let ¯
A be an n × n invertible matrix and
u, v ∈Rn vectors such that ¯
A = A + uvT and vT ¯
A−1u ̸= 1.
(a) Show that A is invertible and
A−1 = ¯
A−1 + α( ¯
A−1u)(vT ¯
A−1) ,
where
α =
1
1 −vT ¯
A−1u .
This is the Sherman-Morrison-Woodbury formula which provides a fast and memory
efficient way to compute the inverse of A = ¯
A −uvT .
(b) Let b ∈Rn. Show that the linear system ¯
A¯x = b can be solved using the Sherman-
Morrison-Woodbury algorithm [73]
Algorithm 36 Sherman-Morrison-Woodbury algorithm
Solve the system ¯
A¯x = b
Solve the system ¯
Ay = u
Solve the system ¯
AT z = v
Compute α = 1/(1 −vT y)
Compute β = zT b
Compute the solution x = ¯x + αβy
(c) Show that the complexity of Algorithm 36 is O(n2).
(d) Write a function with input a matrix A, the parameters na and nk and the vector
b. This function should generate appropriate vectors u, v and matrix A. Then the
function will compute approximate solution ˜x of the system Ax = b implementing
Algorithm 36. The function should also estimate the accuracy of the solution by
computing appropriate norm of the residual vector r = Ax −b.
(e) Test your code for the system of Exercise 10 of Chapter 2.
(f) Compute the LU factorization of A and solve the system Ax = b using forward
and backward substitution. Compare the speed of the two methods.
378

11. Consider the n × n tridiagonal matrix
A =







a1
b1
0
c2
a2
b2
...
...
...
cn−1
an−1
bn−1
0
cn
an







,
where ai, bi, ci ∈R for all i.
(a) Assume that A is invertible and has the LU-factorization A = LU with
L =







d1
0
c2
d2
...
...
cn−1
dn−1
0
cn
dn







,
U =







1
e1
0
1
e2
...
...
1
en−1
0
1







.
Verify that d1 = a1, b1 = d1 · e1, and in general dk = ak −ck · ek−1 and bk = dk · ek.
(b) Using the previous observations devise the Algorithm 37 for the computation of the
LU-factorization of the tridiagonal matrix A.
Algorithm 37 LU-factorization for tridiagonal matrices
Given the three diagonals a, b, c of A
The algorithm returns the diagonals d and e
Set d1 = a1
Set e1 = b1/d1
for k = 2 : n −1 do
dk = ak −ck · ek−1
ek = bk/dk
end for
dn = an −cn · en−1
(c) Prove that if |a1| > |b1|, |an| > |cn| and |ak| ≥|bk| + |ck|, for k = 2, . . . , n −1 then
the matrix A is invertible. [Hint: Use mathematical induction to show that dk ̸= 0
for all k = 1, 2, . . . , n, and that |ek| < 1 for k = 1, 2, . . . , n −1]
(d) Adapt the forward and backward substitution Algorithms 30 and 28 for the solution
of the tridiagonal system Ax = f. [Hint: See Algorithms 38 and 39]
Algorithm 38 Forward substitution for tridiagonal matrices
Given the two diagonals c and d of the matrix L and the right-hand side
the algorithm solves the system Ly = f
Set y1 = f1/d1
for k = 2 : n do
yk = (fk −ck · yk−1)/dk
end for
379

Algorithm 39 Backward substitution for tridiagonal matrices
Given the diagonal e of the matrix U and the right-hand side y
the algorithm solves the system Ux = y
Set xn = yn
for k = n −1 : 1 : −1 do
xk = yk −ek · xk−1
end for
(e) Implement the new algorithms in Python where the input will be the three diagonals
of A let’s say a, b and c.
(f) Test your code for the system with A = tridiag(−1, 3, −1) and exact solution xi = 1
for i = 1, 2, . . . , n.
12. Consider the electric circuit depicted in Figure 9.4.
(a) Analyze the particular circuit using Kirchhoff’s laws, and form a linear system with
8 equations and 8 unknowns.
(b) Solve the linear system using dense matrix techniques. Verify that your solution
satisfies all the equations derived from Kirchhoff’s laws.
(c) Solve the linear system using sparse matrix techniques and absolute error tolerance
10−6.
(d) Compare the speed of the two numerical methods and say which one is faster.
(e) Compute the difference of the two solutions and describe their accuracy.
20 V
2 Ω
I0
2 Ω
I1
1 Ω
I7
I0
1 Ω
I2
1 Ω
I4
2 Ω
I3
2 Ω
I5
2 Ω
I6
FIGURE 9.4
An electric circuit.
380

Part III
Advanced Topics

Taylor & Francis 
Taylor & Francis Group 
http://taylorandfrancis.com 

10
Best Approximations
In this chapter, we discuss rigorously the notion of best approximation, and in particular
best approximation of vectors, matrices and functions. This is a more advanced topic com-
pared to previous topics as it introduces some abstract notions. On the other hand, the
discussion is just as important as the previous chapters. We develop the Singular Value
Decomposition (SVD) of a matrix A and compute its best approximation. The SVD is
used extensively in statistics, data science and machine learning, and also in engineering.
We also present the Gram-Schmidt orthonormalization process and the QR factorization,
which are necessary tools for the development of the SVD. In QR factorization, Q is an or-
thogonal matrix and R is an upper triangular. We close this chapter with an application in
image compression, where the compressed image is basically its best approximation. First,
we review the properties of vector spaces.
10.1
Vector Spaces, Norms and Approximations
In Chapter 6 we introduced the notion of approximation of functions by polynomials via
interpolation. To measure the distance between a function and its interpolating polynomial
we introduced the notion of norm. Later in Chapter 9 we introduced norms for vectors and
matrices and we measured the accuracy of approximations. Norms can measure distances
between exact and numerical approximations, but what is the best approximation of a
solution and how can I compute it? In this section we answer to this question by studying
best approximations in abstract vector spaces.
10.1.1
Vector spaces
For the moment we will take the objects to be in a specific linear, real vector space. A set X
of elements u, v, w, . . . is called vector space (over R or C) with the operations of addition
and scalar multiplication if:
(a) For every pair of elements u, v ∈X, their sum u + v is an element of X
(b) For every number λ and every u ∈X the product λu is an element of X
(c) For all u, v, w ∈X and for numbers λ, µ, the operations of addition and scalar multi-
plication have the following properties:
(i) u + v = v + u
(ii) (u + v) + w = u + (v + w)
(iii) u + 0 = u
(iv) 1 · u = u · 1 = u
DOI: 10.1201/9781003287292-10
383

384
Best Approximations
(v) λ(µu) = (λµ)u
(vi) (λ + µ)u = λu + µu
(vii) λ(u + v) = λu + λv.
Vector spaces (sometimes called linear spaces) consist of objects that we call vectors or
elements. These elements can be anything from functions to arrays. For example u and v
can be any two continuous functions in the space X = C[a, b]. We know that the linear
combination of two continuous functions is continuous. On the other hand u and v can be
real n-dimensional vectors, or even m × n matrices. If X is a vector space, then any subset
Y ⊂X that is also a vector space is called subspace of X.
We
discuss
the
notion
of
linear
dependence
and
independence.
The
elements
u1, u2, . . . , un of a vector space X are called linearly dependent if there are constants
λ1, λ2, . . . , λn not all zero such that
λ1u1 + λ2u2 + · · · + λnun = 0 .
On the other hand, their linear combination is zero only when λi = 0 for all i = 1, . . . , n,
in which case the n vectors are called linearly independent. This means that for linearly
independent vectors u1, u2, . . . , un, we have that
λ1u1 + λ2u2 + · · · + λnun = 0 ,
only when λ1 = λ2 = · · · = λn = 0.
Importance of linear independence
Consider n linearly independent column vectors u1, u2, . . . , un of Rn and an n × n matrix
A with columns the vectors ui. Expressing matrix multiplication as Ax = u1x1 + u2x2 +
· · · + unxn implies that the system Ax = 0 has only the solution x = 0, which means that
A is invertible. If the columns of an n × n matrix A are not linearly independent, then A
will not be invertible since the system Ax = 0 will have in addition to the solution x = 0
another solution1 x ̸= 0.

Matrices with linear independent columns or rows are invertible.
Consider an m×n matrix A with r linearly independent columns. The number of linearly
independent columns of A is called the rank of A and is denoted as rank(A). It happens
that the number of linear independent columns and rows of a matrix will be always the
same. Moreover, r cannot exceed the minimum dimension of A, i.e. if m < n, then r ≤m,
while if n < m, then r ≤n. A matrix A is called full-rank if rank(A) = min{m, n}.
10.1.2
Inner products and norms
The next step towards understanding the best approximation of elements of vector spaces
is to define inner products and introduce some geometry. Inner product is a map or bilinear
form ⟨·, ·⟩: X×X →R and is a real number. For example, if u = (u1, u2)T and v = (v1, v2)T
are two vectors of R2, then we define the inner product of u and v as
⟨u, v⟩= u · v = uT v = u1v1 + u2v2 .
1The system Ax = 0 is characterized by the non-uniqueness of its solutions.

Vector Spaces, Norms and Approximations
385
The inner product can also be defined as a map onto C but for the purposes of this book
we focus on real vector spaces with real inner products.
The inner product must satisfy the following properties for all u, v, w ∈X:
(i) ⟨u, u⟩> 0 for all u ̸= 0
(ii) ⟨u, v⟩= ⟨v, u⟩
(iii) ⟨au, v⟩= ⟨u, av⟩= a⟨u, v⟩for any a ∈R
(iv) ⟨u + v, w⟩= ⟨u, w⟩+ ⟨v, w⟩.
If we work with complex inner product instead of real, then the property (ii) can be replaced
by ⟨u, v⟩= ⟨v, u⟩, while in (iii) we can take a ∈C.
If u = f and v = g functions of the vector space C[a, b], we can define an inner product
of C[a, b] to be the integral
⟨f, g⟩=
Z b
a
f(x) g(x) dx ,
(10.1)
for any f, g ∈C[a, b]. This is one of the most commonly used inner products between
functions. We saw this before when we discussed the definition of norms of functions in
Chapter 6.
A vector space equipped with inner product is called inner product space. We will
denote the general inner product space by X. An inner product enhances a vector space
with geometry and things can be visualized. This is mainly because the inner product leads
to the notion of orthogonality. It doesn’t really matter what the objects in the space are,
we can always think of them as points in general spaces. Now that we have in our arsenal
inner products, we define again the norm ∥· ∥: X →[0, +∞) as
∥u∥=
p
⟨u, u⟩,
for any u ∈X .
The norm of u determines the magnitude of u. The magnitude of u is practically its distance
from the origin 0. So if we want to study the distance between two objects u and v, then
it suffices to study the norm ∥u −v∥. This will give us the magnitude of the error between
u and v.
If u = (u1, u2)T is a real vector, then ∥u∥=
p
u2
1 + u2
2, which is exactly the well-known
modulus of vectors. Let’s discuss the norm of a function u = f. Since ∥f∥=
p
⟨f, f⟩, using
the inner product (10.1) we have
∥f∥=
sZ b
a
f 2(x) dx .
This is the norm ∥· ∥2 of Chapter 6.
In any case, we need to measure the accuracy of our approximations, so we need to
define the best approximation in a formal way. Let’s say we have our general vector space
X and its subspace Y as shown in Figure 10.1. We will define the best approximation of a
solution u ∈X to be the closest to u element of Y . So the best approximation will always
depend on the choice of the subspace Y .
For practical reasons think of X as a very complicated space with many elements (di-
mensions), while Y is a low-dimensional space. One such example is the infinite dimensional
space X = C(a, b) of continuous functions and the two-dimensional space of linear polyno-
mials Y = P1. Our object u lives in X and we search for its best approximation v ∈Y .
Obviously, we don’t want to find the best approximation in a totally irrelevant space, and

386
Best Approximations
FIGURE 10.1
The space X and its subspace Y .
that is why we choose Y to be a subspace of X. On the other hand, we could have cho-
sen a more complicated subspace but we need to be very careful so as everything make
sense. Figure 10.1 shows a sketch of a space X and its subspace Y . We repeat that the best
approximation of u will be the element v ∈Y , which is the closest to u.
Before we proceed with a definition of the best approximation, we revise the notion of
orthogonality in analogy to what we know in geometry. Two objects u, v of a vector space
X are orthogonal if and only if ⟨u, v⟩= 0.
u ⊥v
⇐⇒
⟨u, v⟩= 0
The Pythagoras theorem states that for any two orthogonal elements u and v we have
∥u + v∥2 = ∥u∥2 + ∥v∥2 .
(10.2)
This is true because
∥u + v∥2 = ⟨u + v, u + v⟩
= ⟨u, u⟩+ 2⟨u, v⟩+ ⟨v, v⟩
= ∥u∥2 + 2⟨u, v⟩+ ∥v∥2 ,
and since ⟨u, v⟩= 0, then we have the result. Note that the relationship ∥u + v∥2 =
∥u∥2 +2⟨u, v⟩+∥v∥2 generalizes the identity (a+b)2 = a2 +2ab+b2 in the case of vectors.
10.1.3
Best approximations
The best approximation of an object is very similar to an orthogonal projection. The formal
definition of the best approximation is the following:
Definition 10.1. Let u ∈X and Y ⊂X. The best approximation of u in Y is the element
v ∈Y such that
∥u −v∥≤∥u −w∥,
for all w ∈Y .
With this definition of the best approximation we can explore the geometry of an inner
product space. We know from geometry that the shortest distance between a point and
a line in a space is the vertical distance. In Figure 10.2, the space X = R2 and Y is a
straight line. The best approximation of u ∈X in Y ⊂X is the element v ∈Y such as
∥u −v∥≤∥u −w∥for all w ∈Y .

Vector Spaces, Norms and Approximations
387
FIGURE 10.2
Practical representation of best approximation and the orthogonal projection.
The element v is practically the orthogonal projection of u onto Y . In Figure 10.2, the
vector u −v connecting u and v is orthogonal to the line connecting 0 and w (all vector
spaces contain 0). Since orthogonal vectors have zero inner product, we have that
⟨u −v, w⟩= 0 .
We therefore conclude that for u in an inner product space X, its best approximation v in
the subspace Y is the orthogonal projection defined as
⟨u, w⟩= ⟨v, w⟩
for all
w ∈Y .
The fact that v is the closest to u element of Y can be expressed by the inequality
∥u −v∥≤∥u −w∥
for all
w ∈Y .
This is described formally with the following theorem:
Theorem 10.2. Let Y be a subspace of an inner product space X and u ∈X. A vector
v ∈Y is the best approximation of u if and only if
⟨v, w⟩= ⟨u, w⟩,
for all w ∈Y .
(10.3)
Proof. If (10.3) is true, then it suffices to prove that
∥u −v∥≤∥u −w∥,
for all w ∈Y .
From (10.3) we have
⟨u −v, w⟩= 0,
for all w ∈Y ,
and since v ∈Y we can take w = v and thus
⟨u −v, v⟩= 0 .
Subtracting the last two relations we obtain
⟨u −v, v −w⟩= 0 .

388
Best Approximations
This means that the vectors u −v and v −w are orthogonal, and thus from Pythagoras’
theorem we have
∥u −w∥2 = ∥(u −v) + (v −w)∥2 = ∥u −v∥2 + ∥v −w∥2 ≥∥u −v∥2 ,
since ∥v −w∥2 ≥0. Thus, v is the best approximation of u in Y .
On the other hand, if v is the best approximation of u in Y , we can prove (10.3) using a
contradiction. We assume that there is w ∈Y , w ̸= 0, such that ⟨u −v, w⟩̸= 0. We define
the function ϕ : R →R with
ϕ(x) = ∥u −(v + xw)∥2 .
For this function ϕ(x) with x ∈R we have that
ϕ(x) = ⟨u −v −xw, u −v −xw⟩= ∥u −v∥2 −2⟨u −v, w⟩x + x2∥w∥2 ,
which is a quadratic polynomial in x. Its minimum can be achieved at the point x =
⟨u −v, w⟩/∥w∥, and thus
min
x∈R ϕ(x) = ϕ
⟨u −v, w⟩
∥w∥2

< ϕ(0) = ∥u −v∥2 ,
which is a contradiction since v is the best approximation. Thus, ⟨u −v, w⟩= 0.
All the above apply to vectors, matrices and functions by using appropriate inner prod-
ucts and norms. The inner product is not always necessary to define the best approximation,
as the norm suffices by itself. The importance of the inner product is the geometry induced
by it, so we can visualize the orthogonality of the projections.
10.2
Linear Least Squares
In Chapter 6 we studied the problem of least squares where in order to approximate a
set of data (xi, yi), i = 0, . . . , N by a function f(x) that depends on the parameters ai,
i = 0, . . . , m, we used the parameters ai to minimize the error
S(a0, . . . , am) =
N
X
i=0
|yi −f(xi)|2 .
When we chose the function f(x) to be linear, and in particular of the form f(x) = a0x+a1,
the problem was reduced in finding the coefficients a0 and a1 such that the error
S(a0, a1) =
N
X
i=0
|yi −a0xi −a1|2 ,
becomes minimum.
Considering the notation for the matrix
A =





x0
1
x1
1
...
xN
1




,

Linear Least Squares
389
and the vectors
x =
a0
a1

and
b =





y0
y1
...
yN




,
we can write the linear least squares problem in the equivalent form
S(a0, a1) =
N
X
i=0
|bi −a0xi −a1|2 = ∥b −Ax∥2
2 .
This problem is a special case of the more general linear least squares problem: If A is
an m × n matrix and b an m-dimensional vector, then the linear least squares solution x∗
is the n-dimensional vector that minimizes the error function ∥b −Ax∥2
2. In this sense, the
linear least squares approximation is a best approximation. Note that in linear least squares
problem m > n.
The least squares problem can also be understood as a special case of the general opti-
mization problem of finding x∗that minimizes a function F (x). We usually call the solution
x∗optimal solution or minimizer and we write x∗= argminF (x). The optimal solution of
the linear least squares problem is the x∗= argminF (x) where F (x) = ∥b −Ax∥2
2.
10.2.1
Theoretical properties of linear least squares
The linear least squares problem always has a solution, which is also unique if the kernel
of the m × n matrix A with m ≥n consists of the n-dimensional zero vector only, that is
ker(A) = {0}. Recall that the kernel of an m × n matrix A is the set of solutions of the
equation Ax = 0
ker(A) = {x ∈Rn : Ax = 0} .
Proposition 10.3. Let A be any m × n matrix. There is always an optimal solution to the
linear least squares problem x∗= argmin∥b −Ax∥2
2. The optimal solution is also unique if
and only if the kernel of A is ker(A) = {0}.
Proof. We denote by R(A) = range(A) = {Ax ∈Rm : x ∈Rn} the range of A. It is easy
to check that if y ∈R(A), then y is an m-dimensional vector. Let also
R⊥(A) = {z ∈Rm : ⟨z, x⟩= 0 for all x ∈R(A)} .
The space R⊥(A) is called the orthogonal complement of R(A), and consists of m-
dimensional vectors that are perpendicular to every element of R(A). We know from linear
algebra that every vector b ∈Rm can be analyzed into two components b1 ∈R(A) and
b2 ∈R⊥(A) such that b = b1 + b2. Therefore, for any y ∈Rm, we have
b −Ay = (b1 −Ay) + b2 .
Since b1 ∈R(A) and also Ay ∈R(A), then b1 −Ay ∈R(A), and thus b1 −Ay ⊥b2, or
else ⟨b1 −Ay, b2⟩= 0.
We now consider the function F (x) = ∥b −Ax∥2
2. Using the previous analysis of the
vector b = b1 + b2 and the Pythagoras’ Theorem we have
F (x) = ∥b −Ax∥2
2 = ∥b1 −Ax∥2
2 + ∥b2∥2
2 .

390
Best Approximations
Thus, the optimal solution of the problem argmin∥b1 −Ax∥2
2 will be the optimal solution
of the problem argminF (x) as well. Since b1 ∈R(A), we know that there exists an x∗such
that b1 = Ax∗. This implies that ∥b1 −Ax∗∥2
2 = 0. On the other hand ∥b1 −Ax∥2
2 ≥0 =
∥b1 −Ax∗∥2
2 for all x ∈Rn. Therefore, x∗= argmin∥b1 −Ax∥2
2. This proves the existence
of the optimal solution to the linear least squares problem.
In order to prove uniqueness, we need to observe that the linear system Ax = b1 has
a unique solution if and only if the homogenous system Ax = 0 has the unique solution
x = 0, which is equivalent to the fact that ker(A) = {0}.
10.2.2
Solution of linear least squares problem
In this section we derive the solution of the linear least squares problem in closed form. Let
x∗∈Rm be the optimal solution of the linear least squares problem
x∗= argmin∥b −Ax∥2
2 .
If r = b −Ax is the residual, then from the previous section we have that
r = b1 −Ax∗+ b2 = b2 ,
where b1 + b2 = b, b1 ∈R(A) and b2 ∈R⊥(A). Thus, we have that r = b2, and since
b2 ∈R⊥(A), we have that
AT r = AT b = 0 .
The last relationship is very interesting since it guarantees that the residual r is also or-
thogonal to the columns of A. Anyway, we have
0 = AT r = AT (b −Ax∗) = AT b −AT Ax∗.
Thus, we have
AT Ax∗= AT b ,
even if b −Ax∗̸= 0.

The solution of the linear least squares problem x∗= argmin∥b −Ax∥2
2 is the
solution of the linear system AT Ax = AT b.
The matrix AT A is an n × n symmetric matrix since (AT A)T = AT (AT )T = AT A.
If we also assume that ker(A) = {0}, then the matrix AT A is positive definite and thus
invertible. Therefore, the optimal solution of the linear least squares problem is given by
the formula
x∗= (AT A)−1AT b .
(10.4)
The matrix
A+ = (AT A)−1AT ,
is called the pseudoinverse or Moore-Penrose inverse and is of significant importance in
statistics, data science and other modern fields of science and engineering. The matrix A+
is also called generalized inverse since in the special case of invertible n × n matrix A it
coincides with the classical inverse matrix A−1. This can be verified easily by taking
A+ = (AT A)−1AT = A−1(AT )−1AT = A−1 .

Linear Least Squares
391
The pseudoinverse matrix A+ can help to define a condition number for the linear least
squares problem. The condition number of any m × n matrix A is defined as cond(A) =
∥A∥∥A+∥generalizing the condition number of invertible n × n matrices.
The module numpy.linalg provides the function pinv for efficient computation of the
pseudoinverse A+. The input of the function pinv is a matrix A and optionally a tolerant
(rcond with default value 1.e-15). This tolerance is related with the singular values of
A (the square roots of eigenvalues of AT A). Optionally also accepts a boolean variable
hermitian (with default value False) specifying if the matrix A is Hermitian or not.

The pseudoinverse matrix A+ of any m × n matrix A generalizes the classical
inverse of invertible matrices. If AT A is invertible, then the pseudoinverse is given
explicitly as A+ = (AT A)−1AT and provides the solution of the linear least squares
problem x∗= argmin∥b −Ax∥2
2 = A+b.
In terms of best approximations, when we solve the linear least squares problem, we
compute a solution (the optimal solution) such that the residual r is orthogonal to the
range R(A). This means that the optimal solution x∗minimizes the distance of Ax∗from
b in the space R(A). To see this consider an x ∈R(A), and take the inner product
⟨Ax, b −Ax∗⟩= (Ax)T · (b −Ax∗) = 0 .
The solution of linear least squares problem is a best approximation.
10.2.3
Linear least squares problem in Python
As we have already noticed, if ker(A) = {0} then the optimal solution x∗of the linear least
squares problem satisfies the linear system
AT Ax = AT b .
(10.5)
This set of equations is called the normal equations. Since, in this case, the matrix AT A is
symmetric and positive definite, one can solve the linear system (10.5) using the Cholesky
factorization as we saw in Section 9.5. Although, this procedure can be efficient, the Cholesky
factorization of AT A can be inaccurate. The reason for this inaccuracy is that if A is not
well-conditioned, in the sense that its condition number cond(A) is large, then the condition
number cond(AT A) = (cond(A))2 can be even larger. Therefore, we conclude that solving
the linear least squares problem by solving the system of the normal equations is not a good
idea. We will see later that in order to solve efficiently linear least squares problems we can
use other factorization methods, such as the singular value decomposition.
In Python, one can use the function lstsq of the module numpy.linalg to solve linear
least squares problems. The general syntax of this function is
lstsq(a,b,rcond)
where
a:
Is an m × n matrix A
b:
Is the right hand side b
rcond: Is a float that serves as a tolerance in the numerical computations of the solution.
When it is not set, then warnings are printed on the screen. (Optional with default
value rcond=’warn’)

392
Best Approximations
The function lstsq returns a tuple (x, residuals, rank, s) where
x:
Is the optimal solution x∗
residuals: Is the quantity ∥b −Ax∗∥2 for each column of b
rank: Is the rank of A
s:
Is a vector with the singular values of A. These are the eigenvalues of the matrix
AT A.
For the moment we will try to find the argmin∥b −Ax∥2 with
A =


1
1
−1
1
1
1

, and b =


2
1
3

.
This can be done easily with the following code.
1
import numpy.linalg as npl
2
A = np.array([[1.0 , 1.0],
3
[-1.0, 1.0],
4
[1.0, 1.0]])
5
b = np.array([2.0],
6
[1.0],
7
[3.0]])
8
(x, residual, rank,s) = npl.lstsq(A,b)
9
print('x= '); print(x)
10
print('residual= '); print(residual)
11
print('rank= '); print(rank)
12
print('singular values= '); print(s)
x=
[[0.75]
[1.75]]
residual=
[0.5]
rank=
2
singular values=
[2.
1.41421356]
Similarly, there is a function in the module scipy.linalg with the same name lstsq and
some extra capabilities.
Solving the system of the normal equations AT Ax = AT b can be done by computing
first the pseudoinverse A+ = (AT A)−1AT and then the product x = A+b. In the previous
case we can compute the optimal solution x = (3/4, 7/4)T analytically. We verify this
result with Python once more. We first compute the matrix (AT A)−1 and we store it in
the variable tmp. We compute the pseudoinverse (AT A)−1AT and we store it in the array
Amp. Finally, we compute the solution x = A+b and we verify the result.

Gram-Schmidt Orthonormalization
393
1
# Compute the Moore-Penrose inverse
2
tmp = npl.inv(np.dot(np.transpose(A),A))
3
Amp= np.dot(tmp,np.transpose(A))
4
x = np.dot(Amp,b)
5
print('x= '); print(x)
6
print('x= '); print(npl.pinv(A)@b)
x=
[[0.75]
[1.75]]
x=
[[0.75]
[1.75]]
In the last line of the previous code (line 6) we verify the result using the function
pinv of numpy.linalg, while we left for the reader to test the scipy.linalg version of the
function pinv.
The last implementation is not useful for large matrices since the computation of the
inverse of a full and large matrix is not an efficient operation. The next sections are devoted
to tools and methods that are required for the development of the singular value decompo-
sition. They are also very important developments by themselves because of their numerous
applications. We present first the Gram-Schmidt orthonormalization.
10.3
Gram-Schmidt Orthonormalization
Let X be a (finite) n-dimensional vector space with basis {e1, e2, . . . , en}. For example,
think of the space Rn of n-dimensional real vectors2. Any vector x ∈X can be expressed
as a linear combination of these basis functions
x = c1e1 + c2e2 + · · · + cnen .
(10.6)
If we take the inner product of (10.6) with the basis vector ei for i = 1, 2, . . . , n we form
the following equations
⟨e1, e1⟩c1 + ⟨e2, e1⟩c2 + · · · + ⟨en, e1⟩cn = ⟨x, e1⟩,
⟨e1, e2⟩c1 + ⟨e2, e2⟩c2 + · · · + ⟨en, e2⟩cn = ⟨x, e2⟩,
...
⟨e1, en⟩c1 + ⟨e2, en⟩c2 + · · · + ⟨en, en⟩cn = ⟨x, en⟩.
(10.7)
These are the normal equations we discussed before. Assume in addition that the basis
vectors are orthogonal but not necessarily normal. This means that ⟨ei, ej⟩= 0 if i ̸= j,
while ∥ei∥2 = ⟨ei, ei⟩is not necessarily equal to 1. Since ⟨ei, ej⟩= 0 for i ̸= j, then the set
2The dimension of the space X need not be n.

394
Best Approximations
of the normal equations is reduced to
∥e1∥2c1 = ⟨x, e1⟩,
∥e2∥2c2 = ⟨x, e2⟩,
...
∥en∥2cn = ⟨x, en⟩.
(10.8)
Solving for the coefficients ci yields
ci = ⟨x, ei⟩
∥ei∥2 ,
i = 1, 2, . . . , n .
Thus, the vector x can be expressed as
x = ⟨x, e1⟩
∥e1∥2 e1 + ⟨x, e2⟩
∥e2∥2 e2 + · · · + ⟨x, en⟩
∥en∥2 en .
(10.9)
This is an analysis of the vector x into coordinates along the directions of the basis
elements ei. The component ⟨x,ei⟩
∥ei∥2 ei is the projection of the vector x onto ei and is written
usually as
projeix = ⟨x, ei⟩
∥ei∥2 ei .
From this procedure, it is clear that in order to decompose a vector x into its coordinates we
need to know the basis vectors ei, which might not be trivial in a general case. Orthonormal
vectors are orthogonal and at the same time their norm equals 1.
The Gram-Schmidt orthonormalization is a method to produce a set of orthonormal
vectors from an arbitrary set of linearly independent vectors. The resulting vectors can
serve as basis of the vector space, but as we shall see in the next section, the Gram-Schmidt
orthonormalization leads to a matrix factorization different from the LU decomposition.
The basic Gram-Schmidt orthonormalization algorithm is based on the construction of
projections onto vertical directions to generate orthogonal vectors.
Let x1, x2, . . . , xn be linearly independent vectors. Then we define the vectors
e′
1, e′
2, . . . , e′
n such that
e′
1 = x1 ,
e′
2 = x2 −⟨x2, e′
1⟩
⟨e′
1, e′
1⟩e′
1 ,
e′
3 = x3 −⟨x3, e′
1⟩
⟨e′
1, e′
1⟩e′
1 −⟨x3, e′
2⟩
⟨e′
2, e′
2⟩e′
2 ,
...
e′
n = xn −⟨xn, e′
1⟩
⟨e′
1, e′
1⟩e′
1 −· · · −⟨xn, e′
n−1⟩
⟨e′
n−1, e′
n−1⟩en−1 ,
(10.10)
which are the same with
e′
1 = x1 ,
e′
2 = x2 −proje′
1x2 ,
e′
3 = x3 −proje′
1x3 −proje′
2x3 ,

Gram-Schmidt Orthonormalization
395
...
e′
n = xn −
n−1
X
j=1
proje′
jxn .
It is easy to check that ⟨e′
1, e′
2⟩= 0, and also, generally, that ⟨e′
i, e′
j⟩= 0 for j =
1, 2, . . . , i −1, which implies that the vectors e′
1, e′
2, . . . , e′
n are orthogonal. In order to
normalize them, we divide by their norms. We define the orthonormal vectors
ei =
e′
i
∥e′
i∥,
i = 1, 2, . . . , n .
The Gram-Schmidt orthonormalization is summarized in Algorithm 40. In this algorithm
Algorithm 40 Naive Gram-Schmidt orthonormalization procedure
for i = 1 : n do
E′(:, i) = X(:, i)
for j = 1 : i −1 do
E′(:, i) = E′(:, i) −(E(:, j)T X(:, i))E(:, j)
end for
E(:, i) = X(:, i)/∥X(: .i)∥2
end for
we store the linearly independent vectors xi ∈Rm, i = 1, . . . , n into the columns of an m×n
matrix X. We compute the vectors e′
j as columns of matrix E′ and the orthonormal vectors
ei are stored into the columns of matrix E.
10.3.1
Numerical implementation
Direct implementation of the classical Gram-Schmidt process is not recommended because
of rounding errors that can result in non-orthogonal vectors. As a more stable alternative the
following modified Gram-Schmidt process is recommended. In this process the computation
of the vector ei happens in i −1 steps, for i = 1, . . . , n:
e(1)
i
= xi −proje1xi ,
e(2)
i
= e(1)
i
−proje2e(1)
i
,
...
e(i−2)
i
= e(i−3)
i
−projei−2e(i−3)
i
,
e(i−1)
i
= e(i−2)
i
−projei−1e(i−2)
i
,
ei = e(i−1)
i
/∥e(i−1)
i
∥,
Note that the normalization follows immediately after the computation of the orthogonal
vector. This method contains smaller rounding errors and leads to a more stable algorithm.
But again this might not be an ideal algorithm for the generation of orthonormal vectors.
This modified Gram-Schmidt method is summarized in Algorithm 41, where the vectors
xi are stored in the columns of an m × n matrix X and the orthonormal set of vectors is
returned in the columns of an m × n matrix E .
The implementation of the modified Gram-Schmidt algorithm is presented in the next
function gram schmidt:

396
Best Approximations
Algorithm 41 Modified Gram-Schmidt orthonormalization procedure
E(:, 0) = X(:, 0)/∥X(:, 0)∥2
2
for i = 2, n do
E(:, i) = X(:, i)
for j = 1 : i −1 do
E(:, i) = E(:, i) −
 E(:, i)T E(:, j)

E(:, j)/∥E(:, j)∥2
end for
E(:, i) = E(:, i)/∥E(:, i)∥2
end for
1
def gram_schmidt(X):
2
E = np.zeros(np.shape(X))
3
(m,n)=np.shape(X)
4
E[:,0] = X[:,0]/np.sqrt(np.inner(X[:,0],X[:,0]))
5
for i in range(1,n):
6
E[:,i] = X[:,i]
7
for j in range(0,i):
8
proj=np.inner(E[:,i],E[:,j])/np.inner(E[:,j],E[:,j])*E[:,j]
9
E[:,i] = E[:,i]-proj
10
E[:,i] = E[:,i]/np.sqrt(np.inner(E[:,i],E[:,i]))
11
return E
Now, we test our code with the vectors
x1 =




1
−1
−1
1



,
x2 =




2
1
0
1




and
x3 =




2
2
1
2



.
In order to check the orthonormality of the columns of the resulting matrix E we compute
the product ET E which must be the identity matrix.
1
import numpy as np
2
X = np.array([[ 1, 2, 2],
3
[-1, 1, 2],
4
[-1, 0, 1],
5
[ 1, 1, 2]])
6
E = gram_schmidt(X)
7
print('E='); print(E)
8
print('I='); print(np.dot(np.transpose(E),E))
E=
[[ 0.5
0.67082039 -0.40824829]
[-0.5
0.67082039
0.
]
[-0.5
0.2236068
0.40824829]
[ 0.5
0.2236068
0.81649658]]
I=
[[1. 0. 0.]
[0. 1. 0.]
[0. 0. 1.]]

QR Factorization
397
In practice, the Gram-Schmidt orthonormalization algorithm is not used at all. Instead
one can use the QR factorization, which for pedagogical reasons we introduce as a conse-
quence of the Gram-Schmidt method, and then we use it to generate orthonormal vectors.
10.4
QR Factorization
Suppose that we have n linearly independent vectors a1, a2, . . . , an ∈Rm forming the n
columns of an m×n matrix A with m ≥n. Applying the Gram-Schmidt orthonormalization
procedure to the n column-vectors ai we construct n orthonormal vectors ei, for which
a1 = r11e1 ,
a2 = r12e1 + r22e2 ,
...
an = r1ne1 + r2ne2 + · · · + rnnen ,
(10.11)
with rij = ⟨ei, aj⟩being the coefficients obtained from (10.10). Writing (10.11) in matrix-
vector form, we obtain the famous QR factorization of A
A =
 a1
a2
· · ·
an

=
 e1
e2
· · ·
en

·





r11
r12
· · ·
r1n
0
r22
· · ·
r2n
...
...
...
...
0
0
· · ·
rnn




= QR .
The matrix Q is m × n matrix with orthonormal columns (Q−1 = QT ) the vectors from
the Gram-Schmidt orthonormalization procedure, while the matrix R is an n × n upper-
triangular matrix with diagonal entries rii ̸= 0 for all i = 1, 2, . . . , n. If one of those was
zero, let’s say rjj = 0, then the column aj would have been written as a linear combination
of the vectors a1, . . . , aj−1. This contradicts to the assumption that all ai are linearly
independent. Therefore, R is invertible, and Q = AR−1. Hence, rank(Q) = rank(A).

An m × n, full-rank, complex matrix A with m ≥n has a QR factorization
with rii ̸= 0 for all i = 1, 2, . . . , n.
The QR decomposition of a matrix A, contrary to the LU decomposition, is a stable
algorithm and the result is not susceptible to rounding errors. Thus, QR decomposition can
be helpful in various problems. Here we discuss a few applications.
10.4.1
Linear least squares using QR factorization
We have seen that the solution of the linear least squares problem can be found using the
pseudoinverse. The knowledge of the QR decomposition of an m×n matrix A can lead to an
efficient computation of its pseudoinverse A+. Assume that we have the QR decomposition
of A = QR of an m × n matrix A. Using the properties of the orthogonal matrix Q we

398
Best Approximations
have
A+ = (AT A)−1AT
= ((QR)T (QR))−1(QR)T
= (RT QT QR)−1RT QT
= (RT R)−1RT QT
(QQT = I)
= R−1R−T RT QT
(R is nonsingular)
= R−1QT
Since the pseudoinverse of a nonsingular, square matrix coincides with its inverse A−1,
we can use the QR decomposition to compute the inverse of a square matrix A using the
same formula A−1 = R−1QT .
10.4.2
Computation of range
Recall that range of an m × n matrix A is the set range(A) = {Ax : x ∈Rn}. If A has
linearly independent columns and A = QR, then range(A) = range(Q). In order to see
this, consider a vector y ∈range(A). This means that there is an x ∈Rn such that y = Ax.
This is equivalent to
y = QRx = Qz ,
with z = Rx ∈Rn, which is equivalent to y ∈range(Q).
10.4.3
Householder matrices and QR factorization
Although the modified Gram-Schmidt orthonormalization appears to be very stable in ob-
taining the QR factorization of a matrix A, in practice we obtain the QR factorization
using an even more stable algorithm, which is based on series of reflections. For any vector
u, a representation of the reflection about the hyper-plane perpendicular to u is given by
the Householder matrix
H = I −2uuT
∥u∥2 .
For the sake of convenience we often set v = u/∥u∥and we write H = I −2vvT . Such
matrices have been introduced by A. S. Householder (1904–1993) in [68]. Any Householder
matrix H is symmetric since
HT =
 I −2vvT T = IT −2(vvT )T = I −2(vT )T vT = H .
Moreover, H is orthonormal with
H−1H = HT H = H2 = I .
To see this take
HT H =
 I −2vvT 2 = I −2 · 2vvT + 4vvT vvT = I −4vvT + 4v∥v∥2vT = I ,
because ∥v∥= ∥u/∥u∥∥= ∥u∥/∥u∥= 1.
Consider a matrix A with columns a1, a2, . . . , an. If a is a column vector, we define the
Householder matrix H1 with u = a + r1 where
r1 = sign(a1)∥a∥e1 =





sign(a1)∥a∥
0
...
0




.

QR Factorization
399
We observe that ∥r1∥= ∥a∥and subsequently
H1a =

I −2uuT
∥u∥2

a
= a −(a + r1)
2(a + r1)T a
(a + r1)T (a + r1)
= a −(a + r1)
2∥a∥2 + 2rT
1 a
∥a∥2 + aT r1 + rT
1 a + ∥r1∥2
= a −(a + r1)2∥a∥2 + 2rT
1 a
2∥a∥2 + 2rT
1 a
= a −(a + r1)
= −r1 .
The matrix H1 practically is used to transform the first column of A into the first
column of R. Subsequently, we consider the Householder matrix H2 with u = a + r2 with
r2 = sign(a2)∥a∥e2 =







0
sign(a2)∥a∥
0
...
0







,
and a the second column of the matrix H1A with 0 above the principal diagonal. Then the
first row and first column of matrix H2H1A remain unchanged since the first entry of u is 0.
Repeating the same process for every column ai we obtain the product Hn−1 · · · H2H1A =
R, which after inversion of the orthogonal matrices Hi gives us
A = (H1H2 · · · Hn−1)R = QR ,
since H−1
i
= HT
i
= Hi. The matrices Hi are also known as Householder reflections or
reflectors. This is the QR factorization of a matrix A obtained without the use of the
Gram-Schmidt process.
The matrix H = I −2uuT
∥u∥2 is called reflector because the product Hx is a reflection of a
vector x through the perpendicular to u line {z : uT z = 0}. In practice, we never compute
the matrix H but only the result of its application to another matrix. This is made clear
in the Householder QR algorithm as it is presented in Algorithm 42. In order to decrease
the complexity of the Householder algorithm, instead of working with the full matrix A, we
work with sub-matrices at each step.
Algorithm 42 Householder QR
for k = 1, 2, . . . , n do
Define a = A(k : m, k)
Compute w = a + sign(a(1))∥a∥e1 and u = w/∥w∥
Compute A(k : m, k : n) = A(k : m, k : n) −2u(uT A(k : m, k : n))
end for
The algorithm overwrites A with R
This algorithm reduces A to upper-triangular matrix R but it does not explicitly com-
putes the matrix Q. This is because the computation of the matrix Q requires many opera-
tions. Moreover, in applications we usually need the products QT b and Qx. These products
can be computed efficiently using the knowledge of the vectors u, [135].

400
Best Approximations
Although this procedure can lead to a more stable algorithm to implement, again, it is
not the most efficient and stable way to obtain the QR factorization. Other commonly used
methods for the QR factorization can be found in books that specialize in numerical linear
algebra.
10.4.4
Python implementation and orthonormalization
The QR factorization of an m × n matrix A can be computed using the function qr of
numpy.linalg. The general call of this function is
q, r, (h,tau) = qr(a, mode)
The function qr accepts as input a matrix A in the variable a and returns in the output
arrays q and r the matrices Q, R, respectively, and also the tuple (h,tau) where h is
an array with the Householder reflectors. The array tau contains scaling factors for the
Householder reflectors. All the output parameters are optional, so we can call the function
qr using any of the output arguments we need. In addition to the array a, the function qr
accepts as input the optional argument mode, which takes one of the following string values:
‘reduced’, the default value that asks the code to return q and r with dimensions m × k
and k × n; ‘complete’, that asks the code to return q and r with dimensions m × m and
m×n; ‘r’ that asks the code to return only the array r with dimensions k ×n; and ‘raw’,
that asks the code to return only the tuple (h,tau) with dimensions n × k and (k,).
Similarly, there is a SciPy implementation of the QR factorization, namely the function
qr of scipy.linalg. The SciPy implementation can be also called easily as qr(a) since all
its rest arguments are optional.
For example, consider the matrix
A =


2
−2
18
2
1
0
1
2
0

.
We will use the Householder reflections method to compute the QR decomposition analyt-
ically first, and then we will proceed with its numerical computation. Initially, we take the
first column of A, which is a = (2, 2, 1)T with
∥a∥=
p
22 + 22 + 12 = 3 .
The vector r1 is r1 = (3, 0, 0)T and the vector u = a + r1 = (5, 2, 1)T with ∥u∥=
√
30.
Thus,
H1 = I −2uuT
∥u∥2 =


1
0
0
0
1
0
0
0
1

−2
30


25
10
15
10
4
2
5
2
1

= 1
3


−2
−2
−1
−2
11/5
−2/5
−1
−2/5
14/5

.
So, we have
H1A =


−3
0
−12
0
9/5
−12
0
12/5
−6

.
Observe that the first column of H1A is the column vector −r1.
We proceed now with a = (0, 9/5, 12/5)T , the second column of the matrix H1A, where
∥a∥= 3. Here, r2 = (0, 3, 0)T and u = a + r2 = (0, 24/5, 12/5)T with ∥u∥= 12/
√
5. Then,
H2 = I −2uuT
∥u∥2 =


1
0
0
0
1
0
0
0
1

−2
10


0
0
0
0
8
4
0
4
2

= 1
3


1
0
0
0
−3/5
−4/5
0
−4/5
3/5

.

Singular Value Decomposition
401
So, we have
H2H1A =


−3
0
−12
0
−3
12
0
0
6

.
Thus,
R =


−3
0
−12
0
−3
12
0
0
6


and
Q = H1H2 = 1
3


−2
2
1
−2
−1
−2
−1
−2
2

.
We can check the validity of the result by computing the product QR and verifying that
Q is orthogonal. Next, we compute a QR factorization of A using Python and the following
simple script:
1
import numpy as np
2
from numpy.linalg import qr
3
A = np.array([[2.0, -2.0, 18.0],
4
[2.0,
1.0,
0.0],
5
[1.0,
2.0,
0.0]])
6
Q, R = qr( A )
7
print('R= '); print(R)
8
print('Q= '); print(Q)
R=
[[-3.0000000e+00
4.4408921e-16 -1.2000000e+01]
[ 0.0000000e+00 -3.0000000e+00
1.2000000e+01]
[ 0.0000000e+00
0.0000000e+00
6.0000000e+00]]
Q=
[[-0.66666667
0.66666667
0.33333333]
[-0.66666667 -0.33333333 -0.66666667]
[-0.33333333 -0.66666667
0.66666667]]
We observe that the numerical results verify our manual computations. We refer the
interested reader to the references for more sophisticated algorithms related to the compu-
tation of the QR factorization.
10.5
Singular Value Decomposition
A very important decomposition for both Statistics and Machine Learning is the Singular
Value Decomposition (SVD). The SVD has a wide spectrum of applications in many fields of
science, even in cryptography and in image processing. At the end of this chapter, we present
an application of SVD in image processing. A digital image can be represented by an m×n
matrix with entries values that represent the intensity of the colors of the corresponding
pixels. Processing the matrix with the colors of the pixels will result in a modified image.
As you understood very well, we will deal with general rectangular matrices rather than
square matrices. The singular value decomposition of an m × n matrix A is a product of
three matrices UΣV T , where Σ is m × n diagonal matrix, U and V are m × m and n × n
orthogonal matrices, respectively. Recall, that because U and V are orthogonal matrices
we have that U T U = I and V T V = I, and that U and V have orthonormal rows and
columns.

402
Best Approximations
10.5.1
Derivation of SVD
The singular value decomposition is based on computations of eigenvalues and eigenvectors.
Here, A is m × n, so we cannot compute any eigenvalues unless m = n. Although it might
seem to have our hands tight, there are various miracles happening with the SVD, if the
actual SVD is not a miracle. We start by exploring the matrix AT A, which is n × n and
symmetric since (AT A)T = AT (AT )T = AT A. A direct consequence of this, and the fact
that AT A is symmetric and square, is that AT A has real and positive eigenvalues. To see
this, consider an eigenvalue λ of AT A and the corresponding eigenvector x ̸= 0 with real
entries. Since AT Ax = λx we have
0 ≤∥Ax∥2 = Ax · Ax = (Ax)T (Ax) = xT AT Ax
= xT (AT Ax) = xT (λx) = λxT x
= λ∥x∥2 ,
from which we obtain that λ∥x∥2 ≥0, and thus λ ≥0 since ∥x∥> 0.
The eigenvalues of AT A are of great importance. The square roots of these eigenvalues
are called singular values of A and are denoted by σ1, σ2, . . . , σn. In other words, if λi
is the i-th eigenvalue of AT A with xi the corresponding (normalized) eigenvector, then
σi = √λi = ∥Axi∥. It is also very important to consider them ordered in the sense that
σ1 ≥σ2 ≥· · · ≥σn ≥0.
Assume that the nonzero singular values are the σ1, σ2, . . . , σr and all the rest σr+1 =
· · · = σn = 0. Since we want to produce a factorization A = UΣV T , we consider first an
m × n matrix Σ with diagonal values the singular values of A
Σ =

D
0
0
0

and
D =





σ1
0
· · ·
0
0
σ2
· · ·
0
...
...
...
0
0
· · ·
σr




.
Since we want the matrix V of the SVD to be orthogonal, we take V = (v1, v2, . . . , vn)
where vi are the orthonormal vectors produced by the Gram-Schmidt orthonormalization
of the eigenvectors xi of AT A. At this stage, we have chosen Σ and V in the analysis
A = UΣV T and it remains to find matrix U. From the equation A = UΣV T , since
V T V = I (or else since V −1 = V T ) we can solve easily for UΣ and obtain
UΣ = AV .
Moreover, we observe that the columns of AV consist of the vectors Avi, and thus
AV = (Av1, Av2, . . . , Avn) .
The columns Avi, for i = 1, . . . , n are orthogonal. To see this take i ̸= j, and then
(Avi) · (Avj) = (Avi)T (Avj) = vT
i AT Avj = vT
i λjvj = λjvi · vj = 0 .
If Σ was invertible, then we would have defined U = AV Σ−1. Although this is not the
case, it gives us the idea to define the first r columns of U as ui = Avi/σi for i = 1, 2, . . . , r.
This could have been adequate if we could extend this set of r orthogonal column-vectors
to a set of n orthogonal column-vectors. This again can be done by considering the rest ui,
i = r + 1, . . . , m to be the result of the Gram-Schmidt orthonormalization procedure of the
set {u1, u2, . . . , ur, er+1, . . . , em} where er+1, . . . , em are the standard basis vectors of Rm.

Singular Value Decomposition
403
With this construction of Σ, U and V we have that A = UΣV T , which can be written
in the form
A =
  u1
u2
· · ·
ur
ur+1
· · ·
um








σ1
0
· · ·
0
0
σ2
· · ·
0
...
...
...
0
0
· · ·
σr
O
O
O




















vT
1
vT
2
...
vT
r
vT
r+1
...
vT
n













.
Remark 10.4. The singular values σi are the square roots of the eigenvalues λi of the
matrix AT A. If A is symmetric matrix with eigenvalues κi then σi = |κi|. This is because
for symmetric matrix A the product AT A = A2 with eigenvalues λi = κ2
i .
And still we haven’t explored all the magic of this method.

The Singular Value Decomposition of an m × n matrix A is the factorization
A = UΣV T where Σ is a diagonal matrix with values in the main diagonal the r
eigenvalues of the matrix AT A. V is n×n orthogonal matrix with columns the Gram-
Schmidt orthonormalized eigenvectors of AT A, and U is m × m orthogonal matrix
with columns the result of the Gram-Schmidt orthonormalization of the vectors
ui = Avi/σi for i = 1, 2, . . . , r and ui = ei for i = r + 1, . . . , m. The columns of U
are called right singular vectors and the columns of V left singular vectors.
For example, consider the 2 × 3 matrix
A =

1
2
3
3
2
1

,
where m = 2 and n = 3. First, we form the matrix
AT A =


10
8
6
8
8
8
6
8
10

,
which has eigenvalues
λ1 = 24,
λ2 = 4,
and
λ2 = 0 ,
and (normilized) eigenvectors
v1 =
1
√
3


−1
−1
−1

,
v2 =
1
√
2


1
0
−1

,
and
v3 =
1
√
6


1
−2
1

.
Therefore, the singular values of A are σi = √λi for i = 1, 2. More precisely,
σ1 = 2
√
6,
and
σ2 = 2 .
Here r = 2, which coincides with the rank of A since σ2 ̸= 0 and σ3 = 0. Hence, the 2 × 3
matrix Σ is written as
Σ =

2
√
6
0
0
0
2
0

.

404
Best Approximations
The 3 × 3 orthogonal matrix V is defined by the orthonormalized eigenvectors vi and can
be written as
V =
1
√
6


−
√
2
√
3
1
−
√
2
0
−2
−
√
2
−
√
3
1

.
Finally, in order to compute the 2 × 2 matrix U we consider the vectors
u1 = Av1/σ1 =
1
√
2

−1
−1

and
u2 = Av2/σ2 =
1
√
2

−1
1

.
These two vectors are adequate to form the matrix
U =
1
√
2

−1
−1
−1
1

.
It is easy now to verify that A = UΣV T .
10.5.2
Theoretical considerations
Taking the SVD of A we have
A = UΣV T
=
  u1
u2
· · ·
ur
ur+1
· · ·
um








σ1
0
· · ·
0
0
σ2
· · ·
0
...
...
...
0
0
· · ·
σr
O
O
O




















vT
1
vT
2
...
vT
r
vT
r+1
...
vT
n













=
 u1
u2
· · ·
ur






σ1
0
· · ·
0
0
σ2
· · ·
0
...
...
...
0
0
· · ·
σr










vT
1
vT
2
...
vT
r





=
 σ1u1
σ2u2
· · ·
σrur






vT
1
vT
2
...
vT
r





= σ1u1vT
1 + σ2u2vT
2 + · · · + σrurvT
r .
In the previous computations we wrote A as a sum of r matrices A = B1+B2+· · ·+Br
where Bi = σiuivT
i . Something which is intrinsic is that
∥Bi∥= σi∥uivT
i ∥= σi ,
and thus ∥B1∥≥∥B2∥≥· · · ≥∥Br∥. In this way we have obtained a hierarchical analysis
of A in matrices where the first of them is the most important. Now, you might be able to
guess what is the biggest miracle of the singular values of A. This is that the SVD of A
contains all the important information of the matrix A in a hierarchical form, in the sense

Singular Value Decomposition
405
that the largest singular value contains most of the information of the matrix, the second
largest singular value something less and so on. So if we take the first k < r terms in the
sum of Bi’s, we construct an approximate matrix of A. Specifically, the matrix
Ak = UΣkV T =
k
X
i=1
Bi ,
where Σk is the m × n diagonal matrix with entries on the principal diagonal only the
first k singular values σ1, . . . , σk. This is of great importance not only because it is an
approximation of A but because it is the best approximation of rank k. Specifically, we
have the following theorem:
Theorem 10.5. The matrix
Ak =
k
X
i=1
Bi =
k
X
i=1
σiuivT
i ,
is the best rank-k approximation of matrix A by minimizing the ℓ2-norm of the error
∥A −Ak∥2 =
min
rank(B)≤k ∥A −B∥2 .
(10.12)
Moreover,
∥A −Ak∥2 = σk+1 .
Proof. First we observe that rank(Ak) = k. This is because
rank(Ak) = rank(UΣkV T ) = rank(Σk) = k .
For the minimization problem, we consider a matrix B with rank(B) = k. Then the
kernel (null space) ker(B) is of dimension n −k. Take also the space X produced by the
vectors {v1, . . . , vk+1}. Since both ker(B) and X are subspaces of Rn, and the sum of their
dimensions is greater than n we conclude that they have nonempty intersection. If z is a
vector in their intersection with ∥z∥2 = 1 such that Bz = 0, then z = c1v1 + c2v2 + · · · +
ck+1vk+1. Since ∥z∥2 = 1 and vi’s are orthonormal, we have |c1|2 +|c2|2 +· · ·+|ck+1|2 = 1.
So,
(A −B)z = Az = A
k+1
X
i=1
civi =
k+1
X
i=1
ciAvi =
k+1
X
i=1
ciσiui .
Because ui’s are orthogonal, we have
∥(A −B)z∥2
2 =
k+1
X
i=1
|σici|2 ≥σ2
k+1
k+1
X
i=1
|ci|2 = σ2
k+1 .
Hence,
∥A −B∥2 ≥∥(A −B)z∥2
∥z∥2
≥σk+1 .
To show that σk+1 = ∥A −Ak∥2 we take the difference
∥A −Ak∥2 = ∥U(Σ −Σk)V T ∥2 = ∥Σ −Σk∥2 = σk+1 ,
and we have that
∥A −B∥2 ≥∥A −Ak∥2 ,
for any m × n matrix B of rank k.

406
Best Approximations
This best approximation property of the SVD perhaps is the most applicable. It is also
known as Principal Component Analysis. This lies on the fact that from all the ordered
singular values σ1 ≥σ2 ≥· · · ≥σr only some of them are important and the rest can
be discarded. Applications areas are numerous and include machine learning where we can
extract information from a matrix A without using data, and also in dimension reduction
problems where, obviously, by ignoring negligible singular values, the resulting problem is
much simpler and smaller compared to the original one. For an example in image processing
see Section 10.5.6.
On the other hand, the SVD has some other very useful properties. For example, it helps
in the computations with norms.
Theorem 10.6. For any m × n matrix A with singular values σ1 ≥σ2 ≥· · · ≥σr. Then,
(i) ∥A∥2 = σ1
(ii) ∥A∥F =
p
σ2
1 + σ2
2 + · · · + σ2r
Proof. In order to prove (i) we write
∥A∥2 = ∥UΣV T ∥2 =
q
σ(UΣV T (UΣV T )T ) =
q
ρ(UΣV T V (UΣ)T )
=
q
ρ(((UΣ)T UΣ)T ) =
q
ρ((ΣT U T UΣ)T ) =
q
ρ(ΣΣT )
= ∥Σ∥2 = max
i
σi = σ1 .
For the property (ii), similarly, we have
∥A∥F = ∥UΣV T ∥F = ∥Σ∥F =
q
σ2
1 + σ2
2 + · · · + σ2r .
If A is square n × n and invertible (rank(A) = n), then we have some even more
interesting properties.
Theorem 10.7. For any non-singular n × n matrix A we have that
∥A−1∥2 = 1
σn
and thus
cond(A) = σ1
σn
.
Proof. Since, A = UΣV T we have that A−1 = V Σ−1U T , and thus ∥A−1∥2 = 1/σ1
according to the previous theorem. Moreover,
cond(A) = ∥A∥2 · ∥A−1∥2 = σn/σ1 ,
since ∥A∥2 = σn and ∥A−1∥2 = 1/σ1.
10.5.3
Pseudoinverse and SVD
The pseudoinverse matrix A+ can be computed in a trivial way using the singular value
decomposition of A. Recall that the pseudoinverse of an m×n matrix A is the m×n matrix
A+ = (AT A)−1AT . Since AT = (UΣV T )T = V ΣU T , we have that
A+ = (AT A)−1AT = (V ΣU T UΣV T )−1(V ΣU T )
= V (ΣT Σ)−1V T V ΣU T = V (ΣT Σ)−1ΣT U T ,

Singular Value Decomposition
407
and thus we write
A+ = V Σ+U T ,
(10.13)
where Σ+ is the n × m matrix
Σ+ =







1/σ1
0
· · ·
0
0
1/σ2
· · ·
0
...
...
...
...
0
0
· · ·
1/σr
O
O
O







.
10.5.4
Linear least squares problem and SVD
A very important application of the singular value decomposition is the solution of the
linear least squares problem. We try to minimize the error-norm ∥b −Ax∥2
2 for an m × n
matrix A, given that the singular value decomposition of A = UΣV T , with singular values
σ1 ≥σ2 ≥· · · ≥σr > 0. Note that because U is orthonormal, then
∥Ux∥2 =
q
(Ux)T (Ux) =
√
xT U T Ux =
√
xT x = ∥x∥2 ,
for any vector x. Using the orthogonality of U and V , we have
∥Ax −b∥2
2 = ∥U T (Ax −b)∥2
2 = ∥ΣV T x −U T b∥2
2
=
r
X
i=1
(σizi −uT
i b)2 +
m
X
i=r+1
(uT
i b)2 ,
where zi are the entries of the vector z = V T x. Thus, the minimum minx ∥Ax −b∥2
2
can be achieved when σizi −uT
i b = 0 for i = 1, 2, . . . , r, and for arbitrary values zi for
i = r + 1, . . . , n. So, the solution of the linear least squares problem is x∗= V z, where
z ∈Rn is the vector with entries
zi = uT
i b
σi
,
for i = 1, . . . , r ,
zi = 0,
for i = r + 1, . . . , n .
Since z = V T x∗, the minimum norm solution is
x∗= V z =
r
X
i=1
uT
i b
σi
vi .
Moreover, we have
min
x ∥Ax −b∥2
2 =
m
X
i=r+1
(uT
i b)2 .
Given the pseudoinverse A+ = V Σ+U T we can also compute the solution of the linear
least squares problem using the formula (10.4) as x∗= A+b.
10.5.5
Singular value decomposition in Python
We can compute the Singular Value Decomposition of any matrix A in Python just by
using the function svd of the module numpy.linalg. For example, typing U, S, V = svd(

408
Best Approximations
A ) we get the three matrices U, Σ and V T of the SVD. The matrix S contains only the
nonzero diagonal entries of Σ. The general call of the function svd is
svd(a, full_matrices, compute_uv,hermitian)
where
a:
Is an m × n array
full matrices: Is a boolean variable, which is True if the output arrays u and vh have
shapes (m,m) and (n,n), respectively. Otherwise, the shapes are (m,k) and (k,n),
respectively, where k=min(m,n). (Optional with default value True)
compute uv: Is a boolean variable that specifies whether to compute the matrices u and
vh in addition to s. (Optional with default value True)
hermitian: A boolean variable determining whether the matrix A is Hermitian (symmetric
if real-valued). (Optional with default value True)
The function svd returns the arrays u, s and vh with the matrices U, Σ and V T respectively.
For example, let us consider the matrix
A =


1
2
0
2
1
2
0
2
1

,
which is symmetric. Because A is symmetric, its singular values coincide with the absolute
values of the eigenvalues of A. Let’s see if this is true using the following code
1
A = np.array([[1.0, 2.0, 0.0],
2
[2.0, 1.0, 2.0],
3
[0.0, 2.0, 1.0]])
4
U, S, V = npl.svd( A )
5
print(S)
6
print(npl.eigvals(A))
[3.82842712 1.82842712 1.
]
[ 3.82842712
1.
-1.82842712]
Observe that S contains the absolute values of the eigenvalues of A, ordered from the
one with maximum magnitude to the minimum. This is because given an eigenvalue λ of
A, then the eigenvalues of AT A satisfy
AT Ax = AT λx = λAx = λ2x ,
and thus are the eigenvalues of A squared. If we want to verify the result of the svd we
need to transform the diagonal matrix S into a rectangular matrix. In the previous example
we can verify the result A = UΣV T by typing
1
# Convert matrix S into rectangular matrix
2
Sigma = np.zeros((A.shape[0], A.shape[1]))
3
Sigma[:A.shape[1], :A.shape[1]] = np.diag(S)
4
print(U.dot(Sigma.dot(V)))
[[ 1.00000000e+00
2.00000000e+00 -6.66133815e-16]
[ 2.00000000e+00
1.00000000e+00
2.00000000e+00]
[-4.99600361e-16
2.00000000e+00
1.00000000e+00]]

Singular Value Decomposition
409
10.5.6
Application in image compression
Here, we demonstrate how to use the SVD in image compression. We have seen in Section
6.6.6 how to manipulate digital images using arrays. Any digital color image is an arranged
set of pixels. Each pixel has each own color, which can be represented by its values of the
intensity of red, green and blue colors (RGB). These can be a tuple of the form (R, G, B)
where R stands for Red, G for Green and B for Blue. The digital colors can take values
from 0 to 255 and usually are integer values. The value 0 indicates the complete absence of
a specific color. For example, the blue color in the RGB scale will be (0, 0, 255), indicating
that there is no red and green since their values are zero and there is only blue with value
255.
In Python we can read an image using the command imread of the module imageio.
Let’s try using a photo with the name Newton.jpg. The imread function in the following
code reads the digital image stored in the file Newton.jpg and stores it into the rectangular
array photo. Printing the shape of the array photo, we get that this array is 559 × 407 × 3,
which means that our image consists of 559 × 407 pixels, with RGB values stored in three
slices of the array photo. We can print the photo on the screen with the command imshow
of MatPlotLib.
1
import imageio
2
photo = imageio.imread("Newton.jpg") # Read the image into the array photo
3
print(photo.shape)
4
plt.imshow(photo) # Plot the image on the screen
5
plt.show()
In order to do some image processing we store each slice of the array photo in a different
matrix, for example storing the values of the red intensity in the matrix Red, the values of
the green intensity in Green and the respective values for the blue in the matrix Blue. In
this way we will have three 559 × 407 matrices. If we want to explore the intensity of the
colors, then we will need to put the three matrices back in three dimensional arrays and
plot them using the command imshow.
1
# Plot the different matrices using imshow
2
f, axs = plt.subplots(2,2,figsize=(15,15))
3
# Separate the three basic colors
4
Red[:,:,0] = photo[:,:,0]; Green[:,:,1] = photo[:,:,1];
5
Blue[:,:,2] = photo[:,:,2]
6
plt.subplot(2,2,1); plt.imshow(Red); plt.subplot(2,2,2); plt.imshow(Green)
7
plt.subplot(2,2,3); plt.imshow(Blue); plt.subplot(2,2,4); plt.imshow(photo)
8
plt.show()

410
Best Approximations
In this figure we observe that the first three matrices contain only red, green and blue
colors of different intensity, while the last image, which is the original one contains all the
information of the picture.
Now we perform the SVD to these three matrices, and approximate them by keeping
only k singular values. Specifically, we approximate the arrays Red, Green and Blue, using
the property A ≈Ak = UΣkV T . Then we combine the three approximate matrices into
one (putting them in a three-dimensional array), and we plot the approximate matrix.
We will try several values of k, including small and large values, to see how good the
approximation is. Observe first by executing the following code that the rank of the original
matrix is 407. So we choose to compute approximations of the original matrix of rank
5, 10, 20, 40, 100 and 400. We observe that there are practically no significant differences
between the approximation up to rank 40. The image becomes blurred as we use smaller
rank matrices (less singular values) but even with the tiny matrix of rank 5 we can still
recognize the image.
1
U_r,S_r,V_r = svd(Red); U_g,S_g,V_g = svd(Green); U_b,S_b,V_b = svd(Blue)
2
s = len(S_r)
3
sequence = [5, 10, 20, 40, 100, 400]
4
f, axs = plt.subplots(2,3,figsize=(15,15))
5
j=0
6
for k in sequence:
7
U_r_c = U_r[:,0:k]; V_r_c = V_r[0:k,:]; S_r_c = diag(S_r[0:k])
8
U_g_c = U_g[:,0:k]; V_g_c = V_g[0:k,:]; S_g_c = diag(S_g[0:k])
9
U_b_c = U_b[:,0:k]; V_b_c = V_b[0:k,:]; S_b_c = diag(S_b[0:k])
10
comp_img_r = dot(U_r_c, dot(S_r_c,V_r_c))
11
comp_img_g = dot(U_g_c, dot(S_g_c,V_g_c))
12
comp_img_b = dot(U_b_c, dot(S_b_c,V_b_c))
13
comp_img = zeros((row, col, 3))
14
comp_img[:,:,0] = comp_img_r
15
comp_img[:,:,1] = comp_img_g
16
comp_img[:,:,2] = comp_img_b
17
comp_img[comp_img < 0] = 0; comp_img[comp_img > 1] = 1

Further Reading
411
18
j=j+1
19
plt.subplot(2,3,j); plt.title('Rank %d'%(k))
20
plt.imshow(comp_img)
21
plt.show()
Compared to the original image we can see that the compressed images of the SV D
are indeed of very good quality. Moreover, instead of 407 singular values and the respective
singular eigenvectors even 20 are enough for a good quality image. This can be very useful
especially when we deal with huge amount of data. We can approximate a huge matrix
by using its SVD and then analyze its properties using approximations and still get safe
results. This is why the SVD is considered one of the pillars of machine learning.
10.6
Further Reading
The material covered in this chapter such as the QR factorization and the SVD decompo-
sition are usually included in all classical numerical analysis and linear algebra textbooks.
Many details can be found in more specialized books such as [48, 135, 24, 29, 12]. The
Gram-Schmidt orthonormalization is also described in most linear algebra books [128, 129].

Chapter Highlights
 The best approximation v ∈Y ⊂X of an element u ∈X is a solution that
minimizes the error norm of the form ∥u −w∥for all w ∈Y .
 The linear least squares problem is the problem of finding a solution x∗that
minimizes the error ∥b −Ax∥2
2 with A ∈Rm,n (m ≥n) and b ∈Rn. This is
written as x∗= argmin∥b −Ax∥2
2.
 We can compute the solution of the linear least squares problem by solving the
linear system AT Ax = AT b.
 The pseudoinverse of an m × n matrix A is a matrix A+ such that A+A = I.
If AT A is invertible, then the pseudoinverse is given explicitly by the formula
A+ = (AT A)−1AT .
 The pseudoinverse leads to the solution x∗= A+b of linear least squares
problem after multiplying both sides of the equation Ax = b with A+.
 The Gram-Schmidt orthonormalization is an algorithm that generates a set of
orthonormal vectors from a set of linearly independent vectors. The
orthonormal set of vectors generated by the Gram-Schmidt orthonormalization
algorithm can serve as a basis for a linear space.
 Any m × n matrix A (with m ≥n) can be factorized in the form A = QR
where Q is m × m matrix with orthonormal columns and R is an m × n upper
triangular matrix with nonzero diagonal entries.
 In practice we use the QR decomposition of an m × n matrix A instead of the
Gram-Schmidt orthonormalization due to the complexity and numerical
instability of its algorithm. Applications of the QR factorization includes the
computation of the pseudoinverse matrix, the linear least squares problem and
the range of a matrix.
 Householder matrix is a matrix of the form H = I −2uuT /∥u∥2, for any
vector u. Householder matrices are symmetric and orthogonal in the sense
H−1 = HT = H. Householder matrices can be used for the computation of the
QR decomposition.
 The Singular Value Decomposition of an m × n matrix A is the factorization
A = UΣV T where U is m × m and V is n × n orthogonal matrices, while Σ is
an m × n diagonal matrix with the r eigenvalues of the matrix AT A in the
main diagonal. The eigenvalues of AT A are called singular values of A.
 The best rank k approximation matrix of A = UΣV T is the matrix
Ak = UΣkV T where Σk contains only the first k singular values of A.
 Applications of SVD include the solution of the linear least squares problem,
the computation of the pseudoinverse matrix A+, the condition number and
various matrix norms as well as applications in other fields of science such as
image processing and machine learning.
412

Exercises
1. Consider the space Pk of polynomials of degree k, with the inner product
⟨f, g⟩=
Z 1
0
f(x)g(x) dx .
(a) Show that the polynomials p0(t) = 1, p1(t) = t, p2(t) = t2 and p3(t) = t3 are
linearly independent in P3, and that any polynomial of degree 3 can be written as
a linear combination of these functions.
(b) Starting with the set {p0, p1, p2} construct using the Gram-Schmidt orthonormaliza-
tion process a set of orthonormal polynomials {u0, u1, u2} = {1, t−1/2.t2−t+1/6}.
(c) Find a quadratic polynomial p(t) ∈P2, which is the closest to p3(t) = t3. [Hint:
p(t) = 3/2t2 −3/5t + 1/20.
2. Find the best approximation of the function f(x) = ex in the space P3[−1, 1] of cubic
polynomials in [−1, 1] with the norm
∥v∥2 =
sZ 1
−1
|v(x)|2 dx,
v ∈C[−1, 1] .
3. Consider the matrix
A =




1
0
1
1
0
−1
0
1
1
0
1
−1




and the vector
b =




1
1
1
1



.
(a) Solve the linear least squares problem argmin∥b −Ax∥2
2 using the corresponding
normal equations. In order to solve the normal equations employ appropriate nu-
merical method of your choice such as Cholesky decomposition.
(b) Solve the same problem using the QR decomposition of A.
(c) Find the value min ∥b −Ax∥2
2.
4. Let A be an m × n matrix and ∥· ∥the Euclidean vector norm. Prove that
(a) ∥A∥= max {|⟨Ax, y⟩: x ∈Rn, y ∈Rm, ∥x∥= ∥y∥= 1},
(b) ∥A∥= ∥AT ∥,
(c) ∥AT A∥= ∥A∥2.
5. Find the singular value decomposition SVD of the following matrices:
(a) A1 =
−2
0
0
−1

,
(b) A2 =
1
2
2
1

,
(c) A3 =


1
1
0
1
0
0
0
1
1
1
0
0

.
413

6. Consider the matrix
A =




1
1
1
1
1
0
−1
0
1
0
0
1



.
(a) Use the Python function qr to compute the QR decomposition of A.
(b) Use the QR decomposition to compute the solution of the linear least squares prob-
lems Ax = b with b = (1, 2, 3, 4)T .
(c) Compute the SVD of A using the Python function svd.
7. Prove that the pseudoinverse A+ of an m × n matrix A is the unique matrix satisfying:
(a) AA+A = A,
(b) A+AA+ = A+,
(c) (AA+)T = AA+,
(d) (A+A)T = A+A.
8. Prove that for all A ∈Rm×n,
(a) (AT )
+ = (A+)T ,
(b) (A+)+ = A
(c) (AT A)
+ = A+(AT )
+,
(d) (AAT )
+ = (AT )
+,
(e) R(A+) = R(AT ) = R(A+A) = R(AT A), where R(C) = {y ∈Rm : Cx = y} is
the range of C ∈Rm×n,
(f) N(A+) = N(AA+) = N((AAT )
+) = N(AAT ) = N(AT ), where N(C) = {x ∈
Rn : Cx = 0} is the kernel (or null space) of C ∈Rm×n,
(g) If A ∈Rn×n is normal such that AAT = AT A then AkA+ = A+Ak for all k > 0,
and (Ak)+ = (A+)k for all k > 0.
9. Let A ∈Rm×n, b ∈Rn, and suppose AA+b = b. Then for any vector y ∈Rn the vector
x = A+b + (I −A+A)y is a solution to the system Ax = b.
10. For any A ∈Rm×n, prove that
(a) R(A) = R(AAT ),
(b) R(A+) = R(AT ).
11. A planet P is moving in the space following an elliptic orbit. If (x, y) is the location of
the planet at some time in the space, then the equation describing its orbit is given by
the formula
c1x2 + c2xy + c3y2 + c4x + c5y = 634.37 ,
for some parameters c = (c1, c2, . . . , c5)T . Suppose that the following set of observed
locations (xk, yk), k = 1, . . . , 11 has been recorded
x
−0.14
−3.76
3.85
−3.31
−2.84
−1.97
0.42
2.15
2.06
1.53
0.31
−2.51
y
1.51
−2.32
−1.27
−0.18
0.33
0.95
1.50
−0.27
−0.72
−1.67
−2.69
−3.24
(a) Find an overdetermined system Ac = b by using the recorded data for the coeffi-
cients ci, i = 1, . . . , 5.
414

(b) Solve the system Ac = b using the function lstsq of numpy.linalg.
(c) Repeat the previous questions using 9, 10 and 11 recorded locations instead of 12
and plot the different orbits using the following script
1
import numpy as np
2
import matplotlib.pyplot as plt
3
xx = [-0.14, -3.76,-3.85,-3.31,-2.84,-1.97,
4
0.42,2.15,2.06,1.53,0.31,-2.51]
5
yy = [1.51, -2.32,-1.27,-0.18,0.33,0.95,1.5,
6
-0.27,-0.72,-1.67,-2.69,-3.24]
7
x = np.linspace(-5,5,1000)
8
y = np.linspace(-5,5,1000)
9
X,Y = np.meshgrid(x,y)
10
eqn = c[0]* X**2 + c[1]*X*Y + c[2]*Y**2 + c[3]*X + c[4]*Y-634.37
11
Z = 1
12
plt.plot(xx,yy,'o')
13
plt.contour(X,Y,eqn,[Z])
14
plt.xlim([-5,5])
15
plt.ylim([-5,5])
16
plt.show()
(d) In all cases compute the condition number of A. What do you observe?
(e) The exact values of the coefficients are given by the vector
c = (93.21, −75.32, 146.26, 94.78, 196, 29)T .
What is the error between the linear least squares approximations and the exact
values?
415

Taylor & Francis 
Taylor & Francis Group 
http://taylorandfrancis.com 

11
Unconstrained Optimization and Neural Networks
The main objective of optimization is the study of methods for computing best approxi-
mations with special focus on the minimization of functions. We have already studied the
least squares problem, which is the problem of finding the vector x∗∈Rn that minimizes
the error function
E(x) = ∥b −Ax∥2
2 ,
for appropriate matrix A ∈Rm,n and vector b ∈Rm. To solve such problems we employed
direct methods such as the QR decomposition. In this chapter, we will study numerical
methods for the approximation of vectors x∗∈Rn that minimize general functions f(x).
These methods are iterative methods and are used often in problems of data science and
machine learning. For this reason, at the end of this chapter, we present an introduction to
neural networks with some applications.
11.1
Gradient Methods for Unconstrained Optimization
We consider a real function f : Rn →R (often called objective function) with
f := f(x1, x2, . . . , xn) ≡f(x),
x ∈Rn .
A point x∗∈Rn is called minimizer of f if
f(x∗) ≤f(x)
for all
x ∈D ⊂Rn ,
where D is a part or the whole of the domain of f. If D is the entire domain of the function
f, we call x∗global minimizer. If there is another minimum value in a different region of the
domain of f, then x∗is called local minimizer. There is only one global minimizer, while
there might be several local minimizers. The vector x∗that minimizes the function f is
called minimizer, and we write
x∗= argminf(x) .
Similar definitions can be used for the maxima of functions, but because finding maxima of a
function f is the same with finding the minima of the function −f, i.e. max(f) = −min(−f),
we focus on finding minimizers only1. Moreover, we will only consider minimizers that are
not on the boundary of the domain of f but rather an interior point of D where f is
sufficiently smooth.
Convexity is also a factor that plays crucial role in the discussion below. For this reason,
the branch of optimization of convex functions is called convex optimization f, [13]. A
function f is called convex if
f(px + (1 −p)y) < pf(x) + (1 −p)f(y)
for
p ∈(0, 1)
and
x, y ∈D .
1Let y = max(f), then for all x we have f(x) ≥y, which implies −f(x) ≤−y for all x. Therefore,
min(−f) = −y and thus y = −min(−f).
DOI: 10.1201/9781003287292-11
417

418
Unconstrained Optimization and Neural Networks
FIGURE 11.1
An example of convex function.
(a) Saddle point of f(x) = x2
1 −x2
2
(b) Global minimum of f(x) = x2
1 + x2
2
FIGURE 11.2
Multivariable functions and its extreme values.
Note that this definition requires px + (1 −p)y ∈D since D is the domain of f. The
definition implies that the line segment pf(x) + (1 −p)f(y) with p ∈(0, 1) that connects
the point (x, f(x)) with the point (y, f(y)) is above the graph of the function. Convexity
ensures the existence of minima, and thus the solution to the optimization problem. An
example of a convex function is the function f(x) = x2 (see Figure 11.1). In general, we can
imagine convex functions to have similar shape to that of the x2 function.
Optimization of functions relies also on the gradient of a function f, which is defined as
the vector with the partial derivatives of f
∇f(x) =

∂f
∂x1
∂f
∂x2
· · ·
∂f
∂xn
T
.
Recall from multivariable calculus that the local minima of a smooth function f will be the
critical points of f. If f is smooth, then the critical points coincide with the zeros of the
gradient. More precisely, a horizontal tangent plane to f has slope
∇f(x) = 0 .
Note that there might be critical points that are not minimizers of f. These are called saddle
points. For example, the point x1 = 0 is a saddle point of the function f(x) = x3
1. Figure
11.2 shows a case with a saddle in three dimensions.

Gradient Methods for Unconstrained Optimization
419
In general, we assume that the objective function f is sufficiently smooth, in the sense
that all the derivatives are well defined and continuous. The Taylor expansion of a smooth,
multivariable function f in a neighborhood of a vector x can be written in the form
f(x + u) = f(x) + ∇f(x)T u + 1
2uT H(x)u + O(∥u∥3) ,
(11.1)
where u is a vector close enough to x, and H is the Hessian matrix with entries
Hij(x) = ∂2f(x)
∂xi∂xj
.
If ∇f and H are well defined, and if x∗is a minimizer of f, then ∇f(x∗) = 0, and H(x∗)
is positive semidefinite. Conversely, if ∇f(x∗) = 0 and H(x∗) is positive definite, then x∗
is a local minimizer. This generalizes the second derivative test of single variable calculus.
If we consider the first order Taylor expansion of the function f in (11.1), we have
f(x + u) = f(x) + ∇f(ξ)T u ,
for some ξ ∈D. Choosing a direction u such that ∇f(ξ)T u < 0, then we observe that
f(x + u) < f(x) .
This direction u is called descent direction since it leads to smaller values of f.
Denote ⟨·, ·⟩≡⟨·, ·⟩2 and ∥·∥≡∥·∥2 the Euclidean inner product and norm, respectively.
From multivariable calculus we know that the gradient ∇f(x0) is orthogonal to the tangent
line of the level set f(x) = f(x0), and behaves like a compass which shows the direction of
most rapid increase of f. This means that if we are moving on the graph of f(x) and we
wish to move in the direction with the most rapid increase, we shall follow the direction of
the vector ∇f(x0). Moreover, if we choose to move along the direction of a different vector
u, with ∥u∥= 1, then the rate of increase of f in the direction of u at the point x0 is the
inner product ⟨∇f(x0), u⟩= ∇f(x0)T u. Recall that the inner product ⟨∇f(x0), u⟩is the
directional derivative of f and is usually denoted by
∂f(x)
∂u
= ∇f(x)T u .
In order to verify that moving towards the direction of ∇f(x0) we move towards higher
points, we take the inner product between ∇f(x0) and a vector u with ∥u∥= 1. Using the
Cauchy-Schwarz inequality (Theorem 9.3) we obtain
⟨∇f(x0), u⟩≤∥∇f(x0)∥· ∥u∥= ∥∇f(x0)∥.
This means that the rate of increase has the upper bound ∥∇f(x0)∥.
On the other hand, for a particular value of u = u0 with
u0 =
∇f(x0)
∥∇f(x0)∥,
we have
∥∇f(x0)∥= ⟨∇f(x0), u0⟩,
which means that the maximum rate of increase can be achieved if we follow the direction
of the vector u0.

420
Unconstrained Optimization and Neural Networks
If we take u ∈Rn, u ̸= 0, fixed and scaled by λ ∈R, then the Taylor expansion of the
function f around the vector x0 implies for the function g(λ) = f(x0 + λu) that
g(λ) = f(x0 + λu) = f(x0) + λ⟨∇f(x0), u⟩+ O(λ2) .
(11.2)
Obviously, g(0) = f(x0) and g′(0) = ⟨∇f(x0), u⟩and thus, g is increasing if ⟨f(x0), u⟩> 0
and is decreasing when ⟨f(x0), u⟩< 0. Solving (11.2) for λ⟨∇f(x0), u⟩we observe that for
small enough λ > 0, the difference f(x0 +λu)−f(x0) has the same sign as ⟨∇f(x0), u⟩. So
when g(λ) is decreasing, then the decreasing rate is maximal if and only if ⟨∇f(x0), u⟩=
∥∇f(x0)∥∥u∥. This means that the direction of u = −∇f(x0) is the one that leads to the
fastest descent.
From the previous analysis we deduce that moving in the direction of −∇f(x0) leads to
a lower point such that
f(x0 −λ∇f(x0)) = f(x0) −λ∥∇f(x0)∥2 + O(λ2) < f(x0) + O(λ2) .
This leads to the definition of an iterative method for which starting from an initial guess
of the minimizer x(0) we approximate the minimizer x∗of f(x) by the iteration
x(k+1) = x(k) −λ∇f(x(k))
k = 0, 1, 2, . . . .
(11.3)
In order to show that the sequence x(k) converges to a minimizer, assume that x(k) →x∗
as k →∞for some x∗. Then the same holds true for the x(k+1), and thus we have that
∇f(x(k)) →∇f(x∗) = 0.
This is the main idea behind gradient methods. The parameter λ in the language of
machine learning is called learning rate, and can take any arbitrary positive value. To
achieve optimal speed of convergence we assign to λ different values λ = λk, at every
iteration k = 0, 1, 2, . . . . This is the subject of the next few paragraphs.
11.1.1
Estimation of convergence
Let us first estimate the convergence of general gradient method through an example. In
particular, consider the general gradient method of the form
x(k+1) = x(k) −λ∇f(x(k)) ,
(11.4)
for the minimization of f(x) = 1
2(2x2
1 + x2
2). In this case, the Hessian matrix is
H =
2
0
0
1

.
Thus, for every y ∈R2
yT Hy =
 y1
y2
 
2
0
0
1
 
y1
y2

= 2y2
1 + 1y2
2 ≤2∥y∥2 ,
and similarly that
yT Hy ≥∥y∥2 .
Then from the Taylor expansion (11.1) we estimate
f(x(k+1)) = f(x(k)) + ∇f(x(k))T (x(k+1) −x(k)) + 1
2(x(k+1) −x(k))T H(x(k+1) −x(k))
≤f(x(k)) + ∇f(x(k))T (x(k+1) −x(k)) + ∥x(k+1) −x(k)∥2 .

Gradient Methods for Unconstrained Optimization
421
Equation (11.4) implies x(k+1) −x(k) = −λ∇f(x(k)) and thus
f(x(k+1)) = f(x(k)) −λ∥∇f(x(k))∥2 + λ2∥∇f(x(k))∥2 .
The value λopt that minimizes the quadratic polynomial on the right-hand side of the above
equation can be found easily to be 1/2. Thus,
f(x(k+1)) ≤f(x(k)) −1
4∥∇f(x(k))∥2 .
(11.5)
Working in the same way we obtain
f(x) ≥f(x(k)) + ∇f(x(k))T (x −x(k)) + 1
2∥x −x(k)∥2 .
(11.6)
We observe that the left side of (11.6) has minimum at x = x∗while the right-hand side
for x = x(k) −∇f(x(k)). Thus, minimizing both sides with respect to x we obtain
f(x∗) ≥f(x(k)) −1
2∥∇f(x(k))∥2 ,
or equivalently
2f(x∗) ≥f(x∗) + f(x(k)) −1
2∥∇f(x(k))∥2 .
(11.7)
Multiplying (11.5) with 2 and subtracting (11.7) yields
|f(x(k+1)) −f(x∗)| ≤1
2|f(x(k)) −f(x∗)| .
This shows that a gradient method can converge at least linearly. Even if this is not optimal,
it is optimistic. The previous description does not promise convergence in general and for any
value of λ. In particular, there are cases where the method converges only for appropriate
values of λ.
In general, the convergence of the gradient descent method depends on the eigenvalues
of the Hessian matrix. Let the Hessian matrix H be positive definite. Then the eigenvalues
of H are κi > 0, and f is strictly convex. Assume also that 0 < m ≤κi ≤M for all i. We
will see that the convergence is in general linear, and its speed depends on the magnitude
of the ratio m/M.
The Taylor expansion of f(x(k+1)) around x(k) gives
f(x(k+1)) = f(x(k)) + ∇f(x(k))T (x(k+1) −x(k)) + 1
2(x(k+1) −x(k))T H(ξ)(x(k+1) −x(k)) ,
for some ξ close to x(k+1) and x(k). Since H is positive definite, then from the Rayleigh
inequality2 we have
(x(k+1) −x(k))T H(ξ)(x(k+1) −x(k)) ≤M∥x(k+1) −x(k)∥2 .
Thus, we have
f(x(k+1)) ≤f(x(k)) + ∇f(x(k))T (x(k+1) −x(k)) + M
2 ∥x(k+1) −x(k)∥2
= f(x(k)) −λ∇f(x(k))T ∇f(x(k)) + M
2 ∥x(k+1) −x(k)∥2 ,
2The Rayleigh inequality states that for any H = HT we have κmin∥x∥2 ≤xT Hx ≤κmax∥x∥2, where
κmin and κmax are the maximum and minimum eigenvalues of H.

422
Unconstrained Optimization and Neural Networks
which gives
f(x(k+1)) ≤f(x(k)) −λ∥∇f(x(k))∥2 + M
2 λ2∥∇f(x(k))∥2 .
The right-hand side of the last inequality is a quadratic polynomial for the variable λ. By
choosing λ = 1/M we make the right-hand side to be the smallest possible, giving also
f(x(k+1)) ≤f(x(k)) +
1
2M ∥∇f(x(k))∥2 .
(11.8)
Similarly, we have that
f(v) ≥f(w) + ∇f(w)T (v −w) + m
2 ∥v −w∥2 .
Treating the right-hand side as a function of v with w = x(k), and minimizing both sides
in terms of v we obtain f(x∗) ≥f(x(k)) −
1
2m∥∇f(x(k))∥2, which implies
−∥∇f(x(k))∥2 ≤−2m(f(x(k)) −f(x∗)) .
(11.9)
The last inequality is known to as the Polyak- Lojasiewicz inequality, [74]. The estimation
of the convergence rate follows from (11.8) after substitution of the gradient using (11.9)
we obtain
f(x(k+1)) ≤f(x(k)) −m
M (f(x(k)) −f(x∗)) .
Subtracting f(x∗) from both sides implies
f(x(k+1)) −f(x∗) ≤f(x(k)) −f(x∗) −m
M (f(x(k)) −f(x∗)) ,
and factorizing the right-hand side yields
f(x(k+1)) −f(x∗) ≤

1 −m
M

(f(x(k)) −f(x∗)) .
(11.10)
Inequality (11.10) shows that the general gradient method converges linearly. Moreover,
applying (11.10) recursively, we obtain
f(x(k)) −f(x∗) ≤

1 −m
M

(f(x(k−1)) −f(x∗))
≤

1 −m
M
2
(f(x(k−2)) −f(x∗))
· · ·
≤

1 −m
M
k
(f(x(0)) −f(x∗)) .
The constant C = (1 −m/M) characterizes the speed of convergence: Since we will always
have 0 < m ≤M, we deduce that the smaller the quantity C is, the faster the error
f(x(k)) −f(x∗) converges to 0.

General gradient descent methods converge linearly.

Gradient Methods for Unconstrained Optimization
423
11.1.2
Method of steepest descent
The main idea behind gradient methods is to construct approximations x(k+1) from previous
approximations x(k) in the direction of the vector u(k) = −∇f(x(k)). The method of steepest
descent is the gradient method for which the parameter λ = λk in the general iteration
formula
x(k+1) = x(k) −λk∇f(x(k))
k = 1, 2, . . . ,
is chosen to minimize the function g(λ) = f(x(k) −λ∇f(x(k))) and is updated at every
iteration. This value minimizes f(x(k+1)), which means that for λ = λk we have g′(λk) = 0.
The derivative
g′(λ) = d
dλg(λ) = ∇f(x(k) −λ∇f(x(k)))T (−∇f(x(k))) ,
implies for λ = λk that
0 = g′(λk) = −⟨∇f(x(k) −λk∇f(x(k))), ∇f(x(k))⟩.
(11.11)
Because x(k+1) = x(k) −λk∇f(x(k)) we have that
⟨∇f(x(k+1)), ∇f(x(k))⟩= 0 .
Thus, the directions of the vectors ∇f(x(k+1)) and ∇f(x(k)) are orthogonal.
This observation leads to the following property of the method of steepest descent:
Consider three iterations x(k), x(k+1) and x(k+2), then
⟨x(k+1) −x(k), x(k+2) −x(k+1)⟩= λkλk+1⟨∇f(x(k)), ∇f(x(k+1))⟩= 0 ,
or in other words, for every three iterations the directions we followed are orthogonal.
None of the previous observations show how to find the actual value of λk. To find the
optimal value λk one can use methods of Chapter 5 for the approximation of the roots of
g′(λk) = 0. If the minimizer x∗is a point in the interior of the domain of f, and if f is
strictly convex smooth function with
f(px + (1 −p)y) < pf(x) + (1 −p)f(y),
for
0 < p < 1 ,
then the Hessian matrix H(x) is positive definite with entries
Hij(x) = ∂2f(x)
∂xi∂xj
,
i, j = 1, 2, . . . , n .
Moreover, the Hessian matrix is symmetric due to the properties of the second derivatives
of f. Then the Taylor expansion of ∇f(x(k) −λ∇f(x(k))) around x(k) is
∇f(x(k+1)) = ∇f(x(k) −λk∇f(x(k))) = ∇f(x(k)) −λkH(x(k))∇f(x(k)) + O(λ2
k) .
Substituting this formula into (11.11), and discarding the high-order terms of O(λ2
k) we
obtain
0 ≈⟨∇f(x(k)) −λkH(x(k))∇f(x(k)), ∇f(x(k))⟩.
Solving for λk we obtain
λk ≈
∥∇f(x(k))∥2
⟨H(x(k))∇f(x(k)), ∇f(x(k))⟩.

424
Unconstrained Optimization and Neural Networks
Note that this formula can be useful if the initial approximation xk is close to the minimizer
x∗and ∥∇f(x(k))∥2 < ⟨H(x(k))∇f(x(k)), ∇f(x(k))⟩.
An alternative computation of the parameter λk is the Barzilai-Borwein method, [9],
where
λk = |(x(k) −x(k−1))T (∇f(x(k)) −∇f(x(k−1)))|
∥∇f(x(k)) −∇f(x(k−1))∥2
.
A description of the general method of steepest descent can be found in Algorithm 43.
Algorithm 43 Method of steepest descent
Set a tolerance TOL for the accuracy
Initialize x(k) in the domain of f and set k = 0
while ∥∇f(x(k))∥> TOL or ∥x(k+1) −x(k)∥> TOL do
Find λk = argminλ>0f(x(k) −λ∇f(x(k)))
Compute x(k+1) = x(k) −λk∇f(x(k))
Increase the counter k = k + 1
end while
Return the approximation x(k)
This algorithm requires the minimization of the function f(x(k) −λ∇f(x(k))) as a func-
tion of the single variable λ. An alternative of Chapter 5 methods to solve this simple mini-
mization problem is a variant of a search method (like bisection method) known as the golden
section search algorithm, which is presented in the exercises at the end of this chapter3. An
implementation of this algorithm is the function golden of the module scipy.optimize.
The specific function can be used to obtain an approximation to the value λk. The general
call of function golden is the following:
golden(func, args, brac, tol, full_output, maxiter)
where
func: Can be the function g(λ) = f(x −λr)
args: A tuple containing other input arguments of the function func. (Optional with
default value func=())
brack: A tuple (a,b,c), where func(b)<func(a), func(c) used in the process to find
the minimum of f. (Optional with default value brack=None)
tol: The stopping criterion tolerance. (Optional with default value tol=1.5e-8)
full output: Is a bolean variable. If it is True then the function returns optional output.
(Optional with default value full output=0)
maxiter: The maximum number of iterations allowed. (Optional with default value
maxiter=5000)
The output is an approximation of the minimizer. With the help of the function golden we
present an implementation of Algorithm 43 in the following block of code:
3Of course one can use any of the methods presented in Chapter 5.

Gradient Methods for Unconstrained Optimization
425
1
import numpy as np
2
import numpy.linalg as npl
3
import scipy.optimize as spo
4
5
def steepestdescent(f,df,x0,tol=1.e-3,maxit=50):
6
x = x0
7
r = df(x0)
8
iters = 0
9
while ( np.abs(npl.norm(r))>tol and iters<maxit ):
10
lambda_k = spo.golden(g,(x,r))
11
x = x - lambda_k * r
12
r = df(x)
13
iters += 1
14
return x
As an example, we consider the function f(x1, x2) = x2
1/2+5x2
2/2 which has its minimum
value at the point x∗= (0, 0). As an initial guess we consider the value x(0) = (2, 1). Using a
tolerance tol=1.e-8 we are able to achieve a very accurate solution within a few iterations.
1
def f(x):
2
return 0.5*x[0]**2 + 2.5*x[1]**2
3
def df(x):
4
return np.array([x[0], 5*x[1]])
5
def g(lambda_k,x,r):
6
return f(x - lambda_k*r)
7
x0 = np.array([2.0,1.0])
8
x=steepestdescent(f, df, x0, tol = 1.e-8, maxit = 50)
9
print('x = ', x)
x =
[ 6.2403221e-09 -4.9922576e-10]
In order to observe the sequence of the approximations and the orthogonality between
the subsequent vectors generated by the solution we record all the approximations for each
step of the steepest descent method in the following code:
1
def steepestdescent(f,df,x0,tol=1.e-3,maxit=50):
2
xk = x0
3
x = [xk]
4
r = df(x0)
5
iters = 0
6
while (np.abs(npl.norm(r))>tol and iters<maxit):
7
lambda_k = sopt.golden(g,(xk,r))
8
xk = xk - lambda_k * r
9
r = df(xk)
10
x.append(xk)
11
iters += 1
12
return x
13
x0 = np.array([2.0,1.0])
14
x = steepestdescent(f,df,x0,tol=1.e-3,maxit=50)
15
xmesh, ymesh = np.mgrid[-3:3:50j,-2:2:50j]
16
fmesh = f(np.array([xmesh, ymesh]))

426
Unconstrained Optimization and Neural Networks
17
plt.axis("equal")
18
plt.contour(xmesh, ymesh, fmesh, 20)
19
it_array = np.array(x)
20
plt.plot(it_array.T[0], it_array.T[1], "x-")
21
plt.show()
−3
−2
−1
0
1
2
3
−2.0
−1.5
−1.0
−0.5
0.0
0.5
1.0
1.5
2.0
In this example we used a quite large value for tolerance since our intention was to
demonstrate the orthogonality property of the relevant approximations and the convergence
of the method.
11.1.3
Solving linear systems using optimization
Although the method of steepest descent can be applied to very general functions f(x), it is
of special interest the case where f(x) is a quadratic functional and especially a functional
of the form
f(x) = 1
2⟨Ax, x⟩−⟨b, x⟩,
x ∈Rn ,
(11.12)
where A is an n×n matrix and b an n×1 vector. This function is of special interest because
its gradient is the residual of the linear system Ax = b. Specifically, we have
∇f(x) = Ax −b .
(11.13)
If x∗is a minimizer of f, then ∇f(x∗) = Ax∗−b = 0, and thus it is a solution of the linear
system Ax = b. Note that the inner product is the Euclidean inner product and the norm
is the Euclidean norm
⟨x, y⟩=
n
X
i=1
xiyi
and
∥x∥2 =
v
u
u
t
n
X
i=1
x2
i .

Gradient Methods for Unconstrained Optimization
427
To prove (11.13), we compute the partial derivatives of f
∂
∂xk
f(x) =
∂
∂xk
1
2⟨Ax, x⟩−⟨b, x⟩

= 1
2
∂
∂xk
n
X
i=1

xi
n
X
j=1
aijxj

−
∂
∂xk
n
X
i=1
bixi
= 1
2


n
X
j=1
akjxj +
n
X
i=1
xiaik

−bk =
n
X
i=1
akixi −bk = (Ax −b)k .
If A is symmetric (AT = A) and positive definite (⟨Ax, x⟩> 0 for all x ∈Rn, x ̸= 0),
then since ∇f(x∗) = 0, the minimizer is the solution x∗= A−1b of the corresponding linear
system. If x = x∗+ y, y ∈Rn is any other vector, then
f(x) = f(x∗+ y) = 1
2⟨A(x∗+ y), x∗+ y⟩−⟨b, x∗+ y⟩
= 1
2⟨Ax∗, x∗⟩+ 1
2⟨Ax∗, y⟩+ 1
2⟨Ay, x∗⟩+ 1
2⟨Ay, y⟩−⟨b, x∗⟩−⟨b, y⟩
= f(x∗) + ⟨Ax∗−b, y⟩+ 1
2⟨Ay, y⟩
> f(x∗) .
Due to the simplicity of the function f, we can explicitly compute the values of the
parameter λ > 0 to achieve optimal descent rates. Suppose that an initial guess x(0) is
given. We define the residual of the k-th iteration to be
r(k) = b −Ax(k) = −∇f(x(k)) .
(11.14)
If r(k) = 0, then the vector x(k) is the solution of the system Ax = b. Otherwise, we define
the iteration
x(k+1) = x(k) + λr(k) ,
(11.15)
for λ > 0 to be determined so as to minimize the function
g(λ) = f(x(k) + λr(k)) .
Using the linearity of the inner product we can analyze the function g(λ) such as
f(x(k) + λr(k)) = 1
2⟨A(x(k) + λr(k)), x(k) + λr(k)⟩+ ⟨b, x(k) + λr(k)⟩
= 1
2⟨Ax(k), x(k)⟩+ 1
2λ⟨Ax(k), r(k)) + 1
2λ⟨Ar(k), x(k)⟩+ 1
2λ2⟨Ar(k), r(k)⟩
−⟨b, x(k)⟩−λ⟨b, r(k)⟩
= f(x(k)) + 1
2λ2⟨Ar(k), r(k)⟩+ λ⟨Ax(k), r(k)⟩−λ⟨b, r(k)⟩
= f(x(k)) + 1
2λ2⟨Ar(k), r(k)⟩−λ⟨r(k), r(k)⟩.
The last equation is a quadratic polynomial of λ. Since ⟨Ar(k), r(k)⟩> 0 due to the positive
definiteness of A, and r(k) ̸= 0, the quadratic polynomial achieves its minimum value for
λ = λk =
⟨r(k), r(k)⟩
⟨Ar(k), r(k)⟩.
(11.16)

428
Unconstrained Optimization and Neural Networks
Observe that for the specific value of λ we have
f(x(k) + λkr(k)) = f(x(k)) −
⟨r(k), r(k)⟩2
2⟨Ar(k), r(k)⟩< f(x(k)) .
The algorithm for the method of steepest descent in the case of quadratic functions
is presented in Algorithm 44. This algorithm computes the parameter λk using (11.16),
the residual (11.14), and then updates the approximation of the minimizer via (11.15). We
consider here the zero vector as an initial guess for the minimizer, but any other vector can
be used, and then of course, the initialization of the residual should be updated with the
appropriate residual as defined by (11.14).
Algorithm 44 Steepest descent method for linear equations
Set a tolerance TOL for the accuracy
Initialize x(0) = 0 and r(0) = b
Initialize k = 0
while ∥r(k))∥> TOL or ∥x(k+1) −x(k)∥> TOL do
Find λk =
⟨r(k), r(k)⟩
⟨Ar(k), r(k)⟩
Compute x(k+1) = x(k) −λkr(k)
Compute r(k+1) = b −Ax(k+1)
Increase the counter k = k + 1
end while
Return the approximation x(k)
11.1.4
Theoretical considerations
The way we devised the algorithm of the method of steepest descent leads to the conclusion
that the residual r(k) = −∇f(x(k)) is in practice the direction in which we move in order
to approach the minimizer. It is interesting to see that, as in the case of a general function
f(x), these directions are orthogonal, in the sense ⟨r(k), r(k−1)⟩= 0. More precisely, we
have
⟨r(k), r(k−1)⟩= ⟨r(k−1) −⟨r(k−1), r(k−1)⟩
⟨Ar(k−1), r(k−1)⟩Ar(k−1), r(k−1)⟩
= ⟨r(k−1), r(k−1)⟩−⟨r(k−1), r(k−1)⟩
⟨Ar(k−1), r(k−1)⟩⟨Ar(k−1), r(k−1)⟩
= 0 .
Since the iteration of the method of steepest descent is defined as x(k+1) = x(k) +λkr(k)
we can conclude that the vectors connecting three successive iterations are orthogonal, or
in other words
⟨x(k+1) −x(k), x(k) −x(k−1)⟩= ⟨λkr(k), λk−1r(k−1)⟩= 0 .
Proof of convergence
Showing the convergence of the method of steepest descent is not straightforward, and the
information included in this section can appear to be very technical but it is included for
the sake of completeness. We first assume that A is symmetric and positive definite, and
we define the weighted norm
∥x∥A =
p
⟨Ax, x⟩.

Gradient Methods for Unconstrained Optimization
429
In order to see that this inner product forms a vector norm indeed, consider the Cholesky
decomposition of A = HHT , denote HT = A1/2 and write
p
⟨Ax, x⟩=
q
⟨HT x, HT x⟩=
q
⟨A1/2x, A1/2x⟩= ∥A1/2x∥.
Then we have the following theorem:
Theorem 11.1. If
κ = ρmax/ρmin, where ρmax and ρmin the maximum and minimum
eigenvalues of A, respectively, then if e(k) = x(k) −x, is the error between the k-th ap-
proximation x(k) of the method of steepest descent and the solution x of the linear system
Ax = b, then
∥e(k)∥A ≤
κ −1
κ + 1
k
∥e(0)∥A,
k = 1, 2, . . . .
(11.17)
Proof. We first note that
Ae(k+1) = A(x(k+1) −x) = Ax(k+1) −b = −r(k+1) .
Thus,
⟨Ae(k+1), r(k)⟩= −⟨r(k+1), r(k)⟩= 0 .
Furthermore, we observe that
e(k+1) = x(k+1) −x = x(k) + λkr(k) −x = e(k) + λkr(k−1).
Hence, if λ ∈R we have
∥e(k+1)∥2
A = ⟨Ae(k+1), e(k+1)⟩
= ⟨Ae(k+1), e(k) + λkr(k)⟩
= ⟨Ae(k+1), e(k)⟩+ λk⟨Ae(k+1), r(k)⟩
= ⟨Ae(k+1), e(k)⟩+ λ⟨Ae(k+1), r(k)⟩
= ⟨Ae(k+1), e(k) + λr(k)⟩,
where we replaced λk with general λ ∈R, since ⟨Ae(k+1), r(k)⟩= 0.
Using the Cauchy-Schwarz inequality (Theorem 9.3) we have
∥e(k+1)∥2
A = ⟨Ae(k+1), e(k) + λr(k)⟩= ⟨A1/2e(k+1), A1/2(e(k) + λr(k))⟩
≤∥e(k+1)∥A ∥e(k) + λr(k)∥A ,
or equivalently
∥e(k+1)∥2
A ≤∥e(k) + λr(k)∥2
A = ⟨A(e(k) + λr(k)), e(k) + λr(k)⟩,
for all λ ∈R. Since e(k) + λr(k) = (I −λA)e(k) and A(e(k) + λr(k)) = (I −λA)e(k) we
have
∥e(k+1)∥2
A ≤inf
λ∈R⟨(I −λA)Ae(k), (I −λA)e(k)⟩,
k ≥0 .
(11.18)
Here, we denote the eigenvalues of A by ρ, i = 1, 2, . . . . Since A is symmetric and
positive definite we have that
0 < ρmin = ρ1 ≤ρ2 ≤· · · ≤ρn = ρmax .

430
Unconstrained Optimization and Neural Networks
Let zi be the eigenvector of the eigenvalues ρi. For each u ∈Rn we have that
u =
n
X
i=1
⟨u, zi⟩zi .
This is true because the eigenvectors of the specific A can form a basis of Rn. Furthermore,
for any real polynomial P(x), we have that
P(A)u =
n
X
i=1
P(ρi)⟨u, zi⟩zi .
If
e(k) =
n
X
i=1
βizi ,
with βi = ⟨e(k), zi⟩, for all i = 1, 2, . . . , then, for each λ ∈R, the inner product in the
infimum of (11.18) can be estimated as follows
⟨(I −λA)Ae(k), (I −λA)e(k)⟩= ⟨(I −λA)A
n
X
i=1
βizi, (I −λA)
n
X
i=1
βizi⟩
= ⟨
n
X
i=1
(1 −λρi)ρiβizi,
n
X
i=1
(1 −λρi)βizi⟩
=
n
X
i=1
(1 −λρi)2ρiβ2
i
≤(max
i
|1 −λρi|)2
n
X
i=1
ρiβ2
i
= (max
i
|1 −λρi|)2⟨
n
X
i=1
ρiβizi,
n
X
i=1
βizi⟩
= (max
i
|1 −λρi|)2⟨
n
X
i=1
βiAzi,
n
X
i=1
βizi⟩
= (max
i
|1 −λρi|)2⟨Ae(k), e(k)⟩
= (max
i
|1 −λρi|)2∥e(k)∥2
A .
Equation (11.18) then becomes
∥e(k+1)∥2
A ≤inf
λ∈R

max
ρ∈[ρmin,ρmax] |1 −λρ|

∥e(k)∥A,
k ≥0 .
(11.19)
In this min-max problem the optimal value of ρ can be found to be 2/(ρmin + ρmax).
Then we have that
∥e(k+1)∥A ≤ρmax −ρmin
ρmax + ρmin
∥e(k)∥A ,
which implies directly that
∥e(k)∥A ≤
κ −1
κ + 1
k
∥e(0)∥A ,
and the proof is complete.

Conjugate Gradient Method
431
From the last relationship we can see easily that
lim
k→∞e(k) = 0 ,
and thus the convergence can be achieved. For more details, we refer to specialized books
on numerical linear algebra.
11.2
Conjugate Gradient Method
Thus far, we approximated the minimizer x∗of a function f(x) following the direction
r(k) = −∇f(x(k)), for k = 0, 1, 2, . . . . If instead we start with an arbitrary direction r(k) =
p(k), and we try to minimize the value of the function f(x(k+1)) using the approximation
x(k+1) = x(k) + λp(k) we obtain a new method. This new method is known as the method
of general directions.
For simplicity, we consider the quadratic function
f(x) = 1
2⟨Ax, x⟩−⟨b, x⟩,
where A being a positive definite matrix, and we estimate the value f(x(k+1)).
f(x(k+1)) = f(x(k) + λp(k))
= 1
2⟨A(x(k) + λp(k)), x(k) + λp(k)⟩−⟨b, x(k) + λp(k)⟩
= 1
2⟨Ax(k), x(k)⟩+ λ⟨Ax(k), p(k) + 1
2λ2⟨Ap(k), p(k)⟩−⟨b, x(k)⟩−λb, p(k+1)⟩
= f(x(k)) + 1
2λ2⟨Ap(k), p(k)⟩−λ⟨p(k), r(k)⟩.
From the last equality we conclude that eliminating the positive inner product we achieve
the minimization of f(x(k+1)). This can be achieved if ⟨p(k), r(k)⟩̸= 0 by taking
λ = λk =
⟨p(k), r(k)⟩
⟨Ap(k), p(k)⟩,
leading to
f(x(k+1)) = f(x(k)) −
⟨p(k), r(k)⟩2
2⟨Ap(k), p(k)⟩< f(x(k)) .
In such a case, the sequence of the values f(x(k)) will be strictly decreasing and bounded
from below by the value f(A−1b), and thus will converge to the limit
lim
k→∞f(x(k)) ≥f(A−1b) .
This fact of course doesn’t guarantee the convergence of the method to the solution of the
linear system x = A−1b since this would require
lim
k→∞f(x(k)) = f(A−1b) ,
which cannot be proved. The idea, though, of choosing other directions than those of the
method of steepest descent leads to the very important method of conjugate gradient which
was introduced by Magnus Hestenes (1906–1991) and Edward Stiefel (1909–1978), [60].

432
Unconstrained Optimization and Neural Networks
11.2.1
Conjugate gradient method and linear systems
In the previous analysis, where we used a general direction p(k) instead of the directions of
the steepest descent r(k) = −∇f(x(k)), we observed that each iteration x(k+1) is a linear
combination of the previous iteration x(k) and the direction p(k). This implies that
x(k+1) = x(k) + λkp(k)
= x(k−1) + λk−1p(k−1) + λkp(k)
...
= x(0) +
k
X
i=0
λkp(k) .
This is also true for the method of steepest descent, where
x(k+1) = x(0) +
k
X
i=0
λkr(k) .
Thus, in both methods the difference x(k+1) −x(0) is a linear combination of the previously
chosen directions. If all these directions were linearly independent, then they would form a
linear space. If the initial guess lies in the same space, then the same will happen to the
approximate solution x(k) for any k = 1, 2, . . . . We proceed with the generation of such
linearly independent directions p(k).
Let the n × n matrix A be symmetric and positive-definite (xT Ax > 0 for all non-zero
vectors x ∈Rn). Then two vectors u, v ∈Rn, u ̸= v are called conjugate with respect to A
(or A-orthogonal) if
uT Av = 0 .
This product is simply the inner product ⟨Av, u⟩= uT Av. In the sequel, we refer to such
vectors as conjugate without mentioning their dependence on the matrix A.
Suppose that we have k + 1 conjugate vectors p(0), p(1), . . . , p(k). These vectors are
linearly independent. To see this consider the linear combination
c0p(0) + c1p(1) + · · · + ckp(k) = 0 ,
with ci ∈R for i = 0, 1, . . . , k. Taking the inner product with Ap(j) for all j = 0, 1, . . . , k
we have
0 = ⟨Ap(j),
k
X
i=0
cip(i)⟩=
k
X
i=0
ci⟨Ap(j), p(i)⟩= cj⟨Ap(j), p(j)⟩.
Since A is positive definite we have that ⟨Ap(j), p(j)⟩> 0 for all j = 0, 1, . . . , k. Thus, we
have that cj = 0 for all j = 0, 1, . . . , k.
Given the initial guess x(0), we define the first direction to be p(0) = b −Ax(0), which
coincides with the direction of the steepest descent −∇f(x(0)) for the function f(x) =
1
2⟨Ax, x⟩+ ⟨b, x⟩. The rest of the vectors should be conjugate to the gradient and to each
other.
Note that the residual
r(k) = b −Ax(k) = b −A(x(k−1) + λk−1p(k−1)) = r(k−1) −λk−1Ap(k−1) .
Given the conjugate direction p(k) it holds (can be proved using induction) that
⟨r(k), p(j)⟩= 0,
j = 0, 1, 2, . . . k −1 .

Conjugate Gradient Method
433
What remains is to find the conjugate direction p(k) given the conjugate direction p(k−1).
The new vector will be also conjugate to the others by construction. We choose the new
direction p(k) to be a linear combination of the residual −r(k) and the previous conjugate
direction p(k−1). Specifically, we consider the new direction to be
p(k) = −r(k) + βkp(k−1) .
We compute the values βk as follows: We first take the inner product of p(k) with Ap(k−1)
to get
⟨Ap(k−1), p(k)⟩= −⟨Ap(k−1), r(k)⟩+ βk⟨Ap(k−1), p(k−1)⟩.
(11.20)
Since ⟨Ap(k−1), p(k)⟩= 0, solving equation (11.20) yields
βk =
⟨Ap(k−1), r(k)⟩
⟨Ap(k−1), p(k−1)⟩.
The last formula can be simplified using the facts that λkAp(k) = r(k+1)−r(k), ⟨r(k), p(j)⟩=
0 for all j < k, and p(k+1) = −r(k+1) + βkp(k), into
βk =
⟨r(k), r(k)⟩
⟨r(k−1), r(k−1)⟩.
In this way less matrix-vector multiplications are required.
We summarize all the above into the Conjugate Gradient Algorithm 45.
Algorithm 45 Conjugate Gradient method for linear equations
Set a tolerance TOL for the accuracy
Initialize x(0) = 0, r(0) = Ax(0) −b, p(0) = −r(0)
Initialize k = 0
while ∥r(k)∥> TOL or ∥x(k+1) −x(k)∥> TOL do
Compute λk =
⟨r(k),r(k)⟩
⟨p(k),Ap(k)⟩
Compute x(k+1) = x(k) −λkp(k)
Compute r(k+1) = r(k) + λkAp(k)
Compute βk+1 = ⟨r(k+1),r(k+1)⟩
⟨r(k),r(k)⟩
Compute p(k+1) = −r(k+1) + βk+1p(k)
Increase the counter k = k + 1
end while
Return the approximation x(k)
An implementation of the Conjugate Gradient Algorithm 45 can be the following
1
def conjgrad(A,b,x0,tol=1.e-3,maxit=50):
2
x = x0.copy()
3
r = np.dot(A,x0) - b
4
p = - r.copy()
5
iters = 0
6
while (npl.norm(r)>tol and iters<maxit):
7
# Compute the products
8
Ap = np.dot(A,p)
9
r_dot_r = np.sum(r*r)
10
p_dot_Ap = np.sum(p*Ap)

434
Unconstrained Optimization and Neural Networks
11
# Compute the parameters and the unknowns
12
lam = r_dot_r / p_dot_Ap
13
x = x + lam * p
14
r = r + lam * Ap
15
beta = np.sum(r*r)/r_dot_r
16
p = - r + beta * p
17
iters += 1
18
return x
As we mentioned before, the Conjugate Gradient method converges if A is symmetric
and positive definite. For this reason, in order to test our implementation we consider the
linear system Ax = b with
A =


2
−1
0
−1
2
−1
0
−1
2


and
b =


1
0
1

,
which has the exact solution x = (1, 1, 1)T . As initial condition we choose the vector x(0) =
(0, 0, 0)T .
1
A = np.array([[2.0, -1.0, 0.0],[-1.0, 2.0, -1.0],[0.0, -1.0, 2.0]])
2
b = np.array([[1],[0],[1]])
3
x0 = np.zeros((3,1))
4
x= conjgrad(A, b, x0)
5
print('x = '); print(x)
x =
[[1.]
[1.]
[1.]]
Printing the number of iterations iters variable we observe that for the 3 × 3 matrix of
our example, it is required only 2 iterations to converge within the prescribed tol. Similarly,
fast convergence can be achieved even if we try smaller values of tol. In principle, if A is
n×n symmetric and positive definite matrix, then the Conjugate Gradient method converges
in at most n iterations when exact arithmetic is being used.
11.2.2
Convergence and preconditioning
Approximations of the conjugate gradient method can be shown to converge for symmetric
and positive definite n×n matrix A. More precisely, if κ = cond(A) is the condition number
of A based on the ℓ2-norm, then the error e(k) = x(k) −x is
∥e(k)∥A ≤2
"√κ −1
√κ + 1
k
+
√κ + 1
√κ −1
k#−1
∥e(0)∥A,
k = 1, 2, . . . , n −1 .
Although convergence can be achieved, for large values of n, it happens that this can be a
slow process. Moreover, the speed of convergence is an increasing function of the condition
number cond(A).
In order to improve the speed of convergence of iterative methods including the conju-
gate gradient method we usually employ a preconditioning technique. Preconditioning will

Conjugate Gradient Method
435
improve the condition number of a matrix A or just change its structure. For this reason,
we multiply the system Ax = b with the inverse of an n × n matrix M. The matrix M
is called preconditioner and is chosen symmetric and positive definite. Instead of working
with the system Ax = b we work with the system
M −1Ax = M −1b ,
(11.21)
with the hope that the condition number of the matrix M −1A is smaller compared to A.
Since M is symmetric and positive definite, then we can find a matrix C such that
C2 = M. Using the matrix C we can write (11.21) in the form
C−1AC−1Cx = C−1b ,
or
˜
A˜x = ˜b ,
(11.22)
with ˜
A = C−1AC−1, ˜x = Cx, and ˜b = C−1b.
If σ(A) denotes the spectrum of A, i.e. the set of the eigenvalues of A in absolute value,
then
σ( ˜
A) = σ(C−1AC−1) = σ(C−2A) = σ(M −1A) .
An example of preconditioner is the Jacobi matrix
M = diag(a11, a22, . . . , ann) ,
which can be inverted trivially. The resulting conjugate gradient method is known as the
Jacobi-Conjugate gradient method.
The algorithm for the preconditioned Conjugate Gradient method is described in Algo-
rithm 46. We leave the implementation of the preconditioned Conjugate Gradient method
as an exercise for the reader.
Algorithm 46 Preconditioned Conjugate Gradient method for linear equations
Set a tolerance TOL for the accuracy
Initialize x(0) = 0, r(0) = Ax(0) −b, p(0) = −r(0)
Solve the system My(0) = r(0) for y(0)
Initialize k = 0
while ∥r(k)∥> TOL or ∥x(k+1) −x(k)∥> TOL do
Compute λk =
⟨r(k),y(k)⟩
⟨p(k),Ap(k)⟩
Compute x(k+1) = x(k) −λkp(k)
Compute r(k+1) = r(k) + λkAp(k)
Solve the system My(k+1) = r(k+1) for y(k+1)
Compute βk+1 = ⟨r(k+1),y(k+1)⟩
⟨r(k),y(k)⟩
Compute p(k+1) = −y(k+1) + βk+1p(k)
Increase the counter k = k + 1
end while
Return the approximation x(k)
11.2.3
Extensions to nonlinear systems
The conjugate gradient method has been extended for the minimization of general functions.
The idea of its extension to nonlinear equations has been attributed to Fletcher and Reeves

436
Unconstrained Optimization and Neural Networks
[41]. Other extensions are by Polak and Ribi`ere, Hestenes and Stiefel, and Dai and Yuan
[104, 60, 28].
In the Fletcher-Reeves extension we consider the general function f(x), then as before,
we start with the direction p(0) = −∇f(x(0)). The new approximation x(k+1) = x(k)+λkp(k)
is computed with
λk = argminλ>0f(x(k) −λp(k)) .
Then the new direction p(k+1) is chosen so as
p(k+1) = r(k+1) + βk+1p(k) ,
with r(k+1) = −∇f(x(k+1)) and
βk+1 = ⟨r(k+1), r(k+1)⟩
⟨r(k), r(k)⟩
.
If the function f(x) is a quadratic function, then the method reduces to the linear conjugate
gradient method.
Algorithm 47 Conjugate gradient method for nonlinear equations
Set a tolerance TOL for the accuracy
Initialize x(0) = 0, r(0) = ∇f(x(0)), p(0) = −r(0)
Initialize k = 0
while ∥r(k))∥> TOL or ∥x(k+1) −x(k)∥> TOL do
Compute λk = argminλ>0f(x(k) −λp(k))
Compute x(k+1) = x(k) −λkp(k)
Compute r(k+1) = r(k) + λkAp(k)
Compute βk+1 = ⟨r(k+1),r(k+1)⟩
⟨r(k),r(k)⟩
Compute p(k+1) = −r(k+1) + βk+1p(k)
Increase the counter k = k + 1
end while
Return the approximation x(k)
The Fletcher-Reeves algorithm is presented in Algorithm 47. The other methods are
improvements of the Fletcher-Reeves algorithm and are based on different computations of
the parameter βk. We summarize the various choices of these values in Table 11.1.
TABLE 11.1
Variations of nonlinear conjugate gradient method
Fletcher-Reeves
βk =
⟨r(k), r(k)⟩
⟨r(k−1), r(k−1)⟩
Polak-Ribi`ere
βk = ⟨r(k), r(k) −r(k−1)⟩
⟨r(k−1), r(k−1)⟩
Hestenes-Stiefel
βk =
⟨r(k), r(k) −r(k−1)⟩
⟨p(k−1), r(k) −r(k−1)⟩
Dai-Yuan
βk =
⟨r(k), r(k)⟩
⟨p(k−1), r(k) −r(k−1)⟩

Conjugate Gradient Method
437
The Polak-Ribi`ere modification appears to lead to a more robust method compared
to the original Fletcher-Reeves algorithm. Sometimes, the Fletcher-Reeves algorithm can
fail to converge if the direction pk does not have the descent direction property. We can
overcome this problem by choosing in Algorithm 47
p(k+1) = r(k) + βk+1p(k) .
If the choice of the parameter λk minimizes the function f, then the p(k) is indeed a
direction of descent. Otherwise, there are modifications that can help us overcome the
specific problem, but we do not mention them here. Also, the Polak-Ribi`ere modification
can appear to solve convergence problems but a small modification of the Algorithm 47 can
lead to more stable algorithm. For example, choosing the parameter
β+
k+1 = max{βk+1, 0} ,
we can ensure that the resulting directions are descent directions.
More precisely, to guarantee the convergence of such Conjugate Gradient methods, the
parameter λk needs to satisfy the following Wolfe conditions,
f(x(k) + λkp(k)) ≤f(x(k)) + c1λk⟨∇f(x(k)), p(k)⟩,
|⟨f(x(k) + λkp(k)), p(k)⟩| ≤c2|⟨∇f(x(k)), p(k)⟩| ,
where 0 < c1 < c2 < 1/2. One can verify that both Fletcher-Reeves and Polak-Ribi`ere
methods, with the small modification described above, satisfy the Wolfe conditions.
Python implementations
Conjugate Gradient implementations have been included in Python for both linear and
nonlinear equations. There are all included in submodules of scipy, which we describe
below. We start with the Python implementation of the Conjugate Gradient method for
linear systems.
The Conjugate Gradient implementation for linear systems is the function cg of the
module scipy.sparse.linalg. The method has been included in the specific module as it
appears to be exceptionally popular for systems with sparse matrix A. The specific function
can also be used with preconditioner. Its general call is the following:
cg(A,b,x0,tol,maxiter,M,callback,atol)
where
A:
Is the n × n matrix A of the linear system. This can be sparse or dense, and must be
symmetric (or Hermitian if it is complex) and positive definite
b:
Is the right hand side b
x0:
Is the initial guess of the solution. (Optional with default value x0=None)
tol: Used for the termination of the algorithm alongside atol. (Optional with default
value tol=1.e-5)
atol: Used with the tol for the termination of the algorithm with default value None. The
termination criterion is the following
∥rk∥≤max{tol∥b∥, atol} .
(Optional with default value atol=None)

438
Unconstrained Optimization and Neural Networks
maxiter: Is the maximum number of iterations allowed. (Optional with default value
maxiter=None)
M:
It can be a sparse or dense matrix and is the preconditioner M described in Section
11.2.2. (Optional with default value M=None)
callback: Is a user-supplied function to call after each iteration. (Optional with default
value is callback=None)
The function cg returns the approximation of the solution vector x and an integer vari-
able info which can be either 0 indicating that the convergence was successful, positive,
indicating that convergence was not achieved, or negative, indicating that other problems
occurred.
Solving the linear system Ax = b (see also Section 11.2) can be done in straightforward
way as described in the following code:
1
from scipy.sparse.linalg import cg
2
A = np.array([[2.0, -1.0, 0.0],[-1.0, 2.0, -1.0],[0.0, -1.0, 2.0]])
3
b = np.array([[1],[0],[1]])
4
x0 = np.zeros((3,1))
5
print( cg(A,b,x0) )
(array([1., 1., 1.]), 0)
We observe that the solution is the correct one, and also the integer parameter info is 0
indicating the convergence of the Conjugate Gradient method without any problems.
Various extensions of the Conjugate Gradient method for the minimization of nonlinear
functions can be found in the module scipy.optimize such as fmin cg, fmin ncg, fmin -
powel and others. The fmin cg function is based on the Polak-Ribi`ere algorithm [104] and
is suggested when f has a unique global minimum, and no other local minima or stationary
points. It is also required that f is smooth in the sense that both f and its gradient are
continuous. The function fmin ncg is based on a Newton-Conjugate Gradient method and
perhaps is more powerful in terms of convergence rate. All the minimization algorithms can
be called through the function minimize of scipy.optimize, which is analyzed later in this
chapter.
11.3
Newton’s Method in Optimization
Finding a minimizer for a smooth function f(x) = 0 is equivalent to finding a root of the
system of equations ∇f(x) = 0. As we have already discussed in Section 5.5.6, Newton’s
method can be an effective method for the solution of such equations.
11.3.1
Newton’s iteration
For a vector function F (x) with x ∈Rn the Newton iteration takes the form
x(k+1) = x(k) −[DF (x(k))]−1F (x(k)) ,
where DF (x(k)) = J is the Jacobian matrix with the first derivatives of F . In optimization,
we often seek for the roots of the vector function ∇f(x) where f is a real valued function. In

Newton’s Method in Optimization
439
this case, the Jacobian of the vector function ∇f(x) is the Hessian matrix with the second
derivatives of the function f(x). Consider for example the Taylor expansion of the function
∇f(x) around x(k+1)
∇f(x(k+1)) ≈∇f(x(k)) + H(x(k))(x(k+1) −x(k)) ,
where H is the Hessian matrix of f with entries the second derivatives of the function f,
Hij =
∂2f
∂xi∂xj
.
Alternatively, one can think of the Hessian matrix H(x(k)) as the Jacobian matrix of the
∇f(x(k)). Taking ∇f(x(k+1)) ≈0 we obtain
0 ≈∇f(x(k)) + H(x(k))(x(k+1) −x(k)) .
Given an initial guess x(0) of the solution x∗of the equation ∇f(x) = 0, the Newton
iteration for k = 0, 1, . . . takes the form
x(k+1) = x(k) −H−1(x(k))∇f(x(k)) ,
(11.23)
Newton’s iteration (11.23) can be seen as the gradient method of the form
x(k+1) = x(k) + λkp(k) ,
with direction p(k) = −H−1(x(k))∇f(x(k)) and λk = 1, which is quadratically convergent,
in the sense
∥x(k+1) −x∗∥≤C∥x(k) −x∗∥2 .
Sometimes the choice λk ∈(0, 1) can improve the convergence of Newton’s iteration by
satisfying the so-called Wolfe conditions. The inclusion of such small parameter λk can
be seen as a generic technique of performing smaller step from x(k) to obtain x(k+1). In
principle Newton’s method can be convergent if the function ∇f(x) satisfies a Lipschitz
condition
∥∇f(x) −∇f(y)∥≤L∥x −y∥,
for some constant L > 0.
11.3.2
Quasi-Newton methods
Quasi-Newton methods can be thought of as generalizations of the secant method, where
instead of using the Hessian matrix, we consider approximations B(k) of it. A general quasi-
Newton iteration can be expressed as
x(k+1) = x(k) −[B(k)]−1∇f(x(k)) .
A straightforward approximation of the Hessian matrix can be obtained by using the Taylor
expansion of ∇f(x(k)) around x(k−1). This is
∇f(x(k)) = ∇f(x(k−1)) + B(k)p(k−1) ,
where p(k−1) = x(k−1) −x(k). Solving for B(k) requires the solution of a linear system of
course, but this technique can be useful when the computation of the Hessian matrix is not
possible4.
4Alternatively, one can use the complex-step approximation of the second derivative to bypass the barrier
of the Hessian. For more information see the exercises of Chapter 5.

440
Unconstrained Optimization and Neural Networks
One of the most well-known quasi-Newton methods is Broyden’s method, in which the
use of Sherman-Morrison formula was suggested for the computation of the matrix B(k)
from the previous approximation B(k−1). More precisely, Broyden’s method suggests the
approximation
B(k) = B(k−1) + y(k) −B(k−1)p(k−1)
⟨p(k−1), p(k−1)⟩
[p(k−1)]T ,
where y(k) = ∇f(x(k)) −∇f(x(k−1)).
Because the Sherman-Morrison formula appeared to be useful for the solution of linear
systems of some special form, we proceed with the complete derivation of Broyden’s method.
First, we remind that the outer product of two vectors u = (u1, u2, . . . , un)T and v =
(v1, v2, . . . , vn)T , is defined as
u ⊗v = uvT =





u1v1
u1v2
· · ·
u1vn
u2v1
u2v2
· · ·
u2vn
...
...
...
...
unv1
unv2
· · ·
unvn




.
The Sherman-Morrison formula provides a way to compute any n × n matrix B that can
be written in the form
B = A + u ⊗v .
In such cases, the matrix B is called rank-one update, since the columns of the matrix u⊗v
are constant multiples of the vector u, and thus it is of rank one.
Let x be the solution of the system Ax = u. Then,
Bx = (A + u ⊗v)x = Ax + u ⊗vT x = u + u(vxT ) = (1 + vxT )u ,
and
x = (1 + vxT )B−1u .
Solving for B−1u and using the formula x = A−1u we obtain
B−1u =
1
1 + v(A−1u)T A−1u .
In case ⟨v, A−1x⟩= 0, the situation can be simplified even more. For example,
BA−1x = (A + u ⊗v)A−1x = AA−1x + uvT A−1x
= x + u[v(A−1x)T ] = x ,
which is simplified to B−1x = A−1x.
This formula can lead to a formula for the computation of the inverse for more general
matrices. For example, let C be an n × n matrix, and suppose we want to compute the
matrix D such that Dw = z for some given vectors w, z, and Dy = Cy for y orthogonal
to a given vector g. Here C = A−1, D = B−1, w = u, z = 1/[1 + v(A−1u)T ]A−1u, and
g = A−T v. Setting
D = C + (z −Cw) ⊗g
gwT
,
then, if gyT = 0, from the analysis above we have Dy = Cy. Moreover, we observe that
Dw = Cw + (z −Cw) = z .

Newton’s Method in Optimization
441
Applying all these in the definition of D, we obtain
B−1 = A−1 +
h
1
1+v·A−1uA−1u −A−1u

⊗v
i
A−1
v · A−1u
= A−1 −A−1(u ⊗v)A−1
1 + v · A−1u
.
This is the Sherman-Morrison formula, which can lead to an approximation of [B(k)]−1
using the previous matrix [B(k−1)]−1. More precisely, given B(k−1) we have
B(k)(x(k) −x(k−1)) = ∇f(x(k)) −∇f(x(k−1)) ,
and if zT (x(k) −x(k−1)) = 0 then B(k)z = B(k−1)z. The Sherman-Morrison formula then
yields
B(k) = B(k−1) + y(k−1) −B(k−1)p(k−1)
[p(k−1)]T p(k−1)
⊗p(k) ,
where p(k−1) = x(k) −x(k−1), and y(k−1) = ∇f(x(k)) −∇f(x(k−1)). Moreover, since
y(k−1) −B(k−1)p(k−1) = ∇f(x(k−1)) ,
then
B(k) = B(k−1) + ∇f(x(k))T p(k−1)
[p(k−1)]T p(k−1)
.
Using the Sherman-Morrison formula we obtain
[B(k)]
−1 = [B(k−1)]−1 −
[B(k−1)]−1 
1
[p(k−1)]T p(k−1) ∇f(x(k)) ⊗p(k−1)
[B(k−1)]−1
1 + [p(k−1)]T [B(k−1)]−1

1
[p(k−1)]T p(k−1) ∇f(x(k))

= [B(k−1)]−1 −
[B(k−1)]−1(∇f(x(k)) ⊗p(k−1))[B(k−1)]−1
[p(k−1)]T p(k−1) + [p(k−1)]T [B(k−1)]−1∇f(x(k))
= [B(k−1)]−1 −(u(k−1) ⊗p(k−1))[B(k−1)]−1
[p(k−1)]T (p(k−1) + u(k−1))
,
where u(k−1) = [B(k−1)]−1∇f(x(k)).
11.3.3
Nonlinear optimization and the module scipy.optimize
In the module scipy.optimize the general purpose function minimize is provided for
the minimization of a scalar function of one or more variables. One can use this function
to employ any of the previously described methods, which is among at least 15 different
methods! The general call of minimize is the following:
minimize(fun,x0,args,method,jac,hess,hessp,
bounds,constraints,tol,callback,options)
where some of the arguments are the following:
fun: Is the objective function we want to minimize, which can be given as fun(x,args)
x0:
Is the initial guess of the solution

442
Unconstrained Optimization and Neural Networks
args: Is a tuple containing any extra arguments needed by the function fun. (Optional
with default value the empty tuple ())
method: Is a string defining the method we prefer to use for the minimization process.
We can choose among many the methods we have described such as ’CG’ and
’Newton-CG’. The complete list of all possible choices can be found online. (Optional
with default value method=None in which case the method is chosen internally)
jac: Can be a function that returns the gradient vector. Alternatively, can be one of the
strings 2-point, 3-point or cs for the numerical estimation of the gradient using
finite differences. It can also be a boolean. If it is True then the function fun is
assumed to return the gradient along with the objective function, otherwise, the
gradient is estimated using the 2-point finite difference estimation. (Optional with
default value jac=None)
tol: Is the tolerance for the termination of the method. (Optional with default value
tol=None)
options: Is a dictionary with the integer maxiter maximum number of iterations and the
boolean value disp which determines whether messages related to convergence will
be print on the screen. (Optional with default value options=None)
The function returns the OptimizeResult object in a variable res, which includes the
solution x, and boolean variable success and the string message which describes the reason
of the termination. As you may have observed, here we do not provide information related
to parameters hess, hessp, bounds, constraints and callback since we didn’t mention
anything about these in the theory and they are optional arguments. Information about
these arguments can be found in the official documentation of the module SciPy.
11.3.4
The Gauss-Newton approximation
In the linear least squares problem we seek for a minimizer of the error function
E(x) = 1
2∥Ax −b∥2 .
In such a case Newton’s method takes the form
H(x(k+1) −x(k)) = −∇E(x(k)) ,
where the gradient ∇E and the Hessian matrix of the second derivatives of E can be
computed explicitly by differentiating the function E(x) as
∇E(x) = AT (Ax −b)
and
H = AT A .
Thus, Newton’s iteration can be written as
AT A(x(k+1) −x(k)) = −AT (Ax(k) −b) ,
which can be simplified to
AT Ax(k+1) = AT b .
The Hessian H = AT A is the idea behind the use of the Gauss-Newton method for
the solution of the nonlinear least squares problem. In the nonlinear least squares problem
the Hessian matrix H is being approximated by the product of two matrices H ≈2JT J,
where in practice the matrix J is the Jacobian matrix of the nonlinear fit function ˆy(x).

Newton’s Method in Optimization
443
More precisely, assume that we have a set of data (ti, yi) for i = 0, 1, . . . , N that we
want to approximate by a fitting function ˆy(t; x) that depends perhaps in a nonlinear way
on the n parameters x = (x1, . . . , xn). Sometimes, for the sake of simplicity, we will write
ˆy(x) ignoring the dependence on t. For example, if n = 2 and we consider a linear function
ˆy(t; x) = x0t+x1, then the problem is the linear least squares problem of Section 10.2. The
general least squares problem is to find the minimizer of residual function
f(x) =
N
X
i=0
(yi −ˆyi(x))2 ,
where ˆyi = ˆy(ti; x). Note that we changed the notation slightly from Section 10.2 so as to
be in agreement with the previous analysis.
If H denotes the Jacobian matrix of ∇f then the Newton iteration is
H(x(k+1) −x(k)) = −∇f(x(k)) .
The idea of Gauss-Newton’s method is to avoid the computation of the second derivatives
based on the following observation
f(x) =
N
X
i=0
(yi −ˆyi)2 = (y −ˆy(x))T (y −ˆy(x)) = yT y −2yT ˆy(x) + ˆy(x)T ˆy(x) ,
which yields to
∇f(x) = −2JT (y −ˆy(x)) ,
where J is the Jacobian of the function ˆy with
Jij =
∂
∂xj
ˆyi .
Next, we need to estimate the Hessian matrix in order to derive the Gauss-Newton
method. Taking the Taylor’s expansion ˆy(x + δx) ≈ˆy(x) + Jδx, substitution into the
expression of the function f yields
f(x + δx) = yT y −2yT ˆy(x + δx) + ˆy(x + δx)T ˆy(x + δx)
≈yT y −2yT (ˆy(x) + Jδx) + (ˆy(x) + Jδx)T (ˆy(x) + Jδx)
= (y −ˆy(x))T (y −ˆy(x)) −2(y −ˆy(x))T Jδx + δxT JT Jδx .
Comparing the last relation with the Taylor expansion of f(x + δx) we conclude that
JT J ≈
1
2H. Here, the Hessian cannot be equal to the matrix 2JT J but based on the
approximation H ≈2JT J we modify the Newton iteration to be
JT J(x(k+1) −x(k)) = JT 
y −ˆy(x(k))

.
(11.24)
The iteration (11.24) is known to as the Gauss-Newton iteration.
11.3.5
The Levenberg-Marquardt modification
Using the previous approximations for the ∇f(x) we can write the general method of
steepest descent in the form
x(k+1) −x(k) = −λkJT 
y −ˆy(x(k))

.

444
Unconstrained Optimization and Neural Networks
The Levenberg-Marquardt method is a modification of the Gauss-Newton method that
combines both the method of steepest descent and the Gauss-Newton method
JT J(x(k+1) −x(k)) = JT 
y −ˆy(x(k))

.
In particular, the Levenberg-Marguardt method for nonlinear least squares problems is
formulated as
(JT J + λI)(x(k+1) −x(k)) = JT 
y −ˆy(x(k))

,
(11.25)
where λ is usually chosen to be fairly large. Many attempts to determine the parameter λ
lead to the following simple algorithm in adapting the value of λ depending on the value
of the error E(x): Choose a large initial value λ = λ0 and a parameter ν > 1 for the first
iteration. After computing x(1), compute the value E(x(1)). Continue using λ = λ1 = λ0/ν
and compute again the value E(x(2)). If the values of the error functions are decreasing
in a satisfactory way continue, otherwise use the value λ = λkνj for some j until better
convergence is achieved.
The Levenberg-Marquardt method is an enhanced first order method, which is very
popular in optimization and also in the training of neural networks of moderate size. Min-
imization algorithms in Python are implemented mainly in the module scipy.optimize.
Gauss-Newton and Levenberg-Marquardt methods are implemented in the function least -
squares of the previously mentioned module, and finds the local minimum of the cost
function
F(x) = 1
2
m−1
X
i=0
ρ(fi(x)2),
x ∈[a, b] .
11.4
Introduction to Neural Networks
Methods of optimization are perhaps the most useful tools of computational mathematics
in the study of artificial neural networks of machine learning. The training of a computer
system, and in particular a machine learning procedure, is based on the minimization of ap-
propriate functionals. Artificial neural networks are inspired by biological neural networks.
These can be thought of as algorithms, that “learn” to perform tasks by considering ex-
amples. Artificial neural networks find application in fields such as computer science, data
science, statistics and mathematics. Examples include computer vision, speech and face
recognition, social networks, computer games, and even the solution of differential equa-
tions. In this section we introduce the notion of artificial neural networks, which we will
call for simplicity neural networks from now on, and we explain the most basic algorithm
we use to train them, the back-propagation algorithm.
11.4.1
A simple neural network
Think of an artificial neural network as a mathematical function y = f(x; w) which depends
on some parameters w and requires an input x to return the output y. The function f is
adjusted to approximate a function ˆf which corresponds to the real problem. We usually
achieve this by minimizing the difference f −ˆf. In artificial neural networks we can adjust
the function f in order to return desired values y for certain input x. This is usually done
by finding appropriate parameters w. Artificial neural networks work similarly to biological
neural networks. Neural networks consist of neurons. Neurons receive signals (input) from
the environment and they react appropriately by sending (firing) signals to the brain, which

Introduction to Neural Networks
445
FIGURE 11.3
A perceptron: The simplest neural network with only two layers.
is responsible for the output y. The output y in biological neural networks depends on the
experiences we have or in other words on our training. Think what happens when we drive.
If the input we receive from our eyes is a red traffic light, then our brain signals to stop
since this is what we have learnt to do.
Artificial neural networks, like biological neural networks, have nodes called neurons
that are responsible for receiving input, processing it and propagating information inside
the network. Usually, because there are more than one input data, there are more than one
neurons in a neural network. There are many different ways that neurons are connected. The
connections between neurons are called synapses (singular synapsis). There are also many
different strategies to process the input data. Each way determines a different architecture in
artificial neural networks. In this brief introduction we consider only feed-forward networks
where the connections (synapses) between neurons are direct and acyclic in the sense that
the information can propagate only in one direction.
The perceptron
The simplest feed-forward neural network was introduced in 1957 by Frank Rosenblatt
(1928–1971) [110] and is called perceptron. This neural network consists of two nodes (neu-
rons). The perceptron receives the input x at the input node, and returns the output y at
the output node. The process that this simple perceptron can perform for example could
be to take the input x, multiply it with a synaptic weight w and turn in the output result
y. This simple neural network can be represented schematically in Figure 11.3. We say in
general that the input nodes consist of the input layer and the output nodes the output
layer. So in this simple example we have only two nodes (the input and the output layers)
and a weight w.
The output y is the product of the weight w with the input x such that y = w · x.
Given the input x, we need to estimate the unknown weight w so as to obtain the correct
output y. This is actually the main task of a feed-forward neural network. Initially, we give
to w any arbitrary value w(0). In this simple case we can train the algorithm to find (or in
other words learn) what the weight should be so as to solve the problem in a trivial way. In
order to train the algorithm to compute the correct output value y for general x we need
to provide the algorithm with an example. It is worth mentioning that in general neural
networks there might be more layers between the input and output layers. These layers are
called hidden layers. In this simple case we just presented there are no hidden layers.
As an example, assume that the desired, weighted output for input 2 is 0.5. These data
serve as training data. Now the determination of the neural network is complete. Using the
equation y = w · x we can solve for w and we can use the specific value of w to compute
the output y for any given input x. Obviously w = y/x = 1/4.

446
Unconstrained Optimization and Neural Networks

A neural network is determined by its structure and the given training data. A
neural network with the same structure but different training data will provide with
totally different results. The procedure of estimating the synaptic weights is called
training of the neural network. Sometimes we also say that the neural network is
learning the synaptic weights.
Instead of using this simple technique and dividing to find the optimal weight, we present
a more sophisticated way to estimate weights. This general methodology is used for more
complicated neural networks and is called back-propagation. We introduce the error function
borrowed from the problem of linear least squares
E(w) = |y −w · x|2 ,
which in the language of machine learning is called cost function. In order to estimate the
optimal value of w we need to minimize the error E(w) and find an approximation of the
value w∗= argminE(w). We can approximate the argminE(w), using the gradient method
(11.3), which in this case is
w(k+1) = w(k) −λE′(w(k)) .
It is noted that since the only independent variable in E(w) is w, then the gradient ∇E(w)
is reduced to the standard scalar derivative E′(w). In the language of neural networks the
parameter λ is called learning rate. We have discussed how to compute the value of this
parameter in each step using the method of steepest descent. Here we take arbitrary learning
rate and we focus only on neural network techniques.
Using the values x = 2 and y = 0.5 of our example we have E(w) = |0.5 −2w|2.
Computing the derivative E′(w) = −2 + 8w we can write the steepest descent method as
w(k+1) = w(k) −λ(−2 + 8w(k)) .
Using an initial guess w(0) = 0.8 and learning rate λ = 0.1 we compute the first five
approximations w(k) for k = 1, 2, . . . , 5 with the following simple code.
1
w = 0.8; lam = 0.1
2
for i in range(5):
3
w = w - lam*(-2+8*w)
4
print(w)
0.36
0.272
0.2544
0.25088
0.250176
We observe that the code converges to the optimal value w = 0.25, which is the same with
the value we computed with the direct division. If we are given the input x = 3 and asked
about the output y, we can immediately respond with y = 0.75 since y = 0.25 · 3.
In the previous example we chose the learning rate λ = 0.1. Typically, this can be
chosen using the techniques described in the previous sections. The method of determining
the weight w using optimization techniques is called back-propagation. Also the specific form
of learning we just described is called supervised learning.

Introduction to Neural Networks
447
FIGURE 11.4
A serial neural network with hidden layers.

When we say that a neural network is learning we mean that it is just minimizing
a cost function to find the optimal synaptic weights involved. The computation of
the optimal weights using the previous methodology is called back-propagation.
A serial neural network
In the perceptron model we had a neural network with only two layers (neurons), the input
and output layers. A more complicated neural network consists of more neurons and more
layers. As a second example we consider a neural network consisting of N+2 layers connected
in a serial way as shown in Figure 11.4. Since we have N + 1 neurons xi, i = 0, 1, . . . , N we
consider also N + 1 weights wi, for i = 0, 1, . . . , N for the computation of the values xi for
each of the hidden layers. The layers for i = 1, . . . , N we call them hidden as their values
are computed internally in order to find the output value y. Also the number of hidden
layers in a neural network determines the depth of the neural network, and that is why the
training of neural networks is called deep learning.
In such topology each value xi = wi−1 · xi−1, thus the output value is
y = wN · xN
= wNwN−1 · xN−1
...
= wNwN−1 · · · w0 · x0 .
Such a neural network can be considered as perceptron where the output y = w·x with x =
x0 and w = wNwN−1 · · · w0. All the layers between the input and the output are considered
as hidden layers. If it is required to compute the synaptic weights wi, i = 0, 1, . . . , N, then
by setting arbitrary initial guess w(0) for the vector w = (w0, w1, . . . , wN) and considering
the minimization of the cost function
E(w) = |y −w0w1 · · · wNx|2 ,
with the help of the steepest descent method we have
w(k+1) = w(k) −λ ∇E(w(k)) .
This time the gradient ∇E(w) is a vector defined as
∇E(w) =
 ∂
∂w0
E(w),
∂
∂w1
E(w), . . . ,
∂
∂wN
E(w)
T
.

Synaptic weights are initialized usually with guesses, and then optimal values
are computed using optimization techniques.

448
Unconstrained Optimization and Neural Networks
FIGURE 11.5
Perceptron with activation function.
11.4.2
Activation functions
Let a perceptron simulate one of our fingers that checks the water temperature (input)
and returns a response (output). If the temperature is less than a certain value we might
not want to do anything. On the other hand, if the water temperature is greater than a
threshold, then we want the response output to represent an intense reaction. This can be
done by allowing the neuron to apply an activation (or learning) function to the original
output and return y = f(w · x) instead of just w · x. The architecture of the perceptron is
shown in Figure 11.5.
Examples of activation functions include the logistic (or step) function
fstep(z) =
 0,
if z < 0
1,
if z ≥0
,
which in practical terms returns a non-zero output only if w·x ≥0. The step function is not
the most popular choice compared to other activation functions due to its discontinuity. The
main feature of an activation function is that it returns small or zero values for arguments
that are smaller than a certain value, and values close to one for arguments of larger value.
Another candidate for activation function is the sigmoid function
fsigmoid(z) =
1
1 + e−r·z ,
for appropriate value r ∈R, r > 0. This function is called sigmoid due to its graph (Figure
11.6).
Other activation functions is the hyperbolic tangent ftanh(z) = tanh(r · z) the inverse
tangent farctan(z) = arctan(z), the rectified linear unit (ReLU) function
fReLU(z) = (z)+ = max{0, z} =
 0,
if z < 0
z,
if z ≥0
,
and others.
FIGURE 11.6
Sketch of the sigmoid function.

Introduction to Neural Networks
449
Since the output of the activation function will be the output of our simple neural
network, we can only have output in the range of the activation function. For example, in
the case of the sigmoid function we can have output y ∈(0, 1) only. If we need the output
to be in a different interval, then we need to modify the activation function, for example,
by multiplying it with an appropriate constant.
Looking back at the example with the single neuron and with training data x = 2,
y = 0.5 using the sigmoid function (with r = 1) as activation function, we need to estimate
a new optimal value of the weight w. This time the situation is more complicated. The
optimal value can be found as w∗= argminE(w) where E(w) = |y −f(w · x)|2. Trying to
find the gradient E′(w) we obtain
E′(w) = −2(y −f(w · x))xf ′(w · x) .
Since f ′(z) = e−z/(1 + e−z)2 we have
E′(w) = −2xe−2·w 0.5(1 + e−2·w) −1
(1 + e−2·w)3
.
The steepest descent method then becomes
w(k+1) = w(k) −λE′(w(k)) ,
with given w(0) = 0.8. Modifying the code for the perceptron appropriately we can check
that in the case where the activation function is the sigmoid the convergence to the optimal
weight w = 0 can be achieved by using large amount of iterations k. This is because the
sigmoid function is very smooth with small derivative. The convergence can be improved
by using larger values of learning rate λ.
11.4.3
General feedforward neural networks
General feedforward neural networks, can contain layers with multiple neurons. These neu-
rons can be interconnected with other neurons of other layers with different synapses. A
general neuron receives multiple input values xi, processes them and computes their sum
s =
N
X
i=1
wi · xi ,
adds a bias b to the sum s and then uses an activation function f to decide whether to fire
a positive response or return a zero value. This can be summarized by considering the i-th
neuron’s output defined as
y = f
 N
X
i=1
wi · xi + b
!
,
and can be represented by the diagram of Figure 11.7.
In this general neuron we consider a bias term b, which is added to the linear combination
of the synaptic weights and the input data. The bias term can be considered though as a
weight w0 = b of given input x0 = 1. Thus, we could write the summation as
z =
N
X
i=0
wi · xi .
The role of the bias is to increase or decrease the chances of neuron’s reaction after the
value z passes through the activation function f(z).

450
Unconstrained Optimization and Neural Networks
FIGURE 11.7
General perceptron with multiple input, bias unit and activation function.
The synaptic weights wi and the bias value b are set initially to arbitrary values, and in
order to find their optimal values, we consider a cost function of the form
E(w) = 1
2
y −f(
N
X
i=0
wixi)

2
.
(11.26)
As an example, consider the case N = 2 and the training data x1 = 0.7, x2 = 0.3,
y = 0.5. For simplicity, we consider the simplest activation function f(z) = z and bias
w0 = b with x0 = 1. For the cost function 11.26) with N = 2, we have
∇E(w) =

−x0

y −P2
i=0 wixi

,
−x1

y −P2
i=0 wixi

,
−x2

y −P2
i=0 wixi
T
.
The optimal synaptic weights (including the bias) can be found with the help of the gradient
method
w(k+1) = w(k) −λ ∇E(w) ,
with λ an arbitrary small value for the learning rate. Using the steepest descent method we
obtain the values b = w0 ≈0.05, w1 ≈0.33 and w2 ≈0.71.
It is worth noting that avoiding the use of activation function, then the cost function
can be written as
E(w) = 1
2∥y −Ax∥2
2 ,
where x = (x0, x1, x2)T , y = y and A = (w0, w1, w2), and thus the problem of training a
neural network can be seen as not very different from solving a least squares problem.

Introduction to Neural Networks
451
FIGURE 11.8
Perceptron with a hidden layer and multiple input and output neurons.
In general, a neural network consists of multiple input nodes xi and multiple output
nodes yi. In such case the cost function can be defined as E(w) = 1
2
P
i |yi −P
j wijxj|2.
This cost function is again of the same kind as before. To demonstrate the optimization
of a neural network with multiple output we consider the simple case with two nodes y1
and y2 in the output layer and one node x1 in the input layer. Furthermore, we assume a
bias b = w0 and also the respective given input x0 = 1. To keep the discussion simple we
consider the activation function f(z) = z. Such a simple neural network is represented in
Figure 11.8.
In this simple example, the cost function is
E(w) = 1
2
2
X
i=1
|yi −wi1z|2 = 1
2
2
X
i=1
|yi −wi1(w10x1 + b)|2
= 1
2
2
X
i=1
|yi −wi1(w10x1 + w00x0)|2 .
The problem is four-dimensional and we need to find optimal values for
w = (w00, w10, w11, w21)T .
With the help of chain rule of differentiation we obtain
∇E(w) =




−P2
i=1(yi −wi1z)wi1x0
−P2
i=1(yi −wi1z)wi1x1
−(y1 −w11z)z
−(y2 −w21z)z



,
with z = w10x1 + w00x0. Taking arbitrary initial guess w = (1, 1, 1, 1)T and using the
method of steepest descent with training data x1 = 0.4, y1 = 0.3, y2 = 0.4 we obtain the
optimal solution w ≈(0.35, 0.74, 0.46, 0.62)T . Note that the term
1
2 in the definition of
cost functions could be avoided without any difference in the results but it is included for
convenience in the calculations.

452
Unconstrained Optimization and Neural Networks
FIGURE 11.9
A neural network with multiple input and output layers, and one hidden layer.
More general neural networks
In most of the applications we prefer to use multiple hidden layers with multiple neurons.
Consider a neural net with N inputs xi, i = 1, 2, . . . , N, M outputs yj, j = 1, 2, . . . , M
and one hidden layer with L neurons. Denote the activation function of each neuron in the
hidden layer by f 1
k, k = 1, 2, . . . , L, and that of the output layer by f 2
j , j = 1, 2, . . . , M.
Let w1
ki, k = 1, 2, . . . , L, i = 1, 2, . . . , N be the synaptic weights for inputs into the hidden
layer, and w2
jk, j = 1, 2, . . . , M, k = 1, 2, . . . , L the synaptic weights for the output layer.
For simplicity, we ignore biases that anyway can be incorporated into the input data. Such
a neural network is depicted in Figure 11.9.
Denoting the entries of the hidden layer by
zk = f 1
k
 N
X
i=1
w1
kixi
!
,
then the j-th output in the output layer will be
yj = f 2
j
 L
X
k=1
w2
jkzk
!
= f 2
j
 L
X
k=1
w2
jkf 1
k
 N
X
i=1
w1
kixi
!!
.
Let’s now denote the unknown vector of synaptic weights by
w = {w1
ki, w2
jk : i = 1, 2, . . . , N, k = 1, 2, . . . , L, j = 1, 2, . . . , M} .

Introduction to Neural Networks
453
Given the training data x = (x1, x2, . . . , xN)T and y = (y1, y2, . . . , yM)T , the training of
the neural network requires the estimation of the optimal synaptic weights that minimize
the cost function
E(w) = 1
2
M
X
j=1
yj −f 2
j
 L
X
k=1
w2
jkzk
!
2
= 1
2
M
X
j=1
yj −f 2
j
 L
X
k=1
w2
jkf 1
k
 N
X
i=1
w1
kixi
!!
2
.
To solve this minimization problem we employ a gradient descent method as before. This
requires though the computation of the partial derivatives of the cost function E which
using the chain rule of differentiation we can write them as
∂E
∂w2
jk
(w) =
 
yj −f 2
j
 L
X
k=1
w2
jkzk
!!
f 2
j
′
 L
X
s=1
w2
jszs
!
zk ,
where the symbol ′ denotes the ordinary derivative with respect to the independent variable.
To simplify notation, we write
δj =
 
yj −f 2
j
 L
X
k=1
w2
jkzk
!!
f 2
j
′
 L
X
s=1
w2
jszs
!
,
so the partial derivatives can be expressed in the form
∂E
∂w2
jk
(w) = −δjzk .
Similarly, we have
∂E
∂w2
ki
(w) = −
 L
X
i=1
δiw1
ik
!
f 1
k
′
 N
X
s=1
w1
ksxi
!
xi .
Having computed the gradient of the cost function we can perform the minimization algo-
rithm of our choice to compute the synaptic weights. After computing the synaptic weights
we can use them anytime we want to compute unknown values y for given input x.
Instead of presenting theoretical examples of the backpropagation algorithm, we present
the way it works in practice and with Python. There are several libraries dedicated to
neural networks. Such libraries are the modules TensorFlow, PyTorch and others. In this
book we present briefly the module Scikit-Learn. For a detailed discussion of artificial neural
networks, we refer to the references and exercises at the end of this chapter.
11.4.4
Machine learning and the module sklearn
The module sklearn5 is a simple and efficient tool for basic machine learning problems such
as classification, regression, clustering, dimensionality reduction, and others. In this intro-
ductory text we consider only the classification and the regression problems. The regression
problem is the problem of approximating data and predicting the unknown from the known,
like what we achieved with interpolation and least-squares approximation. The methods
used for solving the regression problem are called regressors. The classification problem is
quite different. In particular, the classification problem is the problem of identifying the cat-
egory of an object, given some specified categories. An example of a classification problem
5sklearn is an acronym for the library Scikit-Learn

454
Unconstrained Optimization and Neural Networks
is the problem of identifying spam emails from regular emails. In the next section we will
present another classification problem, which is the recognition of handwritten numbers.
The methods we use to solve classification problems are called classifiers.
We begin with a brief presentation of the module sklearn and in particular a class that
can solve regression problems using a few commands. The module sklearn contains two
public attributes named coefs and intercepts . The first one is a list of weight matrices
where its i-th column contains the weights between the i and i + 1 layers, while the second
is a list of bias vectors where the i-th vector represents the bias values added to layer i + 1.
The module that we care more about here is the submodule sklearn.neural network
and its classes MLPRegressor and MLPClassifier. These classes implement backpropagation
algorithms to train a general perceptron such as the one in Figure 11.7. The MLP in the names
of these classes is an abbreviation of the words multi-layer perceptron, which is mainly setup
by these classes. The optimization is based on either the so-called L-BFGS method which
is a quasi-Newton-type method or the sgd and adam methods, which are both stochastic
gradient descent methods. Let’s make a parenthesis here to discuss the stochastic gradient
descent method.
Convergence of gradient descent methods based on the iteration w(k+1) = w(k) −
λ∇E(w(k)) can be time consuming, especially, when the computation of the gradient is
considered. In applications of neural networks we often use a modification of the gradient
descent methods called stochastic gradient descent method where at every step only small
sets of data is used for training the network. These small sets are called minibatches and
are chosen randomly.
Using M minibatches leads to the modification of the function E(x) =
1
M
P Ei(x),
which takes into account the contribution of the M minibatches only. An additional advan-
tage of the stochastic gradient descent is that using minibatches we avoid a phenomenon
called overfitting. Overfitting happens when we approximate noisy data with great accuracy,
like the noise is part of the actual solution, leading to inaccurate predictions. Adaptation
in the various choices of the learning rate result in a variety of stochastic gradient descent
methods, one of which is the so-called Adam method6. For more information related to the
stochastic gradient method and its variants, we refer to the references at the end of this
chapter.
We proceed with the general call of the class MLPRegressor, which is the following:
MLPRegressor(hidden_layer_sizes, activation, solver, alpha, batch_size,
learning_rate, learning_rate_init, power_t, max_iter, other_options)
where
hidden layer sizes: Is a tuple where the i-th element represents the number of neurons
in the i-th hidden layer. Its default value is the tuple (100,) indicating that there is
only one hidden layer with 100 neurons
activation: Is a string defining the activation function and can take one of the following
values: ’indentity’, ’logistic’, ’tanh’, ’relu’. (Optional with default value
activation=’relu’)
solver: Is a string defining the optimization method and can take one of the following
values ’lbfgs’, ’sgd’, ’adam’. (Optional with default value solver=’adam’)
alpha: Is a floating point number identifying an L2 penalty parameter. (Optional with
default value alpha=0.0001)
6The name Adam was derived from the name of the method “adaptive moment estimation”

Introduction to Neural Networks
455
batch size: Is an integer identifying the size of minibatches for the stochastic optimization
method and is ignored if lbfgs is the choice for the solver parameter. (Optional
with default value batch size=auto)
learning rate: Is a string defining the learning rate schedule for weight updates. It
can take the value constant for constant learning rate given by the parameter
learning rate init, ’invscaling’ when the learning rate is gradually decreasing
at each time step t using an inverse scaling exponent of power t and ’adaptive’
when the learning rate changes adaptively. (Optional with default value learning -
rate=’constant’)
learning rate init: Is the constant value of the learning rate. (Optional with default
value learning rate init=0.001)
power t: Is the exponent for the inverse scaling learning rate and is only used with the
’sgd’ solver. (Optional with default value power t=0.5)
max iter: Is the maximum number of iterations we allow the optimization method to
perform. (Optional with default value max iter=200)
Other
input
parameters
include
the
optional
parameters
shuffle,
random state,
tol, verbose, momentum, nesterovs momentum, early stopping, validation fraction,
beta 1, beta 2, epsilon, n iter no change and max fun. We refer to the online manual
of the Scikit-Learn module for a description of these values.
Similarly the general call of the class MLPClassifier is the following
MLPClassifier(hidden_layer_sizes, activation, solver, alpha, batch_size,
learning_rate, learning_rate_init, power_t, max_iter, other_options)
and the various arguments coincide with those of the MLPRegressor, for which we refer to
the previous description and the online manual of Scikit-Learn.
After we have setup a neural network we can train it using the member function fit. If
we have created a neural net in the variable mlp, then we can train it by calling
1
mlp.fit(x_train,y_train)
As an example we consider the approximation of the function f(x) = sin(2πx)+sin(7πx)
in the interval [−1, 1] using neural networks methodology. The idea is to use some points of
the function f as given training data and the rest as testing data. This problem is analogous
to regression we studied before.
First, we setup our data by generating the data set x, y with x consisting of 2000
uniformly distributed points in [−1, 1] and y containing the corresponding values of f.
1
def f(x):
2
y = np.sin(2.0*np.pi*x) + np.sin(7.0*np.pi*x)
3
return y
4
h = 0.001
5
x = np.arange(-1.0,1.0+h,h)
6
y = f(x)
7
plt.plot(x,y)
8
plt.xlabel('$x$')
9
plt.ylabel('$y$',rotation=0)
10
plt.show()

456
Unconstrained Optimization and Neural Networks
−1.00 −0.75 −0.50 −0.25
0.00
0.25
0.50
0.75
1.00
x
−2.0
−1.5
−1.0
−0.5
0.0
0.5
1.0
1.5
2.0
y
The next step is to select randomly data points to use them as training data. Usually,
we select 70-80% of the data as training data, and in this example we choose 75%. The
separation between testing and training data can be done with the function train test -
split of the module sklearn.model selection.
1
from sklearn.model_selection import train_test_split
2
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)
3
plt.plot(x_train, y_train, '.', x_test, y_test,'x')
4
plt.xlabel('$x$')
5
plt.ylabel('$y$',rotation=0)
6
plt.show()
−1.00 −0.75 −0.50 −0.25
0.00
0.25
0.50
0.75
1.00
x
−2.0
−1.5
−1.0
−0.5
0.0
0.5
1.0
1.5
2.0
y
In this figure we can see that most of the points (dots) are training data. Then using
the testing data, we will try to reconstruct the shape of the function f.
The back-propagation algorithm with one hidden layer of 100 neurons in total for this
problem can be implemented as easy as the following code:
1
# reshape the date into (N,1)-dimensional array
2
x_train = x_train.reshape(-1,1)
3
x_test = x_test.reshape(-1,1)
4
from sklearn.neural_network import MLPRegressor
5
# setup the network
6
mlp = MLPRegressor(hidden_layer_sizes=[100])
7
# train the network
8
mlp.fit(x_train,y_train)

Introduction to Neural Networks
457
9
# use the trained network to obtain results
10
predictions = mlp.predict(x_test)
11
plt.plot(x,y,x_test, predictions, 'r.')
12
plt.xlabel('$x$')
13
plt.ylabel('$y$',rotation=0)
14
plt.show()
−1.00 −0.75 −0.50 −0.25
0.00
0.25
0.50
0.75
1.00
x
−2.0
−1.5
−1.0
−0.5
0.0
0.5
1.0
1.5
2.0
y
In this code we obtain in the output mlp the setup of the neural network, then with the
fit function we train the network and finally we receive the predictions with the function
predict.
The predicted values are not very accurate, although the result is better than what we
would have gotten in the case of a linear least squares approximation. On the other hand,
it demonstrates the ease of use of the Scikit-Learn with its default parameters. To obtain
better results we increase the number of hidden layers and their neurons to six hidden layers
with [20, 50, 50, 50, 50, 20] neurons.
1
x_train = x_train.reshape(-1,1)
2
x_test = x_test.reshape(-1,1)
3
from sklearn.neural_network import MLPRegressor
4
mlp = MLPRegressor(hidden_layer_sizes=[20,50,50,50,50,20])
5
mlp.fit(x_train,y_train)
6
predictions = mlp.predict(x_test)
7
plt.plot(x,y,x_test, predictions, 'r.')
8
plt.xlabel('$x$')
9
plt.ylabel('$y$',rotation=0)
10
plt.show()

458
Unconstrained Optimization and Neural Networks
−1.00 −0.75 −0.50 −0.25
0.00
0.25
0.50
0.75
1.00
x
−2.0
−1.5
−1.0
−0.5
0.0
0.5
1.0
1.5
2.0
y
In addition to the MLPRegressor the Scikit-Learn is equipped with the class
MLPClassifier which has a number of attributes and methods specialized for solving clas-
sification problems. After training the network we use the method predict to predict new
samples. We will see all these in action in the following application example.
11.4.5
Application in image recognition
Perhaps one of the most important classification problems that has been solved with ma-
chine learning is the digits recognition and the recognition of car registration plates by
machines. In this section we show how to train and test a simple neural network to recog-
nize handwritten numbers from 0 to 9. For training and testing the network we need a set
of images with handwritten digits. For this reason, we will use a dataset provided by the
sklearn module. This dataset can be loaded into the memory using the command
1
from sklearn import datasets
2
digits = datasets.load_digits()
which will load all the images and their attributes into the Python class digits. The images
are stored into the array digits.images, which is a three-dimensional array with shape
(1797, 8, 8) meaning that we have 1797 images of 8 × 8 pixels. Using subplots we plot
the first 10 digits with the commands
1
figure, axes = plt.subplots(nrows=1, ncols=10, figsize=(10, 3))
2
for i in range(10):
3
axes[i].set_axis_off()
4
axes[i].imshow(digits.images[i],cmap='binary')
5
plt.show()
Each of these digits is an image in grey scale. Each pixel is an entry of an array and its
value represents the intensity of grey. The rest of the images are similar but all different.
You can try plotting more of such images by modifying the previous code appropriately.
For more information about digital image representation, we refer to Section 10.5.6.
As a first step we consider a simple neural network with 64 neurons for the input layer.
Each neuron corresponds to a pixel. We will also consider a hidden layer of 15 neurons and
an output layer with 10 neurons for the digits 0 to 9.

Introduction to Neural Networks
459
Since the input layer is a vector of 64 entries, we need to reshape the input images and
transform them into (64,) vectors, and store them as columns of an array x instead of
square 8 × 8 arrays.
1
x = digits.images.reshape((len(digits.images), -1))
2
print(x.shape)
We also keep a record of the digits using the attribute target of the class digits with the
command y = digits.target.
Next, we split our data into training and testing data by separating the first 1000 images
to be used for training and the rest 797 for testing. We do the same for their labels and we
store them into two different arrays with names x train, y train, and x text, y test.
1
x_train = x[:1000]; y_train = y[:1000]
2
x_test = x[1000:]; y_test = y[1000:]
After having all the data ready, we build a neural network with 15 hidden layers using the
class MLPClassifier. We store the neural network in a variable called NN. For this neural
network we consider the activation function logistic and learning rate 0.1, while for solver
we use the sgd which implements a stochastic gradient descent method. The complete call
should look like
1
from sklearn.neural_network import MLPClassifier
2
NN = MLPClassifier(hidden_layer_sizes=[15], activation='logistic',
3
solver='sgd', learning_rate_init=.1, verbose=True)
We give the input parameter verbose=True so as to observe the progress during the training
of the neural network and receive important information. The training of the network is
completed with the method fit
1
NN.fit(x_train,y_train)
Since we have computed all the weights we can let our neural network recognize our test
images using the method predict. For the sake of convenience we show the first 50 digits
from the set x test. In addition to these predictions we present the exact values stored in
the array y test.
1
predictions = NN.predict(x_test)
2
print('predicted values=', predictions[:50])
3
print('exact values=', y_test[:50])
predicted values=[1 4 0 5 3 6 9 6 1 7 5 4 4 7 2 8 2 2 5 7 9 5 4 4 9 0 8 9 8 0 1
2 3 4 5 6 7 8 3 0 1 2 3 4 5 6 7 8 5 0]
exact values=[1 4 0 5 3 6 9 6 1 7 5 4 4 7 2 8 2 2 5 7 9 5 4 4 9 0 8 9 8 0 1 2 3
4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0]
Observe that the 49-th digit is 9 but our network predicted 5. We can avoid such errors
by choosing different parameters for the neural network. This is not the only error in this
set of data but as you can see the mixed numbers are quite the same. We can easily compare
them using the command sum(predictions==y test). This will return the total number
of correct predictions, while subtracting from len(predictions) we estimate the wrong
predictions. In our test case we got 67 wrong predictions and 730 correct. How many wrong
predictions did you get?

460
Unconstrained Optimization and Neural Networks
11.5
Further Reading
Suggested books for further reading in optimization include the books [13, 23, 93, 98]. These
are also the books that we have followed closely. Optimization methods for the numerical
solution of linear systems, such as the method of steepest descent and conjugate gradient
are analyzed in books of numerical linear algebra such as [112, 29, 53, 48, 24]. An important
review on methods of optimization is the review paper [33]. Applications of optimization
in artificial neural networks can be found in [59]. For a complete introduction to neural
network techniques, refer to [49, 86, 92]. The paper [62] consists of an introduction to deep
learning and the backpropagation algorithm and is highly recommended.

Chapter Highlights
 Unconstrained optimization is the branch of optimization that focuses on the
minimization of functions.
 The solution x∗minimizing a function f(x) is called minimizer.
 Gradient methods are iterative methods where at every iteration the new
approximation is computed along the direction of the gradient −∇f(x), the
direction of the steepest descent.
 General gradient descent methods converge linearly.
 The method of steepest descent is a particular gradient method where the step
of the minimization is defined so as to minimize the value f(x(k+1)).
 The steepest descent method finds applications in the solution of linear systems
of equations by minimizing the function
f(x) = 1
2⟨Ax, x⟩−⟨b, x⟩.
 The conjugate gradient method is an alternative of the steepest descent method
in which the directions are more general and can be derived using the notion of
conjugate directions.
 The conjugate gradient method for linear systems converges if A is symmetric
and positive definite. It also requires at most n iterations to converge to the
exact solution with exact arithmetic.
 The convergence of iterative methods for linear systems can be accelerated
using preconditioning techniques.
 Other popular methods for the minimization of functions are Newton-type
methods such as the classical Newton method and other approximations such
as quasi-Newton and Levenberg-Marquardt methods.
 One of the pillars of modern machine learning is the branch of optimization.
 Neural networks represented by connected nodes (neurons) are characterized by
undetermined weights.
 The estimation of weights (known as backpropagation) can be done using
optimization techniques to minimize errors on given training data.
 The error in neural network processes is usually expressed as a least squares
error and is known as cost function.
 SciKit-Learn is a Python library for machine learning problems. Other libraries
are the TensorFlow and PyTorch.
461

Exercises
1. (Golden section search algorithm) The golden section search algorithm is an iter-
ative algorithm for the approximation of the value x∗= argminf(x). Let x∗∈[a, b] be
the unique minimizer of the objective function f. Like the bisection method, the initial
interval will be replaced by a smaller one in the next step of the method. The main
difference is that in order to locate an interval with the minimizer we need two points to
detect whether the function f is increasing or decreasing. For this reason, in each step
we compute the values
x = a + r(b −a),
u = f(x)
y = a + r2(b −a),
v = f(y)
,
where r = 1/ρ and ρ is the golden section ratio
ρ = 1 +
√
5
2
≈1.62 .
If u > v then the minimum of f lies in the interval [a, x], which will be the input interval
for the next step. If u ≤v then the minimum lies in the interval [y, b]. We repeat the
previous steps in the new interval until the interval is small enough to meet appropriate
tolerance.
(a) Show that r is a root of the equation r2 + r −1 = 0.
(b) Implement the previous method in a Python function.
(c) Use the method to find the minimum of the function f(x) = x2 + x + 1.
(d) Compare your results with the results of the function golden of the module
scipy.optimize.
2. Prove that ∥· ∥1, ∥· ∥2 and ∥· ∥∞as defined in Chapter 9 are vector norms. Let A be a
symmetric and positive definite matrix. Prove that the map ∥· ∥A : Rn →R with
∥x∥A = xT Ax ,
is a vector norm. This norm is known as A-norm.
3. Consider the minimization of the linear least squares error E(x) = 1
2∥Ax −b∥2, where
A is a real m × n matrix, and b an n-dimensional column vector.
(a) Write and implement the steepest descent method for solving the specific linear
least squares problem.
(b) Write and implement the conjugate gradient method for solving the same problem.
(c) Test your codes for the problem with
A =


0
1.1
1
0
0
−0.2

,
b =


1
−1.1
−0.2

,
which has optimal solution the vector x = (−1.1, 1)T .
(d) Compare the results with those obtained using the SVD of A.
4. Consider the function f(x) = x3
1 −x1x2 −x1 + x1x3
2 −x4
2 with x = (x1, x2)T .
462

(a) Find all critical points for which ∇f(x) = 0.
(b) Verify which are maxima and minima.
(c) Use the steepest descent method to compute approximations of all these points.
5. Consider the function f(x) = 100(x2
1 −x2
2) + (1 −x1)2, with x = (x1, x2)T .
(a) Use the steepest descent method to approximate the minima of f.
(b) Use the conjugate gradient method to approximate the minima of f.
6. Consider the linear system Ax = b with
A =
1
0
0
λ

,
with λ > 0 and x = b = 0.
(a) If x(k) = (x(k)
1 , x(k)
2 )T , show that the method of steepest descent is
x(k+1) =
x(k)
1 x(k)
2 (λ −1)
(x(k)
1 )2 + λ3(x(k)
2 )2
 
λ2x(k)
2
−x(k)
1
!
.
Sketch a diagram with the isolines of the functional f(x) as defined in (11.12) and
some approximations x(k), k = 1, 2, 3, . . . when x(0) = (5, 1)T .
(b) Show that if x(k) = c(λ, ±1)T , then the inequality (11.17) holds as an equality.
(c) If λ = 100, how many steps of the method are needed until the error ⟨Ae(k), e(k)⟩1/2
becomes less than ε⟨Ae(0), e(0)⟩1/2 for given ε > 0?
7. Consider the linear system Ax = b with
A =


2
1
1
1
2
1
1
1
2


and
b =


2
0
2

.
(a) Solve the system with the conjugate gradient method using as initial guess the
vector x0 = (0, 0, 0)T .
(b) Solve the system with the Jacobi and Gauss-Seidel methods.
(c) Compare the methods in terms of convergence, speed and accuracy.
8. Consider an artificial neural network with three neurons x1, x2, x3 as input layer, a
hidden layer with two neurons z1, z2 and the output layer comprised two neurons y1,
y2. The neural network has a bias unit connected to both z1, z2 and a different bias
connected to y1, y2. The specific neural network can be described with the graph diagram
11.10. Given the training data ˆx = ((ˆy1, ˆy2, ˆx3)T = (1, 4, 5)T with desired output ˆy =
(ˆy1, ˆy2)T = (0.1, 0.05)T :
(a) Write a Python function that will implement the fsigmoid activation function.
(b) Write a Python function that given the synaptic weights and input data will com-
pute the values
fsigmoid(w1x1 + w3x2 + w5x3 + b1) = z1 ,
fsigmoid(w2x1 + w4x2 + w6x3 + b1) = z2 ,
and
fsigmoid(w7z1 + w9z2 + b2) = y1 ,
fsigmoid(w8z1 + w10z2 + b2) = y2 .
463

FIGURE 11.10
General neural network.
(c) Initialize the synaptic weights with the values
w1 = 0.1,
w2 = 0.2,
w3 = 0.3,
w4 = 0.4,
w5 = 0.5,
w6 = 0.6,
w7 = 0.7,
w8 = 0.8,
w9 = 0.9,
w10 = 0.1,
and biases b1 = b2 = 0.5. Forward propagate the network to compute the output
y = (y1, y2)T . Estimate the error in the forward propagation using the cost function
E(w) = 1
2∥y −ˆy∥2
2 .
Estimate also the default synaptic weights and biases.
(d) Compute the gradient
∇E =
 ∂E
∂w1
, ∂E
∂w2
, . . . , ∂E
∂w10
T
.
For the last one you will need to use the chain rule. Then write a Python function
that will return the gradient of the cost function.
(e) Write a Python program to back propagate the network using the given training
data and compute the optimal synaptic weights and biases.
(f) Use Python to compute the output of the specific neural network for x =
(x1, x2, x3)T = (1, 6, 9)T .
9. In this problem we analyze the housing market of the Boston state of the USA and we
predict the value of a house.
(a) Load the sklearn dataset with name load boston. The particular dataset returns
a dictionary with five variables: data, target, feature names, and DESCR. The
variable feature names is explained in the variable DESCR.
(b) From this dataset extract the number of rooms and the price of the houses in two
variables names as X rooms and y price.
464

(c) Split the data using the function train test split of sklearn into 80% training
and 20% testing data.
(d) Use the MLPRegressor to construct a neural network with six hidden layers of
10, 50, 50, 50, 50 and 10 perceptrons respectively.
(e) Use the appropriate sklearn function to train and test the neural network for this
problem.
(f) Explore the predictions and compute a mean error using vector norms.
465

Taylor & Francis 
Taylor & Francis Group 
http://taylorandfrancis.com 

12
Eigenvalue Problems
We have seen that computing the SVD of a matrix A requires the computation of the
eigenvalues of the matrix AT A. This is a simple example where the knowledge of eigenvalues
can be very important. In addition to numerical methods that require the knowledge of
eigenvalues, there are applications like the PageRank algorithm of Google, that rely on
the fast computation of the principal eigenvalue of a large matrix. In this chapter, we
discuss numerical methods for the computation of eigenvalues and eigenvectors of matrices.
Initially we discuss algorithms for the estimation of selected eigenvalues, for example the
maximum in magnitude eigenvalue. Although this algorithm is very simple, it has a wide
range of applications. We close this chapter with the QR iteration, which is not limited to
the computation of selective eigenvalues.
12.1
Eigenvalues and Eigenvectors
We begin with a revision of eigenvalues and eigenvectors. Some of their properties can
be found useful in the development of efficient algorithms for their computation. We also
include some practical information for computations with the so-called Jordan normal form.
Readers interested in the numerical methods only, they can skip that part and continue with
Section 12.2.
12.1.1
Basic properties
In Section 2.2.12 we defined the eigenvalues of an n × n matrix A to be the roots of the
characteristic equation det(A −λI) = 0 where ϕ(λ) = det(A −λI) is the characteristic
polynomial. Because of this definition, if λ is an eigenvalue of A, then the matrix A −λI
is singular (not invertible).
As an immediate consequence of the previous definition is that A and its transpose share
exactly the same eigenvalues. To see this suppose that λ is an eigenvalue of A such that
det(A −λI) = 0. Then,
det(AT −λI) = det(A −λI)T = det(A −λI) = 0 ,
which means that λ is also an eigenvalue of AT .
The set of all eigenvalues of A is called spectrum and is denoted by σ(A). Since eigen-
values are zeros of a polynomial, they might not be simple roots. The algebraic multiplicity
τ of an eigenvalue λj is the number of times the eigenvalue λj appears as a root of the
characteristic polynomial ϕ(λ), that is the largest integer τ such that (λ −λj)τ divides
exactly the characteristic polynomial.
The linear system (A −λI)x = 0 for an eigenvalue λ will have non-trivial solutions
x = u ̸= 0 (in addition to x = 0) since the matrix A −λI is not invertible. The non-
trivial solutions u are called eigenvectors associated with the eigenvalue λ. Suppose that
DOI: 10.1201/9781003287292-12
467

468
Eigenvalue Problems
an eigenvalue λ has m linearly independent eigenvectors ui such that Aui = λui for all
i = 1, 2, . . . , m. Define the space produced by the eigenvectors of A corresponding to the
eigenvalue λ
Vλ = {u : (A −λI)u = 0} .
The space Vλ is called eigenspace or the kernel of the matrix A −λI. For this reason,
sometimes we write Vλ = ker(A −λI) while m = dim(Vλ).
The geometric multiplicity of an eigenvalue λ is the number d = dim(Vλ), the dimension
of Vλ. The geometric multiplicity is actually the number of linearly independent eigenvectors
associated with the eigenvalue λ. It can be shown that d ≤τ. If d = τ for each eigenvalue
of A, then the matrix A is called nondefective (or matrix of simple structure). If A has an
eigenvalue with d < τ, then it is called defective.
Two matrices A, J are called similar if there is an invertible matrix P such that A =
P JP −1. If λ is an eigenvalue of J with corresponding eigenvector u, then the following
calculations reveal that λ is also eigenvalue of A and P u a corresponding eigenvector.
Ju = λu
JP −1P u = λu
P JP −1P u = λP u
AP u = λP u
In the theory of linear algebra it is known that any square matrix A is similar to its
Jordan normal form J, or else there is an upper triangular matrix J with diagonal entries
the eigenvalues of A and an invertible and orthogonal matrix P such that A = P JP −1.
12.1.2
Diagonalization of a matrix and the Jordan normal form
Suppose that an n × n matrix A has n distinct eigenvalues. This means that the spectrum
of A is σ(A) = {λ1, λ2, . . . , λn} with λi ̸= λj, i ̸= j. If A is nondefective and u1, u2, . . . , un
are eigenvectors associated with the eigenvalues λ1, λ2, . . . , λn of σ(A), then they will be
linearly independent (since they correspond to different eigenvalues), [105].
Let
P =
 u1
u2
· · ·
un

,
the matrix with columns the eigenvectors of A. Since the columns of P are linearly in-
dependent, then det(P ) ̸= 0, i.e. P is invertible. Moreover, Aui = λiui, i = 1, 2, . . . , n.
Then,
A P = A
 u1
u2
· · ·
un

=
 λ1u1
λ2u2
· · ·
λnun

,
which in matrix notation can be written as
A P =
 u1
u2
· · ·
un







λ1
0
· · ·
0
0
λ2
...
0
0
...
...
0
0
· · ·
0
λn






= P D ,
where
D =






λ1
0
· · ·
0
0
λ2
...
0
0
...
...
0
0
· · ·
0
λn






= diag{λ1, λ2, . . . , λn} .

Eigenvalues and Eigenvectors
469
The relation AP = P D implies that A = P DP −1. We call A diagonalizable.

If an n × n matrix A is nondefective, then the n linearly independent eigen-
vectors of A form a similarity transform P such that A = P DP −1 where
D = diag{λ1, λ2, . . . , λn}.
Diagonalizable matrices is a special case but in general not every matrix is similar to
a diagonal matrix. On the other hand, a square (complex) matrix A is similar to a block
diagonal matrix
J =



J1
...
Jp


,
where the blocks Ji are called Jordan blocks. A Jordan block is upper-triangular
Ji =







λ
1
λ
1
...
...
λ
1
λ







,
where λ is an eigenvalue of A. In the special case of a diagonalizable matrix, the Jordan
blocks are 1 × 1 blocks consisting of the eigenvalues of A. More information about the
computation of the Jordan canonical form can be found in the Appendix.
12.1.3
Other properties
Let A = P JP −1, then any power of A can be computed as
Ak = P JkP −1 .
To see this, take k = 2 and write
A2 = A · A = P JP −1 · P JP −1 = P J2P −1 .
The same applies to more general functions f(A) of a matrix A.
The trace of a matrix A is the sum of all its diagonal elements
trace(A) =
n
X
i=1
aii .
Since by the Jordan normal form theorem any n × n matrix A is similar to an upper
triangular matrix J where the diagonal entries of J are the eigenvalues of A repeated
depending on their multiplicity, then the trace of A is the same with the sum of all the
eigenvalues of A
trace(A) =
n
X
i=1
aii =
n
X
i=1
λi ,
where λi are the eigenvalues of A, even with non-trivial multiplicity. This follows from the
fact that trace(AB) = trace(BA) for any square matrices A and B.

470
Eigenvalue Problems
Using again the Jordan normal form of any square matrix A we have that the determi-
nant of A is the product of the eigenvalues of A (counting their multiplicity)
det(A) = det(P JP −1) = det(P ) det(J) det(P −1) =
n
Y
i=1
λi .
Thus, the knowledge of the eigenvalues of a matrix A can solve the computationally expen-
sive problem of computing its determinant.
Consider the shifted matrix A + sI for some s ∈R. If u is an eigenvector of A that
corresponds to an eigenvalue λ, then
(A + sI)u = Au + su = λu + su = (λ + s)u .
This means that the shifted matrix A + sI has the shifted eigenvalues λ + s and shares the
same eigenvectors with A.
In general, the eigenvalues of a real matrix A do not need to be real. Some of them can
be complex, unless the matrix is symmetric A = AT . For example, suppose A is symmetric
with eigenvalue λ and eigenvector u ̸= 0, then Au = λu. Taking the complex conjugate on
both sides of the previous relation and the transpose of the result we have
(Au)T = (λu)T ,
which can be written as
uT AT = λuT .
If we multiply from the right both sides of the last relation with u we get
uT AT u = λuT u ,
(12.1)
Similarly, if we multiply the relation Au = λu with uT from the left we have
uT Au = λuT u .
(12.2)
If we subtract (12.1) from (12.2) and use the fact that AT = A we have that
(λ −λ)uT u = 0 ,
or better
∥u∥2(λ −λ) = 0 .
Since u ̸= 0 we have that λ −λ = 0 which implies that λ = λ and thus λ ∈R.
Interesting are also the properties of the eigenvectors of a symmetric matrix. Two dif-
ferent eigenvectors ui, uj of a real symmetric matrix A corresponding to the eigenvalues
λi ̸= λj, are orthogonal, in the sense that uT
i uj = 0 if i ̸= j. To see this, take the transpose
of Aui = λiui to obtain uT
i A = λiuT
i . Multiplication with uj gives
λiuT
i uj = uT
i Auj = uT
i λjuj = λjuT
i uj .
Transfering everything to the left side yields
(λi −λj)uT
i uj = 0 .
Since λi ̸= λj implies uT
i uj = 0, which means that ui ⊥uj.
It is worth mentioning that solving (12.2) for the eigenvalue λ we obtain the formula
λ = uT Au
uT u
= uT Au
∥u∥2
2
,
(12.3)
which gives the value of the eigenvalue λ given its eigenvector u.

Eigenvalues and Eigenvectors
471
12.1.4
First estimation of eigenvalues using Gerschgorin disks
A first estimation of the location of the eigenvalues of a matrix A can be found using
Gerschgorin’s theorem.
Theorem 12.1 (Gerschgorin). Any eigenvalue λ of an n×n matrix A is located in at least
one of the discs with center the diagonal entry aii of A and radius the trace
ri =
n
X
j=1
j̸=i
|aij| .
These disks are known as Gerschgorin disks. An immediate consequence is that the spectrum
of A is contained in the union of Gerschgorin disks of A,
σ(A) ⊂∪n
i=1{z : |z −aii| ≤ri} ⊂C .
Proof. Let λ be an eigenvalue of A with corresponding eigenvector x. We write A = D −
L −U where D is the diagonal matrix with the entries aii, i = 1, 2, . . . , n, while the rest of
the entries of A are in the matrix −(L + U), as in Section 9.7.2. Then we have that
(A −λI)x = 0
(D −λI)x −(L + U)x = 0
(λI −D)x = −(L + U)x .
This implies that the i-th entry of the vector (λI −D)x is
(λ −aii)xi =
n
X
j=1
j̸=i
aijxj,
for
i = 1, 2, . . . , n .
Taking modulus on both sides we get
|λ −aii| |xi| ≤
n
X
j=1
j̸=i
|aij| |xj| ,
where we made use of the triangles inequality |a + b| ≤|a| + |b|.
Let xk be the largest in magnitude entry of the eigenvector x. Then after scaling x with
xk we have
|λ −aii| ≤
n
X
j=1
j̸=i
|aij| |xj|
|xk| ≤
n
X
j=1
j̸=i
|aij| ,
since |xj|/|xk| ≤1. Thus, any eigenvalue λ is contained in at least one of the Gerschgorin
disks, which proves the theorem.
For example, consider the matrix
A =


−2
−4
2
−2
1
2
4
2
5

,
with spectrum σ(A) = {−5, 3, 6}. The Gerschgorin disks in this case are the sets
D1 = {z : |z + 2| ≤6},
D2 = {z : |z −1| ≤4},
D3 = {z : |z −5| ≤6} .

472
Eigenvalue Problems
-8
-8
-6
-6
-4
-4
-2
-2
2
4
6
8
10
10
12
12
14
14
-6
-6
-4
-4
-2
-2
2
4
6
8
0
A
B
C
FIGURE 12.1
The Gerschgorin disks and the eigenvalues of a matrix A.
The Gerschgorin disks and with the locations of the eigenvalues are depicted in Figure
12.1. Apart from its beauty and theoretical use, the particular theorem can only provide a
rough estimation of the location of the eigenvalues of a matrix, especially for the extreme
eigenvalues. For more accurate estimations we need to use more sophisticated numerical
algorithms.
12.2
Numerical Approximation of Eigenvalues and Eigenvectors
There are several numerical methods for the approximation of eigenvalues of matrices.
Namely, the power method, inverse iteration, Raleigh quotient iteration, Arnoldi iteration,
Lanczos algorithm, QR algorithm and many more. In this section we present some numer-
ical methods for the computation of selected eigenvalues such as the one with maximum
magnitude. We will call this eigenvalue principal eigenvalue. We start with the simplest
method known as the power method or power iteration.
12.2.1
Power method
The power method or power iteration is an iterative method for the estimation of the prin-
cipal eigenvalue of an n × n matrix A. This is the largest in magnitude eigenvalue of A.
The eigenvector that corresponds to the eigenvalue with the largest magnitude is called the
principal eigenvector. Assume that A has N eigenvalues with
|λ1| > |λ2| ≥· · · ≥|λN| .
It is important for the convergence of this method to notice that the eigenvalue λ1 is not
repeated. Assume also that each eigenvalue λi has an eigenvector ui for i = 1, 2, . . . , N that
altogether form a linearly independent set of eigenvectors
E = {u1, u2, . . . , uN} .

Numerical Approximation of Eigenvalues and Eigenvectors
473
Since the N eigenvectors ui, i = 1, 2, . . . , N are linearly independent, they form a basis
of RN. And so any vector x(0) ∈RN can be expressed as a linear combination of all these
ui
x(0) = c1u1 + c2u2 + · · · + cNuN .
We choose arbitrarily such a vector x(0) ̸= 0 to be an initial approximation of u1. Then we
define the iterative method
x(k+1) = Ax(k)
for k = 1, 2, . . . ,
for the approximation of the eigenvector u1.
Note that
x(k) = Ax(k−1) = AAx(k−2) = A2x(k−2) = · · · = Akx(0) .
Because in every iteration we implicitly construct powers of A, we call this particular
numerical method power method.
Moreover,
Akx(0) = Ak(c1u1 + c2u2 + · · · + cNuN)
= c1Aku1 + c2Aku2 + · · · + cNAkuN
= c1λk
1u1 + c2λk
2u2 + · · · + cNλk
NuN
= λk
1
"
c1u1 +
λ2
λ1
k
c2u2 + · · · +
λN
λ1
k
cNuN
#
,
which implies
Akx(0)
λk
1
= c1u1 +
λ2
λ1
k
c2u2 + · · · +
λN
λ1
k
cNuN .
(12.4)
Since λ1 > λj for all j ≥2 we have that
λj
λ1
< 1
for j = 2, 3, . . . , N .
Taking the limit k →∞in (12.4), we have
lim
k→∞
Akx(0)
λk
1
= c1u1 .
Thus, if we could estimate the eigenvalue λ1, then we can choose the vector
u1 ≈
x(k)/λk
1
∥x(k)/λk
1∥,
for large value of k to be an approximation of the eigenvector u1.
Suppose that the maximum entry of the vector x(k) is its j-th entry x(k)
j
for some j. In
order to find the eigenvalue λ1, we first define the function fj(x) = xj where xj is the j-th
entry of the vector x and j = argmax(x(k)) fixed. Then we have that
fj(x(k)) = λk
1c1fj(u1) +
λ2
λ1
k
c2fj(u2) + · · · +
λN
λ1
k
cNfj(uN) .

474
Eigenvalue Problems
For convenience denote
E(k) =
λ2
λ1
k
c2fj(u2) + · · · +
λN
λ1
k
cNfj(uN) ,
which has
lim
k→∞E(k) = 0 .
Computing the ratio
fj(x(k+1))
fj(x(k))
= λ1
c1fj(u1) + E(k+1)
c1fj(u1) + E(k)
,
and taking the limit k →∞we obtain the maximum in magnitude eigenvalue λ1 to be
λ1 = lim
k→∞
fj(x(k+1))
fj(x(k))
.
Therefore, we approximate this eigenvalue with the number
λ1 ≈fj(x(k+1))
fj(x(k))
,
for a large value of k.

The convergence of the power iteration is geometric and depends on the ratio
λ2/λ1 < 1. If λ2 ≈λ1 then the convergence is very slow. On the other hand, if
λ2 ≪λ1 then the convergence will be fast.
The algorithm of the power method is summarized in Algorithm 48.
Algorithm 48 Power method
Set a tolerance TOL for the accuracy
Set the maximum number of iterations MAXIT
Initialize the vector x(k) ̸= 0 and the eigenvalue λ1 = 0, and set k = 0
Set Error = TOL + 1
Compute j = argmaxj(x(k)
j )
while Error > TOL and k < MAXIT do
Compute new x(k+1) = Ax(k)
Set λ0 = x(k+1)
j
/x(k)
j
Set Error = |λ1 −λ0|
Increase the counter k = k + 1
Set λ1 = λ0
end while
Return the approximate eigenvalue λ1 and the eigenvector u1 = (x(k)/λk
1)/∥x(k)/λk
1∥
Algorithm 48 is implemented in the Python function powermethod below:
1
def powerMethod(A, x0, tol = 1.e-6, maxit = 100):
2
# initialize the parameters
3
iteration = 0
4
error = tol+1.0

Numerical Approximation of Eigenvalues and Eigenvectors
475
5
lambda0 = 0.0
6
# find the index for the maximum entry
7
j = np.argmax(x0)
8
while (error > tol and iteration < maxit):
9
x1 = np.dot(A,x0)
10
# find the approximation of the eigenvalue
11
lambda1 = x1[j]/x0[j]
12
error = np.abs(lambda0-lambda1)
13
iteration = iteration + 1
14
lambda0 = lambda1
15
x0 = x1.copy()
16
k = iteration
17
u1 = (x1/lambda1**k)/npl.norm(x1/lambda1**k,np.inf)
18
print('number of iterations required = ',iteration)
19
# return eigenvalue and corresponding eigenvector
20
return lambda1, u1
Note that for the computation of the eigenvector u1, we normalize its value using the
maximum norm. As testing example we consider the matrix
A =


−2
−4
2
−2
1
2
4
2
5


with spectrum σ(A) = {−5, 3, 6}. Using our function powerMethod we compute as expected
the maximum in magnitude eigenvalue while we verify that ∥Au1 −λ1u1∥≈0.
1
# define matrix and initial guess x0
2
A = np.array([[-2.,-4.,2.],[-2.,1.,2.],[4.,2.,5.]])
3
x0 = np.array([1,1,1])
4
# compute eigenvalue and eigenvector
5
lambda1,u1 = powerMethod(A,x0, tol=1.e-10, maxit=1000)
6
# print eigenvalue and eigenvector
7
print(lambda1)
8
print(u1)
9
# compute and print the residual ∥Au1 −λ1u1∥
10
error =
npl.norm(np.dot(A,u1) - lambda1*u1)
11
print('actual error = ', error)
number of iterations required =
158
6.000000000040729
[0.0625 0.375
1.
]
actual error =
4.315242285689494e-11
12.2.2
Inverse power method
The inverse power method (or else the inverse iteration) is a modification of the power
method for the computation of the minimum in magnitude eigenvalue of A. Assume that
A has eigenvalues
|λ1| ≥|λ2| ≥· · · ≥|λN−1| > |λN| > 0 .

476
Eigenvalue Problems
If uN is the eigenvector that corresponds to the eigenvalue λN, then we have
AuN = λNuN ,
which can be rearranged to the formula
A−1uN =
1
λN
uN .
Thus, the eigenvalue λ−1
N is the dominant eigenvalue of A−1. To approximate the dominant
eigenvalue of A−1 we can employ the power method, which can be expressed as
x(k+1) = A−1x(k) .
Since the direct computation of the inverse A−1 is not a good practice, we prefer to compute
the vector x(k+1) by solving the system
Ax(k+1) = x(k) .
This can be done efficaciously using the LU decomposition, and the function lu factor
and lu solve as described in Sections 9.1.2 and 9.6. The modification of the function
powermethod is very simple and we call it inversePowerMethod
1
def inversePowerMethod(A, x0, tol = 1.e-6, maxit = 100):
2
# initialize the parameters
3
iteration = 0
4
error = tol+1.0
5
lambda0 = 0.0
6
lu, piv = spl.lu_factor(A)
7
# find the index for the maximum entry
8
j = np.argmax(x0)
9
while (error > tol and iteration < maxit):
10
x1 = spl.lu_solve((lu, piv), x0)
11
# find the approximation of the eigenvalue
12
lambda1 = x1[j]/x0[j]
13
error = np.abs(lambda0-lambda1)
14
iteration = iteration + 1
15
lambda0 = lambda1
16
x0 = x1.copy()
17
k = iteration
18
u1 = (x1/lambda1**k)/npl.norm(x1/lambda1**k,np.inf)
19
print('number of iterations required = ',iteration)
20
# return eigenvalue and corresponding eigenvector
21
return 1/lambda1, u1
Using the matrix from the example with the power method and the following code we
obtain the eigenvalue 3 with the smallest magnitude.
1
A = np.array([[-2.,-4.,2.],[-2.,1.,2.],[4.,2.,5.]])
2
x0 = np.array([-1,1,1])
3
lambda1,u1 = inversePowerMethod(A,x0, tol=1.e-10, maxit=1000)
4
print(lambda1)

Numerical Approximation of Eigenvalues and Eigenvectors
477
number of iterations required =
44
3.0000000002520206
The approximation of the rest of the eigenvalues can be done with more sophisticated
numerical methods or the simple shifted power method. The last method is the subject of
the next paragraph.
12.2.3
Shifted inverse power method
So far we have seen how to approximate the largest and smallest in magnitude eigenvalues
of a matrix A. As example we used the matrix
A =


−2
−4
2
−2
1
2
4
2
5

,
that has spectrum σ(A) = {−5, 3, 6}. The smallest in magnitude eigenvalue is 3 and the
largest one is 6. The question is if we could use the power method to approximate the other
eigenvalue as well. The answer is positive. We can compute the eigenvalue −5 by using a
modified power method known to as the shifted power method. The name shifted is because
we shift the spectrum of A so as the desired eigenvalue becomes closer to 0.
The shifted power method relies on the fact that if λ is an eigenvalue of A and u its
corresponding eigenvector, then λ −α is an eigenvalue of the matrix A −αI with the same
corresponding eigenvector u. Similarly, the matrix (A−αI)−1 has the eigenvalue 1/(λ−α).
To compute an eigenvalue λ, which is not any of the extreme in magnitude, we choose α
such that λ −α is the closest to 0 eigenvalue of the matrix A −αI, and then we use the
inverse power method to find it. The choice of α can rely on experimentation or intuition.
In our example, from Gerschgorin’s theorem we know that there is an eigenvalue in the disk
with center −2 and radius 6. Using the center of the Gerschgorin disk α = −2 to shift the
matrix we obtain
A + 2I =


0
−4
2
−2
3
2
4
2
7

.
Using the inverse power method we approximate the eigenvalue λ −α = −3 for the matrix
A + 2I. Solving for λ with α = −2, we obtain λ = −5. We leave the implementation of the
shifted power method as an exercise for the reader.
12.2.4
Basic QR iteration
Power methods are very simple and easy to implement. Their major drawback is that they
return only one eigenvalue at a time. On the other hand, more sophisticated methods can
lead to the approximation of all the eigenvalues of a matrix at once. One such example is
the QR iteration.
The QR iteration is an iterative method based on a similarity transformation of A to
a matrix T for which it is easier to compute its eigenvalues. In what follows we describe
briefly the basic QR iteration, where for the sake of simplicity, assume that A is a real n×n
matrix with n distinct eigenvalues
|λ1| > |λ2| > · · · > |λn| .
Choosing an orthogonal matrix Q(0) we define T (0) = [Q(0)]T AQ(0). Usually, we take
Q(0) = I, and thus T (0) = A. Then we perform the QR factorization
Q(k+1)R(k+1) = T (k),
for k = 0, 1, . . . ,

478
Eigenvalue Problems
and we compute the new matrix
T (k+1) = R(k+1)Q(k+1) ,
for all k = 0, 1, 2, . . . .
In this way we produce every time the matrix
T (k+1) = R(k+1)Q(k+1) = [Q(k+1)]T [Q(k+1)R(k+1)]Q(k+1) = [Q(k+1)]T T (k)Q(k+1)
= [Q(0)Q(1) · · · Q(k+1)]T A[Q(0)Q(1) · · · Q(k+1)] .
Thus, the matrix T (k) is always similar to A, and thus they share the same eigenvalues.
One can prove that the limit
lim
k→∞T (k) = T ,
where T contains the n eigenvalues of A in its main diagonal. Based on the last assertion,
the QR iteration returns all the eigenvalues of A on the main diagonal of T . The algorithm
of the basic QR iteration is presented in Algorithm 49.
Algorithm 49 Basic QR iteration
Set a tolerance TOL for the accuracy
Set the maximum number of iterations MAXIT
Initialize the matrices Q(0) = I, T (0) = A and set k = 0
Set Error = TOL + 1
while Error > TOL and k < MAXIT do
Compute the QR decomposition Q(k+1)R(k+1) = T (k)
Compute the new T (k+1) = R(k+1)Q(k+1)
Compute Error = ∥diag(T (k+1)) −diag(T (k))∥
Increase the counter k = k + 1
end while
Return the approximate eigenvalues diag(T (k+1))
For the implementation of the basic QR iteration algorithm 49 we will use the QR
factorization of Python as it was described in Section 10.4.4.
1
def basicQRiteration(A, tol = 1.e-6, maxit = 100):
2
# initialize the parameters
3
iteration = 0
4
error = tol+1.0
5
T = A.copy()
6
#set first approximation of eigenvalues
7
eigs = np.diag(T)
8
while (error > tol and iteration < maxit):
9
#extract the diagonal entries of T
10
eig0=eigs
11
Q, R = npl.qr(T)
12
T = np.dot(R,Q)
13
#extract the new diagonal entries
14
eigs = np.diag(T)
15
error = npl.norm(eigs-eig0)
16
iteration = iteration + 1
17
print('number of iterations required = ',iteration)

Numerical Approximation of Eigenvalues and Eigenvectors
479
18
# return eigenvalue and corresponding eigenvector
19
return eigs
In the implementation of the basic QR iteration in the function basicQRiteration after
computing the array T, the code returns the approximate eigenvalues in the vector eigs.
For example, in the case of the matrix
A =


−2
−4
2
−2
1
2
4
2
5

.
with spectrum σ(A) = {−5, 3, 6} we get
1
A = np.array([[-2.,-4.,2.],[-2.,1.,2.],[4.,2.,5.]])
2
eigs = basicQRiteration(A, tol = 1.e-6, maxit = 100)
3
print(eigs)
number of iterations required =
89
[ 5.99999972 -4.99999972
3.
]
It is worth mentioning that the basic QR iteration will not order the eigenvalues but they
appear in a rather arbitrary order. The justification of this simple method along with more
sophisticated methods can be found in the references at the end of this chapter.
12.2.5
Application in computer networks
In this section we present the idea behind a very successful algorithm used by Google Search
to rank webpages based on the likelihood to be useful to the user. This algorithm is called
PageRank, and it was named after the term “webpage” and the co-founder of Google, Larry
Page. Assume that there is an internet surfer who has submitted a search query to a search
engine. The search engine identifies and gathers information of all possible webpages that
contain the keywords of the search. The question we will discuss below is the following: How
can we order the search results to present first the most relevant webpages? For example,
when I searched on Google for the phrase “numerical analysis” I got 523,000,000 results as
one can see in Figure 12.2. How a search engine can decide which one is the most useful
for me and present it first? The answer to this question is to transform the problem in
an eigenvalue problem and compute the eigenvector of the dominant eigenvalue. The idea
of transforming ranking problems into eigenvalue problems goes back to the work [102].
Many works followed until 1996 when Larry Page and Sergey Brin developed the PageRank
algorithm as a new kind of search engine, [17].
FIGURE 12.2
Google search.

480
Eigenvalue Problems
FIGURE 12.3
Connectivity graph of webpages and their links.
TABLE 12.1
Number of departing links per node
i
1
2
3
4
5
6
7
8
9
10
di
3
2
3
2
4
2
2
2
2
3
For the sake of simplicity assume that the search identifies 10 webpages with the term
‘numerical analysis’. Using these 10 webpages we create a directed graph. The 10 nodes of
this graph represent the webpages and the directed edges of the graph the links between
them. This graph is shown in Figure 12.3. In this way we can refer to the webpages with
the numbers {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}, and the problem has been transformed into ordering
this set based on the importance of the website.
In order to define the importance of the j-th webpage we assume that the i-th node
has di departing links to other nodes. Table 12.1 shows the number of links departing from
node i. Naturally, the importance of the j-th node must depend on the links it receives from
other nodes and also on the importance of these nodes. Suppose that the links between the
nodes are all equally important. We define the importance of a webpage to be the number
rj =
X
i→j
ri
di
,
(12.5)
where i →j means that the sum is over the nodes i that have a departing link to the j-th
node, ri is the importance of the i-th node, and di is the number of links departing from
the i-th node. This number is also called the score of the j-th node. For example, the 4th
node in the graph of Figure 12.3 receives links from the nodes 1, 2, 3, 5. Then its score is
r4 = r1
d1
+ r2
d2
+ r3
d3
+ r5
d5
.

Numerical Approximation of Eigenvalues and Eigenvectors
481
Using the formula (12.5) for the scores of all the nodes i = 1, 2, . . . , 10, we obtain 10
equations with 10 unknowns:
r1 = r5
4
r6 = r4
2 + r5
4 + r8
2
r2 = r1
3 + r3
3
r7 = r3
3 + r6
2 + r10
3
r3 = r2
2
r8 = r7
2 + r9
2 + r10
3
r4 = r1
3 + r2
2 + r3
3 + r5
4
r9 = r5
4 + r8
2 + r10
3
r5 = r1
3 + r4
2 + r6
2 + r9
2
r10 = r7
2
If we denote by r the vector with entries ri, then the previous linear system can be written
as
r = Gr
(12.6)
where
G =
















0
0
0
0
1/4
0
0
0
0
0
1/3
0
1/3
0
0
0
0
0
0
0
0
1/2
0
0
0
0
0
0
0
0
1/3
1/2
1/3
0
1/4
0
0
0
0
0
1/3
0
0
1/2
0
1/2
0
0
1/2
0
0
0
0
1/2
1/4
0
0
1/2
0
0
0
0
1/3
0
0
1/2
0
0
0
1/3
0
0
0
0
0
0
1/2
0
1/2
1/3
0
0
0
0
1/4
0
0
1/2
0
1/3
0
0
0
0
0
0
1/2
0
0
0
















.
In realistic situations this matrix can contain billions of entries and it might not be even
possible to be stored. Solving a linear system such as (12.6) using the methods of Chapter 9,
it will not be efficient. On the other hand, G has some nice properties. If we see the system
(12.6) as an eigensystem with λ1 = 1 an eigenvalue of G with corresponding eigenvector r,
then we could use the power method of Section 12.2.1. First we note that the connectivity
graph such as the graph in Figure 12.3 is a Markov chain with transition matrix G. More-
over, the sum of the entries of each column of G equals 1. Such a matrix is called stochastic
or column stochastic. The following lemma states that the spectral radius of G is σ(G) = 1.
Lemma 12.2. The maximum in magnitude eigenvalue of a stochastic matrix G is the
eigenvalue λ1 = 1.
Proof. Let λ be an eigenvalue of G with corresponding eigenvector x. Then, Gx = λx. Since
G is a stochastic matrix then ∥G∥1 = 1. On the other hand, ∥Gx∥1 = ∥λx∥1 = |λ|∥x∥1,
which gives
|λ| = ∥Gx∥1
∥x∥1
≤∥G∥1∥x∥1
∥x∥1
= ∥G∥1 = 1 .
Thus, any eigenvalue of G has magnitude less than or equal to 1. Also the eigenvalue
λ1 = 1 is an eigenvalue of G. To see this first observe that GT has the eigenvalue λ1 = 1
with corresponding eigenvector the vector (1, 1, . . . , 1)T . From Section 12.1.1 we know that
G and GT share the same eigenvalues, and thus λ1 is also an eigenvalue of G. We conclude
that λ1 is the eigenvalue with maximum magnitude since all others have |λ| ≤1.
The last question is if the eigenvalue λ1 has multiplicity 1, that is λ1 > |λ| for all
λ ∈σ(G) with λ ̸= λ1. The answer is given by Perron-Frobenius theorem. Its proof goes
beyond the scope of this book, and we just mention the main result of this theorem which
is the following:

482
Eigenvalue Problems
Theorem 12.3 (Perron-Frobenius). If G is a positive n × n matrix, then |λ| < ρ(G) for
any eigenvalue λ with λ ̸= ρ(G).
Now that we know that λ1 = 1 is a simple eigenvalue of G and all the rest are strictly
less than 1 in magnitude, we can use the Algorithm 48 of the power method from Section
12.2.1. This method relies only on matrix vector multiplication, and thus it is very efficient
for the computation of the eigenvector r. Recall, that the eigenvector contains the scores of
the webpages.
Using the code of Section 12.2.1 we compute the following vector r which we normalize
so as the sum of its entries to be 1 as its entry is a probability.
1
A = np.array([[0,0,0,0,1/4,0,0,0,0,0],
2
[1/3,0,1/3,0,0,0,0,0,0,0],
3
[0,1/2,0,0,0,0,0,0,0,0],
4
[1/3,1/2,1/3,0,1/4,0,0,0,0,0],
5
[1/3,0,0,1/2,0,1/2,0,0,1/2,0],
6
[0,0,0,1/2,1/4,0,0,1/2,0,0],
7
[0,0,1/3,0,0,1/2,0,0,0,1/3],
8
[0,0,0,0,0,0,1/2,0,1/2,1/3],
9
[0,0,0,0,1/4,0,0,1/2,0,1/3],
10
[0,0,0,0,0,0,1/2,0,0,0]] )
11
x0 = np.ones(10)/10.0
12
lambda1,u1 = powermethod(A,x0, tol=1.e-10, maxit=1000)
13
r1 = u1/npl.norm(u1,1)
14
print(r1)
number of iterations required =
52
[0.05417957 0.02167183 0.01083591 0.08668731 0.21671827 0.16821465
0.10526316 0.14138287 0.14241486 0.05263158]
Based on the principal eigenvector r, the webpage with the highest score is the one cor-
responding to node 5 of the graph. Its score is 0.21671827. This webpage is more likely
to be useful to the user, and it will appear on the top of the search results. Based on
the output of the PageRank algorithm, the webpages will appear in the following order
{5, 6, 9, 8, 7, 4, 1, 10, 2, 3}. This is the main idea behind an algorithm that we use almost
every day.
12.3
Further Reading
Most classical books of numerical analysis such as [18, 22, 108, 115, 90, 100] dedicate part of
their exposition to eigenvalue problems. Specialized books to linear algebra problems such
as [29, 135, 48, 105] contain extensive analysis of eigenvalue problems. For more information
on the Jordan normal form, we refer to the books [128, 67, 103] and the references therein.
Some specialized books dedicated only to the numerical eigenvalue problem include the
books [113, 80, 97, 140]. A simple introduction to the PageRank algorithm can be found
in [105] and [115] while more information can be found in the review article [63], and the
references therein.

Chapter Highlights
 The matrices A and AT have the same eigenvalues.
 Similar matrices share the same eigenvalues.
 If a matrix has an eigenvalue with geometric multiplicity less than algebraic
multiplicity, then it is called defective.
 If each eigenvalue of a matrix has geometric multiplicity equal to algebraic
multiplicity, then the matrix is called nondefective.
 A nondefective matrix A with n linearly independent eigenvectors is similar to
a diagonal matrix with diagonal entries the eigenvalues of A.
 The Jordan normal form of a matrix A is an upper-triangular matrix J with
diagonal elements all the eigenvalues of the matrix A. The matrix J is similar
to A. If A is nondefective, then J is diagonal.
 Real, symmetric matrices have real eigenvalues and orthogonal eigenvectors.
 The eigenvalues of a matrix A are contained in the union of the Gerschgorin
disks of A.
 The i-th Gerschgorin disk of A has center at aii and radius
ri =
n
X
j=1,j̸=i
|aij| .
 The power iteration is used for the approximation of the eigenvalue of A with
the maximum magnitude and its corresponding eigenvector.
 The convergence of the power iteration depends on the ratio λ2/λ1 < 1. If
λ2 ≈λ1, then the convergence is very slow. On the other hand, if λ2 ≪λ1, then
the convergence will be fast.
 For the approximation of the eigenvalue with the minimum magnitude of A we
use the inverse power method, which approximates the maximum in magnitude
eigenvalue of A−1.
 Other eigenvalues of a matrix A can be computed with the shifted inverse
power method. This method relies on shifting the spectrum of A in such a way
that the desired eigenvalue becomes close to 0.
 The QR is a more sophisticated algorithm for the estimation of the eigenvalues
of a matrix A.
 The PageRank algorithm relies on the computation of the eigenvector of the
principal eigenvalue of a stochastic matrix.
483

Exercises
1. Show that for any 2 × 2 matrix A the characteristic polynomial is
ϕ(λ) = λ2 −trace(A)λ + det(A) .
2. For any n × m matrix A show that T = 1
2(A + AT ) is symmetric.
3. Consider the n × n tridiagonal matrix
A = tridiag(b, a, c) =








a
c
b
a
c
b
a
...
...
...
c
b
a








,
with bc > 0.
(a) Prove that A has eigenvalues
λk = a + 2
√
bc cos
πk
n + 1,
k = 1, 2, . . . , n .
(b) Why A is diagonalizable?
(c) Show that if a = 2 and b = c = −1, then λk = 4 sin2(πk/2(n + 1)).
(d) Use this fact to prove that A is positive definite.
4. Consider the matrix
A =
1
1
1
0

.
(a) Compute the eigenvalues and the corresponding eigenvectors of the matrix A.
(b) Find the sequence of numbers {xn} with x0 = 0 and x1 = 1 and the rest of the
terms are defined recursively by the formula
x(n) = Ax(n−1),
for
n = 1, 2, . . . ,
where x(n) = (xn, xn−1)T .
(c) Determine a recursive formula F(xn, xn−1, xn−2) = 0 for the terms of this sequence.
(d) Compute the ratio xn/xn−1 for n = 1, 2, . . . , 106. What do you observe?
(e) If xn = 832, 040 find the term xn+1 without using the term xn−1.
[Hint: The sequence xn of this problem is known to as the Fibonacci sequence and the
golden ratio is (1 +
√
5)/2.]
5. Let x = (x, y)T . Consider the line described by the equation
Q : 5x2 + 8xy + 5y2 = 1 .
(a) Identify the shape of the line Q
(b) Find a symmetric matrix A such that Q(x) = xT Ax.
484

(c) Find the eigenvalues and eigenvectors of A, and show that A is diagonalizable, i.e.
write
A = P JP T ,
where P has the eigenvectors of A as columns and J is diagonal with the eigenvalues
in its main diagonal.
(d) Use the equation xT Ax = 1 and the previous question to write the equation of the
line Q in its canonical form.
(e) Use the power method and its modifications for the computation of the eigenvalues
and eigenvectors of A, and validate your theoretical calculations.
6. Consider the matrix
A =


3
−2
−1
1
−2
1
1
−1
0

.
(a) Find analytically all the eigenvalues and eigenvectors of A.
(b) Confirm your results using the function eig of the module numpy.linalg.
(c) Estimate the principal eigenvalue of the matrix A using the power method using
x0 = (−1, 1, 1)T . Explain why the Python code provided in the book fails when
x0 = (1, 1, 1)T .
(d) Explain why we cannot use the inverse power method for the computation of the
minimum in magnitude eigenvalue of A.
(e) Use the shifted inverse power method for the approximation of the minimum in
magnitude eigenvalue of A.
(f) Compare the solutions of the QR iteration with the previous acquired results.
7. Consider the generalized eigenvalue problem
Cx = λBx ,
(12.7)
where C and B are symmetric n × n matrices, while B is also positive definite.
(a) Using the Cholesky decomposition of B transform (12.7) into an equation of the
form
Au = λu .
This is called the standard form of an eigenvalue problem.
(b) Consider the matrices
C =


4
−1
0
−1
4
−1
0
−1
4


and
B =


2
−1
0
−1
2
−1
0
−1
1

.
Find the standard form of the generalized eigenvalue problem (12.7).
(c) Use the power method and its variants to approximate all the eigenvalues λ of
(12.7).
(d) Use the QR iteration to approximate all the eigenvalues λ of (12.7).
(e) Compare your results with the function eig of the module numpy.linalg.
[Hint: For more information, we refer to [99] and [78]]
485

8. The quotient
xT Ax
xT x
,
is called the Rayleigh quotient.
(a) Show that if u is an eigenvector of A, then the corresponding eigenvalue λ of A is
λ = uT Au
uT u
.
(b) If all the eigenvalues of A are positive, then what can you say about the matrix A?
(c) Modify the power method accordingly so as to use the Rayleigh quotient formula
for the computation of the principal eigenvalue.
(d) Modify the inverse power iteration in the same way for the computation of the
eigenvalue with the minimum magnitude.
(e) Test your codes with the matrix
A =


−2
−4
2
−2
1
2
4
2
5

.
9. Consider a 3 × 3 matrix A with eigenvalues
|λ1| > |λ2| > |λ3| .
(a) Show that if we apply the power method with an initial condition
x(0) = c2u2 + c3u3 ,
then we obtain an approximation to the eigenvalue λ2.
(b) Show that for any vector in the form x = a1u1 + a2u2 + a3u3, a1, a2, a3 ∈R, the
vector
x(0) = (A −λ1I)x ,
is of the form x(0) = c2u2 + c3u3.
(c) Show that the power method with initial condition
x(0) = (A −λ2I)(A −λ1I)x ,
will approximate the eigenvalue λ3.
(d) Write a Python code to implement this technique. Use your code to approximate
all the eigenvalues of the matrix
A =


−2
−4
2
−2
1
2
4
2
5

.
[This technique is known as annihilation technique]
486

A
Computing Jordan Normal Forms
In this Appendix, we review briefly a very important matrix factorization known to as the
Jordan normal form or Jordan canonical form, a subject that is not covered usually in basic
linear algebra courses. As we have already seen, this plays a significant role in some of the
proofs of convergence in linear algebra, and it is also a very important tool for the study
of eigenvalues. We will see how we can write any matrix A as a product P JP −1, where J
is a sparse, upper-diagonal matrix associated with the eigenvalues of A, and P invertible
matrix associated with the eigenvectors of A. First we consider the easiest case where J is
a diagonal matrix. For more information and a more in-depth presentation of the subject,
we refer to [67].
Generalized Eigenvectors and the Jordan Normal Form
Let A be an n×n (complex) matrix and λ ∈σ(A) an eigenvalue with algebraic multiplicity
τ. Let d = dim ker(A −λI) be the geometric multiplicity of λ (the number of linearly
independent eigenvectors), with d < τ. In such case A is called defective. (Recall that the
space ker(A −λI) = Vλ is the kernel (or null) of A −λI and contains vectors u such that
(A −λI)u = 0). This means that A is a defective matrix (not of simple structure), and
therefore it is not diagonalizable using a similarity transformation. This is because there
are not enough linearly independent eigenvectors for the construction of the matrix P . For
each eigenvalue λ with d < τ, the d linearly independent eigenvectors can be completed
with (τ −d) generalized eigenvectors to form a set of τ linearly independent eigenvectors
(simple and generalized together).
A nonzero vector uk is a generalized eigenvector of A corresponding to the eigenvalue λ
if
(A −λI)kuk = 0
for some k ∈N ,
which is equivalent to say that uk ∈ker(A −λI)k. A generalized eigenvector uk is called
of rank k if
(A −λI)kuk = 0 and (A −λI)k−1uk ̸= 0 .
According to this definition, the (classical) eigenvectors of A are generalized eigenvector of
rank 1.
If uk is a rank k generalized eigenvector of A with respect to the eigenvalue λ then
(A −λI)uk = uk−1 ,
where uk−1 is a rank (k −1) generalized eigenvector of A. Therefore, for the generalized
eigenvector uk there is a chain
{uk, uk−1, . . . , u1} ,
DOI: 10.1201/9781003287292-A
487

488
Computation of Jordan Normal Form
of generalized eigenvectors associated with the eigenvalue λ of rank k, k−1, . . . , 1 respectively
with
uk ,
uk−1 = (A −λI)uk ⇒Auk = λuk + uk−1 ,
uk−2 = (A −λI)2uk = (A −λI)uk−1 ⇒Auk−1 = λuk−1 + uk−2 ,
...
u1 = (A −λI)k−1uk = · · · = (A −λI)u1 = 0 ⇒Au1 = λu1 .
The number of these chains is defined by the geometric multiplicity d, while the maximal
possible length p is called the index of annihilation. These eigenvectors are also linearly
independent. This can be seen by taking a linear combination of these vectors with akuk +
ak−1uk−1 + · · · a1u1 = 0, and then substituting uk−1, . . . , u1 with the previous formulas
and multiplying with (A −λI)k−1. Since uk is a generalized eigenvector, then ak = 0. It is
noted that any chain of generalized eigenvectors is also called Jordan chain or string ending
at uk.
If {uk, uk−1, · · · , u1} is a chain of generalized eigenvectors corresponding to the eigen-
value λ, then as we have seen, we have
Auk = λuk + uk−1, Auk−1 = λuk−1 + uk−2 · · · Au1 = λu1 .
If P
is the matrix with columns the linear independent generalized eigenvectors
 u1
u2
· · ·
uk

then
A P = A
 u1
u2
· · ·
uk

=
 Au1
Au2
· · ·
Auk

=
 λu1
λu2 + u1
· · ·
λuk + uk−1

=
 u1
u2
· · ·
uk








λ
1
0
· · ·
0
0
λ
1
· · ·
0
...
...
0
0
0
· · ·
1
0
0
0
· · ·
λ







= P Jk .
The k × k matrix Jk is called Jordan block.
The trivial 1 × 1 Jordan block J1(λ) = (λ) implies that the main diagonal of a diagonal
matrix consists of Jordan blocks J1. Other examples of Jordan blocks are the following 2×2
and 3 × 3 Jordan blocks
J2(λ) =
λ
1
0
λ

and
J3(λ) =


λ
1
0
0
λ
1
0
0
λ

.
In general, if P is the n×n matrix with all the chains of generalized eigenvectors of matrix
A, then P is invertible (with linearly independent columns, the generalized eigenvectors).
Therefore, we can write A as A = P JP −1 where J is the so-called Jordan normal form of
A. Moreover, J is a block-diagonal matrix where each diagonal block is a Jordan block.
Computation of Jordan normal form
Let di = dim ker(A −λI)i and ri = rank(A −λI)i, i = 1, 2, · · · , then
di = n −ri .

Computation of Jordan Normal Form
489
It is now obvious tha:
 the number of simple eigenvectors is d1 = n −r1.
 the number of generalized eigenvectors of rank 2 is d2−d1 = (n−r2)−(n−r1) = r1−r2.
 the number of generalized eigenvectors of rank p is dp −dp−1 = rp−1 −rp.
We form the vector s with these numbers
s =
 n −r1
r1 −r2
· · ·
rp−1 −rp

,
known as the Segr´e characteristic. Using the Segr´e characteristic we construct a diagram that
reveals the Jordan blocks. This diagram is called the Ferrer diagram and can be constructed
using the following steps:
Step 1: In the first row we draw n −r1 asterisks ⋆to represent the generalized eigenvectors of
rank 1 (simple eigenvectors).
Step 2: In the second row we draw r1 −r2 ⋆to represent the generalized eigenvectors of rank
2.
Step 3: We continue until the p-th row where we draw rp−1 −rp ⋆corresponding to the gen-
eralized eigenvectors of rank p.
The number of the asterisks appearing in each column of this diagram shows the rank of
the corresponding Jordan blocks which we use to formulate the matrix J.
For example, consider a 10 × 10 matrix A with λ ∈σ(A), an eigenvalue of A with
r1 = 5, r2 = 3, r3 = 2, r4 = 1, r5 = 1 (where ri = rank(A −λI)i, i = 1, 2, . . . , 5). The
minimum number p ∈N such that rp = rp+1 is p = 4 is the index of annihilation. Consider
the differences n −r1 = 10 −5 = 5, r1 −r2 = 2, r2 −r3 = 1, r3 −r4 = 1. Then the
characteristic Segr´e is (5, 2, 1, 1). The Ferrer diagram is:
n −r1 = 5
−−
⋆
⋆
⋆
⋆
⋆
r1 −r2 = 2
−−
⋆
⋆
r2 −r3 = 1
−−
⋆
r3 −r4 = 1
−−
⋆
4
2
1
1
1
The numbers 4, 2, 1, 1, 1 are called the Weyr characteristics, and show the rank of the Jordan
blocks corresponding to the eigenvalue λ. We repeat the same procedure for each eigenvalue
λ, and we write the Jordan normal form using the computed Jordan blocks.

To compute the Jordan normal form of a matrix A we follow the steps:
1. Compute all the eigenvalues of matrix A
2. For each eigenvalue compute all the eigenvectors of rank 1
3. For each eigenvalue compute the Ferrer diagram
4. Construct the Jordan normal form

490
Computation of Jordan Normal Form
Examples
As a first example consider the matrix
A =


4
0
1
2
3
2
1
0
4

.
First we compute the eigenvalues by solving the characteristic equation det(A −λI) = 0.
The characteristic polynomial is
det(A −λI) =

4 −λ
0
1
2
3 −λ
2
1
0
4 −λ

= (3 −λ)2(5 −λ) .
The characteristic equation (3 −λ)2(5 −λ) = 0 has only two roots λ1 = 3 and λ2 = 5. For
λ1 = 3 we have τ1 = 2 and we compute two eigenvectors of rank 1 (since d1 = n −r1 =
3 −1 = 2)
u1 =
 0
1
0T
and
u2 =
 −1
0
1T .
Therefore, λ1 has the same algebraic and geometric multiplicity τ1 = d1 = 2. For λ2 we com-
pute only one eigenvector u3 =
 1
2
1T and so this eigenvalue has algebraic multiplicity
τ2 = 1 and geometric multiplicity d2 = 1. Since all eigenvalues have the same algebraic and
geometric multiplicity we conclude that the matrix A is diagonalizable. Although we can
formulate directly the Jordan normal form by using the eigenvalues for the main diagonal,
we continue using our methodology.
Computing the matrices (A −λiI)2 for i = 1, 2 we observe that they have ranks r2 =
r1 and therefore r1 −r2 = 0 in both cases. This means that there are no generalized
eigenvectors. So the Ferrer diagram consists of only one row with the simple eigenvector (of
rank 1). For example, for λ1 = 3 we have
n −r1 = 2
−−
⋆
⋆
r1 −r2 = 0
−−
1
1
which means that there will be two Jordan blocks of dimension 1. More precisely the blocks
[3] and [3]. For λ2 = 5 again we have
n −r1 = 1
−−
⋆
r1 −r2 = 0
−−
1
which means that there will be one more Jordan block of dimension 1, that is [5]. Therefore,
the Jordan normal form in this case is
J =


3
0
0
0
3
0
0
0
5

.
Moreover, defining P to be the matrix with columns the eigenvectors of matrix A
P =


0
−1
1
1
0
2
0
1
1

,
then easily we can verify that A = P JP −1.

Computation of Jordan Normal Form
491
As another example we consider the problem of finding the Jordan normal form of the
matrix
A =


1
1
1
0
1
0
0
0
1

.
In order to find the eigenvalues we first compute the matrix
A −λI =


1 −λ
1
1
0
1 −λ
0
0
0
1 −λ

.
In this case, the matrix A has only one eigenvalue, λ = 1 with algebraic multiplicity τ = 3,
and obviously, because the last two rows for λ = 1 are zero, yields r1 = rank(A −I) = 1.
Thus, for λ = 1 the matrix A has d1 = n −r1 = 3 −1 = 2 eigenvectors of rank 1, namely
u1 =
 1
0
0T
and
u2 =
 0
1
−1T .
To find the generalized eigenvector in this case, the matrix (A −I)2 is not helpful since
it coincides with the 3 × 3 zero matrix. For this reason, we solve the system
(A −I)u3 = u1 ,
which gives u3 =
 0
0
1T . In this case, the transformation matrix P =
 u1
u2
u3

.
The Ferrer diagram is
n −r1 = 2
−−
⋆
⋆
r1 −r2 = 1
−−
⋆
2
1
which means that J consists of a 2 × 2 and 1 × 1 Jordan blocks. The Jordan normal form
is then
J =


1
1
0
0
1
0
0
0
1

.
Finally, we consider the problem of finding the Jordan normal form of the matrix
A =


−1
−1
0
0
−1
−2
0
0
−1

.
In this example there is only one eigenvalue λ = −1 (easy to see since matrix A is upper-
triangular). We observe that the matrix
A −λI = A + I =


0
−1
0
0
0
−2
0
0
0

,
has r1 = rank(A −λI) = 2. Thus, d1 = n −r1 = 3 −2 = 1 and there is only one
eigenvector, namely u1 =
 1
0
0T . Solving the system (A+I)u2 = u1 we compute only
one generalized eigenvector of rank 2, the eigenvector u2 =
 0
−1
0T , which implies
that d2 = 1. Similarly, the system (A + I)u3 = u2 leads to the generalized eigenvector of
rank 3, u3 =
 0
0
1/2T , and thus d3 = 1.

492
Computation of Jordan Normal Form
The Ferrer diagram in this case is
n −r1 = 1
−−
⋆
r1 −r2 = 1
−−
⋆
r2 −r3 = 1
−−
⋆
3
and therefore there is only one 3 × 3 Jordan block forming the Jordan normal form of A
J =


−1
1
0
0
−1
1
0
0
−1

.
Note that the previous methodology can be used even when there are complex eigenval-
ues. For more information, we refer to the books [128, 67, 103, 21, 139] and the references
therein.

Bibliography
[1] G. Akrivis and V. Dougalis. Introduction to numerical analysis. Cretan University
Press, 2004.
[2] W. Ames. Numerical methods for partial differential equations. Academic Press, New
York, 1977.
[3] T. Apostol. Calculus, Volume 1, One-variable calculus, with an introduction to linear
algebra, volume 1. Wiley, 1991.
[4] T. Apostol. Calculus, Volume 2, Multi-variable calculus and linear algebra with ap-
plications to differential equations and probability, volume 2. Wiley, 1991.
[5] I. Argyros, Y. Cho, and S. Hilout. Numerical methods for equations and its applica-
tions. CRC Press, Boca Raton, FL, 2012.
[6] I. Argyros and F. Szidarovszky. The theory and applications of iteration methods.
CRC Press, Boca Raton, FL, 2018.
[7] K. Atkinson. An introduction to numerical analysis. Wiley, New York, 2008.
[8] O. Axelsson. Iterative solution methods. Cambridge University Press, Cambridge,
1994.
[9] J. Barzilai and J. Borwein. Two-point step size gradient methods. IMA Journal of
Numerical Analysis, 8:141—148, 1988.
[10] G. Birkhoff. General mean value and remainder theorems with applications to me-
chanical differentiation and quadrature. Trans. Amer. Math. Soc., 7:107–136, 1906.
[11] G. Birkhoff and G.-C. Rota. Ordinary differential equations. John Wiley & Sons,
1978.
[12] ˚A. Bj¨orck. Numerical methods for least squares problems. SIAM, Philadelphia, 1996.
[13] S. Boyd and L. Vandenberghe. Convex optimization. Cambridge University Press,
Cambridge, 2004.
[14] H. Brass and K. Petras. Quadrature theory, The theory of numerical integration on a
compact interval. American Mathematical Society, Providence, Rhode Island, 2011.
[15] F. Brauer and C. Castillo-Chavez. Mathematical models for communicable diseases.
SIAM, Philadelphia, 2012.
[16] E. Bressert. SciPy and NumPy. O’Reilly, 1st edition, 2013.
[17] S. Brin and L. Page. The anatomy of a large-scale hypertextual web search engine.
Computer networks and ISDN systems, 30:107–117, 1998.
[18] R. Burden and J. Faires. Numerical analysis. Brooks/Cole, Cengage Learning, 2011.
493

494
Bibliography
[19] J. Butcher. Numerical methods for ordinary differential equations. Johm Wiley &
Sons, UK, 2016.
[20] F. Chaitin-Chatelin and V. Frayss´e. Lectures on finite precision computations. SIAM,
1996.
[21] C.-T. Chen. Linear system theory and design. Oxford university press, New York,
Oxford, 1999.
[22] E. Cheney and D. Kincaid. Numerical mathematics and computing. Brooks/Cole:
Cengage Learning, 2013.
[23] E. Chong and S. ˙Zak. An introduction to optimization. John Wiley & Sons, Inc.,
Hoboken, New Jersey, 2013.
[24] P. Ciarlet.
Introduction to numerical linear algebra and optimisation.
Cambridge
University Press, Cambridge, (English translation) 1989.
[25] S. Conte and C. De Boor. Elementary numerical analysis: An algorithmic approach.
SIAM, Philadelphia, 2018.
[26] G. Dahlquist and ˚A. Bj¨orck. Numerical methods. Dover Publications, Inc. New York,
NY, USA, 1974.
[27] G. Dahlquist and ˚A. Bj¨orck.
Numerical methods in scientific computing.
SIAM,
Philadelphia, 2008.
[28] Y.-H. Dai and Y. Yuan. A nonlinear conjugate gradient method with a strong global
convergence property. SIAM J. Optim., 10:177–182, 1999.
[29] B.N. Datta. Numerical linear algebra and applications. SIAM, Philadelphia, 2010.
[30] P. Davis and P. Rabinowitz. Methods of numerical integration. Academic Press Inc.,
San Diego, 1984.
[31] C. De Boor. A practical guide to splines. Springer-Verlag New York, 1978.
[32] J. Demmel. Applied numerical linear algebra. SIAM, Philadelphia, 1997.
[33] J. Dennis and J. Mor´e. Quasi-newton methods, motivation and theory. SIAM review,
19:46–89, 1977.
[34] J. Dennis and R. Schnabel. Numerical methods for unconstrained optimization and
nonlinear equations. SIAM, Philadelphia, 1996.
[35] J. Dongarra, C. Moler, J. Bunch, and G. Stewart. LINPACK users’ guide. SIAM,
Philadelphia, 1979.
[36] J. Dormand. Numerical methods for differential equations: a computational approach.
CRC Press, Boca Raton, FL, 2018.
[37] V. Dougalis, D. Noutsos, and A. Hadjidimos. Numerical linear algebra. University of
Thessaly, 2012.
[38] G. Evans. Practical numerical integration. Wiley, New York, 1993.
[39] K. Feng and M. Qin.
Symplectic geometric algorithms for Hamiltonian systems.
Springer-Verlag Berlin Heidelberg, 2010.

Bibliography
495
[40] R. Feynman. The best short works of Richard P. Feynman. In J. Robbins, editor,
The pleasure of finding things out. Perseus books, 1999.
[41] R. Fletcher and C. Reeves.
Function minimization by conjugate gradients.
The
Computer Journal, 7:149–154, 1964.
[42] G. Forsythe. Pitfalls in computation, or why a math book isn’t enough. The American
Mathematical Monthly, 77:931–956, 1970.
[43] G. Forsythe, M. Malcolm, and C. Moler. Computer methods for mathematical com-
putations. Prentice-Hall, Inc. Englewood Cliffs, N.J., 1977.
[44] W. Gear. Numerical initial value problems in ordinary differential equations. Prentice-
Hall, Englewood Cliffs, N.J., 1971.
[45] A. George and J. Liu. Computer solution of large sparse positive definite systems.
Prentice-Hall Englewood Cliffs, New Jersey, 1981.
[46] D. Goldberg. What every computer scientist should know about floating-point arith-
metic. ACM computing surveys, 23:5–48, 1991.
[47] G. Golub and J. Ortega. Scientific computing: an introduction with parallel computing.
Academic Press Inc., San Diego, 1993.
[48] G. Golub and C. Van Loan. Matrix computations. Johns Hopkins University Press,
2012.
[49] I. Goodfellow, Y. Bengio, and A. Courville. Deep learning. MIT press, Cambridge,
2016.
[50] Steven I Gordon and Brian Guilfoos. Introduction to Modeling and Simulation with
MATLAB® and Python. CRC Press, Boca Raton, FL, 2017.
[51] D. Griffiths and D. Higham. Numerical methods for ordinary differential equations.
Springer-Verlag London, 2010.
[52] C. Groetsch. Lanczo’s generalized derivative. The American Mathematical Monthly,
105:320–326, 1998.
[53] W. Hackbusch.
Iterative solution of large sparse systems of equations.
Springer
Switzerland, 2016.
[54] E. Hairer, C. Lubich, and G. Wanner. Geometric numerical integration: Structure-
preserving algorithms for ordinary differential equations. Springer-Verlag Berlin Hei-
delberg, 2006.
[55] E. Hairer, S. Nørsett, and G. Wanner. Solving ordinary differential equations I: Non-
stiff problems. Springer-Verlag Berlin Heidelberg, 1993.
[56] E. Hairer and G. Wanner.
Solving ordinary differential equations II: Stiff and
differential-algebraic problems. Springer-Verlag Berlin Heidelberg, 1996.
[57] G. H¨ammerlin and K.-H. Hoffmann. Numerical mathematics. Springer-Verlag New
York, 2012.
[58] C. Harris, J. Millman, S. van der Walt, R. Gommers, et al. Array programming with
NumPy. Nature, 585:357–362, 2020.

496
Bibliography
[59] S. Haykin. Neural networks and learning machines. Pearson, 2009.
[60] M. Hestenes and E. Stiefel. Methods of conjugate gradients for solving linear systems.
Journal of research of the National Bureau of Standards, 49:409–436, 1952.
[61] H. Hethcote. The mathematics of infectious diseases. SIAM review, 42:599–653, 2000.
[62] C. Higham and D. Higham. Deep learning: An introduction for applied mathemati-
cians. SIAM Review, 61:860–891, 2019.
[63] D. Higham and A. Taylor. The sleekest link algorithm. Mathematics Today, 39:192–
197, 2003.
[64] N. Higham.
Accuracy and stability of numerical algorithms.
SIAM, Philadelphia,
2002.
[65] N. Higham, editor. Princeton companion to applied mathematics. Princeton University
Press, 2015.
[66] F. Hildebrand.
Introduction to numerical analysis.
Dover Publications, Inc. New
York, USA, 1987.
[67] R. Horn and C. Johnson. Matrix analysis. Cambridge University Press, 2012.
[68] A. Householder. Unitary triangularization of a nonsymmetric matrix. Journal of the
ACM, 5:339–342, 1958.
[69] A. Householder. The theory of matrices in numerical analysis. Dover Publications,
Inc. New York, USA, 2013.
[70] E. Isaacson and H.B. Keller. Analysis of numerical methods. Dover Publications, Inc.
New York, USA, 1994.
[71] A. Iserles. A first course in the numerical analysis of differential equations. Cambridge
University Press, Cambridge, 2008.
[72] R. Johansson. Numerical Python: Scientific Computing and Data Science Applications
with Numpy, SciPy and Matplotlib. Apress, Berkeley, CA, 2019.
[73] D. Kahaner, C. Moler, and S. Nash. Numerical methods and software. Prentice-Hall
Englewood Cliffs, New Jersey, 1989.
[74] H. Karimi, J. Nutini, and M. Schmidt.
Linear convergence of gradient and
proximal-gradient methods under the Polyak- Lojasiewicz condition. In P. Frasconi,
N. Landwehr, G. Manco, and J. Vreeken, editors, Machine Learning and Knowledge
Discovery in Databases, pages 795–811. Springer International Publishing, 2016.
[75] C. Kelley. Iterative method for linear and nonlinear equations. SIAM, Philadelphia,
1995.
[76] D. Kincaid and E. Cheney. Numerical analysis: mathematics of scientific computing.
American Mathematical Society, Providence, Rhode Island, 2009.
[77] D. Kincaid, J. Respess, D. Young, and R. Grimes.
Algorithm 586: Itpack 2c: A
fortran package for solving large sparse linear systems by adaptive accelerated iterative
methods. ACM Transactions on Mathematical Software (TOMS), 8:302–322, 1982.

Bibliography
497
[78] J. Kiusalaas. Numerical methods in engineering with Python 3. Cambridge University
Press, 2013.
[79] Q. Kong, T. Siauw, and A. Bayen. Python programming and numerical methods: A
guide for engineers and scientists. Elsevier Inc., 2020.
[80] D. Kressner.
Numerical methods for general and structured eigenvalue problems.
Springer-Verlag Berlin Heidelberg, 2005.
[81] E. Kreyszig. Introductory functional analysis with applications. Wiley, New York,
1978.
[82] H. Langtangen and S. Linge. Finite difference compute with PDEs: A modern software
approach. Springer Nature, 2010.
[83] B. Leimkuhler and S. Reich. Simulating Hamiltonian dynamics. Cambridge University
Press, 2004.
[84] M. Lutz. Learning Python. O’Reilly, 5th edition, 2013.
[85] J. Lyness and C. Moler. Numerical differentiation of analytic functions. SIAM Journal
on Numerical Analysis, 4:202–210, 1967.
[86] S. Marsland. Machine learning: An algorithmic perspective. Chapman and Hall/CRC,
New York, 2009.
[87] E. Matthes. Python crash course: A hands-on, project-based introduction to program-
ming. No Starch Press, US, 2nd edition, 2019.
[88] W. McKinney. Python for data analysis: Data wrangling with Pandas, NumPy, and
IPython. O’Reilly, 2nd edition, 2017.
[89] C. Moler. Experiments with MATLAB. Mathworks, 2001.
[90] C. Moler. Numerical computing with MATLAB. SIAM, 2004.
[91] J. Mor´e, B. Garbow, and K. Hillstrom. User Guide for MINPACK-1. Technical Report
III, Argonne, 1980.
[92] K. Murphy. Probabilistic Machine Learning: An introduction. MIT Press, 2022.
[93] J. Nocedal and S. Wright. Numerical optimization. Springer-Verlag New York, 2006.
[94] J. Ortega. Numerical analysis: a second course. SIAM, Philadelphia, 1990.
[95] J. Ortega and W. Rheinboldt. Iterative solution of nonlinear equations in several
variables. SIAM, Philadelphia, 2000.
[96] A. Ostrowski. Solution of Equations and Systems of Equations: Pure and Applied
Mathematics: A Series of Monographs and Textbooks, Vol. 9. Academic Press Inc.,
New York, 2016.
[97] B. Parlett. The symmetric eigenvalue problem. SIAM, Philadelphia, 1998.
[98] A. Peressini, F. Sullivan, and J. Uhl Jr. The mathematics of nonlinear programming.
Springer-Verlag, 1988.
[99] G. Peters and J. Wilkinson.
ax = λbx and the generalized eigenproblem.
SIAM
Journal on Numerical Analysis, 7:479–492, 1970.

498
Bibliography
[100] G. Phillips and P. Taylor. Theory and applications of numerical analysis. Academic
press, London, 1996.
[101] R. Piessens, E. de Doncker-Kapenga, C. ¨Uberhuber, and D. Kahaner.
Quadpack,
A subroutine package for automatic integration. Springer-Verlag Berlin Heidelberg,
1983.
[102] G. Pinski and F. Narin. Citation influence for journal aggregates of scientific publi-
cations: Theory, with application to the literature of physics. Information Processing
& Management, 12:297–312, 1976.
[103] R. Piziak and P. Odell.
Matrix theory: from generalized inverses to Jordan form.
Chapman and Hall/CRC, 2007.
[104] E. Polak and G. Ribiere. Note sur la convergence de m´ethodes de directions con-
jugu´ees. ESAIM: Mathematical Modelling and Numerical Analysis, 3:35–43, 1969.
[105] D. Poole. Linear algebra: A modern introduction. Cengage Learning, 4th edition,
2015.
[106] G. Poore. PythonTeX: reproducible documents with LaTeX, Python, and more. Com-
putational Science & Discovery, 8:014010, 2015.
[107] M. Powell. Approximation theory and methods. Cambridge University Press, 1981.
[108] A. Quarteroni, R. Sacco, and F. Saleri.
Numerical mathematics.
Springer-Verlag
Berlin Heidelberg, 2007.
[109] A. Ralston and P. Rabinowitz. A first course in numerical analysis. Dover Publica-
tions, Inc. New York, USA, 2001.
[110] F. Rosenblatt. Principles of neurodynamics; perecptrons and the theory of brain mech-
anisms. Spartan books, Washington D.C., 1962.
[111] C. Runge. ¨Uber empirische funktionen und die interpolation zwischen ¨aquidistanten
ordinaten. Zeitschrift f¨ur Mathematik und Physik, 46:224–243, 1901.
[112] Y. Saad. Iterative methods for sparse linear systems. SIAM, Philadelphia, 2003.
[113] Y. Saad. Numerical methods for large eigenvalue problems. SIAM, Philadelphia, 2011.
[114] J.M. Sanz-Serna and M.P. Calvo. Numerical Hamiltonian problems. Chapman and
Hall/CRC Press, London, 1994.
[115] T. Sauer. Numerical analysis. Pearson, 2018.
[116] M. Schatzman. Numerical analysis: a mathematical introduction. Oxford University
Press, 2002.
[117] M. Schultz. Spline analysis. Prentice-Hall Englewood Cliffs, New Jersey, 1973.
[118] L. Schumaker. Spline functions: basic theory. Cambridge University Press, Cambridge,
2007.
[119] L. Schumaker. Spline functions: Computational methods. SIAM, Philadelphia, 2015.
[120] R. Scott. Numerical Analysis. Princeton University Press, 2011.

Bibliography
499
[121] L. Shampine. Numerical solution of ordinary differential equations. CRC Press, Boca
Raton, FL, 1994.
[122] M. Spivak. Caluclus, volume 3rd. Cambridge University Press, 2006.
[123] W. Squire and G. Trapp.
Using complex variables to estimate derivatives of real
functions. SIAM review, 40:110–112, 1998.
[124] G. Stewart. Afternotes on numerical analysis. SIAM, Philadelphia, 1996.
[125] G. Stewart. Afternotes goes to graduate school, lectures on advanced numerical anal-
ysis. SIAM, Philadelphia, 1998.
[126] J. Stewart. Calculus. Cengage Learning, Inc, 2011.
[127] J. Stoer and R. Bulirsch. Introduction to numerical analysis. Springer-Verlag New
York, 2013.
[128] G. Strang. Linear algebra and its applications. Thomson Brooks/Cole, 2006.
[129] G. Strang. Introduction to linear algebra. Wellesley-Cambridge Press, 4th edition,
2009.
[130] G. Strang. Linear algebra and learning from data. Wellesley-Cambridge Press, 1st
edition, 2019.
[131] A. Stroud and D. Secrest. Gaussian quadrature formulas. Prentice-Hall, Englewood
Cliffs, N.J., 1966.
[132] E. S¨uli and D. Mayers. An introduction to numerical analysis. Cambridge, UK, 2003.
[133] T. Tao. Analysis I. Springer, Singapore, 2016.
[134] T. Tao. Analysis II. Springer, Singapore, 2016.
[135] N. Trefethen and D. III Bau. Numerical linear algebra. SIAM, Philadelphia, 1997.
[136] J. VanderPlas. Python data science handbook: Essential tools for working with data.
O’Reilly, 1st edition, 2016.
[137] R. Varga. Matrix iterative analysis. Springer-Verlag Berlin Heidelberg, 2000.
[138] P. Virtanen, R. Gommers, T. Oliphant, et al. SciPy 1.0: Fundamental Algorithms for
Scientific Computing in Python. Nature Methods, 17:261–272, 2020.
[139] S. Weintraub. Jordan canonical form: theory and practice. Morgan & Claypool Pub-
lishers, 2009.
[140] J. Wilkinson. The algebraic eigenvalue problem. Clarendon Press, Oxford, 1965.
[141] J. Wilkinson. Rounding errors in algebraic processes. Dover Publications, Inc. New
York, USA, 1994.
[142] D. Young. Iterative solution of large linear systems. Academic Press, New York, 1971.

Taylor & Francis 
Taylor & Francis Group 
http://taylorandfrancis.com 

Index
A-stable methods, 295
activation function, 448
ReLU function, 448
sigmoid function, 448
step function, 448
Adam method, 454
Adams-Bashforth-Moulton quadrature, 271
Aitken extrapolation, 157
Aitken’s process, 157
algebraic multiplicity, 467
algorithm, 94
LU factorization, 327
Archimedes, 98
backward substitution, 375
band Cholesky, 375
bisection method, 128
Cholesky factorization, 350
conditionally stable, 94
conjugate gradient, 433
cubic spline, 208
divided differences, 191, 195
Evaluation of Lagrange polynomials,
181
fixed point method, 135
Fletcher-Reeves, 436
forward substitution, 375
Householder QR, 399
linear least squares, 223
modified Gram-Schmidt
orthonormalization, 395
moments of clamped cubic spline, 211,
212
naive Gaussian elimination, 321
naive Gram-Schmidt
orthonormalization, 395
Newton’s form of polynomials, 188
Newton’s method, 143
nonlinear conjugate gradient, 436
power method, 474, 478
preconditioned conjugate gradient, 434
secant method, 149
Sherman-Morrison-Woodbury, 84, 378
stable, 94
steepest descent, 424
steepest descent for linear systems, 428
unstable, 94
annihilation technique, 486
anomaly
eccentric, 165
true, 165
approximation, 175
argmin, 389
augmented matrix, 319
B-splines, 217
cardinal, 217
back-propagation, 446
backward Euler method, 290
backward propagation, 446
backward substitution, 317, 319
Barzilai-Borwein method, 424
base, 91
battery, 369
best approximation, 386
bisection method, 127
Bolzano, see theorem
boundary, 207
clamped, 207
condition, 207
natural, 207
not-a-knot, 207
periodic, 207
Broyden’s method, 440
Butcher tableau, 297
calculus, 105
cardinal B-splines, 217
catastrophic cancelation, 88
Cauchy-Schwarz inequality, 339
Chebyshev, 185
Cholesky factorization, 348
chopping, 92
classifier, 454
compartmental model, 307
complete pivoting, 332
501

502
Index
complex-step approximation, 174, 313
composite rule, 252, 255
condition number, 337, 391
conjugate gradient, 431, 432
preconditioned, 434
variations, 436
continuous, see function
convergence, 131
order, 131
rate, 131
convex
function, 417
optimization, 417
cost function, 446
Cramer’s rule, 64
Crank-Nicolson method, 290
critical point, 418
Crout factorization, 348
cubic spline, 207
algorithm, 208
error, 213
Dai and Yuan extension, 436
Dai-Yuan method, 437
decomposition
QR, 397
SVD, 401
deep learning, 447
defective, 468
degree of exactness, 257
derivative, 110
descent
direction, 419
determinant, 347
Vandermonde, 178
diagonalization, 468
differentiation, 110
dimension reduction, 406
directional derivative, 419
discretization error, 88
divided differences, 188, 190, 193
dominant, 472
dot product, 338
eigenspace, 468
eigenvactor, 467
eigenvalue, 64, 472
dominant, 472
principal, 472
eigenvalues, 467
eigenvector, 64
eigenvectors
generalized, 487
electric circuit, 369
epidemiology, 307
error
absolute, 93
relative, 93
Euclidean norm, 338
Euler method, 283
exactness, 257
exponent, 91
extrapolation, 175
factorization
HHT , 349
LDLT , 348
LU, 323
QR, 397
SVD, 401
Cholesky, 348
Crout, 348
false position, 173
feedforward network, 445, 449
finite difference, 148, 275
backward finite difference, 277
central finite difference, 277
forward finite difference, 275
second-order finite difference, 279
fixed point, 135
existence, 139
method, 135
uniqueness, 139
Fletcher-Reeves extension, 436
Fletcher-Reeves method, 437
floating point error, 88
floating-point, 87
double precision, 91
precision, 91
single precision, 91
Frobenius norm, 341
function, 107
activation, 448
continuous, 107
discontinuous, 107
hat, 205
Lipschitz continuous, 108
objective, 417
recursive, 29
root, 107

Index
503
Runge, 185, 231
smooth, 111
tangent, 110
Gauss, 258
Gauss-Legendre
nodes, 262
weights, 262
Gauss-Legendre quadrature, 260
Gauss-Newton method, 442
Gauss-Seidel method, 358, 361
for nonlinear equations, 300
Gaussian elimination, 317
Gaussian quadrature, 258, 262
composite, 262
error, 264
nodes, 259
weights, 259
general directions, 431
generalized inverse, 390
geometric multiplicity, 468
global error, 287
gradient, 418
gradient method, 417
Gram-Schmidt orthonormalization, 393
grid, 19, 283
Hadamard, 282
hat functions, 205
heliocentric distance, 165
Hermite
error, 198
interpolant, 196
Hestenes and Stiefel extension, 436
Hestenes-Stiefel method, 437
Heun’s method, 291
hidden layer, 447
hidden layers, 445
Householder
matrix, 398
reflection, 399
image compression, 409
image processing, 409
implicit Euler method, 290
implicit trapezoidal method, 290
improved Euler method, 291
index of annihilation, 488
inequality
Cauchy-Schwarz, 339
Polyak- Lojasiewicz, 422
triangle, 340
infectious disease, 307
initial value problem, 282
inner product, 338, 384
input layer, 445
integral, 115
Riemann, 116
integration, 247
numerical, 247
intermediate stages, 292
interpolant, 175, 177
interpolation, 175
Aitken-Neville, 192
Hermite, 195
Lagrange, 177
moments, 209
piecewise cubic, 207
piecewise linear, 202, 205
piecewise polynomial, 200
spline, 200
interval, 105
closed, 105
open, 105
inverse iteration, 475
inverse power method, 475
iteration matrix, 360
iterative method, 355
Jacobi method, 356, 361
Jacobian matrix, 159
Jordan
block, 488
canonical form, 487, 488
chain, 488
normal form, 487, 488
string, 488
Jordan canonical form, 468, 487, 488
Jordan normal form, 468, 487, 488
Kepler’s equation, 165
Kirchhoff’s laws, 369
knots, 175
Kronecker delta, 260
Lagrange, 180
basis, 180
interpolation, 177
polynomial, 177, 180
layers, 447
learning rate, 420
least squares, 222

504
Index
linear, 222
method, 222
non-polynomial, 227
nonlinear, 225, 227
polynomial, 225
problem, 222
Levenberg-Marquardt method, 443
linear algebra, 317
linear independence, 384
linear least squares, 388
linear regression, 222
linear space, 383
linear system, 62
circulant, 74
Toeplitz, 73
triangular, 73
linearly dependent, 384
linearly independent, 384
Lipschitz continuous, see function, 439
local minimizer, 417
local truncation error, 287
loss of significance, 94
machine epsilon, 89
mantissa, 91
Markov chain, 481
Markov matrix, 481
MatPlotLib, 75
imshow, 239
plot, 76
show, 76
spy, 368
imshow, 409
matrix, 37
addition, 38
augmented, 319
banded, 40, 66, 67
circulant, 74
column stochastic, 481
condition number, 337
defective, 468, 487
determinant, 61, 347
diagonal, 40
diagonalizable, 469
diagonally dominant, 361
full-rank, 384
Hermitian, 66, 72
Hessian, 419
Householder, 398
identity, 39
ill-conditioned, 345
inverse, 60, 346
iteration, 360
Jacobian, 159
lower triangular, 41
Markov, 481
matrix multiplication, 38
multiplication, 54, 365
nondefective, 468
permuation, 333
positive definite, 69, 348
positive semidefinite, 69
preconditioner, 435
range, 398
rank, 384
scalar multiplication, 38
similar, 468
simple structure, 468
sparse, 362
stochastic, 481
symmetric, 41
Toeplitz, 73
transpose, 41
triangular, 40, 48, 73
tridiagonal, 380
unit triangular, 324
upper triangular, 40
Vandermonde, 178
zero, 39
matrix norm, 337
mean motion, 165
mesh, 19, 283
method
Barzilai-Borwein, 424
bisection, 127
Broyden, 440
complex step Newton, 174
conjugate gradient, 431,
432
false position, 173
fixed point, 135
Gauss-Seidel, 358, 361
iterative, 355
Jacobi, 356
Newton, 141
quasi-Newton, 439
secant, 147
steepest descent, 423, 426
Steffensen, 156
midpoint rule, see quadrature
minibatch, 454
minimizer, 417

Index
505
modified Gram-Schmidt
orthonormalization, 395
Moore-Penrose inverse, 390
multiplicity
algebraic, 467
geometric, 468
multiplier, 324
natural norm, 340
neural network, 417, 444, 445
bias, 449
feedforward network, 445
layer, 445
supervised learning, 446
weights, 445
neuron, 445
Newton’s method, 141, 438
complex-step approximation, 174, 313
nodes, 175
Chebyshev, 185
non-polynomial fit, 227
nondefective, 468
nonlinear Gauss-Seidel method, 300
nonlinear system, 158
norm, 185, 337, 384
ℓp, 341
Euclidean, 338
Frobenius, 341
natural, 340
normal equations, 223, 391, 393
numerical differentiation, 275
numerical linear algebra, 317
NumPy, 42
arange, 77
count non-zero, 369
det, 61, 347
dot, 58
eig, 65
empty, 52
eye, 47
interp, 204
inv, 346
isclose, 143
linspace, 77
lstsq, 391
matrix power, 59
matrix, 58
ones, 47
pinv, 391, 397
poly1d, 228
polyder, 197
polyfit, 228
power, 59
qr, 400
solve, 62
svd, 408
toarray, 369
todense, 369
transpose, 49
tril, 48
triu, 48
vander, 178
zeros, 46
array, 42
inv, 60
matrix addition, 50
matrix assignment, 50
scalar multiplication, 50
vector, 45
Numpypoly1d, 197
objective function, 417
operations count, 323
optimal solution, 389
optimization, 417
order, 115
ordinary differential equations, 282
autonomous, 284
first-order, 282
stiff, 290
systems, 306
orthogonal polynomials, 260
orthogonal projection, 387
orthogonal vectors, 386
orthonormalization, 393
outer product, 440
output layer, 445
overfitting, 454
overflow, 91, 92
PageRank algorithm, 479
partial pivoting, 331
perceptron, 445
perihelion, 165
Perron-Frobenius theorem, 482
pivot, 329
pivoting, 329
complete, 332
partial, 331
scaled partial, 332
scaled-column, 332
Polak and Ribi`ere extension, 436

506
Index
Polak-Ribi`ere method, 437
polynomial, 113
multivariable Taylor, 159
fit, 225
Lagrange, 180
Legendre, 260
Newton’s, 188
orthogonal, 260
remainder, 118
Taylor, 113, 118, 419
positive definite matrix, 69, 348
power iteration, 472
power method, 472
precondition, 357
preconditioner, 435
preconditioning, 434
principal component analysis, 406
principal eigenvector, 472
pseudoinverse, 390, 407
Python, 3
assert, 25
break, 25
close, 31
for/else loops, 18
for loops, 16
if statement, 23
imageio, 239
imread, 239
lambda functions, 29
meshgrid, 237
open, 31
read, 31
sklearn, 454
str, 31
train test split, 456
while loops, 21
write, 31
boolean variables, 21
classes, 29
dictionaries, 12
division by zero, 25
error control, 24
exceptions, 24
files, 31
flow control, 16
functions, 26
imageio, 409
imread, 409
indices, 43
lists, 13
slicing, 44
str, 31
strings, 10
timing, 53
tuples, 11
quadrature, 117, 247
Gauss-Legendre, 260
Gaussian, 258
midpoint rule, 117, 247
Newton-Cotes rules, 249
one-third rule, 254
rules, 247
Simpson’s rule, 254
trapezoidal rule, 251
quasi-Newton’s method, 439
rectified linear unit, 448
reduced form, 319
reflectors, 399
regression, 222, 455
regressor, 454
Regula Falsi method, 173
remainder, 118
residual, 114, 426
resistor, 369
Richardson’s extrapolation, 280
Riemann integral, 248
rounding, 92
row operations, 318
Runge
function, 185
phenomenon, 185
Runge-Kutta method, 292, 295
adaptive Runge-Kutta methods, 301
diagonally implicit, 298
explicit, 295
Gauss-Legendre Runge-Kutta methods,
300
implicit, 298
Runge-Kutta-Fehlberg method, 302
saddle point, 418
scaled pivoting, 332
scientific notation, 90
Scikit-Learn
MLPClassifier, 454
model selection, 456
neural network, 454
sklearn, 453
train test split, 456
SciPy, 66

Index
507
CubicSpline, 230
bisect, 160
bsr matrix, 363
cg, 437
cho factor, 354
cho solve, 354
cholesky, 354
coo matrix, 363
count non-zero, 369
csc matrix, 363
csr matrix, 363
dia matrix, 363
dok matrix, 363
fixed point, 161
fixed quad, 267
fsolve, 164
golden, 424
integrate, 265, 303
interp1d, 234
interp2d, 235
interpolate, 229
lagrange, 229
ldl, 354
lil matrix, 363
linalg, 68, 353
lu factor, 353, 476
lu solve, 353, 476
lu, 352
minimize, 441
newton, 162
optimize, 160
quadrature, 267
radau, 303
rk23, 303
rk45, 303
simpson, 266
solve banded, 68
solve circulant, 74
solve ivp, 303
solve toeplitz, 73
solve triangular, 73, 354
solveh banded, 69
sparse, 367
splev, 232
splrep, 232
spsolve, 367
trapezoid, 265
score, 480
secant method, 147
Segr´e characteristic, 489
sequence, 105, 106
convergence, 105
convergent, 106
Sherman-Morrison formula, 440
Sherman-Morrison-Woodbury algorithm,
84, 378
shifted inverse iteration, 477
shifted power method, 477
similar matrix, 468
Simpson’s rule, 254
composite, 255
error, 256
singular value decomposition, 401
singular values, 402
SIR model, 307
sites, 175
sparse
Gauss-Seidel method, 365
sparsity index, 369
sparse format, 364
sparse matrix, 362
multiplication, 365
sparsity index, 369
spectral radius, 341
spline, 207
clamped, 207
cubic, 207
de Boor, 219
natural, 207
periodic, 207
SciPy, 232
stability, 293
steepest descent, 423, 426
Steffensen’s method, 156
stepsize, 19
stochastic gradient, 454
stochastic matrix, 481
successive over-relaxation, 377
supervised learning, 446
synapsis, 445
tangent, 111
Taylor, see polynomial
Taylor polynomial, 419
tensor produce, 440
the golden ratio, 152
theorem
Bolzano, 109
fundamental theorem of calculus, 117
intermediate value, 109
mean value, 112
mean value theorem of integrals, 118

508
Index
Neumann, 342
Pythagoras, 386
Rolle, 112
Weierstrass approximation, 176
timestep, 283
trapezoidal rule, 251
composite, 252
error, 251
triangle inequality, 340
triangular form, 319
truncation error, 88
underflow, 91, 92
unit roundoff, 89
unsupervised learning, 406
upper triangular, 40
Vandermonde, 178
vector format, 52, 249
vector norm, 337
vector space, 383
vectorized algorithm, 52, 256
Weierstrass, see theorem
weights
Gauss-Legendre, 261, 262
Newton-Cotes, 250
quadrature, 247
synaptic, 445
Wolfe conditions, 437
x-axis, 75
y-axis, 75
zero
division by, 23
matrix, 39

